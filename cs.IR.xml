<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;CLLM4Rec&#65292;&#39318;&#20010;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#25512;&#33616;&#31995;&#32479;&#30340; ID &#27169;&#24335;&#32039;&#23494;&#38598;&#25104;&#30340;&#21327;&#21516;&#25512;&#33616;&#31639;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#35821;&#20041;&#24046;&#36317;&#12289;&#34394;&#20551;&#30456;&#20851;&#21644;&#20302;&#25928;&#25512;&#33616;&#31561;&#38382;&#39064;&#12290;&#36890;&#36807;&#25193;&#23637;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#35789;&#27719;&#34920;&#65292;&#24182;&#24341;&#20837;&#36719;&#30828;&#25552;&#31034;&#31574;&#30053;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#27169;&#25311;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#21327;&#21516;&#19982;&#20869;&#23481;&#35821;&#20041;&#12290;</title><link>http://arxiv.org/abs/2311.01343</link><description>&lt;p&gt;
&#21327;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Collaborative Large Language Model for Recommender Systems. (arXiv:2311.01343v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;CLLM4Rec&#65292;&#39318;&#20010;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#25512;&#33616;&#31995;&#32479;&#30340; ID &#27169;&#24335;&#32039;&#23494;&#38598;&#25104;&#30340;&#21327;&#21516;&#25512;&#33616;&#31639;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#35821;&#20041;&#24046;&#36317;&#12289;&#34394;&#20551;&#30456;&#20851;&#21644;&#20302;&#25928;&#25512;&#33616;&#31561;&#38382;&#39064;&#12290;&#36890;&#36807;&#25193;&#23637;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#35789;&#27719;&#34920;&#65292;&#24182;&#24341;&#20837;&#36719;&#30828;&#25552;&#31034;&#31574;&#30053;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#27169;&#25311;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#21327;&#21516;&#19982;&#20869;&#23481;&#35821;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#23545;&#22522;&#20110;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24320;&#21457;&#19979;&#19968;&#20195;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#20135;&#29983;&#20102;&#20852;&#36259;&#65292;&#20805;&#20998;&#21033;&#29992;&#20854;&#32534;&#30721;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#33258;&#28982;&#35821;&#35328;&#19982;&#25512;&#33616;&#20219;&#21153;&#20043;&#38388;&#30340;&#35821;&#20041;&#24046;&#36317;&#20173;&#26410;&#24471;&#21040;&#24456;&#22909;&#30340;&#35299;&#20915;&#65292;&#23548;&#33268;&#19968;&#20123;&#38382;&#39064;&#65292;&#22914;&#34394;&#20551;&#30456;&#20851;&#30340;&#29992;&#25143;/&#39033;&#30446;&#25551;&#36848;&#31526;&#12289;&#23545;&#29992;&#25143;/&#39033;&#30446;&#20869;&#23481;&#30340;&#20302;&#25928;&#35821;&#35328;&#24314;&#27169;&#20197;&#21450;&#36890;&#36807;&#33258;&#21160;&#22238;&#24402;&#36827;&#34892;&#20302;&#25928;&#30340;&#25512;&#33616;&#31561;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CLLM4Rec&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#32039;&#23494;&#38598;&#25104;LLM&#33539;&#24335;&#21644;RS&#30340;ID&#33539;&#24335;&#30340;&#29983;&#25104;RS&#65292;&#26088;&#22312;&#21516;&#26102;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#29992;&#25143;/&#39033;&#30446;ID&#26631;&#35760;&#25193;&#23637;&#20102;&#39044;&#35757;&#32451;LLM&#30340;&#35789;&#27719;&#34920;&#65292;&#20197;&#24544;&#23454;&#22320;&#27169;&#25311;&#29992;&#25143;/&#39033;&#30446;&#30340;&#21327;&#21516;&#21644;&#20869;&#23481;&#35821;&#20041;&#12290;&#22240;&#27492;&#65292;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36719;&#30828;&#25552;&#31034;&#31574;&#30053;&#65292;&#36890;&#36807;&#35821;&#35328;&#24314;&#27169;&#26377;&#25928;&#22320;&#23398;&#20064;&#29992;&#25143;/&#39033;&#30446;&#30340;&#21327;&#21516;/&#20869;&#23481;&#26631;&#35760;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there is a growing interest in developing next-generation recommender systems (RSs) based on pretrained large language models (LLMs), fully utilizing their encoded knowledge and reasoning ability. However, the semantic gap between natural language and recommendation tasks is still not well addressed, leading to multiple issues such as spuriously-correlated user/item descriptors, ineffective language modeling on user/item contents, and inefficient recommendations via auto-regression, etc. In this paper, we propose CLLM4Rec, the first generative RS that tightly integrates the LLM paradigm and ID paradigm of RS, aiming to address the above challenges simultaneously. We first extend the vocabulary of pretrained LLMs with user/item ID tokens to faithfully model the user/item collaborative and content semantics. Accordingly, in the pretraining stage, a novel soft+hard prompting strategy is proposed to effectively learn user/item collaborative/content token embeddings via language m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29992;&#25143;&#25552;&#20379;&#30340;&#35780;&#35770;&#25991;&#26412;&#26500;&#24314;&#31616;&#27905;&#29992;&#25143;&#26723;&#26696;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25903;&#25345;&#20114;&#21160;&#38750;&#24120;&#31232;&#30095;&#20294;&#20449;&#24687;&#20016;&#23500;&#30340;&#29992;&#25143;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#31934;&#24515;&#36873;&#25321;&#30340;&#25991;&#26412;&#29255;&#27573;&#21487;&#20197;&#23454;&#29616;&#26368;&#20339;&#24615;&#33021;&#65292;&#24182;&#36229;&#36807;&#20102;&#20351;&#29992;ChatGPT&#29983;&#25104;&#30340;&#29992;&#25143;&#26723;&#26696;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.01314</link><description>&lt;p&gt;
&#36890;&#36807;&#31616;&#27905;&#30340;&#29992;&#25143;&#26723;&#26696;&#20013;&#30340;&#35780;&#35770;&#25991;&#26412;&#36827;&#34892;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Recommendations by Concise User Profiles from Review Text. (arXiv:2311.01314v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29992;&#25143;&#25552;&#20379;&#30340;&#35780;&#35770;&#25991;&#26412;&#26500;&#24314;&#31616;&#27905;&#29992;&#25143;&#26723;&#26696;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25903;&#25345;&#20114;&#21160;&#38750;&#24120;&#31232;&#30095;&#20294;&#20449;&#24687;&#20016;&#23500;&#30340;&#29992;&#25143;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#31934;&#24515;&#36873;&#25321;&#30340;&#25991;&#26412;&#29255;&#27573;&#21487;&#20197;&#23454;&#29616;&#26368;&#20339;&#24615;&#33021;&#65292;&#24182;&#36229;&#36807;&#20102;&#20351;&#29992;ChatGPT&#29983;&#25104;&#30340;&#29992;&#25143;&#26723;&#26696;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#23545;&#20110;&#21463;&#27426;&#36814;&#30340;&#29289;&#21697;&#21644;&#19982;&#29992;&#25143;&#30340;&#20016;&#23500;&#20114;&#21160;&#65288;&#21916;&#27426;&#12289;&#35780;&#20998;&#31561;&#65289;&#26368;&#20026;&#25104;&#21151;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#20010;&#22256;&#38590;&#19988;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#30340;&#24773;&#20917;&#65292;&#21363;&#22914;&#20309;&#25903;&#25345;&#20114;&#21160;&#38750;&#24120;&#31232;&#30095;&#20294;&#21457;&#24067;&#20449;&#24687;&#20016;&#23500;&#30340;&#35780;&#35770;&#25991;&#26412;&#30340;&#29992;&#25143;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#30740;&#31350;&#28041;&#21450;&#20004;&#20010;&#20855;&#26377;&#36825;&#20123;&#29305;&#28857;&#30340;&#22270;&#20070;&#31038;&#21306;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#34920;&#24449;&#23398;&#20064;&#26694;&#26550;&#65292;&#28085;&#30422;&#29992;&#25143;-&#29289;&#21697;&#20114;&#21160;&#12289;&#29289;&#21697;&#20869;&#23481;&#21644;&#29992;&#25143;&#25552;&#20379;&#30340;&#35780;&#35770;&#12290;&#20026;&#20102;&#20811;&#26381;&#20114;&#21160;&#31232;&#30095;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20123;&#25216;&#26415;&#26469;&#36873;&#25321;&#26500;&#24314;&#31616;&#27905;&#29992;&#25143;&#26723;&#26696;&#30340;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#32447;&#32034;&#12290;&#36890;&#36807;&#26469;&#33258;Amazon&#21644;Goodreads&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#20840;&#38754;&#23454;&#39564;&#34920;&#26126;&#65292;&#31934;&#24515;&#36873;&#25321;&#30340;&#25991;&#26412;&#29255;&#27573;&#21487;&#20197;&#23454;&#29616;&#26368;&#20339;&#24615;&#33021;&#65292;&#29978;&#33267;&#20248;&#20110;ChatGPT&#29983;&#25104;&#30340;&#29992;&#25143;&#26723;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems are most successful for popular items and users with ample interactions (likes, ratings etc.). This work addresses the difficult and underexplored case of supporting users who have very sparse interactions but post informative review texts. Our experimental studies address two book communities with these characteristics. We design a framework with Transformer-based representation learning, covering user-item interactions, item content, and user-provided reviews. To overcome interaction sparseness, we devise techniques for selecting the most informative cues to construct concise user profiles. Comprehensive experiments, with datasets from Amazon and Goodreads, show that judicious selection of text snippets achieves the best performance, even in comparison to ChatGPT-generated user profiles.
&lt;/p&gt;</description></item><item><title>VM-Rec&#26159;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20919;&#21551;&#21160;&#29992;&#25143;&#25512;&#33616;&#38382;&#39064;&#30340;&#21464;&#20998;&#26144;&#23556;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#29983;&#25104;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#23884;&#20837;&#30340;&#29616;&#26377;&#29992;&#25143;&#30340;&#20114;&#21160;&#65292;&#20174;&#32780;&#27169;&#25311;&#29983;&#25104;&#20919;&#21551;&#21160;&#29992;&#25143;&#30340;&#23884;&#20837;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2311.01304</link><description>&lt;p&gt;
VM-Rec&#65306;&#19968;&#31181;&#29992;&#20110;&#20919;&#21551;&#21160;&#29992;&#25143;&#25512;&#33616;&#30340;&#21464;&#20998;&#26144;&#23556;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
VM-Rec: A Variational Mapping Approach for Cold-start User Recommendation. (arXiv:2311.01304v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01304
&lt;/p&gt;
&lt;p&gt;
VM-Rec&#26159;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20919;&#21551;&#21160;&#29992;&#25143;&#25512;&#33616;&#38382;&#39064;&#30340;&#21464;&#20998;&#26144;&#23556;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#29983;&#25104;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#23884;&#20837;&#30340;&#29616;&#26377;&#29992;&#25143;&#30340;&#20114;&#21160;&#65292;&#20174;&#32780;&#27169;&#25311;&#29983;&#25104;&#20919;&#21551;&#21160;&#29992;&#25143;&#30340;&#23884;&#20837;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20919;&#21551;&#21160;&#38382;&#39064;&#26159;&#22823;&#22810;&#25968;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30340;&#20849;&#21516;&#25361;&#25112;&#12290;&#20256;&#32479;&#30340;&#25512;&#33616;&#27169;&#22411;&#22312;&#20919;&#21551;&#21160;&#29992;&#25143;&#30340;&#20114;&#21160;&#38750;&#24120;&#26377;&#38480;&#26102;&#36890;&#24120;&#38590;&#20197;&#29983;&#25104;&#20855;&#26377;&#36275;&#22815;&#34920;&#36798;&#33021;&#21147;&#30340;&#23884;&#20837;&#12290;&#27492;&#22806;&#65292;&#32570;&#20047;&#29992;&#25143;&#30340;&#36741;&#21161;&#20869;&#23481;&#20449;&#24687;&#21152;&#21095;&#20102;&#25361;&#25112;&#30340;&#23384;&#22312;&#65292;&#20351;&#24471;&#22823;&#22810;&#25968;&#20919;&#21551;&#21160;&#26041;&#27861;&#38590;&#20197;&#24212;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22914;&#26524;&#27169;&#22411;&#33021;&#22815;&#20026;&#30456;&#23545;&#26356;&#22810;&#20114;&#21160;&#30340;&#29616;&#26377;&#29992;&#25143;&#29983;&#25104;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#30340;&#23884;&#20837;&#65292;&#36825;&#20123;&#29992;&#25143;&#26368;&#21021;&#20063;&#26159;&#20919;&#21551;&#21160;&#29992;&#25143;&#65292;&#37027;&#20040;&#25105;&#20204;&#21487;&#20197;&#24314;&#31435;&#19968;&#20010;&#20174;&#23569;&#37327;&#21021;&#22987;&#20114;&#21160;&#21040;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#30340;&#23884;&#20837;&#30340;&#26144;&#23556;&#65292;&#27169;&#25311;&#20026;&#20919;&#21551;&#21160;&#29992;&#25143;&#29983;&#25104;&#23884;&#20837;&#30340;&#36807;&#31243;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#20998;&#26144;&#23556;&#26041;&#27861;&#29992;&#20110;&#20919;&#21551;&#21160;&#29992;&#25143;&#25512;&#33616;&#65288;VM-Rec&#65289;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#26681;&#25454;&#20919;&#21551;&#21160;&#29992;&#25143;&#30340;&#21021;&#22987;&#20114;&#21160;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#26144;&#23556;&#20989;&#25968;&#65292;&#24182;&#36827;&#34892;&#21442;&#25968;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The cold-start problem is a common challenge for most recommender systems. With extremely limited interactions of cold-start users, conventional recommender models often struggle to generate embeddings with sufficient expressivity. Moreover, the absence of auxiliary content information of users exacerbates the presence of challenges, rendering most cold-start methods difficult to apply. To address this issue, our motivation is based on the observation that if a model can generate expressive embeddings for existing users with relatively more interactions, who were also initially cold-start users, then we can establish a mapping from few initial interactions to expressive embeddings, simulating the process of generating embeddings for cold-start users. Based on this motivation, we propose a Variational Mapping approach for cold-start user Recommendation (VM-Rec). Firstly, we generate a personalized mapping function for cold-start users based on their initial interactions, and parameters 
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411;&#30340;&#35821;&#20041;&#21305;&#37197;&#33021;&#21147;&#21644;&#24555;&#36895;&#21069;&#21521;&#32034;&#24341;&#65292;&#25552;&#39640;&#20102;&#31070;&#32463;&#25490;&#21517;&#30340;&#25928;&#29575;&#21644;&#24310;&#36831;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#39044;&#35745;&#31639;&#34920;&#31034;&#21644;&#20248;&#21270;&#32034;&#24341;&#23610;&#23544;&#65292;&#36827;&#19968;&#27493;&#25913;&#21892;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#36164;&#28304;&#28040;&#32791;&#12290;</title><link>http://arxiv.org/abs/2311.01263</link><description>&lt;p&gt;
&#20351;&#29992;&#21069;&#21521;&#32034;&#24341;&#21644;&#36731;&#37327;&#32423;&#32534;&#30721;&#22120;&#30340;&#39640;&#25928;&#31070;&#32463;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Efficient Neural Ranking using Forward Indexes and Lightweight Encoders. (arXiv:2311.01263v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01263
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411;&#30340;&#35821;&#20041;&#21305;&#37197;&#33021;&#21147;&#21644;&#24555;&#36895;&#21069;&#21521;&#32034;&#24341;&#65292;&#25552;&#39640;&#20102;&#31070;&#32463;&#25490;&#21517;&#30340;&#25928;&#29575;&#21644;&#24310;&#36831;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#39044;&#35745;&#31639;&#34920;&#31034;&#21644;&#20248;&#21270;&#32034;&#24341;&#23610;&#23544;&#65292;&#36827;&#19968;&#27493;&#25913;&#21892;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#36164;&#28304;&#28040;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#21452;&#32534;&#30721;&#22120;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#30340;&#26631;&#20934;&#12290;&#23427;&#20204;&#37319;&#29992;&#20102;&#22823;&#22411;&#30340;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#22312;&#36164;&#28304;&#21644;&#24310;&#36831;&#26041;&#38754;&#25928;&#29575;&#20302;&#19979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24555;&#36895;&#21069;&#21521;&#32034;&#24341;&#8212;&#8212;&#21033;&#29992;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411;&#30340;&#35821;&#20041;&#21305;&#37197;&#33021;&#21147;&#36827;&#34892;&#39640;&#25928;&#21644;&#26377;&#25928;&#30340;&#37325;&#26032;&#25490;&#21517;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#22312;&#38750;&#24120;&#39640;&#30340;&#26816;&#32034;&#28145;&#24230;&#19979;&#36827;&#34892;&#37325;&#26032;&#25490;&#21517;&#65292;&#24182;&#36890;&#36807;&#20998;&#25968;&#25554;&#20540;&#32467;&#21512;&#20102;&#35789;&#27719;&#21305;&#37197;&#21644;&#35821;&#20041;&#21305;&#37197;&#30340;&#20248;&#28857;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20943;&#36731;&#21452;&#32534;&#30721;&#22120;&#30340;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;&#39318;&#20808;&#65292;&#36890;&#36807;&#39044;&#35745;&#31639;&#34920;&#31034;&#12289;&#36991;&#20813;&#19981;&#24517;&#35201;&#30340;&#35745;&#31639;&#25110;&#38477;&#20302;&#32534;&#30721;&#22120;&#30340;&#22797;&#26434;&#24230;&#65292;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#38477;&#20302;&#20102;&#25490;&#21517;&#30340;&#36164;&#28304;&#28040;&#32791;&#21644;&#24310;&#36831;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20248;&#21270;&#20102;&#32034;&#24341;&#30340;&#20869;&#23384;&#21344;&#29992;&#21644;&#32500;&#25252;&#25104;&#26412;&#65307;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20114;&#34917;&#30340;&#25216;&#26415;&#26469;&#20943;&#23567;&#32034;&#24341;&#30340;&#23610;&#23544;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dual-encoder-based dense retrieval models have become the standard in IR. They employ large Transformer-based language models, which are notoriously inefficient in terms of resources and latency. We propose Fast-Forward indexes -- vector forward indexes which exploit the semantic matching capabilities of dual-encoder models for efficient and effective re-ranking. Our framework enables re-ranking at very high retrieval depths and combines the merits of both lexical and semantic matching via score interpolation. Furthermore, in order to mitigate the limitations of dual-encoders, we tackle two main challenges: Firstly, we improve computational efficiency by either pre-computing representations, avoiding unnecessary computations altogether, or reducing the complexity of encoders. This allows us to considerably improve ranking efficiency and latency. Secondly, we optimize the memory footprint and maintenance cost of indexes; we propose two complementary techniques to reduce the index size a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;AI&#21103;&#39550;&#39542;&#21592;&#26469;&#23548;&#33322;&#22797;&#26434;&#25628;&#32034;&#20219;&#21153;&#65292;&#24182;&#25506;&#35752;&#20102;&#29983;&#25104;AI&#21644;&#36741;&#21161;&#20195;&#29702;&#30340;&#20986;&#29616;&#23545;&#20110;&#25903;&#25345;&#22797;&#26434;&#25628;&#32034;&#20219;&#21153;&#30340;&#28508;&#21147;&#21644;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01235</link><description>&lt;p&gt;
&#20351;&#29992;AI&#21103;&#39550;&#39542;&#21592;&#23548;&#33322;&#22797;&#26434;&#25628;&#32034;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
Navigating Complex Search Tasks with AI Copilots. (arXiv:2311.01235v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01235
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;AI&#21103;&#39550;&#39542;&#21592;&#26469;&#23548;&#33322;&#22797;&#26434;&#25628;&#32034;&#20219;&#21153;&#65292;&#24182;&#25506;&#35752;&#20102;&#29983;&#25104;AI&#21644;&#36741;&#21161;&#20195;&#29702;&#30340;&#20986;&#29616;&#23545;&#20110;&#25903;&#25345;&#22797;&#26434;&#25628;&#32034;&#20219;&#21153;&#30340;&#28508;&#21147;&#21644;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#22914;&#20449;&#24687;&#26816;&#32034;(IR)&#30740;&#31350;&#30028;&#30340;&#35768;&#22810;&#20154;&#25152;&#30693;&#21644;&#27427;&#36175;&#30340;&#37027;&#26679;&#65292;&#25628;&#32034;&#36828;&#26410;&#35299;&#20915;&#12290;&#27599;&#22825;&#37117;&#26377;&#25968;&#30334;&#19975;&#20154;&#22312;&#25628;&#32034;&#24341;&#25806;&#19978;&#38754;&#23545;&#20219;&#21153;&#30340;&#22256;&#38590;&#12290;&#20182;&#20204;&#30340;&#22256;&#38590;&#36890;&#24120;&#19982;&#20219;&#21153;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#20197;&#21450;&#25628;&#32034;&#31995;&#32479;&#26080;&#27861;&#23436;&#20840;&#29702;&#35299;&#20219;&#21153;&#21644;&#25552;&#20379;&#30456;&#20851;&#32467;&#26524;&#26377;&#20851;&#12290;&#20219;&#21153;&#28608;&#21457;&#20102;&#25628;&#32034;&#65292;&#21019;&#24314;&#20102;&#25628;&#32034;&#32773;&#23581;&#35797;&#36830;&#25509;/&#35299;&#20915;&#30340;&#24046;&#36317;/&#38382;&#39064;&#24773;&#20917;&#65292;&#24182;&#22312;&#20182;&#20204;&#22788;&#29702;&#19981;&#21516;&#20219;&#21153;&#26041;&#38754;&#26102;&#39537;&#21160;&#25628;&#32034;&#34892;&#20026;&#12290;&#22797;&#26434;&#25628;&#32034;&#20219;&#21153;&#38656;&#35201;&#30340;&#19981;&#20165;&#26159;&#22522;&#26412;&#20107;&#23454;&#26597;&#25214;&#25110;&#25628;&#32034;&#30340;&#25903;&#25345;&#12290;&#25903;&#25345;&#22797;&#26434;&#20219;&#21153;&#30340;&#26041;&#27861;&#30740;&#31350;&#21253;&#25324;&#29983;&#25104;&#26597;&#35810;&#21644;&#32593;&#31449;&#24314;&#35758;&#65292;&#20010;&#24615;&#21270;&#21644;&#19978;&#19979;&#25991;&#21270;&#25628;&#32034;&#65292;&#20197;&#21450;&#24320;&#21457;&#26032;&#30340;&#25628;&#32034;&#20307;&#39564;&#65292;&#21253;&#25324;&#36328;&#26102;&#38388;&#21644;&#31354;&#38388;&#12290;&#26368;&#36817;&#20852;&#36215;&#30340;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;(AI)&#21644;&#22522;&#20110;&#35813;&#25216;&#26415;&#30340;&#36741;&#21161;&#20195;&#29702;&#65292;&#25110;&#32773;&#35828;&#21103;&#39550;&#39542;&#21592;&#65292;&#30340;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
As many of us in the information retrieval (IR) research community know and appreciate, search is far from being a solved problem. Millions of people struggle with tasks on search engines every day. Often, their struggles relate to the intrinsic complexity of their task and the failure of search systems to fully understand the task and serve relevant results. The task motivates the search, creating the gap/problematic situation that searchers attempt to bridge/resolve and drives search behavior as they work through different task facets. Complex search tasks require more than support for rudimentary fact finding or re-finding. Research on methods to support complex tasks includes work on generating query and website suggestions, personalizing and contextualizing search, and developing new search experiences, including those that span time and space. The recent emergence of generative artificial intelligence (AI) and the arrival of assistive agents, or copilots, based on this technology
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#20559;&#22909;&#23398;&#20064;&#24322;&#26500;&#36229;&#22270;&#32593;&#32476;&#65288;BiPNet&#65289;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20013;&#30340;&#20215;&#26684;&#20559;&#22909;&#38382;&#39064;&#12290;&#36825;&#20010;&#26041;&#27861;&#32771;&#34385;&#20102;&#20215;&#26684;&#20559;&#22909;&#19982;&#20852;&#36259;&#20559;&#22909;&#30340;&#20114;&#30456;&#24433;&#21709;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#21644;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2311.01125</link><description>&lt;p&gt;
&#23545;&#20110;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#30340;&#21452;&#20559;&#22909;&#23398;&#20064;&#24322;&#26500;&#36229;&#22270;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Bi-Preference Learning Heterogeneous Hypergraph Networks for Session-based Recommendation. (arXiv:2311.01125v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01125
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#20559;&#22909;&#23398;&#20064;&#24322;&#26500;&#36229;&#22270;&#32593;&#32476;&#65288;BiPNet&#65289;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20013;&#30340;&#20215;&#26684;&#20559;&#22909;&#38382;&#39064;&#12290;&#36825;&#20010;&#26041;&#27861;&#32771;&#34385;&#20102;&#20215;&#26684;&#20559;&#22909;&#19982;&#20852;&#36259;&#20559;&#22909;&#30340;&#20114;&#30456;&#24433;&#21709;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#21644;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#26088;&#22312;&#22522;&#20110;&#21311;&#21517;&#34892;&#20026;&#24207;&#21015;&#39044;&#27979;&#19979;&#19968;&#20010;&#36141;&#20080;&#30340;&#29289;&#21697;&#12290;&#35768;&#22810;&#32463;&#27982;&#30740;&#31350;&#34920;&#26126;&#65292;&#29289;&#21697;&#20215;&#26684;&#26159;&#24433;&#21709;&#29992;&#25143;&#36141;&#20080;&#20915;&#31574;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#26041;&#27861;&#21482;&#20851;&#27880;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#20559;&#22909;&#65292;&#24573;&#30053;&#20102;&#29992;&#25143;&#30340;&#20215;&#26684;&#20559;&#22909;&#12290;&#23454;&#38469;&#19978;&#65292;&#26377;&#20004;&#20010;&#20027;&#35201;&#30340;&#25361;&#25112;&#38459;&#30861;&#25105;&#20204;&#33719;&#21462;&#20215;&#26684;&#20559;&#22909;&#12290;&#39318;&#20808;&#65292;&#20215;&#26684;&#20559;&#22909;&#19982;&#21508;&#31181;&#29289;&#21697;&#29305;&#24449;&#65288;&#21363;&#31867;&#21035;&#21644;&#21697;&#29260;&#65289;&#23494;&#20999;&#30456;&#20851;&#65292;&#36825;&#35201;&#27714;&#25105;&#20204;&#20174;&#24322;&#26500;&#20449;&#24687;&#20013;&#25366;&#25496;&#20215;&#26684;&#20559;&#22909;&#12290;&#20854;&#27425;&#65292;&#20215;&#26684;&#20559;&#22909;&#21644;&#20852;&#36259;&#20559;&#22909;&#26159;&#30456;&#20114;&#20381;&#36182;&#30340;&#65292;&#20849;&#21516;&#20915;&#23450;&#29992;&#25143;&#30340;&#36873;&#25321;&#65292;&#36825;&#35201;&#27714;&#25105;&#20204;&#21516;&#26102;&#32771;&#34385;&#20215;&#26684;&#21644;&#20852;&#36259;&#20559;&#22909;&#36827;&#34892;&#24847;&#22270;&#24314;&#27169;&#12290;&#20026;&#20102;&#24212;&#23545;&#19978;&#36848;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#26041;&#27861;&#8212;&#8212;&#21452;&#20559;&#22909;&#23398;&#20064;&#24322;&#26500;&#36229;&#22270;&#32593;&#32476;&#65288;BiPNet&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Session-based recommendation intends to predict next purchased items based on anonymous behavior sequences. Numerous economic studies have revealed that item price is a key factor influencing user purchase decisions. Unfortunately, existing methods for session-based recommendation only aim at capturing user interest preference, while ignoring user price preference. Actually, there are primarily two challenges preventing us from accessing price preference. Firstly, the price preference is highly associated to various item features (i.e., category and brand), which asks us to mine price preference from heterogeneous information. Secondly, price preference and interest preference are interdependent and collectively determine user choice, necessitating that we jointly consider both price and interest preference for intent modeling. To handle above challenges, we propose a novel approach Bi-Preference Learning Heterogeneous Hypergraph Networks (BiPNet) for session-based recommendation. Spec
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#31995;&#32479;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#26597;&#35810;&#33258;&#27880;&#24847;&#21147;&#21644;&#36807;&#28193;&#24863;&#30693;&#23884;&#20837;&#33976;&#39311;&#26469;&#25429;&#25417;&#29992;&#25143;&#20132;&#20114;&#24207;&#21015;&#20013;&#30340;&#21512;&#20316;&#21644;&#36807;&#28193;&#20449;&#21495;&#12290;</title><link>http://arxiv.org/abs/2311.01056</link><description>&lt;p&gt;
&#21512;&#20316;&#19982;&#36716;&#25442;&#65306;&#23558;&#29289;&#21697;&#36716;&#25442;&#36716;&#21270;&#20026;&#22810;&#26597;&#35810;&#33258;&#27880;&#24847;&#21147;&#36827;&#34892;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Collaboration and Transition: Distilling Item Transitions into Multi-Query Self-Attention for Sequential Recommendation. (arXiv:2311.01056v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01056
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#31995;&#32479;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#26597;&#35810;&#33258;&#27880;&#24847;&#21147;&#21644;&#36807;&#28193;&#24863;&#30693;&#23884;&#20837;&#33976;&#39311;&#26469;&#25429;&#25417;&#29992;&#25143;&#20132;&#20114;&#24207;&#21015;&#20013;&#30340;&#21512;&#20316;&#21644;&#36807;&#28193;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20351;&#29992;&#21508;&#31181;&#39034;&#24207;&#27169;&#22359;&#65292;&#22914;&#33258;&#27880;&#24847;&#21147;&#26469;&#23398;&#20064;&#21160;&#24577;&#29992;&#25143;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#25429;&#25417;&#29992;&#25143;&#20132;&#20114;&#24207;&#21015;&#20013;&#30340;&#21512;&#20316;&#21644;&#36807;&#28193;&#20449;&#21495;&#26041;&#38754;&#25928;&#26524;&#36739;&#24046;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#22810;&#26597;&#35810;&#33258;&#27880;&#24847;&#21147;&#19982;&#36807;&#28193;&#24863;&#30693;&#23884;&#20837;&#33976;&#39311;&#65288;MQSA-TED&#65289;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;$L$-&#26597;&#35810;&#33258;&#27880;&#24847;&#21147;&#27169;&#22359;&#65292;&#20351;&#29992;&#28789;&#27963;&#30340;&#31383;&#21475;&#22823;&#23567;&#20316;&#20026;&#27880;&#24847;&#21147;&#26597;&#35810;&#26469;&#25429;&#25417;&#21512;&#20316;&#20449;&#21495;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#26597;&#35810;&#33258;&#27880;&#24847;&#21147;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#38271;&#26597;&#35810;&#21644;&#30701;&#26597;&#35810;&#26469;&#24179;&#34913;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern recommender systems employ various sequential modules such as self-attention to learn dynamic user interests. However, these methods are less effective in capturing collaborative and transitional signals within user interaction sequences. First, the self-attention architecture uses the embedding of a single item as the attention query, which is inherently challenging to capture collaborative signals. Second, these methods typically follow an auto-regressive framework, which is unable to learn global item transition patterns. To overcome these limitations, we propose a new method called Multi-Query Self-Attention with Transition-Aware Embedding Distillation (MQSA-TED). First, we propose an $L$-query self-attention module that employs flexible window sizes for attention queries to capture collaborative signals. In addition, we introduce a multi-query self-attention method that balances the bias-variance trade-off in modeling user preferences by combining long and short-query self-
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#20010;&#20307;&#39033;&#30340;&#20844;&#24179;&#24615;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#20102;&#20851;&#38190;&#30740;&#31350;&#65292;&#24182;&#25351;&#20986;&#20102;&#29616;&#26377;&#25351;&#26631;&#23384;&#22312;&#30340;&#38480;&#21046;&#21644;&#38382;&#39064;&#12290;&#36890;&#36807;&#37325;&#26032;&#23450;&#20041;&#21644;&#32416;&#27491;&#36825;&#20123;&#25351;&#26631;&#65292;&#25110;&#32773;&#35299;&#37322;&#20026;&#20309;&#26576;&#20123;&#38480;&#21046;&#26080;&#27861;&#35299;&#20915;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#35777;&#20998;&#26512;&#65292;&#39564;&#35777;&#20102;&#36825;&#20123;&#25913;&#36827;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01013</link><description>&lt;p&gt;
&#35780;&#20272;&#20010;&#20307;&#39033;&#20844;&#24179;&#24615;&#30340;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#25351;&#26631;&#65306;&#19968;&#39033;&#20851;&#38190;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Evaluation Measures of Individual Item Fairness for Recommender Systems: A Critical Study. (arXiv:2311.01013v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01013
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#20010;&#20307;&#39033;&#30340;&#20844;&#24179;&#24615;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#20102;&#20851;&#38190;&#30740;&#31350;&#65292;&#24182;&#25351;&#20986;&#20102;&#29616;&#26377;&#25351;&#26631;&#23384;&#22312;&#30340;&#38480;&#21046;&#21644;&#38382;&#39064;&#12290;&#36890;&#36807;&#37325;&#26032;&#23450;&#20041;&#21644;&#32416;&#27491;&#36825;&#20123;&#25351;&#26631;&#65292;&#25110;&#32773;&#35299;&#37322;&#20026;&#20309;&#26576;&#20123;&#38480;&#21046;&#26080;&#27861;&#35299;&#20915;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#35777;&#20998;&#26512;&#65292;&#39564;&#35777;&#20102;&#36825;&#20123;&#25913;&#36827;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#24179;&#24615;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#26032;&#20852;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#35805;&#39064;&#12290;&#36817;&#24180;&#26469;&#65292;&#20986;&#29616;&#20102;&#21508;&#31181;&#35780;&#20272;&#21644;&#25913;&#21892;&#20844;&#24179;&#24615;&#30340;&#26041;&#24335;&#12290;&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#29616;&#26377;&#30340;&#20844;&#24179;&#24615;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20165;&#20851;&#27880;&#20010;&#20307;&#39033;&#30340;&#26333;&#20809;&#24230;&#20844;&#24179;&#24615;&#35780;&#20272;&#25351;&#26631;&#65292;&#26088;&#22312;&#37327;&#21270;&#20010;&#20307;&#39033;&#22312;&#21521;&#29992;&#25143;&#25512;&#33616;&#26102;&#30340;&#24046;&#24322;&#65292;&#19982;&#29992;&#25143;&#23545;&#39033;&#30340;&#30456;&#20851;&#24615;&#26080;&#20851;&#12290;&#25105;&#20204;&#25910;&#38598;&#20102;&#25152;&#26377;&#36825;&#20123;&#25351;&#26631;&#65292;&#24182;&#23545;&#23427;&#20204;&#30340;&#29702;&#35770;&#23646;&#24615;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#21457;&#29616;&#27599;&#20010;&#25351;&#26631;&#37117;&#23384;&#22312;&#19968;&#31995;&#21015;&#38480;&#21046;&#65292;&#36825;&#20123;&#38480;&#21046;&#21487;&#33021;&#20351;&#24471;&#21463;&#24433;&#21709;&#30340;&#25351;&#26631;&#38590;&#20197;&#35299;&#37322;&#12289;&#35745;&#31639;&#25110;&#29992;&#20110;&#27604;&#36739;&#25512;&#33616;&#12290;&#25105;&#20204;&#36890;&#36807;&#37325;&#26032;&#23450;&#20041;&#25110;&#32416;&#27491;&#21463;&#24433;&#21709;&#30340;&#25351;&#26631;&#26469;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25110;&#32773;&#25105;&#20204;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#26576;&#20123;&#38480;&#21046;&#26080;&#27861;&#35299;&#20915;&#12290;&#25105;&#20204;&#36824;&#23545;&#36825;&#20123;&#20844;&#24179;&#24615;&#25351;&#26631;&#30340;&#21407;&#22987;&#29256;&#26412;&#21644;&#25105;&#20204;&#32416;&#27491;&#21518;&#30340;&#29256;&#26412;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#35777;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fairness is an emerging and challenging topic in recommender systems. In recent years, various ways of evaluating and therefore improving fairness have emerged. In this study, we examine existing evaluation measures of fairness in recommender systems. Specifically, we focus solely on exposure-based fairness measures of individual items that aim to quantify the disparity in how individual items are recommended to users, separate from item relevance to users. We gather all such measures and we critically analyse their theoretical properties. We identify a series of limitations in each of them, which collectively may render the affected measures hard or impossible to interpret, to compute, or to use for comparing recommendations. We resolve these limitations by redefining or correcting the affected measures, or we argue why certain limitations cannot be resolved. We further perform a comprehensive empirical analysis of both the original and our corrected versions of these fairness measure
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#26415;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#30340;&#31185;&#30740;&#22242;&#38431;&#35782;&#21035;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#33410;&#28857;&#32423;&#21644;&#20803;&#36335;&#24452;&#32423;&#30340;&#27880;&#24847;&#26426;&#21046;&#23398;&#20064;&#20302;&#32500;&#31264;&#23494;&#23454;&#20540;&#21521;&#37327;&#34920;&#31034;&#65292;&#20197;&#26377;&#25928;&#35782;&#21035;&#21644;&#21457;&#29616;&#23398;&#26415;&#32593;&#32476;&#20013;&#30340;&#31185;&#30740;&#22242;&#38431;&#12290;</title><link>http://arxiv.org/abs/2311.00922</link><description>&lt;p&gt;
&#22522;&#20110;&#23398;&#26415;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#30340;&#30740;&#31350;&#22242;&#38431;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Research Team Identification Based on Representation Learning of Academic Heterogeneous Information Network. (arXiv:2311.00922v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00922
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#26415;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#30340;&#31185;&#30740;&#22242;&#38431;&#35782;&#21035;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#33410;&#28857;&#32423;&#21644;&#20803;&#36335;&#24452;&#32423;&#30340;&#27880;&#24847;&#26426;&#21046;&#23398;&#20064;&#20302;&#32500;&#31264;&#23494;&#23454;&#20540;&#21521;&#37327;&#34920;&#31034;&#65292;&#20197;&#26377;&#25928;&#35782;&#21035;&#21644;&#21457;&#29616;&#23398;&#26415;&#32593;&#32476;&#20013;&#30340;&#31185;&#30740;&#22242;&#38431;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#23398;&#26415;&#32593;&#32476;&#36890;&#24120;&#21487;&#20197;&#30001;&#30001;&#22810;&#31867;&#22411;&#33410;&#28857;&#21644;&#20851;&#31995;&#32452;&#25104;&#30340;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#26469;&#25551;&#36848;&#12290;&#29616;&#26377;&#20851;&#20110;&#21516;&#26500;&#20449;&#24687;&#32593;&#32476;&#30340;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#32570;&#20047;&#23545;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#30340;&#25506;&#32034;&#33021;&#21147;&#65292;&#26080;&#27861;&#24212;&#29992;&#20110;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#12290;&#38024;&#23545;&#20174;&#30001;&#24222;&#22823;&#22797;&#26434;&#30340;&#31185;&#25216;&#22823;&#25968;&#25454;&#32452;&#25104;&#30340;&#23398;&#26415;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#20013;&#26377;&#25928;&#35782;&#21035;&#21644;&#21457;&#29616;&#31185;&#30740;&#22242;&#38431;&#30340;&#23454;&#38469;&#38656;&#27714;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#26415;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#30340;&#31185;&#30740;&#22242;&#38431;&#35782;&#21035;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#33410;&#28857;&#32423;&#21644;&#20803;&#36335;&#24452;&#32423;&#30340;&#27880;&#24847;&#26426;&#21046;&#65292;&#22312;&#20445;&#30041;&#32593;&#32476;&#20013;&#33410;&#28857;&#30340;&#20016;&#23500;&#25299;&#25169;&#20449;&#24687;&#21644;&#35821;&#20041;&#20449;&#24687;&#30340;&#22522;&#30784;&#19978;&#65292;&#23398;&#20064;&#20302;&#32500;&#31264;&#23494;&#23454;&#20540;&#21521;&#37327;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Academic networks in the real world can usually be described by heterogeneous information networks composed of multi-type nodes and relationships. Some existing research on representation learning for homogeneous information networks lacks the ability to explore heterogeneous information networks in heterogeneous information networks. It cannot be applied to heterogeneous information networks. Aiming at the practical needs of effectively identifying and discovering scientific research teams from the academic heterogeneous information network composed of massive and complex scientific and technological big data, this paper proposes a scientific research team identification method based on representation learning of academic heterogeneous information networks. The attention mechanism at node level and meta-path level learns low-dimensional, dense and real-valued vector representations on the basis of retaining the rich topological information of nodes in the network and the semantic info
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#20010;&#21517;&#20026;ZeroMat&#30340;&#31639;&#27861;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#34920;&#26126;&#20154;&#31867;&#25991;&#21270;&#21463;&#36827;&#21270;&#38480;&#21046;&#65292;&#20010;&#20307;&#30340;&#25991;&#21270;&#21697;&#21619;&#21487;&#20197;&#22312;&#27809;&#26377;&#21382;&#21490;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20197;&#39640;&#31934;&#24230;&#39044;&#27979;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#21644;&#23545;&#20013;&#22269;&#25919;&#24220;&#27861;&#35268;&#21644;&#25919;&#31574;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2311.00719</link><description>&lt;p&gt;
&#20154;&#31867;&#25991;&#21270;&#21463;&#36827;&#21270;&#38480;&#21046;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is Human Culture Locked by Evolution?. (arXiv:2311.00719v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00719
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#20010;&#21517;&#20026;ZeroMat&#30340;&#31639;&#27861;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#34920;&#26126;&#20154;&#31867;&#25991;&#21270;&#21463;&#36827;&#21270;&#38480;&#21046;&#65292;&#20010;&#20307;&#30340;&#25991;&#21270;&#21697;&#21619;&#21487;&#20197;&#22312;&#27809;&#26377;&#21382;&#21490;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20197;&#39640;&#31934;&#24230;&#39044;&#27979;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#21644;&#23545;&#20013;&#22269;&#25919;&#24220;&#27861;&#35268;&#21644;&#25919;&#31574;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#25991;&#21270;&#24050;&#32463;&#28436;&#21270;&#20102;&#25968;&#21315;&#24180;&#65292;&#22312;&#20114;&#32852;&#32593;&#26102;&#20195;&#34028;&#21187;&#21457;&#23637;&#12290;&#30001;&#20110;&#22823;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#65292;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#20998;&#26512;&#35832;&#22914;MovieLens&#21644;&#35910;&#29923;&#31561;&#32593;&#31449;&#19978;&#30340;&#29992;&#25143;&#39033;&#30446;&#35780;&#20998;&#20540;&#31561;&#34920;&#31034;&#26469;&#30740;&#31350;&#20154;&#31867;&#25991;&#21270;&#12290;&#24037;&#19994;&#24037;&#20154;&#24050;&#32463;&#23558;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#20110;&#22823;&#25968;&#25454;&#20197;&#39044;&#27979;&#29992;&#25143;&#34892;&#20026;&#24182;&#20419;&#36827;&#32593;&#32476;&#27969;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#21517;&#20026;ZeroMat&#30340;&#31639;&#27861;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20197;&#26174;&#31034;&#20154;&#31867;&#25991;&#21270;&#22788;&#20110;&#19968;&#31181;&#29366;&#24577;&#20013;&#65292;&#20854;&#20013;&#20010;&#20154;&#30340;&#25991;&#21270;&#21697;&#21619;&#21487;&#20197;&#22312;&#27809;&#26377;&#21382;&#21490;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20197;&#39640;&#31934;&#24230;&#39044;&#27979;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#35299;&#37322;&#20102;&#24403;&#21069;&#20013;&#22269;&#25919;&#24220;&#30340;&#27861;&#35268;&#21644;&#25919;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Human culture has evolved for thousands of years and thrived in the era of Internet. Due to the availability of big data, we could do research on human culture by analyzing its representation such as user item rating values on websites like MovieLens and Douban. Industrial workers have applied recommender systems in big data to predict user behavior and promote web traffic. In this paper, we analyze the social impact of an algorithm named ZeroMat to show that human culture is locked into a state where individual's cultural taste is predictable at high precision without historic data. We also provide solutions to this problem and interpretation of current Chinese government's regulations and policies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#22686;&#24378;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#20013;&#30340;&#20813;&#35757;&#32451;&#25968;&#25454;&#38598;&#21387;&#32553;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#26469;&#21512;&#25104;&#19968;&#20010;&#23567;&#32780;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#36798;&#21040;&#19982;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.09874</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22686;&#24378;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#30340;&#20813;&#35757;&#32451;&#25968;&#25454;&#38598;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Leveraging Large Language Models (LLMs) to Empower Training-Free Dataset Condensation for Content-Based Recommendation. (arXiv:2310.09874v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09874
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#22686;&#24378;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#20013;&#30340;&#20813;&#35757;&#32451;&#25968;&#25454;&#38598;&#21387;&#32553;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#26469;&#21512;&#25104;&#19968;&#20010;&#23567;&#32780;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#36798;&#21040;&#19982;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20869;&#23481;&#25512;&#33616;&#65288;CBR&#65289;&#25216;&#26415;&#21033;&#29992;&#29289;&#21697;&#30340;&#20869;&#23481;&#20449;&#24687;&#20026;&#29992;&#25143;&#25552;&#20379;&#20010;&#24615;&#21270;&#26381;&#21153;&#65292;&#20294;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#30340;&#36164;&#28304;&#23494;&#38598;&#22411;&#35757;&#32451;&#23384;&#22312;&#38382;&#39064;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#23545;&#25991;&#26412;CBR&#36827;&#34892;&#25968;&#25454;&#38598;&#21387;&#32553;&#30340;&#26041;&#27861;&#12290;&#25968;&#25454;&#38598;&#21387;&#32553;&#30340;&#30446;&#26631;&#26159;&#21512;&#25104;&#19968;&#20010;&#23567;&#19988;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#27169;&#22411;&#24615;&#33021;&#21487;&#20197;&#19982;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#23218;&#32654;&#12290;&#29616;&#26377;&#30340;&#21387;&#32553;&#26041;&#27861;&#38024;&#23545;&#36830;&#32493;&#25968;&#25454;&#65288;&#22914;&#22270;&#20687;&#25110;&#23884;&#20837;&#21521;&#37327;&#65289;&#30340;&#20998;&#31867;&#20219;&#21153;&#32780;&#35774;&#35745;&#65292;&#30452;&#25509;&#24212;&#29992;&#20110;CBR&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#20013;&#39640;&#25928;&#30340;&#25968;&#25454;&#38598;&#21387;&#32553;&#26041;&#27861;&#12290;&#21463;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25991;&#26412;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#20986;&#33394;&#30340;&#33021;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#21033;&#29992;LLMs&#22312;&#25968;&#25454;&#38598;&#21387;&#32553;&#26399;&#38388;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#12290;&#20026;&#20102;&#22788;&#29702;&#28041;&#21450;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#20132;&#20114;&#25968;&#25454;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21452;...
&lt;/p&gt;
&lt;p&gt;
Modern techniques in Content-based Recommendation (CBR) leverage item content information to provide personalized services to users, but suffer from resource-intensive training on large datasets. To address this issue, we explore the dataset condensation for textual CBR in this paper. The goal of dataset condensation is to synthesize a small yet informative dataset, upon which models can achieve performance comparable to those trained on large datasets. While existing condensation approaches are tailored to classification tasks for continuous data like images or embeddings, direct application of them to CBR has limitations. To bridge this gap, we investigate efficient dataset condensation for content-based recommendation. Inspired by the remarkable abilities of large language models (LLMs) in text comprehension and generation, we leverage LLMs to empower the generation of textual content during condensation. To handle the interaction data involving both users and items, we devise a dua
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#20248;&#21270;&#30340;DiskANN++&#26041;&#27861;&#65292;&#20351;&#29992;&#26597;&#35810;&#25935;&#24863;&#30340;&#20837;&#21475;&#39030;&#28857;&#22312;&#21516;&#26500;&#26144;&#23556;&#22270;&#32034;&#24341;&#19978;&#36827;&#34892;&#39640;&#25928;&#22522;&#20110;&#39029;&#38754;&#30340;&#25628;&#32034;&#12290;</title><link>http://arxiv.org/abs/2310.00402</link><description>&lt;p&gt;
DiskANN++: &#20351;&#29992;&#26597;&#35810;&#25935;&#24863;&#30340;&#20837;&#21475;&#39030;&#28857;&#22312;&#21516;&#26500;&#26144;&#23556;&#22270;&#32034;&#24341;&#19978;&#36827;&#34892;&#39640;&#25928;&#22522;&#20110;&#39029;&#38754;&#30340;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph Index using Query-sensitivity Entry Vertex. (arXiv:2310.00402v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00402
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#20248;&#21270;&#30340;DiskANN++&#26041;&#27861;&#65292;&#20351;&#29992;&#26597;&#35810;&#25935;&#24863;&#30340;&#20837;&#21475;&#39030;&#28857;&#22312;&#21516;&#26500;&#26144;&#23556;&#22270;&#32034;&#24341;&#19978;&#36827;&#34892;&#39640;&#25928;&#22522;&#20110;&#39029;&#38754;&#30340;&#25628;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#19968;&#20010;&#21521;&#37327;&#25968;&#25454;&#38598;X&#21644;&#19968;&#20010;&#26597;&#35810;&#21521;&#37327;xq&#65292;&#22522;&#20110;&#22270;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;(ANNS)&#26088;&#22312;&#26500;&#24314;&#19968;&#20010;&#22270;&#32034;&#24341;G&#65292;&#24182;&#36890;&#36807;&#22312;G&#19978;&#25628;&#32034;&#26469;&#36817;&#20284;&#36820;&#22238;&#19982;xq&#30340;&#26368;&#23567;&#36317;&#31163;&#21521;&#37327;&#12290;&#22522;&#20110;&#22270;&#30340;ANNS&#30340;&#20027;&#35201;&#32570;&#28857;&#26159;&#22270;&#32034;&#24341;&#22826;&#22823;&#65292;&#26080;&#27861;&#36866;&#24212;&#23588;&#20854;&#26159;&#22823;&#35268;&#27169;X&#30340;&#20869;&#23384;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20135;&#21697;&#37327;&#21270;(PQ)&#30340;&#28151;&#21512;&#26041;&#27861;DiskANN&#65292;&#23427;&#22312;&#20869;&#23384;&#20013;&#23384;&#20648;&#20302;&#32500;&#24230;&#30340;PQ&#32034;&#24341;&#65292;&#24182;&#22312;SSD&#20013;&#20445;&#30041;&#22270;&#32034;&#24341;&#65292;&#20174;&#32780;&#20943;&#23567;&#20869;&#23384;&#24320;&#38144;&#21516;&#26102;&#30830;&#20445;&#39640;&#25628;&#32034;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#23384;&#22312;&#20004;&#20010;&#37325;&#35201;&#30340;I/O&#38382;&#39064;&#65292;&#20005;&#37325;&#24433;&#21709;&#20102;&#25972;&#20307;&#25928;&#29575;&#65306;(1)&#20174;&#20837;&#21475;&#39030;&#28857;&#21040;&#26597;&#35810;&#37051;&#22495;&#30340;&#38271;&#36335;&#24452;&#23548;&#33268;&#22823;&#37327;&#30340;I/O&#35831;&#27714;&#65292;&#20197;&#21450;(2)&#22312;&#36335;&#30001;&#36807;&#31243;&#20013;&#30340;&#20887;&#20313;I/O&#35831;&#27714;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20248;&#21270;&#30340;DiskANN++&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a vector dataset $\mathcal{X}$ and a query vector $\vec{x}_q$, graph-based Approximate Nearest Neighbor Search (ANNS) aims to build a graph index $G$ and approximately return vectors with minimum distances to $\vec{x}_q$ by searching over $G$. The main drawback of graph-based ANNS is that a graph index would be too large to fit into the memory especially for a large-scale $\mathcal{X}$. To solve this, a Product Quantization (PQ)-based hybrid method called DiskANN is proposed to store a low-dimensional PQ index in memory and retain a graph index in SSD, thus reducing memory overhead while ensuring a high search accuracy. However, it suffers from two I/O issues that significantly affect the overall efficiency: (1) long routing path from an entry vertex to the query's neighborhood that results in large number of I/O requests and (2) redundant I/O requests during the routing process. We propose an optimized DiskANN++ to overcome above issues. Specifically, for the first issue, we pre
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#29289;&#21697;&#27969;&#34892;&#24230;&#12289;&#36136;&#37327;&#21644;&#20301;&#32622;&#20559;&#24046;&#23545;&#29992;&#25143;&#31119;&#21033;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#25506;&#32034;&#20943;&#36731;&#27969;&#34892;&#24230;&#20559;&#35265;&#36127;&#38754;&#24433;&#21709;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.18333</link><description>&lt;p&gt;
&#20855;&#26377;&#27969;&#34892;&#24230;&#20559;&#35265;&#30340;&#25490;&#21517;&#65306;&#33258;&#22686;&#24378;&#21160;&#24577;&#19979;&#30340;&#29992;&#25143;&#31119;&#21033;
&lt;/p&gt;
&lt;p&gt;
Ranking with Popularity Bias: User Welfare under Self-Amplification Dynamics. (arXiv:2305.18333v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18333
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#29289;&#21697;&#27969;&#34892;&#24230;&#12289;&#36136;&#37327;&#21644;&#20301;&#32622;&#20559;&#24046;&#23545;&#29992;&#25143;&#31119;&#21033;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#25506;&#32034;&#20943;&#36731;&#27969;&#34892;&#24230;&#20559;&#35265;&#36127;&#38754;&#24433;&#21709;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#24050;&#32463;&#30830;&#35748;&#27969;&#34892;&#24230;&#20559;&#35265;&#22312;&#25512;&#33616;&#65288;&#21644;&#20854;&#20182;&#22522;&#20110;&#25490;&#21517;&#30340;&#65289;&#31995;&#32479;&#20013;&#21457;&#25381;&#20316;&#29992;&#65292;&#20294;&#20854;&#23545;&#29992;&#25143;&#31119;&#21033;&#30340;&#24433;&#21709;&#30340;&#35814;&#32454;&#20998;&#26512;&#20173;&#28982;&#32570;&#20047;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26426;&#21046;&#65292;&#36890;&#36807;&#23427;&#65292;&#29289;&#21697;&#30340;&#27969;&#34892;&#24230;&#12289;&#36136;&#37327;&#21644;&#20301;&#32622;&#20559;&#24046;&#21487;&#20197;&#24433;&#21709;&#29992;&#25143;&#36873;&#25321;&#65292;&#24182;&#19988;&#21487;&#20197;&#36127;&#38754;&#24433;&#21709;&#21508;&#31181;&#25512;&#33616;&#31574;&#30053;&#30340;&#38598;&#20307;&#29992;&#25143;&#25928;&#29992;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#34920;&#36848;&#20026;&#38750;&#24179;&#31283;&#19978;&#19979;&#25991;&#33073;&#38774;&#26426;&#65292;&#24378;&#35843;&#19981;&#26159;&#20026;&#20102;&#28040;&#38500;&#27969;&#34892;&#24230;&#20559;&#35265;&#32780;&#26159;&#20026;&#20102;&#20943;&#36731;&#20854;&#36127;&#38754;&#24433;&#21709;&#32780;&#36827;&#34892;&#25506;&#32034;&#30340;&#37325;&#35201;&#24615;&#12290;&#39318;&#20808;&#65292;&#26222;&#36890;&#30340;&#26377;&#27969;&#34892;&#24230;&#20559;&#24046;&#30340;&#25512;&#33616;&#31995;&#32479;&#20250;&#36890;&#36807;&#28151;&#28102;&#29289;&#21697;&#36136;&#37327;&#21644;&#27969;&#34892;&#24230;&#32780;&#24341;&#21457;&#32447;&#24615;&#36951;&#25022;&#12290;&#26356;&#19968;&#33324;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#32447;&#24615;&#35774;&#32622;&#19979;&#65292;&#30001;&#20110;&#27969;&#34892;&#24230;&#20559;&#35265;&#30340;&#28151;&#28102;&#25928;&#24212;&#65292;&#29289;&#21697;&#36136;&#37327;&#30340;&#21487;&#35782;&#21035;&#24615;&#20063;&#21487;&#33021;&#26080;&#27861;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#22312;&#36275;&#22815;&#21464;&#24322;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31867;UCB&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#26377;&#25928;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35777;&#23454;&#20102;&#27969;&#34892;&#24230;&#20559;&#35265;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
While popularity bias is recognized to play a role in recommmender (and other ranking-based) systems, detailed analyses of its impact on user welfare have largely been lacking. We propose a general mechanism by which item popularity, item quality, and position bias can impact user choice, and how it can negatively impact the collective user utility of various recommender policies. Formulating the problem as a non-stationary contextual bandit, we highlight the importance of exploration, not to eliminate popularity bias, but to mitigate its negative effects. First, naive popularity-biased recommenders are shown to induce linear regret by conflating item quality and popularity. More generally, we show that, even in linear settings, identifiability of item quality may not be possible due to the confounding effects of popularity bias. However, under sufficient variability assumptions, we develop an efficient UCB-style algorithm and prove efficient regret guarantees. We complement our analys
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#22411;&#27604;&#20363;&#30456;&#20851;&#24230;&#20998;&#25968;&#65288;RPRS&#65289;&#30340;&#39640;&#25928;&#26377;&#25928;&#30340;&#22522;&#20110;Transformer&#30340;&#37325;&#26032;&#25490;&#24207;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#26497;&#38271;&#26597;&#35810;&#21644;&#25991;&#26723;&#30340;&#26816;&#32034;&#20219;&#21153;&#12290;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#22312;&#20116;&#20010;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#24191;&#27867;&#35780;&#20272;&#26174;&#31034;RPRS&#33719;&#24471;&#20102;&#26174;&#33879;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;RPRS&#20855;&#26377;&#39640;&#25928;&#24615;&#65292;&#24182;&#19988;&#35299;&#20915;&#20102;QBD&#26816;&#32034;&#20219;&#21153;&#20013;&#20302;&#36164;&#28304;&#35757;&#32451;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.01200</link><description>&lt;p&gt;
&#20351;&#29992;RPRS&#30340;&#39640;&#25928;&#26377;&#25928;&#30340;&#22522;&#20110;Transformer&#30340;&#37325;&#26032;&#25490;&#24207;&#22120;&#22788;&#29702;&#26497;&#38271;&#26597;&#35810;&#21644;&#25991;&#26723;&#30340;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Retrieval for Extremely Long Queries and Documents with RPRS: a Highly Efficient and Effective Transformer-based Re-Ranker. (arXiv:2303.01200v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01200
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#22411;&#27604;&#20363;&#30456;&#20851;&#24230;&#20998;&#25968;&#65288;RPRS&#65289;&#30340;&#39640;&#25928;&#26377;&#25928;&#30340;&#22522;&#20110;Transformer&#30340;&#37325;&#26032;&#25490;&#24207;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#26497;&#38271;&#26597;&#35810;&#21644;&#25991;&#26723;&#30340;&#26816;&#32034;&#20219;&#21153;&#12290;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#22312;&#20116;&#20010;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#24191;&#27867;&#35780;&#20272;&#26174;&#31034;RPRS&#33719;&#24471;&#20102;&#26174;&#33879;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;RPRS&#20855;&#26377;&#39640;&#25928;&#24615;&#65292;&#24182;&#19988;&#35299;&#20915;&#20102;QBD&#26816;&#32034;&#20219;&#21153;&#20013;&#20302;&#36164;&#28304;&#35757;&#32451;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#65292;&#20351;&#29992;&#26497;&#38271;&#26597;&#35810;&#21644;&#25991;&#26723;&#36827;&#34892;&#26816;&#32034;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#36890;&#24120;&#31216;&#20026;&#26597;&#35810;-&#25991;&#26723;&#65288;QBD&#65289;&#26816;&#32034;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#22788;&#29702;&#38271;&#36755;&#20837;&#24207;&#21015;&#30340;Transformer&#27169;&#22411;&#22312;QBD&#20219;&#21153;&#20013;&#24182;&#27809;&#26377;&#23637;&#29616;&#20986;&#24456;&#39640;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#22411;&#27604;&#20363;&#30456;&#20851;&#24230;&#20998;&#25968;&#65288;RPRS&#65289;&#30340;&#37325;&#26032;&#25490;&#24207;&#22120;&#65292;&#29992;&#20110;&#35745;&#31639;&#26597;&#35810;&#19982;&#21069;k&#20010;&#20505;&#36873;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20851;&#24230;&#20998;&#25968;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;RPRS&#22312;&#20116;&#20010;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#27604;&#29616;&#26377;&#27169;&#22411;&#21462;&#24471;&#20102;&#26174;&#33879;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;RPRS&#38750;&#24120;&#39640;&#25928;&#65292;&#22240;&#20026;&#22312;&#26597;&#35810;&#26102;&#38388;&#20043;&#21069;&#21487;&#20197;&#23545;&#25152;&#26377;&#25991;&#26723;&#36827;&#34892;&#39044;&#22788;&#29702;&#12289;&#23884;&#20837;&#21644;&#32034;&#24341;&#65292;&#20351;&#24471;&#25105;&#20204;&#30340;&#37325;&#26032;&#25490;&#24207;&#22120;&#20855;&#26377;O(N)&#30340;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;N&#26159;&#26597;&#35810;&#21644;&#20505;&#36873;&#25991;&#26723;&#20013;&#21477;&#23376;&#30340;&#24635;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;QBD&#26816;&#32034;&#20219;&#21153;&#20013;&#20302;&#36164;&#28304;&#35757;&#32451;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#19981;&#38656;&#35201;&#22823;&#37327;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieval with extremely long queries and documents is a well-known and challenging task in information retrieval and is commonly known as Query-by-Document (QBD) retrieval. Specifically designed Transformer models that can handle long input sequences have not shown high effectiveness in QBD tasks in previous work. We propose a Re-Ranker based on the novel Proportional Relevance Score (RPRS) to compute the relevance score between a query and the top-k candidate documents. Our extensive evaluation shows RPRS obtains significantly better results than the state-of-the-art models on five different datasets. Furthermore, RPRS is highly efficient since all documents can be pre-processed, embedded, and indexed before query time which gives our re-ranker the advantage of having a complexity of O(N) where N is the total number of sentences in the query and candidate documents. Furthermore, our method solves the problem of the low-resource training in QBD retrieval tasks as it does not need larg
&lt;/p&gt;</description></item></channel></rss>