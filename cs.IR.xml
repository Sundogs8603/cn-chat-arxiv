<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>LLaRA&#26159;&#19968;&#20010;&#23558;&#20256;&#32479;&#25512;&#33616;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#26041;&#27861;&#26469;&#20195;&#34920;&#39033;&#30446;&#65292;&#22312;&#39034;&#24207;&#25512;&#33616;&#20013;&#20805;&#20998;&#21033;&#29992;&#20102;&#20256;&#32479;&#25512;&#33616;&#22120;&#30340;&#29992;&#25143;&#34892;&#20026;&#30693;&#35782;&#21644;LLMs&#30340;&#19990;&#30028;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2312.02445</link><description>&lt;p&gt;
LLaRA: &#20351;&#29992;&#39034;&#24207;&#25512;&#33616;&#22120;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LLaRA: Aligning Large Language Models with Sequential Recommenders. (arXiv:2312.02445v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.02445
&lt;/p&gt;
&lt;p&gt;
LLaRA&#26159;&#19968;&#20010;&#23558;&#20256;&#32479;&#25512;&#33616;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#26041;&#27861;&#26469;&#20195;&#34920;&#39033;&#30446;&#65292;&#22312;&#39034;&#24207;&#25512;&#33616;&#20013;&#20805;&#20998;&#21033;&#29992;&#20102;&#20256;&#32479;&#25512;&#33616;&#22120;&#30340;&#29992;&#25143;&#34892;&#20026;&#30693;&#35782;&#21644;LLMs&#30340;&#19990;&#30028;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25512;&#33616;&#26088;&#22312;&#26681;&#25454;&#29992;&#25143;&#30340;&#21382;&#21490;&#20132;&#20114;&#39044;&#27979;&#19982;&#29992;&#25143;&#20559;&#22909;&#30456;&#21305;&#37197;&#30340;&#21518;&#32493;&#39033;&#30446;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLMs) &#30340;&#21457;&#23637;&#65292;&#20154;&#20204;&#23545;&#20110;&#23558;LLMs &#24212;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#24182;&#23558;&#20854;&#35270;&#20026;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#30340;&#28508;&#21147;&#36234;&#26469;&#36234;&#24863;&#20852;&#36259;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#20351;&#29992;ID&#32034;&#24341;&#25110;&#25991;&#26412;&#32034;&#24341;&#26469;&#34920;&#31034;&#25991;&#26412;&#25552;&#31034;&#20013;&#30340;&#39033;&#30446;&#65292;&#24182;&#23558;&#25552;&#31034;&#36755;&#20837;LLMs&#65292;&#20294;&#26080;&#27861;&#20840;&#38754;&#34701;&#21512;&#19990;&#30028;&#30693;&#35782;&#25110;&#23637;&#31034;&#36275;&#22815;&#30340;&#39034;&#24207;&#29702;&#35299;&#33021;&#21147;&#12290;&#20026;&#20102;&#20805;&#20998;&#21457;&#25381;&#20256;&#32479;&#25512;&#33616;&#22120;&#65288;&#21487;&#20197;&#32534;&#30721;&#29992;&#25143;&#34892;&#20026;&#30693;&#35782;&#65289;&#21644;LLMs&#65288;&#20855;&#26377;&#39033;&#30446;&#30340;&#19990;&#30028;&#30693;&#35782;&#65289;&#30340;&#20114;&#34917;&#20248;&#21183;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LLaRA - &#19968;&#31181;&#22823;&#22411;&#35821;&#35328;&#21644;&#25512;&#33616;&#21161;&#25163;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;LLaRA&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#23558;&#20256;&#32479;&#25512;&#33616;&#22120;&#30340;&#22522;&#20110;ID&#30340;&#39033;&#30446;&#23884;&#20837;&#19982;&#25991;&#26412;&#39033;&#30446;&#29305;&#24449;&#25972;&#21512;&#21040;LLM&#30340;&#36755;&#20837;&#25552;&#31034;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommendation aims to predict the subsequent items matching user preference based on her/his historical interactions. With the development of Large Language Models (LLMs), there is growing interest in exploring the potential of LLMs for sequential recommendation by framing it as a language modeling task. Prior works represent items in the textual prompts using either ID indexing or text indexing and feed the prompts into LLMs, but falling short of either encapsulating comprehensive world knowledge or exhibiting sufficient sequential understanding. To harness the complementary strengths of traditional recommenders (which encode user behavioral knowledge) and LLMs (which possess world knowledge about items), we propose LLaRA -- a Large Language and Recommendation Assistant framework. Specifically, LLaRA represents items in LLM's input prompts using a novel hybrid approach that integrates ID-based item embeddings from traditional recommenders with textual item features. Viewin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20107;&#20214;&#20013;&#24515;&#30340;&#38598;&#21512;&#25490;&#21517;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32771;&#34385;&#21040;&#26102;&#38388;&#21160;&#24577;&#24615;&#65292;&#33021;&#22815;&#25512;&#33616;&#26368;&#30456;&#20851;&#30340;&#23454;&#20307;&#26041;&#38754;&#65292;&#25552;&#39640;&#25628;&#32034;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/1803.07890</link><description>&lt;p&gt;
&#25512;&#33616;&#23454;&#20307;&#30340;&#26102;&#38388;&#22240;&#32032;&#30340;&#22810;&#27169;&#22411;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multiple Models for Recommending Temporal Aspects of Entities. (arXiv:1803.07890v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1803.07890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20107;&#20214;&#20013;&#24515;&#30340;&#38598;&#21512;&#25490;&#21517;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32771;&#34385;&#21040;&#26102;&#38388;&#21160;&#24577;&#24615;&#65292;&#33021;&#22815;&#25512;&#33616;&#26368;&#30456;&#20851;&#30340;&#23454;&#20307;&#26041;&#38754;&#65292;&#25552;&#39640;&#25628;&#32034;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#26041;&#38754;&#30340;&#25512;&#33616;&#26159;&#35821;&#20041;&#25628;&#32034;&#20013;&#30340;&#26032;&#20852;&#20219;&#21153;&#65292;&#21487;&#20197;&#24110;&#21161;&#29992;&#25143;&#21457;&#29616;&#19982;&#23454;&#20307;&#30456;&#20851;&#30340;&#24039;&#21512;&#21644;&#31361;&#20986;&#20449;&#24687;&#65292;&#20854;&#20013;&#26174;&#30528;&#24615;&#65288;&#20363;&#22914;&#27969;&#34892;&#24230;&#65289;&#26159;&#20197;&#21069;&#24037;&#20316;&#20013;&#26368;&#37325;&#35201;&#30340;&#22240;&#32032;&#12290;&#20294;&#26159;&#65292;&#23454;&#20307;&#26041;&#38754;&#26159;&#20855;&#26377;&#26102;&#38388;&#21160;&#24577;&#24615;&#30340;&#65292;&#32463;&#24120;&#21463;&#21040;&#38543;&#26102;&#38388;&#21457;&#29983;&#30340;&#20107;&#20214;&#30340;&#24433;&#21709;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20165;&#22522;&#20110;&#26174;&#30528;&#24615;&#29305;&#24449;&#30340;&#26041;&#38754;&#24314;&#35758;&#21487;&#33021;&#20250;&#32473;&#20986;&#20196;&#20154;&#19981;&#28385;&#24847;&#30340;&#32467;&#26524;&#65292;&#21407;&#22240;&#26377;&#20004;&#20010;&#12290;&#39318;&#20808;&#65292;&#26174;&#30528;&#24615;&#36890;&#24120;&#22312;&#38271;&#26102;&#38388;&#27573;&#20869;&#32047;&#31215;&#65292;&#24182;&#19988;&#19981;&#32771;&#34385;&#26368;&#36817;&#24773;&#20917;&#12290;&#20854;&#27425;&#65292;&#19982;&#20107;&#20214;&#23454;&#20307;&#30456;&#20851;&#30340;&#35768;&#22810;&#26041;&#38754;&#24378;&#28872;&#20381;&#36182;&#20110;&#26102;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#32473;&#23450;&#23454;&#20307;&#30340;&#26102;&#38388;&#26041;&#38754;&#25512;&#33616;&#20219;&#21153;&#65292;&#26088;&#22312;&#25512;&#33616;&#26368;&#30456;&#20851;&#30340;&#26041;&#38754;&#65292;&#24182;&#32771;&#34385;&#26102;&#38388;&#20197;&#25552;&#39640;&#25628;&#32034;&#20307;&#39564;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20107;&#20214;&#20013;&#24515;&#30340;&#38598;&#21512;&#25490;&#21517;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20174;&#22810;&#20010;&#26102;&#38388;&#21644;&#31867;&#22411;&#20381;&#36182;&#30340;&#27169;&#22411;&#20013;&#23398;&#20064;&#65292;&#24182;&#21160;&#24577;&#26435;&#34913;&#26174;&#30528;&#24615;&#21644;&#26368;&#36817;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entity aspect recommendation is an emerging task in semantic search that helps users discover serendipitous and prominent information with respect to an entity, of which salience (e.g., popularity) is the most important factor in previous work. However, entity aspects are temporally dynamic and often driven by events happening over time. For such cases, aspect suggestion based solely on salience features can give unsatisfactory results, for two reasons. First, salience is often accumulated over a long time period and does not account for recency. Second, many aspects related to an event entity are strongly time-dependent. In this paper, we study the task of temporal aspect recommendation for a given entity, which aims at recommending the most relevant aspects and takes into account time in order to improve search experience. We propose a novel event-centric ensemble ranking method that learns from multiple time and type-dependent models and dynamically trades off salience and recency c
&lt;/p&gt;</description></item></channel></rss>