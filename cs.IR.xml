<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LOT-CRS&#30340;&#26032;&#26694;&#26550;&#65292;&#26680;&#24515;&#26159;&#36890;&#36807;&#27169;&#25311;&#21644;&#21033;&#29992;&#22343;&#34913;&#30340;CRS&#25968;&#25454;&#38598;&#26469;&#25913;&#21892;&#38271;&#23614;&#25512;&#33616;&#24615;&#33021;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;CRS&#25968;&#25454;&#38598;&#20013;&#38271;&#23614;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.11650</link><description>&lt;p&gt;
&#32531;&#35299;&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38271;&#23614;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Alleviating the Long-Tail Problem in Conversational Recommender Systems. (arXiv:2307.11650v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LOT-CRS&#30340;&#26032;&#26694;&#26550;&#65292;&#26680;&#24515;&#26159;&#36890;&#36807;&#27169;&#25311;&#21644;&#21033;&#29992;&#22343;&#34913;&#30340;CRS&#25968;&#25454;&#38598;&#26469;&#25913;&#21892;&#38271;&#23614;&#25512;&#33616;&#24615;&#33021;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;CRS&#25968;&#25454;&#38598;&#20013;&#38271;&#23614;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#65288;CRS&#65289;&#26088;&#22312;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23545;&#35805;&#25552;&#20379;&#25512;&#33616;&#26381;&#21153;&#12290;&#20026;&#20102;&#24320;&#21457;&#26377;&#25928;&#30340;CRS&#65292;&#39640;&#36136;&#37327;&#30340;CRS&#25968;&#25454;&#38598;&#38750;&#24120;&#20851;&#38190;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;CRS&#25968;&#25454;&#38598;&#23384;&#22312;&#38271;&#23614;&#38382;&#39064;&#65292;&#21363;&#22312;&#23545;&#35805;&#20013;&#24456;&#23569;&#65288;&#29978;&#33267;&#20174;&#26410;&#65289;&#25552;&#21040;&#30340;&#39033;&#30446;&#21344;&#36739;&#22823;&#27604;&#20363;&#65292;&#36825;&#20123;&#34987;&#31216;&#20026;&#38271;&#23614;&#39033;&#30446;&#12290;&#22240;&#27492;&#65292;&#22522;&#20110;&#36825;&#20123;&#25968;&#25454;&#38598;&#35757;&#32451;&#30340;CRS&#20542;&#21521;&#20110;&#25512;&#33616;&#39057;&#32321;&#20986;&#29616;&#30340;&#39033;&#30446;&#65292;&#24182;&#19988;&#25512;&#33616;&#39033;&#30446;&#30340;&#22810;&#26679;&#24615;&#20250;&#22823;&#22823;&#38477;&#20302;&#65292;&#20351;&#29992;&#25143;&#26356;&#23481;&#26131;&#24863;&#21040;&#21388;&#20518;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;LOT-CRS&#65292;&#35813;&#26694;&#26550;&#19987;&#27880;&#20110;&#27169;&#25311;&#21644;&#21033;&#29992;&#24179;&#34913;&#30340;CRS&#25968;&#25454;&#38598;&#65288;&#21363;&#22343;&#21248;&#28085;&#30422;&#25152;&#26377;&#39033;&#30446;&#65289;&#26469;&#25913;&#21892;CRS&#30340;&#38271;&#23614;&#25512;&#33616;&#24615;&#33021;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#20197;&#22686;&#24378;&#23545;&#38271;&#23614;&#39033;&#30446;&#30340;&#27169;&#25311;&#23545;&#35805;&#30340;&#29702;&#35299;&#65292;&#24182;&#37319;&#29992;&#26816;&#32034;&#22686;&#24378;&#30340;&#24494;&#35843;&#19982;&#23454;&#39564;&#23460;
&lt;/p&gt;
&lt;p&gt;
Conversational recommender systems (CRS) aim to provide the recommendation service via natural language conversations. To develop an effective CRS, high-quality CRS datasets are very crucial. However, existing CRS datasets suffer from the long-tail issue, \ie a large proportion of items are rarely (or even never) mentioned in the conversations, which are called long-tail items. As a result, the CRSs trained on these datasets tend to recommend frequent items, and the diversity of the recommended items would be largely reduced, making users easier to get bored.  To address this issue, this paper presents \textbf{LOT-CRS}, a novel framework that focuses on simulating and utilizing a balanced CRS dataset (\ie covering all the items evenly) for improving \textbf{LO}ng-\textbf{T}ail recommendation performance of CRSs. In our approach, we design two pre-training tasks to enhance the understanding of simulated conversation for long-tail items, and adopt retrieval-augmented fine-tuning with lab
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21387;&#32553;&#21644;&#31614;&#21517;&#24555;&#36895;&#20272;&#35745;Levenshtein&#36317;&#31163;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;&#25991;&#26723;&#30456;&#20284;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36816;&#34892;&#26102;&#38388;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#26041;&#38754;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.11496</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#21387;&#32553;&#21644;&#31614;&#21517;&#30340;Levenshtein&#36317;&#31163;&#24555;&#36895;&#20272;&#35745;&#26041;&#27861;&#35782;&#21035;&#25991;&#26723;&#30456;&#20284;&#24615;
&lt;/p&gt;
&lt;p&gt;
Identifying document similarity using a fast estimation of the Levenshtein Distance based on compression and signatures. (arXiv:2307.11496v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11496
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21387;&#32553;&#21644;&#31614;&#21517;&#24555;&#36895;&#20272;&#35745;Levenshtein&#36317;&#31163;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;&#25991;&#26723;&#30456;&#20284;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36816;&#34892;&#26102;&#38388;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#26041;&#38754;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#25991;&#26723;&#30456;&#20284;&#24615;&#22312;&#35832;&#22914;&#28304;&#20195;&#30721;&#20998;&#26512;&#25110;&#25220;&#34989;&#26816;&#27979;&#31561;&#24212;&#29992;&#20013;&#26377;&#35768;&#22810;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#35782;&#21035;&#30456;&#20284;&#24615;&#24182;&#38750;&#26131;&#20107;&#65292;&#21487;&#33021;&#20855;&#26377;&#22797;&#26434;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#20363;&#22914;&#65292;Levenshtein&#36317;&#31163;&#26159;&#23450;&#20041;&#20004;&#20010;&#25991;&#26723;&#30456;&#20284;&#24615;&#30340;&#24120;&#35265;&#24230;&#37327;&#26631;&#20934;&#65292;&#20294;&#23427;&#20855;&#26377;&#20108;&#27425;&#36816;&#34892;&#26102;&#38388;&#65292;&#20351;&#20854;&#22312;&#22823;&#25991;&#26723;&#65288;&#20197;&#20960;&#30334;&#21315;&#23383;&#33410;&#24320;&#22836;&#30340;&#22823;&#25991;&#26723;&#65289;&#20013;&#19981;&#36866;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27010;&#24565;&#65292;&#20801;&#35768;&#20272;&#35745;Levenshtein&#36317;&#31163;&#65306;&#31639;&#27861;&#39318;&#20808;&#20351;&#29992;&#29992;&#25143;&#23450;&#20041;&#30340;&#21387;&#32553;&#27604;&#23545;&#25991;&#26723;&#36827;&#34892;&#31614;&#21517;&#65288;&#31867;&#20284;&#20110;&#21704;&#24076;&#20540;&#65289;&#21387;&#32553;&#12290;&#28982;&#21518;&#21487;&#20197;&#23558;&#31614;&#21517;&#30456;&#20114;&#27604;&#36739;&#65288;&#24212;&#29992;&#19968;&#20123;&#32422;&#26463;&#26465;&#20214;&#65289;&#65292;&#32467;&#26524;&#23601;&#26159;&#20272;&#35745;&#30340;Levenshtein&#36317;&#31163;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#22312;&#36816;&#34892;&#26102;&#38388;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#26041;&#38754;&#37117;&#26377;&#20196;&#20154;&#26399;&#24453;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26174;&#33879;&#24230;&#35780;&#20998;&#65292;&#20801;&#35768;&#35780;&#20272;&#20154;&#21592;&#35774;&#23450;&#38408;&#20540;&#24182;&#35782;&#21035;&#30456;&#20851;&#25991;&#26723;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying document similarity has many applications, e.g., source code analysis or plagiarism detection. However, identifying similarities is not trivial and can be time complex. For instance, the Levenshtein Distance is a common metric to define the similarity between two documents but has quadratic runtime which makes it impractical for large documents where large starts with a few hundred kilobytes. In this paper, we present a novel concept that allows estimating the Levenshtein Distance: the algorithm first compresses documents to signatures (similar to hash values) using a user-defined compression ratio. Signatures can then be compared against each other (some constrains apply) where the outcome is the estimated Levenshtein Distance. Our evaluation shows promising results in terms of runtime efficiency and accuracy. In addition, we introduce a significance score allowing examiners to set a threshold and identify related documents.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#33832;&#36203;&#21202;&#20197;&#21335;&#38750;&#27954;&#35937;&#31227;&#21160;&#30340;&#27169;&#24335;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#23395;&#33410;&#21464;&#21270;&#21644;&#38477;&#38632;&#27169;&#24335;&#31561;&#21160;&#24577;&#39537;&#21160;&#22240;&#32032;&#12290;&#30740;&#31350;&#32467;&#26524;&#26377;&#21161;&#20110;&#39044;&#27979;&#29983;&#24577;&#22240;&#32032;&#23545;&#35937;&#36801;&#24473;&#30340;&#28508;&#22312;&#24433;&#21709;&#65292;&#24182;&#20026;&#21046;&#23450;&#20445;&#25252;&#31574;&#30053;&#25552;&#20379;&#20102;&#32508;&#21512;&#30340;&#35270;&#35282;&#12290;</title><link>http://arxiv.org/abs/2307.11325</link><description>&lt;p&gt;
&#33832;&#36203;&#21202;&#20197;&#21335;&#38750;&#27954;&#35937;&#31227;&#21160;&#30340;&#20998;&#26512;&#65306;&#29983;&#24577;&#23398;&#12289;&#27668;&#20505;&#21644;&#20445;&#25252;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Analysis of Elephant Movement in Sub-Saharan Africa: Ecological, Climatic, and Conservation Perspectives. (arXiv:2307.11325v1 [q-bio.PE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11325
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#33832;&#36203;&#21202;&#20197;&#21335;&#38750;&#27954;&#35937;&#31227;&#21160;&#30340;&#27169;&#24335;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#23395;&#33410;&#21464;&#21270;&#21644;&#38477;&#38632;&#27169;&#24335;&#31561;&#21160;&#24577;&#39537;&#21160;&#22240;&#32032;&#12290;&#30740;&#31350;&#32467;&#26524;&#26377;&#21161;&#20110;&#39044;&#27979;&#29983;&#24577;&#22240;&#32032;&#23545;&#35937;&#36801;&#24473;&#30340;&#28508;&#22312;&#24433;&#21709;&#65292;&#24182;&#20026;&#21046;&#23450;&#20445;&#25252;&#31574;&#30053;&#25552;&#20379;&#20102;&#32508;&#21512;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35937;&#19982;&#29615;&#22659;&#30340;&#30456;&#20114;&#20316;&#29992;&#23545;&#29983;&#24577;&#23398;&#21644;&#20445;&#25252;&#31574;&#30053;&#37117;&#26377;&#28145;&#36828;&#30340;&#24433;&#21709;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#26512;&#26041;&#27861;&#26469;&#35299;&#35835;&#33832;&#36203;&#21202;&#20197;&#21335;&#38750;&#27954;&#35937;&#31227;&#21160;&#30340;&#22797;&#26434;&#27169;&#24335;&#65292;&#37325;&#28857;&#20851;&#27880;&#23395;&#33410;&#21464;&#21270;&#21644;&#38477;&#38632;&#27169;&#24335;&#31561;&#20851;&#38190;&#29983;&#24577;&#39537;&#21160;&#22240;&#32032;&#12290;&#23613;&#31649;&#22260;&#32469;&#36825;&#20123;&#20855;&#26377;&#24433;&#21709;&#21147;&#30340;&#22240;&#32032;&#23384;&#22312;&#22797;&#26434;&#24615;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#23545;&#38750;&#27954;&#21160;&#24577;&#26223;&#35266;&#32972;&#26223;&#19979;&#35937;&#36801;&#24473;&#34892;&#20026;&#30340;&#20840;&#38754;&#35270;&#35282;&#12290;&#25105;&#20204;&#32508;&#21512;&#30340;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#39044;&#27979;&#36825;&#20123;&#29983;&#24577;&#20915;&#23450;&#22240;&#32032;&#23545;&#35937;&#36801;&#24473;&#30340;&#28508;&#22312;&#24433;&#21709;&#65292;&#36825;&#26159;&#24314;&#31435;&#30693;&#24773;&#30340;&#20445;&#25252;&#31574;&#30053;&#30340;&#20851;&#38190;&#19968;&#27493;&#12290;&#32771;&#34385;&#21040;&#20840;&#29699;&#27668;&#20505;&#21464;&#21270;&#23545;&#23395;&#33410;&#21644;&#38477;&#38632;&#27169;&#24335;&#30340;&#24433;&#21709;&#65292;&#36825;&#31181;&#39044;&#27979;&#23588;&#20026;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#26410;&#26469;&#21487;&#33021;&#20250;&#23545;&#35937;&#30340;&#34892;&#21160;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25104;&#26524;&#26088;&#22312;&#19981;&#20165;&#25512;&#36827;&#23545;&#31227;&#21160;&#29983;&#24577;&#23398;&#30340;&#29702;&#35299;&#65292;&#21516;&#26102;&#20063;&#20026;&#20445;&#25252;&#23454;&#36341;&#25552;&#20379;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;
The interaction between elephants and their environment has profound implications for both ecology and conservation strategies. This study presents an analytical approach to decipher the intricate patterns of elephant movement in Sub-Saharan Africa, concentrating on key ecological drivers such as seasonal variations and rainfall patterns. Despite the complexities surrounding these influential factors, our analysis provides a holistic view of elephant migratory behavior in the context of the dynamic African landscape. Our comprehensive approach enables us to predict the potential impact of these ecological determinants on elephant migration, a critical step in establishing informed conservation strategies. This projection is particularly crucial given the impacts of global climate change on seasonal and rainfall patterns, which could substantially influence elephant movements in the future. The findings of our work aim to not only advance the understanding of movement ecology but also f
&lt;/p&gt;</description></item><item><title>Jina Embeddings&#26159;&#19968;&#32452;&#39640;&#24615;&#33021;&#30340;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25991;&#26412;&#30340;&#35821;&#20041;&#26412;&#36136;&#12290;&#35813;&#35770;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;Jina Embeddings&#30340;&#24320;&#21457;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#24615;&#33021;&#35780;&#20272;&#39564;&#35777;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.11224</link><description>&lt;p&gt;
Jina Embeddings:&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#24615;&#33021;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models. (arXiv:2307.11224v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11224
&lt;/p&gt;
&lt;p&gt;
Jina Embeddings&#26159;&#19968;&#32452;&#39640;&#24615;&#33021;&#30340;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25991;&#26412;&#30340;&#35821;&#20041;&#26412;&#36136;&#12290;&#35813;&#35770;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;Jina Embeddings&#30340;&#24320;&#21457;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#24615;&#33021;&#35780;&#20272;&#39564;&#35777;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Jina Embeddings&#30001;&#19968;&#32452;&#39640;&#24615;&#33021;&#30340;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#32452;&#25104;&#65292;&#33021;&#22815;&#23558;&#21508;&#31181;&#25991;&#26412;&#36755;&#20837;&#36716;&#21270;&#20026;&#25968;&#20540;&#34920;&#31034;&#65292;&#20174;&#32780;&#25429;&#25417;&#25991;&#26412;&#30340;&#35821;&#20041;&#26412;&#36136;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#24182;&#38750;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#25991;&#26412;&#29983;&#25104;&#65292;&#20294;&#22312;&#23494;&#38598;&#26816;&#32034;&#21644;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#31561;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#26412;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;Jina Embeddings&#30340;&#24320;&#21457;&#36807;&#31243;&#65292;&#20174;&#21019;&#24314;&#39640;&#36136;&#37327;&#30340;&#25104;&#23545;&#21644;&#19977;&#20803;&#25968;&#25454;&#38598;&#24320;&#22987;&#12290;&#23427;&#24378;&#35843;&#20102;&#25968;&#25454;&#28165;&#29702;&#22312;&#25968;&#25454;&#38598;&#20934;&#22791;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#65292;&#24182;&#23545;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#36827;&#34892;&#20102;&#28145;&#20837;&#25506;&#35752;&#65292;&#26368;&#21518;&#21033;&#29992;Massive Textual Embedding Benchmark&#65288;MTEB&#65289;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Jina Embeddings constitutes a set of high-performance sentence embedding models adept at translating various textual inputs into numerical representations, thereby capturing the semantic essence of the text. While these models are not exclusively designed for text generation, they excel in applications such as dense retrieval and semantic textual similarity. This paper details the development of Jina Embeddings, starting with the creation of a high-quality pairwise and triplet dataset. It underlines the crucial role of data cleaning in dataset preparation, gives in-depth insights into the model training process, and concludes with a comprehensive performance evaluation using the Massive Textual Embedding Benchmark (MTEB).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#32463;&#27982;&#26041;&#27861;RCVaR&#65292;&#21033;&#29992;&#20844;&#24320;&#30340;&#32593;&#32476;&#23433;&#20840;&#25253;&#21578;&#30340;&#29616;&#23454;&#19990;&#30028;&#20449;&#24687;&#26469;&#20272;&#31639;&#32593;&#32476;&#23433;&#20840;&#25104;&#26412;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24110;&#21161;&#29702;&#35299;&#30001;&#32593;&#32476;&#25915;&#20987;&#23548;&#33268;&#30340;&#36130;&#21153;&#25439;&#22833;&#65292;&#24182;&#30830;&#23450;&#26368;&#37325;&#35201;&#30340;&#32593;&#32476;&#39118;&#38505;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2307.11140</link><description>&lt;p&gt;
RCVaR:&#19968;&#31181;&#21033;&#29992;&#34892;&#19994;&#25253;&#21578;&#25968;&#25454;&#20272;&#31639;&#32593;&#32476;&#25915;&#20987;&#25104;&#26412;&#30340;&#32463;&#27982;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
RCVaR: an Economic Approach to Estimate Cyberattacks Costs using Data from Industry Reports. (arXiv:2307.11140v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#32463;&#27982;&#26041;&#27861;RCVaR&#65292;&#21033;&#29992;&#20844;&#24320;&#30340;&#32593;&#32476;&#23433;&#20840;&#25253;&#21578;&#30340;&#29616;&#23454;&#19990;&#30028;&#20449;&#24687;&#26469;&#20272;&#31639;&#32593;&#32476;&#23433;&#20840;&#25104;&#26412;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24110;&#21161;&#29702;&#35299;&#30001;&#32593;&#32476;&#25915;&#20987;&#23548;&#33268;&#30340;&#36130;&#21153;&#25439;&#22833;&#65292;&#24182;&#30830;&#23450;&#26368;&#37325;&#35201;&#30340;&#32593;&#32476;&#39118;&#38505;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23383;&#21270;&#22686;&#21152;&#20102;&#21830;&#19994;&#26426;&#20250;&#65292;&#20063;&#22686;&#21152;&#20102;&#20844;&#21496;&#25104;&#20026;&#27585;&#28781;&#24615;&#32593;&#32476;&#25915;&#20987;&#21463;&#23475;&#32773;&#30340;&#39118;&#38505;&#12290;&#22240;&#27492;&#65292;&#31649;&#29702;&#39118;&#38505;&#26292;&#38706;&#21644;&#32593;&#32476;&#23433;&#20840;&#31574;&#30053;&#23545;&#20110;&#24076;&#26395;&#22312;&#31454;&#20105;&#24066;&#22330;&#20013;&#29983;&#23384;&#30340;&#25968;&#23383;&#21270;&#20844;&#21496;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29702;&#35299;&#20844;&#21496;&#29305;&#23450;&#30340;&#39118;&#38505;&#24182;&#37327;&#21270;&#20854;&#30456;&#20851;&#25104;&#26412;&#24182;&#19981;&#23481;&#26131;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#26080;&#27861;&#25552;&#20379;&#20010;&#24615;&#21270;&#21644;&#23450;&#37327;&#21270;&#30340;&#32593;&#32476;&#23433;&#20840;&#24433;&#21709;&#36135;&#24065;&#20272;&#35745;&#12290;&#30001;&#20110;&#36164;&#28304;&#26377;&#38480;&#21644;&#25216;&#26415;&#19987;&#38271;&#65292;&#20013;&#23567;&#22411;&#20225;&#19994;&#29978;&#33267;&#22823;&#20844;&#21496;&#21463;&#21040;&#24433;&#21709;&#65292;&#24182;&#19988;&#38590;&#20197;&#37327;&#21270;&#20854;&#32593;&#32476;&#25915;&#20987;&#39118;&#38505;&#12290;&#22240;&#27492;&#65292;&#24517;&#39035;&#37319;&#29992;&#26032;&#30340;&#26041;&#27861;&#26469;&#25903;&#25345;&#23545;&#32593;&#32476;&#25915;&#20987;&#23548;&#33268;&#30340;&#36130;&#21153;&#25439;&#22833;&#30340;&#29702;&#35299;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#23454;&#38469;&#32593;&#32476;&#39118;&#38505;&#20215;&#20540; (RCVaR)&#65292;&#36825;&#26159;&#19968;&#31181;&#32463;&#27982;&#26041;&#27861;&#65292;&#21033;&#29992;&#20844;&#24320;&#30340;&#32593;&#32476;&#23433;&#20840;&#25253;&#21578;&#30340;&#29616;&#23454;&#19990;&#30028;&#20449;&#24687;&#26469;&#20272;&#31639;&#32593;&#32476;&#23433;&#20840;&#25104;&#26412;&#12290;RCVaR&#20174;&#21508;&#31181;&#26469;&#28304;&#20013;&#30830;&#23450;&#26368;&#37325;&#35201;&#30340;&#32593;&#32476;&#39118;&#38505;&#22240;&#32032;
&lt;/p&gt;
&lt;p&gt;
Digitization increases business opportunities and the risk of companies being victims of devastating cyberattacks. Therefore, managing risk exposure and cybersecurity strategies is essential for digitized companies that want to survive in competitive markets. However, understanding company-specific risks and quantifying their associated costs is not trivial. Current approaches fail to provide individualized and quantitative monetary estimations of cybersecurity impacts. Due to limited resources and technical expertise, SMEs and even large companies are affected and struggle to quantify their cyberattack exposure. Therefore, novel approaches must be placed to support the understanding of the financial loss due to cyberattacks. This article introduces the Real Cyber Value at Risk (RCVaR), an economical approach for estimating cybersecurity costs using real-world information from public cybersecurity reports. RCVaR identifies the most significant cyber risk factors from various sources an
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#26089;&#26399;&#24191;&#21578;&#25490;&#24207;&#65292;&#20197;&#35299;&#20915;&#26089;&#26399;&#38454;&#27573;&#21644;&#26368;&#32456;&#38454;&#27573;&#25490;&#24207;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.11096</link><description>&lt;p&gt;
&#20026;&#20102;&#26356;&#22909;&#30340;&#25490;&#24207;&#19968;&#33268;&#24615;&#65306;&#19968;&#31181;&#38754;&#21521;&#26089;&#26399;&#24191;&#21578;&#25490;&#24207;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Towards the Better Ranking Consistency: A Multi-task Learning Framework for Early Stage Ads Ranking. (arXiv:2307.11096v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#26089;&#26399;&#24191;&#21578;&#25490;&#24207;&#65292;&#20197;&#35299;&#20915;&#26089;&#26399;&#38454;&#27573;&#21644;&#26368;&#32456;&#38454;&#27573;&#25490;&#24207;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#24191;&#21578;&#25512;&#33616;&#20013;&#65292;&#23558;&#24191;&#21578;&#25490;&#24207;&#31995;&#32479;&#20998;&#20026;&#26816;&#32034;&#12289;&#26089;&#26399;&#21644;&#26368;&#32456;&#38454;&#27573;&#26159;&#19968;&#31181;&#24120;&#35265;&#20570;&#27861;&#65292;&#20197;&#24179;&#34913;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;&#26089;&#26399;&#38454;&#27573;&#30340;&#25490;&#24207;&#36890;&#24120;&#20351;&#29992;&#39640;&#25928;&#27169;&#22411;&#20174;&#19968;&#32452;&#26816;&#32034;&#21040;&#30340;&#24191;&#21578;&#20013;&#29983;&#25104;&#20505;&#36873;&#38598;&#12290;&#28982;&#21518;&#65292;&#23558;&#20505;&#36873;&#38598;&#39304;&#36865;&#21040;&#35745;&#31639;&#23494;&#38598;&#19988;&#20934;&#30830;&#30340;&#26368;&#32456;&#38454;&#27573;&#25490;&#24207;&#31995;&#32479;&#65292;&#29983;&#25104;&#26368;&#32456;&#30340;&#24191;&#21578;&#25512;&#33616;&#12290;&#30001;&#20110;&#31995;&#32479;&#38480;&#21046;&#65292;&#26089;&#26399;&#21644;&#26368;&#32456;&#38454;&#27573;&#30340;&#25490;&#24207;&#20351;&#29992;&#19981;&#21516;&#30340;&#29305;&#24449;&#21644;&#27169;&#22411;&#26550;&#26500;&#65292;&#23548;&#33268;&#20102;&#20005;&#37325;&#30340;&#25490;&#24207;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#21363;&#26089;&#26399;&#38454;&#27573;&#30340;&#24191;&#21578;&#21484;&#22238;&#29575;&#36739;&#20302;&#65292;&#21363;&#26368;&#32456;&#38454;&#27573;&#20013;&#25490;&#21517;&#38752;&#21069;&#30340;&#24191;&#21578;&#22312;&#26089;&#26399;&#38454;&#27573;&#25490;&#21517;&#36739;&#20302;&#12290;&#20026;&#20102;&#23558;&#26356;&#22909;&#30340;&#24191;&#21578;&#20174;&#26089;&#26399;&#38454;&#27573;&#20256;&#36882;&#21040;&#26368;&#32456;&#38454;&#27573;&#30340;&#25490;&#21517;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#26089;&#26399;&#38454;&#27573;&#25490;&#24207;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#20197;&#25429;&#33719;&#22810;&#20010;&#26368;&#32456;&#38454;&#27573;&#25490;&#24207;&#32452;&#20214;&#65288;&#21363;&#24191;&#21578;&#28857;&#20987;&#21644;&#24191;&#21578;&#36136;&#37327;&#20107;&#20214;&#65289;&#21450;&#20854;&#20219;&#21153;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dividing ads ranking system into retrieval, early, and final stages is a common practice in large scale ads recommendation to balance the efficiency and accuracy. The early stage ranking often uses efficient models to generate candidates out of a set of retrieved ads. The candidates are then fed into a more computationally intensive but accurate final stage ranking system to produce the final ads recommendation. As the early and final stage ranking use different features and model architectures because of system constraints, a serious ranking consistency issue arises where the early stage has a low ads recall, i.e., top ads in the final stage are ranked low in the early stage. In order to pass better ads from the early to the final stage ranking, we propose a multi-task learning framework for early stage ranking to capture multiple final stage ranking components (i.e. ads clicks and ads quality events) and their task relations. With our multi-task learning framework, we can not only ac
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#65292;&#24182;&#36890;&#36807;&#22312;&#39184;&#39302;&#35780;&#35770;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.10617</link><description>&lt;p&gt;
&#20351;&#29992;&#25991;&#26412;&#20998;&#31867;&#26816;&#27979;&#34394;&#20551;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
Detecting deceptive reviews using text classification. (arXiv:2307.10617v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10617
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#65292;&#24182;&#36890;&#36807;&#22312;&#39184;&#39302;&#35780;&#35770;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22312;&#32447;&#35780;&#35770;&#22312;&#25512;&#24191;&#20219;&#20309;&#20135;&#21697;&#25110;&#26381;&#21153;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20225;&#19994;&#21487;&#33021;&#20250;&#23884;&#20837;&#34394;&#20551;&#35780;&#35770;&#20197;&#21560;&#24341;&#23458;&#25143;&#36141;&#20080;&#20182;&#20204;&#30340;&#20135;&#21697;&#12290;&#20182;&#20204;&#29978;&#33267;&#21487;&#33021;&#31361;&#20986;&#24378;&#35843;&#33258;&#24049;&#20135;&#21697;&#30340;&#20248;&#28857;&#25110;&#25209;&#35780;&#31454;&#20105;&#23545;&#25163;&#30340;&#20135;&#21697;&#12290;&#24066;&#22330;&#33829;&#38144;&#20154;&#21592;&#12289;&#24191;&#21578;&#21830;&#21644;&#20854;&#20182;&#22312;&#32447;&#21830;&#19994;&#29992;&#25143;&#26377;&#21160;&#26426;&#20026;&#20182;&#20204;&#24819;&#35201;&#25512;&#24191;&#30340;&#20135;&#21697;&#32534;&#20889;&#34394;&#20551;&#30340;&#27491;&#38754;&#35780;&#35770;&#65292;&#25110;&#32773;&#20026;&#20182;&#20204;&#30495;&#27491;&#19981;&#21916;&#27426;&#30340;&#20135;&#21697;&#25552;&#20379;&#34394;&#20551;&#30340;&#36127;&#38754;&#35780;&#35770;&#12290;&#22240;&#27492;&#65292;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#26159;&#19968;&#20010;&#32039;&#36843;&#19988;&#25345;&#32493;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#30740;&#31350;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26041;&#27861;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#12290;&#35770;&#25991;&#35843;&#26597;&#20102;&#22312;&#19968;&#20010;&#39184;&#39302;&#35780;&#35770;&#30340;&#34394;&#20551;&#24847;&#35265;&#22403;&#22334;&#35821;&#26009;&#24211;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22810;&#27425;&#23454;&#39564;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;n-gram&#27169;&#22411;&#21644;&#26368;&#22823;&#29305;&#24449;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, online reviews play a vital role for promoting any kind of product or services. Businesses may embed fake reviews in order to attract customers to purchase their products. They may even highlight the benefits of their own product or criticize the competition's product. Marketers, advertisers, and other online business users have incentive to create fake positive reviews for products which they want to promote or give fake negative reviews for products which they really don't like. So now-a-days writing a deceptive review is inevitable thing for promoting their own business or degrading competitor's reputation. Thus, identifying deceptive reviews is an intense and on-going research area. This research paper proposes machine learning model approach to identify deceptive reviews. The paper investigates the performance of the several experiments done on a Deceptive Opinion Spam Corpus dataset of restaurants reviews. We developed a n-gram model and max features to identify 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GLORY&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20840;&#23616;&#22270;&#19982;&#26412;&#22320;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#22686;&#24378;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#26500;&#24314;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#65292;&#24182;&#32771;&#34385;&#20102;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2307.06576</link><description>&lt;p&gt;
&#36229;&#36234;&#26412;&#22320;&#33539;&#22260;&#65306;&#20840;&#29699;&#22270;&#22686;&#24378;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06576
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GLORY&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20840;&#23616;&#22270;&#19982;&#26412;&#22320;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#22686;&#24378;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#26500;&#24314;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#65292;&#24182;&#32771;&#34385;&#20102;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#22320;&#21521;&#29992;&#25143;&#25512;&#33616;&#20505;&#36873;&#26032;&#38395;&#25991;&#31456;&#19968;&#30452;&#26159;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#30340;&#26680;&#24515;&#25361;&#25112;&#12290;&#22823;&#22810;&#25968;&#36817;&#26399;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20351;&#29992;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#20174;&#20016;&#23500;&#30340;&#25991;&#26412;&#25968;&#25454;&#20013;&#25552;&#21462;&#35821;&#20041;&#20449;&#24687;&#65292;&#20351;&#29992;&#20174;&#26412;&#22320;&#21382;&#21490;&#26032;&#38395;&#27966;&#29983;&#30340;&#22522;&#20110;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#32570;&#20047;&#20840;&#23616;&#35270;&#35282;&#65292;&#26410;&#33021;&#32771;&#34385;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#65292;&#36229;&#36234;&#35821;&#20041;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411; GLORY&#65288;Global-LOcal news Recommendation sYstem&#65289;&#65292;&#23427;&#32467;&#21512;&#20102;&#20174;&#20854;&#20182;&#29992;&#25143;&#23398;&#21040;&#30340;&#20840;&#23616;&#34920;&#31034;&#21644;&#26412;&#22320;&#34920;&#31034;&#65292;&#26469;&#22686;&#24378;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#20840;&#23616;&#26032;&#38395;&#22270;&#65292;&#24182;&#20351;&#29992;&#38376;&#25511;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20016;&#23500;&#26032;&#38395;&#34920;&#31034;&#65292;&#20174;&#32780;&#36890;&#36807;&#21382;&#21490;&#26032;&#38395;&#32858;&#21512;&#22120;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Precisely recommending candidate news articles to users has always been a core challenge for personalized news recommendation systems. Most recent works primarily focus on using advanced natural language processing techniques to extract semantic information from rich textual data, employing content-based methods derived from local historical news. However, this approach lacks a global perspective, failing to account for users' hidden motivations and behaviors beyond semantic information. To address this challenge, we propose a novel model called GLORY (Global-LOcal news Recommendation sYstem), which combines global representations learned from other users with local representations to enhance personalized recommendation systems. We accomplish this by constructing a Global-aware Historical News Encoder, which includes a global news graph and employs gated graph neural networks to enrich news representations, thereby fusing historical news representations by a historical news aggregator.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20026;&#22522;&#20110;&#21465;&#20107;&#30340;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#25968;&#25454;&#22686;&#24378;&#65292;&#20197;&#35299;&#20915;&#20854;&#32570;&#20047;&#35757;&#32451;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.02250</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#30340;&#22522;&#20110;&#21465;&#20107;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Large Language Model Augmented Narrative Driven Recommendations. (arXiv:2306.02250v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02250
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20026;&#22522;&#20110;&#21465;&#20107;&#30340;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#25968;&#25454;&#22686;&#24378;&#65292;&#20197;&#35299;&#20915;&#20854;&#32570;&#20047;&#35757;&#32451;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#21465;&#20107;&#30340;&#25512;&#33616;&#31995;&#32479;&#26159;&#19968;&#20010;&#20449;&#24687;&#33719;&#21462;&#38382;&#39064;&#65292;&#29992;&#25143;&#36890;&#36807;&#35814;&#32454;&#25551;&#36848;&#20182;&#20204;&#30340;&#20559;&#22909;&#21644;&#32972;&#26223;&#26469;&#35831;&#27714;&#25512;&#33616;&#65292;&#27604;&#22914;&#26053;&#34892;&#32773;&#22312;&#25551;&#36848;&#20182;&#20204;&#30340;&#21916;&#22909;&#12289;&#19981;&#21916;&#27426;&#21644;&#26053;&#34892;&#24773;&#20917;&#26102;&#35831;&#27714;&#26223;&#28857;&#30340;&#25512;&#33616;&#12290;&#38543;&#30528;&#33258;&#28982;&#35821;&#35328;&#23545;&#35805;&#30028;&#38754;&#22312;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20852;&#36215;&#65292;&#36825;&#20123;&#35831;&#27714;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#21465;&#20107;&#30340;&#25512;&#33616;&#31995;&#32479;&#32570;&#20047;&#20016;&#23500;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#19988;&#24403;&#21069;&#30340;&#24179;&#21488;&#36890;&#24120;&#19981;&#25903;&#25345;&#36825;&#20123;&#35831;&#27714;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#20256;&#32479;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;&#20016;&#23500;&#30340;&#25991;&#26412;&#25968;&#25454;&#65292;&#20363;&#22914;&#35780;&#35770;&#65292;&#36825;&#20123;&#35780;&#35770;&#32463;&#24120;&#25551;&#36848;&#20102;&#29992;&#25143;&#30340;&#20559;&#22909;&#21644;&#32972;&#26223; - &#36825;&#20123;&#25968;&#25454;&#21487;&#20197;&#29992;&#26469;&#20026;&#22522;&#20110;&#21465;&#20107;&#30340;&#25512;&#33616;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLMs) &#26469;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#65292;&#20197;&#35757;&#32451;&#22522;&#20110;&#21465;&#20107;&#30340;&#25512;&#33616;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context - this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with few-shot prompting and train retri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#24565;&#20540;&#29942;&#39048;&#27169;&#22411;LACE&#65292;&#29992;&#20110;&#21487;&#25511;&#25991;&#26412;&#25512;&#33616;&#12290;&#35813;&#27169;&#22411;&#22522;&#20110;&#29992;&#25143;&#25991;&#26723;&#23398;&#20064;&#20010;&#24615;&#21270;&#30340;&#27010;&#24565;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#22810;&#31181;&#20132;&#20114;&#26041;&#24335;&#20026;&#29992;&#25143;&#25552;&#20379;&#20102;&#25511;&#21046;&#25512;&#33616;&#30340;&#26426;&#21046;&#65292;&#39564;&#35777;&#20102;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#35813;&#27169;&#22411;&#30340;&#25512;&#33616;&#36136;&#37327;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.04250</link><description>&lt;p&gt;
&#21487;&#32534;&#36753;&#29992;&#25143;&#26723;&#26696;&#30340;&#21487;&#25511;&#25991;&#26412;&#25512;&#33616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Editable User Profiles for Controllable Text Recommendation. (arXiv:2304.04250v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#24565;&#20540;&#29942;&#39048;&#27169;&#22411;LACE&#65292;&#29992;&#20110;&#21487;&#25511;&#25991;&#26412;&#25512;&#33616;&#12290;&#35813;&#27169;&#22411;&#22522;&#20110;&#29992;&#25143;&#25991;&#26723;&#23398;&#20064;&#20010;&#24615;&#21270;&#30340;&#27010;&#24565;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#22810;&#31181;&#20132;&#20114;&#26041;&#24335;&#20026;&#29992;&#25143;&#25552;&#20379;&#20102;&#25511;&#21046;&#25512;&#33616;&#30340;&#26426;&#21046;&#65292;&#39564;&#35777;&#20102;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#35813;&#27169;&#22411;&#30340;&#25512;&#33616;&#36136;&#37327;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#39640;&#36136;&#37327;&#25512;&#33616;&#30340;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#20174;&#20132;&#20114;&#25968;&#25454;&#20013;&#23398;&#20064;&#28508;&#22312;&#34920;&#31034;&#12290;&#28982;&#32780;&#36825;&#20123;&#26041;&#27861;&#27809;&#26377;&#25552;&#20379;&#32473;&#29992;&#25143;&#25511;&#21046;&#25152;&#25509;&#25910;&#30340;&#25512;&#33616;&#30340;&#26426;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;LACE&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#24565;&#20540;&#29942;&#39048;&#27169;&#22411;&#65292;&#29992;&#20110;&#21487;&#25511;&#25991;&#26412;&#25512;&#33616;&#12290;LACE&#22522;&#20110;&#29992;&#25143;&#20132;&#20114;&#30340;&#25991;&#26723;&#26816;&#32034;&#65292;&#23558;&#27599;&#20010;&#29992;&#25143;&#34920;&#31034;&#20026;&#31616;&#27905;&#30340;&#21487;&#35835;&#30340;&#27010;&#24565;&#38598;&#65292;&#24182;&#22522;&#20110;&#29992;&#25143;&#25991;&#26723;&#23398;&#20064;&#27010;&#24565;&#30340;&#20010;&#24615;&#21270;&#34920;&#31034;&#12290;&#35813;&#22522;&#20110;&#27010;&#24565;&#30340;&#29992;&#25143;&#26723;&#26696;&#34987;&#21033;&#29992;&#26469;&#20570;&#20986;&#25512;&#33616;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#35774;&#35745;&#36890;&#36807;&#36879;&#26126;&#30340;&#29992;&#25143;&#26723;&#26696;&#65292;&#25552;&#20379;&#20102;&#25511;&#21046;&#25512;&#33616;&#30340;&#22810;&#31181;&#30452;&#35266;&#20132;&#20114;&#26041;&#24335;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#19977;&#20010;&#25512;&#33616;&#20219;&#21153;&#65288;&#28201;&#21551;&#21160;&#12289;&#20919;&#21551;&#21160;&#21644;&#38646;&#26679;&#26412;&#65289;&#30340;&#20845;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#31163;&#32447;&#35780;&#20272;&#65292;&#39564;&#35777;&#20102;&#20174;LACE&#33719;&#24471;&#30340;&#25512;&#33616;&#36136;&#37327;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#22312;&#22312;&#32447;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;LACE&#30340;&#26377;&#25928;&#24615;&#21644;&#29992;&#25143;&#25511;&#21046;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Methods for making high-quality recommendations often rely on learning latent representations from interaction data. These methods, while performant, do not provide ready mechanisms for users to control the recommendation they receive. Our work tackles this problem by proposing LACE, a novel concept value bottleneck model for controllable text recommendations. LACE represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents and learns personalized representations of the concepts based on user documents. This concept based user profile is then leveraged to make recommendations. The design of our model affords control over the recommendations through a number of intuitive interactions with a transparent user profile. We first establish the quality of recommendations obtained from LACE in an offline evaluation on three recommendation tasks spanning six datasets in warm-start, cold-start, and zero-shot setups. Next, we validate the 
&lt;/p&gt;</description></item></channel></rss>