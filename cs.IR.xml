<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#35821;&#20041;&#30693;&#35782;&#22270;&#33258;&#21160;&#21019;&#24314;&#25919;&#31574;&#36777;&#35770;&#26696;&#20363;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20105;&#35770;&#30340;&#35821;&#20041;&#30693;&#35782;&#22270;&#19978;&#36827;&#34892;&#38480;&#21046;&#26368;&#30701;&#36335;&#24452;&#36941;&#21382;&#65292;&#26377;&#25928;&#26500;&#24314;&#39640;&#36136;&#37327;&#30340;&#36777;&#35770;&#26696;&#20363;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#32654;&#22269;&#31454;&#36187;&#36777;&#35770;&#20013;&#65292;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#26174;&#33879;&#25913;&#36827;&#20102;&#24050;&#26377;&#25968;&#25454;&#38598;DebateSum&#65292;&#24182;&#36129;&#29486;&#20102;&#26032;&#30340;&#20363;&#23376;&#21644;&#26377;&#29992;&#30340;&#20803;&#25968;&#25454;&#12290;&#36890;&#36807;&#20351;&#29992;txtai&#35821;&#20041;&#25628;&#32034;&#21644;&#30693;&#35782;&#22270;&#24037;&#20855;&#38142;&#65292;&#21019;&#24314;&#21644;&#36129;&#29486;&#20102;9&#20010;&#35821;&#20041;&#30693;&#35782;&#22270;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#35780;&#20272;&#26041;&#27861;&#26469;&#30830;&#23450;&#21738;&#20010;&#30693;&#35782;&#22270;&#26356;&#36866;&#21512;&#25919;&#31574;&#36777;&#35770;&#26696;&#20363;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2307.04090</link><description>&lt;p&gt;
DebateKG: &#29992;&#35821;&#20041;&#30693;&#35782;&#22270;&#33258;&#21160;&#21019;&#24314;&#25919;&#31574;&#36777;&#35770;&#26696;&#20363;
&lt;/p&gt;
&lt;p&gt;
DebateKG: Automatic Policy Debate Case Creation with Semantic Knowledge Graphs. (arXiv:2307.04090v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#35821;&#20041;&#30693;&#35782;&#22270;&#33258;&#21160;&#21019;&#24314;&#25919;&#31574;&#36777;&#35770;&#26696;&#20363;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20105;&#35770;&#30340;&#35821;&#20041;&#30693;&#35782;&#22270;&#19978;&#36827;&#34892;&#38480;&#21046;&#26368;&#30701;&#36335;&#24452;&#36941;&#21382;&#65292;&#26377;&#25928;&#26500;&#24314;&#39640;&#36136;&#37327;&#30340;&#36777;&#35770;&#26696;&#20363;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#32654;&#22269;&#31454;&#36187;&#36777;&#35770;&#20013;&#65292;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#26174;&#33879;&#25913;&#36827;&#20102;&#24050;&#26377;&#25968;&#25454;&#38598;DebateSum&#65292;&#24182;&#36129;&#29486;&#20102;&#26032;&#30340;&#20363;&#23376;&#21644;&#26377;&#29992;&#30340;&#20803;&#25968;&#25454;&#12290;&#36890;&#36807;&#20351;&#29992;txtai&#35821;&#20041;&#25628;&#32034;&#21644;&#30693;&#35782;&#22270;&#24037;&#20855;&#38142;&#65292;&#21019;&#24314;&#21644;&#36129;&#29486;&#20102;9&#20010;&#35821;&#20041;&#30693;&#35782;&#22270;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#35780;&#20272;&#26041;&#27861;&#26469;&#30830;&#23450;&#21738;&#20010;&#30693;&#35782;&#22270;&#26356;&#36866;&#21512;&#25919;&#31574;&#36777;&#35770;&#26696;&#20363;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30456;&#20851;&#24037;&#20316;&#34920;&#26126;&#65292;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31995;&#32479;&#22312;&#35299;&#20915;&#31454;&#36187;&#36777;&#35770;&#20013;&#30340;&#38382;&#39064;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#24615;&#12290;&#31454;&#36187;&#36777;&#35770;&#20013;&#26368;&#37325;&#35201;&#30340;&#20219;&#21153;&#20043;&#19968;&#26159;&#36777;&#25163;&#21019;&#24314;&#39640;&#36136;&#37327;&#30340;&#36777;&#35770;&#26696;&#20363;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#38480;&#21046;&#26368;&#30701;&#36335;&#24452;&#36941;&#21382;&#22312;&#20105;&#35770;&#30340;&#35821;&#20041;&#30693;&#35782;&#22270;&#19978;&#26500;&#24314;&#26377;&#25928;&#30340;&#36777;&#35770;&#26696;&#20363;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#21517;&#20026;DebateSum&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30740;&#31350;&#20102;&#36825;&#31181;&#28508;&#21147;&#65292;&#35813;&#25968;&#25454;&#38598;&#38024;&#23545;&#30340;&#26159;&#19968;&#31181;&#21517;&#20026;&#25919;&#31574;&#36777;&#35770;&#30340;&#32654;&#22269;&#31454;&#36187;&#36777;&#35770;&#31867;&#22411;&#12290;&#25105;&#20204;&#36890;&#36807;&#21521;&#25968;&#25454;&#38598;&#20013;&#24341;&#20837;53180&#20010;&#26032;&#30340;&#20363;&#23376;&#65292;&#24182;&#20026;&#27599;&#20010;&#20363;&#23376;&#25552;&#20379;&#36827;&#19968;&#27493;&#26377;&#29992;&#30340;&#20803;&#25968;&#25454;&#65292;&#26174;&#33879;&#25913;&#36827;&#20102;DebateSum&#12290;&#25105;&#20204;&#21033;&#29992;txtai&#35821;&#20041;&#25628;&#32034;&#21644;&#30693;&#35782;&#22270;&#24037;&#20855;&#38142;&#22522;&#20110;&#36825;&#20010;&#25968;&#25454;&#38598;&#20135;&#29983;&#24182;&#36129;&#29486;&#20102;9&#20010;&#35821;&#20041;&#30693;&#35782;&#22270;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#30830;&#23450;&#22312;&#25919;&#31574;&#36777;&#35770;&#26696;&#20363;&#29983;&#25104;&#30340;&#32972;&#26223;&#19979;&#21738;&#20010;&#30693;&#35782;&#22270;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work within the Argument Mining community has shown the applicability of Natural Language Processing systems for solving problems found within competitive debate. One of the most important tasks within competitive debate is for debaters to create high quality debate cases. We show that effective debate cases can be constructed using constrained shortest path traversals on Argumentative Semantic Knowledge Graphs. We study this potential in the context of a type of American Competitive Debate, called Policy Debate, which already has a large scale dataset targeting it called DebateSum. We significantly improve upon DebateSum by introducing 53180 new examples, as well as further useful metadata for every example, to the dataset. We leverage the txtai semantic search and knowledge graph toolchain to produce and contribute 9 semantic knowledge graphs built on this dataset. We create a unique method for evaluating which knowledge graphs are better in the context of producing policy deb
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#20844;&#24179;&#24863;&#30693;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#35752;&#35770;&#20102;&#25552;&#39640;GNNs&#20844;&#24179;&#24615;&#30340;&#25216;&#26415;&#65292;&#24182;&#20171;&#32461;&#20102;&#20844;&#24179;&#24230;&#35780;&#20272;&#25351;&#26631;&#20998;&#31867;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.03929</link><description>&lt;p&gt;
&#20844;&#24179;&#24863;&#30693;&#22270;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Fairness-Aware Graph Neural Networks: A Survey. (arXiv:2307.03929v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03929
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#20844;&#24179;&#24863;&#30693;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#35752;&#35770;&#20102;&#25552;&#39640;GNNs&#20844;&#24179;&#24615;&#30340;&#25216;&#26415;&#65292;&#24182;&#20171;&#32461;&#20102;&#20844;&#24179;&#24230;&#35780;&#20272;&#25351;&#26631;&#20998;&#31867;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#20195;&#34920;&#33021;&#21147;&#21644;&#22312;&#35768;&#22810;&#22522;&#26412;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#26368;&#20808;&#36827;&#39044;&#27979;&#24615;&#33021;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;GNNs&#30001;&#20110;&#22522;&#30784;&#22270;&#25968;&#25454;&#21644;&#24222;&#22823;&#30340;GNN&#27169;&#22411;&#20013;&#24515;&#30340;&#22522;&#26412;&#32858;&#21512;&#26426;&#21046;&#30340;&#32467;&#26524;&#65292;&#23384;&#22312;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#23519;&#24182;&#20998;&#31867;&#20102;&#25552;&#39640;GNNs&#20844;&#24179;&#24615;&#30340;&#20844;&#24179;&#25216;&#26415;&#12290;&#20808;&#21069;&#20851;&#20110;&#20844;&#24179;GNN&#27169;&#22411;&#21644;&#25216;&#26415;&#30340;&#24037;&#20316;&#22312;&#39044;&#22788;&#29702;&#27493;&#39588;&#12289;&#35757;&#32451;&#36807;&#31243;&#20013;&#25110;&#21518;&#22788;&#29702;&#38454;&#27573;&#26159;&#21542;&#20851;&#27880;&#25552;&#39640;&#20844;&#24179;&#24615;&#26041;&#38754;&#36827;&#34892;&#20102;&#35752;&#35770;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#36825;&#20123;&#25216;&#26415;&#22914;&#20309;&#22312;&#36866;&#24403;&#30340;&#24773;&#20917;&#19979;&#20849;&#21516;&#20351;&#29992;&#65292;&#24182;&#24378;&#35843;&#20102;&#21508;&#33258;&#30340;&#20248;&#21183;&#21644;&#30452;&#35273;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#20844;&#24179;&#24230;&#35780;&#20272;&#25351;&#26631;&#20998;&#31867;&#27861;&#65292;&#21253;&#25324;&#22270;&#32423;&#20844;&#24179;&#24615;&#12289;&#37051;&#22495;&#32423;&#20844;&#24179;&#24615;&#12289;&#23884;&#20837;&#32423;&#20844;&#24179;&#24615;&#21644;&#39044;&#27979;&#32423;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have become increasingly important due to their representational power and state-of-the-art predictive performance on many fundamental learning tasks. Despite this success, GNNs suffer from fairness issues that arise as a result of the underlying graph data and the fundamental aggregation mechanism that lies at the heart of the large class of GNN models. In this article, we examine and categorize fairness techniques for improving the fairness of GNNs. Previous work on fair GNN models and techniques are discussed in terms of whether they focus on improving fairness during a preprocessing step, during training, or in a post-processing phase. Furthermore, we discuss how such techniques can be used together whenever appropriate, and highlight the advantages and intuition as well. We also introduce an intuitive taxonomy for fairness evaluation metrics including graph-level fairness, neighborhood-level fairness, embedding-level fairness, and prediction-level fair
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#35805;&#35821;&#23884;&#20837;&#25216;&#26415;&#24320;&#21457;&#31038;&#21306;&#25512;&#33616;&#31995;&#32479;&#65292;&#37325;&#28857;&#20851;&#27880;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#32676;&#20307;&#12290;&#36890;&#36807;&#25972;&#21512;&#19981;&#21516;&#31038;&#21306;&#30340;&#35805;&#35821;&#20449;&#24687;&#65292;&#37319;&#29992;&#22522;&#20110;&#20869;&#23481;&#21644;&#21327;&#21516;&#36807;&#28388;&#25216;&#26415;&#65292;&#25552;&#21319;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.03892</link><description>&lt;p&gt;
&#23558;&#24515;&#29702;&#20581;&#24247;&#35805;&#35821;&#23884;&#20837;&#31038;&#21306;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Embedding Mental Health Discourse for Community Recommendation. (arXiv:2307.03892v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#35805;&#35821;&#23884;&#20837;&#25216;&#26415;&#24320;&#21457;&#31038;&#21306;&#25512;&#33616;&#31995;&#32479;&#65292;&#37325;&#28857;&#20851;&#27880;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#32676;&#20307;&#12290;&#36890;&#36807;&#25972;&#21512;&#19981;&#21516;&#31038;&#21306;&#30340;&#35805;&#35821;&#20449;&#24687;&#65292;&#37319;&#29992;&#22522;&#20110;&#20869;&#23481;&#21644;&#21327;&#21516;&#36807;&#28388;&#25216;&#26415;&#65292;&#25552;&#21319;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#35805;&#35821;&#23884;&#20837;&#25216;&#26415;&#26469;&#24320;&#21457;&#19968;&#20010;&#31038;&#21306;&#25512;&#33616;&#31995;&#32479;&#65292;&#37325;&#28857;&#20851;&#27880;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#32676;&#20307;&#12290;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#20026;&#29992;&#25143;&#25552;&#20379;&#20102;&#19982;&#28385;&#36275;&#20854;&#29305;&#23450;&#20852;&#36259;&#30340;&#31038;&#21306;&#21311;&#21517;&#36830;&#25509;&#30340;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22312;&#32447;&#31038;&#21306;&#25968;&#37327;&#24222;&#22823;&#65292;&#29992;&#25143;&#21487;&#33021;&#38590;&#20197;&#25214;&#21040;&#30456;&#20851;&#32676;&#32452;&#26469;&#35299;&#20915;&#20182;&#20204;&#30340;&#24515;&#29702;&#20581;&#24247;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#20351;&#29992;&#23884;&#20837;&#25216;&#26415;&#25506;&#32034;&#26469;&#33258;&#19981;&#21516;subreddit&#31038;&#21306;&#30340;&#35805;&#35821;&#20449;&#24687;&#30340;&#25972;&#21512;&#65292;&#20197;&#24320;&#21457;&#19968;&#20010;&#26377;&#25928;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;&#20869;&#23481;&#21644;&#21327;&#21516;&#36807;&#28388;&#30340;&#25216;&#26415;&#26469;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#21333;&#29420;&#20351;&#29992;&#27599;&#31181;&#25216;&#26415;&#65292;&#24182;&#25552;&#20379;&#20102;&#25512;&#33616;&#36807;&#31243;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our paper investigates the use of discourse embedding techniques to develop a community recommendation system that focuses on mental health support groups on social media. Social media platforms provide a means for users to anonymously connect with communities that cater to their specific interests. However, with the vast number of online communities available, users may face difficulties in identifying relevant groups to address their mental health concerns. To address this challenge, we explore the integration of discourse information from various subreddit communities using embedding techniques to develop an effective recommendation system. Our approach involves the use of content-based and collaborative filtering techniques to enhance the performance of the recommendation system. Our findings indicate that the proposed approach outperforms the use of each technique separately and provides interpretability in the recommendation process.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;AI&#32842;&#22825;&#31995;&#32479;&#22312;&#25628;&#32034;&#36807;&#31243;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#30740;&#31350;&#20102;&#23558;&#32842;&#22825;&#31995;&#32479;&#19982;&#25628;&#32034;&#24037;&#20855;&#32467;&#21512;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;&#35813;&#30740;&#31350;&#21457;&#29616;AI&#32842;&#22825;&#31995;&#32479;&#26377;&#26395;&#25913;&#21464;&#20154;&#20204;&#30340;&#25628;&#32034;&#34892;&#20026;&#21644;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2307.03826</link><description>&lt;p&gt;
AI&#32842;&#22825;&#22914;&#20309;&#25913;&#21464;&#25628;&#32034;&#34892;&#20026;&#65311;
&lt;/p&gt;
&lt;p&gt;
How does AI chat change search behaviors?. (arXiv:2307.03826v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03826
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;AI&#32842;&#22825;&#31995;&#32479;&#22312;&#25628;&#32034;&#36807;&#31243;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#30740;&#31350;&#20102;&#23558;&#32842;&#22825;&#31995;&#32479;&#19982;&#25628;&#32034;&#24037;&#20855;&#32467;&#21512;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;&#35813;&#30740;&#31350;&#21457;&#29616;AI&#32842;&#22825;&#31995;&#32479;&#26377;&#26395;&#25913;&#21464;&#20154;&#20204;&#30340;&#25628;&#32034;&#34892;&#20026;&#21644;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;AI&#24037;&#20855;&#22914;chatGPT&#26377;&#26395;&#25913;&#21464;&#20154;&#20204;&#19982;&#22312;&#32447;&#20449;&#24687;&#30340;&#20114;&#21160;&#26041;&#24335;&#12290;&#36817;&#26399;&#65292;&#24494;&#36719;&#23459;&#24067;&#20102;&#20182;&#20204;&#30340;&#8220;&#26032;Bing&#8221;&#25628;&#32034;&#31995;&#32479;&#65292;&#20854;&#20013;&#25972;&#21512;&#20102;&#26469;&#33258;OpenAI&#30340;&#32842;&#22825;&#21644;&#29983;&#25104;&#24335;AI&#25216;&#26415;&#12290;&#35895;&#27468;&#20063;&#23459;&#24067;&#20102;&#23558;&#37096;&#32626;&#31867;&#20284;&#25216;&#26415;&#30340;&#25628;&#32034;&#30028;&#38754;&#30340;&#35745;&#21010;&#12290;&#36825;&#20123;&#26032;&#25216;&#26415;&#23558;&#25913;&#21464;&#20154;&#20204;&#25628;&#32034;&#20449;&#24687;&#30340;&#26041;&#24335;&#12290;&#26412;&#30740;&#31350;&#26159;&#23545;&#20154;&#20204;&#22312;&#25628;&#32034;&#36807;&#31243;&#20013;&#22914;&#20309;&#20351;&#29992;&#29983;&#25104;&#24335;AI&#32842;&#22825;&#31995;&#32479;&#65288;&#20197;&#19979;&#31616;&#31216;&#20026;chat&#65289;&#20197;&#21450;&#23558;chat&#31995;&#32479;&#19982;&#29616;&#26377;&#25628;&#32034;&#24037;&#20855;&#32467;&#21512;&#21487;&#33021;&#22914;&#20309;&#24433;&#21709;&#29992;&#25143;&#30340;&#25628;&#32034;&#34892;&#20026;&#21644;&#31574;&#30053;&#30340;&#26089;&#26399;&#35843;&#26597;&#30740;&#31350;&#12290;&#25105;&#20204;&#25253;&#36947;&#20102;&#19968;&#20010;&#25506;&#32034;&#24615;&#29992;&#25143;&#30740;&#31350;&#65292;&#26377;10&#21517;&#21442;&#19982;&#32773;&#20351;&#29992;&#20102;&#19968;&#20010;&#20351;&#29992;OpenAI GPT-3.5 API&#21644;Bing Web Search v5 API&#30340;&#32508;&#21512;Chat+Search&#31995;&#32479;&#12290;&#21442;&#19982;&#32773;&#23436;&#25104;&#20102;&#19977;&#20010;&#25628;&#32034;&#20219;&#21153;&#12290;&#22312;&#36825;&#31687;&#21021;&#27493;&#32467;&#26524;&#30340;&#39044;&#21360;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25253;&#36947;&#20102;&#29992;&#25143;&#22312;&#25628;&#32034;&#36807;&#31243;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#21644;&#20351;&#29992;chat&#31995;&#32479;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative AI tools such as chatGPT are poised to change the way people engage with online information. Recently, Microsoft announced their "new Bing" search system which incorporates chat and generative AI technology from OpenAI. Google has announced plans to deploy search interfaces that incorporate similar types of technology. These new technologies will transform how people can search for information. The research presented here is an early investigation into how people make use of a generative AI chat system (referred to simply as chat from here on) as part of a search process, and how the incorporation of chat systems with existing search tools may effect users search behaviors and strategies.  We report on an exploratory user study with 10 participants who used a combined Chat+Search system that utilized the OpenAI GPT-3.5 API and the Bing Web Search v5 API. Participants completed three search tasks. In this pre-print paper of preliminary results, we report on ways that users in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21019;&#26032;&#25512;&#33616;&#31995;&#32479;&#26041;&#27861;GenRec&#65292;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#30446;&#26631;&#25512;&#33616;&#39033;&#32780;&#19981;&#26159;&#35745;&#31639;&#25490;&#21517;&#20998;&#25968;&#65292;&#21033;&#29992;LLM&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#29702;&#35299;&#33021;&#21147;&#26469;&#29983;&#25104;&#30456;&#20851;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2307.00457</link><description>&lt;p&gt;
GenRec:&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#24335;&#25512;&#33616;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
GenRec: Large Language Model for Generative Recommendation. (arXiv:2307.00457v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00457
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21019;&#26032;&#25512;&#33616;&#31995;&#32479;&#26041;&#27861;GenRec&#65292;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#30446;&#26631;&#25512;&#33616;&#39033;&#32780;&#19981;&#26159;&#35745;&#31639;&#25490;&#21517;&#20998;&#25968;&#65292;&#21033;&#29992;LLM&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#29702;&#35299;&#33021;&#21147;&#26469;&#29983;&#25104;&#30456;&#20851;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(Large Language Model&#65292;LLM)&#24050;&#32463;&#25104;&#20026;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#22312;&#29983;&#25104;&#24335;&#25512;&#33616;&#33539;&#24335;&#19979;&#65292;&#23427;&#20204;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#28508;&#21147;&#30456;&#23545;&#26410;&#34987;&#25506;&#32034;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;&#25991;&#26412;&#25968;&#25454;&#30340;&#25512;&#33616;&#31995;&#32479;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#26469;&#36827;&#34892;&#25512;&#33616;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33616;&#31995;&#32479;(GenRec)&#65292;&#35813;&#31995;&#32479;&#21033;&#29992;LLM&#30340;&#34920;&#36798;&#33021;&#21147;&#30452;&#25509;&#29983;&#25104;&#30446;&#26631;&#25512;&#33616;&#39033;&#65292;&#32780;&#19981;&#26159;&#20687;&#20256;&#32479;&#30340;&#21028;&#21035;&#24335;&#25512;&#33616;&#31995;&#32479;&#19968;&#26679;&#36880;&#20010;&#35745;&#31639;&#27599;&#20010;&#20505;&#36873;&#39033;&#30340;&#25490;&#21517;&#20998;&#25968;&#12290;GenRec&#21033;&#29992;LLM&#30340;&#29702;&#35299;&#33021;&#21147;&#26469;&#35299;&#37322;&#19978;&#19979;&#25991;&#12289;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#24182;&#29983;&#25104;&#30456;&#20851;&#25512;&#33616;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#32534;&#30721;&#30340;&#20016;&#23500;&#30693;&#35782;&#26469;&#23436;&#25104;&#25512;&#33616;&#20219;&#21153;&#12290;&#25105;&#20204;&#39318;&#20808;&#21046;&#23450;&#20102;&#19987;&#38376;&#30340;&#25552;&#31034;&#65292;&#20197;&#22686;&#24378;LLM&#29702;&#35299;&#25512;&#33616;&#20219;&#21153;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, large language models (LLM) have emerged as powerful tools for diverse natural language processing tasks. However, their potential for recommender systems under the generative recommendation paradigm remains relatively unexplored. This paper presents an innovative approach to recommendation systems using large language models (LLMs) based on text data. In this paper, we present a novel LLM for generative recommendation (GenRec) that utilized the expressive power of LLM to directly generate the target item to recommend, rather than calculating ranking score for each candidate item one by one as in traditional discriminative recommendation. GenRec uses LLM's understanding ability to interpret context, learn user preferences, and generate relevant recommendation. Our proposed approach leverages the vast knowledge encoded in large language models to accomplish recommendation tasks. We first we formulate specialized prompts to enhance the ability of LLM to comprehend recomm
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#22810;&#31181;&#29615;&#22659;&#20256;&#24863;&#22120;&#32467;&#21512;&#30340;&#28151;&#21512;&#20256;&#24863;&#22120;&#20154;&#31867;&#27963;&#21160;&#35782;&#21035;&#26694;&#26550;&#65292;&#21487;&#35782;&#21035;&#20986;&#26356;&#22810;&#30340;&#27963;&#21160;&#65292;&#26377;&#21161;&#20110;&#25512;&#23548;&#20986;&#20154;&#31867;&#27963;&#21160;&#27169;&#24335;&#25110;&#29992;&#25143;&#30011;&#20687;&#12290;</title><link>http://arxiv.org/abs/2306.13374</link><description>&lt;p&gt;
&#38271;&#26399;&#25968;&#25454;&#37319;&#38598;&#19979;&#30340;&#26234;&#33021;&#23478;&#23621;&#20154;&#31867;&#27963;&#21160;&#34892;&#20026;&#27169;&#24335;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Human Activity Behavioural Pattern Recognition in Smarthome with Long-hour Data Collection. (arXiv:2306.13374v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13374
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#22810;&#31181;&#29615;&#22659;&#20256;&#24863;&#22120;&#32467;&#21512;&#30340;&#28151;&#21512;&#20256;&#24863;&#22120;&#20154;&#31867;&#27963;&#21160;&#35782;&#21035;&#26694;&#26550;&#65292;&#21487;&#35782;&#21035;&#20986;&#26356;&#22810;&#30340;&#27963;&#21160;&#65292;&#26377;&#21161;&#20110;&#25512;&#23548;&#20986;&#20154;&#31867;&#27963;&#21160;&#27169;&#24335;&#25110;&#29992;&#25143;&#30011;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#27963;&#21160;&#35782;&#21035;&#30340;&#30740;&#31350;&#20026;&#21307;&#30103;&#20445;&#20581;&#12289;&#36816;&#21160;&#21644;&#29992;&#25143;&#30011;&#20687;&#31561;&#35768;&#22810;&#24212;&#29992;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#32771;&#34385;&#21040;&#20154;&#31867;&#27963;&#21160;&#30340;&#22797;&#26434;&#24615;&#65292;&#21363;&#20351;&#26377;&#26377;&#25928;&#30340;&#20256;&#24863;&#22120;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#30446;&#21069;&#20351;&#29992;&#26234;&#33021;&#25163;&#26426;&#20256;&#24863;&#22120;&#36827;&#34892;&#20154;&#31867;&#27963;&#21160;&#35782;&#21035;&#30340;&#29616;&#26377;&#24037;&#20316;&#65292;&#19987;&#27880;&#20110;&#35782;&#21035;&#22914;&#22352;&#12289;&#30561;&#30496;&#12289;&#31449;&#31435;&#12289;&#19978;&#19979;&#27004;&#26799;&#21644;&#22868;&#36305;&#31561;&#22522;&#26412;&#30340;&#20154;&#31867;&#27963;&#21160;&#12290;&#28982;&#32780;&#65292;&#20998;&#26512;&#20154;&#31867;&#34892;&#20026;&#27169;&#24335;&#38656;&#35201;&#26356;&#22810;&#30340;&#27963;&#21160;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#35782;&#21035;&#22522;&#26412;&#20154;&#31867;&#27963;&#21160;&#65292;&#21516;&#26102;&#32467;&#21512;&#29615;&#22659;&#20256;&#24863;&#22120;&#65288;&#22914;PIR&#12289;&#21387;&#21147;&#20256;&#24863;&#22120;&#65289;&#21644;&#22522;&#20110;&#26234;&#33021;&#25163;&#26426;&#30340;&#20256;&#24863;&#22120;&#65288;&#22914;&#21152;&#36895;&#24230;&#35745;&#21644;&#38464;&#34746;&#20202;&#65289;&#26469;&#23454;&#29616;&#28151;&#21512;&#20256;&#24863;&#22120;&#20154;&#31867;&#27963;&#21160;&#35782;&#21035;&#12290;&#28151;&#21512;&#26041;&#27861;&#24110;&#21161;&#25512;&#23548;&#20986;&#27604;&#22522;&#26412;&#27963;&#21160;&#26356;&#22810;&#30340;&#27963;&#21160;&#65292;&#36825;&#20063;&#26377;&#21161;&#20110;&#25512;&#23548;&#20986;&#20154;&#31867;&#27963;&#21160;&#27169;&#24335;&#25110;&#29992;&#25143;&#30011;&#20687;&#12290;&#29992;&#25143;&#30011;&#20687;&#25552;&#20379;&#20102;&#36275;&#22815;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
The research on human activity recognition has provided novel solutions to many applications like healthcare, sports, and user profiling. Considering the complex nature of human activities, it is still challenging even after effective and efficient sensors are available. The existing works on human activity recognition using smartphone sensors focus on recognizing basic human activities like sitting, sleeping, standing, stair up and down and running. However, more than these basic activities is needed to analyze human behavioural pattern. The proposed framework recognizes basic human activities using deep learning models. Also, ambient sensors like PIR, pressure sensors, and smartphone-based sensors like accelerometers and gyroscopes are combined to make it hybrid-sensor-based human activity recognition. The hybrid approach helped derive more activities than the basic ones, which also helped derive human activity patterns or user profiling. User profiling provides sufficient informatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#22270;&#23545;&#27604;&#23398;&#20064;&#30340;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#24335;&#25913;&#36827;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#34920;&#31034;&#65292;&#20851;&#27880;&#25968;&#25454;&#20013;&#30340;&#38590;&#20197;&#21306;&#20998;&#30340;&#36127;&#38754;&#20363;&#23376;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2305.10837</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#22270;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Adaptive Graph Contrastive Learning for Recommendation. (arXiv:2305.10837v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10837
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#22270;&#23545;&#27604;&#23398;&#20064;&#30340;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#24335;&#25913;&#36827;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#34920;&#31034;&#65292;&#20851;&#27880;&#25968;&#25454;&#20013;&#30340;&#38590;&#20197;&#21306;&#20998;&#30340;&#36127;&#38754;&#20363;&#23376;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#24050;&#25104;&#21151;&#22320;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#65292;&#25104;&#20026;&#19968;&#31181;&#26377;&#25928;&#30340;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#12290;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#27839;&#30528;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#36793;&#36882;&#24402;&#22320;&#25191;&#34892;&#28040;&#24687;&#20256;&#36882;&#65292;&#20197;&#23436;&#21892;&#32534;&#30721;&#23884;&#20837;&#65292;&#36825;&#20381;&#36182;&#20110;&#20805;&#36275;&#21644;&#39640;&#36136;&#37327;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#30001;&#20110;&#23454;&#38469;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#36890;&#24120;&#23384;&#22312;&#22122;&#22768;&#24182;&#21576;&#29616;&#20986;&#20542;&#26012;&#20998;&#24067;&#65292;&#19968;&#20123;&#25512;&#33616;&#26041;&#27861;&#21033;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#26469;&#25913;&#21892;&#29992;&#25143;&#34920;&#31034;&#65292;&#20363;&#22914;SGL&#21644;SimGCL&#12290; &#28982;&#32780;&#65292;&#23613;&#31649;&#23427;&#20204;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#23427;&#20204;&#36890;&#36807;&#21019;&#24314;&#23545;&#27604;&#35270;&#22270;&#36827;&#34892;&#33258;&#30417;&#30563;&#23398;&#20064;&#65292;&#20855;&#26377;&#25968;&#25454;&#22686;&#24378;&#25506;&#32034;&#65292;&#38656;&#35201;&#36827;&#34892;&#32321;&#29712;&#30340;&#35797;&#38169;&#36873;&#25321;&#22686;&#24378;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;AdaptiveGCL&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#20294;&#20851;&#27880;&#25968;&#25454;&#20013;&#30340;&#38590;&#20197;&#21306;&#20998;&#30340;&#36127;&#38754;&#20363;&#23376;&#30340;&#20449;&#24687;&#65292;&#29992;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#24335;&#25913;&#36827;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, graph neural networks (GNNs) have been successfully applied to recommender systems as an effective collaborative filtering (CF) approach. The key idea of GNN-based recommender system is to recursively perform the message passing along the user-item interaction edge for refining the encoded embeddings, relying on sufficient and high-quality training data. Since user behavior data in practical recommendation scenarios is often noisy and exhibits skewed distribution, some recommendation approaches, e.g., SGL and SimGCL, leverage self-supervised learning to improve user representations against the above issues. Despite their effectiveness, however, they conduct self-supervised learning through creating contrastvie views, depending on the exploration of data augmentations with the problem of tedious trial-and-error selection of augmentation methods. In this paper, we propose a novel Adaptive Graph Contrastive Learning (AdaptiveGCL) framework which conducts graph contrastive learni
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;PropensityNet&#65292;&#29992;&#20110;&#22312;&#24378;&#26085;&#24535;&#35760;&#24405;&#31574;&#30053;&#19979;&#36827;&#34892;&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;&#65288;ULTR&#65289;&#30340;&#20542;&#21521;&#24615;&#20272;&#35745;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;ULTR&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.09918</link><description>&lt;p&gt;
&#26080;&#20559;&#20542;&#21521;&#20272;&#35745;&#29992;&#20110;&#26080;&#20559;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Unconfounded Propensity Estimation for Unbiased Ranking. (arXiv:2305.09918v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09918
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;PropensityNet&#65292;&#29992;&#20110;&#22312;&#24378;&#26085;&#24535;&#35760;&#24405;&#31574;&#30053;&#19979;&#36827;&#34892;&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;&#65288;ULTR&#65289;&#30340;&#20542;&#21521;&#24615;&#20272;&#35745;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;ULTR&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;&#65288;ULTR&#65289;&#30340;&#30446;&#26631;&#26159;&#21033;&#29992;&#38544;&#21547;&#30340;&#29992;&#25143;&#21453;&#39304;&#26469;&#20248;&#21270;&#23398;&#20064;&#25490;&#24207;&#31995;&#32479;&#12290;&#22312;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#20013;&#65292;&#33258;&#21160;ULTR&#31639;&#27861;&#22312;&#23454;&#36341;&#20013;&#22240;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#21644;&#20302;&#37096;&#32626;&#25104;&#26412;&#32780;&#21463;&#21040;&#20851;&#27880;&#65292;&#35813;&#31639;&#27861;&#21516;&#26102;&#23398;&#20064;&#29992;&#25143;&#20559;&#24046;&#27169;&#22411;&#65288;&#21363;&#20542;&#21521;&#24615;&#27169;&#22411;&#65289;&#21644;&#26080;&#20559;&#25490;&#21517;&#22120;&#12290;&#23613;&#31649;&#35813;&#31639;&#27861;&#22312;&#29702;&#35770;&#19978;&#26159;&#21487;&#38752;&#30340;&#65292;&#20294;&#20854;&#26377;&#25928;&#24615;&#36890;&#24120;&#22312;&#24369;&#26085;&#24535;&#35760;&#24405;&#31574;&#30053;&#19979;&#36827;&#34892;&#39564;&#35777;&#65292;&#20854;&#20013;&#25490;&#21517;&#27169;&#22411;&#20960;&#20046;&#26080;&#27861;&#26681;&#25454;&#19982;&#26597;&#35810;&#30456;&#20851;&#24615;&#26469;&#23545;&#25991;&#26723;&#36827;&#34892;&#25490;&#21517;&#12290;&#28982;&#32780;&#65292;&#24403;&#26085;&#24535;&#35760;&#24405;&#31574;&#30053;&#24456;&#24378;&#26102;&#65292;&#20363;&#22914;&#24037;&#19994;&#37096;&#32626;&#30340;&#25490;&#21517;&#31574;&#30053;&#65292;&#25152;&#25253;&#21578;&#30340;&#26377;&#25928;&#24615;&#26080;&#27861;&#20877;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20174;&#22240;&#26524;&#35282;&#24230;&#35843;&#26597;ULTR&#65292;&#24182;&#25581;&#31034;&#19968;&#20010;&#36127;&#38754;&#32467;&#26524;&#65306;&#29616;&#26377;&#30340;ULTR&#31639;&#27861;&#26410;&#33021;&#35299;&#20915;&#30001;&#26597;&#35810;-&#25991;&#26723;&#30456;&#20851;&#24615;&#28151;&#28102;&#23548;&#33268;&#30340;&#20542;&#21521;&#24615;&#39640;&#20272;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#38376;&#35843;&#25972;&#30340;&#26032;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PropensityNet&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#24378;&#26085;&#24535;&#35760;&#24405;&#31574;&#30053;&#19979;&#20026;ULTR&#20272;&#35745;&#26080;&#20559;&#30340;&#20542;&#21521;&#24615;&#20998;&#25968;&#12290;&#22810;&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;PropensityNet&#22312;&#24378;&#26085;&#24535;&#35760;&#24405;&#31574;&#30053;&#21644;&#24369;&#26085;&#24535;&#35760;&#24405;&#31574;&#30053;&#19979;&#22343;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;ULTR&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of unbiased learning to rank~(ULTR) is to leverage implicit user feedback for optimizing learning-to-rank systems. Among existing solutions, automatic ULTR algorithms that jointly learn user bias models (\ie propensity models) with unbiased rankers have received a lot of attention due to their superior performance and low deployment cost in practice. Despite their theoretical soundness, the effectiveness is usually justified under a weak logging policy, where the ranking model can barely rank documents according to their relevance to the query. However, when the logging policy is strong, e.g., an industry-deployed ranking policy, the reported effectiveness cannot be reproduced. In this paper, we first investigate ULTR from a causal perspective and uncover a negative result: existing ULTR algorithms fail to address the issue of propensity overestimation caused by the query-document relevance confounder. Then, we propose a new learning objective based on backdoor adjustment and 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.06569</link><description>&lt;p&gt;
&#22914;&#20309;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#32034;&#24341;&#39033;&#30446;ID
&lt;/p&gt;
&lt;p&gt;
How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#23558;&#25512;&#33616;&#20219;&#21153;&#36716;&#25442;&#20026;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#25512;&#33616;&#12290;&#23427;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#24314;&#35758;&#30340;&#39033;&#30446;&#32780;&#19981;&#26159;&#35745;&#31639;&#20256;&#32479;&#25512;&#33616;&#27169;&#22411;&#20013;&#27599;&#20010;&#20505;&#36873;&#39033;&#30446;&#30340;&#25490;&#21517;&#24471;&#20998;&#65292;&#31616;&#21270;&#20102;&#25512;&#33616;&#31649;&#36947;&#65292;&#36991;&#20813;&#20102;&#22810;&#27573;&#36807;&#28388;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#22312;&#20915;&#23450;&#35201;&#25512;&#33616;&#21738;&#20123;&#39033;&#30446;&#26102;&#29983;&#25104;&#36807;&#38271;&#30340;&#25991;&#26412;&#65292;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#21019;&#24314;LLM&#20860;&#23481;&#30340;&#39033;&#30446;ID&#26159;&#24517;&#35201;&#30340;&#12290;&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#65292;&#20197;P5&#20026;&#20195;&#34920;&#30340;&#20027;&#24178;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32034;&#24341;&#26041;&#27861;&#22797;&#21046;&#20854;&#32467;&#26524;&#12290;&#25105;&#20204;&#39318;&#20808;&#35752;&#35770;&#20102;&#20960;&#31181;&#24494;&#19981;&#36275;&#36947;&#30340;&#39033;&#30446;&#32034;&#24341;&#26041;&#27861;&#65288;&#22914;&#29420;&#31435;&#32034;&#24341;&#12289;&#26631;&#39064;&#32034;&#24341;&#21644;&#38543;&#26426;&#32034;&#24341;&#65289;&#30340;&#38382;&#39064;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#19981;&#36866;&#29992;&#20110;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32034;&#24341;&#26041;&#27861;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#31181;&#32034;&#24341;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#32034;&#24341;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
&lt;/p&gt;</description></item><item><title>TalkTheWalk &#26159;&#19968;&#31181;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#21033;&#29992;&#31934;&#24515;&#31574;&#21010;&#30340;&#39033;&#30446;&#25910;&#34255;&#20013;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#21512;&#25104;&#36924;&#30495;&#39640;&#36136;&#37327;&#30340;&#20250;&#35805;&#25968;&#25454;&#65292;&#35299;&#20915;&#20102;&#26500;&#24314;&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#30340;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2301.11489</link><description>&lt;p&gt;
Talk the Walk: &#38024;&#23545;&#20250;&#35805;&#24335;&#38899;&#20048;&#25512;&#33616;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Talk the Walk: Synthetic Data Generation for Conversational Music Recommendation. (arXiv:2301.11489v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11489
&lt;/p&gt;
&lt;p&gt;
TalkTheWalk &#26159;&#19968;&#31181;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#21033;&#29992;&#31934;&#24515;&#31574;&#21010;&#30340;&#39033;&#30446;&#25910;&#34255;&#20013;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#21512;&#25104;&#36924;&#30495;&#39640;&#36136;&#37327;&#30340;&#20250;&#35805;&#25968;&#25454;&#65292;&#35299;&#20915;&#20102;&#26500;&#24314;&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24191;&#27867;&#23384;&#22312;&#65292;&#20294;&#29992;&#25143;&#24448;&#24448;&#24456;&#38590;&#22312;&#25512;&#33616;&#36136;&#37327;&#36739;&#24046;&#26102;&#36827;&#34892;&#25511;&#21046;&#21644;&#35843;&#25972;&#12290;&#36825;&#20419;&#20351;&#20102;&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;(CRSs)&#30340;&#21457;&#23637;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#21453;&#39304;&#25552;&#20379;&#23545;&#25512;&#33616;&#30340;&#25511;&#21046;&#12290;&#28982;&#32780;&#65292;&#26500;&#24314;&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#38656;&#35201;&#21253;&#21547;&#29992;&#25143;&#35805;&#35821;&#21644;&#28085;&#30422;&#22810;&#26679;&#21270;&#20559;&#22909;&#33539;&#22260;&#30340;&#39033;&#30446;&#30340;&#20250;&#35805;&#35757;&#32451;&#25968;&#25454;&#12290;&#20351;&#29992;&#20256;&#32479;&#26041;&#27861;&#22914;&#20247;&#21253;&#65292;&#36825;&#26679;&#30340;&#25968;&#25454;&#25910;&#38598;&#36215;&#26469;&#38750;&#24120;&#22256;&#38590;&#12290;&#25105;&#20204;&#22312;&#39033;&#30446;&#38598;&#25512;&#33616;&#30340;&#32972;&#26223;&#19979;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#27880;&#24847;&#21040;&#36825;&#20010;&#20219;&#21153;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#20851;&#27880;&#65292;&#21160;&#26426;&#22312;&#20110;&#38899;&#20048;&#12289;&#26032;&#38395;&#21644;&#39135;&#35889;&#25512;&#33616;&#31561;&#20351;&#29992;&#26696;&#20363;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#25216;&#26415;TalkTheWalk&#65292;&#36890;&#36807;&#21033;&#29992;&#24191;&#27867;&#21487;&#33719;&#24471;&#30340;&#31934;&#24515;&#31574;&#21010;&#30340;&#39033;&#30446;&#25910;&#34255;&#20013;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#21512;&#25104;&#36924;&#30495;&#39640;&#36136;&#37327;&#30340;&#20250;&#35805;&#25968;&#25454;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#39033;&#30446;&#38598;&#31574;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems are ubiquitous yet often difficult for users to control and adjust when recommendation quality is poor. This has motivated the development of conversational recommendation systems (CRSs), with control over recommendations provided through natural language feedback. However, building conversational recommendation systems requires conversational training data involving user utterances paired with items that cover a diverse range of preferences. Such data has proved challenging to collect scalably using conventional methods like crowdsourcing. We address it in the context of item-set recommendation, noting the increasing attention to this task motivated by use cases like music, news and recipe recommendation. We present a new technique, TalkTheWalk, that synthesizes realistic high-quality conversational data by leveraging domain expertise encoded in widely available curated item collections, showing how these can be transformed into corresponding item set curation c
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#35843;&#30740;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#29992;&#20110;&#23558;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#22810;&#26679;&#21270;&#25351;&#26631;&#21644;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#12290;&#35843;&#30740;&#24635;&#32467;&#20102;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#21508;&#31181;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#21508;&#31181;&#24212;&#29992;&#22312;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#35843;&#30740;&#25104;&#26524;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#20063;&#34987;&#35752;&#35770;&#12290;</title><link>http://arxiv.org/abs/2212.14464</link><description>&lt;p&gt;
&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#32467;&#26524;&#22810;&#26679;&#21270;&#65306;&#19968;&#39033;&#35843;&#30740;
&lt;/p&gt;
&lt;p&gt;
Result Diversification in Search and Recommendation: A Survey. (arXiv:2212.14464v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14464
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#30740;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#29992;&#20110;&#23558;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#22810;&#26679;&#21270;&#25351;&#26631;&#21644;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#12290;&#35843;&#30740;&#24635;&#32467;&#20102;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#21508;&#31181;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#21508;&#31181;&#24212;&#29992;&#22312;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#35843;&#30740;&#25104;&#26524;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#20063;&#34987;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26679;&#21270;&#36820;&#22238;&#32467;&#26524;&#23545;&#20110;&#28385;&#36275;&#23458;&#25143;&#30340;&#21508;&#31181;&#20852;&#36259;&#21644;&#25552;&#20379;&#32773;&#30340;&#24066;&#22330;&#26333;&#20809;&#26159;&#37325;&#35201;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#36817;&#24180;&#26469;&#65292;&#23545;&#22810;&#26679;&#21270;&#30740;&#31350;&#30340;&#20851;&#27880;&#19981;&#26029;&#22686;&#21152;&#65292;&#20276;&#38543;&#30528;&#23545;&#22312;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#20419;&#36827;&#22810;&#26679;&#24615;&#30340;&#26041;&#27861;&#30340;&#25991;&#29486;&#22823;&#37327;&#28044;&#29616;&#12290;&#28982;&#32780;&#65292;&#26816;&#32034;&#31995;&#32479;&#20013;&#30340;&#22810;&#26679;&#21270;&#30740;&#31350;&#32570;&#20047;&#31995;&#32479;&#32452;&#32455;&#65292;&#23384;&#22312;&#29255;&#27573;&#21270;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#35843;&#30740;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#29992;&#20110;&#23558;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#22810;&#26679;&#21270;&#25351;&#26631;&#21644;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#65292;&#36825;&#20004;&#20010;&#39046;&#22495;&#26159;&#26816;&#32034;&#31995;&#32479;&#20013;&#30740;&#31350;&#26368;&#24191;&#27867;&#30340;&#39046;&#22495;&#20043;&#19968;&#12290;&#25105;&#20204;&#20174;&#31616;&#35201;&#35752;&#35770;&#20026;&#20309;&#22810;&#26679;&#24615;&#22312;&#26816;&#32034;&#31995;&#32479;&#20013;&#37325;&#35201;&#24320;&#22987;&#35843;&#30740;&#65292;&#28982;&#21518;&#24635;&#32467;&#20102;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#21508;&#31181;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#31361;&#20986;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#21644;&#24046;&#24322;&#12290;&#35843;&#30740;&#30340;&#20027;&#20307;&#37096;&#20998;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#25551;&#36848;&#29616;&#26377;&#22810;&#26679;&#21270;&#25351;&#26631;&#21644;&#26041;&#27861;&#30340;&#35814;&#32454;&#20869;&#23481;&#65292;&#23637;&#31034;&#20102;&#21508;&#31181;&#24212;&#29992;&#22312;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#35843;&#30740;&#25104;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23545;&#24403;&#21069;&#30340;&#30740;&#31350;&#36235;&#21183;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diversifying return results is an important research topic in retrieval systems in order to satisfy both the various interests of customers and the equal market exposure of providers. There has been growing attention on diversity-aware research during recent years, accompanied by a proliferation of literature on methods to promote diversity in search and recommendation. However, diversity-aware studies in retrieval systems lack a systematic organization and are rather fragmented. In this survey, we are the first to propose a unified taxonomy for classifying the metrics and approaches of diversification in both search and recommendation, which are two of the most extensively researched fields of retrieval systems. We begin the survey with a brief discussion of why diversity is important in retrieval systems, followed by a summary of the various diversity concerns in search and recommendation, highlighting their relationship and differences. For the survey's main body, we present a unifi
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32423;&#32852;&#21097;&#20313;&#22270;&#21367;&#31215;&#32593;&#32476;&#29992;&#20110;&#22810;&#34892;&#20026;&#25512;&#33616;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19981;&#21516;&#34892;&#20026;&#20043;&#38388;&#30340;&#32852;&#31995;&#26469;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#65292;&#20943;&#36731;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.13128</link><description>&lt;p&gt;
&#32423;&#32852;&#21097;&#20313;&#22270;&#21367;&#31215;&#32593;&#32476;&#29992;&#20110;&#22810;&#34892;&#20026;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Cascading Residual Graph Convolutional Network for Multi-Behavior Recommendation. (arXiv:2205.13128v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13128
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32423;&#32852;&#21097;&#20313;&#22270;&#21367;&#31215;&#32593;&#32476;&#29992;&#20110;&#22810;&#34892;&#20026;&#25512;&#33616;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19981;&#21516;&#34892;&#20026;&#20043;&#38388;&#30340;&#32852;&#31995;&#26469;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#65292;&#20943;&#36731;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#34892;&#20026;&#25512;&#33616;&#21033;&#29992;&#22810;&#31181;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#31867;&#22411;&#26469;&#20943;&#36731;&#20256;&#32479;&#27169;&#22411;&#38754;&#20020;&#30340;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#65292;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20165;&#21033;&#29992;&#19968;&#31181;&#20132;&#20114;&#31867;&#22411;&#36827;&#34892;&#25512;&#33616;&#12290;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#29992;&#25143;&#36890;&#24120;&#37319;&#21462;&#19968;&#31995;&#21015;&#21160;&#20316;&#19982;&#29289;&#21697;&#36827;&#34892;&#20132;&#20114;&#65292;&#20197;&#33719;&#21462;&#26356;&#22810;&#20851;&#20110;&#29289;&#21697;&#30340;&#20449;&#24687;&#65292;&#20174;&#32780;&#20934;&#30830;&#35780;&#20272;&#29289;&#21697;&#26159;&#21542;&#31526;&#21512;&#20010;&#20154;&#20559;&#22909;&#12290;&#36825;&#20123;&#20132;&#20114;&#34892;&#20026;&#36890;&#24120;&#36981;&#24490;&#19968;&#23450;&#30340;&#39034;&#24207;&#65292;&#19981;&#21516;&#30340;&#34892;&#20026;&#25581;&#31034;&#20102;&#29992;&#25143;&#23545;&#30446;&#26631;&#29289;&#21697;&#30340;&#19981;&#21516;&#20449;&#24687;&#25110;&#20559;&#22909;&#26041;&#38754;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#22810;&#34892;&#20026;&#25512;&#33616;&#26041;&#27861;&#37319;&#21462;&#20808;&#20998;&#21035;&#20174;&#19981;&#21516;&#30340;&#34892;&#20026;&#20013;&#25552;&#21462;&#20449;&#24687;&#65292;&#28982;&#21518;&#23558;&#20854;&#34701;&#21512;&#36827;&#34892;&#26368;&#32456;&#39044;&#27979;&#30340;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#27809;&#26377;&#21033;&#29992;&#19981;&#21516;&#34892;&#20026;&#20043;&#38388;&#30340;&#32852;&#31995;&#26469;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#36890;&#24120;&#24341;&#20837;&#22797;&#26434;&#30340;&#27169;&#22411;&#32467;&#26500;&#21644;&#26356;&#22810;&#30340;&#21442;&#25968;&#26469;&#24314;&#27169;&#22810;&#31181;&#34892;&#20026;&#65292;&#20174;&#32780;&#22823;&#24133;&#22686;&#21152;&#20102;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-behavior recommendation exploits multiple types of user-item interactions to alleviate the data sparsity problem faced by the traditional models that often utilize only one type of interaction for recommendation. In real scenarios, users often take a sequence of actions to interact with an item, in order to get more information about the item and thus accurately evaluate whether an item fits personal preference. Those interaction behaviors often obey a certain order, and different behaviors reveal different information or aspects of user preferences towards the target item. Most existing multi-behavior recommendation methods take the strategy to first extract information from different behaviors separately and then fuse them for final prediction. However, they have not exploited the connections between different behaviors to learn user preferences. Besides, they often introduce complex model structures and more parameters to model multiple behaviors, largely increasing the space 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24352;&#37327;&#20998;&#35299;&#26469;&#23454;&#29616;&#19968;&#33268;&#21327;&#21516;&#36807;&#28388;&#30340;&#26032;&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#25193;&#23637;&#20256;&#32479;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20559;&#22909;&#35745;&#31639;&#26041;&#27861;&#65292;&#20351;&#24471;&#22312;&#35780;&#20272;&#29289;&#21697;&#30456;&#23545;&#20559;&#22909;&#26102;&#20135;&#29983;&#29289;&#21697;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#38750;&#32447;&#24615;&#24577;&#24230;&#12290;</title><link>http://arxiv.org/abs/2201.11936</link><description>&lt;p&gt;
&#36890;&#36807;&#24352;&#37327;&#20998;&#35299;&#23454;&#29616;&#19968;&#33268;&#30340;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
Consistent Collaborative Filtering via Tensor Decomposition. (arXiv:2201.11936v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.11936
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24352;&#37327;&#20998;&#35299;&#26469;&#23454;&#29616;&#19968;&#33268;&#21327;&#21516;&#36807;&#28388;&#30340;&#26032;&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#25193;&#23637;&#20256;&#32479;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20559;&#22909;&#35745;&#31639;&#26041;&#27861;&#65292;&#20351;&#24471;&#22312;&#35780;&#20272;&#29289;&#21697;&#30456;&#23545;&#20559;&#22909;&#26102;&#20135;&#29983;&#29289;&#21697;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#38750;&#32447;&#24615;&#24577;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#26159;&#20998;&#26512;&#29992;&#25143;&#27963;&#21160;&#21644;&#26500;&#24314;&#29289;&#21697;&#25512;&#33616;&#31995;&#32479;&#30340;&#20107;&#23454;&#26631;&#20934;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38544;&#24335;&#21453;&#39304;&#30340;&#21327;&#21516;&#36807;&#28388;&#26032;&#27169;&#22411;&#8212;&#8212;&#20999;&#21106;&#21453;&#23545;&#31216;&#20998;&#35299;&#65288;SAD&#65289;&#12290;&#19982;&#20256;&#32479;&#25216;&#26415;&#19981;&#21516;&#65292;SAD&#36890;&#36807;&#23545;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30340;&#26032;&#39062;&#19977;&#32500;&#24352;&#37327;&#35270;&#22270;&#24341;&#20837;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#29289;&#21697;&#30340;&#38544;&#21547;&#21521;&#37327;&#12290;&#35813;&#21521;&#37327;&#23558;&#36890;&#36807;&#26631;&#20934;&#28857;&#20056;&#35745;&#31639;&#20986;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20559;&#22909;&#25193;&#23637;&#21040;&#19968;&#33324;&#20869;&#31215;&#65292;&#20174;&#32780;&#22312;&#35780;&#20272;&#29289;&#21697;&#30340;&#30456;&#23545;&#20559;&#22909;&#26102;&#20135;&#29983;&#29289;&#21697;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#24403;&#21521;&#37327;&#25240;&#21472;&#20026;1&#26102;&#65292;SAD&#38477;&#20026;&#26368;&#20808;&#36827;&#30340;&#21327;&#21516;&#36807;&#28388;&#27169;&#22411;&#65288;SOTA&#65289;&#65292;&#32780;&#26412;&#25991;&#20801;&#35768;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#20854;&#20540;&#12290;&#20801;&#35768;&#26032;&#29289;&#21697;&#21521;&#37327;&#30340;&#20540;&#19982;1&#19981;&#21516;&#20855;&#26377;&#28145;&#36828;&#30340;&#24433;&#21709;&#12290;&#36825;&#34920;&#26126;&#29992;&#25143;&#21487;&#33021;&#20855;&#26377;&#38750;&#32447;&#24615;&#24577;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative filtering is the de facto standard for analyzing users' activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlin
&lt;/p&gt;</description></item></channel></rss>