<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#23545;&#35810;&#38382;&#28548;&#28165;&#38382;&#39064;&#65288;ACQ&#65289;&#30340;&#30456;&#20851;&#30740;&#31350;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#20102;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#30340;&#35814;&#32454;&#27604;&#36739;&#21644;&#22810;&#20010;ACQ&#30456;&#20851;&#20219;&#21153;&#30340;&#22522;&#20934;&#65292;&#26088;&#22312;&#21327;&#21161;ACQ&#25216;&#26415;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2305.15933</link><description>&lt;p&gt;
&#23545;&#35805;&#31995;&#32479;&#20013;&#35810;&#38382;&#28548;&#28165;&#38382;&#39064;&#25968;&#25454;&#38598;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Asking Clarification Questions Datasets in Conversational Systems. (arXiv:2305.15933v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15933
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#35810;&#38382;&#28548;&#28165;&#38382;&#39064;&#65288;ACQ&#65289;&#30340;&#30456;&#20851;&#30740;&#31350;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#20102;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#30340;&#35814;&#32454;&#27604;&#36739;&#21644;&#22810;&#20010;ACQ&#30456;&#20851;&#20219;&#21153;&#30340;&#22522;&#20934;&#65292;&#26088;&#22312;&#21327;&#21161;ACQ&#25216;&#26415;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#29992;&#25143;&#30495;&#23454;&#38656;&#27714;&#23545;&#20110;&#23545;&#35805;&#31995;&#32479;&#23588;&#20026;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#23545;&#35805;&#20013;&#29992;&#25143;&#25552;&#20379;&#30340;&#20449;&#24687;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#26679;&#30340;&#39046;&#22495;&#20013;&#65292;&#35810;&#38382;&#28548;&#28165;&#38382;&#39064;&#65288;ACQ&#65289;&#20197;&#25581;&#31034;&#29992;&#25143;&#24847;&#22270;&#20026;&#20851;&#38190;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;ACQ&#30740;&#31350;&#30340;&#20851;&#38190;&#38480;&#21046;&#26159;&#23427;&#20204;&#30340;&#19981;&#21487;&#27604;&#24615;&#65292;&#26469;&#33258;&#25968;&#25454;&#30340;&#19981;&#19968;&#33268;&#20351;&#29992;&#65292;&#19981;&#21516;&#30340;&#23454;&#39564;&#35774;&#32622;&#21644;&#35780;&#20272;&#31574;&#30053;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#20026;&#21327;&#21161;ACQ&#25216;&#26415;&#30340;&#21457;&#23637;&#65292;&#20840;&#38754;&#20998;&#26512;&#20102;&#24403;&#21069;ACQ&#30740;&#31350;&#29366;&#24577;&#65292;&#25552;&#20379;&#20102;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#30340;&#35814;&#32454;&#27604;&#36739;&#65292;&#24182;&#35752;&#35770;&#20102;&#24212;&#29992;&#35780;&#20272;&#25351;&#26631;&#20197;&#21450;&#22810;&#20010;&#19982;ACQ&#30456;&#20851;&#20219;&#21153;&#30340;&#22522;&#20934;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#23545;ACQ&#20219;&#21153;&#36827;&#34892;&#24443;&#24213;&#20998;&#26512;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19968;&#20123;&#30456;&#24212;&#30340;&#30740;&#31350;&#26041;&#21521;&#65292;&#20197;&#35843;&#26597;ACQ&#20197;&#21450;&#23545;&#35805;&#31995;&#32479;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to understand a user's underlying needs is critical for conversational systems, especially with limited input from users in a conversation. Thus, in such a domain, Asking Clarification Questions (ACQs) to reveal users' true intent from their queries or utterances arise as an essential task. However, it is noticeable that a key limitation of the existing ACQs studies is their incomparability, from inconsistent use of data, distinct experimental setups and evaluation strategies. Therefore, in this paper, to assist the development of ACQs techniques, we comprehensively analyse the current ACQs research status, which offers a detailed comparison of publicly available datasets, and discusses the applied evaluation metrics, joined with benchmarks for multiple ACQs-related tasks. In particular, given a thorough analysis of the ACQs task, we discuss a number of corresponding research directions for the investigation of ACQs as well as the development of conversational systems.
&lt;/p&gt;</description></item><item><title>&#20026;&#20102;&#35299;&#20915;&#31232;&#30095;&#26631;&#27880;&#22312;&#31264;&#23494;&#26816;&#32034;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#35777;&#25454;&#30340;&#26631;&#31614;&#24179;&#28369;&#26041;&#27861;&#65292;&#24182;&#19988;&#24341;&#20837;&#20102;&#36870;&#21521;&#26368;&#36817;&#37051;&#30456;&#20284;&#24230;&#24230;&#37327;&#26041;&#27861;&#26469;&#25552;&#39640;&#30456;&#20851;&#24615;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15720</link><description>&lt;p&gt;
&#36890;&#36807;&#36870;&#21521;&#26368;&#36817;&#37051;&#25552;&#21319;&#31264;&#23494;&#26816;&#32034;&#26041;&#27861;&#30340;&#25490;&#21517;&#19978;&#19979;&#25991;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;
Enhancing the Ranking Context of Dense Retrieval Methods through Reciprocal Nearest Neighbors. (arXiv:2305.15720v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15720
&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#20915;&#31232;&#30095;&#26631;&#27880;&#22312;&#31264;&#23494;&#26816;&#32034;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#35777;&#25454;&#30340;&#26631;&#31614;&#24179;&#28369;&#26041;&#27861;&#65292;&#24182;&#19988;&#24341;&#20837;&#20102;&#36870;&#21521;&#26368;&#36817;&#37051;&#30456;&#20284;&#24230;&#24230;&#37327;&#26041;&#27861;&#26469;&#25552;&#39640;&#30456;&#20851;&#24615;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#26631;&#27880;&#32473;&#31264;&#23494;&#26816;&#32034;&#27169;&#22411;&#35757;&#32451;&#24102;&#26469;&#20102;&#25345;&#20037;&#30340;&#25361;&#25112;&#65292;&#20363;&#22914;&#34394;&#20551;&#36127;&#26679;&#26412;&#38382;&#39064;&#65292;&#21363;&#26410;&#26631;&#35760;&#30340;&#30456;&#20851;&#25991;&#26723;&#34987;&#38169;&#35823;&#22320;&#29992;&#20316;&#36127;&#26679;&#26412;&#65292;&#25197;&#26354;&#20102;&#35757;&#32451;&#20449;&#21495;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#35777;&#25454;&#30340;&#26631;&#31614;&#24179;&#28369;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#36991;&#20813;&#24809;&#32602;&#27169;&#22411;&#23558;&#39640;&#30456;&#20851;&#24615;&#36171;&#20104;&#34394;&#20551;&#36127;&#26679;&#26412;&#12290;&#20026;&#20102;&#22312;&#32473;&#23450;&#26597;&#35810;&#30340;&#25490;&#21517;&#19978;&#19979;&#25991;&#20013;&#35745;&#31639;&#20505;&#36873;&#25991;&#26723;&#30340;&#30446;&#26631;&#30456;&#20851;&#24615;&#20998;&#24067;&#65292;&#19982;&#22522;&#26412;&#20107;&#23454;&#26368;&#30456;&#20284;&#30340;&#20505;&#36873;&#32773;&#34987;&#36171;&#20104;&#38750;&#38646;&#30456;&#20851;&#27010;&#29575;&#65292;&#35813;&#27010;&#29575;&#22522;&#20110;&#23427;&#20204;&#19982;&#22522;&#26412;&#20107;&#23454;&#25991;&#26723;&#30340;&#30456;&#20284;&#24230;&#31243;&#24230;&#12290;&#20316;&#20026;&#30456;&#20851;&#24615;&#20272;&#35745;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#19968;&#31181;&#22522;&#20110;&#36870;&#21521;&#26368;&#36817;&#37051;&#30340;&#25913;&#36827;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#35813;&#24230;&#37327;&#36824;&#21487;&#21333;&#29420;&#29992;&#20110;&#21518;&#22788;&#29702;&#20013;&#37325;&#26032;&#25490;&#21517;&#20505;&#36873;&#32773;&#12290;&#36890;&#36807;&#22312;&#20004;&#20010;&#22823;&#35268;&#27169;&#30340;&#33258;&#36866;&#24212;&#25991;&#26412;&#26816;&#32034;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26412;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse annotation poses persistent challenges to training dense retrieval models, such as the problem of false negatives, i.e. unlabeled relevant documents that are spuriously used as negatives in contrastive learning, distorting the training signal. To alleviate this problem, we introduce evidence-based label smoothing, a computationally efficient method that prevents penalizing the model for assigning high relevance to false negatives. To compute the target relevance distribution over candidate documents within the ranking context of a given query, candidates most similar to the ground truth are assigned a non-zero relevance probability based on the degree of their similarity to the ground-truth document(s). As a relevance estimate we leverage an improved similarity metric based on reciprocal nearest neighbors, which can also be used independently to rerank candidates in post-processing. Through extensive experiments on two large-scale ad hoc text retrieval datasets we demonstrate th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#29992;&#22270;&#20070;&#25512;&#33616;&#26694;&#26550;BookGPT&#65292;&#36890;&#36807;&#23558;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#21464;&#25442;&#22120;&#25216;&#26415;&#24212;&#29992;&#20110;&#22270;&#20070;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#19977;&#31181;&#20219;&#21153;&#65292;&#21363;&#22270;&#20070;&#35780;&#20998;&#25512;&#33616;&#12289;&#29992;&#25143;&#35780;&#20998;&#25512;&#33616;&#21644;&#22270;&#20070;&#25688;&#35201;&#25512;&#33616;&#65292;&#23454;&#29616;&#20102;&#23545;&#22270;&#20070;&#25512;&#33616;&#30340;&#26377;&#21147;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2305.15673</link><description>&lt;p&gt;
BookGPT&#65306;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#29992;&#22270;&#20070;&#25512;&#33616;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
BookGPT: A General Framework for Book Recommendation Empowered by Large Language Model. (arXiv:2305.15673v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#29992;&#22270;&#20070;&#25512;&#33616;&#26694;&#26550;BookGPT&#65292;&#36890;&#36807;&#23558;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#21464;&#25442;&#22120;&#25216;&#26415;&#24212;&#29992;&#20110;&#22270;&#20070;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#19977;&#31181;&#20219;&#21153;&#65292;&#21363;&#22270;&#20070;&#35780;&#20998;&#25512;&#33616;&#12289;&#29992;&#25143;&#35780;&#20998;&#25512;&#33616;&#21644;&#22270;&#20070;&#25688;&#35201;&#25512;&#33616;&#65292;&#23454;&#29616;&#20102;&#23545;&#22270;&#20070;&#25512;&#33616;&#30340;&#26377;&#21147;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#21464;&#25442;&#22120;&#65288;GPT&#65289;&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25216;&#26415;&#30340;&#19981;&#26029;&#21457;&#23637;&#21644;&#21464;&#21270;&#65292;&#21508;&#20010;&#39046;&#22495;&#30340;&#35768;&#22810;&#32463;&#20856;&#22330;&#26223;&#37325;&#26032;&#23637;&#29616;&#20986;&#26032;&#30340;&#26426;&#36935;&#12290;&#26412;&#25991;&#23558;ChatGPT&#20316;&#20026;&#24314;&#27169;&#23545;&#35937;&#65292;&#39318;&#27425;&#23558;LLM&#25216;&#26415;&#24182;&#20837;&#20256;&#32479;&#30340;&#22270;&#20070;&#36164;&#28304;&#29702;&#35299;&#21644;&#25512;&#33616;&#22330;&#26223;&#20013;&#65292;&#24182;&#20184;&#35832;&#23454;&#36341;&#12290;&#26412;&#25991;&#22522;&#20110;ChatGPT&#26500;&#24314;&#20102;&#31867;&#20284;&#20110;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#22270;&#20070;&#25512;&#33616;&#31995;&#32479;&#26694;&#26550;&#65288;BookGPT&#65289;&#65292;&#35797;&#22270;&#23558;ChatGPT&#24212;&#29992;&#20110;&#19977;&#31181;&#20856;&#22411;&#20219;&#21153;&#30340;&#25512;&#33616;&#24314;&#27169;&#65306;&#22270;&#20070;&#35780;&#20998;&#25512;&#33616;&#65292;&#29992;&#25143;&#35780;&#20998;&#25512;&#33616;&#21644;&#22270;&#20070;&#25688;&#35201;&#25512;&#33616;&#65292;&#25506;&#32034;LLM&#25216;&#26415;&#22312;&#22270;&#20070;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#21487;&#34892;&#24615;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#26681;&#25454;&#19981;&#21516;&#30340;&#22270;&#20070;&#25512;&#33616;&#20219;&#21153;&#35780;&#20272;&#26041;&#26696;&#21644;&#29616;&#26377;&#30340;&#32463;&#20856;&#25512;&#33616;&#27169;&#22411;&#65292;&#35752;&#35770;&#20102;BookGPT&#22312;&#22270;&#20070;&#25512;&#33616;&#22330;&#26223;&#19979;&#30340;&#20248;&#32570;&#28857;&#65292;&#24182;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#23454;&#35777;&#27604;&#36739;&#21644;&#20998;&#26512;&#65292;&#35777;&#26126;&#22522;&#20110;LLM&#25216;&#26415;&#30340;BookGPT&#26694;&#26550;&#21487;&#20197;&#20026;&#22270;&#20070;&#25512;&#33616;&#39046;&#22495;&#24102;&#26469;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the continuous development and change exhibited by large language model (LLM) technology, represented by generative pretrained transformers (GPTs), many classic scenarios in various fields have re-emerged with new opportunities. This paper takes ChatGPT as the modeling object, incorporates LLM technology into the typical book resource understanding and recommendation scenario for the first time, and puts it into practice. By building a ChatGPT-like book recommendation system (BookGPT) framework based on ChatGPT, this paper attempts to apply ChatGPT to recommendation modeling for three typical tasks, book rating recommendation, user rating recommendation, and book summary recommendation, and explores the feasibility of LLM technology in book recommendation scenarios. At the same time, based on different evaluation schemes for book recommendation tasks and the existing classic recommendation models, this paper discusses the advantages and disadvantages of the BookGPT in book recomme
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#20250;&#35805;&#25628;&#32034;&#30340;ConvGQR&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#37325;&#26032;&#26500;&#36896;&#26597;&#35810;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2305.15645</link><description>&lt;p&gt;
ConvGQR&#65306;&#38754;&#21521;&#20250;&#35805;&#25628;&#32034;&#30340;&#29983;&#25104;&#24335;&#26597;&#35810;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
ConvGQR: Generative Query Reformulation for Conversational Search. (arXiv:2305.15645v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15645
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#20250;&#35805;&#25628;&#32034;&#30340;ConvGQR&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#37325;&#26032;&#26500;&#36896;&#26597;&#35810;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20250;&#35805;&#25628;&#32034;&#20013;&#65292;&#29992;&#25143;&#24403;&#21069;&#25628;&#32034;&#24847;&#22270;&#20381;&#36182;&#20110;&#20808;&#21069;&#30340;&#23545;&#35805;&#21382;&#21490;&#12290;&#20174;&#25972;&#20010;&#23545;&#35805;&#19978;&#19979;&#25991;&#20013;&#30830;&#23450;&#19968;&#20010;&#33391;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#36991;&#20813;&#26597;&#35810;&#32534;&#30721;&#22120;&#30340;&#26114;&#36149;&#37325;&#26032;&#35757;&#32451;&#65292;&#22823;&#37096;&#20998;&#29616;&#26377;&#26041;&#27861;&#23581;&#35797;&#23398;&#20064;&#19968;&#20010;&#37325;&#20889;&#27169;&#22411;&#65292;&#36890;&#36807;&#27169;&#20223;&#25163;&#21160;&#26597;&#35810;&#37325;&#20889;&#26469;&#21435;&#38500;&#24403;&#21069;&#26597;&#35810;&#30340;&#19978;&#19979;&#25991;&#12290;&#28982;&#32780;&#65292;&#25163;&#21160;&#37325;&#20889;&#30340;&#26597;&#35810;&#24182;&#19981;&#24635;&#26159;&#26368;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#12290;&#35757;&#32451;&#37325;&#20889;&#27169;&#22411;&#20250;&#38480;&#21046;&#27169;&#22411;&#20135;&#29983;&#33391;&#22909;&#25628;&#32034;&#26597;&#35810;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;ConvGQR&#65292;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM&#65289;&#65292;&#19968;&#20010;&#29992;&#20110;&#26597;&#35810;&#37325;&#20889;&#65292;&#21478;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#28508;&#22312;&#31572;&#26696;&#65292;&#20197;&#37325;&#26032;&#26500;&#36896;&#20250;&#35805;&#26597;&#35810;&#12290;&#36890;&#36807;&#32467;&#21512;&#20004;&#32773;&#65292;ConvGQR&#21487;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#23558;&#26597;&#35810;&#37325;&#26500;&#19982;&#26816;&#32034;&#24615;&#33021;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#24449;&#36873;&#25321;&#30340;&#30456;&#20284;&#24230;&#20998;&#25968;&#27169;&#22411;&#65292;&#29992;&#20110;&#39564;&#35777;ConvGQR&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In conversational search, the user's real search intent for the current turn is dependent on the previous conversation history. It is challenging to determine a good search query from the whole conversation context. To avoid the expensive re-training of the query encoder, most existing methods try to learn a rewriting model to de-contextualize the current query by mimicking the manual query rewriting. However, manually rewritten queries are not always the best search queries. Training a rewriting model on them would limit the model's ability to produce good search queries. Another useful hint is the potential answer to the question. In this paper, we propose ConvGQR, a new framework to reformulate conversational queries based on generative pre-trained language models (PLMs), one for query rewriting and another for generating potential answers. By combining both, ConvGQR can produce better search queries. In addition, to relate query reformulation to retrieval performance, we propose a 
&lt;/p&gt;</description></item><item><title>TAGREAL&#26159;&#19968;&#31181;&#21487;&#33258;&#21160;&#29983;&#25104;&#39640;&#36136;&#37327;&#26597;&#35810;&#25552;&#31034;&#20449;&#24687;&#65292;&#20174;&#22823;&#22411;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#25903;&#25345;&#20449;&#24687;&#20197;&#20174;PLM&#20013;&#25506;&#27979;&#30693;&#35782;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24320;&#25918;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#20013;&#65292;&#22312;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#34920;&#29616;&#65292;&#24182;&#19988;&#21363;&#20351;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#20855;&#26377;&#31361;&#20986;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15597</link><description>&lt;p&gt;
&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#22686;&#24378;&#24320;&#25918;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Text-Augmented Open Knowledge Graph Completion via Pre-Trained Language Models. (arXiv:2305.15597v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15597
&lt;/p&gt;
&lt;p&gt;
TAGREAL&#26159;&#19968;&#31181;&#21487;&#33258;&#21160;&#29983;&#25104;&#39640;&#36136;&#37327;&#26597;&#35810;&#25552;&#31034;&#20449;&#24687;&#65292;&#20174;&#22823;&#22411;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#25903;&#25345;&#20449;&#24687;&#20197;&#20174;PLM&#20013;&#25506;&#27979;&#30693;&#35782;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24320;&#25918;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#20013;&#65292;&#22312;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#34920;&#29616;&#65292;&#24182;&#19988;&#21363;&#20351;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#20855;&#26377;&#31361;&#20986;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#25918;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#30340;&#20219;&#21153;&#26159;&#20174;&#24050;&#30693;&#20107;&#23454;&#20013;&#25552;&#21462;&#26032;&#30340;&#21457;&#29616;&#12290;&#29616;&#26377;&#30340;&#22686;&#24378;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#30340;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#20107;&#23454;&#19977;&#20803;&#32452;&#20197;&#25193;&#22823;&#22270;&#25512;&#29702;&#31354;&#38388;&#65292;&#35201;&#20040;&#38656;&#35201;&#25163;&#21160;&#35774;&#35745;&#25552;&#31034;&#20449;&#24687;&#20197;&#20174;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#25552;&#21462;&#30693;&#35782;&#65292;&#36825;&#20123;&#26041;&#27861;&#24615;&#33021;&#26377;&#38480;&#65292;&#38656;&#35201;&#19987;&#23478;&#26114;&#36149;&#30340;&#24037;&#20316;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TAGREAL&#65292;&#23427;&#33258;&#21160;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26597;&#35810;&#25552;&#31034;&#20449;&#24687;&#65292;&#24182;&#20174;&#22823;&#22411;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#25903;&#25345;&#20449;&#24687;&#20197;&#20174;PLM&#20013;&#25506;&#27979;&#30693;&#35782;&#20197;&#23436;&#25104;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;TAGREAL&#22312;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21363;&#20351;&#26159;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;TAGREAL&#30340;&#24615;&#33021;&#20173;&#28982;&#38750;&#24120;&#31361;&#20986;&#65292;&#36229;&#36807;&#20102;&#29616;&#26377;&#30340;&#22522;&#20110;&#23884;&#20837;&#12289;&#22522;&#20110;&#22270;&#21644;&#22522;&#20110;PLM&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The mission of open knowledge graph (KG) completion is to draw new findings from known facts. Existing works that augment KG completion require either (1) factual triples to enlarge the graph reasoning space or (2) manually designed prompts to extract knowledge from a pre-trained language model (PLM), exhibiting limited performance and requiring expensive efforts from experts. To this end, we propose TAGREAL that automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion. The results show that TAGREAL achieves state-of-the-art performance on two benchmark datasets. We find that TAGREAL has superb performance even with limited training data, outperforming existing embedding-based, graph-based, and PLM-based methods.
&lt;/p&gt;</description></item><item><title>&#20026;&#20102;&#25913;&#21892;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20195;&#34920;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#22810;&#26679;&#21270;&#26041;&#27861;&#65292;&#24182;&#22312;Pinterest&#24179;&#21488;&#19978;&#23454;&#39564;&#21644;&#37096;&#32626;&#20102;&#21487;&#25193;&#23637;&#30340;&#22810;&#26679;&#21270;&#26426;&#21046;&#65292;&#20197;&#25913;&#21892;&#32654;&#23481;&#21644;&#26102;&#23578;&#31867;&#21035;&#20013;&#19981;&#21516;&#32932;&#33394;&#30340;&#20195;&#34920;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15534</link><description>&lt;p&gt;
&#22312;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#22312;&#32447;&#34920;&#31034;&#24456;&#37325;&#35201;&#65306;&#23454;&#29992;&#30340;&#31471;&#21040;&#31471;&#22810;&#26679;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation Online Matters: Practical End-to-End Diversification in Search and Recommender Systems. (arXiv:2305.15534v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15534
&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25913;&#21892;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20195;&#34920;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#22810;&#26679;&#21270;&#26041;&#27861;&#65292;&#24182;&#22312;Pinterest&#24179;&#21488;&#19978;&#23454;&#39564;&#21644;&#37096;&#32626;&#20102;&#21487;&#25193;&#23637;&#30340;&#22810;&#26679;&#21270;&#26426;&#21046;&#65292;&#20197;&#25913;&#21892;&#32654;&#23481;&#21644;&#26102;&#23578;&#31867;&#21035;&#20013;&#19981;&#21516;&#32932;&#33394;&#30340;&#20195;&#34920;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22312;&#32447;&#24179;&#21488;&#22312;&#21508;&#20010;&#20154;&#21475;&#32479;&#35745;&#23398;&#20013;&#30340;&#20351;&#29992;&#19981;&#26029;&#22686;&#38271;&#65292;&#29992;&#25143;&#32463;&#24120;&#34920;&#36798;&#24076;&#26395;&#22312;&#20869;&#23481;&#20013;&#24863;&#21463;&#21040;&#33258;&#24049;&#30340;&#20195;&#34920;&#24615;&#12290;&#20026;&#20102;&#25913;&#21892;&#25628;&#32034;&#32467;&#26524;&#21644;&#25512;&#33616;&#20013;&#30340;&#20195;&#34920;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31471;&#21040;&#31471;&#30340;&#22810;&#26679;&#21270;&#26041;&#27861;&#65292;&#30830;&#20445;&#22810;&#26679;&#21270;&#20869;&#23481;&#22312;&#36825;&#20123;&#31995;&#32479;&#30340;&#21508;&#20010;&#38454;&#27573;&#20013;&#27969;&#21160;&#65292;&#20174;&#26816;&#32034;&#21040;&#25490;&#24207;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;Pinterest&#24179;&#21488;&#30340;&#29983;&#20135;&#30028;&#38754;&#20013;&#24320;&#21457;&#12289;&#23454;&#39564;&#21644;&#37096;&#32626;&#21487;&#25193;&#23637;&#30340;&#22810;&#26679;&#21270;&#26426;&#21046;&#65292;&#21253;&#25324;&#25628;&#32034;&#12289;&#30456;&#20851;&#20135;&#21697;&#21644;&#26032;&#29992;&#25143;&#20027;&#39029;&#65292;&#20197;&#25913;&#21892;&#32654;&#23481;&#21644;&#26102;&#23578;&#20869;&#23481;&#20013;&#19981;&#21516;&#32932;&#33394;&#30340;&#20195;&#34920;&#24615;&#12290;&#29983;&#20135;&#31995;&#32479;&#20013;&#30340;&#22810;&#26679;&#21270;&#21253;&#25324;&#19977;&#20010;&#32452;&#25104;&#37096;&#20998;&#65306;&#30830;&#23450;&#20250;&#35302;&#21457;&#22810;&#26679;&#21270;&#30340;&#35831;&#27714;&#65292;&#22312;&#26816;&#32034;&#38454;&#27573;&#30830;&#20445;&#20174;&#22823;&#22411;&#20869;&#23481;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#21040;&#22810;&#26679;&#21270;&#30340;&#20869;&#23481;&#65292;&#26368;&#21518;&#65292;&#22312;&#25490;&#21517;&#38454;&#27573;&#20197;&#33258;&#25105;&#35843;&#25972;&#30340;&#26041;&#24335;&#24179;&#34913;&#22810;&#26679;&#24615;&#21644;&#25928;&#29992;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20174;&#20351;&#29992;Strong-O&#24320;&#22987;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the use of online platforms continues to grow across all demographics, users often express a desire to feel represented in the content. To improve representation in search results and recommendations, we introduce end-to-end diversification, ensuring that diverse content flows throughout the various stages of these systems, from retrieval to ranking. We develop, experiment, and deploy scalable diversification mechanisms in multiple production surfaces on the Pinterest platform, including Search, Related Products, and New User Homefeed, to improve the representation of different skin tones in beauty and fashion content. Diversification in production systems includes three components: identifying requests that will trigger diversification, ensuring diverse content is retrieved from the large content corpus during the retrieval stage, and finally, balancing the diversity-utility trade-off in a self-adjusting manner in the ranking stage. Our approaches, which evolved from using Strong-O
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23545;&#29992;&#25143;&#20852;&#36259;&#36827;&#34892;&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#20852;&#36259;&#26053;&#31243;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#26088;&#22312;&#25552;&#39640;&#25512;&#33616;&#30340;&#36136;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#26032;&#39062;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15498</link><description>&lt;p&gt;
&#29992;&#25143;&#20852;&#36259;&#26053;&#31243;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large Language Models for User Interest Journeys. (arXiv:2305.15498v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15498
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23545;&#29992;&#25143;&#20852;&#36259;&#36827;&#34892;&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#20852;&#36259;&#26053;&#31243;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#26088;&#22312;&#25552;&#39640;&#25512;&#33616;&#30340;&#36136;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#26032;&#39062;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#23637;&#31034;&#20986;&#22312;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#30340;&#20196;&#20154;&#30633;&#30446;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#29992;&#25143;&#21644;&#25913;&#21892;&#20010;&#24615;&#21270;&#25512;&#33616;&#24179;&#21488;&#20307;&#39564;&#26041;&#38754;&#30340;&#28508;&#21147;&#36824;&#36828;&#26410;&#34987;&#21457;&#25381;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;LLMs&#23545;&#29992;&#25143;&#20852;&#36259;&#36827;&#34892;&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#24182;&#23450;&#20041;&#20102;&#20852;&#36259;&#26053;&#31243;&#20316;&#20026;&#29992;&#25143;&#22522;&#20110;&#20182;&#20204;&#30340;&#27963;&#21160;&#32780;&#36941;&#21382;&#36807;&#30340;&#20852;&#36259;&#29366;&#24577;&#24207;&#21015;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#29992;&#25143;&#34920;&#31034;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#25512;&#33616;&#30340;&#36136;&#37327;&#65292;&#24182;&#19988;&#29983;&#25104;&#30340;&#20852;&#36259;&#26053;&#31243;&#20026;&#25512;&#33616;&#36807;&#31243;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#26032;&#39062;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have shown impressive capabilities in natural language understanding and generation. Their potential for deeper user understanding and improved personalized user experience on recommendation platforms is, however, largely untapped. This paper aims to address this gap. Recommender systems today capture users' interests through encoding their historical activities on the platforms. The generated user representations are hard to examine or interpret. On the other hand, if we were to ask people about interests they pursue in their life, they might talk about their hobbies, like I just started learning the ukulele, or their relaxation routines, e.g., I like to watch Saturday Night Live, or I want to plant a vertical garden. We argue, and demonstrate through extensive experiments, that LLMs as foundation models can reason through user activities, and describe their interests in nuanced and interesting ways, similar to how a human would.  We define interest journe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32858;&#31867;&#21644;&#36801;&#31227;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#24456;&#22909;&#22320;&#24212;&#23545;&#20102;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#22522;&#20934;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.15431</link><description>&lt;p&gt;
&#25506;&#32034;&#21644;&#21033;&#29992;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;
&lt;/p&gt;
&lt;p&gt;
Exploring and Exploiting Data Heterogeneity in Recommendation. (arXiv:2305.15431v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15431
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32858;&#31867;&#21644;&#36801;&#31227;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#24456;&#22909;&#22320;&#24212;&#23545;&#20102;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#37327;&#30340;&#25968;&#25454;&#26159;&#25968;&#25454;&#39537;&#21160;&#25512;&#33616;&#27169;&#22411;&#30340;&#22522;&#30784;&#12290;&#25968;&#25454;&#24322;&#36136;&#24615;&#26159;&#22823;&#25968;&#25454;&#30340;&#20869;&#22312;&#29305;&#24615;&#65292;&#22312;&#29616;&#23454;&#25512;&#33616;&#31995;&#32479;&#20013;&#24191;&#27867;&#23384;&#22312;&#12290;&#23427;&#21453;&#26144;&#20102;&#23376;&#20154;&#21475;&#32676;&#20307;&#20043;&#38388;&#23646;&#24615;&#30340;&#24046;&#24322;&#12290;&#24573;&#30053;&#25512;&#33616;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#21487;&#33021;&#20250;&#38480;&#21046;&#25512;&#33616;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#25439;&#23475;&#23376;&#20154;&#21475;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#20351;&#27169;&#22411;&#35823;&#23548;&#25968;&#25454;&#20559;&#35265;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#24322;&#36136;&#24615;&#22312;&#25512;&#33616;&#30028;&#24182;&#27809;&#26377;&#21463;&#21040;&#36275;&#22815;&#30340;&#20851;&#27880;&#12290;&#22240;&#27492;&#65292;&#23427;&#28608;&#21457;&#25105;&#20204;&#20805;&#20998;&#25506;&#32034;&#21644;&#21033;&#29992;&#24322;&#36136;&#24615;&#26469;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#24182;&#36741;&#21161;&#25968;&#25454;&#20998;&#26512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#25506;&#35752;&#20102;&#25512;&#33616;&#25968;&#25454;&#20013;&#20004;&#31867;&#20856;&#22411;&#30340;&#24322;&#36136;&#24615;&#65292;&#21363;&#39044;&#27979;&#26426;&#21046;&#21644;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#24322;&#36136;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21452;&#23618;&#32858;&#31867;&#26041;&#27861;&#25506;&#32034;&#24322;&#36136;&#24615;&#30340;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#36801;&#31227;&#23398;&#20064;&#26426;&#21046;&#21033;&#29992;&#20102;&#25366;&#25496;&#20986;&#26469;&#30340;&#24322;&#36136;&#24615;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Massive amounts of data are the foundation of data-driven recommendation models. As an inherent nature of big data, data heterogeneity widely exists in real-world recommendation systems. It reflects the differences in the properties among sub-populations. Ignoring the heterogeneity in recommendation data could limit the performance of recommendation models, hurt the sub-populational robustness, and make the models misled by biases. However, data heterogeneity has not attracted substantial attention in the recommendation community. Therefore, it inspires us to adequately explore and exploit heterogeneity for solving the above problems and assisting data analysis. In this work, we focus on exploring two representative categories of heterogeneity in recommendation data that is the heterogeneity of prediction mechanism and covariate distribution and propose an algorithm that explores the heterogeneity through a bilevel clustering method. Furthermore, the uncovered heterogeneity is exploite
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#39033;&#30446;&#30456;&#20851;&#24615;&#30340;&#26032;&#22411;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#65292;&#29992;&#20110;&#25552;&#39640;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#23545;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.10824</link><description>&lt;p&gt;
&#34701;&#21512;&#39033;&#30446;&#30456;&#20851;&#24615;&#30340;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Integrating Item Relevance in Training Loss for Sequential Recommender Systems. (arXiv:2305.10824v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#39033;&#30446;&#30456;&#20851;&#24615;&#30340;&#26032;&#22411;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#65292;&#29992;&#20110;&#25552;&#39640;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#23545;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#26159;&#19968;&#31181;&#21463;&#27426;&#36814;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#23427;&#36890;&#36807;&#23398;&#20064;&#29992;&#25143;&#30340;&#21382;&#21490;&#25968;&#25454;&#26469;&#39044;&#27979;&#29992;&#25143;&#19979;&#19968;&#20010;&#21487;&#33021;&#19982;&#20043;&#20132;&#20114;&#30340;&#39033;&#30446;&#12290;&#28982;&#32780;&#65292;&#29992;&#25143;&#30340;&#20132;&#20114;&#21487;&#33021;&#20250;&#21463;&#21040;&#26469;&#33258;&#24080;&#25143;&#20849;&#20139;&#12289;&#19981;&#19968;&#33268;&#30340;&#20559;&#22909;&#25110;&#24847;&#22806;&#28857;&#20987;&#31561;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#65288;i&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#32771;&#34385;&#22810;&#20010;&#26410;&#26469;&#39033;&#30446;&#30340;&#26032;&#30340;&#35780;&#20272;&#21327;&#35758;&#65292;&#65288;ii&#65289;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20851;&#27880;&#30456;&#20851;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#29992;&#20110;&#35757;&#32451;&#20855;&#26377;&#22810;&#20010;&#26410;&#26469;&#39033;&#30446;&#30340;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#20351;&#20854;&#23545;&#22122;&#22768;&#26356;&#21152;&#40065;&#26834;&#12290;&#25105;&#20204;&#30340;&#20851;&#27880;&#30456;&#20851;&#24615;&#27169;&#22411;&#22312;&#20256;&#32479;&#35780;&#20272;&#21327;&#35758;&#20013;&#25552;&#39640;&#20102;NDCG@10&#32422;1.2%&#21644;HR&#32422;0.88%&#65292;&#32780;&#22312;&#26032;&#35780;&#20272;&#21327;&#35758;&#20013;&#65292;&#25913;&#36827;&#30340;NDCG@10&#32422;1.63%&#21644;HR&#32422;1.5%&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential Recommender Systems (SRSs) are a popular type of recommender system that learns from a user's history to predict the next item they are likely to interact with. However, user interactions can be affected by noise stemming from account sharing, inconsistent preferences, or accidental clicks. To address this issue, we (i) propose a new evaluation protocol that takes multiple future items into account and (ii) introduce a novel relevance-aware loss function to train a SRS with multiple future items to make it more robust to noise. Our relevance-aware models obtain an improvement of ~1.2% of NDCG@10 and 0.88% in the traditional evaluation protocol, while in the new evaluation protocol, the improvement is ~1.63% of NDCG@10 and ~1.5% of HR w.r.t the best performing models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35299;&#32806;&#26041;&#27861;&#65292;&#23558;&#22797;&#26434;&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#24418;&#24335;&#21270;&#20026;&#19978;&#19979;&#25991;&#30693;&#35782;&#22270;&#25628;&#32034;&#21644;&#25277;&#35937;&#36923;&#36753;&#26597;&#35810;&#25512;&#29702;&#30340;&#32452;&#21512;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#23427;&#22312;&#22810;&#20010;&#36923;&#36753;&#26597;&#35810;&#32467;&#26500;&#30340;&#26631;&#20934;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#37117;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#26356;&#39640;&#22797;&#26434;&#24615;&#30340;&#26597;&#35810;&#20013;&#33719;&#24471;&#20102;&#26174;&#30528;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2305.01157</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#36827;&#34892;&#22797;&#26434;&#36923;&#36753;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Complex Logical Reasoning over Knowledge Graphs using Large Language Models. (arXiv:2305.01157v1 [cs.LO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35299;&#32806;&#26041;&#27861;&#65292;&#23558;&#22797;&#26434;&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#24418;&#24335;&#21270;&#20026;&#19978;&#19979;&#25991;&#30693;&#35782;&#22270;&#25628;&#32034;&#21644;&#25277;&#35937;&#36923;&#36753;&#26597;&#35810;&#25512;&#29702;&#30340;&#32452;&#21512;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#23427;&#22312;&#22810;&#20010;&#36923;&#36753;&#26597;&#35810;&#32467;&#26500;&#30340;&#26631;&#20934;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#37117;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#26356;&#39640;&#22797;&#26434;&#24615;&#30340;&#26597;&#35810;&#20013;&#33719;&#24471;&#20102;&#26174;&#30528;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#36827;&#34892;&#25512;&#29702;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#23427;&#38656;&#35201;&#23545;&#23454;&#20307;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#20197;&#21450;&#23427;&#20204;&#20043;&#38388;&#30340;&#22522;&#30784;&#36923;&#36753;&#36827;&#34892;&#28145;&#20837;&#29702;&#35299;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#23398;&#20064;&#20960;&#20309;&#26469;&#23884;&#20837;&#23454;&#20307;&#30340;&#21521;&#37327;&#31354;&#38388;&#36827;&#34892;&#36923;&#36753;&#26597;&#35810;&#25805;&#20316;&#65292;&#20294;&#26159;&#23427;&#20204;&#22312;&#22797;&#26434;&#26597;&#35810;&#21644;&#29305;&#23450;&#25968;&#25454;&#38598;&#34920;&#31034;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#32806;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#35821;&#35328;&#24341;&#23548;&#30340;&#30693;&#35782;&#22270;&#35889;&#25277;&#35937;&#25512;&#29702;&#65288;LARK&#65289;&#65292;&#23558;&#22797;&#26434;&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#24418;&#24335;&#21270;&#20026;&#19978;&#19979;&#25991;&#30693;&#35782;&#22270;&#25628;&#32034;&#21644;&#25277;&#35937;&#36923;&#36753;&#26597;&#35810;&#25512;&#29702;&#30340;&#32452;&#21512;&#65292;&#20197;&#20998;&#21035;&#21033;&#29992;&#22270;&#24418;&#25552;&#21462;&#31639;&#27861;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#36923;&#36753;&#26597;&#35810;&#32467;&#26500;&#30340;&#26631;&#20934;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#26041;&#27861;&#65292;&#22312;&#26356;&#39640;&#22797;&#26434;&#24615;&#30340;&#26597;&#35810;&#20013;&#33719;&#24471;&#20102;&#26174;&#30528;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reasoning over knowledge graphs (KGs) is a challenging task that requires a deep understanding of the complex relationships between entities and the underlying logic of their relations. Current approaches rely on learning geometries to embed entities in vector space for logical query operations, but they suffer from subpar performance on complex queries and dataset-specific representations. In this paper, we propose a novel decoupled approach, Language-guided Abstract Reasoning over Knowledge graphs (LARK), that formulates complex KG reasoning as a combination of contextual KG search and abstract logical query reasoning, to leverage the strengths of graph extraction algorithms and large language models (LLM), respectively. Our experiments demonstrate that the proposed approach outperforms state-of-the-art KG reasoning methods on standard benchmark datasets across several logical query constructs, with significant performance gain for queries of higher complexity. Furthermore, we show t
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#23558;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#30693;&#35782;&#20805;&#20998;&#24212;&#29992;&#20110;&#23494;&#38598;&#24335;&#27573;&#33853;&#26816;&#32034;&#65292;&#31216;&#20026;Aggretriever&#65292;&#36890;&#36807;&#23558;&#19978;&#19979;&#25991;&#21270;&#30340;token&#23884;&#20837;&#32858;&#21512;&#21040;&#23494;&#38598;&#21521;&#37327;&#20013;&#65292;&#30456;&#23545;&#20110;&#20197;&#21069;&#38656;&#35201;&#37319;&#29992;&#35745;&#31639;&#37327;&#26114;&#36149;&#30340;&#25216;&#26415;&#36827;&#34892;&#35757;&#32451;&#30340;DPR&#27169;&#22411;&#65292;Aggretriever&#19981;&#38656;&#24341;&#20837;&#23454;&#36136;&#24615;&#30340;&#35757;&#32451;&#24320;&#38144;&#65292;&#33021;&#26174;&#33879;&#25552;&#39640;&#22312;&#22495;&#20869;&#21644;&#38646;-shot&#35780;&#20272;&#20013;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2208.00511</link><description>&lt;p&gt;
Aggretriever&#65306;&#19968;&#31181;&#31616;&#21333;&#30340;&#32858;&#21512;&#25991;&#26412;&#34920;&#31034;&#26041;&#27861;&#65292;&#29992;&#20110;&#24378;&#22823;&#30340;&#23494;&#38598;&#24335;&#27573;&#33853;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Aggretriever: A Simple Approach to Aggregate Textual Representations for Robust Dense Passage Retrieval. (arXiv:2208.00511v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.00511
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#23558;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#30693;&#35782;&#20805;&#20998;&#24212;&#29992;&#20110;&#23494;&#38598;&#24335;&#27573;&#33853;&#26816;&#32034;&#65292;&#31216;&#20026;Aggretriever&#65292;&#36890;&#36807;&#23558;&#19978;&#19979;&#25991;&#21270;&#30340;token&#23884;&#20837;&#32858;&#21512;&#21040;&#23494;&#38598;&#21521;&#37327;&#20013;&#65292;&#30456;&#23545;&#20110;&#20197;&#21069;&#38656;&#35201;&#37319;&#29992;&#35745;&#31639;&#37327;&#26114;&#36149;&#30340;&#25216;&#26415;&#36827;&#34892;&#35757;&#32451;&#30340;DPR&#27169;&#22411;&#65292;Aggretriever&#19981;&#38656;&#24341;&#20837;&#23454;&#36136;&#24615;&#30340;&#35757;&#32451;&#24320;&#38144;&#65292;&#33021;&#26174;&#33879;&#25552;&#39640;&#22312;&#22495;&#20869;&#21644;&#38646;-shot&#35780;&#20272;&#20013;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#22312;&#24456;&#22810;&#30693;&#35782;&#23494;&#38598;&#22411;NLP&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;BERT&#36825;&#26679;&#30340;&#27169;&#22411;&#22312;&#23558;&#25991;&#26412;&#20449;&#24687;&#32858;&#21512;&#25104;[CLS]&#21521;&#37327;&#20197;&#36827;&#34892;&#23494;&#38598;&#24335;&#27573;&#33853;&#26816;&#32034;&#65288;DPR&#65289;&#26102;&#24182;&#19981;&#26159;&#8220;&#32467;&#26500;&#19978;&#20934;&#22791;&#22909;&#30340;&#8221;&#12290;&#36825;&#31181;&#8220;&#20934;&#22791;&#19981;&#36275;&#8221;&#26159;&#30001;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#21644;DPR&#24494;&#35843;&#20043;&#38388;&#30340;&#24046;&#36317;&#36896;&#25104;&#30340;&#12290;&#20197;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#35201;&#27714;&#20351;&#29992;&#35745;&#31639;&#37327;&#26114;&#36149;&#30340;&#25216;&#26415;&#65292;&#22914;&#30828;&#36127;&#37319;&#26679;&#12289;&#20132;&#21449;&#32534;&#30721;&#22120;&#33976;&#39311;&#21644;&#26356;&#36827;&#19968;&#27493;&#30340;&#39044;&#35757;&#32451;&#26469;&#23398;&#20064;&#24378;&#22823;&#30340;DPR&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#32858;&#21512;&#19978;&#19979;&#25991;&#21270;&#30340;token&#23884;&#20837;&#21040;&#19968;&#20010;&#23494;&#38598;&#21521;&#37327;&#20013;&#65292;&#20805;&#20998;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#22312;DPR&#20013;&#30340;&#30693;&#35782;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;agg*&#12290;&#36890;&#36807;&#23558;&#26469;&#33258;[CLS] token&#21644;agg*&#30340;&#21521;&#37327;&#36827;&#34892;&#20018;&#32852;&#65292;&#25105;&#20204;&#30340;Aggretriever&#27169;&#22411;&#22312;&#19981;&#24341;&#20837;&#23454;&#36136;&#24615;&#30340;&#35757;&#32451;&#24320;&#38144;&#30340;&#24773;&#20917;&#19979;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#23494;&#38598;&#24335;&#26816;&#32034;&#27169;&#22411;&#22312;&#22495;&#20869;&#21644;&#38646;-shot&#35780;&#20272;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#21487;&#22312;h&#19978;&#33719;&#21462;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained language models have been successful in many knowledge-intensive NLP tasks. However, recent work has shown that models such as BERT are not ``structurally ready'' to aggregate textual information into a [CLS] vector for dense passage retrieval (DPR). This ``lack of readiness'' results from the gap between language model pre-training and DPR fine-tuning. Previous solutions call for computationally expensive techniques such as hard negative mining, cross-encoder distillation, and further pre-training to learn a robust DPR model. In this work, we instead propose to fully exploit knowledge in a pre-trained language model for DPR by aggregating the contextualized token embeddings into a dense vector, which we call agg*. By concatenating vectors from the [CLS] token and agg*, our Aggretriever model substantially improves the effectiveness of dense retrieval models on both in-domain and zero-shot evaluations without introducing substantial training overhead. Code is available at h
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35745;&#31639;&#21464;&#38761;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#26368;&#26032;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#26469;&#22686;&#24378;&#31185;&#23398;&#21457;&#29616;&#21644;&#20132;&#27969;&#12290;&#36825;&#20010;&#26694;&#26550;&#26377;&#24456;&#22810;&#24212;&#29992;&#22330;&#26223;&#65292;&#20316;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#21407;&#22411;&#31995;&#32479;&#30340;&#21021;&#22987;&#23454;&#29616;&#65292;&#24182;&#25506;&#35752;&#20102;&#26410;&#26469;&#30740;&#31350;&#21644;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2205.02007</link><description>&lt;p&gt;
&#31185;&#23398;&#21457;&#29616;&#30340;&#35745;&#31639;&#21464;&#38761;
&lt;/p&gt;
&lt;p&gt;
A Computational Inflection for Scientific Discovery. (arXiv:2205.02007v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.02007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35745;&#31639;&#21464;&#38761;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#26368;&#26032;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#26469;&#22686;&#24378;&#31185;&#23398;&#21457;&#29616;&#21644;&#20132;&#27969;&#12290;&#36825;&#20010;&#26694;&#26550;&#26377;&#24456;&#22810;&#24212;&#29992;&#22330;&#26223;&#65292;&#20316;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#21407;&#22411;&#31995;&#32479;&#30340;&#21021;&#22987;&#23454;&#29616;&#65292;&#24182;&#25506;&#35752;&#20102;&#26410;&#26469;&#30740;&#31350;&#21644;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#27491;&#31449;&#22312;&#31185;&#23398;&#21457;&#29616;&#36712;&#36857;&#19978;&#19968;&#20010;&#37325;&#35201;&#30340;&#25296;&#28857;&#19978;&#12290;&#38543;&#30528;&#31038;&#20250;&#30340;&#24555;&#36895;&#25968;&#23383;&#21270;&#36716;&#22411;&#65292;&#20154;&#31867;&#30340;&#31185;&#23398;&#30693;&#35782;&#21644;&#20132;&#27969;&#20063;&#22312;&#25968;&#23383;&#21270;&#30340;&#24418;&#24335;&#19979;&#19981;&#26029;&#22686;&#38271;&#12290;&#25105;&#20204;&#29616;&#22312;&#38405;&#35835;&#21644;&#25776;&#20889;&#30340;&#35770;&#25991;&#12289;&#39044;&#21360;&#26412;&#12289;&#20070;&#31821;&#12289;&#20195;&#30721;&#12289;&#25968;&#25454;&#38598;&#12289;&#20250;&#35758;&#28436;&#31034;&#31295;&#20197;&#21450;&#31038;&#20132;&#32593;&#32476;&#21644;&#21327;&#20316;&#21644;&#27807;&#36890;&#24179;&#21488;&#19978;&#30340;&#20132;&#20114;&#31561;&#65292;&#22823;&#22810;&#24050;&#32463;&#20197;&#25968;&#23383;&#21270;&#30340;&#26041;&#24335;&#35760;&#24405;&#12290;&#36825;&#31181;&#36716;&#21464;&#23548;&#33268;&#20102;&#22823;&#37327;&#20449;&#24687;&#30340;&#21019;&#36896;&#21644;&#22686;&#38271;&#8212;&#8212;&#20854;&#20013;&#24456;&#22810;&#24050;&#32463;&#21487;&#20379;&#20844;&#20247;&#33719;&#21462;&#8212;&#8212;&#20026;&#20998;&#26512;&#21644;&#21033;&#29992;&#20854;&#30340;&#35745;&#31639;&#27169;&#22411;&#21644;&#31995;&#32479;&#24320;&#21551;&#20102;&#20196;&#20154;&#28608;&#21160;&#30340;&#26426;&#36935;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25968;&#25454;&#22788;&#29702;&#33021;&#21147;&#30340;&#25351;&#25968;&#22686;&#38271;&#25512;&#21160;&#20102;&#20154;&#24037;&#26234;&#33021;&#30340;&#26174;&#33879;&#36827;&#27493;&#65292;&#21253;&#25324;&#33021;&#22815;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#23398;&#20064;&#24378;&#22823;&#34920;&#31034;&#30340;&#22823;&#22411;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#38656;&#35201;&#36827;&#34892;&#37325;&#22823;&#25913;&#21464;&#65292;&#20197;&#22312;&#31185;&#23398;&#30693;&#35782;&#21644;&#20132;&#27969;&#30340;&#26356;&#22823;&#29983;&#24577;&#31995;&#32479;&#20013;&#26377;&#25928;&#25972;&#21512;&#36825;&#20123;&#36827;&#23637;&#65292;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#30340;&#31185;&#23398;&#20132;&#27969;&#33539;&#24335;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31185;&#23398;&#21457;&#29616;&#30340;&#35745;&#31639;&#21464;&#38761;&#8212;&#8212;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#22686;&#24378;&#31185;&#23398;&#21457;&#29616;&#21644;&#20132;&#27969;&#30340;&#32479;&#19968;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#26694;&#26550;&#30340;&#28508;&#21147;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#21407;&#22411;&#31995;&#32479;&#30340;&#21021;&#22987;&#23454;&#29616;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#21644;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
We stand at the foot of a significant inflection in the trajectory of scientific discovery. As society continues on its fast-paced digital transformation, so does humankind's collective scientific knowledge and discourse. We now read and write papers in digitized form, and a great deal of the formal and informal processes of science are captured digitally -including papers, preprints and books, code and datasets, conference presentations, and interactions in social networks and collaboration and communication platforms. The transition has led to the creation and growth of a tremendous amount of information -- much of which is available for public access -- opening exciting opportunities for computational models and systems that analyze and harness it. In parallel, exponential growth in data processing power has fueled remarkable advances in artificial intelligence, including large neural language models capable of learning powerful representations from unstructured text. Dramatic cha
&lt;/p&gt;</description></item><item><title>ATRapos&#26159;&#19968;&#31181;&#23454;&#26102;&#35780;&#20272;&#20803;&#36335;&#24452;&#26597;&#35810;&#24037;&#20316;&#36127;&#36733;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#20102;&#39640;&#25928;&#31232;&#30095;&#30697;&#38453;&#20056;&#27861;&#21644;&#20013;&#38388;&#32467;&#26524;&#32531;&#23384;&#30340;&#32452;&#21512;&#65292;&#22312;&#20351;&#29992;&#23450;&#21046;&#30340;&#25968;&#25454;&#32467;&#26500;&#26469;&#26816;&#27979;&#26597;&#35810;&#20043;&#38388;&#30340;&#39057;&#32321;&#23376;&#20803;&#36335;&#24452;&#26469;&#36873;&#25321;&#35201;&#32531;&#23384;&#21644;&#37325;&#29992;&#30340;&#20013;&#38388;&#32467;&#26524;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ATRapos&#21487;&#20197;&#21152;&#36895;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2201.04058</link><description>&lt;p&gt;
Atrapos: &#20803;&#36335;&#24452;&#26597;&#35810;&#24037;&#20316;&#36127;&#36733;&#30340;&#23454;&#26102;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Atrapos: Real-time Evaluation of Metapath Query Workloads. (arXiv:2201.04058v2 [cs.DB] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.04058
&lt;/p&gt;
&lt;p&gt;
ATRapos&#26159;&#19968;&#31181;&#23454;&#26102;&#35780;&#20272;&#20803;&#36335;&#24452;&#26597;&#35810;&#24037;&#20316;&#36127;&#36733;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#20102;&#39640;&#25928;&#31232;&#30095;&#30697;&#38453;&#20056;&#27861;&#21644;&#20013;&#38388;&#32467;&#26524;&#32531;&#23384;&#30340;&#32452;&#21512;&#65292;&#22312;&#20351;&#29992;&#23450;&#21046;&#30340;&#25968;&#25454;&#32467;&#26500;&#26469;&#26816;&#27979;&#26597;&#35810;&#20043;&#38388;&#30340;&#39057;&#32321;&#23376;&#20803;&#36335;&#24452;&#26469;&#36873;&#25321;&#35201;&#32531;&#23384;&#21644;&#37325;&#29992;&#30340;&#20013;&#38388;&#32467;&#26524;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ATRapos&#21487;&#20197;&#21152;&#36895;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#65288;HIN&#65289;&#34920;&#31034;&#19981;&#21516;&#31867;&#22411;&#30340;&#23454;&#20307;&#21450;&#20854;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25506;&#32034;&#12289;&#20998;&#26512;&#21644;&#25552;&#21462;&#36825;&#26679;&#30340;&#32593;&#32476;&#20013;&#30340;&#30693;&#35782;&#20381;&#36182;&#20110;&#20803;&#36335;&#24452;&#26597;&#35810;&#65292;&#36825;&#20123;&#26597;&#35810;&#35782;&#21035;&#30001;&#22810;&#26679;&#30340;&#35821;&#20041;&#20851;&#31995;&#36830;&#25509;&#30340;&#23454;&#20307;&#23545;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22823;&#35268;&#27169;&#30340;&#32593;&#32476;&#65292;&#23454;&#26102;&#35780;&#20272;&#20803;&#36335;&#24452;&#26597;&#35810;&#24037;&#20316;&#36127;&#36733;&#30340;&#35745;&#31639;&#25104;&#26412;&#38750;&#24120;&#39640;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#20063;&#27809;&#26377;&#21033;&#29992;&#26597;&#35810;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; ATRAPOS &#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#23454;&#26102;&#35780;&#20272;&#20803;&#36335;&#24452;&#26597;&#35810;&#24037;&#20316;&#36127;&#36733;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#39640;&#25928;&#31232;&#30095;&#30697;&#38453;&#20056;&#27861;&#21644;&#20013;&#38388;&#32467;&#26524;&#32531;&#23384;&#30340;&#32452;&#21512;&#12290;ATRAPOS &#36890;&#36807;&#20351;&#29992;&#23450;&#21046;&#30340;&#25968;&#25454;&#32467;&#26500;&#8212;&#8212;&#37325;&#21472;&#26641;&#21644;&#30456;&#20851;&#30340;&#32531;&#23384;&#31574;&#30053;&#65292;&#22312;&#23454;&#26102;&#26816;&#27979;&#21040;&#24037;&#20316;&#36127;&#36733;&#26597;&#35810;&#20043;&#38388;&#30340;&#39057;&#32321;&#23376;&#20803;&#36335;&#24452;&#26469;&#36873;&#25321;&#35201;&#32531;&#23384;&#21644;&#37325;&#29992;&#30340;&#20013;&#38388;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;ATRAPOS &#21152;&#36895;&#20102;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous information networks (HINs) represent different types of entities and relationships between them. Exploring, analysing, and extracting knowledge from such networks relies on metapath queries that identify pairs of entities connected by relationships of diverse semantics. While the real-time evaluation of metapath query workloads on large, web-scale HINs is highly demanding in computational cost, current approaches do not exploit interrelationships among the queries. In this paper, we present ATRAPOS, a new approach for the real-time evaluation of metapath query workloads that leverages a combination of efficient sparse matrix multiplication and intermediate result caching. ATRAPOS selects intermediate results to cache and reuse by detecting frequent sub-metapaths among workload queries in real time, using a tailor-made data structure, the Overlap Tree, and an associated caching policy. Our experimental study on real data shows that ATRAPOS accelerates exploratory data ana
&lt;/p&gt;</description></item></channel></rss>