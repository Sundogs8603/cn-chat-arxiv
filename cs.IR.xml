<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedDCSR&#30340;&#32852;&#37030;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#26469;&#22788;&#29702;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#24207;&#21015;&#29305;&#24449;&#24322;&#36136;&#24615;&#65292;&#24182;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2309.08420</link><description>&lt;p&gt;
FedDCSR: &#36890;&#36807;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#23454;&#29616;&#32852;&#37030;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning. (arXiv:2309.08420v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08420
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedDCSR&#30340;&#32852;&#37030;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#26469;&#22788;&#29702;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#24207;&#21015;&#29305;&#24449;&#24322;&#36136;&#24615;&#65292;&#24182;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#39046;&#22495;&#30340;&#29992;&#25143;&#24207;&#21015;&#25968;&#25454;&#30340;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;(CSR)&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;CSR&#26041;&#27861;&#38656;&#35201;&#22312;&#39046;&#22495;&#20043;&#38388;&#20849;&#20139;&#21407;&#22987;&#29992;&#25143;&#25968;&#25454;&#65292;&#36825;&#36829;&#21453;&#20102;&#12298;&#36890;&#29992;&#25968;&#25454;&#20445;&#25252;&#26465;&#20363;&#12299;(GDPR)&#12290;&#22240;&#27492;&#65292;&#26377;&#24517;&#35201;&#23558;&#32852;&#37030;&#23398;&#20064;(FL)&#21644;CSR&#30456;&#32467;&#21512;&#65292;&#20805;&#20998;&#21033;&#29992;&#19981;&#21516;&#39046;&#22495;&#30340;&#30693;&#35782;&#65292;&#21516;&#26102;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#24207;&#21015;&#29305;&#24449;&#24322;&#36136;&#24615;&#23545;FL&#30340;&#25972;&#20307;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FedDCSR&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#35299;&#20915;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#24207;&#21015;&#29305;&#24449;&#24322;&#36136;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#39046;&#22495;&#20869;-&#39046;&#22495;&#38388;&#24207;&#21015;&#34920;&#31034;&#35299;&#32544;(SRD)&#30340;&#26041;&#27861;&#65292;&#23558;&#29992;&#25143;&#24207;&#21015;&#29305;&#24449;&#35299;&#32544;&#25104;&#39046;&#22495;&#20849;&#20139;&#21644;&#39046;&#22495;&#19987;&#23646;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-domain Sequential Recommendation (CSR) which leverages user sequence data from multiple domains has received extensive attention in recent years. However, the existing CSR methods require sharing origin user data across domains, which violates the General Data Protection Regulation (GDPR). Thus, it is necessary to combine federated learning (FL) and CSR to fully utilize knowledge from different domains while preserving data privacy. Nonetheless, the sequence feature heterogeneity across different domains significantly impacts the overall performance of FL. In this paper, we propose FedDCSR, a novel federated cross-domain sequential recommendation framework via disentangled representation learning. Specifically, to address the sequence feature heterogeneity across domains, we introduce an approach called inter-intra domain sequence representation disentanglement (SRD) to disentangle the user sequence features into domain-shared and domain-exclusive features. In addition, we design
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;KAR&#26694;&#26550;&#65292;&#23427;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#33719;&#21462;&#20004;&#31181;&#31867;&#22411;&#30340;&#22806;&#37096;&#30693;&#35782;&#65292;&#20998;&#21035;&#26159;&#29992;&#25143;&#20559;&#22909;&#30340;&#25512;&#29702;&#30693;&#35782;&#21644;&#39033;&#30446;&#30340;&#20107;&#23454;&#30693;&#35782;&#12290;&#36890;&#36807;&#28151;&#21512;&#19987;&#23478;&#36866;&#37197;&#22120;&#23558;&#25512;&#29702;&#21644;&#20107;&#23454;&#30693;&#35782;&#36716;&#25442;&#20026;&#22686;&#24378;&#21521;&#37327;&#65292;&#20197;&#20415;&#19982;&#29616;&#26377;&#30340;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31639;&#27861;&#20860;&#23481;&#12290;</title><link>http://arxiv.org/abs/2306.10933</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#25918;&#19990;&#30028;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models. (arXiv:2306.10933v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10933
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;KAR&#26694;&#26550;&#65292;&#23427;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#33719;&#21462;&#20004;&#31181;&#31867;&#22411;&#30340;&#22806;&#37096;&#30693;&#35782;&#65292;&#20998;&#21035;&#26159;&#29992;&#25143;&#20559;&#22909;&#30340;&#25512;&#29702;&#30693;&#35782;&#21644;&#39033;&#30446;&#30340;&#20107;&#23454;&#30693;&#35782;&#12290;&#36890;&#36807;&#28151;&#21512;&#19987;&#23478;&#36866;&#37197;&#22120;&#23558;&#25512;&#29702;&#21644;&#20107;&#23454;&#30693;&#35782;&#36716;&#25442;&#20026;&#22686;&#24378;&#21521;&#37327;&#65292;&#20197;&#20415;&#19982;&#29616;&#26377;&#30340;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31639;&#27861;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#21508;&#31181;&#22312;&#32447;&#26381;&#21153;&#20013;&#37117;&#25198;&#28436;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#35282;&#33394;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#22312;&#29305;&#23450;&#39046;&#22495;&#20869;&#36827;&#34892;&#35757;&#32451;&#21644;&#37096;&#32626;&#30340;&#23553;&#38381;&#24615;&#38480;&#21046;&#20102;&#23427;&#20204;&#35775;&#38382;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#20986;&#29616;&#22312;&#32534;&#30721;&#24191;&#27867;&#30340;&#19990;&#30028;&#30693;&#35782;&#21644;&#23637;&#31034;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#24076;&#26395;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#30452;&#25509;&#20351;&#29992;LLM&#20316;&#20026;&#25512;&#33616;&#20154;&#20043;&#21069;&#30340;&#23581;&#35797;&#24182;&#27809;&#26377;&#21462;&#24471;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#22686;&#24378;&#25512;&#33616;&#26694;&#26550;(KAR)&#65292;&#20197;&#20174;LLM&#33719;&#21462;&#20004;&#31181;&#31867;&#22411;&#30340;&#22806;&#37096;&#30693;&#35782;--&#29992;&#25143;&#20559;&#22909;&#30340;&#25512;&#29702;&#30693;&#35782;&#21644;&#39033;&#30446;&#30340;&#20107;&#23454;&#30693;&#35782;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#22240;&#23376;&#20998;&#35299;&#25552;&#31034;&#26469;&#24341;&#23548;&#23545;&#29992;&#25143;&#21916;&#22909;&#30340;&#20934;&#30830;&#25512;&#29702;&#12290;&#29983;&#25104;&#30340;&#25512;&#29702;&#21644;&#20107;&#23454;&#30693;&#35782;&#36890;&#36807;&#28151;&#21512;&#19987;&#23478;&#36866;&#37197;&#22120;&#26377;&#25928;&#22320;&#36716;&#25442;&#24182;&#21387;&#32553;&#20026;&#22686;&#24378;&#21521;&#37327;&#65292;&#20197;&#20415;&#19982;&#29616;&#26377;&#30340;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31639;&#27861;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems play a vital role in various online services. However, the insulated nature of training and deploying separately within a specific domain limits their access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capability. Nevertheless, previous attempts to directly use LLMs as recommenders have not achieved satisfactory results. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs -- the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with
&lt;/p&gt;</description></item><item><title>&#20302;&#36164;&#28304;&#24773;&#22659;&#19979;&#65292;&#22914;&#20309;&#35753;&#30693;&#35782;&#25277;&#21462;&#26356;&#22909;&#22320;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#25552;&#21462;&#20449;&#24687;&#65311;&#26412;&#25991;&#35843;&#30740;&#20102;&#19977;&#31181;&#35299;&#20915;&#33539;&#24335;&#65306;&#39640;&#36164;&#28304;&#25968;&#25454;&#12289;&#26356;&#24378;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#19982;&#27169;&#22411;&#30340;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2202.08063</link><description>&lt;p&gt;
&#20302;&#36164;&#28304;&#24773;&#22659;&#19979;&#30340;&#30693;&#35782;&#25277;&#21462;&#65306;&#35843;&#30740;&#19982;&#23637;&#26395;
&lt;/p&gt;
&lt;p&gt;
Knowledge Extraction in Low-Resource Scenarios: Survey and Perspective. (arXiv:2202.08063v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.08063
&lt;/p&gt;
&lt;p&gt;
&#20302;&#36164;&#28304;&#24773;&#22659;&#19979;&#65292;&#22914;&#20309;&#35753;&#30693;&#35782;&#25277;&#21462;&#26356;&#22909;&#22320;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#25552;&#21462;&#20449;&#24687;&#65311;&#26412;&#25991;&#35843;&#30740;&#20102;&#19977;&#31181;&#35299;&#20915;&#33539;&#24335;&#65306;&#39640;&#36164;&#28304;&#25968;&#25454;&#12289;&#26356;&#24378;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#19982;&#27169;&#22411;&#30340;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#25277;&#21462;&#65288;KE&#65289;&#26088;&#22312;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#25552;&#21462;&#32467;&#26500;&#20449;&#24687;&#65292;&#36890;&#24120;&#36973;&#21463;&#25968;&#25454;&#21294;&#20047;&#21644;&#20986;&#29616;&#26410;&#35265;&#31867;&#22411;&#65288;&#20302;&#36164;&#28304;&#24773;&#22659;&#65289;&#30340;&#22256;&#25200;&#12290;&#35768;&#22810;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#24050;&#24191;&#27867;&#30740;&#31350;&#24182;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#34920;&#29616;&#12290;&#26412;&#25991;&#23545;&#20302;&#36164;&#28304;&#24773;&#22659;&#19979;KE&#36827;&#34892;&#25991;&#29486;&#32508;&#36848;&#65292;&#24182;&#23558;&#29616;&#26377;&#30340;&#24037;&#20316;&#31995;&#32479;&#24615;&#22320;&#20998;&#20026;&#19977;&#31181;&#33539;&#24335;&#65306;&#65288;1&#65289;&#21033;&#29992;&#39640;&#36164;&#28304;&#25968;&#25454;&#65292;&#65288;2&#65289;&#21033;&#29992;&#26356;&#24378;&#30340;&#27169;&#22411;&#65292;&#65288;3&#65289;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#21644;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#26377;&#21069;&#36884;&#30340;&#24212;&#29992;&#65292;&#24182;&#27010;&#36848;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#19968;&#20123;&#28508;&#22312;&#26041;&#21521;&#12290;&#25105;&#20204;&#24076;&#26395;&#25105;&#20204;&#30340;&#35843;&#30740;&#21487;&#20197;&#24110;&#21161;&#23398;&#26415;&#21644;&#24037;&#19994;&#30028;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#39046;&#22495;&#65292;&#28608;&#21457;&#26356;&#22810;&#30340;&#21019;&#24847;&#65292;&#25552;&#21319;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge Extraction (KE), aiming to extract structural information from unstructured texts, often suffers from data scarcity and emerging unseen types, i.e., low-resource scenarios. Many neural approaches to low-resource KE have been widely investigated and achieved impressive performance. In this paper, we present a literature review towards KE in low-resource scenarios, and systematically categorize existing works into three paradigms: (1) exploiting higher-resource data, (2) exploiting stronger models, and (3) exploiting data and models together. In addition, we highlight promising applications and outline some potential directions for future research. We hope that our survey can help both the academic and industrial communities to better understand this field, inspire more ideas, and boost broader applications.
&lt;/p&gt;</description></item></channel></rss>