<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;paNNG&#30340;&#31639;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#33258;&#36866;&#24212;kNN&#21644;&#22522;&#20110;&#20998;&#24067;&#30340;&#22270;&#26500;&#24314;&#12290;&#36890;&#36807;&#21253;&#21547;&#20998;&#24067;&#20449;&#24687;&#65292;paNNG&#33021;&#22815;&#26377;&#25928;&#25552;&#21319;&#27169;&#31946;&#26679;&#26412;&#30340;&#24615;&#33021;&#65292;&#24182;&#23454;&#29616;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.02442</link><description>&lt;p&gt;
&#20351;&#29992;&#20998;&#24067;&#24863;&#30693;&#30340;&#33258;&#36866;&#24212;&#20248;&#20808;&#32423;&#38468;&#21152;kNN&#22270;
&lt;/p&gt;
&lt;p&gt;
Adaptive Preferential Attached kNN Graph With Distribution-Awareness. (arXiv:2308.02442v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;paNNG&#30340;&#31639;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#33258;&#36866;&#24212;kNN&#21644;&#22522;&#20110;&#20998;&#24067;&#30340;&#22270;&#26500;&#24314;&#12290;&#36890;&#36807;&#21253;&#21547;&#20998;&#24067;&#20449;&#24687;&#65292;paNNG&#33021;&#22815;&#26377;&#25928;&#25552;&#21319;&#27169;&#31946;&#26679;&#26412;&#30340;&#24615;&#33021;&#65292;&#24182;&#23454;&#29616;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;kNN&#31639;&#27861;&#22240;&#20854;&#31616;&#21333;&#24615;&#21644;&#26377;&#25928;&#24615;&#22312;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#24191;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;kNN&#22270;&#23545;&#20110;k&#20540;&#30340;&#22266;&#23450;&#20381;&#36182;&#21487;&#33021;&#20250;&#24433;&#21709;&#20854;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#28041;&#21450;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#12290;&#27492;&#22806;&#65292;&#19982;&#20854;&#20182;&#20998;&#31867;&#27169;&#22411;&#31867;&#20284;&#65292;&#20915;&#31574;&#36793;&#30028;&#19978;&#23384;&#22312;&#30340;&#27169;&#31946;&#26679;&#26412;&#24120;&#24120;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#22240;&#20026;&#23427;&#20204;&#26356;&#23481;&#26131;&#34987;&#38169;&#35823;&#20998;&#31867;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20248;&#20808;&#32423;&#38468;&#21152;k-&#26368;&#36817;&#37051;&#22270;&#65288;paNNG&#65289;&#65292;&#23427;&#23558;&#33258;&#36866;&#24212;&#30340;kNN&#19982;&#22522;&#20110;&#20998;&#24067;&#30340;&#22270;&#26500;&#24314;&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#32467;&#21512;&#20998;&#24067;&#20449;&#24687;&#65292;paNNG&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#27169;&#31946;&#26679;&#26412;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#8220;&#25289;&#8221;&#23427;&#20204;&#22238;&#21040;&#21407;&#22987;&#31867;&#21035;&#65292;&#20174;&#32780;&#23454;&#29616;&#25913;&#36827;&#30340;&#25972;&#20307;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#22810;&#26679;&#21270;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20005;&#26684;&#35780;&#20272;&#65292;paNNG&#30340;&#24615;&#33021;&#36229;&#36234;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;&#23637;&#31034;&#20102;&#23427;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph-based kNN algorithms have garnered widespread popularity for machine learning tasks, due to their simplicity and effectiveness. However, the conventional kNN graph's reliance on a fixed value of k can hinder its performance, especially in scenarios involving complex data distributions. Moreover, like other classification models, the presence of ambiguous samples along decision boundaries often presents a challenge, as they are more prone to incorrect classification. To address these issues, we propose the Preferential Attached k-Nearest Neighbors Graph (paNNG), which combines adaptive kNN with distribution-based graph construction. By incorporating distribution information, paNNG can significantly improve performance for ambiguous samples by "pulling" them towards their original classes and hence enable enhanced overall accuracy and generalization capability. Through rigorous evaluations on diverse benchmark datasets, paNNG outperforms state-of-the-art algorithms, showcasing its 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;Gramm&#35282;&#24230;&#22330;&#30340;ECG&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#26102;&#38388;&#39057;&#29575;1D&#21521;&#37327;&#36716;&#25442;&#20026;2D&#22270;&#20687;&#65292;&#24182;&#23545;&#36716;&#25442;&#21518;&#30340;ECG&#20449;&#21495;&#36827;&#34892;&#20998;&#31867;&#65292;&#36798;&#21040;&#20102;&#39640;&#20934;&#30830;&#29575;&#12290;&#35813;&#26041;&#27861;&#25913;&#21892;&#20102;&#20998;&#31867;&#24615;&#33021;&#65292;&#21516;&#26102;&#36824;&#26377;&#21161;&#20110;&#35782;&#21035;&#21644;&#21487;&#35270;&#21270;ECG&#20449;&#21495;&#20013;&#30340;&#26102;&#22495;&#27169;&#24335;&#65292;&#22312;&#24515;&#34880;&#31649;&#30142;&#30149;&#35786;&#26029;&#21644;&#27835;&#30103;&#20197;&#21450;&#24322;&#24120;&#26816;&#27979;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2308.02395</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;Gramm&#35282;&#24230;&#22330;&#30340;ECG&#20998;&#31867;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
ECG classification using Deep CNN and Gramian Angular Field. (arXiv:2308.02395v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;Gramm&#35282;&#24230;&#22330;&#30340;ECG&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#26102;&#38388;&#39057;&#29575;1D&#21521;&#37327;&#36716;&#25442;&#20026;2D&#22270;&#20687;&#65292;&#24182;&#23545;&#36716;&#25442;&#21518;&#30340;ECG&#20449;&#21495;&#36827;&#34892;&#20998;&#31867;&#65292;&#36798;&#21040;&#20102;&#39640;&#20934;&#30830;&#29575;&#12290;&#35813;&#26041;&#27861;&#25913;&#21892;&#20102;&#20998;&#31867;&#24615;&#33021;&#65292;&#21516;&#26102;&#36824;&#26377;&#21161;&#20110;&#35782;&#21035;&#21644;&#21487;&#35270;&#21270;ECG&#20449;&#21495;&#20013;&#30340;&#26102;&#22495;&#27169;&#24335;&#65292;&#22312;&#24515;&#34880;&#31649;&#30142;&#30149;&#35786;&#26029;&#21644;&#27835;&#30103;&#20197;&#21450;&#24322;&#24120;&#26816;&#27979;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#29305;&#24449;&#34920;&#31034;&#26041;&#27861;&#65292;&#21363;Gramm&#35282;&#24230;&#22330;&#21464;&#25442;&#65292;&#20026;ECG&#20449;&#21495;&#20998;&#26512;&#30340;&#20449;&#21495;&#22788;&#29702;&#21644;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#25552;&#20379;&#20102;&#19968;&#39033;&#21019;&#26032;&#36129;&#29486;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#23558;&#26102;&#38388;&#39057;&#29575;1D&#21521;&#37327;&#36716;&#25442;&#20026;2D&#22270;&#20687;&#65292;&#28982;&#21518;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#23545;&#36716;&#25442;&#21518;&#30340;ECG&#20449;&#21495;&#36827;&#34892;&#20998;&#31867;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#24322;&#24120;&#26816;&#27979;&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#36798;&#21040;&#20102;97.47%&#21644;98.65%&#12290;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#29305;&#24449;&#34920;&#31034;&#26041;&#27861;&#19981;&#20165;&#25913;&#21892;&#20102;&#20998;&#31867;&#24615;&#33021;&#65292;&#36824;&#26377;&#21161;&#20110;&#35782;&#21035;&#21644;&#21487;&#35270;&#21270;ECG&#20449;&#21495;&#20013;&#30340;&#26102;&#22495;&#27169;&#24335;&#65292;&#20363;&#22914;&#24515;&#29575;&#12289;&#33410;&#24459;&#21644;&#24418;&#24577;&#30340;&#21464;&#21270;&#65292;&#36825;&#22312;&#24515;&#34880;&#31649;&#30142;&#30149;&#30340;&#35786;&#26029;&#21644;&#27835;&#30103;&#20197;&#21450;&#24322;&#24120;&#26816;&#27979;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper study provides a novel contribution to the field of signal processing and DL for ECG signal analysis by introducing a new feature representation method for ECG signals. The proposed method is based on transforming time frequency 1D vectors into 2D images using Gramian Angular Field transform. Moving on, the classification of the transformed ECG signals is performed using Convolutional Neural Networks (CNN). The obtained results show a classification accuracy of 97.47% and 98.65% for anomaly detection. Accordingly, in addition to improving the classification performance compared to the state-of-the-art, the feature representation helps identify and visualize temporal patterns in the ECG signal, such as changes in heart rate, rhythm, and morphology, which may not be apparent in the original signal. This has significant implications in the diagnosis and treatment of cardiovascular diseases and detection of anomalies.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#22411;&#28151;&#21512;&#32593;&#32476;(RAHNet)&#29992;&#20110;&#38271;&#23614;&#22270;&#20998;&#31867;&#20219;&#21153;&#65292;&#36890;&#36807;&#32852;&#21512;&#23398;&#20064;&#31283;&#20581;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#21644;&#26080;&#20559;&#30340;&#20998;&#31867;&#22120;&#65292;&#35299;&#20915;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38271;&#23614;&#31867;&#21035;&#20998;&#24067;&#19979;&#30340;&#20559;&#24046;&#21644;&#27867;&#21270;&#33021;&#21147;&#26377;&#38480;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.02335</link><description>&lt;p&gt;
RAHNet: &#26816;&#32034;&#22686;&#24378;&#22411;&#28151;&#21512;&#32593;&#32476;&#29992;&#20110;&#38271;&#23614;&#22270;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification. (arXiv:2308.02335v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02335
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#22411;&#28151;&#21512;&#32593;&#32476;(RAHNet)&#29992;&#20110;&#38271;&#23614;&#22270;&#20998;&#31867;&#20219;&#21153;&#65292;&#36890;&#36807;&#32852;&#21512;&#23398;&#20064;&#31283;&#20581;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#21644;&#26080;&#20559;&#30340;&#20998;&#31867;&#22120;&#65292;&#35299;&#20915;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38271;&#23614;&#31867;&#21035;&#20998;&#24067;&#19979;&#30340;&#20559;&#24046;&#21644;&#27867;&#21270;&#33021;&#21147;&#26377;&#38480;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#20998;&#31867;&#26159;&#35768;&#22810;&#23454;&#38469;&#22810;&#23186;&#20307;&#24212;&#29992;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#65292;&#22270;&#21487;&#20197;&#34920;&#31034;&#21508;&#31181;&#22810;&#23186;&#20307;&#25968;&#25454;&#31867;&#22411;&#65292;&#22914;&#22270;&#20687;&#12289;&#35270;&#39057;&#21644;&#31038;&#20132;&#32593;&#32476;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#22312;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#24212;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;(GNN)&#65292;&#20854;&#20013;&#31867;&#20998;&#24067;&#26159;&#24179;&#34913;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#25968;&#25454;&#36890;&#24120;&#21576;&#29616;&#20986;&#38271;&#23614;&#31867;&#21035;&#20998;&#24067;&#65292;&#23548;&#33268;&#22312;&#20351;&#29992;GNN&#26102;&#23545;&#22836;&#37096;&#31867;&#21035;&#23384;&#22312;&#20559;&#24046;&#65292;&#19988;&#23545;&#23614;&#37096;&#31867;&#21035;&#30340;&#27867;&#21270;&#33021;&#21147;&#26377;&#38480;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#37325;&#26032;&#24179;&#34913;&#19981;&#21516;&#30340;&#31867;&#21035;&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#26410;&#33021;&#26126;&#30830;&#24341;&#20837;&#26032;&#30693;&#35782;&#65292;&#24182;&#29306;&#29298;&#20102;&#22836;&#37096;&#31867;&#21035;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#32570;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#26816;&#32034;&#22686;&#24378;&#22411;&#28151;&#21512;&#32593;&#32476;(RAHNet)&#65292;&#20197;&#20998;&#31163;&#30340;&#26041;&#24335;&#32852;&#21512;&#23398;&#20064;&#31283;&#20581;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#21644;&#26080;&#20559;&#30340;&#20998;&#31867;&#22120;&#12290;&#22312;&#29305;&#24449;&#25552;&#21462;&#22120;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22270;&#26816;&#32034;&#27169;&#22359;&#26469;&#25628;&#32034;&#30456;&#20851;&#22270;&#24418;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph classification is a crucial task in many real-world multimedia applications, where graphs can represent various multimedia data types such as images, videos, and social networks. Previous efforts have applied graph neural networks (GNNs) in balanced situations where the class distribution is balanced. However, real-world data typically exhibit long-tailed class distributions, resulting in a bias towards the head classes when using GNNs and limited generalization ability over the tail classes. Recent approaches mainly focus on re-balancing different classes during model training, which fails to explicitly introduce new knowledge and sacrifices the performance of the head classes. To address these drawbacks, we propose a novel framework called Retrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature extractor and an unbiased classifier in a decoupled manner. In the feature extractor training stage, we develop a graph retrieval module to search for relevant grap
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;DHS-ConvQA&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#20250;&#35805;&#24335;&#38382;&#31572;&#20013;&#21160;&#24577;&#36873;&#25321;&#30456;&#20851;&#30340;&#21382;&#21490;&#36716;&#25240;&#28857;&#65292;&#20197;&#25351;&#23548;&#31572;&#26696;&#30340;&#20934;&#30830;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.02294</link><description>&lt;p&gt;
&#23398;&#20064;&#36873;&#25321;&#20250;&#35805;&#38382;&#31572;&#20013;&#30456;&#20851;&#30340;&#21382;&#21490;&#23545;&#35805;&#36716;&#25240;&#28857;
&lt;/p&gt;
&lt;p&gt;
Learning to Select the Relevant History Turns in Conversational Question Answering. (arXiv:2308.02294v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02294
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;DHS-ConvQA&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#20250;&#35805;&#24335;&#38382;&#31572;&#20013;&#21160;&#24577;&#36873;&#25321;&#30456;&#20851;&#30340;&#21382;&#21490;&#36716;&#25240;&#28857;&#65292;&#20197;&#25351;&#23548;&#31572;&#26696;&#30340;&#20934;&#30830;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22522;&#20110;&#32593;&#32476;&#30340;&#25968;&#23383;&#21161;&#25163;&#30340;&#26085;&#30410;&#38656;&#27714;&#65292;&#24341;&#36215;&#20102;&#20449;&#24687;&#26816;&#32034;(IR)&#31038;&#21306;&#23545;&#20250;&#35805;&#24335;&#38382;&#31572;(ConvQA)&#39046;&#22495;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;ConvQA&#30340;&#19968;&#20010;&#20851;&#38190;&#26041;&#38754;&#26159;&#26377;&#25928;&#36873;&#25321;&#20250;&#35805;&#21382;&#21490;&#36716;&#25240;&#28857;&#20197;&#22238;&#31572;&#24403;&#21069;&#38382;&#39064;&#12290;&#30456;&#20851;&#21382;&#21490;&#36873;&#25321;&#19982;&#27491;&#30830;&#31572;&#26696;&#39044;&#27979;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#26159;&#19968;&#20010;&#26377;&#36259;&#20294;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#30340;&#39046;&#22495;&#12290;&#36873;&#25321;&#30340;&#30456;&#20851;&#19978;&#19979;&#25991;&#21487;&#20197;&#26356;&#22909;&#22320;&#25351;&#23548;&#31995;&#32479;&#22312;&#25991;&#31456;&#20013;&#23547;&#25214;&#31572;&#26696;&#30340;&#30830;&#20999;&#20301;&#32622;&#12290;&#32780;&#19981;&#30456;&#20851;&#30340;&#19978;&#19979;&#25991;&#21017;&#32473;&#31995;&#32479;&#24102;&#26469;&#22122;&#38899;&#65292;&#20174;&#32780;&#23548;&#33268;&#27169;&#22411;&#24615;&#33021;&#19979;&#38477;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;DHS-ConvQA&#65288;&#20250;&#35805;&#38382;&#31572;&#20013;&#30340;&#21160;&#24577;&#21382;&#21490;&#36873;&#25321;&#65289;&#65292;&#39318;&#20808;&#20026;&#25152;&#26377;&#21382;&#21490;&#36716;&#25240;&#28857;&#29983;&#25104;&#19978;&#19979;&#25991;&#21644;&#38382;&#39064;&#23454;&#20307;&#65292;&#28982;&#21518;&#26681;&#25454;&#23427;&#20204;&#19982;&#38382;&#39064;&#30340;&#30456;&#20284;&#24230;&#36827;&#34892;&#20462;&#21098;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing demand for the web-based digital assistants has given a rapid rise in the interest of the Information Retrieval (IR) community towards the field of conversational question answering (ConvQA). However, one of the critical aspects of ConvQA is the effective selection of conversational history turns to answer the question at hand. The dependency between relevant history selection and correct answer prediction is an intriguing but under-explored area. The selected relevant context can better guide the system so as to where exactly in the passage to look for an answer. Irrelevant context, on the other hand, brings noise to the system, thereby resulting in a decline in the model's performance. In this paper, we propose a framework, DHS-ConvQA (Dynamic History Selection in Conversational Question Answering), that first generates the context and question entities for all the history turns, which are then pruned on the basis of similarity they share in common with the question at
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#32039;&#20945;&#30340;&#26377;&#21521;&#26080;&#29615;&#35789;&#22270;&#65288;CDAWG&#65289;&#36716;&#25442;&#25104;&#20854;&#20182;&#36866;&#29992;&#20110;&#39640;&#24230;&#37325;&#22797;&#25991;&#26412;&#30340;&#25991;&#26412;&#32034;&#24341;&#32467;&#26500;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20248;&#21270;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#36825;&#20123;&#36716;&#25442;&#25552;&#20379;&#20102;&#26368;&#20248;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.02269</link><description>&lt;p&gt;
&#22522;&#20110;&#32039;&#20945;&#30340;&#26377;&#21521;&#26080;&#29615;&#35789;&#22270;&#36827;&#34892;&#21387;&#32553;&#32034;&#24341;&#25968;&#32452;&#30340;&#26368;&#20248;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Optimally Computing Compressed Indexing Arrays Based on the Compact Directed Acyclic Word Graph. (arXiv:2308.02269v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02269
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#32039;&#20945;&#30340;&#26377;&#21521;&#26080;&#29615;&#35789;&#22270;&#65288;CDAWG&#65289;&#36716;&#25442;&#25104;&#20854;&#20182;&#36866;&#29992;&#20110;&#39640;&#24230;&#37325;&#22797;&#25991;&#26412;&#30340;&#25991;&#26412;&#32034;&#24341;&#32467;&#26500;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20248;&#21270;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#36825;&#20123;&#36716;&#25442;&#25552;&#20379;&#20102;&#26368;&#20248;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#23558;&#22522;&#20110;&#33258;&#21160;&#26426;&#30340;&#25991;&#26412;&#32034;&#24341;&#32467;&#26500;&#65288;&#31216;&#20026;&#32039;&#20945;&#30340;&#26377;&#21521;&#26080;&#29615;&#35789;&#22270;&#65292;CDAWG&#65289;&#22823;&#23567;&#20026;$e$&#30340;&#25991;&#26412;$T$&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#36716;&#25442;&#25104;&#36866;&#29992;&#20110;&#39640;&#24230;&#37325;&#22797;&#25991;&#26412;&#30340;&#20854;&#20182;&#25991;&#26412;&#32034;&#24341;&#32467;&#26500;&#30340;&#24773;&#20917;&#65306;&#22823;&#23567;&#20026;$r$&#30340;&#32463;&#36807;&#36816;&#34892;&#38271;&#24230;&#32534;&#30721;&#30340;BWT&#12289;&#22823;&#23567;&#20026;$r$&#30340;&#19981;&#21487;&#32422;PLCP&#25968;&#32452;&#12289;&#22823;&#23567;&#20026;$e$&#30340;&#20934;&#19981;&#21487;&#32422;LPF&#25968;&#32452;&#65292;&#20197;&#21450;&#22823;&#23567;&#20026;$O(r)$&#30340;lex&#35299;&#26512;&#21644;&#22823;&#23567;&#20026;$z$&#30340;LZ77&#35299;&#26512;&#65292;&#20854;&#20013;$r, z \le e$&#12290;&#20316;&#20026;&#20027;&#35201;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19978;&#36848;&#32467;&#26500;&#21487;&#20197;&#36890;&#36807;&#20174;&#21482;&#35835;&#23384;&#20648;&#22120;&#20013;&#30340;CDAWG&#25110;&#20854;&#22823;&#23567;&#20026;$e$&#30340;&#33258;&#32034;&#24341;&#29256;&#26412;&#20013;&#26368;&#20248;&#22320;&#35745;&#31639;&#24471;&#21040;&#65292;&#35745;&#31639;&#26102;&#38388;&#20026;$O(e)$&#65292;&#24037;&#20316;&#31354;&#38388;&#20026;&#23383;&#38271;&#12290;&#20026;&#20102;&#33719;&#24471;&#19978;&#36848;&#32467;&#26524;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22312;CDAWG&#19978;&#36890;&#36807;&#27491;&#21521;&#21644;&#21453;&#21521;&#25628;&#32034;&#26469;&#26522;&#20030;&#35789;&#20856;&#21644;&#25991;&#26412;&#39034;&#24207;&#20013;&#29305;&#23450;&#21518;&#32512;&#23376;&#38598;&#30340;&#25216;&#26415;&#65292;&#25193;&#23637;&#20102;Belazzougui&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present the first study of the computational complexity of converting an automata-based text index structure, called the Compact Directed Acyclic Word Graph (CDAWG), of size $e$ for a text $T$ of length $n$ into other text indexing structures for the same text, suitable for highly repetitive texts: the run-length BWT of size $r$, the irreducible PLCP array of size $r$, and the quasi-irreducible LPF array of size $e$, as well as the lex-parse of size $O(r)$ and the LZ77-parse of size $z$, where $r, z \le e$. As main results, we showed that the above structures can be optimally computed from either the CDAWG for $T$ stored in read-only memory or its self-index version of size $e$ without a text in $O(e)$ worst-case time and words of working space. To obtain the above results, we devised techniques for enumerating a particular subset of suffixes in the lexicographic and text orders using the forward and backward search on the CDAWG by extending the results by Belazzougui
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23545;&#38889;&#22269;&#27665;&#27468;&#36827;&#34892;&#35745;&#31639;&#26426;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#20197;&#8220;&#25176;&#37324;&#8221;&#20316;&#20026;&#26696;&#20363;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#8220;&#25176;&#37324;&#8221;&#30340;&#29305;&#24449;&#65292;&#20026;&#30740;&#31350;&#38889;&#22269;&#27665;&#27468;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;</title><link>http://arxiv.org/abs/2308.02249</link><description>&lt;p&gt;
&#23547;&#25214;&#25176;&#37324;&#65306;&#33258;&#30417;&#30563;&#23398;&#20064;&#29992;&#20110;&#20998;&#26512;&#38889;&#22269;&#27665;&#27468;
&lt;/p&gt;
&lt;p&gt;
Finding Tori: Self-supervised Learning for Analyzing Korean Folk Song. (arXiv:2308.02249v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23545;&#38889;&#22269;&#27665;&#27468;&#36827;&#34892;&#35745;&#31639;&#26426;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#20197;&#8220;&#25176;&#37324;&#8221;&#20316;&#20026;&#26696;&#20363;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#8220;&#25176;&#37324;&#8221;&#30340;&#29305;&#24449;&#65292;&#20026;&#30740;&#31350;&#38889;&#22269;&#27665;&#27468;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#23545;&#22823;&#32422;700&#23567;&#26102;&#30340;&#38889;&#22269;&#27665;&#27468;&#22330;&#24405;&#38899;&#25968;&#25454;&#38598;&#36827;&#34892;&#35745;&#31639;&#26426;&#20998;&#26512;&#65292;&#36825;&#20123;&#24405;&#38899;&#22823;&#22810;&#25968;&#22312;1980-90&#24180;&#20195;&#24405;&#21046;&#12290;&#30001;&#20110;&#22823;&#37096;&#20998;&#27468;&#26354;&#37117;&#26159;&#30001;&#38750;&#19987;&#19994;&#38899;&#20048;&#23478;&#22312;&#27809;&#26377;&#20276;&#22863;&#30340;&#24773;&#20917;&#19979;&#28436;&#21809;&#30340;&#65292;&#22240;&#27492;&#35813;&#25968;&#25454;&#38598;&#25552;&#20379;&#20102;&#19968;&#20123;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#38899;&#35843;&#36718;&#24275;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#65292;&#24182;&#20998;&#26512;&#20102;&#27169;&#22411;&#22914;&#20309;&#25429;&#25417;&#21040;&#8220;&#25176;&#37324;&#8221;&#36825;&#19968;&#38899;&#20048;&#27010;&#24565;&#65292;&#23427;&#26159;&#19968;&#20010;&#22522;&#20110;&#29305;&#23450;&#38899;&#38454;&#12289;&#35013;&#39280;&#38899;&#21644;&#25104;&#35821;&#21270;&#26059;&#24459;&#36718;&#24275;&#30340;&#20998;&#31867;&#31995;&#32479;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479;&#30340;&#38899;&#39640;&#30452;&#26041;&#22270;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#8220;&#25176;&#37324;&#8221;&#30340;&#29305;&#24449;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29616;&#26377;&#23398;&#26415;&#30028;&#25552;&#20986;&#30340;&#38899;&#20048;&#35752;&#35770;&#22312;&#38889;&#22269;&#27665;&#27468;&#23454;&#38469;&#24405;&#38899;&#20013;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a computational analysis of the field recording dataset of approximately 700 hours of Korean folk songs, which were recorded around 1980-90s. Because most of the songs were sung by non-expert musicians without accompaniment, the dataset provides several challenges. To address this challenge, we utilized self-supervised learning with convolutional neural network based on pitch contour, then analyzed how the musical concept of tori, a classification system defined by a specific scale, ornamental notes, and an idiomatic melodic contour, is captured by the model. The experimental result shows that our approach can better capture the characteristics of tori compared to traditional pitch histograms. Using our approaches, we have examined how musical discussions proposed in existing academia manifest in the actual field recordings of Korean folk songs.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#25552;&#31034;-&#27169;&#22411;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#20010;&#24615;&#21270;&#30340;&#29983;&#25104;&#24335;&#25512;&#33616;&#20219;&#21153;&#12290;&#36890;&#36807;GEMRec-18K&#25968;&#25454;&#38598;&#30340;&#30740;&#31350;&#65292;&#20316;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#26694;&#26550;&#65292;&#20998;&#21035;&#26159;&#25552;&#31034;-&#27169;&#22411;&#26816;&#32034;&#21644;&#29983;&#25104;&#39033;&#25490;&#24207;&#65292;&#20197;&#35299;&#20915;&#36825;&#19968;&#26032;&#20219;&#21153;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.02205</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#29983;&#25104;&#24335;&#25512;&#33616;&#30340;&#20010;&#24615;&#21270;&#25552;&#31034;-&#27169;&#22411;&#26816;&#32034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Personalized Prompt-Model Retrieval for Generative Recommendation. (arXiv:2308.02205v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02205
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#25552;&#31034;-&#27169;&#22411;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#20010;&#24615;&#21270;&#30340;&#29983;&#25104;&#24335;&#25512;&#33616;&#20219;&#21153;&#12290;&#36890;&#36807;GEMRec-18K&#25968;&#25454;&#38598;&#30340;&#30740;&#31350;&#65292;&#20316;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#26694;&#26550;&#65292;&#20998;&#21035;&#26159;&#25552;&#31034;-&#27169;&#22411;&#26816;&#32034;&#21644;&#29983;&#25104;&#39033;&#25490;&#24207;&#65292;&#20197;&#35299;&#20915;&#36825;&#19968;&#26032;&#20219;&#21153;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#26816;&#32034;&#19982;&#29992;&#25143;&#20449;&#24687;&#38656;&#27714;&#30456;&#20851;&#30340;&#20869;&#23481;&#12290;&#29616;&#26377;&#30340;&#20505;&#36873;&#24211;&#36890;&#24120;&#30001;&#19968;&#32452;&#24050;&#20934;&#22791;&#22909;&#30340;&#39033;&#32452;&#25104;&#65292;&#22914;&#35270;&#39057;&#12289;&#20135;&#21697;&#25110;&#25991;&#31456;&#12290;&#38543;&#30528;&#29983;&#25104;&#24335;AI&#22914;GPT&#21644;Diffusion&#27169;&#22411;&#30340;&#36817;&#26399;&#36827;&#23637;&#65292;&#36824;&#26377;&#19968;&#31181;&#26032;&#24418;&#24335;&#30340;&#25512;&#33616;&#20219;&#21153;&#24453;&#25506;&#32034;&#65292;&#21363;&#36890;&#36807;&#20010;&#24615;&#21270;&#25552;&#31034;&#30001;&#29983;&#25104;&#27169;&#22411;&#21019;&#24314;&#39033;&#12290;&#20197;&#22270;&#20687;&#29983;&#25104;&#20026;&#20363;&#65292;&#20973;&#20511;&#29992;&#25143;&#30340;&#21333;&#20010;&#25552;&#31034;&#21644;&#29983;&#25104;&#27169;&#22411;&#30340;&#35775;&#38382;&#26435;&#38480;&#65292;&#22312;&#20960;&#20998;&#38047;&#20869;&#21487;&#20197;&#29983;&#25104;&#25968;&#30334;&#20010;&#26032;&#22270;&#20687;&#12290;&#22312;&#8220;&#26080;&#38480;&#8221;&#39033;&#30340;&#23384;&#22312;&#19979;&#65292;&#25105;&#20204;&#22914;&#20309;&#23454;&#29616;&#20010;&#24615;&#21270;&#65311;&#22312;&#36825;&#39033;&#21021;&#27493;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#26694;&#26550;&#65292;&#21363;&#25552;&#31034;-&#27169;&#22411;&#26816;&#32034;&#21644;&#29983;&#25104;&#39033;&#25490;&#24207;&#65292;&#26469;&#35299;&#20915;&#36825;&#20010;&#26032;&#30340;&#20219;&#21153;&#24418;&#24335;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#19968;&#20010;&#21517;&#20026;GEMRec-18K&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#30001;200&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;18K&#22270;&#20687;&#65292;&#24182;&#19982;&#19968;&#22871;&#22810;&#26679;&#21270;&#30340;90&#20010;&#25991;&#26412;&#25552;&#31034;&#30456;&#37197;&#23545;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender Systems are built to retrieve relevant items to satisfy users' information needs. The candidate corpus usually consists of a finite set of items that are ready to be served, such as videos, products, or articles. With recent advances in Generative AI such as GPT and Diffusion models, a new form of recommendation task is yet to be explored where items are to be created by generative models with personalized prompts. Taking image generation as an example, with a single prompt from the user and access to a generative model, it is possible to generate hundreds of new images in a few minutes. How shall we attain personalization in the presence of "infinite" items? In this preliminary study, we propose a two-stage framework, namely Prompt-Model Retrieval and Generated Item Ranking, to approach this new task formulation. We release GEMRec-18K, a prompt-model interaction dataset with 18K images generated by 200 publicly-available generative models paired with a diverse set of 90 te
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.02058</link><description>&lt;p&gt;
&#25972;&#21512;&#40065;&#33725;&#34892;&#20026;&#21040;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;
&lt;/p&gt;
&lt;p&gt;
Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21253;&#21547;&#21487;&#38752;&#24615;&#27979;&#37327;&#30340;&#25512;&#33616;&#31995;&#32479;&#24448;&#24448;&#22312;&#39044;&#27979;&#20013;&#26356;&#21152;&#20445;&#23432;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20445;&#25345;&#21487;&#38752;&#24615;&#12290;&#36825;&#23548;&#33268;&#20102;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#25552;&#20379;&#30340;&#35206;&#30422;&#33539;&#22260;&#21644;&#26032;&#39062;&#24615;&#30340;&#26174;&#33879;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#30697;&#38453;&#20998;&#35299;&#22411;&#25512;&#33616;&#31995;&#32479;&#30340;&#23398;&#20064;&#36807;&#31243;&#20013;&#21152;&#20837;&#19968;&#39033;&#26032;&#30340;&#39033;&#65292;&#31216;&#20026;&#40065;&#33725;&#34892;&#20026;&#65292;&#23427;&#21487;&#20197;&#25511;&#21046;&#22312;&#20570;&#20986;&#20851;&#20110;&#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#20915;&#31574;&#26102;&#25152;&#24076;&#26395;&#30340;&#39118;&#38505;&#27700;&#24179;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#40065;&#33725;&#34892;&#20026;&#19981;&#20165;&#20801;&#35768;&#36827;&#34892;&#39118;&#38505;&#35843;&#25511;&#65292;&#36824;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#30340;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31639;&#27861;&#65292;&#29992;&#20110;&#23558;&#23395;&#33410;&#24615;&#20316;&#20026;&#20449;&#21495;&#26469;&#37325;&#26032;&#25490;&#24207;&#30005;&#23376;&#21830;&#21153;&#30340;&#33258;&#21160;&#23436;&#25104;&#21151;&#33021;&#65292;&#20174;&#32780;&#25552;&#39640;&#33258;&#21160;&#23436;&#25104;&#30340;&#30456;&#20851;&#24615;&#21644;&#19994;&#21153;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2308.02055</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#30340;&#30005;&#23376;&#21830;&#21153;&#33258;&#21160;&#23436;&#25104;&#30340;&#23395;&#33410;&#24615;&#37325;&#26032;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Seasonality Based Reranking of E-commerce Autocomplete Using Natural Language Queries. (arXiv:2308.02055v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31639;&#27861;&#65292;&#29992;&#20110;&#23558;&#23395;&#33410;&#24615;&#20316;&#20026;&#20449;&#21495;&#26469;&#37325;&#26032;&#25490;&#24207;&#30005;&#23376;&#21830;&#21153;&#30340;&#33258;&#21160;&#23436;&#25104;&#21151;&#33021;&#65292;&#20174;&#32780;&#25552;&#39640;&#33258;&#21160;&#23436;&#25104;&#30340;&#30456;&#20851;&#24615;&#21644;&#19994;&#21153;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#33258;&#21160;&#23436;&#25104;&#65288;QAC&#65289;&#20063;&#34987;&#31216;&#20026;typeahead&#65292;&#23427;&#22312;&#29992;&#25143;&#22312;&#25628;&#32034;&#26694;&#20013;&#36755;&#20837;&#21069;&#32512;&#26102;&#24314;&#35758;&#23436;&#25972;&#26597;&#35810;&#21015;&#34920;&#12290;&#23427;&#26159;&#29616;&#20195;&#25628;&#32034;&#24341;&#25806;&#29305;&#21035;&#26159;&#22312;&#30005;&#23376;&#21830;&#21153;&#39046;&#22495;&#30340;&#20851;&#38190;&#21151;&#33021;&#20043;&#19968;&#12290;typeahead&#30340;&#30446;&#26631;&#20043;&#19968;&#26159;&#21521;&#29992;&#25143;&#24314;&#35758;&#19982;&#23395;&#33410;&#24615;&#30456;&#20851;&#30340;&#37325;&#35201;&#26597;&#35810;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#31639;&#27861;&#65292;&#20197;&#23558;&#23395;&#33410;&#24615;&#20316;&#20026;&#19968;&#20010;&#20449;&#21495;&#24182;&#23545;QAC&#25490;&#24207;&#27169;&#22411;&#36827;&#34892;&#31471;&#21040;&#31471;&#35780;&#20272;&#12290;&#23558;&#23395;&#33410;&#24615;&#32435;&#20837;&#33258;&#21160;&#23436;&#25104;&#25490;&#24207;&#27169;&#22411;&#20013;&#21487;&#20197;&#25552;&#39640;&#33258;&#21160;&#23436;&#25104;&#30340;&#30456;&#20851;&#24615;&#21644;&#19994;&#21153;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Query autocomplete (QAC) also known as typeahead, suggests list of complete queries as user types prefix in the search box. It is one of the key features of modern search engines specially in e-commerce. One of the goals of typeahead is to suggest relevant queries to users which are seasonally important. In this paper we propose a neural network based natural language processing (NLP) algorithm to incorporate seasonality as a signal and present end to end evaluation of the QAC ranking model. Incorporating seasonality into autocomplete ranking model can improve autocomplete relevance and business metric.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#31995;&#32479;&#24615;&#22238;&#39038;&#20998;&#26512;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#21046;&#36896;&#19994;&#20013;&#30340;&#24212;&#29992;&#21450;&#20854;&#28508;&#22312;&#30340;&#31038;&#20250;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#21046;&#36896;&#19994;&#20013;&#20154;&#24037;&#26234;&#33021;&#30340;&#24212;&#29992;&#22810;&#26679;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#20197;&#21450;&#23545;&#21171;&#21160;&#21147;&#12289;&#32593;&#32476;&#23433;&#20840;&#24615;&#21644;&#29615;&#22659;&#30340;&#24433;&#21709;&#38656;&#35201;&#34987;&#37325;&#35270;&#12290;</title><link>http://arxiv.org/abs/2308.02025</link><description>&lt;p&gt;
&#22312;&#21046;&#36896;&#19994;&#20013;&#20154;&#24037;&#26234;&#33021;&#30340;&#24212;&#29992;&#21450;&#20854;&#31038;&#20250;&#24433;&#21709;&#65306;&#19968;&#39033;&#31995;&#32479;&#24615;&#22238;&#39038;
&lt;/p&gt;
&lt;p&gt;
Applications and Societal Implications of Artificial Intelligence in Manufacturing: A Systematic Review. (arXiv:2308.02025v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#31995;&#32479;&#24615;&#22238;&#39038;&#20998;&#26512;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#21046;&#36896;&#19994;&#20013;&#30340;&#24212;&#29992;&#21450;&#20854;&#28508;&#22312;&#30340;&#31038;&#20250;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#21046;&#36896;&#19994;&#20013;&#20154;&#24037;&#26234;&#33021;&#30340;&#24212;&#29992;&#22810;&#26679;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#20197;&#21450;&#23545;&#21171;&#21160;&#21147;&#12289;&#32593;&#32476;&#23433;&#20840;&#24615;&#21644;&#29615;&#22659;&#30340;&#24433;&#21709;&#38656;&#35201;&#34987;&#37325;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#31995;&#32479;&#22238;&#39038;&#30456;&#20851;&#25991;&#29486;&#65292;&#32771;&#34385;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#21046;&#36896;&#19994;&#22686;&#38271;&#20013;&#28508;&#22312;&#30340;&#31038;&#20250;&#24433;&#21709;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#24191;&#27867;&#30340;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#65292;&#22914;&#20225;&#19994;&#38388;&#29289;&#27969;&#21327;&#35843;&#12289;&#20844;&#21496;&#37319;&#36141;&#31649;&#29702;&#12289;&#39044;&#27979;&#24615;&#32500;&#25252;&#20197;&#21450;&#36710;&#38388;&#30417;&#25511;&#21644;&#36807;&#31243;&#12289;&#35774;&#22791;&#21644;&#21592;&#24037;&#25511;&#21046;&#31561;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#24037;&#19994;&#20154;&#24037;&#26234;&#33021;&#30340;&#19981;&#30830;&#23450;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#21253;&#25324;&#23545;&#21171;&#21160;&#21147;&#30340;&#24433;&#21709;&#12289;&#24037;&#20316;&#25552;&#21319;&#21644;&#38477;&#20302;&#12289;&#32593;&#32476;&#23433;&#20840;&#24615;&#33030;&#24369;&#24615;&#20197;&#21450;&#29615;&#22659;&#21518;&#26524;&#12290;&#22312;&#26500;&#24314;&#20102;&#21046;&#36896;&#19994;&#20013;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#30340;&#20998;&#31867;&#21518;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#19981;&#21516;&#35268;&#27169;&#21644;&#24212;&#29992;&#31867;&#22411;&#30340;&#20154;&#24037;&#26234;&#33021;&#23454;&#26045;&#30340;&#22810;&#26679;&#24615;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#32771;&#34385;&#20154;&#24037;&#26234;&#33021;&#23545;&#20010;&#20307;&#20225;&#19994;&#21644;&#25972;&#20010;&#31038;&#20250;&#30340;&#24433;&#21709;&#30340;&#37325;&#35201;&#24615;&#65292;&#28085;&#30422;&#32463;&#27982;&#32321;&#33635;&#12289;&#20844;&#24179;&#12289;&#29615;&#22659;&#20581;&#24247;&#20197;&#21450;&#31038;&#21306;&#23433;&#20840;&#12290;&#30740;&#31350;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
This paper undertakes a systematic review of relevant extant literature to consider the potential societal implications of the growth of AI in manufacturing. We analyze the extensive range of AI applications in this domain, such as interfirm logistics coordination, firm procurement management, predictive maintenance, and shop-floor monitoring and control of processes, machinery, and workers. Additionally, we explore the uncertain societal implications of industrial AI, including its impact on the workforce, job upskilling and deskilling, cybersecurity vulnerability, and environmental consequences. After building a typology of AI applications in manufacturing, we highlight the diverse possibilities for AI's implementation at different scales and application types. We discuss the importance of considering AI's implications both for individual firms and for society at large, encompassing economic prosperity, equity, environmental health, and community safety and security. The study finds 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22312;&#32447;&#24066;&#22330;&#20013;&#25340;&#20889;&#38169;&#35823;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#21644;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#20102;&#39046;&#22495;&#29305;&#23450;&#30340;&#25340;&#20889;&#26816;&#26597;&#22120;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#22312;&#24494;&#36719;AppSource&#24066;&#22330;&#30340;&#23454;&#26102;&#25512;&#26029;API&#20013;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#34920;&#26126;&#65292;&#25511;&#21046;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#25968;&#25454;&#21487;&#33021;&#25104;&#20026;&#19968;&#20010;&#26377;&#21147;&#30340;&#24037;&#20855;&#65292;&#29305;&#21035;&#26159;&#32771;&#34385;&#21040;&#24403;&#21069;&#22823;&#35821;&#35328;&#27169;&#22411;&#25152;&#20381;&#36182;&#30340;&#24040;&#22823;&#19988;&#38590;&#20197;&#25511;&#21046;&#30340;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2308.01976</link><description>&lt;p&gt;
&#25340;&#20889;&#26816;&#26597;&#22120;&#22312;&#22312;&#32447;&#24066;&#22330;&#20013;&#30340;&#39046;&#22495;&#29305;&#24322;&#24615;&#21644;&#25968;&#25454;&#25928;&#29575;&#65306;&#20197;&#22312;&#32447;&#24066;&#22330;&#25628;&#32034;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces. (arXiv:2308.01976v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01976
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22312;&#32447;&#24066;&#22330;&#20013;&#25340;&#20889;&#38169;&#35823;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#21644;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#20102;&#39046;&#22495;&#29305;&#23450;&#30340;&#25340;&#20889;&#26816;&#26597;&#22120;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#22312;&#24494;&#36719;AppSource&#24066;&#22330;&#30340;&#23454;&#26102;&#25512;&#26029;API&#20013;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#34920;&#26126;&#65292;&#25511;&#21046;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#25968;&#25454;&#21487;&#33021;&#25104;&#20026;&#19968;&#20010;&#26377;&#21147;&#30340;&#24037;&#20855;&#65292;&#29305;&#21035;&#26159;&#32771;&#34385;&#21040;&#24403;&#21069;&#22823;&#35821;&#35328;&#27169;&#22411;&#25152;&#20381;&#36182;&#30340;&#24040;&#22823;&#19988;&#38590;&#20197;&#25511;&#21046;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22312;&#32447;&#24066;&#22330;&#30340;&#39046;&#22495;&#29305;&#23450;&#24615;&#21644;&#29992;&#25143;&#30701;&#26597;&#35810;&#30340;&#29305;&#28857;&#65292;&#38169;&#23383;&#26159;&#22312;&#32447;&#24066;&#22330;&#35775;&#38382;&#32773;&#30340;&#20027;&#35201;&#22256;&#25200;&#12290;&#20256;&#32479;&#30340;&#25340;&#20889;&#26816;&#26597;&#35299;&#20915;&#26041;&#26696;&#22312;&#32416;&#27491;&#25340;&#20889;&#38169;&#35823;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#26469;&#35299;&#20915;&#32570;&#20047;&#26631;&#27880;&#25340;&#20889;&#38169;&#35823;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20102;&#19978;&#19979;&#25991;&#38480;&#21046;&#30340;&#39046;&#22495;&#29305;&#23450;&#23884;&#20837;&#12290;&#36825;&#20123;&#23884;&#20837;&#34987;&#37096;&#32626;&#22312;&#24494;&#36719;AppSource&#24066;&#22330;&#30340;&#23454;&#26102;&#25512;&#26029;API&#20013;&#65292;&#20197;&#22312;&#38169;&#35823;&#25340;&#20889;&#30340;&#29992;&#25143;&#26597;&#35810;&#21644;&#21487;&#29992;&#20135;&#21697;&#21517;&#31216;&#20043;&#38388;&#25214;&#21040;&#26368;&#25509;&#36817;&#30340;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#34920;&#26126;&#65292;&#21463;&#21040;&#24403;&#21069;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#25511;&#21046;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#25968;&#25454;&#21487;&#33021;&#25104;&#20026;&#19968;&#20010;&#26377;&#21147;&#30340;&#24037;&#20855;&#65292;&#32780;&#36825;&#20123;&#27169;&#22411;&#20381;&#36182;&#20110;&#24040;&#22823;&#19988;&#38590;&#20197;&#25511;&#21046;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Typographical errors are a major source of frustration for visitors of online marketplaces. Because of the domain-specific nature of these marketplaces and the very short queries users tend to search for, traditional spell cheking solutions do not perform well in correcting typos. We present a data augmentation method to address the lack of annotated typo data and train a recurrent neural network to learn context-limited domain-specific embeddings. Those embeddings are deployed in a real-time inferencing API for the Microsoft AppSource marketplace to find the closest match between a misspelled user query and the available product names. Our data efficient solution shows that controlled high quality synthetic data may be a powerful tool especially considering the current climate of large language models which rely on prohibitively huge and often uncontrolled datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;MultiEM&#30340;&#39640;&#25928;&#26377;&#25928;&#26080;&#30417;&#30563;&#22810;&#34920;&#23454;&#20307;&#21305;&#37197;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#22686;&#24378;&#23454;&#20307;&#34920;&#31034;&#12289;&#34920;&#32423;&#23618;&#27425;&#21512;&#24182;&#21644;&#22522;&#20110;&#23494;&#24230;&#30340;&#21098;&#26525;&#65292;&#24182;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.01927</link><description>&lt;p&gt;
MultiEM: &#39640;&#25928;&#26377;&#25928;&#30340;&#26080;&#30417;&#30563;&#22810;&#34920;&#23454;&#20307;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
MultiEM: Efficient and Effective Unsupervised Multi-Table Entity Matching. (arXiv:2308.01927v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;MultiEM&#30340;&#39640;&#25928;&#26377;&#25928;&#26080;&#30417;&#30563;&#22810;&#34920;&#23454;&#20307;&#21305;&#37197;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#22686;&#24378;&#23454;&#20307;&#34920;&#31034;&#12289;&#34920;&#32423;&#23618;&#27425;&#21512;&#24182;&#21644;&#22522;&#20110;&#23494;&#24230;&#30340;&#21098;&#26525;&#65292;&#24182;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#21305;&#37197;&#65288;EM&#65289;&#26088;&#22312;&#20174;&#20851;&#31995;&#34920;&#20013;&#35782;&#21035;&#20986;&#25351;&#21521;&#21516;&#19968;&#29616;&#23454;&#19990;&#30028;&#23454;&#20307;&#30340;&#25152;&#26377;&#23454;&#20307;&#23545;&#65292;&#23427;&#26159;&#23454;&#38469;&#25968;&#25454;&#31649;&#29702;&#31995;&#32479;&#20013;&#26368;&#37325;&#35201;&#30340;&#20219;&#21153;&#20043;&#19968;&#12290;&#30001;&#20110;EM&#30340;&#26631;&#35760;&#36807;&#31243;&#38750;&#24120;&#36153;&#26102;&#36153;&#21147;&#65292;&#30456;&#36739;&#20110;&#30417;&#30563;&#24335;EM&#65292;&#26080;&#30417;&#30563;&#24335;EM&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#26356;&#20855;&#36866;&#29992;&#24615;&#12290;&#20256;&#32479;&#30340;&#26080;&#30417;&#30563;&#24335;EM&#20551;&#35774;&#25152;&#26377;&#23454;&#20307;&#26469;&#33258;&#20004;&#20010;&#34920;&#65292;&#28982;&#32780;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#22810;&#20010;&#34920;&#20043;&#38388;&#30340;&#23454;&#20307;&#21305;&#37197;&#65288;&#22810;&#34920;EM&#65289;&#26356;&#20026;&#24120;&#35265;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#39640;&#25928;&#26377;&#25928;&#30340;&#26080;&#30417;&#30563;&#22810;&#34920;EM&#30340;&#30740;&#31350;&#23578;&#26410;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#26412;&#35770;&#25991;&#23545;&#26080;&#30417;&#30563;&#22810;&#34920;&#23454;&#20307;&#21305;&#37197;&#38382;&#39064;&#36827;&#34892;&#20102;&#27491;&#24335;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#31216;&#20026;MultiEM&#12290;MultiEM&#26159;&#19968;&#20010;&#21487;&#24182;&#34892;&#30340;&#27969;&#27700;&#32447;&#65292;&#21253;&#25324;&#22686;&#24378;&#30340;&#23454;&#20307;&#34920;&#31034;&#12289;&#22522;&#20110;&#34920;&#30340;&#23618;&#27425;&#21512;&#24182;&#21644;&#22522;&#20110;&#23494;&#24230;&#30340;&#21098;&#26525;&#12290;&#22312;&#20845;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;MultiEM&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entity Matching (EM), which aims to identify all entity pairs referring to the same real-world entity from relational tables, is one of the most important tasks in real-world data management systems. Due to the labeling process of EM being extremely labor-intensive, unsupervised EM is more applicable than supervised EM in practical scenarios. Traditional unsupervised EM assumes that all entities come from two tables; however, it is more common to match entities from multiple tables in practical applications, that is, multi-table entity matching (multi-table EM). Unfortunately, effective and efficient unsupervised multi-table EM remains under-explored. To fill this gap, this paper formally studies the problem of unsupervised multi-table entity matching and proposes an effective and efficient solution, termed as MultiEM. MultiEM is a parallelable pipeline of enhanced entity representation, table-wise hierarchical merging, and density-based pruning. Extensive experimental results on six r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#24182;&#25552;&#20379;&#35780;&#20272;&#26426;&#21046;&#65292;&#21516;&#26102;&#20063;&#32771;&#34385;&#21040;&#20102;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#26088;&#22312;&#24110;&#21161;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#22522;&#20110;&#21487;&#20449;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2307.15464</link><description>&lt;p&gt;
&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#36136;&#37327;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Framework to Automatically Determine the Quality of Open Data Catalogs. (arXiv:2307.15464v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#24182;&#25552;&#20379;&#35780;&#20272;&#26426;&#21046;&#65292;&#21516;&#26102;&#20063;&#32771;&#34385;&#21040;&#20102;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#26088;&#22312;&#24110;&#21161;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#22522;&#20110;&#21487;&#20449;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#30446;&#24405;&#22312;&#29616;&#20195;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36890;&#36807;&#20419;&#36827;&#21508;&#31181;&#25968;&#25454;&#36164;&#20135;&#30340;&#21457;&#29616;&#12289;&#29702;&#35299;&#21644;&#21033;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#24320;&#25918;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#29615;&#22659;&#20013;&#30830;&#20445;&#20854;&#36136;&#37327;&#21644;&#21487;&#38752;&#24615;&#26159;&#22797;&#26434;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35299;&#20915;&#20102;&#39640;&#25928;&#21644;&#21487;&#38752;&#30340;&#36136;&#37327;&#35780;&#20272;&#26426;&#21046;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#21508;&#31181;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#22914;&#20934;&#30830;&#24615;&#12289;&#23436;&#25972;&#24615;&#12289;&#19968;&#33268;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#21450;&#26102;&#24615;&#65292;&#25552;&#20379;&#22810;&#31181;&#35780;&#20272;&#20860;&#23481;&#24615;&#21644;&#30456;&#20284;&#24615;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20197;&#21450;&#23454;&#26045;&#19968;&#32452;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#22914;&#28335;&#28304;&#24615;&#12289;&#21487;&#35835;&#24615;&#21644;&#35768;&#21487;&#35777;&#12290;&#20854;&#30446;&#26631;&#26159;&#20351;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#33021;&#22815;&#22522;&#20110;&#21487;&#20449;&#21644;&#31934;&#24515;&#31649;&#29702;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data catalogs play a crucial role in modern data-driven organizations by facilitating the discovery, understanding, and utilization of diverse data assets. However, ensuring their quality and reliability is complex, especially in open and large-scale data environments. This paper proposes a framework to automatically determine the quality of open data catalogs, addressing the need for efficient and reliable quality assessment mechanisms. Our framework can analyze various core quality dimensions, such as accuracy, completeness, consistency, scalability, and timeliness, offer several alternatives for the assessment of compatibility and similarity across such catalogs as well as the implementation of a set of non-core quality dimensions such as provenance, readability, and licensing. The goal is to empower data-driven organizations to make informed decisions based on trustworthy and well-curated data assets. The source code that illustrates our approach can be downloaded from https://www.
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20986;&#20102;&#21028;&#21035;&#24335;LLMs&#21644;&#29983;&#25104;&#24335;LLMs&#20004;&#31181;&#27169;&#22411;&#33539;&#24335;&#65292;&#24635;&#32467;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24378;&#35843;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2305.19860</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Large Language Models for Recommendation. (arXiv:2305.19860v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20986;&#20102;&#21028;&#21035;&#24335;LLMs&#21644;&#29983;&#25104;&#24335;LLMs&#20004;&#31181;&#27169;&#22411;&#33539;&#24335;&#65292;&#24635;&#32467;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24378;&#35843;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#39046;&#22495;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#24182;&#22312;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#24341;&#36215;&#20102;&#37325;&#35270;&#12290;&#36825;&#20123;&#27169;&#22411;&#20351;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#28023;&#37327;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#24050;&#22312;&#23398;&#20064;&#36890;&#29992;&#34920;&#31034;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#30528;&#25104;&#21151;&#65292;&#24182;&#26377;&#21487;&#33021;&#36890;&#36807;&#19968;&#20123;&#26377;&#25928;&#30340;&#36716;&#31227;&#25216;&#26415;&#65288;&#22914;&#24494;&#35843;&#21644;&#25552;&#31034;&#35843;&#25972;&#65289;&#31561;&#25163;&#27573;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#21508;&#20010;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#25512;&#33616;&#36136;&#37327;&#30340;&#20851;&#38190;&#26159;&#21033;&#29992;&#23427;&#20204;&#39640;&#36136;&#37327;&#30340;&#25991;&#26412;&#29305;&#24449;&#34920;&#31034;&#21644;&#22823;&#37327;&#30340;&#22806;&#37096;&#30693;&#35782;&#35206;&#30422;&#65292;&#24314;&#31435;&#39033;&#30446;&#21644;&#29992;&#25143;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#20102;&#20840;&#38754;&#20102;&#35299;&#29616;&#26377;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#26412;&#32508;&#36848;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#27861;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#20998;&#20026;&#20004;&#31181;&#20027;&#35201;&#33539;&#24335;&#65292;&#20998;&#21035;&#26159;&#21028;&#21035;&#24335;LLMs&#21644;&#29983;&#25104;&#24335;LLMs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#36825;&#20123;&#33539;&#24335;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#24378;&#35843;&#20102;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#24320;&#25918;&#24615;&#30740;&#31350;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have emerged as powerful tools in the field of Natural Language Processing (NLP) and have recently gained significant attention in the domain of Recommendation Systems (RS). These models, trained on massive amounts of data using self-supervised learning, have demonstrated remarkable success in learning universal representations and have the potential to enhance various aspects of recommendation systems by some effective transfer techniques such as fine-tuning and prompt tuning, and so on. The crucial aspect of harnessing the power of language models in enhancing recommendation quality is the utilization of their high-quality representations of textual features and their extensive coverage of external knowledge to establish correlations between items and users. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey presents a taxonomy that categorizes these models into two major paradigms, respectively Discrimi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22270;&#20687;&#25490;&#21517;&#31639;&#27861;&#65292;&#20351;&#29992;&#32423;&#32852;&#30340;&#31070;&#32463;&#32534;&#30721;&#22120;&#26469;&#36880;&#27493;&#36807;&#28388;&#22270;&#20687;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;3&#20493;&#20197;&#19978;&#30340;TIR&#29983;&#21629;&#21608;&#26399;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2303.15595</link><description>&lt;p&gt;
&#39640;&#25928;&#22270;&#20687;&#25628;&#32034;&#30340;&#27169;&#22411;&#32423;&#32852;
&lt;/p&gt;
&lt;p&gt;
Model Cascades for Efficient Image Search. (arXiv:2303.15595v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15595
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22270;&#20687;&#25490;&#21517;&#31639;&#27861;&#65292;&#20351;&#29992;&#32423;&#32852;&#30340;&#31070;&#32463;&#32534;&#30721;&#22120;&#26469;&#36880;&#27493;&#36807;&#28388;&#22270;&#20687;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;3&#20493;&#20197;&#19978;&#30340;TIR&#29983;&#21629;&#21608;&#26399;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#31070;&#32463;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#25991;&#26412;-&#22270;&#20687;&#26816;&#32034;&#65288;TIR&#65289;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#39640;&#26114;&#30340;&#35745;&#31639;&#25104;&#26412;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#22823;&#35268;&#27169;&#22270;&#20687;&#25628;&#32034;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#20687;&#25490;&#21517;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36880;&#27493;&#22686;&#24378;&#30340;&#31070;&#32463;&#32534;&#30721;&#22120;&#32423;&#32852;&#36880;&#27493;&#25353;&#29031;&#23427;&#20204;&#19982;&#32473;&#23450;&#30340;&#25991;&#26412;&#21305;&#37197;&#30340;&#22909;&#22351;&#31243;&#24230;&#26469;&#36807;&#28388;&#22270;&#20687;&#12290; &#25105;&#20204;&#30340;&#31639;&#27861;&#23558;TIR&#30340;&#29983;&#21629;&#21608;&#26399;&#25104;&#26412;&#38477;&#20302;&#20102;3&#20493;&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern neural encoders offer unprecedented text-image retrieval (TIR) accuracy. However, their high computational cost impedes an adoption to large-scale image searches. We propose a novel image ranking algorithm that uses a cascade of increasingly powerful neural encoders to progressively filter images by how well they match a given text. Our algorithm reduces lifetime TIR costs by over 3x.
&lt;/p&gt;</description></item></channel></rss>