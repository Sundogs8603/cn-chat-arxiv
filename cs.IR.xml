<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>SSLRec&#26159;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#24211;&#65292;&#20026;&#35780;&#20272;&#21508;&#31181;SSL&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#20102;&#26631;&#20934;&#21270;&#12289;&#28789;&#27963;&#21644;&#32508;&#21512;&#30340;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2308.05697</link><description>&lt;p&gt;
SSLRec: &#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#24211;
&lt;/p&gt;
&lt;p&gt;
SSLRec: A Self-Supervised Learning Library for Recommendation. (arXiv:2308.05697v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05697
&lt;/p&gt;
&lt;p&gt;
SSLRec&#26159;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#24211;&#65292;&#20026;&#35780;&#20272;&#21508;&#31181;SSL&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#20102;&#26631;&#20934;&#21270;&#12289;&#28789;&#27963;&#21644;&#32508;&#21512;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#20316;&#20026;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#31232;&#30095;&#21644;&#22122;&#22768;&#25968;&#25454;&#25361;&#25112;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22312;&#26368;&#36817;&#20960;&#24180;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#23613;&#31649;&#35774;&#35745;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;SSL&#31639;&#27861;&#26469;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#25552;&#20379;&#26368;&#20808;&#36827;&#30340;&#25512;&#33616;&#24615;&#33021;&#65288;&#20363;&#22914;&#22270;&#21327;&#21516;&#36807;&#28388;&#12289;&#39034;&#24207;&#25512;&#33616;&#12289;&#31038;&#20132;&#25512;&#33616;&#12289;&#30693;&#35782;&#22270;&#22686;&#24378;&#25512;&#33616;&#65289;&#65292;&#20294;&#30446;&#21069;&#20173;&#32570;&#20047;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#26469;&#25972;&#21512;&#19981;&#21516;&#39046;&#22495;&#30340;&#25512;&#33616;&#31639;&#27861;&#12290;&#36825;&#26679;&#30340;&#26694;&#26550;&#21487;&#20197;&#20316;&#20026;&#33258;&#30417;&#30563;&#25512;&#33616;&#31639;&#27861;&#30340;&#22522;&#30707;&#65292;&#32479;&#19968;&#29616;&#26377;&#26041;&#27861;&#30340;&#39564;&#35777;&#65292;&#24182;&#25512;&#21160;&#26032;&#26041;&#27861;&#30340;&#35774;&#35745;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;SSLRec&#65292;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20934;&#24179;&#21488;&#65292;&#20026;&#35780;&#20272;&#21508;&#31181;SSL&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#20102;&#26631;&#20934;&#21270;&#12289;&#28789;&#27963;&#21644;&#32508;&#21512;&#30340;&#26694;&#26550;&#12290;SSLRec&#24211;&#20855;&#26377;&#27169;&#22359;&#21270;&#26550;&#26500;&#65292;&#21487;&#20197;&#26041;&#20415;&#29992;&#25143;&#35780;&#20272;&#26368;&#20808;&#36827;&#30340;&#25512;&#33616;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) has gained significant interest in recent years as a solution to address the challenges posed by sparse and noisy data in recommender systems. Despite the growing number of SSL algorithms designed to provide state-of-the-art performance in various recommendation scenarios (e.g., graph collaborative filtering, sequential recommendation, social recommendation, KG-enhanced recommendation), there is still a lack of unified frameworks that integrate recommendation algorithms across different domains. Such a framework could serve as the cornerstone for self-supervised recommendation algorithms, unifying the validation of existing methods and driving the design of new ones. To address this gap, we introduce SSLRec, a novel benchmark platform that provides a standardized, flexible, and comprehensive framework for evaluating various SSL-enhanced recommenders. The SSLRec library features a modular architecture that allows users to easily evaluate state-of-the-art m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#21019;&#24314;&#26032;&#30340;&#25968;&#25454;&#38598;&#12289;&#35780;&#20272;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#20197;&#21450;&#25552;&#20986;&#22810;&#38454;&#27573;&#26694;&#26550;&#26469;&#35299;&#20915;&#20102;&#36328;&#35821;&#35328;&#28548;&#28165;&#26816;&#32034;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.05680</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#38454;&#27573;&#26816;&#32034;&#25214;&#21040;&#24050;&#32463;&#34987;&#28548;&#28165;&#30340;&#21465;&#36848;&#65306;&#23454;&#29616;&#36328;&#35821;&#35328;&#12289;&#36328;&#25968;&#25454;&#38598;&#21644;&#38646;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning. (arXiv:2308.05680v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#21019;&#24314;&#26032;&#30340;&#25968;&#25454;&#38598;&#12289;&#35780;&#20272;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#20197;&#21450;&#25552;&#20986;&#22810;&#38454;&#27573;&#26694;&#26550;&#26469;&#35299;&#20915;&#20102;&#36328;&#35821;&#35328;&#28548;&#28165;&#26816;&#32034;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#24050;&#32463;&#34987;&#28548;&#28165;&#30340;&#21465;&#36848;&#30340;&#20219;&#21153;&#26088;&#22312;&#26816;&#27979;&#24050;&#32463;&#32463;&#36807;&#20107;&#23454;&#26680;&#26597;&#30340;&#25925;&#20107;&#12290;&#25104;&#21151;&#26816;&#27979;&#21040;&#24050;&#34987;&#28548;&#28165;&#30340;&#22768;&#26126;&#19981;&#20165;&#20943;&#23569;&#20102;&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#20154;&#21592;&#30340;&#25163;&#21160;&#21162;&#21147;&#65292;&#36824;&#21487;&#20197;&#26377;&#21161;&#20110;&#20943;&#32531;&#34394;&#20551;&#20449;&#24687;&#30340;&#20256;&#25773;&#12290;&#30001;&#20110;&#32570;&#20047;&#21487;&#29992;&#25968;&#25454;&#65292;&#36825;&#26159;&#19968;&#20010;&#30740;&#31350;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#32771;&#34385;&#36328;&#35821;&#35328;&#20219;&#21153;&#26102;&#65292;&#21363;&#22312;&#26816;&#26597;&#30340;&#22312;&#32447;&#24086;&#23376;&#30340;&#35821;&#35328;&#19982;&#20107;&#23454;&#26680;&#26597;&#25991;&#31456;&#30340;&#35821;&#35328;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#26816;&#32034;&#12290;&#26412;&#25991;&#36890;&#36807;&#20197;&#19979;&#26041;&#24335;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65306;&#65288;i&#65289;&#21019;&#24314;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#20801;&#35768;&#23545;&#24050;&#34987;&#28548;&#28165;&#30340;&#21465;&#36848;&#36827;&#34892;&#36328;&#35821;&#35328;&#26816;&#32034;&#30340;&#30740;&#31350;&#65292;&#20351;&#29992;&#25512;&#25991;&#20316;&#20026;&#23545;&#20107;&#23454;&#26680;&#26597;&#25991;&#31456;&#25968;&#25454;&#24211;&#30340;&#26597;&#35810;&#65307;&#65288;ii&#65289;&#23637;&#31034;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#20197;&#35780;&#20272;&#32463;&#36807;&#24494;&#35843;&#21644;&#29616;&#25104;&#30340;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#65307;&#65288;iii&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22810;&#38454;&#27573;&#26694;&#26550;&#65292;&#23558;&#36825;&#20010;&#36328;&#35821;&#35328;&#28548;&#28165;&#26816;&#32034;&#38382;&#39064;&#21010;&#20998;&#20026;&#19981;&#21516;&#30340;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;
The task of retrieving already debunked narratives aims to detect stories that have already been fact-checked. The successful detection of claims that have already been debunked not only reduces the manual efforts of professional fact-checkers but can also contribute to slowing the spread of misinformation. Mainly due to the lack of readily available data, this is an understudied problem, particularly when considering the cross-lingual task, i.e. the retrieval of fact-checking articles in a language different from the language of the online post being checked. This paper fills this gap by (i) creating a novel dataset to enable research on cross-lingual retrieval of already debunked narratives, using tweets as queries to a database of fact-checking articles; (ii) presenting an extensive experiment to benchmark fine-tuned and off-the-shelf multilingual pre-trained Transformer models for this task; and (iii) proposing a novel multistage framework that divides this cross-lingual debunk ret
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;LASIGE&#21644;UNICAGE&#22312;NASA LitCoin NLP&#31454;&#36187;&#20013;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23558;&#20135;&#19994;&#30028;&#30340;&#25968;&#25454;&#24037;&#31243;&#35299;&#20915;&#26041;&#26696;&#19982;&#23398;&#26415;&#30028;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#21644;&#20851;&#31995;&#25277;&#21462;&#31995;&#32479;&#25972;&#21512;&#65292;&#25104;&#21151;&#22320;&#22312;&#22823;&#35268;&#27169;&#30340;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#22788;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.05609</link><description>&lt;p&gt;
LASIGE&#21644;UNICAGE&#35299;&#20915;NASA LitCoin NLP&#31454;&#36187;&#30340;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
LASIGE and UNICAGE solution to the NASA LitCoin NLP Competition. (arXiv:2308.05609v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;LASIGE&#21644;UNICAGE&#22312;NASA LitCoin NLP&#31454;&#36187;&#20013;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23558;&#20135;&#19994;&#30028;&#30340;&#25968;&#25454;&#24037;&#31243;&#35299;&#20915;&#26041;&#26696;&#19982;&#23398;&#26415;&#30028;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#21644;&#20851;&#31995;&#25277;&#21462;&#31995;&#32479;&#25972;&#21512;&#65292;&#25104;&#21151;&#22320;&#22312;&#22823;&#35268;&#27169;&#30340;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#22788;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22823;&#22810;&#25968;&#30740;&#31350;&#20154;&#21592;&#26469;&#35828;&#65292;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#24448;&#24448;&#21464;&#24471;&#32321;&#29712;&#65292;&#24448;&#24448;&#26159;&#22240;&#20026;&#38656;&#35201;&#22788;&#29702;&#30340;&#25991;&#26412;&#25968;&#37327;&#21644;&#24322;&#36136;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#34892;&#19994;&#19981;&#26029;&#24320;&#21457;&#39640;&#25928;&#30340;&#24037;&#20855;&#24182;&#21019;&#24314;&#26356;&#28789;&#27963;&#30340;&#24037;&#31243;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#34892;&#19994;&#25968;&#25454;&#24037;&#31243;&#35299;&#20915;&#26041;&#26696;&#19982;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;LasigeUnicage_NER&#65289;&#21644;&#20851;&#31995;&#25277;&#21462;&#65288;BiOnt&#65289;&#30340;&#23398;&#26415;&#31995;&#32479;&#30340;&#25972;&#21512;&#12290;&#25105;&#20204;&#30340;&#35774;&#35745;&#21453;&#26144;&#20102;&#36825;&#20123;&#32452;&#20214;&#19982;&#20854;&#20182;&#25968;&#25454;&#38598;&#21644;&#29983;&#29289;&#21307;&#23398;&#26412;&#20307;&#30340;&#39069;&#22806;&#35757;&#32451;&#25968;&#25454;&#30340;&#22806;&#37096;&#30693;&#35782;&#30340;&#25972;&#21512;&#12290;&#25105;&#20204;&#22312;2022&#24180;LitCoin NLP&#25361;&#25112;&#36187;&#20013;&#20351;&#29992;&#20102;&#36825;&#20010;&#27969;&#27700;&#32447;&#65292;&#25105;&#20204;&#30340;&#22242;&#38431;LasigeUnicage&#33719;&#24471;&#20102;&#31532;&#19971;&#21517;&#22870;&#39033;&#65292;&#32422;&#26377;200&#20010;&#21442;&#36187;&#22242;&#38431;&#65292;&#21453;&#26144;&#20102;&#23398;&#26415;&#30028;&#65288;LASIGE&#65289;&#21644;&#20135;&#19994;&#30028;&#65288;Unicage&#65289;&#20043;&#38388;&#30340;&#25104;&#21151;&#21512;&#20316;&#12290;&#25903;&#25345;&#36825;&#39033;&#24037;&#20316;&#30340;&#36719;&#20214;&#21487;&#22312;
&lt;/p&gt;
&lt;p&gt;
Biomedical Natural Language Processing (NLP) tends to become cumbersome for most researchers, frequently due to the amount and heterogeneity of text to be processed. To address this challenge, the industry is continuously developing highly efficient tools and creating more flexible engineering solutions. This work presents the integration between industry data engineering solutions for efficient data processing and academic systems developed for Named Entity Recognition (LasigeUnicage\_NER) and Relation Extraction (BiOnt). Our design reflects an integration of those components with external knowledge in the form of additional training data from other datasets and biomedical ontologies. We used this pipeline in the 2022 LitCoin NLP Challenge, where our team LasigeUnicage was awarded the 7th Prize out of approximately 200 participating teams, reflecting a successful collaboration between the academia (LASIGE) and the industry (Unicage). The software supporting this work is available at \
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#39046;&#22495;&#25512;&#33616;&#26041;&#27861;EDDA&#65292;&#23427;&#36890;&#36807;&#23884;&#20837;&#35299;&#32806;&#25512;&#33616;&#22120;&#21644;&#39046;&#22495;&#23545;&#40784;&#20004;&#20010;&#20851;&#38190;&#32452;&#20214;&#20998;&#21035;&#35299;&#20915;&#20102;&#30693;&#35782;&#35299;&#32806;&#21644;&#36328;&#39046;&#22495;&#30693;&#35782;&#36716;&#31227;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.05508</link><description>&lt;p&gt;
&#22810;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#23884;&#20837;&#35299;&#32806;&#19982;&#39046;&#22495;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Multi-domain Recommendation with Embedding Disentangling and Domain Alignment. (arXiv:2308.05508v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05508
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#39046;&#22495;&#25512;&#33616;&#26041;&#27861;EDDA&#65292;&#23427;&#36890;&#36807;&#23884;&#20837;&#35299;&#32806;&#25512;&#33616;&#22120;&#21644;&#39046;&#22495;&#23545;&#40784;&#20004;&#20010;&#20851;&#38190;&#32452;&#20214;&#20998;&#21035;&#35299;&#20915;&#20102;&#30693;&#35782;&#35299;&#32806;&#21644;&#36328;&#39046;&#22495;&#30693;&#35782;&#36716;&#31227;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#39046;&#22495;&#25512;&#33616;(MDR)&#26088;&#22312;&#20026;&#20855;&#26377;&#37325;&#21472;&#29992;&#25143;/&#29289;&#21697;&#30340;&#19981;&#21516;&#39046;&#22495;(&#20363;&#22914;&#20135;&#21697;&#31867;&#22411;)&#25552;&#20379;&#25512;&#33616;&#65292;&#23545;&#20110;&#25317;&#26377;&#22810;&#20010;&#26381;&#21153;&#30340;&#24179;&#21488;&#22914;&#20122;&#39532;&#36874;&#12289;Facebook&#21644;LinkedIn&#26159;&#24120;&#35265;&#30340;&#12290;&#29616;&#26377;&#30340;MDR&#27169;&#22411;&#38754;&#20020;&#20004;&#20010;&#25361;&#25112;&#65306;&#39318;&#20808;&#65292;&#24456;&#38590;&#35299;&#32806;&#21487;&#20197;&#27867;&#21270;&#21040;&#25152;&#26377;&#39046;&#22495;&#30340;&#30693;&#35782;(&#20363;&#22914;&#65292;&#29992;&#25143;&#21916;&#27426;&#24265;&#20215;&#30340;&#29289;&#21697;)&#19982;&#29305;&#23450;&#20110;&#21333;&#20010;&#39046;&#22495;&#30340;&#30693;&#35782;(&#20363;&#22914;&#65292;&#29992;&#25143;&#21916;&#27426;&#34013;&#33394;&#30340;&#26381;&#35013;&#20294;&#19981;&#21916;&#27426;&#34013;&#33394;&#30340;&#27773;&#36710;)&#12290;&#20854;&#27425;&#65292;&#23427;&#20204;&#22312;&#20855;&#26377;&#23567;&#37325;&#21472;&#30340;&#39046;&#22495;&#20043;&#38388;&#36716;&#31227;&#30693;&#35782;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EDDA&#30340;&#26032;&#30340;MDR&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#21547;&#20004;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#21363;&#23884;&#20837;&#35299;&#32806;&#25512;&#33616;&#22120;&#21644;&#39046;&#22495;&#23545;&#40784;&#65292;&#20998;&#21035;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#25361;&#25112;&#12290;&#29305;&#21035;&#22320;&#65292;&#23884;&#20837;&#35299;&#32806;&#25512;&#33616;&#22120;&#20998;&#31163;&#20102;&#36328;&#39046;&#22495;&#37096;&#20998;&#21644;&#21333;&#39046;&#22495;&#37096;&#20998;&#30340;&#27169;&#22411;&#21644;&#23884;&#20837;&#65292;&#32780;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;MDR&#26041;&#27861;&#21482;&#20851;&#27880;&#27169;&#22411;&#23618;&#38754;&#30340;&#35299;&#32806;&#12290;&#39046;&#22495;&#23545;&#40784;&#20351;&#29992;&#39046;&#22495;&#29305;&#23450;&#30340;&#23545;&#25239;&#35757;&#32451;&#26469;&#25552;&#21319;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-domain recommendation (MDR) aims to provide recommendations for different domains (e.g., types of products) with overlapping users/items and is common for platforms such as Amazon, Facebook, and LinkedIn that host multiple services. Existing MDR models face two challenges: First, it is difficult to disentangle knowledge that generalizes across domains (e.g., a user likes cheap items) and knowledge specific to a single domain (e.g., a user likes blue clothing but not blue cars). Second, they have limited ability to transfer knowledge across domains with small overlaps. We propose a new MDR method named EDDA with two key components, i.e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively. In particular, the embedding disentangling recommender separates both the model and embedding for the inter-domain part and the intra-domain part, while most existing MDR methods only focus on model-level disentangling. The domain alignment leverag
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#23545;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#27861;&#24459;&#39046;&#22495;&#30340;&#20154;&#24037;&#26234;&#33021;&#38382;&#39064;&#21644;&#20219;&#21153;&#20013;&#30340;&#26041;&#27861;&#30340;&#31995;&#32479;&#27010;&#36848;&#12290;&#25991;&#31456;&#26088;&#22312;&#31361;&#20986;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#20197;&#36827;&#19968;&#27493;&#20102;&#35299;Transformer&#22312;&#25903;&#25345;&#27861;&#24459;&#27969;&#31243;&#20013;&#30340;AI&#25104;&#21151;&#36129;&#29486;&#20197;&#21450;&#24403;&#21069;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05502</link><description>&lt;p&gt;
&#23558;&#39034;&#24207;&#24102;&#20837;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#29992;&#20110;&#20154;&#24037;&#26234;&#33021;&#21644;&#27861;&#24459;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Bringing order into the realm of Transformer-based language models for artificial intelligence and law. (arXiv:2308.05502v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05502
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#23545;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#27861;&#24459;&#39046;&#22495;&#30340;&#20154;&#24037;&#26234;&#33021;&#38382;&#39064;&#21644;&#20219;&#21153;&#20013;&#30340;&#26041;&#27861;&#30340;&#31995;&#32479;&#27010;&#36848;&#12290;&#25991;&#31456;&#26088;&#22312;&#31361;&#20986;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#20197;&#36827;&#19968;&#27493;&#20102;&#35299;Transformer&#22312;&#25903;&#25345;&#27861;&#24459;&#27969;&#31243;&#20013;&#30340;AI&#25104;&#21151;&#36129;&#29486;&#20197;&#21450;&#24403;&#21069;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;TLM&#65289;&#34987;&#24191;&#27867;&#35748;&#21487;&#26159;&#19968;&#31181;&#20808;&#36827;&#30340;&#25216;&#26415;&#65292;&#33021;&#22815;&#25104;&#21151;&#24320;&#21457;&#20986;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#38656;&#35201;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#29702;&#35299;&#30340;&#38382;&#39064;&#21644;&#24212;&#29992;&#12290;&#19982;&#20854;&#20182;&#25991;&#26412;&#39046;&#22495;&#19968;&#26679;&#65292;TLM&#30830;&#23454;&#25512;&#21160;&#20102;&#27861;&#24459;&#39046;&#22495;&#35768;&#22810;&#24863;&#20852;&#36259;&#20219;&#21153;&#23545;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#23613;&#31649;&#31532;&#19968;&#20010;Transformer&#27169;&#22411;&#25552;&#20986;&#20102;&#22823;&#32422;6&#24180;&#26102;&#38388;&#65292;&#20294;&#36825;&#39033;&#25216;&#26415;&#20197;&#21069;&#25152;&#26410;&#26377;&#30340;&#36895;&#24230;&#36805;&#29467;&#21457;&#23637;&#65292;BERT&#21644;&#30456;&#20851;&#27169;&#22411;&#25104;&#20026;&#20027;&#35201;&#21442;&#32771;&#65292;&#20063;&#22312;&#27861;&#24459;&#39046;&#22495;&#21344;&#26377;&#37325;&#35201;&#22320;&#20301;&#12290;&#26412;&#25991;&#39318;&#27425;&#31995;&#32479;&#27010;&#36848;&#20102;TLM&#22312;&#27861;&#24459;&#39046;&#22495;&#30340;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#38382;&#39064;&#21644;&#20219;&#21153;&#20013;&#30340;&#26041;&#27861;&#12290;&#19968;&#20010;&#20027;&#35201;&#30446;&#26631;&#26159;&#31361;&#20986;&#30740;&#31350;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#36827;&#23637;&#65292;&#20197;&#20415;&#19968;&#26041;&#38754;&#20102;&#35299;Transformer&#22312;&#25903;&#25345;&#27861;&#24459;&#27969;&#31243;&#20013;&#21462;&#24471;&#30340;AI&#25104;&#21151;&#36129;&#29486;&#26159;&#20160;&#20040;&#65292;&#21478;&#19968;&#26041;&#38754;&#20102;&#35299;&#24403;&#21069;&#30340;&#23616;&#38480;&#24615;&#26159;&#20160;&#20040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the state-of-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#26102;&#23578;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#30340;&#20135;&#21697;&#35780;&#35770;&#22270;&#29255;&#25490;&#24207;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#33021;&#22815;&#23558;&#26368;&#30456;&#20851;&#30340;&#22270;&#29255;&#26174;&#31034;&#22312;&#21069;&#38754;&#65292;&#23545;&#29992;&#25143;&#30340;&#22312;&#32447;&#36141;&#29289;&#36873;&#25321;&#21644;&#34892;&#20026;&#20135;&#29983;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2308.05390</link><description>&lt;p&gt;
&#26102;&#23578;&#30005;&#23376;&#21830;&#21153;&#20013;&#30340;&#20135;&#21697;&#35780;&#35770;&#22270;&#29255;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Product Review Image Ranking for Fashion E-commerce. (arXiv:2308.05390v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05390
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26102;&#23578;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#30340;&#20135;&#21697;&#35780;&#35770;&#22270;&#29255;&#25490;&#24207;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#33021;&#22815;&#23558;&#26368;&#30456;&#20851;&#30340;&#22270;&#29255;&#26174;&#31034;&#22312;&#21069;&#38754;&#65292;&#23545;&#29992;&#25143;&#30340;&#22312;&#32447;&#36141;&#29289;&#36873;&#25321;&#21644;&#34892;&#20026;&#20135;&#29983;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#20010;&#26102;&#23578;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#65292;&#39038;&#23458;&#26080;&#27861;&#20146;&#33258;&#26816;&#26597;&#20135;&#21697;&#65292;&#22240;&#27492;&#33021;&#22815;&#30475;&#21040;&#20854;&#20182;&#39038;&#23458;&#23545;&#20135;&#21697;&#30340;&#25991;&#23383;&#21644;&#22270;&#29255;&#35780;&#35770;&#22312;&#20570;&#36141;&#20080;&#20915;&#31574;&#26102;&#38750;&#24120;&#37325;&#35201;&#12290;&#38543;&#30528;&#29992;&#25143;&#29983;&#25104;&#20869;&#23481;&#30340;&#22686;&#21152;&#65292;&#23458;&#25143;&#22270;&#20687;&#30340;&#25968;&#37327;&#20063;&#30456;&#24212;&#22686;&#21152;&#65292;&#22240;&#27492;&#23558;&#26368;&#30456;&#20851;&#30340;&#22270;&#29255;&#26174;&#31034;&#22312;&#21069;&#38754;&#23545;&#20110;&#29992;&#25143;&#30340;&#22312;&#32447;&#36141;&#29289;&#36873;&#25321;&#21644;&#34892;&#20026;&#21487;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#29992;&#20110;&#25490;&#21517;&#39038;&#23458;&#22270;&#20687;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#21360;&#24230;&#20027;&#35201;&#26102;&#23578;&#30005;&#23376;&#21830;&#21153;&#20844;&#21496;Myntra&#30340;&#24037;&#20316;&#23460;&#24086;&#23376;&#21644;&#39640;&#24230;&#21442;&#19982;&#65288;&#39030;/&#36393;&#65289;&#30340;&#29992;&#25143;&#29983;&#25104;&#20869;&#23481;&#22270;&#20687;&#65292;&#24182;&#23545;&#19978;&#36848;&#25968;&#25454;&#38598;&#30340;&#22270;&#20687;&#20351;&#29992;&#20102;&#36873;&#25321;&#30340;&#25197;&#26354;&#25216;&#26415;&#65292;&#20351;&#23427;&#20204;&#30340;&#36136;&#37327;&#36798;&#21040;&#19982;&#20302;&#36136;&#37327;&#30340;UGC&#22270;&#20687;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a fashion e-commerce platform where customers can't physically examine the products on their own, being able to see other customers' text and image reviews of the product is critical while making purchase decisions. Given the high reliance on these reviews, over the years we have observed customers proactively sharing their reviews. With an increase in the coverage of User Generated Content (UGC), there has been a corresponding increase in the number of customer images. It is thus imperative to display the most relevant images on top as it may influence users' online shopping choices and behavior. In this paper, we propose a simple yet effective training procedure for ranking customer images. We created a dataset consisting of Myntra (A Major Indian Fashion e-commerce company) studio posts and highly engaged (upvotes/downvotes) UGC images as our starting point and used selected distortion techniques on the images of the above dataset to bring their quality at par with those of bad U
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#22686;&#24378;&#30340;&#30456;&#20851;&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#65292;&#26469;&#25913;&#36827;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#26597;&#35810;-&#39033;&#30446;&#21305;&#37197;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05379</link><description>&lt;p&gt;
&#36229;&#36234;&#35821;&#20041;&#65306;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#30340;&#34892;&#20026;&#22686;&#24378;&#30456;&#20851;&#27169;&#22411;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning. (arXiv:2308.05379v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05379
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#22686;&#24378;&#30340;&#30456;&#20851;&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#65292;&#26469;&#25913;&#36827;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#26597;&#35810;-&#39033;&#30446;&#21305;&#37197;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#24314;&#27169;&#26088;&#22312;&#23450;&#20301;&#19982;&#23545;&#24212;&#26597;&#35810;&#30456;&#20851;&#30340;&#29702;&#24819;&#39033;&#30446;&#65292;&#36825;&#23545;&#20110;&#25628;&#32034;&#24341;&#25806;&#30830;&#20445;&#29992;&#25143;&#20307;&#39564;&#38750;&#24120;&#37325;&#35201;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#20256;&#32479;&#26041;&#27861;&#36890;&#36807;&#35780;&#20272;&#26597;&#35810;&#19982;&#39033;&#30446;&#20043;&#38388;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#32431;&#35821;&#20041;&#21305;&#37197;&#24182;&#19981;&#26159;&#21807;&#19968;&#30340;&#26041;&#27861;&#12290;&#23454;&#38469;&#19978;&#65292;&#20174;&#29992;&#25143;&#25628;&#32034;&#35760;&#24405;&#30340;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#30340;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#21487;&#20197;&#25552;&#20379;&#36827;&#19968;&#27493;&#25581;&#31034;&#29992;&#25143;&#25628;&#32034;&#24847;&#22270;&#30340;&#32447;&#32034;&#12290;&#24471;&#30410;&#20110;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#34892;&#20026;&#22686;&#24378;&#30456;&#20851;&#23398;&#20064;&#27169;&#22411;&#30340;&#25903;&#20184;&#23453;&#25628;&#32034;&#27169;&#22411;&#65288;BARL-ASe&#65289;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#30446;&#26631;&#39033;&#30446;&#30340;&#30456;&#37051;&#26597;&#35810;&#21644;&#30446;&#26631;&#26597;&#35810;&#30340;&#30456;&#37051;&#39033;&#30446;&#26469;&#34917;&#20805;&#30446;&#26631;&#26597;&#35810;-&#39033;&#30446;&#30340;&#35821;&#20041;&#21305;&#37197;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#24314;&#31435;&#20102;&#22810;&#23618;&#20849;&#21516;&#27880;&#24847;&#21147;&#65292;&#20174;&#30456;&#37051;&#21644;&#30446;&#26631;&#35270;&#22270;&#20013;&#25552;&#21462;&#20102;&#31895;&#31890;&#24230;&#21644;&#32454;&#31890;&#24230;&#30340;&#35821;&#20041;&#34920;&#31034;&#12290;&#27169;&#22411;&#38543;&#21518;&#37319;&#29992;&#37051;&#23621;-&#30446;&#26631;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#26469;&#25552;&#39640;&#31934;&#24230;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robu
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#21644;SIR&#27169;&#22411;&#30740;&#31350;&#20102;2020&#24180;&#35199;&#37096;&#32654;&#22269;&#28779;&#28798;&#23395;&#30340;&#28798;&#23475;&#21709;&#24212;&#12290;&#30740;&#31350;&#21457;&#29616;Twitter&#29992;&#25143;&#20027;&#35201;&#20851;&#27880;&#20581;&#24247;&#24433;&#21709;&#12289;&#25439;&#22833;&#21644;&#25764;&#31163;&#19977;&#20010;&#20027;&#39064;&#65292;&#24182;&#20351;&#29992;SIR&#29702;&#35770;&#25506;&#32034;&#20102;&#36825;&#20123;&#20027;&#39064;&#22312;Twitter&#19978;&#30340;&#20256;&#25773;&#35268;&#27169;&#21644;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.05281</link><description>&lt;p&gt;
&#36890;&#36807;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#21644;&#26131;&#24863;-&#24863;&#26579;-&#24247;&#22797;&#65288;SIR&#65289;&#27169;&#22411;&#30740;&#31350;&#28798;&#23475;&#21709;&#24212;&#65306;&#20197;2020&#24180;&#35199;&#37096;&#32654;&#22269;&#28779;&#28798;&#23395;&#20026;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season. (arXiv:2308.05281v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05281
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#21644;SIR&#27169;&#22411;&#30740;&#31350;&#20102;2020&#24180;&#35199;&#37096;&#32654;&#22269;&#28779;&#28798;&#23395;&#30340;&#28798;&#23475;&#21709;&#24212;&#12290;&#30740;&#31350;&#21457;&#29616;Twitter&#29992;&#25143;&#20027;&#35201;&#20851;&#27880;&#20581;&#24247;&#24433;&#21709;&#12289;&#25439;&#22833;&#21644;&#25764;&#31163;&#19977;&#20010;&#20027;&#39064;&#65292;&#24182;&#20351;&#29992;SIR&#29702;&#35770;&#25506;&#32034;&#20102;&#36825;&#20123;&#20027;&#39064;&#22312;Twitter&#19978;&#30340;&#20256;&#25773;&#35268;&#27169;&#21644;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#30340;&#28798;&#23475;&#21709;&#24212;&#23545;&#21463;&#24433;&#21709;&#30340;&#31038;&#21306;&#33267;&#20851;&#37325;&#35201;&#12290;&#24212;&#24613;&#20154;&#21592;&#21644;&#20915;&#31574;&#32773;&#22312;&#28798;&#23475;&#26399;&#38388;&#22312;&#20102;&#35299;&#31038;&#21306;&#25152;&#38754;&#20020;&#38382;&#39064;&#30340;&#21487;&#38752;&#21644;&#21450;&#26102;&#30340;&#25351;&#26631;&#19978;&#23558;&#21463;&#30410;&#20110;&#31038;&#20132;&#23186;&#20307;&#25552;&#20379;&#30340;&#20016;&#23500;&#25968;&#25454;&#26469;&#28304;&#12290;&#31038;&#20132;&#23186;&#20307;&#21487;&#20197;&#21453;&#26144;&#20844;&#20247;&#20851;&#27880;&#21644;&#38656;&#27714;&#65292;&#20026;&#20915;&#31574;&#32773;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#27934;&#35265;&#65292;&#20197;&#20102;&#35299;&#19981;&#26029;&#28436;&#21464;&#30340;&#24773;&#20917;&#24182;&#20248;&#21270;&#36164;&#28304;&#37197;&#32622;&#12290;&#25105;&#20204;&#20351;&#29992;&#21452;&#21521;&#32534;&#30721;&#22120;&#34920;&#31034;&#36716;&#25442;&#65288;BERT&#65289;&#20027;&#39064;&#24314;&#27169;&#23545;Twitter&#25968;&#25454;&#36827;&#34892;&#20027;&#39064;&#32858;&#31867;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#26102;&#38388;-&#31354;&#38388;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;&#36825;&#20123;&#20027;&#39064;&#22312;2020&#24180;&#32654;&#22269;&#35199;&#37096;&#28779;&#28798;&#23395;&#26399;&#38388;&#22312;&#19981;&#21516;&#22320;&#21306;&#30340;&#20998;&#24067;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;Twitter&#29992;&#25143;&#20027;&#35201;&#20851;&#27880;&#19977;&#20010;&#20027;&#39064;&#65306;&#8220;&#20581;&#24247;&#24433;&#21709;&#8221;&#65292;&#8220;&#25439;&#22833;&#8221;&#65292;&#8220;&#25764;&#31163;&#8221;&#12290;&#25105;&#20204;&#20351;&#29992;&#26131;&#24863;-&#24863;&#26579;-&#24247;&#22797;&#65288;SIR&#65289;&#29702;&#35770;&#26469;&#25506;&#32034;&#20027;&#39064;&#22312;Twitter&#19978;&#30340;&#20256;&#25773;&#35268;&#27169;&#21644;&#36895;&#24230;&#12290;&#32467;&#26524;&#28165;&#26224;&#22320;&#26174;&#31034;&#20102;&#20027;&#39064;&#20256;&#25773;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Effective disaster response is critical for affected communities. Responders and decision-makers would benefit from reliable, timely measures of the issues impacting their communities during a disaster, and social media offers a potentially rich data source. Social media can reflect public concerns and demands during a disaster, offering valuable insights for decision-makers to understand evolving situations and optimize resource allocation. We used Bidirectional Encoder Representations from Transformers (BERT) topic modeling to cluster topics from Twitter data. Then, we conducted a temporal-spatial analysis to examine the distribution of these topics across different regions during the 2020 western U.S. wildfire season. Our results show that Twitter users mainly focused on three topics:"health impact," "damage," and "evacuation." We used the Susceptible-Infected-Recovered (SIR) theory to explore the magnitude and velocity of topic diffusion on Twitter. The results displayed a clear re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29992;&#25143;&#21442;&#19982;&#32676;&#32452;&#30340;&#28608;&#21169;&#24847;&#22270;&#65292;&#21253;&#25324;&#31038;&#20132;&#24847;&#22270;&#21644;&#20010;&#20154;&#20852;&#36259;&#24847;&#22270;&#65292;&#24182;&#25552;&#20986;&#20102;&#21452;&#37325;&#24847;&#22270;&#22270;&#27169;&#22411;&#26469;&#36827;&#34892;&#29992;&#25143;&#20013;&#24515;&#30340;&#32676;&#32452;&#21457;&#29616;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2308.05013</link><description>&lt;p&gt;
&#29992;&#25143;&#20013;&#24515;&#30340;&#32676;&#32452;&#21457;&#29616;&#30340;&#21452;&#37325;&#24847;&#22270;&#22270;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Dual Intents Graph Modeling for User-centric Group Discovery. (arXiv:2308.05013v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05013
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29992;&#25143;&#21442;&#19982;&#32676;&#32452;&#30340;&#28608;&#21169;&#24847;&#22270;&#65292;&#21253;&#25324;&#31038;&#20132;&#24847;&#22270;&#21644;&#20010;&#20154;&#20852;&#36259;&#24847;&#22270;&#65292;&#24182;&#25552;&#20986;&#20102;&#21452;&#37325;&#24847;&#22270;&#22270;&#27169;&#22411;&#26469;&#36827;&#34892;&#29992;&#25143;&#20013;&#24515;&#30340;&#32676;&#32452;&#21457;&#29616;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#32676;&#32452;&#36234;&#26469;&#36234;&#26222;&#36941;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#20102;&#20998;&#20139;&#32463;&#39564;&#21644;&#25506;&#32034;&#20852;&#36259;&#30340;&#31354;&#38388;&#12290;&#22240;&#27492;&#65292;&#29992;&#25143;&#20013;&#24515;&#30340;&#32676;&#32452;&#21457;&#29616;&#20219;&#21153;&#65292;&#21363;&#21521;&#29992;&#25143;&#25512;&#33616;&#32676;&#32452;&#65292;&#21487;&#20197;&#24110;&#21161;&#29992;&#25143;&#30340;&#22312;&#32447;&#20307;&#39564;&#21644;&#24179;&#21488;&#30340;&#38271;&#26399;&#21457;&#23637;&#12290;&#29616;&#26377;&#30340;&#25512;&#33616;&#26041;&#27861;&#19981;&#33021;&#22788;&#29702;&#36825;&#20010;&#20219;&#21153;&#65292;&#22240;&#20026;&#23558;&#29992;&#25143;-&#32676;&#32452;&#21442;&#19982;&#24314;&#27169;&#25104;&#19968;&#20010;&#20108;&#37096;&#22270;&#24573;&#35270;&#20102;&#20182;&#20204;&#30340;&#39033;&#30446;&#20391;&#20852;&#36259;&#12290;&#34429;&#28982;&#26377;&#19968;&#20123;&#20316;&#21697;&#35797;&#22270;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#20294;&#20173;&#28982;&#19981;&#36275;&#20197;&#23436;&#20840;&#20445;&#30041;&#31038;&#20132;&#19978;&#19979;&#25991;&#24182;&#30830;&#20445;&#26377;&#25928;&#30340;&#20852;&#36259;&#34920;&#31034;&#23398;&#20064;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#28608;&#21169;&#29992;&#25143;&#21442;&#19982;&#32676;&#32452;&#30340;&#24847;&#22270;&#65292;&#36825;&#20123;&#24847;&#22270;&#21487;&#20197;&#20998;&#20026;&#19981;&#21516;&#31867;&#22411;&#65292;&#22914;&#31038;&#20132;&#24847;&#22270;&#21644;&#20010;&#20154;&#20852;&#36259;&#24847;&#22270;&#12290;&#21069;&#32773;&#25351;&#30340;&#26159;&#29992;&#25143;&#21152;&#20837;&#32676;&#32452;&#21463;&#21040;&#20182;&#20204;&#30340;&#31038;&#20132;&#20851;&#31995;&#30340;&#24433;&#21709;&#65292;&#32780;&#21518;&#32773;&#25351;&#30340;&#26159;&#29992;&#25143;&#19982;&#24535;&#21516;&#36947;&#21512;&#30340;&#20154;&#19968;&#36215;&#21152;&#20837;&#32676;&#32452;&#36827;&#34892;&#33258;&#25105;&#20139;&#21463;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#20123;&#24847;&#22270;
&lt;/p&gt;
&lt;p&gt;
Online groups have become increasingly prevalent, providing users with space to share experiences and explore interests. Therefore, user-centric group discovery task, i.e., recommending groups to users can help both users' online experiences and platforms' long-term developments. Existing recommender methods can not deal with this task as modeling user-group participation into a bipartite graph overlooks their item-side interests. Although there exist a few works attempting to address this task, they still fall short in fully preserving the social context and ensuring effective interest representation learning.  In this paper, we focus on exploring the intents that motivate users to participate in groups, which can be categorized into different types, like the social-intent and the personal interest-intent. The former refers to users joining a group affected by their social links, while the latter relates to users joining groups with like-minded people for self-enjoyment. To comprehend
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;NextGen Communications Copilot&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#26080;&#32447;&#36890;&#20449;&#35268;&#33539;&#20449;&#24687;&#32508;&#21512;&#30340;&#23545;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#12290;&#23427;&#37319;&#29992;&#22522;&#30784;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#39046;&#22495;&#29305;&#23450;&#30340;&#25968;&#25454;&#24211;&#12289;&#19978;&#19979;&#25991;&#25552;&#21462;&#22120;&#21644;&#21453;&#39304;&#26426;&#21046;&#65292;&#33021;&#22815;&#25552;&#20379;&#20934;&#30830;&#19988;&#30456;&#20851;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#24182;&#32467;&#21512;&#19987;&#23478;&#21453;&#39304;&#21644;&#25968;&#25454;&#36129;&#29486;&#24037;&#20855;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#35780;&#20272;&#20013;&#65292;&#35813;&#31995;&#32479;&#23637;&#31034;&#20102;&#26356;&#22810;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2308.04033</link><description>&lt;p&gt;
&#36866;&#24212;&#26080;&#32447;&#36890;&#20449;&#35268;&#33539;&#20449;&#24687;&#32508;&#21512;&#30340;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Adapting Foundation Models for Information Synthesis of Wireless Communication Specifications. (arXiv:2308.04033v1 [cs.NI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;NextGen Communications Copilot&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#26080;&#32447;&#36890;&#20449;&#35268;&#33539;&#20449;&#24687;&#32508;&#21512;&#30340;&#23545;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#12290;&#23427;&#37319;&#29992;&#22522;&#30784;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#39046;&#22495;&#29305;&#23450;&#30340;&#25968;&#25454;&#24211;&#12289;&#19978;&#19979;&#25991;&#25552;&#21462;&#22120;&#21644;&#21453;&#39304;&#26426;&#21046;&#65292;&#33021;&#22815;&#25552;&#20379;&#20934;&#30830;&#19988;&#30456;&#20851;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#24182;&#32467;&#21512;&#19987;&#23478;&#21453;&#39304;&#21644;&#25968;&#25454;&#36129;&#29486;&#24037;&#20855;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#35780;&#20272;&#20013;&#65292;&#35813;&#31995;&#32479;&#23637;&#31034;&#20102;&#26356;&#22810;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#12289;&#24320;&#21457;&#21644;&#30740;&#31350;&#29616;&#20195;&#26080;&#32447;&#36890;&#20449;&#25216;&#26415;&#30340;&#29616;&#26377;&#26041;&#27861;&#28041;&#21450;&#32791;&#26102;&#19988;&#32321;&#29712;&#30340;&#36807;&#31243;&#65292;&#38656;&#35201;&#31579;&#36873;&#22823;&#37327;&#30340;&#32593;&#39029;&#21644;&#25216;&#26415;&#35268;&#33539;&#25991;&#20214;&#65292;&#25910;&#38598;&#25152;&#38656;&#20449;&#24687;&#24182;&#36827;&#34892;&#32508;&#21512;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;NextGen Communications Copilot&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#26080;&#32447;&#36890;&#20449;&#35268;&#33539;&#20449;&#24687;&#32508;&#21512;&#30340;&#23545;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#12290;&#35813;&#31995;&#32479;&#22522;&#20110;&#26368;&#26032;&#30340;&#22522;&#30784;&#27169;&#22411;&#36827;&#23637;&#65292;&#24182;&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#30340;&#38468;&#21152;&#32452;&#20214;&#65306;&#19968;&#20010;&#39046;&#22495;&#29305;&#23450;&#30340;&#25968;&#25454;&#24211;&#65292;&#19968;&#20010;&#19978;&#19979;&#25991;&#25552;&#21462;&#22120;&#21644;&#19968;&#20010;&#21453;&#39304;&#26426;&#21046;&#12290;&#35813;&#31995;&#32479;&#21487;&#20197;&#20174;&#26080;&#32447;&#25216;&#26415;&#35268;&#33539;&#25968;&#25454;&#24211;&#20013;&#25552;&#21462;&#31616;&#27905;&#30340;&#12289;&#19982;&#26597;&#35810;&#30456;&#20851;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#24182;&#32467;&#21512;&#19987;&#23478;&#21453;&#39304;&#21644;&#25968;&#25454;&#36129;&#29486;&#24037;&#20855;&#12290;&#22312;&#20351;&#29992;&#30001;&#19987;&#23478;&#21019;&#24314;&#30340;&#26597;&#35810;&#21644;&#21442;&#32771;&#21709;&#24212;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;&#35813;&#31995;&#32479;&#23637;&#31034;&#20102;&#26356;&#22810;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing approaches to understanding, developing and researching modern wireless communication technologies involves time-intensive and arduous process of sifting through numerous webpages and technical specification documents, gathering the required information and synthesizing it. This paper presents NextGen Communications Copilot, a conversational artificial intelligence tool for information synthesis of wireless communication specifications. The system builds on top of recent advancements in foundation models and consists of three key additional components: a domain-specific database, a context extractor, and a feedback mechanism. The system appends user queries with concise and query-dependent contextual information extracted from a database of wireless technical specifications and incorporates tools for expert feedback and data contributions. On evaluation using a benchmark dataset of queries and reference responses created by subject matter experts, the system demonstrated more 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;GenExpan&#65292;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#26694;&#26550;&#65292;&#21033;&#29992;&#21069;&#32512;&#26641;&#20445;&#35777;&#23454;&#20307;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#65292;&#37319;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#31867;&#21517;&#26469;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#21516;&#19968;&#31867;&#23454;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.03531</link><description>&lt;p&gt;
&#20174;&#26816;&#32034;&#21040;&#29983;&#25104;&#65306;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
From Retrieval to Generation: Efficient and Effective Entity Set Expansion. (arXiv:2304.03531v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03531
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;GenExpan&#65292;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#26694;&#26550;&#65292;&#21033;&#29992;&#21069;&#32512;&#26641;&#20445;&#35777;&#23454;&#20307;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#65292;&#37319;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#31867;&#21517;&#26469;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#21516;&#19968;&#31867;&#23454;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#38598;&#25193;&#23637;&#65288;ESE&#65289;&#26159;&#19968;&#39033;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#26088;&#22312;&#25193;&#23637;&#30001;&#23567;&#30340;&#31181;&#23376;&#23454;&#20307;&#38598;&#25551;&#36848;&#30340;&#30446;&#26631;&#35821;&#20041;&#31867;&#30340;&#23454;&#20307;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;ESE&#26041;&#27861;&#26159;&#22522;&#20110;&#26816;&#32034;&#30340;&#26694;&#26550;&#65292;&#38656;&#35201;&#25552;&#21462;&#23454;&#20307;&#30340;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#24182;&#35745;&#31639;&#31181;&#23376;&#23454;&#20307;&#21644;&#20505;&#36873;&#23454;&#20307;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20004;&#20010;&#30446;&#30340;&#65292;&#23427;&#20204;&#24517;&#39035;&#36845;&#20195;&#22320;&#36941;&#21382;&#35821;&#26009;&#24211;&#21644;&#25968;&#25454;&#38598;&#20013;&#25552;&#20379;&#30340;&#23454;&#20307;&#35789;&#27719;&#65292;&#23548;&#33268;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#36739;&#24046;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#26816;&#32034;&#30340;ESE&#26041;&#27861;&#28040;&#32791;&#30340;&#26102;&#38388;&#19982;&#23454;&#20307;&#35789;&#27719;&#21644;&#35821;&#26009;&#24211;&#30340;&#22823;&#23567;&#25104;&#32447;&#24615;&#22686;&#38271;&#12290;&#26412;&#25991;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#24335;ESE&#26694;&#26550;&#65292;Generative Entity Set Expansion (GenExpan)&#65292;&#23427;&#21033;&#29992;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#23436;&#25104;ESE&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#37319;&#29992;&#21069;&#32512;&#26641;&#26469;&#20445;&#35777;&#23454;&#20307;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#37319;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#31867;&#21517;&#26469;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#21516;&#19968;&#31867;&#23454;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entity Set Expansion (ESE) is a critical task aiming to expand entities of the target semantic class described by a small seed entity set. Most existing ESE methods are retrieval-based frameworks that need to extract the contextual features of entities and calculate the similarity between seed entities and candidate entities. To achieve the two purposes, they should iteratively traverse the corpus and the entity vocabulary provided in the datasets, resulting in poor efficiency and scalability. The experimental results indicate that the time consumed by the retrieval-based ESE methods increases linearly with entity vocabulary and corpus size. In this paper, we firstly propose a generative ESE framework, Generative Entity Set Expansion (GenExpan), which utilizes a generative pre-trained language model to accomplish ESE task. Specifically, a prefix tree is employed to guarantee the validity of entity generation, and automatically generated class names are adopted to guide the model to gen
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#21033;&#29992;Kendall-Tau&#36317;&#31163;&#26469;&#34913;&#37327;&#29992;&#25143;&#22312;&#25490;&#21517;&#21015;&#34920;&#20013;&#30340;&#30456;&#20284;&#24230;&#65292;&#24182;&#24212;&#29992;&#32423;&#32852;&#24230;&#37327;&#26641;&#26469;&#25552;&#39640;&#25628;&#32034;&#24615;&#33021;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#23454;&#38469;&#26102;&#38388;&#20869;&#36820;&#22238;&#26368;&#20339;&#21305;&#37197;&#30340;&#29992;&#25143;&#12290;</title><link>http://arxiv.org/abs/2303.11174</link><description>&lt;p&gt;
&#24212;&#29992;&#20110;&#25490;&#21517;&#21015;&#34920;&#20860;&#23481;&#21305;&#37197;&#30340;&#24230;&#37327;&#25628;&#32034;&#31639;&#27861;&#21450;&#20854;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Metric Search for Rank List Compatibility Matching with Applications. (arXiv:2303.11174v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11174
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#21033;&#29992;Kendall-Tau&#36317;&#31163;&#26469;&#34913;&#37327;&#29992;&#25143;&#22312;&#25490;&#21517;&#21015;&#34920;&#20013;&#30340;&#30456;&#20284;&#24230;&#65292;&#24182;&#24212;&#29992;&#32423;&#32852;&#24230;&#37327;&#26641;&#26469;&#25552;&#39640;&#25628;&#32034;&#24615;&#33021;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#23454;&#38469;&#26102;&#38388;&#20869;&#36820;&#22238;&#26368;&#20339;&#21305;&#37197;&#30340;&#29992;&#25143;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22312;&#32447;&#32422;&#20250;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#27969;&#34892;&#65292;&#38656;&#35201;&#19968;&#31181;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#21305;&#37197;&#29992;&#25143;&#12290;&#22312;&#36825;&#20010;&#39033;&#30446;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32422;&#20250;&#21305;&#37197;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;Kendall-Tau&#36317;&#31163;&#26469;&#34913;&#37327;&#29992;&#25143;&#22312;&#21015;&#34920;&#20013;&#23545;&#39033;&#30446;&#65288;&#20363;&#22914;&#65292;&#20182;&#20204;&#21916;&#27426;&#30340;&#36816;&#21160;&#12289;&#38899;&#20048;&#31561;&#65289;&#30340;&#25490;&#24207;&#30456;&#20284;&#24230;&#12290;&#20026;&#20102;&#25552;&#39640;&#25628;&#32034;&#36807;&#31243;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#22312;&#27492;&#24230;&#37327;&#19978;&#24212;&#29992;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#25628;&#32034;&#32467;&#26500;&#65292;&#32423;&#32852;&#24230;&#37327;&#26641;&#65288;CMT&#65289;&#12290;&#35813;&#26641;&#26159;&#24314;&#31435;&#22312;&#25152;&#26377;&#29992;&#25143;&#30340;&#25490;&#21517;&#21015;&#34920;&#19978;&#30340;&#65307;&#24403;&#25552;&#20379;&#26597;&#35810;&#30446;&#26631;&#21644;&#21322;&#24452;&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#36820;&#22238;&#30446;&#26631;&#21322;&#24452;&#20869;&#30340;&#29992;&#25143;&#12290;&#25105;&#20204;&#36890;&#36807;&#21464;&#21270;&#21015;&#34920;&#38271;&#24230;&#12289;&#20154;&#21475;&#35268;&#27169;&#21644;&#26597;&#35810;&#21322;&#24452;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#35813;&#25628;&#32034;&#26041;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#21512;&#29702;&#30340;&#21442;&#25968;&#19979;&#65292;&#22312;&#23454;&#38469;&#26102;&#38388;&#20869;&#26597;&#35810;&#21040;&#26368;&#20339;&#21305;&#37197;&#30340;&#20154;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23545;&#35813;&#31639;&#27861;&#30340;&#28508;&#22312;&#26410;&#26469;&#25913;&#36827;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
As online dating has become more popular in the past few years, an efficient and effective algorithm to match users is needed. In this project, we proposed a new dating matching algorithm that uses Kendall-Tau distance to measure the similarity between users based on their ranking for items in a list. (e.g., their favourite sports, music, etc.) To increase the performance of the search process, we applied a tree-based searching structure, Cascading Metric Tree (CMT), on this metric. The tree is built on ranked lists from all the users; when a query target and a radius are provided, our algorithm can return users within the radius of the target. We tested the scaling of this searching method on a synthetic dataset by varying list length, population size, and query radius. We observed that the algorithm is able to query the best matching people for the user in a practical time, given reasonable parameters. We also provided potential future improvements that can be made to this algorithm 
&lt;/p&gt;</description></item></channel></rss>