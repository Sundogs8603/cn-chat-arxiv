<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#35780;&#20272;&#22810;&#27169;&#24577;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#22312;Amazon&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#20102;&#22810;&#27169;&#24577;&#25512;&#33616;&#22914;&#20309;&#36827;&#19968;&#27493;&#25918;&#22823;&#27969;&#34892;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.12911</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#27169;&#24577;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#65306;&#19968;&#31181;&#27169;&#24577;&#39537;&#21160;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
On Popularity Bias of Multimodal-aware Recommender Systems: a Modalities-driven Analysis. (arXiv:2308.12911v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12911
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#35780;&#20272;&#22810;&#27169;&#24577;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#22312;Amazon&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#20102;&#22810;&#27169;&#24577;&#25512;&#33616;&#22914;&#20309;&#36827;&#19968;&#27493;&#25918;&#22823;&#27969;&#34892;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;(MRSs)&#21033;&#29992;&#22810;&#27169;&#24577;&#20869;&#23481;&#65288;&#20363;&#22914;&#20135;&#21697;&#22270;&#29255;&#25110;&#25551;&#36848;&#65289;&#20316;&#20026;&#39033;&#30446;&#30340;&#38468;&#21152;&#20449;&#24687;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#36825;&#26679;&#30340;&#26041;&#27861;&#37117;&#20381;&#36182;&#20110;&#20998;&#35299;&#27169;&#22411;&#65288;&#20363;&#22914;MFBPR&#65289;&#20316;&#20026;&#22522;&#30784;&#26550;&#26500;&#65292;&#20294;&#24050;&#32463;&#35777;&#26126;MFBPR&#21487;&#33021;&#21463;&#21040;&#27969;&#34892;&#20559;&#24046;&#30340;&#24433;&#21709;&#65292;&#21363;&#23427;&#26412;&#36136;&#19978;&#20542;&#21521;&#20110;&#25552;&#21319;&#27969;&#34892;&#65288;&#21363;&#30701;&#22836;&#65289;&#30446;&#24405;&#20013;&#30340;&#39033;&#30446;&#25512;&#33616;&#65292;&#32780;&#23545;&#38271;&#23614;&#65288;&#21363;&#23567;&#20247;&#65289;&#30446;&#24405;&#20013;&#30340;&#39033;&#30446;&#25512;&#33616;&#19981;&#21033;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;&#20851;&#20110;&#22810;&#27169;&#24577;&#25512;&#33616;&#22914;&#20309;&#36827;&#19968;&#27493;&#25918;&#22823;&#27969;&#34892;&#20559;&#24046;&#30340;&#20998;&#26512;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#22235;&#31181;&#26368;&#20808;&#36827;&#30340;MRSs&#31639;&#27861;&#65288;&#21363;VBPR&#12289;MMGCN&#12289;GRCN&#12289;LATTICE&#65289;&#22312;Amazon&#30340;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#35780;&#20272;&#25512;&#33616;&#20934;&#30830;&#24230;&#25351;&#26631;&#30340;&#21516;&#26102;&#65292;&#36824;&#32771;&#34385;&#20102;&#25512;&#33616;&#39033;&#30446;&#30340;&#22810;&#26679;&#24615;&#21644;&#26816;&#32034;&#21040;&#30340;&#23567;&#20247;&#39033;&#30446;&#30340;&#27604;&#20363;&#31561;&#24615;&#33021;&#24230;&#37327;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#30740;&#31350;&#36825;&#19968;&#28857;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
Multimodal-aware recommender systems (MRSs) exploit multimodal content (e.g., product images or descriptions) as items' side information to improve recommendation accuracy. While most of such methods rely on factorization models (e.g., MFBPR) as base architecture, it has been shown that MFBPR may be affected by popularity bias, meaning that it inherently tends to boost the recommendation of popular (i.e., short-head) items at the detriment of niche (i.e., long-tail) items from the catalog. Motivated by this assumption, in this work, we provide one of the first analyses on how multimodality in recommendation could further amplify popularity bias. Concretely, we evaluate the performance of four state-of-the-art MRSs algorithms (i.e., VBPR, MMGCN, GRCN, LATTICE) on three datasets from Amazon by assessing, along with recommendation accuracy metrics, performance measures accounting for the diversity of recommended items and the portion of retrieved niche items. To better investigate this as
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#21512;&#32534;&#30721;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20113;&#31471;&#26356;&#26032;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#24182;&#36890;&#36807;&#32593;&#32476;&#36890;&#20449;&#20256;&#36755;&#21040;&#35774;&#22791;&#19978;&#65292;&#20197;&#35299;&#20915;&#35774;&#22791;&#36164;&#28304;&#26377;&#38480;&#21644;&#32593;&#32476;&#24102;&#23485;&#21387;&#21147;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.12777</link><description>&lt;p&gt;
&#38754;&#21521;&#36890;&#20449;&#39640;&#25928;&#30340;&#22312;&#32447;&#35774;&#22791;&#20250;&#35805;&#25512;&#33616;&#27169;&#22411;&#26356;&#26032;
&lt;/p&gt;
&lt;p&gt;
Towards Communication-Efficient Model Updating for On-Device Session-Based Recommendation. (arXiv:2308.12777v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12777
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#21512;&#32534;&#30721;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20113;&#31471;&#26356;&#26032;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#24182;&#36890;&#36807;&#32593;&#32476;&#36890;&#20449;&#20256;&#36755;&#21040;&#35774;&#22791;&#19978;&#65292;&#20197;&#35299;&#20915;&#35774;&#22791;&#36164;&#28304;&#26377;&#38480;&#21644;&#32593;&#32476;&#24102;&#23485;&#21387;&#21147;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;&#35774;&#22791;&#30340;&#25512;&#33616;&#31995;&#32479;&#30001;&#20110;&#20854;&#25552;&#20379;&#21363;&#26102;&#21709;&#24212;&#21644;&#20445;&#25252;&#38544;&#31169;&#30340;&#20248;&#21183;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#19982;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#20445;&#25345;&#21516;&#27493;&#65292;&#20113;&#31471;&#25512;&#33616;&#31995;&#32479;&#20250;&#23450;&#26399;&#20351;&#29992;&#26032;&#30340;&#20132;&#20114;&#25968;&#25454;&#36827;&#34892;&#26356;&#26032;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26377;&#38480;&#30340;&#35774;&#22791;&#35745;&#31639;&#36164;&#28304;&#65292;&#35774;&#22791;&#19978;&#30340;&#27169;&#22411;&#38590;&#20197;&#36827;&#34892;&#37325;&#26032;&#35757;&#32451;&#12290;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#27169;&#22411;&#37325;&#26032;&#35757;&#32451;&#21457;&#29983;&#22312;&#26381;&#21153;&#22120;&#31471;&#30340;&#24773;&#26223;&#65292;&#28982;&#21518;&#36890;&#36807;&#32593;&#32476;&#36890;&#20449;&#23558;&#26356;&#26032;&#30340;&#21442;&#25968;&#20256;&#36755;&#21040;&#36793;&#32536;&#35774;&#22791;&#12290;&#34429;&#28982;&#36825;&#28040;&#38500;&#20102;&#26412;&#22320;&#37325;&#26032;&#35757;&#32451;&#30340;&#38656;&#27714;&#65292;&#20294;&#20063;&#23548;&#33268;&#20102;&#24120;&#35268;&#21442;&#25968;&#20256;&#36755;&#65292;&#32473;&#32593;&#32476;&#24102;&#23485;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#21387;&#21147;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22522;&#20110;&#32452;&#21512;&#32534;&#30721;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#26469;&#21387;&#32553;&#27169;&#22411;&#26356;&#26032;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#23613;&#37327;&#20351;&#29992;&#20808;&#21069;&#30693;&#35782;&#30340;&#21516;&#26102;&#65292;&#28789;&#27963;&#22320;&#26356;&#26032;&#35774;&#22791;&#19978;&#30340;&#27169;&#22411;&#65292;&#20943;&#23569;&#39069;&#22806;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#26469;&#39564;&#35777;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
On-device recommender systems recently have garnered increasing attention due to their advantages of providing prompt response and securing privacy. To stay current with evolving user interests, cloud-based recommender systems are periodically updated with new interaction data. However, on-device models struggle to retrain themselves because of limited onboard computing resources. As a solution, we consider the scenario where the model retraining occurs on the server side and then the updated parameters are transferred to edge devices via network communication. While this eliminates the need for local retraining, it incurs a regular transfer of parameters that significantly taxes network bandwidth. To mitigate this issue, we develop an efficient approach based on compositional codes to compress the model update. This approach ensures the on-device model is updated flexibly with minimal additional parameters whilst utilizing previous knowledge. The extensive experiments conducted on mul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#22343;&#23884;&#20837;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#23884;&#20837;&#22312;&#25512;&#33616;&#20013;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#36827;&#19968;&#27493;&#25913;&#36827;&#29616;&#23454;&#19990;&#30028;&#23884;&#20837;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2308.12767</link><description>&lt;p&gt;
&#20851;&#20110;&#24179;&#22343;&#23884;&#20837;&#29992;&#20110;&#29289;&#21697;&#25512;&#33616;&#30340;&#19968;&#33268;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Consistency of Average Embeddings for Item Recommendation. (arXiv:2308.12767v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12767
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#22343;&#23884;&#20837;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#23884;&#20837;&#22312;&#25512;&#33616;&#20013;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#36827;&#19968;&#27493;&#25913;&#36827;&#29616;&#23454;&#19990;&#30028;&#23884;&#20837;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#20570;&#27861;&#26159;&#23558;&#29289;&#21697;&#23884;&#20837;&#36827;&#34892;&#24179;&#22343;&#20197;&#22312;&#21516;&#19968;&#23884;&#20837;&#31354;&#38388;&#20013;&#20195;&#34920;&#29992;&#25143;&#25110;&#26356;&#39640;&#32423;&#30340;&#27010;&#24565;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#31181;&#20570;&#27861;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26399;&#26395;&#31934;&#24230;&#20998;&#25968;&#65292;&#29992;&#20110;&#34913;&#37327;&#24179;&#22343;&#23884;&#20837;&#19982;&#20854;&#26500;&#24314;&#25152;&#20351;&#29992;&#30340;&#29289;&#21697;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#38543;&#21518;&#22312;&#20855;&#26377;&#29305;&#23450;&#20551;&#35774;&#30340;&#29702;&#35770;&#29615;&#22659;&#21644;&#26469;&#33258;&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#30340;&#30495;&#23454;&#25968;&#25454;&#19978;&#20998;&#26512;&#20102;&#35813;&#20998;&#25968;&#30340;&#25968;&#23398;&#34920;&#36798;&#24335;&#21450;&#20854;&#32463;&#39564;&#34920;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24378;&#35843;&#20102;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#20540;&#22312;&#25512;&#33616;&#20013;&#30340;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#26356;&#22909;&#22320;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#23884;&#20837;&#19982;&#25105;&#20204;&#29702;&#35770;&#29615;&#22659;&#30340;&#20551;&#35774;&#30456;&#19968;&#33268;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
A prevalent practice in recommender systems consists of averaging item embeddings to represent users or higher-level concepts in the same embedding space. This paper investigates the relevance of such a practice. For this purpose, we propose an expected precision score, designed to measure the consistency of an average embedding relative to the items used for its construction. We subsequently analyze the mathematical expression of this score in a theoretical setting with specific assumptions, as well as its empirical behavior on real-world data from music streaming services. Our results emphasize that real-world averages are less consistent for recommendation, which paves the way for future research to better align real-world embeddings with assumptions from our theoretical setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#26088;&#22312;&#22635;&#34917;&#29616;&#26377;&#22522;&#20110;&#38544;&#24615;&#21453;&#39304;&#30340;&#35270;&#39057;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#31354;&#30333;&#65292;&#36890;&#36807;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#21644;&#29992;&#25143;&#35266;&#30475;&#27169;&#24335;&#26469;&#26500;&#24314;&#26377;&#25928;&#30340;&#35270;&#39057;&#25512;&#33616;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.12743</link><description>&lt;p&gt;
&#20351;&#29992;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#21644;&#29992;&#25143;&#35266;&#30475;&#27169;&#24335;&#30340;&#35270;&#39057;&#25512;&#33616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Video Recommendation Using Social Network Analysis and User Viewing Patterns. (arXiv:2308.12743v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12743
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#26088;&#22312;&#22635;&#34917;&#29616;&#26377;&#22522;&#20110;&#38544;&#24615;&#21453;&#39304;&#30340;&#35270;&#39057;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#31354;&#30333;&#65292;&#36890;&#36807;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#21644;&#29992;&#25143;&#35266;&#30475;&#27169;&#24335;&#26469;&#26500;&#24314;&#26377;&#25928;&#30340;&#35270;&#39057;&#25512;&#33616;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35270;&#39057;&#28857;&#25773;&#24179;&#21488;&#30340;&#36805;&#29467;&#23835;&#36215;&#65292;&#29992;&#25143;&#38754;&#20020;&#30528;&#20174;&#22823;&#37327;&#20869;&#23481;&#20013;&#31579;&#36873;&#20986;&#19982;&#33258;&#24049;&#21916;&#22909;&#30456;&#31526;&#30340;&#33410;&#30446;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20449;&#24687;&#36807;&#36733;&#30340;&#22256;&#22659;&#65292;&#35270;&#39057;&#28857;&#25773;&#26381;&#21153;&#36234;&#26469;&#36234;&#22810;&#22320;&#21152;&#20837;&#20102;&#21033;&#29992;&#31639;&#27861;&#20998;&#26512;&#29992;&#25143;&#34892;&#20026;&#24182;&#24314;&#35758;&#20010;&#24615;&#21270;&#20869;&#23481;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#25512;&#33616;&#31995;&#32479;&#20381;&#36182;&#20110;&#29992;&#25143;&#26126;&#30830;&#30340;&#21453;&#39304;&#65292;&#22914;&#35780;&#20998;&#21644;&#35780;&#35770;&#65292;&#20294;&#36825;&#31181;&#21453;&#39304;&#30340;&#25910;&#38598;&#24448;&#24448;&#22256;&#38590;&#19988;&#32791;&#26102;&#12290;&#22240;&#27492;&#65292;&#22312;&#24314;&#31435;&#26377;&#25928;&#30340;&#35270;&#39057;&#25512;&#33616;&#27169;&#22411;&#26041;&#38754;&#65292;&#21033;&#29992;&#29992;&#25143;&#30340;&#38544;&#24615;&#21453;&#39304;&#27169;&#24335;&#21487;&#33021;&#25552;&#20379;&#20102;&#19968;&#26465;&#26367;&#20195;&#36884;&#24452;&#65292;&#36991;&#20813;&#20102;&#23545;&#26126;&#30830;&#35780;&#20998;&#30340;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#25991;&#29486;&#23545;&#20110;&#22522;&#20110;&#38544;&#24615;&#21453;&#39304;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#29305;&#21035;&#26159;&#22312;&#24314;&#27169;&#35270;&#39057;&#35266;&#30475;&#34892;&#20026;&#26041;&#38754;&#65292;&#23578;&#32570;&#20047;&#36275;&#22815;&#30340;&#25506;&#32034;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the meteoric rise of video-on-demand (VOD) platforms, users face the challenge of sifting through an expansive sea of content to uncover shows that closely match their preferences. To address this information overload dilemma, VOD services have increasingly incorporated recommender systems powered by algorithms that analyze user behavior and suggest personalized content. However, a majority of existing recommender systems depend on explicit user feedback in the form of ratings and reviews, which can be difficult and time-consuming to collect at scale. This presents a key research gap, as leveraging users' implicit feedback patterns could provide an alternative avenue for building effective video recommendation models, circumventing the need for explicit ratings. However, prior literature lacks sufficient exploration into implicit feedback-based recommender systems, especially in the context of modeling video viewing behavior. Therefore, this paper aims to bridge this research gap 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20219;&#21153;&#26694;&#26550;ExpLTV&#65292;&#21033;&#29992;&#28216;&#25103;&#40120;&#40060;&#30340;&#26816;&#27979;&#26469;&#25913;&#36827;&#23458;&#25143;&#32456;&#36523;&#20215;&#20540;&#39044;&#27979;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.12729</link><description>&lt;p&gt;
&#29420;&#29305;&#24605;&#32500;&#65306;&#36890;&#36807;&#19987;&#23478;&#36335;&#24452;&#36873;&#25321;&#21644;&#28216;&#25103;&#40120;&#40060;&#26816;&#27979;&#25913;&#36827;&#23458;&#25143;&#32456;&#36523;&#20215;&#20540;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Out of the Box Thinking: Improving Customer Lifetime Value Modelling via Expert Routing and Game Whale Detection. (arXiv:2308.12729v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12729
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20219;&#21153;&#26694;&#26550;ExpLTV&#65292;&#21033;&#29992;&#28216;&#25103;&#40120;&#40060;&#30340;&#26816;&#27979;&#26469;&#25913;&#36827;&#23458;&#25143;&#32456;&#36523;&#20215;&#20540;&#39044;&#27979;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23458;&#25143;&#32456;&#36523;&#20215;&#20540;&#65288;LTV&#65289;&#39044;&#27979;&#23545;&#20110;&#35797;&#22270;&#26681;&#25454;&#20272;&#35745;&#20215;&#20540;&#20248;&#21270;&#24191;&#21578;&#25237;&#36164;&#30340;&#31227;&#21160;&#28216;&#25103;&#21457;&#34892;&#21830;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#31227;&#21160;&#28216;&#25103;&#20013;&#65292;&#37096;&#32626;&#24494;&#20132;&#26131;&#26159;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#36135;&#24065;&#21270;&#31574;&#30053;&#65292;&#21560;&#24341;&#20102;&#19968;&#23567;&#32676;&#22312;&#28216;&#25103;&#20869;&#36141;&#20080;&#19978;&#22823;&#37327;&#28040;&#36153;&#30340;&#28216;&#25103;&#40120;&#40060;&#12290;&#36825;&#31181;&#28216;&#25103;&#40120;&#40060;&#30340;&#23384;&#22312;&#21487;&#33021;&#38459;&#30861;&#29616;&#26377;LTV&#39044;&#27979;&#27169;&#22411;&#30340;&#23454;&#29992;&#24615;&#65292;&#22240;&#20026;&#28216;&#25103;&#40120;&#40060;&#30340;&#36141;&#20080;&#34892;&#20026;&#24635;&#26159;&#34920;&#29616;&#20986;&#19982;&#26222;&#36890;&#29992;&#25143;&#19981;&#21516;&#30340;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;&#35782;&#21035;&#28216;&#25103;&#40120;&#40060;&#21487;&#20197;&#20026;&#25913;&#36827;LTV&#39044;&#27979;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#25171;&#24320;&#26032;&#26426;&#20250;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#22312;LTV&#39044;&#27979;&#20013;&#24212;&#29992;&#28216;&#25103;&#40120;&#40060;&#26816;&#27979;&#30340;&#30740;&#31350;&#24456;&#23569;&#65292;&#29616;&#26377;&#24037;&#20316;&#20027;&#35201;&#38024;&#23545;&#20551;&#35774;&#21487;&#33719;&#24471;&#39640;&#36136;&#37327;&#29992;&#25143;&#29305;&#24449;&#30340;&#38271;&#26399;LTV&#39044;&#27979;&#65292;&#36825;&#22312;&#29992;&#25143;&#33719;&#21462;&#38454;&#27573;&#19981;&#36866;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20219;&#21153;&#26694;&#26550;ExpLTV&#12290;
&lt;/p&gt;
&lt;p&gt;
Customer lifetime value (LTV) prediction is essential for mobile game publishers trying to optimize the advertising investment for each user acquisition based on the estimated worth. In mobile games, deploying microtransactions is a simple yet effective monetization strategy, which attracts a tiny group of game whales who splurge on in-game purchases. The presence of such game whales may impede the practicality of existing LTV prediction models, since game whales' purchase behaviours always exhibit varied distribution from general users. Consequently, identifying game whales can open up new opportunities to improve the accuracy of LTV prediction models. However, little attention has been paid to applying game whale detection in LTV prediction, and existing works are mainly specialized for the long-term LTV prediction with the assumption that the high-quality user features are available, which is not applicable in the UA stage. In this paper, we propose ExpLTV, a novel multi-task framew
&lt;/p&gt;</description></item><item><title>&#20026;&#20102;&#35299;&#20915;&#31185;&#23398;&#35770;&#25991;&#30340;&#21487;&#37325;&#22797;&#24615;&#21361;&#26426;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20123;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#26631;&#35760;&#21487;&#37325;&#22797;&#24615;&#25991;&#31456;&#12289;&#20250;&#35758;&#19978;&#30340;&#21487;&#37325;&#22797;&#24615;&#26816;&#26597;&#28165;&#21333;&#21644;&#22312;OpenReview&#19978;&#20849;&#20139;&#25104;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.12580</link><description>&lt;p&gt;
&#24314;&#31435;&#37327;&#21270;"&#21487;&#37325;&#22797;&#24615;&#21162;&#21147;"&#30340;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
Laying foundations to quantify the "Effort of Reproducibility". (arXiv:2308.12580v1 [cs.DL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12580
&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#20915;&#31185;&#23398;&#35770;&#25991;&#30340;&#21487;&#37325;&#22797;&#24615;&#21361;&#26426;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20123;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#26631;&#35760;&#21487;&#37325;&#22797;&#24615;&#25991;&#31456;&#12289;&#20250;&#35758;&#19978;&#30340;&#21487;&#37325;&#22797;&#24615;&#26816;&#26597;&#28165;&#21333;&#21644;&#22312;OpenReview&#19978;&#20849;&#20139;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20160;&#20040;&#26377;&#20123;&#30740;&#31350;&#23481;&#26131;&#37325;&#29616;&#65292;&#32780;&#20854;&#20182;&#30740;&#31350;&#21017;&#38590;&#20197;&#37325;&#29616;&#65311;&#23545;&#31185;&#23398;&#24037;&#20316;&#30340;&#20934;&#30830;&#24615;&#20135;&#29983;&#24576;&#30097;&#24182;&#19981;&#26159;&#26377;&#30410;&#30340;&#65292;&#29305;&#21035;&#26159;&#24403;&#20010;&#20307;&#30740;&#31350;&#32773;&#26080;&#27861;&#37325;&#29616;&#35770;&#25991;&#20013;&#30340;&#20027;&#24352;&#26102;&#12290;&#26080;&#27861;&#37325;&#29616;&#31185;&#30740;&#35770;&#25991;&#21487;&#33021;&#26377;&#35768;&#22810;&#20027;&#35266;&#21407;&#22240;&#12290;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#38754;&#20020;&#30528;&#21487;&#37325;&#22797;&#24615;&#21361;&#26426;&#65292;&#23545;&#24050;&#21457;&#34920;&#25991;&#31456;&#30340;&#35843;&#26597;&#23548;&#33268;&#20154;&#20204;&#24847;&#35782;&#21040;&#34429;&#28982;&#20849;&#20139;&#20195;&#30721;&#23384;&#20648;&#24211;&#21487;&#21462;&#65292;&#20294;&#20195;&#30721;&#24182;&#19981;&#33021;&#20915;&#23450;&#19968;&#31687;&#25991;&#31456;&#30340;&#21487;&#37325;&#22797;&#24615;&#12290;&#21442;&#19982;&#20986;&#29256;&#36807;&#31243;&#30340;&#21508;&#26041;&#37117;&#22312;&#31215;&#26497;&#35299;&#20915;&#21487;&#37325;&#22797;&#24615;&#21361;&#26426;&#65292;&#35832;&#22914;&#23545;&#20855;&#26377;&#21487;&#37325;&#22797;&#24615;&#30340;&#25991;&#31456;&#36827;&#34892;&#24509;&#31456;&#26631;&#35760;&#12289;&#20250;&#35758;&#19978;&#30340;&#21487;&#37325;&#22797;&#24615;&#26816;&#26597;&#28165;&#21333;&#65288;&#22914;NeurIPS&#12289;ICML&#12289;ICLR&#31561;&#65289;&#20197;&#21450;&#22312;OpenReview&#19978;&#20849;&#20139;&#25104;&#26524;&#31561;&#35299;&#20915;&#26041;&#26696;&#37117;&#26174;&#24471;&#24456;&#26377;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Why are some research studies easy to reproduce while others are difficult? Casting doubt on the accuracy of scientific work is not fruitful, especially when an individual researcher cannot reproduce the claims made in the paper. There could be many subjective reasons behind the inability to reproduce a scientific paper. The field of Machine Learning (ML) faces a reproducibility crisis, and surveying a portion of published articles has resulted in a group realization that although sharing code repositories would be appreciable, code bases are not the end all be all for determining the reproducibility of an article. Various parties involved in the publication process have come forward to address the reproducibility crisis and solutions such as badging articles as reproducible, reproducibility checklists at conferences (\textit{NeurIPS, ICML, ICLR, etc.}), and sharing artifacts on \textit{OpenReview} come across as promising solutions to the core problem. The breadth of literature on rep
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#19981;&#21516;&#30340;&#26816;&#32034;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25972;&#21512;&#26041;&#27861;&#26469;&#22686;&#24378;&#31572;&#26696;&#29983;&#25104;&#65292;&#24182;&#21457;&#29616;&#24120;&#29992;&#30340;&#36830;&#25509;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22235;&#31181;&#26367;&#20195;&#31574;&#30053;&#65292;&#21253;&#25324;&#20004;&#31181;&#21333;&#36718;&#26041;&#27861;&#21644;&#20004;&#31181;&#22810;&#36718;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2308.12574</link><description>&lt;p&gt;
&#25506;&#32034;&#26816;&#32034;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25972;&#21512;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Exploring the Integration Strategies of Retriever and Large Language Models. (arXiv:2308.12574v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#19981;&#21516;&#30340;&#26816;&#32034;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25972;&#21512;&#26041;&#27861;&#26469;&#22686;&#24378;&#31572;&#26696;&#29983;&#25104;&#65292;&#24182;&#21457;&#29616;&#24120;&#29992;&#30340;&#36830;&#25509;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22235;&#31181;&#26367;&#20195;&#31574;&#30053;&#65292;&#21253;&#25324;&#20004;&#31181;&#21333;&#36718;&#26041;&#27861;&#21644;&#20004;&#31181;&#22810;&#36718;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;ChatGPT&#65289;&#30340;&#25972;&#21512;&#20026;&#25552;&#39640;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#20316;&#20986;&#20102;&#26174;&#33879;&#36129;&#29486;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#23558;&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#34701;&#20837;&#31572;&#26696;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#26368;&#20339;&#26041;&#27861;&#20173;&#28982;&#32570;&#20047;&#25506;&#32034;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#30740;&#31350;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#32467;&#21512;&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#22686;&#24378;&#31572;&#26696;&#29983;&#25104;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#24120;&#29992;&#30340;&#36830;&#25509;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21363;&#20351;&#27491;&#30830;&#30340;&#25991;&#26723;&#22312;&#21069;k&#20010;&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#20013;&#65292;&#36825;&#31181;&#26041;&#27861;&#32463;&#24120;&#20250;&#29983;&#25104;&#8220;&#26410;&#30693;&#8221;&#36755;&#20986;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22235;&#31181;&#23558;&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25972;&#21512;&#30340;&#26367;&#20195;&#31574;&#30053;&#12290;&#36825;&#20123;&#31574;&#30053;&#21253;&#25324;&#20004;&#31181;&#21033;&#29992;&#24605;&#32500;&#38142;&#25512;&#29702;&#30340;&#21333;&#36718;&#26041;&#27861;&#21644;&#20004;&#31181;&#21033;&#29992;&#21453;&#39304;&#24490;&#29615;&#30340;&#22810;&#36718;&#31574;&#30053;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#20998;&#26512;&#21644;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;...
&lt;/p&gt;
&lt;p&gt;
The integration of retrieved passages and large language models (LLMs), such as ChatGPTs, has significantly contributed to improving open-domain question answering. However, there is still a lack of exploration regarding the optimal approach for incorporating retrieved passages into the answer generation process. This paper aims to fill this gap by investigating different methods of combining retrieved passages with LLMs to enhance answer generation. We begin by examining the limitations of a commonly-used concatenation approach. Surprisingly, this approach often results in generating "unknown" outputs, even when the correct document is among the top-k retrieved passages. To address this issue, we explore four alternative strategies for integrating the retrieved passages with the LLMs. These strategies include two single-round methods that utilize chain-of-thought reasoning and two multi-round strategies that incorporate feedback loops. Through comprehensive analyses and experiments, w
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;NLP&#20998;&#26512;&#20102;ESG&#20027;&#23548;&#30340;DLT&#30740;&#31350;&#30340;&#28436;&#21270;&#65292;&#36890;&#36807;&#26500;&#24314;&#24341;&#29992;&#32593;&#32476;&#21644;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#65292;&#23545;DLT&#22312;ESG&#32972;&#26223;&#19979;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#25991;&#29486;&#32508;&#36848;&#12290;</title><link>http://arxiv.org/abs/2308.12420</link><description>&lt;p&gt;
ESG&#20027;&#23548;&#30340;DLT&#30740;&#31350;&#30340;&#28436;&#21270;&#65306;&#23545;&#25991;&#29486;&#36827;&#34892;NLP&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature. (arXiv:2308.12420v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;NLP&#20998;&#26512;&#20102;ESG&#20027;&#23548;&#30340;DLT&#30740;&#31350;&#30340;&#28436;&#21270;&#65292;&#36890;&#36807;&#26500;&#24314;&#24341;&#29992;&#32593;&#32476;&#21644;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#65292;&#23545;DLT&#22312;ESG&#32972;&#26223;&#19979;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#25991;&#29486;&#32508;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#36134;&#26412;&#25216;&#26415;(DLT)&#36805;&#36895;&#21457;&#23637;&#65292;&#38656;&#35201;&#20840;&#38754;&#20102;&#35299;&#20854;&#21508;&#20010;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#38024;&#23545;DLT&#30340;&#29615;&#22659;&#12289;&#21487;&#25345;&#32493;&#24615;&#21644;&#27835;&#29702;(ESG)&#32452;&#25104;&#37096;&#20998;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#36824;&#19981;&#36275;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;107&#31687;&#31181;&#23376;&#25991;&#29486;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;63,083&#20010;&#21442;&#32771;&#25991;&#29486;&#30340;&#24341;&#29992;&#32593;&#32476;&#65292;&#24182;&#23558;&#20854;&#31934;&#28860;&#20026;24,539&#31687;&#25991;&#29486;&#30340;&#35821;&#26009;&#24211;&#36827;&#34892;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#19968;&#20010;&#24050;&#24314;&#31435;&#30340;&#25216;&#26415;&#20998;&#31867;&#27861;&#20174;46&#31687;&#35770;&#25991;&#20013;&#26631;&#35760;&#20102;&#21629;&#21517;&#23454;&#20307;&#65292;&#24182;&#36890;&#36807;&#25214;&#20986;DLT&#30340;ESG&#35201;&#32032;&#26469;&#23436;&#21892;&#36825;&#20010;&#20998;&#31867;&#27861;&#12290;&#21033;&#29992;&#22522;&#20110;transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#23545;&#19968;&#20010;&#39044;&#20808;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#32454;&#21270;&#35843;&#25972;&#65292;&#29992;&#20110;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#65292;&#20351;&#29992;&#25105;&#20204;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#35843;&#25972;&#21518;&#30340;&#35821;&#35328;&#27169;&#22411;&#23545;&#35821;&#26009;&#24211;&#36827;&#34892;&#20102;&#31934;&#31616;&#65292;&#24471;&#21040;&#20102;505&#31687;&#20851;&#38190;&#35770;&#25991;&#65292;&#36890;&#36807;&#21629;&#21517;&#23454;&#20307;&#21644;&#26102;&#38388;&#22270;&#20998;&#26512;&#65292;&#20419;&#36827;&#20102;&#23545;DLT&#22312;ESG&#32972;&#26223;&#19979;&#30340;&#28436;&#21270;&#30340;&#25991;&#29486;&#32508;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed Ledger Technologies (DLTs) have rapidly evolved, necessitating comprehensive insights into their diverse components. However, a systematic literature review that emphasizes the Environmental, Sustainability, and Governance (ESG) components of DLT remains lacking. To bridge this gap, we selected 107 seed papers to build a citation network of 63,083 references and refined it to a corpus of 24,539 publications for analysis. Then, we labeled the named entities in 46 papers according to twelve top-level categories derived from an established technology taxonomy and enhanced the taxonomy by pinpointing DLT's ESG elements. Leveraging transformer-based language models, we fine-tuned a pre-trained language model for a Named Entity Recognition (NER) task using our labeled dataset. We used our fine-tuned language model to distill the corpus to 505 key papers, facilitating a literature review via named entities and temporal graph analysis on DLT evolution in the context of ESG. Our con
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InstructGLM&#30340;&#32467;&#26500;&#21270;&#35821;&#35328;&#27169;&#22411;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#22270;&#34920;&#23398;&#20064;&#38382;&#39064;&#30456;&#32467;&#21512;&#65292;&#26088;&#22312;&#25506;&#32034;&#26159;&#21542;&#21487;&#20197;&#29992;&#35821;&#35328;&#27169;&#22411;&#21462;&#20195;&#22270;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#22270;&#34920;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.07134</link><description>&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#26159;&#22270;&#34920;&#25152;&#38656;&#35201;&#30340;&#20840;&#37096;&#20869;&#23481;
&lt;/p&gt;
&lt;p&gt;
Natural Language is All a Graph Needs. (arXiv:2308.07134v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07134
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InstructGLM&#30340;&#32467;&#26500;&#21270;&#35821;&#35328;&#27169;&#22411;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#22270;&#34920;&#23398;&#20064;&#38382;&#39064;&#30456;&#32467;&#21512;&#65292;&#26088;&#22312;&#25506;&#32034;&#26159;&#21542;&#21487;&#20197;&#29992;&#35821;&#35328;&#27169;&#22411;&#21462;&#20195;&#22270;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#22270;&#34920;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#22914;ChatGPT&#65292;&#24050;&#32463;&#22312;&#20154;&#24037;&#26234;&#33021;&#30340;&#21508;&#20010;&#30740;&#31350;&#39046;&#22495;&#20013;&#24341;&#36215;&#20102;&#38761;&#21629;&#12290;&#22522;&#20110;Transformer&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36880;&#28176;&#21462;&#20195;&#20102;CNN&#21644;RNN&#65292;&#23558;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#32479;&#19968;&#36215;&#26469;&#12290;&#19982;&#30456;&#23545;&#29420;&#31435;&#23384;&#22312;&#30340;&#25968;&#25454;&#65288;&#22914;&#22270;&#20687;&#12289;&#35270;&#39057;&#25110;&#25991;&#26412;&#65289;&#30456;&#27604;&#65292;&#22270;&#34920;&#26159;&#19968;&#31181;&#21253;&#21547;&#20016;&#23500;&#32467;&#26500;&#21644;&#20851;&#31995;&#20449;&#24687;&#30340;&#25968;&#25454;&#31867;&#22411;&#12290;&#21516;&#26102;&#65292;&#20316;&#20026;&#26368;&#20855;&#34920;&#29616;&#21147;&#30340;&#23186;&#20171;&#20043;&#19968;&#65292;&#33258;&#28982;&#35821;&#35328;&#22312;&#25551;&#36848;&#22797;&#26434;&#32467;&#26500;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#23558;&#22270;&#34920;&#23398;&#20064;&#38382;&#39064;&#32435;&#20837;&#29983;&#25104;&#24335;&#35821;&#35328;&#24314;&#27169;&#26694;&#26550;&#30340;&#29616;&#26377;&#24037;&#20316;&#20173;&#28982;&#38750;&#24120;&#26377;&#38480;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#19981;&#26029;&#22686;&#38271;&#65292;&#25506;&#32034;LLMs&#26159;&#21542;&#20063;&#21487;&#20197;&#26367;&#20195;GNNs&#25104;&#20026;&#22270;&#34920;&#30340;&#22522;&#30784;&#27169;&#22411;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;InstructGLM&#65288;&#32467;&#26500;&#21270;&#35821;&#35328;&#27169;&#22411;&#65289;&#31639;&#27861;&#65292;&#31995;&#32479;&#22320;&#35774;&#35745;&#39640;&#24230;&#21487;&#25193;&#23637;&#30340;&#27169;&#22411;&#26469;&#22788;&#29702;&#22270;&#34920;&#23398;&#20064;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers-based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Pareto Invariant Representation Learning&#65288;PaInvRL&#65289;&#30340;&#26694;&#26550;&#65292;&#24212;&#29992;&#20110;&#22810;&#23186;&#20307;&#25512;&#33616;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#23398;&#20064;&#19981;&#21464;&#34920;&#31034;&#21644;&#21464;&#20307;&#34920;&#31034;&#30340;&#21516;&#26102;&#26469;&#32531;&#35299;&#36890;&#29992;&#34920;&#31034;&#24341;&#20837;&#30340;&#38169;&#35823;&#30456;&#20851;&#24615;&#38382;&#39064;&#12290;&#20174;IID-OOD&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#35282;&#24230;&#65292;PaInvRL&#20943;&#23569;&#20102;&#38169;&#35823;&#30456;&#20851;&#24615;&#23545;&#29992;&#25143;&#20559;&#22909;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2308.04706</link><description>&lt;p&gt;
Pareto&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#22312;&#22810;&#23186;&#20307;&#25512;&#33616;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Pareto Invariant Representation Learning for Multimedia Recommendation. (arXiv:2308.04706v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04706
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Pareto Invariant Representation Learning&#65288;PaInvRL&#65289;&#30340;&#26694;&#26550;&#65292;&#24212;&#29992;&#20110;&#22810;&#23186;&#20307;&#25512;&#33616;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#23398;&#20064;&#19981;&#21464;&#34920;&#31034;&#21644;&#21464;&#20307;&#34920;&#31034;&#30340;&#21516;&#26102;&#26469;&#32531;&#35299;&#36890;&#29992;&#34920;&#31034;&#24341;&#20837;&#30340;&#38169;&#35823;&#30456;&#20851;&#24615;&#38382;&#39064;&#12290;&#20174;IID-OOD&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#35282;&#24230;&#65292;PaInvRL&#20943;&#23569;&#20102;&#38169;&#35823;&#30456;&#20851;&#24615;&#23545;&#29992;&#25143;&#20559;&#22909;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23186;&#20307;&#25512;&#33616;&#28041;&#21450;&#20010;&#24615;&#21270;&#25490;&#24207;&#20219;&#21153;&#65292;&#36890;&#24120;&#20351;&#29992;&#36890;&#29992;&#32534;&#30721;&#22120;&#34920;&#31034;&#22810;&#23186;&#20307;&#20869;&#23481;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36890;&#29992;&#34920;&#31034;&#24341;&#20837;&#20102;&#38169;&#35823;&#30340;&#30456;&#20851;&#24615;&#65292;&#26080;&#27861;&#25581;&#31034;&#29992;&#25143;&#30340;&#30495;&#23454;&#20559;&#22909;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#23581;&#35797;&#36890;&#36807;&#23398;&#20064;&#19981;&#21464;&#34920;&#31034;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#24573;&#35270;&#20102;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;IID&#65289;&#21644;&#38750;&#20998;&#24067;&#65288;OOD&#65289;&#24191;&#20041;&#21270;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Pareto Invariant Representation Learning&#65288;PaInvRL&#65289;&#30340;&#26694;&#26550;&#65292;&#20174;IID-OOD&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#35282;&#24230;&#20943;&#23569;&#20102;&#38169;&#35823;&#30456;&#20851;&#24615;&#30340;&#24433;&#21709;&#65292;&#21516;&#26102;&#23398;&#20064;&#19981;&#21464;&#34920;&#31034;&#65288;&#21560;&#24341;&#29992;&#25143;&#27880;&#24847;&#30340;&#20869;&#22312;&#22240;&#32032;&#65289;&#21644;&#21464;&#20307;&#34920;&#31034;&#65288;&#20854;&#20182;&#22240;&#32032;&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;PaInvRL&#21253;&#25324;&#19977;&#20010;&#36845;&#20195;&#25191;&#34892;&#30340;&#27169;&#22359;&#65306;&#65288;i&#65289;&#38750;&#21516;&#36136;&#35782;&#21035;&#27169;&#22359;&#65292;&#29992;&#20110;&#35782;&#21035;&#21453;&#26144;&#20998;&#24067;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Multimedia recommendation involves personalized ranking tasks, where multimedia content is usually represented using a generic encoder. However, these generic representations introduce spurious correlations that fail to reveal users' true preferences. Existing works attempt to alleviate this problem by learning invariant representations, but overlook the balance between independent and identically distributed (IID) and out-of-distribution (OOD) generalization. In this paper, we propose a framework called Pareto Invariant Representation Learning (PaInvRL) to mitigate the impact of spurious correlations from an IID-OOD multi-objective optimization perspective, by learning invariant representations (intrinsic factors that attract user attention) and variant representations (other factors) simultaneously. Specifically, PaInvRL includes three iteratively executed modules: (i) heterogeneous identification module, which identifies the heterogeneous environments to reflect distributional shift
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20174;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;ChatGPT&#22312;&#28857;&#12289;&#23545;&#12289;&#21015;&#34920;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#25512;&#33616;&#33021;&#21147;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#22312;&#22235;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#24182;&#21457;&#29616;ChatGPT&#22312;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#34920;&#29616;&#22343;&#20248;&#20110;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#21015;&#34920;&#25490;&#21517;&#20013;&#33021;&#22815;&#36798;&#21040;&#25104;&#26412;&#21644;&#24615;&#33021;&#26368;&#20339;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.02182</link><description>&lt;p&gt;
&#25581;&#31034;ChatGPT&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Uncovering ChatGPT's Capabilities in Recommender Systems. (arXiv:2305.02182v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02182
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;ChatGPT&#22312;&#28857;&#12289;&#23545;&#12289;&#21015;&#34920;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#25512;&#33616;&#33021;&#21147;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#22312;&#22235;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#24182;&#21457;&#29616;ChatGPT&#22312;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#34920;&#29616;&#22343;&#20248;&#20110;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#21015;&#34920;&#25490;&#21517;&#20013;&#33021;&#22815;&#36798;&#21040;&#25104;&#26412;&#21644;&#24615;&#33021;&#26368;&#20339;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#30340;&#38382;&#31572;&#21151;&#33021;&#21560;&#24341;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30028;&#21450;&#22806;&#30028;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#27979;&#35797;ChatGPT&#22312;&#25512;&#33616;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#26412;&#30740;&#31350;&#20174;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;ChatGPT&#22312;&#28857;&#12289;&#23545;&#12289;&#21015;&#34920;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#25512;&#33616;&#33021;&#21147;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#12290;&#36890;&#36807;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#22235;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;ChatGPT&#22312;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#34920;&#29616;&#22343;&#20248;&#20110;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#22522;&#20110;&#21333;&#20301;&#25104;&#26412;&#25913;&#36827;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#30830;&#23450;ChatGPT&#22312;&#21015;&#34920;&#25490;&#21517;&#20013;&#33021;&#22815;&#22312;&#25104;&#26412;&#21644;&#24615;&#33021;&#20043;&#38388;&#23454;&#29616;&#26368;&#20339;&#24179;&#34913;&#65292;&#32780;&#22312;&#23545;&#21644;&#28857;&#25490;&#21517;&#20013;&#34920;&#29616;&#30456;&#23545;&#36739;&#24369;&#12290;
&lt;/p&gt;
&lt;p&gt;
The debut of ChatGPT has recently attracted the attention of the natural language processing (NLP) community and beyond. Existing studies have demonstrated that ChatGPT shows significant improvement in a range of downstream NLP tasks, but the capabilities and limitations of ChatGPT in terms of recommendations remain unclear. In this study, we aim to conduct an empirical analysis of ChatGPT's recommendation ability from an Information Retrieval (IR) perspective, including point-wise, pair-wise, and list-wise ranking. To achieve this goal, we re-formulate the above three recommendation policies into a domain-specific prompt format. Through extensive experiments on four datasets from different domains, we demonstrate that ChatGPT outperforms other large language models across all three ranking policies. Based on the analysis of unit cost improvements, we identify that ChatGPT with list-wise ranking achieves the best trade-off between cost and performance compared to point-wise and pair-wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#35805;&#24335;&#25628;&#32034;&#20013;&#29992;&#25143;&#21709;&#24212;&#27169;&#25311;&#30340;&#26041;&#27861;&#12290;&#24403;&#21069;&#30340;&#27169;&#25311;&#31995;&#32479;&#35201;&#20040;&#21482;&#33021;&#23545;&#26159;&#38750;&#38382;&#39064;&#36827;&#34892;&#22238;&#31572;&#65292;&#35201;&#20040;&#26080;&#27861;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#21709;&#24212;&#12290;&#36890;&#36807;&#29992;&#26356;&#23567;&#20294;&#20808;&#36827;&#30340;&#31995;&#32479;&#26367;&#25442;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#29992;&#25143;&#27169;&#25311;&#31995;&#32479;&#65292;&#33021;&#22815;&#26174;&#33879;&#25913;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.07944</link><description>&lt;p&gt;
&#35770;&#29992;&#25143;&#21709;&#24212;&#27169;&#25311;&#22312;&#23545;&#35805;&#24335;&#25628;&#32034;&#20013;&#30340;&#28145;&#20837;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An In-depth Investigation of User Response Simulation for Conversational Search. (arXiv:2304.07944v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#35805;&#24335;&#25628;&#32034;&#20013;&#29992;&#25143;&#21709;&#24212;&#27169;&#25311;&#30340;&#26041;&#27861;&#12290;&#24403;&#21069;&#30340;&#27169;&#25311;&#31995;&#32479;&#35201;&#20040;&#21482;&#33021;&#23545;&#26159;&#38750;&#38382;&#39064;&#36827;&#34892;&#22238;&#31572;&#65292;&#35201;&#20040;&#26080;&#27861;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#21709;&#24212;&#12290;&#36890;&#36807;&#29992;&#26356;&#23567;&#20294;&#20808;&#36827;&#30340;&#31995;&#32479;&#26367;&#25442;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#29992;&#25143;&#27169;&#25311;&#31995;&#32479;&#65292;&#33021;&#22815;&#26174;&#33879;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24335;&#25628;&#32034;&#22312;&#20449;&#24687;&#26816;&#32034;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#23427;&#36890;&#36807;&#22810;&#27425;&#33258;&#28982;&#35821;&#35328;&#20132;&#20114;&#26469;&#28548;&#28165;&#21644;&#35299;&#20915;&#29992;&#25143;&#30340;&#25628;&#32034;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#31995;&#32479;&#26159;&#36890;&#36807;&#35760;&#24405;&#25110;&#20154;&#24037;&#23545;&#35805;&#26085;&#24535;&#36827;&#34892;&#35757;&#32451;&#21644;&#28436;&#31034;&#30340;&#12290;&#26368;&#32456;&#65292;&#23545;&#35805;&#24335;&#25628;&#32034;&#31995;&#32479;&#24212;&#35813;&#22312;&#26410;&#35265;&#36807;&#30340;&#23545;&#35805;&#36712;&#36857;&#30340;&#24320;&#25918;&#29615;&#22659;&#20013;&#36827;&#34892;&#35757;&#32451;&#12289;&#35780;&#20272;&#21644;&#37096;&#32626;&#12290;&#19968;&#20010;&#20851;&#38190;&#30340;&#25361;&#25112;&#26159;&#35757;&#32451;&#21644;&#35780;&#20272;&#36825;&#26679;&#30340;&#31995;&#32479;&#37117;&#38656;&#35201;&#20154;&#24037;&#21442;&#19982;&#65292;&#36825;&#26082;&#26114;&#36149;&#21448;&#19981;&#21487;&#25193;&#23637;&#12290;&#20854;&#20013;&#19968;&#31181;&#31574;&#30053;&#26159;&#27169;&#25311;&#29992;&#25143;&#65292;&#20197;&#27492;&#26469;&#20943;&#23569;&#25193;&#23637;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#29992;&#25143;&#27169;&#25311;&#22120;&#35201;&#20040;&#20165;&#38480;&#20110;&#23545;&#23545;&#35805;&#25628;&#32034;&#31995;&#32479;&#30340;&#26159;&#38750;&#38382;&#39064;&#36827;&#34892;&#22238;&#31572;&#65292;&#35201;&#20040;&#26080;&#27861;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#21709;&#24212;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#36890;&#36807;&#29992;&#19968;&#20010;&#26356;&#23567;&#20294;&#20808;&#36827;&#30340;&#31995;&#32479;&#26469;&#26367;&#25442;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#29992;&#25143;&#27169;&#25311;&#31995;&#32479;&#65292;&#33021;&#22815;&#22823;&#24133;&#25913;&#36827;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational search has seen increased recent attention in both the IR and NLP communities. It seeks to clarify and solve a user's search need through multi-turn natural language interactions. However, most existing systems are trained and demonstrated with recorded or artificial conversation logs. Eventually, conversational search systems should be trained, evaluated, and deployed in an open-ended setting with unseen conversation trajectories. A key challenge is that training and evaluating such systems both require a human-in-the-loop, which is expensive and does not scale. One strategy for this is to simulate users, thereby reducing the scaling costs. However, current user simulators are either limited to only respond to yes-no questions from the conversational search system, or unable to produce high quality responses in general.  In this paper, we show that current state-of-the-art user simulation system could be significantly improved by replacing it with a smaller but advanced
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25215;&#35834;PIR&#26041;&#26696;&#65292;&#36890;&#36807;&#32467;&#21512;&#32447;&#24615;&#26144;&#23556;&#25215;&#35834;&#21644;&#20219;&#24847;&#32447;&#24615;PIR&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;$k$-&#21487;&#39564;&#35777;&#30340;PIR&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2302.01733</link><description>&lt;p&gt;
&#25215;&#35834;&#31169;&#20154;&#20449;&#24687;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Committed Private Information Retrieval. (arXiv:2302.01733v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01733
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25215;&#35834;PIR&#26041;&#26696;&#65292;&#36890;&#36807;&#32467;&#21512;&#32447;&#24615;&#26144;&#23556;&#25215;&#35834;&#21644;&#20219;&#24847;&#32447;&#24615;PIR&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;$k$-&#21487;&#39564;&#35777;&#30340;PIR&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31169;&#20154;&#20449;&#24687;&#26816;&#32034;&#65288;PIR&#65289;&#26041;&#26696;&#20801;&#35768;&#23458;&#25143;&#31471;&#22312;$k$&#20010;&#26381;&#21153;&#22120;&#30340;$n$&#20010;&#39033;&#30446;$x_1,x_2,\ldots,x_n$&#20013;&#26816;&#32034;&#20986;&#19968;&#20010;&#25968;&#25454;&#39033;&#30446;$x_i$&#65292;&#21363;&#20351;&#24403;$t&lt;k$&#20010;&#26381;&#21153;&#22120;&#21512;&#35851;&#24182;&#35797;&#22270;&#23398;&#20064;$i$&#26102;&#20063;&#19981;&#20250;&#36879;&#38706;$i$&#26159;&#20160;&#20040;&#12290;&#36825;&#26679;&#30340;PIR&#26041;&#26696;&#34987;&#31216;&#20026;$t-$&#31169;&#23494;&#12290;&#22914;&#26524;&#23458;&#25143;&#31471;&#21487;&#20197;&#22312;$v\leq k$&#20010;&#26381;&#21153;&#22120;&#21512;&#35851;&#24182;&#35797;&#22270;&#36890;&#36807;&#21457;&#36865;&#31713;&#25913;&#30340;&#25968;&#25454;&#26469;&#24858;&#24324;&#23458;&#25143;&#31471;&#30340;&#24773;&#20917;&#19979;&#39564;&#35777;&#26816;&#32034;&#21040;&#30340;$x_i$&#30340;&#27491;&#30830;&#24615;&#65292;&#21017;PIR&#26041;&#26696;&#20026;$v-$&#21487;&#39564;&#35777;&#12290;&#25991;&#29486;&#20013;&#30340;&#22823;&#22810;&#25968;&#20808;&#21069;&#30740;&#31350;&#20551;&#35774;$v&lt;k$&#65292;&#30041;&#19979;&#20102;&#26381;&#21153;&#22120;&#20840;&#37096;&#21512;&#35851;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26500;&#36896;&#65292;&#23558;&#32447;&#24615;&#26144;&#23556;&#25215;&#35834;&#65288;LMC&#65289;&#21644;&#20219;&#24847;&#32447;&#24615;PIR&#26041;&#26696;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#20135;&#29983;&#19968;&#20010;$k-$&#21487;&#39564;&#35777;&#30340;PIR&#26041;&#26696;&#65292;&#31216;&#20026;&#25215;&#35834;PIR&#26041;&#26696;&#12290;&#21363;&#20351;&#22312;&#26368;&#22351;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#25152;&#26377;&#26381;&#21153;&#22120;&#37117;&#22312;&#25915;&#20987;&#32773;&#30340;&#25511;&#21046;&#19979;&#65292;&#23613;&#31649;&#38544;&#31169;&#26080;&#27861;&#36991;&#20813;&#20002;&#22833;&#65292;&#23458;&#25143;&#31471;&#20063;&#19981;&#20250;&#34987;&#24858;&#24324;&#32780;&#25509;&#21463;&#19981;&#27491;&#30830;&#30340;$x_i$&#12290;
&lt;/p&gt;
&lt;p&gt;
A private information retrieval (PIR) scheme allows a client to retrieve a data item $x_i$ among $n$ items $x_1,x_2,\ldots,x_n$ from $k$ servers, without revealing what $i$ is even when $t &lt; k$ servers collude and try to learn $i$. Such a PIR scheme is said to be $t$-private. A PIR scheme is $v$-verifiable if the client can verify the correctness of the retrieved $x_i$ even when $v \leq k$ servers collude and try to fool the client by sending manipulated data. Most of the previous works in the literature on PIR assumed that $v &lt; k$, leaving the case of all-colluding servers open. We propose a generic construction that combines a linear map commitment (LMC) and an arbitrary linear PIR scheme to produce a $k$-verifiable PIR scheme, termed a committed PIR scheme. Such a scheme guarantees that even in the worst scenario, when all servers are under the control of an attacker, although the privacy is unavoidably lost, the client won't be fooled into accepting an incorrect $x_i$. We demonstra
&lt;/p&gt;</description></item></channel></rss>