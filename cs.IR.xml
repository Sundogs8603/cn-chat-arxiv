<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#39044;&#35757;&#32451;&#26694;&#26550;&#65292;&#29992;&#20110;&#28857;&#20987;&#29575;&#39044;&#27979;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#22810;&#23383;&#27573;&#20998;&#31867;&#25968;&#25454;&#21644;&#22823;&#37327;&#29992;&#25143;&#28857;&#20987;&#26085;&#24535;&#65292;&#23398;&#20064;&#26356;&#24191;&#20041;&#21644;&#26377;&#25928;&#30340;&#29305;&#24449;&#21644;&#23454;&#20363;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2308.01737</link><description>&lt;p&gt;
MAP: &#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#39044;&#35757;&#32451;&#26694;&#26550;&#29992;&#20110;&#28857;&#20987;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction. (arXiv:2308.01737v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01737
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#39044;&#35757;&#32451;&#26694;&#26550;&#65292;&#29992;&#20110;&#28857;&#20987;&#29575;&#39044;&#27979;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#22810;&#23383;&#27573;&#20998;&#31867;&#25968;&#25454;&#21644;&#22823;&#37327;&#29992;&#25143;&#28857;&#20987;&#26085;&#24535;&#65292;&#23398;&#20064;&#26356;&#24191;&#20041;&#21644;&#26377;&#25928;&#30340;&#29305;&#24449;&#21644;&#23454;&#20363;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20010;&#24615;&#21270;&#22312;&#32447;&#26381;&#21153;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#21644;&#30740;&#31350;&#12290;CTR&#39044;&#27979;&#30340;&#26368;&#31361;&#20986;&#29305;&#28857;&#26159;&#20854;&#22810;&#23383;&#27573;&#20998;&#31867;&#25968;&#25454;&#26684;&#24335;&#21644;&#24222;&#22823;&#32780;&#26085;&#30410;&#22686;&#38271;&#30340;&#25968;&#25454;&#37327;&#12290;&#31070;&#32463;&#27169;&#22411;&#30340;&#22823;&#23481;&#37327;&#26377;&#21161;&#20110;&#22312;&#30417;&#30563;&#23398;&#20064;&#33539;&#24335;&#19979;&#28040;&#21270;&#22914;&#27492;&#22823;&#37327;&#30340;&#25968;&#25454;&#65292;&#20294;&#26159;&#23427;&#20204;&#26410;&#33021;&#20805;&#20998;&#21033;&#29992;&#22823;&#37327;&#25968;&#25454;&#30340;&#28508;&#21147;&#65292;&#22240;&#20026;1&#27604;&#29305;&#30340;&#28857;&#20987;&#20449;&#21495;&#19981;&#36275;&#20197;&#25351;&#23548;&#27169;&#22411;&#23398;&#20064;&#21151;&#33021;&#24378;&#22823;&#30340;&#29305;&#24449;&#21644;&#23454;&#20363;&#34920;&#31034;&#12290;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#33539;&#24335;&#25552;&#20379;&#20102;&#26356;&#26377;&#21069;&#26223;&#30340;&#39044;&#35757;&#32451;-&#24494;&#35843;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#22823;&#37327;&#29992;&#25143;&#28857;&#20987;&#26085;&#24535;&#24182;&#23398;&#20064;&#26356;&#24191;&#20041;&#21644;&#26377;&#25928;&#30340;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;CTR&#39044;&#27979;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#24403;&#21069;&#22312;&#36825;&#26041;&#38754;&#30340;&#24037;&#20316;&#20165;&#20165;&#26159;&#21021;&#27493;&#21644;&#22522;&#30784;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#39044;&#35757;&#32451;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research. The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume. The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances. The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations. However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary. To this end, we propose a Model-agnostic pretrain
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#23545;&#20020;&#24202;&#35760;&#24405;&#20013;&#32933;&#32982;&#30417;&#27979;&#30340;&#25991;&#26412;&#25366;&#25496;&#33021;&#21147;&#65292;&#19982;&#20043;&#21069;&#30340;&#27491;&#21017;&#34920;&#36798;&#24335;&#30456;&#27604;&#65292;ChatGPT&#30340;&#21484;&#22238;&#29575;&#26356;&#39640;&#65292;&#20294;&#31934;&#30830;&#24230;&#30053;&#20302;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#20861;&#21307;&#20020;&#24202;&#21465;&#36848;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#28508;&#21147;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2308.01666</link><description>&lt;p&gt;
&#35780;&#20272;ChatGPT&#23545;&#32933;&#32982;&#30417;&#27979;&#20013;&#20020;&#24202;&#35760;&#24405;&#30340;&#25991;&#26412;&#25366;&#25496;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Evaluating ChatGPT text-mining of clinical records for obesity monitoring. (arXiv:2308.01666v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01666
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#23545;&#20020;&#24202;&#35760;&#24405;&#20013;&#32933;&#32982;&#30417;&#27979;&#30340;&#25991;&#26412;&#25366;&#25496;&#33021;&#21147;&#65292;&#19982;&#20043;&#21069;&#30340;&#27491;&#21017;&#34920;&#36798;&#24335;&#30456;&#27604;&#65292;ChatGPT&#30340;&#21484;&#22238;&#29575;&#26356;&#39640;&#65292;&#20294;&#31934;&#30830;&#24230;&#30053;&#20302;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#20861;&#21307;&#20020;&#24202;&#21465;&#36848;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#28508;&#21147;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#20861;&#21307;&#20020;&#24202;&#21465;&#36848;&#20173;&#28982;&#26159;&#19968;&#20010;&#24456;&#23569;&#34987;&#21033;&#29992;&#30340;&#36164;&#28304;&#65292;&#29992;&#20110;&#24212;&#23545;&#22797;&#26434;&#30142;&#30149;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#19968;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(ChatGPT)&#21644;&#20043;&#21069;&#24320;&#21457;&#30340;&#27491;&#21017;&#34920;&#36798;&#24335;(RegexT)&#22312;&#35782;&#21035;&#20861;&#21307;&#21465;&#36848;&#20013;&#36229;&#37325;&#20307;&#20917;&#35780;&#20998;(BCS)&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#26041;&#27861;&#65306;&#20351;&#29992;RegexT&#25110;&#23558;&#21465;&#36848;&#38468;&#21152;&#21040;&#21457;&#36865;&#32473;ChatGPT&#30340;&#25552;&#31034;&#20013;&#26469;&#25552;&#21462;4,415&#20010;&#21311;&#21517;&#20020;&#24202;&#21465;&#36848;&#20013;&#30340;BCS&#20540;&#65292;&#36843;&#20351;&#27169;&#22411;&#36820;&#22238;BCS&#20449;&#24687;&#12290;&#36890;&#36807;&#25163;&#21160;&#23457;&#26597;&#25968;&#25454;&#36827;&#34892;&#27604;&#36739;&#12290;&#32467;&#26524;&#65306;RegexT&#30340;&#31934;&#30830;&#24230;(100%&#65292;95% CI 94.81-100%)&#39640;&#20110;ChatGPT&#30340;&#31934;&#30830;&#24230;(89.3%&#65292;95% CI 82.75-93.64%)&#12290;&#28982;&#32780;&#65292;ChatGPT&#30340;&#21484;&#22238;&#29575;(100%&#65292;95% CI 96.18-100%)&#35201;&#36828;&#39640;&#20110;RegexT&#30340;&#21484;&#22238;&#29575;(72.6%&#65292;95% CI 63.92-79.94%)&#12290;&#23616;&#38480;&#24615;&#65306;&#38656;&#35201;&#23545;&#25552;&#31034;&#24037;&#31243;&#36827;&#34892;&#24494;&#35843;&#20197;&#25913;&#21892;ChatGPT&#36755;&#20986;&#12290;&#32467;&#35770;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#21019;&#24314;&#21508;&#31181;&#26426;&#20250;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#65292;&#24182;&#19988;&#34429;&#28982;&#22797;&#26434;&#65292;&#20294;&#20855;&#26377;&#30452;&#35266;&#30340;&#30028;&#38754;&#29992;&#20110;in
&lt;/p&gt;
&lt;p&gt;
Background: Veterinary clinical narratives remain a largely untapped resource for addressing complex diseases. Here we compare the ability of a large language model (ChatGPT) and a previously developed regular expression (RegexT) to identify overweight body condition scores (BCS) in veterinary narratives. Methods: BCS values were extracted from 4,415 anonymised clinical narratives using either RegexT or by appending the narrative to a prompt sent to ChatGPT coercing the model to return the BCS information. Data were manually reviewed for comparison. Results: The precision of RegexT was higher (100%, 95% CI 94.81-100%) than the ChatGPT (89.3%; 95% CI82.75-93.64%). However, the recall of ChatGPT (100%. 95% CI 96.18-100%) was considerably higher than that of RegexT (72.6%, 95% CI 63.92-79.94%). Limitations: Subtle prompt engineering is needed to improve ChatGPT output. Conclusions: Large language models create diverse opportunities and, whilst complex, present an intuitive interface to in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;Slate&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#31867;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#20915;&#31574;&#31995;&#32479;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#20219;&#24847;&#22870;&#21169;&#20989;&#25968;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30334;&#19975;&#32423;&#21035;&#21160;&#20316;&#31354;&#38388;&#38382;&#39064;&#19978;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.01566</link><description>&lt;p&gt;
&#24555;&#36895;Slate&#31574;&#30053;&#20248;&#21270;&#65306;&#36229;&#36234;Plackett-Luce
&lt;/p&gt;
&lt;p&gt;
Fast Slate Policy Optimization: Going Beyond Plackett-Luce. (arXiv:2308.01566v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;Slate&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#31867;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#20915;&#31574;&#31995;&#32479;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#20219;&#24847;&#22870;&#21169;&#20989;&#25968;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30334;&#19975;&#32423;&#21035;&#21160;&#20316;&#31354;&#38388;&#38382;&#39064;&#19978;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20013;&#19968;&#20010;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#26500;&#24314;&#27169;&#22359;&#26159;&#36820;&#22238;Slate&#65292;&#21363;&#32473;&#23450;&#19968;&#20010;&#26597;&#35810;&#36820;&#22238;&#26377;&#24207;&#30340;&#39033;&#30446;&#21015;&#34920;&#12290;&#35813;&#25216;&#26415;&#30340;&#24212;&#29992;&#21253;&#25324;&#25628;&#32034;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#12290;&#24403;&#34892;&#21160;&#31354;&#38388;&#24456;&#22823;&#26102;&#65292;&#20915;&#31574;&#31995;&#32479;&#20250;&#38480;&#21046;&#22312;&#29305;&#23450;&#32467;&#26500;&#20013;&#20197;&#24555;&#36895;&#23436;&#25104;&#22312;&#32447;&#26597;&#35810;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#36825;&#20123;&#22823;&#35268;&#27169;&#20915;&#31574;&#31995;&#32479;&#22312;&#32473;&#23450;&#20219;&#24847;&#22870;&#21169;&#20989;&#25968;&#19979;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#23398;&#20064;&#38382;&#39064;&#36716;&#21270;&#20026;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#31867;&#65292;&#23427;&#28304;&#20110;&#20915;&#31574;&#20989;&#25968;&#30340;&#19968;&#31181;&#26032;&#39062;&#25918;&#26494;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#30340;&#21160;&#20316;&#31354;&#38388;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#24120;&#29992;&#30340;Plackett-Luce&#31574;&#30053;&#31867;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21160;&#20316;&#31354;&#38388;&#22823;&#23567;&#36798;&#21040;&#30334;&#19975;&#32423;&#21035;&#30340;&#38382;&#39064;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
An increasingly important building block of large scale machine learning systems is based on returning slates; an ordered lists of items given a query. Applications of this technology include: search, information retrieval and recommender systems. When the action space is large, decision systems are restricted to a particular structure to complete online queries quickly. This paper addresses the optimization of these large scale decision systems given an arbitrary reward function. We cast this learning problem in a policy optimization framework and propose a new class of policies, born from a novel relaxation of decision functions. This results in a simple, yet efficient learning algorithm that scales to massive action spaces. We compare our method to the commonly adopted Plackett-Luce policy class and demonstrate the effectiveness of our approach on problems with action space sizes in the order of millions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#20852;&#36259;&#20010;&#24615;&#21270;&#25512;&#33616;&#20013;&#25968;&#25454;&#19981;&#24179;&#34913;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#29992;&#25143;&#34920;&#31034;&#65288;MUR&#65289;&#23545;&#20110;&#25968;&#25454;&#19981;&#24179;&#34913;&#30340;&#25935;&#24863;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23494;&#24230;&#21152;&#26435;&#30340;&#26041;&#27861;&#26469;&#25913;&#36827;&#23545;&#20110;&#38271;&#23614;&#29289;&#21697;&#30340;&#25512;&#33616;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.01563</link><description>&lt;p&gt;
&#22810;&#20852;&#36259;&#20010;&#24615;&#21270;&#25512;&#33616;&#20013;&#30340;&#23494;&#24230;&#21152;&#26435;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Density Weighting for Multi-Interest Personalized Recommendation. (arXiv:2308.01563v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#20852;&#36259;&#20010;&#24615;&#21270;&#25512;&#33616;&#20013;&#25968;&#25454;&#19981;&#24179;&#34913;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#29992;&#25143;&#34920;&#31034;&#65288;MUR&#65289;&#23545;&#20110;&#25968;&#25454;&#19981;&#24179;&#34913;&#30340;&#25935;&#24863;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23494;&#24230;&#21152;&#26435;&#30340;&#26041;&#27861;&#26469;&#25913;&#36827;&#23545;&#20110;&#38271;&#23614;&#29289;&#21697;&#30340;&#25512;&#33616;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#20351;&#29992;&#22810;&#29992;&#25143;&#34920;&#31034;&#65288;MUR&#65289;&#26469;&#24314;&#27169;&#29992;&#25143;&#34892;&#20026;&#32780;&#19981;&#26159;&#21333;&#20010;&#29992;&#25143;&#34920;&#31034;&#65288;SUR&#65289;&#24050;&#32463;&#35777;&#26126;&#21487;&#20197;&#25552;&#39640;&#20010;&#24615;&#21270;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;MUR&#30340;&#24615;&#33021;&#25552;&#21319;&#21487;&#33021;&#23545;&#29289;&#21697;&#21644;/&#25110;&#29992;&#25143;&#20852;&#36259;&#20998;&#24067;&#30340;&#20559;&#26012;&#24615;&#25935;&#24863;&#12290;&#24403;&#25968;&#25454;&#20998;&#24067;&#39640;&#24230;&#20559;&#26012;&#26102;&#65292;&#23398;&#20064;&#22810;&#20010;&#34920;&#31034;&#30340;&#25910;&#30410;&#20943;&#23567;&#65292;&#22240;&#20026;&#27169;&#22411;&#22312;&#28909;&#38376;&#29289;&#21697;/&#20852;&#36259;&#19978;&#21344;&#20027;&#23548;&#22320;&#20301;&#65292;&#23548;&#33268;&#23545;&#20110;&#38271;&#23614;&#29289;&#21697;&#30340;&#25512;&#33616;&#25928;&#26524;&#24046;&#12290;&#22240;&#27492;&#65292;MUR&#26041;&#27861;&#23545;&#20110;&#25968;&#25454;&#31232;&#30095;&#24615;&#30340;&#40065;&#26834;&#24615;&#26159;&#23454;&#29616;&#33391;&#22909;&#25512;&#33616;&#25928;&#26524;&#30340;&#20851;&#38190;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;MUR&#21644;&#25968;&#25454;&#19981;&#24179;&#34913;&#30340;&#30740;&#31350;&#22312;&#36807;&#21435;&#24456;&#22823;&#31243;&#24230;&#19978;&#26159;&#29420;&#31435;&#36827;&#34892;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26356;&#28145;&#20837;&#22320;&#30740;&#31350;&#20102;&#20174;&#19981;&#24179;&#34913;&#25968;&#25454;&#20998;&#24067;&#20013;&#25512;&#26029;&#20986;&#30340;MUR&#30340;&#32570;&#28857;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#28857;&#36129;&#29486;&#65306;&#65288;1&#65289;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MUR&#30456;&#23545;&#20110;&#25968;&#25454;&#19981;&#24179;&#34913;&#30340;&#25935;&#24863;&#24615;&#65292;&#65288;2&#65289;&#20026;&#20102;&#25913;&#36827;&#23545;&#20110;&#38271;&#23614;&#29289;&#21697;&#30340;MUR&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23494;&#24230;&#21152;&#26435;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Using multiple user representations (MUR) to model user behavior instead of a single user representation (SUR) has been shown to improve personalization in recommendation systems. However, the performance gains observed with MUR can be sensitive to the skewness in the item and/or user interest distribution. When the data distribution is highly skewed, the gains observed by learning multiple representations diminish since the model dominates on head items/interests, leading to poor performance on tail items. Robustness to data sparsity is therefore essential for MUR-based approaches to achieve good performance for recommendations. Yet, research in MUR and data imbalance have largely been done independently. In this paper, we delve deeper into the shortcomings of MUR inferred from imbalanced data distributions. We make several contributions: (1) Using synthetic datasets, we demonstrate the sensitivity of MUR with respect to data imbalance, (2) To improve MUR for tail items, we propose an
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#35843;&#26597;&#65292;&#38024;&#23545;&#25512;&#33616;&#36807;&#31243;&#20013;&#21487;&#33021;&#20986;&#29616;&#30340;&#25968;&#25454;&#25110;&#31639;&#27861;&#20559;&#35265;&#65292;&#25552;&#20379;&#20102;&#19968;&#20123;&#26041;&#27861;&#21644;&#24212;&#29992;&#26469;&#25552;&#21319;&#25512;&#33616;&#20013;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.13619</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20844;&#24179;&#24615;&#65306;&#22522;&#30784;&#12289;&#26041;&#27861;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fairness in Recommendation: Foundations, Methods and Applications. (arXiv:2205.13619v5 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13619
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#35843;&#26597;&#65292;&#38024;&#23545;&#25512;&#33616;&#36807;&#31243;&#20013;&#21487;&#33021;&#20986;&#29616;&#30340;&#25968;&#25454;&#25110;&#31639;&#27861;&#20559;&#35265;&#65292;&#25552;&#20379;&#20102;&#19968;&#20123;&#26041;&#27861;&#21644;&#24212;&#29992;&#26469;&#25552;&#21319;&#25512;&#33616;&#20013;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#26368;&#26222;&#36941;&#30340;&#24212;&#29992;&#20043;&#19968;&#65292;&#25512;&#33616;&#31995;&#32479;&#22312;&#36741;&#21161;&#20154;&#31867;&#20915;&#31574;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#29992;&#25143;&#30340;&#28385;&#24847;&#24230;&#21644;&#24179;&#21488;&#30340;&#21033;&#30410;&#19982;&#29983;&#25104;&#30340;&#25512;&#33616;&#32467;&#26524;&#30340;&#36136;&#37327;&#23494;&#20999;&#30456;&#20851;&#12290;&#28982;&#32780;&#65292;&#20316;&#20026;&#19968;&#20010;&#39640;&#24230;&#25968;&#25454;&#39537;&#21160;&#30340;&#31995;&#32479;&#65292;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#21463;&#21040;&#25968;&#25454;&#25110;&#31639;&#27861;&#20559;&#35265;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#20135;&#29983;&#19981;&#20844;&#24179;&#30340;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#21066;&#24369;&#31995;&#32479;&#30340;&#21487;&#20449;&#36182;&#24615;&#12290;&#22240;&#27492;&#65292;&#22312;&#25512;&#33616;&#35774;&#32622;&#20013;&#35299;&#20915;&#28508;&#22312;&#30340;&#19981;&#20844;&#24179;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#65292;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#32771;&#34385;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#28041;&#21450;&#25552;&#21319;&#25512;&#33616;&#20013;&#30340;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#36234;&#26469;&#36234;&#22810;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#30456;&#23545;&#38646;&#25955;&#19988;&#32570;&#20047;&#31995;&#32479;&#21270;&#25972;&#29702;&#65292;&#22240;&#27492;&#23545;&#20110;&#26032;&#30740;&#31350;&#20154;&#21592;&#26469;&#35828;&#38590;&#20197;&#28145;&#20837;&#39046;&#22495;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#23545;&#25512;&#33616;&#20013;&#29616;&#26377;&#20844;&#24179;&#24615;&#20316;&#21697;&#36827;&#34892;&#31995;&#32479;&#35843;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;
As one of the most pervasive applications of machine learning, recommender systems are playing an important role on assisting human decision making. The satisfaction of users and the interests of platforms are closely related to the quality of the generated recommendation results. However, as a highly data-driven system, recommender system could be affected by data or algorithmic bias and thus generate unfair results, which could weaken the reliance of the systems. As a result, it is crucial to address the potential unfairness problems in recommendation settings. Recently, there has been growing attention on fairness considerations in recommender systems with more and more literature on approaches to promote fairness in recommendation. However, the studies are rather fragmented and lack a systematic organization, thus making it difficult to penetrate for new researchers to the domain. This motivates us to provide a systematic survey of existing works on fairness in recommendation. This
&lt;/p&gt;</description></item></channel></rss>