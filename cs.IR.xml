<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;InteR&#65292;&#36890;&#36807;&#25628;&#32034;&#24341;&#25806;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#30340;&#20132;&#20114;&#20419;&#36827;&#30693;&#35782;&#31934;&#28860;&#65292;&#20174;&#32780;&#25552;&#39640;&#26816;&#32034;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.07402</link><description>&lt;p&gt;
&#25628;&#32034;&#24341;&#25806;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38388;&#30340;&#20132;&#20114;&#20248;&#21270;&#30693;&#35782;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
Knowledge Refinement via Interaction Between Search Engines and Large Language Models. (arXiv:2305.07402v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;InteR&#65292;&#36890;&#36807;&#25628;&#32034;&#24341;&#25806;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#30340;&#20132;&#20114;&#20419;&#36827;&#30693;&#35782;&#31934;&#28860;&#65292;&#20174;&#32780;&#25552;&#39640;&#26816;&#32034;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#22312;&#20174;&#22823;&#37327;&#25968;&#25454;&#20013;&#23450;&#20301;&#30456;&#20851;&#36164;&#28304;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#20316;&#29992;&#65292;&#20854;&#24212;&#29992;&#24050;&#20174;&#20256;&#32479;&#30693;&#35782;&#24211;&#21457;&#23637;&#33267;&#29616;&#20195;&#25628;&#32034;&#24341;&#25806;&#65288;SEs&#65289;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#36827;&#19968;&#27493;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#19982;&#25628;&#32034;&#31995;&#32479;&#20132;&#20114;&#38761;&#21629;&#24615;&#22320;&#25913;&#21464;&#20102;&#35813;&#39046;&#22495;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;LLMs&#21644;SEs&#30340;&#20248;&#32570;&#28857;&#65292;&#24378;&#35843;&#23427;&#20204;&#22312;&#29702;&#35299;&#29992;&#25143;&#26597;&#35810;&#21644;&#26816;&#32034;&#26368;&#26032;&#20449;&#24687;&#26041;&#38754;&#30340;&#21508;&#33258;&#20248;&#21183;&#12290;&#20026;&#20102;&#21033;&#29992;&#20004;&#31181;&#33539;&#20363;&#30340;&#20248;&#21183;&#24182;&#36991;&#20813;&#20854;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;InteR&#65292;&#36825;&#26159;&#19968;&#20010;&#36890;&#36807;SEs&#21644;LLMs&#20043;&#38388;&#30340;&#20132;&#20114;&#20419;&#36827;&#30693;&#35782;&#31934;&#28860;&#30340;&#26032;&#26694;&#26550;&#12290; InteR&#20351;SEs&#33021;&#22815;&#20351;&#29992;LLM&#29983;&#25104;&#30340;&#25688;&#35201;&#26469;&#35843;&#25972;&#26597;&#35810;&#65292;&#21516;&#26102;&#20351;LLMs&#33021;&#22815;&#20351;&#29992;SE&#26816;&#32034;&#21040;&#30340;&#25991;&#26723;&#26469;&#22686;&#24378;&#25552;&#31034;&#12290;&#36825;&#31181;&#36845;&#20195;&#30340;&#31934;&#28860;&#36807;&#31243;&#22686;&#24378;&#20102;SEs&#21644;LLMs&#30340;&#36755;&#20837;&#65292;&#20174;&#32780;&#23548;&#33268;&#26356;&#20934;&#30830;&#30340;&#26816;&#32034;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern search engines (SEs). The emergence of large language models (LLMs) has further revolutionized the field by enabling users to interact with search systems in natural language. In this paper, we explore the advantages and disadvantages of LLMs and SEs, highlighting their respective strengths in understanding user-issued queries and retrieving up-to-date information. To leverage the benefits of both paradigms while circumventing their limitations, we propose InteR, a novel framework that facilitates knowledge refinement through interaction between SEs and LLMs. InteR allows SEs to refine knowledge in query using LLM-generated summaries and enables LLMs to enhance prompts using SE-retrieved documents. This iterative refinement process augments the inputs of SEs and LLMs, leading to more accurate retrieval. Ex
&lt;/p&gt;</description></item></channel></rss>