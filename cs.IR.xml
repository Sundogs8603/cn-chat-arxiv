<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25490;&#24207;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;&#31639;&#27861;Neural PG-RANK&#65292;&#36890;&#36807;&#23558;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#23454;&#20363;&#21270;&#20026;Plackett-Luce&#25490;&#21517;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#23545;&#26816;&#32034;&#27169;&#22411;&#30340;&#21407;&#21017;&#24615;&#12289;&#31471;&#21040;&#31471;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2310.04407</link><description>&lt;p&gt;
&#29992;&#20110;&#25490;&#24207;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Policy-Gradient Training of Language Models for Ranking. (arXiv:2310.04407v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04407
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25490;&#24207;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;&#31639;&#27861;Neural PG-RANK&#65292;&#36890;&#36807;&#23558;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#23454;&#20363;&#21270;&#20026;Plackett-Luce&#25490;&#21517;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#23545;&#26816;&#32034;&#27169;&#22411;&#30340;&#21407;&#21017;&#24615;&#12289;&#31471;&#21040;&#31471;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#26816;&#32034;&#22312;&#23558;&#20107;&#23454;&#30693;&#35782;&#32435;&#20837;&#21040;&#35821;&#35328;&#22788;&#29702;&#27969;&#31243;&#20013;&#30340;&#20915;&#31574;&#36807;&#31243;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#20174;&#32842;&#22825;&#24335;&#32593;&#39029;&#25628;&#32034;&#21040;&#38382;&#31572;&#31995;&#32479;&#12290;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#25991;&#26412;&#26816;&#32034;&#27169;&#22411;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#36798;&#21040;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#65292;&#20294;&#36890;&#36807;&#20856;&#22411;&#30340;&#23545;&#27604;&#25439;&#22833;&#35757;&#32451;&#22522;&#20110;LLM&#30340;&#26816;&#32034;&#22120;&#38656;&#35201;&#22797;&#26434;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21253;&#25324;&#36873;&#25321;&#22256;&#38590;&#30340;&#36127;&#26679;&#26412;&#21644;&#20351;&#29992;&#39069;&#22806;&#30340;&#30417;&#30563;&#20316;&#20026;&#23398;&#20064;&#20449;&#21495;&#12290;&#36825;&#31181;&#20381;&#36182;&#20110;&#21551;&#21457;&#24335;&#31639;&#27861;&#30340;&#21407;&#22240;&#26159;&#23545;&#27604;&#25439;&#22833;&#26412;&#36523;&#26159;&#21551;&#21457;&#24335;&#30340;&#65292;&#19981;&#33021;&#30452;&#25509;&#20248;&#21270;&#22788;&#29702;&#27969;&#31243;&#26411;&#31471;&#20915;&#31574;&#36136;&#37327;&#30340;&#19979;&#28216;&#25351;&#26631;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31070;&#32463;PG-RANK&#65292;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;LLM&#23454;&#20363;&#21270;&#20026;Plackett-Luce&#25490;&#21517;&#31574;&#30053;&#65292;&#23398;&#20064;&#25490;&#24207;&#12290;&#31070;&#32463;PG-RANK&#20026;&#26816;&#32034;&#27169;&#22411;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#25552;&#20379;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#20316;&#20026;&#26356;&#22823;&#30340;&#20915;&#31574;&#31995;&#32479;&#30340;&#19968;&#37096;&#20998;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Text retrieval plays a crucial role in incorporating factual knowledge for decision making into language processing pipelines, ranging from chat-based web search to question answering systems. Current state-of-the-art text retrieval models leverage pre-trained large language models (LLMs) to achieve competitive performance, but training LLM-based retrievers via typical contrastive losses requires intricate heuristics, including selecting hard negatives and using additional supervision as learning signals. This reliance on heuristics stems from the fact that the contrastive loss itself is heuristic and does not directly optimize the downstream metrics of decision quality at the end of the processing pipeline. To address this issue, we introduce Neural PG-RANK, a novel training algorithm that learns to rank by instantiating a LLM as a Plackett-Luce ranking policy. Neural PG-RANK provides a principled method for end-to-end training of retrieval models as part of larger decision systems vi
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#21487;&#32553;&#25918;&#25512;&#33616;&#27169;&#22411;&#20013;&#23884;&#20837;&#23618;&#30340;&#23849;&#28291;&#29616;&#35937;&#65292;&#21457;&#29616;&#29305;&#24449;&#20132;&#20114;&#27169;&#22359;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#38480;&#21046;&#20102;&#23884;&#20837;&#23398;&#20064;&#65292;&#20294;&#20063;&#26159;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2310.04400</link><description>&lt;p&gt;
&#35770;&#21487;&#25193;&#23637;&#25512;&#33616;&#27169;&#22411;&#20013;&#23884;&#20837;&#22349;&#32553;&#29616;&#35937;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Embedding Collapse when Scaling up Recommendation Models. (arXiv:2310.04400v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04400
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#21487;&#32553;&#25918;&#25512;&#33616;&#27169;&#22411;&#20013;&#23884;&#20837;&#23618;&#30340;&#23849;&#28291;&#29616;&#35937;&#65292;&#21457;&#29616;&#29305;&#24449;&#20132;&#20114;&#27169;&#22359;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#38480;&#21046;&#20102;&#23884;&#20837;&#23398;&#20064;&#65292;&#20294;&#20063;&#26159;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#22522;&#30784;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#24341;&#21457;&#20102;&#24320;&#21457;&#22823;&#22411;&#25512;&#33616;&#27169;&#22411;&#20197;&#21033;&#29992;&#22823;&#37327;&#21487;&#29992;&#25968;&#25454;&#30340;&#26377;&#21069;&#26223;&#36235;&#21183;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35797;&#39564;&#25918;&#22823;&#29616;&#26377;&#30340;&#25512;&#33616;&#27169;&#22411;&#26102;&#21457;&#29616;&#65292;&#25193;&#22823;&#30340;&#27169;&#22411;&#24182;&#27809;&#26377;&#20196;&#20154;&#28385;&#24847;&#30340;&#25913;&#36827;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25193;&#22823;&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#65292;&#24182;&#21457;&#29616;&#20102;&#19968;&#31181;&#23884;&#20837;&#22349;&#32553;&#29616;&#35937;&#65292;&#36825;&#26368;&#32456;&#38459;&#30861;&#20102;&#21487;&#25193;&#23637;&#24615;&#65292;&#22312;&#36825;&#31181;&#29616;&#35937;&#20013;&#65292;&#23884;&#20837;&#30697;&#38453;&#20542;&#21521;&#20110;&#23384;&#22312;&#20110;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25512;&#33616;&#27169;&#22411;&#29305;&#23450;&#30340;&#29305;&#24449;&#20132;&#20114;&#27169;&#22359;&#20855;&#26377;&#21452;&#37325;&#20316;&#29992;&#12290;&#19968;&#26041;&#38754;&#65292;&#24403;&#19982;&#22349;&#32553;&#30340;&#23884;&#20837;&#20132;&#20114;&#26102;&#65292;&#35813;&#20132;&#20114;&#38480;&#21046;&#20102;&#23884;&#20837;&#23398;&#20064;&#65292;&#21152;&#21095;&#20102;&#23849;&#28291;&#38382;&#39064;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#29305;&#24449;&#20132;&#20114;&#23545;&#20110;&#32531;&#35299;&#20551;&#29305;&#24449;&#30340;&#25311;&#21512;&#33267;&#20851;&#37325;&#35201;&#65292;&#20174;&#32780;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;&#22522;&#20110;&#36825;&#19968;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Recent advances in deep foundation models have led to a promising trend of developing large recommendation models to leverage vast amounts of available data. However, we experiment to scale up existing recommendation models and observe that the enlarged models do not improve satisfactorily. In this context, we investigate the embedding layers of enlarged models and identify a phenomenon of embedding collapse, which ultimately hinders scalability, wherein the embedding matrix tends to reside in a low-dimensional subspace. Through empirical and theoretical analysis, we demonstrate that the feature interaction module specific to recommendation models has a two-sided effect. On the one hand, the interaction restricts embedding learning when interacting with collapsed embeddings, exacerbating the collapse issue. On the other hand, feature interaction is crucial in mitigating the fitting of spurious features, thereby improving scalability. Based on this analysis, we propose a simple yet effe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24037;&#20316;&#36127;&#36733;&#21644;&#23398;&#20064;&#30340;Z-&#32034;&#24341;&#21464;&#20307;&#65292;&#36890;&#36807;&#20248;&#21270;&#23384;&#20648;&#24067;&#23616;&#21644;&#25628;&#32034;&#32467;&#26500;&#65292;&#25913;&#21892;&#20102;&#33539;&#22260;&#26597;&#35810;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#39029;&#38754;&#36339;&#36291;&#26426;&#21046;&#36827;&#19968;&#27493;&#25552;&#21319;&#26597;&#35810;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#32034;&#24341;&#22312;&#33539;&#22260;&#26597;&#35810;&#26102;&#38388;&#12289;&#28857;&#26597;&#35810;&#24615;&#33021;&#21644;&#26500;&#24314;&#26102;&#38388;&#19982;&#32034;&#24341;&#22823;&#23567;&#20043;&#38388;&#20445;&#25345;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2310.04268</link><description>&lt;p&gt;
&#22522;&#20110;&#24037;&#20316;&#36127;&#36733;&#21644;&#23398;&#20064;&#30340;Z-&#32034;&#24341;
&lt;/p&gt;
&lt;p&gt;
Workload-aware and Learned Z-Indexes. (arXiv:2310.04268v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04268
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24037;&#20316;&#36127;&#36733;&#21644;&#23398;&#20064;&#30340;Z-&#32034;&#24341;&#21464;&#20307;&#65292;&#36890;&#36807;&#20248;&#21270;&#23384;&#20648;&#24067;&#23616;&#21644;&#25628;&#32034;&#32467;&#26500;&#65292;&#25913;&#21892;&#20102;&#33539;&#22260;&#26597;&#35810;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#39029;&#38754;&#36339;&#36291;&#26426;&#21046;&#36827;&#19968;&#27493;&#25552;&#21319;&#26597;&#35810;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#32034;&#24341;&#22312;&#33539;&#22260;&#26597;&#35810;&#26102;&#38388;&#12289;&#28857;&#26597;&#35810;&#24615;&#33021;&#21644;&#26500;&#24314;&#26102;&#38388;&#19982;&#32034;&#24341;&#22823;&#23567;&#20043;&#38388;&#20445;&#25345;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24037;&#20316;&#36127;&#36733;&#21644;&#23398;&#20064;&#30340;Z-&#32034;&#24341;&#30340;&#21464;&#20307;&#65292;&#35813;&#32034;&#24341;&#21516;&#26102;&#20248;&#21270;&#23384;&#20648;&#24067;&#23616;&#21644;&#25628;&#32034;&#32467;&#26500;&#65292;&#20316;&#20026;&#35299;&#20915;&#31354;&#38388;&#32034;&#24341;&#30340;&#25361;&#25112;&#30340;&#21487;&#34892;&#35299;&#20915;&#26041;&#26696;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#21046;&#23450;&#20102;&#19968;&#20010;&#25104;&#26412;&#20989;&#25968;&#65292;&#29992;&#20110;&#34913;&#37327;Z-&#32034;&#24341;&#22312;&#25968;&#25454;&#38598;&#19978;&#30340;&#33539;&#22260;&#26597;&#35810;&#24037;&#20316;&#36127;&#36733;&#19979;&#30340;&#24615;&#33021;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#20998;&#21306;&#21644;&#25490;&#24207;&#20248;&#21270;Z-&#32034;&#24341;&#32467;&#26500;&#65292;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39029;&#38754;&#36339;&#36291;&#26426;&#21046;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#26080;&#20851;&#25968;&#25454;&#39029;&#38754;&#30340;&#35775;&#38382;&#26469;&#25913;&#21892;&#26597;&#35810;&#24615;&#33021;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#22522;&#32447;&#65292;&#25105;&#20204;&#30340;&#32034;&#24341;&#24179;&#22343;&#25913;&#21892;&#20102;40%&#30340;&#33539;&#22260;&#26597;&#35810;&#26102;&#38388;&#65292;&#21516;&#26102;&#22987;&#32456;&#34920;&#29616;&#24471;&#26356;&#22909;&#25110;&#19982;&#26368;&#20808;&#36827;&#30340;&#31354;&#38388;&#32034;&#24341;&#30456;&#24403;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32034;&#24341;&#22312;&#25552;&#20379;&#26377;&#21033;&#30340;&#26500;&#24314;&#26102;&#38388;&#21644;&#32034;&#24341;&#22823;&#23567;&#26435;&#34913;&#30340;&#21516;&#26102;&#65292;&#20445;&#25345;&#33391;&#22909;&#30340;&#28857;&#26597;&#35810;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, a learned and workload-aware variant of a Z-index, which jointly optimizes storage layout and search structures, as a viable solution for the above challenges of spatial indexing. Specifically, we first formulate a cost function to measure the performance of a Z-index on a dataset for a range-query workload. Then, we optimize the Z-index structure by minimizing the cost function through adaptive partitioning and ordering for index construction. Moreover, we design a novel page-skipping mechanism to improve its query performance by reducing access to irrelevant data pages. Our extensive experiments show that our index improves range query time by 40% on average over the baselines, while always performing better or comparably to state-of-the-art spatial indexes. Additionally, our index maintains good point query performance while providing favourable construction time and index size tradeoffs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#23545;&#35805;&#20195;&#29702;&#19982;&#25512;&#33616;&#31995;&#32479;&#32467;&#21512;&#30340;&#26032;&#33539;&#20363;CORE&#65292;&#36890;&#36807;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26368;&#23567;&#21270;&#26694;&#26550;&#65292;&#20197;&#31163;&#32447;&#35757;&#32451;&#21644;&#22312;&#32447;&#26816;&#39564;&#30340;&#24418;&#24335;&#23454;&#29616;&#20102;&#23545;&#35805;&#21644;&#25512;&#33616;&#37096;&#20998;&#30340;&#20132;&#20114;&#12290;&#26680;&#24515;&#24605;&#24819;&#26159;&#23558;&#25512;&#33616;&#31995;&#32479;&#20316;&#20026;&#31163;&#32447;&#30456;&#20851;&#24615;&#35780;&#20998;&#20272;&#35745;&#22120;&#65292;&#23558;&#23545;&#35805;&#20195;&#29702;&#20316;&#20026;&#22312;&#32447;&#30456;&#20851;&#24615;&#35780;&#20998;&#26816;&#26597;&#22120;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#19981;&#30830;&#23450;&#24615;&#26469;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#20934;&#30830;&#24615;&#21644;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.04230</link><description>&lt;p&gt;
&#23558;&#23545;&#35805;&#20195;&#29702;&#24341;&#20837;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20114;&#21160;
&lt;/p&gt;
&lt;p&gt;
Lending Interaction Wings to Recommender Systems with Conversational Agents. (arXiv:2310.04230v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#23545;&#35805;&#20195;&#29702;&#19982;&#25512;&#33616;&#31995;&#32479;&#32467;&#21512;&#30340;&#26032;&#33539;&#20363;CORE&#65292;&#36890;&#36807;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26368;&#23567;&#21270;&#26694;&#26550;&#65292;&#20197;&#31163;&#32447;&#35757;&#32451;&#21644;&#22312;&#32447;&#26816;&#39564;&#30340;&#24418;&#24335;&#23454;&#29616;&#20102;&#23545;&#35805;&#21644;&#25512;&#33616;&#37096;&#20998;&#30340;&#20132;&#20114;&#12290;&#26680;&#24515;&#24605;&#24819;&#26159;&#23558;&#25512;&#33616;&#31995;&#32479;&#20316;&#20026;&#31163;&#32447;&#30456;&#20851;&#24615;&#35780;&#20998;&#20272;&#35745;&#22120;&#65292;&#23558;&#23545;&#35805;&#20195;&#29702;&#20316;&#20026;&#22312;&#32447;&#30456;&#20851;&#24615;&#35780;&#20998;&#26816;&#26597;&#22120;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#19981;&#30830;&#23450;&#24615;&#26469;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#20934;&#30830;&#24615;&#21644;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31163;&#32447;&#21382;&#21490;&#29992;&#25143;&#34892;&#20026;&#35757;&#32451;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#23545;&#35805;&#25216;&#26415;&#36827;&#34892;&#22312;&#32447;&#26597;&#35810;&#29992;&#25143;&#20559;&#22909;&#12290;&#19982;&#20197;&#24448;&#31995;&#32479;&#22320;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#23558;&#23545;&#35805;&#21644;&#25512;&#33616;&#37096;&#20998;&#32467;&#21512;&#30340;&#23545;&#35805;&#25512;&#33616;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CORE&#65292;&#19968;&#31181;&#22522;&#20110;&#31163;&#32447;&#35757;&#32451;&#21644;&#22312;&#32447;&#26816;&#39564;&#30340;&#26032;&#33539;&#20363;&#65292;&#36890;&#36807;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26368;&#23567;&#21270;&#26694;&#26550;&#65292;&#23558;&#23545;&#35805;&#20195;&#29702;&#21644;&#25512;&#33616;&#31995;&#32479;&#36830;&#25509;&#36215;&#26469;&#12290;&#23427;&#21487;&#20197;&#20197;&#21363;&#25554;&#21363;&#29992;&#30340;&#26041;&#24335;&#20026;&#20219;&#20309;&#25512;&#33616;&#24179;&#21488;&#24102;&#26469;&#22909;&#22788;&#12290;&#22312;&#36825;&#37324;&#65292;CORE&#23558;&#25512;&#33616;&#31995;&#32479;&#35270;&#20026;&#31163;&#32447;&#30456;&#20851;&#24615;&#35780;&#20998;&#20272;&#35745;&#22120;&#65292;&#20026;&#27599;&#20010;&#39033;&#30446;&#20135;&#29983;&#19968;&#20010;&#20272;&#35745;&#30340;&#30456;&#20851;&#24615;&#35780;&#20998;&#65307;&#32780;&#23545;&#35805;&#20195;&#29702;&#34987;&#35270;&#20026;&#22312;&#32447;&#30456;&#20851;&#24615;&#35780;&#20998;&#26816;&#26597;&#22120;&#65292;&#22312;&#27599;&#20010;&#20250;&#35805;&#20013;&#26816;&#26597;&#36825;&#20123;&#20272;&#35745;&#20998;&#25968;&#12290;&#25105;&#20204;&#23558;&#19981;&#30830;&#23450;&#24615;&#23450;&#20041;&#20026;&#26410;&#32463;&#26816;&#26597;&#30340;&#30456;&#20851;&#24615;&#35780;&#20998;&#30340;&#24635;&#21644;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#23545;&#35805;&#20195;&#29702;&#36890;&#36807;&#26597;&#35810;&#23646;&#24615;&#25110;&#39033;&#30446;&#26469;&#26368;&#23567;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems trained on offline historical user behaviors are embracing conversational techniques to online query user preference. Unlike prior conversational recommendation approaches that systemically combine conversational and recommender parts through a reinforcement learning framework, we propose CORE, a new offline-training and online-checking paradigm that bridges a COnversational agent and REcommender systems via a unified uncertainty minimization framework. It can benefit any recommendation platform in a plug-and-play style. Here, CORE treats a recommender system as an offline relevance score estimator to produce an estimated relevance score for each item; while a conversational agent is regarded as an online relevance score checker to check these estimated scores in each session. We define uncertainty as the summation of unchecked relevance scores. In this regard, the conversational agent acts to minimize uncertainty via querying either attributes or items. Based on th
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20851;&#38190;&#35789;&#22686;&#24378;&#26816;&#32034;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#20351;&#29992;&#20851;&#38190;&#35789;&#26469;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#21457;&#29616;&#21644;&#31572;&#26696;&#29983;&#25104;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#24555;&#36895;&#12289;&#20302;&#25104;&#26412;&#30340;&#20449;&#24687;&#26816;&#32034;&#21644;&#35821;&#38899;&#25509;&#21475;&#38598;&#25104;&#12290;</title><link>http://arxiv.org/abs/2310.04205</link><description>&lt;p&gt;
&#20851;&#38190;&#35789;&#22686;&#24378;&#26816;&#32034;: &#38598;&#25104;&#35821;&#38899;&#25509;&#21475;&#30340;&#20449;&#24687;&#26816;&#32034;&#26032;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Keyword Augmented Retrieval: Novel framework for Information Retrieval integrated with speech interface. (arXiv:2310.04205v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04205
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20851;&#38190;&#35789;&#22686;&#24378;&#26816;&#32034;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#20351;&#29992;&#20851;&#38190;&#35789;&#26469;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#21457;&#29616;&#21644;&#31572;&#26696;&#29983;&#25104;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#24555;&#36895;&#12289;&#20302;&#25104;&#26412;&#30340;&#20449;&#24687;&#26816;&#32034;&#21644;&#35821;&#38899;&#25509;&#21475;&#38598;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20174;&#32467;&#26500;&#21270;&#21644;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#32452;&#21512;&#20013;&#24555;&#36895;&#12289;&#20302;&#25104;&#26412;&#22320;&#26816;&#32034;&#31572;&#26696;&#65292;&#32780;&#19981;&#20135;&#29983;&#24187;&#35273;&#65292;&#26159;&#38459;&#27490;&#35821;&#35328;&#27169;&#22411;&#22312;&#30693;&#35782;&#26816;&#32034;&#33258;&#21160;&#21270;&#20013;&#24212;&#29992;&#30340;&#19968;&#22823;&#38556;&#30861;&#12290;&#24403;&#24819;&#35201;&#38598;&#25104;&#35821;&#38899;&#25509;&#21475;&#26102;&#65292;&#36825;&#19968;&#38382;&#39064;&#21464;&#24471;&#26356;&#21152;&#31361;&#20986;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#21830;&#19994;&#25628;&#32034;&#21644;&#32842;&#22825;&#26426;&#22120;&#20154;&#24212;&#29992;&#26469;&#35828;&#65292;&#23436;&#20840;&#20381;&#36182;&#21830;&#19994;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;GPT 3.5&#31561;&#65289;&#21487;&#33021;&#38750;&#24120;&#26114;&#36149;&#12290;&#26412;&#25991;&#20316;&#32773;&#36890;&#36807;&#39318;&#20808;&#24320;&#21457;&#22522;&#20110;&#20851;&#38190;&#35789;&#30340;&#25628;&#32034;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#26694;&#26550;&#22686;&#24378;&#20102;&#23545;&#35201;&#25552;&#20379;&#32473;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#30340;&#21457;&#29616;&#12290;&#20851;&#38190;&#35789;&#21453;&#36807;&#26469;&#26159;&#30001;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24182;&#32531;&#23384;&#65292;&#20197;&#20415;&#19982;&#26597;&#35810;&#29983;&#25104;&#30340;&#20851;&#38190;&#35789;&#36827;&#34892;&#27604;&#36739;&#12290;&#36825;&#26174;&#33879;&#20943;&#23569;&#20102;&#22312;&#25991;&#26723;&#20013;&#26597;&#25214;&#19978;&#19979;&#25991;&#25152;&#38656;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#12290;&#19968;&#26086;&#19978;&#19979;&#25991;&#35774;&#32622;&#22909;&#20102;&#65292;&#35821;&#35328;&#27169;&#22411;&#23601;&#21487;&#20197;&#26681;&#25454;&#20026;&#38382;&#31572;&#23450;&#21046;&#30340;&#25552;&#31034;&#25552;&#20379;&#31572;&#26696;&#12290;&#36825;&#39033;&#30740;&#31350;&#24037;&#20316;&#34920;&#26126;&#65292;
&lt;/p&gt;
&lt;p&gt;
Retrieving answers in a quick and low cost manner without hallucinations from a combination of structured and unstructured data using Language models is a major hurdle which prevents employment of Language models in knowledge retrieval automation. This becomes accentuated when one wants to integrate a speech interface. Besides, for commercial search and chatbot applications, complete reliance on commercial large language models (LLMs) like GPT 3.5 etc. can be very costly. In this work, authors have addressed this problem by first developing a keyword based search framework which augments discovery of the context to be provided to the large language model. The keywords in turn are generated by LLM and cached for comparison with keywords generated by LLM against the query raised. This significantly reduces time and cost to find the context within documents. Once the context is set, LLM uses that to provide answers based on a prompt tailored for Q&amp;A. This research work demonstrates that u
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#24418;&#25688;&#35201;&#26469;&#25628;&#32034;COVID-19&#20020;&#24202;&#30740;&#31350;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#25688;&#35201;&#21644;&#22270;&#24418;&#25688;&#35201;&#34920;&#31034;&#20026;&#26412;&#20307;&#26415;&#35821;&#22270;&#24182;&#22312;&#32593;&#32476;&#20013;&#21305;&#37197;&#65292;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#23545;&#29616;&#26377;&#25991;&#29486;&#36827;&#34892;&#25628;&#32034;&#12290;</title><link>http://arxiv.org/abs/2310.04094</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#24418;&#25688;&#35201;&#25628;&#32034;COVID-19&#20020;&#24202;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Searching COVID-19 clinical research using graphical abstracts. (arXiv:2310.04094v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04094
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#24418;&#25688;&#35201;&#26469;&#25628;&#32034;COVID-19&#20020;&#24202;&#30740;&#31350;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#25688;&#35201;&#21644;&#22270;&#24418;&#25688;&#35201;&#34920;&#31034;&#20026;&#26412;&#20307;&#26415;&#35821;&#22270;&#24182;&#22312;&#32593;&#32476;&#20013;&#21305;&#37197;&#65292;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#23545;&#29616;&#26377;&#25991;&#29486;&#36827;&#34892;&#25628;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#65306;&#22270;&#24418;&#25688;&#35201;&#26159;&#23545;&#31185;&#23398;&#25991;&#31456;&#20027;&#35201;&#21457;&#29616;&#36827;&#34892;&#35270;&#35273;&#24635;&#32467;&#30340;&#27010;&#24565;&#22270;&#12290;&#34429;&#28982;&#22270;&#24418;&#25688;&#35201;&#36890;&#24120;&#29992;&#20110;&#31185;&#23398;&#20986;&#29256;&#29289;&#20013;&#39044;&#27979;&#21644;&#24635;&#32467;&#20027;&#35201;&#32467;&#26524;&#65292;&#20294;&#25105;&#20204;&#23558;&#20854;&#20316;&#20026;&#34920;&#36798;&#23545;&#29616;&#26377;&#25991;&#29486;&#36827;&#34892;&#22270;&#24418;&#25628;&#32034;&#30340;&#25163;&#27573;&#12290;&#26448;&#26009;&#21644;&#26041;&#27861;&#65306;&#25105;&#20204;&#32771;&#34385;COVID-19&#24320;&#25918;&#30740;&#31350;&#25968;&#25454;&#38598;&#65288;CORD-19&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#21253;&#21547;&#36229;&#36807;&#19968;&#30334;&#19975;&#20010;&#25688;&#35201;&#30340;&#35821;&#26009;&#24211;&#65307;&#27599;&#20010;&#25688;&#35201;&#34987;&#25551;&#36848;&#20026;&#20849;&#29616;&#26412;&#20307;&#26415;&#35821;&#22270;&#65292;&#36825;&#20123;&#26415;&#35821;&#20174;&#32479;&#19968;&#21307;&#23398;&#35821;&#35328;&#31995;&#32479;&#65288;UMLS&#65289;&#21644;&#20896;&#29366;&#30149;&#27602;&#20256;&#26579;&#30149;&#26412;&#20307;&#65288;CIDO&#65289;&#20013;&#36873;&#25321;&#12290;&#22270;&#24418;&#25688;&#35201;&#20063;&#34987;&#34920;&#31034;&#20026;&#26412;&#20307;&#26415;&#35821;&#22270;&#65292;&#21487;&#33021;&#36824;&#21253;&#25324;&#25551;&#36848;&#20854;&#30456;&#20114;&#20316;&#29992;&#30340;&#23454;&#29992;&#26415;&#35821;&#65288;&#20363;&#22914;&#65292;&#8220;&#30456;&#20851;&#8221;&#65292;&#8220;&#22686;&#21152;&#8221;&#65292;&#8220;&#24341;&#21457;&#8221;&#65289;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;&#35821;&#26009;&#24211;&#20013;&#25552;&#21450;&#30340;&#27010;&#24565;&#30340;&#20849;&#29616;&#32593;&#32476;&#65307;&#28982;&#21518;&#25105;&#20204;&#22312;&#32593;&#32476;&#19978;&#35782;&#21035;&#20986;&#22270;&#24418;&#25688;&#35201;&#30340;&#26368;&#20339;&#21305;&#37197;&#39033;&#12290;&#25105;&#20204;&#21033;&#29992;&#22270;&#24418;&#25968;&#25454;&#24211;...
&lt;/p&gt;
&lt;p&gt;
Objective. Graphical abstracts are small graphs of concepts that visually summarize the main findings of scientific articles. While graphical abstracts are customarily used in scientific publications to anticipate and summarize their main results, we propose them as a means for expressing graph searches over existing literature. Materials and methods. We consider the COVID-19 Open Research Dataset (CORD-19), a corpus of more than one million abstracts; each of them is described as a graph of co-occurring ontological terms, selected from the Unified Medical Language System (UMLS) and the Ontology of Coronavirus Infectious Disease (CIDO). Graphical abstracts are also expressed as graphs of ontological terms, possibly augmented by utility terms describing their interactions (e.g., "associated with", "increases", "induces"). We build a co-occurrence network of concepts mentioned in the corpus; we then identify the best matches of graphical abstracts on the network. We exploit graph databas
&lt;/p&gt;</description></item><item><title>AdaRec&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#39034;&#24207;&#25512;&#33616;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#36317;&#31163;&#30340;&#34920;&#31034;&#25439;&#22833;&#26469;&#25552;&#21462;&#28508;&#22312;&#20449;&#24687;&#65292;&#20197;&#36866;&#24212;&#22823;&#35268;&#27169;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#30340;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.03984</link><description>&lt;p&gt;
AdaRec&#65306;&#29992;&#20110;&#22686;&#24378;&#29992;&#25143;&#38271;&#26399;&#21442;&#19982;&#24230;&#30340;&#33258;&#36866;&#24212;&#39034;&#24207;&#25512;&#33616;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
AdaRec: Adaptive Sequential Recommendation for Reinforcing Long-term User Engagement. (arXiv:2310.03984v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03984
&lt;/p&gt;
&lt;p&gt;
AdaRec&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#39034;&#24207;&#25512;&#33616;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#36317;&#31163;&#30340;&#34920;&#31034;&#25439;&#22833;&#26469;&#25552;&#21462;&#28508;&#22312;&#20449;&#24687;&#65292;&#20197;&#36866;&#24212;&#22823;&#35268;&#27169;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39034;&#24207;&#25512;&#33616;&#20219;&#21153;&#20013;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#20851;&#27880;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#20248;&#21270;&#29992;&#25143;&#30340;&#38271;&#26399;&#21442;&#19982;&#24230;&#12290;&#22823;&#35268;&#27169;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#65288;&#22914;&#20114;&#21160;&#39057;&#29575;&#21644;&#20445;&#30041;&#20542;&#21521;&#65289;&#30340;&#19981;&#26029;&#22797;&#26434;&#21464;&#21270;&#12290;&#24403;&#23558;&#38382;&#39064;&#24314;&#27169;&#20026;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#26102;&#65292;&#25512;&#33616;&#31995;&#32479;&#30340;&#21160;&#24577;&#21644;&#22870;&#21169;&#20989;&#25968;&#20250;&#19981;&#26029;&#21463;&#21040;&#36825;&#20123;&#21464;&#21270;&#30340;&#24433;&#21709;&#12290;&#29616;&#26377;&#30340;&#25512;&#33616;&#31995;&#32479;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20250;&#21463;&#21040;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#30340;&#22256;&#25200;&#65292;&#24182;&#38590;&#20197;&#36866;&#24212;&#36825;&#31181;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#24335;&#65292;&#31216;&#20026;&#33258;&#36866;&#24212;&#39034;&#24207;&#25512;&#33616;&#65288;AdaRec&#65289;&#65292;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;AdaRec&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#34920;&#31034;&#25439;&#22833;&#65292;&#20174;&#29992;&#25143;&#30340;&#20114;&#21160;&#36712;&#36857;&#20013;&#25552;&#21462;&#28508;&#22312;&#20449;&#24687;&#12290;&#36825;&#20123;&#20449;&#24687;&#21453;&#26144;&#20102;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#19982;&#24403;&#21069;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#30340;&#21305;&#37197;&#31243;&#24230;&#65292;&#24182;&#24110;&#21161;&#31574;&#30053;&#35782;&#21035;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#32454;&#24494;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Growing attention has been paid to Reinforcement Learning (RL) algorithms when optimizing long-term user engagement in sequential recommendation tasks. One challenge in large-scale online recommendation systems is the constant and complicated changes in users' behavior patterns, such as interaction rates and retention tendencies. When formulated as a Markov Decision Process (MDP), the dynamics and reward functions of the recommendation system are continuously affected by these changes. Existing RL algorithms for recommendation systems will suffer from distribution shift and struggle to adapt in such an MDP. In this paper, we introduce a novel paradigm called Adaptive Sequential Recommendation (AdaRec) to address this issue. AdaRec proposes a new distance-based representation loss to extract latent information from users' interaction trajectories. Such information reflects how RL policy fits to current user behavior patterns, and helps the policy to identify subtle changes in the recomm
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#20869;&#23481;&#30340;&#26102;&#38388;&#24207;&#21015;&#26816;&#32034;&#31995;&#32479;&#65292;&#21487;&#20197;&#22312;&#29992;&#25143;&#19982;&#31995;&#32479;&#23454;&#26102;&#20132;&#20114;&#30340;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#22320;&#24230;&#37327;&#21644;&#35745;&#31639;&#19981;&#21516;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#65292;&#28385;&#36275;&#29992;&#25143;&#20174;&#22810;&#20010;&#39046;&#22495;&#33719;&#21462;&#26102;&#38388;&#24207;&#21015;&#20449;&#24687;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.03919</link><description>&lt;p&gt;
&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#20869;&#23481;&#30340;&#26102;&#38388;&#24207;&#21015;&#26816;&#32034;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
An Efficient Content-based Time Series Retrieval System. (arXiv:2310.03919v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03919
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#20869;&#23481;&#30340;&#26102;&#38388;&#24207;&#21015;&#26816;&#32034;&#31995;&#32479;&#65292;&#21487;&#20197;&#22312;&#29992;&#25143;&#19982;&#31995;&#32479;&#23454;&#26102;&#20132;&#20114;&#30340;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#22320;&#24230;&#37327;&#21644;&#35745;&#31639;&#19981;&#21516;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#65292;&#28385;&#36275;&#29992;&#25143;&#20174;&#22810;&#20010;&#39046;&#22495;&#33719;&#21462;&#26102;&#38388;&#24207;&#21015;&#20449;&#24687;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20869;&#23481;&#30340;&#26102;&#38388;&#24207;&#21015;&#26816;&#32034;(CTSR)&#31995;&#32479;&#26159;&#19968;&#20010;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#65292;&#29992;&#25143;&#21487;&#20197;&#19982;&#26469;&#33258;&#22810;&#20010;&#39046;&#22495;(&#22914;&#37329;&#34701;&#12289;&#21307;&#30103;&#21644;&#21046;&#36896;&#19994;)&#30340;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#20132;&#20114;&#12290;&#20363;&#22914;&#65292;&#29992;&#25143;&#24819;&#35201;&#20102;&#35299;&#26102;&#38388;&#24207;&#21015;&#30340;&#26469;&#28304;&#65292;&#21487;&#20197;&#23558;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;&#26597;&#35810;&#25552;&#20132;&#32473;CTSR&#31995;&#32479;&#65292;&#24182;&#26816;&#32034;&#19982;&#20043;&#30456;&#20851;&#30340;&#26102;&#38388;&#24207;&#21015;&#21015;&#34920;&#21450;&#30456;&#20851;&#20803;&#25968;&#25454;&#12290;&#36890;&#36807;&#20998;&#26512;&#26816;&#32034;&#21040;&#30340;&#20803;&#25968;&#25454;&#65292;&#29992;&#25143;&#21487;&#20197;&#33719;&#24471;&#26377;&#20851;&#26102;&#38388;&#24207;&#21015;&#26469;&#28304;&#30340;&#26356;&#22810;&#20449;&#24687;&#12290;&#30001;&#20110;CTSR&#31995;&#32479;&#38656;&#35201;&#22788;&#29702;&#26469;&#33258;&#19981;&#21516;&#39046;&#22495;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#22240;&#27492;&#38656;&#35201;&#19968;&#20010;&#39640;&#23481;&#37327;&#27169;&#22411;&#26469;&#26377;&#25928;&#22320;&#24230;&#37327;&#19981;&#21516;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#12290;&#27492;&#22806;&#65292;CTSR&#31995;&#32479;&#20869;&#30340;&#27169;&#22411;&#36824;&#38656;&#35201;&#20197;&#39640;&#25928;&#30340;&#26041;&#24335;&#35745;&#31639;&#30456;&#20284;&#24230;&#24471;&#20998;&#65292;&#20197;&#28385;&#36275;&#29992;&#25143;&#22312;&#23454;&#26102;&#20132;&#20114;&#20013;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#19988;&#39640;&#25928;&#30340;CTSR&#27169;&#22411;&#65292;&#20854;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26367;&#20195;&#27169;&#22411;&#65292;&#21516;&#26102;&#20173;&#28982;&#25552;&#20379;&#21512;&#29702;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Content-based Time Series Retrieval (CTSR) system is an information retrieval system for users to interact with time series emerged from multiple domains, such as finance, healthcare, and manufacturing. For example, users seeking to learn more about the source of a time series can submit the time series as a query to the CTSR system and retrieve a list of relevant time series with associated metadata. By analyzing the retrieved metadata, users can gather more information about the source of the time series. Because the CTSR system is required to work with time series data from diverse domains, it needs a high-capacity model to effectively measure the similarity between different time series. On top of that, the model within the CTSR system has to compute the similarity scores in an efficient manner as the users interact with the system in real-time. In this paper, we propose an effective and efficient CTSR model that outperforms alternative models, while still providing reasonable in
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#36890;&#36807;LiLAS&#23454;&#39564;&#23460;&#23545;&#29983;&#21629;&#31185;&#23398;&#21644;&#31038;&#20250;&#31185;&#23398;&#39046;&#22495;&#30340;&#30495;&#23454;&#23398;&#26415;&#25628;&#32034;&#31995;&#32479;&#36827;&#34892;&#29992;&#25143;&#20013;&#24515;&#35780;&#20272;&#30340;&#26041;&#27861;&#65292;&#20026;&#21442;&#19982;&#32773;&#25552;&#20379;&#20102;&#31995;&#32479;&#20869;&#23481;&#30340;&#20803;&#25968;&#25454;&#21644;&#20505;&#36873;&#21015;&#34920;&#65292;&#24182;&#20801;&#35768;&#20182;&#20204;&#36731;&#26494;&#38598;&#25104;&#33258;&#24049;&#30340;&#26041;&#27861;&#21040;&#23454;&#38469;&#31995;&#32479;&#20013;&#12290;</title><link>http://arxiv.org/abs/2310.03859</link><description>&lt;p&gt;
&#29983;&#27963;&#19982;&#31038;&#20250;&#31185;&#23398;&#25628;&#32034;&#24179;&#21488;&#30340;Living Lab&#35780;&#20272;- LiLAS&#22312;CLEF 2021&#20013;
&lt;/p&gt;
&lt;p&gt;
Living Lab Evaluation for Life and Social Sciences Search Platforms -- LiLAS at CLEF 2021. (arXiv:2310.03859v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#36890;&#36807;LiLAS&#23454;&#39564;&#23460;&#23545;&#29983;&#21629;&#31185;&#23398;&#21644;&#31038;&#20250;&#31185;&#23398;&#39046;&#22495;&#30340;&#30495;&#23454;&#23398;&#26415;&#25628;&#32034;&#31995;&#32479;&#36827;&#34892;&#29992;&#25143;&#20013;&#24515;&#35780;&#20272;&#30340;&#26041;&#27861;&#65292;&#20026;&#21442;&#19982;&#32773;&#25552;&#20379;&#20102;&#31995;&#32479;&#20869;&#23481;&#30340;&#20803;&#25968;&#25454;&#21644;&#20505;&#36873;&#21015;&#34920;&#65292;&#24182;&#20801;&#35768;&#20182;&#20204;&#36731;&#26494;&#38598;&#25104;&#33258;&#24049;&#30340;&#26041;&#27861;&#21040;&#23454;&#38469;&#31995;&#32479;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25511;&#21046;&#30340;&#31163;&#32447;&#35780;&#20272;&#27963;&#21160;&#65288;&#22914;TREC&#21644;CLEF&#65289;&#30340;&#20803;&#35780;&#20272;&#30740;&#31350;&#20013;&#65292;&#31995;&#32479;&#24615;&#33021;&#35780;&#20272;&#26041;&#38754;&#23384;&#22312;&#21019;&#26032;&#30340;&#38656;&#27714;&#65292;&#23398;&#26415;&#25628;&#32034;&#39046;&#22495;&#20063;&#19981;&#20363;&#22806;&#12290;&#36825;&#21487;&#33021;&#19982;&#23398;&#26415;&#25628;&#32034;&#20013;&#30340;&#30456;&#20851;&#24615;&#26159;&#22810;&#23618;&#27425;&#30340;&#20107;&#23454;&#26377;&#20851;&#65292;&#22240;&#27492;&#29992;&#25143;&#20013;&#24515;&#35780;&#20272;&#30340;&#26041;&#38754;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#23398;&#26415;&#25628;&#32034;&#30340;Living Labs&#65288;LiLAS&#65289;&#23454;&#39564;&#23460;&#26088;&#22312;&#36890;&#36807;&#20801;&#35768;&#21442;&#19982;&#32773;&#22312;&#29983;&#21629;&#31185;&#23398;&#21644;&#31038;&#20250;&#31185;&#23398;&#39046;&#22495;&#30340;&#20004;&#20010;&#30495;&#23454;&#23398;&#26415;&#25628;&#32034;&#31995;&#32479;&#20013;&#35780;&#20272;&#20854;&#26816;&#32034;&#26041;&#27861;&#65292;&#21152;&#24378;&#29992;&#25143;&#20013;&#24515;&#29983;&#27963;&#23454;&#39564;&#23460;&#30340;&#27010;&#24565;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20026;&#21442;&#19982;&#32773;&#25552;&#20379;&#20102;&#31995;&#32479;&#20869;&#23481;&#30340;&#20803;&#25968;&#25454;&#20197;&#21450;&#20505;&#36873;&#21015;&#34920;&#65292;&#35201;&#27714;&#23558;&#26368;&#30456;&#20851;&#30340;&#20505;&#36873;&#25490;&#22312;&#21069;&#38754;&#12290;&#21033;&#29992;STELLA&#22522;&#30784;&#35774;&#26045;&#65292;&#25105;&#20204;&#20801;&#35768;&#21442;&#19982;&#32773;&#23558;&#33258;&#24049;&#30340;&#26041;&#27861;&#36731;&#26494;&#38598;&#25104;&#21040;&#30495;&#23454;&#31995;&#32479;&#20013;&#65292;&#24182;&#25552;&#20379;&#23558;&#26041;&#26696;&#37096;&#32626;&#21040;&#22312;&#32447;&#23454;&#39564;&#31995;&#32479;&#20013;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meta-evaluation studies of system performances in controlled offline evaluation campaigns, like TREC and CLEF, show a need for innovation in evaluating IR-systems. The field of academic search is no exception to this. This might be related to the fact that relevance in academic search is multilayered and therefore the aspect of user-centric evaluation is becoming more and more important. The Living Labs for Academic Search (LiLAS) lab aims to strengthen the concept of user-centric living labs for the domain of academic search by allowing participants to evaluate their retrieval approaches in two real-world academic search systems from the life sciences and the social sciences. To this end, we provide participants with metadata on the systems' content as well as candidate lists with the task to rank the most relevant candidate to the top. Using the STELLA-infrastructure, we allow participants to easily integrate their approaches into the real-world systems and provide the possibility to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;CoHeat&#31639;&#27861;&#65292;&#19968;&#31181;&#20934;&#30830;&#30340;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#26041;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#32467;&#21512;&#21382;&#21490;&#21644;&#20851;&#32852;&#20449;&#24687;&#65292;&#24212;&#23545;&#25414;&#32465;&#20114;&#21160;&#20998;&#24067;&#30340;&#20542;&#26012;&#65292;&#24182;&#26377;&#25928;&#22320;&#23398;&#20064;&#28508;&#22312;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.03813</link><description>&lt;p&gt;
&#20934;&#30830;&#30340;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#65306;&#22522;&#20110;&#27969;&#34892;&#24230;&#30340;&#32858;&#21512;&#21644;&#35838;&#31243;&#21152;&#28909;
&lt;/p&gt;
&lt;p&gt;
Accurate Cold-start Bundle Recommendation via Popularity-based Coalescence and Curriculum Heating. (arXiv:2310.03813v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;CoHeat&#31639;&#27861;&#65292;&#19968;&#31181;&#20934;&#30830;&#30340;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#26041;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#32467;&#21512;&#21382;&#21490;&#21644;&#20851;&#32852;&#20449;&#24687;&#65292;&#24212;&#23545;&#25414;&#32465;&#20114;&#21160;&#20998;&#24067;&#30340;&#20542;&#26012;&#65292;&#24182;&#26377;&#25928;&#22320;&#23398;&#20064;&#28508;&#22312;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#20934;&#30830;&#22320;&#21521;&#29992;&#25143;&#25512;&#33616;&#20919;&#21551;&#21160;&#25414;&#32465;&#65311;&#25414;&#32465;&#25512;&#33616;&#20013;&#30340;&#20919;&#21551;&#21160;&#38382;&#39064;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#26032;&#24314;&#25414;&#32465;&#19981;&#26029;&#20986;&#29616;&#20197;&#28385;&#36275;&#21508;&#31181;&#33829;&#38144;&#30446;&#30340;&#12290;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#20043;&#21069;&#27809;&#26377;&#30740;&#31350;&#28041;&#21450;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#20919;&#21551;&#21160;&#29289;&#21697;&#25512;&#33616;&#26041;&#27861;&#36807;&#20110;&#20381;&#36182;&#21382;&#21490;&#20449;&#24687;&#65292;&#21363;&#20351;&#23545;&#20110;&#19981;&#21463;&#27426;&#36814;&#30340;&#25414;&#32465;&#20063;&#26159;&#22914;&#27492;&#65292;&#26080;&#27861;&#24212;&#23545;&#25414;&#32465;&#20114;&#21160;&#20998;&#24067;&#39640;&#24230;&#20542;&#26012;&#30340;&#20027;&#35201;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CoHeat&#65288;&#22522;&#20110;&#27969;&#34892;&#24230;&#30340;&#32858;&#21512;&#21644;&#35838;&#31243;&#21152;&#28909;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#20934;&#30830;&#30340;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#26041;&#27861;&#12290;CoHeat&#36890;&#36807;&#32467;&#21512;&#21382;&#21490;&#20449;&#24687;&#21644;&#20851;&#32852;&#20449;&#24687;&#26469;&#20272;&#35745;&#29992;&#25143;&#19982;&#25414;&#32465;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#24212;&#23545;&#25414;&#32465;&#20114;&#21160;&#20998;&#24067;&#30340;&#39640;&#24230;&#20542;&#26012;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;CoHeat&#36824;&#36890;&#36807;&#21033;&#29992;&#35838;&#31243;&#23398;&#20064;&#21644;&#32858;&#21512;&#29305;&#24449;&#23398;&#20064;&#25928;&#26524;&#22320;&#23398;&#20064;&#28508;&#22312;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
How can we accurately recommend cold-start bundles to users? The cold-start problem in bundle recommendation is critical in practical scenarios since new bundles are continuously created for various marketing purposes. Despite its importance, no previous studies have addressed cold-start bundle recommendation. Moreover, existing methods for cold-start item recommendation overly rely on historical information, even for unpopular bundles, failing to tackle the primary challenge of the highly skewed distribution of bundle interactions. In this work, we propose CoHeat (Popularity-based Coalescence and Curriculum Heating), an accurate approach for the cold-start bundle recommendation. CoHeat tackles the highly skewed distribution of bundle interactions by incorporating both historical and affiliation information based on the bundle's popularity when estimating the user-bundle relationship. Furthermore, CoHeat effectively learns latent representations by exploiting curriculum learning and co
&lt;/p&gt;</description></item><item><title>LBD&#26159;&#22312;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#25366;&#25496;&#20013;&#36890;&#36807;&#33258;&#21160;&#21457;&#29616;&#21307;&#23398;&#26415;&#35821;&#20043;&#38388;&#30340;&#26032;&#20851;&#32852;&#26469;&#32553;&#30701;&#21457;&#29616;&#28508;&#22312;&#20851;&#32852;&#30340;&#26102;&#38388;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.03766</link><description>&lt;p&gt;
&#22522;&#20110;&#25991;&#29486;&#30340;&#21457;&#29616;&#65288;LBD&#65289;&#65306;&#22312;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#25366;&#25496;&#20013;&#23454;&#29616;&#20551;&#35774;&#29983;&#25104;&#21644;&#30693;&#35782;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Literature Based Discovery (LBD): Towards Hypothesis Generation and Knowledge Discovery in Biomedical Text Mining. (arXiv:2310.03766v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03766
&lt;/p&gt;
&lt;p&gt;
LBD&#26159;&#22312;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#25366;&#25496;&#20013;&#36890;&#36807;&#33258;&#21160;&#21457;&#29616;&#21307;&#23398;&#26415;&#35821;&#20043;&#38388;&#30340;&#26032;&#20851;&#32852;&#26469;&#32553;&#30701;&#21457;&#29616;&#28508;&#22312;&#20851;&#32852;&#30340;&#26102;&#38388;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#20197;&#31185;&#23398;&#20986;&#29256;&#29289;&#30340;&#24418;&#24335;&#20197;&#24778;&#20154;&#30340;&#36895;&#24230;&#22686;&#38271;&#12290;&#25991;&#26412;&#25366;&#25496;&#24037;&#20855;&#21644;&#26041;&#27861;&#20195;&#34920;&#20102;&#20174;&#36825;&#20123;&#21322;&#32467;&#26500;&#21270;&#21644;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#20013;&#25552;&#21462;&#38544;&#34255;&#27169;&#24335;&#21644;&#36235;&#21183;&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#12290;&#22312;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#25366;&#25496;&#20013;&#65292;&#22522;&#20110;&#25991;&#29486;&#30340;&#21457;&#29616;&#65288;LBD&#65289;&#26159;&#33258;&#21160;&#21457;&#29616;&#19981;&#21516;&#25991;&#29486;&#38598;&#20013;&#25552;&#21040;&#30340;&#21307;&#23398;&#26415;&#35821;&#20043;&#38388;&#30340;&#26032;&#20851;&#32852;&#30340;&#36807;&#31243;&#12290;LBD&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#25104;&#21151;&#32553;&#30701;&#22312;&#22823;&#37327;&#31185;&#23398;&#25991;&#29486;&#20013;&#38544;&#34255;&#30340;&#28508;&#22312;&#20851;&#32852;&#30340;&#21457;&#29616;&#26102;&#38388;&#12290;&#35813;&#36807;&#31243;&#20391;&#37325;&#20110;&#20026;&#30142;&#30149;&#25110;&#30151;&#29366;&#31561;&#21307;&#23398;&#26415;&#35821;&#21019;&#24314;&#27010;&#24565;&#26723;&#26696;&#65292;&#24182;&#26681;&#25454;&#20849;&#20139;&#26723;&#26696;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#23558;&#20854;&#19982;&#33647;&#29289;&#21644;&#27835;&#30103;&#32852;&#31995;&#36215;&#26469;&#12290;&#36825;&#31181;&#30693;&#35782;&#21457;&#29616;&#26041;&#27861;&#22312;1989&#24180;&#24341;&#20837;&#21518;&#20173;&#28982;&#26159;&#25991;&#26412;&#25366;&#25496;&#30340;&#26680;&#24515;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Biomedical knowledge is growing in an astounding pace with a majority of this knowledge is represented as scientific publications. Text mining tools and methods represents automatic approaches for extracting hidden patterns and trends from this semi structured and unstructured data. In Biomedical Text mining, Literature Based Discovery (LBD) is the process of automatically discovering novel associations between medical terms otherwise mentioned in disjoint literature sets. LBD approaches proven to be successfully reducing the discovery time of potential associations that are hidden in the vast amount of scientific literature. The process focuses on creating concept profiles for medical terms such as a disease or symptom and connecting it with a drug and treatment based on the statistical significance of the shared profiles. This knowledge discovery approach introduced in 1989 still remains as a core task in text mining. Currently the ABC principle based two approaches namely open disco
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FASER&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20013;&#38388;&#34920;&#31034;&#36827;&#34892;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#25628;&#32034;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36328;&#26550;&#26500;&#22320;&#35782;&#21035;&#20989;&#25968;&#65292;&#24182;&#26126;&#30830;&#32534;&#30721;&#20989;&#25968;&#30340;&#35821;&#20041;&#65292;&#20197;&#25903;&#25345;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2310.03605</link><description>&lt;p&gt;
FASER: &#36890;&#36807;&#20013;&#38388;&#34920;&#31034;&#36827;&#34892;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
FASER: Binary Code Similarity Search through the use of Intermediate Representations. (arXiv:2310.03605v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FASER&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20013;&#38388;&#34920;&#31034;&#36827;&#34892;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#25628;&#32034;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36328;&#26550;&#26500;&#22320;&#35782;&#21035;&#20989;&#25968;&#65292;&#24182;&#26126;&#30830;&#32534;&#30721;&#20989;&#25968;&#30340;&#35821;&#20041;&#65292;&#20197;&#25903;&#25345;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#35782;&#21035;&#36328;&#26550;&#26500;&#36719;&#20214;&#20013;&#24863;&#20852;&#36259;&#30340;&#20989;&#25968;&#23545;&#20110;&#20998;&#26512;&#24694;&#24847;&#36719;&#20214;&#12289;&#20445;&#25252;&#36719;&#20214;&#20379;&#24212;&#38142;&#25110;&#36827;&#34892;&#28431;&#27934;&#30740;&#31350;&#37117;&#26159;&#26377;&#29992;&#30340;&#12290;&#36328;&#26550;&#26500;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#25628;&#32034;&#24050;&#22312;&#35768;&#22810;&#30740;&#31350;&#20013;&#25506;&#32034;&#65292;&#24182;&#20351;&#29992;&#20102;&#21508;&#31181;&#19981;&#21516;&#30340;&#25968;&#25454;&#26469;&#28304;&#26469;&#23454;&#29616;&#20854;&#30446;&#26631;&#12290;&#36890;&#24120;&#20351;&#29992;&#30340;&#25968;&#25454;&#26469;&#28304;&#21253;&#25324;&#20174;&#20108;&#36827;&#21046;&#25991;&#20214;&#20013;&#25552;&#21462;&#30340;&#24120;&#35265;&#32467;&#26500;&#65292;&#22914;&#20989;&#25968;&#25511;&#21046;&#27969;&#22270;&#25110;&#20108;&#36827;&#21046;&#32423;&#35843;&#29992;&#22270;&#65292;&#21453;&#27719;&#32534;&#36807;&#31243;&#30340;&#36755;&#20986;&#25110;&#21160;&#24577;&#20998;&#26512;&#26041;&#27861;&#30340;&#36755;&#20986;&#12290;&#20854;&#20013;&#19968;&#31181;&#21463;&#21040;&#36739;&#23569;&#20851;&#27880;&#30340;&#25968;&#25454;&#26469;&#28304;&#26159;&#20108;&#36827;&#21046;&#20013;&#38388;&#34920;&#31034;&#12290;&#20108;&#36827;&#21046;&#20013;&#38388;&#34920;&#31034;&#20855;&#26377;&#20004;&#20010;&#26377;&#36259;&#30340;&#23646;&#24615;&#65306;&#23427;&#20204;&#30340;&#36328;&#26550;&#26500;&#24615;&#36136;&#20197;&#21450;&#26126;&#30830;&#32534;&#30721;&#20989;&#25968;&#30340;&#35821;&#20041;&#20197;&#25903;&#25345;&#19979;&#28216;&#20351;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FASER&#30340;&#20989;&#25968;&#23383;&#31526;&#20018;&#32534;&#30721;&#34920;&#31034;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#38271;&#25991;&#26723;&#36716;&#25442;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Being able to identify functions of interest in cross-architecture software is useful whether you are analysing for malware, securing the software supply chain or conducting vulnerability research. Cross-Architecture Binary Code Similarity Search has been explored in numerous studies and has used a wide range of different data sources to achieve its goals. The data sources typically used draw on common structures derived from binaries such as function control flow graphs or binary level call graphs, the output of the disassembly process or the outputs of a dynamic analysis approach. One data source which has received less attention is binary intermediate representations. Binary Intermediate representations possess two interesting properties: they are cross architecture by their very nature and encode the semantics of a function explicitly to support downstream usage. Within this paper we propose Function as a String Encoded Representation (FASER) which combines long document transforme
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#32676;&#20307;&#29992;&#25143;&#25512;&#33616;&#21830;&#21697;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#27169;&#22411;&#30456;&#27604;&#29616;&#26377;&#27169;&#22411;&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.09447</link><description>&lt;p&gt;
&#20026;&#32676;&#20307;&#29992;&#25143;&#25512;&#33616;&#21830;&#21697;&#30340;&#28145;&#24230;&#31070;&#32463;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Aggregation for Recommending Items to Group of Users. (arXiv:2307.09447v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09447
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#32676;&#20307;&#29992;&#25143;&#25512;&#33616;&#21830;&#21697;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#27169;&#22411;&#30456;&#27604;&#29616;&#26377;&#27169;&#22411;&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#31038;&#20250;&#33457;&#36153;&#20102;&#22823;&#37327;&#26102;&#38388;&#22312;&#25968;&#23383;&#20132;&#20114;&#19978;&#65292;&#25105;&#20204;&#30340;&#26085;&#24120;&#34892;&#20026;&#24456;&#22810;&#37117;&#36890;&#36807;&#25968;&#23383;&#25163;&#27573;&#23436;&#25104;&#12290;&#36825;&#23548;&#33268;&#20102;&#35768;&#22810;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#30340;&#20986;&#29616;&#65292;&#24110;&#21161;&#25105;&#20204;&#22312;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#36827;&#34892;&#36741;&#21161;&#12290;&#23545;&#20110;&#25968;&#23383;&#31038;&#20250;&#26469;&#35828;&#65292;&#19968;&#20010;&#20851;&#38190;&#30340;&#24037;&#20855;&#26159;&#25512;&#33616;&#31995;&#32479;&#65292;&#23427;&#26159;&#26234;&#33021;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#23398;&#20064;&#25105;&#20204;&#30340;&#36807;&#21435;&#34892;&#20026;&#65292;&#25552;&#20986;&#19982;&#25105;&#20204;&#20852;&#36259;&#30456;&#31526;&#30340;&#26032;&#34892;&#20026;&#24314;&#35758;&#12290;&#20854;&#20013;&#19968;&#20123;&#31995;&#32479;&#19987;&#38376;&#20174;&#29992;&#25143;&#32676;&#20307;&#30340;&#34892;&#20026;&#20013;&#23398;&#20064;&#65292;&#21521;&#24076;&#26395;&#20849;&#21516;&#23436;&#25104;&#26576;&#20010;&#20219;&#21153;&#30340;&#20010;&#20307;&#32676;&#20307;&#25552;&#20986;&#24314;&#35758;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;&#30340;&#29616;&#29366;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#20351;&#29992;&#26032;&#20852;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#27169;&#22411;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20351;&#29992;&#22235;&#20010;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#26368;&#26032;&#27169;&#22411;&#30456;&#27604;&#65292;&#37319;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#21487;&#20197;&#21462;&#24471;&#25913;&#36827;&#12290;&#35813;&#27169;&#22411;&#21450;&#25152;&#26377;&#23454;&#39564;&#30340;&#28304;&#20195;&#30721;&#37117;&#21487;&#20379;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern society devotes a significant amount of time to digital interaction. Many of our daily actions are carried out through digital means. This has led to the emergence of numerous Artificial Intelligence tools that assist us in various aspects of our lives. One key tool for the digital society is Recommender Systems, intelligent systems that learn from our past actions to propose new ones that align with our interests. Some of these systems have specialized in learning from the behavior of user groups to make recommendations to a group of individuals who want to perform a joint task. In this article, we analyze the current state of Group Recommender Systems and propose two new models that use emerging Deep Learning architectures. Experimental results demonstrate the improvement achieved by employing the proposed models compared to the state-of-the-art models using four different datasets. The source code of the models, as well as that of all the experiments conducted, is available i
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#39064;&#30340;&#35299;&#37322;&#24615;&#26032;&#38395;&#25512;&#33616;&#27169;&#22411;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#30456;&#20851;&#25991;&#31456;&#24182;&#35299;&#37322;&#20026;&#20160;&#20040;&#25512;&#33616;&#36825;&#20123;&#25991;&#31456;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#35299;&#37322;&#30340;&#21487;&#35299;&#37322;&#24615;&#24230;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.07506</link><description>&lt;p&gt;
&#22522;&#20110;&#20027;&#39064;&#30340;&#26032;&#38395;&#25512;&#33616;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Topic-Centric Explanations for News Recommendation. (arXiv:2306.07506v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07506
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#39064;&#30340;&#35299;&#37322;&#24615;&#26032;&#38395;&#25512;&#33616;&#27169;&#22411;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#30456;&#20851;&#25991;&#31456;&#24182;&#35299;&#37322;&#20026;&#20160;&#20040;&#25512;&#33616;&#36825;&#20123;&#25991;&#31456;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#35299;&#37322;&#30340;&#21487;&#35299;&#37322;&#24615;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22312;&#32447;&#26032;&#38395;&#32593;&#31449;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#26681;&#25454;&#20182;&#20204;&#30340;&#20852;&#36259;&#25214;&#21040;&#30456;&#20851;&#25991;&#31456;&#12290;&#28982;&#32780;&#65292;&#25512;&#33616;&#32570;&#20047;&#35299;&#37322;&#20250;&#23548;&#33268;&#29992;&#25143;&#30340;&#19981;&#20449;&#20219;&#21644;&#25512;&#33616;&#30340;&#32570;&#20047;&#25509;&#21463;&#24230;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#30340;&#26032;&#38395;&#27169;&#22411;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20110;&#20027;&#39064;&#30340;&#35299;&#37322;&#24615;&#25512;&#33616;&#26041;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#30456;&#20851;&#25991;&#31456;&#24182;&#35299;&#37322;&#20026;&#20160;&#20040;&#25512;&#33616;&#36825;&#20123;&#25991;&#31456;&#65292;&#21033;&#29992;&#30456;&#20851;&#20027;&#39064;&#30340;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#32467;&#21512;&#20102;&#20004;&#31181;&#29992;&#20110;&#35780;&#20272;&#20027;&#39064;&#36136;&#37327;&#30340;&#19968;&#33268;&#24615;&#24230;&#37327;&#65292;&#25552;&#20379;&#20102;&#36825;&#20123;&#35299;&#37322;&#30340;&#21487;&#35299;&#37322;&#24615;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#22312;MIND&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#21487;&#35299;&#37322;&#24615;NRS&#20248;&#20110;&#20854;&#20182;&#20960;&#20010;&#22522;&#32447;&#31995;&#32479;&#65292;&#21516;&#26102;&#36824;&#33021;&#22815;&#20135;&#29983;&#21487;&#35299;&#37322;&#30340;&#20027;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
News recommender systems (NRS) have been widely applied for online news websites to help users find relevant articles based on their interests. Recent methods have demonstrated considerable success in terms of recommendation performance. However, the lack of explanation for these recommendations can lead to mistrust among users and lack of acceptance of recommendations. To address this issue, we propose a new explainable news model to construct a topic-aware explainable recommendation approach that can both accurately identify relevant articles and explain why they have been recommended, using information from associated topics. Additionally, our model incorporates two coherence metrics applied to assess topic quality, providing measure of the interpretability of these explanations. The results of our experiments on the MIND dataset indicate that the proposed explainable NRS outperforms several other baseline systems, while it is also capable of producing interpretable topics compared 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35774;&#35745;&#24182;&#37096;&#32626;&#20102;&#19968;&#20010;&#24179;&#21488;&#65292;&#29992;&#20110;&#25910;&#38598;&#22797;&#26434;&#20132;&#20114;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#20197;&#35299;&#20915;&#24403;&#21069;&#20132;&#20114;&#31995;&#32479;&#26080;&#27861;&#29702;&#35299;&#19968;&#27425;&#24615;&#25552;&#20986;&#30340;&#22797;&#26434;&#20449;&#24687;&#26816;&#32034;&#35831;&#27714;&#30340;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#21457;&#29616;&#24403;&#21069;&#30340;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#20379;&#20934;&#30830;&#30340;&#20107;&#23454;&#30693;&#35782;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.00584</link><description>&lt;p&gt;
&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#20132;&#20114;&#21151;&#33021;&#65306;&#20851;&#20110;&#25903;&#25345;&#24102;&#26377;&#38544;&#21547;&#32422;&#26463;&#30340;&#22797;&#26434;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#30340;&#20808;&#39537;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Making Large Language Models Interactive: A Pioneer Study on Supporting Complex Information-Seeking Tasks with Implicit Constraints. (arXiv:2205.00584v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.00584
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35774;&#35745;&#24182;&#37096;&#32626;&#20102;&#19968;&#20010;&#24179;&#21488;&#65292;&#29992;&#20110;&#25910;&#38598;&#22797;&#26434;&#20132;&#20114;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#20197;&#35299;&#20915;&#24403;&#21069;&#20132;&#20114;&#31995;&#32479;&#26080;&#27861;&#29702;&#35299;&#19968;&#27425;&#24615;&#25552;&#20986;&#30340;&#22797;&#26434;&#20449;&#24687;&#26816;&#32034;&#35831;&#27714;&#30340;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#21457;&#29616;&#24403;&#21069;&#30340;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#20379;&#20934;&#30830;&#30340;&#20107;&#23454;&#30693;&#35782;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#20855;&#26377;&#33258;&#28982;&#35821;&#35328;&#25509;&#21475;&#30340;&#20132;&#20114;&#31995;&#32479;&#32570;&#20047;&#29702;&#35299;&#21516;&#26102;&#34920;&#36798;&#22810;&#20010;&#38544;&#21547;&#32422;&#26463;&#30340;&#22797;&#26434;&#20449;&#24687;&#26816;&#32034;&#35831;&#27714;&#30340;&#33021;&#21147;&#65292;&#24182;&#19988;&#27809;&#26377;&#20851;&#20110;&#29992;&#25143;&#20559;&#22909;&#30340;&#20808;&#21069;&#20449;&#24687;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29992;&#25143;&#35831;&#27714;&#21487;&#20197;&#19968;&#27425;&#24615;&#20197;&#22797;&#26434;&#21644;&#38271;&#30340;&#26597;&#35810;&#24418;&#24335;&#25552;&#20986;&#65292;&#19982;&#23545;&#35805;&#21644;&#25506;&#32034;&#24335;&#25628;&#32034;&#27169;&#22411;&#19981;&#21516;&#65292;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#23558;&#30701;&#34920;&#36798;&#25110;&#26597;&#35810;&#36880;&#27493;&#21576;&#29616;&#32473;&#31995;&#32479;&#12290;&#25105;&#20204;&#35774;&#35745;&#24182;&#37096;&#32626;&#20102;&#19968;&#20010;&#24179;&#21488;&#26469;&#25910;&#38598;&#36825;&#31181;&#22797;&#26434;&#20132;&#20114;&#31995;&#32479;&#30340;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#23613;&#31649;&#24403;&#21069;&#30340;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#22312;&#25552;&#20379;&#20934;&#30830;&#30340;&#20107;&#23454;&#30693;&#35782;&#26041;&#38754;&#23384;&#22312;&#24187;&#35273;&#12290;&#25152;&#26377;&#35821;&#35328;&#27169;&#22411;&#22823;&#22810;&#26159;&#22312;
&lt;/p&gt;
&lt;p&gt;
Current interactive systems with natural language interfaces lack the ability to understand a complex information-seeking request which expresses several implicit constraints at once, and there is no prior information about user preferences e.g.,"find hiking trails around San Francisco which are accessible with toddlers and have beautiful scenery in summer", where output is a list of possible suggestions for users to start their exploration. In such scenarios, user requests can be issued in one shot in the form of a complex and long query, unlike conversational and exploratory search models, where require short utterances or queries are often presented to the system step by step. We have designed and deployed a platform to collect the data from approaching such complex interactive systems. Moreover, despite with the current advancement of generative language models these models suffer from hallucination in providing accurate factual knowledge. All language models are mostly trained in 
&lt;/p&gt;</description></item></channel></rss>