<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36890;&#36807;&#31070;&#32463;&#25490;&#24207;&#26041;&#27861;&#65292;&#20934;&#30830;&#36873;&#25321;&#21644;&#20248;&#20808;&#25490;&#24207;&#25935;&#24863;&#33647;&#29289;&#26469;&#36827;&#34892;&#20010;&#24615;&#21270;&#25239;&#30284;&#27835;&#30103;&#12290;</title><link>http://arxiv.org/abs/2306.17771</link><description>&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#25490;&#24207;&#23454;&#29616;&#31934;&#30830;&#30340;&#25239;&#30284;&#33647;&#29289;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Precision Anti-Cancer Drug Selection via Neural Ranking. (arXiv:2306.17771v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17771
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#25490;&#24207;&#26041;&#27861;&#65292;&#20934;&#30830;&#36873;&#25321;&#21644;&#20248;&#20808;&#25490;&#24207;&#25935;&#24863;&#33647;&#29289;&#26469;&#36827;&#34892;&#20010;&#24615;&#21270;&#25239;&#30284;&#27835;&#30103;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#30284;&#30151;&#27835;&#30103;&#38656;&#35201;&#23545;&#33647;&#29289;&#19982;&#30284;&#32454;&#32990;&#31995;&#22312;&#19981;&#21516;&#30340;&#36951;&#20256;&#21644;&#20998;&#23376;&#29615;&#22659;&#20013;&#30340;&#22797;&#26434;&#30456;&#20114;&#20316;&#29992;&#26377;&#28145;&#20837;&#30340;&#29702;&#35299;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#39640;&#36890;&#37327;&#31579;&#36873;&#24050;&#34987;&#29992;&#26469;&#29983;&#25104;&#22823;&#35268;&#27169;&#30340;&#33647;&#29289;&#21453;&#24212;&#25968;&#25454;&#65292;&#20419;&#36827;&#25968;&#25454;&#39537;&#21160;&#30340;&#35745;&#31639;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#23436;&#20840;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#25429;&#25417;&#21040;&#19981;&#21516;&#29615;&#22659;&#19979;&#22797;&#26434;&#30340;&#33647;&#29289;-&#32454;&#32990;&#31995;&#30456;&#20114;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#20934;&#30830;&#22320;&#20026;&#27599;&#20010;&#32454;&#32990;&#31995;&#20248;&#20808;&#36873;&#25321;&#26368;&#25935;&#24863;&#30340;&#33647;&#29289;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#31070;&#32463;&#25490;&#24207;&#26041;&#27861;&#65292;&#21033;&#29992;&#26469;&#33258;&#19981;&#21516;&#30284;&#30151;&#31867;&#22411;&#30340;&#22810;&#20010;&#32454;&#32990;&#31995;&#30340;&#22823;&#35268;&#27169;&#33647;&#29289;&#21453;&#24212;&#25968;&#25454;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#20351;&#29992;&#22238;&#24402;&#21644;&#20998;&#31867;&#25216;&#26415;&#36827;&#34892;&#33647;&#29289;&#21453;&#24212;&#39044;&#27979;&#19981;&#21516;&#65292;&#25105;&#20204;&#23558;&#33647;&#29289;&#36873;&#25321;&#21644;&#20248;&#20808;&#32423;&#30830;&#23450;&#30340;&#30446;&#26631;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#33647;&#29289;&#25490;&#24207;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31070;&#32463;&#25490;&#24207;&#26041;&#27861;&#65292;&#21487;&#20197;&#23398;&#20064;&#28508;&#22312;&#30340;&#34920;&#31034;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized cancer treatment requires a thorough understanding of complex interactions between drugs and cancer cell lines in varying genetic and molecular contexts. To address this, high-throughput screening has been used to generate large-scale drug response data, facilitating data-driven computational models. Such models can capture complex drug-cell line interactions across various contexts in a fully data-driven manner. However, accurately prioritizing the most sensitive drugs for each cell line still remains a significant challenge. To address this, we developed neural ranking approaches that leverage large-scale drug response data across multiple cell lines from diverse cancer types. Unlike existing approaches that primarily utilize regression and classification techniques for drug response prediction, we formulated the objective of drug selection and prioritization as a drug ranking problem. In this work, we proposed two neural listwise ranking methods that learn latent repres
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#23558;&#32771;&#34385;&#37325;&#26032;&#35780;&#20272;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.17614</link><description>&lt;p&gt;
&#25353;&#32467;&#26524;&#35780;&#20272;&#31995;&#32479;&#21270;&#32508;&#36848;&#33258;&#21160;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Outcome-based Evaluation of Systematic Review Automation. (arXiv:2306.17614v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17614
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#23558;&#32771;&#34385;&#37325;&#26032;&#35780;&#20272;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#35780;&#20272;&#31995;&#32479;&#21270;&#25991;&#29486;&#32508;&#36848;&#30340;&#25628;&#32034;&#31574;&#30053;&#21644;&#33258;&#21160;&#21270;&#24341;&#25991;&#31579;&#36873;&#30340;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#35745;&#31639;&#30456;&#20851;&#21644;&#19981;&#30456;&#20851;&#20986;&#29256;&#29289;&#30340;&#25968;&#37327;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20570;&#27861;&#24182;&#26410;&#20934;&#30830;&#21453;&#26144;&#36827;&#34892;&#31995;&#32479;&#21270;&#32508;&#36848;&#30340;&#29616;&#23454;&#24773;&#20917;&#65292;&#22240;&#20026;&#24182;&#38750;&#25152;&#26377;&#21253;&#21547;&#30340;&#20986;&#29256;&#29289;&#23545;&#26368;&#32456;&#30340;&#32508;&#36848;&#32467;&#26524;&#30340;&#24433;&#21709;&#30456;&#21516;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22914;&#26524;&#37325;&#35201;&#30340;&#20986;&#29256;&#29289;&#34987;&#25490;&#38500;&#25110;&#21253;&#21547;&#65292;&#36825;&#21487;&#33021;&#20250;&#26174;&#33879;&#25913;&#21464;&#25972;&#20010;&#32508;&#36848;&#32467;&#26524;&#65292;&#32780;&#19981;&#21253;&#21547;&#25110;&#25490;&#38500;&#19981;&#22826;&#37325;&#35201;&#30340;&#30740;&#31350;&#21487;&#33021;&#21482;&#20250;&#26377;&#26377;&#38480;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22312;&#35780;&#20272;&#25351;&#26631;&#26041;&#38754;&#65292;&#25152;&#26377;&#30340;&#21253;&#21547;&#21644;&#25490;&#38500;&#20915;&#31574;&#34987;&#24179;&#31561;&#23545;&#24453;&#65292;&#22240;&#27492;&#26410;&#33021;&#26816;&#32034;&#20986;&#23545;&#32508;&#36848;&#32467;&#26524;&#20960;&#20046;&#26080;&#24433;&#21709;&#30340;&#20986;&#29256;&#29289;&#19982;&#26410;&#33021;&#26816;&#32034;&#21040;&#20851;&#38190;&#20986;&#29256;&#29289;&#23548;&#33268;&#30340;&#21484;&#22238;&#29575;&#38477;&#20302;&#26159;&#19968;&#26679;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#32771;&#34385;&#21040;&#20102;&#37325;&#26032;&#35780;&#20272;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current methods of evaluating search strategies and automated citation screening for systematic literature reviews typically rely on counting the number of relevant and not relevant publications. This established practice, however, does not accurately reflect the reality of conducting a systematic review, because not all included publications have the same influence on the final outcome of the systematic review. More specifically, if an important publication gets excluded or included, this might significantly change the overall review outcome, while not including or excluding less influential studies may only have a limited impact. However, in terms of evaluation measures, all inclusion and exclusion decisions are treated equally and, therefore, failing to retrieve publications with little to no impact on the review outcome leads to the same decrease in recall as failing to retrieve crucial publications. We propose a new evaluation framework that takes into account the impact of the re
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PRP&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#20351;&#29992;&#20004;&#20004;&#25490;&#21517;&#25552;&#31034;&#26469;&#26174;&#33879;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36127;&#25285;&#65292;&#24182;&#39318;&#27425;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.17563</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#26377;&#25928;&#30340;&#25991;&#26412;&#25490;&#24207;&#22120;&#65292;&#20855;&#26377;&#20004;&#20004;&#25490;&#21517;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting. (arXiv:2306.17563v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PRP&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#20351;&#29992;&#20004;&#20004;&#25490;&#21517;&#25552;&#31034;&#26469;&#26174;&#33879;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36127;&#25285;&#65292;&#24182;&#39318;&#27425;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36890;&#36807;&#30452;&#25509;&#23558;&#26597;&#35810;&#21644;&#20505;&#36873;&#25991;&#26723;&#36755;&#20837;&#25552;&#31034;&#36827;&#34892;&#25991;&#26723;&#25490;&#24207;&#26159;&#19968;&#20010;&#26377;&#36259;&#19988;&#23454;&#29992;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#21462;&#24471;&#20102;&#26377;&#38480;&#30340;&#25104;&#21151;&#65292;&#30740;&#31350;&#20154;&#21592;&#21457;&#29616;&#24456;&#38590;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36229;&#36234;&#31934;&#35843;&#22522;&#20934;&#25490;&#24207;&#22120;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#29616;&#26377;&#26041;&#27861;&#20351;&#29992;&#30340;&#28857;&#23545;&#28857;&#21644;&#21015;&#34920;&#25490;&#24207;&#25552;&#31034;&#65292;&#24182;&#35748;&#20026;&#29616;&#25104;&#30340;LLM&#27809;&#26377;&#23436;&#20840;&#29702;&#35299;&#36825;&#20123;&#25490;&#24207;&#20844;&#24335;&#65292;&#21487;&#33021;&#26159;&#30001;&#20110;LLM&#30340;&#35757;&#32451;&#26041;&#24335;&#30340;&#29305;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20004;&#20004;&#25490;&#21517;&#25552;&#31034;&#65288;PRP&#65289;&#30340;&#26032;&#25216;&#26415;&#65292;&#22823;&#22823;&#20943;&#36731;&#20102;LLM&#30340;&#36127;&#25285;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#25991;&#29486;&#20013;&#39318;&#27425;&#20351;&#29992;&#20013;&#31561;&#35268;&#27169;&#30340;&#24320;&#28304;LLM&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;&#22312;TREC-DL2020&#19978;&#65292;&#22522;&#20110;20B&#21442;&#25968;&#30340;Flan-UL2&#27169;&#22411;&#30340;PRP&#36229;&#36807;&#20102;&#25991;&#29486;&#20013;&#22522;&#20110;&#21830;&#19994;&#40657;&#30418;GPT-4&#30340;&#26368;&#20339;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ranking documents using Large Language Models (LLMs) by directly feeding the query and candidate documents into the prompt is an interesting and practical problem. However, there has been limited success so far, as researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets. We analyze pointwise and listwise ranking prompts used by existing methods and argue that off-the-shelf LLMs do not fully understand these ranking formulations, possibly due to the nature of how LLMs are trained. In this paper, we propose to significantly reduce the burden on LLMs by using a new technique called Pairwise Ranking Prompting (PRP). Our results are the first in the literature to achieve state-of-the-art ranking performance on standard benchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on the Flan-UL2 model with 20B parameters outperforms the previous best approach in the literature, which is based on the blackbox commercial GPT-4 that ha
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#26631;&#35760;&#26694;&#26550;&#65292;&#21033;&#29992;&#35266;&#30475;&#26102;&#38388;&#21453;&#39304;&#36827;&#34892;&#30701;&#35270;&#39057;&#25512;&#33616;&#12290;&#36890;&#36807;&#26500;&#24314;&#22810;&#20010;&#35821;&#20041;&#30340;&#26631;&#31614;&#65292;&#24182;&#20351;&#29992;&#20998;&#20301;&#25968;&#26469;&#25552;&#21462;&#35266;&#30475;&#26102;&#38388;&#30340;&#20449;&#24687;&#65292;&#20351;&#27169;&#22411;&#23398;&#20064;&#26356;&#21152;&#23481;&#26131;&#65292;&#21516;&#26102;&#20943;&#23569;&#20559;&#35265;&#23545;&#25512;&#33616;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.17426</link><description>&lt;p&gt;
&#21033;&#29992;&#35266;&#30475;&#26102;&#38388;&#21453;&#39304;&#36827;&#34892;&#30701;&#35270;&#39057;&#25512;&#33616;&#65306;&#19968;&#31181;&#22240;&#26524;&#26631;&#35760;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal Labeling Framework. (arXiv:2306.17426v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17426
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#26631;&#35760;&#26694;&#26550;&#65292;&#21033;&#29992;&#35266;&#30475;&#26102;&#38388;&#21453;&#39304;&#36827;&#34892;&#30701;&#35270;&#39057;&#25512;&#33616;&#12290;&#36890;&#36807;&#26500;&#24314;&#22810;&#20010;&#35821;&#20041;&#30340;&#26631;&#31614;&#65292;&#24182;&#20351;&#29992;&#20998;&#20301;&#25968;&#26469;&#25552;&#21462;&#35266;&#30475;&#26102;&#38388;&#30340;&#20449;&#24687;&#65292;&#20351;&#27169;&#22411;&#23398;&#20064;&#26356;&#21152;&#23481;&#26131;&#65292;&#21516;&#26102;&#20943;&#23569;&#20559;&#35265;&#23545;&#25512;&#33616;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#30701;&#35270;&#39057;&#24212;&#29992;&#30340;&#26222;&#21450;&#65292;&#30701;&#35270;&#39057;&#25512;&#33616;&#30340;&#37325;&#35201;&#24615;&#22823;&#22823;&#22686;&#21152;&#12290;&#19982;&#20854;&#20182;&#25512;&#33616;&#22330;&#26223;&#19981;&#21516;&#65292;&#30701;&#35270;&#39057;&#25512;&#33616;&#31995;&#32479;&#22823;&#37327;&#20381;&#36182;&#20110;&#35266;&#30475;&#26102;&#38388;&#30340;&#21453;&#39304;&#12290;&#29616;&#26377;&#26041;&#27861;&#31616;&#21333;&#22320;&#23558;&#35266;&#30475;&#26102;&#38388;&#35270;&#20026;&#30452;&#25509;&#26631;&#31614;&#65292;&#26410;&#33021;&#20805;&#20998;&#21033;&#29992;&#20854;&#24191;&#27867;&#30340;&#35821;&#20041;&#24182;&#24341;&#20837;&#20559;&#35265;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#22522;&#20110;&#35266;&#30475;&#26102;&#38388;&#24314;&#27169;&#29992;&#25143;&#20852;&#36259;&#30340;&#28508;&#21147;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#21435;&#20559;&#22810;&#35821;&#20041;&#25552;&#21462;&#26631;&#35760;&#65288;DML&#65289;&#30340;&#26694;&#26550;&#12290;DML&#21033;&#29992;&#35266;&#30475;&#26102;&#38388;&#20998;&#24067;&#24471;&#20986;&#30340;&#20998;&#20301;&#25968;&#26500;&#24314;&#21253;&#21547;&#21508;&#31181;&#35821;&#20041;&#30340;&#26631;&#31614;&#65292;&#20248;&#20808;&#32771;&#34385;&#30456;&#23545;&#39034;&#24207;&#32780;&#19981;&#26159;&#32477;&#23545;&#26631;&#31614;&#20540;&#12290;&#36825;&#31181;&#26041;&#27861;&#20415;&#20110;&#27169;&#22411;&#23398;&#20064;&#65292;&#21516;&#26102;&#31526;&#21512;&#25512;&#33616;&#30340;&#25490;&#24207;&#30446;&#26631;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21463;&#22240;&#26524;&#35843;&#25972;&#21551;&#21457;&#30340;&#26041;&#27861;&#26469;&#20248;&#21270;&#26631;&#31614;&#23450;&#20041;&#65292;&#20174;&#32780;&#20943;&#23569;&#20559;&#35265;&#23545;&#25512;&#33616;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the proliferation of short video applications, the significance of short video recommendations has vastly increased. Unlike other recommendation scenarios, short video recommendation systems heavily rely on feedback from watch time. Existing approaches simply treat watch time as a direct label, failing to effectively harness its extensive semantics and introduce bias, thereby limiting the potential for modeling user interests based on watch time. To overcome this challenge, we propose a framework named Debiasied Multiple-semantics-extracting Labeling (DML). DML constructs labels that encompass various semantics by utilizing quantiles derived from the distribution of watch time, prioritizing relative order rather than absolute label values. This approach facilitates easier model learning while aligning with the ranking objective of recommendations. Furthermore, we introduce a method inspired by causal adjustment to refine label definitions, thereby reducing the impact of bias on th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#38899;&#39057;&#23884;&#20837;&#20316;&#20026;&#25945;&#24072;&#26469;&#24341;&#23548;&#20302;&#22797;&#26434;&#24230;&#23398;&#29983;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#38899;&#20048;&#20048;&#22120;&#20998;&#31867;&#21644;&#38899;&#20048;&#33258;&#21160;&#26631;&#35760;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;.</title><link>http://arxiv.org/abs/2306.17424</link><description>&lt;p&gt;
&#38899;&#39057;&#23884;&#20837;&#20316;&#20026;&#38899;&#20048;&#20998;&#31867;&#30340;&#25945;&#24072;
&lt;/p&gt;
&lt;p&gt;
Audio Embeddings as Teachers for Music Classification. (arXiv:2306.17424v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#38899;&#39057;&#23884;&#20837;&#20316;&#20026;&#25945;&#24072;&#26469;&#24341;&#23548;&#20302;&#22797;&#26434;&#24230;&#23398;&#29983;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#38899;&#20048;&#20048;&#22120;&#20998;&#31867;&#21644;&#38899;&#20048;&#33258;&#21160;&#26631;&#35760;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#20048;&#20998;&#31867;&#19968;&#30452;&#26159;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#20013;&#26368;&#21463;&#27426;&#36814;&#30340;&#20219;&#21153;&#20043;&#19968;&#12290;&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21457;&#23637;&#65292;&#36807;&#21435;&#21313;&#24180;&#22312;&#21508;&#31181;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#19981;&#26029;&#22686;&#21152;&#30340;&#27169;&#22411;&#22797;&#26434;&#24615;&#20351;&#24471;&#35757;&#32451;&#21644;&#25512;&#26029;&#30340;&#35745;&#31639;&#25104;&#26412;&#21464;&#24471;&#26114;&#36149;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36801;&#31227;&#23398;&#20064;&#21644;&#22522;&#20110;&#29305;&#24449;&#30340;&#30693;&#35782;&#33976;&#39311;&#30340;&#24605;&#24819;&#30456;&#32467;&#21512;&#65292;&#24182;&#31995;&#32479;&#22320;&#30740;&#31350;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#38899;&#39057;&#23884;&#20837;&#20316;&#20026;&#25945;&#24072;&#26469;&#25351;&#23548;&#20302;&#22797;&#26434;&#24230;&#30340;&#23398;&#29983;&#32593;&#32476;&#30340;&#35757;&#32451;&#12290;&#36890;&#36807;&#29992;&#39044;&#35757;&#32451;&#30340;&#23884;&#20837;&#26041;&#24335;&#35268;&#33539;&#21270;&#23398;&#29983;&#32593;&#32476;&#30340;&#29305;&#24449;&#31354;&#38388;&#65292;&#25945;&#24072;&#23884;&#20837;&#20013;&#30340;&#30693;&#35782;&#21487;&#20197;&#20256;&#36882;&#32473;&#23398;&#29983;&#12290;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#39044;&#35757;&#32451;&#30340;&#38899;&#39057;&#23884;&#20837;&#65292;&#24182;&#22312;&#38899;&#20048;&#20048;&#22120;&#20998;&#31867;&#21644;&#38899;&#20048;&#33258;&#21160;&#26631;&#35760;&#20219;&#21153;&#19978;&#27979;&#35797;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#21516;&#19968;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#32467;&#26524;.
&lt;/p&gt;
&lt;p&gt;
Music classification has been one of the most popular tasks in the field of music information retrieval. With the development of deep learning models, the last decade has seen impressive improvements in a wide range of classification tasks. However, the increasing model complexity makes both training and inference computationally expensive. In this paper, we integrate the ideas of transfer learning and feature-based knowledge distillation and systematically investigate using pre-trained audio embeddings as teachers to guide the training of low-complexity student networks. By regularizing the feature space of the student networks with the pre-trained embeddings, the knowledge in the teacher embeddings can be transferred to the students. We use various pre-trained audio embeddings and test the effectiveness of the method on the tasks of musical instrument classification and music auto-tagging. Results show that our method significantly improves the results in comparison to the identical 
&lt;/p&gt;</description></item><item><title>DeepTagger&#26159;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22686;&#24378;&#30340;&#32593;&#32476;&#24191;&#21578;&#26597;&#35810;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#27169;&#22411;&#26080;&#20851;&#21644;&#27169;&#22411;&#22522;&#20110;&#26041;&#27861;&#65292;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#32593;&#32476;&#26597;&#35810;&#21644;&#32593;&#32476;&#25628;&#32034;&#32467;&#26524;&#26469;&#22686;&#21152;&#39046;&#22495;&#30693;&#35782;&#65292;&#37319;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#29983;&#25104;&#26631;&#31614;&#65292;&#24182;&#24212;&#29992;&#23545;&#25239;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2306.17413</link><description>&lt;p&gt;
DeepTagger: &#22522;&#20110;&#30693;&#35782;&#22686;&#24378;&#30340;&#32593;&#32476;&#24191;&#21578;&#26597;&#35810;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
DeepTagger: Knowledge Enhanced Named Entity Recognition for Web-Based Ads Queries. (arXiv:2306.17413v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17413
&lt;/p&gt;
&lt;p&gt;
DeepTagger&#26159;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22686;&#24378;&#30340;&#32593;&#32476;&#24191;&#21578;&#26597;&#35810;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#27169;&#22411;&#26080;&#20851;&#21644;&#27169;&#22411;&#22522;&#20110;&#26041;&#27861;&#65292;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#32593;&#32476;&#26597;&#35810;&#21644;&#32593;&#32476;&#25628;&#32034;&#32467;&#26524;&#26469;&#22686;&#21152;&#39046;&#22495;&#30693;&#35782;&#65292;&#37319;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#29983;&#25104;&#26631;&#31614;&#65292;&#24182;&#24212;&#29992;&#23545;&#25239;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#26159;&#22312;&#32447;&#24191;&#21578;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#26368;&#20808;&#36827;&#30340;&#35299;&#20915;&#26041;&#26696;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#23436;&#25104;&#36825;&#39033;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#20173;&#23384;&#22312;&#19977;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;&#32593;&#32476;&#26597;&#35810;&#19982;&#39044;&#35757;&#32451;&#27169;&#22411;&#35757;&#32451;&#30340;&#33258;&#28982;&#35821;&#35328;&#19981;&#21516;&#65307;&#32593;&#32476;&#26597;&#35810;&#30701;&#23567;&#65292;&#32570;&#20047;&#19978;&#19979;&#25991;&#20449;&#24687;&#65307;NER&#30340;&#26631;&#35760;&#25968;&#25454;&#31232;&#32570;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;DeepTagger&#65292;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22686;&#24378;&#30340;&#32593;&#32476;&#24191;&#21578;&#26597;&#35810;&#30340;NER&#27169;&#22411;&#12290;&#25152;&#25552;&#20986;&#30340;&#30693;&#35782;&#22686;&#24378;&#26694;&#26550;&#21033;&#29992;&#27169;&#22411;&#26080;&#20851;&#21644;&#27169;&#22411;&#22522;&#20110;&#26041;&#27861;&#12290;&#23545;&#20110;&#27169;&#22411;&#26080;&#20851;&#30340;&#22686;&#24378;&#65292;&#25105;&#20204;&#25910;&#38598;&#26410;&#26631;&#35760;&#30340;&#32593;&#32476;&#26597;&#35810;&#26469;&#22686;&#21152;&#39046;&#22495;&#30693;&#35782;&#65307;&#36824;&#25910;&#38598;&#32593;&#32476;&#25628;&#32034;&#32467;&#26524;&#26469;&#20016;&#23500;&#24191;&#21578;&#26597;&#35810;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21033;&#29992;ChatGPT&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#37319;&#29992;&#26377;&#25928;&#30340;&#25552;&#31034;&#26041;&#27861;&#33258;&#21160;&#29983;&#25104;&#26631;&#31614;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#23545;&#25239;&#25968;&#25454;&#22686;&#24378;&#30340;&#27169;&#22411;&#22522;&#20110;&#30693;&#35782;&#22686;&#24378;&#26041;&#27861;&#12290;&#25105;&#20204;&#37319;&#29992;&#19977;&#38454;&#27573;&#30340;&#35757;&#32451;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Named entity recognition (NER) is a crucial task for online advertisement. State-of-the-art solutions leverage pre-trained language models for this task. However, three major challenges remain unresolved: web queries differ from natural language, on which pre-trained models are trained; web queries are short and lack contextual information; and labeled data for NER is scarce. We propose DeepTagger, a knowledge-enhanced NER model for web-based ads queries. The proposed knowledge enhancement framework leverages both model-free and model-based approaches. For model-free enhancement, we collect unlabeled web queries to augment domain knowledge; and we collect web search results to enrich the information of ads queries. We further leverage effective prompting methods to automatically generate labels using large language models such as ChatGPT. Additionally, we adopt a model-based knowledge enhancement method based on adversarial data augmentation. We employ a three-stage training framework 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#20010;&#24615;&#21270;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#23558;&#25512;&#33616;&#36807;&#31243;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#65292;&#25552;&#20379;&#36866;&#29992;&#20110;&#21019;&#19994;&#20225;&#19994;&#21644;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#19981;&#36275;&#30340;&#24179;&#21488;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2306.17256</link><description>&lt;p&gt;
&#20197;&#25552;&#31034;&#20026;&#22522;&#30784;&#30340;&#20010;&#24615;&#21270;&#20919;&#21551;&#21160;&#25512;&#33616;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#20010;&#24615;&#21270;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#23558;&#25512;&#33616;&#36807;&#31243;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#65292;&#25552;&#20379;&#36866;&#29992;&#20110;&#21019;&#19994;&#20225;&#19994;&#21644;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#19981;&#36275;&#30340;&#24179;&#21488;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#26681;&#25454;&#29992;&#25143;&#36807;&#21435;&#30340;&#34892;&#20026;&#24110;&#21161;&#29992;&#25143;&#21457;&#29616;&#19982;&#20854;&#20852;&#36259;&#30456;&#31526;&#30340;&#20449;&#24687;&#26041;&#38754;&#21457;&#25381;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#24403;&#29992;&#25143;&#21644;&#29289;&#21697;&#20043;&#38388;&#30340;&#21382;&#21490;&#20132;&#20114;&#35760;&#24405;&#19981;&#21487;&#29992;&#26102;&#65292;&#24320;&#21457;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#36825;&#23601;&#26159;&#25152;&#35859;&#30340;&#31995;&#32479;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#12290;&#27492;&#38382;&#39064;&#22312;&#21019;&#19994;&#20225;&#19994;&#25110;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#19981;&#36275;&#30340;&#24179;&#21488;&#20013;&#23588;&#20026;&#31361;&#20986;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#29992;&#25143;&#25110;&#29289;&#21697;&#30340;&#20919;&#21551;&#21160;&#22330;&#26223;&#65292;&#20854;&#20013;&#31995;&#32479;&#20173;&#28982;&#36890;&#36807;&#22312;&#21516;&#19968;&#39046;&#22495;&#20013;&#30340;&#21382;&#21490;&#29992;&#25143;&#21644;&#29289;&#21697;&#20132;&#20114;&#36827;&#34892;&#35757;&#32451;&#26469;&#20026;&#26032;&#29992;&#25143;&#25110;&#29289;&#21697;&#25552;&#20379;&#25512;&#33616;&#65292;&#32780;&#26080;&#27861;&#35299;&#20915;&#25105;&#20204;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#40511;&#27807;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#19988;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#23558;&#25512;&#33616;&#36807;&#31243;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#65292;&#20854;&#20013;&#21253;&#21547;&#29992;&#25143;&#36164;&#26009;&#21644;&#29289;&#21697;&#23646;&#24615;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems play a crucial role in helping users discover information that aligns with their interests based on their past behaviors. However, developing personalized recommendation systems becomes challenging when historical records of user-item interactions are unavailable, leading to what is known as the system cold-start recommendation problem. This issue is particularly prominent in start-up businesses or platforms with insufficient user engagement history. Previous studies focus on user or item cold-start scenarios, where systems could make recommendations for new users or items but are still trained with historical user-item interactions in the same domain, which cannot solve our problem. To bridge the gap, our research introduces an innovative and effective approach, capitalizing on the capabilities of pre-trained language models. We transform the recommendation process into sentiment analysis of natural languages containing information of user profiles and item attribu
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21487;&#20449;&#35745;&#31639;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#38480;&#21046;&#20844;&#20849;&#20113;&#20013;&#25968;&#25454;&#30340;&#22320;&#29702;&#20301;&#32622;&#12290;&#29992;&#25143;&#23558;&#19978;&#20256;&#25968;&#25454;&#65292;&#24182;&#21482;&#19982;&#31532;&#19977;&#26041;&#39564;&#35777;&#26381;&#21153;&#22120;&#20849;&#20139;&#35299;&#23494;&#23494;&#38053;&#12290;</title><link>http://arxiv.org/abs/2306.17171</link><description>&lt;p&gt;
&#22312;&#20844;&#20849;&#20113;&#20013;&#20351;&#29992;&#21487;&#20449;&#35745;&#31639;&#24378;&#21046;&#25191;&#34892;&#25968;&#25454;&#22320;&#29702;&#20301;&#32622;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Enforcing Data Geolocation Policies in Public Clouds using Trusted Computing. (arXiv:2306.17171v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21487;&#20449;&#35745;&#31639;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#38480;&#21046;&#20844;&#20849;&#20113;&#20013;&#25968;&#25454;&#30340;&#22320;&#29702;&#20301;&#32622;&#12290;&#29992;&#25143;&#23558;&#19978;&#20256;&#25968;&#25454;&#65292;&#24182;&#21482;&#19982;&#31532;&#19977;&#26041;&#39564;&#35777;&#26381;&#21153;&#22120;&#20849;&#20139;&#35299;&#23494;&#23494;&#38053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25216;&#26415;&#30340;&#36827;&#27493;&#65292;&#20113;&#35745;&#31639;&#36890;&#36807;&#38761;&#21629;&#24615;&#30340;&#35299;&#20915;&#26041;&#26696;&#33258;&#21160;&#21270;&#21644;&#31616;&#21270;&#22797;&#26434;&#30340;&#35745;&#31639;&#20219;&#21153;&#65292;&#19981;&#26029;&#32473;&#19990;&#30028;&#24102;&#26469;&#24778;&#21916;&#12290;&#20813;&#32500;&#25252;&#25104;&#26412;&#12289;&#21487;&#35775;&#38382;&#24615;&#12289;&#25968;&#25454;&#22791;&#20221;&#12289;&#25353;&#20351;&#29992;&#20184;&#36153;&#27169;&#24335;&#12289;&#26080;&#38480;&#23384;&#20648;&#21644;&#22788;&#29702;&#33021;&#21147;&#31561;&#20248;&#21183;&#65292;&#40723;&#21169;&#20010;&#20154;&#21644;&#20225;&#19994;&#23558;&#24037;&#20316;&#36127;&#36733;&#36801;&#31227;&#21040;&#20113;&#31471;&#12290;&#23613;&#31649;&#20113;&#35745;&#31639;&#26377;&#35768;&#22810;&#20248;&#28857;&#65292;&#20294;&#25968;&#25454;&#22312;&#20113;&#29615;&#22659;&#20013;&#30340;&#22320;&#29702;&#20301;&#32622;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#38382;&#39064;&#65292;&#23427;&#19982;&#25968;&#25454;&#25152;&#21463;&#21040;&#30340;&#24615;&#33021;&#21644;&#25919;&#24220;&#27861;&#35268;&#26377;&#20851;&#12290;&#25968;&#25454;&#22320;&#29702;&#20301;&#32622;&#30340;&#19981;&#28165;&#26224;&#21487;&#33021;&#24341;&#21457;&#21512;&#35268;&#24615;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25216;&#26415;&#65292;&#20801;&#35768;&#29992;&#25143;&#38480;&#21046;&#20854;&#25968;&#25454;&#22312;&#20113;&#29615;&#22659;&#20013;&#30340;&#22320;&#29702;&#20301;&#32622;&#12290;&#25105;&#20204;&#20351;&#29992;&#21487;&#20449;&#35745;&#31639;&#26426;&#21046;&#36828;&#31243;&#39564;&#35777;&#20027;&#26426;&#21450;&#20854;&#22320;&#29702;&#20301;&#32622;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#29992;&#25143;&#23558;&#19978;&#20256;&#20854;&#25968;&#25454;&#65292;&#24182;&#23558;&#35299;&#23494;&#23494;&#38053;&#20165;&#19982;&#31532;&#19977;&#26041;&#39564;&#35777;&#26381;&#21153;&#22120;&#20849;&#20139;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the advancement in technology, Cloud computing always amazes the world with revolutionizing solutions that automate and simplify complex computational tasks. The advantages like no maintenance cost, accessibility, data backup, pay-per-use models, unlimited storage, and processing power encourage individuals and businesses to migrate their workload to the cloud. Despite the numerous advantages of cloud computing, the geolocation of data in the cloud environment is a massive concern, which relates to the performance and government legislation that will be applied to data. The unclarity of data geolocation can cause compliance concerns. In this work, we have presented a technique that will allow users to restrict the geolocation of their data in the cloud environment. We have used trusted computing mechanisms to attest the host and its geolocation remotely. With this model, the user will upload the data whose decryption key will be shared with a third-party attestation server only. T
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#31038;&#20132;&#23186;&#20307;&#21644;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#25506;&#32034;&#20102;&#20351;&#29992;&#29992;&#25143;&#29983;&#25104;&#30340;&#25968;&#25454;&#39044;&#27979;&#31934;&#31070;&#38556;&#30861;&#30151;&#29366;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#26032;&#27169;&#22411;&#30340;&#20934;&#30830;&#24230;&#39640;&#36798;97%&#12290;&#36825;&#34920;&#26126;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#26159;&#36827;&#34892;&#31934;&#31070;&#20581;&#24247;&#31579;&#26597;&#30340;&#19968;&#20010;&#37325;&#35201;&#36164;&#28304;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#22320;&#33258;&#21160;&#21270;&#36825;&#19968;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2306.16891</link><description>&lt;p&gt;
&#21033;&#29992;Hugging Face Transformers&#39044;&#27979;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#31934;&#31070;&#20581;&#24247;&#38556;&#30861;&#30340;&#21147;&#37327;
&lt;/p&gt;
&lt;p&gt;
Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks. (arXiv:2306.16891v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16891
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#31038;&#20132;&#23186;&#20307;&#21644;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#25506;&#32034;&#20102;&#20351;&#29992;&#29992;&#25143;&#29983;&#25104;&#30340;&#25968;&#25454;&#39044;&#27979;&#31934;&#31070;&#38556;&#30861;&#30151;&#29366;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#26032;&#27169;&#22411;&#30340;&#20934;&#30830;&#24230;&#39640;&#36798;97%&#12290;&#36825;&#34920;&#26126;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#26159;&#36827;&#34892;&#31934;&#31070;&#20581;&#24247;&#31579;&#26597;&#30340;&#19968;&#20010;&#37325;&#35201;&#36164;&#28304;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#22320;&#33258;&#21160;&#21270;&#36825;&#19968;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26089;&#26399;&#35786;&#26029;&#31934;&#31070;&#38556;&#30861;&#24182;&#36827;&#34892;&#24178;&#39044;&#21487;&#20197;&#20419;&#36827;&#39044;&#38450;&#20005;&#37325;&#20260;&#23475;&#21644;&#25913;&#21892;&#27835;&#30103;&#25928;&#26524;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#31038;&#20132;&#23186;&#20307;&#21644;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#25506;&#35752;&#29992;&#25143;&#29983;&#25104;&#30340;&#25968;&#25454;&#22914;&#20309;&#29992;&#20110;&#39044;&#27979;&#31934;&#31070;&#38556;&#30861;&#30151;&#29366;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#27604;&#36739;&#20102;Hugging Face&#30340;&#22235;&#31181;&#19981;&#21516;BERT&#27169;&#22411;&#21644;&#36817;&#26399;&#25991;&#29486;&#20013;&#29992;&#20110;&#33258;&#21160;&#25233;&#37057;&#30151;&#35786;&#26029;&#30340;&#26631;&#20934;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#26032;&#27169;&#22411;&#30340;&#20934;&#30830;&#29575;&#39640;&#36798;97%&#65292;&#36229;&#36807;&#20102;&#20197;&#21069;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#34917;&#20805;&#20808;&#21069;&#30340;&#21457;&#29616;&#65292;&#23545;&#32467;&#26524;&#36827;&#34892;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#21363;&#20351;&#26159;&#24494;&#23567;&#30340;&#25968;&#25454;&#37327;&#65288;&#22914;&#29992;&#25143;&#30340;&#20010;&#20154;&#31616;&#20171;&#25551;&#36848;&#65289;&#20063;&#26377;&#39044;&#27979;&#31934;&#31070;&#38556;&#30861;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#26159;&#36827;&#34892;&#31934;&#31070;&#20581;&#24247;&#31579;&#26597;&#30340;&#19968;&#20010;&#26497;&#22909;&#30340;&#26469;&#28304;&#65292;&#24182;&#19988;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#33258;&#21160;&#21270;&#36825;&#19968;&#20851;&#38190;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Early diagnosis of mental disorders and intervention can facilitate the prevention of severe injuries and the improvement of treatment results. Using social media and pre-trained language models, this study explores how user-generated data can be used to predict mental disorder symptoms. Our study compares four different BERT models of Hugging Face with standard machine learning techniques used in automatic depression diagnosis in recent literature. The results show that new models outperform the previous approach with an accuracy rate of up to 97%. Analyzing the results while complementing past findings, we find that even tiny amounts of data (like users' bio descriptions) have the potential to predict mental disorders. We conclude that social media data is an excellent source of mental health screening, and pre-trained models can effectively automate this critical task.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#20002;&#22833;&#32422;&#26463;&#30340;&#22823;&#35268;&#27169;&#20844;&#20849;&#23433;&#20840;&#26102;&#31354;&#25968;&#25454;&#39640;&#25928;&#21010;&#20998;&#26041;&#27861;(IFL-LSTP)&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#25968;&#25454;&#35268;&#27169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#30830;&#20445;&#20998;&#24067;&#24335;&#23384;&#20648;&#30340;&#36127;&#36733;&#24179;&#34913;&#65292;&#21516;&#26102;&#20445;&#25345;&#25968;&#25454;&#21010;&#20998;&#30340;&#26102;&#31354;&#25509;&#36817;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.12857</link><description>&lt;p&gt;
&#22522;&#20110;&#20449;&#24687;&#20002;&#22833;&#32422;&#26463;&#30340;&#22823;&#35268;&#27169;&#20844;&#20849;&#23433;&#20840;&#26102;&#31354;&#25968;&#25454;&#39640;&#25928;&#21010;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Partitioning Method of Large-Scale Public Safety Spatio-Temporal Data based on Information Loss Constraints. (arXiv:2306.12857v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#20002;&#22833;&#32422;&#26463;&#30340;&#22823;&#35268;&#27169;&#20844;&#20849;&#23433;&#20840;&#26102;&#31354;&#25968;&#25454;&#39640;&#25928;&#21010;&#20998;&#26041;&#27861;(IFL-LSTP)&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#25968;&#25454;&#35268;&#27169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#30830;&#20445;&#20998;&#24067;&#24335;&#23384;&#20648;&#30340;&#36127;&#36733;&#24179;&#34913;&#65292;&#21516;&#26102;&#20445;&#25345;&#25968;&#25454;&#21010;&#20998;&#30340;&#26102;&#31354;&#25509;&#36817;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#26102;&#31354;&#25968;&#25454;&#30340;&#23384;&#20648;&#12289;&#31649;&#29702;&#21644;&#24212;&#29992;&#22312;&#21508;&#31181;&#23454;&#38469;&#22330;&#26223;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#21253;&#25324;&#20844;&#20849;&#23433;&#20840;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#29420;&#29305;&#26102;&#31354;&#20998;&#24067;&#29305;&#24449;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#22312;&#25968;&#25454;&#26102;&#31354;&#25509;&#36817;&#24230;&#21644;&#20998;&#24067;&#24335;&#23384;&#20648;&#36127;&#36733;&#24179;&#34913;&#26041;&#38754;&#23384;&#22312;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#20002;&#22833;&#32422;&#26463;&#30340;&#22823;&#35268;&#27169;&#20844;&#20849;&#23433;&#20840;&#26102;&#31354;&#25968;&#25454;&#39640;&#25928;&#21010;&#20998;&#26041;&#27861;(IFL-LSTP)&#12290;&#35813;IFL-LSTP&#27169;&#22411;&#38024;&#23545;&#22823;&#35268;&#27169;&#26102;&#31354;&#28857;&#25968;&#25454;&#65292;&#23558;&#26102;&#31354;&#21010;&#20998;&#27169;&#22359;(STPM)&#21644;&#22270;&#21010;&#20998;&#27169;&#22359;(GPM)&#30456;&#32467;&#21512;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#25968;&#25454;&#35268;&#27169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#20197;&#25552;&#39640;&#21010;&#20998;&#25928;&#29575;&#12290;&#23427;&#36824;&#21487;&#20197;&#30830;&#20445;&#20998;&#24067;&#24335;&#23384;&#20648;&#30340;&#36127;&#36733;&#24179;&#34913;&#65292;&#21516;&#26102;&#20445;&#25345;&#25968;&#25454;&#21010;&#20998;&#30340;&#26102;&#31354;&#25509;&#36817;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The storage, management, and application of massive spatio-temporal data are widely applied in various practical scenarios, including public safety. However, due to the unique spatio-temporal distribution characteristics of re-al-world data, most existing methods have limitations in terms of the spatio-temporal proximity of data and load balancing in distributed storage. There-fore, this paper proposes an efficient partitioning method of large-scale public safety spatio-temporal data based on information loss constraints (IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporal point da-ta by combining the spatio-temporal partitioning module (STPM) with the graph partitioning module (GPM). This approach can significantly reduce the scale of data while maintaining the model's accuracy, in order to improve the partitioning efficiency. It can also ensure the load balancing of distributed storage while maintaining spatio-temporal proximity of the data partitioning res
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21512;&#25104;&#25511;&#21046;&#29702;&#35770;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#26377;&#30028;&#36951;&#25022;&#30340;&#25512;&#33616;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#32447;&#24615;&#27169;&#22411;&#30340;&#31934;&#30830;&#30693;&#35782;&#12289;&#28508;&#22312;&#21327;&#21464;&#37327;&#30340;&#23384;&#22312;&#12289;&#19981;&#22343;&#21248;&#30340;&#29992;&#25143;&#21040;&#36798;&#36895;&#29575;&#21644;&#29992;&#25143;&#36873;&#25321;&#36864;&#20986;&#31169;&#20154;&#25968;&#25454;&#36319;&#36394;&#31561;&#23454;&#36341;&#20013;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.12571</link><description>&lt;p&gt;
&#36890;&#36807;&#21512;&#25104;&#25511;&#21046;&#29702;&#35770;&#23454;&#29616;&#26377;&#30028;&#65288;O(1)&#65289;&#36951;&#25022;&#30340;&#25512;&#33616;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bounded (O(1)) Regret Recommendation Learning via Synthetic Controls Oracle. (arXiv:2301.12571v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12571
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21512;&#25104;&#25511;&#21046;&#29702;&#35770;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#26377;&#30028;&#36951;&#25022;&#30340;&#25512;&#33616;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#32447;&#24615;&#27169;&#22411;&#30340;&#31934;&#30830;&#30693;&#35782;&#12289;&#28508;&#22312;&#21327;&#21464;&#37327;&#30340;&#23384;&#22312;&#12289;&#19981;&#22343;&#21248;&#30340;&#29992;&#25143;&#21040;&#36798;&#36895;&#29575;&#21644;&#29992;&#25143;&#36873;&#25321;&#36864;&#20986;&#31169;&#20154;&#25968;&#25454;&#36319;&#36394;&#31561;&#23454;&#36341;&#20013;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#25506;&#32034;&#31995;&#32479;&#20013;&#65292;&#24403;&#20855;&#26377;&#22266;&#23450;&#20559;&#22909;&#30340;&#29992;&#25143;&#37325;&#22797;&#21040;&#36798;&#26102;&#65292;&#26368;&#36817;&#24050;&#32463;&#35777;&#26126;&#21487;&#20197;&#23558;&#31995;&#32479;&#24314;&#27169;&#20026;&#32447;&#24615;&#24773;&#22659;&#24191;&#21578;&#24102;&#26469;O(1)&#30340;&#26377;&#30028;&#36951;&#25022;&#12290;&#36825;&#20010;&#32467;&#26524;&#21487;&#33021;&#23545;&#25512;&#33616;&#31995;&#32479;&#20855;&#26377;&#20852;&#36259;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#29289;&#21697;&#30340;&#27969;&#34892;&#24230;&#36890;&#24120;&#26159;&#30701;&#26242;&#30340;&#65292;&#21363;&#25506;&#32034;&#26412;&#36523;&#21487;&#33021;&#22312;&#28508;&#22312;&#30340;&#38271;&#26399;&#38750;&#31283;&#24577;&#24320;&#22987;&#20043;&#21069;&#24456;&#24555;&#23436;&#25104;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#32447;&#24615;&#27169;&#22411;&#30340;&#31934;&#30830;&#30693;&#35782;&#24448;&#24448;&#38590;&#20197;&#35777;&#26126;&#12290;&#27492;&#22806;&#65292;&#28508;&#22312;&#21327;&#21464;&#37327;&#30340;&#23384;&#22312;&#65292;&#19981;&#22343;&#21248;&#30340;&#29992;&#25143;&#21040;&#36798;&#36895;&#29575;&#65292;&#23545;&#24517;&#35201;&#31561;&#32423;&#26465;&#20214;&#30340;&#35299;&#37322;&#20197;&#21450;&#29992;&#25143;&#36873;&#25321;&#36864;&#20986;&#31169;&#20154;&#25968;&#25454;&#36319;&#36394;&#31561;&#37117;&#38656;&#35201;&#22312;&#23454;&#38469;&#30340;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#20013;&#35299;&#20915;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#20197;&#35299;&#20915;&#25152;&#26377;&#36825;&#20123;&#38382;&#39064;&#65292;&#21516;&#26102;&#20173;&#28982;&#23454;&#29616;&#20102;&#26377;&#30028;&#36951;&#25022;&#12290;&#38500;&#20102;&#35777;&#26126;&#25216;&#26415;&#65292;&#25105;&#20204;&#22312;&#36825;&#37324;&#25152;&#20570;&#30340;&#20851;&#38190;&#21306;&#21035;&#24615;&#20551;&#35774;&#26159;&#26377;&#25928;&#21512;&#25104;&#25511;&#21046;&#29702;&#35770;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
In online exploration systems where users with fixed preferences repeatedly arrive, it has recently been shown that O(1), i.e., bounded regret, can be achieved when the system is modeled as a linear contextual bandit. This result may be of interest for recommender systems, where the popularity of their items is often short-lived, as the exploration itself may be completed quickly before potential long-run non-stationarities come into play. However, in practice, exact knowledge of the linear model is difficult to justify. Furthermore, potential existence of unobservable covariates, uneven user arrival rates, interpretation of the necessary rank condition, and users opting out of private data tracking all need to be addressed for practical recommender system applications. In this work, we conduct a theoretical study to address all these issues while still achieving bounded regret. Aside from proof techniques, the key differentiating assumption we make here is the presence of effective Sy
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#65292;&#32771;&#34385;&#20102;&#29992;&#25143;&#30340;&#36141;&#20080;&#39034;&#24207;&#20197;&#39044;&#27979;&#20182;&#20204;&#30340;&#19979;&#19968;&#27425;&#36141;&#20080;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#22823;&#35268;&#27169;&#30340;&#20449;&#29992;&#21345;&#20132;&#26131;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#39564;&#35777;&#21644;&#25490;&#21517;&#65292;&#23637;&#29616;&#20102;&#20854;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2207.06225</link><description>&lt;p&gt;
&#38024;&#23545;&#19979;&#19968;&#27425;&#36141;&#20080;&#39044;&#27979;&#30340;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Sequential Recommendation Model for Next Purchase Prediction. (arXiv:2207.06225v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.06225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#65292;&#32771;&#34385;&#20102;&#29992;&#25143;&#30340;&#36141;&#20080;&#39034;&#24207;&#20197;&#39044;&#27979;&#20182;&#20204;&#30340;&#19979;&#19968;&#27425;&#36141;&#20080;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#22823;&#35268;&#27169;&#30340;&#20449;&#29992;&#21345;&#20132;&#26131;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#39564;&#35777;&#21644;&#25490;&#21517;&#65292;&#23637;&#29616;&#20102;&#20854;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25552;&#20379;&#24403;&#20195;&#25968;&#23383;&#33829;&#38144;&#20307;&#39564;&#26102;&#65292;&#25512;&#33616;&#30340;&#26102;&#25928;&#24615;&#21644;&#19978;&#19979;&#25991;&#20934;&#30830;&#24615;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#20256;&#32479;&#30340;&#25512;&#33616;&#31995;&#32479;&#36890;&#36807;&#32771;&#34385;&#29992;&#25143;&#30340;&#36807;&#21435;&#36141;&#20080;&#35760;&#24405;&#21521;&#29992;&#25143;&#25512;&#33616;&#30456;&#20851;&#20294;&#19981;&#21463;&#26102;&#38388;&#24433;&#21709;&#30340;&#29289;&#21697;&#12290;&#36825;&#20123;&#25512;&#33616;&#21482;&#26159;&#31526;&#21512;&#29992;&#25143;&#30340;&#19968;&#33324;&#20559;&#22909;&#65292;&#32780;&#19981;&#26159;&#29992;&#25143;&#22312;&#36141;&#20080;&#20043;&#21069;&#30340;&#20855;&#20307;&#38656;&#27714;&#12290;&#30456;&#21453;&#65292;&#32771;&#34385;&#20132;&#26131;&#12289;&#36141;&#20080;&#25110;&#20307;&#39564;&#39034;&#24207;&#26469;&#34913;&#37327;&#29992;&#25143;&#28436;&#21270;&#20559;&#22909;&#30340;&#25512;&#33616;&#31995;&#32479;&#33021;&#22815;&#20026;&#29992;&#25143;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#26377;&#25928;&#30340;&#25512;&#33616;&#65306;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#19981;&#20165;&#33021;&#26356;&#22909;&#22320;&#29702;&#35299;&#29992;&#25143;&#24403;&#21069;&#38656;&#27714;&#30340;&#34892;&#20026;&#65292;&#36824;&#20855;&#26377;&#26356;&#22909;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#19968;&#20221;&#21253;&#21547;&#36229;&#36807;2.7&#30334;&#19975;&#20449;&#29992;&#21345;&#20132;&#26131;&#25968;&#25454;&#21644;46K&#20010;&#25345;&#21345;&#20154;&#30340;&#29983;&#20135;&#25968;&#25454;&#38598;&#65292;&#23637;&#31034;&#24182;&#25490;&#21517;&#20102;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#25928;&#26524;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#20351;&#29992;&#33258;&#32534;&#30721;&#22120;&#23545;&#21407;&#22987;&#30340;&#20132;&#26131;&#25968;&#25454;&#36827;&#34892;&#22788;&#29702;&#65292;&#28982;&#21518;&#25552;&#20132;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Timeliness and contextual accuracy of recommendations are increasingly important when delivering contemporary digital marketing experiences. Conventional recommender systems (RS) suggest relevant but time-invariant items to users by accounting for their past purchases. These recommendations only map to customers' general preferences rather than a customer's specific needs immediately preceding a purchase. In contrast, RSs that consider the order of transactions, purchases, or experiences to measure evolving preferences can offer more salient and effective recommendations to customers: Sequential RSs not only benefit from a better behavioral understanding of a user's current needs but also better predictive power. In this paper, we demonstrate and rank the effectiveness of a sequential recommendation system by utilizing a production dataset of over 2.7 million credit card transactions for 46K cardholders. The method first employs an autoencoder on raw transaction data and submits observ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;CONVINSE&#65292;&#19968;&#20010;&#29992;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#19978;&#30340;ConvQA&#30340;&#31471;&#21040;&#31471;&#27969;&#27700;&#32447;&#65292;&#36890;&#36807;&#32852;&#21512;&#25552;&#21462;&#26469;&#33258;&#30693;&#35782;&#24211;&#12289;&#25991;&#26412;&#21644;&#34920;&#26684;&#30340;&#20449;&#24687;&#65292;&#25552;&#21319;&#20102;&#31572;&#26696;&#35206;&#30422;&#29575;&#21644;&#21487;&#20449;&#24230;&#12290;</title><link>http://arxiv.org/abs/2204.11677</link><description>&lt;p&gt;
&#24322;&#26500;&#25968;&#25454;&#28304;&#19978;&#30340;&#23545;&#35805;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
Conversational Question Answering on Heterogeneous Sources. (arXiv:2204.11677v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.11677
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;CONVINSE&#65292;&#19968;&#20010;&#29992;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#19978;&#30340;ConvQA&#30340;&#31471;&#21040;&#31471;&#27969;&#27700;&#32447;&#65292;&#36890;&#36807;&#32852;&#21512;&#25552;&#21462;&#26469;&#33258;&#30693;&#35782;&#24211;&#12289;&#25991;&#26412;&#21644;&#34920;&#26684;&#30340;&#20449;&#24687;&#65292;&#25552;&#21319;&#20102;&#31572;&#26696;&#35206;&#30422;&#29575;&#21644;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#38382;&#31572;(ConvQA)&#35299;&#20915;&#20102;&#39034;&#24207;&#20449;&#24687;&#38656;&#27714;&#20013;&#30340;&#21518;&#32493;&#38382;&#39064;&#20013;&#19978;&#19979;&#25991;&#38544;&#21547;&#30340;&#38382;&#39064;&#12290;&#24403;&#21069;&#30340;ConvQA&#31995;&#32479;&#21482;&#33021;&#22312;&#21516;&#36136;&#21270;&#30340;&#20449;&#24687;&#28304;&#19978;&#25805;&#20316;&#65292;&#22914;&#30693;&#35782;&#24211;(KB)&#12289;&#25991;&#26412;&#35821;&#26009;&#24211;&#25110;&#34920;&#26684;&#38598;&#21512;&#12290;&#26412;&#25991;&#38024;&#23545;&#30340;&#26159;&#22312;&#36825;&#20123;&#24322;&#36136;&#25968;&#25454;&#28304;&#20013;&#32852;&#21512;&#25552;&#21462;&#20449;&#24687;&#65292;&#20174;&#32780;&#25552;&#21319;&#31572;&#26696;&#35206;&#30422;&#29575;&#21644;&#21487;&#20449;&#24230;&#30340;&#26032;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;CONVINSE&#65292;&#19968;&#20010;&#29992;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#19978;&#30340;ConvQA&#30340;&#31471;&#21040;&#31471;&#27969;&#27700;&#32447;&#65292;&#20998;&#20026;&#19977;&#20010;&#38454;&#27573;&#65306;i&#65289;&#23398;&#20064;&#23545;&#20256;&#20837;&#38382;&#39064;&#21450;&#20854;&#23545;&#35805;&#19978;&#19979;&#25991;&#30340;&#26126;&#30830;&#32467;&#26500;&#21270;&#34920;&#31034;&#65292;ii&#65289;&#21033;&#29992;&#36825;&#20010;&#31867;&#20284;&#26694;&#26550;&#30340;&#34920;&#31034;&#26041;&#24335;&#32479;&#19968;&#22320;&#33719;&#21462;&#21040;&#26469;&#33258;KB&#12289;&#25991;&#26412;&#21644;&#34920;&#26684;&#30340;&#30456;&#20851;&#35777;&#25454;&#65292;iii&#65289;&#36816;&#34892;&#34701;&#21512;&#35299;&#30721;&#27169;&#22411;&#26469;&#29983;&#25104;&#31572;&#26696;&#12290;&#25105;&#20204;&#26500;&#24314;&#24182;&#21457;&#24067;&#20102;&#31532;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;ConvMix&#65292;&#29992;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#19978;&#30340;ConvQA&#65292;&#21253;&#25324;3000&#20010;&#30495;&#23454;&#29992;&#25143;&#23545;&#35805;&#21644;16000&#20010;&#38382;&#39064;&#65292;&#20197;&#21450;&#23454;&#20307;&#27880;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational question answering (ConvQA) tackles sequential information needs where contexts in follow-up questions are left implicit. Current ConvQA systems operate over homogeneous sources of information: either a knowledge base (KB), or a text corpus, or a collection of tables. This paper addresses the novel issue of jointly tapping into all of these together, this way boosting answer coverage and confidence. We present CONVINSE, an end-to-end pipeline for ConvQA over heterogeneous sources, operating in three stages: i) learning an explicit structured representation of an incoming question and its conversational context, ii) harnessing this frame-like representation to uniformly capture relevant evidences from KB, text, and tables, and iii) running a fusion-in-decoder model to generate the answer. We construct and release the first benchmark, ConvMix, for ConvQA over heterogeneous sources, comprising 3000 real-user conversations with 16000 questions, along with entity annotations,
&lt;/p&gt;</description></item></channel></rss>