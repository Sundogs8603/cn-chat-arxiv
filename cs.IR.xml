<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19979;&#19968;&#20010;&#26032;&#31726;&#23376;&#25512;&#33616;&#30340;&#20219;&#21153;&#65292;&#21363;&#25512;&#33616;&#20165;&#21253;&#21547;&#26032;&#29289;&#21697;&#30340;&#31726;&#23376;&#12290;&#20316;&#32773;&#21457;&#29616;&#29616;&#26377;&#19979;&#19968;&#20010;&#31726;&#23376;&#25512;&#33616;&#26041;&#27861;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#30340;&#36827;&#23637;&#26377;&#38480;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21452;&#21521;&#21464;&#25442;&#31726;&#23376;&#25512;&#33616;&#27169;&#22411;&#65288;BTBR&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.01308</link><description>&lt;p&gt;
&#36974;&#30422;&#21644;&#20132;&#25442;&#24207;&#21015;&#24314;&#27169;&#65306;&#29992;&#20110;&#26434;&#36135;&#36141;&#29289;&#20013;&#19979;&#19968;&#20010;&#26032;&#31726;&#23376;&#25512;&#33616;&#30340;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Masked and Swapped Sequence Modeling for Next Novel Basket Recommendation in Grocery Shopping. (arXiv:2308.01308v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01308
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19979;&#19968;&#20010;&#26032;&#31726;&#23376;&#25512;&#33616;&#30340;&#20219;&#21153;&#65292;&#21363;&#25512;&#33616;&#20165;&#21253;&#21547;&#26032;&#29289;&#21697;&#30340;&#31726;&#23376;&#12290;&#20316;&#32773;&#21457;&#29616;&#29616;&#26377;&#19979;&#19968;&#20010;&#31726;&#23376;&#25512;&#33616;&#26041;&#27861;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#30340;&#36827;&#23637;&#26377;&#38480;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21452;&#21521;&#21464;&#25442;&#31726;&#23376;&#25512;&#33616;&#27169;&#22411;&#65288;BTBR&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19979;&#19968;&#20010;&#31726;&#23376;&#25512;&#33616;&#26159;&#22522;&#20110;&#24050;&#36141;&#31726;&#23376;&#24207;&#21015;&#39044;&#27979;&#19979;&#19968;&#32452;&#29289;&#21697;&#30340;&#20219;&#21153;&#12290;&#36825;&#26159;&#19968;&#20010;&#34987;&#24191;&#27867;&#30740;&#31350;&#30340;&#25512;&#33616;&#20219;&#21153;&#65292;&#23588;&#20854;&#26159;&#22312;&#26434;&#36135;&#36141;&#29289;&#29615;&#22659;&#20013;&#12290;&#22312;&#19979;&#19968;&#20010;&#31726;&#23376;&#25512;&#33616;&#20013;&#65292;&#21306;&#20998;&#37325;&#22797;&#29289;&#21697;&#21644;&#25506;&#32034;&#29289;&#21697;&#26159;&#24456;&#26377;&#29992;&#30340;&#65292;&#21363;&#29992;&#25143;&#24050;&#32463;&#28040;&#36153;&#36807;&#30340;&#29289;&#21697;&#21644;&#29992;&#25143;&#26410;&#28040;&#36153;&#36807;&#30340;&#29289;&#21697;&#12290;&#22823;&#37096;&#20998;&#19979;&#19968;&#20010;&#31726;&#23376;&#25512;&#33616;&#30340;&#30740;&#31350;&#35201;&#20040;&#24573;&#30053;&#36825;&#31181;&#21306;&#20998;&#65292;&#35201;&#20040;&#19987;&#27880;&#20110;&#37325;&#22797;&#29289;&#21697;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19979;&#19968;&#20010;&#26032;&#31726;&#23376;&#25512;&#33616;&#30340;&#20219;&#21153;&#65292;&#21363;&#25512;&#33616;&#20165;&#21253;&#21547;&#26032;&#29289;&#21697;&#30340;&#31726;&#23376;&#65292;&#36825;&#23545;&#20110;&#23454;&#38469;&#24212;&#29992;&#21644;&#19979;&#19968;&#20010;&#31726;&#23376;&#25512;&#33616;&#35780;&#20272;&#37117;&#24456;&#26377;&#20215;&#20540;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#29616;&#26377;&#19979;&#19968;&#20010;&#31726;&#23376;&#25512;&#33616;&#26041;&#27861;&#22312;&#19979;&#19968;&#20010;&#26032;&#31726;&#23376;&#25512;&#33616;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#65292;&#24182;&#21457;&#29616;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#21462;&#24471;&#30340;&#36827;&#23637;&#26377;&#38480;&#12290;&#20026;&#20102;&#35299;&#20915;&#19979;&#19968;&#20010;&#26032;&#31726;&#23376;&#25512;&#33616;&#20219;&#21153;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21452;&#21521;&#21464;&#25442;&#31726;&#23376;&#25512;&#33616;&#27169;&#22411;&#65288;BTBR&#65289;&#65292;&#23427;&#19987;&#27880;&#20110;&#30452;&#25509;&#24314;&#27169;&#31726;&#23376;&#24207;&#21015;&#20013;&#30340;&#26032;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;
Next basket recommendation (NBR) is the task of predicting the next set of items based on a sequence of already purchased baskets. It is a recommendation task that has been widely studied, especially in the context of grocery shopping. In next basket recommendation (NBR), it is useful to distinguish between repeat items, i.e., items that a user has consumed before, and explore items, i.e., items that a user has not consumed before. Most NBR work either ignores this distinction or focuses on repeat items. We formulate the next novel basket recommendation (NNBR) task, i.e., the task of recommending a basket that only consists of novel items, which is valuable for both real-world application and NBR evaluation. We evaluate how existing NBR methods perform on the NNBR task and find that, so far, limited progress has been made w.r.t. the NNBR task. To address the NNBR task, we propose a simple bi-directional transformer basket recommendation model (BTBR), which is focused on directly modeli
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19978;&#19979;&#25991;&#39044;&#27979;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#20381;&#36182;&#29992;&#25143;&#21644;&#19978;&#19979;&#25991;&#29305;&#24449;&#26469;&#39044;&#27979;&#29992;&#25143;&#34892;&#20026;&#30340;&#27010;&#29575;&#65292;&#20174;&#32780;&#22312;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#20013;&#25552;&#39640;&#24615;&#33021;&#24182;&#23545;&#20010;&#24615;&#21270;&#25512;&#33616;&#39046;&#22495;&#20135;&#29983;&#24191;&#27867;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2308.01231</link><description>&lt;p&gt;
&#21457;&#25381;&#19978;&#19979;&#25991;&#30340;&#21147;&#37327;&#65306;&#22522;&#20110;&#19978;&#19979;&#25991;&#39044;&#27979;&#27169;&#22411;&#22686;&#24378;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Unleash the Power of Context: Enhancing Large-Scale Recommender Systems with Context-Based Prediction Models. (arXiv:2308.01231v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19978;&#19979;&#25991;&#39044;&#27979;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#20381;&#36182;&#29992;&#25143;&#21644;&#19978;&#19979;&#25991;&#29305;&#24449;&#26469;&#39044;&#27979;&#29992;&#25143;&#34892;&#20026;&#30340;&#27010;&#29575;&#65292;&#20174;&#32780;&#22312;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#20013;&#25552;&#39640;&#24615;&#33021;&#24182;&#23545;&#20010;&#24615;&#21270;&#25512;&#33616;&#39046;&#22495;&#20135;&#29983;&#24191;&#27867;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19978;&#19979;&#25991;&#39044;&#27979;&#27169;&#22411;&#30340;&#27010;&#24565;&#12290;&#19978;&#19979;&#25991;&#39044;&#27979;&#27169;&#22411;&#20165;&#20381;&#36182;&#20110;&#29992;&#25143;&#21644;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#32780;&#19981;&#32771;&#34385;&#29289;&#21697;&#26412;&#36523;&#30340;&#29305;&#23450;&#29305;&#24449;&#65292;&#26469;&#30830;&#23450;&#29992;&#25143;&#34892;&#20026;&#65288;&#22914;&#28857;&#20987;&#25110;&#36716;&#21270;&#65289;&#30340;&#27010;&#29575;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#35768;&#22810;&#26377;&#20215;&#20540;&#30340;&#24212;&#29992;&#22330;&#26223;&#65292;&#21253;&#25324;&#35757;&#32451;&#36741;&#21161;&#30340;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#27169;&#22411;&#26469;&#20272;&#35745;&#28857;&#20987;&#27010;&#29575;&#65292;&#24182;&#23558;&#20854;&#39044;&#27979;&#32467;&#26524;&#20316;&#20026;CTR&#39044;&#27979;&#27169;&#22411;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#31181;&#25913;&#36827;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#19994;&#21153;&#25351;&#26631;&#19978;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#32780;&#23545;&#26381;&#21153;&#25104;&#26412;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#21487;&#25193;&#23637;&#65292;&#20294;&#24378;&#22823;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22686;&#24378;&#22823;&#35268;&#27169;&#21830;&#19994;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#24182;&#23545;&#20010;&#24615;&#21270;&#25512;&#33616;&#39046;&#22495;&#20855;&#26377;&#24191;&#27867;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce the notion of Context-Based Prediction Models. A Context-Based Prediction Model determines the probability of a user's action (such as a click or a conversion) solely by relying on user and contextual features, without considering any specific features of the item itself. We have identified numerous valuable applications for this modeling approach, including training an auxiliary context-based model to estimate click probability and incorporating its prediction as a feature in CTR prediction models. Our experiments indicate that this enhancement brings significant improvements in offline and online business metrics while having minimal impact on the cost of serving. Overall, our work offers a simple and scalable, yet powerful approach for enhancing the performance of large-scale commercial recommender systems, with broad implications for the field of personalized recommendations.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20010;&#24615;&#21270;&#26102;&#38388;&#34928;&#20943;&#20989;&#25968;&#30340;&#33258;&#36866;&#24212;&#21327;&#21516;&#36807;&#28388;&#37329;&#34701;&#20135;&#21697;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#22312;&#21160;&#24577;&#29615;&#22659;&#19979;&#25552;&#20379;&#21487;&#38752;&#25512;&#33616;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24314;&#27169;&#23458;&#25143;&#21644;&#20135;&#21697;&#20043;&#38388;&#30340;&#21160;&#24577;&#21327;&#21516;&#20449;&#21495;&#65292;&#22788;&#29702;&#37329;&#34701;&#25968;&#25454;&#30340;&#38750;&#24179;&#31283;&#24615;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2308.01208</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#26102;&#38388;&#34928;&#20943;&#20989;&#25968;&#30340;&#33258;&#36866;&#24212;&#21327;&#21516;&#36807;&#28388;&#37329;&#34701;&#20135;&#21697;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Adaptive Collaborative Filtering with Personalized Time Decay Functions for Financial Product Recommendation. (arXiv:2308.01208v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20010;&#24615;&#21270;&#26102;&#38388;&#34928;&#20943;&#20989;&#25968;&#30340;&#33258;&#36866;&#24212;&#21327;&#21516;&#36807;&#28388;&#37329;&#34701;&#20135;&#21697;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#22312;&#21160;&#24577;&#29615;&#22659;&#19979;&#25552;&#20379;&#21487;&#38752;&#25512;&#33616;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24314;&#27169;&#23458;&#25143;&#21644;&#20135;&#21697;&#20043;&#38388;&#30340;&#21160;&#24577;&#21327;&#21516;&#20449;&#21495;&#65292;&#22788;&#29702;&#37329;&#34701;&#25968;&#25454;&#30340;&#38750;&#24179;&#31283;&#24615;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#20551;&#35774;&#21382;&#21490;&#25968;&#25454;&#26159;&#19981;&#21464;&#30340;&#65292;&#26080;&#27861;&#32771;&#34385;&#29992;&#25143;&#20559;&#22909;&#30340;&#21160;&#24577;&#24615;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#26102;&#38388;&#25935;&#24863;&#29615;&#22659;&#20013;&#25552;&#20379;&#21487;&#38752;&#25512;&#33616;&#30340;&#33021;&#21147;&#12290;&#36825;&#19968;&#20551;&#35774;&#22312;&#37329;&#34701;&#39046;&#22495;&#23588;&#20854;&#26377;&#38382;&#39064;&#65292;&#22240;&#20026;&#37329;&#34701;&#20135;&#21697;&#30340;&#20272;&#20540;&#19981;&#26029;&#21464;&#21270;&#65292;&#23548;&#33268;&#23458;&#25143;&#20852;&#36259;&#39057;&#32321;&#36716;&#31227;&#12290;&#36825;&#20123;&#28436;&#21464;&#30340;&#20852;&#36259;&#21487;&#20197;&#36890;&#36807;&#36807;&#21435;&#23458;&#25143;-&#20135;&#21697;&#20132;&#20114;&#20013;&#24635;&#32467;&#20986;&#26469;&#65292;&#20854;&#25928;&#29992;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#20250;&#22240;&#23458;&#25143;&#32780;&#24322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#30456;&#20851;&#30340;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#20010;&#24615;&#21270;&#34928;&#20943;&#20989;&#25968;&#33258;&#36866;&#24212;&#22320;&#25240;&#20215;&#36828;&#31163;&#30340;&#23458;&#25143;-&#20135;&#21697;&#20132;&#20114;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#22788;&#29702;&#37329;&#34701;&#25968;&#25454;&#30340;&#38750;&#24179;&#31283;&#24615;&#65292;&#24182;&#36890;&#36807;&#24314;&#27169;&#23458;&#25143;&#21644;&#20135;&#21697;&#20043;&#38388;&#30340;&#21160;&#24577;&#21327;&#21516;&#20449;&#21495;&#26469;&#20135;&#29983;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#20351;&#29992;&#19987;&#26377;&#25968;&#25454;&#38598;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical recommender systems often assume that historical data are stationary and fail to account for the dynamic nature of user preferences, limiting their ability to provide reliable recommendations in time-sensitive settings. This assumption is particularly problematic in finance, where financial products exhibit continuous changes in valuations, leading to frequent shifts in client interests. These evolving interests, summarized in the past client-product interactions, see their utility fade over time with a degree that might differ from one client to another. To address this challenge, we propose a time-dependent collaborative filtering algorithm that can adaptively discount distant client-product interactions using personalized decay functions. Our approach is designed to handle the non-stationarity of financial data and produce reliable recommendations by modeling the dynamic collaborative signals between clients and products. We evaluate our method using a proprietary dataset 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#25552;&#39640;&#29616;&#20195;&#24037;&#19994;&#25512;&#33616;&#31995;&#32479;&#30340;&#26041;&#27861;&#35770;&#65292;&#20026;&#32463;&#39564;&#20016;&#23500;&#30340;RS&#24037;&#31243;&#24072;&#25552;&#20379;&#23454;&#29992;&#32463;&#39564;&#65292;&#21487;&#33021;&#36866;&#29992;&#20110;&#20854;&#20182;RS&#12290;</title><link>http://arxiv.org/abs/2308.01204</link><description>&lt;p&gt;
&#25552;&#21319;&#29616;&#20195;&#24037;&#19994;&#25512;&#33616;&#31995;&#32479;&#30340;&#26041;&#27861;&#35770;
&lt;/p&gt;
&lt;p&gt;
Methodologies for Improving Modern Industrial Recommender Systems. (arXiv:2308.01204v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#25552;&#39640;&#29616;&#20195;&#24037;&#19994;&#25512;&#33616;&#31995;&#32479;&#30340;&#26041;&#27861;&#35770;&#65292;&#20026;&#32463;&#39564;&#20016;&#23500;&#30340;RS&#24037;&#31243;&#24072;&#25552;&#20379;&#23454;&#29992;&#32463;&#39564;&#65292;&#21487;&#33021;&#36866;&#29992;&#20110;&#20854;&#20182;RS&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#26159;&#19968;&#39033;&#25104;&#29087;&#30340;&#25216;&#26415;&#65292;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#31038;&#20132;&#23186;&#20307;&#12289;&#30005;&#23376;&#21830;&#21153;&#12289;&#23089;&#20048;&#31561;&#39046;&#22495;&#12290;RS&#30830;&#23454;&#26159;&#35768;&#22810;&#27969;&#34892;APP&#65288;&#22914;YouTube&#12289;Tik Tok&#12289;&#23567;&#32418;&#20070;&#12289;&#21716;&#21737;&#21716;&#21737;&#31561;&#65289;&#25104;&#21151;&#30340;&#20851;&#38190;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#25552;&#39640;&#29616;&#20195;&#24037;&#19994;RS&#30340;&#26041;&#27861;&#35770;&#65292;&#26088;&#22312;&#20026;&#32463;&#39564;&#20016;&#23500;&#30340;RS&#24037;&#31243;&#24072;&#25552;&#20379;&#24110;&#21161;&#65292;&#20182;&#20204;&#27491;&#22312;&#21162;&#21147;&#25913;&#21892;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#65292;&#22914;&#29992;&#25143;&#30041;&#23384;&#21644;&#20351;&#29992;&#26102;&#38271;&#12290;&#26412;&#25991;&#20013;&#20998;&#20139;&#30340;&#32463;&#39564;&#24050;&#32463;&#22312;&#19968;&#20123;&#30495;&#23454;&#30340;&#24037;&#19994;RS&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#24182;&#19988;&#21487;&#33021;&#36866;&#29992;&#20110;&#20854;&#20182;RS&#12290;&#22823;&#37096;&#20998;&#20869;&#23481;&#37117;&#22522;&#20110;&#19994;&#30028;&#32463;&#39564;&#65292;&#27809;&#26377;&#20844;&#24320;&#21487;&#29992;&#30340;&#21442;&#32771;&#36164;&#26009;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender system (RS) is an established technology with successful applications in social media, e-commerce, entertainment, and more. RSs are indeed key to the success of many popular APPs, such as YouTube, Tik Tok, Xiaohongshu, Bilibili, and others. This paper explores the methodology for improving modern industrial RSs. It is written for experienced RS engineers who are diligently working to improve their key performance indicators, such as retention and duration. The experiences shared in this paper have been tested in some real industrial RSs and are likely to be generalized to other RSs as well. Most contents in this paper are industry experience without publicly available references.
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;&#27573;&#33853;&#32423;&#21035;&#20449;&#24687;&#22312;&#25429;&#25417;&#21028;&#20363;&#30456;&#20284;&#24615;&#20197;&#25552;&#39640;&#20808;&#20363;&#26816;&#32034;&#24615;&#33021;&#26041;&#38754;&#30340;&#36164;&#28304;&#21033;&#29992;&#24615;&#65292;&#24182;&#21457;&#29616;&#27573;&#33853;&#32423;&#21035;&#26041;&#27861;&#22312;&#19982;&#22522;&#32447;&#25991;&#26723;&#32423;&#21035;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26356;&#24378;&#30340;&#21306;&#20998;&#33021;&#21147;&#12290;&#23545;&#21360;&#24230;&#26368;&#39640;&#27861;&#38498;&#21028;&#20915;&#20219;&#21153;&#30340;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#32467;&#26524;&#26174;&#31034;&#65292;&#27573;&#33853;&#32423;&#21035;&#26041;&#27861;&#20855;&#26377;&#21487;&#27604;&#24615;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.01203</link><description>&lt;p&gt;
&#20998;&#26512;&#27573;&#33853;&#30340;&#36164;&#28304;&#21033;&#29992;&#24615;&#20197;&#29992;&#20110;&#20808;&#20363;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Analysing the Resourcefulness of the Paragraph for Precedence Retrieval. (arXiv:2308.01203v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01203
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#27573;&#33853;&#32423;&#21035;&#20449;&#24687;&#22312;&#25429;&#25417;&#21028;&#20363;&#30456;&#20284;&#24615;&#20197;&#25552;&#39640;&#20808;&#20363;&#26816;&#32034;&#24615;&#33021;&#26041;&#38754;&#30340;&#36164;&#28304;&#21033;&#29992;&#24615;&#65292;&#24182;&#21457;&#29616;&#27573;&#33853;&#32423;&#21035;&#26041;&#27861;&#22312;&#19982;&#22522;&#32447;&#25991;&#26723;&#32423;&#21035;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26356;&#24378;&#30340;&#21306;&#20998;&#33021;&#21147;&#12290;&#23545;&#21360;&#24230;&#26368;&#39640;&#27861;&#38498;&#21028;&#20915;&#20219;&#21153;&#30340;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#32467;&#26524;&#26174;&#31034;&#65292;&#27573;&#33853;&#32423;&#21035;&#26041;&#27861;&#20855;&#26377;&#21487;&#27604;&#24615;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#25552;&#21462;&#30456;&#20851;&#27861;&#24459;&#20449;&#24687;&#20197;&#24110;&#21161;&#27861;&#24459;&#20174;&#19994;&#32773;&#30340;&#26041;&#27861;&#26159;&#19968;&#20010;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#30740;&#31350;&#24037;&#20316;&#36890;&#36807;&#21033;&#29992;&#19981;&#21516;&#31867;&#22411;&#30340;&#20449;&#24687;&#65292;&#22914;&#20803;&#25968;&#25454;&#12289;&#24341;&#29992;&#25991;&#29486;&#12289;&#20851;&#38190;&#35789;&#12289;&#21477;&#23376;&#12289;&#27573;&#33853;&#31561;&#65292;&#27491;&#22312;&#36827;&#34892;&#12290;&#19982;&#20219;&#20309;&#25991;&#26412;&#25991;&#26723;&#19968;&#26679;&#65292;&#27861;&#24459;&#25991;&#20214;&#30001;&#27573;&#33853;&#32452;&#25104;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#27573;&#33853;&#32423;&#21035;&#20449;&#24687;&#22312;&#25429;&#25417;&#21028;&#20363;&#30456;&#20284;&#24615;&#20197;&#25552;&#39640;&#20808;&#20363;&#26816;&#32034;&#24615;&#33021;&#26041;&#38754;&#30340;&#36164;&#28304;&#21033;&#29992;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#27573;&#33853;&#32423;&#21035;&#26041;&#27861;&#21482;&#38656;&#23569;&#37327;&#27573;&#33853;&#20132;&#20114;&#21363;&#21487;&#25429;&#25417;&#21028;&#20363;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#19988;&#22312;&#22522;&#32447;&#25991;&#26723;&#32423;&#21035;&#26041;&#27861;&#19978;&#20855;&#26377;&#26356;&#24378;&#30340;&#21306;&#20998;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#23545;&#21360;&#24230;&#26368;&#39640;&#27861;&#38498;&#21028;&#20915;&#20219;&#21153;&#30340;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#27604;&#36739;&#32467;&#26524;&#34920;&#26126;&#65292;&#27573;&#33853;&#32423;&#21035;&#26041;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#21487;&#27604;&#24615;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Developing methods for extracting relevant legal information to aid legal practitioners is an active research area. In this regard, research efforts are being made by leveraging different kinds of information, such as meta-data, citations, keywords, sentences, paragraphs, etc. Similar to any text document, legal documents are composed of paragraphs. In this paper, we have analyzed the resourcefulness of paragraph-level information in capturing similarity among judgments for improving the performance of precedence retrieval. We found that the paragraph-level methods could capture the similarity among the judgments with only a few paragraph interactions and exhibit more discriminating power over the baseline document-level method. Moreover, the comparison results on two benchmark datasets for the precedence retrieval on the Indian supreme court judgments task show that the paragraph-level methods exhibit comparable performance with the state-of-the-art methods
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#26080;&#25439;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#21487;&#20197;&#23454;&#29616;&#20840;&#22270;&#35757;&#32451;&#65292;&#25429;&#25417;&#39640;&#38454;&#32467;&#26500;&#20449;&#24687;&#65292;&#24182;&#22312;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#21069;&#25552;&#19979;&#26377;&#25928;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2308.01197</link><description>&lt;p&gt;
GNN4FR:&#19968;&#31181;&#26080;&#25439;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
GNN4FR: A Lossless GNN-based Federated Recommendation Framework. (arXiv:2308.01197v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01197
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#26080;&#25439;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#21487;&#20197;&#23454;&#29616;&#20840;&#22270;&#35757;&#32451;&#65292;&#25429;&#25417;&#39640;&#38454;&#32467;&#26500;&#20449;&#24687;&#65292;&#24182;&#22312;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#21069;&#25552;&#19979;&#26377;&#25928;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30001;&#20110;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#21644;&#29289;&#21697;&#33410;&#28857;&#20043;&#38388;&#30340;&#39640;&#38454;&#32467;&#26500;&#20449;&#24687;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#38656;&#35201;&#25910;&#38598;&#29992;&#25143;&#21644;&#30456;&#24212;&#29289;&#21697;&#20043;&#38388;&#30340;&#20010;&#20154;&#20132;&#20114;&#25968;&#25454;&#65292;&#24182;&#22312;&#20013;&#24515;&#26381;&#21153;&#22120;&#20013;&#23545;&#20854;&#36827;&#34892;&#24314;&#27169;&#65292;&#36825;&#21487;&#33021;&#36829;&#21453;GDPR&#31561;&#38544;&#31169;&#27861;&#24459;&#12290;&#33267;&#20170;&#27809;&#26377;&#29616;&#26377;&#30340;&#24037;&#20316;&#21487;&#20197;&#26500;&#24314;&#19968;&#20010;&#20840;&#23616;&#22270;&#65292;&#21516;&#26102;&#21448;&#19981;&#27844;&#38706;&#27599;&#20010;&#29992;&#25143;&#30340;&#31169;&#20154;&#20132;&#20114;&#25968;&#25454;&#65288;&#21363;&#20182;&#25110;&#22905;&#30340;&#23376;&#22270;&#65289;&#12290;&#26412;&#25991;&#39318;&#27425;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;GNN&#30340;&#26032;&#22411;&#26080;&#25439;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#20855;&#26377;&#23436;&#25972;&#39640;&#38454;&#32467;&#26500;&#20449;&#24687;&#30340;&#20840;&#22270;&#35757;&#32451;&#65292;&#20351;&#35757;&#32451;&#36807;&#31243;&#31561;&#20215;&#20110;&#30456;&#24212;&#30340;&#38750;&#32852;&#37030;&#23545;&#24212;&#29289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;LightGCN&#26469;&#23454;&#20363;&#21270;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#24182;&#23637;&#31034;&#20854;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have gained wide popularity in recommender systems due to their capability to capture higher-order structure information among the nodes of users and items. However, these methods need to collect personal interaction data between a user and the corresponding items and then model them in a central server, which would break the privacy laws such as GDPR. So far, no existing work can construct a global graph without leaking each user's private interaction data (i.e., his or her subgraph). In this paper, we are the first to design a novel lossless federated recommendation framework based on GNN, which achieves full-graph training with complete high-order structure information, enabling the training process to be equivalent to the corresponding un-federated counterpart. In addition, we use LightGCN to instantiate an example of our framework and show its equivalence.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#26088;&#22312;&#23454;&#29616;&#25512;&#33616;&#31995;&#32479;&#30340;&#21487;&#25345;&#32493;&#36879;&#26126;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36125;&#21494;&#26031;&#25490;&#21517;&#22270;&#20687;&#36827;&#34892;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#20197;&#26368;&#22823;&#21270;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20449;&#20219;&#12290;</title><link>http://arxiv.org/abs/2308.01196</link><description>&lt;p&gt;
&#21487;&#25345;&#32493;&#36879;&#26126;&#30340;&#25512;&#33616;&#31995;&#32479;: &#29992;&#20110;&#35299;&#37322;&#24615;&#30340;&#36125;&#21494;&#26031;&#22270;&#20687;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Sustainable Transparency in Recommender Systems: Bayesian Ranking of Images for Explainability. (arXiv:2308.01196v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01196
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#26088;&#22312;&#23454;&#29616;&#25512;&#33616;&#31995;&#32479;&#30340;&#21487;&#25345;&#32493;&#36879;&#26126;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36125;&#21494;&#26031;&#25490;&#21517;&#22270;&#20687;&#36827;&#34892;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#20197;&#26368;&#22823;&#21270;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20449;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#29616;&#20195;&#19990;&#30028;&#20013;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#36890;&#24120;&#25351;&#23548;&#29992;&#25143;&#25214;&#21040;&#30456;&#20851;&#30340;&#20869;&#23481;&#25110;&#20135;&#21697;&#65292;&#24182;&#23545;&#29992;&#25143;&#21644;&#20844;&#27665;&#30340;&#20915;&#31574;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#30830;&#20445;&#36825;&#20123;&#31995;&#32479;&#30340;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20449;&#20219;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65307;&#20010;&#24615;&#21270;&#35299;&#37322;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#20026;&#25512;&#33616;&#25552;&#20379;&#29702;&#30001;&#12290;&#22312;&#29983;&#25104;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#29992;&#25143;&#21019;&#24314;&#30340;&#35270;&#35273;&#20869;&#23481;&#26159;&#19968;&#20010;&#29305;&#21035;&#26377;&#28508;&#21147;&#30340;&#36873;&#39033;&#65292;&#26377;&#28508;&#21147;&#26368;&#22823;&#21270;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20449;&#20219;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#27169;&#22411;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#35299;&#37322;&#25512;&#33616;&#26102;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#65306;&#21487;&#25345;&#32493;&#24615;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#20204;&#32463;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#23548;&#33268;&#30340;&#30899;&#25490;&#25918;&#37327;&#19982;&#23427;&#20204;&#34987;&#25972;&#21512;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#30456;&#24403;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#27169;&#22411;&#20351;&#29992;&#30340;&#26367;&#20195;&#23398;&#20064;&#30446;&#26631;&#19982;&#25490;&#21517;&#26368;&#26377;&#25928;&#30340;&#30446;&#26631;&#19981;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender Systems have become crucial in the modern world, commonly guiding users towards relevant content or products, and having a large influence over the decisions of users and citizens. However, ensuring transparency and user trust in these systems remains a challenge; personalized explanations have emerged as a solution, offering justifications for recommendations. Among the existing approaches for generating personalized explanations, using visual content created by the users is one particularly promising option, showing a potential to maximize transparency and user trust. Existing models for explaining recommendations in this context face limitations: sustainability has been a critical concern, as they often require substantial computational resources, leading to significant carbon emissions comparable to the Recommender Systems where they would be integrated. Moreover, most models employ surrogate learning goals that do not align with the objective of ranking the most effect
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#29992;&#20110;&#26681;&#25454;&#23458;&#25143;&#30340;&#37325;&#22797;&#36141;&#20080;&#27169;&#24335;&#39044;&#27979;&#20877;&#27425;&#36141;&#20080;&#30340;&#31867;&#21035;&#21644;&#21830;&#21697;&#12290;&#37319;&#29992;&#23618;&#27425;&#21270;PCIC&#27169;&#22411;&#65292;&#36890;&#36807;&#29983;&#23384;&#27169;&#22411;&#21644;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#25429;&#25417;&#28040;&#36153;&#34892;&#20026;&#21644;&#36235;&#21183;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#29305;&#24449;&#35757;&#32451;&#31867;&#21035;&#31890;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2308.01195</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#8220;&#20877;&#27425;&#36141;&#20080;&#8221;&#25512;&#33616;&#20013;&#30340;&#31867;&#21035;&#39057;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Personalized Category Frequency prediction for Buy It Again recommendations. (arXiv:2308.01195v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01195
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#29992;&#20110;&#26681;&#25454;&#23458;&#25143;&#30340;&#37325;&#22797;&#36141;&#20080;&#27169;&#24335;&#39044;&#27979;&#20877;&#27425;&#36141;&#20080;&#30340;&#31867;&#21035;&#21644;&#21830;&#21697;&#12290;&#37319;&#29992;&#23618;&#27425;&#21270;PCIC&#27169;&#22411;&#65292;&#36890;&#36807;&#29983;&#23384;&#27169;&#22411;&#21644;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#25429;&#25417;&#28040;&#36153;&#34892;&#20026;&#21644;&#36235;&#21183;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#29305;&#24449;&#35757;&#32451;&#31867;&#21035;&#31890;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#8220;&#20877;&#27425;&#36141;&#20080;&#8221;&#65288;BIA&#65289;&#25512;&#33616;&#23545;&#20110;&#38646;&#21806;&#21830;&#26469;&#35828;&#33267;&#20851;&#37325;&#35201;&#65292;&#36890;&#36807;&#26681;&#25454;&#23458;&#25143;&#33258;&#24049;&#30340;&#37325;&#22797;&#36141;&#20080;&#27169;&#24335;&#25552;&#20379;&#21487;&#33021;&#20877;&#27425;&#36141;&#20080;&#30340;&#21830;&#21697;&#25512;&#33616;&#65292;&#20197;&#25913;&#21892;&#29992;&#25143;&#20307;&#39564;&#21644;&#32593;&#31449;&#21442;&#19982;&#24230;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;BIA&#30740;&#31350;&#20998;&#26512;&#20102;&#23458;&#25143;&#22312;&#21830;&#21697;&#31890;&#24230;&#19978;&#30340;&#20010;&#24615;&#21270;&#34892;&#20026;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22522;&#20110;&#31867;&#21035;&#30340;&#27169;&#22411;&#21487;&#33021;&#26356;&#21512;&#36866;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23618;&#27425;&#21270;PCIC&#27169;&#22411;&#8221;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#23427;&#21253;&#25324;&#20102;&#20010;&#24615;&#21270;&#31867;&#21035;&#27169;&#22411;&#65288;PC&#27169;&#22411;&#65289;&#21644;&#31867;&#21035;&#20869;&#20010;&#24615;&#21270;&#21830;&#21697;&#27169;&#22411;&#65288;IC&#27169;&#22411;&#65289;&#12290;PC&#27169;&#22411;&#29983;&#25104;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#30340;&#31867;&#21035;&#21015;&#34920;&#65292;&#26174;&#31034;&#20102;&#23458;&#25143;&#21487;&#33021;&#20877;&#27425;&#36141;&#20080;&#30340;&#31867;&#21035;&#12290;IC&#27169;&#22411;&#22312;&#31867;&#21035;&#20869;&#23545;&#21830;&#21697;&#36827;&#34892;&#25490;&#21517;&#65292;&#26174;&#31034;&#20102;&#23458;&#25143;&#22312;&#31867;&#21035;&#20869;&#21487;&#33021;&#28040;&#36153;&#30340;&#21830;&#21697;&#12290;&#23618;&#27425;&#21270;PCIC&#27169;&#22411;&#20351;&#29992;&#29983;&#23384;&#27169;&#22411;&#25429;&#25417;&#20135;&#21697;&#30340;&#19968;&#33324;&#28040;&#36153;&#29575;&#12290;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#25429;&#25417;&#20102;&#28040;&#36153;&#36235;&#21183;&#12290;&#20174;&#36825;&#20123;&#27169;&#22411;&#20013;&#25552;&#21462;&#30340;&#29305;&#24449;&#34987;&#29992;&#26469;&#35757;&#32451;&#19968;&#20010;&#22522;&#20110;&#31867;&#21035;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Buy It Again (BIA) recommendations are crucial to retailers to help improve user experience and site engagement by suggesting items that customers are likely to buy again based on their own repeat purchasing patterns. Most existing BIA studies analyze guests personalized behavior at item granularity. A category-based model may be more appropriate in such scenarios. We propose a recommendation system called a hierarchical PCIC model that consists of a personalized category model (PC model) and a personalized item model within categories (IC model). PC model generates a personalized list of categories that customers are likely to purchase again. IC model ranks items within categories that guests are likely to consume within a category. The hierarchical PCIC model captures the general consumption rate of products using survival models. Trends in consumption are captured using time series models. Features derived from these models are used in training a category-grained neural network. We 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#35752;&#35770;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#12289;&#37327;&#21270;&#21644;&#20943;&#23569;&#27969;&#34892;&#20559;&#24046;&#12290;&#23427;&#21516;&#26102;&#25552;&#20379;&#20102;&#35745;&#31639;&#24230;&#37327;&#30340;&#27010;&#36848;&#21644;&#20027;&#35201;&#25216;&#26415;&#26041;&#27861;&#30340;&#22238;&#39038;&#12290;</title><link>http://arxiv.org/abs/2308.01118</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Popularity Bias in Recommender Systems. (arXiv:2308.01118v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01118
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#35752;&#35770;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#12289;&#37327;&#21270;&#21644;&#20943;&#23569;&#27969;&#34892;&#20559;&#24046;&#12290;&#23427;&#21516;&#26102;&#25552;&#20379;&#20102;&#35745;&#31639;&#24230;&#37327;&#30340;&#27010;&#36848;&#21644;&#20027;&#35201;&#25216;&#26415;&#26041;&#27861;&#30340;&#22238;&#39038;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20197;&#20010;&#24615;&#21270;&#30340;&#26041;&#24335;&#24110;&#21161;&#20154;&#20204;&#25214;&#21040;&#30456;&#20851;&#20869;&#23481;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#19968;&#20010;&#20027;&#35201;&#25215;&#35834;&#26159;&#33021;&#22815;&#22686;&#21152;&#30446;&#24405;&#20013;&#36739;&#23569;&#30693;&#21517;&#30340;&#29289;&#21697;&#30340;&#21487;&#35265;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#29616;&#20170;&#30340;&#25512;&#33616;&#31639;&#27861;&#21453;&#32780;&#34920;&#29616;&#20986;&#27969;&#34892;&#20559;&#24046;&#65292;&#21363;&#23427;&#20204;&#22312;&#25512;&#33616;&#20013;&#32463;&#24120;&#20851;&#27880;&#30456;&#24403;&#27969;&#34892;&#30340;&#29289;&#21697;&#12290;&#36825;&#31181;&#20559;&#24046;&#19981;&#20165;&#21487;&#33021;&#23548;&#33268;&#30701;&#26399;&#20869;&#23545;&#28040;&#36153;&#32773;&#21644;&#25552;&#20379;&#32773;&#30340;&#25512;&#33616;&#20215;&#20540;&#26377;&#38480;&#65292;&#32780;&#19988;&#36824;&#21487;&#33021;&#24341;&#36215;&#19981;&#24076;&#26395;&#30340;&#24378;&#21270;&#25928;&#24212;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#27969;&#34892;&#20559;&#24046;&#30340;&#28508;&#22312;&#21407;&#22240;&#65292;&#24182;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#26816;&#27979;&#12289;&#37327;&#21270;&#21644;&#20943;&#23569;&#25512;&#33616;&#31995;&#32479;&#20013;&#27969;&#34892;&#20559;&#24046;&#30340;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#32508;&#36848;&#26082;&#21253;&#25324;&#20102;&#25991;&#29486;&#20013;&#20351;&#29992;&#30340;&#35745;&#31639;&#24230;&#37327;&#30340;&#27010;&#36848;&#65292;&#20063;&#21253;&#25324;&#20102;&#20943;&#23569;&#20559;&#24046;&#30340;&#20027;&#35201;&#25216;&#26415;&#26041;&#27861;&#30340;&#22238;&#39038;&#12290;&#25105;&#20204;&#36824;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems help people find relevant content in a personalized way. One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue. Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations. Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time. In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems. Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias. We furthermore critically discu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#65288;KC&#65289;&#65292;&#36890;&#36807;&#22312;&#20005;&#26684;&#30340;&#20302;&#24310;&#36831;&#32422;&#26463;&#19979;&#25552;&#21319;&#22312;&#32447;FastText&#27169;&#22411;&#30340;&#26597;&#35810;&#20998;&#31867;&#24615;&#33021;&#65292;&#22312;&#20140;&#19996;&#24191;&#21578;&#25628;&#32034;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2308.01098</link><description>&lt;p&gt;
&#22312;&#20140;&#19996;&#24191;&#21578;&#25628;&#32034;&#20013;&#21033;&#29992;&#22810;&#19987;&#23478;&#30693;&#35782;&#33976;&#39311;&#23454;&#29616;&#26356;&#22909;&#30340;&#26597;&#35810;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search. (arXiv:2308.01098v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#65288;KC&#65289;&#65292;&#36890;&#36807;&#22312;&#20005;&#26684;&#30340;&#20302;&#24310;&#36831;&#32422;&#26463;&#19979;&#25552;&#21319;&#22312;&#32447;FastText&#27169;&#22411;&#30340;&#26597;&#35810;&#20998;&#31867;&#24615;&#33021;&#65292;&#22312;&#20140;&#19996;&#24191;&#21578;&#25628;&#32034;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#20998;&#31867;&#20316;&#20026;&#29702;&#35299;&#29992;&#25143;&#24847;&#22270;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22312;&#32447;&#24191;&#21578;&#31995;&#32479;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#20026;&#20102;&#30830;&#20445;&#26356;&#20302;&#30340;&#24310;&#36831;&#65292;&#24120;&#20351;&#29992;&#27973;&#23618;&#27169;&#22411;&#65288;&#22914;FastText&#65289;&#36827;&#34892;&#39640;&#25928;&#30340;&#22312;&#32447;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;FastText&#27169;&#22411;&#30340;&#34920;&#24449;&#33021;&#21147;&#19981;&#36275;&#65292;&#23548;&#33268;&#20998;&#31867;&#24615;&#33021;&#36739;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#19968;&#20123;&#20302;&#39057;&#26597;&#35810;&#21644;&#23614;&#37096;&#31867;&#21035;&#19978;&#12290;&#20351;&#29992;&#26356;&#28145;&#20837;&#19988;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#65288;&#22914;BERT&#65289;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#23558;&#23548;&#33268;&#26356;&#39640;&#30340;&#22312;&#32447;&#25512;&#26029;&#24310;&#36831;&#21644;&#26356;&#26114;&#36149;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#22240;&#27492;&#65292;&#22914;&#20309;&#22312;&#25512;&#26029;&#25928;&#29575;&#21644;&#20998;&#31867;&#24615;&#33021;&#20043;&#38388;&#25240;&#34935;&#26174;&#28982;&#20855;&#26377;&#37325;&#22823;&#23454;&#38469;&#24847;&#20041;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#30693;&#35782;&#33976;&#39311;&#65288;KC&#65289;&#65292;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#65292;&#20197;&#22312;&#20005;&#26684;&#30340;&#20302;&#24310;&#36831;&#32422;&#26463;&#19979;&#25552;&#21319;&#22312;&#32447;FastText&#27169;&#22411;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35757;&#32451;&#19968;&#20010;&#31163;&#32447;&#27169;&#22411;&#65292;&#36890;&#36807;&#33976;&#39311;&#30693;&#35782;&#26469;&#25913;&#21892;&#22312;&#32447;&#27169;&#22411;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Search query classification, as an effective way to understand user intents, is of great importance in real-world online ads systems. To ensure a lower latency, a shallow model (e.g. FastText) is widely used for efficient online inference. However, the representation ability of the FastText model is insufficient, resulting in poor classification performance, especially on some low-frequency queries and tailed categories. Using a deeper and more complex model (e.g. BERT) is an effective solution, but it will cause a higher online inference latency and more expensive computing costs. Thus, how to juggle both inference efficiency and classification performance is obviously of great practical importance. To overcome this challenge, in this paper, we propose knowledge condensation (KC), a simple yet effective knowledge distillation framework to boost the classification performance of the online FastText model under strict low latency constraints. Specifically, we propose to train an offline
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#21464;&#35270;&#35282;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#30456;&#20284;&#24230;&#25628;&#32034;&#30340;&#25928;&#26524;&#65292;&#19981;&#20165;&#35201;&#25552;&#39640;&#25968;&#25454;&#36136;&#37327;&#65292;&#36824;&#35201;&#32508;&#21512;&#24615;&#22320;&#25913;&#36827;&#25628;&#32034;&#26426;&#21046;&#12290;&#20316;&#32773;&#25351;&#20986;&#20102;&#21033;&#29992;&#38544;&#24335;&#30340;&#25968;&#25454;&#32467;&#26500;&#21644;&#20998;&#24067;&#12289;&#35753;&#29992;&#25143;&#21442;&#19982;&#36845;&#20195;&#21453;&#39304;&#24490;&#29615;&#12289;&#36229;&#36234;&#21333;&#19968;&#26597;&#35810;&#21521;&#37327;&#31561;&#26032;&#39062;&#30340;&#30740;&#31350;&#36335;&#24452;&#65292;&#36825;&#20123;&#36335;&#24452;&#22312;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#12289;&#35270;&#39057;&#29255;&#27573;&#26816;&#32034;&#21644;&#25968;&#25454;&#26631;&#27880;&#31561;&#26032;&#20852;&#24212;&#29992;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#23545;&#20110;&#36825;&#20123;&#26032;&#38382;&#39064;&#39046;&#22495;&#25152;&#24102;&#26469;&#30340;&#30740;&#31350;&#25361;&#25112;&#65292;&#20316;&#32773;&#20063;&#20998;&#20139;&#20102;&#21021;&#27493;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2308.00909</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#30456;&#20284;&#24230;&#25628;&#32034;&#65306;&#22312;&#26234;&#33021;&#25968;&#25454;&#20043;&#19978;&#25317;&#25265;&#26356;&#26234;&#33021;&#30340;&#25628;&#32034;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Rethinking Similarity Search: Embracing Smarter Mechanisms over Smarter Data. (arXiv:2308.00909v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00909
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#21464;&#35270;&#35282;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#30456;&#20284;&#24230;&#25628;&#32034;&#30340;&#25928;&#26524;&#65292;&#19981;&#20165;&#35201;&#25552;&#39640;&#25968;&#25454;&#36136;&#37327;&#65292;&#36824;&#35201;&#32508;&#21512;&#24615;&#22320;&#25913;&#36827;&#25628;&#32034;&#26426;&#21046;&#12290;&#20316;&#32773;&#25351;&#20986;&#20102;&#21033;&#29992;&#38544;&#24335;&#30340;&#25968;&#25454;&#32467;&#26500;&#21644;&#20998;&#24067;&#12289;&#35753;&#29992;&#25143;&#21442;&#19982;&#36845;&#20195;&#21453;&#39304;&#24490;&#29615;&#12289;&#36229;&#36234;&#21333;&#19968;&#26597;&#35810;&#21521;&#37327;&#31561;&#26032;&#39062;&#30340;&#30740;&#31350;&#36335;&#24452;&#65292;&#36825;&#20123;&#36335;&#24452;&#22312;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#12289;&#35270;&#39057;&#29255;&#27573;&#26816;&#32034;&#21644;&#25968;&#25454;&#26631;&#27880;&#31561;&#26032;&#20852;&#24212;&#29992;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#23545;&#20110;&#36825;&#20123;&#26032;&#38382;&#39064;&#39046;&#22495;&#25152;&#24102;&#26469;&#30340;&#30740;&#31350;&#25361;&#25112;&#65292;&#20316;&#32773;&#20063;&#20998;&#20139;&#20102;&#21021;&#27493;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#23637;&#26395;&#24615;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#21464;&#35270;&#35282;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#30456;&#20284;&#24230;&#25628;&#32034;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#20027;&#24352;&#19981;&#20165;&#35201;&#25552;&#39640;&#25968;&#25454;&#36136;&#37327;&#65292;&#29305;&#21035;&#26159;&#26426;&#22120;&#23398;&#20064;&#29983;&#25104;&#30340;&#23884;&#20837;&#21521;&#37327;&#65292;&#36824;&#35201;&#32508;&#21512;&#24615;&#22320;&#25913;&#36827;&#25628;&#32034;&#26426;&#21046;&#12290;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;&#19977;&#20010;&#26032;&#39062;&#30340;&#26041;&#21521;&#65292;&#38656;&#35201;&#37325;&#26032;&#23450;&#20041;&#30456;&#20284;&#24230;&#25628;&#32034;&#38382;&#39064;&#65306;&#21033;&#29992;&#38544;&#24335;&#30340;&#25968;&#25454;&#32467;&#26500;&#21644;&#20998;&#24067;&#12289;&#35753;&#29992;&#25143;&#21442;&#19982;&#36845;&#20195;&#21453;&#39304;&#24490;&#29615;&#12289;&#36229;&#36234;&#21333;&#19968;&#26597;&#35810;&#21521;&#37327;&#12290;&#36825;&#20123;&#26032;&#39062;&#30340;&#30740;&#31350;&#36335;&#24452;&#22312;&#26032;&#20852;&#24212;&#29992;&#39046;&#22495;&#65292;&#22914;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#12289;&#35270;&#39057;&#29255;&#27573;&#26816;&#32034;&#21644;&#25968;&#25454;&#26631;&#27880;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#36825;&#20123;&#26032;&#38382;&#39064;&#39046;&#22495;&#25152;&#24102;&#26469;&#30340;&#30740;&#31350;&#25361;&#25112;&#65292;&#24182;&#20998;&#20139;&#20102;&#25105;&#20204;&#21021;&#27493;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this vision paper, we propose a shift in perspective for improving the effectiveness of similarity search. Rather than focusing solely on enhancing the data quality, particularly machine learning-generated embeddings, we advocate for a more comprehensive approach that also enhances the underpinning search mechanisms. We highlight three novel avenues that call for a redefinition of the similarity search problem: exploiting implicit data structures and distributions, engaging users in an iterative feedback loop, and moving beyond a single query vector. These novel pathways have gained relevance in emerging applications such as large-scale language models, video clip retrieval, and data labeling. We discuss the corresponding research challenges posed by these new problem areas and share insights from our preliminary discoveries.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#25143;&#21487;&#25511;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#20107;&#21518;&#21644;&#20107;&#21069;&#35299;&#37322;&#65292;&#29992;&#25143;&#21487;&#20197;&#26681;&#25454;&#36825;&#20123;&#35299;&#37322;&#19982;&#31995;&#32479;&#36827;&#34892;&#20132;&#20114;&#65292;&#20174;&#32780;&#23450;&#21046;&#23545;&#31995;&#32479;&#30340;&#25511;&#21046;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#31995;&#32479;&#22312;&#25552;&#20379;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#21516;&#26102;&#65292;&#25552;&#39640;&#20102;&#29992;&#25143;&#23545;&#31995;&#32479;&#30340;&#28385;&#24847;&#24230;&#21644;&#20449;&#20219;&#12290;</title><link>http://arxiv.org/abs/2308.00894</link><description>&lt;p&gt;
&#29992;&#25143;&#21487;&#25511;&#30340;&#25512;&#33616;&#31995;&#32479;&#65306;&#36890;&#36807;&#20107;&#21518;&#21644;&#20107;&#21069;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
User-Controllable Recommendation via Counterfactual Retrospective and Prospective Explanations. (arXiv:2308.00894v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#25143;&#21487;&#25511;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#20107;&#21518;&#21644;&#20107;&#21069;&#35299;&#37322;&#65292;&#29992;&#25143;&#21487;&#20197;&#26681;&#25454;&#36825;&#20123;&#35299;&#37322;&#19982;&#31995;&#32479;&#36827;&#34892;&#20132;&#20114;&#65292;&#20174;&#32780;&#23450;&#21046;&#23545;&#31995;&#32479;&#30340;&#25511;&#21046;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#31995;&#32479;&#22312;&#25552;&#20379;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#21516;&#26102;&#65292;&#25552;&#39640;&#20102;&#29992;&#25143;&#23545;&#31995;&#32479;&#30340;&#28385;&#24847;&#24230;&#21644;&#20449;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#21033;&#29992;&#29992;&#25143;&#30340;&#21382;&#21490;&#34892;&#20026;&#26469;&#29983;&#25104;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#24448;&#24448;&#32570;&#20047;&#29992;&#25143;&#21487;&#25511;&#24615;&#65292;&#23548;&#33268;&#29992;&#25143;&#28385;&#24847;&#24230;&#21644;&#23545;&#31995;&#32479;&#30340;&#20449;&#20219;&#38477;&#20302;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#26368;&#26032;&#36827;&#23637;&#26469;&#25552;&#39640;&#29992;&#25143;&#21487;&#25511;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#25143;&#21487;&#25511;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#22312;&#32479;&#19968;&#26694;&#26550;&#20013;&#26080;&#32541;&#38598;&#25104;&#20102;&#35299;&#37322;&#24615;&#21644;&#21487;&#25511;&#24615;&#12290;&#36890;&#36807;&#36890;&#36807;&#21453;&#20107;&#23454;&#25512;&#29702;&#25552;&#20379;&#20107;&#21518;&#21644;&#20107;&#21069;&#35299;&#37322;&#65292;&#29992;&#25143;&#21487;&#20197;&#36890;&#36807;&#19982;&#36825;&#20123;&#35299;&#37322;&#36827;&#34892;&#20132;&#20114;&#26469;&#23450;&#21046;&#23545;&#31995;&#32479;&#30340;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#21644;&#35780;&#20272;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20004;&#20010;&#21487;&#25511;&#24615;&#23646;&#24615;&#65306;&#21487;&#25511;&#24615;&#30340;&#22797;&#26434;&#24615;&#21644;&#21487;&#25511;&#24615;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;MovieLens&#21644;Yelp&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern recommender systems utilize users' historical behaviors to generate personalized recommendations. However, these systems often lack user controllability, leading to diminished user satisfaction and trust in the systems. Acknowledging the recent advancements in explainable recommender systems that enhance users' understanding of recommendation mechanisms, we propose leveraging these advancements to improve user controllability. In this paper, we present a user-controllable recommender system that seamlessly integrates explainability and controllability within a unified framework. By providing both retrospective and prospective explanations through counterfactual reasoning, users can customize their control over the system by interacting with these explanations.  Furthermore, we introduce and assess two attributes of controllability in recommendation systems: the complexity of controllability and the accuracy of controllability. Experimental evaluations on MovieLens and Yelp datas
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25193;&#23637;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#21040;&#35780;&#35770;&#39033;&#26816;&#32034;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26469;&#23398;&#20064;BERT&#23884;&#20837;&#65292;&#20197;&#34701;&#21512;&#26597;&#35810;&#21644;&#35780;&#35770;&#24471;&#20998;&#24182;&#36827;&#34892;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2308.00762</link><description>&lt;p&gt;
&#33258;&#30417;&#30563;&#23545;&#27604;BERT&#24494;&#35843;&#29992;&#20110;&#22522;&#20110;&#34701;&#21512;&#30340;&#35780;&#35770;&#39033;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Self-Supervised Contrastive BERT Fine-tuning for Fusion-based Reviewed-Item Retrieval. (arXiv:2308.00762v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25193;&#23637;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#21040;&#35780;&#35770;&#39033;&#26816;&#32034;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26469;&#23398;&#20064;BERT&#23884;&#20837;&#65292;&#20197;&#34701;&#21512;&#26597;&#35810;&#21644;&#35780;&#35770;&#24471;&#20998;&#24182;&#36827;&#34892;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#33258;&#28982;&#35821;&#35328;&#30028;&#38754;&#20351;&#29992;&#25143;&#33021;&#22815;&#34920;&#36798;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#65292;&#29992;&#25143;&#35780;&#35770;&#20869;&#23481;&#20063;&#21576;&#29190;&#28856;&#24335;&#22686;&#38271;&#65292;&#36825;&#21487;&#20197;&#20351;&#29992;&#25143;&#26356;&#22909;&#22320;&#25214;&#21040;&#19982;&#36825;&#20123;&#34920;&#36798;&#24615;&#26597;&#35810;&#21305;&#37197;&#30340;&#39184;&#21381;&#12289;&#20070;&#31821;&#25110;&#30005;&#24433;&#31561;&#29289;&#21697;&#12290;&#34429;&#28982;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;(IR)&#26041;&#27861;&#20026;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#21305;&#37197;&#25552;&#20379;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#20294;&#23427;&#20204;&#23578;&#26410;&#25193;&#23637;&#21040;&#35780;&#20272;&#39033;&#26816;&#32034;(RIR)&#20219;&#21153;&#65292;&#20854;&#20013;&#26597;&#35810;-&#35780;&#35770;&#24471;&#20998;&#24517;&#39035;&#32858;&#21512;(&#25110;&#34701;&#21512;)&#25104;&#29289;&#21697;&#32423;&#24471;&#20998;&#36827;&#34892;&#25490;&#21517;&#12290;&#22312;&#27809;&#26377;&#26631;&#35760;&#30340;RIR&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#33258;&#30417;&#30563;&#26041;&#27861;&#23545;BERT&#23884;&#20837;&#36827;&#34892;&#23545;&#27604;&#23398;&#20064;&#26469;&#23558;&#31070;&#32463;IR&#26041;&#27861;&#25193;&#23637;&#21040;RIR&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#27604;&#23398;&#20064;&#38656;&#35201;&#36873;&#25321;&#27491;&#26679;&#26412;&#21644;&#36127;&#26679;&#26412;&#65292;&#32780;&#25105;&#20204;&#30340;&#39033;-&#35780;&#35770;&#25968;&#25454;&#30340;&#29420;&#29305;&#20108;&#32423;&#32467;&#26500;&#32467;&#21512;&#20803;&#25968;&#25454;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#26679;&#26412;&#36873;&#25321;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
As natural language interfaces enable users to express increasingly complex natural language queries, there is a parallel explosion of user review content that can allow users to better find items such as restaurants, books, or movies that match these expressive queries. While Neural Information Retrieval (IR) methods have provided state-of-the-art results for matching queries to documents, they have not been extended to the task of Reviewed-Item Retrieval (RIR), where query-review scores must be aggregated (or fused) into item-level scores for ranking. In the absence of labeled RIR datasets, we extend Neural IR methodology to RIR by leveraging self-supervised methods for contrastive learning of BERT embeddings for both queries and reviews. Specifically, contrastive learning requires a choice of positive and negative samples, where the unique two-level structure of our item-review data combined with meta-data affords us a rich structure for the selection of these samples. For contrasti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#23548;&#21521;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#21517;&#20026;POnto&#30340;&#39046;&#22495;&#26412;&#20307;&#65292;&#25552;&#20379;&#32467;&#26500;&#21270;&#30340;&#29983;&#24577;&#31995;&#32479;&#27010;&#24565;&#21644;&#20851;&#31995;&#34920;&#31034;&#65292;&#20197;&#22686;&#24378;Polkadot&#29983;&#24577;&#31995;&#32479;&#30340;&#38598;&#25104;&#21644;&#21487;&#20132;&#27969;&#24615;&#12290;&#35813;&#26041;&#27861;&#26377;&#21161;&#20110;&#26356;&#24191;&#27867;&#30340;&#29992;&#25143;&#21442;&#19982;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#20419;&#36827;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#24212;&#29992;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2308.00735</link><description>&lt;p&gt;
&#19968;&#31181;&#30693;&#35782;&#23548;&#21521;&#30340;&#26041;&#27861;&#65292;&#22686;&#24378; Polkadot &#29983;&#24577;&#31995;&#32479;&#20013;&#30340;&#38598;&#25104;&#21644;&#21487;&#20132;&#27969;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Knowledge-Oriented Approach to Enhance Integration and Communicability in the Polkadot Ecosystem. (arXiv:2308.00735v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00735
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#23548;&#21521;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#21517;&#20026;POnto&#30340;&#39046;&#22495;&#26412;&#20307;&#65292;&#25552;&#20379;&#32467;&#26500;&#21270;&#30340;&#29983;&#24577;&#31995;&#32479;&#27010;&#24565;&#21644;&#20851;&#31995;&#34920;&#31034;&#65292;&#20197;&#22686;&#24378;Polkadot&#29983;&#24577;&#31995;&#32479;&#30340;&#38598;&#25104;&#21644;&#21487;&#20132;&#27969;&#24615;&#12290;&#35813;&#26041;&#27861;&#26377;&#21161;&#20110;&#26356;&#24191;&#27867;&#30340;&#29992;&#25143;&#21442;&#19982;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#20419;&#36827;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#24212;&#29992;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Polkadot &#29983;&#24577;&#31995;&#32479;&#26159;&#19968;&#31181;&#20855;&#26377;&#39072;&#35206;&#24615;&#21644;&#39640;&#24230;&#22797;&#26434;&#30340;&#22810;&#38142;&#26550;&#26500;&#65292;&#23545;&#25968;&#25454;&#20998;&#26512;&#21644;&#21487;&#20132;&#27969;&#24615;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#30446;&#21069;&#65292;&#32570;&#20047;&#26631;&#20934;&#21270;&#21644;&#20840;&#38754;&#30340;&#26041;&#27861;&#26469;&#26816;&#32034;&#21644;&#20998;&#26512;&#36328;&#24179;&#34892;&#38142;&#21644;&#24212;&#29992;&#30340;&#25968;&#25454;&#65292;&#20351;&#24471;&#19968;&#33324;&#29992;&#25143;&#21644;&#24320;&#21457;&#32773;&#38590;&#20197;&#19968;&#33268;&#22320;&#35775;&#38382;&#29983;&#24577;&#31995;&#32479;&#25968;&#25454;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#24565;&#26694;&#26550;&#65292;&#21253;&#25324;&#19968;&#20010;&#21517;&#20026; POnto&#65288;Polkadot Ontology&#65289;&#30340;&#39046;&#22495;&#26412;&#20307;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;POnto &#25552;&#20379;&#20102;&#29983;&#24577;&#31995;&#32479;&#27010;&#24565;&#21644;&#20851;&#31995;&#30340;&#32467;&#26500;&#21270;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#23545;&#24179;&#21488;&#30340;&#24418;&#24335;&#21270;&#29702;&#35299;&#12290;&#25552;&#20986;&#30340;&#30693;&#35782;&#23548;&#21521;&#26041;&#27861;&#22686;&#24378;&#20102;&#38598;&#25104;&#21644;&#21487;&#20132;&#27969;&#24615;&#65292;&#20351;&#26356;&#24191;&#27867;&#30340;&#29992;&#25143;&#33021;&#22815;&#21442;&#19982;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#20419;&#36827;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#24212;&#29992;&#30340;&#24320;&#21457;&#12290;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#26041;&#27861;&#26469;&#39564;&#35777;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#26469;&#33258;Polkado&#30340;&#19987;&#23478;&#21453;&#39304;&#21644;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Polkadot ecosystem is a disruptive and highly complex multi-chain architecture that poses challenges in terms of data analysis and communicability. Currently, there is a lack of standardized and holistic approaches to retrieve and analyze data across parachains and applications, making it difficult for general users and developers to access ecosystem data consistently. This paper proposes a conceptual framework that includes a domain ontology called POnto (a Polkadot Ontology) to address these challenges. POnto provides a structured representation of the ecosystem's concepts and relationships, enabling a formal understanding of the platform. The proposed knowledge-oriented approach enhances integration and communicability, enabling a wider range of users to participate in the ecosystem and facilitating the development of AI-based applications. The paper presents a case study methodology to validate the proposed framework, which includes expert feedback and insights from the Polkado
&lt;/p&gt;</description></item><item><title>AsdKB&#26159;&#19968;&#20010;&#29992;&#20110;&#33258;&#38381;&#30151;&#35889;&#31995;&#38556;&#30861;&#26089;&#26399;&#31579;&#36873;&#21644;&#35786;&#26029;&#30340;&#20013;&#25991;&#30693;&#35782;&#24211;&#65292;&#21253;&#21547;&#20102;&#26469;&#33258;&#22810;&#20010;&#26469;&#28304;&#30340;&#30142;&#30149;&#21644;&#35786;&#26029;&#30693;&#35782;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#38382;&#39064;&#22238;&#31572;&#12289;&#36741;&#21161;&#35786;&#26029;&#21644;&#19987;&#23478;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2307.16773</link><description>&lt;p&gt;
AsdKB: &#19968;&#20010;&#29992;&#20110;&#33258;&#38381;&#30151;&#35889;&#31995;&#38556;&#30861;&#26089;&#26399;&#31579;&#36873;&#21644;&#35786;&#26029;&#30340;&#20013;&#25991;&#30693;&#35782;&#24211;
&lt;/p&gt;
&lt;p&gt;
AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder. (arXiv:2307.16773v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16773
&lt;/p&gt;
&lt;p&gt;
AsdKB&#26159;&#19968;&#20010;&#29992;&#20110;&#33258;&#38381;&#30151;&#35889;&#31995;&#38556;&#30861;&#26089;&#26399;&#31579;&#36873;&#21644;&#35786;&#26029;&#30340;&#20013;&#25991;&#30693;&#35782;&#24211;&#65292;&#21253;&#21547;&#20102;&#26469;&#33258;&#22810;&#20010;&#26469;&#28304;&#30340;&#30142;&#30149;&#21644;&#35786;&#26029;&#30693;&#35782;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#38382;&#39064;&#22238;&#31572;&#12289;&#36741;&#21161;&#35786;&#26029;&#21644;&#19987;&#23478;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20415;&#25463;&#22320;&#33719;&#21462;&#26377;&#20851;&#33258;&#38381;&#30151;&#35889;&#31995;&#38556;&#30861;&#30340;&#30693;&#35782;&#24182;&#24110;&#21161;&#20854;&#26089;&#26399;&#31579;&#36873;&#21644;&#35786;&#26029;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;AsdKB&#65292;&#19968;&#20010;&#20851;&#20110;&#33258;&#38381;&#30151;&#35889;&#31995;&#38556;&#30861;&#30340;&#20013;&#25991;&#30693;&#35782;&#24211;&#12290;&#35813;&#30693;&#35782;&#24211;&#24314;&#31435;&#22312;&#22810;&#31181;&#26469;&#28304;&#30340;&#22522;&#30784;&#19978;&#65292;&#21253;&#25324;1&#65289;&#20174;SNOMED CT&#21644;ICD-10&#30340;&#20020;&#24202;&#25551;&#36848;&#20013;&#33719;&#24471;&#30340;&#30142;&#30149;&#30693;&#35782;&#65292;2&#65289;&#20174;DSM-5&#21644;&#31038;&#20250;&#32452;&#32455;&#21644;&#21307;&#23398;&#30740;&#31350;&#26426;&#26500;&#25512;&#33616;&#30340;&#19981;&#21516;&#31579;&#36873;&#24037;&#20855;&#20013;&#33719;&#24471;&#30340;&#35786;&#26029;&#30693;&#35782;&#65292;&#20197;&#21450;3&#65289;&#26469;&#33258;&#32593;&#32476;&#19978;&#19987;&#19994;&#21307;&#29983;&#21644;&#21307;&#38498;&#30340;&#19987;&#19994;&#30693;&#35782;&#12290;AsdKB&#21253;&#21547;&#26412;&#20307;&#30693;&#35782;&#21644;&#20107;&#23454;&#30693;&#35782;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807; https://w3id.org/asdkb/ &#20316;&#20026;&#38142;&#25509;&#25968;&#25454;&#36827;&#34892;&#35775;&#38382;&#12290;AsdKB&#30340;&#28508;&#22312;&#24212;&#29992;&#21253;&#25324;&#38382;&#39064;&#22238;&#31572;&#12289;&#36741;&#21161;&#35786;&#26029;&#21644;&#19987;&#23478;&#25512;&#33616;&#65292;&#24182;&#19988;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#21407;&#22411;&#26469;&#36827;&#34892;&#28436;&#31034;&#65292;&#35813;&#21407;&#22411;&#21487;&#20197;&#36890;&#36807;&#27492;http URL&#36827;&#34892;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
To easily obtain the knowledge about autism spectrum disorder and help its early screening and diagnosis, we create AsdKB, a Chinese knowledge base on autism spectrum disorder. The knowledge base is built on top of various sources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinical descriptions on mental and behavioural disorders, 2) the diagnostic knowledge from DSM-5 and different screening tools recommended by social organizations and medical institutes, and 3) the expert knowledge on professional physicians and hospitals from the Web. AsdKB contains both ontological and factual knowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. The potential applications of AsdKB are question answering, auxiliary diagnosis, and expert recommendation, and we illustrate them with a prototype which can be accessed at this http URL
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38646;-shot&#22330;&#26223;&#19979;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#22823;&#35268;&#27169;&#26816;&#32034;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#26597;&#35810;&#21644;&#26597;&#35810;&#30340;&#20505;&#36873;&#31572;&#26696;&#30340;&#32452;&#21512;&#20316;&#20026;&#25552;&#31034;&#65292;&#20351;LLM&#29983;&#25104;&#26356;&#31934;&#30830;&#30340;&#31572;&#26696;&#12290;&#30001;&#20110;&#33258;&#30417;&#30563;&#26816;&#32034;&#22120;&#22312;&#38646;-shot&#22330;&#26223;&#20013;&#24615;&#33021;&#36739;&#24046;&#65292;&#22240;&#27492;LameR&#20248;&#20110;&#33258;&#30417;&#30563;&#26816;&#32034;&#22120;&#12290;</title><link>http://arxiv.org/abs/2304.14233</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#26816;&#32034;&#20013;&#20855;&#26377;&#36739;&#24378;&#30340;&#34920;&#29616;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Strong Zero-Shot Retriever. (arXiv:2304.14233v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14233
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38646;-shot&#22330;&#26223;&#19979;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#22823;&#35268;&#27169;&#26816;&#32034;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#26597;&#35810;&#21644;&#26597;&#35810;&#30340;&#20505;&#36873;&#31572;&#26696;&#30340;&#32452;&#21512;&#20316;&#20026;&#25552;&#31034;&#65292;&#20351;LLM&#29983;&#25104;&#26356;&#31934;&#30830;&#30340;&#31572;&#26696;&#12290;&#30001;&#20110;&#33258;&#30417;&#30563;&#26816;&#32034;&#22120;&#22312;&#38646;-shot&#22330;&#26223;&#20013;&#24615;&#33021;&#36739;&#24046;&#65292;&#22240;&#27492;LameR&#20248;&#20110;&#33258;&#30417;&#30563;&#26816;&#32034;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#22312;&#38646;-shot&#22330;&#26223;&#19979;&#24212;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#22823;&#35268;&#27169;&#26816;&#32034;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;Language Model&#20316;&#20026;&#26816;&#32034;&#22120;&#65288;LameR&#65289;&#20165;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#32780;&#19981;&#26159;&#20854;&#20182;&#31070;&#32463;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;LLM&#19982;&#26816;&#32034;&#22120;&#30340;&#26292;&#21147;&#32452;&#21512;&#36827;&#34892;&#20998;&#35299;&#65292;&#23558;&#38646;-shot&#26816;&#32034;&#30340;&#24615;&#33021;&#25552;&#39640;&#21040;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#24456;&#24378;&#30340;&#31454;&#20105;&#21147;&#12290;&#26412;&#25991;&#20027;&#35201;&#25552;&#20986;&#36890;&#36807;&#20351;&#29992;&#26597;&#35810;&#21644;&#26597;&#35810;&#30340;&#20505;&#36873;&#31572;&#26696;&#30340;&#32452;&#21512;&#20316;&#20026;&#25552;&#31034;&#65292;&#20351;LLM&#29983;&#25104;&#26356;&#31934;&#30830;&#30340;&#31572;&#26696;&#12290;&#26080;&#35770;&#20505;&#36873;&#31572;&#26696;&#26159;&#21542;&#27491;&#30830;&#65292;&#37117;&#21487;&#20197;&#36890;&#36807;&#27169;&#24335;&#27169;&#20223;&#25110;&#20505;&#36873;&#25688;&#35201;&#26469;&#24110;&#21161;LLM&#20135;&#29983;&#26356;&#31934;&#30830;&#30340;&#31572;&#26696;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#33258;&#30417;&#30563;&#26816;&#32034;&#22120;&#22312;&#38646;-shot&#22330;&#26223;&#20013;&#24615;&#33021;&#36739;&#24046;&#65292;&#22240;&#27492;&#36890;&#36807;&#21033;&#29992;LLM&#23545;&#25991;&#26412;&#27169;&#24335;&#30340;&#24378;&#22823;&#34920;&#29616;&#33021;&#21147;&#65292;LameR&#21487;&#20197;&#20248;&#20110;&#33258;&#30417;&#30563;&#26816;&#32034;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a simple method that applies a large language model (LLM) to large-scale retrieval in zero-shot scenarios. Our method, Language language model as Retriever (LameR) is built upon no other neural models but an LLM, while breaking up brute-force combinations of retrievers with LLMs and lifting the performance of zero-shot retrieval to be very competitive on benchmark datasets. Essentially, we propose to augment a query with its potential answers by prompting LLMs with a composition of the query and the query's in-domain candidates. The candidates, regardless of correct or wrong, are obtained by a vanilla retrieval procedure on the target collection. Such candidates, as a part of prompts, are likely to help LLM generate more precise answers by pattern imitation or candidate summarization. Even if all the candidates are wrong, the prompts at least make LLM aware of in-collection patterns and genres. Moreover, due to the low performance of a self-supervised retriever
&lt;/p&gt;</description></item></channel></rss>