<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35774;&#22791;&#19978;&#30340;&#20010;&#24615;&#21270;&#24377;&#24615;&#23884;&#20837;&#23398;&#20064;&#26694;&#26550;&#65288;PEEL&#65289;&#65292;&#35813;&#26694;&#26550;&#32771;&#34385;&#20102;&#35774;&#22791;&#21644;&#29992;&#25143;&#30340;&#24322;&#36136;&#24615;&#19982;&#21160;&#24577;&#36164;&#28304;&#32422;&#26463;&#65292;&#24182;&#22312;&#19968;&#27425;&#24615;&#29983;&#25104;&#20010;&#24615;&#21270;&#23884;&#20837;&#30340;&#22522;&#30784;&#19978;&#36827;&#34892;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2306.10532</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#24377;&#24615;&#23884;&#20837;&#23398;&#20064;&#29992;&#20110;&#35774;&#22791;&#19978;&#30340;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Personalized Elastic Embedding Learning for On-Device Recommendation. (arXiv:2306.10532v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35774;&#22791;&#19978;&#30340;&#20010;&#24615;&#21270;&#24377;&#24615;&#23884;&#20837;&#23398;&#20064;&#26694;&#26550;&#65288;PEEL&#65289;&#65292;&#35813;&#26694;&#26550;&#32771;&#34385;&#20102;&#35774;&#22791;&#21644;&#29992;&#25143;&#30340;&#24322;&#36136;&#24615;&#19982;&#21160;&#24577;&#36164;&#28304;&#32422;&#26463;&#65292;&#24182;&#22312;&#19968;&#27425;&#24615;&#29983;&#25104;&#20010;&#24615;&#21270;&#23884;&#20837;&#30340;&#22522;&#30784;&#19978;&#36827;&#34892;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#20915;&#38544;&#31169;&#38382;&#39064;&#24182;&#20943;&#23569;&#32593;&#32476;&#24310;&#36831;&#65292;&#36817;&#24180;&#26469;&#19968;&#30452;&#26377;&#23558;&#22312;&#20113;&#31471;&#35757;&#32451;&#30340;&#33219;&#32959;&#30340;&#25512;&#33616;&#27169;&#22411;&#21387;&#32553;&#24182;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#35774;&#22791;&#19978;&#37096;&#32626;&#32039;&#20945;&#30340;&#25512;&#33616;&#22120;&#27169;&#22411;&#20197;&#36827;&#34892;&#23454;&#26102;&#25512;&#33616;&#30340;&#36235;&#21183;&#12290;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#36890;&#24120;&#24573;&#35270;&#20102;&#35774;&#22791;&#24322;&#36136;&#24615;&#21644;&#29992;&#25143;&#24322;&#36136;&#24615;&#12290;&#23427;&#20204;&#35201;&#20040;&#35201;&#27714;&#25152;&#26377;&#35774;&#22791;&#20849;&#20139;&#30456;&#21516;&#30340;&#21387;&#32553;&#27169;&#22411;&#65292;&#35201;&#20040;&#35201;&#27714;&#20855;&#26377;&#30456;&#21516;&#36164;&#28304;&#39044;&#31639;&#30340;&#35774;&#22791;&#20849;&#20139;&#30456;&#21516;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#26159;&#20855;&#26377;&#30456;&#21516;&#35774;&#22791;&#30340;&#29992;&#25143;&#21487;&#33021;&#20063;&#20855;&#26377;&#19981;&#21516;&#30340;&#20559;&#22909;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#20551;&#35774;&#35774;&#22791;&#19978;&#30340;&#25512;&#33616;&#22120;&#21487;&#29992;&#36164;&#28304;&#65288;&#22914;&#20869;&#23384;&#65289;&#26159;&#24658;&#23450;&#30340;&#65292;&#36825;&#19982;&#29616;&#23454;&#24773;&#20917;&#19981;&#31526;&#12290;&#37492;&#20110;&#35774;&#22791;&#21644;&#29992;&#25143;&#30340;&#24322;&#36136;&#24615;&#20197;&#21450;&#21160;&#24577;&#36164;&#28304;&#32422;&#26463;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35774;&#22791;&#19978;&#30340;&#20010;&#24615;&#21270;&#24377;&#24615;&#23884;&#20837;&#23398;&#20064;&#26694;&#26550;&#65288;PEEL&#65289;&#65292;&#35813;&#26694;&#26550;&#20197;&#19968;&#27425;&#24615;&#26041;&#24335;&#20026;&#20855;&#26377;&#19981;&#21516;&#20869;&#23384;&#39044;&#31639;&#30340;&#35774;&#22791;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
To address privacy concerns and reduce network latency, there has been a recent trend of compressing cumbersome recommendation models trained on the cloud and deploying compact recommender models to resource-limited devices for real-time recommendation. Existing solutions generally overlook device heterogeneity and user heterogeneity. They either require all devices to share the same compressed model or the devices with the same resource budget to share the same model. However, even users with the same devices may have different preferences. In addition, they assume the available resources (e.g., memory) for the recommender on a device are constant, which is not reflective of reality. In light of device and user heterogeneities as well as dynamic resource constraints, this paper proposes a Personalized Elastic Embedding Learning framework (PEEL) for on-device recommendation, which generates personalized embeddings for devices with various memory budgets in once-for-all manner, efficien
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21160;&#24577;&#35821;&#26009;&#24211;&#19978;&#30340;&#29983;&#25104;&#26816;&#32034;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38745;&#24577;&#35774;&#32622;&#19979;&#65292;&#29983;&#25104;&#26816;&#32034;&#25928;&#26524;&#20248;&#20110;&#21452;&#32534;&#30721;&#22120;&#65292;&#20294;&#22312;&#21160;&#24577;&#35774;&#32622;&#19979;&#24773;&#20917;&#30456;&#21453;&#12290;&#36890;&#36807;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;DynamicGR&#22312;&#26032;&#30340;&#35821;&#26009;&#24211;&#19978;&#23637;&#29616;&#20986;&#20102;&#24847;&#22806;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.18952</link><description>&lt;p&gt;
&#22312;&#21160;&#24577;&#35821;&#26009;&#24211;&#19978;&#25345;&#32493;&#26356;&#26032;&#29983;&#25104;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Continually Updating Generative Retrieval on Dynamic Corpora. (arXiv:2305.18952v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21160;&#24577;&#35821;&#26009;&#24211;&#19978;&#30340;&#29983;&#25104;&#26816;&#32034;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38745;&#24577;&#35774;&#32622;&#19979;&#65292;&#29983;&#25104;&#26816;&#32034;&#25928;&#26524;&#20248;&#20110;&#21452;&#32534;&#30721;&#22120;&#65292;&#20294;&#22312;&#21160;&#24577;&#35774;&#32622;&#19979;&#24773;&#20917;&#30456;&#21453;&#12290;&#36890;&#36807;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;DynamicGR&#22312;&#26032;&#30340;&#35821;&#26009;&#24211;&#19978;&#23637;&#29616;&#20986;&#20102;&#24847;&#22806;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#20851;&#20110;&#20449;&#24687;&#26816;&#32034;(IR)&#30340;&#22823;&#22810;&#25968;&#30740;&#31350;&#20551;&#35774;&#35821;&#26009;&#24211;&#26159;&#38745;&#24577;&#30340;&#65292;&#32780;&#23454;&#38469;&#19990;&#30028;&#20013;&#30340;&#25991;&#26723;&#26159;&#19981;&#26029;&#26356;&#26032;&#30340;&#12290;&#26412;&#25991;&#23558;&#30693;&#35782;&#30340;&#21160;&#24577;&#24615;&#24341;&#20837;&#26816;&#32034;&#31995;&#32479;&#20013;&#65292;&#23558;&#26816;&#32034;&#35270;&#20026;&#21160;&#24577;&#30340;&#30693;&#35782;&#24211;&#65292;&#26356;&#31526;&#21512;&#30495;&#23454;&#29615;&#22659;&#12290;&#25105;&#20204;&#23545;&#21452;&#32534;&#30721;&#22120;&#21644;&#29983;&#25104;&#26816;&#32034;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#65292;&#21033;&#29992;StreamingQA&#22522;&#20934;&#27979;&#35797;&#29992;&#20110;&#26102;&#24577;&#30693;&#35782;&#26356;&#26032;&#12290;&#25105;&#20204;&#30340;&#21021;&#27493;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#38745;&#24577;&#35774;&#32622;&#19979;&#65292;&#29983;&#25104;&#26816;&#32034;&#20248;&#20110;&#21452;&#32534;&#30721;&#22120;&#65292;&#20294;&#22312;&#21160;&#24577;&#35774;&#32622;&#19979;&#24773;&#20917;&#30456;&#21453;&#12290;&#28982;&#32780;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#24403;&#25105;&#20204;&#21033;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#22686;&#24378;&#29983;&#25104;&#26816;&#32034;&#23545;&#26032;&#35821;&#26009;&#24211;&#30340;&#36866;&#24212;&#24615;&#26102;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;Dynamic Generative Retrieval (DynamicGR)&#23637;&#29616;&#20986;&#24847;&#22806;&#30340;&#21457;&#29616;&#12290;&#23427;&#33021;&#22815;&#22312;&#20854;&#20869;&#37096;&#32034;&#24341;&#20013;&#39640;&#25928;&#21387;&#32553;&#26032;&#30340;&#30693;&#35782;&#65292;
&lt;/p&gt;
&lt;p&gt;
The majority of prior work on information retrieval (IR) assumes that the corpus is static, whereas in the real world, the documents are continually updated. In this paper, we incorporate often overlooked dynamic nature of knowledge into the retrieval systems. Our work treats retrieval not as static archives but as dynamic knowledge bases better aligned with real-world environments. We conduct a comprehensive evaluation of dual encoders and generative retrieval, utilizing the StreamingQA benchmark designed for the temporal knowledge updates. Our initial results show that while generative retrieval outperforms dual encoders in static settings, the opposite is true in dynamic settings. Surprisingly, however, when we utilize a parameter-efficient pre-training method to enhance adaptability of generative retrieval to new corpora, our resulting model, Dynamic Generative Retrieval (DynamicGR), exhibits unexpected findings. It (1) efficiently compresses new knowledge in their internal index, 
&lt;/p&gt;</description></item></channel></rss>