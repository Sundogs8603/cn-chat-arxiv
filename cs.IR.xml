<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#26032;&#24037;&#20855;&#65292;&#25506;&#35752;&#20102;&#31038;&#20250;&#24433;&#21709;&#26426;&#21046;&#19982;&#33322;&#31354;&#20844;&#21496;&#36873;&#25321;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#23545;&#29992;&#25143;&#35780;&#35770;&#30340;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#21345;&#22612;&#23612;&#20122;&#26426;&#22330;&#33322;&#31354;&#29983;&#24577;&#31995;&#32479;&#20013;&#33322;&#31354;&#20844;&#21496;&#30340;&#37325;&#35201;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.15541</link><description>&lt;p&gt;
&#35299;&#25918;&#29992;&#25143;&#35780;&#35770;&#30340;&#21147;&#37327;&#65306;&#25506;&#32034;&#24847;&#22823;&#21033;&#21345;&#22612;&#23612;&#20122;&#26426;&#22330;&#30340;&#33322;&#31354;&#20844;&#21496;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Unleashing the Power of User Reviews: Exploring Airline Choices at Catania Airport, Italy. (arXiv:2306.15541v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#26032;&#24037;&#20855;&#65292;&#25506;&#35752;&#20102;&#31038;&#20250;&#24433;&#21709;&#26426;&#21046;&#19982;&#33322;&#31354;&#20844;&#21496;&#36873;&#25321;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#23545;&#29992;&#25143;&#35780;&#35770;&#30340;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#21345;&#22612;&#23612;&#20122;&#26426;&#22330;&#33322;&#31354;&#29983;&#24577;&#31995;&#32479;&#20013;&#33322;&#31354;&#20844;&#21496;&#30340;&#37325;&#35201;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#26032;&#24037;&#20855;&#65292;&#25506;&#35752;&#31038;&#20250;&#24433;&#21709;&#26426;&#21046;&#19982;&#33322;&#31354;&#20844;&#21496;&#36873;&#25321;&#20043;&#38388;&#30340;&#21487;&#33021;&#20851;&#31995;&#65292;&#20197;&#36827;&#19968;&#27493;&#20102;&#35299;&#24433;&#21709;&#28040;&#36153;&#32773;&#22312;&#33322;&#31354;&#39046;&#22495;&#20915;&#31574;&#30340;&#22240;&#32032;&#12290;&#25105;&#20204;&#36873;&#25321;&#20174;&#30693;&#21517;&#24179;&#21488;Trustpilot&#12289;Google&#21644;Twitter&#20013;&#25552;&#21462;&#29992;&#25143;&#35780;&#35770;&#12290;&#36890;&#36807;&#32467;&#21512;&#32593;&#32476;&#29228;&#21462;&#25216;&#26415;&#65292;&#25105;&#20204;&#33021;&#22815;&#25910;&#38598;&#21040;&#21253;&#21547;&#21508;&#31181;&#29992;&#25143;&#24847;&#35265;&#12289;&#21453;&#39304;&#21644;&#35780;&#20998;&#30340;&#20840;&#38754;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20248;&#21270;&#20102;BERT&#27169;&#22411;&#65292;&#20197;&#20415;&#26356;&#22909;&#22320;&#32858;&#28966;&#33322;&#31354;&#20844;&#21496;&#35780;&#35770;&#20013;&#30340;&#26377;&#35265;&#22320;&#30340;&#24773;&#24863;&#12290;&#36890;&#36807;&#20998;&#26512;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#19981;&#21516;&#33322;&#31354;&#20844;&#21496;&#24179;&#22343;&#36127;&#38754;&#24773;&#24863;&#24471;&#20998;&#30340;&#26377;&#36259;&#36235;&#21183;&#65292;&#36825;&#20351;&#25105;&#20204;&#26356;&#28145;&#20837;&#22320;&#20102;&#35299;&#20102;&#33322;&#31354;&#20844;&#21496;&#20043;&#38388;&#30340;&#21160;&#24577;&#65292;&#24110;&#21161;&#25105;&#20204;&#35782;&#21035;&#21345;&#22612;&#23612;&#20122;&#26426;&#22330;&#33322;&#31354;&#29983;&#24577;&#31995;&#32479;&#20013;&#30340;&#20851;&#38190;&#21512;&#20316;&#20249;&#20276;&#12289;&#28909;&#38376;&#33322;&#32447;&#21644;&#25198;&#28436;&#26680;&#24515;&#35282;&#33394;&#30340;&#33322;&#31354;&#20844;&#21496;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study aims to investigate the possible relationship between the mechanisms of social influence and the choice of airline, through the use of new tools, with the aim of understanding whether they can contribute to a better understanding of the factors influencing the decisions of consumers in the aviation sector. We have chosen to extract user reviews from well-known platforms: Trustpilot, Google, and Twitter. By combining web scraping techniques, we have been able to collect a comprehensive dataset comprising a wide range of user opinions, feedback, and ratings. We then refined the BERT model to focus on insightful sentiment in the context of airline reviews. Through our analysis, we observed an intriguing trend of average negative sentiment scores across various airlines, giving us deeper insight into the dynamics between airlines and helping us identify key partnerships, popular routes, and airlines that play a central role in the aeronautical ecosystem of Catania airport during
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#29983;&#25104;&#24335;&#26816;&#32034;&#21644;&#32463;&#20856;&#30340;&#23398;&#20064;&#25490;&#24207;&#33539;&#20363;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27573;&#33853;&#25490;&#24207;&#25439;&#22833;&#26469;&#35757;&#32451;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#30452;&#25509;&#20248;&#21270;&#33258;&#22238;&#24402;&#27169;&#22411;&#26397;&#30528;&#26368;&#20248;&#35299;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2306.15222</link><description>&lt;p&gt;
&#23398;&#20064;&#22312;&#29983;&#25104;&#24335;&#26816;&#32034;&#20013;&#36827;&#34892;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Learning to Rank in Generative Retrieval. (arXiv:2306.15222v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15222
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#29983;&#25104;&#24335;&#26816;&#32034;&#21644;&#32463;&#20856;&#30340;&#23398;&#20064;&#25490;&#24207;&#33539;&#20363;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27573;&#33853;&#25490;&#24207;&#25439;&#22833;&#26469;&#35757;&#32451;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#30452;&#25509;&#20248;&#21270;&#33258;&#22238;&#24402;&#27169;&#22411;&#26397;&#30528;&#26368;&#20248;&#35299;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#26816;&#32034;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#25991;&#26412;&#26816;&#32034;&#33539;&#20363;&#65292;&#23427;&#23558;&#30456;&#20851;&#27573;&#33853;&#30340;&#26631;&#35782;&#31526;&#23383;&#31526;&#20018;&#29983;&#25104;&#20026;&#26816;&#32034;&#30446;&#26631;&#12290;&#36825;&#31181;&#33539;&#20363;&#21033;&#29992;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#20195;&#34920;&#20102;&#19982;&#20256;&#32479;&#30340;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#26377;&#25152;&#19981;&#21516;&#30340;&#26032;&#33539;&#20363;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20854;&#24555;&#36895;&#21457;&#23637;&#65292;&#24403;&#21069;&#30340;&#29983;&#25104;&#24335;&#26816;&#32034;&#26041;&#27861;&#20173;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#23427;&#20204;&#36890;&#24120;&#20381;&#36182;&#21551;&#21457;&#24335;&#20989;&#25968;&#23558;&#39044;&#27979;&#30340;&#26631;&#35782;&#31526;&#36716;&#25442;&#20026;&#27573;&#33853;&#25490;&#24207;&#21015;&#34920;&#65292;&#36825;&#22312;&#29983;&#25104;&#24335;&#26816;&#32034;&#30340;&#23398;&#20064;&#30446;&#26631;&#19982;&#26399;&#26395;&#30340;&#27573;&#33853;&#25490;&#24207;&#30446;&#26631;&#20043;&#38388;&#20135;&#29983;&#20102;&#24046;&#36317;&#12290;&#27492;&#22806;&#65292;&#25991;&#26412;&#29983;&#25104;&#30340;&#22266;&#26377;&#26333;&#20809;&#20559;&#24046;&#38382;&#39064;&#22312;&#29983;&#25104;&#24335;&#26816;&#32034;&#20013;&#20173;&#28982;&#23384;&#22312;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;LTRGR&#65292;&#23427;&#23558;&#29983;&#25104;&#24335;&#26816;&#32034;&#19982;&#32463;&#20856;&#30340;&#23398;&#20064;&#25490;&#24207;&#33539;&#20363;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#27573;&#33853;&#25490;&#24207;&#25439;&#22833;&#35757;&#32451;&#19968;&#20010;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#25439;&#22833;&#30452;&#25509;&#20248;&#21270;&#33258;&#22238;&#24402;&#27169;&#22411;&#26397;&#30528;&#26368;&#20248;&#35299;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative retrieval is a promising new paradigm in text retrieval that generates identifier strings of relevant passages as the retrieval target. This paradigm leverages powerful generation models and represents a new paradigm distinct from traditional learning-to-rank methods. However, despite its rapid development, current generative retrieval methods are still limited. They typically rely on a heuristic function to transform predicted identifiers into a passage rank list, which creates a gap between the learning objective of generative retrieval and the desired passage ranking target. Moreover, the inherent exposure bias problem of text generation also persists in generative retrieval. To address these issues, we propose a novel framework, called LTRGR, that combines generative retrieval with the classical learning-to-rank paradigm. Our approach involves training an autoregressive model using a passage rank loss, which directly optimizes the autoregressive model toward the optimal 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;Adaptive IPS (AIPS)&#65292;&#38024;&#23545;&#25490;&#21517;&#31574;&#30053;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#36890;&#36807;&#32771;&#34385;&#29992;&#25143;&#34892;&#20026;&#30340;&#22810;&#26679;&#24615;&#21644;&#19978;&#19979;&#25991;&#30340;&#21464;&#21270;&#65292;&#26377;&#25928;&#38477;&#20302;&#20102;&#20272;&#35745;&#20013;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.15098</link><description>&lt;p&gt;
&#19981;&#21516;&#29992;&#25143;&#34892;&#20026;&#19979;&#30340;&#25490;&#21517;&#31574;&#30053;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation of Ranking Policies under Diverse User Behavior. (arXiv:2306.15098v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;Adaptive IPS (AIPS)&#65292;&#38024;&#23545;&#25490;&#21517;&#31574;&#30053;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#36890;&#36807;&#32771;&#34385;&#29992;&#25143;&#34892;&#20026;&#30340;&#22810;&#26679;&#24615;&#21644;&#19978;&#19979;&#25991;&#30340;&#21464;&#21270;&#65292;&#26377;&#25928;&#38477;&#20302;&#20102;&#20272;&#35745;&#20013;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24179;&#21488;&#19978;&#21040;&#22788;&#37117;&#26159;&#25490;&#21517;&#30028;&#38754;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#20351;&#29992;&#35760;&#24405;&#25968;&#25454;&#36827;&#34892;&#25490;&#21517;&#31574;&#30053;&#30340;&#20934;&#30830;&#24615;&#33021;&#35780;&#20272;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#36234;&#26469;&#36234;&#24863;&#20852;&#36259;&#12290;OPE&#30340;&#19968;&#31181;&#20107;&#23454;&#19978;&#30340;&#26041;&#27861;&#26159;&#20498;&#25968;&#20542;&#21521;&#24471;&#20998;&#27861;&#65288;IPS&#65289;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#26080;&#20559;&#19988;&#19968;&#33268;&#30340;&#20540;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22312;&#25490;&#21517;&#35774;&#32622;&#20013;&#65292;&#30001;&#20110;&#22312;&#22823;&#22411;&#34892;&#20026;&#31354;&#38388;&#19979;&#20855;&#26377;&#36739;&#39640;&#30340;&#26041;&#24046;&#65292;&#23427;&#21464;&#24471;&#26497;&#20854;&#19981;&#20934;&#30830;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#20551;&#35774;&#29992;&#25143;&#34892;&#20026;&#26159;&#29420;&#31435;&#30340;&#25110;&#32423;&#32852;&#30340;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#20123;IPS&#30340;&#25490;&#21517;&#29256;&#26412;&#12290;&#23613;&#31649;&#36825;&#20123;&#20272;&#35745;&#22120;&#22312;&#20943;&#23569;&#26041;&#24046;&#26041;&#38754;&#26377;&#19968;&#23450;&#30340;&#25928;&#26524;&#65292;&#20294;&#25152;&#26377;&#29616;&#26377;&#30340;&#20272;&#35745;&#22120;&#37117;&#23545;&#27599;&#20010;&#29992;&#25143;&#24212;&#29992;&#20102;&#19968;&#20010;&#21333;&#19968;&#30340;&#36890;&#29992;&#20551;&#35774;&#65292;&#23548;&#33268;&#36807;&#24230;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;&#22240;&#27492;&#65292;&#36825;&#39033;&#24037;&#20316;&#25506;&#32034;&#20102;&#26356;&#36890;&#29992;&#30340;&#20844;&#24335;&#65292;&#20854;&#20013;&#29992;&#25143;&#34892;&#20026;&#26159;&#22810;&#26679;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#19978;&#19979;&#25991;&#30340;&#19981;&#21516;&#32780;&#21464;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20986;&#30001;&#27492;&#20135;&#29983;&#30340;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#33258;&#36866;&#24212;IPS&#65288;AIPS&#65289;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#36827;&#34892;&#31163;&#31574;&#30053;&#35780;&#20272;&#21644;&#25490;&#21517;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ranking interfaces are everywhere in online platforms. There is thus an ever growing interest in their Off-Policy Evaluation (OPE), aiming towards an accurate performance evaluation of ranking policies using logged data. A de-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides an unbiased and consistent value estimate. However, it becomes extremely inaccurate in the ranking setup due to its high variance under large action spaces. To deal with this problem, previous studies assume either independent or cascade user behavior, resulting in some ranking versions of IPS. While these estimators are somewhat effective in reducing the variance, all existing estimators apply a single universal assumption to every user, causing excessive bias and variance. Therefore, this work explores a far more general formulation where user behavior is diverse and can vary depending on the user context. We show that the resulting estimator, which we call Adaptive IPS (AIPS), can be unb
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#39640;&#20998;&#36776;&#29575;&#27169;&#26495;&#21305;&#37197;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#37327;&#37327;&#21270;&#21644;&#28388;&#27874;&#26469;&#20943;&#23569;&#35745;&#31639;&#37327;&#21644;&#32771;&#34385;&#21464;&#24418;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.15010</link><description>&lt;p&gt;
&#39640;&#20998;&#36776;&#29575;&#27169;&#26495;&#21305;&#37197;&#20013;&#30340;&#39640;&#25928;&#21521;&#37327;&#37327;&#21270;&#26368;&#36817;&#37051;&#22330;
&lt;/p&gt;
&lt;p&gt;
Efficient High-Resolution Template Matching with Vector Quantized Nearest Neighbour Fields. (arXiv:2306.15010v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#39640;&#20998;&#36776;&#29575;&#27169;&#26495;&#21305;&#37197;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#37327;&#37327;&#21270;&#21644;&#28388;&#27874;&#26469;&#20943;&#23569;&#35745;&#31639;&#37327;&#21644;&#32771;&#34385;&#21464;&#24418;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#26495;&#21305;&#37197;&#26159;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#30340;&#22522;&#30784;&#38382;&#39064;&#65292;&#24182;&#22312;&#29289;&#20307;&#26816;&#27979;&#12289;&#22270;&#20687;&#37197;&#20934;&#21644;&#29289;&#20307;&#36319;&#36394;&#31561;&#39046;&#22495;&#26377;&#24212;&#29992;&#12290;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26159;&#20381;&#36182;&#20110;&#26368;&#36817;&#37051;&#65288;NN&#65289;&#21305;&#37197;&#65292;&#22312;&#35813;&#26041;&#27861;&#20013;&#65292;&#23558;&#26597;&#35810;&#29305;&#24449;&#31354;&#38388;&#36716;&#25442;&#20026;NN&#31354;&#38388;&#65292;&#20854;&#20013;&#27599;&#20010;&#26597;&#35810;&#20687;&#32032;&#29992;&#27169;&#26495;&#20687;&#32032;&#20013;&#30340;&#26368;&#36817;&#37051;&#34920;&#31034;&#12290;NN&#21305;&#37197;&#22312;&#36974;&#25377;&#12289;&#22806;&#35266;&#21464;&#21270;&#12289;&#20809;&#29031;&#21464;&#21270;&#21644;&#38750;&#21018;&#24615;&#21464;&#25442;&#31561;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;NN&#21305;&#37197;&#22312;&#39640;&#20998;&#36776;&#29575;&#25968;&#25454;&#21644;&#39640;&#32500;&#29305;&#24449;&#26041;&#38754;&#30340;&#25193;&#23637;&#24615;&#36739;&#24046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;NN&#30340;&#27169;&#26495;&#21305;&#37197;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26377;&#25928;&#22320;&#20943;&#23569;&#20102;NN&#35745;&#31639;&#37327;&#65292;&#24182;&#22312;NN&#22330;&#20013;&#24341;&#20837;&#28388;&#27874;&#20197;&#32771;&#34385;&#21464;&#24418;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#21521;&#37327;&#37327;&#21270;&#23558;&#27169;&#26495;&#34920;&#31034;&#20026;k&#20010;&#29305;&#24449;&#65292;&#28982;&#21518;&#36890;&#36807;&#28388;&#27874;&#27604;&#36739;&#27169;&#26495;&#21644;&#26597;&#35810;&#22312;k&#20010;&#29305;&#24449;&#19978;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Template matching is a fundamental problem in computer vision and has applications in various fields, such as object detection, image registration, and object tracking. The current state-of-the-art methods rely on nearest-neighbour (NN) matching in which the query feature space is converted to NN space by representing each query pixel with its NN in the template pixels. The NN-based methods have been shown to perform better in occlusions, changes in appearance, illumination variations, and non-rigid transformations. However, NN matching scales poorly with high-resolution data and high feature dimensions. In this work, we present an NN-based template-matching method which efficiently reduces the NN computations and introduces filtering in the NN fields to consider deformations. A vector quantization step first represents the template with $k$ features, then filtering compares the template and query distributions over the $k$ features. We show that state-of-the-art performance was achiev
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;ChatGPT&#36827;&#34892;&#20135;&#21697;&#20449;&#24687;&#25552;&#21462;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#23545;&#22823;&#37327;&#35757;&#32451;&#25968;&#25454;&#21644;&#27867;&#21270;&#21040;&#26410;&#30693;&#23646;&#24615;&#21644;&#23646;&#24615;&#20540;&#30340;&#22256;&#38590;&#65292;&#20026;&#30005;&#23376;&#21830;&#21153;&#24212;&#29992;&#25552;&#20379;&#20102;&#21487;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2306.14921</link><description>&lt;p&gt;
&#20351;&#29992;ChatGPT&#36827;&#34892;&#20135;&#21697;&#20449;&#24687;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Product Information Extraction using ChatGPT. (arXiv:2306.14921v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14921
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;ChatGPT&#36827;&#34892;&#20135;&#21697;&#20449;&#24687;&#25552;&#21462;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#23545;&#22823;&#37327;&#35757;&#32451;&#25968;&#25454;&#21644;&#27867;&#21270;&#21040;&#26410;&#30693;&#23646;&#24615;&#21644;&#23646;&#24615;&#20540;&#30340;&#22256;&#38590;&#65292;&#20026;&#30005;&#23376;&#21830;&#21153;&#24212;&#29992;&#25552;&#20379;&#20102;&#21487;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#23646;&#24615;/&#20540;&#23545;&#30340;&#24418;&#24335;&#21576;&#29616;&#30340;&#32467;&#26500;&#21270;&#20135;&#21697;&#25968;&#25454;&#26159;&#35768;&#22810;&#30005;&#23376;&#21830;&#21153;&#24212;&#29992;&#30340;&#22522;&#30784;&#65292;&#20363;&#22914;&#20998;&#38754;&#20135;&#21697;&#25628;&#32034;&#12289;&#20135;&#21697;&#27604;&#36739;&#21644;&#20135;&#21697;&#25512;&#33616;&#12290;&#20135;&#21697;&#25253;&#20215;&#36890;&#24120;&#21482;&#21253;&#21547;&#20197;&#26631;&#39064;&#25110;&#33258;&#30001;&#25991;&#26412;&#24418;&#24335;&#21576;&#29616;&#30340;&#20135;&#21697;&#23646;&#24615;&#30340;&#25991;&#26412;&#25551;&#36848;&#12290;&#22240;&#27492;&#65292;&#20174;&#25991;&#26412;&#20135;&#21697;&#25551;&#36848;&#20013;&#25552;&#21462;&#23646;&#24615;/&#20540;&#23545;&#23545;&#20110;&#30005;&#23376;&#21830;&#21153;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#12290;&#20026;&#20102;&#34920;&#29616;&#20986;&#33394;&#65292;&#26368;&#20808;&#36827;&#30340;&#20135;&#21697;&#20449;&#24687;&#25552;&#21462;&#26041;&#27861;&#38656;&#35201;&#22823;&#37327;&#30340;&#20219;&#21153;&#29305;&#23450;&#35757;&#32451;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#36824;&#38590;&#20197;&#25512;&#24191;&#21040;&#35757;&#32451;&#25968;&#25454;&#20013;&#27809;&#26377;&#21253;&#21547;&#30340;&#20998;&#24067;&#20043;&#22806;&#30340;&#23646;&#24615;&#21644;&#23646;&#24615;&#20540;&#12290;&#30001;&#20110;&#22312;&#22823;&#37327;&#25991;&#26412;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#20197;&#21450;&#30001;&#20110;&#27169;&#22411;&#35268;&#27169;&#23548;&#33268;&#30340;&#26032;&#20852;&#25928;&#26524;&#65292;&#20687;ChatGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#35299;&#20915;&#36825;&#20004;&#20010;&#32570;&#28857;&#30340;&#28508;&#21147;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;ChatGPT&#22312;&#25552;&#21462;&#23646;&#24615;/&#20540;&#23545;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structured product data in the form of attribute/value pairs is the foundation of many e-commerce applications such as faceted product search, product comparison, and product recommendation. Product offers often only contain textual descriptions of the product attributes in the form of titles or free text. Hence, extracting attribute/value pairs from textual product descriptions is an essential enabler for e-commerce applications. In order to excel, state-of-the-art product information extraction methods require large quantities of task-specific training data. The methods also struggle with generalizing to out-of-distribution attributes and attribute values that were not a part of the training data. Due to being pre-trained on huge amounts of text as well as due to emergent effects resulting from the model size, Large Language Models like ChatGPT have the potential to address both of these shortcomings. This paper explores the potential of ChatGPT for extracting attribute/value pairs f
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;FPGA&#19978;&#30340;&#21521;&#37327;&#25628;&#32034;&#26694;&#26550;FANNS&#65292;&#23454;&#29616;&#20102;&#30828;&#20214;&#21644;&#31639;&#27861;&#30340;&#20849;&#21516;&#35774;&#35745;&#65292;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#38656;&#27714;&#21644;&#30828;&#20214;&#39044;&#31639;&#29983;&#25104;&#30456;&#24212;&#30340;&#21152;&#36895;&#22120;&#12290;&#19982;FPGA&#21644;CPU&#22522;&#20934;&#30456;&#27604;&#65292;FANNS&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#21152;&#36895;&#65292;&#24182;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11182</link><description>&lt;p&gt;
&#20026;&#21521;&#37327;&#25628;&#32034;&#36827;&#34892;&#30828;&#20214;&#21644;&#31639;&#27861;&#30340;&#20849;&#21516;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Co-design Hardware and Algorithm for Vector Search. (arXiv:2306.11182v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11182
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;FPGA&#19978;&#30340;&#21521;&#37327;&#25628;&#32034;&#26694;&#26550;FANNS&#65292;&#23454;&#29616;&#20102;&#30828;&#20214;&#21644;&#31639;&#27861;&#30340;&#20849;&#21516;&#35774;&#35745;&#65292;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#38656;&#27714;&#21644;&#30828;&#20214;&#39044;&#31639;&#29983;&#25104;&#30456;&#24212;&#30340;&#21152;&#36895;&#22120;&#12290;&#19982;FPGA&#21644;CPU&#22522;&#20934;&#30456;&#27604;&#65292;FANNS&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#21152;&#36895;&#65292;&#24182;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21521;&#37327;&#25628;&#32034;&#24050;&#25104;&#20026;&#22823;&#35268;&#27169;&#20449;&#24687;&#26816;&#32034;&#21644;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#22522;&#30784;&#65292;&#20687;Google&#21644;Bing&#36825;&#26679;&#30340;&#25628;&#32034;&#24341;&#25806;&#36890;&#36807;&#35780;&#20272;&#32534;&#30721;&#26597;&#35810;&#25991;&#26412;&#21644;&#32593;&#32476;&#25991;&#26723;&#20043;&#38388;&#30340;&#21521;&#37327;&#30456;&#20284;&#24230;&#65292;&#27599;&#31186;&#22788;&#29702;&#25968;&#19975;&#20010;&#26597;&#35810;&#65292;&#22312;&#25317;&#26377;PB&#32423;&#25991;&#26723;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#12290;&#38543;&#30528;&#23545;&#21521;&#37327;&#25628;&#32034;&#31995;&#32479;&#24615;&#33021;&#30340;&#38656;&#27714;&#28608;&#22686;&#65292;&#22312;&#25705;&#23572;&#23450;&#24459;&#26102;&#20195;&#21518;&#65292;&#21152;&#36895;&#30828;&#20214;&#25104;&#20026;&#20102;&#19968;&#20010;&#26377;&#21069;&#26223;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#22312;FPGA&#19978;&#30340;&#31471;&#21040;&#31471;&#21487;&#25193;&#23637;&#21521;&#37327;&#25628;&#32034;&#26694;&#26550;FANNS&#12290;&#32473;&#23450;&#29992;&#25143;&#25552;&#20379;&#30340;&#23545;&#25968;&#25454;&#38598;&#30340;&#21484;&#22238;&#35201;&#27714;&#21644;&#30828;&#20214;&#36164;&#28304;&#39044;&#31639;&#65292;FANNS&#33258;&#21160;&#36827;&#34892;&#30828;&#20214;&#21644;&#31639;&#27861;&#30340;&#20849;&#21516;&#35774;&#35745;&#65292;&#38543;&#21518;&#29983;&#25104;&#30456;&#24212;&#30340;&#21152;&#36895;&#22120;&#12290;&#35813;&#26694;&#26550;&#36824;&#36890;&#36807;&#22312;&#21152;&#36895;&#22120;&#20013;&#24341;&#20837;&#30828;&#20214;TCP/IP&#22534;&#26632;&#26469;&#25903;&#25345;&#35268;&#27169;&#25193;&#23637;&#12290;&#19982;FPGA&#21644;CPU&#22522;&#20934;&#30456;&#27604;&#65292;FANNS&#20998;&#21035;&#23454;&#29616;&#20102;23.0&#20493;&#21644;37.2&#20493;&#30340;&#21152;&#36895;&#65292;&#24182;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vector search has emerged as the foundation for large-scale information retrieval and machine learning systems, with search engines like Google and Bing processing tens of thousands of queries per second on petabyte-scale document datasets by evaluating vector similarities between encoded query texts and web documents. As performance demands for vector search systems surge, accelerated hardware offers a promising solution in the post-Moore's Law era. We introduce \textit{FANNS}, an end-to-end and scalable vector search framework on FPGAs. Given a user-provided recall requirement on a dataset and a hardware resource budget, \textit{FANNS} automatically co-designs hardware and algorithm, subsequently generating the corresponding accelerator. The framework also supports scale-out by incorporating a hardware TCP/IP stack in the accelerator. \textit{FANNS} attains up to 23.0$\times$ and 37.2$\times$ speedup compared to FPGA and CPU baselines, respectively, and demonstrates superior scalabil
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26053;&#28216;&#26223;&#28857;&#25512;&#33616;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#21160;&#35821;&#20041;&#21457;&#25496;&#30446;&#26631;&#26223;&#28857;&#30340;&#30456;&#37051;&#23454;&#20307;&#65292;&#26681;&#25454;&#26053;&#23458;&#30340;&#21916;&#22909;&#36873;&#25321;&#65292;&#39044;&#27979;&#31867;&#20284;&#26223;&#28857;&#30340;&#27010;&#29575;&#65292;&#23454;&#39564;&#20013;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10946</link><description>&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26053;&#28216;&#26223;&#28857;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network. (arXiv:2306.10946v1 [cs.IR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26053;&#28216;&#26223;&#28857;&#25512;&#33616;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#21160;&#35821;&#20041;&#21457;&#25496;&#30446;&#26631;&#26223;&#28857;&#30340;&#30456;&#37051;&#23454;&#20307;&#65292;&#26681;&#25454;&#26053;&#23458;&#30340;&#21916;&#22909;&#36873;&#25321;&#65292;&#39044;&#27979;&#31867;&#20284;&#26223;&#28857;&#30340;&#27010;&#29575;&#65292;&#23454;&#39564;&#20013;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#25512;&#33616;&#31639;&#27861;&#22312;&#30456;&#23545;&#25104;&#29087;&#38454;&#27573;&#65292;&#20294;&#22312;&#29305;&#23450;&#39046;&#22495;&#30340;&#25512;&#33616;&#20173;&#23384;&#22312;&#38382;&#39064;&#12290;&#20363;&#22914;&#22312;&#26053;&#28216;&#39046;&#22495;&#65292;&#36873;&#25321;&#36866;&#21512;&#30340;&#26053;&#28216;&#26223;&#28857;&#23646;&#24615;&#27969;&#31243;&#20316;&#20026;&#25512;&#33616;&#22522;&#30784;&#36739;&#20026;&#22797;&#26434;&#12290;&#26412;&#25991;&#25552;&#20986;&#25913;&#36827;&#30340;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#27169;&#22411;(Att-KGCN)&#65292;&#33258;&#21160;&#35821;&#20041;&#22320;&#21457;&#25496;&#30446;&#26631;&#26223;&#28857;&#30340;&#30456;&#37051;&#23454;&#20307;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#23618;&#23558;&#30456;&#23545;&#30456;&#20284;&#30340;&#20301;&#32622;&#36827;&#34892;&#32858;&#21512;&#65292;&#24182;&#36890;&#36807;&#25512;&#29702;&#26053;&#23458;&#21916;&#22909;&#36873;&#25321;&#65292;&#39044;&#27979;&#31867;&#20284;&#26223;&#28857;&#30340;&#27010;&#29575;&#20316;&#20026;&#25512;&#33616;&#31995;&#32479;&#12290;&#23454;&#39564;&#20013;&#65292;&#37319;&#29992;&#32034;&#31185;&#29305;&#25289;&#23707;-&#20063;&#38376;&#30340;&#26053;&#28216;&#25968;&#25454;&#65292;&#35777;&#26126;&#20102;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#22312;&#26053;&#28216;&#39046;&#22495;&#30340;&#26223;&#28857;&#25512;&#33616;&#25928;&#26524;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recommendation algorithm based on knowledge graphs is at a relatively mature stage. However, there are still some problems in the recommendation of specific areas. For example, in the tourism field, selecting suitable tourist attraction attributes process is complicated as the recommendation basis for tourist attractions. In this paper, we propose the improved Attention Knowledge Graph Convolution Network model, named (Att-KGCN), which automatically discovers the neighboring entities of the target scenic spot semantically. The attention layer aggregates relatively similar locations and represents them with an adjacent vector. Then, according to the tourist's preferred choices, the model predicts the probability of similar spots as a recommendation system. A knowledge graph dataset of tourist attractions used based on tourism data on Socotra Island-Yemen. Through experiments, it is verified that the Attention Knowledge Graph Convolution Network has a good effect on the recommendatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38416;&#36848;&#20102;&#23545;&#20110;&#35782;&#21035;&#21644;&#25511;&#21046;&#26263;&#32593;&#38750;&#27861;&#27963;&#21160;&#30340;&#36843;&#20999;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26816;&#32034; .onion &#25193;&#23637;&#21517;&#30340;&#32593;&#31449;&#19978;&#30456;&#20851;&#22270;&#29255;&#30340;&#25628;&#32034;&#24341;&#25806;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20013;&#36798;&#21040;&#20102;94% &#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.07980</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#26263;&#32593;&#27963;&#21160;&#20998;&#31867;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Dark web activity classification using deep learning. (arXiv:2306.07980v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07980
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38416;&#36848;&#20102;&#23545;&#20110;&#35782;&#21035;&#21644;&#25511;&#21046;&#26263;&#32593;&#38750;&#27861;&#27963;&#21160;&#30340;&#36843;&#20999;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26816;&#32034; .onion &#25193;&#23637;&#21517;&#30340;&#32593;&#31449;&#19978;&#30456;&#20851;&#22270;&#29255;&#30340;&#25628;&#32034;&#24341;&#25806;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20013;&#36798;&#21040;&#20102;94% &#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24378;&#35843;&#20102;&#35782;&#21035;&#21644;&#25511;&#21046;&#26263;&#32593;&#38750;&#27861;&#27963;&#21160;&#30340;&#36843;&#20999;&#38656;&#35201;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#36890;&#36807; .onion &#25193;&#23637;&#21517;&#30340;&#32593;&#31449;&#26816;&#32034;&#38750;&#27861;&#27963;&#21160;&#30456;&#20851;&#22270;&#29255;&#30340;&#26032;&#22411;&#25628;&#32034;&#24341;&#25806;&#12290;&#22312;&#21517;&#20026; darkoob &#30340;&#20840;&#38754;&#25968;&#25454;&#38598;&#30340;&#27979;&#35797;&#20013;&#65292;&#35813;&#26041;&#27861;&#36798;&#21040;&#20102;94% &#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The present article highlights the pressing need for identifying and controlling illicit activities on the dark web. While only 4% of the information available on the internet is accessible through regular search engines, the deep web contains a plethora of information, including personal data and online accounts, that is not indexed by search engines. The dark web, which constitutes a subset of the deep web, is a notorious breeding ground for various illegal activities, such as drug trafficking, weapon sales, and money laundering. Against this backdrop, the authors propose a novel search engine that leverages deep learning to identify and extract relevant images related to illicit activities on the dark web. Specifically, the system can detect the titles of illegal activities on the dark web and retrieve pertinent images from websites with a .onion extension. The authors have collected a comprehensive dataset named darkoob and the proposed method achieves an accuracy of 94% on the tes
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2306.05817</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22914;&#20309;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#21463;&#30410;&#65306;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Can Recommender Systems Benefit from Large Language Models: A Survey. (arXiv:2306.05817v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#21305;&#37197;&#20114;&#32852;&#32593;&#24212;&#29992;&#31243;&#24207;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#23637;&#29616;&#20986;&#20102;&#24778;&#20154;&#30340;&#26032;&#20852;&#33021;&#21147;&#65288;&#20363;&#22914;&#25351;&#20196;&#36319;&#36394;&#12289;&#25512;&#29702;&#65289;&#65292;&#20174;&#32780;&#20026;&#23558;LLM&#35843;&#25972;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#20197;&#25552;&#39640;&#24615;&#33021;&#21644;&#25913;&#21892;&#29992;&#25143;&#20307;&#39564;&#30340;&#30740;&#31350;&#26041;&#21521;&#24102;&#26469;&#20102;&#24076;&#26395;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#24212;&#29992;&#23548;&#21521;&#30340;&#35282;&#24230;&#23545;&#27492;&#30740;&#31350;&#26041;&#21521;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;&#25105;&#20204;&#39318;&#20808;&#20174;&#20004;&#20010;&#27491;&#20132;&#30340;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#23545;&#20110;&#8220;&#22312;&#21738;&#37324;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;LLM&#22312;&#25512;&#33616;&#27969;&#31243;&#30340;&#19981;&#21516;&#38454;&#27573;&#20013;&#21487;&#33021;&#21457;&#25381;&#30340;&#20316;&#29992;&#65292;&#21363;&#29305;&#24449;&#24037;&#31243;&#12289;&#29305;&#24449;&#32534;&#30721;&#22120;&#12289;&#35780;&#20998;/&#25490;&#21517;&#20989;&#25968;&#21644;&#27969;&#31243;&#25511;&#21046;&#22120;&#12290;&#23545;&#20110;&#8220;&#22914;&#20309;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#31574;&#30053;&#65292;&#20174;&#32780;&#24471;&#20986;&#20004;&#20010;&#32454;&#31890;&#24230;&#30340;&#20998;&#31867;&#26631;&#20934;&#65292;&#21363;&#26159;&#21542;&#35843;&#25972;LLM&#21644;&#26159;&#21542;&#23558;LLM&#20316;&#20026;&#29420;&#31435;&#27169;&#22411;&#25110;&#28151;&#21512;&#27169;&#22411;&#32452;&#20214;&#20351;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#23558;LLM&#35843;&#25972;&#21040;RS&#20013;&#30340;&#19968;&#20123;&#25361;&#25112;&#21644;&#28508;&#22312;&#26041;&#21521;&#65292;&#21253;&#25324;&#19982;&#29616;&#26377;&#31995;&#32479;&#30340;&#38598;&#25104;&#12289;&#29992;&#25143;&#21453;&#39304;&#12289;&#35780;&#20272;&#24230;&#37327;&#21644;&#30693;&#35782;&#33976;&#39311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RS) play important roles to match users' information needs for Internet applications. In natural language processing (NLP) domains, large language model (LLM) has shown astonishing emergent abilities (e.g., instruction following, reasoning), thus giving rise to the promising research direction of adapting LLM to RS for performance enhancements and user experience improvements. In this paper, we conduct a comprehensive survey on this research direction from an application-oriented view. We first summarize existing research works from two orthogonal perspectives: where and how to adapt LLM to RS. For the "WHERE" question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, and pipeline controller. For the "HOW" question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLMs or not, a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22797;&#21046;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#32593;&#32476;&#65288;CRNNet&#65289;&#30340;&#26032;&#22411;&#31895;&#21040;&#32454;&#30340;ICD&#36335;&#24452;&#29983;&#25104;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;RNN&#29983;&#25104;&#39034;&#24207;&#36755;&#20986;&#24182;&#32467;&#21512;&#22797;&#21046;&#27169;&#22359;&#65292;&#26377;&#25928;&#35782;&#21035;&#22797;&#26434;&#30142;&#30149;&#65292;&#30456;&#27604;&#20110;&#26368;&#20808;&#36827;&#30340;&#21644;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#22312;&#39044;&#27979;&#20013;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#22797;&#26434;&#30142;&#30149;&#27604;&#29575;&#65288;57.30%&#65289;&#12290;</title><link>http://arxiv.org/abs/2305.13250</link><description>&lt;p&gt;
&#22797;&#21046;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Copy Recurrent Neural Network Structure Network. (arXiv:2305.13250v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22797;&#21046;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#32593;&#32476;&#65288;CRNNet&#65289;&#30340;&#26032;&#22411;&#31895;&#21040;&#32454;&#30340;ICD&#36335;&#24452;&#29983;&#25104;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;RNN&#29983;&#25104;&#39034;&#24207;&#36755;&#20986;&#24182;&#32467;&#21512;&#22797;&#21046;&#27169;&#22359;&#65292;&#26377;&#25928;&#35782;&#21035;&#22797;&#26434;&#30142;&#30149;&#65292;&#30456;&#27604;&#20110;&#26368;&#20808;&#36827;&#30340;&#21644;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#22312;&#39044;&#27979;&#20013;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#22797;&#26434;&#30142;&#30149;&#27604;&#29575;&#65288;57.30%&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#32534;&#30721;&#28041;&#21450;&#23558;EHR&#33258;&#21160;&#20998;&#31867;&#20026;&#35786;&#26029;&#20195;&#30721;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#30740;&#31350;&#23558;&#20854;&#35270;&#20026;&#22810;&#26631;&#31614;&#20998;&#31867;&#20219;&#21153;&#65292;&#29983;&#25104;&#27599;&#20010;&#20195;&#30721;&#30340;&#27010;&#29575;&#24182;&#36873;&#25321;&#36229;&#36807;&#19968;&#23450;&#38408;&#20540;&#30340;&#26631;&#31614;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#24120;&#24120;&#24573;&#35270;&#20102;&#35782;&#21035;&#22797;&#26434;&#30142;&#30149;&#30340;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#30340;&#37325;&#28857;&#26159;&#22312;EHR&#20013;&#26816;&#27979;&#24182;&#21457;&#30142;&#30149;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22797;&#21046;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#32593;&#32476;&#65288;CRNNet&#65289;&#30340;&#26032;&#22411;&#31895;&#21040;&#32454;&#30340;ICD&#36335;&#24452;&#29983;&#25104;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#36335;&#24452;&#29983;&#25104;&#22120;&#65288;PG&#65289;&#21644;&#36335;&#24452;&#37492;&#21035;&#22120;&#65288;PD&#65289;&#36827;&#34892;EHR&#32534;&#30721;&#12290;&#36890;&#36807;&#20351;&#29992;RNN&#29983;&#25104;&#39034;&#24207;&#36755;&#20986;&#24182;&#32467;&#21512;&#22797;&#21046;&#27169;&#22359;&#65292;&#25105;&#20204;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#22797;&#26434;&#30142;&#30149;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#39044;&#27979;&#20013;&#23454;&#29616;&#20102;57.30&#65285;&#30340;&#22797;&#26434;&#30142;&#30149;&#27604;&#29575;&#65292;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#21644;&#20808;&#21069;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#28040;&#34701;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#22797;&#21046;&#26426;&#21046;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Electronic Health Record (EHR) coding involves automatically classifying EHRs into diagnostic codes. While most previous research treats this as a multi-label classification task, generating probabilities for each code and selecting those above a certain threshold as labels, these approaches often overlook the challenge of identifying complex diseases. In this study, our focus is on detecting complication diseases within EHRs.  We propose a novel coarse-to-fine ICD path generation framework called the Copy Recurrent Neural Network Structure Network (CRNNet), which employs a Path Generator (PG) and a Path Discriminator (PD) for EHR coding. By using RNNs to generate sequential outputs and incorporating a copy module, we efficiently identify complication diseases. Our method achieves a 57.30\% ratio of complex diseases in predictions, outperforming state-of-the-art and previous approaches.  Additionally, through an ablation study, we demonstrate that the copy mechanism plays a crucial rol
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;HDR&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#21382;&#21490;&#20419;&#38144;&#25968;&#25454;&#65292;&#26469;&#25429;&#25417;&#20419;&#38144;&#36716;&#21270;&#27169;&#24335;&#65292;&#36798;&#21040;&#26356;&#22909;&#22320;&#36866;&#24212;&#20419;&#38144;&#27169;&#24335;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.12837</link><description>&lt;p&gt;
&#25429;&#25417;&#20419;&#38144;&#26399;&#38388;&#30340;&#36716;&#21270;&#29575;&#27874;&#21160;&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;&#21382;&#21490;&#25968;&#25454;&#20877;&#21033;&#29992;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel Historical Data Reuse Approach. (arXiv:2305.12837v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12837
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;HDR&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#21382;&#21490;&#20419;&#38144;&#25968;&#25454;&#65292;&#26469;&#25429;&#25417;&#20419;&#38144;&#36716;&#21270;&#27169;&#24335;&#65292;&#36798;&#21040;&#26356;&#22909;&#22320;&#36866;&#24212;&#20419;&#38144;&#27169;&#24335;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#21270;&#29575;&#65288;CVR&#65289;&#39044;&#27979;&#26159;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#30340;&#26680;&#24515;&#32452;&#20214;&#20043;&#19968;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#20197;&#33719;&#24471;&#20934;&#30830;&#21644;&#19968;&#33268;&#30340;CVR&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#21363;&#20351;&#35757;&#32451;&#33391;&#22909;&#30340;CVR&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;&#20419;&#38144;&#26399;&#38388;&#20063;&#32463;&#24120;&#34920;&#29616;&#20986;&#27425;&#20248;&#30340;&#24615;&#33021;&#12290;&#36825;&#20027;&#35201;&#24402;&#22240;&#20110;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#38382;&#39064;&#65292;&#20854;&#20013;&#20256;&#32479;&#26041;&#27861;&#19981;&#20877;&#36215;&#20316;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23547;&#27714;&#24320;&#21457;&#26367;&#20195;&#24314;&#27169;&#25216;&#26415;&#29992;&#20110;CVR&#39044;&#27979;&#12290;&#35266;&#23519;&#21040;&#19981;&#21516;&#20419;&#38144;&#20043;&#38388;&#23384;&#22312;&#30456;&#20284;&#30340;&#36141;&#20080;&#27169;&#24335;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#37325;&#29992;&#21382;&#21490;&#20419;&#38144;&#25968;&#25454;&#20197;&#25429;&#25417;&#20419;&#38144;&#36716;&#21270;&#27169;&#24335;&#30340;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21382;&#21490;&#25968;&#25454;&#20877;&#21033;&#29992;&#65288;HDR&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#39318;&#20808;&#26816;&#32034;&#21382;&#21490;&#19978;&#30456;&#20284;&#30340;&#20419;&#38144;&#25968;&#25454;&#65292;&#28982;&#21518;&#20351;&#29992;&#33719;&#21462;&#30340;&#25968;&#25454;&#24494;&#35843;CVR&#39044;&#27979;&#27169;&#22411;&#20197;&#26356;&#22909;&#22320;&#36866;&#24212;&#20419;&#38144;&#27169;&#24335;&#12290;HDR&#30001;&#19977;&#20010;&#32452;&#20214;&#32452;&#25104;&#65306;&#33258;&#21160;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Conversion rate (CVR) prediction is one of the core components in online recommender systems, and various approaches have been proposed to obtain accurate and well-calibrated CVR estimation. However, we observe that a well-trained CVR prediction model often performs sub-optimally during sales promotions. This can be largely ascribed to the problem of the data distribution shift, in which the conventional methods no longer work. To this end, we seek to develop alternative modeling techniques for CVR prediction. Observing similar purchase patterns across different promotions, we propose reusing the historical promotion data to capture the promotional conversion patterns. Herein, we propose a novel \textbf{H}istorical \textbf{D}ata \textbf{R}euse (\textbf{HDR}) approach that first retrieves historically similar promotion data and then fine-tunes the CVR prediction model with the acquired data for better adaptation to the promotion mode. HDR consists of three components: an automated data 
&lt;/p&gt;</description></item><item><title>TWIN&#26159;&#19968;&#31181;&#35299;&#20915;&#29616;&#26377;CTR&#39044;&#27979;&#31995;&#32479;&#20013;&#20852;&#36259;&#19981;&#19968;&#33268;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#20004;&#20010;&#38454;&#27573;&#30340;&#20852;&#36259;&#32593;&#32476;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.02352</link><description>&lt;p&gt;
TWIN: &#20004;&#38454;&#27573;&#20852;&#36259;&#32593;&#32476;&#22312;&#24555;&#25163;&#20013;&#36827;&#34892;&#32456;&#36523;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#19982;CTR&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in CTR Prediction at Kuaishou. (arXiv:2302.02352v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02352
&lt;/p&gt;
&lt;p&gt;
TWIN&#26159;&#19968;&#31181;&#35299;&#20915;&#29616;&#26377;CTR&#39044;&#27979;&#31995;&#32479;&#20013;&#20852;&#36259;&#19981;&#19968;&#33268;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#20004;&#20010;&#38454;&#27573;&#30340;&#20852;&#36259;&#32593;&#32476;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32456;&#36523;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#65292;&#21363;&#20174;&#20016;&#23500;&#30340;&#21382;&#21490;&#34892;&#20026;&#20013;&#25552;&#21462;&#29992;&#25143;&#30340;&#38544;&#34255;&#20852;&#36259;&#65292;&#22312;&#29616;&#20195;CTR&#39044;&#27979;&#31995;&#32479;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#20256;&#32479;&#31639;&#27861;&#20027;&#35201;&#36981;&#24490;&#20004;&#20010;&#32423;&#32852;&#38454;&#27573;&#65306;&#19968;&#20010;&#31616;&#21333;&#30340;&#36890;&#29992;&#25628;&#32034;&#21333;&#20803;&#65288;GSU&#65289;&#29992;&#20110;&#24555;&#36895;&#25628;&#32034;&#25968;&#20197;&#19975;&#35745;&#30340;&#38271;&#26399;&#34892;&#20026;&#65292;&#19968;&#20010;&#31934;&#30830;&#25628;&#32034;&#21333;&#20803;&#65288;ESU&#65289;&#29992;&#20110;&#23545;&#26469;&#33258;GSU&#30340;&#23569;&#25968;&#20505;&#36873;&#20154;&#36827;&#34892;&#26377;&#38024;&#23545;&#24615;&#30340;&#20851;&#27880;&#12290;&#34429;&#28982;&#39640;&#25928;&#65292;&#20294;&#29616;&#26377;&#31639;&#27861;&#22823;&#22810;&#23384;&#22312;&#19968;&#20010;&#20851;&#38190;&#38480;&#21046;&#65306;GSU&#21644;ESU&#20043;&#38388;&#30340;&#30446;&#26631;-&#34892;&#20026;&#30456;&#20851;&#25351;&#26631;&#19981;&#19968;&#33268;&#12290;&#22240;&#27492;&#65292;&#20182;&#20204;&#30340;GSU&#36890;&#24120;&#20250;&#38169;&#36807;&#39640;&#30456;&#20851;&#30340;&#34892;&#20026;&#65292;&#20294;&#21448;&#20250;&#26816;&#32034;&#21040;&#34987;ESU&#35748;&#20026;&#19981;&#30456;&#20851;&#30340;&#34892;&#20026;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26080;&#35770;ESU&#22914;&#20309;&#20998;&#37197;&#27880;&#24847;&#21147;&#65292;&#23427;&#30340;&#20851;&#27880;&#28857;&#22823;&#22810;&#19982;&#30495;&#23454;&#29992;&#25143;&#20852;&#36259;&#20559;&#31163;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#25972;&#20307;CTR&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#31181;&#19981;&#19968;&#33268;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;&#20004;&#38454;&#27573;&#20852;&#36259;&#32593;&#32476;&#65288;TWIN&#65289;&#8221;&#65292;
&lt;/p&gt;
&lt;p&gt;
Life-long user behavior modeling, i.e., extracting a user's hidden interests from rich historical behaviors in months or even years, plays a central role in modern CTR prediction systems. Conventional algorithms mostly follow two cascading stages: a simple General Search Unit (GSU) for fast and coarse search over tens of thousands of long-term behaviors and an Exact Search Unit (ESU) for effective Target Attention (TA) over the small number of finalists from GSU. Although efficient, existing algorithms mostly suffer from a crucial limitation: the \textit{inconsistent} target-behavior relevance metrics between GSU and ESU. As a result, their GSU usually misses highly relevant behaviors but retrieves ones considered irrelevant by ESU. In such case, the TA in ESU, no matter how attention is allocated, mostly deviates from the real user interests and thus degrades the overall CTR prediction accuracy. To address such inconsistency, we propose \textbf{TWo-stage Interest Network (TWIN)}, wher
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#20010;&#24615;&#21270;&#20808;&#39564;&#20449;&#24687;&#30340;&#21487;&#25554;&#25300;&#32593;&#32476;&#65288;PEPNet&#65289;&#65292;&#29992;&#20110;&#22810;&#39046;&#22495;&#21644;&#22810;&#20219;&#21153;&#25512;&#33616;&#12290;&#35813;&#32593;&#32476;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#24213;&#23618;&#23884;&#20837;&#21644;&#39030;&#23618;DNN&#38544;&#34255;&#21333;&#20803;&#65292;&#20197;&#20934;&#30830;&#25429;&#25417;&#29992;&#25143;&#22312;&#22810;&#20010;&#22330;&#26223;&#20013;&#30340;&#20852;&#36259;&#12290;</title><link>http://arxiv.org/abs/2302.01115</link><description>&lt;p&gt;
PEPNet&#65306;&#34701;&#20837;&#20010;&#24615;&#21270;&#20808;&#39564;&#20449;&#24687;&#30340;&#21442;&#25968;&#21644;&#23884;&#20837;&#24335;&#20010;&#24615;&#21270;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
PEPNet: Parameter and Embedding Personalized Network for Infusing with Personalized Prior Information. (arXiv:2302.01115v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#20010;&#24615;&#21270;&#20808;&#39564;&#20449;&#24687;&#30340;&#21487;&#25554;&#25300;&#32593;&#32476;&#65288;PEPNet&#65289;&#65292;&#29992;&#20110;&#22810;&#39046;&#22495;&#21644;&#22810;&#20219;&#21153;&#25512;&#33616;&#12290;&#35813;&#32593;&#32476;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#24213;&#23618;&#23884;&#20837;&#21644;&#39030;&#23618;DNN&#38544;&#34255;&#21333;&#20803;&#65292;&#20197;&#20934;&#30830;&#25429;&#25417;&#29992;&#25143;&#22312;&#22810;&#20010;&#22330;&#26223;&#20013;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22312;&#32447;&#26381;&#21153;&#22914;&#32593;&#36141;&#21644;&#35270;&#39057;&#35266;&#30475;&#32593;&#31449;&#20013;&#20869;&#23481;&#39029;&#38754;&#21644;&#20132;&#20114;&#25353;&#38062;&#30340;&#22686;&#21152;&#65292;&#24037;&#19994;&#35268;&#27169;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#22810;&#39046;&#22495;&#21644;&#22810;&#20219;&#21153;&#25512;&#33616;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#22810;&#20219;&#21153;&#21644;&#22810;&#39046;&#22495;&#25512;&#33616;&#30340;&#26680;&#24515;&#26159;&#22312;&#32473;&#23450;&#22810;&#20010;&#29992;&#25143;&#34892;&#20026;&#30340;&#22810;&#20010;&#22330;&#26223;&#20013;&#20934;&#30830;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25554;&#25300;&#30340;&#8220;&#21442;&#25968;&#21644;&#23884;&#20837;&#24335;&#20010;&#24615;&#21270;&#32593;&#32476;&#65288;PEPNet&#65289;&#8221;&#65292;&#29992;&#20110;&#22810;&#39046;&#22495;&#21644;&#22810;&#20219;&#21153;&#25512;&#33616;&#12290;PEPNet&#23558;&#20010;&#24615;&#21270;&#20808;&#39564;&#20449;&#24687;&#20316;&#20026;&#36755;&#20837;&#65292;&#24182;&#36890;&#36807;&#38376;&#26426;&#21046;&#21160;&#24577;&#35843;&#25972;&#24213;&#23618;&#23884;&#20837;&#21644;&#39030;&#23618;DNN&#38544;&#34255;&#21333;&#20803;&#12290;&#23884;&#20837;&#20010;&#24615;&#21270;&#32593;&#32476;&#65288;EPNet&#65289;&#23545;&#23884;&#20837;&#25191;&#34892;&#20010;&#24615;&#21270;&#36873;&#25321;&#65292;&#20197;&#34701;&#21512;&#19981;&#21516;&#29992;&#25143;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#19981;&#21516;&#37325;&#35201;&#24615;&#30340;&#29305;&#24449;&#12290;&#21442;&#25968;&#20010;&#24615;&#21270;&#32593;&#32476;&#65288;PPNet&#65289;&#23545;&#21442;&#25968;&#25191;&#34892;&#20010;&#24615;&#21270;&#20462;&#25913;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the increase of content pages and interactive buttons in online services such as online-shopping and video-watching websites, industrial-scale recommender systems face challenges in multi-domain and multi-task recommendations. The core of multi-task and multi-domain recommendation is to accurately capture user interests in multiple scenarios given multiple user behaviors. In this paper, we propose a plug-and-play \textit{\textbf{P}arameter and \textbf{E}mbedding \textbf{P}ersonalized \textbf{Net}work (\textbf{PEPNet})} for multi-domain and multi-task recommendation. PEPNet takes personalized prior information as input and dynamically scales the bottom-level Embedding and top-level DNN hidden units through gate mechanisms. \textit{Embedding Personalized Network (EPNet)} performs personalized selection on Embedding to fuse features with different importance for different users in multiple domains. \textit{Parameter Personalized Network (PPNet)} executes personalized modification on 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#25345;&#32493;&#32456;&#36523;&#23398;&#20064;&#30340;&#31070;&#32463;&#20027;&#39064;&#24314;&#27169;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#25968;&#25454;&#31232;&#30095;&#24615;&#65292;&#24182;&#36890;&#36807;&#30693;&#35782;&#30340;&#25345;&#32493;&#31215;&#32047;&#21644;&#36716;&#31227;&#26469;&#25552;&#39640;&#20027;&#39064;&#24314;&#27169;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2006.10909</link><description>&lt;p&gt;
&#20855;&#26377;&#25345;&#32493;&#32456;&#36523;&#23398;&#20064;&#30340;&#31070;&#32463;&#20027;&#39064;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Neural Topic Modeling with Continual Lifelong Learning. (arXiv:2006.10909v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.10909
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#25345;&#32493;&#32456;&#36523;&#23398;&#20064;&#30340;&#31070;&#32463;&#20027;&#39064;&#24314;&#27169;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#25968;&#25454;&#31232;&#30095;&#24615;&#65292;&#24182;&#36890;&#36807;&#30693;&#35782;&#30340;&#25345;&#32493;&#31215;&#32047;&#21644;&#36716;&#31227;&#26469;&#25552;&#39640;&#20027;&#39064;&#24314;&#27169;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32456;&#36523;&#23398;&#20064;&#21560;&#24341;&#20102;&#20154;&#20204;&#23545;&#24314;&#31435;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#20851;&#27880;&#65292;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#19981;&#26029;&#31215;&#32047;&#21644;&#20256;&#36882;&#30693;&#35782;&#65292;&#20197;&#24110;&#21161;&#26410;&#26469;&#30340;&#23398;&#20064;&#12290;&#26080;&#30417;&#30563;&#20027;&#39064;&#24314;&#27169;&#24191;&#27867;&#29992;&#20110;&#20174;&#25991;&#26723;&#38598;&#21512;&#20013;&#21457;&#29616;&#20027;&#39064;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#31232;&#30095;&#24615;&#65292;&#20363;&#22914;&#22312;&#19968;&#20010;&#23567;&#30340;&#65288;&#30701;&#65289;&#25991;&#26723;&#38598;&#21512;&#20013;&#65292;&#20027;&#39064;&#24314;&#27169;&#30340;&#24212;&#29992;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#20174;&#32780;&#20135;&#29983;&#19981;&#36830;&#36143;&#30340;&#20027;&#39064;&#21644;&#27425;&#20248;&#30340;&#25991;&#26723;&#34920;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31070;&#32463;&#20027;&#39064;&#24314;&#27169;&#30340;&#32456;&#36523;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#25345;&#32493;&#22788;&#29702;&#25991;&#26723;&#38598;&#21512;&#30340;&#27969;&#65292;&#31215;&#32047;&#20027;&#39064;&#65292;&#24182;&#36890;&#36807;&#20174;&#22810;&#20010;&#28304;&#30340;&#30693;&#35782;&#36716;&#31227;&#25351;&#23548;&#26410;&#26469;&#30340;&#20027;&#39064;&#24314;&#27169;&#20219;&#21153;&#65292;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#31232;&#30095;&#25968;&#25454;&#12290;&#22312;&#32456;&#36523;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#29305;&#21035;&#30740;&#31350;&#20102;&#20849;&#20139;&#30340;&#29983;&#25104;&#21516;&#28304;&#24615;&#65288;&#28508;&#22312;&#20027;&#39064;&#65289;&#20197;&#22312;&#32456;&#36523;&#20013;&#20256;&#36882;&#20808;&#21069;&#30340;&#30693;&#35782;&#65292;&#20197;&#21450;&#36890;&#36807;&#26032;&#30340;&#36873;&#25321;&#24615;&#36951;&#24536;&#26469;&#26368;&#23567;&#21270;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#20197;&#20445;&#30041;&#36807;&#21435;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lifelong learning has recently attracted attention in building machine learning systems that continually accumulate and transfer knowledge to help future learning. Unsupervised topic modeling has been popularly used to discover topics from document collections. However, the application of topic modeling is challenging due to data sparsity, e.g., in a small collection of (short) documents and thus, generate incoherent topics and sub-optimal document representations. To address the problem, we propose a lifelong learning framework for neural topic modeling that can continuously process streams of document collections, accumulate topics and guide future topic modeling tasks by knowledge transfer from several sources to better deal with the sparse data. In the lifelong process, we particularly investigate jointly: (1) sharing generative homologies (latent topics) over lifetime to transfer prior knowledge, and (2) minimizing catastrophic forgetting to retain the past learning via novel sele
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25512;&#24191;&#21452;&#20998;&#22270;PageRank&#30340;&#24819;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#32593;&#32476;&#30340;&#36229;&#22270;&#31867;&#22411;&#65292;&#35777;&#26126;&#20102;&#22810;&#27169;&#32593;&#32476;&#20013;&#20010;&#24615;&#21270;PageRank&#30340;&#32593;&#32476;&#23481;&#37327;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/1706.00178</link><description>&lt;p&gt;
&#22810;&#27169;&#32593;&#32476;&#20013;&#20010;&#24615;&#21270;PageRank&#30340;&#32593;&#32476;&#23481;&#37327;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Network Capacity Bound for Personalized PageRank in Multimodal Networks. (arXiv:1706.00178v3 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1706.00178
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25512;&#24191;&#21452;&#20998;&#22270;PageRank&#30340;&#24819;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#32593;&#32476;&#30340;&#36229;&#22270;&#31867;&#22411;&#65292;&#35777;&#26126;&#20102;&#22810;&#27169;&#32593;&#32476;&#20013;&#20010;&#24615;&#21270;PageRank&#30340;&#32593;&#32476;&#23481;&#37327;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#31687;&#20808;&#21069;&#30340;&#35770;&#25991;&#20013;&#65292;&#20171;&#32461;&#20102;&#21452;&#20998;&#22270;PageRank&#30340;&#27010;&#24565;&#65292;&#24182;&#25512;&#24191;&#20102;&#20010;&#24615;&#21270;PageRank&#20013;&#33410;&#28857;&#20043;&#38388;&#25480;&#26435;&#27969;&#38480;&#21046;&#30340;&#23450;&#29702;&#12290;&#26412;&#25991;&#23558;&#36825;&#20123;&#32467;&#26524;&#25512;&#24191;&#21040;&#22810;&#27169;&#32593;&#32476;&#20013;&#12290;&#25105;&#20204;&#29305;&#21035;&#22788;&#29702;&#20102;&#19968;&#31181;&#29992;&#20110;&#25551;&#36848;&#22810;&#27169;&#32593;&#32476;&#30340;&#36229;&#22270;&#31867;&#22411;&#65292;&#20854;&#20013;&#36229;&#38142;&#25509;&#23558;&#27599;&#20010;&#27169;&#24577;&#30340;&#33410;&#28857;&#36830;&#25509;&#36215;&#26469;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#36825;&#31181;&#22270;&#30340;PageRank&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#23450;&#20041;&#20102;&#30456;&#24212;&#30340;&#38543;&#26426;&#28216;&#36208;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#35745;&#31639;&#12290;&#25105;&#20204;&#23545;&#20855;&#26377;&#30456;&#21516;&#21644;&#19981;&#21516;&#38459;&#23612;&#22240;&#23376;&#30340;&#24773;&#20917;&#19979;&#25480;&#26435;&#27969;&#20986;&#37327;&#30340;&#26497;&#38480;&#24773;&#20917;&#36827;&#34892;&#20102;&#38472;&#36848;&#21644;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a former paper the concept of Bipartite PageRank was introduced and a theorem on the limit of authority flowing between nodes for personalized PageRank has been generalized. In this paper we want to extend those results to multimodal networks. In particular we deal with a hypergraph type that may be used for describing multimodal network where a hyperlink connects nodes from each of the modalities. We introduce a generalisation of PageRank for such graphs and define the respective random walk model that can be used for computations. We state and prove theorems on the limit of outflow of authority for cases where individual modalities have identical and distinct damping factors.
&lt;/p&gt;</description></item></channel></rss>