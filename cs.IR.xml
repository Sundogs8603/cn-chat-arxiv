<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36890;&#36807;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#30340;&#25193;&#23637;&#21644;&#22256;&#38590;&#26597;&#35810;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#25552;&#39640;&#22256;&#38590;&#26597;&#35810;&#30340;&#25490;&#24207;&#24615;&#33021;&#65292;&#32780;&#19981;&#38477;&#20302;&#20854;&#20182;&#26597;&#35810;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.02587</link><description>&lt;p&gt;
&#35757;&#32451;&#25193;&#23637;&#26597;&#35810;&#30340;&#25490;&#24207;&#22120;&#30340;&#20986;&#20046;&#24847;&#26009;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Surprising Effectiveness of Rankers Trained on Expanded Queries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02587
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#30340;&#25193;&#23637;&#21644;&#22256;&#38590;&#26597;&#35810;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#25552;&#39640;&#22256;&#38590;&#26597;&#35810;&#30340;&#25490;&#24207;&#24615;&#33021;&#65292;&#32780;&#19981;&#38477;&#20302;&#20854;&#20182;&#26597;&#35810;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#25490;&#24207;&#31995;&#32479;&#20013;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#26159;&#22788;&#29702;&#26597;&#35810;&#20998;&#24067;&#23614;&#37096;&#30340;&#22256;&#38590;&#26597;&#35810;&#12290;&#36825;&#31181;&#22256;&#38590;&#21487;&#33021;&#28304;&#20110;&#23384;&#22312;&#19981;&#24120;&#35265;&#12289;&#26410;&#26126;&#30830;&#25110;&#19981;&#23436;&#25972;&#30340;&#26597;&#35810;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#30456;&#20851;&#25991;&#26723;&#23545;&#35757;&#32451;&#26597;&#35810;&#36827;&#34892;&#20102;&#22522;&#20110;LLM&#30340;&#26597;&#35810;&#25193;&#23637;&#26469;&#25552;&#39640;&#22256;&#38590;&#26597;&#35810;&#30340;&#25490;&#24207;&#24615;&#33021;&#65292;&#32780;&#19981;&#25439;&#23475;&#20854;&#20182;&#26597;&#35810;&#30340;&#24615;&#33021;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22522;&#20110;LLM&#36827;&#34892;&#26597;&#35810;&#20016;&#23500;&#21270;&#65292;&#20351;&#29992;&#30456;&#20851;&#25991;&#26723;&#36827;&#34892;&#35757;&#32451;&#12290;&#25509;&#19979;&#26469;&#65292;&#19987;&#38376;&#30340;&#25490;&#24207;&#22120;&#20165;&#22312;&#20016;&#23500;&#30340;&#22256;&#38590;&#26597;&#35810;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#32780;&#19981;&#26159;&#22312;&#21407;&#22987;&#26597;&#35810;&#19978;&#36827;&#34892;&#24494;&#35843;&#12290;&#25105;&#20204;&#23558;&#26469;&#33258;&#19987;&#38376;&#25490;&#24207;&#22120;&#21644;&#22522;&#26412;&#25490;&#24207;&#22120;&#30340;&#30456;&#20851;&#24615;&#24471;&#20998;&#20197;&#21450;&#20026;&#27599;&#20010;&#26597;&#35810;&#20272;&#35745;&#30340;&#26597;&#35810;&#24615;&#33021;&#24471;&#20998;&#36827;&#34892;&#32452;&#21512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#21516;&#20110;&#36890;&#24120;&#23545;&#25152;&#26377;&#26597;&#35810;&#20351;&#29992;&#21333;&#20010;&#25490;&#24207;&#22120;&#30340;&#29616;&#26377;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#26131;&#26597;&#35810;&#26377;&#20559;&#35265;&#65292;&#26131;&#26597;&#35810;&#26500;&#25104;&#26597;&#35810;&#20998;&#24067;&#30340;&#22823;&#22810;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02587v1 Announce Type: cross  Abstract: An important problem in text-ranking systems is handling the hard queries that form the tail end of the query distribution. The difficulty may arise due to the presence of uncommon, underspecified, or incomplete queries. In this work, we improve the ranking performance of hard or difficult queries without compromising the performance of other queries. Firstly, we do LLM based query enrichment for training queries using relevant documents. Next, a specialized ranker is fine-tuned only on the enriched hard queries instead of the original queries. We combine the relevance scores from the specialized ranker and the base ranker, along with a query performance score estimated for each query. Our approach departs from existing methods that usually employ a single ranker for all queries, which is biased towards easy queries, which form the majority of the query distribution. In our extensive experiments on the DL-Hard dataset, we find that a p
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24402;&#32435;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#26696;&#20363;&#38388;&#30340;&#36830;&#25509;&#20851;&#31995;&#65292;&#25552;&#39640;&#20102;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.17780</link><description>&lt;p&gt;
CaseLink:&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#30340;&#24402;&#32435;&#22270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
CaseLink: Inductive Graph Learning for Legal Case Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17780
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24402;&#32435;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#26696;&#20363;&#38388;&#30340;&#36830;&#25509;&#20851;&#31995;&#65292;&#25552;&#39640;&#20102;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26696;&#20363;&#27861;&#20013;&#65292;&#20808;&#20363;&#26159;&#29992;&#26469;&#25903;&#25345;&#27861;&#23448;&#20570;&#20986;&#20915;&#23450;&#20197;&#21450;&#24459;&#24072;&#23545;&#29305;&#23450;&#26696;&#20363;&#30340;&#35266;&#28857;&#30340;&#30456;&#20851;&#26696;&#20363;&#12290;&#20026;&#20102;&#20174;&#22823;&#37327;&#26696;&#20363;&#27744;&#20013;&#39640;&#25928;&#22320;&#25214;&#21040;&#30456;&#20851;&#26696;&#20363;&#65292;&#27861;&#24459;&#20174;&#19994;&#32773;&#24191;&#27867;&#20351;&#29992;&#26816;&#32034;&#24037;&#20855;&#12290;&#29616;&#26377;&#30340;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#27169;&#22411;&#20027;&#35201;&#36890;&#36807;&#27604;&#36739;&#21333;&#20010;&#26696;&#20363;&#30340;&#25991;&#26412;&#34920;&#31034;&#26469;&#24037;&#20316;&#12290;&#23613;&#31649;&#23427;&#20204;&#33719;&#24471;&#20102;&#19981;&#38169;&#30340;&#26816;&#32034;&#20934;&#30830;&#24615;&#65292;&#20294;&#26696;&#20363;&#20043;&#38388;&#30340;&#22266;&#26377;&#36830;&#25509;&#20851;&#31995;&#26410;&#34987;&#20805;&#20998;&#21033;&#29992;&#20110;&#26696;&#20363;&#32534;&#30721;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#32034;&#24615;&#33021;&#12290;&#22312;&#26696;&#20363;&#27744;&#20013;&#65292;&#26377;&#19977;&#31181;&#26696;&#20363;&#36830;&#25509;&#20851;&#31995;&#65306;&#26696;&#20363;&#24341;&#29992;&#20851;&#31995;&#12289;&#26696;&#20363;&#35821;&#20041;&#20851;&#31995;&#21644;&#26696;&#20363;&#27861;&#24459;&#25351;&#25511;&#20851;&#31995;&#12290;&#30001;&#20110;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20219;&#21153;&#30340;&#24402;&#32435;&#26041;&#24335;&#30340;&#29305;&#28857;&#65292;&#20351;&#29992;&#26696;&#20363;&#24341;&#29992;&#20316;&#20026;&#36755;&#20837;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17780v1 Announce Type: new  Abstract: In case law, the precedents are the relevant cases that are used to support the decisions made by the judges and the opinions of lawyers towards a given case. This relevance is referred to as the case-to-case reference relation. To efficiently find relevant cases from a large case pool, retrieval tools are widely used by legal practitioners. Existing legal case retrieval models mainly work by comparing the text representations of individual cases. Although they obtain a decent retrieval accuracy, the intrinsic case connectivity relationships among cases have not been well exploited for case encoding, therefore limiting the further improvement of retrieval performance. In a case pool, there are three types of case connectivity relationships: the case reference relationship, the case semantic relationship, and the case legal charge relationship. Due to the inductive manner in the task of legal case retrieval, using case reference as input 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InFO-RAG&#30340;&#26080;&#30417;&#30563;&#20449;&#24687;&#32454;&#21270;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#20013;&#30340;&#35282;&#33394;&#23450;&#20041;&#20026;&#8220;&#20449;&#24687;&#32454;&#21270;&#32773;&#8221;&#65292;&#24110;&#21161;&#27169;&#22411;&#26356;&#22909;&#22320;&#25972;&#21512;&#26816;&#32034;&#20449;&#24687;&#20197;&#29983;&#25104;&#26356;&#21152;&#31616;&#27905;&#12289;&#20934;&#30830;&#21644;&#23436;&#25972;&#30340;&#25991;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.18150</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#20449;&#24687;&#32454;&#21270;&#35757;&#32451;&#29992;&#20110;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18150
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InFO-RAG&#30340;&#26080;&#30417;&#30563;&#20449;&#24687;&#32454;&#21270;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#20013;&#30340;&#35282;&#33394;&#23450;&#20041;&#20026;&#8220;&#20449;&#24687;&#32454;&#21270;&#32773;&#8221;&#65292;&#24110;&#21161;&#27169;&#22411;&#26356;&#22909;&#22320;&#25972;&#21512;&#26816;&#32034;&#20449;&#24687;&#20197;&#29983;&#25104;&#26356;&#21152;&#31616;&#27905;&#12289;&#20934;&#30830;&#21644;&#23436;&#25972;&#30340;&#25991;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#36890;&#36807;&#23558;&#26469;&#33258;&#26816;&#32034;&#30340;&#39069;&#22806;&#20449;&#24687;&#25972;&#21512;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#65292;&#20174;&#32780;&#22686;&#24378;&#20854;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#30740;&#31350;&#34920;&#26126;&#65292;LLMs&#22312;&#26377;&#25928;&#21033;&#29992;&#26816;&#32034;&#20449;&#24687;&#26041;&#38754;&#20173;&#28982;&#38754;&#20020;&#25361;&#25112;&#65292;&#26377;&#26102;&#20250;&#24573;&#35270;&#25110;&#34987;&#38169;&#35823;&#24341;&#23548;&#12290;&#20854;&#20851;&#38190;&#21407;&#22240;&#22312;&#20110;LLMs&#30340;&#35757;&#32451;&#27809;&#26377;&#28165;&#26224;&#22320;&#35753;LLMs&#23398;&#20250;&#22914;&#20309;&#21033;&#29992;&#20855;&#26377;&#19981;&#21516;&#36136;&#37327;&#30340;&#26816;&#32034;&#25991;&#26412;&#36755;&#20837;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#35270;&#35282;&#65292;&#23558;LLMs&#22312;RAG&#20013;&#30340;&#35282;&#33394;&#35270;&#20026;&#8220;&#20449;&#24687;&#32454;&#21270;&#32773;&#8221;&#65292;&#36825;&#24847;&#21619;&#30528;&#26080;&#35770;&#26816;&#32034;&#25991;&#26412;&#30340;&#27491;&#30830;&#24615;&#12289;&#23436;&#25972;&#24615;&#25110;&#26377;&#29992;&#24615;&#22914;&#20309;&#65292;LLMs&#37117;&#33021;&#19968;&#33268;&#22320;&#25972;&#21512;&#26816;&#32034;&#25991;&#26412;&#20013;&#30340;&#30693;&#35782;&#21644;&#27169;&#22411;&#21442;&#25968;&#65292;&#29983;&#25104;&#27604;&#26816;&#32034;&#25991;&#26412;&#26356;&#31616;&#27905;&#12289;&#20934;&#30830;&#21644;&#23436;&#25972;&#30340;&#25991;&#26412;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InFO-RAG&#30340;&#20449;&#24687;&#32454;&#21270;&#35757;&#32451;&#26041;&#27861;&#65292;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#20248;&#21270;LLMs&#29992;&#20110;RAG&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18150v1 Announce Type: cross  Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating additional information from retrieval. However, studies have shown that LLMs still face challenges in effectively using the retrieved information, even ignoring it or being misled by it. The key reason is that the training of LLMs does not clearly make LLMs learn how to utilize input retrieved texts with varied quality. In this paper, we propose a novel perspective that considers the role of LLMs in RAG as ``Information Refiner'', which means that regardless of correctness, completeness, or usefulness of retrieved texts, LLMs can consistently integrate knowledge within the retrieved texts and model parameters to generate the texts that are more concise, accurate, and complete than the retrieved texts. To this end, we propose an information refinement training method named InFO-RAG that optimizes LLMs for RAG in an unsupervised manner. InFO-RAG i
&lt;/p&gt;</description></item><item><title>CDRNP&#26159;&#19968;&#31181;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23558;&#29992;&#25143;&#34920;&#31034;&#20174;&#28304;&#39046;&#22495;&#36716;&#31227;&#21040;&#30446;&#26631;&#39046;&#22495;&#65292;&#35299;&#20915;&#29992;&#25143;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#36328;&#39046;&#22495;&#25512;&#33616;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.12732</link><description>&lt;p&gt;
CDRNP: &#36890;&#36807;&#31070;&#32463;&#36807;&#31243;&#23454;&#29616;&#36328;&#39046;&#22495;&#25512;&#33616;&#20197;&#35299;&#20915;&#20919;&#21551;&#21160;&#29992;&#25143;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process. (arXiv:2401.12732v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12732
&lt;/p&gt;
&lt;p&gt;
CDRNP&#26159;&#19968;&#31181;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23558;&#29992;&#25143;&#34920;&#31034;&#20174;&#28304;&#39046;&#22495;&#36716;&#31227;&#21040;&#30446;&#26631;&#39046;&#22495;&#65292;&#35299;&#20915;&#29992;&#25143;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#36328;&#39046;&#22495;&#25512;&#33616;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#25512;&#33616;&#65288;CDR&#65289;&#24050;&#34987;&#35777;&#26126;&#26159;&#35299;&#20915;&#29992;&#25143;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#19968;&#31181;&#26377;&#25928;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#20174;&#28304;&#39046;&#22495;&#36716;&#31227;&#29992;&#25143;&#20559;&#22909;&#26469;&#20026;&#30446;&#26631;&#39046;&#22495;&#30340;&#29992;&#25143;&#36827;&#34892;&#25512;&#33616;&#12290;&#20256;&#32479;&#30340;CDR&#30740;&#31350;&#36981;&#24490;&#23884;&#20837;&#21644;&#26144;&#23556;&#65288;EMCDR&#65289;&#33539; paradigm&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#29992;&#25143;&#20849;&#20139;&#26144;&#23556;&#20989;&#25968;&#23558;&#29992;&#25143;&#34920;&#31034;&#20174;&#28304;&#39046;&#22495;&#36716;&#31227;&#21040;&#30446;&#26631;&#39046;&#22495;&#65292;&#24573;&#35270;&#20102;&#29992;&#25143;&#29305;&#23450;&#20559;&#22909;&#12290;&#26368;&#36817;&#30340;CDR&#30740;&#31350;&#23581;&#35797;&#22312;&#20803;&#23398;&#20064;&#33539; paradigm &#19979;&#23398;&#20064;&#29992;&#25143;&#29305;&#23450;&#26144;&#23556;&#20989;&#25968;&#65292;&#23558;&#27599;&#20010;&#29992;&#25143;&#30340;CDR&#35270;&#20026;&#29420;&#31435;&#20219;&#21153;&#65292;&#20294;&#24573;&#35270;&#20102;&#29992;&#25143;&#20043;&#38388;&#30340;&#20559;&#22909;&#30456;&#20851;&#24615;&#65292;&#38480;&#21046;&#20102;&#29992;&#20110;&#34920;&#31034;&#29992;&#25143;&#30340;&#26377;&#30410;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#36825;&#20004;&#20010;&#33539; paradigm &#37117;&#24573;&#30053;&#20102;&#26144;&#23556;&#36807;&#31243;&#20013;&#26469;&#33258;&#20004;&#20010;&#39046;&#22495;&#30340;&#29992;&#25143;-&#39033;&#30446;&#26174;&#24335;&#20132;&#20114;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;CDR&#26694;&#26550;&#65292;&#20351;&#29992;&#31070;&#32463;&#36807;&#31243;&#65288;NP&#65289;&#65292;&#31216;&#20026;CDRNP&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-domain recommendation (CDR) has been proven as a promising way to tackle the user cold-start problem, which aims to make recommendations for users in the target domain by transferring the user preference derived from the source domain. Traditional CDR studies follow the embedding and mapping (EMCDR) paradigm, which transfers user representations from the source to target domain by learning a user-shared mapping function, neglecting the user-specific preference. Recent CDR studies attempt to learn user-specific mapping functions in meta-learning paradigm, which regards each user's CDR as an individual task, but neglects the preference correlations among users, limiting the beneficial information for user representations. Moreover, both of the paradigms neglect the explicit user-item interactions from both domains during the mapping process. To address the above issues, this paper proposes a novel CDR framework with neural process (NP), termed as CDRNP. Particularly, it develops th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MARVEL&#30340;&#22810;&#27169;&#24577;&#26816;&#32034;&#27169;&#22411;&#65292;&#36890;&#36807;&#35270;&#35273;&#27169;&#22359;&#25554;&#20214;&#20026;&#23494;&#38598;&#26816;&#32034;&#22120;&#28155;&#21152;&#22270;&#20687;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#19988;&#22312;&#22810;&#27169;&#24577;&#26816;&#32034;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14037</link><description>&lt;p&gt;
&#36890;&#36807;&#35270;&#35273;&#27169;&#22359;&#25554;&#20214;&#35299;&#38145;&#23494;&#38598;&#26816;&#32034;&#30340;&#22810;&#27169;&#24577;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unlock Multi-Modal Capability of Dense Retrieval via Visual Module Plugin. (arXiv:2310.14037v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14037
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MARVEL&#30340;&#22810;&#27169;&#24577;&#26816;&#32034;&#27169;&#22411;&#65292;&#36890;&#36807;&#35270;&#35273;&#27169;&#22359;&#25554;&#20214;&#20026;&#23494;&#38598;&#26816;&#32034;&#22120;&#28155;&#21152;&#22270;&#20687;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#19988;&#22312;&#22810;&#27169;&#24577;&#26816;&#32034;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#35270;&#35273;&#27169;&#22359;&#25554;&#20214;&#65288;MARVEL&#65289;&#23398;&#20064;&#26597;&#35810;&#21644;&#22810;&#27169;&#24577;&#25991;&#26723;&#30340;&#23884;&#20837;&#31354;&#38388;&#20197;&#36827;&#34892;&#26816;&#32034;&#30340;&#22810;&#27169;&#24577;&#26816;&#32034;&#27169;&#22411;&#12290;MARVEL&#20351;&#29992;&#32479;&#19968;&#30340;&#32534;&#30721;&#22120;&#27169;&#22411;&#23545;&#26597;&#35810;&#21644;&#22810;&#27169;&#24577;&#25991;&#26723;&#36827;&#34892;&#32534;&#30721;&#65292;&#26377;&#21161;&#20110;&#20943;&#23567;&#22270;&#20687;&#21644;&#25991;&#26412;&#20043;&#38388;&#30340;&#27169;&#24577;&#24046;&#36317;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#35270;&#35273;&#27169;&#22359;&#32534;&#30721;&#30340;&#22270;&#20687;&#29305;&#24449;&#20316;&#20026;&#20854;&#36755;&#20837;&#65292;&#20351;&#24471;&#32463;&#36807;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;T5-ANCE&#20855;&#26377;&#22270;&#20687;&#29702;&#35299;&#33021;&#21147;&#12290;&#20026;&#20102;&#20419;&#36827;&#22810;&#27169;&#24577;&#26816;&#32034;&#20219;&#21153;&#65292;&#25105;&#20204;&#22522;&#20110;ClueWeb22&#25968;&#25454;&#38598;&#26500;&#24314;&#20102;ClueWeb22-MM&#25968;&#25454;&#38598;&#65292;&#23558;&#38170;&#25991;&#26412;&#20316;&#20026;&#26597;&#35810;&#65292;&#24182;&#20174;&#38170;&#38142;&#25509;&#30340;&#32593;&#39029;&#20013;&#25552;&#21462;&#30456;&#20851;&#25991;&#26412;&#21644;&#22270;&#20687;&#25991;&#26723;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;MARVEL&#22312;&#22810;&#27169;&#24577;&#26816;&#32034;&#25968;&#25454;&#38598;WebQA&#21644;ClueWeb22-MM&#19978;&#26126;&#26174;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;&#36827;&#19968;&#27493;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#35270;&#35273;&#27169;&#22359;&#25554;&#20214;&#26041;&#27861;&#20026;&#23454;&#29616;&#22270;&#20687;&#29702;&#35299;&#33021;&#21147;&#37327;&#36523;&#23450;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes Multi-modAl Retrieval model via Visual modulE pLugin (MARVEL) to learn an embedding space for queries and multi-modal documents to conduct retrieval. MARVEL encodes queries and multi-modal documents with a unified encoder model, which helps to alleviate the modality gap between images and texts. Specifically, we enable the image understanding ability of a well-trained dense retriever, T5-ANCE, by incorporating the image features encoded by the visual module as its inputs. To facilitate the multi-modal retrieval tasks, we build the ClueWeb22-MM dataset based on the ClueWeb22 dataset, which regards anchor texts as queries, and exact the related texts and image documents from anchor linked web pages. Our experiments show that MARVEL significantly outperforms the state-of-the-art methods on the multi-modal retrieval dataset WebQA and ClueWeb22-MM. Our further analyses show that the visual module plugin method is tailored to enable the image understanding ability for an 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20165;&#20351;&#29992;&#21387;&#32553;&#34920;&#31034;&#26469;&#24674;&#22797;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#31526;&#21495;&#30340;&#39057;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#23558;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#35770;&#35266;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#36824;&#25193;&#23637;&#20102;&#35813;&#26041;&#27861;&#20197;&#35299;&#20915;&#22522;&#25968;&#24674;&#22797;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.15408</link><description>&lt;p&gt;
&#20174;&#21387;&#32553;&#25968;&#25454;&#20013;&#24674;&#22797;&#39057;&#29575;&#21644;&#22522;&#25968;&#65306;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#35770;&#35266;&#28857;&#36830;&#25509;&#36215;&#26469;&#30340;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Frequency and cardinality recovery from sketched data: a novel approach bridging Bayesian and frequentist views. (arXiv:2309.15408v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15408
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20165;&#20351;&#29992;&#21387;&#32553;&#34920;&#31034;&#26469;&#24674;&#22797;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#31526;&#21495;&#30340;&#39057;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#23558;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#35770;&#35266;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#36824;&#25193;&#23637;&#20102;&#35813;&#26041;&#27861;&#20197;&#35299;&#20915;&#22522;&#25968;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#20165;&#20351;&#29992;&#36890;&#36807;&#38543;&#26426;&#21704;&#24076;&#33719;&#24471;&#30340;&#23545;&#25968;&#25454;&#36827;&#34892;&#21387;&#32553;&#34920;&#31034;&#25110;&#33609;&#22270;&#26469;&#24674;&#22797;&#22823;&#35268;&#27169;&#31163;&#25955;&#25968;&#25454;&#38598;&#20013;&#31526;&#21495;&#30340;&#39057;&#29575;&#12290;&#36825;&#26159;&#19968;&#20010;&#22312;&#35745;&#31639;&#26426;&#31185;&#23398;&#20013;&#30340;&#32463;&#20856;&#38382;&#39064;&#65292;&#26377;&#21508;&#31181;&#31639;&#27861;&#21487;&#29992;&#65292;&#22914;&#35745;&#25968;&#26368;&#23567;&#33609;&#22270;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#20551;&#35774;&#25968;&#25454;&#26159;&#22266;&#23450;&#30340;&#65292;&#22788;&#29702;&#38543;&#26426;&#37319;&#26679;&#25968;&#25454;&#26102;&#20272;&#35745;&#36807;&#20110;&#20445;&#23432;&#19988;&#21487;&#33021;&#19981;&#20934;&#30830;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#33609;&#22270;&#25968;&#25454;&#35270;&#20026;&#26410;&#30693;&#20998;&#24067;&#30340;&#38543;&#26426;&#26679;&#26412;&#65292;&#28982;&#21518;&#24341;&#20837;&#25913;&#36827;&#29616;&#26377;&#26041;&#27861;&#30340;&#26032;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#21644;&#32463;&#20856;&#65288;&#39057;&#29575;&#35770;&#65289;&#35266;&#28857;&#65292;&#35299;&#20915;&#20102;&#23427;&#20204;&#29420;&#29305;&#30340;&#38480;&#21046;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21407;&#21017;&#19988;&#23454;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20197;&#35299;&#20915;&#30456;&#20851;&#20294;&#19981;&#21516;&#30340;&#22522;&#25968;&#24674;&#22797;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#28041;&#21450;&#20272;&#35745;&#25968;&#25454;&#38598;&#20013;&#19981;&#21516;&#23545;&#35937;&#30340;&#24635;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how to recover the frequency of a symbol in a large discrete data set, using only a compressed representation, or sketch, of those data obtained via random hashing. This is a classical problem in computer science, with various algorithms available, such as the count-min sketch. However, these algorithms often assume that the data are fixed, leading to overly conservative and potentially inaccurate estimates when dealing with randomly sampled data. In this paper, we consider the sketched data as a random sample from an unknown distribution, and then we introduce novel estimators that improve upon existing approaches. Our method combines Bayesian nonparametric and classical (frequentist) perspectives, addressing their unique limitations to provide a principled and practical solution. Additionally, we extend our method to address the related but distinct problem of cardinality recovery, which consists of estimating the total number of distinct objects in the data set. We validate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25209;&#21028;&#24615;&#23457;&#35270;&#20102;(Normalised) Discounted Cumulative Gain&#20316;&#20026;Top-n&#25512;&#33616;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#20309;&#26102;&#21487;&#20197;&#26399;&#26395;&#36825;&#20123;&#25351;&#26631;&#36924;&#36817;&#22312;&#32447;&#23454;&#39564;&#30340;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.15053</link><description>&lt;p&gt;
&#20851;&#20110;(Normalised) Discounted Cumulative Gain&#20316;&#20026;Top-n&#25512;&#33616;&#30340;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#35770;&#25991;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
On (Normalised) Discounted Cumulative Gain as an Offline Evaluation Metric for Top-$n$ Recommendation. (arXiv:2307.15053v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25209;&#21028;&#24615;&#23457;&#35270;&#20102;(Normalised) Discounted Cumulative Gain&#20316;&#20026;Top-n&#25512;&#33616;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#20309;&#26102;&#21487;&#20197;&#26399;&#26395;&#36825;&#20123;&#25351;&#26631;&#36924;&#36817;&#22312;&#32447;&#23454;&#39564;&#30340;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#26041;&#27861;&#36890;&#24120;&#36890;&#36807;&#20004;&#31181;&#26041;&#24335;&#36827;&#34892;&#35780;&#20272;&#65306;(1) &#36890;&#36807;(&#27169;&#25311;)&#22312;&#32447;&#23454;&#39564;&#65292;&#36890;&#24120;&#34987;&#35270;&#20026;&#37329;&#26631;&#20934;&#65292;&#25110;&#32773;(2) &#36890;&#36807;&#19968;&#20123;&#31163;&#32447;&#35780;&#20272;&#31243;&#24207;&#65292;&#30446;&#26631;&#26159;&#36817;&#20284;&#22312;&#32447;&#23454;&#39564;&#30340;&#32467;&#26524;&#12290;&#25991;&#29486;&#20013;&#37319;&#29992;&#20102;&#20960;&#31181;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#65292;&#21463;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#20013;&#24120;&#35265;&#30340;&#25490;&#21517;&#25351;&#26631;&#30340;&#21551;&#21457;&#12290;(Normalised) Discounted Cumulative Gain (nDCG)&#26159;&#20854;&#20013;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#22312;&#24456;&#22810;&#24180;&#37324;&#65292;&#26356;&#39640;&#30340;(n)DCG&#20540;&#34987;&#29992;&#26469;&#23637;&#31034;&#26032;&#26041;&#27861;&#22312;Top-n&#25512;&#33616;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#36825;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#30340;&#23457;&#35270;&#65292;&#24182;&#30740;&#31350;&#20102;&#25105;&#20204;&#20309;&#26102;&#21487;&#20197;&#26399;&#26395;&#36825;&#20123;&#25351;&#26631;&#36924;&#36817;&#22312;&#32447;&#23454;&#39564;&#30340;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;&#25105;&#20204;&#20174;&#31532;&#19968;&#21407;&#29702;&#19978;&#27491;&#24335;&#25552;&#20986;&#20102;DCG&#34987;&#35748;&#20026;&#26159;&#22312;&#32447;&#22870;&#21169;&#30340;&#26080;&#20559;&#20272;&#35745;&#30340;&#20551;&#35774;&#65292;&#24182;&#32473;&#20986;&#20102;&#36825;&#20010;&#25351;&#26631;&#30340;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approaches to recommendation are typically evaluated in one of two ways: (1) via a (simulated) online experiment, often seen as the gold standard, or (2) via some offline evaluation procedure, where the goal is to approximate the outcome of an online experiment. Several offline evaluation metrics have been adopted in the literature, inspired by ranking metrics prevalent in the field of Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one such metric that has seen widespread adoption in empirical studies, and higher (n)DCG values have been used to present new methods as the state-of-the-art in top-$n$ recommendation for many years.  Our work takes a critical look at this approach, and investigates when we can expect such metrics to approximate the gold standard outcome of an online experiment. We formally present the assumptions that are necessary to consider DCG an unbiased estimator of online reward and provide a derivation for this metric from first principles
&lt;/p&gt;</description></item></channel></rss>