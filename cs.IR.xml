<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#36793;&#38469;&#30697;&#38453;&#20998;&#35299;&#30340;&#21322;&#30417;&#30563;&#26041;&#27861;&#26469;&#22686;&#24191;&#21644;&#32454;&#21270;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#30340;&#35780;&#32423;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#33258;&#25105;&#35757;&#32451;&#26469;&#35780;&#20272;&#35780;&#20998;&#30340;&#32622;&#20449;&#24230;&#65292;&#24182;&#36890;&#36807;&#31995;&#32479;&#30340;&#25968;&#25454;&#22686;&#24191;&#31574;&#30053;&#26469;&#25552;&#39640;&#31639;&#27861;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.13050</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#25968;&#25454;&#22686;&#24191;&#65306;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#36793;&#38469;&#30697;&#38453;&#20998;&#35299;&#30340;&#21322;&#30417;&#30563;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Data augmentation for recommender system: A semi-supervised approach using maximum margin matrix factorization. (arXiv:2306.13050v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#36793;&#38469;&#30697;&#38453;&#20998;&#35299;&#30340;&#21322;&#30417;&#30563;&#26041;&#27861;&#26469;&#22686;&#24191;&#21644;&#32454;&#21270;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#30340;&#35780;&#32423;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#33258;&#25105;&#35757;&#32451;&#26469;&#35780;&#20272;&#35780;&#20998;&#30340;&#32622;&#20449;&#24230;&#65292;&#24182;&#36890;&#36807;&#31995;&#32479;&#30340;&#25968;&#25454;&#22686;&#24191;&#31574;&#30053;&#26469;&#25552;&#39640;&#31639;&#27861;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#24050;&#25104;&#20026;&#25512;&#33616;&#31995;&#32479;&#24320;&#21457;&#30340;&#24120;&#29992;&#26041;&#27861;&#65292;&#20854;&#20013;&#65292;&#26681;&#25454;&#29992;&#25143;&#30340;&#36807;&#21435;&#21916;&#22909;&#21644;&#20854;&#20182;&#29992;&#25143;&#30340;&#21487;&#29992;&#20559;&#22909;&#20449;&#24687;&#39044;&#27979;&#20854;&#23545;&#26032;&#29289;&#21697;&#30340;&#35780;&#20998;&#12290;&#23613;&#31649;CF&#26041;&#27861;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#20854;&#24615;&#33021;&#36890;&#24120;&#21463;&#35266;&#23519;&#21040;&#30340;&#26465;&#30446;&#30340;&#31232;&#30095;&#24615;&#30340;&#26497;&#22823;&#38480;&#21046;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#26368;&#22823;&#36793;&#38469;&#30697;&#38453;&#20998;&#35299;&#65288;MMMF&#65289;&#30340;&#25968;&#25454;&#22686;&#24191;&#21644;&#32454;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#26159;&#24191;&#27867;&#25509;&#21463;&#30340;&#29992;&#20110;&#35780;&#32423;&#39044;&#27979;&#30340;CF&#25216;&#26415;&#65292;&#20043;&#21069;&#23578;&#26410;&#36827;&#34892;&#30740;&#31350;&#12290;&#25105;&#20204;&#21033;&#29992;CF&#31639;&#27861;&#30340;&#22266;&#26377;&#29305;&#24615;&#26469;&#35780;&#20272;&#21333;&#20010;&#35780;&#20998;&#30340;&#32622;&#20449;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#25105;&#35757;&#32451;&#30340;&#21322;&#30417;&#30563;&#35780;&#32423;&#22686;&#24378;&#26041;&#27861;&#12290;&#25105;&#20204;&#20551;&#35774;&#20219;&#20309;CF&#31639;&#27861;&#30340;&#39044;&#27979;&#20302;&#32622;&#20449;&#24230;&#26159;&#30001;&#20110;&#35757;&#32451;&#25968;&#25454;&#30340;&#26576;&#20123;&#19981;&#36275;&#65292;&#22240;&#27492;&#65292;&#36890;&#36807;&#37319;&#29992;&#31995;&#32479;&#30340;&#25968;&#25454;&#22686;&#24191;&#31574;&#30053;&#65292;&#21487;&#20197;&#25552;&#39640;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative filtering (CF) has become a popular method for developing recommender systems (RS) where ratings of a user for new items is predicted based on her past preferences and available preference information of other users. Despite the popularity of CF-based methods, their performance is often greatly limited by the sparsity of observed entries. In this study, we explore the data augmentation and refinement aspects of Maximum Margin Matrix Factorization (MMMF), a widely accepted CF technique for the rating predictions, which have not been investigated before. We exploit the inherent characteristics of CF algorithms to assess the confidence level of individual ratings and propose a semi-supervised approach for rating augmentation based on self-training. We hypothesize that any CF algorithm's predictions with low confidence are due to some deficiency in the training data and hence, the performance of the algorithm can be improved by adopting a systematic data augmentation strategy
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#20002;&#22833;&#32422;&#26463;&#30340;&#22823;&#35268;&#27169;&#20844;&#20849;&#23433;&#20840;&#26102;&#31354;&#25968;&#25454;&#39640;&#25928;&#21010;&#20998;&#26041;&#27861;(IFL-LSTP)&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#25968;&#25454;&#35268;&#27169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#30830;&#20445;&#20998;&#24067;&#24335;&#23384;&#20648;&#30340;&#36127;&#36733;&#24179;&#34913;&#65292;&#21516;&#26102;&#20445;&#25345;&#25968;&#25454;&#21010;&#20998;&#30340;&#26102;&#31354;&#25509;&#36817;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.12857</link><description>&lt;p&gt;
&#22522;&#20110;&#20449;&#24687;&#20002;&#22833;&#32422;&#26463;&#30340;&#22823;&#35268;&#27169;&#20844;&#20849;&#23433;&#20840;&#26102;&#31354;&#25968;&#25454;&#39640;&#25928;&#21010;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Partitioning Method of Large-Scale Public Safety Spatio-Temporal Data based on Information Loss Constraints. (arXiv:2306.12857v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#20002;&#22833;&#32422;&#26463;&#30340;&#22823;&#35268;&#27169;&#20844;&#20849;&#23433;&#20840;&#26102;&#31354;&#25968;&#25454;&#39640;&#25928;&#21010;&#20998;&#26041;&#27861;(IFL-LSTP)&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#25968;&#25454;&#35268;&#27169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#30830;&#20445;&#20998;&#24067;&#24335;&#23384;&#20648;&#30340;&#36127;&#36733;&#24179;&#34913;&#65292;&#21516;&#26102;&#20445;&#25345;&#25968;&#25454;&#21010;&#20998;&#30340;&#26102;&#31354;&#25509;&#36817;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#26102;&#31354;&#25968;&#25454;&#30340;&#23384;&#20648;&#12289;&#31649;&#29702;&#21644;&#24212;&#29992;&#22312;&#21508;&#31181;&#23454;&#38469;&#22330;&#26223;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#21253;&#25324;&#20844;&#20849;&#23433;&#20840;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#29420;&#29305;&#26102;&#31354;&#20998;&#24067;&#29305;&#24449;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#22312;&#25968;&#25454;&#26102;&#31354;&#25509;&#36817;&#24230;&#21644;&#20998;&#24067;&#24335;&#23384;&#20648;&#36127;&#36733;&#24179;&#34913;&#26041;&#38754;&#23384;&#22312;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#20002;&#22833;&#32422;&#26463;&#30340;&#22823;&#35268;&#27169;&#20844;&#20849;&#23433;&#20840;&#26102;&#31354;&#25968;&#25454;&#39640;&#25928;&#21010;&#20998;&#26041;&#27861;(IFL-LSTP)&#12290;&#35813;IFL-LSTP&#27169;&#22411;&#38024;&#23545;&#22823;&#35268;&#27169;&#26102;&#31354;&#28857;&#25968;&#25454;&#65292;&#23558;&#26102;&#31354;&#21010;&#20998;&#27169;&#22359;(STPM)&#21644;&#22270;&#21010;&#20998;&#27169;&#22359;(GPM)&#30456;&#32467;&#21512;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#25968;&#25454;&#35268;&#27169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#20197;&#25552;&#39640;&#21010;&#20998;&#25928;&#29575;&#12290;&#23427;&#36824;&#21487;&#20197;&#30830;&#20445;&#20998;&#24067;&#24335;&#23384;&#20648;&#30340;&#36127;&#36733;&#24179;&#34913;&#65292;&#21516;&#26102;&#20445;&#25345;&#25968;&#25454;&#21010;&#20998;&#30340;&#26102;&#31354;&#25509;&#36817;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The storage, management, and application of massive spatio-temporal data are widely applied in various practical scenarios, including public safety. However, due to the unique spatio-temporal distribution characteristics of re-al-world data, most existing methods have limitations in terms of the spatio-temporal proximity of data and load balancing in distributed storage. There-fore, this paper proposes an efficient partitioning method of large-scale public safety spatio-temporal data based on information loss constraints (IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporal point da-ta by combining the spatio-temporal partitioning module (STPM) with the graph partitioning module (GPM). This approach can significantly reduce the scale of data while maintaining the model's accuracy, in order to improve the partitioning efficiency. It can also ensure the load balancing of distributed storage while maintaining spatio-temporal proximity of the data partitioning res
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#38598;&#25104;&#25512;&#33616;&#31995;&#32479;&#65292;&#23558;&#19981;&#21516;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#32467;&#21512;&#25104;&#19968;&#20010;&#36229;&#22270;&#25490;&#21517;&#26694;&#26550;&#65292;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;&#36229;&#22270;&#25490;&#21517;&#24314;&#27169;&#38598;&#25104;&#25512;&#33616;&#31995;&#32479;&#30340;&#12290;&#36229;&#22270;&#21487;&#20197;&#24314;&#27169;&#39640;&#38454;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2306.12800</link><description>&lt;p&gt;
HypeRS&#65306;&#26500;&#24314;&#22522;&#20110;&#36229;&#22270;&#39537;&#21160;&#30340;&#38598;&#25104;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
HypeRS: Building a Hypergraph-driven ensemble Recommender System. (arXiv:2306.12800v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12800
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#38598;&#25104;&#25512;&#33616;&#31995;&#32479;&#65292;&#23558;&#19981;&#21516;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#32467;&#21512;&#25104;&#19968;&#20010;&#36229;&#22270;&#25490;&#21517;&#26694;&#26550;&#65292;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;&#36229;&#22270;&#25490;&#21517;&#24314;&#27169;&#38598;&#25104;&#25512;&#33616;&#31995;&#32479;&#30340;&#12290;&#36229;&#22270;&#21487;&#20197;&#24314;&#27169;&#39640;&#38454;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#39044;&#27979;&#29992;&#25143;&#23545;&#29289;&#21697;&#30340;&#20559;&#22909;&#12290;&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#38598;&#25104;&#25512;&#33616;&#31995;&#32479;&#65292;&#23558;&#19981;&#21516;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#32467;&#21512;&#25104;&#19968;&#20010;&#32479;&#19968;&#30340;&#36229;&#22270;&#25490;&#21517;&#26694;&#26550;&#65292;&#36825;&#26159;&#31532;&#19968;&#27425;&#20351;&#29992;&#36229;&#22270;&#25490;&#21517;&#24314;&#27169;&#25512;&#33616;&#31995;&#32479;&#30340;&#38598;&#25104;&#12290;&#36229;&#22270;&#26159;&#22270;&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#24314;&#27169;&#39640;&#38454;&#20851;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19981;&#21516;&#30340;&#25512;&#33616;&#31995;&#32479;&#20998;&#37197;&#19981;&#21516;&#30340;&#36229;&#36793;&#26435;&#37325;&#26469;&#21306;&#20998;&#29992;&#25143;&#21644;&#29289;&#21697;&#20043;&#38388;&#30340;&#23454;&#38469;&#21644;&#39044;&#27979;&#36830;&#25509;&#65292;&#24182;&#22312;&#30005;&#24433;&#12289;&#38899;&#20048;&#21644;&#26032;&#38395;&#39046;&#22495;&#30340;&#22235;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems are designed to predict user preferences over collections of items. These systems process users' previous interactions to decide which items should be ranked higher to satisfy their desires. An ensemble recommender system can achieve great recommendation performance by effectively combining the decisions generated by individual models. In this paper, we propose a novel ensemble recommender system that combines predictions made by different models into a unified hypergraph ranking framework. This is the first time that hypergraph ranking has been employed to model an ensemble of recommender systems. Hypergraphs are generalizations of graphs where multiple vertices can be connected via hyperedges, efficiently modeling high-order relations. We differentiate real and predicted connections between users and items by assigning different hyperedge weights to individual recommender systems. We perform experiments using four datasets from the fields of movie, music and news 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#22312;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#27867;&#21270;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#23450;&#20041;&#20102;&#20174;&#19977;&#20010;&#26041;&#38754;&#34913;&#37327;OOD&#40065;&#26834;&#24615;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#19982;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#27604;&#36739;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#30340;OOD&#40065;&#26834;&#24615;&#36739;&#24369;&#65292;&#29305;&#21035;&#26159;&#22312;&#38754;&#21521;&#20219;&#21153;&#30340;&#36229;&#20986;&#20998;&#24067;&#22330;&#26223;&#20013;&#26356;&#20026;&#26126;&#26174;&#12290;&#38024;&#23545;&#36896;&#25104;&#40065;&#26834;&#24615;&#36739;&#24369;&#30340;&#21407;&#22240;&#65292;&#25552;&#20986;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2306.12756</link><description>&lt;p&gt;
&#20851;&#20110;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;:&#22522;&#20110;&#36229;&#20986;&#20998;&#24067;&#35270;&#35282;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Robustness of Generative Retrieval Models: An Out-of-Distribution Perspective. (arXiv:2306.12756v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12756
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#22312;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#27867;&#21270;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#23450;&#20041;&#20102;&#20174;&#19977;&#20010;&#26041;&#38754;&#34913;&#37327;OOD&#40065;&#26834;&#24615;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#19982;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#27604;&#36739;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#30340;OOD&#40065;&#26834;&#24615;&#36739;&#24369;&#65292;&#29305;&#21035;&#26159;&#22312;&#38754;&#21521;&#20219;&#21153;&#30340;&#36229;&#20986;&#20998;&#24067;&#22330;&#26223;&#20013;&#26356;&#20026;&#26126;&#26174;&#12290;&#38024;&#23545;&#36896;&#25104;&#40065;&#26834;&#24615;&#36739;&#24369;&#30340;&#21407;&#22240;&#65292;&#25552;&#20986;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#29983;&#25104;&#24335;&#26816;&#32034;&#22312;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#26085;&#30410;&#21463;&#21040;&#20851;&#27880;&#65292;&#23427;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#26631;&#35782;&#31526;&#26469;&#26816;&#32034;&#25991;&#26723;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#20154;&#20204;&#24050;&#32463;&#20184;&#20986;&#20102;&#24456;&#22810;&#21162;&#21147;&#26469;&#24320;&#21457;&#26377;&#25928;&#30340;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22312;&#40065;&#26834;&#24615;&#26041;&#38754;&#21364;&#24471;&#21040;&#30340;&#20851;&#27880;&#36739;&#23569;&#12290;&#24403;&#19968;&#20010;&#26032;&#30340;&#26816;&#32034;&#33539;&#24335;&#36827;&#20837;&#21040;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#26102;&#65292;&#34913;&#37327;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#27867;&#21270;&#20063;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#21363;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#22914;&#20309;&#27867;&#21270;&#21040;&#26032;&#30340;&#20998;&#24067;&#20013;&#12290;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#20174;&#26816;&#32034;&#38382;&#39064;&#30340;&#19977;&#20010;&#26041;&#38754;&#23450;&#20041;OOD&#40065;&#26834;&#24615;&#65306;1&#65289;&#26597;&#35810;&#21464;&#21270;&#65307;2&#65289;&#26410;&#30693;&#30340;&#26597;&#35810;&#31867;&#22411;&#65307;3&#65289;&#26410;&#30693;&#20219;&#21153;&#12290;&#22522;&#20110;&#36825;&#20010;&#20998;&#31867;&#27861;&#65292;&#25105;&#20204;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#20998;&#26512;&#20102;&#20960;&#20010;&#20195;&#34920;&#24615;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#19982;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#22312;OOD&#40065;&#26834;&#24615;&#26041;&#38754;&#30340;&#27604;&#36739;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#30340;OOD&#40065;&#26834;&#24615;&#27604;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#24369;&#65292;&#29305;&#21035;&#26159;&#22312;&#38754;&#21521;&#20219;&#21153;&#30340;OOD&#22330;&#26223;&#20013;&#26356;&#26126;&#26174;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#36896;&#25104;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#40065;&#26834;&#24615;&#36739;&#24369;&#30340;&#21407;&#22240;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#21892;&#23427;&#20204;OOD&#27867;&#21270;&#24615;&#33021;&#30340;&#28508;&#22312;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, we have witnessed generative retrieval increasingly gaining attention in the information retrieval (IR) field, which retrieves documents by directly generating their identifiers. So far, much effort has been devoted to developing effective generative retrieval models. There has been less attention paid to the robustness perspective. When a new retrieval paradigm enters into the real-world application, it is also critical to measure the out-of-distribution (OOD) generalization, i.e., how would generative retrieval models generalize to new distributions. To answer this question, firstly, we define OOD robustness from three perspectives in retrieval problems: 1) The query variations; 2) The unforeseen query types; and 3) The unforeseen tasks. Based on this taxonomy, we conduct empirical studies to analyze the OOD robustness of several representative generative retrieval models against dense retrieval models. The empirical results indicate that the OOD robustness of generative re
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#32508;&#36848;&#20840;&#38754;&#24635;&#32467;&#20102;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#21644;&#36235;&#21183;&#65292;&#21253;&#25324;&#25512;&#33616;&#31995;&#32479;&#20998;&#31867;&#65292;&#30693;&#35782;&#25512;&#33616;&#31995;&#32479;&#65292;&#40065;&#26834;&#24615;&#65292;&#25968;&#25454;&#20559;&#35265;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#20197;&#21450;&#35780;&#20272;&#24230;&#37327;&#12290;&#35813;&#30740;&#31350;&#36824;&#25552;&#20379;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26032;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2306.12680</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#26368;&#26032;&#21457;&#23637;&#65306;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Recent Developments in Recommender Systems: A Survey. (arXiv:2306.12680v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#32508;&#36848;&#20840;&#38754;&#24635;&#32467;&#20102;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#21644;&#36235;&#21183;&#65292;&#21253;&#25324;&#25512;&#33616;&#31995;&#32479;&#20998;&#31867;&#65292;&#30693;&#35782;&#25512;&#33616;&#31995;&#32479;&#65292;&#40065;&#26834;&#24615;&#65292;&#25968;&#25454;&#20559;&#35265;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#20197;&#21450;&#35780;&#20272;&#24230;&#37327;&#12290;&#35813;&#30740;&#31350;&#36824;&#25552;&#20379;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26032;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#25216;&#26415;&#32508;&#36848;&#20840;&#38754;&#24635;&#32467;&#20102;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#30340;&#26159;&#25552;&#20379;&#39046;&#22495;&#20869;&#29616;&#29366;&#30340;&#27010;&#36848;&#65292;&#24182;&#24378;&#35843;&#25512;&#33616;&#31995;&#32479;&#21457;&#23637;&#30340;&#26368;&#26032;&#36235;&#21183;&#12290;&#35813;&#30740;&#31350;&#39318;&#20808;&#20840;&#38754;&#24635;&#32467;&#20102;&#20027;&#35201;&#25512;&#33616;&#31995;&#32479;&#20998;&#31867;&#26041;&#27861;&#65292;&#21253;&#25324;&#20010;&#24615;&#21270;&#21644;&#32676;&#32452;&#25512;&#33616;&#31995;&#32479;&#65292;&#28982;&#21518;&#28145;&#20837;&#25506;&#35752;&#20102;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#33616;&#31995;&#32479;&#31867;&#21035;&#12290;&#27492;&#22806;&#65292;&#35813;&#32508;&#36848;&#20998;&#26512;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#40065;&#26834;&#24615;&#12289;&#25968;&#25454;&#20559;&#35265;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#24182;&#24635;&#32467;&#20102;&#35780;&#20272;&#24230;&#37327;&#29992;&#20110;&#35780;&#20272;&#36825;&#20123;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#20851;&#25512;&#33616;&#31995;&#32479;&#21457;&#23637;&#30340;&#26368;&#26032;&#36235;&#21183;&#30340;&#35265;&#35299;&#65292;&#24182;&#24378;&#35843;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26032;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this technical survey, we comprehensively summarize the latest advancements in the field of recommender systems. The objective of this study is to provide an overview of the current state-of-the-art in the field and highlight the latest trends in the development of recommender systems. The study starts with a comprehensive summary of the main taxonomy of recommender systems, including personalized and group recommender systems, and then delves into the category of knowledge-based recommender systems. In addition, the survey analyzes the robustness, data bias, and fairness issues in recommender systems, summarizing the evaluation metrics used to assess the performance of these systems. Finally, the study provides insights into the latest trends in the development of recommender systems and highlights the new directions for future research in the field.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#38382;&#39064;&#8212;&#8212;&#22810;&#20998;&#24067;&#20449;&#24687;&#26816;&#32034;&#65292;&#24182;&#36890;&#36807;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#31616;&#21333;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21487;&#38450;&#27490;&#24050;&#30693;&#39046;&#22495;&#28040;&#32791;&#22823;&#37096;&#20998;&#26816;&#32034;&#39044;&#31639;&#65292;&#24179;&#22343;&#25552;&#39640;Recall @ 100&#28857;3.8+&#65292;&#26368;&#39640;&#21487;&#36798;8.0&#20010;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.12601</link><description>&lt;p&gt;
&#22810;&#20998;&#24067;&#31264;&#23494;&#20449;&#24687;&#26816;&#32034;&#30340;&#36164;&#28304;&#21644;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Resources and Evaluations for Multi-Distribution Dense Information Retrieval. (arXiv:2306.12601v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12601
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#38382;&#39064;&#8212;&#8212;&#22810;&#20998;&#24067;&#20449;&#24687;&#26816;&#32034;&#65292;&#24182;&#36890;&#36807;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#31616;&#21333;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21487;&#38450;&#27490;&#24050;&#30693;&#39046;&#22495;&#28040;&#32791;&#22823;&#37096;&#20998;&#26816;&#32034;&#39044;&#31639;&#65292;&#24179;&#22343;&#25552;&#39640;Recall @ 100&#28857;3.8+&#65292;&#26368;&#39640;&#21487;&#36798;8.0&#20010;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#24182;&#23450;&#20041;&#20102;&#22810;&#20998;&#24067;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#30340;&#26032;&#38382;&#39064;&#65292;&#21363;&#22312;&#32473;&#23450;&#26597;&#35810;&#30340;&#24773;&#20917;&#19979;&#65292;&#31995;&#32479;&#38656;&#35201;&#20174;&#22810;&#20010;&#38598;&#21512;&#20013;&#26816;&#32034;&#20986;&#27573;&#33853;&#65292;&#27599;&#20010;&#38598;&#21512;&#37117;&#26469;&#33258;&#19981;&#21516;&#30340;&#20998;&#24067;&#12290;&#20854;&#20013;&#19968;&#20123;&#38598;&#21512;&#21644;&#20998;&#24067;&#21487;&#33021;&#22312;&#35757;&#32451;&#26102;&#19981;&#21487;&#29992;&#12290;&#20026;&#20102;&#35780;&#20272;&#22810;&#20998;&#24067;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#20174;&#29616;&#26377;&#30340;&#21333;&#20998;&#24067;&#25968;&#25454;&#38598;&#35774;&#35745;&#20102;&#19977;&#20010;&#22522;&#20934;&#65292;&#20998;&#21035;&#26159;&#22522;&#20110;&#38382;&#39064;&#22238;&#31572;&#30340;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#22522;&#20110;&#23454;&#20307;&#21305;&#37197;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#27492;&#20219;&#21153;&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#22495;&#20043;&#38388;&#25112;&#30053;&#24615;&#22320;&#20998;&#37197;&#22266;&#23450;&#30340;&#26816;&#32034;&#39044;&#31639;&#65288;&#21069;k&#20010;&#27573;&#33853;&#65289;&#65292;&#20197;&#38450;&#24050;&#30693;&#39046;&#22495;&#28040;&#32791;&#22823;&#37096;&#20998;&#39044;&#31639;&#12290;&#25105;&#20204;&#23637;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25968;&#25454;&#38598;&#19978;&#23548;&#33268;&#20102;&#24179;&#22343;3.8+&#21644;&#39640;&#36798;8.0&#20010;Recall @ 100&#28857;&#30340;&#25552;&#39640;&#65292;&#24182;&#19988;&#22312;&#24494;&#35843;&#19981;&#21516;&#30340;&#22522;&#30784;&#26816;&#32034;&#27169;&#22411;&#26102;&#25913;&#36827;&#26159;&#19968;&#33268;&#30340;&#12290;&#25105;&#20204;&#30340;&#22522;&#20934;&#20844;&#24320;&#21487;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce and define the novel problem of multi-distribution information retrieval (IR) where given a query, systems need to retrieve passages from within multiple collections, each drawn from a different distribution. Some of these collections and distributions might not be available at training time. To evaluate methods for multi-distribution retrieval, we design three benchmarks for this task from existing single-distribution datasets, namely, a dataset based on question answering and two based on entity matching. We propose simple methods for this task which allocate the fixed retrieval budget (top-k passages) strategically across domains to prevent the known domains from consuming most of the budget. We show that our methods lead to an average of 3.8+ and up to 8.0 points improvements in Recall@100 across the datasets and that improvements are consistent when fine-tuning different base retrieval models. Our benchmarks are made publicly available.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;ReLoop2&#65292;&#19968;&#31181;&#21033;&#29992;&#21709;&#24212;&#24335;&#35823;&#24046;&#34917;&#20607;&#24490;&#29615;&#26500;&#24314;&#33258;&#36866;&#24212;&#25512;&#33616;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38169;&#35823;&#35760;&#24518;&#27169;&#22359;&#26469;&#34917;&#20607;&#27169;&#22411;&#39044;&#27979;&#35823;&#24046;&#65292;&#23454;&#29616;&#24555;&#36895;&#27169;&#22411;&#36866;&#24212;&#12290;</title><link>http://arxiv.org/abs/2306.08808</link><description>&lt;p&gt;
ReLoop2: &#36890;&#36807;&#21709;&#24212;&#24335;&#35823;&#24046;&#34917;&#20607;&#24490;&#29615;&#26500;&#24314;&#33258;&#36866;&#24212;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ReLoop2: Building Self-Adaptive Recommendation Models via Responsive Error Compensation Loop. (arXiv:2306.08808v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;ReLoop2&#65292;&#19968;&#31181;&#21033;&#29992;&#21709;&#24212;&#24335;&#35823;&#24046;&#34917;&#20607;&#24490;&#29615;&#26500;&#24314;&#33258;&#36866;&#24212;&#25512;&#33616;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38169;&#35823;&#35760;&#24518;&#27169;&#22359;&#26469;&#34917;&#20607;&#27169;&#22411;&#39044;&#27979;&#35823;&#24046;&#65292;&#23454;&#29616;&#24555;&#36895;&#27169;&#22411;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#19994;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#36816;&#34892;&#30340;&#25361;&#25112;&#65292;&#20854;&#20013;&#25968;&#25454;&#20998;&#24067;&#30340;&#36716;&#31227;&#28304;&#20110;&#29992;&#25143;&#34892;&#20026;&#30340;&#28436;&#21464;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#19968;&#31181;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#20351;&#29992;&#26032;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#23450;&#26399;&#37325;&#26032;&#35757;&#32451;&#25110;&#22686;&#37327;&#26356;&#26032;&#24050;&#37096;&#32626;&#30340;&#28145;&#24230;&#27169;&#22411;&#65292;&#20135;&#29983;&#36830;&#32493;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#20256;&#32479;&#23398;&#20064;&#33539;&#24335;&#20381;&#36182;&#20110;&#23567;&#23398;&#20064;&#29575;&#30340;&#36845;&#20195;&#26799;&#24230;&#26356;&#26032;&#65292;&#20351;&#24471;&#22823;&#25512;&#33616;&#27169;&#22411;&#24456;&#38590;&#36866;&#24212;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;ReLoop2&#65292;&#19968;&#31181;&#33258;&#25105;&#32416;&#27491;&#30340;&#23398;&#20064;&#29615;&#36335;&#65292;&#36890;&#36807;&#21709;&#24212;&#24335;&#35823;&#24046;&#34917;&#20607;&#20419;&#36827;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24555;&#36895;&#27169;&#22411;&#36866;&#24212;&#12290;&#26412;&#25991;&#21463;&#20154;&#31867;&#22823;&#33041;&#20013;&#35266;&#23519;&#21040;&#30340;&#24930;-&#24555;&#20114;&#34917;&#23398;&#20064;&#31995;&#32479;&#30340;&#21551;&#21457;&#65292;&#25552;&#20986;&#19968;&#20010;&#38169;&#35823;&#35760;&#24518;&#27169;&#22359;&#65292;&#30452;&#25509;&#23384;&#20648;&#26469;&#33258;&#25968;&#25454;&#27969;&#30340;&#38169;&#35823;&#26679;&#26412;&#12290;&#38543;&#21518;&#21033;&#29992;&#36825;&#20123;&#23384;&#20648;&#30340;&#26679;&#26412;&#26469;&#34917;&#20607;&#27169;&#22411;&#39044;&#27979;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Industrial recommender systems face the challenge of operating in non-stationary environments, where data distribution shifts arise from evolving user behaviors over time. To tackle this challenge, a common approach is to periodically re-train or incrementally update deployed deep models with newly observed data, resulting in a continual training process. However, the conventional learning paradigm of neural networks relies on iterative gradient-based updates with a small learning rate, making it slow for large recommendation models to adapt. In this paper, we introduce ReLoop2, a self-correcting learning loop that facilitates fast model adaptation in online recommender systems through responsive error compensation. Inspired by the slow-fast complementary learning system observed in human brains, we propose an error memory module that directly stores error samples from incoming data streams. These stored samples are subsequently leveraged to compensate for model prediction errors durin
&lt;/p&gt;</description></item><item><title>IGB&#26159;&#19968;&#20010;&#30740;&#31350;&#25968;&#25454;&#38598;&#24037;&#20855;&#65292;&#21253;&#21547;&#21516;&#36136;&#21644;&#24322;&#36136;&#24615;&#23398;&#26415;&#22270;&#24418;&#65292;&#35268;&#27169;&#24040;&#22823;&#65292;&#24182;&#25552;&#20379;&#24037;&#20855;&#29992;&#20110;&#29983;&#25104;&#19981;&#21516;&#29305;&#24615;&#30340;&#21512;&#25104;&#22270;&#24418;&#65292;&#20026;GNN&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#35299;&#20915;&#20844;&#20849;&#22270;&#24418;&#25968;&#25454;&#38598;&#22312;&#26631;&#35760;&#12289;&#29305;&#24449;&#12289;&#24322;&#36136;&#24615;&#21644;&#22823;&#23567;&#26041;&#38754;&#24046;&#36317;&#30340;&#26377;&#20215;&#20540;&#36164;&#28304;&#12290;</title><link>http://arxiv.org/abs/2302.13522</link><description>&lt;p&gt;
IGB: &#38024;&#23545;&#20844;&#20849;&#22270;&#24418;&#25968;&#25454;&#38598;&#22312;&#26631;&#35760;&#12289;&#29305;&#24449;&#12289;&#24322;&#36136;&#24615;&#21644;&#22823;&#23567;&#26041;&#38754;&#30340;&#24046;&#36317;&#20026;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size of Public Graph Datasets for Deep Learning Research. (arXiv:2302.13522v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13522
&lt;/p&gt;
&lt;p&gt;
IGB&#26159;&#19968;&#20010;&#30740;&#31350;&#25968;&#25454;&#38598;&#24037;&#20855;&#65292;&#21253;&#21547;&#21516;&#36136;&#21644;&#24322;&#36136;&#24615;&#23398;&#26415;&#22270;&#24418;&#65292;&#35268;&#27169;&#24040;&#22823;&#65292;&#24182;&#25552;&#20379;&#24037;&#20855;&#29992;&#20110;&#29983;&#25104;&#19981;&#21516;&#29305;&#24615;&#30340;&#21512;&#25104;&#22270;&#24418;&#65292;&#20026;GNN&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#35299;&#20915;&#20844;&#20849;&#22270;&#24418;&#25968;&#25454;&#38598;&#22312;&#26631;&#35760;&#12289;&#29305;&#24449;&#12289;&#24322;&#36136;&#24615;&#21644;&#22823;&#23567;&#26041;&#38754;&#24046;&#36317;&#30340;&#26377;&#20215;&#20540;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#24418;&#31070;&#32463;&#32593;&#32476; (GNNs) &#24050;&#32463;&#23637;&#31034;&#20102;&#23545;&#20110;&#21508;&#31181;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30495;&#23454;&#24212;&#29992;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#20294; GNN &#30740;&#31350;&#20013;&#30340;&#19968;&#20010;&#20027;&#35201;&#38556;&#30861;&#26159;&#32570;&#20047;&#22823;&#35268;&#27169;&#28789;&#27963;&#30340;&#25968;&#25454;&#38598;&#12290;&#29616;&#26377;&#30340;&#22823;&#37096;&#20998;&#20844;&#20849;GNN&#25968;&#25454;&#38598;&#37117;&#30456;&#23545;&#36739;&#23567;&#65292;&#36825;&#38480;&#21046;&#20102; GNN &#30340;&#25512;&#24191;&#21040;&#26410;&#30693;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#24456;&#23569;&#26377;&#22823;&#22411;&#30340;&#22270;&#24418;&#25968;&#25454;&#38598;&#25552;&#20379;&#20016;&#23500;&#30340;&#26631;&#35760;&#25968;&#25454;&#65292;&#36825;&#20351;&#24471;&#38590;&#20197;&#30830;&#23450; GNN &#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#30340;&#20302;&#20934;&#30830;&#24615;&#26159;&#30001;&#20110;&#35757;&#32451;&#25968;&#25454;&#19981;&#36275;&#36824;&#26159;&#27169;&#22411;&#26080;&#27861;&#25512;&#24191;&#12290;&#27492;&#22806;&#65292;&#35757;&#32451; GNN &#30340;&#25968;&#25454;&#38598;&#38656;&#35201;&#25552;&#20379;&#28789;&#27963;&#24615;&#65292;&#20197;&#20415;&#28145;&#20837;&#30740;&#31350;&#21508;&#31181;&#22240;&#32032;&#23545; GNN &#27169;&#22411;&#35757;&#32451;&#30340;&#24433;&#21709;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20234;&#21033;&#35834;&#20234;&#22270;&#24418;&#22522;&#20934; (IGB)&#65292;&#36825;&#26159;&#19968;&#20010;&#30740;&#31350;&#25968;&#25454;&#38598;&#24037;&#20855;&#65292;&#24320;&#21457;&#20154;&#21592;&#21487;&#20197;&#20351;&#29992;&#23427;&#26469;&#39640;&#31934;&#24230;&#22320;&#35757;&#32451;&#12289;&#23457;&#26597;&#21644;&#31995;&#32479;&#22320;&#35780;&#20272;GNN&#27169;&#22411;&#12290;IGB &#21253;&#25324;&#21516;&#36136;&#21644;&#24322;&#36136;&#24615;&#23398;&#26415;&#22270;&#24418;&#65292;&#35268;&#27169;&#24040;&#22823;&#65292;&#24182;&#19988;&#21487;&#20197;&#26631;&#35760;&#21644;&#25805;&#20316;&#65292;&#20197;&#27169;&#25311;&#30495;&#23454;&#22330;&#26223;&#12290;&#35813;&#25968;&#25454;&#38598;&#36824;&#21253;&#25324;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#19981;&#21516;&#29305;&#24615;&#30340;&#21512;&#25104;&#22270;&#24418;&#30340;&#24037;&#20855;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#25506;&#32034;&#21508;&#31181;&#22270;&#24418;&#29305;&#24615;&#23545; GNN &#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30456;&#20449;&#65292;&#20234;&#21033;&#35834;&#20234;&#22270;&#24418;&#22522;&#20934;&#23558;&#20026; GNN &#30740;&#31350;&#22242;&#20307;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#36164;&#28304;&#65292;&#20197;&#35299;&#20915;&#20844;&#20849;&#22270;&#24418;&#25968;&#25454;&#38598;&#22312;&#26631;&#35760;&#12289;&#29305;&#24449;&#12289;&#24322;&#36136;&#24615;&#21644;&#22823;&#23567;&#26041;&#38754;&#30340;&#24046;&#36317;&#65292;&#20197;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have shown high potential for a variety of real-world, challenging applications, but one of the major obstacles in GNN research is the lack of large-scale flexible datasets. Most existing public datasets for GNNs are relatively small, which limits the ability of GNNs to generalize to unseen data. The few existing large-scale graph datasets provide very limited labeled data. This makes it difficult to determine if the GNN model's low accuracy for unseen data is inherently due to insufficient training data or if the model failed to generalize. Additionally, datasets used to train GNNs need to offer flexibility to enable a thorough study of the impact of various factors while training GNN models.  In this work, we introduce the Illinois Graph Benchmark (IGB), a research dataset tool that the developers can use to train, scrutinize and systematically evaluate GNN models with high fidelity. IGB includes both homogeneous and heterogeneous academic graphs of enorm
&lt;/p&gt;</description></item></channel></rss>