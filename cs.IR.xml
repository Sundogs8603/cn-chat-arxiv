<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26500;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;MultiVENT&#30340;&#22810;&#35821;&#35328;&#12289;&#20107;&#20214;&#20026;&#20013;&#24515;&#30340;&#35270;&#39057;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#26032;&#38395;&#24191;&#25773;&#35270;&#39057;&#21644;&#38750;&#19987;&#19994;&#27963;&#21160;&#32032;&#26448;&#12290;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#35821;&#35328;&#35270;&#39057;&#26816;&#32034;&#27169;&#22411;&#20316;&#20026;&#20351;&#29992;MultiVENT&#36827;&#34892;&#20449;&#24687;&#26816;&#32034;&#30340;&#22522;&#32447;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2307.03153</link><description>&lt;p&gt;
MultiVENT&#65306;&#20855;&#26377;&#23545;&#40784;&#30340;&#33258;&#28982;&#25991;&#26412;&#30340;&#22810;&#35821;&#35328;&#27963;&#21160;&#35270;&#39057;
&lt;/p&gt;
&lt;p&gt;
MultiVENT: Multilingual Videos of Events with Aligned Natural Text. (arXiv:2307.03153v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03153
&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;MultiVENT&#30340;&#22810;&#35821;&#35328;&#12289;&#20107;&#20214;&#20026;&#20013;&#24515;&#30340;&#35270;&#39057;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#26032;&#38395;&#24191;&#25773;&#35270;&#39057;&#21644;&#38750;&#19987;&#19994;&#27963;&#21160;&#32032;&#26448;&#12290;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#35821;&#35328;&#35270;&#39057;&#26816;&#32034;&#27169;&#22411;&#20316;&#20026;&#20351;&#29992;MultiVENT&#36827;&#34892;&#20449;&#24687;&#26816;&#32034;&#30340;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27599;&#26085;&#26032;&#38395;&#25253;&#36947;&#24050;&#20174;&#20256;&#32479;&#30340;&#24191;&#25773;&#36716;&#21521;&#21508;&#31181;&#26410;&#32463;&#32534;&#36753;&#30340;&#31532;&#19968;&#25163;&#35270;&#39057;&#32032;&#26448;&#31561;&#22810;&#31181;&#21576;&#29616;&#26041;&#24335;&#12290;&#21453;&#26144;&#22312;&#32447;&#19978;&#21487;&#29992;&#30340;&#22810;&#27169;&#24577;&#12289;&#22810;&#35821;&#35328;&#26032;&#38395;&#26469;&#28304;&#30340;&#25968;&#25454;&#38598;&#21487;&#20197;&#29992;&#26469;&#25945;&#25480;&#27169;&#22411;&#20174;&#36825;&#31181;&#36716;&#21464;&#20013;&#21463;&#30410;&#65292;&#20294;&#29616;&#26377;&#30340;&#26032;&#38395;&#35270;&#39057;&#25968;&#25454;&#38598;&#20027;&#35201;&#20851;&#27880;&#20026;&#33521;&#35821;&#21548;&#20247;&#21046;&#20316;&#30340;&#20256;&#32479;&#26032;&#38395;&#24191;&#25773;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314; MultiVENT &#25968;&#25454;&#38598;&#26469;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#20197;&#20116;&#31181;&#30446;&#26631;&#35821;&#35328;&#20026;&#22522;&#30784;&#30340;&#22810;&#35821;&#35328;&#12289;&#20107;&#20214;&#20026;&#20013;&#24515;&#30340;&#35270;&#39057;&#65292;&#24182;&#21253;&#25324;&#26032;&#38395;&#24191;&#25773;&#35270;&#39057;&#21644;&#38750;&#19987;&#19994;&#27963;&#21160;&#32032;&#26448;&#65292;&#25105;&#20204;&#29992;&#20854;&#26469;&#20998;&#26512;&#22312;&#32447;&#26032;&#38395;&#35270;&#39057;&#30340;&#29616;&#29366;&#20197;&#21450;&#22914;&#20309;&#21033;&#29992;&#23427;&#20204;&#26469;&#26500;&#24314;&#24378;&#22823;&#12289;&#20934;&#30830;&#30340;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22797;&#26434;&#30340;&#22810;&#35821;&#35328;&#35270;&#39057;&#26816;&#32034;&#27169;&#22411;&#65292;&#20197;&#29992;&#20316;&#20351;&#29992; MultiVENT &#36827;&#34892;&#20449;&#24687;&#26816;&#32034;&#30340;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Everyday news coverage has shifted from traditional broadcasts towards a wide range of presentation formats such as first-hand, unedited video footage. Datasets that reflect the diverse array of multimodal, multilingual news sources available online could be used to teach models to benefit from this shift, but existing news video datasets focus on traditional news broadcasts produced for English-speaking audiences. We address this limitation by constructing MultiVENT, a dataset of multilingual, event-centric videos grounded in text documents across five target languages. MultiVENT includes both news broadcast videos and non-professional event footage, which we use to analyze the state of online news videos and how they can be leveraged to build robust, factually accurate models. Finally, we provide a model for complex, multilingual video retrieval to serve as a baseline for information retrieval using MultiVENT.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;2022&#24180;&#22312;Deezer&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#19978;&#25512;&#20986;&#30340;Track Mix&#20010;&#24615;&#21270;&#27468;&#21333;&#29983;&#25104;&#31995;&#32479;&#65292;&#36890;&#36807;&#20351;&#29992;Transformer&#27169;&#22411;&#20998;&#26512;&#29992;&#25143;&#25773;&#25918;&#21015;&#34920;&#30340;&#26354;&#30446;&#24207;&#21015;&#26469;&#29983;&#25104;&#20197;&#21021;&#22987;&#38899;&#20048;&#26354;&#30446;&#20026;&#28789;&#24863;&#30340;&#8220;&#28151;&#21512;&#8221;&#25773;&#25918;&#21015;&#34920;&#65292;&#25552;&#21319;&#29992;&#25143;&#22312;Deezer&#19978;&#30340;&#38899;&#20048;&#21457;&#29616;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2307.03045</link><description>&lt;p&gt;
&#22312;&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#20013;&#20351;&#29992;Transformer&#29983;&#25104;&#27468;&#21333;&#28151;&#21512;
&lt;/p&gt;
&lt;p&gt;
Track Mix Generation on Music Streaming Services using Transformers. (arXiv:2307.03045v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;2022&#24180;&#22312;Deezer&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#19978;&#25512;&#20986;&#30340;Track Mix&#20010;&#24615;&#21270;&#27468;&#21333;&#29983;&#25104;&#31995;&#32479;&#65292;&#36890;&#36807;&#20351;&#29992;Transformer&#27169;&#22411;&#20998;&#26512;&#29992;&#25143;&#25773;&#25918;&#21015;&#34920;&#30340;&#26354;&#30446;&#24207;&#21015;&#26469;&#29983;&#25104;&#20197;&#21021;&#22987;&#38899;&#20048;&#26354;&#30446;&#20026;&#28789;&#24863;&#30340;&#8220;&#28151;&#21512;&#8221;&#25773;&#25918;&#21015;&#34920;&#65292;&#25552;&#21319;&#29992;&#25143;&#22312;Deezer&#19978;&#30340;&#38899;&#20048;&#21457;&#29616;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Track Mix&#65292;&#36825;&#26159;&#19968;&#20010;&#20110;2022&#24180;&#22312;&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;Deezer&#19978;&#25512;&#20986;&#30340;&#20010;&#24615;&#21270;&#27468;&#21333;&#29983;&#25104;&#31995;&#32479;&#12290;Track Mix&#36890;&#36807;&#33258;&#21160;&#20026;&#29992;&#25143;&#29983;&#25104;&#20197;&#21021;&#22987;&#38899;&#20048;&#26354;&#30446;&#20026;&#28789;&#24863;&#30340;&#8220;&#28151;&#21512;&#8221;&#25773;&#25918;&#21015;&#34920;&#65292;&#35753;&#29992;&#25143;&#21487;&#20197;&#21457;&#29616;&#19982;&#20182;&#20204;&#21916;&#29233;&#30340;&#20869;&#23481;&#30456;&#20284;&#30340;&#38899;&#20048;&#12290;&#20026;&#20102;&#29983;&#25104;&#36825;&#20123;&#28151;&#21512;&#27468;&#21333;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20351;&#29992;Transformer&#27169;&#22411;&#22312;&#29992;&#25143;&#25773;&#25918;&#21015;&#34920;&#30340;&#25968;&#30334;&#19975;&#20010;&#26354;&#30446;&#24207;&#21015;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#37492;&#20110;&#36817;&#24180;&#26469;Transformers&#30340;&#26085;&#30410;&#27969;&#34892;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19982;&#20256;&#32479;&#21512;&#20316;&#36807;&#28388;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#26381;&#21153;&#20013;&#20351;&#29992;&#36825;&#31181;&#27169;&#22411;&#36827;&#34892;&#28151;&#21512;&#29983;&#25104;&#25152;&#24102;&#26469;&#30340;&#20248;&#21183;&#12289;&#19981;&#36275;&#21644;&#25216;&#26415;&#25361;&#25112;&#12290;&#33258;&#25512;&#20986;&#20197;&#26469;&#65292;Track Mix&#27599;&#22825;&#20026;&#25968;&#30334;&#19975;&#29992;&#25143;&#29983;&#25104;&#27468;&#21333;&#65292;&#22312;Deezer&#19978;&#25552;&#21319;&#20102;&#20182;&#20204;&#30340;&#38899;&#20048;&#21457;&#29616;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces Track Mix, a personalized playlist generation system released in 2022 on the music streaming service Deezer. Track Mix automatically generates "mix" playlists inspired by initial music tracks, allowing users to discover music similar to their favorite content. To generate these mixes, we consider a Transformer model trained on millions of track sequences from user playlists. In light of the growing popularity of Transformers in recent years, we analyze the advantages, drawbacks, and technical challenges of using such a model for mix generation on the service, compared to a more traditional collaborative filtering approach. Since its release, Track Mix has been generating playlists for millions of users daily, enhancing their music discovery experience on Deezer.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22810;&#32447;&#24615;&#25193;&#23637;&#31639;&#27861;&#35780;&#20272;&#26816;&#32034;&#22686;&#24378;&#27169;&#22411;&#20013;&#26816;&#32034;&#21040;&#30340;&#25968;&#25454;&#28857;&#30340;&#25968;&#25454;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#35745;&#31639;&#20854;&#25968;&#25454;&#37325;&#35201;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20462;&#21098;&#25110;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.03027</link><description>&lt;p&gt;
&#36890;&#36807;&#25968;&#25454;&#37325;&#35201;&#24615;&#23398;&#20064;&#25913;&#21892;&#26816;&#32034;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Improving Retrieval-Augmented Large Language Models via Data Importance Learning. (arXiv:2307.03027v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22810;&#32447;&#24615;&#25193;&#23637;&#31639;&#27861;&#35780;&#20272;&#26816;&#32034;&#22686;&#24378;&#27169;&#22411;&#20013;&#26816;&#32034;&#21040;&#30340;&#25968;&#25454;&#28857;&#30340;&#25968;&#25454;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#35745;&#31639;&#20854;&#25968;&#25454;&#37325;&#35201;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20462;&#21098;&#25110;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#65292;&#20363;&#22914;&#22312;&#38382;&#39064;&#22238;&#31572;&#21644;&#25968;&#25454;&#34917;&#20840;&#31561;&#20219;&#21153;&#20013;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26816;&#32034;&#22686;&#24378;&#27169;&#22411;&#30340;&#24615;&#33021;&#21463;&#21040;&#20854;&#22522;&#30784;&#26816;&#32034;&#35821;&#26009;&#30340;&#25968;&#25454;&#36136;&#37327;&#30340;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#32447;&#24615;&#25193;&#23637;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#26816;&#32034;&#21040;&#30340;&#25968;&#25454;&#28857;&#30340;&#25968;&#25454;&#37325;&#35201;&#24615;&#12290;&#22810;&#32447;&#24615;&#25193;&#23637;&#20013;&#23384;&#22312;&#25351;&#25968;&#32423;&#30340;&#39033;&#65292;&#26412;&#25991;&#30340;&#19968;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#33021;&#22815;&#31934;&#30830;&#35745;&#31639;&#20855;&#26377;&#21152;&#27861;&#25928;&#29992;&#20989;&#25968;&#21644;&#39564;&#35777;&#38598;&#30340;&#26816;&#32034;&#22686;&#24378;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#28857;&#22312;&#26816;&#32034;&#35821;&#26009;&#20013;&#30340;&#25968;&#25454;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#65288;&#949;&#65292;&#948;&#65289;-&#36817;&#20284;&#31639;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#20165;&#20462;&#21098;&#25110;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieval augmentation enables large language models to take advantage of external knowledge, for example on tasks like question answering and data imputation. However, the performance of such retrieval-augmented models is limited by the data quality of their underlying retrieval corpus. In this paper, we propose an algorithm based on multilinear extension for evaluating the data importance of retrieved data points. There are exponentially many terms in the multilinear extension, and one key contribution of this paper is a polynomial time algorithm that computes exactly, given a retrieval-augmented model with an additive utility function and a validation set, the data importance of data points in the retrieval corpus using the multilinear extension of the model's utility function. We further proposed an even more efficient ({\epsilon}, {\delta})-approximation algorithm. Our experimental results illustrate that we can enhance the performance of large language models by only pruning or r
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#19981;&#21516;&#32858;&#21512;&#26041;&#24335;&#30340;C/W/L/A&#25351;&#26631;&#36827;&#34892;&#20803;&#35780;&#20272;&#65292;&#30740;&#31350;&#21457;&#29616;&#23427;&#20204;&#22312;&#31995;&#32479;&#25490;&#21517;&#30456;&#20284;&#24615;&#12289;&#31995;&#32479;&#25490;&#21517;&#19968;&#33268;&#24615;&#21644;&#21306;&#20998;&#33021;&#21147;&#31561;&#26041;&#38754;&#20855;&#26377;&#19968;&#23450;&#30340;&#32479;&#35745;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02936</link><description>&lt;p&gt;
C/W/L/A&#25351;&#26631;&#30340;&#20803;&#35780;&#20272;&#65306;&#31995;&#32479;&#25490;&#21517;&#30456;&#20284;&#24615;&#65292;&#31995;&#32479;&#25490;&#21517;&#19968;&#33268;&#24615;&#21644;&#21306;&#20998;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
A Meta-Evaluation of C/W/L/A Metrics: System Ranking Similarity, System Ranking Consistency and Discriminative Power. (arXiv:2307.02936v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02936
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#19981;&#21516;&#32858;&#21512;&#26041;&#24335;&#30340;C/W/L/A&#25351;&#26631;&#36827;&#34892;&#20803;&#35780;&#20272;&#65292;&#30740;&#31350;&#21457;&#29616;&#23427;&#20204;&#22312;&#31995;&#32479;&#25490;&#21517;&#30456;&#20284;&#24615;&#12289;&#31995;&#32479;&#25490;&#21517;&#19968;&#33268;&#24615;&#21644;&#21306;&#20998;&#33021;&#21147;&#31561;&#26041;&#38754;&#20855;&#26377;&#19968;&#23450;&#30340;&#32479;&#35745;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;Moffat&#31561;&#20154;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;C/W/L/A&#30340;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#20998;&#26512;&#26694;&#26550;&#12290;&#36825;&#20010;&#26694;&#26550;&#20801;&#35768;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#30740;&#31350;&#20154;&#21592;&#36890;&#36807;&#28789;&#27963;&#32452;&#21512;&#29992;&#25143;&#27983;&#35272;&#27169;&#22411;&#21644;&#29992;&#25143;&#25910;&#30410;&#32858;&#21512;&#26469;&#35774;&#35745;&#35780;&#20272;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#19981;&#21516;&#32858;&#21512;&#26041;&#24335;&#30340;C/W/L/A&#25351;&#26631;&#30340;&#32479;&#35745;&#31283;&#23450;&#24615;&#23578;&#26410;&#34987;&#30740;&#31350;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20174;&#20197;&#19979;&#19977;&#20010;&#26041;&#38754;&#23545;C/W/L/A&#25351;&#26631;&#30340;&#32479;&#35745;&#31283;&#23450;&#24615;&#36827;&#34892;&#20102;&#35843;&#26597;&#65306;&#65288;1&#65289;&#32858;&#21512;&#26041;&#24335;&#20043;&#38388;&#30340;&#31995;&#32479;&#25490;&#21517;&#30456;&#20284;&#24615;&#65292;&#65288;2&#65289;&#32858;&#21512;&#26041;&#24335;&#30340;&#31995;&#32479;&#25490;&#21517;&#19968;&#33268;&#24615;&#65292;&#21644;&#65288;3&#65289;&#32858;&#21512;&#26041;&#24335;&#30340;&#21306;&#20998;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#19981;&#21516;&#30340;&#32858;&#21512;&#20989;&#25968;&#19982;Precision&#12289;Discounted Cumulative Gain (DCG)&#12289;Rank-Biased Precision (RBP)&#12289;INST&#12289;Average Precision (AP)&#21644;Expected Reciprocal Rank (ERR)&#31561;&#27983;&#35272;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#31995;&#32479;&#25490;&#21517;&#30456;&#20284;&#24615;&#12289;&#31995;&#32479;&#25490;&#21517;&#19968;&#33268;&#24615;&#21644;&#21306;&#20998;&#33021;&#21147;&#31561;&#25351;&#26631;&#35780;&#20272;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, Moffat et al. proposed an analytic framework, namely C/W/L/A, for offline evaluation metrics. This framework allows information retrieval (IR) researchers to design evaluation metrics through the flexible combination of user browsing models and user gain aggregations. However, the statistical stability of C/W/L/A metrics with different aggregations is not yet investigated. In this study, we investigate the statistical stability of C/W/L/A metrics from the perspective of: (1) the system ranking similarity among aggregations, (2) the system ranking consistency of aggregations and (3) the discriminative power of aggregations. More specifically, we combined various aggregation functions with the browsing model of Precision, Discounted Cumulative Gain (DCG), Rank-Biased Precision (RBP), INST, Average Precision (AP) and Expected Reciprocal Rank (ERR), examing their performances in terms of system ranking similarity, system ranking consistency and discriminative power on two offline
&lt;/p&gt;</description></item><item><title>PLIERS&#26159;&#19968;&#31181;&#22522;&#20110;&#27969;&#34892;&#24230;&#30340;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#20869;&#23481;&#20256;&#25773;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#22312;&#31639;&#27861;&#22797;&#26434;&#24615;&#21644;&#25512;&#33616;&#29289;&#21697;&#30340;&#20010;&#24615;&#21270;&#27700;&#24179;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#20010;&#24615;&#21270;&#12289;&#30456;&#20851;&#24615;&#21644;&#25512;&#33616;&#30340;&#26032;&#39062;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02865</link><description>&lt;p&gt;
PLIERS: &#22522;&#20110;&#27969;&#34892;&#24230;&#30340;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#20869;&#23481;&#20256;&#25773;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
PLIERS: a Popularity-Based Recommender System for Content Dissemination in Online Social Networks. (arXiv:2307.02865v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02865
&lt;/p&gt;
&lt;p&gt;
PLIERS&#26159;&#19968;&#31181;&#22522;&#20110;&#27969;&#34892;&#24230;&#30340;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#20869;&#23481;&#20256;&#25773;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#22312;&#31639;&#27861;&#22797;&#26434;&#24615;&#21644;&#25512;&#33616;&#29289;&#21697;&#30340;&#20010;&#24615;&#21270;&#27700;&#24179;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#20010;&#24615;&#21270;&#12289;&#30456;&#20851;&#24615;&#21644;&#25512;&#33616;&#30340;&#26032;&#39062;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26631;&#31614;&#30340;&#25512;&#33616;&#31995;&#32479;PLIERS&#65292;&#35813;&#31995;&#32479;&#20551;&#35774;&#29992;&#25143;&#20027;&#35201;&#23545;&#19982;&#20182;&#20204;&#24050;&#25317;&#26377;&#30340;&#29289;&#21697;&#21644;&#26631;&#31614;&#20855;&#26377;&#30456;&#20284;&#27969;&#34892;&#24230;&#30340;&#29289;&#21697;&#21644;&#26631;&#31614;&#24863;&#20852;&#36259;&#12290;PLIERS&#26088;&#22312;&#22312;&#31639;&#27861;&#22797;&#26434;&#24615;&#21644;&#25512;&#33616;&#29289;&#21697;&#30340;&#20010;&#24615;&#21270;&#27700;&#24179;&#20043;&#38388;&#21462;&#24471;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;&#36890;&#36807;&#22312;&#30495;&#23454;&#30340;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;PLIERS&#22312;&#20010;&#24615;&#21270;&#12289;&#30456;&#20851;&#24615;&#21644;&#25512;&#33616;&#30340;&#26032;&#39062;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a novel tag-based recommender system called PLIERS, which relies on the assumption that users are mainly interested in items and tags with similar popularity to those they already own. PLIERS is aimed at reaching a good tradeoff between algorithmic complexity and the level of personalization of recommended items. To evaluate PLIERS, we performed a set of experiments on real OSN datasets, demonstrating that it outperforms state-of-the-art solutions in terms of personalization, relevance, and novelty of recommendations.
&lt;/p&gt;</description></item><item><title>BHEISR&#27169;&#22411;&#36890;&#36807;&#28040;&#38500;&#36807;&#28388;&#27873;&#27819;&#25928;&#24212;&#65292;&#20419;&#36827;&#20449;&#24565;&#21644;&#35856;&#65292;&#36890;&#36807;&#21033;&#29992;&#20010;&#24615;&#21270;&#30340;&#31867;&#21035;&#20449;&#24687;&#28608;&#21457;&#29992;&#25143;&#30340;&#22909;&#22855;&#24515;&#21644;&#20852;&#36259;&#65292;&#40723;&#21169;&#29992;&#25143;&#25299;&#23485;&#20449;&#24565;&#35270;&#37326;&#21644;&#25506;&#32034;&#26032;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2307.02797</link><description>&lt;p&gt;
BHEISR: &#20174;&#20559;&#35265;&#21040;&#24179;&#34913; - &#28040;&#38500;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#33616;&#20013;&#30340;&#24847;&#35782;&#24418;&#24577;&#38548;&#31163;&#65292;&#20419;&#36827;&#20449;&#24565;&#21644;&#35856;
&lt;/p&gt;
&lt;p&gt;
BHEISR: Nudging from Bias to Balance -- Promoting Belief Harmony by Eliminating Ideological Segregation in Knowledge-based Recommendations. (arXiv:2307.02797v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02797
&lt;/p&gt;
&lt;p&gt;
BHEISR&#27169;&#22411;&#36890;&#36807;&#28040;&#38500;&#36807;&#28388;&#27873;&#27819;&#25928;&#24212;&#65292;&#20419;&#36827;&#20449;&#24565;&#21644;&#35856;&#65292;&#36890;&#36807;&#21033;&#29992;&#20010;&#24615;&#21270;&#30340;&#31867;&#21035;&#20449;&#24687;&#28608;&#21457;&#29992;&#25143;&#30340;&#22909;&#22855;&#24515;&#21644;&#20852;&#36259;&#65292;&#40723;&#21169;&#29992;&#25143;&#25299;&#23485;&#20449;&#24565;&#35270;&#37326;&#21644;&#25506;&#32034;&#26032;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#20851;&#27880;&#30340;&#26159;&#20449;&#24565;&#22833;&#34913;&#21644;&#29992;&#25143;&#20559;&#35265;&#30340;&#21152;&#21095;&#29616;&#35937;&#65292;&#36825;&#19968;&#29616;&#35937;&#20027;&#35201;&#24402;&#22240;&#20110;&#36807;&#28388;&#27873;&#27819;&#12290;&#38024;&#23545;&#36825;&#19968;&#20851;&#38190;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#20013;&#20171;&#26426;&#26500;&#65288;BHEISR&#65289;&#65292;&#23558;&#20854;&#32622;&#20110;&#29992;&#25143;&#21644;&#29616;&#26377;&#25512;&#33616;&#31995;&#32479;&#20043;&#38388;&#65292;&#20197;&#20943;&#36731;&#36807;&#28388;&#27873;&#27819;&#25928;&#24212;&#22312;&#29616;&#26377;&#25512;&#33616;&#31995;&#32479;&#20013;&#20135;&#29983;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;&#20027;&#35201;&#30446;&#26631;&#26159;&#20026;&#29992;&#25143;&#21019;&#36896;&#20449;&#24565;&#24179;&#34913;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#36807;&#28388;&#27873;&#27819;&#24102;&#26469;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;BHEISR&#27169;&#22411;&#34701;&#21512;&#20102;&#8220;&#25512;&#21160;&#29702;&#35770;&#8221;&#30340;&#21407;&#21017;&#65292;&#21516;&#26102;&#31177;&#25345;&#27665;&#20027;&#21644;&#36879;&#26126;&#30340;&#21407;&#21017;&#12290;&#23427;&#21033;&#29992;&#29992;&#25143;&#29305;&#23450;&#30340;&#31867;&#21035;&#20449;&#24687;&#26469;&#28608;&#21457;&#22909;&#22855;&#24515;&#65292;&#21363;&#20351;&#22312;&#29992;&#25143;&#21487;&#33021;&#26368;&#21021;&#35748;&#20026;&#19981;&#24863;&#20852;&#36259;&#30340;&#39046;&#22495;&#12290;&#36890;&#36807;&#36880;&#27493;&#28608;&#21457;&#23545;&#26032;&#39046;&#22495;&#30340;&#20852;&#36259;&#65292;&#35813;&#27169;&#22411;&#40723;&#21169;&#29992;&#25143;&#25299;&#23485;&#20449;&#24565;&#35270;&#37326;&#24182;&#25506;&#32034;&#20182;&#20204;&#36890;&#24120;&#24573;&#35270;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20855;&#26377;&#26102;&#38388;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the realm of personalized recommendation systems, the increasing concern is the amplification of belief imbalance and user biases, a phenomenon primarily attributed to the filter bubble. Addressing this critical issue, we introduce an innovative intermediate agency (BHEISR) between users and existing recommendation systems to attenuate the negative repercussions of the filter bubble effect in extant recommendation systems. The main objective is to strike a belief balance for users while minimizing the detrimental influence caused by filter bubbles. The BHEISR model amalgamates principles from nudge theory while upholding democratic and transparent principles. It harnesses user-specific category information to stimulate curiosity, even in areas users might initially deem uninteresting. By progressively stimulating interest in novel categories, the model encourages users to broaden their belief horizons and explore the information they typically overlook. Our model is time-sensitive a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25512;&#33616;&#26694;&#26550;&#65292;&#21517;&#20026;&#36328;&#27169;&#24577;&#20869;&#23481;&#25512;&#29702;&#19982;&#29305;&#24449;&#22686;&#24378;&#25512;&#33616; (CIERec)&#65292;&#21033;&#29992;&#22810;&#27169;&#24577;&#20449;&#24687;&#26469;&#25913;&#21892;&#20919;&#21551;&#21160;&#25512;&#33616;&#24615;&#33021;&#65292;&#24341;&#20837;&#22270;&#20687;&#27880;&#37322;&#20316;&#20026;&#29305;&#26435;&#20449;&#24687;&#65292;&#36890;&#36807;&#34701;&#21512;&#21327;&#21516;&#12289;&#35270;&#35273;&#21644;&#35821;&#20041;&#20449;&#24687;&#26469;&#22686;&#24378;&#20869;&#23481;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2307.02761</link><description>&lt;p&gt;
&#36328;&#27169;&#24577;&#20869;&#23481;&#25512;&#29702;&#19982;&#29305;&#24449;&#22686;&#24378;&#29992;&#20110;&#20919;&#21551;&#21160;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Cross-Modal Content Inference and Feature Enrichment for Cold-Start Recommendation. (arXiv:2307.02761v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02761
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25512;&#33616;&#26694;&#26550;&#65292;&#21517;&#20026;&#36328;&#27169;&#24577;&#20869;&#23481;&#25512;&#29702;&#19982;&#29305;&#24449;&#22686;&#24378;&#25512;&#33616; (CIERec)&#65292;&#21033;&#29992;&#22810;&#27169;&#24577;&#20449;&#24687;&#26469;&#25913;&#21892;&#20919;&#21551;&#21160;&#25512;&#33616;&#24615;&#33021;&#65292;&#24341;&#20837;&#22270;&#20687;&#27880;&#37322;&#20316;&#20026;&#29305;&#26435;&#20449;&#24687;&#65292;&#36890;&#36807;&#34701;&#21512;&#21327;&#21516;&#12289;&#35270;&#35273;&#21644;&#35821;&#20041;&#20449;&#24687;&#26469;&#22686;&#24378;&#20869;&#23481;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23186;&#20307;&#25512;&#33616;&#26088;&#22312;&#34701;&#21512;&#29289;&#21697;&#30340;&#22810;&#27169;&#24577;&#20449;&#24687;&#65292;&#36890;&#36807;&#29305;&#24449;&#22686;&#24378;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#22522;&#20110;&#21327;&#21516;&#20449;&#24687;&#24341;&#20837;&#22810;&#27169;&#24577;&#20449;&#24687;&#65292;&#20197;&#25552;&#39640;&#25972;&#20307;&#25512;&#33616;&#31934;&#24230;&#65292;&#20294;&#26410;&#25506;&#32034;&#20919;&#21551;&#21160;&#25512;&#33616;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#20165;&#36866;&#29992;&#20110;&#24403;&#26377;&#22810;&#27169;&#24577;&#25968;&#25454;&#21487;&#29992;&#26102;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25512;&#33616;&#26694;&#26550;&#65292;&#21629;&#21517;&#20026;&#36328;&#27169;&#24577;&#20869;&#23481;&#25512;&#29702;&#19982;&#29305;&#24449;&#22686;&#24378;&#25512;&#33616; (CIERec)&#65292;&#23427;&#21033;&#29992;&#22810;&#27169;&#24577;&#20449;&#24687;&#26469;&#25913;&#21892;&#20854;&#20919;&#21551;&#21160;&#25512;&#33616;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;CIERec&#39318;&#20808;&#22312;&#35757;&#32451;&#38454;&#27573;&#24341;&#20837;&#22270;&#20687;&#27880;&#37322;&#20316;&#20026;&#29305;&#26435;&#20449;&#24687;&#65292;&#20197;&#24110;&#21161;&#25351;&#23548;&#20174;&#35270;&#35273;&#31354;&#38388;&#21040;&#35821;&#20041;&#31354;&#38388;&#30340;&#32479;&#19968;&#29305;&#24449;&#26144;&#23556;&#12290;&#28982;&#21518;&#65292;CIERec&#36890;&#36807;&#21327;&#21516;&#12289;&#35270;&#35273;&#21644;&#35821;&#20041;&#20449;&#24687;&#30340;&#34701;&#21512;&#26469;&#22686;&#24378;&#20869;&#23481;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimedia recommendation aims to fuse the multi-modal information of items for feature enrichment to improve the recommendation performance. However, existing methods typically introduce multi-modal information based on collaborative information to improve the overall recommendation precision, while failing to explore its cold-start recommendation performance. Meanwhile, these above methods are only applicable when such multi-modal data is available. To address this problem, this paper proposes a recommendation framework, named Cross-modal Content Inference and Feature Enrichment Recommendation (CIERec), which exploits the multi-modal information to improve its cold-start recommendation performance. Specifically, CIERec first introduces image annotation as the privileged information to help guide the mapping of unified features from the visual space to the semantic space in the training phase. And then CIERec enriches the content representation with the fusion of collaborative, visual
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#21512;&#29702;&#21270;&#26041;&#27861;KGRec&#65292;&#29992;&#20110;&#30693;&#35782;&#24863;&#30693;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#36890;&#36807;&#20851;&#27880;&#30693;&#35782;&#21512;&#29702;&#21270;&#26426;&#21046;&#21644;&#29983;&#25104;&#23545;&#27604;&#24230;&#33258;&#30417;&#30563;&#20219;&#21153;&#65292;KGRec&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#26377;&#20449;&#24687;&#37327;&#30340;&#30693;&#35782;&#36830;&#25509;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#36830;&#25509;&#36827;&#34892;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2307.02759</link><description>&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#33258;&#30417;&#30563;&#21512;&#29702;&#21270;&#26041;&#27861;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Knowledge Graph Self-Supervised Rationalization for Recommendation. (arXiv:2307.02759v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02759
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#21512;&#29702;&#21270;&#26041;&#27861;KGRec&#65292;&#29992;&#20110;&#30693;&#35782;&#24863;&#30693;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#36890;&#36807;&#20851;&#27880;&#30693;&#35782;&#21512;&#29702;&#21270;&#26426;&#21046;&#21644;&#29983;&#25104;&#23545;&#27604;&#24230;&#33258;&#30417;&#30563;&#20219;&#21153;&#65292;KGRec&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#26377;&#20449;&#24687;&#37327;&#30340;&#30693;&#35782;&#36830;&#25509;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#36830;&#25509;&#36827;&#34892;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#21512;&#29702;&#21270;&#26041;&#27861;&#65292;&#31216;&#20026;KGRec&#65292;&#29992;&#20110;&#30693;&#35782;&#24863;&#30693;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#20026;&#20102;&#26377;&#25928;&#22320;&#35782;&#21035;&#26377;&#20449;&#24687;&#37327;&#30340;&#30693;&#35782;&#36830;&#25509;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#27880;&#30693;&#35782;&#21512;&#29702;&#21270;&#26426;&#21046;&#65292;&#20026;&#30693;&#35782;&#19977;&#20803;&#32452;&#29983;&#25104;&#21512;&#29702;&#21270;&#24471;&#20998;&#12290;&#36890;&#36807;&#36825;&#20123;&#24471;&#20998;&#65292;KGRec&#36890;&#36807;&#21512;&#29702;&#21270;&#25513;&#30721;&#38598;&#25104;&#29983;&#25104;&#21644;&#23545;&#27604;&#24230;&#33258;&#30417;&#30563;&#20219;&#21153;&#36827;&#34892;&#25512;&#33616;&#12290;&#20026;&#20102;&#31361;&#20986;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#21512;&#29702;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#20197;&#25513;&#30721;&#37325;&#24314;&#24418;&#24335;&#30340;&#26032;&#22411;&#29983;&#25104;&#20219;&#21153;&#12290;&#36890;&#36807;&#20351;&#29992;&#39640;&#21512;&#29702;&#21270;&#24471;&#20998;&#23545;&#37325;&#35201;&#30693;&#35782;&#36827;&#34892;&#25513;&#30721;&#65292;KGRec&#34987;&#35757;&#32451;&#26469;&#37325;&#24314;&#24182;&#31361;&#20986;&#26377;&#29992;&#30340;&#30693;&#35782;&#36830;&#25509;&#65292;&#20316;&#20026;&#21512;&#29702;&#30340;&#20381;&#25454;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#21512;&#29702;&#21270;&#21327;&#21516;&#20132;&#20114;&#23545;&#30693;&#35782;&#22270;&#35889;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#23545;&#27604;&#24230;&#23398;&#20064;&#20219;&#21153;&#65292;&#23545;&#40784;&#26469;&#33258;&#30693;&#35782;&#21644;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#35270;&#22270;&#30340;&#20449;&#21495;&#12290;&#20026;&#20102;&#30830;&#20445;&#23545;&#27604;&#24230;&#30340;&#25239;&#22122;&#22768;&#24615;&#65292;&#36890;&#36807;&#21028;&#26029;&#20004;&#20010;&#22270;&#20013;&#30340;&#28508;&#22312;&#22122;&#22768;&#36793;&#32536;&#65292;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a new self-supervised rationalization method, called KGRec, for knowledge-aware recommender systems. To effectively identify informative knowledge connections, we propose an attentive knowledge rationalization mechanism that generates rational scores for knowledge triplets. With these scores, KGRec integrates generative and contrastive self-supervised tasks for recommendation through rational masking. To highlight rationales in the knowledge graph, we design a novel generative task in the form of masking-reconstructing. By masking important knowledge with high rational scores, KGRec is trained to rebuild and highlight useful knowledge connections that serve as rationales. To further rationalize the effect of collaborative interactions on knowledge graph learning, we introduce a contrastive learning task that aligns signals from knowledge and user-item interaction views. To ensure noise-resistant contrasting, potential noisy edges in both graphs judged by the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20551;&#35774;&#26816;&#32034;&#27169;&#22411;&#26080;&#27861;&#35775;&#38382;&#30446;&#26631;&#25991;&#26723;&#38598;&#65292;&#20294;&#21487;&#20197;&#35775;&#38382;&#25551;&#36848;&#30446;&#26631;&#39046;&#22495;&#30340;&#31616;&#35201;&#25991;&#26412;&#25551;&#36848;&#12290;</title><link>http://arxiv.org/abs/2307.02740</link><description>&lt;p&gt;
&#20351;&#29992;&#30446;&#26631;&#39046;&#22495;&#25551;&#36848;&#30340;&#23494;&#38598;&#26816;&#32034;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Dense Retrieval Adaptation using Target Domain Description. (arXiv:2307.02740v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02740
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20551;&#35774;&#26816;&#32034;&#27169;&#22411;&#26080;&#27861;&#35775;&#38382;&#30446;&#26631;&#25991;&#26723;&#38598;&#65292;&#20294;&#21487;&#20197;&#35775;&#38382;&#25551;&#36848;&#30446;&#26631;&#39046;&#22495;&#30340;&#31616;&#35201;&#25991;&#26412;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#65292;&#39046;&#22495;&#36866;&#24212;&#26159;&#23558;&#26816;&#32034;&#27169;&#22411;&#36866;&#24212;&#20110;&#25968;&#25454;&#20998;&#24067;&#19982;&#28304;&#39046;&#22495;&#19981;&#21516;&#30340;&#26032;&#39046;&#22495;&#30340;&#36807;&#31243;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#38598;&#20013;&#20110;&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#21487;&#20197;&#35775;&#38382;&#30446;&#26631;&#25991;&#26723;&#38598;&#65292;&#25110;&#32773;&#26159;&#30417;&#30563;&#65288;&#36890;&#24120;&#26159;&#23569;&#26679;&#26412;&#65289;&#39046;&#22495;&#36866;&#24212;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#36824;&#21487;&#20197;&#35775;&#38382;&#30446;&#26631;&#39046;&#22495;&#20013;&#65288;&#26377;&#38480;&#30340;&#65289;&#26631;&#35760;&#25968;&#25454;&#12290;&#36824;&#23384;&#22312;&#19968;&#20123;&#30740;&#31350;&#33268;&#21147;&#20110;&#25913;&#21892;&#27809;&#26377;&#36866;&#24212;&#30340;&#26816;&#32034;&#27169;&#22411;&#30340;&#38646;&#26679;&#26412;&#24615;&#33021;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20449;&#24687;&#26816;&#32034;&#20013;&#23578;&#26410;&#25506;&#32034;&#30340;&#19968;&#31867;&#26032;&#30340;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#19982;&#38646;&#26679;&#26412;&#35774;&#32622;&#31867;&#20284;&#65292;&#25105;&#20204;&#20551;&#35774;&#26816;&#32034;&#27169;&#22411;&#26080;&#27861;&#35775;&#38382;&#30446;&#26631;&#25991;&#26723;&#38598;&#65292;&#20294;&#21487;&#20197;&#35775;&#38382;&#19968;&#20010;&#31616;&#35201;&#30340;&#25991;&#26412;&#25551;&#36848;&#65292;&#35828;&#26126;&#30446;&#26631;&#39046;&#22495;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#39046;&#22495;&#23646;&#24615;&#30340;&#20998;&#31867;&#23398;&#65292;&#29992;&#20110;&#29702;&#35299;&#28304;&#39046;&#22495;&#21487;&#20197;&#36866;&#24212;&#21040;&#30446;&#26631;&#39046;&#22495;&#30340;&#19981;&#21516;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In information retrieval (IR), domain adaptation is the process of adapting a retrieval model to a new domain whose data distribution is different from the source domain. Existing methods in this area focus on unsupervised domain adaptation where they have access to the target document collection or supervised (often few-shot) domain adaptation where they additionally have access to (limited) labeled data in the target domain. There also exists research on improving zero-shot performance of retrieval models with no adaptation. This paper introduces a new category of domain adaptation in IR that is as-yet unexplored. Here, similar to the zero-shot setting, we assume the retrieval model does not have access to the target document collection. In contrast, it does have access to a brief textual description that explains the target domain. We define a taxonomy of domain attributes in retrieval tasks to understand different properties of a source domain that can be adapted to a target domain
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#31038;&#20132;&#23186;&#20307;&#19978;COVID-19&#35805;&#39064;&#23545;&#20844;&#20247;&#25509;&#31181;&#30123;&#33495;&#24577;&#24230;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#21487;&#20197;&#20998;&#26512;&#35805;&#39064;&#20849;&#40483;&#21644;&#21160;&#21147;&#36716;&#31227;&#65292;&#22686;&#21152;&#30740;&#31350;&#19982;&#20844;&#20247;&#30340;&#36879;&#26126;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.12118</link><description>&lt;p&gt;
&#21487;&#35270;&#21270;&#25506;&#31350;&#19982;COVID-19&#30123;&#33495;&#25509;&#31181;&#24577;&#24230;&#30456;&#20851;&#30340;&#35752;&#35770;&#35805;&#39064;
&lt;/p&gt;
&lt;p&gt;
Visualizing Relation Between (De)Motivating Topics and Public Stance toward COVID-19 Vaccine. (arXiv:2306.12118v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12118
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#31038;&#20132;&#23186;&#20307;&#19978;COVID-19&#35805;&#39064;&#23545;&#20844;&#20247;&#25509;&#31181;&#30123;&#33495;&#24577;&#24230;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#21487;&#20197;&#20998;&#26512;&#35805;&#39064;&#20849;&#40483;&#21644;&#21160;&#21147;&#36716;&#31227;&#65292;&#22686;&#21152;&#30740;&#31350;&#19982;&#20844;&#20247;&#30340;&#36879;&#26126;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#22312;&#24403;&#20170;&#36890;&#35759;&#20013;&#36215;&#21040;&#20102;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#20294;&#35823;&#23548;&#21644;&#24694;&#24847;&#35780;&#35770;&#24456;&#23481;&#26131;&#21344;&#25454;&#35805;&#39064;&#65292;&#24341;&#23548;&#20844;&#20247;&#33286;&#35770;&#12290;&#22312;COVID-19&#30123;&#24773;&#26399;&#38388;&#65292;&#25105;&#20204;&#30475;&#21040;&#20102;&#19981;&#23454;&#20449;&#24687;&#30340;&#24433;&#21709;&#65292;&#20844;&#20849;&#21355;&#29983;&#23448;&#21592;&#22312;&#35797;&#22270;&#28608;&#21169;&#20844;&#20247;&#25509;&#31181;&#30123;&#33495;&#26102;&#36973;&#21040;&#20102;&#37325;&#22823;&#25269;&#21046;&#12290;&#20026;&#20102;&#24212;&#23545;&#24403;&#21069;&#21644;&#20219;&#20309;&#26410;&#26469;&#30340;&#32039;&#24613;&#23041;&#32961;&#65292;&#24182;&#28608;&#21169;&#20844;&#20247;&#26397;&#30528;&#19968;&#20010;&#20849;&#21516;&#30340;&#30446;&#26631;&#21069;&#36827;&#65292;&#25105;&#20204;&#38656;&#35201;&#20102;&#35299;&#20844;&#20247;&#21160;&#21147;&#30340;&#36716;&#31227;&#20197;&#21450;&#21738;&#20123;&#35805;&#39064;&#22312;&#26222;&#36890;&#27665;&#20247;&#20013;&#26377;&#20849;&#40483;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#20197;&#26816;&#26597;&#21644;&#20998;&#26512;COVID-19&#30123;&#24773;&#26399;&#38388;Twitter-sphere&#20013;&#30340;&#35805;&#39064;&#65292;&#24182;&#20102;&#35299;&#20851;&#38190;&#22240;&#32032;&#26159;&#20160;&#20040;&#23548;&#33268;&#20844;&#20247;&#23545;&#25509;&#31181;&#30123;&#33495;&#30340;&#24577;&#24230;&#36716;&#21464;&#12290;&#35813;&#24037;&#20855;&#21487;&#20197;&#36731;&#26494;&#25512;&#24191;&#20026;&#20219;&#20309;&#24773;&#26223;&#30340;&#35270;&#35273;&#20998;&#26512;&#24037;&#20855;&#65292;&#24182;&#22686;&#21152;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#23545;&#30740;&#31350;&#20154;&#21592;&#21644;&#26222;&#36890;&#27665;&#20247;&#30340;&#36879;&#26126;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
While social media plays a vital role in communication nowadays, misinformation and trolls can easily take over the conversation and steer public opinion on these platforms. We saw the effect of misinformation during the {COVID-19} pandemic when public health officials faced significant push-back while trying to motivate the public to vaccinate. To tackle the current and any future threats in emergencies and motivate the public towards a common goal, it is essential to understand how public motivation shifts and which topics resonate among the general population. In this study, we proposed an interactive visualization tool to inspect and analyze the topics that resonated among Twitter-sphere during the {COVID-19} pandemic and understand the key factors that shifted public stance for vaccination. This tool can easily be generalized for any scenario for visual analysis and to increase the transparency of social media data for researchers and the general population alike.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;FPGA&#19978;&#30340;&#21521;&#37327;&#25628;&#32034;&#26694;&#26550;FANNS&#65292;&#23454;&#29616;&#20102;&#30828;&#20214;&#21644;&#31639;&#27861;&#30340;&#20849;&#21516;&#35774;&#35745;&#65292;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#38656;&#27714;&#21644;&#30828;&#20214;&#39044;&#31639;&#29983;&#25104;&#30456;&#24212;&#30340;&#21152;&#36895;&#22120;&#12290;&#19982;FPGA&#21644;CPU&#22522;&#20934;&#30456;&#27604;&#65292;FANNS&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#21152;&#36895;&#65292;&#24182;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11182</link><description>&lt;p&gt;
&#20026;&#21521;&#37327;&#25628;&#32034;&#36827;&#34892;&#30828;&#20214;&#21644;&#31639;&#27861;&#30340;&#20849;&#21516;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Co-design Hardware and Algorithm for Vector Search. (arXiv:2306.11182v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11182
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;FPGA&#19978;&#30340;&#21521;&#37327;&#25628;&#32034;&#26694;&#26550;FANNS&#65292;&#23454;&#29616;&#20102;&#30828;&#20214;&#21644;&#31639;&#27861;&#30340;&#20849;&#21516;&#35774;&#35745;&#65292;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#38656;&#27714;&#21644;&#30828;&#20214;&#39044;&#31639;&#29983;&#25104;&#30456;&#24212;&#30340;&#21152;&#36895;&#22120;&#12290;&#19982;FPGA&#21644;CPU&#22522;&#20934;&#30456;&#27604;&#65292;FANNS&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#21152;&#36895;&#65292;&#24182;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21521;&#37327;&#25628;&#32034;&#24050;&#25104;&#20026;&#22823;&#35268;&#27169;&#20449;&#24687;&#26816;&#32034;&#21644;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#22522;&#30784;&#65292;&#20687;Google&#21644;Bing&#36825;&#26679;&#30340;&#25628;&#32034;&#24341;&#25806;&#36890;&#36807;&#35780;&#20272;&#32534;&#30721;&#26597;&#35810;&#25991;&#26412;&#21644;&#32593;&#32476;&#25991;&#26723;&#20043;&#38388;&#30340;&#21521;&#37327;&#30456;&#20284;&#24230;&#65292;&#27599;&#31186;&#22788;&#29702;&#25968;&#19975;&#20010;&#26597;&#35810;&#65292;&#22312;&#25317;&#26377;PB&#32423;&#25991;&#26723;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#12290;&#38543;&#30528;&#23545;&#21521;&#37327;&#25628;&#32034;&#31995;&#32479;&#24615;&#33021;&#30340;&#38656;&#27714;&#28608;&#22686;&#65292;&#22312;&#25705;&#23572;&#23450;&#24459;&#26102;&#20195;&#21518;&#65292;&#21152;&#36895;&#30828;&#20214;&#25104;&#20026;&#20102;&#19968;&#20010;&#26377;&#21069;&#26223;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#22312;FPGA&#19978;&#30340;&#31471;&#21040;&#31471;&#21487;&#25193;&#23637;&#21521;&#37327;&#25628;&#32034;&#26694;&#26550;FANNS&#12290;&#32473;&#23450;&#29992;&#25143;&#25552;&#20379;&#30340;&#23545;&#25968;&#25454;&#38598;&#30340;&#21484;&#22238;&#35201;&#27714;&#21644;&#30828;&#20214;&#36164;&#28304;&#39044;&#31639;&#65292;FANNS&#33258;&#21160;&#36827;&#34892;&#30828;&#20214;&#21644;&#31639;&#27861;&#30340;&#20849;&#21516;&#35774;&#35745;&#65292;&#38543;&#21518;&#29983;&#25104;&#30456;&#24212;&#30340;&#21152;&#36895;&#22120;&#12290;&#35813;&#26694;&#26550;&#36824;&#36890;&#36807;&#22312;&#21152;&#36895;&#22120;&#20013;&#24341;&#20837;&#30828;&#20214;TCP/IP&#22534;&#26632;&#26469;&#25903;&#25345;&#35268;&#27169;&#25193;&#23637;&#12290;&#19982;FPGA&#21644;CPU&#22522;&#20934;&#30456;&#27604;&#65292;FANNS&#20998;&#21035;&#23454;&#29616;&#20102;23.0&#20493;&#21644;37.2&#20493;&#30340;&#21152;&#36895;&#65292;&#24182;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vector search has emerged as the foundation for large-scale information retrieval and machine learning systems, with search engines like Google and Bing processing tens of thousands of queries per second on petabyte-scale document datasets by evaluating vector similarities between encoded query texts and web documents. As performance demands for vector search systems surge, accelerated hardware offers a promising solution in the post-Moore's Law era. We introduce \textit{FANNS}, an end-to-end and scalable vector search framework on FPGAs. Given a user-provided recall requirement on a dataset and a hardware resource budget, \textit{FANNS} automatically co-designs hardware and algorithm, subsequently generating the corresponding accelerator. The framework also supports scale-out by incorporating a hardware TCP/IP stack in the accelerator. \textit{FANNS} attains up to 23.0$\times$ and 37.2$\times$ speedup compared to FPGA and CPU baselines, respectively, and demonstrates superior scalabil
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35752;&#35770;&#20102;&#22312;&#32447;&#24179;&#21488;&#19978;&#20869;&#23481;&#21019;&#20316;&#32773;&#28608;&#21169;&#26426;&#21046;&#30340;&#24314;&#27169;&#65292;&#36890;&#36807;&#20998;&#26512;&#31639;&#27861;&#36873;&#25321;&#23545;&#26333;&#20809;&#28216;&#25103;&#65288;&#21253;&#25324;&#29616;&#20195;&#20998;&#35299;&#21644;&#20004;&#22612;&#26550;&#26500;&#65289;&#20013;&#65288;&#32435;&#20160;&#65289;&#22343;&#34913;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#26333;&#20809;&#28216;&#25103;&#27169;&#22411;&#36827;&#34892;&#39044;&#37096;&#32626;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#20197;&#35782;&#21035;&#26399;&#26395;&#21644;&#28608;&#21169;&#20869;&#23481;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2206.13102</link><description>&lt;p&gt;
&#22312;&#31639;&#27861;&#31574;&#21010;&#24179;&#21488;&#19978;&#24314;&#27169;&#20869;&#23481;&#21019;&#20316;&#32773;&#30340;&#28608;&#21169;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Modeling Content Creator Incentives on Algorithm-Curated Platforms. (arXiv:2206.13102v2 [cs.GT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13102
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35752;&#35770;&#20102;&#22312;&#32447;&#24179;&#21488;&#19978;&#20869;&#23481;&#21019;&#20316;&#32773;&#28608;&#21169;&#26426;&#21046;&#30340;&#24314;&#27169;&#65292;&#36890;&#36807;&#20998;&#26512;&#31639;&#27861;&#36873;&#25321;&#23545;&#26333;&#20809;&#28216;&#25103;&#65288;&#21253;&#25324;&#29616;&#20195;&#20998;&#35299;&#21644;&#20004;&#22612;&#26550;&#26500;&#65289;&#20013;&#65288;&#32435;&#20160;&#65289;&#22343;&#34913;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#26333;&#20809;&#28216;&#25103;&#27169;&#22411;&#36827;&#34892;&#39044;&#37096;&#32626;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#20197;&#35782;&#21035;&#26399;&#26395;&#21644;&#28608;&#21169;&#20869;&#23481;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20869;&#23481;&#21019;&#20316;&#32773;&#22312;&#20105;&#22842;&#29992;&#25143;&#27880;&#24847;&#21147;&#12290;&#20182;&#20204;&#30340;&#24433;&#21709;&#21147;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#22312;&#32447;&#24179;&#21488;&#24320;&#21457;&#32773;&#25152;&#20570;&#30340;&#31639;&#27861;&#36873;&#25321;&#12290;&#20026;&#20102;&#26368;&#22823;&#38480;&#24230;&#22320;&#25552;&#39640;&#26333;&#20809;&#29575;&#65292;&#35768;&#22810;&#21019;&#20316;&#32773;&#37319;&#21462;&#25112;&#30053;&#24615;&#30340;&#35843;&#25972;&#65292;&#22914;&#25628;&#32034;&#24341;&#25806;&#20248;&#21270;&#34892;&#19994;&#30340;&#20363;&#23376;&#25152;&#35777;&#26126;&#12290;&#36825;&#23548;&#33268;&#20102;&#23545;&#26377;&#38480;&#29992;&#25143;&#27880;&#24847;&#21147;&#27744;&#30340;&#31454;&#20105;&#12290;&#25105;&#20204;&#22312;&#25152;&#35859;&#30340;&#26333;&#20809;&#28216;&#25103;&#20013;&#24418;&#24335;&#21270;&#20102;&#36825;&#20123;&#21160;&#24577;&#65292;&#36825;&#26159;&#19968;&#31181;&#30001;&#31639;&#27861;&#24341;&#36215;&#30340;&#28608;&#21169;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#29616;&#20195;&#20998;&#35299;&#21644;&#65288;&#28145;&#23618;&#65289;&#20004;&#22612;&#26550;&#26500;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#30475;&#20284;&#26080;&#23475;&#30340;&#31639;&#27861;&#36873;&#25321;&#65292;&#20363;&#22914;&#38750;&#36127;&#19982;&#26080;&#32422;&#26463;&#20998;&#35299;&#65292;&#22312;&#26333;&#20809;&#28216;&#25103;&#20013;&#26174;&#33879;&#24433;&#21709;&#65288;&#32435;&#20160;&#65289;&#22343;&#34913;&#30340;&#23384;&#22312;&#21644;&#29305;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21019;&#20316;&#32773;&#34892;&#20026;&#27169;&#22411;&#65292;&#22914;&#26333;&#20809;&#28216;&#25103;&#65292;&#36827;&#34892;&#65288;ex-ante&#65289;&#39044;&#37096;&#32626;&#23457;&#35745;&#12290;&#36825;&#26679;&#30340;&#23457;&#35745;&#21487;&#20197;&#35782;&#21035;&#26399;&#26395;&#21644;&#28608;&#21169;&#20869;&#23481;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#65292;&#24182;&#22312;&#20869;&#23481;&#36807;&#28388;&#21644;&#31649;&#29702;&#31561;&#20107;&#21518;&#25514;&#26045;&#19978;&#36827;&#34892;&#34917;&#20805;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Content creators compete for user attention. Their reach crucially depends on algorithmic choices made by developers on online platforms. To maximize exposure, many creators adapt strategically, as evidenced by examples like the sprawling search engine optimization industry. This begets competition for the finite user attention pool. We formalize these dynamics in what we call an exposure game, a model of incentives induced by algorithms, including modern factorization and (deep) two-tower architectures. We prove that seemingly innocuous algorithmic choices, e.g., non-negative vs. unconstrained factorization, significantly affect the existence and character of (Nash) equilibria in exposure games. We proffer use of creator behavior models, like exposure games, for an (ex-ante) pre-deployment audit. Such an audit can identify misalignment between desirable and incentivized content, and thus complement post-hoc measures like content filtering and moderation. To this end, we propose tools 
&lt;/p&gt;</description></item></channel></rss>