<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;-&#23545;&#27604;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#23545;&#27604;&#35270;&#22270;&#22686;&#24378;&#31574;&#30053;&#12289;&#20301;&#32622;&#24863;&#30693;&#21644;&#35821;&#20041;&#24863;&#30693;&#27491;&#26679;&#26412;&#37319;&#26679;&#31574;&#30053;&#20197;&#21450;&#20998;&#23618;&#23545;&#27604;&#23398;&#20064;&#31574;&#30053;&#26469;&#20811;&#26381;&#22270;&#25968;&#25454;&#22686;&#24378;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2404.02810</link><description>&lt;p&gt;
&#29983;&#25104;-&#23545;&#27604;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Generative-Contrastive Heterogeneous Graph Neural Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02810
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;-&#23545;&#27604;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#23545;&#27604;&#35270;&#22270;&#22686;&#24378;&#31574;&#30053;&#12289;&#20301;&#32622;&#24863;&#30693;&#21644;&#35821;&#20041;&#24863;&#30693;&#27491;&#26679;&#26412;&#37319;&#26679;&#31574;&#30053;&#20197;&#21450;&#20998;&#23618;&#23545;&#27604;&#23398;&#20064;&#31574;&#30053;&#26469;&#20811;&#26381;&#22270;&#25968;&#25454;&#22686;&#24378;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#26500;&#22270;&#34920;&#36798;&#20102;&#29616;&#23454;&#19990;&#30028;&#20013;&#22797;&#26434;&#20851;&#31995;&#65292;&#21253;&#25324;&#22810;&#31181;&#31867;&#22411;&#30340;&#33410;&#28857;&#21644;&#36793;&#12290;&#21463;&#33258;&#30417;&#30563;&#23398;&#20064;&#21551;&#21457;&#65292;&#23545;&#27604;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;(HGNNs)&#21033;&#29992;&#25968;&#25454;&#22686;&#24378;&#21644;&#36776;&#21035;&#22120;&#23637;&#29616;&#20102;&#24040;&#22823;&#28508;&#21147;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22270;&#30340;&#31163;&#25955;&#21644;&#25277;&#35937;&#29305;&#24615;&#65292;&#25968;&#25454;&#22686;&#24378;&#20173;&#28982;&#23384;&#22312;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;\textit{&#29983;&#25104;-&#23545;&#27604;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;(GC-HGNN)}&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02810v1 Announce Type: new  Abstract: Heterogeneous Graphs (HGs) can effectively model complex relationships in the real world by multi-type nodes and edges. In recent years, inspired by self-supervised learning, contrastive Heterogeneous Graphs Neural Networks (HGNNs) have shown great potential by utilizing data augmentation and discriminators for downstream tasks. However, data augmentation is still limited due to the discrete and abstract nature of graphs. To tackle the above limitations, we propose a novel \textit{Generative-Contrastive Heterogeneous Graph Neural Network (GC-HGNN)}. Specifically, we first propose a heterogeneous graph generative learning enhanced contrastive paradigm. This paradigm includes: 1) A contrastive view augmentation strategy by using masked autoencoder. 2) Position-aware and semantics-aware positive sample sampling strategy for generate hard negative samples. 3) A hierarchical contrastive learning strategy for capturing local and global informa
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#34701;&#21512;&#23454;&#20307;&#25551;&#36848;&#36827;&#34892;&#23454;&#20307;&#28040;&#27495;&#30340;&#32534;&#30721;-&#35299;&#30721;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2404.01626</link><description>&lt;p&gt;
&#36890;&#36807;&#34701;&#21512;&#23454;&#20307;&#35299;&#30721;&#36827;&#34892;&#23454;&#20307;&#28040;&#27495;
&lt;/p&gt;
&lt;p&gt;
Entity Disambiguation via Fusion Entity Decoding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01626
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#34701;&#21512;&#23454;&#20307;&#25551;&#36848;&#36827;&#34892;&#23454;&#20307;&#28040;&#27495;&#30340;&#32534;&#30721;-&#35299;&#30721;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#28040;&#27495;&#65288;ED&#65289;&#26159;&#23558;&#27169;&#31946;&#23454;&#20307;&#30340;&#25552;&#21450;&#38142;&#25509;&#21040;&#30693;&#35782;&#24211;&#20013;&#30340;&#25351;&#20195;&#23454;&#20307;&#30340;&#36807;&#31243;&#65292;&#22312;&#23454;&#20307;&#38142;&#25509;&#65288;EL&#65289;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#29616;&#26377;&#30340;&#29983;&#25104;&#24335;&#26041;&#27861;&#22312;&#26631;&#20934;&#21270;&#30340;ZELDA&#22522;&#20934;&#19979;&#23637;&#31034;&#20986;&#27604;&#20998;&#31867;&#26041;&#27861;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#24335;&#26041;&#27861;&#38656;&#35201;&#22823;&#35268;&#27169;&#30340;&#39044;&#35757;&#32451;&#19988;&#29983;&#25104;&#25928;&#29575;&#20302;&#19979;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#23454;&#20307;&#25551;&#36848;&#32463;&#24120;&#34987;&#24573;&#35270;&#65292;&#32780;&#36825;&#20123;&#25551;&#36848;&#21487;&#33021;&#21253;&#21547;&#21306;&#20998;&#30456;&#20284;&#23454;&#20307;&#30340;&#20851;&#38190;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32534;&#30721;-&#35299;&#30721;&#27169;&#22411;&#65292;&#20197;&#26356;&#35814;&#32454;&#30340;&#23454;&#20307;&#25551;&#36848;&#26469;&#36827;&#34892;&#23454;&#20307;&#28040;&#27495;&#12290;&#32473;&#23450;&#25991;&#26412;&#21644;&#20505;&#36873;&#23454;&#20307;&#65292;&#32534;&#30721;&#22120;&#23398;&#20064;&#25991;&#26412;&#19982;&#27599;&#20010;&#20505;&#36873;&#23454;&#20307;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#20026;&#27599;&#20010;&#23454;&#20307;&#20505;&#36873;&#20135;&#29983;&#34920;&#31034;&#12290;&#35299;&#30721;&#22120;&#38543;&#21518;&#23558;&#23454;&#20307;&#20505;&#36873;&#30340;&#34920;&#31034;&#34701;&#21512;&#22312;&#19968;&#36215;&#65292;&#24182;&#36873;&#25321;&#27491;&#30830;&#30340;&#23454;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01626v1 Announce Type: new  Abstract: Entity disambiguation (ED), which links the mentions of ambiguous entities to their referent entities in a knowledge base, serves as a core component in entity linking (EL). Existing generative approaches demonstrate improved accuracy compared to classification approaches under the standardized ZELDA benchmark. Nevertheless, generative approaches suffer from the need for large-scale pre-training and inefficient generation. Most importantly, entity descriptions, which could contain crucial information to distinguish similar entities from each other, are often overlooked. We propose an encoder-decoder model to disambiguate entities with more detailed entity descriptions. Given text and candidate entities, the encoder learns interactions between the text and each candidate entity, producing representations for each entity candidate. The decoder then fuses the representations of entity candidates together and selects the correct entity. Our 
&lt;/p&gt;</description></item><item><title>ResumeFlow&#26159;&#19968;&#31181;&#21033;&#29992;LLM&#25216;&#26415;&#30340;&#24037;&#20855;&#65292;&#33021;&#22815;&#24110;&#21161;&#27714;&#32844;&#32773;&#26681;&#25454;&#29305;&#23450;&#30340;&#32844;&#20301;&#35201;&#27714;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#31616;&#21382;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#25163;&#21160;&#23450;&#21046;&#31616;&#21382;&#30340;&#32791;&#26102;&#21644;&#23481;&#26131;&#20986;&#38169;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06221</link><description>&lt;p&gt;
ResumeFlow: &#19968;&#31181;&#20010;&#24615;&#21270;&#31616;&#21382;&#29983;&#25104;&#21644;&#20462;&#35746;&#30340;LLM&#36741;&#21161;&#27969;&#31243;
&lt;/p&gt;
&lt;p&gt;
ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06221
&lt;/p&gt;
&lt;p&gt;
ResumeFlow&#26159;&#19968;&#31181;&#21033;&#29992;LLM&#25216;&#26415;&#30340;&#24037;&#20855;&#65292;&#33021;&#22815;&#24110;&#21161;&#27714;&#32844;&#32773;&#26681;&#25454;&#29305;&#23450;&#30340;&#32844;&#20301;&#35201;&#27714;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#31616;&#21382;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#25163;&#21160;&#23450;&#21046;&#31616;&#21382;&#30340;&#32791;&#26102;&#21644;&#23481;&#26131;&#20986;&#38169;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#35768;&#22810;&#27714;&#32844;&#32773;&#26469;&#35828;&#65292;&#21046;&#20316;&#31526;&#21512;&#29305;&#23450;&#32844;&#20301;&#35201;&#27714;&#30340;&#29702;&#24819;&#31616;&#21382;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#21021;&#20837;&#32844;&#22330;&#30340;&#27714;&#32844;&#32773;&#26469;&#35828;&#12290;&#34429;&#28982;&#24378;&#28872;&#24314;&#35758;&#27714;&#32844;&#32773;&#26681;&#25454;&#20182;&#20204;&#30003;&#35831;&#30340;&#20855;&#20307;&#32844;&#20301;&#23450;&#21046;&#31616;&#21382;&#65292;&#20294;&#25163;&#21160;&#26681;&#25454;&#24037;&#20316;&#25551;&#36848;&#21644;&#32844;&#20301;&#35201;&#27714;&#26469;&#23450;&#21046;&#31616;&#21382;&#36890;&#24120; (1) &#38750;&#24120;&#32791;&#26102;&#65292;&#19988; (2) &#23481;&#26131;&#20986;&#38169;&#12290;&#27492;&#22806;&#65292;&#22312;&#30003;&#35831;&#22810;&#20010;&#32844;&#20301;&#26102;&#36827;&#34892;&#36825;&#26679;&#30340;&#23450;&#21046;&#27493;&#39588;&#21487;&#33021;&#23548;&#33268;&#32534;&#36753;&#31616;&#21382;&#36136;&#37327;&#19981;&#39640;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#26412;&#28436;&#31034;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ResumeFlow: &#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#24037;&#20855;&#65292;&#20351;&#32456;&#31471;&#29992;&#25143;&#21482;&#38656;&#25552;&#20379;&#35814;&#32454;&#30340;&#31616;&#21382;&#21644;&#25152;&#38656;&#30340;&#32844;&#20301;&#21457;&#24067;&#20449;&#24687;&#65292;&#23601;&#33021;&#22312;&#20960;&#31186;&#38047;&#20869;&#33719;&#24471;&#19968;&#20010;&#38024;&#23545;&#35813;&#29305;&#23450;&#32844;&#20301;&#21457;&#24067;&#30340;&#20010;&#24615;&#21270;&#31616;&#21382;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#27969;&#31243;&#21033;&#29992;&#20102;&#26368;&#20808;&#36827;&#30340;LLM&#65288;&#22914;OpenAI&#30340;GPT-4&#21644;Google&#30340;......&#65289;
&lt;/p&gt;
&lt;p&gt;
Crafting the ideal, job-specific resume is a challenging task for many job applicants, especially for early-career applicants. While it is highly recommended that applicants tailor their resume to the specific role they are applying for, manually tailoring resumes to job descriptions and role-specific requirements is often (1) extremely time-consuming, and (2) prone to human errors. Furthermore, performing such a tailoring step at scale while applying to several roles may result in a lack of quality of the edited resumes. To tackle this problem, in this demo paper, we propose ResumeFlow: a Large Language Model (LLM) aided tool that enables an end user to simply provide their detailed resume and the desired job posting, and obtain a personalized resume specifically tailored to that specific job posting in the matter of a few seconds. Our proposed pipeline leverages the language understanding and information extraction capabilities of state-of-the-art LLMs such as OpenAI's GPT-4 and Goog
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23439;&#35266;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MAG&#65289;&#26469;&#35299;&#20915;Graph Neural Networks&#22312;&#20159;&#32423;&#25512;&#33616;&#31995;&#32479;&#20013;&#39044;&#27979;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#30340;&#25361;&#25112;&#12290;MAG&#36890;&#36807;&#23558;&#34892;&#20026;&#27169;&#24335;&#30456;&#20284;&#30340;&#24494;&#35266;&#33410;&#28857;&#20998;&#32452;&#65292;&#23558;&#33410;&#28857;&#25968;&#37327;&#20174;&#25968;&#21313;&#20159;&#20943;&#23569;&#21040;&#25968;&#30334;&#20010;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.14939</link><description>&lt;p&gt;
&#22312;&#32447;&#20159;&#32423;&#25512;&#33616;&#31995;&#32479;&#30340;&#23439;&#35266;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Macro Graph Neural Networks for Online Billion-Scale Recommender Systems. (arXiv:2401.14939v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14939
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23439;&#35266;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MAG&#65289;&#26469;&#35299;&#20915;Graph Neural Networks&#22312;&#20159;&#32423;&#25512;&#33616;&#31995;&#32479;&#20013;&#39044;&#27979;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#30340;&#25361;&#25112;&#12290;MAG&#36890;&#36807;&#23558;&#34892;&#20026;&#27169;&#24335;&#30456;&#20284;&#30340;&#24494;&#35266;&#33410;&#28857;&#20998;&#32452;&#65292;&#23558;&#33410;&#28857;&#25968;&#37327;&#20174;&#25968;&#21313;&#20159;&#20943;&#23569;&#21040;&#25968;&#30334;&#20010;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#32858;&#21512;&#25968;&#21313;&#20159;&#20010;&#37051;&#23621;&#25152;&#28041;&#21450;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#20196;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#20159;&#32423;&#25512;&#33616;&#31995;&#32479;&#20013;&#39044;&#27979;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#38754;&#20020;&#38271;&#26399;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23439;&#35266;&#25512;&#33616;&#22270;&#65288;MAG&#65289;&#8221;&#30340;&#26356;&#36866;&#21512;&#20159;&#32423;&#25512;&#33616;&#30340;&#26041;&#27861;&#12290;MAG&#36890;&#36807;&#23558;&#34892;&#20026;&#27169;&#24335;&#30456;&#20284;&#30340;&#24494;&#35266;&#33410;&#28857;&#65288;&#29992;&#25143;&#21644;&#29289;&#21697;&#65289;&#20998;&#32452;&#65292;&#23558;&#33410;&#28857;&#25968;&#37327;&#20174;&#25968;&#21313;&#20159;&#20010;&#20943;&#23569;&#21040;&#25968;&#30334;&#20010;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22522;&#30784;&#35774;&#26045;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting Click-Through Rate (CTR) in billion-scale recommender systems poses a long-standing challenge for Graph Neural Networks (GNNs) due to the overwhelming computational complexity involved in aggregating billions of neighbors. To tackle this, GNN-based CTR models usually sample hundreds of neighbors out of the billions to facilitate efficient online recommendations. However, sampling only a small portion of neighbors results in a severe sampling bias and the failure to encompass the full spectrum of user or item behavioral patterns. To address this challenge, we name the conventional user-item recommendation graph as "micro recommendation graph" and introduce a more suitable MAcro Recommendation Graph (MAG) for billion-scale recommendations. MAG resolves the computational complexity problems in the infrastructure by reducing the node count from billions to hundreds. Specifically, MAG groups micro nodes (users and items) with similar behavior patterns to form macro nodes. Subsequ
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#39046;&#22495;&#30693;&#35782;&#30340;&#33647;&#29289;&#25512;&#33616;&#26694;&#26550;DKINet&#65292;&#23558;&#39046;&#22495;&#30693;&#35782;&#19982;&#24739;&#32773;&#20020;&#24202;&#34920;&#29616;&#30456;&#32467;&#21512;&#65292;&#27492;&#20026;&#39318;&#27425;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2305.19604</link><description>&lt;p&gt;
&#36890;&#36807;&#39046;&#22495;&#30693;&#35782;&#21551;&#31034;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#33647;&#29289;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Medication Recommendation via Domain Knowledge Informed Deep Learning. (arXiv:2305.19604v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19604
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#39046;&#22495;&#30693;&#35782;&#30340;&#33647;&#29289;&#25512;&#33616;&#26694;&#26550;DKINet&#65292;&#23558;&#39046;&#22495;&#30693;&#35782;&#19982;&#24739;&#32773;&#20020;&#24202;&#34920;&#29616;&#30456;&#32467;&#21512;&#65292;&#27492;&#20026;&#39318;&#27425;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33647;&#29289;&#25512;&#33616;&#26159;&#21307;&#30103;&#20445;&#20581;&#30340;&#22522;&#26412;&#20294;&#33267;&#20851;&#37325;&#35201;&#30340;&#20998;&#25903;&#65292;&#25552;&#20379;&#26426;&#20250;&#20026;&#22797;&#26434;&#20581;&#24247;&#29366;&#20917;&#30340;&#24739;&#32773;&#25903;&#25345;&#20020;&#24202;&#21307;&#29983;&#26356;&#31934;&#30830;&#30340;&#33647;&#29289;&#22788;&#26041;&#12290;&#20174;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20013;&#23398;&#20064;&#25512;&#33616;&#33647;&#29289;&#26159;&#20808;&#21069;&#30740;&#31350;&#20013;&#26368;&#24120;&#35265;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#24573;&#35270;&#20102;&#26681;&#25454;&#24739;&#32773;&#30340;EHR&#20013;&#30340;&#20020;&#24202;&#34920;&#29616;&#32435;&#20837;&#39046;&#22495;&#30693;&#35782;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#21160;&#24577;&#39046;&#22495;&#30693;&#35782;&#30340;&#33647;&#29289;&#25512;&#33616;&#26694;&#26550;&#65292;&#21363;&#39046;&#22495;&#30693;&#35782;&#21551;&#31034;&#32593;&#32476;&#65288;DKINet&#65289;&#65292;&#29992;&#20110;&#23558;&#39046;&#22495;&#30693;&#35782;&#19982;&#21487;&#35266;&#23519;&#30340;&#24739;&#32773;&#20020;&#24202;&#34920;&#29616;&#30456;&#32467;&#21512;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#39318;&#20808;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#39046;&#22495;&#30693;&#35782;&#30340;&#32534;&#30721;&#22120;&#26469;&#25429;&#25417;&#39046;&#22495;&#20449;&#24687;&#65292;&#28982;&#21518;&#24320;&#21457;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#32534;&#30721;&#22120;&#23558;&#39046;&#22495;&#30693;&#35782;&#25972;&#21512;&#21040;&#21487;&#35266;&#23519;&#30340;EHR&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Medication recommendation is a fundamental yet crucial branch of healthcare, which provides opportunities to support clinical physicians with more accurate medication prescriptions for patients with complex health conditions. Learning from electronic health records (EHR) to recommend medications is the most common way in previous studies. However, most of them neglect incorporating domain knowledge according to the clinical manifestations in the EHR of the patient. To address these issues, we propose a novel \textbf{D}omain \textbf{K}nowledge \textbf{I}nformed \textbf{Net}work (DKINet) to integrate domain knowledge with observable clinical manifestations of the patient, which is the first dynamic domain knowledge informed framework toward medication recommendation. In particular, we first design a knowledge-driven encoder to capture the domain information and then develop a data-driven encoder to integrate domain knowledge into the observable EHR. To endow the model with the capability
&lt;/p&gt;</description></item></channel></rss>