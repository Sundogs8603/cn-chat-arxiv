<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#22312;&#19968;&#20010;&#22823;&#22411;&#21830;&#19994;&#24179;&#21488;&#19978;&#26500;&#24314;&#19968;&#20010;&#25104;&#21151;&#30340;&#19987;&#38376;&#29992;&#20110;&#26032;&#40092;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#12290;&#20182;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22810;&#20837;&#21475;&#25552;&#21517;&#31995;&#32479;&#65292;&#26377;&#25928;&#24179;&#34913;&#20102;&#35206;&#30422;&#21644;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#36890;&#36807;&#32771;&#34385;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26469;&#36991;&#20813;&#23637;&#31034;&#24179;&#24248;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2306.01720</link><description>&lt;p&gt;
&#26032;&#40092;&#20869;&#23481;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;: &#22810;&#20837;&#21475;&#26032;&#40092;&#20869;&#23481;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Fresh Content Needs More Attention: Multi-funnel Fresh Content Recommendation. (arXiv:2306.01720v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01720
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#22312;&#19968;&#20010;&#22823;&#22411;&#21830;&#19994;&#24179;&#21488;&#19978;&#26500;&#24314;&#19968;&#20010;&#25104;&#21151;&#30340;&#19987;&#38376;&#29992;&#20110;&#26032;&#40092;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#12290;&#20182;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22810;&#20837;&#21475;&#25552;&#21517;&#31995;&#32479;&#65292;&#26377;&#25928;&#24179;&#34913;&#20102;&#35206;&#30422;&#21644;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#36890;&#36807;&#32771;&#34385;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26469;&#36991;&#20813;&#23637;&#31034;&#24179;&#24248;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20316;&#20026;&#23558;&#29992;&#25143;&#19982;&#24222;&#22823;&#12289;&#22810;&#26679;&#21644;&#19981;&#26029;&#22686;&#38271;&#30340;&#20869;&#23481;&#38598;&#21512;&#36827;&#34892;&#36830;&#25509;&#30340;&#20013;&#20171;&#12290;&#23454;&#38469;&#19978;&#65292;&#38656;&#35201;&#22635;&#34917;&#20851;&#20110;&#26032;&#40092;&#65288;&#21644;&#23614;&#37096;&#65289;&#20869;&#23481;&#30340;&#20449;&#24687;&#32570;&#22833;&#65292;&#20197;&#20415;&#35753;&#35266;&#20247;&#24471;&#20197;&#21457;&#29616;&#21644;&#21033;&#29992;&#23427;&#20204;&#12290;&#26412;&#25991;&#20998;&#20139;&#20102;&#25105;&#20204;&#22312;&#19968;&#20010;&#22823;&#22411;&#21830;&#19994;&#24179;&#21488;&#19978;&#26500;&#24314;&#19987;&#29992;&#30340;&#26032;&#40092;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#30340;&#25104;&#21151;&#32463;&#39564;&#12290;&#20026;&#20102;&#25552;&#21517;&#26032;&#40092;&#20869;&#23481;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22810;&#20837;&#21475;&#25552;&#21517;&#31995;&#32479;&#65292;&#23427;&#32467;&#21512;&#20102;&#65288;i&#65289;&#20855;&#26377;&#24191;&#27867;&#27867;&#21270;&#33021;&#21147;&#30340;&#20004;&#22612;&#27169;&#22411;&#21644;&#65288;ii&#65289;&#20855;&#26377;&#25509;&#36817;&#23454;&#26102;&#30340;&#29992;&#25143;&#21453;&#39304;&#26356;&#26032;&#30340;&#24207;&#21015;&#27169;&#22411;&#65292;&#20197;&#20445;&#25345;&#35206;&#30422;&#21644;&#30456;&#20851;&#24615;&#20043;&#38388;&#30340;&#26377;&#25928;&#24179;&#34913;&#12290;&#28145;&#20837;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#29992;&#25143;&#27963;&#21160;&#27700;&#24179;&#19982;&#20854;&#25509;&#36817;&#26032;&#40092;&#20869;&#23481;&#30340;&#20851;&#31995;&#65292;&#36825;&#36827;&#19968;&#27493;&#28608;&#21457;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22810;&#20837;&#21475;&#30340;&#35774;&#32622;&#12290;&#25552;&#21517;&#30340;&#26032;&#40092;&#20505;&#36873;&#32773;&#28982;&#21518;&#30001;&#31995;&#32479;&#24471;&#20998;&#21644;&#25490;&#21517;&#65292;&#32771;&#34385;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20197;&#36991;&#20813;&#26292;&#38706;&#24179;&#24248;&#30340;&#20869;&#23481;&#12290;&#36825;&#20010;&#25552;&#21517;&#21644;&#25490;&#21517;&#31995;&#32479;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#26032;&#40092;&#20869;&#23481;&#30340;&#25972;&#20307;&#36136;&#37327;&#21644;&#26131;&#20110;&#19982;&#29616;&#26377;&#30340;&#25512;&#33616;&#31995;&#32479;&#38598;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation system serves as a conduit connecting users to an incredibly large, diverse and ever growing collection of contents. In practice, missing information on fresh (and tail) contents needs to be filled in order for them to be exposed and discovered by their audience. We here share our success stories in building a dedicated fresh content recommendation stack on a large commercial platform. To nominate fresh contents, we built a multi-funnel nomination system that combines (i) a two-tower model with strong generalization power for coverage, and (ii) a sequence model with near real-time update on user feedback for relevance. The multi-funnel setup effectively balances between coverage and relevance. An in-depth study uncovers the relationship between user activity level and their proximity toward fresh contents, which further motivates a contextual multi-funnel setup. Nominated fresh candidates are then scored and ranked by systems considering prediction uncertainty to further
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#26694;&#26550;SAT-Ranker&#65292;&#26088;&#22312;&#20197;&#32479;&#19968;&#26041;&#24335;&#20840;&#38754;&#24314;&#27169;&#29992;&#25143;&#28385;&#24847;&#24230;&#30340;&#19981;&#21516;&#32500;&#24230;&#65292;&#20174;&#32780;&#22312;&#32593;&#32476;&#25628;&#32034;&#20013;&#25490;&#21517;&#29992;&#25143;&#28385;&#24847;&#24230;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#20248;&#24322;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.01599</link><description>&lt;p&gt;
&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#32593;&#32476;&#25628;&#32034;&#25490;&#21517;: &#20174;&#30456;&#20851;&#24615;&#21040;&#28385;&#36275;&#24863;
&lt;/p&gt;
&lt;p&gt;
Pretrained Language Model based Web Search Ranking: From Relevance to Satisfaction. (arXiv:2306.01599v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01599
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#26694;&#26550;SAT-Ranker&#65292;&#26088;&#22312;&#20197;&#32479;&#19968;&#26041;&#24335;&#20840;&#38754;&#24314;&#27169;&#29992;&#25143;&#28385;&#24847;&#24230;&#30340;&#19981;&#21516;&#32500;&#24230;&#65292;&#20174;&#32780;&#22312;&#32593;&#32476;&#25628;&#32034;&#20013;&#25490;&#21517;&#29992;&#25143;&#28385;&#24847;&#24230;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#20248;&#24322;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#24341;&#25806;&#22312;&#28385;&#36275;&#29992;&#25143;&#22810;&#31181;&#20449;&#24687;&#38656;&#27714;&#26041;&#38754;&#21457;&#25381;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#30340;&#25991;&#26412;&#25490;&#21517;&#27169;&#22411;&#22312;Web&#25628;&#32034;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#25991;&#26412;&#25490;&#21517;&#26041;&#27861;&#20165;&#20851;&#27880;&#26680;&#24515;&#30456;&#20851;&#24615;&#65292;&#32780;&#24573;&#30053;&#20102;&#20854;&#20182;&#26377;&#21161;&#20110;&#29992;&#25143;&#28385;&#24847;&#24230;&#30340;&#32500;&#24230;&#65292;&#20363;&#22914;&#25991;&#26723;&#36136;&#37327;&#12289;&#26102;&#25928;&#24615;&#12289;&#26435;&#23041;&#24615;&#31561;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#22312;&#32593;&#32476;&#25628;&#32034;&#20013;&#25490;&#21517;&#29992;&#25143;&#28385;&#24847;&#24230;&#65292;&#32780;&#19981;&#26159;&#30456;&#20851;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PLM&#30340;&#26694;&#26550;&#65292;&#21363;SAT-Ranker&#65292;&#23427;&#20197;&#32479;&#19968;&#30340;&#26041;&#24335;&#20840;&#38754;&#24314;&#27169;&#29992;&#25143;&#28385;&#24847;&#24230;&#30340;&#19981;&#21516;&#32500;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21033;&#29992;PLM&#22312;&#25991;&#26412;&#21644;&#25968;&#23383;&#36755;&#20837;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#24212;&#29992;&#22810;&#23383;&#27573;&#36755;&#20837;&#65292;&#23558;&#27599;&#20010;&#29992;&#25143;&#28385;&#24847;&#24230;&#32500;&#24230;&#20316;&#20026;&#36755;&#20837;&#23383;&#27573;&#36827;&#34892;&#27169;&#22359;&#21270;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;SAT-Ranker&#26159;&#19968;&#20010;&#26377;&#25928;&#12289;&#21487;&#25193;&#23637;&#21644;&#25968;&#25454;&#20013;&#24515;&#30340;&#26694;&#26550;&#65292;&#20855;&#26377;&#24040;&#22823;&#30340;&#24037;&#19994;&#24212;&#29992;&#28508;&#21147;&#12290;&#22312;&#20005;&#26684;&#30340;&#32447;&#19979;&#21644;&#32447;&#19978;&#23454;&#39564;&#20013;&#65292;SAT-Ranker&#34920;&#29616;&#20248;&#24322;&#65292;&#20248;&#20110;&#24378;&#22522;&#32447;&#65292;&#24182;&#22312;MSR-Web30K&#21644;TREC Web Track&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Search engine plays a crucial role in satisfying users' diverse information needs. Recently, Pretrained Language Models (PLMs) based text ranking models have achieved huge success in web search. However, many state-of-the-art text ranking approaches only focus on core relevance while ignoring other dimensions that contribute to user satisfaction, e.g., document quality, recency, authority, etc. In this work, we focus on ranking user satisfaction rather than relevance in web search, and propose a PLM-based framework, namely SAT-Ranker, which comprehensively models different dimensions of user satisfaction in a unified manner. In particular, we leverage the capacities of PLMs on both textual and numerical inputs, and apply a multi-field input that modularizes each dimension of user satisfaction as an input field. Overall, SAT-Ranker is an effective, extensible, and data-centric framework that has huge potential for industrial applications. On rigorous offline and online experiments, SAT-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#24433;&#21709;&#26368;&#22823;&#21270;&#38382;&#39064;&#20013;&#30340;&#20844;&#24179;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#20844;&#24179;&#20256;&#25773;&#65292;&#20174;&#32780;&#23454;&#29616;&#21487;&#25193;&#23637;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#25968;&#30334;&#19975;&#25110;&#25968;&#21313;&#20159;&#33410;&#28857;&#30340;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2306.01587</link><description>&lt;p&gt;
&#22312;&#35268;&#27169;&#19978;&#32771;&#34385;&#20844;&#24179;&#30340;&#24433;&#21709;&#26368;&#22823;&#21270;&#38382;&#39064;&#65288;&#25193;&#23637;&#29256;&#65289;
&lt;/p&gt;
&lt;p&gt;
Influence Maximization with Fairness at Scale (Extended Version). (arXiv:2306.01587v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01587
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24433;&#21709;&#26368;&#22823;&#21270;&#38382;&#39064;&#20013;&#30340;&#20844;&#24179;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#20844;&#24179;&#20256;&#25773;&#65292;&#20174;&#32780;&#23454;&#29616;&#21487;&#25193;&#23637;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#25968;&#30334;&#19975;&#25110;&#25968;&#21313;&#20159;&#33410;&#28857;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20851;&#20110;&#24433;&#21709;&#26368;&#22823;&#21270;&#38382;&#39064;&#20013;&#20844;&#24179;&#30340;&#38382;&#39064;&#65292;&#21363;&#22312;&#36873;&#25321;k&#20010;&#20855;&#26377;&#24433;&#21709;&#21147;&#30340;&#33410;&#28857;&#26469;&#26368;&#22823;&#21270;&#20449;&#24687;&#20256;&#25773;&#30340;&#21516;&#26102;&#65292;&#30830;&#20445;&#25152;&#36873;&#25321;&#33410;&#28857;&#23545;&#25935;&#24863;&#29992;&#25143;&#23646;&#24615;&#30340;&#24433;&#21709;&#26159;&#20844;&#24179;&#30340;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20165;&#20851;&#27880;&#20110;&#26497;&#23567;&#30340;&#32593;&#32476;&#65292;&#22240;&#27492;&#20851;&#38190;&#38382;&#39064;&#22312;&#20110;&#22914;&#20309;&#23454;&#29616;&#21487;&#25193;&#23637;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#25968;&#30334;&#19975;&#25110;&#25968;&#21313;&#20159;&#33410;&#28857;&#30340;&#32593;&#32476;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#20844;&#24179;&#20256;&#25773;&#65292;&#32780;&#19981;&#26159;&#20381;&#36182;&#20110;&#31038;&#20132;&#36830;&#25509;&#65292;&#20197;&#20415;&#25105;&#20204;&#21487;&#20197;&#22788;&#29702;&#38750;&#24120;&#22823;&#30340;&#22270;&#24418;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65306;&#65288;a&#65289;&#22522;&#20110;&#20844;&#24179;&#30340;&#21442;&#19982;&#32773;&#25277;&#26679;&#65288;FPS&#65289;&#21644;&#65288;b&#65289;&#20844;&#24179;&#20316;&#20026;&#19978;&#19979;&#25991;&#65288;FAC&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we revisit the problem of influence maximization with fairness, which aims to select k influential nodes to maximise the spread of information in a network, while ensuring that selected sensitive user attributes are fairly affected, i.e., are proportionally similar between the original network and the affected users. Recent studies on this problem focused only on extremely small networks, hence the challenge remains on how to achieve a scalable solution, applicable to networks with millions or billions of nodes. We propose an approach that is based on learning node representations for fair spread from diffusion cascades, instead of the social connectivity s.t. we can deal with very large graphs. We propose two data-driven approaches: (a) fairness-based participant sampling (FPS), and (b) fairness as context (FAC). Spread related user features, such as the probability of diffusing information to others, are derived from the historical information cascades, using a deep ne
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#22522;&#20110;&#32422;&#26463;&#30340;&#25512;&#33616;&#31995;&#32479;&#26469;&#25512;&#33616;&#39550;&#39542;&#21592;/&#36710;&#36742;&#37197;&#23545;&#65292;&#22312;&#21361;&#26426;&#31649;&#29702;&#27169;&#25311;&#20013;&#23454;&#29616;&#22478;&#24066;&#23621;&#27665;&#30340;&#33258;&#24895;&#21442;&#19982;&#12290;</title><link>http://arxiv.org/abs/2306.01504</link><description>&lt;p&gt;
&#22522;&#20110;&#32422;&#26463;&#30340;&#21361;&#26426;&#31649;&#29702;&#27169;&#25311;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Syst\`eme de recommandations bas\'e sur les contraintes pour les simulations de gestion de crise. (arXiv:2306.01504v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01504
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#22522;&#20110;&#32422;&#26463;&#30340;&#25512;&#33616;&#31995;&#32479;&#26469;&#25512;&#33616;&#39550;&#39542;&#21592;/&#36710;&#36742;&#37197;&#23545;&#65292;&#22312;&#21361;&#26426;&#31649;&#29702;&#27169;&#25311;&#20013;&#23454;&#29616;&#22478;&#24066;&#23621;&#27665;&#30340;&#33258;&#24895;&#21442;&#19982;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30095;&#25955;&#20154;&#32676;&#30340;&#32972;&#26223;&#19979;&#65292;&#19968;&#20123;&#24066;&#27665;/&#24535;&#24895;&#32773;&#21487;&#33021;&#24076;&#26395;&#24182;&#33021;&#22815;&#36890;&#36807;&#33258;&#24049;&#30340;&#36710;&#36742;&#26469;&#24110;&#21161;&#24212;&#24613;/&#30095;&#25955;&#36710;&#36742;&#30095;&#25955;&#22788;&#20110;&#22256;&#22659;&#20013;&#30340;&#20154;&#32676;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#21361;&#26426;&#31649;&#29702;&#27169;&#25311;&#31995;&#32479;&#20013;&#22686;&#21152;&#25512;&#33616;&#39550;&#39542;&#21592;/&#36710;&#36742;&#37197;&#23545;&#27169;&#22359;&#30340;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36873;&#25321;&#24314;&#27169;&#24182;&#24320;&#21457;&#19968;&#20010;&#22522;&#20110;&#26412;&#20307;&#25903;&#25345;&#30340;&#32422;&#26463;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#29992;&#20110;&#21361;&#26426;&#31649;&#29702;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the context of the evacuation of populations, some citizens/volunteers may want and be able to participate in the evacuation of populations in difficulty by coming to lend a hand to emergency/evacuation vehicles with their own vehicles. One way of framing these impulses of solidarity would be to be able to list in real-time the citizens/volunteers available with their vehicles (land, sea, air, etc.), to be able to geolocate them according to the risk areas to be evacuated, and adding them to the evacuation/rescue vehicles. Because it is difficult to propose an effective real-time operational system on the field in a real crisis situation, in this work, we propose to add a module for recommending driver/vehicle pairs (with their specificities) to a system of crisis management simulation. To do that, we chose to model and develop an ontology-supported constraint-based recommender system for crisis management simulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24314;&#27169;&#29992;&#25143;&#30340;&#23618;&#27425;&#26032;&#22855;&#23547;&#27714;&#24847;&#22270;&#24182;&#35843;&#25972;&#25512;&#33616;&#31574;&#30053;&#20197;&#25552;&#39640;&#25512;&#33616;&#39033;&#30446;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.01476</link><description>&lt;p&gt;
&#29992;&#20110;&#24314;&#27169;&#29992;&#25143;&#26032;&#22855;&#23547;&#27714;&#24847;&#22270;&#30340;&#23618;&#27425;&#24378;&#21270;&#23398;&#20064;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Reinforcement Learning for Modeling User Novelty-Seeking Intent in Recommender Systems. (arXiv:2306.01476v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24314;&#27169;&#29992;&#25143;&#30340;&#23618;&#27425;&#26032;&#22855;&#23547;&#27714;&#24847;&#22270;&#24182;&#35843;&#25972;&#25512;&#33616;&#31574;&#30053;&#20197;&#25552;&#39640;&#25512;&#33616;&#39033;&#30446;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#26032;&#39062;&#20869;&#23481;&#21487;&#20197;&#36890;&#36807;&#21521;&#29992;&#25143;&#20171;&#32461;&#26032;&#30340;&#20852;&#36259;&#28857;&#26469;&#25913;&#21892;&#29992;&#25143;&#22312;&#25512;&#33616;&#24179;&#21488;&#19978;&#30340;&#38271;&#26399;&#20307;&#39564;&#12290;&#28982;&#32780;&#65292;&#29992;&#25143;&#24182;&#19981;&#24635;&#26159;&#24819;&#35201;&#25506;&#32034;&#26032;&#39062;&#30340;&#20869;&#23481;&#12290;&#22240;&#27492;&#65292;&#20102;&#35299;&#20182;&#20204;&#30340;&#23547;&#27714;&#26032;&#22855;&#30340;&#24847;&#22270;&#24182;&#30456;&#24212;&#22320;&#35843;&#25972;&#25512;&#33616;&#31574;&#30053;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#24378;&#21270;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#24314;&#27169;&#29992;&#25143;&#30340;&#23618;&#27425;&#26032;&#22855;&#23547;&#27714;&#24847;&#22270;&#65292;&#24182;&#26681;&#25454;&#25552;&#21462;&#30340;&#29992;&#25143;&#23547;&#27714;&#26032;&#22855;&#20542;&#21521;&#24615;&#26469;&#35843;&#25972;&#25512;&#33616;&#31574;&#30053;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#25512;&#33616;&#39033;&#30446;&#30340;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommending novel content, which expands user horizons by introducing them to new interests, has been shown to improve users' long-term experience on recommendation platforms \cite{chen2021values}. Users however are not constantly looking to explore novel content. It is therefore crucial to understand their novelty-seeking intent and adjust the recommendation policy accordingly. Most existing literature models a user's propensity to choose novel content or to prefer a more diverse set of recommendations at individual interactions. Hierarchical structure, on the other hand, exists in a user's novelty-seeking intent, which is manifested as a static and intrinsic user preference for seeking novelty along with a dynamic session-based propensity. To this end, we propose a novel hierarchical reinforcement learning-based method to model the hierarchical user novelty-seeking intent, and to adapt the recommendation policy accordingly based on the extracted user novelty-seeking propensity. We f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#26041;&#27861;&#65292;&#23558;&#38754;&#21521;&#26041;&#38754;&#30340;&#25552;&#21462;&#21644;&#25512;&#33616;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#20010;&#24615;&#21270;&#22522;&#20110;&#26041;&#38754;&#30340;&#25512;&#33616;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35774;&#35745;&#20102;&#26032;&#30340;&#27169;&#22411;&#26469;&#20026;&#26368;&#32456;&#30340;&#25512;&#33616;&#20219;&#21153;&#29983;&#25104;&#26041;&#38754;&#12290;</title><link>http://arxiv.org/abs/2306.01475</link><description>&lt;p&gt;
&#38754;&#21521;&#20010;&#24615;&#21270;&#26041;&#38754;&#25552;&#21462;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25552;&#31034;&#35843;&#25972;&#29992;&#20110;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Prompt Tuning Large Language Models on Personalized Aspect Extraction for Recommendations. (arXiv:2306.01475v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#26041;&#27861;&#65292;&#23558;&#38754;&#21521;&#26041;&#38754;&#30340;&#25552;&#21462;&#21644;&#25512;&#33616;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#20010;&#24615;&#21270;&#22522;&#20110;&#26041;&#38754;&#30340;&#25512;&#33616;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35774;&#35745;&#20102;&#26032;&#30340;&#27169;&#22411;&#26469;&#20026;&#26368;&#32456;&#30340;&#25512;&#33616;&#20219;&#21153;&#29983;&#25104;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#26041;&#38754;&#25552;&#21462;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#26174;&#24335;&#25110;&#22522;&#30784;&#20107;&#23454;&#26041;&#38754;&#20449;&#24687;&#65292;&#25110;&#32773;&#20351;&#29992;&#25968;&#25454;&#25366;&#25496;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20174;&#38544;&#21547;&#29992;&#25143;&#21453;&#39304;&#65288;&#20363;&#22914;&#29992;&#25143;&#35780;&#35770;&#65289;&#20013;&#25552;&#21462;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#21033;&#29992;&#25552;&#21462;&#20986;&#30340;&#26041;&#38754;&#29983;&#25104;&#26356;&#26377;&#24847;&#20041;&#30340;&#25512;&#33616;&#32473;&#29992;&#25143;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#21516;&#26102;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#26041;&#38754;&#30340;&#25512;&#33616;&#30740;&#31350;&#36890;&#24120;&#20381;&#36182;&#20110;&#21333;&#29420;&#30340;&#26041;&#38754;&#25552;&#21462;&#27169;&#22411;&#25110;&#20551;&#35774;&#26041;&#38754;&#26159;&#24050;&#30693;&#30340;&#65292;&#32780;&#27809;&#26377;&#32771;&#34385;&#21040;&#26368;&#20339;&#26041;&#38754;&#38598;&#21487;&#33021;&#21462;&#20915;&#20110;&#25163;&#22836;&#30340;&#25512;&#33616;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#26041;&#38754;&#25552;&#21462;&#19982;&#22522;&#20110;&#26041;&#38754;&#30340;&#25512;&#33616;&#32467;&#21512;&#36215;&#26469;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#24182;&#22312;&#21333;&#20010;&#26694;&#26550;&#20013;&#21516;&#26102;&#23454;&#29616;&#36825;&#20004;&#20010;&#30446;&#26631;&#12290;&#23545;&#20110;&#26041;&#38754;&#25552;&#21462;&#32452;&#20214;&#65292;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#25552;&#31034;&#23398;&#20064;&#26426;&#21046;&#26469;&#20026;&#26368;&#32456;&#30340;&#25512;&#33616;&#20219;&#21153;&#29983;&#25104;&#26041;&#38754;&#12290;&#23545;&#20110;&#22522;&#20110;&#26041;&#38754;&#30340;&#25512;&#33616;&#32452;&#20214;&#65292;&#25105;&#20204;&#24341;&#36827;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#30340;&#22522;&#20110;&#26041;&#38754;&#30340;&#25512;&#33616;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#19982;&#26041;&#38754;&#25552;&#21462;&#27169;&#22411;&#19968;&#36215;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#26041;&#38754;&#25552;&#21462;&#21644;&#22522;&#20110;&#26041;&#38754;&#30340;&#25512;&#33616;&#20219;&#21153;&#19978;&#37117;&#20248;&#20110;&#20960;&#31181;&#24378;&#22522;&#20934;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing aspect extraction methods mostly rely on explicit or ground truth aspect information, or using data mining or machine learning approaches to extract aspects from implicit user feedback such as user reviews. It however remains under-explored how the extracted aspects can help generate more meaningful recommendations to the users. Meanwhile, existing research on aspect-based recommendations often relies on separate aspect extraction models or assumes the aspects are given, without accounting for the fact the optimal set of aspects could be dependent on the recommendation task at hand.  In this work, we propose to combine aspect extraction together with aspect-based recommendations in an end-to-end manner, achieving the two goals together in a single framework. For the aspect extraction component, we leverage the recent advances in large language models and design a new prompt learning mechanism to generate aspects for the end recommendation task. For the aspect-based recommendat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;OPC UA&#30340;&#22823;&#25968;&#25454;&#26550;&#26500;&#65292;&#21033;&#29992;&#20803;&#25968;&#25454;&#21644;&#35821;&#20041;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#22788;&#29702;&#21644;&#26597;&#35810;&#25928;&#29575;&#65292;&#20351;&#22810;&#20010;&#22788;&#29702;&#27744;&#33021;&#22815;&#21327;&#21516;&#24037;&#20316;&#32780;&#19981;&#24178;&#25200;&#29616;&#22330;&#35774;&#22791;&#21644;&#29983;&#20135;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2306.01418</link><description>&lt;p&gt;
&#22522;&#20110;OPC UA&#30340;&#24037;&#19994;&#22823;&#25968;&#25454;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
An OPC UA-based industrial Big Data architecture. (arXiv:2306.01418v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;OPC UA&#30340;&#22823;&#25968;&#25454;&#26550;&#26500;&#65292;&#21033;&#29992;&#20803;&#25968;&#25454;&#21644;&#35821;&#20041;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#22788;&#29702;&#21644;&#26597;&#35810;&#25928;&#29575;&#65292;&#20351;&#22810;&#20010;&#22788;&#29702;&#27744;&#33021;&#22815;&#21327;&#21516;&#24037;&#20316;&#32780;&#19981;&#24178;&#25200;&#29616;&#22330;&#35774;&#22791;&#21644;&#29983;&#20135;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#19994;4.0&#24037;&#21378;&#24456;&#22797;&#26434;&#65292;&#26159;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#12290;&#25968;&#25454;&#26469;&#33258;&#35768;&#22810;&#26469;&#28304;&#65292;&#21253;&#25324;&#20256;&#24863;&#22120;&#12289;PLC&#21644;&#20854;&#20182;&#35774;&#22791;&#65292;&#36824;&#26377;IT&#31995;&#32479;&#65292;&#22914;ERP&#25110;CRM&#31995;&#32479;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26597;&#35810;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#22823;&#25968;&#25454;&#26550;&#26500;&#65292;&#20351;&#29992;OPC UA&#20316;&#20026;&#22522;&#30784;&#26469;&#25429;&#33719;&#26469;&#33258;&#19981;&#21516;&#26469;&#28304;&#30340;&#25968;&#25454;&#12290;&#23427;&#32531;&#20914;&#24182;&#39044;&#22788;&#29702;&#20449;&#24687;&#65292;&#20197;&#23454;&#29616;&#24037;&#21378;&#30340;&#25972;&#20307;&#29366;&#24577;&#31354;&#38388;&#30340;&#21327;&#35843;&#65292;&#24182;&#26144;&#23556;&#21040;&#29983;&#20135;&#29616;&#22330;&#30340;&#24403;&#21069;&#29366;&#24577;&#12290;&#35813;&#20449;&#24687;&#21487;&#20197;&#25552;&#20379;&#32473;&#22810;&#20010;&#22788;&#29702;&#27744;&#65292;&#19982;&#25968;&#25454;&#28304;&#20998;&#31163;&#65292;&#20351;&#20854;&#33021;&#22815;&#22788;&#29702;&#20449;&#24687;&#65292;&#32780;&#19981;&#20250;&#24178;&#25200;&#29983;&#20135;&#35774;&#22791;&#12289;&#32593;&#32476;&#35774;&#22791;&#25110;&#23545;&#29983;&#20135;&#36807;&#31243;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#20803;&#25968;&#25454;&#21644;&#35821;&#20041;&#27169;&#22411;&#29992;&#20110;&#20351;&#25968;&#25454;&#22788;&#29702;&#21644;&#26597;&#35810;&#26356;&#21152;&#39640;&#25928;&#21644;&#28789;&#27963;&#12290;&#35813;&#26550;&#26500;&#22312;&#23454;&#38469;&#24037;&#19994;&#29615;&#22659;&#20013;&#24471;&#21040;&#23454;&#29616;&#21644;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Industry 4.0 factories are complex and data-driven. Data is yielded from many sources, including sensors, PLCs, and other devices, but also from IT, like ERP or CRM systems. We ask how to collect and process this data in a way, such that it includes metadata and can be used for industrial analytics or to derive intelligent support systems. This paper describes a new, query model based approach, which uses a big data architecture to capture data from various sources using OPC UA as a foundation. It buffers and preprocesses the information for the purpose of harmonizing and providing a holistic state space of a factory, as well as mappings to the current state of a production site. That information can be made available to multiple processing sinks, decoupled from the data sources, which enables them to work with the information without interfering with devices of the production, disturbing the network devices they are working in, or influencing the production process negatively. Metadat
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DWT-CompCNN&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#30452;&#25509;&#23545;&#20351;&#29992;HTJ2K&#31639;&#27861;&#21387;&#32553;&#30340;&#25991;&#26723;&#36827;&#34892;&#20998;&#31867;&#65292;&#20174;&#32780;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.01359</link><description>&lt;p&gt;
DWT-CompCNN&#65306;&#29992;&#20110;&#39640;&#21534;&#21520;&#37327;JPEG 2000&#21387;&#32553;&#25991;&#26723;&#30340;&#28145;&#24230;&#22270;&#20687;&#20998;&#31867;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
DWT-CompCNN: Deep Image Classification Network for High Throughput JPEG 2000 Compressed Documents. (arXiv:2306.01359v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01359
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DWT-CompCNN&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#30452;&#25509;&#23545;&#20351;&#29992;HTJ2K&#31639;&#27861;&#21387;&#32553;&#30340;&#25991;&#26723;&#36827;&#34892;&#20998;&#31867;&#65292;&#20174;&#32780;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20219;&#20309;&#21253;&#21547;&#25991;&#26723;&#22270;&#20687;&#30340;&#25968;&#23383;&#24212;&#29992;&#31243;&#24207;&#65292;&#22914;&#26816;&#32034;&#65292;&#25991;&#26723;&#22270;&#20687;&#30340;&#20998;&#31867;&#25104;&#20026;&#24517;&#35201;&#30340;&#38454;&#27573;&#12290;&#20256;&#32479;&#19978;&#65292;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#30340;&#65292;&#25991;&#26723;&#30340;&#23436;&#25972;&#29256;&#26412;&#65292;&#21363;&#26410;&#21387;&#32553;&#30340;&#25991;&#26723;&#22270;&#20687;&#26500;&#25104;&#36755;&#20837;&#25968;&#25454;&#38598;&#65292;&#36825;&#20250;&#22240;&#25968;&#25454;&#37327;&#22823;&#32780;&#24102;&#26469;&#23041;&#32961;&#12290;&#22240;&#27492;&#65292;&#22914;&#26524;&#21487;&#20197;&#20351;&#29992;&#25991;&#26723;&#30340;&#21387;&#32553;&#34920;&#31034;&#65288;&#22312;&#37096;&#20998;&#35299;&#21387;&#32553;&#30340;&#24773;&#20917;&#19979;&#65289;&#65292;&#30452;&#25509;&#23436;&#25104;&#30456;&#21516;&#30340;&#20998;&#31867;&#20219;&#21153;&#20197;&#20351;&#25972;&#20010;&#36807;&#31243;&#35745;&#31639;&#25928;&#29575;&#26356;&#39640;&#65292;&#37027;&#23558;&#20250;&#26159;&#19968;&#39033;&#21019;&#26032;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;DWT-CompCNN&#65292;&#29992;&#20110;&#20351;&#29992;&#39640;&#21534;&#21520;&#37327;JPEG 2000&#65288;HTJ2K&#65289;&#31639;&#27861;&#21387;&#32553;&#30340;&#25991;&#26723;&#30340;&#20998;&#31867;&#12290;&#25152;&#25552;&#20986;&#30340;DWT-CompCNN&#21253;&#25324;&#20116;&#20010;&#21367;&#31215;&#23618;&#65292;&#21367;&#31215;&#26680;&#22823;&#23567;&#20998;&#21035;&#20026;16&#12289;32&#12289;64&#12289;128&#21644;256&#29992;&#20110;&#20174;&#25552;&#21462;&#30340;&#23567;&#27874;&#31995;&#25968;&#20013;&#25552;&#39640;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
For any digital application with document images such as retrieval, the classification of document images becomes an essential stage. Conventionally for the purpose, the full versions of the documents, that is the uncompressed document images make the input dataset, which poses a threat due to the big volume required to accommodate the full versions of the documents. Therefore, it would be novel, if the same classification task could be accomplished directly (with some partial decompression) with the compressed representation of documents in order to make the whole process computationally more efficient. In this research work, a novel deep learning model, DWT CompCNN is proposed for classification of documents that are compressed using High Throughput JPEG 2000 (HTJ2K) algorithm. The proposed DWT-CompCNN comprises of five convolutional layers with filter sizes of 16, 32, 64, 128, and 256 consecutively for each increasing layer to improve learning from the wavelet coefficients extracted
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26368;&#20248;&#36127;&#37319;&#26679;&#20174;&#26681;&#26412;&#19978;&#32531;&#35299;&#27969;&#34892;&#24230;&#20559;&#24046;&#65292;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.01348</link><description>&lt;p&gt;
&#36890;&#36807;AUC-&#26368;&#20248;&#36127;&#37319;&#26679;&#38477;&#20302;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#24230;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Reducing Popularity Bias in Recommender Systems through AUC-Optimal Negative Sampling. (arXiv:2306.01348v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01348
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#36127;&#37319;&#26679;&#20174;&#26681;&#26412;&#19978;&#32531;&#35299;&#27969;&#34892;&#24230;&#20559;&#24046;&#65292;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#34892;&#24230;&#20559;&#24046;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#38271;&#26399;&#38382;&#39064;&#65292;&#23545;&#20844;&#24179;&#24615;&#21644;&#25928;&#29575;&#37117;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#29616;&#26377;&#25991;&#29486;&#26222;&#36941;&#35748;&#20026;&#65292;&#20943;&#23569;&#27969;&#34892;&#24230;&#20559;&#24046;&#36890;&#24120;&#38656;&#35201;&#29306;&#29298;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#36825;&#31181;&#20849;&#35782;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#36890;&#29992;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#26694;&#26550;&#19979;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#20943;&#23569;&#20559;&#24046;&#23454;&#38469;&#19978;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#31181;&#21452;&#36194;&#30340;&#23616;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#36127;&#37319;&#26679;&#24178;&#39044;&#27169;&#22411;&#35757;&#32451;&#65292;&#20174;&#32780;&#20462;&#25913;&#27169;&#22411;&#39044;&#27979;&#65292;&#20197;&#27492;&#26469;&#32531;&#35299;&#27969;&#34892;&#24230;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26368;&#20248;&#36127;&#37319;&#26679;&#35268;&#21017;&#65292;&#20197;&#26368;&#22823;&#21270;&#23616;&#37096;AUC&#65292;&#20174;&#32780;&#20445;&#25345;&#20219;&#20309;&#32473;&#23450;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#36890;&#36807;&#20462;&#27491;&#37319;&#26679;&#20449;&#24687;&#21644;&#20808;&#21069;&#20449;&#24687;&#30340;&#26041;&#24335;&#26469;&#28789;&#27963;&#21644;&#26377;&#21407;&#21017;&#22320;&#20943;&#23569;&#27969;&#34892;&#24230;&#20559;&#24046;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#21644;&#20943;&#23569;&#27969;&#34892;&#24230;&#20559;&#24046;&#26041;&#38754;&#30340;&#21331;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Popularity bias is a persistent issue associated with recommendation systems, posing challenges to both fairness and efficiency. Existing literature widely acknowledges that reducing popularity bias often requires sacrificing recommendation accuracy. In this paper, we challenge this commonly held belief. Our analysis under general bias-variance decomposition framework shows that reducing bias can actually lead to improved model performance under certain conditions. To achieve this win-win situation, we propose to intervene in model training through negative sampling thereby modifying model predictions. Specifically, we provide an optimal negative sampling rule that maximizes partial AUC to preserve the accuracy of any given model, while correcting sample information and prior information to reduce popularity bias in a flexible and principled way. Our experimental results on real-world datasets demonstrate the superiority of our approach in improving recommendation performance and reduc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#35821;&#20041;&#30456;&#20284;&#24615;&#20219;&#21153;&#30340;&#26032;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#65292;&#30001;&#22810;&#20010;&#26412;&#22320;&#27880;&#37322;&#32773;&#23436;&#25104;&#38598;&#20307;&#27880;&#37322;&#23454;&#39564;&#65292;&#35780;&#20272;&#20102;&#21508;&#31181;&#26368;&#20808;&#36827;&#30340;&#21333;&#35821;&#21644;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24314;&#31435;&#20102;&#22522;&#20934;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.01325</link><description>&lt;p&gt;
LyricSIM&#65306;&#19968;&#31181;&#29992;&#20110;&#26816;&#27979;&#35199;&#29677;&#29273;&#27468;&#35789;&#30456;&#20284;&#24615;&#30340;&#26032;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
LyricSIM: A novel Dataset and Benchmark for Similarity Detection in Spanish Song LyricS. (arXiv:2306.01325v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01325
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#35821;&#20041;&#30456;&#20284;&#24615;&#20219;&#21153;&#30340;&#26032;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#65292;&#30001;&#22810;&#20010;&#26412;&#22320;&#27880;&#37322;&#32773;&#23436;&#25104;&#38598;&#20307;&#27880;&#37322;&#23454;&#39564;&#65292;&#35780;&#20272;&#20102;&#21508;&#31181;&#26368;&#20808;&#36827;&#30340;&#21333;&#35821;&#21644;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24314;&#31435;&#20102;&#22522;&#20934;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#65292;&#26088;&#22312;&#38024;&#23545;&#27468;&#35789;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#26368;&#21021;&#30001;2775&#23545;&#35199;&#29677;&#29273;&#27468;&#26354;&#32452;&#25104;&#65292;&#30001;63&#20010;&#26412;&#22320;&#27880;&#37322;&#32773;&#36827;&#34892;&#38598;&#20307;&#27880;&#37322;&#23454;&#39564;&#12290;&#32463;&#36807;&#25910;&#38598;&#21644;&#31934;&#32454;&#21270;&#22788;&#29702;&#25968;&#25454;&#20197;&#30830;&#20445;&#39640;&#24230;&#30340;&#20849;&#35782;&#21644;&#25968;&#25454;&#23436;&#25972;&#24615;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;676&#20010;&#39640;&#36136;&#37327;&#30340;&#26631;&#27880;&#23545;&#65292;&#29992;&#20110;&#35780;&#20272;&#21508;&#31181;&#26368;&#20808;&#36827;&#30340;&#21333;&#35821;&#21644;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20934;&#32467;&#26524;&#65292;&#24076;&#26395;&#36825;&#20123;&#32467;&#26524;&#23545;&#35813;&#39046;&#22495;&#26410;&#26469;&#30340;&#23398;&#26415;&#21644;&#24037;&#19994;&#24212;&#29992;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a new dataset and benchmark tailored to the task of semantic similarity in song lyrics. Our dataset, originally consisting of 2775 pairs of Spanish songs, was annotated in a collective annotation experiment by 63 native annotators. After collecting and refining the data to ensure a high degree of consensus and data integrity, we obtained 676 high-quality annotated pairs that were used to evaluate the performance of various state-of-the-art monolingual and multilingual language models. Consequently, we established baseline results that we hope will be useful to the community in all future academic and industrial applications conducted in this context.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;JEPOO&#30340;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#65292;&#25903;&#25345;&#21333;&#38899;&#39640;&#21644;&#22810;&#38899;&#39640;&#25968;&#25454;&#65292;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#31934;&#24230;&#25552;&#21319;&#39640;&#36798;10.6%&#65292;8.3%&#21644;10.3%&#12290;</title><link>http://arxiv.org/abs/2306.01304</link><description>&lt;p&gt;
JEPOO&#65306;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#20013;&#20934;&#30830;&#20272;&#35745;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#30340;&#32852;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
JEPOO: Highly Accurate Joint Estimation of Pitch, Onset and Offset for Music Information Retrieval. (arXiv:2306.01304v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;JEPOO&#30340;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#65292;&#25903;&#25345;&#21333;&#38899;&#39640;&#21644;&#22810;&#38899;&#39640;&#25968;&#25454;&#65292;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#31934;&#24230;&#25552;&#21319;&#39640;&#36798;10.6%&#65292;8.3%&#21644;10.3%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26059;&#24459;&#25552;&#21462;&#26159;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#26680;&#24515;&#20219;&#21153;&#65292;&#32780;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#30340;&#20272;&#35745;&#26159;&#26059;&#24459;&#25552;&#21462;&#30340;&#20851;&#38190;&#23376;&#20219;&#21153;&#12290;&#29616;&#26377;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#26377;&#38480;&#65292;&#24182;&#19988;&#21482;&#36866;&#29992;&#20110;&#21333;&#38899;&#39640;&#25110;&#22810;&#38899;&#39640;&#25968;&#25454;&#20013;&#30340;&#19968;&#31181;&#31867;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;JEPOO&#30340;&#39640;&#24230;&#20934;&#30830;&#30340;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#32852;&#21512;&#20272;&#35745;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#26032;&#39062;&#30340;&#27169;&#22411;&#35774;&#35745;&#21644;&#19968;&#31181;&#21517;&#20026;&#24085;&#32047;&#25176;&#27169;&#35843;&#25439;&#22833;&#30340;&#20248;&#21270;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#32852;&#21512;&#23398;&#20064;&#20248;&#21270;&#21644;&#22788;&#29702;&#21333;&#38899;&#39640;&#21644;&#22810;&#38899;&#39640;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;&#36825;&#26159;&#31532;&#19968;&#31181;&#33021;&#22815;&#20934;&#30830;&#22788;&#29702;&#21333;&#38899;&#39640;&#21644;&#22810;&#38899;&#39640;&#38899;&#20048;&#25968;&#25454;&#65292;&#29978;&#33267;&#28151;&#21512;&#31867;&#22411;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#22312;&#24191;&#27867;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#20840;&#38754;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;JEPOO&#22312;&#39044;&#27979;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#26041;&#38754;&#27604;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20998;&#21035;&#39640;&#20986;10.6&#65285;&#12289;8.3&#65285;&#21644;10.3&#65285;&#65292;&#21516;&#26102;&#23545;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#21644;&#20048;&#22120;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Melody extraction is a core task in music information retrieval, and the estimation of pitch, onset and offset are key sub-tasks in melody extraction. Existing methods have limited accuracy, and work for only one type of data, either single-pitch or multipitch. In this paper, we propose a highly accurate method for joint estimation of pitch, onset and offset, named JEPOO. We address the challenges of joint learning optimization and handling both single-pitch and multi-pitch data through novel model design and a new optimization technique named Pareto modulated loss with loss weight regularization. This is the first method that can accurately handle both single-pitch and multi-pitch music data, and even a mix of them. A comprehensive experimental study on a wide range of real datasets shows that JEPOO outperforms state-ofthe-art methods by up to 10.6%, 8.3% and 10.3% for the prediction of Pitch, Onset and Offset, respectively, and JEPOO is robust for various types of data and instrument
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#31616;&#21270;&#20102;&#20250;&#35805;&#25512;&#33616;&#39046;&#22495;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#39640;&#20102;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.01266</link><description>&lt;p&gt;
&#33258;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Self Contrastive Learning for Session-based Recommendation. (arXiv:2306.01266v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#31616;&#21270;&#20102;&#20250;&#35805;&#25512;&#33616;&#39046;&#22495;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#39640;&#20102;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#26088;&#22312;&#39044;&#27979;&#29992;&#25143;&#23545;&#29616;&#26377;&#39033;&#30446;&#20132;&#20114;&#24207;&#21015;&#30340;&#19979;&#19968;&#20010;&#24863;&#20852;&#36259;&#30340;&#39033;&#30446;&#65292;&#24050;&#32463;&#21560;&#24341;&#20102;&#36234;&#26469;&#36234;&#22810;&#24212;&#29992;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#65288;CL&#65289;&#25552;&#39640;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#23545;&#27604;&#30446;&#26631;&#65306;&#65288;1&#65289;&#36215;&#21040;&#19982;&#20132;&#21449;&#29109;&#25439;&#22833;&#31867;&#20284;&#30340;&#20316;&#29992;&#65292;&#21516;&#26102;&#24573;&#30053;&#20102;&#39033;&#30446;&#34920;&#31034;&#31354;&#38388;&#20248;&#21270;&#65307;&#65288;2&#65289;&#36890;&#24120;&#38656;&#35201;&#22797;&#26434;&#30340;&#24314;&#27169;&#65292;&#21253;&#25324;&#22797;&#26434;&#30340;&#27491;/&#36127;&#26679;&#26412;&#26500;&#24314;&#21644;&#39069;&#22806;&#30340;&#25968;&#25454;&#22686;&#24378;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#23545;&#27604;&#23398;&#20064;&#65288;SCL&#65289;&#65292;&#31616;&#21270;&#20102;&#23545;&#27604;&#23398;&#20064;&#30340;&#24212;&#29992;&#65292;&#24182;&#22686;&#24378;&#20102;&#22522;&#20110;&#29366;&#24577;&#30340;&#25512;&#33616;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;SCL&#34987;&#21046;&#23450;&#20026;&#19968;&#20010;&#30446;&#26631;&#20989;&#25968;&#65292;&#30452;&#25509;&#20419;&#36827;&#39033;&#30446;&#34920;&#31034;&#20043;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#65292;&#24182;&#26377;&#25928;&#22320;&#26367;&#25442;&#20102;&#25152;&#26377;&#29616;&#26377;&#30340;&#23545;&#27604;&#30446;&#26631;&#32452;&#20214;&#30340;&#29366;&#24577;-&#33402;&#26415;&#27169;&#22411;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;SCL&#28040;&#38500;&#20102;&#20219;&#20309;&#27491;&#26679;&#26412;&#25110;&#36127;&#26679;&#26412;&#30340;&#38656;&#27714;&#21644;SCL&#28040;&#38500;&#20102;&#20219;&#20309;&#27491;&#26679;&#26412;&#25110;&#36127;&#26679;&#26412;&#30340;&#38656;&#27714;&#21644;&#25968;&#25454;&#22686;&#24378;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Session-based recommendation, which aims to predict the next item of users' interest as per an existing sequence interaction of items, has attracted growing applications of Contrastive Learning (CL) with improved user and item representations. However, these contrastive objectives: (1) serve a similar role as the cross-entropy loss while ignoring the item representation space optimisation; and (2) commonly require complicated modelling, including complex positive/negative sample constructions and extra data augmentation. In this work, we introduce Self-Contrastive Learning (SCL), which simplifies the application of CL and enhances the performance of state-of-the-art CL-based recommendation techniques. Specifically, SCL is formulated as an objective function that directly promotes a uniform distribution among item representations and efficiently replaces all the existing contrastive objective components of state-of-the-art models. Unlike previous works, SCL eliminates the need for any p
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#26159;&#21542;&#21487;&#20197;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#25277;&#35937;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#33258;&#21160;&#29983;&#25104;&#27861;&#24459;&#26696;&#20363;&#21028;&#20915;&#30340;&#25688;&#35201;&#65292;&#24182;&#22312;&#21360;&#24230;&#30340;&#27861;&#24237;&#26696;&#20363;&#21028;&#20915;&#20013;&#36827;&#34892;&#20102;&#30456;&#20851;&#23454;&#39564;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.01248</link><description>&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#25277;&#35937;&#27169;&#22411;&#21644;LLMs&#22312;&#27861;&#24459;&#26696;&#20363;&#21028;&#20915;&#25688;&#35201;&#20013;&#30340;&#24212;&#29992;&#20934;&#22791;&#24773;&#20917;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?. (arXiv:2306.01248v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01248
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#26159;&#21542;&#21487;&#20197;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#25277;&#35937;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#33258;&#21160;&#29983;&#25104;&#27861;&#24459;&#26696;&#20363;&#21028;&#20915;&#30340;&#25688;&#35201;&#65292;&#24182;&#22312;&#21360;&#24230;&#30340;&#27861;&#24237;&#26696;&#20363;&#21028;&#20915;&#20013;&#36827;&#34892;&#20102;&#30456;&#20851;&#23454;&#39564;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#25688;&#35201;&#27861;&#24459;&#26696;&#20363;&#21028;&#20915;&#19968;&#30452;&#26159;&#37319;&#29992;&#25277;&#21462;&#24335;&#25688;&#35201;&#26041;&#27861;&#23581;&#35797;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36817;&#24180;&#26469;&#65292;&#20855;&#26377;&#29983;&#25104;&#26356;&#33258;&#28982;&#21644;&#36830;&#36143;&#25688;&#35201;&#33021;&#21147;&#30340;&#25277;&#35937;&#25688;&#35201;&#27169;&#22411;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#29616;&#22312;&#24050;&#32463;&#26377;&#20102;&#19987;&#38376;&#29992;&#20110;&#27861;&#24459;&#39046;&#22495;&#30340;&#39044;&#35757;&#32451;&#25277;&#35937;&#25688;&#35201;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#22914;ChatGPT&#36825;&#26679;&#30340;&#36890;&#29992;&#39046;&#22495;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25991;&#26412;&#65292;&#24182;&#20855;&#26377;&#25991;&#26412;&#25688;&#35201;&#30340;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#20540;&#24471;&#38382;&#30340;&#26159;&#65292;&#36825;&#20123;&#27169;&#22411;&#26159;&#21542;&#24050;&#20934;&#22791;&#22909;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#26696;&#20363;&#21028;&#20915;&#30340;&#25277;&#35937;&#25688;&#35201;&#12290;&#20026;&#20102;&#25506;&#35752;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#39046;&#22495;&#29305;&#23450;&#30340;&#25277;&#35937;&#24615;&#25688;&#35201;&#27169;&#22411;&#21644;&#36890;&#29992;&#39046;&#22495;&#30340;LLMs&#24212;&#29992;&#20110;&#21360;&#24230;&#27861;&#24237;&#26696;&#20363;&#21028;&#20915;&#20013;&#65292;&#24182;&#26816;&#26597;&#25152;&#29983;&#25104;&#25688;&#35201;&#30340;&#36136;&#37327;&#12290;&#38500;&#20102;&#25688;&#35201;&#36136;&#37327;&#30340;&#26631;&#20934;&#24230;&#37327;&#65292;&#25105;&#20204;&#36824;&#26816;&#26597;&#20102;&#29983;&#25104;&#30340;&#25688;&#35201;&#20013;&#21487;&#33021;&#23384;&#22312;&#30340;&#19981;&#19968;&#33268;&#24615;&#21644;&#34394;&#26500;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatic summarization of legal case judgements has traditionally been attempted by using extractive summarization methods. However, in recent years, abstractive summarization models are gaining popularity since they can generate more natural and coherent summaries. Legal domain-specific pre-trained abstractive summarization models are now available. Moreover, general-domain pre-trained Large Language Models (LLMs), such as ChatGPT, are known to generate high-quality text and have the capacity for text summarization. Hence it is natural to ask if these models are ready for off-the-shelf application to automatically generate abstractive summaries for case judgements. To explore this question, we apply several state-of-the-art domain-specific abstractive summarization models and general-domain LLMs on Indian court case judgements, and check the quality of the generated summaries. In addition to standard metrics for summary quality, we check for inconsistencies and hallucinations in the 
&lt;/p&gt;</description></item><item><title>TimelineQA&#26159;&#19968;&#20010;&#29992;&#20110;&#26597;&#35810;&#29983;&#27963;&#26085;&#24535;&#30340;&#21152;&#36895;&#36827;&#23637;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#28041;&#21450;&#26102;&#38388;&#21644;&#22320;&#29702;&#20449;&#24687;&#65292;&#24050;&#32463;&#20844;&#24320;&#21457;&#24067;&#65292;&#24182;&#20351;&#29992;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#20294;&#36825;&#20004;&#31181;&#27169;&#22411;&#22343;&#26410;&#36798;&#21040;&#20154;&#31867;&#34920;&#29616;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2306.01069</link><description>&lt;p&gt;
TimelineQA: &#19968;&#20010;&#29992;&#20110;&#26102;&#38388;&#32447;&#38382;&#31572;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
TimelineQA: A Benchmark for Question Answering over Timelines. (arXiv:2306.01069v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01069
&lt;/p&gt;
&lt;p&gt;
TimelineQA&#26159;&#19968;&#20010;&#29992;&#20110;&#26597;&#35810;&#29983;&#27963;&#26085;&#24535;&#30340;&#21152;&#36895;&#36827;&#23637;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#28041;&#21450;&#26102;&#38388;&#21644;&#22320;&#29702;&#20449;&#24687;&#65292;&#24050;&#32463;&#20844;&#24320;&#21457;&#24067;&#65292;&#24182;&#20351;&#29992;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#20294;&#36825;&#20004;&#31181;&#27169;&#22411;&#22343;&#26410;&#36798;&#21040;&#20154;&#31867;&#34920;&#29616;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lifelogs&#65288;&#29983;&#27963;&#26085;&#24535;&#65289;&#26159;&#20154;&#20204;&#29983;&#27963;&#32463;&#21382;&#30340;&#25551;&#36848;&#65292;&#36825;&#20123;&#26085;&#24535;&#36890;&#36807;&#32467;&#21512;&#26469;&#33258;&#22810;&#20010;&#25968;&#23383;&#26381;&#21153;&#65288;&#22914;&#22312;&#32447;&#29031;&#29255;&#12289;&#22320;&#22270;&#12289;&#36141;&#29289;&#21644;&#20869;&#23481;&#27969;&#23186;&#20307;&#26381;&#21153;&#65289;&#30340;&#25968;&#25454;&#26469;&#21019;&#24314;&#12290;&#38382;&#31572;&#25216;&#26415;&#22312;&#29983;&#27963;&#26085;&#24535;&#19978;&#30340;&#24212;&#29992;&#21487;&#20197;&#20026;&#20010;&#20154;&#21161;&#25163;&#22312;&#25552;&#20379;&#19978;&#19979;&#25991;&#26041;&#38754;&#25552;&#20379;&#20851;&#38190;&#36164;&#28304;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#29983;&#27963;&#26085;&#24535;&#32467;&#21512;&#20102;&#33258;&#30001;&#25991;&#26412;&#19982;&#19968;&#23450;&#31243;&#24230;&#30340;&#32467;&#26500;&#65292;&#22914;&#26102;&#38388;&#21644;&#22320;&#29702;&#20449;&#24687;&#65292;&#22240;&#27492;&#24403;&#21069;&#30340;&#38382;&#31572;&#25216;&#26415;&#26080;&#27861;&#22238;&#31572;&#27492;&#31867;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#21019;&#24314;&#24182;&#20844;&#24320;&#21457;&#24067;&#20102;TimelineQA&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#26597;&#35810;&#29983;&#27963;&#26085;&#24535;&#30340;&#21152;&#36895;&#36827;&#23637;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;TimelineQA&#29983;&#25104;&#34394;&#26500;&#20154;&#29289;&#30340;&#29983;&#27963;&#26085;&#24535;&#12290;&#29983;&#27963;&#26085;&#24535;&#20013;&#30340;&#20107;&#20214;&#20174;&#39640;&#20013;&#27605;&#19994;&#31561;&#37325;&#22823;&#29983;&#27963;&#20107;&#20214;&#21040;&#26085;&#24120;&#27963;&#21160;&#22914;&#24930;&#36305;&#37117;&#26377;&#25152;&#35206;&#30422;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#20851;&#20110;TimelineQA&#30340;&#23454;&#39564;&#65292;&#20351;&#29992;&#20102;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#65292;&#21457;&#29616;&#36825;&#20004;&#31181;&#27169;&#22411;&#22312;&#36825;&#19968;&#20219;&#21153;&#19978;&#22343;&#26410;&#36798;&#21040;&#20154;&#31867;&#34920;&#29616;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lifelogs are descriptions of experiences that a person had during their life. Lifelogs are created by fusing data from the multitude of digital services, such as online photos, maps, shopping and content streaming services. Question answering over lifelogs can offer personal assistants a critical resource when they try to provide advice in context. However, obtaining answers to questions over lifelogs is beyond the current state of the art of question answering techniques for a variety of reasons, the most pronounced of which is that lifelogs combine free text with some degree of structure such as temporal and geographical information.  We create and publicly release TimelineQA1, a benchmark for accelerating progress on querying lifelogs. TimelineQA generates lifelogs of imaginary people. The episodes in the lifelog range from major life episodes such as high school graduation to those that occur on a daily basis such as going for a run. We describe a set of experiments on TimelineQA w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32467;&#26500;&#21387;&#32553;&#21644;&#27169;&#22411;&#23610;&#23544;&#19981;&#23545;&#31216;&#30340;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411; KALE&#65292;&#26377;&#25928;&#25552;&#39640;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#30340;&#25512;&#29702;&#25928;&#29575;&#65292;&#21516;&#26102;&#20801;&#35768;&#26597;&#35810;&#32534;&#30721;&#22120;&#30340;&#26377;&#25928;&#21387;&#32553;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20840;&#37096;&#30340;&#20877;&#35757;&#32451;&#25110;&#32034;&#24341;&#29983;&#25104;&#65292;&#27492;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#36229;&#36807;DistilBERT&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2304.01016</link><description>&lt;p&gt;
&#24555;&#36895;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#22120;&#21033;&#29992;KALE&#36827;&#34892;&#21518;&#32622;KL&#23545;&#40784;&#30340;&#24322;&#24418;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411;&#35757;&#32451; (arXiv:2304.01016v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
Quick Dense Retrievers Consume KALE: Post Training Kullback Leibler Alignment of Embeddings for Asymmetrical dual encoders. (arXiv:2304.01016v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01016
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32467;&#26500;&#21387;&#32553;&#21644;&#27169;&#22411;&#23610;&#23544;&#19981;&#23545;&#31216;&#30340;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411; KALE&#65292;&#26377;&#25928;&#25552;&#39640;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#30340;&#25512;&#29702;&#25928;&#29575;&#65292;&#21516;&#26102;&#20801;&#35768;&#26597;&#35810;&#32534;&#30721;&#22120;&#30340;&#26377;&#25928;&#21387;&#32553;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20840;&#37096;&#30340;&#20877;&#35757;&#32451;&#25110;&#32034;&#24341;&#29983;&#25104;&#65292;&#27492;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#36229;&#36807;DistilBERT&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#32467;&#26500;&#21387;&#32553;&#21644;&#27169;&#22411;&#23610;&#23544;&#19981;&#23545;&#31216;&#30340;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411;&#65292;&#26088;&#22312;&#25552;&#39640;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#30340;&#25512;&#29702;&#36895;&#24230;&#12290;&#36890;&#36807;&#23545;MSMARCO&#12289;&#33258;&#28982;&#38382;&#31572;&#12289;&#38382;&#31572;&#28216;&#25103;&#31561;&#22810;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#21069;&#21518;&#35757;&#32451;&#21387;&#32553;&#23454;&#39564;&#65292;&#30740;&#31350;&#20102;&#21387;&#32553;&#23545;&#31995;&#32479;&#25512;&#29702;&#25928;&#29575;&#30340;&#24433;&#21709;&#65292;&#32467;&#26524;&#34920;&#26126;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#22120;&#30340;&#21452;&#32534;&#30721;&#22120;&#32467;&#26500;&#24322;&#24418;&#21270;&#26377;&#21161;&#20110;&#25552;&#39640;&#20854;&#25512;&#29702;&#25928;&#29575;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;Kullback Leibler Alignment of Embeddings (KALE)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35009;&#21098;&#21644;&#23545;&#40784;&#26597;&#35810;&#32534;&#30721;&#22120;&#65292;&#25552;&#39640;&#20102;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#30340;&#25512;&#29702;&#25928;&#29575;&#12290;KALE&#25193;&#23637;&#20102;&#20256;&#32479;&#30340;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#65292;&#20351;&#24471;&#22312;&#21452;&#32534;&#30721;&#22120;&#35757;&#32451;&#21518;&#21487;&#20197;&#26377;&#25928;&#22320;&#23545;&#26597;&#35810;&#32534;&#30721;&#22120;&#36827;&#34892;&#21387;&#32553;&#32780;&#26080;&#38656;&#36827;&#34892;&#23436;&#25972;&#30340;&#20877;&#35757;&#32451;&#25110;&#32034;&#24341;&#29983;&#25104;&#12290;&#20351;&#29992;KALE&#21644;&#19981;&#23545;&#31216;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;DistilBERT&#24615;&#33021;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#27169;&#22411;&#23610;&#23544;&#26356;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the problem of improving the inference latency of language model-based dense retrieval systems by introducing structural compression and model size asymmetry between the context and query encoders. First, we investigate the impact of pre and post-training compression on the MSMARCO, Natural Questions, TriviaQA, SQUAD, and SCIFACT, finding that asymmetry in the dual encoders in dense retrieval can lead to improved inference efficiency. Knowing this, we introduce Kullback Leibler Alignment of Embeddings (KALE), an efficient and accurate method for increasing the inference efficiency of dense retrieval methods by pruning and aligning the query encoder after training. Specifically, KALE extends traditional Knowledge Distillation after bi-encoder training, allowing for effective query encoder compression without full retraining or index generation. Using KALE and asymmetric training, we can generate models which exceed the performance of DistilBERT despite having 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20154;&#31867;&#20559;&#22909;&#30340;&#25512;&#33616;&#31995;&#32479;&#33539;&#24335;PrefRec&#65292;&#20801;&#35768;&#24378;&#21270;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#20559;&#22909;&#20013;&#23398;&#20064;&#65292;&#20197;&#20248;&#21270;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#12290;</title><link>http://arxiv.org/abs/2212.02779</link><description>&lt;p&gt;
PrefRec&#65306;&#21033;&#29992;&#20154;&#31867;&#20559;&#22909;&#21152;&#24378;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
PrefRec: Recommender Systems with Human Preferences for Reinforcing Long-term User Engagement. (arXiv:2212.02779v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.02779
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20154;&#31867;&#20559;&#22909;&#30340;&#25512;&#33616;&#31995;&#32479;&#33539;&#24335;PrefRec&#65292;&#20801;&#35768;&#24378;&#21270;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#20559;&#22909;&#20013;&#23398;&#20064;&#65292;&#20197;&#20248;&#21270;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#25512;&#33616;&#31995;&#32479;&#22312;&#20248;&#21270;&#21363;&#26102;&#21442;&#19982;&#26041;&#38754;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#26356;&#21487;&#21462;&#30340;&#32489;&#25928;&#25351;&#26631;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#30340;&#25552;&#39640;&#20173;&#28982;&#24456;&#38590;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#26368;&#36817;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#22312;&#21508;&#31181;&#38271;&#26399;&#30446;&#26631;&#20248;&#21270;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26377;&#25928;&#24615;&#12290;&#22240;&#27492;&#65292;&#24378;&#21270;&#23398;&#20064;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#20248;&#21270;&#25512;&#33616;&#20013;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#30340;&#26377;&#21069;&#36884;&#30340;&#26694;&#26550;&#12290;&#34429;&#28982;&#26377;&#21069;&#36884;&#65292;&#20294;&#24212;&#29992;&#24378;&#21270;&#23398;&#20064;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#31934;&#24515;&#35774;&#35745;&#30340;&#22870;&#21169;&#65292;&#20294;&#35774;&#35745;&#19982;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#26377;&#20851;&#30340;&#22870;&#21169;&#30456;&#24403;&#22256;&#38590;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#24335;&#65292;&#21363;&#20197;&#20154;&#31867;&#20559;&#22909;&#20026;&#22522;&#30784;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#20801;&#35768;&#24378;&#21270;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#20174;&#26377;&#20851;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#30340;&#20559;&#22909;&#20013;&#23398;&#20064;&#65292;&#32780;&#19981;&#26159;&#20174;&#26126;&#30830;&#23450;&#20041;&#30340;&#22870;&#21169;&#20013;&#23398;&#20064;&#12290;&#36825;&#20123;&#20559;&#22909;&#21487;&#20197;&#36890;&#36807;&#20247;&#21253;&#31561;&#25216;&#26415;&#36731;&#26494;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current advances in recommender systems have been remarkably successful in optimizing immediate engagement. However, long-term user engagement, a more desirable performance metric, remains difficult to improve. Meanwhile, recent reinforcement learning (RL) algorithms have shown their effectiveness in a variety of long-term goal optimization tasks. For this reason, RL is widely considered as a promising framework for optimizing long-term user engagement in recommendation. Though promising, the application of RL heavily relies on well-designed rewards, but designing rewards related to long-term user engagement is quite difficult. To mitigate the problem, we propose a novel paradigm, recommender systems with human preferences (or Preference-based Recommender systems), which allows RL recommender systems to learn from preferences about users historical behaviors rather than explicitly defined rewards. Such preferences are easily accessible through techniques such as crowdsourcing, as they 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#33258;&#30417;&#30563;&#25512;&#33616;&#65288;SSR&#65289;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#26041;&#27861;&#65306;&#23545;&#27604;&#12289;&#29983;&#25104;&#12289;&#39044;&#27979;&#21644;&#28151;&#21512;&#65292;&#24182;&#20171;&#32461;&#20102;&#21508;&#31181;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#21450;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2203.15876</link><description>&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#65306;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Self-Supervised Learning for Recommender Systems: A Survey. (arXiv:2203.15876v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.15876
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#33258;&#30417;&#30563;&#25512;&#33616;&#65288;SSR&#65289;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#26041;&#27861;&#65306;&#23545;&#27604;&#12289;&#29983;&#25104;&#12289;&#39044;&#27979;&#21644;&#28151;&#21512;&#65292;&#24182;&#20171;&#32461;&#20102;&#21508;&#31181;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#21450;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#33616;&#31995;&#32479;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#22312;&#22788;&#29702;&#39640;&#24230;&#31232;&#30095;&#30340;&#25968;&#25454;&#26102;&#20173;&#19981;&#23613;&#20154;&#24847;&#12290;&#33258;&#30417;&#30563;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#20174;&#26080;&#26631;&#31614;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#26032;&#20852;&#25216;&#26415;&#65292;&#24050;&#32463;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#34987;&#30475;&#20316;&#26159;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#28508;&#22312;&#26041;&#27861;&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;&#33258;&#30417;&#30563;&#25512;&#33616;&#30340;&#30740;&#31350;&#24037;&#20316;&#65292;&#25552;&#20986;&#20102;&#33258;&#30417;&#30563;&#25512;&#33616;&#30340;&#23450;&#20041;&#21644;&#20998;&#31867;&#26041;&#27861;&#65292;&#24182;&#35814;&#32454;&#20171;&#32461;&#20102;&#21508;&#31181;&#26041;&#27861;&#30340;&#20248;&#21155;&#20197;&#21450;&#23558;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, neural architecture-based recommender systems have achieved tremendous success, but they still fall short of expectation when dealing with highly sparse data. Self-supervised learning (SSL), as an emerging technique for learning from unlabeled data, has attracted considerable attention as a potential solution to this issue. This survey paper presents a systematic and timely review of research efforts on self-supervised recommendation (SSR). Specifically, we propose an exclusive definition of SSR, on top of which we develop a comprehensive taxonomy to divide existing SSR methods into four categories: contrastive, generative, predictive, and hybrid. For each category, we elucidate its concept and formulation, the involved methods, as well as its pros and cons. Furthermore, to facilitate empirical comparison, we release an open-source library SELFRec (https://github.com/Coder-Yu/SELFRec), which incorporates a wide range of SSR models and benchmark datasets. Through rigoro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24773;&#24863;&#21644;&#21477;&#23376;&#31867;&#22411;&#30340;&#26041;&#27861;&#65292;&#23558;&#21407;&#22987;&#30340;YouTube&#35780;&#35770;&#20998;&#31867;&#65292;&#20197;&#24110;&#21161;YouTuber&#25214;&#21040;&#26356;&#30456;&#20851;&#30340;&#35780;&#35770;&#65292;&#20174;&#32780;&#22686;&#21152;&#20854;&#35266;&#20247;&#32676;&#12290;</title><link>http://arxiv.org/abs/2111.01908</link><description>&lt;p&gt;
&#22522;&#20110;&#24773;&#24863;&#21644;&#21477;&#23376;&#31867;&#22411;&#23545;YouTube&#35780;&#35770;&#36827;&#34892;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Classifying YouTube Comments Based on Sentiment and Type of Sentence. (arXiv:2111.01908v1 [cs.IR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.01908
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24773;&#24863;&#21644;&#21477;&#23376;&#31867;&#22411;&#30340;&#26041;&#27861;&#65292;&#23558;&#21407;&#22987;&#30340;YouTube&#35780;&#35770;&#20998;&#31867;&#65292;&#20197;&#24110;&#21161;YouTuber&#25214;&#21040;&#26356;&#30456;&#20851;&#30340;&#35780;&#35770;&#65292;&#20174;&#32780;&#22686;&#21152;&#20854;&#35266;&#20247;&#32676;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;YouTube&#39057;&#36947;&#30340;&#22686;&#38271;&#65292;&#27599;&#20010;&#35270;&#39057;&#37117;&#21487;&#33021;&#25910;&#38598;&#22823;&#37327;&#35780;&#35770;&#65292;&#36825;&#20123;&#35780;&#35770;&#26159;&#29702;&#35299;&#35266;&#20247;&#26399;&#26395;&#21644;&#25913;&#21892;&#39057;&#36947;&#21442;&#19982;&#24230;&#30340;&#20027;&#35201;&#25163;&#27573;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#35780;&#35770;&#21482;&#20195;&#34920;&#29992;&#25143;&#20851;&#20110;&#39057;&#36947;&#21644;&#20869;&#23481;&#30340;&#19968;&#33324;&#35266;&#28857;&#12290;&#35768;&#22810;&#35780;&#35770;&#26500;&#36896;&#36739;&#24046;&#65292;&#29712;&#30862;&#24182;&#19988;&#23384;&#22312;&#25340;&#20889;&#21644;&#35821;&#27861;&#38169;&#35823;&#65292;&#22240;&#27492;&#65292;&#35782;&#21035;&#26368;&#33021;&#21560;&#24341;&#20869;&#23481;&#21019;&#20316;&#32773;&#30340;&#35780;&#35770;&#26159;&#19968;&#39033;&#32321;&#29712;&#30340;&#24037;&#20316;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#24773;&#24863;&#21644;&#21477;&#23376;&#31867;&#22411;&#23558;&#21407;&#22987;&#35780;&#35770;&#20998;&#31867;&#65292;&#20197;&#24110;&#21161;YouTuber&#25214;&#21040;&#26356;&#30456;&#20851;&#30340;&#35780;&#35770;&#65292;&#20174;&#32780;&#22686;&#21152;&#20854;&#35266;&#20247;&#32676;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a YouTube channel grows, each video can potentially collect enormous amounts of comments that provide direct feedback from the viewers. These comments are a major means of understanding viewer expectations and improving channel engagement. However, the comments only represent a general collection of user opinions about the channel and the content. Many comments are poorly constructed, trivial, and have improper spellings and grammatical errors. As a result, it is a tedious job to identify the comments that best interest the content creators. In this paper, we extract and classify the raw comments into different categories based on both sentiment and sentence types that will help YouTubers find relevant comments for growing their viewership. Existing studies have focused either on sentiment analysis (positive and negative) or classification of sub-types within the same sentence types (e.g., types of questions) on a text corpus. These have limited application on non-traditional text c
&lt;/p&gt;</description></item></channel></rss>