<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>SPAR&#26159;&#19968;&#20010;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;PLM&#12289;&#22810;&#27880;&#24847;&#21147;&#23618;&#21644;&#27880;&#24847;&#21147;&#31232;&#30095;&#26426;&#21046;&#65292;&#22312;&#20250;&#35805;&#32423;&#21035;&#26377;&#25928;&#22320;&#22788;&#29702;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#65292;&#25552;&#21462;&#20840;&#38754;&#29992;&#25143;&#20852;&#36259;&#65292;&#23454;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;</title><link>https://arxiv.org/abs/2402.10555</link><description>&lt;p&gt;
SPAR&#65306;&#36890;&#36807;&#38271;&#26399;&#21442;&#19982;&#27880;&#24847;&#21147;&#23454;&#29616;&#20010;&#24615;&#21270;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
SPAR: Personalized Content-Based Recommendation via Long Engagement Attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10555
&lt;/p&gt;
&lt;p&gt;
SPAR&#26159;&#19968;&#20010;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;PLM&#12289;&#22810;&#27880;&#24847;&#21147;&#23618;&#21644;&#27880;&#24847;&#21147;&#31232;&#30095;&#26426;&#21046;&#65292;&#22312;&#20250;&#35805;&#32423;&#21035;&#26377;&#25928;&#22320;&#22788;&#29702;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#65292;&#25552;&#21462;&#20840;&#38754;&#29992;&#25143;&#20852;&#36259;&#65292;&#23454;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#29992;&#25143;&#38271;&#26399;&#21442;&#19982;&#21382;&#21490;&#23545;&#20010;&#24615;&#21270;&#20869;&#23481;&#25512;&#33616;&#33267;&#20851;&#37325;&#35201;&#12290;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25104;&#21151;&#23548;&#33268;&#23427;&#20204;&#34987;&#29992;&#20110;&#32534;&#30721;&#29992;&#25143;&#21382;&#21490;&#21644;&#20505;&#36873;&#39033;&#65292;&#23558;&#20869;&#23481;&#25512;&#33616;&#35270;&#20026;&#25991;&#26412;&#35821;&#20041;&#21305;&#37197;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#24037;&#20316;&#20173;&#28982;&#22312;&#22788;&#29702;&#38750;&#24120;&#38271;&#30340;&#29992;&#25143;&#21382;&#21490;&#25991;&#26412;&#21644;&#19981;&#36275;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#26694;&#26550;SPAR&#65292;&#26377;&#25928;&#24212;&#23545;&#20102;&#20174;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#20013;&#25552;&#21462;&#20840;&#38754;&#29992;&#25143;&#20852;&#36259;&#30340;&#25361;&#25112;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;PLM&#12289;&#22810;&#27880;&#24847;&#21147;&#23618;&#21644;&#27880;&#24847;&#21147;&#31232;&#30095;&#26426;&#21046;&#20197;&#20250;&#35805;&#20026;&#22522;&#30784;&#23545;&#29992;&#25143;&#30340;&#21382;&#21490;&#36827;&#34892;&#32534;&#30721;&#12290;&#29992;&#25143;&#21644;&#29289;&#21697;&#20391;&#29305;&#24449;&#34987;&#20805;&#20998;&#34701;&#21512;&#36827;&#34892;&#21442;&#19982;&#39044;&#27979;&#65292;&#21516;&#26102;&#20445;&#25345;&#21452;&#26041;&#30340;&#29420;&#31435;&#34920;&#31034;&#65292;&#36825;&#23545;&#20110;&#23454;&#38469;&#27169;&#22411;&#37096;&#32626;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10555v1 Announce Type: cross  Abstract: Leveraging users' long engagement histories is essential for personalized content recommendations. The success of pretrained language models (PLMs) in NLP has led to their use in encoding user histories and candidate items, framing content recommendations as textual semantic matching tasks. However, existing works still struggle with processing very long user historical text and insufficient user-item interaction. In this paper, we introduce a content-based recommendation framework, SPAR, which effectively tackles the challenges of holistic user interest extraction from the long user engagement history. It achieves so by leveraging PLM, poly-attention layers and attention sparsity mechanisms to encode user's history in a session-based manner. The user and item side features are sufficiently fused for engagement prediction while maintaining standalone representations for both sides, which is efficient for practical model deployment. Mor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#26080;&#30417;&#30563;&#36873;&#25321;&#26368;&#20339;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#26032;&#25216;&#26415;&#12290;&#36873;&#25321;&#21512;&#36866;&#30340;&#26816;&#32034;&#22120;&#23545;&#20110;&#24212;&#29992;&#20110;&#26032;&#30340;&#30446;&#26631;&#35821;&#26009;&#24211;&#24182;&#19988;&#23384;&#22312;&#39046;&#22495;&#36716;&#31227;&#30340;&#24773;&#20917;&#38750;&#24120;&#37325;&#35201;&#12290;</title><link>https://arxiv.org/abs/2402.04853</link><description>&lt;p&gt;
&#21033;&#29992;LLMs&#36827;&#34892;&#26080;&#30417;&#30563;&#30340;&#23494;&#38598;&#26816;&#32034;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Leveraging LLMs for Unsupervised Dense Retriever Ranking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#26080;&#30417;&#30563;&#36873;&#25321;&#26368;&#20339;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#26032;&#25216;&#26415;&#12290;&#36873;&#25321;&#21512;&#36866;&#30340;&#26816;&#32034;&#22120;&#23545;&#20110;&#24212;&#29992;&#20110;&#26032;&#30340;&#30446;&#26631;&#35821;&#26009;&#24211;&#24182;&#19988;&#23384;&#22312;&#39046;&#22495;&#36716;&#31227;&#30340;&#24773;&#20917;&#38750;&#24120;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30830;&#23450;&#29305;&#23450;&#27979;&#35797;&#65288;&#30446;&#26631;&#65289;&#35821;&#26009;&#24211;&#26368;&#21512;&#36866;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#26032;&#39062;&#26080;&#30417;&#30563;&#25216;&#26415;&#12290;&#36873;&#25321;&#21512;&#36866;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#23545;&#20110;&#35768;&#22810;&#37319;&#29992;&#36825;&#20123;&#22312;&#20844;&#24320;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#26816;&#32034;&#22120;&#36827;&#34892;&#32534;&#30721;&#25110;&#22312;&#26032;&#30340;&#31169;&#26377;&#30446;&#26631;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#25628;&#32034;&#30340;&#20449;&#24687;&#26816;&#32034;&#24212;&#29992;&#31243;&#24207;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#23494;&#38598;&#26816;&#32034;&#22120;&#24212;&#29992;&#20110;&#19982;&#21407;&#22987;&#35757;&#32451;&#38598;&#22312;&#39046;&#22495;&#25110;&#20219;&#21153;&#19978;&#26377;&#24046;&#24322;&#30340;&#30446;&#26631;&#35821;&#26009;&#24211;&#26102;&#65292;&#20854;&#26377;&#25928;&#24615;&#21487;&#33021;&#20250;&#22823;&#22823;&#38477;&#20302;&#12290;&#22312;&#30446;&#26631;&#35821;&#26009;&#24211;&#27809;&#26377;&#26631;&#27880;&#30340;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#22312;&#38646;&#26679;&#26412;&#22330;&#26223;&#20013;&#65292;&#26080;&#27861;&#30452;&#25509;&#35780;&#20272;&#27169;&#22411;&#22312;&#30446;&#26631;&#35821;&#26009;&#24211;&#19978;&#30340;&#25928;&#26524;&#12290;&#22240;&#27492;&#65292;&#26080;&#30417;&#30563;&#36873;&#25321;&#26368;&#20339;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#65292;&#29305;&#21035;&#26159;&#22312;&#39046;&#22495;&#36801;&#31227;&#26465;&#20214;&#19979;&#65292;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#25490;&#24207;&#26041;&#27861;&#22312;&#35299;&#20915;&#36825;&#20123;&#39046;&#22495;&#36801;&#31227;&#38382;&#39064;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel unsupervised technique that utilizes large language models (LLMs) to determine the most suitable dense retriever for a specific test(target) corpus. Selecting the appropriate dense retriever is vital for numerous IR applications that employ these retrievers, trained on public datasets, to encode or conduct searches within a new private target corpus. The effectiveness of a dense retriever can significantly diminish when applied to a target corpus that diverges in domain or task from the original training set. The problem becomes more pronounced in cases where the target corpus is unlabeled, e.g. in zero-shot scenarios, rendering direct evaluation of the model's effectiveness on the target corpus unattainable. Therefore, the unsupervised selection of an optimally pre-trained dense retriever, especially under conditions of domain shift, emerges as a critical challenge. Existing methodologies for ranking dense retrievers fall short in addressing these domain 
&lt;/p&gt;</description></item><item><title>&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;&#20102;&#25512;&#33616;&#31995;&#32479;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#21040;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#36716;&#21464;&#12290;&#36825;&#31687;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25512;&#33616;&#25968;&#25454;&#30340;&#20027;&#35201;&#38382;&#39064;&#20197;&#21450;&#26368;&#36817;&#30340;&#30740;&#31350;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2401.17878</link><description>&lt;p&gt;
&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Data-Centric Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17878
&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;&#20102;&#25512;&#33616;&#31995;&#32479;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#21040;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#36716;&#21464;&#12290;&#36825;&#31687;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25512;&#33616;&#25968;&#25454;&#30340;&#20027;&#35201;&#38382;&#39064;&#20197;&#21450;&#26368;&#36817;&#30340;&#30740;&#31350;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#24212;&#23545;&#20449;&#24687;&#36807;&#36733;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#23454;&#38469;&#22330;&#26223;&#12290;&#26368;&#36817;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#36235;&#21183;&#20986;&#29616;&#20102;&#33539;&#24335;&#36716;&#21464;&#65292;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#30340;&#21019;&#26032;&#36716;&#21521;&#25968;&#25454;&#36136;&#37327;&#21644;&#25968;&#37327;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#19968;&#21464;&#21270;&#24341;&#20986;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#65288;Data-Centric RS&#65289;&#30340;&#27010;&#24565;&#65292;&#26631;&#24535;&#30528;&#35813;&#39046;&#22495;&#30340;&#37325;&#35201;&#21457;&#23637;&#12290;&#26412;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#22320;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#65292;&#21253;&#25324;1&#65289;&#25512;&#33616;&#25968;&#25454;&#21644;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#65307;2&#65289;&#25512;&#33616;&#25968;&#25454;&#38754;&#20020;&#30340;&#19977;&#20010;&#20027;&#35201;&#38382;&#39064;&#65307;3&#65289;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#32780;&#24320;&#23637;&#30340;&#26368;&#36817;&#30740;&#31350;&#65307;&#20197;&#21450;4&#65289;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#30340;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RS) have become essential tools for mitigating information overload in a range of real-world scenarios. Recent trends in RS have seen a paradigm shift, moving the spotlight from model-centric innovations to the importance of data quality and quantity. This evolution has given rise to the concept of data-centric recommender systems (Data-Centric RS), marking a significant development in the field. This survey provides the first systematic overview of Data-Centric RS, covering 1) the foundational concepts of recommendation data and Data-Centric RS; 2) three primary issues in recommendation data; 3) recent research developed to address these issues; and 4) several potential future directions in Data-Centric RS.
&lt;/p&gt;</description></item><item><title>&#35780;&#20272;&#20102;&#24403;&#21069;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861;&#22312;&#35268;&#27169;&#21270;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#38543;&#30528;&#27169;&#22411;&#34987;&#39034;&#24207;&#32534;&#36753;&#22810;&#20010;&#20107;&#23454;&#65292;&#23427;&#20250;&#36880;&#28176;&#36951;&#24536;&#20808;&#21069;&#30340;&#20107;&#23454;&#21450;&#25191;&#34892;&#19979;&#28216;&#20219;&#21153;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2401.07453</link><description>&lt;p&gt;
&#35268;&#27169;&#21270;&#27169;&#22411;&#32534;&#36753;&#20250;&#23548;&#33268;&#28176;&#36827;&#24615;&#21644;&#31361;&#21457;&#24615;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Model Editing at Scale leads to Gradual and Catastrophic Forgetting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.07453
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#20102;&#24403;&#21069;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861;&#22312;&#35268;&#27169;&#21270;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#38543;&#30528;&#27169;&#22411;&#34987;&#39034;&#24207;&#32534;&#36753;&#22810;&#20010;&#20107;&#23454;&#65292;&#23427;&#20250;&#36880;&#28176;&#36951;&#24536;&#20808;&#21069;&#30340;&#20107;&#23454;&#21450;&#25191;&#34892;&#19979;&#28216;&#20219;&#21153;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#32534;&#36753;&#30693;&#35782;&#26159;&#19968;&#31181;&#20855;&#26377;&#21560;&#24341;&#21147;&#30340;&#33021;&#21147;&#65292;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#39044;&#35757;&#32451;&#26399;&#38388;&#32416;&#27491;&#38169;&#35823;&#23398;&#20064;&#30340;&#20107;&#23454;&#65292;&#21516;&#26102;&#20351;&#29992;&#19981;&#26029;&#22686;&#38271;&#30340;&#26032;&#20107;&#23454;&#21015;&#34920;&#26356;&#26032;&#27169;&#22411;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#20026;&#20102;&#20351;&#27169;&#22411;&#32534;&#36753;&#20855;&#26377;&#23454;&#38469;&#25928;&#29992;&#65292;&#25105;&#20204;&#24517;&#39035;&#33021;&#22815;&#23545;&#21516;&#19968;&#27169;&#22411;&#36827;&#34892;&#22810;&#27425;&#32534;&#36753;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#24403;&#21069;&#35268;&#27169;&#19979;&#30340;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65306;ROME &#21644; MEMIT&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#38543;&#30528;&#27169;&#22411;&#34987;&#39034;&#24207;&#32534;&#36753;&#22810;&#20010;&#20107;&#23454;&#65292;&#23427;&#19981;&#26029;&#22320;&#36951;&#24536;&#20808;&#21069;&#32534;&#36753;&#36807;&#30340;&#20107;&#23454;&#20197;&#21450;&#25191;&#34892;&#19979;&#28216;&#20219;&#21153;&#30340;&#33021;&#21147;&#12290;&#36825;&#31181;&#36951;&#24536;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;--&#21021;&#22987;&#30340;&#28176;&#36827;&#24615;&#36951;&#24536;&#38454;&#27573;&#65292;&#38543;&#21518;&#26159;&#31361;&#28982;&#25110;&#28798;&#38590;&#24615;&#30340;&#36951;&#24536;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.07453v2 Announce Type: replace-cross  Abstract: Editing knowledge in large language models is an attractive capability to have which allows us to correct incorrectly learnt facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated using metrics for reliability, specificity and generalization over one or few edits. We argue that for model editing to have practical utility, we must be able to make multiple edits to the same model. With this in mind, we evaluate the current model editing methods at scale, focusing on two state of the art methods: ROME and MEMIT. We find that as the model is edited sequentially with multiple facts, it continually forgets previously edited facts and the ability to perform downstream tasks. This forgetting happens in two phases -- an initial gradual but progressive forgetting phase followed by abrupt or catastrophic forgettin
&lt;/p&gt;</description></item><item><title>ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2401.10225</link><description>&lt;p&gt;
ChatQA: &#26500;&#24314;GPT-4&#32423;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10225
&lt;/p&gt;
&lt;p&gt;
ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChatQA&#65292;&#19968;&#31995;&#21015;&#20855;&#26377;GPT-4&#32423;&#21035;&#20934;&#30830;&#24615;&#30340;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#22788;&#29702;&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#26816;&#32034;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#22810;&#36718;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#24494;&#35843;&#65292;&#36825;&#26679;&#21487;&#20197;&#25552;&#20379;&#19982;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22823;&#22823;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;ChatQA-70B&#21487;&#20197;&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24179;&#22343;&#20998;&#19978;&#36229;&#36807;GPT-4&#65288;54.14 vs. 53.90&#65289;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;OpenAI GPT&#27169;&#22411;&#30340;&#20219;&#20309;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.
&lt;/p&gt;</description></item><item><title>UOEP&#26159;&#19968;&#31181;&#29992;&#25143;&#23548;&#21521;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#19981;&#21516;&#27963;&#36291;&#27700;&#24179;&#30340;&#29992;&#25143;&#32676;&#20307;&#23454;&#29616;&#32454;&#31890;&#24230;&#25506;&#32034;&#65292;&#20197;&#22686;&#24378;&#29992;&#25143;&#30340;&#38271;&#26399;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2401.09034</link><description>&lt;p&gt;
UOEP: &#29992;&#25143;&#23548;&#21521;&#30340;&#25506;&#32034;&#31574;&#30053;&#20197;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38271;&#26399;&#29992;&#25143;&#20307;&#39564;
&lt;/p&gt;
&lt;p&gt;
UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems. (arXiv:2401.09034v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09034
&lt;/p&gt;
&lt;p&gt;
UOEP&#26159;&#19968;&#31181;&#29992;&#25143;&#23548;&#21521;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#19981;&#21516;&#27963;&#36291;&#27700;&#24179;&#30340;&#29992;&#25143;&#32676;&#20307;&#23454;&#29616;&#32454;&#31890;&#24230;&#25506;&#32034;&#65292;&#20197;&#22686;&#24378;&#29992;&#25143;&#30340;&#38271;&#26399;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#24050;&#32463;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#65292;&#26377;&#25928;&#22320;&#25506;&#32034;&#29992;&#25143;&#30340;&#20852;&#36259;&#65292;&#20197;&#25552;&#21319;&#29992;&#25143;&#30340;&#38271;&#26399;&#20307;&#39564;&#12290;&#28982;&#32780;&#65292;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#30528;&#25968;&#21315;&#19975;&#20010;&#39033;&#30446;&#20043;&#38388;&#30340;&#19981;&#21516;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#65292;&#36825;&#22686;&#21152;&#20102;&#25506;&#32034;&#30340;&#38590;&#24230;&#12290;&#20363;&#22914;&#65292;&#19981;&#21516;&#27963;&#36291;&#27700;&#24179;&#30340;&#29992;&#25143;&#34892;&#20026;&#38656;&#35201;&#19981;&#21516;&#24378;&#24230;&#30340;&#25506;&#32034;&#65292;&#32780;&#20043;&#21069;&#30340;&#30740;&#31350;&#24448;&#24448;&#24573;&#35270;&#20102;&#36825;&#19968;&#26041;&#38754;&#65292;&#23545;&#25152;&#26377;&#29992;&#25143;&#24212;&#29992;&#32479;&#19968;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#26368;&#32456;&#25439;&#23475;&#20102;&#29992;&#25143;&#30340;&#38271;&#26399;&#20307;&#39564;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#25143;&#23548;&#21521;&#30340;&#25506;&#32034;&#31574;&#30053;&#65288;UOEP&#65289;&#65292;&#19968;&#31181;&#22312;&#29992;&#25143;&#32676;&#20307;&#20013;&#23454;&#29616;&#32454;&#31890;&#24230;&#25506;&#32034;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#26500;&#24314;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#35780;&#35770;&#23478;&#65292;&#23427;&#20801;&#35768;&#22312;&#19981;&#21516;&#30340;&#32047;&#31215;&#22870;&#21169;&#21453;&#39304;&#30340;&#20998;&#20301;&#25968;&#27700;&#24179;&#19979;&#36827;&#34892;&#31574;&#30053;&#20248;&#21270;&#65292;&#34920;&#31034;&#20855;&#26377;&#19981;&#21516;&#27963;&#21160;&#27700;&#24179;&#30340;&#29992;&#25143;&#32676;&#20307;&#12290;&#22312;&#36825;&#20010;&#35780;&#35770;&#23478;&#30340;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#32452;&#19981;&#21516;&#30340;&#28436;&#21592;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) has gained traction for enhancing user long-term experiences in recommender systems by effectively exploring users' interests. However, modern recommender systems exhibit distinct user behavioral patterns among tens of millions of items, which increases the difficulty of exploration. For example, user behaviors with different activity levels require varying intensity of exploration, while previous studies often overlook this aspect and apply a uniform exploration strategy to all users, which ultimately hurts user experiences in the long run. To address these challenges, we propose User-Oriented Exploration Policy (UOEP), a novel approach facilitating fine-grained exploration among user groups. We first construct a distributional critic which allows policy optimization under varying quantile levels of cumulative reward feedbacks from users, representing user groups with varying activity levels. Guided by this critic, we devise a population of distinct actors 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#30340;&#25932;&#23545;&#39033;&#30446;&#25512;&#24191;&#30340;&#24341;&#23548;&#25193;&#25955;&#65292;&#25581;&#31034;&#20102;&#29289;&#21697;&#20379;&#24212;&#21830;&#22914;&#20309;&#36890;&#36807;&#26500;&#24314;&#25932;&#23545;&#22270;&#20687;&#26469;&#25805;&#32437;&#29289;&#21697;&#26292;&#38706;&#29575;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#25932;&#23545;&#22270;&#20687;&#23384;&#22312;&#30340;&#38382;&#39064;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2312.15826</link><description>&lt;p&gt;
&#23545;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#30340;&#25932;&#23545;&#39033;&#30446;&#25512;&#24191;&#30340;&#24341;&#23548;&#25193;&#25955;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adversarial Item Promotion on Visually-Aware Recommender Systems by Guided Diffusion. (arXiv:2312.15826v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15826
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#30340;&#25932;&#23545;&#39033;&#30446;&#25512;&#24191;&#30340;&#24341;&#23548;&#25193;&#25955;&#65292;&#25581;&#31034;&#20102;&#29289;&#21697;&#20379;&#24212;&#21830;&#22914;&#20309;&#36890;&#36807;&#26500;&#24314;&#25932;&#23545;&#22270;&#20687;&#26469;&#25805;&#32437;&#29289;&#21697;&#26292;&#38706;&#29575;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#25932;&#23545;&#22270;&#20687;&#23384;&#22312;&#30340;&#38382;&#39064;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#22312;&#37027;&#20123;&#35270;&#35273;&#20803;&#32032;&#23545;&#29992;&#25143;&#28508;&#22312;&#20559;&#22909;&#30340;&#25512;&#26029;&#26377;&#26174;&#33879;&#36129;&#29486;&#30340;&#39046;&#22495;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;&#32435;&#20837;&#35270;&#35273;&#20449;&#24687;&#26377;&#26395;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#21644;&#32531;&#35299;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#20294;&#38656;&#35201;&#25351;&#20986;&#30340;&#26159;&#65292;&#21253;&#21547;&#29289;&#21697;&#22270;&#20687;&#21487;&#33021;&#20250;&#24341;&#20837;&#37325;&#22823;&#30340;&#23433;&#20840;&#25361;&#25112;&#12290;&#19968;&#20123;&#29616;&#26377;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#29289;&#21697;&#20379;&#24212;&#21830;&#21487;&#20197;&#36890;&#36807;&#26500;&#24314;&#25932;&#23545;&#22270;&#20687;&#26469;&#25805;&#32437;&#29289;&#21697;&#26292;&#38706;&#29575;&#20197;&#20854;&#21033;&#30410;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24037;&#20316;&#26080;&#27861;&#25581;&#31034;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#38754;&#23545;&#25932;&#23545;&#22270;&#20687;&#26102;&#30340;&#30495;&#23454;&#33030;&#24369;&#24615;&#65292;&#21407;&#22240;&#22914;&#19979;&#65306;&#65288;1&#65289;&#29983;&#25104;&#30340;&#25932;&#23545;&#22270;&#20687;&#26126;&#26174;&#30072;&#21464;&#65292;&#26131;&#20110;&#34987;&#20154;&#31867;&#35266;&#23519;&#32773;&#26816;&#27979;&#21040;&#65307;&#65288;2&#65289;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#19981;&#19968;&#33268;&#65292;&#29978;&#33267;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#26080;&#25928;&#12290;&#20026;&#20102;&#25581;&#31034;&#38754;&#23545;&#25932;&#23545;&#22270;&#20687;&#26102;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#30340;&#30495;&#23454;&#33030;&#24369;&#24615;
&lt;/p&gt;
&lt;p&gt;
Visually-aware recommender systems have found widespread application in domains where visual elements significantly contribute to the inference of users' potential preferences. While the incorporation of visual information holds the promise of enhancing recommendation accuracy and alleviating the cold-start problem, it is essential to point out that the inclusion of item images may introduce substantial security challenges. Some existing works have shown that the item provider can manipulate item exposure rates to its advantage by constructing adversarial images. However, these works cannot reveal the real vulnerability of visually-aware recommender systems because (1) The generated adversarial images are markedly distorted, rendering them easily detectable by human observers; (2) The effectiveness of the attacks is inconsistent and even ineffective in some scenarios. To shed light on the real vulnerabilities of visually-aware recommender systems when confronted with adversarial images
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;</title><link>http://arxiv.org/abs/2310.20091</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#23494;&#24230;&#29992;&#25143;&#34920;&#31034;&#26041;&#27861;&#29992;&#20110;&#22810;&#20852;&#36259;&#20010;&#24615;&#21270;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Density-based User Representation through Gaussian Process Regression for Multi-interest Personalized Retrieval. (arXiv:2310.20091v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35774;&#35745;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#20934;&#30830;&#24314;&#27169;&#29992;&#25143;&#30340;&#21508;&#31181;&#22810;&#26679;&#21270;&#21644;&#21160;&#24577;&#30340;&#20852;&#36259;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#29992;&#25143;&#24314;&#27169;&#26041;&#27861;&#65292;&#22914;&#21333;&#28857;&#21644;&#22810;&#28857;&#34920;&#31034;&#65292;&#23384;&#22312;&#20934;&#30830;&#24615;&#12289;&#22810;&#26679;&#24615;&#12289;&#35745;&#31639;&#25104;&#26412;&#21644;&#36866;&#24212;&#24615;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#19981;&#36275;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#8212;&#8212;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;GPR4DUR&#21033;&#29992;DURs&#26469;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#26080;&#38656;&#25163;&#21160;&#35843;&#25972;&#65292;&#21516;&#26102;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;GPR4DUR&#30340;&#36866;&#24212;&#24615;&#21644;&#25928;&#29575;&#65292;&#32780;&#20351;&#29992;&#27169;&#25311;&#29992;&#25143;&#30340;&#22312;&#32447;&#23454;&#39564;&#21017;&#35777;&#26126;&#20102;&#23427;&#36890;&#36807;&#26377;&#25928;&#21033;&#29992;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#33021;&#22815;&#35299;&#20915;&#25506;&#32034;-&#24320;&#21457;&#30340;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate modeling of the diverse and dynamic interests of users remains a significant challenge in the design of personalized recommender systems. Existing user modeling methods, like single-point and multi-point representations, have limitations w.r.t. accuracy, diversity, computational cost, and adaptability. To overcome these deficiencies, we introduce density-based user representations (DURs), a novel model that leverages Gaussian process regression for effective multi-interest recommendation and retrieval. Our approach, GPR4DUR, exploits DURs to capture user interest variability without manual tuning, incorporates uncertainty-awareness, and scales well to large numbers of users. Experiments using real-world offline datasets confirm the adaptability and efficiency of GPR4DUR, while online experiments with simulated users demonstrate its ability to address the exploration-exploitation trade-off by effectively utilizing model uncertainty.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#22823;&#35821;&#35328;&#27169;&#22411;&#21512;&#25104;&#26597;&#35810;&#30340;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23433;&#20840;&#26377;&#25928;&#22320;&#35757;&#32451;&#28145;&#24230;&#26816;&#32034;&#27169;&#22411;&#24182;&#25552;&#39640;&#26816;&#32034;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.05973</link><description>&lt;p&gt;
&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#22823;&#35821;&#35328;&#27169;&#22411;&#21512;&#25104;&#26597;&#35810;&#30340;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#31995;&#32479;.
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models. (arXiv:2305.05973v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05973
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#22823;&#35821;&#35328;&#27169;&#22411;&#21512;&#25104;&#26597;&#35810;&#30340;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23433;&#20840;&#26377;&#25928;&#22320;&#35757;&#32451;&#28145;&#24230;&#26816;&#32034;&#27169;&#22411;&#24182;&#25552;&#39640;&#26816;&#32034;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24320;&#21457;&#38544;&#31169;&#20445;&#25252;&#30340;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#65292;&#20811;&#26381;&#20102;&#22312;&#35757;&#32451;&#36825;&#20123;&#22797;&#26434;&#31995;&#32479;&#26102;&#30340;&#26576;&#20123;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#29305;&#21035;&#36866;&#29992;&#20110;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#20852;&#39046;&#22495;&#65292;&#20294;&#20063;&#21487;&#20197;&#36731;&#26494;&#22320;&#29992;&#20110;&#22788;&#29702;&#33258;&#28982;&#35821;&#35328;&#36755;&#20837;&#34920;&#31034;&#30340;&#20219;&#20309;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;DP&#35757;&#32451;&#26041;&#27861;&#65292;&#23545;&#20844;&#24320;&#39044;&#35757;&#32451;&#30340;LLM&#22312;&#26597;&#35810;&#29983;&#25104;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#12290;&#29983;&#25104;&#30340;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#31169;&#26377;&#21512;&#25104;&#26597;&#35810;&#65292;&#20195;&#34920;&#21407;&#22987;&#26597;&#35810;&#65292;&#21487;&#20197;&#22312;&#20219;&#20309;&#19979;&#28216;&#38750;&#31169;&#26377;&#25512;&#33616;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#30001;&#20849;&#20139;&#65292;&#32780;&#19981;&#20250;&#20135;&#29983;&#20219;&#20309;&#39069;&#22806;&#30340;&#38544;&#31169;&#25104;&#26412;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#23433;&#20840;&#35757;&#32451;&#26377;&#25928;&#30340;&#28145;&#24230;&#26816;&#32034;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#23427;&#20204;&#30340;&#26816;&#32034;&#36136;&#37327;&#26377;&#26174;&#30528;&#30340;&#25552;&#39640;&#65292;&#32780;&#19981;&#20250;&#25439;&#23475;&#26597;&#35810;&#32423;&#21035;&#30340;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel approach for developing privacy-preserving large-scale recommender systems using differentially private (DP) large language models (LLMs) which overcomes certain challenges and limitations in DP training these complex systems. Our method is particularly well suited for the emerging area of LLM-based recommender systems, but can be readily employed for any recommender systems that process representations of natural language inputs. Our approach involves using DP training methods to fine-tune a publicly pre-trained LLM on a query generation task. The resulting model can generate private synthetic queries representative of the original queries which can be freely shared for any downstream non-private recommendation training procedures without incurring any additional privacy cost. We evaluate our method on its ability to securely train effective deep retrieval models, and we observe significant improvements in their retrieval quality without compromising query-level pri
&lt;/p&gt;</description></item></channel></rss>