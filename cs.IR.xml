<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23433;&#20840;&#30340;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;&#65292;&#25552;&#39640;&#20302;&#28385;&#24847;&#24230;&#29992;&#25143;&#30340;&#25512;&#33616;&#36136;&#37327;&#12290;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21516;&#26102;&#20063;&#20445;&#25345;&#24635;&#20307;&#25512;&#33616;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.05292</link><description>&lt;p&gt;
&#23433;&#20840;&#30340;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
Safe Collaborative Filtering. (arXiv:2306.05292v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05292
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23433;&#20840;&#30340;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;&#65292;&#25552;&#39640;&#20302;&#28385;&#24847;&#24230;&#29992;&#25143;&#30340;&#25512;&#33616;&#36136;&#37327;&#12290;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21516;&#26102;&#20063;&#20445;&#25345;&#24635;&#20307;&#25512;&#33616;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#20363;&#22914;&#31639;&#27861;&#20844;&#24179;&#24615;&#12289;&#31867;&#21035;&#19981;&#24179;&#34913;&#21644;&#39118;&#38505;&#25935;&#24863;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#20248;&#31168;&#30340;&#23614;&#37096;&#24615;&#33021;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#30830;&#20445;&#20102;&#23545;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26679;&#26412;&#30340;&#26377;&#25928;&#22788;&#29702;&#12290;&#23614;&#37096;&#24615;&#33021;&#20063;&#26159;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#25104;&#21151;&#30340;&#37325;&#35201;&#20915;&#23450;&#22240;&#32032;&#65292;&#20197;&#20943;&#23569;&#23545;&#20302;&#28385;&#24847;&#24230;&#29992;&#25143;&#30340;&#27969;&#22833;&#39118;&#38505;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#8220;&#23433;&#20840;&#8221;&#30340;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20248;&#20808;&#32771;&#34385;&#20302;&#28385;&#24847;&#24230;&#29992;&#25143;&#30340;&#25512;&#33616;&#36136;&#37327;&#65292;&#32780;&#19981;&#26159;&#20851;&#27880;&#24179;&#22343;&#34920;&#29616;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26368;&#23567;&#21270;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;&#65288;CVaR&#65289;&#65292;&#34920;&#31034;&#29992;&#25143;&#25439;&#22833;&#23614;&#37096;&#30340;&#24179;&#22343;&#39118;&#38505;&#12290;&#20026;&#20102;&#20811;&#26381;&#32593;&#32476;&#35268;&#27169;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#35745;&#31639;&#38590;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#24378;&#22823;&#32780;&#23454;&#29992;&#30340;&#31639;&#27861;&#65292;&#25193;&#23637;&#20102;&#26368;&#21487;&#25193;&#23637;&#30340;&#26041;&#27861;&#38544;&#24335;&#20132;&#26367;&#26368;&#23567;&#20108;&#20056;&#27861;&#65288;iALS&#65289;&#12290;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#32463;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20986;&#33394;&#30340;&#23614;&#37096;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#24635;&#20307;&#25512;&#33616;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Excellent tail performance is crucial for modern machine learning tasks, such as algorithmic fairness, class imbalance, and risk-sensitive decision making, as it ensures the effective handling of challenging samples within a dataset. Tail performance is also a vital determinant of success for personalised recommender systems to reduce the risk of losing users with low satisfaction. This study introduces a "safe" collaborative filtering method that prioritises recommendation quality for less-satisfied users rather than focusing on the average performance. Our approach minimises the conditional value at risk (CVaR), which represents the average risk over the tails of users' loss. To overcome computational challenges for web-scale recommender systems, we develop a robust yet practical algorithm that extends the most scalable method, implicit alternating least squares (iALS). Empirical evaluation on real-world datasets demonstrates the excellent tail performance of our approach while maint
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;CMR&#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22810;&#30446;&#26631;&#20877;&#25490;&#24207;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#31574;&#30053;&#36229;&#32593;&#32476;&#65292;&#20351;&#24471;&#20559;&#22909;&#26435;&#37325;&#21487;&#20197;&#22312;&#32447;&#20248;&#21270;&#65292;&#32780;&#19981;&#29992;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2306.05118</link><description>&lt;p&gt;
&#29992;&#31574;&#30053;&#36229;&#32593;&#32476;&#30340;&#21487;&#25511;&#22810;&#30446;&#26631;&#20877;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Controllable Multi-Objective Re-ranking with Policy Hypernetworks. (arXiv:2306.05118v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05118
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;CMR&#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22810;&#30446;&#26631;&#20877;&#25490;&#24207;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#31574;&#30053;&#36229;&#32593;&#32476;&#65292;&#20351;&#24471;&#20559;&#22909;&#26435;&#37325;&#21487;&#20197;&#22312;&#32447;&#20248;&#21270;&#65292;&#32780;&#19981;&#29992;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#38454;&#27573;&#25490;&#21517;&#31649;&#36947;&#24050;&#25104;&#20026;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#26368;&#32456;&#38454;&#27573;&#26088;&#22312;&#36820;&#22238;&#19968;&#20010;&#25490;&#21517;&#21015;&#34920;&#65292;&#20197;&#24179;&#34913;&#29992;&#25143;&#20559;&#22909;&#12289;&#22810;&#26679;&#24615;&#12289;&#26032;&#39062;&#24615;&#31561;&#22810;&#20010;&#35201;&#27714;&#12290;&#32447;&#24615;&#26631;&#37327;&#21270;&#26159;&#23558;&#22810;&#20010;&#35201;&#27714;&#21512;&#24182;&#20026;&#19968;&#20010;&#20248;&#21270;&#30446;&#26631;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#23450;&#30340;&#20559;&#22909;&#26435;&#37325;&#26469;&#24635;&#32467;&#36825;&#20123;&#35201;&#27714;&#12290;&#29616;&#26377;&#30340;&#26368;&#32456;&#38454;&#27573;&#25490;&#21517;&#26041;&#27861;&#36890;&#24120;&#37319;&#29992;&#38745;&#24577;&#27169;&#22411;&#65292;&#20854;&#20013;&#20559;&#22909;&#26435;&#37325;&#22312;&#31163;&#32447;&#35757;&#32451;&#26399;&#38388;&#30830;&#23450;&#65292;&#24182;&#22312;&#22312;&#32447;&#26381;&#21153;&#26399;&#38388;&#20445;&#25345;&#19981;&#21464;&#12290;&#27599;&#24403;&#38656;&#35201;&#20462;&#25913;&#20559;&#22909;&#26435;&#37325;&#26102;&#65292;&#27169;&#22411;&#24517;&#39035;&#37325;&#26032;&#35757;&#32451;&#65292;&#36825;&#26159;&#26102;&#38388;&#21644;&#36164;&#28304;&#19978;&#30340;&#28010;&#36153;&#12290;&#21516;&#26102;&#65292;&#19981;&#21516;&#29992;&#25143;&#32676;&#20307;&#25110;&#19981;&#21516;&#26102;&#38388;&#27573;&#65288;&#20363;&#22914;&#65292;&#22312;&#33410;&#26085;&#20419;&#38144;&#26399;&#38388;&#65289;&#30340;&#26368;&#21512;&#36866;&#26435;&#37325;&#21487;&#33021;&#20250;&#26377;&#24456;&#22823;&#30340;&#24046;&#24322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#21487;&#25511;&#22810;&#30446;&#26631;&#20877;&#25490;&#24207;&#65288;CMR&#65289;&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#31574;&#30053;&#36229;&#32593;&#32476;&#65292;&#20197;&#20351;&#20559;&#22909;&#26435;&#37325;&#22312;&#32447;&#20248;&#21270;&#65292;&#32780;&#19981;&#24517;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#20855;&#26377;&#28789;&#27963;&#24615;&#21644;&#21487;&#25511;&#24615;&#65292;&#20026;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22810;&#30446;&#26631;&#20877;&#25490;&#24207;&#38382;&#39064;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-stage ranking pipelines have become widely used strategies in modern recommender systems, where the final stage aims to return a ranked list of items that balances a number of requirements such as user preference, diversity, novelty etc. Linear scalarization is arguably the most widely used technique to merge multiple requirements into one optimization objective, by summing up the requirements with certain preference weights. Existing final-stage ranking methods often adopt a static model where the preference weights are determined during offline training and kept unchanged during online serving. Whenever a modification of the preference weights is needed, the model has to be re-trained, which is time and resources inefficient. Meanwhile, the most appropriate weights may vary greatly for different groups of targeting users or at different time periods (e.g., during holiday promotions). In this paper, we propose a framework called controllable multi-objective re-ranking (CMR) whic
&lt;/p&gt;</description></item><item><title>&#30005;&#23376;&#21830;&#21153;&#20010;&#24615;&#21270;&#25490;&#21517;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;MoE&#26694;&#26550;&#36827;&#34892;&#29305;&#24449;&#20132;&#20114;&#24314;&#27169;&#65292;&#37319;&#29992;&#23545;&#27604;&#23398;&#20064;&#25552;&#21319;&#21382;&#21490;&#34892;&#20026;&#36739;&#23569;&#30340;&#38271;&#23614;&#29992;&#25143;&#20010;&#24615;&#21270;&#25490;&#21517;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.05011</link><description>&lt;p&gt;
&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#21152;&#26435;&#27880;&#24847;&#21147;&#30340;&#30005;&#23376;&#21830;&#21153;&#20010;&#24615;&#21270;&#25490;&#21517;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Attention Weighted Mixture of Experts with Contrastive Learning for Personalized Ranking in E-commerce. (arXiv:2306.05011v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05011
&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#21830;&#21153;&#20010;&#24615;&#21270;&#25490;&#21517;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;MoE&#26694;&#26550;&#36827;&#34892;&#29305;&#24449;&#20132;&#20114;&#24314;&#27169;&#65292;&#37319;&#29992;&#23545;&#27604;&#23398;&#20064;&#25552;&#21319;&#21382;&#21490;&#34892;&#20026;&#36739;&#23569;&#30340;&#38271;&#23614;&#29992;&#25143;&#20010;&#24615;&#21270;&#25490;&#21517;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#21517;&#27169;&#22411;&#22312;&#30005;&#23376;&#21830;&#21153;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#26377;&#25928;&#30340;&#25490;&#21517;&#27169;&#22411;&#24212;&#35813;&#26681;&#25454;&#29992;&#25143;&#21916;&#22909;&#20026;&#27599;&#20010;&#29992;&#25143;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#25490;&#21517;&#21015;&#34920;&#12290;&#29616;&#26377;&#31639;&#27861;&#36890;&#24120;&#20174;&#29992;&#25143;&#34892;&#20026;&#24207;&#21015;&#20013;&#25552;&#21462;&#29992;&#25143;&#34920;&#31034;&#21521;&#37327;&#65292;&#28982;&#21518;&#23558;&#35813;&#21521;&#37327;&#19982;&#20854;&#20182;&#29305;&#24449;&#19968;&#36215;&#39304;&#20837;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FFN&#65289;&#36827;&#34892;&#29305;&#24449;&#20132;&#20114;&#65292;&#24182;&#26368;&#32456;&#29983;&#25104;&#20010;&#24615;&#21270;&#25490;&#21517;&#24471;&#20998;&#12290;&#23613;&#31649;&#36807;&#21435;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#23637;&#65292;&#20294;&#20173;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;&#39318;&#20808;&#65292;&#19981;&#21516;&#29992;&#25143;&#30340;&#20010;&#24615;&#21270;&#29305;&#24449;&#20132;&#20114;&#27169;&#24335;&#27809;&#26377;&#26126;&#30830;&#24314;&#27169;&#12290;&#20854;&#27425;&#65292;&#30001;&#20110;&#25968;&#25454;&#31232;&#30095;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#31639;&#27861;&#22312;&#20855;&#26377;&#23569;&#37327;&#21382;&#21490;&#34892;&#20026;&#30340;&#38271;&#23614;&#29992;&#25143;&#19978;&#30340;&#20010;&#24615;&#21270;&#25490;&#21517;&#32467;&#26524;&#36739;&#24046;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20004;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#21152;&#26435;&#27880;&#24847;&#21147;&#30340;&#20010;&#24615;&#21270;&#25490;&#21517;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65288;AW-MoE&#65289;&#12290;&#39318;&#20808;&#65292;AW-MoE&#21033;&#29992;MoE&#26694;&#26550;&#25429;&#33719;&#20010;&#24615;&#21270;&#29305;&#24449;&#20132;&#20114;&#27169;&#24335;&#65292;
&lt;/p&gt;
&lt;p&gt;
Ranking model plays an essential role in e-commerce search and recommendation. An effective ranking model should give a personalized ranking list for each user according to the user preference. Existing algorithms usually extract a user representation vector from the user behavior sequence, then feed the vector into a feed-forward network (FFN) together with other features for feature interactions, and finally produce a personalized ranking score. Despite tremendous progress in the past, there is still room for improvement. Firstly, the personalized patterns of feature interactions for different users are not explicitly modeled. Secondly, most of existing algorithms have poor personalized ranking results for long-tail users with few historical behaviors due to the data sparsity. To overcome the two challenges, we propose Attention Weighted Mixture of Experts (AW-MoE) with contrastive learning for personalized ranking. Firstly, AW-MoE leverages the MoE framework to capture personalized 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22270;&#24418;&#12289;&#36716;&#25442;&#21644;&#22522;&#20110;&#26415;&#35821;&#30340;&#23884;&#20837;&#32467;&#21512;&#36215;&#26469;&#30340;&#32479;&#19968;&#23884;&#20837;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#31471;&#21040;&#31471;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#20010;&#24615;&#21270;&#26816;&#32034;&#65292;&#20197;&#35299;&#20915;Etsy&#25628;&#32034;&#20013;&#30340;&#35821;&#20041;&#24046;&#36317;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#20998;&#20139;&#20102;&#29305;&#24449;&#24037;&#31243;&#12289;&#30828;&#36127;&#37319;&#26679;&#31574;&#30053;&#21644;&#24212;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#26032;&#31574;&#30053;&#65292;&#20197;&#26500;&#24314;&#20855;&#26377;&#24037;&#19994;&#35268;&#27169;&#30340;&#27169;&#22411;&#26469;&#25913;&#21892;&#25972;&#20307;&#25628;&#32034;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2306.04833</link><description>&lt;p&gt;
Etsy&#25628;&#32034;&#20013;&#32479;&#19968;&#23884;&#20837;&#24335;&#20010;&#24615;&#21270;&#26816;&#32034;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unified Embedding Based Personalized Retrieval in Etsy Search. (arXiv:2306.04833v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22270;&#24418;&#12289;&#36716;&#25442;&#21644;&#22522;&#20110;&#26415;&#35821;&#30340;&#23884;&#20837;&#32467;&#21512;&#36215;&#26469;&#30340;&#32479;&#19968;&#23884;&#20837;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#31471;&#21040;&#31471;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#20010;&#24615;&#21270;&#26816;&#32034;&#65292;&#20197;&#35299;&#20915;Etsy&#25628;&#32034;&#20013;&#30340;&#35821;&#20041;&#24046;&#36317;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#20998;&#20139;&#20102;&#29305;&#24449;&#24037;&#31243;&#12289;&#30828;&#36127;&#37319;&#26679;&#31574;&#30053;&#21644;&#24212;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#26032;&#31574;&#30053;&#65292;&#20197;&#26500;&#24314;&#20855;&#26377;&#24037;&#19994;&#35268;&#27169;&#30340;&#27169;&#22411;&#26469;&#25913;&#21892;&#25972;&#20307;&#25628;&#32034;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#23884;&#20837;&#24335;&#31070;&#32463;&#32593;&#32476;&#30340;&#20449;&#24687;&#26816;&#32034;&#24050;&#32463;&#25104;&#20026;&#35299;&#20915;&#23614;&#26597;&#35810;&#20013;&#32463;&#24120;&#20986;&#29616;&#30340;&#35821;&#20041;&#24046;&#36317;&#38382;&#39064;&#30340;&#26222;&#36941;&#26041;&#27861;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#28909;&#38376;&#26597;&#35810;&#36890;&#24120;&#32570;&#20047;&#19978;&#19979;&#25991;&#65292;&#26377;&#24191;&#27867;&#30340;&#24847;&#22270;&#65292;&#29992;&#25143;&#21382;&#21490;&#20114;&#21160;&#30340;&#38468;&#21152;&#19978;&#19979;&#25991;&#26377;&#21161;&#20110;&#35299;&#20915;&#38382;&#39064;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#25105;&#20204;&#35299;&#20915;&#35821;&#20041;&#24046;&#36317;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#21450;&#19968;&#31181;&#29992;&#20110;&#20010;&#24615;&#21270;&#35821;&#20041;&#26816;&#32034;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#27169;&#22411;&#12290;&#25105;&#20204;&#24314;&#35758;&#23398;&#20064;&#19968;&#31181;&#32479;&#19968;&#30340;&#23884;&#20837;&#27169;&#22411;&#65292;&#21253;&#25324;&#22522;&#20110;&#22270;&#24418;&#12289;&#21464;&#21387;&#22120;&#21644;&#26415;&#35821;&#30340;&#23884;&#20837;&#65292;&#21516;&#26102;&#20998;&#20139;&#20102;&#25105;&#20204;&#30340;&#35774;&#35745;&#36873;&#25321;&#65292;&#20197;&#22312;&#24615;&#33021;&#21644;&#25928;&#29575;&#20043;&#38388;&#23454;&#29616;&#26368;&#20339;&#26435;&#34913;&#12290;&#25105;&#20204;&#20998;&#20139;&#20102;&#29305;&#24449;&#24037;&#31243;&#12289;&#30828;&#36127;&#37319;&#26679;&#31574;&#30053;&#21644;&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#24212;&#29992;&#26041;&#38754;&#30340;&#32463;&#39564;&#25945;&#35757;&#65292;&#21253;&#25324;&#29992;&#20110;&#25552;&#39640;&#25628;&#32034;&#30456;&#20851;&#24615;&#21644;&#37096;&#32626;&#27492;&#31867;&#27169;&#22411;&#30340;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#31574;&#30053;&#21644;&#20854;&#20182;&#25216;&#24039;&#12290;&#25105;&#20204;&#30340;&#20010;&#24615;&#21270;&#26816;&#32034;&#27169;&#22411;&#26174;&#30528;&#25552;&#39640;&#20102;&#25972;&#20307;&#25628;&#32034;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Embedding-based neural retrieval is a prevalent approach to address the semantic gap problem which often arises in product search on tail queries. In contrast, popular queries typically lack context and have a broad intent where additional context from users historical interaction can be helpful. In this paper, we share our novel approach to address both: the semantic gap problem followed by an end to end trained model for personalized semantic retrieval. We propose learning a unified embedding model incorporating graph, transformer and term-based embeddings end to end and share our design choices for optimal tradeoff between performance and efficiency. We share our learnings in feature engineering, hard negative sampling strategy, and application of transformer model, including a novel pre-training strategy and other tricks for improving search relevance and deploying such a model at industry scale. Our personalized retrieval model significantly improves the overall search experience,
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#35821;&#20041;&#30693;&#35782;&#22270;&#35889;&#30340;Academic Papers&#20449;&#24687;&#26816;&#32034;&#19982;&#20998;&#26512;&#26694;&#26550;(SKG)&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#25972;&#21512;&#35821;&#20041;&#27010;&#24565;&#34920;&#31034;&#35821;&#26009;&#24211;&#65292;&#25903;&#25345;&#21508;&#31181;&#23398;&#26415;&#25991;&#29486;&#30340;&#35821;&#20041;&#26597;&#35810;&#65292;&#24182;&#24320;&#21457;&#20102;&#25968;&#25454;&#27969;&#31995;&#32479;&#36827;&#34892;&#28789;&#27963;&#12289;&#20132;&#20114;&#30340;&#21508;&#31181;&#35821;&#20041;&#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2306.04758</link><description>&lt;p&gt;
SKG: &#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#22522;&#20110;&#35821;&#20041;&#30693;&#35782;&#22270;&#35889;&#30340;&#23398;&#26415;&#35770;&#25991;&#20449;&#24687;&#26816;&#32034;&#19982;&#20998;&#26512;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
SKG: A Versatile Information Retrieval and Analysis Framework for Academic Papers with Semantic Knowledge Graphs. (arXiv:2306.04758v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04758
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#35821;&#20041;&#30693;&#35782;&#22270;&#35889;&#30340;Academic Papers&#20449;&#24687;&#26816;&#32034;&#19982;&#20998;&#26512;&#26694;&#26550;(SKG)&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#25972;&#21512;&#35821;&#20041;&#27010;&#24565;&#34920;&#31034;&#35821;&#26009;&#24211;&#65292;&#25903;&#25345;&#21508;&#31181;&#23398;&#26415;&#25991;&#29486;&#30340;&#35821;&#20041;&#26597;&#35810;&#65292;&#24182;&#24320;&#21457;&#20102;&#25968;&#25454;&#27969;&#31995;&#32479;&#36827;&#34892;&#28789;&#27963;&#12289;&#20132;&#20114;&#30340;&#21508;&#31181;&#35821;&#20041;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20986;&#29256;&#30340;&#30740;&#31350;&#35770;&#25991;&#25968;&#37327;&#21576;&#25351;&#25968;&#22686;&#38271;&#65292;&#22240;&#27492;&#24320;&#21457;&#26032;&#30340;&#39640;&#25928;&#12289;&#22810;&#21151;&#33021;&#30340;&#20449;&#24687;&#25552;&#21462;&#21644;&#30693;&#35782;&#21457;&#29616;&#26041;&#27861;&#21313;&#20998;&#37325;&#35201;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#20041;&#30693;&#35782;&#22270;&#35889;&#65288;SKG&#65289;&#65292;&#35813;&#22270;&#35889;&#25972;&#21512;&#20102;&#26469;&#33258;&#25688;&#35201;&#21644;&#20854;&#20182;&#20803;&#20449;&#24687;&#30340;&#35821;&#20041;&#27010;&#24565;&#26469;&#34920;&#31034;&#35821;&#26009;&#24211;&#12290;&#30001;&#20110;SKG&#20013;&#23384;&#20648;&#20102;&#39640;&#24230;&#22810;&#26679;&#21270;&#21644;&#20016;&#23500;&#30340;&#20449;&#24687;&#20869;&#23481;&#65292;&#22240;&#27492;&#23427;&#21487;&#20197;&#25903;&#25345;&#21508;&#31181;&#23398;&#26415;&#25991;&#29486;&#30340;&#35821;&#20041;&#26597;&#35810;&#12290;&#20026;&#20102;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#25552;&#21462;&#30693;&#35782;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#30693;&#35782;&#25552;&#21462;&#27169;&#22359;&#65292;&#20854;&#20013;&#21253;&#25324;&#21322;&#30417;&#30563;&#31649;&#36947;&#29992;&#20110;&#23454;&#20307;&#25552;&#21462;&#21644;&#23454;&#20307;&#24402;&#19968;&#21270;&#12290;&#25105;&#20204;&#36824;&#21019;&#24314;&#20102;&#19968;&#20010;&#26412;&#20307;&#35770;&#20197;&#23558;&#36825;&#20123;&#27010;&#24565;&#19982;&#20854;&#20182;&#20803;&#20449;&#24687;&#25972;&#21512;&#65292;&#20174;&#32780;&#26500;&#24314;&#20102;SKG&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#25968;&#25454;&#27969;&#31995;&#32479;&#65292;&#28436;&#31034;&#22914;&#20309;&#22312;SKG&#19978;&#28789;&#27963;&#12289;&#20132;&#20114;&#22320;&#36827;&#34892;&#21508;&#31181;&#35821;&#20041;&#26597;&#35810;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#23545;&#22823;&#35268;&#27169;&#30340;&#23398;&#26415;&#20986;&#29256;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#24182;&#35828;&#26126;&#20102;SKG&#22914;&#20309;&#21327;&#21161;&#23398;&#26415;&#30740;&#31350;&#20219;&#21153;&#65292;&#21253;&#25324;&#25991;&#29486;&#32508;&#36848;&#12289;&#26597;&#35810;&#22238;&#31572;&#21644;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The number of published research papers has experienced exponential growth in recent years, which makes it crucial to develop new methods for efficient and versatile information extraction and knowledge discovery. To address this need, we propose a Semantic Knowledge Graph (SKG) that integrates semantic concepts from abstracts and other meta-information to represent the corpus. The SKG can support various semantic queries in academic literature thanks to the high diversity and rich information content stored within. To extract knowledge from unstructured text, we develop a Knowledge Extraction Module that includes a semi-supervised pipeline for entity extraction and entity normalization. We also create an ontology to integrate the concepts with other meta information, enabling us to build the SKG. Furthermore, we design and develop a dataflow system that demonstrates how to conduct various semantic queries flexibly and interactively over the SKG. To demonstrate the effectiveness of our
&lt;/p&gt;</description></item><item><title>PANE-GNN&#27169;&#22411;&#32479;&#19968;&#20102;&#29992;&#25143;&#30340;&#27491;&#21453;&#39304;&#21453;&#39304;&#20449;&#24687;&#65292;&#37319;&#29992;&#20004;&#20010;&#19981;&#21516;&#30340;&#23884;&#20837;&#34920;&#36798;&#29992;&#25143;&#21644;&#29289;&#21697;&#65292;&#33021;&#22815;&#25552;&#20379;&#26356;&#20248;&#30340;&#20010;&#24615;&#21270;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2306.04095</link><description>&lt;p&gt;
PANE-GNN&#65306;&#32479;&#19968;&#27491;&#21453;&#39304;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
PANE-GNN: Unifying Positive and Negative Edges in Graph Neural Networks for Recommendation. (arXiv:2306.04095v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04095
&lt;/p&gt;
&lt;p&gt;
PANE-GNN&#27169;&#22411;&#32479;&#19968;&#20102;&#29992;&#25143;&#30340;&#27491;&#21453;&#39304;&#21453;&#39304;&#20449;&#24687;&#65292;&#37319;&#29992;&#20004;&#20010;&#19981;&#21516;&#30340;&#23884;&#20837;&#34920;&#36798;&#29992;&#25143;&#21644;&#29289;&#21697;&#65292;&#33021;&#22815;&#25552;&#20379;&#26356;&#20248;&#30340;&#20010;&#24615;&#21270;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#36890;&#36807;&#21521;&#29992;&#25143;&#25552;&#20379;&#20010;&#24615;&#21270;&#24314;&#35758;&#26469;&#35299;&#20915;&#20449;&#24687;&#36807;&#36733;&#38382;&#39064;&#12290;&#36817;&#24180;&#26469;&#65292;&#20511;&#37492;&#22270;&#34920;&#31034;&#23398;&#20064;&#30340;&#36827;&#23637;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#24320;&#22987;&#20851;&#27880;&#37319;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#23454;&#29616;&#25512;&#33616;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22522;&#20110;GNN&#30340;&#27169;&#22411;&#20027;&#35201;&#20851;&#27880;&#29992;&#25143;&#30340;&#31215;&#26497;&#21453;&#39304;&#32780;&#24573;&#35270;&#20102;&#28040;&#26497;&#21453;&#39304;&#30340;&#26377;&#20215;&#20540;&#35265;&#35299;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#25512;&#33616;&#27169;&#22411;PANE-GNN&#65292;&#29992;&#20110;&#32479;&#19968;&#27491;&#21453;&#39304;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#12290;&#36890;&#36807;&#32467;&#21512;&#29992;&#25143;&#30340;&#20559;&#22909;&#21644;&#21453;&#24863;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22686;&#24378;&#20102;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#20010;&#24615;&#21270;&#24314;&#35758;&#30340;&#33021;&#21147;&#12290;PANE-GNN&#23558;&#21407;&#22987;&#35780;&#20998;&#22270;&#20998;&#25104;&#22522;&#20110;&#27491;&#21453;&#39304;&#30340;&#20004;&#20010;&#19981;&#21516;&#30340;&#20108;&#20998;&#22270;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#37319;&#29992;&#20004;&#20010;&#19981;&#21516;&#30340;&#23884;&#20837;&#65292;&#21363;&#20852;&#36259;&#23884;&#20837;&#21644;&#19981;&#20852;&#36259;&#23884;&#20837;&#65292;&#26469;&#34920;&#31034;&#29992;&#25143;&#21644;&#29289;&#21697;&#12290;&#26368;&#32456;&#30340;&#25512;&#33616;&#20998;&#25968;&#26159;&#22522;&#20110;&#36825;&#20004;&#20010;&#23884;&#20837;&#30340;&#32452;&#21512;&#35745;&#31639;&#24471;&#20986;&#30340;&#12290;&#22312;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;PANE-GNN&#22312;&#25512;&#33616;&#24615;&#33021;&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems play a crucial role in addressing the issue of information overload by delivering personalized recommendations to users. In recent years, there has been a growing interest in leveraging graph neural networks (GNNs) for recommender systems, capitalizing on advancements in graph representation learning. These GNN-based models primarily focus on analyzing users' positive feedback while overlooking the valuable insights provided by their negative feedback. In this paper, we propose PANE-GNN, an innovative recommendation model that unifies Positive And Negative Edges in Graph Neural Networks for recommendation. By incorporating user preferences and dispreferences, our approach enhances the capability of recommender systems to offer personalized suggestions. PANE-GNN first partitions the raw rating graph into two distinct bipartite graphs based on positive and negative feedback. Subsequently, we employ two separate embeddings, the interest embedding and the disinterest em
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#30340;&#21453;&#20107;&#23454;&#25968;&#25454;&#27169;&#25311;&#26041;&#27861;CFCRS&#65292;&#20197;&#32531;&#35299;&#30001;&#20110;&#25968;&#25454;&#19981;&#36275;&#32780;&#23548;&#33268;&#30340;&#35757;&#32451;&#19981;&#36275;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.02842</link><description>&lt;p&gt;
&#36890;&#36807;&#21453;&#20107;&#23454;&#25968;&#25454;&#27169;&#25311;&#25552;&#39640;&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Improving Conversational Recommendation Systems via Counterfactual Data Simulation. (arXiv:2306.02842v1 [cs.CL] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#30340;&#21453;&#20107;&#23454;&#25968;&#25454;&#27169;&#25311;&#26041;&#27861;CFCRS&#65292;&#20197;&#32531;&#35299;&#30001;&#20110;&#25968;&#25454;&#19981;&#36275;&#32780;&#23548;&#33268;&#30340;&#35757;&#32451;&#19981;&#36275;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#65288;CRSs&#65289;&#26088;&#22312;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23545;&#35805;&#25552;&#20379;&#25512;&#33616;&#26381;&#21153;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#22810;&#31181;&#26041;&#27861;&#29992;&#20110;&#24320;&#21457;&#26377;&#33021;&#21147;&#30340;CRSs&#65292;&#20294;&#36890;&#24120;&#38656;&#35201;&#36275;&#22815;&#30340;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#30001;&#20110;&#38590;&#20197;&#27880;&#37322;&#38754;&#21521;&#25512;&#33616;&#30340;&#23545;&#35805;&#25968;&#25454;&#38598;&#65292;&#29616;&#26377;&#30340;CRSs&#26041;&#27861;&#36890;&#24120;&#22240;&#35757;&#32451;&#25968;&#25454;&#30340;&#31232;&#32570;&#32780;&#21463;&#21040;&#19981;&#36275;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;CFCRS&#30340;CRS&#30340;&#21453;&#20107;&#23454;&#25968;&#25454;&#27169;&#25311;&#26041;&#27861;&#65292;&#20197;&#20943;&#32531;CRSs&#20013;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26694;&#26550;&#24320;&#21457;&#30340;&#65292;&#35813;&#26694;&#26550;&#36880;&#27493;&#23558;&#37325;&#20889;&#21040;&#30495;&#23454;&#23545;&#35805;&#20013;&#30340;&#29992;&#25143;&#20559;&#22909;&#20013;&#65292;&#32780;&#19981;&#24178;&#25200;&#25972;&#20010;&#23545;&#35805;&#27969;&#31243;&#12290;&#20026;&#20102;&#24320;&#21457;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#36890;&#36807;&#28041;&#21450;&#23545;&#35805;&#30340;&#23454;&#20307;&#26469;&#23545;&#29992;&#25143;&#20559;&#22909;&#36827;&#34892;&#34920;&#24449;&#24182;&#32452;&#32455;&#23545;&#35805;&#27969;&#31243;&#65292;&#24182;&#35774;&#35745;&#20102;&#22810;&#38454;&#27573;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational recommender systems (CRSs) aim to provide recommendation services via natural language conversations. Although a number of approaches have been proposed for developing capable CRSs, they typically rely on sufficient training data for training. Since it is difficult to annotate recommendation-oriented dialogue datasets, existing CRS approaches often suffer from the issue of insufficient training due to the scarcity of training data. To address this issue, in this paper, we propose a CounterFactual data simulation approach for CRS, named CFCRS, to alleviate the issue of data scarcity in CRSs. Our approach is developed based on the framework of counterfactual data augmentation, which gradually incorporates the rewriting to the user preference from a real dialogue without interfering with the entire conversation flow. To develop our approach, we characterize user preference and organize the conversation flow by the entities involved in the dialogue, and design a multi-stage 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;CTRL&#26694;&#26550;&#65292;&#23558;&#21407;&#22987;&#34920;&#26684;&#25968;&#25454;&#36716;&#25442;&#20026;&#25991;&#26412;&#25968;&#25454;&#65292;&#20351;&#29992;&#21327;&#20316;CTR&#27169;&#22411;&#20998;&#21035;&#23545;&#20004;&#31181;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#65292;&#25552;&#21462;&#20851;&#20110;CTR&#39044;&#27979;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#24182;&#22312;&#30495;&#23454;&#24037;&#19994;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#26368;&#26032;&#30340;SOTA&#24615;&#33021;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2306.02841</link><description>&lt;p&gt;
CTRL: &#36830;&#25509;&#34920;&#26684;&#21644;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;CTR&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
CTRL: Connect Tabular and Language Model for CTR Prediction. (arXiv:2306.02841v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02841
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;CTRL&#26694;&#26550;&#65292;&#23558;&#21407;&#22987;&#34920;&#26684;&#25968;&#25454;&#36716;&#25442;&#20026;&#25991;&#26412;&#25968;&#25454;&#65292;&#20351;&#29992;&#21327;&#20316;CTR&#27169;&#22411;&#20998;&#21035;&#23545;&#20004;&#31181;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#65292;&#25552;&#21462;&#20851;&#20110;CTR&#39044;&#27979;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#24182;&#22312;&#30495;&#23454;&#24037;&#19994;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#26368;&#26032;&#30340;SOTA&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;CTR&#39044;&#27979;&#27169;&#22411;&#23558;&#34920;&#26684;&#25968;&#25454;&#36716;&#25442;&#20026;one-hot&#21521;&#37327;&#65292;&#24182;&#21033;&#29992;&#29305;&#24449;&#20043;&#38388;&#30340;&#21327;&#20316;&#20851;&#31995;&#26469;&#25512;&#26029;&#29992;&#25143;&#23545;&#39033;&#30446;&#30340;&#20559;&#22909;&#12290;&#36825;&#31181;&#24314;&#27169;&#33539;&#24335;&#25243;&#24323;&#20102;&#22522;&#26412;&#30340;&#35821;&#20041;&#20449;&#24687;&#12290;&#23613;&#31649;&#19968;&#20123;&#26368;&#36817;&#30340;&#24037;&#20316;&#65288;&#22914;P5&#21644;M6-Rec&#65289;&#24050;&#32463;&#25506;&#32034;&#20102;&#20351;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#25552;&#21462;CTR&#39044;&#27979;&#30340;&#35821;&#20041;&#20449;&#21495;&#30340;&#28508;&#21147;&#65292;&#20294;&#23427;&#20204;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#25928;&#29575;&#20302;&#12290;&#27492;&#22806;&#65292;&#23578;&#26410;&#32771;&#34385;&#21040;&#26377;&#30410;&#30340;&#21327;&#20316;&#20851;&#31995;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#25512;&#33616;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;CTRL&#65292;&#23427;&#26159;&#24037;&#19994;&#21451;&#22909;&#30340;&#21644;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#65292;&#20855;&#26377;&#39640;&#35757;&#32451;&#21644;&#25512;&#29702;&#25928;&#29575;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#21407;&#22987;&#30340;&#34920;&#26684;&#25968;&#25454;&#39318;&#20808;&#34987;&#36716;&#25442;&#20026;&#25991;&#26412;&#25968;&#25454;&#12290;&#20004;&#31181;&#19981;&#21516;&#30340;&#27169;&#24577;&#34987;&#20998;&#21035;&#35270;&#20026;&#20004;&#20010;&#27169;&#24577;&#65292;&#24182;&#20998;&#21035;&#36755;&#20837;&#21327;&#20316;CTR&#27169;&#22411;&#20013;&#20197;&#24314;&#27169;&#23427;&#20204;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#20449;&#24687;&#33976;&#39311;&#26426;&#21046;&#65292;&#20174;PLMs&#20013;&#25552;&#21462;&#20851;&#20110;CTR&#39044;&#27979;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22312;&#19977;&#20010;&#30495;&#23454;&#30340;&#24037;&#19994;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#27604;&#36739;&#20854;&#20182;&#29616;&#26377;&#30340;&#27169;&#22411;&#26102;&#22343;&#36798;&#21040;&#20102;&#26368;&#26032;&#30340;SOTA&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional click-through rate (CTR) prediction models convert the tabular data into one-hot vectors and leverage the collaborative relations among features for inferring user's preference over items. This modeling paradigm discards the essential semantic information. Though some recent works like P5 and M6-Rec have explored the potential of using Pre-trained Language Models (PLMs) to extract semantic signals for CTR prediction, they are computationally expensive and suffer from low efficiency. Besides, the beneficial collaborative relations are not considered, hindering the recommendation performance. To solve these problems, in this paper, we propose a novel framework \textbf{CTRL}, which is industrial friendly and model-agnostic with high training and inference efficiency. Specifically, the original tabular data is first converted into textual data. Both tabular data and converted textual data are regarded as two different modalities and are separately fed into the collaborative CTR
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;&#29992;&#20110;&#21015;&#34920;&#21270;&#25512;&#33616;&#30340;&#35299;&#20915;&#26041;&#26696;GFN4Rec&#65292;&#36890;&#36807;&#29983;&#25104;&#27969;&#32593;&#32476;&#21644;&#21015;&#34920;&#21464;&#25442;&#22120;&#30340;&#24378;&#22823;&#24314;&#27169;&#33021;&#21147;&#65292;&#29983;&#25104;&#20855;&#26377;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#30340;&#39033;&#30446;&#21015;&#34920;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#25512;&#33616;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02239</link><description>&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#29992;&#20110;&#21015;&#34920;&#21270;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Network for Listwise Recommendation. (arXiv:2306.02239v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;&#29992;&#20110;&#21015;&#34920;&#21270;&#25512;&#33616;&#30340;&#35299;&#20915;&#26041;&#26696;GFN4Rec&#65292;&#36890;&#36807;&#29983;&#25104;&#27969;&#32593;&#32476;&#21644;&#21015;&#34920;&#21464;&#25442;&#22120;&#30340;&#24378;&#22823;&#24314;&#27169;&#33021;&#21147;&#65292;&#29983;&#25104;&#20855;&#26377;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#30340;&#39033;&#30446;&#21015;&#34920;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#25512;&#33616;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#33021;&#22815;&#28385;&#36275;&#29992;&#25143;&#30340;&#26085;&#24120;&#38656;&#27714;&#24182;&#20419;&#36827;&#22312;&#32447;&#19994;&#21153;&#30340;&#21457;&#23637;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#31181;&#31574;&#30053;&#65292;&#33021;&#22815;&#29983;&#25104;&#31526;&#21512;&#29992;&#25143;&#38656;&#27714;&#25110;&#20852;&#36259;&#30340;&#39033;&#30446;&#21015;&#34920;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#23398;&#20064;&#20102;&#19968;&#31181;&#39044;&#27979;&#27599;&#20010;&#21333;&#29420;&#39033;&#30446;&#25490;&#21517;&#24471;&#20998;&#30340;&#28857;&#31215;&#35780;&#20998;&#27169;&#22411;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21015;&#34920;&#24335;&#26041;&#27861;&#36890;&#36807;&#24314;&#27169;&#21516;&#26102;&#23637;&#31034;&#30340;&#39033;&#30446;&#30340;&#20869;&#37096;&#21015;&#34920;&#30456;&#20851;&#24615;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#25512;&#33616;&#36136;&#37327;&#12290;&#36825;&#28608;&#21457;&#20102;&#26368;&#36817;&#30340;&#21015;&#34920;&#37325;&#25490;&#21644;&#29983;&#25104;&#24335;&#25512;&#33616;&#26041;&#27861;&#65292;&#23427;&#20204;&#20248;&#21270;&#25972;&#20010;&#21015;&#34920;&#30340;&#24635;&#20307;&#25928;&#29992;&#12290;&#28982;&#32780;&#65292;&#25506;&#32034;&#21015;&#34920;&#25805;&#20316;&#30340;&#32452;&#21512;&#31354;&#38388;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#29616;&#26377;&#20351;&#29992;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#26041;&#27861;&#21487;&#33021;&#20250;&#36973;&#21463;&#20302;&#22810;&#26679;&#24615;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#23398;&#20064;&#19968;&#31181;&#31574;&#30053;&#65292;&#33021;&#22815;&#29983;&#25104;&#29992;&#25143;&#30340;&#36275;&#22815;&#22810;&#26679;&#24615;&#30340;&#39033;&#30446;&#21015;&#34920;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#25512;&#33616;&#36136;&#37327;&#12290;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;GFN4Rec&#26159;&#19968;&#20010;&#29983;&#25104;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#30001;&#29983;&#25104;&#27969;&#32593;&#32476;&#21644;&#21015;&#34920;&#21464;&#25442;&#22120;&#32452;&#25104;&#65292;&#36890;&#36807;&#21033;&#29992;&#29983;&#25104;&#27969;&#32593;&#32476;&#21644;&#22788;&#29702;&#39033;&#30446;&#30340;&#20869;&#37096;&#21015;&#34920;&#30456;&#20114;&#20851;&#32852;&#24615;&#30340;&#21015;&#34920;&#21464;&#25442;&#22120;&#30340;&#24378;&#22823;&#24314;&#27169;&#33021;&#21147;&#65292;&#29983;&#25104;&#20855;&#26377;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#30340;&#39033;&#30446;&#21015;&#34920;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#32508;&#21512;&#23454;&#39564;&#35777;&#26126;&#65292;GFN4Rec&#22312;&#25512;&#33616;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized recommender systems fulfill the daily demands of customers and boost online businesses. The goal is to learn a policy that can generate a list of items that matches the user's demand or interest. While most existing methods learn a pointwise scoring model that predicts the ranking score of each individual item, recent research shows that the listwise approach can further improve the recommendation quality by modeling the intra-list correlations of items that are exposed together. This has motivated the recent list reranking and generative recommendation approaches that optimize the overall utility of the entire list. However, it is challenging to explore the combinatorial space of list actions and existing methods that use cross-entropy loss may suffer from low diversity issues. In this work, we aim to learn a policy that can generate sufficiently diverse item lists for users while maintaining high recommendation quality. The proposed solution, GFN4Rec, is a generative met
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;HDR&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#21382;&#21490;&#20419;&#38144;&#25968;&#25454;&#65292;&#26469;&#25429;&#25417;&#20419;&#38144;&#36716;&#21270;&#27169;&#24335;&#65292;&#36798;&#21040;&#26356;&#22909;&#22320;&#36866;&#24212;&#20419;&#38144;&#27169;&#24335;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.12837</link><description>&lt;p&gt;
&#25429;&#25417;&#20419;&#38144;&#26399;&#38388;&#30340;&#36716;&#21270;&#29575;&#27874;&#21160;&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;&#21382;&#21490;&#25968;&#25454;&#20877;&#21033;&#29992;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel Historical Data Reuse Approach. (arXiv:2305.12837v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12837
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;HDR&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#21382;&#21490;&#20419;&#38144;&#25968;&#25454;&#65292;&#26469;&#25429;&#25417;&#20419;&#38144;&#36716;&#21270;&#27169;&#24335;&#65292;&#36798;&#21040;&#26356;&#22909;&#22320;&#36866;&#24212;&#20419;&#38144;&#27169;&#24335;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#21270;&#29575;&#65288;CVR&#65289;&#39044;&#27979;&#26159;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#30340;&#26680;&#24515;&#32452;&#20214;&#20043;&#19968;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#20197;&#33719;&#24471;&#20934;&#30830;&#21644;&#19968;&#33268;&#30340;CVR&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#21363;&#20351;&#35757;&#32451;&#33391;&#22909;&#30340;CVR&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;&#20419;&#38144;&#26399;&#38388;&#20063;&#32463;&#24120;&#34920;&#29616;&#20986;&#27425;&#20248;&#30340;&#24615;&#33021;&#12290;&#36825;&#20027;&#35201;&#24402;&#22240;&#20110;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#38382;&#39064;&#65292;&#20854;&#20013;&#20256;&#32479;&#26041;&#27861;&#19981;&#20877;&#36215;&#20316;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23547;&#27714;&#24320;&#21457;&#26367;&#20195;&#24314;&#27169;&#25216;&#26415;&#29992;&#20110;CVR&#39044;&#27979;&#12290;&#35266;&#23519;&#21040;&#19981;&#21516;&#20419;&#38144;&#20043;&#38388;&#23384;&#22312;&#30456;&#20284;&#30340;&#36141;&#20080;&#27169;&#24335;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#37325;&#29992;&#21382;&#21490;&#20419;&#38144;&#25968;&#25454;&#20197;&#25429;&#25417;&#20419;&#38144;&#36716;&#21270;&#27169;&#24335;&#30340;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21382;&#21490;&#25968;&#25454;&#20877;&#21033;&#29992;&#65288;HDR&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#39318;&#20808;&#26816;&#32034;&#21382;&#21490;&#19978;&#30456;&#20284;&#30340;&#20419;&#38144;&#25968;&#25454;&#65292;&#28982;&#21518;&#20351;&#29992;&#33719;&#21462;&#30340;&#25968;&#25454;&#24494;&#35843;CVR&#39044;&#27979;&#27169;&#22411;&#20197;&#26356;&#22909;&#22320;&#36866;&#24212;&#20419;&#38144;&#27169;&#24335;&#12290;HDR&#30001;&#19977;&#20010;&#32452;&#20214;&#32452;&#25104;&#65306;&#33258;&#21160;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Conversion rate (CVR) prediction is one of the core components in online recommender systems, and various approaches have been proposed to obtain accurate and well-calibrated CVR estimation. However, we observe that a well-trained CVR prediction model often performs sub-optimally during sales promotions. This can be largely ascribed to the problem of the data distribution shift, in which the conventional methods no longer work. To this end, we seek to develop alternative modeling techniques for CVR prediction. Observing similar purchase patterns across different promotions, we propose reusing the historical promotion data to capture the promotional conversion patterns. Herein, we propose a novel \textbf{H}istorical \textbf{D}ata \textbf{R}euse (\textbf{HDR}) approach that first retrieves historically similar promotion data and then fine-tunes the CVR prediction model with the acquired data for better adaptation to the promotion mode. HDR consists of three components: an automated data 
&lt;/p&gt;</description></item><item><title>CoMeta&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21327;&#20316;&#20449;&#24687;&#22686;&#24378;&#20803;&#23884;&#20837;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#22312;&#20919;&#21551;&#21160;&#38382;&#39064;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2303.07607</link><description>&lt;p&gt;
CoMeta&#65306;&#22312;&#25512;&#33616;&#31995;&#32479;&#30340;&#20919;&#21551;&#21160;&#38382;&#39064;&#20013;&#21033;&#29992;&#21327;&#20316;&#20449;&#24687;&#22686;&#24378;&#20803;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
CoMeta: Enhancing Meta Embeddings with Collaborative Information in Cold-start Problem of Recommendation. (arXiv:2303.07607v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07607
&lt;/p&gt;
&lt;p&gt;
CoMeta&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21327;&#20316;&#20449;&#24687;&#22686;&#24378;&#20803;&#23884;&#20837;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#22312;&#20919;&#21551;&#21160;&#38382;&#39064;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#29616;&#26377;&#30340;&#25512;&#33616;&#27169;&#22411;&#26469;&#35828;&#65292;&#20919;&#21551;&#21160;&#38382;&#39064;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20855;&#20307;&#22320;&#65292;&#23545;&#20110;&#20165;&#20855;&#26377;&#23569;&#25968;&#20132;&#20114;&#30340;&#26032;&#39033;&#30446;&#65292;&#20854;ID&#23884;&#20837;&#35757;&#32451;&#19981;&#20805;&#20998;&#65292;&#23548;&#33268;&#25512;&#33616;&#24615;&#33021;&#36739;&#24046;&#12290;&#19968;&#20123;&#26368;&#36817;&#30340;&#30740;&#31350;&#36890;&#36807;&#20026;&#26032;&#29289;&#21697;&#29983;&#25104;&#20803;&#23884;&#20837;&#26469;&#24341;&#20837;&#20803;&#23398;&#20064;&#26469;&#35299;&#20915;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#20123;&#26041;&#27861;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#22240;&#20026;&#23427;&#20204;&#20027;&#35201;&#21033;&#29992;&#30340;&#26159;&#29289;&#21697;&#23646;&#24615;&#29305;&#24449;&#65292;&#20165;&#21253;&#21547;&#23569;&#37327;&#20449;&#24687;&#65292;&#20294;&#24573;&#30053;&#20102;&#29992;&#25143;&#21644;&#26087;&#39033;&#30446;ID&#23884;&#20837;&#20013;&#21253;&#21547;&#30340;&#26377;&#29992;&#30340;&#21327;&#20316;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CoMeta&#26469;&#22686;&#24378;&#21327;&#20316;&#20449;&#24687;&#30340;&#20803;&#23884;&#20837;&#12290;CoMeta&#30001;&#20004;&#20010;&#23376;&#27169;&#22359;&#32452;&#25104;&#65306;B-EG&#21644;S-EG&#12290;
&lt;/p&gt;
&lt;p&gt;
The cold-start problem is quite challenging for existing recommendation models. Specifically, for the new items with only a few interactions, their ID embeddings are trained inadequately, leading to poor recommendation performance. Some recent studies introduce meta learning to solve the cold-start problem by generating meta embeddings for new items as their initial ID embeddings. However, we argue that the capability of these methods is limited, because they mainly utilize item attribute features which only contain little information, but ignore the useful collaborative information contained in the ID embeddings of users and old items. To tackle this issue, we propose CoMeta to enhance the meta embeddings with the collaborative information. CoMeta consists of two submodules: B-EG and S-EG. Specifically, for a new item: B-EG calculates the similarity-based weighted sum of the ID embeddings of old items as its base embedding; S-EG generates its shift embedding not only with its attribut
&lt;/p&gt;</description></item><item><title>UA-FedRec &#26159;&#19968;&#31181;&#38024;&#23545;&#32852;&#37030;&#23398;&#20064;&#30340;&#38750;&#23450;&#21521;&#25915;&#20987;&#65292;&#35813;&#25915;&#20987;&#36890;&#36807;&#25200;&#21160;&#26032;&#38395;&#30456;&#20284;&#24615;&#21644;&#29992;&#25143;&#27169;&#22411;&#26469;&#22312;&#19981;&#20849;&#20139;&#21407;&#22987;&#25968;&#25454;&#30340;&#32852;&#37030;&#27169;&#22411;&#23398;&#20064;&#20013;&#26377;&#25928;&#22320;&#38477;&#20302;&#27169;&#22411;&#24615;&#33021;&#12290;&#38656;&#35201;&#20851;&#27880;&#26356;&#23433;&#20840;&#30340;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#30340;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2202.06701</link><description>&lt;p&gt;
UA-FedRec: &#38754;&#21521;&#32852;&#37030;&#26032;&#38395;&#25512;&#33616;&#30340;&#38750;&#23450;&#21521;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
UA-FedRec: Untargeted Attack on Federated News Recommendation. (arXiv:2202.06701v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.06701
&lt;/p&gt;
&lt;p&gt;
UA-FedRec &#26159;&#19968;&#31181;&#38024;&#23545;&#32852;&#37030;&#23398;&#20064;&#30340;&#38750;&#23450;&#21521;&#25915;&#20987;&#65292;&#35813;&#25915;&#20987;&#36890;&#36807;&#25200;&#21160;&#26032;&#38395;&#30456;&#20284;&#24615;&#21644;&#29992;&#25143;&#27169;&#22411;&#26469;&#22312;&#19981;&#20849;&#20139;&#21407;&#22987;&#25968;&#25454;&#30340;&#32852;&#37030;&#27169;&#22411;&#23398;&#20064;&#20013;&#26377;&#25928;&#22320;&#38477;&#20302;&#27169;&#22411;&#24615;&#33021;&#12290;&#38656;&#35201;&#20851;&#27880;&#26356;&#23433;&#20840;&#30340;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#30340;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#38395;&#25512;&#33616;&#23545;&#20110;&#20010;&#24615;&#21270;&#26032;&#38395;&#20256;&#25773;&#33267;&#20851;&#37325;&#35201;&#12290;&#32852;&#37030;&#26032;&#38395;&#25512;&#33616;&#21487;&#25903;&#25345;&#19981;&#20849;&#20139;&#21407;&#22987;&#25968;&#25454;&#30340;&#35768;&#22810;&#23458;&#25143;&#31471;&#30340;&#21327;&#20316;&#27169;&#22411;&#23398;&#20064;&#65292;&#26377;&#26395;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;&#26032;&#38395;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#32852;&#37030;&#26032;&#38395;&#25512;&#33616;&#30340;&#23433;&#20840;&#24615;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#31216;&#20026; UA-FedRec &#30340;&#38750;&#23450;&#21521;&#25915;&#20987;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#12290;UA-FedRec &#21033;&#29992;&#26032;&#38395;&#25512;&#33616;&#21644;&#32852;&#37030;&#23398;&#20064;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#21487;&#20197;&#36890;&#36807;&#23569;&#37327;&#24694;&#24847;&#23458;&#25143;&#31471;&#26377;&#25928;&#38477;&#20302;&#27169;&#22411;&#24615;&#33021;&#12290;&#39318;&#20808;&#65292;&#26032;&#38395;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#39640;&#24230;&#20381;&#36182;&#20110;&#29992;&#25143;&#27169;&#22411;&#21644;&#26032;&#38395;&#27169;&#22411;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#38395;&#30456;&#20284;&#24615;&#25200;&#21160;&#26041;&#27861;&#65292;&#20351;&#31867;&#20284;&#26032;&#38395;&#30340;&#34920;&#31034;&#26356;&#36828;&#31163;&#37027;&#20123;&#19981;&#30456;&#20284;&#30340;&#26032;&#38395;&#65292;&#20197;&#25171;&#26029;&#26032;&#38395;&#24314;&#27169;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#29992;&#25143;&#27169;&#22411;&#25200;&#21160;&#26041;&#27861;&#65292;&#20351;&#24694;&#24847;&#29992;&#25143;&#26356;&#26032;&#19982;&#33391;&#24615;&#26356;&#26032;&#26041;&#21521;&#30456;&#21453;&#65292;&#20197;&#25171;&#26029;&#29992;&#25143;&#24314;&#27169;&#12290;&#20854;&#27425;&#65292;&#32852;&#37030;&#23398;&#20064;&#23481;&#26131;&#21463;&#21040;&#21508;&#31181;&#25915;&#20987;&#65292;&#30001;&#20110;&#26032;&#38395;&#25968;&#25454;&#30340;&#38544;&#31169;&#21644;&#25935;&#24863;&#24615;&#65292;&#32852;&#37030;&#26032;&#38395;&#25512;&#33616;&#30340;&#23433;&#20840;&#24615;&#23588;&#20026;&#37325;&#35201;&#12290;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#25915;&#20987;&#32773;&#22330;&#26223;&#21644;&#24230;&#37327;&#26631;&#20934;&#22312;&#19968;&#20010;&#30495;&#23454;&#30340;&#26032;&#38395;&#25512;&#33616;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272; UA-FedRec&#65292;&#24182;&#35777;&#26126;&#20165;&#23569;&#37327;&#24694;&#24847;&#23458;&#25143;&#31471;&#23601;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#27169;&#22411;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#25581;&#31034;&#20102;&#32852;&#37030;&#26032;&#38395;&#25512;&#33616;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#21628;&#21505;&#20851;&#27880;&#26356;&#23433;&#20840;&#30340;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#30340;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
News recommendation is critical for personalized news distribution. Federated news recommendation enables collaborative model learning from many clients without sharing their raw data. It is promising for privacy-preserving news recommendation. However, the security of federated news recommendation is still unclear. In this paper, we study this problem by proposing an untargeted attack called UA-FedRec. By exploiting the prior knowledge of news recommendation and federated learning, UA-FedRec can effectively degrade the model performance with a small percentage of malicious clients. First, the effectiveness of news recommendation highly depends on user modeling and news modeling. We design a news similarity perturbation method to make representations of similar news farther and those of dissimilar news closer to interrupt news modeling, and propose a user model perturbation method to make malicious user updates in opposite directions of benign updates to interrupt user modeling. Second
&lt;/p&gt;</description></item></channel></rss>