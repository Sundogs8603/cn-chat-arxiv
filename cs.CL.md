# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Satisfiability-Aided Language Models Using Declarative Prompting.](http://arxiv.org/abs/2305.09656) | 本文提出了一种利用自动定理证明器和声明性任务规范的可满足性辅助语言建模方法，可以提高大型语言模型的推理能力。 |
| [^2] | [The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation.](http://arxiv.org/abs/2305.09652) | 语音翻译(ST)是预训练语音模型进行端到端口语理解的良好手段。通过引入ST，我们的模型在单语言和跨语言场景下表现均好，具有更高的性能。 |
| [^3] | [Tailoring Instructions to Student's Learning Levels Boosts Knowledge Distillation.](http://arxiv.org/abs/2305.09651) | 本文提出了一种个性化指导的学习技术，称为LGTM，其利用蒸馏效应选择样本以增强学生的泛化能力，在GLUE基准测试的6个文本分类任务中优于10个常见的知识蒸馏基线算法。 |
| [^4] | [AI-Augmented Surveys: Leveraging Large Language Models for Opinion Prediction in Nationally Representative Surveys.](http://arxiv.org/abs/2305.09620) | 本论文研究了利用经过全国代表性调查微调的大语言模型（LLMs）来增强调查的观点预测，取得了在遗漏数据插值和回溯推理方面优秀的成果，在零次预测方面仍需进一步研究。 |
| [^5] | [Towards Expert-Level Medical Question Answering with Large Language Models.](http://arxiv.org/abs/2305.09617) | 本研究提出了Med-PaLM2，通过结合基础LLM改进、医学领域微调和提示策略，并用新颖的集成精炼方法，实现了在MedQA数据集上达到86.5%的医学问答准确率，迈向医学专家级别的问答能力。 |
| [^6] | [Large Language Models are Built-in Autoregressive Search Engines.](http://arxiv.org/abs/2305.09612) | 本篇论文指出大型语言模型可以作为内置搜索引擎，通过提供一些上下文演示直接生成Web URLs，在文档检索中表现出色。 |
| [^7] | [Boosting Event Extraction with Denoised Structure-to-Text Augmentation.](http://arxiv.org/abs/2305.09598) | 本文提出了一个去噪结构到文本增强框架（DAEE），通过基于知识的生成模型生成附加的训练数据，并通过深度强化学习代理迭代地选择有效的数据子集，以解决事件提取中标注数据不足的问题。 |
| [^8] | [UOR: Universal Backdoor Attacks on Pre-trained Language Models.](http://arxiv.org/abs/2305.09574) | 本文介绍了一种新的后门攻击方法UOR，可以自动选择触发器并学习通用输出表示，成功率高达99.3％，能够对多种预训练语言模型和下游任务实施攻击，且可突破最新的防御方法。 |
| [^9] | [Adapting Sentence Transformers for the Aviation Domain.](http://arxiv.org/abs/2305.09556) | 本研究提出了一种针对航空领域的句子变换器调整方法，在预训练阶段使用TSDAE模型进行改进，然后在少量注释的数据集上进行微调，实验结果表明在航空相关的自然语言处理任务中取得了最好的表现。 |
| [^10] | [Life of PII -- A PII Obfuscation Transformer.](http://arxiv.org/abs/2305.09550) | “Life of PII”是一种新颖的混淆变换器框架，用于将PII转化为人造PII同时尽可能地保留原始信息、意图和上下文，使我们能够有选择地混淆文档中的敏感信息，同时保留文档的统计和语义特性。 |
| [^11] | [Measuring Stereotypes using Entity-Centric Data.](http://arxiv.org/abs/2305.09548) | 本文提出并评估了三种新的以实体为中心的方法，展示了这些模型在预测人们如何将身份标签应用于自己和他人以及量化突出的社会维度（如性别）的刻板印象方面优于现有方法。 |
| [^12] | [MetaSRL++: A Uniform Scheme for Modelling Deeper Semantics.](http://arxiv.org/abs/2305.09534) | 本文介绍了MetaSRL ++，它是一种统一、语言和形式无关的建模方案，基于语义图，用于建模更深层的语义。 |
| [^13] | [AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation.](http://arxiv.org/abs/2305.09515) | 本文提出了一种自回归扩散模型（AR-Diffusion）用于文本生成，通过动态数量的降噪步骤，确保左侧标记的生成影响右侧标记的生成。 |
| [^14] | [Fuzzy Temporal Protoforms for the Quantitative Description of Processes in Natural Language.](http://arxiv.org/abs/2305.09506) | 本文提出了一种自然语言进程描述方法，使用模糊时间原型体实现定量描述。模型能提取过程的相关信息，并用自然语言描述，可应用于心脏病领域等其他复杂领域。 |
| [^15] | [MPI-rical: Data-Driven MPI Distributed Parallelism Assistance with Transformers.](http://arxiv.org/abs/2305.09438) | 本文提出了一种基于Transformer模型的新方法MPI-rical，通过对大量代码片段进行训练实现自动化MPI代码生成，使并行化成为可能。 |
| [^16] | [About Evaluation of F1 Score for RECENT Relation Extraction System.](http://arxiv.org/abs/2305.09410) | 本文讨论了一个名为RECENT的关系抽取系统，作者在TACRED数据集上取得了之前的最新成果74.8的F1分数，但在更正错误和重新评估后其F1分数为65.16。 |
| [^17] | [A Preliminary Analysis on the Code Generation Capabilities of GPT-3.5 and Bard AI Models for Java Functions.](http://arxiv.org/abs/2305.09402) | 本文评估了GPT-3.5和Bard AI模型在生成Java代码方面的能力，结果表明GPT-3.5表现更好，为AI辅助代码生成工具的开发提供了潜在途径。 |
| [^18] | [GIFT: Graph-Induced Fine-Tuning for Multi-Party Conversation Understanding.](http://arxiv.org/abs/2305.09360) | GIFT是一个适用于多方对话理解的方法，通过设计四种类型的边缘将图感知信息集成到注意力机制中，改进了原始的顺序文本处理的PLM。 |
| [^19] | [MsPrompt: Multi-step Prompt Learning for Debiasing Few-shot Event Detection.](http://arxiv.org/abs/2305.09335) | 本研究提出了一个多步骤提示学习模型（MsPrompt），用于解决少样本场景下的事件检测问题，并通过欠采样、多级提示以及原型模块来解决上下文绕过和增强事件语义和潜在先验知识。 |
| [^20] | [Multi-modal Visual Understanding with Prompts for Semantic Information Disentanglement of Image.](http://arxiv.org/abs/2305.09333) | 本论文研究了基于提示的多模态视觉理解技术，通过分离语义信息提高对图像的理解，旨在推进图像识别和理解领域的研究。 |
| [^21] | [BERTTM: Leveraging Contextualized Word Embeddings from Pre-trained Language Models for Neural Topic Modeling.](http://arxiv.org/abs/2305.09329) | 本文提出了一种新颖的神经主题模型，利用来自预训练语言模型BERT的上下文化词嵌入，可以在不使用任何BoW信息的情况下推断出文档的主题分布，并直接从上下文化词嵌入中推断出文档中每个单词的主题分布。实验结果表明，该模型优于仅依赖BoW表示和其他神经主题模型的现有最先进方法。 |
| [^22] | [Enhancing Keyphrase Extraction from Long Scientific Documents using Graph Embeddings.](http://arxiv.org/abs/2305.09316) | 本文研究了使用图神经网络表示加强预训练语言模型对长篇科技论文的关键词提取。通过构建文本共现图并结合图表示和上下文化的PLM嵌入，我们展示了对于长篇文档，增强PLMs性能比现有技术的模型表现更加出色。 |
| [^23] | [Hybrid and Collaborative Passage Reranking.](http://arxiv.org/abs/2305.09313) | 该论文提出了一种名为HybRank的混合与协作的段落再排序方法，通过利用上游检索器的相似性度量实现段落协作，再利用稀疏和密集检索器的词汇和语义属性进行重新排序，该方法可以增强包括先前被重新排序的段落列表在内的任意段落列表，并在实验证明了性能稳定的提升。 |
| [^24] | [Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation.](http://arxiv.org/abs/2305.09312) | 研究发现，在零样本翻译中，使用残差连接后的Transformer设置的层归一化（PostNorm）始终优于带有层归一化的PreNorm，最高可提高12.3 BLEU分。 |
| [^25] | [On the Origins of Bias in NLP through the Lens of the Jim Code.](http://arxiv.org/abs/2305.09281) | 本文追溯了过去500年种族主义、性别歧视和同性恋恐惧症，认为NLP模型中的偏见源自社会问题，并提出了解决方法与建议。 |
| [^26] | [ContrastNet: A Contrastive Learning Framework for Few-Shot Text Classification.](http://arxiv.org/abs/2305.09269) | ContrastNet是一种对比学习框架，旨在解决少样本文本分类中的区分性表示和过拟合问题，通过拉近相同类别的文本表示，并推远不同类别的文本表示来学习区分特征。 |
| [^27] | [HyHTM: Hyperbolic Geometry based Hierarchical Topic Models.](http://arxiv.org/abs/2305.09258) | HyHTM是一种基于双曲几何的层次主题模型，通过将双曲几何中的层次信息纳入主题模型中，显式地建模主题层次结构。相较于传统方法，HyHTM更好地关注主题之间的父子关系，并产生了连贯的主题层次结构。同时，HyHTM的计算速度更快，内存占用更小。 |
| [^28] | [xPQA: Cross-Lingual Product Question Answering across 12 Languages.](http://arxiv.org/abs/2305.09249) | xPQA是一个支持12种语言的跨语言产品问答系统，通过选择最佳英文候选人并生成自然的其他语言答案，实现了多语言顾客支持。在实验中，研究者发现域内数据是不可或缺的，并且虽然多语言预训练语言模型很有希望，但运行时翻译仍然必要。 |
| [^29] | [Maybe Only 0.5% Data is Needed: A Preliminary Exploration of Low Training Data Instruction Tuning.](http://arxiv.org/abs/2305.09246) | 本研究发现只需使用0.5%数据便可以进行训练大型语言模型（LLMs）指令调整，并且不影响性能表现。这种方法可以提高数据效率和节约培训成本。 |
| [^30] | [Towards Unifying Multi-Lingual and Cross-Lingual Summarization.](http://arxiv.org/abs/2305.09220) | 本文旨在将多语言摘要和跨语言摘要统一到更通用的多对多摘要中。我们提出了预先训练的M2MS模型“Pisces”，该模型可以处理任何语言的文档并生成摘要。实验结果表明，Pisces在零-shot方向上表现显着优于现有的基线模型。 |
| [^31] | [Towards Speech Dialogue Translation Mediating Speakers of Different Languages.](http://arxiv.org/abs/2305.09210) | 本文提出了一项新任务，即为不同语言的发言人构建语音对话翻译。作者构建了SpeechBSD数据集并进行了基准实验。作者指出上下文是该任务中需要考虑的一个重要方面，并提出了两种利用上下文的方法。最终结果表明，在该任务中双语上下文比单语上下文表现更好。 |
| [^32] | [The Weighted M\"obius Score: A Unified Framework for Feature Attribution.](http://arxiv.org/abs/2305.09204) | 本文提出了权重莫比乌斯分数作为一个参数化的归因框架，可以涵盖很多不同的特征归因方法，包括特征交互，解决了方法繁衍和不可比的问题。通过研究方法的向量空间，提供了一些新方法和解释，实证结果表明其多功能性和有效性。 |
| [^33] | [Easy-to-Hard Learning for Information Extraction.](http://arxiv.org/abs/2305.09193) | 本文提出了一种易学难学的信息抽取学习框架，分为入门、困难和主阶段，模仿人类学习过程，通过分阶段学习提高模型泛化能力。 |
| [^34] | [Progressive Translation: Improving Domain Robustness of Neural Machine Translation with Intermediate Sequences.](http://arxiv.org/abs/2305.09154) | 该论文提出了使用中间序列来提高神经机器翻译的领域鲁棒性的方法，并通过全排列多任务学习和最小贝叶斯风险译码算法进一步提高了模型性能。 |
| [^35] | [Dual-Alignment Pre-training for Cross-lingual Sentence Embedding.](http://arxiv.org/abs/2305.09148) | 该论文提出了一个双重对齐预训练框架，用于跨语言句子嵌入，它结合了句子级别和标记级别的对齐。引入了一种表示翻译学习任务，从而将翻译信息嵌入标记表示中。 |
| [^36] | [Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism of Language Models.](http://arxiv.org/abs/2305.09144) | 本论文研究了语言模型的记忆机制，发现预训练可以有效提高模型的记忆能力，而知识相关性和多样性对于记忆形成也有显著影响。 |
| [^37] | [Is a Video worth $n\times n$ Images? A Highly Efficient Approach to Transformer-based Video Question Answering.](http://arxiv.org/abs/2305.09107) | 本文提出了一种高效的Transformer-based Video Question Answering方法，即将视频帧连接成 $n\times n$ 的矩阵，从而将图像编码器的使用量从 $n^{2}$ 减少到1，从而显著提高了训练和推理速度和节省了存储空间，而仍然保持了原始视频的时间结构，并在实验中取得了较好结果。 |
| [^38] | [Weight-Inherited Distillation for Task-Agnostic BERT Compression.](http://arxiv.org/abs/2305.09098) | 本文提出了一种直接从教师模型传递知识的权重继承蒸馏方法，不需要额外的对齐损失就可以训练出一个紧凑的学生模型，并且在GLUE和SQuAD基准测试上优于之前最先进的基于KD的基线。 |
| [^39] | [SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting.](http://arxiv.org/abs/2305.09067) | 本文提出了一种基于模式引导的LLM提示SGP-TOD，用于轻松构建任务型对话系统，避免了训练数据的需求。实验证明，该方法在多个数据集上显著优于先进的基线方法。 |
| [^40] | [It Takes Two to Tango: Navigating Conceptualizations of NLP Tasks and Measurements of Performance.](http://arxiv.org/abs/2305.09022) | 本文针对NLP的任务和性能测量提出了一种分歧分类方法，经过相关研究和调查，发现现有任务没有明确和一致的概念，基准存在操作化分歧，提出了解决基准争议的建议。 |
| [^41] | [Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback.](http://arxiv.org/abs/2305.08982) | 本论文介绍了一个基于AI的交互式工具CARE，用于支持同侪辅导员通过自动建议生成来提高他们的能力。利用 Motivational Interviewing 框架，CARE 在实际培训阶段帮助辅导员诊断哪种具体的辅导策略最合适，并提供个性化的响应示例作为建议。 |
| [^42] | [Watermarking Text Generated by Black-Box Language Models.](http://arxiv.org/abs/2305.08883) | 本研究提出了一种利用Transformer注意力图来获得词级反馈的新型黑盒LLM水印算法，实现对由黑盒语言模型生成的文本的水印保护。 |
| [^43] | [A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document Summarization.](http://arxiv.org/abs/2305.08503) | 本研究提出了一种用于抽象多文档摘要的层次编码-解码方案，在多领域的10个MDS数据集上测试表现最佳。 |
| [^44] | [Text2Cohort: Democratizing the NCI Imaging Data Commons with Natural Language Cohort Discovery.](http://arxiv.org/abs/2305.07637) | Text2Cohort是一个基于大语言模型的工具箱，可以将用户输入转化为IDC数据库查询，促进自然语言队列发现，减少研究人员查询IDC数据库的学习曲线，实现了癌症成像数据的民主化。 |
| [^45] | [QURG: Question Rewriting Guided Context-Dependent Text-to-SQL Semantic Parsing.](http://arxiv.org/abs/2305.06655) | QURG是一种帮助文本到SQL语义解析模型实现上下文理解的新颖方法，能在SParC和CoSQL等上下文依赖性数据集上提高模型性能，特别是对于难以处理和长轮次的问题。 |
| [^46] | [Bot or Human? Detecting ChatGPT Imposters with A Single Question.](http://arxiv.org/abs/2305.06424) | 本文提出了一个名为FLAIR的框架，通过一个问题和回答来检测ChatGPT中的聊天机器人真实性，可以分类人和机器人。单问题分为对于人类而言容易但对于机器人很难和对于机器人而言容易但对于人类很难两个类别，分别进行检测。 在多个数据集上实现了最先进的性能。 |
| [^47] | [K-UniMorph: Korean Universal Morphology and its Feature Schema.](http://arxiv.org/abs/2305.06335) | 本文介绍了一种韩语通用词形学数据集，保留韩语特色并采用Sylak-Glassman等人的词形特征模式，为韩语形态学范式领域做出了贡献。 |
| [^48] | [Unified Demonstration Retriever for In-Context Learning.](http://arxiv.org/abs/2305.04320) | 本文提出了一种统一的演示检索器UDR，可用于广泛的任务检索演示，在训练时使用语言模型的反馈来将各种任务的训练信号转换为统一的列表排序公式。 |
| [^49] | [Adaptive loose optimization for robust question answering.](http://arxiv.org/abs/2305.03971) | 本论文提出了一种简单而有效的自适应宽松优化损失函数，用于为问答系统综合内外分布的最佳表现，并显示了对对抗攻击的强韧性。 |
| [^50] | [LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models.](http://arxiv.org/abs/2305.03445) | 本文研究调查了具身化策略对语言模型解释比喻性语言的影响。结果表明，更大的模型在处理行为更具体化的隐喻性句子时表现更佳。 |
| [^51] | [Automated Code generation for Information Technology Tasks in YAML through Large Language Models.](http://arxiv.org/abs/2305.02783) | 这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。 |
| [^52] | [How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model.](http://arxiv.org/abs/2305.00586) | 本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。 |
| [^53] | [GeneGPT: Teaching Large Language Models to Use NCBI Web APIs.](http://arxiv.org/abs/2304.09667) | GeneGPT通过少量NCBI API调用URL请求作为演示，教授大型语言模型使用NCBI Web API回答基因组问题，并在GeneTuring测试中达到了优异的结果。 |
| [^54] | [On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis.](http://arxiv.org/abs/2304.03347) | 本文全面评估了ChatGPT在心理健康分析和情感推理方面的表现，以及不同提示策略和情感信息对其性能的影响。结果显示，ChatGPT在心理健康分析方面表现良好，加入情感增强提示对某些任务效果显著。 |
| [^55] | [Rediscovering Hashed Random Projections for Efficient Quantization of Contextualized Sentence Embeddings.](http://arxiv.org/abs/2304.02481) | 本文提出了一种有效的方法，使用哈希随机投影和量化技术有效量化上下文化句子嵌入，以降低存储空间的开销，并可以用于在多种英语和德语句子分类任务上训练模型。 |
| [^56] | [SemiMemes: A Semi-supervised Learning Approach for Multimodal Memes Analysis.](http://arxiv.org/abs/2304.00020) | 研究提出了一种利用多模态数据的半监督学习方法，命名为SemiMemes，主要应用于Memes的分析和注释过程。该方法在多个数据集中表现优异，并优于其他最新的多模态半监督学习和监督学习模型。 |
| [^57] | [Zero-shot Clinical Entity Recognition using ChatGPT.](http://arxiv.org/abs/2303.16416) | 本研究探讨了使用 ChatGPT 进行零样本临床实体识别任务，并发现 ChatGPT 在松弛匹配 F1 分数方面显著优于 GPT-3。虽然其性能仍低于 BioClinicalBERT 模型，但我们的研究表明了 ChatGPT 在零样本设置下有很大的临床 NER 任务潜力。 |
| [^58] | [Partial Mobilization: Tracking Multilingual Information Flows Amongst Russian Media Outlets and Telegram.](http://arxiv.org/abs/2301.10856) | 本文研究了16个俄罗斯媒体机构和732个电报频道之间的互动，发现新闻媒体不仅通过电报传播现有的叙事，而且会从电报平台源材料，研究结果表明2.3％至26.7％的文章将主题归因于电报活动。 |
| [^59] | [tasksource: A Dataset Harmonization Framework for Streamlined NLP Multi-Task Learning and Evaluation.](http://arxiv.org/abs/2301.05948) | tasksource是一个数据集协调框架，为多任务学习和评估提供流畅的体验。该框架提供了结构化注释，使得数据处理更加便捷。 |
| [^60] | [Contrastive Language-Vision AI Models Pretrained on Web-Scraped Multimodal Data Exhibit Sexual Objectification Bias.](http://arxiv.org/abs/2212.11261) | 本文使用对比语言图像预训练的多模态AI模型，使用网页抓取的数据训练，发现这些模型存在性物化偏见，即人的情感状态与身体的呈现相关，表现出对女性的性别偏见。 |
| [^61] | [DimonGen: Diversified Generative Commonsense Reasoning for Explaining Concept Relationships.](http://arxiv.org/abs/2212.10545) | 本文提出了DimonGen模型，通过生成各种日常场景的概念关系描述来实现多元化通识推理。实验结果表明，MoREE模型在生成质量和多样性方面均优于基线模型。 |
| [^62] | [CiteBench: A benchmark for Scientific Citation Text Generation.](http://arxiv.org/abs/2212.09577) | CiteBench是一个科学引文文本生成基准测试，旨在解决研究加速导致的解读和总结先前工作的困难。该基准测试可以进行标准化评估，研究不同任务设计和领域的引文文本生成模型。对多个基线模型的大量测试发现了新的见解。 |
| [^63] | [PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism.](http://arxiv.org/abs/2212.09086) | 该论文提出了一个名为PVGRU的组件，可以通过引入汇总变量来聚合子序列的累积分布变化，从而优化基于生成的聊天机器人的多轮对话回复，提高对话模型的多样性和相关性。 |
| [^64] | [Self-Prompting Large Language Models for Zero-Shot Open-Domain QA.](http://arxiv.org/abs/2212.08635) | 本论文提出了一种自我提示框架，可以有效利用大型语言模型的参数中存储的知识和指令理解能力，以实现零样本开放域问答，并且实验证明该方法在三个广泛使用的ODQA数据集中显著优于现有的最先进方法。 |
| [^65] | [CREPE: Can Vision-Language Foundation Models Reason Compositionally?.](http://arxiv.org/abs/2212.07796) | CREPE提出了一个新的组合性评估基准，衡量了模型的系统性和产出性能，发现大型预训练的视觉-语言基础模型在组合性上仍存在问题。 |
| [^66] | [AIONER: All-in-one scheme-based biomedical named entity recognition using deep learning.](http://arxiv.org/abs/2211.16944) | AIONER是一种新颖的基于深度学习的全套方案生物医学命名实体识别工具，利用外部数据提高BioNER模型准确性和稳定性，具有良好的性能和泛化能力。 |
| [^67] | [Frustratingly Easy Label Projection for Cross-lingual Transfer.](http://arxiv.org/abs/2211.15613) | 本文通过一项广泛的实证研究，对57种语言和三个任务下的跨语言转移进行了研究，并发现优化后的标记-翻译法比传统注释投影方法更有效。 |
| [^68] | [Large Pre-Trained Models with Extra-Large Vocabularies: A Contrastive Analysis of Hebrew BERT Models and a New One to Outperform Them All.](http://arxiv.org/abs/2211.15199) | 阐述了新的预训练语言模型AlephBERTGimmel在希伯来语基准测试上的表现，其使用更高的词汇量，达到了新的最新最好的性能。 |
| [^69] | [Pruning Pre-trained Language Models Without Fine-Tuning.](http://arxiv.org/abs/2210.06210) | 本文提出了静态模型剪枝（SMP），它只使用一阶剪枝来适应下游任务，同时实现目标稀疏度水平，在大量实验证明SMP具有显著的改进。 |
| [^70] | [What Makes Pre-trained Language Models Better Zero-shot Learners?.](http://arxiv.org/abs/2209.15206) | 本文提出一个理论框架来解释prompt learning在零样本/少样本场景下的有效性，并基于此提出了一个注释无关的模板选择方法。 |
| [^71] | [Fast-FNet: Accelerating Transformer Encoder Models via Efficient Fourier Layers.](http://arxiv.org/abs/2209.12816) | FNet模型通过替换注意力层为傅里叶变换，加速了Transformer编码器模型的训练过程并保持相同的性能水平。 |
| [^72] | [WeLM: A Well-Read Pre-trained Language Model for Chinese.](http://arxiv.org/abs/2209.10372) | WeLM 是一种面向中文的读过书的预训练语言模型，它通过读取高质量的语料库训练了100亿个参数，并可以在18个中文任务中显著优于现有同规模预训练模型，同时表现出强大的多语言和代码转换理解能力。 |
| [^73] | [Non-Parametric Temporal Adaptation for Social Media Topic Classification.](http://arxiv.org/abs/2209.05706) | 本文提出了一种非参数化的密集检索技术，可以解决当前自然语言处理模型无法适应时间变化，无法应对测试数据分布变化和已删除的训练数据的问题，并在Twitter数据集上取得了显著的实验结果。 |
| [^74] | [A New Aligned Simple German Corpus.](http://arxiv.org/abs/2209.01106) | 本文介绍了一个新的对齐的简易德语语料库，用于辅助不同人群理解复杂的德语书面语言；该语料库通过自动句子对齐方法使多个文档对齐，且质量优于之前的工作。 |
| [^75] | [Faking Fake News for Real Fake News Detection: Propaganda-loaded Training Data Generation.](http://arxiv.org/abs/2203.05386) | 该论文提出了一个生成具有宣传性的训练数据的框架，以帮助检测人工撰写的虚假信息。所生成的的训练数据集PropaNews在假新闻检测方面表现更好。 |
| [^76] | [Improving Implicit Sentiment Learning via Local Sentiment Aggregation.](http://arxiv.org/abs/2110.08604) | 本文提出了一种本地情感聚合范式，可以提高情感学习的能力，该方法可以有效地建模方面情感相干性，并在三个公共数据集上实现了最先进的性能。 |
| [^77] | [UNIQORN: Unified Question Answering over RDF Knowledge Graphs and Natural Language Text.](http://arxiv.org/abs/2108.08614) | 本文提出了一个名为UNIQORN的问答系统，它能够无缝地处理RDF数据和文本，使用fine-tuned BERT模型为问题构建上下文图，并使用图算法确定与问题相关的子图来回答问题。 |
| [^78] | [Open Korean Corpora: A Practical Report.](http://arxiv.org/abs/2012.15621) | 本文回顾了韩语语料库，提出了针对资源较少的语言进行开源数据集构建和发布以促进研究的方向。 |

# 详细

[^1]: 声明提示下的可满足性辅助语言模型

    Satisfiability-Aided Language Models Using Declarative Prompting. (arXiv:2305.09656v1 [cs.CL])

    [http://arxiv.org/abs/2305.09656](http://arxiv.org/abs/2305.09656)

    本文提出了一种利用自动定理证明器和声明性任务规范的可满足性辅助语言建模方法，可以提高大型语言模型的推理能力。

    

    本文提出了一种新的可满足性辅助语言建模方法，用于提高大型语言模型的推理能力。我们使用一个大型语言模型生成一个声明性任务规范，并利用一个现成的自动定理证明器得出最终答案。该方法具有两个关键优点：第一，声明性规范比推理步骤更接近问题描述，因此大型语言模型可以更准确地解析它；第二，通过将实际推理任务委托给自动定理证明器，我们的方法可以保证正确性。

    Prior work has combined chain-of-thought prompting in large language models (LLMs) with programmatic representations to perform effective and transparent reasoning. While such an approach works very well for tasks that only require forward reasoning (e.g., straightforward arithmetic), it is less effective for constraint solving tasks that require more sophisticated planning and search. In this paper, we propose a new satisfiability-aided language modeling approach for improving the reasoning capabilities of LLMs. We use an LLM to generate a declarative task specification rather than an imperative program and leverage an off-the-shelf automated theorem prover to derive the final answer. This approach has two key advantages. The declarative specification is closer to the problem description than the reasoning steps are, so the LLM can parse it more accurately. Furthermore, by offloading the actual reasoning task to an automated theorem prover, our approach can guarantee the correctness o
    
[^2]: 解释器理解您的意思: 由语音翻译协助的端到端口语理解

    The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation. (arXiv:2305.09652v1 [cs.CL])

    [http://arxiv.org/abs/2305.09652](http://arxiv.org/abs/2305.09652)

    语音翻译(ST)是预训练语音模型进行端到端口语理解的良好手段。通过引入ST，我们的模型在单语言和跨语言场景下表现均好，具有更高的性能。

    

    尽管当前在文本和语音上有大规模预训练的语言模型，但端到端口语理解仍然难以实现，特别是在多语言情况下。机器翻译已被确定为强大的文本预训练目标，因为它使模型能够捕捉输入语句的高级语义和不同语言之间的关联，这对于处理更低级别的声学帧的语音模型非常有用。本文特别针对跨语言口语理解任务，证明了语音翻译(ST)是预训练语音模型进行端到端口语理解的良好手段，无论是在单语言场景还是跨语言场景下。通过引入ST，我们的模型在使用SLURP、MINDS-14和NMSQA基准测试进行单语言和多语言意图分类以及口语问答时，相比当前基准测试方法均具有更高性能。为验证我们方法的有效性，我们还发布了两个新的基准数据集，分别来自合成和真实数据。

    End-to-end spoken language understanding (SLU) remains elusive even with current large pretrained language models on text and speech, especially in multilingual cases. Machine translation has been established as a powerful pretraining objective on text as it enables the model to capture high-level semantics of the input utterance and associations between different languages, which is desired for speech models that work on lower-level acoustic frames. Motivated particularly by the task of cross-lingual SLU, we demonstrate that the task of speech translation (ST) is a good means of pretraining speech models for end-to-end SLU on both monolingual and cross-lingual scenarios.  By introducing ST, our models give higher performance over current baselines on monolingual and multilingual intent classification as well as spoken question answering using SLURP, MINDS-14, and NMSQA benchmarks. To verify the effectiveness of our methods, we also release two new benchmark datasets from both syntheti
    
[^3]: 个性化指导有助于知识蒸馏

    Tailoring Instructions to Student's Learning Levels Boosts Knowledge Distillation. (arXiv:2305.09651v1 [cs.CL])

    [http://arxiv.org/abs/2305.09651](http://arxiv.org/abs/2305.09651)

    本文提出了一种个性化指导的学习技术，称为LGTM，其利用蒸馏效应选择样本以增强学生的泛化能力，在GLUE基准测试的6个文本分类任务中优于10个常见的知识蒸馏基线算法。

    

    先前研究表明，能力超群的教师模型并不一定能够让学生水平得到提升，这凸显了当前教师培训实践和有效知识传授之间的不一致性。为了提高教师培训过程的指导效果，本文引入了蒸馏效应的概念，以确定每个训练样本对学生泛化能力的影响。我们提出了一种名为学好教师很重要（LGTM）的有效训练技术，以将蒸馏效应纳入教师的学习过程中。通过优先选择可能提升学生泛化能力的样本，我们的LGTM在GLUE基准测试的6个文本分类任务中优于10个常见的知识蒸馏基线算法。

    It has been commonly observed that a teacher model with superior performance does not necessarily result in a stronger student, highlighting a discrepancy between current teacher training practices and effective knowledge transfer. In order to enhance the guidance of the teacher training process, we introduce the concept of distillation influence to determine the impact of distillation from each training sample on the student's generalization ability. In this paper, we propose Learning Good Teacher Matters (LGTM), an efficient training technique for incorporating distillation influence into the teacher's learning process. By prioritizing samples that are likely to enhance the student's generalization ability, our LGTM outperforms 10 common knowledge distillation baselines on 6 text classification tasks in the GLUE benchmark.
    
[^4]: AI增强的调查：利用大语言模型进行全国代表性调查的观点预测

    AI-Augmented Surveys: Leveraging Large Language Models for Opinion Prediction in Nationally Representative Surveys. (arXiv:2305.09620v1 [cs.CL])

    [http://arxiv.org/abs/2305.09620](http://arxiv.org/abs/2305.09620)

    本论文研究了利用经过全国代表性调查微调的大语言模型（LLMs）来增强调查的观点预测，取得了在遗漏数据插值和回溯推理方面优秀的成果，在零次预测方面仍需进一步研究。

    

    本论文研究了如何使用经过全国代表性调查微调的大语言模型（LLMs）来增强调查。本文探讨了LLMs在观点预测中，遗漏数据插值，回溯推理和零次预测三个不同应用。我们提出了一种新的方法论框架，将调查问题、个人信念和时间背景的神经嵌入引入到观点预测的个性化LLMs中。在1972年到2021年的“常规社会调查”中，我们从68,846名美国人中获得了3,110个二进制观点，在Alpaca-7b模型的基础上取得了最好的成果，在缺失数据插值（AUC=0.87，公开观点预测为$\rho$=0.99）和回溯推理（AUC=0.86，$\rho$=0.98）方面表现出色。这些显著的预测能力能够以高置信度填补缺失的趋势，并标明公众态度何时发生变化，如同性婚姻的获取支持。然而，在零次预测的情况下，模型的表现受到限制，需要进一步研究。

    How can we use large language models (LLMs) to augment surveys? This paper investigates three distinct applications of LLMs fine-tuned by nationally representative surveys for opinion prediction -- missing data imputation, retrodiction, and zero-shot prediction. We present a new methodological framework that incorporates neural embeddings of survey questions, individual beliefs, and temporal contexts to personalize LLMs in opinion prediction. Among 3,110 binarized opinions from 68,846 Americans in the General Social Survey from 1972 to 2021, our best models based on Alpaca-7b excels in missing data imputation (AUC = 0.87 for personal opinion prediction and $\rho$ = 0.99 for public opinion prediction) and retrodiction (AUC = 0.86, $\rho$ = 0.98). These remarkable prediction capabilities allow us to fill in missing trends with high confidence and pinpoint when public attitudes changed, such as the rising support for same-sex marriage. However, the models show limited performance in a zer
    
[^5]: 大型语言模型在医学问答中的应用：迈向医学专家级别的问答能力

    Towards Expert-Level Medical Question Answering with Large Language Models. (arXiv:2305.09617v1 [cs.CL])

    [http://arxiv.org/abs/2305.09617](http://arxiv.org/abs/2305.09617)

    本研究提出了Med-PaLM2，通过结合基础LLM改进、医学领域微调和提示策略，并用新颖的集成精炼方法，实现了在MedQA数据集上达到86.5%的医学问答准确率，迈向医学专家级别的问答能力。

    

    近年来，人工智能系统在诸如围棋和蛋白质折叠等“宏伟挑战”方面取得了里程碑式的进展。但回答医学问题并像医生一样进行推理被认为也是一种宏伟挑战。大型语言模型在医学问答方面取得了重大进展；Med-PaLM是第一个在MedQA数据集上以67.2％的分数超过美国医疗执业考试（USMLE）样式问题的“及格”分数的模型。 然而，对比模型答案和医生答案，这项和其他先前工作表明还有很大的改进空间。本文提出了Med-PaLM2，通过利用基础LLM改进（PaLM2）、医学领域微调和提示策略（包括新颖的集成精炼方法）来弥合这些差距。在MedQA数据集上，Med-PaLM2的得分可达86.5％，比Med-PaLM提高了超过11％。

    Recent artificial intelligence (AI) systems have reached milestones in "grand challenges" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge.  Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a "passing" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach.  Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM by over 
    
[^6]: 大型语言模型是内置的自回归搜索引擎

    Large Language Models are Built-in Autoregressive Search Engines. (arXiv:2305.09612v1 [cs.CL])

    [http://arxiv.org/abs/2305.09612](http://arxiv.org/abs/2305.09612)

    本篇论文指出大型语言模型可以作为内置搜索引擎，通过提供一些上下文演示直接生成Web URLs，在文档检索中表现出色。

    

    文档检索是标准网络搜索引擎的关键阶段。现有的双编码器密集检索器独立地获取问题和文档的表示，只允许它们之间的浅层交互。为了克服这个限制，最近的自回归搜索引擎通过直接生成候选池中相关文档的标识符来替换双编码器架构。然而，这种自回归搜索引擎的训练成本随着候选文档数量的增加而急剧上升。在本文中，我们发现大型语言模型（LLM）可以遵循人类指示直接生成文档检索的URL。令人惊讶的是，当提供一些{Query-URL}对作为上下文演示时，LLMs可以生成Web URL，其中近90％的相应文档包含开放域问题的正确答案。这样，LLMs可以被认为是内置搜索引擎，因为它们没有明确训练以映射问题和文档之间的相关性。

    Document retrieval is a key stage of standard Web search engines. Existing dual-encoder dense retrievers obtain representations for questions and documents independently, allowing for only shallow interactions between them. To overcome this limitation, recent autoregressive search engines replace the dual-encoder architecture by directly generating identifiers for relevant documents in the candidate pool. However, the training cost of such autoregressive search engines rises sharply as the number of candidate documents increases. In this paper, we find that large language models (LLMs) can follow human instructions to directly generate URLs for document retrieval.  Surprisingly, when providing a few {Query-URL} pairs as in-context demonstrations, LLMs can generate Web URLs where nearly 90\% of the corresponding documents contain correct answers to open-domain questions. In this way, LLMs can be thought of as built-in search engines, since they have not been explicitly trained to map qu
    
[^7]: 用去噪结构到文本增强技术提升事件提取

    Boosting Event Extraction with Denoised Structure-to-Text Augmentation. (arXiv:2305.09598v1 [cs.CL])

    [http://arxiv.org/abs/2305.09598](http://arxiv.org/abs/2305.09598)

    本文提出了一个去噪结构到文本增强框架（DAEE），通过基于知识的生成模型生成附加的训练数据，并通过深度强化学习代理迭代地选择有效的数据子集，以解决事件提取中标注数据不足的问题。

    

    事件提取旨在从文本中识别预定义的事件触发器和参数，但这种任务常常受制于缺乏高质量的标注数据。最近的数据增强方法经常因语法不正确、结构不匹配和语义漂移等问题而导致性能不尽如人意。本文提出了一种用于事件提取的去噪结构到文本增强框架，称为DAEE，通过基于知识的结构到文本生成模型生成附加的训练数据，并使用深层强化学习代理迭代地选择生成数据的有效子集，以解决这些问题。在多个数据集上的实验结果表明，所提出的方法生成了更具多样性的文本表示。

    Event extraction aims to recognize pre-defined event triggers and arguments from texts, which suffer from the lack of high-quality annotations. In most NLP applications, involving a large scale of synthetic training data is a practical and effective approach to alleviate the problem of data scarcity. However, when applying to the task of event extraction, recent data augmentation methods often neglect the problem of grammatical incorrectness, structure misalignment, and semantic drifting, leading to unsatisfactory performances. In order to solve these problems, we propose a denoised structure-to-text augmentation framework for event extraction DAEE, which generates additional training data through the knowledge-based structure-to-text generation model and selects the effective subset from the generated data iteratively with a deep reinforcement learning agent. Experimental results on several datasets demonstrate that the proposed method generates more diverse text representations for e
    
[^8]: UOR：预训练语言模型的通用后门攻击

    UOR: Universal Backdoor Attacks on Pre-trained Language Models. (arXiv:2305.09574v1 [cs.CL])

    [http://arxiv.org/abs/2305.09574](http://arxiv.org/abs/2305.09574)

    本文介绍了一种新的后门攻击方法UOR，可以自动选择触发器并学习通用输出表示，成功率高达99.3％，能够对多种预训练语言模型和下游任务实施攻击，且可突破最新的防御方法。

    

    在预训练语言模型中植入后门可以传递到各种下游任务，这对安全构成了严重威胁。然而，现有的针对预训练语言模型的后门攻击大都是非目标和特定任务的。很少有针对目标和任务不可知性的方法使用手动预定义的触发器和输出表示，这使得攻击效果不够强大和普适。本文首先总结了一个更具威胁性的预训练语言模型后门攻击应满足的要求，然后提出了一种新的后门攻击方法UOR，通过将手动选择变成自动优化，打破了以往方法的瓶颈。具体来说，我们定义了被污染的监督对比学习，可以自动学习各种预训练语言模型触发器的更加均匀和通用输出表示。此外，我们使用梯度搜索选取适当的触发词，可以适应不同的预训练语言模型和词汇表。实验证明，UOR可以在各种PLMs和下游任务中实现高后门成功率（高达99.3％），优于现有方法。此外，UOR还可以突破对抗后门攻击的最新防御方法。

    Backdoors implanted in pre-trained language models (PLMs) can be transferred to various downstream tasks, which exposes a severe security threat. However, most existing backdoor attacks against PLMs are un-targeted and task-specific. Few targeted and task-agnostic methods use manually pre-defined triggers and output representations, which prevent the attacks from being more effective and general. In this paper, we first summarize the requirements that a more threatening backdoor attack against PLMs should satisfy, and then propose a new backdoor attack method called UOR, which breaks the bottleneck of the previous approach by turning manual selection into automatic optimization. Specifically, we define poisoned supervised contrastive learning which can automatically learn the more uniform and universal output representations of triggers for various PLMs. Moreover, we use gradient search to select appropriate trigger words which can be adaptive to different PLMs and vocabularies. Experi
    
[^9]: 针对航空领域进行句子变换器的适应性研究

    Adapting Sentence Transformers for the Aviation Domain. (arXiv:2305.09556v1 [cs.CL])

    [http://arxiv.org/abs/2305.09556](http://arxiv.org/abs/2305.09556)

    本研究提出了一种针对航空领域的句子变换器调整方法，在预训练阶段使用TSDAE模型进行改进，然后在少量注释的数据集上进行微调，实验结果表明在航空相关的自然语言处理任务中取得了最好的表现。

    

    学习有效的句子表示对于许多自然语言处理任务至关重要，包括语义搜索、语义文本相似度（STS）和聚类。虽然已经开发了多个用于句子嵌入学习的变形器模型，但是这些模型在处理具有唯一特征的专业领域时，如航空领域，可能无法发挥最佳性能，因为航空领域包含特殊术语、缩写词和非传统语法等领域特有特点。此外，缺乏标记的数据集使得难以专门训练航空领域的模型。为了解决这些挑战，我们提出了一种针对航空领域调整句子变换器的新方法。我们的方法是一个两阶段的过程，包括预训练和微调。在预训练阶段，我们使用含航空文本数据的变形器和序列去噪自编码器(TSDAE)作为输入来提高初始模型性能。随后，我们使用少量注释的航空数据集进行自然语言推理（NLI）任务来微调我们的模型。在几个与航空相关的自然语言处理任务上的实验结果表明，我们的方法明显优于基准变换模型，并在某些情况下取得了最新的结果。

    Learning effective sentence representations is crucial for many Natural Language Processing (NLP) tasks, including semantic search, semantic textual similarity (STS), and clustering. While multiple transformer models have been developed for sentence embedding learning, these models may not perform optimally when dealing with specialized domains like aviation, which has unique characteristics such as technical jargon, abbreviations, and unconventional grammar. Furthermore, the absence of labeled datasets makes it difficult to train models specifically for the aviation domain. To address these challenges, we propose a novel approach for adapting sentence transformers for the aviation domain. Our method is a two-stage process consisting of pre-training followed by fine-tuning. During pre-training, we use Transformers and Sequential Denoising AutoEncoder (TSDAE) with aviation text data as input to improve the initial model performance. Subsequently, we fine-tune our models using a Natural 
    
[^10]: PII的生命--一种PII混淆变换器

    Life of PII -- A PII Obfuscation Transformer. (arXiv:2305.09550v1 [cs.CL])

    [http://arxiv.org/abs/2305.09550](http://arxiv.org/abs/2305.09550)

    “Life of PII”是一种新颖的混淆变换器框架，用于将PII转化为人造PII同时尽可能地保留原始信息、意图和上下文，使我们能够有选择地混淆文档中的敏感信息，同时保留文档的统计和语义特性。

    

    在当今大型语言模型和数据驱动服务的世界中，保护敏感信息至关重要。一种常见的方法是使用数据扰动技术来减少(敏感)个人身份识别信息(PII)数据的过度实用性，同时保持其统计和语义特性。数据扰动方法经常导致显着的信息损失，使它们难以使用。在本文中，我们提出了“PII的生命”--一种新颖的混淆变换器框架，用于将PII转化为人造PII同时尽可能地保留原始信息、意图和上下文。我们的方法包括一个API来与给定的文档进行接口，一个基于配置的混淆器和一个基于Transformer架构的模型，在自然语言处理任务和LLMs中表现出高的上下文保存性能。我们的基于Transformer的方法学习了原始PII和其转换后的人造PII对应的映射，使我们能够有选择地混淆文档中的敏感信息，同时保留文档的统计和语义特性。

    Protecting sensitive information is crucial in today's world of Large Language Models (LLMs) and data-driven services. One common method used to preserve privacy is by using data perturbation techniques to reduce overreaching utility of (sensitive) Personal Identifiable Information (PII) data while maintaining its statistical and semantic properties. Data perturbation methods often result in significant information loss, making them impractical for use. In this paper, we propose 'Life of PII', a novel Obfuscation Transformer framework for transforming PII into faux-PII while preserving the original information, intent, and context as much as possible. Our approach includes an API to interface with the given document, a configuration-based obfuscator, and a model based on the Transformer architecture, which has shown high context preservation and performance in natural language processing tasks and LLMs.  Our Transformer-based approach learns mapping between the original PII and its tra
    
[^11]: 使用以实体为中心的数据来衡量刻板印象

    Measuring Stereotypes using Entity-Centric Data. (arXiv:2305.09548v1 [cs.CL])

    [http://arxiv.org/abs/2305.09548](http://arxiv.org/abs/2305.09548)

    本文提出并评估了三种新的以实体为中心的方法，展示了这些模型在预测人们如何将身份标签应用于自己和他人以及量化突出的社会维度（如性别）的刻板印象方面优于现有方法。

    

    刻板印象影响我们如何展示自己和他人，从而影响我们的行为。因此，衡量刻板印象非常重要。最近的研究使用分布语义模型（DSM）（如BERT）中嵌入的投影来进行这些测量。然而，DSMs捕捉到的认知联想不一定与刻板印象的人际性质相关。在这里，我们提出并评估了三种新的以实体为中心的方法，从Twitter和Wikipedia传记中学习刻板印象。通过利用多个短语应用于同一个人的事实来训练模型，扩大了学习联想的人本身中心性。我们证明了这些模型在预测人们如何将身份标签应用于自己和他人以及量化突出的社会维度（如性别）的刻板印象方面优于现有方法。通过一个案例研究，我们还展示了这些模型对未来计算社会科学问题的实用性。

    Stereotypes inform how we present ourselves and others, and in turn how we behave. They are thus important to measure. Recent work has used projections of embeddings from Distributional Semantic Models (DSMs), such as BERT, to perform these measurements. However, DSMs capture cognitive associations that are not necessarily relevant to the interpersonal nature of stereotyping. Here, we propose and evaluate three novel, entity-centric methods for learning stereotypes from Twitter and Wikipedia biographies. Models are trained by leveraging the fact that multiple phrases are applied to the same person, magnifying the person-centric nature of the learned associations. We show that these models outperform existing approaches to stereotype measurement with respect to 1) predicting which identities people apply to themselves and others, and 2) quantifying stereotypes on salient social dimensions (e.g. gender). Via a case study, we also show the utility of these models for future questions in c
    
[^12]: MetaSRL++：用于建模更深层语义的统一方案

    MetaSRL++: A Uniform Scheme for Modelling Deeper Semantics. (arXiv:2305.09534v1 [cs.CL])

    [http://arxiv.org/abs/2305.09534](http://arxiv.org/abs/2305.09534)

    本文介绍了MetaSRL ++，它是一种统一、语言和形式无关的建模方案，基于语义图，用于建模更深层的语义。

    

    自然语言处理领域虽然取得了巨大的进展，但仍缺乏一种共同的深层语义表示方案。因此，本文提出了基于语义图的统一、语言和形式无关的建模方案MetaSRL ++作为实现这样的方案的一种方法，同时还介绍了一种定义这些图中使用的概念和实体方法。本文的输出有两部分：首先，我们通过具体示例说明MetaSRL ++；其次，我们讨论了它与该领域现有工作的关系。

    Despite enormous progress in Natural Language Processing (NLP), our field is still lacking a common deep semantic representation scheme. As a result, the problem of meaning and understanding is typically sidestepped through more simple, approximative methods. This paper argues that in order to arrive at such a scheme, we also need a common modelling scheme. It therefore introduces MetaSRL++, a uniform, language- and modality-independent modelling scheme based on Semantic Graphs, as a step towards a common representation scheme; as well as a method for defining the concepts and entities that are used in these graphs. Our output is twofold. First, we illustrate MetaSRL++ through concrete examples. Secondly, we discuss how it relates to existing work in the field.
    
[^13]: AR-Diffusion：自回归扩散模型用于文本生成

    AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation. (arXiv:2305.09515v1 [cs.CL])

    [http://arxiv.org/abs/2305.09515](http://arxiv.org/abs/2305.09515)

    本文提出了一种自回归扩散模型（AR-Diffusion）用于文本生成，通过动态数量的降噪步骤，确保左侧标记的生成影响右侧标记的生成。

    

    扩散模型由于其出色的性能，在图像生成领域引起了广泛的关注。最近，这种成功已经扩展到了通过同时生成序列中的所有标记来实现文本生成。然而，自然语言相对于图像具有更为明显的序列依赖性，现有的大多数语言模型都是使用自左向右的自回归方法进行训练的。为了解决自然语言固有的序列特征，我们引入了自回归扩散（AR-Diffusion）模型。AR-Diffusion确保右侧标记的生成取决于左侧标记的生成，这种机制是通过采用动态数量的降噪步骤来实现的，这些步骤根据标记位置而变化。这导致左侧的标记经历的降噪步骤比右侧的标记少，从而使它们能够更早地生成并随后影响右侧标记的生成。

    Diffusion models have gained significant attention in the realm of image generation due to their exceptional performance. Their success has been recently expanded to text generation via generating all tokens within a sequence concurrently. However, natural language exhibits a far more pronounced sequential dependency in comparison to images, and the majority of existing language models are trained utilizing a left-to-right auto-regressive approach. To account for the inherent sequential characteristic of natural language, we introduce Auto-Regressive Diffusion (AR-Diffusion). AR-Diffusion ensures that the generation of tokens on the right depends on the generated ones on the left, a mechanism achieved through employing a dynamic number of denoising steps that vary based on token position. This results in tokens on the left undergoing fewer denoising steps than those on the right, thereby enabling them to generate earlier and subsequently influence the generation of tokens on the right.
    
[^14]: 模糊时间原型体用于自然语言进程的定量描述

    Fuzzy Temporal Protoforms for the Quantitative Description of Processes in Natural Language. (arXiv:2305.09506v1 [cs.CL])

    [http://arxiv.org/abs/2305.09506](http://arxiv.org/abs/2305.09506)

    本文提出了一种自然语言进程描述方法，使用模糊时间原型体实现定量描述。模型能提取过程的相关信息，并用自然语言描述，可应用于心脏病领域等其他复杂领域。

    

    本文在自然语言过程的定量和定性描述的框架中提出了一系列模糊时间原型体。该模型包括过程和属性的时间和因果信息，定量描述了过程寿命内的属性，并回忆了事件之间的因果关系和时间距离，等等其他特征。通过在常规数据到文本架构中集成过程挖掘技术和模糊集，我们的框架能够从过程中提取相关的定量和结构信息，并用涉及不确定术语的自然语言描述来描述它。本文还介绍了心脏病领域的实际用例，展示了我们的模型为向领域专家提供自然语言解释的潜力。

    In this paper, we propose a series of fuzzy temporal protoforms in the framework of the automatic generation of quantitative and qualitative natural language descriptions of processes. The model includes temporal and causal information from processes and attributes, quantifies attributes in time during the process life-span and recalls causal relations and temporal distances between events, among other features. Through integrating process mining techniques and fuzzy sets within the usual Data-to-Text architecture, our framework is able to extract relevant quantitative temporal as well as structural information from a process and describe it in natural language involving uncertain terms. A real use-case in the cardiology domain is presented, showing the potential of our model for providing natural language explanations addressed to domain experts.
    
[^15]: MPI-rical：基于Transformer的数据驱动MPI分布式并行辅助

    MPI-rical: Data-Driven MPI Distributed Parallelism Assistance with Transformers. (arXiv:2305.09438v1 [cs.DC])

    [http://arxiv.org/abs/2305.09438](http://arxiv.org/abs/2305.09438)

    本文提出了一种基于Transformer模型的新方法MPI-rical，通过对大量代码片段进行训练实现自动化MPI代码生成，使并行化成为可能。

    

    在高性能计算中，将串行代码自动并行化以支持共享内存和分布式内存系统是一项具有挑战性的任务。虽然许多尝试将串行代码转换为共享内存环境的并行代码（通常使用OpenMP），但没有任何一项尝试成功将其转化为分布式内存环境。本文提出了一种称为MPI-rical的新方法，通过基于Transformer模型对大约25,000个串行代码片段及其对应的并行MPI代码进行训练，从我们的语料库（MPICodeCorpus）的50,000多个代码片段中生成自动化MPI代码。为了评估模型的性能，我们首先将串行代码转换为基于MPI的并行代码翻译问题分解为两个子问题，并制定两个研究目标：代码补全，即在给定源代码中的某个位置，预测该位置的MPI函数；代码翻译，即预测一个MPI函数。

    Automatic source-to-source parallelization of serial code for shared and distributed memory systems is a challenging task in high-performance computing. While many attempts were made to translate serial code into parallel code for a shared memory environment (usually using OpenMP), none has managed to do so for a distributed memory environment. In this paper, we propose a novel approach, called MPI-rical, for automated MPI code generation using a transformer-based model trained on approximately 25,000 serial code snippets and their corresponding parallelized MPI code out of more than 50,000 code snippets in our corpus (MPICodeCorpus). To evaluate the performance of the model, we first break down the serial code to MPI-based parallel code translation problem into two sub-problems and develop two research objectives: code completion defined as given a location in the source code, predict the MPI function for that location, and code translation defined as predicting an MPI function as wel
    
[^16]: 关于F1分数的讨论——以最近的关系抽取系统为例

    About Evaluation of F1 Score for RECENT Relation Extraction System. (arXiv:2305.09410v1 [cs.CL])

    [http://arxiv.org/abs/2305.09410](http://arxiv.org/abs/2305.09410)

    本文讨论了一个名为RECENT的关系抽取系统，作者在TACRED数据集上取得了之前的最新成果74.8的F1分数，但在更正错误和重新评估后其F1分数为65.16。

    

    本文讨论了Shengfei Lyu和Huanhuan Chen在Findings of the Association for Computational Linguistics：ACL-IJCNLP 2021上发表的论文“Relation Classification with Entity Type Restriction”中使用的F1分数评估方法。作者创建的系统名为RECENT，声称其在TACRED数据集上取得了（当时的）最新的75.2（之前为74.8）的最新成果，但在更正错误和重新评估后最终结果为65.16。

    This document contains a discussion of the F1 score evaluation used in the article 'Relation Classification with Entity Type Restriction' by Shengfei Lyu, Huanhuan Chen published on Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. The authors created a system named RECENT and claim it achieves (then) a new state-of-the-art result 75.2 (previous 74.8) on the TACRED dataset, while after correcting errors and reevaluation the final result is 65.16
    
[^17]: GPT-3.5和Bard AI模型在Java函数代码生成能力方面的初步分析

    A Preliminary Analysis on the Code Generation Capabilities of GPT-3.5 and Bard AI Models for Java Functions. (arXiv:2305.09402v1 [cs.SE])

    [http://arxiv.org/abs/2305.09402](http://arxiv.org/abs/2305.09402)

    本文评估了GPT-3.5和Bard AI模型在生成Java代码方面的能力，结果表明GPT-3.5表现更好，为AI辅助代码生成工具的开发提供了潜在途径。

    

    本文评估了两个最先进的人工智能（AI）模型GPT-3.5和Bard在给定函数描述时生成Java代码的能力。我们从CodingBat.com获取了这些描述，并基于平台自己的测试用例比较了两个模型生成的Java代码的正确性。结果表明，两个模型的能力存在明显差异。GPT-3.5表现出更高的性能，对大约90.6％的函数描述生成正确的代码，而Bard仅为53.1％的函数生成了正确的代码。尽管两个模型都有优势和劣势，但这些发现为更先进的AI辅助代码生成工具的开发和改进提供了潜在途径。本研究强调了AI在自动化和支持软件开发方面的潜力，但需要进一步研究。

    This paper evaluates the capability of two state-of-the-art artificial intelligence (AI) models, GPT-3.5 and Bard, in generating Java code given a function description. We sourced the descriptions from CodingBat.com, a popular online platform that provides practice problems to learn programming. We compared the Java code generated by both models based on correctness, verified through the platform's own test cases. The results indicate clear differences in the capabilities of the two models. GPT-3.5 demonstrated superior performance, generating correct code for approximately 90.6% of the function descriptions, whereas Bard produced correct code for 53.1% of the functions. While both models exhibited strengths and weaknesses, these findings suggest potential avenues for the development and refinement of more advanced AI-assisted code generation tools. The study underlines the potential of AI in automating and supporting aspects of software development, although further research is requir
    
[^18]: GIFT: 基于图感知微调的多方对话理解

    GIFT: Graph-Induced Fine-Tuning for Multi-Party Conversation Understanding. (arXiv:2305.09360v1 [cs.CL])

    [http://arxiv.org/abs/2305.09360](http://arxiv.org/abs/2305.09360)

    GIFT是一个适用于多方对话理解的方法，通过设计四种类型的边缘将图感知信息集成到注意力机制中，改进了原始的顺序文本处理的PLM。

    

    最近，关于谁与谁在多方对话中说了什么的问题已经引起了很多研究的关注。然而，现有的多方对话理解方法通常将说话者和话语嵌入到顺序信息流中，或仅利用多方对话中固有图结构的表层信息。为此，我们提出了一种名为图感知微调（GIFT）的即插即用轻量级方法，可以适应各种基于Transformer预训练语言模型（PLMs）的通用多方对话理解。具体地，在普通Transformer中，话语之间的全等连接会忽略一个话语对另一个话语的稀疏但有区别的依赖关系。为了区分话语之间的不同关系，设计了四种类型的边缘以将图感知信号集成到注意机制中，以改进最初设计用于处理顺序文本的PLMs。我们通过将GIFT实现到三个PLMs并对其进行测试来评估GIFT。

    Addressing the issues of who saying what to whom in multi-party conversations (MPCs) has recently attracted a lot of research attention. However, existing methods on MPC understanding typically embed interlocutors and utterances into sequential information flows, or utilize only the superficial of inherent graph structures in MPCs. To this end, we present a plug-and-play and lightweight method named graph-induced fine-tuning (GIFT) which can adapt various Transformer-based pre-trained language models (PLMs) for universal MPC understanding. In detail, the full and equivalent connections among utterances in regular Transformer ignore the sparse but distinctive dependency of an utterance on another in MPCs. To distinguish different relationships between utterances, four types of edges are designed to integrate graph-induced signals into attention mechanisms to refine PLMs originally designed for processing sequential texts. We evaluate GIFT by implementing it into three PLMs, and test the
    
[^19]: MsPrompt: 多步骤提示学习用于去偏少样本事件检测

    MsPrompt: Multi-step Prompt Learning for Debiasing Few-shot Event Detection. (arXiv:2305.09335v1 [cs.CL])

    [http://arxiv.org/abs/2305.09335](http://arxiv.org/abs/2305.09335)

    本研究提出了一个多步骤提示学习模型（MsPrompt），用于解决少样本场景下的事件检测问题，并通过欠采样、多级提示以及原型模块来解决上下文绕过和增强事件语义和潜在先验知识。

    

    事件检测（ED）旨在识别非结构化文本中的关键触发词并相应地预测事件类型。传统的 ED 模型过于依赖数据，难以适应缺乏标记数据的实际应用。此外，触发偏见会导致 ED 数据集存在上下文绕过和残缺泛化等问题。因此，我们专注于真正的少样本范式来适应低资源场景。我们提出了一个多步骤提示学习模型（MsPrompt）用于去偏少样本事件检测，包括以下三个组成部分：一个欠采样模块， 具有多级提示模块和原型模块，以解决语境绕过问题和增强事件语义和潜在先验知识。

    Event detection (ED) is aimed to identify the key trigger words in unstructured text and predict the event types accordingly. Traditional ED models are too data-hungry to accommodate real applications with scarce labeled data. Besides, typical ED models are facing the context-bypassing and disabled generalization issues caused by the trigger bias stemming from ED datasets. Therefore, we focus on the true few-shot paradigm to satisfy the low-resource scenarios. In particular, we propose a multi-step prompt learning model (MsPrompt) for debiasing few-shot event detection, that consists of the following three components: an under-sampling module targeting to construct a novel training set that accommodates the true few-shot setting, a multi-step prompt module equipped with a knowledge-enhanced ontology to leverage the event semantics and latent prior knowledge in the PLMs sufficiently for tackling the context-bypassing problem, and a prototypical module compensating for the weakness of cl
    
[^20]: 基于提示的多模态视觉理解技术对图像语义信息进行分离的研究

    Multi-modal Visual Understanding with Prompts for Semantic Information Disentanglement of Image. (arXiv:2305.09333v1 [cs.CV])

    [http://arxiv.org/abs/2305.09333](http://arxiv.org/abs/2305.09333)

    本论文研究了基于提示的多模态视觉理解技术，通过分离语义信息提高对图像的理解，旨在推进图像识别和理解领域的研究。

    

    通过提示来进行多模态视觉理解技术可利用各种视觉及文本线索，提高对图像的语义理解。这种方法结合了视觉和语言处理，能够产生更准确的预测和识别图像。通过采用基于提示的技术，模型可以学习关注图像的某些特征，以提取下游任务所需的有用信息。此外，多模态理解可以通过提供更强大的图像表示来改善单模态模型的性能。总的来说，视觉和文本信息的结合是推进图像识别和理解领域的有望研究方向。本文将尝试一些提示设计方法，并提出一种更好地提取语义信息的新方法。

    Multi-modal visual understanding of images with prompts involves using various visual and textual cues to enhance the semantic understanding of images. This approach combines both vision and language processing to generate more accurate predictions and recognition of images. By utilizing prompt-based techniques, models can learn to focus on certain features of an image to extract useful information for downstream tasks. Additionally, multi-modal understanding can improve upon single modality models by providing more robust representations of images. Overall, the combination of visual and textual information is a promising area of research for advancing image recognition and understanding. In this paper we will try an amount of prompt design methods and propose a new method for better extraction of semantic information
    
[^21]: BERTTM: 利用来自预训练语言模型的上下文化词向量进行神经主题建模

    BERTTM: Leveraging Contextualized Word Embeddings from Pre-trained Language Models for Neural Topic Modeling. (arXiv:2305.09329v1 [cs.CL])

    [http://arxiv.org/abs/2305.09329](http://arxiv.org/abs/2305.09329)

    本文提出了一种新颖的神经主题模型，利用来自预训练语言模型BERT的上下文化词嵌入，可以在不使用任何BoW信息的情况下推断出文档的主题分布，并直接从上下文化词嵌入中推断出文档中每个单词的主题分布。实验结果表明，该模型优于仅依赖BoW表示和其他神经主题模型的现有最先进方法。

    

    随着近年来神经主题模型的发展，主题建模在自然语言理解中扮演着日益重要的角色。然而，大多数现有的主题模型仍然依赖于词袋（BoW）信息，无论是作为训练输入还是训练目标。这限制了它们捕捉文档中的单词顺序信息的能力，并导致它们在处理新文档中的未观察到的单词时遇到困难。预训练语言模型中的上下文化词向量在词义消歧的能力上表现优越，并证明了它们在处理OOV单词时是有效的。在这项工作中，我们开发了一种新颖的神经主题模型，结合了预训练语言模型BERT的上下文化词嵌入。该模型可以在不使用任何BoW信息的情况下推断出文档的主题分布。此外，该模型可以直接从上下文化词嵌入中推断出文档中每个单词的主题分布。基准数据集的实验表明，我们的模型优于仅依赖BoW表示和其他神经主题模型的现有最先进方法。

    With the development of neural topic models in recent years, topic modelling is playing an increasingly important role in natural language understanding. However, most existing topic models still rely on bag-of-words (BoW) information, either as training input or training target. This limits their ability to capture word order information in documents and causes them to suffer from the out-of-vocabulary (OOV) issue, i.e. they cannot handle unobserved words in new documents. Contextualized word embeddings from pre-trained language models show superiority in the ability of word sense disambiguation and prove to be effective in dealing with OOV words. In this work, we developed a novel neural topic model combining contextualized word embeddings from the pre-trained language model BERT. The model can infer the topic distribution of a document without using any BoW information. In addition, the model can infer the topic distribution of each word in a document directly from the contextualize
    
[^22]: 利用图嵌入增强从长篇科技论文中提取关键词的方法

    Enhancing Keyphrase Extraction from Long Scientific Documents using Graph Embeddings. (arXiv:2305.09316v1 [cs.CL])

    [http://arxiv.org/abs/2305.09316](http://arxiv.org/abs/2305.09316)

    本文研究了使用图神经网络表示加强预训练语言模型对长篇科技论文的关键词提取。通过构建文本共现图并结合图表示和上下文化的PLM嵌入，我们展示了对于长篇文档，增强PLMs性能比现有技术的模型表现更加出色。

    

    本研究探讨了使用图神经网络（GNN）表示强化预训练语言模型（PLMs）对长篇文档中的关键词提取的上下文表示的方法。我们展示了利用图嵌入增强PLM提供更全面的语义理解文档中的单词，特别是对于长篇文档。我们构建了文本的共现图，并使用在边预测任务上训练的图卷积网络（GCN）来嵌入它。我们提出了一种图增强的序列标记架构，它将上下文化的PLM嵌入与图表示相结合。在基准测试数据集上的评估表明，增强PLM与图嵌入比现有技术的模型在长文档上表现更出色，在所有数据集中都显着提高F1得分。我们的研究突出了GNN表示作为改进PLM性能的一种补充方法的潜力。

    In this study, we investigate using graph neural network (GNN) representations to enhance contextualized representations of pre-trained language models (PLMs) for keyphrase extraction from lengthy documents. We show that augmenting a PLM with graph embeddings provides a more comprehensive semantic understanding of words in a document, particularly for long documents. We construct a co-occurrence graph of the text and embed it using a graph convolutional network (GCN) trained on the task of edge prediction. We propose a graph-enhanced sequence tagging architecture that augments contextualized PLM embeddings with graph representations. Evaluating on benchmark datasets, we demonstrate that enhancing PLMs with graph embeddings outperforms state-of-the-art models on long documents, showing significant improvements in F1 scores across all the datasets. Our study highlights the potential of GNN representations as a complementary approach to improve PLM performance for keyphrase extraction fro
    
[^23]: 混合与协作的段落再排序方法

    Hybrid and Collaborative Passage Reranking. (arXiv:2305.09313v1 [cs.IR])

    [http://arxiv.org/abs/2305.09313](http://arxiv.org/abs/2305.09313)

    该论文提出了一种名为HybRank的混合与协作的段落再排序方法，通过利用上游检索器的相似性度量实现段落协作，再利用稀疏和密集检索器的词汇和语义属性进行重新排序，该方法可以增强包括先前被重新排序的段落列表在内的任意段落列表，并在实验证明了性能稳定的提升。

    

    在段落检索系统中，初始检索结果可能不尽如人意，需要通过重新排序方案进行改善。现有的段落重新排序方案主要集中于丰富查询和每个段落之间的交互，忽略了在初始检索列表中排名靠前的多个段落之间的上下文关系。为解决这个问题，我们提出了一种混合与协作的段落再排序方法（HybRank），该方法利用上游检索器的相似性度量进行段落协作，并结合稀疏和密集检索器的词汇和语义属性进行重新排序。此外，基于现成的检索器特征，HybRank是一个插件再排序器，能够增强包括先前重新排序的段落列表在内的任意段落列表。大量实验证明了比普遍的检索和再排序方法性能稳定的提升，并验证了HybRank的核心组件的有效性。

    In passage retrieval system, the initial passage retrieval results may be unsatisfactory, which can be refined by a reranking scheme. Existing solutions to passage reranking focus on enriching the interaction between query and each passage separately, neglecting the context among the top-ranked passages in the initial retrieval list. To tackle this problem, we propose a Hybrid and Collaborative Passage Reranking (HybRank) method, which leverages the substantial similarity measurements of upstream retrievers for passage collaboration and incorporates the lexical and semantic properties of sparse and dense retrievers for reranking. Besides, built on off-the-shelf retriever features, HybRank is a plug-in reranker capable of enhancing arbitrary passage lists including previously reranked ones. Extensive experiments demonstrate the stable improvements of performance over prevalent retrieval and reranking methods, and verify the effectiveness of the core components of HybRank.
    
[^24]: 探究层归一化在零样本神经机器翻译中的影响

    Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation. (arXiv:2305.09312v1 [cs.CL])

    [http://arxiv.org/abs/2305.09312](http://arxiv.org/abs/2305.09312)

    研究发现，在零样本翻译中，使用残差连接后的Transformer设置的层归一化（PostNorm）始终优于带有层归一化的PreNorm，最高可提高12.3 BLEU分。

    

    本文研究了层归一化（LayerNorm）对零样本翻译（ZST）的影响。最近的ZST研究通常使用Transformer架构作为主干，并将层的输入设置为带有LayerNorm的PreNorm。然而，徐等人（2019）揭示了PreNorm存在过度拟合训练数据的风险。基于此，我们假设PreNorm可能会过度拟合监督方向，因此在ZST中具有低的泛化能力。通过在OPUS、IWSLT和Europarl数据集上进行54个ZST方向的实验，我们证明了在残差连接后使用原始的Transformer设置LayerNorm（PostNorm）的表现始终优于PreNorm达12.3 BLEU分。然后，我们通过分析PreNorm和PostNorm之间的离靶率和结构变化的差异，研究了性能差异。这项研究强调了对ZST的LayerNorm设置需要仔细考虑。

    This paper studies the impact of layer normalization (LayerNorm) on zero-shot translation (ZST). Recent efforts for ZST often utilize the Transformer architecture as the backbone, with LayerNorm at the input of layers (PreNorm) set as the default. However, Xu et al. (2019) has revealed that PreNorm carries the risk of overfitting the training data. Based on this, we hypothesize that PreNorm may overfit supervised directions and thus have low generalizability for ZST. Through experiments on OPUS, IWSLT, and Europarl datasets for 54 ZST directions, we demonstrate that the original Transformer setting of LayerNorm after residual connections (PostNorm) consistently outperforms PreNorm by up to 12.3 BLEU points. We then study the performance disparities by analyzing the differences in off-target rates and structural variations between PreNorm and PostNorm. This study highlights the need for careful consideration of the LayerNorm setting for ZST.
    
[^25]: 从Jim代码的角度探究自然语言处理中偏见的起源

    On the Origins of Bias in NLP through the Lens of the Jim Code. (arXiv:2305.09281v1 [cs.CL])

    [http://arxiv.org/abs/2305.09281](http://arxiv.org/abs/2305.09281)

    本文追溯了过去500年种族主义、性别歧视和同性恋恐惧症，认为NLP模型中的偏见源自社会问题，并提出了解决方法与建议。

    

    本文通过追溯过去500年的种族主义、性别歧视和同性恋恐惧症，将当前自然语言处理（NLP）模型中的偏见追溯到它们的起源。我们从关键种族理论、性别研究、数据伦理和数字人文研究的文献中总结了偏见在NLP模型中的起源。我们展示了NLP中偏见的根本原因是社会问题。最后，我们认为解决NLP中的偏见和不公平的唯一方法是解决导致这些问题的社会问题，并将社会科学和社会科学家纳入减轻NLP模型偏见的努力中。我们提供了可实施的建议，供NLP研究界使用。

    In this paper, we trace the biases in current natural language processing (NLP) models back to their origins in racism, sexism, and homophobia over the last 500 years. We review literature from critical race theory, gender studies, data ethics, and digital humanities studies, and summarize the origins of bias in NLP models from these social science perspective. We show how the causes of the biases in the NLP pipeline are rooted in social issues. Finally, we argue that the only way to fix the bias and unfairness in NLP is by addressing the social problems that caused them in the first place and by incorporating social sciences and social scientists in efforts to mitigate bias in NLP models. We provide actionable recommendations for the NLP research community to do so.
    
[^26]: ContrastNet：一种用于少样本文本分类的对比学习框架

    ContrastNet: A Contrastive Learning Framework for Few-Shot Text Classification. (arXiv:2305.09269v1 [cs.CL])

    [http://arxiv.org/abs/2305.09269](http://arxiv.org/abs/2305.09269)

    ContrastNet是一种对比学习框架，旨在解决少样本文本分类中的区分性表示和过拟合问题，通过拉近相同类别的文本表示，并推远不同类别的文本表示来学习区分特征。

    

    近年来，元学习范式推动了少样本文本分类，旨在通过名为episodes的小任务，将知识从源类别转移到目标类别。然而，现有基于原型网络构建元学习器的方法，不能很好地学习相似类别之间的区分性文本表示，可能导致标签预测时的矛盾问题。此外，由于少量训练示例，少样本文本分类中的任务层和实例层过拟合问题也没有得到足够解决。因此，我们提出了一种名为ContrastNet的对比学习框架，以解决少样本文本分类中的区分性表示和过拟合问题。ContrastNet学习将属于同一类别的文本表示拉近，并将属于不同类别的文本表示推远，同时引入无监督的对比学习以促进表示学习。

    Few-shot text classification has recently been promoted by the meta-learning paradigm which aims to identify target classes with knowledge transferred from source classes with sets of small tasks named episodes. Despite their success, existing works building their meta-learner based on Prototypical Networks are unsatisfactory in learning discriminative text representations between similar classes, which may lead to contradictions during label prediction. In addition, the tasklevel and instance-level overfitting problems in few-shot text classification caused by a few training examples are not sufficiently tackled. In this work, we propose a contrastive learning framework named ContrastNet to tackle both discriminative representation and overfitting problems in few-shot text classification. ContrastNet learns to pull closer text representations belonging to the same class and push away text representations belonging to different classes, while simultaneously introducing unsupervised con
    
[^27]: HyHTM: 基于双曲几何的层次主题模型

    HyHTM: Hyperbolic Geometry based Hierarchical Topic Models. (arXiv:2305.09258v1 [cs.IR])

    [http://arxiv.org/abs/2305.09258](http://arxiv.org/abs/2305.09258)

    HyHTM是一种基于双曲几何的层次主题模型，通过将双曲几何中的层次信息纳入主题模型中，显式地建模主题层次结构。相较于传统方法，HyHTM更好地关注主题之间的父子关系，并产生了连贯的主题层次结构。同时，HyHTM的计算速度更快，内存占用更小。

    

    层次主题模型对于发现文档集合中的主题层次结构非常有用。然而，传统的层次主题模型常常产生低层次主题与其高层次主题无关且不够具体的层次结构。此外，这些方法计算成本较高。我们提出了一种名为 HyHTM 的双曲几何层次主题模型，通过将双曲几何中的层次信息纳入主题模型中，显式地建模主题层次结构，从而解决了这些限制。与四个基线做实验结果表明，HyHTM 可以更好地关注主题之间父子关系。HyHTM 产生连贯的主题层次结构，从通用的高层次主题到具体的低层次主题。此外，我们的模型计算速度更快，内存占用更小。我们已经公开了算法的源代码。

    Hierarchical Topic Models (HTMs) are useful for discovering topic hierarchies in a collection of documents. However, traditional HTMs often produce hierarchies where lowerlevel topics are unrelated and not specific enough to their higher-level topics. Additionally, these methods can be computationally expensive. We present HyHTM - a Hyperbolic geometry based Hierarchical Topic Models - that addresses these limitations by incorporating hierarchical information from hyperbolic geometry to explicitly model hierarchies in topic models. Experimental results with four baselines show that HyHTM can better attend to parent-child relationships among topics. HyHTM produces coherent topic hierarchies that specialise in granularity from generic higher-level topics to specific lowerlevel topics. Further, our model is significantly faster and leaves a much smaller memory footprint than our best-performing baseline.We have made the source code for our algorithm publicly accessible.
    
[^28]: xPQA：跨12种语言的跨语言产品问答系统

    xPQA: Cross-Lingual Product Question Answering across 12 Languages. (arXiv:2305.09249v1 [cs.CL])

    [http://arxiv.org/abs/2305.09249](http://arxiv.org/abs/2305.09249)

    xPQA是一个支持12种语言的跨语言产品问答系统，通过选择最佳英文候选人并生成自然的其他语言答案，实现了多语言顾客支持。在实验中，研究者发现域内数据是不可或缺的，并且虽然多语言预训练语言模型很有希望，但运行时翻译仍然必要。

    

    在电子商务应用中，产品问答系统是提供顾客问题回答的关键，以帮助他们在购物时对产品进行了解。尽管现有的产品问答系统主要集中在英语上，但实际上需要支持多种语言的顾客，并利用英文版产品信息进行回答。为了研究这个实际的工业任务，我们提出了xPQA，一个跨9个分支的12种语言的大规模语言标注跨语言产品问答数据集，并报告了(1)候选答案的排名，以选择最佳的英文候选答案来回答非英语问题;和(2)回答生成，以基于选择的英文候选答案生成一个自然语言的非英语回答。我们评估了涉及机器翻译、多语言预训练语言模型等不同方法，包括或排除xPQA训练数据的运行时或离线。我们发现(1)域内数据是必不可少的，因为在其他领域训练的跨语言排名器性能下降；(2)虽然多语言预训练语言模型很有希望，但运行时翻译仍然必要。

    Product Question Answering (PQA) systems are key in e-commerce applications to provide responses to customers' questions as they shop for products. While existing work on PQA focuses mainly on English, in practice there is need to support multiple customer languages while leveraging product information available in English. To study this practical industrial task, we present xPQA, a large-scale annotated cross-lingual PQA dataset in 12 languages across 9 branches, and report results in (1) candidate ranking, to select the best English candidate containing the information to answer a non-English question; and (2) answer generation, to generate a natural-sounding non-English answer based on the selected English candidate. We evaluate various approaches involving machine translation at runtime or offline, leveraging multilingual pre-trained LMs, and including or excluding xPQA training data. We find that (1) In-domain data is essential as cross-lingual rankers trained on other domains per
    
[^29]: 或许只需要0.5％的数据：低数据量训练指令调整初步探索

    Maybe Only 0.5% Data is Needed: A Preliminary Exploration of Low Training Data Instruction Tuning. (arXiv:2305.09246v1 [cs.AI])

    [http://arxiv.org/abs/2305.09246](http://arxiv.org/abs/2305.09246)

    本研究发现只需使用0.5%数据便可以进行训练大型语言模型（LLMs）指令调整，并且不影响性能表现。这种方法可以提高数据效率和节约培训成本。

    

    针对训练大型语言模型（LLMs）的问题，本文进行了初步探索，以降低LLM指令调整所需的数据量，从而减少培训成本，提高数据效率。 研究发现，LLM指令调整的数据可以降至0.5％而不影响性能，将这种方法称为Low Training Data Instruction Tuning（LTD Instruction Tuning）。

    Instruction tuning for large language models (LLMs) has gained attention from researchers due to its ability to unlock the potential of LLMs in following instructions. While instruction tuning offers advantages for facilitating the adaptation of large language models (LLMs) to downstream tasks as a fine-tuning approach, training models with tens of millions or even billions of parameters on large amounts of data results in unaffordable computational costs. To address this, we focus on reducing the data used in LLM instruction tuning to decrease training costs and improve data efficiency, dubbed as Low Training Data Instruction Tuning (LTD Instruction Tuning). Specifically, this paper conducts a preliminary exploration into reducing the data used in LLM training and identifies several observations regarding task specialization for LLM training, such as the optimization of performance for a specific task, the number of instruction types required for instruction tuning, and the amount of 
    
[^30]: 走向统一多语言和跨语言摘要

    Towards Unifying Multi-Lingual and Cross-Lingual Summarization. (arXiv:2305.09220v1 [cs.CL])

    [http://arxiv.org/abs/2305.09220](http://arxiv.org/abs/2305.09220)

    本文旨在将多语言摘要和跨语言摘要统一到更通用的多对多摘要中。我们提出了预先训练的M2MS模型“Pisces”，该模型可以处理任何语言的文档并生成摘要。实验结果表明，Pisces在零-shot方向上表现显着优于现有的基线模型。

    

    为了适应多语言的世界，先前的工作提出了多语言摘要（MLS）和跨语言摘要（CLS）。然而，这两个任务因为定义的不同而被分别研究，限制了两者的兼容性和系统研究。在本文中，我们旨在将MLS和CLS统一到更通用的设置中，即多对多摘要（M2MS），其中单个模型可以处理任何语言的文档并生成它们的摘要，也可以用任何语言。作为通向M2MS的第一步，我们进行初步研究，表明M2MS可以更好地在不同语言之间传递任务知识，而不是MLS和CLS。此外，我们提出了Pisces，这是一个预先训练的M2MS模型，通过三阶段的预先训练学习语言建模、跨语言和摘要能力。实验结果表明，我们的Pisces显着优于现有的基线，特别是在零-shot方向中。

    To adapt text summarization to the multilingual world, previous work proposes multi-lingual summarization (MLS) and cross-lingual summarization (CLS). However, these two tasks have been studied separately due to the different definitions, which limits the compatible and systematic research on both of them. In this paper, we aim to unify MLS and CLS into a more general setting, i.e., many-to-many summarization (M2MS), where a single model could process documents in any language and generate their summaries also in any language. As the first step towards M2MS, we conduct preliminary studies to show that M2MS can better transfer task knowledge across different languages than MLS and CLS. Furthermore, we propose Pisces, a pre-trained M2MS model that learns language modeling, cross-lingual ability and summarization ability via three-stage pre-training. Experimental results indicate that our Pisces significantly outperforms the state-of-the-art baselines, especially in the zero-shot directio
    
[^31]: 向不同语言发言人斡旋的语音对话翻译

    Towards Speech Dialogue Translation Mediating Speakers of Different Languages. (arXiv:2305.09210v1 [cs.CL])

    [http://arxiv.org/abs/2305.09210](http://arxiv.org/abs/2305.09210)

    本文提出了一项新任务，即为不同语言的发言人构建语音对话翻译。作者构建了SpeechBSD数据集并进行了基准实验。作者指出上下文是该任务中需要考虑的一个重要方面，并提出了两种利用上下文的方法。最终结果表明，在该任务中双语上下文比单语上下文表现更好。

    

    我们提出了一项新任务，该任务是为不同语言的发言人构建语音对话翻译。我们构建了SpeechBSD数据集，并进行了基准实验。此外，我们认为上下文是这项任务中需要解决的一个重要方面，并提出了两种利用上下文的方法，即单语上下文和双语上下文。我们使用Whisper和mBART进行级联式语音翻译实验，并展示了双语上下文在我们的设置中表现更好。

    We present a new task, speech dialogue translation mediating speakers of different languages. We construct the SpeechBSD dataset for the task and conduct baseline experiments. Furthermore, we consider context to be an important aspect that needs to be addressed in this task and propose two ways of utilizing context, namely monolingual context and bilingual context. We conduct cascaded speech translation experiments using Whisper and mBART, and show that bilingual context performs better in our settings.
    
[^32]: 权重莫比乌斯分数：一个特征归因的统一框架

    The Weighted M\"obius Score: A Unified Framework for Feature Attribution. (arXiv:2305.09204v1 [cs.LG])

    [http://arxiv.org/abs/2305.09204](http://arxiv.org/abs/2305.09204)

    本文提出了权重莫比乌斯分数作为一个参数化的归因框架，可以涵盖很多不同的特征归因方法，包括特征交互，解决了方法繁衍和不可比的问题。通过研究方法的向量空间，提供了一些新方法和解释，实证结果表明其多功能性和有效性。

    

    特征归因旨在通过识别每个特征对预测的影响来解释黑盒模型预测的推理过程。最近的工作将特征归因扩展到多个特征之间的交互。然而，缺乏统一的框架导致方法的大量繁衍，这些方法通常不能直接比较。本文介绍了一种参数化的归因框架——权重莫比乌斯分数，并显示了许多不同的针对单个特征和特征交互的归因方法是特例，还验证了一些新方法。通过研究归因方法的向量空间，我们的框架利用标准线性代数工具，并在各个领域提供解释，包括合作博弈理论和因果中介分析。我们通过将这些归因方法应用于情感分析中的特征交互来实证了框架的多功能性和有效性。

    Feature attribution aims to explain the reasoning behind a black-box model's prediction by identifying the impact of each feature on the prediction. Recent work has extended feature attribution to interactions between multiple features. However, the lack of a unified framework has led to a proliferation of methods that are often not directly comparable. This paper introduces a parameterized attribution framework -- the Weighted M\"obius Score -- and (i) shows that many different attribution methods for both individual features and feature interactions are special cases and (ii) identifies some new methods. By studying the vector space of attribution methods, our framework utilizes standard linear algebra tools and provides interpretations in various fields, including cooperative game theory and causal mediation analysis. We empirically demonstrate the framework's versatility and effectiveness by applying these attribution methods to feature interactions in sentiment analysis and chain-
    
[^33]: 信息抽取的易学难学学习方法

    Easy-to-Hard Learning for Information Extraction. (arXiv:2305.09193v1 [cs.CL])

    [http://arxiv.org/abs/2305.09193](http://arxiv.org/abs/2305.09193)

    本文提出了一种易学难学的信息抽取学习框架，分为入门、困难和主阶段，模仿人类学习过程，通过分阶段学习提高模型泛化能力。

    

    信息抽取是指从非结构化文本中自动提取出命名实体、实体关系和事件等结构化信息的系统。本文提出了一种模仿人类学习过程的易学难学框架，分为三个阶段：入门阶段、困难阶段和主阶段。通过分阶段学习，我们的框架促进了模型获得更广泛的信息抽取任务知识，并提高了其泛化能力。在四个信息抽取任务上进行了大量实验，证明了我们框架的有效性。

    Information extraction (IE) systems aim to automatically extract structured information, such as named entities, relations between entities, and events, from unstructured texts. While most existing work addresses a particular IE task, universally modeling various IE tasks with one model has achieved great success recently. Despite their success, they employ a one-stage learning strategy, i.e., directly learning to extract the target structure given the input text, which contradicts the human learning process. In this paper, we propose a unified easy-to-hard learning framework consisting of three stages, i.e., the easy stage, the hard stage, and the main stage, for IE by mimicking the human learning process. By breaking down the learning process into multiple stages, our framework facilitates the model to acquire general IE task knowledge and improve its generalization ability. Extensive experiments across four IE tasks demonstrate the effectiveness of our framework. We achieve new stat
    
[^34]: 迭代翻译：使用中间序列来提高神经机器翻译的领域鲁棒性

    Progressive Translation: Improving Domain Robustness of Neural Machine Translation with Intermediate Sequences. (arXiv:2305.09154v1 [cs.CL])

    [http://arxiv.org/abs/2305.09154](http://arxiv.org/abs/2305.09154)

    该论文提出了使用中间序列来提高神经机器翻译的领域鲁棒性的方法，并通过全排列多任务学习和最小贝叶斯风险译码算法进一步提高了模型性能。

    

    先前的研究表明，中间监督信号有助于各种自然语言处理任务。然而，目前尚不清楚是否存在有助于神经机器翻译（NMT）的中间信号。借鉴统计机器翻译技术，我们提出了中间信号，即从“源语言”结构到“目标语言”结构的中间序列。这种中间序列引入了一个归纳偏置，反映了一种领域无关的翻译原则，可以减少有害于跨领域泛化的虚假相关性。此外，我们引入了全排列多任务学习，以减轻由暴露偏差引起的中间序列对目标的虚假因果关系。使用最小贝叶斯风险译码算法从所有排列中选择最佳候选翻译进一步提高性能。实验表明，引入的中间信号显著提高了NMT模型跨不同领域的鲁棒性，并减小了内部和外部翻译之间的性能差距。

    Previous studies show that intermediate supervision signals benefit various Natural Language Processing tasks. However, it is not clear whether there exist intermediate signals that benefit Neural Machine Translation (NMT). Borrowing techniques from Statistical Machine Translation, we propose intermediate signals which are intermediate sequences from the "source-like" structure to the "target-like" structure. Such intermediate sequences introduce an inductive bias that reflects a domain-agnostic principle of translation, which reduces spurious correlations that are harmful to out-of-domain generalisation. Furthermore, we introduce a full-permutation multi-task learning to alleviate the spurious causal relations from intermediate sequences to the target, which results from exposure bias. The Minimum Bayes Risk decoding algorithm is used to pick the best candidate translation from all permutations to further improve the performance. Experiments show that the introduced intermediate signa
    
[^35]: 双重对齐预训练用于跨语言句子嵌入

    Dual-Alignment Pre-training for Cross-lingual Sentence Embedding. (arXiv:2305.09148v1 [cs.CL])

    [http://arxiv.org/abs/2305.09148](http://arxiv.org/abs/2305.09148)

    该论文提出了一个双重对齐预训练框架，用于跨语言句子嵌入，它结合了句子级别和标记级别的对齐。引入了一种表示翻译学习任务，从而将翻译信息嵌入标记表示中。

    

    最近的研究表明，使用句子级别翻译排名任务训练的双编码器模型是跨语言句子嵌入的有效方法。然而，我们的研究表明，在多语言场景中，标记级别的对齐也是至关重要的，但此前尚未完全探索这一问题。基于我们的发现，我们提出了一个双重对齐预训练（DAP）框架，用于跨语言句子嵌入，它结合了句子级别和标记级别的对齐。为此，我们引入了一种新颖的表示翻译学习（RTL）任务，其中模型学习使用单侧上下文化的标记表示来重建其翻译对应物。这种重建目标鼓励模型将翻译信息嵌入标记表示中。与其他标记级别对齐方法（如翻译语言模型）相比，RTL更适合双编码器体系结构，而且计算效率更高。

    Recent studies have shown that dual encoder models trained with the sentence-level translation ranking task are effective methods for cross-lingual sentence embedding. However, our research indicates that token-level alignment is also crucial in multilingual scenarios, which has not been fully explored previously. Based on our findings, we propose a dual-alignment pre-training (DAP) framework for cross-lingual sentence embedding that incorporates both sentence-level and token-level alignment. To achieve this, we introduce a novel representation translation learning (RTL) task, where the model learns to use one-side contextualized token representation to reconstruct its translation counterpart. This reconstruction objective encourages the model to embed translation information into the token representation. Compared to other token-level alignment methods such as translation language modeling, RTL is more suitable for dual encoder architectures and is computationally efficient. Extensive
    
[^36]: 记忆还是忘却？深入探讨语言模型的知识记忆机制

    Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism of Language Models. (arXiv:2305.09144v1 [cs.CL])

    [http://arxiv.org/abs/2305.09144](http://arxiv.org/abs/2305.09144)

    本论文研究了语言模型的记忆机制，发现预训练可以有效提高模型的记忆能力，而知识相关性和多样性对于记忆形成也有显著影响。

    

    记忆是最基本的认知功能之一，是存储世界知识和活动经历的储藏库。近年来，大规模预训练语言模型展现出卓越的记忆能力。相反，没有预训练的神经网络长期以来一直存在灾难性遗忘问题。为了研究这种保持-遗忘的矛盾并了解语言模型的记忆机制，我们通过控制目标知识类型、学习策略和学习时间表等，开展了深入的实验研究。结果发现：1）传统语言模型是容易遗忘的；2）预训练可以使语言模型具有记忆能力；3）知识相关性和多样性显著影响记忆形成。这些结论有助于理解预训练语言模型的能力，并为设计和评估新的语言模型学习方法和推理算法提供了启示。

    Memory is one of the most essential cognitive functions serving as a repository of world knowledge and episodes of activities. In recent years, large-scale pre-trained language models have shown remarkable memorizing ability. On the contrary, vanilla neural networks without pre-training have been long observed suffering from the catastrophic forgetting problem. To investigate such a retentive-forgetful contradiction and understand the memory mechanism of language models, we conduct thorough experiments by controlling the target knowledge types, the learning strategies and the learning schedules. We find that: 1) Vanilla language models are forgetful; 2) Pre-training leads to retentive language models; 3) Knowledge relevance and diversification significantly influence the memory formation. These conclusions are useful for understanding the abilities of pre-trained language models and shed light on designing and evaluating new learning and inference algorithms of language models.
    
[^37]: 视频值得 $n\times n$ 张图像吗? 一种基于Transformer的视频问答高效方法。

    Is a Video worth $n\times n$ Images? A Highly Efficient Approach to Transformer-based Video Question Answering. (arXiv:2305.09107v1 [cs.CV])

    [http://arxiv.org/abs/2305.09107](http://arxiv.org/abs/2305.09107)

    本文提出了一种高效的Transformer-based Video Question Answering方法，即将视频帧连接成 $n\times n$ 的矩阵，从而将图像编码器的使用量从 $n^{2}$ 减少到1，从而显著提高了训练和推理速度和节省了存储空间，而仍然保持了原始视频的时间结构，并在实验中取得了较好结果。

    

    传统的基于Transformer的视频问答（VideoQA）方法通常通过一个或多个图像编码器独立编码帧，并在帧和问题之间进行交互。然而，这种模式会导致显著的内存使用和训练和推理速度的不可避免的减慢。本文提出了一种基于现有视觉-语言预训练模型的高效VideoQA方法，其中我们将视频帧连接到一个 $n\times n$ 矩阵中，然后将其转换为一张图像。通过这样做，我们将图像编码器的使用从 $n^{2}$减少到1，同时保持了原始视频的时间结构。在MSRVTT和TrafficQA上的实验结果表明，我们提出的方法以近 $4\times$ 更快的速度和只有30％的内存使用实现了最先进的性能。我们展示了通过将我们的方法集成到VideoQA系统中，我们能够在只有很小代价的情况下实现可比甚至优异的表现，同时训练和推理速度显著加快。

    Conventional Transformer-based Video Question Answering (VideoQA) approaches generally encode frames independently through one or more image encoders followed by interaction between frames and question. However, such schema would incur significant memory use and inevitably slow down the training and inference speed. In this work, we present a highly efficient approach for VideoQA based on existing vision-language pre-trained models where we concatenate video frames to a $n\times n$ matrix and then convert it to one image. By doing so, we reduce the use of the image encoder from $n^{2}$ to $1$ while maintaining the temporal structure of the original video. Experimental results on MSRVTT and TrafficQA show that our proposed approach achieves state-of-the-art performance with nearly $4\times$ faster speed and only 30% memory use. We show that by integrating our approach into VideoQA systems we can achieve comparable, even superior, performance with a significant speed up for training and 
    
[^38]: 任务无关BERT压缩的权重继承蒸馏方法

    Weight-Inherited Distillation for Task-Agnostic BERT Compression. (arXiv:2305.09098v1 [cs.CL])

    [http://arxiv.org/abs/2305.09098](http://arxiv.org/abs/2305.09098)

    本文提出了一种直接从教师模型传递知识的权重继承蒸馏方法，不需要额外的对齐损失就可以训练出一个紧凑的学生模型，并且在GLUE和SQuAD基准测试上优于之前最先进的基于KD的基线。

    

    知识蒸馏（KD）是压缩BERT的主要方法。之前的KD方法侧重于为学生模型设计额外的对齐损失，以模仿教师模型的行为。这些方法以间接的方式传递知识。在本文中，我们提出了一种新颖的权重继承蒸馏（WID）方法，直接从教师模型传递知识。WID不需要额外的对齐损失，通过继承权重来训练一个紧凑的学生模型，展示了知识蒸馏的新视角。具体来说，我们将行压缩器和列压缩器设计为映射，然后通过结构重参数化压缩权重。在GLUE和SQuAD基准测试上的实验结果表明，WID优于之前最先进的基于KD的基线。进一步的分析表明，WID也可以在不需要注意力分布对齐损失的情况下学习教师模型的注意力模式。

    Knowledge Distillation (KD) is a predominant approach for BERT compression. Previous KD-based methods focus on designing extra alignment losses for the student model to mimic the behavior of the teacher model. These methods transfer the knowledge in an indirect way. In this paper, we propose a novel Weight-Inherited Distillation (WID), which directly transfers knowledge from the teacher. WID does not require any additional alignment loss and trains a compact student by inheriting the weights, showing a new perspective of knowledge distillation. Specifically, we design the row compactors and column compactors as mappings and then compress the weights via structural re-parameterization. Experimental results on the GLUE and SQuAD benchmarks show that WID outperforms previous state-of-the-art KD-based baselines. Further analysis indicates that WID can also learn the attention patterns from the teacher model without any alignment loss on attention distributions.
    
[^39]: SGP-TOD: 基于模式引导的LLM提示轻松构建任务机器人

    SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting. (arXiv:2305.09067v1 [cs.CL])

    [http://arxiv.org/abs/2305.09067](http://arxiv.org/abs/2305.09067)

    本文提出了一种基于模式引导的LLM提示SGP-TOD，用于轻松构建任务型对话系统，避免了训练数据的需求。实验证明，该方法在多个数据集上显著优于先进的基线方法。

    

    在对话研究中，轻松构建端到端任务机器人并以最小的人力投入维护其与新功能的集成是一个长期存在的挑战。最近，大型语言模型（LLM）在各种下游任务中展示了卓越的对话能力和遵循指令的能力。在这项工作中，我们介绍了SGP-TOD，一种基于LLM的模式引导提示，用于轻松构建面向任务的对话系统。利用符号知识--任务模式，我们指导固定的LLM在新任务上生成适当的响应，避免了训练数据的需求。具体而言，SGP-TOD包括三个组件：用于与用户交互的LLM，用于帮助LLM进行对话状态跟踪的DST提示器，以及用于引出符合提供的对话策略的适当响应的策略提示器。在Multiwoz、RADDLE和STAR数据集上的实验结果表明，我们的无需训练的策略显著优于几个最先进的基线。

    Building end-to-end task bots and maintaining their integration with new functionalities using minimal human efforts is a long-standing challenge in dialog research. Recently large language models (LLMs) have demonstrated exceptional proficiency in conversational engagement and adherence to instructions across various downstream tasks. In this work, we introduce SGP-TOD, Schema-Guided Prompting for building Task-Oriented Dialog systems effortlessly based on LLMs. Utilizing the symbolic knowledge -- task schema, we instruct fixed LLMs to generate appropriate responses on novel tasks, circumventing the need for training data. Specifically, SGP-TOD comprises three components: a LLM for engaging with users, a DST Prompter to aid the LLM with dialog state tracking, which is then used to retrieve database items, and a Policy Prompter to elicit proper responses adhering to the provided dialog policy. Experimental results on Multiwoz, RADDLE and STAR datasets show that our training-free strate
    
[^40]: 双方共舞：导航NLP任务的概念化和性能测量

    It Takes Two to Tango: Navigating Conceptualizations of NLP Tasks and Measurements of Performance. (arXiv:2305.09022v1 [cs.CL])

    [http://arxiv.org/abs/2305.09022](http://arxiv.org/abs/2305.09022)

    本文针对NLP的任务和性能测量提出了一种分歧分类方法，经过相关研究和调查，发现现有任务没有明确和一致的概念，基准存在操作化分歧，提出了解决基准争议的建议。

    

    自然语言处理（NLP）的进展越来越多地通过基准进行衡量；因此，了解从业者可能在基准的有效性上存在分歧的原因和时间需要对进展进行具体化。我们利用测量建模工具，开发了一种分歧分类方法，区分了两种类型的分歧：1）如何概念化任务；2）如何操作化模型性能的测量。为了提供支持我们分类的证据，我们进行了相关文献的元分析，以了解NLP任务的概念化，以及对影响基准有效性的不同因素印象的从业者的调查。我们对从核心参考解决到问答等八项任务的元分析和调查发现，任务通常没有明确和一致的概念，基准存在操作化分歧。这些发现支持了我们提出的分歧分类方法。最后，基于结果，我们提出了解决基准争议的建议。

    Progress in NLP is increasingly measured through benchmarks; hence, contextualizing progress requires understanding when and why practitioners may disagree about the validity of benchmarks. We develop a taxonomy of disagreement, drawing on tools from measurement modeling, and distinguish between two types of disagreement: 1) how tasks are conceptualized and 2) how measurements of model performance are operationalized. To provide evidence for our taxonomy, we conduct a meta-analysis of relevant literature to understand how NLP tasks are conceptualized, as well as a survey of practitioners about their impressions of different factors that affect benchmark validity. Our meta-analysis and survey across eight tasks, ranging from coreference resolution to question answering, uncover that tasks are generally not clearly and consistently conceptualized and benchmarks suffer from operationalization disagreements. These findings support our proposed taxonomy of disagreement. Finally, based on ou
    
[^41]: 帮助帮助者：通过 AI 强化实践和反馈来支持同侪辅导员。

    Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback. (arXiv:2305.08982v1 [cs.HC])

    [http://arxiv.org/abs/2305.08982](http://arxiv.org/abs/2305.08982)

    本论文介绍了一个基于AI的交互式工具CARE，用于支持同侪辅导员通过自动建议生成来提高他们的能力。利用 Motivational Interviewing 框架，CARE 在实际培训阶段帮助辅导员诊断哪种具体的辅导策略最合适，并提供个性化的响应示例作为建议。

    

    数百万用户来到在线同侪辅导平台寻求关于从关系压力到焦虑等多种主题的支持。然而，研究表明，在线同侪支持群体并不总是像预期的那样有效，这主要是由于用户与无用的辅导员产生了负面体验。同侪辅导员是在线同侪辅导平台成功的关键，但他们中的大多数通常没有系统地接收指导或监督的方式。在这项工作中，我们介绍 CARE：一个交互式的基于 AI 的工具，通过自动建议生成增强同侪辅导员的能力。在实际培训阶段，CARE 帮助诊断在给定情境下哪些具体的辅导策略最合适，并提供量身定制的示例响应作为建议。辅导员可以选择在回复求助者之前选择、修改或忽略任何建议。

    Millions of users come to online peer counseling platforms to seek support on diverse topics ranging from relationship stress to anxiety. However, studies show that online peer support groups are not always as effective as expected largely due to users' negative experiences with unhelpful counselors. Peer counselors are key to the success of online peer counseling platforms, but most of them often do not have systematic ways to receive guidelines or supervision. In this work, we introduce CARE: an interactive AI-based tool to empower peer counselors through automatic suggestion generation. During the practical training stage, CARE helps diagnose which specific counseling strategies are most suitable in the given context and provides tailored example responses as suggestions. Counselors can choose to select, modify, or ignore any suggestion before replying to the support seeker. Building upon the Motivational Interviewing framework, CARE utilizes large-scale counseling conversation data
    
[^42]: 黑盒语言模型生成的水印文本

    Watermarking Text Generated by Black-Box Language Models. (arXiv:2305.08883v1 [cs.CL])

    [http://arxiv.org/abs/2305.08883](http://arxiv.org/abs/2305.08883)

    本研究提出了一种利用Transformer注意力图来获得词级反馈的新型黑盒LLM水印算法，实现对由黑盒语言模型生成的文本的水印保护。

    

    LLM现在展示了在各领域中与人类类似的技能，引发人们对误用的担忧。因此，检测生成的文本至关重要。然而，被动式检测方法陷入了领域特异性和有限的对抗强度。为了实现可靠的检测，提出了一种基于水印的白盒LLM方法，使其能够在文本生成过程中嵌入水印。该方法涉及将模型词汇随机分割以获得特殊列表并调整概率分布以促进列表中单词的选择。一个知晓列表的检测算法可以识别带水印的文本。然而，这种方法在许多仅有黑盒语言模型的真实场景中不适用。为了允许第三方给由黑盒语言模型生成的文本加上水印，本文提出了一种利用转换器注意力图来获得词级反馈的新水印算法。实验结果表明，所提出的方法可以有效地给由黑盒语言模型生成的文本加上水印，而不影响文本生成的质量。

    LLMs now exhibit human-like skills in various fields, leading to worries about misuse. Thus, detecting generated text is crucial. However, passive detection methods are stuck in domain specificity and limited adversarial robustness. To achieve reliable detection, a watermark-based method was proposed for white-box LLMs, allowing them to embed watermarks during text generation. The method involves randomly dividing the model vocabulary to obtain a special list and adjusting the probability distribution to promote the selection of words in the list. A detection algorithm aware of the list can identify the watermarked text. However, this method is not applicable in many real-world scenarios where only black-box language models are available. For instance, third-parties that develop API-based vertical applications cannot watermark text themselves because API providers only supply generated text and withhold probability distributions to shield their commercial interests. To allow third-part
    
[^43]: 一种用于抽象多文档摘要的层次编码-解码方案

    A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document Summarization. (arXiv:2305.08503v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08503](http://arxiv.org/abs/2305.08503)

    本研究提出了一种用于抽象多文档摘要的层次编码-解码方案，在多领域的10个MDS数据集上测试表现最佳。

    

    预训练语言模型（PLM）在抽象单文档摘要（SDS）方面取得了显著的成就。但是，这种好处可能不会轻易扩展到多文档摘要（MDS），因为文档之间的交互更加复杂。以前的工作要么设计新的架构或新的预训练目标，用于MDS，要么将PLM应用于MDS，但未考虑到复杂的文档交互。本文中，我们在编码器和解码器上强制使用层次结构，并寻求更好地利用PLM促进MDS任务的多文档交互作用。我们在10个MDS数据集上测试我们的设计，这些数据集覆盖各种领域。广泛的实验表明，我们提出的方法在所有这些数据集上都能够实现持续改进，优于最先进的MDS方法。

    Pre-trained language models (PLMs) have accomplished impressive achievements in abstractive single-document summarization (SDS). However, such benefits may not be readily extended to muti-document summarization (MDS), where the interactions among documents are more complex. Previous works either design new architectures or new pre-training objectives for MDS, or apply PLMs to MDS without considering the complex document interactions. While the former does not make full use of previous pre-training efforts and may not generalize well across multiple domains, the latter cannot fully attend to the intricate relationships unique to MDS tasks. In this paper, we enforce hierarchy on both the encoder and decoder and seek to make better use of a PLM to facilitate multi-document interactions for the MDS task. We test our design on 10 MDS datasets across a wide range of domains. Extensive experiments show that our proposed method can achieve consistent improvements on all these datasets, outperf
    
[^44]: Text2Cohort: 自然语言队列发现对癌症影像数据共享平台的民主化

    Text2Cohort: Democratizing the NCI Imaging Data Commons with Natural Language Cohort Discovery. (arXiv:2305.07637v1 [cs.LG])

    [http://arxiv.org/abs/2305.07637](http://arxiv.org/abs/2305.07637)

    Text2Cohort是一个基于大语言模型的工具箱，可以将用户输入转化为IDC数据库查询，促进自然语言队列发现，减少研究人员查询IDC数据库的学习曲线，实现了癌症成像数据的民主化。

    

    影像数据共享平台(IDC)是一个基于云的数据库，为研究人员提供开放获取的癌症成像数据和分析工具，旨在促进医学成像研究中的协作。然而，由于其复杂和技术性质，查询IDC数据库以进行队列发现和访问成像数据对研究人员来说具有显著的学习曲线。我们开发了基于大语言模型（LLM）的Text2Cohort工具箱，通过提示工程将用户输入转化为IDC数据库查询，并将查询的响应返回给用户，以促进自然语言队列发现。此外，实现了自动校正以解决查询中的语法和语义错误，通过将错误传回模型进行解释和校正。我们对50个自然语言用户输入进行了Text2Cohort评估，范围从信息提取到队列发现。结果查询和输出由两位计算机科学家进行了确认。

    The Imaging Data Commons (IDC) is a cloud-based database that provides researchers with open access to cancer imaging data and tools for analysis, with the goal of facilitating collaboration in medical imaging research. However, querying the IDC database for cohort discovery and access to imaging data has a significant learning curve for researchers due to its complex and technical nature. We developed Text2Cohort, a large language model (LLM) based toolkit to facilitate natural language cohort discovery by translating user input into IDC database queries through prompt engineering and returning the query's response to the user. Furthermore, autocorrection is implemented to resolve syntax and semantic errors in queries by passing the errors back to the model for interpretation and correction. We evaluate Text2Cohort on 50 natural language user inputs ranging from information extraction to cohort discovery. The resulting queries and outputs were verified by two computer scientists to me
    
[^45]: QURG: 问题重写引导下的上下文依赖性文本到SQL语义解析

    QURG: Question Rewriting Guided Context-Dependent Text-to-SQL Semantic Parsing. (arXiv:2305.06655v1 [cs.CL])

    [http://arxiv.org/abs/2305.06655](http://arxiv.org/abs/2305.06655)

    QURG是一种帮助文本到SQL语义解析模型实现上下文理解的新颖方法，能在SParC和CoSQL等上下文依赖性数据集上提高模型性能，特别是对于难以处理和长轮次的问题。

    

    上下文依赖性文本到SQL的目标是将多轮自然语言问题翻译成SQL查询语句。本文提出了QURG，一种新颖的问题重写引导方法，以帮助模型实现足够的上下文理解。具体地，我们首先训练一个问题重写模型，在问题上下文的基础上完成当前问题，并将其转换为重写编辑矩阵。我们设计了一个双流矩阵编码器，来共同建模问题和上下文之间的重写关系，以及自然语言和结构化模式之间的模式链接关系。实验结果表明，QURG显著提高了两个大规模上下文依赖性数据集SParC和CoSQL的性能，特别是对于难以处理和长轮次的问题。

    Context-dependent Text-to-SQL aims to translate multi-turn natural language questions into SQL queries. Despite various methods have exploited context-dependence information implicitly for contextual SQL parsing, there are few attempts to explicitly address the dependencies between current question and question context. This paper presents QURG, a novel Question Rewriting Guided approach to help the models achieve adequate contextual understanding. Specifically, we first train a question rewriting model to complete the current question based on question context, and convert them into a rewriting edit matrix. We further design a two-stream matrix encoder to jointly model the rewriting relations between question and context, and the schema linking relations between natural language and structured schema. Experimental results show that QURG significantly improves the performances on two large-scale context-dependent datasets SParC and CoSQL, especially for hard and long-turn questions.
    
[^46]: 机器人还是人类？用一个问题检测ChatGPT冒名顶替者

    Bot or Human? Detecting ChatGPT Imposters with A Single Question. (arXiv:2305.06424v1 [cs.CL])

    [http://arxiv.org/abs/2305.06424](http://arxiv.org/abs/2305.06424)

    本文提出了一个名为FLAIR的框架，通过一个问题和回答来检测ChatGPT中的聊天机器人真实性，可以分类人和机器人。单问题分为对于人类而言容易但对于机器人很难和对于机器人而言容易但对于人类很难两个类别，分别进行检测。 在多个数据集上实现了最先进的性能。

    

    大型语言模型如ChatGPT最近展示了令人瞩目的自然语言理解和生成能力，使得翻译、写作和闲聊等各种应用成为可能。然而，人们担心它们可能被滥用于欺诈或拒绝服务攻击等恶意用途。因此，开发检测聊天中涉及的另一方是机器人还是人类的方法至关重要。本文提出了一个名为FLAIR的框架，即通过单个问题和回答来查找大型语言模型的真实性，以在线方式检测会话中的对话机器人。具体而言，我们针对一个单一问题场景，该场景可以有效地区分人类用户和机器人。这些问题分为两类：对于人类而言容易但对于机器人很难（例如计数、替换、定位、噪音过滤和ASCII艺术），以及对于机器人而言容易但对于人类很难（例如机器生成文本识别）。我们在多个基准数据集上评估了FLAIR，并在机器人检测方面实现了最先进的性能。

    Large language models like ChatGPT have recently demonstrated impressive capabilities in natural language understanding and generation, enabling various applications including translation, essay writing, and chit-chatting. However, there is a concern that they can be misused for malicious purposes, such as fraud or denial-of-service attacks. Therefore, it is crucial to develop methods for detecting whether the party involved in a conversation is a bot or a human. In this paper, we propose a framework named FLAIR, Finding Large language model Authenticity via a single Inquiry and Response, to detect conversational bots in an online manner. Specifically, we target a single question scenario that can effectively differentiate human users from bots. The questions are divided into two categories: those that are easy for humans but difficult for bots (e.g., counting, substitution, positioning, noise filtering, and ASCII art), and those that are easy for bots but difficult for humans (e.g., m
    
[^47]: K-UniMorph：韩语通用词形学及其特征模式

    K-UniMorph: Korean Universal Morphology and its Feature Schema. (arXiv:2305.06335v1 [cs.CL])

    [http://arxiv.org/abs/2305.06335](http://arxiv.org/abs/2305.06335)

    本文介绍了一种韩语通用词形学数据集，保留韩语特色并采用Sylak-Glassman等人的词形特征模式，为韩语形态学范式领域做出了贡献。

    

    本文介绍了一种韩语通用词形学数据集，之前，韩语在数百种多样的世界语言中的形态学范式领域中一直处于少数。因此，我们提出了这种保留韩语特色的通用词形学范式。我们的K-UniMorph数据集中，我们详细概述了每个语法标准的动词结尾，并阐明如何提取变形形式以及如何生成词形模式。此数据集采用Sylak-Glassman等人（2015）和Sylak-Glassman（2016）的词形特征模式，而我们从Sejong形态分析语料库中提取变形形式，这是韩语最大的注释语料库之一。在数据创建过程中，我们的方法还包括调查从Sejong语料库中的转换的正确性。此外，我们使用三种不同的模型进行了变形任务。

    We present in this work a new Universal Morphology dataset for Korean. Previously, the Korean language has been underrepresented in the field of morphological paradigms amongst hundreds of diverse world languages. Hence, we propose this Universal Morphological paradigms for the Korean language that preserve its distinct characteristics. For our K-UniMorph dataset, we outline each grammatical criterion in detail for the verbal endings, clarify how to extract inflected forms, and demonstrate how we generate the morphological schemata. This dataset adopts morphological feature schema from Sylak-Glassman et al. (2015) and Sylak-Glassman (2016) for the Korean language as we extract inflected verb forms from the Sejong morphologically analyzed corpus that is one of the largest annotated corpora for Korean. During the data creation, our methodology also includes investigating the correctness of the conversion from the Sejong corpus. Furthermore, we carry out the inflection task using three di
    
[^48]: 统一的上下文学习演示检索器

    Unified Demonstration Retriever for In-Context Learning. (arXiv:2305.04320v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04320](http://arxiv.org/abs/2305.04320)

    本文提出了一种统一的演示检索器UDR，可用于广泛的任务检索演示，在训练时使用语言模型的反馈来将各种任务的训练信号转换为统一的列表排序公式。

    

    上下文学习是一种新的学习范式，其中语言模型在少量输入-输出对（演示）和测试输入的条件下，直接输出预测结果。研究表明它高度依赖于提供的演示，并促进了演示检索的研究：根据测试输入从训练集中检索相关示例，为上下文学习提供信息丰富的演示。本文提出了统一的演示检索器（UDR），用于为广泛的任务检索演示；通过使用语言模型的反馈将各种任务的训练信号转换为统一的列表排序公式来训练UDR。

    In-context learning is a new learning paradigm where a language model conditions on a few input-output pairs (demonstrations) and a test input, and directly outputs the prediction. It has been shown highly dependent on the provided demonstrations and thus promotes the research of demonstration retrieval: given a test input, relevant examples are retrieved from the training set to serve as informative demonstrations for in-context learning. While previous works focus on training task-specific retrievers for several tasks separately, these methods are often hard to transfer and scale on various tasks, and separately trained retrievers incur a lot of parameter storage and deployment cost. In this paper, we propose Unified Demonstration Retriever (\textbf{UDR}), a single model to retrieve demonstrations for a wide range of tasks. To train UDR, we cast various tasks' training signals into a unified list-wise ranking formulation by language model's feedback. Then we propose a multi-task list
    
[^49]: 自适应宽松优化用于强韧问答系统

    Adaptive loose optimization for robust question answering. (arXiv:2305.03971v1 [cs.CL])

    [http://arxiv.org/abs/2305.03971](http://arxiv.org/abs/2305.03971)

    本论文提出了一种简单而有效的自适应宽松优化损失函数，用于为问答系统综合内外分布的最佳表现，并显示了对对抗攻击的强韧性。

    

    问答方法以利用数据偏差为特点，如视觉问答中的语言先验和机器阅读理解（抽取式问答）中的位置偏差。目前的去偏方法往往以在分布内表现不佳为代价获得有利的分布外泛化能力，而不去偏方法则在获得高分布内表现的同时牺牲了相当数量的分布外表现。因此，它们难以应对复杂变化的现实世界情况。本文提出了一种简单而有效的新型自适应宽松优化损失函数，为问答系统综合两者最佳表现而努力。我们的主要技术贡献是根据小批量训练数据上先前和当前优化状态之间的比率自适应地减少损失。这种宽松优化可以用来防止非凸优化陷入局部最小值，并帮助模型学习更好的表示。实验证明，我们的方法在各种基准测试中与最先进的方法具有竞争性能，同时表现出对对抗性攻击的强韧性。

    Question answering methods are well-known for leveraging data bias, such as the language prior in visual question answering and the position bias in machine reading comprehension (extractive question answering). Current debiasing methods often come at the cost of significant in-distribution performance to achieve favorable out-of-distribution generalizability, while non-debiasing methods sacrifice a considerable amount of out-of-distribution performance in order to obtain high in-distribution performance. Therefore, it is challenging for them to deal with the complicated changing real-world situations. In this paper, we propose a simple yet effective novel loss function with adaptive loose optimization, which seeks to make the best of both worlds for question answering. Our main technical contribution is to reduce the loss adaptively according to the ratio between the previous and current optimization state on mini-batch training data. This loose optimization can be used to prevent non
    
[^50]: LMs固守阵地：探究具身化对语言模型理解比喻性语言的影响

    LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models. (arXiv:2305.03445v1 [cs.CL])

    [http://arxiv.org/abs/2305.03445](http://arxiv.org/abs/2305.03445)

    本文研究调查了具身化策略对语言模型解释比喻性语言的影响。结果表明，更大的模型在处理行为更具体化的隐喻性句子时表现更佳。

    

    比喻语言是语言模型的挑战，因为其解释基于单词的使用方式偏离了它们的常规顺序和含义。然而，人类可以轻松理解和诠释隐喻、比喻或习语，因为它们可以从具身隐喻中推导出来。语言是具身化的代理，如果隐喻是传统的和词汇化的，那么一个没有身体的系统就更容易理解具身概念。本文研究表明，在比喻性句子的行动更具体化时，更大的语言模型在解释隐喻句子时表现更好，并排除了与其他特征（例如单词长度或具体性）的多重共线性。

    Figurative language is a challenge for language models since its interpretation is based on the use of words in a way that deviates from their conventional order and meaning. Yet, humans can easily understand and interpret metaphors, similes or idioms as they can be derived from embodied metaphors. Language is a proxy for embodiment and if a metaphor is conventional and lexicalised, it becomes easier for a system without a body to make sense of embodied concepts. Yet, the intricate relation between embodiment and features such as concreteness or age of acquisition has not been studied in the context of figurative language interpretation concerning language models. Hence, the presented study shows how larger language models perform better at interpreting metaphoric sentences when the action of the metaphorical sentence is more embodied. The analysis rules out multicollinearity with other features (e.g. word length or concreteness) and provides initial evidence that larger language model
    
[^51]: 大语言模型在信息技术任务中自动生成YAML代码

    Automated Code generation for Information Technology Tasks in YAML through Large Language Models. (arXiv:2305.02783v1 [cs.SE])

    [http://arxiv.org/abs/2305.02783](http://arxiv.org/abs/2305.02783)

    这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。

    

    由于大语言模型在代码生成方面的不断提升，在通用编程语言方面的受益最大，而针对IT自动化等领域特定语言的研究较少。本研究聚焦于Ansible-YAML的生成，提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，旨在提高IT自动化生产力。研究采用基于Transformer的模型，并通过新的包含Ansible-YAML的数据集进行扩展训练。同时，还开发了两个用于捕捉此领域特征的YAML和Ansible性能指标。结果表明，Ansible Wisdom可以精确地从自然语言提示中生成Ansible脚本，并且其性能可与现有技术的状态相媲美或更好。

    The recent improvement in code generation capabilities due to the use of large language models has mainly benefited general purpose programming languages. Domain specific languages, such as the ones used for IT Automation, have received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible-YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible-YAML code generation tool, aimed at improving IT automation productivity. Ansible Wisdom is a transformer-based model, extended by training with a new dataset containing Ansible-YAML. We also develop two novel performance metrics for YAML and Ansible to capture the specific characteristics of this domain. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code 
    
[^52]: GPT-2是如何计算大于符号的？解释预训练语言模型中的数学能力

    How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v1 [cs.CL])

    [http://arxiv.org/abs/2305.00586](http://arxiv.org/abs/2305.00586)

    本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。

    

    预训练语言模型在未被明确训练的任务上表现出惊人的能力，但它们如何实现这些功能却不为人所知。本文通过机械式可解释性技术探究预训练语言模型通常具有的基本数学能力。具体来说，我们以GPT-2 Small为例，研究其能否通过输入"战争持续时间是从1732年到17年"，预测出有效的两位数字的截止年份 (大于32年)。我们首先确定了一个电路，即GPT-2 Small计算图的一个小子集，用于计算这个任务的输出，然后我们解释了每个电路组件的作用，显示出GPT-2 Small的最终多层感知器提高了结束年份大于开始年份的概率。最后，我们证明了我们的电路适用于其他任务，在其他大于场景中发挥作用。

    Pre-trained language models can be surprisingly adept at tasks they were not explicitly trained on, but how they implement these capabilities is poorly understood. In this paper, we investigate the basic mathematical abilities often acquired by pre-trained language models. Concretely, we use mechanistic interpretability techniques to explain the (limited) mathematical abilities of GPT-2 small. As a case study, we examine its ability to take in sentences such as "The war lasted from the year 1732 to the year 17", and predict valid two-digit end years (years > 32). We first identify a circuit, a small subset of GPT-2 small's computational graph that computes this task's output. Then, we explain the role of each circuit component, showing that GPT-2 small's final multi-layer perceptrons boost the probability of end years greater than the start year. Finally, we show that our circuit generalizes to other tasks, playing a role in other greater-than scenarios.
    
[^53]: GeneGPT: 教授大型语言模型使用NCBI Web API

    GeneGPT: Teaching Large Language Models to Use NCBI Web APIs. (arXiv:2304.09667v1 [cs.CL])

    [http://arxiv.org/abs/2304.09667](http://arxiv.org/abs/2304.09667)

    GeneGPT通过少量NCBI API调用URL请求作为演示，教授大型语言模型使用NCBI Web API回答基因组问题，并在GeneTuring测试中达到了优异的结果。

    

    本文介绍了GeneGPT，一种新颖的方法，用于教授大型语言模型（LLM）使用国家生物技术信息中心（NCBI）的Web应用程序编程接口（API），并回答基因组问题。具体而言，我们通过少量的NCBI API调用URL请求作为上下文学习的演示，启发Codex（code-davinci-002）解决GeneTuring测试。在推理过程中，一旦检测到调用请求，我们就停止解码并使用生成的URL进行API调用。我们然后将NCBI API返回的原始执行结果附加到生成的文本中，并继续生成直到找到答案或检测到另一个API调用。初步结果表明，GeneGPT在GeneTuring数据集的四个One-shot任务中取得了三个最先进的结果，在五个Zero-shot任务中取得了四个最先进的结果。总体而言，GeneGPT的宏平均分数为0.76，远高于检索增强LLM，如New Bin。

    In this paper, we present GeneGPT, a novel method for teaching large language models (LLMs) to use the Web Application Programming Interfaces (APIs) of the National Center for Biotechnology Information (NCBI) and answer genomics questions. Specifically, we prompt Codex (code-davinci-002) to solve the GeneTuring tests with few-shot URL requests of NCBI API calls as demonstrations for in-context learning. During inference, we stop the decoding once a call request is detected and make the API call with the generated URL. We then append the raw execution results returned by NCBI APIs to the generated texts and continue the generation until the answer is found or another API call is detected. Our preliminary results show that GeneGPT achieves state-of-the-art results on three out of four one-shot tasks and four out of five zero-shot tasks in the GeneTuring dataset. Overall, GeneGPT achieves a macro-average score of 0.76, which is much higher than retrieval-augmented LLMs such as the New Bin
    
[^54]: 论ChatGPT和情感增强提示在心理健康分析中的评估

    On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis. (arXiv:2304.03347v1 [cs.CL])

    [http://arxiv.org/abs/2304.03347](http://arxiv.org/abs/2304.03347)

    本文全面评估了ChatGPT在心理健康分析和情感推理方面的表现，以及不同提示策略和情感信息对其性能的影响。结果显示，ChatGPT在心理健康分析方面表现良好，加入情感增强提示对某些任务效果显著。

    

    自动化心理健康分析显示出提高心理健康护理效率和可访问性的巨大潜力，而最近的主流方法利用预训练的语言模型(PLMs)作为骨干，并融入情感信息。最新的大型语言模型(LLMs)，如ChatGPT，在各种自然语言处理任务上表现出惊人的能力。然而，现有的ChatGPT零-shot性能研究在不充分的评估、情感信息利用和方法可解释性方面存在局限性。本文全面评估了ChatGPT在11个数据集上的心理健康分析和情感推理能力，涵盖了5个任务，包括二进制和多类心理健康状况检测、心理健康状况的原因/因素检测、对话中的情绪识别和因果情感蕴含。我们在实证分析中探究了不同提示策略以及情感增强提示对ChatGPT性能的影响。结果表明，ChatGPT在心理健康分析中有着良好的表现，并且在某些任务中加入情感增强提示效果显著。

    Automated mental health analysis shows great potential for enhancing the efficiency and accessibility of mental health care, whereas the recent dominant methods utilized pre-trained language models (PLMs) as the backbone and incorporated emotional information. The latest large language models (LLMs), such as ChatGPT, exhibit dramatic capabilities on diverse natural language processing tasks. However, existing studies on ChatGPT's zero-shot performance for mental health analysis have limitations in inadequate evaluation, utilization of emotional information, and explainability of methods. In this work, we comprehensively evaluate the mental health analysis and emotional reasoning ability of ChatGPT on 11 datasets across 5 tasks, including binary and multi-class mental health condition detection, cause/factor detection of mental health conditions, emotion recognition in conversations, and causal emotion entailment. We empirically analyze the impact of different prompting strategies with 
    
[^55]: 重新发现基于哈希的随机投影，用于有效量化上下文化句子嵌入

    Rediscovering Hashed Random Projections for Efficient Quantization of Contextualized Sentence Embeddings. (arXiv:2304.02481v1 [cs.CL])

    [http://arxiv.org/abs/2304.02481](http://arxiv.org/abs/2304.02481)

    本文提出了一种有效的方法，使用哈希随机投影和量化技术有效量化上下文化句子嵌入，以降低存储空间的开销，并可以用于在多种英语和德语句子分类任务上训练模型。

    

    由于计算能力的限制，对边缘设备进行训练和推断通常需要高效的设置。尽管预先计算数据表示并在服务器上缓存可以减少边缘设备的计算量，但这会带来两个挑战。首先，存储在服务器上所需的存储量随实例数量呈线性增长。其次，需要发送大量数据的带宽到边缘设备。为了减少预先计算的数据表示的存储空间开销，我们提出了一种简单但有效的方法，即使用随机初始化的超平面投影。为了将它们的大小进一步缩小至98.96％，我们将得到的浮点表示量化为二进制向量。尽管大小大大缩小，但我们表明这些嵌入对多种保留了94％-99％浮点值的英语和德语句子分类任务训练模型仍然有效。

    Training and inference on edge devices often requires an efficient setup due to computational limitations. While pre-computing data representations and caching them on a server can mitigate extensive edge device computation, this leads to two challenges. First, the amount of storage required on the server that scales linearly with the number of instances. Second, the bandwidth required to send extensively large amounts of data to an edge device. To reduce the memory footprint of pre-computed data representations, we propose a simple, yet effective approach that uses randomly initialized hyperplane projections. To further reduce their size by up to 98.96%, we quantize the resulting floating-point representations into binary vectors. Despite the greatly reduced size, we show that the embeddings remain effective for training models across various English and German sentence classification tasks that retain 94%--99% of their floating-point.
    
[^56]: SemiMemes：一种用于多模态Memes分析的半监督学习方法

    SemiMemes: A Semi-supervised Learning Approach for Multimodal Memes Analysis. (arXiv:2304.00020v1 [cs.LG])

    [http://arxiv.org/abs/2304.00020](http://arxiv.org/abs/2304.00020)

    研究提出了一种利用多模态数据的半监督学习方法，命名为SemiMemes，主要应用于Memes的分析和注释过程。该方法在多个数据集中表现优异，并优于其他最新的多模态半监督学习和监督学习模型。

    

    社交媒体上Memes的普及性引发了分析其隐含含义、审查有害内容的需求。机器学习的Meme审查系统需要半监督学习解决方案，以利用互联网上大量未标记的Memes，并使注释过程变得更简单。此外，该方法需要利用多模态数据，因为Memes的含义通常来自图像和文本。该研究提出了一种多模态半监督学习方法，在两个数据集，即多媒体自动性别歧视识别和令人讨厌的Memes数据集上，优于其他多模态半监督和监督学习的最新模型。借鉴对比语言-图像预训练所获得的见解，这项研究引入了SemiMemes，一种新颖的训练方法，它结合了自编码器和分类任务

    The prevalence of memes on social media has created the need to sentiment analyze their underlying meanings for censoring harmful content. Meme censoring systems by machine learning raise the need for a semi-supervised learning solution to take advantage of the large number of unlabeled memes available on the internet and make the annotation process less challenging. Moreover, the approach needs to utilize multimodal data as memes' meanings usually come from both images and texts. This research proposes a multimodal semi-supervised learning approach that outperforms other multimodal semi-supervised learning and supervised learning state-of-the-art models on two datasets, the Multimedia Automatic Misogyny Identification and Hateful Memes dataset. Building on the insights gained from Contrastive Language-Image Pre-training, which is an effective multimodal learning technique, this research introduces SemiMemes, a novel training method that combines auto-encoder and classification task to
    
[^57]: 利用ChatGPT进行零样本临床实体识别

    Zero-shot Clinical Entity Recognition using ChatGPT. (arXiv:2303.16416v1 [cs.CL])

    [http://arxiv.org/abs/2303.16416](http://arxiv.org/abs/2303.16416)

    本研究探讨了使用 ChatGPT 进行零样本临床实体识别任务，并发现 ChatGPT 在松弛匹配 F1 分数方面显著优于 GPT-3。虽然其性能仍低于 BioClinicalBERT 模型，但我们的研究表明了 ChatGPT 在零样本设置下有很大的临床 NER 任务潜力。

    

    本研究探讨了OpenAI开发的大型语言模型ChatGPT在2010年i2b2挑战中指定的临床命名实体识别任务中的潜力，使用两种不同的提示策略进行了零样本设置。同时，我们将其性能与GPT-3在类似的零样本设置下进行了比较，以及使用MTSamples的一组合成的临床笔记对BioClinicalBERT模型进行优化微调。研究结果显示，ChatGPT在零样本设置中表现优异，精确匹配和松弛匹配的F1分别为0.418（vs.0.250）和0.620（vs.0.480），相比之下，GPT-3的表现较差。另外，提示策略极大地影响了ChatGPT的性能，在两种不同提示策略下松弛匹配的F1分别为0.628和0.541。虽然ChatGPT的性能仍低于受监督的BioClinicalBERT模型（即松弛匹配F1分数分别为0.628和0.870），但我们的研究表明了ChatGPT在零样本设置下临床NER任务中的巨大潜力。

    In this study, we investigated the potential of ChatGPT, a large language model developed by OpenAI, for the clinical named entity recognition task defined in the 2010 i2b2 challenge, in a zero-shot setting with two different prompt strategies. We compared its performance with GPT-3 in a similar zero-shot setting, as well as a fine-tuned BioClinicalBERT model using a set of synthetic clinical notes from MTSamples. Our findings revealed that ChatGPT outperformed GPT-3 in the zero-shot setting, with F1 scores of 0.418 (vs.0.250) and 0.620 (vs. 0.480) for exact- and relaxed-matching, respectively. Moreover, prompts affected ChatGPT's performance greatly, with relaxed-matching F1 scores of 0.628 vs.0.541 for two different prompt strategies. Although ChatGPT's performance was still lower than that of the supervised BioClinicalBERT model (i.e., relaxed-matching F1 scores of 0.628 vs. 0.870), our study demonstrates the great potential of ChatGPT for clinical NER tasks in a zero-shot setting, 
    
[^58]: 部分动员：跟踪俄罗斯媒体和电报之间的多语言信息流

    Partial Mobilization: Tracking Multilingual Information Flows Amongst Russian Media Outlets and Telegram. (arXiv:2301.10856v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2301.10856](http://arxiv.org/abs/2301.10856)

    本文研究了16个俄罗斯媒体机构和732个电报频道之间的互动，发现新闻媒体不仅通过电报传播现有的叙事，而且会从电报平台源材料，研究结果表明2.3％至26.7％的文章将主题归因于电报活动。

    

    在俄罗斯入侵乌克兰后，针对俄罗斯在线媒体的虚假信息和宣传，包括俄罗斯之声和卫星新闻在内的俄罗斯媒体在欧洲遭到禁止。为了保持观众数量，许多俄罗斯媒体开始在电报等消息服务上大力宣传其内容。在这项工作中，我们研究了2022年期间16家俄罗斯媒体机构如何与732个电报频道互动和利用。利用基础模型MPNet、DP-means聚类和Hawkes过程，我们跟踪新闻网站和电报频道之间的叙事传播情况。我们表明，新闻媒体不仅通过电报传播现有的叙事，而且他们会从电报平台源材料。在我们研究的网站中，2.3％（ura.news）至26.7％（ukraina.ru）的文章讨论了源于/导致电报活动的内容。最后，通过跟踪个别主题的扩散，我们测量新闻网站发表文章的速率。

    In response to disinformation and propaganda from Russian online media following the Russian invasion of Ukraine, Russian outlets including Russia Today and Sputnik News were banned throughout Europe. To maintain viewership, many of these Russian outlets began to heavily promote their content on messaging services like Telegram. In this work, we study how 16 Russian media outlets interacted with and utilized 732 Telegram channels throughout 2022. Leveraging the foundational model MPNet, DP-means clustering, and Hawkes Processes, we trace how narratives spread between news sites and Telegram channels. We show that news outlets not only propagate existing narratives through Telegram, but that they source material from the messaging platform. Across the sites in our study, between 2.3% (ura.news) and 26.7% (ukraina.ru) of articles discuss content that originated/resulted from activity on Telegram. Finally, tracking the spread of individual topics, we measure the rate at which news website
    
[^59]: tasksource：流畅的NLP多任务学习和评估的数据集协调框架

    tasksource: A Dataset Harmonization Framework for Streamlined NLP Multi-Task Learning and Evaluation. (arXiv:2301.05948v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.05948](http://arxiv.org/abs/2301.05948)

    tasksource是一个数据集协调框架，为多任务学习和评估提供流畅的体验。该框架提供了结构化注释，使得数据处理更加便捷。

    

    HuggingFace数据集中心提供数千个数据集，为语言模型的训练和评估提供了令人兴奋的机会。然而，特定任务类型的数据集往往具有不同的架构，使得协调变得具有挑战性。多任务训练或评估需要手动将数据适配到任务模板中。为了解决这个问题，一些倡议采取独立的方法，发布协调的数据集或提供协调代码以将数据集预处理为一致格式。我们确定了以前的预处理工作中的模式，例如列名称映射和从列中提取结构化数据的特定子字段。然后，我们提出了一个结构化注释框架，确保我们的注释完全暴露而不隐藏在非结构化代码中。我们发布了一个数据集注释框架和500多个英语任务的数据集注释。

    The HuggingFace Datasets Hub hosts thousands of datasets, offering exciting opportunities for language model training and evaluation. However, datasets for a specific task type often have different schemas, making harmonization challenging. Multi-task training or evaluation necessitates manual work to fit data into task templates. Several initiatives independently tackle this issue by releasing harmonized datasets or providing harmonization codes to preprocess datasets into a consistent format. We identify patterns across previous preprocessing efforts, such as column name mapping and extracting specific sub-fields from structured data in a column. We then propose a structured annotation framework that ensures our annotations are fully exposed and not hidden within unstructured code. We release a dataset annotation framework and dataset annotations for more than 500 English tasks\footnote{\url{https://github.com/sileod/tasksource}}. These annotations include metadata, such as the names
    
[^60]: 使用网页抓取的多模态数据预训练的对比语言-视觉AI模型存在性物化偏见

    Contrastive Language-Vision AI Models Pretrained on Web-Scraped Multimodal Data Exhibit Sexual Objectification Bias. (arXiv:2212.11261v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2212.11261](http://arxiv.org/abs/2212.11261)

    本文使用对比语言图像预训练的多模态AI模型，使用网页抓取的数据训练，发现这些模型存在性物化偏见，即人的情感状态与身体的呈现相关，表现出对女性的性别偏见。

    

    本文评估了使用对比语言图像预训练（CLIP）目标进行网页抓取的多模态数据的九种语言-视觉AI模型，以寻找心理学家研究的偏见的证据：女孩和女性的性物化现象。我们复制了三个心理实验，并显示这种偏见在AI中依然存在。第一个实验使用Sexual OBjectification and EMotion Database中的标准女性图像，并发现情感状态的识别是由主体是否全身或部分穿着进行介导的。嵌入关联测试返回了愤怒(d>0.80)和悲伤(d>0.50)的显着效应大小，将完全穿着的主体的图像与情感相关联。GRAD-CAM显著性图突出显示，CLIP生成的模型存在性物化偏见，即使使用最先进的对比多模态预训练和网页抓取的数据也是如此。

    Nine language-vision AI models trained on web scrapes with the Contrastive Language-Image Pretraining (CLIP) objective are evaluated for evidence of a bias studied by psychologists: the sexual objectification of girls and women, which occurs when a person's human characteristics, such as emotions, are disregarded and the person is treated as a body. We replicate three experiments in psychology quantifying sexual objectification and show that the phenomena persist in AI. A first experiment uses standardized images of women from the Sexual OBjectification and EMotion Database, and finds that human characteristics are disassociated from images of objectified women: the model's recognition of emotional state is mediated by whether the subject is fully or partially clothed. Embedding association tests (EATs) return significant effect sizes for both anger (d >0.80) and sadness (d >0.50), associating images of fully clothed subjects with emotions. GRAD-CAM saliency maps highlight that CLIP ge
    
[^61]: DimonGen：多元化生成通识推理以解释概念关系。

    DimonGen: Diversified Generative Commonsense Reasoning for Explaining Concept Relationships. (arXiv:2212.10545v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10545](http://arxiv.org/abs/2212.10545)

    本文提出了DimonGen模型，通过生成各种日常场景的概念关系描述来实现多元化通识推理。实验结果表明，MoREE模型在生成质量和多样性方面均优于基线模型。

    

    本文提出了DimonGen，旨在生成描述各种日常场景中概念关系的多样化句子。为此，我们首先通过改编现有的CommonGen数据集创建了一个基准数据集。然后，我们提出了一个名为MoREE的两阶段模型来生成目标句子。MoREE包含一种混合检索模型，该模型检索与给定概念相关的多样性上下文句子，以及一种混合生成器模型，该模型基于检索到的上下文生成多样化的句子。我们在DimonGen任务上进行了实验，并展示了MoREE在生成的句子的质量和多样性方面优于强基线模型。我们的结果表明，MoREE能够生成反映概念之间不同关系的多样化句子，从而实现对概念关系的全面理解。

    In this paper, we propose DimonGen, which aims to generate diverse sentences describing concept relationships in various everyday scenarios. To support this, we first create a benchmark dataset for this task by adapting the existing CommonGen dataset. We then propose a two-stage model called MoREE to generate the target sentences. MoREE consists of a mixture of retrievers model that retrieves diverse context sentences related to the given concepts, and a mixture of generators model that generates diverse sentences based on the retrieved contexts. We conduct experiments on the DimonGen task and show that MoREE outperforms strong baselines in terms of both the quality and diversity of the generated sentences. Our results demonstrate that MoREE is able to generate diverse sentences that reflect different relationships between concepts, leading to a comprehensive understanding of concept relationships.
    
[^62]: CiteBench：科学引文文本生成基准测试

    CiteBench: A benchmark for Scientific Citation Text Generation. (arXiv:2212.09577v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09577](http://arxiv.org/abs/2212.09577)

    CiteBench是一个科学引文文本生成基准测试，旨在解决研究加速导致的解读和总结先前工作的困难。该基准测试可以进行标准化评估，研究不同任务设计和领域的引文文本生成模型。对多个基线模型的大量测试发现了新的见解。

    

    科学通过逐步建立在科学出版物中记录的先前知识体系的基础上提高。许多领域的研究加速使得跟上最新发展并总结不断增长的先前工作的困难。为了解决这个问题，引文文本生成的任务旨在在给定需要引用的论文和引用论文的情境的情况下生成准确的文本摘要。现有的引文文本生成研究基于广泛分歧的任务定义，这使得系统地研究这个任务变得困难。为了应对这个挑战，我们提出了CiteBench：一个引文文本生成基准测试，它统一了多个不同的数据集，使得可以对任务设计和领域中的引文文本生成模型进行标准化评估。使用这个新的基准测试，我们调查了多个强基准的性能，测试了它们在数据集之间的可转移性，并提供了对任务的新见解。

    Science progresses by incrementally building upon the prior body of knowledge documented in scientific publications. The acceleration of research across many fields makes it hard to stay up-to-date with the recent developments and to summarize the ever-growing body of prior work. To target this issue, the task of citation text generation aims to produce accurate textual summaries given a set of papers-to-cite and the citing paper context. Existing studies in citation text generation are based upon widely diverging task definitions, which makes it hard to study this task systematically. To address this challenge, we propose CiteBench: a benchmark for citation text generation that unifies multiple diverse datasets and enables standardized evaluation of citation text generation models across task designs and domains. Using the new benchmark, we investigate the performance of multiple strong baselines, test their transferability between the datasets, and deliver new insights into the task 
    
[^63]: PVGRU：通过Pseudo-Variational机制生成多样且相关的对话回复

    PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism. (arXiv:2212.09086v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09086](http://arxiv.org/abs/2212.09086)

    该论文提出了一个名为PVGRU的组件，可以通过引入汇总变量来聚合子序列的累积分布变化，从而优化基于生成的聊天机器人的多轮对话回复，提高对话模型的多样性和相关性。

    

    我们研究了基于生成的聊天机器人中用于多轮对话的回复生成。现有的基于RNN（循环神经网络）的生成模型通常使用最后隐藏的状态来汇总序列，这使得模型无法捕捉不同对话中观察到的微妙变化，并且不能区分在构成方面相似的对话之间的差异。在本文中，我们提出了一种Pseudo-Variational Gated Recurrent Unit（PVGRU）组件，无需后验知识即可将汇总变量引入GRU，其可以聚合子序列的累积分布变化。 PVGRU可以通过总结变量感知微妙的语义变化，这些变化是通过设计的分布一致性和重构目标进行优化的。此外，我们基于PVGRU构建了Pseudo-Variational Hierarchical Dialogue（PVHD）模型。实验结果表明，PVGRU可以广泛提高对话模型的多样性和相关性。

    We investigate response generation for multi-turn dialogue in generative-based chatbots. Existing generative models based on RNNs (Recurrent Neural Networks) usually employ the last hidden state to summarize the sequences, which makes models unable to capture the subtle variability observed in different dialogues and cannot distinguish the differences between dialogues that are similar in composition. In this paper, we propose a Pseudo-Variational Gated Recurrent Unit (PVGRU) component without posterior knowledge through introducing a recurrent summarizing variable into the GRU, which can aggregate the accumulated distribution variations of subsequences. PVGRU can perceive the subtle semantic variability through summarizing variables that are optimized by the devised distribution consistency and reconstruction objectives. In addition, we build a Pseudo-Variational Hierarchical Dialogue (PVHD) model based on PVGRU. Experimental results demonstrate that PVGRU can broadly improve the dive
    
[^64]: 自我提示的大型语言模型用于零样本开放域问答

    Self-Prompting Large Language Models for Zero-Shot Open-Domain QA. (arXiv:2212.08635v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08635](http://arxiv.org/abs/2212.08635)

    本论文提出了一种自我提示框架，可以有效利用大型语言模型的参数中存储的知识和指令理解能力，以实现零样本开放域问答，并且实验证明该方法在三个广泛使用的ODQA数据集中显著优于现有的最先进方法。

    

    开放域问答目标在于回答关于事实的问题，而无需提供特定的背景文档。在零样本设置下，由于没有数据来训练类似检索器-阅读器的定制模型，因此此任务更加具有挑战性。最近，像GPT-3这样的大型语言模型已经通过直接提示方法在零样本开放域问答中展示了其强大的能力，但是这些方法仍然远远不能充分发挥LLM的强大功能，而只是以隐式方式调用它们而已。本文提出了一个自我提示框架，以明确利用LLM参数中存储的大量知识和其强大的指令理解能力。具体而言，我们逐步提示LLM生成多个伪QA对，并从头开始生成背景段落和解释，然后使用生成的元素进行上下文学习。实验结果表明，我们的方案在三个广泛使用的ODQA数据集上显著超过了先前的SOTA方法。

    Open-Domain Question Answering (ODQA) aims at answering factoid questions without explicitly providing specific background documents. In a zero-shot setting, this task is more challenging since no data is available to train customized models like Retriever-Readers. Recently, Large Language Models (LLMs) like GPT-3 have shown their power in zero-shot ODQA with direct prompting methods, but these methods are still far from releasing the full powerfulness of LLMs only in an implicitly invoking way. In this paper, we propose a Self-Prompting framework to explicitly utilize the massive knowledge stored in the parameters of LLMs and their strong instruction understanding abilities. Concretely, we prompt LLMs step by step to generate multiple pseudo QA pairs with background passages and explanations from scratch and then use those generated elements for in-context learning. Experimental results show our method surpasses previous SOTA methods significantly on three widely-used ODQA datasets, a
    
[^65]: CREPE：视觉-语言基础模型是否能够按组合思考？

    CREPE: Can Vision-Language Foundation Models Reason Compositionally?. (arXiv:2212.07796v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07796](http://arxiv.org/abs/2212.07796)

    CREPE提出了一个新的组合性评估基准，衡量了模型的系统性和产出性能，发现大型预训练的视觉-语言基础模型在组合性上仍存在问题。

    

    人类视觉和自然语言的一个共同特征是它们的构成性质。然而，尽管大型视觉和语言预训练为性能提升做出了贡献，但我们发现：在训练了4种算法的7个架构和海量数据集后，它们都难以实现组合性。为了得出这个结论，我们介绍了一个新的组合性评估基准，即CREPE，它衡量了认知科学文献所识别的组合性的两个重要方面：系统性和产出性。为了衡量系统性，CREPE包含一个测试数据集，其中包含超过37万个图像-文本对和三个不同的已看/未看分割。这三个分割是设计用来测试在三个流行的训练数据集CC-12M、YFCC-15M和LAION-400M上训练的模型。我们还为其中的一个子集生成了32.5万、31.6万和30.9万个困难的负面字幕。为了测试产出性能，CREPE包含了17,000个图像-文本对，涵盖了九种不同的复杂性和。

    A fundamental characteristic common to both human vision and natural language is their compositional nature. Yet, despite the performance gains contributed by large vision and language pretraining, we find that: across 7 architectures trained with 4 algorithms on massive datasets, they struggle at compositionality. To arrive at this conclusion, we introduce a new compositionality evaluation benchmark, CREPE, which measures two important aspects of compositionality identified by cognitive science literature: systematicity and productivity. To measure systematicity, CREPE consists of a test dataset containing over $370K$ image-text pairs and three different seen-unseen splits. The three splits are designed to test models trained on three popular training datasets: CC-12M, YFCC-15M, and LAION-400M. We also generate $325K$, $316K$, and $309K$ hard negative captions for a subset of the pairs. To test productivity, CREPE contains $17K$ image-text pairs with nine different complexities plus $
    
[^66]: AIONER: 基于深度学习的全套方案生物医学命名实体识别

    AIONER: All-in-one scheme-based biomedical named entity recognition using deep learning. (arXiv:2211.16944v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.16944](http://arxiv.org/abs/2211.16944)

    AIONER是一种新颖的基于深度学习的全套方案生物医学命名实体识别工具，利用外部数据提高BioNER模型准确性和稳定性，具有良好的性能和泛化能力。

    

    生物医学命名实体识别（BioNER）旨在自动识别自然语言文本中的生物医学实体，为信息提取和问答等下游文本挖掘任务和应用提供必要的基础。然而，由于准确注释所需的领域专业知识昂贵，因此手动标记训练数据对BioNER任务来说是昂贵的。导致的数据稀缺问题导致当前的BioNER方法容易出现过度拟合，具有有限的泛化能力，并且一次只能解决一种实体类型（例如，基因或疾病）。因此，我们提出了一种新颖的全套方案（AIO）方案，利用现有的注释资源外部数据来提高BioNER模型的准确性和稳定性。我们进一步提出了基于尖端深度学习和我们的AIO方案的通用BioNER工具AIONER。我们在14个BioNER基准任务上评估了AIONER，并展示了AIONER的有效性，稳健性，与其他方法相比优异。

    Biomedical named entity recognition (BioNER) seeks to automatically recognize biomedical entities in natural language text, serving as a necessary foundation for downstream text mining tasks and applications such as information extraction and question answering. Manually labeling training data for the BioNER task is costly, however, due to the significant domain expertise required for accurate annotation. The resulting data scarcity causes current BioNER approaches to be prone to overfitting, to suffer from limited generalizability, and to address a single entity type at a time (e.g., gene or disease). We therefore propose a novel all-in-one (AIO) scheme that uses external data from existing annotated resources to enhance the accuracy and stability of BioNER models. We further present AIONER, a general-purpose BioNER tool based on cutting-edge deep learning and our AIO schema. We evaluate AIONER on 14 BioNER benchmark tasks and show that AIONER is effective, robust, and compares favora
    
[^67]: 跨语言转移的令人沮丧的简易标签投影

    Frustratingly Easy Label Projection for Cross-lingual Transfer. (arXiv:2211.15613v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15613](http://arxiv.org/abs/2211.15613)

    本文通过一项广泛的实证研究，对57种语言和三个任务下的跨语言转移进行了研究，并发现优化后的标记-翻译法比传统注释投影方法更有效。

    

    将训练数据翻译成多种语言已成为提高跨语言转移的实际解决方案。对于涉及跨度级别注释（例如信息提取或问题回答）的任务，需要进行额外的标签投影步骤，将已注释的跨度映射到翻译后的文本中。然而，据我们所知，迄今为止尚未对这种方法与基于单词对齐的传统注释投影进行实证分析。在本文中，我们展示了一项对57种语言和三个任务（QA，NER和事件提取）进行广泛的实证研究，以评估两种方法的有效性和局限性，并填补文献中的重要空白。实验结果表明，我们优化后的标记-翻译法比传统注释投影方法更有效。

    Translating training data into many languages has emerged as a practical solution for improving cross-lingual transfer. For tasks that involve span-level annotations, such as information extraction or question answering, an additional label projection step is required to map annotated spans onto the translated texts. Recently, a few efforts have utilized a simple mark-then-translate method to jointly perform translation and projection by inserting special markers around the labeled spans in the original sentence. However, as far as we are aware, no empirical analysis has been conducted on how this approach compares to traditional annotation projection based on word alignment. In this paper, we present an extensive empirical study across 57 languages and three tasks (QA, NER, and Event Extraction) to evaluate the effectiveness and limitations of both methods, filling an important gap in the literature. Experimental results show that our optimized version of mark-then-translate, which we
    
[^68]: 带着额外大词汇量的大型预训练模型：希伯来语BERT模型对比分析和一种新的模型来超越它们。

    Large Pre-Trained Models with Extra-Large Vocabularies: A Contrastive Analysis of Hebrew BERT Models and a New One to Outperform Them All. (arXiv:2211.15199v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15199](http://arxiv.org/abs/2211.15199)

    阐述了新的预训练语言模型AlephBERTGimmel在希伯来语基准测试上的表现，其使用更高的词汇量，达到了新的最新最好的性能。

    

    本文介绍了一种名为AlephBERTGimmel的现代希伯来语新预训练语言模型（PLM），其使用比标准希伯来PLMs更大的词汇量（128K项目）。我们对这个模型进行对比分析，与所有以前的希伯来PLMs（mBERT，heBERT，AlephBERT）进行比较，并评估更大词汇量对任务性能的影响。我们的实验表明，更大的词汇量导致更少的分裂，而减少分裂对于模型性能更好，适用于不同任务。总的来说，这个新模型在包括分词，词性标注，全形态分析，命名实体识别和情感分析在内的所有可用的希伯来语基准测试上都达到了最先进的水平。因此，我们提倡不仅以层数或训练数据数量为衡量标准，而且还以词汇量为标准的更大PLMs。我们公开发布这个新模型，可以不受限制地使用。

    We present a new pre-trained language model (PLM) for modern Hebrew, termed AlephBERTGimmel, which employs a much larger vocabulary (128K items) than standard Hebrew PLMs before. We perform a contrastive analysis of this model against all previous Hebrew PLMs (mBERT, heBERT, AlephBERT) and assess the effects of larger vocabularies on task performance. Our experiments show that larger vocabularies lead to fewer splits, and that reducing splits is better for model performance, across different tasks. All in all this new model achieves new SOTA on all available Hebrew benchmarks, including Morphological Segmentation, POS Tagging, Full Morphological Analysis, NER, and Sentiment Analysis. Subsequently we advocate for PLMs that are larger not only in terms of number of layers or training data, but also in terms of their vocabulary. We release the new model publicly for unrestricted use.
    
[^69]: 不需要微调的预训练语言模型剪枝

    Pruning Pre-trained Language Models Without Fine-Tuning. (arXiv:2210.06210v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06210](http://arxiv.org/abs/2210.06210)

    本文提出了静态模型剪枝（SMP），它只使用一阶剪枝来适应下游任务，同时实现目标稀疏度水平，在大量实验证明SMP具有显著的改进。

    

    为了克服预训练语言模型中过于参数化的问题，我们广泛地使用剪枝作为一种简单和直接的压缩方法，直接去除不重要的权重。先前的一阶方法成功地将PLMs压缩到极高的稀疏性，同时表现几乎不下降，如运动剪枝等。这些方法使用一阶信息来剪枝PLMs，同时微调其余的权重。在这项工作中，我们认为对于一阶剪枝，微调是多余的，因为一阶剪枝足以将PLMs收敛到下游任务，而无需微调。在这个初衷下，我们提出了静态模型剪枝（SMP），它只使用一阶剪枝来使PLMs适应下游任务，同时实现目标稀疏度水平。此外，我们还设计了一个新的蒙版函数和训练目标，以进一步改进SMP。大量各种稀疏度水平下的实验证明了SMP比一阶和零阶方法具有显著的改进。

    To overcome the overparameterized problem in Pre-trained Language Models (PLMs), pruning is widely used as a simple and straightforward compression method by directly removing unimportant weights. Previous first-order methods successfully compress PLMs to extremely high sparsity with little performance drop. These methods, such as movement pruning, use first-order information to prune PLMs while fine-tuning the remaining weights. In this work, we argue fine-tuning is redundant for first-order pruning, since first-order pruning is sufficient to converge PLMs to downstream tasks without fine-tuning. Under this motivation, we propose Static Model Pruning (SMP), which only uses first-order pruning to adapt PLMs to downstream tasks while achieving the target sparsity level. In addition, we also design a new masking function and training objective to further improve SMP. Extensive experiments at various sparsity levels show SMP has significant improvements over first-order and zero-order met
    
[^70]: 预训练语言模型为什么更适合零样本学习？

    What Makes Pre-trained Language Models Better Zero-shot Learners?. (arXiv:2209.15206v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.15206](http://arxiv.org/abs/2209.15206)

    本文提出一个理论框架来解释prompt learning在零样本/少样本场景下的有效性，并基于此提出了一个注释无关的模板选择方法。

    

    本文提出了一个理论框架来解释prompt learning在零样本/少样本场景下的有效性。首先，我们证明传统的预训练和微调范式在少样本场景下会因为过拟合不具代表性的标注数据而失败。然后，我们详细阐述了prompt learning更有效的假设，因为它使建立在海量文本语料库和领域相关人类知识的预训练语言模型可以更多地参与预测，从而减少小型训练集提供的有限标签信息的影响。我们进一步假设，语言差异可以衡量提示质量。我们进行了全面的实验证明了我们的假设。更为重要的是，受到理论框架的启发，我们提出了一种基于困惑度的注释无关的模板选择方法，可以事先“预测”提示性能。这种方法特别值得鼓励。

    In this paper, we propose a theoretical framework to explain the efficacy of prompt learning in zero/few-shot scenarios. First, we prove that conventional pre-training and fine-tuning paradigm fails in few-shot scenarios due to overfitting the unrepresentative labelled data. We then detail the assumption that prompt learning is more effective because it empowers pre-trained language model that is built upon massive text corpora, as well as domain-related human knowledge to participate more in prediction and thereby reduces the impact of limited label information provided by the small training set. We further hypothesize that language discrepancy can measure the quality of prompting. Comprehensive experiments are performed to verify our assumptions. More remarkably, inspired by the theoretical framework, we propose an annotation-agnostic template selection method based on perplexity, which enables us to ``forecast'' the prompting performance in advance. This approach is especially encou
    
[^71]: 快速FNet：通过高效的傅里叶层加速Transformer编码器模型

    Fast-FNet: Accelerating Transformer Encoder Models via Efficient Fourier Layers. (arXiv:2209.12816v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.12816](http://arxiv.org/abs/2209.12816)

    FNet模型通过替换注意力层为傅里叶变换，加速了Transformer编码器模型的训练过程并保持相同的性能水平。

    

    基于Transformer的语言模型在几乎所有自然语言处理任务中利用注意力机制实现了显著的性能提升。相似的注意力结构也在其他领域广泛研究。虽然注意力机制显著增强了模型性能，但其二次复杂度阻碍了对长序列的高效处理。最近的研究集中在消除计算效率的缺点上，并表明在无需注意力层的情况下，基于Transformer的模型仍然能够达到竞争性的结果。一项开创性的研究提出了FNet，在Transformer编码器结构中用傅里叶变换（FT）替换注意力层。FNet在加速训练过程中去除了注意力机制的运算负担，同时实现了与原始Transformer编码器模型相当的性能。然而，FNet模型忽略了FT的基本属性..

    Transformer-based language models utilize the attention mechanism for substantial performance improvements in almost all natural language processing (NLP) tasks. Similar attention structures are also extensively studied in several other areas. Although the attention mechanism enhances the model performances significantly, its quadratic complexity prevents efficient processing of long sequences. Recent works focused on eliminating the disadvantages of computational inefficiency and showed that transformer-based models can still reach competitive results without the attention layer. A pioneering study proposed the FNet, which replaces the attention layer with the Fourier Transform (FT) in the transformer encoder architecture. FNet achieves competitive performances concerning the original transformer encoder model while accelerating training process by removing the computational burden of the attention mechanism. However, the FNet model ignores essential properties of the FT from the clas
    
[^72]: WeLM: 一种面向中文的读过书的预训练语言模型

    WeLM: A Well-Read Pre-trained Language Model for Chinese. (arXiv:2209.10372v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.10372](http://arxiv.org/abs/2209.10372)

    WeLM 是一种面向中文的读过书的预训练语言模型，它通过读取高质量的语料库训练了100亿个参数，并可以在18个中文任务中显著优于现有同规模预训练模型，同时表现出强大的多语言和代码转换理解能力。

    

    以自我监督学习为基础的大型语言模型在广泛的任务中显示了出色的零样本泛化能力。在本文中，我们介绍了WeLM：一种能够零或少样本演示无缝执行不同类型任务的面向中文的读过书的预训练语言模型。WeLM通过阅读精心策划的高质量语料库中的信息，以100亿个参数进行训练。我们展示了WeLM在各个领域和语言方面具备广泛的知识。在18项独立的（中文）任务中，WeLM能够显著优于现有规模相似且预训练模型，并且能够匹配规模高达25倍的模型的性能。WeLM还表现出强大的多语言和代码转换理解能力，优于预先在30种语言上进行预训练的现有多语言语言模型。此外，我们为大量中文监督式数据集收集了人工编写的提示，并对WeLM进行了微调。

    Large Language Models pre-trained with self-supervised learning have demonstrated impressive zero-shot generalization capabilities on a wide spectrum of tasks. In this work, we present WeLM: a well-read pre-trained language model for Chinese that is able to seamlessly perform different types of tasks with zero or few-shot demonstrations. WeLM is trained with 10B parameters by "reading" a curated high-quality corpus covering a wide range of topics. We show that WeLM is equipped with broad knowledge on various domains and languages. On 18 monolingual (Chinese) tasks, WeLM can significantly outperform existing pre-trained models with similar sizes and match the performance of models up to 25 times larger. WeLM also exhibits strong capabilities in multi-lingual and code-switching understanding, outperforming existing multilingual language models pre-trained on 30 languages. Furthermore, We collected human-written prompts for a large set of supervised datasets in Chinese and fine-tuned WeLM
    
[^73]: 面向社交媒体话题分类的非参数化时间自适应方法

    Non-Parametric Temporal Adaptation for Social Media Topic Classification. (arXiv:2209.05706v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.05706](http://arxiv.org/abs/2209.05706)

    本文提出了一种非参数化的密集检索技术，可以解决当前自然语言处理模型无法适应时间变化，无法应对测试数据分布变化和已删除的训练数据的问题，并在Twitter数据集上取得了显著的实验结果。

    

    用户生成的社交媒体数据不断变化，新的趋势影响在线讨论，个人信息由于隐私问题而被删除。然而，大多数当前的自然语言处理模型是静态的，并依赖于固定的训练数据，这意味着它们无法适应时间变化，无法应对测试数据分布变化和已删除的训练数据，需要经常昂贵的重新训练。本文通过长期的话题预测任务研究时间自适应，提出了一种非参数化的密集检索技术作为简单但有效的解决方案。在一个新收集的、公开可用的、为期一年的Twitter数据集上进行了实验，该数据集表现出时间分布变化，我们方法比最佳参数基线改善了64.12%，而且不需要其昂贵的基于梯度的更新。我们的密集检索方法也非常适用于符合数据隐私法规的动态删除用户数据，几乎没有计算成本。

    User-generated social media data is constantly changing as new trends influence online discussion and personal information is deleted due to privacy concerns. However, most current NLP models are static and rely on fixed training data, which means they are unable to adapt to temporal change -- both test distribution shift and deleted training data -- without frequent, costly re-training. In this paper, we study temporal adaptation through the task of longitudinal hashtag prediction and propose a non-parametric dense retrieval technique, which does not require re-training, as a simple but effective solution. In experiments on a newly collected, publicly available, year-long Twitter dataset exhibiting temporal distribution shift, our method improves by 64.12% over the best parametric baseline without any of its costly gradient-based updating. Our dense retrieval approach is also particularly well-suited to dynamically deleted user data in line with data privacy laws, with negligible comp
    
[^74]: 一个新的对齐的简易德语语料库

    A New Aligned Simple German Corpus. (arXiv:2209.01106v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.01106](http://arxiv.org/abs/2209.01106)

    本文介绍了一个新的对齐的简易德语语料库，用于辅助不同人群理解复杂的德语书面语言；该语料库通过自动句子对齐方法使多个文档对齐，且质量优于之前的工作。

    

    "Leichte Sprache"是德语版的简易英语，旨在为不同人群提供复杂的书面语言，以便使这些内容易于理解。本文介绍了一个新的对齐句子的单语语料库，用于简易德语--德语。它包含多个文档对齐来源，我们使用自动句子对齐方法对其进行了对齐。我们基于手动标记的对齐文档的子集来评估我们的对齐质量。根据F1分数测量，我们的句子对齐质量超过了以前的工作。我们在CC BY-SA下发布数据集，在MIT许可下发布附带的代码。

    "Leichte Sprache", the German counterpart to Simple English, is a regulated language aiming to facilitate complex written language that would otherwise stay inaccessible to different groups of people. We present a new sentence-aligned monolingual corpus for Simple German -- German. It contains multiple document-aligned sources which we have aligned using automatic sentence-alignment methods. We evaluate our alignments based on a manually labelled subset of aligned documents. The quality of our sentence alignments, as measured by F1-score, surpasses previous work. We publish the dataset under CC BY-SA and the accompanying code under MIT license.
    
[^75]: 为检测真假新闻而伪造的假新闻：有宣传性的训练数据生成

    Faking Fake News for Real Fake News Detection: Propaganda-loaded Training Data Generation. (arXiv:2203.05386v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.05386](http://arxiv.org/abs/2203.05386)

    该论文提出了一个生成具有宣传性的训练数据的框架，以帮助检测人工撰写的虚假信息。所生成的的训练数据集PropaNews在假新闻检测方面表现更好。

    

    尽管神经模型能够检测生成的假新闻，但它们的结果不适用于有效检测人工撰写的虚假信息。这是由于机器生成的假新闻和人工撰写的假新闻之间存在巨大差距，包括风格和基本意图方面的显著不同。鉴于此，我们提出了一个新颖框架，通过已知人工宣传的风格和策略来生成训练样本。具体来说，我们进行了自我批判的序列训练，引导自然语言推理以确保所生成的文章的有效性，同时还包括宣传技巧，如权威呼吁和有宣传性的语言。特别是，我们创建了一个新的训练数据集PropaNews，其中包含2,256个示例，并发布以供将来使用。我们的实验结果表明，通过PropaNews训练的假新闻检测器比那些在传统机器生成的假新闻数据集上训练的检测器更适用于检测人工撰写的虚假信息。

    Despite recent advances in detecting fake news generated by neural models, their results are not readily applicable to effective detection of human-written disinformation. What limits the successful transfer between them is the sizable gap between machine-generated fake news and human-authored ones, including the notable differences in terms of style and underlying intent. With this in mind, we propose a novel framework for generating training examples that are informed by the known styles and strategies of human-authored propaganda. Specifically, we perform self-critical sequence training guided by natural language inference to ensure the validity of the generated articles, while also incorporating propaganda techniques, such as appeal to authority and loaded language. In particular, we create a new training dataset, PropaNews, with 2,256 examples, which we release for future use. Our experimental results show that fake news detectors trained on PropaNews are better at detecting human
    
[^76]: 通过本地情感聚合改进隐式情感学习

    Improving Implicit Sentiment Learning via Local Sentiment Aggregation. (arXiv:2110.08604v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.08604](http://arxiv.org/abs/2110.08604)

    本文提出了一种本地情感聚合范式，可以提高情感学习的能力，该方法可以有效地建模方面情感相干性，并在三个公共数据集上实现了最先进的性能。

    

    面向方面的情感分类（ABSC）揭示了不同方面之间情感极性的潜在依赖关系。我们的研究进一步探讨了这一现象，提出了相邻方面经常表现出相似情感的概念，我们称之为“方面情感相干性”。我们认为，当前的研究领域还没有充分重视建模方面情感相干性的重要性。为了解决这一问题，我们引入了一种本地情感聚合范式（LSA），可以促进精细的情感相干性建模。这种方法使得可以提取缺乏显式情感描述的方面的隐含情感。利用梯度下降，我们设计了一种差分加权情感聚合窗口，来指导方面情感相干性的建模。实验结果表明，LSA在学习情感相干性方面具有很好的效果，在三个公共数据集上实现了最先进的性能，从而显著提高了情感学习的能力。

    Aspect-based sentiment classification (ABSC) has revealed the potential dependency of sentiment polarities among different aspects. Our study further explores this phenomenon, positing that adjacent aspects often exhibit similar sentiments, a concept we term "aspect sentiment coherency." We argue that the current research landscape has not fully appreciated the significance of modeling aspect sentiment coherency. To address this gap, we introduce a local sentiment aggregation paradigm (LSA) that facilitates fine-grained sentiment coherency modeling. This approach enables the extraction of implicit sentiments for aspects lacking explicit sentiment descriptions. Leveraging gradient descent, we design a differential-weighted sentiment aggregation window that guides the modeling of aspect sentiment coherency. Experimental results affirm the efficacy of LSA in learning sentiment coherency, as it achieves state-of-the-art performance across three public datasets, thus significantly enhancing
    
[^77]: UNIQORN：统一的RDF知识图谱与自然语言文本问答系统

    UNIQORN: Unified Question Answering over RDF Knowledge Graphs and Natural Language Text. (arXiv:2108.08614v5 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2108.08614](http://arxiv.org/abs/2108.08614)

    本文提出了一个名为UNIQORN的问答系统，它能够无缝地处理RDF数据和文本，使用fine-tuned BERT模型为问题构建上下文图，并使用图算法确定与问题相关的子图来回答问题。

    

    问题回答在知识图谱和其他RDF数据上已经取得了巨大的进展，许多优秀的系统可以为自然语言问题或电报查询提供清晰的答案。其中一些系统将文本源作为附加证据纳入回答过程，但不能计算仅存在于文本中的答案。相反，IR和NLP社区的系统已经解决了有关文本的QA问题，但是这些系统几乎不利用语义数据和知识。本文提出了第一个可以无缝操作混合RDF数据集和文本语料库或单个来源的复杂问题的系统，在统一框架中进行操作。我们的方法称为UNIQORN，通过使用经过精细调整的BERT模型从RDF数据和/或文本语料库中检索与问题相关的证据来动态构建上下文图。结果图通常非常丰富但高度嘈杂。UNIQORN通过用于组Steiner树的图算法来处理这个输入，从而确定与问题相关的子图，进而回答问题。

    Question answering over knowledge graphs and other RDF data has been greatly advanced, with a number of good systems providing crisp answers for natural language questions or telegraphic queries. Some of these systems incorporate textual sources as additional evidence for the answering process, but cannot compute answers that are present in text alone. Conversely, systems from the IR and NLP communities have addressed QA over text, but such systems barely utilize semantic data and knowledge. This paper presents the first system for complex questions that can seamlessly operate over a mixture of RDF datasets and text corpora, or individual sources, in a unified framework. Our method, called UNIQORN, builds a context graph on-the-fly, by retrieving question-relevant evidences from the RDF data and/or a text corpus, using fine-tuned BERT models. The resulting graph is typically rich but highly noisy. UNIQORN copes with this input by a graph algorithm for Group Steiner Trees, that identifi
    
[^78]: 开放式韩语语料库: 实用报告。

    Open Korean Corpora: A Practical Report. (arXiv:2012.15621v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2012.15621](http://arxiv.org/abs/2012.15621)

    本文回顾了韩语语料库，提出了针对资源较少的语言进行开源数据集构建和发布以促进研究的方向。

    

    韩语在研究社区中常被称为低资源语言。虽然这种说法在一定程度上是正确的，但也因为资源的可用性没有得到充分的宣传和整理。本文整理和回顾了一系列韩语语料库，首先描述了机构级别的资源开发，然后进一步列举了不同类型任务的当前开源数据集清单。然后，我们提出了如何为资源较少的语言进行开源数据集构建和发布以促进研究的方向。

    Korean is often referred to as a low-resource language in the research community. While this claim is partially true, it is also because the availability of resources is inadequately advertised and curated. This work curates and reviews a list of Korean corpora, first describing institution-level resource development, then further iterate through a list of current open datasets for different types of tasks. We then propose a direction on how open-source dataset construction and releases should be done for less-resourced languages to promote research.
    

