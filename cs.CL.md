# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Why Does ChatGPT Fall Short in Answering Questions Faithfully?.](http://arxiv.org/abs/2304.10513) | 该论文分析了ChatGPT在问答系统中的失误，归纳并确定其失败的原因类型和关键能力，进一步提出了潜在方法来提高其准确性。 |
| [^2] | ["Can We Detect Substance Use Disorder?": Knowledge and Time Aware Classification on Social Media from Darkweb.](http://arxiv.org/abs/2304.10512) | 本研究使用知识感知BERT模型，分析社交媒体上发布的与合成阿片类物质相关的帖子，以了解用户对不同合成阿片类物质的情感和情绪，从而帮助预测物质使用障碍。 |
| [^3] | [A primer on getting neologisms from foreign languages to under-resourced languages.](http://arxiv.org/abs/2304.10495) | 本文介绍了一种从外语到欠发达语言获取新词的初步指南，提出可以引入任何语言的新词，只要这些词语“听起来像”目标语言的本地单词。 |
| [^4] | [Learning to Program with Natural Language.](http://arxiv.org/abs/2304.10464) | 该论文提出了一种用自然语言作为编程语言并通过学习编程方法让大语言模型直接生成自然语言程序并指导推理的方法。实验结果表明，这种方法在解决编程任务上比基线方法有更高的成功率。 |
| [^5] | [Phoenix: Democratizing ChatGPT across Languages.](http://arxiv.org/abs/2304.10453) | Phoenix 是一款大型语言模型，实现了跨语言民主化，不仅在英文和中文中表现良好，也在资源有限的语言中表现出色，使得 ChatGPT 在更多的国家和地区变得更加可用。 |
| [^6] | [Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health.](http://arxiv.org/abs/2304.10447) | 本文在心理健康领域进行了继续预训练以捕捉长上下文。作者基于XLNet和Longformer训练和发布了MentalXLNet和MentalLongformer模型，并对其进行了性能评估和能力测试。这些模型对于早期心理健康问题的检测非常有用。 |
| [^7] | [Safety Assessment of Chinese Large Language Models.](http://arxiv.org/abs/2304.10436) | 该论文介绍了中国大型语言模型的安全评估，提出一种基于8种典型安全场景和6种更具挑战性指令攻击的综合安全性能评估基准，利用LLMs的强大评估能力开发并量化了评估模型的安全性能。 |
| [^8] | [GPT-NER: Named Entity Recognition via Large Language Models.](http://arxiv.org/abs/2304.10428) | 本文提出了GPT-NER来解决大型语言模型在命名实体识别任务（NER）上表现不佳的问题，它通过将序列标记任务转化为生成任务，将LLM能够容易地适应NER任务。同时，为了有效解决LLMs“幻觉”问题，作者们提出了自我验证策略，通过提示LLMs询问自身来确定提取的实体是否属于实际存在的实体。 |
| [^9] | [CKBP v2: An Expert-Annotated Evaluation Set for Commonsense Knowledge Base Population.](http://arxiv.org/abs/2304.10392) | 本文介绍了CKBP v2, 一个使用专家注释而囊括对抗样本的高质量通识知识库填充基准，以解决CKBP v1由于众包注释和随机抽样导致的问题。实验结果表明，通识知识库填充任务对于现有技术水平仍然具有挑战性。 |
| [^10] | [Prompt-Learning for Cross-Lingual Relation Extraction.](http://arxiv.org/abs/2304.10354) | 本文提出了一种新型的XRE算法Prompt-XRE，基于Prompt调优方法，它能够有效提高多语种预训练语言模型在跨语言环境下的表现。 |
| [^11] | [Interventional Probing in High Dimensions: An NLI Case Study.](http://arxiv.org/abs/2304.10346) | 本文利用表示级干预进行了自然语言推理任务中中间语义特征对分类结果的影响研究，包括健忘探测及遗忘-记忆探测变体，为之后的干预探测提供了重要指导意义。 |
| [^12] | [Towards a Benchmark for Scientific Understanding in Humans and Machines.](http://arxiv.org/abs/2304.10327) | 该论文提出了一个框架来创建衡量人类和人工智能科学理解的基准。他们使用了行为观念，提出了一组问题以衡量不同水平的科学理解。这个框架可以帮助评估和比较不同水平和方法的科学理解。 |
| [^13] | [Improving Speech Translation by Cross-Modal Multi-Grained Contrastive Learning.](http://arxiv.org/abs/2304.10309) | 本文提出了基于跨模态多粒度对比学习的语音翻译模型优化方法，该方法通过跨模态多粒度对比学习进行显式知识转移，并在E2E-ST和MT任务上都取得了显著的改进。 |
| [^14] | [Decouple Non-parametric Knowledge Distillation For End-to-end Speech Translation.](http://arxiv.org/abs/2304.10295) | 本文提出了一种新方法，从数据角度提高了语音翻译模型的数据效率，而不需要转录数据。该方法解离了非参数知识蒸馏，通过构建教师分布来达到知识转移的目的。 |
| [^15] | [Is augmentation effective to improve prediction in imbalanced text datasets?.](http://arxiv.org/abs/2304.10283) | 本文研究发现，通过调整分类器截断点而不进行数据增强可以在不平衡数据集上得到类似于过采样技术的结果，为处理不平衡数据提供了一种新的思路。 |
| [^16] | [Effective Open Intent Classification with K-center Contrastive Learning and Adjustable Decision Boundary.](http://arxiv.org/abs/2304.10220) | 本文介绍了基于K-center对比学习和可调决策边界学习(CLAB)的开放意图分类方法，通过预训练得到知识迁移，并用K-center对比学习算法学习出区分性和平衡性的意图特征，同时使用可调边界学习方法确定合适的决策条件。 |
| [^17] | [Exploring Paracrawl for Document-level Neural Machine Translation.](http://arxiv.org/abs/2304.10216) | 本文研究了使用 Paracrawl 平行语料库提取平行段落训练文档级翻译模型的有效性。 |
| [^18] | [CoT-MoTE: Exploring ConTextual Masked Auto-Encoder Pre-training with Mixture-of-Textual-Experts for Passage Retrieval.](http://arxiv.org/abs/2304.10195) | 本文提出了一种在段落检索中采用基于文本专家混合的上下文掩码自编码器预训练的新方法，可以有效改进嵌入空间的判别效果。 |
| [^19] | [Analyzing FOMC Minutes: Accuracy and Constraints of Language Models.](http://arxiv.org/abs/2304.10164) | 该研究分析了FOMC官方声明中使用的语言，采用VADER和FinBERT等模型预测负面情绪，结果显示FinBERT表现相对更好。但是，该研究也强调了使用当前NLP技术分析FOMC文本的挑战和限制，建议增强语言模型并探索替代方法。 |
| [^20] | [Does Manipulating Tokenization Aid Cross-Lingual Transfer? A Study on POS Tagging for Non-Standardized Languages.](http://arxiv.org/abs/2304.10158) | 本研究探讨了微调预训练语言模型在非标准化语言上的词性标注的问题，发现通过调整标记化方法可以提高模型在跨语言转移方面的性能。 |
| [^21] | [On the Independence of Association Bias and Empirical Fairness in Language Models.](http://arxiv.org/abs/2304.10153) | 本文探讨了预先训练的语言模型中联想偏差和实证公正的关系，通过理论实验和实证研究证明了两者可以是独立的。本文呼吁采用实证公正的模型开发方法并减少表示偏差。 |
| [^22] | [Can ChatGPT Reproduce Human-Generated Labels? A Study of Social Computing Tasks.](http://arxiv.org/abs/2304.10145) | 本文研究了ChatGPT在社交计算任务中是否可以复制人类生成的标签注释，结果表明ChatGPT有潜力处理这些数据注释任务，尽管仍存在许多挑战。 |
| [^23] | [Supporting Human-AI Collaboration in Auditing LLMs with LLMs.](http://arxiv.org/abs/2304.09991) | 本论文通过对安全和公正人工智能专家的采访以及对人工智能协作和感知文献的研究，增强了“AdaTest”审计工具，这个工具可以通过利用人和生成模型的协同优势，进行更严格的大型语言模型审计。 |
| [^24] | [Radar de Parit\'e: An NLP system to measure gender representation in French news stories.](http://arxiv.org/abs/2304.09982) | 本文介绍了Radar de Parit\'e，一种自动化的NLP系统，根据六个加拿大法语媒体每天引用的女性和男性比例的数据，详细介绍了该系统的架构，以及如何解决法语语言中的技术难题，展示了在一年的数据统计中，新闻报道中女性的代表性不足，因此该系统为我们解决社会问题提供了新的思路和方法。 |
| [^25] | [MasakhaNEWS: News Topic Classification for African languages.](http://arxiv.org/abs/2304.09972) | 该论文开发了MasakhaNEWS，它是一个覆盖16种非洲语言的新闻主题分类的基准数据集。除了评估基线模型外，还探索了适用于零样本学习和少样本学习的全面微调语言模型的替代方案。 |
| [^26] | [A Latent Space Theory for Emergent Abilities in Large Language Models.](http://arxiv.org/abs/2304.09960) | 本文探讨了大规模语言模型中的贝叶斯推断和稀疏联合分布，证明了LLMs能够完成语言理解、上下文学习、思路启发以及有效指令微调的新兴能力。 |
| [^27] | [Low-resource Bilingual Dialect Lexicon Induction with Large Language Models.](http://arxiv.org/abs/2304.09957) | 本文探索了在低资源情况下使用大型语言模型进行双语方言词典归纳的方法，对德语及其巴伐利亚和阿勒曼尼亚方言进行分析，提出了应对资源稀缺、语言相关性和拼写标准化缺失等挑战的解决方案。输出结果通过单词频率和成对编辑距离进行评估，同时发布了包括1500个双语句子对和1000个双语单词对的评估数据集。 |
| [^28] | [Catch Me If You Can: Identifying Fraudulent Physician Reviews with Large Language Models Using Generative Pre-Trained Transformers.](http://arxiv.org/abs/2304.09948) | 本研究使用GPT-3模型，比以往的传统机器学习模型（如逻辑回归和支持向量机）性能更出色。同时，本研究揭示虚假评论与真实评论在语言表达上存在的差异，分析了虚假评论的模式和特征。 |
| [^29] | [The eBible Corpus: Data and Model Benchmarks for Bible Translation for Low-Resource Languages.](http://arxiv.org/abs/2304.09919) | 介绍了一个名为eBible的圣经翻译语料库，包含1009个圣经部分翻译的数据集，涵盖了833种不同语言的数据，分布在75个语言家族中。同时还提供了基于NLLB神经机器翻译模型的性能基准，并讨论了在圣经翻译领域中的一些问题。 |
| [^30] | [Bridging Natural Language Processing and Psycholinguistics: computationally grounded semantic similarity and relatedness datasets for Basque and Spanish.](http://arxiv.org/abs/2304.09616) | 该论文提出了一个基于计算的词语相似性数据集，旨在弥补心理语言学研究中的空白，通过提供大量控制了在词汇处理中起重要作用的变量的名词对的语义相似性的量化。数据集包括巴斯克语和欧洲西班牙语的名词对信息，但进一步的工作意图将其扩展到更多语言。 |
| [^31] | [Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes.](http://arxiv.org/abs/2304.09433) | 本文探讨了使用大型语言模型在不需要特定领域的训练和定制下实现生成可查询表格的简单系统，并给出了两种实现策略，在不同质量和成本中平衡。通过实验证明，该系统对不同类型文档生成的表格均高质量，且无需文档特定的定制。 |
| [^32] | [Low-code LLM: Visual Programming over LLMs.](http://arxiv.org/abs/2304.08103) | 本文介绍了一种新颖的人-LLM交互框架，低代码LLM，该框架可通过六种类型的简单低代码可视化编程交互实现更可控和稳定的响应，具有可控性强、用户友好的交互方式和广泛的应用范围的优点。 |
| [^33] | [Emergence of Symbols in Neural Networks for Semantic Understanding and Communication.](http://arxiv.org/abs/2304.06377) | 本文介绍了一种名为SEA-net的神经网络解决方案，可以生成符号，实现语义理解和交流。这些符号可以捕捉到组成性语义信息，并呈现类似自然语言的内在结构。 |
| [^34] | [Similarity-Aware Multimodal Prompt Learning for Fake News Detection.](http://arxiv.org/abs/2304.04187) | 该论文提出了一种相似度感知的多模态提示学习框架，用于有效融合不同模态信息，实现假新闻检测。所设计的相似度感知融合模块可以量化地根据不同模态之间的相似性权衡每个模态的重要性，有效避免了多模态融合中可能存在的噪声干扰。在两个基准数据集上的实验结果也证明提出的框架实现了最先进的性能，超越了其他强大基线方法。 |
| [^35] | [Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4.](http://arxiv.org/abs/2304.03439) | 本文分析了多个逻辑推理数据集，评估了ChatGPT和GPT-4在逻辑推理任务上的表现，并构造了一个逻辑推理的分布之外的数据集来研究它们的鲁棒性。实验结果显示，ChatGPT在大多数逻辑推理基准测试中的表现远优于RoBERTa微调方法，而GPT-4的表现则更高。 |
| [^36] | [ParroT: Translating During Chat Using Large Language Models.](http://arxiv.org/abs/2304.02426) | ParroT提出了一种基于开源LLM和人工编写的翻译评估数据的聊天翻译框架，可以将翻译数据转化为指令执行样式，并引入额外要求来规范翻译过程。在使用相对较少的训练数据的情况下，实验结果表明 ParroT 可以大幅提高翻译质量。 |
| [^37] | [Hyena Hierarchy: Towards Larger Convolutional Language Models.](http://arxiv.org/abs/2302.10866) | 本文提出一种名为九斑狼的卷积语言模型，通过交错隐式参数化的长卷积和数据控制门构造。在记忆任务和推理任务中，序列有几千到几十万个标记，九斑狼取得了比其他算子更为精确的表现，达到了基于注意力的模型的水平，并取得了密集注意力模型的最新结构。 |
| [^38] | [InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis.](http://arxiv.org/abs/2302.08624) | InstructABSA是一种使用指令学习范式的方面情感分析方法，能够显著提高Aspect Term Extraction、Aspect Term Sentiment Classification、和Joint Task subtasks三个子任务的性能，并且在多个数据集上表现超过之前的最先进方法。 |
| [^39] | ["Correct answers" from the psychology of artificial intelligence.](http://arxiv.org/abs/2302.07267) | 本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。 |
| [^40] | [MEAformer: Multi-modal Entity Alignment Transformer for Meta Modality Hybrid.](http://arxiv.org/abs/2212.14454) | 该论文提出了一种适用于元模态混合的多模式实体对齐变压器方法，通过动态预测模态之间的相互关联系数以进行实体级特征聚合，进一步提出了一种模态感知的硬实体重播策略，用于解决模糊实体细节的问题。该模型在多个训练场景中实现了SOTA性能并有效提高了MMEA的鲁棒性。 |
| [^41] | [BERT Meets CTC: New Formulation of End-to-End Speech Recognition with Pre-trained Masked Language Model.](http://arxiv.org/abs/2210.16663) | 本文提出了BERT-CTC，一种新型的端到端语音识别公式，它利用BERT上下文嵌入获取显式输出依赖性来整合语言知识，并通过自我注意机制关注序列的全部上下文。在实验中表现优于传统方法，语义表示对下游口语理解任务有益作用。 |
| [^42] | [Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear Guarded Attribute Information.](http://arxiv.org/abs/2203.07893) | 这篇论文提出了一种光谱属性去除方法，用于从神经表示中去除私有或保护信息。实验证明，该方法保留了更好的主要任务性能，同时只需少量的被保护属性数据即可去除信息，适用于资源有限的情况。 |
| [^43] | [Media Slant is Contagious.](http://arxiv.org/abs/2202.07269) | 本文研究了国家有线电视新闻对美国本土报纸的影响，发现当地报纸的内容会因为当地 FNC 观众数量的增加而趋向于 FNC 的倾向，并且有线电视倾向会极化地方新闻内容。 |

# 详细

[^1]: 为什么ChatGPT无法准确回答问题？

    Why Does ChatGPT Fall Short in Answering Questions Faithfully?. (arXiv:2304.10513v1 [cs.CL])

    [http://arxiv.org/abs/2304.10513](http://arxiv.org/abs/2304.10513)

    该论文分析了ChatGPT在问答系统中的失误，归纳并确定其失败的原因类型和关键能力，进一步提出了潜在方法来提高其准确性。

    

    最近，大型语言模型，如ChatGPT，展示出对人类生活各方面产生重大影响的巨大潜力。然而，ChatGPT在诚实性等方面仍然面临挑战。以问答系统为代表应用程序，我们试图了解为什么ChatGPT在准确回答问题方面有所不足。为了回答这个问题，我们试图分析ChatGPT在复杂的开放领域问答中失败的原因，并确定与这些失败有关的能力。具体来说，我们将ChatGPT的失败归为四种类型：理解、事实性、具体性和推理。我们进一步确定了与QA失败有关的三个关键能力：知识记忆、知识关联和知识推理。此外，我们还进行了围绕这些能力的实验，并提出了提高准确性的潜在方法。结果表明，向模型提供细粒度的外部知识、给予提示来帮助它聚焦并加强关键能力，这都有助于提高其准确性。

    Recent advancements in Large Language Models, such as ChatGPT, have demonstrated significant potential to impact various aspects of human life. However, ChatGPT still faces challenges in aspects like faithfulness. Taking question answering as a representative application, we seek to understand why ChatGPT falls short in answering questions faithfully. To address this question, we attempt to analyze the failures of ChatGPT in complex open-domain question answering and identifies the abilities under the failures. Specifically, we categorize ChatGPT's failures into four types: comprehension, factualness, specificity, and inference. We further pinpoint three critical abilities associated with QA failures: knowledge memorization, knowledge association, and knowledge reasoning. Additionally, we conduct experiments centered on these abilities and propose potential approaches to enhance faithfulness. The results indicate that furnishing the model with fine-grained external knowledge, hints for
    
[^2]: “我们能检测出物质使用障碍吗？”：来自暗网社交媒体上的知识和时间感知分类研究。(arXiv:2304.10512v1[cs.LG])

    "Can We Detect Substance Use Disorder?": Knowledge and Time Aware Classification on Social Media from Darkweb. (arXiv:2304.10512v1 [cs.LG])

    [http://arxiv.org/abs/2304.10512](http://arxiv.org/abs/2304.10512)

    本研究使用知识感知BERT模型，分析社交媒体上发布的与合成阿片类物质相关的帖子，以了解用户对不同合成阿片类物质的情感和情绪，从而帮助预测物质使用障碍。

    

    目前，美国的阿片类和物质滥用问题日益严重，这种现象被称为“阿片类危机”。物质使用和心理健康之间的关系已经得到了广泛研究，其中一种可能的关系是：物质滥用导致心理健康状况不佳。然而，由于缺乏证据，导致合法途径购买的阿片类物质很难获得。本研究分析了社交媒体上有关物质使用的帖子，重点关注通过加密市场销售的合成阿片类物质。我们使用了药物滥用本体论，最先进的深度学习和知识感知BERT模型生成社交媒体帖子的情感和情绪，以了解用户对社交媒体的看法，研究问题，例如：人们对哪种合成阿片类物质持乐观态度、中立态度或者消极态度？或者哪些药物引起了恐惧和悲伤？人们喜欢哪些药物，或者对哪些药物感激？哪些药物人们持消极态度？

    Opioid and substance misuse is rampant in the United States today, with the phenomenon known as the "opioid crisis". The relationship between substance use and mental health has been extensively studied, with one possible relationship being: substance misuse causes poor mental health. However, the lack of evidence on the relationship has resulted in opioids being largely inaccessible through legal means. This study analyzes the substance use posts on social media with opioids being sold through crypto market listings. We use the Drug Abuse Ontology, state-of-the-art deep learning, and knowledge-aware BERT-based models to generate sentiment and emotion for the social media posts to understand users' perceptions on social media by investigating questions such as: which synthetic opioids people are optimistic, neutral, or negative about? or what kind of drugs induced fear and sorrow? or what kind of drugs people love or are thankful about? or which drugs people think negatively about? or 
    
[^3]: 从外语到欠发达语言中获取新词的初步指南

    A primer on getting neologisms from foreign languages to under-resourced languages. (arXiv:2304.10495v1 [cs.CL])

    [http://arxiv.org/abs/2304.10495](http://arxiv.org/abs/2304.10495)

    本文介绍了一种从外语到欠发达语言获取新词的初步指南，提出可以引入任何语言的新词，只要这些词语“听起来像”目标语言的本地单词。

    

    由于缺乏支持，大多数欠发达语言在大多数领域和领域中的词汇量都很少，而其使用者需要大量增加词汇量。虽然新词应该从语言本身产生，但外部来源被广泛接受。然而，我们对使用被强加的官方语言的“常识”提出了质疑，这些语言很可能是殖民主义的遗产，作为唯一的来源，我们提出了引入任何语言的新词，只要这些新词“听起来像”目标语言的本地单词。

    Mainly due to lack of support, most under-resourced languages have a reduced lexicon in most realms and domains of increasing importance, then their speakers need to significantly augment it. Although neologisms should arise from the languages themselves, external sources are widely accepted. However, we dispute the "common sense" of using the imposed official languages, which are highly probably a legacy of colonialism, as the only source, and we propose to introduce neologisms from any language as long as these neologisms "sound like" native words of the target languages.
    
[^4]: 用自然语言学习编程

    Learning to Program with Natural Language. (arXiv:2304.10464v1 [cs.CL])

    [http://arxiv.org/abs/2304.10464](http://arxiv.org/abs/2304.10464)

    该论文提出了一种用自然语言作为编程语言并通过学习编程方法让大语言模型直接生成自然语言程序并指导推理的方法。实验结果表明，这种方法在解决编程任务上比基线方法有更高的成功率。

    

    大语言模型在各种基本自然语言任务中表现出卓越性能，这引起了实现人工通用智能的希望。为了更好地完成复杂任务，我们需要利用大语言模型进行编程，然后按照程序生成特定的解决方案。我们提出使用自然语言作为一种新的编程语言来描述任务过程，使它们易于人类和大语言模型理解。虽然大语言模型能够直接生成自然语言程序，但这些程序可能仍然存在错误或不完整的步骤。因此，我们进一步提出了学习编程（LP）的方法，要求大语言模型从复杂任务的训练数据集中学习自然语言程序，然后使用学习到的程序来指导推理。我们在AMPS（高中数学）和Math（竞赛数学问题）数据集上的实验证明了我们方法的有效性。在测试ChatGP解决编程任务时，LP能够实现80%的成功率，优于基线方法。

    Large Language Models (LLMs) have shown remarkable performance in various basic natural language tasks, which raises hopes for achieving Artificial General Intelligence. To better complete complex tasks, we need LLMs to program for the task and then follow the program to generate a specific solution for the test sample. We propose using natural language as a new programming language to describe task procedures, making them easily understandable to both humans and LLMs. LLMs are capable of directly generating natural language programs, but these programs may still contain factual errors or incomplete steps. Therefore, we further propose the Learning to Program (LP) method to ask LLMs themselves to learn natural language programs from the training dataset of complex tasks and then use the learned program to guide inference. Our experiments on the AMPS (high school math) and Math (competition mathematics problems) datasets demonstrate the effectiveness of our approach. When testing ChatGP
    
[^5]: Phoenix: 实现 ChatGPT 的跨语言民主化

    Phoenix: Democratizing ChatGPT across Languages. (arXiv:2304.10453v1 [cs.CL])

    [http://arxiv.org/abs/2304.10453](http://arxiv.org/abs/2304.10453)

    Phoenix 是一款大型语言模型，实现了跨语言民主化，不仅在英文和中文中表现良好，也在资源有限的语言中表现出色，使得 ChatGPT 在更多的国家和地区变得更加可用。

    

    本文介绍了我们努力实现 ChatGPT 跨语言民主化的工作。我们发布了一款大型语言模型“Phoenix”，在开源的英文和中文模型中实现了有竞争力的性能，并在资源有限的语言（包括拉丁和非拉丁语言）中表现出色。我们相信这项工作将有利于让 ChatGPT 在更多的国家和地区变得更加可用，特别是在由于OpenAI或当地政府的限制而无法使用ChatGPT的国家。

    This paper presents our efforts to democratize ChatGPT across language. We release a large language model "Phoenix", achieving competitive performance among open-source English and Chinese models while excelling in languages with limited resources (covering both Latin and non-Latin languages). We believe this work will be beneficial to make ChatGPT more accessible, especially in countries where people cannot use ChatGPT due to restrictions from OpenAI or local goverments. Our data, code, and models are available at https://github.com/FreedomIntelligence/LLMZoo.
    
[^6]: 面向心理健康的语言模型继续预训练以捕获长上下文

    Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health. (arXiv:2304.10447v1 [cs.CL])

    [http://arxiv.org/abs/2304.10447](http://arxiv.org/abs/2304.10447)

    本文在心理健康领域进行了继续预训练以捕捉长上下文。作者基于XLNet和Longformer训练和发布了MentalXLNet和MentalLongformer模型，并对其进行了性能评估和能力测试。这些模型对于早期心理健康问题的检测非常有用。

    

    预训练语言模型已被用于各种自然语言处理应用。在心理健康领域，预训练的领域特定语言模型被释放，有助于早期发现心理健康问题。社交媒体帖子（例如 Reddit）通常都很长。然而，在心理健康领域中并没有面向长序列的领域特定预训练模型。本文进行了面向心理健康的继续预训练，以捕捉长上下文。具体而言，我们基于 XLNet 和 Longformer 训练并发布了 MentalXLNet 和 MentalLongformer。我们评估了这两个领域特定预训练模型的心理健康分类性能和长距离建模能力。我们的模型已在 HuggingFace 上发布。

    Pretrained language models have been used in various natural language processing applications. In the mental health domain, domain-specific language models are pretrained and released, which facilitates the early detection of mental health conditions. Social posts, e.g., on Reddit, are usually long documents. However, there are no domain-specific pretrained models for long-sequence modeling in the mental health domain. This paper conducts domain-specific continued pretraining to capture the long context for mental health. Specifically, we train and release MentalXLNet and MentalLongformer based on XLNet and Longformer. We evaluate the mental health classification performance and the long-range ability of these two domain-specific pretrained models. Our models are released in HuggingFace.
    
[^7]: 中国大型语言模型的安全评估

    Safety Assessment of Chinese Large Language Models. (arXiv:2304.10436v1 [cs.CL])

    [http://arxiv.org/abs/2304.10436](http://arxiv.org/abs/2304.10436)

    该论文介绍了中国大型语言模型的安全评估，提出一种基于8种典型安全场景和6种更具挑战性指令攻击的综合安全性能评估基准，利用LLMs的强大评估能力开发并量化了评估模型的安全性能。

    

    随着诸如ChatGPT和GPT-4等大型语言模型的迅速普及，人们越来越关注它们的安全问题。这些模型可能生成侮辱性和歧视性内容，反映不正确的社会价值观，并可能被用于欺诈和传播误导信息等恶意用途。评估和增强它们的安全性对于广泛应用大型语言模型(LLMs)尤为重要。为进一步促进LLMs的安全部署,我们开发了一个中国LLM安全评估基准。我们的基准从8种典型的安全场景和6种更具挑战性的指令攻击两个方面探索LLMs的综合安全性能。我们的基准是基于一个简单明了的过程，其中它提供测试提示并评估从评估模型产生的响应的安全性。在评估中，我们利用LLMs的强大评估能力，并将其开发为一种安全评估工具，以量化评估模型的安全性能。实验结果表明，我们的基准对于评估和比较不同的中文LLMs的安全性能是有效和可靠的。

    With the rapid popularity of large language models such as ChatGPT and GPT-4, a growing amount of attention is paid to their safety concerns. These models may generate insulting and discriminatory content, reflect incorrect social values, and may be used for malicious purposes such as fraud and dissemination of misleading information. Evaluating and enhancing their safety is particularly essential for the wide application of large language models (LLMs). To further promote the safe deployment of LLMs, we develop a Chinese LLM safety assessment benchmark. Our benchmark explores the comprehensive safety performance of LLMs from two perspectives: 8 kinds of typical safety scenarios and 6 types of more challenging instruction attacks. Our benchmark is based on a straightforward process in which it provides the test prompts and evaluates the safety of the generated responses from the evaluated model. In evaluation, we utilize the LLM's strong evaluation ability and develop it as a safety ev
    
[^8]: GPT-NER：基于大型语言模型的命名实体识别

    GPT-NER: Named Entity Recognition via Large Language Models. (arXiv:2304.10428v1 [cs.CL])

    [http://arxiv.org/abs/2304.10428](http://arxiv.org/abs/2304.10428)

    本文提出了GPT-NER来解决大型语言模型在命名实体识别任务（NER）上表现不佳的问题，它通过将序列标记任务转化为生成任务，将LLM能够容易地适应NER任务。同时，为了有效解决LLMs“幻觉”问题，作者们提出了自我验证策略，通过提示LLMs询问自身来确定提取的实体是否属于实际存在的实体。

    

    尽管大规模语言模型（LLM）在各种NLP任务上已经实现了最先进的性能，但其NER性能仍然明显低于监督基线。这是由于命名实体识别（NER）和LLMs之间的差距：前者在本质上是序列标记任务，后者是一种文本生成模型。在本文中，我们提出了GPT-NER来解决这个问题。 GPT-NER通过将序列标记任务转换为生成任务来弥合差距，LLMs可以轻松适应。例如，将在输入文本“哥伦布是一座城市”中查找位置实体的任务转换为生成文本序列“@@哥伦布##是一座城市”，其中特殊标记@@##标记要提取的实体。为了有效解决LLMs“幻觉”问题，即LLMs有很强的倾向将空输入过度自信地标记为实体，我们提出了自我验证策略，通过提示LLMs询问自身来确定提取的实体是否属于实际存在的实体。

    Despite the fact that large-scale Language Models (LLM) have achieved SOTA performances on a variety of NLP tasks, its performance on NER is still significantly below supervised baselines. This is due to the gap between the two tasks the NER and LLMs: the former is a sequence labeling task in nature while the latter is a text-generation model.  In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the gap by transforming the sequence labeling task to a generation task that can be easily adapted by LLMs e.g., the task of finding location entities in the input text "Columbus is a city" is transformed to generate the text sequence "@@Columbus## is a city", where special tokens @@## marks the entity to extract. To efficiently address the "hallucination" issue of LLMs, where LLMs have a strong inclination to over-confidently label NULL inputs as entities, we propose a self-verification strategy by prompting LLMs to ask itself whether the extracted entities belong to a lab
    
[^9]: CKBP v2：一个通识知识库填充的专家注释评估集合

    CKBP v2: An Expert-Annotated Evaluation Set for Commonsense Knowledge Base Population. (arXiv:2304.10392v1 [cs.CL])

    [http://arxiv.org/abs/2304.10392](http://arxiv.org/abs/2304.10392)

    本文介绍了CKBP v2, 一个使用专家注释而囊括对抗样本的高质量通识知识库填充基准，以解决CKBP v1由于众包注释和随机抽样导致的问题。实验结果表明，通识知识库填充任务对于现有技术水平仍然具有挑战性。

    

    填充通识知识库是NLP中一个重要但困难的任务，因为它处理外部来源、未见过的事件和实体的知识。 Fang等人提出了一个通识知识库填充基准，其中包括评估集CKBP v1。但是，CKBP v1采用由众包注释，存在相当大比例的错误答案，并且由于随机抽样，评估集与外部知识来源的对齐效果不佳。在本文中，我们引入了CKBP v2，一个新的高质量的通识知识库填充基准，通过使用专家而不是众包注释，并添加多样化的对抗样本来使评估集更具代表性来解决上述两个问题。我们在新的评估集上进行了各种实验，比较了用于通识知识库填充的最新方法，以用于未来的研究比较。实证结果表明，即使对于大型语言模型（LLM），填充任务仍然具有挑战性。

    Populating Commonsense Knowledge Bases (CSKB) is an important yet hard task in NLP, as it tackles knowledge from external sources with unseen events and entities. Fang et al. (2021a) proposed a CSKB Population benchmark with an evaluation set CKBP v1. However, CKBP v1 adopts crowdsourced annotations that suffer from a substantial fraction of incorrect answers, and the evaluation set is not well-aligned with the external knowledge source as a result of random sampling. In this paper, we introduce CKBP v2, a new high-quality CSKB Population benchmark, which addresses the two mentioned problems by using experts instead of crowd-sourced annotation and by adding diversified adversarial samples to make the evaluation set more representative. We conduct extensive experiments comparing state-of-the-art methods for CSKB Population on the new evaluation set for future research comparisons. Empirical results show that the population task is still challenging, even for large language models (LLM) 
    
[^10]: 跨语言关系抽取中的Prompt学习

    Prompt-Learning for Cross-Lingual Relation Extraction. (arXiv:2304.10354v1 [cs.CL])

    [http://arxiv.org/abs/2304.10354](http://arxiv.org/abs/2304.10354)

    本文提出了一种新型的XRE算法Prompt-XRE，基于Prompt调优方法，它能够有效提高多语种预训练语言模型在跨语言环境下的表现。

    

    关系抽取(RE)是信息提取中的关键任务，涉及预测给定句子中实体之间的关系。然而，将预先训练好的RE模型扩展到其他语言是具有挑战性的，特别是在需要进行跨语言关系抽取(XRE)的实际场景中。本文介绍了一种基于Prompt调优的新型XRE算法，称为Prompt-XRE。为了评估其有效性，我们设计并实现了几个Prompt模板，包括硬Prompt、软Prompt和混合Prompt，并在竞争性多语种PLM（特别是mBART）上进行了实证测试。我们在低资源ACE05基准测试上进行了大量实验，涵盖多种语言。

    Relation Extraction (RE) is a crucial task in Information Extraction, which entails predicting relationships between entities within a given sentence. However, extending pre-trained RE models to other languages is challenging, particularly in real-world scenarios where Cross-Lingual Relation Extraction (XRE) is required. Despite recent advancements in Prompt-Learning, which involves transferring knowledge from Multilingual Pre-trained Language Models (PLMs) to diverse downstream tasks, there is limited research on the effective use of multilingual PLMs with prompts to improve XRE. In this paper, we present a novel XRE algorithm based on Prompt-Tuning, referred to as Prompt-XRE. To evaluate its effectiveness, we design and implement several prompt templates, including hard, soft, and hybrid prompts, and empirically test their performance on competitive multilingual PLMs, specifically mBART. Our extensive experiments, conducted on the low-resource ACE05 benchmark across multiple language
    
[^11]: 高维干预探测：一项自然语言推理案例研究

    Interventional Probing in High Dimensions: An NLI Case Study. (arXiv:2304.10346v1 [cs.CL])

    [http://arxiv.org/abs/2304.10346](http://arxiv.org/abs/2304.10346)

    本文利用表示级干预进行了自然语言推理任务中中间语义特征对分类结果的影响研究，包括健忘探测及遗忘-记忆探测变体，为之后的干预探测提供了重要指导意义。

    

    探测策略已被证明可以检测大型语言模型中各种语言特征的存在；特别是作为自然语言推理任务（NLI）的“自然逻辑”片段的中间语义特征。在自然逻辑中，中间特征与蕴含标签之间的关系是明确知晓的：因此，这为对NLI模型表示进行干预研究提供了成熟的设置，从而能够提供更强的因果假说和对干预探测方法进行更深入的批判性分析。在这项工作中，我们进行新的和现有的表示级干预，以研究这些语义特征对NLI分类的影响：我们执行了健忘探测（根据学习的线性探测器删除特征），并引入了遗忘-记忆探测变体（除了探测器选择的特征外，遗忘所有维度）。此外，我们深入探讨了这些方法的局限性，并概述了一些可能的改进方向。

    Probing strategies have been shown to detect the presence of various linguistic features in large language models; in particular, semantic features intermediate to the "natural logic" fragment of the Natural Language Inference task (NLI). In the case of natural logic, the relation between the intermediate features and the entailment label is explicitly known: as such, this provides a ripe setting for interventional studies on the NLI models' representations, allowing for stronger causal conjectures and a deeper critical analysis of interventional probing methods. In this work, we carry out new and existing representation-level interventions to investigate the effect of these semantic features on NLI classification: we perform amnesic probing (which removes features as directed by learned linear probes) and introduce the mnestic probing variation (which forgets all dimensions except the probe-selected ones). Furthermore, we delve into the limitations of these methods and outline some pi
    
[^12]: 向着人类和机器科学理解的基准迈进

    Towards a Benchmark for Scientific Understanding in Humans and Machines. (arXiv:2304.10327v1 [cs.AI])

    [http://arxiv.org/abs/2304.10327](http://arxiv.org/abs/2304.10327)

    该论文提出了一个框架来创建衡量人类和人工智能科学理解的基准。他们使用了行为观念，提出了一组问题以衡量不同水平的科学理解。这个框架可以帮助评估和比较不同水平和方法的科学理解。

    

    科学理解是科学的基本目标，它使我们能够解释世界。目前还没有好的方法来衡量代理人的科学理解，无论它们是人类还是人工智能系统。缺乏清晰的基准，难以评估和比较不同水平和方法的科学理解。在此路线图中，我们提出了一个框架，利用科学哲学工具创建科学理解的基准。我们采用行为观念，认为真正的理解应该被认为是执行某些任务的能力。我们通过考虑一组问题来扩展这个概念，这些问题可以衡量不同水平的科学理解，包括信息检索，安排信息以生成解释的能力以及在不同情况下推断事物会有哪些不同。Scientific Understanding Benchmark（SUB）由

    Scientific understanding is a fundamental goal of science, allowing us to explain the world. There is currently no good way to measure the scientific understanding of agents, whether these be humans or Artificial Intelligence systems. Without a clear benchmark, it is challenging to evaluate and compare different levels of and approaches to scientific understanding. In this Roadmap, we propose a framework to create a benchmark for scientific understanding, utilizing tools from philosophy of science. We adopt a behavioral notion according to which genuine understanding should be recognized as an ability to perform certain tasks. We extend this notion by considering a set of questions that can gauge different levels of scientific understanding, covering information retrieval, the capability to arrange information to produce an explanation, and the ability to infer how things would be different under different circumstances. The Scientific Understanding Benchmark (SUB), which is formed by 
    
[^13]: 基于跨模态多粒度对比学习的语音翻译模型优化

    Improving Speech Translation by Cross-Modal Multi-Grained Contrastive Learning. (arXiv:2304.10309v1 [cs.CL])

    [http://arxiv.org/abs/2304.10309](http://arxiv.org/abs/2304.10309)

    本文提出了基于跨模态多粒度对比学习的语音翻译模型优化方法，该方法通过跨模态多粒度对比学习进行显式知识转移，并在E2E-ST和MT任务上都取得了显著的改进。

    

    由于低延迟和误差传播少，端到端语音翻译（E2E-ST）模型已成为主流的范例。然而，由于任务复杂性和数据稀缺性，训练这样的模型并不容易。由于语音和文本MODALITY的差异，E2E-ST模型的性能通常比相应的机器翻译（MT）模型稍逊。现有方法通常通过施加各种约束来使用共享机制进行隐式知识转移。然而，最终的模型在MT任务上的表现往往比单独训练的MT模型还要差，这意味着这种方法的知识转移能力也是有限的。为了解决这些问题，我们提出了适用于E2E-ST的FCCL（Fine- and Coarse- Granularity Contrastive Learning）方法，它通过跨模态多粒度对比学习进行显式知识转移。我们方法的一个关键组成部分是在多个粒度级别上对编码器输出和解码器输入进行对比学习。具体而言，我们对语音编码器输出和文本解码器输入进行精细和粗粒度的对比学习。此外，我们引入了一种支持E2E-ST和MT模型同时优化的多任务学习方案。实验结果表明，我们的方法在E2E-ST任务和MT任务上均取得了显著的改进，并且在MuST-C基准测试中表现优于现有技术水平。

    The end-to-end speech translation (E2E-ST) model has gradually become a mainstream paradigm due to its low latency and less error propagation. However, it is non-trivial to train such a model well due to the task complexity and data scarcity. The speech-and-text modality differences result in the E2E-ST model performance usually inferior to the corresponding machine translation (MT) model. Based on the above observation, existing methods often use sharingmechanisms to carry out implicit knowledge transfer by imposing various constraints. However, the final model often performs worse on the MT task than the MT model trained alone, which means that the knowledge transfer ability of this method is also limited. To deal with these problems, we propose the FCCL (Fine- and Coarse- Granularity Contrastive Learning) approach for E2E-ST, which makes explicit knowledge transfer through cross-modal multi-grained contrastive learning. A key ingredient of our approach is applying contrastive learni
    
[^14]: 解离非参数知识蒸馏来达到端到端语音翻译

    Decouple Non-parametric Knowledge Distillation For End-to-end Speech Translation. (arXiv:2304.10295v1 [cs.CL])

    [http://arxiv.org/abs/2304.10295](http://arxiv.org/abs/2304.10295)

    本文提出了一种新方法，从数据角度提高了语音翻译模型的数据效率，而不需要转录数据。该方法解离了非参数知识蒸馏，通过构建教师分布来达到知识转移的目的。

    

    现有技术通常尝试通过一些复杂的技术，将强大的机器翻译(MT)向语音翻译(ST)模型进行知识转移，但这往往需要在训练期间作为额外输入来记录。然而，并不总是有转录数据可用，如何在没有转录的情况下提高ST模型的性能，即数据效率，在文献中很少被研究。在本文中，我们从数据角度提出了解离非参数知识蒸馏(DNKD)来提高数据效率。我们的方法遵循知识蒸馏范式。但是，我们构建它的教师分布，而不是从复杂的MT模型中获得它，而是通过kNN检索从非参数数据存储中获得它，这消除了对转录和MT模型的依赖。然后，我们将经典的知识蒸馏损失分为目标和非目标蒸馏，以增强非目标logit之间的知识效果。

    Existing techniques often attempt to make knowledge transfer from a powerful machine translation (MT) to speech translation (ST) model with some elaborate techniques, which often requires transcription as extra input during training. However, transcriptions are not always available, and how to improve the ST model performance without transcription, i.e., data efficiency, has rarely been studied in the literature. In this paper, we propose Decoupled Non-parametric Knowledge Distillation (DNKD) from data perspective to improve the data efficiency. Our method follows the knowledge distillation paradigm. However, instead of obtaining the teacher distribution from a sophisticated MT model, we construct it from a non-parametric datastore via k-Nearest-Neighbor (kNN) retrieval, which removes the dependence on transcription and MT model. Then we decouple the classic knowledge distillation loss into target and non-target distillation to enhance the effect of the knowledge among non-target logit
    
[^15]: 数据增强对不平衡文本数据集预测的有效性研究

    Is augmentation effective to improve prediction in imbalanced text datasets?. (arXiv:2304.10283v1 [cs.CL])

    [http://arxiv.org/abs/2304.10283](http://arxiv.org/abs/2304.10283)

    本文研究发现，通过调整分类器截断点而不进行数据增强可以在不平衡数据集上得到类似于过采样技术的结果，为处理不平衡数据提供了一种新的思路。

    

    不平衡数据集对机器学习模型构成了重大挑战，往往导致预测有偏。为了解决这个问题，自然语言处理（NLP）中广泛使用数据增强技术为少数类生成新样本。然而，在本文中，我们质疑了数据增强总是必要来提高不平衡数据集预测的常见假设。相反，我们认为通过调整分类器截断点而不进行数据增强可以产生与过采样技术类似的结果。我们的研究提供了理论和实证证据支持这一主张。我们的发现有助于更好地了解处理不平衡数据的不同方法的优势和局限性，并帮助研究人员和实践者为给定任务做出明智的决策。

    Imbalanced datasets present a significant challenge for machine learning models, often leading to biased predictions. To address this issue, data augmentation techniques are widely used in natural language processing (NLP) to generate new samples for the minority class. However, in this paper, we challenge the common assumption that data augmentation is always necessary to improve predictions on imbalanced datasets. Instead, we argue that adjusting the classifier cutoffs without data augmentation can produce similar results to oversampling techniques. Our study provides theoretical and empirical evidence to support this claim. Our findings contribute to a better understanding of the strengths and limitations of different approaches to dealing with imbalanced data, and help researchers and practitioners make informed decisions about which methods to use for a given task.
    
[^16]: 基于K-center对比学习和可调决策边界的有效开放意图分类

    Effective Open Intent Classification with K-center Contrastive Learning and Adjustable Decision Boundary. (arXiv:2304.10220v1 [cs.CL])

    [http://arxiv.org/abs/2304.10220](http://arxiv.org/abs/2304.10220)

    本文介绍了基于K-center对比学习和可调决策边界学习(CLAB)的开放意图分类方法，通过预训练得到知识迁移，并用K-center对比学习算法学习出区分性和平衡性的意图特征，同时使用可调边界学习方法确定合适的决策条件。

    

    开放意图分类旨在将已知意图正确分类到它们相应的类别中，同时识别新的未知(开放)意图，在对话系统中是一项重要但具有挑战性的任务。本文引入了新颖的K-center对比学习和可调决策边界学习(CLAB)来提高开放意图分类的效果。

    Open intent classification, which aims to correctly classify the known intents into their corresponding classes while identifying the new unknown (open) intents, is an essential but challenging task in dialogue systems. In this paper, we introduce novel K-center contrastive learning and adjustable decision boundary learning (CLAB) to improve the effectiveness of open intent classification. First, we pre-train a feature encoder on the labeled training instances, which transfers knowledge from known intents to unknown intents. Specifically, we devise a K-center contrastive learning algorithm to learn discriminative and balanced intent features, improving the generalization of the model for recognizing open intents. Second, we devise an adjustable decision boundary learning method with expanding and shrinking (ADBES) to determine the suitable decision conditions. Concretely, we learn a decision boundary for each known intent class, which consists of a decision center and the radius of the
    
[^17]: 探究基于 Paracrawl 的文档级神经机器翻译

    Exploring Paracrawl for Document-level Neural Machine Translation. (arXiv:2304.10216v1 [cs.CL])

    [http://arxiv.org/abs/2304.10216](http://arxiv.org/abs/2304.10216)

    本文研究了使用 Paracrawl 平行语料库提取平行段落训练文档级翻译模型的有效性。

    

    文档级神经机器翻译在许多数据集上的性能已经超过了句子级神经机器翻译。然而，由于缺乏大规模通用领域的文档级训练数据，文档级翻译仍然没有被广泛采用于实际的翻译系统中。本文研究了使用 Paracrawl 来学习文档级翻译的有效性。Paracrawl 是一种大规模从互联网上爬取的平行语料库，包含来自各种领域的数据。在本文中，我们使用自动句子对齐从 Paracrawl 平行网页中提取平行段落，并将提取的平行段落用作训练文档级翻译模型的平行文档。我们展示了仅使用来自 Paracrawl 的平行段落训练的文档级 NMT 模型的性能。

    Document-level neural machine translation (NMT) has outperformed sentence-level NMT on a number of datasets. However, document-level NMT is still not widely adopted in real-world translation systems mainly due to the lack of large-scale general-domain training data for document-level NMT. We examine the effectiveness of using Paracrawl for learning document-level translation. Paracrawl is a large-scale parallel corpus crawled from the Internet and contains data from various domains. The official Paracrawl corpus was released as parallel sentences (extracted from parallel webpages) and therefore previous works only used Paracrawl for learning sentence-level translation. In this work, we extract parallel paragraphs from Paracrawl parallel webpages using automatic sentence alignments and we use the extracted parallel paragraphs as parallel documents for training document-level translation models. We show that document-level NMT models trained with only parallel paragraphs from Paracrawl c
    
[^18]: CoT-MoTE：探索基于文本专家混合的上下文掩码自编码器预训练在段落检索中的应用

    CoT-MoTE: Exploring ConTextual Masked Auto-Encoder Pre-training with Mixture-of-Textual-Experts for Passage Retrieval. (arXiv:2304.10195v1 [cs.CL])

    [http://arxiv.org/abs/2304.10195](http://arxiv.org/abs/2304.10195)

    本文提出了一种在段落检索中采用基于文本专家混合的上下文掩码自编码器预训练的新方法，可以有效改进嵌入空间的判别效果。

    

    段落检索旨在从大规模开放式语料库中检索相关段落。上下文掩码自编码器在单体双编码器的表示瓶颈预训练中证明有效，并常常被采用为基本的检索架构，在预训练和微调阶段中将查询和段落编码为它们的潜在嵌入空间。然而，简单地共享或分离双编码器的参数会导致嵌入空间的不平衡判别。本文中，我们提出了一种预先训练具有文本专家混合的上下文掩码自编码器（CoT-MoTE）。具体来说，我们为查询和段落的不同属性分别编码文本特定的专家。同时，仍保留一个共享的自我注意层，用于统一的注意建模。对大规模段落检索基准测试的结果显示稳定的改进。

    Passage retrieval aims to retrieve relevant passages from large collections of the open-domain corpus. Contextual Masked Auto-Encoding has been proven effective in representation bottleneck pre-training of a monolithic dual-encoder for passage retrieval. Siamese or fully separated dual-encoders are often adopted as basic retrieval architecture in the pre-training and fine-tuning stages for encoding queries and passages into their latent embedding spaces. However, simply sharing or separating the parameters of the dual-encoder results in an imbalanced discrimination of the embedding spaces. In this work, we propose to pre-train Contextual Masked Auto-Encoder with Mixture-of-Textual-Experts (CoT-MoTE). Specifically, we incorporate textual-specific experts for individually encoding the distinct properties of queries and passages. Meanwhile, a shared self-attention layer is still kept for unified attention modeling. Results on large-scale passage retrieval benchmarks show steady improvemen
    
[^19]: 分析FOMC会议记录：语言模型的准确性和限制。

    Analyzing FOMC Minutes: Accuracy and Constraints of Language Models. (arXiv:2304.10164v1 [cs.CL])

    [http://arxiv.org/abs/2304.10164](http://arxiv.org/abs/2304.10164)

    该研究分析了FOMC官方声明中使用的语言，采用VADER和FinBERT等模型预测负面情绪，结果显示FinBERT表现相对更好。但是，该研究也强调了使用当前NLP技术分析FOMC文本的挑战和限制，建议增强语言模型并探索替代方法。

    

    本研究论文分析了联邦公开市场委员会（FOMC）在其定期会议后发布的官方声明中使用的语言，以获取有关FOMC官方声明对金融市场和经济预测的影响的见解。研究发现，FOMC小心避免在句子中表达情感，并遵循一套模板来覆盖经济情况。该分析采用了VADER和FinBERT等先进的语言建模技术，以及使用GPT-4的试验测试。结果表明，在准确预测负面情绪方面，FinBERT的表现优于其他技术。然而，研究还强调了使用当前NLP技术分析FOMC文本的挑战和限制，并建议增强语言模型并探索替代方法的潜力。

    This research article analyzes the language used in the official statements released by the Federal Open Market Committee (FOMC) after its scheduled meetings to gain insights into the impact of FOMC official statements on financial markets and economic forecasting. The study reveals that the FOMC is careful to avoid expressing emotion in their sentences and follows a set of templates to cover economic situations. The analysis employs advanced language modeling techniques such as VADER and FinBERT, and a trial test with GPT-4. The results show that FinBERT outperforms other techniques in predicting negative sentiment accurately. However, the study also highlights the challenges and limitations of using current NLP techniques to analyze FOMC texts and suggests the potential for enhancing language models and exploring alternative approaches.
    
[^20]: 前置语言模型的标记方法能否促进跨语言转移？一个非标准化语言词性标注研究

    Does Manipulating Tokenization Aid Cross-Lingual Transfer? A Study on POS Tagging for Non-Standardized Languages. (arXiv:2304.10158v1 [cs.CL])

    [http://arxiv.org/abs/2304.10158](http://arxiv.org/abs/2304.10158)

    本研究探讨了微调预训练语言模型在非标准化语言上的词性标注的问题，发现通过调整标记化方法可以提高模型在跨语言转移方面的性能。

    

    微调预训练语言模型（PLM）的一个挑战是，它们的标记器虽然针对预训练语言进行了优化，但在处理以前没有见过的数据变化时容易出问题。当在一个语言上进行微调并在没有标准正字法的密切相关语言变体的数据上进行评估时，就会出现这种情况。尽管两种语言具有高度相似性，但标记化不再对目标数据的有意义表征相对应，导致部分语音标注等性能下降。在这项工作中，我们微调了来自三个不同家族的七种语言的 PLM，并分析了它们在密切相关的非标准化语言变体上的零样本表现。我们考虑了不同的标记化源和目标数据差异度量方式以及在微调过程中调整它们的方式。总的来说，我们发现通过调整标记化方法可以在跨语言转移方面提高 PLM 的性能。

    One of the challenges with finetuning pretrained language models (PLMs) is that their tokenizer is optimized for the language(s) it was pretrained on, but brittle when it comes to previously unseen variations in the data. This can for instance be observed when finetuning PLMs on one language and evaluating them on data in a closely related language variety with no standardized orthography. Despite the high linguistic similarity, tokenization no longer corresponds to meaningful representations of the target data, leading to low performance in, e.g., part-of-speech tagging.  In this work, we finetune PLMs on seven languages from three different families and analyze their zero-shot performance on closely related, non-standardized varieties. We consider different measures for the divergence in the tokenization of the source and target data, and the way they can be adjusted by manipulating the tokenization during the finetuning step. Overall, we find that the similarity between the percenta
    
[^21]: 论语言模型中的联想偏差与实证公正的独立性

    On the Independence of Association Bias and Empirical Fairness in Language Models. (arXiv:2304.10153v1 [cs.CL])

    [http://arxiv.org/abs/2304.10153](http://arxiv.org/abs/2304.10153)

    本文探讨了预先训练的语言模型中联想偏差和实证公正的关系，通过理论实验和实证研究证明了两者可以是独立的。本文呼吁采用实证公正的模型开发方法并减少表示偏差。

    

    预先训练的语言模型的社会影响促使研究人员探索它们之间是否存在受保护属性和价值负载术语之间的强关联，从蔑称到享有声望的职位名称等。这样的工作被认为是探索模型的偏差或公平性，或者这种探测 "表征偏差 "的工作被认为是 "基于公平性的 "——这表明了偏差和公平性之间的密切联系。我们通过区分联想偏差和实证公正来提供概念上的清晰度，并展示了两者可以是独立的。然而，我们的主要贡献在于展示了为什么这不应该让人感到惊讶。为此，我们首先提供了一个思想实验，展示了联想偏见和实证公正可以完全独立。接下来，我们提供了经验证据，表明在最广泛使用的语言模型中，偏差指标和公平指标之间不存在相关性。最后，我们调查了社会和心理学文献，勾勒出了联想偏差在语言使用中的普遍存在以及解决它们的重要性。我们最后提出呼吁，关注降低表示偏差和采用实证公正模型开发的做法。

    The societal impact of pre-trained language models has prompted researchers to probe them for strong associations between protected attributes and value-loaded terms, from slur to prestigious job titles. Such work is said to probe models for bias or fairness-or such probes 'into representational biases' are said to be 'motivated by fairness'-suggesting an intimate connection between bias and fairness. We provide conceptual clarity by distinguishing between association biases (Caliskan et al., 2022) and empirical fairness (Shen et al., 2022) and show the two can be independent. Our main contribution, however, is showing why this should not come as a surprise. To this end, we first provide a thought experiment, showing how association bias and empirical fairness can be completely orthogonal. Next, we provide empirical evidence that there is no correlation between bias metrics and fairness metrics across the most widely used language models. Finally, we survey the sociological and psychol
    
[^22]: ChatGPT能否复制人类生成的标签？对社交计算任务的研究

    Can ChatGPT Reproduce Human-Generated Labels? A Study of Social Computing Tasks. (arXiv:2304.10145v1 [cs.AI])

    [http://arxiv.org/abs/2304.10145](http://arxiv.org/abs/2304.10145)

    本文研究了ChatGPT在社交计算任务中是否可以复制人类生成的标签注释，结果表明ChatGPT有潜力处理这些数据注释任务，尽管仍存在许多挑战。

    

    ChatGPT的发布揭示了语言模型可以取代人类智慧的各种可能性。本文旨在了解ChatGPT是否有潜力在社交计算任务中复制人类生成的标签注释。这样的成就可以显著降低社交计算研究的成本和复杂性。因此，我们使用ChatGPT重新标记了五个具有里程碑意义的数据集，涉及立场检测（2个）、情感分析、仇恨言论和机器人检测。我们的结果表明，ChatGPT有潜力处理这些数据注释任务，尽管仍存在许多挑战。ChatGPT获得了平均精度0.609。 ChatGPT对情感分析数据集的表现最佳，正确注释了64.9％的推文。然而，我们显示性能在不同标签之间有很大差异。我们认为这项工作可以开辟新的分析线路，并作为未来利用ChatGPT进行数据注释的基础。

    The release of ChatGPT has uncovered a range of possibilities whereby large language models (LLMs) can substitute human intelligence. In this paper, we seek to understand whether ChatGPT has the potential to reproduce human-generated label annotations in social computing tasks. Such an achievement could significantly reduce the cost and complexity of social computing research. As such, we use ChatGPT to re-label five seminal datasets covering stance detection (2x), sentiment analysis, hate speech, and bot detection. Our results highlight that ChatGPT does have the potential to handle these data annotation tasks, although a number of challenges remain. ChatGPT obtains an average precision 0.609. Performance is highest for the sentiment analysis dataset, with ChatGPT correctly annotating 64.9% of tweets. Yet, we show that performance varies substantially across individual labels. We believe this work can open up new lines of analysis and act as a basis for future research into the exploi
    
[^23]: 支持人工智能协作审计LLM的LLM

    Supporting Human-AI Collaboration in Auditing LLMs with LLMs. (arXiv:2304.09991v1 [cs.HC])

    [http://arxiv.org/abs/2304.09991](http://arxiv.org/abs/2304.09991)

    本论文通过对安全和公正人工智能专家的采访以及对人工智能协作和感知文献的研究，增强了“AdaTest”审计工具，这个工具可以通过利用人和生成模型的协同优势，进行更严格的大型语言模型审计。

    

    大型语言模型通过部署在社会技术系统中变得越来越普遍和普及。然而，这些语言模型，无论是用于分类还是生成，都表现出有偏差和不负责任的行为，对人类造成了规模性的伤害。因此，对这些语言模型进行严格审计至关重要。现有的审计工具利用人和或AI来发现失败。在这项工作中，我们借鉴了人工智能协作和感知的文献，并采访了安全和公正人工智能的研究专家，以增强审计工具“AdaTest”（Ribeiro和Lundberg，2022），该工具由生成大型语言模型（LLM）驱动。通过设计过程，我们强调了感知和人工智能通信在协作审计中利用人与生成模型的互补优势的重要性。为了评估增强工具AdaTest ++的有效性，我们进行了用户研究，使参与者进行审计

    Large language models are becoming increasingly pervasive and ubiquitous in society via deployment in sociotechnical systems. Yet these language models, be it for classification or generation, have been shown to be biased and behave irresponsibly, causing harm to people at scale. It is crucial to audit these language models rigorously. Existing auditing tools leverage either or both humans and AI to find failures. In this work, we draw upon literature in human-AI collaboration and sensemaking, and conduct interviews with research experts in safe and fair AI, to build upon the auditing tool: AdaTest (Ribeiro and Lundberg, 2022), which is powered by a generative large language model (LLM). Through the design process we highlight the importance of sensemaking and human-AI communication to leverage complementary strengths of humans and generative models in collaborative auditing. To evaluate the effectiveness of the augmented tool, AdaTest++, we conduct user studies with participants audit
    
[^24]: Radar de Parit\'e: 一种衡量法语新闻报道中性别代表性的NLP系统

    Radar de Parit\'e: An NLP system to measure gender representation in French news stories. (arXiv:2304.09982v1 [cs.CL])

    [http://arxiv.org/abs/2304.09982](http://arxiv.org/abs/2304.09982)

    本文介绍了Radar de Parit\'e，一种自动化的NLP系统，根据六个加拿大法语媒体每天引用的女性和男性比例的数据，详细介绍了该系统的架构，以及如何解决法语语言中的技术难题，展示了在一年的数据统计中，新闻报道中女性的代表性不足，因此该系统为我们解决社会问题提供了新的思路和方法。

    

    我们提出了Radar de Parit\'e，这是一个自动化的自然语言处理（NLP）系统，用于衡量六个加拿大法语媒体中每日引用的女性和男性的比例。我们概述了该系统的架构，并详细介绍了我们克服的法语特定问题，特别是关于coreference resolution的问题，这是法语NLP文献的新贡献。我们还展示了超过一年的数据统计（282,512篇新闻文章）。我们的结果突出了新闻报道中女性的代表性不足，同时也展示了运用现代NLP方法来衡量性别代表性和解决社会问题的应用。

    We present the Radar de Parit\'e, an automated Natural Language Processing (NLP) system that measures the proportion of women and men quoted daily in six Canadian French-language media outlets. We outline the system's architecture and detail the challenges we overcame to address French-specific issues, in particular regarding coreference resolution, a new contribution to the NLP literature on French. We also showcase statistics covering over one year's worth of data (282,512 news articles). Our results highlight the underrepresentation of women in news stories, while also illustrating the application of modern NLP methods to measure gender representation and address societal issues.
    
[^25]: MasakhaNEWS：非洲语言新闻主题分类

    MasakhaNEWS: News Topic Classification for African languages. (arXiv:2304.09972v1 [cs.CL])

    [http://arxiv.org/abs/2304.09972](http://arxiv.org/abs/2304.09972)

    该论文开发了MasakhaNEWS，它是一个覆盖16种非洲语言的新闻主题分类的基准数据集。除了评估基线模型外，还探索了适用于零样本学习和少样本学习的全面微调语言模型的替代方案。

    

    由于缺乏覆盖多个NLP任务的数据集，非洲语言在NLP研究中严重受到忽视。虽然存在一些语言特定的数据集，但只有少数NLP任务（如命名实体识别和机器翻译）具有覆盖多个地理和分类多样的非洲语言的标准基准数据集。在本文中，我们开发了MasakhaNEWS - 一个新的用于涵盖非洲广泛使用的16种语言的新闻主题分类的基准数据集。我们通过训练经典的机器学习模型和微调多个语言模型来评估基线模型。此外，我们还探索了一些适用于零样本学习和少样本学习的语言模型的全面微调的替代方案，例如跨语言参数高效微调（如MAD-X）、模式利用训练（PET）、提示语言模型（如ChatGPT）和无提示句子训练（ELECTRA）等。

    African languages are severely under-represented in NLP research due to lack of datasets covering several NLP tasks. While there are individual language specific datasets that are being expanded to different tasks, only a handful of NLP tasks (e.g. named entity recognition and machine translation) have standardized benchmark datasets covering several geographical and typologically-diverse African languages. In this paper, we develop MasakhaNEWS -- a new benchmark dataset for news topic classification covering 16 languages widely spoken in Africa. We provide an evaluation of baseline models by training classical machine learning models and fine-tuning several language models. Furthermore, we explore several alternatives to full fine-tuning of language models that are better suited for zero-shot and few-shot learning such as cross-lingual parameter-efficient fine-tuning (like MAD-X), pattern exploiting training (PET), prompting language models (like ChatGPT), and prompt-free sentence tra
    
[^26]: 大规模语言模型中潜在空间理论对应新兴能力

    A Latent Space Theory for Emergent Abilities in Large Language Models. (arXiv:2304.09960v1 [cs.CL])

    [http://arxiv.org/abs/2304.09960](http://arxiv.org/abs/2304.09960)

    本文探讨了大规模语言模型中的贝叶斯推断和稀疏联合分布，证明了LLMs能够完成语言理解、上下文学习、思路启发以及有效指令微调的新兴能力。

    

    语言并不是随机生成，而是为了传递信息。语言与其底层含义之间存在强烈的关联，在其相关性方面有着严重偏差的稀疏联合分布。此外，由于稀疏性，这些高峰值恰好与语言的边缘分布匹配。随着大数据和大模型上训练的LLMs的出现，我们现在可以精确评估语言的边缘分布，这提供了一种方便的探索联合分布稀疏结构实现有效推理的方式。在本文中，我们将语言分类为明确与{\epsilon}-模糊，并提出定量结果，以表明LLMs的新兴能力（例如语言理解、上下文学习、思路启发以及有效指令微调）都可以归因于对稀疏联合分布进行贝叶斯推断。

    Languages are not created randomly but rather to communicate information. There is a strong association between languages and their underlying meanings, resulting in a sparse joint distribution that is heavily peaked according to their correlations. Moreover, these peak values happen to match with the marginal distribution of languages due to the sparsity. With the advent of LLMs trained on big data and large models, we can now precisely assess the marginal distribution of languages, providing a convenient means of exploring the sparse structures in the joint distribution for effective inferences. In this paper, we categorize languages as either unambiguous or {\epsilon}-ambiguous and present quantitative results to demonstrate that the emergent abilities of LLMs, such as language understanding, in-context learning, chain-of-thought prompting, and effective instruction fine-tuning, can all be attributed to Bayesian inference on the sparse joint distribution of languages.
    
[^27]: 利用大型语言模型进行低资源双语方言词典归纳

    Low-resource Bilingual Dialect Lexicon Induction with Large Language Models. (arXiv:2304.09957v1 [cs.CL])

    [http://arxiv.org/abs/2304.09957](http://arxiv.org/abs/2304.09957)

    本文探索了在低资源情况下使用大型语言模型进行双语方言词典归纳的方法，对德语及其巴伐利亚和阿勒曼尼亚方言进行分析，提出了应对资源稀缺、语言相关性和拼写标准化缺失等挑战的解决方案。输出结果通过单词频率和成对编辑距离进行评估，同时发布了包括1500个双语句子对和1000个双语单词对的评估数据集。

    

    双语单词词典是多语言自然语言理解和机器翻译任务的关键工具，因为它们有助于将一种语言中的单词映射到另一种语言中的同义词。本文分析了德语及其两种方言（巴伐利亚和阿勒曼尼亚）的双语词典归纳过程，该过程存在资源稀缺、语言相关性以及方言拼写标准化缺失等独特挑战。为了评估输出结果，我们分析了单词频率和成对编辑距离。此外，我们发布了两个评估数据集，包括1500个双语句子对和1000个双语单词对。

    Bilingual word lexicons are crucial tools for multilingual natural language understanding and machine translation tasks, as they facilitate the mapping of words in one language to their synonyms in another language. To achieve this, numerous papers have explored bilingual lexicon induction (BLI) in high-resource scenarios, using a typical pipeline consisting of two unsupervised steps: bitext mining and word alignment, both of which rely on pre-trained large language models~(LLMs).  In this paper, we present an analysis of the BLI pipeline for German and two of its dialects, Bavarian and Alemannic. This setup poses several unique challenges, including the scarcity of resources, the relatedness of the languages, and the lack of standardization in the orthography of dialects. To evaluate the BLI outputs, we analyze them with respect to word frequency and pairwise edit distance. Additionally, we release two evaluation datasets comprising 1,500 bilingual sentence pairs and 1,000 bilingual w
    
[^28]: 抓住你的话语：使用生成式预训练Transformer识别虚假医师评论

    Catch Me If You Can: Identifying Fraudulent Physician Reviews with Large Language Models Using Generative Pre-Trained Transformers. (arXiv:2304.09948v1 [cs.CL])

    [http://arxiv.org/abs/2304.09948](http://arxiv.org/abs/2304.09948)

    本研究使用GPT-3模型，比以往的传统机器学习模型（如逻辑回归和支持向量机）性能更出色。同时，本研究揭示虚假评论与真实评论在语言表达上存在的差异，分析了虚假评论的模式和特征。

    

    医生虚假评论的泛滥可能会对患者福利产生潜在危害，并引起消费者保护组织和监管机构的关注。尽管机器学习和自然语言处理领域已取得重大进展，但虚假评论与真实评论之间的差异特征还是理解有限。本研究利用了一个新的标记好的数据集，包括38048个医师评论，以验证大型语言模型对评论分类的有效性。具体来说，我们比较了传统的机器学习模型（如逻辑回归和支持向量机）与生成式预训练Transformer模型之间的性能差异。此外，我们使用GPT4，GPT系列中最新的模型，来揭示虚假和真实医生评论的关键维度。我们的研究发现，GPT-3在这个领域比传统机器学习模型表现优异。此外，我们还分析了虚假评论与真实评论在语言表达上的差异， 进一步揭示了虚假评论的模式和特征。

    The proliferation of fake reviews of doctors has potentially detrimental consequences for patient well-being and has prompted concern among consumer protection groups and regulatory bodies. Yet despite significant advancements in the fields of machine learning and natural language processing, there remains limited comprehension of the characteristics differentiating fraudulent from authentic reviews. This study utilizes a novel pre-labeled dataset of 38048 physician reviews to establish the effectiveness of large language models in classifying reviews. Specifically, we compare the performance of traditional ML models, such as logistic regression and support vector machines, to generative pre-trained transformer models. Furthermore, we use GPT4, the newest model in the GPT family, to uncover the key dimensions along which fake and genuine physician reviews differ. Our findings reveal significantly superior performance of GPT-3 over traditional ML models in this context. Additionally, ou
    
[^29]: The eBible语料库：用于面向低资源语言圈的圣经翻译的数据和模型基准

    The eBible Corpus: Data and Model Benchmarks for Bible Translation for Low-Resource Languages. (arXiv:2304.09919v1 [cs.CL])

    [http://arxiv.org/abs/2304.09919](http://arxiv.org/abs/2304.09919)

    介绍了一个名为eBible的圣经翻译语料库，包含1009个圣经部分翻译的数据集，涵盖了833种不同语言的数据，分布在75个语言家族中。同时还提供了基于NLLB神经机器翻译模型的性能基准，并讨论了在圣经翻译领域中的一些问题。

    

    无论采用手动、自动或两者结合的策略，高效准确地将语料库翻译成低资源语言仍然是一项挑战。许多基督教组织致力于将圣经翻译成缺乏现代翻译的语言。我们介绍了eBible语料库：一个包含1009个圣经部分翻译的数据集，其中包含833种不同语言的数据，分布在75个语言家族中。除了圣经翻译基准数据集，我们还介绍了基于No Language Left Behind（NLLB）神经机器翻译（NMT）模型的模型性能基准。最后，我们描述了圣经翻译领域特有的若干问题，并考虑已建立的数据和模型基准如何用于未来的翻译工作。对于使用NLLB进行训练的BT任务，南岛和新几内亚传输语系的语言表现不佳，而印欧语系和非洲亚洲语系的语言表现更好。

    Efficiently and accurately translating a corpus into a low-resource language remains a challenge, regardless of the strategies employed, whether manual, automated, or a combination of the two. Many Christian organizations are dedicated to the task of translating the Holy Bible into languages that lack a modern translation. Bible translation (BT) work is currently underway for over 3000 extremely low resource languages. We introduce the eBible corpus: a dataset containing 1009 translations of portions of the Bible with data in 833 different languages across 75 language families. In addition to a BT benchmarking dataset, we introduce model performance benchmarks built on the No Language Left Behind (NLLB) neural machine translation (NMT) models. Finally, we describe several problems specific to the domain of BT and consider how the established data and model benchmarks might be used for future translation efforts. For a BT task trained with NLLB, Austronesian and Trans-New Guinea languag
    
[^30]: 连接自然语言处理与心理语言学：面向巴斯克语和西班牙语的基于语料库和知识库的计算语义相似性和相关数据集

    Bridging Natural Language Processing and Psycholinguistics: computationally grounded semantic similarity and relatedness datasets for Basque and Spanish. (arXiv:2304.09616v1 [cs.CL])

    [http://arxiv.org/abs/2304.09616](http://arxiv.org/abs/2304.09616)

    该论文提出了一个基于计算的词语相似性数据集，旨在弥补心理语言学研究中的空白，通过提供大量控制了在词汇处理中起重要作用的变量的名词对的语义相似性的量化。数据集包括巴斯克语和欧洲西班牙语的名词对信息，但进一步的工作意图将其扩展到更多语言。

    

    我们基于两个著名的自然语言处理资源：文本语料库和知识库，提出了一个基于计算的词语相似性数据集。该数据集旨在弥补心理语言学研究中的空白，通过提供大量控制了在词汇处理中起重要作用的变量的名词对的语义相似性的量化。数据集的创建包括三个步骤：1）为每个名词计算四个关键的心理语言学特征：具体性、频率、语义和音位邻近密度；2）在这些四个变量下对名词进行配对；3）对于每个名词对，分配三种类型的单词相似度测量，计算出文本、Wordnet和混合嵌入。目前的数据集包括巴斯克语和欧洲西班牙语的名词对信息，但进一步的工作意图将其扩展到更多语言。

    We present a computationally-grounded word similarity dataset based on two well-known Natural Language Processing resources; text corpora and knowledge bases. This dataset aims to fulfil a gap in psycholinguistic research by providing a variety of quantifications of semantic similarity in an extensive set of noun pairs controlled by variables that play a significant role in lexical processing. The dataset creation has consisted in three steps, 1) computing four key psycholinguistic features for each noun; concreteness, frequency, semantic and phonological neighbourhood density; 2) pairing nouns across these four variables; 3) for each noun pair, assigning three types of word similarity measurements, computed out of text, Wordnet and hybrid embeddings. The present dataset includes noun pairs' information in Basque and European Spanish, but further work intends to extend it to more languages.
    
[^31]: 语言模型实现异构数据湖结构化视图生成的简单系统

    Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes. (arXiv:2304.09433v1 [cs.CL])

    [http://arxiv.org/abs/2304.09433](http://arxiv.org/abs/2304.09433)

    本文探讨了使用大型语言模型在不需要特定领域的训练和定制下实现生成可查询表格的简单系统，并给出了两种实现策略，在不同质量和成本中平衡。通过实验证明，该系统对不同类型文档生成的表格均高质量，且无需文档特定的定制。

    

    数据管理界长期以来的目标是开发出通用自动化系统，可以在不需要人力或特定领域的定制情况下摄取半结构化文档并输出可查询的表格。鉴于潜在文档的多样性，现有的最先进系统进行简化的假设并使用特定领域的训练。本文中，我们询问是否可以通过使用大型语言模型（LLMs）来保持广泛性。在广泛数据上预训练的LLMs可仅限于基于自然语言任务描述执行各种下游任务。我们提出并评估了由LLMs驱动的简单原型系统EVAPORATE。我们确定了实现该系统的两种基本不同策略：提示LLM直接从文档中提取值或提示LLM合成执行提取的代码。我们的评估显示，这两种方法之间存在成本-质量权衡。代码合成便宜，但比直接抽取远不准确。我们对四种不同类型文档的实验表明，EVAPORATE可以在不需要任何文档特定的定制情况下为各种文档类型生成高质量的表格。

    A long standing goal of the data management community is to develop general, automated systems that ingest semi-structured documents and output queryable tables without human effort or domain specific customization. Given the sheer variety of potential documents, state-of-the art systems make simplifying assumptions and use domain specific training. In this work, we ask whether we can maintain generality by using large language models (LLMs). LLMs, which are pretrained on broad data, can perform diverse downstream tasks simply conditioned on natural language task descriptions.  We propose and evaluate EVAPORATE, a simple, prototype system powered by LLMs. We identify two fundamentally different strategies for implementing this system: prompt the LLM to directly extract values from documents or prompt the LLM to synthesize code that performs the extraction. Our evaluations show a cost-quality tradeoff between these two approaches. Code synthesis is cheap, but far less accurate than dire
    
[^32]: 低代码LLM：LLM上的可视化编程

    Low-code LLM: Visual Programming over LLMs. (arXiv:2304.08103v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08103](http://arxiv.org/abs/2304.08103)

    本文介绍了一种新颖的人-LLM交互框架，低代码LLM，该框架可通过六种类型的简单低代码可视化编程交互实现更可控和稳定的响应，具有可控性强、用户友好的交互方式和广泛的应用范围的优点。

    

    有效地利用LLM来完成复杂任务非常具有挑战性，通常需要进行耗时而难以掌控的提示工程处理过程。本文提出了一种新颖的人-LLM交互框架，即低代码LLM。它包括六种类型的简单低代码可视化编程交互，全部支持点击、拖放或文本编辑，以实现更可控和稳定的响应。通过与图形用户界面的视觉交互，用户可以将其想法纳入工作流程，而不必编写琐碎的提示。提出的低代码LLM框架由规划LLM和执行LLM两部分组成，规划LLM为复杂任务设计了一个结构化的规划工作流程，用户可以通过低代码可视化编程操作相应地进行编辑和确认，而执行LLM则按照用户确认的工作流程生成响应。我们强调低代码LLM的三个优点：可控的生成结果、用户友好的人-LLM交互以及广泛的应用。

    Effectively utilizing LLMs for complex tasks is challenging, often involving a time-consuming and uncontrollable prompt engineering process. This paper introduces a novel human-LLM interaction framework, Low-code LLM. It incorporates six types of simple low-code visual programming interactions, all supported by clicking, dragging, or text editing, to achieve more controllable and stable responses. Through visual interaction with a graphical user interface, users can incorporate their ideas into the workflow without writing trivial prompts. The proposed Low-code LLM framework consists of a Planning LLM that designs a structured planning workflow for complex tasks, which can be correspondingly edited and confirmed by users through low-code visual programming operations, and an Executing LLM that generates responses following the user-confirmed workflow. We highlight three advantages of the low-code LLM: controllable generation results, user-friendly human-LLM interaction, and broadly app
    
[^33]: 神经网络中符号的出现与语义理解和交流

    Emergence of Symbols in Neural Networks for Semantic Understanding and Communication. (arXiv:2304.06377v1 [cs.AI])

    [http://arxiv.org/abs/2304.06377](http://arxiv.org/abs/2304.06377)

    本文介绍了一种名为SEA-net的神经网络解决方案，可以生成符号，实现语义理解和交流。这些符号可以捕捉到组成性语义信息，并呈现类似自然语言的内在结构。

    

    能够创造有意义的符号，并熟练地将它们用于更高的认知功能，如交流、推理、规划等，是人类智能的重要和独特之处。 目前，深度神经网络仍远远落后于人类创造符号进行这些高级认知功能的能力。本文提出了一种名为SEA-net的解决方案，使神经网络具有符号创造、语义理解和交流能力。SEA-net生成动态配置网络以执行特定任务的符号。这些符号捕捉了组成性语义信息，使系统能够通过纯符号操作或交流获得新功能。此外，我们发现这些自动生成的符号呈现出类似自然语言的内在结构，表明在人类大脑和人工神经网络中生成和理解符号的共同框架。我们希望这将成为将来发展人工智能的助推器。

    Being able to create meaningful symbols and proficiently use them for higher cognitive functions such as communication, reasoning, planning, etc., is essential and unique for human intelligence. Current deep neural networks are still far behind human's ability to create symbols for such higher cognitive functions. Here we propose a solution, named SEA-net, to endow neural networks with ability of symbol creation, semantic understanding and communication. SEA-net generates symbols that dynamically configure the network to perform specific tasks. These symbols capture compositional semantic information that enables the system to acquire new functions purely by symbolic manipulation or communication. In addition, we found that these self-generated symbols exhibit an intrinsic structure resembling that of natural language, suggesting a common framework underlying the generation and understanding of symbols in both human brains and artificial neural networks. We hope that it will be instrum
    
[^34]: 相似度感知的多模态提示学习用于假新闻检测

    Similarity-Aware Multimodal Prompt Learning for Fake News Detection. (arXiv:2304.04187v1 [cs.CL])

    [http://arxiv.org/abs/2304.04187](http://arxiv.org/abs/2304.04187)

    该论文提出了一种相似度感知的多模态提示学习框架，用于有效融合不同模态信息，实现假新闻检测。所设计的相似度感知融合模块可以量化地根据不同模态之间的相似性权衡每个模态的重要性，有效避免了多模态融合中可能存在的噪声干扰。在两个基准数据集上的实验结果也证明提出的框架实现了最先进的性能，超越了其他强大基线方法。

    

    假新闻检测的标准范式主要利用文本信息来建立新闻的真实性，然而，网上假新闻的话语通常比较微妙，需要专家知识才能使用文本信息揭露假新闻。最近，关注于多模态假新闻检测的研究已经超越了仅基于文本的方法。最近的方法利用预训练模型来提取单模态特征，或直接微调预训练模型，这成为检测假新闻的新范式。然而，这种方法要么需要大量的训练实例，要么需要更新整个预训练模型参数集，不实际可行。此外，传统的多模态方法将跨模态特征直接融合，而不考虑不相关的语义表示可能会引入噪声到多模态特征中。本文提出了一种相似度感知的多模态提示学习（SAMPLE）框架，用于假新闻检测，利用不同模态之间的内在相关性来有效地融合信息。所提出的框架包括一种新颖的相似度感知融合模块，该模块学习根据它们之间的相似度来权衡不同模态的重要性。在两个基准数据集上的实验结果表明，我们的框架实现了最先进的性能，并大幅优于强基线。

    The standard paradigm for fake news detection mainly utilizes text information to model the truthfulness of news. However, the discourse of online fake news is typically subtle and it requires expert knowledge to use textual information to debunk fake news. Recently, studies focusing on multimodal fake news detection have outperformed text-only methods. Recent approaches utilizing the pre-trained model to extract unimodal features, or fine-tuning the pre-trained model directly, have become a new paradigm for detecting fake news. Again, this paradigm either requires a large number of training instances, or updates the entire set of pre-trained model parameters, making real-world fake news detection impractical. Furthermore, traditional multimodal methods fuse the cross-modal features directly without considering that the uncorrelated semantic representation might inject noise into the multimodal features. This paper proposes a Similarity-Aware Multimodal Prompt Learning (SAMPLE) framewo
    
[^35]: 评估ChatGPT和GPT-4的逻辑推理能力

    Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. (arXiv:2304.03439v1 [cs.CL])

    [http://arxiv.org/abs/2304.03439](http://arxiv.org/abs/2304.03439)

    本文分析了多个逻辑推理数据集，评估了ChatGPT和GPT-4在逻辑推理任务上的表现，并构造了一个逻辑推理的分布之外的数据集来研究它们的鲁棒性。实验结果显示，ChatGPT在大多数逻辑推理基准测试中的表现远优于RoBERTa微调方法，而GPT-4的表现则更高。

    

    利用逻辑推理能力是一个全面的自然语言理解任务。随着先进的生成预训练转换器4（GPT-4）的发布，我们渴望了解GPT-4在各种逻辑推理任务上的表现。本文分析了多个逻辑推理数据集，包括LogiQA和ReClor等常用基准测试，以及像AR-LSAT这样的新发布的数据集。我们对需要逻辑推理的基准测试进行了多项选择阅读理解和自然语言推理任务测试。我们进一步构造了一个逻辑推理的分布之外的数据集，以研究ChatGPT和GPT-4的鲁棒性。我们还进行了ChatGPT和GPT-4之间的性能比较。实验结果表明，在大多数逻辑推理基准测试中，ChatGPT的表现远远优于RoBERTa微调方法。GPT-4在我们的手动测试中表现更高。在基准测试中，ChatGPT和GPT-4的表现相对较为均衡。

    Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as "advanced" at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs significantly better than the RoBERTa fine-tuning method on most logical reasoning benchmarks. GPT-4 shows even higher performance on our manual tests. Among benchmarks, ChatGPT and GPT-4 do relatively w
    
[^36]: ParroT: 使用大型语言模型进行聊天翻译

    ParroT: Translating During Chat Using Large Language Models. (arXiv:2304.02426v1 [cs.CL])

    [http://arxiv.org/abs/2304.02426](http://arxiv.org/abs/2304.02426)

    ParroT提出了一种基于开源LLM和人工编写的翻译评估数据的聊天翻译框架，可以将翻译数据转化为指令执行样式，并引入额外要求来规范翻译过程。在使用相对较少的训练数据的情况下，实验结果表明 ParroT 可以大幅提高翻译质量。

    

    大型语言模型（LLM）如 ChatGPT 和 GPT-4 在各种自然语言处理（NLP）任务上展现出了卓越的能力，包括在聊天过程中完成各种机器翻译能力。然而，这些模型只能通过受限的API访问，这为新的研究和领域进展带来了障碍。因此，我们提出了 ParroT 框架，基于开源LLM（如LLaMA-7b）和人工编写的翻译评估数据来增强和规范聊天翻译能力。具体而言，ParroT将翻译数据转化为指令执行的样式，并引入 "Hint " 字段以加入额外要求来规范翻译过程。因此，我们提出了三种指令类型来微调 ParroT 模型，包括翻译指令、对比指令和误差引导指令。在两个 Flores 子集和 WMT22 测试集上的实验证明，使用 ParroT 可以大幅提高翻译质量，且需要相对较少的训练数据。

    Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose the $\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a "Hint" field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on two Flores subsets and WMT22 test sets suggest that tr
    
[^37]: 几千到几十万个标记的序列推理和记忆任务中的卷积语言模型 - 九斑狼等级: 迈向更大的卷积语言模型

    Hyena Hierarchy: Towards Larger Convolutional Language Models. (arXiv:2302.10866v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10866](http://arxiv.org/abs/2302.10866)

    本文提出一种名为九斑狼的卷积语言模型，通过交错隐式参数化的长卷积和数据控制门构造。在记忆任务和推理任务中，序列有几千到几十万个标记，九斑狼取得了比其他算子更为精确的表现，达到了基于注意力的模型的水平，并取得了密集注意力模型的最新结构。

    

    深度学习的最新进展在很大程度上依赖于大型Transformer的使用，因为它们可以在任意规模上进行学习。然而，Transformers的核心构件——注意力操作符——在长度方面呈现出二次的成本，限制了可以访问的上下文量。现有的基于低秩和稀疏逼近的亚二次方法需要与密集的注意力层结合使用来匹配Transformers，表明存在能力差距。在这项工作中，我们提出了九斑狼，一种亚二次的注意力替代品，通过交错隐式参数化的长卷积和数据控制门构造。在记忆任务和推理任务中，序列有几千到几十万个标记，九斑狼的准确度比依赖于状态空间和其他隐式和显式方法的算子提高了50以上，达到了基于注意力的模型的水平。在标准数据集上，九斑狼并不需要密集注意力的结构，就已经取得了密集注意力模型的最新结构。

    Recent advances in deep learning have relied heavily on the use of large Transformers due to their ability to learn at scale. However, the core building block of Transformers, the attention operator, exhibits quadratic cost in sequence length, limiting the amount of context accessible. Existing subquadratic methods based on low-rank and sparse approximations need to be combined with dense attention layers to match Transformers, indicating a gap in capability. In this work, we propose Hyena, a subquadratic drop-in replacement for attention constructed by interleaving implicitly parametrized long convolutions and data-controlled gating. In recall and reasoning tasks on sequences of thousands to hundreds of thousands of tokens, Hyena improves accuracy by more than 50 points over operators relying on state-spaces and other implicit and explicit methods, matching attention-based models. We set a new state-of-the-art for dense-attention-free architectures on language modeling in standard dat
    
[^38]: InstructABSA: 基于指令学习的方面情感分析

    InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis. (arXiv:2302.08624v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08624](http://arxiv.org/abs/2302.08624)

    InstructABSA是一种使用指令学习范式的方面情感分析方法，能够显著提高Aspect Term Extraction、Aspect Term Sentiment Classification、和Joint Task subtasks三个子任务的性能，并且在多个数据集上表现超过之前的最先进方法。

    

    本文介绍了InstructABSA，一种使用指令学习范式进行Aspect Based Sentiment Analysis (ABSA) 所有子任务（Aspect Term Extraction (ATE)，Aspect Term Sentiment Classification (ATSC)，以及Joint Task modeling）的方法。我们的方法对每个训练样本引入了正面、负面、和中性的例子，并使用指令来调整每个ABSA子任务的模型（Tk-Instruct），从而显著提高了性能。在Sem Eval 2014、2015和2016数据集上的实验结果表明，在所有三个ABSA子任务（ATE、ATSC和Joint Task）上，InstructABSA在性能上都比之前的最先进方法（SOTA）表现出了显著的优势，并且表现超过了7倍大的模型。特别是，在Rest14 ATE子任务上，InstructABSA超过了SOTA 7.31%的得分，Rest15 ATSC子任务上也有提升，并且在Lapt14 Joint Task上的表现提升了8.63%点。我们的结果还表明，对于所有三个子任务，InstructABSA具有强大的新领域泛化能力。

    In this paper, we present InstructABSA, Aspect Based Sentiment Analysis (ABSA) using the instruction learning paradigm for all ABSA subtasks: Aspect Term Extraction (ATE), Aspect Term Sentiment Classification (ATSC), and Joint Task modeling. Our method introduces positive, negative, and neutral examples to each training sample, and instruction tunes the model (Tk-Instruct) for each ABSA subtask, yielding significant performance improvements. Experimental results on the Sem Eval 2014, 15, and 16 datasets demonstrate that InstructABSA outperforms the previous state-of-the-art (SOTA) approaches on all three ABSA subtasks (ATE, ATSC, and Joint Task) by a significant margin, outperforming 7x larger models. In particular, InstructABSA surpasses the SOTA on the Rest14 ATE subtask by 7.31% points, Rest15 ATSC subtask by and on the Lapt14 Joint Task by 8.63% points. Our results also suggest a strong generalization ability to new domains across all three subtasks
    
[^39]: 人工智能心理学中的“正确答案”

    "Correct answers" from the psychology of artificial intelligence. (arXiv:2302.07267v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.07267](http://arxiv.org/abs/2302.07267)

    本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。

    This paper replicates 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, and successfully replicates the results of 8 studies. However, for the remaining 6 studies, GPT3.5 answered survey questions in an extremely predetermined way, making it impossible to analyze these studies.

    大型语言模型的能力已经大大增强。这种AI系统的一个提出的应用是支持社会和认知科学中的数据收集，目前完美的实验控制是不可行的，而大规模、代表性数据集的收集通常是昂贵的。在本文中，我们使用OpenAI的text-davinci-003模型（俗称GPT3.5）重新复制了Many Labs 2复制项目中的14项研究。我们通过将每项研究的调查作为文本输入，从GPT3.5的默认设置中收集了响应。在我们可以分析的八项研究中，我们的GPT样本复制了原始结果的37.5%以及Many Labs 2结果的37.5%。出乎意料的是，我们无法像预先注册的计划那样分析剩下的六项研究。这是因为对于这六项研究中的每一项，GPT3.5以极其预定的方式回答了调查问题（无论是因变量还是条件变量）：一个未知的

    Large Language Models have vastly grown in capabilities. One proposed application of such AI systems is to support data collection in the social and cognitive sciences, where perfect experimental control is currently unfeasible and the collection of large, representative datasets is generally expensive. In this paper, we re-replicate 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, colloquially known as GPT3.5. We collected responses from the default setting of GPT3.5 by inputting each study's survey as text. Among the eight studies we could analyse, our GPT sample replicated 37.5% of the original results as well as 37.5% of the Many Labs 2 results. Unexpectedly, we could not analyse the remaining six studies as we had planned in our pre-registration. This was because for each of these six studies, GPT3.5 answered at least one of the survey questions (either a dependent variable or a condition variable) in an extremely predetermined way: an unex
    
[^40]: MEAformer: 多模式实体对齐变压器用于元模态混合

    MEAformer: Multi-modal Entity Alignment Transformer for Meta Modality Hybrid. (arXiv:2212.14454v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.14454](http://arxiv.org/abs/2212.14454)

    该论文提出了一种适用于元模态混合的多模式实体对齐变压器方法，通过动态预测模态之间的相互关联系数以进行实体级特征聚合，进一步提出了一种模态感知的硬实体重播策略，用于解决模糊实体细节的问题。该模型在多个训练场景中实现了SOTA性能并有效提高了MMEA的鲁棒性。

    

    作为实体对齐（EA）的一个重要变体，多模式实体对齐（MMEA）旨在发现不同知识图谱（KGs）中具有相关图像的相同实体。 我们注意到，当前的MMEA算法都全局采用KG级模态融合策略进行多模式实体表示，但忽略了个体实体的模态偏好变化，从而削弱了对模态（例如模糊图像和关系）中潜在噪声的鲁棒性。在本文中，我们提出了MEAformer，一种适用于元模态混合的多模式实体对齐变压器方法，该方法动态预测模态之间的相互关联系数以进行实体级特征聚合。进一步提出了一种模态感知的硬实体重播策略，用于解决模糊实体细节的问题。实验结果表明，我们的模型不仅在多个训练场景（包括有监督、无监督、迭代和低资源设置）中实现了SOTA性能，而且通过利用模态偏好变化有效提高了MMEA的鲁棒性。

    As an important variant of entity alignment (EA), multi-modal entity alignment (MMEA) aims to discover identical entities across different knowledge graphs (KGs) with relevant images attached. We noticed that current MMEA algorithms all globally adopt the KG-level modality fusion strategies for multi-modal entity representation but ignore the variation in modality preferences for individual entities, hurting the robustness to potential noise involved in modalities (e.g., blurry images and relations). In this paper, we present MEAformer, a multi-modal entity alignment transformer approach for meta modality hybrid, which dynamically predicts the mutual correlation coefficients among modalities for entity-level feature aggregation. A modal-aware hard entity replay strategy is further proposed for addressing vague entity details. Experimental results show that our model not only achieves SOTA performance on multiple training scenarios including supervised, unsupervised, iterative, and low 
    
[^41]: BERT遇见CTC：利用预先训练好的遮蔽语言模型的新型端到端语音识别公式

    BERT Meets CTC: New Formulation of End-to-End Speech Recognition with Pre-trained Masked Language Model. (arXiv:2210.16663v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2210.16663](http://arxiv.org/abs/2210.16663)

    本文提出了BERT-CTC，一种新型的端到端语音识别公式，它利用BERT上下文嵌入获取显式输出依赖性来整合语言知识，并通过自我注意机制关注序列的全部上下文。在实验中表现优于传统方法，语义表示对下游口语理解任务有益作用。

    

    本文提出了BERT-CTC，一种新型的端到端语音识别公式，该公式通过对连接主义时间分类（CTC）使用BERT来实现。我们的公式放宽了常规CTC中使用的条件独立性假设，并通过BERT上下文嵌入获取显式输出依赖性来整合语言知识。BERT-CTC通过自我注意机制关注输入和假设的输出序列的全部上下文。该机制鼓励模型学习音频和标记表示之间的内在/相互依赖关系，同时保持CTC的训练效率。在推理期间，BERT-CTC将遮蔽预测算法与CTC解码相结合，通过迭代细化输出序列。实验结果表明，BERT-CTC在不同的言语风格和语言变化方面都优于传统方法。最后，我们展示了BERT-CTC中的语义表示对下游口语理解任务的有益作用。

    This paper presents BERT-CTC, a novel formulation of end-to-end speech recognition that adapts BERT for connectionist temporal classification (CTC). Our formulation relaxes the conditional independence assumptions used in conventional CTC and incorporates linguistic knowledge through the explicit output dependency obtained by BERT contextual embedding. BERT-CTC attends to the full contexts of the input and hypothesized output sequences via the self-attention mechanism. This mechanism encourages a model to learn inner/inter-dependencies between the audio and token representations while maintaining CTC's training efficiency. During inference, BERT-CTC combines a mask-predict algorithm with CTC decoding, which iteratively refines an output sequence. The experimental results reveal that BERT-CTC improves over conventional approaches across variations in speaking styles and languages. Finally, we show that the semantic representations in BERT-CTC are beneficial towards downstream spoken lan
    
[^42]: 黄金并非一切：线性和非线性保护属性信息的光谱去除方法

    Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear Guarded Attribute Information. (arXiv:2203.07893v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.07893](http://arxiv.org/abs/2203.07893)

    这篇论文提出了一种光谱属性去除方法，用于从神经表示中去除私有或保护信息。实验证明，该方法保留了更好的主要任务性能，同时只需少量的被保护属性数据即可去除信息，适用于资源有限的情况。

    

    我们描述了一种简单而有效的方法（称为光谱属性去除方法; SAL），用于从神经表示中去除私有或保护信息。我们的方法使用矩阵分解将输入表示投影到与保护信息协方差较小的方向上，而不是像因式分解方法那样最大化协方差。我们从线性信息删除开始，并通过使用内核将算法推广到非线性信息删除的情况。我们的实验证明，在删除保护信息后，我们的算法保留了更好的主要任务性能，而不像以前的工作那样删除该信息削弱了性能。此外，实验表明，我们只需少量的被保护属性数据即可去除有关这些属性的信息，这降低了敏感数据的暴露，并更适用于资源有限的情况。可以在https://github.com/jasonshaoshun/SAL上找到代码。

    We describe a simple and effective method (Spectral Attribute removaL; SAL) to remove private or guarded information from neural representations. Our method uses matrix decomposition to project the input representations into directions with reduced covariance with the guarded information rather than maximal covariance as factorization methods normally use. We begin with linear information removal and proceed to generalize our algorithm to the case of nonlinear information removal using kernels. Our experiments demonstrate that our algorithm retains better main task performance after removing the guarded information compared to previous work. In addition, our experiments demonstrate that we need a relatively small amount of guarded attribute data to remove information about these attributes, which lowers the exposure to sensitive data and is more suitable for low-resource scenarios. Code is available at https://github.com/jasonshaoshun/SAL.
    
[^43]: 媒体倾向是具有传染性的。

    Media Slant is Contagious. (arXiv:2202.07269v2 [econ.GN] UPDATED)

    [http://arxiv.org/abs/2202.07269](http://arxiv.org/abs/2202.07269)

    本文研究了国家有线电视新闻对美国本土报纸的影响，发现当地报纸的内容会因为当地 FNC 观众数量的增加而趋向于 FNC 的倾向，并且有线电视倾向会极化地方新闻内容。

    

    本研究考察了媒体倾向的传播，具体来说是国家有线电视新闻对美国本土报纸（2005-2008）的影响。我们使用一种基于 Fox News Channel（FNC）、CNN 和 MSNBC 内容的有线电视倾向文本度量方法，分析地方报纸如何采用 FNC 的倾向而不是 CNN/MSNBC 的倾向。研究结果显示，地方新闻随着当地 FNC 观众人数的外部增长而变得更加类似于 FNC 的内容。这种转变不仅限于从有线电视借鉴，而是地方报纸自身内容的改变。此外，有线电视倾向极化了地方新闻内容。

    We examine the diffusion of media slant, specifically how partisan content from national cable news affects local newspapers in the U.S., 2005-2008. We use a text-based measure of cable news slant trained on content from Fox News Channel (FNC), CNN, and MSNBC to analyze how local newspapers adopt FNC's slant over CNN/MSNBC's. Our findings show that local news becomes more similar to FNC content in response to an exogenous increase in local FNC viewership. This shift is not limited to borrowing from cable news, but rather, local newspapers' own content changes. Further, cable TV slant polarizes local news content.
    

