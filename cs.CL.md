# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Towards Generalist Biomedical AI.](http://arxiv.org/abs/2307.14334) | 这篇论文介绍了一种通用的生物医学人工智能系统，该系统灵活地对多模态的生物医学数据进行编码、整合和解释，可以应用于诸如科学发现和护理交付等重要领域。 |
| [^2] | [Evaluating the Moral Beliefs Encoded in LLMs.](http://arxiv.org/abs/2307.14324) | 本文提出了一种对LLMs中编码的道德信念进行评估的案例研究方法。通过设计大规模调查了解不同LLMs中的道德信念，在明确的情况下，LLMs倾向于与人类的道德直觉保持一致，但在模糊的情况下，它们的回答会有所不同，并可能存在偏见和不一致性。 |
| [^3] | [Comparative Analysis of Libraries for the Sentimental Analysis.](http://arxiv.org/abs/2307.14311) | 本研究对情感分析库进行比较分析，探讨了情感分析和所使用的库的问题，并提供了一些合作方法来分类情绪极性。 |
| [^4] | [Automatically Evaluating Opinion Prevalence in Opinion Summarization.](http://arxiv.org/abs/2307.14305) | 本论文提出了一种自动评估意见总结的意见普遍性的方法，通过统计与摘要陈述一致的评论数量，并排除琐碎或冗余的陈述。实验证明，人类编写的摘要在意见普遍性方面仅稍微优于从源评论中随机选择的摘录。 |
| [^5] | [ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality.](http://arxiv.org/abs/2307.14298) | 本文研究了将ChatGPT和说服技术应用于酒店推荐系统的潜力，通过ChatGPT可以提供更准确和上下文感知的推荐，而说服技术可影响用户行为并增强推荐的说服力。 |
| [^6] | [Founding a mathematical diffusion model in linguistics. The case study of German syntactic features in the North-Eastern Italian dialects.](http://arxiv.org/abs/2307.14291) | 该论文通过研究德语句法特征在北东意大利方言中的传播，建立了一个数学扩散模型，并通过地理数据科学工具生成了交互式地图。 |
| [^7] | [UnScientify: Detecting Scientific Uncertainty in Scholarly Full Text.](http://arxiv.org/abs/2307.14236) | UnScientify是一个交互系统，可以检测学术全文中的科学不确定性。它利用弱监督技术和细粒度注释方案，自动标记和注释科学不确定性，并提供可解释的结果。 |
| [^8] | [LOIS: Looking Out of Instance Semantics for Visual Question Answering.](http://arxiv.org/abs/2307.14142) | LOIS是一个新的模型框架，用于解决视觉问答中的语义理解问题。它不依赖于边界框，并使用精细的特征描述来生成视觉事实。另外，LOIS通过两种类型的关系注意力模块来解决由实例掩码引起的标签不确定性。 |
| [^9] | [Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models.](http://arxiv.org/abs/2307.14134) | 本研究开发并评估了小型到中型的土耳其BERT模型，在填补资源匮乏语言领域的研究空白方面取得了积极的成果，并为开发和应用小型语言模型提供了有价值的见解。 |
| [^10] | [Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for Automatic Speech Recognition.](http://arxiv.org/abs/2307.14132) | 本文提出了一种名为CIF-Transducer的新型模型，将连续积分和火机制与RNN-T模型结合起来，实现了高效的对齐，并放弃了RNN-T Loss，从而减少了计算量，并使预测网络发挥更重要的作用。实验证明CIF-T在自动语音识别中取得了最先进的结果。 |
| [^11] | [Leveraging Implicit Feedback from Deployment Data in Dialogue.](http://arxiv.org/abs/2307.14117) | 研究利用对话中的隐式反馈来改进社交对话系统。实验结果表明通过收集用户响应长度、情感和反应等信号可以提高机器生成话语的质量。 |
| [^12] | [Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions.](http://arxiv.org/abs/2307.14107) | 本论文对ChatGPT的现有研究进行了分类学总结，并探索了其在各个应用领域中的潜力。此外，该研究还批判性分析了现有文献和ChatGPT在解决现实挑战方面的贡献。 |
| [^13] | [Multi3WOZ: A Multilingual, Multi-Domain, Multi-Parallel Dataset for Training and Evaluating Culturally Adapted Task-Oriented Dialog Systems.](http://arxiv.org/abs/2307.14031) | Multi3WOZ是一个用于训练和评估文化适应任务导向对话系统的多语言、多领域、多对话平行数据集。 |
| [^14] | [Unsupervised extraction of local and global keywords from a single text.](http://arxiv.org/abs/2307.14005) | 这种无监督的方法可以从单一文本中提取关键词，具有更高效的长文本关键词提取能力，可以推断出局部和全局关键词，并揭示文本的基本主题。此外，它还是语言无关的，适用于短文本。 |
| [^15] | [Affective Natural Language Generation of Event Descriptions through Fine-grained Appraisal Conditions.](http://arxiv.org/abs/2307.14004) | 本研究提出了一种基于细粒度评估条件的情感自然语言生成模型，该模型能够更详细地了解特定情绪的形成原因和属性，从而使文本生成更加准确和逼真。 |
| [^16] | [This is not correct! Negation-aware Evaluation of Language Generation Systems.](http://arxiv.org/abs/2307.13989) | 本文提出了一种对语言生成系统进行否定感知的评估方法，并开发了NegBLEURT评估指标以提高对否定的敏感性。实验结果表明，该方法在否定句上的表现优于现有指标，并且在其他扰动上保持了性能。 |
| [^17] | [How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?.](http://arxiv.org/abs/2307.13949) | 这项研究探讨了扩散模型对预训练语言模型(PLMs)在超出分布(OOD)数据上的影响。研究发现，在OOD数据上使用扩散微调PLMs会降低重建能力。比较实验还表明，扩散模型能够有效提高OOD样本的重构能力和检测能力。 |
| [^18] | [GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning.](http://arxiv.org/abs/2307.13923) | 本文介绍了GrammarGPT，一个开源LLM用于母语汉语语法错误修正，通过混合数据集和启发式方法，提高了模型的修正能力。 |
| [^19] | [FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction.](http://arxiv.org/abs/2307.13900) | FinTree是一种用于关系抽取的金融数据集预训练变换器编码器，其采用了预测掩码标记的新颖结构，通过训练提供上下文和位置信息，并在大规模金融关系抽取数据集上表现出色。 |
| [^20] | [WebArena: A Realistic Web Environment for Building Autonomous Agents.](http://arxiv.org/abs/2307.13854) | WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。 |
| [^21] | [ARC-NLP at Multimodal Hate Speech Event Detection 2023: Multimodal Methods Boosted by Ensemble Learning, Syntactical and Entity Features.](http://arxiv.org/abs/2307.13829) | 本文介绍了在《2023年多模态仇恨言论事件检测》中，我们利用多模态深度学习模型与集成学习和句法、实体特征相结合的方法来检测仇恨言论和宣传。通过实验证明，我们的模型在多模态仇恨言论检测中表现出优异的性能。 |
| [^22] | [Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy.](http://arxiv.org/abs/2307.13808) | 本论文研究了在语言模型中嵌入水印以进行AI检测的挑战，并提出了一种简单而有效的语义感知水印算法，该算法在保持检测能力的同时，在不同的文本生成任务中取得了显著改进。 |
| [^23] | [Is GPT a Computational Model of Emotion? Detailed Analysis.](http://arxiv.org/abs/2307.13779) | 本文通过组件的视角研究了GPT系列大型语言模型的情感推理能力。尽管GPT的预测结果与人类提供的评估和情感标签显著一致，但在预测情感强度和应对反应方面遇到了困难。 |
| [^24] | [Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning Sparse Contextualized Word Representations.](http://arxiv.org/abs/2307.13776) | 本文提出了使用大型预训练单语语言模型和上下文化映射机制来解决跨语言词义消歧的多语言诅咒，并通过实验验证了这种方法的有效性。 |
| [^25] | [Diversity and Language Technology: How Techno-Linguistic Bias Can Cause Epistemic Injustice.](http://arxiv.org/abs/2307.13714) | 本文揭示了多样性和语言技术之间的关系，指出科技语言偏见会导致认识论不公正的问题，限制了AI技术对于未服务语言的发展和应用。 |
| [^26] | [Measuring Faithfulness in Chain-of-Thought Reasoning.](http://arxiv.org/abs/2307.13702) | 本研究探讨了在回答问题之前，大型语言模型（LLMs）能否进行忠实的“链式思维”推理。结果显示，模型在不同任务上对链式思维的依赖程度有很大变化，随着模型变得更大更能力越强，它们在大多数任务中产生的推理越来越不忠实。 |
| [^27] | [EFL Students' Attitudes and Contradictions in a Machine-in-the-loop Activity System.](http://arxiv.org/abs/2307.13699) | 这项研究探讨了67位来自香港四所中学的EFL学生对机器辅助写作的态度和矛盾。研究发现学生对机器辅助写作持积极态度，但也存在一些负面或矛盾的感情。研究提出了在EFL课堂中实施机器辅助写作的益处和挑战，建议教育工作者将活动目标与学生的价值观、语言能力和AI能力相一致，以提高学生的活动系统。 |
| [^28] | [GPT-3 Models are Few-Shot Financial Reasoners.](http://arxiv.org/abs/2307.13617) | GPT-3模型在金融领域的少样本推理表现有限，需要使用独立的检索模型和逻辑引擎来获得最佳性能。 |
| [^29] | [FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios.](http://arxiv.org/abs/2307.13528) | 提出了FacTool框架，用于检测大型语言模型（如ChatGPT）生成的文本中的事实错误。实验结果表明该方法在知识型问答、代码生成、数学推理和科学文献综述等四个任务中具有良好的效果。 |
| [^30] | [MediaGPT : A Large Language Model For Chinese Media.](http://arxiv.org/abs/2307.10930) | 本论文提出了MediaGPT，一个用于中国媒体领域的大型语言模型。通过特定领域数据和专家数据的训练，MediaGPT在各种中国媒体任务上优于主流模型，并验证了其重要性。 |
| [^31] | [Do Emergent Abilities Exist in Quantized Large Language Models: An Empirical Study.](http://arxiv.org/abs/2307.08072) | 本研究旨在研究量子化对大型语言模型中的新兴能力的影响，结果显示在4位量化模型中这些新兴能力仍然存在。 |
| [^32] | [No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models.](http://arxiv.org/abs/2307.06440) | 本论文重新审视了基于Transformer的语言模型的高效训练算法，包括动态架构，批量选择和高效优化器。然而，在使用这些算法预训练时，相对于基线方法，它们的训练、验证和下游收益消失了。同时，论文提出了一个评估协议来进行计算，并释放了代码来促进高效训练的研究。 |
| [^33] | [MMBench: Is Your Multi-modal Model an All-around Player?.](http://arxiv.org/abs/2307.06281) | MMBench是一个新型的多模态基准测试，旨在解决大型视觉语言模型评估的挑战，通过开发全面的评估流程和精心策划的数据集进行细粒度能力评估。 |
| [^34] | [SAS Video-QA: Self-Adaptive Sampling for Efficient Video Question-Answering.](http://arxiv.org/abs/2307.04192) | SAS视频问答通过自适应采样策略解决了视频问答中的问题，提高了效率和准确性 |
| [^35] | [Derivative Free Weight-space Ensembling.](http://arxiv.org/abs/2307.03506) | 本文引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。通过在几个不同的知识库的角度上对专家模型进行微调，并使用无梯度优化算法进行线性插值，我们有效地找到了一个好的模型权重插值，从而在FETA-Friends上超过了标准的预训练-微调方法。 |
| [^36] | ["Are you telling me to put glasses on the dog?'' Content-Grounded Annotation of Instruction Clarification Requests in the CoDraw Dataset.](http://arxiv.org/abs/2306.02377) | 这项工作在CoDraw数据集中扩展了已有的指令澄清请求标识符，注释了与底层对话游戏项目和可能动作相关的细节信息，可以用于模拟和评估对话代理的修复能力 |
| [^37] | [Table and Image Generation for Investigating Knowledge of Entities in Pre-trained Vision and Language Models.](http://arxiv.org/abs/2306.02115) | 本文提出了一个表格和图像生成的任务，研究了预训练的视觉与语言模型中关于实体的知识如何被保留。通过实验结果发现，预训练模型OFA在生成图像的过程中忘记了部分实体知识。 |
| [^38] | [Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale.](http://arxiv.org/abs/2306.00017) | 本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。 |
| [^39] | [Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework.](http://arxiv.org/abs/2302.12247) | 通过引入信息分解框架，我们提供了一种量化和建模多模态交互的方法，通过PID统计量来度量输入模态与输出任务之间的冗余度、独特性和协同性，并引入了两个新的PID统计估计器。 |
| [^40] | [Direct Speech Translation for Automatic Subtitling.](http://arxiv.org/abs/2209.13192) | 本论文提出了自动字幕的直接语音翻译模型，通过单一模型生成目标语言的字幕及其时间戳，该方法在多语言对上对比级联系统表现更好，并在领域内和领域外基准测试中与生产工具相媲美。 |
| [^41] | [Exploring Multi-Modal Representations for Ambiguity Detection & Coreference Resolution in the SIMMC 2.0 Challenge.](http://arxiv.org/abs/2202.12645) | 本文在SIMMC 2.0挑战中探索了多模态表达对于歧义检测和共识消解的影响，并通过实验证明了语言模型的能力和基于单模态的共识消解模型的优势。 |
| [^42] | [A Comprehensive Comparison of Pre-training Language Models.](http://arxiv.org/abs/2106.11483) | 本文比较了各种预训练语言模型的效率，发现添加RNN层可以在短文本理解中获得最大的改进，但对于类似的BERT结构并没有明显的改进。数据中心方法能够实现更好的性能。 |

# 详细

[^1]: 迈向通用的生物医学人工智能

    Towards Generalist Biomedical AI. (arXiv:2307.14334v1 [cs.CL])

    [http://arxiv.org/abs/2307.14334](http://arxiv.org/abs/2307.14334)

    这篇论文介绍了一种通用的生物医学人工智能系统，该系统灵活地对多模态的生物医学数据进行编码、整合和解释，可以应用于诸如科学发现和护理交付等重要领域。

    

    医学本质上是多模态的，具有丰富的数据模态，包括文本、影像、基因组等。灵活地对这些数据进行编码、整合和解释的通用生物医学人工智能系统可以实现从科学发现到护理交付的重要应用。为了促进这些模型的发展，我们首先策划了一个新的多模态生物医学基准，称为MultiMedBench。MultiMedBench涵盖了14项不同的任务，包括医学问题回答、乳腺造影和皮肤病图像解释、放射学报告生成和总结、基因组变异调用等。然后，我们引入了Med-PaLM Multimodal (Med-PaLM M)，这是我们通用生物医学人工智能系统的概念验证。Med-PaLM M是一个大型多模态生成模型，可以灵活地编码和解释包括临床语言、影像和基因组在内的生物医学数据，使用相同的模型权重。Med-PaLM M的性能达到或超过竞争对手的水平。

    Medicine is inherently multimodal, with rich data modalities spanning text, imaging, genomics, and more. Generalist biomedical artificial intelligence (AI) systems that flexibly encode, integrate, and interpret this data at scale can potentially enable impactful applications ranging from scientific discovery to care delivery. To enable the development of these models, we first curate MultiMedBench, a new multimodal biomedical benchmark. MultiMedBench encompasses 14 diverse tasks such as medical question answering, mammography and dermatology image interpretation, radiology report generation and summarization, and genomic variant calling. We then introduce Med-PaLM Multimodal (Med-PaLM M), our proof of concept for a generalist biomedical AI system. Med-PaLM M is a large multimodal generative model that flexibly encodes and interprets biomedical data including clinical language, imaging, and genomics with the same set of model weights. Med-PaLM M reaches performance competitive with or e
    
[^2]: 评估LLMs中编码的道德信念

    Evaluating the Moral Beliefs Encoded in LLMs. (arXiv:2307.14324v1 [cs.CL])

    [http://arxiv.org/abs/2307.14324](http://arxiv.org/abs/2307.14324)

    本文提出了一种对LLMs中编码的道德信念进行评估的案例研究方法。通过设计大规模调查了解不同LLMs中的道德信念，在明确的情况下，LLMs倾向于与人类的道德直觉保持一致，但在模糊的情况下，它们的回答会有所不同，并可能存在偏见和不一致性。

    

    本文提供了一个关于对大型语言模型(LLMs)进行设计、管理、后处理和评估调查的案例研究。它包括两个组成部分：(1) 一种用于获取LLMs中编码的信念的统计方法。我们介绍了统计量和评估指标，用于量化LLM“做出选择”的概率、相关的不确定性以及选择的一致性。(b) 我们将这种方法应用于研究不同LLMs中编码的道德信念，特别是在正确选择不明显的模糊情况下。我们设计了一个大规模调查，其中包括680个高模糊度的道德场景（例如，“我应该撒一个善意的谎言吗？”）和687个低模糊度的道德场景（例如，“我应该为路上的行人停下来吗？”）。每个场景包括一个描述、两个可能的行动以及指示违反规则的辅助标签（例如，“不要杀人”）。我们将这个调查应用于28个开源和闭源的LLMs。我们发现(b) 在明确的情况下，LLMs tend to align with human moral intuitions, but in ambiguous scenarios, their responses vary and may exhibit biases and inconsistencies.

    This paper presents a case study on the design, administration, post-processing, and evaluation of surveys on large language models (LLMs). It comprises two components: (1) A statistical method for eliciting beliefs encoded in LLMs. We introduce statistical measures and evaluation metrics that quantify the probability of an LLM "making a choice", the associated uncertainty, and the consistency of that choice. (2) We apply this method to study what moral beliefs are encoded in different LLMs, especially in ambiguous cases where the right choice is not obvious. We design a large-scale survey comprising 680 high-ambiguity moral scenarios (e.g., "Should I tell a white lie?") and 687 low-ambiguity moral scenarios (e.g., "Should I stop for a pedestrian on the road?"). Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g., "do not kill"). We administer the survey to 28 open- and closed-source LLMs. We find that (a) in unambiguous scen
    
[^3]: 情感分析库的比较分析

    Comparative Analysis of Libraries for the Sentimental Analysis. (arXiv:2307.14311v1 [cs.CL])

    [http://arxiv.org/abs/2307.14311](http://arxiv.org/abs/2307.14311)

    本研究对情感分析库进行比较分析，探讨了情感分析和所使用的库的问题，并提供了一些合作方法来分类情绪极性。

    

    本研究的主要目标是使用机器学习方法对情感分析库进行比较分析。自然语言处理（NLP）领域的专家对文本情感分析越来越感兴趣，目的是识别和分类与Twitter用户言论相关的情感。本研究还探讨了情感分析和所使用的库的问题，并提供了一些合作方法来分类情绪极性。根据最近的研究，朴素贝叶斯分类器、决策树分类器、最大熵分类器、Sklearn分类器、Sklearn分类器MultinomialNB等共同学习算法非常有效。在本项目中，将使用五个Python和R库NLTK、TextBlob、Vader、Transformers（GPT和BERT预训练）以及Tidytext来应用情感分析技术。

    This study is main goal is to provide a comparative comparison of libraries using machine learning methods. Experts in natural language processing (NLP) are becoming more and more interested in sentiment analysis (SA) of text changes. The objective of employing NLP text analysis techniques is to recognize and categorize feelings related to twitter users utterances. In this examination, issues with SA and the libraries utilized are also looked at. provides a number of cooperative methods to classify emotional polarity. The Naive Bayes Classifier, Decision Tree Classifier, Maxent Classifier, Sklearn Classifier, Sklearn Classifier MultinomialNB, and other conjoint learning algorithms, according to recent research, are very effective. In the project will use Five Python and R libraries NLTK, TextBlob, Vader, Transformers (GPT and BERT pretrained), and Tidytext will be used in the study to apply sentiment analysis techniques. Four machine learning models Tree of Decisions (DT), Support Vect
    
[^4]: 自动评估意见总结中的意见普遍性

    Automatically Evaluating Opinion Prevalence in Opinion Summarization. (arXiv:2307.14305v1 [cs.CL])

    [http://arxiv.org/abs/2307.14305](http://arxiv.org/abs/2307.14305)

    本论文提出了一种自动评估意见总结的意见普遍性的方法，通过统计与摘要陈述一致的评论数量，并排除琐碎或冗余的陈述。实验证明，人类编写的摘要在意见普遍性方面仅稍微优于从源评论中随机选择的摘录。

    

    当面对大量产品评论时，不清楚人类是否能记住所有评论并以代表性权重编写好的参考摘要。我们提出了一种自动度量标准来测试摘要所表达的意见普遍性，该标准基于统计与摘要中每个陈述一致的评论数量，同时贬低琐碎或冗余的陈述。为了制定这种意见普遍性度量标准，我们考虑了几种现有方法来评分摘要陈述相对于每个个体源评论的事实一致性。在亚马逊产品评论语料库上，我们收集了多个人对意见一致性的评判，以确定哪种自动度量标准最能表达产品评论的一致性。通过使用得到的意见普遍性度量标准，我们展示了人类编写的摘要与从源评论中随机选择的摘录相比只有稍微更好的意见普遍性，以及以前的摘录方法。

    When faced with a large number of product reviews, it is not clear that a human can remember all of them and weight opinions representatively to write a good reference summary. We propose an automatic metric to test the prevalence of the opinions that a summary expresses, based on counting the number of reviews that are consistent with each statement in the summary, while discrediting trivial or redundant statements. To formulate this opinion prevalence metric, we consider several existing methods to score the factual consistency of a summary statement with respect to each individual source review. On a corpus of Amazon product reviews, we gather multiple human judgments of the opinion consistency, to determine which automatic metric best expresses consistency in product reviews. Using the resulting opinion prevalence metric, we show that a human authored summary has only slightly better opinion prevalence than randomly selected extracts from the source reviews, and previous extractive
    
[^5]: ChatGPT和说服技术在酒店服务领域个性化推荐管理和提供中的应用

    ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality. (arXiv:2307.14298v1 [cs.IR])

    [http://arxiv.org/abs/2307.14298](http://arxiv.org/abs/2307.14298)

    本文研究了将ChatGPT和说服技术应用于酒店推荐系统的潜力，通过ChatGPT可以提供更准确和上下文感知的推荐，而说服技术可影响用户行为并增强推荐的说服力。

    

    推荐系统在酒店服务业已成为不可或缺的工具，为客人提供个性化和定制化的体验。近年来，大型语言模型（LLM），如ChatGPT和说服技术的进步，为提升这些系统的效果打开了新的途径。本文探讨了将ChatGPT和说服技术整合到酒店服务推荐系统中自动化和改进的潜力。首先，我们深入研究了ChatGPT的能力，它可以理解和生成类似人类的文本，从而实现更准确和上下文感知的推荐。我们讨论了将ChatGPT整合到推荐系统中的能力，突出了其分析用户偏好、从在线评论中提取有价值的洞见，并根据客人配置生成个性化推荐的能力。其次，我们研究了说服技术在影响用户行为和提升酒店推荐的说服效果方面的作用。

    Recommender systems have become indispensable tools in the hotel hospitality industry, enabling personalized and tailored experiences for guests. Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies, have opened new avenues for enhancing the effectiveness of those systems. This paper explores the potential of integrating ChatGPT and persuasive technologies for automating and improving hotel hospitality recommender systems. First, we delve into the capabilities of ChatGPT, which can understand and generate human-like text, enabling more accurate and context-aware recommendations. We discuss the integration of ChatGPT into recommender systems, highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles. Second, we investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recomm
    
[^6]: 在语言学中创立一个数学扩散模型。北东意大利方言中德语句法特征的案例研究。

    Founding a mathematical diffusion model in linguistics. The case study of German syntactic features in the North-Eastern Italian dialects. (arXiv:2307.14291v1 [cs.CL])

    [http://arxiv.org/abs/2307.14291](http://arxiv.org/abs/2307.14291)

    该论文通过研究德语句法特征在北东意大利方言中的传播，建立了一个数学扩散模型，并通过地理数据科学工具生成了交互式地图。

    

    我们以北东意大利罗曼方言中德语句法特征的传播为案例研究，该特征在中世纪高中世纪时期的蒂罗尔德国人移民后发生。使用地理数据科学工具绘制出一个交互式地图。一个平滑的二维曲面$\mathcal{G}$表示当地使用给定德语语言特征的领土比例：通过对表示该特征在任何调查地点是否使用的离散函数进行插值得到。

    We take as a case study the spread of Germanic syntactic features into Romance dialects of North-Eastern Italy, which occurred after the immigration of German people in the Tyrol during the High Middle Ages.  An interactive map is produced using tools of what is called Geographic Data Science. A smooth two-dimensional surface $\mathcal{G}$ expresses locally which fraction of territory uses a given German language feature: it is obtained by interpolating a discrete function that says if at any surveyed locality that feature is used or not.\newline  This surface $\mathcal{G}$ is thought of as the value at the present time of a function describing a diffusion-convection phenomenon in two dimensions (here said \emph{tidal} mode), which is subjected in a very natural way to the same equation, suitably contextualized, used in physics for a number of phenomenological facts like the heat diffusion. It is shown that solutions of this equation, evaluated at the present time, fit well with the da
    
[^7]: UnScientify: 检测学术全文中的科学不确定性

    UnScientify: Detecting Scientific Uncertainty in Scholarly Full Text. (arXiv:2307.14236v1 [cs.CL])

    [http://arxiv.org/abs/2307.14236](http://arxiv.org/abs/2307.14236)

    UnScientify是一个交互系统，可以检测学术全文中的科学不确定性。它利用弱监督技术和细粒度注释方案，自动标记和注释科学不确定性，并提供可解释的结果。

    

    本演示论文介绍了UnScientify，一个用于检测学术全文中科学不确定性的交互系统。该系统利用一种弱监督技术，采用细粒度注释方案，从句子级别上识别科学文本中口头表述的不确定性。系统的流程包括模式匹配、复杂句子检查和作者参考检查。我们的方法自动标记和注释科学不确定性识别任务，考虑了不同类型的科学不确定性，可以用于信息检索、文本挖掘和学术文献处理等多种应用。此外，UnScientify提供可解释的结果，有助于理解文本中识别出的科学不确定性实例。

    This demo paper presents UnScientify, an interactive system designed to detect scientific uncertainty in scholarly full text. The system utilizes a weakly supervised technique that employs a fine-grained annotation scheme to identify verbally formulated uncertainty at the sentence level in scientific texts. The pipeline for the system includes a combination of pattern matching, complex sentence checking, and authorial reference checking. Our approach automates labeling and annotation tasks for scientific uncertainty identification, taking into account different types of scientific uncertainty, that can serve various applications such as information retrieval, text mining, and scholarly document processing. Additionally, UnScientify provides interpretable results, aiding in the comprehension of identified instances of scientific uncertainty in text.
    
[^8]: LOIS: 在视觉问答中观察实例语义

    LOIS: Looking Out of Instance Semantics for Visual Question Answering. (arXiv:2307.14142v1 [cs.CV])

    [http://arxiv.org/abs/2307.14142](http://arxiv.org/abs/2307.14142)

    LOIS是一个新的模型框架，用于解决视觉问答中的语义理解问题。它不依赖于边界框，并使用精细的特征描述来生成视觉事实。另外，LOIS通过两种类型的关系注意力模块来解决由实例掩码引起的标签不确定性。

    

    视觉问答(VQA)作为一项多模态任务，需要在视觉和语言之间进行努力，以正确地推断答案。最近的研究尝试开发了各种基于注意力的模块来解决VQA任务。然而，模型推断的性能主要受限于对语义理解的视觉处理。大多数现有的检测方法依赖于边界框，这对于VQA模型理解图像中物体语义的因果关系并正确推断上下文信息仍然是一个严峻的挑战。为此，我们在这项工作中提出了一个更精细的模型框架，名为Looking Out of Instance Semantics (LOIS)，以解决这个重要问题。LOIS能够生成更精细的特征描述，以产生视觉事实。此外，为了克服实例掩码引起的标签不确定性，我们设计了两种类型的关系注意力模块：1) 内部模态和2) 交互模态，用于推断正确的上下文关系。

    Visual question answering (VQA) has been intensively studied as a multimodal task that requires effort in bridging vision and language to infer answers correctly. Recent attempts have developed various attention-based modules for solving VQA tasks. However, the performance of model inference is largely bottlenecked by visual processing for semantics understanding. Most existing detection methods rely on bounding boxes, remaining a serious challenge for VQA models to understand the causal nexus of object semantics in images and correctly infer contextual information. To this end, we propose a finer model framework without bounding boxes in this work, termed Looking Out of Instance Semantics (LOIS) to tackle this important issue. LOIS enables more fine-grained feature descriptions to produce visual facts. Furthermore, to overcome the label ambiguity caused by instance masks, two types of relation attention modules: 1) intra-modality and 2) inter-modality, are devised to infer the correct
    
[^9]: 开发和评估小型到中型的土耳其BERT模型

    Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models. (arXiv:2307.14134v1 [cs.CL])

    [http://arxiv.org/abs/2307.14134](http://arxiv.org/abs/2307.14134)

    本研究开发并评估了小型到中型的土耳其BERT模型，在填补资源匮乏语言领域的研究空白方面取得了积极的成果，并为开发和应用小型语言模型提供了有价值的见解。

    

    本研究引入并评估了小型、迷你型、小型和中型的无大小写的土耳其BERT模型，旨在填补资源匮乏语言领域的研究空白。我们使用多个来源的75GB以上文本数据集对这些模型进行了训练，并在多个任务上进行了测试，包括掩码预测、情感分析、新闻分类和零样本分类。尽管规模较小，我们的模型表现出了强大的性能，包括零样本任务，同时保证了计算效率和更快的执行时间。我们的研究结果为小型语言模型的开发和应用提供了有价值的见解，特别是在土耳其语境下。

    This study introduces and evaluates tiny, mini, small, and medium-sized uncased Turkish BERT models, aiming to bridge the research gap in less-resourced languages. We trained these models on a diverse dataset encompassing over 75GB of text from multiple sources and tested them on several tasks, including mask prediction, sentiment analysis, news classification, and, zero-shot classification. Despite their smaller size, our models exhibited robust performance, including zero-shot task, while ensuring computational efficiency and faster execution times. Our findings provide valuable insights into the development and application of smaller language models, especially in the context of the Turkish language.
    
[^10]: 告别RNN-T Loss：一种新的基于CIF的转录器架构用于自动语音识别

    Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for Automatic Speech Recognition. (arXiv:2307.14132v1 [cs.SD])

    [http://arxiv.org/abs/2307.14132](http://arxiv.org/abs/2307.14132)

    本文提出了一种名为CIF-Transducer的新型模型，将连续积分和火机制与RNN-T模型结合起来，实现了高效的对齐，并放弃了RNN-T Loss，从而减少了计算量，并使预测网络发挥更重要的作用。实验证明CIF-T在自动语音识别中取得了最先进的结果。

    

    RNN-T模型在ASR中广泛使用，依靠RNN-T Loss实现输入音频和目标序列的长度对齐。然而，RNN-T Loss的实现复杂性和基于对齐的优化目标导致计算冗余和预测网络角色的减少。在本文中，我们提出了一种名为CIF-Transducer（CIF-T）的新型模型，它将连续积分和火（CIF）机制与RNN-T模型结合起来，实现高效的对齐。通过这种方式，放弃了RNN-T Loss，从而减少了计算量，并使预测网络发挥更重要的作用。我们还引入了Funnel-CIF、Context Blocks、Unified Gating和Bilinear Pooling联合网络以及辅助训练策略来进一步提高性能。在178小时的AISHELL-1和10000小时的WenetSpeech数据集上的实验证明，与RNN-T模型相比，CIF-T以更低的计算开销实现了最先进的结果。

    RNN-T models are widely used in ASR, which rely on the RNN-T loss to achieve length alignment between input audio and target sequence. However, the implementation complexity and the alignment-based optimization target of RNN-T loss lead to computational redundancy and a reduced role for predictor network, respectively. In this paper, we propose a novel model named CIF-Transducer (CIF-T) which incorporates the Continuous Integrate-and-Fire (CIF) mechanism with the RNN-T model to achieve efficient alignment. In this way, the RNN-T loss is abandoned, thus bringing a computational reduction and allowing the predictor network a more significant role. We also introduce Funnel-CIF, Context Blocks, Unified Gating and Bilinear Pooling joint network, and auxiliary training strategy to further improve performance. Experiments on the 178-hour AISHELL-1 and 10000-hour WenetSpeech datasets show that CIF-T achieves state-of-the-art results with lower computational overhead compared to RNN-T models.
    
[^11]: 在对话中利用来自部署数据的隐式反馈

    Leveraging Implicit Feedback from Deployment Data in Dialogue. (arXiv:2307.14117v1 [cs.CL])

    [http://arxiv.org/abs/2307.14117](http://arxiv.org/abs/2307.14117)

    研究利用对话中的隐式反馈来改进社交对话系统。实验结果表明通过收集用户响应长度、情感和反应等信号可以提高机器生成话语的质量。

    

    我们研究通过学习用户与部署模型之间的自然对话来改进社交对话系统，而无需额外的注释。为了隐式衡量机器生成话语的质量，我们利用收集对话中未来人类话语的用户响应长度、情感和反应等信号。我们的实验使用了BlenderBot（Xu等，2023年）公开发布的部署数据。人类评估显示出我们的新模型比基线回复有所改进；然而，我们发现一些代理信号也可能导致出现不良属性的生成。例如，优化对话长度可能导致与基线相比更具争议性或不友好的生成，而优化积极情感或反应则可以减少这些行为。

    We study improving social conversational agents by learning from natural dialogue between users and a deployed model, without extra annotations. To implicitly measure the quality of a machine-generated utterance, we leverage signals like user response length, sentiment and reaction of the future human utterances in the collected dialogue episodes. Our experiments use the publicly released deployment data from BlenderBot (Xu et al., 2023). Human evaluation indicates improvements in our new models over baseline responses; however, we find that some proxy signals can lead to more generations with undesirable properties as well. For example, optimizing for conversation length can lead to more controversial or unfriendly generations compared to the baseline, whereas optimizing for positive sentiment or reaction can decrease these behaviors.
    
[^12]: 解码ChatGPT：现有研究、当前挑战和未来可能方向的分类学

    Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions. (arXiv:2307.14107v1 [cs.CL])

    [http://arxiv.org/abs/2307.14107](http://arxiv.org/abs/2307.14107)

    本论文对ChatGPT的现有研究进行了分类学总结，并探索了其在各个应用领域中的潜力。此外，该研究还批判性分析了现有文献和ChatGPT在解决现实挑战方面的贡献。

    

    自2022年11月发布以来，Chat GPT（Chat Generative Pre-trained Transformer）引起了极大的兴趣和关注。它在包括考试通过和创造性写作在内的各个领域中展现出令人印象深刻的表现。然而，与偏见和信任相关的挑战和担忧依然存在。在这项工作中，我们对ChatGPT的100多篇Scopus索引的出版物进行了全面回顾，旨在提供ChatGPT研究的分类学，并探索其应用。我们对现有文献进行了批判性分析，确定了研究中常用的方法。此外，我们调查了ChatGPT在医疗、营销和金融服务、软件工程、学术和科学写作、研究和教育、环境科学以及自然语言处理等各种应用领域中的实用性。通过研究这些应用，我们获得了ChatGPT在应对现实挑战方面的有价值的见解。

    Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022. It has shown impressive performance in various domains, including passing exams and creative writing. However, challenges and concerns related to biases and trust persist. In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications. We critically analyze the existing literature, identifying common approaches employed in the studies. Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing. Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges. We also 
    
[^13]: Multi3WOZ: 一个用于训练和评估文化适应任务导向对话系统的多语言、多领域、多对话平行数据集

    Multi3WOZ: A Multilingual, Multi-Domain, Multi-Parallel Dataset for Training and Evaluating Culturally Adapted Task-Oriented Dialog Systems. (arXiv:2307.14031v1 [cs.CL])

    [http://arxiv.org/abs/2307.14031](http://arxiv.org/abs/2307.14031)

    Multi3WOZ是一个用于训练和评估文化适应任务导向对话系统的多语言、多领域、多对话平行数据集。

    

    任务导向对话（ToD）的高质量标注数据的创建被公认为极其困难，而当目标是为多种语言创建公平、文化适应和大规模的ToD数据集时，挑战更加严峻。因此，当前的数据集仍然非常稀缺，并且存在诸如基于翻译的非母语对话与翻译效果不佳、规模小或缺乏文化适应等限制。在这项工作中，我们首先梳理了当前多语言ToD数据集的现状，系统地概述了它们的特点和限制。为了减少所有检测到的限制，我们引入了Multi3WOZ，这是一个新颖的多语言、多领域、多对话平行ToD数据集。它是大规模的，并提供了以四种语言进行文化适应的对话，以便训练和评估多语言和跨语言的ToD系统。我们描述了一个复杂的自下而上的数据收集过程，得到了最终的数据集。

    Creating high-quality annotated data for task-oriented dialog (ToD) is known to be notoriously difficult, and the challenges are amplified when the goal is to create equitable, culturally adapted, and large-scale ToD datasets for multiple languages. Therefore, the current datasets are still very scarce and suffer from limitations such as translation-based non-native dialogs with translation artefacts, small scale, or lack of cultural adaptation, among others. In this work, we first take stock of the current landscape of multilingual ToD datasets, offering a systematic overview of their properties and limitations. Aiming to reduce all the detected limitations, we then introduce Multi3WOZ, a novel multilingual, multi-domain, multi-parallel ToD dataset. It is large-scale and offers culturally adapted dialogs in 4 languages to enable training and evaluation of multilingual and cross-lingual ToD systems. We describe a complex bottom-up data collection process that yielded the final dataset,
    
[^14]: 单一文本的无监督提取局部和全局关键词

    Unsupervised extraction of local and global keywords from a single text. (arXiv:2307.14005v1 [cs.CL])

    [http://arxiv.org/abs/2307.14005](http://arxiv.org/abs/2307.14005)

    这种无监督的方法可以从单一文本中提取关键词，具有更高效的长文本关键词提取能力，可以推断出局部和全局关键词，并揭示文本的基本主题。此外，它还是语言无关的，适用于短文本。

    

    我们提出了一种无监督、与语料库无关的方法来从单一文本中提取关键词。它基于单词的空间分布及其对单词的随机排列的响应。与现有方法（如YAKE等）相比，我们的方法具有三个优点。首先，它在从长文本中提取关键词方面更加有效。其次，它能够推断出两种类型的关键词：局部和全局。第三，它揭示了文本的基本主题。此外，我们的方法与语言无关，适用于短文本。结果通过我们的古典文学作品数据库的具备先前知识的人类注释者获得（注释者之间的一致性从中等到重大）。我们的结果得到了基于提取内容词的平均长度和提取词中名词的平均数量的无人参与论证的支持。我们讨论了关键词与高阶文本特征的关系。

    We propose an unsupervised, corpus-independent method to extract keywords from a single text. It is based on the spatial distribution of words and the response of this distribution to a random permutation of words. As compared to existing methods (such as e.g. YAKE) our method has three advantages. First, it is significantly more effective at extracting keywords from long texts. Second, it allows inference of two types of keywords: local and global. Third, it uncovers basic themes in texts. Additionally, our method is language-independent and applies to short texts. The results are obtained via human annotators with previous knowledge of texts from our database of classical literary works (the agreement between annotators is from moderate to substantial). Our results are supported via human-independent arguments based on the average length of extracted content words and on the average number of nouns in extracted words. We discuss relations of keywords with higher-order textual feature
    
[^15]: 基于细粒度评估条件的情感自然语言生成事件描述

    Affective Natural Language Generation of Event Descriptions through Fine-grained Appraisal Conditions. (arXiv:2307.14004v1 [cs.CL])

    [http://arxiv.org/abs/2307.14004](http://arxiv.org/abs/2307.14004)

    本研究提出了一种基于细粒度评估条件的情感自然语言生成模型，该模型能够更详细地了解特定情绪的形成原因和属性，从而使文本生成更加准确和逼真。

    

    情感文本生成模型取得了显著进展，但通常仅依赖于基本情绪理论或价值/唤醒值作为条件。然而，情感通常是隐含传达的。我们假设并随后展示，在生成框架中包括评估变量作为条件具有两个优势。第一，生成模型能够更详细地了解特定情绪的形成原因和属性。这导致文本生成更加准确和逼真。

    Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements ("The kid is happy."). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event ("Their dog died.") does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generat
    
[^16]: 这是不正确的！对语言生成系统进行否定感知的评估

    This is not correct! Negation-aware Evaluation of Language Generation Systems. (arXiv:2307.13989v1 [cs.CL])

    [http://arxiv.org/abs/2307.13989](http://arxiv.org/abs/2307.13989)

    本文提出了一种对语言生成系统进行否定感知的评估方法，并开发了NegBLEURT评估指标以提高对否定的敏感性。实验结果表明，该方法在否定句上的表现优于现有指标，并且在其他扰动上保持了性能。

    

    大型语言模型低估了否定对句子含义变化的影响。因此，基于这些模型的学习评估指标对否定不敏感。在本文中，我们提出了NegBLEURT，一种针对否定感知的BLEURT评估指标的改进版本。为此，我们设计了一种基于规则的句子否定工具，并用它来创建了CANNOT否定评估数据集。基于这个数据集，我们对句子转换器和评估指标进行了微调，以提高它们对否定的敏感性。在现有的基准测试中评估这些模型表明，我们微调后的模型在否定句上的表现远远优于现有的指标，同时保持了它们基础模型在其他扰动上的性能。

    Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations. In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity. Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.
    
[^17]: 扩散如何影响预训练语言模型在超出分布数据上的表现？

    How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?. (arXiv:2307.13949v1 [cs.CL])

    [http://arxiv.org/abs/2307.13949](http://arxiv.org/abs/2307.13949)

    这项研究探讨了扩散模型对预训练语言模型(PLMs)在超出分布(OOD)数据上的影响。研究发现，在OOD数据上使用扩散微调PLMs会降低重建能力。比较实验还表明，扩散模型能够有效提高OOD样本的重构能力和检测能力。

    

    基于Transformer的预训练语言模型(PLMs)在现代自然语言处理(NLP)领域取得了巨大成功。PLMs的一个重要优势是良好的超出分布(OOD)鲁棒性。最近，扩散模型吸引了很多研究将扩散应用于PLMs。然而，扩散对PLMs在OOD数据上的影响仍未得到充分探讨。扩散模型的核心是一个前向扩散过程，逐渐对输入应用高斯噪声，并且一个反向去噪过程，用于去除噪声。噪声输入重建是扩散模型的基本能力。我们通过测量重建损失直接分析OOD鲁棒性，包括测试重建OOD数据和检测OOD样本的能力。通过分析不同的训练参数和数据统计特征在八个数据集上进行了实验。结果显示，使用扩散微调PLMs会降低在OOD数据上的重建能力。比较还表明，扩散模型可以有效地提高OOD样本的重构能力和检测能力。

    Transformer-based pretrained language models (PLMs) have achieved great success in modern NLP. An important advantage of PLMs is good out-of-distribution (OOD) robustness. Recently, diffusion models have attracted a lot of work to apply diffusion to PLMs. It remains under-explored how diffusion influences PLMs on OOD data. The core of diffusion models is a forward diffusion process which gradually applies Gaussian noise to inputs, and a reverse denoising process which removes noise. The noised input reconstruction is a fundamental ability of diffusion models. We directly analyze OOD robustness by measuring the reconstruction loss, including testing the abilities to reconstruct OOD data, and to detect OOD samples. Experiments are conducted by analyzing different training parameters and data statistical features on eight datasets. It shows that finetuning PLMs with diffusion degrades the reconstruction ability on OOD data. The comparison also shows that diffusion models can effectively d
    
[^18]: GrammarGPT: 使用有监督微调的开源LLM探索母语汉语语法错误修正

    GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning. (arXiv:2307.13923v1 [cs.CL])

    [http://arxiv.org/abs/2307.13923](http://arxiv.org/abs/2307.13923)

    本文介绍了GrammarGPT，一个开源LLM用于母语汉语语法错误修正，通过混合数据集和启发式方法，提高了模型的修正能力。

    

    语法错误修正旨在自动修正不符合语法的句子。最近的一些研究表明，闭源大型语言模型（LLM，例如ChatGPT）在语法错误修正方面具有出色的能力。然而，开源LLM的潜力仍未被探索。本文介绍了一个名为GrammarGPT的开源LLM，旨在初步探索其在母语汉语语法错误修正方面的潜力。GrammarGPT的核心方法是利用ChatGPT生成的数据和人工标注的混合数据集。对于带有提示信息的语法错误，我们提出了一种启发式方法来指导ChatGPT通过提供这些提示信息生成不符合语法的句子。对于没有提示信息的语法错误，我们从公开可用的网站收集了不符合语法的句子，并进行手动修正。此外，我们还采用了一种错误不变增强方法，以增强该模型纠正母语汉语语法错误的能力。

    Grammatical error correction aims to correct ungrammatical sentences automatically. Recently, some work has demonstrated the excellent capabilities of closed-source Large Language Models (LLMs, e.g., ChatGPT) in grammatical error correction. However, the potential of open-source LLMs remains unexplored. In this paper, we introduced GrammarGPT, an open-source LLM, to preliminary explore its potential for native Chinese grammatical error correction. The core recipe of GrammarGPT is to leverage the hybrid dataset of ChatGPT-generated and human-annotated. For grammatical errors with clues, we proposed a heuristic method to guide ChatGPT to generate ungrammatical sentences by providing those clues. For grammatical errors without clues, we collected ungrammatical sentences from publicly available websites and manually corrected them. In addition, we employed an error-invariant augmentation method to enhance the ability of the model to correct native Chinese grammatical errors. We ultimately 
    
[^19]: FinTree：用于关系抽取的金融数据集预训练变换器编码器

    FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction. (arXiv:2307.13900v1 [cs.CL])

    [http://arxiv.org/abs/2307.13900](http://arxiv.org/abs/2307.13900)

    FinTree是一种用于关系抽取的金融数据集预训练变换器编码器，其采用了预测掩码标记的新颖结构，通过训练提供上下文和位置信息，并在大规模金融关系抽取数据集上表现出色。

    

    我们提出了FinTree，使用金融数据集预训练的变换器编码器，用于关系抽取。利用编码器语言模型，在金融领域任务中进一步预训练FinTree。FinTree以其预测掩码标记而不是传统的[CLS]标记的新颖结构而脱颖而出，受到模式利用训练方法的启发。这种结构可以更准确地预测两个给定实体之间的关系。该模型通过一种独特的输入模式进行训练，以提供有关所关注实体的上下文和位置信息，并通过后处理步骤确保与实体类型一致的准确预测。我们的实验证明FinTree在大规模金融关系抽取数据集REFinD上的表现优于其他模型。代码和预训练模型可在https://github.com/HJ-Ok/FinTree上获取。

    We present FinTree, Financial Dataset Pretrain Transformer Encoder for Relation Extraction. Utilizing an encoder language model, we further pretrain FinTree on the financial dataset, adapting the model in financial domain tasks. FinTree stands out with its novel structure that predicts a masked token instead of the conventional [CLS] token, inspired by the Pattern Exploiting Training methodology. This structure allows for more accurate relation predictions between two given entities. The model is trained with a unique input pattern to provide contextual and positional information about the entities of interest, and a post-processing step ensures accurate predictions in line with the entity types. Our experiments demonstrate that FinTree outperforms on the REFinD, a large-scale financial relation extraction dataset. The code and pretrained models are available at https://github.com/HJ-Ok/FinTree.
    
[^20]: WebArena: 一个用于构建自主智能体的真实网络环境

    WebArena: A Realistic Web Environment for Building Autonomous Agents. (arXiv:2307.13854v1 [cs.AI])

    [http://arxiv.org/abs/2307.13854](http://arxiv.org/abs/2307.13854)

    WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。

    

    随着生成式人工智能的进展，通过自然语言指令进行日常任务的自主智能体的潜力逐渐显现。然而，当前的智能体主要是在简化的合成环境中创建和测试的，严重限制了现实世界场景的表示能力。在本文中，我们构建了一个高度逼真且可复现的智能体指令和控制环境。具体而言，我们关注在网站上执行任务的智能体，我们创建了一个包含来自四个常见领域的完全功能网站的环境，分别是电子商务、社交论坛讨论、协同软件开发和内容管理。我们的环境使用工具（如地图）和外部知识库（如用户手册）来鼓励像人类一样解决任务。在我们的环境基础上，我们发布了一组重点评估任务完成功能正确性的基准任务。我们基准任务具有多样性和长远的视野，并且被设计为鼓励智能体进行更深层次的任务理解和解决。

    With generative AI advances, the exciting potential for autonomous agents to manage daily tasks via natural language commands has emerged. However, cur rent agents are primarily created and tested in simplified synthetic environments, substantially limiting real-world scenario representation. In this paper, we build an environment for agent command and control that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and are desi
    
[^21]: 《2023年多模态仇恨言论事件检测中的ARC-NLP: 通过集成学习、句法和实体特征提升的多模态方法》

    ARC-NLP at Multimodal Hate Speech Event Detection 2023: Multimodal Methods Boosted by Ensemble Learning, Syntactical and Entity Features. (arXiv:2307.13829v1 [cs.CL])

    [http://arxiv.org/abs/2307.13829](http://arxiv.org/abs/2307.13829)

    本文介绍了在《2023年多模态仇恨言论事件检测》中，我们利用多模态深度学习模型与集成学习和句法、实体特征相结合的方法来检测仇恨言论和宣传。通过实验证明，我们的模型在多模态仇恨言论检测中表现出优异的性能。

    

    文本嵌入图片可以传播仇恨言论、宣传和极端主义信仰。在俄罗斯-乌克兰战争期间，双方都大量依赖文本嵌入图片传播宣传和仇恨言论。确保有效检测仇恨言论和宣传对于减轻仇恨言论传播的负面影响至关重要。本文概述了我们在《2023年多模态仇恨言论事件检测》两个子任务中的方法。对于第一个子任务，仇恨言论检测，我们采用了通过集成学习和句法文本属性提升的多模态深度学习模型。对于第二个子任务，目标检测，我们使用了通过命名实体特征提升的多模态深度学习模型。通过实验，我们证明了我们的模型相较于在多模态仇恨言论检测中使用的所有文本、视觉和文本-视觉基准线的卓越性能。

    Text-embedded images can serve as a means of spreading hate speech, propaganda, and extremist beliefs. Throughout the Russia-Ukraine war, both opposing factions heavily relied on text-embedded images as a vehicle for spreading propaganda and hate speech. Ensuring the effective detection of hate speech and propaganda is of utmost importance to mitigate the negative effect of hate speech dissemination. In this paper, we outline our methodologies for two subtasks of Multimodal Hate Speech Event Detection 2023. For the first subtask, hate speech detection, we utilize multimodal deep learning models boosted by ensemble learning and syntactical text attributes. For the second subtask, target detection, we employ multimodal deep learning models boosted by named entity features. Through experimentation, we demonstrate the superior performance of our models compared to all textual, visual, and text-visual baselines employed in multimodal hate speech detection. Furthermore, our models achieve th
    
[^22]: 水印技术用于AI检测的条件文本生成：揭示挑战及语义感知水印解决方案

    Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy. (arXiv:2307.13808v1 [cs.CL])

    [http://arxiv.org/abs/2307.13808](http://arxiv.org/abs/2307.13808)

    本论文研究了在语言模型中嵌入水印以进行AI检测的挑战，并提出了一种简单而有效的语义感知水印算法，该算法在保持检测能力的同时，在不同的文本生成任务中取得了显著改进。

    

    为了减轻语言模型可能带来的潜在风险，最近的AI检测研究提出了通过随机限制词汇并利用此信息进行检测的方式将水印嵌入到机器生成的文本中。虽然这些水印只会导致困惑度轻微下降，但我们的实证调查揭示了对条件文本生成性能的显著影响。为了解决这个问题，我们引入了一个简单但有效的语义感知水印算法，考虑了条件文本生成的特性和输入上下文。实验结果表明，我们提出的方法在各种文本生成模型（包括BART和Flan-T5）中取得了显著改进，在摘要生成和数据到文本生成等任务中仍保持了检测能力。

    To mitigate potential risks associated with language models, recent AI detection research proposes incorporating watermarks into machine-generated text through random vocabulary restrictions and utilizing this information for detection. While these watermarks only induce a slight deterioration in perplexity, our empirical investigation reveals a significant detriment to the performance of conditional text generation. To address this issue, we introduce a simple yet effective semantic-aware watermarking algorithm that considers the characteristics of conditional text generation and the input context. Experimental results demonstrate that our proposed method yields substantial improvements across various text generation models, including BART and Flan-T5, in tasks such as summarization and data-to-text generation while maintaining detection ability.
    
[^23]: GPT是情感的计算模型吗？详细分析。

    Is GPT a Computational Model of Emotion? Detailed Analysis. (arXiv:2307.13779v1 [cs.CL])

    [http://arxiv.org/abs/2307.13779](http://arxiv.org/abs/2307.13779)

    本文通过组件的视角研究了GPT系列大型语言模型的情感推理能力。尽管GPT的预测结果与人类提供的评估和情感标签显著一致，但在预测情感强度和应对反应方面遇到了困难。

    

    本文通过组件的视角研究了GPT系列大型语言模型的情感推理能力。首先，本文考察了该模型对自传式记忆的推理方式。其次，通过系统性地改变情境的各个方面来影响情感强度和应对倾向。研究结果表明，即使在没有使用提示工程的情况下，GPT的预测结果与人类提供的评估和情感标签显著一致。然而，GPT在预测情感强度和应对反应方面遇到了困难。尽管GPT-4在初步研究中表现最好，但在第二项研究中表现不佳，尽管经过轻微的提示工程后提供了更好的结果。这个评估引发了如何有效地利用这些模型的优点并解决其弱点的问题，尤其是关于响应的变异性。这些研究突显了从组件的角度评估模型的优点。

    This paper investigates the emotional reasoning abilities of the GPT family of large language models via a component perspective. The paper first examines how the model reasons about autobiographical memories. Second, it systematically varies aspects of situations to impact emotion intensity and coping tendencies. Even without the use of prompt engineering, it is shown that GPT's predictions align significantly with human-provided appraisals and emotional labels. However, GPT faces difficulties predicting emotion intensity and coping responses. GPT-4 showed the highest performance in the initial study but fell short in the second, despite providing superior results after minor prompt engineering. This assessment brings up questions on how to effectively employ the strong points and address the weak areas of these models, particularly concerning response variability. These studies underscore the merits of evaluating models from a componential perspective.
    
[^24]: 通过对齐稀疏上下文化的词表示来解决跨语言词义消歧中的多语言诅咒

    Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning Sparse Contextualized Word Representations. (arXiv:2307.13776v1 [cs.CL])

    [http://arxiv.org/abs/2307.13776](http://arxiv.org/abs/2307.13776)

    本文提出了使用大型预训练单语语言模型和上下文化映射机制来解决跨语言词义消歧的多语言诅咒，并通过实验验证了这种方法的有效性。

    

    本文提倡在跨语言零样本词义消歧（WSD）中使用大型预训练单语语言模型，并结合上下文化映射机制。我们还进行了严格的实验，证明了通过字典学习过程获得的稀疏上下文化词表示的有效性。我们的实验结果表明，上述改进使得17种语言的平均F分数有近6.5个百分点的显著提高（从62.0提高到68.5）。我们在https://github.com/begab/sparsity_makes_sense发布了用于复现我们实验的源代码。

    In this paper, we advocate for using large pre-trained monolingual language models in cross lingual zero-shot word sense disambiguation (WSD) coupled with a contextualized mapping mechanism. We also report rigorous experiments that illustrate the effectiveness of employing sparse contextualized word representations obtained via a dictionary learning procedure. Our experimental results demonstrate that the above modifications yield a significant improvement of nearly 6.5 points of increase in the average F-score (from 62.0 to 68.5) over a collection of 17 typologically diverse set of target languages. We release our source code for replicating our experiments at https://github.com/begab/sparsity_makes_sense.
    
[^25]: 多样性和语言技术：科技语言偏见如何导致认识论不公正

    Diversity and Language Technology: How Techno-Linguistic Bias Can Cause Epistemic Injustice. (arXiv:2307.13714v1 [cs.CY])

    [http://arxiv.org/abs/2307.13714](http://arxiv.org/abs/2307.13714)

    本文揭示了多样性和语言技术之间的关系，指出科技语言偏见会导致认识论不公正的问题，限制了AI技术对于未服务语言的发展和应用。

    

    众所周知，基于人工智能的语言技术，如大型语言模型、机器翻译系统、多语言词典和语料库等，目前仅限于世界上2%至3%的最常用、政治和财政支持最好的语言。为此，最近的研究努力试图将AI技术扩展到“未服务的语言”。在本文中，我们展示了许多这些尝试所产生的解决方案存在缺陷，这些方案遵循了对某些语言的硬编码表现偏好，我们称之为科技语言偏见。科技语言偏见与已经被广泛认可的语言偏见现象不同，它不涉及所代表的语言，而是涉及技术的设计。正如我们在本文中所展示的那样，科技语言偏见可能导致系统只能表达属于特定语言和文化的概念，无法正确表达其他社区的概念。

    It is well known that AI-based language technology -- large language models, machine translation systems, multilingual dictionaries, and corpora -- is currently limited to 2 to 3 percent of the world's most widely spoken and/or financially and politically best supported languages. In response, recent research efforts have sought to extend the reach of AI technology to ``underserved languages.'' In this paper, we show that many of these attempts produce flawed solutions that adhere to a hard-wired representational preference for certain languages, which we call techno-linguistic bias. Techno-linguistic bias is distinct from the well-established phenomenon of linguistic bias as it does not concern the languages represented but rather the design of the technologies. As we show through the paper, techno-linguistic bias can result in systems that can only express concepts that are part of the language and culture of dominant powers, unable to correctly represent concepts from other communit
    
[^26]: 测量链式思维推理中的忠诚度

    Measuring Faithfulness in Chain-of-Thought Reasoning. (arXiv:2307.13702v1 [cs.AI])

    [http://arxiv.org/abs/2307.13702](http://arxiv.org/abs/2307.13702)

    本研究探讨了在回答问题之前，大型语言模型（LLMs）能否进行忠实的“链式思维”推理。结果显示，模型在不同任务上对链式思维的依赖程度有很大变化，随着模型变得更大更能力越强，它们在大多数任务中产生的推理越来越不忠实。

    

    大型语言模型（LLMs）在回答问题之前，如果能够产生逐步的“链式思维”推理，其表现会更好，但不清楚所述的推理是否忠实地解释了模型实际的推理过程（即回答问题的方式）。我们通过检查当介入链式思维时模型预测如何发生变化（例如，添加错误或改写它），来研究链式思维可能不忠实的假设。模型在不同任务上在预测答案时对链式思维的依赖程度有很大变化，有时会严重依赖链式思维，而其他时候则主要忽视它。链式思维的性能提升似乎不仅仅来自于其增加的测试计算量，也不仅仅来自于链式思维的特定措辞所编码的信息。随着模型变得更大更有能力，它们在我们研究的大多数任务中产生的推理越来越不忠实。总体而言，我们的结果表明，如果环境适当，链式思维可以是忠实的。

    Large language models (LLMs) perform better when they produce step-by-step, "Chain-of-Thought" (CoT) reasoning before answering a question, but it is unclear if the stated reasoning is a faithful explanation of the model's actual reasoning (i.e., its process for answering the question). We investigate hypotheses for how CoT reasoning may be unfaithful, by examining how the model predictions change when we intervene on the CoT (e.g., by adding mistakes or paraphrasing it). Models show large variation across tasks in how strongly they condition on the CoT when predicting their answer, sometimes relying heavily on the CoT and other times primarily ignoring it. CoT's performance boost does not seem to come from CoT's added test-time compute alone or from information encoded via the particular phrasing of the CoT. As models become larger and more capable, they produce less faithful reasoning on most tasks we study. Overall, our results suggest that CoT can be faithful if the circumstances s
    
[^27]: EFL学生对机器辅助写作的态度和矛盾的研究

    EFL Students' Attitudes and Contradictions in a Machine-in-the-loop Activity System. (arXiv:2307.13699v1 [cs.HC])

    [http://arxiv.org/abs/2307.13699](http://arxiv.org/abs/2307.13699)

    这项研究探讨了67位来自香港四所中学的EFL学生对机器辅助写作的态度和矛盾。研究发现学生对机器辅助写作持积极态度，但也存在一些负面或矛盾的感情。研究提出了在EFL课堂中实施机器辅助写作的益处和挑战，建议教育工作者将活动目标与学生的价值观、语言能力和AI能力相一致，以提高学生的活动系统。

    

    本研究应用活动理论探讨了来自香港四所中学的67名英语作为外语（EFL）学生对机器辅助写作的态度和矛盾。在写作过程中，人工智能（AI）提供创作想法。学生回答了一个开放性问题，表达他们对与AI一起写作的感受。研究结果显示，大部分学生持积极态度，但也存在一些负面或矛盾的感情。通过主题分析发现，学生和AI之间的矛盾或紧张点源于AI的不足，学生在热情和偏好之间的平衡，以及他们追求语言自主性。研究突出了在EFL课堂上实施机器辅助写作的益处和挑战，建议教育工作者将活动目标与学生的价值观、语言能力和AI能力相一致，以提高学生的活动系统。

    This study applies Activity Theory and investigates the attitudes and contradictions of 67 English as a foreign language (EFL) students from four Hong Kong secondary schools towards machine-in-the-loop writing, where artificial intelligence (AI) suggests ideas during composition. Students answered an open-ended question about their feelings on writing with AI. Results revealed mostly positive attitudes, with some negative or mixed feelings. From a thematic analysis, contradictions or points of tension between students and AI stemmed from AI inadequacies, students' balancing enthusiasm with preference, and their striving for language autonomy. The research highlights the benefits and challenges of implementing machine-in-the-loop writing in EFL classrooms, suggesting educators align activity goals with students' values, language abilities, and AI capabilities to enhance students' activity systems.
    
[^28]: GPT-3模型是少样本金融推理器

    GPT-3 Models are Few-Shot Financial Reasoners. (arXiv:2307.13617v1 [cs.CL])

    [http://arxiv.org/abs/2307.13617](http://arxiv.org/abs/2307.13617)

    GPT-3模型在金融领域的少样本推理表现有限，需要使用独立的检索模型和逻辑引擎来获得最佳性能。

    

    金融分析是评估公司业绩的重要工具。从业者通过深入的量化分析回答金融问题，从而做出有利可图的投资决策。因此，金融问答是一个需要对数字进行深入推理的问题回答任务。此外，目前尚不清楚预训练语言模型在金融领域的推理能力如何。目前的最新技术需要一个检索模型从文本中收集与金融问题相关的事实，并使用一个生成器来生成有效的金融程序和最终答案。然而，最近的大型语言模型如GPT-3仅仅通过少量示例就实现了广泛任务的最新性能。我们对GPT-3进行了多个实验，发现独立的检索模型和逻辑引擎仍然是实现这一任务的关键组件，尤其是由于金融领域的精确性要求。

    Financial analysis is an important tool for evaluating company performance. Practitioners work to answer financial questions to make profitable investment decisions, and use advanced quantitative analyses to do so. As a result, Financial Question Answering (QA) is a question answering task that requires deep reasoning about numbers. Furthermore, it is unknown how well pre-trained language models can reason in the financial domain. The current state-of-the-art requires a retriever to collect relevant facts about the financial question from the text and a generator to produce a valid financial program and a final answer. However, recently large language models like GPT-3 have achieved state-of-the-art performance on wide variety of tasks with just a few shot examples. We run several experiments with GPT-3 and find that a separate retrieval model and logic engine continue to be essential components to achieving SOTA performance in this task, particularly due to the precise nature of finan
    
[^29]: FacTool：生成AI中的事实性检测 —— 一种为多任务和多领域场景加强的工具增强框架

    FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios. (arXiv:2307.13528v1 [cs.CL])

    [http://arxiv.org/abs/2307.13528](http://arxiv.org/abs/2307.13528)

    提出了FacTool框架，用于检测大型语言模型（如ChatGPT）生成的文本中的事实错误。实验结果表明该方法在知识型问答、代码生成、数学推理和科学文献综述等四个任务中具有良好的效果。

    

    生成式预训练模型的出现方便了高质量文本的合成，但也在识别生成文本中的事实错误方面提出了挑战。本文针对以下问题提出了FacTool框架：（1）越来越多的任务由生成模型处理时，存在着包含事实错误的风险；（2）生成的文本往往很长，缺乏清晰定义的细粒度个体事实；（3）在事实检查过程中缺乏明确的证据。我们在四个不同的任务上进行实验（基于知识的问答、代码生成、数学推理和科学文献综述），证明了该方法的有效性。

    The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method.
    
[^30]: MediaGPT：用于中国媒体的大型语言模型

    MediaGPT : A Large Language Model For Chinese Media. (arXiv:2307.10930v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.10930](http://arxiv.org/abs/2307.10930)

    本论文提出了MediaGPT，一个用于中国媒体领域的大型语言模型。通过特定领域数据和专家数据的训练，MediaGPT在各种中国媒体任务上优于主流模型，并验证了其重要性。

    

    大型语言模型（LLM）在生成高质量文本和基于大量数据进行预测方面展现出了卓越的能力，包括媒体领域。然而，在实际应用中，媒体的用例与通用LLM应用之间的差异变得越来越明显，特别是在中文方面。本文研究了媒体领域特定LLM与通用LLM之间的独特特点，设计了一系列多样化的任务指令类型以满足领域特定需求，并构建了适用于媒体领域的独特数据集。基于这些工作，我们提出了一种针对中国媒体领域的领域特定LLM，通过领域特定数据和专家的SFT数据进行训练。通过在验证集上进行人工专家评估和强模型评估，本文证明了MediaGPT在各种中国媒体领域任务上优于主流模型，并验证了其重要性。

    Large language models (LLMs) have shown remarkable capabilities in generating high-quality text and making predictions based on large amounts of data, including the media domain. However, in practical applications, the differences between the media's use cases and the general-purpose applications of LLMs have become increasingly apparent, especially Chinese. This paper examines the unique characteristics of media-domain-specific LLMs compared to general LLMs, designed a diverse set of task instruction types to cater the specific requirements of the domain and constructed unique datasets that are tailored to the media domain. Based on these, we proposed MediaGPT, a domain-specific LLM for the Chinese media domain, training by domain-specific data and experts SFT data. By performing human experts evaluation and strong model evaluation on a validation set, this paper demonstrated that MediaGPT outperforms mainstream models on various Chinese media domain tasks and verifies the importance 
    
[^31]: 在量子化的大型语言模型中是否存在新兴能力：一项经验研究

    Do Emergent Abilities Exist in Quantized Large Language Models: An Empirical Study. (arXiv:2307.08072v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08072](http://arxiv.org/abs/2307.08072)

    本研究旨在研究量子化对大型语言模型中的新兴能力的影响，结果显示在4位量化模型中这些新兴能力仍然存在。

    

    尽管大型语言模型（LLMs）具有出色的性能，但需要大量的计算资源进行部署和使用。为了解决这个问题，已经广泛应用量子化方法来减少LLMs的内存占用以及增加推理速度。然而，一个主要的挑战是低位量子化方法往往会导致性能下降。了解量子化对LLMs能力的影响是重要的。与以往专注于总体性能的研究不同，本研究旨在调查量子化对“新兴能力”的影响，这些能力是区分LLMs和小型语言模型的重要特征。具体而言，我们研究了量子化LLMs中的上下文学习、思维连贯和遵循指令的能力。我们的实证实验表明，这些新兴能力在4位量化模型中仍然存在，而2位模型在这些能力上遇到了严重的性能下降。

    Despite the superior performance, Large Language Models~(LLMs) require significant computational resources for deployment and use. To overcome this issue, quantization methods have been widely applied to reduce the memory footprint of LLMs as well as increasing the inference rate. However, a major challenge is that low-bit quantization methods often lead to performance degradation. It is important to understand how quantization impacts the capacity of LLMs. Different from previous studies focused on overall performance, this work aims to investigate the impact of quantization on \emph{emergent abilities}, which are important characteristics that distinguish LLMs from small language models. Specially, we examine the abilities of in-context learning, chain-of-thought reasoning, and instruction-following in quantized LLMs. Our empirical experiments show that these emergent abilities still exist in 4-bit quantization models, while 2-bit models encounter severe performance degradation on th
    
[^32]: 没有训练就没有收益：重新审视基于Transformer的语言模型的高效训练算法

    No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models. (arXiv:2307.06440v1 [cs.LG])

    [http://arxiv.org/abs/2307.06440](http://arxiv.org/abs/2307.06440)

    本论文重新审视了基于Transformer的语言模型的高效训练算法，包括动态架构，批量选择和高效优化器。然而，在使用这些算法预训练时，相对于基线方法，它们的训练、验证和下游收益消失了。同时，论文提出了一个评估协议来进行计算，并释放了代码来促进高效训练的研究。

    

    近年来，训练Transformer-based语言模型所需的计算量急剧增加。这一趋势促使研究者们开展了针对高效训练算法的研究，旨在比标准训练更快地改善训练、验证和下游性能。在这项工作中，我们重新审视了三类这样的算法：动态架构（层叠、层丢弃）、批量选择（选择性反向传播、RHO损失）和高效优化器（Lion、Sophia）。当使用这些方法在固定计算预算下对BERT和T5进行预训练时，我们发现它们的训练、验证和下游收益相对于一个具有完全衰减学习率的基线而言会消失。我们定义了一个评估协议，可以通过将所有计算时间映射到一个称为参考系统时间的参考机器上，在任意机器上进行计算。我们讨论了我们提出的协议的局限性，并发布了我们的代码，以鼓励对高效训练的严格研究。

    The computation necessary for training Transformer-based language models has skyrocketed in recent years. This trend has motivated research on efficient training algorithms designed to improve training, validation, and downstream performance faster than standard training. In this work, we revisit three categories of such algorithms: dynamic architectures (layer stacking, layer dropping), batch selection (selective backprop, RHO loss), and efficient optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed computation budget using such methods, we find that their training, validation, and downstream gains vanish compared to a baseline with a fully-decayed learning rate. We define an evaluation protocol that enables computation to be done on arbitrary machines by mapping all computation time to a reference machine which we call reference system time. We discuss the limitations of our proposed protocol and release our code to encourage rigorous research in efficient training p
    
[^33]: MMBench: 您的多模态模型是全能球员吗？

    MMBench: Is Your Multi-modal Model an All-around Player?. (arXiv:2307.06281v1 [cs.CV])

    [http://arxiv.org/abs/2307.06281](http://arxiv.org/abs/2307.06281)

    MMBench是一个新型的多模态基准测试，旨在解决大型视觉语言模型评估的挑战，通过开发全面的评估流程和精心策划的数据集进行细粒度能力评估。

    

    最近，大型视觉语言模型在视觉信息的感知和推理能力方面取得了显著进展。然而，如何有效评估这些大型视觉语言模型仍然是一个主要障碍，阻碍了未来模型的发展。传统的基准测试，如VQAv2或COCO Caption提供了定量的性能测量，但在细粒度能力评估和非鲁棒评估指标方面存在不足。最近的主观基准测试，如OwlEval，通过整合人力资源，对模型的能力进行了全面评估，但不可扩展并且存在显著的偏见。针对这些挑战，我们提出了MMBench，一种新型的多模态基准测试。MMBench系统地开发了一个全面的评估流程，主要由两个元素组成。第一个元素是精心策划的数据集，在评估数量和多样性方面超越了现有的类似基准测试。

    Large vision-language models have recently achieved remarkable progress, exhibiting great perception and reasoning abilities concerning visual information. However, how to effectively evaluate these large vision-language models remains a major obstacle, hindering future model development. Traditional benchmarks like VQAv2 or COCO Caption provide quantitative performance measurements but suffer from a lack of fine-grained ability assessment and non-robust evaluation metrics. Recent subjective benchmarks, such as OwlEval, offer comprehensive evaluations of a model's abilities by incorporating human labor, but they are not scalable and display significant bias. In response to these challenges, we propose MMBench, a novel multi-modality benchmark. MMBench methodically develops a comprehensive evaluation pipeline, primarily comprised of two elements. The first element is a meticulously curated dataset that surpasses existing similar benchmarks in terms of the number and variety of evaluatio
    
[^34]: SAS视频问答：自适应采样用于高效视频问答

    SAS Video-QA: Self-Adaptive Sampling for Efficient Video Question-Answering. (arXiv:2307.04192v1 [cs.CV])

    [http://arxiv.org/abs/2307.04192](http://arxiv.org/abs/2307.04192)

    SAS视频问答通过自适应采样策略解决了视频问答中的问题，提高了效率和准确性

    

    视频问答是视频理解领域的一项基础任务。尽管当前的视觉-语言模型(VLMs)配备了视频变换器(Video Transformers)，实现了时间建模并取得了优秀的结果，但代价是巨大的计算能力，因此在实时应用场景中过于昂贵。一种经济的解决方法是只对视频的一小部分帧进行采样，来代表视频的主要内容，并在这些采样帧上调整图像-文本模型。最近的视频理解模型通常随机采样一组帧或片段，而不考虑它们的内部关联性和与问题的相关性。我们认为这种无目标的采样可能会遗漏可以推导出正确答案的关键帧，在采样稀疏程度增加时，情况会变得更糟，而随着视频长度的增加，采样稀疏程度也会增加。为了解决这个问题，我们提出了两种帧采样策略，分别是

    Video question--answering is a fundamental task in the field of video understanding. Although current vision--language models (VLMs) equipped with Video Transformers have enabled temporal modeling and yielded superior results, they are at the cost of huge computational power and thus too expensive to deploy in real-time application scenarios. An economical workaround only samples a small portion of frames to represent the main content of that video and tune an image--text model on these sampled frames. Recent video understanding models usually randomly sample a set of frames or clips, regardless of internal correlations between their visual contents, nor their relevance to the problem. We argue that such kinds of aimless sampling may omit the key frames from which the correct answer can be deduced, and the situation gets worse when the sampling sparsity increases, which always happens as the video lengths increase. To mitigate this issue, we propose two frame sampling strategies, namel
    
[^35]: 无导数的权重空间集成

    Derivative Free Weight-space Ensembling. (arXiv:2307.03506v1 [cs.CL])

    [http://arxiv.org/abs/2307.03506](http://arxiv.org/abs/2307.03506)

    本文引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。通过在几个不同的知识库的角度上对专家模型进行微调，并使用无梯度优化算法进行线性插值，我们有效地找到了一个好的模型权重插值，从而在FETA-Friends上超过了标准的预训练-微调方法。

    

    最近的研究表明，在两个专门的语言模型的权重之间插值可以在任务之间传递知识，但很少有人探索在两个以上模型之间插值，每个模型都有一个不同的知识库。在本文中，我们引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。我们的框架创建了一组多样化的专家语言模型，这些模型是使用预定义的一组源任务进行训练的。接下来，我们对每个专家模型在目标任务上进行微调，从几个不同的知识库的角度来处理目标任务。最后，我们使用无梯度优化算法在模型权重之间进行线性插值，以高效地找到一个好的插值权重。我们在FETA-Friends上展示了该方法的有效性，优于标准的预训练-微调方法。

    Recent work suggests that interpolating between the weights of two specialized language models can transfer knowledge between tasks in a way that multi-task learning cannot. However, very few have explored interpolation between more than two models, where each has a distinct knowledge base. In this paper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new few-sample task transfer approach for open-domain dialogue. Our framework creates a set of diverse expert language models trained using a predefined set of source tasks. Next, we finetune each of the expert models on the target task, approaching the target task from several distinct knowledge bases. Finally, we linearly interpolate between the model weights using a gradient-free-optimization algorithm, to efficiently find a good interpolation weighting. We demonstrate the effectiveness of the method on FETA-Friends outperforming the standard pretrain-finetune approach.
    
[^36]: "你是让我给狗戴眼镜吗？" 在CoDraw数据集中注释指令澄清请求的内容基础

    "Are you telling me to put glasses on the dog?'' Content-Grounded Annotation of Instruction Clarification Requests in the CoDraw Dataset. (arXiv:2306.02377v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02377](http://arxiv.org/abs/2306.02377)

    这项工作在CoDraw数据集中扩展了已有的指令澄清请求标识符，注释了与底层对话游戏项目和可能动作相关的细节信息，可以用于模拟和评估对话代理的修复能力

    

    指令澄清请求是解决沟通问题的机制，在指令跟随互动中非常实用。最近的研究认为CoDraw数据集是一个有价值的自然发生iCR的来源。除了确定何时需要提出iCR外，对话模型还应该能够以合适的形式和内容生成它们。在这项工作中，我们介绍了CoDraw-iCR(v2)，通过与底层对话游戏项目和可能的动作相关的细粒度信息扩展了现有的iCR标识符。我们的注释可以用来建模和评估对话代理的修复能力。

    Instruction Clarification Requests are a mechanism to solve communication problems, which is very functional in instruction-following interactions. Recent work has argued that the CoDraw dataset is a valuable source of naturally occurring iCRs. Beyond identifying when iCRs should be made, dialogue models should also be able to generate them with suitable form and content. In this work, we introduce CoDraw-iCR (v2), extending the existing iCR identifiers with fine-grained information grounded in the underlying dialogue game items and possible actions. Our annotation can serve to model and evaluate repair capabilities of dialogue agents.
    
[^37]: 预训练的视觉与语言模型中的实体知识探究的表格和图像生成

    Table and Image Generation for Investigating Knowledge of Entities in Pre-trained Vision and Language Models. (arXiv:2306.02115v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02115](http://arxiv.org/abs/2306.02115)

    本文提出了一个表格和图像生成的任务，研究了预训练的视觉与语言模型中关于实体的知识如何被保留。通过实验结果发现，预训练模型OFA在生成图像的过程中忘记了部分实体知识。

    

    本文提出了一个表格和图像生成任务，以验证自然语言中获取的关于实体的知识如何被保留在视觉与语言（V&L）模型中。该任务由两个部分组成：第一个部分是生成一个包含关于实体及其相关图像的知识的表格，第二个部分是根据实体、标题和包含相关实体知识的表格生成图像。在两个任务中，模型必须正确地了解用于执行生成的实体。我们从英文维基百科文章中的约200,000个信息框创建了维基百科表格和图像生成（WikiTIG）数据集来执行提出的任务。我们使用在多个任务中取得了最先进结果的V&L模型OFA对任务的表现进行了评估。实验结果显示，OFA在预训练过程中忘记了部分实体知识，这对于提高图像相关性能是一种补充。

    In this paper, we propose a table and image generation task to verify how the knowledge about entities acquired from natural language is retained in Vision & Language (V&L) models. This task consists of two parts: the first is to generate a table containing knowledge about an entity and its related image, and the second is to generate an image from an entity with a caption and a table containing related knowledge of the entity. In both tasks, the model must know the entities used to perform the generation properly. We created the Wikipedia Table and Image Generation (WikiTIG) dataset from about 200,000 infoboxes in English Wikipedia articles to perform the proposed tasks. We evaluated the performance on the tasks with respect to the above research question using the V&L model OFA, which has achieved state-of-the-art results in multiple tasks. Experimental results show that OFA forgets part of its entity knowledge by pre-training as a complement to improve the performance of image relat
    
[^38]: 向可解释的、语言无关的LLMs迈进：大规模语言符号逆向工程

    Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v1 [cs.CL])

    [http://arxiv.org/abs/2306.00017](http://arxiv.org/abs/2306.00017)

    本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。

    

    大型语言模型（LLMs）取得了一个里程碑，无可否认地改变了人工智能（AI）中许多信仰。然而，当涉及真正的语言理解时，这些LLM的许多限制仍然存在，这些限制是深度神经网络底层架构的副产品。此外，由于它们的亚符号性质，这些模型获得有关语言如何运作的任何知识都将被埋在数十亿个微特征（权重）中，其中没有一个单独的特征有意义，使得这些模型无法解释。为了解决这些限制，我们建议将符号表示的强度与我们认为是LLMs成功的关键结合起来，即在规模上成功地进行自下而上的语言逆向工程。因此，我们主张在符号设置下对语言进行自下而上的逆向工程。一些作者提出了这个项目的提示，我们将进行详细讨论。

    Large language models (LLMs) have achieved a milestone that undenia-bly changed many held beliefs in artificial intelligence (AI). However, there remains many limitations of these LLMs when it comes to true language understanding, limitations that are a byproduct of the under-lying architecture of deep neural networks. Moreover, and due to their subsymbolic nature, whatever knowledge these models acquire about how language works will always be buried in billions of microfeatures (weights), none of which is meaningful on its own, making such models hopelessly unexplainable. To address these limitations, we suggest com-bining the strength of symbolic representations with what we believe to be the key to the success of LLMs, namely a successful bottom-up re-verse engineering of language at scale. As such we argue for a bottom-up reverse engineering of language in a symbolic setting. Hints on what this project amounts to have been suggested by several authors, and we discuss in some detail
    
[^39]: 量化和建模多模态交互：一种信息分解框架

    Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework. (arXiv:2302.12247v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12247](http://arxiv.org/abs/2302.12247)

    通过引入信息分解框架，我们提供了一种量化和建模多模态交互的方法，通过PID统计量来度量输入模态与输出任务之间的冗余度、独特性和协同性，并引入了两个新的PID统计估计器。

    

    对于解决多模态任务所需的交互如何进行量化？最适合捕捉这些交互的多模态模型是什么？为了回答这些问题，我们提出了一种信息论方法来量化输入模态与输出任务之间的冗余度、独特性和协同性。我们将这三个衡量标准称为多模态分布（或简称PID）的PID统计量，并引入了两个新的PID统计估计器，适用于高维分布。为了验证PID估计，我们在已知PID的合成数据集和大规模多模态基准测试集上进行了大量实验。

    The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and integrating information from different modalities. Despite these empirical advances, there remain fundamental research questions: How can we quantify the interactions that are necessary to solve a multimodal task? Subsequently, what are the most suitable multimodal models to capture these interactions? To answer these questions, we propose an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy relating input modalities with an output task. We term these three measures as the PID statistics of a multimodal distribution (or PID for short), and introduce two new estimators for these PID statistics that scale to high-dimensional distributions. To validate PID estimation, we conduct extensive experiments on both synthetic datasets where the PID is known and on large-scale multimodal benchmarks where PID estimations
    
[^40]: 自动字幕的直接语音翻译

    Direct Speech Translation for Automatic Subtitling. (arXiv:2209.13192v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.13192](http://arxiv.org/abs/2209.13192)

    本论文提出了自动字幕的直接语音翻译模型，通过单一模型生成目标语言的字幕及其时间戳，该方法在多语言对上对比级联系统表现更好，并在领域内和领域外基准测试中与生产工具相媲美。

    

    自动字幕是将视听内容的语音自动翻译为短时文本，即字幕及其对应的时间戳的任务。生成的字幕需要符合空间和时间要求，同时与语音同步，并以便于理解的方式进行分割。鉴于其相当复杂性，该任务迄今为止通常通过一系列单独处理文本转录、翻译和分割为字幕以及预测时间戳的组件来解决。在本文中，我们提出了自动字幕的第一个直接ST模型，该模型能够使用单一模型生成目标语言的字幕及其时间戳。我们在7个语言对上的实验表明，我们的方法在相同数据条件下优于级联系统，同时在涵盖新场景的领域内和新发布的领域外基准测试中与生产工具相媲美。

    Automatic subtitling is the task of automatically translating the speech of audiovisual content into short pieces of timed text, i.e. subtitles and their corresponding timestamps. The generated subtitles need to conform to space and time requirements, while being synchronised with the speech and segmented in a way that facilitates comprehension. Given its considerable complexity, the task has so far been addressed through a pipeline of components that separately deal with transcribing, translating, and segmenting text into subtitles, as well as predicting timestamps. In this paper, we propose the first direct ST model for automatic subtitling that generates subtitles in the target language along with their timestamps with a single model. Our experiments on 7 language pairs show that our approach outperforms a cascade system in the same data condition, also being competitive with production tools on both in-domain and newly-released out-domain benchmarks covering new scenarios.
    
[^41]: 在SIMMC 2.0挑战中探索多模态表达对于歧义检测和共识消解的影响

    Exploring Multi-Modal Representations for Ambiguity Detection & Coreference Resolution in the SIMMC 2.0 Challenge. (arXiv:2202.12645v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.12645](http://arxiv.org/abs/2202.12645)

    本文在SIMMC 2.0挑战中探索了多模态表达对于歧义检测和共识消解的影响，并通过实验证明了语言模型的能力和基于单模态的共识消解模型的优势。

    

    指代表达，比如代词和指示描述，既受前文的语言语境的影响，也受到当前视觉环境的影响。然而，发言者的指示描述并不能总是唯一地确定指代物，导致需要通过后续的澄清交流来消除歧义。因此，在对话式人工智能中，有效的歧义检测和共识消解对于任务成功至关重要。本文作为SIMMC 2.0挑战的一部分，提出了这两个任务的模型。具体来说，我们使用TOD-BERT和LXMERT模型，并将它们与一些基线模型进行对比，并进行了消融实验。我们的结果表明，（1）语言模型能够利用数据中的相关性来检测歧义；（2）基于单模态的共识消解模型可以通过使用智能物体表示来避免需要视觉组件。

    Anaphoric expressions, such as pronouns and referential descriptions, are situated with respect to the linguistic context of prior turns, as well as, the immediate visual environment. However, a speaker's referential descriptions do not always uniquely identify the referent, leading to ambiguities in need of resolution through subsequent clarificational exchanges. Thus, effective Ambiguity Detection and Coreference Resolution are key to task success in Conversational AI. In this paper, we present models for these two tasks as part of the SIMMC 2.0 Challenge (Kottur et al. 2021). Specifically, we use TOD-BERT and LXMERT based models, compare them to a number of baselines and provide ablation experiments. Our results show that (1) language models are able to exploit correlations in the data to detect ambiguity; and (2) unimodal coreference resolution models can avoid the need for a vision component, through the use of smart object representations.
    
[^42]: 预训练语言模型的全面比较

    A Comprehensive Comparison of Pre-training Language Models. (arXiv:2106.11483v9 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2106.11483](http://arxiv.org/abs/2106.11483)

    本文比较了各种预训练语言模型的效率，发现添加RNN层可以在短文本理解中获得最大的改进，但对于类似的BERT结构并没有明显的改进。数据中心方法能够实现更好的性能。

    

    最近，预训练语言模型的发展使得自然语言处理（NLP）任务达到了新的最先进水平。在本文中，我们探索了各种预训练语言模型的效率。我们使用相同数量的文本和相同的训练步骤来预训练一系列基于transformer的模型。实验结果表明，对于短文本理解，最大的改进是在原始BERT模型中添加RNN层以捕捉更多的语境信息。但是结论是：类似的BERT结构对于短文本理解没有明显的改进。数据中心方法[12]可以实现更好的性能。

    Recently, the development of pre-trained language models has brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained language models. We pre-train a list of transformer-based models with the same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is adding the RNN-layer to capture more contextual information for short text understanding. But the conclusion is: There are no remarkable improvement for short text understanding for similar BERT structures. Data-centric method[12] can achieve better performance.
    

