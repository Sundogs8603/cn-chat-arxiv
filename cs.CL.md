# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [GameEval: Evaluating LLMs on Conversational Games.](http://arxiv.org/abs/2308.10032) | GameEval是一种通过面向目标的对话游戏来评估LLM的新方法。通过设计具有合作或对抗目标的独特游戏，GameEval可以全面评估模型性能。 |
| [^2] | [ControlRetriever: Harnessing the Power of Instructions for Controllable Retrieval.](http://arxiv.org/abs/2308.10025) | ControlRetriever是一种有参数隔离架构的通用且高效的方法，借助于任务特定的指令，能够控制密集检索模型直接执行各种检索任务，提高检索效果。 |
| [^3] | [HICL: Hashtag-Driven In-Context Learning for Social Media Natural Language Understanding.](http://arxiv.org/abs/2308.09985) | 本论文提出了一种基于标签驱动的上下文学习（HICL）框架，通过使用＃hashtags驱动BERT的预训练过程，使＃Encoder能够整合主题相关语义信息，丰富上下文并提升社交媒体自然语言理解的性能。 |
| [^4] | [FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models.](http://arxiv.org/abs/2308.09975) | 本论文提出了一个专门用于评估大型语言模型在金融领域知识上的基准FinEval。通过在FinEval上评估中英文LLMs，结果显示只有GPT-4在不同提示设置下实现了接近70%的准确率，展示了LLMs在金融领域知识中的显著增长潜力。 |
| [^5] | [Tackling Vision Language Tasks Through Learning Inner Monologues.](http://arxiv.org/abs/2308.09970) | 通过学习内心独白，提出了一种新方法（IMMO）来解决复杂的视觉语言任务，克服了混合融合和特征对齐方法所面临的优化和可解释性问题。 |
| [^6] | [Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate.](http://arxiv.org/abs/2308.09957) | 本文研究了在资源严重匮乏的语言中使用GPT-3.5进行数据到文本生成的任务。发现few-shot引导对于直接生成目标语言效果更好，而通过英语进行中转后，这种差异消失了。在WebNLG 2023共享任务中，这种few-shot + 翻译系统的变体在所有语言中的表现都优于竞争系统。 |
| [^7] | [Eva-KELLM: A New Benchmark for Evaluating Knowledge Editing of LLMs.](http://arxiv.org/abs/2308.09954) | Eva-KELLM是一个新的用于评估LLMs知识编辑的基准，提供了一个评估框架和数据集。该基准通过使用原始文档进行知识编辑和多角度的评估来解决了现有研究中收集成本高、表达复杂事实困难、评估视角受限等问题。 |
| [^8] | [Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection.](http://arxiv.org/abs/2308.09892) | 利用语义文本相似性对临床调查数据进行特征选择，通过评估特征名称与目标名称之间的关系来选择特征。 |
| [^9] | [Inductive-bias Learning: Generating Code Models with Large Language Model.](http://arxiv.org/abs/2308.09890) | 这篇论文提出了一种新的学习方法，称为归纳偏差学习（IBL），它将上下文学习（ICL）和代码生成相结合，通过输入训练数据到提示中，输出相应的代码。 |
| [^10] | [Breaking Language Barriers: A Question Answering Dataset for Hindi and Marathi.](http://arxiv.org/abs/2308.09862) | 本论文开发了一个用于印地语和马拉地语的问答数据集，通过翻译SQuAD 2.0数据集解决了数据稀缺问题，提供了这两种语言的最好表现模型。 |
| [^11] | [Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method.](http://arxiv.org/abs/2308.09861) | 本文针对密集检索模型提出了一种黑盒对抗攻击方法，旨在欺骗模型检索到初始候选文档集范围之外的目标文档。 |
| [^12] | [How susceptible are LLMs to Logical Fallacies?.](http://arxiv.org/abs/2308.09853) | 本文研究了大型语言模型（LLMs）在多轮辩论中的合理思考能力，并通过逻辑能力测量基准（LOGICOM）评估了它们对逻辑谬误的鲁棒性。评估结果展示了GPT-3.5和GPT-4在包含有争议的数据集上的表现。 |
| [^13] | [An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software.](http://arxiv.org/abs/2308.09810) | 本文提出了OASIS，一个用于内容审核软件的变形测试框架，以解决现代社交媒体平台上恶意内容的传播问题。 |
| [^14] | [VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control.](http://arxiv.org/abs/2308.09804) | 本文提出了一种名为VL-PET的视觉和语言参数高效调整框架，通过粒度控制机制对模块化修改进行有效控制，克服了现有技术在性能和功能差距方面的不足。 |
| [^15] | [Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models.](http://arxiv.org/abs/2308.09778) | 本文旨在研究多模态视觉语言模型在理解空间关系方面的能力，提出了细粒度组合的空间关系基础，并采用自底向上的方法评估空间关系推理任务的性能。 |
| [^16] | [YORC: Yoruba Reading Comprehension dataset.](http://arxiv.org/abs/2308.09768) | 本文介绍了一个新的多项选择约鲁巴语阅读理解数据集YORC，通过跨语言转移和大型语言模型的使用，提供了该数据集的基准结果和更高层次的结果。 |
| [^17] | [Taken by Surprise: Contrast effect for Similarity Scores.](http://arxiv.org/abs/2308.09765) | 提出了一种新的相似度度量方法，称为“惊喜分数”，该方法能够考虑对象的上下文信息并显著提高零样本和少样本文档分类任务的性能。 |
| [^18] | [ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based Healthcare Decision Support using ChatGPT.](http://arxiv.org/abs/2308.09731) | 本研究介绍了一种创新的方法，利用ChatGPT在临床决策中应用大型语言模型，通过策略性设计上下文提示，并以领域知识为基础进行高质量的二元分类任务。通过将机器学习模型视为医疗专家，提取关键见解并辅助决策过程，这一领域知识和人工智能的结合在创建更具洞察力的诊断工具方面具有重要潜力。此外，研究还探索了基于ChatGPT的零样本和少样本提示学习的动态，并验证了ChatGPT在医疗决策支持中的优势。 |
| [^19] | [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models.](http://arxiv.org/abs/2308.09729) | 本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。 |
| [^20] | [FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs.](http://arxiv.org/abs/2308.09723) | 该论文提出了一种针对LLMs的高效权重量化方法，通过减少内存消耗和加速推理，解决了大型语言模型在实际部署中遇到的挑战。研究者们通过引入一种简单而有效的启发式方法，仅利用模型的权重，而无需额外微调，成功降低了质量损失。 |
| [^21] | [A Trustable LSTM-Autoencoder Network for Cyberbullying Detection on Social Media Using Synthetic Data.](http://arxiv.org/abs/2308.09722) | 本研究提出了一种使用合成数据进行社交媒体网络欺凌检测的可信LSTM-Autoencoder网络。该方法解决了数据可用性困难的问题，并通过实验证明了在印地语、孟加拉语和英语数据集上的有效性。 |
| [^22] | [On the Unexpected Abilities of Large Language Models.](http://arxiv.org/abs/2308.09720) | 大型语言模型展示了与其训练任务不直接相关的广泛能力，通过间接获取过程使其拥有综合能力的发展，这些能力在一定程度上可预测，并且与人类认知有关。 |
| [^23] | [Graph of Thoughts: Solving Elaborate Problems with Large Language Models.](http://arxiv.org/abs/2308.09687) | 想法图（GoT）是一种新的框架，它超越了现有的提示范式，通过将大型语言模型（LLM）的信息建模为任意图形，将LLM想法组合成具有协同效应的结果，提炼整个思维网络的本质，或者使用反馈环路增强思维。GoT在不同任务上展示出优势，并可以通过新的想法转换进行扩展，使LLM的推理更接近人类思维。 |
| [^24] | [Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning.](http://arxiv.org/abs/2308.09658) | 该论文提出了一种树形混合思维的方法，通过将快速和慢速思考结合，用于解决多跳视觉推理任务中准确性和效率之间的权衡问题。 |
| [^25] | [Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification.](http://arxiv.org/abs/2308.09308) | 本研究提出了一种可微的检索增强方法，通过生成式语言建模，在电子商务查询意图分类任务中显著提升了性能，解决了检索器和下游模型之间的不可微性问题。 |
| [^26] | [Reinforced Self-Training (ReST) for Language Modeling.](http://arxiv.org/abs/2308.08998) | 本文提出了一种称为自学习增强 (ReST) 的算法，通过从人类反馈中进行强化学习来提高大型语言模型 (LLM) 的输出质量。在机器翻译任务上的实验结果表明，ReST能够以高效的方式显著提高翻译质量。 |
| [^27] | [Exploring Demonstration Ensembling for In-context Learning.](http://arxiv.org/abs/2308.08780) | 本研究探索了上下文学习的演示集成方法，用于提高语言模型在给定任务的输入输出对中的预测性能。通过将演示分成子集并组合各子集的输出概率，我们得到了最终的预测结果。 |
| [^28] | [An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning.](http://arxiv.org/abs/2308.08747) | 该研究实证评估了大型语言模型在持续微调过程中的灾难性遗忘现象，并发现随着模型规模增加，遗忘的严重程度也加剧。与编码器-解码器模型相比，仅有解码器的模型遗忘较少并保留更多知识。此外，研究还发现LLMs可以减轻语言偏见，并且ALPACA在保留知识和容量方面具有优势。 |
| [^29] | [Natural Language is All a Graph Needs.](http://arxiv.org/abs/2308.07134) | 本论文提出了一种名为InstructGLM的结构化语言模型算法，该算法将大型语言模型与图表学习问题相结合，旨在探索是否可以用语言模型取代图神经网络作为图表的基础模型。 |
| [^30] | [Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias.](http://arxiv.org/abs/2308.04566) | 本论文针对机器阅读理解中的答案位置偏倚问题，提出了一种名为单句阅读器的新方法，该方法使用六种不同模型实现。实验证明，单句阅读器与传统训练集上训练的模型几乎具有相当的性能，有效解决了答案位置偏倚问题。 |
| [^31] | [PaniniQA: Enhancing Patient Education Through Interactive Question Answering.](http://arxiv.org/abs/2308.03253) | PaniniQA是一个以患者为中心的交互式问答系统，旨在帮助患者理解他们的出院指导，提供及时的反馈以纠正患者的误解，通过有效的互动提高患者对医疗指导的掌握程度。 |
| [^32] | [Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology.](http://arxiv.org/abs/2308.02180) | 本文研究了使用大型语言模型（LLMs）扩展临床试验匹配的方法，并以肿瘤学为案例研究。研究结果显示，先进的LLMs能够处理临床试验的复杂条件和匹配逻辑，相较于之前的方法，性能显著提升，并可作为人工辅助筛选患者-试验候选人的初步解决方案。 |
| [^33] | [Teaching Smaller Language Models To Generalise To Unseen Compositional Questions.](http://arxiv.org/abs/2308.00946) | 我们研究了如何教授较小的语言模型来推广到未见过的组合问题，通过多任务监督预训练和密集检索系统，我们建立了强大的基准，并展示了解决多个评估数据集上的问题的能力。 |
| [^34] | [Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?.](http://arxiv.org/abs/2308.00158) | 本研究探讨了使用Fine-Tuned的OpenAI LLM进行翻译质量估计的能力，实验证明可以通过Fine-Tuned的ChatGPT来预测机器翻译的质量，但仍有改进的空间。 |
| [^35] | [Getting pwn'd by AI: Penetration Testing with Large Language Models.](http://arxiv.org/abs/2308.00121) | 本文探讨了使用大型语言模型（如GPT3.5）作为AI助手来增强渗透测试人员的能力，实现了高级任务规划和低级漏洞寻找两种用例，取得了有前景的初步结果，并就提供该技术的伦理问题进行了讨论。 |
| [^36] | [DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for Detecting Abuse Targeted at Public Figures.](http://arxiv.org/abs/2307.16811) | 该研究旨在通过探索跨领域和跨人口的文本分类动态，构建更通用的滥用分类器。研究发现，少量多样的数据对于模型的通用化和适应非常有益。 |
| [^37] | [RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment.](http://arxiv.org/abs/2307.12950) | RLCD是一种用于语言模型对齐的强化学习方法，利用对比蒸馏训练偏好模型，可以使语言模型在不使用人类反馈的情况下遵循自然语言规则。在多个对齐任务和不同规模的模型上，RLCD优于其他基线方法。 |
| [^38] | [Exploring the Landscape of Natural Language Processing Research.](http://arxiv.org/abs/2307.10652) | 该论文系统分类和分析了ACL Anthology中的研究论文，提供了对研究领域的结构化概述和NLP领域的分类学。本研究总结了最新的NLP发展，并提出了未来工作的方向。 |
| [^39] | [Efficient Guided Generation for LLMs.](http://arxiv.org/abs/2307.09702) | 本文描述了一种使用正则表达式和上下文无关文法来引导语言模型文本生成的高效方法。 |
| [^40] | [Large Language Models as Superpositions of Cultural Perspectives.](http://arxiv.org/abs/2307.07870) | 大型语言模型被认为是具有个性或一套价值观的，但实际上它可以看作是具有不同价值观和个性特征的角度的叠加。通过角度可控性的概念，我们研究了大型语言模型在不同角度下展示的价值观和个性特征的变化。实验结果表明，即使在没有明显提示的情况下，大型语言模型也会表达出不同的价值观。 |
| [^41] | [Efficient Domain Adaptation of Sentence Embeddings using Adapters.](http://arxiv.org/abs/2307.03104) | 本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。 |
| [^42] | [AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities and Risks.](http://arxiv.org/abs/2306.08107) | 论文探讨了AutoML和LLMs之间的共生关系，并指出这两个领域的融合有望颠覆NLP和AutoML两个领域，同时也存在风险。 |
| [^43] | [Reliable identification of selection mechanisms in language change.](http://arxiv.org/abs/2305.15914) | 本文探究了语言变化中的选择机制，提出了一个可靠且可解释的方法来量化历史语言变化的特定实例中的选择强度。该方法被证明比以前应用过的方法更可靠。作者还展示了语音简单性优先于语法简单性，并说明了该方法也可以检测选择强度变化的时间点。 |
| [^44] | [Reducing Sensitivity on Speaker Names for Text Generation from Dialogues.](http://arxiv.org/abs/2305.13833) | 本文提出在对话生成文本中降低说话者名称敏感度的方法，通过定量测量模型敏感度并全面评估已知方法，得出了一种新方法的良好表现，为此问题提供了基准。 |
| [^45] | [MPI-rical: Data-Driven MPI Distributed Parallelism Assistance with Transformers.](http://arxiv.org/abs/2305.09438) | 本文提出了一种基于Transformer模型的新方法MPI-rical，通过对大量代码片段进行训练实现自动化MPI代码生成，使并行化成为可能。 |
| [^46] | [Large Linguistic Models: Analyzing theoretical linguistic abilities of LLMs.](http://arxiv.org/abs/2305.00948) | 本研究展示了大型语言模型(LLMs)在语言任务上性能不断提高，且首次展示了它们能够生成连贯和有效的语言数据分析。分析和评估它们的元语言能力有助于我们理解它们的一般能力并对语言学理论模型提供新的认识。 |
| [^47] | [Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology.](http://arxiv.org/abs/2304.11957) | 本研究评估了ChatGPT-4在放射肿瘤学方面的表现，成绩显示出它在医学考试上有很大的优势，在实际应用中存在局限性。另外，ChatGPT-4 在放射肿瘤学上表现出色，但在骨骼和软组织以及妇科方面有待改进。 |
| [^48] | [Supporting Human-AI Collaboration in Auditing LLMs with LLMs.](http://arxiv.org/abs/2304.09991) | 本论文通过对安全和公正人工智能专家的采访以及对人工智能协作和感知文献的研究，增强了“AdaTest”审计工具，这个工具可以通过利用人和生成模型的协同优势，进行更严格的大型语言模型审计。 |
| [^49] | [Zero-Shot Composed Image Retrieval with Textual Inversion.](http://arxiv.org/abs/2303.15247) | 提出了零样本组合图像检索任务(ZS-CIR)，通过将视觉特征映射到CLIP令牌嵌入空间中的伪词标记并与相对标题集成，解决了不需要标记训练数据集的组合图像检索问题。引入了名为CIRCO的开放域基准数据集，该数据集是第一个包含每个查询的多个真实答案的CIR数据集。实验结果表明，SEARLE具有更好的性能。 |
| [^50] | [ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction.](http://arxiv.org/abs/2303.05063) | 这篇论文提出了一个简单而有效的上下文学习框架ICL-D3IE，这个框架使LLM在不同类型演示下的DIE任务中表现出色，具有改进性能的反馈机制，同时涵盖了位置和格式方面的演示示例。 |
| [^51] | [Language-Specific Representation of Emotion-Concept Knowledge Causally Supports Emotion Inference.](http://arxiv.org/abs/2302.09582) | 本研究通过操纵大型语言模型中的语言衍生的情绪概念知识表示，探讨了语言是否会因果支持情绪推断。实验结果显示，属性特定的神经元操纵导致情绪推断任务的性能下降，这与人类心理空间中不同属性的重要性有关。这些发现为支持基于语言的情绪推断机制提供了因果证据，并凸显了情绪概念知识的贡献。 |
| [^52] | [Data Augmentation using Transformers and Similarity Measures for Improving Arabic Text Classification.](http://arxiv.org/abs/2212.13939) | 本论文提出一种使用Transformer和相似度度量进行数据增强的方法，以改进阿拉伯文本分类，该方法利用AraGPT-2进行增强，并使用Euclidean、cosine、Jaccard和BLEU距离评估生成的句子。 |
| [^53] | [Federated Few-Shot Learning for Mobile NLP.](http://arxiv.org/abs/2212.05974) | 本研究首次探索了联邦学习在移动少样本自然语言处理中的应用，通过使用伪标签和提示学习算法，实现了仅有少量标记数据时的竞争性准确性。同时，通过创新的设计解决了高执行成本的问题。 |
| [^54] | [Towards Practical Few-shot Federated NLP.](http://arxiv.org/abs/2212.00192) | 本论文介绍了一个用于处理联邦自然语言处理中少样本问题的方法，通过引入数据生成器和基于提示的联邦学习系统，能够在有限的标记数据下实现与完整微调相媲美的性能。然而，这种性能要求付出显著的系统成本。 |
| [^55] | [I Can't Believe There's No Images! Learning Visual Tasks Using only Language Data.](http://arxiv.org/abs/2211.09778) | 本文研究了通过利用对比训练的视觉和语言编码器的联合嵌入空间，并仅使用文本训练数据，在没有对视觉训练数据进行训练的情况下完成四项代表性视觉任务。研究发现这些模型表现良好，具有一定的可迁移性。 |
| [^56] | [YATO: Yet Another deep learning based Text analysis Open toolkit.](http://arxiv.org/abs/2209.13877) | YATO是一个轻量且易于使用的开源工具包，支持深度学习文本分析，可组合不同的特征类型，并提供灵活性和易用性的优势，促进了先进NLP模型的复现和改进，以及跨学科应用的推动。 |
| [^57] | [PreSTU: Pre-Training for Scene-Text Understanding.](http://arxiv.org/abs/2209.05534) | PreSTU是一种针对场景文本理解的预训练方法，通过引入OCR感知的预训练目标，可以提高模型对于图像中嵌入文本的识别和连接能力，并在多个视觉问答和图像字幕基准上展示了其有效性。 |
| [^58] | [Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks.](http://arxiv.org/abs/2207.13243) | 这篇综述调查了深度神经网络内部结构内部解释方法，并提出了一种分析方法的分类。这些解释方法对于帮助构建更可信赖的AI是至关重要的。 |
| [^59] | [Unsupervised Multimodal Word Discovery based on Double Articulation Analysis with Co-occurrence cues.](http://arxiv.org/abs/2201.06786) | 本研究提出了一种无监督学习方法，基于语音学信息和对象信息，用于从语音信号中发现单词和音素，并同时利用多种模态的对象信息。实验结果表明，该方法在单词发现性能上优于基线方法。 |

# 详细

[^1]: GameEval: 在对话游戏上评估LLM

    GameEval: Evaluating LLMs on Conversational Games. (arXiv:2308.10032v1 [cs.CL])

    [http://arxiv.org/abs/2308.10032](http://arxiv.org/abs/2308.10032)

    GameEval是一种通过面向目标的对话游戏来评估LLM的新方法。通过设计具有合作或对抗目标的独特游戏，GameEval可以全面评估模型性能。

    

    大型语言模型（LLM）的快速发展使评估这些模型变得具有挑战性。现有的评估方法要么基于参考，要么基于偏好，这些方法不可避免地需要人为干预或引入由评估模型引起的测试偏差。在本文中，我们提出了GameEval，一种通过面向目标的对话游戏来评估LLM的新方法，克服了以前方法的局限性。GameEval将LLM视为游戏玩家，并为他们分配具有特定目标的不同角色，通过启动各种形式的对话（包括讨论、问答和投票）来实现这些目标。我们设计了三个具有合作或对抗目标的独特游戏，并附带相应的评估指标，以展示这种新范 Paradigm如何全面评估模型性能。通过大量的实验证明，GameEval可以有效区分各种LLM的能力，提供了对它们整体表现的全面评估。

    The rapid advancements in large language models (LLMs) have presented challenges in evaluating those models. Existing evaluation methods are either reference-based or preference based, which inevitably need human intervention or introduce test bias caused by evaluator models. In this paper, we propose GameEval, a novel approach to evaluating LLMs through goal-driven conversational games, overcoming the limitations of previous methods. GameEval treats LLMs as game players and assigns them distinct roles with specific goals achieved by launching conversations of various forms, including discussion, question answering, and voting. We design three unique games with cooperative or adversarial objectives, accompanied by corresponding evaluation metrics, to show how this new paradigm comprehensively evaluates model performance.Through extensive experiments, we show that GameEval can effectively differentiate the capabilities of various LLMs, providing a comprehensive assessment of their integ
    
[^2]: ControlRetriever: 发挥指令的力量进行可控检索

    ControlRetriever: Harnessing the Power of Instructions for Controllable Retrieval. (arXiv:2308.10025v1 [cs.CL])

    [http://arxiv.org/abs/2308.10025](http://arxiv.org/abs/2308.10025)

    ControlRetriever是一种有参数隔离架构的通用且高效的方法，借助于任务特定的指令，能够控制密集检索模型直接执行各种检索任务，提高检索效果。

    

    最近的研究表明，缺乏专门的训练数据的密集检索模型在各种检索任务中往往难以表现出色，因为不同的检索任务通常涉及不同的搜索意图。为解决这一挑战，在本工作中，我们引入了ControlRetriever，一种通用且高效的方法，采用参数隔离的架构，能够控制密集检索模型直接执行各种检索任务，发挥自然语言中明确描述检索意图的指令的力量。借助已在文本到图像生成中证明强大的ControlNet的基础，ControlRetriever将不同的检索模型赋予了可控性检索的新能力，同时还受到任务特定指令的指导。此外，我们提出了一种新颖的基于LLM引导的指令合成和迭代训练策略，通过广泛生成的检索数据迭代调整ControlRetriever。

    Recent studies have shown that dense retrieval models, lacking dedicated training data, struggle to perform well across diverse retrieval tasks, as different retrieval tasks often entail distinct search intents. To address this challenge, in this work we introduce ControlRetriever, a generic and efficient approach with a parameter isolated architecture, capable of controlling dense retrieval models to directly perform varied retrieval tasks, harnessing the power of instructions that explicitly describe retrieval intents in natural language. Leveraging the foundation of ControlNet, which has proven powerful in text-to-image generation, ControlRetriever imbues different retrieval models with the new capacity of controllable retrieval, all while being guided by task-specific instructions. Furthermore, we propose a novel LLM guided Instruction Synthesizing and Iterative Training strategy, which iteratively tunes ControlRetriever based on extensive automatically-generated retrieval data wit
    
[^3]: HICL: 基于标签驱动的社交媒体自然语言理解中的上下文学习

    HICL: Hashtag-Driven In-Context Learning for Social Media Natural Language Understanding. (arXiv:2308.09985v1 [cs.CL])

    [http://arxiv.org/abs/2308.09985](http://arxiv.org/abs/2308.09985)

    本论文提出了一种基于标签驱动的上下文学习（HICL）框架，通过使用＃hashtags驱动BERT的预训练过程，使＃Encoder能够整合主题相关语义信息，丰富上下文并提升社交媒体自然语言理解的性能。

    

    自然语言理解（NLU）对各种社交媒体应用程序至关重要。然而，现有的NLU模型在语义学习中过于依赖上下文，导致在面对短且嘈杂的社交媒体内容时性能受损。为了解决这个问题，我们利用上下文学习（ICL），即语言模型通过有限的示例进行条件推理从而丰富上下文，并提出了一种新颖的基于标签驱动的上下文学习（HICL）框架。具体地，我们预训练一个模型＃Encoder，它通过对比学习使得基于BERT的预训练过程通过＃hashtags（用户注释的主题标签）驱动。我们的目标是使＃Encoder能够获取整合了主题相关语义信息的能力，从而使其能够检索与主题相关的帖子以丰富上下文，并通过噪声上下文增强社交媒体NLU。为了进一步将检索到的上下文与源文本整合，我们使用了一种基于梯度的方法进行标识。

    Natural language understanding (NLU) is integral to various social media applications. However, existing NLU models rely heavily on context for semantic learning, resulting in compromised performance when faced with short and noisy social media content. To address this issue, we leverage in-context learning (ICL), wherein language models learn to make inferences by conditioning on a handful of demonstrations to enrich the context and propose a novel hashtag-driven in-context learning (HICL) framework. Concretely, we pre-train a model #Encoder, which employs #hashtags (user-annotated topic labels) to drive BERT-based pre-training through contrastive learning. Our objective here is to enable #Encoder to gain the ability to incorporate topic-related semantic information, which allows it to retrieve topic-related posts to enrich contexts and enhance social media NLU with noisy contexts. To further integrate the retrieved context with the source text, we employ a gradient-based method to id
    
[^4]: FinEval：一个用于大型语言模型的中文金融领域知识评估基准

    FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models. (arXiv:2308.09975v1 [cs.CL])

    [http://arxiv.org/abs/2308.09975](http://arxiv.org/abs/2308.09975)

    本论文提出了一个专门用于评估大型语言模型在金融领域知识上的基准FinEval。通过在FinEval上评估中英文LLMs，结果显示只有GPT-4在不同提示设置下实现了接近70%的准确率，展示了LLMs在金融领域知识中的显著增长潜力。

    

    大型语言模型（LLMs）在各种自然语言处理任务中展示出了出色的性能，但是它们在更具挑战性和专业领域的任务中的效果尚未得到深入研究。本文提出了FinEval，这是一个专门为LLMs中的金融领域知识设计的评估基准。FinEval是一个包含了金融、经济、会计和证书等34个学术科目的高质量多项选择题的集合，总计包含了4,661道题目。为了确保对模型性能进行全面评估，FinEval使用了多种提示类型，包括零样本和少样本提示，以及仅答案提示和思路链式提示。通过在FinEval上评估最先进的中文和英文LLMs，结果显示只有GPT-4在不同的提示设置下实现了接近70%的准确率，表明LLMs在金融领域知识中具有显著的增长潜力。我们的工作为金融领域的知识评估提供了更全面的基准。

    Large language models (LLMs) have demonstrated exceptional performance in various natural language processing tasks, yet their efficacy in more challenging and domain-specific tasks remains largely unexplored. This paper presents FinEval, a benchmark specifically designed for the financial domain knowledge in the LLMs. FinEval is a collection of high-quality multiple-choice questions covering Finance, Economy, Accounting, and Certificate. It includes 4,661 questions spanning 34 different academic subjects. To ensure a comprehensive model performance evaluation, FinEval employs a range of prompt types, including zero-shot and few-shot prompts, as well as answer-only and chain-of-thought prompts. Evaluating state-of-the-art Chinese and English LLMs on FinEval, the results show that only GPT-4 achieved an accuracy close to 70% in different prompt settings, indicating significant growth potential for LLMs in the financial domain knowledge. Our work offers a more comprehensive financial kno
    
[^5]: 通过学习内心独白解决视觉语言任务

    Tackling Vision Language Tasks Through Learning Inner Monologues. (arXiv:2308.09970v1 [cs.CL])

    [http://arxiv.org/abs/2308.09970](http://arxiv.org/abs/2308.09970)

    通过学习内心独白，提出了一种新方法（IMMO）来解决复杂的视觉语言任务，克服了混合融合和特征对齐方法所面临的优化和可解释性问题。

    

    视觉语言任务需要AI模型对视觉和文本内容进行理解和推理。基于大型语言模型（LLM）的强大力量，出现了两种主要方法：（1）LLM和视觉-语言模型（VLM）之间的混合融合，其中视觉输入首先被VLM转化为语言描述，成为LLM生成最终答案的输入；（2）语言空间中的视觉特征对齐，其中视觉输入被编码为嵌入向量，并通过进一步的监督微调将其投影到LLM的语言空间中。第一种方法具有轻量级的训练成本和可解释性，但很难以端到端的方式进行优化。第二种方法具有相当的性能，但特征对齐通常需要大量的训练数据，并且缺乏可解释性。为了解决这个困境，我们提出了一种新的方法，即内心独白多模态优化（IMMO），通过模拟思维过程来解决复杂的视觉语言问题。

    Visual language tasks require AI models to comprehend and reason with both visual and textual content. Driven by the power of Large Language Models (LLMs), two prominent methods have emerged: (1) the hybrid integration between LLMs and Vision-Language Models (VLMs), where visual inputs are firstly converted into language descriptions by VLMs, serving as inputs for LLMs to generate final answer(s); (2) visual feature alignment in language space, where visual inputs are encoded as embeddings and projected to LLMs' language space via further supervised fine-tuning. The first approach provides light training costs and interpretability but is hard to be optimized in an end-to-end fashion. The second approach presents decent performance, but feature alignment usually requires large amounts of training data and lacks interpretability. To tackle this dilemma, we propose a novel approach, Inner Monologue Multi-Modal Optimization (IMMO), to solve complex vision language problems by simulating in
    
[^6]: 使用GPT-3.5在资源严重匮乏的语言中进行数据到文本生成:需要谷歌翻译的一点帮助

    Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate. (arXiv:2308.09957v1 [cs.CL])

    [http://arxiv.org/abs/2308.09957](http://arxiv.org/abs/2308.09957)

    本文研究了在资源严重匮乏的语言中使用GPT-3.5进行数据到文本生成的任务。发现few-shot引导对于直接生成目标语言效果更好，而通过英语进行中转后，这种差异消失了。在WebNLG 2023共享任务中，这种few-shot + 翻译系统的变体在所有语言中的表现都优于竞争系统。

    

    LLM（语言模型，如GPT）在处理英语相关任务时表现出色，因为训练数据中英语的比例占主导地位。本文研究了在数据到文本生成任务中，它们如何应对那些在训练数据中严重不足的语言，具体包括爱尔兰语、马耳他语、威尔士语和布里多尼语。我们在GPT-3.5和GPT-4上进行了引导式工程阶段的测试，使用了一小部分示例输入/输出对的各种引导类型和格式。然后我们在两种场景中对两个最有希望的引导进行了全面评估：（i）直接生成目标语言（资源匮乏的语言），（ii）生成英语后再翻译成目标语言。我们发现，在直接生成资源匮乏的语言方面，few-shot引导效果更好，但通过英语进行中转后，这种差异消失了。我们将few-shot + 翻译系统的变体提交到了WebNLG 2023共享任务中，在所有语言中，它们的表现都比竞争系统好得多。

    LLMs like GPT are great at tasks involving English which dominates in their training data. In this paper, we look at how they cope with tasks involving languages that are severely under-represented in their training data, in the context of data-to-text generation for Irish, Maltese, Welsh and Breton. During the prompt-engineering phase we tested a range of prompt types and formats on GPT-3.5 and~4 with a small sample of example input/output pairs. We then fully evaluated the two most promising prompts in two scenarios: (i) direct generation into the under-resourced language, and (ii) generation into English followed by translation into the under-resourced language. We find that few-shot prompting works better for direct generation into under-resourced languages, but that the difference disappears when pivoting via English. The few-shot + translation system variants were submitted to the WebNLG 2023 shared task where they outperformed competitor systems by substantial margins in all lan
    
[^7]: Eva-KELLM：评估LLMs的知识编辑的新基准

    Eva-KELLM: A New Benchmark for Evaluating Knowledge Editing of LLMs. (arXiv:2308.09954v1 [cs.CL])

    [http://arxiv.org/abs/2308.09954](http://arxiv.org/abs/2308.09954)

    Eva-KELLM是一个新的用于评估LLMs知识编辑的基准，提供了一个评估框架和数据集。该基准通过使用原始文档进行知识编辑和多角度的评估来解决了现有研究中收集成本高、表达复杂事实困难、评估视角受限等问题。

    

    大型语言模型（LLMs）的参数中存储着丰富的知识。然而，这些知识随着时间的推移可能变得过时或不合适。因此，对LLMs进行知识编辑并评估其效果引起了越来越多的关注。现有研究主要集中在使用事实三元组进行知识编辑，这不仅在收集上产生高成本，而且在表达复杂事实时也存在困难。此外，这些研究在评估视角上往往受到限制。在本文中，我们提出了Eva-KELLM，用于评估LLMs的知识编辑的新基准。该基准包括一个评估框架和相应的数据集。在我们的框架下，我们首先要求LLM使用原始文档进行知识编辑，与使用事实三元组相比，这提供了一种更方便、更通用的方法。然后我们从多个角度评估更新后的LLM的表现。

    Large language models (LLMs) possess a wealth of knowledge encoded in their parameters. However, this knowledge may become outdated or unsuitable over time. As a result, there has been a growing interest in knowledge editing for LLMs and evaluating its effectiveness. Existing studies primarily focus on knowledge editing using factual triplets, which not only incur high costs for collection but also struggle to express complex facts. Furthermore, these studies are often limited in their evaluation perspectives. In this paper, we propose Eva-KELLM, a new benchmark for evaluating knowledge editing of LLMs. This benchmark includes an evaluation framework and a corresponding dataset. Under our framework, we first ask the LLM to perform knowledge editing using raw documents, which provides a more convenient and universal approach compared to using factual triplets. We then evaluate the updated LLM from multiple perspectives. In addition to assessing the effectiveness of knowledge editing and
    
[^8]: 利用语义文本相似性进行临床调查数据特征选择

    Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection. (arXiv:2308.09892v1 [cs.CL])

    [http://arxiv.org/abs/2308.09892](http://arxiv.org/abs/2308.09892)

    利用语义文本相似性对临床调查数据进行特征选择，通过评估特征名称与目标名称之间的关系来选择特征。

    

    调查数据可能包含大量特征，而示例数量相对较低。在这种情况下，试图从调查数据预测结果的机器学习模型可能会过拟合，导致泛化能力较差。解决这个问题的一种方法是特征选择，它试图选择一个最佳的特征子集进行学习。特征选择过程中一个相对未被探索的信息来源是特征的文本名称，这可能在语义上指示哪些特征与目标结果相关。可以使用语言模型（LMs）评估特征名称和目标名称之间的关系，以生成语义文本相似性（STS）分数，然后可以使用这些分数来选择特征。我们研究了使用STS直接选择特征和在最小冗余最大相关（mRMR）算法中的性能。根据初步调查的结果评估了STS作为特征选择指标的性能。

    Survey data can contain a high number of features while having a comparatively low quantity of examples. Machine learning models that attempt to predict outcomes from survey data under these conditions can overfit and result in poor generalizability. One remedy to this issue is feature selection, which attempts to select an optimal subset of features to learn upon. A relatively unexplored source of information in the feature selection process is the usage of textual names of features, which may be semantically indicative of which features are relevant to a target outcome. The relationships between feature names and target names can be evaluated using language models (LMs) to produce semantic textual similarity (STS) scores, which can then be used to select features. We examine the performance using STS to select features directly and in the minimal-redundancy-maximal-relevance (mRMR) algorithm. The performance of STS as a feature selection metric is evaluated against preliminary survey
    
[^9]: 归纳偏差学习: 用大语言模型生成代码模型

    Inductive-bias Learning: Generating Code Models with Large Language Model. (arXiv:2308.09890v1 [cs.LG])

    [http://arxiv.org/abs/2308.09890](http://arxiv.org/abs/2308.09890)

    这篇论文提出了一种新的学习方法，称为归纳偏差学习（IBL），它将上下文学习（ICL）和代码生成相结合，通过输入训练数据到提示中，输出相应的代码。

    

    大型语言模型(LLMs)因其在上下文学习(ICL)方面的能力而受到关注。ICL技术在不更新LLM参数的情况下，仅通过输入训练数据到提示中即可实现基于规则的高准确性推理。虽然ICL是一个发展中的领域，还有许多未解答的问题，但LLMs本身作为推理模型似乎实现了不需要明确指出"归纳偏差"的推理。另一方面，代码生成也是LLMs的一项重要应用。代码生成的准确性大大提高，使得即使非工程师也可以通过精心设计的提示来生成执行所需任务的代码。本文提出了一种新颖的“学习”方法，称为“归纳偏差学习（IBL）”，它结合了ICL和代码生成的技术。IBL的思想很直观。与ICL类似，IBL将训练数据输入到提示中，并输出相应的代码。

    Large Language Models(LLMs) have been attracting attention due to a ability called in-context learning(ICL). ICL, without updating the parameters of a LLM, it is possible to achieve highly accurate inference based on rules ``in the context'' by merely inputting a training data into the prompt. Although ICL is a developing field with many unanswered questions, LLMs themselves serves as a inference model, seemingly realizing inference without explicitly indicate ``inductive bias''. On the other hand, a code generation is also a highlighted application of LLMs. The accuracy of code generation has dramatically improved, enabling even non-engineers to generate code to perform the desired tasks by crafting appropriate prompts. In this paper, we propose a novel ``learning'' method called an ``Inductive-Bias Learning (IBL)'', which combines the techniques of ICL and code generation. An idea of IBL is straightforward. Like ICL, IBL inputs a training data into the prompt and outputs a code with 
    
[^10]: 打破语言障碍：用于印地语和马拉地语的问答数据集

    Breaking Language Barriers: A Question Answering Dataset for Hindi and Marathi. (arXiv:2308.09862v1 [cs.CL])

    [http://arxiv.org/abs/2308.09862](http://arxiv.org/abs/2308.09862)

    本论文开发了一个用于印地语和马拉地语的问答数据集，通过翻译SQuAD 2.0数据集解决了数据稀缺问题，提供了这两种语言的最好表现模型。

    

    深度学习的最新进展导致了开发出高度复杂的系统，对数据有着无止境的需求。然而，对于低资源语言来说，构建良好的深度学习模型仍然是一个具有挑战性的任务。本文重点是为两种这样的语言-印地语和马拉地语-开发一个问答数据集。虽然印地语是全球第三大使用人数最多的语言，拥有3.45亿说话者，而马拉地语则是全球第11大使用人数最多的语言，拥有8.32千万说话者，但这两种语言在构建高效的问答系统的资源上都面临限制。为了解决数据稀缺的挑战，我们开发了一种新颖的方法来将SQuAD 2.0数据集翻译成印地语和马拉地语。我们发布了这两种语言中最大的问答数据集，每个数据集包含28,000个样本。我们在各种架构上评估了数据集，并发布了在印地语和马拉地语中表现最好的模型。

    The recent advances in deep-learning have led to the development of highly sophisticated systems with an unquenchable appetite for data. On the other hand, building good deep-learning models for low-resource languages remains a challenging task. This paper focuses on developing a Question Answering dataset for two such languages- Hindi and Marathi. Despite Hindi being the 3rd most spoken language worldwide, with 345 million speakers, and Marathi being the 11th most spoken language globally, with 83.2 million speakers, both languages face limited resources for building efficient Question Answering systems. To tackle the challenge of data scarcity, we have developed a novel approach for translating the SQuAD 2.0 dataset into Hindi and Marathi. We release the largest Question-Answering dataset available for these languages, with each dataset containing 28,000 samples. We evaluate the dataset on various architectures and release the best-performing models for both Hindi and Marathi, which 
    
[^11]: 黑盒对抗攻击针对密集检索模型：一种多视角对比学习方法

    Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method. (arXiv:2308.09861v1 [cs.IR])

    [http://arxiv.org/abs/2308.09861](http://arxiv.org/abs/2308.09861)

    本文针对密集检索模型提出了一种黑盒对抗攻击方法，旨在欺骗模型检索到初始候选文档集范围之外的目标文档。

    

    神经排名模型（NRMs）和密集检索（DR）模型在整体检索性能方面取得了重大改进。除了它们的有效性之外，由于深度学习方法在其他领域的鲁棒性已被证明不足，对于核心检索问题的深度学习方法的鲁棒性越来越引起人们的兴趣。到目前为止，所开发的对抗攻击方法主要集中在攻击NRMs上，对DR模型的抗性鲜有关注。本文介绍了对抗检索攻击（AREA）任务。AREA任务旨在欺骗DR模型，使其在响应查询时从最初检索候选文档集之外检索到目标文档。我们考虑了基于决策的黑盒对抗设置，这在实际搜索引擎中是现实的。为了解决AREA任务，我们首先采用现有的为NRMs设计的对抗攻击方法。

    Neural ranking models (NRMs) and dense retrieval (DR) models have given rise to substantial improvements in overall retrieval performance. In addition to their effectiveness, and motivated by the proven lack of robustness of deep learning-based approaches in other areas, there is growing interest in the robustness of deep learning-based approaches to the core retrieval problem. Adversarial attack methods that have so far been developed mainly focus on attacking NRMs, with very little attention being paid to the robustness of DR models. In this paper, we introduce the adversarial retrieval attack (AREA) task. The AREA task is meant to trick DR models into retrieving a target document that is outside the initial set of candidate documents retrieved by the DR model in response to a query. We consider the decision-based black-box adversarial setting, which is realistic in real-world search engines. To address the AREA task, we first employ existing adversarial attack methods designed for N
    
[^12]: LLM对逻辑谬误的容易受到的程度有多大？

    How susceptible are LLMs to Logical Fallacies?. (arXiv:2308.09853v1 [cs.CL])

    [http://arxiv.org/abs/2308.09853](http://arxiv.org/abs/2308.09853)

    本文研究了大型语言模型（LLMs）在多轮辩论中的合理思考能力，并通过逻辑能力测量基准（LOGICOM）评估了它们对逻辑谬误的鲁棒性。评估结果展示了GPT-3.5和GPT-4在包含有争议的数据集上的表现。

    

    本文通过探索谬误论证对大型语言模型（LLMs）在多轮辩论中的合理思考能力的影响，研究了LLMs对逻辑推理性能的鲁棒性。具体而言，我们提出了逻辑能力测量基准（LOGICOM），一种用于评估LLMs对逻辑谬误的鲁棒性的诊断基准。LOGICOM涉及两个角色：说服者和辩手，在一个有争议的话题上进行多轮辩论，说服者试图说服辩手其主张的正确性。首先，LOGICOM评估LLMs通过推理改变其观点的潜力。然后，通过对比说服者使用逻辑谬误和使用逻辑推理的情景，评估辩手在逻辑推理方面的表现。我们使用这个基准测试了GPT-3.5和GPT-4在包含有争议的话题、主张和支持理由的数据集上的表现。

    This paper investigates the rational thinking capability of Large Language Models (LLMs) in multi-round argumentative debates by exploring the impact of fallacious arguments on their logical reasoning performance. More specifically, we present Logic Competence Measurement Benchmark (LOGICOM), a diagnostic benchmark to assess the robustness of LLMs against logical fallacies. LOGICOM involves two agents: a persuader and a debater engaging in a multi-round debate on a controversial topic, where the persuader tries to convince the debater of the correctness of its claim. First, LOGICOM assesses the potential of LLMs to change their opinions through reasoning. Then, it evaluates the debater's performance in logical reasoning by contrasting the scenario where the persuader employs logical fallacies against one where logical reasoning is used. We use this benchmark to evaluate the performance of GPT-3.5 and GPT-4 using a dataset containing controversial topics, claims, and reasons supporting 
    
[^13]: 一幅图像胜过千言万语：内容审核软件的变形测试框架

    An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software. (arXiv:2308.09810v1 [cs.SE])

    [http://arxiv.org/abs/2308.09810](http://arxiv.org/abs/2308.09810)

    本文提出了OASIS，一个用于内容审核软件的变形测试框架，以解决现代社交媒体平台上恶意内容的传播问题。

    

    社交媒体平台的指数增长为人类社会的沟通和内容传播带来了革命。然而，这些平台越来越多地被滥用来传播有害内容，包括仇恨言论、恶意广告和色情内容，导致严重的负面后果，如对青少年心理健康的伤害。尽管在开发和部署文本和图像内容审核方法方面已经做出了巨大努力，但恶意用户可以通过将文字嵌入图像中来规避审核，例如文字的截图，通常带有一些干扰。我们发现现代内容审核软件对此类恶意输入的性能仍然未被充分探索。在这项工作中，我们提出了OASIS，一个用于内容审核软件的变形测试框架。OASIS采用了21个转换规则，这些规则是从我们对来自4个流行社交媒体应用（包括Twitter、Instagram）收集的5000个真实有害内容的试验研究总结出来的。

    The exponential growth of social media platforms has brought about a revolution in communication and content dissemination in human society. Nevertheless, these platforms are being increasingly misused to spread toxic content, including hate speech, malicious advertising, and pornography, leading to severe negative consequences such as harm to teenagers' mental health. Despite tremendous efforts in developing and deploying textual and image content moderation methods, malicious users can evade moderation by embedding texts into images, such as screenshots of the text, usually with some interference. We find that modern content moderation software's performance against such malicious inputs remains underexplored. In this work, we propose OASIS, a metamorphic testing framework for content moderation software. OASIS employs 21 transform rules summarized from our pilot study on 5,000 real-world toxic contents collected from 4 popular social media applications, including Twitter, Instagram,
    
[^14]: VL-PET：通过粒度控制实现视觉和语言参数高效调整

    VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control. (arXiv:2308.09804v1 [cs.CV])

    [http://arxiv.org/abs/2308.09804](http://arxiv.org/abs/2308.09804)

    本文提出了一种名为VL-PET的视觉和语言参数高效调整框架，通过粒度控制机制对模块化修改进行有效控制，克服了现有技术在性能和功能差距方面的不足。

    

    随着预训练语言模型（PLM）的模型规模迅速增长，全面微调在模型训练和存储方面变得代价高昂。在视觉与语言（VL）中，提出了参数高效调整（PET）技术，将模块化修改（例如Adapter和LoRA）集成到编码器-解码器PLMs中。通过调整一小组可训练参数，这些技术的性能与全面微调相当。然而，过度的模块化修改和忽视编码器和解码器之间的功能差距可能导致性能降低，而现有的PET技术（例如VL-Adapter）忽视了这些关键问题。在本文中，我们提出了一种名为Vision-and-Language Parameter-Efficient Tuning（VL-PET）的框架，通过一种新颖的粒度控制机制对模块化修改进行有效控制。通过考虑由这种机制生成的不同粒度控制矩阵，可以实例化多种与模型无关的VL-PET模块。

    As the model size of pre-trained language models (PLMs) grows rapidly, full fine-tuning becomes prohibitively expensive for model training and storage. In vision-and-language (VL), parameter-efficient tuning (PET) techniques are proposed to integrate modular modifications (e.g., Adapter and LoRA) into encoder-decoder PLMs. By tuning a small set of trainable parameters, these techniques perform on par with full fine-tuning. However, excessive modular modifications and neglecting the functionality gap between the encoders and decoders can lead to performance degradation, while existing PET techniques (e.g., VL-Adapter) overlook these critical issues. In this paper, we propose a Vision-and-Language Parameter-Efficient Tuning (VL-PET) framework to impose effective control over modular modifications via a novel granularity-controlled mechanism. Considering different granularity-controlled matrices generated by this mechanism, a variety of model-agnostic VL-PET modules can be instantiated fr
    
[^15]: 追求多模态视觉语言模型中的基于实际的视觉空间推理

    Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models. (arXiv:2308.09778v1 [cs.CV])

    [http://arxiv.org/abs/2308.09778](http://arxiv.org/abs/2308.09778)

    本文旨在研究多模态视觉语言模型在理解空间关系方面的能力，提出了细粒度组合的空间关系基础，并采用自底向上的方法评估空间关系推理任务的性能。

    

    随着大规模视觉和语言模型（VLMs）的进展，评估它们在各种视觉推理任务（如计数、指涉表达和一般的视觉问题回答）上的表现变得越来越重要。本文的重点是研究这些模型理解空间关系的能力。先前，人们尝试使用图像-文本匹配（Liu, Emerson, and Collier 2022) 或视觉问题回答任务来处理此问题，但都表现出性能不佳并且与人类性能存在较大差距。为了更好地理解差距，我们提出了细粒度组合的空间关系基础，并提出了一种自底向上的方法来对空间从句进行排名并评估空间关系推理任务的性能。我们建议通过结合和地面化物体对应的名词短语和它们的位置的证据来计算空间从句的最终排名。我们在代表性的视觉语言模型上展示了这种方法。

    With the advances in large scale vision-and-language models (VLMs) it is of interest to assess their performance on various visual reasoning tasks such as counting, referring expressions and general visual question answering. The focus of this work is to study the ability of these models to understanding spatial relations. Previously, this has been tackled using image-text matching (Liu, Emerson, and Collier 2022) or visual question answering task, both showing poor performance and a large gap compared to human performance. To better understand the gap, we present fine-grained compositional grounding of spatial relationships and propose a bottom up approach for ranking spatial clauses and evaluating the performance of spatial relationship reasoning task. We propose to combine the evidence from grounding noun phrases corresponding to objects and their locations to compute the final rank of the spatial clause. We demonstrate the approach on representative vision-language models (Tan and 
    
[^16]: YORC：约鲁巴语阅读理解数据集

    YORC: Yoruba Reading Comprehension dataset. (arXiv:2308.09768v1 [cs.CL])

    [http://arxiv.org/abs/2308.09768](http://arxiv.org/abs/2308.09768)

    本文介绍了一个新的多项选择约鲁巴语阅读理解数据集YORC，通过跨语言转移和大型语言模型的使用，提供了该数据集的基准结果和更高层次的结果。

    

    本文介绍了YORC：一个基于约鲁巴语高中阅读理解考试的新的多项选择约鲁巴语阅读理解数据集。我们使用已训练的仅编码器模型，通过跨语言转移来提供基准结果，同时还使用大型语言模型（LLMs）如GPT-4提供了结果。

    In this paper, we create YORC: a new multi-choice Yoruba Reading Comprehension dataset that is based on Yoruba high-school reading comprehension examination. We provide baseline results by performing cross-lingual transfer using existing English RACE dataset based on a pre-trained encoder-only model. Additionally, we provide results by prompting large language models (LLMs) like GPT-4.
    
[^17]: 受冷落: 相似度分数的反差效应

    Taken by Surprise: Contrast effect for Similarity Scores. (arXiv:2308.09765v1 [cs.CL])

    [http://arxiv.org/abs/2308.09765](http://arxiv.org/abs/2308.09765)

    提出了一种新的相似度度量方法，称为“惊喜分数”，该方法能够考虑对象的上下文信息并显著提高零样本和少样本文档分类任务的性能。

    

    准确评估物体向量嵌入的相似度对于自然语言处理、信息检索和分类任务至关重要。流行的相似度分数（如余弦相似度）基于嵌入向量对，并忽略了从中提取对象的分布。人类对物体相似度的感知显著取决于对象出现的上下文。在这项工作中，我们提出了“惊喜分数”，这是一个对整体进行归一化的相似度度量，包括了人类感知的反差效应，并显著提高了零样本和少样本文档分类任务的性能。此分数量化了在两个元素之间找到给定相似度的惊喜，相对于成对的整体相似度。我们在零样本/少样本分类和聚类任务上评估了这个度量，通常发现与原始余弦相似度相比，性能提高了10-15\%。我们的代码...

    Accurately evaluating the similarity of object vector embeddings is of critical importance for natural language processing, information retrieval and classification tasks. Popular similarity scores (e.g cosine similarity) are based on pairs of embedding vectors and disregard the distribution of the ensemble from which objects are drawn. Human perception of object similarity significantly depends on the context in which the objects appear. In this work we propose the \emph{surprise score}, an ensemble-normalized similarity metric that encapsulates the contrast effect of human perception and significantly improves the classification performance on zero- and few-shot document classification tasks. This score quantifies the surprise to find a given similarity between two elements relative to the pairwise ensemble similarities. We evaluate this metric on zero/few shot classification and clustering tasks and typically find 10-15\% better performance compared to raw cosine similarity. Our cod
    
[^18]: ChatGPT-HealthPrompt. 利用ChatGPT在基于提示的医疗决策支持中发挥可解释人工智能的力量

    ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based Healthcare Decision Support using ChatGPT. (arXiv:2308.09731v1 [cs.AI])

    [http://arxiv.org/abs/2308.09731](http://arxiv.org/abs/2308.09731)

    本研究介绍了一种创新的方法，利用ChatGPT在临床决策中应用大型语言模型，通过策略性设计上下文提示，并以领域知识为基础进行高质量的二元分类任务。通过将机器学习模型视为医疗专家，提取关键见解并辅助决策过程，这一领域知识和人工智能的结合在创建更具洞察力的诊断工具方面具有重要潜力。此外，研究还探索了基于ChatGPT的零样本和少样本提示学习的动态，并验证了ChatGPT在医疗决策支持中的优势。

    

    本研究提出了一种创新的方法，将大型语言模型（LLMs）应用于临床决策，重点关注OpenAI的ChatGPT。我们的方法引入了上下文提示的使用，策略性地设计包括任务描述、特征描述，并且关键地整合领域知识，以便在数据稀缺的情况下进行高质量的二元分类任务。我们工作的创新之处在于利用从高性能可解释机器学习模型获得的领域知识，并将其无缝地融入到提示设计中。通过将这些机器学习模型视为医疗专家，我们提取了关于特征重要性的关键见解，以帮助决策过程。领域知识和人工智能的相互作用在创建更具洞察力的诊断工具方面具有重要的潜力。此外，我们的研究探讨了基于LLMs的零样本和少样本提示学习的动态。通过比较OpenAI的ChatGPT与传统的supervised学习方法的表现，我们证明了ChatGPT在医疗决策支持方面的优势。

    This study presents an innovative approach to the application of large language models (LLMs) in clinical decision-making, focusing on OpenAI's ChatGPT. Our approach introduces the use of contextual prompts-strategically designed to include task description, feature description, and crucially, integration of domain knowledge-for high-quality binary classification tasks even in data-scarce scenarios. The novelty of our work lies in the utilization of domain knowledge, obtained from high-performing interpretable ML models, and its seamless incorporation into prompt design. By viewing these ML models as medical experts, we extract key insights on feature importance to aid in decision-making processes. This interplay of domain knowledge and AI holds significant promise in creating a more insightful diagnostic tool.  Additionally, our research explores the dynamics of zero-shot and few-shot prompt learning based on LLMs. By comparing the performance of OpenAI's ChatGPT with traditional supe
    
[^19]: MindMap：知识图谱激发大型语言模型的思维图思考方法

    MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])

    [http://arxiv.org/abs/2308.09729](http://arxiv.org/abs/2308.09729)

    本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。

    

    通常，大型语言模型存在无法整合新知识、产生幻觉和决策过程不透明等限制。本文探讨了如何利用知识图谱（KG）来激发大型语言模型，以解决整合最新知识和引发模型思维路径的问题。具体来说，我们构建了一个提示管道，使大型语言模型能够理解KG输入并利用隐含知识和检索到的外部知识进行推理。此外，我们研究了引发大型语言模型执行推理和生成答案的思维导图。研究发现，生成的思维导图基于知识的本体论，展示了大型语言模型的推理路径，从而为生产环境中的推理提供了探索和评估的可能性。对三个问答数据集的实验证明，MindMap提示方法带来了显著的实证增益。

    LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, pr
    
[^20]: FineQuant: 利用细粒度的权重量化为LLMs解锁效率

    FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs. (arXiv:2308.09723v1 [cs.LG])

    [http://arxiv.org/abs/2308.09723](http://arxiv.org/abs/2308.09723)

    该论文提出了一种针对LLMs的高效权重量化方法，通过减少内存消耗和加速推理，解决了大型语言模型在实际部署中遇到的挑战。研究者们通过引入一种简单而有效的启发式方法，仅利用模型的权重，而无需额外微调，成功降低了质量损失。

    

    大型语言模型（LLMs）在各种语言任务中取得了最先进的性能，但由于其大量的内存需求，对于实际部署提出了挑战。此外，最新的生成模型由于自回归解码过程中的内存带宽瓶颈导致推理成本高。为了解决这些问题，我们提出了一种高效的仅基于权重量化方法，以减少LLMs的内存消耗并加速推理。为了确保质量降低最小化，我们引入了一种简单而有效的启发式方法，仅利用预训练模型的模型权重。这种方法适用于无需额外微调的Mixture-of-Experts（MoE）和密集模型。为了展示我们提出的方法的有效性，我们首先分析与LLMs量化相关的挑战和问题。随后，我们提出了自适应找到权重细粒度的启发式方法。

    Large Language Models (LLMs) have achieved state-of-the-art performance across various language tasks but pose challenges for practical deployment due to their substantial memory requirements. Furthermore, the latest generative models suffer from high inference costs caused by the memory bandwidth bottleneck in the auto-regressive decoding process. To address these issues, we propose an efficient weight-only quantization method that reduces memory consumption and accelerates inference for LLMs. To ensure minimal quality degradation, we introduce a simple and effective heuristic approach that utilizes only the model weights of a pre-trained model. This approach is applicable to both Mixture-of-Experts (MoE) and dense models without requiring additional fine-tuning. To demonstrate the effectiveness of our proposed method, we first analyze the challenges and issues associated with LLM quantization. Subsequently, we present our heuristic approach, which adaptively finds the granularity of 
    
[^21]: 一个可信的基于LSTM-Autoencoder网络的社交媒体网络欺凌检测方法：使用合成数据

    A Trustable LSTM-Autoencoder Network for Cyberbullying Detection on Social Media Using Synthetic Data. (arXiv:2308.09722v1 [cs.LG])

    [http://arxiv.org/abs/2308.09722](http://arxiv.org/abs/2308.09722)

    本研究提出了一种使用合成数据进行社交媒体网络欺凌检测的可信LSTM-Autoencoder网络。该方法解决了数据可用性困难的问题，并通过实验证明了在印地语、孟加拉语和英语数据集上的有效性。

    

    社交媒体网络欺凌对人类生活有害。随着在线社交网络的不断增长，仇恨言论的数量也在增加。这些可怕的内容可能导致抑郁和与自杀有关的行为。本文提出了一种使用合成数据进行社交媒体网络欺凌检测的可信LSTM-Autoencoder网络。我们通过生成机器翻译数据展示了一种解决数据可用性困难的前沿方法。然而，印地语和孟加拉语等几种语言由于缺乏数据集的原因，仍然缺乏足够的研究。我们使用提出的模型和传统模型（包括长短期记忆网络（LSTM），双向长短期记忆网络（BiLSTM），LSTM-Autoencoder，Word2vec，双向编码器表示转换（BERT）和生成预训练转换器2（GPT-2）模型）对印地语、孟加拉语和英语数据集进行了实验性的侵犯评论识别。我们采用了评估指标来评估模型的性能。

    Social media cyberbullying has a detrimental effect on human life. As online social networking grows daily, the amount of hate speech also increases. Such terrible content can cause depression and actions related to suicide. This paper proposes a trustable LSTM-Autoencoder Network for cyberbullying detection on social media using synthetic data. We have demonstrated a cutting-edge method to address data availability difficulties by producing machine-translated data. However, several languages such as Hindi and Bangla still lack adequate investigations due to a lack of datasets. We carried out experimental identification of aggressive comments on Hindi, Bangla, and English datasets using the proposed model and traditional models, including Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM), LSTM-Autoencoder, Word2vec, Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformer 2 (GPT-2) models. We employed evaluation m
    
[^22]: 关于大型语言模型的意想不到能力

    On the Unexpected Abilities of Large Language Models. (arXiv:2308.09720v1 [cs.AI])

    [http://arxiv.org/abs/2308.09720](http://arxiv.org/abs/2308.09720)

    大型语言模型展示了与其训练任务不直接相关的广泛能力，通过间接获取过程使其拥有综合能力的发展，这些能力在一定程度上可预测，并且与人类认知有关。

    

    大型语言模型能展示出与其训练任务（预测人类书写文本的下一个单词）不直接相关的广泛能力。本文讨论了这种间接获取过程的性质及其与其他已知间接过程的关系。文章主张这种间接获取的一个重要副作用是综合能力的发展。本文还讨论了大型语言模型所开发的能力在多大程度上是可预测的。最后，文章简要讨论了这些系统所获得的认知技能与人类认知之间的关系。

    Large language models are capable of displaying a wide range of abilities that are not directly connected with the task for which they are trained: predicting the next words of human-written texts. In this article, I discuss the nature of this indirect acquisition process and its relation to other known indirect processes. I argue that an important side effect of such indirect acquisition is the development of integrated abilities. I discuss the extent to which the abilities developed by large language models are predictable. Finally, I briefly discuss the relation between the cognitive skills acquired by these systems and human cognition.
    
[^23]: 想法图：用大型语言模型解决复杂问题

    Graph of Thoughts: Solving Elaborate Problems with Large Language Models. (arXiv:2308.09687v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.09687](http://arxiv.org/abs/2308.09687)

    想法图（GoT）是一种新的框架，它超越了现有的提示范式，通过将大型语言模型（LLM）的信息建模为任意图形，将LLM想法组合成具有协同效应的结果，提炼整个思维网络的本质，或者使用反馈环路增强思维。GoT在不同任务上展示出优势，并可以通过新的想法转换进行扩展，使LLM的推理更接近人类思维。

    

    我们介绍了一种名为想法图（Graph of Thoughts，GoT）的框架，它在大型语言模型（LLM）的提示能力上超越了Chain-of-Thought或Tree of Thoughts（ToT）等范式。GoT的关键思想和主要优势在于能够将LLM生成的信息建模为任意图形，其中信息单元（"LLM想法"）是顶点，边表示这些顶点之间的依赖关系。这种方法使得将任意LLM想法组合成具有协同效应的结果、提炼整个思维网络的本质或者使用反馈环路增强思维成为可能。我们证明GoT在不同任务上比最先进的方法有优势，例如在排序任务上质量提高了62%，同时成本降低了超过31%。我们确保GoT能够通过新的想法转换进行扩展，从而可以用于开创新的提示方案。这项工作使得LLM的推理更接近人类思维。

    We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information ("LLM thoughts") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62% over ToT, while simultaneously reducing costs by >31%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinki
    
[^24]: 树形混合思维: 将快速和慢速思考结合用于多跳视觉推理

    Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning. (arXiv:2308.09658v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.09658](http://arxiv.org/abs/2308.09658)

    该论文提出了一种树形混合思维的方法，通过将快速和慢速思考结合，用于解决多跳视觉推理任务中准确性和效率之间的权衡问题。

    

    使用大型语言模型（LLMs）生成类似代码的计划，用于复杂推理任务（如视觉推理）正在成为一种有前途的趋势。这种被称为LLM-based planning的范式在问题解决的灵活性和可解释性方面具有优势。然而，当前的研究大多限于简单问题的基本情景，这些问题可以直接回答出来，只需要几个推理步骤。对于更具挑战性的多跳视觉推理任务的计划制订还未充分探索。在多跳推理的情况下，准确性和计划搜索复杂性之间的权衡变得显著。目前的算法要么通过采用快速一次性生成来解决效率问题，要么采用复杂的迭代生成方法来提高准确性。但两种方法都无法平衡效率和性能的需求。受到人脑中的双系统认知（快速思考和慢速思考）的启发，我们提出了一种树形混合思维的方法。

    There emerges a promising trend of using large language models (LLMs) to generate code-like plans for complex inference tasks such as visual reasoning. This paradigm, known as LLM-based planning, provides flexibility in problem solving and endows better interpretability. However, current research is mostly limited to basic scenarios of simple questions that can be straightforward answered in a few inference steps. Planning for the more challenging multi-hop visual reasoning tasks remains under-explored. Specifically, under multi-hop reasoning situations, the trade-off between accuracy and the complexity of plan-searching becomes prominent. The prevailing algorithms either address the efficiency issue by employing the fast one-stop generation or adopt a complex iterative generation method to improve accuracy. Both fail to balance the need for efficiency and performance. Drawing inspiration from the dual system of cognition in the human brain, the fast and the slow think processes, we pr
    
[^25]: 可微检索增强通过生成式语言建模的电子商务查询意图分类

    Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification. (arXiv:2308.09308v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2308.09308](http://arxiv.org/abs/2308.09308)

    本研究提出了一种可微的检索增强方法，通过生成式语言建模，在电子商务查询意图分类任务中显著提升了性能，解决了检索器和下游模型之间的不可微性问题。

    

    检索增强通过使用知识检索器和外部语料库来增强下游模型，而不仅仅是增加模型参数的数量，在许多自然语言处理（NLP）任务中，如文本分类、问题回答等方面已经取得了成功。然而，由于两个部分之间的不可微性，现有方法通常通过分别或异步训练检索器和下游模型来导致性能下降，与端到端联合训练相比。在本文中，我们提出了Differentiable Retrieval Augmentation via Generative lANguage modeling（Dragan），通过一种新颖的可微重构来解决这个问题。我们在电子商务搜索中的一个有挑战性的NLP任务上展示了我们提出的方法的有效性，即查询意图分类。实验结果和消融研究均表明，所提出的方法显著且合理地改进了最先进的基准模型。

    Retrieval augmentation, which enhances downstream models by a knowledge retriever and an external corpus instead of by merely increasing the number of model parameters, has been successfully applied to many natural language processing (NLP) tasks such as text classification, question answering and so on. However, existing methods that separately or asynchronously train the retriever and downstream model mainly due to the non-differentiability between the two parts, usually lead to degraded performance compared to end-to-end joint training. In this paper, we propose Differentiable Retrieval Augmentation via Generative lANguage modeling(Dragan), to address this problem by a novel differentiable reformulation. We demonstrate the effectiveness of our proposed method on a challenging NLP task in e-commerce search, namely query intent classification. Both the experimental results and ablation study show that the proposed method significantly and reasonably improves the state-of-the-art basel
    
[^26]: 自学习增强 (ReST) 用于语言模型的强化学习

    Reinforced Self-Training (ReST) for Language Modeling. (arXiv:2308.08998v1 [cs.CL])

    [http://arxiv.org/abs/2308.08998](http://arxiv.org/abs/2308.08998)

    本文提出了一种称为自学习增强 (ReST) 的算法，通过从人类反馈中进行强化学习来提高大型语言模型 (LLM) 的输出质量。在机器翻译任务上的实验结果表明，ReST能够以高效的方式显著提高翻译质量。

    

    通过从人类反馈中进行强化学习 (RLHF)，可以通过与人类偏好对齐来提高大型语言模型 (LLM) 的输出质量。我们提出了一种简单的算法，通过增长批量强化学习 (RL) 来与人类偏好对齐 LLM，我们称之为增强自学习 (ReST)。给定初始的LLM策略，ReST通过从策略中生成样本来产生一个数据集，然后使用离线强化学习算法改进LLM策略。ReST比典型的在线RLHF方法更高效，因为训练数据集是离线生成的，可以重复使用数据。虽然ReST是适用于所有生成学习设置的通用方法，但我们将重点放在其在机器翻译中的应用上。我们的结果表明，ReST可以以计算和采样高效的方式显著提高翻译质量，通过自动化指标和人工评估在机器翻译基准上测量。

    Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.
    
[^27]: 探索上下文学习的演示集成

    Exploring Demonstration Ensembling for In-context Learning. (arXiv:2308.08780v1 [cs.CL])

    [http://arxiv.org/abs/2308.08780](http://arxiv.org/abs/2308.08780)

    本研究探索了上下文学习的演示集成方法，用于提高语言模型在给定任务的输入输出对中的预测性能。通过将演示分成子集并组合各子集的输出概率，我们得到了最终的预测结果。

    

    上下文学习通过向语言模型展示输入-输出对的示例来进行操作，即演示。上下文学习的标准方法是将演示与测试输入连接起来提示给语言模型。然而，这种方法存在一些问题。首先，连接方法几乎无法控制每个演示对模型预测的贡献。当一些演示与测试示例无关时，这可能不是最优的。其次，由于某些变换器模型对输入长度有限制，将许多示例放入上下文中可能是不可行的，特别是在处理长输入任务时。在本研究中，我们探索了演示集成（DENSE）作为简单连接的替代方法。模型使用演示的子集（即bucket）来预测输出，然后将每个子集得到的输出概率组合起来生成最终预测结果。我们使用GPT-j研究了不同的集成方法，并进行了实验。

    In-context learning (ICL) operates by showing language models (LMs) examples of input-output pairs for a given task, i.e., demonstrations. The standard approach for ICL is to prompt the LM with concatenated demonstrations followed by the test input. This approach suffers from some issues. First, concatenation offers almost no control over the contribution of each demo to the model prediction. This can be sub-optimal when some demonstrations are irrelevant to the test example. Second, due to the input length limit of some transformer models, it might be infeasible to fit many examples into the context, especially when dealing with long-input tasks. In this work, we explore Demonstration Ensembling (DENSE) as an alternative to simple concatenation. \model predicts outputs using subsets (i.e., buckets) of the demonstrations and then combines the output probabilities resulting from each subset to produce the final prediction. We study different ensembling methods using GPT-j and experiment
    
[^28]: 大型语言模型在持续微调过程中的灾难性遗忘的实证研究

    An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning. (arXiv:2308.08747v1 [cs.CL])

    [http://arxiv.org/abs/2308.08747](http://arxiv.org/abs/2308.08747)

    该研究实证评估了大型语言模型在持续微调过程中的灾难性遗忘现象，并发现随着模型规模增加，遗忘的严重程度也加剧。与编码器-解码器模型相比，仅有解码器的模型遗忘较少并保留更多知识。此外，研究还发现LLMs可以减轻语言偏见，并且ALPACA在保留知识和容量方面具有优势。

    

    灾难性遗忘（CF）是机器学习中的一种现象，当模型学习新信息时，它会忘记先前学到的信息。由于大型语言模型（LLMs）显示出了出色的性能，探究LLMs在持续微调中是否存在CF是很有意义的。在这项研究中，我们从领域知识、推理和阅读理解的角度对LLMs的遗忘现象进行了实证评估。实验表明，从1b到7b的范围内，LLMs普遍存在灾难性遗忘现象，并且随着规模的增加，遗忘的严重程度也加剧。与编码器-解码器模型mT0相比，仅有解码器的模型BLOOMZ遗忘较少并保留更多知识。我们还观察到，在持续微调过程中，LLMs可以减轻语言偏见（如性别偏见）。此外，我们发现与LLAMA相比，ALPACA在保留更多知识和容量方面具有优势。

    Catastrophic forgetting (CF) is a phenomenon that occurs in machine learning when a model forgets previously learned information as it learns new information. As large language models (LLMs) have shown excellent performance, it is interesting to uncover whether CF exists in the continual fine-tuning of LLMs. In this study, we empirically evaluate the forgetting phenomenon in LLMs' knowledge, from the perspectives of domain knowledge, reasoning, and reading comprehension. The experiments demonstrate that catastrophic forgetting is generally observed in LLMs ranging from 1b to 7b. Furthermore, as the scale increases, the severity of forgetting also intensifies. Comparing the decoder-only model BLOOMZ with the encoder-decoder model mT0, BLOOMZ suffers less forgetting and maintains more knowledge. We also observe that LLMs can mitigate language bias (e.g. gender bias) during continual fine-tuning. Moreover, we find that ALPACA can maintain more knowledge and capacity compared with LLAMA du
    
[^29]: 自然语言是图表所需要的全部内容

    Natural Language is All a Graph Needs. (arXiv:2308.07134v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07134](http://arxiv.org/abs/2308.07134)

    本论文提出了一种名为InstructGLM的结构化语言模型算法，该算法将大型语言模型与图表学习问题相结合，旨在探索是否可以用语言模型取代图神经网络作为图表的基础模型。

    

    大规模预训练语言模型的出现，如ChatGPT，已经在人工智能的各个研究领域中引起了革命。基于Transformer的大型语言模型（LLMs）逐渐取代了CNN和RNN，将计算机视觉和自然语言处理领域统一起来。与相对独立存在的数据（如图像、视频或文本）相比，图表是一种包含丰富结构和关系信息的数据类型。同时，作为最具表现力的媒介之一，自然语言在描述复杂结构方面表现出色。然而，将图表学习问题纳入生成式语言建模框架的现有工作仍然非常有限。随着大型语言模型的重要性不断增长，探索LLMs是否也可以替代GNNs成为图表的基础模型变得至关重要。在本文中，我们提出了InstructGLM（结构化语言模型）算法，系统地设计高度可扩展的模型来处理图表学习问题。

    The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers-based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scal
    
[^30]: 单句阅读器：解决答案位置偏倚的新方法

    Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias. (arXiv:2308.04566v1 [cs.CL])

    [http://arxiv.org/abs/2308.04566](http://arxiv.org/abs/2308.04566)

    本论文针对机器阅读理解中的答案位置偏倚问题，提出了一种名为单句阅读器的新方法，该方法使用六种不同模型实现。实验证明，单句阅读器与传统训练集上训练的模型几乎具有相当的性能，有效解决了答案位置偏倚问题。

    

    机器阅读理解（MRC）模型往往利用伪相关性（也称为数据集偏差或研究界的标注工件）。因此，这些模型可能在不完全理解给定的上下文和问题的情况下执行MRC任务，这是不可取的，因为它可能导致对分布转移的低稳健性。本文深入探讨了答案位置偏倚的概念，其中训练问题中有相当比例的答案仅位于上下文的第一句。我们提出了一种名为单句阅读器的新方法来解决MRC中的答案位置偏倚问题。我们使用六种不同模型来实现这种方法，并对其性能进行了彻底分析。值得注意的是，我们提出的单句阅读器的结果几乎与传统训练集上训练的模型相当，证明了其有效性。我们的研究还讨论了我们的单句阅读器遇到的几个挑战和提出的应对策略。

    Machine Reading Comprehension (MRC) models tend to take advantage of spurious correlations (also known as dataset bias or annotation artifacts in the research community). Consequently, these models may perform the MRC task without fully comprehending the given context and question, which is undesirable since it may result in low robustness against distribution shift. This paper delves into the concept of answer-position bias, where a significant percentage of training questions have answers located solely in the first sentence of the context. We propose a Single-Sentence Reader as a new approach for addressing answer position bias in MRC. We implement this approach using six different models and thoroughly analyze their performance. Remarkably, our proposed Single-Sentence Readers achieve results that nearly match those of models trained on conventional training sets, proving their effectiveness. Our study also discusses several challenges our Single-Sentence Readers encounter and prop
    
[^31]: PaniniQA: 通过交互式问答提升患者教育

    PaniniQA: Enhancing Patient Education Through Interactive Question Answering. (arXiv:2308.03253v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03253](http://arxiv.org/abs/2308.03253)

    PaniniQA是一个以患者为中心的交互式问答系统，旨在帮助患者理解他们的出院指导，提供及时的反馈以纠正患者的误解，通过有效的互动提高患者对医疗指导的掌握程度。

    

    患者门户允许出院患者在电子健康记录中访问他们的个性化出院指导。然而，许多患者很难理解或记住他们的出院指导。在本论文中，我们提出了PaniniQA，一个以患者为中心的交互式问答系统，旨在帮助患者理解他们的出院指导。PaniniQA首先从患者的出院指导中识别重要的临床内容，然后提出患者特定的教育问题。此外，PaniniQA还配备了答案验证功能，可以及时反馈来纠正患者的误解。我们的全面自动和人工评估结果表明，PaniniQA能够通过有效的互动提高患者对医疗指导的掌握程度。

    Patient portal allows discharged patients to access their personalized discharge instructions in electronic health records (EHRs). However, many patients have difficulty understanding or memorizing their discharge instructions. In this paper, we present PaniniQA, a patient-centric interactive question answering system designed to help patients understand their discharge instructions. PaniniQA first identifies important clinical content from patients' discharge instructions and then formulates patient-specific educational questions. In addition, PaniniQA is also equipped with answer verification functionality to provide timely feedback to correct patients' misunderstandings. Our comprehensive automatic and human evaluation results demonstrate our PaniniQA is capable of improving patients' mastery of their medical instructions through effective interactions
    
[^32]: 通过大型语言模型扩展临床试验匹配：以肿瘤学为案例研究

    Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology. (arXiv:2308.02180v1 [cs.CL])

    [http://arxiv.org/abs/2308.02180](http://arxiv.org/abs/2308.02180)

    本文研究了使用大型语言模型（LLMs）扩展临床试验匹配的方法，并以肿瘤学为案例研究。研究结果显示，先进的LLMs能够处理临床试验的复杂条件和匹配逻辑，相较于之前的方法，性能显著提升，并可作为人工辅助筛选患者-试验候选人的初步解决方案。

    

    临床试验匹配是医疗传递和发现中的关键过程。实际上，由于庞大的非结构化数据和不可扩展的手动处理，该过程存在问题。本文通过以肿瘤学为重点领域，对使用大型语言模型（LLM）扩展临床试验匹配进行了系统研究。我们的研究基于一个正在美国一个大型医疗网络进行测试部署的临床试验匹配系统。初步结果令人鼓舞：先进的LLM（如GPT-4）可以立即连接临床试验的复杂的合格条件，并提取复杂的匹配逻辑（例如嵌套的AND/OR/NOT）。虽然仍不完美，LLM在性能上显著优于以前的强基准线，并可能作为在人与人之间进行候选患者-试验划分的初步解决方案。我们的研究还揭示了一些应用LLM进行端到端临床试验匹配的重要增长领域，例如上下文限制和准确性。

    Clinical trial matching is a key process in health delivery and discovery. In practice, it is plagued by overwhelming unstructured data and unscalable manual processing. In this paper, we conduct a systematic study on scaling clinical trial matching using large language models (LLMs), with oncology as the focus area. Our study is grounded in a clinical trial matching system currently in test deployment at a large U.S. health network. Initial findings are promising: out of box, cutting-edge LLMs, such as GPT-4, can already structure elaborate eligibility criteria of clinical trials and extract complex matching logic (e.g., nested AND/OR/NOT). While still far from perfect, LLMs substantially outperform prior strong baselines and may serve as a preliminary solution to help triage patient-trial candidates with humans in the loop. Our study also reveals a few significant growth areas for applying LLMs to end-to-end clinical trial matching, such as context limitation and accuracy, especially
    
[^33]: 教授较小的语言模型如何推广到未见过的组合问题

    Teaching Smaller Language Models To Generalise To Unseen Compositional Questions. (arXiv:2308.00946v1 [cs.CL])

    [http://arxiv.org/abs/2308.00946](http://arxiv.org/abs/2308.00946)

    我们研究了如何教授较小的语言模型来推广到未见过的组合问题，通过多任务监督预训练和密集检索系统，我们建立了强大的基准，并展示了解决多个评估数据集上的问题的能力。

    

    我们使一个较小的语言模型能够推广到回答具有挑战性的组合问题，这些问题在训练中没有出现。为此，我们提出了一种多任务监督预训练的组合方法，涵盖了最多93个任务，旨在培养多样的推理能力，并结合了一个密集的检索系统，旨在检索一组证据性的段落片段。在问答方面，最近的进展要么通过针对非常大的预训练语言模型的提示方法实现零或少样本学习，要么通过微调较小的模型，有时结合信息检索进行。我们关注较少探索的问题，即较小的模型在对于不存在足够信息来回答特定问题的语料库进行检索时，能否实现零样本推广。我们在这个设置中为多样的评估数据集（StrategyQA，CommonsenseQA，IIRC，DROP，Musique和ARC-DA）建立了强大的基准，并展示了...

    We equip a smaller Language Model to generalise to answering challenging compositional questions that have not been seen in training. To do so we propose a combination of multitask supervised pretraining on up to 93 tasks designed to instill diverse reasoning abilities, and a dense retrieval system that aims to retrieve a set of evidential paragraph fragments. Recent progress in question-answering has been achieved either through prompting methods against very large pretrained Language Models in zero or few-shot fashion, or by fine-tuning smaller models, sometimes in conjunction with information retrieval. We focus on the less explored question of the extent to which zero-shot generalisation can be enabled in smaller models with retrieval against a corpus within which sufficient information to answer a particular question may not exist. We establish strong baselines in this setting for diverse evaluation datasets (StrategyQA, CommonsenseQA, IIRC, DROP, Musique and ARC-DA), and show tha
    
[^34]: 使用Fine-Tuned的OpenAI LLM预测机器翻译输出中的完美质量段落：是否可以从历史数据中捕捉编辑距离模式？

    Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?. (arXiv:2308.00158v1 [cs.CL])

    [http://arxiv.org/abs/2308.00158](http://arxiv.org/abs/2308.00158)

    本研究探讨了使用Fine-Tuned的OpenAI LLM进行翻译质量估计的能力，实验证明可以通过Fine-Tuned的ChatGPT来预测机器翻译的质量，但仍有改进的空间。

    

    翻译质量估计（TQE）是将输出翻译部署到使用中之前的重要步骤。 TQE对于评估机器翻译（MT）和人工翻译（HT）的质量也是至关重要的，而不需要查看参考翻译。在这项工作中，我们检查了最先进的大型语言模型（LLMs）是否可以为TQE任务和它们的能力进行Fine-Tune。我们以ChatGPT为例，将TQE视为二元分类任务。使用英意和英德训练语料库，我们的实验结果显示，通过ChatGPT的API Fine-Tuned可以在预测翻译质量方面获得相对较高的得分，即是否需要编辑翻译，但肯定有改进准确性的空间。英意双语摘要可在论文中找到。

    Translation Quality Estimation (TQE) is an important step before deploying the output translation into usage. TQE is also critical in assessing machine translation (MT) and human translation (HT) quality without seeing the reference translations. In this work, we examine if the state-of-the-art large language models (LLMs) can be fine-tuned for the TQE task and their capability. We take ChatGPT as one example and approach TQE as a binary classification task. Using English-Italian and English-German training corpus, our experimental results show that fine-tuned ChatGPT via its API can achieve a relatively high score on predicting translation quality, i.e. if the translation needs to be edited, but there is definitely space to improve the accuracy. English-Italiano bilingual Abstract is available in the paper.
    
[^35]: 使用大型语言模型进行渗透测试：AI作为辅助

    Getting pwn'd by AI: Penetration Testing with Large Language Models. (arXiv:2308.00121v1 [cs.CL])

    [http://arxiv.org/abs/2308.00121](http://arxiv.org/abs/2308.00121)

    本文探讨了使用大型语言模型（如GPT3.5）作为AI助手来增强渗透测试人员的能力，实现了高级任务规划和低级漏洞寻找两种用例，取得了有前景的初步结果，并就提供该技术的伦理问题进行了讨论。

    

    软件安全测试领域，尤其是渗透测试是一项需要高水平专业知识的活动，并涉及许多手动测试和分析步骤。本文探讨了使用大型语言模型（如GPT3.5）来增强渗透测试人员的能力。我们研究了两种不同的用例：用于安全测试任务的高级任务规划和在易受攻击的虚拟机中进行低级漏洞寻找。对于后者，我们实现了一个闭环反馈，将由语言模型生成的低级操作与易受攻击的虚拟机（通过SSH连接）相连，并允许语言模型分析虚拟机状态以寻找漏洞，并提供具体的攻击向量。我们讨论了有前景的初步结果，详细介绍了改进的途径，并就提供该技术的伦理问题进行了讨论。

    The field of software security testing, more specifically penetration testing, is an activity that requires high levels of expertise and involves many manual testing and analysis steps. This paper explores the potential usage of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners. We explore the feasibility of supplementing penetration testers with AI models for two distinct use cases: high-level task planning for security testing assignments and low-level vulnerability hunting within a vulnerable virtual machine. For the latter, we implemented a closed-feedback loop between LLM-generated low-level actions with a vulnerable virtual machine (connected through SSH) and allowed the LLM to analyze the machine state for vulnerabilities and suggest concrete attack vectors which were automatically executed within the virtual machine. We discuss promising initial results, detail avenues for improvement, and close deliberating on the ethics of providi
    
[^36]: DoDo学习: 语言模型中用于检测针对公众人物的滥用的领域-人口转移

    DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for Detecting Abuse Targeted at Public Figures. (arXiv:2307.16811v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.16811](http://arxiv.org/abs/2307.16811)

    该研究旨在通过探索跨领域和跨人口的文本分类动态，构建更通用的滥用分类器。研究发现，少量多样的数据对于模型的通用化和适应非常有益。

    

    公众人物在社交媒体上受到了不成比例的滥用，这对他们在公众生活中的积极参与产生了影响。自动化系统可以大规模识别滥用，但标记训练数据既昂贵又复杂，可能会造成伤害。因此，系统的高效性和通用性是可取的，可以处理在线滥用的共享和特定方面。我们探索交叉群体文本分类的动态，以了解训练在一个领域或人口统计上的分类器在其他领域或人口统计上的转移情况，从而构建更通用的滥用分类器。我们使用我们的创新DODO数据集，其中包含28,000个标记条目，在跨领域（体育和政治）和跨人口（女性和男性）的四个领域-人口对中，微调语言模型来分类针对公众人物的推文。我们发现，（i）少量多样的数据对通用化和模型适应非常有益；（ii）模型的转移更容易。

    Public figures receive a disproportionate amount of abuse on social media, impacting their active participation in public life. Automated systems can identify abuse at scale but labelling training data is expensive, complex and potentially harmful. So, it is desirable that systems are efficient and generalisable, handling both shared and specific aspects of online abuse. We explore the dynamics of cross-group text classification in order to understand how well classifiers trained on one domain or demographic can transfer to others, with a view to building more generalisable abuse classifiers. We fine-tune language models to classify tweets targeted at public figures across DOmains (sport and politics) and DemOgraphics (women and men) using our novel DODO dataset, containing 28,000 labelled entries, split equally across four domain-demographic pairs. We find that (i) small amounts of diverse data are hugely beneficial to generalisation and model adaptation; (ii) models transfer more eas
    
[^37]: RLCD: 基于对比蒸馏的强化学习用于语言模型对齐

    RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment. (arXiv:2307.12950v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12950](http://arxiv.org/abs/2307.12950)

    RLCD是一种用于语言模型对齐的强化学习方法，利用对比蒸馏训练偏好模型，可以使语言模型在不使用人类反馈的情况下遵循自然语言规则。在多个对齐任务和不同规模的模型上，RLCD优于其他基线方法。

    

    我们提出了一种称为Reinforcement Learning from Contrast Distillation (RLCD)的方法，用于无需使用人类反馈即可使语言模型遵循自然语言规则的对齐。RLCD使用模拟的偏好对进行训练，这些对包含了高质量和低质量的示例，其中使用对比的正负提示生成。然后，使用偏好模型通过强化学习来改进基础的无对齐语言模型。在实证上，RLCD在三个不同的对齐任务（无害性、有用性和故事大纲生成）以及7B和30B模型规模的偏好数据模拟上，都优于RLAIF (Bai等人，2022b)和上下文蒸馏 (Huang等人，2022) 的基准方法。

    We propose Reinforcement Learning from Contrast Distillation (RLCD), a method for aligning language models to follow natural language principles without using human feedback. RLCD trains a preference model using simulated preference pairs that contain both a high-quality and low-quality example, generated using contrasting positive and negative prompts. The preference model is then used to improve a base unaligned language model via reinforcement learning. Empirically, RLCD outperforms RLAIF (Bai et al., 2022b) and context distillation (Huang et al., 2022) baselines across three diverse alignment tasks--harmlessness, helpfulness, and story outline generation--and on both 7B and 30B model scales for preference data simulation.
    
[^38]: 探讨自然语言处理研究领域的发展趋势

    Exploring the Landscape of Natural Language Processing Research. (arXiv:2307.10652v1 [cs.CL])

    [http://arxiv.org/abs/2307.10652](http://arxiv.org/abs/2307.10652)

    该论文系统分类和分析了ACL Anthology中的研究论文，提供了对研究领域的结构化概述和NLP领域的分类学。本研究总结了最新的NLP发展，并提出了未来工作的方向。

    

    自然语言处理(NLP)作为理解、生成和处理自然语言文本的一种高效方法，在近年来得到了快速传播和广泛应用。鉴于该领域研究工作的不断增加，研究界已对数个与NLP相关的方法进行了调查。然而，到目前为止，仍缺少一项全面的研究，对已建立的主题进行分类、识别趋势并概括未来研究方向。为填补这一空白，我们对ACL Anthology中包含的研究论文进行了系统分类和分析。结果呈现了研究领域的结构化概述，为NLP领域的研究提供了一个分类学，分析了NLP的最新发展，总结了我们的研究发现，并突出了未来工作的方向。

    As an efficient approach to understand, generate, and process natural language texts, research in natural language processing (NLP) has exhibited a rapid spread and wide adoption in recent years. Given the increasing amount of research work in this area, several NLP-related approaches have been surveyed in the research community. However, a comprehensive study that categorizes established topics, identifies trends, and outlines areas for future research remains absent to this day. Contributing to closing this gap, we have systematically classified and analyzed research papers included in the ACL Anthology. As a result, we present a structured overview of the research landscape, provide a taxonomy of fields-of-study in NLP, analyze recent developments in NLP, summarize our findings, and highlight directions for future work.
    
[^39]: 高效的LLM引导生成

    Efficient Guided Generation for LLMs. (arXiv:2307.09702v1 [cs.CL])

    [http://arxiv.org/abs/2307.09702](http://arxiv.org/abs/2307.09702)

    本文描述了一种使用正则表达式和上下文无关文法来引导语言模型文本生成的高效方法。

    

    在本文中，我们描述了一种使用正则表达式和上下文无关文法来引导语言模型文本生成的高效方法。我们的方法在标记序列生成过程中几乎不增加任何开销，并使得引导生成在实际中可行。在开源Python库Outlines中提供了一个实现。

    In this article we describe an efficient approach to guiding language model text generation with regular expressions and context-free grammars. Our approach adds little to no overhead to the token sequence generation process, and makes guided generation feasible in practice. An implementation is provided in the open source Python library Outlines.
    
[^40]: 大型语言模型作为文化角度的叠加

    Large Language Models as Superpositions of Cultural Perspectives. (arXiv:2307.07870v1 [cs.CL])

    [http://arxiv.org/abs/2307.07870](http://arxiv.org/abs/2307.07870)

    大型语言模型被认为是具有个性或一套价值观的，但实际上它可以看作是具有不同价值观和个性特征的角度的叠加。通过角度可控性的概念，我们研究了大型语言模型在不同角度下展示的价值观和个性特征的变化。实验结果表明，即使在没有明显提示的情况下，大型语言模型也会表达出不同的价值观。

    

    大型语言模型（LLMs）常常被错误地认为具有个性或一套价值观。我们认为LLMs可以看作是具有不同价值观和个性特征的角度叠加。LLMs表现出依赖于上下文的价值观和个性特征，这些特征基于产生的角度而改变（与人类相反，人类在不同情境下通常具有更一致的价值观和个性特征）。我们引入了“角度可控性”的概念，指的是模型采用不同具有不同价值观和个性特征的角度的能力。在我们的实验中，我们使用心理学问卷（PVQ、VSM、IPIP）来研究展示的价值观和个性特征如何基于不同角度而改变。通过定性实验，我们展示了当提示中（隐式或显式）暗示了某些价值观时，LLMs表达出不同的价值观，即使在没有明显暗示的情况下，LLMs也会表达出不同的价值观。

    Large Language Models (LLMs) are often misleadingly recognized as having a personality or a set of values. We argue that an LLM can be seen as a superposition of perspectives with different values and personality traits. LLMs exhibit context-dependent values and personality traits that change based on the induced perspective (as opposed to humans, who tend to have more coherent values and personality traits across contexts). We introduce the concept of perspective controllability, which refers to a model's affordance to adopt various perspectives with differing values and personality traits. In our experiments, we use questionnaires from psychology (PVQ, VSM, IPIP) to study how exhibited values and personality traits change based on different perspectives. Through qualitative experiments, we show that LLMs express different values when those are (implicitly or explicitly) implied in the prompt, and that LLMs express different values even when those are not obviously implied (demonstrat
    
[^41]: 使用适配器高效域自适应句子嵌入

    Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v1 [cs.CL])

    [http://arxiv.org/abs/2307.03104](http://arxiv.org/abs/2307.03104)

    本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。

    

    句子嵌入使我们能够捕捉短文本的语义相似性。大多数句子嵌入模型是针对一般语义文本相似性（STS）任务进行训练的。因此，要在特定领域中使用句子嵌入，必须将模型适应于该领域以获得良好的结果。通常，这是通过对感兴趣的域对整个句子嵌入模型进行微调来实现的。虽然这种方法能够产生最先进的结果，但在微调过程中更新了所有模型的权重，使该方法在资源上要求较高。因此，我们提出了训练轻量级适配器的方法，而不是单独为每个目标领域微调整个句子嵌入模型。这些特定领域的适配器不需要微调所有底层句子嵌入模型的参数。相反，我们只训练少量的额外参数，同时保持底层句子嵌入模型的权重不变。训练特定领域的适配器可以始终使用同一模型并在不同领域中获得良好的性能。

    Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always 
    
[^42]: 巨型语言模型时代的AutoML：当前挑战，未来机遇和风险。

    AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities and Risks. (arXiv:2306.08107v1 [cs.LG])

    [http://arxiv.org/abs/2306.08107](http://arxiv.org/abs/2306.08107)

    论文探讨了AutoML和LLMs之间的共生关系，并指出这两个领域的融合有望颠覆NLP和AutoML两个领域，同时也存在风险。

    

    在过去的几年中，自然语言处理（NLP）和自动化机器学习（AutoML）领域取得了显著的成果。特别是在NLP领域，巨型语言模型（LLMs）最近经历了一系列突破。我们设想，两个领域通过紧密的融合可以彼此推动极限。为了展示这一愿景，我们探索了AutoML和LLMs之间的共生关系潜力，着重探讨了它们如何互相受益。我们特别研究了从不同角度增强LLMs的AutoML方法的机会以及利用AutoML进一步改进LLMs的挑战。为此，我们调查了现有工作，并对其中的风险进行了批判性评估。我们坚信，两个领域的融合有可能颠覆NLP和AutoML两个领域。通过强调可想象的协同作用和风险，我们旨在促进在交叉点的进一步探索。

    The fields of both Natural Language Processing (NLP) and Automated Machine Learning (AutoML) have achieved remarkable results over the past years. In NLP, especially Large Language Models (LLMs) have experienced a rapid series of breakthroughs very recently. We envision that the two fields can radically push the boundaries of each other through tight integration. To showcase this vision, we explore the potential of a symbiotic relationship between AutoML and LLMs, shedding light on how they can benefit each other. In particular, we investigate both the opportunities to enhance AutoML approaches with LLMs from different perspectives and the challenges of leveraging AutoML to further improve LLMs. To this end, we survey existing work, and we critically assess risks. We strongly believe that the integration of the two fields has the potential to disrupt both fields, NLP and AutoML. By highlighting conceivable synergies, but also risks, we aim to foster further exploration at the intersect
    
[^43]: 语言变化中选择机制的可靠识别

    Reliable identification of selection mechanisms in language change. (arXiv:2305.15914v1 [cs.CL])

    [http://arxiv.org/abs/2305.15914](http://arxiv.org/abs/2305.15914)

    本文探究了语言变化中的选择机制，提出了一个可靠且可解释的方法来量化历史语言变化的特定实例中的选择强度。该方法被证明比以前应用过的方法更可靠。作者还展示了语音简单性优先于语法简单性，并说明了该方法也可以检测选择强度变化的时间点。

    

    语言变化是一种文化进化过程，其中语言变量的变异通过类似于突变、选择和遗传漂变的过程而频繁变化。本文应用最近引入的一种方法来对语料库数据进行分析，以量化历史语言变化的特定实例中的选择强度。我们首先在英语不规则动词的语境下证明了这种方法比以前应用过的类似方法更可靠和可解释。我们进一步扩展了这项研究，证明了在语音简单性与语法简单性冲突时，对语音简单性的偏好优先于对语法简单性的偏好。最后，针对西班牙的拼写改革，我们展示了该方法也可以检测选择强度变化的时间点，这是社会动机语言变化通常具有的特征。这些结果共同表明如何测试语言变化机制的假设。

    Language change is a cultural evolutionary process in which variants of linguistic variables change in frequency through processes analogous to mutation, selection and genetic drift. In this work, we apply a recently-introduced method to corpus data to quantify the strength of selection in specific instances of historical language change. We first demonstrate, in the context of English irregular verbs, that this method is more reliable and interpretable than similar methods that have previously been applied. We further extend this study to demonstrate that a bias towards phonological simplicity overrides that favouring grammatical simplicity when these are in conflict. Finally, with reference to Spanish spelling reforms, we show that the method can also detect points in time at which selection strengths change, a feature that is generically expected for socially-motivated language change. Together, these results indicate how hypotheses for mechanisms of language change can be tested qu
    
[^44]: 从对话生成文本中降低说话者名称敏感度

    Reducing Sensitivity on Speaker Names for Text Generation from Dialogues. (arXiv:2305.13833v1 [cs.CL])

    [http://arxiv.org/abs/2305.13833](http://arxiv.org/abs/2305.13833)

    本文提出在对话生成文本中降低说话者名称敏感度的方法，通过定量测量模型敏感度并全面评估已知方法，得出了一种新方法的良好表现，为此问题提供了基准。

    

    在对话中始终保持说话者名称的一致性不应该影响到其含义以及对话生成的相应输出。然而，预训练的语言模型作为对话处理任务的主干已经显示出对微妙之处的敏感性。这可能会导致现实世界中的不公平。过去没有对这个问题进行全面的分析。在这项工作中，我们建议定量测量模型对说话者名称的敏感度，并全面评估许多已知的减少说话者名称敏感度的方法，包括我们自己的一种新方法。对多个数据集进行的广泛实验为此问题提供了基准，并展示了我们的方法在敏感度降低和生成质量方面的优异表现。

    Changing speaker names consistently throughout a dialogue should not affect its meaning and corresponding outputs for text generation from dialogues. However, pre-trained language models, serving as the backbone for dialogue-processing tasks, have shown to be sensitive to nuances. This may result in unfairness in real-world applications. No comprehensive analysis of this problem has been done in the past. In this work, we propose to quantitatively measure a model's sensitivity on speaker names, and comprehensively evaluate a number of known methods for reducing speaker name sensitivity, including a novel approach of our own. Extensive experiments on multiple datasets provide a benchmark for this problem and show the favorable performance of our approach in sensitivity reduction and quality of generation.
    
[^45]: MPI-rical：基于Transformer的数据驱动MPI分布式并行辅助

    MPI-rical: Data-Driven MPI Distributed Parallelism Assistance with Transformers. (arXiv:2305.09438v1 [cs.DC])

    [http://arxiv.org/abs/2305.09438](http://arxiv.org/abs/2305.09438)

    本文提出了一种基于Transformer模型的新方法MPI-rical，通过对大量代码片段进行训练实现自动化MPI代码生成，使并行化成为可能。

    

    在高性能计算中，将串行代码自动并行化以支持共享内存和分布式内存系统是一项具有挑战性的任务。虽然许多尝试将串行代码转换为共享内存环境的并行代码（通常使用OpenMP），但没有任何一项尝试成功将其转化为分布式内存环境。本文提出了一种称为MPI-rical的新方法，通过基于Transformer模型对大约25,000个串行代码片段及其对应的并行MPI代码进行训练，从我们的语料库（MPICodeCorpus）的50,000多个代码片段中生成自动化MPI代码。为了评估模型的性能，我们首先将串行代码转换为基于MPI的并行代码翻译问题分解为两个子问题，并制定两个研究目标：代码补全，即在给定源代码中的某个位置，预测该位置的MPI函数；代码翻译，即预测一个MPI函数。

    Automatic source-to-source parallelization of serial code for shared and distributed memory systems is a challenging task in high-performance computing. While many attempts were made to translate serial code into parallel code for a shared memory environment (usually using OpenMP), none has managed to do so for a distributed memory environment. In this paper, we propose a novel approach, called MPI-rical, for automated MPI code generation using a transformer-based model trained on approximately 25,000 serial code snippets and their corresponding parallelized MPI code out of more than 50,000 code snippets in our corpus (MPICodeCorpus). To evaluate the performance of the model, we first break down the serial code to MPI-based parallel code translation problem into two sub-problems and develop two research objectives: code completion defined as given a location in the source code, predict the MPI function for that location, and code translation defined as predicting an MPI function as wel
    
[^46]: 大型语言模型：分析LLM的理论语言能力

    Large Linguistic Models: Analyzing theoretical linguistic abilities of LLMs. (arXiv:2305.00948v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.00948](http://arxiv.org/abs/2305.00948)

    本研究展示了大型语言模型(LLMs)在语言任务上性能不断提高，且首次展示了它们能够生成连贯和有效的语言数据分析。分析和评估它们的元语言能力有助于我们理解它们的一般能力并对语言学理论模型提供新的认识。

    

    大型语言模型(LLMs)的性能最近已经提高到了能够在许多语言任务上表现良好的程度。我们在这里展示了，这些模型也可以生成连贯和有效的语言数据的形式分析，展示了大型语言模型对其元语言能力分析的巨大潜力。LLMs主要是通过文本形式的语言数据进行训练；分析和评估它们的元语言能力改进了我们对它们的一般能力的理解，并对语言学中的理论模型提供了新的认识。在本文中，我们通过专注于形式语言学的三个子领域：句法、音韵学和语义学，探究了GPT-4的元语言能力。我们提出了一个关于大型语言模型元语言分析的研究计划，提出了实验设计，提供了一般指导方针，讨论了限制，并为这个研究方向提供了未来的方向。这个研究还有助于揭示大型语言模型的潜在能力和理论模型的新视角。

    The performance of large language models (LLMs) has recently improved to the point where the models can perform well on many language tasks. We show here that for the first time, the models can also generate coherent and valid formal analyses of linguistic data and illustrate the vast potential of large language models for analyses of their metalinguistic abilities. LLMs are primarily trained on language data in the form of text; analyzing and evaluating their metalinguistic abilities improves our understanding of their general capabilities and sheds new light on theoretical models in linguistics. In this paper, we probe into GPT-4's metalinguistic capabilities by focusing on three subfields of formal linguistics: syntax, phonology, and semantics. We outline a research program for metalinguistic analyses of large language models, propose experimental designs, provide general guidelines, discuss limitations, and offer future directions for this line of research. This line of inquiry als
    
[^47]: 基于ChatGPT-4的ACR放射肿瘤内科（TXIT）考试和Red Journal Gray Zone案例的基准测试：AI辅助医学教育和放射肿瘤治疗决策的潜力与挑战

    Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology. (arXiv:2304.11957v2 [physics.med-ph] UPDATED)

    [http://arxiv.org/abs/2304.11957](http://arxiv.org/abs/2304.11957)

    本研究评估了ChatGPT-4在放射肿瘤学方面的表现，成绩显示出它在医学考试上有很大的优势，在实际应用中存在局限性。另外，ChatGPT-4 在放射肿瘤学上表现出色，但在骨骼和软组织以及妇科方面有待改进。

    

    大型语言模型在医学上的教育和决策方面的潜力已经得到证明，因为它们在美国医学许可考试（USMLE）和MedQA考试等医学考试中取得了不错的成绩。本研究评估了ChatGPT-4在放射肿瘤学专业领域的表现，使用了第38届美国放射学院（ACR）放射肿瘤内科（TXIT）考试和2022年的Red Journal Gray Zone案例。基于TXIT考试，ChatGPT-4在放射肿瘤学方面表现出色，但在ACR知识领域中的骨骼和软组织以及妇科方面存在局限性。在临床路径方面，ChatGPT-4在2022年的Red Journal Gray Zone案例中表现较好，具有70.65％的准确率。本研究展示了使用大型语言模型（例如ChatGPT-4）进行放射肿瘤学AI辅助医学教育和决策制定的潜力和挑战。

    The potential of large language models in medicine for education and decision making purposes has been demonstrated as they achieve decent scores on medical exams such as the United States Medical Licensing Exam (USMLE) and the MedQA exam. In this work, we evaluate the performance of ChatGPT-4 in the specialized field of radiation oncology using the 38th American College of Radiology (ACR) radiation oncology in-training (TXIT) exam and the 2022 red journal gray zone cases. For the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of 63.65% and 74.57%, respectively, highlighting the advantage of the latest ChatGPT-4 model. Based on the TXIT exam, ChatGPT-4's strong and weak areas in radiation oncology are identified to some extent. Specifically, ChatGPT-4 demonstrates good knowledge of statistics, CNS & eye, pediatrics, biology, and physics but has limitations in bone & soft tissue and gynecology, as per the ACR knowledge domain. Regarding clinical care paths, ChatGPT-4 perf
    
[^48]: 支持人工智能协作审计LLM的LLM

    Supporting Human-AI Collaboration in Auditing LLMs with LLMs. (arXiv:2304.09991v1 [cs.HC])

    [http://arxiv.org/abs/2304.09991](http://arxiv.org/abs/2304.09991)

    本论文通过对安全和公正人工智能专家的采访以及对人工智能协作和感知文献的研究，增强了“AdaTest”审计工具，这个工具可以通过利用人和生成模型的协同优势，进行更严格的大型语言模型审计。

    

    大型语言模型通过部署在社会技术系统中变得越来越普遍和普及。然而，这些语言模型，无论是用于分类还是生成，都表现出有偏差和不负责任的行为，对人类造成了规模性的伤害。因此，对这些语言模型进行严格审计至关重要。现有的审计工具利用人和或AI来发现失败。在这项工作中，我们借鉴了人工智能协作和感知的文献，并采访了安全和公正人工智能的研究专家，以增强审计工具“AdaTest”（Ribeiro和Lundberg，2022），该工具由生成大型语言模型（LLM）驱动。通过设计过程，我们强调了感知和人工智能通信在协作审计中利用人与生成模型的互补优势的重要性。为了评估增强工具AdaTest ++的有效性，我们进行了用户研究，使参与者进行审计

    Large language models are becoming increasingly pervasive and ubiquitous in society via deployment in sociotechnical systems. Yet these language models, be it for classification or generation, have been shown to be biased and behave irresponsibly, causing harm to people at scale. It is crucial to audit these language models rigorously. Existing auditing tools leverage either or both humans and AI to find failures. In this work, we draw upon literature in human-AI collaboration and sensemaking, and conduct interviews with research experts in safe and fair AI, to build upon the auditing tool: AdaTest (Ribeiro and Lundberg, 2022), which is powered by a generative large language model (LLM). Through the design process we highlight the importance of sensemaking and human-AI communication to leverage complementary strengths of humans and generative models in collaborative auditing. To evaluate the effectiveness of the augmented tool, AdaTest++, we conduct user studies with participants audit
    
[^49]: 零样本组合图像检索与文本反转

    Zero-Shot Composed Image Retrieval with Textual Inversion. (arXiv:2303.15247v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15247](http://arxiv.org/abs/2303.15247)

    提出了零样本组合图像检索任务(ZS-CIR)，通过将视觉特征映射到CLIP令牌嵌入空间中的伪词标记并与相对标题集成，解决了不需要标记训练数据集的组合图像检索问题。引入了名为CIRCO的开放域基准数据集，该数据集是第一个包含每个查询的多个真实答案的CIR数据集。实验结果表明，SEARLE具有更好的性能。

    

    组合图像检索(CIR)旨在根据由参考图像和描述两个图像之间差异的相对标题组成的查询来检索目标图像。标记CIR数据集所需的高工作量和成本阻碍了现有方法的广泛使用，因为它们依赖于监督学习。在这项工作中，我们提出了一个新的任务，零样本CIR (ZS-CIR)，旨在解决在不需要标记训练数据集的情况下进行CIR。我们的方法名为零样本组合图像检索与文本反转(SEARLE)，它将参考图像的视觉特征映射到CLIP令牌嵌入空间中的伪词标记，并将其与相对标题集成。为了支持ZS-CIR的研究，我们引入了一个名为“共同对象环境中的组合图像检索”(CIRCO)的开放域基准数据集，这是第一个包含每个查询的多个真实答案的CIR数据集。实验表明，SEARLE具有更好的性能。

    Composed Image Retrieval (CIR) aims to retrieve a target image based on a query composed of a reference image and a relative caption that describes the difference between the two images. The high effort and cost required for labeling datasets for CIR hamper the widespread usage of existing methods, as they rely on supervised learning. In this work, we propose a new task, Zero-Shot CIR (ZS-CIR), that aims to address CIR without requiring a labeled training dataset. Our approach, named zero-Shot composEd imAge Retrieval with textuaL invErsion (SEARLE), maps the visual features of the reference image into a pseudo-word token in CLIP token embedding space and integrates it with the relative caption. To support research on ZS-CIR, we introduce an open-domain benchmarking dataset named Composed Image Retrieval on Common Objects in context (CIRCO), which is the first dataset for CIR containing multiple ground truths for each query. The experiments show that SEARLE exhibits better performance 
    
[^50]: ICL-D3IE：上下文学习+多样展示更新，用于文档信息抽取（arXiv:2303.05063v2 [cs.CL] UPDATED）

    ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction. (arXiv:2303.05063v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.05063](http://arxiv.org/abs/2303.05063)

    这篇论文提出了一个简单而有效的上下文学习框架ICL-D3IE，这个框架使LLM在不同类型演示下的DIE任务中表现出色，具有改进性能的反馈机制，同时涵盖了位置和格式方面的演示示例。

    

    大型语言模型（LLM）如GPT-3和ChatGPT在各种自然语言处理（NLP）任务中展示了卓越的成果，尤其是应用于上下文学习，即基于少量演示示例进行推理。尽管在NLP任务中取得了成功，但尚未进行研究以评估LLM在使用上下文学习执行文档信息抽取（DIE）的能力。应用LLM执行DIE存在两个挑战：模态和任务差距。为此，我们提出了一种简单而有效的上下文学习框架ICL-D3IE，它使LLM能够使用不同类型的演示示例执行DIE。具体而言，我们从难以训练的文档中提取最困难和最不同的片段作为演示示例，以便受益于所有测试实例。我们设计了描述关系的演示示例，使LLM能够理解位置关系。我们引入了格式化演示示例，以方便提取答案。此外，我们采用了反馈机制，更新了演示示例，以进一步提高ICL-D3IE的性能。

    Large language models (LLMs), such as GPT-3 and ChatGPT, have demonstrated remarkable results in various natural language processing (NLP) tasks with in-context learning, which involves inference based on a few demonstration examples. Despite their successes in NLP tasks, no investigation has been conducted to assess the ability of LLMs to perform document information extraction (DIE) using in-context learning. Applying LLMs to DIE poses two challenges: the modality and task gap. To this end, we propose a simple but effective in-context learning framework called ICL-D3IE, which enables LLMs to perform DIE with different types of demonstration examples. Specifically, we extract the most difficult and distinct segments from hard training documents as hard demonstrations for benefiting all test instances. We design demonstrations describing relationships that enable LLMs to understand positional relationships. We introduce formatting demonstrations for easy answer extraction. Additionally
    
[^51]: 语言特定的情绪概念知识表示对情绪推断的因果支持

    Language-Specific Representation of Emotion-Concept Knowledge Causally Supports Emotion Inference. (arXiv:2302.09582v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09582](http://arxiv.org/abs/2302.09582)

    本研究通过操纵大型语言模型中的语言衍生的情绪概念知识表示，探讨了语言是否会因果支持情绪推断。实验结果显示，属性特定的神经元操纵导致情绪推断任务的性能下降，这与人类心理空间中不同属性的重要性有关。这些发现为支持基于语言的情绪推断机制提供了因果证据，并凸显了情绪概念知识的贡献。

    

    在情绪科学中，如何理解语言支持情绪推断仍然是一个争议的话题。本研究通过操纵大型语言模型中的语言衍生的情绪概念知识表示，调查了语言是否会因果支持情绪推断。使用提示技术，发现了14个情绪概念的属性由不同的人工神经元群体表示。通过操纵这些属性相关的神经元，与随机操纵相比，大多数情绪推断任务的表现出现了下降。属性特定的表现下降与人类心理空间中不同属性的重要性有关。我们的发现提供了支持基于语言的情绪推断机制的因果证据，并强调了情绪概念知识的贡献。

    Understanding how language supports emotion inference remains a topic of debate in emotion science. The present study investigated whether language-derived emotion-concept knowledge would causally support emotion inference by manipulating the language-specific knowledge representations in large language models. Using the prompt technique, 14 attributes of emotion concepts were found to be represented by distinct artificial neuron populations. By manipulating these attribute-related neurons, the majority of the emotion inference tasks showed performance deterioration compared to random manipulations. The attribute-specific performance deterioration was related to the importance of different attributes in human mental space. Our findings provide causal evidence in support of a language-based mechanism for emotion inference and highlight the contributions of emotion-concept knowledge.
    
[^52]: 使用Transformer和相似度度量改进阿拉伯文本分类的数据增强

    Data Augmentation using Transformers and Similarity Measures for Improving Arabic Text Classification. (arXiv:2212.13939v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.13939](http://arxiv.org/abs/2212.13939)

    本论文提出一种使用Transformer和相似度度量进行数据增强的方法，以改进阿拉伯文本分类，该方法利用AraGPT-2进行增强，并使用Euclidean、cosine、Jaccard和BLEU距离评估生成的句子。

    

    学习模型的性能很大程度上依赖于训练数据的可用性和充足性。为了解决数据集充足性问题，研究人员广泛探索了数据增强（DA）作为一种有前景的方法。DA通过对现有数据应用转换来生成新的数据实例，从而增加数据集的大小和变化性。这种方法提高了模型的性能和准确性，尤其是在解决分类任务中的类别不平衡问题方面。然而，很少有研究探讨阿拉伯语的DA，而是依赖于传统的方法，如释义或基于噪声的技术。在本文中，我们提出了一种新的阿拉伯语DA方法，采用了最近强大的建模技术AraGPT-2来进行增强过程。利用欧氏距离、余弦距离、Jaccard距离和BLEU距离对生成的句子进行了上下文、语义、多样性和新颖性的评估。最后，使用AraBERT transformer对情感进行了预测。

    The performance of learning models heavily relies on the availability and adequacy of training data. To address the dataset adequacy issue, researchers have extensively explored data augmentation (DA) as a promising approach. DA generates new data instances through transformations applied to the available data, thereby increasing dataset size and variability. This approach has enhanced model performance and accuracy, particularly in addressing class imbalance problems in classification tasks. However, few studies have explored DA for the Arabic language, relying on traditional approaches such as paraphrasing or noising-based techniques. In this paper, we propose a new Arabic DA method that employs the recent powerful modeling technique, namely the AraGPT-2, for the augmentation process. The generated sentences are evaluated in terms of context, semantics, diversity, and novelty using the Euclidean, cosine, Jaccard, and BLEU distances. Finally, the AraBERT transformer is used on sentime
    
[^53]: 基于联邦学习的移动自然语言处理中的少样本学习

    Federated Few-Shot Learning for Mobile NLP. (arXiv:2212.05974v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.05974](http://arxiv.org/abs/2212.05974)

    本研究首次探索了联邦学习在移动少样本自然语言处理中的应用，通过使用伪标签和提示学习算法，实现了仅有少量标记数据时的竞争性准确性。同时，通过创新的设计解决了高执行成本的问题。

    

    自然语言处理（NLP）在移动应用中得到广泛应用。为了支持各种语言理解任务，通常需要在联邦隐私保护环境中对基础NLP模型进行微调。这个过程通常依赖于至少数十万个来自移动客户端的带标签训练样本；然而移动用户通常缺乏标记数据的意愿或知识。这种数据标签的不足被称为少样本场景，它成为移动NLP应用的主要障碍。本研究首次探究了少样本场景下的联邦NLP（FedFSL）。通过结合伪标签和提示学习等算法进展，我们首先建立了一个训练流程，在仅有0.05%（少于100个）的训练数据被标记，其余数据未标记的情况下，实现了竞争性的准确性。为了具体实施这个工作流程，我们进一步提出了一个名为FeS的系统，通过创新设计解决了高执行成本的问题。其中包括课程进度控制，目标网络和验证器网络的结构等方面的创新。

    Natural language processing (NLP) sees rich mobile applications. To support various language understanding tasks, a foundation NLP model is often fine-tuned in a federated, privacy-preserving setting (FL). This process currently relies on at least hundreds of thousands of labeled training samples from mobile clients; yet mobile users often lack willingness or knowledge to label their data. Such an inadequacy of data labels is known as a few-shot scenario; it becomes the key blocker for mobile NLP applications.  For the first time, this work investigates federated NLP in the few-shot scenario (FedFSL). By retrofitting algorithmic advances of pseudo labeling and prompt learning, we first establish a training pipeline that delivers competitive accuracy when only 0.05% (fewer than 100) of the training data is labeled and the remaining is unlabeled. To instantiate the workflow, we further present a system FeS, addressing the high execution cost with novel designs. (1) Curriculum pacing, whi
    
[^54]: 迈向实用的少样本联邦自然语言处理

    Towards Practical Few-shot Federated NLP. (arXiv:2212.00192v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.00192](http://arxiv.org/abs/2212.00192)

    本论文介绍了一个用于处理联邦自然语言处理中少样本问题的方法，通过引入数据生成器和基于提示的联邦学习系统，能够在有限的标记数据下实现与完整微调相媲美的性能。然而，这种性能要求付出显著的系统成本。

    

    基于Transformer的预训练模型已成为自然语言处理(NLP)的主流解决方案。为了在下游任务中对这些预训练模型进行微调，通常需要大量标注的私有数据。实际上，私有数据通常分布在异构的移动设备上，并且可能被禁止上传。此外，精心策划的标记数据通常很稀缺，这增加了另一个挑战。为了解决这些问题，我们首先引入了一个用于联邦少样本学习任务的数据生成器，它模拟了现实情况下稀缺标记数据的数量和偏斜性。随后，我们提出了AUG-FedPrompt，这是一个基于提示的联邦学习系统，利用大量无标签数据进行数据增强。我们的实验证明，在有限量的标记数据下，AUG-FedPrompt能够与完整微调相媲美。然而，这种竞争性能是以显著的系统成本为代价的。

    Transformer-based pre-trained models have emerged as the predominant solution for natural language processing (NLP). Fine-tuning such pre-trained models for downstream tasks often requires a considerable amount of labeled private data. In practice, private data is often distributed across heterogeneous mobile devices and may be prohibited from being uploaded. Moreover, well-curated labeled data is often scarce, presenting an additional challenge. To address these challenges, we first introduce a data generator for federated few-shot learning tasks, which encompasses the quantity and skewness of scarce labeled data in a realistic setting. Subsequently, we propose AUG-FedPrompt, a prompt-based federated learning system that exploits abundant unlabeled data for data augmentation. Our experiments indicate that AUG-FedPrompt can perform on par with full-set fine-tuning with a limited amount of labeled data. However, such competitive performance comes at a significant system cost.
    
[^55]: 我竟然没有图片了！仅使用语言数据学习视觉任务

    I Can't Believe There's No Images! Learning Visual Tasks Using only Language Data. (arXiv:2211.09778v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.09778](http://arxiv.org/abs/2211.09778)

    本文研究了通过利用对比训练的视觉和语言编码器的联合嵌入空间，并仅使用文本训练数据，在没有对视觉训练数据进行训练的情况下完成四项代表性视觉任务。研究发现这些模型表现良好，具有一定的可迁移性。

    

    计算机视觉任务所需的许多高级技能，例如解析问题、比较和对比语义以及编写描述，也同样适用于其他领域，例如自然语言处理。本文探讨了是否可能从文本数据中学习这些技能，然后在没有对视觉训练数据进行训练的情况下将它们转移到视觉任务中。我们的方法的关键在于利用对比训练的视觉和语言编码器的联合嵌入空间。实践中，对比模型中不同模态的嵌入空间之间可能存在系统性差异，我们分析了这些差异如何影响我们的方法，并研究了缓解此问题的策略。我们使用仅 文本训练数据在四个代表性任务上生成模型：图像字幕、视觉蕴含、视觉问答和视觉新闻，并使用图像对标准基准进行评估。我们发现这些模型通常表现接近。

    Many high-level skills that are required for computer vision tasks, such as parsing questions, comparing and contrasting semantics, and writing descriptions, are also required in other domains such as natural language processing. In this paper, we ask whether it is possible to learn those skills from textual data and then transfer them to vision tasks without ever training on visual training data. Key to our approach is exploiting the joint embedding space of contrastively trained vision and language encoders. In practice, there can be systematic differences between embedding spaces for different modalities in contrastive models, and we analyze how these differences affect our approach and study strategies to mitigate this concern. We produce models using only text training data on four representative tasks: image captioning, visual entailment, visual question answering and visual news, and evaluate them on standard benchmarks using images. We find these models generally perform close 
    
[^56]: YATO: 另一个基于深度学习的文本分析开源工具包

    YATO: Yet Another deep learning based Text analysis Open toolkit. (arXiv:2209.13877v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.13877](http://arxiv.org/abs/2209.13877)

    YATO是一个轻量且易于使用的开源工具包，支持深度学习文本分析，可组合不同的特征类型，并提供灵活性和易用性的优势，促进了先进NLP模型的复现和改进，以及跨学科应用的推动。

    

    我们介绍了YATO，一个开源、易于使用的用于深度学习文本分析的工具包。与现有的重度工程化工具包和平台不同，YATO轻量且用户友好，适用于跨学科领域的研究人员。YATO设计成分层结构，支持自由组合三种广泛使用的特征类型，包括1）传统神经网络（CNN，RNN等）；2）预训练语言模型（BERT，RoBERTa，ELECTRA等）；和3）通过简单可配置的文件实现的用户定制化神经特征。由于灵活性和易用性的优势，YATO可以促进快速复现和改进先进的自然语言处理模型，并推动自然语言处理技术在跨学科领域的应用。代码、示例和文档可在https://github.com/jiesutd/YATO公开获取。还提供了演示视频https://youtu.be/tSjjf5BzfQg。

    We introduce YATO, an open-source, easy-to-use toolkit for text analysis with deep learning. Different from existing heavily engineered toolkits and platforms, YATO is lightweight and user-friendly for researchers from cross-disciplinary areas. Designed in a hierarchical structure, YATO supports free combinations of three types of widely used features including 1) traditional neural networks (CNN, RNN, etc.); 2) pre-trained language models (BERT, RoBERTa, ELECTRA, etc.); and 3) user-customized neural features via a simple configurable file. Benefiting from the advantages of flexibility and ease of use, YATO can facilitate fast reproduction and refinement of state-of-the-art NLP models, and promote the cross-disciplinary applications of NLP techniques. The code, examples, and documentation are publicly available at https://github.com/jiesutd/YATO. A demo video is also available at https://youtu.be/tSjjf5BzfQg.
    
[^57]: PreSTU: 场景文本理解的预训练方法

    PreSTU: Pre-Training for Scene-Text Understanding. (arXiv:2209.05534v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.05534](http://arxiv.org/abs/2209.05534)

    PreSTU是一种针对场景文本理解的预训练方法，通过引入OCR感知的预训练目标，可以提高模型对于图像中嵌入文本的识别和连接能力，并在多个视觉问答和图像字幕基准上展示了其有效性。

    

    在视觉与语言模型中，对于嵌入在视觉输入中的文本进行识别和推理的能力通常是缺乏的，可能是因为视觉与语言的预训练方法在其训练目标中往往没有包括这种能力。在本文中，我们提出了一种名为PreSTU的新型预训练方法，专注于场景文本理解。PreSTU引入了OCR感知的预训练目标，鼓励模型识别图像中的文本并将其与图像的其他内容连接起来。我们使用基于transformer编码器-解码器架构和大规模图像文本数据集实现了PreSTU，其中的场景文本来自现成的OCR系统。我们通过在八个视觉问答和四个图像字幕基准上进行实证，验证了这种预训练方法的有效性。

    The ability to recognize and reason about text embedded in visual inputs is often lacking in vision-and-language (V&L) models, perhaps because V&L pre-training methods have often failed to include such an ability in their training objective. In this paper, we propose PreSTU, a novel pre-training recipe dedicated to scene-text understanding (STU). PreSTU introduces OCR-aware pre-training objectives that encourage the model to recognize text from an image and connect it to the rest of the image content. We implement PreSTU using a simple transformer-based encoder-decoder architecture, combined with large-scale image-text datasets with scene text obtained from an off-the-shelf OCR system. We empirically demonstrate the effectiveness of this pre-training approach on eight visual question answering and four image captioning benchmarks.
    
[^58]: 走向透明AI: 对深度神经网络内部结构的解释的调查

    Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.13243](http://arxiv.org/abs/2207.13243)

    这篇综述调查了深度神经网络内部结构内部解释方法，并提出了一种分析方法的分类。这些解释方法对于帮助构建更可信赖的AI是至关重要的。

    

    过去十年的机器学习取得了巨大的规模和能力的增长，深度神经网络(DNNs)越来越多地被部署在现实世界中。然而，它们很难分析，这引发了对在不彻底理解其工作原理的情况下使用它们的担忧。解释它们的有效工具将对构建更可信赖的AI非常重要，通过帮助识别问题、修复错误和增进基本理解。特别是，"内部"可解释性技术，它们专注于解释DNNs的内部组件，非常适合于开发机械理解、指导手动修改和逆向工程解决方案。最近的研究主要集中在DNN可解释性上，迅速取得的进展使得对方法进行彻底系统化的困难。在这篇调查中，我们回顾了300多篇作品，重点关注内部可解释性工具。我们引入了一种分类方法，将方法按网络的哪个部分进行分类。

    The last decade of machine learning has seen drastic increases in scale and capabilities. Deep neural networks (DNNs) are increasingly being deployed in the real world. However, they are difficult to analyze, raising concerns about using them without a rigorous understanding of how they function. Effective tools for interpreting them will be important for building more trustworthy AI by helping to identify problems, fix bugs, and improve basic understanding. In particular, "inner" interpretability techniques, which focus on explaining the internal components of DNNs, are well-suited for developing a mechanistic understanding, guiding manual modifications, and reverse engineering solutions.  Much recent work has focused on DNN interpretability, and rapid progress has thus far made a thorough systematization of methods difficult. In this survey, we review over 300 works with a focus on inner interpretability tools. We introduce a taxonomy that classifies methods by what part of the netwo
    
[^59]: 无监督双关节分析与共现线索的多模态单词发现

    Unsupervised Multimodal Word Discovery based on Double Articulation Analysis with Co-occurrence cues. (arXiv:2201.06786v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2201.06786](http://arxiv.org/abs/2201.06786)

    本研究提出了一种无监督学习方法，基于语音学信息和对象信息，用于从语音信号中发现单词和音素，并同时利用多种模态的对象信息。实验结果表明，该方法在单词发现性能上优于基线方法。

    

    人类婴儿在没有太多语言先验知识的情况下，通过声音分布的统计特性和其他感官刺激的共现来获取其语言词汇。本研究提出了一种基于语音学信息和对象信息的全新无监督学习方法，用于发现语音单元。该方法可以利用无监督学习从语音信号中获得单词和音素，并同时利用基于多种模态的对象信息，包括视觉、触觉和听觉。该方法基于非参数贝叶斯双关节分析器（NPB-DAA）从语音学特征中发现音素和单词，并且基于多模态潜在狄利克雷分配（MLDA）对从对象中获取的多模态信息进行分类。实验结果显示，该方法比基线方法具有更高的单词发现性能。表达了特性的单词包含了...

    Human infants acquire their verbal lexicon with minimal prior knowledge of language based on the statistical properties of phonological distributions and the co-occurrence of other sensory stimuli. This study proposes a novel fully unsupervised learning method for discovering speech units using phonological information as a distributional cue and object information as a co-occurrence cue. The proposed method can acquire words and phonemes from speech signals using unsupervised learning and utilize object information based on multiple modalities-vision, tactile, and auditory-simultaneously. The proposed method is based on the nonparametric Bayesian double articulation analyzer (NPB-DAA) discovering phonemes and words from phonological features, and multimodal latent Dirichlet allocation (MLDA) categorizing multimodal information obtained from objects. In an experiment, the proposed method showed higher word discovery performance than baseline methods. Words that expressed the characteri
    

