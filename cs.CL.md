# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Constructing Holistic Spatio-Temporal Scene Graph for Video Semantic Role Labeling.](http://arxiv.org/abs/2308.05081) | 本论文提出了一种全面的时空场景图表示来解决视频语义角色标注中细粒度空间语义和时间建模的问题，并设计了一个面向特定目标的VidSRL框架，通过场景-事件映射机制来改进性能。 |
| [^2] | [RadGraph2: Modeling Disease Progression in Radiology Reports via Hierarchical Information Extraction.](http://arxiv.org/abs/2308.05046) | RadGraph2是一个新的数据集，用于从放射学报告中提取信息，并以分层信息提取模型HGIE为基础，能够更好地捕捉疾病进展和关系提取任务中的发现。 |
| [^3] | [AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities.](http://arxiv.org/abs/2308.04992) | AspectMMKG是一个具有方面意识的多模态知识图谱，通过匹配图像和不同实体方面，它提供了从多个角度理解实体的能力，并在实体方面链接任务中取得了最先进的性能。 |
| [^4] | [Exploring Multilingual Text Data Distillation.](http://arxiv.org/abs/2308.04982) | 本论文提出了基于语言模型的学习方法，用于多语言文本分类数据集的数据提炼。通过实验分析，我们发现这些方法在分类强度和跨架构泛化方面的性能良好，并考虑了数据摘要的语言特定公平性。 |
| [^5] | [Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection.](http://arxiv.org/abs/2308.04950) | 该论文分析了基于Transformer模型的BERT、ALBERT和RoBERTa在假新闻检测中的性能。研究发现，Transformer模型（特别是BERT）在处理文本上表现优异，但不同研究对性能评估和结论的实现方法存在差异。 |
| [^6] | [Extrapolating Large Language Models to Non-English by Aligning Languages.](http://arxiv.org/abs/2308.04948) | 本文介绍了一种通过语义对齐来增强非英语语言模型的方法，并通过实验证明，该方法在跨语言任务中取得了显著的改进。同时，我们还发现在翻译数据中加入非英语文本可以有效提升模型能力，且LLM内部的语义对齐也可以进一步加强。 |
| [^7] | [LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking.](http://arxiv.org/abs/2308.04945) | LLMeBench是一个灵活的框架，用于加速LLMs基准测试。它可以定制任何NLP任务和模型，无论语言，支持零和少样本学习设置，并允许用户添加新的自定义数据集。已经在31个独特的NLP任务上进行了测试，并计划将框架开源。 |
| [^8] | [Integrating large language models and active inference to understand eye movements in reading and dyslexia.](http://arxiv.org/abs/2308.04941) | 该论文提出了一种集成大型语言模型和主动推理的计算模型，用于模拟阅读过程中的眼动行为。该模型能够准确地预测和推理不同粒度的文本信息，并能够模拟阅读障碍中不适应推理效果的情况。 |
| [^9] | [LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following.](http://arxiv.org/abs/2308.04913) | LLaMA-E是一种统一且定制的指导语言模型，旨在解决电子商务创作过程中遇到的各种任务，包括广告生成、查询增强的产品标题改写、产品分类、购买意图推测和常规问答。 |
| [^10] | [Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance.](http://arxiv.org/abs/2308.04886) | 提出了一种使用马氏距离进行无监督的方言识别方法，通过利用多任务学习从wav2vec 2.0变压器模型的中间层潜在嵌入中提取特征，实现了有效的离群样本检测，并在该问题上明显优于其他方法。 |
| [^11] | [Information-Theoretic Characterization of Vowel Harmony: A Cross-Linguistic Study on Word Lists.](http://arxiv.org/abs/2308.04885) | 通过计算建模，该跨语言研究利用信息论量化了元音和谐，并通过使用词根形式而不是屈折变形的词形进行模型训练，涵盖了更多未被研究的语言。实验证明，神经PLMs能够捕捉到存在元音和谐的语言中的和谐模式。 |
| [^12] | [Emotion-Conditioned Text Generation through Automatic Prompt Optimization.](http://arxiv.org/abs/2308.04857) | 本论文提出了一种通过自动提示优化的方法，用于情感条件文本生成。通过改变提示，我们的方法能够实现生成文本中条件变量的实现情况。这种方法经济高效且具有竞争力。 |
| [^13] | [TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks.](http://arxiv.org/abs/2308.04832) | 本文介绍了一种新的激活函数 TSSR，具有奇数、非线性、单调和可微分的特性。实验证实了TSSR相比其他激活函数具有更好的性能，对神经网络模型的发展具有重要意义，并适用于多个领域的广泛应用。 |
| [^14] | [Evaluating the Generation Capabilities of Large Chinese Language Models.](http://arxiv.org/abs/2308.04823) | 本文首次对大型中文语言模型在多个学科领域的生成能力进行了全面评估，并提出了Gscore作为衡量生成结果质量的综合指数。 |
| [^15] | [CLEVA: Chinese Language Models EVAluation Platform.](http://arxiv.org/abs/2308.04813) | CLEVA是一个用于评估中文语言模型的用户友好平台，通过标准化工作流程、竞争排行榜和减少污染的策略，使用户能够轻松进行全面评估。 |
| [^16] | [A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge.](http://arxiv.org/abs/2308.04811) | 通过使用二分异构图(BHG)方法，我们提出了一种增强具有常识知识的情感推理能力的方法，该方法能够解决常见的知识注入方法的问题，并提供了更好的泛化能力和知识丰富度。 |
| [^17] | [ADMUS: A Progressive Question Answering Framework Adaptable to Multiple Knowledge Sources.](http://arxiv.org/abs/2308.04800) | ADMUS是一种渐进式的知识库问答框架，可以适应多种知识源，包括多语言、多种知识库和不同的问答数据集。它通过解耦知识库问答系统的架构，提供了一个与数据集无关的框架，实现了新数据集的无缝集成，并且成本极低。 |
| [^18] | [Automatically measuring speech fluency in people with aphasia: first achievements using read-speech data.](http://arxiv.org/abs/2308.04763) | 本研究首次使用朗读语音数据，评估了一种信号处理算法在自动测量失语症患者言语流利度方面的相关性。通过对比专业言语治疗师的评估结果，发现该算法可以有效地预测失语症患者的言语流利程度。 |
| [^19] | [Building Interpretable and Reliable Open Information Retriever for New Domains Overnight.](http://arxiv.org/abs/2308.04756) | 本论文提出了一种信息检索流程，通过使用实体/事件链接模型和查询分解模型，更准确地聚焦于查询的不同信息单元。这种流程在段落覆盖和命名准确性方面显著改进，同时也更具解释性和可靠性。 |
| [^20] | [Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning.](http://arxiv.org/abs/2308.04712) | 本研究通过利用预训练语言模型的探测和对比学习机制，在槽位归纳任务中，成功地诱导了槽位边界，并在两个NLU基准数据集上表现出与令牌级监督模型相当的性能，同时也能提供增强的槽位标签表示。 |
| [^21] | [Answering Unseen Questions With Smaller Language\\Models Using Rationale Generation and Dense Retrieval.](http://arxiv.org/abs/2308.04711) | 本论文提出了两种方法来改进在具有充分解释性背景下，使用较小语言模型回答训练中未见的挑战性短问题回答任务。第一种方法是使用理据生成和密集检索结合的方式，并通过理据排名模型进行评分和组合。第二种方法是使用增强检索训练数据集训练较小的推理模型，以利用长文本序列中的相关信息。 |
| [^22] | [A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology.](http://arxiv.org/abs/2308.04709) | 本研究比较了几个开源的大型语言模型（LLMs）和GPT-4、Claude 2在肾病学内科多项选择题考试方面的表现。这些模型在未来有潜力成为医学培训、医疗协助和患者交互的一部分。 |
| [^23] | [Generating News-Centric Crossword Puzzles As A Constraint Satisfaction and Optimization Problem.](http://arxiv.org/abs/2308.04688) | 本研究提出了一个约束满足和优化问题的框架，用于自动生成面向新闻的填字游戏。通过添加尽可能多的新闻衍生词汇，可以增强教育目的和人们对新闻的兴趣。 |
| [^24] | [Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA.](http://arxiv.org/abs/2308.04679) | 本论文研究了通过知识蒸馏将大型语言模型(LLMs)的推理能力转移到较小模型的可能性，提出了Sci-CoT框架，分离了生成理由和推理的过程。 |
| [^25] | [Sudowoodo: a Chinese Lyric Imitation System with Source Lyrics.](http://arxiv.org/abs/2308.04665) | Sudowoodo是一个中文歌词模仿系统，通过构建平行语料库和利用后处理模块来生成新的高质量歌词，实现了模仿源歌词的风格和内容。 |
| [^26] | [Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach.](http://arxiv.org/abs/2308.04645) | 本研究通过利用中古高地德语和现代德语的语言连续性和结构相似性，以及现有的现代德语树库资源，构建了一种适用于中古高地德语的短语结构分析器，无需依赖标注的MHG树库资源。 |
| [^27] | [A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation.](http://arxiv.org/abs/2308.04625) | 本研究比较了几种最近的句子嵌入方法在分析语义变化方面的一致性和有效性，并通过真实世界文本进行了评估。 |
| [^28] | [Benchmarking LLM powered Chatbots: Methods and Metrics.](http://arxiv.org/abs/2308.04624) | 本文提出了一种新型的E2E基准测试，用于评估由LLM驱动的聊天机器人的准确性和实用性，相比其他指标，该基准测试展现出更好的结果。 |
| [^29] | [Accelerating LLM Inference with Staged Speculative Decoding.](http://arxiv.org/abs/2308.04623) | 本文提出了一种新算法，分阶段推测解码，用于加速在小批量、设备上进行LLM推理。通过使用树形结构的批次重组和增加第二阶段的推测解码，将单批解码延迟降低了3.16倍，而输出质量保持完美。 |
| [^30] | [Shepherd: A Critic for Language Model Generation.](http://arxiv.org/abs/2308.04592) | Shepherd是一种专门用于评论和提出改进建议的语言模型，通过使用高质量的反馈数据集，它可以识别和修复不同的错误。与其他模型相比，在评估和人工评估中，Shepherd的性能表现更佳。 |
| [^31] | [Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias.](http://arxiv.org/abs/2308.04566) | 本论文针对机器阅读理解中的答案位置偏倚问题，提出了一种名为单句阅读器的新方法，该方法使用六种不同模型实现。实验证明，单句阅读器与传统训练集上训练的模型几乎具有相当的性能，有效解决了答案位置偏倚问题。 |
| [^32] | [Ahead of the Text: Leveraging Entity Preposition for Financial Relation Extraction.](http://arxiv.org/abs/2308.04534) | 本文在ACM KDF-SIGIR 2023竞赛中提出了一种利用实体介词进行财务关系提取的方法，在比赛中赢得了第一名。 |
| [^33] | [Who should I Collaborate with? A Comparative Study of Academia and Industry Research Collaboration in NLP.](http://arxiv.org/abs/2308.04524) | 本研究调查了学术界和工业界在自然语言处理（NLP）领域的合作对研究的影响。结果显示，学术界和工业界的合作出版物数量有增长趋势，并且这些出版物往往比仅由学术界产生的出版物具有更高的影响力。 |
| [^34] | [DisCoCat for Donkey Sentences.](http://arxiv.org/abs/2308.04519) | 这篇论文展示了如何在一个组合分布式意义模型中解析Donkey句子，并提出了一种类型逻辑语法和关系向量空间语义。 |
| [^35] | [Capturing Spectral and Long-term Contextual Information for Speech Emotion Recognition Using Deep Learning Techniques.](http://arxiv.org/abs/2308.04517) | 本研究提出了一种使用组合模型的方法，将图卷积网络（GCN）与HuBERT transformer相结合，以捕捉语音情感识别中的光谱和长期上下文信息。GCN利用图表示文本数据，捕捉长期上下文依赖和语义关系，而HuBERT利用自注意机制捕捉长距离依赖性和语音中的时间动态。结合这两个方法可以更有效地进行情感识别。 |
| [^36] | [Revisiting Disentanglement and Fusion on Modality and Context in Conversational Multimodal Emotion Recognition.](http://arxiv.org/abs/2308.04502) | 本研究重新审视对话多模态情感识别中的模态和上下文，提出了一种双层解缠机制来同时建模特征的多模态性和对话的语境化，以进一步提高任务性能。 |
| [^37] | [DialogRE^C+: An Extension of DialogRE to Investigate How Much Coreference Helps Relation Extraction in Dialogs.](http://arxiv.org/abs/2308.04498) | 本研究将核指代解决方案引入到对话关系抽取领域，并通过新的数据集DialogRE^C+进行评估。研究表明，通过高质量的核指代知识可以增强参数关系的推理能力，从而在提升DRE任务中起到积极作用。 |
| [^38] | [Changes in Policy Preferences in German Tweets during the COVID Pandemic.](http://arxiv.org/abs/2308.04444) | 这项研究提供了一种量化德国推特上COVID疫情期间政策偏好的方法，通过建立细粒度政治偏好的数据集，并使用文本分类模型进行分析，结果显示政治观点在疫情期间有所增加，研究还突出了不同政治类别的变化。 |
| [^39] | [OpinionConv: Conversational Product Search with Grounded Opinions.](http://arxiv.org/abs/2308.04226) | OpinionConv是第一个用于模拟销售对话的对话式AI，通过利用产品评论作为观点的丰富来源，实现了对话和决策中的真实性和信息基础。 |
| [^40] | [Towards Multiple References Era -- Addressing Data Leakage and Limited Reference Diversity in NLG Evaluation.](http://arxiv.org/abs/2308.03131) | 本论文提出了使用多个参考来增强匹配指标与人类评估之间的一致性。在WMT Metrics基准中，多参考F200spBLEU相对于传统的单参考方法准确率提高了7.2\%，超过了基于神经网络的BERTscore的3.9\%的准确率提高。此外，该方法还可以在很大程度上缓解大型语言模型中的数据泄漏问题。 |
| [^41] | [Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting.](http://arxiv.org/abs/2308.02582) | 该论文介绍了一种通过领域适应和最少到最多提示的方式实现文本到SQL的高效泛化的方法。通过离线抽样获取少量样本，并合成一个通用提示，避免了昂贵的测试时间样本检索，并通过自适应和分解的方法更好地处理跨领域和跨组合式的泛化。 |
| [^42] | [Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education.](http://arxiv.org/abs/2307.12267) | 本研究探索了在教育领域中，由人类和生成性语言模型协作编写的混合文本的AI内容检测方法，将其形式化为识别转换点的任务，以区分人类编写和AI生成的部分。 |
| [^43] | [Retentive Network: A Successor to Transformer for Large Language Models.](http://arxiv.org/abs/2307.08621) | Retentive Network（RetNet）作为大型语言模型的基础架构，实现了训练并行、低成本推理和良好的性能。通过并行、循环和分块循环三种计算范式，RetNet具有训练并行化、低成本推理和高效的长序列建模的特点。 |
| [^44] | [AutoHint: Automatic Prompt Optimization with Hint Generation.](http://arxiv.org/abs/2307.07415) | 本文介绍了AutoHint，一种用于大型语言模型的自动提示生成和优化的新框架。该方法通过从输入-输出演示中生成提示，并利用上下文学习和零样本学习的优点，优化原始提示，从而提高了大型语言模型在特定任务上的表现。 |
| [^45] | [A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media.](http://arxiv.org/abs/2307.06775) | 本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。 |
| [^46] | [Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models.](http://arxiv.org/abs/2307.06713) | 本文提出了一种使用大型语言模型进行文本分类的无监督校准方法，通过调整先验类别分布，实现在没有标记样本和仅少量领域内样本查询的情况下执行任务。 |
| [^47] | [Beyond the Obvious: Evaluating the Reasoning Ability In Real-life Scenarios of Language Models on Life Scapes Reasoning Benchmark~(LSR-Benchmark).](http://arxiv.org/abs/2307.05113) | 本论文介绍了一个新的数据集LSR-Benchmark，旨在评估语言模型在真实情境中的推理能力。结果显示，人类在这方面表现明显优于最先进的语言模型，说明机器学习模型在理解日常生活方面仍面临挑战。 |
| [^48] | [Knowing-how & Knowing-that: A New Task for Machine Reading Comprehension of User Manuals.](http://arxiv.org/abs/2306.04187) | 该论文提出了知道如何与知道什么的任务，要求模型回答关于用户手册的基本事实、流程，并解决一些不一致的问题。他们采用图(TARA)来联合表示步骤和事实，成功地解决了这个任务，并构建了一个注释数据集，以测试模型在回答实际问题方面的能力。 |
| [^49] | [AdversarialWord Dilution as Text Data Augmentation in Low-Resource Regime.](http://arxiv.org/abs/2305.09287) | 本文提出了一种对抗性词汇稀释方法，用于作为低资源情况下的文本数据增强方法，能够生成硬正例以有效地训练文本分类模型。 |
| [^50] | [AttentionViz: A Global View of Transformer Attention.](http://arxiv.org/abs/2305.03210) | 这篇论文介绍了AttentionViz，一种以联合嵌入为基础的交互式可视化工具，用于帮助研究人员理解Transformer中的自我注意机制。该方法使得可以全局分析多个输入序列的注意力模式，提高对模型的理解并通过多个应用场景和专家反馈提供新的交互见解。 |
| [^51] | [Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts.](http://arxiv.org/abs/2303.17408) | 使用语言增强Transformer编码器，并结合医学提示，将结构化、非结构化的临床数据投影到一个语言潜空间中，以实现更精确的医学干预持续时间估计。 |
| [^52] | [MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks.](http://arxiv.org/abs/2303.16839) | 提出了一种名为MaMMUT的简单模型，可以通过两步方法容纳对比和生成学习，并在联合训练不同的视觉语言任务时表现出很高的效力。 |
| [^53] | [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference.](http://arxiv.org/abs/2303.04673) | 本文研究了优化大规模语言模型生成推理的成本效益超参数，通过经济的超参数优化和基于成本的修剪，提出了EcoOptiGen框架，该框架在使用GPT-3.5/GPT-4模型的任务中表现出有效性。 |
| [^54] | [A Universal Question-Answering Platform for Knowledge Graphs.](http://arxiv.org/abs/2303.00595) | 本文提出了KGQAn，一个通用的问答系统，它无需针对每个目标知识图谱进行定制。通过新颖的形式化方法，将问题转换为中间的抽象表示，从而实现了将自然语言问题转换为SPARQL查询的目标。 |

# 详细

[^1]: 为视频语义角色标注构建全面的时空场景图

    Constructing Holistic Spatio-Temporal Scene Graph for Video Semantic Role Labeling. (arXiv:2308.05081v1 [cs.CV])

    [http://arxiv.org/abs/2308.05081](http://arxiv.org/abs/2308.05081)

    本论文提出了一种全面的时空场景图表示来解决视频语义角色标注中细粒度空间语义和时间建模的问题，并设计了一个面向特定目标的VidSRL框架，通过场景-事件映射机制来改进性能。

    

    视频语义角色标注(VidSRL)旨在通过识别预测-参数事件结构和事件之间的相互关系，从给定的视频中检测出显著的事件。尽管最近的努力已经提出了VidSRL的方法，但它们主要存在两个关键缺点，包括缺乏细粒度的空间场景感知和不足的视频时间建模。为了解决这个问题，本文基于现有的动态场景图结构，探索了一种新颖的全面的时空场景图(Holistic Spatio-Temporal Scene Graph)表示，很好地模拟了视频的细粒度空间语义和时间动态特性以进行VidSRL。在Holistic Spatio-Temporal Scene Graph的基础上，我们提出了一种面向特定目标的VidSRL框架。首先设计了一种场景-事件映射机制，以弥合底层场景结构与高级事件语义结构之间的差距，形成一个整体层次的场景-事件(ICE)图结构。我们进一步进行迭代操作以逐步改进VidSRL性能。

    Video Semantic Role Labeling (VidSRL) aims to detect the salient events from given videos, by recognizing the predict-argument event structures and the interrelationships between events. While recent endeavors have put forth methods for VidSRL, they can be mostly subject to two key drawbacks, including the lack of fine-grained spatial scene perception and the insufficiently modeling of video temporality. Towards this end, this work explores a novel holistic spatio-temporal scene graph (namely HostSG) representation based on the existing dynamic scene graph structures, which well model both the fine-grained spatial semantics and temporal dynamics of videos for VidSRL. Built upon the HostSG, we present a nichetargeting VidSRL framework. A scene-event mapping mechanism is first designed to bridge the gap between the underlying scene structure and the high-level event semantic structure, resulting in an overall hierarchical scene-event (termed ICE) graph structure. We further perform itera
    
[^2]: RadGraph2：通过分层信息提取建模放射学报告中的疾病进展

    RadGraph2: Modeling Disease Progression in Radiology Reports via Hierarchical Information Extraction. (arXiv:2308.05046v1 [cs.CL])

    [http://arxiv.org/abs/2308.05046](http://arxiv.org/abs/2308.05046)

    RadGraph2是一个新的数据集，用于从放射学报告中提取信息，并以分层信息提取模型HGIE为基础，能够更好地捕捉疾病进展和关系提取任务中的发现。

    

    我们提出了RadGraph2，这是一个新的数据集，用于从放射学报告中提取信息，重点是捕捉疾病状态和设备放置随时间的变化。我们引入了一个基于关系组织实体的分层模式，并展示了在训练过程中使用这种层次结构可以改善信息提取模型的性能。具体地，我们对DyGIE++框架进行了修改，得到了我们的模型HGIE，该模型在实体和关系提取任务中优于先前的模型。我们证明了RadGraph2使模型能够捕捉更广泛的发现，并在关系提取方面表现优于那些在原始RadGraph数据集上训练的模型。我们的工作奠定了在医学领域开发可以跟踪疾病进展并利用标签的自然分层的信息提取模型的自动化系统的基础。

    We present RadGraph2, a novel dataset for extracting information from radiology reports that focuses on capturing changes in disease state and device placement over time. We introduce a hierarchical schema that organizes entities based on their relationships and show that using this hierarchy during training improves the performance of an information extraction model. Specifically, we propose a modification to the DyGIE++ framework, resulting in our model HGIE, which outperforms previous models in entity and relation extraction tasks. We demonstrate that RadGraph2 enables models to capture a wider variety of findings and perform better at relation extraction compared to those trained on the original RadGraph dataset. Our work provides the foundation for developing automated systems that can track disease progression over time and develop information extraction models that leverage the natural hierarchy of labels in the medical domain.
    
[^3]: AspectMMKG: 一个具有方面意识的多模态知识图谱

    AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities. (arXiv:2308.04992v1 [cs.CL])

    [http://arxiv.org/abs/2308.04992](http://arxiv.org/abs/2308.04992)

    AspectMMKG是一个具有方面意识的多模态知识图谱，通过匹配图像和不同实体方面，它提供了从多个角度理解实体的能力，并在实体方面链接任务中取得了最先进的性能。

    

    多模态知识图谱（MMKG）结合不同的模态数据（例如文本和图像），以全面理解实体。尽管大规模MMKG的最近进展，但现有的MMKG忽视了实体的多方面性质，限制了从各种角度理解实体的能力。在本文中，我们构建了AspectMMKG，这是第一个具有与方面相关的图像的MMKG，通过将图像与不同的实体方面进行匹配。具体而言，我们从知识库中收集与方面相关的图像，并通过在线图像搜索引擎提取知识库中与方面相关的句子作为查询，以检索大量与方面相关的图像。最后，AspectMMKG包含2380个实体，18139个实体方面和645383个与方面相关的图像。我们展示了AspectMMKG在实体方面链接（EAL）下游任务中的可用性，并证明在AspectMMKG的帮助下，先前的EAL模型实现了新的最先进性能。

    Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text and image) for a comprehensive understanding of entities. Despite the recent progress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature of entities, limiting the ability to comprehend entities from various perspectives. In this paper, we construct AspectMMKG, the first MMKG with aspect-related images by matching images to different entity aspects. Specifically, we collect aspect-related images from a knowledge base, and further extract aspect-related sentences from the knowledge base as queries to retrieve a large number of aspect-related images via an online image search engine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and 645,383 aspect-related images. We demonstrate the usability of AspectMMKG in entity aspect linking (EAL) downstream task and show that previous EAL models achieve a new state-of-the-art performance with the help of AspectMMKG. To facilitate the
    
[^4]: 探索多语言文本数据提炼

    Exploring Multilingual Text Data Distillation. (arXiv:2308.04982v1 [cs.CL])

    [http://arxiv.org/abs/2308.04982](http://arxiv.org/abs/2308.04982)

    本论文提出了基于语言模型的学习方法，用于多语言文本分类数据集的数据提炼。通过实验分析，我们发现这些方法在分类强度和跨架构泛化方面的性能良好，并考虑了数据摘要的语言特定公平性。

    

    随着深度学习的兴起，大规模数据集和复杂模型已经成为常见的需求，需要大量的计算资源。为了解决这个问题，数据提炼技术应运而生，能够用更低的内存和时间要求快速训练模型。然而，在文本数据集上进行数据提炼并没有得到很好的研究，因为其离散性带来了挑战。此外，现有的数据集提炼方法通常难以泛化到新的架构上。在这篇论文中，我们提出了几种基于语言模型的学习方法，用于多语言文本分类数据集的数据提炼。我们进行了实验，分析了其在分类强度和跨架构泛化方面的性能。此外，我们还研究了这些方法生成的数据摘要的语言特定公平性。我们的方法建立在现有技术的基础上，增强了文本数据提炼中的跨架构泛化能力。

    With the rise of deep learning, large datasets and complex models have become common, requiring significant computing power. To address this, data distillation has emerged as a technique to quickly train models with lower memory and time requirements. However, data distillation on text-based datasets hasn't been explored much because of the challenges rising due to its discrete nature. Additionally, existing dataset distillation methods often struggle to generalize to new architectures. In the paper, we propose several data distillation techniques for multilingual text classification datasets using language-model-based learning methods. We conduct experiments to analyze their performance in terms of classification strength, and cross-architecture generalization. Furthermore, we investigate the language-specific fairness of the data summaries generated by these methods. Our approach builds upon existing techniques, enhancing cross-architecture generalization in the text data distillatio
    
[^5]: 基于Transformer模型（BERT，ALBERT和RoBERTa）在假新闻检测中的性能分析

    Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection. (arXiv:2308.04950v1 [cs.CL])

    [http://arxiv.org/abs/2308.04950](http://arxiv.org/abs/2308.04950)

    该论文分析了基于Transformer模型的BERT、ALBERT和RoBERTa在假新闻检测中的性能。研究发现，Transformer模型（特别是BERT）在处理文本上表现优异，但不同研究对性能评估和结论的实现方法存在差异。

    

    假新闻是一种媒体格式的虚假材料，但没有经过新闻机构的适当处理。这些虚假材料可能会激起或诽谤重要实体或个人，甚至可能是创作者的个人利益，给社会带来问题。由于领域知识有限和时间限制，区分假新闻和真新闻是具有挑战性的。根据调查，受到谣言和信息误导的三个地区最多的是万丹特区、雅加达特区和西爪哇。Transformer模型是指在自然语言处理中利用深度学习架构的一种人工智能（AI）方法。Transformer模型通过强大的注意机制并行处理文本，并生成丰富和上下文相关的词表示。先前的研究表明，一种名为BERT的Transformer模型在性能上优于非Transformer方法。然而，一些研究表明性能评估和结bonclusion的实现方法之间可能存在一定的差异。

    Fake news is fake material in a news media format but is not processed properly by news agencies. The fake material can provoke or defame significant entities or individuals or potentially even for the personal interests of the creators, causing problems for society. Distinguishing fake news and real news is challenging due to limited of domain knowledge and time constraints. According to the survey, the top three areas most exposed to hoaxes and misinformation by residents are in Banten, DKI Jakarta and West Java. The model of transformers is referring to an approach in the field of artificial intelligence (AI) in natural language processing utilizing the deep learning architectures. Transformers exercise a powerful attention mechanism to process text in parallel and produce rich and contextual word representations. A previous study indicates a superior performance of a transformer model known as BERT over and above non transformer approach. However, some studies suggest the performan
    
[^6]: 通过语言对齐将大型语言模型推广到非英语中

    Extrapolating Large Language Models to Non-English by Aligning Languages. (arXiv:2308.04948v1 [cs.CL])

    [http://arxiv.org/abs/2308.04948](http://arxiv.org/abs/2308.04948)

    本文介绍了一种通过语义对齐来增强非英语语言模型的方法，并通过实验证明，该方法在跨语言任务中取得了显著的改进。同时，我们还发现在翻译数据中加入非英语文本可以有效提升模型能力，且LLM内部的语义对齐也可以进一步加强。

    

    由于训练数据分布不均衡，大型语言模型（LLM）往往在语言能力上偏向英语。本文提出通过构建跨语言的语义对齐，来增强预训练的非英语语言模型的能力。我们使用翻译任务数据和跨语言通用任务数据对LLaMA进行指令调整，得到跨语言模型（x-LLaMA）。在跨语言基准XQUAD和MLQA上的实验结果表明，x-LLaMA模型在六种非英语语言上平均超过英语指令调整的模型（Alpaca）42.50%。在中文基准C-Eval上的进一步实验表明，x-LLaMA在中文人文任务上取得了显著改进，超过Alpaca 8.2%。此外，我们发现在翻译数据的目标端加入非英语文本可以有效提升非英语能力。另外，我们还发现LLM内部的语义对齐可以进一步加强。

    Due to the unbalanced training data distribution, the language ability of large language models (LLMs) is often biased towards English. In this paper, we propose to empower pre-trained LLMs on non-English languages by building semantic alignment across languages. We perform instruction-tuning on LLaMA with both translation task data and cross-lingual general task data to obtain cross-lingual models (x-LLaMA). Experiment results on cross-lingual benchmark XQUAD and MLQA show that x-LLaMA models outperform the English instruction-tuned counterpart (Alpaca) by 42.50% on average on six non-English languages. Further experiments on Chinese benchmark C-Eval show that x-LLaMA achieves significant improvement on Chinese humanities tasks, outperforming Alpaca by 8.2%. We also discover that incorporating non-English text on the target side of translation data is particularly effective for boosting non-English ability. Besides, we find that semantic alignment within LLM can be further strengthene
    
[^7]: LLMeBench：用于加速LLMs基准测试的灵活框架

    LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking. (arXiv:2308.04945v1 [cs.CL])

    [http://arxiv.org/abs/2308.04945](http://arxiv.org/abs/2308.04945)

    LLMeBench是一个灵活的框架，用于加速LLMs基准测试。它可以定制任何NLP任务和模型，无论语言，支持零和少样本学习设置，并允许用户添加新的自定义数据集。已经在31个独特的NLP任务上进行了测试，并计划将框架开源。

    

    最近大型语言模型（LLMs）的发展和成功使得需要评估它们在不同语言的各种NLP任务中的性能。尽管已经开发并公开了几个框架，但对于不同用户来说，它们对特定任务和数据集的定制能力通常很复杂。在这项研究中，我们引入了LLMeBench框架。最初是为了使用OpenAI的GPT和BLOOM模型评估阿拉伯语NLP任务而开发的；它可以无缝定制任何NLP任务和模型，无论语言如何。该框架还具有零和少样本学习设置。可以在不到10分钟内添加新的自定义数据集，并且用户可以使用自己的模型API密钥来评估当前任务。该框架已经在90个实验设置中使用53个公开可用数据集对31个独特的NLP任务进行了测试，涉及大约296K个数据点。我们计划将该框架开源供社区使用。

    The recent development and success of Large Language Models (LLMs) necessitate an evaluation of their performance across diverse NLP tasks in different languages. Although several frameworks have been developed and made publicly available, their customization capabilities for specific tasks and datasets are often complex for different users. In this study, we introduce the LLMeBench framework. Initially developed to evaluate Arabic NLP tasks using OpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task and model, regardless of language. The framework also features zero- and few-shot learning settings. A new custom dataset can be added in less than 10 minutes, and users can use their own model API keys to evaluate the task at hand. The developed framework has been already tested on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. We plan to open-source the framework for the community
    
[^8]: 集成大型语言模型和主动推理以理解阅读和阅读障碍中的眼动行为

    Integrating large language models and active inference to understand eye movements in reading and dyslexia. (arXiv:2308.04941v1 [q-bio.NC])

    [http://arxiv.org/abs/2308.04941](http://arxiv.org/abs/2308.04941)

    该论文提出了一种集成大型语言模型和主动推理的计算模型，用于模拟阅读过程中的眼动行为。该模型能够准确地预测和推理不同粒度的文本信息，并能够模拟阅读障碍中不适应推理效果的情况。

    

    我们提出了一种新颖的计算模型，采用层次化主动推理来模拟阅读和眼动行为。该模型将语言处理描述为对层次生成模型的推理，从音节到句子的不同粒度实现预测和推理。我们的方法结合了大型语言模型的优势，用于实现逼真的文本预测，以及主动推理用于引导眼动到信息丰富的文本信息，从而使得对预测进行测试成为可能。该模型能够熟练阅读已知和未知的单词和句子，并遵循阅读双路理论中的词汇和非词汇路径的区分。值得注意的是，我们的模型允许模拟阅读过程中对眼动行为产生不适应推理效果的情况，例如阅读障碍。为了模拟这种情况，我们在阅读过程中减弱了先验的贡献，导致不正确的推理和更加断片化的阅读。

    We present a novel computational model employing hierarchical active inference to simulate reading and eye movements. The model characterizes linguistic processing as inference over a hierarchical generative model, facilitating predictions and inferences at various levels of granularity, from syllables to sentences.  Our approach combines the strengths of large language models for realistic textual predictions and active inference for guiding eye movements to informative textual information, enabling the testing of predictions. The model exhibits proficiency in reading both known and unknown words and sentences, adhering to the distinction between lexical and nonlexical routes in dual-route theories of reading. Notably, our model permits the exploration of maladaptive inference effects on eye movements during reading, such as in dyslexia. To simulate this condition, we attenuate the contribution of priors during the reading process, leading to incorrect inferences and a more fragmented
    
[^9]: LLaMA-E：多方面指导下的电子商务创作增强系统

    LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following. (arXiv:2308.04913v1 [cs.CL])

    [http://arxiv.org/abs/2308.04913](http://arxiv.org/abs/2308.04913)

    LLaMA-E是一种统一且定制的指导语言模型，旨在解决电子商务创作过程中遇到的各种任务，包括广告生成、查询增强的产品标题改写、产品分类、购买意图推测和常规问答。

    

    电子商务创作涉及创建吸引人、丰富且有针对性的促销内容，以推动产品销售。大型语言模型（LLM）的出现引入了一种创新的范例，为解决这种情景中的各种创作任务提供了统一的解决方案。然而，基于通用语料库和常识知识训练的主流LLM在适应电子商务产品和客户独特的复杂和个性化特征方面存在局限性。此外，像GPT-3.5这样的LLM需要进行远程访问，引发了在传输过程中保护大量客户隐私数据的担忧。本文提出了LLaMA-E，针对多样化的电子商务创作任务的统一且定制的指导语言模型。具体而言，领域专家从广告生成、查询增强的产品标题改写、产品分类、购买意图推测和常规问答等任务中创建了种子指导集合。这些任务能够...

    E-commerce authoring involves creating attractive, abundant, and targeted promotional content to drive product sales. The emergence of large language models (LLMs) introduces an innovative paradigm, offering a unified solution to address various authoring tasks within this scenario. However, mainstream LLMs trained on general corpora with common sense knowledge reveal limitations in fitting complex and personalized features unique to e-commerce products and customers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility, raising concerns about safeguarding voluminous customer privacy data during transmission. This paper proposes the LLaMA-E, the unified and customized instruction-following language models focusing on diverse e-commerce authoring tasks. Specifically, the domain experts create the seed instruction set from the tasks of ads generation, query-enhanced product title rewriting, product classification, purchase intent speculation, and general Q&A. These tasks enabl
    
[^10]: 使用马氏距离进行无监督的方言识别

    Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance. (arXiv:2308.04886v1 [cs.CL])

    [http://arxiv.org/abs/2308.04886](http://arxiv.org/abs/2308.04886)

    提出了一种使用马氏距离进行无监督的方言识别方法，通过利用多任务学习从wav2vec 2.0变压器模型的中间层潜在嵌入中提取特征，实现了有效的离群样本检测，并在该问题上明显优于其他方法。

    

    方言分类被用于提高机器翻译和语音识别等多种应用系统的整体性能。在实际应用中，部署的方言分类模型可能会遇到与训练数据分布不同的异常输入，也称为离群样本（OOD 样本）。这些 OOD 样本可能导致意外的输出，因为模型训练过程中没有见过这些样本所属的方言。在方言分类领域，离群样本检测是一个鲜为人知的研究领域。为此，我们提出了一种简单而有效的无监督马氏距离特征方法来检测离群样本。我们利用了基于 wav2vec 2.0 变压器模型的方言分类器模型的所有中间层的潜在嵌入来进行多任务学习。我们的方法在离群样本检测方面明显优于其他最先进的方法。

    Dialect classification is used in a variety of applications, such as machine translation and speech recognition, to improve the overall performance of the system. In a real-world scenario, a deployed dialect classification model can encounter anomalous inputs that differ from the training data distribution, also called out-of-distribution (OOD) samples. Those OOD samples can lead to unexpected outputs, as dialects of those samples are unseen during model training. Out-of-distribution detection is a new research area that has received little attention in the context of dialect classification. Towards this, we proposed a simple yet effective unsupervised Mahalanobis distance feature-based method to detect out-of-distribution samples. We utilize the latent embeddings from all intermediate layers of a wav2vec 2.0 transformer-based dialect classifier model for multi-task learning. Our proposed approach outperforms other state-of-the-art OOD detection methods significantly.
    
[^11]: 元音和谐的信息论特征：词汇列表的跨语言研究

    Information-Theoretic Characterization of Vowel Harmony: A Cross-Linguistic Study on Word Lists. (arXiv:2308.04885v1 [cs.CL])

    [http://arxiv.org/abs/2308.04885](http://arxiv.org/abs/2308.04885)

    通过计算建模，该跨语言研究利用信息论量化了元音和谐，并通过使用词根形式而不是屈折变形的词形进行模型训练，涵盖了更多未被研究的语言。实验证明，神经PLMs能够捕捉到存在元音和谐的语言中的和谐模式。

    

    我们提出了一项跨语言研究，旨在利用数据驱动的计算建模来量化元音和谐。具体而言，我们基于自然语言词汇中元音的可预测性定义了一个信息论的和谐度量，我们通过音素级语言模型（PLMs）来估计。此前的定量研究在分析元音和谐时主要依赖于屈折变形的词形。相反，我们使用跨语言可比较的词根形式进行模型训练，这些形式很少或没有屈折变形，这样可以涵盖更多未被研究的语言。我们的PLMs的训练数据包括每种语言最多1000个词汇条目的词汇列表。尽管我们使用的数据比以前使用的语料库要小得多，但我们的实验表明，神经PLMs能够捕捉到一组存在这种现象的语言中的元音和谐模式。我们的工作还证明了词汇列表是一种有价值的类型学研究资源，

    We present a cross-linguistic study that aims to quantify vowel harmony using data-driven computational modeling. Concretely, we define an information-theoretic measure of harmonicity based on the predictability of vowels in a natural language lexicon, which we estimate using phoneme-level language models (PLMs). Prior quantitative studies have relied heavily on inflected word-forms in the analysis of vowel harmony. We instead train our models using cross-linguistically comparable lemma forms with little or no inflection, which enables us to cover more under-studied languages. Training data for our PLMs consists of word lists with a maximum of 1000 entries per language. Despite the fact that the data we employ are substantially smaller than previously used corpora, our experiments demonstrate the neural PLMs capture vowel harmony patterns in a set of languages that exhibit this phenomenon. Our work also demonstrates that word lists are a valuable resource for typological research, and 
    
[^12]: 通过自动提示优化进行情感条件文本生成

    Emotion-Conditioned Text Generation through Automatic Prompt Optimization. (arXiv:2308.04857v1 [cs.CL])

    [http://arxiv.org/abs/2308.04857](http://arxiv.org/abs/2308.04857)

    本论文提出了一种通过自动提示优化的方法，用于情感条件文本生成。通过改变提示，我们的方法能够实现生成文本中条件变量的实现情况。这种方法经济高效且具有竞争力。

    

    条件自然语言生成方法通常需要耗费巨大的微调或从头开始训练一个大型语言模型。这两种方法都很难在没有大量数据和计算资源的情况下得到好的结果。不改变大型语言模型的参数而进行提示学习则是一个具有潜力的替代方法。这是一种经济高效的方法，同时又能够达到竞争力的结果。虽然这种方法在零样本和少样本文本分类和结构化预测中已经得到了广泛应用，但在条件文本生成中受到的关注却有限。我们提出了第一个用于情感条件文本生成的自动提示优化方法，采用了指令微调模型。我们的方法使用迭代优化过程，通过添加、删除或替换标记来改变提示。作为目标函数，我们只需要一个文本分类器来衡量生成文本中条件变量的实现情况。

    Conditional natural language generation methods often require either expensive fine-tuning or training a large language model from scratch. Both are unlikely to lead to good results without a substantial amount of data and computational resources. Prompt learning without changing the parameters of a large language model presents a promising alternative. It is a cost-effective approach, while still achieving competitive results. While this procedure is now established for zero- and few-shot text classification and structured prediction, it has received limited attention in conditional text generation. We present the first automatic prompt optimization approach for emotion-conditioned text generation with instruction-fine-tuned models. Our method uses an iterative optimization procedure that changes the prompt by adding, removing, or replacing tokens. As objective function, we only require a text classifier that measures the realization of the conditional variable in the generated text. 
    
[^13]: TSSR：一种截断和带符号的平方根激活函数用于神经网络

    TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks. (arXiv:2308.04832v1 [cs.CV])

    [http://arxiv.org/abs/2308.04832](http://arxiv.org/abs/2308.04832)

    本文介绍了一种新的激活函数 TSSR，具有奇数、非线性、单调和可微分的特性。实验证实了TSSR相比其他激活函数具有更好的性能，对神经网络模型的发展具有重要意义，并适用于多个领域的广泛应用。

    

    激活函数是神经网络的重要组成部分。本文介绍了一种新的激活函数，称为截断和带符号平方根（TSSR）函数。该函数具有奇数、非线性、单调和可微分的特性。其梯度是连续且始终为正。由于这些特性，它有潜力改善神经网络的数值稳定性。多个实验证实了所提出的TSSR比其他最先进的激活函数具有更好的性能。该函数对神经网络模型的发展具有重要意义，并可应用于计算机视觉、自然语言处理和语音识别等领域的广泛应用。

    Activation functions are essential components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is distinctive because it is odd, nonlinear, monotone and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other stat-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.
    
[^14]: 评估大型中文语言模型的生成能力

    Evaluating the Generation Capabilities of Large Chinese Language Models. (arXiv:2308.04823v1 [cs.CL])

    [http://arxiv.org/abs/2308.04823](http://arxiv.org/abs/2308.04823)

    本文首次对大型中文语言模型在多个学科领域的生成能力进行了全面评估，并提出了Gscore作为衡量生成结果质量的综合指数。

    

    本文介绍了CG-Eval，这是第一个对大型中文语言模型在多个学科领域生成能力进行全面评估的研究。通过在科学工程、人文社科、数学计算、医师资格考试、司法考试和注册会计师考试六个学科中生成准确和相关的回答，评估了这些模型的性能。本文还提出了Gscore，这是一个由多个度量指标加权求和得到的综合指数，用于衡量模型生成结果与参考答案的质量。测试数据和测试结果可在此http URL找到。

    This paper presents CG-Eval, the first comprehensive evaluation of the generation capabilities of large Chinese language models across a wide range of academic disciplines. The models' performance was assessed based on their ability to generate accurate and relevant responses to different types of questions in six disciplines, namely, Science and Engineering, Humanities and Social Sciences, Mathematical Calculations, Medical Practitioner Qualification Examination, Judicial Examination, and Certified Public Accountant Examination. This paper also presents Gscore, a composite index derived from the weighted sum of multiple metrics to measure the quality of model's generation against a reference. The test data and test results can be found at this http URL
    
[^15]: CLEVA：中文语言模型评估平台

    CLEVA: Chinese Language Models EVAluation Platform. (arXiv:2308.04813v1 [cs.CL])

    [http://arxiv.org/abs/2308.04813](http://arxiv.org/abs/2308.04813)

    CLEVA是一个用于评估中文语言模型的用户友好平台，通过标准化工作流程、竞争排行榜和减少污染的策略，使用户能够轻松进行全面评估。

    

    随着中文大型语言模型（LLMs）的不断出现，如何评估模型的能力已成为一个越来越重要的问题。当前评估中文LLMs面临着缺乏全面评估模型性能的基准、非标准化和无法比较的提示过程，以及普遍存在的污染风险等主要挑战。我们提出了CLEVA，一个用户友好的平台，用于全面评估中文LLMs。我们的平台采用标准化工作流程，定期更新竞争排行榜，评估LLMs在各个维度上的性能。为了减少污染，CLEVA精选了大量新数据，并开发了一种采样策略，保证每个排行榜轮次都有独特的子集。用户只需点击几下鼠标并使用模型API即可进行全面评估，无需编写大量代码。

    With the continuous emergence of Chinese Large Language Models (LLMs), how to evaluate a model's capabilities has become an increasingly significant issue. The absence of a comprehensive Chinese benchmark that thoroughly assesses a model's performance, the unstandardized and incomparable prompting procedure, and the prevalent risk of contamination pose major challenges in the current evaluation of Chinese LLMs. We present CLEVA, a user-friendly platform crafted to holistically evaluate Chinese LLMs. Our platform employs a standardized workflow to assess LLMs' performance across various dimensions, regularly updating a competitive leaderboard. To alleviate contamination, CLEVA curates a significant proportion of new data and develops a sampling strategy that guarantees a unique subset for each leaderboard round. Empowered by an easy-to-use interface that requires just a few mouse clicks and a model API, users can conduct a thorough evaluation with minimal coding. Large-scale experiments
    
[^16]: 我们只需要一个二分图来增强具有常识知识的情感推理能力

    A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge. (arXiv:2308.04811v1 [cs.CL])

    [http://arxiv.org/abs/2308.04811](http://arxiv.org/abs/2308.04811)

    通过使用二分异构图(BHG)方法，我们提出了一种增强具有常识知识的情感推理能力的方法，该方法能够解决常见的知识注入方法的问题，并提供了更好的泛化能力和知识丰富度。

    

    AI系统在情感推理方面的上下文感知能力，特别是在对话中，对于诸如从社交媒体中进行在线意见挖掘和共情对话系统等应用非常重要。由于许多情境中情感的传递具有隐含性质，常识知识被广泛应用于丰富话语语义和增强对话建模。然而，大多数先前的知识注入方法执行经验性的知识过滤，并设计高度定制的架构以与话语进行知识交互，这可能丢弃有用的知识方面并限制其对不同知识来源的泛化能力。基于这些观察结果，我们提出了一种用于增强具有常识知识的情感推理的二分异构图(BHG)方法。在BHG中，提取的上下文感知话语表示和知识表示被建模为异构节点。还提出了两种更多的知识聚合节点类型。

    The context-aware emotional reasoning ability of AI systems, especially in conversations, is of vital importance in applications such as online opinion mining from social media and empathetic dialogue systems. Due to the implicit nature of conveying emotions in many scenarios, commonsense knowledge is widely utilized to enrich utterance semantics and enhance conversation modeling. However, most previous knowledge infusion methods perform empirical knowledge filtering and design highly customized architectures for knowledge interaction with the utterances, which can discard useful knowledge aspects and limit their generalizability to different knowledge sources. Based on these observations, we propose a Bipartite Heterogeneous Graph (BHG) method for enhancing emotional reasoning with commonsense knowledge. In BHG, the extracted context-aware utterance representations and knowledge representations are modeled as heterogeneous nodes. Two more knowledge aggregation node types are proposed 
    
[^17]: ADMUS: 一种适应多种知识源的渐进式问答框架

    ADMUS: A Progressive Question Answering Framework Adaptable to Multiple Knowledge Sources. (arXiv:2308.04800v1 [cs.CL])

    [http://arxiv.org/abs/2308.04800](http://arxiv.org/abs/2308.04800)

    ADMUS是一种渐进式的知识库问答框架，可以适应多种知识源，包括多语言、多种知识库和不同的问答数据集。它通过解耦知识库问答系统的架构，提供了一个与数据集无关的框架，实现了新数据集的无缝集成，并且成本极低。

    

    随着深度学习模型的引入，基于语义解析的知识库问答系统在处理复杂问题方面取得了高性能。然而，大多数现有方法主要关注于提高模型在各个基准数据集上的效果，忽视了在现实场景中（例如多租户平台）将系统适应不同数据集的高成本。因此，我们提出了ADMUS，一种适应多种数据集的渐进式知识库问答框架，包括多种语言，不同的知识库和不同的问答数据集。为了实现这个目的，我们解耦常规知识库问答系统的架构，并提出了这种与数据集无关的框架。我们的框架支持无缝集成新的数据集，只需要以极小的成本创建一个与数据集相关的微服务。

    With the introduction of deep learning models, semantic parsingbased knowledge base question answering (KBQA) systems have achieved high performance in handling complex questions. However, most existing approaches primarily focus on enhancing the model's effectiveness on individual benchmark datasets, disregarding the high costs of adapting the system to disparate datasets in real-world scenarios (e.g., multi-tenant platform). Therefore, we present ADMUS, a progressive knowledge base question answering framework designed to accommodate a wide variety of datasets, including multiple languages, diverse backbone knowledge bases, and disparate question answering datasets. To accomplish the purpose, we decouple the architecture of conventional KBQA systems and propose this dataset-independent framework. Our framework supports the seamless integration of new datasets with minimal effort, only requiring creating a dataset-related micro-service at a negligible cost. To enhance the usability of
    
[^18]: 用于自动测量失语症患者讲话流利度的初步成果：基于朗读语音数据的实现

    Automatically measuring speech fluency in people with aphasia: first achievements using read-speech data. (arXiv:2308.04763v1 [cs.CL])

    [http://arxiv.org/abs/2308.04763](http://arxiv.org/abs/2308.04763)

    本研究首次使用朗读语音数据，评估了一种信号处理算法在自动测量失语症患者言语流利度方面的相关性。通过对比专业言语治疗师的评估结果，发现该算法可以有效地预测失语症患者的言语流利程度。

    

    背景：言语和语言病理学家常常依赖对于失语症患者的言语流利性的评判来诊断或监测患者。然而，这样的主观方法因其可靠性不足以及在临床上花费过多的时间而受到批评。目的：本研究旨在评估一种信号处理算法在自动测量失语症患者言语流利度方面的相关性，该算法最初是在语言习得领域开发的。方法与过程：通过非营利组织和言语治疗师网络招募了29名失语症患者和5名对照参与者。所有参与者在朗读法语版波士顿诊断性失语症测试中的一组句子时被录制下来。三名受过训练的言语治疗师根据一个五点临床性质评价尺度评估了每个句子的流利度。使用正反向分歧分割和聚类算法来计算每个句子的四个自动预测因子，即语音相关部分的长度、正反向分歧部分的长度、正反向分歧部分的数量和句子中共振离散程度的表示。

    Background: Speech and language pathologists (SLPs) often relyon judgements of speech fluency for diagnosing or monitoringpatients with aphasia. However, such subjective methods havebeen criticised for their lack of reliability and their clinical cost interms of time. Aims: This study aims at assessing the relevance of a signalprocessingalgorithm, initially developed in the field of language acquisition, for the automatic measurement of speech fluency in people with aphasia (PWA). Methods & Procedures: Twenty-nine PWA and five control participantswere recruited via non-profit organizations and SLP networks. All participants were recorded while reading out loud a set ofsentences taken from the French version of the Boston Diagnostic Aphasia Examination. Three trained SLPs assessed the fluency of each sentence on a five-point qualitative scale. A forward-backward divergence segmentation and a clustering algorithm were used to compute, for each sentence, four automatic predictors of speec
    
[^19]: 为新的领域构建可解释和可靠的开放信息检索器

    Building Interpretable and Reliable Open Information Retriever for New Domains Overnight. (arXiv:2308.04756v1 [cs.CL])

    [http://arxiv.org/abs/2308.04756](http://arxiv.org/abs/2308.04756)

    本论文提出了一种信息检索流程，通过使用实体/事件链接模型和查询分解模型，更准确地聚焦于查询的不同信息单元。这种流程在段落覆盖和命名准确性方面显著改进，同时也更具解释性和可靠性。

    

    信息检索（IR）或知识检索是许多下游任务（如开放领域问答）的关键组成部分。然而，它面临许多挑战，因为它需要简洁性、完整性和正确性。最近的研究中，通过使用稠密向量表示查询和知识段落，并学习词汇和语义相似性，稠密检索模型在领域内IR和QA基准上取得了最先进的性能。然而，使用单一的稠密向量和端到端监督并不总是最优的，因为查询可能需要注意多个方面和隐含的知识。在这项工作中，我们提出了一种信息检索流程，利用实体/事件链接模型和查询分解模型，更准确地聚焦于查询的不同信息单元。我们证明，尽管更具解释性和可靠性，我们提出的流程在段落覆盖和命名准确性方面都有显著改进。

    Information retrieval (IR) or knowledge retrieval, is a critical component for many down-stream tasks such as open-domain question answering (QA). It is also very challenging, as it requires succinctness, completeness, and correctness. In recent works, dense retrieval models have achieved state-of-the-art (SOTA) performance on in-domain IR and QA benchmarks by representing queries and knowledge passages with dense vectors and learning the lexical and semantic similarity. However, using single dense vectors and end-to-end supervision are not always optimal because queries may require attention to multiple aspects and event implicit knowledge. In this work, we propose an information retrieval pipeline that uses entity/event linking model and query decomposition model to focus more accurately on different information units of the query. We show that, while being more interpretable and reliable, our proposed pipeline significantly improves passage coverages and denotation accuracies across
    
[^20]: 通过预训练语言模型探测和多层对比学习进行槽位归纳

    Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning. (arXiv:2308.04712v1 [cs.CL])

    [http://arxiv.org/abs/2308.04712](http://arxiv.org/abs/2308.04712)

    本研究通过利用预训练语言模型的探测和对比学习机制，在槽位归纳任务中，成功地诱导了槽位边界，并在两个NLU基准数据集上表现出与令牌级监督模型相当的性能，同时也能提供增强的槽位标签表示。

    

    最近在面向任务的对话系统（如意图识别和槽位填充）的自然语言理解中，需要大量的标注数据才能达到竞争性的性能。在现实中，标记的时间级别（槽位标签）耗时且难以获取。在本文中，我们研究了槽位归纳(SI)任务，其目标是在没有显式了解的情况下诱导槽位边界。我们提出了利用无监督预训练语言模型(PLM)探测和对比学习机制来利用(1)从PLM中提取的无监督语义知识，和(2)从TOD中可用的额外句子级意图标签信号。我们的方法在槽位归纳任务中证明了其有效性，并能够弥补与基于令牌级监督模型在两个NLU基准数据集上的差距。当推广到新出现的意图时，我们的SI目标也提供了增强的槽位标签表示，从而提高了性能。

    Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved per
    
[^21]: 使用理由生成和密集检索回答未知问题的较小语言模型

    Answering Unseen Questions With Smaller Language\\Models Using Rationale Generation and Dense Retrieval. (arXiv:2308.04711v1 [cs.CL])

    [http://arxiv.org/abs/2308.04711](http://arxiv.org/abs/2308.04711)

    本论文提出了两种方法来改进在具有充分解释性背景下，使用较小语言模型回答训练中未见的挑战性短问题回答任务。第一种方法是使用理据生成和密集检索结合的方式，并通过理据排名模型进行评分和组合。第二种方法是使用增强检索训练数据集训练较小的推理模型，以利用长文本序列中的相关信息。

    

    在提供足够的解释性背景的情况下，已经证明较小的语言模型在挑战性的无法在训练中见过的短问题回答任务上展现出强大的推理能力。我们评估了两种进一步改进该场景的方法。这两种方法都注重将大型语言模型生成的理由与通过多轮密集检索系统创建的更长上下文结合起来。第一个方法（$RR$）涉及训练一个理据排名模型，以评分的方式衡量生成的理由和检索到的上下文的相关性和真实性。然后，我们使用这些评分使用多种组合策略从两个知识源中获得组合上下文。对于第二种方法（$RATD$），我们使用增强检索训练数据集训练较小的推理模型，使其能够熟练地利用来自更长文本序列的相关信息，这些信息可能部分具有证据性且频繁出现。

    When provided with sufficient explanatory context, smaller Language Models have been shown to exhibit strong reasoning ability on challenging short-answer question-answering tasks where the questions are unseen in training. We evaluate two methods for further improvement in this setting. Both methods focus on combining rationales generated by a larger Language Model with longer contexts created from a multi-hop dense retrieval system. The first method ($\textit{RR}$) involves training a Rationale Ranking model to score both generated rationales and retrieved contexts with respect to relevance and truthfulness. We then use the scores to derive combined contexts from both knowledge sources using a number of combinatory strategies. For the second method ($\textit{RATD}$) we train a smaller Reasoning model using retrieval-augmented training datasets such that it becomes proficient at utilising relevant information from longer text sequences that may be only partially evidential and frequen
    
[^22]: 开源大型语言模型GPT-4和Claude 2的比较研究：肾病学中的多项选择题考试

    A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology. (arXiv:2308.04709v1 [cs.CL])

    [http://arxiv.org/abs/2308.04709](http://arxiv.org/abs/2308.04709)

    本研究比较了几个开源的大型语言模型（LLMs）和GPT-4、Claude 2在肾病学内科多项选择题考试方面的表现。这些模型在未来有潜力成为医学培训、医疗协助和患者交互的一部分。

    

    近年来，自然语言处理领域取得了重大突破，尤其是大型语言模型（LLM）的发展。这些LLM在各种基准测试中展示了 remarkable 能力。在医疗领域，LLM和其他未来的人工智能模型所扮演的确切角色仍不清楚。将来，这些模型有可能成为适应性医师培训、医疗协助应用和数字化患者交互场景的一部分。人工智能模型参与医学培训和患者护理的能力将部分取决于它们是否掌握特定医学领域的知识内容。本研究在内科专业多项选择题考试能力的背景下，调查了LLM的医学知识能力。我们研究了几个开源的LLM（Koala 7B、Falcon 7B、Stable-Vicuna 13B和Orca Mini 13B）与GPT-4和Claude 2的性能进行比较。

    In recent years, there have been significant breakthroughs in the field of natural language processing, particularly with the development of large language models (LLMs). These LLMs have showcased remarkable capabilities on various benchmarks. In the healthcare field, the exact role LLMs and other future AI models will play remains unclear. There is a potential for these models in the future to be used as part of adaptive physician training, medical co-pilot applications, and digital patient interaction scenarios. The ability of AI models to participate in medical training and patient care will depend in part on their mastery of the knowledge content of specific medical fields. This study investigated the medical knowledge capability of LLMs, specifically in the context of internal medicine subspecialty multiple-choice test-taking ability. We compared the performance of several open-source LLMs (Koala 7B, Falcon 7B, Stable-Vicuna 13B, and Orca Mini 13B), to GPT-4 and Claude 2 on multip
    
[^23]: 生成面向新闻的填字游戏作为约束满足和优化问题

    Generating News-Centric Crossword Puzzles As A Constraint Satisfaction and Optimization Problem. (arXiv:2308.04688v1 [cs.CL])

    [http://arxiv.org/abs/2308.04688](http://arxiv.org/abs/2308.04688)

    本研究提出了一个约束满足和优化问题的框架，用于自动生成面向新闻的填字游戏。通过添加尽可能多的新闻衍生词汇，可以增强教育目的和人们对新闻的兴趣。

    

    填字游戏不仅仅作为娱乐活动，还是一种可以用来获取词汇和语言能力的教育工具。增强教育目的的一种策略是个性化，比如添加更多关于特定主题的单词。本文关注于鼓励人们对新闻感兴趣的情况，并提出了一个自动生成面向新闻的填字游戏的框架。我们设计了可能的场景，并构建了一个原型作为约束满足和优化问题，即包含尽可能多的新闻衍生词汇。我们的实验报告了在几个条件下所需的生成概率和时间。结果表明，即使只有少数新闻衍生词汇，也可以生成面向新闻的填字游戏。通过对原型的定性评估，我们总结了当前的问题和未来的研究方向。这是第一个关于约束满足和优化问题的提案的形式。

    Crossword puzzles have traditionally served not only as entertainment but also as an educational tool that can be used to acquire vocabulary and language proficiency. One strategy to enhance the educational purpose is personalization, such as including more words on a particular topic. This paper focuses on the case of encouraging people's interest in news and proposes a framework for automatically generating news-centric crossword puzzles. We designed possible scenarios and built a prototype as a constraint satisfaction and optimization problem, that is, containing as many news-derived words as possible. Our experiments reported the generation probabilities and time required under several conditions. The results showed that news-centric crossword puzzles can be generated even with few news-derived words. We summarize the current issues and future research directions through a qualitative evaluation of the prototype. This is the first proposal that a formulation of a constraint satisfa
    
[^24]: Sci-CoT: 利用大型语言模型改进小型科学问答中的知识蒸馏

    Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA. (arXiv:2308.04679v1 [cs.CL])

    [http://arxiv.org/abs/2308.04679](http://arxiv.org/abs/2308.04679)

    本论文研究了通过知识蒸馏将大型语言模型(LLMs)的推理能力转移到较小模型的可能性，提出了Sci-CoT框架，分离了生成理由和推理的过程。

    

    大型语言模型(LLMs)在广泛的下游任务中展现出了出色的性能。这种能力归功于它们庞大的参数规模和对大量语料库的预训练。此外，LLMs展现出增强的推理能力，能够应对复杂的推理任务，这归功于一种名为"思维链 (CoT)提示"的方法。该方法旨在生成引导最终答案推理的中间推理步骤。然而，需要强调的是，这些先进的推理能力似乎只在具有至少100亿参数的模型中出现，从而限制了其在计算资源有限的情况下的有效性。在本文中，我们探讨了通过知识蒸馏将LLMs的推理能力转移到较小模型的可能性。具体来说，我们提出了Sci-CoT，一个两阶段的框架，分离了生成理由和推理的过程。

    Large Language Models (LLMs) have shown outstanding performance across wide range of downstream tasks. This competency is attributed to their substantial parameter size and pre-training on extensive corpus. Moreover, LLMs have exhibited enhanced reasoning capabilities in tackling complex reasoning tasks, owing to the utilization of a method named ``Chain-of-Thought (CoT) prompting''. This method is designed to generate intermediate reasoning steps that guide the inference of the final answer. However, it is essential to highlight that these advanced reasoning abilities appear to emerge in models with a minimum of 10 billion parameters, thereby limiting its efficacy in situations where computational resources are constrained. In this paper, we investigate the possibility of transferring the reasoning capabilities of LLMs to smaller models via knowledge distillation. Specifically, we propose Sci-CoT, a two-stage framework that separates the processes of generating rationales and inferrin
    
[^25]: Sudowoodo: 一种带有源歌词的中文抒情模仿系统

    Sudowoodo: a Chinese Lyric Imitation System with Source Lyrics. (arXiv:2308.04665v1 [cs.CL])

    [http://arxiv.org/abs/2308.04665](http://arxiv.org/abs/2308.04665)

    Sudowoodo是一个中文歌词模仿系统，通过构建平行语料库和利用后处理模块来生成新的高质量歌词，实现了模仿源歌词的风格和内容。

    

    歌词生成是自然语言生成研究中一个众所周知的应用，之前的研究主要集中在使用关键词、押韵等精确控制来生成准确的歌词。然而，歌词模仿，即通过模仿源歌词的风格和内容来创作新歌词，仍然是一个具有挑战性的任务，因为缺乏平行语料库。在本文中，我们介绍了一个名为"Sudowoodo"的中文歌词模仿系统，它可以基于源歌词的文本生成新的歌词。为了解决歌词模仿训练过程中缺乏平行语料库的问题，我们提出了一个新颖的框架，通过基于源歌词的基于关键词的歌词模型构建平行语料库。然后使用新歌词与源歌词的对来训练歌词模仿模型。在推理过程中，我们利用后处理模块来过滤和排序生成的歌词，选择最高质量的歌词。

    Lyrics generation is a well-known application in natural language generation research, with several previous studies focusing on generating accurate lyrics using precise control such as keywords, rhymes, etc. However, lyrics imitation, which involves writing new lyrics by imitating the style and content of the source lyrics, remains a challenging task due to the lack of a parallel corpus. In this paper, we introduce \textbf{\textit{Sudowoodo}}, a Chinese lyrics imitation system that can generate new lyrics based on the text of source lyrics. To address the issue of lacking a parallel training corpus for lyrics imitation, we propose a novel framework to construct a parallel corpus based on a keyword-based lyrics model from source lyrics. Then the pairs \textit{(new lyrics, source lyrics)} are used to train the lyrics imitation model. During the inference process, we utilize a post-processing module to filter and rank the generated lyrics, selecting the highest-quality ones. We incorpora
    
[^26]: 中古高地德语的跨语言短语结构分析：一种去词法化的方法

    Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach. (arXiv:2308.04645v1 [cs.CL])

    [http://arxiv.org/abs/2308.04645](http://arxiv.org/abs/2308.04645)

    本研究通过利用中古高地德语和现代德语的语言连续性和结构相似性，以及现有的现代德语树库资源，构建了一种适用于中古高地德语的短语结构分析器，无需依赖标注的MHG树库资源。

    

    短语结构分析在推动自然语言处理（NLP）任务中起着基础性的作用。然而，仅依靠标注的解析数据训练古代语言的自动句法分析系统是一项艰巨的任务，因为构建这些语言的树库存在固有挑战。这需要丰富的语言专业知识，导致可用资源的稀缺。为了克服这个障碍，跨语言转移技术为低资源目标语言提供了一种有希望的解决方案，这些技术需要最少甚至没有标注数据。在本研究中，我们着重于构建适用于中古高地德语（MHG）的短语结构分析器，在缺乏标注的MHG树库进行训练的现实条件下。在我们的方法中，我们利用MHG和现代德语（MG）之间的语言连续性和结构相似性，以及丰富的MG树库资源。

    Constituency parsing plays a fundamental role in advancing natural language processing (NLP) tasks. However, training an automatic syntactic analysis system for ancient languages solely relying on annotated parse data is a formidable task due to the inherent challenges in building treebanks for such languages. It demands extensive linguistic expertise, leading to a scarcity of available resources. To overcome this hurdle, cross-lingual transfer techniques which require minimal or even no annotated data for low-resource target languages offer a promising solution. In this study, we focus on building a constituency parser for $\mathbf{M}$iddle $\mathbf{H}$igh $\mathbf{G}$erman $\mathbf{MHG}$ under realistic conditions, where no annotated MHG treebank is available for training. In our approach, we leverage the linguistic continuity and structural similarity between MHG and $\mathbf{M}$odern $\mathbf{G}$erman $\mathbf{MG}$, along with the abundance of MG treebank resources. Specifically, b
    
[^27]: 句子嵌入模型在评估语义变化中的比较研究

    A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation. (arXiv:2308.04625v1 [cs.CL])

    [http://arxiv.org/abs/2308.04625](http://arxiv.org/abs/2308.04625)

    本研究比较了几种最近的句子嵌入方法在分析语义变化方面的一致性和有效性，并通过真实世界文本进行了评估。

    

    分析长篇真实世界文本（如书籍或记录）中语义变化的模式在文体、认知和语言学的角度上很有趣。它也有助于诸如文本分段、文档摘要和语义新颖性检测等应用。最近出现的几种句子嵌入方法使得这种分析成为可能。然而，这引发了不同方法产生的语义表示在自身上是否一致和有意义的问题。在本文中，我们通过时间序列的连续句子语义相似度和多本文学作品的句子对语义相似度矩阵来比较几种最近的句子嵌入方法。与以前使用目标任务和策划数据集来比较句子嵌入方法的工作相比，我们的方法在"野外"提供了对方法的评估。我们发现，大多数考虑的句子嵌入方法确实可以获得良好的效果。

    Analyzing the pattern of semantic variation in long real-world texts such as books or transcripts is interesting from the stylistic, cognitive, and linguistic perspectives. It is also useful for applications such as text segmentation, document summarization, and detection of semantic novelty. The recent emergence of several vector-space methods for sentence embedding has made such analysis feasible. However, this raises the issue of how consistent and meaningful the semantic representations produced by various methods are in themselves. In this paper, we compare several recent sentence embedding methods via time-series of semantic similarity between successive sentences and matrices of pairwise sentence similarity for multiple books of literature. In contrast to previous work using target tasks and curated datasets to compare sentence embedding methods, our approach provides an evaluation of the methods 'in the wild'. We find that most of the sentence embedding methods considered do in
    
[^28]: 基于LLM技术的聊天机器人的基准测试：方法和指标

    Benchmarking LLM powered Chatbots: Methods and Metrics. (arXiv:2308.04624v1 [cs.CL])

    [http://arxiv.org/abs/2308.04624](http://arxiv.org/abs/2308.04624)

    本文提出了一种新型的E2E基准测试，用于评估由LLM驱动的聊天机器人的准确性和实用性，相比其他指标，该基准测试展现出更好的结果。

    

    自主对话代理，即聊天机器人，正成为企业为客户和合作伙伴提供支持的越来越常见的机制。为了评估特别是由大型语言模型（LLM）驱动的聊天机器人的表现，我们需要能够准确评估其性能。这就是聊天机器人基准测试的重要性所在。在本文中，我们提出了一种称为E2E（端到端）基准测试的新型基准测试，并展示了如何使用E2E基准测试来评估由LLM驱动的聊天机器人提供的答案的准确性和实用性。我们根据我们的E2E基准测试以及其他常用的现有指标评估了一个示例聊天机器人的不同复杂程度，并观察到所提出的基准测试相比其他指标展现出更好的结果。此外，一些指标被证明是不可预测的，而与E2E基准测试相关的指标使用了余弦相似度。

    Autonomous conversational agents, i.e. chatbots, are becoming an increasingly common mechanism for enterprises to provide support to customers and partners. In order to rate chatbots, especially ones powered by Generative AI tools like Large Language Models (LLMs) we need to be able to accurately assess their performance. This is where chatbot benchmarking becomes important. In this paper, we propose the use of a novel benchmark that we call the E2E (End to End) benchmark, and show how the E2E benchmark can be used to evaluate accuracy and usefulness of the answers provided by chatbots, especially ones powered by LLMs. We evaluate an example chatbot at different levels of sophistication based on both our E2E benchmark, as well as other available metrics commonly used in the state of art, and observe that the proposed benchmark show better results compared to others. In addition, while some metrics proved to be unpredictable, the metric associated with the E2E benchmark, which uses cosi
    
[^29]: 采用分阶段推测解码加速LLM推理

    Accelerating LLM Inference with Staged Speculative Decoding. (arXiv:2308.04623v1 [cs.AI])

    [http://arxiv.org/abs/2308.04623](http://arxiv.org/abs/2308.04623)

    本文提出了一种新算法，分阶段推测解码，用于加速在小批量、设备上进行LLM推理。通过使用树形结构的批次重组和增加第二阶段的推测解码，将单批解码延迟降低了3.16倍，而输出质量保持完美。

    

    最近LLM的大规模语言模型的进展展示了它们的多样化能力。我们提出了一种新颖的算法，即分阶段推测解码，来加速在小批量、设备上进行LLM推理。通过改进先前的推测解码工作，我们解决了小批量推理的低算术强度问题。首先，我们将推测批次重新组织成树形结构，从而降低了生成成本，并增加了每批预期的标记数。其次，我们增加了第二阶段的推测解码。综合而言，我们在保持输出质量完美的情况下，将单批解码延迟降低了3.16倍，使用了762M参数的GPT-2-L模型。

    Recent advances with large language models (LLM) illustrate their diverse capabilities. We propose a novel algorithm, staged speculative decoding, to accelerate LLM inference in small-batch, on-device scenarios. We address the low arithmetic intensity of small-batch inference by improving upon previous work in speculative decoding. First, we restructure the speculative batch as a tree, which reduces generation costs and increases the expected tokens per batch. Second, we add a second stage of speculative decoding. Taken together, we reduce single-batch decoding latency by 3.16x with a 762M parameter GPT-2-L model while perfectly preserving output quality.
    
[^30]: "Shepherd: 一种用于语言模型生成的评论者"

    Shepherd: A Critic for Language Model Generation. (arXiv:2308.04592v1 [cs.CL])

    [http://arxiv.org/abs/2308.04592](http://arxiv.org/abs/2308.04592)

    Shepherd是一种专门用于评论和提出改进建议的语言模型，通过使用高质量的反馈数据集，它可以识别和修复不同的错误。与其他模型相比，在评估和人工评估中，Shepherd的性能表现更佳。

    

    随着大型语言模型的改进，越来越多的技术开始利用这些模型的能力来优化其输出。本研究介绍了Shepherd，一种特定调整的语言模型，用于评论回复并提出改进建议，超越了未调整模型的能力，可以识别不同的错误并提供建议来修复它们。我们的方法的核心是一个高质量的反馈数据集，我们从社区反馈和人工注释中策划整理而成。尽管Shepherd规模较小（7B个参数），但其评论要么与ChatGPT等已建立的模型等效，要么更优。通过使用GPT-4进行评估，Shepherd相对于竞争对手平均具有53-87%的胜率。在人工评估中，Shepherd明显优于其他模型，并且平均与ChatGPT持平。

    As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs. In this work, we introduce Shepherd, a language model specifically tuned to critique responses and suggest refinements, extending beyond the capabilities of an untuned model to identify diverse errors and provide suggestions to remedy them. At the core of our approach is a high quality feedback dataset, which we curate from community feedback and human annotations. Even though Shepherd is small (7B parameters), its critiques are either equivalent or preferred to those from established models including ChatGPT. Using GPT-4 for evaluation, Shepherd reaches an average win-rate of 53-87% compared to competitive alternatives. In human evaluation, Shepherd strictly outperforms other models and on average closely ties with ChatGPT.
    
[^31]: 单句阅读器：解决答案位置偏倚的新方法

    Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias. (arXiv:2308.04566v1 [cs.CL])

    [http://arxiv.org/abs/2308.04566](http://arxiv.org/abs/2308.04566)

    本论文针对机器阅读理解中的答案位置偏倚问题，提出了一种名为单句阅读器的新方法，该方法使用六种不同模型实现。实验证明，单句阅读器与传统训练集上训练的模型几乎具有相当的性能，有效解决了答案位置偏倚问题。

    

    机器阅读理解（MRC）模型往往利用伪相关性（也称为数据集偏差或研究界的标注工件）。因此，这些模型可能在不完全理解给定的上下文和问题的情况下执行MRC任务，这是不可取的，因为它可能导致对分布转移的低稳健性。本文深入探讨了答案位置偏倚的概念，其中训练问题中有相当比例的答案仅位于上下文的第一句。我们提出了一种名为单句阅读器的新方法来解决MRC中的答案位置偏倚问题。我们使用六种不同模型来实现这种方法，并对其性能进行了彻底分析。值得注意的是，我们提出的单句阅读器的结果几乎与传统训练集上训练的模型相当，证明了其有效性。我们的研究还讨论了我们的单句阅读器遇到的几个挑战和提出的应对策略。

    Machine Reading Comprehension (MRC) models tend to take advantage of spurious correlations (also known as dataset bias or annotation artifacts in the research community). Consequently, these models may perform the MRC task without fully comprehending the given context and question, which is undesirable since it may result in low robustness against distribution shift. This paper delves into the concept of answer-position bias, where a significant percentage of training questions have answers located solely in the first sentence of the context. We propose a Single-Sentence Reader as a new approach for addressing answer position bias in MRC. We implement this approach using six different models and thoroughly analyze their performance. Remarkably, our proposed Single-Sentence Readers achieve results that nearly match those of models trained on conventional training sets, proving their effectiveness. Our study also discusses several challenges our Single-Sentence Readers encounter and prop
    
[^32]: 提前文本：利用实体介词进行财务关系提取

    Ahead of the Text: Leveraging Entity Preposition for Financial Relation Extraction. (arXiv:2308.04534v1 [cs.CL])

    [http://arxiv.org/abs/2308.04534](http://arxiv.org/abs/2308.04534)

    本文在ACM KDF-SIGIR 2023竞赛中提出了一种利用实体介词进行财务关系提取的方法，在比赛中赢得了第一名。

    

    在ACM KDF-SIGIR 2023竞赛的背景下，我们在一个名为REFind的财务实体关系数据集上进行了一个实体关系任务。我们的最佳解决方案采用了一个多步骤的方法。首先，我们将提供的实体插入到文本中对应的位置。然后，我们利用带标签的训练集对基于transformer的语言模型roberta-large进行了文本分类的微调，以预测实体关系。最后，我们实施了后处理阶段，以识别和处理模型生成的不太可能的预测。由于我们的方法，我们在比赛的公共排行榜上获得了第一名的排名。

    In the context of the ACM KDF-SIGIR 2023 competition, we undertook an entity relation task on a dataset of financial entity relations called REFind. Our top-performing solution involved a multi-step approach. Initially, we inserted the provided entities at their corresponding locations within the text. Subsequently, we fine-tuned the transformer-based language model roberta-large for text classification by utilizing a labeled training set to predict the entity relations. Lastly, we implemented a post-processing phase to identify and handle improbable predictions generated by the model. As a result of our methodology, we achieved the 1st place ranking on the competition's public leaderboard.
    
[^33]: 我应该和谁合作? 关于NLP学术界与工业界合作的比较研究。

    Who should I Collaborate with? A Comparative Study of Academia and Industry Research Collaboration in NLP. (arXiv:2308.04524v1 [cs.DL])

    [http://arxiv.org/abs/2308.04524](http://arxiv.org/abs/2308.04524)

    本研究调查了学术界和工业界在自然语言处理（NLP）领域的合作对研究的影响。结果显示，学术界和工业界的合作出版物数量有增长趋势，并且这些出版物往往比仅由学术界产生的出版物具有更高的影响力。

    

    我们的研究目标是调查学术界和工业界在自然语言处理（NLP）领域的合作对研究的影响。为了实现这一目标，我们创建了一个从NLP论文中提取机构和引用信息的流程，并将其分为三类：学术界、工业界和混合型（学术界与工业界的合作）。我们的实证分析发现，工业界和学术界-工业界合作出版物的数量呈增长趋势，并且这些类型的出版物与仅在学术界产生的出版物相比，往往具有更高的影响力。

    The goal of our research was to investigate the effects of collaboration between academia and industry on Natural Language Processing (NLP). To do this, we created a pipeline to extract affiliations and citations from NLP papers and divided them into three categories: academia, industry, and hybrid (collaborations between academia and industry). Our empirical analysis found that there is a trend towards an increase in industry and academia-industry collaboration publications and that these types of publications tend to have a higher impact compared to those produced solely within academia.
    
[^34]: DisCoCat用于Donkey句子

    DisCoCat for Donkey Sentences. (arXiv:2308.04519v1 [cs.CL])

    [http://arxiv.org/abs/2308.04519](http://arxiv.org/abs/2308.04519)

    这篇论文展示了如何在一个组合分布式意义模型中解析Donkey句子，并提出了一种类型逻辑语法和关系向量空间语义。

    

    我们展示了如何在一个组合分布式意义模型中解析Geach的Donkey句子。我们在之前关于DisCoCat（分布式组合范畴）框架的工作基础上进行扩展，包括对话语、限定词和关系代词的建模。我们提出了一种类型逻辑语法来解析donkey句子，同时定义了关系和向量空间语义。

    We demonstrate how to parse Geach's Donkey sentences in a compositional distributional model of meaning. We build on previous work on the DisCoCat (Distributional Compositional Categorical) framework, including extensions that model discourse, determiners, and relative pronouns. We present a type-logical syntax for parsing donkey sentences, for which we define both relational and vector space semantics.
    
[^35]: 使用深度学习技术捕捉语音情感识别中的光谱和长期上下文信息

    Capturing Spectral and Long-term Contextual Information for Speech Emotion Recognition Using Deep Learning Techniques. (arXiv:2308.04517v1 [cs.SD])

    [http://arxiv.org/abs/2308.04517](http://arxiv.org/abs/2308.04517)

    本研究提出了一种使用组合模型的方法，将图卷积网络（GCN）与HuBERT transformer相结合，以捕捉语音情感识别中的光谱和长期上下文信息。GCN利用图表示文本数据，捕捉长期上下文依赖和语义关系，而HuBERT利用自注意机制捕捉长距离依赖性和语音中的时间动态。结合这两个方法可以更有效地进行情感识别。

    

    传统的语音情感识别方法，如LSTM、CNN、RNN、SVM和MLP，在捕捉序列数据中的长期依赖性、捕捉时间动态性以及捕捉多模态数据中的复杂模式和关系方面存在局限性。本研究通过提出一种组合模型，将图卷积网络（GCN）用于处理文本数据，HuBERT transformer用于分析音频信号，来解决这些问题。我们发现，GCN在利用基于图的文本表示捕捉文本数据中的长期上下文依赖和关系以及检测词之间的语境意义和语义关系方面表现出色。另一方面，HuBERT利用自注意机制捕捉长距离依赖性，能够对语音中的时间动态进行建模，并捕捉对情感识别产生贡献的微妙差异和变化。通过结合这两种方法，我们的模型能够更有效地进行语音情感识别。

    Traditional approaches in speech emotion recognition, such as LSTM, CNN, RNN, SVM, and MLP, have limitations such as difficulty capturing long-term dependencies in sequential data, capturing the temporal dynamics, and struggling to capture complex patterns and relationships in multimodal data. This research addresses these shortcomings by proposing an ensemble model that combines Graph Convolutional Networks (GCN) for processing textual data and the HuBERT transformer for analyzing audio signals. We found that GCNs excel at capturing Long-term contextual dependencies and relationships within textual data by leveraging graph-based representations of text and thus detecting the contextual meaning and semantic relationships between words. On the other hand, HuBERT utilizes self-attention mechanisms to capture long-range dependencies, enabling the modeling of temporal dynamics present in speech and capturing subtle nuances and variations that contribute to emotion recognition. By combining
    
[^36]: 在对话多模情感识别中重新审视模态和上下文的解缠和融合

    Revisiting Disentanglement and Fusion on Modality and Context in Conversational Multimodal Emotion Recognition. (arXiv:2308.04502v1 [cs.CL])

    [http://arxiv.org/abs/2308.04502](http://arxiv.org/abs/2308.04502)

    本研究重新审视对话多模态情感识别中的模态和上下文，提出了一种双层解缠机制来同时建模特征的多模态性和对话的语境化，以进一步提高任务性能。

    

    在对话场景下，使机器能够理解人类情感在多模态语境下的研究一直是一个热门研究课题，这个任务被称为对话式多模态情感分析（MM-ERC）。近年来，MM-ERC一直受到关注，许多方法已被提出以提高任务性能。大多数现有的研究将MM-ERC视为标准的多模态分类问题，并通过解缠和融合多模态特征来最大化特征的效用。然而在重新审视MM-ERC的特点后，我们认为在特征解缠和融合的步骤中，既应该适当地建模特征的多模态性，也应该建模对话的语境化。在这项工作中，我们将充分考虑上述观点来进一步提高任务性能。一方面，在特征解缠阶段，我们根据对比学习技术，设计了一个双层解缠机制。

    It has been a hot research topic to enable machines to understand human emotions in multimodal contexts under dialogue scenarios, which is tasked with multimodal emotion analysis in conversation (MM-ERC). MM-ERC has received consistent attention in recent years, where a diverse range of methods has been proposed for securing better task performance. Most existing works treat MM-ERC as a standard multimodal classification problem and perform multimodal feature disentanglement and fusion for maximizing feature utility. Yet after revisiting the characteristic of MM-ERC, we argue that both the feature multimodality and conversational contextualization should be properly modeled simultaneously during the feature disentanglement and fusion steps. In this work, we target further pushing the task performance by taking full consideration of the above insights. On the one hand, during feature disentanglement, based on the contrastive learning technique, we devise a Dual-level Disentanglement Mec
    
[^37]: DialogRE^C+：DialogRE在对话中关系抽取中核指代帮助的扩展研究

    DialogRE^C+: An Extension of DialogRE to Investigate How Much Coreference Helps Relation Extraction in Dialogs. (arXiv:2308.04498v1 [cs.CL])

    [http://arxiv.org/abs/2308.04498](http://arxiv.org/abs/2308.04498)

    本研究将核指代解决方案引入到对话关系抽取领域，并通过新的数据集DialogRE^C+进行评估。研究表明，通过高质量的核指代知识可以增强参数关系的推理能力，从而在提升DRE任务中起到积极作用。

    

    对话关系抽取(DRE)是识别对话文本中参数对之间关系的任务，但常见的问题是人称代词、实体和发言者的核指代。本文引入了一个新的基准数据集DialogRE^C+，将核指代解决方案引入到DRE场景中。通过高质量的核指代知识，期望增强参数关系的推理能力。在DialogRE^C+数据集中，我们根据现有的DialogRE数据手动注释了总共5,068个核指代链，涵盖了36,369个参数提及。其中，明确标记了四种不同的核指代链类型，分别是发言者链、个人链、地点链和组织链。我们还开发了4个基于图的DRE模型，以学习有效的核指代表示，从而改进DRE任务。我们还基于我们的注释训练了一个核指代解决模型，并评估了自动提取的核指代对任务的影响。

    Dialogue relation extraction (DRE) that identifies the relations between argument pairs in dialogue text, suffers much from the frequent occurrence of personal pronouns, or entity and speaker coreference. This work introduces a new benchmark dataset DialogRE^C+, introducing coreference resolution into the DRE scenario. With the aid of high-quality coreference knowledge, the reasoning of argument relations is expected to be enhanced. In DialogRE^C+ dataset, we manually annotate total 5,068 coreference chains over 36,369 argument mentions based on the existing DialogRE data, where four different coreference chain types namely speaker chain, person chain, location chain and organization chain are explicitly marked. We further develop 4 coreference-enhanced graph-based DRE models, which learn effective coreference representations for improving the DRE task. We also train a coreference resolution model based on our annotations and evaluate the effect of automatically extracted coreference c
    
[^38]: 德国推特上COVID疫情期间政策偏好的变化

    Changes in Policy Preferences in German Tweets during the COVID Pandemic. (arXiv:2308.04444v1 [cs.CY])

    [http://arxiv.org/abs/2308.04444](http://arxiv.org/abs/2308.04444)

    这项研究提供了一种量化德国推特上COVID疫情期间政策偏好的方法，通过建立细粒度政治偏好的数据集，并使用文本分类模型进行分析，结果显示政治观点在疫情期间有所增加，研究还突出了不同政治类别的变化。

    

    在线社交媒体已成为交流政治观点的重要论坛。针对COVID措施，公民直接在这些平台上表达了自己的政策偏好。在在线社交媒体中量化政治偏好仍然具有挑战性：大量的内容需要可扩展的自动提取政治偏好--然而，由于缺乏数据集，使用当前的机器学习（ML）技术进行细粒度的政治偏好提取是困难的。在这里，我们提供了一个带有细粒度政治偏好注释的推文数据集。使用训练在这个数据上的文本分类模型，我们提取了从2019年到2022年的德国Twitter语料库中的政策偏好。我们的结果表明，对于COVID疫情，政治观点的表达增加了。我们使用一个成熟的政策偏好分类法分析了细粒度的政治观点，并突出了不同政治类别的变化。

    Online social media have become an important forum for exchanging political opinions. In response to COVID measures citizens expressed their policy preferences directly on these platforms. Quantifying political preferences in online social media remains challenging: The vast amount of content requires scalable automated extraction of political preferences -- however fine grained political preference extraction is difficult with current machine learning (ML) technology, due to the lack of data sets. Here we present a novel data set of tweets with fine grained political preference annotations. A text classification model trained on this data is used to extract policy preferences in a German Twitter corpus ranging from 2019 to 2022. Our results indicate that in response to the COVID pandemic, expression of political opinions increased. Using a well established taxonomy of policy preferences we analyse fine grained political views and highlight changes in distinct political categories. The
    
[^39]: OpinionConv: 通过基于真实主观体验的观点实现对话式产品搜索

    OpinionConv: Conversational Product Search with Grounded Opinions. (arXiv:2308.04226v1 [cs.HC])

    [http://arxiv.org/abs/2308.04226](http://arxiv.org/abs/2308.04226)

    OpinionConv是第一个用于模拟销售对话的对话式AI，通过利用产品评论作为观点的丰富来源，实现了对话和决策中的真实性和信息基础。

    

    在搜索产品时，他人的观点在做出明智决策方面起着重要作用。对产品的主观体验可以是有价值的信息来源。这在销售对话中也是如此，在这种对话中，客户和销售助手交换有关产品的事实和观点。然而，训练一个用于此类对话的AI是复杂的，因为语言模型由于缺乏真实世界的经验没有真实的观点。我们通过利用产品评论作为产品观点的丰富来源来解决这个问题，以真实主观叙述支持对话式AI。通过OpinionConv，我们开发了第一个模拟销售对话的对话式AI。为了验证生成的对话，我们进行了多个用户研究，结果显示生成的观点被认为是真实的。我们的评估员也确认了观点对于决策的信息基础的重要性。

    When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision-making.
    
[^40]: 迈向多参考时代 —— 解决NLG评估中的数据泄漏和参考多样性有限问题

    Towards Multiple References Era -- Addressing Data Leakage and Limited Reference Diversity in NLG Evaluation. (arXiv:2308.03131v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03131](http://arxiv.org/abs/2308.03131)

    本论文提出了使用多个参考来增强匹配指标与人类评估之间的一致性。在WMT Metrics基准中，多参考F200spBLEU相对于传统的单参考方法准确率提高了7.2\%，超过了基于神经网络的BERTscore的3.9\%的准确率提高。此外，该方法还可以在很大程度上缓解大型语言模型中的数据泄漏问题。

    

    N-gram匹配的评估指标，如BLEU和chrF，在各种自然语言生成（NLG）任务中被广泛使用。然而，最近的研究发现，这些基于匹配的指标与人类评估之间存在较弱的相关性，尤其是与基于神经网络的指标如BLEURT相比。在本文中，我们推测匹配指标性能瓶颈的原因可能是参考资料多样性有限。为了解决这个问题，我们提出利用"多个参考"来增强这些指标与人类评估之间的一致性。在WMT Metrics基准中，我们观察到多参考F200spBLEU相对于传统的单参考方法，准确率提高了7.2\%。值得注意的是，它还超过了基于神经网络的BERTscore，准确率提高了3.9\%。此外，我们观察到大型语言模型（LLMs）中的数据泄漏问题可以在很大程度上得到缓解通过我们的多参考方法。

    N-gram matching-based evaluation metrics, such as BLEU and chrF, are widely utilized across a range of natural language generation (NLG) tasks. However, recent studies have revealed a weak correlation between these matching-based metrics and human evaluations, especially when compared with neural-based metrics like BLEURT. In this paper, we conjecture that the performance bottleneck in matching-based metrics may be caused by the limited diversity of references. To address this issue, we propose to utilize \textit{multiple references} to enhance the consistency between these metrics and human evaluations. Within the WMT Metrics benchmarks, we observe that the multi-references F200spBLEU surpasses the conventional single-reference one by an accuracy improvement of 7.2\%. Remarkably, it also exceeds the neural-based BERTscore by an accuracy enhancement of 3.9\%. Moreover, we observe that the data leakage issue in large language models (LLMs) can be mitigated to a large extent by our multi
    
[^41]: 通过领域适应的最少到最多提示的方式实现文本到SQL的高效泛化

    Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting. (arXiv:2308.02582v1 [cs.CL])

    [http://arxiv.org/abs/2308.02582](http://arxiv.org/abs/2308.02582)

    该论文介绍了一种通过领域适应和最少到最多提示的方式实现文本到SQL的高效泛化的方法。通过离线抽样获取少量样本，并合成一个通用提示，避免了昂贵的测试时间样本检索，并通过自适应和分解的方法更好地处理跨领域和跨组合式的泛化。

    

    跨领域和跨组合式的文本到SQL语义解析的泛化是一项具有挑战性的任务。现有的基于大型语言模型（LLM）的解决方案依赖于从训练集中推理出少量样本，以合成每个自然语言（NL）测试查询的运行时提示。与此相反，我们设计了一种算法，该算法通过离线抽样从训练数据中获取少量样本，完全覆盖SQL子句、运算符和函数，并在允许的令牌长度范围内实现最大领域覆盖。这样可以合成一个固定的通用提示（GP），其中包含NL测试查询之间共用的多样化样本集，避免了昂贵的测试时间样本检索。我们还将GP自适应到目标数据库领域（DA-GP），以更好地处理跨领域泛化；然后采用分解的最少到最多提示（LTMP-DA-GP）来处理跨组合泛化。LTMP-DA-GP的合成是离线任务，

    Cross-domain and cross-compositional generalization of Text-to-SQL semantic parsing is a challenging task. Existing Large Language Model (LLM) based solutions rely on inference-time retrieval of few-shot exemplars from the training set to synthesize a run-time prompt for each Natural Language (NL) test query. In contrast, we devise an algorithm which performs offline sampling of a minimal set-of few-shots from the training data, with complete coverage of SQL clauses, operators and functions, and maximal domain coverage within the allowed token length. This allows for synthesis of a fixed Generic Prompt (GP), with a diverse set-of exemplars common across NL test queries, avoiding expensive test time exemplar retrieval. We further auto-adapt the GP to the target database domain (DA-GP), to better handle cross-domain generalization; followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle cross-compositional generalization. The synthesis of LTMP-DA-GP is an offline task, to
    
[^42]: 面向教育中人工智能协作混合论文的自动边界检测

    Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education. (arXiv:2307.12267v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12267](http://arxiv.org/abs/2307.12267)

    本研究探索了在教育领域中，由人类和生成性语言模型协作编写的混合文本的AI内容检测方法，将其形式化为识别转换点的任务，以区分人类编写和AI生成的部分。

    

    最近的大型语言模型（如ChatGPT）能够在提供具体指导的情况下生成类似于人类的流畅回答。尽管承认技术进步带来的便利，教育者也担心学生可能利用语言模型来完成写作任务并将其假冒为自己的原创作品。虽然有很多AI内容检测研究是基于这些担忧进行的，但大多数之前的研究将AI内容检测建模为一个分类问题，假设一个文本要么完全由人类编写，要么完全由AI生成。在本研究中，我们研究了AI内容检测在一个少有探索但却现实的情况下，即检测的文本由人类和生成性语言模型（即混合文本）协作编写。我们首先将检测任务形式化为从给定的混合文本中识别人类编写内容和AI生成内容之间的转换点（边界检测）。

    The recent large language models (LLMs), e.g., ChatGPT, have been able to generate human-like and fluent responses when provided with specific instructions. While admitting the convenience brought by technological advancement, educators also have concerns that students might leverage LLMs to complete their writing assignments and pass them off as their original work. Although many AI content detection studies have been conducted as a result of such concerns, most of these prior studies modeled AI content detection as a classification problem, assuming that a text is either entirely human-written or entirely AI-generated. In this study, we investigated AI content detection in a rarely explored yet realistic setting where the text to be detected is collaboratively written by human and generative LLMs (i.e., hybrid text). We first formalized the detection task as identifying the transition points between human-written content and AI-generated content from a given hybrid text (boundary det
    
[^43]: Retentive Network: 作为大型语言模型的Transformer的继任者

    Retentive Network: A Successor to Transformer for Large Language Models. (arXiv:2307.08621v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08621](http://arxiv.org/abs/2307.08621)

    Retentive Network（RetNet）作为大型语言模型的基础架构，实现了训练并行、低成本推理和良好的性能。通过并行、循环和分块循环三种计算范式，RetNet具有训练并行化、低成本推理和高效的长序列建模的特点。

    

    在这项工作中，我们提出了Retentive Network (RetNet)作为大型语言模型的基础架构，同时实现了训练并行、低成本推理和良好的性能。我们从理论上推导出了循环和注意力之间的连接。然后，我们提出了序列建模的保留机制，支持三种计算范式，即并行、循环和分块循环。具体而言，并行表示允许进行训练并行化。循环表示能够实现低成本的$O(1)$推理，从而提高解码吞吐量、延迟和GPU内存，同时不损失性能。分块循环表示便于使用线性复杂度进行高效的长序列建模，其中每个块可以并行编码，同时进行循环摘要。语言建模实验结果表明，RetNet实现了良好的扩展结果、并行训练、低成本部署和高效的推理。

    In this work, we propose Retentive Network (RetNet) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost $O(1)$ inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that RetNet achieves favorable scaling results, parallel training, low-cost deployment, and efficient i
    
[^44]: AutoHint: 自动提示生成与优化的新框架

    AutoHint: Automatic Prompt Optimization with Hint Generation. (arXiv:2307.07415v1 [cs.CL])

    [http://arxiv.org/abs/2307.07415](http://arxiv.org/abs/2307.07415)

    本文介绍了AutoHint，一种用于大型语言模型的自动提示生成和优化的新框架。该方法通过从输入-输出演示中生成提示，并利用上下文学习和零样本学习的优点，优化原始提示，从而提高了大型语言模型在特定任务上的表现。

    

    本文提出了AutoHint，一种用于大型语言模型（LLM）的自动提示工程和优化的新框架。虽然LLM在各种任务中展示了出色的注释能力，但将此能力应用于特定任务的关键在于开发高质量的提示。因此，我们提出了一种框架，通过将从输入-输出演示中派生的丰富指导纳入原始提示，以继承上下文学习和零样本学习的优点。我们将这种丰富称为“提示”，并提出了一种从标记数据中自动生成提示的框架。具体而言，从一个初始提示开始，我们的方法首先指导LLM从错误预测中推断出选定样本的新提示，然后从每个样本的提示中进行总结，并将结果添加回初始提示，形成一个新的丰富指导。该方法在BIG-Bench指令推导任务上进行了评估。

    This paper presents AutoHint, a novel framework for automatic prompt engineering and optimization for Large Language Models (LLM). While LLMs have demonstrated remarkable ability in achieving high-quality annotation in various tasks, the key to applying this ability to specific tasks lies in developing high-quality prompts. Thus we propose a framework to inherit the merits of both in-context learning and zero-shot learning by incorporating enriched instructions derived from input-output demonstrations to optimize original prompt. We refer to the enrichment as the hint and propose a framework to automatically generate the hint from labeled data. More concretely, starting from an initial prompt, our method first instructs a LLM to deduce new hints for selected samples from incorrect predictions, and then summarizes from per-sample hints and adds the results back to the initial prompt to form a new, enriched instruction. The proposed method is evaluated on the BIG-Bench Instruction Induct
    
[^45]: 一种新型的与平台无关的多模态深度学习模型，用于识别社交媒体上的促进饮食紊乱内容

    A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v1 [cs.LG])

    [http://arxiv.org/abs/2307.06775](http://arxiv.org/abs/2307.06775)

    本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。

    

    在过去的十年中，饮食紊乱的诊断和与之相关的死亡数量大幅增加，尤其是在新冠疫情期间。这种巨大增长部分来源于疫情的压力，但也与社交媒体的暴露增加有关，社交媒体上充斥着促进饮食紊乱的内容。这些内容可以诱发观看者的饮食紊乱。本研究旨在创建一个多模态深度学习模型，能够基于视觉和文本数据的组合判断给定的社交媒体帖子是否促进饮食紊乱。从Twitter收集了一个带有标签的推文数据集，对其进行了十二个深度学习模型的训练和测试。根据模型的性能，最有效的深度学习模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的多模态融合模型，准确率和F1分数分别达到95.9%和0.959。RoBERTa和MaxViT融合模型可以有效地识别社交媒体上的促进饮食紊乱的内容。

    Over the last decade, there has been a vast increase in eating disorder diagnoses and eating disorder-attributed deaths, reaching their zenith during the Covid-19 pandemic. This immense growth derived in part from the stressors of the pandemic but also from increased exposure to social media, which is rife with content that promotes eating disorders. Such content can induce eating disorders in viewers. This study aimed to create a multimodal deep learning model capable of determining whether a given social media post promotes eating disorders based on a combination of visual and textual data. A labeled dataset of Tweets was collected from Twitter, upon which twelve deep learning models were trained and tested. Based on model performance, the most effective deep learning model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, attaining accuracy and F1 scores of 95.9% and 0.959 respectively. The RoBERTa and MaxViT fusion
    
[^46]: 使用大型语言模型实现无监督校准的文本分类方法的先验适应

    Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models. (arXiv:2307.06713v1 [cs.CL])

    [http://arxiv.org/abs/2307.06713](http://arxiv.org/abs/2307.06713)

    本文提出了一种使用大型语言模型进行文本分类的无监督校准方法，通过调整先验类别分布，实现在没有标记样本和仅少量领域内样本查询的情况下执行任务。

    

    当前有许多自然语言任务正在使用大规模语言模型（LLM）进行研究。这些模型通常通过大量无监督文本数据进行训练，并通过微调、校准或上下文学习等方法进行适应以执行下游自然语言任务。在本研究中，我们提出了一种方法，通过调整先验类别分布，实现在没有标记样本和仅少量领域内样本查询的情况下执行文本分类任务。该方法将LLM视为黑盒，在模型屏障中添加了一个阶段，用于校准模型后验以完成任务。结果表明，这些方法在不同数量的提示训练样本和无适应数据下的校准方法中优于未适应的模型。

    A wide variety of natural language tasks are currently being addressed with large-scale language models (LLMs). These models are usually trained with a very large amount of unsupervised text data and adapted to perform a downstream natural language task using methods like fine-tuning, calibration or in-context learning. In this work, we propose an approach to adapt the prior class distribution to perform text classification tasks without the need for labelled samples and only few in-domain sample queries. The proposed approach treats the LLM as a black box, adding a stage where the model posteriors are calibrated to the task. Results show that these methods outperform the un-adapted model for different number of training shots in the prompt and a previous approach were calibration is performed without using any adaptation data.
    
[^47]: 超越显而易见：评估语言模型在真实情境中的推理能力——基于生活景观推理基准(LSR-Benchmark)的研究

    Beyond the Obvious: Evaluating the Reasoning Ability In Real-life Scenarios of Language Models on Life Scapes Reasoning Benchmark~(LSR-Benchmark). (arXiv:2307.05113v1 [cs.CL])

    [http://arxiv.org/abs/2307.05113](http://arxiv.org/abs/2307.05113)

    本论文介绍了一个新的数据集LSR-Benchmark，旨在评估语言模型在真实情境中的推理能力。结果显示，人类在这方面表现明显优于最先进的语言模型，说明机器学习模型在理解日常生活方面仍面临挑战。

    

    本文介绍了生活景观推理基准 (LSR-Benchmark)，这是一个针对真实情境推理的新型数据集，旨在弥补人工神经网络在日常背景下推理能力的差距。与领域知识推理数据集不同，LSR-Benchmark包含自由文本格式的问题，提供有关真实生活情景、人类行为和角色的丰富信息。该数据集由来自开源在线来源的2162个问题组成，并进行手动注释以提高质量。实验使用了最先进的语言模型，如gpt3.5-turbo和instruction fine-tuned llama模型，测试其在LSR-Benchmark上的性能。结果表明，人类明显优于这些模型，这表明机器学习模型在理解日常生活方面仍存在挑战。

    This paper introduces the Life Scapes Reasoning Benchmark (LSR-Benchmark), a novel dataset targeting real-life scenario reasoning, aiming to close the gap in artificial neural networks' ability to reason in everyday contexts. In contrast to domain knowledge reasoning datasets, LSR-Benchmark comprises free-text formatted questions with rich information on real-life scenarios, human behaviors, and character roles. The dataset consists of 2,162 questions collected from open-source online sources and is manually annotated to improve its quality. Experiments are conducted using state-of-the-art language models, such as gpt3.5-turbo and instruction fine-tuned llama models, to test the performance in LSR-Benchmark. The results reveal that humans outperform these models significantly, indicating a persisting challenge for machine learning models in comprehending daily human life.
    
[^48]: 知道如何与知道什么：用户手册机器阅读理解的新任务

    Knowing-how & Knowing-that: A New Task for Machine Reading Comprehension of User Manuals. (arXiv:2306.04187v1 [cs.CL])

    [http://arxiv.org/abs/2306.04187](http://arxiv.org/abs/2306.04187)

    该论文提出了知道如何与知道什么的任务，要求模型回答关于用户手册的基本事实、流程，并解决一些不一致的问题。他们采用图(TARA)来联合表示步骤和事实，成功地解决了这个任务，并构建了一个注释数据集，以测试模型在回答实际问题方面的能力。

    

    用户手册的机器阅读理解具有巨大的客户服务潜力。然而，当前的方法在回答复杂问题方面存在困难。因此，我们介绍了知道如何与知道什么的任务，要求模型回答关于用户手册的基本事实、流程，并解决一些不一致的问题。我们通过在图(TARA)中联合表示步骤和事实来解决这个任务，支持各种问题的统一推理。为了进行系统化的基准评估研究，我们设计了一种启发式方法，自动将用户手册解析成TARA，并构建了一个注释数据集，以测试模型在回答实际问题方面的能力。实证结果表明，将用户手册表示为TARA是用户手册机器阅读理解的理想解决方案。对TARA的深入研究进一步阐明了未来用户手册表示的问题和广泛的影响。我们希望我们的工作可以将用户手册的机器阅读理解推向更实用和有效的水平。

    The machine reading comprehension (MRC) of user manuals has huge potential in customer service. However,current methods have trouble answering complex questions. Therefore, we introduce the Knowing-how & Knowing-that task that requires the model to answer factoid-style, procedure-style, and inconsistent questions about user manuals. We resolve this task by jointly representing the steps and facts in a graph (TARA), which supports a unified inference of various questions. Towards a systematical benchmarking study, we design a heuristic method to automatically parse user manuals into TARAs and build an annotated dataset to test the model's ability in answering real-world questions. Empirical results demonstrate that representing user manuals as TARAs is a desired solution for the MRC of user manuals. An in-depth investigation of TARA further sheds light on the issues and broader impacts of future representations of user manuals. We hope our work can move the MRC of user manuals to a more
    
[^49]: 对抗性词汇稀释作为低资源情况下的文本数据增强方法

    AdversarialWord Dilution as Text Data Augmentation in Low-Resource Regime. (arXiv:2305.09287v1 [cs.CL])

    [http://arxiv.org/abs/2305.09287](http://arxiv.org/abs/2305.09287)

    本文提出了一种对抗性词汇稀释方法，用于作为低资源情况下的文本数据增强方法，能够生成硬正例以有效地训练文本分类模型。

    

    在低资源情况下，数据增强被广泛应用于文本分类中。然而，如何生成硬正例用作数据增强的有效方法却仍有待探索。本文提出了一种对抗性词汇稀释方法，该方法能够生成硬正例作为文本数据增强，从而有效地训练低资源文本分类模型。

    Data augmentation is widely used in text classification, especially in the low-resource regime where a few examples for each class are available during training. Despite the success, generating data augmentations as hard positive examples that may increase their effectiveness is under-explored. This paper proposes an Adversarial Word Dilution (AWD) method that can generate hard positive examples as text data augmentations to train the low-resource text classification model efficiently. Our idea of augmenting the text data is to dilute the embedding of strong positive words by weighted mixing with unknown-word embedding, making the augmented inputs hard to be recognized as positive by the classification model. We adversarially learn the dilution weights through a constrained min-max optimization process with the guidance of the labels. Empirical studies on three benchmark datasets show that AWD can generate more effective data augmentations and outperform the state-of-the-art text data 
    
[^50]: AttentionViz：Transformer Attention的全局视图

    AttentionViz: A Global View of Transformer Attention. (arXiv:2305.03210v1 [cs.HC])

    [http://arxiv.org/abs/2305.03210](http://arxiv.org/abs/2305.03210)

    这篇论文介绍了AttentionViz，一种以联合嵌入为基础的交互式可视化工具，用于帮助研究人员理解Transformer中的自我注意机制。该方法使得可以全局分析多个输入序列的注意力模式，提高对模型的理解并通过多个应用场景和专家反馈提供新的交互见解。

    

    Transformer模型正在革新机器学习，但它们的内部运作仍然神秘莫测。在本文中，我们提出了一种新的可视化技术，旨在帮助研究人员理解Transformer中的自我注意机制，使这些模型能够学习序列中元素之间丰富的上下文关系。我们方法的主要思想是可视化Transformer模型用于计算注意力的查询和键向量的联合嵌入。与以前的注意力可视化技术不同，我们的方法能够分析多个输入序列的全局模式。我们基于这些联合查询-键嵌入创建了一个交互式可视化工具AttentionViz，并将其用于研究语言和视觉变压器中的注意机制。通过几个应用场景和专家反馈，我们展示了我们的方法在提高模型理解和提供有关查询-键交互的新见解方面的实用性。

    Transformer models are revolutionizing machine learning, but their inner workings remain mysterious. In this work, we present a new visualization technique designed to help researchers understand the self-attention mechanism in transformers that allows these models to learn rich, contextual relationships between elements of a sequence. The main idea behind our method is to visualize a joint embedding of the query and key vectors used by transformer models to compute attention. Unlike previous attention visualization techniques, our approach enables the analysis of global patterns across multiple input sequences. We create an interactive visualization tool, AttentionViz, based on these joint query-key embeddings, and use it to study attention mechanisms in both language and vision transformers. We demonstrate the utility of our approach in improving model understanding and offering new insights about query-key interactions through several application scenarios and expert feedback.
    
[^51]: 基于医学提示的语言增强Transformer编码器的医疗干预持续时间估计

    Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts. (arXiv:2303.17408v1 [cs.CL])

    [http://arxiv.org/abs/2303.17408](http://arxiv.org/abs/2303.17408)

    使用语言增强Transformer编码器，并结合医学提示，将结构化、非结构化的临床数据投影到一个语言潜空间中，以实现更精确的医学干预持续时间估计。

    

    近年来，基于电子病历(EHRs)估计医疗干预的持续时间在临床决策支持领域引起了重视。然而，当前的模型主要关注结构化数据，忽略了来自非结构化的临床自由文本数据的信息。为了解决这个问题，我们提出了一个新颖的语言增强Transformer-based框架，它使用经过预训练的句子编码器将所有相关的临床数据模态（连续、分类、二进制和自由文本特征）投影到一个协调的语言潜空间中，借助医学提示。所提出的方法使得不同模态的信息在单元变压器编码器中集成起来，从而实现更准确的医学干预持续时间估计。我们在美国（ICU住院时间估计）和亚洲（手术持续时间预测）医学数据集上的实验结果证明了我们提出的框架的有效性。

    In recent years, estimating the duration of medical intervention based on electronic health records (EHRs) has gained significant attention in the filed of clinical decision support. However, current models largely focus on structured data, leaving out information from the unstructured clinical free-text data. To address this, we present a novel language-enhanced transformer-based framework, which projects all relevant clinical data modalities (continuous, categorical, binary, and free-text features) into a harmonized language latent space using a pre-trained sentence encoder with the help of medical prompts. The proposed method enables the integration of information from different modalities within the cell transformer encoder and leads to more accurate duration estimation for medical intervention. Our experimental results on both US-based (length of stay in ICU estimation) and Asian (surgical duration prediction) medical datasets demonstrate the effectiveness of our proposed framewor
    
[^52]: MaMMUT: 一种用于多模态任务联合学习的简单架构

    MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks. (arXiv:2303.16839v1 [cs.CV])

    [http://arxiv.org/abs/2303.16839](http://arxiv.org/abs/2303.16839)

    提出了一种名为MaMMUT的简单模型，可以通过两步方法容纳对比和生成学习，并在联合训练不同的视觉语言任务时表现出很高的效力。

    

    语言模型的发展已从编码-解码转向仅解码的设计。此外，普遍认为，最流行的两种多模态任务，生成任务和对比任务，往往互相冲突，难以在一个架构中容纳，并进一步需要用于下游任务的复杂调整。我们提出了一种新的培训范式，用于多模态任务的仅解码模型，这在联合学习这些不同的视觉语言任务方面非常有效。这是通过一个简单的模型MaMMUT实现的。它由单一的视觉编码器和一个文本解码器组成，并能够通过文本解码器上的新的两步方法容纳对比和生成学习。我们证明这些不同目标任务的联合训练是简单的，有效的，并最大化了模型的权重共享。此外，相同的架构使得对开放词汇对象检测的简单扩展成为可能。

    The development of language models have moved from encoder-decoder to decoder-only designs. In addition, the common knowledge has it that the two most popular multimodal tasks, the generative and contrastive tasks, tend to conflict with one another, are hard to accommodate in one architecture, and further need complex adaptations for downstream tasks. We propose a novel paradigm of training with a decoder-only model for multimodal tasks, which is surprisingly effective in jointly learning of these disparate vision-language tasks. This is done with a simple model, called MaMMUT. It consists of a single vision encoder and a text decoder, and is able to accommodate contrastive and generative learning by a novel two-pass approach on the text decoder. We demonstrate that joint training of these diverse-objective tasks is simple, effective, and maximizes the weight-sharing of the model. Furthermore, the same architecture enables straightforward extensions to open-vocabulary object detection 
    
[^53]: 大规模语言模型生成推理的成本效益超参数优化

    Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference. (arXiv:2303.04673v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04673](http://arxiv.org/abs/2303.04673)

    本文研究了优化大规模语言模型生成推理的成本效益超参数，通过经济的超参数优化和基于成本的修剪，提出了EcoOptiGen框架，该框架在使用GPT-3.5/GPT-4模型的任务中表现出有效性。

    

    大规模语言模型（LLM）在其生成能力方面引起了广泛关注，从而推动了各种商业应用的发展。使用这些模型的高成本驱使应用程序构建者在有限的推理预算下最大化生成价值。本文提出了一项关于优化推理超参数（如回复数量、温度和最大token数）的研究，这显著影响了文本生成的效用/成本。我们设计了一个名为EcoOptiGen的框架，它利用经济的超参数优化和基于成本的修剪。通过在各种任务上使用GPT-3.5/GPT-4模型进行实验，验证了其有效性。EcoOptiGen已在FLAML库的`autogen'包中实现：\url{https://aka.ms/autogen}。

    Large Language Models (LLMs) have sparked significant interest in their generative capabilities, leading to the development of various commercial applications. The high cost of using the models drives application builders to maximize the value of generation under a limited inference budget. This paper presents a study of optimizing inference hyperparameters such as the number of responses, temperature and max tokens, which significantly affects the utility/cost of text generation. We design a framework named EcoOptiGen which leverages economical hyperparameter optimization and cost-based pruning. Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its effectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML library: \url{https://aka.ms/autogen}.
    
[^54]: 一个适用于知识图谱的通用问答平台

    A Universal Question-Answering Platform for Knowledge Graphs. (arXiv:2303.00595v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.00595](http://arxiv.org/abs/2303.00595)

    本文提出了KGQAn，一个通用的问答系统，它无需针对每个目标知识图谱进行定制。通过新颖的形式化方法，将问题转换为中间的抽象表示，从而实现了将自然语言问题转换为SPARQL查询的目标。

    

    知识图谱是以RDF引擎存储的来自不同应用领域的知识。通过SPARQL端点可以在Web上访问知识图谱。为了正确表达一个符合规范的SPARQL查询，需要了解图结构和其组成部分的确切URI，这对于普通用户来说是不现实的。问答系统通过将自然语言问题转换为SPARQL来提供帮助。现有的问答系统通常基于应用特定的人工策略，或者需要先验信息、昂贵的预处理和模型调整来适配每个目标知识图谱。因此，它们很难推广到广泛的应用和知识图谱。本文提出了KGQAn，一个不需要针对每个目标知识图谱进行定制的通用问答系统。KGQAn不使用人工策略，而是将问题理解作为一个文本生成问题来进行新颖的形式化，通过神经序列到序列模型将问题转换为中间的抽象表示。

    Knowledge from diverse application domains is organized as knowledge graphs (KGs) that are stored in RDF engines accessible in the web via SPARQL endpoints. Expressing a well-formed SPARQL query requires information about the graph structure and the exact URIs of its components, which is impractical for the average user. Question answering (QA) systems assist by translating natural language questions to SPARQL. Existing QA systems are typically based on application-specific human-curated rules, or require prior information, expensive pre-processing and model adaptation for each targeted KG. Therefore, they are hard to generalize to a broad set of applications and KGs.  In this paper, we propose KGQAn, a universal QA system that does not need to be tailored to each target KG. Instead of curated rules, KGQAn introduces a novel formalization of question understanding as a text generation problem to convert a question into an intermediate abstract representation via a neural sequence-to-se
    

