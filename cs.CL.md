# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Word-Level ASR Quality Estimation for Efficient Corpus Sampling and Post-Editing through Analyzing Attentions of a Reference-Free Metric.](http://arxiv.org/abs/2401.11268) | 本研究介绍了一种使用质量估计度量来增强自动语音识别系统(XAI)的方法。实验证明了NoRefER度量在识别单词错误和提供有价值的模型行为见解方面的能力。研究还发现NoRefER在语料库构建和后期编辑工作流程中的实用性，表明其有潜力成为提高ASR系统效率和可解释性的关键工具。 |
| [^2] | [Drop your Decoder: Pre-training with Bag-of-Word Prediction for Dense Passage Retrieval.](http://arxiv.org/abs/2401.11248) | 本研究介绍了一种使用词袋预测进行预训练的密集通行检索方法，通过替换解码器实现了高效压缩词汇信号，显著改进了输入令牌的条款覆盖。 |
| [^3] | [Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine.](http://arxiv.org/abs/2401.11246) | Prompt-RAG是一种在小众领域中增强了大型语言模型性能的新方法，与传统的RAG模型不同，它不需要使用嵌入向量。通过问答机器人应用程序的评估，结果表明Prompt-RAG优于现有模型，包括ChatGPT。 |
| [^4] | [End-to-End Argument Mining over Varying Rhetorical Structures.](http://arxiv.org/abs/2401.11218) | 本研究通过使用深度依存解析模型，利用修辞关系和修辞结构训练数据增强的方法，实现了跨不同修辞结构进行端到端的论证分析。初步结果表明，在不同修辞结构下进行的论证解析是有效的。 |
| [^5] | [Unfair TOS: An Automated Approach using Customized BERT.](http://arxiv.org/abs/2401.11207) | 本研究利用定制的BERT与SVC的集成，针对ToS文档中的不公平条款进行了SOTA级别的检测，取得了出色的结果。 |
| [^6] | [InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance.](http://arxiv.org/abs/2401.11206) | InferAligner是一种新颖的推理时间对齐方法，利用跨模型引导实现无害化对齐，可以有效地应用于领域特定模型中。 |
| [^7] | [How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation.](http://arxiv.org/abs/2401.11185) | 万物普及的大型语言模型的出现既推动了动态对抗性问题生成的发展，又阻碍了其进展。为了解决这个问题，我们为作者提供了LLMs和检索模型的写作指导，提出了新的度量标准和激励机制，并创建了一个新的对抗性问题数据集。 |
| [^8] | [Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities.](http://arxiv.org/abs/2401.11143) | 该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。 |
| [^9] | [Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines.](http://arxiv.org/abs/2401.11120) | 该论文研究了将临床实践指南纳入大型语言模型以增强临床决策支持的方法。他们开发了三种方法，并对四个大型语言模型进行了评估，在COVID-19门诊治疗方面取得了较高的性能。 |
| [^10] | [Exploiting Duality in Open Information Extraction with Predicate Prompt.](http://arxiv.org/abs/2401.11107) | 本文提出了一种新的生成式OpenIE模型DualOIE，通过实现一个双重任务，即将句子中的三元组转化为句子，来更有效地提取复杂的三元组。此方法鼓励模型正确识别句子结构，从而有助于提取所有潜在的三元组。 |
| [^11] | [Mining experimental data from Materials Science literature with Large Language Models.](http://arxiv.org/abs/2401.11052) | 本研究评估了使用大型语言模型从材料科学文献中提取结构化信息的能力，并引入了一种新颖的方法来处理材料科学信息的复杂性。在命名实体识别和关系提取任务上，LLMs与传统模型相比表现有限，但在少数-shot提示下有一定的改进。 |
| [^12] | [PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge.](http://arxiv.org/abs/2401.11048) | PubTator 3.0是一个使用AI技术的生物医学文献资源，提供语义和关系搜索，以及高级搜索功能和大规模分析。与PubMed和Google Scholar相比，在检索精度和文章数量上都有明显优势。同时，与ChatGPT（GPT-4）API集成可以进一步提高搜索结果的质量。 |
| [^13] | [FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for Large Language Models' Training?.](http://arxiv.org/abs/2401.11033) | 这项工作介绍了一个将FAIR数据原则嵌入到大型语言模型训练中的框架，并提供了整合指南和检查清单。通过一个案例研究，展示了在符合FAIR标准的数据集中识别和减轻偏见的实际应用。 |
| [^14] | [Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning.](http://arxiv.org/abs/2401.11021) | 提出了一种基于Transformer模型的方法来检测社交媒体上的多语言仇恨言论。该模型在意大利语、英语、德语和孟加拉语上进行了测试，并取得了比现有模型更高的成功率。 |
| [^15] | [The Radiation Oncology NLP Database.](http://arxiv.org/abs/2401.10995) | 放射肿瘤学自然语言处理数据库（ROND）是第一个专门针对放射肿瘤学的自然语言处理数据集，其中包含了逻辑推理、文本分类、命名实体识别等多个任务，并且还开发了一个指令对数据集和相应的语言模型CancerChat。 |
| [^16] | [RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation.](http://arxiv.org/abs/2401.10940) | RELIANCE是一个可靠的集成学习系统，用于评估信息和新闻的可信度。它通过整合多个基本模型的优势，提供了对可信和不可信信息源的准确区分，并在信息和新闻可信度评估方面优于基准模型。 |
| [^17] | [Towards building a monitoring platform for a challenge-oriented smart specialisation with RIS3-MCAT.](http://arxiv.org/abs/2401.10900) | 构建了一个面向挑战导向的智能专业化监测平台RIS3-MCAT，利用开放数据、语义分析和数据可视化技术，以监测挑战导向智能专业化的加泰罗尼亚为例，实现了对大量文本进行详细研究的分析和可视化。 |
| [^18] | [Location Sensitive Embedding for Knowledge Graph Embedding.](http://arxiv.org/abs/2401.10893) | 这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。 |
| [^19] | [Knowledge Fusion of Large Language Models.](http://arxiv.org/abs/2401.10491) | 本文介绍了一种大型语言模型知识融合的方法，通过将现有预训练的语言模型合并为一个更强大的模型，从而提高目标模型的能力，验证实验结果证实了该方法的有效性。 |
| [^20] | [Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition.](http://arxiv.org/abs/2401.10337) | 该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。 |
| [^21] | [Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction.](http://arxiv.org/abs/2401.10189) | 这篇论文提出了一种名为Chem-FINESE的方法来处理化学领域中细粒度少样本实体提取的问题。该方法通过使用序列到序列的实体提取器和自我验证模块来从输入句子中提取命名实体并重构原始输入句子。实验证明了该方法的有效性和可行性。 |
| [^22] | [Towards Hierarchical Spoken Language Dysfluency Modeling.](http://arxiv.org/abs/2401.10015) | 本论文介绍了一种名为H-UDM的层次化口语淤塞建模方法，它能够解决口语淤塞转录和检测问题，并且消除了对大量手动注释的需求。实验结果证明了该方法在转录和检测任务中的有效性和鲁棒性。 |
| [^23] | [All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks.](http://arxiv.org/abs/2401.09798) | 本研究提出了一种简单的黑盒方法，用于生成越狱攻击提示，克服了现有方法的复杂性和计算成本的限制。该方法通过使用语言模型自身，将有害提示重写为非有害表达，实现了超过80%的攻击成功率，并且即使模型更新，效果仍然有效。 |
| [^24] | [Machines Do See Color: A Guideline to Classify Different Forms of Racist Discourse in Large Corpora.](http://arxiv.org/abs/2401.09333) | 本文提供了一个逐步可推广的准则，用于在大规模语料库中识别和分类不同形式的种族主义言论。通过对种族主义的概念化和上下文化，以及使用XLM-R和XLM-R-Racismo模型，我们展示了在大规模语料库中进行种族主义分类的优势。 |
| [^25] | [Code Simulation Challenges for Large Language Models.](http://arxiv.org/abs/2401.09074) | 大型语言模型在模拟计算机代码和算法执行方面遇到挑战，性能随着代码长度的增加而迅速下降。在处理短程序或标准过程时，它们能以低错误率按顺序执行指令，但对于复杂的程序，特别是包含关键路径和冗余指令的程序，模拟效果较差。我们提出了一种逐行模拟代码执行的方法来解决这个问题。 |
| [^26] | [Augmenting Math Word Problems via Iterative Question Composing.](http://arxiv.org/abs/2401.09003) | 本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。 |
| [^27] | [Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering.](http://arxiv.org/abs/2401.07510) | 开发用于生物学和医学的ChatGPT，通过自然语言处理和多模态范式，加速了医学问题回答的进展，并且能够处理医学环境中的大规模、多样化、无标签数据分析场景。 |
| [^28] | [Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks.](http://arxiv.org/abs/2401.05949) | 本研究发现上下文学习范式在大型语言模型中存在漏洞，攻击者可以通过污染示范上下文来操控模型行为，而无需进行微调。这项研究设计了一种名为ICLAttack的后门攻击方法，可以通过污染示范样本和提示来使模型按照预定义的意图行事。 |
| [^29] | [The Impact of Reasoning Step Length on Large Language Models.](http://arxiv.org/abs/2401.04925) | 本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。 |
| [^30] | [Agent Alignment in Evolving Social Norms.](http://arxiv.org/abs/2401.04620) | 本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。 |
| [^31] | [MR-GSM8K: A Meta-Reasoning Revolution in Large Language Model Evaluation.](http://arxiv.org/abs/2312.17080) | 本文介绍了一种新的大型语言模型评估范式，通过挑战这些模型进行元推理，从而有效区分它们的认知能力。这一范式的重要性在于能够揭示出传统基准测试无法发现的模型的潜在认知缺陷。 |
| [^32] | [A Comprehensive Analysis of the Effectiveness of Large Language Models as Automatic Dialogue Evaluators.](http://arxiv.org/abs/2312.15407) | 本研究对利用大型语言模型（LLMs）进行自动对话评估的应用进行了全面研究，发现LLMs在对话和转向层面上具有多维评估能力，并提出了一套全面的评估方法。 |
| [^33] | [Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation.](http://arxiv.org/abs/2312.11532) | 本文介绍了一种利用隐变量码本实现灵活的主题导向文档生成的新方法，通过名为TVQ-VAE的生成式主题模型，可以有效捕捉主题上下文，并支持灵活形式的文档生成。 |
| [^34] | [Towards Optimal Statistical Watermarking.](http://arxiv.org/abs/2312.07930) | 追求最优统计水印技术。通过将统计水印技术视为假设检验问题并引入伪随机生成器，我们实现了输出令牌和拒绝区域的耦合，实现了第一类错误和第二类错误之间的非平凡权衡，同时提出了最统一最有力的水印和最小化第二类错误的解决方案。我们还提供了独立同分布令牌数量的上下界，突显了改进的潜力。此外，我们还探讨了鲁棒性水印问题。 |
| [^35] | [Assertion Enhanced Few-Shot Learning: Instructive Technique for Large Language Models to Generate Educational Explanations.](http://arxiv.org/abs/2312.03122) | 本研究提出了一种强化断言的少样本学习技术，用于大型语言模型生成精确、详细的教育解释。实验结果显示，该方法在解释准确性上提升了15%，获得了教师评估为高质量的解释。 |
| [^36] | [GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge Graphs.](http://arxiv.org/abs/2312.02317) | GNN2R是一种基于图神经网络的两步推理模型，通过弱监督训练，能够在知识图谱问答中提供最终答案以及推理子图的理由。该方法解决了现有方法缺乏解释以及效率低下的问题。 |
| [^37] | [Annotation Sensitivity: Training Data Collection Methods Affect Model Performance.](http://arxiv.org/abs/2311.14212) | 该研究发现训练数据收集方法对注释本身和下游模型性能产生影响。在对仇恨言论和冒犯性语言进行注释收集的实验中，发现注释工具的设计选择会对模型的性能产生明显差异。 |
| [^38] | [Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code.](http://arxiv.org/abs/2311.07989) | 这篇论文系统地回顾了代码处理方面的语言模型的最新进展，涵盖了50多个模型、30多个评估任务、170多个数据集和700多个相关工作。它突出了代码建模从统计模型和RNN到预训练的Transformer和LLM之间的历史转变，并讨论了代码特定的特性和关键挑战。 |
| [^39] | [Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment.](http://arxiv.org/abs/2310.15823) | 本论文介绍了在KSAA-RD共享任务中Rosetta Stone的应用，将语言建模应用到词--定义对齐中。论文通过使用一组微调的阿拉伯BERT模型来预测给定定义的词嵌入，从而实现了阿拉伯词的向量表示。 |
| [^40] | [IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models.](http://arxiv.org/abs/2310.10873) | 本文提出了一种影响驱动的选择性注释方法，用于在大型语言模型中改善上下文学习。该方法通过选择关键的未标记数据子集进行注释，在降低注释成本的同时提高了上下文示例的质量。 |
| [^41] | [EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling.](http://arxiv.org/abs/2310.04691) | EMO提出了地球移动距离优化（EMO）来解决语言模型中的退化现象。EMO利用了地球移动距离的特性，并引入了一个可行的上界来简化训练。经过评估，发现EMO在语言模型上有显著的改进。 |
| [^42] | [MathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V, Bard, and Other Large Multimodal Models.](http://arxiv.org/abs/2310.02255) | 本论文提出了MathVista，这是一个评估视觉场景中数学推理能力的基准测试。通过对12个著名的基础模型进行全面的定量评估，发现最好的GPT-4V模型相对于第二名的Bard模型在准确率上提升了15.1%。 |
| [^43] | [TWIZ-v2: The Wizard of Multimodal Conversational-Stimulus.](http://arxiv.org/abs/2310.02118) | TWIZ-v2是一个多模态对话刺激的巫师助手，旨在通过以人性化的方式提供信息、利用多种模态进行刺激以及改进对未见过场景的交互鲁棒性来引导用户成功完成复杂的手动任务。 |
| [^44] | [Who is ChatGPT? Benchmarking LLMs' Psychological Portrayal Using PsychoBench.](http://arxiv.org/abs/2310.01386) | 本文提出了PsychoBench框架，用于评估LLMs的心理因素，并对text-davinci-003、gpt-3.5-turbo、gpt-4、LLaMA-2-7b和LLaMA-2-13b等五个模型进行研究。 |
| [^45] | [GenSim: Generating Robotic Simulation Tasks via Large Language Models.](http://arxiv.org/abs/2310.01361) | GenSim通过利用大型语言模型自动生成丰富的模拟环境和专家示范，解决了目前模拟数据中缺乏任务级别多样性的问题，提高了机器人策略在任务级别上的泛化能力。 |
| [^46] | [Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection.](http://arxiv.org/abs/2309.12247) | 大型语言模型对于假新闻检测的潜力仍未得到充分探索。实证研究发现，尽管复杂的大型语言模型能够揭示假新闻并提供多角度解释，但仍不如经过fine-tuned的小型语言模型表现出色。当前的大型语言模型可能无法取代小型语言模型，但可以作为一个良好的辅助顾问。 |
| [^47] | [ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events.](http://arxiv.org/abs/2309.12244) | ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。 |
| [^48] | [DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning.](http://arxiv.org/abs/2309.05173) | DePT通过将软提示分解为较短的软提示和一对低秩矩阵，并用两个不同的学习率来优化，以解决提示调整对训练和推理时间以及内存使用的影响，从而实现更好的性能。 |
| [^49] | [ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning.](http://arxiv.org/abs/2309.01538) | 本论文提出了一个框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。该框架通过充分利用知识图谱的语义和结构信息，能够提高推理性能并提供可解释的结果。 |
| [^50] | [TIM: Teaching Large Language Models to Translate with Comparison.](http://arxiv.org/abs/2307.04408) | 我们提出了一个使用对比教授大型语言模型进行翻译的新框架，通过向模型呈现正确和错误翻译的示例并使用偏好损失来指导模型学习，我们证明该方法优于现有方法，在精调LLMs用于翻译任务方面提供了新的视角。 |
| [^51] | [Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning.](http://arxiv.org/abs/2306.16001) | 本研究介绍了一个使用深度学习简化社交媒体信息检索的框架，通过识别医学实体、标准化实体和分配UMLS概念，构建了一个用于COVID-19相关推文的症状词典。 |
| [^52] | [Zero and Few-shot Semantic Parsing with Ambiguous Inputs.](http://arxiv.org/abs/2306.00824) | 该论文提出了一个名为AmP的框架、数据集和挑战，用于将模糊自然语言翻译成形式化表示，如逻辑和代码。研究发现，大型预训练模型在没有明确指示的情况下难以捕捉到可能的意义分布，但当输入中存在模糊性时，模型能够很好地捕捉到分布。 |
| [^53] | [Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations.](http://arxiv.org/abs/2305.16326) | 本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。 |
| [^54] | [Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?.](http://arxiv.org/abs/2305.14578) | 本文研究了基于图的文本表示方法在文本分类中的应用，发现文本输入特征和领域要素对图的性能具有重要影响，BERT在处理短文本时难以收敛，图方法对于较长的文档特别有益。 |
| [^55] | [Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation.](http://arxiv.org/abs/2305.14189) | 本文提出了一种超越共享词汇的方法，通过定义词级信息传输路径和使用图网络来融合跨语言的词嵌入，实现了在多语言机器翻译中提高相似含义词的对齐性和BLEU分数的一致提升。此方法只需要少量额外参数且计算成本增加有限，并且推理时间与基线相同。 |
| [^56] | [A Framework for Designing Foundation Model based Systems.](http://arxiv.org/abs/2305.05352) | 本文提出了一个基于基础模型的系统分类体系，分类和比较了基础模型和基于基础模型的系统的特点。它为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。 |
| [^57] | [Large Language Models Are State-of-the-Art Evaluators of Code Generation.](http://arxiv.org/abs/2304.14317) | 本文提出了一个基于 GPT-3.5 的评估框架，解决了现有方法在代码生成任务上的局限性，取得了更好的相关性。 |
| [^58] | [ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments.](http://arxiv.org/abs/2304.03047) | ETPNav是一个能够在连续环境中进行视觉语言导航的新导航框架，它具有两个关键技能：能够抽象环境与生成长程导航计划以及在连续环境中避障控制的能力。ETPNav使用演化算法优化拓扑规划模块并在Matterport3D模拟器上实现了最先进的性能，达到了人类水平的VLN-CE任务性能。 |
| [^59] | [VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining.](http://arxiv.org/abs/2302.12584) | VivesDebate-Speech是一个用于利用音频特征进行论证挖掘的口语论证语料库，通过整合音频特征，改进了论证挖掘的性能。 |
| [^60] | [Keep it Neutral: Using Natural Language Inference to Improve Generation.](http://arxiv.org/abs/2302.08577) | 本文将自然语言推理（NLI）引入文本生成过程中，通过预训练的NLI模型评估生成的句子是否符合、与原始文本相矛盾或中立。最大化中立类别的NLI策略提供了最高质量的生成文本，无论参数取值如何。 |
| [^61] | [AV-data2vec: Self-supervised Learning of Audio-Visual Speech Representations with Contextualized Target Representations.](http://arxiv.org/abs/2302.06419) | AV-data2vec是一种使用自监督学习来构建音视频语音表示的方法，能够同时训练音频和视频的联合表示，并在语音识别任务中表现出优越性能。 |
| [^62] | [Using Twitter Data to Understand Public Perceptions of Approved versus Off-label Use for COVID-19-related Medications.](http://arxiv.org/abs/2206.14358) | 通过Twitter数据分析了解公众对COVID-19相关药物的批准和离标使用的看法。Hydroxychloroquine和Ivermectin比Molnupiravir和Remdesivir的讨论更多，时间趋势分析和内容分析揭示了人们对每种药物立场的可能理由。 |
| [^63] | [Automatic Debate Evaluation with Argumentation Semantics and Natural Language Argument Graph Networks.](http://arxiv.org/abs/2203.14647) | 本文提出了一种使用论证语义和自然语言论证图网络的混合方法来自动评估辩论，并取得了有希望的结果，为自然语言论据的自动分析开辟了新的未开发领域。 |
| [^64] | [Empirical Study of Named Entity Recognition Performance Using Distribution-aware Word Embedding.](http://arxiv.org/abs/2109.01636) | 研究开发了一种分布感知词嵌入，并实施了三种不同的方法来利用NER框架中的分布信息，实验表明将词的特异性融入NER方法可提高NER的性能。 |

# 详细

[^1]: 单词级别的ASR质量评估用于通过分析参考无关的指标的注意力进行高效语料库采样和后期编辑

    Word-Level ASR Quality Estimation for Efficient Corpus Sampling and Post-Editing through Analyzing Attentions of a Reference-Free Metric. (arXiv:2401.11268v1 [cs.CL])

    [http://arxiv.org/abs/2401.11268](http://arxiv.org/abs/2401.11268)

    本研究介绍了一种使用质量估计度量来增强自动语音识别系统(XAI)的方法。实验证明了NoRefER度量在识别单词错误和提供有价值的模型行为见解方面的能力。研究还发现NoRefER在语料库构建和后期编辑工作流程中的实用性，表明其有潜力成为提高ASR系统效率和可解释性的关键工具。

    

    在自动语音识别（ASR）领域中，不仅要有高准确性的模型，还要提供决策过程的可解释性是至关重要的。引入和评估了质量估计（QE）度量作为增强ASR系统可解释人工智能（XAI）的新工具。通过实验证明了NoRefER（无参考错误率）度量在识别单词级错误方面的能力，以帮助后期编辑者改进ASR假设。研究还扩展到NoRefER在语料库构建过程中的实用性，展示了它在增强具有有见地注释的数据集方面的有效性。对NoRefER的诊断特性进行了研究，揭示了其提供有价值的模型行为和决策模式见解的能力。这对于在后期编辑工作流程和微调ASR模型中优先考虑假设是有益的。研究结果表明NoRefER具有潜力成为提高ASR系统可解释性和效率的关键工具。

    In the realm of automatic speech recognition (ASR), the quest for models that not only perform with high accuracy but also offer transparency in their decision-making processes is crucial. The potential of quality estimation (QE) metrics is introduced and evaluated as a novel tool to enhance explainable artificial intelligence (XAI) in ASR systems. Through experiments and analyses, the capabilities of the NoRefER (No Reference Error Rate) metric are explored in identifying word-level errors to aid post-editors in refining ASR hypotheses. The investigation also extends to the utility of NoRefER in the corpus-building process, demonstrating its effectiveness in augmenting datasets with insightful annotations. The diagnostic aspects of NoRefER are examined, revealing its ability to provide valuable insights into model behaviors and decision patterns. This has proven beneficial for prioritizing hypotheses in post-editing workflows and fine-tuning ASR models. The findings suggest that NoRef
    
[^2]: 放弃解码器：使用词袋预测进行预训练的密集通行检索研究

    Drop your Decoder: Pre-training with Bag-of-Word Prediction for Dense Passage Retrieval. (arXiv:2401.11248v1 [cs.IR])

    [http://arxiv.org/abs/2401.11248](http://arxiv.org/abs/2401.11248)

    本研究介绍了一种使用词袋预测进行预训练的密集通行检索方法，通过替换解码器实现了高效压缩词汇信号，显著改进了输入令牌的条款覆盖。

    

    掩码自编码器预训练已成为初始化和增强密集检索系统的流行技术。它通常利用额外的Transformer解码块提供可持续的监督信号，并将上下文信息压缩到密集表示中。然而，这种预训练技术有效性的原因尚不清楚。使用基于Transformer的额外解码器也会产生显著的计算成本。本研究旨在通过揭示增强解码的掩码自编码器（MAE）预训练相对于普通BERT检查点在输入令牌的条款覆盖上的显著改进，以解释这个问题。基于这一观察，我们提出了对传统MAE的修改，将掩码自编码器的解码器替换为完全简化的词袋预测任务。这种修改使得词汇信号能够高效地压缩到密集表示中。

    Masked auto-encoder pre-training has emerged as a prevalent technique for initializing and enhancing dense retrieval systems. It generally utilizes additional Transformer decoder blocks to provide sustainable supervision signals and compress contextual information into dense representations. However, the underlying reasons for the effectiveness of such a pre-training technique remain unclear. The usage of additional Transformer-based decoders also incurs significant computational costs. In this study, we aim to shed light on this issue by revealing that masked auto-encoder (MAE) pre-training with enhanced decoding significantly improves the term coverage of input tokens in dense representations, compared to vanilla BERT checkpoints. Building upon this observation, we propose a modification to the traditional MAE by replacing the decoder of a masked auto-encoder with a completely simplified Bag-of-Word prediction task. This modification enables the efficient compression of lexical signa
    
[^3]: Prompt-RAG: 在小众领域中的基于向量嵌入的检索增强生成的开创性研究，以韩医学为例

    Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine. (arXiv:2401.11246v1 [cs.CL])

    [http://arxiv.org/abs/2401.11246](http://arxiv.org/abs/2401.11246)

    Prompt-RAG是一种在小众领域中增强了大型语言模型性能的新方法，与传统的RAG模型不同，它不需要使用嵌入向量。通过问答机器人应用程序的评估，结果表明Prompt-RAG优于现有模型，包括ChatGPT。

    

    我们提出了一种基于自然语言提示的检索增强生成（Prompt-RAG）的新方法，旨在增强大型语言模型（LLM）在小众领域中的性能。传统的RAG方法大多需要向量嵌入，然而通用的LLM基于嵌入表示对于专业领域的适用性仍然不确定。为了探索和举例说明这一点，我们比较了韩医学（KM）和传统医学（CM）文档的向量嵌入，发现KM文档的嵌入与标记重叠相关性更强，与人工评估的文档相关性较小，而CM文档则相反。Prompt-RAG与传统的RAG模型不同，它不需要嵌入向量。通过问答机器人应用程序对其性能进行了评估，其中回答的相关性、可读性和信息性进行了评估。结果表明，Prompt-RAG优于现有模型，包括ChatGPT和...

    We propose a natural language prompt-based retrieval augmented generation (Prompt-RAG), a novel approach to enhance the performance of generative large language models (LLMs) in niche domains. Conventional RAG methods mostly require vector embeddings, yet the suitability of generic LLM-based embedding representations for specialized domains remains uncertain. To explore and exemplify this point, we compared vector embeddings from Korean Medicine (KM) and Conventional Medicine (CM) documents, finding that KM document embeddings correlated more with token overlaps and less with human-assessed document relatedness, in contrast to CM embeddings. Prompt-RAG, distinct from conventional RAG models, operates without the need for embedding vectors. Its performance was assessed through a Question-Answering (QA) chatbot application, where responses were evaluated for relevance, readability, and informativeness. The results showed that Prompt-RAG outperformed existing models, including ChatGPT and
    
[^4]: 跨多种修辞结构的端到端论证挖掘

    End-to-End Argument Mining over Varying Rhetorical Structures. (arXiv:2401.11218v1 [cs.CL])

    [http://arxiv.org/abs/2401.11218](http://arxiv.org/abs/2401.11218)

    本研究通过使用深度依存解析模型，利用修辞关系和修辞结构训练数据增强的方法，实现了跨不同修辞结构进行端到端的论证分析。初步结果表明，在不同修辞结构下进行的论证解析是有效的。

    

    修辞结构理论暗示了文本的单一话语解释不存在，并且RST解析器的局限性进一步加剧了类似结构的不一致解析。因此，重要的是要考虑到在语义上相似的文本中可以找到相同的论证结构但修辞结构各异。本研究从修辞角度评估了同一论证方案中的释义差异。研究提出了一种深层依存解析模型来评估修辞和论证结构之间的联系。该模型利用修辞关系，修辞结构的释义作为训练数据增强。该方法允许使用修辞树而不是词序列进行端到端的论证分析。它在双语微文语料库上进行了评估，并报告了该语料库俄文版本的完整论证解析的初步结果。结果表明，论证结构和修辞结构之间的连接可以有效地在不同修辞结构下进行分析。

    Rhetorical Structure Theory implies no single discourse interpretation of a text, and the limitations of RST parsers further exacerbate inconsistent parsing of similar structures. Therefore, it is important to take into account that the same argumentative structure can be found in semantically similar texts with varying rhetorical structures. In this work, the differences between paraphrases within the same argument scheme are evaluated from a rhetorical perspective. The study proposes a deep dependency parsing model to assess the connection between rhetorical and argument structures. The model utilizes rhetorical relations; RST structures of paraphrases serve as training data augmentations. The method allows for end-to-end argumentation analysis using a rhetorical tree instead of a word sequence. It is evaluated on the bilingual Microtexts corpus, and the first results on fully-fledged argument parsing for the Russian version of the corpus are reported. The results suggest that argume
    
[^5]: 不公平的服务条款：使用定制的BERT的自动化方法

    Unfair TOS: An Automated Approach using Customized BERT. (arXiv:2401.11207v1 [cs.CL])

    [http://arxiv.org/abs/2401.11207](http://arxiv.org/abs/2401.11207)

    本研究利用定制的BERT与SVC的集成，针对ToS文档中的不公平条款进行了SOTA级别的检测，取得了出色的结果。

    

    服务条款(Terms of Service，ToS)是任何协议的重要组成部分，它定义了服务提供商和最终用户之间的法律关系。它们不仅确定和界定了相互的权利和责任，还为用户提供了与使用数字空间有关的合同重要方面的信息。这些方面包括责任限制、数据保护等各种主题。用户倾向于在使用任何应用程序或服务之前接受ToS而不进行阅读。这种无知可能使他们在需要采取任何行动时处于较弱的状况。现有的检测或分类不公平条款的方法已经过时且表现不佳。在这篇研究论文中，我们以前所未有的Fine-tuning BERT与SVC（支持向量分类器）相结合，提出了关于ToS文档中不公平条款检测的SOTA（最新技术）结果。研究表明了出色的性能。

    Terms of Service (ToS) form an integral part of any agreement as it defines the legal relationship between a service provider and an end-user. Not only do they establish and delineate reciprocal rights and responsibilities, but they also provide users with information on essential aspects of contracts that pertain to the use of digital spaces. These aspects include a wide range of topics, including limitation of liability, data protection, etc. Users tend to accept the ToS without going through it before using any application or service. Such ignorance puts them in a potentially weaker situation in case any action is required. Existing methodologies for the detection or classification of unfair clauses are however obsolete and show modest performance. In this research paper, we present SOTA(State of The Art) results on unfair clause detection from ToS documents based on unprecedented Fine-tuning BERT in integration with SVC(Support Vector Classifier). The study shows proficient perform
    
[^6]: InferAligner: 利用跨模型引导进行无害化推理时间对齐

    InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance. (arXiv:2401.11206v1 [cs.CL])

    [http://arxiv.org/abs/2401.11206](http://arxiv.org/abs/2401.11206)

    InferAligner是一种新颖的推理时间对齐方法，利用跨模型引导实现无害化对齐，可以有效地应用于领域特定模型中。

    

    随着大型语言模型（LLM）的快速发展，它们不仅被用作通用AI助手，还通过进一步的微调定制以满足不同应用的要求。当前LLM成功的一个关键因素是对齐过程。当前的对齐方法，如有监督的微调（SFT）和从人类反馈中强化学习（RLHF），侧重于训练时间的对齐，往往复杂且难以实现。因此，我们开发了InferAligner，一种利用跨模型引导进行无害化对齐的新方法。InferAligner利用从安全对齐模型中提取的安全转向向量来修改目标模型在响应有害输入时的激活，从而引导目标模型提供无害响应。实验结果表明，我们的方法可以非常有效地应用于金融、医学和市场等领域特定模型中。

    With the rapid development of large language models (LLMs), they are not only used as general-purpose AI assistants but are also customized through further fine-tuning to meet the requirements of different applications. A pivotal factor in the success of current LLMs is the alignment process. Current alignment methods, such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), focus on training-time alignment and are often complex and cumbersome to implement. Therefore, we develop \textbf{InferAligner}, a novel inference-time alignment method that utilizes cross-model guidance for harmlessness alignment. InferAligner utilizes safety steering vectors extracted from safety-aligned model to modify the activations of the target model when responding to harmful inputs, thereby guiding the target model to provide harmless responses. Experimental results show that our method can be very effectively applied to domain-specific models in finance, medicine, and ma
    
[^7]: 万物普及的大型语言模型的出现既阻碍又推动了动态对抗性问题生成

    How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation. (arXiv:2401.11185v1 [cs.CL])

    [http://arxiv.org/abs/2401.11185](http://arxiv.org/abs/2401.11185)

    万物普及的大型语言模型的出现既推动了动态对抗性问题生成的发展，又阻碍了其进展。为了解决这个问题，我们为作者提供了LLMs和检索模型的写作指导，提出了新的度量标准和激励机制，并创建了一个新的对抗性问题数据集。

    

    动态对抗性问题生成旨在生成既真实又有信息的示例来困扰模型，然而，大型语言模型（LLMs）的出现对人类作者来说是一把双刃剑：更多人对这些模型感兴趣并推动其极限，但由于模型对手更强大，难以击败。为了了解这些模型对对抗性问题编写过程的影响，我们为作者提供了LLMs和检索模型的写作指导，以理解为什么他们的问题不具备对抗性。虽然作者可以创建有趣且具有挑战性的对抗性问题，但他们有时会采用诡计导致问题质量变差，这些问题不仅对计算机而且对人类也是模糊、主观或混乱的。为了解决这些问题，我们提出了精心设计的度量标准和激励机制来引发好的、具有挑战性的问题，并提出了一个新的对抗性问题数据集。

    Dynamic adversarial question generation, where humans write examples to stump a model, aims to create examples that are realistic and informative. However, the advent of large language models (LLMs) has been a double-edged sword for human authors: more people are interested in seeing and pushing the limits of these models, but because the models are so much stronger an opponent, they are harder to defeat. To understand how these models impact adversarial question writing process, we enrich the writing guidance with LLMs and retrieval models for the authors to reason why their questions are not adversarial. While authors could create interesting, challenging adversarial questions, they sometimes resort to tricks that result in poor questions that are ambiguous, subjective, or confusing not just to a computer but also to humans. To address these issues, we propose new metrics and incentives for eliciting good, challenging questions and present a new dataset of adversarially authored ques
    
[^8]: 高斯自适应注意力是唯一所需的：跨多个模态的健壮上下文表示

    Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities. (arXiv:2401.11143v1 [cs.LG])

    [http://arxiv.org/abs/2401.11143](http://arxiv.org/abs/2401.11143)

    该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。

    

    我们提出了多头高斯自适应注意力机制（GAAM），一种新颖的概率注意力框架，并设计了高斯自适应变压器（GAT），旨在增强跨多个模态（包括语音、文本和视觉）的信息聚合。GAAM将可学习的均值和方差融入其注意力机制中，采用多头框架实现，使其能够集体建模任何概率分布，以动态重新调整特征重要性。该方法在处理高度非平稳数据时表现出显著改进，通过识别特征空间中的关键元素，超越了现有的注意力技术在模型性能上的状态（精度增加约20%）。GAAM与基于点积的注意力模型兼容，并具有相对较低的参数数量，展示了其适应性和提升现有注意力框架的潜力。在实证方面，GAAM表现出卓越的适应性和功效。

    We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a novel probabilistic attention framework, and the Gaussian Adaptive Transformer (GAT), designed to enhance information aggregation across multiple modalities, including Speech, Text and Vision. GAAM integrates learnable mean and variance into its attention mechanism, implemented in a Multi-Headed framework enabling it to collectively model any Probability Distribution for dynamic recalibration of feature significance. This method demonstrates significant improvements, especially with highly non-stationary data, surpassing the state-of-the-art attention techniques in model performance (up to approximately +20% in accuracy) by identifying key elements within the feature space. GAAM's compatibility with dot-product-based attention models and relatively low number of parameters showcases its adaptability and potential to boost existing attention frameworks. Empirically, GAAM exhibits superior adaptability and efficacy
    
[^9]: 将临床实践指南纳入大型语言模型以增强临床决策支持

    Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines. (arXiv:2401.11120v1 [cs.CL])

    [http://arxiv.org/abs/2401.11120](http://arxiv.org/abs/2401.11120)

    该论文研究了将临床实践指南纳入大型语言模型以增强临床决策支持的方法。他们开发了三种方法，并对四个大型语言模型进行了评估，在COVID-19门诊治疗方面取得了较高的性能。

    

    大型语言模型（LLM），搭配临床实践指南（CPGs），可以显著提高临床决策支持（CDS）。然而，将CPGs纳入LLMs的方法并未得到充分研究。我们开发了三种不同的方法将CPGs纳入LLMs：二元决策树（BDT），程序辅助图构建（PAGC），以及思维链少样本提示（CoT-FSP）。为评估所提方法的有效性，我们创建了一组合成患者描述，并对由四个LLMs生成的响应进行自动和人工评估：GPT-4，GPT-3.5 Turbo，LLaMA和PaLM 2。零样本提示（ZSP）被用作基线方法。我们以COVID-19门诊治疗的临床决策支持为案例研究。四个LLMs在增加了CPGs后相对于基线ZSP展现了提高的性能。BDT在自动评估中表现优于CoT-FSP和PAGC。所有提出的方法都表现出了较高的性能。

    Background Large Language Models (LLMs), enhanced with Clinical Practice Guidelines (CPGs), can significantly improve Clinical Decision Support (CDS). However, methods for incorporating CPGs into LLMs are not well studied. Methods We develop three distinct methods for incorporating CPGs into LLMs: Binary Decision Tree (BDT), Program-Aided Graph Construction (PAGC), and Chain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of the proposed methods, we create a set of synthetic patient descriptions and conduct both automatic and human evaluation of the responses generated by four LLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was used as the baseline method. We focus on CDS for COVID-19 outpatient treatment as the case study. Results All four LLMs exhibit improved performance when enhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP and PAGC in automatic evaluation. All of the proposed methods demonstrated high per
    
[^10]: 使用谓词提示在开放信息提取中利用对偶性

    Exploiting Duality in Open Information Extraction with Predicate Prompt. (arXiv:2401.11107v1 [cs.CL])

    [http://arxiv.org/abs/2401.11107](http://arxiv.org/abs/2401.11107)

    本文提出了一种新的生成式OpenIE模型DualOIE，通过实现一个双重任务，即将句子中的三元组转化为句子，来更有效地提取复杂的三元组。此方法鼓励模型正确识别句子结构，从而有助于提取所有潜在的三元组。

    

    开放信息提取（OpenIE）旨在从给定的句子中提取以（主体，谓词，宾语）形式呈现的无模式三元组。与一般的信息提取（IE）相比，OpenIE对IE模型提出了更多挑战，尤其是在句子中存在多个复杂的三元组时。为了更有效地提取这些复杂的三元组，我们提出了一种新颖的生成式OpenIE模型，名为DualOIE，它在提取句子中的一些三元组的同时实现了另一个任务，即将三元组转化为句子。这种双重任务鼓励模型正确识别给定句子的结构，从而有助于从句子中提取所有潜在的三元组。具体而言，DualOIE分为两个步骤提取三元组：首先提取所有潜在谓词的序列，然后使用谓词序列作为提示诱导三元组的生成。

    Open information extraction (OpenIE) aims to extract the schema-free triplets in the form of (\emph{subject}, \emph{predicate}, \emph{object}) from a given sentence. Compared with general information extraction (IE), OpenIE poses more challenges for the IE models, {especially when multiple complicated triplets exist in a sentence. To extract these complicated triplets more effectively, in this paper we propose a novel generative OpenIE model, namely \emph{DualOIE}, which achieves a dual task at the same time as extracting some triplets from the sentence, i.e., converting the triplets into the sentence.} Such dual task encourages the model to correctly recognize the structure of the given sentence and thus is helpful to extract all potential triplets from the sentence. Specifically, DualOIE extracts the triplets in two steps: 1) first extracting a sequence of all potential predicates, 2) then using the predicate sequence as a prompt to induce the generation of triplets. Our experiments 
    
[^11]: 使用大型语言模型从材料科学文献中挖掘实验数据

    Mining experimental data from Materials Science literature with Large Language Models. (arXiv:2401.11052v1 [cs.CL])

    [http://arxiv.org/abs/2401.11052](http://arxiv.org/abs/2401.11052)

    本研究评估了使用大型语言模型从材料科学文献中提取结构化信息的能力，并引入了一种新颖的方法来处理材料科学信息的复杂性。在命名实体识别和关系提取任务上，LLMs与传统模型相比表现有限，但在少数-shot提示下有一定的改进。

    

    本研究致力于评估先进的大型语言模型（LLMs），如GPT-3.5-Turbo、GPT-4和GPT-4-Turbo，在材料科学领域科学文档中提取结构化信息的能力。我们引入了一种新颖的方法，用于比较分析复杂的材料表达式，强调化学式的标准化，以解决材料科学信息评估中固有的复杂性。为此，我们主要关注信息提取的两个关键任务：（i）研究材料和物理性质的命名实体识别（NER）和（ii）这些实体之间的关系提取（RE）。LLMs在执行这些任务时的表现与基于BERT架构和基于规则的传统模型进行了基准测试。对于NER，LLMs在零-shot提示下无法超越基准线，并且仅在少数-shot提示下有少量改进。然而，对于...

    This study is dedicated to evaluating the capabilities of advanced large language models (LLMs) such as GPT-3.5-Turbo, GPT-4, and GPT-4-Turbo in the extraction of structured information from scientific documents within the field of materials science. We introduce a novel methodology for the comparative analysis of intricate material expressions, emphasising the standardisation of chemical formulas to tackle the complexities inherent in materials science information assessment. To this end, we primarily focus on two critical tasks of information extraction: (i) a named entity recognition (NER) of studied materials and physical properties and (ii) a relation extraction (RE) between these entities. The performance of LLMs in executing these tasks is benchmarked against traditional models based on the BERT architecture and rule-based approaches. For NER, LLMs fail to outperform the baseline with zero-shot prompting and exhibit only limited improvement with few-shot prompting. However, for 
    
[^12]: PubTator 3.0：基于人工智能的生物医学知识解锁文献资源

    PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge. (arXiv:2401.11048v1 [cs.CL])

    [http://arxiv.org/abs/2401.11048](http://arxiv.org/abs/2401.11048)

    PubTator 3.0是一个使用AI技术的生物医学文献资源，提供语义和关系搜索，以及高级搜索功能和大规模分析。与PubMed和Google Scholar相比，在检索精度和文章数量上都有明显优势。同时，与ChatGPT（GPT-4）API集成可以进一步提高搜索结果的质量。

    

    PubTator 3.0是一个使用最先进的人工智能技术提供语义和关系搜索的生物医学文献资源，涵盖蛋白质、遗传变异、疾病和化合物等关键概念。它目前提供了超过10亿个实体和关系注释，覆盖了大约3600万篇PubMed摘要和600万篇PMC开放获取子集的全文文章，并每周更新。PubTator 3.0的在线界面和API利用这些预计算的实体关系和同义词提供高级搜索功能，支持大规模分析，简化了许多复杂信息需求。通过一系列实体对查询，我们展示了PubTator 3.0的检索质量，证明它检索到的文章数量比PubMed和Google Scholar更多，并在前20个结果中具有更高的精度。我们进一步展示了将ChatGPT（GPT-4）与PubTator API集成可以大大改善结果。

    PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is a biomedical literature resource using state-of-the-art AI techniques to offer semantic and relation searches for key concepts like proteins, genetic variants, diseases, and chemicals. It currently provides over one billion entity and relation annotations across approximately 36 million PubMed abstracts and 6 million full-text articles from the PMC open access subset, updated weekly. PubTator 3.0's online interface and API utilize these precomputed entity relations and synonyms to provide advanced search capabilities and enable large-scale analyses, streamlining many complex information needs. We showcase the retrieval quality of PubTator 3.0 using a series of entity pair queries, demonstrating that PubTator 3.0 retrieves a greater number of articles than either PubMed or Google Scholar, with higher precision in the top 20 results. We further show that integrating ChatGPT (GPT-4) with PubTator APIs dramatically improves
    
[^13]: FAIR到位：我们如何为大型语言模型的训练开发和评估符合FAIR标准的数据集？

    FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for Large Language Models' Training?. (arXiv:2401.11033v1 [cs.CL])

    [http://arxiv.org/abs/2401.11033](http://arxiv.org/abs/2401.11033)

    这项工作介绍了一个将FAIR数据原则嵌入到大型语言模型训练中的框架，并提供了整合指南和检查清单。通过一个案例研究，展示了在符合FAIR标准的数据集中识别和减轻偏见的实际应用。

    

    大型语言模型的进展凸显了道德实践和数据完整性的需求。我们引入了一个将FAIR（可发现、可访问、可互操作、可重用）数据原则嵌入到LLM训练中的框架。这一方法标志着朝着符合FAIR标准的实践的转变。我们的框架提供了将FAIR数据原则整合到LLM训练中的指南。该举措包括研究人员和开发人员的检查清单。我们还通过一个案例研究展示了它的实际应用，重点是在我们符合FAIR标准的数据集中识别和减轻偏见。这项工作对于人工智能伦理和数据科学是重要的贡献，倡导在LLMs中使用平衡和道德的训练方法。

    Advancements in Large Language Models (LLMs) highlight the need for ethical practices and data integrity. We introduce a framework that embeds FAIR (Findable, Accessible, Interoperable, Reusable) data principles into LLM training. This approach marks a shift towards practices compliant with FAIR standards. Our framework presents guidelines for integrating FAIR data principles into LLM training. This initiative includes a checklist for researchers and developers. We also demonstrate its practical application through a case study focused on bias identification and mitigation in our FAIR-compliant dataset. This work is a significant contribution to AI ethics and data science, advocating for balanced and ethical training methods in LLMs.
    
[^14]: 基于Transformer深度学习的多语言仇恨言论分析和检测

    Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning. (arXiv:2401.11021v1 [cs.CL])

    [http://arxiv.org/abs/2401.11021](http://arxiv.org/abs/2401.11021)

    提出了一种基于Transformer模型的方法来检测社交媒体上的多语言仇恨言论。该模型在意大利语、英语、德语和孟加拉语上进行了测试，并取得了比现有模型更高的成功率。

    

    仇恨言论是直接攻击或宣传针对特定群体或个人的憎恨的有害内容，例如种族主义、宗教或性取向等。这会对社交媒体平台上的社会生活产生影响，因为通过社交媒体分享的仇恨内容可能会对个人和社区造成伤害。随着网络上仇恨言论的增加，自动化检测作为自然语言处理的一个任务的需求也在增加。在这项工作中，提出了一种使用基于Transformer模型在社交媒体上检测仇恨言论的方法，如Twitter、Facebook、WhatsApp、Instagram等。该模型独立于语言，并已在意大利语、英语、德语、孟加拉语上进行了测试。黄金标准数据集由知名研究者Zeerak Talat、Sara Tonelli、Melanie Siegel和Rezaul Karim收集。所提出模型在仇恨言论检测方面的成功率高于现有基准和最先进模型，准确率较高。

    Hate speech is harmful content that directly attacks or promotes hatred against members of groups or individuals based on actual or perceived aspects of identity, such as racism, religion, or sexual orientation. This can affect social life on social media platforms as hateful content shared through social media can harm both individuals and communities. As the prevalence of hate speech increases online, the demand for automated detection as an NLP task is increasing. In this work, the proposed method is using transformer-based model to detect hate speech in social media, like twitter, Facebook, WhatsApp, Instagram, etc. The proposed model is independent of languages and has been tested on Italian, English, German, Bengali. The Gold standard datasets were collected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel, and Rezaul Karim. The success rate of the proposed model for hate speech detection is higher than the existing baseline and state-of-the-art models with acc
    
[^15]: 放射肿瘤学自然语言处理数据库

    The Radiation Oncology NLP Database. (arXiv:2401.10995v1 [cs.CL])

    [http://arxiv.org/abs/2401.10995](http://arxiv.org/abs/2401.10995)

    放射肿瘤学自然语言处理数据库（ROND）是第一个专门针对放射肿瘤学的自然语言处理数据集，其中包含了逻辑推理、文本分类、命名实体识别等多个任务，并且还开发了一个指令对数据集和相应的语言模型CancerChat。

    

    我们介绍了放射肿瘤学自然语言处理数据库（ROND），这是第一个专门针对放射肿瘤学的自然语言处理数据集。放射肿瘤学是一门重要的医学专业，但在过去受到自然语言处理社区的关注有限。随着人工通用智能（AGI）的出现，需要专门的数据集和基准来促进研究和发展。ROND专门针对放射肿瘤学领域中的空白进行设计，这个领域为自然语言处理的探索提供了许多机会。它涵盖了各种自然语言处理任务，包括逻辑推理、文本分类、命名实体识别（NER）、问题回答（QA）、文本摘要和患者-临床医生对话，每个任务都着重放射肿瘤学概念和应用案例。此外，我们还采用ROND开发了一个包含20k多个指令对的数据集，并训练了一个大型语言模型CancerChat。

    We present the Radiation Oncology NLP Database (ROND), the first dedicated Natural Language Processing (NLP) dataset for radiation oncology, an important medical specialty that has received limited attention from the NLP community in the past. With the advent of Artificial General Intelligence (AGI), there is an increasing need for specialized datasets and benchmarks to facilitate research and development. ROND is specifically designed to address this gap in the domain of radiation oncology, a field that offers many opportunities for NLP exploration. It encompasses various NLP tasks including Logic Reasoning, Text Classification, Named Entity Recognition (NER), Question Answering (QA), Text Summarization, and Patient-Clinician Conversations, each with a distinct focus on radiation oncology concepts and application cases. In addition, we have developed an instruction-tuning dataset consisting of over 20k instruction pairs (based on ROND) and trained a large language model, CancerChat. T
    
[^16]: RELIANCE: 可靠的集成学习用于信息和新闻可信度评估

    RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation. (arXiv:2401.10940v1 [cs.IR])

    [http://arxiv.org/abs/2401.10940](http://arxiv.org/abs/2401.10940)

    RELIANCE是一个可靠的集成学习系统，用于评估信息和新闻的可信度。它通过整合多个基本模型的优势，提供了对可信和不可信信息源的准确区分，并在信息和新闻可信度评估方面优于基准模型。

    

    在信息泛滥的时代，辨别新闻内容的可信度越来越具有挑战性。本文介绍了RELIANCE，这是一个专为鲁棒信息和虚假新闻可信度评估而设计的先进的集成学习系统。RELIANCE由五个不同的基本模型组成，包括支持向量机（SVM）、朴素贝叶斯、逻辑回归、随机森林和双向长短期记忆网络（BiLSTMs）。RELIANCE采用了创新的方法来整合它们的优势，利用集成的智能提高准确性。实验证明了RELIANCE在区分可信和不可信信息源方面的优越性，表明其在信息和新闻可信度评估方面超过了单个模型，并成为评估信息源可靠性的有效解决方案。

    In the era of information proliferation, discerning the credibility of news content poses an ever-growing challenge. This paper introduces RELIANCE, a pioneering ensemble learning system designed for robust information and fake news credibility evaluation. Comprising five diverse base models, including Support Vector Machine (SVM), naive Bayes, logistic regression, random forest, and Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs an innovative approach to integrate their strengths, harnessing the collective intelligence of the ensemble for enhanced accuracy. Experiments demonstrate the superiority of RELIANCE over individual models, indicating its efficacy in distinguishing between credible and non-credible information sources. RELIANCE, also surpasses baseline models in information and news credibility assessment, establishing itself as an effective solution for evaluating the reliability of information sources.
    
[^17]: 构建一个面向挑战导向的智能专业化监测平台RIS3-MCAT

    Towards building a monitoring platform for a challenge-oriented smart specialisation with RIS3-MCAT. (arXiv:2401.10900v1 [cs.CY])

    [http://arxiv.org/abs/2401.10900](http://arxiv.org/abs/2401.10900)

    构建了一个面向挑战导向的智能专业化监测平台RIS3-MCAT，利用开放数据、语义分析和数据可视化技术，以监测挑战导向智能专业化的加泰罗尼亚为例，实现了对大量文本进行详细研究的分析和可视化。

    

    在新的研究与创新（R&I）范式中，为了解决社会和环境挑战、生成新的专业化模式和社会经济发展轨迹，提供监测系统和工具以及对 R&I 政策和项目的贡献进行映射和理解变得至关重要。为了解决这一转变，我们介绍了 RIS3-MCAT 平台，它是探索开放数据、语义分析和数据可视化潜力的一项工作的结果，用于监测加泰罗尼亚的挑战导向智能专业化。RIS3-MCAT 是一个交互式平台，可以以支持复杂文本的详细研究为特色，使得访问 R&I 项目数据变得更容易，可以超越经典的分类系统，对主题专业化和挑战进行深入研究。

    In the new research and innovation (R&I) paradigm, aimed at a transformation towards more sustainable, inclusive and fair pathways to address societal and environmental challenges, and at generating new patterns of specialisation and new trajectories for socioeconomic development, it is essential to provide monitoring systems and tools to map and understand the contribution of R&I policies and projects. To address this transformation, we present the RIS3-MCAT platform, the result of a line of work aimed at exploring the potential of open data, semantic analysis, and data visualisation, for monitoring challenge-oriented smart specialisation in Catalonia. RIS3-MCAT is an interactive platform that facilitates access to R&I project data in formats that allow for sophisticated analyses of a large volume of texts, enabling the detailed study of thematic specialisations and challenges beyond classical classification systems. Its conceptualisation, development framework and use are presented i
    
[^18]: 知识图谱嵌入的位置敏感嵌入

    Location Sensitive Embedding for Knowledge Graph Embedding. (arXiv:2401.10893v1 [cs.IR])

    [http://arxiv.org/abs/2401.10893](http://arxiv.org/abs/2401.10893)

    这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。

    

    知识图谱嵌入将知识图谱转化为连续的、低维度的空间，有助于推理和补全任务。该领域主要分为传统的距离模型和语义匹配模型。传统的距离模型面临的关键挑战是无法有效区分图谱中的“头实体”和“尾实体”。为了解决这个问题，提出了新颖的位置敏感嵌入（LSE）方法。LSE通过关系特定的映射修改头实体，将关系概念化为线性变换而不仅仅是平移。LSE的理论基础，包括其表示能力和与现有模型的联系，都进行了详细研究。一种更简化的变体LSEd利用对角矩阵进行变换以提高实用性能。在对四个大规模数据集进行链接预测的测试中，LSEd要么表现更好，要么具有竞争力。

    Knowledge graph embedding transforms knowledge graphs into a continuous, low-dimensional space, facilitating inference and completion tasks. This field is mainly divided into translational distance models and semantic matching models. A key challenge in translational distance models is their inability to effectively differentiate between 'head' and 'tail' entities in graphs. To address this, the novel location-sensitive embedding (LSE) method has been developed. LSE innovatively modifies the head entity using relation-specific mappings, conceptualizing relations as linear transformations rather than mere translations. The theoretical foundations of LSE, including its representational capabilities and its connections to existing models, have been thoroughly examined. A more streamlined variant, LSEd, employs a diagonal matrix for transformations to enhance practical efficiency. In tests conducted on four large-scale datasets for link prediction, LSEd either outperforms or is competitive
    
[^19]: 大型语言模型的知识融合

    Knowledge Fusion of Large Language Models. (arXiv:2401.10491v1 [cs.CL])

    [http://arxiv.org/abs/2401.10491](http://arxiv.org/abs/2401.10491)

    本文介绍了一种大型语言模型知识融合的方法，通过将现有预训练的语言模型合并为一个更强大的模型，从而提高目标模型的能力，验证实验结果证实了该方法的有效性。

    

    尽管从头开始训练大型语言模型（LLMs）可以生成具有独特功能和优势的模型，但这将带来巨大的成本，并可能导致冗余的能力。相反，一种具有成本效益和强大功能的方法是将现有的预训练LLMs合并为一个更强大的模型。然而，由于这些LLMs的不同架构，直接混合它们的权重是不切实际的。在本文中，我们引入了LLMs的知识融合的概念，旨在将现有LLMs的能力结合起来并转移到单个LLM中。通过利用源LLMs的生成分布，我们外部化它们的集体知识和独特优势，从而可能提高目标模型的能力超过任何单个源LLM的能力。我们使用具有不同架构的三个流行LLMs —— Llama-2、MPT和OpenLLaMA在各种基准和任务中验证了我们的方法。我们的研究结果证实了融合这三个LLMs的能力。

    While training large language models (LLMs) from scratch can generate models with distinct functionalities and strengths, it comes at significant costs and may result in redundant capabilities. Alternatively, a cost-effective and compelling approach is to merge existing pre-trained LLMs into a more potent model. However, due to the varying architectures of these LLMs, directly blending their weights is impractical. In this paper, we introduce the notion of knowledge fusion for LLMs, aimed at combining the capabilities of existing LLMs and transferring them into a single LLM. By leveraging the generative distributions of source LLMs, we externalize their collective knowledge and unique strengths, thereby potentially elevating the capabilities of the target model beyond those of any individual source LLM. We validate our approach using three popular LLMs with different architectures--Llama-2, MPT, and OpenLLaMA--across various benchmarks and tasks. Our findings confirm that the fusion of
    
[^20]: 基于噪声对比估计的低资源安全攻击模式识别匹配框架

    Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v1 [cs.LG])

    [http://arxiv.org/abs/2401.10337](http://arxiv.org/abs/2401.10337)

    该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。

    

    战术、技术和程序（TTPs）是网络安全领域中复杂的攻击模式，在文本知识库中有详细的描述。在网络安全写作中识别TTPs，通常称为TTP映射，是一个重要而具有挑战性的任务。传统的学习方法通常以经典的多类或多标签分类设置为目标。由于存在大量的类别（即TTPs），标签分布的不均衡和标签空间的复杂层次结构，这种设置限制了模型的学习能力。我们采用了一种不同的学习范式来解决这个问题，其中将文本与TTP标签之间的直接语义相似度决定为文本分配给TTP标签，从而减少了仅仅在大型标签空间上竞争的复杂性。为此，我们提出了一种具有有效的基于采样的学习比较机制的神经匹配架构，促进学习过程。

    Tactics, Techniques and Procedures (TTPs) represent sophisticated attack patterns in the cybersecurity domain, described encyclopedically in textual knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP mapping, is an important and challenging task. Conventional learning approaches often target the problem in the classical multi-class or multilabel classification setting. This setting hinders the learning ability of the model due to a large number of classes (i.e., TTPs), the inevitable skewness of the label distribution and the complex hierarchical structure of the label space. We formulate the problem in a different learning paradigm, where the assignment of a text to a TTP label is decided by the direct semantic similarity between the two, thus reducing the complexity of competing solely over the large labeling space. To that end, we propose a neural matching architecture with an effective sampling-based learn-to-compare mechanism, facilitating the learning pr
    
[^21]: Chem-FINESE: 通过文本重构验证细粒度少样本实体提取

    Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction. (arXiv:2401.10189v1 [cs.CL])

    [http://arxiv.org/abs/2401.10189](http://arxiv.org/abs/2401.10189)

    这篇论文提出了一种名为Chem-FINESE的方法来处理化学领域中细粒度少样本实体提取的问题。该方法通过使用序列到序列的实体提取器和自我验证模块来从输入句子中提取命名实体并重构原始输入句子。实验证明了该方法的有效性和可行性。

    

    在化学领域中，细粒度少样本实体提取面临两个独特的挑战。首先，与一般领域的实体提取任务相比，化学论文中的句子通常包含更多的实体。此外，实体提取模型通常难以提取长尾类型的实体。在本文中，我们提出了一种新颖的基于序列到序列的少样本实体提取方法Chem-FINESE来解决这两个挑战。我们的Chem-FINESE包含两个组件：一个序列到序列的实体提取器用于从输入句子中提取命名实体，以及一个序列到序列的自我验证模块用于从提取的实体中重构原始输入句子。受到一个好的实体提取系统需要忠实提取实体的事实启发，我们的新自我验证模块利用实体提取结果来重构原始输入句子。此外，我们设计了一种新的对比损失来减少在提取过程中的过度复制。

    Fine-grained few-shot entity extraction in the chemical domain faces two unique challenges. First, compared with entity extraction tasks in the general domain, sentences from chemical papers usually contain more entities. Moreover, entity extraction models usually have difficulty extracting entities of long-tailed types. In this paper, we propose Chem-FINESE, a novel sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to address these two challenges. Our Chem-FINESE has two components: a seq2seq entity extractor to extract named entities from the input sentence and a seq2seq self-validation module to reconstruct the original input sentence from extracted entities. Inspired by the fact that a good entity extraction system needs to extract entities faithfully, our new self-validation module leverages entity extraction results to reconstruct the original input sentence. Besides, we design a new contrastive loss to reduce excessive copying during the extraction proces
    
[^22]: 向层次化口语淤塞建模迈进

    Towards Hierarchical Spoken Language Dysfluency Modeling. (arXiv:2401.10015v1 [cs.CL])

    [http://arxiv.org/abs/2401.10015](http://arxiv.org/abs/2401.10015)

    本论文介绍了一种名为H-UDM的层次化口语淤塞建模方法，它能够解决口语淤塞转录和检测问题，并且消除了对大量手动注释的需求。实验结果证明了该方法在转录和检测任务中的有效性和鲁棒性。

    

    口语淤塞建模是语言治疗和语言学习的瓶颈。然而，目前没有人工智能解决方案来系统地应对这个问题。我们首先提出了定义口语淤塞和口语淤塞建模的概念。然后，我们提出了一种名为Hierarchical Unconstrained Dysfluency Modeling (H-UDM)的方法，既解决了口语淤塞转录问题，又解决了检测问题，消除了对大量手动注释的需求。此外，我们还引入了一个名为VCTK++的模拟淤塞数据集，以增强H-UDM在音标转录方面的能力。我们的实验结果证明了我们提出的方法在转录和检测任务中的有效性和鲁棒性。

    Speech dysfluency modeling is the bottleneck for both speech therapy and language learning. However, there is no AI solution to systematically tackle this problem. We first propose to define the concept of dysfluent speech and dysfluent speech modeling. We then present Hierarchical Unconstrained Dysfluency Modeling (H-UDM) approach that addresses both dysfluency transcription and detection to eliminate the need for extensive manual annotation. Furthermore, we introduce a simulated dysfluent dataset called VCTK++ to enhance the capabilities of H-UDM in phonetic transcription. Our experimental results demonstrate the effectiveness and robustness of our proposed methods in both transcription and detection tasks.
    
[^23]: 一种简单的黑盒方法用于越狱攻击

    All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks. (arXiv:2401.09798v1 [cs.CL])

    [http://arxiv.org/abs/2401.09798](http://arxiv.org/abs/2401.09798)

    本研究提出了一种简单的黑盒方法，用于生成越狱攻击提示，克服了现有方法的复杂性和计算成本的限制。该方法通过使用语言模型自身，将有害提示重写为非有害表达，实现了超过80%的攻击成功率，并且即使模型更新，效果仍然有效。

    

    像ChatGPT这样的大型语言模型面临着“越狱”挑战，即规避保障措施以产生不符合伦理的提示。本研究引入了一种简单的黑盒方法，有效地生成越狱提示，克服了现有方法的高复杂性和计算成本的限制。该方法通过使用目标语言模型自身，迭代地将有害提示重写为非有害表达，基于假设认为语言模型可以直接生成规避保障的表达。通过在ChatGPT（GPT-3.5和GPT-4）和Gemini-Pro上进行实验证明，该方法在平均5次迭代内实现了超过80%的攻击成功率，并且即使模型更新，效果仍然有效。生成的越狱提示自然而简练，表明它们较不易被检测。结果表明，创建有效的越狱提示比先前研究认为的要简单，并且黑盒越狱攻击构成了一个重要的挑战。

    Large Language Models (LLMs) like ChatGPT face `jailbreak' challenges, where safeguards are bypassed to produce ethically harmful prompts. This study introduces a simple black-box method to effectively generate jailbreak prompts, overcoming the limitations of high complexity and computational costs associated with existing methods. The proposed technique iteratively rewrites harmful prompts into non-harmful expressions using the target LLM itself, based on the hypothesis that LLMs can directly sample safeguard-bypassing expressions. Demonstrated through experiments with ChatGPT (GPT-3.5 and GPT-4) and Gemini-Pro, this method achieved an attack success rate of over 80% within an average of 5 iterations and remained effective despite model updates. The jailbreak prompts generated were naturally-worded and concise, suggesting they are less detectable. The results indicate that creating effective jailbreak prompts is simpler than previously considered, and black-box jailbreak attacks pose 
    
[^24]: 机器能够看到颜色：大规模语料库中分类不同形式种族主义言论的准则

    Machines Do See Color: A Guideline to Classify Different Forms of Racist Discourse in Large Corpora. (arXiv:2401.09333v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.09333](http://arxiv.org/abs/2401.09333)

    本文提供了一个逐步可推广的准则，用于在大规模语料库中识别和分类不同形式的种族主义言论。通过对种族主义的概念化和上下文化，以及使用XLM-R和XLM-R-Racismo模型，我们展示了在大规模语料库中进行种族主义分类的优势。

    

    目前识别和分类文本中的种族主义语言的方法主要依赖小规模的质性方法或大规模的方法，专注于明显的种族主义言论。本文提供了一个逐步可推广的准则，用于在大规模语料库中识别和分类不同形式的种族主义言论。在我们的方法中，我们首先将种族主义及其不同表现形式进行概念化。然后，我们将这些种族主义表现形式置于感兴趣的时间和地点背景下，以便研究人员能够识别它们的话语形式。最后，我们应用了XLM-RoBERTa（XLM-R），这是一个具有先进上下文理解能力的跨语言监督文本分类模型。我们展示了XLM-R和XLM-R-Racismo（我们的预训练模型）在大规模语料库中对种族主义进行分类的性能优于其他最先进的方法。我们通过使用涉及2018年至2021年厄瓜多尔本土群体的推文语料库来说明我们的方法。

    Current methods to identify and classify racist language in text rely on small-n qualitative approaches or large-n approaches focusing exclusively on overt forms of racist discourse. This article provides a step-by-step generalizable guideline to identify and classify different forms of racist discourse in large corpora. In our approach, we start by conceptualizing racism and its different manifestations. We then contextualize these racist manifestations to the time and place of interest, which allows researchers to identify their discursive form. Finally, we apply XLM-RoBERTa (XLM-R), a cross-lingual model for supervised text classification with a cutting-edge contextual understanding of text. We show that XLM-R and XLM-R-Racismo, our pretrained model, outperform other state-of-the-art approaches in classifying racism in large corpora. We illustrate our approach using a corpus of tweets relating to the Ecuadorian ind\'igena community between 2018 and 2021.
    
[^25]: 大型语言模型中的代码模拟挑战

    Code Simulation Challenges for Large Language Models. (arXiv:2401.09074v1 [cs.LG])

    [http://arxiv.org/abs/2401.09074](http://arxiv.org/abs/2401.09074)

    大型语言模型在模拟计算机代码和算法执行方面遇到挑战，性能随着代码长度的增加而迅速下降。在处理短程序或标准过程时，它们能以低错误率按顺序执行指令，但对于复杂的程序，特别是包含关键路径和冗余指令的程序，模拟效果较差。我们提出了一种逐行模拟代码执行的方法来解决这个问题。

    

    我们调查了大型语言模型（LLMs）在模拟计算机代码和算法执行方面的能力。我们首先研究了直线程序，并展示了当前LLMs在处理这样简单的程序时表现出的性能较差——性能随着代码长度的增加而迅速下降。接着，我们研究了LLMs在模拟包含关键路径和冗余指令的程序方面的能力。我们还通过排序算法和嵌套循环超越了直线程序的模拟，并展示了程序的计算复杂性直接影响LLMs模拟其执行的能力。我们观察到LLMs只有在处理短程序或标准过程时才能以低错误率按顺序执行指令。LLMs的代码模拟与它们的模式识别和记忆能力存在矛盾：在记忆对任务有害的情况下，我们提出了一种新的提示方法，逐行模拟代码的执行。

    We investigate the extent to which Large Language Models (LLMs) can simulate the execution of computer code and algorithms. We begin by looking straight line programs, and show that current LLMs demonstrate poor performance even with such simple programs -- performance rapidly degrades with the length of code. We then investigate the ability of LLMs to simulate programs that contain critical paths and redundant instructions. We also go beyond straight line program simulation with sorting algorithms and nested loops, and we show the computational complexity of a routine directly affects the ability of an LLM to simulate its execution. We observe that LLMs execute instructions sequentially and with a low error margin only for short programs or standard procedures. LLMs' code simulation is in tension with their pattern recognition and memorisation capabilities: on tasks where memorisation is detrimental, we propose a novel prompting method to simulate code execution line by line. Empirica
    
[^26]: 通过迭代组合问题来增强数学问题求解

    Augmenting Math Word Problems via Iterative Question Composing. (arXiv:2401.09003v1 [cs.CL])

    [http://arxiv.org/abs/2401.09003](http://arxiv.org/abs/2401.09003)

    本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。

    

    尽管在改善大型语言模型(LLMs)的数学推理能力方面取得了一定进展，但在不使用外部工具的情况下解决竞赛级数学问题仍然对开源LLMs具有挑战性。在这项工作中，我们介绍了MMIQC数据集，这是一个混合处理的网络数据和合成问题-响应对的混合数据集，以提供基础模型更好的数学推理能力。通过在MMIQC上对Mistral-7B(arXiv:2310.06825)进行微调获得的模型Mistral-7B-MMIQC，在MATH(arXiv:2103.03874)上达到了36.0%的准确率，比之前(model size $\sim$7B)的最佳结果高出5.8%。我们的实验还表明，改进的一个重要部分归功于我们的新颖增强方法IQC(迭代组合问题)，其中我们迭代地要求LLM从给定的种子问题中组合新问题，并从另一个LLM中进行拒绝抽样。MMIQC现已在https://huggingface.co/datasets/Vivacem/MMIQC上发布。

    Despite recent progress in improving the mathematical reasoning ability of large language models(LLMs), solving competition-level math problems without the use of external tools remains challenging for open-source LLMs. In this work, we introduce the MMIQC dataset, a mixture of processed web data and synthetic question-response pairs, to equip base models with better mathematical reasoning skills. Mistral-7B-MMIQC, the model obtained by fine-tuning Mistral-7B(arXiv:2310.06825) on MMIQC, achieves 36.0\% accuracy on MATH(arXiv:2103.03874), 5.8\% higher than the previous (model size $\sim$7B) SOTA. Our experiments also show that a large part of the improvement attributes to our novel augmentation method IQC(Iterative Question Composing), where we iteratively ask an LLM to compose new questions from the given seed problems and do rejection sampling from another LLM. MMIQC has now been released on https://huggingface.co/datasets/Vivacem/MMIQC.
    
[^27]: 开发用于生物学和医学的ChatGPT：生物医学问题回答的完整综述

    Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering. (arXiv:2401.07510v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.07510](http://arxiv.org/abs/2401.07510)

    开发用于生物学和医学的ChatGPT，通过自然语言处理和多模态范式，加速了医学问题回答的进展，并且能够处理医学环境中的大规模、多样化、无标签数据分析场景。

    

    ChatGPT通过自然语言处理（NLP）和多模态范式，通过增加医学领域数据的融入，探索了在提供医学诊断、治疗建议和其他医疗支持方面的问答（QA）的战略蓝图。通过将文本、图像、视频和其他模态从通用领域转向医学领域，这些技术加快了医学领域问题回答（MDQA）的进展。它们弥合了人类自然语言和复杂医学领域知识或专家手动注释之间的差距，处理了医学环境中的大规模、多样化、不平衡甚至无标签数据分析场景。我们重点研究的是利用语言模型和多模态范式进行医学问题回答，旨在指导研究界根据其特定的医学研究需求选择合适的机制。

    ChatGPT explores a strategic blueprint of question answering (QA) in delivering medical diagnosis, treatment recommendations, and other healthcare support. This is achieved through the increasing incorporation of medical domain data via natural language processing (NLP) and multimodal paradigms. By transitioning the distribution of text, images, videos, and other modalities from the general domain to the medical domain, these techniques have expedited the progress of medical domain question answering (MDQA). They bridge the gap between human natural language and sophisticated medical domain knowledge or expert manual annotations, handling large-scale, diverse, unbalanced, or even unlabeled data analysis scenarios in medical contexts. Central to our focus is the utilizing of language models and multimodal paradigms for medical question answering, aiming to guide the research community in selecting appropriate mechanisms for their specific medical research requirements. Specialized tasks
    
[^28]: 大型语言模型中的通用漏洞：上下文学习后门攻击

    Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks. (arXiv:2401.05949v1 [cs.CL])

    [http://arxiv.org/abs/2401.05949](http://arxiv.org/abs/2401.05949)

    本研究发现上下文学习范式在大型语言模型中存在漏洞，攻击者可以通过污染示范上下文来操控模型行为，而无需进行微调。这项研究设计了一种名为ICLAttack的后门攻击方法，可以通过污染示范样本和提示来使模型按照预定义的意图行事。

    

    上下文学习是一种在预训练和微调之间弥合差距的范式，在几个自然语言处理任务中展现了高效性，特别是在少样本设置中。与传统的微调方法不同，上下文学习能够适应未见过的任务而无需更新任何参数。尽管被广泛应用，上下文学习仍然容易受到恶意攻击。本研究提出了对这一范式的安全性问题的关切。我们的研究表明，攻击者可以通过污染示范上下文来操控大型语言模型的行为，而无需对模型进行微调。具体来说，我们设计了一种新的后门攻击方法，命名为ICLAttack，针对基于上下文学习的大型语言模型。我们的方法包括两种类型的攻击：污染示范样本和污染提示，可以使模型按照预定义的意图行事。ICLAttack不需要额外的微调。

    In-context learning, a paradigm bridging the gap between pre-training and fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in few-shot settings. Unlike traditional fine-tuning methods, in-context learning adapts pre-trained models to unseen tasks without updating any parameters. Despite being widely applied, in-context learning is vulnerable to malicious attacks. In this work, we raise security concerns regarding this paradigm. Our studies demonstrate that an attacker can manipulate the behavior of large language models by poisoning the demonstration context, without the need for fine-tuning the model. Specifically, we have designed a new backdoor attack method, named ICLAttack, to target large language models based on in-context learning. Our method encompasses two types of attacks: poisoning demonstration examples and poisoning prompts, which can make models behave in accordance with predefined intentions. ICLAttack does not require additional fine-tuning 
    
[^29]: 推理步长对大型语言模型的影响

    The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v1 [cs.CL])

    [http://arxiv.org/abs/2401.04925](http://arxiv.org/abs/2401.04925)

    本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。

    

    思维链条（CoT）对于提高大型语言模型（LLM）的推理能力具有重要作用。然而，CoT的有效性与提示中推理步骤的长度之间的关系仍然不为人所知。为了揭示这一点，我们进行了几个实证实验来探索这些关系。具体而言，我们设计了一些实验，扩展和压缩CoT演示中的合理推理步骤，同时保持其他因素不变。我们得出了以下主要发现。首先，结果表明，在提示中延长推理步骤，即使没有向提示中添加新信息，也会显著提高LLM在多个数据集上的推理能力。相反，缩短推理步骤，即使保留关键信息，也会显著降低模型的推理能力。这一发现突显了CoT提示中步骤数量的重要性，并提供了实际指导。

    Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have the following key findings. First, the results indicate that lengthening the reasoning steps in prompts, even without adding new information into the prompt, considerably enhances LLMs' reasoning abilities across multiple datasets. Alternatively, shortening the reasoning steps, even while preserving the key information, significantly diminishes the reasoning abilities of models. This finding highlights the importance of the number of steps in CoT prompts and provides practical guidance to make 
    
[^30]: 在不断演化的社会规范中的Agent对齐

    Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v1 [cs.CL])

    [http://arxiv.org/abs/2401.04620](http://arxiv.org/abs/2401.04620)

    本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。

    

    基于大型语言模型（LLM）的Agent越来越多地渗透到人类生产和生活的各个领域，凸显了将其与人类价值观对齐的重要性。目前AI系统的对齐主要集中在通过人为干预对LLM进行被动对齐。然而，Agent具有接受环境反馈和自我进化等特性，使得LLM对齐方法变得不足够。为此，我们提出了一个名为EvolutionaryAgent的Agent进化和对齐的进化框架，将Agent对齐转化为适者生存的演化和选择过程。在社会规范不断演化的环境中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率，而对齐不足的Agent则逐渐减少。通过多个角度对与社会规范相对齐的Agent进行的实验结果进行评估。

    Agents based on Large Language Models (LLMs) are increasingly permeating various domains of human production and life, highlighting the importance of aligning them with human values. The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate. In response, we propose an evolutionary framework for agent evolution and alignment, named EvolutionaryAgent, which transforms agent alignment into a process of evolution and selection under the principle of survival of the fittest. In an environment where social norms continuously evolve, agents better adapted to the current social norms will have a higher probability of survival and proliferation, while those inadequately aligned dwindle over time. Experimental results assessing the agents from multiple perspectives in aligning with social norms demonstr
    
[^31]: MR-GSM8K: 大型语言模型评估中的元推理革命

    MR-GSM8K: A Meta-Reasoning Revolution in Large Language Model Evaluation. (arXiv:2312.17080v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.17080](http://arxiv.org/abs/2312.17080)

    本文介绍了一种新的大型语言模型评估范式，通过挑战这些模型进行元推理，从而有效区分它们的认知能力。这一范式的重要性在于能够揭示出传统基准测试无法发现的模型的潜在认知缺陷。

    

    在这项工作中，我们引入了一种新颖的评估范式，用于大型语言模型，这种范式挑战它们从事元推理。这种方法解决了现有的数学问题求解基准中的关键缺陷，传统上用于评估智能体的认知能力。我们的范式将焦点从以结果为导向的评估转移到了更全面的评估，有效地区分了模型之间的认知能力。例如，在我们的基准测试中，GPT-4 的性能较 GPT3-5 提升了五倍。这种新范式的重要意义在于它能够揭示出当前基准测试（如GSM8K）无法发现的大型语言模型的潜在认知缺陷，这是由于基准测试的饱和度和对不同推理能力的有效区分不足。我们的综合分析包括了来自开源和闭源社区的几种最先进的数学模型，揭示了一些关于大型语言模型的认知能力的重要发现。

    In this work, we introduce a novel evaluation paradigm for Large Language Models, one that challenges them to engage in meta-reasoning. This approach addresses critical shortcomings in existing math problem-solving benchmarks, traditionally used to evaluate the cognitive capabilities of agents. Our paradigm shifts the focus from result-oriented assessments, which often overlook the reasoning process, to a more holistic evaluation that effectively differentiates the cognitive capabilities among models. For example, in our benchmark, GPT-4 demonstrates a performance five times better than GPT3-5. The significance of this new paradigm lies in its ability to reveal potential cognitive deficiencies in LLMs that current benchmarks, such as GSM8K, fail to uncover due to their saturation and lack of effective differentiation among varying reasoning abilities. Our comprehensive analysis includes several state-of-the-art math models from both open-source and closed-source communities, uncovering
    
[^32]: 大型语言模型作为自动对话评估器的有效性综合分析

    A Comprehensive Analysis of the Effectiveness of Large Language Models as Automatic Dialogue Evaluators. (arXiv:2312.15407v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.15407](http://arxiv.org/abs/2312.15407)

    本研究对利用大型语言模型（LLMs）进行自动对话评估的应用进行了全面研究，发现LLMs在对话和转向层面上具有多维评估能力，并提出了一套全面的评估方法。

    

    自动评估是对话系统研究中的重要方面。传统的基于参考的自然语言生成指标通常不适用于对话评估。因此，最近的研究提出了各种独特的基于神经网络的无参考指标，更符合人类评估的要求。其中特别值得注意的是大型语言模型（LLMs），尤其是调整指令的变体，如ChatGPT，被证明是人类评判的有希望的替代品。然而，目前关于利用LLMs进行自动对话评估的研究在元评估数据集的数量、评估方式、LLMs的覆盖范围等方面存在局限性。因此，LLMs的效果如何仍然未定。为此，我们对LLMs在自动对话评估中的应用进行了全面的研究。具体而言，我们分析了30种最近出现的LLMs在对话和转向层面上的多维评估能力，使用了一套全面的12个元评估数据集进行评估。

    Automatic evaluation is an integral aspect of dialogue system research. The traditional reference-based NLG metrics are generally found to be unsuitable for dialogue assessment. Consequently, recent studies have suggested various unique, reference-free neural metrics that better align with human evaluations. Notably among them, large language models (LLMs), particularly the instruction-tuned variants like ChatGPT, are shown to be promising substitutes for human judges. Yet, existing works on utilizing LLMs for automatic dialogue evaluation are limited in their scope in terms of the number of meta-evaluation datasets, mode of evaluation, coverage of LLMs, etc. Hence, it remains inconclusive how effective these LLMs are. To this end, we conduct a comprehensive study on the application of LLMs for automatic dialogue evaluation. Specifically, we analyze the multi-dimensional evaluation capability of 30 recently emerged LLMs at both turn and dialogue levels, using a comprehensive set of 12 
    
[^33]: Topic-VQ-VAE: 利用隐变量码本实现灵活的主题导向文档生成

    Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation. (arXiv:2312.11532v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11532](http://arxiv.org/abs/2312.11532)

    本文介绍了一种利用隐变量码本实现灵活的主题导向文档生成的新方法，通过名为TVQ-VAE的生成式主题模型，可以有效捕捉主题上下文，并支持灵活形式的文档生成。

    

    本文介绍了一种利用Vector-Quantized Variational Auto-Encoder（VQ-VAE）中的隐变量码本进行主题建模的新方法，离散地封装了预训练嵌入（例如预训练语言模型）的丰富信息。根据对隐变量码本和嵌入的新解释，我们提出了一种新的生成式主题模型，称为Topic-VQ-VAE（TVQ-VAE），它可以反向生成与相应隐变量码本相关的原始文档。TVQ-VAE可以通过包括传统的词袋（BoW）分布和自回归图像生成在内的各种生成分布来可视化主题。我们在文档分析和图像生成上的实验结果表明，TVQ-VAE可以有效捕捉主题上下文，揭示数据集的潜在结构，并支持灵活形式的文档生成。所提出的TVQ-VAE的官方实现可在https://github.com/clo找到。

    This paper introduces a novel approach for topic modeling utilizing latent codebooks from Vector-Quantized Variational Auto-Encoder~(VQ-VAE), discretely encapsulating the rich information of the pre-trained embeddings such as the pre-trained language model. From the novel interpretation of the latent codebooks and embeddings as conceptual bag-of-words, we propose a new generative topic model called Topic-VQ-VAE~(TVQ-VAE) which inversely generates the original documents related to the respective latent codebook. The TVQ-VAE can visualize the topics with various generative distributions including the traditional BoW distribution and the autoregressive image generation. Our experimental results on document analysis and image generation demonstrate that TVQ-VAE effectively captures the topic context which reveals the underlying structures of the dataset and supports flexible forms of document generation. Official implementation of the proposed TVQ-VAE is available at https://github.com/clo
    
[^34]: 追求最优统计水印技术

    Towards Optimal Statistical Watermarking. (arXiv:2312.07930v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.07930](http://arxiv.org/abs/2312.07930)

    追求最优统计水印技术。通过将统计水印技术视为假设检验问题并引入伪随机生成器，我们实现了输出令牌和拒绝区域的耦合，实现了第一类错误和第二类错误之间的非平凡权衡，同时提出了最统一最有力的水印和最小化第二类错误的解决方案。我们还提供了独立同分布令牌数量的上下界，突显了改进的潜力。此外，我们还探讨了鲁棒性水印问题。

    

    我们将统计水印技术作为一个假设检验问题进行研究，这是一个泛化了所有之前统计水印方法的通用框架。我们的关键是通过实践中的伪随机生成器实现输出令牌和拒绝区域的耦合，从而允许在第一类错误和第二类错误之间进行非平凡的权衡。我们在一般的假设检验环境下表征了最统一最有力的水印以及在模型无关的环境中最小化第二类错误。在输出是$n$个令牌的常见情况下，我们对需要保证小的第一类和第二类错误的独立同分布令牌数量建立了近乎匹配的上下界。与之前的工作中的$ h ^ {-2} $速率相比，我们相对于每个令牌的平均熵$h$的速率为$ \Theta(h ^ {-1} \log (1/h)) $，突显了改进的潜力。此外，我们提出了鲁棒性水印问题，其中用户都是...

    We study statistical watermarking by formulating it as a hypothesis testing problem, a general framework which subsumes all previous statistical watermarking methods. Key to our formulation is a coupling of the output tokens and the rejection region, realized by pseudo-random generators in practice, that allows non-trivial trade-off between the Type I error and Type II error. We characterize the Uniformly Most Powerful (UMP) watermark in the general hypothesis testing setting and the minimax Type II error in the model-agnostic setting. In the common scenario where the output is a sequence of $n$ tokens, we establish nearly matching upper and lower bounds on the number of i.i.d. tokens required to guarantee small Type I and Type II errors. Our rate of $\Theta(h^{-1} \log (1/h))$ with respect to the average entropy per token $h$ highlights potentials for improvement from the rate of $h^{-2}$ in the previous works. Moreover, we formulate the robust watermarking problem where users are all
    
[^35]: 强化断言的少样本学习：用于大型语言模型生成教育解释的教导技术。

    Assertion Enhanced Few-Shot Learning: Instructive Technique for Large Language Models to Generate Educational Explanations. (arXiv:2312.03122v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.03122](http://arxiv.org/abs/2312.03122)

    本研究提出了一种强化断言的少样本学习技术，用于大型语言模型生成精确、详细的教育解释。实验结果显示，该方法在解释准确性上提升了15%，获得了教师评估为高质量的解释。

    

    人类教育者具备从学生中预测并寻求教育解释的内在能力，当学生无法独立表达这些解释时，他们能够提出发人深省的问题。我们的目标是利用大型语言模型的少样本学习能力为智能辅导系统赋予这种能力。我们的工作提出了一种新颖的教导技术，即强化断言的少样本学习，以促进准确、详细的教育解释的生成。我们的核心假设是，在教育领域，少样本演示是必要但不足以保证高质量的解释生成的条件。我们进行了一项涉及12名在职教师的研究，将我们的方法与传统的少样本学习进行了比较。结果显示，强化断言的少样本学习将解释准确性提高了15%，并得到了教师评估为高质量的解释。我们还进行了定性的剔除研究。

    Human educators possess an intrinsic ability to anticipate and seek educational explanations from students, which drives them to pose thought-provoking questions when students cannot articulate these explanations independently. We aim to imbue Intelligent Tutoring Systems with this ability using few-shot learning capability of Large Language Models. Our work proposes a novel prompting technique, Assertion Enhanced Few-Shot Learning, to facilitate the generation of accurate, detailed oriented educational explanations. Our central hypothesis is that, in educational domain, few-shot demonstrations are necessary but not a sufficient condition for quality explanation generation. We conducted a study involving 12 in-service teachers, comparing our approach to Traditional Few-Shot Learning. The results show that Assertion Enhanced Few-Shot Learning improves explanation accuracy by 15% and yields higher-quality explanations, as evaluated by teachers. We also conduct a qualitative ablation stud
    
[^36]: GNN2R: 基于弱监督的知识图谱问答中提供理由的问题回答方法

    GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge Graphs. (arXiv:2312.02317v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.02317](http://arxiv.org/abs/2312.02317)

    GNN2R是一种基于图神经网络的两步推理模型，通过弱监督训练，能够在知识图谱问答中提供最终答案以及推理子图的理由。该方法解决了现有方法缺乏解释以及效率低下的问题。

    

    目前大多数基于知识图谱的多跳问题回答方法只提供最终的确定答案，而没有解释，对于普通用户难以理解和查看的KG实体集。这严重限制了知识图谱问答在现实场景中的应用。本文提出了一种基于图神经网络的两步推理模型（GNN2R）来解决这个问题。GNN2R能够通过仅有的问题-最终答案对提供最终答案以及作为最终答案背后的推理子图的理由，且仅需要通过弱监督进行训练。我们对GNN2R进行了大量评估，并进行了详细的实验。

    Most current methods for multi-hop question answering (QA) over knowledge graphs (KGs) only provide final conclusive answers without explanations, such as a set of KG entities that is difficult for normal users to review and comprehend. This issue severely limits the application of KG-based QA in real-world scenarios. However, it is non-trivial to solve due to two challenges: First, annotations of reasoning chains of multi-hop questions, which could serve as supervision for explanation generation, are usually lacking. Second, it is difficult to maintain high efficiency when explicit KG triples need to be retrieved to generate explanations. In this paper, we propose a novel Graph Neural Network-based Two-Step Reasoning model (GNN2R) to solve this issue. GNN2R can provide both final answers and reasoning subgraphs as a rationale behind final answers efficiently with only weak supervision that is available through question-final answer pairs. We extensively evaluated GNN2R with detailed a
    
[^37]: 注释敏感性：训练数据收集方法影响模型性能

    Annotation Sensitivity: Training Data Collection Methods Affect Model Performance. (arXiv:2311.14212v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2311.14212](http://arxiv.org/abs/2311.14212)

    该研究发现训练数据收集方法对注释本身和下游模型性能产生影响。在对仇恨言论和冒犯性语言进行注释收集的实验中，发现注释工具的设计选择会对模型的性能产生明显差异。

    

    当训练数据由人工注释者收集时，注释工具的设计、给予注释者的指示、注释者的特征以及他们之间的互动都可能对训练数据产生影响。这项研究证明了创建注释工具时的设计选择也会影响基于得到的注释训练的模型。我们引入了"注释敏感性"这个术语，用来指代注释数据收集方法对注释本身以及下游模型性能和预测的影响。我们在五种实验条件下对仇恨言论和冒犯性语言进行注释收集，随机将注释者分配到不同条件下。然后，在每个得到的五个数据集上对BERT模型进行微调，并在每个条件的保留部分上评估模型性能。我们发现在以下方面条件之间存在明显差异：1）仇恨言论/冒犯性语言注释的比例，2）模型性能。

    When training data are collected from human annotators, the design of the annotation instrument, the instructions given to annotators, the characteristics of the annotators, and their interactions can impact training data. This study demonstrates that design choices made when creating an annotation instrument also impact the models trained on the resulting annotations. We introduce the term annotation sensitivity to refer to the impact of annotation data collection methods on the annotations themselves and on downstream model performance and predictions. We collect annotations of hate speech and offensive language in five experimental conditions of an annotation instrument, randomly assigning annotators to conditions. We then fine-tune BERT models on each of the five resulting datasets and evaluate model performance on a holdout portion of each condition. We find considerable differences between the conditions for 1) the share of hate speech/offensive language annotations, 2) model per
    
[^38]: 统一自然语言处理和软件工程视角：代码语言模型综述

    Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code. (arXiv:2311.07989v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.07989](http://arxiv.org/abs/2311.07989)

    这篇论文系统地回顾了代码处理方面的语言模型的最新进展，涵盖了50多个模型、30多个评估任务、170多个数据集和700多个相关工作。它突出了代码建模从统计模型和RNN到预训练的Transformer和LLM之间的历史转变，并讨论了代码特定的特性和关键挑战。

    

    在这项工作中，我们系统地回顾了最近在代码处理中的语言模型方面的进展，涵盖了50多个模型、30多个评估任务、170多个数据集和700多个相关工作。我们将代码处理模型分为通用语言模型（如GPT系列）和专门在代码上预训练的模型，通常具有专门的目标。我们讨论了这些模型之间的关系和差异，并突出了代码建模从统计模型和RNN到预训练的Transformer和LLM之间的历史转变，这正是NLP也经历的过程。我们还讨论了代码特定的特性，如AST、CFG和单元测试，以及它们在训练代码语言模型中的应用，并确定了该领域中的关键挑战和潜在的未来方向。我们将这份综述保持开放，并在GitHub上更新，网址为https://github.com/codefuse-ai/Awesome-Code-LLM。

    In this work we systematically review the recent advancements in code processing with language models, covering 50+ models, 30+ evaluation tasks, 170+ datasets, and 700+ related works. We break down code processing models into general language models represented by the GPT family and specialized models that are specifically pretrained on code, often with tailored objectives. We discuss the relations and differences between these models, and highlight the historical transition of code modeling from statistical models and RNNs to pretrained Transformers and LLMs, which is exactly the same course that had been taken by NLP. We also discuss code-specific features such as AST, CFG, and unit tests, along with their application in training code language models, and identify key challenges and potential future directions in this domain. We keep the survey open and updated on GitHub at https://github.com/codefuse-ai/Awesome-Code-LLM.
    
[^39]: Rosetta Stone在KSAA-RD共享任务中：从语言建模到词--定义对齐的跃进。

    Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment. (arXiv:2310.15823v1 [cs.CL])

    [http://arxiv.org/abs/2310.15823](http://arxiv.org/abs/2310.15823)

    本论文介绍了在KSAA-RD共享任务中Rosetta Stone的应用，将语言建模应用到词--定义对齐中。论文通过使用一组微调的阿拉伯BERT模型来预测给定定义的词嵌入，从而实现了阿拉伯词的向量表示。

    

    反向词典是一种工具，可根据提供的定义、含义或描述来发现一个词。这种技术在各种场景中都非常有价值，可以帮助掌握一个词的描述而不知其身份的语言学习者，并使寻求精确术语的写作者受益。这些场景通常涵盖被称为“舌尖上的词”现象。在这项工作中，我们呈现了我们在阿拉伯语反向词典共享任务中获胜的解决方案。该任务的重点是从伴随的描述中推导出阿拉伯词的向量表示。共享任务包括两个不同的子任务：第一个子任务涉及一个阿拉伯定义作为输入，而第二个子任务则使用一个英文定义。对于第一个子任务，我们的方法依赖于一组经过微调的阿拉伯BERT模型，来预测给定定义的词嵌入。最终表示是通过对每个模型输出的嵌入进行平均得到的。

    A Reverse Dictionary is a tool enabling users to discover a word based on its provided definition, meaning, or description. Such a technique proves valuable in various scenarios, aiding language learners who possess a description of a word without its identity, and benefiting writers seeking precise terminology. These scenarios often encapsulate what is referred to as the "Tip-of-the-Tongue" (TOT) phenomena. In this work, we present our winning solution for the Arabic Reverse Dictionary shared task. This task focuses on deriving a vector representation of an Arabic word from its accompanying description. The shared task encompasses two distinct subtasks: the first involves an Arabic definition as input, while the second employs an English definition. For the first subtask, our approach relies on an ensemble of finetuned Arabic BERT-based models, predicting the word embedding for a given definition. The final representation is obtained through averaging the output embeddings from each m
    
[^40]: IDEAL: 强化大型语言模型中上下文学习的影响驱动选择性注释方法

    IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models. (arXiv:2310.10873v1 [cs.CL])

    [http://arxiv.org/abs/2310.10873](http://arxiv.org/abs/2310.10873)

    本文提出了一种影响驱动的选择性注释方法，用于在大型语言模型中改善上下文学习。该方法通过选择关键的未标记数据子集进行注释，在降低注释成本的同时提高了上下文示例的质量。

    

    上下文学习是一种有前景的范式，它利用上下文示例作为大型语言模型预测的提示。这些提示对于获得强大的性能至关重要。然而，由于这些提示需要从大量注释的示例中进行采样，找到正确的提示可能导致高昂的注释成本。为解决这一挑战，本文引入了一种基于影响驱动的选择性注释方法，旨在在改善上下文示例质量的同时最大程度地降低注释成本。我们的方法的核心是从大规模未标记的数据池中选择一个关键子集进行注释，以用于后续的提示采样。具体地，首先构建一个有向图来表示未标记的数据，然后利用扩散过程量化候选未标记子集的影响力，最后引入一个简单又有效的贪心算法来选择未标记的数据。如果数据提供了最大的影响力，算法就会迭代地选择这些数据。

    In-context learning is a promising paradigm that utilizes in-context examples as prompts for the predictions of large language models. These prompts are crucial for achieving strong performance. However, since the prompts need to be sampled from a large volume of annotated examples, finding the right prompt may result in high annotation costs. To address this challenge, this paper introduces an influence-driven selective annotation method that aims to minimize annotation costs while improving the quality of in-context examples. The essence of our method is to select a pivotal subset from a large-scale unlabeled data pool to annotate for the subsequent sampling of prompts. Specifically, a directed graph is first constructed to represent unlabeled data. Afterward, the influence of candidate unlabeled subsets is quantified with a diffusion process. A simple yet effective greedy algorithm for unlabeled data selection is lastly introduced. It iteratively selects the data if it provides a ma
    
[^41]: EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling. (arXiv:2310.04691v2 [cs.CL] UPDATED)

    EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling. (arXiv:2310.04691v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.04691](http://arxiv.org/abs/2310.04691)

    EMO提出了地球移动距离优化（EMO）来解决语言模型中的退化现象。EMO利用了地球移动距离的特性，并引入了一个可行的上界来简化训练。经过评估，发现EMO在语言模型上有显著的改进。

    

    神经语言模型是人文本的概率模型。它们主要通过最大似然估计（MLE）进行训练，该方法等同于最小化经验数据分布和模型分布之间的前向交叉熵。然而，当从这些模型学习的分布解码时，仍然经常观察到各种退化现象。我们确定前向交叉熵作为人与模型分布对齐的距离度量是次优的，原因有：（1）召回优化，（2）负样本多样性忽视和（3）训练测试不匹配。在本文中，我们提出了用于自回归语言模型的地球移动距离优化（EMO）。EMO利用地球移动距离的内在特性来解决上述挑战。由于直接计算的复杂性，我们进一步引入了一种可行的EMO上界来简化端到端训练。经过广泛评估之后，发现我们的方法在语言模型上有显著的改进。

    Neural language models are probabilistic models of human text. They are predominantly trained using maximum likelihood estimation (MLE), which is equivalent to minimizing the forward cross-entropy between the empirical data distribution and the model distribution. However, various degeneration phenomena are still widely observed when decoding from the distributions learned by such models. We establish that the forward cross-entropy is suboptimal as a distance metric for aligning human and model distribution due to its (1) recall-prioritization (2) negative diversity ignorance and (3) train-test mismatch. In this paper, we propose Earth Mover Distance Optimization (EMO) for auto-regressive language modeling. EMO capitalizes on the inherent properties of earth mover distance to address the aforementioned challenges. Due to the high complexity of direct computation, we further introduce a feasible upper bound for EMO to ease end-to-end training. Upon extensive evaluation of language model
    
[^42]: MathVista: 用GPT-4V、Bard和其他大型多模态模型评估视觉场景中的数学推理能力

    MathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V, Bard, and Other Large Multimodal Models. (arXiv:2310.02255v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.02255](http://arxiv.org/abs/2310.02255)

    本论文提出了MathVista，这是一个评估视觉场景中数学推理能力的基准测试。通过对12个著名的基础模型进行全面的定量评估，发现最好的GPT-4V模型相对于第二名的Bard模型在准确率上提升了15.1%。

    

    大型语言模型（LLMs）和大型多模态模型（LMMs）在许多任务和领域中展示出令人印象深刻的问题解决能力，但它们在视觉环境中的数学推理能力尚未得到系统研究。为了弥补这一差距，我们提出了MathVista，这是一个综合了不同数学和视觉任务的挑战的基准测试。它包含了6141个例子，其中有28个现有的多模态数据集和3个新创建的数据集（即IQTest、FunctionQA和PaperQA）。完成这些任务需要精细的、深入的视觉理解和组合推理，这些都是当前最先进的基础模型所面临的困难。通过MathVista，我们对12个著名的基础模型进行了全面的定量评估。表现最好的GPT-4V模型的整体准确率为49.9%，明显优于第二名的Bard模型，相差15.1%。我们的深入分析揭示了

    Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MathVista, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 examples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging. With MathVista, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of
    
[^43]: TWIZ-v2: 多模态对话刺激的巫师

    TWIZ-v2: The Wizard of Multimodal Conversational-Stimulus. (arXiv:2310.02118v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.02118](http://arxiv.org/abs/2310.02118)

    TWIZ-v2是一个多模态对话刺激的巫师助手，旨在通过以人性化的方式提供信息、利用多种模态进行刺激以及改进对未见过场景的交互鲁棒性来引导用户成功完成复杂的手动任务。

    

    在本报告中，我们描述了Task Wizard团队TWIZ在Alexa Prize TaskBot Challenge 2022中的愿景、挑战和科学贡献。我们的愿景是构建TWIZ机器人作为一个有用、多模态、知识丰富和引人入胜的助手，可以引导用户成功完成复杂的手动任务。为了实现这一目标，我们将我们的努力集中在三个主要的研究问题上：（1）以人性化的对话方式提供信息；（2）利用声音、图像和视频等各种模态进行多模态刺激；（3）零-shot对话流程，以提高对未见过场景的交互的鲁棒性。TWIZ是一个能支持各种任务的助手，具有创新的功能，如创意烹饪、通过声音导航视频和强大的TWIZ-LLM，一个用于复杂手动任务对话的大型语言模型。根据用户提供的评级和反馈，我们观察到

    In this report, we describe the vision, challenges, and scientific contributions of the Task Wizard team, TWIZ, in the Alexa Prize TaskBot Challenge 2022. Our vision, is to build TWIZ bot as an helpful, multimodal, knowledgeable, and engaging assistant that can guide users towards the successful completion of complex manual tasks. To achieve this, we focus our efforts on three main research questions: (1) Humanly-Shaped Conversations, by providing information in a knowledgeable way; (2) Multimodal Stimulus, making use of various modalities including voice, images, and videos; and (3) Zero-shot Conversational Flows, to improve the robustness of the interaction to unseen scenarios. TWIZ is an assistant capable of supporting a wide range of tasks, with several innovative features such as creative cooking, video navigation through voice, and the robust TWIZ-LLM, a Large Language Model trained for dialoguing about complex manual tasks. Given ratings and feedback provided by users, we observ
    
[^44]: 谁是ChatGPT？使用PsychoBench对LLMs的心理描绘进行基准测试

    Who is ChatGPT? Benchmarking LLMs' Psychological Portrayal Using PsychoBench. (arXiv:2310.01386v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.01386](http://arxiv.org/abs/2310.01386)

    本文提出了PsychoBench框架，用于评估LLMs的心理因素，并对text-davinci-003、gpt-3.5-turbo、gpt-4、LLaMA-2-7b和LLaMA-2-13b等五个模型进行研究。

    

    大型语言模型（LLMs）最近展示了其卓越的能力，不仅在自然语言处理任务中，而且跨越了临床医学、法律咨询和教育等各个领域。LLMs已经超出了简单的应用，演变成能够解决各种用户请求的助手。这缩小了人类和人工智能代理之间的差距，引发了有关LLMs内部个性、性格和情绪潜在表现的有趣问题。在本文中，我们提出了一个框架PsychoBench，用于评估LLMs的各种心理因素。PsychoBench由临床心理学中常用的13个量表组成，进一步将这些量表分为四个不同的类别：人格特质、人际关系、动机测试和情感能力。我们的研究重点考察了五个流行的模型，分别是text-davinci-003、gpt-3.5-turbo、gpt-4、LLaMA-2-7b和LLaMA-2-13b。

    Large Language Models (LLMs) have recently showcased their remarkable capacities, not only in natural language processing tasks but also across diverse domains such as clinical medicine, legal consultation, and education. LLMs become more than mere applications, evolving into assistants capable of addressing diverse user requests. This narrows the distinction between human beings and artificial intelligence agents, raising intriguing questions regarding the potential manifestation of personalities, temperaments, and emotions within LLMs. In this paper, we propose a framework, PsychoBench, for evaluating diverse psychological aspects of LLMs. Comprising thirteen scales commonly used in clinical psychology, PsychoBench further classifies these scales into four distinct categories: personality traits, interpersonal relationships, motivational tests, and emotional abilities. Our study examines five popular models, namely text-davinci-003, gpt-3.5-turbo, gpt-4, LLaMA-2-7b, and LLaMA-2-13b. 
    
[^45]: 通过大型语言模型生成机器人模拟任务的GenSim

    GenSim: Generating Robotic Simulation Tasks via Large Language Models. (arXiv:2310.01361v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.01361](http://arxiv.org/abs/2310.01361)

    GenSim通过利用大型语言模型自动生成丰富的模拟环境和专家示范，解决了目前模拟数据中缺乏任务级别多样性的问题，提高了机器人策略在任务级别上的泛化能力。

    

    由于收集大量真实交互数据来训练通用机器人策略往往代价高昂，因此在数据生成方面通常采用模拟数据。然而，现有的数据生成方法通常专注于场景级别的多样性（例如对象实例和姿势），而忽视了任务级别的多样性，这是因为需要人工努力提出和验证新的任务。这导致在模拟数据上训练的策略很难展示显著的任务级别泛化能力。本文提出了一种通过利用大型语言模型（LLM）的基于场景和编码能力自动生成丰富的模拟环境和专家示范的方法，称为GenSim。我们的方法有两种模式：目标导向生成，其中将目标任务提供给LLM，LLM提出解决目标任务的任务课程；探索性生成，其中LLM从先前的任务中启动，并迭代地提出新的任务。

    Collecting large amounts of real-world interaction data to train general robotic policies is often prohibitively expensive, thus motivating the use of simulation data. However, existing methods for data generation have generally focused on scene-level diversity (e.g., object instances and poses) rather than task-level diversity, due to the human effort required to come up with and verify novel tasks. This has made it challenging for policies trained on simulation data to demonstrate significant task-level generalization. In this paper, we propose to automatically generate rich simulation environments and expert demonstrations by exploiting a large language models' (LLM) grounding and coding ability. Our approach, dubbed GenSim, has two modes: goal-directed generation, wherein a target task is given to the LLM and the LLM proposes a task curriculum to solve the target task, and exploratory generation, wherein the LLM bootstraps from previous tasks and iteratively proposes novel tasks th
    
[^46]: 坏角色好顾问：探索大型语言模型在假新闻检测中的作用

    Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. (arXiv:2309.12247v1 [cs.CL])

    [http://arxiv.org/abs/2309.12247](http://arxiv.org/abs/2309.12247)

    大型语言模型对于假新闻检测的潜力仍未得到充分探索。实证研究发现，尽管复杂的大型语言模型能够揭示假新闻并提供多角度解释，但仍不如经过fine-tuned的小型语言模型表现出色。当前的大型语言模型可能无法取代小型语言模型，但可以作为一个良好的辅助顾问。

    

    检测假新闻需要对多样线索有敏锐的感知和对现实世界背景有深入的理解，对于基于小型语言模型的检测器来说，由于其知识和能力的限制，这仍然是具有挑战性的。近期大型语言模型的进步在各种任务中表现出了卓越的性能，但大型语言模型能否以及如何帮助假新闻检测仍然未经过深入研究。在本文中，我们研究了大型语言模型在假新闻检测中的潜力。首先，我们进行了实证研究，发现像GPT 3.5这样的复杂大型语言模型通常能够揭示假新闻并提供理想的多角度解释，但仍然不如基础小型语言模型fine-tuned BERT表现出色。我们随后的分析将这种差距归因于大型语言模型不能正确选择并整合证据以得出结论。基于这些发现，我们提出当前的大型语言模型可能无法取代在假新闻检测中经过fine-tuned的小型语言模型，但可以作为一个良好的辅助顾问。

    Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good a
    
[^47]: ChaCha：利用大型语言模型引导儿童分享与个人事件相关的情绪

    ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events. (arXiv:2309.12244v1 [cs.HC])

    [http://arxiv.org/abs/2309.12244](http://arxiv.org/abs/2309.12244)

    ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。

    

    儿童通常通过与家人或他人分享故事和感受来学习辨识和表达情绪，然而，由于儿童正在发展他们的交流技能，父母或兄弟姐妹很难与他们进行情感沟通。本文介绍了ChaCha，一个鼓励和引导儿童分享个人事件和相关情绪的聊天机器人。ChaCha结合了状态机和大型语言模型（LLMs），在进行自由对话的同时保持对话的方向性。通过与20名年龄在8-12岁的儿童进行的探索性研究，我们研究了ChaCha如何促使儿童分享个人事件并引导他们描述相关情绪。参与者认为ChaCha就像一个亲密的朋友，并分享了各种主题的故事，如家庭旅行和个人成就。基于定量和定性发现，我们讨论了利用LLMs设计适合儿童的聊天机器人的机遇。

    Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to
    
[^48]: DePT:分解提示调整以实现参数高效微调

    DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning. (arXiv:2309.05173v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05173](http://arxiv.org/abs/2309.05173)

    DePT通过将软提示分解为较短的软提示和一对低秩矩阵，并用两个不同的学习率来优化，以解决提示调整对训练和推理时间以及内存使用的影响，从而实现更好的性能。

    

    提示调整（PT）是一种将可训练的少量软提示向量附加到语言模型（LM）输入中的参数高效微调（PEFT）方法，已在各种任务和模型中显示出了有希望的结果。 与其他PEFT方法相比，PT的竞争性能可以在可训练参数更少的情况下保持，并且随着模型规模的扩大，其参数并不会显著增加。 但是，PT引入了额外的软提示标记，导致输入序列变长，这对于Transformer的二次复杂度而言，在训练和推理时间以及内存使用方面会产生显著影响。 这对于面临大量每日查询的大型语言模型（LLMs）尤其令人担忧。

    Prompt tuning (PT), where a small amount of trainable soft (continuous) prompt vectors is affixed to the input of language models (LM), has shown promising results across various tasks and models for parameter-efficient fine-tuning (PEFT). PT stands out from other PEFT approaches because it maintains competitive performance with fewer trainable parameters and does not drastically scale up its parameters as the model size expands. However, PT introduces additional soft prompt tokens, leading to longer input sequences, which significantly impacts training and inference time and memory usage due to the Transformer's quadratic complexity. Particularly concerning for Large Language Models (LLMs) that face heavy daily querying. To address this issue, we propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt into a shorter soft prompt and a pair of low-rank matrices that are then optimised with two different learning rates. This allows DePT to achieve better performance whi
    
[^49]: ChatRule：利用大型语言模型挖掘知识图谱推理中的逻辑规则

    ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning. (arXiv:2309.01538v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.01538](http://arxiv.org/abs/2309.01538)

    本论文提出了一个框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。该框架通过充分利用知识图谱的语义和结构信息，能够提高推理性能并提供可解释的结果。

    

    逻辑规则对于发现关系之间的逻辑连接至关重要，可以提高推理性能并提供可解释的知识图谱结果。尽管已经有许多努力在知识图谱上挖掘有意义的逻辑规则，但现有方法在规则空间上搜索计算密集且缺乏可伸缩性，尤其是对于大规模知识图谱。此外，它们常常忽视了关系的语义，而这对于揭示逻辑连接至关重要。最近，大型语言模型（LLMs）在自然语言处理领域和各种应用中展现出了令人瞩目的性能，归功于它们的新能力和泛化能力。在本文中，我们提出了一个新颖的框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。具体而言，该框架以基于LLM的规则生成器为初始，充分利用了知识图谱的语义和结构信息。

    Logical rules are essential for uncovering the logical connections between relations, which could improve the reasoning performance and provide interpretable results on knowledge graphs (KGs). Although there have been many efforts to mine meaningful logical rules over KGs, existing methods suffer from the computationally intensive searches over the rule space and a lack of scalability for large-scale KGs. Besides, they often ignore the semantics of relations which is crucial for uncovering logical connections. Recently, large language models (LLMs) have shown impressive performance in the field of natural language processing and various applications, owing to their emergent ability and generalizability. In this paper, we propose a novel framework, ChatRule, unleashing the power of large language models for mining logical rules over knowledge graphs. Specifically, the framework is initiated with an LLM-based rule generator, leveraging both the semantic and structural information of KGs 
    
[^50]: TIM: 使用对比教授大型语言模型进行翻译

    TIM: Teaching Large Language Models to Translate with Comparison. (arXiv:2307.04408v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.04408](http://arxiv.org/abs/2307.04408)

    我们提出了一个使用对比教授大型语言模型进行翻译的新框架，通过向模型呈现正确和错误翻译的示例并使用偏好损失来指导模型学习，我们证明该方法优于现有方法，在精调LLMs用于翻译任务方面提供了新的视角。

    

    开源的大型语言模型（LLMs）在通过指令调整方面展示了出色的效果。然而，这些模型在需要更专业知识的任务（如翻译）中有时会遇到困难。这种不足的可能原因之一是指令调整旨在生成流畅、连贯的文本，而不受任何任务特定要求的限制。此外，调整较小的LLM并使用较低质量的训练数据可能更具挑战性。为了解决这个问题，我们提出了一个使用例子进行对比教授LLMs学习翻译的新框架。我们的方法涉及向模型呈现正确和错误翻译的示例，并使用偏好损失来指导模型的学习。我们在WMT2022测试集上评估了我们的方法，并证明其优于现有方法。我们的发现为精调LLMs用于翻译任务提供了新的视角。

    Open-sourced large language models (LLMs) have demonstrated remarkable efficacy in various tasks with instruction tuning. However, these models can sometimes struggle with tasks that require more specialized knowledge such as translation. One possible reason for such deficiency is that instruction tuning aims to generate fluent and coherent text that continues from a given instruction without being constrained by any task-specific requirements. Moreover, it can be more challenging for tuning smaller LLMs with lower-quality training data. To address this issue, we propose a novel framework using examples in comparison to teach LLMs to learn translation. Our approach involves presenting the model with examples of correct and incorrect translations and using a preference loss to guide the model's learning. We evaluate our method on WMT2022 test sets and show that it outperforms existing methods. Our findings offer a new perspective on fine-tuning LLMs for translation tasks and provide a p
    
[^51]: 用深度学习简化社交媒体信息检索以支持公共卫生研究

    Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning. (arXiv:2306.16001v1 [cs.CL])

    [http://arxiv.org/abs/2306.16001](http://arxiv.org/abs/2306.16001)

    本研究介绍了一个使用深度学习简化社交媒体信息检索的框架，通过识别医学实体、标准化实体和分配UMLS概念，构建了一个用于COVID-19相关推文的症状词典。

    

    社交媒体在流行病监测中的利用已经得到了很好的证实。然而，当使用预定义的词汇表来检索相关语料库时，常常会引入偏见。本研究介绍了一个框架，旨在构建医学俗语和统一医学语言系统（UMLS）概念的广泛字典。该框架由三个模块组成：基于BERT的命名实体识别（NER）模型，用于从社交媒体内容中识别出医学实体；深度学习驱动的标准化模块，用于对提取出的实体进行规范化处理；半监督聚类模块，将最可能的UMLS概念分配给每个规范化实体。我们将该框架应用于从2020年2月1日到2022年4月30日期间与COVID-19相关的推文，生成了一个症状词典（可在https://github.com/ningkko/UMLS_colloquialism/上获取），其中包含9,249个标准化实体，映射到876个UMLS概念和38,175个俚语表达。该框架的演示

    The utilization of social media in epidemic surveillance has been well established. Nonetheless, bias is often introduced when pre-defined lexicons are used to retrieve relevant corpus. This study introduces a framework aimed at curating extensive dictionaries of medical colloquialisms and Unified Medical Language System (UMLS) concepts. The framework comprises three modules: a BERT-based Named Entity Recognition (NER) model that identifies medical entities from social media content, a deep-learning powered normalization module that standardizes the extracted entities, and a semi-supervised clustering module that assigns the most probable UMLS concept to each standardized entity. We applied this framework to COVID-19-related tweets from February 1, 2020, to April 30, 2022, generating a symptom dictionary (available at https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249 standardized entities mapped to 876 UMLS concepts and 38,175 colloquial expressions. This framework demo
    
[^52]: 具有模糊输入的零和少样本语义解析

    Zero and Few-shot Semantic Parsing with Ambiguous Inputs. (arXiv:2306.00824v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00824](http://arxiv.org/abs/2306.00824)

    该论文提出了一个名为AmP的框架、数据集和挑战，用于将模糊自然语言翻译成形式化表示，如逻辑和代码。研究发现，大型预训练模型在没有明确指示的情况下难以捕捉到可能的意义分布，但当输入中存在模糊性时，模型能够很好地捕捉到分布。

    

    尽管用自然语言表示意思时常常会遇到模糊性的挑战，但在将语言映射到形式化设计的表示时，这种模糊性经常被忽略或故意删除，这些任务通常假设语言和形式化表示之间有一对一的映射。我们尝试通过引入 AmP，一个将模糊自然语言翻译成逻辑和代码等形式化表示的框架、数据集和挑战，来解决这个问题。我们定义了模板并生成了五个明确记录的语言模糊性的数据。使用 AmP，我们研究了几个零样本文本到代码系统如何处理模糊性，并引入了三个新的指标。我们发现，大型预训练模型在没有明确指示的情况下很难捕捉到可能意义的分布。然而，当输入中存在模糊性时，模型能够很好地捕捉到分布。这些结果呼吁在数据集中明确包含模糊性。

    Despite the frequent challenges posed by ambiguity when representing meaning via natural language, it is often ignored or deliberately removed in tasks mapping language to formally-designed representations, which generally assume a one-to-one mapping between linguistic and formal representations. We attempt to address this shortcoming by introducing AmP, a framework, dataset, and challenge for translating ambiguous natural language to formal representations like logic and code. We define templates and generate data for five well-documented linguistic ambiguities. Using AmP, we investigate how several few-shot text-to-code systems handle ambiguity, introducing three new metrics. We find that large pre-trained models perform poorly at capturing the distribution of possible meanings without deliberate instruction. However, models are able to capture the distribution well when ambiguity is attested in their inputs. These results motivate a call for including ambiguity explicitly in dataset
    
[^53]: 生物医学自然语言处理中的大型语言模型: 基准、基线和建议

    Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])

    [http://arxiv.org/abs/2305.16326](http://arxiv.org/abs/2305.16326)

    本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。

    

    生物医学文献呈指数级增长，手动筛选和提取知识变得困难。自动从生物医学文献中提取信息的生物医学自然语言处理（BioNLP）技术有助于减轻这种负担。近年来，如GPT-3和GPT-4等大型语言模型（LLMs）因其卓越的性能而受到重视。但是，它们在BioNLP任务中的有效性以及对方法开发和下游用户的影响仍未得到研究。本研究（1）在四个应用程序中在八个BioNLP数据集中建立了GPT-3和GPT-4在零-shot和一-shot设置下的基准表现，包括命名实体识别，关系提取，多标签文档分类和语义相似性和推理；（2）审查了LLMs产生的错误，并将错误分为三种类型：缺失，不一致和不需要的人工内容；（3）提出了使用LLMs的建议。

    Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
    
[^54]: 连接点：基于图网络的文本表示在文本分类中的最佳表现研究

    Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?. (arXiv:2305.14578v1 [cs.CL])

    [http://arxiv.org/abs/2305.14578](http://arxiv.org/abs/2305.14578)

    本文研究了基于图的文本表示方法在文本分类中的应用，发现文本输入特征和领域要素对图的性能具有重要影响，BERT在处理短文本时难以收敛，图方法对于较长的文档特别有益。

    

    鉴于图神经网络在结构感知机器学习中的成功，许多研究已经探索了它们作为传统特征表示模型的替代方法，用于文本分类。然而，大多数研究仅考虑了特定领域，并验证了具有特定特征的数据。本文对提出用于文本分类的基于图的文本表示方法进行了广泛的实证研究，确定了实际实施的含义和领域中的挑战。我们比较了五个数据集中的几种GNN架构以及BERT，涵盖了长短文档。结果表明：i）图的性能与文本输入特征和领域密切相关，ii）尽管其表现出色，但BERT在处理短文本时难以收敛， iii）图方法对于较长的文档特别有益。

    Given the success of Graph Neural Networks (GNNs) for structure-aware machine learning, numerous studies have explored their application to text classification, as an alternative to traditional feature representation models. However, most studies considered just a specific domain and validated on data with particular characteristics. This work presents an extensive empirical investigation of graph-based text representation methods proposed for text classification, identifying practical implications and open challenges in the field. We compare several GNN architectures as well as BERT across five datasets, encompassing short and also long documents. The results show that: i) graph performance is highly related to the textual input features and domain, ii) despite its outstanding performance, BERT has difficulties converging when dealing with short texts, iii) graph methods are particularly beneficial for longer documents.
    
[^55]: 超越共享词汇：增加多语言机器翻译中的表示词语相似性

    Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation. (arXiv:2305.14189v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14189](http://arxiv.org/abs/2305.14189)

    本文提出了一种超越共享词汇的方法，通过定义词级信息传输路径和使用图网络来融合跨语言的词嵌入，实现了在多语言机器翻译中提高相似含义词的对齐性和BLEU分数的一致提升。此方法只需要少量额外参数且计算成本增加有限，并且推理时间与基线相同。

    

    在多语言神经机器翻译(MNMT)中，使用共享的词汇是常见的做法。除了简单的设计外，共享标记在积极的知识转移中起着重要的作用，假设共享标记在不同语言中指的是相似的含义。然而，当词汇的重叠较小时，尤其是由于不同的书写系统，转移被限制。在本文中，我们通过词等价类定义了词级信息传输路径，并依赖图网络来融合跨语言的词嵌入。我们的实验证明了我们方法的优势：1) 具有相似含义的词的嵌入在不同语言中更好地对齐，2) 我们的方法在高和低资源MNMT方面实现了一致的BLEU提升达2.3个点，3) 需要少于1.0%的额外可训练参数，并且计算成本的增加有限，而推理时间与基线相同。

    Using a vocabulary that is shared across languages is common practice in Multilingual Neural Machine Translation (MNMT). In addition to its simple design, shared tokens play an important role in positive knowledge transfer, assuming that shared tokens refer to similar meanings across languages. However, when word overlap is small, especially due to different writing systems, transfer is inhibited. In this paper, we define word-level information transfer pathways via word equivalence classes and rely on graph networks to fuse word embeddings across languages. Our experiments demonstrate the advantages of our approach: 1) embeddings of words with similar meanings are better aligned across languages, 2) our method achieves consistent BLEU improvements of up to 2.3 points for high- and low-resource MNMT, and 3) less than 1.0\% additional trainable parameters are required with a limited increase in computational costs, while inference time remains identical to the baseline. We release the c
    
[^56]: 基于基础模型的系统设计框架

    A Framework for Designing Foundation Model based Systems. (arXiv:2305.05352v1 [cs.SE])

    [http://arxiv.org/abs/2305.05352](http://arxiv.org/abs/2305.05352)

    本文提出了一个基于基础模型的系统分类体系，分类和比较了基础模型和基于基础模型的系统的特点。它为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。

    

    最近推出了大型语言模型(LLM)的聊天机器人，如ChatGPT，这引起了人们对基础模型的广泛关注。基础模型被广泛认为将成为未来人工智能系统的基石。由于基础模型处于早期阶段，基于基础模型的系统设计尚未得到系统地探索。人们对在软件架构中引入基础模型的影响知之甚少。因此，在本文中，我们提出了一个基于基础模型的系统分类法，对基础模型和基于基础模型的系统的特点进行了分类和比较。我们的分类法包括三个类别：基础模型预训练和微调、基于基础模型的系统架构设计和负责任的AI设计。这个分类法为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。

    The recent release of large language model (LLM) based chatbots, such as ChatGPT, has attracted significant attention on foundations models. It is widely believed that foundation models will serve as the fundamental building blocks for future AI systems. As foundation models are in their early stages, the design of foundation model based systems has not yet been systematically explored. There is little understanding about the impact of introducing foundation models in software architecture. Therefore, in this paper, we propose a taxonomy of foundation model based systems, which classifies and compares the characteristics of foundation models and foundation model based systems. Our taxonomy comprises three categories: foundation model pretraining and fine-tuning, architecture design of foundation model based systems, and responsible-AI-by-design. This taxonomy provides concrete guidance for making major design decisions when designing foundation model based systems and highlights trade-
    
[^57]: 大型语言模型是代码生成的最先进评估器

    Large Language Models Are State-of-the-Art Evaluators of Code Generation. (arXiv:2304.14317v1 [cs.AI])

    [http://arxiv.org/abs/2304.14317](http://arxiv.org/abs/2304.14317)

    本文提出了一个基于 GPT-3.5 的评估框架，解决了现有方法在代码生成任务上的局限性，取得了更好的相关性。

    

    自然语言生成领域的最新进展推动了利用大型语言模型评估生成文本的能力。虽然这些模型在机器翻译和摘要等任务中表现出了很好的结果，但其在代码生成任务中的适用性仍然存在限制。这些任务所需的编程概念的复杂性使得开发评估指标以与人类判断相一致变得困难。以词汇匹配为基础的度量标准（如BLEU）在代码生成任务中与人工从业者的相关性较弱。此外，在低资源领域中利用人为编写的测试套件进行功能正确性评估也具有挑战性。为了克服这些障碍，我们提出了一个基于GPT-3.5的代码生成评估框架（\texttt{GPT-3.5-turbo}）。我们的框架通过取得更好的相关性来解决现有方法的局限性。

    Recent advancements in the field of natural language generation have facilitated the use of large language models to assess the quality of generated text. Although these models have shown promising results in tasks such as machine translation and summarization, their applicability in code generation tasks remains limited without human involvement. The complexity of programming concepts required for such tasks makes it difficult to develop evaluation metrics that align with human judgment. Token-matching-based metrics, such as BLEU, have demonstrated weak correlations with human practitioners in code generation tasks. Moreover, the utilization of human-written test suites to evaluate functional correctness can be challenging in domains with low resources. To overcome these obstacles, we propose a new evaluation framework based on the GPT-3.5 (\texttt{GPT-3.5-turbo}), for code generation assessments. Our framework addresses the limitations of existing approaches by achieving superior cor
    
[^58]: ETPNav: 在连续环境中演化拓扑规划的视觉语言导航

    ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments. (arXiv:2304.03047v1 [cs.CV])

    [http://arxiv.org/abs/2304.03047](http://arxiv.org/abs/2304.03047)

    ETPNav是一个能够在连续环境中进行视觉语言导航的新导航框架，它具有两个关键技能：能够抽象环境与生成长程导航计划以及在连续环境中避障控制的能力。ETPNav使用演化算法优化拓扑规划模块并在Matterport3D模拟器上实现了最先进的性能，达到了人类水平的VLN-CE任务性能。

    

    视觉语言导航需要智能体遵循指示在环境中导航，该任务在体验式人工智能领域中具有潜在应用，如自治导航、搜索与救援和人机交互。本文提出了一个更为实用但具有挑战性的情景 - 在连续环境中进行视觉语言导航（VLN-CE）。为了开发一个强大的VLN-CE代理，我们提出了一个新的导航框架ETPNav，它专注于两个关键技能：1）抽象环境和生成长程导航计划的能力；和2）在连续环境中避障控制的能力。ETPNav通过自组织沿着经过的路径预测的路标进行在线环境拓扑映射，而不需要先前的环境经验。它将导航过程分解为高层规划和低层控制。同时，ETPNav使用一种新颖的演化算法来优化拓扑规划模块，以实现有效的长期导航计划。所提出的方法在Matterport3D模拟器上实现了最先进的性能，并在任意起点和终点的VLN-CE任务中达到了人类水平的性能。

    Vision-language navigation is a task that requires an agent to follow instructions to navigate in environments. It becomes increasingly crucial in the field of embodied AI, with potential applications in autonomous navigation, search and rescue, and human-robot interaction. In this paper, we propose to address a more practical yet challenging counterpart setting - vision-language navigation in continuous environments (VLN-CE). To develop a robust VLN-CE agent, we propose a new navigation framework, ETPNav, which focuses on two critical skills: 1) the capability to abstract environments and generate long-range navigation plans, and 2) the ability of obstacle-avoiding control in continuous environments. ETPNav performs online topological mapping of environments by self-organizing predicted waypoints along a traversed path, without prior environmental experience. It privileges the agent to break down the navigation procedure into high-level planning and low-level control. Concurrently, ET
    
[^59]: VivesDebate-Speech: 用于利用音频特征进行论证挖掘的口语论证语料库

    VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining. (arXiv:2302.12584v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12584](http://arxiv.org/abs/2302.12584)

    VivesDebate-Speech是一个用于利用音频特征进行论证挖掘的口语论证语料库，通过整合音频特征，改进了论证挖掘的性能。

    

    本文描述了VivesDebate-Speech，一个用于利用音频特征进行论证挖掘任务的口语论证语料库。该语料库的创建对于语音处理和论证挖掘领域的交叉研究作出了重要贡献，是该领域中最完整的公开资源之一。此外，我们进行了一系列首次尝试的实验，结果表明将音频特征整合到论证挖掘流程中可以提高性能。提供的结果可作为未来研究的基准。

    In this paper, we describe VivesDebate-Speech, a corpus of spoken argumentation created to leverage audio features for argument mining tasks. The creation of this corpus represents an important contribution to the intersection of speech processing and argument mining communities, and one of the most complete publicly available resources in this topic. Moreover, we have performed a set of first-of-their-kind experiments which show an improvement when integrating audio features into the argument mining pipeline. The provided results can be used as a baseline for future research.
    
[^60]: 保持中立：使用自然语言推理改进生成器

    Keep it Neutral: Using Natural Language Inference to Improve Generation. (arXiv:2302.08577v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08577](http://arxiv.org/abs/2302.08577)

    本文将自然语言推理（NLI）引入文本生成过程中，通过预训练的NLI模型评估生成的句子是否符合、与原始文本相矛盾或中立。最大化中立类别的NLI策略提供了最高质量的生成文本，无论参数取值如何。

    

    本文研究将自然语言推理（NLI）引入文本生成过程中，通过使用预训练的NLI模型来评估生成的句子是否符合、与原始文本相矛盾或中立。首先，我们证明NLI任务能够预测GPT-3生成错误。我们利用这些结果为GPT-J开发了一种基于NLI的生成策略。然后，我们通过人工标注错误类型和整体质量来评估生成的结果。我们发现，在核心采样的随机参数值较高时，最大化蕴涵关系的NLI策略改善了文本生成，而在参数值较低时，最大化矛盾关系的策略实际上是有效的。总体而言，我们展示了最大化中立类别的NLI策略提供了最高质量的生成文本（显著优于普通生成器），无论参数取值如何。

    We explore incorporating natural language inference (NLI) into the text generative pipeline by using a pre-trained NLI model to assess whether a generated sentence entails, contradicts, or is neutral to the prompt and preceding text. First, we show that the NLI task is predictive of generation errors made by GPT-3. We use these results to develop an NLI-informed generation procedure for GPT-J. Then, we evaluate these generations by obtaining human annotations on error types and overall quality. We find that an NLI strategy of maximizing entailment improves text generation when the nucleus sampling randomness parameter value is high, while one which maximizes contradiction is in fact productive when the parameter value is low. Overall, though, we demonstrate that an NLI strategy of maximizing the neutral class provides the highest quality of generated text (significantly better than the vanilla generations), regardless of parameter value.
    
[^61]: AV-data2vec: 使用上下文化目标表示的自监督学习音视频语音表示

    AV-data2vec: Self-supervised Learning of Audio-Visual Speech Representations with Contextualized Target Representations. (arXiv:2302.06419v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2302.06419](http://arxiv.org/abs/2302.06419)

    AV-data2vec是一种使用自监督学习来构建音视频语音表示的方法，能够同时训练音频和视频的联合表示，并在语音识别任务中表现出优越性能。

    

    自监督学习已经显示出在语音识别方面具有很大的潜力，通过大大减少构建好的系统所需的标记数据量。然而，现有的方法要么不完全端到端，要么不能同时训练两种模态的联合表示。在本文中，我们引入了AV-data2vec，它解决了这些挑战，并基于预测上下文化表示构建音视频表示，这在单模态情况下取得了成功。该模型使用共享的Transformer编码器对音频和视频进行表示，并可以结合两种模态来改进语音识别。在LRS3上的结果表明，AV-data2vec在所有设置下都比现有方法表现更好，而使用的数据量和模型大小相同。

    Self-supervision has shown great potential for audio-visual speech recognition by vastly reducing the amount of labeled data required to build good systems. However, existing methods are either not entirely end-to-end or do not train joint representations of both modalities. In this paper, we introduce AV-data2vec which addresses these challenges and builds audio-visual representations based on predicting contextualized representations which has been successful in the uni-modal case. The model uses a shared transformer encoder for both audio and video and can combine both modalities to improve speech recognition. Results on LRS3 show that AV-data2vec consistently outperforms existing methods under all settings with the same amount of data and model size.
    
[^62]: 使用Twitter数据了解公众对COVID-19相关药物批准和离标使用的看法

    Using Twitter Data to Understand Public Perceptions of Approved versus Off-label Use for COVID-19-related Medications. (arXiv:2206.14358v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2206.14358](http://arxiv.org/abs/2206.14358)

    通过Twitter数据分析了解公众对COVID-19相关药物的批准和离标使用的看法。Hydroxychloroquine和Ivermectin比Molnupiravir和Remdesivir的讨论更多，时间趋势分析和内容分析揭示了人们对每种药物立场的可能理由。

    

    理解公众关于未经证实治疗方法的紧急使用的讨论对于监测安全使用和打击错误信息至关重要。我们开发了一种自然语言处理的流程，以理解Twitter上关于冠状病毒病2019（COVID-19）相关药物的公众看法和立场。这项回顾性研究包括了在COVID-19大流行期间，从2020年1月29日到2021年11月30日，关于四种药物的609,189条美国推文，这四种药物在公众中引起了重大关注：（1）羟氯喹和伊维菌素，具有案例证据的治疗方法；（2）莫米匹雷韦和瑞德西韦，FDA批准用于合格患者的治疗方法。利用时间趋势分析了解其受欢迎度趋势和相关事件。进行了内容和人口统计学分析，以探索人们对每种药物立场的潜在理由。

    Understanding public discourse on emergency use of unproven therapeutics is crucial for monitoring safe use and combating misinformation. We developed a natural language processing-based pipeline to comprehend public perceptions of and stances on coronavirus disease 2019 (COVID-19)-related drugs on Twitter over time. This retrospective study included 609,189 US-based tweets from January 29, 2020, to November 30, 2021, about four drugs that garnered significant public attention during the COVID-19 pandemic: (1) Hydroxychloroquine and Ivermectin, therapies with anecdotal evidence; and (2) Molnupiravir and Remdesivir, FDA-approved treatments for eligible patients. Time-trend analysis was employed to understand popularity trends and related events. Content and demographic analyses were conducted to explore potential rationales behind people's stances on each drug. Time-trend analysis indicated that Hydroxychloroquine and Ivermectin were discussed more than Molnupiravir and Remdesivir, part
    
[^63]: 使用论证语义和自然语言论证图网络实现自动辩论评估

    Automatic Debate Evaluation with Argumentation Semantics and Natural Language Argument Graph Networks. (arXiv:2203.14647v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.14647](http://arxiv.org/abs/2203.14647)

    本文提出了一种使用论证语义和自然语言论证图网络的混合方法来自动评估辩论，并取得了有希望的结果，为自然语言论据的自动分析开辟了新的未开发领域。

    

    缺乏专业论证和完整论述辩论的注解数据导致了对更复杂的自然语言处理任务的过于简化和无法处理。自动辩论评估正是其案例。在本文中，我们提出了一种原始的混合方法来自动评估辩论。为此，我们结合了论证理论中的论证框架和语义概念，与基于Transformer的架构和神经图网络。此外，我们获得了有希望的结果，为自然语言论据的自动分析开辟了新的未开发领域。

    The lack of annotated data on professional argumentation and complete argumentative debates has led to the oversimplification and the inability of approaching more complex natural language processing tasks. Such is the case of the automatic debate evaluation. In this paper, we propose an original hybrid method to automatically evaluate argumentative debates. For that purpose, we combine concepts from argumentation theory such as argumentation frameworks and semantics, with Transformer-based architectures and neural graph networks. Furthermore, we obtain promising results that lay the basis on an unexplored new instance of the automatic analysis of natural language arguments.
    
[^64]: 使用分布感知词嵌入的命名实体识别性能的实证研究。

    Empirical Study of Named Entity Recognition Performance Using Distribution-aware Word Embedding. (arXiv:2109.01636v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2109.01636](http://arxiv.org/abs/2109.01636)

    研究开发了一种分布感知词嵌入，并实施了三种不同的方法来利用NER框架中的分布信息，实验表明将词的特异性融入NER方法可提高NER的性能。

    

    随着深度学习技术的快速发展，命名实体识别（NER）在信息提取任务中变得越来越重要。NER任务面临的最大困难是即使在NE类型和文档不熟悉的情况下仍然需要保持可检测性。意识到特定性信息可能包含单词的潜在含义并生成词嵌入的语义相关特征，我们开发了一个分布感知词嵌入，并实施了三种不同的方法来利用NER框架中的分布信息。结果表明，如果将词的特异性融入现有的NER方法中，NER的性能将得到提高。

    With the fast development of Deep Learning techniques, Named Entity Recognition (NER) is becoming more and more important in the information extraction task. The greatest difficulty that the NER task faces is to keep the detectability even when types of NE and documents are unfamiliar. Realizing that the specificity information may contain potential meanings of a word and generate semantic-related features for word embedding, we develop a distribution-aware word embedding and implement three different methods to make use of the distribution information in a NER framework. And the result shows that the performance of NER will be improved if the word specificity is incorporated into existing NER methods.
    

