# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [GPT-4 Technical Report.](http://arxiv.org/abs/2303.08774) | GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。 |
| [^2] | [Artificial Influence: An Analysis Of AI-Driven Persuasion.](http://arxiv.org/abs/2303.08721) | 本文探讨了AI驱动的说服未来的不确定性，包括移动说服力平衡的方式、定制化的说服、虚假信息的带动以及改变人类自身言论的方式。我们警告存在负面影响，并呼吁加强对其开发和使用的监管。 |
| [^3] | [Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization.](http://arxiv.org/abs/2303.08697) | Mirror 是一个由大型语言模型支持的平台，它提供了一个直观的自然语言接口，可以将问题转化为 SQL，并自动生成可执行的 SQL 命令。用户可以预览和编辑 SQL 以保证查询的准确性，还可以获得数据摘要和可视化。它适用于各种程度的数据分析人员和非技术专业人员。 |
| [^4] | [Automated Query Generation for Evidence Collection from Web Search Engines.](http://arxiv.org/abs/2303.08652) | 本研究考虑了自动查询生成，即根据事实陈述自动生成搜索查询。研究引入了一个包含390个事实陈述和相关搜索查询和结果的中等规模证据收集数据集。 |
| [^5] | [On the Calibration and Uncertainty with P\'{o}lya-Gamma Augmentation for Dialog Retrieval Models.](http://arxiv.org/abs/2303.08606) | 本文提出了一种PG-DRR框架，通过加入高斯过程层来提高对话响应检索模型的校准性和不确定性估计，可以在保持性能不变的情况下实现最低的校准误差。 |
| [^6] | [GCRE-GPT: A Generative Model for Comparative Relation Extraction.](http://arxiv.org/abs/2303.08601) | 本文介绍了一种生成模型GCRE-GPT, 可直接从比较文本中提取出高精度的比较关系。 |
| [^7] | [Efficient Uncertainty Estimation with Gaussian Process for Reliable Dialog Response Retrieval.](http://arxiv.org/abs/2303.08599) | 本文提出了一个高斯过程下的不确定性校准框架GPF-BERT用于基于BERT的对话搜索，实现了高质量的神经排名器，相较于基本校准方法具有更低的经验校准误差和更高的检索性能，在时间上具有8倍的加速效果。 |
| [^8] | [Distinguishing Cause from Effect on Categorical Data: The Uniform Channel Model.](http://arxiv.org/abs/2303.08572) | 本文提出了一种名为“均匀通道模型”的方法，用于区分分类数据中的因果关系，该方法将条件概率质量函数视为离散无记忆通道，并选择最可能的因果方向使得条件概率质量函数更接近于均匀分布。 |
| [^9] | [The Image of the Process Interpretation of Regular Expressions is Not Closed under Bisimulation Collapse.](http://arxiv.org/abs/2303.08553) | 论文探讨了一种存在于正则表达式进程语义中的双模折叠不封闭性问题，并在1-free正则表达式的解释中发现了对这种难题的关键原因，进一步提出了LEE属性的特征，证明了1-free正则表达式的方程证明系统是完备的，并且多项式时间可以解决解释和过程图双模相似性问题。 |
| [^10] | [UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation.](http://arxiv.org/abs/2303.08518) | UPRISE是一种通用的检索器，可自动为给定的零样本任务输入检索提示，从而提高大型语言模型的零样本评估。它通过跨任务和跨模型的实验展示了其通用性和潜力，同时表明具有减轻幻觉问题和提高LLM性能的能力。 |
| [^11] | [A Cross-institutional Evaluation on Breast Cancer Phenotyping NLP Algorithms on Electronic Health Records.](http://arxiv.org/abs/2303.08448) | 本研究通过对乳腺癌表型提取任务的评估，展示了基于BERT的临床NLP模型在不同临床环境中具有良好的泛化能力，并强调了使用转移学习开发广义临床NLP模型的潜力。 |
| [^12] | [PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning.](http://arxiv.org/abs/2303.08389) | 本文提出了一种面向多语言图像字幕的扰动鲁棒度量方法（PR-MCS），通过对CLIP的文本编码器进行微调，实现了对扰动文本的区分，并在新的细粒度评估数据集上展现出比基线指标更好的表现，证明了其适应多种语言的图像字幕评估指标中表现出良好的鲁棒性。 |
| [^13] | [FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization.](http://arxiv.org/abs/2303.08335) | FactReranker是一种新颖的辅助评估器，可以在保持摘要与放射学发现实况一致性的基础上，通过事实引导来有效地选择最佳的摘要。 |
| [^14] | [Cross-speaker Emotion Transfer by Manipulating Speech Style Latents.](http://arxiv.org/abs/2303.08329) | 本文提出了一种通过操纵语音风格隐变量进行跨说话人情感转移和操纵的新方法，能从阅读风格的语音生成情感语音，且情感强度可通过标量值进行可控，保留说话人身份。 |
| [^15] | [A Comprehensive Study on Post-Training Quantization for Large Language Models.](http://arxiv.org/abs/2303.08302) | 本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。 |
| [^16] | [Rediscovery of CNN's Versatility for Text-based Encoding of Raw Electronic Health Records.](http://arxiv.org/abs/2303.08290) | 本文发现，CNN在健康记录文本编码方面的多功能性和隐含层次结构可以提高其性能，提出了一种基于CNN的编码器来处理不同类型的EHR特征，并在临床任务中展示了其有效性。 |
| [^17] | [Attention-likelihood relationship in transformers.](http://arxiv.org/abs/2303.08288) | 本文分析了Transformer中标记可能性和注意力值之间的关联，揭示了在遇到意外标记时模型关注较少的信息，对于评估LLMs在现实世界场景中的稳健性具有有价值的影响。 |
| [^18] | [Clinical Concept and Relation Extraction Using Prompt-based Machine Reading Comprehension.](http://arxiv.org/abs/2303.08262) | 该论文提出了一种基于提示的机器阅读理解结构，能够有效解决临床概念提取和关系提取问题，并具有跨机构应用的良好通用性。 |
| [^19] | [Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures.](http://arxiv.org/abs/2303.08259) | 本文使用Transformer预训练深度学习架构开发了NLP系统，可在临床笔记中提取药物及其上下文信息，并在药物信息提取任务中取得最先进的性能。 |
| [^20] | [NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions.](http://arxiv.org/abs/2303.08233) | NL4Opt比赛旨在研究如何从自然语言描述中提取出优化问题的含义和表述，并通过自然语言与非专业人士进行交互。竞赛分为两个子任务：(1) 识别和标记对应于优化问题组件的语义实体;(2)从检测到的问题实体生成意义表示(即逻辑形式)。 |
| [^21] | [MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain.](http://arxiv.org/abs/2303.08179) | 本文介绍了medBERT.de，这是一个用于德语医学领域的BERT模型，通过在大规模语料库上的训练，在八个不同的医学基准测试中取得最新的最先进的表现。该模型对长文本特别有用，而数据去重和有效的分词则只对模型性能产生了较小的影响。 |
| [^22] | [Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images.](http://arxiv.org/abs/2303.07274) | WHOOPS!是一个新的视觉常识数据集和基准测试，包括了图像字幕、跨模态匹配和视觉问答等若干个任务，引入了解释生成任务，挑战了AI模型识别和解释不合常规的图像的能力。 |
| [^23] | [Which One Are You Referring To? Multimodal Object Identification in Situated Dialogue.](http://arxiv.org/abs/2302.14680) | 本文探索了三种多模态对象识别方法并在SIMMC 2.1数据集上进行了评估。最佳方法是基于场景对话的对齐，相比基准测试提高了约20%的F1分数。 |
| [^24] | [FiTs: Fine-grained Two-stage Training for Knowledge-aware Question Answering.](http://arxiv.org/abs/2302.11799) | 本文提出了一个Fine-grained Two-stage训练框架（FiTs），用于解决知识感知问答（KAQA）中，从语言模型和知识图谱中获得的两种不同类型的知识在表示上的差异和联合推理的困难问题。 |
| [^25] | [TRESTLE: Toolkit for Reproducible Execution of Speech, Text and Language Experiments.](http://arxiv.org/abs/2302.07322) | TRESTLE是一个由TalkBank存储库中选取两个数据集的可重复执行工具包。其中，老年痴呆检测为例子。TRESTLE为该领域提供了标准化和可重复的实验平台，可以使得研究者可以在之上进行更加高效、准确的模型构建。 |
| [^26] | [Theory of Mind May Have Spontaneously Emerged in Large Language Models.](http://arxiv.org/abs/2302.02083) | “通过测试多个语言模型在解决40个ToM任务上的表现，研究发现GPT-3和GPT-4能够解决大部分任务，说明类似ToM的能力可能是语言模型自发出现的附带产物。” |
| [^27] | [Measuring The Impact Of Programming Language Distribution.](http://arxiv.org/abs/2302.01973) | 该研究提出了BabelCode框架和Translating Python Programming Puzzles（TP3）基准测试，探讨了平衡训练数据集中14种编程语言分布的影响。结果显示平衡分布有助于大型语言模型在低资源语言上的性能提升。 |
| [^28] | [Author as Character and Narrator: Deconstructing Personal Narratives from the r/AmITheAsshole Reddit Community.](http://arxiv.org/abs/2301.08104) | 研究从r/AmITheAsshole Reddit社区中的个人叙述中鉴别了作者作为角色和叙述者的语言和叙事特征，以回答什么样的人物会成为“混蛋”，以及什么样的叙述方式会被视为“混蛋”。 |
| [^29] | [Generalized Category Discovery with Decoupled Prototypical Network.](http://arxiv.org/abs/2211.15115) | 本文提出了一种解耦原型网络（DPN）模型，通过二分图匹配问题分离已知和新类别来有效地实现不同的训练目标，并将标记和未标记数据中的已知类别对齐，以显式转移类别特定的知识和捕获高级语义信息。 |
| [^30] | [Understanding BLOOM: An empirical study on diverse NLP tasks.](http://arxiv.org/abs/2211.14865) | 本文对比了BLOOM和其他语言模型在性能、跨语言和多语言微调以及基于提示文本生成中的毒性分析方面的表现，发现BLOOM与其他LLM的性能不成正比，但在生成毒性低的文本方面表现更好。 |
| [^31] | [Once-for-All Sequence Compression for Self-Supervised Speech Models.](http://arxiv.org/abs/2211.02332) | 本文提出了一种自监督语音模型的一次性序列压缩框架，该框架支持连续的操作压缩率范围，并在各种任务上展现出平滑的性能效率权衡。 |
| [^32] | [End-to-end Spoken Language Understanding with Tree-constrained Pointer Generator.](http://arxiv.org/abs/2210.16554) | 本论文针对口语理解中的长尾词问题，提出了一种带树约束的指针生成器TCPGen和槽概率偏置机制SPB，通过对应的实体和短槽列表提取偏置列表来偏置SLU模型的输出槽分布，取得了不错的实验结果。 |
| [^33] | [Analyzing Acoustic Word Embeddings from Pre-trained Self-supervised Speech Models.](http://arxiv.org/abs/2210.16043) | 本篇论文研究了自监督模型用于构建声学词嵌入（AWE）的效果，发现平均汇聚的HuBERT表示法已经可以与英语AWE的最新表现相媲美，而且在其他语言上也表现优异。 |
| [^34] | [Terminology-aware Medical Dialogue Generation.](http://arxiv.org/abs/2210.15551) | 本研究提出了一种新的医学对话生成框架，通过考虑以术语为中心的特征改进医学对话生成。实验结果表明，我们的框架比现有的最先进语言模型表现更好。 |
| [^35] | [Virtuoso: Massive Multilingual Speech-Text Joint Semi-Supervised Learning for Text-To-Speech.](http://arxiv.org/abs/2210.15447) | 本文提出了Virtuoso，一种大规模多语言语音-文字联合半监督学习框架，可用于TTS模型，并通过不同训练方案使模型在已知语言和未知语言中均能表现出色。 |
| [^36] | [Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion.](http://arxiv.org/abs/2210.08471) | 本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。 |
| [^37] | [MAPL: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting.](http://arxiv.org/abs/2210.07179) | MAPL使用对齐的图像-文本数据学习单模态模型表示空间之间的轻量级映射，从而实现了面向视觉-语言少样本任务的基于参数效率的适应，并在测试中显示出优越的性能表现。 |
| [^38] | [Perplexity from PLM Is Unreliable for Evaluating Text Quality.](http://arxiv.org/abs/2210.05892) | 该研究发现，使用困惑度指标评估生成文本质量是不可靠的，由于短文本 PPL 值高于长文本，重复文本段落和标点符号也可以损坏指标表现。 使用语言模型评估文本质量应谨慎。 |
| [^39] | [DABERT: Dual Attention Enhanced BERT for Semantic Matching.](http://arxiv.org/abs/2210.03454) | DABERT 通过双重注意力机制和自适应融合模块增强了 BERT 在捕捉句子对之间细微差异的能力，并在实验中取得了良好的效果。 |
| [^40] | [How GPT-3 responds to different publics on climate change and Black Lives Matter: A critical appraisal of equity in conversational AI.](http://arxiv.org/abs/2209.13627) | 本论文提出了一个分析框架，以检查人工智能和人类对话中公平性的含义。作者使用这个框架进行了审计研究，发现 GPT-3 在回应气候变化和BBL运动的提示时存在不公平的行为，强化了刻板印象，边缘化了某些特定的群体。该研究表明有必要解决这些偏见，以防止AI-powered服务中进一步巩固权力结构。 |
| [^41] | [Unsupervised Opinion Summarization Using Approximate Geodesics.](http://arxiv.org/abs/2209.07496) | 本文提出了一种名为GeoSumm的新型系统，用于执行无监督的抽取式意见摘要。它使用基于编码器解码器的表示学习模型和近似测地线距离的得分机制，在保证性能的同时鲁棒性也得到了保证。 |
| [^42] | [Masked Vision and Language Modeling for Multi-modal Representation Learning.](http://arxiv.org/abs/2208.02131) | 本文提出了联合遮蔽视觉和语言建模，在跨模态对齐方面取得成果，并在百万级别的预训练数据范围内取得了最先进的性能。 |
| [^43] | [A Large and Diverse Arabic Corpus for Language Modeling.](http://arxiv.org/abs/2201.09227) | 该论文介绍了一个大规模的阿拉伯语语料库，旨在提高大规模语言模型的跨领域知识和推理能力。 |
| [^44] | [Label prompt for multi-label text classification.](http://arxiv.org/abs/2106.10076) | 本文提出了一种 Label Mask 多标签文本分类模型（LM-MTC），利用预训练语言模型的能力来捕捉标签之间的隐含关系，并通过基于标签的遮盖语言模型（MLM）进一步提高模型的泛化能力。 |

# 详细

[^1]: GPT-4技术报告

    GPT-4 Technical Report. (arXiv:2303.08774v1 [cs.CL])

    [http://arxiv.org/abs/2303.08774](http://arxiv.org/abs/2303.08774)

    GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。

    

    我们报告了GPT-4的开发，它是一个可以接受图像和文本输入并产生文本输出的大规模多模态模型。虽然在许多现实场景中不如人类，但GPT-4在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试，成绩排名在前10％左右。GPT-4是一个基于Transformer的模型，预训练用于预测文档中的下一个标记。后训练对齐过程提高了事实性和符合期望行为的性能指标。项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。这使我们能够准确预测GPT-4的某些性能方面，而这些性能是基于使用不超过GPT-4计算能力的1/1,000的模型训练的。

    We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.
    
[^2]: 人工影响: AI驱动的说服分析

    Artificial Influence: An Analysis Of AI-Driven Persuasion. (arXiv:2303.08721v1 [cs.CY])

    [http://arxiv.org/abs/2303.08721](http://arxiv.org/abs/2303.08721)

    本文探讨了AI驱动的说服未来的不确定性，包括移动说服力平衡的方式、定制化的说服、虚假信息的带动以及改变人类自身言论的方式。我们警告存在负面影响，并呼吁加强对其开发和使用的监管。

    

    说服是人类的重要特征之一，是商业、政治等事业的核心。人工智能（AI）的进步已经产生了能够说服人类购买产品、观看视频、点击搜索结果等的AI系统。即使没有明确设计为说服的系统，在实践中也可能会这样做。未来，越来越具有人形特征的AI系统可能会与用户形成持续的关系，提高它们的说服力。本文探讨了具有不确定性的AI系统的说服能力未来。我们考虑到AI如何在移动说服力平衡的基础上，实现定制化的说服，为虚假信息带来动力以及改变人类塑造自身言论的方式。我们考虑AI驱动的说服方式可能与人类驱动的方式有所不同。我们警告说，普遍存在高度说服力的AI系统可能对人类的自主权和福祉产生负面影响，并呼吁加强关于其开发和使用的对话和监管。

    Persuasion is a key aspect of what it means to be human, and is central to business, politics, and other endeavors. Advancements in artificial intelligence (AI) have produced AI systems that are capable of persuading humans to buy products, watch videos, click on search results, and more. Even systems that are not explicitly designed to persuade may do so in practice. In the future, increasingly anthropomorphic AI systems may form ongoing relationships with users, increasing their persuasive power. This paper investigates the uncertain future of persuasive AI systems. We examine ways that AI could qualitatively alter our relationship to and views regarding persuasion by shifting the balance of persuasive power, allowing personalized persuasion to be deployed at scale, powering misinformation campaigns, and changing the way humans can shape their own discourse. We consider ways AI-driven persuasion could differ from human-driven persuasion. We warn that ubiquitous highlypersuasive AI sy
    
[^3]: Mirror: 自然语言接口用于数据查询、摘要和可视化

    Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization. (arXiv:2303.08697v1 [cs.DB])

    [http://arxiv.org/abs/2303.08697](http://arxiv.org/abs/2303.08697)

    Mirror 是一个由大型语言模型支持的平台，它提供了一个直观的自然语言接口，可以将问题转化为 SQL，并自动生成可执行的 SQL 命令。用户可以预览和编辑 SQL 以保证查询的准确性，还可以获得数据摘要和可视化。它适用于各种程度的数据分析人员和非技术专业人员。

    

    我们提出了 Mirror，这是一个由大型语言模型推动的数据探索和分析开源平台。Mirror 提供了一个直观的自然语言接口，用于查询数据库，并自动生成可执行的 SQL 命令来检索相关数据并用自然语言进行摘要。此外，用户可以预览和手动编辑生成的 SQL 命令，以确保查询的准确性。Mirror 还生成可视化图表，以便了解数据情况。设计时考虑到灵活性和人的输入，因此 Mirror 适合于经验丰富的数据分析师和非技术专业人员从数据中获取见解。

    We present Mirror, an open-source platform for data exploration and analysis powered by large language models. Mirror offers an intuitive natural language interface for querying databases, and automatically generates executable SQL commands to retrieve relevant data and summarize it in natural language. In addition, users can preview and manually edit the generated SQL commands to ensure the accuracy of their queries. Mirror also generates visualizations to facilitate understanding of the data. Designed with flexibility and human input in mind, Mirror is suitable for both experienced data analysts and non-technical professionals looking to gain insights from their data.
    
[^4]: 自动查询生成用于从网络搜索引擎中收集证据。

    Automated Query Generation for Evidence Collection from Web Search Engines. (arXiv:2303.08652v1 [cs.CL])

    [http://arxiv.org/abs/2303.08652](http://arxiv.org/abs/2303.08652)

    本研究考虑了自动查询生成，即根据事实陈述自动生成搜索查询。研究引入了一个包含390个事实陈述和相关搜索查询和结果的中等规模证据收集数据集。

    

    人们普遍认为，可以通过在互联网上搜索信息来验证所谓的事实。这个过程需要事实核查员根据事实制定搜索查询并向搜索引擎提交，然后需要在搜索结果中识别相关和可信的段落，然后才能做出决策。在许多新闻和媒体组织中，这个过程由副编辑每天完成。在这里，我们问一个问题，那就是是否可能自动化第一步，即查询生成。我们是否能够根据类似于人类专家制定的事实陈述自动生成搜索查询？我们考虑相似性，无论是从文本相似性的角度还是从搜索引擎返回相关文档的角度。首先，我们介绍一个中等规模的证据收集数据集，其中包括390个事实陈述以及相关的人工生成的搜索查询和搜索结果。

    It is widely accepted that so-called facts can be checked by searching for information on the Internet. This process requires a fact-checker to formulate a search query based on the fact and to present it to a search engine. Then, relevant and believable passages need to be identified in the search results before a decision is made. This process is carried out by sub-editors at many news and media organisations on a daily basis. Here, we ask the question as to whether it is possible to automate the first step, that of query generation. Can we automatically formulate search queries based on factual statements which are similar to those formulated by human experts? Here, we consider similarity both in terms of textual similarity and with respect to relevant documents being returned by a search engine. First, we introduce a moderate-sized evidence collection dataset which includes 390 factual statements together with associated human-generated search queries and search results. Then, we i
    
[^5]: 论文标题：Polya-Gamma增强对于对话检索模型的校准和不确定性研究

    On the Calibration and Uncertainty with P\'{o}lya-Gamma Augmentation for Dialog Retrieval Models. (arXiv:2303.08606v1 [cs.CL])

    [http://arxiv.org/abs/2303.08606](http://arxiv.org/abs/2303.08606)

    本文提出了一种PG-DRR框架，通过加入高斯过程层来提高对话响应检索模型的校准性和不确定性估计，可以在保持性能不变的情况下实现最低的校准误差。

    

    深度神经检索模型已经充分展示了它们的能力，但估计它们预测的可靠性仍然具有挑战性。大多数对话响应检索模型为每个响应输出一个相关问题的单个得分。然而，深度神经网络的坏校准会导致各种不确定性单个得分，从而不可靠的预测总是误导用户决策。为了研究这些问题，我们提出了一种高效的校准和不确定性估计框架PG-DRR，用于对话响应检索模型，它将一个高斯过程层添加到一个确定性深度神经网络中，并通过Polya-Gamma增强恢复共轭以便得到易处理的后验推断。最后，PG-DRR在域内数据集和分布偏移任务中实现了最低的实证校准误差（ECE），同时保持$R_{10}@1$和MAP性能。

    Deep neural retrieval models have amply demonstrated their power but estimating the reliability of their predictions remains challenging. Most dialog response retrieval models output a single score for a response on how relevant it is to a given question. However, the bad calibration of deep neural network results in various uncertainty for the single score such that the unreliable predictions always misinform user decisions. To investigate these issues, we present an efficient calibration and uncertainty estimation framework PG-DRR for dialog response retrieval models which adds a Gaussian Process layer to a deterministic deep neural network and recovers conjugacy for tractable posterior inference by P\'{o}lya-Gamma augmentation. Finally, PG-DRR achieves the lowest empirical calibration error (ECE) in the in-domain datasets and the distributional shift task while keeping $R_{10}@1$ and MAP performance.
    
[^6]: GCRE-GPT: 一种用于比较关系提取的生成模型

    GCRE-GPT: A Generative Model for Comparative Relation Extraction. (arXiv:2303.08601v1 [cs.CL])

    [http://arxiv.org/abs/2303.08601](http://arxiv.org/abs/2303.08601)

    本文介绍了一种生成模型GCRE-GPT, 可直接从比较文本中提取出高精度的比较关系。

    

    给定比较文本，比较关系提取旨在提取两个目标（例如两个相机）的比较和它们被比较的方面（例如图像质量）。提取出的比较关系是进一步意见分析的基础。现有的解决方案将此任务作为一个序列标记任务，以提取目标和方面。然而，它们不能直接从文本中提取比较关系。本文通过生成模型展示出，可以直接以高精度提取出比较关系。基于GPT-2，我们提出了一种生成式比较关系提取器（GCRE-GPT）。实验结果表明，该模型在两个数据集上达到了最先进的准确性。

    Given comparative text, comparative relation extraction aims to extract two targets (\eg two cameras) in comparison and the aspect they are compared for (\eg image quality). The extracted comparative relations form the basis of further opinion analysis.Existing solutions formulate this task as a sequence labeling task, to extract targets and aspects. However, they cannot directly extract comparative relation(s) from text. In this paper, we show that comparative relations can be directly extracted with high accuracy, by generative model. Based on GPT-2, we propose a Generation-based Comparative Relation Extractor (GCRE-GPT). Experiment results show that \modelname achieves state-of-the-art accuracy on two datasets.
    
[^7]: 高斯过程的高效不确定性估计用于可靠对话响应检索

    Efficient Uncertainty Estimation with Gaussian Process for Reliable Dialog Response Retrieval. (arXiv:2303.08599v1 [cs.CL])

    [http://arxiv.org/abs/2303.08599](http://arxiv.org/abs/2303.08599)

    本文提出了一个高斯过程下的不确定性校准框架GPF-BERT用于基于BERT的对话搜索，实现了高质量的神经排名器，相较于基本校准方法具有更低的经验校准误差和更高的检索性能，在时间上具有8倍的加速效果。

    

    检索式对话系统中的深度神经网络表现出卓越的性能，但它们被证明是不良校准的。虽然像蒙特卡罗Dropout和Ensemble这样的基本校准方法可以很好地校准，但这些方法在训练或推理阶段需要耗费大量时间。为了应对这些挑战，我们提出了一种高效的不确定性校准框架GPF-BERT，用于基于BERT的会话搜索，它采用高斯过程层和焦点损失在BERT架构的顶部，以实现高质量的神经排名器。大量实验用于验证我们的方法的有效性。与基本校准方法相比，GPF-BERT在三个领域内数据集和分布偏移任务中实现了最低的经验校准误差（ECE），同时在大多数情况下产生了最高的$R_{10}@1$和MAP性能。在时间消耗方面，我们的GPF-BERT具有8倍的加速效果。

    Deep neural networks have achieved remarkable performance in retrieval-based dialogue systems, but they are shown to be ill calibrated. Though basic calibration methods like Monte Carlo Dropout and Ensemble can calibrate well, these methods are time-consuming in the training or inference stages. To tackle these challenges, we propose an efficient uncertainty calibration framework GPF-BERT for BERT-based conversational search, which employs a Gaussian Process layer and the focal loss on top of the BERT architecture to achieve a high-quality neural ranker. Extensive experiments are conducted to verify the effectiveness of our method. In comparison with basic calibration methods, GPF-BERT achieves the lowest empirical calibration error (ECE) in three in-domain datasets and the distributional shift tasks, while yielding the highest $R_{10}@1$ and MAP performance on most cases. In terms of time consumption, our GPF-BERT has an 8$\times$ speedup.
    
[^8]: 区分分类数据中的因果关系：均匀通道模型

    Distinguishing Cause from Effect on Categorical Data: The Uniform Channel Model. (arXiv:2303.08572v1 [cs.LG])

    [http://arxiv.org/abs/2303.08572](http://arxiv.org/abs/2303.08572)

    本文提出了一种名为“均匀通道模型”的方法，用于区分分类数据中的因果关系，该方法将条件概率质量函数视为离散无记忆通道，并选择最可能的因果方向使得条件概率质量函数更接近于均匀分布。

    

    区分因果关系是因果发现中的核心问题。大多数用于此任务的方法，即加性噪声模型（ANM），仅适用于定量数据。我们提出了一个在分类变量（属于没有有意义顺序的集合）上解决因果-效应问题的标准，灵感来源于将条件概率质量函数（pmf）视为离散无记忆通道。我们选择最可能的因果方向，其中条件pmf更接近均匀通道（UC）。原理是，在UC中，正如在ANM中一样，（给定因果关系的效应）条件熵独立于因果分布，符合因果和机制独立性原则。因此，我们的方法称为均匀通道模型（UCM），扩展了ANM理论到分类变量。为了评估从数据估计的条件pmf与UC的接近程度，我们使用s

    Distinguishing cause from effect using observations of a pair of random variables is a core problem in causal discovery. Most approaches proposed for this task, namely additive noise models (ANM), are only adequate for quantitative data. We propose a criterion to address the cause-effect problem with categorical variables (living in sets with no meaningful order), inspired by seeing a conditional probability mass function (pmf) as a discrete memoryless channel. We select as the most likely causal direction the one in which the conditional pmf is closer to a uniform channel (UC). The rationale is that, in a UC, as in an ANM, the conditional entropy (of the effect given the cause) is independent of the cause distribution, in agreement with the principle of independence of cause and mechanism. Our approach, which we call the uniform channel model (UCM), thus extends the ANM rationale to categorical variables. To assess how close a conditional pmf (estimated from data) is to a UC, we use s
    
[^9]: 关于正则表达式进程语义的双模折叠不封闭性问题

    The Image of the Process Interpretation of Regular Expressions is Not Closed under Bisimulation Collapse. (arXiv:2303.08553v1 [cs.LO])

    [http://arxiv.org/abs/2303.08553](http://arxiv.org/abs/2303.08553)

    论文探讨了一种存在于正则表达式进程语义中的双模折叠不封闭性问题，并在1-free正则表达式的解释中发现了对这种难题的关键原因，进一步提出了LEE属性的特征，证明了1-free正则表达式的方程证明系统是完备的，并且多项式时间可以解决解释和过程图双模相似性问题。

    

    Milner提出的正则表达式进程语义的公理化和表达问题在考虑死锁0和空步长1的完整表达式类中变得困难起来。我们报告了当0存在时添加1会产生的现象，这将这个困难的关键原因带到了聚焦点。即，虽然1-free正则表达式的解释在双模折叠下是封闭的，但任意正则表达式的解释不是这种情况。1-free正则表达式的过程图解释满足循环存在和消除属性LEE，该属性在双模折叠下得以保留。LEE的这些特征被用于证明1-free正则表达式的方程证明系统是完备的，并且用于判断一个1-free正则表达式的解释是否与一个过程图双模相似是一个多项式时间可判定的问题。

    Axiomatization and expressibility problems for Milner's process semantics (1984) of regular expressions modulo bisimilarity have turned out to be difficult for the full class of expressions with deadlock 0 and empty step~1. We report on a phenomenon that arises from the added presence of 1 when 0 is available, and that brings a crucial reason for this difficulty into focus. To wit, while interpretations of 1-free regular expressions are closed under bisimulation collapse, this is not the case for the interpretations of arbitrary regular expressions.  Process graph interpretations of 1-free regular expressions satisfy the loop existence and elimination property LEE, which is preserved under bisimulation collapse. These features of LEE were applied for showing that an equational proof system for 1-free regular expressions modulo bisimilarity is complete, and that it is decidable in polynomial time whether a process graph is bisimilar to the interpretation of a 1-free regular expression. 
    
[^10]: UPRISE: 通用提示检索以提高零样本评估

    UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation. (arXiv:2303.08518v1 [cs.CL])

    [http://arxiv.org/abs/2303.08518](http://arxiv.org/abs/2303.08518)

    UPRISE是一种通用的检索器，可自动为给定的零样本任务输入检索提示，从而提高大型语言模型的零样本评估。它通过跨任务和跨模型的实验展示了其通用性和潜力，同时表明具有减轻幻觉问题和提高LLM性能的能力。

    

    大型语言模型因其出色的能力而受欢迎，但需要特定模型的微调或任务特定提示工程可能会阻碍其一般化。我们提出了UPRISE（通用提示检索以提高零样本评估），该方法调整了轻量级和多功能的检索器，以自动检索给定零样本任务输入的提示。具体而言，在跨任务和跨模型方案中展示了通用性：检索器针对各种任务进行微调，但在看不见的任务类型上进行测试；我们在一个小型冻结LLM——GPT-Neo-2.7B上调整检索器，但在不同规模的LLM上测试检索器，例如BLOOM-7.1B、OPT-66B和GPT3-175B。此外，我们展示了UPRISE在我们与ChatGPT的实验中减轻了幻觉问题，表明它有潜力改进甚至是最强的LLM。

    Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs.
    
[^11]: 通过对电子病历的乳腺癌表型NLP算法进行跨机构评估

    A Cross-institutional Evaluation on Breast Cancer Phenotyping NLP Algorithms on Electronic Health Records. (arXiv:2303.08448v1 [cs.CL])

    [http://arxiv.org/abs/2303.08448](http://arxiv.org/abs/2303.08448)

    本研究通过对乳腺癌表型提取任务的评估，展示了基于BERT的临床NLP模型在不同临床环境中具有良好的泛化能力，并强调了使用转移学习开发广义临床NLP模型的潜力。

    

    目标：在模型开发过程中，通常忽略临床大型语言模型的泛化能力。本研究通过乳腺癌表型提取任务，评估了基于BERT的临床NLP模型在不同临床环境下的泛化能力。方法：从明尼苏达大学和梅奥诊所的电子病历中收集了两种乳腺癌患者的临床语料库，并按照同一指南进行注释。我们开发了三种类型的NLP模型（条件随机场、双向长短期记忆和CancerBERT），从临床文本中提取癌症表型。使用不同的学习策略（模型转移与本地训练）对模型在不同测试集上进行泛化能力评估。评估实体覆盖率与模型性能的相关性得分。结果：在UMN和MC手动注释了200和161份临床文档。CancerBERT模型达到了最高的F1分数（0.896）和实体覆盖率（98.8%），优于其他模型。模型转移方法在两个机构中产生了类似于本地训练模型的结果，表明跨机构存在潜在的泛化性。结论：本研究展示了在不同临床环境中评估NLP模型的重要性，并强调了使用转移学习开发广义临床NLP模型的潜力。

    Objective: The generalizability of clinical large language models is usually ignored during the model development process. This study evaluated the generalizability of BERT-based clinical NLP models across different clinical settings through a breast cancer phenotype extraction task.  Materials and Methods: Two clinical corpora of breast cancer patients were collected from the electronic health records from the University of Minnesota and the Mayo Clinic, and annotated following the same guideline. We developed three types of NLP models (i.e., conditional random field, bi-directional long short-term memory and CancerBERT) to extract cancer phenotypes from clinical texts. The models were evaluated for their generalizability on different test sets with different learning strategies (model transfer vs. locally trained). The entity coverage score was assessed with their association with the model performances.  Results: We manually annotated 200 and 161 clinical documents at UMN and MC, re
    
[^12]: PR-MCS: 面向多语言图像字幕的扰动鲁棒度量方法

    PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning. (arXiv:2303.08389v1 [cs.CL])

    [http://arxiv.org/abs/2303.08389](http://arxiv.org/abs/2303.08389)

    本文提出了一种面向多语言图像字幕的扰动鲁棒度量方法（PR-MCS），通过对CLIP的文本编码器进行微调，实现了对扰动文本的区分，并在新的细粒度评估数据集上展现出比基线指标更好的表现，证明了其适应多种语言的图像字幕评估指标中表现出良好的鲁棒性。

    

    自动评估图像字幕的指标对于词汇扰动的易受攻击性是一个关键弱点。本文提出了Perturbation Robust Multi-Lingual CLIPScore（PR-MCS），它能够表现出对这种扰动的鲁棒性，并且是一种新的不需要参照物的适用于多种语言的图像字幕评估指标。为了实现扰动鲁棒性，我们使用我们的语言无关方法对CLIP的文本编码器进行微调，以区分扰动文本和原始文本。为了验证PR-MCS的鲁棒性，我们引入了一个新的细粒度评估数据集，包括五种语言中 3,000 个图像的详细字幕，关键对象和对象之间的关系。在我们的实验中，PR-MCS 在捕获所有不同扰动类型的词汇噪声方面显着优于基线指标，证明了 PR-MCS 对于词汇扰动具有高度的鲁棒性。

    Vulnerability to lexical perturbation is a critical weakness of automatic evaluation metrics for image captioning. This paper proposes Perturbation Robust Multi-Lingual CLIPScore(PR-MCS), which exhibits robustness to such perturbations, as a novel reference-free image captioning metric applicable to multiple languages. To achieve perturbation robustness, we fine-tune the text encoder of CLIP with our language-agnostic method to distinguish the perturbed text from the original text. To verify the robustness of PR-MCS, we introduce a new fine-grained evaluation dataset consisting of detailed captions, critical objects, and the relationships between the objects for 3, 000 images in five languages. In our experiments, PR-MCS significantly outperforms baseline metrics in capturing lexical noise of all various perturbation types in all five languages, proving that PR-MCS is highly robust to lexical perturbations.
    
[^13]: FactReranker：基于事实引导的辅助评估器用于忠实的放射学报告摘要。

    FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization. (arXiv:2303.08335v1 [cs.CL])

    [http://arxiv.org/abs/2303.08335](http://arxiv.org/abs/2303.08335)

    FactReranker是一种新颖的辅助评估器，可以在保持摘要与放射学发现实况一致性的基础上，通过事实引导来有效地选择最佳的摘要。

    

    自动放射学报告摘要是一项至关重要的临床任务，其主要挑战在于保持所产生的摘要和地面实况放射学发现之间的实际准确性。现有研究采用强化学习来直接优化正确认知度量指标，如CheXBert或RadGraph分数。然而，它们使用贪婪搜索或束搜索的解码方法，在选择最佳候选项时没有考虑事实的一致性，从而导致实际一致性的改善受限。为了解决这个问题，我们提出了一种新颖的第二阶段摘要方法FactReranker，它是第一次尝试基于它们估计的实际一致性得分来学习从所有候选项中选择最佳摘要。我们建议基于RadGraph模式提取输入医疗报告、其黄金摘要和候选摘要的医疗事实，并设计基于事实引导的重新排序器，以有效地结合提取的医疗事实来选择最佳摘要。我们分解了事实-

    Automatic radiology report summarization is a crucial clinical task, whose key challenge is to maintain factual accuracy between produced summaries and ground truth radiology findings. Existing research adopts reinforcement learning to directly optimize factual consistency metrics such as CheXBert or RadGraph score. However, their decoding method using greedy search or beam search considers no factual consistency when picking the optimal candidate, leading to limited factual consistency improvement. To address it, we propose a novel second-stage summarizing approach FactReranker, the first attempt that learns to choose the best summary from all candidates based on their estimated factual consistency score. We propose to extract medical facts of the input medical report, its gold summary, and candidate summaries based on the RadGraph schema and design the fact-guided reranker to efficiently incorporate the extracted medical facts for selecting the optimal summary. We decompose the fact-
    
[^14]: 通过操纵语音风格隐变量进行跨说话人情感转移

    Cross-speaker Emotion Transfer by Manipulating Speech Style Latents. (arXiv:2303.08329v1 [cs.SD])

    [http://arxiv.org/abs/2303.08329](http://arxiv.org/abs/2303.08329)

    本文提出了一种通过操纵语音风格隐变量进行跨说话人情感转移和操纵的新方法，能从阅读风格的语音生成情感语音，且情感强度可通过标量值进行可控，保留说话人身份。

    

    近年来，情绪文本转语音已经取得了相当大的进展，但仍需要大量标记数据，这并不容易获取。即使有可能获得情感语音数据集，仍然存在控制情感强度的限制。本文提出了一种新方法，通过操纵潜在的语音风格空间中的向量算术，实现跨说话人情感转移和操纵。利用少量标记样本，可以从阅读风格的语音生成情感语音，同时保留说话人身份。此外，情感强度可以通过标量值进行可控，为用户提供了一种直观的操作语音的方式。实验结果表明，所提出的方法在表现力、自然度和可控性方面都有着优越的性能，保留说话人身份。

    In recent years, emotional text-to-speech has shown considerable progress. However, it requires a large amount of labeled data, which is not easily accessible. Even if it is possible to acquire an emotional speech dataset, there is still a limitation in controlling emotion intensity. In this work, we propose a novel method for cross-speaker emotion transfer and manipulation using vector arithmetic in latent style space. By leveraging only a few labeled samples, we generate emotional speech from reading-style speech without losing the speaker identity. Furthermore, emotion strength is readily controllable using a scalar value, providing an intuitive way for users to manipulate speech. Experimental results show the proposed method affords superior performance in terms of expressiveness, naturalness, and controllability, preserving speaker identity.
    
[^15]: 基于后训练量化的大型语言模型综合研究

    A Comprehensive Study on Post-Training Quantization for Large Language Models. (arXiv:2303.08302v1 [cs.LG])

    [http://arxiv.org/abs/2303.08302](http://arxiv.org/abs/2303.08302)

    本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。

    

    后训练量化是一种减少大型语言模型内存消耗和/或计算成本的权衡方法。然而，关于不同量化方案、不同模型族、不同后训练量化方法、不同量化位精度等的影响的全面研究仍缺失。本文通过数万个零-shot实验对这些组件进行了广泛的研究。我们的研究结果表明：(1)细粒度量化和后训练量化方法(而不是朴素的最近舍入量化)是实现良好精度的必要条件；(2) 用粗粒度量化的更高位数（如5位）比用非常细粒度的更低位数（如4位）（其有效位数与5位相似）更强大。我们还提出了如何为不同大小的\llms利用量化的建议，并留下未来机会和系统工作的建议。

    Post-training quantization (\ptq) had been recently shown as a compromising method to reduce the memory consumption and/or compute cost for large language models. However, a comprehensive study about the effect of different quantization schemes, different model families, different \ptq methods, different quantization bit precision, etc, is still missing. In this work, we provide an extensive study on those components over tens of thousands of zero-shot experiments. Our results show that (1) Fine-grained quantization and \ptq methods (instead of naive round-to-nearest quantization) are necessary to achieve good accuracy and (2) Higher bits (e.g., 5 bits) with coarse-grained quantization is more powerful than lower bits (e.g., 4 bits) with very fine-grained quantization (whose effective bits is similar to 5-bits). We also present recommendations about how to utilize quantization for \llms with different sizes, and leave suggestions of future opportunities and system work that are not res
    
[^16]: 重新发现CNN在原始电子健康记录文本编码中的多功能性

    Rediscovery of CNN's Versatility for Text-based Encoding of Raw Electronic Health Records. (arXiv:2303.08290v1 [cs.LG])

    [http://arxiv.org/abs/2303.08290](http://arxiv.org/abs/2303.08290)

    本文发现，CNN在健康记录文本编码方面的多功能性和隐含层次结构可以提高其性能，提出了一种基于CNN的编码器来处理不同类型的EHR特征，并在临床任务中展示了其有效性。

    

    充分利用电子健康记录（EHR）中丰富的信息正逐渐成为医学领域的重要话题。最近的工作提出了一个有前途的框架，该框架可以在不考虑其格式和医学编码标准的情况下嵌入原始EHR数据的整个特征。然而，该框架仅侧重于对EHR进行最小的预处理，未考虑如何学习高效的EHR表示，包括计算和内存使用等方面。在本文中，我们寻找一种多功能的编码器，不仅将大量数据缩小到可管理的大小，还能很好地保留患者的核心信息，以执行各种临床任务。我们发现，具有分层结构的卷积神经网络（CNN）在各种任务（如重建，预测和生成）中经常优于最先进的模型，即使参数较少且训练时间较短。此外，利用EHR数据的固有层次结构可以提高CNN的性能。在这些发现的基础上，我们提出了一种基于CNN的编码器，可以处理不同类型的EHR特征，并证明了所提出的模型在几种临床任务中的有效性。

    Making the most use of abundant information in electronic health records (EHR) is rapidly becoming an important topic in the medical domain. Recent work presented a promising framework that embeds entire features in raw EHR data regardless of its form and medical code standards. The framework, however, only focuses on encoding EHR with minimal preprocessing and fails to consider how to learn efficient EHR representation in terms of computation and memory usage. In this paper, we search for a versatile encoder not only reducing the large data into a manageable size but also well preserving the core information of patients to perform diverse clinical tasks. We found that hierarchically structured Convolutional Neural Network (CNN) often outperforms the state-of-the-art model on diverse tasks such as reconstruction, prediction, and generation, even with fewer parameters and less training time. Moreover, it turns out that making use of the inherent hierarchy of EHR data can boost the perfo
    
[^17]: Transformer中的注意力-可能性关系分析

    Attention-likelihood relationship in transformers. (arXiv:2303.08288v1 [cs.CL])

    [http://arxiv.org/abs/2303.08288](http://arxiv.org/abs/2303.08288)

    本文分析了Transformer中标记可能性和注意力值之间的关联，揭示了在遇到意外标记时模型关注较少的信息，对于评估LLMs在现实世界场景中的稳健性具有有价值的影响。

    

    本文分析了大型语言模型（LLMs）如何表示上下文之外的单词，并调查它们对给定上下文来捕捉语义的依赖性。我们的可能性引导的文本扰动揭示了基于transformer的语言模型中标记可能性和注意力值之间的关联。广泛的实验发现，在更高层特别是遇到意外的标记时，模型会关注较少的来自自身的信息来计算它们的表示。这些发现对于评估LLMs在现实世界场景中的稳健性具有有价值的影响。在https://github.com/Flegyas/AttentionLikelihood中有完全可重现的代码库。

    We analyze how large language models (LLMs) represent out-of-context words, investigating their reliance on the given context to capture their semantics. Our likelihood-guided text perturbations reveal a correlation between token likelihood and attention values in transformer-based language models. Extensive experiments reveal that unexpected tokens cause the model to attend less to the information coming from themselves to compute their representations, particularly at higher layers. These findings have valuable implications for assessing the robustness of LLMs in real-world scenarios. Fully reproducible codebase at https://github.com/Flegyas/AttentionLikelihood.
    
[^18]: 基于提示的机器阅读理解的临床概念及关系提取

    Clinical Concept and Relation Extraction Using Prompt-based Machine Reading Comprehension. (arXiv:2303.08262v1 [cs.CL])

    [http://arxiv.org/abs/2303.08262](http://arxiv.org/abs/2303.08262)

    该论文提出了一种基于提示的机器阅读理解结构，能够有效解决临床概念提取和关系提取问题，并具有跨机构应用的良好通用性。

    

    目标：采用统一的基于提示的机器阅读理解结构，开发出一种自然语言处理系统，可有效地解决临床概念提取和关系提取，具有跨机构应用的良好通用性。方法：我们使用统一的基于提示的机器阅读理解结构来提取临床概念和关系，并探索最先进的Transformer模型。我们使用2018年国家NLP临床挑战赛（n2c2）开发的两个基准数据集（药物和不良药物事件）以及2022年n2c2挑战赛（健康社会决定因素的关系）对我们的MRC模型与现有深度学习模型进行比较，进行端到端的关系提取。我们还在跨机构设置中评估所提出的MRC模型的迁移学习能力。我们进行误差分析，并检查不同提示策略如何影响MRC模型的性能。

    Objective: To develop a natural language processing system that solves both clinical concept extraction and relation extraction in a unified prompt-based machine reading comprehension (MRC) architecture with good generalizability for cross-institution applications.  Methods: We formulate both clinical concept extraction and relation extraction using a unified prompt-based MRC architecture and explore state-of-the-art transformer models. We compare our MRC models with existing deep learning models for concept extraction and end-to-end relation extraction using two benchmark datasets developed by the 2018 National NLP Clinical Challenges (n2c2) challenge (medications and adverse drug events) and the 2022 n2c2 challenge (relations of social determinants of health [SDoH]). We also evaluate the transfer learning ability of the proposed MRC models in a cross-institution setting. We perform error analyses and examine how different prompting strategies affect the performance of MRC models.  Re
    
[^19]: 基于Transformer的深度学习体系结构在语境化药物信息提取中的应用

    Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures. (arXiv:2303.08259v1 [cs.CL])

    [http://arxiv.org/abs/2303.08259](http://arxiv.org/abs/2303.08259)

    本文使用Transformer预训练深度学习架构开发了NLP系统，可在临床笔记中提取药物及其上下文信息，并在药物信息提取任务中取得最先进的性能。

    

    目的：开发自然语言处理(NLP)系统，提取药物及有助于理解药物变化的上下文信息。方法：开发了三个NLP系统，包括药物提及提取、事件分类(指药物变化的讨论或未讨论)、以及分类药物变化上下文到5个与药物变化相关的正交维度。我们探索了6个最先进的预训练变压器模型，包括GatorTron，它是一个大型语言模型，预训练使用超过90亿个单词的文本(包括来自佛罗里达大学健康中心识别的2.9亿多个临床笔记中的超过80亿个单词)。我们使用2022 n2c2的注释数据和评估脚本来评估我们的NLP系统。结果：我们的GatorTron模型在药物提取、事件分类和上下文分类方面分别取得了最佳的 F1 分数，分别为 0.9828（排名第3）、0.9379（排名第1）、0.8375（排名第1），超过其他5个预训练模型。我们最佳的NLP系统在18个参赛团队中排名第二，获得了总体F1得分0.8774 。结论：基于Transformer的深度学习体系结构，如GatorTron，可以有效地从临床笔记中提取药物和上下文信息，并在药物信息提取任务中取得最先进的性能。

    Objective: To develop a natural language processing (NLP) system to extract medications and contextual information that help understand drug changes. This project is part of the 2022 n2c2 challenge.  Materials and methods: We developed NLP systems for medication mention extraction, event classification (indicating medication changes discussed or not), and context classification to classify medication changes context into 5 orthogonal dimensions related to drug changes. We explored 6 state-of-the-art pretrained transformer models for the three subtasks, including GatorTron, a large language model pretrained using >90 billion words of text (including >80 billion words from >290 million clinical notes identified at the University of Florida Health). We evaluated our NLP systems using annotated data and evaluation scripts provided by the 2022 n2c2 organizers.  Results:Our GatorTron models achieved the best F1-scores of 0.9828 for medication extraction (ranked 3rd), 0.9379 for event classif
    
[^20]: NL4Opt 比赛：基于自然语言描述构建优化问题

    NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions. (arXiv:2303.08233v1 [cs.CL])

    [http://arxiv.org/abs/2303.08233](http://arxiv.org/abs/2303.08233)

    NL4Opt比赛旨在研究如何从自然语言描述中提取出优化问题的含义和表述，并通过自然语言与非专业人士进行交互。竞赛分为两个子任务：(1) 识别和标记对应于优化问题组件的语义实体;(2)从检测到的问题实体生成意义表示(即逻辑形式)。

    

    自然语言优化（NL4Opt）竞赛旨在研究如何根据优化问题的文本描述提取其含义和表述的方法。具体而言，该竞赛的目标是通过使用自然语言中介来使非专业人士能够接口使用优化求解器，以增加其可访问性和可用性。我们将这一挑战性目标分为两个子任务：(1)识别和标记对应于优化问题组件的语义实体;(2)从检测到的问题实体生成意义表示(即逻辑形式)。第一个任务旨在通过检测和标记优化问题的实体来减少歧义。第二个任务创建了一个线性规划(LP)问题的中间表示，该中间表示被转换为商用求解器可用的格式。在本报告中，我们介绍了LP单词问题数据集和NL4Opt比赛的共享任务，并总结了竞赛条目的结果。

    The Natural Language for Optimization (NL4Opt) Competition was created to investigate methods of extracting the meaning and formulation of an optimization problem based on its text description. Specifically, the goal of the competition is to increase the accessibility and usability of optimization solvers by allowing non-experts to interface with them using natural language. We separate this challenging goal into two sub-tasks: (1) recognize and label the semantic entities that correspond to the components of the optimization problem; (2) generate a meaning representation (i.e., a logical form) of the problem from its detected problem entities. The first task aims to reduce ambiguity by detecting and tagging the entities of the optimization problems. The second task creates an intermediate representation of the linear programming (LP) problem that is converted into a format that can be used by commercial solvers. In this report, we present the LP word problem dataset and shared tasks f
    
[^21]: MEDBERT.de：一个基于德语的、针对医学领域专门设计的全面BERT模型

    MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain. (arXiv:2303.08179v1 [cs.CL])

    [http://arxiv.org/abs/2303.08179](http://arxiv.org/abs/2303.08179)

    本文介绍了medBERT.de，这是一个用于德语医学领域的BERT模型，通过在大规模语料库上的训练，在八个不同的医学基准测试中取得最新的最先进的表现。该模型对长文本特别有用，而数据去重和有效的分词则只对模型性能产生了较小的影响。

    

    本文介绍了medBERT.de，这是一个针对德语医学领域专门设计的预训练BERT模型。该模型已经在470万份德语医学文档的大型语料库上进行了训练，并在八个不同的医学基准测试中取得了新的最先进的效果，涉及各种学科和医学文献类型。除了评估该模型的整体性能外，本文还对其能力进行了更深入的分析。我们研究了数据去重对模型性能的影响，以及使用更有效的分词方法的潜在好处。我们的结果表明，像medBERT.de这样的领域专用模型特别适用于较长的文本，并且数据去重不一定会导致性能改善。此外，我们发现有效的分词只在提高模型性能方面发挥了较小的作用，并且大多数改进源于模型的预训练。

    This paper presents medBERT.de, a pre-trained German BERT model specifically designed for the German medical domain. The model has been trained on a large corpus of 4.7 Million German medical documents and has been shown to achieve new state-of-the-art performance on eight different medical benchmarks covering a wide range of disciplines and medical document types. In addition to evaluating the overall performance of the model, this paper also conducts a more in-depth analysis of its capabilities. We investigate the impact of data deduplication on the model's performance, as well as the potential benefits of using more efficient tokenization methods. Our results indicate that domain-specific models such as medBERT.de are particularly useful for longer texts, and that deduplication of training data does not necessarily lead to improved performance. Furthermore, we found that efficient tokenization plays only a minor role in improving model performance, and attribute most of the improved
    
[^22]: 打破常识：WHOOPS！一个基于合成和组合图像的视觉与语言基准测试

    Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images. (arXiv:2303.07274v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.07274](http://arxiv.org/abs/2303.07274)

    WHOOPS!是一个新的视觉常识数据集和基准测试，包括了图像字幕、跨模态匹配和视觉问答等若干个任务，引入了解释生成任务，挑战了AI模型识别和解释不合常规的图像的能力。

    

    奇怪、异常和神秘的图像会引起观察者的好奇心，因为它们挑战了常识。我们提出WHOOPS！一个新的视觉常识数据集和基准测试。该数据集由设计师使用Midjourney等公共可用图像生成工具制作，并包含若干个任务。除了图像字幕、跨模态匹配和视觉问答之外，我们还引入了一个困难的解释生成任务，其中模型必须识别并解释给定图像的异常之处。

    Weird, unusual, and uncanny images pique the curiosity of observers because they challenge commonsense. For example, an image released during the 2022 world cup depicts the famous soccer stars Lionel Messi and Cristiano Ronaldo playing chess, which playfully violates our expectation that their competition should occur on the football field. Humans can easily recognize and interpret these unconventional images, but can AI models do the same? We introduce WHOOPS!, a new dataset and benchmark for visual commonsense. The dataset is comprised of purposefully commonsense-defying images created by designers using publicly-available image generation tools like Midjourney. We consider several tasks posed over the dataset. In addition to image captioning, cross-modal matching, and visual question answering, we introduce a difficult explanation generation task, where models must identify and explain why a given image is unusual. Our results show that state-of-the-art models such as GPT3 and BLIP2
    
[^23]: 你是指哪一个？基于情境对话的多模态对象识别

    Which One Are You Referring To? Multimodal Object Identification in Situated Dialogue. (arXiv:2302.14680v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14680](http://arxiv.org/abs/2302.14680)

    本文探索了三种多模态对象识别方法并在SIMMC 2.1数据集上进行了评估。最佳方法是基于场景对话的对齐，相比基准测试提高了约20%的F1分数。

    

    多模态对话系统的需求在各个领域都有不断上升，这强调了从对话和情境背景中理解多模态信息的重要性。我们探索了三种方法来解决这个问题，并在最大的情境对话数据集SIMMC 2.1上对它们进行了评估。我们最好的方法是基于场景对话的对齐，相比SIMMC 2.1的基准测试，它提高了约20%的F1分数。我们提供了分析和讨论我们方法的局限性和未来工作的潜在方向。我们的代码公开在https://github.com/holylovenia/multimodal-object-identification中。

    The demand for multimodal dialogue systems has been rising in various domains, emphasizing the importance of interpreting multimodal inputs from conversational and situational contexts. We explore three methods to tackle this problem and evaluate them on the largest situated dialogue dataset, SIMMC 2.1. Our best method, scene-dialogue alignment, improves the performance by ~20% F1-score compared to the SIMMC 2.1 baselines. We provide analysis and discussion regarding the limitation of our methods and the potential directions for future works. Our code is publicly available at https://github.com/holylovenia/multimodal-object-identification.
    
[^24]: FiTs:细粒度两阶段训练用于知识感知问答

    FiTs: Fine-grained Two-stage Training for Knowledge-aware Question Answering. (arXiv:2302.11799v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.11799](http://arxiv.org/abs/2302.11799)

    本文提出了一个Fine-grained Two-stage训练框架（FiTs），用于解决知识感知问答（KAQA）中，从语言模型和知识图谱中获得的两种不同类型的知识在表示上的差异和联合推理的困难问题。

    

    知识感知问答（KAQA）需要模型在知识库中回答问题，这对于开放域QA和特定领域QA都是必要的，尤其是当语言模型无法提供所需的所有知识时。最近KAQA系统融合了从预训练语言模型（PLM）和知识图谱（KG）中获得的语言知识和事实知识以回答复杂问题，取得了令人鼓舞的结果，但是存在困难，即有效地融合来自PLMs和KGs的表示，因为（i）它们之间存在语义和分布差异，以及（ii）难以联合推理提供的两类知识。针对上述两个问题，我们提出了一个Fine-grained Two-stage训练框架（FiTs），旨在提高KAQA系统的性能。第一阶段旨在通过知识适应后训练来对齐来自PLM和KG的表示，从而弥合它们之间的模态差距。

    Knowledge-aware question answering (KAQA) requires the model to answer questions over a knowledge base, which is essential for both open-domain QA and domain-specific QA, especially when language models alone cannot provide all the knowledge needed. Despite the promising result of recent KAQA systems which tend to integrate linguistic knowledge from pre-trained language models (PLM) and factual knowledge from knowledge graphs (KG) to answer complex questions, a bottleneck exists in effectively fusing the representations from PLMs and KGs because of (i) the semantic and distributional gaps between them, and (ii) the difficulties in joint reasoning over the provided knowledge from both modalities. To address the above two problems, we propose a Fine-grained Two-stage training framework (FiTs) to boost the KAQA system performance: The first stage aims at aligning representations from the PLM and the KG, thus bridging the modality gaps between them, named knowledge adaptive post-training. 
    
[^25]: TRESTLE：语音、文本和语言实验的可重复执行工具包

    TRESTLE: Toolkit for Reproducible Execution of Speech, Text and Language Experiments. (arXiv:2302.07322v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07322](http://arxiv.org/abs/2302.07322)

    TRESTLE是一个由TalkBank存储库中选取两个数据集的可重复执行工具包。其中，老年痴呆检测为例子。TRESTLE为该领域提供了标准化和可重复的实验平台，可以使得研究者可以在之上进行更加高效、准确的模型构建。

    

    越来越多的证据表明，机器学习和深度学习方法可以学习到不同认知障碍（如老年痴呆症）个体和认知健康个体所产生的语言之间微妙的差异。TalkBank等公共数据资源已经使得计算机领域的研究人员能够联合起来，相互学习，取得了显著进展。然而，由于不同研究者使用的方法和数据选取策略的变异性，不同团体获得的结果很难直接进行比较。本文介绍了TRESTLE（\textbf{T}oolkit for \textbf{R}eproducible \textbf{E}xecution of \textbf{S}peech \textbf{T}ext and \textbf{L}anguage \textbf{E}xperiments），这是一个开放源码平台，专注于从TalkBank存储库中选取两个数据集，需以老年痴呆检测为例。TRESTLE已经成功地应用于2019年信息检索国际会议Hackathon / Challenge的比赛中，在标准化和可重复实验方面为社区提供支持，为检测认知障碍的更准确和临床有效的模型提供了有用的参考。

    The evidence is growing that machine and deep learning methods can learn the subtle differences between the language produced by people with various forms of cognitive impairment such as dementia and cognitively healthy individuals. Valuable public data repositories such as TalkBank have made it possible for researchers in the computational community to join forces and learn from each other to make significant advances in this area. However, due to variability in approaches and data selection strategies used by various researchers, results obtained by different groups have been difficult to compare directly. In this paper, we present TRESTLE (\textbf{T}oolkit for \textbf{R}eproducible \textbf{E}xecution of \textbf{S}peech \textbf{T}ext and \textbf{L}anguage \textbf{E}xperiments), an open source platform that focuses on two datasets from the TalkBank repository with dementia detection as an illustrative domain. Successfully deployed in the hackallenge (Hackathon/Challenge) of the Intern
    
[^26]: “大型语言模型可能会自发出现心智理论”

    Theory of Mind May Have Spontaneously Emerged in Large Language Models. (arXiv:2302.02083v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.02083](http://arxiv.org/abs/2302.02083)

    “通过测试多个语言模型在解决40个ToM任务上的表现，研究发现GPT-3和GPT-4能够解决大部分任务，说明类似ToM的能力可能是语言模型自发出现的附带产物。”

    

    “心智理论（ToM）指能够推理他人内心的不可观察状态，对于人类社交互动、交流、移情、自我意识和道德至关重要。我们使用了40个广泛用于测试人类ToM的经典虚假信念任务来测试几个语言模型。2020年之前发布的模型在解决ToM任务方面几乎没有能力。然而，2020年5月发布的第一个GPT-3版本（“davinci-001”）解决了约40％的虚假信念任务，与3.5岁的儿童的表现相当。它的第二个版本（“davinci-002”，2022年1月）解决了70％的虚假信念任务，与6岁儿童的表现相当。最新版本的GPT-3.5（“davinci-003”，2022年11月）解决了90％的虚假信念任务，达到了7岁儿童水平。于2023年3月发布的GPT-4解决了几乎所有的任务（95％）。这些发现表明，类似ToM的能力（迄今被认为是人类独有的）可能是语言的附带产物。”

    Theory of mind (ToM), or the ability to impute unobservable mental states to others, is central to human social interactions, communication, empathy, self-consciousness, and morality. We tested several language models using 40 classic false-belief tasks widely used to test ToM in humans. The models published before 2020 showed virtually no ability to solve ToM tasks. Yet, the first version of GPT-3 ("davinci-001"), published in May 2020, solved about 40% of false-belief tasks-performance comparable with 3.5-year-old children. Its second version ("davinci-002"; January 2022) solved 70% of false-belief tasks, performance comparable with six-year-olds. Its most recent version, GPT-3.5 ("davinci-003"; November 2022), solved 90% of false-belief tasks, at the level of seven-year-olds. GPT-4 published in March 2023 solved nearly all the tasks (95%). These findings suggest that ToM-like ability (thus far considered to be uniquely human) may have spontaneously emerged as a byproduct of language
    
[^27]: 测量编程语言分布的影响

    Measuring The Impact Of Programming Language Distribution. (arXiv:2302.01973v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01973](http://arxiv.org/abs/2302.01973)

    该研究提出了BabelCode框架和Translating Python Programming Puzzles（TP3）基准测试，探讨了平衡训练数据集中14种编程语言分布的影响。结果显示平衡分布有助于大型语言模型在低资源语言上的性能提升。

    

    目前用于评估神经代码模型的基准测试只集中在很少的一部分编程语言上，不包括许多流行的语言，例如Go或Rust。为了解决这个问题，我们提出了BabelCode框架，用于基于执行的评估任何语言中的任何基准测试。BabelCode使得可以对模型的内存、运行时间和单个测试案例结果进行新的定性性能调查。此外，我们还提供了一个名为Translating Python Programming Puzzles（TP3）的新代码翻译数据集，该数据集来自Python Programming Puzzles（Schuster等人，2021）基准测试，涉及将专家级Python函数翻译成任何语言。通过对BabelCode和TP3基准测试的研究，我们探讨了在训练数据集中平衡14种语言的分布是否可以提高大型语言模型在低资源语言上的性能。在平衡语料库上训练模型，平均而言，相对于不平衡分布的情况，所有任务和语言的$pass@k$结果平均提高了12.34%。

    Current benchmarks for evaluating neural code models focus on only a small subset of programming languages, excluding many popular languages such as Go or Rust. To ameliorate this issue, we present the BabelCode framework for execution-based evaluation of any benchmark in any language. BabelCode enables new investigations into the qualitative performance of models' memory, runtime, and individual test case results. Additionally, we present a new code translation dataset called Translating Python Programming Puzzles (TP3) from the Python Programming Puzzles (Schuster et al. 2021) benchmark that involves translating expert-level python functions to any language. With both BabelCode and the TP3 benchmark, we investigate if balancing the distributions of 14 languages in a training dataset improves a large language model's performance on low-resource languages. Training a model on a balanced corpus results in, on average, 12.34% higher $pass@k$ across all tasks and languages compared to the
    
[^28]: 作者即角色又叙述者：从r/AmITheAsshole Reddit社区解构个人叙述

    Author as Character and Narrator: Deconstructing Personal Narratives from the r/AmITheAsshole Reddit Community. (arXiv:2301.08104v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.08104](http://arxiv.org/abs/2301.08104)

    研究从r/AmITheAsshole Reddit社区中的个人叙述中鉴别了作者作为角色和叙述者的语言和叙事特征，以回答什么样的人物会成为“混蛋”，以及什么样的叙述方式会被视为“混蛋”。

    

    在r/AmITheAsshole子论坛中，人们匿名分享包含一些道德困境或冲突的第一人称叙述，并询问社区判断谁是错的（即“混蛋”）。一般来说，第一人称叙述是一个独特的讲故事领域，其中作者既是叙述者（讲述故事的人），又可以是角色（生活故事的人），因此作者在故事中有两种不同的声音。本研究识别了与作者作为角色或叙述者相关的语言和叙事特征。我们使用这些特征回答以下问题：（1）是什么让一个角色成为混蛋，（2）叙述者怎样才算是一个混蛋？我们提取了作者作为角色的特征（例如人口统计信息、叙事事件链和情感弧线）和作者作为叙述者的特征（即整体故事的风格和情感），以确定故事的哪些方面与最终的道德判断相关。

    In the r/AmITheAsshole subreddit, people anonymously share first person narratives that contain some moral dilemma or conflict and ask the community to judge who is at fault (i.e., who is "the asshole"). In general, first person narratives are a unique storytelling domain where the author is the narrator (the person telling the story) but can also be a character (the person living the story) and, thus, the author has two distinct voices presented in the story. In this study, we identify linguistic and narrative features associated with the author as the character or as a narrator. We use these features to answer the following questions: (1) what makes an asshole character and (2) what makes an asshole narrator? We extract both Author-as-Character features (e.g., demographics, narrative event chain, and emotional arc) and Author-as-Narrator features (i.e., the style and emotion of the story as a whole) in order to identify which aspects of the narrative are correlated with the final mor
    
[^29]: 基于解耦原型网络的广义类别发现

    Generalized Category Discovery with Decoupled Prototypical Network. (arXiv:2211.15115v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15115](http://arxiv.org/abs/2211.15115)

    本文提出了一种解耦原型网络（DPN）模型，通过二分图匹配问题分离已知和新类别来有效地实现不同的训练目标，并将标记和未标记数据中的已知类别对齐，以显式转移类别特定的知识和捕获高级语义信息。

    

    广义类别发现（GCD）的目标是从一组无标签数据中识别已知和新的类别，基于另一个仅带有已知类别的数据集。目前的方法忽略已知和新类别之间的差异，在耦合的方式下学习它们，这可能会损害模型的泛化和区分能力。此外，耦合训练方法阻止这些模型显式地从标记数据向未标记数据转移类别特定的知识，这可能会丢失高级语义信息并影响模型性能。为了减轻上述限制，我们提出了一种新颖的模型，称为解耦原型网络（DPN）。通过为类别原型制定一个二分图匹配问题，DPN不仅可以解耦已知和新的类别以有效地实现不同的训练目标，而且还可以将标记和未标记数据中的已知类别对齐，以显式地转移类别特定的知识并捕获高水平的语义信息。

    Generalized Category Discovery (GCD) aims to recognize both known and novel categories from a set of unlabeled data, based on another dataset labeled with only known categories. Without considering differences between known and novel categories, current methods learn about them in a coupled manner, which can hurt model's generalization and discriminative ability. Furthermore, the coupled training approach prevents these models transferring category-specific knowledge explicitly from labeled data to unlabeled data, which can lose high-level semantic information and impair model performance. To mitigate above limitations, we present a novel model called Decoupled Prototypical Network (DPN). By formulating a bipartite matching problem for category prototypes, DPN can not only decouple known and novel categories to achieve different training targets effectively, but also align known categories in labeled and unlabeled data to transfer category-specific knowledge explicitly and capture high
    
[^30]: 解析BLOOM：对各种NLP任务的实证研究

    Understanding BLOOM: An empirical study on diverse NLP tasks. (arXiv:2211.14865v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.14865](http://arxiv.org/abs/2211.14865)

    本文对比了BLOOM和其他语言模型在性能、跨语言和多语言微调以及基于提示文本生成中的毒性分析方面的表现，发现BLOOM与其他LLM的性能不成正比，但在生成毒性低的文本方面表现更好。

    

    本文通过评估较小的BLOOM模型（350m/560m和1b3/1b7）在多个NLP基准数据集和流行排行榜上的表现，以了解BLOOM和其他仅使用解码器的LLM与BERT式编码器-仅模型的性能。 我们得出以下观察结果:（1）BLOOM的性能与参数大小没有正比例关系，不同于GPT和BERT等其他LLM。微调BLOOM模型的实验表明，与1b7变体相比，560m变体的表现相似或更好。（2）零-shot交叉语言和多语言微调实验表明，BLOOM与单语言的GPT-2模型相当或更差，（3）使用RealToxicityPrompts数据集进行基于提示的文本生成毒性分析显示，BLOOM生成的文本至少比GPT-2和GPT-3模型毒性低17％。

    We view the landscape of large language models (LLMs) through the lens of the recently released BLOOM model to understand the performance of BLOOM and other decoder-only LLMs compared to BERT-style encoder-only models. We achieve this by evaluating the smaller BLOOM model variants (\textit{350m/560m} and \textit{1b3/1b7}) on several NLP benchmark datasets and popular leaderboards. We make the following observations: (1) BLOOM performance does not scale with parameter size, unlike other LLMs like GPT and BERT. Experiments fine-tuning BLOOM models show that the 560m variant performs similarly to or better than the 1b7 variant, (2) Zero-shot cross-lingual and multi-lingual fine-tuning experiments show that BLOOM is at par or worse than monolingual GPT-2 models, and (3) Toxicity analysis of prompt-based text generation using the RealToxicityPrompts dataset shows that the text generated by BLOOM is at least 17\% less toxic than GPT-2 and GPT-3 models.
    
[^31]: 自监督语音模型一次性序列压缩

    Once-for-All Sequence Compression for Self-Supervised Speech Models. (arXiv:2211.02332v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.02332](http://arxiv.org/abs/2211.02332)

    本文提出了一种自监督语音模型的一次性序列压缩框架，该框架支持连续的操作压缩率范围，并在各种任务上展现出平滑的性能效率权衡。

    

    在语音处理中，时间轴上的序列长度通常是计算的主要因素。为了降低自监督语音模型的计算成本，已经提出了一些方法来减少序列长度。然而，不同的下游任务对序列压缩有不同的容忍度，因此生产固定压缩率的模型可能不适用于所有任务。本文介绍了一种自监督语音模型的一次性序列压缩框架，支持连续的操作压缩率范围。该框架在各种任务上进行了评估，与固定压缩率变体相比，表现出平滑的性能效率权衡。我们进一步探讨了自适应压缩率学习，演示了选择任务特定的优先帧时期的能力，无需进行网格搜索。

    The sequence length along the time axis is often the dominant factor of the computation in speech processing. Works have been proposed to reduce the sequence length for lowering the computational cost in self-supervised speech models. However, different downstream tasks have different tolerance of sequence compressing, so a model that produces a fixed compressing rate may not fit all tasks. In this work, we introduce a once-for-all (OFA) sequence compression framework for self-supervised speech models that supports a continuous range of operating compressing rates. The framework is evaluated on various tasks, showing marginal degradation compared to the fixed compressing rate variants with a smooth performance-efficiency trade-off. We further explore adaptive compressing rate learning, demonstrating the ability to select task-specific preferred frame periods without needing a grid search.
    
[^32]: 带树约束的指针生成器的端到端口语理解

    End-to-end Spoken Language Understanding with Tree-constrained Pointer Generator. (arXiv:2210.16554v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.16554](http://arxiv.org/abs/2210.16554)

    本论文针对口语理解中的长尾词问题，提出了一种带树约束的指针生成器TCPGen和槽概率偏置机制SPB，通过对应的实体和短槽列表提取偏置列表来偏置SLU模型的输出槽分布，取得了不错的实验结果。

    

    端到端的口语理解系统面临着长尾词问题。本文利用上下文偏置技术提高了口语理解系统的稀有词识别能力，具体研究了一种称为树约束指针生成器（TCPGen）的强大高效的偏置模型组件，该组件利用对应的实体和短槽列表提取偏置列表。同时，为了偏置SLU模型的输出槽分布，提出一种称为槽概率偏置（SPB）机制，从TCPGen计算槽分布。在SLURP数据集上的实验证明，使用TCPGen和SPB可以持续改善SLU-F1得分，尤其是在看不见的实体上。在保留5个槽类型进行测试的新分割上，TCPGen和SPB实现了零样本学习，在SLU-F1得分上超过了50%的基线水平。除了槽填充外，意图分类准确性也有所提高。

    End-to-end spoken language understanding (SLU) suffers from the long-tail word problem. This paper exploits contextual biasing, a technique to improve the speech recognition of rare words, in end-to-end SLU systems. Specifically, a tree-constrained pointer generator (TCPGen), a powerful and efficient biasing model component, is studied, which leverages a slot shortlist with corresponding entities to extract biasing lists. Meanwhile, to bias the SLU model output slot distribution, a slot probability biasing (SPB) mechanism is proposed to calculate a slot distribution from TCPGen. Experiments on the SLURP dataset showed consistent SLU-F1 improvements using TCPGen and SPB, especially on unseen entities. On a new split by holding out 5 slot types for the test, TCPGen with SPB achieved zero-shot learning with an SLU-F1 score over 50% compared to baselines which can not deal with it. In addition to slot filling, the intent classification accuracy was also improved.
    
[^33]: 从预训练的自监督语音模型分析声学词嵌入

    Analyzing Acoustic Word Embeddings from Pre-trained Self-supervised Speech Models. (arXiv:2210.16043v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.16043](http://arxiv.org/abs/2210.16043)

    本篇论文研究了自监督模型用于构建声学词嵌入（AWE）的效果，发现平均汇聚的HuBERT表示法已经可以与英语AWE的最新表现相媲美，而且在其他语言上也表现优异。

    

    自监督模型取得了在各种任务上的强大结果，但对于用于代表可变长的口语单词片段的声学词嵌入（AWE），却很少有研究探索自监督表示法。在这项工作中，我们研究了几种预训练模型和汇聚方法，用于构建具有自监督表示法的AWE。由于自监督表示法具有上下文化的特点，我们假设简单的汇聚方法，如平均法，可能已经有助于构建AWE。在标准的单词区分任务上进行评估时，我们发现具有均值汇聚的HuBERT表示法已经可以与英语AWE的最新表现相媲美。更令人惊讶的是，尽管只在英语上进行训练，但在Xitsonga、普通话和法语上评估的HuBERT表示法始终优于多语言模型XLSR-53（以及在英语上训练的Wav2Vec 2.0）。

    Given the strong results of self-supervised models on various tasks, there have been surprisingly few studies exploring self-supervised representations for acoustic word embeddings (AWE), fixed-dimensional vectors representing variable-length spoken word segments. In this work, we study several pre-trained models and pooling methods for constructing AWEs with self-supervised representations. Owing to the contextualized nature of self-supervised representations, we hypothesize that simple pooling methods, such as averaging, might already be useful for constructing AWEs. When evaluating on a standard word discrimination task, we find that HuBERT representations with mean-pooling rival the state of the art on English AWEs. More surprisingly, despite being trained only on English, HuBERT representations evaluated on Xitsonga, Mandarin, and French consistently outperform the multilingual model XLSR-53 (as well as Wav2Vec 2.0 trained on English).
    
[^34]: 术语感知医学对话生成

    Terminology-aware Medical Dialogue Generation. (arXiv:2210.15551v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.15551](http://arxiv.org/abs/2210.15551)

    本研究提出了一种新的医学对话生成框架，通过考虑以术语为中心的特征改进医学对话生成。实验结果表明，我们的框架比现有的最先进语言模型表现更好。

    

    医学对话生成旨在根据医生和患者之间的对话历史记录生成响应。与面向开放领域的对话生成不同，这要求具有医学领域特定的背景知识。现有的医学对话生成生成框架未能纳入特定于领域的知识，尤其是涉及医学术语。在本文中，我们提出了一种新的框架，通过考虑以术语为中心的特征来改进医学对话生成。我们利用注意机制来纳入术语居中的特征，并通过强制语言模型通过辅助术语识别任务学习术语表示来填补医学背景知识和常用话语之间的语义差距。实验结果证明了我们的方法的有效性，其中我们提出的框架优于SOTA语言模型。此外，我们提供了一个新的数据集。

    Medical dialogue generation aims to generate responses according to a history of dialogue turns between doctors and patients. Unlike open-domain dialogue generation, this requires background knowledge specific to the medical domain. Existing generative frameworks for medical dialogue generation fall short of incorporating domain-specific knowledge, especially with regard to medical terminology. In this paper, we propose a novel framework to improve medical dialogue generation by considering features centered on domain-specific terminology. We leverage an attention mechanism to incorporate terminologically centred features, and fill in the semantic gap between medical background knowledge and common utterances by enforcing language models to learn terminology representations with an auxiliary terminology recognition task. Experimental results demonstrate the effectiveness of our approach, in which our proposed framework outperforms SOTA language models. Additionally, we provide a new da
    
[^35]: Virtuoso：大规模多语言语音文字联合半监督学习用于语音合成

    Virtuoso: Massive Multilingual Speech-Text Joint Semi-Supervised Learning for Text-To-Speech. (arXiv:2210.15447v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.15447](http://arxiv.org/abs/2210.15447)

    本文提出了Virtuoso，一种大规模多语言语音-文字联合半监督学习框架，可用于TTS模型，并通过不同训练方案使模型在已知语言和未知语言中均能表现出色。

    

    本文提出Virtuoso，这是一个用于文本到语音合成（TTS）模型的大规模多语言语音文字联合半监督学习框架。现有的多语言TTS通常支持几十种语言，这只是全球数千种语言的一小部分。将多语言TTS扩展到数百种语言的一个困难是，在低资源语言中收集高质量的语音-文本配对数据。本研究将Maestro（一种面向自动语音识别（ASR）的语音-文本联合预训练框架）扩展到语音生成任务。为了从不同类型的语音和文本数据中训练TTS模型，设计了不同的训练方案，以处理有监督的（配对的TTS和ASR数据）和无监督的（未转录的语音和未发声的文本）数据集。实验评估表明，1）在已知语言中，使用Virtuoso训练的多语言TTS模型可以比基线模型显着提高自然度和可懂度；2）在看不到参考语音样本或转录文本的情况下，它们可以合成未知语言的语音。

    This paper proposes Virtuoso, a massively multilingual speech-text joint semi-supervised learning framework for text-to-speech synthesis (TTS) models. Existing multilingual TTS typically supports tens of languages, which are a small fraction of the thousands of languages in the world. One difficulty to scale multilingual TTS to hundreds of languages is collecting high-quality speech-text paired data in low-resource languages. This study extends Maestro, a speech-text joint pretraining framework for automatic speech recognition (ASR), to speech generation tasks. To train a TTS model from various types of speech and text data, different training schemes are designed to handle supervised (paired TTS and ASR data) and unsupervised (untranscribed speech and unspoken text) datasets. Experimental evaluation shows that 1) multilingual TTS models trained on Virtuoso can achieve significantly better naturalness and intelligibility than baseline ones in seen languages, and 2) they can synthesize 
    
[^36]: 通过结构增强的预训练模型和自适应融合提高语义匹配

    Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion. (arXiv:2210.08471v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08471](http://arxiv.org/abs/2210.08471)

    本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。

    

    基于Transformer的预训练模型，如BERT，在语义句子匹配方面取得了很大的进展。同时，依赖性先验知识在多个NLP任务中也显示出普遍的益处。然而，如何将依赖性先验结构有效地集成到预训练模型中，以更好地模拟复杂的语义匹配关系，仍未确定。在本文中，我们提出了一种名为DAFA的依赖增强自适应融合注意力模型，这将依赖结构明确地引入预训练模型，并将其自适应地融合到语义信息中。具体地，DAFA首先提出了一个结构敏感范式来构建一个依赖矩阵，以校准注意力权重。它采用自适应融合模块来集成获取的依赖信息和原始语义信号。此外，DAFA重构了注意力计算流程，并提供了更好的可解释性。

    Transformer-based pre-trained models like BERT have achieved great progress on Semantic Sentence Matching. Meanwhile, dependency prior knowledge has also shown general benefits in multiple NLP tasks. However, how to efficiently integrate dependency prior structure into pre-trained models to better model complex semantic matching relations is still unsettled. In this paper, we propose the \textbf{D}ependency-Enhanced \textbf{A}daptive \textbf{F}usion \textbf{A}ttention (\textbf{DAFA}), which explicitly introduces dependency structure into pre-trained models and adaptively fuses it with semantic information. Specifically, \textbf{\emph{(i)}} DAFA first proposes a structure-sensitive paradigm to construct a dependency matrix for calibrating attention weights. It adopts an adaptive fusion module to integrate the obtained dependency information and the original semantic signals. Moreover, DAFA reconstructs the attention calculation flow and provides better interpretability. By applying it o
    
[^37]: MAPL: 基于参数效率的单模态预训练模型在视觉-语言少样本任务中的适应

    MAPL: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting. (arXiv:2210.07179v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.07179](http://arxiv.org/abs/2210.07179)

    MAPL使用对齐的图像-文本数据学习单模态模型表示空间之间的轻量级映射，从而实现了面向视觉-语言少样本任务的基于参数效率的适应，并在测试中显示出优越的性能表现。

    

    在单模态视觉和语言任务中，大型预训练模型已经被证明是出色的零样本和（基于提示的）少样本学习器。我们提出了MAPL，一种简单且参数效率高的方法，它重用冻结的单模态预训练模型，并利用它们在多模态视觉-语言（VL）场景中的强大泛化能力。MAPL使用对齐的图像-文本数据学习了单模态模型表示空间之间的轻量级映射，并且可以从仅有少量上下文示例就推广到看不见的VL任务。MAPL的可训练参数数量很少，使得它在低数据和域内学习方面非常有效。此外，MAPL的模块化使得可以轻松扩展到其他预训练模型。在几个视觉问答和图像标题生成基准测试上的大量实验证明，MAPL相对于类似方法在训练少得多的参数时实现了优越或有竞争力的性能。MAPL可以在几小时内使用适度的计算资源进行训练。

    Large pre-trained models have proved to be remarkable zero- and (prompt-based) few-shot learners in unimodal vision and language tasks. We propose MAPL, a simple and parameter-efficient method that reuses frozen pre-trained unimodal models and leverages their strong generalization capabilities in multimodal vision-language (VL) settings. MAPL learns a lightweight mapping between the representation spaces of unimodal models using aligned image-text data, and can generalize to unseen VL tasks from just a few in-context examples. The small number of trainable parameters makes MAPL effective at low-data and in-domain learning. Moreover, MAPL's modularity enables easy extension to other pre-trained models. Extensive experiments on several visual question answering and image captioning benchmarks show that MAPL achieves superior or competitive performance compared to similar methods while training orders of magnitude fewer parameters. MAPL can be trained in just a few hours using modest comp
    
[^38]: PLM 困惑度不可靠，用于评估文本质量

    Perplexity from PLM Is Unreliable for Evaluating Text Quality. (arXiv:2210.05892v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.05892](http://arxiv.org/abs/2210.05892)

    该研究发现，使用困惑度指标评估生成文本质量是不可靠的，由于短文本 PPL 值高于长文本，重复文本段落和标点符号也可以损坏指标表现。 使用语言模型评估文本质量应谨慎。

    

    最近，很多研究都使用困惑度（PPL）来评估生成文本的质量。他们认为，如果 PPL 的值越小，被评估文本的质量（即流畅性）就越好。然而，我们发现 PPL 双重错误，不能公正地评估生成文本的质量，原因包括：（i）短文本的 PPL 值大于长文本，这与常识相悖，（ii）重复文本段落状态下可以损坏 PPL，（iii）标点符号可以严重影响 PPL 的表现。实验表明，PPL 不能可靠地评估给定文本的质量。最后，我们讨论了使用语言模型评估文本质量的关键问题。

    Recently, amounts of works utilize perplexity~(PPL) to evaluate the quality of the generated text. They suppose that if the value of PPL is smaller, the quality(i.e. fluency) of the text to be evaluated is better. However, we find that the PPL referee is unqualified and it cannot evaluate the generated text fairly for the following reasons: (i) The PPL of short text is larger than long text, which goes against common sense, (ii) The repeated text span could damage the performance of PPL, and (iii) The punctuation marks could affect the performance of PPL heavily. Experiments show that the PPL is unreliable for evaluating the quality of given text. Last, we discuss the key problems with evaluating text quality using language models.
    
[^39]: DABERT：双重注意力增强的BERT语义匹配模型

    DABERT: Dual Attention Enhanced BERT for Semantic Matching. (arXiv:2210.03454v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.03454](http://arxiv.org/abs/2210.03454)

    DABERT 通过双重注意力机制和自适应融合模块增强了 BERT 在捕捉句子对之间细微差异的能力，并在实验中取得了良好的效果。

    

    基于Transformer的预训练语言模型（如BERT）在语义句子匹配方面取得了杰出的成果。然而，现有模型仍然在捕捉微小差异的能力上存在不足。如加入、删除或修改句子中的一个单词等噪声可能导致模型预测出错。为了缓解这个问题，我们提出了一种新颖的双重注意力增强的BERT模型（DABERT），以增强BERT在捕捉句子对之间细微差异方面的能力。DABERT由（1）双重注意力模块和（2）自适应融合模块构成。我们在经典的语义匹配和鲁棒性测试数据集上进行了广泛的实验，实验结果表明了DABERT的有效性。

    Transformer-based pre-trained language models such as BERT have achieved remarkable results in Semantic Sentence Matching. However, existing models still suffer from insufficient ability to capture subtle differences. Minor noise like word addition, deletion, and modification of sentences may cause flipped predictions. To alleviate this problem, we propose a novel Dual Attention Enhanced BERT (DABERT) to enhance the ability of BERT to capture fine-grained differences in sentence pairs. DABERT comprises (1) Dual Attention module, which measures soft word matches by introducing a new dual channel alignment mechanism to model affinity and difference attention. (2) Adaptive Fusion module, this module uses attention to learn the aggregation of difference and affinity features, and generates a vector describing the matching details of sentence pairs. We conduct extensive experiments on well-studied semantic matching and robustness test datasets, and the experimental results show the effectiv
    
[^40]: GPT-3 如何处理气候变化和“黑人的命也是命”等不同公众的话题：关于对话式 AI 公平性的批判性评估

    How GPT-3 responds to different publics on climate change and Black Lives Matter: A critical appraisal of equity in conversational AI. (arXiv:2209.13627v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.13627](http://arxiv.org/abs/2209.13627)

    本论文提出了一个分析框架，以检查人工智能和人类对话中公平性的含义。作者使用这个框架进行了审计研究，发现 GPT-3 在回应气候变化和BBL运动的提示时存在不公平的行为，强化了刻板印象，边缘化了某些特定的群体。该研究表明有必要解决这些偏见，以防止AI-powered服务中进一步巩固权力结构。

    

    自回归语言模型越来越普遍，这种模型利用深度学习生成接近人类的文本。这些模型驱动着智能健康、金融和自主驾驶等领域的流行虚拟助手。虽然这些大型语言模型的参数正在改进，但人们仍然担心这些模型可能不同程度地为社会中的所有子群体提供服务。尽管跨学科的 AI 公平讨论越来越多，但缺乏系统性的指标来评估对话系统中公平的含义，以及如何让不同的人群参与评估循环。本文基于民主决策理论和科学技术研究，提出了一个分析框架来揭示人工智能和人类对话中公平性的含义。使用这一框架，我们进行了审计研究，以检查 GPT-3 如何响应关键的科学和社会话题：气候变化和“黑人的命也是命”运动。我们的语料库包括 480 次提示，其中系统地变化发言人的性别、种族和地理位置。我们的发现表明，当回应气候变化和 BLM 的提示时，GPT-3 有时会强化刻板印象，边缘化某些群体，如土著民族。我们认为必须解决这些偏见，以防止权力结构在 AI 动力服务中进一步巩固。

    Autoregressive language models, which use deep learning to produce human-like texts, have become increasingly widespread. Such models are powering popular virtual assistants in areas like smart health, finance, and autonomous driving. While the parameters of these large language models are improving, concerns persist that these models might not work equally for all subgroups in society. Despite growing discussions of AI fairness across disciplines, there lacks systemic metrics to assess what equity means in dialogue systems and how to engage different populations in the assessment loop. Grounded in theories of deliberative democracy and science and technology studies, this paper proposes an analytical framework for unpacking the meaning of equity in human-AI dialogues. Using this framework, we conducted an auditing study to examine how GPT-3 responded to different sub-populations on crucial science and social topics: climate change and the Black Lives Matter (BLM) movement. Our corpus 
    
[^41]: 使用近似测地线的无监督意见摘要。

    Unsupervised Opinion Summarization Using Approximate Geodesics. (arXiv:2209.07496v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.07496](http://arxiv.org/abs/2209.07496)

    本文提出了一种名为GeoSumm的新型系统，用于执行无监督的抽取式意见摘要。它使用基于编码器解码器的表示学习模型和近似测地线距离的得分机制，在保证性能的同时鲁棒性也得到了保证。

    

    意见摘要是从用户评论中捕获流行观点的任务。本文介绍了一种名为Geodesic Summarizer (GeoSumm)的新型系统，用于执行无监督的抽取式意见摘要。GeoSumm涉及基于编码器解码器的表示学习模型，通过在多个解码器层上对预训练文本表示进行词典学习来生成文本的表示形式为潜在语义单元的分布。然后，我们使用这些表示来量化评论句子的相关性，使用一种基于近似测地线距离的得分机制。我们使用相关性评分来识别流行观点，从而组成普遍性和方面特定的摘要。我们提出的模型GeoSumm在三个意见摘要数据集上取得了最先进的性能。我们进行了额外的实验来分析我们的模型的功能，并展示了生成的摘要。

    Opinion summarization is the task of creating summaries capturing popular opinions from user reviews. In this paper, we introduce Geodesic Summarizer (GeoSumm), a novel system to perform unsupervised extractive opinion summarization. GeoSumm involves an encoder-decoder based representation learning model, that generates representations of text as a distribution over latent semantic units. GeoSumm generates these representations by performing dictionary learning over pre-trained text representations at multiple decoder layers. We then use these representations to quantify the relevance of review sentences using a novel approximate geodesic distance based scoring mechanism. We use the relevance scores to identify popular opinions in order to compose general and aspect-specific summaries. Our proposed model, GeoSumm, achieves state-of-the-art performance on three opinion summarization datasets. We perform additional experiments to analyze the functioning of our model and showcase the gene
    
[^42]: 多模态表示学习中的遮蔽视觉和语言建模

    Masked Vision and Language Modeling for Multi-modal Representation Learning. (arXiv:2208.02131v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.02131](http://arxiv.org/abs/2208.02131)

    本文提出了联合遮蔽视觉和语言建模，在跨模态对齐方面取得成果，并在百万级别的预训练数据范围内取得了最先进的性能。

    

    本文研究了如何在视觉和语言（V + L）表示学习中使用遮蔽信号建模。我们提出了建立联合遮蔽视觉和语言建模，其中一个模态的遮蔽信号在另一个模态的帮助下进行重建。这是由图像文本配对数据的性质所驱动的，因为图像和文本都传达几乎相同的信息但以不同的格式呈现。一个模态的遮蔽信号重建以另一模态为条件也可以隐式地学习语言标记和图像补丁之间的跨模态对齐。我们在各种V + L任务上进行的实验表明，该方法连同常见的V + L对齐损失，在百万级别的预训练数据范围内取得了最先进的性能。此外，在有限的数据场景中，我们超过了其他竞争对手的表现。

    In this paper, we study how to use masked signal modeling in vision and language (V+L) representation learning. Instead of developing masked language modeling (MLM) and masked image modeling (MIM) independently, we propose to build joint masked vision and language modeling, where the masked signal of one modality is reconstructed with the help from another modality. This is motivated by the nature of image-text paired data that both of the image and the text convey almost the same information but in different formats. The masked signal reconstruction of one modality conditioned on another modality can also implicitly learn cross-modal alignment between language tokens and image patches. Our experiments on various V+L tasks show that the proposed method, along with common V+L alignment losses, achieves state-of-the-art performance in the regime of millions of pre-training data. Also, we outperforms the other competitors by a significant margin in limited data scenarios.
    
[^43]: 一个大规模多元化的阿拉伯语语料库用于语言建模

    A Large and Diverse Arabic Corpus for Language Modeling. (arXiv:2201.09227v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.09227](http://arxiv.org/abs/2201.09227)

    该论文介绍了一个大规模的阿拉伯语语料库，旨在提高大规模语言模型的跨领域知识和推理能力。

    

    语言模型（LM）引入了自然语言处理（NLP）建模的重大范式转变，其中大型预先训练的LM已经成为大多数NLP任务不可分割的组成部分。LM足够智能，可以在没有任何监督的情况下找到语言的有用和相关表示。这些模型被用于对常规NLP任务进行微调，相对于传统方法，具有显着更高的准确性。相反，这些模型的训练需要一个大规模的语料库，这个语料库可以很好地代表阿拉伯语。由于英语语料库可获得大量资源，因此英语LM通常比其他语言LM表现更好。本文详细描述了一个大型阿拉伯语语料库的设计和开发。它由超过500GB的已加工的阿拉伯文本组成，旨在提高大规模语言模型的跨领域知识和下游推理能力。此外，该语料库还用于训练大型阿拉伯语LM。

    Language models (LMs) have introduced a major paradigm shift in Natural Language Processing (NLP) modeling where large pre-trained LMs became integral to most of the NLP tasks. The LMs are intelligent enough to find useful and relevant representations of the language without any supervision. Perhaps, these models are used to fine-tune typical NLP tasks with significantly high accuracy as compared to the traditional approaches. Conversely, the training of these models requires a massively large corpus that is a good representation of the language. English LMs generally perform better than their other language counterparts, due to the availability of massive English corpora. This work elaborates on the design and development of a large Arabic corpus. It consists of over 500 GB of Arabic cleaned text targeted at improving cross-domain knowledge and downstream generalization capability of large-scale language models. Moreover, the corpus is utilized in the training of a large Arabic LM. In
    
[^44]: 多标签文本分类的标签提示方法

    Label prompt for multi-label text classification. (arXiv:2106.10076v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2106.10076](http://arxiv.org/abs/2106.10076)

    本文提出了一种 Label Mask 多标签文本分类模型（LM-MTC），利用预训练语言模型的能力来捕捉标签之间的隐含关系，并通过基于标签的遮盖语言模型（MLM）进一步提高模型的泛化能力。

    

    在多标签文本分类中，一个关键问题是如何利用标签之间的关联。但是，在一个复杂和未知的标签空间中直接建模标签之间的关联是非常具有挑战性的。在本文中，我们提出了一种 Label Mask 多标签文本分类模型（LM-MTC），它受到语言模型的填空问题思想的启发。LM-MTC 能够通过预训练语言模型的强大能力捕捉标签之间的隐含关系。在此基础上，我们为每个潜在标签分配一个不同的标记，并以一定概率随机遮盖该标记，建立了基于标签的遮掩语言模型（MLM）。我们同时训练 MTC 和 MLM，进一步提高了模型的泛化能力。多个数据集上的大量实验证明了我们方法的有效性。

    One of the key problems in multi-label text classification is how to take advantage of the correlation among labels. However, it is very challenging to directly model the correlations among labels in a complex and unknown label space. In this paper, we propose a Label Mask multi-label text classification model (LM-MTC), which is inspired by the idea of cloze questions of language model. LM-MTC is able to capture implicit relationships among labels through the powerful ability of pre-train language models. On the basis, we assign a different token to each potential label, and randomly mask the token with a certain probability to build a label based Masked Language Model (MLM). We train the MTC and MLM together, further improving the generalization ability of the model. A large number of experiments on multiple datasets demonstrate the effectiveness of our method.
    

