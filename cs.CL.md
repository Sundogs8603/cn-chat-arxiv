# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [An Investigation of Large Language Models for Real-World Hate Speech Detection.](http://arxiv.org/abs/2401.03346) | 本研究调查了大规模语言模型在现实世界中对恶意言论检测的有效性，并发现现有方法在上下文感知方面存在显著限制。而大规模语言模型具有潜力作为上下文感知恶意言论检测的知识库，但目前缺乏有效提示这些模型的方法。 |
| [^2] | [PIXAR: Auto-Regressive Language Modeling in Pixel Space.](http://arxiv.org/abs/2401.03321) | 本论文介绍了PIXAR，这是第一个像素自回归的语言模型，可以用于生成自由形式的文本作为图像，而不依赖于预定义的词汇表。同时，论文还提出了一个简单的对抗性预训练方法来解决生成非模糊文本的挑战。 |
| [^3] | [Enhancing Context Through Contrast.](http://arxiv.org/abs/2401.03314) | 本研究提出了一种通过对比学习来提高神经机器翻译性能的新方法，利用巴洛双胞胎损失最大化互信息。与其他方法不同的是，该方法通过上下文增强来提升性能，而不需要明确地增加数据或从头开始学习嵌入。 |
| [^4] | [Large Language Models as Visual Cross-Domain Learners.](http://arxiv.org/abs/2401.03253) | 本研究提出了大型语言模型作为视觉跨领域学习器（LLaVO），通过将图像转换为文本描述，使用大型语言模型进行训练和微调，实现了在跨领域任务中减少领域转移的效果。 |
| [^5] | [Reflections on Inductive Thematic Saturation as a potential metric for measuring the validity of an inductive Thematic Analysis with LLMs.](http://arxiv.org/abs/2401.03239) | 本文对归纳主题饱和度作为衡量归纳主题分析与LLMs有效性的潜在指标进行了反思，并提出了一种用于合成度量初步主题饱和度的指标。 |
| [^6] | [The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models.](http://arxiv.org/abs/2401.03205) | 本研究通过实证研究探讨了大型语言模型中事实性幻觉的检测、来源和缓解方法。研究构建了新的幻觉基准HaluluEval 2.0，并设计了简单有效的LLM幻觉检测方法。通过深入分析LLMs的训练和利用阶段，并研究导致幻觉的潜在因素，提出了一系列可行的减轻幻觉的技术。 |
| [^7] | [MPN: Leveraging Multilingual Patch Neuron for Cross-lingual Model Editing.](http://arxiv.org/abs/2401.03190) | 本论文提出了一种简单而有效的方法，利用多语言补丁神经元来解决多语言模型的跨语言知识同步问题，并取得了良好的实验结果。 |
| [^8] | [{\delta}-CAUSAL: Exploring Defeasibility in Causal Reasoning.](http://arxiv.org/abs/2401.03183) | 本文提出了{\delta}-CAUSAL，这是一个用于研究因果推理中可废除性的基准数据集，并指出现有的因果强度度量无法在可废除环境中准确评估因果关系的变化。 |
| [^9] | [A Joint-Reasoning based Disease Q&A System.](http://arxiv.org/abs/2401.03181) | 这项研究提出了一种基于联合推理的疾病问答系统，通过结合语言模型和知识图谱的方法，旨在回答普通用户的健康相关问题并减轻医疗保健专业人员的负担。 |
| [^10] | [Text-Video Retrieval via Variational Multi-Modal Hypergraph Networks.](http://arxiv.org/abs/2401.03177) | 本文提出了一种文本-视频检索的方法，通过引入多模态超图进行n元相关建模，从而解决了文本性质和视频内容的语义差距问题。 |
| [^11] | [Part-of-Speech Tagger for Bodo Language using Deep Learning approach.](http://arxiv.org/abs/2401.03175) | 本文介绍了使用深度学习方法的Bodo语词性标注器。首先，我们提出了Bodo语言模型BodoBERT，这项工作是第一个为Bodo开发的语言模型。其次，我们提出了基于深度学习的Bodo词性标注模型，该模型利用了BiLSTM、CRF和BodoBERT与BytePairEmbeddings的组合。尽管研究已经在资源丰富的语言中进行了大量的语言模型和词性标注模型的研究，但对于低资源语言如Bodo，仍然缺乏相关研究。 |
| [^12] | [Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification.](http://arxiv.org/abs/2401.03158) | 四步推理（QLFR）框架是一种通过引入句法和语义丰富的CoT来提升短文本分类任务中大型语言模型（LLMs）性能的方法。 |
| [^13] | [Examining Forgetting in Continual Pre-training of Aligned Large Language Models.](http://arxiv.org/abs/2401.03129) | 本文研究了在对齐大型语言模型的持续预训练过程中出现的遗忘现象，通过评估持续预训练对微调模型在输出格式、知识和可靠性等方面的影响，结果发现解决灾难性遗忘，尤其是重复问题，是一个非常具有挑战性的问题。 |
| [^14] | [Exploring Gender Biases in Language Patterns of Human-Conversational Agent Conversations.](http://arxiv.org/abs/2401.03030) | 本研究旨在探索人与对话型智能体交互中的性别偏见，并研究对话型智能体的性别设计如何触发既有性别偏见并强化性别刻板印象。 |
| [^15] | [AST-T5: Structure-Aware Pretraining for Code Generation and Understanding.](http://arxiv.org/abs/2401.03003) | AST-T5是一种结构感知的预训练模型，通过利用抽象语法树（AST）来增强代码生成、转换和理解的能力。它优于其他同等大小的语言模型，并在代码到代码任务中表现出色。 |
| [^16] | [Blar-SQL: Faster, Stronger, Smaller NL2SQL.](http://arxiv.org/abs/2401.02997) | 该研究通过任务分解，提出了Blar-SQL框架，将两个不同的模型组合，分别专注于不同的任务，从而极大地提高了NL2SQL任务的准确性。该模型比GPT-4更小、更快、更便宜。 |
| [^17] | [CANAMRF: An Attention-Based Model for Multimodal Depression Detection.](http://arxiv.org/abs/2401.02995) | CANAMRF 是一种基于注意力机制的多模态抑郁检测模型，通过考虑不同模态之间的相对重要性，有效地进行多模态表示，并在两个基准数据集上取得了最先进的性能。 |
| [^18] | [Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM.](http://arxiv.org/abs/2401.02994) | 本研究介绍了一种名为“混合”的方法，通过组合多个适度规模的聊天AI模型，可以达到或超越比它们更大的模型的性能表现。 |
| [^19] | [Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion.](http://arxiv.org/abs/2401.02993) | 本文提出了一种计算高效的检索表示融合方法ReFusion，通过将检索表示直接融合到语言模型中，解决了将外部数据库的知识融入非知识密集型任务中的挑战。 |
| [^20] | [Advanced Unstructured Data Processing for ESG Reports: A Methodology for Structured Transformation and Enhanced Analysis.](http://arxiv.org/abs/2401.02992) | 本研究引入了一种创新的方法论，利用"非结构化核心库"，将ESG报告转换为结构化、可分析的格式，并在文本清洗、从图像中敏锐识别和提取文本以及标准化报告中的表格等方面取得了显著进展，为工业生态学和企业可持续性评估领域的发展奠定了基础。 |
| [^21] | [GLIDE-RL: Grounded Language Instruction through DEmonstration in RL.](http://arxiv.org/abs/2401.02991) | GLIDE-RL是一种基于演示的强化学习算法，通过引入教师-指导员-学生的课程学习框架，训练出了一个能够遵循自然语言指令并且可以推广到未见指令的RL代理。 |
| [^22] | [A Latent Dirichlet Allocation (LDA) Semantic Text Analytics Approach to Explore Topical Features in Charity Crowdfunding Campaigns.](http://arxiv.org/abs/2401.02988) | 本文提出了一种创新的文本分析框架，利用潜在狄利克雷分配（LDA）从慈善众筹活动的文本描述中提取潜在主题特征。 |
| [^23] | [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach.](http://arxiv.org/abs/2401.02987) | 本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。 |
| [^24] | [Identification of Regulatory Requirements Relevant to Business Processes: A Comparative Study on Generative AI, Embedding-based Ranking, Crowd and Expert-driven Methods.](http://arxiv.org/abs/2401.02986) | 本研究比较了基于嵌入的自然语言处理排序方法，生成AI模型以及众包和专家驱动方法，旨在研究如何辅助法律和领域专家识别与业务流程相关的监管要求。 |
| [^25] | [Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education.](http://arxiv.org/abs/2401.02985) | 本研究评估了七个主要的大型语言模型在GMAT考试上的表现，并发现大多数模型优于人类考生，其中GPT-4 Turbo不仅在其他模型之上，而且超过了顶级商学院研究生的平均分数。此外，通过案例研究，本研究还考察了GPT-4 Turbo在解释答案、评估回答、识别错误、调整指导和生成替代场景方面的能力。 |
| [^26] | [Large Language Models in Mental Health Care: a Scoping Review.](http://arxiv.org/abs/2401.02984) | 本综述研究对大型语言模型在心理健康护理中的应用和结果进行了综合分析，发现其在诊断、治疗和患者参与增强等方面具有多样化的应用。同时，该研究还识别和讨论了在这些专业领域中所面临的挑战和限制。 |
| [^27] | [BIBench: Benchmarking Data Analysis Knowledge of Large Language Models.](http://arxiv.org/abs/2401.02982) | BIBench是一个旨在评估大型语言模型（LLMs）在商业智能（BI）数据分析领域中能力的综合基准测试，其通过测试模型在BI基础知识、应用知识和技术技能三个维度上的表现来进行评估。 |
| [^28] | [Fine-tuning and Utilization Methods of Domain-specific LLMs.](http://arxiv.org/abs/2401.02981) | 本研究调查了领域特定LLM的微调和利用方法，以金融领域为例，详细介绍了数据集选择、预处理、模型选择以及在金融领域LLM微调中的关键因素。研究探讨了领域特定词汇的构建和安全合规性的考虑因素，并提供了在金融领域生成领域特定LLM的过程和实施方法。多种金融案例被涵盖在内，包括股票价格预测、金融新闻情绪分析、自动文档处理、研究和信息提取等。 |
| [^29] | [Are we describing the same sound? An analysis of word embedding spaces of expressive piano performance.](http://arxiv.org/abs/2401.02979) | 本文探讨了对表现力钢琴演奏特征的不确定性，测试了五个嵌入模型及其相似性结构与真值的对应关系，并进行了进一步评估。嵌入模型的质量在这方面显示出很大的差异性。 |
| [^30] | [Learning from a Generative AI Predecessor -- The Many Motivations for Interacting with Conversational Agents.](http://arxiv.org/abs/2401.02978) | 这项研究通过分析与虚拟伙伴Zo互动的动机，总结出了多种增加互动性的方法，为生成式AI的发展提供了借鉴。 |
| [^31] | [Trace and Edit Relation Associations in GPT.](http://arxiv.org/abs/2401.02976) | 本研究介绍了一种在GPT模型中分析和修改实体关系的新方法，通过关系追踪技术，我们识别了MLP模块和注意机制在处理关系信息方面的关键作用，实验表明该方法在特异性和泛化性方面取得了平衡的改善。 |
| [^32] | [Uncovering Regulatory Affairs Complexity in Medical Products: A Qualitative Assessment Utilizing Open Coding and Natural Language Processing (NLP).](http://arxiv.org/abs/2401.02975) | 本研究揭示了医疗器械行业法规事务的复杂性，并提供了法规语言、流程、全球层面、数据库和产品层面等五个领域的关键复杂性来源。研究结果强调了需要简化法规合规、改善法规机构与行业参与者之间的互动以及制定适应性框架的重要性。 |
| [^33] | [Efficacy of Utilizing Large Language Models to Detect Public Threat Posted Online.](http://arxiv.org/abs/2401.02974) | 本文研究了利用大型语言模型(LLMs)检测在线公开威胁的效力。通过实验发现，不同的LLMs在威胁和非威胁识别方面表现出较高的准确性，其中GPT-4的表现最佳。研究还发现PaLM API的定价非常具有成本效益。研究结果表明，LLMs可以有效地增强人工内容审查，帮助减轻新兴的在线风险。 |
| [^34] | [REE-HDSC: Recognizing Extracted Entities for the Historical Database Suriname Curacao.](http://arxiv.org/abs/2401.02972) | 本文介绍了REE-HDSC项目，旨在改进手写文本识别软件自动提取的命名实体的质量。通过六步处理流程，我们测试了该流程在处理库拉索民事登记处的19世纪和20世纪死亡证书时，日期提取具有高精度，人名提取的精度较低。我们提出了通过重新训练HTR模型、后处理和识别删除不正确的名字来提高人名提取精度的方法。 |
| [^35] | [Deep Anomaly Detection in Text.](http://arxiv.org/abs/2401.02971) | 本研究旨在开发一种基于自我监督学习的方法，用于文本中的异常检测，通过利用预处理任务来提高最新技术，并在半监督和无监督的情况下对两个数据集进行了显著改进。 |
| [^36] | [Rule-Guided Joint Embedding Learning of Knowledge Graphs.](http://arxiv.org/abs/2401.02968) | 本文介绍了一种新型模型，该模型将上下文和字面信息容纳到实体和关系的嵌入中，利用图卷积网络，并通过规则和字面信息的表示计算置信度和相关性指标，以提高知识图谱嵌入学习的效果。 |
| [^37] | [Understanding LLMs: A Comprehensive Overview from Training to Inference.](http://arxiv.org/abs/2401.02038) | 本文提供了一份综合概述，介绍了大规模语言模型（LLMs）从训练到推理的演变过程，并探讨了这一新兴趋势中与成本效率相关的训练和部署方法。同时，还讨论了推理阶段的模型压缩、并行计算、内存调度和结构优化等关键主题，为LLMs的利用和未来发展提供了见解。 |
| [^38] | [Generalist embedding models are better at short-context clinical semantic search than specialized embedding models.](http://arxiv.org/abs/2401.01943) | 本研究发现，在临床语义搜索方面，通用嵌入模型比专业嵌入模型表现更好，这表明现有的临床专业化模型对输入的微小变化更敏感。 |
| [^39] | [GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse.](http://arxiv.org/abs/2401.01523) | 通过基于迷因的社交虐待研究对大型多模态模型的安全洞察，我们引入了综合的迷因基准测试集GOAT-Bench，评估各种LMMs在识别和回应迷因中体现的微妙社交虐待方面的能力。 |
| [^40] | [A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models.](http://arxiv.org/abs/2401.01313) | 大型语言模型在生成文本时容易出现幻觉，这是安全部署这些模型的最大障碍。解决幻觉问题对于在实际环境中广泛使用这些模型至关重要。 |
| [^41] | [A Comprehensive Study of Knowledge Editing for Large Language Models.](http://arxiv.org/abs/2401.01286) | 本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。 |
| [^42] | [Quality and Quantity of Machine Translation References for Automated Metrics.](http://arxiv.org/abs/2401.01283) | 本研究发现，机器翻译评估的较高质量参考文献对于评估指标与人类评价之间的相关性更好。每个段落平均使用7个参考文献有助于提升所有评估指标。不同质量的供应商参考文献可以混合使用来提高评估指标的准确性。这些发现可用于在特定预算下创建参考文献的共享任务的评估者。 |
| [^43] | [Cheetah: Natural Language Generation for 517 African Languages.](http://arxiv.org/abs/2401.01053) | Cheetah是一个面向517种非洲语言的大规模多语种自然语言生成模型，通过综合评估和人工评估，证明了其在生成连贯和上下文恰当的文本方面的卓越性能，并提供了促进语言多样性的解决方案。 |
| [^44] | [If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents.](http://arxiv.org/abs/2401.00812) | 本调查研究探讨了在大规模语言模型中整合代码的好处，包括提升LLMs的代码生成能力、激发推理能力、生成结构化和精确的中间步骤，并利用代码的编译和执行环境来改善模型。 |
| [^45] | [SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models.](http://arxiv.org/abs/2401.00793) | SecFormer是一个优化框架，旨在实现Transformer模型的快速准确隐私保护推理。通过消除高成本的指数和线性操作，SecFormer能够有效解决在大型语言模型中应用SMPC时的性能问题。 |
| [^46] | [Action-Item-Driven Summarization of Long Meeting Transcripts.](http://arxiv.org/abs/2312.17581) | 本文提出了一种新方法来自动化生成行动项驱动的会议摘要，通过递归生成分段摘要并使用行动项提取算法。同时，本文还引入了三种用于将长记录分割成主题部分的新方法，以提高算法的效率和解决问题。 |
| [^47] | [YAYI-UIE: A Chat-Enhanced Instruction Tuning Framework for Universal Information Extraction.](http://arxiv.org/abs/2312.15548) | 本文提出了一个端到端的增强对话指导的通用信息抽取调优框架（YAYI-UIE），利用对话数据和信息抽取数据共同增强信息抽取性能，在中文数据集上达到了业界领先的性能，在英文数据集上也达到了可比较的性能。 |
| [^48] | [Multi-Granularity Information Interaction Framework for Incomplete Utterance Rewriting.](http://arxiv.org/abs/2312.11945) | 该论文提出了一种多层次信息交互框架用于不完整话语重写，该框架通过上下文选择、编辑矩阵构建和相关性合并捕捉多层次的语义信息，并在不完整话语编辑任务中取得了优越的性能。 |
| [^49] | [Toward A Reinforcement-Learning-Based System for Adjusting Medication to Minimize Speech Disfluency.](http://arxiv.org/abs/2312.11509) | 这个论文介绍了一种基于强化学习的系统，该系统可以根据患者言语不流畅程度自动调整药物，通过对药物组合的强化学习算法的优化，能够收敛到良好的用药方案。 |
| [^50] | ["Paraphrasing The Original Text" Makes High Accuracy Long-Context QA.](http://arxiv.org/abs/2312.11193) | 本论文提出了一种名为"原文改写"的任务来处理长文本问答，通过低成本高效的方法成功扩展了现有模型的上下文窗口至32k，并在多文档问答中达到了最先进的准确性。 |
| [^51] | [RJUA-QA: A Comprehensive QA Dataset for Urology.](http://arxiv.org/abs/2312.09785) | RJUA-QA是一个全面的泌尿外科问答数据集，帮助大型语言模型在生成可靠的诊断和建议方面发挥作用。 |
| [^52] | [Analyzing the Impact of Fake News on the Anticipated Outcome of the 2024 Election Ahead of Time.](http://arxiv.org/abs/2312.03750) | 本研究提供了一个全面的数据集，用于分析假新闻对2024年选举结果的提前影响。该数据集包含了40,000篇关于北美政治演讲的新闻文章，并利用先进的语言模型和人工验证方法对其中的一部分进行了注释。研究人员鼓励使用这个数据集并为该倡议做出贡献。 |
| [^53] | [From Beginner to Expert: Modeling Medical Knowledge into General LLMs.](http://arxiv.org/abs/2312.01040) | 本文提出了一种将医学知识建模到通用LLM中的方法，并通过优化过程将其从医学初学者调整为医学专家。实验证明该方法在回答医学问题方面取得了良好的效果，同时使用较小规模的模型大小，与大规模LLM模型相当，更加适用于医学应用。 |
| [^54] | [Comparative Experimentation of Accuracy Metrics in Automated Medical Reporting: The Case of Otitis Consultations.](http://arxiv.org/abs/2311.13273) | 本研究进行了一项比较实验，评估了自动化医学报告中10种准确性度量指标的应用。以中耳咨询为例，分析了生成的报告与全科医生报告之间的相关性。同时，引入了一个组合准确度得分，用于比较自动化医学报告领域内的度量指标。 |
| [^55] | [Explore Spurious Correlations at the Concept Level in Language Models for Text Classification.](http://arxiv.org/abs/2311.08648) | 本文研究了语言模型在文本分类中概念级别的误相关性问题，并通过使用ChatGPT分配概念标签和引入数据再平衡技术来解决这一问题。 |
| [^56] | [Kiki or Bouba? Sound Symbolism in Vision-and-Language Models.](http://arxiv.org/abs/2310.16781) | 这项研究通过调查视觉与语言模型中的内在知识，发现它们显示了声音象征性的模式，进一步证实声音和意义之间的相关性在跨模态关联中得到了体现。 |
| [^57] | [Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons.](http://arxiv.org/abs/2310.16582) | 本文介绍了一种新方法，通过无监督建立个性化词典，来定制大型语言模型的个性特征。该方法可以以可插拔的方式结合五个大类因素，实现对个性特征的精确操纵。 |
| [^58] | [What is a good question? Task-oriented asking with fact-level masking.](http://arxiv.org/abs/2310.11571) | 本论文提出了基于任务的询问（TOA）的概念和框架，介绍了一种用于生成对推理任务有用答案的问题的方法。同时还提出了一种事实级遮蔽（FLM）的技术，用于将自然语言数据集转换为自我监督的TOA数据集。 |
| [^59] | [ResidualTransformer: Residual Low-rank Learning with Weight-sharing for Transformer Layers.](http://arxiv.org/abs/2310.02489) | 本文提出了一种名为ResidualTransformer的方法，通过重新参数化Transformer编码器层之间的模型权重，将模型的大小减小。实验结果表明，ResidualTransformer的性能优于传统Transformer模型，且模型大小得到了显著减小。 |
| [^60] | [Automated Evaluation of Classroom Instructional Support with LLMs and BoWs: Connecting Global Predictions to Specific Feedback.](http://arxiv.org/abs/2310.01132) | 本研究旨在利用大型语言模型和词袋模型自动估计课堂教学支持，以提供更具体、频繁和可行动的反馈给教师。实验证明，所提出的方法准确性接近于人工互评可靠性，LLM模型可以更好地捕捉到教学支持特征。 |
| [^61] | [Synthetic Data Generation in Low-Resource Settings via Fine-Tuning of Large Language Models.](http://arxiv.org/abs/2310.01119) | 通过对大型语言模型进行微调，在低资源环境中可以通过合成数据生成来改善较小模型的性能，显著提高了下游模型的性能。 |
| [^62] | [Can Large Language Models Understand Real-World Complex Instructions?.](http://arxiv.org/abs/2309.09150) | 本论文提出了一个用于评估大规模语言模型理解复杂指令能力的基准——CELLO。通过设计复杂指令的八个特征并构建全面的评估数据集，可以解决现有基准的不足。 |
| [^63] | [TextBind: Multi-turn Interleaved Multimodal Instruction-following.](http://arxiv.org/abs/2309.08637) | TextBind是一个注释极少的框架，用于将较大规模的语言模型赋予多轮交错多模态指令跟随能力，并通过图像-标题对生成多轮多模态指令-回应对话。这个框架对于解决实际任务具有重要意义，并为未来的研究提供了数据集、模型和演示。 |
| [^64] | [Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies.](http://arxiv.org/abs/2309.02045) | 通过提示策略，本论文探究了如何通过应用角色扮演和思维链提示策略来增强大型语言模型（LLMs）在情感分析中的性能，并在三个不同领域的数据集上进行了评估。 |
| [^65] | [Long-Term Memorability On Advertisements.](http://arxiv.org/abs/2309.00378) | 本研究是首个大规模的记忆性研究，发现广告的长期记忆性对于市场营销非常重要，但在机器学习文献中一直缺乏相关研究。通过分析大量参与者和广告，我们得出了关于什么使广告记忆深刻的有趣见解。 |
| [^66] | [WavMark: Watermarking for Audio Generation.](http://arxiv.org/abs/2308.12770) | WavMark是一种创新的音频水印技术，可以在短短1秒的音频片段中编码多达32位的水印，对人类感官无感知并且具有强大的韧性。它可以用于合成声音的有效识别和音频版权保护。 |
| [^67] | [Convoifilter: A case study of doing cocktail party speech recognition.](http://arxiv.org/abs/2308.11380) | 本文通过使用单声道语音增强模块与ASR模块，成功将ASR的词错误率从80%降低到26.4%，并通过联合微调策略将其进一步降低到14.5%。 |
| [^68] | [Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review.](http://arxiv.org/abs/2308.04306) | 本文对基于深度学习的隐喻识别任务中知识注入的研究进展进行了全面综述，包括主流知识和知识注入原则的总结、数据集、评估指标和基准模型的回顾，并探讨了当前的知识注入问题。 |
| [^69] | [Exploring Format Consistency for Instruction Tuning.](http://arxiv.org/abs/2307.15504) | 本研究探究了指令调整的格式一致性，并提出了统一指令调整（UIT）框架，通过自动格式转换来提高泛化性能。该研究强调了格式一致性的重要性。 |
| [^70] | [Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media.](http://arxiv.org/abs/2307.09312) | 多模态讨论变换器 (mDT) 是一个用于检测在线社交网络中仇恨言论的新颖模型。与传统的仅使用文本的方法不同，mDT通过整体分析文本和图像，结合图变换器捕捉评论周围整个讨论的上下文关系，并通过交织融合层将文本和图像嵌入进行组合。研究发现，捕捉对话的整体视图可以极大地提高检测反社会行为的准确性。 |
| [^71] | [Cross-Lingual Transfer Learning for Low-Resource Speech Translation.](http://arxiv.org/abs/2306.00789) | 提出了一种三步跨语言迁移学习框架，通过在现有框架中增加一步语义知识蒸馏，该方法有效地增强了自动语音翻译中从高资源语言到低资源语言的跨语言迁移能力，显著改善了翻译性能，特别是对于低资源语言，并减少了跨语言迁移间隙(TRFGap)。 |
| [^72] | [AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback.](http://arxiv.org/abs/2305.14387) | 该论文提出了一种名为AlpacaFarm的低成本模拟器，该模拟器为从人类反馈中学习的研究和开发提供了一种解决方案，通过设计LLM提示来模拟人类反馈，提出自动评估并提供参考实现，克服了数据收集的高昂成本、缺乏可信的评估和缺乏参考方法实现的挑战。 |
| [^73] | [Can Language Models Solve Graph Problems in Natural Language?.](http://arxiv.org/abs/2305.10037) | 本论文提出了自然语言图形(NLGraph)，这是一个全面的基于图形问题解决测试，旨在评估LLM在文本描述的图形结构和图形解决方案方面的处理能力。实验结果表明，LLM(GPT-3/4)具有相应的图形推理能力。 |
| [^74] | [Natural Language Decomposition and Interpretation of Complex Utterances.](http://arxiv.org/abs/2305.08677) | 本论文提出了一种处理复杂意图话语的方法，通过分层自然语言分解和解释的过程将复杂话语分解为简单的自然语言步骤，并使用预训练的语言模型和语言到程序模型解释每个步骤。实验证明了该方法的有效性。 |
| [^75] | [Answering Complex Questions over Text by Hybrid Question Parsing and Execution.](http://arxiv.org/abs/2305.07789) | 提出了一种混合问题解析和执行框架，在文字问答系统中实现回答复杂问题，通过解析问题为H表达式并设计混合执行器实现。在基准数据集中实现了最先进的准确率和效率表现。 |
| [^76] | [Explainable Recommender with Geometric Information Bottleneck.](http://arxiv.org/abs/2305.05331) | 该论文提出了一种新的可解释推荐系统模型，将从用户-商品交互中学得的几何先验知识与变分网络相结合，可以为用户提供既具备推荐性能又具有解释性能的解释推荐服务。 |
| [^77] | [Building a Non-native Speech Corpus Featuring Chinese-English Bilingual Children: Compilation and Rationale.](http://arxiv.org/abs/2305.00446) | 本文介绍了一份非母语语音语料库，由50名中英双语儿童提供英语（L2）叙述，为第二语言教学提供了有价值的资源并有可能提高自动语音识别（ASR）的整体性能。 |
| [^78] | [The Deep Latent Position Topic Model for Clustering and Representation of Networks with Textual Edges.](http://arxiv.org/abs/2304.08242) | 深层潜在位置主题模型用于网络聚类和表示，通过基于模型的聚类策略和概率模型对节点和边进行联合表示，并使用模型选择准则进行参数选择。 |
| [^79] | [Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning.](http://arxiv.org/abs/2303.10475) | 传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。 |
| [^80] | [LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain.](http://arxiv.org/abs/2301.13126) | LEXTREME是一个多语言和多任务的法律领域基准，该基准提供了11个数据集涵盖24种语言的测评，最佳模型（XLM-R large）在数据集和语言综合评分上均达到了61.3。这使得LEXTREME仍然具有挑战性并且有改进空间。 |
| [^81] | [Evaluating Human-Language Model Interaction.](http://arxiv.org/abs/2212.09746) | 为了评估人机交互，研究人员开发了一个框架HALIE，该框架捕捉了交互过程、主观体验和偏好概念，并设计了五个任务来涵盖不同形式的交互。 |
| [^82] | [Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations.](http://arxiv.org/abs/2206.15462) | 该论文提出了一种名为 AMC 的目标函数，鼓励基于梯度的解释覆盖有注释的感兴趣区域，即编码区域。该方法在提高视觉 grounding 性能方面表现卓越，有望成为视觉 grounding 领域的新进展。 |
| [^83] | [Token-Modification Adversarial Attacks for Natural Language Processing: A Survey.](http://arxiv.org/abs/2103.00676) | 这项调研对现有的自然语言处理中的标记修改对抗攻击进行了分类和比较，并旨在指导新的研究并推动进一步的攻击组件研究。 |

# 详细

[^1]: 大规模语言模型在现实世界中对恶意言论检测的调查

    An Investigation of Large Language Models for Real-World Hate Speech Detection. (arXiv:2401.03346v1 [cs.CY])

    [http://arxiv.org/abs/2401.03346](http://arxiv.org/abs/2401.03346)

    本研究调查了大规模语言模型在现实世界中对恶意言论检测的有效性，并发现现有方法在上下文感知方面存在显著限制。而大规模语言模型具有潜力作为上下文感知恶意言论检测的知识库，但目前缺乏有效提示这些模型的方法。

    

    恶意言论已经成为困扰我们社交空间的一个主要问题。虽然在解决这个问题上已经做出了一些显著的努力，但现有方法在有效检测在线恶意言论方面仍然存在显著限制。现有方法的一个主要限制是恶意言论检测是一个高度上下文相关的问题，而这些方法无法完全捕捉恶意言论的上下文以进行准确的预测。最近，大规模语言模型（LLMs）在几个自然语言任务中展示了最先进的性能。LLMs经过大量的自然语言数据进行了广泛的训练，使其能够掌握复杂的上下文细节。因此，它们可以用作上下文感知的恶意言论检测的知识库。然而，使用LLMs检测恶意言论的一个基本问题是没有关于有效提示LLMs进行上下文感知的恶意言论检测的研究。在本研究中，我们进行了一个大规模的研究，调查恶意言论检测方面的问题。

    Hate speech has emerged as a major problem plaguing our social spaces today. While there have been significant efforts to address this problem, existing methods are still significantly limited in effectively detecting hate speech online. A major limitation of existing methods is that hate speech detection is a highly contextual problem, and these methods cannot fully capture the context of hate speech to make accurate predictions. Recently, large language models (LLMs) have demonstrated state-of-the-art performance in several natural language tasks. LLMs have undergone extensive training using vast amounts of natural language data, enabling them to grasp intricate contextual details. Hence, they could be used as knowledge bases for context-aware hate speech detection. However, a fundamental problem with using LLMs to detect hate speech is that there are no studies on effectively prompting LLMs for context-aware hate speech detection. In this study, we conduct a large-scale study of hat
    
[^2]: PIXAR：像素空间中的自回归语言建模

    PIXAR: Auto-Regressive Language Modeling in Pixel Space. (arXiv:2401.03321v1 [cs.CL])

    [http://arxiv.org/abs/2401.03321](http://arxiv.org/abs/2401.03321)

    本论文介绍了PIXAR，这是第一个像素自回归的语言模型，可以用于生成自由形式的文本作为图像，而不依赖于预定义的词汇表。同时，论文还提出了一个简单的对抗性预训练方法来解决生成非模糊文本的挑战。

    

    最近的研究显示可以构建基于像素表示的开放词汇量大语言模型（LLMs），这些模型以编码器-解码器模型的形式，重构遮蔽的图像文本补丁。然而，这些基于像素的LLMs仅限于自编码任务，无法生成新的文本作为图像。因此，它们不能用于开放式回答或生成式语言任务。在这项工作中，我们克服了这一限制，并引入了PIXAR，这是第一个不需要预定义词汇表的像素自回归LLM，用于输入和输出文本。PIXAR只有一个解码器，可以回答自由形式的生成任务，并且在文本表示学习性能上与以前的编码器-解码器模型持平。此外，我们强调了以自回归方式生成非模糊文本作为图像的挑战，并将其与通常的最大似然目标联系起来。我们提出了一个简单的对抗性预训练方法，该方法在很大程度上解决了这个问题。

    Recent works showed the possibility of building open-vocabulary large language models (LLMs) that directly operate on pixel representations and are implemented as encoder-decoder models that reconstruct masked image patches of rendered text. However, these pixel-based LLMs are limited to autoencoding tasks and cannot generate new text as images. As such, they cannot be used for open-answer or generative language tasks. In this work, we overcome this limitation and introduce PIXAR, the first pixel-based autoregressive LLM that does not rely on a pre-defined vocabulary for both input and output text. Consisting of only a decoder, PIXAR can answer free-form generative tasks while keeping the text representation learning performance on par with previous encoder-decoder models. Furthermore, we highlight the challenges to autoregressively generate non-blurred text as images and link this to the usual maximum likelihood objective. We propose a simple adversarial pretraining that significantly
    
[^3]: 提升对比度的上下文增强

    Enhancing Context Through Contrast. (arXiv:2401.03314v1 [cs.CL])

    [http://arxiv.org/abs/2401.03314](http://arxiv.org/abs/2401.03314)

    本研究提出了一种通过对比学习来提高神经机器翻译性能的新方法，利用巴洛双胞胎损失最大化互信息。与其他方法不同的是，该方法通过上下文增强来提升性能，而不需要明确地增加数据或从头开始学习嵌入。

    

    神经机器翻译受益于语义丰富的表示。通过语言建模和对比学习使用互信息最大化目标，已经实现了对这种表示的大幅进展。语言建模的依赖性使得在学习表示的通用性和模型在语言建模任务上的性能之间存在权衡。虽然对比学习改进了性能，但其成功不能仅归因于互信息。我们提出了一种新的上下文增强步骤，通过使用巴洛双胞胎损失最大化互信息来提高神经机器翻译的性能。与其他方法不同的是，我们不是显式地增加数据，而是将语言视为隐含的增强，消除了破坏语义信息的风险。此外，我们的方法不会从头开始学习嵌入，并且可以推广到任何一组预训练的嵌入。

    Neural machine translation benefits from semantically rich representations. Considerable progress in learning such representations has been achieved by language modelling and mutual information maximization objectives using contrastive learning. The language-dependent nature of language modelling introduces a trade-off between the universality of the learned representations and the model's performance on the language modelling tasks. Although contrastive learning improves performance, its success cannot be attributed to mutual information alone. We propose a novel Context Enhancement step to improve performance on neural machine translation by maximizing mutual information using the Barlow Twins loss. Unlike other approaches, we do not explicitly augment the data but view languages as implicit augmentations, eradicating the risk of disrupting semantic information. Further, our method does not learn embeddings from scratch and can be generalised to any set of pre-trained embeddings. Fin
    
[^4]: 大型语言模型作为视觉跨领域学习器

    Large Language Models as Visual Cross-Domain Learners. (arXiv:2401.03253v1 [cs.CV])

    [http://arxiv.org/abs/2401.03253](http://arxiv.org/abs/2401.03253)

    本研究提出了大型语言模型作为视觉跨领域学习器（LLaVO），通过将图像转换为文本描述，使用大型语言模型进行训练和微调，实现了在跨领域任务中减少领域转移的效果。

    

    深度学习模型取得的最新进展依赖于独立同分布的假设，这限制了它们在真实世界中面对领域转移时的应用。为了解决以上问题，跨领域学习旨在提取领域不变的知识，减少训练与测试数据之间的领域转移。然而，在视觉跨领域学习中，传统方法仅关注图像模态，忽视了使用文本模态来缓解领域转移的作用。在本研究中，我们提出了大型语言模型作为视觉跨领域学习器（LLaVO）。LLaVO使用视觉-语言模型将图像转换为详细的文本描述。然后，在经过设计的指导模板生成的源域/目标域的文本描述上，对大型语言模型进行微调。在领域泛化和无监督领域自适应设置下进行的各种跨领域任务的广泛实验结果表明了该方法的效果。

    Recent advances achieved by deep learning models rely on the independent and identically distributed assumption, hindering their applications in real-world scenarios with domain shifts. To address the above issues, cross-domain learning aims at extracting domain-invariant knowledge to reduce the domain shift between training and testing data. However, in visual cross-domain learning, traditional methods concentrate solely on the image modality, neglecting the use of the text modality to alleviate the domain shift. In this work, we propose Large Language models as Visual cross-dOmain learners (LLaVO). LLaVO uses vision-language models to convert images into detailed textual descriptions. A large language model is then finetuned on textual descriptions of the source/target domain generated by a designed instruction template. Extensive experimental results on various cross-domain tasks under the domain generalization and unsupervised domain adaptation settings have demonstrated the effect
    
[^5]: 对归纳主题饱和度作为衡量归纳主题分析与LLMs有效性的潜在指标的反思

    Reflections on Inductive Thematic Saturation as a potential metric for measuring the validity of an inductive Thematic Analysis with LLMs. (arXiv:2401.03239v1 [cs.CL])

    [http://arxiv.org/abs/2401.03239](http://arxiv.org/abs/2401.03239)

    本文对归纳主题饱和度作为衡量归纳主题分析与LLMs有效性的潜在指标进行了反思，并提出了一种用于合成度量初步主题饱和度的指标。

    

    本文对饱和度和使用大型语言模型（LLMs）进行主题分析（TA）进行了一系列反思。本文提出初步主题饱和度（ITS）可以用作评估LLM下TA的一部分事务有效性的指标，重点是初始编码。本文呈现了两个不同规模数据集的初始编码，并反思LLM在编码过程中达到某种形式的分析饱和度。本文所提出的方法导致了创建了两个编码手册，一个包括累积初始编码的总数，另一个包括唯一编码的总数。本文提出了一种用简单数学计算（使用累积编码和唯一编码之间的斜率比）来综合度量ITS的指标。本文对于探索如何使用LLMs进行定性分析的初步研究有所贡献。

    This paper presents a set of reflections on saturation and the use of Large Language Models (LLMs) for performing Thematic Analysis (TA). The paper suggests that initial thematic saturation (ITS) could be used as a metric to assess part of the transactional validity of TA with LLM, focusing on the initial coding. The paper presents the initial coding of two datasets of different sizes, and it reflects on how the LLM reaches some form of analytical saturation during the coding. The procedure proposed in this work leads to the creation of two codebooks, one comprising the total cumulative initial codes and the other the total unique codes. The paper proposes a metric to synthetically measure ITS using a simple mathematical calculation employing the ratio between slopes of cumulative codes and unique codes. The paper contributes to the initial body of work exploring how to perform qualitative analysis with LLMs.
    
[^6]: 黑暗之后的黎明：大型语言模型中关于事实性幻觉的实证研究

    The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models. (arXiv:2401.03205v1 [cs.CL])

    [http://arxiv.org/abs/2401.03205](http://arxiv.org/abs/2401.03205)

    本研究通过实证研究探讨了大型语言模型中事实性幻觉的检测、来源和缓解方法。研究构建了新的幻觉基准HaluluEval 2.0，并设计了简单有效的LLM幻觉检测方法。通过深入分析LLMs的训练和利用阶段，并研究导致幻觉的潜在因素，提出了一系列可行的减轻幻觉的技术。

    

    在大型语言模型（LLM）的时代，幻觉（即生成错误事实内容的倾向）给在现实世界中信任和可靠地部署LLMs带来了巨大的挑战。为了解决LLM幻觉问题，需要深入研究三个关键问题：如何检测幻觉（检测），LLMs为什么会产生幻觉（来源），以及如何减轻LLM幻觉（缓解）。为了解决这些挑战，本研究提出了一项系统的LLM幻觉实证研究，专注于幻觉的检测、来源和缓解三个方面。具体地，我们构建了一个新的幻觉基准HaluluEval 2.0，并为LLM幻觉设计了一个简单而有效的检测方法。此外，我们对LLMs的不同训练或利用阶段进行了深入分析，广泛研究了导致LLM幻觉的潜在因素。最后，我们实施并检验了一系列广泛使用的技术来减轻幻觉。

    In the era of large language models (LLMs), hallucination (i.e., the tendency to generate factually incorrect content) poses great challenge to trustworthy and reliable deployment of LLMs in real-world applications. To tackle the LLM hallucination, three key questions should be well studied: how to detect hallucinations (detection), why do LLMs hallucinate (source), and what can be done to mitigate them (mitigation). To address these challenges, this work presents a systematic empirical study on LLM hallucination, focused on the the three aspects of hallucination detection, source and mitigation. Specially, we construct a new hallucination benchmark HaluEval 2.0, and designs a simple yet effective detection method for LLM hallucination. Furthermore, we zoom into the different training or utilization stages of LLMs and extensively analyze the potential factors that lead to the LLM hallucination. Finally, we implement and examine a series of widely used techniques to mitigate the halluci
    
[^7]: MPN: 利用多语言补丁神经元进行跨语言模型编辑

    MPN: Leveraging Multilingual Patch Neuron for Cross-lingual Model Editing. (arXiv:2401.03190v1 [cs.CL])

    [http://arxiv.org/abs/2401.03190](http://arxiv.org/abs/2401.03190)

    本论文提出了一种简单而有效的方法，利用多语言补丁神经元来解决多语言模型的跨语言知识同步问题，并取得了良好的实验结果。

    

    大型语言模型通常编码了大量的事实知识，但由于外部信息的不断变化，它们经常过时。解决这个挑战的一个有前途的方法是利用模型编辑方法以高效的方式更新知识。然而，大部分现有的模型编辑技术局限于单语框架，因此无法解决多语言模型的跨语言知识同步的关键问题。为了解决这个问题，我们提出了一种简单而有效的方法，即训练多语言补丁神经元来存储跨语言知识。它可以轻松适应现有方法，增强它们的跨语言编辑能力。为了评估我们的方法，我们使用XNLI数据集和自建的XFEVER数据集进行了实验。实验结果表明，我们提出的方法在跨语言编辑任务中实现了改进的性能，而不需要额外的工作。

    Large language models are known for encoding a vast amount of factual knowledge, but they often becomes outdated due to the ever-changing nature of external information. A promising solution to this challenge is the utilization of model editing methods to update the knowledge in an efficient manner. However, the majority of existing model editing techniques are limited to monolingual frameworks, thus failing to address the crucial issue of cross-lingual knowledge synchronization for multilingual models. To tackle this problem, we propose a simple yet effective method that trains multilingual patch neuron to store cross-lingual knowledge. It can be easily adapted to existing approaches to enhance their cross-lingual editing capabilities. To evaluate our method, we conduct experiments using both the XNLI dataset and a self-constructed XFEVER dataset. Experimental results demonstrate that our proposed method achieves improved performance in cross-lingual editing tasks without requiring ex
    
[^8]: {\delta}-CAUSAL：探索因果推理中的可废除性

    {\delta}-CAUSAL: Exploring Defeasibility in Causal Reasoning. (arXiv:2401.03183v1 [cs.CL])

    [http://arxiv.org/abs/2401.03183](http://arxiv.org/abs/2401.03183)

    本文提出了{\delta}-CAUSAL，这是一个用于研究因果推理中可废除性的基准数据集，并指出现有的因果强度度量无法在可废除环境中准确评估因果关系的变化。

    

    因果推理中的可废除性意味着因果关系可以被加强或削弱。也就是说，因果关系的强度应该随着加入支持者或驳斥者而增加或减少。然而，现有的研究忽视了因果推理中的可废除性，并未在可废除环境中评估现有的因果强度度量。在这项工作中，我们提出了第一个用于研究因果推理中的可废除性的基准数据集{\delta}-CAUSAL。{\delta}-CAUSAL包括约11K个涵盖十个领域的事件，其中包括支持者和驳斥者的可废除因果关系对。我们进一步展示了当前的因果强度度量无法反映{\delta}-CAUSAL中的支持者或驳斥者加入后的因果强度变化。为此，我们提出了CESAR（Causal Embedding aSsociation with Attention Rating）。

    Defeasibility in causal reasoning implies that the causal relationship between cause and effect can be strengthened or weakened. Namely, the causal strength between cause and effect should increase or decrease with the incorporation of strengthening arguments (supporters) or weakening arguments (defeaters), respectively. However, existing works ignore defeasibility in causal reasoning and fail to evaluate existing causal strength metrics in defeasible settings. In this work, we present {\delta}-CAUSAL, the first benchmark dataset for studying defeasibility in causal reasoning. {\delta}-CAUSAL includes around 11K events spanning ten domains, featuring defeasible causality pairs, i.e., cause-effect pairs accompanied by supporters and defeaters. We further show current causal strength metrics fail to reflect the change of causal strength with the incorporation of supporters or defeaters in {\delta}-CAUSAL. To this end, we propose CESAR (Causal Embedding aSsociation with Attention Rating),
    
[^9]: 一种基于联合推理的疾病问答系统

    A Joint-Reasoning based Disease Q&A System. (arXiv:2401.03181v1 [cs.CL])

    [http://arxiv.org/abs/2401.03181](http://arxiv.org/abs/2401.03181)

    这项研究提出了一种基于联合推理的疾病问答系统，通过结合语言模型和知识图谱的方法，旨在回答普通用户的健康相关问题并减轻医疗保健专业人员的负担。

    

    医学问答（QA）助手通过使用自然语言处理和相关技术从多个信息源合成信息来回答普通用户的健康相关问题。它们可以作为重要工具来缓解误导、信息过载和医学术语复杂性问题，从而满足普通用户的信息需求并减轻医疗保健专业人员的负担。QA系统通常使用语言模型（LM）或知识图谱（KG），尽管这两种方法可以互补。基于LM的QA系统擅长理解复杂问题并提供合适的答案，但易于出现事实错误。基于KG的QA系统能够很好地表示事实，但大多数仅限于回答已预先创建模板的简短问题。虽然一些研究已经联合使用了LM和KG方法来进行基于文本的QA，但这是用于回答多项选择题。现有的QA系统也存在一些问题。

    Medical question answer (QA) assistants respond to lay users' health-related queries by synthesizing information from multiple sources using natural language processing and related techniques. They can serve as vital tools to alleviate issues of misinformation, information overload, and complexity of medical language, thus addressing lay users' information needs while reducing the burden on healthcare professionals. QA systems, the engines of such assistants, have typically used either language models (LMs) or knowledge graphs (KG), though the approaches could be complementary. LM-based QA systems excel at understanding complex questions and providing well-formed answers, but are prone to factual mistakes. KG-based QA systems, which represent facts well, are mostly limited to answering short-answer questions with pre-created templates. While a few studies have jointly used LM and KG approaches for text-based QA, this was done to answer multiple-choice questions. Extant QA systems also 
    
[^10]: 文本-视频检索通过变分多模态超图网络

    Text-Video Retrieval via Variational Multi-Modal Hypergraph Networks. (arXiv:2401.03177v1 [cs.CV])

    [http://arxiv.org/abs/2401.03177](http://arxiv.org/abs/2401.03177)

    本文提出了一种文本-视频检索的方法，通过引入多模态超图进行n元相关建模，从而解决了文本性质和视频内容的语义差距问题。

    

    文本-视频检索是一个具有挑战性的任务，旨在根据文本查询识别相关视频。与传统的文本检索相比，文本-视频检索的主要障碍是查询的文本性质和视频内容的视觉丰富性之间的语义差距。以人类认知过程中模块化判断文本和视频相关性为灵感，由于视频内容的连续和复杂性，判断需要高阶匹配信号。在本文中，我们提出了块级文本-视频匹配，其中提取查询块以描述特定的检索单元，而视频块则从视频中分割成不同的片段。我们将块级匹配形式化为查询词和视频帧之间的n元相关建模，并引入多模态超图进行n元相关建模。

    Text-video retrieval is a challenging task that aims to identify relevant videos given textual queries. Compared to conventional textual retrieval, the main obstacle for text-video retrieval is the semantic gap between the textual nature of queries and the visual richness of video content. Previous works primarily focus on aligning the query and the video by finely aggregating word-frame matching signals. Inspired by the human cognitive process of modularly judging the relevance between text and video, the judgment needs high-order matching signal due to the consecutive and complex nature of video contents. In this paper, we propose chunk-level text-video matching, where the query chunks are extracted to describe a specific retrieval unit, and the video chunks are segmented into distinct clips from videos. We formulate the chunk-level matching as n-ary correlations modeling between words of the query and frames of the video and introduce a multi-modal hypergraph for n-ary correlation m
    
[^11]: 使用深度学习方法的Bodo语词性标注器

    Part-of-Speech Tagger for Bodo Language using Deep Learning approach. (arXiv:2401.03175v1 [cs.CL])

    [http://arxiv.org/abs/2401.03175](http://arxiv.org/abs/2401.03175)

    本文介绍了使用深度学习方法的Bodo语词性标注器。首先，我们提出了Bodo语言模型BodoBERT，这项工作是第一个为Bodo开发的语言模型。其次，我们提出了基于深度学习的Bodo词性标注模型，该模型利用了BiLSTM、CRF和BodoBERT与BytePairEmbeddings的组合。尽管研究已经在资源丰富的语言中进行了大量的语言模型和词性标注模型的研究，但对于低资源语言如Bodo，仍然缺乏相关研究。

    

    语言处理系统如词性标注、命名实体识别、机器翻译、语音识别和语言建模在资源丰富的语言中已经得到了广泛研究。然而，对于一些低资源语言，如Bodo、Mizo、Nagamese等，这些系统的研究要么尚未开始，要么处于起步阶段。语言模型在现代自然语言处理的下游任务中起着重要作用。对于资源丰富的语言已经进行了大量的语言模型研究。然而，像Bodo、Rabha和Mising这样的语言仍然缺乏相关研究。本研究首先提出了BodoBERT，一个用于Bodo语的语言模型。据我们所知，这项工作是第一个为Bodo开发语言模型的努力。其次，我们提出了一个基于集成深度学习的Bodo词性标注模型。该词性标注模型基于BiLSTM和CRF的组合，以及BodoBERT与BytePairEmbeddings的堆叠嵌入。我们涵盖了多种语言...（摘要被截断）

    Language Processing systems such as Part-of-speech tagging, Named entity recognition, Machine translation, Speech recognition, and Language modeling (LM) are well-studied in high-resource languages. Nevertheless, research on these systems for several low-resource languages, including Bodo, Mizo, Nagamese, and others, is either yet to commence or is in its nascent stages. Language model plays a vital role in the downstream tasks of modern NLP. Extensive studies are carried out on LMs for high-resource languages. Nevertheless, languages such as Bodo, Rabha, and Mising continue to lack coverage. In this study, we first present BodoBERT, a language model for the Bodo language. To the best of our knowledge, this work is the first such effort to develop a language model for Bodo. Secondly, we present an ensemble DL-based POS tagging model for Bodo. The POS tagging model is based on combinations of BiLSTM with CRF and stacked embedding of BodoBERT with BytePairEmbeddings. We cover several lan
    
[^12]: 四步推理（QLFR）框架：推进短文本分类的四步推理

    Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification. (arXiv:2401.03158v1 [cs.CL])

    [http://arxiv.org/abs/2401.03158](http://arxiv.org/abs/2401.03158)

    四步推理（QLFR）框架是一种通过引入句法和语义丰富的CoT来提升短文本分类任务中大型语言模型（LLMs）性能的方法。

    

    短文本分类（STC）对于处理和理解当代数字平台上流行的简洁而重要的内容至关重要。STC在抓住语义和句法复杂性方面遇到困难，这个问题在传统的预训练语言模型中很明显。尽管图卷积网络通过整合外部知识库提高了性能，但这些方法受到应用知识质量和范围的限制。最近，大型语言模型（LLMs）和思维链（CoT）的出现显著提高了复杂推理任务的性能。然而，一些研究指出了它们在基础NLP任务中的应用限制。因此，本研究旨在运用CoT来研究LLMs在STC任务中的能力。本研究引入了四步推理（QLFR）框架。这个框架主要包括句法和语义丰富的CoT，有效利用了LLMs的能力。

    Short Text Classification (STC) is crucial for processing and comprehending the brief but substantial content prevalent on contemporary digital platforms. The STC encounters difficulties in grasping semantic and syntactic intricacies, an issue that is apparent in traditional pre-trained language models. Although Graph Convolutional Networks enhance performance by integrating external knowledge bases, these methods are limited by the quality and extent of the knowledge applied. Recently, the emergence of Large Language Models (LLMs) and Chain-of-Thought (CoT) has significantly improved the performance of complex reasoning tasks. However, some studies have highlighted the limitations of their application in fundamental NLP tasks. Consequently, this study sought to employ CoT to investigate the capabilities of LLMs in STC tasks. This study introduces Quartet Logic: A Four-Step Reasoning (QLFR) framework. This framework primarily incorporates Syntactic and Semantic Enrichment CoT, effectiv
    
[^13]: 在对齐大型语言模型的持续预训练中研究遗忘现象

    Examining Forgetting in Continual Pre-training of Aligned Large Language Models. (arXiv:2401.03129v1 [cs.CL])

    [http://arxiv.org/abs/2401.03129](http://arxiv.org/abs/2401.03129)

    本文研究了在对齐大型语言模型的持续预训练过程中出现的遗忘现象，通过评估持续预训练对微调模型在输出格式、知识和可靠性等方面的影响，结果发现解决灾难性遗忘，尤其是重复问题，是一个非常具有挑战性的问题。

    

    最近大型语言模型(LLMs)的先进研究在各种任务中展现了出色的能力。鉴于LLMs在很多领域中的重要应用，LLM的开发也有了显著增长。在开发LLMs时，一种常见做法是对先前微调模型进行连续的预训练。然而，这可能导致灾难性的遗忘。在我们的工作中，我们研究了在现有微调LLM的持续预训练过程中发生的遗忘现象。我们评估了持续预训练对微调LLM在输出格式、知识和可靠性等各个维度上的影响。实验结果突显了在持续预训练过程中解决灾难性遗忘的非平凡挑战，尤其是重复问题。

    Recent advances in Large Language Models (LLMs) have exhibited remarkable proficiency across various tasks. Given the potent applications of LLMs in numerous fields, there has been a surge in LLM development. In developing LLMs, a common practice involves continual pre-training on previously fine-tuned models. However, this can lead to catastrophic forgetting. In our work, we investigate the phenomenon of forgetting that occurs during continual pre-training on an existing fine-tuned LLM. We evaluate the impact of continuous pre-training on the fine-tuned LLM across various dimensions, including output format, knowledge, and reliability. Experiment results highlight the non-trivial challenge of addressing catastrophic forgetting during continual pre-training, especially the repetition issue.
    
[^14]: 探索人与对话型智能体交互中语言模式中的性别偏见

    Exploring Gender Biases in Language Patterns of Human-Conversational Agent Conversations. (arXiv:2401.03030v1 [cs.HC])

    [http://arxiv.org/abs/2401.03030](http://arxiv.org/abs/2401.03030)

    本研究旨在探索人与对话型智能体交互中的性别偏见，并研究对话型智能体的性别设计如何触发既有性别偏见并强化性别刻板印象。

    

    随着人机交互的兴起，机器越来越多地设计成类似人类的特征，如性别，这可能无意中引发认知偏见。许多对话型智能体（CAs），如语音助手和聊天机器人，默认为女性角色，引发了有关持续性性别刻板印象和不平等的担忧。有人批评这些技术可能把女性物化并强化性别刻板印象。这项研究旨在从对话型人工智能设计的角度深入探讨性别偏见在人与对话型智能体交互中的影响。从行为和沟通研究的角度来看，该项目不仅关注用户与对话型智能体互动时的认知，还关注其语言风格，之前的研究很少涉及这方面。研究目的是了解对话型智能体的性别设计如何触发既有性别偏见，并进一步研究对话型智能体的性别设计如何强化性别刻板印象。

    With the rise of human-machine communication, machines are increasingly designed with humanlike characteristics, such as gender, which can inadvertently trigger cognitive biases. Many conversational agents (CAs), such as voice assistants and chatbots, default to female personas, leading to concerns about perpetuating gender stereotypes and inequality. Critiques have emerged regarding the potential objectification of females and reinforcement of gender stereotypes by these technologies. This research, situated in conversational AI design, aims to delve deeper into the impacts of gender biases in human-CA interactions. From a behavioral and communication research standpoint, this program focuses not only on perceptions but also the linguistic styles of users when interacting with CAs, as previous research has rarely explored. It aims to understand how pre-existing gender biases might be triggered by CAs' gender designs. It further investigates how CAs' gender designs may reinforce gender
    
[^15]: AST-T5：面向代码生成和理解的结构感知预训练模型

    AST-T5: Structure-Aware Pretraining for Code Generation and Understanding. (arXiv:2401.03003v1 [cs.SE])

    [http://arxiv.org/abs/2401.03003](http://arxiv.org/abs/2401.03003)

    AST-T5是一种结构感知的预训练模型，通过利用抽象语法树（AST）来增强代码生成、转换和理解的能力。它优于其他同等大小的语言模型，并在代码到代码任务中表现出色。

    

    大型语言模型在代码相关任务中取得了显著进展，然而许多模型将代码视为简单序列，忽略了其结构化特性。我们引入了AST-T5，一种新颖的预训练范式，利用抽象语法树（AST）增强了代码生成、转换和理解。通过动态规划，我们的AST感知分割保留了代码结构，而AST感知跨度破坏目标使模型能够重建各种代码结构。与其他模型不同，AST-T5避免了复杂的程序分析或架构更改，因此可以与任何编码器-解码器Transformer无缝集成。评估结果显示，AST-T5在各种代码相关任务中始终优于同等大小的语言模型。结构感知使得AST-T5在代码到代码任务中特别强大，在Bugs2Fix任务的精确匹配得分上超过CodeT5 2个点，并在CodeXGLUE中的Java-C#转换任务的精确匹配得分上超过CodeT5 3个点。

    Large language models (LLMs) have made significant advancements in code-related tasks, yet many LLMs treat code as simple sequences, neglecting its structured nature. We introduce AST-T5, a novel pretraining paradigm that leverages the Abstract Syntax Tree (AST) for enhanced code generation, transpilation, and understanding. Using dynamic programming, our AST-Aware Segmentation retains code structure, while our AST-Aware Span Corruption objective equips the model to reconstruct various code structures. Unlike other models, AST-T5 avoids intricate program analyses or architectural changes, so it integrates seamlessly with any encoder-decoder Transformer. Evaluations show that AST-T5 consistently outperforms similar-sized LMs across various code-related tasks. Structure-awareness makes AST-T5 particularly powerful in code-to-code tasks, surpassing CodeT5 by 2 points in exact match score for the Bugs2Fix task and by 3 points in exact match score for Java-C# Transpilation in CodeXGLUE. Our
    
[^16]: Blar-SQL: 更快、更强、更小的NL2SQL

    Blar-SQL: Faster, Stronger, Smaller NL2SQL. (arXiv:2401.02997v1 [cs.CL])

    [http://arxiv.org/abs/2401.02997](http://arxiv.org/abs/2401.02997)

    该研究通过任务分解，提出了Blar-SQL框架，将两个不同的模型组合，分别专注于不同的任务，从而极大地提高了NL2SQL任务的准确性。该模型比GPT-4更小、更快、更便宜。

    

    大型语言模型（LLMs）在自然语言到SQL任务（NL2SQL）领域取得了可观的声誉。在本研究中，我们展示了如何通过任务分解来极大地改善LLMs在数据库理解和查询生成方面的能力，以便使用一个SQL查询来回答人类的问题。我们通过组合两个不同模型，分别专注于两个任务，对开源模型（特别是Llama-2和Code Llama）进行了精调，以利用每个模型的核心竞争力，进一步提高最终SQL查询的准确性。我们提出了一个新的框架来将模式划分为块，以将更多信息适应有限的上下文中。我们的结果与GPT-4获得的结果相当，同时比GPT-4更小135倍、更快90倍，并且比GPT-4便宜100倍以上。

    Large Language Models (LLMs) have gained considerable notoriety in the field of natural language to SQL tasks (NL2SQL). In this study, we show how task decomposition can greatly benefit LLMs in database understanding and query generation in order to answer human questions with an SQL query.  We fined-tuned open source models, specifically Llama-2 and Code Llama, by combining 2 different models each designated to focus on one of two tasks in order to leverage each model's core competency to further increase the accuracy of the final SQL query.  We propose a new framework to divide the schema into chunks in order to fit more information into a limited context. Our results are comparable with those obtained by GPT-4 at the same time being 135 times smaller, 90 times faster and more than 100 times cheaper than GPT-4.
    
[^17]: CANAMRF：一种基于注意力的多模态抑郁检测模型

    CANAMRF: An Attention-Based Model for Multimodal Depression Detection. (arXiv:2401.02995v1 [cs.CL])

    [http://arxiv.org/abs/2401.02995](http://arxiv.org/abs/2401.02995)

    CANAMRF 是一种基于注意力机制的多模态抑郁检测模型，通过考虑不同模态之间的相对重要性，有效地进行多模态表示，并在两个基准数据集上取得了最先进的性能。

    

    多模态抑郁检测是一个重要的研究课题，旨在利用多模态数据预测人类的心理状态。之前的方法平等对待不同的模态，并通过简单的数学运算融合每个模态，没有对它们之间的相对重要性进行衡量，这不能获得适用于下游抑郁任务的良好多模态表示。为了解决上述问题，我们提出了一种带有自适应多模态循环融合的跨模态注意力网络（CANAMRF）用于多模态抑郁检测。CANAMRF由多模态特征提取器、自适应多模态循环融合模块和混合注意力模块构成。通过在两个基准数据集上进行实验，CANAMRF展示出了最先进的性能，突显了我们提出方法的有效性。

    Multimodal depression detection is an important research topic that aims to predict human mental states using multimodal data. Previous methods treat different modalities equally and fuse each modality by na\"ive mathematical operations without measuring the relative importance between them, which cannot obtain well-performed multimodal representations for downstream depression tasks. In order to tackle the aforementioned concern, we present a Cross-modal Attention Network with Adaptive Multi-modal Recurrent Fusion (CANAMRF) for multimodal depression detection. CANAMRF is constructed by a multimodal feature extractor, an Adaptive Multimodal Recurrent Fusion module, and a Hybrid Attention Module. Through experimentation on two benchmark datasets, CANAMRF demonstrates state-of-the-art performance, underscoring the effectiveness of our proposed approach.
    
[^18]: 基于混合方法的聊天AI模型：相对于万亿级参数模型的更廉价、更好的替代方案

    Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM. (arXiv:2401.02994v1 [cs.CL])

    [http://arxiv.org/abs/2401.02994](http://arxiv.org/abs/2401.02994)

    本研究介绍了一种名为“混合”的方法，通过组合多个适度规模的聊天AI模型，可以达到或超越比它们更大的模型的性能表现。

    

    在会话型AI研究中，越来越多的模型采用了更多的参数，如ChatGPT等模型。虽然这些庞大的模型往往能生成更好的聊天回复，但它们需要大量的计算资源和内存。本研究探讨了一个重要问题：能否通过组合较小的模型来达到与单个大模型相当或更好的性能？我们提出了一种称为“混合”的方法，它是一种简单但有效的将多个聊天AI集成在一起的方法。我们的实证证据表明，当特定较小的模型协同混合时，它们可以潜在地超越或匹敌大型模型的性能。例如，仅集成三个适度规模的模型（6B/13B参数）就可以达到或甚至超越ChatGPT（175B+参数）等大型模型的性能指标。这个假设经过了严格的测试。

    In conversational AI research, there's a noticeable trend towards developing models with a larger number of parameters, exemplified by models like ChatGPT. While these expansive models tend to generate increasingly better chat responses, they demand significant computational resources and memory. This study explores a pertinent question: Can a combination of smaller models collaboratively achieve comparable or enhanced performance relative to a singular large model? We introduce an approach termed "blending", a straightforward yet effective method of integrating multiple chat AIs. Our empirical evidence suggests that when specific smaller models are synergistically blended, they can potentially outperform or match the capabilities of much larger counterparts. For instance, integrating just three models of moderate size (6B/13B paramaeters) can rival or even surpass the performance metrics of a substantially larger model like ChatGPT (175B+ paramaters). This hypothesis is rigorously tes
    
[^19]: 使用计算高效的检索表示融合提高自然语言理解能力

    Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion. (arXiv:2401.02993v1 [cs.CL])

    [http://arxiv.org/abs/2401.02993](http://arxiv.org/abs/2401.02993)

    本文提出了一种计算高效的检索表示融合方法ReFusion，通过将检索表示直接融合到语言模型中，解决了将外部数据库的知识融入非知识密集型任务中的挑战。

    

    从外部数据库中获取知识并融入语言模型的检索增强方法在各种知识密集型任务（例如问答和文本生成）中取得了巨大成功。然而，在非知识密集型任务（例如文本分类）中集成检索仍然具有挑战性。现有的研究集中在将检索内容拼接到输入中形成提示性的输入。然而，这种方法要求语言模型具备处理长文本的能力。此外，推断这种拼接数据也会消耗大量的计算资源。为了解决这些问题，本文提出了一种计算高效的检索表示融合方法ReFusion，采用神经架构搜索。主要思想是直接将检索表示与语言模型进行融合。具体地，我们首先提出了一种在线检索模块，重新检索...

    Retrieval-based augmentations that aim to incorporate knowledge from an external database into language models have achieved great success in various knowledge-intensive (KI) tasks, such as question-answering and text generation. However, integrating retrievals in non-knowledge-intensive (NKI) tasks, such as text classification, is still challenging. Existing works focus on concatenating retrievals to inputs as context to form the prompt-based inputs. Unfortunately, such methods require language models to have the capability to handle long texts. Besides, inferring such concatenated data would also consume a significant amount of computational resources.  To solve these challenges, we propose \textbf{ReFusion} in this paper, a computation-efficient \textbf{Re}trieval representation \textbf{Fusion} with neural architecture search. The main idea is to directly fuse the retrieval representations into the language models. Specifically, we first propose an online retrieval module that retri
    
[^20]: ESG报告的高级非结构化数据处理：结构化转换和增强分析的方法论

    Advanced Unstructured Data Processing for ESG Reports: A Methodology for Structured Transformation and Enhanced Analysis. (arXiv:2401.02992v1 [cs.CL])

    [http://arxiv.org/abs/2401.02992](http://arxiv.org/abs/2401.02992)

    本研究引入了一种创新的方法论，利用"非结构化核心库"，将ESG报告转换为结构化、可分析的格式，并在文本清洗、从图像中敏锐识别和提取文本以及标准化报告中的表格等方面取得了显著进展，为工业生态学和企业可持续性评估领域的发展奠定了基础。

    

    在企业可持续性发展领域，分析非结构化的环境、社会和治理（ESG）报告是一个复杂的挑战，因为它们具有各种格式和复杂的内容。本研究引入了一种创新的方法论，利用"非结构化核心库"，专门针对这些挑战将ESG报告转换为结构化、可分析的格式。我们的方法在文本清洗、从图像中敏锐地识别和提取文本以及标准化这些报告中的表格等方面显著推进了现有研究。强调其处理不同行业的不同页面布局和报告样式方面的能力，该方法熟练地管理各种数据类型，包括文本、图像和表格。这项研究对于工业生态学和企业可持续性评估领域具有重大意义，为应用先进的自然语言处理技术奠定了基础。

    In the evolving field of corporate sustainability, analyzing unstructured Environmental, Social, and Governance (ESG) reports is a complex challenge due to their varied formats and intricate content. This study introduces an innovative methodology utilizing the "Unstructured Core Library", specifically tailored to address these challenges by transforming ESG reports into structured, analyzable formats. Our approach significantly advances the existing research by offering high-precision text cleaning, adept identification and extraction of text from images, and standardization of tables within these reports. Emphasizing its capability to handle diverse data types, including text, images, and tables, the method adeptly manages the nuances of differing page layouts and report styles across industries. This research marks a substantial contribution to the fields of industrial ecology and corporate sustainability assessment, paving the way for the application of advanced NLP technologies an
    
[^21]: GLIDE-RL：基于演示的强化学习中的自然语言指导

    GLIDE-RL: Grounded Language Instruction through DEmonstration in RL. (arXiv:2401.02991v1 [cs.CL])

    [http://arxiv.org/abs/2401.02991](http://arxiv.org/abs/2401.02991)

    GLIDE-RL是一种基于演示的强化学习算法，通过引入教师-指导员-学生的课程学习框架，训练出了一个能够遵循自然语言指令并且可以推广到未见指令的RL代理。

    

    复杂的人工智能与人类协作系统的最后一项挑战是AI代理能够理解自然语言并相应地执行任务。然而，由于语言的复杂性和歧义性以及奖励的稀疏性等因素，训练有效的基于自然语言的强化学习（RL）代理一直是一个长期的挑战。强化学习、课程学习、持续学习和语言模型的几项进展分别为在不同环境中训练基于自然语言的代理做出了有效贡献。在这些发展的基础上，我们提出了一种新算法GLIDE-RL，通过引入教师-指导员-学生的课程学习框架来培训一个能够遵循自然语言指令，并且能够推广到之前未见的语言指令的RL代理。

    One of the final frontiers in the development of complex human - AI collaborative systems is the ability of AI agents to comprehend the natural language and perform tasks accordingly. However, training efficient Reinforcement Learning (RL) agents grounded in natural language has been a long-standing challenge due to the complexity and ambiguity of the language and sparsity of the rewards, among other factors. Several advances in reinforcement learning, curriculum learning, continual learning, language models have independently contributed to effective training of grounded agents in various environments. Leveraging these developments, we present a novel algorithm, Grounded Language Instruction through DEmonstration in RL (GLIDE-RL) that introduces a teacher-instructor-student curriculum learning framework for training an RL agent capable of following natural language instructions that can generalize to previously unseen language instructions. In this multi-agent framework, the teacher a
    
[^22]: 采用潜在狄利克雷分配（LDA）语义文本分析方法探索慈善众筹活动的主题特征

    A Latent Dirichlet Allocation (LDA) Semantic Text Analytics Approach to Explore Topical Features in Charity Crowdfunding Campaigns. (arXiv:2401.02988v1 [cs.CL])

    [http://arxiv.org/abs/2401.02988](http://arxiv.org/abs/2401.02988)

    本文提出了一种创新的文本分析框架，利用潜在狄利克雷分配（LDA）从慈善众筹活动的文本描述中提取潜在主题特征。

    

    社交网络中的众筹活动引起了广泛的关注，先前的研究关注了众筹活动的各个方面，包括项目目标、持续时间以及成功筹款的有影响力的项目类别。这些因素对于寻求捐赠者支持的企业家来说至关重要。然而，在社交网络中的慈善众筹领域仍然相对未开发，缺乏对驱动捐赠的动机的理解，这些捐赠通常缺乏具体的回报。与提供具体回报的传统众筹不同，慈善众筹依赖于无形的回报，如税收优惠、认可帖子或咨询角色。这些细节通常嵌入在众筹活动的叙述中，但对慈善众筹中文本内容的分析是有限的。本研究引入了一种创新的文本分析框架，利用潜在狄利克雷分配（LDA）从慈善活动的文本描述中提取潜在主题。

    Crowdfunding in the realm of the Social Web has received substantial attention, with prior research examining various aspects of campaigns, including project objectives, durations, and influential project categories for successful fundraising. These factors are crucial for entrepreneurs seeking donor support. However, the terrain of charity crowdfunding within the Social Web remains relatively unexplored, lacking comprehension of the motivations driving donations that often lack concrete reciprocation. Distinct from conventional crowdfunding that offers tangible returns, charity crowdfunding relies on intangible rewards like tax advantages, recognition posts, or advisory roles. Such details are often embedded within campaign narratives, yet, the analysis of textual content in charity crowdfunding is limited. This study introduces an inventive text analytics framework, utilizing Latent Dirichlet Allocation (LDA) to extract latent themes from textual descriptions of charity campaigns. Th
    
[^23]: 你的预训练模型有改进吗？一种基于多头后验的方法

    Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach. (arXiv:2401.02987v1 [cs.CL])

    [http://arxiv.org/abs/2401.02987](http://arxiv.org/abs/2401.02987)

    本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。

    

    预训练模型的出现对自然语言处理（NLP）、计算机视觉和关系型数据集等领域产生了显著影响。传统上，这些模型通过下游任务进行评估。然而，这引发了如何更高效、更有效地评估这些模型的问题。在本研究中，我们探索了一种新颖的方法，即利用与每个实体相关的元特征作为世界知识的来源，并利用模型的实体表示。我们提出使用这些表示和元特征之间的一致性作为评估预训练模型的度量标准。我们的方法在各个领域表现出了有效性，包括具有关系型数据集、大型语言模型和图像模型的模型。

    The emergence of pretrained models has significantly impacted from Natural Language Processing (NLP) and Computer Vision to relational datasets. Traditionally, these models are assessed through fine-tuned downstream tasks. However, this raises the question of how to evaluate these models more efficiently and more effectively. In this study, we explore a novel approach where we leverage the meta features associated with each entity as a source of worldly knowledge and employ entity representations from the models. We propose using the consistency between these representations and the meta features as a metric for evaluating pretrained models. Our method's effectiveness is demonstrated across various domains, including models with relational datasets, large language models and images models.
    
[^24]: 识别与业务流程相关的监管要求：一项关于生成AI、基于嵌入的排序、众包和专家驱动方法的比较研究

    Identification of Regulatory Requirements Relevant to Business Processes: A Comparative Study on Generative AI, Embedding-based Ranking, Crowd and Expert-driven Methods. (arXiv:2401.02986v1 [cs.CL])

    [http://arxiv.org/abs/2401.02986](http://arxiv.org/abs/2401.02986)

    本研究比较了基于嵌入的自然语言处理排序方法，生成AI模型以及众包和专家驱动方法，旨在研究如何辅助法律和领域专家识别与业务流程相关的监管要求。

    

    组织面临着确保遵守各种监管文件中越来越多要求的挑战。哪些要求是相关的取决于如组织的地理位置、领域、规模和业务流程等方面的因素。考虑到这些情境因素，首先需要识别相关文件（例如法律、规则、指令、政策），然后详细分析识别文件的哪些部分与给定业务流程的哪个步骤相关。目前，识别与业务流程相关的监管要求主要由领域和法律专家手动完成，对他们来说是一项巨大的工作量，特别是对于可能经常变化的大量监管文件。因此，本研究探讨了如何辅助法律和领域专家评估相关要求。为此，我们比较了基于嵌入的自然语言处理排序方法，生成AI模型及众包和专家驱动方法。

    Organizations face the challenge of ensuring compliance with an increasing amount of requirements from various regulatory documents. Which requirements are relevant depends on aspects such as the geographic location of the organization, its domain, size, and business processes. Considering these contextual factors, as a first step, relevant documents (e.g., laws, regulations, directives, policies) are identified, followed by a more detailed analysis of which parts of the identified documents are relevant for which step of a given business process. Nowadays the identification of regulatory requirements relevant to business processes is mostly done manually by domain and legal experts, posing a tremendous effort on them, especially for a large number of regulatory documents which might frequently change. Hence, this work examines how legal and domain experts can be assisted in the assessment of relevant requirements. For this, we compare an embedding-based NLP ranking method, a generativ
    
[^25]: 在GMAT上评估大型语言模型：对未来商业教育的影响

    Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education. (arXiv:2401.02985v1 [cs.CL])

    [http://arxiv.org/abs/2401.02985](http://arxiv.org/abs/2401.02985)

    本研究评估了七个主要的大型语言模型在GMAT考试上的表现，并发现大多数模型优于人类考生，其中GPT-4 Turbo不仅在其他模型之上，而且超过了顶级商学院研究生的平均分数。此外，通过案例研究，本研究还考察了GPT-4 Turbo在解释答案、评估回答、识别错误、调整指导和生成替代场景方面的能力。

    

    人工智能尤其是大型语言模型和生成式人工智能的迅速发展，为在各个领域中的应用开辟了新的途径，然而其在商业教育中的作用仍未得到充分探索。本研究引入了首个基准来评估七个重要的大型语言模型，包括OpenAI的模型（GPT-3.5 Turbo、GPT-4和GPT-4 Turbo）、Google的模型（PaLM 2、Gemini 1.0 Pro）和Anthropic的模型（Claude 2和Claude 2.1），在GMAT考试上的表现。我们的分析显示，大多数语言模型优于人类考生，其中GPT-4 Turbo不仅在其他模型之上，而且超过了顶级商学院研究生的平均分数。通过一个案例研究，本研究考察了GPT-4 Turbo在解释答案、评估回答、识别错误、调整指导和生成替代场景方面的能力。

    The rapid evolution of artificial intelligence (AI), especially in the domain of Large Language Models (LLMs) and generative AI, has opened new avenues for application across various fields, yet its role in business education remains underexplored. This study introduces the first benchmark to assess the performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models (Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission process for graduate business programs. Our analysis shows that most LLMs outperform human candidates, with GPT-4 Turbo not only outperforming the other models but also surpassing the average scores of graduate students at top business schools. Through a case study, this research examines GPT-4 Turbo's ability to explain answers, evaluate responses, identify errors, tailor instructions, and generate alternative scenarios. The latest LLM versions, GPT-4 Turbo,
    
[^26]: 大型语言模型在心理健康护理中的应用：一项综述研究

    Large Language Models in Mental Health Care: a Scoping Review. (arXiv:2401.02984v1 [cs.CL])

    [http://arxiv.org/abs/2401.02984](http://arxiv.org/abs/2401.02984)

    本综述研究对大型语言模型在心理健康护理中的应用和结果进行了综合分析，发现其在诊断、治疗和患者参与增强等方面具有多样化的应用。同时，该研究还识别和讨论了在这些专业领域中所面临的挑战和限制。

    

    目的：大型语言模型（LLM）的使用越来越广泛，需要对它们在心理健康护理领域的应用和结果进行全面的综述。本综述研究旨在对LLMs在心理健康护理中的现有发展和应用进行批判性分析，突出它们的成功，并识别这些专业领域中的挑战和限制。材料和方法：2023年11月，在PubMed、Web of Science、Google Scholar、arXiv、medRxiv和PsyArXiv六个数据库中进行了广泛的文献搜索，遵循2020年版的“系统评价和Meta分析的首选报告项目”（PRISMA）指南。最初识别了313篇出版物，按照研究纳入标准，最终选择了34篇出版物进行综述。结果：我们发现了LLMs在心理健康护理中的多种应用，包括诊断、治疗、患者参与增强等。关键挑战和限制方面的发现将被总结和讨论。

    Objective: The growing use of large language models (LLMs) stimulates a need for a comprehensive review of their applications and outcomes in mental health care contexts. This scoping review aims to critically analyze the existing development and applications of LLMs in mental health care, highlighting their successes and identifying their challenges and limitations in these specialized fields. Materials and Methods: A broad literature search was conducted in November 2023 using six databases (PubMed, Web of Science, Google Scholar, arXiv, medRxiv, and PsyArXiv) following the 2020 version of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A total of 313 publications were initially identified, and after applying the study inclusion criteria, 34 publications were selected for the final review. Results: We identified diverse applications of LLMs in mental health care, including diagnosis, therapy, patient engagement enhancement, etc. Key challen
    
[^27]: BIBench: 大型语言模型数据分析知识基准测试

    BIBench: Benchmarking Data Analysis Knowledge of Large Language Models. (arXiv:2401.02982v1 [cs.CL])

    [http://arxiv.org/abs/2401.02982](http://arxiv.org/abs/2401.02982)

    BIBench是一个旨在评估大型语言模型（LLMs）在商业智能（BI）数据分析领域中能力的综合基准测试，其通过测试模型在BI基础知识、应用知识和技术技能三个维度上的表现来进行评估。

    

    大型语言模型（LLMs）在各种任务中展示了令人印象深刻的能力。然而，它们在数据分析的专业领域中的熟练度和可靠性，特别是在以数据驱动思维为重点的领域中，仍然存在不确定性。为了填补这一差距，我们介绍了BIBench，这是一个全面的基准测试，旨在评估LLMs在商业智能（BI）的背景下的数据分析能力。BIBench通过三个维度评估LLMs：1）BI基础知识，评估模型的数值推理能力和对金融概念的熟悉程度；2）BI知识应用，确定模型快速理解文本信息并从多个视角生成分析问题的能力；3）BI技术技能，检查模型使用技术知识解决现实数据分析挑战的能力。BIBench包括11个子任务，涵盖分类、提取和生成三种任务类型。

    Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. However, their proficiency and reliability in the specialized domain of Data Analysis, particularly with a focus on data-driven thinking, remain uncertain. To bridge this gap, we introduce BIBench, a comprehensive benchmark designed to evaluate the data analysis capabilities of LLMs within the context of Business Intelligence (BI). BIBench assesses LLMs across three dimensions: 1) BI foundational knowledge, evaluating the models' numerical reasoning and familiarity with financial concepts; 2) BI knowledge application, determining the models' ability to quickly comprehend textual information and generate analysis questions from multiple views; and 3) BI technical skills, examining the models' use of technical knowledge to address real-world data analysis challenges. BIBench comprises 11 sub-tasks, spanning three categories of task types: classification, extraction, and generation. Additi
    
[^28]: 领域特定LLM的微调和利用方法

    Fine-tuning and Utilization Methods of Domain-specific LLMs. (arXiv:2401.02981v1 [cs.CL])

    [http://arxiv.org/abs/2401.02981](http://arxiv.org/abs/2401.02981)

    本研究调查了领域特定LLM的微调和利用方法，以金融领域为例，详细介绍了数据集选择、预处理、模型选择以及在金融领域LLM微调中的关键因素。研究探讨了领域特定词汇的构建和安全合规性的考虑因素，并提供了在金融领域生成领域特定LLM的过程和实施方法。多种金融案例被涵盖在内，包括股票价格预测、金融新闻情绪分析、自动文档处理、研究和信息提取等。

    

    最近发布的预训练的大型语言模型（LLM）引起了相当大的关注，但关于领域特定LLM的微调和应用的研究仍然很少。本研究调查了领域特定LLM的微调和利用方法，重点关注LLM的趋势、基础模型和用于领域特定预训练的方法。以金融行业为例，详细介绍了数据集选择、预处理、模型选择以及在金融领域LLM微调中关键的考虑因素。针对金融数据的独特特点，本研究探讨了领域特定词汇的构建，以及安全性和合规性的考虑因素。在LLM微调的实际应用中，本研究概述了在金融领域生成领域特定LLM的过程和实施方法。包括股票价格预测、金融新闻情绪分析、自动文档处理、研究和信息提取等多种金融案例被涵盖在内。

    Recent releases of pre-trained Large Language Models (LLMs) have gained considerable traction, yet research on fine-tuning and employing domain-specific LLMs remains scarce. This study investigates approaches for fine-tuning and leveraging domain-specific LLMs, highlighting trends in LLMs, foundational models, and methods for domain-specific pre-training. Focusing on the financial sector, it details dataset selection, preprocessing, model choice, and considerations crucial for LLM fine-tuning in finance. Addressing the unique characteristics of financial data, the study explores the construction of domain-specific vocabularies and considerations for security and regulatory compliance. In the practical application of LLM fine-tuning, the study outlines the procedure and implementation for generating domain-specific LLMs in finance. Various financial cases, including stock price prediction, sentiment analysis of financial news, automated document processing, research, information extract
    
[^29]: 我们在描述同样的声音吗？对表现力钢琴演奏词嵌入空间的分析

    Are we describing the same sound? An analysis of word embedding spaces of expressive piano performance. (arXiv:2401.02979v1 [cs.CL])

    [http://arxiv.org/abs/2401.02979](http://arxiv.org/abs/2401.02979)

    本文探讨了对表现力钢琴演奏特征的不确定性，测试了五个嵌入模型及其相似性结构与真值的对应关系，并进行了进一步评估。嵌入模型的质量在这方面显示出很大的差异性。

    

    语义嵌入在基于自然语言的信息检索中起到至关重要的作用。嵌入模型将单词和上下文表示为向量，其空间配置是根据大型文本语料库中单词的分布导出的。尽管这些表示一般非常强大，但它们可能未能考虑到细粒度的领域特定细微差别。在本文中，我们探讨了这种对表现力钢琴演奏特征的不确定性。我们使用一个音乐研究数据集，其中包含自由文本演奏特征的注释，并进行了一个后续研究，将注释分类成不同的聚类。我们得出了一个特定领域语义相似性结构的真值。我们测试了五个嵌入模型及其相似性结构与真值的对应关系。我们进一步评估了上下文提示、中心度降低、跨模态相似性和k-means聚类的影响。嵌入模型的质量在这方面显示出很大的差异性。

    Semantic embeddings play a crucial role in natural language-based information retrieval. Embedding models represent words and contexts as vectors whose spatial configuration is derived from the distribution of words in large text corpora. While such representations are generally very powerful, they might fail to account for fine-grained domain-specific nuances. In this article, we investigate this uncertainty for the domain of characterizations of expressive piano performance. Using a music research dataset of free text performance characterizations and a follow-up study sorting the annotations into clusters, we derive a ground truth for a domain-specific semantic similarity structure. We test five embedding models and their similarity structure for correspondence with the ground truth. We further assess the effects of contextualizing prompts, hubness reduction, cross-modal similarity, and k-means clustering. The quality of embedding models shows great variability with respect to this 
    
[^30]: 从生成式AI前辈中学习——与对话代理互动的许多动机

    Learning from a Generative AI Predecessor -- The Many Motivations for Interacting with Conversational Agents. (arXiv:2401.02978v1 [cs.CL])

    [http://arxiv.org/abs/2401.02978](http://arxiv.org/abs/2401.02978)

    这项研究通过分析与虚拟伙伴Zo互动的动机，总结出了多种增加互动性的方法，为生成式AI的发展提供了借鉴。

    

    要使生成式AI成功，它必须具备多么引人入胜的对话能力？近60年来，一些对话代理会回应任何问题或评论以保持对话的进行。近年来，许多人开始利用机器学习或复杂的语言处理技术，例如Tay、Xiaoice、Zo、Hugging Face、Kuki和Replika。与生成式AI不同的是，它们关注的是互动性，而不是专业知识。数百万人被激发起与它们进行互动。那么这些吸引力是什么呢？如果生成式AI同样引人入胜，它会做得更好吗，还是应该减少互动性？在生成式AI出现之前，我们进行了大规模定量和定性分析，以了解数百万人与微软伙伴Zo进行互动的动机。我们研究了2000个匿名用户的完整聊天记录，并确定了数十种人们与该软件进行互动的动机。设计师们学会了不同的方法来提高互动性。

    For generative AI to succeed, how engaging a conversationalist must it be? For almost sixty years, some conversational agents have responded to any question or comment to keep a conversation going. In recent years, several utilized machine learning or sophisticated language processing, such as Tay, Xiaoice, Zo, Hugging Face, Kuki, and Replika. Unlike generative AI, they focused on engagement, not expertise. Millions of people were motivated to engage with them. What were the attractions? Will generative AI do better if it is equally engaging, or should it be less engaging? Prior to the emergence of generative AI, we conducted a large-scale quantitative and qualitative analysis to learn what motivated millions of people to engage with one such 'virtual companion,' Microsoft's Zo. We examined the complete chat logs of 2000 anonymized people. We identified over a dozen motivations that people had for interacting with this software. Designers learned different ways to increase engagement. 
    
[^31]: 在GPT模型中追踪和编辑关系关联

    Trace and Edit Relation Associations in GPT. (arXiv:2401.02976v1 [cs.CL])

    [http://arxiv.org/abs/2401.02976](http://arxiv.org/abs/2401.02976)

    本研究介绍了一种在GPT模型中分析和修改实体关系的新方法，通过关系追踪技术，我们识别了MLP模块和注意机制在处理关系信息方面的关键作用，实验表明该方法在特异性和泛化性方面取得了平衡的改善。

    

    本研究介绍了一种新颖的方法，用于分析和修改GPT模型中的实体关系，与ROME的基于实体的方法不同。我们开发了一种关系追踪技术，以了解语言模型计算对关系判断的影响。使用FewRel数据集，我们识别了MLP模块和注意机制在处理关系信息方面的关键作用。我们的方法在一个新的数据集上与ROME进行了测试，显示出在特异性和泛化性方面的平衡改善，突显了操纵早期层模块以提高模型理解和准确性的潜力。

    This study introduces a novel approach for analyzing and modifying entity relationships in GPT models, diverging from ROME's entity-focused methods. We develop a relation tracing technique to understand the influence of language model computations on relationship judgments. Using the FewRel dataset, we identify key roles of MLP modules and attention mechanisms in processing relationship information. Our method, tested against ROME on a new dataset, shows improved balance in specificity and generalization, underscoring the potential of manipulating early-layer modules for enhanced model understanding and accuracy.
    
[^32]: 揭示医疗产品法规事务的复杂性：利用开放编码和自然语言处理的定性评估

    Uncovering Regulatory Affairs Complexity in Medical Products: A Qualitative Assessment Utilizing Open Coding and Natural Language Processing (NLP). (arXiv:2401.02975v1 [cs.CY])

    [http://arxiv.org/abs/2401.02975](http://arxiv.org/abs/2401.02975)

    本研究揭示了医疗器械行业法规事务的复杂性，并提供了法规语言、流程、全球层面、数据库和产品层面等五个领域的关键复杂性来源。研究结果强调了需要简化法规合规、改善法规机构与行业参与者之间的互动以及制定适应性框架的重要性。

    

    本研究调查了医疗器械行业法规事务的复杂性，这是影响市场准入和患者护理的关键因素。通过定性研究，我们寻求专家洞察力，以了解导致这种复杂性的因素。该研究涉及对28位医疗器械公司专业人士进行的半结构化访谈，这些专业人士专注于法规事务的各个方面。通过采用开放编码和自然语言处理（NLP）技术对这些访谈进行了分析。研究结果揭示了法规环境中的关键复杂性来源，分为五个领域：（A）法规语言复杂性，（B）法规流程的复杂性，（C）全球层面的复杂性，（D）与数据库相关的考虑事项，和（E）产品层面问题。参与者强调了需要制定策略来简化法规合规，提高法规机构与行业参与者之间的互动，并开发适应性框架的重要性。

    This study investigates the complexity of regulatory affairs in the medical device industry, a critical factor influencing market access and patient care. Through qualitative research, we sought expert insights to understand the factors contributing to this complexity. The study involved semi-structured interviews with 28 professionals from medical device companies, specializing in various aspects of regulatory affairs. These interviews were analyzed using open coding and Natural Language Processing (NLP) techniques. The findings reveal key sources of complexity within the regulatory landscape, divided into five domains: (A) Regulatory language complexity, (B) Intricacies within the regulatory process, (C) Global-level complexities, (D) Database-related considerations, and (E) Product-level issues. The participants highlighted the need for strategies to streamline regulatory compliance, enhance interactions between regulatory bodies and industry players, and develop adaptable framework
    
[^33]: 利用大型语言模型检测在线公开威胁的效力

    Efficacy of Utilizing Large Language Models to Detect Public Threat Posted Online. (arXiv:2401.02974v1 [cs.CL])

    [http://arxiv.org/abs/2401.02974](http://arxiv.org/abs/2401.02974)

    本文研究了利用大型语言模型(LLMs)检测在线公开威胁的效力。通过实验发现，不同的LLMs在威胁和非威胁识别方面表现出较高的准确性，其中GPT-4的表现最佳。研究还发现PaLM API的定价非常具有成本效益。研究结果表明，LLMs可以有效地增强人工内容审查，帮助减轻新兴的在线风险。

    

    本文研究了利用大型语言模型(LLMs)检测在线公开威胁的效力。在对威胁 retoric 的传播和暴力预告的增长越来越担忧的背景下，自动内容分析技术可以帮助早期发现和处理。我们开发了自定义的数据收集工具，从一个热门的韩国在线社区收集了500个非威胁示例和20个威胁示例的帖子标题。各种LLMs (GPT-3.5, GPT-4, PaLM) 被提示将单个帖子分类为"威胁"或"安全"。统计分析发现所有模型在威胁和非威胁识别方面表现出较高的准确性，通过卡方拟合度检验也得到了验证。GPT-4 的整体表现最好，非威胁精度达到了97.9%，威胁精度达到了100%。可行性分析还显示PaLM API的定价非常具有成本效益。研究结果显示，LLMs 在规模化环境中可以有效地增强人工内容审查，以帮助减轻新兴的在线风险。

    This paper examines the efficacy of utilizing large language models (LLMs) to detect public threats posted online. Amid rising concerns over the spread of threatening rhetoric and advance notices of violence, automated content analysis techniques may aid in early identification and moderation. Custom data collection tools were developed to amass post titles from a popular Korean online community, comprising 500 non-threat examples and 20 threats. Various LLMs (GPT-3.5, GPT-4, PaLM) were prompted to classify individual posts as either "threat" or "safe." Statistical analysis found all models demonstrated strong accuracy, passing chi-square goodness of fit tests for both threat and non-threat identification. GPT-4 performed best overall with 97.9% non-threat and 100% threat accuracy. Affordability analysis also showed PaLM API pricing as highly cost-efficient. The findings indicate LLMs can effectively augment human content moderation at scale to help mitigate emerging online risks. Howe
    
[^34]: REE-HDSC: 识别历史数据库Suriname Curacao中提取的实体

    REE-HDSC: Recognizing Extracted Entities for the Historical Database Suriname Curacao. (arXiv:2401.02972v1 [cs.CL])

    [http://arxiv.org/abs/2401.02972](http://arxiv.org/abs/2401.02972)

    本文介绍了REE-HDSC项目，旨在改进手写文本识别软件自动提取的命名实体的质量。通过六步处理流程，我们测试了该流程在处理库拉索民事登记处的19世纪和20世纪死亡证书时，日期提取具有高精度，人名提取的精度较低。我们提出了通过重新训练HTR模型、后处理和识别删除不正确的名字来提高人名提取精度的方法。

    

    我们描述了REE-HDSC项目，并概述了我们努力提高手写文本识别（HTR）软件生成的文本自动提取的命名实体质量的工作。我们描述了一个六步处理流程，并通过处理库拉索民事登记处的19世纪和20世纪死亡证书进行测试。我们发现该流水线提取的日期具有高精度，但人名提取的精度较低。接下来，我们展示了如何通过重新训练含有名字的HTR模型、后处理以及识别和删除不正确的名字来改善名字提取的精度。

    We describe the project REE-HDSC and outline our efforts to improve the quality of named entities extracted automatically from texts generated by hand-written text recognition (HTR) software. We describe a six-step processing pipeline and test it by processing 19th and 20th century death certificates from the civil registry of Curacao. We find that the pipeline extracts dates with high precision but that the precision of person name extraction is low. Next we show how name precision extraction can be improved by retraining HTR models with names, post-processing and by identifying and removing incorrect names.
    
[^35]: 文本中的深度异常检测

    Deep Anomaly Detection in Text. (arXiv:2401.02971v1 [cs.CL])

    [http://arxiv.org/abs/2401.02971](http://arxiv.org/abs/2401.02971)

    本研究旨在开发一种基于自我监督学习的方法，用于文本中的异常检测，通过利用预处理任务来提高最新技术，并在半监督和无监督的情况下对两个数据集进行了显著改进。

    

    近年来，深度异常检测方法变得越来越受欢迎，诸如堆叠自动编码器、变分自动编码器和生成对抗网络等方法大大改进了最新技术。其他方法通过使用神经网络学习适当的核函数来增强经典模型（如单类支持向量机）。自我监督学习在异常检测领域中的代表线学习方面的最新发展证明在这一背景下非常有益。受计算机视觉领域中使用自我监督学习进行异常检测的进展启发，本论文旨在通过利用为文本语料库量身定制的预处理任务来开发一种检测异常的方法。这种方法在20Newsgroups和AG News两个数据集上大大改进了半监督和无监督的异常检测最新技术，从而证明了自我监督异常检测器在自然领域的潜力。

    Deep anomaly detection methods have become increasingly popular in recent years, with methods like Stacked Autoencoders, Variational Autoencoders, and Generative Adversarial Networks greatly improving the state-of-the-art. Other methods rely on augmenting classical models (such as the One-Class Support Vector Machine), by learning an appropriate kernel function using Neural Networks. Recent developments in representation learning by self-supervision are proving to be very beneficial in the context of anomaly detection. Inspired by the advancements in anomaly detection using self-supervised learning in the field of computer vision, this thesis aims to develop a method for detecting anomalies by exploiting pretext tasks tailored for text corpora. This approach greatly improves the state-of-the-art on two datasets, 20Newsgroups, and AG News, for both semi-supervised and unsupervised anomaly detection, thus proving the potential for self-supervised anomaly detectors in the field of natural
    
[^36]: 知识图谱的规则引导联合嵌入学习

    Rule-Guided Joint Embedding Learning of Knowledge Graphs. (arXiv:2401.02968v1 [cs.CL])

    [http://arxiv.org/abs/2401.02968](http://arxiv.org/abs/2401.02968)

    本文介绍了一种新型模型，该模型将上下文和字面信息容纳到实体和关系的嵌入中，利用图卷积网络，并通过规则和字面信息的表示计算置信度和相关性指标，以提高知识图谱嵌入学习的效果。

    

    在最近的研究中，关注点主要集中在增强知识图谱嵌入学习上，该学习将知识图谱中的实体和关系编码为低维向量空间。尽管当前模型主要考虑这些图谱的结构方面，但在知识图谱中存在着丰富的上下文和字面信息，可以用于更有效的嵌入学习。本文引入了一种新型模型，该模型将上下文和字面信息容纳到实体和关系的嵌入中，利用图卷积网络。具体地，对于上下文信息，我们通过置信度和相关性指标评估其重要性。我们开发了一种独特的基于规则的方法来计算置信度指标，并从字面信息的表示中得出相关性指标。我们通过对两个已建立的基准数据集进行详尽的实验证实了我们模型的性能。

    In recent studies, the focus has been on enhancing knowledge graph embedding learning, which encodes entities and relations in knowledge graphs into low-dimensional vector spaces. While current models mainly consider the structural aspects of these graphs, there's a wealth of contextual and literal information in knowledge graphs that can be utilized for more effective embeddings. This paper introduces a novel model that incorporates both contextual and literal information into entity and relation embeddings, utilizing graph convolutional networks. Specifically, for contextual information, we assess its significance through confidence and relatedness metrics. A unique rule-based method is developed to calculate the confidence metric, and the relatedness metric is derived from the literal information's representations. We validated our model's performance with thorough experiments on two established benchmark datasets.
    
[^37]: 理解LLMs：从训练到推理的全面概述

    Understanding LLMs: A Comprehensive Overview from Training to Inference. (arXiv:2401.02038v1 [cs.CL])

    [http://arxiv.org/abs/2401.02038](http://arxiv.org/abs/2401.02038)

    本文提供了一份综合概述，介绍了大规模语言模型（LLMs）从训练到推理的演变过程，并探讨了这一新兴趋势中与成本效率相关的训练和部署方法。同时，还讨论了推理阶段的模型压缩、并行计算、内存调度和结构优化等关键主题，为LLMs的利用和未来发展提供了见解。

    

    ChatGPT的引入导致了大规模语言模型（LLMs）在解决下游任务中的大量使用。在这个背景下，对于成本效率的关注越来越多。低成本的LLMs训练和部署代表了未来的发展趋势。本文回顾了与这一新兴趋势相一致的大规模语言模型训练技术和推理部署技术的演变。训练的讨论包括数据预处理、训练架构、预训练任务、并行训练以及与模型微调相关的内容。在推理方面，本文涵盖了模型压缩、并行计算、内存调度和结构优化等主题。它还探讨了LLMs的利用并提供了对其未来发展的见解。

    The introduction of ChatGPT has led to a significant increase in the utilization of Large Language Models (LLMs) for addressing downstream tasks. There's an increasing focus on cost-efficient training and deployment within this context. Low-cost training and deployment of LLMs represent the future development trend. This paper reviews the evolution of large language model training techniques and inference deployment technologies aligned with this emerging trend. The discussion on training includes various aspects, including data preprocessing, training architecture, pre-training tasks, parallel training, and relevant content related to model fine-tuning. On the inference side, the paper covers topics such as model compression, parallel computation, memory scheduling, and structural optimization. It also explores LLMs' utilization and provides insights into their future development.
    
[^38]: 通用嵌入模型在短语境临床语义搜索方面表现比专业嵌入模型更好

    Generalist embedding models are better at short-context clinical semantic search than specialized embedding models. (arXiv:2401.01943v1 [cs.CL])

    [http://arxiv.org/abs/2401.01943](http://arxiv.org/abs/2401.01943)

    本研究发现，在临床语义搜索方面，通用嵌入模型比专业嵌入模型表现更好，这表明现有的临床专业化模型对输入的微小变化更敏感。

    

    基于大型语言模型（LLM）的工具和解决方案在医疗领域的应用日益增多，这已成为一个重要趋势。然而，在这个高度关键和敏感的领域中使用它们对其稳健性产生了重要的问题，特别是对输入变化和生成的输出的可靠性。本研究通过构建基于ICD-10-CM代码描述的文本数据集来解决这些问题，该数据集广泛应用于美国医院，包含许多临床术语及其易于复制的改写。然后，我们在语义搜索任务中对现有的通用或临床专业化的嵌入模型进行了基准测试，目标是正确匹配改写的文本与原始描述。我们的结果表明，通用模型比临床模型表现更好，这表明现有的临床专业化模型对输入的微小变化更敏感，从而使其困惑。

    The increasing use of tools and solutions based on Large Language Models (LLMs) for various tasks in the medical domain has become a prominent trend. Their use in this highly critical and sensitive domain has thus raised important questions about their robustness, especially in response to variations in input, and the reliability of the generated outputs. This study addresses these questions by constructing a textual dataset based on the ICD-10-CM code descriptions, widely used in US hospitals and containing many clinical terms, and their easily reproducible rephrasing. We then benchmarked existing embedding models, either generalist or specialized in the clinical domain, in a semantic search task where the goal was to correctly match the rephrased text to the original description. Our results showed that generalist models performed better than clinical models, suggesting that existing clinical specialized models are more sensitive to small changes in input that confuse them. The highl
    
[^39]: GOAT-Bench: 通过基于迷因的社交虐待研究对大型多模态模型的安全洞察

    GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse. (arXiv:2401.01523v1 [cs.CL])

    [http://arxiv.org/abs/2401.01523](http://arxiv.org/abs/2401.01523)

    通过基于迷因的社交虐待研究对大型多模态模型的安全洞察，我们引入了综合的迷因基准测试集GOAT-Bench，评估各种LMMs在识别和回应迷因中体现的微妙社交虐待方面的能力。

    

    社交媒体的指数级增长深刻改变了信息的创造、传播和吸收方式，在数字时代产生了前所未有的影响。遗憾的是，这个爆炸也导致了网络迷因的滥用数量显著增加。评估迷因的负面影响是相当具有挑战性的，因为它们通常具有微妙和隐晦的含义，这些含义不能直接通过显性的文本和图像传达出来。鉴于此，大型多模态模型(LMMs)作为处理多样化多模态任务的卓越能力的焦点引起了人们的兴趣。针对这一发展，我们的论文旨在深入研究各种LMMs(如GPT-4V)识别和回应迷因中体现的微妙社交虐待方面的能力。我们引入了综合的迷因基准测试集GOAT-Bench，其中包含超过6K个多样的迷因，涵盖的主题包括隐性仇恨言论、性别歧视和网络欺凌等。利用GOAT-Be

    The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Be
    
[^40]: 大型语言模型中幻觉缓解技术的综述

    A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models. (arXiv:2401.01313v1 [cs.CL])

    [http://arxiv.org/abs/2401.01313](http://arxiv.org/abs/2401.01313)

    大型语言模型在生成文本时容易出现幻觉，这是安全部署这些模型的最大障碍。解决幻觉问题对于在实际环境中广泛使用这些模型至关重要。

    

    随着大型语言模型（LLMs）在生成人类化文本方面的能力不断提高，一个关键挑战是它们倾向于产生虚构的内容，看似真实但没有依据。幻觉问题可以说是安全地将这些强大的LLMs部署到影响人们生活的现实生产系统中最大的障碍。在实际环境中广泛采用LLMs的过程严重依赖于解决和减轻幻觉。与传统的专注于有限任务的人工智能系统不同，LLMs在训练过程中可以接触到大量的在线文本数据。这使它们能够展示出令人印象深刻的语言流利性，但也意味着它们能够从训练数据的偏见中推断信息，错误解释含糊不清的提示，或者修改信息以表面上与输入一致。当我们依赖语言生成能力来完成敏感应用时，这变得非常令人担忧。

    As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded. This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives. The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations. Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training. While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. This becomes hugely alarming when we rely on language generation capabilities for sensitive applica
    
[^41]: 大型语言模型的知识编辑全面研究

    A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v1 [cs.CL])

    [http://arxiv.org/abs/2401.01286](http://arxiv.org/abs/2401.01286)

    本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。

    

    大型语言模型(LLM)在理解和生成与人类交流紧密相似的文本方面展现出了非凡的能力。然而，其主要限制在于训练过程中的显著计算需求，这是由于其广泛的参数化造成的。这一挑战在于世界的动态性，需要频繁更新LLM以修正过时的信息或集成新知识，从而确保其持续的相关性。许多应用需要在训练后进行持续的模型调整，以解决缺陷或不良行为。近年来，对于LLM的知识编辑技术的兴趣越来越高，在特定领域内有效地修改LLM的行为，同时保持整体性能在各种输入中的表现。本文首先定义了知识编辑的目标和挑战，然后综述了现有的知识编辑方法和技术，并讨论了其应用和未来发展的方向。

    Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the kno
    
[^42]: 机器翻译自动评估的参考文献质量和数量

    Quality and Quantity of Machine Translation References for Automated Metrics. (arXiv:2401.01283v1 [cs.CL])

    [http://arxiv.org/abs/2401.01283](http://arxiv.org/abs/2401.01283)

    本研究发现，机器翻译评估的较高质量参考文献对于评估指标与人类评价之间的相关性更好。每个段落平均使用7个参考文献有助于提升所有评估指标。不同质量的供应商参考文献可以混合使用来提高评估指标的准确性。这些发现可用于在特定预算下创建参考文献的共享任务的评估者。

    

    自动机器翻译评估指标通常使用人工翻译来确定系统翻译的质量。领域内的共识认为人工参考文献应具有很高的质量。然而，目前没有成本效益分析可以指导计划收集机器翻译评估参考文献的从业者。我们发现，较高质量的参考文献能够在段落级别上与人类评价的相关性更好。每个段落平均使用7个参考文献有助于所有评估指标的提升。有趣的是，来自不同质量的供应商的参考文献可以混合使用，并提高评估指标的准确性。然而，较高质量的参考文献制作成本更高，我们将其视为一个优化问题：在特定预算下，应该收集哪些参考文献以最大化评估指标的准确性。这些发现可用于在特定预算下创建参考文献的共享任务的评估者。

    Automatic machine translation metrics often use human translations to determine the quality system translations. Common wisdom in the field dictates that the human references should be of very high quality. However, there are no cost-benefit analyses that could be used to guide practitioners who plan to collect references for machine translation evaluation. We find that higher-quality references lead to better metric correlations with humans at the segment-level. Having up to 7 references per segment and taking their average helps all metrics. Interestingly, the references from vendors of different qualities can be mixed together and improve metric success. Higher quality references, however, cost more to create and we frame this as an optimization problem: given a specific budget, what references should be collected to maximize metric success. These findings can be used by evaluators of shared tasks when references need to be created under a certain budget.
    
[^43]: Cheetah: 517种非洲语言的自然语言生成

    Cheetah: Natural Language Generation for 517 African Languages. (arXiv:2401.01053v1 [cs.CL])

    [http://arxiv.org/abs/2401.01053](http://arxiv.org/abs/2401.01053)

    Cheetah是一个面向517种非洲语言的大规模多语种自然语言生成模型，通过综合评估和人工评估，证明了其在生成连贯和上下文恰当的文本方面的卓越性能，并提供了促进语言多样性的解决方案。

    

    对于自然语言处理 (NLP) 任务来说，非洲语言资源稀缺是一个独特的挑战，包括自然语言生成 (NLG)。在本文中，我们开发了Cheetah，一个面向非洲语言的大规模多语种NLG语言模型。Cheetah支持517种非洲语言和语言变体，解决了NLG资源匮乏问题，并为促进语言多样性提供了解决方案。我们通过七个生成下游任务的综合评估证明了Cheetah的有效性。在七个任务中的五个任务中，Cheetah的表现显著优于其他模型，展示了其在广泛范围的非洲语言中生成连贯和上下文恰当的文本的卓越性能。我们还进行了详细的人工评估，以深入了解Cheetah的语言能力。Cheetah的引入对语言多样性具有深远的益处。通过利用预训练模型并将其适应特定的非洲语言，我们能够提供更多的语言生成选择和资源。

    Low-resource African languages pose unique challenges for natural language processing (NLP) tasks, including natural language generation (NLG). In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages. Cheetah supports 517 African languages and language varieties, allowing us to address the scarcity of NLG resources and provide a solution to foster linguistic diversity. We demonstrate the effectiveness of Cheetah through comprehensive evaluations across seven generation downstream tasks. In five of the seven tasks, Cheetah significantly outperforms other models, showcasing its remarkable performance for generating coherent and contextually appropriate text in a wide range of African languages. We additionally conduct a detailed human evaluation to delve deeper into the linguistic capabilities of Cheetah. The introduction of Cheetah has far-reaching benefits for linguistic diversity. By leveraging pretrained models and adapting them to specifi
    
[^44]: 如果LLM是巫师，那么代码就是魔杖：关于代码如何使大规模语言模型成为智能代理的调查

    If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents. (arXiv:2401.00812v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.00812](http://arxiv.org/abs/2401.00812)

    本调查研究探讨了在大规模语言模型中整合代码的好处，包括提升LLMs的代码生成能力、激发推理能力、生成结构化和精确的中间步骤，并利用代码的编译和执行环境来改善模型。

    

    当今知名的大规模语言模型（LLMs）与过去的语言模型不仅在大小上有所不同，还在于它们在训练数据中结合了自然语言和形式语言（代码）。作为人类和计算机之间的中介，代码将高层次的目标转化为可执行的步骤，具有标准的语法、逻辑一致性、抽象和模块化。在本调查中，我们概述了将代码整合到LLMs的训练数据中的各种好处。具体而言，除了增强LLMs的代码生成能力外，我们观察到代码的这些独特属性有助于（i）激发LLMs的推理能力，使其能够应用于更复杂的自然语言任务；（ii）引导LLMs生成结构化和精确的中间步骤，然后通过函数调用与外部执行端连接起来；以及（iii）利用代码编译和执行环境，为模型改进提供多样化的反馈。

    The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. In this survey, we present an overview of the various benefits of integrating code into LLMs' training data. Specifically, beyond enhancing LLMs in code generation, we observe that these unique properties of code help (i) unlock the reasoning ability of LLMs, enabling their applications to a range of more complex natural language tasks; (ii) steer LLMs to produce structured and precise intermediate steps, which can then be connected to external execution ends through function calls; and (iii) take advantage of code compilation and execution environment, which also provides diverse feedback for model improve
    
[^45]: SecFormer：面向大型语言模型的快速准确隐私保护推理

    SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models. (arXiv:2401.00793v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.00793](http://arxiv.org/abs/2401.00793)

    SecFormer是一个优化框架，旨在实现Transformer模型的快速准确隐私保护推理。通过消除高成本的指数和线性操作，SecFormer能够有效解决在大型语言模型中应用SMPC时的性能问题。

    

    随着在云平台上部署大型语言模型以提供推理服务的使用增加，隐私问题日益加剧，尤其是涉及投资计划和银行账户等敏感数据。安全多方计算（SMPC）被视为保护推理数据和模型参数隐私的一种有前途的解决方案。然而，SMPC在大型语言模型（特别是基于Transformer架构的模型）的隐私保护推理中的应用往往会导致显著的减速或性能下降。这主要是由于Transformer架构中的众多非线性操作不适合SMPC，并且难以有效规避或优化。为了解决这个问题，我们引入了一个先进的优化框架，称为SecFormer，以实现Transformer模型的快速准确隐私保护推理。通过实施模型设计优化，我们成功消除了高成本的指数和线性操作，并取得了良好的性能。

    With the growing use of large language models hosted on cloud platforms to offer inference services, privacy concerns are escalating, especially concerning sensitive data like investment plans and bank account details. Secure Multi-Party Computing (SMPC) emerges as a promising solution to protect the privacy of inference data and model parameters. However, the application of SMPC in Privacy-Preserving Inference (PPI) for large language models, particularly those based on the Transformer architecture, often leads to considerable slowdowns or declines in performance. This is largely due to the multitude of nonlinear operations in the Transformer architecture, which are not well-suited to SMPC and difficult to circumvent or optimize effectively. To address this concern, we introduce an advanced optimization framework called SecFormer, to achieve fast and accurate PPI for Transformer models. By implementing model design optimization, we successfully eliminate the high-cost exponential and 
    
[^46]: 长时间会议记录的行动项驱动摘要生成

    Action-Item-Driven Summarization of Long Meeting Transcripts. (arXiv:2312.17581v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.17581](http://arxiv.org/abs/2312.17581)

    本文提出了一种新方法来自动化生成行动项驱动的会议摘要，通过递归生成分段摘要并使用行动项提取算法。同时，本文还引入了三种用于将长记录分割成主题部分的新方法，以提高算法的效率和解决问题。

    

    在在线会议的流行下，自动生成会议摘要的模型变得更加实用。本文介绍了一种创新而有效的方法来自动化生成会议摘要。当前解决这个问题的方法只生成一般而基本的摘要，将会议简单地视为一个长对话。然而，我们的新算法可以根据会议记录中的行动项生成抽象的会议摘要。这是通过递归生成摘要并并行运行我们的行动项提取算法来实现的。所有这些章节摘要然后合并并总结在一起，以创建一个连贯且以行动项为导向的摘要。此外，本文还介绍了三种将长记录分割成基于主题的部分的新方法，以提高算法的时间效率，并解决问题。

    The increased prevalence of online meetings has significantly enhanced the practicality of a model that can automatically generate the summary of a given meeting. This paper introduces a novel and effective approach to automate the generation of meeting summaries. Current approaches to this problem generate general and basic summaries, considering the meeting simply as a long dialogue. However, our novel algorithms can generate abstractive meeting summaries that are driven by the action items contained in the meeting transcript. This is done by recursively generating summaries and employing our action-item extraction algorithm for each section of the meeting in parallel. All of these sectional summaries are then combined and summarized together to create a coherent and action-item-driven summary. In addition, this paper introduces three novel methods for dividing up long transcripts into topic-based sections to improve the time efficiency of our algorithm, as well as to resolve the iss
    
[^47]: YAYI-UIE: 一个增强对话指导的通用信息抽取调优框架

    YAYI-UIE: A Chat-Enhanced Instruction Tuning Framework for Universal Information Extraction. (arXiv:2312.15548v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.15548](http://arxiv.org/abs/2312.15548)

    本文提出了一个端到端的增强对话指导的通用信息抽取调优框架（YAYI-UIE），利用对话数据和信息抽取数据共同增强信息抽取性能，在中文数据集上达到了业界领先的性能，在英文数据集上也达到了可比较的性能。

    

    信息抽取任务的难点在于处理特定任务的标签模式和异构数据结构。最近的工作提出了基于大型语言模型的方法来统一建模不同的信息抽取任务。然而，这些现有方法在除了英语以外的中文语言的信息提取能力上存在不足。在本文中，我们提出了一个端到端的增强对话指导的通用信息抽取调优框架（YAYI-UIE），支持中文和英文。具体而言，我们利用对话数据和信息抽取数据共同增强信息抽取性能。实验结果表明，我们提出的框架在中文数据集上达到了业界领先的性能，同时在有监督和零样本设置下在英文数据集上也达到了可比较的性能。

    The difficulty of the information extraction task lies in dealing with the task-specific label schemas and heterogeneous data structures. Recent work has proposed methods based on large language models to uniformly model different information extraction tasks. However, these existing methods are deficient in their information extraction capabilities for Chinese languages other than English. In this paper, we propose an end-to-end chat-enhanced instruction tuning framework for universal information extraction (YAYI-UIE), which supports both Chinese and English. Specifically, we utilize dialogue data and information extraction data to enhance the information extraction performance jointly. Experimental results show that our proposed framework achieves state-of-the-art performance on Chinese datasets while also achieving comparable performance on English datasets under both supervised settings and zero-shot settings.
    
[^48]: 多层次信息交互框架用于不完整话语重写

    Multi-Granularity Information Interaction Framework for Incomplete Utterance Rewriting. (arXiv:2312.11945v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11945](http://arxiv.org/abs/2312.11945)

    该论文提出了一种多层次信息交互框架用于不完整话语重写，该框架通过上下文选择、编辑矩阵构建和相关性合并捕捉多层次的语义信息，并在不完整话语编辑任务中取得了优越的性能。

    

    近期不完整话语重写（IUR）的方法未能捕捉到关键词的来源，这对于编辑不完整话语至关重要，并引入了来自无关话语的词语。我们提出了一种新颖有效的多任务信息交互框架，包括上下文选择、编辑矩阵构建和相关性合并，以捕捉语义信息的多层次性。通过获取相关话语和确定重要词语，我们的方法在该领域的两个基准数据集Restoration-200K和CANAND上优于现有的最先进模型。代码将在\url{https://github.com/yanmenxue/QR}上提供。

    Recent approaches in Incomplete Utterance Rewriting (IUR) fail to capture the source of important words, which is crucial to edit the incomplete utterance, and introduce words from irrelevant utterances. We propose a novel and effective multi-task information interaction framework including context selection, edit matrix construction, and relevance merging to capture the multi-granularity of semantic information. Benefiting from fetching the relevant utterance and figuring out the important words, our approach outperforms existing state-of-the-art models on two benchmark datasets Restoration-200K and CANAND in this field. Code will be provided on \url{https://github.com/yanmenxue/QR}.
    
[^49]: 面向基于强化学习的药物调整系统以减少言语不流畅的论文翻译

    Toward A Reinforcement-Learning-Based System for Adjusting Medication to Minimize Speech Disfluency. (arXiv:2312.11509v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11509](http://arxiv.org/abs/2312.11509)

    这个论文介绍了一种基于强化学习的系统，该系统可以根据患者言语不流畅程度自动调整药物，通过对药物组合的强化学习算法的优化，能够收敛到良好的用药方案。

    

    我们提出了一种基于强化学习的系统，该系统可以自动为患有与心理健康相关的言语不流畅的虚拟患者开具药物处方，并根据零成本频繁测量结果，调整药物和剂量。我们展示了系统的两个组成部分：一个在我们构建的大型数据集上检测和评估言语不流畅的模块，以及一个可以自动找到良好药物组合的强化学习算法。为了支持这两个模块，我们从文献中收集了关于药物治疗言语不流畅的效果的数据，并建立了一个可信的患者模拟系统。我们证明了在某些情况下，强化学习系统能够收敛到一个良好的用药方案。我们收集并对可能存在言语不流畅的人群进行了数据标注，并使用该数据集演示了我们的方法。我们的工作是一个概念验证:

    We propose a Reinforcement-Learning-based system that would automatically prescribe a hypothetical patient medication that may help the patient with their mental-health-related speech disfluency, and adjust the medication and the dosages in response to zero-cost frequent measurement of the fluency of the patient. We demonstrate the components of the system: a module that detects and evaluates speech disfluency on a large dataset we built, and a Reinforcement Learning algorithm that automatically finds good combinations of medications. To support the two modules, we collect data on the effect of psychiatric medications for speech disfluency from the literature, and build a plausible patient simulation system. We demonstrate that the Reinforcement Learning system is, under some circumstances, able to converge to a good medication regime. We collect and label a dataset of people with possible speech disfluency and demonstrate our methods using that dataset. Our work is a proof of concept:
    
[^50]: "原文改写"提高了高精度长文本问答的效果

    "Paraphrasing The Original Text" Makes High Accuracy Long-Context QA. (arXiv:2312.11193v6 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11193](http://arxiv.org/abs/2312.11193)

    本论文提出了一种名为"原文改写"的任务来处理长文本问答，通过低成本高效的方法成功扩展了现有模型的上下文窗口至32k，并在多文档问答中达到了最先进的准确性。

    

    当面对长文本时，大多数开源生成式语言模型的上下文窗口限制在4k以内，这限制了它们的能力。即使是具有更长上下文窗口的模型也无法在长上下文问题上保证令人满意的准确性。为了解决这个问题，我们从训练数据的角度出发，从理论上证明了提高处理长上下文能力需要的是"有效"而不仅仅是"长"的数据。基于这个洞见，我们提出了使用"原文改写"任务，并通过一种低成本高效的方法，成功将现有模型的上下文窗口扩展到32k。我们的微调模型在具有相近规模的模型中在多文档问答方面达到了最先进的准确性。模型和训练数据已经在HuggingFace（https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k）和WiseModel（https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k）上提供。

    Most open-source generative language models currently have a context window of no more than 4k, limiting their ability when facing long text. Even models with longer context windows cannot guarantee satisfactory accuracy on long-context problems. To tackle this issue, we explore from the perspective of training data and theoretically demonstrate that improving the capability to handle long contexts requires "effective" rather than simply "long" data. Based on this insight, we propose using the "original text paraphrasing" task and successfully extend the context window of existing models to 32k through a low-cost and effective method. Our fine-tuned model achieves state-of-the-art accuracy in multi-document-QA among models of comparable scale. The model and training data have been made available on HuggingFace(https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k) and WiseModel(https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k).
    
[^51]: RJUA-QA：一份全面的泌尿外科问答数据集

    RJUA-QA: A Comprehensive QA Dataset for Urology. (arXiv:2312.09785v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.09785](http://arxiv.org/abs/2312.09785)

    RJUA-QA是一个全面的泌尿外科问答数据集，帮助大型语言模型在生成可靠的诊断和建议方面发挥作用。

    

    我们介绍了RJUA-QA，这是一个新颖的医学问答和基于临床证据推理的数据集，有助于弥合通用大型语言模型（LLM）和医学特定LLM应用之间的差距。RJUA-QA来源于真实的临床场景，旨在帮助LLMs生成可靠的诊断和建议。该数据集包含2,132个策划问题-上下文-答案对，对应约25,000条诊断记录和临床案例。该数据集涵盖了67个常见的泌尿外科疾病类别，疾病覆盖率超过97.6％的寻求泌尿外科医疗服务的人群。RJUA-QA中的每个数据实例包括：（1）一个模仿真实患者的问题，询问临床症状和医学状况，（2）包含全面专家知识的上下文，作为医学检查和诊断的参考，（3）医生的答复提供诊断结论和建议的检查指导，（4）一些…

    We introduce RJUA-QA, a novel medical dataset for question answering (QA) and reasoning with clinical evidence, contributing to bridge the gap between general large language models (LLMs) and medical-specific LLM applications. RJUA-QA is derived from realistic clinical scenarios and aims to facilitate LLMs in generating reliable diagnostic and advice. The dataset contains 2,132 curated Question-Context-Answer pairs, corresponding about 25,000 diagnostic records and clinical cases. The dataset covers 67 common urological disease categories, where the disease coverage exceeds 97.6\% of the population seeking medical services in urology. Each data instance in RJUA-QA comprises: (1) a question mirroring real patient to inquiry about clinical symptoms and medical conditions, (2) a context including comprehensive expert knowledge, serving as a reference for medical examination and diagnosis, (3) a doctor response offering the diagnostic conclusion and suggested examination guidance, (4) a di
    
[^52]: 分析假新闻对2024年选举结果的提前影响

    Analyzing the Impact of Fake News on the Anticipated Outcome of the 2024 Election Ahead of Time. (arXiv:2312.03750v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.03750](http://arxiv.org/abs/2312.03750)

    本研究提供了一个全面的数据集，用于分析假新闻对2024年选举结果的提前影响。该数据集包含了40,000篇关于北美政治演讲的新闻文章，并利用先进的语言模型和人工验证方法对其中的一部分进行了注释。研究人员鼓励使用这个数据集并为该倡议做出贡献。

    

    尽管对假新闻的认识和研究越来越多，但在北美政治演讲中特定针对种族侮辱和偏见的数据集仍然很有必要。这在即将举行的北美选举的背景下尤为重要。本研究介绍了一个全面的数据集，揭示了这些误导信息的关键方面。为了开发这个假新闻数据集，我们收集并建立了一个包含4万篇北美政治演讲新闻文章的语料库。其中的一部分数据集（4000篇）经过仔细注释，采用了先进的语言模型和人工验证方法的融合。我们已经将这两个数据集公开提供给研究界，并在注释数据上进行了性能基准测试以展示其实用性。我们发布了表现最佳的语言模型以及数据。我们鼓励研究人员和开发者使用这个数据集，并为这一持续进行的倡议做出贡献。

    Despite increasing awareness and research around fake news, there is still a significant need for datasets that specifically target racial slurs and biases within North American political speeches. This is particulary important in the context of upcoming North American elections. This study introduces a comprehensive dataset that illuminates these critical aspects of misinformation. To develop this fake news dataset, we scraped and built a corpus of 40,000 news articles about political discourses in North America. A portion of this dataset (4000) was then carefully annotated, using a blend of advanced language models and human verification methods. We have made both these datasets openly available to the research community and have conducted benchmarking on the annotated data to demonstrate its utility. We release the best-performing language model along with data. We encourage researchers and developers to make use of this dataset and contribute to this ongoing initiative.
    
[^53]: 从初学者到专家：将医学知识建模到通用LLM中

    From Beginner to Expert: Modeling Medical Knowledge into General LLMs. (arXiv:2312.01040v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.01040](http://arxiv.org/abs/2312.01040)

    本文提出了一种将医学知识建模到通用LLM中的方法，并通过优化过程将其从医学初学者调整为医学专家。实验证明该方法在回答医学问题方面取得了良好的效果，同时使用较小规模的模型大小，与大规模LLM模型相当，更加适用于医学应用。

    

    最近，基于大型语言模型（LLM）的人工智能系统在自然语言理解和生成方面展现出了显著的能力。然而，当涉及到对医学知识进行推理和以医生的方式回答医学问题等敏感应用时，这些模型面临着巨大的挑战。先前的研究试图通过增加模型的大小（>100B）来学习更通用的医学知识，但在模型规模较小（<100B）的LLM中仍有改进的空间。在这项工作中，我们从一个预训练的通用LLM模型（AntGLM-10B）开始，经过三阶段的优化过程，即通用医学知识注入、医学领域指导调优和特定医学任务适应，将其从医学初学者精细调整为医学专家（称为AntGLM-Med-10B）。我们的贡献主要有三个方面：（1）我们具体研究了如何将预训练的通用LLM模型调整为医学专家。(2) We evaluate the performance of our model on various medical tasks and demonstrate its effectiveness and reliability in answering medical questions. (3) We show that our approach can achieve comparable performance to larger-scale LLM models (>100B) while using a smaller-scale model size (<100B), making it more practical and accessible for medical applications.

    Recently, large language model (LLM) based artificial intelligence (AI) systems have demonstrated remarkable capabilities in natural language understanding and generation. However, these models face a significant challenge when it comes to sensitive applications, such as reasoning over medical knowledge and answering medical questions in a physician-like manner. Prior studies attempted to overcome this challenge by increasing the model size (>100B) to learn more general medical knowledge, while there is still room for improvement in LLMs with smaller-scale model sizes (<100B). In this work, we start from a pre-trained general LLM model (AntGLM-10B) and fine-tune it from a medical beginner towards a medical expert (called AntGLM-Med-10B), which leverages a 3-stage optimization procedure, i.e., general medical knowledge injection, medical domain instruction tuning, and specific medical task adaptation. Our contributions are threefold: (1) We specifically investigate how to adapt a pre-tr
    
[^54]: 自动化医学报告准确性度量的比较实验：以中耳咨询为例

    Comparative Experimentation of Accuracy Metrics in Automated Medical Reporting: The Case of Otitis Consultations. (arXiv:2311.13273v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.13273](http://arxiv.org/abs/2311.13273)

    本研究进行了一项比较实验，评估了自动化医学报告中10种准确性度量指标的应用。以中耳咨询为例，分析了生成的报告与全科医生报告之间的相关性。同时，引入了一个组合准确度得分，用于比较自动化医学报告领域内的度量指标。

    

    生成的人工智能可以根据医学咨询的文本生成医学报告。其目的是减轻医疗保健专业人员的行政负担。为了确保报告的正确性和实用性，需要对生成的报告的准确性进行评估。有几种度量指标可用于衡量AI生成的报告的准确性，但在医学报告中应用这些指标的研究很少。我们对与中耳咨询相关的生成的医学报告和相应的全科医生报告进行了10种准确性度量的比较实验。我们将生成的报告中缺失、错误和附加的陈述与度量指标得分进行了相关性分析。此外，我们引入和定义了一个组合准确度得分，用于比较自动化医学报告领域内的度量指标。

    Generative Artificial Intelligence (AI) can be used to automatically generate medical reports based on transcripts of medical consultations. The aim is to reduce the administrative burden that healthcare professionals face. The accuracy of the generated reports needs to be established to ensure their correctness and usefulness. There are several metrics for measuring the accuracy of AI generated reports, but little work has been done towards the application of these metrics in medical reporting. A comparative experimentation of 10 accuracy metrics has been performed on AI generated medical reports against their corresponding General Practitioner's (GP) medical reports concerning Otitis consultations. The number of missing, incorrect, and additional statements of the generated reports have been correlated with the metric scores. In addition, we introduce and define a Composite Accuracy Score which produces a single score for comparing the metrics within the field of automated medical re
    
[^55]: 在文本分类中探索语言模型中的概念级别的误相关性

    Explore Spurious Correlations at the Concept Level in Language Models for Text Classification. (arXiv:2311.08648v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.08648](http://arxiv.org/abs/2311.08648)

    本文研究了语言模型在文本分类中概念级别的误相关性问题，并通过使用ChatGPT分配概念标签和引入数据再平衡技术来解决这一问题。

    

    语言模型在众多自然语言处理任务中取得了显著的成功，采用了微调和上下文学习方法。虽然语言模型表现出卓越的性能，但由于训练数据中标签分布不平衡或上下文学习实例产生的误相关性，它们面临着鲁棒性挑战。以往的研究主要集中在词语、短语和句法特征上，忽视了概念级别的研究，这往往是由于缺乏概念标签和难以确定输入文本中的概念内容。本文提出了两个主要贡献。首先，我们使用ChatGPT为文本分配概念标签，评估模型在微调或上下文学习测试数据中的概念偏差。我们发现，当语言模型在训练或提示中遇到概念和标签之间的误相关性时，会采取预测的捷径。其次，我们引入了一种数据再平衡技术，将ChatGPT生成的反事实数据纳入其中。

    Language models (LMs) have achieved notable success in numerous NLP tasks, employing both fine-tuning and in-context learning (ICL) methods. While language models demonstrate exceptional performance, they face robustness challenges due to spurious correlations arising from imbalanced label distributions in training data or ICL exemplars. Previous research has primarily concentrated on word, phrase, and syntax features, neglecting the concept level, often due to the absence of concept labels and difficulty in identifying conceptual content in input texts. This paper introduces two main contributions. First, we employ ChatGPT to assign concept labels to texts, assessing concept bias in models during fine-tuning or ICL on test data. We find that LMs, when encountering spurious correlations between a concept and a label in training or prompts, resort to shortcuts for predictions. Second, we introduce a data rebalancing technique that incorporates ChatGPT-generated counterfactual data, ther
    
[^56]: Kiki还是Bouba？视觉与语言模型中的声音象征性

    Kiki or Bouba? Sound Symbolism in Vision-and-Language Models. (arXiv:2310.16781v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.16781](http://arxiv.org/abs/2310.16781)

    这项研究通过调查视觉与语言模型中的内在知识，发现它们显示了声音象征性的模式，进一步证实声音和意义之间的相关性在跨模态关联中得到了体现。

    

    尽管人类语言中的声音和意义之间的映射被认为在很大程度上是随机的，但认知科学的研究表明，在语言和人口群体之间的特定声音和意义之间存在非平凡的相关性，这种现象被称为声音象征性。在许多意义维度中，声音象征性在语言和视觉领域之间的跨模态关联方面尤为显著和充分证明。在这项工作中，我们探讨了声音象征性是否在CLIP和Stable Diffusion等视觉与语言模型中得到体现。通过使用零样本知识探测来调查这些模型的内在知识，我们发现强有力的证据表明它们确实显示了这种模式，与心理语言学中众所周知的kiki-bouba效应相一致。我们的工作提供了一种使用计算工具来展示声音象征性并理解其本质的新方法。我们的代码将公开提供。

    Although the mapping between sound and meaning in human language is assumed to be largely arbitrary, research in cognitive science has shown that there are non-trivial correlations between particular sounds and meanings across languages and demographic groups, a phenomenon known as sound symbolism. Among the many dimensions of meaning, sound symbolism is particularly salient and well-demonstrated with regards to cross-modal associations between language and the visual domain. In this work, we address the question of whether sound symbolism is reflected in vision-and-language models such as CLIP and Stable Diffusion. Using zero-shot knowledge probing to investigate the inherent knowledge of these models, we find strong evidence that they do show this pattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our work provides a novel method for demonstrating sound symbolism and understanding its nature using computational tools. Our code will be made publicly available.
    
[^57]: 通过无监督建立个性化词典来定制大型语言模型的个性特征

    Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons. (arXiv:2310.16582v1 [cs.CL])

    [http://arxiv.org/abs/2310.16582](http://arxiv.org/abs/2310.16582)

    本文介绍了一种新方法，通过无监督建立个性化词典，来定制大型语言模型的个性特征。该方法可以以可插拔的方式结合五个大类因素，实现对个性特征的精确操纵。

    

    个性在塑造人类表达模式方面起着关键作用，赋予和操纵大型语言模型（LLM）的个性特征在提升用户体验方面具有重大潜力。然而，先前的方法要么依赖于在富含个性表达的语料库上对LLM进行微调，要么需要手动制作提示来诱导LLM产生个性化回应。前者需要大量时间和资源来收集足够的训练样本，而后者可能无法精确操纵个性特征以达到细粒度的水平（例如，在减少开放性的同时提高宜人性）。在这项研究中，我们介绍了一种新的方法来定制LLM中的个性特征，允许以可插拔的方式结合五个大类因素（即开放性、责任心、外向性、宜人性和神经质）的任意组合。

    Personality plays a pivotal role in shaping human expression patterns, and empowering and manipulating large language models (LLMs) with personality traits holds significant promise in enhancing the user experience of LLMs. However, prior approaches either rely on fine-tuning LLMs on a corpus enriched with personalized expressions or necessitate the manual crafting of prompts to induce LLMs to produce personalized responses. The former approaches demand substantial time and resources for collecting sufficient training examples while the latter might fail in enabling the precise manipulation of the personality traits at a fine-grained level (e.g., achieving high agreeableness while reducing openness). In this study, we introduce a novel approach for tailoring personality traits within LLMs, allowing for the incorporation of any combination of the Big Five factors (i.e., openness, conscientiousness, extraversion, agreeableness, and neuroticism) in a pluggable manner. This is achieved by 
    
[^58]: 什么是一个好问题？基于任务的询问与事实级遮蔽。

    What is a good question? Task-oriented asking with fact-level masking. (arXiv:2310.11571v1 [cs.CL])

    [http://arxiv.org/abs/2310.11571](http://arxiv.org/abs/2310.11571)

    本论文提出了基于任务的询问（TOA）的概念和框架，介绍了一种用于生成对推理任务有用答案的问题的方法。同时还提出了一种事实级遮蔽（FLM）的技术，用于将自然语言数据集转换为自我监督的TOA数据集。

    

    提问是现实生活中合作推理任务（如问答）的重要组成部分。例如，一个法律助手聊天机器人在没有用户情况的具体信息的情况下可能无法提供准确的建议。然而，通常会直接使用大型语言模型来解决推理任务，而不会向用户或第三方提出后续问题。我们将这个问题称为基于任务的询问（TOA）。零-shot聊天模型可以执行TOA，但它们的训练主要基于下一个词预测，而不是问题是否对成功的合作有帮助。为了能够训练和评估TOA模型，我们提出了自然语言任务导向询问的定义和框架，即生成能够为推理任务提供有用答案的问题的问题。我们还提出了事实级遮蔽（FLM）的方法，通过省略特定的部分将自然语言数据集转换为自我监督的TOA数据集。

    Asking questions is an important element of real-life collaboration on reasoning tasks like question answering. For example, a legal assistant chatbot may be unable to make accurate recommendations without specific information on the user's circumstances. However, large language models are usually deployed to solve reasoning tasks directly without asking follow-up questions to the user or third parties. We term this problem task-oriented asking (TOA). Zero-shot chat models can perform TOA, but their training is primarily based on next-token prediction rather than whether questions contribute to successful collaboration. To enable the training and evaluation of TOA models, we present a definition and framework for natural language task-oriented asking, the problem of generating questions that result in answers useful for a reasoning task. We also present fact-level masking (FLM), a procedure for converting natural language datasets into self-supervised TOA datasets by omitting particula
    
[^59]: ResidualTransformer：带有权重共享的残差低秩学习的Transformer层

    ResidualTransformer: Residual Low-rank Learning with Weight-sharing for Transformer Layers. (arXiv:2310.02489v1 [cs.CL])

    [http://arxiv.org/abs/2310.02489](http://arxiv.org/abs/2310.02489)

    本文提出了一种名为ResidualTransformer的方法，通过重新参数化Transformer编码器层之间的模型权重，将模型的大小减小。实验结果表明，ResidualTransformer的性能优于传统Transformer模型，且模型大小得到了显著减小。

    

    在部署语音处理模型到始终开启设备上时，内存限制是一个主要关注点之一。虽然使用足够大量的数据训练得到的更大的模型通常表现更好，但使其适应设备内存是一个具有挑战性的问题。在本文中，我们旨在通过重新参数化Transformer编码器层之间的模型权重，并假设特殊的权重组合和结构，来减小模型的大小。更具体地说，受ResNet和最新的LoRA工作的启发，我们提出了一种名为ResidualTransformer的方法，其中Transformer层中的每个权重矩阵包括1）与其相邻层共享的满秩组件，和2）仅属于它自己的独特低秩组件。低秩矩阵只占模型大小的一小部分。此外，我们添加对角线权重矩阵来提高低秩矩阵的建模能力。我们的10k小时语音识别和语音翻译任务的实验结果表明，ResidualTransformer的性能优于传统Transformer模型，且模型大小得到了显著减小。

    Memory constraint of always-on devices is one of the major concerns when deploying speech processing models on these devices. While larger models trained with sufficiently large amount of data generally perform better, making them fit in the device memory is a demanding challenge. In this paper, we aim to reduce model size by reparameterizing model weights across Transformer encoder layers and assuming a special weight composition and structure. More specifically, inspired by ResNet and the more recent LoRA work, we propose an approach named ResidualTransformer, where each weight matrix in a Transformer layer comprises 1) a shared full-rank component with its adjacent layers, and 2) a unique low-rank component to itself. The low-rank matrices only account for a small amount of model size increase. In addition, we add diagonal weight matrices to improve modeling capacity of the low-rank matrices. Experiments of our 10k-hour speech recognition and speech translation tasks show that the T
    
[^60]: 使用LLM和BoWs自动评估课堂教学支持：将全局预测与具体反馈相连接

    Automated Evaluation of Classroom Instructional Support with LLMs and BoWs: Connecting Global Predictions to Specific Feedback. (arXiv:2310.01132v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.01132](http://arxiv.org/abs/2310.01132)

    本研究旨在利用大型语言模型和词袋模型自动估计课堂教学支持，以提供更具体、频繁和可行动的反馈给教师。实验证明，所提出的方法准确性接近于人工互评可靠性，LLM模型可以更好地捕捉到教学支持特征。

    

    为了向教师提供更具体、更频繁和可行动的反馈，我们探讨了如何利用大型语言模型（LLMs）来估计“教学支持”领域的CLASS课堂评估得分，该评估方法是广泛使用的观测协议。我们设计了一个机器学习架构，使用Meta的Llama2的零-shot提示，和/或经典的词袋（BoW）模型，用于对教师言语的个别话语（使用OpenAI的Whisper进行自动转录）进行分类，以确定是否存在教学支持。然后，这些话语级的判断结果在整个15分钟的观察会话中进行聚合，以估计全局CLASS得分。在幼儿园和学前班教室的两个经过CLASS编码的数据集上进行的实验证明：（1）所提出的方法自动估计CLASS教学支持的准确性（Pearson R高达0.47）接近人工互评可靠性（最高R=0.55）；（2）LLM模型可以更好地捕捉到小班教室中的教学支持特征。

    With the aim to provide teachers with more specific, frequent, and actionable feedback about their teaching, we explore how Large Language Models (LLMs) can be used to estimate ``Instructional Support'' domain scores of the CLassroom Assessment Scoring System (CLASS), a widely used observation protocol. We design a machine learning architecture that uses either zero-shot prompting of Meta's Llama2, and/or a classic Bag of Words (BoW) model, to classify individual utterances of teachers' speech (transcribed automatically using OpenAI's Whisper) for the presence of Instructional Support. Then, these utterance-level judgments are aggregated over an entire 15-min observation session to estimate a global CLASS score. Experiments on two CLASS-coded datasets of toddler and pre-kindergarten classrooms indicate that (1) automatic CLASS Instructional Support estimation accuracy using the proposed method (Pearson $R$ up to $0.47$) approaches human inter-rater reliability (up to $R=0.55$); (2) LLM
    
[^61]: 通过对大型语言模型进行微调在低资源环境中合成数据生成

    Synthetic Data Generation in Low-Resource Settings via Fine-Tuning of Large Language Models. (arXiv:2310.01119v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.01119](http://arxiv.org/abs/2310.01119)

    通过对大型语言模型进行微调，在低资源环境中可以通过合成数据生成来改善较小模型的性能，显著提高了下游模型的性能。

    

    大型语言模型(LLMs)的上下文学习能力使它们能够以相对较少的标记样本推广到新的下游任务。然而，它们需要巨大的计算资源才能部署。相反，如果用足够多的标记样本对较小的模型进行微调，它们可以解决特定任务。然而，这些样本获取起来很昂贵。为了追求两全其美，我们研究了通过对经过精细调整的教师LLMs生成的训练数据进行合成的合成数据生成，以改善较小模型的下游性能。在四个文本分类和两个文本生成任务中，我们发现数据生成和注释都显著提高了相应下游模型的性能，有时只需要原始训练数据集的一小部分。

    The in-context learning ability of large language models (LLMs) enables them to generalize to novel downstream tasks with relatively few labeled examples. However, they require enormous computational resources to be deployed. Alternatively, smaller models can solve specific tasks if fine-tuned with enough labeled examples. These examples, however, are expensive to obtain. In pursuit of the best of both worlds, we study synthetic data generation of fine-tuning training data via fine-tuned teacher LLMs to improve the downstream performance of much smaller models. In four text classification and two text generation tasks, we find that both data generation and annotation dramatically improve the respective downstream model's performance, occasionally necessitating only a minor fraction of the original training dataset.
    
[^62]: 大规模语言模型能够理解真实世界复杂指令吗？

    Can Large Language Models Understand Real-World Complex Instructions?. (arXiv:2309.09150v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09150](http://arxiv.org/abs/2309.09150)

    本论文提出了一个用于评估大规模语言模型理解复杂指令能力的基准——CELLO。通过设计复杂指令的八个特征并构建全面的评估数据集，可以解决现有基准的不足。

    

    大规模语言模型（LLMs）能够理解人类指令，展示了它们在传统NLP任务之外的实用应用潜力。然而，它们仍然在复杂指令上存在困难，这些指令可以是需要多个任务和约束的复杂任务描述，或者包含长篇背景、噪声、异构信息和多轮格式的复杂输入。由于这些特点，LLMs常常忽略任务描述中的语义约束，产生错误的格式，违反长度或样本计数的约束，对输入文本不忠实。现有的基准不足以评估LLMs理解复杂指令的能力，因为它们是封闭式和简单的。为了弥补这一间隙，我们提出了CELLO，一个用于系统评估LLMs遵循复杂指令能力的基准。我们为复杂指令设计了八个特征，并从现实场景中构建了一个全面的评估数据集。我们还建立了四个评价标准。

    Large language models (LLMs) can understand human instructions, showing their potential for pragmatic applications beyond traditional NLP tasks. However, they still struggle with complex instructions, which can be either complex task descriptions that require multiple tasks and constraints, or complex input that contains long context, noise, heterogeneous information and multi-turn format. Due to these features, LLMs often ignore semantic constraints from task descriptions, generate incorrect formats, violate length or sample count constraints, and be unfaithful to the input text. Existing benchmarks are insufficient to assess LLMs' ability to understand complex instructions, as they are close-ended and simple. To bridge this gap, we propose CELLO, a benchmark for evaluating LLMs' ability to follow complex instructions systematically. We design eight features for complex instructions and construct a comprehensive evaluation dataset from real-world scenarios. We also establish four crit
    
[^63]: TextBind: 多轮交错多模态指令跟随

    TextBind: Multi-turn Interleaved Multimodal Instruction-following. (arXiv:2309.08637v1 [cs.CL])

    [http://arxiv.org/abs/2309.08637](http://arxiv.org/abs/2309.08637)

    TextBind是一个注释极少的框架，用于将较大规模的语言模型赋予多轮交错多模态指令跟随能力，并通过图像-标题对生成多轮多模态指令-回应对话。这个框架对于解决实际任务具有重要意义，并为未来的研究提供了数据集、模型和演示。

    

    具有指令跟随能力的大型语言模型已经在人工智能领域产生了革命性的影响。这些模型通过其自然语言界面展示了卓越的泛化能力，可以解决各种实际任务。然而，它们的性能在很大程度上依赖于高质量的示例数据，而这往往很难获得。当涉及到多模态指令跟随时，这个挑战变得更加严峻。我们引入了TextBind，这是一个几乎不需要注释的框架，用于赋予较大规模的语言模型多轮交错多模态指令跟随能力。我们的方法仅需要图像-标题对，并从语言模型生成多轮多模态指令-回应对话。我们发布了我们的数据集、模型和演示，以促进未来在多模态指令跟随领域的研究。

    Large language models with instruction-following abilities have revolutionized the field of artificial intelligence. These models show exceptional generalizability to tackle various real-world tasks through their natural language interfaces. However, their performance heavily relies on high-quality exemplar data, which is often difficult to obtain. This challenge is further exacerbated when it comes to multimodal instruction following. We introduce TextBind, an almost annotation-free framework for empowering larger language models with the multi-turn interleaved multimodal instruction-following capabilities. Our approach requires only image-caption pairs and generates multi-turn multimodal instruction-response conversations from a language model. We release our dataset, model, and demo to foster future research in the area of multimodal instruction following.
    
[^64]: 通过提示策略增强评论文本的多领域情感分析

    Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies. (arXiv:2309.02045v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.02045](http://arxiv.org/abs/2309.02045)

    通过提示策略，本论文探究了如何通过应用角色扮演和思维链提示策略来增强大型语言模型（LLMs）在情感分析中的性能，并在三个不同领域的数据集上进行了评估。

    

    大型语言模型（LLMs）在科学研究和实际应用中取得了重大进展。现有研究已证明了LLMs在各种自然语言处理任务中的最新性能。然而，如何通过提示策略进一步增强LLMs在特定任务中的性能仍然是一个重要问题。本文探讨了通过应用提示策略来提高LLMs在情感分析中的性能。我们对情感分析任务的提示过程进行了建模，并介绍了两种针对情感分析的新颖策略：角色扮演（RP）提示和思维链（CoT）提示。具体地，我们还提出了RP-CoT提示策略，它是RP提示和CoT提示的结合。我们在三个不同领域的数据集上进行了比较实验，以评估所提出的情感分析策略的有效性。结果表明...

    Large Language Models (LLMs) have made significant strides in both scientific research and practical applications. Existing studies have demonstrated the state-of-the-art (SOTA) performance of LLMs in various natural language processing tasks. However, the question of how to further enhance LLMs' performance in specific task using prompting strategies remains a pivotal concern. This paper explores the enhancement of LLMs' performance in sentiment analysis through the application of prompting strategies. We formulate the process of prompting for sentiment analysis tasks and introduce two novel strategies tailored for sentiment analysis: RolePlaying (RP) prompting and Chain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoT prompting strategy which is a combination of RP prompting and CoT prompting. We conduct comparative experiments on three distinct domain datasets to evaluate the effectiveness of the proposed sentiment analysis strategies. The results demonstrate tha
    
[^65]: 广告的长期记忆性研究

    Long-Term Memorability On Advertisements. (arXiv:2309.00378v1 [cs.CL])

    [http://arxiv.org/abs/2309.00378](http://arxiv.org/abs/2309.00378)

    本研究是首个大规模的记忆性研究，发现广告的长期记忆性对于市场营销非常重要，但在机器学习文献中一直缺乏相关研究。通过分析大量参与者和广告，我们得出了关于什么使广告记忆深刻的有趣见解。

    

    市场营销人员花费数十亿美元在广告上，但是投入到广告上的金钱能起多大作用呢？当顾客在购买时无法辨认出他们看过的品牌的话，花在广告上的钱基本上就被浪费了。尽管在营销中很重要，但迄今为止，在机器学习的文献中还没有关于广告记忆力的研究。大多数研究都是对特定内容类型（如物体和动作视频）进行短期回忆（<5分钟）的研究。另一方面，广告行业只关心长期记忆（几个小时或更长时间），而且广告几乎总是高度多模式化，通过不同的形式（文本、图像和视频）来讲故事。基于这一动机，我们进行了首个大规模记忆性研究，共有1203名参与者和2205个广告涵盖了276个品牌。在不同参与者子群体和广告类型上进行统计测试，我们发现了许多有关什么使广告难忘的有趣见解-无论是内容还是

    Marketers spend billions of dollars on advertisements but to what end? At the purchase time, if customers cannot recognize a brand for which they saw an ad, the money spent on the ad is essentially wasted. Despite its importance in marketing, until now, there has been no study on the memorability of ads in the ML literature. Most studies have been conducted on short-term recall (<5 mins) on specific content types like object and action videos. On the other hand, the advertising industry only cares about long-term memorability (a few hours or longer), and advertisements are almost always highly multimodal, depicting a story through its different modalities (text, images, and videos). With this motivation, we conduct the first large scale memorability study consisting of 1203 participants and 2205 ads covering 276 brands. Running statistical tests over different participant subpopulations and ad-types, we find many interesting insights into what makes an ad memorable - both content and h
    
[^66]: WavMark：用于音频生成的水印技术

    WavMark: Watermarking for Audio Generation. (arXiv:2308.12770v1 [cs.SD])

    [http://arxiv.org/abs/2308.12770](http://arxiv.org/abs/2308.12770)

    WavMark是一种创新的音频水印技术，可以在短短1秒的音频片段中编码多达32位的水印，对人类感官无感知并且具有强大的韧性。它可以用于合成声音的有效识别和音频版权保护。

    

    最近在零-shot语音合成方面的突破使得只用几秒钟的录音就能模仿说话者的声音，并且保持高度的真实感。除了潜在的好处之外，这项强大的技术还带来了明显的风险，包括语音欺诈和冒充说话者。与仅依赖被动方法来检测合成数据的传统方法不同，水印技术提供了一种积极且强大的防御机制来应对这些潜在风险。本文介绍了一种创新的音频水印技术框架，可以在仅1秒的音频片段中编码多达32位的水印。水印对人类感官来说是无法察觉的，并且对各种攻击表现出强大的韧性。它可以作为合成声音的有效标识符，并在音频版权保护的更广泛应用中具有潜力。此外，这个框架具有很高的灵活性，可以将多个水印片段进行组合以实现更加丰富的功能。

    Recent breakthroughs in zero-shot voice synthesis have enabled imitating a speaker's voice using just a few seconds of recording while maintaining a high level of realism. Alongside its potential benefits, this powerful technology introduces notable risks, including voice fraud and speaker impersonation. Unlike the conventional approach of solely relying on passive methods for detecting synthetic data, watermarking presents a proactive and robust defence mechanism against these looming risks. This paper introduces an innovative audio watermarking framework that encodes up to 32 bits of watermark within a mere 1-second audio snippet. The watermark is imperceptible to human senses and exhibits strong resilience against various attacks. It can serve as an effective identifier for synthesized voices and holds potential for broader applications in audio copyright protection. Moreover, this framework boasts high flexibility, allowing for the combination of multiple watermark segments to achi
    
[^67]: Convoifilter: 鸡尾酒会语音识别的案例研究

    Convoifilter: A case study of doing cocktail party speech recognition. (arXiv:2308.11380v1 [cs.SD])

    [http://arxiv.org/abs/2308.11380](http://arxiv.org/abs/2308.11380)

    本文通过使用单声道语音增强模块与ASR模块，成功将ASR的词错误率从80%降低到26.4%，并通过联合微调策略将其进一步降低到14.5%。

    

    本文提出了一个端到端的模型，用于改进拥挤、嘈杂环境下的自动语音识别（ASR），针对特定说话者。该模型利用单声道语音增强模块将说话者的声音与背景噪声分离，结合ASR模块。通过这种方法，该模型能够将ASR的词错误率（WER）从80%降低到26.4%。通常情况下，由于数据要求的变化，这两个组件会独立调整。然而，语音增强可能会导致ASR效率下降。通过实施联合微调策略，该模型可以将分别调整的WER从26.4%降低到14.5%。

    This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise, along with an ASR module. Through this approach, the model is able to decrease the word error rate (WER) of ASR from 80% to 26.4%. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning.
    
[^68]: 基于深度学习的隐喻检测知识注入：综述研究

    Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review. (arXiv:2308.04306v1 [cs.CL])

    [http://arxiv.org/abs/2308.04306](http://arxiv.org/abs/2308.04306)

    本文对基于深度学习的隐喻识别任务中知识注入的研究进展进行了全面综述，包括主流知识和知识注入原则的总结、数据集、评估指标和基准模型的回顾，并探讨了当前的知识注入问题。

    

    隐喻研究的历史也标志着知识注入研究的演变。随着近年来深度学习技术的不断进步，自然语言处理社区对将知识应用于在隐喻识别任务中取得成功结果表现出极大兴趣。尽管在隐喻识别领域涉及知识注入的方法逐渐增加，但缺乏一篇完整的关于基于知识注入的方法的综述文章。因此，本文旨在综述深度学习在隐喻识别任务中应用知识注入的研究进展。本文系统总结和概括了主流的知识和知识注入原则，同时回顾了在隐喻识别任务中使用的数据集、评估指标和基准模型。最后，我们探讨了当前面临的知识注入问题。

    The history of metaphor research also marks the evolution of knowledge infusion research. With the continued advancement of deep learning techniques in recent years, the natural language processing community has shown great interest in applying knowledge to successful results in metaphor recognition tasks. Although there has been a gradual increase in the number of approaches involving knowledge injection in the field of metaphor recognition, there is a lack of a complete review article on knowledge injection based approaches. Therefore, the goal of this paper is to provide a comprehensive review of research advances in the application of deep learning for knowledge injection in metaphor recognition tasks. In this paper, we systematically summarize and generalize the mainstream knowledge and knowledge injection principles, as well as review the datasets, evaluation metrics, and benchmark models used in metaphor recognition tasks. Finally, we explore the current issues facing knowledge 
    
[^69]: 探索指令调整的格式一致性

    Exploring Format Consistency for Instruction Tuning. (arXiv:2307.15504v1 [cs.CL])

    [http://arxiv.org/abs/2307.15504](http://arxiv.org/abs/2307.15504)

    本研究探究了指令调整的格式一致性，并提出了统一指令调整（UIT）框架，通过自动格式转换来提高泛化性能。该研究强调了格式一致性的重要性。

    

    指令调整已经成为一种提升大型语言模型遵循人类指令能力的有前途的方法。研究表明，增加训练数据中指令的多样性和数量可以持续提升泛化性能，从而促进了最近的一项努力，即收集各种指令并将现有的指令调整数据集整合到更大的集合中。然而，不同用户有其独特的表达指令的方式，不同数据集之间通常存在指令风格和格式的变化，即格式不一致性。在这项工作中，我们研究了格式不一致性如何影响指令调整的性能。我们提出了一个名为“统一指令调整”（UIT）的框架，通过调用OpenAI的API实现在不同的指令调整数据集之间的自动格式转换。我们展示了UIT成功提高了在未见指令上的泛化性能，并强调了格式一致性的重要性。

    Instruction tuning has emerged as a promising approach to enhancing large language models in following human instructions. It is shown that increasing the diversity and number of instructions in the training data can consistently enhance generalization performance, which facilitates a recent endeavor to collect various instructions and integrate existing instruction tuning datasets into larger collections. However, different users have their unique ways of expressing instructions, and there often exist variations across different datasets in the instruction styles and formats, i.e., format inconsistency. In this work, we study how format inconsistency may impact the performance of instruction tuning. We propose a framework called "Unified Instruction Tuning" (UIT), which calls OpenAI APIs for automatic format transfer among different instruction tuning datasets. We show that UIT successfully improves the generalization performance on unseen instructions, which highlights the importance
    
[^70]: 多模态讨论变换器：整合文本、图像和图变换器以检测社交媒体上的仇恨言论。

    Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media. (arXiv:2307.09312v1 [cs.CL])

    [http://arxiv.org/abs/2307.09312](http://arxiv.org/abs/2307.09312)

    多模态讨论变换器 (mDT) 是一个用于检测在线社交网络中仇恨言论的新颖模型。与传统的仅使用文本的方法不同，mDT通过整体分析文本和图像，结合图变换器捕捉评论周围整个讨论的上下文关系，并通过交织融合层将文本和图像嵌入进行组合。研究发现，捕捉对话的整体视图可以极大地提高检测反社会行为的准确性。

    

    我们提出了一种新颖的多模态基于图的变换器模型，名为多模态讨论变换器（mDT），用于检测在线社交网络中的仇恨言论。与传统的仅使用文本的方法不同，我们将标记评论为仇恨言论的方法围绕文本和图像的整体分析展开。这是通过利用图变换器来捕捉评论周围整个讨论中的上下文关系，并采用交织融合层来组合文本和图像嵌入，而不是单独处理不同的模态。我们将模型的性能与仅处理文本的基线进行比较，还进行了广泛的消融研究。最后，我们展望了多模态解决方案在在线环境中提供社会价值的未来工作，并认为捕捉对话的整体视图极大地推进了检测反社会行为的努力。

    We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal graph-based transformer model for detecting hate speech in online social networks. In contrast to traditional text-only methods, our approach to labelling a comment as hate speech centers around the holistic analysis of text and images. This is done by leveraging graph transformers to capture the contextual relationships in the entire discussion that surrounds a comment, with interwoven fusion layers to combine text and image embeddings instead of processing different modalities separately. We compare the performance of our model to baselines that only process text; we also conduct extensive ablation studies. We conclude with future work for multimodal solutions to deliver social value in online contexts, arguing that capturing a holistic view of a conversation greatly advances the effort to detect anti-social behavior.
    
[^71]: 低资源语音翻译的跨语言迁移学习

    Cross-Lingual Transfer Learning for Low-Resource Speech Translation. (arXiv:2306.00789v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00789](http://arxiv.org/abs/2306.00789)

    提出了一种三步跨语言迁移学习框架，通过在现有框架中增加一步语义知识蒸馏，该方法有效地增强了自动语音翻译中从高资源语言到低资源语言的跨语言迁移能力，显著改善了翻译性能，特别是对于低资源语言，并减少了跨语言迁移间隙(TRFGap)。

    

    本文提出了一种新颖的三步跨语言迁移学习框架，用于增强自动语音翻译中从高资源语言到低资源语言的跨语言迁移能力。该方法将语义知识蒸馏步骤集成到现有的两步跨语言迁移学习框架XLS-R中。这一额外的步骤旨在通过使用无标签语音进行自监督学习来对多语言语音编码器进行预训练以编码语义知识。我们提出的三步跨语言迁移学习框架解决了XLS-R框架中高资源语言和低资源语言之间存在的大的跨语言迁移差距。我们通过在CoVoST-2基准测试上进行广泛实验和比较来验证我们的提议，结果显示在翻译性能方面取得了显著改进，特别是对于低资源语言，并且跨语言迁移间隙(TRFGap)有明显减少。

    The paper presents a novel three-step transfer learning framework for enhancing cross-lingual transfer from high- to low-resource languages in the downstream application of Automatic Speech Translation. The approach integrates a semantic knowledge-distillation step into the existing two-step cross-lingual transfer learning framework XLS-R. This extra step aims to encode semantic knowledge in the multilingual speech encoder pre-trained via Self-Supervised Learning using unlabeled speech. Our proposed three-step cross-lingual transfer learning framework addresses the large cross-lingual transfer gap (TRFGap) observed in the XLS-R framework between high-resource and low-resource languages. We validate our proposal through extensive experiments and comparisons on the CoVoST-2 benchmark, showing significant improvements in translation performance, especially for low-resource languages, and a notable reduction in the TRFGap.
    
[^72]: AlpacaFarm: 一种从人类反馈中学习的方法模拟框架

    AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback. (arXiv:2305.14387v1 [cs.LG])

    [http://arxiv.org/abs/2305.14387](http://arxiv.org/abs/2305.14387)

    该论文提出了一种名为AlpacaFarm的低成本模拟器，该模拟器为从人类反馈中学习的研究和开发提供了一种解决方案，通过设计LLM提示来模拟人类反馈，提出自动评估并提供参考实现，克服了数据收集的高昂成本、缺乏可信的评估和缺乏参考方法实现的挑战。

    

    大型语言模型（LLMs）如ChatGPT因其良好的指令跟随能力而得到了广泛应用。开发这些LLMs需要使用人类反馈进行训练的复杂且尚不明确的工作流程。将此指令跟随过程复制和理解面临三大挑战： 数据收集的高昂成本，缺乏可信的评估和缺乏参考方法实现。我们通过AlpacaFarm解决了这些挑战，这是一个低成本的模拟器，可用于从反馈中学习的研究和开发。第一，我们设计了LLM提示来模拟人类反馈，其成本比众包工作者便宜45倍，并且与人类反馈具有高度一致性。第二，我们提出了一种自动评估方法，并将其与真实世界交互中获得的人类指令进行验证。第三，我们为几种从配对反馈中学习的方法（PPO，best-of-n，expert iteration等）提供了参考实现。

    Large language models (LLMs) such as ChatGPT have seen widespread adoption due to their ability to follow user instructions well. Developing these LLMs involves a complex yet poorly understood workflow requiring training with human feedback. Replicating and understanding this instruction-following process faces three major challenges: the high cost of data collection, the lack of trustworthy evaluation, and the absence of reference method implementations. We address these challenges with AlpacaFarm, a simulator that enables research and development for learning from feedback at a low cost. First, we design LLM prompts to simulate human feedback that are 45x cheaper than crowdworkers and display high agreement with humans. Second, we propose an automatic evaluation and validate it against human instructions obtained on real-world interactions. Third, we contribute reference implementations for several methods (PPO, best-of-n, expert iteration, and more) that learn from pairwise feedback
    
[^73]: 语言模型能否用自然语言解决图问题？

    Can Language Models Solve Graph Problems in Natural Language?. (arXiv:2305.10037v1 [cs.CL])

    [http://arxiv.org/abs/2305.10037](http://arxiv.org/abs/2305.10037)

    本论文提出了自然语言图形(NLGraph)，这是一个全面的基于图形问题解决测试，旨在评估LLM在文本描述的图形结构和图形解决方案方面的处理能力。实验结果表明，LLM(GPT-3/4)具有相应的图形推理能力。

    

    大型语言模型越来越多地应用于一些具有隐式图形结构的任务，例如机器人规划、多跳问题回答或知识探索、结构化常识推理等等。虽然LLM在这些任务中已经取得了一定的进展，但是LLM是否能够显式处理图形的文本描述，将它们映射到基于概念的空间中，并执行结构化操作仍然尚未得到足够的研究。为此，我们提出了自然语言图形(NLGraph)，它是一个设计用于自然语言的基于图形问题解决全面测试。NLGraph包含29,370个问题，涵盖了八个图形推理任务，从简单的连接和最短路径到复杂的最大流和模拟图神经网络等任务不等。我们在NLGraph基准测试上评估了LLM(GPT-3/4)，并发现1)语言模型具有相应的图形推理能力；

    Large language models (LLMs) are increasingly adopted for a variety of tasks with implicit graphical structures, such as planning in robotics, multi-hop question answering or knowledge probing, structured commonsense reasoning, and more. While LLMs have advanced the state-of-the-art on these tasks with structure implications, whether LLMs could explicitly process textual descriptions of graphs and structures, map them to grounded conceptual spaces, and perform structured operations remains underexplored. To this end, we propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problem solving designed in natural language. NLGraph contains 29,370 problems, covering eight graph reasoning tasks with varying complexity from simple tasks such as connectivity and shortest path up to complex problems such as maximum flow and simulating graph neural networks. We evaluate LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and find that 1) language
    
[^74]: 复杂话语的自然语言分解和解释

    Natural Language Decomposition and Interpretation of Complex Utterances. (arXiv:2305.08677v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08677](http://arxiv.org/abs/2305.08677)

    本论文提出了一种处理复杂意图话语的方法，通过分层自然语言分解和解释的过程将复杂话语分解为简单的自然语言步骤，并使用预训练的语言模型和语言到程序模型解释每个步骤。实验证明了该方法的有效性。

    

    设计自然语言界面在历史上一直需要收集监督数据，将用户请求转化为精心设计的意图表示。这需要列举和标记一系列用户请求，这是具有挑战性的。同时，大型语言模型(LLMs)编码有关目标和计划的知识，可以帮助对用户请求进行解释，需要完成许多步骤。我们引入了一种处理用户通过分层自然语言分解和解释过程产生的复杂意图话语的方法。我们的方法使用预训练的语言模型将复杂话语分解为一系列更简单的自然语言步骤，并使用为界面设计的语言到程序模型解释每个步骤。为了测试我们的方法，我们收集和发布了DeCU -- 一个新的用于评估复杂话语分解的自然语言到程序基准。实验证明了所提出的方法的有效性。

    Designing natural language interfaces has historically required collecting supervised data to translate user requests into carefully designed intent representations. This requires enumerating and labeling a long tail of user requests, which is challenging. At the same time, large language models (LLMs) encode knowledge about goals and plans that can help conversational assistants interpret user requests requiring numerous steps to complete. We introduce an approach to handle complex-intent-bearing utterances from a user via a process of hierarchical natural language decomposition and interpretation. Our approach uses a pre-trained language model to decompose a complex utterance into a sequence of simpler natural language steps and interprets each step using the language-to-program model designed for the interface. To test our approach, we collect and release DeCU -- a new NL-to-program benchmark to evaluate Decomposition of Complex Utterances. Experiments show that the proposed approac
    
[^75]: 混合问题解析与执行答案复杂问题的文字问答系统

    Answering Complex Questions over Text by Hybrid Question Parsing and Execution. (arXiv:2305.07789v1 [cs.CL])

    [http://arxiv.org/abs/2305.07789](http://arxiv.org/abs/2305.07789)

    提出了一种混合问题解析和执行框架，在文字问答系统中实现回答复杂问题，通过解析问题为H表达式并设计混合执行器实现。在基准数据集中实现了最先进的准确率和效率表现。

    

    文本问答系统的主导模式是基于端到端的神经网络，其在回答自然语言问题方面表现突出，但在回答复杂问题方面表现不足。这与基于语义解析的方法在结构化数据源（如关系数据库、知识图谱）上广泛适应形成对比，后者将自然语言问题转换为逻辑形式，并利用查询引擎进行执行。为了结合神经和符号方法的优势，我们提出了一种在文本问答系统中进行解析和执行问题的框架。它包括两个中心支柱：（1）我们将各种复杂问题解析成中间表示，称为H表达式，它由简单问题组成原语和表示它们之间关系的符号操作组成；（2）为了执行产生的H表达式，我们设计了一个混合执行器，它集成了确定规则来翻译符号操作，与处理原始问题的插入神经模块。我们在包含复杂问题的大规模基准数据集上评估了我们的方法，并在准确性和效率指标方面取得了最先进的表现。

    The dominant paradigm of textual question answering systems is based on end-to-end neural networks, which excels at answering natural language questions but falls short on complex ones. This stands in contrast to the broad adaptation of semantic parsing approaches over structured data sources (e.g., relational database, knowledge graphs), that convert natural language questions to logical forms and execute them with query engines. Towards combining the strengths of neural and symbolic methods, we propose a framework of question parsing and execution on textual QA. It comprises two central pillars: (1) We parse the question of varying complexity into an intermediate representation, named H-expression, which is composed of simple questions as the primitives and symbolic operations representing the relationships among them; (2) To execute the resulting H-expressions, we design a hybrid executor, which integrates the deterministic rules to translate the symbolic operations with a drop-in n
    
[^76]: 具有几何信息瓶颈的可解释推荐系统

    Explainable Recommender with Geometric Information Bottleneck. (arXiv:2305.05331v1 [cs.IR])

    [http://arxiv.org/abs/2305.05331](http://arxiv.org/abs/2305.05331)

    该论文提出了一种新的可解释推荐系统模型，将从用户-商品交互中学得的几何先验知识与变分网络相结合，可以为用户提供既具备推荐性能又具有解释性能的解释推荐服务。

    

    可解释的推荐系统能够解释其推荐决策，增强用户对系统的信任。大多数可解释的推荐系统要么依赖于人工标注的原理来训练模型以生成解释，要么利用注意机制从评论中提取重要的文本段落作为解释。提取的原理往往局限于单个评论，可能无法识别评论文本之外的隐含特征。为了避免昂贵的人工注释过程并生成超出单个评论的解释，我们建议将从用户-商品交互中学得的几何先验知识与变分网络相结合，该网络从用户-商品评论中推断潜在因子。单个用户-商品对的潜在因子可用于推荐和解释生成，自然地继承了编码在先验知识中的全局特征。三个电子商务数据集上的实验结果表明，我们的模型在推荐性能和可解释性方面都具有竞争力。

    Explainable recommender systems can explain their recommendation decisions, enhancing user trust in the systems. Most explainable recommender systems either rely on human-annotated rationales to train models for explanation generation or leverage the attention mechanism to extract important text spans from reviews as explanations. The extracted rationales are often confined to an individual review and may fail to identify the implicit features beyond the review text. To avoid the expensive human annotation process and to generate explanations beyond individual reviews, we propose to incorporate a geometric prior learnt from user-item interactions into a variational network which infers latent factors from user-item reviews. The latent factors from an individual user-item pair can be used for both recommendation and explanation generation, which naturally inherit the global characteristics encoded in the prior knowledge. Experimental results on three e-commerce datasets show that our mo
    
[^77]: 构建一份中英双语儿童非母语语音语料库：编制和原理

    Building a Non-native Speech Corpus Featuring Chinese-English Bilingual Children: Compilation and Rationale. (arXiv:2305.00446v1 [cs.CL])

    [http://arxiv.org/abs/2305.00446](http://arxiv.org/abs/2305.00446)

    本文介绍了一份非母语语音语料库，由50名中英双语儿童提供英语（L2）叙述，为第二语言教学提供了有价值的资源并有可能提高自动语音识别（ASR）的整体性能。

    

    本文介绍了一份非母语语音语料库，包含了来自50位5-6岁的中英双语儿童的叙述。提供了总计6.5小时的英语（L2）叙述理解测试的转录文本，以及评分和语法及发音错误的注释。这些孩子还完成了中文（L1）的平行MAIN测试以便进行参考。对于所有测试，我们记录了音频和视频，并采用了自主开发的远程收集方法。视频记录有助于减轻在转录过程中由年幼儿童的L2叙述低可懂性所带来的难度。该语料库为第二语言教学提供了有价值的资源，并有可能提高自动语音识别（ASR）的整体性能。

    This paper introduces a non-native speech corpus consisting of narratives from fifty 5- to 6-year-old Chinese-English children. Transcripts totaling 6.5 hours of children taking a narrative comprehension test in English (L2) are presented, along with human-rated scores and annotations of grammatical and pronunciation errors. The children also completed the parallel MAIN tests in Chinese (L1) for reference purposes. For all tests we recorded audio and video with our innovative self-developed remote collection methods. The video recordings serve to mitigate the challenge of low intelligibility in L2 narratives produced by young children during the transcription process. This corpus offers valuable resources for second language teaching and has the potential to enhance the overall performance of automatic speech recognition (ASR).
    
[^78]: 深层潜在位置主题模型用于带有文本边的网络聚类和表示

    The Deep Latent Position Topic Model for Clustering and Representation of Networks with Textual Edges. (arXiv:2304.08242v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.08242](http://arxiv.org/abs/2304.08242)

    深层潜在位置主题模型用于网络聚类和表示，通过基于模型的聚类策略和概率模型对节点和边进行联合表示，并使用模型选择准则进行参数选择。

    

    数值交互导致用户共享其他人发布的文本内容，这些内容自然地由将个体与节点关联和交换的文本定义为边的网络来表示。为了理解这些异构和复杂的数据结构，将节点聚类为同类群组以及呈现可理解的数据可视化是必要的。为了解决这两个问题，我们引入了Deep-LPTM，这是一种基于模型的聚类策略，依赖于变分图自动编码器方法以及概率模型来描述讨论的主题。Deep-LPTM允许在两个嵌入空间中构建节点和边的联合表示。参数使用变分推断算法进行推断。我们还引入了IC2L，这是一种专门设计用于选择具有相关聚类和可视化属性的模型的模型选择准则。对合成数据进行了广泛的基准测试研究。特别是

    Numerical interactions leading to users sharing textual content published by others are naturally represented by a network where the individuals are associated with the nodes and the exchanged texts with the edges. To understand those heterogeneous and complex data structures, clustering nodes into homogeneous groups as well as rendering a comprehensible visualisation of the data is mandatory. To address both issues, we introduce Deep-LPTM, a model-based clustering strategy relying on a variational graph auto-encoder approach as well as a probabilistic model to characterise the topics of discussion. Deep-LPTM allows to build a joint representation of the nodes and of the edges in two embeddings spaces. The parameters are inferred using a variational inference algorithm. We also introduce IC2L, a model selection criterion specifically designed to choose models with relevant clustering and visualisation properties. An extensive benchmark study on synthetic data is provided. In particular
    
[^79]: 仅仅提示足够了吗？不是的。指导学习的全面和更广阔视角（arXiv：2303.10475v1 [cs.CL]）

    Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning. (arXiv:2303.10475v1 [cs.CL])

    [http://arxiv.org/abs/2303.10475](http://arxiv.org/abs/2303.10475)

    传统的自然语言处理机器学习需要大规模的任务特定示例，但这不适用于任务可能过于复杂或成本过高以进行注释的场景。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。

    

    任务语义可以通过一组输入输出示例或一条文本指令来表达。传统的自然语言处理（NLP）机器学习方法主要依赖于大规模的任务特定示例的可用性。这引起了两个问题：首先，收集任务特定标记示例不适用于任务可能过于复杂或成本过高以进行注释的场景，或者系统需要立即处理新任务。其次，这不是用户友好的，因为最终用户可能更愿意在使用系统之前提供任务描述而不是一组示例。因此，社区对于自然语言处理中新的监督寻求范式--从任务指令学习--越来越感兴趣。尽管取得了令人印象深刻的进展，但社区仍然面临着一些共同的问题。本次调查旨在总结指导学习的当前研究，特别是回答以下问题：

    Task semantics can be expressed by a set of input-to-output examples or a piece of textual instruction. Conventional machine learning approaches for natural language processing (NLP) mainly rely on the availability of large-scale sets of task-specific examples. Two issues arise: first, collecting task-specific labeled examples does not apply to scenarios where tasks may be too complicated or costly to annotate, or the system is required to handle a new task immediately; second, this is not user-friendly since end-users are probably more willing to provide task description rather than a set of examples before using the system. Therefore, the community is paying increasing interest in a new supervision-seeking paradigm for NLP: learning from task instructions. Despite its impressive progress, there are some common issues that the community struggles with. This survey paper tries to summarize the current research on instruction learning, particularly, by answering the following questions:
    
[^80]: LEXTREME：多语言和多任务的法律领域基准

    LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain. (arXiv:2301.13126v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13126](http://arxiv.org/abs/2301.13126)

    LEXTREME是一个多语言和多任务的法律领域基准，该基准提供了11个数据集涵盖24种语言的测评，最佳模型（XLM-R large）在数据集和语言综合评分上均达到了61.3。这使得LEXTREME仍然具有挑战性并且有改进空间。

    

    最近，在transformer架构的显著进展推动下，法律自然语言处理领域取得了惊人的增长。为了衡量进展，精心策划和具有挑战性的基准是至关重要的。然而，大多数基准只能处理英文，而在法律自然语言处理方面尚未有多语言基准可用。此外，许多基准已经饱和，最佳模型明显优于最佳人类，并达到近乎完美的分数。我们调查了法律自然语言处理文献，并选择了11个涵盖24种语言的数据集，创建了LEXTREME。为了进行公平比较，我们提出了两种综合评分，一种基于数据集，一种基于语言。最佳基线模型（XLM-R large）在数据集综合评分和语言综合评分上均达到了61.3。这表明LEXTREME仍然非常具有挑战性，并且为改进留下了充足空间。为了方便研究人员和实践者使用，我们将LEXTREME与所有数据一起发布在huggingface上。

    Lately, propelled by the phenomenal advances around the transformer architecture, the legal NLP field has enjoyed spectacular growth. To measure progress, well curated and challenging benchmarks are crucial. However, most benchmarks are English only and in legal NLP specifically there is no multilingual benchmark available yet. Additionally, many benchmarks are saturated, with the best models clearly outperforming the best humans and achieving near perfect scores. We survey the legal NLP literature and select 11 datasets covering 24 languages, creating LEXTREME. To provide a fair comparison, we propose two aggregate scores, one based on the datasets and one on the languages. The best baseline (XLM-R large) achieves both a dataset aggregate score a language aggregate score of 61.3. This indicates that LEXTREME is still very challenging and leaves ample room for improvement. To make it easy for researchers and practitioners to use, we release LEXTREME on huggingface together with all the
    
[^81]: 评估人机语言模型交互

    Evaluating Human-Language Model Interaction. (arXiv:2212.09746v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09746](http://arxiv.org/abs/2212.09746)

    为了评估人机交互，研究人员开发了一个框架HALIE，该框架捕捉了交互过程、主观体验和偏好概念，并设计了五个任务来涵盖不同形式的交互。

    

    许多语言模型（LM）的实际应用，例如写作辅助和代码自动完成，涉及到人机交互。然而，大多数基准测试都是非交互式的，模型在没有人类参与的情况下产生输出。为了评估人机交互，我们开发了一个新的框架，人机语言交互评估（HALIE），该框架定义了交互式系统的组成部分和设计评估指标时要考虑的维度。与标准的非交互式评估相比，HALIE捕捉到了（i）交互过程，而不仅仅是最终输出；（ii）第一人称主观体验，而不仅仅是第三方评估；（iii）除了质量之外的偏好概念（例如享受和所有权）。然后，我们设计了五个任务，涵盖不同形式的交互：社交对话、问答、填字游戏、摘要和隐喻生成。使用四个最先进的LM（OpenAI的GPT-3的三个变体和AI21 Labs的Jurass）

    Many real-world applications of language models (LMs), such as writing assistance and code autocomplete, involve human-LM interaction. However, most benchmarks are non-interactive in that a model produces output without human involvement. To evaluate human-LM interaction, we develop a new framework, Human-AI Language-based Interaction Evaluation (HALIE), that defines the components of interactive systems and dimensions to consider when designing evaluation metrics. Compared to standard, non-interactive evaluation, HALIE captures (i) the interactive process, not only the final output; (ii) the first-person subjective experience, not just a third-party assessment; and (iii) notions of preference beyond quality (e.g., enjoyment and ownership). We then design five tasks to cover different forms of interaction: social dialogue, question answering, crossword puzzles, summarization, and metaphor generation. With four state-of-the-art LMs (three variants of OpenAI's GPT-3 and AI21 Labs' Jurass
    
[^82]: 通过鼓励一致的基于梯度的解释来改进视觉 grounding

    Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations. (arXiv:2206.15462v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.15462](http://arxiv.org/abs/2206.15462)

    该论文提出了一种名为 AMC 的目标函数，鼓励基于梯度的解释覆盖有注释的感兴趣区域，即编码区域。该方法在提高视觉 grounding 性能方面表现卓越，有望成为视觉 grounding 领域的新进展。

    

    我们提出了一种基于边缘的损失，用于预训练视觉语言模型，鼓励基于梯度的解释与区域级注释保持一致。我们将这个目标称为 Attention Mask Consistency（AMC），并证明它产生了比依赖于区域级注释的模型更优越的视觉 grounding 性能。 AMC 通过鼓励基于梯度的解释掩码，在包含此类注释的图像中，把它们的注意力分数主要集中在注释的感兴趣区域内。特别地，一个在标准视觉-语言建模目标之上用 AMC 训练的模型，在 Flickr30k 视觉 grounding 基准测试中获得了86.59%的最新结果，相比最佳结果获得了5.48%的绝对提升。我们的方法在已建立的指代表达理解基准测试中表现优秀，还提供了额外的好处。

    We propose a margin-based loss for vision-language model pretraining that encourages gradient-based explanations that are consistent with region-level annotations. We refer to this objective as Attention Mask Consistency (AMC) and demonstrate that it produces superior visual grounding performance compared to models that rely instead on region-level annotations for explicitly training an object detector such as Faster R-CNN. AMC works by encouraging gradient-based explanation masks that focus their attention scores mostly within annotated regions of interest for images that contain such annotations. Particularly, a model trained with AMC on top of standard vision-language modeling objectives obtains a state-of-the-art accuracy of 86.59% in the Flickr30k visual grounding benchmark, an absolute improvement of 5.48% when compared to the best previous model. Our approach also performs exceedingly well on established benchmarks for referring expression comprehension and offers the added bene
    
[^83]: 自然语言处理中的标记修改对抗攻击：一项调研

    Token-Modification Adversarial Attacks for Natural Language Processing: A Survey. (arXiv:2103.00676v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2103.00676](http://arxiv.org/abs/2103.00676)

    这项调研对现有的自然语言处理中的标记修改对抗攻击进行了分类和比较，并旨在指导新的研究并推动进一步的攻击组件研究。

    

    现在有很多针对自然语言处理系统的对抗攻击。其中，绝大多数攻击通过修改单个文档标记来实现成功，我们将其称为标记修改攻击。每种标记修改攻击都由一组特定的基本组件定义，例如对攻击者的约束或特定的搜索算法。基于这一观察，我们对现有的标记修改攻击进行调查，并提取每种攻击的组件。我们使用一个与攻击无关的框架来组织我们的调研，从而对该领域进行有效的分类，并方便进行组件比较。本调研旨在指导新的研究人员进入这一领域，并推动对于个体攻击组件的进一步研究。

    There are now many adversarial attacks for natural language processing systems. Of these, a vast majority achieve success by modifying individual document tokens, which we call here a token-modification attack. Each token-modification attack is defined by a specific combination of fundamental components, such as a constraint on the adversary or a particular search algorithm. Motivated by this observation, we survey existing token-modification attacks and extract the components of each. We use an attack-independent framework to structure our survey which results in an effective categorisation of the field and an easy comparison of components. This survey aims to guide new researchers to this field and spark further research into individual attack components.
    

