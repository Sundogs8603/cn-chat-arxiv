# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation.](http://arxiv.org/abs/2310.04408) | RECOMP提出了一种改善检索辅助LMs性能的方法，通过压缩检索到的文档为摘要，降低计算成本，并减轻LMs在长文档中识别相关信息的负担。 |
| [^2] | [Policy-Gradient Training of Language Models for Ranking.](http://arxiv.org/abs/2310.04407) | 该论文提出了一种用于排序的语言模型的策略梯度训练算法Neural PG-RANK，通过将大规模语言模型实例化为Plackett-Luce排名策略，实现了对检索模型的原则性、端到端训练。 |
| [^3] | [Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models.](http://arxiv.org/abs/2310.04406) | 语言代理树搜索（LATS）是一个通用框架，利用大型语言模型（LLMs）的能力在规划、行动和推理方面相互协同，通过使用具有外部反馈的环境，实现更加深思熟虑和适应性的问题解决机制。实验评估表明，LATS在多个领域具有广泛的应用性，特别在编程方面表现出了94.4%的准确率。 |
| [^4] | [Improving Stability in Simultaneous Speech Translation: A Revision-Controllable Decoding Approach.](http://arxiv.org/abs/2310.04399) | 本文提出了一种可控修订的解码方法，用于改善同时语音翻译中的稳定性问题，通过在波束搜索修剪过程中引入修订窗口，筛选出可能引起广泛修订的候选翻译，实现了大幅减少闪烁甚至完全消除闪烁的效果，同时不显著影响翻译质量。 |
| [^5] | [Hermes: Unlocking Security Analysis of Cellular Network Protocols by Synthesizing Finite State Machines from Natural Language Specifications.](http://arxiv.org/abs/2310.04381) | Hermes是一个自动生成有限状态机的端到端框架，用于解锁移动网络协议的安全分析。通过处理自然语言规范并生成逻辑公式，Hermes能够发现新的漏洞和攻击，并对现有规范和商业基带进行评估。 |
| [^6] | [Amortizing intractable inference in large language models.](http://arxiv.org/abs/2310.04363) | 本论文提出了一种使用摊销的贝叶斯推理从难以处理的后验分布中进行抽样的方法，并利用生成流网络来实现大规模语言模型的微调，从而解决了在这些模型中处理推理问题的限制。 |
| [^7] | [Transferring speech-generic and depression-specific knowledge for Alzheimer's disease detection.](http://arxiv.org/abs/2310.04358) | 本文通过同时转移语音通用和抑郁特定的知识，解决了通过自发性语音进行阿尔茨海默病检测时训练数据稀缺的问题，并提出了一个并行的知识转移框架，在AD和抑郁症诊断中取得了改进。 |
| [^8] | [Large-Scale Korean Text Dataset for Classifying Biased Speech in Real-World Online Services.](http://arxiv.org/abs/2310.04313) | 该论文介绍了一个大规模韩文文本数据集，用于分类有偏见言论。通过使用最先进的语言模型，该方法在多项分类任务中实现了超越人类水平的准确性。 |
| [^9] | [A Comprehensive Evaluation of Large Language Models on Benchmark Biomedical Text Processing Tasks.](http://arxiv.org/abs/2310.04270) | 本文对大型语言模型（LLM）在生物医学任务中的性能进行了综合评估，发现零样本LLMs在小样本生物医学数据集上的表现甚至超过了先进的精调生物医学模型，预训练使LLMs在生物医学领域具备了很强的专业能力。 |
| [^10] | [Written and spoken corpus of real and fake social media postings about COVID-19.](http://arxiv.org/abs/2310.04237) | 本研究通过对COVID-19相关推文和TikTok视频的分析，发现了一系列区分真假新闻的语言特征，为理解语言在此方面的作用提供了有价值的洞察。 |
| [^11] | [Keyword Augmented Retrieval: Novel framework for Information Retrieval integrated with speech interface.](http://arxiv.org/abs/2310.04205) | 这项研究工作介绍了一种关键词增强检索框架，该框架通过使用关键词来优化语言模型的上下文发现和答案生成，从而实现了快速、低成本的信息检索和语音接口集成。 |
| [^12] | [mlirSynth: Automatic, Retargetable Program Raising in Multi-Level IR using Program Synthesis.](http://arxiv.org/abs/2310.04196) | mlirSynth采用程序综合的方法，无需手动定义规则即可将低级MLIR方言的程序提升到高级方言，实现了自动且重定向的提升，极大地提高了编译效率。 |
| [^13] | [Automatic Aspect Extraction from Scientific Texts.](http://arxiv.org/abs/2310.04074) | 该论文介绍了一个用于从俄语科学文本中自动提取方面的工具，包括任务、贡献、方法和结论等方面，并提出了基于BERT模型的基准算法。通过跨领域实验证明，即使在有限的科学领域上进行训练，该模型仍能推广到新的领域。 |
| [^14] | [How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation.](http://arxiv.org/abs/2310.04064) | 本文研究了将经典transformer attention泛化到能够捕捉三元相关性的问题，并提出了一个在有界输入下具有近线性时间复杂度的算法。 |
| [^15] | [Analysis of the Reasoning with Redundant Information Provided Ability of Large Language Models.](http://arxiv.org/abs/2310.04039) | 该论文研究了大型语言模型在推理能力上的表现，通过引入一种新的问答任务（RRIP）来评估这些模型在冗余信息提供的推理中的性能。研究发现，尽管这些模型在传统QA任务上表现良好，但在RRIP任务中性能明显下降。 |
| [^16] | [Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models.](http://arxiv.org/abs/2310.04027) | 本文通过引入检索增强型的大型语言模型框架，提升金融情感分析的效果，并解决了传统模型在参数规模和训练数据范围方面的限制。 |
| [^17] | [SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation.](http://arxiv.org/abs/2310.03991) | SemStamp是一种稳健的句级语义水印算法，通过局部敏感哈希将语义空间划分，并使用边界约束增强了其稳健性。实验证明，相比现有方法，SemStamp在释义和bigram方面更为有效。 |
| [^18] | [Dementia Assessment Using Mandarin Speech with an Attention-based Speech Recognition Encoder.](http://arxiv.org/abs/2310.03985) | 本文提出了一个基于注意力的语音识别模型，用于构建一个普通话言语痴呆评估系统。通过训练模型并提取编码器，实现了在阿尔茨海默病检测和临床痴呆评分预测方面的显著提升。 |
| [^19] | [HuBERTopic: Enhancing Semantic Representation of HuBERT through Self-supervision Utilizing Topic Model.](http://arxiv.org/abs/2310.03975) | 本文提出了一种通过利用主题模型的自监督方法来提升HuBERT的语义表示能力的方法。这种方法通过添加一个辅助主题分类任务，将主题标签作为教师，以无监督的方式将全局语义信息融入模型中。实验证明，这种方法能够提升模型的语义表示能力。 |
| [^20] | [Quantized Transformer Language Model Implementations on Edge Devices.](http://arxiv.org/abs/2310.03971) | 在这项研究中，我们评估了将大规模Transformer模型转换为FlatBuffer格式在资源受限的边缘设备上的性能表现，并对其进行了声誉分析任务的微调。 |
| [^21] | [Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models.](http://arxiv.org/abs/2310.03965) | 提出了思维传播（TP）方法，通过探索类比问题和利用类比问题的解决方案来增强大型语言模型的复杂推理能力。 |
| [^22] | [Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations.](http://arxiv.org/abs/2310.03951) | 这项研究提出了一个分层框架，通过自然语言推理链条（CoNLI）来检测和减少大型语言模型（LLMs）的幻觉。该框架不需要对LLMs进行微调或特定领域的提示工程，能够从不同的上下文中实现具有竞争性能的幻觉检测和减少。 |
| [^23] | [Exploring the evolution of research topics during the COVID-19 pandemic.](http://arxiv.org/abs/2310.03928) | 本研究提出了一种用于检查COVID-19科学摘要文本的CORToViz工具，并基于大型语言模型和聚类技术，实现了对科学文章的主题挖掘和可视化分析。 |
| [^24] | [Evaluating Multi-Agent Coordination Abilities in Large Language Models.](http://arxiv.org/abs/2310.03903) | 本研究构建了使用大型语言模型（LLMs）的智能体，并评估其在多智能体协调中的有效性。我们引入了LLM-Co框架，用于在三个游戏环境中评估LLMs的协调能力。评估结果显示LLMs具有推断伙伴意图和理解其行动的能力。 |
| [^25] | [Trustworthy Formal Natural Language Specifications.](http://arxiv.org/abs/2310.03885) | 本文表明了在现有的证明助手中构建支持使用自然语言表达的规范的可能性，从而解决了翻译自然语言规范到正式规范的问题。 |
| [^26] | [Automatic and Human-AI Interactive Text Generation.](http://arxiv.org/abs/2310.03878) | 本教程专注于自然语言生成中的文本到文本生成任务，通过自动化和人机交互的方式，生成修订版的文本，保持原文含义和长度，并满足特定的标准和语言风格要求。 |
| [^27] | [Benchmarking a foundation LLM on its ability to re-label structure names in accordance with the AAPM TG-263 report.](http://arxiv.org/abs/2310.03874) | 本文介绍了使用大型语言模型（LLMs）按照AAPM TG-263标准重新标注结构名称的概念，并建立了一个基准，供未来的研究参考。 |
| [^28] | [Contextualized Structural Self-supervised Learning for Ontology Matching.](http://arxiv.org/abs/2310.03840) | 本研究提出了一种名为LaKERMap的自监督学习OM框架，通过将上下文和结构信息整合到transformer中，捕捉多个结构化上下文，并应用于本体匹配中。 |
| [^29] | [HandMeThat: Human-Robot Communication in Physical and Social Environments.](http://arxiv.org/abs/2310.03779) | HandMeThat是一个综合评估基准，用于在物理和社交环境中理解和遵循人类指令。在该论文中，提出了一个包含10000个人机交互场景的数据集，并评估了不同的基准模型的表现。结果显示离线和在线强化学习算法在该基准上表现不佳，暗示了其中的挑战和困难。 |
| [^30] | [PrIeD-KIE: Towards Privacy Preserved Document Key Information Extraction.](http://arxiv.org/abs/2310.03777) | 本文提出了一种通过使用差分隐私、联邦学习和差分隐私联邦学习的策略，开发隐私保护的关键信息提取系统的方法。实验证明，在私密环境下，可以通过微调大型文档基础模型来获得足够的性能和强大的隐私保证。通过分析各种训练和模型参数的影响，提出了实现最佳隐私-效用权衡的准则。引入了一种新颖的DP-FL算法，可以将全局差分隐私从独立环境扩展到多客户联合环境。 |
| [^31] | [Investigating Alternative Feature Extraction Pipelines For Clinical Note Phenotyping.](http://arxiv.org/abs/2310.03772) | 研究探索了临床记录表型的替代特征提取流程，使用基于BERT模型的方法将临床记录转换为文档表示，并传入LSTM模型，取得了明显的性能改进，但收敛时间较长且不支持增量训练。 |
| [^32] | [GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction.](http://arxiv.org/abs/2310.03668) | GoLLIE 是一个遵循注释指南的大型语言模型，通过微调以改进未见信息抽取任务的零样本结果。 |
| [^33] | [The North System for Formosa Speech Recognition Challenge 2023.](http://arxiv.org/abs/2310.03443) | 本報告提供了北系統的簡要概述，該系統旨在實現對台灣客家語（四縣腔）的自動詞/音節識別。關鍵部分包括訓練數據的獲取、組成和利用，模型的架構，以及硬件規格和運行統計。 |
| [^34] | [Learning Personalized Story Evaluation.](http://arxiv.org/abs/2310.03304) | 该论文提出了学习个性化故事评估的方法。为了解决大型语言模型在开放式文本生成任务的评估问题，论文创建了两个新的数据集，并开发了一个个性化故事评估模型，能够根据评审人员的示例评价进行个性化评估。 |
| [^35] | [Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation.](http://arxiv.org/abs/2310.02842) | 本论文提出了一种使用智能多任务适应混合提示的方法来解决LLM在处理异质任务和数据分布时的问题。研究者设计了智能门控功能，用于识别嵌入在不同提示组中的相关技能，并根据目标任务的需求动态分配组合专家。该方法对任何模型压缩技术都不受限制，提高了任务处理的效率。 |
| [^36] | [Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance.](http://arxiv.org/abs/2310.02107) | 为了提高大型语言模型的零样本性能，本文提出了一种新的方法，通过为每个个别的测试输入重新写作任务提示，使其更具体、明确和完整，从而提供更好的指导，实现了约10%的改进。 |
| [^37] | [Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation.](http://arxiv.org/abs/2310.01320) | 本研究通过使用复杂的Avalon游戏作为测试平台，引入了一种名为递归思考（ReCon）的新框架，用于增强大型语言模型（LLM）识别和对抗欺骗信息的能力。 |
| [^38] | [Enable Language Models to Implicitly Learn Self-Improvement From Data.](http://arxiv.org/abs/2310.00898) | 该论文探索了如何让语言模型隐式学习自我改进，并减少对人类标注的依赖。 |
| [^39] | [BooookScore: A systematic exploration of book-length summarization in the era of LLMs.](http://arxiv.org/abs/2310.00785) | 本文对LLM模型进行了系统探索，以解决对超过上下文窗口大小的书籍进行摘要的问题，并通过两种提示工作流实施了基于LLM的书籍长度摘要器的连贯性研究。通过对100本书的GPT-4生成摘要的人工注释，发现了八种常见的连贯性错误。 |
| [^40] | [Multilingual Natural Language ProcessingModel for Radiology Reports -- The Summary is all you need!.](http://arxiv.org/abs/2310.00100) | 本研究通过在多语言文本到文本变换器模型上微调，开发了一个能够自动在多语言中总结放射学报告的模型。该模型有助于提高未来深度学习模型的研究和发展，且能够应用于不同族裔背景的患者数据。 |
| [^41] | [Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities.](http://arxiv.org/abs/2309.17255) | 这篇论文综述了在生命科学领域中使用知识图谱的最新发展和进展，并展望了这些技术在未来对这些领域的影响。 |
| [^42] | [Hierarchical attention interpretation: an interpretable speech-level transformer for bi-modal depression detection.](http://arxiv.org/abs/2309.13476) | 本文提出了一种双模式语音级变换器，通过引入分层解释方法解决了自动抑郁症检测工具中的标注噪声和模型解释性问题，同时展示了其在性能上的优势。该模型通过梯度加权注意力图追踪输入特征之间的交互作用，可以提供语音级和句子级的解释。 |
| [^43] | [Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract Code Using Vulnerability-constrained Decoding.](http://arxiv.org/abs/2309.09826) | 本研究提出了一种漏洞约束解码方法，通过微调大型语言模型并在解码过程中阻止生成漏洞标记，以高效减少自动完成代码中的漏洞。以以太坊智能合约为案例研究，验证了该方法的有效性。 |
| [^44] | [Answering Subjective Induction Questions on Products by Summarizing Multi-sources Multi-viewpoints Knowledge.](http://arxiv.org/abs/2309.05938) | 本文提出了一个新任务：回答产品的主观归纳问题（SUBJPQA）。与传统的QA任务不同，这类问题的答案是非唯一的，并且需要从多个角度总结多个知识源的主观意见和客观知识来解释。为了解决这个任务，我们提出了一个三步骤的方法，包括信息检索、相关性捕捉和摘要生成。 |
| [^45] | [On Large Language Models' Selection Bias in Multi-Choice Questions.](http://arxiv.org/abs/2309.03882) | 本研究发现大型语言模型在多项选择题中存在选择偏差，即倾向于选择特定位置上的选项。研究指出这一偏差的主要原因是选项编号，提出了一种名为PriDe的方法来减轻偏差，并展示了其高精度和稳定性。 |
| [^46] | [Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection.](http://arxiv.org/abs/2307.16888) | 这项研究介绍了一种针对指令调整的大型语言模型的新型后门攻击方法，即虚拟提示注入（VPI）。通过在特定触发场景下将虚拟提示与用户指令连接，攻击者可以精细操纵模型的回应而无需明确注入。 |
| [^47] | [CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots.](http://arxiv.org/abs/2307.11865) | 本研究使用大型语言模型，探索了在空间规划和导航交叉问题中，通过解析复杂的自然语言指令来执行任务的新方法。 |
| [^48] | [Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning.](http://arxiv.org/abs/2307.10274) | 本研究提出了一种零样本领域敏感语音识别方法，利用文本提示来生成领域敏感模型，通过微调预训练的端到端模型实现。实验结果表明，该方法在不同领域和提示上下文下均取得了良好的性能，词错误率降低达到最高33%。通过仅使用文本进行微调，该模型在医学对话数据集上的识别效果最佳，词错误率降低达到29%。 |
| [^49] | [Large Language Models.](http://arxiv.org/abs/2307.05782) | 这篇论文介绍了大型语言模型的发展历史和现状，详细描述了底层的Transformer架构，并探讨了如何训练模型来实现多种智能任务。 |
| [^50] | [A Simple and Effective Pruning Approach for Large Language Models.](http://arxiv.org/abs/2306.11695) | 本论文提出了一种称为Wanda的新颖、简单而有效的剪枝方法，用于大型语言模型，通过对每个输出上的权重按照最小幅度乘以对应的输入激活来进行剪枝，无需重新训练或更新权重。 |
| [^51] | [Now It Sounds Like You: Learning Personalized Vocabulary On Device.](http://arxiv.org/abs/2305.03584) | 这项研究提出了一种称为“生词扩展”的技术，通过个性化的“生词适配器”来学习个性化词汇，提高了生词覆盖率并显著提高了模型准确度。 |
| [^52] | [Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner.](http://arxiv.org/abs/2305.01711) | 本文研究了持续预训练对于微调性能的影响，发现传统的持续预训练不能保证一致的提高性能，甚至会对一些任务产生负面影响。针对这些问题，作者提出了基于提示的持续预训练，旨在通过无监督的预训练向LM展示任务相关文本和提示模板，从而提高基于提示的微调表现。 |
| [^53] | [Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis.](http://arxiv.org/abs/2302.05608) | 本研究提出了一个可微的异常检测方法来实现鲁棒的深度多模态分析，通过借助明确的知识图谱和交互式的区分外部领域层来过滤噪声。在多个视觉和语言任务中得到了良好的应用效果。 |
| [^54] | [Preserving Semantics in Textual Adversarial Attacks.](http://arxiv.org/abs/2211.04205) | 本文研究了在文本对抗攻击中保持语义的问题，并提出了一个新的句子嵌入技术SPE，可以显著提高对抗攻击的成功率。 |
| [^55] | [TwiRGCN: Temporally Weighted Graph Convolution for Question Answering over Temporal Knowledge Graphs.](http://arxiv.org/abs/2210.06281) | TwiRGCN是一种基于时间加权图卷积的问答系统，通过关联问题的时间段与知识图谱的边来传递信息，使用门控装置来预测答案的类型，并在多跳复杂时间问答数据集上取得显著优势。 |
| [^56] | [AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations.](http://arxiv.org/abs/2205.11023) | AdaptivePaste是一种基于变压器的学习型源代码适应方法，通过学习变量使用模式的有意义表示，可以以高准确率适应源代码。用户研究结果显示，AdaptivePaste能够降低开发时间的浪费。 |
| [^57] | [Vector Space Semantics for Lambek Calculus with Soft Subexponentials.](http://arxiv.org/abs/2111.11331) | 本论文介绍了一种软子指数Lambek演算的向量空间语义，应用于构建委托语缺位名词短语和带有回指和省略的话语单元的组合向量解释，具有很好的应用前景。 |

# 详细

[^1]: RECOMP:通过压缩和选择性增强改善检索辅助LMs

    RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation. (arXiv:2310.04408v1 [cs.CL])

    [http://arxiv.org/abs/2310.04408](http://arxiv.org/abs/2310.04408)

    RECOMP提出了一种改善检索辅助LMs性能的方法，通过压缩检索到的文档为摘要，降低计算成本，并减轻LMs在长文档中识别相关信息的负担。

    

    在推断时，将文档检索并在上下文中前置可以提高语言模型（LMs）在各种任务中的性能。然而，这些文档通常包含数百个词，使推断过程更加昂贵。我们提出将检索到的文档压缩为文本摘要，以降低计算成本，同时减轻LMs在长文档中识别相关信息的负担。我们提出了两种压缩器：一种是从检索文档中选择有用句子的抽取式压缩器，另一种是通过综合多个文档的信息生成摘要的生成式压缩器。这两种压缩器在将生成的摘要前置到LMs的输入时被训练以改善LMs在最终任务上的性能，同时保持摘要简洁。

    Retrieving documents and prepending them in-context at inference time improves performance of language model (LMs) on a wide range of tasks. However, these documents, often spanning hundreds of words, make inference substantially more expensive. We propose compressing the retrieved documents into textual summaries prior to in-context integration. This not only reduces the computational costs but also relieves the burden of LMs to identify relevant information in long retrieved documents. We present two compressors -- an extractive compressor which selects useful sentences from retrieved documents and an abstractive compressor which generates summaries by synthesizing information from multiple documents. Both compressors are trained to improve LMs' performance on end tasks when the generated summaries are prepended to the LMs' input, while keeping the summary concise.If the retrieved documents are irrelevant to the input or offer no additional information to LM, our compressor can retur
    
[^2]: 用于排序的语言模型的策略梯度训练

    Policy-Gradient Training of Language Models for Ranking. (arXiv:2310.04407v1 [cs.CL])

    [http://arxiv.org/abs/2310.04407](http://arxiv.org/abs/2310.04407)

    该论文提出了一种用于排序的语言模型的策略梯度训练算法Neural PG-RANK，通过将大规模语言模型实例化为Plackett-Luce排名策略，实现了对检索模型的原则性、端到端训练。

    

    文本检索在将事实知识纳入到语言处理流程中的决策过程中起着关键作用，从聊天式网页搜索到问答系统。当前最先进的文本检索模型利用预训练的大规模语言模型（LLM）以达到有竞争力的性能，但通过典型的对比损失训练基于LLM的检索器需要复杂的启发式算法，包括选择困难的负样本和使用额外的监督作为学习信号。这种依赖于启发式算法的原因是对比损失本身是启发式的，不能直接优化处理流程末端决策质量的下游指标。为了解决这个问题，我们引入了神经PG-RANK，一种新的训练算法，通过将LLM实例化为Plackett-Luce排名策略，学习排序。神经PG-RANK为检索模型的端到端训练提供了一种原则性方法，作为更大的决策系统的一部分进行训练。

    Text retrieval plays a crucial role in incorporating factual knowledge for decision making into language processing pipelines, ranging from chat-based web search to question answering systems. Current state-of-the-art text retrieval models leverage pre-trained large language models (LLMs) to achieve competitive performance, but training LLM-based retrievers via typical contrastive losses requires intricate heuristics, including selecting hard negatives and using additional supervision as learning signals. This reliance on heuristics stems from the fact that the contrastive loss itself is heuristic and does not directly optimize the downstream metrics of decision quality at the end of the processing pipeline. To address this issue, we introduce Neural PG-RANK, a novel training algorithm that learns to rank by instantiating a LLM as a Plackett-Luce ranking policy. Neural PG-RANK provides a principled method for end-to-end training of retrieval models as part of larger decision systems vi
    
[^3]: 语言代理树搜索统一了语言模型中的推理、行动和规划

    Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models. (arXiv:2310.04406v1 [cs.AI])

    [http://arxiv.org/abs/2310.04406](http://arxiv.org/abs/2310.04406)

    语言代理树搜索（LATS）是一个通用框架，利用大型语言模型（LLMs）的能力在规划、行动和推理方面相互协同，通过使用具有外部反馈的环境，实现更加深思熟虑和适应性的问题解决机制。实验评估表明，LATS在多个领域具有广泛的应用性，特别在编程方面表现出了94.4%的准确率。

    

    虽然大型语言模型（LLMs）在一系列决策任务上表现出了令人印象深刻的性能，但它们依赖于简单的行动过程，并未能广泛部署作为自主代理。我们引入了LATS（语言代理树搜索），这是一个通用框架，将LLMs在规划、行动和推理方面的能力相互协同。LATS借鉴了模型导向的强化学习中的蒙特卡洛树搜索的思想，将LLMs用作代理、价值函数和优化器，重新利用其潜在的优势以提升决策能力。关键的一点是LATS使用一个具有外部反馈的环境，这提供了一种更加深思熟虑和适应性的问题解决机制，超越了现有技术的局限性。我们在编程、HotPotQA和WebShop等多个领域进行了实验评估，证明了LATS在推理和行动方面的适用性。特别是，在编程方面，LATS实现了94.4%的准确率。

    While large language models (LLMs) have demonstrated impressive performance on a range of decision-making tasks, they rely on simple acting processes and fall short of broad deployment as autonomous agents. We introduce LATS (Language Agent Tree Search), a general framework that synergizes the capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration from Monte Carlo tree search in model-based reinforcement learning, LATS employs LLMs as agents, value functions, and optimizers, repurposing their latent strengths for enhanced decision-making. What is crucial in this method is the use of an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism that moves beyond the limitations of existing techniques. Our experimental evaluation across diverse domains, such as programming, HotPotQA, and WebShop, illustrates the applicability of LATS for both reasoning and acting. In particular, LATS achieves 94.4\% for programming on Hu
    
[^4]: 在同时语音翻译中改善稳定性：一种可控修订的解码方法

    Improving Stability in Simultaneous Speech Translation: A Revision-Controllable Decoding Approach. (arXiv:2310.04399v1 [cs.CL])

    [http://arxiv.org/abs/2310.04399](http://arxiv.org/abs/2310.04399)

    本文提出了一种可控修订的解码方法，用于改善同时语音翻译中的稳定性问题，通过在波束搜索修剪过程中引入修订窗口，筛选出可能引起广泛修订的候选翻译，实现了大幅减少闪烁甚至完全消除闪烁的效果，同时不显著影响翻译质量。

    

    同时语音到文本翻译在实时跨语言交流中起着关键作用。尽管近年来取得了一些进展，但在翻译过程中仍然面临稳定性的挑战，主要表现为部分结果的闪烁。在本文中，我们提出了一种新颖的可控修订方法，旨在解决这个问题。我们的方法在波束搜索修剪过程中引入了一个允许的修订窗口，用于筛选出可能造成广泛修订的候选翻译，从而大大减少闪烁，并且关键地提供了完全消除闪烁的能力。实验证明，所提出的方法可以显著改善解码稳定性，同时不大幅度影响翻译质量。

    Simultaneous Speech-to-Text translation serves a critical role in real-time crosslingual communication. Despite the advancements in recent years, challenges remain in achieving stability in the translation process, a concern primarily manifested in the flickering of partial results. In this paper, we propose a novel revision-controllable method designed to address this issue. Our method introduces an allowed revision window within the beam search pruning process to screen out candidate translations likely to cause extensive revisions, leading to a substantial reduction in flickering and, crucially, providing the capability to completely eliminate flickering. The experiments demonstrate the proposed method can significantly improve the decoding stability without compromising substantially on the translation quality.
    
[^5]: Hermes：通过从自然语言规范合成有限状态机来解锁移动网络协议的安全分析

    Hermes: Unlocking Security Analysis of Cellular Network Protocols by Synthesizing Finite State Machines from Natural Language Specifications. (arXiv:2310.04381v1 [cs.CR])

    [http://arxiv.org/abs/2310.04381](http://arxiv.org/abs/2310.04381)

    Hermes是一个自动生成有限状态机的端到端框架，用于解锁移动网络协议的安全分析。通过处理自然语言规范并生成逻辑公式，Hermes能够发现新的漏洞和攻击，并对现有规范和商业基带进行评估。

    

    本文介绍了Hermes，一个自动生成自然语言移动规范的形式表达的端到端框架。我们首先开发了神经组成分析器NEUTREX，用于处理与转换相关的文本并提取转换组件（即状态、条件和动作）。我们还设计了一种领域特定语言，通过利用依存解析树将这些转换组件转化成逻辑公式。最后，我们将这些逻辑公式编译成转换和创建形式模型作为有限状态机。为了证明Hermes的有效性，我们在4G NAS、5G NAS和5G RRC规范上进行评估，并获得了81-87%的总体准确率，这是对现有技术的显著改进。我们对提取的模型进行的安全分析揭示出了3个新的漏洞、发现了19个之前的攻击4G和5G规范，以及7个商业4G基带的偏差。

    In this paper, we present Hermes, an end-to-end framework to automatically generate formal representations from natural language cellular specifications. We first develop a neural constituency parser, NEUTREX, to process transition-relevant texts and extract transition components (i.e., states, conditions, and actions). We also design a domain-specific language to translate these transition components to logical formulas by leveraging dependency parse trees. Finally, we compile these logical formulas to generate transitions and create the formal model as finite state machines. To demonstrate the effectiveness of Hermes, we evaluate it on 4G NAS, 5G NAS, and 5G RRC specifications and obtain an overall accuracy of 81-87%, which is a substantial improvement over the state-of-the-art. Our security analysis of the extracted models uncovers 3 new vulnerabilities and identifies 19 previous attacks in 4G and 5G specifications, and 7 deviations in commercial 4G basebands.
    
[^6]: 在大规模语言模型中摊销难以处理的推理问题

    Amortizing intractable inference in large language models. (arXiv:2310.04363v1 [cs.LG])

    [http://arxiv.org/abs/2310.04363](http://arxiv.org/abs/2310.04363)

    本论文提出了一种使用摊销的贝叶斯推理从难以处理的后验分布中进行抽样的方法，并利用生成流网络来实现大规模语言模型的微调，从而解决了在这些模型中处理推理问题的限制。

    

    自回归的大规模语言模型通过下一个词条件分布来压缩其训练数据中的知识，这限制了对该知识的可处理查询仅限于从头到尾的自回归抽样。然而，许多感兴趣的任务，包括序列延续、填充和其他形式的受约束生成，都涉及从难以处理的后验分布中进行抽样。我们通过使用摊销的贝叶斯推理从这些难以处理的后验分布中进行抽样来解决这个限制。这种摊销通过通过寻求多样性的强化学习算法 - 生成流网络 (GFlowNets) 来微调 LLMs 实现。我们凭经验证明，LLM微调的这种分布匹配范式可以作为最大似然训练和奖励最大化策略优化的有效替代方法。作为一个重要应用，我们将思维链推理解释为潜变量建模问题，并证明了...

    Autoregressive large language models (LLMs) compress knowledge from their training data through next-token conditional distributions. This limits tractable querying of this knowledge to start-to-end autoregressive sampling. However, many tasks of interest -- including sequence continuation, infilling, and other forms of constrained generation -- involve sampling from intractable posterior distributions. We address this limitation by using amortized Bayesian inference to sample from these intractable posteriors. Such amortization is algorithmically achieved by fine-tuning LLMs via diversity-seeking reinforcement learning algorithms: generative flow networks (GFlowNets). We empirically demonstrate that this distribution-matching paradigm of LLM fine-tuning can serve as an effective alternative to maximum-likelihood training and reward-maximizing policy optimization. As an important application, we interpret chain-of-thought reasoning as a latent variable modeling problem and demonstrate 
    
[^7]: 转移语音通用和抑郁特定的知识用于阿尔茨海默病检测

    Transferring speech-generic and depression-specific knowledge for Alzheimer's disease detection. (arXiv:2310.04358v1 [cs.CL])

    [http://arxiv.org/abs/2310.04358](http://arxiv.org/abs/2310.04358)

    本文通过同时转移语音通用和抑郁特定的知识，解决了通过自发性语音进行阿尔茨海默病检测时训练数据稀缺的问题，并提出了一个并行的知识转移框架，在AD和抑郁症诊断中取得了改进。

    

    阿尔茨海默病（AD）是一种通过自发性语音进行检测的疾病，但训练数据的稀缺性仍然是一个重要问题。本文通过知识转移来处理这个问题，具体来说是从语音通用和抑郁特定的知识中进行转移。首先，本文研究了从通用基础模型中进行顺序知识转移，这些模型是在大量语音和文本数据上预训练的。然后，对基于不同基础模型不同中间块提取的表示进行了AD诊断的块分析。除了来自语音通用表示的知识外，本文还提出了同时从基于抑郁症和AD高共病率的语音抑郁检测任务中转移知识的方法。研究了一个并行的知识转移框架，共同学习这两个任务之间的共享信息。实验结果表明，所提出的方法提高了AD和depression的诊断性能。

    The detection of Alzheimer's disease (AD) from spontaneous speech has attracted increasing attention while the sparsity of training data remains an important issue. This paper handles the issue by knowledge transfer, specifically from both speech-generic and depression-specific knowledge. The paper first studies sequential knowledge transfer from generic foundation models pretrained on large amounts of speech and text data. A block-wise analysis is performed for AD diagnosis based on the representations extracted from different intermediate blocks of different foundation models. Apart from the knowledge from speech-generic representations, this paper also proposes to simultaneously transfer the knowledge from a speech depression detection task based on the high comorbidity rates of depression and AD. A parallel knowledge transfer framework is studied that jointly learns the information shared between these two tasks. Experimental results show that the proposed method improves AD and de
    
[^8]: 用于在真实世界在线服务中分类有偏见言论的大规模韩文文本数据集

    Large-Scale Korean Text Dataset for Classifying Biased Speech in Real-World Online Services. (arXiv:2310.04313v1 [cs.CL])

    [http://arxiv.org/abs/2310.04313](http://arxiv.org/abs/2310.04313)

    该论文介绍了一个大规模韩文文本数据集，用于分类有偏见言论。通过使用最先进的语言模型，该方法在多项分类任务中实现了超越人类水平的准确性。

    

    随着在线服务的增长，对高级文本分类算法（如情感分析和有偏文本检测）的需求越来越明显。在线服务的匿名性常常导致有偏见和有害言语的存在，对维护在线社区的健康带来挑战。这种现象在韩国尤其相关，目前尚未广泛研究大规模仇恨言论检测算法。在本文中，我们介绍了一个新的综合、大规模数据集，该数据集是从一个知名的韩国社交网络平台收集而来的。我们提供了包括(1)偏好、(2)低俗语言和(3)九种偏见类型的文本样本的注释，使得能够同时对用户生成的文本进行多任务学习的分类。利用最先进的基于BERT的语言模型，我们的方法在各种指标下超过了人类水平的准确性。

    With the growth of online services, the need for advanced text classification algorithms, such as sentiment analysis and biased text detection, has become increasingly evident. The anonymous nature of online services often leads to the presence of biased and harmful language, posing challenges to maintaining the health of online communities. This phenomenon is especially relevant in South Korea, where large-scale hate speech detection algorithms have not yet been broadly explored. In this paper, we introduce a new comprehensive, large-scale dataset collected from a well-known South Korean SNS platform. Our proposed dataset provides annotations including (1) Preferences, (2) Profanities, and (3) Nine types of Bias for the text samples, enabling multi-task learning for simultaneous classification of user-generated texts. Leveraging state-of-the-art BERT-based language models, our approach surpasses human-level accuracy across diverse classification tasks, as measured by various metrics. 
    
[^9]: 大型语言模型在生物医学文本处理任务中的综合评估

    A Comprehensive Evaluation of Large Language Models on Benchmark Biomedical Text Processing Tasks. (arXiv:2310.04270v1 [cs.CL])

    [http://arxiv.org/abs/2310.04270](http://arxiv.org/abs/2310.04270)

    本文对大型语言模型（LLM）在生物医学任务中的性能进行了综合评估，发现零样本LLMs在小样本生物医学数据集上的表现甚至超过了先进的精调生物医学模型，预训练使LLMs在生物医学领域具备了很强的专业能力。

    

    最近，大型语言模型（LLM）展示了解决各种任务的出色能力。然而，尽管它们在各种任务中取得了成功，但目前还没有研究它们在生物医学领域的能力。因此，本文旨在评估LLMs在基准生物医学任务上的性能。为此，我们对6个不同生物医学任务的26个数据集中的4个热门LLMs进行了综合评估。据我们所知，这是第一篇在生物医学领域对各种LLMs进行广泛评估和比较的研究。有趣的是，根据我们的评估，我们发现在训练集较小的生物医学数据集中，零样本LLMs甚至超过了当前最先进的精调生物医学模型。这表明在大型文本语料库上进行预训练使LLMs在生物医学领域具备了很强的专业能力。我们还发现，在所有任务中没有一个LLM能够胜过其他LLMs。

    Recently, Large Language Models (LLM) have demonstrated impressive capability to solve a wide range of tasks. However, despite their success across various tasks, no prior work has investigated their capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of LLMs on benchmark biomedical tasks. For this purpose, we conduct a comprehensive evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets. To the best of our knowledge, this is the first work that conducts an extensive evaluation and comparison of various LLMs in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot LLMs even outperform the current state-of-the-art fine-tuned biomedical models. This suggests that pretraining on large text corpora makes LLMs quite specialized even in the biomedical domain. We also find that not a single LLM can outperform other LLMs in all tasks, with 
    
[^10]: COVID-19相关真假社交媒体发布的书面和口语语料库

    Written and spoken corpus of real and fake social media postings about COVID-19. (arXiv:2310.04237v1 [cs.CL])

    [http://arxiv.org/abs/2310.04237](http://arxiv.org/abs/2310.04237)

    本研究通过对COVID-19相关推文和TikTok视频的分析，发现了一系列区分真假新闻的语言特征，为理解语言在此方面的作用提供了有价值的洞察。

    

    本研究探讨了假新闻和真实新闻的语言特征。研究分为文本数据和语音数据两个部分。文本数据包括从Patwa等人（2021）的6420条与COVID-19相关的推文中重新筛选出来的3049条推文，其中2161条标记为“真实”，888条标记为“假”。语音数据采集自TikTok，重点关注COVID-19相关视频。研究助理使用可靠来源对每个视频的内容进行事实核查，并将其标记为“真实”、“假”或“可疑”，结果得到了来自200个TikTok视频的91个真实条目和109个假条目的数据，总词数为53,710个词。使用Linguistic Inquiry and Word Count（LIWC）软件分析数据以检测语言数据中的模式。结果表明了区分假新闻和真实新闻的一系列语言特征，无论是在书面数据还是口语数据中。这为了解语言在此方面的作用提供了有价值的洞察。

    This study investigates the linguistic traits of fake news and real news. There are two parts to this study: text data and speech data. The text data for this study consisted of 6420 COVID-19 related tweets re-filtered from Patwa et al. (2021). After cleaning, the dataset contained 3049 tweets, with 2161 labeled as 'real' and 888 as 'fake'. The speech data for this study was collected from TikTok, focusing on COVID-19 related videos. Research assistants fact-checked each video's content using credible sources and labeled them as 'Real', 'Fake', or 'Questionable', resulting in a dataset of 91 real entries and 109 fake entries from 200 TikTok videos with a total word count of 53,710 words. The data was analysed using the Linguistic Inquiry and Word Count (LIWC) software to detect patterns in linguistic data. The results indicate a set of linguistic features that distinguish fake news from real news in both written and speech data. This offers valuable insights into the role of language i
    
[^11]: 关键词增强检索: 集成语音接口的信息检索新框架

    Keyword Augmented Retrieval: Novel framework for Information Retrieval integrated with speech interface. (arXiv:2310.04205v1 [cs.IR])

    [http://arxiv.org/abs/2310.04205](http://arxiv.org/abs/2310.04205)

    这项研究工作介绍了一种关键词增强检索框架，该框架通过使用关键词来优化语言模型的上下文发现和答案生成，从而实现了快速、低成本的信息检索和语音接口集成。

    

    使用语言模型从结构化和非结构化数据的组合中快速、低成本地检索答案，而不产生幻觉，是阻止语言模型在知识检索自动化中应用的一大障碍。当想要集成语音接口时，这一问题变得更加突出。此外，对于商业搜索和聊天机器人应用来说，完全依赖商业大型语言模型（如GPT 3.5等）可能非常昂贵。本文作者通过首先开发基于关键词的搜索框架来解决这个问题，该框架增强了对要提供给大型语言模型的上下文的发现。关键词反过来是由语言模型生成并缓存，以便与查询生成的关键词进行比较。这显著减少了在文档中查找上下文所需的时间和成本。一旦上下文设置好了，语言模型就可以根据为问答定制的提示提供答案。这项研究工作表明，

    Retrieving answers in a quick and low cost manner without hallucinations from a combination of structured and unstructured data using Language models is a major hurdle which prevents employment of Language models in knowledge retrieval automation. This becomes accentuated when one wants to integrate a speech interface. Besides, for commercial search and chatbot applications, complete reliance on commercial large language models (LLMs) like GPT 3.5 etc. can be very costly. In this work, authors have addressed this problem by first developing a keyword based search framework which augments discovery of the context to be provided to the large language model. The keywords in turn are generated by LLM and cached for comparison with keywords generated by LLM against the query raised. This significantly reduces time and cost to find the context within documents. Once the context is set, LLM uses that to provide answers based on a prompt tailored for Q&A. This research work demonstrates that u
    
[^12]: mlirSynth：使用程序综合在多级IR中进行自动、重定向的程序提升

    mlirSynth: Automatic, Retargetable Program Raising in Multi-Level IR using Program Synthesis. (arXiv:2310.04196v1 [cs.PL])

    [http://arxiv.org/abs/2310.04196](http://arxiv.org/abs/2310.04196)

    mlirSynth采用程序综合的方法，无需手动定义规则即可将低级MLIR方言的程序提升到高级方言，实现了自动且重定向的提升，极大地提高了编译效率。

    

    MLIR是一个新兴的针对现代硬件的编译器基础设施，但是如果现有程序是用低级通用语言描述的，无法充分利用MLIR的高性能编译。因此，为了避免手动重写程序，现有方法致力于自动将低级别提升到MLIR中的高级别方言。然而，当前的方法依赖于手动定义的提升规则，这限制了它们的适用性，并且随着MLIR方言的演变，使它们难以维护。我们提出了mlirSynth，一种新颖的方法，它在不需要手动定义规则的情况下，将低级别MLIR方言的程序转换为高级别方言。相反，它利用可用的方言定义构建程序空间，并使用类型约束和等效性有效地搜索。我们通过将C程序提升到两个不同的高级MLIR方言来展示其有效性，这使我们能够使用现有的高级方言特定编译。

    MLIR is an emerging compiler infrastructure for modern hardware, but existing programs cannot take advantage of MLIR's high-performance compilation if they are described in lower-level general purpose languages. Consequently, to avoid programs needing to be rewritten manually, this has led to efforts to automatically raise lower-level to higher-level dialects in MLIR. However, current methods rely on manually-defined raising rules, which limit their applicability and make them challenging to maintain as MLIR dialects evolve.  We present mlirSynth -- a novel approach which translates programs from lower-level MLIR dialects to high-level ones without manually defined rules. Instead, it uses available dialect definitions to construct a program space and searches it effectively using type constraints and equivalences. We demonstrate its effectiveness \revi{by raising C programs} to two distinct high-level MLIR dialects, which enables us to use existing high-level dialect specific compilati
    
[^13]: 从科学文本中自动提取方面

    Automatic Aspect Extraction from Scientific Texts. (arXiv:2310.04074v1 [cs.CL])

    [http://arxiv.org/abs/2310.04074](http://arxiv.org/abs/2310.04074)

    该论文介绍了一个用于从俄语科学文本中自动提取方面的工具，包括任务、贡献、方法和结论等方面，并提出了基于BERT模型的基准算法。通过跨领域实验证明，即使在有限的科学领域上进行训练，该模型仍能推广到新的领域。

    

    能够从科学论文中提取出主要观点、关键见解和其他重要信息（在此称为方面），可能有助于进行科学文献综述的过程。因此，我们的研究目的是创建一个用于从任何领域的俄语科学文本中自动提取方面的工具。在本文中，我们介绍了一个包含俄语科学文本的跨领域数据集，注释有任务、贡献、方法和结论等方面，并提出了一种基于多语言BERT模型在我们的数据上微调的基准算法进行方面提取。我们表明，在不同的领域中方面的表示存在一些差异，但即使我们的模型是在有限数量的科学领域上进行训练的，它仍然能够推广到新的领域，这在跨领域实验中得到了证明。代码和数据集可在 \url{https://github.com/anna-marshalova/automatic-aspect-extraction-from} 获取。

    Being able to extract from scientific papers their main points, key insights, and other important information, referred to here as aspects, might facilitate the process of conducting a scientific literature review. Therefore, the aim of our research is to create a tool for automatic aspect extraction from Russian-language scientific texts of any domain. In this paper, we present a cross-domain dataset of scientific texts in Russian, annotated with such aspects as Task, Contribution, Method, and Conclusion, as well as a baseline algorithm for aspect extraction, based on the multilingual BERT model fine-tuned on our data. We show that there are some differences in aspect representation in different domains, but even though our model was trained on a limited number of scientific domains, it is still able to generalize to new domains, as was proved by cross-domain experiments. The code and the dataset are available at \url{https://github.com/anna-marshalova/automatic-aspect-extraction-from
    
[^14]: 如何捕捉高阶相关性？将矩阵Softmax Attention推广到Kronecker计算。

    How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation. (arXiv:2310.04064v1 [cs.DS])

    [http://arxiv.org/abs/2310.04064](http://arxiv.org/abs/2310.04064)

    本文研究了将经典transformer attention泛化到能够捕捉三元相关性的问题，并提出了一个在有界输入下具有近线性时间复杂度的算法。

    

    在经典的transformer attention方案中，我们给定三个大小为$n \times d$的矩阵$Q, K, V$（查询、键和值标记），目标是计算一个新的大小为$n \times d$的矩阵$D^{-1} \exp(QK^\top) V$，其中$D = \mathrm{diag}( \exp(QK^\top) {\bf 1}_n )$。在这项工作中，我们研究了一种能够捕捉三元相关性的注意力的泛化。这种泛化能够解决关于检测transformers无法解决的三元连接的问题。这种泛化的潜在缺点是，计算似乎更加困难，因为直接的算法在$n$的立方时间内完成。然而，我们证明在有界输入的情况下（实践中经常出现，并且在理论和实践中都有广泛研究），实际上存在一个近线性时间的算法。更准确地说，我们证明有界输入既是快速执行广义计算的必要条件也是充分条件： $\bul

    In the classical transformer attention scheme, we are given three $n \times d$ size matrices $Q, K, V$ (the query, key, and value tokens), and the goal is to compute a new $n \times d$ size matrix $D^{-1} \exp(QK^\top) V$ where $D = \mathrm{diag}( \exp(QK^\top) {\bf 1}_n )$. In this work, we study a generalization of attention which captures triple-wise correlations. This generalization is able to solve problems about detecting triple-wise connections that were shown to be impossible for transformers. The potential downside of this generalization is that it appears as though computations are even more difficult, since the straightforward algorithm requires cubic time in $n$. However, we show that in the bounded-entry setting (which arises in practice, and which is well-studied in both theory and practice), there is actually a near-linear time algorithm. More precisely, we show that bounded entries are both necessary and sufficient for quickly performing generalized computations:  $\bul
    
[^15]: 大型语言模型的冗余信息解释能力分析

    Analysis of the Reasoning with Redundant Information Provided Ability of Large Language Models. (arXiv:2310.04039v1 [cs.CL])

    [http://arxiv.org/abs/2310.04039](http://arxiv.org/abs/2310.04039)

    该论文研究了大型语言模型在推理能力上的表现，通过引入一种新的问答任务（RRIP）来评估这些模型在冗余信息提供的推理中的性能。研究发现，尽管这些模型在传统QA任务上表现良好，但在RRIP任务中性能明显下降。

    

    最近对大型语言模型（LLMs）的研究取得了令人印象深刻的成果，在一系列自然语言处理任务中展示了出色的能力，尤其是在推理方面，这是实现人工通用智能（AGI）的基石。然而，常用的基准测试可能无法完全捕捉到这些模型在真实场景中的推理能力。为了弥补这一差距，引入了一种新的问答（QA）任务形式，称为冗余信息提供的推理（RRIP）。该研究设计了修改版的8K小学数学（GSM-8K）数据集，该数据集有多种变体，专注于冗余信息的不同属性。该研究评估了两种常用的LLMs，LlaMA2-13B-chat和生成预训练变压器3.5（GPT-3.5），对比了它们在传统QA任务和RRIP任务中的表现。结果表明，尽管这些模型在标准QA基准测试中取得了适度的成功，但它们的性能明显下降了。

    Recent advancements in Large Language Models (LLMs) have demonstrated impressive capabilities across a range of natural language processing tasks, especially in reasoning, a cornerstone for achieving Artificial General Intelligence (AGI). However, commonly used benchmarks may not fully encapsulate the inferential abilities of these models in real-world scenarios. To address this gap, a new form of Question-Answering (QA) task, termed Reasoning with Redundant Information Provided (RRIP), is introduced. The study designed a modified version of the grade school math 8K (GSM-8K) dataset which has several variants focusing on different attributes of redundant information. This investigation evaluates two popular LLMs, LlaMA2-13B-chat and generative pre-trained transformer 3.5 (GPT-3.5), contrasting their performance on traditional QA tasks against the RRIP tasks. Findings indicate that while these models achieved moderate success on standard QA benchmarks, their performance notably declines
    
[^16]: 通过检索增强的大型语言模型提升金融情感分析

    Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models. (arXiv:2310.04027v1 [cs.CL])

    [http://arxiv.org/abs/2310.04027](http://arxiv.org/abs/2310.04027)

    本文通过引入检索增强型的大型语言模型框架，提升金融情感分析的效果，并解决了传统模型在参数规模和训练数据范围方面的限制。

    

    金融情感分析对于估值和投资决策至关重要。然而，传统的自然语言处理模型受其参数规模和训练数据集范围的限制，其泛化能力和在该领域的有效性受到了限制。最近，以广泛语料库进行预训练的大型语言模型（LLMs）由于其令人称赞的零样本能力，在各种自然语言处理任务中展示了优越的性能。然而，直接将LLMs应用于金融情感分析存在挑战：LLMs的预训练目标与情感标签预测之间的差异可能会 compromise其预测性能。此外，金融新闻的简洁性，常常缺乏足够的上下文，也可能会显著降低LLMs的情感分析可靠性。为了解决这些挑战，我们提出了一个用于金融情感分析的检索增强型LLMs框架。

    Financial sentiment analysis is critical for valuation and investment decision-making. Traditional NLP models, however, are limited by their parameter size and the scope of their training datasets, which hampers their generalization capabilities and effectiveness in this field. Recently, Large Language Models (LLMs) pre-trained on extensive corpora have demonstrated superior performance across various NLP tasks due to their commendable zero-shot abilities. Yet, directly applying LLMs to financial sentiment analysis presents challenges: The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs' sentiment analysis. To address these challenges, we introduce a retrieval-augmented LLMs framework for financial sentiment analysis. This framework includes an instruction-tuned L
    
[^17]: SemStamp：一种具有释义稳健性的文本生成语义水印

    SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation. (arXiv:2310.03991v1 [cs.CL])

    [http://arxiv.org/abs/2310.03991](http://arxiv.org/abs/2310.03991)

    SemStamp是一种稳健的句级语义水印算法，通过局部敏感哈希将语义空间划分，并使用边界约束增强了其稳健性。实验证明，相比现有方法，SemStamp在释义和bigram方面更为有效。

    

    现有的水印算法由于其基于令牌级别的设计，对释义攻击具有弱点。为了解决这个问题，我们提出了一种基于局部敏感哈希（LSH）的稳健句级语义水印算法——SemStamp，该算法对句子的语义空间进行划分。算法对由LLM生成的候选句子进行编码和LSH哈希，并在语义嵌入空间中执行句级拒绝采样，直到采样的句子落入水印分区中。采用基于边界的约束来增强其稳健性。为了展示我们算法的优势，我们提出了一种名为"bigram"的释义攻击，使用与原始句子最少的bigram重叠的释义。实验结果表明，我们的新颖语义水印算法不仅在常见的释义和bigram上比之前的最先进方法更稳健。

    Existing watermarking algorithms are vulnerable to paraphrase attacks because of their token-level design. To address this issue, we propose SemStamp, a robust sentence-level semantic watermarking algorithm based on locality-sensitive hashing (LSH), which partitions the semantic space of sentences. The algorithm encodes and LSH-hashes a candidate sentence generated by an LLM, and conducts sentence-level rejection sampling until the sampled sentence falls in watermarked partitions in the semantic embedding space. A margin-based constraint is used to enhance its robustness. To show the advantages of our algorithm, we propose a "bigram" paraphrase attack using the paraphrase that has the fewest bigram overlaps with the original sentence. This attack is shown to be effective against the existing token-level watermarking method. Experimental results show that our novel semantic watermark algorithm is not only more robust than the previous state-of-the-art method on both common and bigram pa
    
[^18]: 使用基于注意力的语音识别编码器进行普通话言语的痴呆评估

    Dementia Assessment Using Mandarin Speech with an Attention-based Speech Recognition Encoder. (arXiv:2310.03985v1 [cs.CL])

    [http://arxiv.org/abs/2310.03985](http://arxiv.org/abs/2310.03985)

    本文提出了一个基于注意力的语音识别模型，用于构建一个普通话言语痴呆评估系统。通过训练模型并提取编码器，实现了在阿尔茨海默病检测和临床痴呆评分预测方面的显著提升。

    

    痴呆诊断需要一系列不同的测试方法，这是复杂且耗时的。痴呆的早期检测非常重要，因为它可以防止病情进一步恶化。本文利用语音识别模型构建了一个针对普通话使用者在图片描述任务中的痴呆评估系统。通过在与真实世界情境非常相似的语音数据上训练基于注意力的语音识别模型，我们显著提高了模型的识别能力。随后，我们从语音识别模型中提取编码器，并添加了一个线性层用于痴呆评估。我们收集了来自99名被试的普通话语音数据，并从当地医院获取了他们的临床评估数据。在阿尔茨海默病检测中，我们实现了92.04%的准确性，并在临床痴呆评分预测中达到了9%的平均绝对误差。

    Dementia diagnosis requires a series of different testing methods, which is complex and time-consuming. Early detection of dementia is crucial as it can prevent further deterioration of the condition. This paper utilizes a speech recognition model to construct a dementia assessment system tailored for Mandarin speakers during the picture description task. By training an attention-based speech recognition model on voice data closely resembling real-world scenarios, we have significantly enhanced the model's recognition capabilities. Subsequently, we extracted the encoder from the speech recognition model and added a linear layer for dementia assessment. We collected Mandarin speech data from 99 subjects and acquired their clinical assessments from a local hospital. We achieved an accuracy of 92.04% in Alzheimer's disease detection and a mean absolute error of 9% in clinical dementia rating score prediction.
    
[^19]: 通过利用主题模型的自监督方法提升HuBERT的语义表示能力

    HuBERTopic: Enhancing Semantic Representation of HuBERT through Self-supervision Utilizing Topic Model. (arXiv:2310.03975v1 [cs.SD])

    [http://arxiv.org/abs/2310.03975](http://arxiv.org/abs/2310.03975)

    本文提出了一种通过利用主题模型的自监督方法来提升HuBERT的语义表示能力的方法。这种方法通过添加一个辅助主题分类任务，将主题标签作为教师，以无监督的方式将全局语义信息融入模型中。实验证明，这种方法能够提升模型的语义表示能力。

    

    最近，自监督学习方法在各种下游任务中的有用性得到了证实。其中许多模型，如HuBERT和WavLM，使用从谱特征或模型自身的表示特征生成的伪标签。根据以前的研究，伪标签包含语义信息。然而，HuBERT的学习准则遮蔽预测任务专注于局部上下文信息，可能未能有效利用全局语义信息，如说话人、演讲主题等。本文提出了一种新方法来丰富HuBERT的语义表示。我们将主题模型应用于伪标签，为每个话语生成一个主题标签。通过使用主题标签作为教师，向HuBERT添加了一个辅助主题分类任务。这样可以以无监督的方式融入更多的全局语义信息。实验证明，我们的方法可以提升模型的语义表示能力。

    Recently, the usefulness of self-supervised representation learning (SSRL) methods has been confirmed in various downstream tasks. Many of these models, as exemplified by HuBERT and WavLM, use pseudo-labels generated from spectral features or the model's own representation features. From previous studies, it is known that the pseudo-labels contain semantic information. However, the masked prediction task, the learning criterion of HuBERT, focuses on local contextual information and may not make effective use of global semantic information such as speaker, theme of speech, and so on. In this paper, we propose a new approach to enrich the semantic representation of HuBERT. We apply topic model to pseudo-labels to generate a topic label for each utterance. An auxiliary topic classification task is added to HuBERT by using topic labels as teachers. This allows additional global semantic information to be incorporated in an unsupervised manner. Experimental results demonstrate that our meth
    
[^20]: 边缘设备上的量化Transformer语言模型实现

    Quantized Transformer Language Model Implementations on Edge Devices. (arXiv:2310.03971v1 [cs.CL])

    [http://arxiv.org/abs/2310.03971](http://arxiv.org/abs/2310.03971)

    在这项研究中，我们评估了将大规模Transformer模型转换为FlatBuffer格式在资源受限的边缘设备上的性能表现，并对其进行了声誉分析任务的微调。

    

    大规模基于Transformer的模型，如双向编码器Transformer（BERT），被广泛用于自然语言处理（NLP）应用中。这些模型首先通过大规模语料库进行预训练，然后对下游NLP任务进行微调。这些大规模模型的一个主要限制是它们不能在资源受限的设备上部署，因为其模型大小较大且推理延迟增加。为了克服这些限制，可以将这些大规模模型转换为优化的FlatBuffer格式，以便在资源受限的边缘设备上部署。在本研究中，我们评估了转换为FlatBuffer的MobileBERT模型在三种不同边缘设备上的性能，并对其进行了针对RepLab 2013数据集中英语推文的声誉分析进行微调。此外，该研究还评估了部署模型的延迟，性能等指标。

    Large-scale transformer-based models like the Bidirectional Encoder Representations from Transformers (BERT) are widely used for Natural Language Processing (NLP) applications, wherein these models are initially pre-trained with a large corpus with millions of parameters and then fine-tuned for a downstream NLP task. One of the major limitations of these large-scale models is that they cannot be deployed on resource-constrained devices due to their large model size and increased inference latency. In order to overcome these limitations, such large-scale models can be converted to an optimized FlatBuffer format, tailored for deployment on resource-constrained edge devices. Herein, we evaluate the performance of such FlatBuffer transformed MobileBERT models on three different edge devices, fine-tuned for Reputation analysis of English language tweets in the RepLab 2013 dataset. In addition, this study encompassed an evaluation of the deployed models, wherein their latency, performance, a
    
[^21]: 思维传播：一种通过类比方法进行大型语言模型复杂推理的方法

    Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models. (arXiv:2310.03965v1 [cs.AI])

    [http://arxiv.org/abs/2310.03965](http://arxiv.org/abs/2310.03965)

    提出了思维传播（TP）方法，通过探索类比问题和利用类比问题的解决方案来增强大型语言模型的复杂推理能力。

    

    大型语言模型（LLMs）在推理任务中取得了显著的成功，但现有的提示方法无法重用解决类似问题的见解，并且在多步推理中累积了错误，因为它们要求LLMs从零开始推理。为了解决这些问题，我们提出了“思维传播”（TP），它探索类似问题并利用它们的解决方案来增强LLMs的复杂推理能力。这些类比问题与输入问题相关，具有可重用的解决方案和问题解决策略。因此，将解决先前类似问题的见解传播以激发新的问题解决是有希望的。为了实现这一点，TP首先提示LLMs提出并解决一组与输入问题相关的类比问题。然后，TP重用类比问题的结果直接产生一个新的解决方案或者推导一个知识密集型计划。

    Large Language Models (LLMs) have achieved remarkable success in reasoning tasks with the development of prompting methods. However, existing prompting approaches cannot reuse insights of solving similar problems and suffer from accumulated errors in multi-step reasoning, since they prompt LLMs to reason \textit{from scratch}. To address these issues, we propose \textbf{\textit{Thought Propagation} (TP)}, which explores the analogous problems and leverages their solutions to enhance the complex reasoning ability of LLMs. These analogous problems are related to the input one, with reusable solutions and problem-solving strategies. Thus, it is promising to propagate insights of solving previous analogous problems to inspire new problem-solving. To achieve this, TP first prompts LLMs to propose and solve a set of analogous problems that are related to the input one. Then, TP reuses the results of analogous problems to directly yield a new solution or derive a knowledge-intensive plan for 
    
[^22]: 自然语言推理链条用于减少大型语言模型无根幻觉

    Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations. (arXiv:2310.03951v1 [cs.CL])

    [http://arxiv.org/abs/2310.03951](http://arxiv.org/abs/2310.03951)

    这项研究提出了一个分层框架，通过自然语言推理链条（CoNLI）来检测和减少大型语言模型（LLMs）的幻觉。该框架不需要对LLMs进行微调或特定领域的提示工程，能够从不同的上下文中实现具有竞争性能的幻觉检测和减少。

    

    当给定相关文档作为背景上下文时，大型语言模型（LLMs）能够生成流利的自然语言文本。这种能力引起了人们对LLMs在工业应用中的广泛关注。然而，LLMs容易产生没有提供来源支持的幻觉。在本文中，我们提出了一个分层框架来检测和减少这种无根幻觉。我们的框架使用自然语言推理链条（CoNLI）进行幻觉检测，并通过后期编辑进行幻觉减少。我们的方法在幻觉检测方面取得了最先进的性能，并且通过重写增强文本质量，使用LLMs而无需进行任何微调或特定领域的提示工程。我们展示了这个简单的即插即用框架可以作为幻觉检测和减少的有效选择，在各种情境下实现了竞争性能。

    Large language models (LLMs) can generate fluent natural language texts when given relevant documents as background context. This ability has attracted considerable interest in developing industry applications of LLMs. However, LLMs are prone to generate hallucinations that are not supported by the provided sources. In this paper, we propose a hierarchical framework to detect and mitigate such ungrounded hallucination. Our framework uses Chain of Natural Language Inference (CoNLI) for hallucination detection and hallucination reduction via post-editing. Our approach achieves state-of-the-art performance on hallucination detection and enhances text quality through rewrite, using LLMs without any fine-tuning or domain-specific prompt engineering. We show that this simple plug-and-play framework can serve as an effective choice for hallucination detection and reduction, achieving competitive performance across various contexts.
    
[^23]: 探索COVID-19大流行期间研究主题的演化

    Exploring the evolution of research topics during the COVID-19 pandemic. (arXiv:2310.03928v1 [cs.CL])

    [http://arxiv.org/abs/2310.03928](http://arxiv.org/abs/2310.03928)

    本研究提出了一种用于检查COVID-19科学摘要文本的CORToViz工具，并基于大型语言模型和聚类技术，实现了对科学文章的主题挖掘和可视化分析。

    

    COVID-19大流行改变了大多数科学界的研究议程，导致在医学、病毒学、流行病学、经济学、心理学等众多领域产生了大量的研究文章。建立了几个开放获取的语料库和文献集散地，其中COVID-19开放研究数据集（CORD-19）系统地收集了2.5年的科学贡献，总共收集和索引了100多万篇文章。我们在这里提出了CORD-19主题可视化工具（CORToViz），这是一种用于检查CORD-19科学摘要文本语料库的方法和相关可视化工具。我们的方法基于对最新技术（包括大型语言模型）的精心选择，从而形成了一种用于沿着正交维度聚类文章和时间主题挖掘的架构。主题检查得到了一个交互式仪表板的支持，提供了快速、一键式的可视化功能。

    The COVID-19 pandemic has changed the research agendas of most scientific communities, resulting in an overwhelming production of research articles in a variety of domains, including medicine, virology, epidemiology, economy, psychology, and so on. Several open-access corpora and literature hubs were established; among them, the COVID-19 Open Research Dataset (CORD-19) has systematically gathered scientific contributions for 2.5 years, by collecting and indexing over one million articles. Here, we present the CORD-19 Topic Visualizer (CORToViz), a method and associated visualization tool for inspecting the CORD-19 textual corpus of scientific abstracts. Our method is based upon a careful selection of up-to-date technologies (including large language models), resulting in an architecture for clustering articles along orthogonal dimensions and extraction techniques for temporal topic mining. Topic inspection is supported by an interactive dashboard, providing fast, one-click visualizatio
    
[^24]: 在大型语言模型中评估多智能体协调能力

    Evaluating Multi-Agent Coordination Abilities in Large Language Models. (arXiv:2310.03903v1 [cs.CL])

    [http://arxiv.org/abs/2310.03903](http://arxiv.org/abs/2310.03903)

    本研究构建了使用大型语言模型（LLMs）的智能体，并评估其在多智能体协调中的有效性。我们引入了LLM-Co框架，用于在三个游戏环境中评估LLMs的协调能力。评估结果显示LLMs具有推断伙伴意图和理解其行动的能力。

    

    当代人工智能研究的一个重要目标是开发能够熟练进行多智能体协调、有效与人类和其他系统合作的智能体。大型语言模型（LLM）以其显著的理解、生成和解释语言的能力成为开发这种智能体的有希望的候选模型。本研究中，我们构建了使用LLM构建的智能体，并评估其在各种协调场景中的有效性。我们引入了特别设计的LLM-Co框架，使LLM能够参与协调游戏。通过LLM-Co框架，我们在三个游戏环境中进行评估，并将评估分为五个方面：心智理论、情境推理、持续协调、对合作伙伴的稳健性和明确辅助。首先，心智理论和情境推理的评估揭示了LLM推断伙伴意图和理解其行动的能力。

    A pivotal aim in contemporary AI research is to develop agents proficient in multi-agent coordination, enabling effective collaboration with both humans and other systems. Large Language Models (LLMs), with their notable ability to understand, generate, and interpret language in a human-like manner, stand out as promising candidates for the development of such agents. In this study, we build and assess the effectiveness of agents crafted using LLMs in various coordination scenarios. We introduce the LLM-Coordination (LLM-Co) Framework, specifically designed to enable LLMs to play coordination games. With the LLM-Co framework, we conduct our evaluation with three game environments and organize the evaluation into five aspects: Theory of Mind, Situated Reasoning, Sustained Coordination, Robustness to Partners, and Explicit Assistance. First, the evaluation of the Theory of Mind and Situated Reasoning reveals the capabilities of LLM to infer the partner's intention and reason actions acco
    
[^25]: 可信的正式自然语言规范

    Trustworthy Formal Natural Language Specifications. (arXiv:2310.03885v1 [cs.PL])

    [http://arxiv.org/abs/2310.03885](http://arxiv.org/abs/2310.03885)

    本文表明了在现有的证明助手中构建支持使用自然语言表达的规范的可能性，从而解决了翻译自然语言规范到正式规范的问题。

    

    交互证明助手是精心构建的计算机程序，用于高度可信地检查人设计的数学证明的实现。然而，这只验证了一个正式声明的真实性，该声明可能已经从自然语言中的一个声明中被错误地翻译。当使用证明助手在自然语言规范方面正式验证软件的正确性时，这尤其是有问题的。从非正式到正式的翻译仍然是一个具有挑战性、耗时的过程，难以审计其正确性。本文展示了在现有的证明助手中构建支持使用自然语言表达的规范的可能性，这与建立证明助手自身的信任和可审计性的原则一致。我们实现了一种方法，可以使用可模块化可扩展的英语形式子集提供规范，并自动将其翻译为正式的c

    Interactive proof assistants are computer programs carefully constructed to check a human-designed proof of a mathematical claim with high confidence in the implementation. However, this only validates truth of a formal claim, which may have been mistranslated from a claim made in natural language. This is especially problematic when using proof assistants to formally verify the correctness of software with respect to a natural language specification. The translation from informal to formal remains a challenging, time-consuming process that is difficult to audit for correctness.  This paper shows that it is possible to build support for specifications written in expressive subsets of natural language, within existing proof assistants, consistent with the principles used to establish trust and auditability in proof assistants themselves. We implement a means to provide specifications in a modularly extensible formal subset of English, and have them automatically translated into formal c
    
[^26]: 自动化和人机交互的文本生成

    Automatic and Human-AI Interactive Text Generation. (arXiv:2310.03878v1 [cs.CL])

    [http://arxiv.org/abs/2310.03878](http://arxiv.org/abs/2310.03878)

    本教程专注于自然语言生成中的文本到文本生成任务，通过自动化和人机交互的方式，生成修订版的文本，保持原文含义和长度，并满足特定的标准和语言风格要求。

    

    在本教程中，我们专注于文本到文本生成，一类自然语言生成（NLG）任务，它以一段文本作为输入，然后生成一个按照特定标准改进的修订版（例如可读性或语言风格），同时在很大程度上保留原文的含义和长度。这包括许多有用的应用，如文本简化、改写生成、风格转移等。与文本摘要和开放式文本完成（例如故事）相比，我们在本教程中讨论的文本到文本生成任务在语义一致性和目标语言风格方面更加约束。这种控制水平使得这些任务成为研究模型生成既语义恰当又符合风格要求的文本能力的理想试验台。此外，从技术角度来看，这些任务很有趣，因为它们需要复杂的词汇和句法转换的组合。

    In this tutorial, we focus on text-to-text generation, a class of natural language generation (NLG) tasks, that takes a piece of text as input and then generates a revision that is improved according to some specific criteria (e.g., readability or linguistic styles), while largely retaining the original meaning and the length of the text. This includes many useful applications, such as text simplification, paraphrase generation, style transfer, etc. In contrast to text summarization and open-ended text completion (e.g., story), the text-to-text generation tasks we discuss in this tutorial are more constrained in terms of semantic consistency and targeted language styles. This level of control makes these tasks ideal testbeds for studying the ability of models to generate text that is both semantically adequate and stylistically appropriate. Moreover, these tasks are interesting from a technical standpoint, as they require complex combinations of lexical and syntactical transformations,
    
[^27]: 基准测试基于AAPM TG-263报告的基础LLM在重新标注结构名称方面的能力

    Benchmarking a foundation LLM on its ability to re-label structure names in accordance with the AAPM TG-263 report. (arXiv:2310.03874v1 [physics.med-ph])

    [http://arxiv.org/abs/2310.03874](http://arxiv.org/abs/2310.03874)

    本文介绍了使用大型语言模型（LLMs）按照AAPM TG-263标准重新标注结构名称的概念，并建立了一个基准，供未来的研究参考。

    

    目的：介绍使用大型语言模型（LLM）按照美国医学物理学会（AAPM）任务组（TG）-263标准重新标注结构名称的概念，并为未来的研究建立基准参考。方法和材料：实现了生成式预训练转换器（GPT）-4应用程序接口（API）作为数字影像与通信医学（DICOM）存储服务器，该服务器在接收到结构集DICOM文件时，提示GPT-4根据AAPM TG-263重新标注目标体积和正常组织的结构名称。选择了前列腺、头颈部和胸部三个疾病部位进行评估。对于每个疾病部位类别，随机选择了150名患者进行手动调整指令提示（每批50名）和随机选择了50名患者进行评估。考虑的结构名称是最有可能相关的名称。

    Purpose: To introduce the concept of using large language models (LLMs) to re-label structure names in accordance with the American Association of Physicists in Medicine (AAPM) Task Group (TG)-263 standard, and to establish a benchmark for future studies to reference.  Methods and Materials: The Generative Pre-trained Transformer (GPT)-4 application programming interface (API) was implemented as a Digital Imaging and Communications in Medicine (DICOM) storage server, which upon receiving a structure set DICOM file, prompts GPT-4 to re-label the structure names of both target volumes and normal tissues according to the AAPM TG-263. Three disease sites, prostate, head and neck, and thorax were selected for evaluation. For each disease site category, 150 patients were randomly selected for manually tuning the instructions prompt (in batches of 50) and 50 patients were randomly selected for evaluation. Structure names that were considered were those that were most likely to be relevant for
    
[^28]: 上下文化的结构化自监督学习用于本体匹配

    Contextualized Structural Self-supervised Learning for Ontology Matching. (arXiv:2310.03840v1 [cs.LG])

    [http://arxiv.org/abs/2310.03840](http://arxiv.org/abs/2310.03840)

    本研究提出了一种名为LaKERMap的自监督学习OM框架，通过将上下文和结构信息整合到transformer中，捕捉多个结构化上下文，并应用于本体匹配中。

    

    本体匹配（OM）涉及在两个或多个知识图中识别概念之间的语义关系，并作为整合来自各种来源的知识图的关键步骤。最近深度OM模型的进展已经利用了基于transformer的语言模型的能力和知识图嵌入的优势。然而，这些OM模型仍然面临着持续的挑战，如缺乏参考对齐、运行时延迟和未开发的内部不同图结构等。在本研究中，我们引入了一种新颖的自监督学习OM框架，名为LaKERMap，该框架利用概念的上下文和结构信息，将隐式知识整合到transformer中。具体而言，我们旨在通过采用不同的训练目标捕捉多个结构化上下文，包括局部和全局交互。为了评估我们的方法，我们利用了Bio-ML数据集。

    Ontology matching (OM) entails the identification of semantic relationships between concepts within two or more knowledge graphs (KGs) and serves as a critical step in integrating KGs from various sources. Recent advancements in deep OM models have harnessed the power of transformer-based language models and the advantages of knowledge graph embedding. Nevertheless, these OM models still face persistent challenges, such as a lack of reference alignments, runtime latency, and unexplored different graph structures within an end-to-end framework. In this study, we introduce a novel self-supervised learning OM framework with input ontologies, called LaKERMap. This framework capitalizes on the contextual and structural information of concepts by integrating implicit knowledge into transformers. Specifically, we aim to capture multiple structural contexts, encompassing both local and global interactions, by employing distinct training objectives. To assess our methods, we utilize the Bio-ML 
    
[^29]: HandMeThat: 在物理和社交环境中的人机交流

    HandMeThat: Human-Robot Communication in Physical and Social Environments. (arXiv:2310.03779v1 [cs.AI])

    [http://arxiv.org/abs/2310.03779](http://arxiv.org/abs/2310.03779)

    HandMeThat是一个综合评估基准，用于在物理和社交环境中理解和遵循人类指令。在该论文中，提出了一个包含10000个人机交互场景的数据集，并评估了不同的基准模型的表现。结果显示离线和在线强化学习算法在该基准上表现不佳，暗示了其中的挑战和困难。

    

    我们介绍了HandMeThat，一个用于物理和社交环境中指令理解和遵循的综合评估基准。与先前的数据集主要关注语言依存和规划不同，HandMeThat考虑了基于物理（物体状态和关系）和社交（人类行动和目标）信息的含有歧义的人类指令的解决方案。HandMeThat包含了10000个人机交互的场景。在每个场景中，机器人首先观察到人类行动的轨迹以达到内部目标。接下来，机器人接收到人类指令，并根据指令采取行动以完成子目标。在本文中，我们提出了一个用于我们基准测试的文本界面，机器人通过文本命令与虚拟环境交互。我们评估了HandMeThat上的几个基准模型，并显示离线和在线强化学习算法在HandMeThat上表现不佳，表明其中存在重要的挑战和困难。

    We introduce HandMeThat, a benchmark for a holistic evaluation of instruction understanding and following in physical and social environments. While previous datasets primarily focused on language grounding and planning, HandMeThat considers the resolution of human instructions with ambiguities based on the physical (object states and relations) and social (human actions and goals) information. HandMeThat contains 10,000 episodes of human-robot interactions. In each episode, the robot first observes a trajectory of human actions towards her internal goal. Next, the robot receives a human instruction and should take actions to accomplish the subgoal set through the instruction. In this paper, we present a textual interface for our benchmark, where the robot interacts with a virtual environment through textual commands. We evaluate several baseline models on HandMeThat, and show that both offline and online reinforcement learning algorithms perform poorly on HandMeThat, suggesting signif
    
[^30]: PrIeD-KIE: 实现隐私保护的文档关键信息提取

    PrIeD-KIE: Towards Privacy Preserved Document Key Information Extraction. (arXiv:2310.03777v1 [cs.CL])

    [http://arxiv.org/abs/2310.03777](http://arxiv.org/abs/2310.03777)

    本文提出了一种通过使用差分隐私、联邦学习和差分隐私联邦学习的策略，开发隐私保护的关键信息提取系统的方法。实验证明，在私密环境下，可以通过微调大型文档基础模型来获得足够的性能和强大的隐私保证。通过分析各种训练和模型参数的影响，提出了实现最佳隐私-效用权衡的准则。引入了一种新颖的DP-FL算法，可以将全局差分隐私从独立环境扩展到多客户联合环境。

    

    本文介绍了通过利用大型预训练文档基础模型与差分隐私（DP）、联邦学习（FL）和差分隐私联邦学习（DP-FL）相结合的策略，开发隐私保护的关键信息提取（KIE）系统的方法。通过在六个基准数据集（FUNSD、CORD、SROIE、WildReceipts、XFUND和DOCILE）上进行广泛实验证明，在私密环境下，可以有效地微调大型文档基础模型以实现足够的性能并保持强大的隐私保证。此外，通过深入分析各种训练和模型参数对模型性能的影响，我们提出了实现KIE任务在全局DP下最佳隐私-效用权衡的简单而有效的准则。最后，我们引入了FeAm-DP，一种新颖的DP-FL算法，可以将全局DP从独立环境有效地扩展到多客户联合环境。

    In this paper, we introduce strategies for developing private Key Information Extraction (KIE) systems by leveraging large pretrained document foundation models in conjunction with differential privacy (DP), federated learning (FL), and Differentially Private Federated Learning (DP-FL). Through extensive experimentation on six benchmark datasets (FUNSD, CORD, SROIE, WildReceipts, XFUND, and DOCILE), we demonstrate that large document foundation models can be effectively fine-tuned for the KIE task under private settings to achieve adequate performance while maintaining strong privacy guarantees. Moreover, by thoroughly analyzing the impact of various training and model parameters on model performance, we propose simple yet effective guidelines for achieving an optimal privacy-utility trade-off for the KIE task under global DP. Finally, we introduce FeAm-DP, a novel DP-FL algorithm that enables efficiently upscaling global DP from a standalone context to a multi-client federated environ
    
[^31]: 探索临床记录表型的替代特征提取流程

    Investigating Alternative Feature Extraction Pipelines For Clinical Note Phenotyping. (arXiv:2310.03772v1 [cs.CL])

    [http://arxiv.org/abs/2310.03772](http://arxiv.org/abs/2310.03772)

    研究探索了临床记录表型的替代特征提取流程，使用基于BERT模型的方法将临床记录转换为文档表示，并传入LSTM模型，取得了明显的性能改进，但收敛时间较长且不支持增量训练。

    

    医疗行业常用的实践是使用临床记录，其中包含了详细的患者观察信息。然而，电子健康记录系统经常不以结构化格式包含这些观察结果，使得患者信息难以自动评估和评价。使用计算系统来提取医学属性具有许多应用，包括对患者的纵向分析、风险评估和医院评估。最近的研究已经构建了成功的表型方法：从临床记录中提取医学属性。基于BERT模型的方法可以将临床记录转换为一系列的表示，然后基于它们的CLS嵌入将其压缩为一个单一的文档表示，并传入一个LSTM模型。尽管这个流程相比之前的结果有明显的性能改进，但它需要很长的收敛时间。这个方法也不允许增量训练。

    A common practice in the medical industry is the use of clinical notes, which consist of detailed patient observations. However, electronic health record systems frequently do not contain these observations in a structured format, rendering patient information challenging to assess and evaluate automatically. Using computational systems for the extraction of medical attributes offers many applications, including longitudinal analysis of patients, risk assessment, and hospital evaluation. Recent work has constructed successful methods for phenotyping: extracting medical attributes from clinical notes. BERT-based models can be used to transform clinical notes into a series of representations, which are then condensed into a single document representation based on their CLS embeddings and passed into an LSTM (Mulyar et al., 2020). Though this pipeline yields a considerable performance improvement over previous results, it requires extensive convergence time. This method also does not allo
    
[^32]: GoLLIE:注释指南提高了零样本信息抽取

    GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction. (arXiv:2310.03668v1 [cs.CL])

    [http://arxiv.org/abs/2310.03668](http://arxiv.org/abs/2310.03668)

    GoLLIE 是一个遵循注释指南的大型语言模型，通过微调以改进未见信息抽取任务的零样本结果。

    

    大型语言模型 (LLMs) 结合指导调优已经在泛化到未见任务方面取得了显著进展。然而，在信息抽取 (IE) 方面，它们的表现较差，落后于任务特定模型。通常，IE 任务的特点是复杂的注释指南，描述任务并给出示例给人类。先前利用这样的信息的尝试都失败了，即使使用最大的模型，它们也不能直接遵循指南。在本文中，我们提出了针对信息抽取的指南遵循大型语言模型 GoLLIE (Guideline-following Large Language Model for IE)，该模型通过微调以遵守注释指南，从而能够改进未见 IE 任务的零样本结果。全面的评估实证表明，GoLLIE 能够泛化并遵循未见指南，在零样本信息抽取方面优于先前的尝试。消融研究表明，详细的指南是取得良好结果的关键。

    Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task-specific models. Typically, IE tasks are characterized by complex annotation guidelines which describe the task and give examples to humans. Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out-of-the-box. In this paper we propose GoLLIE (Guideline-following Large Language Model for IE), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero-shot information extraction. The ablation study shows that detailed guidelines is key for good results.
    
[^33]: 2023年福爾摩沙口音辨識挑戰中的北系統

    The North System for Formosa Speech Recognition Challenge 2023. (arXiv:2310.03443v1 [cs.CL])

    [http://arxiv.org/abs/2310.03443](http://arxiv.org/abs/2310.03443)

    本報告提供了北系統的簡要概述，該系統旨在實現對台灣客家語（四縣腔）的自動詞/音節識別。關鍵部分包括訓練數據的獲取、組成和利用，模型的架構，以及硬件規格和運行統計。

    

    本報告提供了北系統的簡要概述，旨在實現對台灣客家語（四縣腔）的自動詞/音節識別。該報告概述了系統的三個關鍵部分：訓練數據的獲取、組成和利用；模型的架構；以及硬件規格和運行統計。系統的演示可以在https://asrvm.iis.sinica.edu.tw/hakka_sixian找到。

    This report provides a concise overview of the proposed North system, which aims to achieve automatic word/syllable recognition for Taiwanese Hakka (Sixian). The report outlines three key components of the system: the acquisition, composition, and utilization of the training data; the architecture of the model; and the hardware specifications and operational statistics. The demonstration of the system can be found at https://asrvm.iis.sinica.edu.tw/hakka_sixian.
    
[^34]: 学习个性化故事评估

    Learning Personalized Story Evaluation. (arXiv:2310.03304v1 [cs.CL])

    [http://arxiv.org/abs/2310.03304](http://arxiv.org/abs/2310.03304)

    该论文提出了学习个性化故事评估的方法。为了解决大型语言模型在开放式文本生成任务的评估问题，论文创建了两个新的数据集，并开发了一个个性化故事评估模型，能够根据评审人员的示例评价进行个性化评估。

    

    尽管大型语言模型（LLM）在诸如问答和检索等更客观的任务上显示出令人印象深刻的结果，但评估它们在开放式文本生成方面的表现仍然是一个困难的问题，原因包括（1）数据污染；（2）多维评估标准；以及（3）来自评审人员个人偏好的主观性。为了解决这些问题，我们提出在一个无污染的开放式生成评估中建模个性化。我们使用适当的匿名化和新的个性化标签，重新利用现有数据集创建了两个新的数据集Per-MPST和Per-DOC用于个性化故事评估。我们进一步开发了一个个性化故事评估模型PERSE来推测评审人员的偏好，并提供个性化评估。具体而言，对于某个评审人员的一些示例评价，PERSE可以预测该评审人员在新的情节上的详细评审或细粒度比较（如趣味性和惊喜）。

    While large language models (LLMs) have shown impressive results for more objective tasks such as QA and retrieval, it remains nontrivial to evaluate their performance on open-ended text generation for reasons including (1) data contamination; (2) multi-dimensional evaluation criteria; and (3) subjectiveness stemming from reviewers' personal preferences. To address such issues, we propose to model personalization in an uncontaminated open-ended generation assessment. We create two new datasets Per-MPST and Per-DOC for personalized story evaluation, by re-purposing existing datasets with proper anonymization and new personalized labels. We further develop a personalized story evaluation model PERSE to infer reviewer preferences and provide a personalized evaluation. Specifically, given a few exemplary reviews from a particular reviewer, PERSE predicts either a detailed review or fine-grained comparison in several aspects (such as interestingness and surprise) for that reviewer on a new 
    
[^35]: 用智能多任务适应混合提示扫描异质性

    Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation. (arXiv:2310.02842v1 [cs.CL])

    [http://arxiv.org/abs/2310.02842](http://arxiv.org/abs/2310.02842)

    本论文提出了一种使用智能多任务适应混合提示的方法来解决LLM在处理异质任务和数据分布时的问题。研究者设计了智能门控功能，用于识别嵌入在不同提示组中的相关技能，并根据目标任务的需求动态分配组合专家。该方法对任何模型压缩技术都不受限制，提高了任务处理的效率。

    

    大型语言模型(LLM)有能力解决各种任务，如文本摘要和数学问题，但通常是针对单一任务进行训练。由于高计算成本，当前趋势是使用提示指导调节预先训练的LLM以适应新的下游任务。因此，如何扩展提示调节以同时处理异质任务和数据分布是一个广泛开放的问题。为了解决这一问题，我们建议使用"混合提示"或MoPs，并结合智能门控功能：后者的设计是本文的贡献之一，它可以识别嵌入在不同提示组中的相关技能，并根据目标任务动态分配组合专家(即一组提示)。此外，MoPs在应用任何模型压缩技术时都不受影响——以提高效率。

    Large Language Models (LLMs) have the ability to solve a variety of tasks, such as text summarization and mathematical questions, just out of the box, but they are often trained with a single task in mind. Due to high computational costs, the current trend is to use prompt instruction tuning to better adjust monolithic, pretrained LLMs for new -- but often individual -- downstream tasks. Thus, how one would expand prompt tuning to handle -- concomitantly -heterogeneous tasks and data distributions is a widely open question. To address this gap, we suggest the use of \emph{Mixture of Prompts}, or MoPs, associated with smart gating functionality: the latter -- whose design is one of the contributions of this paper -- can identify relevant skills embedded in different groups of prompts and dynamically assign combined experts (i.e., collection of prompts), based on the target task. Additionally, MoPs are empirically agnostic to any model compression technique applied -- for efficiency re
    
[^36]: 实例需要更加细致的关怀：为实例重写提示提高了零样本性能

    Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance. (arXiv:2310.02107v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.02107](http://arxiv.org/abs/2310.02107)

    为了提高大型语言模型的零样本性能，本文提出了一种新的方法，通过为每个个别的测试输入重新写作任务提示，使其更具体、明确和完整，从而提供更好的指导，实现了约10%的改进。

    

    让大型语言模型能够在零样本情况下执行任务一直是一个吸引人的目标，因为它可以节省人力（即无需任务特定的注释）；因此，零样本提示方法也享有更好的任务泛化能力。为了提高大型语言模型的零样本性能，先前的工作着重于设计更有效的任务指导（例如“我们一步一步思考”）。然而，我们认为，为了让大型语言模型能够在零样本情况下正确解决问题，每个单独的测试实例需要更仔细地设计和定制的指导。为此，我们提出了PRoMPTd，一种为每个个别的测试输入重新写作任务提示的方法，使其更加具体、明确和完整，以更好地指导任务的大型语言模型。我们使用GPT-4作为任务型大型语言模型，在涵盖算术、逻辑推理和代码生成等任务的8个数据集上对PRoMPTd进行了评估。值得注意的是，PRoMPTd在复杂MATH数据集上的绝对改进约为10%。

    Enabling large language models (LLMs) to perform tasks in zero-shot has been an appealing goal owing to its labor-saving (i.e., requiring no task-specific annotations); as such, zero-shot prompting approaches also enjoy better task generalizability. To improve LLMs' zero-shot performance, prior work has focused on devising more effective task instructions (e.g., ``let's think step by step'' ). However, we argue that, in order for an LLM to solve them correctly in zero-shot, individual test instances need more carefully designed and customized instructions. To this end, we propose PRoMPTd, an approach that rewrites the task prompt for each individual test input to be more specific, unambiguous, and complete, so as to provide better guidance to the task LLM. We evaluated PRoMPTd on eight datasets covering tasks including arithmetics, logical reasoning, and code generation, using GPT-4 as the task LLM. Notably, PRoMPTd achieves an absolute improvement of around 10% on the complex MATH dat
    
[^37]: Avalon的思考游戏：通过递归思考对抗欺骗

    Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation. (arXiv:2310.01320v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.01320](http://arxiv.org/abs/2310.01320)

    本研究通过使用复杂的Avalon游戏作为测试平台，引入了一种名为递归思考（ReCon）的新框架，用于增强大型语言模型（LLM）识别和对抗欺骗信息的能力。

    

    最近在大型语言模型（LLM）的突破带来了在LLM作为智能体领域的显著成功。然而，一种普遍的假设是LLM处理的信息始终是诚实的，忽视了人类社会和AI生成内容中普遍存在的欺骗或误导性信息。这个疏忽使得LLM容易受到恶意操纵，可能导致不利的结果。本研究利用复杂的Avalon游戏作为测试平台，探索LLM在欺骗环境中的潜力。Avalon充满了错误信息，并需要复杂的逻辑，表现为“思考的游戏”。受到人类在Avalon游戏中递归思考和透视能力的启发，我们引入了一种新颖的框架——递归思考（ReCon），以增强LLM识别和对抗欺骗信息的能力。ReCon结合了公式化思考和完善思考的过程；公式化思考产生初始思考，完善思考对初始思考进行调整和改进。

    Recent breakthroughs in large language models (LLMs) have brought remarkable success in the field of LLM-as-Agent. Nevertheless, a prevalent assumption is that the information processed by LLMs is consistently honest, neglecting the pervasive deceptive or misleading information in human society and AI-generated content. This oversight makes LLMs susceptible to malicious manipulations, potentially resulting in detrimental outcomes. This study utilizes the intricate Avalon game as a testbed to explore LLMs' potential in deceptive environments. Avalon, full of misinformation and requiring sophisticated logic, manifests as a "Game-of-Thoughts". Inspired by the efficacy of humans' recursive thinking and perspective-taking in the Avalon game, we introduce a novel framework, Recursive Contemplation (ReCon), to enhance LLMs' ability to identify and counteract deceptive information. ReCon combines formulation and refinement contemplation processes; formulation contemplation produces initial tho
    
[^38]: 让语言模型从数据中隐式学习自我改进能力

    Enable Language Models to Implicitly Learn Self-Improvement From Data. (arXiv:2310.00898v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00898](http://arxiv.org/abs/2310.00898)

    该论文探索了如何让语言模型隐式学习自我改进，并减少对人类标注的依赖。

    

    大型语言模型在开放式文本生成任务中展示了卓越的能力。然而，这些任务的本质决定了模型的回答质量始终有改进的空间。为了解决这个挑战，已经提出了各种方法来增强语言模型的性能。越来越多的关注点集中在使语言模型自我改进其回答质量上，从而减少对广泛的人工标注工作来收集多样化和高质量的训练数据的依赖。最近，基于提示的方法因其有效性、高效性和便利性而受到广泛关注。然而，这些方法通常需要为语言模型提供明确和详尽的指示。对于手动推导和提供所有必要的指示来实现现实世界复杂目标的改进（例如，更有帮助性和更少有害性），这是昂贵且具有挑战性的。

    Large Language Models (LLMs) have demonstrated remarkable capabilities in open-ended text generation tasks. However, the inherent open-ended nature of these tasks implies that there is always room for improvement in the quality of model responses. To address this challenge, various approaches have been proposed to enhance the performance of LLMs. There has been a growing focus on enabling LLMs to self-improve their response quality, thereby reducing the reliance on extensive human annotation efforts for collecting diverse and high-quality training data. Recently, prompting-based methods have been widely explored among self-improvement methods owing to their effectiveness, efficiency, and convenience. However, those methods usually require explicitly and thoroughly written rubrics as inputs to LLMs. It is expensive and challenging to manually derive and provide all necessary rubrics with a real-world complex goal for improvement (e.g., being more helpful and less harmful). To this end, 
    
[^39]: BooookScore: LLM时代中对书籍长度摘要的系统探索

    BooookScore: A systematic exploration of book-length summarization in the era of LLMs. (arXiv:2310.00785v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00785](http://arxiv.org/abs/2310.00785)

    本文对LLM模型进行了系统探索，以解决对超过上下文窗口大小的书籍进行摘要的问题，并通过两种提示工作流实施了基于LLM的书籍长度摘要器的连贯性研究。通过对100本书的GPT-4生成摘要的人工注释，发现了八种常见的连贯性错误。

    

    对于超过大型语言模型（LLMs）上下文窗口大小的书籍长度文档（>100K标记）进行摘要需要首先将输入文档分成较小的块，然后提示LLM合并、更新和压缩块级摘要。尽管这个任务的复杂性和重要性，但由于评估的困难，它尚未得到有意义的研究：现有的书籍长度摘要数据集（例如BookSum）在大多数公共LLM的预训练数据中，而现有的评估方法难以捕捉现代LLM摘要器的错误。在本文中，我们首次研究通过两种提示工作流实施的基于LLM的书籍长度摘要器的连贯性：（1）分层合并块级摘要，（2）逐步更新一个运行摘要。我们对100本最近出版的书籍的GPT-4生成摘要获得了1193个细粒度的人工注释，并确定了LLMs产生的八种常见的连贯性错误。

    Summarizing book-length documents (>100K tokens) that exceed the context window size of large language models (LLMs) requires first breaking the input document into smaller chunks and then prompting an LLM to merge, update, and compress chunk-level summaries. Despite the complexity and importance of this task, it has yet to be meaningfully studied due to the challenges of evaluation: existing book-length summarization datasets (e.g., BookSum) are in the pretraining data of most public LLMs, and existing evaluation methods struggle to capture errors made by modern LLM summarizers. In this paper, we present the first study of the coherence of LLM-based book-length summarizers implemented via two prompting workflows: (1) hierarchically merging chunk-level summaries, and (2) incrementally updating a running summary. We obtain 1193 fine-grained human annotations on GPT-4 generated summaries of 100 recently-published books and identify eight common types of coherence errors made by LLMs. Bec
    
[^40]: 放射学报告的多语言自然语言处理模型--摘要是你需要的一切！

    Multilingual Natural Language ProcessingModel for Radiology Reports -- The Summary is all you need!. (arXiv:2310.00100v1 [cs.CL])

    [http://arxiv.org/abs/2310.00100](http://arxiv.org/abs/2310.00100)

    本研究通过在多语言文本到文本变换器模型上微调，开发了一个能够自动在多语言中总结放射学报告的模型。该模型有助于提高未来深度学习模型的研究和发展，且能够应用于不同族裔背景的患者数据。

    

    放射学报告的印象部分总结了重要的放射学发现，并在向医生传达这些发现时起到了关键作用。然而，对于放射科医生来说，准备这些摘要既耗时又容易出错。最近，已经开发了许多用于放射学报告摘要的模型。然而，目前还没有能够在多种语言中总结这些报告的模型。这样的模型可以极大地改进未来的研究和融合来自不同族裔背景的患者数据的深度学习模型的发展。本研究通过在公开可用的基于多语言文本到文本变换器的模型上微调，自动化地生成了不同语言的放射学印象，以总结英语、葡萄牙语和德语的放射学报告中的发现。在一项盲测中，两位有执业资格的放射科医生表示，对于至少70%的系统生成的摘要，其质量

    The impression section of a radiology report summarizes important radiology findings and plays a critical role in communicating these findings to physicians. However, the preparation of these summaries is time-consuming and error-prone for radiologists. Recently, numerous models for radiology report summarization have been developed. Nevertheless, there is currently no model that can summarize these reports in multiple languages. Such a model could greatly improve future research and the development of Deep Learning models that incorporate data from patients with different ethnic backgrounds. In this study, the generation of radiology impressions in different languages was automated by fine-tuning a model, publicly available, based on a multilingual text-to-text Transformer to summarize findings available in English, Portuguese, and German radiology reports. In a blind test, two board-certified radiologists indicated that for at least 70% of the system-generated summaries, the quality 
    
[^41]: 生命科学领域的知识图谱：最新发展、挑战和机遇

    Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities. (arXiv:2309.17255v1 [cs.AI])

    [http://arxiv.org/abs/2309.17255](http://arxiv.org/abs/2309.17255)

    这篇论文综述了在生命科学领域中使用知识图谱的最新发展和进展，并展望了这些技术在未来对这些领域的影响。

    

    生命科学是研究生物和生命过程的学科，包括化学、生物学、医学和一系列其他相关学科。生命科学的研究工作非常依赖数据，因为它们产生和消费大量科学数据，其中很多数据具有关系和图结构。数据的数量和其中涉及的科学概念和关系的复杂性推动了应用先进的知识驱动技术来管理和解释数据，最终目标是推动科学发现。在这篇综述和观点论文中，我们讨论了知识图谱在生命科学中的最新发展和进展，并展望了这些技术在未来对这些领域的影响。我们重点关注三个主题：知识图谱的构建和管理，以及在新发现的过程中使用知识图谱和相关技术。

    The term life sciences refers to the disciplines that study living organisms and life processes, and include chemistry, biology, medicine, and a range of other related disciplines. Research efforts in life sciences are heavily data-driven, as they produce and consume vast amounts of scientific data, much of which is intrinsically relational and graph-structured.  The volume of data and the complexity of scientific concepts and relations referred to therein promote the application of advanced knowledge-driven technologies for managing and interpreting data, with the ultimate aim to advance scientific discovery.  In this survey and position paper, we discuss recent developments and advances in the use of graph-based technologies in life sciences and set out a vision for how these technologies will impact these fields into the future. We focus on three broad topics: the construction and management of Knowledge Graphs (KGs), the use of KGs and associated technologies in the discovery of ne
    
[^42]: 分层注意解释：一种用于双模式抑郁症检测的可解释性语音级变换器

    Hierarchical attention interpretation: an interpretable speech-level transformer for bi-modal depression detection. (arXiv:2309.13476v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.13476](http://arxiv.org/abs/2309.13476)

    本文提出了一种双模式语音级变换器，通过引入分层解释方法解决了自动抑郁症检测工具中的标注噪声和模型解释性问题，同时展示了其在性能上的优势。该模型通过梯度加权注意力图追踪输入特征之间的交互作用，可以提供语音级和句子级的解释。

    

    抑郁症是一种常见的心理障碍。使用机器学习实现的语音自动抑郁症检测工具有助于早期筛查抑郁症。本文针对这类工具可能存在的两个限制进行了探讨：由分段级标注导致的噪声和模型解释性的缺乏。我们提出了一种双模式语音级变换器来避免分段级标注，同时引入了一种层次化解释方法，根据从所有注意力层导出的梯度加权注意力图来追踪输入特征之间的交互作用，以提供语音级和句子级解释。我们展示了所提出的模型优于在分段级学习的模型（$p$=0.854, $r$=0.947, $F1$=0.897，与$p$=0.732, $r$=0.808, $F1$=0.768相比）。在模型解释方面，使用一个真实阳性样本，我们展示了哪些句子对于抑郁症检测相关性最高，以及哪些文本标记和Mel声谱图与之相关。

    Depression is a common mental disorder. Automatic depression detection tools using speech, enabled by machine learning, help early screening of depression. This paper addresses two limitations that may hinder the clinical implementations of such tools: noise resulting from segment-level labelling and a lack of model interpretability. We propose a bi-modal speech-level transformer to avoid segment-level labelling and introduce a hierarchical interpretation approach to provide both speech-level and sentence-level interpretations, based on gradient-weighted attention maps derived from all attention layers to track interactions between input features. We show that the proposed model outperforms a model that learns at a segment level ($p$=0.854, $r$=0.947, $F1$=0.897 compared to $p$=0.732, $r$=0.808, $F1$=0.768). For model interpretation, using one true positive sample, we show which sentences within a given speech are most relevant to depression detection; and which text tokens and Mel-spe
    
[^43]: 使用漏洞约束解码来高效避免自动完成智能合约代码中的漏洞

    Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract Code Using Vulnerability-constrained Decoding. (arXiv:2309.09826v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2309.09826](http://arxiv.org/abs/2309.09826)

    本研究提出了一种漏洞约束解码方法，通过微调大型语言模型并在解码过程中阻止生成漏洞标记，以高效减少自动完成代码中的漏洞。以以太坊智能合约为案例研究，验证了该方法的有效性。

    

    自动完成代码可以显著加快开发速度。最近，基于Transformer的大型语言模型技术已被应用于代码合成。然而，研究表明许多这种合成的代码存在漏洞。我们提出了一种新颖的漏洞约束解码方法，通过该方法可以减少这类模型生成的漏洞代码的数量。我们使用一个带有标记的漏洞代码数据集，对大型语言模型进行微调，使其在生成代码时包含漏洞标记，并充当内嵌分类器。然后，在解码过程中，我们阻止模型生成这些标记，以避免生成漏洞代码。为了评估该方法，我们选择自动完成以太坊区块链智能合约作为案例研究，因为智能合约安全具有严格要求。我们首先使用186,397个以太坊智能合约（经去重后剩下2,217,692个SC）对60亿参数的GPT-J模型进行微调。

    Auto-completing code enables developers to speed up coding significantly. Recent advances in transformer-based large language model (LLM) technologies have been applied to code synthesis. However, studies show that many of such synthesized codes contain vulnerabilities. We propose a novel vulnerability-constrained decoding approach to reduce the amount of vulnerable code generated by such models. Using a small dataset of labeled vulnerable lines of code, we fine-tune an LLM to include vulnerability labels when generating code, acting as an embedded classifier. Then, during decoding, we deny the model to generate these labels to avoid generating vulnerable code. To evaluate the method, we chose to automatically complete Ethereum Blockchain smart contracts (SCs) as the case study due to the strict requirements of SC security. We first fine-tuned the 6-billion-parameter GPT-J model using 186,397 Ethereum SCs after removing the duplication from 2,217,692 SCs. The fine-tuning took more than
    
[^44]: 通过总结多源多视角知识回答产品的主观归纳问题

    Answering Subjective Induction Questions on Products by Summarizing Multi-sources Multi-viewpoints Knowledge. (arXiv:2309.05938v1 [cs.CL])

    [http://arxiv.org/abs/2309.05938](http://arxiv.org/abs/2309.05938)

    本文提出了一个新任务：回答产品的主观归纳问题（SUBJPQA）。与传统的QA任务不同，这类问题的答案是非唯一的，并且需要从多个角度总结多个知识源的主观意见和客观知识来解释。为了解决这个任务，我们提出了一个三步骤的方法，包括信息检索、相关性捕捉和摘要生成。

    

    本文在回答产品的主观归纳问题（SUBJPQA）的领域中提出了一个新任务。这类问题的答案是非唯一的，但可以从多个角度来解释。例如，对于“手机是否重”的答案有多种不同的观点。一个满意的答案应该能够总结这些来自多个来源的主观意见，并提供客观知识，比如手机的重量。这与传统的QA任务非常不同，传统QA任务中对于事实问题的答案是唯一的，并且可以从单个数据源中找到。为了解决这个新任务，我们提出了一个三步骤的方法。首先，我们从多个知识源中检索所有与答案相关的线索，包括事实和观点。还收集了隐含的常识事实来补充必要但缺失的背景信息。然后，我们通过交互式注意力来捕捉它们与问题的相关性。接下来，我们设计了一个基于强化学习的摘要生成器来聚合这些信息。

    This paper proposes a new task in the field of Answering Subjective Induction Question on Products (SUBJPQA). The answer to this kind of question is non-unique, but can be interpreted from many perspectives. For example, the answer to 'whether the phone is heavy' has a variety of different viewpoints. A satisfied answer should be able to summarize these subjective opinions from multiple sources and provide objective knowledge, such as the weight of a phone. That is quite different from the traditional QA task, in which the answer to a factoid question is unique and can be found from a single data source. To address this new task, we propose a three-steps method. We first retrieve all answer-related clues from multiple knowledge sources on facts and opinions. The implicit commonsense facts are also collected to supplement the necessary but missing contexts. We then capture their relevance with the questions by interactive attention. Next, we design a reinforcement-based summarizer to ag
    
[^45]: 关于大型语言模型在多项选择题中的选择偏差问题

    On Large Language Models' Selection Bias in Multi-Choice Questions. (arXiv:2309.03882v1 [cs.CL])

    [http://arxiv.org/abs/2309.03882](http://arxiv.org/abs/2309.03882)

    本研究发现大型语言模型在多项选择题中存在选择偏差，即倾向于选择特定位置上的选项。研究指出这一偏差的主要原因是选项编号，提出了一种名为PriDe的方法来减轻偏差，并展示了其高精度和稳定性。

    

    多项选择题（MCQs）是大型语言模型（LLMs）研究中常见且重要的任务格式。我们的工作表明，LLMs在MCQs中存在固有的“选择偏差”，即LLMs倾向于选择特定位置上的选项（如“选项C”）。这种偏差在各种LLMs中普遍存在，使得它们在MCQs中对选项位置变化的性能变得脆弱。我们发现导致选择偏差的一个主要原因是选项编号，即与选项相关的ID符号A/B/C/D。为了减轻选择偏差，我们提出了一种新方法称为PriDe。PriDe首先将观察到的模型预测分布分解为对选项内容的内在预测和对选项ID的先验分布。然后，它通过在少量测试样本上对选项内容进行排列组合来估计先验，从而用于消除后续测试样本的偏差。我们证明了作为一种无标签、推断时间方法，PriDe可以实现高精度且稳定的解决方案。

    Multi-choice questions (MCQs) serve as a common yet important task format in the research of large language models (LLMs). Our work shows that LLMs exhibit an inherent "selection bias" in MCQs, which refers to LLMs' preferences to select options located at specific positions (like "Option C"). This bias is prevalent across various LLMs, making their performance vulnerable to option position changes in MCQs. We identify that one primary cause resulting in selection bias is option numbering, i.e., the ID symbols A/B/C/D associated with the options. To mitigate selection bias, we propose a new method called PriDe. PriDe first decomposes the observed model prediction distribution into an intrinsic prediction over option contents and a prior distribution over option IDs. It then estimates the prior by permutating option contents on a small number of test samples, which is used to debias the subsequent test samples. We demonstrate that, as a label-free, inference-time method, PriDe achieves 
    
[^46]: 使用虚拟提示注入向指令调整的大型语言模型后门

    Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection. (arXiv:2307.16888v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.16888](http://arxiv.org/abs/2307.16888)

    这项研究介绍了一种针对指令调整的大型语言模型的新型后门攻击方法，即虚拟提示注入（VPI）。通过在特定触发场景下将虚拟提示与用户指令连接，攻击者可以精细操纵模型的回应而无需明确注入。

    

    指令调整的大型语言模型（LLM）表现出了根据人类指令调节其回应的非凡能力。然而，这种调节能力也引入了潜在的攻击者通过植入后门来对模型功能进行精细操纵的可能性。在本文中，我们介绍了一种针对指令调整的LLM定制的新型后门攻击设置-虚拟提示注入（VPI）。在VPI攻击中，期望通过在特定触发场景下将攻击者指定的虚拟提示连接到用户指令中，使植入后门的模型表现得像是在其输入中没有明确的注入。例如，如果LLM被虚拟提示"负面描述乔·拜登"植入后门的触发场景是讨论乔·拜登，那么当谈论乔·拜登时，模型将传播负面倾向的观点。 VPI尤其有害，因为攻击者可以进行细粒度的操纵。

    Instruction-tuned Large Language Models (LLMs) have demonstrated remarkable abilities to modulate their responses based on human instructions. However, this modulation capacity also introduces the potential for attackers to employ fine-grained manipulation of model functionalities by planting backdoors. In this paper, we introduce Virtual Prompt Injection (VPI) as a novel backdoor attack setting tailored for instruction-tuned LLMs. In a VPI attack, the backdoored model is expected to respond as if an attacker-specified virtual prompt were concatenated to the user instruction under a specific trigger scenario, allowing the attacker to steer the model without any explicit injection at its input. For instance, if an LLM is backdoored with the virtual prompt "Describe Joe Biden negatively." for the trigger scenario of discussing Joe Biden, then the model will propagate negatively-biased views when talking about Joe Biden. VPI is especially harmful as the attacker can take fine-grained and 
    
[^47]: CARTIER: 面向机器人指令执行的地图语言推理

    CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots. (arXiv:2307.11865v1 [cs.RO])

    [http://arxiv.org/abs/2307.11865](http://arxiv.org/abs/2307.11865)

    本研究使用大型语言模型，探索了在空间规划和导航交叉问题中，通过解析复杂的自然语言指令来执行任务的新方法。

    

    本研究探索了大型语言模型（LLM）在空间规划和自然语言界面与导航交叉问题中的应用能力。我们的重点是遵循相对复杂的指令，这些指令更类似于自然对话，而不是传统的显式过程指令。与大多数先前的工作不同，在那些导航指令被提供为命令式指令（例如，去冰箱）的情况下，我们研究了对话交互中的隐式指令。我们利用3D模拟器AI2Thor创建复杂且可重复的场景，并通过为40种对象类型添加复杂的语言查询来增强它。我们证明，通过使用LLM将用户交互解释为场景中对象列表的上下文，机器人可以更好地解析描述性语言查询，优于现有方法。

    This work explores the capacity of large language models (LLMs) to address problems at the intersection of spatial planning and natural language interfaces for navigation.Our focus is on following relatively complex instructions that are more akin to natural conversation than traditional explicit procedural directives seen in robotics. Unlike most prior work, where navigation directives are provided as imperative commands (e.g., go to the fridge), we examine implicit directives within conversational interactions. We leverage the 3D simulator AI2Thor to create complex and repeatable scenarios at scale, and augment it by adding complex language queries for 40 object types. We demonstrate that a robot can better parse descriptive language queries than existing methods by using an LLM to interpret the user interaction in the context of a list of the objects in the scene.
    
[^48]: 使用提示条件微调实现零样本领域敏感语音识别

    Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning. (arXiv:2307.10274v1 [eess.AS])

    [http://arxiv.org/abs/2307.10274](http://arxiv.org/abs/2307.10274)

    本研究提出了一种零样本领域敏感语音识别方法，利用文本提示来生成领域敏感模型，通过微调预训练的端到端模型实现。实验结果表明，该方法在不同领域和提示上下文下均取得了良好的性能，词错误率降低达到最高33%。通过仅使用文本进行微调，该模型在医学对话数据集上的识别效果最佳，词错误率降低达到29%。

    

    本研究提出了一种方法来创建利用文本领域信息的领域敏感语音识别模型，通过将其生成条件化在给定的文本提示上实现。通过对预训练的端到端模型（Whisper）进行微调，从提示示例中学习，这一目标得以实现。我们展示了这种能力可以推广到不同的领域和各种提示上下文，我们的模型在来自不同领域的未见数据集上获得了多达33％的词错误率（WER）降低，例如医学对话，空中交通控制通信和金融会议等。考虑到音频-文本对数据的有限可用性，我们进一步将我们的方法扩展到仅文本微调，以实现领域敏感性和领域适应性。我们证明了我们的仅文本微调模型也可以关注各种提示上下文，该模型在医学对话数据集上的WER降低最多达到29％。

    In this work, we propose a method to create domain-sensitive speech recognition models that utilize textual domain information by conditioning its generation on a given text prompt. This is accomplished by fine-tuning a pre-trained, end-to-end model (Whisper) to learn from demonstrations with prompt examples. We show that this ability can be generalized to different domains and even various prompt contexts, with our model gaining a Word Error Rate (WER) reduction of up to 33% on unseen datasets from various domains, such as medical conversation, air traffic control communication, and financial meetings. Considering the limited availability of audio-transcript pair data, we further extend our method to text-only fine-tuning to achieve domain sensitivity as well as domain adaptation. We demonstrate that our text-only fine-tuned model can also attend to various prompt contexts, with the model reaching the most WER reduction of 29% on the medical conversation dataset.
    
[^49]: 大型语言模型

    Large Language Models. (arXiv:2307.05782v1 [cs.CL])

    [http://arxiv.org/abs/2307.05782](http://arxiv.org/abs/2307.05782)

    这篇论文介绍了大型语言模型的发展历史和现状，详细描述了底层的Transformer架构，并探讨了如何训练模型来实现多种智能任务。

    

    人工智能正在取得惊人的进展，其中一个最好的例子是大型语言模型（LLMs）的发展，如OpenAI的GPT系列。在这些针对具有数学或物理背景的读者编写的讲座中，我们简要介绍了LLMs的历史和现状，并详细描述了底层的Transformer架构。然后，我们探讨了一些关于LLMs工作原理的当前观点，以及训练用于预测文本中下一个单词的模型如何能够执行显示智能的其他任务。

    Artificial intelligence is making spectacular progress, and one of the best examples is the development of large language models (LLMs) such as OpenAI's GPT series. In these lectures, written for readers with a background in mathematics or physics, we give a brief history and survey of the state of the art, and describe the underlying transformer architecture in detail. We then explore some current ideas on how LLMs work and how models trained to predict the next word in a text are able to perform other tasks displaying intelligence.
    
[^50]: 大型语言模型的简单而有效的剪枝方法

    A Simple and Effective Pruning Approach for Large Language Models. (arXiv:2306.11695v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.11695](http://arxiv.org/abs/2306.11695)

    本论文提出了一种称为Wanda的新颖、简单而有效的剪枝方法，用于大型语言模型，通过对每个输出上的权重按照最小幅度乘以对应的输入激活来进行剪枝，无需重新训练或更新权重。

    

    随着规模的增大，大型语言模型（LLMs）是网络剪枝方法的自然候选对象：这些方法在努力保持性能的同时，丢弃了网络权重的一个子集。然而，现有的方法要么需要重新训练，这对于十亿级别的LLMs来说很少可行，要么需要解决一个依赖二阶信息的权重重构问题，这也可能计算成本很高。在本文中，我们介绍了一种新颖的、简单但有效的剪枝方法，称为Wanda（基于权重和激活的剪枝），旨在对预训练的LLMs引入稀疏性。受到最近对LLMs中出现的大幅特征的发现的启发，我们的方法在每个输出上按照权重和对应的输入激活相乘的最小幅度来剪枝权重。值得注意的是，Wanda不需要重新训练或更新权重，剪枝后的LLM可以直接使用。我们在LLaMA和LLaMA-2上对我们的方法Wanda进行了彻底的评估。

    As their size increases, Large Languages Models (LLMs) are natural candidates for network pruning methods: approaches that drop a subset of network weights while striving to preserve performance. Existing methods, however, require either retraining, which is rarely affordable for billion-scale LLMs, or solving a weight reconstruction problem reliant on second-order information, which may also be computationally expensive. In this paper, we introduce a novel, straightforward yet effective pruning method, termed Wanda (Pruning by Weights and activations), designed to induce sparsity in pretrained LLMs. Motivated by the recent observation of emergent large magnitude features in LLMs, our approach prunes weights with the smallest magnitudes multiplied by the corresponding input activations, on a per-output basis. Notably, Wanda requires no retraining or weight update, and the pruned LLM can be used as is. We conduct a thorough evaluation of our method Wanda on LLaMA and LLaMA-2 across vari
    
[^51]: 现在它听起来像你了：在设备上学习个性化词汇

    Now It Sounds Like You: Learning Personalized Vocabulary On Device. (arXiv:2305.03584v1 [cs.CL])

    [http://arxiv.org/abs/2305.03584](http://arxiv.org/abs/2305.03584)

    这项研究提出了一种称为“生词扩展”的技术，通过个性化的“生词适配器”来学习个性化词汇，提高了生词覆盖率并显著提高了模型准确度。

    

    近年来，联邦学习在进行各种自然语言处理任务方面已经显示出显著进展。这项工作侧重于应用个性化联邦学习进行设备端语言建模。由于内存和延迟的限制，这些模型无法支持子单词标记或波束搜索解码的复杂性，因此决定部署封闭词汇的语言模型。然而，封闭词汇模型无法处理特定用户的生词，为了解决这个问题，我们提出了一种称为“生词扩展”的新技术，该技术提高了生词覆盖率，增加了模型的准确性，同时最大程度地减少了对内存和延迟的影响。这种方法引入了个性化的“生词适配器”，有效地从中央模型传输知识，并为个性化词汇学习单词嵌入。在一组常见的联邦学习基准测试中，生词扩展方法明显优于标准个性化联邦学习方法。

    In recent years, Federated Learning (FL) has shown significant advancements in its ability to perform various natural language processing (NLP) tasks. This work focuses on applying personalized FL for on-device language modeling. Due to limitations of memory and latency, these models cannot support the complexity of sub-word tokenization or beam search decoding, resulting in the decision to deploy a closed-vocabulary language model. However, closed-vocabulary models are unable to handle out-of-vocabulary (OOV) words belonging to specific users. To address this issue, We propose a novel technique called "OOV expansion" that improves OOV coverage and increases model accuracy while minimizing the impact on memory and latency. This method introduces a personalized "OOV adapter" that effectively transfers knowledge from a central model and learns word embedding for personalized vocabulary. OOV expansion significantly outperforms standard FL personalization methods on a set of common FL benc
    
[^52]: 不停止预训练？让基于提示的微调更加强大

    Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner. (arXiv:2305.01711v1 [cs.CL])

    [http://arxiv.org/abs/2305.01711](http://arxiv.org/abs/2305.01711)

    本文研究了持续预训练对于微调性能的影响，发现传统的持续预训练不能保证一致的提高性能，甚至会对一些任务产生负面影响。针对这些问题，作者提出了基于提示的持续预训练，旨在通过无监督的预训练向LM展示任务相关文本和提示模板，从而提高基于提示的微调表现。

    

    在大量无标注数据的训练下，语言模型（LM）极大地推动了自然语言处理（NLP）领域的发展。 在本研究中，我们重新审视NLP中广为接受的LM任务相关文本的持续预训练可以提高下游任务微调性能的理论。通过在半监督和全监督设置下对八个单句任务和八个句对任务的实验，我们发现传统的持续预训练不能保证一致的提高性能，甚至可能对句对任务或使用基于提示的微调方式时会产生负面影响。为了解决这些问题，我们提出了基于提示的持续预训练（PCP），将指导调整的思想与传统的持续预训练相结合。我们的方法旨在通过在微调目标之前通过无监督的预训练目标向LM展示任务相关文本和提示模板，从而提高基于提示的FT的表现。

    Language models (LMs) trained on vast quantities of unlabelled data have greatly advanced the field of natural language processing (NLP). In this study, we re-visit the widely accepted notion in NLP that continued pre-training LMs on task-related texts improves the performance of fine-tuning (FT) in downstream tasks. Through experiments on eight single-sentence tasks and eight sentence-pair tasks in both semi-supervised and fully-supervised settings, we find that conventional continued pre-training does not consistently provide benefits and can even be detrimental for sentence-pair tasks or when prompt-based FT is used. To tackle these issues, we propose Prompt-based Continued Pre-training (PCP), which combines the idea of instruction tuning with conventional continued pre-training. Our approach aims to improve the performance of prompt-based FT by presenting both task-related texts and prompt templates to LMs through unsupervised pre-training objectives before fine-tuning for the targ
    
[^53]: 可微异常检测实现鲁棒的深度多模态分析

    Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis. (arXiv:2302.05608v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2302.05608](http://arxiv.org/abs/2302.05608)

    本研究提出了一个可微的异常检测方法来实现鲁棒的深度多模态分析，通过借助明确的知识图谱和交互式的区分外部领域层来过滤噪声。在多个视觉和语言任务中得到了良好的应用效果。

    

    在训练和推理过程中，深度网络模型通常只是归纳式的使用。因此，当这些模型用于预测时，往往无法捕捉到对象（或概念）之间在群体层面上存在的语义信息和隐含依赖关系。此外，在大规模和嘈杂的环境中如何以反向传播友好的方式指定领域或先验模态知识仍然不清楚。在这项工作中，我们提出了一个端到端的视觉和语言模型，其中包括明确的知识图谱。我们还引入了一个使用隐式网络操作符的交互式区分外部领域的层。该层用于过滤由外部知识库带来的噪声。在实践中，我们在不同的数据集上应用我们的模型进行多个视觉和语言下游任务，包括视觉问答、视觉推理和图像文本检索。我们的实验结果表明，在大规模和嘈杂的环境中，可以去除噪声。

    Often, deep network models are purely inductive during training and while performing inference on unseen data. Thus, when such models are used for predictions, it is well known that they often fail to capture the semantic information and implicit dependencies that exist among objects (or concepts) on a population level. Moreover, it is still unclear how domain or prior modal knowledge can be specified in a backpropagation friendly manner, especially in large-scale and noisy settings. In this work, we propose an end-to-end vision and language model incorporating explicit knowledge graphs. We also introduce an interactive out-of-distribution (OOD) layer using implicit network operator. The layer is used to filter noise that is brought by external knowledge base. In practice, we apply our model on several vision and language downstream tasks including visual question answering, visual reasoning, and image-text retrieval on different datasets. Our experiments show that it is possible to de
    
[^54]: 在文本对抗攻击中保持语义的研究

    Preserving Semantics in Textual Adversarial Attacks. (arXiv:2211.04205v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.04205](http://arxiv.org/abs/2211.04205)

    本文研究了在文本对抗攻击中保持语义的问题，并提出了一个新的句子嵌入技术SPE，可以显著提高对抗攻击的成功率。

    

    仇恨性在线内容的增长与全球对少数群体的暴力犯罪增加有关。有害的在线内容可以轻松、自动和匿名地产生。虽然通过NLP中的文本分类器已经实现某种形式的自动检测，但它们可以被对抗攻击所愚弄。为了加强现有系统并赶在攻击者前面，我们需要更好的对抗攻击。在本文中，我们展示了由对抗攻击生成的对抗示例中高达70%的示例应该被丢弃，因为它们无法保持语义。我们解决了这个核心弱点，并提出了一种新的、完全监督的句子嵌入技术，称为语义保持编码器（SPE）。我们的方法在对抗攻击中的成功率方面优于现有的句子编码器，实现了1.2倍至5.1倍的提升。我们将我们的代码作为插件发布，可以用于任何现有的对抗攻击，以提高其质量和加快速度。

    The growth of hateful online content, or hate speech, has been associated with a global increase in violent crimes against minorities [23]. Harmful online content can be produced easily, automatically and anonymously. Even though, some form of auto-detection is already achieved through text classifiers in NLP, they can be fooled by adversarial attacks. To strengthen existing systems and stay ahead of attackers, we need better adversarial attacks. In this paper, we show that up to 70% of adversarial examples generated by adversarial attacks should be discarded because they do not preserve semantics. We address this core weakness and propose a new, fully supervised sentence embedding technique called Semantics-Preserving-Encoder (SPE). Our method outperforms existing sentence encoders used in adversarial attacks by achieving 1.2x - 5.1x better real attack success rate. We release our code as a plugin that can be used in any existing adversarial attack to improve its quality and speed up 
    
[^55]: TwiRGCN: 基于时间加权图卷积的问答中的问题回答

    TwiRGCN: Temporally Weighted Graph Convolution for Question Answering over Temporal Knowledge Graphs. (arXiv:2210.06281v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06281](http://arxiv.org/abs/2210.06281)

    TwiRGCN是一种基于时间加权图卷积的问答系统，通过关联问题的时间段与知识图谱的边来传递信息，使用门控装置来预测答案的类型，并在多跳复杂时间问答数据集上取得显著优势。

    

    近年来，对于复杂问题回答中的时间推理的兴趣日益增加，但是人类的能力仍存在较大差距。本文探索了如何将关系图卷积网络（RGCN）推广到时间知识图谱问答（KGQA）中。具体来说，我们提出了一种新颖、直观且可解释的方案，在卷积过程中通过调节与问题相关的时间段与KG边之间的关联性来传递信息。我们还引入了一个门控装置，用来预测复杂时间问题的答案是否可能是一个KG实体或时间，并使用这个预测来指导我们的评分机制。我们在最近发布的挑战性数据集TimeQuestions上评估了得到的系统，称为TwiRGCN。结果显示，TwiRGCN在不同类型的问题上显著优于现有技术的系统。值得注意的是，TwiRGCN将准确性提高了9-10个百分点。

    Recent years have witnessed much interest in temporal reasoning over knowledge graphs (KG) for complex question answering (QA), but there remains a substantial gap in human capabilities. We explore how to generalize relational graph convolutional networks (RGCN) for temporal KGQA. Specifically, we propose a novel, intuitive and interpretable scheme to modulate the messages passed through a KG edge during convolution, based on the relevance of its associated time period to the question. We also introduce a gating device to predict if the answer to a complex temporal question is likely to be a KG entity or time and use this prediction to guide our scoring mechanism. We evaluate the resulting system, which we call TwiRGCN, on TimeQuestions, a recently released, challenging dataset for multi-hop complex temporal QA. We show that TwiRGCN significantly outperforms state-of-the-art systems on this dataset across diverse question types. Notably, TwiRGCN improves accuracy by 9--10 percentage po
    
[^56]: AdaptivePaste: 通过学习语义感知变量使用表示进行代码适应

    AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations. (arXiv:2205.11023v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2205.11023](http://arxiv.org/abs/2205.11023)

    AdaptivePaste是一种基于变压器的学习型源代码适应方法，通过学习变量使用模式的有意义表示，可以以高准确率适应源代码。用户研究结果显示，AdaptivePaste能够降低开发时间的浪费。

    

    在软件开发中，程序员常常会复制粘贴或移植代码片段，然后根据自己的使用情况进行调整。这种情况促使了代码适应任务——一种程序修复的变体，旨在将粘贴的代码片段中的变量标识符适应到周围已存在的源代码中。然而，目前没有已知的方法能够有效地解决这个任务。在本文中，我们介绍了一种基于变压器和专门的数据流感知去混淆预训练任务的学习型源代码适应方法——AdaptivePaste，它能够学习变量使用模式的有意义表示。我们在一个Python代码片段数据集上评估了AdaptivePaste的性能。结果表明，我们的模型能够以79.8%的准确率适应源代码。为了评估AdaptivePaste在实践中的价值，我们对10名Python开发者进行了一项用户研究，涉及了100个真实世界的复制粘贴实例。结果显示，AdaptivePaste能够降低开发时间的浪费。

    In software development, it is common for programmers to copy-paste or port code snippets and then adapt them to their use case. This scenario motivates the code adaptation task -- a variant of program repair which aims to adapt variable identifiers in a pasted snippet of code to the surrounding, preexisting source code. However, no existing approach has been shown to effectively address this task. In this paper, we introduce AdaptivePaste, a learning-based approach to source code adaptation, based on transformers and a dedicated dataflow-aware deobfuscation pre-training task to learn meaningful representations of variable usage patterns. We evaluate AdaptivePaste on a dataset of code snippets in Python. Results suggest that our model can learn to adapt source code with 79.8% accuracy. To evaluate how valuable is AdaptivePaste in practice, we perform a user study with 10 Python developers on a hundred real-world copy-paste instances. The results show that AdaptivePaste reduces the dwel
    
[^57]: 软子指数Lambek演算的向量空间语义

    Vector Space Semantics for Lambek Calculus with Soft Subexponentials. (arXiv:2111.11331v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2111.11331](http://arxiv.org/abs/2111.11331)

    本论文介绍了一种软子指数Lambek演算的向量空间语义，应用于构建委托语缺位名词短语和带有回指和省略的话语单元的组合向量解释，具有很好的应用前景。

    

    我们为软子指数Lambek演算开发了一个向量空间语义，将演算应用于构建委托语缺位名词短语和带有回指和省略的话语单元的组合向量解释，并在分布式句子相似性任务中实验证明。与以往使用相关模态的Lambek演算不同，本文中使用的演算采用了一个有界版本的模态，且可判定。这种新的模态的向量空间语义允许我们有意义地定义收缩为投影，并提供了一个线性理论，使我们能够通过非线性映射来实现的内容变得可以实现。

    We develop a vector space semantics for Lambek Calculus with Soft Subexponentials, apply the calculus to construct compositional vector interpretations for parasitic gap noun phrases and discourse units with anaphora and ellipsis, and experiment with the constructions in a distributional sentence similarity task. As opposed to previous work, which used Lambek Calculus with a Relevant Modality the calculus used in this paper uses a bounded version of the modality and is decidable. The vector space semantics of this new modality allows us to meaningfully define contraction as projection and provide a linear theory behind what we could previously only achieve via nonlinear maps.
    

