# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FATRER: Full-Attention Topic Regularizer for Accurate and Robust Conversational Emotion Recognition.](http://arxiv.org/abs/2307.12221) | 本文介绍了一种全注意力主题正则化器，用于增强情感识别器在处理对话中的局部上下文时获得情感相关的全局视角，实验证明该模型在准确性和稳健性方面取得了更好的效果。 |
| [^2] | [The Imitation Game: Detecting Human and AI-Generated Texts in the Era of Large Language Models.](http://arxiv.org/abs/2307.12166) | 本论文研究了区分人类和AI生成的文本的任务，在不同体裁下进行了比较研究，提出了一个新的数据集，并采用多种机器学习模型进行分类。结果表明这些模型对于区分人类和AI生成的文本具有很高的效力，尽管在区分GPT生成的文本方面存在一定挑战。 |
| [^3] | [Identifying Misinformation on YouTube through Transcript Contextual Analysis with Transformer Models.](http://arxiv.org/abs/2307.12155) | 本文介绍了一种通过转录上下文分析和Transformer模型，在YouTube上识别错误信息的新方法。该方法将视频分类任务转化为文本分类任务，采用了迁移学习和少样本学习等先进的机器学习技术。在三个数据集上进行了评估，包括YouTube上的疫苗错误信息相关视频、假科学视频和Fake-News数据集。结果表明，该方法在检测YouTube上的错误信息方面具有良好的性能。 |
| [^4] | [Modality Confidence Aware Training for Robust End-to-End Spoken Language Understanding.](http://arxiv.org/abs/2307.12134) | 该论文提出了一种鲁棒的端到端语音理解（SLU）系统，通过融合基于ASR假设的模态置信度来增强对ASR错误的容错性。他们的方法通过有效的编码ASR假设质量，成功将其整合到E2E SLU模型中，提高了准确性。 |
| [^5] | [Explainable Topic-Enhanced Argument Mining from Heterogeneous Sources.](http://arxiv.org/abs/2307.12131) | 这项研究提出了一种可解释的主题增强的论点挖掘方法，通过使用神经主题模型和语言模型来处理多样化的目标相关子主题，并利用句级主题信息进行分析。 |
| [^6] | [A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks.](http://arxiv.org/abs/2307.12114) | 这项研究评估了四种指导细调大型语言模型在临床和生物医学任务上的表现，并发现它们在零样本和少样本情况下接近最先进模型的性能，尤其在问答任务上表现良好。然而，在分类和关系抽取任务上的表现稍逊于特定训练于医学领域的模型。没有一个模型在所有研究任务上胜过其他模型，有些模型更适合特定任务。 |
| [^7] | [External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback.](http://arxiv.org/abs/2307.12057) | 本文提出通过从外部存储库中选择性地集成知识来增强大型语言模型，提出了一种外部推理的新方法，例子是ChatPDF。 |
| [^8] | [Revisiting Distillation for Continual Learning on Visual Question Localized-Answering in Robotic Surgery.](http://arxiv.org/abs/2307.12045) | 本文研究了用于机器人手术中视觉问题定位回答的蒸馏连续学习方法。通过重新审视蒸馏损失，提出了刚性-可塑性感知蒸馏和自校准异质蒸馏来保留旧知识。 |
| [^9] | [Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models.](http://arxiv.org/abs/2307.11991) | Psy-LLM是一个基于人工智能的系统，利用大型语言模型（LLMs）为在线心理咨询提供问答服务，前端工具可让医疗专业人员提供即时响应和正念活动，同时还可作为筛查工具辅助识别紧急案例。 |
| [^10] | [Learning Vision-and-Language Navigation from YouTube Videos.](http://arxiv.org/abs/2307.11984) | 本文提出了从YouTube视频中学习视觉与语言导航的方法，通过创建大规模数据集，利用房屋导览视频中的路径指令对进行预训练，解决了泛化能力不足的问题，并提出了处理自动构建路径指令对和从无标签视频中提取布局知识的挑战的方法。 |
| [^11] | [Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors.](http://arxiv.org/abs/2307.11922) | 本研究提出了一种名为BLINDER的方法，通过学习任务条件下状态描述的值函数，自动选择简明的状态描述，以优化大型语言模型(LLM)演员在顺序决策任务中的性能和效率。 |
| [^12] | [CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots.](http://arxiv.org/abs/2307.11865) | 本研究使用大型语言模型，探索了在空间规划和导航交叉问题中，通过解析复杂的自然语言指令来执行任务的新方法。 |
| [^13] | [The Looming Threat of Fake and LLM-generated LinkedIn Profiles: Challenges and Opportunities for Detection and Prevention.](http://arxiv.org/abs/2307.11864) | 本文介绍了一种在领英平台上检测虚假和大规模语言模型生成的个人资料的新方法，该方法使用领英个人资料中的文本信息，并引入“部分和子部分标签嵌入”（SSTE）方法以增强数据的特征。研究还通过收集3600个领英个人资料建立了一个公开可用的数据集。 |
| [^14] | [MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Question Answering.](http://arxiv.org/abs/2307.11848) | MythQA是一项新的多答案开放领域问题回答（QA）任务，旨在通过矛盾立场挖掘来检测大规模查询值得检查的断言。该任务通过构建一个包含522个基于有争议的话题的评估数据集来进行研究。 |
| [^15] | [Multimodal Document Analytics for Banking Process Automation.](http://arxiv.org/abs/2307.11845) | 本研究聚焦于应对金融科技竞争和提高银行业务运营效率的需求，通过多模式模型特别是先进的文档分析技术，研究了银行流程中的潜力和机会，并展示了LayoutXLM等模型在分析银行文档中的潜力和性能。 |
| [^16] | [Prompting Large Language Models with Speech Recognition Abilities.](http://arxiv.org/abs/2307.11795) | 本研究通过为大型语言模型添加音频编码器，使其具备了语音识别能力。在多语言数据集上的实验证明，这样的扩展能够提高模型的性能，并且在多语言环境下实现了语音识别。通过消融研究，我们还发现可以冻结模型以保持其原有功能，并且提升音频编码器的规模有助于提高性能。 |
| [^17] | [Applying QNLP to sentiment analysis in finance.](http://arxiv.org/abs/2307.11788) | 本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。 |
| [^18] | [LLM Cognitive Judgements Differ From Human.](http://arxiv.org/abs/2307.11787) | 这项研究调查了大型语言模型在认知任务中的表现，并发现它们的认知判断与人类不同。 |
| [^19] | [Adversarial Conversational Shaping for Intelligent Agents.](http://arxiv.org/abs/2307.11785) | 本文研究了通过对抗对话塑造来增强智能对话代理的两个模型：GANPG和REGS。这些模型能够改进当前的自动拨号系统，提高聊天机器人的性能。 |
| [^20] | [The Extractive-Abstractive Axis: Measuring Content "Borrowing" in Generative Language Models.](http://arxiv.org/abs/2307.11779) | 该论文提出了一个名为提取-摘要轴的概念，用于衡量生成语言模型中内容的"借用"程度，并提出了开发相应度量标准、数据集和注释指南的需求。 |
| [^21] | [Transsion TSUP's speech recognition system for ASRU 2023 MADASR Challenge.](http://arxiv.org/abs/2307.11778) | Transsion TSUP团队开发了一种语音识别系统，在ASRU 2023 MADASR挑战赛中取得了显著成果，能够适应低资源的印度语言。该系统针对挑战的四个跟踪进行了优化，并采用了不同的模型和解码策略。对于孟加拉语，取得了较低的词错误率。 |
| [^22] | [A Topical Approach to Capturing Customer Insight In Social Media.](http://arxiv.org/abs/2307.11775) | 本研究通过嵌入狄利克雷过程，嵌入层次狄利克雷过程和面向时间的动态嵌入三种方法，解决了在嘈杂的大数据环境中完全无监督的主题提取挑战。 |
| [^23] | [AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment enabled by Large Language Models.](http://arxiv.org/abs/2307.11772) | AutoAlign是一种全自动的知识图谱对齐方法，不需要手工制作的种子对齐。它利用大型语言模型自动捕捉谓词相似性，并使用TransE计算实体嵌入来实现实体对齐。 |
| [^24] | [an integrated npl approach to sentiment analysis in satisfaction surveys.](http://arxiv.org/abs/2307.11771) | 这项研究使用集成的自然语言处理方法对满意度调查进行情感分析，通过识别重复的词语模式和利用意见挖掘来理解参与者的意见，并且通过分析词语模式来获取更深入的情感、意见和主题信息。 |
| [^25] | [Large-Scale Evaluation of Topic Models and Dimensionality Reduction Methods for 2D Text Spatialization.](http://arxiv.org/abs/2307.11770) | 通过大规模计算评估，我们研究了用于2D文本空间化的主题模型和降维方法的有效性，为语料库分析提供了具有高质量布局的解决方案。 |
| [^26] | [Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain.](http://arxiv.org/abs/2307.11769) | 本文通过使用大型语言模型（LLM）自动化和半自动化的方法，在自动驾驶领域进行了领域知识蒸馏的实证研究。他们发现，尽管完全自动化的领域本体构建是可行的，但人类监督和早期干预通常可以提高效率和输出质量。 |
| [^27] | [Question Decomposition Improves the Faithfulness of Model-Generated Reasoning.](http://arxiv.org/abs/2307.11768) | 通过将问题分解为子问题，可以显著提高大型语言模型生成推理的忠实度。 |
| [^28] | [Recognition of Mental Adjectives in An Efficient and Automatic Style.](http://arxiv.org/abs/2307.11767) | 本论文提出了一个新的词汇推理任务MPC，通过微调BERT模型和采用主动学习算法，在简化标注资源的同时达到了令人满意的准确性。通过与SentiWordNet的比较，还发现了MPC与情感分析中的主观性分类任务的差异。 |
| [^29] | [Three-way Decisions with Evaluative Linguistic Expressions.](http://arxiv.org/abs/2307.11766) | 本文提出了使用评价性语言表达进行三元决策的方法，并发现了三元决策和评价性语言表达理论之间的新联系。 |
| [^30] | [Sensi-BERT: Towards Sensitivity Driven Fine-Tuning for Parameter-Efficient BERT.](http://arxiv.org/abs/2307.11764) | Sensi-BERT是一种面向敏感度驱动的参数高效BERT微调方法，通过敏感度分析和裁剪参数张量，可生成适用于下游任务的高度参数高效的模型。 |
| [^31] | [Similarity-based Memory Enhanced Joint Entity and Relation Extraction.](http://arxiv.org/abs/2307.11762) | 本文提出了一种基于相似性的记忆增强联合实体和关系抽取的方法，通过在任务之间建立双向内存依赖关系，从而更准确地执行文档级联合实体和关系抽取问题。实证研究表明，该方法优于现有方法，并在BioCreative V CDR语料库上达到了最先进的结果。 |
| [^32] | [Fairness of ChatGPT and the Role Of Explainable-Guided Prompts.](http://arxiv.org/abs/2307.11761) | 本研究调查了ChatGPT在信用风险评估中的潜力，发现通过精心设计的提示指导和领域特定知识的补充，ChatGPT能够与传统机器学习模型相媲美，使用的数据量少至传统模型的1/40，表现优异，尤其擅长减小误报并提升公平性。这为未来在其他类似任务中充分利用ChatGPT的能力奠定了基础。 |
| [^33] | [EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus.](http://arxiv.org/abs/2307.11760) | EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。 |
| [^34] | [CausE: Towards Causal Knowledge Graph Embedding.](http://arxiv.org/abs/2307.11610) | CausE是一个采用因果知识图谱嵌入和嵌入解缠的框架，利用因果干预进行稳定预测，并在知识图谱完整性任务上取得了最先进的性能。 |
| [^35] | [Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation.](http://arxiv.org/abs/2307.11019) | 本研究初步分析了大型语言模型的事实知识边界，并研究了检索增强对开放域问答任务中大型语言模型的影响。结果显示大型语言模型在回答问题时表现出自信，并且回答准确。 |
| [^36] | [LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?.](http://arxiv.org/abs/2307.10719) | 本文讨论了大型语言模型(LLM)的审查问题，指出现有的语义审查方法存在理论上的限制，由于LLM的程序化和遵循指令的能力，语义审查可以被认为是一个不可判定的问题。同时，有知识的攻击者可以重构不可容许的输出。 |
| [^37] | [(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs.](http://arxiv.org/abs/2307.10490) | 本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。 |
| [^38] | [Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model.](http://arxiv.org/abs/2307.10443) | 本文提出了一种新的注意力模式，使用图增强自注意力机制将从异构图中导出的推理知识整合到变压器架构中，从而克服了变压器模型在复杂推理任务中的限制。通过全局-局部注意力、图注意力和关系类型考虑，优化了实体和单词之间的注意力。该模式与相对位置标签相结合，能够与LUKE的实体感知自注意力机制相集成。 |
| [^39] | [SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning.](http://arxiv.org/abs/2307.10234) | 本研究通过利用GPT进行高级情感分析，并考察其与当前机器学习方法的差异，发现GPT方法相较于其他模型在预测性能上具有显著优势，并有效解决了情感分析任务中的一些挑战，如理解上下文和检测讽刺。 |
| [^40] | [An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods.](http://arxiv.org/abs/2307.10025) | 本研究通过采用多粒度主题分析方法，对微博评论进行语义分析，发现关于取消婚姻登记的生育限制的提案涉及个人、社会和国家三个维度，详细讨论了个人行为、社会伦理和法律以及国家政策等社会问题。 |
| [^41] | [Generating Mathematical Derivations with Large Language Models.](http://arxiv.org/abs/2307.09998) | 本文利用大型语言模型生成数学导出，分析了微调模型对未见符号和方程结构更改的敏感性，结果表明微调的FLAN-T5-large（MathT5）在各个测试集上的绝对性能优于GPT模型。 |
| [^42] | [Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models.](http://arxiv.org/abs/2307.08303) | 本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。 |
| [^43] | [Disco-Bench: A Discourse-Aware Evaluation Benchmark for Language Modelling.](http://arxiv.org/abs/2307.08074) | Disco-Bench是一个面向语言建模的论述感知评估基准，可以跨多个NLP任务评估句内论述属性。我们设计了文献领域的9个测试集和一个诊断测试套件来评估模型的论述知识。我们在20个不同模型上进行了评估。 |
| [^44] | [AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge.](http://arxiv.org/abs/2307.07851) | AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。 |
| [^45] | [LaunchpadGPT: Language Model as Music Visualization Designer on Launchpad.](http://arxiv.org/abs/2307.04827) | 我们提出了LaunchpadGPT模型，利用语言模型生成音乐可视化设计，并展示出优于随机生成方法的效果，具有广泛的音乐可视化应用潜力。 |
| [^46] | [Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review.](http://arxiv.org/abs/2307.03691) | 该论文提出了一个模型，利用用户评论和相关项目特征生成对比评价句子，以帮助用户找到最适合的产品。该模型包括项目编码模块、比较生成模块和个性化解码方法，并通过人类评估验证了生成句子的相关性和真实性。 |
| [^47] | [Efficient Domain Adaptation of Sentence Embeddings using Adapters.](http://arxiv.org/abs/2307.03104) | 本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。 |
| [^48] | [ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection.](http://arxiv.org/abs/2307.02591) | 这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。 |
| [^49] | [Improved NL2SQL based on Multi-layer Expert Network.](http://arxiv.org/abs/2306.17727) | 本研究提出了一种名为多层专家生成SQL的新方法，通过利用专用的多任务分层网络，该方法解决了由于不同分类任务的负迁移问题导致生成不准确SQL语句的限制。该方法在WiKSQL数据集上取得了良好的效果。 |
| [^50] | [Is ChatGPT a Biomedical Expert? -- Exploring the Zero-Shot Performance of Current GPT Models in Biomedical Tasks.](http://arxiv.org/abs/2306.16108) | 通过对 GPT-3.5-Turbo 和 GPT-4 在生物医学任务中的表现评估，发现它们能够通过零样本学习和相关片段的支撑与领先系统相竞争，但在检索任务中表现不如其他系统。 |
| [^51] | [Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models.](http://arxiv.org/abs/2306.14096) | 本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。 |
| [^52] | [Inference-Time Intervention: Eliciting Truthful Answers from a Language Model.](http://arxiv.org/abs/2306.03341) | 本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。 |
| [^53] | [Emotion Experiencer Recognition as a Prerequisite for Experiencer-Specific Emotion Analysis.](http://arxiv.org/abs/2305.16731) | 本文提出了一种用于检测情感体验者并为其分配情感的自动方法，并进行了相关的实验。该方法的实现具有挑战性，但展示了在文本中检测情感体验者的可行性。 |
| [^54] | [Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art.](http://arxiv.org/abs/2305.16259) | 本文简要概述了长文本的神经自然语言处理的现状，主要包括文档分类和摘要，涵盖了情感分析，同时还探讨了长文本NLP的主要挑战、问题和解决方案。 |
| [^55] | [Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode.](http://arxiv.org/abs/2305.11435) | 本文提出采用基于视觉引导的自监督语音模型进行音节发现和跨语言泛化。使用最小割算法和2阶段聚类方法自动预测语音中的音节边界。在英语上表现优于最先进的音节分割方法，并以零样本的方式在爱沙尼亚语上泛化。在其他语言上也取得了成功。 |
| [^56] | [Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information.](http://arxiv.org/abs/2305.01788) | 本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。 |
| [^57] | [Towards autonomous system: flexible modular production system enhanced with large language model agents.](http://arxiv.org/abs/2304.14721) | 本论文介绍了一种将大语言模型、数字孪生和工业自动化系统相结合的框架，实现生产过程的智能化规划和控制。通过LLM代理的协调控制，实现了灵活生产的自主规划和控制，能够处理未预定义的任务并规划生产过程。 |
| [^58] | [Classification of US Supreme Court Cases using BERT-Based Techniques.](http://arxiv.org/abs/2304.08649) | 本文基于BERT技术探究了对美国最高法院案例进行分类的方法，比较了使用BERT模型与其他先进模型的准确性，最终在15个广泛类别上取得了80%的准确度，在279个细粒度类别上取得了60%的准确度。 |
| [^59] | [ELVIS: Empowering Locality of Vision Language Pre-training with Intra-modal Similarity.](http://arxiv.org/abs/2304.05303) | 本文提出了一种新的视觉语言预训练方法，称为ELVIS，可以增强放射学报告或 X 射线图像中的局部性能力，提高了理解位置参考的能力。 |
| [^60] | [Practical and Ethical Challenges of Large Language Models in Education: A Systematic Literature Review.](http://arxiv.org/abs/2303.13379) | LLMs在教育中有自动生成和分析文本内容的潜力。然而，这些创新的实际性和伦理性存在担忧，需要考虑技术可行性、隐私、平等和善意等因素。 |
| [^61] | [MenuCraft: Interactive Menu System Design with Large Language Models.](http://arxiv.org/abs/2303.04496) | MenuCraft是一个基于大型语言模型的AI辅助设计师，通过对话系统与设计师协作，提供了一个交互式菜单设计工具，可以简化菜单设计过程，并支持零/少次学习。 |
| [^62] | [How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding.](http://arxiv.org/abs/2303.04245) | 本文提供了对Transformer学习语义结构的机制性理解，通过数学分析和实验证明了嵌入层和自注意力层如何对词汇的共现结构进行编码。 |
| [^63] | [Detecting Harmful Agendas in News Articles.](http://arxiv.org/abs/2302.00102) | 这项研究提出了一种新的任务，即在新闻文章中检测有害议程，并发布了一个新闻文章注释数据集以供研究使用。研究者展示了可解释系统在这一任务上的有效性，并证明它们可以和黑盒模型有相当的表现。 |
| [^64] | [DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature.](http://arxiv.org/abs/2301.11305) | 本论文提出了一种名为DetectGPT的方法，使用概率曲率来判断文本是否由一个给定的大型语言模型生成。该方法不需要训练分类器、收集数据集或明确加水印，只使用模型计算的对数概率和另一个预训练语言模型的随机扰动。实验证明，DetectGPT在模型采样方面比现有的零样本方法更具有区分能力。 |
| [^65] | [Can Very Large Pretrained Language Models Learn Storytelling With A Few Examples?.](http://arxiv.org/abs/2301.09790) | 本文探讨了使用极大预训练语言模型（VLPLMs）创作故事的可能性，并通过与SOTA模型在不同数据集上的比较，证明VLPLMs生成的故事质量更高，并展示一定程度上可与人类作者相抗衡，尽管初步调查揭示了它们倾向于“抄袭”真实的故事。 |
| [^66] | [A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multimodal.](http://arxiv.org/abs/2212.05767) | 本文对知识图谱推理进行了综述，涵盖了静态、动态和多模态三种图类型，填补了这一领域的研究空白。 |
| [^67] | [Style Classification of Rabbinic Literature for Detection of Lost Midrash Tanhuma Material.](http://arxiv.org/abs/2211.09710) | 本文提出了一种拉比文学的分类系统，可以通过其风格来检测Midrash Tanhuma中的失落材料。 |
| [^68] | [Toward expanding the scope of radiology report summarization to multiple anatomies and modalities.](http://arxiv.org/abs/2211.08584) | 本论文针对放射学报告摘要存在的限制，提出了一个新的数据集MIMIC-RRS，包含多个解剖学和模态。通过在数据集上进行实验和临床评估，我们旨在扩大放射学报告摘要的应用范围。 |
| [^69] | [Log-linear Guardedness and its Implications.](http://arxiv.org/abs/2210.10012) | 本研究介绍了对数线性保护性及其对下游分类器行为的影响。在二元情况下，下游对数线性模型无法恢复被删除的概念，但在某些情况下，可以通过构建多类对数线性模型间接恢复概念。这些结果揭示了线性删除方法的局限性，并强调了进一步研究的需求。 |
| [^70] | [Learning "O" Helps for Learning More: Handling the Concealed Entity Problem for Class-incremental NER.](http://arxiv.org/abs/2210.04676) | 本研究解决了类增量NER中的隐藏实体问题，提出了一种表示学习方法，通过对实体类别和"O"进行判别式表示学习，改善了NER模型对于新旧类别的识别能力。 |
| [^71] | [DSTEA: Improving Dialogue State Tracking via Entity Adaptive Pre-training.](http://arxiv.org/abs/2207.03858) | 本研究提出了DSTEA方法，通过实体自适应预训练来改进对话状态跟踪。它通过密集训练对话话语中的关键实体，而无需外部对话语料库，并且只需要进行预训练而不直接注入额外的知识到DST模型中。这种方法取得了出色的效果。 |
| [^72] | [LAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model.](http://arxiv.org/abs/2111.09564) | 我们提出了一种名为LAnoBERT的无解析器系统日志异常检测方法，它使用了BERT模型进行掩码语言建模，从而实现了无人工干预的高效异常检测。 |
| [^73] | [SparseGAN: Sparse Generative Adversarial Network for Text Generation.](http://arxiv.org/abs/2103.11578) | SparseGAN是一种稀疏生成对抗网络，通过生成语义可解释且稀疏的句子表示作为输入，实现了在生成对抗网络框架下的神经文本生成模型的学习。通过使用稀疏编码的思想，SparseGAN有效地减少了噪音并实现了完全可微分的训练过程。实验证明SparseGAN在多个文本生成数据集上取得了性能的提升，特别是在序列生成任务中。 |
| [^74] | [XTQA: Span-Level Explanations of the Textbook Question Answering.](http://arxiv.org/abs/2011.12662) | XTQA是针对教科书问答任务提出的一种新架构，通过跨句解释提供答案和证据，显著提高了性能。 |
| [^75] | [Unsupervised Summarization by Jointly Extracting Sentences and Keywords.](http://arxiv.org/abs/2009.07481) | 本论文提出了一种无监督的图排名模型RepRank，通过在统一的向量空间中计算单词、句子和单词到句子之间的距离，来提取多文档摘要中的突出句子和关键词。通过自注意力的学习方法，将句子表示为其词嵌入的加权和，能够更好地反映文档内容。实验证明，通过联合提取句子和关键词的过程可以相互增强，并且总是收敛到唯一的解，从而提高了性能。同时，采用吸收式随机游走的变体和基于采样的算法，可以避免冗余并增加多样性。 |
| [^76] | [Improving Coreference Resolution by Leveraging Entity-Centric Features with Graph Neural Networks and Second-order Inference.](http://arxiv.org/abs/2009.04639) | 该论文提出了一种基于图神经网络和二阶推理的指代消解方法，通过鼓励共享提及之间的特征，有效地捕捉实体为中心的信息，并提供了一个全局推理算法来最优地聚类提及。实验证明该方法的效果很好。 |
| [^77] | [Attention Is All You Need.](http://arxiv.org/abs/1706.03762) | Transformer是一种新的简单网络架构，完全基于注意力机制，取代了复杂的循环神经网络或卷积神经网络。实验证明Transformer在机器翻译任务中的质量更好、并行化效果更佳，且训练时间更短。它在英译德和英译法任务中取得了比其他模型更好的结果。 |

# 详细

[^1]: FATRER: 用于准确和稳健的会话情感识别的全注意力主题正则化器

    FATRER: Full-Attention Topic Regularizer for Accurate and Robust Conversational Emotion Recognition. (arXiv:2307.12221v1 [cs.CL])

    [http://arxiv.org/abs/2307.12221](http://arxiv.org/abs/2307.12221)

    本文介绍了一种全注意力主题正则化器，用于增强情感识别器在处理对话中的局部上下文时获得情感相关的全局视角，实验证明该模型在准确性和稳健性方面取得了更好的效果。

    

    本文关注于理解会话话语中引发的对话者情绪。之前的研究主要关注于更准确的情感预测，而忽视了当局部上下文被对抗性攻击破坏时模型的稳健性。为了在保证准确性的同时维持稳健性，我们提出了一种由全注意力主题正则化器增强的情感识别器，在建模对话中的局部上下文时实现情感相关的全局视角。引入联合主题建模策略，从表示和损失的角度实现正则化。为了避免过度正则化，我们放弃了传统主题建模中存在的关于先验分布的限制，并完全依靠注意力对齐进行概率近似。实验证明，我们的模型比现有最先进的模型获得了更有利的结果，并在三种类型的对抗性攻击下获得了令人信服的稳健性。

    This paper concentrates on the understanding of interlocutors' emotions evoked in conversational utterances. Previous studies in this literature mainly focus on more accurate emotional predictions, while ignoring model robustness when the local context is corrupted by adversarial attacks. To maintain robustness while ensuring accuracy, we propose an emotion recognizer augmented by a full-attention topic regularizer, which enables an emotion-related global view when modeling the local context in a conversation. A joint topic modeling strategy is introduced to implement regularization from both representation and loss perspectives. To avoid over-regularization, we drop the constraints on prior distributions that exist in traditional topic modeling and perform probabilistic approximations based entirely on attention alignment. Experiments show that our models obtain more favorable results than state-of-the-art models, and gain convincing robustness under three types of adversarial attacks
    
[^2]: 模仿游戏：在大型语言模型时代检测人类和AI生成的文本

    The Imitation Game: Detecting Human and AI-Generated Texts in the Era of Large Language Models. (arXiv:2307.12166v1 [cs.CL])

    [http://arxiv.org/abs/2307.12166](http://arxiv.org/abs/2307.12166)

    本论文研究了区分人类和AI生成的文本的任务，在不同体裁下进行了比较研究，提出了一个新的数据集，并采用多种机器学习模型进行分类。结果表明这些模型对于区分人类和AI生成的文本具有很高的效力，尽管在区分GPT生成的文本方面存在一定挑战。

    

    基于人工智能的大型语言模型（LLM）具有革新教育、研究和实践的巨大潜力。然而，区分人类写作和AI生成的文本已经成为一项重要任务。本文介绍了一项比较研究，提出了一个新颖的数据集，包含不同体裁的人类写作和LLM生成的文本：论文、故事、诗歌和Python代码。我们采用了几种机器学习模型来对这些文本进行分类。结果表明，尽管数据集的样本数量有限，这些模型在区分人类和AI生成的文本方面表现出了很高的效力。然而，当分类GPT生成的文本时，任务变得更具挑战性，特别是在故事写作方面。结果表明，与更复杂的多类别任务相比，这些模型在二元分类任务（如区分人类生成文本和特定LLM）方面表现出了更优越的性能。

    The potential of artificial intelligence (AI)-based large language models (LLMs) holds considerable promise in revolutionizing education, research, and practice. However, distinguishing between human-written and AI-generated text has become a significant task. This paper presents a comparative study, introducing a novel dataset of human-written and LLM-generated texts in different genres: essays, stories, poetry, and Python code. We employ several machine learning models to classify the texts. Results demonstrate the efficacy of these models in discerning between human and AI-generated text, despite the dataset's limited sample size. However, the task becomes more challenging when classifying GPT-generated text, particularly in story writing. The results indicate that the models exhibit superior performance in binary classification tasks, such as distinguishing human-generated text from a specific LLM, compared to the more complex multiclass tasks that involve discerning among human-ge
    
[^3]: 通过转录上下文分析与Transformer模型在YouTube上识别错误信息

    Identifying Misinformation on YouTube through Transcript Contextual Analysis with Transformer Models. (arXiv:2307.12155v1 [cs.CL])

    [http://arxiv.org/abs/2307.12155](http://arxiv.org/abs/2307.12155)

    本文介绍了一种通过转录上下文分析和Transformer模型，在YouTube上识别错误信息的新方法。该方法将视频分类任务转化为文本分类任务，采用了迁移学习和少样本学习等先进的机器学习技术。在三个数据集上进行了评估，包括YouTube上的疫苗错误信息相关视频、假科学视频和Fake-News数据集。结果表明，该方法在检测YouTube上的错误信息方面具有良好的性能。

    

    YouTube上的错误信息是一个重要关切，需要强大的检测策略。在本文中，我们引入了一种新的视频分类方法，重点关注内容的真实性。我们通过利用视频转录中获得的文本内容，将传统的视频分类任务转化为文本分类任务。我们采用了先进的机器学习技术，如迁移学习，来解决分类挑战。我们的方法融合了两种形式的迁移学习：（a）微调基础的Transformer模型，如BERT，RoBERTa和ELECTRA，以及（b）使用句子转换器MPNet和RoBERTa-large的少样本学习。我们将训练好的模型应用于三个数据集：（a）与疫苗错误信息相关的YouTube视频，（b）关于假科学的YouTube视频，以及（c）Fake-News数据集（一系列文章的集合）。包括Fake-News数据集扩展了我们方法的评估范围，超越了YouTube视频。

    Misinformation on YouTube is a significant concern, necessitating robust detection strategies. In this paper, we introduce a novel methodology for video classification, focusing on the veracity of the content. We convert the conventional video classification task into a text classification task by leveraging the textual content derived from the video transcripts. We employ advanced machine learning techniques like transfer learning to solve the classification challenge. Our approach incorporates two forms of transfer learning: (a) fine-tuning base transformer models such as BERT, RoBERTa, and ELECTRA, and (b) few-shot learning using sentence-transformers MPNet and RoBERTa-large. We apply the trained models to three datasets: (a) YouTube Vaccine-misinformation related videos, (b) YouTube Pseudoscience videos, and (c) Fake-News dataset (a collection of articles). Including the Fake-News dataset extended the evaluation of our approach beyond YouTube videos. Using these datasets, we evalua
    
[^4]: 鲁棒的端到端语音理解中的模态置信度训练

    Modality Confidence Aware Training for Robust End-to-End Spoken Language Understanding. (arXiv:2307.12134v1 [cs.CL])

    [http://arxiv.org/abs/2307.12134](http://arxiv.org/abs/2307.12134)

    该论文提出了一种鲁棒的端到端语音理解（SLU）系统，通过融合基于ASR假设的模态置信度来增强对ASR错误的容错性。他们的方法通过有效的编码ASR假设质量，成功将其整合到E2E SLU模型中，提高了准确性。

    

    最近，从语音生成语义解析的端到端语音理解（SLU）系统变得更加有希望。这种方法使用一个单一模型，利用预训练语音识别模型（ASR）的音频和文本表示，相比传统的流媒体场景下的流水线SLU系统效果更好。然而，端到端SLU系统仍然在ASR转写错误导致文本表示质量低时显示出弱点。为了解决这个问题，我们提出了一种新颖的端到端SLU系统，通过融合基于估计的ASR假设的模态置信度来增强对ASR错误的容错性。我们引入了两种新颖的技术：1）一种有效的方法来编码ASR假设的质量，2）一种有效的方法将它们整合到端到端SLU模型中。我们展示了在STOP数据集上的准确度改进，并分享分析结果以证明我们的方法的有效性。

    End-to-end (E2E) spoken language understanding (SLU) systems that generate a semantic parse from speech have become more promising recently. This approach uses a single model that utilizes audio and text representations from pre-trained speech recognition models (ASR), and outperforms traditional pipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems still show weakness when text representation quality is low due to ASR transcription errors. To overcome this issue, we propose a novel E2E SLU system that enhances robustness to ASR errors by fusing audio and text representations based on the estimated modality confidence of ASR hypotheses. We introduce two novel techniques: 1) an effective method to encode the quality of ASR hypotheses and 2) an effective approach to integrate them into E2E SLU models. We show accuracy improvements on STOP dataset and share the analysis to demonstrate the effectiveness of our approach.
    
[^5]: 从异构数据源中可解释的主题增强的论点挖掘

    Explainable Topic-Enhanced Argument Mining from Heterogeneous Sources. (arXiv:2307.12131v1 [cs.CL])

    [http://arxiv.org/abs/2307.12131](http://arxiv.org/abs/2307.12131)

    这项研究提出了一种可解释的主题增强的论点挖掘方法，通过使用神经主题模型和语言模型来处理多样化的目标相关子主题，并利用句级主题信息进行分析。

    

    鉴于像“核能”这样的有争议的目标，论点挖掘旨在从异构数据源中识别论证性文本。目前的方法注重探索更好的方法将目标相关的语义信息与论证性文本相结合。尽管它们在经验上取得了成功，但仍然存在两个问题：(一)目标由一个词或短语表示，无法涵盖多样化的目标相关子主题；(二)在论证中忽略了句级主题信息，我们认为这对于论点挖掘至关重要。为解决上述问题，我们提出了一种新颖的可解释的主题增强的论点挖掘方法。具体而言，通过使用神经主题模型和语言模型，目标信息通过可解释的主题表示进行扩充。此外，通过最小化其潜在主题分布与其语义之间的距离来捕捉论证中的句级主题信息。

    Given a controversial target such as ``nuclear energy'', argument mining aims to identify the argumentative text from heterogeneous sources. Current approaches focus on exploring better ways of integrating the target-associated semantic information with the argumentative text. Despite their empirical successes, two issues remain unsolved: (i) a target is represented by a word or a phrase, which is insufficient to cover a diverse set of target-related subtopics; (ii) the sentence-level topic information within an argument, which we believe is crucial for argument mining, is ignored. To tackle the above issues, we propose a novel explainable topic-enhanced argument mining approach. Specifically, with the use of the neural topic model and the language model, the target information is augmented by explainable topic representations. Moreover, the sentence-level topic information within the argument is captured by minimizing the distance between its latent topic distribution and its semantic
    
[^6]: 零样本和少样本情况下应用于临床和生物医学任务的指导细调大型语言模型的研究

    A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks. (arXiv:2307.12114v1 [cs.CL])

    [http://arxiv.org/abs/2307.12114](http://arxiv.org/abs/2307.12114)

    这项研究评估了四种指导细调大型语言模型在临床和生物医学任务上的表现，并发现它们在零样本和少样本情况下接近最先进模型的性能，尤其在问答任务上表现良好。然而，在分类和关系抽取任务上的表现稍逊于特定训练于医学领域的模型。没有一个模型在所有研究任务上胜过其他模型，有些模型更适合特定任务。

    

    我们评估了四种最先进的指导细调大型语言模型（LLM）——ChatGPT、Flan-T5 UL2、Tk-Instruct和Alpaca——在13个实际世界的临床和生物医学自然语言处理（NLP）任务中的表现，例如命名实体识别（NER）、问答（QA）、关系抽取（RE）等。我们的综合结果表明，在大多数任务的零样本和少样本情况下，评估的LLM开始接近最先进模型的性能，尤其对于QA任务表现得特别好，即使它们之前没有见过这些任务的示例。然而，我们观察到分类和关系抽取任务的表现低于特定训练于医学领域的模型（如PubMedBERT）可以达到的水平。最后，我们注意到没有一个LLM在所有研究任务上都胜过其他模型，有些模型更适合于特定的任务。

    We evaluate four state-of-the-art instruction-tuned large language models (LLMs) -- ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca -- on a set of 13 real-world clinical and biomedical natural language processing (NLP) tasks in English, such as named-entity recognition (NER), question-answering (QA), relation extraction (RE), etc. Our overall results demonstrate that the evaluated LLMs begin to approach performance of state-of-the-art models in zero- and few-shot scenarios for most tasks, and particularly well for the QA task, even though they have never seen examples from these tasks before. However, we observed that the classification and RE tasks perform below what can be achieved with a specifically trained model for the medical field, such as PubMedBERT. Finally, we noted that no LLM outperforms all the others on all the studied tasks, with some models being better suited for certain tasks than others.
    
[^7]: 外部推理：朝着多种大型语言模型可互换辅助与人类反馈的方向前进

    External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback. (arXiv:2307.12057v1 [cs.CL])

    [http://arxiv.org/abs/2307.12057](http://arxiv.org/abs/2307.12057)

    本文提出通过从外部存储库中选择性地集成知识来增强大型语言模型，提出了一种外部推理的新方法，例子是ChatPDF。

    

    记忆被认为是使海马体和脑神经元内保持视觉和语言信息、随后用于解决通过学习一生中遇到的现实挑战的关键人类能力。通过应用已获得的知识解决复杂的人工智能任务是实现人工通用智能的一大进展。然而，尽管像GPT-3.5和GPT-4这样的大型语言模型在语言理解、生成、交互和推理方面显示了卓越的能力，但由于上下文长度的限制，它们无法处理广泛、不断演变的知识库。本文提出通过从外部存储库中选择性地集成知识来增强LLMs，并介绍了一种外部推理的新方法，例子是ChatPDF。

    Memory is identified as a crucial human faculty that allows for the retention of visual and linguistic information within the hippocampus and neurons in the brain, which can subsequently be retrieved to address real-world challenges that arise through a lifetime of learning. The resolution of complex AI tasks through the application of acquired knowledge represents a stride toward the realization of artificial general intelligence. However, despite the prevalence of Large Language Models (LLMs) like GPT-3.5 and GPT-4 , which have displayed remarkable capabilities in language comprehension, generation, interaction, and reasoning, they are inhibited by constraints on context length that preclude the processing of extensive, continually evolving knowledge bases. This paper proposes that LLMs could be augmented through the selective integration of knowledge from external repositories, and in doing so, introduces a novel methodology for External Reasoning, exemplified by ChatPDF. Central to
    
[^8]: 重新审视用于机器人手术视觉问题定位回答的蒸馏连续学习方法

    Revisiting Distillation for Continual Learning on Visual Question Localized-Answering in Robotic Surgery. (arXiv:2307.12045v1 [cs.CV])

    [http://arxiv.org/abs/2307.12045](http://arxiv.org/abs/2307.12045)

    本文研究了用于机器人手术中视觉问题定位回答的蒸馏连续学习方法。通过重新审视蒸馏损失，提出了刚性-可塑性感知蒸馏和自校准异质蒸馏来保留旧知识。

    

    视觉问题定位回答（VQLA）系统可以作为手术教育中的知识助手。除了提供基于文本的答案外，VQLA系统还可以高亮感兴趣的区域，以提高手术场景的理解能力。然而，深度神经网络（DNNs）在学习新知识时容易发生灾难性遗忘。具体来说，当DNNs在增量类别或任务上学习时，其对旧任务的性能会大幅下降。此外，由于医疗数据隐私和许可问题，更新连续学习（CL）模型时往往难以访问旧数据。因此，我们开发了一个非示例连续手术VQLA框架，以在顺序学习范式中探索和平衡DNNs的刚性和可塑性之间的权衡。我们重新审视了CL任务中的蒸馏损失，并提出了刚性-可塑性感知蒸馏（RP-Dist）和自校准异质蒸馏（SH-Dist）来保留旧知识。

    The visual-question localized-answering (VQLA) system can serve as a knowledgeable assistant in surgical education. Except for providing text-based answers, the VQLA system can highlight the interested region for better surgical scene understanding. However, deep neural networks (DNNs) suffer from catastrophic forgetting when learning new knowledge. Specifically, when DNNs learn on incremental classes or tasks, their performance on old tasks drops dramatically. Furthermore, due to medical data privacy and licensing issues, it is often difficult to access old data when updating continual learning (CL) models. Therefore, we develop a non-exemplar continual surgical VQLA framework, to explore and balance the rigidity-plasticity trade-off of DNNs in a sequential learning paradigm. We revisit the distillation loss in CL tasks, and propose rigidity-plasticity-aware distillation (RP-Dist) and self-calibrated heterogeneous distillation (SH-Dist) to preserve the old knowledge. The weight aligni
    
[^9]: 用基于人工智能的大型语言模型扩展全球心理健康心理服务的Psy-LLM

    Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models. (arXiv:2307.11991v1 [cs.CL])

    [http://arxiv.org/abs/2307.11991](http://arxiv.org/abs/2307.11991)

    Psy-LLM是一个基于人工智能的系统，利用大型语言模型（LLMs）为在线心理咨询提供问答服务，前端工具可让医疗专业人员提供即时响应和正念活动，同时还可作为筛查工具辅助识别紧急案例。

    

    近年来，心理咨询的需求显著增长，特别是随着全球COVID-19的爆发，这加强了及时和专业的心理健康支持的需求。在线心理咨询成为应对这一需求的主要服务方式。在本研究中，我们提出了Psy-LLM框架，这是一种基于人工智能的系统，利用大型语言模型（LLMs）进行在线心理咨询中的问答。我们的框架结合了经过预训练的LLMs和从心理学家和广泛收集的心理文章中获取的真实世界专业问答。Psy-LLM框架作为医疗专业人员的前端工具，允许他们提供即时响应和正念活动来缓解患者压力，同时还可以作为筛查工具，识别需要进一步协助的紧急案例。我们使用困惑度等内在度量标准和外部度量标准对框架进行了评估。

    The demand for psychological counseling has grown significantly in recent years, particularly with the global outbreak of COVID-19, which has heightened the need for timely and professional mental health support. Online psychological counseling has emerged as the predominant mode of providing services in response to this demand. In this study, we propose the Psy-LLM framework, an AI-based system leveraging Large Language Models (LLMs) for question-answering in online psychological consultation. Our framework combines pre-trained LLMs with real-world professional Q&A from psychologists and extensively crawled psychological articles. The Psy-LLM framework serves as a front-end tool for healthcare professionals, allowing them to provide immediate responses and mindfulness activities to alleviate patient stress. Additionally, it functions as a screening tool to identify urgent cases requiring further assistance. We evaluated the framework using intrinsic metrics, such as perplexity, and ex
    
[^10]: 从YouTube视频中学习视觉与语言导航

    Learning Vision-and-Language Navigation from YouTube Videos. (arXiv:2307.11984v1 [cs.CV])

    [http://arxiv.org/abs/2307.11984](http://arxiv.org/abs/2307.11984)

    本文提出了从YouTube视频中学习视觉与语言导航的方法，通过创建大规模数据集，利用房屋导览视频中的路径指令对进行预训练，解决了泛化能力不足的问题，并提出了处理自动构建路径指令对和从无标签视频中提取布局知识的挑战的方法。

    

    视觉与语言导航需要一个具有身体的机器人代理在现实的三维环境中使用自然语言指令进行导航。现有的视觉与语言导航方法在小规模环境或不合理的路径指令数据集上进行训练，限制了对未知环境的泛化能力。YouTube上有大量的房屋导览视频，提供了丰富的真实导览经验和布局信息。然而，这些视频在视觉与语言导航方面尚未得到探索。在本文中，我们提出通过创建一个大规模的数据集，从导览视频中获取合理的路径指令对，并在其上进行预训练，从这些视频中学习一个智能机器人代理。为了实现这一目标，我们需要解决自动构建路径指令对和从原始和无标签视频中利用真实布局知识的挑战。为了解决这些问题，我们首先利用基于熵的方法构建路径轨迹的节点。然后，我们提出了一个 action-aware g模型来从视频中提取布局知识。

    Vision-and-language navigation (VLN) requires an embodied agent to navigate in realistic 3D environments using natural language instructions. Existing VLN methods suffer from training on small-scale environments or unreasonable path-instruction datasets, limiting the generalization to unseen environments. There are massive house tour videos on YouTube, providing abundant real navigation experiences and layout information. However, these videos have not been explored for VLN before. In this paper, we propose to learn an agent from these videos by creating a large-scale dataset which comprises reasonable path-instruction pairs from house tour videos and pre-training the agent on it. To achieve this, we have to tackle the challenges of automatically constructing path-instruction pairs and exploiting real layout knowledge from raw and unlabeled videos. To address these, we first leverage an entropy-based method to construct the nodes of a path trajectory. Then, we propose an action-aware g
    
[^11]: 选择性感知：利用强化学习为语言模型演员优化状态描述

    Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors. (arXiv:2307.11922v1 [cs.LG])

    [http://arxiv.org/abs/2307.11922](http://arxiv.org/abs/2307.11922)

    本研究提出了一种名为BLINDER的方法，通过学习任务条件下状态描述的值函数，自动选择简明的状态描述，以优化大型语言模型(LLM)演员在顺序决策任务中的性能和效率。

    

    大型语言模型(LLM)被应用于机器人和游戏等顺序决策任务的演员中，利用其丰富的世界知识和规划能力。然而，以往的研究很少探索通过语言向LLM演员提供什么环境状态信息。详尽描述高维状态可能会影响性能并增加LLM演员的推理成本。以前的LLM演员通过依赖手工设计的任务特定协议来确定该状态的哪些特征需要进行传递，哪些不需要。在本工作中，我们提出了一种名为BLINDER的方法，通过学习任务条件下状态描述的值函数，自动选择简明的状态描述。我们在具有挑战性的视频游戏NetHack和机器人操作任务中评估了BLINDER。我们的方法提高了任务成功率，减少了输入大小和计算成本，并且提高了生成的结果。

    Large language models (LLMs) are being applied as actors for sequential decision making tasks in domains such as robotics and games, utilizing their general world knowledge and planning abilities. However, previous work does little to explore what environment state information is provided to LLM actors via language. Exhaustively describing high-dimensional states can impair performance and raise inference costs for LLM actors. Previous LLM actors avoid the issue by relying on hand-engineered, task-specific protocols to determine which features to communicate about a state and which to leave out. In this work, we propose Brief Language INputs for DEcision-making Responses (BLINDER), a method for automatically selecting concise state descriptions by learning a value function for task-conditioned state descriptions. We evaluate BLINDER on the challenging video game NetHack and a robotic manipulation task. Our method improves task success rate, reduces input size and compute costs, and gen
    
[^12]: CARTIER: 面向机器人指令执行的地图语言推理

    CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots. (arXiv:2307.11865v1 [cs.RO])

    [http://arxiv.org/abs/2307.11865](http://arxiv.org/abs/2307.11865)

    本研究使用大型语言模型，探索了在空间规划和导航交叉问题中，通过解析复杂的自然语言指令来执行任务的新方法。

    

    本研究探索了大型语言模型（LLM）在空间规划和自然语言界面与导航交叉问题中的应用能力。我们的重点是遵循相对复杂的指令，这些指令更类似于自然对话，而不是传统的显式过程指令。与大多数先前的工作不同，在那些导航指令被提供为命令式指令（例如，去冰箱）的情况下，我们研究了对话交互中的隐式指令。我们利用3D模拟器AI2Thor创建复杂且可重复的场景，并通过为40种对象类型添加复杂的语言查询来增强它。我们证明，通过使用LLM将用户交互解释为场景中对象列表的上下文，机器人可以更好地解析描述性语言查询，优于现有方法。

    This work explores the capacity of large language models (LLMs) to address problems at the intersection of spatial planning and natural language interfaces for navigation.Our focus is on following relatively complex instructions that are more akin to natural conversation than traditional explicit procedural directives seen in robotics. Unlike most prior work, where navigation directives are provided as imperative commands (e.g., go to the fridge), we examine implicit directives within conversational interactions. We leverage the 3D simulator AI2Thor to create complex and repeatable scenarios at scale, and augment it by adding complex language queries for 40 object types. We demonstrate that a robot can better parse descriptive language queries than existing methods by using an LLM to interpret the user interaction in the context of a list of the objects in the scene.
    
[^13]: 虚假和大规模语言模型生成的领英个人资料的潜在威胁：检测和预防的挑战与机遇

    The Looming Threat of Fake and LLM-generated LinkedIn Profiles: Challenges and Opportunities for Detection and Prevention. (arXiv:2307.11864v1 [cs.SI])

    [http://arxiv.org/abs/2307.11864](http://arxiv.org/abs/2307.11864)

    本文介绍了一种在领英平台上检测虚假和大规模语言模型生成的个人资料的新方法，该方法使用领英个人资料中的文本信息，并引入“部分和子部分标签嵌入”（SSTE）方法以增强数据的特征。研究还通过收集3600个领英个人资料建立了一个公开可用的数据集。

    

    本文提出了一种新的方法，用于在领英在线社交网络注册时和建立连接之前立即检测虚假和大规模语言模型生成的个人资料。早期识别虚假资料对于维护平台的完整性至关重要，它可以防止冒名顶替者获取合法用户的私密和敏感信息，并防止他们获得增加未来钓鱼和欺诈活动可信度的机会。本研究利用领英个人资料中提供的文本信息，并引入了“部分和子部分标签嵌入”（SSTE）方法，以增强区分合法资料和冒名顶替者手动或使用大规模语言模型生成的资料的特征。此外，鉴于目前公开可用的领英数据集较少，我们为研究收集了3600个领英个人资料，并将公开发布我们的数据集供研究使用。

    In this paper, we present a novel method for detecting fake and Large Language Model (LLM)-generated profiles in the LinkedIn Online Social Network immediately upon registration and before establishing connections. Early fake profile identification is crucial to maintaining the platform's integrity since it prevents imposters from acquiring the private and sensitive information of legitimate users and from gaining an opportunity to increase their credibility for future phishing and scamming activities. This work uses textual information provided in LinkedIn profiles and introduces the Section and Subsection Tag Embedding (SSTE) method to enhance the discriminative characteristics of these data for distinguishing between legitimate profiles and those created by imposters manually or by using an LLM. Additionally, the dearth of a large publicly available LinkedIn dataset motivated us to collect 3600 LinkedIn profiles for our research. We will release our dataset publicly for research pur
    
[^14]: MythQA: 多答案开放领域问题回答中的大规模查询值得检查的断言检测

    MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Question Answering. (arXiv:2307.11848v1 [cs.CL])

    [http://arxiv.org/abs/2307.11848](http://arxiv.org/abs/2307.11848)

    MythQA是一项新的多答案开放领域问题回答（QA）任务，旨在通过矛盾立场挖掘来检测大规模查询值得检查的断言。该任务通过构建一个包含522个基于有争议的话题的评估数据集来进行研究。

    

    查询值得检查的断言检测旨在向下游的事实核查系统或人工专家提供可能的错误信息进行检查。这是加速事实核查过程的关键步骤。许多努力已经投入到如何从预收集的少量断言中识别值得检查的断言的研究中，但如何直接从大规模信息源（如Twitter）有效检测值得检查的断言仍然未被充分探索。为了填补这一空白，我们引入了MythQA，一项新的多答案开放领域问题回答（QA）任务，该任务涉及用于查询值得检查的大规模断言检测的矛盾立场挖掘。这一想法的背后是，矛盾的断言是值得由适当的机构进行审查的错误信息的强有力指标。为了研究这个任务，我们构建了TweetMythQA，一个包含522个基于有争议的话题的事实型多答案问题的评估数据集。每个问题都带有多个答案。

    Check-worthy claim detection aims at providing plausible misinformation to downstream fact-checking systems or human experts to check. This is a crucial step toward accelerating the fact-checking process. Many efforts have been put into how to identify check-worthy claims from a small scale of pre-collected claims, but how to efficiently detect check-worthy claims directly from a large-scale information source, such as Twitter, remains underexplored. To fill this gap, we introduce MythQA, a new multi-answer open-domain question answering(QA) task that involves contradictory stance mining for query-based large-scale check-worthy claim detection. The idea behind this is that contradictory claims are a strong indicator of misinformation that merits scrutiny by the appropriate authorities. To study this task, we construct TweetMythQA, an evaluation dataset containing 522 factoid multi-answer questions based on controversial topics. Each question is annotated with multiple answers. Moreover
    
[^15]: 面向银行流程自动化的多模式文档分析

    Multimodal Document Analytics for Banking Process Automation. (arXiv:2307.11845v1 [cs.CL])

    [http://arxiv.org/abs/2307.11845](http://arxiv.org/abs/2307.11845)

    本研究聚焦于应对金融科技竞争和提高银行业务运营效率的需求，通过多模式模型特别是先进的文档分析技术，研究了银行流程中的潜力和机会，并展示了LayoutXLM等模型在分析银行文档中的潜力和性能。

    

    针对金融科技竞争的增长和提高运营效率的需求，本研究关注于理解在银行流程中利用多模式模型特别是先进的文档分析的潜力。我们对多样化的银行文档领域进行了全面分析，突出了通过自动化和先进的分析技术在客户业务中提高效率的机会。基于快速发展的自然语言处理（NLP）领域，我们展示了诸如LayoutXLM这样的模型的潜力，它是一种跨语言、多模式、预训练模型，用于分析银行业中各种不同的文档。该模型对德国公司登记提取的文本标记分类具有大约80%的F1得分性能。我们的实证证据证实了布局信息在提高模型性能方面的关键作用，并进一步强调了整合图像信息的好处。

    In response to growing FinTech competition and the need for improved operational efficiency, this research focuses on understanding the potential of advanced document analytics, particularly using multimodal models, in banking processes. We perform a comprehensive analysis of the diverse banking document landscape, highlighting the opportunities for efficiency gains through automation and advanced analytics techniques in the customer business. Building on the rapidly evolving field of natural language processing (NLP), we illustrate the potential of models such as LayoutXLM, a cross-lingual, multimodal, pre-trained model, for analyzing diverse documents in the banking sector. This model performs a text token classification on German company register extracts with an overall F1 score performance of around 80\%. Our empirical evidence confirms the critical role of layout information in improving model performance and further underscores the benefits of integrating image information. Inte
    
[^16]: 用语音识别能力促进大型语言模型

    Prompting Large Language Models with Speech Recognition Abilities. (arXiv:2307.11795v1 [eess.AS])

    [http://arxiv.org/abs/2307.11795](http://arxiv.org/abs/2307.11795)

    本研究通过为大型语言模型添加音频编码器，使其具备了语音识别能力。在多语言数据集上的实验证明，这样的扩展能够提高模型的性能，并且在多语言环境下实现了语音识别。通过消融研究，我们还发现可以冻结模型以保持其原有功能，并且提升音频编码器的规模有助于提高性能。

    

    大型语言模型已证明其高度灵活，能够解决各种生成任务，如概括性摘要和开放性问答。本文通过直接附加一个小型音频编码器来扩展LLM的功能，使其能够执行语音识别。通过将一系列声音嵌入直接预置到文本令牌嵌入之前，LLM可以转换为自动语音识别（ASR）系统，并且可以与其文本对应物以完全相同的方式使用。在多语言LibriSpeech（MLS）上的实验证明，将一个conformer编码器融入到开源的LLaMA-7B中，使其在单一语言基准上的表现超过18%，并能够执行多语言语音识别，尽管LLaMA的训练主要依赖于英文文本。此外，我们进行了消融研究，以调查LLM在训练过程中是否可以完全冻结以保持其原有功能，以及提升音频编码器的规模。

    Large language models have proven themselves highly flexible, able to solve a wide range of generative tasks, such as abstractive summarization and open-ended question answering. In this paper we extend the capabilities of LLMs by directly attaching a small audio encoder allowing it to perform speech recognition. By directly prepending a sequence of audial embeddings to the text token embeddings, the LLM can be converted to an automatic speech recognition (ASR) system, and be used in the exact same manner as its textual counterpart. Experiments on Multilingual LibriSpeech (MLS) show that incorporating a conformer encoder into the open sourced LLaMA-7B allows it to outperform monolingual baselines by 18% and perform multilingual speech recognition despite LLaMA being trained overwhelmingly on English text. Furthermore, we perform ablation studies to investigate whether the LLM can be completely frozen during training to maintain its original capabilities, scaling up the audio encoder, a
    
[^17]: 在金融行业中应用量子自然语言处理(QNLP)进行情感分析

    Applying QNLP to sentiment analysis in finance. (arXiv:2307.11788v1 [cs.CL])

    [http://arxiv.org/abs/2307.11788](http://arxiv.org/abs/2307.11788)

    本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。

    

    作为一个领域，即使是最微小的质量改进也能产生巨大价值的应用领域，金融是早期量子优势的有前途的候选者。在迅速发展的量子自然语言处理(QNLP)领域中，我们探索了DisCoCat和量子增强的长短期记忆(QNLP)这两种中心方法在金融情感分析问题中的实际适用性。利用一种新颖的基于ChatGPT的数据生成方法，我们进行了一个包含1000多个真实句子的案例研究，发现QLSTM的训练速度比DisCoCat快得多，并且在可用的软件实现中也接近古典结果。

    As an application domain where the slightest qualitative improvements can yield immense value, finance is a promising candidate for early quantum advantage. Focusing on the rapidly advancing field of Quantum Natural Language Processing (QNLP), we explore the practical applicability of the two central approaches DisCoCat and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the problem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data generation approach, we conduct a case study with more than 1000 realistic sentences and find that QLSTMs can be trained substantially faster than DisCoCat while also achieving close to classical results for their available software implementations.
    
[^18]: LLM认知判断与人类有所不同

    LLM Cognitive Judgements Differ From Human. (arXiv:2307.11787v1 [cs.CL])

    [http://arxiv.org/abs/2307.11787](http://arxiv.org/abs/2307.11787)

    这项研究调查了大型语言模型在认知任务中的表现，并发现它们的认知判断与人类不同。

    

    最近，大型语言模型(LLMs)成为研究人员、企业和消费者关注的焦点。虽然这类模型的语言能力已经得到了广泛的研究，但对它们作为认知主体的调查越来越受关注。在本研究中，我对GPT-3和ChatGPT在一个来自认知科学文献的有限数据归纳推理任务上的能力进行了研究。结果表明，这些模型的认知判断与人类不同。

    Large Language Models (LLMs) have lately been on the spotlight of researchers, businesses, and consumers alike. While the linguistic capabilities of such models have been studied extensively, there is growing interest in investigating them as cognitive subjects. In the present work I examine GPT-3 and ChatGPT capabilities on an limited-data inductive reasoning task from the cognitive science literature. The results suggest that these models' cognitive judgements are not human-like.
    
[^19]: 智能代理的对抗对话塑造

    Adversarial Conversational Shaping for Intelligent Agents. (arXiv:2307.11785v1 [cs.CL])

    [http://arxiv.org/abs/2307.11785](http://arxiv.org/abs/2307.11785)

    本文研究了通过对抗对话塑造来增强智能对话代理的两个模型：GANPG和REGS。这些模型能够改进当前的自动拨号系统，提高聊天机器人的性能。

    

    深度学习方法的出现使得研究界在自然语言处理等多个领域取得了最先进的成果。然而，当前的自动拨号系统仍然不稳定且不准确：文本生成器和聊天机器人可能会迟钝并误解人类对话。在这项工作中，我们研究了两种模型的性能，它们通过对抗对话塑造来增强智能对话代理：使用策略梯度的生成对抗网络（GANPG）和基于Li等人提出的REGS模型的每一代生成步骤都有奖励的生成对抗网络（REGS）。该模型能够为部分和完整的生成文本序列分配奖励。我们在强化学习框架中讨论了使用不同训练细节的性能：seq2seq [36]和transformers [37]。

    The recent emergence of deep learning methods has enabled the research community to achieve state-of-the art results in several domains including natural language processing. However, the current robocall system remains unstable and inaccurate: text generator and chat-bots can be tedious and misunderstand human-like dialogue. In this work, we study the performance of two models able to enhance an intelligent conversational agent through adversarial conversational shaping: a generative adversarial network with policy gradient (GANPG) and a generative adversarial network with reward for every generation step (REGS) based on the REGS model presented in Li et al. [18] . This model is able to assign rewards to both partially and fully generated text sequences. We discuss performance with different training details : seq2seq [ 36] and transformers [37 ] in a reinforcement learning framework.
    
[^20]: Generate的语言模型中的提取-摘要轴:测量内容"借用"

    The Extractive-Abstractive Axis: Measuring Content "Borrowing" in Generative Language Models. (arXiv:2307.11779v1 [cs.CL])

    [http://arxiv.org/abs/2307.11779](http://arxiv.org/abs/2307.11779)

    该论文提出了一个名为提取-摘要轴的概念，用于衡量生成语言模型中内容的"借用"程度，并提出了开发相应度量标准、数据集和注释指南的需求。

    

    生成语言模型通过设计产生高度摘要的输出，与搜索引擎中的提取式响应形成对比。鉴于LLMs的这一特点及其对内容许可和归属的影响，我们提出了所谓的提取-摘要轴，用于基准测试生成模型，并强调开发相应的度量标准、数据集和注释指南的需要。我们将讨论限制在文本形式上。

    Generative language models produce highly abstractive outputs by design, in contrast to extractive responses in search engines. Given this characteristic of LLMs and the resulting implications for content Licensing & Attribution, we propose the the so-called Extractive-Abstractive axis for benchmarking generative models and highlight the need for developing corresponding metrics, datasets and annotation guidelines. We limit our discussion to the text modality.
    
[^21]: Transsion TSUP对ASRU 2023 MADASR挑战赛的语音识别系统

    Transsion TSUP's speech recognition system for ASRU 2023 MADASR Challenge. (arXiv:2307.11778v1 [cs.CL])

    [http://arxiv.org/abs/2307.11778](http://arxiv.org/abs/2307.11778)

    Transsion TSUP团队开发了一种语音识别系统，在ASRU 2023 MADASR挑战赛中取得了显著成果，能够适应低资源的印度语言。该系统针对挑战的四个跟踪进行了优化，并采用了不同的模型和解码策略。对于孟加拉语，取得了较低的词错误率。

    

    本文介绍了由Transsion语音理解处理团队（TSUP）开发的语音识别系统，用于ASRU 2023 MADASR挑战赛。该系统专注于适应低资源的印度语言，并涵盖挑战的四个跟踪。在跟踪1和2中，声学模型采用了squeezeformer编码器和双向变换器解码器，采用联合CTC-Attention训练损失。此外，在TLG波束搜索解码期间使用了外部的KenLM语言模型。在跟踪3和4中，使用了预训练的IndicWhisper模型，并在挑战数据集和公开可用的数据集上进行了微调。其whisper波束搜索解码也被修改以支持外部的KenLM语言模型，以更好地利用挑战所提供的附加文本。所提出的方法在四个跟踪中对孟加拉语的词错误率（WER）分别为24.17％、24.43％、15.97％和15.97％，对印地语的WER分别为19.61％、19.54％、15.48％

    This paper presents a speech recognition system developed by the Transsion Speech Understanding Processing Team (TSUP) for the ASRU 2023 MADASR Challenge. The system focuses on adapting ASR models for low-resource Indian languages and covers all four tracks of the challenge. For tracks 1 and 2, the acoustic model utilized a squeezeformer encoder and bidirectional transformer decoder with joint CTC-Attention training loss. Additionally, an external KenLM language model was used during TLG beam search decoding. For tracks 3 and 4, pretrained IndicWhisper models were employed and finetuned on both the challenge dataset and publicly available datasets. The whisper beam search decoding was also modified to support an external KenLM language model, which enabled better utilization of the additional text provided by the challenge. The proposed method achieved word error rates (WER) of 24.17%, 24.43%, 15.97%, and 15.97% for Bengali language in the four tracks, and WER of 19.61%, 19.54%, 15.48%
    
[^22]: 捕捉社交媒体中客户见解的主题方法

    A Topical Approach to Capturing Customer Insight In Social Media. (arXiv:2307.11775v1 [cs.CL])

    [http://arxiv.org/abs/2307.11775](http://arxiv.org/abs/2307.11775)

    本研究通过嵌入狄利克雷过程，嵌入层次狄利克雷过程和面向时间的动态嵌入三种方法，解决了在嘈杂的大数据环境中完全无监督的主题提取挑战。

    

    社交媒体时代为企业带来了新的机遇。这种繁荣的信息财富超出了传统营销研究的渠道和框架，包括营销组合建模(MMM)。特别是，文本数据提出了许多数据分析从业人员必须应对的挑战。社交媒体构成了大规模、异构和嘈杂的文档来源。工业数据采集过程包括一定量的ETL。然而，数据中噪声的变异性和不同来源引入的异构性给予了临时工具的需求。换句话说，在完全无监督、嘈杂的环境中提取客户见解是一项艰巨的任务。本研究解决了在嘈杂的大数据环境中完全无监督的主题提取挑战。我们在变分自动编码器框架上提出了三种方法：嵌入狄利克雷过程、嵌入层次狄利克雷过程和面向时间的动态嵌入

    The age of social media has opened new opportunities for businesses. This flourishing wealth of information is outside traditional channels and frameworks of classical marketing research, including that of Marketing Mix Modeling (MMM). Textual data, in particular, poses many challenges that data analysis practitioners must tackle. Social media constitute massive, heterogeneous, and noisy document sources. Industrial data acquisition processes include some amount of ETL. However, the variability of noise in the data and the heterogeneity induced by different sources create the need for ad-hoc tools. Put otherwise, customer insight extraction in fully unsupervised, noisy contexts is an arduous task. This research addresses the challenge of fully unsupervised topic extraction in noisy, Big Data contexts. We present three approaches we built on the Variational Autoencoder framework: the Embedded Dirichlet Process, the Embedded Hierarchical Dirichlet Process, and the time-aware Dynamic Embe
    
[^23]: AutoAlign：基于大型语言模型的全自动有效知识图谱对齐方法

    AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment enabled by Large Language Models. (arXiv:2307.11772v1 [cs.IR])

    [http://arxiv.org/abs/2307.11772](http://arxiv.org/abs/2307.11772)

    AutoAlign是一种全自动的知识图谱对齐方法，不需要手工制作的种子对齐。它利用大型语言模型自动捕捉谓词相似性，并使用TransE计算实体嵌入来实现实体对齐。

    

    知识图谱间的实体对齐任务旨在识别出两个不同知识图谱中表示相同实体的每对实体。许多基于机器学习的方法已被提出用于这个任务。然而，据我们所知，现有的方法都需要手工制作的种子对齐，这是非常昂贵的。在本文中，我们提出了第一个名为AutoAlign的完全自动对齐方法，它不需要任何手工制作的种子对齐。具体而言，对于谓词嵌入，AutoAlign使用大型语言模型构建谓词近邻图，自动捕捉两个知识图谱中谓词的相似性。对于实体嵌入，AutoAlign首先使用TransE独立计算每个知识图谱的实体嵌入，然后通过计算基于实体属性的实体相似性，将两个知识图谱的实体嵌入移动到相同的向量空间中。因此，AutoAlign实现了谓词对齐和实体对齐。

    The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require manually crafted seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named AutoAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, AutoAlign constructs a predicate-proximity-graph with the help of large language models to automatically capture the similarity between predicates across two KGs. For entity embeddings, AutoAlign first computes the entity embeddings of each KG independently using TransE, and then shifts the two KGs' entity embeddings into the same vector space by computing the similarity between entities based on their attributes. Thus, both predicate alignment and entity al
    
[^24]: 一种集成的自然语言处理方法用于满意度调查中的情感分析

    an integrated npl approach to sentiment analysis in satisfaction surveys. (arXiv:2307.11771v1 [cs.CL])

    [http://arxiv.org/abs/2307.11771](http://arxiv.org/abs/2307.11771)

    这项研究使用集成的自然语言处理方法对满意度调查进行情感分析，通过识别重复的词语模式和利用意见挖掘来理解参与者的意见，并且通过分析词语模式来获取更深入的情感、意见和主题信息。

    

    该研究项目旨在将集成方法应用于满意度调查中的自然语言处理（NLP）。它将着重于理解和提取调查回答中的相关信息，分析情感，识别重复的词语模式。将使用NLP技术来确定情感极性，将回答分类为积极、消极或中性类别，并利用意见挖掘来突出参与者的意见。该方法将有助于确定对参与者最相关的方面，并了解他们对这些特定方面的意见。该研究项目的关键组成部分将是使用NPL对满意度调查回答中的词语模式进行分析。该分析将提供对回答者情感、意见以及出现的主题和趋势的更深入的理解。从该方法得到的结果可以用于确定改进的方向，了解回答者的偏好，并做出战略决策。

    The research project aims to apply an integrated approach to natural language processing NLP to satisfaction surveys. It will focus on understanding and extracting relevant information from survey responses, analyzing feelings, and identifying recurring word patterns. NLP techniques will be used to determine emotional polarity, classify responses into positive, negative, or neutral categories, and use opinion mining to highlight participants opinions. This approach will help identify the most relevant aspects for participants and understand their opinions in relation to those specific aspects. A key component of the research project will be the analysis of word patterns in satisfaction survey responses using NPL. This analysis will provide a deeper understanding of feelings, opinions, and themes and trends present in respondents responses. The results obtained from this approach can be used to identify areas for improvement, understand respondents preferences, and make strategic decisi
    
[^25]: 大规模评估用于2D文本空间化的主题模型和降维方法

    Large-Scale Evaluation of Topic Models and Dimensionality Reduction Methods for 2D Text Spatialization. (arXiv:2307.11770v1 [cs.CL])

    [http://arxiv.org/abs/2307.11770](http://arxiv.org/abs/2307.11770)

    通过大规模计算评估，我们研究了用于2D文本空间化的主题模型和降维方法的有效性，为语料库分析提供了具有高质量布局的解决方案。

    

    主题模型是一类无监督学习算法，用于检测文本语料库中的语义结构。与后续的降维算法一起，主题模型可以用于为文本语料库导出空间化的二维散点图，反映文档之间的语义相似性并支持语料库分析。尽管主题模型、降维算法及其底层超参数的选择对产生的布局有着重要影响，但目前尚不清楚哪种特定组合能够得到具有高质量的布局，准确度和感知度指标方面。为了研究主题模型和降维方法在作为二维散点图的语料库空间化（或作为景观类型可视化的基础）方面的有效性，我们提出了一个基于基准的大规模计算评估。我们的评估包括（1）一组语料库，（2）一组布局算法。

    Topic models are a class of unsupervised learning algorithms for detecting the semantic structure within a text corpus. Together with a subsequent dimensionality reduction algorithm, topic models can be used for deriving spatializations for text corpora as two-dimensional scatter plots, reflecting semantic similarity between the documents and supporting corpus analysis. Although the choice of the topic model, the dimensionality reduction, and their underlying hyperparameters significantly impact the resulting layout, it is unknown which particular combinations result in high-quality layouts with respect to accuracy and perception metrics. To investigate the effectiveness of topic models and dimensionality reduction methods for the spatialization of corpora as two-dimensional scatter plots (or basis for landscape-type visualizations), we present a large-scale, benchmark-based computational evaluation. Our evaluation consists of (1) a set of corpora, (2) a set of layout algorithms that a
    
[^26]: 大型语言模型中的领域知识蒸馏：自动驾驶领域的实证研究

    Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain. (arXiv:2307.11769v1 [cs.CL])

    [http://arxiv.org/abs/2307.11769](http://arxiv.org/abs/2307.11769)

    本文通过使用大型语言模型（LLM）自动化和半自动化的方法，在自动驾驶领域进行了领域知识蒸馏的实证研究。他们发现，尽管完全自动化的领域本体构建是可行的，但人类监督和早期干预通常可以提高效率和输出质量。

    

    工程知识化（或专家）系统需要大量手动工作和领域知识。由于大型语言模型（LLM）使用大量跨领域知识进行训练，因此可以自动化此类工程流程。本文提出了一种基于提示工程和LLM ChatGPT的领域知识蒸馏的实证自动化和半自动化框架，并在自动驾驶领域进行了实证评估并呈现了关键观察结果。在我们的实现中，我们通过与ChatGPT“聊天”来构建领域知识本体论。关键发现是，虽然完全自动化的领域本体构建是可能的，但人类监督和早期干预通常可以提高效率和输出质量，因为它们减少了响应随机性和蝴蝶效应的影响。因此，我们还开发了一个基于网络的蒸馏助手，以在运行时进行监督和灵活干预。

    Engineering knowledge-based (or expert) systems require extensive manual effort and domain knowledge. As Large Language Models (LLMs) are trained using an enormous amount of cross-domain knowledge, it becomes possible to automate such engineering processes. This paper presents an empirical automation and semi-automation framework for domain knowledge distillation using prompt engineering and the LLM ChatGPT. We assess the framework empirically in the autonomous driving domain and present our key observations. In our implementation, we construct the domain knowledge ontology by "chatting" with ChatGPT. The key finding is that while fully automated domain ontology construction is possible, human supervision and early intervention typically improve efficiency and output quality as they lessen the effects of response randomness and the butterfly effect. We, therefore, also develop a web-based distillation assistant enabling supervision and flexible intervention at runtime. We hope our find
    
[^27]: 问题分解提高了模型生成推理的忠实度

    Question Decomposition Improves the Faithfulness of Model-Generated Reasoning. (arXiv:2307.11768v1 [cs.CL])

    [http://arxiv.org/abs/2307.11768](http://arxiv.org/abs/2307.11768)

    通过将问题分解为子问题，可以显著提高大型语言模型生成推理的忠实度。

    

    随着大型语言模型（LLM）执行越来越复杂的任务，验证其行为的正确性和安全性变得越来越困难。其中一种解决方法是要求LLM在回答问题时以逐步推理的方式外化其推理过程（思维链；CoT）。推理过程可以让我们检查模型执行任务的过程。然而，这种方法依赖于所陈述的推理能够忠实地反映模型的实际推理，而这并非总是如此。为了提高CoT推理的忠实度，我们通过将问题分解为子问题来生成推理。基于分解的方法在问答任务上取得了较好的性能，有时接近CoT，并在几个最近提出的度量标准中提高了模型所陈述推理的忠实度。通过强制模型在单独的上下文中回答简单的子问题，我们大大增加了模型的忠实度。

    As large language models (LLMs) perform more difficult tasks, it becomes harder to verify the correctness and safety of their behavior. One approach to help with this issue is to prompt LLMs to externalize their reasoning, e.g., by having them generate step-by-step reasoning as they answer a question (Chain-of-Thought; CoT). The reasoning may enable us to check the process that models use to perform tasks. However, this approach relies on the stated reasoning faithfully reflecting the model's actual reasoning, which is not always the case. To improve over the faithfulness of CoT reasoning, we have models generate reasoning by decomposing questions into subquestions. Decomposition-based methods achieve strong performance on question-answering tasks, sometimes approaching that of CoT while improving the faithfulness of the model's stated reasoning on several recently-proposed metrics. By forcing the model to answer simpler subquestions in separate contexts, we greatly increase the faithf
    
[^28]: 在高效自动化的风格中识别心理形容词

    Recognition of Mental Adjectives in An Efficient and Automatic Style. (arXiv:2307.11767v1 [cs.CL])

    [http://arxiv.org/abs/2307.11767](http://arxiv.org/abs/2307.11767)

    本论文提出了一个新的词汇推理任务MPC，通过微调BERT模型和采用主动学习算法，在简化标注资源的同时达到了令人满意的准确性。通过与SentiWordNet的比较，还发现了MPC与情感分析中的主观性分类任务的差异。

    

    最近几年，常识推理在学术界越来越受到关注。我们提出了一个新的词汇推理任务，心理与物理分类（MPC），以处理常识推理。心理词语与心理活动相关，可分为六个类别：情感、需求、感知、推理、规划和个性。物理词语描述物体的物理属性，如颜色、硬度、速度和可塑性。我们使用BERT模型对这个任务进行了微调，并在训练框架中采用主动学习算法来减少所需的注释资源。使用ENTROPY策略的模型达到了令人满意的准确性，仅需要约300个标注的词语。我们还将结果与SentiWordNet进行了比较，以检查MPC与情感分析中的主观性分类任务之间的差异。

    In recent years, commonsense reasoning has received more and more attention from academic community. We propose a new lexical inference task, Mental and Physical Classification (MPC), to handle commonsense reasoning in a reasoning graph. Mental words relate to mental activities, which fall into six categories: Emotion, Need, Perceiving, Reasoning, Planning and Personality. Physical words describe physical attributes of an object, like color, hardness, speed and malleability. A BERT model is fine-tuned for this task and active learning algorithm is adopted in the training framework to reduce the required annotation resources. The model using ENTROPY strategy achieves satisfactory accuracy and requires only about 300 labeled words. We also compare our result with SentiWordNet to check the difference between MPC and subjectivity classification task in sentiment analysis.
    
[^29]: 使用评价性语言表达进行三元决策

    Three-way Decisions with Evaluative Linguistic Expressions. (arXiv:2307.11766v1 [cs.CL])

    [http://arxiv.org/abs/2307.11766](http://arxiv.org/abs/2307.11766)

    本文提出了使用评价性语言表达进行三元决策的方法，并发现了三元决策和评价性语言表达理论之间的新联系。

    

    我们提出了对三元决策的语言解释，其中接受、拒绝和不承诺的区域是通过使用评价性语言表达构建的，这些表达是自然语言中的表达，比如小、中、非常短、相当粗糙强烈、极好等。我们的结果突出了两个不同研究领域之间的新联系：三元决策和评价性语言表达理论。

    We propose a linguistic interpretation of three-way decisions, where the regions of acceptance, rejection, and non-commitment are constructed by using the so-called evaluative linguistic expressions, which are expressions of natural language such as small, medium, very short, quite roughly strong, extremely good, etc. Our results highlight new connections between two different research areas: three-way decisions and the theory of evaluative linguistic expressions.
    
[^30]: Sensi-BERT: 面向敏感度驱动的参数高效BERT微调

    Sensi-BERT: Towards Sensitivity Driven Fine-Tuning for Parameter-Efficient BERT. (arXiv:2307.11764v1 [cs.CL])

    [http://arxiv.org/abs/2307.11764](http://arxiv.org/abs/2307.11764)

    Sensi-BERT是一种面向敏感度驱动的参数高效BERT微调方法，通过敏感度分析和裁剪参数张量，可生成适用于下游任务的高度参数高效的模型。

    

    近年来，由于在文本分类和问答等各种下游任务上的改进表现，大型预训练语言模型逐渐受到关注，只需进行很少次数的微调。然而，其庞大的模型大小常常限制了它们在资源受限的边缘设备上的应用。现有的参数高效BERT模型解决方案大多依赖于计算密集的训练和微调，并且常常依赖于额外的计算密集型模型来弥补性能差距。本文介绍了Sensi-BERT，一种敏感度驱动的BERT模型高效微调方法，可以使用现成的预训练BERT模型，生成适用于下游任务的高度参数高效的模型。具体而言，我们进行敏感度分析以对每个单独的参数张量进行排序，然后在微调过程中根据给定的参数或FLOPs预算进行相应的裁剪。实验结果表明Sensi-BERT的有效性。

    Large pre-trained language models have recently gained significant traction due to their improved performance on various down-stream tasks like text classification and question answering, requiring only few epochs of fine-tuning. However, their large model sizes often prohibit their applications on resource-constrained edge devices. Existing solutions of yielding parameter-efficient BERT models largely rely on compute-exhaustive training and fine-tuning. Moreover, they often rely on additional compute heavy models to mitigate the performance gap. In this paper, we present Sensi-BERT, a sensitivity driven efficient fine-tuning of BERT models that can take an off-the-shelf pre-trained BERT model and yield highly parameter-efficient models for downstream tasks. In particular, we perform sensitivity analysis to rank each individual parameter tensor, that then is used to trim them accordingly during fine-tuning for a given parameter or FLOPs budget. Our experiments show the efficacy of Sens
    
[^31]: 基于相似性的记忆增强联合实体和关系抽取

    Similarity-based Memory Enhanced Joint Entity and Relation Extraction. (arXiv:2307.11762v1 [cs.CL])

    [http://arxiv.org/abs/2307.11762](http://arxiv.org/abs/2307.11762)

    本文提出了一种基于相似性的记忆增强联合实体和关系抽取的方法，通过在任务之间建立双向内存依赖关系，从而更准确地执行文档级联合实体和关系抽取问题。实证研究表明，该方法优于现有方法，并在BioCreative V CDR语料库上达到了最先进的结果。

    

    文档级联合实体和关系抽取是一个具有挑战性的信息提取问题，需要一个统一的方法，在其中一个单一的神经网络执行四个子任务：提及检测，共指解析，实体分类和关系抽取。现有方法通常采用顺序多任务学习方法，在其中任意分解导致当前任务仅依赖于前一个任务，忽略了它们之间可能存在的更复杂关系的可能性。在本文中，我们提出了一个具有双向内存依赖关系的多任务学习框架，以解决这些缺点并更准确地执行联合问题。我们的实证研究表明，所提出的方法优于现有方法，并在BioCreative V CDR语料库上实现了最先进的结果。

    Document-level joint entity and relation extraction is a challenging information extraction problem that requires a unified approach where a single neural network performs four sub-tasks: mention detection, coreference resolution, entity classification, and relation extraction. Existing methods often utilize a sequential multi-task learning approach, in which the arbitral decomposition causes the current task to depend only on the previous one, missing the possible existence of the more complex relationships between them. In this paper, we present a multi-task learning framework with bidirectional memory-like dependency between tasks to address those drawbacks and perform the joint problem more accurately. Our empirical studies show that the proposed approach outperforms the existing methods and achieves state-of-the-art results on the BioCreative V CDR corpus.
    
[^32]: ChatGPT的公平性及可解释引导提示的作用

    Fairness of ChatGPT and the Role Of Explainable-Guided Prompts. (arXiv:2307.11761v1 [cs.CL])

    [http://arxiv.org/abs/2307.11761](http://arxiv.org/abs/2307.11761)

    本研究调查了ChatGPT在信用风险评估中的潜力，发现通过精心设计的提示指导和领域特定知识的补充，ChatGPT能够与传统机器学习模型相媲美，使用的数据量少至传统模型的1/40，表现优异，尤其擅长减小误报并提升公平性。这为未来在其他类似任务中充分利用ChatGPT的能力奠定了基础。

    

    我们的研究探讨了大规模语言模型（LLMs）在信用风险评估中的潜力，具体来说是OpenAI的GPT，在一个二分类任务中。我们的发现表明，当LLMs受到精心设计的提示指导并补充领域特定知识时，其表现可以与传统的机器学习模型相媲美。有趣的是，他们只使用了少得多的数据-仅仅20个数据点，而传统机器学习模型需要800个数据点，从而实现了与传统模型相当的性能。LLMs在减小误报提升公平性方面表现出色，这两个方面在风险分析中至关重要。尽管我们的结果没有超过传统的机器学习模型，但它们强调了LLMs在类似任务中的潜力，为未来在多样化的机器学习任务中利用LLMs的能力奠定基础。

    Our research investigates the potential of Large-scale Language Models (LLMs), specifically OpenAI's GPT, in credit risk assessment-a binary classification task. Our findings suggest that LLMs, when directed by judiciously designed prompts and supplemented with domain-specific knowledge, can parallel the performance of traditional Machine Learning (ML) models. Intriguingly, they achieve this with significantly less data-40 times less, utilizing merely 20 data points compared to the ML's 800. LLMs particularly excel in minimizing false positives and enhancing fairness, both being vital aspects of risk analysis. While our results did not surpass those of classical ML models, they underscore the potential of LLMs in analogous tasks, laying a groundwork for future explorations into harnessing the capabilities of LLMs in diverse ML tasks.
    
[^33]: EmotionPrompt: 通过情感刺激提升大型语言模型的关键心理学方法

    EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus. (arXiv:2307.11760v1 [cs.CL])

    [http://arxiv.org/abs/2307.11760](http://arxiv.org/abs/2307.11760)

    EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。

    

    大型语言模型（LLMs）在推理、语言理解和数学问题解决等许多领域取得了显著的性能，并被视为人工通用智能（AGI）的关键步骤。然而，LLMs对提示的敏感性仍然是其日常应用的主要瓶颈。本文从心理学中汲取灵感，提出了EmotionPrompt来探索情感智能以提升LLMs的性能。EmotionPrompt基于一个非常简单明了的原则：将情感刺激融入到提示中。实验结果表明，我们的方法在相同的单一提示模板上，与原始的零样本提示和Zero-shot-CoT相比，在8个任务上都显著优于多种模型：ChatGPT、Vicuna-13b、Bloom和T5。此外，观察到EmotionPrompt能够提高真实性和信息量。我们相信EmotionPrompt为探索跨学科知识开辟了一条新的道路。

    Large language models (LLMs) have achieved significant performance in many fields such as reasoning, language understanding, and math problem-solving, and are regarded as a crucial step to artificial general intelligence (AGI). However, the sensitivity of LLMs to prompts remains a major bottleneck for their daily adoption. In this paper, we take inspiration from psychology and propose EmotionPrompt to explore emotional intelligence to enhance the performance of LLMs. EmotionPrompt operates on a remarkably straightforward principle: the incorporation of emotional stimulus into prompts. Experimental results demonstrate that our \method, using the same single prompt templates, significantly outperforms original zero-shot prompt and Zero-shot-CoT on 8 tasks with diverse models: ChatGPT, Vicuna-13b, Bloom, and T5. Further, EmotionPrompt was observed to improve both truthfulness and informativeness. We believe that EmotionPrompt heralds a novel avenue for exploring interdisciplinary knowledg
    
[^34]: CausE: 朝向因果知识图谱嵌入的方向

    CausE: Towards Causal Knowledge Graph Embedding. (arXiv:2307.11610v1 [cs.CL])

    [http://arxiv.org/abs/2307.11610](http://arxiv.org/abs/2307.11610)

    CausE是一个采用因果知识图谱嵌入和嵌入解缠的框架，利用因果干预进行稳定预测，并在知识图谱完整性任务上取得了最先进的性能。

    

    知识图谱嵌入（KGE）的重点是将知识图谱（KG）中的实体和关系表示为连续的向量空间，这可以用于预测缺失的三元组以实现知识图谱完整性（KGC）。然而，KGE模型通常只是简单地学习三元组数据的结构关联，并且在现实世界的KG中，嵌入可能会被微不足道的模式和噪声链接所误导。为了解决这个问题，我们在因果性和嵌入解缠方面建立了KGE的新模式。我们进一步提出了Causality-enhanced knowledge graph Embedding（CausE）框架。CausE使用因果干预来估计混杂嵌入的因果效应，并设计新的训练目标来进行稳定预测。实验结果表明，CausE可以优于基线模型，并实现最先进的KGC性能。我们在https://github.com/zjukg/CausE上发布了我们的代码。

    Knowledge graph embedding (KGE) focuses on representing the entities and relations of a knowledge graph (KG) into the continuous vector spaces, which can be employed to predict the missing triples to achieve knowledge graph completion (KGC). However, KGE models often only briefly learn structural correlations of triple data and embeddings would be misled by the trivial patterns and noisy links in real-world KGs. To address this issue, we build the new paradigm of KGE in the context of causality and embedding disentanglement. We further propose a Causality-enhanced knowledge graph Embedding (CausE) framework. CausE employs causal intervention to estimate the causal effect of the confounder embeddings and design new training objectives to make stable predictions. Experimental results demonstrate that CausE could outperform the baseline models and achieve state-of-the-art KGC performance. We release our code in https://github.com/zjukg/CausE.
    
[^35]: 用检索增强研究大型语言模型的事实知识边界

    Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation. (arXiv:2307.11019v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.11019](http://arxiv.org/abs/2307.11019)

    本研究初步分析了大型语言模型的事实知识边界，并研究了检索增强对开放域问答任务中大型语言模型的影响。结果显示大型语言模型在回答问题时表现出自信，并且回答准确。

    

    知识密集型任务（例如，开放域问答（QA））需要大量的事实知识，并经常依赖外部信息进行协助。最近，大型语言模型（LLMs）（例如，ChatGPT）在解决包括知识密集型任务在内的各种任务上展现出了惊人的能力。然而，目前尚不清楚LLMs在感知其事实知识边界方面表现如何，特别是在使用检索增强时的行为。在本研究中，我们对LLMs的事实知识边界进行了初步分析，并研究了检索增强对LLMs在开放域QA上的影响。具体而言，我们关注了三个主要研究问题，并通过检查LLMs的QA性能、先验判断和后验判断来进行分析。我们提供了证据表明LLMs对于自己回答问题的能力和回答的准确性充满了自信。

    Knowledge-intensive tasks (e.g., open-domain question answering (QA)) require a substantial amount of factual knowledge and often rely on external information for assistance. Recently, large language models (LLMs) (e.g., ChatGPT), have demonstrated impressive prowess in solving a wide range of tasks with world knowledge, including knowledge-intensive tasks. However, it remains unclear how well LLMs are able to perceive their factual knowledge boundaries, particularly how they behave when incorporating retrieval augmentation. In this study, we present an initial analysis of the factual knowledge boundaries of LLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially, we focus on three primary research questions and analyze them by examining QA performance, priori judgement and posteriori judgement of LLMs. We show evidence that LLMs possess unwavering confidence in their capabilities to respond to questions and the accuracy of their responses. Furthermore, retrieval 
    
[^36]: LLM审查：机器学习挑战还是计算机安全问题？

    LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?. (arXiv:2307.10719v1 [cs.AI])

    [http://arxiv.org/abs/2307.10719](http://arxiv.org/abs/2307.10719)

    本文讨论了大型语言模型(LLM)的审查问题，指出现有的语义审查方法存在理论上的限制，由于LLM的程序化和遵循指令的能力，语义审查可以被认为是一个不可判定的问题。同时，有知识的攻击者可以重构不可容许的输出。

    

    大型语言模型(LLM)在理解复杂指令方面展现了令人印象深刻的能力。然而，它们对提供的指令的盲目遵循引发了对恶意使用风险的担忧。现有的防御机制，如LLM的模型微调或使用LLM进行输出审查，已证明是有缺陷的，因为LLM仍然可以生成有问题的回答。常用的审查方法将这个问题视为机器学习问题，并依赖于另一个语言模型来检测LLM输出中的不良内容。在本文中，我们呈现了这种语义审查方法的理论限制。具体来说，我们证明了语义审查可以被认为是一个不可判定的问题，突出了由于LLM的程序化和遵循指令的能力而引起的审查中的固有挑战。此外，我们认为这些挑战不仅限于语义审查，因为有知识的攻击者可以重构不可容许的输出。

    Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, as LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs 
    
[^37]: 图像和声音的滥用用于在多模态LLMs中进行间接指令注入

    (Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v1 [cs.CR])

    [http://arxiv.org/abs/2307.10490](http://arxiv.org/abs/2307.10490)

    本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。

    

    我们展示了如何利用图像和声音在多模态LLMs中进行间接提示和指令注入。攻击者生成与提示相对应的对抗扰动，并将其融入图像或音频录音中。当用户向（未修改的良性）模型询问被扰动的图像或音频时，扰动会引导模型输出攻击者选择的文本和/或使后续对话遵循攻击者的指令。我们用几个概念验证示例针对LLaVa和PandaGPT来说明这种攻击。

    We demonstrate how images and sounds can be used for indirect prompt and instruction injection in multi-modal LLMs. An attacker generates an adversarial perturbation corresponding to the prompt and blends it into an image or audio recording. When the user asks the (unmodified, benign) model about the perturbed image or audio, the perturbation steers the model to output the attacker-chosen text and/or make the subsequent dialog follow the attacker's instruction. We illustrate this attack with several proof-of-concept examples targeting LLaVa and PandaGPT.
    
[^38]: 使用相对位置标签将异构图与实体感知自注意力相结合的阅读理解模型

    Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model. (arXiv:2307.10443v1 [cs.CL])

    [http://arxiv.org/abs/2307.10443](http://arxiv.org/abs/2307.10443)

    本文提出了一种新的注意力模式，使用图增强自注意力机制将从异构图中导出的推理知识整合到变压器架构中，从而克服了变压器模型在复杂推理任务中的限制。通过全局-局部注意力、图注意力和关系类型考虑，优化了实体和单词之间的注意力。该模式与相对位置标签相结合，能够与LUKE的实体感知自注意力机制相集成。

    

    尽管变压器模型在机器阅读理解任务中取得了重大进展，但由于输入序列中缺少显式知识，它们仍然面临处理复杂推理任务的限制。本文提出了一种新颖的注意力模式来克服这个限制，它利用增强图自注意力机制将由异构图导出的推理知识整合到变压器架构中。提出的注意力模式包括三个关键要素：单词标记的全局-局部注意力，对实体标记的图注意力，实体标记对相关联的标记显示强烈的注意力而对不相关的标记显示较弱的注意力，以及考虑每个实体标记与单词标记之间的关系类型。这样，如果存在关系，则可以优化两者之间的注意力。该模式与特殊的相对位置标签相结合，使其能够与LUKE的实体感知自注意力机制相集成。

    Despite the significant progress made by transformer models in machine reading comprehension tasks, they still face limitations in handling complex reasoning tasks due to the absence of explicit knowledge in the input sequence. This paper proposes a novel attention pattern to overcome this limitation, which integrates reasoning knowledge derived from a heterogeneous graph into the transformer architecture using a graph-enhanced self-attention mechanism. The proposed attention pattern comprises three key elements: global-local attention for word tokens, graph attention for entity tokens that exhibit strong attention towards tokens connected in the graph as opposed to those unconnected, and the consideration of the type of relationship between each entity token and word token. This results in optimized attention between the two if a relationship exists. The pattern is coupled with special relative position labels, allowing it to integrate with LUKE's entity-aware self-attention mechanism
    
[^39]: SentimentGPT：利用GPT进行高级情感分析及其与当前机器学习方法的差异

    SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning. (arXiv:2307.10234v1 [cs.CL])

    [http://arxiv.org/abs/2307.10234](http://arxiv.org/abs/2307.10234)

    本研究通过利用GPT进行高级情感分析，并考察其与当前机器学习方法的差异，发现GPT方法相较于其他模型在预测性能上具有显著优势，并有效解决了情感分析任务中的一些挑战，如理解上下文和检测讽刺。

    

    本研究对情感分析中各种生成预训练转换器（GPT）方法进行了全面的考察，特别是在SemEval 2017数据集的任务4中。采用了三种主要策略：1）使用GPT-3.5 Turbo进行提示工程，2）对GPT模型进行微调，3）采用创新的嵌入分类方法。研究结果揭示了这些策略和个别GPT模型之间的详细比较见解，展示了它们独特的优势和潜在的局限性。此外，本研究将这些基于GPT的方法与其他同时代、高性能的模型在相同数据集上进行比较。结果表明，GPT方法在预测性能方面具有显著的优势，相较于最先进技术，F1分数增加了22%以上。此外，本论文还探讨了情感分析任务中的常见挑战，如理解上下文和检测讽刺。研究强调了GPT方法的重要价值和潜力。

    This study presents a thorough examination of various Generative Pretrained Transformer (GPT) methodologies in sentiment analysis, specifically in the context of Task 4 on the SemEval 2017 dataset. Three primary strategies are employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2) fine-tuning GPT models, and 3) an inventive approach to embedding classification. The research yields detailed comparative insights among these strategies and individual GPT models, revealing their unique strengths and potential limitations. Additionally, the study compares these GPT-based methodologies with other contemporary, high-performing models previously used with the same dataset. The results illustrate the significant superiority of the GPT approaches in terms of predictive performance, more than 22% in F1-score compared to the state-of-the-art. Further, the paper addresses common challenges in sentiment analysis tasks, such as understanding context and detecting sarcasm. It underscores
    
[^40]: 通过使用多粒度主题分析方法的实证研究：生育政策提案

    An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods. (arXiv:2307.10025v1 [cs.HC])

    [http://arxiv.org/abs/2307.10025](http://arxiv.org/abs/2307.10025)

    本研究通过采用多粒度主题分析方法，对微博评论进行语义分析，发现关于取消婚姻登记的生育限制的提案涉及个人、社会和国家三个维度，详细讨论了个人行为、社会伦理和法律以及国家政策等社会问题。

    

    生育问题与人口安全密切相关，中国60年来首次出现人口负增长趋势，生育政策的变化引起了社会的极大关注。本文采用共现语义分析、主题分析和情感分析等方法，对微博评论进行多粒度的语义分析。发现关于“取消婚姻登记的生育限制”的提案讨论涉及个人、社会和国家三个维度，并详细探讨了个人行为、社会伦理和法律以及国家政策等社会问题。

    Fertility issues are closely related to population security, in 60 years China's population for the first time in a negative growth trend, the change of fertility policy is of great concern to the community. 2023 ``two sessions" proposal ``suggests that the country in the form of legislation, the birth of the registration of the cancellation of the marriage restriction" This topic was once a hot topic on the Internet, and ``unbundling" the relationship between birth registration and marriage has become the focus of social debate. In this paper, we adopt co-occurrence semantic analysis, topic analysis and sentiment analysis to conduct multi-granularity semantic analysis of microblog comments. It is found that the discussion on the proposal of ``removing marriage restrictions from birth registration" involves the individual, society and the state at three dimensions, and is detailed into social issues such as personal behaviour, social ethics and law, and national policy, with people's s
    
[^41]: 用大型语言模型生成数学导出

    Generating Mathematical Derivations with Large Language Models. (arXiv:2307.09998v1 [cs.CL])

    [http://arxiv.org/abs/2307.09998](http://arxiv.org/abs/2307.09998)

    本文利用大型语言模型生成数学导出，分析了微调模型对未见符号和方程结构更改的敏感性，结果表明微调的FLAN-T5-large（MathT5）在各个测试集上的绝对性能优于GPT模型。

    

    利用大型语言模型（LLM）在专业领域中生成数学结果的导出是一个新兴的研究方向，可以帮助识别模型的局限性，并有可能支持数学发现。本文利用符号引擎在大规模上生成方程的导出，并研究了LLM在从前提中导出目标方程时的能力。具体而言，我们采用上下文学习来对GPT进行训练，并对一系列T5模型进行了微调，以比较预训练策略对专门模型的鲁棒性和泛化能力。实证结果表明，经过微调的FLAN-T5-large（MathT5）在所有静态和超出分布的测试集上的绝对性能优于GPT模型。然而，深入分析表明，微调模型对涉及未见符号的扰动（以及在较小程度上的方程结构更改）更为敏感。此外，我们分析了1.7K个方程和200多个导出以凸显出LLM的局限性。

    The derivation of mathematical results in specialised fields using Large Language Models (LLMs) is an emerging research direction that can help identify models' limitations, and potentially support mathematical discovery. In this paper, we leverage a symbolic engine to generate derivations of equations at scale, and investigate the capabilities of LLMs when deriving goal equations from premises. Specifically, we employ in-context learning for GPT and fine-tune a range of T5 models to compare the robustness and generalisation of pre-training strategies to specialised models. Empirical results show that fine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and out-of-distribution test sets in terms of absolute performance. However, an in-depth analysis reveals that the fine-tuned models are more sensitive to perturbations involving unseen symbols and (to a lesser extent) changes to equation structure. In addition, we analyse 1.7K equations and over 200 derivations to hig
    
[^42]: 使用大型语言模型增强密集检索的软提示调优

    Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2307.08303](http://arxiv.org/abs/2307.08303)

    本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。

    

    密集检索（DR）将查询和文档转化为密集向量表示，并在向量空间中测量查询与文档之间的相似性。DR的一个挑战是缺乏领域特定的训练数据。虽然DR模型可以通过迁移学习从大规模公共数据集（如MS MARCO）中学习，但证据表明，并非所有DR模型和领域都能同等受益于迁移学习。最近，一些研究人员转向使用大型语言模型（LLMs）来改进零样本和少样本的DR模型。然而，这些方法中采用的硬提示或人工编写的提示无法保证生成的弱查询的质量。为了解决这个问题，我们提出了用于增强DR的软提示调优（SPTAR）：对于每个任务，我们利用软提示调优在有限的真实数据上优化任务特定的软提示，然后用这些提示引导LLMs为未标记的文档标记弱查询，从而得到足够的弱文档-查询对来训练任务特定的模型。

    Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
    
[^43]: Disco-Bench: 一种面向语言建模的论述感知评估基准

    Disco-Bench: A Discourse-Aware Evaluation Benchmark for Language Modelling. (arXiv:2307.08074v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08074](http://arxiv.org/abs/2307.08074)

    Disco-Bench是一个面向语言建模的论述感知评估基准，可以跨多个NLP任务评估句内论述属性。我们设计了文献领域的9个测试集和一个诊断测试套件来评估模型的论述知识。我们在20个不同模型上进行了评估。

    

    论述建模，即超越个别句子的语言现象，是自然语言处理(NLP)中一个基本而具有挑战性的方面。然而，现有的评估基准主要关注句间属性的评估，忽视了跨句子的关键论述现象。为了弥合这一差距，我们提出了Disco-Bench，一个可以评估各种NLP任务中句内论述属性的基准，涵盖了理解、翻译和生成。Disco-Bench包括了文献领域的9个文档级测试集，其中包含了中文和/或英文中丰富的论述现象（如连贯性和连贯性）。为了进行语言分析，我们还设计了一套诊断测试套件，可以检查目标模型是否学习到了论述知识。我们总共评估了20个基于Transformer、先进的预训练架构和大型语言模型(LLM)的通用型、领域内和商业化模型。

    Modeling discourse -- the linguistic phenomena that go beyond individual sentences, is a fundamental yet challenging aspect of natural language processing (NLP). However, existing evaluation benchmarks primarily focus on the evaluation of inter-sentence properties and overlook critical discourse phenomena that cross sentences. To bridge the gap, we propose Disco-Bench, a benchmark that can evaluate intra-sentence discourse properties across a diverse set of NLP tasks, covering understanding, translation, and generation. Disco-Bench consists of 9 document-level testsets in the literature domain, which contain rich discourse phenomena (e.g. cohesion and coherence) in Chinese and/or English. For linguistic analysis, we also design a diagnostic test suite that can examine whether the target models learn discourse knowledge. We totally evaluate 20 general-, in-domain and commercial models based on Transformer, advanced pretraining architectures and large language models (LLMs). Our results 
    
[^44]: AspectCSE: 使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入

    AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])

    [http://arxiv.org/abs/2307.07851](http://arxiv.org/abs/2307.07851)

    AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。

    

    通用的句子嵌入提供了对语义文本相似性的粗略近似，但忽略了使文本相似的特定方面。相反，基于方面的句子嵌入提供了基于预定义方面的文本相似性。因此，文本的相似性预测更加针对特定要求，并且更容易解释。在本文中，我们提出了AspectCSE，一种用于基于方面的对比学习句子嵌入的方法。结果表明，与之前最好的结果相比，AspectCSE在多个方面的信息检索任务中实现了平均改善3.97%。我们还提出使用Wikidata知识图属性来训练多方面句子嵌入模型，其中在相似性预测过程中同时考虑多个特定方面。我们证明了多方面嵌入在特定方面信息检索任务上优于单方面嵌入。最后，我们展示了嵌入模型的可解释性，并提出通过对比学习来改进嵌入质量。

    Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
    
[^45]: LaunchpadGPT: 以语言模型作为音乐可视化设计师在Launchpad上

    LaunchpadGPT: Language Model as Music Visualization Designer on Launchpad. (arXiv:2307.04827v1 [cs.SD])

    [http://arxiv.org/abs/2307.04827](http://arxiv.org/abs/2307.04827)

    我们提出了LaunchpadGPT模型，利用语言模型生成音乐可视化设计，并展示出优于随机生成方法的效果，具有广泛的音乐可视化应用潜力。

    

    Launchpad是一种乐器，用户可以通过按亮的按钮来创作和演奏音乐。为了辅助和启发Launchpad灯光效果的设计，并为初学者提供更易于使用的方法来通过这个乐器创建音乐可视化效果，我们提出了LaunchpadGPT模型，可以自动生成Launchpad上的音乐可视化设计。基于具有出色生成能力的语言模型，我们的LaunchpadGPT模型以音频音乐作为输入，并输出以视频形式表现Launchpad演奏的灯光效果（Launchpad播放视频）。我们收集Launchpad演奏视频并进行处理，以获取音乐和相应的Launchpad演奏视频帧作为提示完成对，用于训练语言模型。实验证明，所提出的方法比随机生成方法可以创造出更好的音乐可视化效果，并具有更广泛的音乐可视化应用潜力。

    Launchpad is a musical instrument that allows users to create and perform music by pressing illuminated buttons. To assist and inspire the design of the Launchpad light effect, and provide a more accessible approach for beginners to create music visualization with this instrument, we proposed the LaunchpadGPT model to generate music visualization designs on Launchpad automatically. Based on the language model with excellent generation ability, our proposed LaunchpadGPT takes an audio piece of music as input and outputs the lighting effects of Launchpad-playing in the form of a video (Launchpad-playing video). We collect Launchpad-playing videos and process them to obtain music and corresponding video frame of Launchpad-playing as prompt-completion pairs, to train the language model. The experiment result shows the proposed method can create better music visualization than random generation methods and hold the potential for a broader range of music visualization applications. Our code 
    
[^46]: 将苹果与苹果进行比较：从用户评论生成纵向感知的比较句子

    Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review. (arXiv:2307.03691v1 [cs.CL])

    [http://arxiv.org/abs/2307.03691](http://arxiv.org/abs/2307.03691)

    该论文提出了一个模型，利用用户评论和相关项目特征生成对比评价句子，以帮助用户找到最适合的产品。该模型包括项目编码模块、比较生成模块和个性化解码方法，并通过人类评估验证了生成句子的相关性和真实性。

    

    在众多相似的选择中找到最佳产品是非常耗时的。比较句子可以帮助我们以突出的方式对比一个项目与其他项目，在此过程中强调出重要特征。基于用户对一个或多个项目的评论及相关项目特征，我们生成比较评论句子来帮助用户找到最适合的产品。具体来说，我们的模型包括三个连续组件：（i）一个项目编码模块用于对项目进行编码比较，（ii）一个比较生成模块以自回归的方式生成比较句子，（iii）一种用于用户个性化的新型解码方法。我们展示了我们的流程能够生成流畅且多样的比较句子。我们进行了人类评估研究来验证我们生成的句子的相关性和真实性，结果表明我们的算法能够生成相关且真实的比较评论句子。

    It is time-consuming to find the best product among many similar alternatives. Comparative sentences can help to contrast one item from others in a way that highlights important features of an item that stand out. Given reviews of one or multiple items and relevant item features, we generate comparative review sentences to aid users to find the best fit. Specifically, our model consists of three successive components in a transformer: (i) an item encoding module to encode an item for comparison, (ii) a comparison generation module that generates comparative sentences in an autoregressive manner, (iii) a novel decoding method for user personalization. We show that our pipeline generates fluent and diverse comparative sentences. We run experiments on the relevance and fidelity of our generated sentences in a human evaluation study and find that our algorithm creates comparative review sentences that are relevant and truthful.
    
[^47]: 使用适配器高效域自适应句子嵌入

    Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v1 [cs.CL])

    [http://arxiv.org/abs/2307.03104](http://arxiv.org/abs/2307.03104)

    本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。

    

    句子嵌入使我们能够捕捉短文本的语义相似性。大多数句子嵌入模型是针对一般语义文本相似性（STS）任务进行训练的。因此，要在特定领域中使用句子嵌入，必须将模型适应于该领域以获得良好的结果。通常，这是通过对感兴趣的域对整个句子嵌入模型进行微调来实现的。虽然这种方法能够产生最先进的结果，但在微调过程中更新了所有模型的权重，使该方法在资源上要求较高。因此，我们提出了训练轻量级适配器的方法，而不是单独为每个目标领域微调整个句子嵌入模型。这些特定领域的适配器不需要微调所有底层句子嵌入模型的参数。相反，我们只训练少量的额外参数，同时保持底层句子嵌入模型的权重不变。训练特定领域的适配器可以始终使用同一模型并在不同领域中获得良好的性能。

    Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always 
    
[^48]: ODD: 一份基于自然语言处理的药物滥用异常行为检测的基准数据集

    ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection. (arXiv:2307.02591v1 [cs.CL])

    [http://arxiv.org/abs/2307.02591](http://arxiv.org/abs/2307.02591)

    这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。

    

    药物滥用异常行为（ORAB）是防止药物过量的新风险因素。以往，ORAB主要通过调查结果和药物给予监测进行评估。然而，这些方法无法扩展，并不能涵盖所有异常行为的范围。然而，ORAB在电子健康记录笔记中广泛有记录。本文介绍了一个名为ODD的新型生物医学自然语言处理基准数据集，用于ORAB检测。ODD是一个专家注释的数据集，包括750多个公开可用的电子健康记录笔记。ODD旨在从患者的电子健康记录笔记中识别ORAB，并将其分类为九个类别：1）已确认异常行为，2）暗示的异常行为，3）阿片类药物，4）适应症，5）已诊断的阿片制剂依赖，6）苯二氮平类药物，7）药物变化，8）与中枢神经系统相关，9）社会健康决定因素。

    Opioid related aberrant behaviors (ORAB) present novel risk factors for opioid overdose. Previously, ORAB have been mainly assessed by survey results and by monitoring drug administrations. Such methods however, cannot scale up and do not cover the entire spectrum of aberrant behaviors. On the other hand, ORAB are widely documented in electronic health record notes. This paper introduces a novel biomedical natural language processing benchmark dataset named ODD, for ORAB Detection Dataset. ODD is an expert-annotated dataset comprising of more than 750 publicly available EHR notes. ODD has been designed to identify ORAB from patients' EHR notes and classify them into nine categories; 1) Confirmed Aberrant Behavior, 2) Suggested Aberrant Behavior, 3) Opioids, 4) Indication, 5) Diagnosed opioid dependency, 6) Benzodiapines, 7) Medication Changes, 8) Central Nervous System-related, and 9) Social Determinants of Health. We explored two state-of-the-art natural language processing (NLP) mode
    
[^49]: 基于多层专家网络的改进NL2SQL技术

    Improved NL2SQL based on Multi-layer Expert Network. (arXiv:2306.17727v1 [cs.CL])

    [http://arxiv.org/abs/2306.17727](http://arxiv.org/abs/2306.17727)

    本研究提出了一种名为多层专家生成SQL的新方法，通过利用专用的多任务分层网络，该方法解决了由于不同分类任务的负迁移问题导致生成不准确SQL语句的限制。该方法在WiKSQL数据集上取得了良好的效果。

    

    自然语言到SQL（NL2SQL）技术用于将自然语言查询转换为可执行的SQL语句。通常，通过插槽填充作为多任务分类方法来实现此目标。然而，由于不同分类任务的负迁移问题，插槽填充可能导致生成不准确的SQL语句。为了克服这个限制，本研究引入了一种名为多层专家生成SQL（MLEG-SQL）的新方法，该方法利用专用的多任务分层网络。网络的下层提取自然语言语句的语义特征，而上层构建一个专门的专家系统来处理特定的分类任务。这种分层方法减轻了不同任务冲突带来的性能下降。该方法在WiKSQL数据集上进行了评估，并证明在生成准确的SQL语句方面是有效的。

    The Natural Language to SQL (NL2SQL) technique is used to convert natural language queries into executable SQL statements. Typically, slot-filling is employed as a classification method for multi-task cases to achieve this goal. However, slot-filling can result in inaccurate SQL statement generation due to negative migration issues arising from different classification tasks. To overcome this limitation, this study introduces a new approach called Multi-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated multi-task hierarchical network. The lower layer of the network extracts semantic features of natural language statements, while the upper layer builds a specialized expert system for handling specific classification tasks. This hierarchical approach mitigates performance degradation resulting from different task conflicts. The proposed method was evaluated on the WiKSQL dataset and was found to be effective in generating accurate SQL statements.
    
[^50]: ChatGPT 是一个生物医学专家吗？——探索当前 GPT 模型在生物医学任务中的零样本性能。

    Is ChatGPT a Biomedical Expert? -- Exploring the Zero-Shot Performance of Current GPT Models in Biomedical Tasks. (arXiv:2306.16108v1 [cs.CL])

    [http://arxiv.org/abs/2306.16108](http://arxiv.org/abs/2306.16108)

    通过对 GPT-3.5-Turbo 和 GPT-4 在生物医学任务中的表现评估，发现它们能够通过零样本学习和相关片段的支撑与领先系统相竞争，但在检索任务中表现不如其他系统。

    

    我们评估了商业大型语言模型 GPT-3.5-Turbo 和 GPT-4 在 2023 年 BioASQ 挑战中的任务表现。在任务 11b 第二阶段中，也就是答案生成任务中，这两个模型通过简单的零样本学习和相关片段的支撑表现出了与领先系统相竞争的能力。值得注意的是，即使没有相关片段，它们的性能也令人满意，尽管没有达到最佳系统的水平。有趣的是，较旧且更便宜的 GPT-3.5-Turbo 系统在基于事实和列表答案的问答环境中能够与 GPT-4 相竞争。在任务 11b 第一阶段中，侧重于检索，通过零样本学习的查询扩展提高了模型的性能，但与其他系统相比仍然有所不足。重新运行这些实验所需的代码可在 GitHub 上获得。

    We assessed the performance of commercial Large Language Models (LLMs) GPT-3.5-Turbo and GPT-4 on tasks from the 2023 BioASQ challenge. In Task 11b Phase B, which is focused on answer generation, both models demonstrated competitive abilities with leading systems. Remarkably, they achieved this with simple zero-shot learning, grounded with relevant snippets. Even without relevant snippets, their performance was decent, though not on par with the best systems. Interestingly, the older and cheaper GPT-3.5-Turbo system was able to compete with GPT-4 in the grounded Q&A setting on factoid and list answers. In Task 11b Phase A, focusing on retrieval, query expansion through zero-shot learning improved performance, but the models fell short compared to other systems. The code needed to rerun these experiments is available through GitHub.
    
[^51]: 基于大语言模型的中文细粒度金融情感分析

    Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models. (arXiv:2306.14096v1 [cs.CL])

    [http://arxiv.org/abs/2306.14096](http://arxiv.org/abs/2306.14096)

    本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。

    

    金融领域实体级别的细粒度情感分析是情感分析的重要子任务，目前面临着众多挑战。其中主要挑战之一来自于缺乏专门设计用于金融文本情感分析的高质量大规模标注语料库，这限制了开发有效文本处理技术所需的数据的可用性。大语言模型（LLMs）的最新进展在自然语言处理任务中取得了显著的性能，主要集中在语言模式匹配方面。在本文中，我们提出了一个新颖的、广泛的中文细粒度金融情感分析数据集FinChina SA，用于企业预警。我们对流行的现有开源LLMs使用我们的数据集进行了全面的评估和实验。我们坚信，我们的数据集将成为推动真实世界金融情感分析任务探索的宝贵资源。

    Entity-level fine-grained sentiment analysis in the financial domain is a crucial subtask of sentiment analysis and currently faces numerous challenges. The primary challenge stems from the lack of high-quality and large-scale annotated corpora specifically designed for financial text sentiment analysis, which in turn limits the availability of data necessary for developing effective text processing techniques. Recent advancements in large language models (LLMs) have yielded remarkable performance in natural language processing tasks, primarily centered around language pattern matching. In this paper, we propose a novel and extensive Chinese fine-grained financial sentiment analysis dataset, FinChina SA, for enterprise early warning. We thoroughly evaluate and experiment with well-known existing open-source LLMs using our dataset. We firmly believe that our dataset will serve as a valuable resource to advance the exploration of real-world financial sentiment analysis tasks, which shoul
    
[^52]: 推理时间干预：从语言模型中引导出真实的答案

    Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. (arXiv:2306.03341v1 [cs.LG])

    [http://arxiv.org/abs/2306.03341](http://arxiv.org/abs/2306.03341)

    本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。

    

    我们介绍了推理时间干预（ITI）技术，旨在增强大型语言模型（LLMs）的真实性。ITI通过在推理过程中沿着一组方向移动模型激活，跨越有限数量的注意力头。这种干预显着提高了LLaMA模型在TruthfulQA基准上的表现。在指令微调的LLaMA Alpaca上，ITI将其真实性从32.5％提高到65.1％。我们确定了真实性和可用性之间的权衡，并演示了如何通过调整干预强度来平衡它。ITI 取得了最低程度的干扰且计算廉价。此外，该技术在数据效率上表现优异：虽然像RLHF这样的方法需要广泛注释，但是ITI仅使用了几百个例子就能定位真实的方向。我们的研究结果表明，LLMs可能具有某种内部表示方法来表示某事是真实的可能性，即使它们在表面上产生了虚假的结果。

    We introduce Inference-Time Intervention (ITI), a technique designed to enhance the truthfulness of large language models (LLMs). ITI operates by shifting model activations during inference, following a set of directions across a limited number of attention heads. This intervention significantly improves the performance of LLaMA models on the TruthfulQA benchmark. On an instruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from 32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and demonstrate how to balance it by tuning the intervention strength. ITI is minimally invasive and computationally inexpensive. Moreover, the technique is data efficient: while approaches like RLHF require extensive annotations, ITI locates truthful directions using only few hundred examples. Our findings suggest that LLMs may have an internal representation of the likelihood of something being true, even as they produce falsehoods on the surface.
    
[^53]: 识别情感体验者作为情感分析的先决条件

    Emotion Experiencer Recognition as a Prerequisite for Experiencer-Specific Emotion Analysis. (arXiv:2305.16731v1 [cs.CL])

    [http://arxiv.org/abs/2305.16731](http://arxiv.org/abs/2305.16731)

    本文提出了一种用于检测情感体验者并为其分配情感的自动方法，并进行了相关的实验。该方法的实现具有挑战性，但展示了在文本中检测情感体验者的可行性。

    

    情感角色标注旨在提取文本中描述谁经历情感、为什么以及对谁的信息。这通常是一个具有挑战性的建模任务，如果要回答的主要问题是谁感受到了哪种情感，这可能会过于复杂。本文填补了这一空白，通过自动检测文本中的情感体验者并随后为其分配情感，展示了在文本中检测情感体验者是一项具有挑战性的任务，并呈现了相关的实验结果。

    Emotion role labeling aims at extracting who is described in text to experience an emotion, why, and towards whom. This is often a challenging modelling task which might be overly sophisticated if the main question to answer is who feels which emotion. Recently, Troiano et al. (2022) proposed a data set that focuses on assigning emotion labels and appraisal labels to individual entities in text and Wegge et al. (2022) presented the first modelling experiments. Their experiencer-specific emotion prediction model has, however, only been evaluated on gold-annotated experiencers, due to the unavailability of an automatic experiencer detection approach. We fill this gap with the first experiments to automatically detect emotion experiencers in text and, subsequently, assign them emotions. We show that experiencer detection in text is a challenging task, with a precision of .82 and a recall of .56 (F1 =.66). Consequently, the performance of the experiencer-specific emotion detection pipeline
    
[^54]: 长文本的神经自然语言处理：现状综述

    Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art. (arXiv:2305.16259v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16259](http://arxiv.org/abs/2305.16259)

    本文简要概述了长文本的神经自然语言处理的现状，主要包括文档分类和摘要，涵盖了情感分析，同时还探讨了长文本NLP的主要挑战、问题和解决方案。

    

    在过去的十年中，深度神经网络（DNN）的采用极大地促进了自然语言处理（NLP）的发展。然而，长文本分析的需求与短文本有很大不同，而网络上传输的文档大小不断增加，使长文本的自动理解成为一项关键的研究领域。本文的两个目标是：a）概述相关的神经构建模块，作为短教程；b）总结长文本NLP的现状，主要关注两个核心任务：文档分类和文档摘要。情感分析也涵盖在内，因为它通常被视为文档分类的特例。此外，本文还讨论了长文本NLP相关的主要挑战、问题和解决方案。最后，介绍了相关的公开的注释数据集，以便促进进一步研究。

    The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural Language Processing (NLP) during the past decade. However, the demands of long document analysis are quite different from those of shorter texts, while the ever increasing size of documents uploaded on-line renders automated understanding of long texts a critical area of research. This article has two goals: a) it overviews the relevant neural building blocks, thus serving as a short tutorial, and b) it surveys the state-of-the-art in long document NLP, mainly focusing on two central tasks: document classification and document summarization. Sentiment analysis for long texts is also covered, since it is typically treated as a particular case of document classification. Additionally, this article discusses the main challenges, issues and current solutions related to long document NLP. Finally, the relevant, publicly available, annotated datasets are presented, in order to facilitate further research.
    
[^55]: 基于视觉引导的自监督语音模型中的音节发现和跨语言泛化

    Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode. (arXiv:2305.11435v1 [eess.AS])

    [http://arxiv.org/abs/2305.11435](http://arxiv.org/abs/2305.11435)

    本文提出采用基于视觉引导的自监督语音模型进行音节发现和跨语言泛化。使用最小割算法和2阶段聚类方法自动预测语音中的音节边界。在英语上表现优于最先进的音节分割方法，并以零样本的方式在爱沙尼亚语上泛化。在其他语言上也取得了成功。

    

    本文表明，在使用基于视觉引导的训练目标训练自监督语音模型时，能够捕捉到表示音节的单元的表征。我们证明了几乎相同的模型结构（HuBERT），在使用掩码语言建模损失进行训练时没有表现出这种能力，这表明视觉引导目标导致了这种现象的出现。我们提出使用最小割算法自动预测语音中的音节边界，然后使用两阶段聚类方法将相同的音节组合在一起。我们展示了，我们的模型不仅在训练的语言（英语）上优于最先进的音节分割方法，而且在爱沙尼亚语上以零样本的方式进行泛化。最后，我们展示了相同的模型能够进行4种其他语言的零样本单词分割任务泛化，在某些情况下击败了先前的最先进技术。

    In this paper, we show that representations capturing syllabic units emerge when training a self-supervised speech model with a visually-grounded training objective. We demonstrate that a nearly identical model architecture (HuBERT) trained with a masked language modeling loss does not exhibit this same ability, suggesting that the visual grounding objective is responsible for the emergence of this phenomenon. We propose the use of a minimum cut algorithm to automatically predict syllable boundaries in speech, followed by a 2-stage clustering method to group identical syllables together. We show that our model not only outperforms a state-of-the-art syllabic segmentation method on the language it was trained on (English), but also generalizes in a zero-shot fashion to Estonian. Finally, we show that the same model is capable of zero-shot generalization for a word segmentation task on 4 other languages from the Zerospeech Challenge, in some cases beating the previous state-of-the-art.
    
[^56]: 视觉与定义相遇：融合词义信息的无监督视觉词义消歧

    Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information. (arXiv:2305.01788v1 [cs.CL])

    [http://arxiv.org/abs/2305.01788](http://arxiv.org/abs/2305.01788)

    本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。

    

    视觉词义消歧是一项任务，旨在找到最准确地描述给定上下文中目标词正确意义的图像。以往的图像-文本匹配模型往往受到词义多义性的影响。本文介绍了一种无监督的视觉词义消歧方法，该方法使用了外部词汇知识库的词汇信息，特别是词义定义。具体而言，我们建议在没有提供答案的词义信息时，采用贝叶斯推断来加入词义定义。此外，为了改进词典外问题，我们提出了一种与上下文相关的GPT-3定义生成方法。实验结果表明，我们的基于贝叶斯推断的方法明显提高了视觉词义消歧的性能。此外，我们的上下文相关定义生成方法在词典外例子上取得了显著的性能提升，表现优于现有的定义生成方法。

    Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words. This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3. Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples exhibiting better performance than the existing definition generation method. We will publish source 
    
[^57]: 朝自主系统迈进：使用大语言模型代理增强的灵活模块化生产系统

    Towards autonomous system: flexible modular production system enhanced with large language model agents. (arXiv:2304.14721v1 [cs.RO])

    [http://arxiv.org/abs/2304.14721](http://arxiv.org/abs/2304.14721)

    本论文介绍了一种将大语言模型、数字孪生和工业自动化系统相结合的框架，实现生产过程的智能化规划和控制。通过LLM代理的协调控制，实现了灵活生产的自主规划和控制，能够处理未预定义的任务并规划生产过程。

    

    本文提出了一种新颖的框架，将大型语言模型（LLM），数字孪生和工业自动化系统结合起来，实现生产过程的智能规划和控制。我们的方法涉及开发包含生产描述信息的数字孪生系统，并将自动化系统改造为提供统一接口的细粒度功能或模块，以供自动化组件或模块执行。随后，设计LLM代理来解释数字孪生中的描述性信息，并通过RESTful接口控制物理系统。这些LLM代理作为自动化系统内的智能代理，实现了灵活生产的自主规划和控制。给定一个任务指令作为输入，LLM代理协调一系列原子功能和技能来完成任务。我们展示了我们实现的原型如何处理未预定义的任务，并计划生产过程。

    In this paper, we present a novel framework that combines large language models (LLMs), digital twins and industrial automation system to enable intelligent planning and control of production processes. Our approach involves developing a digital twin system that contains descriptive information about the production and retrofitting the automation system to offer unified interfaces of fine-granular functionalities or skills executable by automation components or modules. Subsequently, LLM-Agents are designed to interpret descriptive information in the digital twins and control the physical system through RESTful interfaces. These LLM-Agents serve as intelligent agents within an automation system, enabling autonomous planning and control of flexible production. Given a task instruction as input, the LLM-agents orchestrate a sequence of atomic functionalities and skills to accomplish the task. We demonstrate how our implemented prototype can handle un-predefined tasks, plan a production p
    
[^58]: 基于BERT的技术对美国最高法院案例进行分类

    Classification of US Supreme Court Cases using BERT-Based Techniques. (arXiv:2304.08649v1 [cs.CL])

    [http://arxiv.org/abs/2304.08649](http://arxiv.org/abs/2304.08649)

    本文基于BERT技术探究了对美国最高法院案例进行分类的方法，比较了使用BERT模型与其他先进模型的准确性，最终在15个广泛类别上取得了80%的准确度，在279个细粒度类别上取得了60%的准确度。

    

    基于双向编码器表示来自变压器的模型（BERT）在许多自然语言处理（NLP）任务（如命名实体识别（NER），词性（POS）标记等）上产生了最新技术（SOTA）结果。当分类长文档（例如来自美国最高法院的文档）时，使用BERT模型可能比较困难。本文中，我们尝试了几种基于BERT的分类技术，用于对美国最高法院决定或最高法院数据库（SCDB）进行分类，并将其与先前的SOTA结果进行了比较。我们还将我们的结果与针对长文档的SOTA模型进行了比较。我们对两个分类任务进行了比较：（1）广泛的分类任务，具有15个类别；（2）细粒度的分类任务，具有279个类别。我们的最佳结果在15个广泛类别上产生80％的准确度，在279个细粒度类别上产生60％的准确度。

    Models based on bidirectional encoder representations from transformers (BERT) produce state of the art (SOTA) results on many natural language processing (NLP) tasks such as named entity recognition (NER), part-of-speech (POS) tagging etc. An interesting phenomenon occurs when classifying long documents such as those from the US supreme court where BERT-based models can be considered difficult to use on a first-pass or out-of-the-box basis. In this paper, we experiment with several BERT-based classification techniques for US supreme court decisions or supreme court database (SCDB) and compare them with the previous SOTA results. We then compare our results specifically with SOTA models for long documents. We compare our results for two classification tasks: (1) a broad classification task with 15 categories and (2) a fine-grained classification task with 279 categories. Our best result produces an accuracy of 80\% on the 15 broad categories and 60\% on the fine-grained 279 categories 
    
[^59]: ELVIS: 利用模态内相似性增强视觉语言预训练中的局部性能力

    ELVIS: Empowering Locality of Vision Language Pre-training with Intra-modal Similarity. (arXiv:2304.05303v1 [cs.CV])

    [http://arxiv.org/abs/2304.05303](http://arxiv.org/abs/2304.05303)

    本文提出了一种新的视觉语言预训练方法，称为ELVIS，可以增强放射学报告或 X 射线图像中的局部性能力，提高了理解位置参考的能力。

    

    深度学习在辅助放射科医生阅读胸部 X 射线图像方面表现出巨大潜力，但其需要昂贵的注释来提高性能，这阻碍了其广泛的临床应用。视觉语言预训练（VLP）可以通过利用常规生成的放射学报告进行训练，从而减轻注释的负担和成本，这些报告以成对的形式（图像-文本对）大量存在。此外，正在提出扩展到定位感知VLP，以满足CAD在CXR的准确异常定位需求。然而，我们发现由局部性VLP文献提出的公式实际上导致了下游定位任务所需的空间关系的丢失。因此，我们提出了Empowering Locality of VLP with Intra-modal Similarity（ELVIS），这是一种VLP，可感知模态内部的局部性能力，以更好地保留放射学报告或 X 射线图像中的局部性能力，从而提高了理解位置参考的能力。

    Deep learning has shown great potential in assisting radiologists in reading chest X-ray (CXR) images, but its need for expensive annotations for improving performance prevents widespread clinical application. Visual language pre-training (VLP) can alleviate the burden and cost of annotation by leveraging routinely generated reports for radiographs, which exist in large quantities as well as in paired form (imagetext pairs). Additionally, extensions to localization-aware VLPs are being proposed to address the needs of accurate localization of abnormalities for CAD in CXR. However, we find that the formulation proposed by locality-aware VLP literatures actually leads to loss in spatial relationships required for downstream localization tasks. Therefore, we propose Empowering Locality of VLP with Intra-modal Similarity, ELVIS, a VLP aware of intra-modal locality, to better preserve the locality within radiographs or reports, which enhances the ability to comprehend location references in
    
[^60]: 大语言模型在教育中的实际和伦理挑战：一项系统文献综述

    Practical and Ethical Challenges of Large Language Models in Education: A Systematic Literature Review. (arXiv:2303.13379v1 [cs.CL])

    [http://arxiv.org/abs/2303.13379](http://arxiv.org/abs/2303.13379)

    LLMs在教育中有自动生成和分析文本内容的潜力。然而，这些创新的实际性和伦理性存在担忧，需要考虑技术可行性、隐私、平等和善意等因素。

    

    基于大语言模型（LLMs）开发的教育技术创新显示出自动生成和分析文本内容的潜力。虽然已经开发了各种创新来自动化各种教育任务（例如，生成问题、提供反馈和评分），但对这些创新的实际性和伦理性存在担忧。这些担忧可能会阻碍未来研究和在真实教育环境中采用基于LLMs的创新。为了解决这个问题，我们对118篇自2017年以来发表的同行评议论文进行了系统的文献综述，以确定使用LLMs自动化和支持教育任务的当前研究状态。通过评估其技术可行性、模型性能、可复制性、系统透明度、隐私、平等和善意，还确定了LLMs创新的实际和伦理挑战。

    Educational technology innovations that have been developed based on large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (e.g., question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs-based innovations in authentic educational contexts. To address this, we conducted a systematic literature review of 118 peer-reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The practical and ethical challenges of LLMs-based innovations were also identified by assessing their technological readiness, model performance, replicability, system transparency, privacy, equality, and beneficence. The findings 
    
[^61]: MenuCraft: 基于大型语言模型的交互式菜单系统设计

    MenuCraft: Interactive Menu System Design with Large Language Models. (arXiv:2303.04496v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04496](http://arxiv.org/abs/2303.04496)

    MenuCraft是一个基于大型语言模型的AI辅助设计师，通过对话系统与设计师协作，提供了一个交互式菜单设计工具，可以简化菜单设计过程，并支持零/少次学习。

    

    菜单系统设计是一项具有挑战性的任务，涉及许多设计选项和各种人因素。本文提出了一种名为MenuCraft的AI辅助设计师，通过设计和细化菜单系统的对话系统，实现设计师与对话系统之间的协作。MenuCraft提供了一个基于语言的交互式菜单设计工具，简化了菜单设计过程，并实现了设计选项的轻松定制。MenuCraft通过对话支持各种交互方式，可以进行零/少次学习。

    Menu system design is a challenging task involving many design options and various human factors. For example, one crucial factor that designers need to consider is the semantic and systematic relation of menu commands. However, capturing these relations can be challenging due to limited available resources. With the advancement of neural language models, large language models can utilize their vast pre-existing knowledge in designing and refining menu systems. In this paper, we propose MenuCraft, an AI-assisted designer for menu design that enables collaboration between the designer and a dialogue system to design menus. MenuCraft offers an interactive language-based menu design tool that simplifies the menu design process and enables easy customization of design options. MenuCraft supports a variety of interactions through dialog that allows performing zero/few-shot learning.
    
[^62]: Transformers如何学习主题结构：走向对其机制的理解

    How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding. (arXiv:2303.04245v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04245](http://arxiv.org/abs/2303.04245)

    本文提供了对Transformer学习语义结构的机制性理解，通过数学分析和实验证明了嵌入层和自注意力层如何对词汇的共现结构进行编码。

    

    尽管Transformer在许多领域都取得了成功，但对其学习机制的准确理解仍然存在较大的缺乏。虽然它们在包括各种结构化和推理任务在内的基准测试中表现出了强大的能力，但对数学理解的研究仍然滞后。最近的研究开始从表示方面研究了这个问题：即基于注意力的网络的大小/深度/复杂性用于执行某些任务。然而，并不能保证学习动态会收敛到所提出的结构上。在本文中，我们提供了细致入微的机制理解，阐明了Transformer如何学习“语义结构”，即捕捉词汇的共现结构。准确地说，我们通过数学分析和对维基百科数据以及由潜在狄利克雷分配（LDA）建模的合成数据进行的实验，展示了嵌入层和自注意力层如何对主题进行编码。

    While the successes of transformers across many domains are indisputable, accurate understanding of the learning mechanics is still largely lacking. Their capabilities have been probed on benchmarks which include a variety of structured and reasoning tasks -- but mathematical understanding is lagging substantially behind. Recent lines of work have begun studying representational aspects of this question: that is, the size/depth/complexity of attention-based networks to perform certain tasks. However, there is no guarantee the learning dynamics will converge to the constructions proposed. In our paper, we provide fine-grained mechanistic understanding of how transformers learn "semantic structure", understood as capturing co-occurrence structure of words. Precisely, we show, through a combination of mathematical analysis and experiments on Wikipedia data and synthetic data modeled by Latent Dirichlet Allocation (LDA), that the embedding layer and the self-attention layer encode the topi
    
[^63]: 在新闻文章中检测有害议程

    Detecting Harmful Agendas in News Articles. (arXiv:2302.00102v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.00102](http://arxiv.org/abs/2302.00102)

    这项研究提出了一种新的任务，即在新闻文章中检测有害议程，并发布了一个新闻文章注释数据集以供研究使用。研究者展示了可解释系统在这一任务上的有效性，并证明它们可以和黑盒模型有相当的表现。

    

    在线上操纵新闻是一个日益严重的问题，需要使用自动化系统来遏制其传播。我们认为，虽然误导信息和虚假信息的检测已经得到研究，但在检测新闻文章中的有害议程这一重要挑战方面缺乏投资；识别有害议程对于识别具有最大潜在现实危害的新闻运动至关重要。此外，由于对审查制度存在真实的担忧，有害议程检测器必须具有可解释性才能发挥作用。在这项工作中，我们提出了这一全新的任务，并发布了一个名为NewsAgendas的新闻文章注释数据集，用于议程识别。我们展示了可解释系统在这一任务上的有效性，并证明它们可以与黑盒模型具有相当的表现。

    Manipulated news online is a growing problem which necessitates the use of automated systems to curtail its spread. We argue that while misinformation and disinformation detection have been studied, there has been a lack of investment in the important open challenge of detecting harmful agendas in news articles; identifying harmful agendas is critical to flag news campaigns with the greatest potential for real world harm. Moreover, due to real concerns around censorship, harmful agenda detectors must be interpretable to be effective. In this work, we propose this new task and release a dataset, NewsAgendas, of annotated news articles for agenda identification. We show how interpretable systems can be effective on this task and demonstrate that they can perform comparably to black-box models.
    
[^64]: DetectGPT：使用概率曲率进行零样本机器生成文本检测

    DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature. (arXiv:2301.11305v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11305](http://arxiv.org/abs/2301.11305)

    本论文提出了一种名为DetectGPT的方法，使用概率曲率来判断文本是否由一个给定的大型语言模型生成。该方法不需要训练分类器、收集数据集或明确加水印，只使用模型计算的对数概率和另一个预训练语言模型的随机扰动。实验证明，DetectGPT在模型采样方面比现有的零样本方法更具有区分能力。

    

    大型语言模型（LLM）的流畅度和广泛使用突显了希望有相应的工具来帮助检测LLM生成的文本的需求。在本文中，我们发现了LLM概率函数结构的一个有用属性，对于这种检测非常有用。具体而言，我们证明从LLM中采样的文本倾向于占据模型的对数概率函数的负曲率区域。基于这一观察，我们定义了一种新的基于曲率的准则，用于判断一个段落是否是由给定的LLM生成的。这种方法被称为DetectGPT，不需要训练单独的分类器，收集真实或生成段落的数据集，也不需要明确地给生成的文本加水印。它只使用所关注模型计算的对数概率和来自另一个通用预训练语言模型（例如T5）的段落的随机扰动。我们发现DetectGPT比现有的零样本方法更具有区分能力，用于模型采样。

    The increasing fluency and widespread usage of large language models (LLMs) highlight the desirability of corresponding tools aiding detection of LLM-generated text. In this paper, we identify a property of the structure of an LLM's probability function that is useful for such detection. Specifically, we demonstrate that text sampled from an LLM tends to occupy negative curvature regions of the model's log probability function. Leveraging this observation, we then define a new curvature-based criterion for judging if a passage is generated from a given LLM. This approach, which we call DetectGPT, does not require training a separate classifier, collecting a dataset of real or generated passages, or explicitly watermarking generated text. It uses only log probabilities computed by the model of interest and random perturbations of the passage from another generic pre-trained language model (e.g., T5). We find DetectGPT is more discriminative than existing zero-shot methods for model samp
    
[^65]: 极大预训练语言模型是否能够在很少的样例下学习故事创作？

    Can Very Large Pretrained Language Models Learn Storytelling With A Few Examples?. (arXiv:2301.09790v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.09790](http://arxiv.org/abs/2301.09790)

    本文探讨了使用极大预训练语言模型（VLPLMs）创作故事的可能性，并通过与SOTA模型在不同数据集上的比较，证明VLPLMs生成的故事质量更高，并展示一定程度上可与人类作者相抗衡，尽管初步调查揭示了它们倾向于“抄袭”真实的故事。

    

    尽管预训练语言模型可以生成语法通顺的句子用于自动生成故事，但是它们难以生成连贯、有意义和有趣的故事。当前最先进的故事生成模型通过探索更高级的特征，例如情节或常识知识以提高生成故事的质量。使用极大预训练语言模型（VLPLMs）如GPT3的提示式学习已经已经在各种自然语言处理任务中表现出惊人的性能。本文提出了一项广泛的研究，使用自动和人类评估来比较VLPLMs与那些在风格、语言和长度等方面不同的SOTA模型在三个不同数据集上的故事生成能力。我们的研究结果表明VLPLMs生成的故事质量远远高于其他故事生成模型，并在一定程度上可以与人类作者相抗衡，尽管初步调查也揭示了它们倾向于“抄袭”真实的故事。

    While pre-trained language models can generate individually fluent sentences for automatic story generation, they struggle to generate stories that are coherent, sensible and interesting. Current state-of-the-art (SOTA) story generation models explore using higher-level features such as plots or commonsense knowledge to improve the quality of generated stories. Prompt-based learning using very large pre-trained language models (VLPLMs) such as GPT3 has demonstrated impressive performance even across various NLP tasks. In this paper, we present an extensive study using automatic and human evaluation to compare the story generation capability of VLPLMs to those SOTA models in three different datasets where stories differ in style, register and length. Our results show that VLPLMs generate much higher quality stories than other story generation models, and to a certain extent rival human authors, although preliminary investigation also reveals that they tend to ``plagiarise'' real stories
    
[^66]: 关于图类型的知识图谱推理综述：静态、动态和多模态

    A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multimodal. (arXiv:2212.05767v7 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.05767](http://arxiv.org/abs/2212.05767)

    本文对知识图谱推理进行了综述，涵盖了静态、动态和多模态三种图类型，填补了这一领域的研究空白。

    

    知识图谱推理（KGR）旨在根据知识图谱（KG）中的逻辑规则推断出新的事实，已成为快速增长的研究方向。它已被证明在许多人工智能应用中极大地有益，如问题回答、推荐系统等。根据图类型，现有的KGR模型可以大致分为三类，即静态模型、时态模型和多模态模型。该领域的早期工作主要集中在静态KGR上，而最近的工作尝试利用更实际和更接近现实世界的时态和多模态信息。然而，目前尚无综合总结和讨论这一重要方向中的模型的调查论文和开源存储库。为了填补这个空白，我们进行了一项针对从静态到时态再到多模态KG的知识图谱推理的首次综述。具体而言，本文基于双层分类对模型进行了回顾，

    Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to significantly benefit the usage of KGs in many AI applications, such as question answering, recommendation systems, and etc. According to the graph types, existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. Early works in this domain mainly focus on static KGR, and recent works try to leverage the temporal and multi-modal information, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the models are reviewed based on bi-level taxonomy,
    
[^67]: 翻译：利用风格分类来检测失落的《Midrash Tanhuma》材料

    Style Classification of Rabbinic Literature for Detection of Lost Midrash Tanhuma Material. (arXiv:2211.09710v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.09710](http://arxiv.org/abs/2211.09710)

    本文提出了一种拉比文学的分类系统，可以通过其风格来检测Midrash Tanhuma中的失落材料。

    

    Midrash集合是复杂的拉比文献作品，由多种语言的文本组成，经过不稳定的口头和书面传递过程演变而来。确定这种合集中的一个给定段落的起源并不总是直观的，常常是学者之间的争议，然而对于学者们理解段落及其与拉比文集中其他文本的关系至关重要。为了解决这个问题，我们提出了一个基于风格的拉比文学分类系统，利用最近发布的针对希伯来语的预训练Transformer模型。此外，我们展示了如何利用我们的方法来发现失落的Midrash Tanhuma材料。

    Midrash collections are complex rabbinic works that consist of text in multiple languages, which evolved through long processes of unstable oral and written transmission. Determining the origin of a given passage in such a compilation is not always straightforward and is often a matter of dispute among scholars, yet it is essential for scholars' understanding of the passage and its relationship to other texts in the rabbinic corpus.  To help solve this problem, we propose a system for classification of rabbinic literature based on its style, leveraging recently released pretrained Transformer models for Hebrew. Additionally, we demonstrate how our method can be applied to uncover lost material from Midrash Tanhuma.
    
[^68]: 扩大放射学报告摘要范围：多个解剖学和模态的综述

    Toward expanding the scope of radiology report summarization to multiple anatomies and modalities. (arXiv:2211.08584v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08584](http://arxiv.org/abs/2211.08584)

    本论文针对放射学报告摘要存在的限制，提出了一个新的数据集MIMIC-RRS，包含多个解剖学和模态。通过在数据集上进行实验和临床评估，我们旨在扩大放射学报告摘要的应用范围。

    

    放射学报告摘要（RRS）是一个不断发展的研究领域。给定放射学报告的发现部分，目标是生成一个概述（称为印象部分），突出放射学研究的关键观察和结论。然而，RRS目前面临着重要的限制。首先，许多先前的研究使用私有数据集进行实验，无法重现结果并在不同系统和解决方案之间进行公平比较。其次，大多数先前的方法仅在胸部X射线上进行评估。为了解决这些限制，我们提出了一个数据集（MIMIC-RRS），涉及MIMIC-III和MIMIC-CXR数据集的三种新的模态和七种新的解剖学。然后，我们进行了大量实验，评估了模型在MIMIC-RRS中的模态-解剖学对内和对外的性能。此外，我们通过RadGraph评估它们的临床功效，这是一个事实正确性指标。

    Radiology report summarization (RRS) is a growing area of research. Given the Findings section of a radiology report, the goal is to generate a summary (called an Impression section) that highlights the key observations and conclusions of the radiology study. However, RRS currently faces essential limitations.First, many prior studies conduct experiments on private datasets, preventing reproduction of results and fair comparisons across different systems and solutions. Second, most prior approaches are evaluated solely on chest X-rays. To address these limitations, we propose a dataset (MIMIC-RRS) involving three new modalities and seven new anatomies based on the MIMIC-III and MIMIC-CXR datasets. We then conduct extensive experiments to evaluate the performance of models both within and across modality-anatomy pairs in MIMIC-RRS. In addition, we evaluate their clinical efficacy via RadGraph, a factual correctness metric.
    
[^69]: 对数线性保护性及其影响的研究

    Log-linear Guardedness and its Implications. (arXiv:2210.10012v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.10012](http://arxiv.org/abs/2210.10012)

    本研究介绍了对数线性保护性及其对下游分类器行为的影响。在二元情况下，下游对数线性模型无法恢复被删除的概念，但在某些情况下，可以通过构建多类对数线性模型间接恢复概念。这些结果揭示了线性删除方法的局限性，并强调了进一步研究的需求。

    

    已经发现，在假设可线性的神经表示中，从中删除可人解释的概念的方法是可行和有用的。然而，这种删除对于基于修改后表示进行训练的下游分类器行为的影响尚未完全理解。在这项工作中，我们正式定义了对数线性保护性的概念，即对手无法直接从表示中预测概念的能力，并研究其影响。我们证明，在二元情况下，在某些假设下，下游对数线性模型无法恢复被删除的概念。然而，我们证明，在某些情况下，可以构建一个多类对数线性模型，间接恢复概念，这指出了对数线性保护性作为下游偏差缓解技术的内在局限性。这些发现揭示了线性删除方法的理论限制，并强调了进一步研究可解释神经表示与分类器之间的联系的需要。

    Methods for erasing human-interpretable concepts from neural representations that assume linearity have been found to be tractable and useful. However, the impact of this removal on the behavior of downstream classifiers trained on the modified representations is not fully understood. In this work, we formally define the notion of log-linear guardedness as the inability of an adversary to predict the concept directly from the representation, and study its implications. We show that, in the binary case, under certain assumptions, a downstream log-linear model cannot recover the erased concept. However, we demonstrate that a multiclass log-linear model \emph{can} be constructed that indirectly recovers the concept in some cases, pointing to the inherent limitations of log-linear guardedness as a downstream bias mitigation technique. These findings shed light on the theoretical limitations of linear erasure methods and highlight the need for further research on the connections between int
    
[^70]: 学习"O"有助于更多的学习：解决类增量NER的隐藏实体问题

    Learning "O" Helps for Learning More: Handling the Concealed Entity Problem for Class-incremental NER. (arXiv:2210.04676v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04676](http://arxiv.org/abs/2210.04676)

    本研究解决了类增量NER中的隐藏实体问题，提出了一种表示学习方法，通过对实体类别和"O"进行判别式表示学习，改善了NER模型对于新旧类别的识别能力。

    

    随着命名实体的类别迅速增加，部署的NER模型需要不断更新以识别更多的实体类型，这就需要对NER进行类增量学习。考虑到隐私问题和存储约束，类增量NER的标准范式仅使用带有新类别注释的训练数据更新模型，而来自其他实体类别的实体被标记为"非实体"（或"O"）。本文对"未标记实体问题"进行了实证研究，发现它导致"O"和实体之间严重混淆，降低了旧类别的分类能力，并降低了模型学习新类别的能力。为了解决未标记实体问题，我们提出了一种新的表示学习方法，学习实体类别和"O"的判别表示。具体而言，我们提出了一种实体感知的对比学习方法，在representation learning方面进行了改进。

    As the categories of named entities rapidly increase, the deployed NER models are required to keep updating toward recognizing more entity types, creating a demand for class-incremental learning for NER. Considering the privacy concerns and storage constraints, the standard paradigm for class-incremental NER updates the models with training data only annotated with the new classes, yet the entities from other entity classes are unlabeled, regarded as "Non-entity" (or "O"). In this work, we conduct an empirical study on the "Unlabeled Entity Problem" and find that it leads to severe confusion between "O" and entities, decreasing class discrimination of old classes and declining the model's ability to learn new classes. To solve the Unlabeled Entity Problem, we propose a novel representation learning method to learn discriminative representations for the entity classes and "O". Specifically, we propose an entity-aware contrastive learning method that adaptively detects entity clusters in
    
[^71]: DSTEA：通过实体自适应预训练来改进对话状态跟踪

    DSTEA: Improving Dialogue State Tracking via Entity Adaptive Pre-training. (arXiv:2207.03858v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.03858](http://arxiv.org/abs/2207.03858)

    本研究提出了DSTEA方法，通过实体自适应预训练来改进对话状态跟踪。它通过密集训练对话话语中的关键实体，而无需外部对话语料库，并且只需要进行预训练而不直接注入额外的知识到DST模型中。这种方法取得了出色的效果。

    

    对话状态跟踪(DST)对于全面解释用户和系统话语以形成高效对话系统的基础至关重要。尽管过去的研究努力集中在通过改变模型结构或集成图关系等额外特征来提升DST性能，但它们常常需要额外的预训练与外部对话语料库。在本研究中，我们提出了DSTEA，通过实体自适应预训练来改进对话状态跟踪，可以通过密集训练对话话语中的关键实体来增强编码器。DSTEA利用四种不同的方法从输入对话中识别出这些关键实体：本体信息、命名实体识别、spaCy和flair library。随后，它采用选择性知识遮罩来有效训练模型。值得注意的是，DSTEA只需要进行预训练，而无需将额外的知识直接注入DST模型中。这种方法产生了出色的效果。

    Dialogue State Tracking (DST) is critical for comprehensively interpreting user and system utterances, thereby forming the cornerstone of efficient dialogue systems. Despite past research efforts focused on enhancing DST performance through alterations to the model structure or integrating additional features like graph relations, they often require additional pre-training with external dialogue corpora. In this study, we propose DSTEA, improving Dialogue State Tracking via Entity Adaptive pre-training, which can enhance the encoder through by intensively training key entities in dialogue utterances. DSTEA identifies these pivotal entities from input dialogues utilizing four different methods: ontology information, named-entity recognition, the spaCy, and the flair library. Subsequently, it employs selective knowledge masking to train the model effectively. Remarkably, DSTEA only requires pre-training without the direct infusion of extra knowledge into the DST model. This approach resu
    
[^72]: LAnoBERT: 基于BERT掩码语言模型的系统日志异常检测方法

    LAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model. (arXiv:2111.09564v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.09564](http://arxiv.org/abs/2111.09564)

    我们提出了一种名为LAnoBERT的无解析器系统日志异常检测方法，它使用了BERT模型进行掩码语言建模，从而实现了无人工干预的高效异常检测。

    

    计算机系统中生成的系统日志指的是大规模同时收集的数据，用作确定错误、入侵和异常行为的基础数据。系统日志异常检测的目标是及时识别异常，同时最小化人工干预，这是行业中的一个关键问题。先前的研究通过将各种形式的日志数据转换为标准化模板，使用解析器进行算法进行异常检测。特别是，应预先定义与特定事件对应的模板，以便所有日志数据使用该模板，其中日志关键信息可能会丢失。在本研究中，我们提出了一种名为LAnoBERT的无解析器系统日志异常检测方法，该方法使用了BERT模型，具有出色的自然语言处理性能。所提出的方法LAnoBERT通过掩码语言建模进行模型学习，进而进行无监督的异常检测。

    The system log generated in a computer system refers to large-scale data that are collected simultaneously and used as the basic data for determining errors, intrusion and abnormal behaviors. The aim of system log anomaly detection is to promptly identify anomalies while minimizing human intervention, which is a critical problem in the industry. Previous studies performed anomaly detection through algorithms after converting various forms of log data into a standardized template using a parser. Particularly, a template corresponding to a specific event should be defined in advance for all the log data using which the information within the log key may get lost. In this study, we propose LAnoBERT, a parser free system log anomaly detection method that uses the BERT model, exhibiting excellent natural language processing performance. The proposed method, LAnoBERT, learns the model through masked language modeling, which is a BERT-based pre-training method, and proceeds with unsupervised 
    
[^73]: SparseGAN: 稀疏生成对抗网络用于文本生成

    SparseGAN: Sparse Generative Adversarial Network for Text Generation. (arXiv:2103.11578v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2103.11578](http://arxiv.org/abs/2103.11578)

    SparseGAN是一种稀疏生成对抗网络，通过生成语义可解释且稀疏的句子表示作为输入，实现了在生成对抗网络框架下的神经文本生成模型的学习。通过使用稀疏编码的思想，SparseGAN有效地减少了噪音并实现了完全可微分的训练过程。实验证明SparseGAN在多个文本生成数据集上取得了性能的提升，特别是在序列生成任务中。

    

    在生成对抗网络（GAN）的框架下，学习神经文本生成模型仍然是一个具有挑战性的任务，因为整个训练过程不可微分。现有的训练策略要么受到不可靠的梯度估计的困扰，要么存在不准确的句子表示。受到稀疏编码原理的启发，我们提出了一种称为SparseGAN的方法，该方法生成语义可解释且稀疏的句子表示作为鉴别器的输入。关键思想是将嵌入矩阵视为一个超完备的词典，并使用极少数的选定词嵌入的线性组合来逼近生成器在每个时间步的输出特征表示。通过这样的语义丰富表示，我们不仅可以减少不必要的噪音以实现有效的对抗训练，还可以使整个训练过程完全可微分。在多个文本生成数据集上的实验证明了性能的提高，特别是在序列生成中。

    It is still a challenging task to learn a neural text generation model under the framework of generative adversarial networks (GANs) since the entire training process is not differentiable. The existing training strategies either suffer from unreliable gradient estimations or imprecise sentence representations. Inspired by the principle of sparse coding, we propose a SparseGAN that generates semantic-interpretable, but sparse sentence representations as inputs to the discriminator. The key idea is that we treat an embedding matrix as an over-complete dictionary, and use a linear combination of very few selected word embeddings to approximate the output feature representation of the generator at each time step. With such semantic-rich representations, we not only reduce unnecessary noises for efficient adversarial training, but also make the entire training process fully differentiable. Experiments on multiple text generation datasets yield performance improvements, especially in sequen
    
[^74]: XTQA: 教科书问答的跨句解释

    XTQA: Span-Level Explanations of the Textbook Question Answering. (arXiv:2011.12662v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2011.12662](http://arxiv.org/abs/2011.12662)

    XTQA是针对教科书问答任务提出的一种新架构，通过跨句解释提供答案和证据，显著提高了性能。

    

    教科书问答（TQA）是一个任务，要求在一个包含大量文章和图表的多模态背景下，回答一个图表/非图表问题。我们认为解释性应该将学生视为一个需要考虑的关键因素。为了解决这个问题，我们设计了一种新的架构，通过我们提出的从粗到细的算法，实现了对TQA的跨句解释（XTQA），该算法可以为学生提供不仅是答案，还包括用于选择答案的跨句证据。该算法首先使用TF-IDF方法粗略地选择与问题相关的前M个段落，然后从这些段落中的所有候选跨句中精细地选择前K个证据跨句，通过计算每个跨句对问题的信息增益。实验结果表明，与基线方法相比，XTQA显著提高了最先进的性能。源代码可在https://github.com/keep-smile-001/opentqa获取。

    Textbook Question Answering (TQA) is a task that one should answer a diagram/non-diagram question given a large multi-modal context consisting of abundant essays and diagrams. We argue that the explainability of this task should place students as a key aspect to be considered. To address this issue, we devise a novel architecture towards span-level eXplanations of the TQA (XTQA) based on our proposed coarse-to-fine grained algorithm, which can provide not only the answers but also the span-level evidences to choose them for students. This algorithm first coarsely chooses top $M$ paragraphs relevant to questions using the TF-IDF method, and then chooses top $K$ evidence spans finely from all candidate spans within these paragraphs by computing the information gain of each span to questions. Experimental results shows that XTQA significantly improves the state-of-the-art performance compared with baselines. The source code is available at https://github.com/keep-smile-001/opentqa
    
[^75]: 通过联合提取句子和关键词进行无监督摘要

    Unsupervised Summarization by Jointly Extracting Sentences and Keywords. (arXiv:2009.07481v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2009.07481](http://arxiv.org/abs/2009.07481)

    本论文提出了一种无监督的图排名模型RepRank，通过在统一的向量空间中计算单词、句子和单词到句子之间的距离，来提取多文档摘要中的突出句子和关键词。通过自注意力的学习方法，将句子表示为其词嵌入的加权和，能够更好地反映文档内容。实验证明，通过联合提取句子和关键词的过程可以相互增强，并且总是收敛到唯一的解，从而提高了性能。同时，采用吸收式随机游走的变体和基于采样的算法，可以避免冗余并增加多样性。

    

    我们提出了RepRank，这是一个无监督的基于图的排名模型，用于提取多文档摘要。通过在统一的向量空间中计算它们的向量表示之间的距离，可以估计单词、句子和单词到句子之间的相似度。为了获得理想的表示，我们提出了一种基于自注意力的学习方法，将句子表示为其词嵌入的加权和，权重集中在那些更好地反映文档内容的词上。我们证明了通过使用我们学习到的表示来联合提取突出的句子和关键词的过程可以相互增强，并证明了这个过程总是收敛到一个唯一的解，从而提高了性能。我们还描述了吸收式随机游走的变体和相应的基于采样的算法，以避免摘要中的冗余并增加多样性。在多个基准数据集上进行了实验

    We present RepRank, an unsupervised graph-based ranking model for extractive multi-document summarization in which the similarity between words, sentences, and word-to-sentence can be estimated by the distances between their vector representations in a unified vector space. In order to obtain desirable representations, we propose a self-attention based learning method that represent a sentence by the weighted sum of its word embeddings, and the weights are concentrated to those words hopefully better reflecting the content of a document. We show that salient sentences and keywords can be extracted in a joint and mutual reinforcement process using our learned representations, and prove that this process always converges to a unique solution leading to improvement in performance. A variant of absorbing random walk and the corresponding sampling-based algorithm are also described to avoid redundancy and increase diversity in the summaries. Experiment results with multiple benchmark datase
    
[^76]: 利用图神经网络和二阶推理改进指代消解

    Improving Coreference Resolution by Leveraging Entity-Centric Features with Graph Neural Networks and Second-order Inference. (arXiv:2009.04639v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2009.04639](http://arxiv.org/abs/2009.04639)

    该论文提出了一种基于图神经网络和二阶推理的指代消解方法，通过鼓励共享提及之间的特征，有效地捕捉实体为中心的信息，并提供了一个全局推理算法来最优地聚类提及。实验证明该方法的效果很好。

    

    指代消解中的主要挑战之一是如何利用在提及集群上定义的实体级特征，而不是提及对。然而，具有共同指代的提及通常在整个文本中分散，这使得整合实体级特征极其困难。我们提出了一种基于图神经网络的指代消解方法，通过鼓励在可能指向同一真实世界实体的所有提及之间共享特征来捕捉实体为中心的信息。通过边将提及彼此链接起来，建模两个链接提及指向相同实体的可能性。通过这样的图形建模，提及之间的特征可以通过实体为中心的信息传递操作进行共享。还提出了一种基于二阶特征的全局推理算法，将提及最优地聚类到一致的组中。实验结果显示，我们基于图神经网络的方法结合二阶特征的效果很好。

    One of the major challenges in coreference resolution is how to make use of entity-level features defined over clusters of mentions rather than mention pairs. However, coreferent mentions usually spread far apart in an entire text, which makes it extremely difficult to incorporate entity-level features. We propose a graph neural network-based coreference resolution method that can capture the entity-centric information by encouraging the sharing of features across all mentions that probably refer to the same real-world entity. Mentions are linked to each other via the edges modeling how likely two linked mentions point to the same entity. Modeling by such graphs, the features between mentions can be shared by message passing operations in an entity-centric manner. A global inference algorithm up to second-order features is also presented to optimally cluster mentions into consistent groups. Experimental results show our graph neural network-based method combing with the second-order de
    
[^77]: 注意力就是一切（arXiv:1706.03762v6 [cs.CL]已更新）

    Attention Is All You Need. (arXiv:1706.03762v6 [cs.CL] UPDATED)

    [http://arxiv.org/abs/1706.03762](http://arxiv.org/abs/1706.03762)

    Transformer是一种新的简单网络架构，完全基于注意力机制，取代了复杂的循环神经网络或卷积神经网络。实验证明Transformer在机器翻译任务中的质量更好、并行化效果更佳，且训练时间更短。它在英译德和英译法任务中取得了比其他模型更好的结果。

    

    目前主要的序列转换模型基于复杂的循环神经网络或卷积神经网络的编码器-解码器配置。表现最好的模型还通过注意力机制连接编码器和解码器。我们提出了一种新的简单网络架构，Transformer，完全基于注意力机制，不再使用循环和卷积。在两个机器翻译任务上的实验证明，这些模型在质量上优于其他模型，同时更易于并行化，训练时间显著减少。我们的模型在WMT 2014英译德任务上达到28.4的BLEU分数，比现有最好结果（包括集成模型）提高了2个BLEU分。在WMT 2014英译法任务上，在8个GPU上训练了3.5天后，我们的模型获得了41.8的单模型最新BLEU分数，训练成本仅为文献中最好模型的一小部分。我们展示了Transformer架构的优势，并证明了其在机器翻译任务中的重要贡献。

    The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transforme
    

