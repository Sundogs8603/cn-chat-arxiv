# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning from Models and Data for Visual Grounding](https://arxiv.org/abs/2403.13804) | 结合数据驱动学习和模型知识传递的新框架，通过优化一致性目标来增强预训练视觉和语言模型的视觉定位能力。 |
| [^2] | [ZigMa: Zigzag Mamba Diffusion Model](https://arxiv.org/abs/2403.13802) | 本研究提出了一种名为Zigzag Mamba的零参数方法，通过纠正当前Mamba-based视觉方法中对空间连续性的忽视，实现了更好的速度和内存利用，同时在大分辨率视觉数据集上展示了出色的性能。 |
| [^3] | [Natural Language as Polices: Reasoning for Coordinate-Level Embodied Control with LLMs](https://arxiv.org/abs/2403.13801) | 用自然语言推理进行坐标级控制，能够显著提高机器人行动规划的成功率，并且具有将机器人技能迁移到新任务的潜力。 |
| [^4] | [Reverse Training to Nurse the Reversal Curse](https://arxiv.org/abs/2403.13799) | 该研究提出了一种称为逆向训练的替代训练方案，通过在正向和逆向方向上训练语言模型并保留选定子串，成功解决了大型语言模型面临的逆转诅咒问题。 |
| [^5] | [Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts](https://arxiv.org/abs/2403.13786) | 该论文引入了“Chain-of-Interaction (CoI)”提示方法，通过二元交互情境来为精神决策支持上下文化大型语言模型(LLMs)，以解决精神治疗中缺乏领域专业知识和忽视患者-治疗师交互的挑战。 |
| [^6] | [Information-Theoretic Distillation for Reference-less Summarization](https://arxiv.org/abs/2403.13780) | 提出了一种名为InfoSumm的框架，通过信息论目标实现了无参考摘要的精炼生成器 |
| [^7] | [Different Tokenization Schemes Lead to Comparable Performance in Spanish Number Agreement](https://arxiv.org/abs/2403.13754) | 不同的分词方案在西班牙语数词一致性中表现相似，结果表明词形对齐的分词是一种可行的分词方法，但并非对性能绝对必要。 |
| [^8] | [EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation](https://arxiv.org/abs/2403.13737) | EthioLLM为埃塞俄比亚五种语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）以及英语引入了多语言大型语言模型，并提出了一个新的基准数据集Ethiobenchmark，为各种下游自然语言处理任务评估了这些模型的性能。 |
| [^9] | [PARAMANU-AYN: An Efficient Novel Generative and Instruction-tuned Language Model for Indian Legal Case Documents](https://arxiv.org/abs/2403.13681) | PARAMANU-AYN是一种基于印度法律案例文件的高效生成式语言模型，采用自回归解码器进行预训练，并经过面向指令的微调，在各种法律任务上取得了良好表现。 |
| [^10] | [RoleInteract: Evaluating the Social Interaction of Role-Playing Agents](https://arxiv.org/abs/2403.13679) | 该论文介绍了RoleInteract，一个旨在评估角色扮演对话代理社交性的基准，覆盖了500个角色、6000多个问题提示和30800个对话话语。 |
| [^11] | [Grounding Spatial Relations in Text-Only Language Models](https://arxiv.org/abs/2403.13666) | 纯文本语言模型可以通过提供对象位置信息并经过适当训练来学习落实空间关系，这可以通过预训练LM在合成数据集上显著改善结果。 |
| [^12] | [Do Not Worry if You Do Not Have Data: Building Pretrained Language Models Using Translationese](https://arxiv.org/abs/2403.13638) | 本文探讨了使用Translationese合成数据作为预训练语言模型的实用性，展示了在英语以外的语言中使用机器翻译创建的合成数据进行LMs预训练的有效性，并提出了通过使用轻量级TinyLMs预训练来过滤合成数据的方法。 |
| [^13] | [Llama meets EU: Investigating the European Political Spectrum through the Lens of LLMs](https://arxiv.org/abs/2403.13592) | 通过调整LLama Chat模型来重新评估其在欧盟政治中的政治倾向，展示了其对国家政党立场的充分了解，并能在上下文中进行有效推理，为将基于对话的LLM用于政治科学研究提供了新的可能性。 |
| [^14] | [Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models](https://arxiv.org/abs/2403.13590) | 本论文提出了一种教师-学生培训方法，通过在推理时将高计算成本的去偏见老师模型的能力蒸馏到更紧凑的学生模型中，来解决大型语言模型在保持特定任务不变性时的低效率问题。 |
| [^15] | [Genetic Auto-prompt Learning for Pre-trained Code Intelligence Language Models](https://arxiv.org/abs/2403.13588) | 提出了一种基于遗传算法的自动设计提示方法，解决了预训练代码智能语言模型中需要人工设计提示的问题。 |
| [^16] | [CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing](https://arxiv.org/abs/2403.13583) | CONLINE框架提出了通过在线搜索和正确性测试来增强复杂代码生成的方法，通过实验证明了其显著提高了代码生成质量。 |
| [^17] | [Dynamic Reward Adjustment in Multi-Reward Reinforcement Learning for Counselor Reflection Generation](https://arxiv.org/abs/2403.13578) | 本文研究了多重奖励强化学习在辅导员反思生成中的应用，引入了两种新的赌博方法DynOpt和C-DynaOpt，动态调整多个奖励权重，通过实验表明这些方法能够优于现有的基线方法。 |
| [^18] | [eRST: A Signaled Graph Theory of Discourse Relations and Organization](https://arxiv.org/abs/2403.13560) | 提出了增强修辞结构理论（eRST），这是一个基于修辞结构理论（RST）拓展的计算话语分析的新理论框架，解决了RST和其他现有框架存在的问题，并提供了相关工具和英文语料库。 |
| [^19] | [What explains the success of cross-modal fine-tuning with ORCA?](https://arxiv.org/abs/2403.13537) | 通过一系列消融实验，确定了ORCA中嵌入器训练对2D任务无帮助、1D任务需要适量嵌入器训练、以及模型微调对性能影响最大的结论。 |
| [^20] | [Motion Generation from Fine-grained Textual Descriptions](https://arxiv.org/abs/2403.13518) | 本文提出了一种从细粒度文本描述中生成运动的方法，构建了FineHumanML3D数据集，设计了FineMotionDiffuse模型，实验结果表明该模型表现出色。 |
| [^21] | [How Gender Interacts with Political Values: A Case Study on Czech BERT Models](https://arxiv.org/abs/2403.13514) | 捷克BERT模型案例研究发现，BERT大小的模型并不体现出与政治价值观的系统对齐，模型中观察到的偏见更多是由表面模仿引起的。 |
| [^22] | [What if...?: Counterfactual Inception to Mitigate Hallucination Effects in Large Multimodal Models](https://arxiv.org/abs/2403.13513) | 本文引入了反事实启示（Counterfactual Inception）方法，通过将反事实思想植入到大型多模态模型（LMMs）中，可以减轻幻觉效应并提高模型的可信度。 |
| [^23] | [An Entropy-based Text Watermarking Detection Method](https://arxiv.org/abs/2403.13485) | 提出了一种基于熵的水印检测方法，在检测过程中根据令牌的熵调整其权重，以更好地反映水印程度，该方法在大型语言模型中具有应用潜力。 |
| [^24] | [HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal Large Language Models](https://arxiv.org/abs/2403.13447) | HyperLLaVA通过引入自适应调整的投影仪和LLM参数，以及动态的视觉专家和语言专家，从而弥补了静态调整策略在不同下游多模态任务上性能受限的不足。 |
| [^25] | [Agent Group Chat: An Interactive Group Chat Simulacra For Better Eliciting Collective Emergent Behavior](https://arxiv.org/abs/2403.13433) | 通过Agent Group Chat模拟，研究了语言在人类集体行为中的作用，发现在不同故事情节下，代理人表现出了意料之外且重要的新兴行为，通过调整环境设置可以评估代理人是否展现出与人类期望一致的行为。 |
| [^26] | [LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://arxiv.org/abs/2403.13372) | LlamaFactory是一个统一框架，整合了一系列前沿的高效训练方法，使用户能够在不需要编码的情况下灵活定制100多种LLMs的微调。 |
| [^27] | [Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting](https://arxiv.org/abs/2403.13369) | 使用预训练语言模型和提示技术，在少资源语言情境下，仅需少量样本训练即可提取临床信息，且表现优于传统方法。 |
| [^28] | [Computational Models to Study Language Processing in the Human Brain: A Survey](https://arxiv.org/abs/2403.13368) | 当前语言模型表现出人类化或超越人类的语言能力，研究发现没有一个单一模型在所有数据集上表现优于其他模型，强调了用于涉及计算模型的研究中绘制健壮结论的需要。 |
| [^29] | [Incentivizing News Consumption on Social Media Platforms Using Large Language Models and Realistic Bot Accounts](https://arxiv.org/abs/2403.13362) | 通过创建使用 GPT-2 的机器人账户，在社交媒体平台上回复用户的推文，鼓励用户接触和关注验证的、意识形态平衡的新闻，以增加用户接触这些新闻并提高参与度。 |
| [^30] | [USE: Dynamic User Modeling with Stateful Sequence Models](https://arxiv.org/abs/2403.13344) | 引入了User Stateful Embedding（USE）来解决动态用户建模中存在的挑战，通过存储先前模型状态，生成用户嵌入并反映用户不断发展的行为。 |
| [^31] | [Hyacinth6B: A large language model for Traditional Chinese](https://arxiv.org/abs/2403.13334) | 为了解决大型语言模型通常存在的高硬件和计算需求，Hyacinth6B在模型轻量化和性能之间找到了平衡，采用LoRA方法进行参数高效微调。 |
| [^32] | [Polaris: A Safety-focused LLM Constellation Architecture for Healthcare](https://arxiv.org/abs/2403.13313) | Polaris是面向医疗保健的首个以安全为重点的LLM星座架构，利用多亿参数的合作代理进行长时间多轮语音对话，通过优化代理的迭代协同训练实现多样化目标的最大化。 |
| [^33] | [LeanReasoner: Boosting Complex Logical Reasoning with Lean](https://arxiv.org/abs/2403.13312) | 使用Lean框架解决大语言模型在复杂逻辑推理中的困难，实现了最先进性能并在少量样本上微调。 |
| [^34] | [Reading Users' Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference](https://arxiv.org/abs/2403.13301) | 本论文研究了使用大型语言模型（LLMs）进行心智推断任务，特别是推断用户的潜在目标和基本心理需求（FPNs），并提出了一种衡量LLMs心理推理性能的共情准确度指标。 |
| [^35] | [Community Needs and Assets: A Computational Analysis of Community Conversations](https://arxiv.org/abs/2403.13272) | 本研究引入了一项任务，即利用复杂的自然语言处理方法从对话数据中识别、提取和分类社区需求与资产，同时介绍了第一个关于社区需求和资产的数据集。 |
| [^36] | [AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models](https://arxiv.org/abs/2403.13269) | AFLoRA是一种自适应冻结低秩调整方法，通过逐步冻结投影矩阵来提高性能，减少计算量，并提供对GLUE基准测试的最先进表现。 |
| [^37] | [Arcee's MergeKit: A Toolkit for Merging Large Language Models](https://arxiv.org/abs/2403.13257) | 合并不同语言模型的参数，无需额外训练即可创建多任务模型，提升模型性能和多功能性，解决AI中的复杂挑战。 |
| [^38] | [Document Author Classification Using Parsed Language Structure](https://arxiv.org/abs/2403.13253) | 本文研究了使用解析语言结构来检测文档作者身份的新方法，通过统计自然语言解析器提取的语法结构信息进行了实证验证。 |
| [^39] | [Facilitating Pornographic Text Detection for Open-Domain Dialogue Systems via Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2403.13250) | 通过知识蒸馏大型语言模型来标注数据集，以便检测开放域对话系统中的色情文本。 |
| [^40] | [Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model](https://arxiv.org/abs/2403.13244) | 介绍了一个多约束分子生成大型语言模型TSMMG，通过整合多个小模型和工具来帮助生成符合描述的新分子，在各种约束任务中表现优秀。 |
| [^41] | [SumTra: A Differentiable Pipeline for Few-Shot Cross-Lingual Summarization](https://arxiv.org/abs/2403.13240) | 本文提出了一种用于少样本跨语言摘要的可微分流水线，通过重新审视摘要和翻译流程，实现了零样本性能和端到端的可微优势。 |
| [^42] | [Technical Report: Competition Solution For BetterMixture](https://arxiv.org/abs/2403.13233) | 本文介绍了针对BetterMixture挑战的解决方案，采用数据去重、质量过滤和多样性选择等方法，最终获得第三名。Ke-Data-Juicer作为解决方案的基础，展现了其在处理和优化大型语言模型数据方面的强大能力。 |
| [^43] | [From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards](https://arxiv.org/abs/2403.13213) | 本文探讨了针对表现性伤害和服务质量伤害的羊驼2安全保障措施的有效性，并指出了大型语言模型在实用性和安全性之间的权衡关系。 |
| [^44] | [Wav2Gloss: Generating Interlinear Glossed Text from Speech](https://arxiv.org/abs/2403.13169) | Wav2Gloss提出了从语音中自动提取语言注释的任务，并引入了第一个数据集Fieldwork，分析表明预先训练的解码器有助于翻译和注释，并且端到端的系统效果较好。 |
| [^45] | [Self-generated Replay Memories for Continual Neural Machine Translation](https://arxiv.org/abs/2403.13130) | 提出了一种利用神经机器翻译系统的生成能力来构建自生成回放记忆的方法，可以有效解决持续学习过程中的灾难性遗忘问题。 |
| [^46] | [Encode Once and Decode in Parallel: Efficient Transformer Decoding](https://arxiv.org/abs/2403.13112) | 提出了一种新的编码器-解码器模型配置，称为prompt-in-decoder（PiD），可以一次编码输入并并行解码输出，在结构化输出和问答任务中取得高效率，避免了重复输入编码，大幅减少了解码器的内存占用。 |
| [^47] | [Towards Unsupervised Question Answering System with Multi-level Summarization for Legal Text](https://arxiv.org/abs/2403.13107) | 提出了一种无监督问答系统，通过多级总结法对法律文本进行处理，实现了F1分数的显著提升 |
| [^48] | [Knowing Your Nonlinearities: Shapley Interactions Reveal the Underlying Structure of Data](https://arxiv.org/abs/2403.13106) | 该论文使用Shapley Taylor互动指数（STII）分析了底层数据结构对各种模态、任务和架构中模型表征的影响，发现了语言模型和语音模型中的新颖现象，并展示了特征交互如何直观反映对象边界。 |
| [^49] | [Automatic Summarization of Doctor-Patient Encounter Dialogues Using Large Language Model through Prompt Tuning](https://arxiv.org/abs/2403.13089) | 本研究提出了一种使用生成式大型语言模型对医患对话进行总结的方法，并通过提示调整算法指导模型进行临床文本总结，实现了在临床基准数据集上表现最佳的性能。 |
| [^50] | [BiLoRA: A Bi-level Optimization Framework for Overfitting-Resilient Low-Rank Adaptation of Large Pre-trained Models](https://arxiv.org/abs/2403.13037) | BiLoRA提出了一种基于双层优化框架的减轻过拟合的微调方法，通过对低秩增量矩阵进行参数化和将训练分为不同的子集，降低了对单一数据集过拟合的风险。 |
| [^51] | [RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content](https://arxiv.org/abs/2403.13031) | RigorLLM提出了一种新颖的框架，旨在高效有效地调节LLMs的有害和不安全输入和输出，包括能量数据增强、最小-最大优化安全输入后缀，以及基于数据增强的鲁棒KNN与LLMs融合模型。 |
| [^52] | [AutoTRIZ: Artificial Ideation with TRIZ and Large Language Models](https://arxiv.org/abs/2403.13002) | 本文提出了AutoTRIZ，一种利用大型语言模型自动化和增强TRIZ方法的人工创意工具，为设计自动化和可解释创意提供了一种新颖方法。 |
| [^53] | [Duwak: Dual Watermarks in Large Language Models](https://arxiv.org/abs/2403.13000) | Duwak提出了一种在大型语言模型中嵌入双重秘密模式的水印技术，可以显著提高水印的效率和质量。 |
| [^54] | [Prompt Selection and Augmentation for Few Examples Code Generation in Large Language Model and its Application in Robotics Control](https://arxiv.org/abs/2403.12999) | 本文介绍了一个提示选择和增强算法，通过优化示例选择和增强，提高了大型语言模型在代码生成和机器人控制方面的性能。 |
| [^55] | [When SMILES have Language: Drug Classification using Text Classification Methods on Drug SMILES Strings](https://arxiv.org/abs/2403.12984) | 将药物SMILES字符串视为句子并利用文本分类方法进行药物分类，证实了通过简单的自然语言处理方法解决复杂问题的可能性 |
| [^56] | [C Analyzer : A Static Program Analysis Tool for C Programs](https://arxiv.org/abs/2403.12973) | 该项目使用抽象解释技术开发了C分析器，可以对C程序进行静态分析，支持多个抽象域，提高程序验证的精度。 |
| [^57] | [m&m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks](https://arxiv.org/abs/2403.11085) | m&m's引入了一个包含4K+多步骤多模态任务的基准，涉及33种工具，用于评估LLM作为规划器的设计决策。 |
| [^58] | [MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations](https://arxiv.org/abs/2403.10943) | MIntRec2.0介绍了一个旨在解决多模态意图识别和对话中场外检测挑战的大规模基准数据集。该数据集包含30个细粒度类别的1,245个对话和15,040个样本，其中包括逼真的场外样本，并丰富了发言者信息以支持多方对话研究。 |
| [^59] | [Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation](https://arxiv.org/abs/2403.09738) | 大型语言模型作为生成式用户模拟器在对话推荐中展现出潜力，新的协议通过五个任务评估了语言模型模拟人类行为的准确程度，揭示了模型与人类行为的偏差，并提出了如何通过模型选择和提示策略减少这些偏差。 |
| [^60] | [SemEval-2024 Shared Task 6: SHROOM, a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes](https://arxiv.org/abs/2403.07726) | 本文介绍了SHROOM共享任务，重点关注检测幻觉，以及参与者使用的模型和策略。 |
| [^61] | [Large, Small or Both: A Novel Data Augmentation Framework Based on Language Models for Debiasing Opinion Summarization](https://arxiv.org/abs/2403.07693) | 使用大型和小型语言模型的新型数据增强框架，通过重新生成评论来实现观点摘要的去偏见化，避免了大型语言模型数据增强可能存在的问题和高昂成本。 |
| [^62] | [The Power of Noise: Toward a Unified Multi-modal Knowledge Graph Representation Framework](https://arxiv.org/abs/2403.06832) | 提出了一种利用噪声掩模的Transformer-based架构SNAG方法，实现了多模态知识图表示中实体嵌入的最先进性能 |
| [^63] | [Designing Informative Metrics for Few-Shot Example Selection](https://arxiv.org/abs/2403.03861) | 提出了一种基于复杂度的提示选择方法，用于将示例与测试句子的句法-语义复杂度对齐，在少样本NER任务中取得了显著的性能提升。 |
| [^64] | [In Search of Truth: An Interrogation Approach to Hallucination Detection](https://arxiv.org/abs/2403.02889) | 提出了一种用于在大型语言模型中检测幻觉的新方法，解决了这些模型在各种现实场景中应用时遇到的关键问题，通过对多个数据集和LLMs进行广泛评估，展示了该方法的有效性。 |
| [^65] | [Mitigating Reversal Curse via Semantic-aware Permutation Training](https://arxiv.org/abs/2403.00758) | 逆转诅咒问题是导致因果语言模型无法进行双向推理的根本原因之一，在这篇论文中，我们提出了通过语义感知的置换训练来缓解这一问题。 |
| [^66] | [AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning](https://arxiv.org/abs/2402.15506) | AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。 |
| [^67] | [Enhancing Amharic-LLaMA: Integrating Task Specific and Generative Datasets](https://arxiv.org/abs/2402.08015) | 本研究通过整合任务特定和生成数据集来增强Amharic-LLaMA模型，提高了阿姆哈拉语言模型的性能。他们通过创建阿姆哈拉语指令微调数据集和微调模型，在不同的NLP任务中取得了有希望的结果。 |
| [^68] | [Over-Reasoning and Redundant Calculation of Large Language Models](https://arxiv.org/abs/2401.11467) | 本文研究表明，大型语言模型在回答问题时倾向于生成冗余的计算和推理，即使这些计算并不必要。 |
| [^69] | [PsyChat: A Client-Centric Dialogue System for Mental Health Support](https://arxiv.org/abs/2312.04262) | PsyChat 提出了一个面向客户的对话系统，通过识别客户行为并结合辅导员策略，在线提供心理支持，弥补了现有心理健康支持中对话系统忽视客户行为的不足。 |
| [^70] | [Calibrated Language Models Must Hallucinate](https://arxiv.org/abs/2311.14648) | 该研究揭示了预训练语言模型在生成某些类型的事实时具有固有的统计下限，这与变压器LM架构或数据质量无关。 |
| [^71] | [LLatrieval: LLM-Verified Retrieval for Verifiable Generation](https://arxiv.org/abs/2311.07838) | 可验证生成中检索的文件不仅帮助LLM生成正确答案，还作为用户验证LLM输出的证据，但目前广泛使用的检索器已成为性能瓶颈，需要解决。 |
| [^72] | [AutoMix: Automatically Mixing Language Models](https://arxiv.org/abs/2310.12963) | AutoMix提出了一种自动选择更大语言模型处理查询的方法，通过少量样本自我验证和元验证器提高了输出的可靠性，可显著提高计算成本和性能的优化，实验证明性能优于基线最多86%. |
| [^73] | [The ParlaSent Multilingual Training Dataset for Sentiment Identification in Parliamentary Proceedings](https://arxiv.org/abs/2309.09783) | 该研究介绍了ParlaSent多语种训练数据集，以及首个专门针对政治科学应用的领域特定多语种变压器语言模型，通过在议会数据上进行预训练，显著提高了情感识别模型在议会会议中的性能。 |
| [^74] | [Exploring semantic information in disease: Simple Data Augmentation Techniques for Chinese Disease Normalization](https://arxiv.org/abs/2306.01931) | 提出了一组定制的数据增强技术，旨在利用疾病名称中的语义信息，增强模型对疾病名称的语义细微差别和分类结构的理解 |
| [^75] | [SDA: Simple Discrete Augmentation for Contrastive Sentence Representation Learning](https://arxiv.org/abs/2210.03963) | 提出了三种简单而有效的离散句子增强方案：标点插入、情态动词和双重否定，用于对比句子表示学习。 |
| [^76] | [Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions](https://arxiv.org/abs/2205.00415) | 基准数据集中存在的指令偏见可能导致对模型性能的高估，模型泛化能力受到影响。 |
| [^77] | [BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction.](http://arxiv.org/abs/2401.14166) | BayesPrompt通过无偏领域抽象解决大规模预训练语言模型在少样本推理中的泛化问题。 |
| [^78] | [AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on Large Language Models.](http://arxiv.org/abs/2401.09002) | 本研究提出一种新方法评估大型语言模型上越狱攻击效果，引入粗粒度和细粒度评估框架，提供了更全面和细致的评估角度，并开发了专门的真实数据集作为基准，为未来研究建立了基础资源。 |
| [^79] | [Token-free LLMs Can Generate Chinese Classical Poetry with More Accurate Format.](http://arxiv.org/abs/2401.03512) | 本文提出了一种无需分词的大型语言模型（LLMs）来生成中国古典诗词，并解决了格式不准确性的问题。验证了现有基于分词的模型在字符和分词之间的关系方面的知识有限，并展示了如何通过定制模型解决这一问题。 |
| [^80] | [General-Purpose Retrieval-Enhanced Medical Prediction Model Using Near-Infinite History.](http://arxiv.org/abs/2310.20204) | 基于电子健康记录，我们提出了一种称为REMed的检索增强医学预测模型，通过无限评估临床事件并自动选择相关事件进行预测，消除了人工特征选择和观察窗口的限制，并在实验中表现出优异的效果。 |
| [^81] | [The Expresssive Power of Transformers with Chain of Thought.](http://arxiv.org/abs/2310.07923) | 本论文研究基于思维链的Transformer的表达能力，通过允许使用中间生成的方式提高了Transformer的推理能力，并发现线性数量的解码步骤在标准计算复杂度下增加了明显的新能力。 |
| [^82] | [BooookScore: A systematic exploration of book-length summarization in the era of LLMs.](http://arxiv.org/abs/2310.00785) | 本文对LLM模型进行了系统探索，以解决对超过上下文窗口大小的书籍进行摘要的问题，并通过两种提示工作流实施了基于LLM的书籍长度摘要器的连贯性研究。通过对100本书的GPT-4生成摘要的人工注释，发现了八种常见的连贯性错误。 |
| [^83] | [ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education.](http://arxiv.org/abs/2309.13243) | 这项研究介绍了ChEDDAR，一个在EFL写作教育中应用的学生-ChatGPT对话数据集。该研究分析了学生对生成型AI的使用模式和感知，并为教育背景下的任务导向对话系统建立了基准结果。 |
| [^84] | [Unimodal Aggregation for CTC-based Speech Recognition.](http://arxiv.org/abs/2309.08150) | 本文提出了一种在CTC-based语音识别中用于学习更好的特征表示和缩短序列长度的单模聚合方法(UMA)，通过分割和集成同一文本标记的特征帧，实现了更低的识别错误和计算复杂度。实验证明，UMA在普通话数据集上表现出较好的性能，并且通过集成自条件CTC可以进一步提高性能。 |
| [^85] | [MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning.](http://arxiv.org/abs/2309.07915) | MMICL提出了一种用于视觉-语言模型的架构和训练数据设计，以解决VLM在理解复杂多模态提示方面的困难。 |
| [^86] | [Can Whisper perform speech-based in-context learning.](http://arxiv.org/abs/2309.07081) | 本文研究了Whisper自动语音识别模型的语境学习能力，并提出了一种基于语境的语音学习方法，用于在测试时适应。通过实验验证了该方法在中文方言上的有效性，可以显著减少单词错误率。通过进一步优化选择技术可以进一步提高效率。 |
| [^87] | [Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models.](http://arxiv.org/abs/2309.04461) | 本研究探索了视觉-语言模型展示人类推理能力的能力，并提出了一种基于思维链的一致性度量。通过一个流水线和已有数据集，建立了一个基准来测量这种推理能力。 |
| [^88] | [HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models.](http://arxiv.org/abs/2309.02706) | HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。 |
| [^89] | [Enhancing Phrase Representation by Information Bottleneck Guided Text Diffusion Process for Keyphrase Extraction.](http://arxiv.org/abs/2308.08739) | 本研究提出了一种利用信息瓶颈引导的文本扩散过程来增强短语表示的关键词提取方法。该方法充分利用关键词信息，通过优化排名网络和变分信息瓶颈来提高关键词提取的效果。 |
| [^90] | [Advancing Beyond Identification: Multi-bit Watermark for Language Models.](http://arxiv.org/abs/2308.00221) | 本研究提出了一种用于语言模型的多位水印技术——COLOR，可在语言模型生成过程中嵌入可追踪的多位信息，实现了提取水印、即时嵌入和维持文本质量等功能，同时允许零位检测。初步实验显示成功在中等长度的文本中嵌入了32位消息，准确率为91.9％。这项研究有效推进了对语言模型滥用的反制策略。 |
| [^91] | [Beyond the Obvious: Evaluating the Reasoning Ability In Real-life Scenarios of Language Models on Life Scapes Reasoning Benchmark~(LSR-Benchmark).](http://arxiv.org/abs/2307.05113) | 本论文介绍了一个新的数据集LSR-Benchmark，旨在评估语言模型在真实情境中的推理能力。结果显示，人类在这方面表现明显优于最先进的语言模型，说明机器学习模型在理解日常生活方面仍面临挑战。 |
| [^92] | [Progressive Multi-task Learning Framework for Chinese Text Error Correction.](http://arxiv.org/abs/2306.17447) | 我们提出了一种面向中文文本错误校正的渐进式多任务学习框架ProTEC，该框架通过引导模型从易到难地学习错误检测、错误类型识别和校正结果生成，以解决过纠正的问题。 |
| [^93] | [Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning.](http://arxiv.org/abs/2306.14565) | 本论文通过引入第一个大型多样化的视觉指令调整数据集，提出了一种解决大规模多模态模型中幻觉问题的方法。通过设计包含正负指令的数据集和提出的评估方法，能够更准确地衡量模型产生的幻觉。 |
| [^94] | [Generative Multimodal Entity Linking.](http://arxiv.org/abs/2306.12725) | 本文提出了 GEMEL 方法，使用大规模预训练的 LLMs 直接生成目标实体名称，仅调整了极少的模型参数即可实现最先进的 MEL 实验结果。 |
| [^95] | [Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking.](http://arxiv.org/abs/2306.12245) | BEER^2是一种用于Retriever和Reader的双向端到端训练框架，通过检索器和阅读器之间的相互学习，共同进步，实现端到端EL。 |
| [^96] | [Do Language Models Know When They're Hallucinating References?.](http://arxiv.org/abs/2305.18248) | 本研究针对大型语言模型中的“幻觉”参考文献进行了研究，通过简单的搜索引擎查询可可靠地识别这些幻觉。并且通过对同一语言模型进行黑盒查询来进行分类，揭示了幻觉参考文献的性质。 |
| [^97] | [Having Beer after Prayer? Measuring Cultural Bias in Large Language Models.](http://arxiv.org/abs/2305.14456) | 这篇论文研究了大型语言模型在处理和生成阿拉伯文本时出现的文化偏向西方文化的现象，表明语言模型在人名、食品、服装、地点、文学、饮料、宗教和体育等八个文化方面存在偏见。这些发现引发对于当前语言模型文化相关性的担忧。 |
| [^98] | [PaD: Program-aided Distillation Specializes Large Models in Reasoning.](http://arxiv.org/abs/2305.13888) | 本文提出了一种程序辅助蒸馏（PaD）技术，它可以蒸馏大型语言模型（LLMs）以在推理任务中获得专业化的小模型。PaD使用程序辅助推理加强专业化模型，并通过自动化错误检查来帮助它们克服错误的推理步骤。 |
| [^99] | [Weight-Inherited Distillation for Task-Agnostic BERT Compression.](http://arxiv.org/abs/2305.09098) | 本文提出了一种直接从教师模型传递知识的权重继承蒸馏方法，不需要额外的对齐损失就可以训练出一个紧凑的学生模型，并且在GLUE和SQuAD基准测试上优于之前最先进的基于KD的基线。 |
| [^100] | [EmotionIC: Emotional Inertia and Contagion-driven Dependency Modelling for Emotion Recognition in Conversation.](http://arxiv.org/abs/2303.11117) | 本文提出了一种新的依赖性建模方法，由情感惯性和感染驱动（EmotionIC），用于在特征提取和分类级别上进行会话情感识别。设计了多项具体方法，包括身份掩码多头注意（IM-MHA）和基于对话门控循环单元(DialogGRU)，以抓取上下文信息，提高模型的性能。 |

# 详细

[^1]: 从模型和数据中学习进行视觉定位

    Learning from Models and Data for Visual Grounding

    [https://arxiv.org/abs/2403.13804](https://arxiv.org/abs/2403.13804)

    结合数据驱动学习和模型知识传递的新框架，通过优化一致性目标来增强预训练视觉和语言模型的视觉定位能力。

    

    我们介绍了SynGround，这是一个结合了数据驱动学习和从各种大规模预训练模型中进行知识传递的新型框架，以增强预训练视觉和语言模型的视觉定位能力。从模型中进行的知识传递引发了通过图像描述生成器生成图像描述。这些描述具有双重作用：它们作为文本到图像生成器合成图像的提示，以及作为查询来合成文本，从其中使用大型语言模型提取短语。最后，我们利用一个开放词汇的对象检测器为合成图像和文本生成合成边界框。通过优化一个遮罩-注意力一致性目标，在这个数据集上微调预训练的视觉和语言模型，该目标将区域注释与基于梯度的模型解释进行对齐。最终的模型提升了定位能力。

    arXiv:2403.13804v1 Announce Type: cross  Abstract: We introduce SynGround, a novel framework that combines data-driven learning and knowledge transfer from various large-scale pretrained models to enhance the visual grounding capabilities of a pretrained vision-and-language model. The knowledge transfer from the models initiates the generation of image descriptions through an image description generator. These descriptions serve dual purposes: they act as prompts for synthesizing images through a text-to-image generator, and as queries for synthesizing text, from which phrases are extracted using a large language model. Finally, we leverage an open-vocabulary object detector to generate synthetic bounding boxes for the synthetic images and texts. We finetune a pretrained vision-and-language model on this dataset by optimizing a mask-attention consistency objective that aligns region annotations with gradient-based model explanations. The resulting model improves the grounding capabilit
    
[^2]: ZigMa：蜿蜒曼巴扩散模型

    ZigMa: Zigzag Mamba Diffusion Model

    [https://arxiv.org/abs/2403.13802](https://arxiv.org/abs/2403.13802)

    本研究提出了一种名为Zigzag Mamba的零参数方法，通过纠正当前Mamba-based视觉方法中对空间连续性的忽视，实现了更好的速度和内存利用，同时在大分辨率视觉数据集上展示了出色的性能。

    

    扩散模型长期以来一直受到可伸缩性和二次复杂性问题的困扰，特别是在基于变压器的结构内部。在这项研究中，我们旨在利用一种称为曼巴的状态空间模型的长序列建模能力，以扩展其在视觉数据生成中的适用性。首先，我们确定了大多数当前基于曼巴的视觉方法中的一个关键疏忽，即曼巴的扫描方案中缺乏对空间连续性的考虑。其次，基于这一洞察力，我们介绍了一种名为Zigzag Mamba的简单、即插即用、零参数方法，它优于基于曼巴的基线，并表现出比基于变压器的基线更快速和更好的内存利用。最后，我们将Zigzag Mamba集成到随机插值框架中，以研究模型在大分辨率视觉数据集（例如FacesHQ $1024\times 1024$和UCF101，MultiModal-CelebA-HQ）上的可伸缩性。

    arXiv:2403.13802v1 Announce Type: cross  Abstract: The diffusion model has long been plagued by scalability and quadratic complexity issues, especially within transformer-based structures. In this study, we aim to leverage the long sequence modeling capability of a State-Space Model called Mamba to extend its applicability to visual data generation. Firstly, we identify a critical oversight in most current Mamba-based vision methods, namely the lack of consideration for spatial continuity in the scan scheme of Mamba. Secondly, building upon this insight, we introduce a simple, plug-and-play, zero-parameter method named Zigzag Mamba, which outperforms Mamba-based baselines and demonstrates improved speed and memory utilization compared to transformer-based baselines. Lastly, we integrate Zigzag Mamba with the Stochastic Interpolant framework to investigate the scalability of the model on large-resolution visual datasets, such as FacesHQ $1024\times 1024$ and UCF101, MultiModal-CelebA-HQ
    
[^3]: 自然语言作为政策：与LLMs一起进行坐标级体态控制的推理

    Natural Language as Polices: Reasoning for Coordinate-Level Embodied Control with LLMs

    [https://arxiv.org/abs/2403.13801](https://arxiv.org/abs/2403.13801)

    用自然语言推理进行坐标级控制，能够显著提高机器人行动规划的成功率，并且具有将机器人技能迁移到新任务的潜力。

    

    我们展示了与LLMs一起解决机器人行动规划问题的实验结果。最近，LLMs已经应用于机器人行动规划，特别是使用代码生成方法将复杂的高级指令转换为中级策略代码。相比之下，我们的方法通过获取任务和场景对象的文本描述，通过自然语言推理制定行动规划，并输出坐标级控制命令，从而减少了作为政策的中间表示代码的必要性。我们的方法在多模态提示仿真基准上进行了评估，表明我们的自然语言推理实验显著提高了成功率，与缺席相比。此外，我们的方法展示了自然语言描述有潜力将机器人技能从已知任务转移到以前未见任务。

    arXiv:2403.13801v1 Announce Type: cross  Abstract: We demonstrate experimental results with LLMs that address robotics action planning problems. Recently, LLMs have been applied in robotics action planning, particularly using a code generation approach that converts complex high-level instructions into mid-level policy codes. In contrast, our approach acquires text descriptions of the task and scene objects, then formulates action planning through natural language reasoning, and outputs coordinate level control commands, thus reducing the necessity for intermediate representation code as policies. Our approach is evaluated on a multi-modal prompt simulation benchmark, demonstrating that our prompt engineering experiments with natural language reasoning significantly enhance success rates compared to its absence. Furthermore, our approach illustrates the potential for natural language descriptions to transfer robotics skills from known tasks to previously unseen tasks.
    
[^4]: 逆向训练以消除逆转诅咒

    Reverse Training to Nurse the Reversal Curse

    [https://arxiv.org/abs/2403.13799](https://arxiv.org/abs/2403.13799)

    该研究提出了一种称为逆向训练的替代训练方案，通过在正向和逆向方向上训练语言模型并保留选定子串，成功解决了大型语言模型面临的逆转诅咒问题。

    

    大型语言模型（LLMs）存在一个令人惊讶的失败现象：当训练模型以"A具有特征B"为基础时，它们无法泛化到"B是A的特征"，这被称为逆转诅咒。即使在使用数万亿令牌进行训练时，由于齐夫定律的存在，这个问题仍然存在，这意味着即使我们在整个互联网上进行训练，该问题仍然会出现。本研究提出了一种名为逆向训练的替代训练方案，在其中所有单词被使用两次，从而使可用令牌数量加倍。该LLM在正向和逆向方向上进行训练，通过颠倒训练字符串来颠倒训练过程，同时保留（即不颠倒）选定的子串，如实体。我们展示了数据匹配的逆向训练模型在标准任务上比标准模型表现更优秀，并且计算匹配的逆向训练模型在逆转任务上表现出远远优于标准模型的性能，有助于解决逆转诅咒问题。

    arXiv:2403.13799v1 Announce Type: new  Abstract: Large language models (LLMs) have a surprising failure: when trained on "A has a feature B", they do not generalize to "B is a feature of A", which is termed the Reversal Curse. Even when training with trillions of tokens this issue still appears due to Zipf's law - hence even if we train on the entire internet. This work proposes an alternative training scheme, called reverse training, whereby all words are used twice, doubling the amount of available tokens. The LLM is trained in both forward and reverse directions by reversing the training strings while preserving (i.e., not reversing) chosen substrings, such as entities. We show that data-matched reverse-trained models provide superior performance to standard models on standard tasks, and compute-matched reverse-trained models provide far superior performance on reversal tasks, helping resolve the reversal curse issue.
    
[^5]: Chain-of-Interaction: 通过二元交互背景增强用于精神行为理解的大型语言模型

    Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts

    [https://arxiv.org/abs/2403.13786](https://arxiv.org/abs/2403.13786)

    该论文引入了“Chain-of-Interaction (CoI)”提示方法，通过二元交互情境来为精神决策支持上下文化大型语言模型(LLMs)，以解决精神治疗中缺乏领域专业知识和忽视患者-治疗师交互的挑战。

    

    自动编码患者行为对于支持精神治疗师在激励性面谈（MI）期间做出决策至关重要，MI是一种协作沟通干预方法，用于解决精神问题，如酒精和药物成瘾。尽管行为编码任务已迅速借助机器学习来预测MI会话期间患者状态，但缺乏领域专业知识并忽视患者-治疗师交互是在实际实践中开发和部署这些模型面临的主要挑战。为了解决这些挑战，我们提出了Chain-of-Interaction (CoI)提示方法，旨在通过二元交互情境来为精神决策支持上下文化大型语言模型(LLMs)。CoI提示方法系统地将编码任务分解为三个关键推理步骤，提取患者参与度，学习治疗师提问策略，并整合二元交互。

    arXiv:2403.13786v1 Announce Type: new  Abstract: Automatic coding patient behaviors is essential to support decision making for psychotherapists during the motivational interviewing (MI), a collaborative communication intervention approach to address psychiatric issues, such as alcohol and drug addiction. While the behavior coding task has rapidly adapted machine learning to predict patient states during the MI sessions, lacking of domain-specific knowledge and overlooking patient-therapist interactions are major challenges in developing and deploying those models in real practice. To encounter those challenges, we introduce the Chain-of-Interaction (CoI) prompting method aiming to contextualize large language models (LLMs) for psychiatric decision support by the dyadic interactions. The CoI prompting approach systematically breaks down the coding task into three key reasoning steps, extract patient engagement, learn therapist question strategies, and integrates dyadic interactions bet
    
[^6]: 无参考摘要的信息论精炼

    Information-Theoretic Distillation for Reference-less Summarization

    [https://arxiv.org/abs/2403.13780](https://arxiv.org/abs/2403.13780)

    提出了一种名为InfoSumm的框架，通过信息论目标实现了无参考摘要的精炼生成器

    

    当前自动摘要的主要方法是使用专有的大规模语言模型（LLMs）如ChatGPT，或者从它们作为教师模型进行模仿学习。本文提出了一种名为InfoSumm的新型框架，通过信息论目标进行精炼强大的摘要生成器，而不依赖于LLM的能力或人工编写的参考文献。

    arXiv:2403.13780v1 Announce Type: new  Abstract: The current winning recipe for automatic summarization is using proprietary large-scale language models (LLMs) such as ChatGPT as is, or imitation learning from them as teacher models. While increasingly ubiquitous dependence on such large-scale language models is convenient, there remains an important question of whether small-scale models could have achieved competitive results, if we were to seek an alternative learning method -- that allows for a more cost-efficient, controllable, yet powerful summarizer. We present InfoSumm, a novel framework to distill a powerful summarizer based on the information-theoretic objective for summarization, without relying on either the LLM's capability or human-written references. To achieve this, we first propose a novel formulation of the desiderata of summarization (saliency, faithfulness and brevity) through the lens of mutual information between the original document and the summary. Based on thi
    
[^7]: 不同的分词方案在西班牙语数词一致性中表现相似

    Different Tokenization Schemes Lead to Comparable Performance in Spanish Number Agreement

    [https://arxiv.org/abs/2403.13754](https://arxiv.org/abs/2403.13754)

    不同的分词方案在西班牙语数词一致性中表现相似，结果表明词形对齐的分词是一种可行的分词方法，但并非对性能绝对必要。

    

    语言模型的分词和性能之间的关系是一个开放的研究领域。本文调查了不同分词方案对西班牙语复数一致性的影响。我们发现，在词形对齐的分词方案下，性能与其他分词方案类似，即使对于训练过程中不会以这种方式分词的词进行人工诱导。我们还展示了探索性分析结果，表明不同复数分词的语言模型嵌入在最大区分单数名词和复数名词的嵌入空间轴上具有相似的分布。我们的结果表明，词形对齐的分词是一种可行的分词方法，而现有模型已经将某些词形模式推广到新项目。然而，我们的结果表明，形态分词并非对性能绝对必要。

    arXiv:2403.13754v1 Announce Type: new  Abstract: The relationship between language model tokenization and performance is an open area of research. Here, we investigate how different tokenization schemes impact number agreement in Spanish plurals. We find that morphologically-aligned tokenization performs similarly to other tokenization schemes, even when induced artificially for words that would not be tokenized that way during training. We then present exploratory analyses demonstrating that language model embeddings for different plural tokenizations have similar distributions along the embedding space axis that maximally distinguishes singular and plural nouns. Our results suggest that morphologically-aligned tokenization is a viable tokenization approach, and existing models already generalize some morphological patterns to new items. However, our results indicate that morphological tokenization is not strictly required for performance.
    
[^8]: EthioLLM：用于埃塞俄比亚语言的多语言大型语言模型及任务评估

    EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation

    [https://arxiv.org/abs/2403.13737](https://arxiv.org/abs/2403.13737)

    EthioLLM为埃塞俄比亚五种语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）以及英语引入了多语言大型语言模型，并提出了一个新的基准数据集Ethiobenchmark，为各种下游自然语言处理任务评估了这些模型的性能。

    

    大型语言模型（LLMs）近来因其在各种下游自然语言处理（NLP）任务中的出色表现而备受青睐。然而，由于训练LLMs的资源不足，低资源语言仍落后于NLP领域的最新发展。埃塞俄比亚语言拥有显著的语言多样性，包括广泛的文字系统，并富有深远的宗教和文化意义。本文介绍了EthioLLM - 五种埃塞俄比亚语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）和英语的多语言大型语言模型，以及Ethiobenchmark - 用于各种下游NLP任务的新基准数据集。我们评估了这些模型在五个下游NLP任务中的性能。我们开源我们的多语言语言模型、各种下游任务的新基准数据集和任务特定的精调语言

    arXiv:2403.13737v1 Announce Type: new  Abstract: Large language models (LLMs) have gained popularity recently due to their outstanding performance in various downstream Natural Language Processing (NLP) tasks. However, low-resource languages are still lagging behind current state-of-the-art (SOTA) developments in the field of NLP due to insufficient resources to train LLMs. Ethiopian languages exhibit remarkable linguistic diversity, encompassing a wide array of scripts, and are imbued with profound religious and cultural significance. This paper introduces EthioLLM -- multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a new benchmark dataset for various downstream NLP tasks. We evaluate the performance of these models across five downstream NLP tasks. We open-source our multilingual language models, new benchmark datasets for various downstream tasks, and task-specific fine-tuned languag
    
[^9]: PARAMANU-AYN：一种有效的新型生成式、面向印度法律案例文件的语言模型

    PARAMANU-AYN: An Efficient Novel Generative and Instruction-tuned Language Model for Indian Legal Case Documents

    [https://arxiv.org/abs/2403.13681](https://arxiv.org/abs/2403.13681)

    PARAMANU-AYN是一种基于印度法律案例文件的高效生成式语言模型，采用自回归解码器进行预训练，并经过面向指令的微调，在各种法律任务上取得了良好表现。

    

    在这篇论文中，我们介绍了PARAMANU-AYN，这是一个仅基于印度最高法院案例文件、印度宪法和印度刑法的语言模型。这种新颖的基于自回归（AR）解码器的模型是从头开始在上下文大小为8192的情况下进行预训练的。我们在困惑度指标上评估了我们的预训练法律模型。我们还对一组包括各种法律任务（如法律推理、判决解释、法律条款生成、法律草拟、法律合同草拟、案件摘要、宪法问题回答等）的10,763条指令进行了针对性训练。我们还通过GPT-3.5-Turbo对面向指令的模型的提示响应进行了在10分制度上的清晰度、相关性、完整性和法律推理指标的评估。我们的模型可以在CPU上运行，并实现每秒42.46个令牌的CPU推理速度。

    arXiv:2403.13681v1 Announce Type: new  Abstract: In this paper, we present PARAMANU-AYN, a language model based exclusively on case documents of the Supreme Court of India, the Constitution of India, and the Indian Penal Code. The novel Auto Regressive (AR) decoder based model is pretrained from scratch at a context size of 8192. We evaluated our pretrained legal model on perplexity metrics. We also instruction-tuned our pretrained model on a set of 10,763 instructions covering various legal tasks such as legal reasoning, judgement explanation, legal clause generation, legal drafting, legal contract drafting, case summarization, constitutional question-answering, etc. We also evaluated the responses of prompts for instruction-tuned models by GPT-3.5-Turbo on clarity, relevance, completeness, and legal reasoning metrics in a scale of 10. Our model can be run on CPU and achieved 42.46 tokens/sec CPU inference speed. We found that our models, despite not being pretrained on legal books, v
    
[^10]: RoleInteract：评估角色扮演代理的社交互动

    RoleInteract: Evaluating the Social Interaction of Role-Playing Agents

    [https://arxiv.org/abs/2403.13679](https://arxiv.org/abs/2403.13679)

    该论文介绍了RoleInteract，一个旨在评估角色扮演对话代理社交性的基准，覆盖了500个角色、6000多个问题提示和30800个对话话语。

    

    大型语言模型（LLMs）推动了各种AI对话代理的发展，包括模仿不同角色和人类行为的角色扮演对话代理。本文引入了RoleInteract，这是第一个旨在系统评估角色扮演对话代理在社交方面表现的基准。该基准从各种来源构建，涵盖了超过500个角色、6000多个问题提示和30800个多轮角色扮演话语。

    arXiv:2403.13679v1 Announce Type: new  Abstract: Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing conversational agents that mimic diverse characters and human behaviors. While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge, and stylistic attributes of these agents, there has been a noticeable gap in assessing their social intelligence. In this paper, we introduce RoleInteract, the first benchmark designed to systematically evaluate the sociality of role-playing conversational agents at both individual and group levels of social interactions. The benchmark is constructed from a variety of sources and covers a wide range of 500 characters and over 6,000 question prompts and 30,800 multi-turn role-playing utterances. We conduct comprehensive evaluations on this benchmark using mainstream open-source and closed-source LLMs. We find that agents excelling in in
    
[^11]: 在纯文本语言模型中落实空间关系

    Grounding Spatial Relations in Text-Only Language Models

    [https://arxiv.org/abs/2403.13666](https://arxiv.org/abs/2403.13666)

    纯文本语言模型可以通过提供对象位置信息并经过适当训练来学习落实空间关系，这可以通过预训练LM在合成数据集上显著改善结果。

    

    本文表明，如果为纯文本语言模型（LM）提供了对象的显式位置信息并进行了适当的训练以利用这些位置信息，它们就可以学习到像“左侧”或“下方”这样的空间关系。我们在一种口头化版本的视觉空间推理（VSR）数据集上进行了实验，在这个数据集中，图像与包含图像两个对象之间真假空间关系的文本陈述相结合。我们使用现成的物体检测器对图像进行口头描述，并在每个对象标签中添加位置标记，以代表它们的边界框的文本形式。鉴于VSR数据集规模较小，当使用位置信息时我们没有观察到任何改进，但是在由我们自动导出的一个合成数据集上对LM进行预训练可以显著改善结果。因此，我们表明位置信息使LM能够落实空间关系，我们的纯文本LM在性能上胜过了Vi。

    arXiv:2403.13666v1 Announce Type: new  Abstract: This paper shows that text-only Language Models (LM) can learn to ground spatial relations like "left of" or "below" if they are provided with explicit location information of objects and they are properly trained to leverage those locations. We perform experiments on a verbalized version of the Visual Spatial Reasoning (VSR) dataset, where images are coupled with textual statements which contain real or fake spatial relations between two objects of the image. We verbalize the images using an off-the-shelf object detector, adding location tokens to every object label to represent their bounding boxes in textual form. Given the small size of VSR, we do not observe any improvement when using locations, but pretraining the LM over a synthetic dataset automatically derived by us improves results significantly when using location tokens. We thus show that locations allow LMs to ground spatial relations, with our text-only LMs outperforming Vi
    
[^12]: 不必担心如果您没有数据：利用Translationese构建预训练语言模型

    Do Not Worry if You Do Not Have Data: Building Pretrained Language Models Using Translationese

    [https://arxiv.org/abs/2403.13638](https://arxiv.org/abs/2403.13638)

    本文探讨了使用Translationese合成数据作为预训练语言模型的实用性，展示了在英语以外的语言中使用机器翻译创建的合成数据进行LMs预训练的有效性，并提出了通过使用轻量级TinyLMs预训练来过滤合成数据的方法。

    

    在本文中，我们探讨了将机器翻译创建的合成数据Translationese用作预训练语言模型（LMs）的实用性。预训练需要大量的单语数据，对于英语以外的语言，这些数据大部分是不可用的。近年来，人们越来越关注使用合成数据来解决这种数据稀缺性问题。我们以英语和Indic语言为例，将网络抓取的单语文档（干净的）翻译成目标语言。然后，我们在这些Translationese数据（合成数据）上训练包含28M和85M参数的语言模型。我们展示了它们在下游自然语言理解和生成任务中的性能与在干净数据上预训练的LMs相比，NLU任务的性能仅差3.56％，NLG任务的差异为1.51％。此外，我们提出了使用在干净数据上预训练的轻量级TinyLMs来高效过滤合成数据的方法，这显著提高了性能。

    arXiv:2403.13638v1 Announce Type: new  Abstract: In this paper, we explore the utility of \textit{Translationese} as synthetic data created using machine translation for pre-training language models (LMs). Pre-training requires vast amounts of monolingual data, which is mostly unavailable for languages other than English. Recently, there has been a growing interest in using synthetic data to address this data scarcity. We take the case of English and Indic languages and translate web-crawled monolingual documents (clean) into the target language. Then, we train language models containing 28M and 85M parameters on this translationese data (synthetic). We show that their performance on downstream natural language understanding and generative tasks is only 3.56\% poorer on NLU tasks and 1.51\% on NLG tasks than LMs pre-trained on clean data. Further, we propose the use of lightweight \textit{TinyLMs} pre-trained on clean data to filter synthetic data efficiently which significantly improv
    
[^13]: 拉马遇上欧盟：通过LLMs探究欧洲政治光谱

    Llama meets EU: Investigating the European Political Spectrum through the Lens of LLMs

    [https://arxiv.org/abs/2403.13592](https://arxiv.org/abs/2403.13592)

    通过调整LLama Chat模型来重新评估其在欧盟政治中的政治倾向，展示了其对国家政党立场的充分了解，并能在上下文中进行有效推理，为将基于对话的LLM用于政治科学研究提供了新的可能性。

    

    arXiv:2403.13592v1 类型：新文章 摘要：细化指导的大型语言模型具有明显的政治倾向，已经被证明会影响下游任务的执行。我们将这一研究领域扩展到美国两党制以外，在不同环境中审计 Llama Chat，以分析该模型对欧盟政治的了解程度及其在上下文中推理的能力。我们适应，即进一步细化，Llama Chat 基于欧洲议会辩论中个别欧洲政党的演讲进行适应性调整，以根据EUandI问卷重新评估其政治倾向。Llama Chat 显著了解各国政党的立场，并能够在上下文中推理。经调整的、特定政党的模型在相应立场上有明显的重新调整，我们认为这是将基于对话的LLM作为数据驱动的对话引擎用于协助政治科学研究的起点。

    arXiv:2403.13592v1 Announce Type: new  Abstract: Instruction-finetuned Large Language Models inherit clear political leanings that have been shown to influence downstream task performance. We expand this line of research beyond the two-party system in the US and audit Llama Chat in the context of EU politics in various settings to analyze the model's political knowledge and its ability to reason in context. We adapt, i.e., further fine-tune, Llama Chat on speeches of individual euro-parties from debates in the European Parliament to reevaluate its political leaning based on the EUandI questionnaire. Llama Chat shows considerable knowledge of national parties' positions and is capable of reasoning in context. The adapted, party-specific, models are substantially re-aligned towards respective positions which we see as a starting point for using chat-based LLMs as data-driven conversational engines to assist research in political science.
    
[^14]: 老师-学生培训用于去偏见：大型语言模型的通用置换去偏见

    Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models

    [https://arxiv.org/abs/2403.13590](https://arxiv.org/abs/2403.13590)

    本论文提出了一种教师-学生培训方法，通过在推理时将高计算成本的去偏见老师模型的能力蒸馏到更紧凑的学生模型中，来解决大型语言模型在保持特定任务不变性时的低效率问题。

    

    大型语言模型（LLMs）展示了在自然语言处理任务中令人印象深刻的零-shot能力和多功能性，然而它们有时会无法保持特定任务的关键不变性。一个例子就是置换敏感性，LLMs的输出可能会根据输入选项的顺序不同而明显不同。虽然去偏见技术可以减轻这些问题，并带来更好的性能和可靠性，但它们在推理时往往会伴随着高计算成本。本文解决了这种推理时的低效率。其目的是将计算密集型、去偏见的老师模型的能力蒸馏到一个更紧凑的学生模型中。我们探讨了两种学生模型的变种：一种基于纯粹蒸馏，另一种基于纠正方法，针对更复杂的任务，学生通过纠正老师的一个有偏决策来实现去偏见的输出。我们的方法是通用的，并可应用于各种任务和语言模型大小。

    arXiv:2403.13590v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive zero-shot capabilities and versatility in NLP tasks, however they sometimes fail to maintain crucial invariances for specific tasks. One example is permutation sensitivity, where LLMs' outputs may significantly vary depending on the order of the input options. While debiasing techniques can mitigate these issues, and yield better performance and reliability, they often come with a high computational cost at inference. This paper addresses this inefficiency at inference time. The aim is to distill the capabilities of a computationally intensive, debiased, teacher model into a more compact student model. We explore two variants of student models: one based on pure distillation, and the other on an error-correction approach for more complex tasks, where the student corrects a single biased decision from the teacher to achieve a debiased output. Our approach is general and can be appl
    
[^15]: 基于遗传自动提示学习的预训练代码智能语言模型

    Genetic Auto-prompt Learning for Pre-trained Code Intelligence Language Models

    [https://arxiv.org/abs/2403.13588](https://arxiv.org/abs/2403.13588)

    提出了一种基于遗传算法的自动设计提示方法，解决了预训练代码智能语言模型中需要人工设计提示的问题。

    

    预训练语言模型（PLMs）作为代码智能的一种流行方法，随着规模的增长，它们的使用计算成本变得难以承受。最近发展起来的提示学习成为解决这一挑战的潜在方法。本文研究了提示学习在代码智能任务中的有效性。我们揭示了其依赖于人工设计的提示，这往往需要大量的人力和专业知识。此外，我们发现现有的自动提示设计方法在代码智能任务中受到很大限制，原因包括梯度依赖性、高计算需求和有限的适用性。为了有效解决这两个问题，我们提出了基因自动提示（GenAP），它利用精心设计的遗传算法来自动设计提示。通过GenAP，非专家可以轻松生成超级

    arXiv:2403.13588v1 Announce Type: cross  Abstract: As Pre-trained Language Models (PLMs), a popular approach for code intelligence, continue to grow in size, the computational cost of their usage has become prohibitively expensive. Prompt learning, a recent development in the field of natural language processing, emerges as a potential solution to address this challenge. In this paper, we investigate the effectiveness of prompt learning in code intelligence tasks. We unveil its reliance on manually designed prompts, which often require significant human effort and expertise. Moreover, we discover existing automatic prompt design methods are very limited to code intelligence tasks due to factors including gradient dependence, high computational demands, and limited applicability. To effectively address both issues, we propose Genetic Auto Prompt (GenAP), which utilizes an elaborate genetic algorithm to automatically design prompts. With GenAP, non-experts can effortlessly generate super
    
[^16]: CONLINE: 复杂代码生成与在线搜索和正确性测试的精炼

    CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing

    [https://arxiv.org/abs/2403.13583](https://arxiv.org/abs/2403.13583)

    CONLINE框架提出了通过在线搜索和正确性测试来增强复杂代码生成的方法，通过实验证明了其显著提高了代码生成质量。

    

    大型语言模型（LLMs）通过将自然语言描述转换为可执行代码，彻底改变了代码生成能力。然而，在真实场景下生成复杂代码仍然具有挑战性，原因在于复杂的结构、微妙的错误、对高级数据类型的理解以及缺少辅助内容。为了解决这些挑战，我们引入了CONLINE框架，通过计划的在线搜索信息检索和自动正确性测试来增强代码生成，进行迭代精炼。CONLINE还串行化了复杂的输入和输出，以改善理解，并生成测试用例，确保框架适用于现实应用。CONLINE通过对DS-1000和ClassEval数据集进行严格实验验证。结果表明，CONLINE显著提高了复杂代码生成的质量，突显了其提升实践应用潜力。

    arXiv:2403.13583v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lack of supplementary contents. To address these challenges, we introduce the CONLINE framework, which enhances code generation by incorporating planned online searches for information retrieval and automated correctness testing for iterative refinement. CONLINE also serializes the complex inputs and outputs to improve comprehension and generate test case to ensure the framework's adaptability for real-world applications. CONLINE is validated through rigorous experiments on the DS-1000 and ClassEval datasets. It shows that CONLINE substantially improves the quality of complex code generation, highlighting its potential to enhance the pra
    
[^17]: 多重奖励强化学习中的动态奖励调整用于辅导员反思生成

    Dynamic Reward Adjustment in Multi-Reward Reinforcement Learning for Counselor Reflection Generation

    [https://arxiv.org/abs/2403.13578](https://arxiv.org/abs/2403.13578)

    本文研究了多重奖励强化学习在辅导员反思生成中的应用，引入了两种新的赌博方法DynOpt和C-DynaOpt，动态调整多个奖励权重，通过实验表明这些方法能够优于现有的基线方法。

    

    在本文中，我们研究了多重奖励强化学习问题，以共同优化自然语言生成中多个文本质量。我们关注辅导员反思生成的任务，我们优化生成器以同时提高生成的辅导员回复的流畅性、连贯性和反思质量。我们引入了两种新的赌博方法，DynaOpt和C-DynaOpt，这些方法依赖于将奖励组合成一个单一值并同时优化它们的广泛策略。具体来说，我们利用非情境和情境多臂赌博来在训练过程中动态调整多个奖励权重。通过自动和手动评估，我们展示了我们提出的技术DynaOpt和C-DynaOpt优于现有的朴素和赌博基线，展示了它们增强语言模型的潜力。

    arXiv:2403.13578v1 Announce Type: new  Abstract: In this paper, we study the problem of multi-reward reinforcement learning to jointly optimize for multiple text qualities for natural language generation. We focus on the task of counselor reflection generation, where we optimize the generators to simultaneously improve the fluency, coherence, and reflection quality of generated counselor responses. We introduce two novel bandit methods, DynaOpt and C-DynaOpt, which rely on the broad strategy of combining rewards into a single value and optimizing them simultaneously. Specifically, we employ non-contextual and contextual multi-arm bandits to dynamically adjust multiple reward weights during training. Through automatic and manual evaluations, we show that our proposed techniques, DynaOpt and C-DynaOpt, outperform existing naive and bandit baselines, showcasing their potential for enhancing language models.
    
[^18]: eRST：一种表征话语关系和组织的信号图论

    eRST: A Signaled Graph Theory of Discourse Relations and Organization

    [https://arxiv.org/abs/2403.13560](https://arxiv.org/abs/2403.13560)

    提出了增强修辞结构理论（eRST），这是一个基于修辞结构理论（RST）拓展的计算话语分析的新理论框架，解决了RST和其他现有框架存在的问题，并提供了相关工具和英文语料库。

    

    在这篇文章中，我们提出了增强修辞结构理论（eRST），这是一个基于修辞结构理论（RST）拓展的计算话语分析的新理论框架。该框架包括具有树状打断、非投射和并发关系的话语关系图，以及给出我们分析解释性基础的隐式和显式信号。我们调查了RST和其他现有框架（如分段话语表示理论（SDRT）、宾夕法尼亚话语树库（PDTB）和话语依赖）的缺陷，并利用所提出的理论中的构建来解决这些问题。我们为数据提供了注释、搜索和可视化工具，并提供和评估了一个根据我们的框架标注的英文语料库，包括12种口头和书面体裁，涵盖了超过200K词元。最后，我们讨论了自动解析、评估度量和应用。

    arXiv:2403.13560v1 Announce Type: new  Abstract: In this article we present Enhanced Rhetorical Structure Theory (eRST), a new theoretical framework for computational discourse analysis, based on an expansion of Rhetorical Structure Theory (RST). The framework encompasses discourse relation graphs with tree-breaking, nonprojective and concurrent relations, as well as implicit and explicit signals which give explainable rationales to our analyses. We survey shortcomings of RST and other existing frameworks, such as Segmented Discourse Representation Theory (SDRT), the Penn Discourse Treebank (PDTB) and Discourse Dependencies, and address these using constructs in the proposed theory. We provide annotation, search and visualization tools for data, and present and evaluate a freely available corpus of English annotated according to our framework, encompassing 12 spoken and written genres with over 200K tokens. Finally, we discuss automatic parsing, evaluation metrics and applications for 
    
[^19]: 解释ORCA交叉模态微调成功的因素是什么？

    What explains the success of cross-modal fine-tuning with ORCA?

    [https://arxiv.org/abs/2403.13537](https://arxiv.org/abs/2403.13537)

    通过一系列消融实验，确定了ORCA中嵌入器训练对2D任务无帮助、1D任务需要适量嵌入器训练、以及模型微调对性能影响最大的结论。

    

    ORCA（Shen等人，2023）是一种最近的交叉模态微调技术，即将预训练的转换器模型应用于其训练数据之外的模态。 该技术主要包括训练一个嵌入器并微调嵌入器和模型。 尽管它在各种下游任务上表现出色，但我们并不确切了解这些组件中的每个如何促成ORCA的成功。 因此，我们进行了一系列消融实验，并发现嵌入器训练对2D任务毫无帮助，与原始论文所言相反。 在1D任务中，一定量的嵌入器训练是必要的，但更多并非总是更好。 在我们尝试的6个数据集中的4个数据集中，模型微调产生了最大的差异。 通过我们的消融实验和基线，我们对ORCA的各个组件有了更好的理解。

    arXiv:2403.13537v1 Announce Type: new  Abstract: ORCA (Shen et al., 2023) is a recent technique for cross-modal fine-tuning, i.e., applying pre-trained transformer models to modalities beyond their training data. The technique consists primarily of training an embedder and fine-tuning the embedder and model. Despite its high performance on a variety of downstream tasks, we do not understand precisely how each of these components contribute to ORCA's success. Therefore, we run a series of ablations and find that embedder training does not help 2D tasks at all, contrary to what the original paper posits. In 1D tasks, some amount of embedder training is necessary but more is not better. In 4 out of 6 datasets we experiment with, it is model fine-tuning that makes the biggest difference. Through our ablations and baselines, we contribute a better understanding of the individual components of ORCA.
    
[^20]: 从细粒度文本描述中生成运动

    Motion Generation from Fine-grained Textual Descriptions

    [https://arxiv.org/abs/2403.13518](https://arxiv.org/abs/2403.13518)

    本文提出了一种从细粒度文本描述中生成运动的方法，构建了FineHumanML3D数据集，设计了FineMotionDiffuse模型，实验结果表明该模型表现出色。

    

    文本到动作的任务是从给定的文字描述生成运动序列，模型应该探索自然语言指令与人体动作之间的交互。大多数现有作品局限于粗粒度的运动描述（例如，“一个人蹲下。”），几乎没有探索指定相关身体部位运动的细粒度描述。用粗糙文本训练的模型可能无法学习从细粒度运动相关词汇到运动基元的映射，导致无法从未见描述生成动作。在本文中，我们通过输入精细提示给 GPT-3.5-turbo，构建了一个细粒度文本描述的大规模语言-动作数据集FineHumanML3D。因此，我们设计了一个新的文本到动作模型FineMotionDiffuse，充分利用细粒度的文本信息。我们的实验表明，FineMotionDiffuse在FineHumanML3D上训练后获得

    arXiv:2403.13518v1 Announce Type: cross  Abstract: The task of text2motion is to generate motion sequences from given textual descriptions, where a model should explore the interactions between natural language instructions and human body movements. While most existing works are confined to coarse-grained motion descriptions (e.g., "A man squats."), fine-grained ones specifying movements of relevant body parts are barely explored. Models trained with coarse texts may not be able to learn mappings from fine-grained motion-related words to motion primitives, resulting in the failure in generating motions from unseen descriptions. In this paper, we build a large-scale language-motion dataset with fine-grained textual descriptions, FineHumanML3D, by feeding GPT-3.5-turbo with delicate prompts. Accordingly, we design a new text2motion model, FineMotionDiffuse, which makes full use of fine-grained textual information. Our experiments show that FineMotionDiffuse trained on FineHumanML3D acqui
    
[^21]: 性别如何与政治价值观互动：捷克BERT模型案例研究

    How Gender Interacts with Political Values: A Case Study on Czech BERT Models

    [https://arxiv.org/abs/2403.13514](https://arxiv.org/abs/2403.13514)

    捷克BERT模型案例研究发现，BERT大小的模型并不体现出与政治价值观的系统对齐，模型中观察到的偏见更多是由表面模仿引起的。

    

    神经语言模型在大多数自然语言处理任务上达到了最先进的结果，这些模型是在不可避免地包含价值负担内容的大型文本语料库上训练的，通常捕捉到不良偏见，这些偏见也会体现在模型中。这个案例研究关注捷克预训练编码器中的政治偏见，并将其与代表性价值调查进行比较。由于捷克是一种性别化语言，我们还衡量了语法性别与调查中对男性和女性回答的关系。我们引入了一种新颖的方法来衡量模型的政治价值观。我们发现模型在分配陈述概率时并不遵循基于价值的推理，并且女性和男性句子之间没有系统差异。我们得出结论，BERT大小的模型并不体现出与政治价值观的系统对齐，模型中观察到的偏见更多是由表面模仿引起的。

    arXiv:2403.13514v1 Announce Type: new  Abstract: Neural language models, which reach state-of-the-art results on most natural language processing tasks, are trained on large text corpora that inevitably contain value-burdened content and often capture undesirable biases, which the models reflect. This case study focuses on the political biases of pre-trained encoders in Czech and compares them with a representative value survey. Because Czech is a gendered language, we also measure how the grammatical gender coincides with responses to men and women in the survey. We introduce a novel method for measuring the model's perceived political values. We find that the models do not assign statement probability following value-driven reasoning, and there is no systematic difference between feminine and masculine sentences. We conclude that BERT-sized models do not manifest systematic alignment with political values and that the biases observed in the models are rather due to superficial imitat
    
[^22]: 如果......会怎样？：反事实启示在大型多模态模型中减轻幻觉效应

    What if...?: Counterfactual Inception to Mitigate Hallucination Effects in Large Multimodal Models

    [https://arxiv.org/abs/2403.13513](https://arxiv.org/abs/2403.13513)

    本文引入了反事实启示（Counterfactual Inception）方法，通过将反事实思想植入到大型多模态模型（LMMs）中，可以减轻幻觉效应并提高模型的可信度。

    

    本文介绍了提高大型多模态模型（LMMs）在处理幻觉效应方面可靠性的方法，其中模型会生成不正确或无关的响应。没有额外的指导调整范式，我们引入了反事实启示，这是一种新颖的方法，通过精心选择的、不对齐的反事实关键词将反事实思想植入到LMMs中。该方法根植于反事实思维概念，这是一种认知过程，人类在其中考虑替代现实和结果。通过将这种类似人类的推理机制应用到LMMs中，我们旨在减少幻觉效应并提高模型的可信度。我们还提出了双模态验证过程（DVP），这是一个严格的框架，用于选择触发LMMs中反事实思维的最佳反事实关键词，同时考虑视觉和语言上下文。我们在各种LMMs上进行了大量实验

    arXiv:2403.13513v1 Announce Type: cross  Abstract: This paper presents a way of enhancing the reliability of Large Multimodal Models (LMMs) in addressing hallucination effects, where models generate incorrect or unrelated responses. Without additional instruction tuning paradigm, we introduce Counterfactual Inception, a novel method that implants counterfactual thoughts into LMMs using carefully chosen, misaligned counterfactual keywords. This method is grounded in the concept of counterfactual thinking, a cognitive process where humans consider alternative realities and outcomes. By applying this human-like reasoning mechanism to LMMs, we aim to reduce hallucination effects and improve the models' trustworthiness. We also propose Dual-modality Verification Process (DVP), a rigorous framework for selecting optimal counterfactual keywords to trigger counterfactual thinking into LMMs, concurrently considering visual and linguistic context. Our extensive experiments across various LMMs, i
    
[^23]: 基于熵的文本水印检测方法

    An Entropy-based Text Watermarking Detection Method

    [https://arxiv.org/abs/2403.13485](https://arxiv.org/abs/2403.13485)

    提出了一种基于熵的水印检测方法，在检测过程中根据令牌的熵调整其权重，以更好地反映水印程度，该方法在大型语言模型中具有应用潜力。

    

    目前，大型语言模型（LLMs）的文本水印算法能够嵌入隐藏特征到LLMs生成的文本中，以便后续检测，从而缓解了LLMs被误用的问题。尽管当前的文本水印算法在大多数高熵情况下表现良好，但在低熵情况下仍需要改进。在这项工作中，我们提出在水印检测过程中应全面考虑令牌熵的影响，即应根据其熵调整每个令牌的重量，而不是像以前的方法中将所有令牌的重量设置为相同值。具体来说，我们提出了一种基于熵的水印检测（EWD），在水印检测过程中赋予高熵令牌更高的权重，以更好地反映水印程度。此外，所提出的检测过程无需训练。

    arXiv:2403.13485v1 Announce Type: new  Abstract: Currently, text watermarking algorithms for large language models (LLMs) can embed hidden features to texts generated by LLMs to facilitate subsequent detection, thus alleviating the problem of misuse of LLMs. Although the current text watermarking algorithms perform well in most high-entropy scenarios, its performance in low-entropy scenarios still needs to be improved. In this work, we proposed that the influence of token entropy should be fully considered in the watermark detection process, that is, the weight of each token should be adjusted according to its entropy during watermark detection, rather than setting the weight of all tokens to the same value as in previous methods. Specifically, we proposed an Entropy-based Watermark Detection (EWD) that gives higher-entropy tokens higher weights during watermark detection, so as to better reflect the degree of watermarking. Furthermore, the proposed detection process is training-free a
    
[^24]: HyperLLaVA: 多模态大型语言模型的动态视觉和语言专家调优

    HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal Large Language Models

    [https://arxiv.org/abs/2403.13447](https://arxiv.org/abs/2403.13447)

    HyperLLaVA通过引入自适应调整的投影仪和LLM参数，以及动态的视觉专家和语言专家，从而弥补了静态调整策略在不同下游多模态任务上性能受限的不足。

    

    最近的进展表明，扩展多模态大型语言模型(MLLMs)有效地提升了在下游多模态任务上的性能。当前的MLLM范式，如LLaVA，通过使用静态视觉-语言映射器将视觉特征转换为类似文本的标记，从而使静态LLMs通过视觉指令调优获得理解视觉信息的能力。尽管有所希望，但相同参数的静态调优策略可能限制不同下游多模态任务的性能。鉴于此，我们介绍了HyperLLaVA，其中包括投影仪和LLM参数的自适应调整，以及动态视觉专家和语言专家。这些专家源自HyperNetworks，它通过生成自适应参数偏移来实现

    arXiv:2403.13447v1 Announce Type: cross  Abstract: Recent advancements indicate that scaling up Multimodal Large Language Models (MLLMs) effectively enhances performance on downstream multimodal tasks. The prevailing MLLM paradigm, \emph{e.g.}, LLaVA, transforms visual features into text-like tokens using a \emph{static} vision-language mapper, thereby enabling \emph{static} LLMs to develop the capability to comprehend visual information through visual instruction tuning. Although promising, the \emph{static} tuning strategy~\footnote{The static tuning refers to the trained model with static parameters.} that shares the same parameters may constrain performance across different downstream multimodal tasks. In light of this, we introduce HyperLLaVA, which involves adaptive tuning of the projector and LLM parameters, in conjunction with a dynamic visual expert and language expert, respectively. These experts are derived from HyperNetworks, which generates adaptive parameter shifts throug
    
[^25]: 代理人群组聊天：一种交互式群组聊天拟真体，用于更好地引发集体新兴行为

    Agent Group Chat: An Interactive Group Chat Simulacra For Better Eliciting Collective Emergent Behavior

    [https://arxiv.org/abs/2403.13433](https://arxiv.org/abs/2403.13433)

    通过Agent Group Chat模拟，研究了语言在人类集体行为中的作用，发现在不同故事情节下，代理人表现出了意料之外且重要的新兴行为，通过调整环境设置可以评估代理人是否展现出与人类期望一致的行为。

    

    为了探讨语言在人类集体行为中的作用，我们开发了代理人群组聊天模拟，模拟多代理之间在不同设置下的语言交互。代理人被要求在该模拟中自由聊天，基于其角色设定追求各自的目的，旨在观察代理人展现出既意料不到又显著的新兴行为。将四个叙事场景（继承争议、法庭辩论、哲学辞说、电影角色争议）整合到代理人群组聊天中，以评估其支持多样化故事情节的能力。通过在代理人群组聊天中配置特定的环境设置，我们能够评估代理人是否展现出与人类期望一致的行为。我们通过计算角色发言的所有内容的n-gram Shannon熵来评估环境中的混乱程度。我们的研究结果显示，在代理人具有子...

    arXiv:2403.13433v1 Announce Type: cross  Abstract: To investigate the role of language in human collective behaviors, we developed the Agent Group Chat simulation to simulate linguistic interactions among multi-agent in different settings. Agents are asked to free chat in this simulation for their own purposes based on their character setting, aiming to see agents exhibit emergent behaviours that are both unforeseen and significant. Four narrative scenarios, Inheritance Disputes, Law Court Debates, Philosophical Discourses, Movie Casting Contention, are integrated into Agent Group Chat to evaluate its support for diverse storylines. By configuring specific environmental settings within Agent Group Chat, we are able to assess whether agents exhibit behaviors that align with human expectations. We evaluate the disorder within the environment by computing the n-gram Shannon entropy of all the content speak by characters. Our findings reveal that under the premise of agents possessing subs
    
[^26]: LlamaFactory：100多种语言模型的统一高效微调

    LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models

    [https://arxiv.org/abs/2403.13372](https://arxiv.org/abs/2403.13372)

    LlamaFactory是一个统一框架，整合了一系列前沿的高效训练方法，使用户能够在不需要编码的情况下灵活定制100多种LLMs的微调。

    

    高效的微调对于将大型语言模型（LLMs）适应下游任务至关重要。然而，在不同模型上实现这些方法需要非平凡的努力。我们提出了LlamaFactory，这是一个统一框架，集成了一套前沿的高效训练方法。它允许用户通过内置的Web UI LlamaBoard 灵活定制100多种LLMs的微调，无需编码。我们在语言建模和文本生成任务上经验性地验证了我们框架的效率和有效性。已发布在 https://github.com/hiyouga/LLaMA-Factory，并已获得超过13,000颗星和1,600个分支。

    arXiv:2403.13372v1 Announce Type: new  Abstract: Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It allows users to flexibly customize the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks. It has been released at https://github.com/hiyouga/LLaMA-Factory and already received over 13,000 stars and 1,600 forks.
    
[^27]: 使用预训练语言模型和提示进行少资源语言的少样本学习的临床信息提取

    Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting

    [https://arxiv.org/abs/2403.13369](https://arxiv.org/abs/2403.13369)

    使用预训练语言模型和提示技术，在少资源语言情境下，仅需少量样本训练即可提取临床信息，且表现优于传统方法。

    

    从临床文件中自动提取医疗信息面临着几个挑战：所需临床专业知识的高成本、模型预测的有限可解释性、受限的计算资源以及隐私法规。最近在领域适应和提示方法上的进展显示，利用轻量级遮蔽语言模型在使用极少的训练数据时取得了令人期待的结果，这些模型适用于成熟的可解释性方法。我们首次在少资源环境中对这些方法进行了系统评估，通过在德国医生信件上进行多类别段分类来实现。我们进行了广泛的类别级评估，支持 Shapley 值，以验证我们的小型训练数据集的质量，并确保模型预测的可解释性。我们证明，一个轻量级、领域适应的预训练模型，在仅仅提示了 20 次的情况下，胜过了传统的分类

    arXiv:2403.13369v1 Announce Type: new  Abstract: Automatic extraction of medical information from clinical documents poses several challenges: high costs of required clinical expertise, limited interpretability of model predictions, restricted computational resources and privacy regulations. Recent advances in domain-adaptation and prompting methods showed promising results with minimal training data using lightweight masked language models, which are suited for well-established interpretability methods. We are first to present a systematic evaluation of these methods in a low-resource setting, by performing multi-class section classification on German doctor's letters. We conduct extensive class-wise evaluations supported by Shapley values, to validate the quality of our small training data set and to ensure the interpretability of model predictions. We demonstrate that a lightweight, domain-adapted pretrained model, prompted with just 20 shots, outperforms a traditional classificatio
    
[^28]: 用于研究人脑语言处理的计算模型：一项调研

    Computational Models to Study Language Processing in the Human Brain: A Survey

    [https://arxiv.org/abs/2403.13368](https://arxiv.org/abs/2403.13368)

    当前语言模型表现出人类化或超越人类的语言能力，研究发现没有一个单一模型在所有数据集上表现优于其他模型，强调了用于涉及计算模型的研究中绘制健壮结论的需要。

    

    尽管在实现和算法上与人类语言处理机制存在差异，但当前的语言模型展示出引人入胜的人类化或超越人类的语言能力。计算语言模型是否应该用于研究大脑，如果是，则何时以及如何？为了深入探讨这个话题，本文回顾了利用计算模型进行大脑研究的努力，突显新兴趋势。为了确保公正比较，本文使用相同数据集上的一致度量评估了各种计算模型。我们的分析显示，没有一个单一模型在所有数据集上表现优于其他模型，强调了在涉及计算模型的研究中绘制健壮结论的需要使用丰富的测试数据集和严格的实验对照。

    arXiv:2403.13368v1 Announce Type: new  Abstract: Despite differing from the human language processing mechanism in implementation and algorithms, current language models demonstrate remarkable human-like or surpassing language capabilities. Should computational language models be employed in studying the brain, and if so, when and how? To delve into this topic, this paper reviews efforts in using computational models for brain research, highlighting emerging trends. To ensure a fair comparison, the paper evaluates various computational models using consistent metrics on the same dataset. Our analysis reveals that no single model outperforms others on all datasets, underscoring the need for rich testing datasets and rigid experimental control to draw robust conclusions in studies involving computational models.
    
[^29]: 利用大型语言模型和真实机器人账户激励社交媒体平台上的新闻消费

    Incentivizing News Consumption on Social Media Platforms Using Large Language Models and Realistic Bot Accounts

    [https://arxiv.org/abs/2403.13362](https://arxiv.org/abs/2403.13362)

    通过创建使用 GPT-2 的机器人账户，在社交媒体平台上回复用户的推文，鼓励用户接触和关注验证的、意识形态平衡的新闻，以增加用户接触这些新闻并提高参与度。

    

    极化、信任下降以及对民主规范支持动摇是美国民主面临的紧迫威胁。接触验证和优质新闻可能降低个人对这些威胁的易感性，并使公民更具抗击错误信息、民粹主义和极端党派言论的能力。该项目探讨了如何在一个生态有效的环境中增强用户接触和参与验证的、意识形态平衡的新闻。我们依赖于对 28,457 个 Twitter 用户进行的大规模为期两周的田野实验（从 2023 年 1 月 19 日到 2 月 3 日）。我们创建了 28 个利用 GPT-2 的机器人，在用户发表有关体育、娱乐或生活方式的推文时回复一个内容相关的回复，其中包含两个硬代码元素：一个指向优质新闻机构相关主题部分的 URL 和鼓励关注其 Twitter 账户。为进一步测试机器人对性别的差异影响，被试用户被随机分配以接受...

    arXiv:2403.13362v1 Announce Type: cross  Abstract: Polarization, declining trust, and wavering support for democratic norms are pressing threats to U.S. democracy. Exposure to verified and quality news may lower individual susceptibility to these threats and make citizens more resilient to misinformation, populism, and hyperpartisan rhetoric. This project examines how to enhance users' exposure to and engagement with verified and ideologically balanced news in an ecologically valid setting. We rely on a large-scale two-week long field experiment (from 1/19/2023 to 2/3/2023) on 28,457 Twitter users. We created 28 bots utilizing GPT-2 that replied to users tweeting about sports, entertainment, or lifestyle with a contextual reply containing two hardcoded elements: a URL to the topic-relevant section of quality news organization and an encouragement to follow its Twitter account. To further test differential effects by gender of the bots, treated users were randomly assigned to receive re
    
[^30]: 使用：带有有状态序列模型的动态用户建模

    USE: Dynamic User Modeling with Stateful Sequence Models

    [https://arxiv.org/abs/2403.13344](https://arxiv.org/abs/2403.13344)

    引入了User Stateful Embedding（USE）来解决动态用户建模中存在的挑战，通过存储先前模型状态，生成用户嵌入并反映用户不断发展的行为。

    

    用户嵌入在用户参与度预测和个性化服务中起着至关重要的作用。序列建模的最新进展引发了从行为数据中学习用户嵌入的兴趣。然而，基于行为的用户嵌入学习面临动态用户建模的独特挑战。随着用户不断与应用程序交互，用户嵌入应定期更新以考虑用户的最近和长期行为模式。现有方法高度依赖于缺乏历史行为记忆的无状态序列模型。它们必须要么丢弃历史数据仅使用最新数据，要么重新处理旧数据和新数据。两种情况均会产生大量计算开销。为解决这一限制，我们引入了用户有状态嵌入（USE）。USE生成用户嵌入并反映用户不断发展的行为，而无需通过存储先前的模型状态来进行详尽的重新处理。

    arXiv:2403.13344v1 Announce Type: cross  Abstract: User embeddings play a crucial role in user engagement forecasting and personalized services. Recent advances in sequence modeling have sparked interest in learning user embeddings from behavioral data. Yet behavior-based user embedding learning faces the unique challenge of dynamic user modeling. As users continuously interact with the apps, user embeddings should be periodically updated to account for users' recent and long-term behavior patterns. Existing methods highly rely on stateless sequence models that lack memory of historical behavior. They have to either discard historical data and use only the most recent data or reprocess the old and new data jointly. Both cases incur substantial computational overhead. To address this limitation, we introduce User Stateful Embedding (USE). USE generates user embeddings and reflects users' evolving behaviors without the need for exhaustive reprocessing by storing previous model states and
    
[^31]: Hyacinth6B：一个用于中文的大型语言模型

    Hyacinth6B: A large language model for Traditional Chinese

    [https://arxiv.org/abs/2403.13334](https://arxiv.org/abs/2403.13334)

    为了解决大型语言模型通常存在的高硬件和计算需求，Hyacinth6B在模型轻量化和性能之间找到了平衡，采用LoRA方法进行参数高效微调。

    

    这项研究的主要动机是应对通常与大型语言模型相关的高硬件和计算需求。因此，我们的目标是在模型轻量化和性能之间找到平衡，努力在使用相对轻量级模型的同时最大化性能。Hyacinth6B是基于这一目标开发的，旨在充分发挥LLM的核心能力，而不造成巨大的资源成本，有效地推动较小模型的性能边界。训练方法涉及使用LoRA方法进行参数高效微调。

    arXiv:2403.13334v1 Announce Type: new  Abstract: This research's primary motivation of this study is to address the high hardware and computational demands typically associated with LLMs.Therefore,our goal is to find a balance between model lightness and performance,striving to maximize performance while using a comparatively lightweight model. Hyacinth6B was developed with this objective in mind,aiming to fully leverage the core capabilities of LLMs without incurring substantial resource costs, effectively pushing the boundaries of smaller model's performance. The training approach involves parameter efficient finetuning using the LoRA method.
    
[^32]: Polaris：面向医疗保健的以安全为重点的LLM星座架构

    Polaris: A Safety-focused LLM Constellation Architecture for Healthcare

    [https://arxiv.org/abs/2403.13313](https://arxiv.org/abs/2403.13313)

    Polaris是面向医疗保健的首个以安全为重点的LLM星座架构，利用多亿参数的合作代理进行长时间多轮语音对话，通过优化代理的迭代协同训练实现多样化目标的最大化。

    

    我们开发了Polaris，这是第一个以安全为重点的LLM星座，用于实时患者 - AI医疗保健对话。与先前侧重于问题回答等任务的医疗保健LLM工作不同，我们的工作专门关注长时间的多轮语音对话。我们的兆个参数星座系统由多个数十亿参数的合作代理组成：一个有状态的主代理，专注于引导引人入胜的对话，以及几个专业支持代理，专注于护士执行的医疗保健任务，以提高安全性并减少幻觉。我们为代理的迭代协同训练开发了复杂的训练协议，优化各种目标。我们在专有数据、临床护理计划、医疗保健监管文件、医疗手册和其他医疗推理文件上训练我们的模型。我们使我们的模型与医疗专业人员说话一样，使用有机医疗术语。

    arXiv:2403.13313v1 Announce Type: cross  Abstract: We develop Polaris, the first safety-focused LLM constellation for real-time patient-AI healthcare conversations. Unlike prior LLM works in healthcare focusing on tasks like question answering, our work specifically focuses on long multi-turn voice conversations. Our one-trillion parameter constellation system is composed of several multibillion parameter LLMs as co-operative agents: a stateful primary agent that focuses on driving an engaging conversation and several specialist support agents focused on healthcare tasks performed by nurses to increase safety and reduce hallucinations. We develop a sophisticated training protocol for iterative co-training of the agents that optimize for diverse objectives. We train our models on proprietary data, clinical care plans, healthcare regulatory documents, medical manuals, and other medical reasoning documents. We align our models to speak like medical professionals, using organic healthcare 
    
[^33]: LeanReasoner: 用Lean提升复杂逻辑推理

    LeanReasoner: Boosting Complex Logical Reasoning with Lean

    [https://arxiv.org/abs/2403.13312](https://arxiv.org/abs/2403.13312)

    使用Lean框架解决大语言模型在复杂逻辑推理中的困难，实现了最先进性能并在少量样本上微调。

    

    大语言模型（LLMs）通常由于逻辑不一致性和推理困难而面临复杂的逻辑推理问题。我们使用Lean，一个定理证明框架，来解决这些挑战。通过在Lean中将逻辑推理问题形式化为定理，我们可以通过证明或证伪相应的定理来解决它们。这种方法通过Lean的符号求解器减少了逻辑不一致性的风险。它还通过使用Lean的广泛定理证明库增强了我们处理复杂推理任务的能力。我们的方法在FOLIO数据集上实现了最先进性能，并在ProofWriter数据集上接近了这一水平。值得注意的是，这些结果是在每个数据集的少于100个领域内样本进行微调后实现的。

    arXiv:2403.13312v1 Announce Type: new  Abstract: Large language models (LLMs) often struggle with complex logical reasoning due to logical inconsistencies and the inherent difficulty of such reasoning. We use Lean, a theorem proving framework, to address these challenges. By formalizing logical reasoning problems into theorems within Lean, we can solve them by proving or disproving the corresponding theorems. This method reduces the risk of logical inconsistencies with the help of Lean's symbolic solver. It also enhances our ability to treat complex reasoning tasks by using Lean's extensive library of theorem proofs. Our method achieves state-of-the-art performance on the FOLIO dataset and achieves performance near this level on ProofWriter. Notably, these results were accomplished by fine-tuning on fewer than 100 in-domain samples for each dataset.
    
[^34]: 从言语中阅读用户心思：基于LLM的移情心理推理研究

    Reading Users' Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference

    [https://arxiv.org/abs/2403.13301](https://arxiv.org/abs/2403.13301)

    本论文研究了使用大型语言模型（LLMs）进行心智推断任务，特别是推断用户的潜在目标和基本心理需求（FPNs），并提出了一种衡量LLMs心理推理性能的共情准确度指标。

    

    在以人为中心的设计中，发展对用户体验的全面深入理解，即共情理解，对于设计真正满足人类需求的产品至关重要。然而，准确理解大人口群体真实的潜在心理状态在今天仍然是一个重大挑战。本文调查了使用大型语言模型（LLMs）执行心理推理任务，特别是推断用户的潜在目标和基本心理需求（FPNs）。从人类用户和设计者那里收集了基准和基准数据集，以开发一个共情准确度指标，用于衡量LLMs的心理推理性能。

    arXiv:2403.13301v1 Announce Type: cross  Abstract: In human-centered design, developing a comprehensive and in-depth understanding of user experiences, i.e., empathic understanding, is paramount for designing products that truly meet human needs. Nevertheless, accurately comprehending the real underlying mental states of a large human population remains a significant challenge today. This difficulty mainly arises from the trade-off between depth and scale of user experience research: gaining in-depth insights from a small group of users does not easily scale to a larger population, and vice versa. This paper investigates the use of Large Language Models (LLMs) for performing mental inference tasks, specifically inferring users' underlying goals and fundamental psychological needs (FPNs). Baseline and benchmark datasets were collected from human users and designers to develop an empathic accuracy metric for measuring the mental inference performance of LLMs. The empathic accuracy of inf
    
[^35]: 社区需求与资产：社区对话的计算分析

    Community Needs and Assets: A Computational Analysis of Community Conversations

    [https://arxiv.org/abs/2403.13272](https://arxiv.org/abs/2403.13272)

    本研究引入了一项任务，即利用复杂的自然语言处理方法从对话数据中识别、提取和分类社区需求与资产，同时介绍了第一个关于社区需求和资产的数据集。

    

    社区需求评估是非营利组织和政府机构用来量化社区优势和问题的工具，使他们能更好地分配资源。这种方法正转向利用社交媒体对话来分析社区的需求和已有资产。然而，对指数增长的社交媒体对话进行手动分析是具有挑战性的。目前文献中缺乏对社区成员如何讨论社区优势和需求进行计算分析的研究。为了解决这一空白，我们引入了利用先进自然语言处理方法从对话数据中识别、提取和分类社区需求与资产的任务。为了促进这一任务，我们引入了第一个关于社区需求与资产的数据集，包括来自Reddit的3,511个对话，使用众包工作者进行注释。

    arXiv:2403.13272v1 Announce Type: cross  Abstract: A community needs assessment is a tool used by non-profits and government agencies to quantify the strengths and issues of a community, allowing them to allocate their resources better. Such approaches are transitioning towards leveraging social media conversations to analyze the needs of communities and the assets already present within them. However, manual analysis of exponentially increasing social media conversations is challenging. There is a gap in the present literature in computationally analyzing how community members discuss the strengths and needs of the community. To address this gap, we introduce the task of identifying, extracting, and categorizing community needs and assets from conversational data using sophisticated natural language processing methods. To facilitate this task, we introduce the first dataset about community needs and assets consisting of 3,511 conversations from Reddit, annotated using crowdsourced wor
    
[^36]: AFLoRA: 自适应冻结低秩调整在大型模型参数高效微调中的应用

    AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models

    [https://arxiv.org/abs/2403.13269](https://arxiv.org/abs/2403.13269)

    AFLoRA是一种自适应冻结低秩调整方法，通过逐步冻结投影矩阵来提高性能，减少计算量，并提供对GLUE基准测试的最先进表现。

    

    我们提出了一种新颖的参数高效微调（PEFT）方法，称为自适应冻结低秩调整（AFLoRA）。具体地，对于每个预训练的冻结权重张量，我们添加一个可训练的低秩矩阵并行路径，即下投影和上投影矩阵，每个矩阵后面跟着一个特征变换向量。基于一种新颖的冻结分数，我们在微调过程中逐步冻结这些投影矩阵，以减少计算量并减轻过拟合。我们的实验结果表明，我们可以在GLUE基准测试中获得最先进的性能，平均改善高达0.85％，同时可减少高达9.5倍的平均可训练参数。在运行时间方面，与类似的PEFT备选方案相比，AFLoRA可以提供高达1.86倍的改进。除了我们方法的实际效用之外，我们还提供了关于训练

    arXiv:2403.13269v1 Announce Type: new  Abstract: We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as Adaptive Freezing of Low Rank Adaptation (AFLoRA). Specifically, for each pre-trained frozen weight tensor, we add a parallel path of trainable low-rank matrices, namely a down-projection and an up-projection matrix, each of which is followed by a feature transformation vector. Based on a novel freezing score, we the incrementally freeze these projection matrices during fine-tuning to reduce the computation and alleviate over-fitting. Our experimental results demonstrate that we can achieve state-of-the-art performance with an average improvement of up to $0.85\%$ as evaluated on GLUE benchmark while yeilding up to $9.5\times$ fewer average trainable parameters. While compared in terms of runtime, AFLoRA can yield up to $1.86\times$ improvement as opposed to similar PEFT alternatives. Besides the practical utility of our approach, we provide insights on the train
    
[^37]: Arcee的MergeKit：用于合并大型语言模型的工具包

    Arcee's MergeKit: A Toolkit for Merging Large Language Models

    [https://arxiv.org/abs/2403.13257](https://arxiv.org/abs/2403.13257)

    合并不同语言模型的参数，无需额外训练即可创建多任务模型，提升模型性能和多功能性，解决AI中的复杂挑战。

    

    开源语言模型领域的快速扩张为通过合并其参数来结合这些模型检查点的能力提供了机会。迁移学习的进步导致了大量针对特定任务进行微调的模型的开发，这些模型通常专门针对个别任务进行专门化，无法利用彼此的优势。模型合并促进了多任务模型的创建，无需额外的训练，为增强模型性能和多功能性提供了一个有前途的途径。通过保留原始模型的固有能力，模型合并解决了人工智能中的复杂挑战，包括灾难性遗忘和多任务学习的困难。为了支持这一不断扩大的研究领域，我们介绍了MergeKit，这是一个全面的、开源的库，旨在促进模型合并的应用。

    arXiv:2403.13257v1 Announce Type: new  Abstract: The rapid expansion of the open-source language model landscape presents an opportunity to merge the competencies of these model checkpoints by combining their parameters. Advances in transfer learning, the process of fine-tuning pre-trained models for specific tasks, has resulted in the development of vast amounts of task-specific models, typically specialized in individual tasks and unable to utilize each other's strengths. Model merging facilitates the creation of multitask models without the need for additional training, offering a promising avenue for enhancing model performance and versatility. By preserving the intrinsic capabilities of the original models, model merging addresses complex challenges in AI - including the difficulties of catastrophic forgetting and multi-task learning. To support this expanding area of research, we introduce MergeKit, a comprehensive, open-source library designed to facilitate the application of mo
    
[^38]: 使用解析语言结构进行文档作者分类

    Document Author Classification Using Parsed Language Structure

    [https://arxiv.org/abs/2403.13253](https://arxiv.org/abs/2403.13253)

    本文研究了使用解析语言结构来检测文档作者身份的新方法，通过统计自然语言解析器提取的语法结构信息进行了实证验证。

    

    多年来，人们一直对基于文本的统计属性来检测作者身份感兴趣，例如使用非情境词的出现率。在先前的研究中，这些技术已经被使用，例如确定《联邦党人文集》中所有文章的作者。这些方法在现代可能有助于检测伪造的或由AI创作的文章。统计自然语言解析器的进展引入了使用语法结构来检测作者身份的可能性。本文探讨了使用统计自然语言解析器提取的语法结构信息进行作者分类的新可能性。本文提供了一个概念验证，测试了基于语法结构的作者分类方法在一组“校样文本”上的效果，《联邦党人文集》和《桑迪顿》曾作为先前作者检测研究的测试案例。从中提取了几个特征。

    arXiv:2403.13253v1 Announce Type: new  Abstract: Over the years there has been ongoing interest in detecting authorship of a text based on statistical properties of the text, such as by using occurrence rates of noncontextual words. In previous work, these techniques have been used, for example, to determine authorship of all of \emph{The Federalist Papers}. Such methods may be useful in more modern times to detect fake or AI authorship. Progress in statistical natural language parsers introduces the possibility of using grammatical structure to detect authorship. In this paper we explore a new possibility for detecting authorship using grammatical structural information extracted using a statistical natural language parser. This paper provides a proof of concept, testing author classification based on grammatical structure on a set of "proof texts," The Federalist Papers and Sanditon which have been as test cases in previous authorship detection studies. Several features extracted fro
    
[^39]: 通过大型语言模型的知识蒸馏促进开放域对话系统中色情文本的检测

    Facilitating Pornographic Text Detection for Open-Domain Dialogue Systems via Knowledge Distillation of Large Language Models

    [https://arxiv.org/abs/2403.13250](https://arxiv.org/abs/2403.13250)

    通过知识蒸馏大型语言模型来标注数据集，以便检测开放域对话系统中的色情文本。

    

    人机交互对话中出现的色情内容可能对开放域对话系统的用户造成严重副作用。然而，有关检测人机交互对话中色情语言的研究是一个很少被研究的重要课题。为了在这个方向上取得进展，我们引入了CensorChat，一个旨在检测对话会话是否包含色情内容的对话监测数据集。为此，我们收集了现实生活中的人机交互对话，并将其分解为单个话语和单轮对话，最后一轮由聊天机器人发表。我们提出利用大型语言模型的知识蒸馏来注释数据集。具体来说，首先，原始数据集由四个开源的大型语言模型进行注释，通过多数票确定标签。其次，我们使用ChatGPT更新第一步中的空标签。

    arXiv:2403.13250v1 Announce Type: new  Abstract: Pornographic content occurring in human-machine interaction dialogues can cause severe side effects for users in open-domain dialogue systems. However, research on detecting pornographic language within human-machine interaction dialogues is an important subject that is rarely studied. To advance in this direction, we introduce CensorChat, a dialogue monitoring dataset aimed at detecting whether the dialogue session contains pornographic content. To this end, we collect real-life human-machine interaction dialogues in the wild and break them down into single utterances and single-turn dialogues, with the last utterance spoken by the chatbot. We propose utilizing knowledge distillation of large language models to annotate the dataset. Specifically, first, the raw dataset is annotated by four open-source large language models, with the majority vote determining the label. Second, we use ChatGPT to update the empty label from the first step
    
[^40]: 使用师生大型语言模型进行多约束分子生成

    Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model

    [https://arxiv.org/abs/2403.13244](https://arxiv.org/abs/2403.13244)

    介绍了一个多约束分子生成大型语言模型TSMMG，通过整合多个小模型和工具来帮助生成符合描述的新分子，在各种约束任务中表现优秀。

    

    尽管已经提出了各种模型和计算工具用于分子的结构和性质分析，但生成符合所有期望结构和性质的分子仍然是一个挑战。在这里，我们介绍了一个多约束分子生成大型语言模型TSMMG，类似于学生，该模型整合了来自各种小模型和工具（即“老师”）的知识。为了训练TSMMG，我们通过从这些‘老师’中提取的分子知识构建了大量文本-分子对，使其能够通过各种文本提示生成符合描述的新分子。我们通过实验证明，TSMMG在生成符合复杂、自然语言描述的两、三和四约束任务的分子方面表现出色，平均分子有效性超过99％，成功率分别为88.08％、65.27％和61.44％。该模型还ex

    arXiv:2403.13244v1 Announce Type: new  Abstract: While various models and computational tools have been proposed for structure and property analysis of molecules, generating molecules that conform to all desired structures and properties remains a challenge. Here, we introduce a multi-constraint molecular generation large language model, TSMMG, which, akin to a student, incorporates knowledge from various small models and tools, namely, the 'teachers'. To train TSMMG, we construct a large set of text-molecule pairs by extracting molecular knowledge from these 'teachers', enabling it to generate novel molecules that conform to the descriptions through various text prompts. We experimentally show that TSMMG remarkably performs in generating molecules meeting complex, natural language-described property requirements across two-, three-, and four-constraint tasks, with an average molecular validity of over 99% and success ratio of 88.08%, 65.27%, and 61.44%, respectively. The model also ex
    
[^41]: SumTra：一种用于少样本跨语言摘要的可微分流水线

    SumTra: A Differentiable Pipeline for Few-Shot Cross-Lingual Summarization

    [https://arxiv.org/abs/2403.13240](https://arxiv.org/abs/2403.13240)

    本文提出了一种用于少样本跨语言摘要的可微分流水线，通过重新审视摘要和翻译流程，实现了零样本性能和端到端的可微优势。

    

    跨语言摘要（XLS）在与输入文档语言不同的语言中生成摘要（例如，从英语到西班牙语），使目标语言的使用者能够简洁地了解内容。本文提出重新审视摘要和翻译流水线，其中摘要和翻译任务以序列方式执行。这种方法允许重复使用许多公开可用的资源进行单语摘要和翻译，获得非常具竞争力的零样本性能。此外，所提出的流水线是完全可微的端到端，使其能够充分利用少样本。

    arXiv:2403.13240v1 Announce Type: new  Abstract: Cross-lingual summarization (XLS) generates summaries in a language different from that of the input documents (e.g., English to Spanish), allowing speakers of the target language to gain a concise view of their content. In the present day, the predominant approach to this task is to take a performing, pretrained multilingual language model (LM) and fine-tune it for XLS on the language pairs of interest. However, the scarcity of fine-tuning samples makes this approach challenging in some cases. For this reason, in this paper we propose revisiting the summarize-and-translate pipeline, where the summarization and translation tasks are performed in a sequence. This approach allows reusing the many, publicly-available resources for monolingual summarization and translation, obtaining a very competitive zero-shot performance. In addition, the proposed pipeline is completely differentiable end-to-end, allowing it to take advantage of few-shot 
    
[^42]: 技术报告：BetterMixture竞赛解决方案

    Technical Report: Competition Solution For BetterMixture

    [https://arxiv.org/abs/2403.13233](https://arxiv.org/abs/2403.13233)

    本文介绍了针对BetterMixture挑战的解决方案，采用数据去重、质量过滤和多样性选择等方法，最终获得第三名。Ke-Data-Juicer作为解决方案的基础，展现了其在处理和优化大型语言模型数据方面的强大能力。

    

    在大规模模型蓬勃发展的时代，从庞大复杂的数据中选择和优化数据集，以提升大型语言模型性能，同时在有限的计算资源约束下，已成为一项重要挑战。本文详细介绍了我们针对BetterMixture挑战的解决方案，重点关注大型语言模型的微调数据混合。我们的方法获得第三名，包括数据去重、低级和高级质量过滤，以及多样性选择。我们解决方案的基础是Ke-Data-Juicer，是Data-Juicer的一个扩展，展示了其处理和优化大型语言模型数据的强大能力。

    arXiv:2403.13233v1 Announce Type: new  Abstract: In the era of flourishing large-scale models, the challenge of selecting and optimizing datasets from the vast and complex sea of data, to enhance the performance of large language models within the constraints of limited computational resources, has become paramount. This paper details our solution for the BetterMixture challenge, which focuses on the fine-tuning data mixing for large language models. Our approach, which secured third place, incorporates data deduplication, low-level and high-level quality filtering, and diversity selection. The foundation of our solution is Ke-Data-Juicer, an extension of Data-Juicer, demonstrating its robust capabilities in handling and optimizing data for large language models.
    
[^43]: 从表现性伤害到服务质量伤害:羊驼2安全保障的案例研究

    From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards

    [https://arxiv.org/abs/2403.13213](https://arxiv.org/abs/2403.13213)

    本文探讨了针对表现性伤害和服务质量伤害的羊驼2安全保障措施的有效性，并指出了大型语言模型在实用性和安全性之间的权衡关系。

    

    近期大型语言模型（LLM）的进展导致它们在各个领域被广泛采用。然而，这些进步也引入了额外的安全风险，并引发了对其对已经边缘化人群的不利影响的担忧。尽管存在越来越多的减轻措施来开发安全保障措施，比如监督式的安全定向微调和利用来自人类反馈的安全强化学习，但关于这些模型的安全性和内在偏见仍存在多重关注。此外，先前的研究已经证明，为了安全而优化的模型通常会展示夸大的安全行为，比如出于预防措施而倾向于不回应某些请求。因此，文献中已经记录了这些模型在实用性和安全性之间的明显权衡。在本文中，我们进一步研究了安全措施的有效性，通过评估...

    arXiv:2403.13213v1 Announce Type: cross  Abstract: Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations. Despite growing mitigation efforts to develop safety safeguards, such as supervised safety-oriented fine-tuning and leveraging safe reinforcement learning from human feedback, multiple concerns regarding the safety and ingrained biases in these models remain. Furthermore, previous work has demonstrated that models optimized for safety often display exaggerated safety behaviors, such as a tendency to refrain from responding to certain requests as a precautionary measure. As such, a clear trade-off between the helpfulness and safety of these models has been documented in the literature. In this paper, we further investigate the effectiveness of safety measures by evaluatin
    
[^44]: Wav2Gloss：从语音生成分词后的文字注释

    Wav2Gloss: Generating Interlinear Glossed Text from Speech

    [https://arxiv.org/abs/2403.13169](https://arxiv.org/abs/2403.13169)

    Wav2Gloss提出了从语音中自动提取语言注释的任务，并引入了第一个数据集Fieldwork，分析表明预先训练的解码器有助于翻译和注释，并且端到端的系统效果较好。

    

    世界上成千上万种语言面临灭绝的危险，这对文化身份和人类语言多样性构成了巨大威胁。分词后的文字注释（IGT）是一种语言注释形式，可以支持对这些语言社区进行文档编制和资源创建。IGT通常包括（1）转录，（2）形态分割，（3）文本注释 和（4）到主流语言的自由翻译。我们提出了Wav2Gloss：一个任务，从语音中自动提取这四个注释组件，并引入了第一个数据集Fieldwork，这是一个包含37种语言的语音语料库，所有这些都有标准格式和训练/评估集划分。

    arXiv:2403.13169v1 Announce Type: new  Abstract: Thousands of the world's languages are in danger of extinction--a tremendous threat to cultural identities and human language diversity. Interlinear Glossed Text (IGT) is a form of linguistic annotation that can support documentation and resource creation for these languages' communities. IGT typically consists of (1) transcriptions, (2) morphological segmentation, (3) glosses, and (4) free translations to a majority language. We propose Wav2Gloss: a task to extract these four annotation components automatically from speech, and introduce the first dataset to this end, Fieldwork: a corpus of speech with all these annotations covering 37 languages with standard formatting and train/dev/test splits. We compare end-to-end and cascaded Wav2Gloss methods, with analysis suggesting that pre-trained decoders assist with translation and glossing, that multi-task and multilingual approaches are underperformant, and that end-to-end systems perform 
    
[^45]: 自生成的回放记忆对持续神经机器翻译的影响

    Self-generated Replay Memories for Continual Neural Machine Translation

    [https://arxiv.org/abs/2403.13130](https://arxiv.org/abs/2403.13130)

    提出了一种利用神经机器翻译系统的生成能力来构建自生成回放记忆的方法，可以有效解决持续学习过程中的灾难性遗忘问题。

    

    现代神经机器翻译系统在多种不同语言中表现出色，并且不断改进。然而，它们对持续学习的能力仍然受到灾难性遗忘问题的严重限制。本研究利用编码器-解码器Transformer的关键属性，即其生成能力，提出了一种新颖的方法来持续学习神经机器翻译系统。我们展示了如何通过利用模型自身作为并行句子生成器来有效地学习由不同语言组成的经验流。我们在实证上证明了我们的方法可以抵消灾难性遗忘，而无需显式记忆训练数据。代码将在发表后公开提供。

    arXiv:2403.13130v1 Announce Type: new  Abstract: Modern Neural Machine Translation systems exhibit strong performance in several different languages and are constantly improving. Their ability to learn continuously is, however, still severely limited by the catastrophic forgetting issue. In this work, we leverage a key property of encoder-decoder Transformers, i.e. their generative ability, to propose a novel approach to continually learning Neural Machine Translation systems. We show how this can effectively learn on a stream of experiences comprising different languages, by leveraging a replay memory populated by using the model itself as a generator of parallel sentences. We empirically demonstrate that our approach can counteract catastrophic forgetting without requiring explicit memorization of training data. Code will be publicly available upon publication. Code: https://github.com/m-resta/sg-rep
    
[^46]: 一次编码，多次并行解码：高效Transformer解码

    Encode Once and Decode in Parallel: Efficient Transformer Decoding

    [https://arxiv.org/abs/2403.13112](https://arxiv.org/abs/2403.13112)

    提出了一种新的编码器-解码器模型配置，称为prompt-in-decoder（PiD），可以一次编码输入并并行解码输出，在结构化输出和问答任务中取得高效率，避免了重复输入编码，大幅减少了解码器的内存占用。

    

    基于Transformer的自然语言处理模型功能强大，但计算成本高，限制了部署场景。在专业领域中，微调的编码器-解码器模型备受青睐，可以胜过更大更通用的仅解码器模型，例如GPT-4。我们介绍了一种新的编码器-解码器模型配置，可以提高在结构化输出和问答任务中的效率，在这些任务中，需要从单个输入中产生多个输出。我们的方法，prompt-in-decoder（PiD），只对输入进行一次编码，并且并行解码输出，通过避免重复输入编码，从而减少解码器的内存占用，提升了训练和推断效率。我们实现了计算减少，大致随子任务数量增加而扩展，相比最先进模型，在对话状态追踪、摘要和问答任务中获得高达4.6倍的速度提升，并且性能相当或更好。我们发布了我们的训练/推断代码。

    arXiv:2403.13112v1 Announce Type: new  Abstract: Transformer-based NLP models are powerful but have high computational costs that limit deployment scenarios. Finetuned encoder-decoder models are popular in specialized domains and can outperform larger more generalized decoder-only models, such as GPT-4. We introduce a new configuration for encoder-decoder models that improves efficiency on structured output and question-answering tasks where multiple outputs are required of a single input. Our method, prompt-in-decoder (PiD), encodes the input once and decodes output in parallel, boosting both training and inference efficiency by avoiding duplicate input encoding, thereby reducing the decoder's memory footprint. We achieve computation reduction that roughly scales with the number of subtasks, gaining up to 4.6x speed-up over state-of-the-art models for dialogue state tracking, summarization, and question-answering tasks with comparable or better performance. We release our training/inf
    
[^47]: 面向法律文本的多级总结无监督问答系统

    Towards Unsupervised Question Answering System with Multi-level Summarization for Legal Text

    [https://arxiv.org/abs/2403.13107](https://arxiv.org/abs/2403.13107)

    提出了一种无监督问答系统，通过多级总结法对法律文本进行处理，实现了F1分数的显著提升

    

    这篇论文总结了团队SCaLAR在SemEval-2024任务5上的工作：民事程序中的法律论证推理。为了解决这个二元分类任务，由于涉及到的法律文本的复杂性而令人望而却步，我们提出了一种简单而又新颖的基于相似度和距离的无监督方法来生成标签。此外，我们探索了使用集成特征（包括CNN、GRU和LSTM）的多级Legal-Bert嵌入的融合。为了解决数据集中法律解释的冗长性，我们引入了基于T5的分段摘要，成功地保留了关键信息，提升了模型的性能。我们的无监督系统在开发集上见证了macro F1分数增加了20个百分点，在测试集上增加了10个百分点，考虑到其简单的架构，这是令人鼓舞的。

    arXiv:2403.13107v1 Announce Type: new  Abstract: This paper summarizes Team SCaLAR's work on SemEval-2024 Task 5: Legal Argument Reasoning in Civil Procedure. To address this Binary Classification task, which was daunting due to the complexity of the Legal Texts involved, we propose a simple yet novel similarity and distance-based unsupervised approach to generate labels. Further, we explore the Multi-level fusion of Legal-Bert embeddings using ensemble features, including CNN, GRU, and LSTM. To address the lengthy nature of Legal explanation in the dataset, we introduce T5-based segment-wise summarization, which successfully retained crucial information, enhancing the model's performance. Our unsupervised system witnessed a 20-point increase in macro F1-score on the development set and a 10-point increase on the test set, which is promising given its uncomplicated architecture.
    
[^48]: 认识你的非线性：Shapley互动揭示数据的潜在结构

    Knowing Your Nonlinearities: Shapley Interactions Reveal the Underlying Structure of Data

    [https://arxiv.org/abs/2403.13106](https://arxiv.org/abs/2403.13106)

    该论文使用Shapley Taylor互动指数（STII）分析了底层数据结构对各种模态、任务和架构中模型表征的影响，发现了语言模型和语音模型中的新颖现象，并展示了特征交互如何直观反映对象边界。

    

    测量非线性特征交互是理解许多模型中复杂归因模式的一种已建立的方法。本文使用Shapley Taylor互动指数（STII）来分析底层数据结构对多种模态、任务和架构中模型表征的影响。在考虑掩码和自回归语言模型（MLMs和ALMs）中的语言结构时，我们发现STII在惯用表达中增加，MLMs随句法距离扩展STII，更多地依赖语法在其非线性结构中相比ALMs。我们的语音模型研究反映了口腔张开程度决定音素根据上下文变化的数量的原则。最后，我们研究图像分类器并说明特征交互直观反映对象边界。我们广泛的结果展示了跨学科工作和领域之间的益处。

    arXiv:2403.13106v1 Announce Type: cross  Abstract: Measuring nonlinear feature interaction is an established approach to understanding complex patterns of attribution in many models. In this paper, we use Shapley Taylor interaction indices (STII) to analyze the impact of underlying data structure on model representations in a variety of modalities, tasks, and architectures. Considering linguistic structure in masked and auto-regressive language models (MLMs and ALMs), we find that STII increases within idiomatic expressions and that MLMs scale STII with syntactic distance, relying more on syntax in their nonlinear structure than ALMs do. Our speech model findings reflect the phonetic principal that the openness of the oral cavity determines how much a phoneme varies based on its context. Finally, we study image classifiers and illustrate that feature interactions intuitively reflect object boundaries. Our wide range of results illustrates the benefits of interdisciplinary work and doma
    
[^49]: 使用大型语言模型通过提示调整自动总结医患对话

    Automatic Summarization of Doctor-Patient Encounter Dialogues Using Large Language Model through Prompt Tuning

    [https://arxiv.org/abs/2403.13089](https://arxiv.org/abs/2403.13089)

    本研究提出了一种使用生成式大型语言模型对医患对话进行总结的方法，并通过提示调整算法指导模型进行临床文本总结，实现了在临床基准数据集上表现最佳的性能。

    

    自动文本总结（ATS）是一种新兴技术，可以帮助临床医生提供持续和协调的护理。本研究介绍了一种使用生成式大型语言模型（LLMs）对医患对话进行总结的方法。我们开发了提示调整算法来指导生成式LLMs对临床文本进行总结。我们研究了提示调整策略、软提示的大小以及GatorTronGPT的few-short学习能力，该模型是使用2770亿临床和通用英语词汇开发的、拥有高达200亿参数的生成式临床LLM。我们将GatorTronGPT与基于广泛使用的T5模型微调的先前解决方案进行了比较，使用了临床基准数据集MTS-DIALOG。实验结果表明，GatorTronGPT-20B模型在所有评估指标上均取得了最佳性能。所提出的解决方案具有较低的计算成本，因为在提示调整过程中不更新LLM参数。

    arXiv:2403.13089v1 Announce Type: new  Abstract: Automatic text summarization (ATS) is an emerging technology to assist clinicians in providing continuous and coordinated care. This study presents an approach to summarize doctor-patient dialogues using generative large language models (LLMs). We developed prompt-tuning algorithms to instruct generative LLMs to summarize clinical text. We examined the prompt-tuning strategies, the size of soft prompts, and the few-short learning ability of GatorTronGPT, a generative clinical LLM developed using 277 billion clinical and general English words with up to 20 billion parameters. We compared GatorTronGPT with a previous solution based on fine-tuning of a widely used T5 model, using a clinical benchmark dataset MTS-DIALOG. The experimental results show that the GatorTronGPT- 20B model achieved the best performance on all evaluation metrics. The proposed solution has a low computing cost as the LLM parameters are not updated during prompt-tunin
    
[^50]: BiLoRA：一种面向大型预训练模型的过度拟合鲁棒低秩适应的双层优化框架

    BiLoRA: A Bi-level Optimization Framework for Overfitting-Resilient Low-Rank Adaptation of Large Pre-trained Models

    [https://arxiv.org/abs/2403.13037](https://arxiv.org/abs/2403.13037)

    BiLoRA提出了一种基于双层优化框架的减轻过拟合的微调方法，通过对低秩增量矩阵进行参数化和将训练分为不同的子集，降低了对单一数据集过拟合的风险。

    

    低秩适应（LoRA）是一种用于微调大规模预训练模型以解决下游任务的流行方法，通过学习低秩增量矩阵。尽管LoRA及其变体相对于完全微调方法有效地减少了可训练参数的数量，但它们经常会在训练数据上过拟合，导致在测试数据上的次优泛化。为解决这一问题，我们介绍了BiLoRA，一种基于双层优化（BLO）的减轻过拟合微调方法。BiLoRA采用伪奇异值分解来参数化低秩增量矩阵，并将伪奇异向量和值的训练分成两个不同的训练数据子集。这种划分嵌入在BLO框架的不同层次中，有助于减轻对单一数据集过度拟合的风险。在涵盖自然语言理解和生成任务的十个数据集上进行测试，并应用于各种知名的大型预训练模型以验证其有效性。

    arXiv:2403.13037v1 Announce Type: cross  Abstract: Low-rank adaptation (LoRA) is a popular method for fine-tuning large-scale pre-trained models in downstream tasks by learning low-rank incremental matrices. Though LoRA and its variants effectively reduce the number of trainable parameters compared to full fine-tuning methods, they often overfit training data, resulting in sub-optimal generalization on test data. To address this problem, we introduce BiLoRA, an overfitting-alleviating fine-tuning approach based on bi-level optimization (BLO). BiLoRA employs pseudo singular value decomposition to parameterize low-rank incremental matrices and splits the training of pseudo singular vectors and values across two different subsets of training data. This division, embedded within separate levels of the BLO framework, mitigates the risk of overfitting to a single dataset. Tested on ten datasets covering natural language understanding and generation tasks and applied to various well-known lar
    
[^51]: RigorLLM：针对大型语言模型抵御不良内容的鲁棒防护栏

    RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content

    [https://arxiv.org/abs/2403.13031](https://arxiv.org/abs/2403.13031)

    RigorLLM提出了一种新颖的框架，旨在高效有效地调节LLMs的有害和不安全输入和输出，包括能量数据增强、最小-最大优化安全输入后缀，以及基于数据增强的鲁棒KNN与LLMs融合模型。

    

    大语言模型（LLMs）的最新进展展示了其在不同领域的各种任务中的显著能力。然而，LLMs中出现的偏见以及在恶意输入下产生有害内容的潜力，尤其是对抗性攻击下，都带来了重大挑战。本文提出了面向大型语言模型的鲁棒防护栏（RigorLLM），这是一个新颖的框架，旨在高效有效地调节LLMs的有害和不安全输入和输出。通过采用多方面的方法，包括通过朗之万动力学进行基于能量的训练数据增强、通过极小极大优化针对输入优化安全后缀，以及基于我们的数据增强将鲁棒KNN与LLMs融合的基于融合的模型，RigorLLM为有害内容的调节提供了强大的解决方案。我们的实验评估

    arXiv:2403.13031v1 Announce Type: cross  Abstract: Recent advancements in Large Language Models (LLMs) have showcased remarkable capabilities across various tasks in different domains. However, the emergence of biases and the potential for generating harmful content in LLMs, particularly under malicious inputs, pose significant challenges. Current mitigation strategies, while effective, are not resilient under adversarial attacks. This paper introduces Resilient Guardrails for Large Language Models (RigorLLM), a novel framework designed to efficiently and effectively moderate harmful and unsafe inputs and outputs for LLMs. By employing a multi-faceted approach that includes energy-based training data augmentation through Langevin dynamics, optimizing a safe suffix for inputs via minimax optimization, and integrating a fusion-based model combining robust KNN with LLMs based on our data augmentation, RigorLLM offers a robust solution to harmful content moderation. Our experimental evalua
    
[^52]: AutoTRIZ：利用TRIZ和大型语言模型的人工创意

    AutoTRIZ: Artificial Ideation with TRIZ and Large Language Models

    [https://arxiv.org/abs/2403.13002](https://arxiv.org/abs/2403.13002)

    本文提出了AutoTRIZ，一种利用大型语言模型自动化和增强TRIZ方法的人工创意工具，为设计自动化和可解释创意提供了一种新颖方法。

    

    研究人员和创新者在开发思维方法方面做出了巨大努力，比如形态分析和类比设计，以辅助工程设计创意，解决问题和推动创新。在这些方法中，TRIZ作为最著名的方法脱颖而出，被广泛应用于系统化创新。然而，TRIZ资源和概念的复杂性，以及其对用户知识、经验和推理能力的依赖，限制了其实用性。本文提出了AutoTRIZ，一种利用大型语言模型（LLMs）自动化和增强TRIZ方法的人工创意工具。通过利用LLMs的广泛知识和先进推理能力，AutoTRIZ提供了一种新颖的利用人工智能进行设计自动化和可解释创意的方法。我们通过对矛盾检测和比较方面的一致性实验来证明并评估AutoTRIZ的有效性。

    arXiv:2403.13002v1 Announce Type: cross  Abstract: Researchers and innovators have made enormous efforts in developing ideation methods, such as morphological analysis and design-by-analogy, to aid engineering design ideation for problem solving and innovation. Among these, TRIZ stands out as the most well-known approach, widely applied for systematic innovation. However, the complexity of TRIZ resources and concepts, coupled with its reliance on users' knowledge, experience, and reasoning capabilities, limits its practicability. This paper proposes AutoTRIZ, an artificial ideation tool that leverages large language models (LLMs) to automate and enhance the TRIZ methodology. By leveraging the broad knowledge and advanced reasoning capabilities of LLMs, AutoTRIZ offers a novel approach to design automation and interpretable ideation with artificial intelligence. We demonstrate and evaluate the effectiveness of AutoTRIZ through consistency experiments in contradiction detection and compa
    
[^53]: Duwak: 大型语言模型中的双重水印

    Duwak: Dual Watermarks in Large Language Models

    [https://arxiv.org/abs/2403.13000](https://arxiv.org/abs/2403.13000)

    Duwak提出了一种在大型语言模型中嵌入双重秘密模式的水印技术，可以显著提高水印的效率和质量。

    

    随着大型语言模型（LLM）在文本生成任务中的日益使用，审计它们的用途、管理它们的应用并减轻其潜在危害至关重要。本文提出了Duwak，通过在令牌概率分布和抽样方案中嵌入双重秘密模式，从根本上提高了水印的效率和质量。

    arXiv:2403.13000v1 Announce Type: cross  Abstract: As large language models (LLM) are increasingly used for text generation tasks, it is critical to audit their usages, govern their applications, and mitigate their potential harms. Existing watermark techniques are shown effective in embedding single human-imperceptible and machine-detectable patterns without significantly affecting generated text quality and semantics. However, the efficiency in detecting watermarks, i.e., the minimum number of tokens required to assert detection with significance and robustness against post-editing, is still debatable. In this paper, we propose, Duwak, to fundamentally enhance the efficiency and quality of watermarking by embedding dual secret patterns in both token probability distribution and sampling schemes. To mitigate expression degradation caused by biasing toward certain tokens, we design a contrastive search to watermark the sampling scheme, which minimizes the token repetition and enhances 
    
[^54]: 大型语言模型中的少样本代码生成中的提示选择和增强以及其在机器人控制中的应用

    Prompt Selection and Augmentation for Few Examples Code Generation in Large Language Model and its Application in Robotics Control

    [https://arxiv.org/abs/2403.12999](https://arxiv.org/abs/2403.12999)

    本文介绍了一个提示选择和增强算法，通过优化示例选择和增强，提高了大型语言模型在代码生成和机器人控制方面的性能。

    

    少样本提示和逐步推理已经增强了大型语言模型（LLMs）在处理包括代码生成在内的复杂任务的能力。在本文中，我们介绍了一个旨在改善数学推理和机器人臂操作的提示选择和增强算法。我们的方法结合了多阶段示例增强方案和示例选择方案。该算法通过选择一组增加多样性、最小化冗余并增加与问题相关性的示例来提高LLM性能。当与“思维编程”提示结合使用时，我们的算法在GSM8K和SVAMP基准测试中表现出性能改进，分别增加了0.3%和1.1%。此外，在模拟桌面环境中，我们的算法通过实现成功任务完成率提高了3.4%，并且成功完成任务的时间减少了。

    arXiv:2403.12999v1 Announce Type: cross  Abstract: Few-shot prompting and step-by-step reasoning have enhanced the capabilities of Large Language Models (LLMs) in tackling complex tasks including code generation. In this paper, we introduce a prompt selection and augmentation algorithm aimed at improving mathematical reasoning and robot arm operations. Our approach incorporates a multi-stage example augmentation scheme combined with an example selection scheme. This algorithm improves LLM performance by selecting a set of examples that increase diversity, minimize redundancy, and increase relevance to the question. When combined with the Program-of-Thought prompting, our algorithm demonstrates an improvement in performance on the GSM8K and SVAMP benchmarks, with increases of 0.3% and 1.1% respectively. Furthermore, in simulated tabletop environments, our algorithm surpasses the Code-as-Policies approach by achieving a 3.4% increase in successful task completions and a decrease of over 
    
[^55]: 当SMILES拥有语言：使用文本分类方法对药物SMILES字符串进行药物分类

    When SMILES have Language: Drug Classification using Text Classification Methods on Drug SMILES Strings

    [https://arxiv.org/abs/2403.12984](https://arxiv.org/abs/2403.12984)

    将药物SMILES字符串视为句子并利用文本分类方法进行药物分类，证实了通过简单的自然语言处理方法解决复杂问题的可能性

    

    复杂的化学结构，如药物，通常由SMILES字符串来定义，作为分子和键的序列。这些SMILES字符串在不同的基于机器学习的药物相关研究和表示工作中使用。在这项工作中，我们摆脱复杂的表示法，提出了一个问题：如果我们将药物SMILES视为常规句子，并进行文本分类以进行药物分类会怎样？我们的实验证实了这种可能性，获得了非常有竞争力的分数。该研究探讨了将每个原子和键视为句子组件的概念，利用基本的自然语言处理方法对药物类型进行分类，表明复杂的问题也可以用更简单的视角来解决。数据和代码可在此处找到：https://github.com/azminewasi/Drug-Classification-NLP。

    arXiv:2403.12984v1 Announce Type: cross  Abstract: Complex chemical structures, like drugs, are usually defined by SMILES strings as a sequence of molecules and bonds. These SMILES strings are used in different complex machine learning-based drug-related research and representation works. Escaping from complex representation, in this work, we pose a single question: What if we treat drug SMILES as conventional sentences and engage in text classification for drug classification? Our experiments affirm the possibility with very competitive scores. The study explores the notion of viewing each atom and bond as sentence components, employing basic NLP methods to categorize drug types, proving that complex problems can also be solved with simpler perspectives. The data and code are available here: https://github.com/azminewasi/Drug-Classification-NLP.
    
[^56]: C分析器：用于C程序的静态程序分析工具

    C Analyzer : A Static Program Analysis Tool for C Programs

    [https://arxiv.org/abs/2403.12973](https://arxiv.org/abs/2403.12973)

    该项目使用抽象解释技术开发了C分析器，可以对C程序进行静态分析，支持多个抽象域，提高程序验证的精度。

    

    在我们这个时代，当世界越来越依赖软件程序时，编写无bug、正确的程序至关重要。基于形式方法的程序验证可以通过检测安全关键系统中的运行时错误来保证这一点，以避免对人类生活可能造成的不利影响，节省时间和金钱。本项目尝试利用抽象解释技术对C程序进行静态分析。C分析器是一种用于C程序的静态分析工具。该C分析器的实现提供了一个可供多个抽象域使用的即插即用的架构。C分析器支持四个抽象域——区间、八角形、多面体和位矢。我们使用这些不同的域来提供程序验证所需的精度。C分析器工具使用LLVM C/C++编译器前端Clang API生成和遍历给定C程序的控制流图（CFG）。

    arXiv:2403.12973v1 Announce Type: cross  Abstract: In our times, when the world is increasingly becoming more dependent on software programs, writing bug-free, correct programs is crucial. Program verification based on formal methods can guarantee this by detecting run-time errors in safety-critical systems to avoid possible adverse impacts on human life and save time and money.   This project work tries to leverage Abstract Interpretation techniques for static analysis of C programs. C Analyzer is a tool developed for static analysis of C programs. This implementation of C Analyzer provides a plug-and-play domain architecture for multiple abstract domains to be used. C Analyzer supports four abstract domains - Interval, Octagon, Polyhedra, and Bit Vector. We use these different domains for required precision in program verification. C Analyzer tool uses LLVM C/C++ compiler frontend Clang API to generate and traverse the Control Flow Graph (CFG) of a given C program. This tool generate
    
[^57]: m&m's: 一个用于评估多步骤多模态任务工具使用的基准

    m&m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks

    [https://arxiv.org/abs/2403.11085](https://arxiv.org/abs/2403.11085)

    m&m's引入了一个包含4K+多步骤多模态任务的基准，涉及33种工具，用于评估LLM作为规划器的设计决策。

    

    现实世界中的多模态问题很少由单个机器学习模型解决，通常需要多步骤计算计划，涉及拼接多个模型。 工具增强型LLM极有可能自动化生成这种计算计划。然而，缺乏用于评估LLM作为多步骤多模态任务规划器的标准化基准，阻碍了对规划器设计决策的系统研究。LLM是否应一次性生成整个计划还是逐步生成？它们是否应该直接使用Python代码调用工具，还是通过类似JSON的结构化数据格式？反馈是否改善规划？为了回答这些问题以及更多问题，我们介绍了m&m's：一个基准，包含4K+个涉及33种工具的多步骤多模态任务，其中包括多模态模型、(免费)公共API和图像处理模块。对于每个任务查询，我们提供使用这种方法自动生成的计划。

    arXiv:2403.11085v1 Announce Type: cross  Abstract: Real-world multi-modal problems are rarely solved by a single machine learning model, and often require multi-step computational plans that involve stitching several models. Tool-augmented LLMs hold tremendous promise for automating the generation of such computational plans. However, the lack of standardized benchmarks for evaluating LLMs as planners for multi-step multi-modal tasks has prevented a systematic study of planner design decisions. Should LLMs generate a full plan in a single shot or step-by-step? Should they invoke tools directly with Python code or through structured data formats like JSON? Does feedback improve planning? To answer these questions and more, we introduce m&m's: a benchmark containing 4K+ multi-step multi-modal tasks involving 33 tools that include multi-modal models, (free) public APIs, and image processing modules. For each of these task queries, we provide automatically generated plans using this realis
    
[^58]: MIntRec2.0：用于多模态意图识别和对话中场外检测的大规模基准数据集

    MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations

    [https://arxiv.org/abs/2403.10943](https://arxiv.org/abs/2403.10943)

    MIntRec2.0介绍了一个旨在解决多模态意图识别和对话中场外检测挑战的大规模基准数据集。该数据集包含30个细粒度类别的1,245个对话和15,040个样本，其中包括逼真的场外样本，并丰富了发言者信息以支持多方对话研究。

    

    多模态意图识别面临重大挑战，需要整合来自现实世界背景的非语言形式，以增强对人类意图的理解。现有的基准数据集在规模上受限，并且在处理多轮对话互动中出现的场外样本时存在困难。我们介绍了MIntRec2.0，这是一个用于多方对话中的多模态意图识别的大规模基准数据集。它包含1,245个对话，15,040个样本，每个样本在30个细粒度类别的新意图分类中进行了注释。除了9,304个场内样本外，还包括5,736个出现在多轮上下文中的场外样本，这在现实场景中自然发生。此外，我们还提供了每个话语中发言者的详细信息，丰富了它在多方对话研究中的实用性。

    arXiv:2403.10943v1 Announce Type: cross  Abstract: Multimodal intent recognition poses significant challenges, requiring the incorporation of non-verbal modalities from real-world contexts to enhance the comprehension of human intentions. Existing benchmark datasets are limited in scale and suffer from difficulties in handling out-of-scope samples that arise in multi-turn conversational interactions. We introduce MIntRec2.0, a large-scale benchmark dataset for multimodal intent recognition in multi-party conversations. It contains 1,245 dialogues with 15,040 samples, each annotated within a new intent taxonomy of 30 fine-grained classes. Besides 9,304 in-scope samples, it also includes 5,736 out-of-scope samples appearing in multi-turn contexts, which naturally occur in real-world scenarios. Furthermore, we provide comprehensive information on the speakers in each utterance, enriching its utility for multi-party conversational research. We establish a general framework supporting the o
    
[^59]: 评估大语言模型作为对话推荐中生成用户模拟器

    Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation

    [https://arxiv.org/abs/2403.09738](https://arxiv.org/abs/2403.09738)

    大型语言模型作为生成式用户模拟器在对话推荐中展现出潜力，新的协议通过五个任务评估了语言模型模拟人类行为的准确程度，揭示了模型与人类行为的偏差，并提出了如何通过模型选择和提示策略减少这些偏差。

    

    合成用户是对话推荐系统评估中成本效益较高的真实用户代理。大型语言模型表现出在模拟类似人类行为方面的潜力，这引发了它们能否代表多样化用户群体的问题。我们引入了一个新的协议，用于衡量语言模型能够准确模拟对话推荐中人类行为的程度。该协议由五个任务组成，每个任务旨在评估合成用户应该表现出的关键特性：选择要谈论的物品，表达二进制偏好，表达开放式偏好，请求推荐以及提供反馈。通过对基准模拟器的评估，我们展示了这些任务有效地揭示了语言模型与人类行为的偏差，并提供了关于如何通过模型选择和提示策略减少这些偏差的见解。

    arXiv:2403.09738v1 Announce Type: cross  Abstract: Synthetic users are cost-effective proxies for real users in the evaluation of conversational recommender systems. Large language models show promise in simulating human-like behavior, raising the question of their ability to represent a diverse population of users. We introduce a new protocol to measure the degree to which language models can accurately emulate human behavior in conversational recommendation. This protocol is comprised of five tasks, each designed to evaluate a key property that a synthetic user should exhibit: choosing which items to talk about, expressing binary preferences, expressing open-ended preferences, requesting recommendations, and giving feedback. Through evaluation of baseline simulators, we demonstrate these tasks effectively reveal deviations of language models from human behavior, and offer insights on how to reduce the deviations with model selection and prompting strategies.
    
[^60]: SemEval-2024共享任务6: SHROOM，一个关于幻觉及相关可观察过度生成错误的共享任务

    SemEval-2024 Shared Task 6: SHROOM, a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes

    [https://arxiv.org/abs/2403.07726](https://arxiv.org/abs/2403.07726)

    本文介绍了SHROOM共享任务，重点关注检测幻觉，以及参与者使用的模型和策略。

    

    本文介绍了SHROOM的结果，这是一个专注于检测幻觉的共享任务：即自然语言生成（NLG）系统的输出流畅但不准确。这种过度生成的情况可能危及许多NLG应用，其中正确性往往至关重要。共享任务使用了一个新构建的数据集，包含4000个由5个标注者标记的模型输出，涵盖了3个NLP任务：机器翻译、释义生成和定义建模。 共享任务由58个不同用户组成的42支团队共同解决，其中27支选择撰写系统描述论文；他们共提交了超过300个预测集在共享任务的两个跟踪上。我们观察到这种方法如何被处理的一些关键趋势--许多参与者依赖少数模型，并经常依赖合成数据进行微调或零样本提示策略。

    arXiv:2403.07726v1 Announce Type: new  Abstract: This paper presents the results of the SHROOM, a shared task focused on detecting hallucinations: outputs from natural language generation (NLG) systems that are fluent, yet inaccurate. Such cases of overgeneration put in jeopardy many NLG applications, where correctness is often mission-critical. The shared task was conducted with a newly constructed dataset of 4000 model outputs labeled by 5 annotators each, spanning 3 NLP tasks: machine translation, paraphrase generation and definition modeling.   The shared task was tackled by a total of 58 different users grouped in 42 teams, out of which 27 elected to write a system description paper; collectively, they submitted over 300 prediction sets on both tracks of the shared task. We observe a number of key trends in how this approach was tackled -- many participants rely on a handful of model, and often rely either on synthetic data for fine-tuning or zero-shot prompting strategies. While 
    
[^61]: 基于语言模型的新型数据增强框架用于去偏见观点摘要

    Large, Small or Both: A Novel Data Augmentation Framework Based on Language Models for Debiasing Opinion Summarization

    [https://arxiv.org/abs/2403.07693](https://arxiv.org/abs/2403.07693)

    使用大型和小型语言模型的新型数据增强框架，通过重新生成评论来实现观点摘要的去偏见化，避免了大型语言模型数据增强可能存在的问题和高昂成本。

    

    现有观点摘要数据集中超过70％的评论是积极的，当前的观点摘要方法在给定负面文本的情况下不愿生成负面摘要，造成情感偏见。为了解决这种情感偏见，一个直接的方法是基于大型语言模型生成额外的数据，平衡数据集的情感分布，而不过分依赖特定框架。然而，基于大型语言模型的数据增强面临两个缺点：1）增强数据中的潜在问题或毒性；2）昂贵的成本。因此，在本文中，我们提出了一个基于大型和小型语言模型的新型数据增强框架，用于去偏见观点摘要。具体而言，通过大型语言模型重写正面文本获得了小规模合成的负面评论。然后，基于生成的内容训练一个解耦重构模型。

    arXiv:2403.07693v1 Announce Type: cross  Abstract: As more than 70$\%$ of reviews in the existing opinion summary data set are positive, current opinion summarization approaches are reluctant to generate negative summaries given the input of negative texts. To address such sentiment bias, a direct approach without the over-reliance on a specific framework is to generate additional data based on large language models to balance the emotional distribution of the dataset. However, data augmentation based on large language models faces two disadvantages: 1) the potential issues or toxicity in the augmented data; 2) the expensive costs. Therefore, in this paper, we propose a novel data augmentation framework based on both large and small language models for debiasing opinion summarization. In specific, a small size of synthesized negative reviews is obtained by rewriting the positive text via a large language model. Then, a disentangle reconstruction model is trained based on the generated 
    
[^62]: 噪声的力量：朝着统一的多模态知识图表示框架

    The Power of Noise: Toward a Unified Multi-modal Knowledge Graph Representation Framework

    [https://arxiv.org/abs/2403.06832](https://arxiv.org/abs/2403.06832)

    提出了一种利用噪声掩模的Transformer-based架构SNAG方法，实现了多模态知识图表示中实体嵌入的最先进性能

    

    多模态预训练的进展凸显出鲁棒的多模态知识图（MMKG）表示学习框架的必要性。此框架对于在规模上将结构化知识整合到多模态大型语言模型（LLMs）中至关重要，旨在减轻知识误解和多模态幻觉等问题。在这项工作中，为了评估模型准确嵌入MMKG中的实体的能力，我们专注于两个广泛研究的任务：多模态知识图完成（MKGC）和多模态实体对齐（MMEA）。在此基础上，我们提出了一种新颖的SNAG方法，该方法利用基于Transformer的架构，并配备了模态级噪声掩模，以在知识图中鲁棒地集成多模态实体特征。通过为MKGC和MMEA都引入特定的训练目标，我们的方法在总共十个数据集上（三个用于MKGC和...

    arXiv:2403.06832v1 Announce Type: cross  Abstract: The advancement of Multi-modal Pre-training highlights the necessity for a robust Multi-Modal Knowledge Graph (MMKG) representation learning framework. This framework is crucial for integrating structured knowledge into multi-modal Large Language Models (LLMs) at scale, aiming to alleviate issues like knowledge misconceptions and multi-modal hallucinations. In this work, to evaluate models' ability to accurately embed entities within MMKGs, we focus on two widely researched tasks: Multi-modal Knowledge Graph Completion (MKGC) and Multi-modal Entity Alignment (MMEA). Building on this foundation, we propose a novel SNAG method that utilizes a Transformer-based architecture equipped with modality-level noise masking for the robust integration of multi-modal entity features in KGs. By incorporating specific training objectives for both MKGC and MMEA, our approach achieves SOTA performance across a total of ten datasets (three for MKGC and 
    
[^63]: 为少样本示例选择设计信息度量

    Designing Informative Metrics for Few-Shot Example Selection

    [https://arxiv.org/abs/2403.03861](https://arxiv.org/abs/2403.03861)

    提出了一种基于复杂度的提示选择方法，用于将示例与测试句子的句法-语义复杂度对齐，在少样本NER任务中取得了显著的性能提升。

    

    预训练语言模型（PLMs）在提供适当格式的示例时展现出了卓越的少样本学习能力。然而，选择“最佳”示例仍然是一个未解决的挑战。我们提出了一种基于复杂度的提示选择方法，适用于序列标注任务。该方法避免了训练一个专门用于选择示例的模型，而是使用特定的度量标准来对齐测试句子和示例的句法-语义复杂度。我们使用句子和单词级别的度量标准，将示例的复杂度与考虑中的（测试）句子进行匹配。我们的结果表明，我们的方法能够从PLMs中提取出更好的性能：在少样本NER上实现了最先进的性能，在CoNLL2003数据集上对GPT-4的F1分数实现了5%的绝对改善。我们还在像GPT-j-6B这样的较小模型中看到了高达28.85个点（F1/Acc.）的显著增益。

    arXiv:2403.03861v1 Announce Type: new  Abstract: Pretrained language models (PLMs) have shown remarkable few-shot learning capabilities when provided with properly formatted examples. However, selecting the "best" examples remains an open challenge. We propose a complexity-based prompt selection approach for sequence tagging tasks. This approach avoids the training of a dedicated model for selection of examples, and instead uses certain metrics to align the syntactico-semantic complexity of test sentences and examples. We use both sentence- and word-level metrics to match the complexity of examples to the (test) sentence being considered. Our results demonstrate that our approach extracts greater performance from PLMs: it achieves state-of-the-art performance on few-shot NER, achieving a 5% absolute improvement in F1 score on the CoNLL2003 dataset for GPT-4. We also see large gains of upto 28.85 points (F1/Acc.) in smaller models like GPT-j-6B.
    
[^64]: 在寻找真相：一种审问方法用于幻觉检测

    In Search of Truth: An Interrogation Approach to Hallucination Detection

    [https://arxiv.org/abs/2403.02889](https://arxiv.org/abs/2403.02889)

    提出了一种用于在大型语言模型中检测幻觉的新方法，解决了这些模型在各种现实场景中应用时遇到的关键问题，通过对多个数据集和LLMs进行广泛评估，展示了该方法的有效性。

    

    尽管大型语言模型（LLMs）取得了许多进展并且以前所未有的速度快速发展，但由于各种原因，它们对我们日常生活的各个方面的影响和整合仍然有限。一个阻碍它们广泛应用的关键因素是幻觉的发生，即LLMs创造出听起来真实但偏离事实真相的答案。在本文中，我们提出了一种新颖的方法用于检测大型语言模型中的幻觉，这解决了这些模型在各种现实场景中应用的一个关键问题。通过对多个数据集和LLMs进行广泛评估，包括Llama-2，我们研究了各种最新LLMs的幻觉水平，并展示了我们的方法在自动检测它们方面的有效性。值得注意的是，我们在一个特定实验中观察到Llama-2达到62%的幻觉水平，而我们的方法在没有依赖的情况下实现了87%的平衡准确率（B-ACC）。

    arXiv:2403.02889v1 Announce Type: new  Abstract: Despite the many advances of Large Language Models (LLMs) and their unprecedented rapid evolution, their impact and integration into every facet of our daily lives is limited due to various reasons. One critical factor hindering their widespread adoption is the occurrence of hallucinations, where LLMs invent answers that sound realistic, yet drift away from factual truth. In this paper, we present a novel method for detecting hallucinations in large language models, which tackles a critical issue in the adoption of these models in various real-world scenarios. Through extensive evaluations across multiple datasets and LLMs, including Llama-2, we study the hallucination levels of various recent LLMs and demonstrate the effectiveness of our method to automatically detect them. Notably, we observe up to 62% hallucinations for Llama-2 in a specific experiment, where our method achieves a Balanced Accuracy (B-ACC) of 87%, all without relying 
    
[^65]: 通过语义感知置换训练来缓解逆转诅咒

    Mitigating Reversal Curse via Semantic-aware Permutation Training

    [https://arxiv.org/abs/2403.00758](https://arxiv.org/abs/2403.00758)

    逆转诅咒问题是导致因果语言模型无法进行双向推理的根本原因之一，在这篇论文中，我们提出了通过语义感知的置换训练来缓解这一问题。

    

    大型语言模型（LLM）在各种任务中取得了令人印象深刻的表现，然而最近的研究表明，因果关系的LLM遭遇了“逆转诅咒”。一个典型的例子是，模型知道“A的父亲是B”，但无法推理出“B的孩子是A”。这一局限性对人工通用智能（AGI）的进展构成了挑战，因为它暗示了模型在理解和应用双向推理方面存在差距。本文首先进行了大量评估，并确定了逆转诅咒的根本原因在于训练和推断阶段之间的词序不同，即因果语言模型在训练数据中预测先行词的能力不足。因此，考虑到在训练数据上进行排列可以被视为潜在解决方案，因为这可以使模型预测先行词或标记。然而，先前的排列方法可能受到截断影响。

    arXiv:2403.00758v1 Announce Type: cross  Abstract: While large language models (LLMs) have achieved impressive performance across diverse tasks, recent studies showcase that causal LLMs suffer from the "reversal curse". It is a typical example that the model knows "A's father is B", but is unable to reason "B's child is A". This limitation poses a challenge to the advancement of artificial general intelligence (AGI), as it suggests a gap in the models' ability to comprehend and apply bidirectional reasoning. In this paper, we first conduct substantial evaluation and identify that the root cause of the reversal curse lies in the different word order between the training and inference stage, namely, the poor ability of causal language models to predict antecedent words within the training data. Accordingly, permutation on the training data is considered as a potential solution, since this can make the model predict antecedent words or tokens. However, previous permutation methods may dis
    
[^66]: AgentOhana：为有效智能体学习设计统一数据和训练流水线

    AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning

    [https://arxiv.org/abs/2402.15506](https://arxiv.org/abs/2402.15506)

    AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。

    

    由大型语言模型（LLMs）提供支持的自主智能体引起了重大研究关注。然而，充分利用LLMs的潜力进行基于智能体的任务面临困难，这是由于具有多轮轨迹的多样化数据源的异构性。在本文中，我们介绍AgentOhana作为解决这些挑战的综合解决方案。AgentOhana从不同环境中聚合智能体轨迹，涵盖了各种情景。它精心地将这些轨迹标准化和统一到一致的格式中，简化了为智能体训练优化的通用数据加载器的创建。通过数据统一，我们的训练流水线在不同数据源之间保持平衡，并在数据集划分和模型训练过程中保持设备之间的独立随机性。此外，我们还介绍了xLAM-v0.1，一个大动作模式

    arXiv:2402.15506v1 Announce Type: new  Abstract: Autonomous agents powered by large language models (LLMs) have garnered significant research attention. However, fully harnessing the potential of LLMs for agent-based tasks presents inherent challenges due to the heterogeneous nature of diverse data sources featuring multi-turn trajectories. In this paper, we introduce \textbf{AgentOhana} as a comprehensive solution to address these challenges. \textit{AgentOhana} aggregates agent trajectories from distinct environments, spanning a wide array of scenarios. It meticulously standardizes and unifies these trajectories into a consistent format, streamlining the creation of a generic data loader optimized for agent training. Leveraging the data unification, our training pipeline maintains equilibrium across different data sources and preserves independent randomness across devices during dataset partitioning and model training. Additionally, we present \textbf{xLAM-v0.1}, a large action mode
    
[^67]: 增强Amharic-LLaMA: 整合特定任务与生成数据集

    Enhancing Amharic-LLaMA: Integrating Task Specific and Generative Datasets

    [https://arxiv.org/abs/2402.08015](https://arxiv.org/abs/2402.08015)

    本研究通过整合任务特定和生成数据集来增强Amharic-LLaMA模型，提高了阿姆哈拉语言模型的性能。他们通过创建阿姆哈拉语指令微调数据集和微调模型，在不同的NLP任务中取得了有希望的结果。

    

    大型语言模型（LLM）因其在理解和生成人类语言方面的出色表现而在自然语言处理（NLP）研究中受到了很多关注。然而，资源匮乏的语言因缺乏资源而被落下。在这项工作中，我们致力于通过整合特定任务和生成数据集来增强LLaMA-2-Amharic模型，以提高阿姆哈拉语的语言模型性能。我们创建了一个阿姆哈拉语指令微调数据集，并对LLaMA-2-Amharic模型进行了微调。经过微调的模型在不同的NLP任务中表现出有希望的结果。我们开源了我们的数据集创建流程、指令数据集、训练模型和评估输出，以促进对这些模型的语言特定研究。

    Large language models (LLMs) have received a lot of attention in natural language processing (NLP) research because of their exceptional performance in understanding and generating human languages. However, low-resource languages are left behind due to the unavailability of resources. In this work, we focus on enhancing the LLaMA-2-Amharic model by integrating task-specific and generative datasets to improve language model performance for Amharic. We compile an Amharic instruction fine-tuning dataset and fine-tuned LLaMA-2-Amharic model. The fine-tuned model shows promising results in different NLP tasks. We open-source our dataset creation pipeline, instruction datasets, trained models, and evaluation outputs to promote language-specific studies on these models.
    
[^68]: 大型语言模型的过度推理和冗余计算

    Over-Reasoning and Redundant Calculation of Large Language Models

    [https://arxiv.org/abs/2401.11467](https://arxiv.org/abs/2401.11467)

    本文研究表明，大型语言模型在回答问题时倾向于生成冗余的计算和推理，即使这些计算并不必要。

    

    大型语言模型（LLMs）可以逐步解决问题。尽管这种思维链（CoT）推理提升了LLMs的性能，但目前尚不清楚LLMs何时会使用CoT，以及这些CoT是否总是必要的来回答问题。本文表明，LLMs倾向于在一个手动构建的数学问答数据集GSM8K-Zero上生成冗余的计算和推理。GSM8K-Zero被构建为这样的问答可以在不做任何计算的情况下回答，但LLMs，包括Llama-2模型和Claude-2，倾向于生成冗长且不必要的计算来回答问题。我们还进行了实验解释为什么LLMs会生成冗余的计算和推理。GSM8K-Zero可以在https://github.com/d223302/Over-Reasoning-of-LLMs 和https://huggingface.co/datasets/dcml0714/GSM8K-Zero 公开获取。

    arXiv:2401.11467v2 Announce Type: replace  Abstract: Large language models (LLMs) can solve problems step-by-step. While this chain-of-thought (CoT) reasoning boosts LLMs' performance, it is unclear if LLMs \textit{know} when to use CoT and whether those CoT are always necessary to answer the question. This paper shows that LLMs tend to generate redundant calculations and reasoning on a manually constructed math QA dataset, GSM8K-Zero. GSM8K-Zero is constructed such that the questions can be answered without any calculations, but LLMs, including Llama-2 models and Claude-2, tend to generate lengthy and unnecessary calculations to answer the questions. We also conduct experiments to explain why LLMs generate redundant calculations and reasonings. GSM8K-Zero is publicly available at https://github.com/d223302/Over-Reasoning-of-LLMs and https://huggingface.co/datasets/dcml0714/GSM8K-Zero.
    
[^69]: PsyChat：面向客户的心理健康支持对话系统

    PsyChat: A Client-Centric Dialogue System for Mental Health Support

    [https://arxiv.org/abs/2312.04262](https://arxiv.org/abs/2312.04262)

    PsyChat 提出了一个面向客户的对话系统，通过识别客户行为并结合辅导员策略，在线提供心理支持，弥补了现有心理健康支持中对话系统忽视客户行为的不足。

    

    对话系统越来越多地整合到心理健康支持中，以帮助客户促进探索，获得洞察力，采取行动，最终自愈。一个实用且用户友好的对话系统应当以客户为中心，专注于客户的行为。然而，目前公开可用于心理健康支持的对话系统往往只集中于辅导员的策略，而忽视了客户表达的行为。这可能导致对话系统产生不合理或不适当的辅导策略以及相应的回应。为解决这一问题，我们提出了PsyChat，一个通过在线聊天提供心理支持的面向客户的对话系统。该对话系统包括五个模块：客户行为识别、辅导员策略选择、输入打包器、回应生成器和回应选择。自动和人工评估表明…

    arXiv:2312.04262v2 Announce Type: replace  Abstract: Dialogue systems are increasingly integrated into mental health support to help clients facilitate exploration, gain insight, take action, and ultimately heal themselves. A practical and user-friendly dialogue system should be client-centric, focusing on the client's behaviors. However, existing dialogue systems publicly available for mental health support often concentrate solely on the counselor's strategies rather than the behaviors expressed by clients. This can lead to unreasonable or inappropriate counseling strategies and corresponding responses generated by the dialogue system. To address this issue, we propose PsyChat, a client-centric dialogue system that provides psychological support through online chat. The client-centric dialogue system comprises five modules: client behavior recognition, counselor strategy selection, input packer, response generator, and response selection. Both automatic and human evaluations demonstr
    
[^70]: 校准语言模型必须出现幻觉

    Calibrated Language Models Must Hallucinate

    [https://arxiv.org/abs/2311.14648](https://arxiv.org/abs/2311.14648)

    该研究揭示了预训练语言模型在生成某些类型的事实时具有固有的统计下限，这与变压器LM架构或数据质量无关。

    

    最近的语言模型频繁生成虚假但听起来似乎合理的文本。这种“幻觉”是语言为基础的人工智能系统可用性的障碍，并可能伤害依赖其输出的人们。这项工作表明，预先训练的语言模型幻想某些类型的事实具有固有的统计下限，与变压器LM架构或数据质量无关。对于那些无法从训练数据中确定真实性的“任意”事实，我们展示了对于满足生成语言模型适当统计校准条件的语言模型，幻觉必须以某种速率发生。具体而言，如果任何事实的最大概率被限制，我们表明生成幻觉的概率接近于在训练数据中仅发生一次的事实的比例（“Good-Turing”估计），即使考虑到可能的情况

    arXiv:2311.14648v3 Announce Type: replace  Abstract: Recent language models generate false but plausible-sounding text with surprising frequency. Such "hallucinations" are an obstacle to the usability of language-based AI systems and can harm people who rely upon their outputs. This work shows that there is an inherent statistical lower-bound on the rate that pretrained language models hallucinate certain types of facts, having nothing to do with the transformer LM architecture or data quality. For "arbitrary" facts whose veracity cannot be determined from the training data, we show that hallucinations must occur at a certain rate for language models that satisfy a statistical calibration condition appropriate for generative language models. Specifically, if the maximum probability of any fact is bounded, we show that the probability of generating a hallucination is close to the fraction of facts that occur exactly once in the training data (a "Good-Turing" estimate), even assuming ide
    
[^71]: LLatrieval：LLM-验证检索用于可验证生成

    LLatrieval: LLM-Verified Retrieval for Verifiable Generation

    [https://arxiv.org/abs/2311.07838](https://arxiv.org/abs/2311.07838)

    可验证生成中检索的文件不仅帮助LLM生成正确答案，还作为用户验证LLM输出的证据，但目前广泛使用的检索器已成为性能瓶颈，需要解决。

    

    可验证生成旨在使大型语言模型（LLM）生成具有支撑文件的文本，这使用户能够灵活验证答案，并使LLM的输出更可靠。检索在可验证生成中起着至关重要的作用。具体而言，检索到的文件不仅补充知识以帮助LLM生成正确答案，还作为支持用户验证LLM输出的证据。然而，广泛使用的检索器成为整个流程的瓶颈，并限制了整体性能。由于通常具有的参数比大型语言模型少得多，并且尚未证明能够良好地扩展到LLM的规模，因此它们的能力通常比LLMs差。如果检索器未能正确找到支持文件，则LLM将无法生成正确和可验证的答案，这会掩盖LLM的显著能力。为解决这些问

    arXiv:2311.07838v2 Announce Type: replace  Abstract: Verifiable generation aims to let the large language model (LLM) generate text with supporting documents, which enables the user to flexibly verify the answer and makes the LLM's output more reliable. Retrieval plays a crucial role in verifiable generation. Specifically, the retrieved documents not only supplement knowledge to help the LLM generate correct answers, but also serve as supporting evidence for the user to verify the LLM's output. However, the widely used retrievers become the bottleneck of the entire pipeline and limit the overall performance. Their capabilities are usually inferior to LLMs since they often have much fewer parameters than the large language model and have not been demonstrated to scale well to the size of LLMs. If the retriever does not correctly find the supporting documents, the LLM can not generate the correct and verifiable answer, which overshadows the LLM's remarkable abilities. To address these li
    
[^72]: AutoMix: 自动混合语言模型

    AutoMix: Automatically Mixing Language Models

    [https://arxiv.org/abs/2310.12963](https://arxiv.org/abs/2310.12963)

    AutoMix提出了一种自动选择更大语言模型处理查询的方法，通过少量样本自我验证和元验证器提高了输出的可靠性，可显著提高计算成本和性能的优化，实验证明性能优于基线最多86%.

    

    大型语言模型(LLMs)现在可以通过各种尺寸和配置的云API提供商获得。虽然这种多样性提供了广泛的选择，但有效利用这些选项以优化计算成本和性能仍然具有挑战性。在这项工作中，我们提出了AutoMix，一种根据较小LM的输出的近似正确性来策略性地将查询路由到更大LM的方法。AutoMix的核心是一种少量样本的自我验证机制，它可以估计输出的可靠性而无需训练。鉴于验证可能存在噪声，我们在AutoMix中使用了元验证器来提高这些评估的准确性。我们在五个基于上下文的推理数据集上使用LLAMA2-13B和GPT-4进行实验，结果表明AutoMix超越了已建立的基线，每单位成本的增量效益提高了最多86%。我们的代码和数据可在https://github.c找到

    arXiv:2310.12963v3 Announce Type: replace  Abstract: Large language models (LLMs) are now available from cloud API providers in various sizes and configurations. While this diversity offers a broad spectrum of choices, effectively leveraging the options to optimize computational cost and performance remains challenging. In this work, we present AutoMix, an approach that strategically routes queries to larger LMs, based on the approximate correctness of outputs from a smaller LM. Central to AutoMix is a few-shot self-verification mechanism, which estimates the reliability of its own outputs without requiring training. Given that verifications can be noisy, we employ a meta-verifier in AutoMix to refine the accuracy of these assessments. Our experiments using LLAMA2-13B and GPT-4, on five context-grounded reasoning datasets demonstrate that AutoMix surpasses established baselines, improving the incremental benefit per cost by up to 86%. Our code and data are available at https://github.c
    
[^73]: ParlaSent多语种训练数据集用于议会会议情感识别

    The ParlaSent Multilingual Training Dataset for Sentiment Identification in Parliamentary Proceedings

    [https://arxiv.org/abs/2309.09783](https://arxiv.org/abs/2309.09783)

    该研究介绍了ParlaSent多语种训练数据集，以及首个专门针对政治科学应用的领域特定多语种变压器语言模型，通过在议会数据上进行预训练，显著提高了情感识别模型在议会会议中的性能。

    

    这篇论文介绍了一个新的训练数据集，其中包含7种语言的句子，手动标注了情感，并在一系列实验中用于训练一个针对议会会议的情感识别器。该论文还介绍了第一个专门针对政治科学应用的领域特定多语种变压器语言模型，该模型额外在27个欧洲议会的议会文件中预先训练了17.2亿字。我们展示了额外在议会数据上进行预训练如何显著提高模型在下游任务中的性能，即在议会会议中进行情感识别。我们进一步表明，我们的多语种模型在未在微调中见过的语言上表现非常好，并且来自其他语言的额外微调数据显著提高了目标议会的结果。

    arXiv:2309.09783v2 Announce Type: replace  Abstract: The paper presents a new training dataset of sentences in 7 languages, manually annotated for sentiment, which are used in a series of experiments focused on training a robust sentiment identifier for parliamentary proceedings. The paper additionally introduces the first domain-specific multilingual transformer language model for political science applications, which was additionally pre-trained on 1.72 billion words from parliamentary proceedings of 27 European parliaments. We present experiments demonstrating how the additional pre-training on parliamentary data can significantly improve the model downstream performance, in our case, sentiment identification in parliamentary proceedings. We further show that our multilingual model performs very well on languages not seen during fine-tuning, and that additional fine-tuning data from other languages significantly improves the target parliament's results. The paper makes an important 
    
[^74]: 探索疾病中的语义信息：用于中文疾病规范化的简单数据增强技术

    Exploring semantic information in disease: Simple Data Augmentation Techniques for Chinese Disease Normalization

    [https://arxiv.org/abs/2306.01931](https://arxiv.org/abs/2306.01931)

    提出了一组定制的数据增强技术，旨在利用疾病名称中的语义信息，增强模型对疾病名称的语义细微差别和分类结构的理解

    

    疾病名称规范化是医学领域中的重要任务。它将以各种格式编写的疾病名称分类为标准化名称，作为智能医疗系统中各种与疾病相关功能的基本组件。然而，现有疾病名称规范化系统面临的最大障碍是训练数据严重不足。虽然数据增强是解决数据稀缺性的有效方法，但我们的研究发现，传统的数据增强技术通常会阻碍任务性能，主要是由于疾病名称的多轴和多粒度性质。因此，我们介绍了一组定制的数据增强技术，旨在利用疾病名称中固有的语义信息。这些技术旨在增强模型对疾病名称的语义复杂性和分类结构的理解。

    arXiv:2306.01931v2 Announce Type: replace  Abstract: Disease name normalization is an important task in the medical domain. It classifies disease names written in various formats into standardized names, serving as a fundamental component in smart healthcare systems for various disease-related functions. Nevertheless, the most significant obstacle to existing disease name normalization systems is the severe shortage of training data. While data augmentation is a powerful approach for addressing data scarcity, our findings reveal that conventional data augmentation techniques often impede task performance, primarily due to the multi-axis and multi-granularity nature of disease names. Consequently, we introduce a set of customized data augmentation techniques designed to leverage the semantic information inherent in disease names. These techniques aim to enhance the model's understanding of the semantic intricacies and classification structure of disease names. Through extensive experime
    
[^75]: SDA：用于对比句子表示学习的简单离散增强

    SDA: Simple Discrete Augmentation for Contrastive Sentence Representation Learning

    [https://arxiv.org/abs/2210.03963](https://arxiv.org/abs/2210.03963)

    提出了三种简单而有效的离散句子增强方案：标点插入、情态动词和双重否定，用于对比句子表示学习。

    

    对比学习最近在无监督句子表示中取得了令人满意的性能。然而，作为一个基本要素，数据增强协议尚未得到充分探讨。本文通过重新审视现有方法，并尝试假设合理数据增强方法的期望，提出了三种简单而有效的离散句子增强方案：标点插入、情态动词和双重否定。

    arXiv:2210.03963v2 Announce Type: replace  Abstract: Contrastive learning has recently achieved compelling performance in unsupervised sentence representation. As an essential element, data augmentation protocols, however, have not been well explored. The pioneering work SimCSE resorting to a simple dropout mechanism (viewed as continuous augmentation) surprisingly dominates discrete augmentations such as cropping, word deletion, and synonym replacement as reported. To understand the underlying rationales, we revisit existing approaches and attempt to hypothesize the desiderata of reasonable data augmentation methods: balance of semantic consistency and expression diversity. We then develop three simple yet effective discrete sentence augmentation schemes: punctuation insertion, modal verbs, and double negation. They act as minimal noises at lexical level to produce diverse forms of sentences. Furthermore, standard negation is capitalized on to generate negative samples for alleviating
    
[^76]: 不要责怪注释人员：偏见已经开始于注释指令

    Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions

    [https://arxiv.org/abs/2205.00415](https://arxiv.org/abs/2205.00415)

    基准数据集中存在的指令偏见可能导致对模型性能的高估，模型泛化能力受到影响。

    

    近年来，自然语言理解（NLU）的进展主要是由基准驱动的。这些基准通常通过众包收集，注释人员根据数据集创建者制定的注释指令编写示例。在这项工作中，我们假设注释人员会注意到众包指令中的模式，使他们写出许多相似的示例，随后这些示例在收集的数据中被过度呈现。我们研究了这种偏见形式，称之为指令偏见，在最近的14个NLU基准中展示了指令示例通常表现出具体模式，这些模式被工人群体传播到收集的数据中。这扩展了先前的工作（Geva等，2019年），提出了一个新的关注点，即我们是否在模拟数据集创建者的指令，而不是任务本身。通过一系列实验，我们展示了指令偏见确实可能导致对模型性能的过高估计，并且模型难以泛化。

    arXiv:2205.00415v3 Announce Type: replace  Abstract: In recent years, progress in NLU has been driven by benchmarks. These benchmarks are typically collected by crowdsourcing, where annotators write examples based on annotation instructions crafted by dataset creators. In this work, we hypothesize that annotators pick up on patterns in the crowdsourcing instructions, which bias them to write many similar examples that are then over-represented in the collected data. We study this form of bias, termed instruction bias, in 14 recent NLU benchmarks, showing that instruction examples often exhibit concrete patterns, which are propagated by crowdworkers to the collected data. This extends previous work (Geva et al., 2019) and raises a new concern of whether we are modeling the dataset creator's instructions, rather than the task. Through a series of experiments, we show that, indeed, instruction bias can lead to overestimation of model performance, and that models struggle to generalize bey
    
[^77]: BayesPrompt: 通过无偏领域抽象在少样本推理上指导大规模预训练语言模型

    BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction. (arXiv:2401.14166v1 [cs.CL])

    [http://arxiv.org/abs/2401.14166](http://arxiv.org/abs/2401.14166)

    BayesPrompt通过无偏领域抽象解决大规模预训练语言模型在少样本推理中的泛化问题。

    

    作为一种基于大规模预训练语言模型（PLMs）的新颖有效的微调范式，prompt-tuning旨在缩小下游任务与预训练目标之间的差距。虽然prompt-tuning在各种任务中取得了持续进展，但这种方法仍然存在一个持久的缺陷：prompt-tuning方法无法泛化到特定的少样本模式。从分布分析的角度来看，我们揭示了这一现象背后的内在问题是PLMs中包含过多的概念知识和目标下游领域的缩减知识，两者共同导致PLMs在普遍的知识嵌入空间中错误地定位与目标领域相对应的知识分布。为此，我们直观地探索了以无偏方式逼近下游任务的完整目标领域，并通过抽象这样的领域生成有区别的提示，从而提供了无歧义的信息。

    As a novel and effective fine-tuning paradigm based on large-scale pre-trained language models (PLMs), prompt-tuning aims to reduce the gap between downstream tasks and pre-training objectives. While prompt-tuning has yielded continuous advancements in various tasks, such an approach still remains a persistent defect: prompt-tuning methods fail to generalize to specific few-shot patterns. From the perspective of distribution analyses, we disclose that the intrinsic issues behind the phenomenon are the over-multitudinous conceptual knowledge contained in PLMs and the abridged knowledge for target downstream domains, which jointly result in that PLMs mis-locate the knowledge distributions corresponding to the target domains in the universal knowledge embedding space. To this end, we intuitively explore to approximate the unabridged target domains of downstream tasks in a debiased manner, and then abstract such domains to generate discriminative prompts, thereby providing the de-ambiguous
    
[^78]: 评估大型语言模型上越狱攻击效果的方法研究

    AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on Large Language Models. (arXiv:2401.09002v1 [cs.CL])

    [http://arxiv.org/abs/2401.09002](http://arxiv.org/abs/2401.09002)

    本研究提出一种新方法评估大型语言模型上越狱攻击效果，引入粗粒度和细粒度评估框架，提供了更全面和细致的评估角度，并开发了专门的真实数据集作为基准，为未来研究建立了基础资源。

    

    在我们的研究中，我们开创性地提出了一种评估大型语言模型（LLMs）上越狱攻击效果的新方法，与传统的健壮性评估方法不同。我们的研究引入了两个不同的评估框架：粗粒度评估和细粒度评估。每个框架都使用从0到1的评分范围，提供了独特的视角，能够更全面和细致地评估攻击效果，并帮助攻击者更好地优化攻击提示。此外，我们还开发了一个专门用于越狱任务的全面的真实数据集。这个数据集不仅是我们当前研究的关键基准，也为未来研究建立了一个基础资源，可以在这个不断发展的领域中进行一致和比较的分析。通过与传统评估方法的精心比较，我们发现我们的评估方法与之相一致。

    In our research, we pioneer a novel approach to evaluate the effectiveness of jailbreak attacks on Large Language Models (LLMs), such as GPT-4 and LLaMa2, diverging from traditional robustness-focused binary evaluations. Our study introduces two distinct evaluation frameworks: a coarse-grained evaluation and a fine-grained evaluation. Each framework, using a scoring range from 0 to 1, offers a unique perspective, enabling a more comprehensive and nuanced evaluation of attack effectiveness and empowering attackers to refine their attack prompts with greater understanding. Furthermore, we have developed a comprehensive ground truth dataset specifically tailored for jailbreak tasks. This dataset not only serves as a crucial benchmark for our current study but also establishes a foundational resource for future research, enabling consistent and comparative analyses in this evolving field. Upon meticulous comparison with traditional evaluation methods, we discovered that our evaluation alig
    
[^79]: 无需分词的大型语言模型能够以更准确的格式生成中国古典诗词

    Token-free LLMs Can Generate Chinese Classical Poetry with More Accurate Format. (arXiv:2401.03512v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.03512](http://arxiv.org/abs/2401.03512)

    本文提出了一种无需分词的大型语言模型（LLMs）来生成中国古典诗词，并解决了格式不准确性的问题。验证了现有基于分词的模型在字符和分词之间的关系方面的知识有限，并展示了如何通过定制模型解决这一问题。

    

    经过微调的大型语言模型（如ChatGPT和Qwen-chat）能够根据人类的指令生成中国古典诗词。虽然语言模型在内容方面表现良好，但通常在格式上存在问题，每行字符的数量有时过多或不足。由于大多数最新的语言模型是基于分词的，我们认为格式不准确是由于"分词规划"任务的难度，即语言模型需要准确知道每个分词中包含多少个字符，并基于这个知识进行长度控制规划。本文首先通过展示现有的基于分词的大型语言模型在分词和字符之间的关系方面知识有限来验证我们的假设。我们使用了拼写比赛探测程序，并发现Qwen-chat在近15%的中文拼写测试中失败。然后，我们展示了一个基于分词的模型可以轻松定制成无需分词的模型（对于中文来说），从而能够很大程度上解决格式准确性问题。

    Finetuned large language models (such as ChatGPT and Qwen-chat) can generate Chinese classical poetry following human's instructions. LLMs perform well in content, but are usually lacking in format, with occasionally excess or insufficient number of characters in each line. Since most SOTA LLMs are token-based, we assume that the format inaccuracy is due to the difficulty of the "token planning" task, which means that the LLM need to know exactly how much characters are contained in each token and do length-control planning based on that knowledge. In this paper, we first confirm our assumption by showing that existing token-based large language models has limited knowledge on token-character relationship. We use a spelling bee probing procedure, and find that Qwen-chat failed in nearly 15% Chinese spelling test. We then show that a token-based model can be easily tailored into a token-free model (in terms of Chinese), which can largely solve the format accuracy problem. Our tailoring 
    
[^80]: 利用近无限历史的通用检索增强医学预测模型

    General-Purpose Retrieval-Enhanced Medical Prediction Model Using Near-Infinite History. (arXiv:2310.20204v1 [cs.LG])

    [http://arxiv.org/abs/2310.20204](http://arxiv.org/abs/2310.20204)

    基于电子健康记录，我们提出了一种称为REMed的检索增强医学预测模型，通过无限评估临床事件并自动选择相关事件进行预测，消除了人工特征选择和观察窗口的限制，并在实验中表现出优异的效果。

    

    基于电子健康记录（EHRs）开发临床预测模型（例如死亡预测）通常依赖于专家意见进行特征选择和调整观测窗口大小。这给专家带来负担并在开发过程中造成瓶颈。我们提出了一种检索增强的医学预测模型（REMed），以应对这些挑战。REMed可以基本评估无限量的临床事件，选择相关的事件并进行预测。这种方法有效地消除了需要手动进行特征选择并实时观察的需要。我们通过对27个临床任务和两个公开可用的EHR数据集的独立队列实验验证了这些特性，结果显示REMed优于其他现代架构，它们旨在处理尽可能多的事件。值得注意的是，我们发现REMed的偏好与医学专家的偏好密切相似。我们期望我们的方法能显著加速该领域的发展。

    Developing clinical prediction models (e.g., mortality prediction) based on electronic health records (EHRs) typically relies on expert opinion for feature selection and adjusting observation window size. This burdens experts and creates a bottleneck in the development process. We propose Retrieval-Enhanced Medical prediction model (REMed) to address such challenges. REMed can essentially evaluate an unlimited number of clinical events, select the relevant ones, and make predictions. This approach effectively eliminates the need for manual feature selection and enables an unrestricted observation window. We verified these properties through experiments on 27 clinical tasks and two independent cohorts from publicly available EHR datasets, where REMed outperformed other contemporary architectures that aim to handle as many events as possible. Notably, we found that the preferences of REMed align closely with those of medical experts. We expect our approach to significantly expedite the d
    
[^81]: 基于思维链的Transformer的表达能力

    The Expresssive Power of Transformers with Chain of Thought. (arXiv:2310.07923v1 [cs.LG])

    [http://arxiv.org/abs/2310.07923](http://arxiv.org/abs/2310.07923)

    本论文研究基于思维链的Transformer的表达能力，通过允许使用中间生成的方式提高了Transformer的推理能力，并发现线性数量的解码步骤在标准计算复杂度下增加了明显的新能力。

    

    最近的理论研究发现了一些出人意料地简单的推理问题，例如检查图中是否存在连接的两个节点，或模拟有限状态机，这些问题被证明无法由立即读取输入后回答的标准Transformer解决。然而，在实践中，通过允许Transformer使用“思维链”或“草稿纸”，即在回答之前生成并依赖一系列中间token，可以改善其推理能力。基于此，我们问：这种中间生成是否从根本上扩展了仅有解码器的Transformer的计算能力？我们表明答案是肯定的，但增加的程度关键取决于中间生成的数量。例如，我们发现相对于输入长度来说，具有对数级解码步骤的Transformer解码器仅略微推动了标准Transformer的极限，而线性数量的解码步骤则增加了明显的新能力（在标准计算复杂度下）。

    Recent theoretical work has identified surprisingly simple reasoning problems, such as checking if two nodes in a graph are connected or simulating finite-state machines, that are provably unsolvable by standard transformers that answer immediately after reading their input. However, in practice, transformers' reasoning can be improved by allowing them to use a "chain of thought" or "scratchpad", i.e., generate and condition on a sequence of intermediate tokens before answering. Motivated by this, we ask: Does such intermediate generation fundamentally extend the computational power of a decoder-only transformer? We show that the answer is yes, but the amount of increase depends crucially on the amount of intermediate generation. For instance, we find that transformer decoders with a logarithmic number of decoding steps (w.r.t. the input length) push the limits of standard transformers only slightly, while a linear number of decoding steps adds a clear new ability (under standard compl
    
[^82]: BooookScore: LLM时代中对书籍长度摘要的系统探索

    BooookScore: A systematic exploration of book-length summarization in the era of LLMs. (arXiv:2310.00785v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00785](http://arxiv.org/abs/2310.00785)

    本文对LLM模型进行了系统探索，以解决对超过上下文窗口大小的书籍进行摘要的问题，并通过两种提示工作流实施了基于LLM的书籍长度摘要器的连贯性研究。通过对100本书的GPT-4生成摘要的人工注释，发现了八种常见的连贯性错误。

    

    对于超过大型语言模型（LLMs）上下文窗口大小的书籍长度文档（>100K标记）进行摘要需要首先将输入文档分成较小的块，然后提示LLM合并、更新和压缩块级摘要。尽管这个任务的复杂性和重要性，但由于评估的困难，它尚未得到有意义的研究：现有的书籍长度摘要数据集（例如BookSum）在大多数公共LLM的预训练数据中，而现有的评估方法难以捕捉现代LLM摘要器的错误。在本文中，我们首次研究通过两种提示工作流实施的基于LLM的书籍长度摘要器的连贯性：（1）分层合并块级摘要，（2）逐步更新一个运行摘要。我们对100本最近出版的书籍的GPT-4生成摘要获得了1193个细粒度的人工注释，并确定了LLMs产生的八种常见的连贯性错误。

    Summarizing book-length documents (>100K tokens) that exceed the context window size of large language models (LLMs) requires first breaking the input document into smaller chunks and then prompting an LLM to merge, update, and compress chunk-level summaries. Despite the complexity and importance of this task, it has yet to be meaningfully studied due to the challenges of evaluation: existing book-length summarization datasets (e.g., BookSum) are in the pretraining data of most public LLMs, and existing evaluation methods struggle to capture errors made by modern LLM summarizers. In this paper, we present the first study of the coherence of LLM-based book-length summarizers implemented via two prompting workflows: (1) hierarchically merging chunk-level summaries, and (2) incrementally updating a running summary. We obtain 1193 fine-grained human annotations on GPT-4 generated summaries of 100 recently-published books and identify eight common types of coherence errors made by LLMs. Bec
    
[^83]: ChEDDAR: 在EFL写作教育中的学生-ChatGPT对话

    ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education. (arXiv:2309.13243v1 [cs.CL])

    [http://arxiv.org/abs/2309.13243](http://arxiv.org/abs/2309.13243)

    这项研究介绍了ChEDDAR，一个在EFL写作教育中应用的学生-ChatGPT对话数据集。该研究分析了学生对生成型AI的使用模式和感知，并为教育背景下的任务导向对话系统建立了基准结果。

    

    尽管将生成型AI应用于教育领域已有不少进展，但对于学生和AI系统之间大规模且真实的互动的实证分析仍然很有限。在本研究中，我们介绍了ChEDDAR，即ChatGPT和EFL学习者的对话数据集，该数据集是在一个学期长的纵向实验中收集的，研究对象包括212名参加英语作为外语（EFL）写作课程的大学生。学生被要求通过与ChatGPT的对话来修改他们的文章。ChEDDAR包括对话日志，话语级别的文章编辑历史，自我评价满意度和学生意图，以及记录他们目标和整体体验的会话级别的前后调查。我们分析了学生对生成型AI的使用模式和感知，以及他们的意图和满意度。作为基础性步骤，我们为教育背景下任务导向对话系统的两个关键任务建立了基准结果：在……

    The integration of generative AI in education is expanding, yet empirical analyses of large-scale, real-world interactions between students and AI systems still remain limited. In this study, we present ChEDDAR, ChatGPT & EFL Learner's Dialogue Dataset As Revising an essay, which is collected from a semester-long longitudinal experiment involving 212 college students enrolled in English as Foreign Langauge (EFL) writing courses. The students were asked to revise their essays through dialogues with ChatGPT. ChEDDAR includes a conversation log, utterance-level essay edit history, self-rated satisfaction, and students' intent, in addition to session-level pre-and-post surveys documenting their objectives and overall experiences. We analyze students' usage patterns and perceptions regarding generative AI with respect to their intent and satisfaction. As a foundational step, we establish baseline results for two pivotal tasks in task-oriented dialogue systems within educational contexts: in
    
[^84]: CTC-based语音识别的单模聚合方法

    Unimodal Aggregation for CTC-based Speech Recognition. (arXiv:2309.08150v1 [cs.CL])

    [http://arxiv.org/abs/2309.08150](http://arxiv.org/abs/2309.08150)

    本文提出了一种在CTC-based语音识别中用于学习更好的特征表示和缩短序列长度的单模聚合方法(UMA)，通过分割和集成同一文本标记的特征帧，实现了更低的识别错误和计算复杂度。实验证明，UMA在普通话数据集上表现出较好的性能，并且通过集成自条件CTC可以进一步提高性能。

    

    本文针对非自回归自动语音识别进行研究。提出了一种单模聚合（UMA）方法，用于对属于同一文本标记的特征帧进行分割和集成，从而学习更好的文本标记特征表示。特征帧和权重都来自于编码器。然后，使用单模权重集成特征帧，并经过解码器进一步处理。训练时采用了连接主义时间分类（CTC）损失。与常规CTC相比，所提出的方法学习到了更好的特征表示，并缩短了序列长度，从而降低了识别错误和计算复杂度。在三个普通话数据集上的实验结果表明，UMA相比其他先进的非自回归方法（如自条件CTC）表现出更好或相当的性能。此外，通过将自条件CTC集成到所提出的框架中，性能可以进一步显著提高。

    This paper works on non-autoregressive automatic speech recognition. A unimodal aggregation (UMA) is proposed to segment and integrate the feature frames that belong to the same text token, and thus to learn better feature representations for text tokens. The frame-wise features and weights are both derived from an encoder. Then, the feature frames with unimodal weights are integrated and further processed by a decoder. Connectionist temporal classification (CTC) loss is applied for training. Compared to the regular CTC, the proposed method learns better feature representations and shortens the sequence length, resulting in lower recognition error and computational complexity. Experiments on three Mandarin datasets show that UMA demonstrates superior or comparable performance to other advanced non-autoregressive methods, such as self-conditioned CTC. Moreover, by integrating self-conditioned CTC into the proposed framework, the performance can be further noticeably improved.
    
[^85]: MMICL：多模态上下文学习增强视觉-语言模型

    MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning. (arXiv:2309.07915v1 [cs.CL])

    [http://arxiv.org/abs/2309.07915](http://arxiv.org/abs/2309.07915)

    MMICL提出了一种用于视觉-语言模型的架构和训练数据设计，以解决VLM在理解复杂多模态提示方面的困难。

    

    从深度学习的复苏开始，借助大型语言模型（LLM）的视觉-语言模型（VLM）变得非常流行。然而，尽管LLM可以利用丰富的背景知识和任务信息进行上下文学习，大多数VLM在理解复杂的多模态提示（包含多个图像）方面仍然面临困难。这个问题可以追溯到VLM的架构设计或预训练数据。具体来说，当前的VLM主要强调利用带有单个图像的多模态数据，而不是带有交错多个图像和文本的多模态提示。尽管一些新提出的VLM可以处理带有多个图像的用户提示，但预训练数据没有提供比从Web抓取时交错图像和文本更复杂的多模态提示。我们提出了MMICL，从模型和数据的角度来解决这个问题。我们引入了一个精心设计的架构，能够无缝地集成视觉和语言信息，并提供更丰富的多模态训练数据。

    Starting from the resurgence of deep learning, vision-language models (VLMs) benefiting from large language models (LLMs) have never been so popular. However, while LLMs can utilize extensive background knowledge and task information with in-context learning, most VLMs still struggle with understanding complex multi-modal prompts with multiple images. The issue can traced back to the architectural design of VLMs or pre-training data. Specifically, the current VLMs primarily emphasize utilizing multi-modal data with a single image some, rather than multi-modal prompts with interleaved multiple images and text. Even though some newly proposed VLMs could handle user prompts with multiple images, pre-training data does not provide more sophisticated multi-modal prompts than interleaved image and text crawled from the web. We propose MMICL to address the issue by considering both the model and data perspectives. We introduce a well-designed architecture capable of seamlessly integrating vis
    
[^86]: Whisper能够进行基于语境的语音学习吗？

    Can Whisper perform speech-based in-context learning. (arXiv:2309.07081v1 [eess.AS])

    [http://arxiv.org/abs/2309.07081](http://arxiv.org/abs/2309.07081)

    本文研究了Whisper自动语音识别模型的语境学习能力，并提出了一种基于语境的语音学习方法，用于在测试时适应。通过实验验证了该方法在中文方言上的有效性，可以显著减少单词错误率。通过进一步优化选择技术可以进一步提高效率。

    

    本文研究了OpenAI发布的Whisper自动语音识别（ASR）模型的语境学习能力。提出了一种新的基于语境的语音学习（SICL）方法，用于测试时适应，可以在没有梯度下降的情况下减少单词错误率（WER），只需要少量标记的语音样本。使用中文方言进行语言级别的适应实验表明，在将SICL应用于孤立词ASR时，可以在两个方言上使用任意大小的Whisper模型实现一致且显著的WER相对降低，平均为32.3%。基于k最近邻的上下文示例选择技术可以进一步提高SICL的效率，平均相对WER降低率为36.4%。通过说话人适应或连续语音识别任务来验证了这些发现，并且两者都实现了显著的相对WER降低。还提供了详细的定量分析。

    This paper investigates the in-context learning abilities of the Whisper automatic speech recognition (ASR) models released by OpenAI. A novel speech-based in-context learning (SICL) approach is proposed for test-time adaptation, which can reduce the word error rates (WERs) with only a small number of labelled speech samples without gradient descent. Language-level adaptation experiments using Chinese dialects showed that when applying SICL to isolated word ASR, consistent and considerable relative WER reductions can be achieved using Whisper models of any size on two dialects, which is on average 32.3%. A k-nearest-neighbours-based in-context example selection technique can be applied to further improve the efficiency of SICL, which can increase the average relative WER reduction to 36.4%. The findings are verified using speaker adaptation or continuous speech recognition tasks, and both achieved considerable relative WER reductions. Detailed quantitative analyses are also provided to
    
[^87]: 测量和改进视觉-语言模型中的思维链推理

    Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models. (arXiv:2309.04461v1 [cs.CL])

    [http://arxiv.org/abs/2309.04461](http://arxiv.org/abs/2309.04461)

    本研究探索了视觉-语言模型展示人类推理能力的能力，并提出了一种基于思维链的一致性度量。通过一个流水线和已有数据集，建立了一个基准来测量这种推理能力。

    

    最近，视觉-语言模型（VLMs）作为能解析关于视觉内容的自然查询并生成类人输出的视觉助手，展示出了强大的功效。在这项工作中，我们探索了这些模型展示基于所感知信息的类人推理的能力。为了解决关于它们的推理能力到底有多一致和有多基于实际的一个重要疑虑，我们还测量了这些模型的推理一致性。我们通过提出一种基于思维链（CoT）的一致性度量来实现这一目标。然而，这样的评估需要涵盖高层次推理和细节推理链的基准，这是一项昂贵的任务。我们通过提出LLM-Human-in-the-Loop流水线来应对这一挑战，该流水线显著降低了成本，同时确保生成高质量的数据集。基于这个流水线和现有的粗粒度注释数据集，我们构建了CURE基准来同时测量两者。

    Vision-language models (VLMs) have recently demonstrated strong efficacy as visual assistants that can parse natural queries about the visual content and generate human-like outputs. In this work, we explore the ability of these models to demonstrate human-like reasoning based on the perceived information. To address a crucial concern regarding the extent to which their reasoning capabilities are fully consistent and grounded, we also measure the reasoning consistency of these models. We achieve this by proposing a chain-of-thought (CoT) based consistency measure. However, such an evaluation requires a benchmark that encompasses both high-level inference and detailed reasoning chains, which is costly. We tackle this challenge by proposing a LLM-Human-in-the-Loop pipeline, which notably reduces cost while simultaneously ensuring the generation of a high-quality dataset. Based on this pipeline and the existing coarse-grained annotated dataset, we build the CURE benchmark to measure both 
    
[^88]: HAE-RAE Bench: 评估语言模型对韩国知识的表现

    HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models. (arXiv:2309.02706v1 [cs.CL])

    [http://arxiv.org/abs/2309.02706](http://arxiv.org/abs/2309.02706)

    HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。

    

    在大规模预训练的语言模型(LLMs)在各种任务中展现出了显著的能力，但是对非英语语言的关注在这个领域的研究中有限。为了弥补这一空白并评估语言模型在韩语语言和文化方面的熟练程度，我们提出了HAE-RAE Bench，在词汇、历史和一般知识等6个任务上进行评估。我们对语言模型在这个基准上的评估突出了使用大型特定语言模型(LLSMs)与像GPT-3.5这样的全面通用模型相比的潜在优势。值得注意的是，我们的研究发现，比GPT-3.5约小13倍的模型，可以在语言特定知识检索方面展现出类似的性能水平。这一观察强调了在训练专业级语言特定模型时同质语料库的重要性。相反，当这些较小的模型在......

    Large Language Models (LLMs) pretrained on massive corpora exhibit remarkable capabilities across a wide range of tasks, however, the attention given to non-English languages has been limited in this field of research. To address this gap and assess the proficiency of language models in the Korean language and culture, we present HAE-RAE Bench, covering 6 tasks including vocabulary, history, and general knowledge. Our evaluation of language models on this benchmark highlights the potential advantages of employing Large Language-Specific Models(LLSMs) over a comprehensive, universal model like GPT-3.5. Remarkably, our study reveals that models approximately 13 times smaller than GPT-3.5 can exhibit similar performance levels in terms of language-specific knowledge retrieval. This observation underscores the importance of homogeneous corpora for training professional-level language-specific models. On the contrary, we also observe a perplexing performance dip in these smaller LMs when th
    
[^89]: 使用信息瓶颈引导的文本扩散过程增强短语表示的关键词提取方法

    Enhancing Phrase Representation by Information Bottleneck Guided Text Diffusion Process for Keyphrase Extraction. (arXiv:2308.08739v1 [cs.CL])

    [http://arxiv.org/abs/2308.08739](http://arxiv.org/abs/2308.08739)

    本研究提出了一种利用信息瓶颈引导的文本扩散过程来增强短语表示的关键词提取方法。该方法充分利用关键词信息，通过优化排名网络和变分信息瓶颈来提高关键词提取的效果。

    

    关键词提取(KPE)是自然语言处理中的一个重要任务，用于从给定文档中提取关键词。许多现有的监督方法将KPE视为序列标注、跨度级分类或生成任务。然而，这些方法缺乏利用关键词信息的能力，可能导致结果有偏差。在本研究中，我们提出了Diff-KPE，它利用监督的变分信息瓶颈(VIB)来引导文本扩散过程，生成增强的关键词表示。Diff-KPE首先根据整个文档生成所需的关键词嵌入，然后将生成的关键词嵌入注入到每个短语表示中。然后，通过排名网络和VIB同时进行排名损失和分类损失的优化。Diff-KPE的设计允许我们利用关键词和文档的信息对每个候选短语进行排名。

    Keyphrase extraction (KPE) is an important task in Natural Language Processing for many scenarios, which aims to extract keyphrases that are present in a given document. Many existing supervised methods treat KPE as sequential labeling, span-level classification, or generative tasks. However, these methods lack the ability to utilize keyphrase information, which may result in biased results. In this study, we propose Diff-KPE, which leverages the supervised Variational Information Bottleneck (VIB) to guide the text diffusion process for generating enhanced keyphrase representations. Diff-KPE first generates the desired keyphrase embeddings conditioned on the entire document and then injects the generated keyphrase embeddings into each phrase representation. A ranking network and VIB are then optimized together with rank loss and classification loss, respectively. This design of Diff-KPE allows us to rank each candidate phrase by utilizing both the information of keyphrases and the docu
    
[^90]: 超越识别：用于语言模型的多位水印技术

    Advancing Beyond Identification: Multi-bit Watermark for Language Models. (arXiv:2308.00221v1 [cs.CL])

    [http://arxiv.org/abs/2308.00221](http://arxiv.org/abs/2308.00221)

    本研究提出了一种用于语言模型的多位水印技术——COLOR，可在语言模型生成过程中嵌入可追踪的多位信息，实现了提取水印、即时嵌入和维持文本质量等功能，同时允许零位检测。初步实验显示成功在中等长度的文本中嵌入了32位消息，准确率为91.9％。这项研究有效推进了对语言模型滥用的反制策略。

    

    本研究旨在积极应对大型语言模型在检测机器生成文本方面的滥用。尽管现有方法侧重于检测，但某些恶意滥用需要跟踪对手用户以进行反制。为了解决这个问题，我们提出了“多位水印通过颜色编码”（COLOR）的方法，在语言模型生成过程中嵌入可追踪的多位信息。利用零位水印技术的优势（Kirchenbauer等，2023a），COLOR实现了在没有模型访问权限的情况下提取水印、即时嵌入和维持文本质量的能力，同时允许零位检测。初步实验表明，在中等长度的文本（约500个标记）中成功嵌入了32位消息，准确率为91.9％。这项工作有效地推进了对语言模型滥用进行反制的策略。

    This study aims to proactively tackle misuse of large language models beyond identification of machine-generated text. While existing methods focus on detection, some malicious misuses demand tracing the adversary user for counteracting them. To address this, we propose "Multi-bit Watermark through Color-listing" (COLOR), embedding traceable multi-bit information during language model generation. Leveraging the benefits of zero-bit watermarking (Kirchenbauer et al., 2023a), COLOR enables extraction without model access, on-the-fly embedding, and maintains text quality, while allowing zero-bit detection all at the same time. Preliminary experiments demonstrates successful embedding of 32-bit messages with 91.9% accuracy in moderate-length texts ($\sim$500 tokens). This work advances strategies to counter language model misuse effectively.
    
[^91]: 超越显而易见：评估语言模型在真实情境中的推理能力——基于生活景观推理基准(LSR-Benchmark)的研究

    Beyond the Obvious: Evaluating the Reasoning Ability In Real-life Scenarios of Language Models on Life Scapes Reasoning Benchmark~(LSR-Benchmark). (arXiv:2307.05113v1 [cs.CL])

    [http://arxiv.org/abs/2307.05113](http://arxiv.org/abs/2307.05113)

    本论文介绍了一个新的数据集LSR-Benchmark，旨在评估语言模型在真实情境中的推理能力。结果显示，人类在这方面表现明显优于最先进的语言模型，说明机器学习模型在理解日常生活方面仍面临挑战。

    

    本文介绍了生活景观推理基准 (LSR-Benchmark)，这是一个针对真实情境推理的新型数据集，旨在弥补人工神经网络在日常背景下推理能力的差距。与领域知识推理数据集不同，LSR-Benchmark包含自由文本格式的问题，提供有关真实生活情景、人类行为和角色的丰富信息。该数据集由来自开源在线来源的2162个问题组成，并进行手动注释以提高质量。实验使用了最先进的语言模型，如gpt3.5-turbo和instruction fine-tuned llama模型，测试其在LSR-Benchmark上的性能。结果表明，人类明显优于这些模型，这表明机器学习模型在理解日常生活方面仍存在挑战。

    This paper introduces the Life Scapes Reasoning Benchmark (LSR-Benchmark), a novel dataset targeting real-life scenario reasoning, aiming to close the gap in artificial neural networks' ability to reason in everyday contexts. In contrast to domain knowledge reasoning datasets, LSR-Benchmark comprises free-text formatted questions with rich information on real-life scenarios, human behaviors, and character roles. The dataset consists of 2,162 questions collected from open-source online sources and is manually annotated to improve its quality. Experiments are conducted using state-of-the-art language models, such as gpt3.5-turbo and instruction fine-tuned llama models, to test the performance in LSR-Benchmark. The results reveal that humans outperform these models significantly, indicating a persisting challenge for machine learning models in comprehending daily human life.
    
[^92]: 面向中文文本错误校正的渐进式多任务学习框架

    Progressive Multi-task Learning Framework for Chinese Text Error Correction. (arXiv:2306.17447v1 [cs.CL])

    [http://arxiv.org/abs/2306.17447](http://arxiv.org/abs/2306.17447)

    我们提出了一种面向中文文本错误校正的渐进式多任务学习框架ProTEC，该框架通过引导模型从易到难地学习错误检测、错误类型识别和校正结果生成，以解决过纠正的问题。

    

    中文文本错误校正旨在检测和纠正输入文本中的错误，这有益于人类日常生活和各种下游任务。近期的方法主要采用预训练语言模型(PLM)来解决中文文本错误校正任务，并取得了巨大成功。然而，之前的方法存在过纠正和欠纠正的问题，前者在对精确性要求较高的中文文本错误校正任务中尤为明显。为了缓解过纠正的问题，我们提出了一种新颖的模型无关的渐进式多任务学习框架，命名为ProTEC，它引导一个CTEC模型从简单到困难地学习任务。我们将CTEC任务分为三个子任务，从易到难分别为错误检测、错误类型识别和校正结果生成。在训练过程中，ProTEC将这些子任务纳入多任务训练目标，引导模型逐渐学习文本错误校正。在推理过程中，模型则...

    Chinese Text Error Correction (CTEC) aims to detect and correct errors in the input text, which benefits human's daily life and various downstream tasks. Recent approaches mainly employ Pre-trained Language Models (PLMs) to resolve CTEC task and achieve tremendous success. However, previous approaches suffer from issues of over-correction and under-correction, and the former is especially conspicuous in the precision-critical CTEC task. To mitigate the issue of overcorrection, we propose a novel model-agnostic progressive multitask learning framework for CTEC, named ProTEC, which guides a CTEC model to learn the task from easy to difficult. We divide CTEC task into three sub-tasks from easy to difficult: Error Detection, Error Type Identification, and Correction Result Generation. During the training process, ProTEC guides the model to learn text error correction progressively by incorporating these sub-tasks into a multi-task training objective. During the inference process, the model
    
[^93]: 通过强化指令调整来减轻大规模多模态模型中的幻觉问题

    Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning. (arXiv:2306.14565v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.14565](http://arxiv.org/abs/2306.14565)

    本论文通过引入第一个大型多样化的视觉指令调整数据集，提出了一种解决大规模多模态模型中幻觉问题的方法。通过设计包含正负指令的数据集和提出的评估方法，能够更准确地衡量模型产生的幻觉。

    

    尽管多模态任务取得了可喜的进展，但当前的大规模多模态模型（LMM）很容易在描述图像和人类指令时产生不一致的幻觉。本文通过引入第一个大型多样化的视觉指令调整数据集LRV-Instruction来解决这个问题。我们的数据集包含由GPT4生成的12万个视觉指令，涵盖了16个开放式指令和答案的视觉与语言任务。与现有研究主要关注正指令样本不同，我们设计了LRV-Instruction以包含更多针对更强的视觉指令调整的正负指令。我们的负指令在两个语义层次上设计：（i）不存在元素操作和（ii）存在元素操作。为了更有效地衡量LMM所产生的幻觉，我们提出了一种新的方法，即GPT4辅助的视觉指令评估（GAVIE）。

    Despite the promising progress in multi-modal tasks, current large multi-modal models (LMM) are prone to hallucinating inconsistent descriptions with respect to the associated image and human instructions. This paper addresses this issue by introducing the first large and diverse visual instruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction. Our dataset consists of 120k visual instructions generated by GPT4, covering 16 vision-and-language tasks with open-ended instructions and answers. Unlike existing studies that primarily focus on positive instruction samples, we design LRV-Instruction to include both positive and negative instructions for more robust visual instruction tuning. Our negative instructions are designed at two semantic levels: (i) Nonexistent Element Manipulation and (ii) Existent Element Manipulation. To efficiently measure the hallucination generated by LMMs, we propose GPT4-Assisted Visual Instruction Evaluation (GAVIE), a novel approach to eva
    
[^94]: 生成式多模态实体链接

    Generative Multimodal Entity Linking. (arXiv:2306.12725v1 [cs.CL])

    [http://arxiv.org/abs/2306.12725](http://arxiv.org/abs/2306.12725)

    本文提出了 GEMEL 方法，使用大规模预训练的 LLMs 直接生成目标实体名称，仅调整了极少的模型参数即可实现最先进的 MEL 实验结果。

    

    多模态实体链接是将带有多模态上下文的提及映射到知识库（例如维基百科）中的引用实体的任务。本文提出了一种名为 GEMEL 的简单而有效的生成式多模态实体链接方法，利用大规模预训练的 LLMs 直接生成目标实体名称。我们保持视觉和语言模型冻结，只训练一个线性层以启用跨模态交互。为了将 LLMs 适应 MEL 任务，我们利用 LLMs 的新兴上下文学习能力，通过检索多模态实例作为示范来进行。大量实验表明，仅调整了大约0.3％的模型参数，GEMEL 就实现了最先进的结果。

    Multimodal Entity Linking (MEL) is the task of mapping mentions with multimodal contexts to the referent entities from a knowledge base (e.g., Wikipedia). Prior MEL methods mainly focus on designing complex multimodal interaction mechanisms and require fine-tuning all model parameters, which can be prohibitively costly and difficult to scale in the era of Large Language Models (LLMs). In this work, we propose GEMEL, a simple yet effective Generative Multimodal Entity Linking method, which leverages the capabilities of LLMs from large-scale pre-training to directly generate target entity names. We keep the vision and language model frozen and only train a linear layer to enable cross-modality interactions. To adapt LLMs to the MEL task, we take advantage of the emerging in-context learning (ICL) capability of LLMs by retrieving multimodal instances as demonstrations. Extensive experiments show that with only ~0.3% of the model parameters fine-tuned, GEMEL achieves state-of-the-art resul
    
[^95]: 实体链接的检索器-阅读器范式的双向端到端学习

    Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking. (arXiv:2306.12245v1 [cs.CL])

    [http://arxiv.org/abs/2306.12245](http://arxiv.org/abs/2306.12245)

    BEER^2是一种用于Retriever和Reader的双向端到端训练框架，通过检索器和阅读器之间的相互学习，共同进步，实现端到端EL。

    

    实体链接（EL）是信息提取和知识图谱的基本任务，它的一般形式（即端到端EL）旨在首先在给定输入文档中找到提及，并将提及链接到特定知识库中的相应实体。最近，检索器-阅读器范式促进了端到端EL的进展，受益于密集的实体检索和机器阅读理解的优势。然而，现有研究仅以流水线方式单独训练检索器和阅读器，忽略了检索器和阅读器之间交互带来的益处。为了使检索器-阅读器范式更完美地执行端到端EL，我们提出了BEER$^2$，一种用于Retriever and Reader的双向端到端训练框架。通过我们设计的双向端到端训练，BEER$^2$指导检索器和阅读器互相学习，共同进步，并最终实现端到端EL。

    Entity Linking (EL) is a fundamental task for Information Extraction and Knowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to first find mentions in the given input document and then link the mentions to corresponding entities in a specific knowledge base. Recently, the paradigm of retriever-reader promotes the progress of end-to-end EL, benefiting from the advantages of dense entity retrieval and machine reading comprehension. However, the existing study only trains the retriever and the reader separately in a pipeline manner, which ignores the benefit that the interaction between the retriever and the reader can bring to the task. To advance the retriever-reader paradigm to perform more perfectly on end-to-end EL, we propose BEER$^2$, a Bidirectional End-to-End training framework for Retriever and Reader. Through our designed bidirectional end-to-end training, BEER$^2$ guides the retriever and the reader to learn from each other, make progress together, and ultimate
    
[^96]: 语言模型知道自己在产生“幻觉”参考文献吗？

    Do Language Models Know When They're Hallucinating References?. (arXiv:2305.18248v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18248](http://arxiv.org/abs/2305.18248)

    本研究针对大型语言模型中的“幻觉”参考文献进行了研究，通过简单的搜索引擎查询可可靠地识别这些幻觉。并且通过对同一语言模型进行黑盒查询来进行分类，揭示了幻觉参考文献的性质。

    

    目前最先进的语言模型以其“幻觉”参考文献而闻名。这些虚构的文章和书名引起了危害，对它们的使用造成了障碍，并引起了公众的反弹。尽管其他类型的语言模型幻觉也很重要，但我们将幻觉参考文献提出作为大型语言模型(LLMs)中幻觉研究的“果蝇”，因为它们特别容易研究。我们展示了简单的搜索引擎查询可可靠地识别此类幻觉，从而便于评估。为了开始剖析幻觉语言模型参考文献的性质，我们尝试使用对同一语言模型的黑盒查询来对其进行分类，而不借助任何外部资源。我们将“直接”查询的一致性检查与“间接”查询的一致性检查进行了比较，后者询问了附加的细节，如作品的作者。

    State-of-the-art language models (LMs) are famous for "hallucinating" references. These fabricated article and book titles lead to harms, obstacles to their use, and public backlash. While other types of LM hallucinations are also important, we propose hallucinated references as the "drosophila" of research on hallucination in large language models (LLMs), as they are particularly easy to study. We show that simple search engine queries reliably identify such hallucinations, which facilitates evaluation. To begin to dissect the nature of hallucinated LM references, we attempt to classify them using black-box queries to the same LM, without consulting any external resources. Consistency checks done with "direct" queries about whether the generated reference title is real (inspired by Kadavath et al. 2022, Lin et al. 2022, Manakul et al. 2023) are compared to consistency checks with "indirect" queries which ask for ancillary details such as the authors of the work. These consistency chec
    
[^97]: 在祈祷之后喝啤酒？测量大型语言模型中的文化偏见。

    Having Beer after Prayer? Measuring Cultural Bias in Large Language Models. (arXiv:2305.14456v1 [cs.CL])

    [http://arxiv.org/abs/2305.14456](http://arxiv.org/abs/2305.14456)

    这篇论文研究了大型语言模型在处理和生成阿拉伯文本时出现的文化偏向西方文化的现象，表明语言模型在人名、食品、服装、地点、文学、饮料、宗教和体育等八个文化方面存在偏见。这些发现引发对于当前语言模型文化相关性的担忧。

    

    语言模型是否存在文化偏见？语言模型符合所服务社区的文化因素很重要。然而，本文表明在处理和生成阿拉伯文本时，语言模型存在显著的偏向西方文化的偏见，倾向于产生西方文化相关内容而非阿拉伯文化相关内容。我们通过使用从在线社交媒体上收集的自然出现的上下文和基于可能性评分的指标来量化这种偏见。我们的实验显示，阿拉伯语单语和多语模型在八个不同的文化方面存在西方文化偏见，包括人名、食品、服装、地点、文学、饮料、宗教和体育。当输入的阿拉伯语句子越接近英语时，模型也更容易表现出偏见。这些发现引发人们对当前语言模型文化相关性的担忧。我们的分析表明，在模型设计中应更多考虑文化因素和多样性。

    Are language models culturally biased? It is important that language models conform to the cultural aspects of the communities they serve. However, we show in this paper that language models suffer from a significant bias towards Western culture when handling and generating text in Arabic, often preferring, and producing Western-fitting content as opposed to the relevant Arab content. We quantify this bias through a likelihood scoring-based metric using naturally occurring contexts that we collect from online social media. Our experiments reveal that both Arabic monolingual and multilingual models exhibit bias towards Western culture in eight different cultural aspects: person names, food, clothing, location, literature, beverage, religion, and sports. Models also tend to exhibit more bias when prompted with Arabic sentences that are more linguistically aligned with English. These findings raise concerns about the cultural relevance of current language models. Our analyses show that pr
    
[^98]: PaD: 程序辅助蒸馏专注于推理的大型模型

    PaD: Program-aided Distillation Specializes Large Models in Reasoning. (arXiv:2305.13888v1 [cs.CL])

    [http://arxiv.org/abs/2305.13888](http://arxiv.org/abs/2305.13888)

    本文提出了一种程序辅助蒸馏（PaD）技术，它可以蒸馏大型语言模型（LLMs）以在推理任务中获得专业化的小模型。PaD使用程序辅助推理加强专业化模型，并通过自动化错误检查来帮助它们克服错误的推理步骤。

    

    尽管大型语言模型（LLMs）在几个自然语言处理任务中表现优异，但它们的大小和不可访问性对于广泛的实际应用仍然存在挑战。先前的研究通过对LLMs进行精炼以获取专业技能，在商业场景中实现了通用能力的交换，称为模型专业化。对于推理能力，公司已合成用于后续提炼的思维链。但是，由于幻觉，LLMs的合成思维链包含错误推理，这些不正确的推理步骤损害了推理能力。为了解决上述问题，我们提出了程序辅助蒸馏（PaD），它可以蒸馏LLMs以在推理任务中获得专业化的小模型。在PaD中，我们使用程序辅助推理加强专业化模型，并通过自动化错误检查来帮助它们克服错误的推理步骤。实验结果表明，在GSM8K基准测试中，使用PaD的0.06B模型不仅可以胜过某些LLMs（例如LLaMA），而且还可以取得比其他模型更好的性能。

    While Large Language Models (LLMs) excel in several natural language processing tasks, their size and inaccessibility present challenges for extensive practical application. Previous studies acquire specialized skills through distillation on LLMs, which result in trading generic abilities, called model specialization. As for reasoning ability, chain-of-thought was synthesized to subsequent distillation. However, due to hallucination, synthetic chain-of-thought from LLMs contains faulty reasoning. These incorrect reasoning steps damage the reasoning capability. To tackle above issues, we propose Program-aided Distillation (PaD), which distills LLMs to obtain specialized small models in reasoning tasks. In PaD, we strengthen specialized models with program-aided reasoning, and help them overcome faulty reasoning steps with automated error checking. Experimental results demonstrate that, on the GSM8K benchmark, a 0.06B model using PaD can not only outperform certain LLMs (e.g., LLaMA), bu
    
[^99]: 任务无关BERT压缩的权重继承蒸馏方法

    Weight-Inherited Distillation for Task-Agnostic BERT Compression. (arXiv:2305.09098v1 [cs.CL])

    [http://arxiv.org/abs/2305.09098](http://arxiv.org/abs/2305.09098)

    本文提出了一种直接从教师模型传递知识的权重继承蒸馏方法，不需要额外的对齐损失就可以训练出一个紧凑的学生模型，并且在GLUE和SQuAD基准测试上优于之前最先进的基于KD的基线。

    

    知识蒸馏（KD）是压缩BERT的主要方法。之前的KD方法侧重于为学生模型设计额外的对齐损失，以模仿教师模型的行为。这些方法以间接的方式传递知识。在本文中，我们提出了一种新颖的权重继承蒸馏（WID）方法，直接从教师模型传递知识。WID不需要额外的对齐损失，通过继承权重来训练一个紧凑的学生模型，展示了知识蒸馏的新视角。具体来说，我们将行压缩器和列压缩器设计为映射，然后通过结构重参数化压缩权重。在GLUE和SQuAD基准测试上的实验结果表明，WID优于之前最先进的基于KD的基线。进一步的分析表明，WID也可以在不需要注意力分布对齐损失的情况下学习教师模型的注意力模式。

    Knowledge Distillation (KD) is a predominant approach for BERT compression. Previous KD-based methods focus on designing extra alignment losses for the student model to mimic the behavior of the teacher model. These methods transfer the knowledge in an indirect way. In this paper, we propose a novel Weight-Inherited Distillation (WID), which directly transfers knowledge from the teacher. WID does not require any additional alignment loss and trains a compact student by inheriting the weights, showing a new perspective of knowledge distillation. Specifically, we design the row compactors and column compactors as mappings and then compress the weights via structural re-parameterization. Experimental results on the GLUE and SQuAD benchmarks show that WID outperforms previous state-of-the-art KD-based baselines. Further analysis indicates that WID can also learn the attention patterns from the teacher model without any alignment loss on attention distributions.
    
[^100]: EmotionIC：基于情感惯性和感染的依赖建模可用于对话中的情感识别

    EmotionIC: Emotional Inertia and Contagion-driven Dependency Modelling for Emotion Recognition in Conversation. (arXiv:2303.11117v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.11117](http://arxiv.org/abs/2303.11117)

    本文提出了一种新的依赖性建模方法，由情感惯性和感染驱动（EmotionIC），用于在特征提取和分类级别上进行会话情感识别。设计了多项具体方法，包括身份掩码多头注意（IM-MHA）和基于对话门控循环单元(DialogGRU)，以抓取上下文信息，提高模型的性能。

    

    最近，随着人机界面技术的进步和实施，对话中的情感识别（ERC）吸引了越来越多的关注。然而，以往的建模方法在全局和局部上下文依赖方面丢失了依赖信息的多样性，并且在分类级别不考虑上下文依赖关系。本文提出了一种新的依赖性建模方法，由情感惯性和感染驱动（EmotionIC），用于在特征提取和分类级别上进行会话情感识别。在特征提取级别，我们设计的身份掩码多头注意（IM-MHA）捕捉对话中基于身份的长距离上下文，以包含不同参与者的不同影响构建全局情感氛围，而设计的基于对话门控循环单元(DialogGRU)则聚合了二元对话的情感倾向，并应用于分类过程。

    Emotion Recognition in Conversation (ERC) has attracted growing attention in recent years as a result of the advancement and implementation of human-computer interface technologies. However, previous approaches to modeling global and local context dependencies lost the diversity of dependency information and do not take the context dependency into account at the classification level. In this paper, we propose a novel approach to dependency modeling driven by Emotional Inertia and Contagion (EmotionIC) for conversational emotion recognition at the feature extraction and classification levels. At the feature extraction level, our designed Identity Masked Multi-head Attention (IM-MHA) captures the identity-based long-distant context in the dialogue to contain the diverse influence of different participants and construct the global emotional atmosphere, while the devised Dialogue-based Gate Recurrent Unit (DialogGRU) that aggregates the emotional tendencies of dyadic dialogue is applied to
    

