# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Going Beyond Nouns With Vision & Language Models Using Synthetic Data.](http://arxiv.org/abs/2303.17590) | 本文在现有的VL模型中加入合成数据集SyViC，成功实现对'名词以外'的理解任务。 |
| [^2] | [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace.](http://arxiv.org/abs/2303.17580) | 用ChatGPT作为任务规划工具，利用大型语言模型（LLM）作为控制器来整合现有的AI模型，解决复杂的AI任务。 |
| [^3] | [Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation.](http://arxiv.org/abs/2303.17579) | 本研究提出了一种基于检索的放射性医学报告生成模块 X-REM，它使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度，以进行报告检索，其在多个先前的放射学报告生成模块中表现优异，可有效提高放射学报告的自动生成精度。 |
| [^4] | [Elastic Weight Removal for Faithful and Abstractive Dialogue Generation.](http://arxiv.org/abs/2303.17574) | EWR方法通过费舍尔信息矩阵权衡语音生成模型中个体参数的重要性，提高对话回复的忠实性，取得了很好的效果。 |
| [^5] | [BloombergGPT: A Large Language Model for Finance.](http://arxiv.org/abs/2303.17564) | 本文提出了BloombergGPT，一个500亿参数的金融领域的大型语言模型，其基于Bloomberg的广泛数据来源和通用数据集进行训练。通过混合数据集训练，该模型在金融任务上表现出色，并且不会牺牲在普通任务上的性能。 |
| [^6] | [Recognition, recall, and retention of few-shot memories in large language models.](http://arxiv.org/abs/2303.17557) | 本文通过对大型语言模型进行实验，揭示了这种模型能够有效地记忆和泛化仅在训练中少次观察到的例子。 |
| [^7] | [Whose Opinions Do Language Models Reflect?.](http://arxiv.org/abs/2303.17548) | 本文通过调查高质量的公共民意调查来创建一个新的数据集OpinionsQA，评估语言模型反映的观点与60个不同人口统计组的观点之间的一致性，发现当前语言模型反映的观点与美国人群组的观点存在巨大差异，甚至通过明确调整LM反映出的观点，仍然无法消除。 |
| [^8] | [Hindi as a Second Language: Improving Visually Grounded Speech with Semantically Similar Samples.](http://arxiv.org/abs/2303.17517) | 本文通过使用语义相似的口语字幕和预训练的语言编码器方法，利用高资源语言来提高低资源语言的基于视觉的语音模型性能。 |
| [^9] | [Improving the Diproche CNL through autoformalization via GPT-3.](http://arxiv.org/abs/2303.17513) | 本文探讨了在Diproche上使用大型语言模型进行自动形式化的可能性，并取得了令人鼓舞的初步结果。 |
| [^10] | [On pitfalls (and advantages) of sophisticated large language models.](http://arxiv.org/abs/2303.17511) | 大型语言模型能够超越人类表现，但过度依赖可能会导致严重后果，包括难以区分的机器生成文本和各种形式的欺诈，进而产生新的伦理挑战。 |
| [^11] | [Language Models can Solve Computer Tasks.](http://arxiv.org/abs/2303.17491) | 本文研究表明，预训练的大型语言模型代理可以通过一个简单的提示方案使用自然语言执行计算机任务，该方法取得了很好的效果并在MiniWoB++基准测试中超越了监督学习和强化学习方法。 |
| [^12] | [Efficient distributed representations beyond negative sampling.](http://arxiv.org/abs/2303.17475) | 本文介绍了一种高效的分布式表示（嵌入）学习方法，通过线性时间估计softmax归一化常数来实现学习过程，该方法优于负采样方法并在多项测试中验证了其有效性。 |
| [^13] | [Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study.](http://arxiv.org/abs/2303.17466) | 本文通过分析ChatGPT对旨在量化人类文化差异的问题的回答，评估了其文化适应能力。发现ChatGPT在以美国背景为提示时表现出与美国文化的强烈对齐，但其对其他文化的适应能力较差，并且英文提示会抹平文化差异并偏向美国文化。 |
| [^14] | [Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts.](http://arxiv.org/abs/2303.17408) | 使用语言增强Transformer编码器，并结合医学提示，将结构化、非结构化的临床数据投影到一个语言潜空间中，以实现更精确的医学干预持续时间估计。 |
| [^15] | [WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research.](http://arxiv.org/abs/2303.17395) | 本文介绍了第一个大规模的弱标注音频字幕数据集WavCaps，含约40万条带有配对字幕的音频剪辑。为克服噪声标注的问题，提出了基于ChatGPT的三阶段字幕生成流程。 |
| [^16] | [A BERT-based Unsupervised Grammatical Error Correction Framework.](http://arxiv.org/abs/2303.17367) | 本研究提出了一种基于BERT的无监督语法纠错框架，用于低资源语言的GEC任务。该框架包含三个模块，并提出一种新颖的伪困惑度评分方法，该方法已经在菲律宾语GEC任务上取得了竞争性的表现。 |
| [^17] | [Topics in the Haystack: Extracting and Evaluating Topics beyond Coherence.](http://arxiv.org/abs/2303.17324) | 这项研究提出了一种新的主题提取方法，可以检测包含不常见词汇的潜在主题，并提出了新的评估指标，在干扰词识别任务上获得接近于人类水平的结果。 |
| [^18] | [Yes but.. Can ChatGPT Identify Entities in Historical Documents?.](http://arxiv.org/abs/2303.17322) | 本文通过比较ChatGPT和最先进的基于LM的系统，探究了它在历史文献中进行命名实体识别和分类的能力，发现存在多方面的缺陷，包括实体复杂性和提示特定性等。 |
| [^19] | [Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure.](http://arxiv.org/abs/2303.17276) | 本文研究了GPT-3、GPT-3.5和GPT-4模型在人类思维模式中的表现, 运用认识论理论提供了符号生成模型，通过实验证实的人类判断数据点以及ETR预测数据点的数量级对模型进行了检验。 |
| [^20] | [The Nordic Pile: A 1.2TB Nordic Dataset for Language Modeling.](http://arxiv.org/abs/2303.17183) | 本论文描述了一个包含1.2TB文本的北欧语言数据集，为预训练大型语言模型提供了重要资源，促进了北欧语言的LLMs的开发。 |
| [^21] | [TreePiece: Faster Semantic Parsing via Tree Tokenization.](http://arxiv.org/abs/2303.17161) | 本文提出的TreePiece技术将解析树分割成子树，以加速自回归模型用于语义分析的过程，相比标准自回归提高了4.6倍的解码速度，并在速度相当的情况下准确性更高于非自回归方法。 |
| [^22] | [TLAG: An Informative Trigger and Label-Aware Knowledge Guided Model for Dialogue-based Relation Extraction.](http://arxiv.org/abs/2303.17119) | TLAG是一种信息触发器和标签感知知识引导模型，通过充分利用触发器和标签信息以及引入标签感知知识来促进基于对话的关系抽取。 |
| [^23] | [DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents.](http://arxiv.org/abs/2303.17071) | 本文介绍了一种名为DERA的对话型解决代理，该代理利用LLM的对话能力提高了模型的补全能力。DERA框架化为两个代理类型之间的讨论，可以在医疗对话摘要和护理计划生成方面实现显著改进。 |
| [^24] | [How do decoding algorithms distribute information in dialogue responses?.](http://arxiv.org/abs/2303.17006) | 该论文研究了在对话生成中解码算法是否遵循均匀信息密度原则（将信息均匀分配在话语中）。研究发现模型生成的回应比人的回应更加遵循该原则，促进该原则的解码算法并没有提高回应质量。此外，作者还发现信息密度的不均匀性与惊奇度非常低/高的回应的质量相关，鼓励非均匀回应是“可能性陷阱”问题的潜在解决方案。 |
| [^25] | [Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams.](http://arxiv.org/abs/2303.17003) | 本研究在巴西大学入学考试中评估了GPT-3.5和GPT-4模型，分析了不同提示策略，最终发现GPT-4与Chain-of-Thought提示结合表现最好，在2022年考试中准确率达到了87％。 |
| [^26] | [ContraSim -- A Similarity Measure Based on Contrastive Learning.](http://arxiv.org/abs/2303.16992) | 本文提出了一种新的相似度度量方法: ContraSim，该方法利用对比学习学习参数化的度量方法。实验表明，ContraSim在多种基准测试中均获得了比之前相似度量方法更高的准确性。 |
| [^27] | [Adapting to the Low-Resource Double-Bind: Investigating Low-Compute Methods on Low-Resource African Languages.](http://arxiv.org/abs/2303.16985) | 本文探讨了在低资源条件下，采用语言适配器等低计算方法在非洲语言上进行NLP研究的有效性，并通过微调实验得出了实现可比性能的结论。 |
| [^28] | [BEVERS: A General, Simple, and Performant Framework for Automatic Fact Verification.](http://arxiv.org/abs/2303.16974) | BEVERS是一个特别针对FEVER数据集进行调整的基准系统，具有通用性、简单性和高性能的特点，并在FEVER和Scifact数据集上取得了最高的标签准确性。 |
| [^29] | [MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks.](http://arxiv.org/abs/2303.16839) | 提出了一种名为MaMMUT的简单模型，可以通过两步方法容纳对比和生成学习，并在联合训练不同的视觉语言任务时表现出很高的效力。 |
| [^30] | [Unified Text Structuralization with Instruction-tuned Language Models.](http://arxiv.org/abs/2303.14956) | 本研究提出了一种使用指导语言模型从文本中提取各种结构的方法，解决了文本结构化领域缺乏高质量数据集且信息提取难以推广的问题。 |
| [^31] | [A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT.](http://arxiv.org/abs/2302.09419) | 本文全面回顾了预训练基础模型的最新研究进展和发展历程，包括它们的架构、培训目标、预培训任务、微调策略和评估。同时，讨论了其局限性和未来研究方向。 |
| [^32] | ["Correct answers" from the psychology of artificial intelligence.](http://arxiv.org/abs/2302.07267) | 本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。 |
| [^33] | [TempCLR: Temporal Alignment Representation with Contrastive Learning.](http://arxiv.org/abs/2212.13738) | 本文提出了一个基于对比学习的框架TempCLR，用于显式比较完整的视频和段落，解决单元级别比较可能忽略全局时间上下文的问题。 |
| [^34] | [LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models.](http://arxiv.org/abs/2212.04088) | 本研究提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划，实验表明其在多任务和快速学习新任务的通用代理的开发中具有很好的表现。 |
| [^35] | [Deep Temporal Modelling of Clinical Depression through Social Media Text.](http://arxiv.org/abs/2211.07717) | 本文通过使用抑郁症状检测分类器，从社交媒体文本提取临床相关特征，建立了一个模型用于检测用户的临床抑郁症，通过提供不同时间粒度的准确度度量来评估该模型。 |
| [^36] | [Language-Family Adapters for Low-Resource Multilingual Neural Machine Translation.](http://arxiv.org/abs/2209.15236) | 本文提出在mBART-50的基础上训练语言家族适配器，以提高低资源语言的翻译性能，该方法优于其他基线。 |
| [^37] | [Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence.](http://arxiv.org/abs/2209.02970) | 凤神榜是一个开源项目，旨在支持汉语社区的发展。它包括大型预训练模型、用户友好的API、基准和数据集等，以促进中国大规模模型的发展。 |
| [^38] | [Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition.](http://arxiv.org/abs/2206.08317) | Paraformer是用于非自回归端到端语音识别的快速准确并行Transformer，通过使用连续积分-火器预测器和扫视式语言模型采样器解决了单步NAR的挑战，并在LibriSpeech数据集上取得了最先进的性能。 |
| [^39] | [Fine-grained Image Captioning with CLIP Reward.](http://arxiv.org/abs/2205.13115) | 本研究提出使用CLIP作为奖励函数, 生成更细致、独特的图像标题。通过FineCapEval测试，该方法在客观指标和人类评估方面均优于最先进的模型。 |
| [^40] | [Enhancing Continual Learning with Global Prototypes: Counteracting Negative Representation Drift.](http://arxiv.org/abs/2205.12186) | 该论文提出了一种基于全局原型的持续学习方法，在自监督信息的正则化下学习数据表示，以缓解负面表示漂移问题，并减少持续学习中的灾难性遗忘。 |

# 详细

[^1]: 利用合成数据，视觉语言模型突破名词局限

    Going Beyond Nouns With Vision & Language Models Using Synthetic Data. (arXiv:2303.17590v1 [cs.CV])

    [http://arxiv.org/abs/2303.17590](http://arxiv.org/abs/2303.17590)

    本文在现有的VL模型中加入合成数据集SyViC，成功实现对'名词以外'的理解任务。

    

    大规模预训练的视觉语言（VL）模型在许多应用中表现出了显着的性能，使得可以通过（几乎任意）自然语言提示进行零样本开放词汇推理，取代了一组支持的类别。然而，最近的研究揭示了这些模型的一个根本性弱点。本文研究了纯合成数据在多大程度上可以教会这些模型克服这些缺点，而不损害它们的零样本能力。作者贡献了一个数百万规模的合成数据集SyViC，以及数据生成代码库，允许在现有的VL基准数据集中生成额外的合适数据，实现'noun'以外的理解任务学习。

    Large-scale pre-trained Vision & Language (VL) models have shown remarkable performance in many applications, enabling replacing a fixed set of supported classes with zero-shot open vocabulary reasoning over (almost arbitrary) natural language prompts. However, recent works have uncovered a fundamental weakness of these models. For example, their difficulty to understand Visual Language Concepts (VLC) that go 'beyond nouns' such as the meaning of non-object words (e.g., attributes, actions, relations, states, etc.), or difficulty in performing compositional reasoning such as understanding the significance of the order of the words in a sentence. In this work, we investigate to which extent purely synthetic data could be leveraged to teach these models to overcome such shortcomings without compromising their zero-shot capabilities. We contribute Synthetic Visual Concepts (SyViC) - a million-scale synthetic dataset and data generation codebase allowing to generate additional suitable dat
    
[^2]: HuggingGPT: 在HugingFace中使用ChatGPT及其伙伴解决AI任务

    HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace. (arXiv:2303.17580v1 [cs.CL])

    [http://arxiv.org/abs/2303.17580](http://arxiv.org/abs/2303.17580)

    用ChatGPT作为任务规划工具，利用大型语言模型（LLM）作为控制器来整合现有的AI模型，解决复杂的AI任务。

    

    解决不同领域和模态的复杂AI任务是通向人工智能的关键步骤。本文提出了一个系统，利用大型语言模型（LLMs）作为控制器来管理现有的AI模型以解决AI任务，语言成为通用接口来赋能它。具体来说，我们使用ChatGPT作为任务规划工具，根据HuggingFace中可用的模型功能描述来选择模型，在选定AI模型的情况下执行每个子任务，并总结响应。

    Solving complicated AI tasks with different domains and modalities is a key step toward artificial general intelligence (AGI). While there are abundant AI models available for different domains and modalities, they cannot handle complicated AI tasks. Considering large language models (LLMs) have exhibited exceptional ability in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks and language could be a generic interface to empower this. Based on this philosophy, we present HuggingGPT, a system that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., HuggingFace) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in HuggingFace, execute each subtask with the selected AI model, and summarize the response acco
    
[^3]: 多模态图像文本匹配优化基于检索的胸部 X 射线报告生成

    Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation. (arXiv:2303.17579v1 [cs.CL])

    [http://arxiv.org/abs/2303.17579](http://arxiv.org/abs/2303.17579)

    本研究提出了一种基于检索的放射性医学报告生成模块 X-REM，它使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度，以进行报告检索，其在多个先前的放射学报告生成模块中表现优异，可有效提高放射学报告的自动生成精度。

    

    自动化生成临床准确的放射学报告可以改善患者护理。以前依赖图像字幕模型的报告生成方法由于缺乏相关领域知识而经常生成不连贯和不正确的文本，而基于检索的尝试经常检索到与输入图像不相关的报告。在这项工作中，我们提出了一种名为 Contrastive X-Ray REport Match（X-REM）的新型基于检索的放射性医学报告生成模块，该模块使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度以进行报告检索。我们观察到，使用语言图像模型计算图像文本匹配分数可以有效地捕捉到在使用余弦相似性时经常丢失的图像和文本之间的细粒度交互。在自然语言和临床度量方面，X-REM在多个先前的放射学报告生成模块中表现优异。通过对生成的报告进行人类评估，表明 X-R...

    Automated generation of clinically accurate radiology reports can improve patient care. Previous report generation methods that rely on image captioning models often generate incoherent and incorrect text due to their lack of relevant domain knowledge, while retrieval-based attempts frequently retrieve reports that are irrelevant to the input image. In this work, we propose Contrastive X-Ray REport Match (X-REM), a novel retrieval-based radiology report generation module that uses an image-text matching score to measure the similarity of a chest X-ray image and radiology report for report retrieval. We observe that computing the image-text matching score with a language-image model can effectively capture the fine-grained interaction between image and text that is often lost when using cosine similarity. X-REM outperforms multiple prior radiology report generation modules in terms of both natural language and clinical metrics. Human evaluation of the generated reports suggests that X-R
    
[^4]: 适用于忠实和抽象化对话生成的弹性权重去除

    Elastic Weight Removal for Faithful and Abstractive Dialogue Generation. (arXiv:2303.17574v1 [cs.CL])

    [http://arxiv.org/abs/2303.17574](http://arxiv.org/abs/2303.17574)

    EWR方法通过费舍尔信息矩阵权衡语音生成模型中个体参数的重要性，提高对话回复的忠实性，取得了很好的效果。

    

    理想情况下，对话系统应该生成忠实于相关文档中包含的知识的回复。然而，许多模型生成了幻想的响应，其中包含与其相矛盾的信息或不可验证的信息。为了减轻这种不良行为，已经提出了在负面示例上微调“负面专家”，并从预训练模型的参数中减去它的参数。然而，直觉上，这并没有考虑到某些参数比其他参数更负责导致幻觉。因此，我们提出通过（近似）费舍尔信息矩阵来权衡它们的个体重要性，该矩阵衡量其估计的不确定性。我们将此方法称为弹性权重去除（EWR）。我们使用Flan-T5不同变体作为骨干语言模型评估我们的方法，并在多个信息寻求对话生成数据集上比较我们的方法与忠实性的最新技术。

    Ideally, dialogue systems should generate responses that are faithful to the knowledge contained in relevant documents. However, many models generate hallucinated responses instead that contradict it or contain unverifiable information. To mitigate such undesirable behaviour, it has been proposed to fine-tune a `negative expert' on negative examples and subtract its parameters from those of a pre-trained model. However, intuitively, this does not take into account that some parameters are more responsible than others in causing hallucinations. Thus, we propose to weigh their individual importance via (an approximation of) the Fisher Information matrix, which measures the uncertainty of their estimate. We call this method Elastic Weight Removal (EWR). We evaluate our method -- using different variants of Flan-T5 as a backbone language model -- on multiple datasets for information-seeking dialogue generation and compare our method with state-of-the-art techniques for faithfulness, such a
    
[^5]: BloombergGPT：金融领域的大型语言模型

    BloombergGPT: A Large Language Model for Finance. (arXiv:2303.17564v1 [cs.LG])

    [http://arxiv.org/abs/2303.17564](http://arxiv.org/abs/2303.17564)

    本文提出了BloombergGPT，一个500亿参数的金融领域的大型语言模型，其基于Bloomberg的广泛数据来源和通用数据集进行训练。通过混合数据集训练，该模型在金融任务上表现出色，并且不会牺牲在普通任务上的性能。

    

    自然语言处理在金融技术领域有着广泛而复杂的应用，从情感分析和命名实体识别到问答。大型语言模型（LLM）已被证明在各种任务上非常有效；然而，专为金融领域设计的LLM尚未在文献中报告。在本文中，我们提出了BloombergGPT，一个拥有500亿个参数的语言模型，它是基于广泛的金融数据进行训练的。我们构建了一种3630亿个标记的数据集，该数据集基于彭博社的广泛数据来源，可能是迄今最大的领域特定数据集，同时又增加了来自通用数据集的3450亿个标记。我们在标准LLM基准、开放式金融基准和一套最能准确反映我们预期用途的内部基准上验证了BloombergGPT。我们的混合数据集训练产生了一个在金融任务上明显优于现有模型的模型，同时不会牺牲普通任务的性能。

    The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg's extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general 
    
[^6]: 大型语言模型的少样本记忆的识别、回忆和保持

    Recognition, recall, and retention of few-shot memories in large language models. (arXiv:2303.17557v1 [cs.CL])

    [http://arxiv.org/abs/2303.17557](http://arxiv.org/abs/2303.17557)

    本文通过对大型语言模型进行实验，揭示了这种模型能够有效地记忆和泛化仅在训练中少次观察到的例子。

    

    当代大型语言模型的训练在一个大多数训练样本仅在模型训练期间看到几次的模式下进行。本文通过对大型语言模型进行简单的识别、回忆和保持实验，探究模型对仅在训练期间少次观察到的样本的记忆及其在继续训练时持续的时间。实验结果表明，仅一个接触通常足以让模型在非常具有挑战性的识别实验中达到近乎完美的准确性。我们估计，在连续训练新样本的几个时期内，模型保持了已见样本的可识别特征。实验表明，大型语言模型具有记忆和泛化少样本例子的能力，这与它们在自然语言处理基准测试中的卓越表现一致。

    The training of modern large language models (LLMs) takes place in a regime where most training examples are seen only a few times by the model during the course of training. What does a model remember about such examples seen only a few times during training and how long does that memory persist in the face of continuous training with new examples? Here, we investigate these questions through simple recognition, recall, and retention experiments with LLMs. In recognition experiments, we ask if the model can distinguish the seen example from a novel example; in recall experiments, we ask if the model can correctly recall the seen example when cued by a part of it; and in retention experiments, we periodically probe the model's memory for the original examples as the model is trained continuously with new examples. We find that a single exposure is generally sufficient for a model to achieve near perfect accuracy even in very challenging recognition experiments. We estimate that the rec
    
[^7]: 语言模型反映了谁的观点？

    Whose Opinions Do Language Models Reflect?. (arXiv:2303.17548v1 [cs.CL])

    [http://arxiv.org/abs/2303.17548](http://arxiv.org/abs/2303.17548)

    本文通过调查高质量的公共民意调查来创建一个新的数据集OpinionsQA，评估语言模型反映的观点与60个不同人口统计组的观点之间的一致性，发现当前语言模型反映的观点与美国人群组的观点存在巨大差异，甚至通过明确调整LM反映出的观点，仍然无法消除。

    

    语言模型（LM）在越来越多的开放环境中被使用，在针对主观查询的响应中反映的观点可能会对用户满意度产生深远影响，同时也可能塑造整个社会的观点。本文提出了一个定量框架，以调查LM反映的观点。我们利用高质量的公共民意调查和相关的人类反应来创建OpinionsQA，并对60个美国人口统计组的意见进行评估，并涉及从堕胎到自动化的各种话题。在各个话题上，我们发现当前LM反映的观点与美国人群组之间存在重大差异，这与民主党和共和党在气候变化问题上的分歧差不多。值得注意的是，即使明确将LM定向于特定的人口统计组，这种差异仍然存在。我们的分析不仅确认了先前对左倾倾向的观察结果，同时提出了这种差异的一个全新的理论解释。

    Language models (LMs) are increasingly being used in open-ended contexts, where the opinions reflected by LMs in response to subjective queries can have a profound impact, both on user satisfaction, as well as shaping the views of society at large. In this work, we put forth a quantitative framework to investigate the opinions reflected by LMs -- by leveraging high-quality public opinion polls and their associated human responses. Using this framework, we create OpinionsQA, a new dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we find substantial misalignment between the views reflected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular demographic groups. Our analysis not only confirms prior observations about the left-leaning
    
[^8]: 印地语作为第二语言：通过语义相似样本提高基于视觉的语音模型的性能

    Hindi as a Second Language: Improving Visually Grounded Speech with Semantically Similar Samples. (arXiv:2303.17517v1 [cs.CL])

    [http://arxiv.org/abs/2303.17517](http://arxiv.org/abs/2303.17517)

    本文通过使用语义相似的口语字幕和预训练的语言编码器方法，利用高资源语言来提高低资源语言的基于视觉的语音模型性能。

    

    本文旨在从多语言角度探索基于视觉的语音模型(VGS)的学习。双语VGS模型通常使用两种语言中平均数量的口语字幕进行训练。然而，实际上，可用口语字幕之间的语言可能存在不平衡。本文主要贡献在于利用高资源语言的力量在双语基于视觉的语音模型中提高低资源语言的性能。我们介绍了两种方法来将高资源语言的知识蒸馏到低资源语言中：(1)整合强大的预训练高资源语言编码器和(2)使用语义相似的口语字幕。我们的实验结果表明，这两种方法的组合有效地使低资源语言在跨模态检索任务中超过单语言和双语言模型的性能。

    The objective of this work is to explore the learning of visually grounded speech models (VGS) from multilingual perspective. Bilingual VGS models are generally trained with an equal number of spoken captions from both languages. However, in reality, there can be an imbalance among the languages for the available spoken captions. Our key contribution in this work is to leverage the power of a high-resource language in a bilingual visually grounded speech model to improve the performance of a low-resource language. We introduce two methods to distill the knowledge of high-resource language into low-resource languages: (1) incorporating a strong pre-trained high-resource language encoder and (2) using semantically similar spoken captions. Our experiments show that combining these two approaches effectively enables the low-resource language to surpass the performances of monolingual and bilingual counterparts for cross-modal retrieval tasks.
    
[^9]: 通过GPT-3自动形式化提高Diproche CNL系统

    Improving the Diproche CNL through autoformalization via GPT-3. (arXiv:2303.17513v1 [cs.CL])

    [http://arxiv.org/abs/2303.17513](http://arxiv.org/abs/2303.17513)

    本文探讨了在Diproche上使用大型语言模型进行自动形式化的可能性，并取得了令人鼓舞的初步结果。

    

    Diproche系统是一款针对德语控制语言片段的自动化证明检查器，旨在用于教学应用，在引导学生进行证明时使用。该系统的第一个版本使用一种控制自然语言，其Prolog形式化例程已经编写好。本文中，我们探讨了在Diproche上使用大型语言模型进行自动形式化的可能性，并取得了令人鼓舞的初步结果。

    The Diproche system is an automated proof checker for texts written in a controlled fragment of German, designed for didactical applications in classes introducing students to proofs for the first time. The first version of the system used a controlled natural language for which a Prolog formalization routine was written. In this paper, we explore the possibility of prompting large language models for autoformalization in the context of Diproche, with encouraging first results.
    
[^10]: 关于复杂大型语言模型的优劣（坑）。

    On pitfalls (and advantages) of sophisticated large language models. (arXiv:2303.17511v1 [cs.CY])

    [http://arxiv.org/abs/2303.17511](http://arxiv.org/abs/2303.17511)

    大型语言模型能够超越人类表现，但过度依赖可能会导致严重后果，包括难以区分的机器生成文本和各种形式的欺诈，进而产生新的伦理挑战。

    

    基于大型语言模型（LLMs）的自然语言处理是人工智能研究的一个蓬勃发展的领域。在神经网络已经在基于模式识别的游戏和实际领域中证明超越人类表现后，我们现在可能处于一个人工实体最终进入人类交流领域的十字路口。然而，这也带来了严重的风险。由于神经网络可靠性固有的限制，过度依赖LLMs可能带来破坏性后果。由于区分人类书写和机器生成的文本将变得越来越困难，人们面临着新的伦理挑战。从不再明确可验证的人类作者身份开始，继续涉及各种类型的欺诈，例如新形式的剽窃。这还涉及侵犯隐私权，可能传播人类伪造品，最后但同样重要的是，它使大规模传播错误信息成为可能。

    Natural language processing based on large language models (LLMs) is a booming field of AI research. After neural networks have proven to outperform humans in games and practical domains based on pattern recognition, we might stand now at a road junction where artificial entities might eventually enter the realm of human communication. However, this comes with serious risks. Due to the inherent limitations regarding the reliability of neural networks, overreliance on LLMs can have disruptive consequences. Since it will be increasingly difficult to distinguish between human-written and machine-generated text, one is confronted with new ethical challenges. This begins with the no longer undoubtedly verifiable human authorship and continues with various types of fraud, such as a new form of plagiarism. This also concerns the violation of privacy rights, the possibility of circulating counterfeits of humans, and, last but not least, it makes a massive spread of misinformation possible.
    
[^11]: 语言模型能够解决计算机任务

    Language Models can Solve Computer Tasks. (arXiv:2303.17491v1 [cs.CL])

    [http://arxiv.org/abs/2303.17491](http://arxiv.org/abs/2303.17491)

    本文研究表明，预训练的大型语言模型代理可以通过一个简单的提示方案使用自然语言执行计算机任务，该方法取得了很好的效果并在MiniWoB++基准测试中超越了监督学习和强化学习方法。

    

    能够在计算机上执行通用任务的代理可以通过自动化重复任务和协助复杂问题的解决来提高效率和生产力。理想情况下，这些代理应该能够通过自然语言命令解决新的计算机任务。然而，先前解决这个问题的方法需要大量专家示范和任务特定的奖励函数，这两者对于新任务来说都不切实际。在这项工作中，我们展示了一个预先训练的大型语言模型（LLM）代理可以使用一个简单的提示方案（RCI），通过自然语言指导执行计算机任务，并在批评和改进输出的过程中取得很好的效果。RCI方法在自动化计算机任务方面明显优于现有的LLM方法，并在MiniWoB++基准测试中超越了监督学习（SL）和强化学习（RL）方法。RCI方法使用每个任务仅有的少数示范，与最新的SL+RL方法相竞争。

    Agents capable of carrying out general tasks on a computer can improve efficiency and productivity by automating repetitive tasks and assisting in complex problem-solving. Ideally, such agents should be able to solve new computer tasks presented to them through natural language commands. However, previous approaches to this problem require large amounts of expert demonstrations and task-specific reward functions, both of which are impractical for new tasks. In this work, we show that a pre-trained large language model (LLM) agent can execute computer tasks guided by natural language using a simple prompting scheme where the agent recursively criticizes and improves its output (RCI). The RCI approach significantly outperforms existing LLM methods for automating computer tasks and surpasses supervised learning (SL) and reinforcement learning (RL) approaches on the MiniWoB++ benchmark. RCI is competitive with the state-of-the-art SL+RL method, using only a handful of demonstrations per ta
    
[^12]: 超越负采样的高效分布式表示方法

    Efficient distributed representations beyond negative sampling. (arXiv:2303.17475v1 [cs.LG])

    [http://arxiv.org/abs/2303.17475](http://arxiv.org/abs/2303.17475)

    本文介绍了一种高效的分布式表示（嵌入）学习方法，通过线性时间估计softmax归一化常数来实现学习过程，该方法优于负采样方法并在多项测试中验证了其有效性。

    

    本文介绍了一种高效的学习分布式表示（也称为嵌入）的方法。该方法通过最小化一个类似于Word2Vec算法中引入并在多个工作中采用的目标函数来实现。优化计算的瓶颈是softmax归一化常数的计算，这需要与样本大小呈二次比例的操作数。这种复杂度不适用于大型数据集，所以负采样是一个常见的解决方法，可以在与样本大小线性相关的时间内获得分布式表示。然而，负采样会改变损失函数，因此解决的是与最初提出的不同的优化问题。我们的贡献在于展示如何通过线性时间估计softmax归一化常数，从而设计了一种有效的优化策略来学习分布式表示。我们使用不同的数据集进行测试，并展示了我们的方法在嵌入质量和训练时间方面优于负采样。

    This article describes an efficient method to learn distributed representations, also known as embeddings. This is accomplished minimizing an objective function similar to the one introduced in the Word2Vec algorithm and later adopted in several works. The optimization computational bottleneck is the calculation of the softmax normalization constants for which a number of operations scaling quadratically with the sample size is required. This complexity is unsuited for large datasets and negative sampling is a popular workaround, allowing one to obtain distributed representations in linear time with respect to the sample size. Negative sampling consists, however, in a change of the loss function and hence solves a different optimization problem from the one originally proposed. Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations. We test our ap
    
[^13]: 评估ChatGPT与人类社会的跨文化对齐：一项实证研究

    Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study. (arXiv:2303.17466v1 [cs.CL])

    [http://arxiv.org/abs/2303.17466](http://arxiv.org/abs/2303.17466)

    本文通过分析ChatGPT对旨在量化人类文化差异的问题的回答，评估了其文化适应能力。发现ChatGPT在以美国背景为提示时表现出与美国文化的强烈对齐，但其对其他文化的适应能力较差，并且英文提示会抹平文化差异并偏向美国文化。

    

    近期发布的ChatGPT因其在对话中生成类人回应的卓越能力而广受认可。考虑到其被各国用户使用以及其训练了包含多样文化和社会规范的庞大多语料库，评估其文化适应能力至关重要。本文通过分析ChatGPT对旨在量化人类文化差异的问题的回答来调查其潜在的文化背景。我们的研究表明，当以美国背景为提示时，ChatGPT表现出与美国文化的强烈对齐，但其对其他文化背景的适应能力较差。此外，通过使用不同的提示来探测模型，我们发现英文提示会降低模型回答的差异，抹平文化差异并偏向美国文化。本研究对ChatGPT的文化影响提供了有价值的见解，并强调了进一步研究开发更具文化适应性的语言模型的必要性。

    The recent release of ChatGPT has garnered widespread recognition for its exceptional ability to generate human-like responses in dialogue. Given its usage by users from various nations and its training on a vast multilingual corpus that incorporates diverse cultural and societal norms, it is crucial to evaluate its effectiveness in cultural adaptation. In this paper, we investigate the underlying cultural background of ChatGPT by analyzing its responses to questions designed to quantify human cultural differences. Our findings suggest that, when prompted with American context, ChatGPT exhibits a strong alignment with American culture, but it adapts less effectively to other cultural contexts. Furthermore, by using different prompts to probe the model, we show that English prompts reduce the variance in model responses, flattening out cultural differences and biasing them towards American culture. This study provides valuable insights into the cultural implications of ChatGPT and highl
    
[^14]: 基于医学提示的语言增强Transformer编码器的医疗干预持续时间估计

    Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts. (arXiv:2303.17408v1 [cs.CL])

    [http://arxiv.org/abs/2303.17408](http://arxiv.org/abs/2303.17408)

    使用语言增强Transformer编码器，并结合医学提示，将结构化、非结构化的临床数据投影到一个语言潜空间中，以实现更精确的医学干预持续时间估计。

    

    近年来，基于电子病历(EHRs)估计医疗干预的持续时间在临床决策支持领域引起了重视。然而，当前的模型主要关注结构化数据，忽略了来自非结构化的临床自由文本数据的信息。为了解决这个问题，我们提出了一个新颖的语言增强Transformer-based框架，它使用经过预训练的句子编码器将所有相关的临床数据模态（连续、分类、二进制和自由文本特征）投影到一个协调的语言潜空间中，借助医学提示。所提出的方法使得不同模态的信息在单元变压器编码器中集成起来，从而实现更准确的医学干预持续时间估计。我们在美国（ICU住院时间估计）和亚洲（手术持续时间预测）医学数据集上的实验结果证明了我们提出的框架的有效性。

    In recent years, estimating the duration of medical intervention based on electronic health records (EHRs) has gained significant attention in the filed of clinical decision support. However, current models largely focus on structured data, leaving out information from the unstructured clinical free-text data. To address this, we present a novel language-enhanced transformer-based framework, which projects all relevant clinical data modalities (continuous, categorical, binary, and free-text features) into a harmonized language latent space using a pre-trained sentence encoder with the help of medical prompts. The proposed method enables the integration of information from different modalities within the cell transformer encoder and leads to more accurate duration estimation for medical intervention. Our experimental results on both US-based (length of stay in ICU estimation) and Asian (surgical duration prediction) medical datasets demonstrate the effectiveness of our proposed framewor
    
[^15]: WavCaps: 一种ChatGPT辅助的弱标注音频字幕数据集，用于音频-语言多模态研究

    WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research. (arXiv:2303.17395v1 [eess.AS])

    [http://arxiv.org/abs/2303.17395](http://arxiv.org/abs/2303.17395)

    本文介绍了第一个大规模的弱标注音频字幕数据集WavCaps，含约40万条带有配对字幕的音频剪辑。为克服噪声标注的问题，提出了基于ChatGPT的三阶段字幕生成流程。

    

    近年来，音频-语言（AL）多模态学习任务的发展非常显著。然而，现有的AL数据集收集过程昂贵费时，规模有限，给研究者带来了挑战。为解决这个数据稀缺问题，我们介绍了WavCaps，这是第一个包含大约40万条带有配对字幕的大规模弱标注音频字幕数据集。我们从Web资源和声音事件检测数据集中获取音频剪辑及原始描述。但是，在线收集到的原始描述非常嘈杂，不适合用于自动化音频字幕等任务。为了克服这个问题，我们提出了一个三阶段的处理流程，以过滤嘈杂数据并生成高质量字幕，在其中利用了ChatGPT，一种大型语言模型，来自动过滤和转换原始描述。我们对WavCaps的特征进行了全面的分析。

    The advancement of audio-language (AL) multimodal learning tasks has been significant in recent years. However, researchers face challenges due to the costly and time-consuming collection process of existing audio-language datasets, which are limited in size. To address this data scarcity issue, we introduce WavCaps, the first large-scale weakly-labelled audio captioning dataset, comprising approximately 400k audio clips with paired captions. We sourced audio clips and their raw descriptions from web sources and a sound event detection dataset. However, the online-harvested raw descriptions are highly noisy and unsuitable for direct use in tasks such as automated audio captioning. To overcome this issue, we propose a three-stage processing pipeline for filtering noisy data and generating high-quality captions, where ChatGPT, a large language model, is leveraged to filter and transform raw descriptions automatically. We conduct a comprehensive analysis of the characteristics of WavCaps 
    
[^16]: 基于BERT的无监督语法纠错框架

    A BERT-based Unsupervised Grammatical Error Correction Framework. (arXiv:2303.17367v1 [cs.CL])

    [http://arxiv.org/abs/2303.17367](http://arxiv.org/abs/2303.17367)

    本研究提出了一种基于BERT的无监督语法纠错框架，用于低资源语言的GEC任务。该框架包含三个模块，并提出一种新颖的伪困惑度评分方法，该方法已经在菲律宾语GEC任务上取得了竞争性的表现。

    

    语法错误纠正是自然语言处理技术中的一项具有挑战性的任务。虽然现在已经有更多的尝试在英语或汉语等通用语言的领域进行研究，但由于缺乏大型注释语料库，对于低资源语言的工作仍然相对较少。在低资源语言领域，目前基于语言模型的无监督GEC具有较好的表现。但是，在这种情况下，预训练的语言模型仍需探索。本研究提出了一种基于BERT的无监督GEC框架，将GEC视为多类分类任务。该框架包含三个模块：数据流构建模块、句子困惑度评分模块和错误检测和纠正模块。我们提出了一种新颖的伪困惑度评分方法，用于评估句子的可能正确性，并建立了一个菲律宾语语料库，用于进行菲律宾语GEC研究。该方法在我们构建的菲律宾语语料库上获得了竞争性的表现，并已在开源平台上公布。

    Grammatical error correction (GEC) is a challenging task of natural language processing techniques. While more attempts are being made in this approach for universal languages like English or Chinese, relatively little work has been done for low-resource languages for the lack of large annotated corpora. In low-resource languages, the current unsupervised GEC based on language model scoring performs well. However, the pre-trained language model is still to be explored in this context. This study proposes a BERT-based unsupervised GEC framework, where GEC is viewed as multi-class classification task. The framework contains three modules: data flow construction module, sentence perplexity scoring module, and error detecting and correcting module. We propose a novel scoring method for pseudo-perplexity to evaluate a sentence's probable correctness and construct a Tagalog corpus for Tagalog GEC research. It obtains competitive performance on the Tagalog corpus we construct and open-source 
    
[^17]: 《堆栈中的话题：超越连贯性的主题提取和评估》

    Topics in the Haystack: Extracting and Evaluating Topics beyond Coherence. (arXiv:2303.17324v1 [cs.CL])

    [http://arxiv.org/abs/2303.17324](http://arxiv.org/abs/2303.17324)

    这项研究提出了一种新的主题提取方法，可以检测包含不常见词汇的潜在主题，并提出了新的评估指标，在干扰词识别任务上获得接近于人类水平的结果。

    

    在自然语言处理领域中，从大型文本语料库中提取和识别潜在主题变得越来越重要。大多数模型，无论是类似于潜在狄利克雷分配（LDA）的概率模型，还是神经主题模型，都遵循主题可解释性和主题提取的相同基本方法。我们提出了一种方法，结合了对句子和文档主题的深刻理解，并超越了对数据中单词频率的简单分析。这使得我们的模型能够检测到包含不常见单词或新词的潜在主题，以及不在文档本身中出现的单词。此外，我们提出了几个基于干扰词和语义空间中相似度测量的新的评估指标。我们提出了与人类干扰词识别的相关系数，并在单词干扰任务上获得了接近于人类水平的结果。我们通过一项大型基准研究展示了我们方法的竞争性能。

    Extracting and identifying latent topics in large text corpora has gained increasing importance in Natural Language Processing (NLP). Most models, whether probabilistic models similar to Latent Dirichlet Allocation (LDA) or neural topic models, follow the same underlying approach of topic interpretability and topic extraction. We propose a method that incorporates a deeper understanding of both sentence and document themes, and goes beyond simply analyzing word frequencies in the data. This allows our model to detect latent topics that may include uncommon words or neologisms, as well as words not present in the documents themselves. Additionally, we propose several new evaluation metrics based on intruder words and similarity measures in the semantic space. We present correlation coefficients with human identification of intruder words and achieve near-human level results at the word-intrusion task. We demonstrate the competitive performance of our method with a large benchmark study,
    
[^18]: 能否使用ChatGPT识别历史文献中的实体？

    Yes but.. Can ChatGPT Identify Entities in Historical Documents?. (arXiv:2303.17322v1 [cs.DL])

    [http://arxiv.org/abs/2303.17322](http://arxiv.org/abs/2303.17322)

    本文通过比较ChatGPT和最先进的基于LM的系统，探究了它在历史文献中进行命名实体识别和分类的能力，发现存在多方面的缺陷，包括实体复杂性和提示特定性等。

    

    大型语言模型(LLM)多年来一直被用于现代文档中的实体识别，取得了最先进的性能。最近几个月，会话代理ChatGPT由于其生成听起来合理的答案的能力，在科学界和公众中引起了很多兴趣。本文尝试以零-shot的方式探究ChatGPT在一次性源（例如历史报纸和古典注释）中进行命名实体识别和分类（NERC）任务的能力，并将其与最先进的基于LM的系统进行比较。研究发现，在识别历史文本中的实体方面存在几个缺陷，包括实体注释准则的一致性、实体的复杂性和代码切换以及提示的特定性。此外，由于历史档案对公众不可访问（因此无法在互联网上使用），也影响了ChatGPT的性能。

    Large language models (LLMs) have been leveraged for several years now, obtaining state-of-the-art performance in recognizing entities from modern documents. For the last few months, the conversational agent ChatGPT has "prompted" a lot of interest in the scientific community and public due to its capacity of generating plausible-sounding answers. In this paper, we explore this ability by probing it in the named entity recognition and classification (NERC) task in primary sources (e.g., historical newspapers and classical commentaries) in a zero-shot manner and by comparing it with state-of-the-art LM-based systems. Our findings indicate several shortcomings in identifying entities in historical text that range from the consistency of entity annotation guidelines, entity complexity, and code-switching, to the specificity of prompting. Moreover, as expected, the inaccessibility of historical archives to the public (and thus on the Internet) also impacts its performance.
    
[^19]: 在GPT成功和失败的情况下，人类输入人类输出：论GPT朝向常识的趋同性

    Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure. (arXiv:2303.17276v1 [cs.AI])

    [http://arxiv.org/abs/2303.17276](http://arxiv.org/abs/2303.17276)

    本文研究了GPT-3、GPT-3.5和GPT-4模型在人类思维模式中的表现, 运用认识论理论提供了符号生成模型，通过实验证实的人类判断数据点以及ETR预测数据点的数量级对模型进行了检验。

    

    计算规模和微调的增加使得大语言模型（LLM）例如GPT的输出质量得到了显著提高。鉴于GPT-3和GPT-4都是使用大量由人类生成的文本进行训练的，我们可以问他们的输出在多大程度上反映了人类思维的模式，无论是正确还是错误的情况。认识论理论提供了关于人类成功和失败的符号生成模型，包括命题、量化、概率推理和决策。本文将ETR的最近一个书本的61个核心推理和判断问题提供给了GPT-3、GPT-3.5和GPT-4，这些问题包括经过实验证实的人类判断数据点和ETR预测的数据点，同时包含正确的推理模式和谬误和框架效应（ETR61基准测试）。 ETR61包括了Wason的卡牌任务、错觉推理、诱饵效应等经典案例。

    Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT. Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases. The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making. We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and
    
[^20]: 《北欧根桩:一个1.2TB的北欧语言建模数据集》

    The Nordic Pile: A 1.2TB Nordic Dataset for Language Modeling. (arXiv:2303.17183v1 [cs.CL])

    [http://arxiv.org/abs/2303.17183](http://arxiv.org/abs/2303.17183)

    本论文描述了一个包含1.2TB文本的北欧语言数据集，为预训练大型语言模型提供了重要资源，促进了北欧语言的LLMs的开发。

    

    预训练大型语言模型( LLMs )需要海量的文本数据，LLMs的性能通常与数据集的规模和质量相关。这意味着在北欧等语种中建立LLMs可能是具有挑战性的，因为其文本语料库的可用性有限。为了促进北欧语言的LLMs开发，我们策划了一个高质量的数据集，其中包括了1.2TB的文本，涵盖了所有重要的北日耳曼语言（丹麦语、冰岛语、挪威语和瑞典语），以及一些高质量的英文数据。本文详细介绍了我们收集、清理和过滤该数据集的考虑和流程。

    Pre-training Large Language Models (LLMs) require massive amounts of text data, and the performance of the LLMs typically correlates with the scale and quality of the datasets. This means that it may be challenging to build LLMs for smaller languages such as Nordic ones, where the availability of text corpora is limited. In order to facilitate the development of the LLMS in the Nordic languages, we curate a high-quality dataset consisting of 1.2TB of text, in all of the major North Germanic languages (Danish, Icelandic, Norwegian, and Swedish), as well as some high-quality English data. This paper details our considerations and processes for collecting, cleaning, and filtering the dataset.
    
[^21]: TreePiece：通过树状分割提高语义解析速度

    TreePiece: Faster Semantic Parsing via Tree Tokenization. (arXiv:2303.17161v1 [cs.CL])

    [http://arxiv.org/abs/2303.17161](http://arxiv.org/abs/2303.17161)

    本文提出的TreePiece技术将解析树分割成子树，以加速自回归模型用于语义分析的过程，相比标准自回归提高了4.6倍的解码速度，并在速度相当的情况下准确性更高于非自回归方法。

    

    自回归编码器-解码器神经网络已经在许多自然语言处理问题中取得了成功，包括语义解析（一种将自然语言转换为机器可读的解析树的任务）。然而，自回归模型的顺序预测过程可能会很慢。为了加速用于语义分析的自回归模型，我们引入了一种新技术，称为TreePiece，它将解析树分割成子树，并在每个解码步骤中生成一个子树。在TopV2基准测试中，TreePiece的解码速度比标准自回归快4.6倍，比非自回归方法（NAR）的速度相当但准确性显着更高。

    Autoregressive (AR) encoder-decoder neural networks have proved successful in many NLP problems, including Semantic Parsing -- a task that translates natural language to machine-readable parse trees. However, the sequential prediction process of AR models can be slow. To accelerate AR for semantic parsing, we introduce a new technique called TreePiece that tokenizes a parse tree into subtrees and generates one subtree per decoding step. On TopV2 benchmark, TreePiece shows 4.6 times faster decoding speed than standard AR, and comparable speed but significantly higher accuracy compared to Non-Autoregressive (NAR).
    
[^22]: TLAG: 一种信息触发器和标签感知知识引导模型用于基于对话的关系抽取

    TLAG: An Informative Trigger and Label-Aware Knowledge Guided Model for Dialogue-based Relation Extraction. (arXiv:2303.17119v1 [cs.CL])

    [http://arxiv.org/abs/2303.17119](http://arxiv.org/abs/2303.17119)

    TLAG是一种信息触发器和标签感知知识引导模型，通过充分利用触发器和标签信息以及引入标签感知知识来促进基于对话的关系抽取。

    

    基于对话的关系抽取（DRE）旨在预测在对话中提到的参数对的关系类型。最新的触发器增强方法提出了触发器预测任务以促进DRE。然而，这些方法不能充分利用触发器信息，甚至会给关系抽取带来噪声。为了解决这些问题，我们提出了TLAG，它充分利用触发器和标签感知知识来引导关系抽取。首先，我们设计了一个自适应触发器融合模块来充分利用触发器信息。然后，我们引入了标签感知知识，进一步提升了模型的性能。在DialogRE数据集上的实验结果表明，我们的TLAG优于基准模型，并且详细的分析表明了我们方法的有效性。

    Dialogue-based Relation Extraction (DRE) aims to predict the relation type of argument pairs that are mentioned in dialogue. The latest trigger-enhanced methods propose trigger prediction tasks to promote DRE. However, these methods are not able to fully leverage the trigger information and even bring noise to relation extraction. To solve these problems, we propose TLAG, which fully leverages the trigger and label-aware knowledge to guide the relation extraction. First, we design an adaptive trigger fusion module to fully leverage the trigger information. Then, we introduce label-aware knowledge to further promote our model's performance. Experimental results on the DialogRE dataset show that our TLAG outperforms the baseline models, and detailed analyses demonstrate the effectiveness of our approach.
    
[^23]: DERA: 使用对话型解决代理提高大型语言模型的补全能力

    DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents. (arXiv:2303.17071v1 [cs.CL])

    [http://arxiv.org/abs/2303.17071](http://arxiv.org/abs/2303.17071)

    本文介绍了一种名为DERA的对话型解决代理，该代理利用LLM的对话能力提高了模型的补全能力。DERA框架化为两个代理类型之间的讨论，可以在医疗对话摘要和护理计划生成方面实现显著改进。

    

    大型语言模型已成为许多自然语言理解任务的有价值工具。在医疗等关乎安全性的应用中，这些模型的实用性取决于它们生成的输出是否具备事实准确和完整性。本文介绍了对话型解决代理（DERA）。DERA是一种由LLM（特别是GPT-4）的对话能力提供支持的模式，它为模型提供了一个简单且易于理解的论坛，用于沟通反馈并迭代改进输出。我们将对话框架化为两个代理类型之间的讨论：一个研究人员，负责处理信息并识别关键问题组件；以及一个决策者，具有将研究人员的信息集成并对最终输出做出判定的自主权。我们将DERA用于三个临床相关任务的测试。在医疗对话摘要和护理计划生成方面，DERA显示出比基础GPT-4性能显著提高的效果。

    Large language models (LLMs) have emerged as valuable tools for many natural language understanding tasks. In safety-critical applications such as healthcare, the utility of these models is governed by their ability to generate outputs that are factually accurate and complete. In this work, we present dialog-enabled resolving agents (DERA). DERA is a paradigm made possible by the increased conversational abilities of LLMs, namely GPT-4. It provides a simple, interpretable forum for models to communicate feedback and iteratively improve output. We frame our dialog as a discussion between two agent types - a Researcher, who processes information and identifies crucial problem components, and a Decider, who has the autonomy to integrate the Researcher's information and makes judgments on the final output.  We test DERA against three clinically-focused tasks. For medical conversation summarization and care plan generation, DERA shows significant improvement over the base GPT-4 performance 
    
[^24]: 解码算法在对话回应中如何分发信息？

    How do decoding algorithms distribute information in dialogue responses?. (arXiv:2303.17006v1 [cs.CL])

    [http://arxiv.org/abs/2303.17006](http://arxiv.org/abs/2303.17006)

    该论文研究了在对话生成中解码算法是否遵循均匀信息密度原则（将信息均匀分配在话语中）。研究发现模型生成的回应比人的回应更加遵循该原则，促进该原则的解码算法并没有提高回应质量。此外，作者还发现信息密度的不均匀性与惊奇度非常低/高的回应的质量相关，鼓励非均匀回应是“可能性陷阱”问题的潜在解决方案。

    

    人类倾向于遵循均匀信息密度（UID）原则，在话语中均匀分配信息。我们研究了解码算法是否会隐式地遵循UID原则，并在什么条件下遵守UID可能对对话生成有益。我们使用不同的解码算法在Persona-Chat数据集上生成回应，并使用Amazon Mechanical Turk收集人类对它们质量的判断。我们发现（i）出乎意料的是，模型生成的回应比人的回应更加遵循UID原则，以及（ii）促进UID的解码算法并没有生成更高质量的回应。相反，当我们控制惊奇度时，信息密度的不均匀性与惊奇度非常低/高的回应的质量相关。我们的发现表明，鼓励非均匀回应是“可能性陷阱”问题（非常高可能性文本的质量下降）的潜在解决方案。我们的数据集包括了...

    Humans tend to follow the Uniform Information Density (UID) principle by distributing information evenly in utterances. We study if decoding algorithms implicitly follow this UID principle, and under what conditions adherence to UID might be desirable for dialogue generation. We generate responses using different decoding algorithms with GPT-2 on the Persona-Chat dataset and collect human judgments on their quality using Amazon Mechanical Turk. We find that (i) surprisingly, model-generated responses follow the UID principle to a greater extent than human responses, and (ii) decoding algorithms that promote UID do not generate higher-quality responses. Instead, when we control for surprisal, non-uniformity of information density correlates with the quality of responses with very low/high surprisal. Our findings indicate that encouraging non-uniform responses is a potential solution to the ``likelihood trap'' problem (quality degradation in very high-likelihood text). Our dataset contai
    
[^25]: 在巴西大学入学考试中评估GPT-3.5和GPT-4模型

    Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams. (arXiv:2303.17003v1 [cs.CL])

    [http://arxiv.org/abs/2303.17003](http://arxiv.org/abs/2303.17003)

    本研究在巴西大学入学考试中评估了GPT-3.5和GPT-4模型，分析了不同提示策略，最终发现GPT-4与Chain-of-Thought提示结合表现最好，在2022年考试中准确率达到了87％。

    

    本研究旨在探索语言模型（LMs）在应对高风险的多项选择测试中的能力，这里以巴西大学广泛采用的多学科入学考试Exame Nacional do Ensino Médio（ENEM）为例。该考试对LMs提出了挑战，因为其问题可能涉及多个知识领域，需要理解来自不同领域的信息。例如，一个问题可能需要理解统计学和生物学才能解决。本研究分析了GPT-3.5和GPT-4模型对2009年至2017年考试以及2022年公开的考试问题的响应。此外，还测试了不同的提示策略，包括使用Chain-of-Thought（CoT）提示生成答案的解释。在2022年的考试中，表现最佳的模型是GPT-4并使用了CoT，在准确率方面达到了87％。

    The present study aims to explore the capabilities of Language Models (LMs) in tackling high-stakes multiple-choice tests, represented here by the Exame Nacional do Ensino M\'edio (ENEM), a multidisciplinary entrance examination widely adopted by Brazilian universities. This exam poses challenging tasks for LMs, since its questions may span into multiple fields of knowledge, requiring understanding of information from diverse domains. For instance, a question may require comprehension of both statistics and biology to be solved. This work analyzed responses generated by GPT-3.5 and GPT-4 models for questions presented in the 2009-2017 exams, as well as for questions of the 2022 exam, which were made public after the training of the models was completed. Furthermore, different prompt strategies were tested, including the use of Chain-of-Thought (CoT) prompts to generate explanations for answers. On the 2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracy of 87%,
    
[^26]: ContraSim -- 基于对比学习的相似度度量方法

    ContraSim -- A Similarity Measure Based on Contrastive Learning. (arXiv:2303.16992v1 [cs.CL])

    [http://arxiv.org/abs/2303.16992](http://arxiv.org/abs/2303.16992)

    本文提出了一种新的相似度度量方法: ContraSim，该方法利用对比学习学习参数化的度量方法。实验表明，ContraSim在多种基准测试中均获得了比之前相似度量方法更高的准确性。

    

    最近有研究通过基于相似性的分析比较神经网络表示，揭示了不同方面（如架构、训练数据等）如何影响模型的内部表示。相似度量的质量通常通过其在预期匹配的表示中分配高分数的成功来评估。然而，现有的相似度量在标准基准测试中表现平庸。本文提出一种新的相似度度量方法，称为ContraSim，基于对比学习，与常见的闭式相似性度量不同，ContraSim使用相似和不相似的示例来学习参数化的度量方法。我们在标准的图层预测基准测试和我们介绍的两个新基准测试中使用语言和视觉模型进行广泛的实验评估：多语言基准测试和图像字幕基准测试。在所有情况下，ContraSim的准确性都比之前的相似度量方法高得多。

    Recent work has compared neural network representations via similarity-based analyses, shedding light on how different aspects (architecture, training data, etc.) affect models' internal representations. The quality of a similarity measure is typically evaluated by its success in assigning a high score to representations that are expected to be matched. However, existing similarity measures perform mediocrely on standard benchmarks. In this work, we develop a new similarity measure, dubbed ContraSim, based on contrastive learning. In contrast to common closed-form similarity measures, ContraSim learns a parameterized measure by using both similar and dissimilar examples. We perform an extensive experimental evaluation of our method, with both language and vision models, on the standard layer prediction benchmark and two new benchmarks that we introduce: the multilingual benchmark and the image-caption benchmark. In all cases, ContraSim achieves much higher accuracy than previous simila
    
[^27]: 适应低资源双连通性: 探究对非洲低资源语言采用低计算方法的有效性

    Adapting to the Low-Resource Double-Bind: Investigating Low-Compute Methods on Low-Resource African Languages. (arXiv:2303.16985v1 [cs.CL])

    [http://arxiv.org/abs/2303.16985](http://arxiv.org/abs/2303.16985)

    本文探讨了在低资源条件下，采用语言适配器等低计算方法在非洲语言上进行NLP研究的有效性，并通过微调实验得出了实现可比性能的结论。

    

    自然语言处理(NLP)的许多任务都使用大规模的预训练语言模型，但这些模型计算成本高昂。然而，非洲语言数据的稀缺性和高计算资源的获取限制了对这些语言进行研究的可能性。本文探讨了在这种低资源双连通性背景下，语言适配器等低计算方法的适用性。我们试图回答以下问题：语言适配器是否允许那些在数据和计算方面双重受限的人实际上构建有用的模型？通过在非洲语言上进行微调实验，我们评估了它们作为低资源非洲NLP的成本效益方法的有效性。使用全部免费计算资源，我们的结果显示，与计算资源损耗大的大规模预训练语言模型相比，语言适配器实现了可比的性能。这为进一步的实验和探索打开了大门。

    Many natural language processing (NLP) tasks make use of massively pre-trained language models, which are computationally expensive. However, access to high computational resources added to the issue of data scarcity of African languages constitutes a real barrier to research experiments on these languages. In this work, we explore the applicability of low-compute approaches such as language adapters in the context of this low-resource double-bind. We intend to answer the following question: do language adapters allow those who are doubly bound by data and compute to practically build useful models? Through fine-tuning experiments on African languages, we evaluate their effectiveness as cost-effective approaches to low-resource African NLP. Using solely free compute resources, our results show that language adapters achieve comparable performances to massive pre-trained language models which are heavy on computational resources. This opens the door to further experimentation and explor
    
[^28]: BEVERS: 一个通用、简单且高性能的自动事实验证框架

    BEVERS: A General, Simple, and Performant Framework for Automatic Fact Verification. (arXiv:2303.16974v1 [cs.CL])

    [http://arxiv.org/abs/2303.16974](http://arxiv.org/abs/2303.16974)

    BEVERS是一个特别针对FEVER数据集进行调整的基准系统，具有通用性、简单性和高性能的特点，并在FEVER和Scifact数据集上取得了最高的标签准确性。

    

    自动事实验证近年来成为越来越受欢迎的研究课题，其中Fact Extraction and VERification（FEVER）数据集是最受欢迎的之一。本文介绍了BEVERS，一个特别针对FEVER数据集进行调整的基准系统。我们的流程使用了标准的文档检索、句子选择和最终声明分类方法，但我们花费了相当多的力气来确保每个组件的最佳性能。结果是，BEVERS 在所有已发布和未发布的文献中实现了最高的FEVER得分和标签准确性。我们还将此流程应用于另一个事实验证数据集Scifact上，并在该数据集上实现了所有系统中最高的标签准确性。我们还提供了完整的代码。

    Automatic fact verification has become an increasingly popular topic in recent years and among datasets the Fact Extraction and VERification (FEVER) dataset is one of the most popular. In this work we present BEVERS, a tuned baseline system for the FEVER dataset. Our pipeline uses standard approaches for document retrieval, sentence selection, and final claim classification, however, we spend considerable effort ensuring optimal performance for each component. The results are that BEVERS achieves the highest FEVER score and label accuracy among all systems, published or unpublished. We also apply this pipeline to another fact verification dataset, Scifact, and achieve the highest label accuracy among all systems on that dataset as well. We also make our full code available.
    
[^29]: MaMMUT: 一种用于多模态任务联合学习的简单架构

    MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks. (arXiv:2303.16839v1 [cs.CV])

    [http://arxiv.org/abs/2303.16839](http://arxiv.org/abs/2303.16839)

    提出了一种名为MaMMUT的简单模型，可以通过两步方法容纳对比和生成学习，并在联合训练不同的视觉语言任务时表现出很高的效力。

    

    语言模型的发展已从编码-解码转向仅解码的设计。此外，普遍认为，最流行的两种多模态任务，生成任务和对比任务，往往互相冲突，难以在一个架构中容纳，并进一步需要用于下游任务的复杂调整。我们提出了一种新的培训范式，用于多模态任务的仅解码模型，这在联合学习这些不同的视觉语言任务方面非常有效。这是通过一个简单的模型MaMMUT实现的。它由单一的视觉编码器和一个文本解码器组成，并能够通过文本解码器上的新的两步方法容纳对比和生成学习。我们证明这些不同目标任务的联合训练是简单的，有效的，并最大化了模型的权重共享。此外，相同的架构使得对开放词汇对象检测的简单扩展成为可能。

    The development of language models have moved from encoder-decoder to decoder-only designs. In addition, the common knowledge has it that the two most popular multimodal tasks, the generative and contrastive tasks, tend to conflict with one another, are hard to accommodate in one architecture, and further need complex adaptations for downstream tasks. We propose a novel paradigm of training with a decoder-only model for multimodal tasks, which is surprisingly effective in jointly learning of these disparate vision-language tasks. This is done with a simple model, called MaMMUT. It consists of a single vision encoder and a text decoder, and is able to accommodate contrastive and generative learning by a novel two-pass approach on the text decoder. We demonstrate that joint training of these diverse-objective tasks is simple, effective, and maximizes the weight-sharing of the model. Furthermore, the same architecture enables straightforward extensions to open-vocabulary object detection 
    
[^30]: 通过指导大型语言模型进行统一文本结构化

    Unified Text Structuralization with Instruction-tuned Language Models. (arXiv:2303.14956v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.14956](http://arxiv.org/abs/2303.14956)

    本研究提出了一种使用指导语言模型从文本中提取各种结构的方法，解决了文本结构化领域缺乏高质量数据集且信息提取难以推广的问题。

    

    文本结构化是自然语言处理领域中信息提取和结构形式化的重要领域之一。然而，目前的文本结构化研究缺乏来自不同领域和语言的高质量手工注释数据集，需要专业知识。此外，大多数信息提取方法都针对特定类型的结构化数据设计，例如实体、关系和事件，使它们难以推广到其他领域。在本研究中，我们提出了一种简单而有效的方法，用于指导大型语言模型从文本中提取各种结构。更具体地说，我们在将文本馈入大型语言模型之前，添加前缀和后缀指令，以指示所需要的信息提取任务和结构类型。在两个大型语言模型的实验中，结果表明这种方法可以使语言模型在各种语言的数据集上表现出与其他最先进方法相当的结果。

    Text structuralization is one of the important fields of natural language processing (NLP) consists of information extraction (IE) and structure formalization. However, current studies of text structuralization suffer from a shortage of manually annotated high-quality datasets from different domains and languages, which require specialized professional knowledge. In addition, most IE methods are designed for a specific type of structured data, e.g., entities, relations, and events, making them hard to generalize to others. In this work, we propose a simple and efficient approach to instruct large language model (LLM) to extract a variety of structures from texts. More concretely, we add a prefix and a suffix instruction to indicate the desired IE task and structure type, respectively, before feeding the text into a LLM. Experiments on two LLMs show that this approach can enable language models to perform comparable with other state-of-the-art methods on datasets of a variety of languag
    
[^31]: 预训练基础模型综述：从BERT到ChatGPT的历程

    A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT. (arXiv:2302.09419v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09419](http://arxiv.org/abs/2302.09419)

    本文全面回顾了预训练基础模型的最新研究进展和发展历程，包括它们的架构、培训目标、预培训任务、微调策略和评估。同时，讨论了其局限性和未来研究方向。

    

    预训练基础模型(PFMs)被认为是各种不同数据模态下游任务的基础。PFM(例如BERT、ChatGPT和GPT-4)在大规模数据上进行训练，为各种下游应用提供了合理的参数初始化。BERT从转换器中学习双向编码器表示，这些模型作为上下文语言模型在大型数据集上进行训练。类似地，生成式预训练变压器(GPT)方法采用转换器作为特征提取器，并采用自回归范式在大型数据集上进行训练。最近，ChatGPT在大语言模型中展现了令人兴奋的成功，它采用自回归式语言模型，可以进行零射击或少射击提示。PFM的卓越成就为各种AI领域带来了重大突破。许多研究提出了不同的方法，提高了对更新调查的需求。本研究全面回顾了PFMs的最新进展，包括它们的架构、培训目标、预培训任务、微调策略和评估。此外，我们还讨论了PFMs的局限性和未来潜在的研究方向。

    Pretrained Foundation Models (PFMs) are regarded as the foundation for various downstream tasks with different data modalities. A PFM (e.g., BERT, ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable parameter initialization for a wide range of downstream applications. BERT learns bidirectional encoder representations from Transformers, which are trained on large datasets as contextual language models. Similarly, the generative pretrained transformer (GPT) method employs Transformers as the feature extractor and is trained using an autoregressive paradigm on large datasets. Recently, ChatGPT shows promising success on large language models, which applies an autoregressive language model with zero shot or few shot prompting. The remarkable achievements of PFM have brought significant breakthroughs to various fields of AI. Numerous studies have proposed different methods, raising the demand for an updated survey. This study provides a comprehensive review of rec
    
[^32]: 人工智能心理学中的“正确答案”

    "Correct answers" from the psychology of artificial intelligence. (arXiv:2302.07267v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.07267](http://arxiv.org/abs/2302.07267)

    本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。

    This paper replicates 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, and successfully replicates the results of 8 studies. However, for the remaining 6 studies, GPT3.5 answered survey questions in an extremely predetermined way, making it impossible to analyze these studies.

    大型语言模型的能力已经大大增强。这种AI系统的一个提出的应用是支持社会和认知科学中的数据收集，目前完美的实验控制是不可行的，而大规模、代表性数据集的收集通常是昂贵的。在本文中，我们使用OpenAI的text-davinci-003模型（俗称GPT3.5）重新复制了Many Labs 2复制项目中的14项研究。我们通过将每项研究的调查作为文本输入，从GPT3.5的默认设置中收集了响应。在我们可以分析的八项研究中，我们的GPT样本复制了原始结果的37.5%以及Many Labs 2结果的37.5%。出乎意料的是，我们无法像预先注册的计划那样分析剩下的六项研究。这是因为对于这六项研究中的每一项，GPT3.5以极其预定的方式回答了调查问题（无论是因变量还是条件变量）：一个未知的

    Large Language Models have vastly grown in capabilities. One proposed application of such AI systems is to support data collection in the social and cognitive sciences, where perfect experimental control is currently unfeasible and the collection of large, representative datasets is generally expensive. In this paper, we re-replicate 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, colloquially known as GPT3.5. We collected responses from the default setting of GPT3.5 by inputting each study's survey as text. Among the eight studies we could analyse, our GPT sample replicated 37.5% of the original results as well as 37.5% of the Many Labs 2 results. Unexpectedly, we could not analyse the remaining six studies as we had planned in our pre-registration. This was because for each of these six studies, GPT3.5 answered at least one of the survey questions (either a dependent variable or a condition variable) in an extremely predetermined way: an unex
    
[^33]: TempCLR:基于对比学习的时间对齐表示

    TempCLR: Temporal Alignment Representation with Contrastive Learning. (arXiv:2212.13738v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.13738](http://arxiv.org/abs/2212.13738)

    本文提出了一个基于对比学习的框架TempCLR，用于显式比较完整的视频和段落，解决单元级别比较可能忽略全局时间上下文的问题。

    

    视频表示学习在视频-文本预训练中取得了成功，在其中每个句子都被训练为接近于共同特征空间中配对的视频剪辑。然而，对于长视频，由于句子描述视频的不同部分，单元级别的比较可能会忽略全局的时间上下文，这必然会限制泛化能力。为此，我们提出了一个对比学习框架TempCLR，以显式地比较完整的视频和段落。

    Video representation learning has been successful in video-text pre-training for zero-shot transfer, where each sentence is trained to be close to the paired video clips in a common feature space. For long videos, given a paragraph of description where the sentences describe different segments of the video, by matching all sentence-clip pairs, the paragraph and the full video are aligned implicitly. However, such unit-level comparison may ignore global temporal context, which inevitably limits the generalization ability. In this paper, we propose a contrastive learning framework TempCLR to compare the full video and the paragraph explicitly. As the video/paragraph is formulated as a sequence of clips/sentences, under the constraint of their temporal order, we use dynamic time warping to compute the minimum cumulative cost over sentence-clip pairs as the sequence-level distance. To explore the temporal dynamics, we break the consistency of temporal succession by shuffling video clips w.
    
[^34]: LLM-Planner: 利用大型语言模型进行少样本实体代理规划

    LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models. (arXiv:2212.04088v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.04088](http://arxiv.org/abs/2212.04088)

    本研究提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划，实验表明其在多任务和快速学习新任务的通用代理的开发中具有很好的表现。

    

    本研究关注利用大型语言模型（LLMs）作为规划器，让实体代理可以按照自然语言指令完成在视觉感知环境中的复杂任务。现有方法的高数据成本和低样本效率阻碍了多任务和快速学习新任务的通用代理的开发。本文提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划。我们进一步提出了一种简单但有效的方法，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划。在ALFRED数据集上的实验表明，我们的方法可以取得非常有竞争力的少样本性能：尽管使用的配对训练数据不到0.5％，LLM-Planner的表现与使用完整训练数据训练的最新基线相当。现有方法几乎无法完成任何任务。

    This study focuses on using large language models (LLMs) as a planner for embodied agents that can follow natural language instructions to complete complex tasks in a visually-perceived environment. The high data cost and poor sample efficiency of existing methods hinders the development of versatile agents that are capable of many tasks and can learn new tasks quickly. In this work, we propose a novel method, LLM-Planner, that harnesses the power of large language models to do few-shot planning for embodied agents. We further propose a simple but effective way to enhance LLMs with physical grounding to generate and update plans that are grounded in the current environment. Experiments on the ALFRED dataset show that our method can achieve very competitive few-shot performance: Despite using less than 0.5% of paired training data, LLM-Planner achieves competitive performance with recent baselines that are trained using the full training data. Existing methods can barely complete any ta
    
[^35]: 社交媒体文本深度时间建模在临床抑郁症中的应用

    Deep Temporal Modelling of Clinical Depression through Social Media Text. (arXiv:2211.07717v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07717](http://arxiv.org/abs/2211.07717)

    本文通过使用抑郁症状检测分类器，从社交媒体文本提取临床相关特征，建立了一个模型用于检测用户的临床抑郁症，通过提供不同时间粒度的准确度度量来评估该模型。

    

    本文描述了一种基于用户时间轴社交媒体帖子的模型，用于检测用户的临床抑郁症。我们的模型使用了抑郁症状检测（DSD）分类器，该分类器基于最大数量的已经过临床医师注释的推文。我们随后使用我们的DSD模型来提取临床相关特征，例如抑郁症评分及其随后的时间模式，以及用户发布活动模式，例如量化他们的“无活动”或“沉默”。此外，为了评估这些提取特征的有效性，我们创建了三种数据集，包括来自两个现有的众所周知的用户级别抑郁症检测基准数据集的测试数据集。然后，我们提供了基于单个特征、基线特征和特征削减测试的准确度度量，在不同时间粒度的几个级别上。

    We describe the development of a model to detect user-level clinical depression based on a user's temporal social media posts. Our model uses a Depression Symptoms Detection (DSD) classifier, which is trained on the largest existing samples of clinician annotated tweets for clinical depression symptoms. We subsequently use our DSD model to extract clinically relevant features, e.g., depression scores and their consequent temporal patterns, as well as user posting activity patterns, e.g., quantifying their ``no activity'' or ``silence.'' Furthermore, to evaluate the efficacy of these extracted features, we create three kinds of datasets including a test dataset, from two existing well-known benchmark datasets for user-level depression detection. We then provide accuracy measures based on single features, baseline features and feature ablation tests, at several different levels of temporal granularity. The relevant data distributions and clinical depression detection related settings can
    
[^36]: 低资源多语言神经机器翻译的语言家族适配器

    Language-Family Adapters for Low-Resource Multilingual Neural Machine Translation. (arXiv:2209.15236v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.15236](http://arxiv.org/abs/2209.15236)

    本文提出在mBART-50的基础上训练语言家族适配器，以提高低资源语言的翻译性能，该方法优于其他基线。

    

    自监督预训练的大型多语言模型在广泛的自然语言处理任务中取得了最先进的结果。这些预训练模型往往会在一个或多个语言对的平行数据上进行微调，以用于机器翻译。多语言微调可以提高低资源语言的性能，但需要修改整个模型，可能成本过高。一种参数有效的选择是针对每个语言对训练一个新的适配器，或在不更新预训练模型的情况下针对所有语言对进行单一适配器的训练。然而，前者不允许语言之间共享参数，而后者则共享所有语言的参数，容易受到负面干扰。在本文中，我们提出在mBART-50的基础上训练语言家族适配器，以促进跨语言转移。我们的方法优于相关基线，在翻译过程中平均获得更高的翻译分数。

    Large multilingual models trained with self-supervision achieve state-of-the-art results in a wide range of natural language processing tasks. Self-supervised pretrained models are often fine-tuned on parallel data from one or multiple language pairs for machine translation. Multilingual fine-tuning improves performance on low-resource languages but requires modifying the entire model and can be prohibitively expensive. Training a new adapter on each language pair or training a single adapter on all language pairs without updating the pretrained model has been proposed as a parameter-efficient alternative. However, the former does not permit any sharing between languages, while the latter shares parameters for all languages and is susceptible to negative interference. In this paper, we propose training language-family adapters on top of mBART-50 to facilitate cross-lingual transfer. Our approach outperforms related baselines, yielding higher translation scores on average when translati
    
[^37]: 凤神榜 1.0：成为中国认知智能的基石

    Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence. (arXiv:2209.02970v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.02970](http://arxiv.org/abs/2209.02970)

    凤神榜是一个开源项目，旨在支持汉语社区的发展。它包括大型预训练模型、用户友好的API、基准和数据集等，以促进中国大规模模型的发展。

    

    当今，基础模型已成为人工智能中的基础设施之一，为通用智能铺平了道路。然而，现实中存在两个紧迫的挑战：现有的基础模型由英语社区主导；用户往往只能使用有限的资源，无法总是使用基础模型。为了支持汉语社区的发展，我们推出了一个名为凤神榜（Fengshenbang）的开源项目，由认知计算与自然语言研究中心（CCNL）领导。我们的项目具有全面的能力，包括大型预训练模型、用户友好的API、基准、数据集等。我们将所有这些包裹在三个子项目中：凤神榜模型、凤神框架和凤神榜基准。一个开源路线图，凤神榜旨在重新评估中国预训练大规模模型的开源社区，促进整个中国大规模模型的发展。

    Nowadays, foundation models become one of fundamental infrastructures in artificial intelligence, paving ways to the general intelligence. However, the reality presents two urgent challenges: existing foundation models are dominated by the English-language community; users are often given limited resources and thus cannot always use foundation models. To support the development of the Chinese-language community, we introduce an open-source project, called Fengshenbang, which leads by the research center for Cognitive Computing and Natural Language (CCNL). Our project has comprehensive capabilities, including large pre-trained models, user-friendly APIs, benchmarks, datasets, and others. We wrap all these in three sub-projects: the Fengshenbang Model, the Fengshen Framework, and the Fengshen Benchmark. An open-source roadmap, Fengshenbang, aims to re-evaluate the open-source community of Chinese pre-trained large-scale models, prompting the development of the entire Chinese large-scale 
    
[^38]: Paraformer：用于非自回归端到端语音识别的快速准确并行Transformer

    Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition. (arXiv:2206.08317v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2206.08317](http://arxiv.org/abs/2206.08317)

    Paraformer是用于非自回归端到端语音识别的快速准确并行Transformer，通过使用连续积分-火器预测器和扫视式语言模型采样器解决了单步NAR的挑战，并在LibriSpeech数据集上取得了最先进的性能。

    

    近年来，Transformer已经成为ASR领域的主要方法。虽然能够产生良好的性能，但是它们涉及使用自回归（AR）解码器一个一个地生成令牌，这在计算上是低效的。为了加速推理，设计了非自回归（NAR）方法，例如单步NAR，以实现并行生成。但是，由于输出令牌中存在独立性假设，单步NAR的性能不如AR模型，特别是在大规模语料库中。提高单步NAR的两个挑战是：第一是准确预测输出令牌的数量和提取隐藏变量；第二是增强输出令牌之间的相互依赖建模。为了解决这两个挑战，我们提出了一种快速准确的并行Transformer模型，称为Paraformer。这利用基于连续积分-火器基础的预测器来预测令牌数并生成隐藏变量。然后，一个扫视式语言模型（GLM）采样器会根据隐藏变量生成语义合理的子序列。在广泛使用的LibriSpeech数据集上的实验表明，Paraformer在NAR模型的识别精度和推理速度方面均实现了最先进的性能。

    Transformers have recently dominated the ASR field. Although able to yield good performance, they involve an autoregressive (AR) decoder to generate tokens one by one, which is computationally inefficient. To speed up inference, non-autoregressive (NAR) methods, e.g. single-step NAR, were designed, to enable parallel generation. However, due to an independence assumption within the output tokens, performance of single-step NAR is inferior to that of AR models, especially with a large-scale corpus. There are two challenges to improving single-step NAR: Firstly to accurately predict the number of output tokens and extract hidden variables; secondly, to enhance modeling of interdependence between output tokens. To tackle both challenges, we propose a fast and accurate parallel transformer, termed Paraformer. This utilizes a continuous integrate-and-fire based predictor to predict the number of tokens and generate hidden variables. A glancing language model (GLM) sampler then generates sem
    
[^39]: 带有CLIP奖励的细粒度图像描述

    Fine-grained Image Captioning with CLIP Reward. (arXiv:2205.13115v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.13115](http://arxiv.org/abs/2205.13115)

    本研究提出使用CLIP作为奖励函数, 生成更细致、独特的图像标题。通过FineCapEval测试，该方法在客观指标和人类评估方面均优于最先进的模型。

    

    现代图像描述模型通常使用文本相似性目标进行训练。然而，由于公共数据集中的参考描述通常描述最显著的共同对象，使用文本相似性目标进行训练的模型往往忽略了区分图像与其他图像的特定和详细方面。为了更详细和独特地生成标题，我们建议使用CLIP作为奖励函数，计算从网络中巨大的图像-文本对中训练的多模式编码器的多模式相似性。我们还提出了一个简单的fine-tuning策略，改进了CLIP文本编码器的语法，不需要额外的文本注释。这完全消除了在奖励计算期间参考标题的需要。为了全面评估描述性标题，我们引入了FineCapEval，这是一个具有细粒度标准（整体、背景、对象、关系）的新标注数据集。在我们的文本-图像检索和FineCapEval实验中，我们展示了我们的方法在客观指标和人类评估方面都优于最先进的模型。

    Modern image captioning models are usually trained with text similarity objectives. However, since reference captions in public datasets often describe the most salient common objects, models trained with text similarity objectives tend to ignore specific and detailed aspects of an image that distinguish it from others. Toward more descriptive and distinctive caption generation, we propose using CLIP, a multimodal encoder trained on huge image-text pairs from web, to calculate multimodal similarity and use it as a reward function. We also propose a simple finetuning strategy of the CLIP text encoder to improve grammar that does not require extra text annotation. This completely eliminates the need for reference captions during the reward computation. To comprehensively evaluate descriptive captions, we introduce FineCapEval, a new dataset for caption evaluation with fine-grained criteria: overall, background, object, relations. In our experiments on text-to-image retrieval and FineCapE
    
[^40]: 基于全局原型的增强持续学习: 对抗负表示漂移

    Enhancing Continual Learning with Global Prototypes: Counteracting Negative Representation Drift. (arXiv:2205.12186v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12186](http://arxiv.org/abs/2205.12186)

    该论文提出了一种基于全局原型的持续学习方法，在自监督信息的正则化下学习数据表示，以缓解负面表示漂移问题，并减少持续学习中的灾难性遗忘。

    

    持续学习旨在学习一系列任务，其中数据分布从一个任务转移到另一个任务。在训练新任务数据时，旧任务的数据表示可能会漂移。一些负面的表示漂移可能会导致灾难性遗忘，因为会导致从本地学习的类别原型和数据表示在任务之间的相关性较差。为了缓解这种表示漂移，我们提出一种方法，通过全局原型指导学习，用自监督信息的正则化来学习数据表示。具体来说，对于NLP任务，我们将每个任务以屏蔽语言建模的方式进行公式化，并通过预训练的语言模型进行相邻注意机制学习任务。实验结果表明，我们提出的方法可以学习出具有较少表示漂移的相当一致的表示，并在不重新采样过去任务的数据的情况下显著减少持续学习中的灾难性遗忘。

    Continual learning (CL) aims to learn a sequence of tasks over time, with data distributions shifting from one task to another. When training on new task data, data representations from old tasks may drift. Some negative representation drift can result in catastrophic forgetting, by causing the locally learned class prototypes and data representations to correlate poorly across tasks. To mitigate such representation drift, we propose a method that finds global prototypes to guide the learning, and learns data representations with the regularization of the self-supervised information. Specifically, for NLP tasks, we formulate each task in a masked language modeling style, and learn the task via a neighbor attention mechanism over a pre-trained language model. Experimental results show that our proposed method can learn fairly consistent representations with less representation drift, and significantly reduce catastrophic forgetting in CL without resampling data from past tasks.
    

