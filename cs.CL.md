# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing Idiomatic Translation with Language Models.](http://arxiv.org/abs/2308.13961) | 本研究提出了利用语言模型开发的多语言习语知识库（IdiomKB），通过检索习语的比喻意义，实现对习语的更好翻译。 |
| [^2] | [Improving Knowledge Distillation for BERT Models: Loss Functions, Mapping Methods, and Weight Tuning.](http://arxiv.org/abs/2308.13958) | 本研究旨在改进BERT模型的知识蒸馏方法，通过实验不同的损失函数、映射方法和权重调整，提高知识蒸馏的效率和精度，从而压缩大型Transformer模型，使其在保持准确性的同时更加高效。 |
| [^3] | [Exploring Large Language Models for Knowledge Graph Completion.](http://arxiv.org/abs/2308.13916) | 本文研究了利用大型语言模型（LLM）进行知识图谱补全的方法，并引入了一种创新的框架（知识图谱LLM），以提高三元组分类和关系预测的性能。 |
| [^4] | [A Wide Evaluation of ChatGPT on Affective Computing Tasks.](http://arxiv.org/abs/2308.13911) | 本论文广泛研究了ChatGPT模型在13个情感计算问题上的能力，并提出了一种能够评估ChatGPT模型在回归问题上的框架。 |
| [^5] | [LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors.](http://arxiv.org/abs/2308.13904) | LMSanitator是一种新颖的方法，用于检测和消除Transformer模型中的任务不可知后门。与传统方法不同，LMSanitator通过逆转预定义的攻击向量而不是触发器，实现更好的收敛性能和后门检测精确度。 |
| [^6] | [Solving Math Word Problem with Problem Type Classification.](http://arxiv.org/abs/2308.13844) | 本文提出了一个使用问题类型分类的方法来解决数学应用题，通过集成多种方法来提高解决能力，并且利用集成技术提高基于树的求解器和大型语言模型求解器的性能。 |
| [^7] | [Planning with Logical Graph-based Language Model for Instruction Generation.](http://arxiv.org/abs/2308.13782) | 本文提出了一种基于逻辑图的语言模型，Logical-GLM，用于指导语言模型生成具有正确逻辑的文本，并以提高文本生成的有效性和可解释性。实验结果表明，Logical-GLM在使用较少数据和参数的情况下仍然有效和高效。 |
| [^8] | [EditSum: A Retrieve-and-Edit Framework for Source Code Summarization.](http://arxiv.org/abs/2308.13775) | 本文提出了一种基于检索和编辑的源代码摘要框架(EditSum)，用于自动生成结构化、信息丰富的代码摘要。 |
| [^9] | [Adversarial Fine-Tuning of Language Models: An Iterative Optimisation Approach for the Generation and Detection of Problematic Content.](http://arxiv.org/abs/2308.13768) | 本研究提出了一种新的双阶段优化技术，使用对抗性微调来解决大型语言模型中意外生成有害内容的问题。通过迭代的提示和微调，实现了持续的改进和性能提升，并在具有挑战性的数据集上展示了显著的分类准确度提升。 |
| [^10] | [How Can Context Help? Exploring Joint Retrieval of Passage and Personalized Context.](http://arxiv.org/abs/2308.13760) | 本文探索了如何将个性化上下文信息与文档对话系统结合，提出了个性化上下文感知的段落检索任务，并引入了一种有效利用上下文信息的新颖方法PCAS。通过实验证明，PCAS不仅在检索最相关的段落方面优于基准系统，而且在确定相关上下文方面也表现出色。这将激发未来研究的兴趣。 |
| [^11] | [ZC3: Zero-Shot Cross-Language Code Clone Detection.](http://arxiv.org/abs/2308.13754) | 本文提出了一种名为ZC3的跨语言零样本代码克隆检测方法。该方法设计了对比代码片段预测，形成不同编程语言之间的同构表示空间，并利用领域感知学习和循环一致性学习来进一步约束模型。 |
| [^12] | [On Philomatics and Psychomatics for Combining Philosophy and Psychology with Mathematics.](http://arxiv.org/abs/2308.13738) | 本文提出了将哲学、心理学与数学相结合的Philomatics和Psychomatics概念，并解释了四个动机：满足分析哲学的需求、提出哲学科学、用哲学来证明数学算法以及哲学和数学的抽象。并列举了多个示例，包括数学中注意机制和上下文原则、形式理论与全息原理的关系等。本文为将哲学和心理学与数学相结合的研究开辟了研究空间。 |
| [^13] | [A Computational Evaluation Framework for Singable Lyric Translation.](http://arxiv.org/abs/2308.13715) | 提出了一个用于量化评估可唱歌词翻译的计算框架，通过综合考量音乐、语言和文化维度，研究歌词的音节、音素、音乐结构和语义等方面的相似性指标，揭示了构成可唱歌词翻译的关键要素。 |
| [^14] | [WellXplain: Wellness Concept Extraction and Classification in Reddit Posts for Mental Health Analysis.](http://arxiv.org/abs/2308.13710) | 本研究提出了一种通过在Reddit内容中识别健康维度的方法来进行复杂的精神健康分析。他们创建了一个名为WELLXPLAIN的数据集，并制定了一个注释框架。这种方法有助于在社交媒体上识别潜在的精神问题指标。 |
| [^15] | [On the Depth between Beam Search and Exhaustive Search for Text Generation.](http://arxiv.org/abs/2308.13696) | 本研究探讨了束搜索和穷举搜索之间一系列不同的搜索深度，提出了前瞻束搜索（LBS）算法进行优化。尽管束搜索的搜索误差较高，但在计算成本和性能方面优于穷举搜索。 |
| [^16] | [1.5 million materials narratives generated by chatbots.](http://arxiv.org/abs/2308.13687) | 聊天机器人生成了150万个材料叙述的数据集，通过与人类专家的评分对比，发现人类评分中的内容深度相对较低。 |
| [^17] | [Rethinking Language Models as Symbolic Knowledge Graphs.](http://arxiv.org/abs/2308.13676) | 本研究对不同大小和能力的语言模型进行了全面评估，发现它们能否涵盖知识图谱的复杂拓扑和语义属性，这对于推理过程至关重要。 |
| [^18] | [GRASP: A Rehearsal Policy for Efficient Online Continual Learning.](http://arxiv.org/abs/2308.13646) | GRASP是一种新的样本选择策略，根据样本的代表性选择最适合学习的样本，从而提高了在线渐进式学习的效率。 |
| [^19] | [LSTM-based QoE Evaluation for Web Microservices' Reputation Scoring.](http://arxiv.org/abs/2308.13590) | 本研究提出了基于LSTM模型的情感分析和Net品牌声誉算法评估微服务的声誉分数的方法，并在一组与Amazon Web微服务相关的超过10,000条评论上进行了测试。 |
| [^20] | [Text Style Transfer Evaluation Using Large Language Models.](http://arxiv.org/abs/2308.13577) | 大型语言模型（LLMs）有潜力成为人工评估和其他自动化评价指标的可行替代方案。 |
| [^21] | [An Ensemble Approach to Personalized Real Time Predictive Writing for Experts.](http://arxiv.org/abs/2308.13576) | 本文介绍了一种集成方法，通过结合大型语言模型、马尔可夫模型和字符级模型，提供个性化的句子/单词自动补全建议，并在严格的延迟约束下实现高效准确的写作体验。 |
| [^22] | [Discovering Mental Health Research Topics with Topic Modeling.](http://arxiv.org/abs/2308.13569) | 本研究通过分析大量心理健康研究论文，采用自定义嵌入模型，识别出该领域的一般趋势和高影响力的研究课题。 |
| [^23] | [MLLM-DataEngine: An Iterative Refinement Approach for MLLM.](http://arxiv.org/abs/2308.13566) | 本文提出了一种名为MLLM-DataEngine的迭代改进方法，它通过分析模型弱点，生成适当的增量数据集并迭代地增强模型能力。与以往方法相比，MLLM-DataEngine生成的数据在定位、质量和正确性方面表现更好。 |
| [^24] | [DARWIN Series: Domain Specific Large Language Models for Natural Science.](http://arxiv.org/abs/2308.13565) | DARWIN系列是为自然科学领域开发的定制语言模型，通过引入科学指令生成模型和大量数据微调，加速了自动化发现过程的进行。 |
| [^25] | [Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4.](http://arxiv.org/abs/2308.13563) | 三个大型语言模型接口(ChatGPT, BARD和GPT4)在分析事故叙述中的效果进行了比较研究。研究结果表明，它们在提取事故相关信息和回答相关问题方面都具有一定的有效性，但也存在一些限制。 |
| [^26] | [Feature Extraction Using Deep Generative Models for Bangla Text Classification on a New Comprehensive Dataset.](http://arxiv.org/abs/2308.13545) | 本研究提出了使用深度生成模型在孟加拉文本分类中进行特征提取的方法，并收集、注释了一个全面的数据集。评估结果表明，对抗自编码器模型产生了最佳的特征空间。 |
| [^27] | [A Preliminary Study on a Conceptual Game Feature Generation and Recommendation System.](http://arxiv.org/abs/2308.13538) | 本研究介绍了一个用于生成游戏特征建议的系统，通过使用文本提示，提取主题相似的游戏特征并生成新特征。经过用户研究比较，该系统的生成模型在某些游戏中的表现超过了人工建议。该系统是一个与用户在概念层面上进行协作的游戏设计助手工具的一部分。 |
| [^28] | [Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph.](http://arxiv.org/abs/2308.13534) | 本论文提出了一种综述和解决方案架构，用于构建可解释的、隐私感知的对话型AI系统。首先介绍了LLM模型的综合工具LLMXplorer，并阐明了其对社会、伦理和监管等方面的影响。然后提出了将知识图谱的结构动态与LLM的语言能力无缝集成的架构。通过使用真实世界的AI新闻数据进行验证，该架构成功地融合了语言的复杂性与事实的严谨性，并增强了数据安全性。 |
| [^29] | [Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level.](http://arxiv.org/abs/2308.13506) | 本论文研究了在机器翻译中，如何在段落级别评估翻译质量。实验结果表明，使用句子级别的评估指标来评分整个段落与使用段落级别的指标一样有效。 |
| [^30] | [Large Language Models Vote: Prompting for Rare Disease Identification.](http://arxiv.org/abs/2308.12890) | 本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。 |
| [^31] | [Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments.](http://arxiv.org/abs/2308.12086) | 本文将预训练的大型语言模型（LLMs）应用于网络安全环境，作为攻击代理人进行顺序决策。该设计表明LLMs在高效应对复杂决策方面具有潜力，并且在大多数场景中表现出与经过训练的最先进代理相似或更好的性能。 |
| [^32] | [Bridging the Gap: Deciphering Tabular Data Using Large Language Model.](http://arxiv.org/abs/2308.11891) | 本研究旨在提升大型语言模型在理解表格数据上的能力，通过设计一个表格序列化模块和纠正机制来实现。实验结果表明，尽管相对于最先进技术仍有差距，但该方法在处理表格数据方面取得了一定的进展。 |
| [^33] | [A Study on Robustness and Reliability of Large Language Model Code Generation.](http://arxiv.org/abs/2308.10335) | 本研究针对大型语言模型生成的代码的可靠性和鲁棒性进行了研究，发现在真实的软件开发中可执行的代码并不能保证可靠和鲁棒，滥用API可能导致严重问题。这对初级开发者来说尤其危险，因为他们很难察觉到代码中的API滥用问题。 |
| [^34] | [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models.](http://arxiv.org/abs/2308.09729) | 本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。 |
| [^35] | [SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search.](http://arxiv.org/abs/2308.07711) | 本论文提出了一种用于在Meituan搜索中进行相关性建模的新颖两阶段预训练和匹配架构。 |
| [^36] | [EcomGPT: Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce.](http://arxiv.org/abs/2308.06966) | EcomGPT是针对电子商务领域的任务链调节语言模型，通过构建原子任务链并使用EcomInstruct数据集进行训练，具有较强的通用化能力。 |
| [^37] | [An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM.](http://arxiv.org/abs/2308.06828) | 本研究提出了一种集成Electra Transformer、GloVe和LSTM模型的创新问题分类方法，通过在TREC数据集上进行严格测试，证明了融合不同技术可以获得更优越的结果。 |
| [^38] | [External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback.](http://arxiv.org/abs/2307.12057) | 本文提出通过从外部存储库中选择性地集成知识来增强大型语言模型，提出了一种外部推理的新方法，例子是ChatPDF。 |
| [^39] | [Latent Jailbreak: A Test Suite for Evaluating Both Text Safety and Output Robustness of Large Language Models.](http://arxiv.org/abs/2307.08487) | 这篇论文提出了一个评估大型语言模型安全性和鲁棒性的基准测试套件，强调了平衡的方法。通过引入含有恶意指令的潜在越狱提示数据集，并设计分层注释框架，全面研究了文本安全性和输出鲁棒性。 |
| [^40] | [Communicative Agents for Software Development.](http://arxiv.org/abs/2307.07924) | 本文介绍了一种创新的软件开发范式，利用大型语言模型(LLMs)在整个软件开发过程中实现自然语言交流，消除了每个阶段需要专门模型的需求。该范式使用ChatDev作为一个虚拟聊天驱动的软件开发公司，通过设计、编码、测试和文档化四个阶段的代理人团队促进协作。 |
| [^41] | [AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge.](http://arxiv.org/abs/2307.07851) | AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。 |
| [^42] | [A Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2307.03109) | 本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。 |
| [^43] | [Efficient Domain Adaptation of Sentence Embeddings using Adapters.](http://arxiv.org/abs/2307.03104) | 本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。 |
| [^44] | [Exploring Linguistic Style Matching in Online Communities: The Role of Social Context and Conversation Dynamics.](http://arxiv.org/abs/2307.02758) | 本研究在Reddit上分析了两方对话主题的大量语料库，研究了LSM在对话中的差异以及与社区指标的关系，揭示了理解社区动态时对话参与的重要性。 |
| [^45] | [Emoji Prediction using Transformer Models.](http://arxiv.org/abs/2307.02054) | 使用基于Transformer的方法，在大型语料库上微调BERT模型以预测给定文本的表情符号。实验结果显示，该方法在预测准确率上优于其他最先进的模型，具有潜在的自然语言处理和社交媒体营销应用价值。 |
| [^46] | [Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset.](http://arxiv.org/abs/2306.11167) | 这项研究探索了大型语言模型（LLMs）对创造性问题解决的能力，并发现大型语言模型容易被误导，出现固定效应和Einstellung范式。 |
| [^47] | [RestGPT: Connecting Large Language Models with Real-World RESTful APIs.](http://arxiv.org/abs/2306.06624) | RestGPT通过连接大型语言模型与RESTful API，提出了RestGPT以解决现实世界场景中的复杂指令问题，并提供了相应的API执行器。 |
| [^48] | [A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises.](http://arxiv.org/abs/2306.04802) | 本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。 |
| [^49] | [Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models.](http://arxiv.org/abs/2305.18703) | 本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。 |
| [^50] | [The Effects of Political Martyrdom on Election Results: The Assassination of Abe.](http://arxiv.org/abs/2305.18004) | 这项研究通过分析推特数据研究了日本前首相阿贝的暗杀事件对2022年日本参议院选举的影响。研究发现，暗杀事件短期内对推特情绪产生了负面影响，并且社交媒体的关注时间也变得更短。此外，研究还发现阿贝之死对选举结果产生了影响，但需要进一步调查以得出确切结论。 |
| [^51] | [Evaluating Open-QA Evaluation.](http://arxiv.org/abs/2305.12421) | 本研究侧重于评估开放式问答（Open-QA）任务的方法，引入了一个新的任务QA-Eval和数据集EVOUNA，通过人工评估方法来评估AI生成的答案的准确性。我们调查了与人工评估相关的方法，并讨论了当前方法的缺陷和改进方法。我们相信这对于未来的自动评估工具发展和研究具有价值。 |
| [^52] | [Towards Versatile and Efficient Visual Knowledge Injection into Pre-trained Language Models with Cross-Modal Adapters.](http://arxiv.org/abs/2305.07358) | 本文提出了X-adapter插拔式模块，利用多模态视觉语言模型，高效地向预训练语言模型注入视觉知识。 |
| [^53] | [Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers.](http://arxiv.org/abs/2305.07011) | 本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。 |
| [^54] | [PGTask: Introducing the Task of Profile Generation from Dialogues.](http://arxiv.org/abs/2304.06634) | 对话系统的个性化需要个人资料信息，而从对话中提取/生成个人资料信息是一项基本需求。为此，我们提出了档案生成任务（PGTask）并提供了相关的数据集和基准，该任务使得研究者可以更好地了解档案生成任务的挑战和可能的解决方案。 |
| [^55] | [Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?.](http://arxiv.org/abs/2304.01002) | 这项研究研究了人类合作是否增强了识别LLM生成的深度伪造文本的准确性。结果表明，合作可以潜在地提高两组人对深度伪造文本的检测准确性。 |
| [^56] | [Comparing Abstractive Summaries Generated by ChatGPT to Real Summaries Through Blinded Reviewers and Text Classification Algorithms.](http://arxiv.org/abs/2303.17650) | 本研究评估了ChatGPT在抽象概括方面的表现，自动化指标和盲审人员评估显示ChatGPT生成的摘要在人类视角下难以分辨真假。 |
| [^57] | [Language Model Behavior: A Comprehensive Survey.](http://arxiv.org/abs/2303.11504) | 该论文总结了250多个关于英文语言模型行为的最近研究，发现大型语言模型具有基本的句法、语义、语用、世界知识和推理能力，但容易出现不实回答、常识错误、记忆化文本和社会偏见等弱点。 |
| [^58] | [EmotionIC: Emotional Inertia and Contagion-driven Dependency Modelling for Emotion Recognition in Conversation.](http://arxiv.org/abs/2303.11117) | 本文提出了一种新的依赖性建模方法，由情感惯性和感染驱动（EmotionIC），用于在特征提取和分类级别上进行会话情感识别。设计了多项具体方法，包括身份掩码多头注意（IM-MHA）和基于对话门控循环单元(DialogGRU)，以抓取上下文信息，提高模型的性能。 |
| [^59] | [The Re-Label Method For Data-Centric Machine Learning.](http://arxiv.org/abs/2302.04391) | 本文提出了一种重新标签的方法来解决手动标记的数据中存在噪声的问题，并通过模型预测来辅助人类标记噪声数据。实验证明此方法适用于多类深度学习任务。 |
| [^60] | [Protecting Language Generation Models via Invisible Watermarking.](http://arxiv.org/abs/2302.03162) | 本文提出了一种名为 GINSEW 的新方法，通过将秘密信号注入到每个目标标记的解码步骤的概率向量中，保护文本生成模型，有效识别出侵权行为，对模型的影响很小。 |
| [^61] | [Event knowledge in large language models: the gap between the impossible and the unlikely.](http://arxiv.org/abs/2212.01488) | 大型语言模型拥有丰富的事件知识，几乎总是将可能事件的描述比不可能事件的描述赋予更高的可能性。 |
| [^62] | [Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem.](http://arxiv.org/abs/2210.11694) | 该论文提出了一种使用多视角一致的对比学习来解决数学应用问题，通过同时考虑自上而下和自下而上的推理视角，以及多种等价的方程形式，实现了更完整的语义到方程的映射。实验证明该方法明显优于现有的基线。 |
| [^63] | [TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations at Twitter.](http://arxiv.org/abs/2209.07562) | TwHIN-BERT是一个在Twitter上训练的多语言语言模型，通过结合基于文本的自监督和基于丰富社交参与对象的社交目标训练，能够有效地表示短、嘈杂的用户生成文本。在各种多语言社交推荐和语义理解任务中，TwHIN-BERT展示了显著的指标提升。 |
| [^64] | [Parameter-Efficient Finetuning for Robust Continual Multilingual Learning.](http://arxiv.org/abs/2209.06767) | 提出了一种参数高效微调策略LAFT-URIEL，用于鲁棒性持续多语言学习，通过利用语言知识平衡过拟合和知识共享，使模型在更新后在更多语种上表现出改进，同时减小了剩余语种的性能损失。 |
| [^65] | [Explaining Machine Learning Models in Natural Conversations: Towards a Conversational XAI Agent.](http://arxiv.org/abs/2209.02552) | 本研究将解释人工智能（XAI）融入到一个对话代理中，设计具有自然语言理解和生成组件的标准模型。通过扩展XAI问题库并提供解释方法，实现了关于机器学习模型的真正自然对话。 |
| [^66] | [Quantum Circuit Compiler for a Shuttling-Based Trapped-Ion Quantum Computer.](http://arxiv.org/abs/2207.01964) | 本文介绍了一个针对穿梭式离子阱量子处理器的量子电路编译器，能够将量子电路转换和优化为特定的本地门序列，与标准编译方法相比，可以将门计数减少到5.1倍。 |
| [^67] | [Making first order linear logic a generating grammar.](http://arxiv.org/abs/2206.08955) | 本文研究了一阶线性逻辑与扩展张量类型演算的关系，提出了一种固有的演绎系统。 |
| [^68] | [Enhancing Self-Disclosure In Neural Dialog Models By Candidate Re-ranking.](http://arxiv.org/abs/2109.05090) | 本论文通过重新排序候选项来提高神经对话模型中的自我披露，从而解决了在神经对话模型中存在的回复逐渐变得琐碎的问题。 |
| [^69] | [CoPaSul Manual -- Contour-based parametric and superpositional intonation stylization.](http://arxiv.org/abs/1612.04765) | CoPaSul工具包提供了自动的韵律标注和特征提取功能，使用了基于轮廓的参数化和叠加韵律风格化的方法。通过该工具包可以得到与韵律边界和突出性相关的特征，并可以通过系数聚类得到韵律轮廓类别。 |

# 详细

[^1]: 翻译含义，而不仅仅是词语：IdiomKB在利用语言模型优化习语翻译中的作用

    Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing Idiomatic Translation with Language Models. (arXiv:2308.13961v1 [cs.CL])

    [http://arxiv.org/abs/2308.13961](http://arxiv.org/abs/2308.13961)

    本研究提出了利用语言模型开发的多语言习语知识库（IdiomKB），通过检索习语的比喻意义，实现对习语的更好翻译。

    

    为了进行良好的翻译，机器翻译系统和通用语言模型需要对源语言和目标语言以及文化有深入的理解。因此，由于其非组合性的特性，习语对基于Transformer的系统提出了特殊的挑战，因为直译往往会忽略意图。传统方法使用现有的知识库（KB）替换习语，往往缺乏规模和上下文意识。针对这些挑战，我们的方法优先考虑上下文意识和可扩展性，允许在可管理的KB大小的离线存储中存储习语。这确保了更高效的小型模型服务，并提供了对习语表达的更全面的理解。我们介绍了一个使用大型语言模型开发的多语言习语KB（IdiomKB）来解决这个问题。通过检索习语的比喻意义，该KB可以帮助小型模型（如BLOOMZ（7.1B），Alpaca（7B）和InstructGPT（6.7B））实现更好的翻译。

    To translate well, machine translation (MT) systems and general-purposed language models (LMs) need a deep understanding of both source and target languages and cultures. Therefore, idioms, with their non-compositional nature, pose particular challenges for Transformer-based systems, as literal translations often miss the intended meaning. Traditional methods, which replace idioms using existing knowledge bases (KBs), often lack scale and context awareness. Addressing these challenges, our approach prioritizes context awareness and scalability, allowing for offline storage of idioms in a manageable KB size. This ensures efficient serving with smaller models and provides a more comprehensive understanding of idiomatic expressions. We introduce a multilingual idiom KB (IdiomKB) developed using large LMs to address this. This KB facilitates better translation by smaller models, such as BLOOMZ (7.1B), Alpaca (7B), and InstructGPT (6.7B), by retrieving idioms' figurative meanings. We presen
    
[^2]: 改进BERT模型的知识蒸馏：损失函数、映射方法和权重调整

    Improving Knowledge Distillation for BERT Models: Loss Functions, Mapping Methods, and Weight Tuning. (arXiv:2308.13958v1 [cs.CL])

    [http://arxiv.org/abs/2308.13958](http://arxiv.org/abs/2308.13958)

    本研究旨在改进BERT模型的知识蒸馏方法，通过实验不同的损失函数、映射方法和权重调整，提高知识蒸馏的效率和精度，从而压缩大型Transformer模型，使其在保持准确性的同时更加高效。

    

    大型基于Transformer的模型，如BERT、GPT和T5在自然语言处理方面取得了重大进展。然而，这些模型计算成本高昂，需要采用模型压缩技术来减小其大小和复杂性，同时保持准确性。本项目研究并应用知识蒸馏用于BERT模型压缩，特别关注TinyBERT学生模型。我们探索了多种技术来改进知识蒸馏，包括实验不同的损失函数、Transformer层映射方法和调整注意力和表示损失的权重，并在GLUE基准测试中评估了我们提出的技术在多个下游任务上的性能。本工作的目标是改进知识蒸馏的效率和效果，从而为各种自然语言处理任务的开发提供更高效和准确的模型。

    The use of large transformer-based models such as BERT, GPT, and T5 has led to significant advancements in natural language processing. However, these models are computationally expensive, necessitating model compression techniques that reduce their size and complexity while maintaining accuracy. This project investigates and applies knowledge distillation for BERT model compression, specifically focusing on the TinyBERT student model. We explore various techniques to improve knowledge distillation, including experimentation with loss functions, transformer layer mapping methods, and tuning the weights of attention and representation loss and evaluate our proposed techniques on a selection of downstream tasks from the GLUE benchmark. The goal of this work is to improve the efficiency and effectiveness of knowledge distillation, enabling the development of more efficient and accurate models for a range of natural language processing tasks.
    
[^3]: 探索大型语言模型用于知识图谱补全

    Exploring Large Language Models for Knowledge Graph Completion. (arXiv:2308.13916v1 [cs.CL])

    [http://arxiv.org/abs/2308.13916](http://arxiv.org/abs/2308.13916)

    本文研究了利用大型语言模型（LLM）进行知识图谱补全的方法，并引入了一种创新的框架（知识图谱LLM），以提高三元组分类和关系预测的性能。

    

    知识图谱在众多人工智能任务中发挥着重要作用，但经常面临不完整性的问题。在本研究中，我们探索了利用大型语言模型（LLM）进行知识图谱补全的方法。我们将知识图谱中的三元组视为文本序列，并引入了一种创新的框架，称为知识图谱LLM（KG-LLM），来对这些三元组进行建模。我们的技术利用三元组的实体和关系描述作为提示，并利用响应进行预测。对各种基准知识图谱的实验表明，我们的方法在三元组分类和关系预测等任务中达到了最先进的性能。我们还发现，微调相对较小的模型（例如LLaMA-7B，ChatGLM-6B）优于最新的ChatGPT和GPT-4。

    Knowledge graphs play a vital role in numerous artificial intelligence tasks, yet they frequently face the issue of incompleteness. In this study, we explore utilizing Large Language Models (LLM) for knowledge graph completion. We consider triples in knowledge graphs as text sequences and introduce an innovative framework called Knowledge Graph LLM (KG-LLM) to model these triples. Our technique employs entity and relation descriptions of a triple as prompts and utilizes the response for predictions. Experiments on various benchmark knowledge graphs demonstrate that our method attains state-of-the-art performance in tasks such as triple classification and relation prediction. We also find that fine-tuning relatively smaller models (e.g., LLaMA-7B, ChatGLM-6B) outperforms recent ChatGPT and GPT-4.
    
[^4]: ChatGPT在情感计算任务上的广泛评估

    A Wide Evaluation of ChatGPT on Affective Computing Tasks. (arXiv:2308.13911v1 [cs.AI])

    [http://arxiv.org/abs/2308.13911](http://arxiv.org/abs/2308.13911)

    本论文广泛研究了ChatGPT模型在13个情感计算问题上的能力，并提出了一种能够评估ChatGPT模型在回归问题上的框架。

    

    随着基础模型的崛起，一个新的人工智能范式出现了，即通过使用通用目的的基础模型，通过提示来解决问题，而不是为每个问题训练单独的机器学习模型。这些模型已经显示出解决一些最初未经训练的问题的新性质。对于这类模型的有效性的研究还相当有限。在这项工作中，我们广泛研究了ChatGPT模型（即GPT-4和GPT-3.5）在13个情感计算问题上的能力，包括方面提取、方面极性分类、意见提取、情感分析、情感强度排序、情绪强度排序、自杀倾向检测、毒性检测、福祉评估、参与度测量、人格评估、讽刺检测和主观性检测。我们介绍了一个评估ChatGPT模型在回归问题上的框架，比如强度排序。

    With the rise of foundation models, a new artificial intelligence paradigm has emerged, by simply using general purpose foundation models with prompting to solve problems instead of training a separate machine learning model for each problem. Such models have been shown to have emergent properties of solving problems that they were not initially trained on. The studies for the effectiveness of such models are still quite limited. In this work, we widely study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13 affective computing problems, namely aspect extraction, aspect polarity classification, opinion extraction, sentiment analysis, sentiment intensity ranking, emotions intensity ranking, suicide tendency detection, toxicity detection, well-being assessment, engagement measurement, personality assessment, sarcasm detection, and subjectivity detection. We introduce a framework to evaluate the ChatGPT models on regression-based problems, such as intensity ranking p
    
[^5]: LMSanitator: 针对任务不可知后门的Prompt-Tuning防御机制

    LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors. (arXiv:2308.13904v1 [cs.CL])

    [http://arxiv.org/abs/2308.13904](http://arxiv.org/abs/2308.13904)

    LMSanitator是一种新颖的方法，用于检测和消除Transformer模型中的任务不可知后门。与传统方法不同，LMSanitator通过逆转预定义的攻击向量而不是触发器，实现更好的收敛性能和后门检测精确度。

    

    Prompt-Tuning已经成为一种引人注目的范式，用于部署大规模语言模型，因为它具有强大的下游任务性能和高效的多任务服务能力。尽管它被广泛采用，我们实证表明，Prompt-Tuning容易受到任务不可知后门的攻击，这些后门存在于预训练模型中，可以影响任意的下游任务。目前的后门检测方法无法防御任务不可知后门，因为它们很难在逆转后门触发器方面收敛。为了解决这个问题，我们提出了LMSanitator，一种在Transformer模型上检测和去除任务不可知后门的新方法。LMSanitator不直接逆转触发器，而是逆转预定义的攻击向量（预训练模型在输入嵌入触发器时的输出），从而实现更好的收敛性能和后门检测精确度。

    Prompt-tuning has emerged as an attractive paradigm for deploying large-scale language models due to its strong downstream task performance and efficient multitask serving ability. Despite its wide adoption, we empirically show that prompt-tuning is vulnerable to downstream task-agnostic backdoors, which reside in the pretrained models and can affect arbitrary downstream tasks. The state-of-the-art backdoor detection approaches cannot defend against task-agnostic backdoors since they hardly converge in reversing the backdoor triggers. To address this issue, we propose LMSanitator, a novel approach for detecting and removing task-agnostic backdoors on Transformer models. Instead of directly inversing the triggers, LMSanitator aims to inverse the predefined attack vectors (pretrained models' output when the input is embedded with triggers) of the task-agnostic backdoors, which achieves much better convergence performance and backdoor detection accuracy. LMSanitator further leverages prom
    
[^6]: 使用问题类型分类解决数学应用题

    Solving Math Word Problem with Problem Type Classification. (arXiv:2308.13844v1 [cs.CL])

    [http://arxiv.org/abs/2308.13844](http://arxiv.org/abs/2308.13844)

    本文提出了一个使用问题类型分类的方法来解决数学应用题，通过集成多种方法来提高解决能力，并且利用集成技术提高基于树的求解器和大型语言模型求解器的性能。

    

    数学应用题需要分析文本描述并生成数学方程来推导解决方案。现有的方法主要通过基于树的求解器和大型语言模型求解器来解决数学应用题。然而，这些方法总是通过单一求解器来解决数学应用题，会带来以下问题：(1) 单一类型的求解器难以很好地解决所有类型的数学应用题。 (2) 单一求解器会导致过拟合，性能不佳。为了解决这些挑战，本文利用多种集成方法来提高解决数学应用题的能力。首先，我们提出了一个问题类型分类器，结合了基于树的求解器和大型语言模型求解器的优势。这种集成方法利用它们各自的优点，扩大了可以解决的数学应用题的范围。此外，我们还将集成技术应用于基于树的求解器和大型语言模型求解器，以提高它们的性能。

    Math word problems (MWPs) require analyzing text descriptions and generating mathematical equations to derive solutions. Existing works focus on solving MWPs with two types of solvers: tree-based solver and large language model (LLM) solver. However, these approaches always solve MWPs by a single solver, which will bring the following problems: (1) Single type of solver is hard to solve all types of MWPs well. (2) A single solver will result in poor performance due to over-fitting. To address these challenges, this paper utilizes multiple ensemble approaches to improve MWP-solving ability. Firstly, We propose a problem type classifier that combines the strengths of the tree-based solver and the LLM solver. This ensemble approach leverages their respective advantages and broadens the range of MWPs that can be solved. Furthermore, we also apply ensemble techniques to both tree-based solver and LLM solver to improve their performance. For the tree-based solver, we propose an ensemble lear
    
[^7]: 使用基于逻辑图的语言模型进行指令生成的规划

    Planning with Logical Graph-based Language Model for Instruction Generation. (arXiv:2308.13782v1 [cs.CL])

    [http://arxiv.org/abs/2308.13782](http://arxiv.org/abs/2308.13782)

    本文提出了一种基于逻辑图的语言模型，Logical-GLM，用于指导语言模型生成具有正确逻辑的文本，并以提高文本生成的有效性和可解释性。实验结果表明，Logical-GLM在使用较少数据和参数的情况下仍然有效和高效。

    

    尽管大型语言模型在生成自然语言文本方面表现出优越性能，但由于神经模型难以从自由形式的文本中捕捉到隐含的规则，因此很难生成具有正确逻辑的文本。在本文中，我们提出了一种新颖的基于图的语言模型，Logical-GLM，将逻辑注入语言模型以进行更有效的文本生成和可解释性。具体而言，我们首先从自然语言指令中提取信息并构建通常描述领域的逻辑贝叶斯图。接下来，我们生成逻辑骨架以指导语言模型训练，将领域知识注入语言模型。最后，我们交替优化图的搜索策略和语言模型，直至收敛。实验结果表明，Logical-GLM与传统语言模型相比，尽管使用规模较小的训练数据和较少的参数，仍然具有有效和高效的性能。我们的方法可以生成有效的指令。

    Despite the superior performance of large language models to generate natural language texts, it is hard to generate texts with correct logic according to a given task, due to the difficulties for neural models to capture implied rules from free-form texts. In this paper, we propose a novel graph-based language model, Logical-GLM, to infuse logic into language models for more valid text generation and interpretability. Specifically, we first capture information from natural language instructions and construct logical bayes graphs that generally describe domains. Next, we generate logical skeletons to guide language model training, infusing domain knowledge into language models. Finally, we alternately optimize the searching policy of graphs and language models until convergence. The experimental results show that Logical-GLM is both effective and efficient compared with traditional language models, despite using smaller-scale training data and fewer parameters. Our approach can generat
    
[^8]: EditSum: 一种基于检索和编辑的源代码摘要框架

    EditSum: A Retrieve-and-Edit Framework for Source Code Summarization. (arXiv:2308.13775v1 [cs.SE])

    [http://arxiv.org/abs/2308.13775](http://arxiv.org/abs/2308.13775)

    本文提出了一种基于检索和编辑的源代码摘要框架(EditSum)，用于自动生成结构化、信息丰富的代码摘要。

    

    现有研究表明，代码摘要有助于开发人员理解和维护源代码。不幸的是，软件项目中经常缺乏或过时的摘要。代码摘要旨在自动生成源代码的自然语言描述。代码摘要非常结构化，并具有重复的模式。除了模式化的单词外，代码摘要还包含重要的关键词，这些关键词是反映代码功能的关键。然而，现有技术在预测关键词方面表现较差，导致生成的摘要信息丧失了信息量。为了缓解这个问题，本文提出了一种名为EditSum的新型检索和编辑方法用于代码摘要。具体而言，EditSum首先从预定义的语料库中检索一个相似的代码片段，并将其摘要视为原型摘要以学习模式。然后，EditSum自动编辑原型摘要，以结合其中的模式。

    Existing studies show that code summaries help developers understand and maintain source code. Unfortunately, these summaries are often missing or outdated in software projects. Code summarization aims to generate natural language descriptions automatically for source code. Code summaries are highly structured and have repetitive patterns. Besides the patternized words, a code summary also contains important keywords, which are the key to reflecting the functionality of the code. However, the state-of-the-art approaches perform poorly on predicting the keywords, which leads to the generated summaries suffering a loss in informativeness. To alleviate this problem, this paper proposes a novel retrieve-and-edit approach named EditSum for code summarization. Specifically, EditSum first retrieves a similar code snippet from a pre-defined corpus and treats its summary as a prototype summary to learn the pattern. Then, EditSum edits the prototype automatically to combine the pattern in the pr
    
[^9]: 通过对语言模型进行敌对微调：针对问题内容生成和检测的迭代优化方法

    Adversarial Fine-Tuning of Language Models: An Iterative Optimisation Approach for the Generation and Detection of Problematic Content. (arXiv:2308.13768v1 [cs.CL])

    [http://arxiv.org/abs/2308.13768](http://arxiv.org/abs/2308.13768)

    本研究提出了一种新的双阶段优化技术，使用对抗性微调来解决大型语言模型中意外生成有害内容的问题。通过迭代的提示和微调，实现了持续的改进和性能提升，并在具有挑战性的数据集上展示了显著的分类准确度提升。

    

    本文采用一种新颖的双阶段优化技术，使用对抗性微调来应对大型语言模型（LLMs）中意外生成有害内容的挑战。我们的方法包括对抗模型和判别模型两个阶段，对抗模型被微调用于生成潜在有害提示，而判别模型则通过迭代优化来识别这些提示。通过对抗循环，两个模型在提示阶段争相超越对方，生成包含丰富示例的数据集，然后用于微调。这种迭代应用提示和微调的方法使得持续的改进和性能提升成为可能。我们通过在一个包含GPT-4未检测到的问题提示和一些有争议但无问题的提示的数据集上进行分类准确度的评估来验证我们的方法的性能。结果显示在这个具有挑战性的数据集上，判别模型的分类准确度有了显著提升。

    In this paper, we tackle the emerging challenge of unintended harmful content generation in Large Language Models (LLMs) with a novel dual-stage optimisation technique using adversarial fine-tuning. Our two-pronged approach employs an adversarial model, fine-tuned to generate potentially harmful prompts, and a judge model, iteratively optimised to discern these prompts. In this adversarial cycle, the two models seek to outperform each other in the prompting phase, generating a dataset of rich examples which are then used for fine-tuning. This iterative application of prompting and fine-tuning allows continuous refinement and improved performance. The performance of our approach is evaluated through classification accuracy on a dataset consisting of problematic prompts not detected by GPT-4, as well as a selection of contentious but unproblematic prompts. We show considerable increase in classification accuracy of the judge model on this challenging dataset as it undergoes the optimisat
    
[^10]: 如何利用上下文帮助？探索段落和个性化上下文的联合检索

    How Can Context Help? Exploring Joint Retrieval of Passage and Personalized Context. (arXiv:2308.13760v1 [cs.AI])

    [http://arxiv.org/abs/2308.13760](http://arxiv.org/abs/2308.13760)

    本文探索了如何将个性化上下文信息与文档对话系统结合，提出了个性化上下文感知的段落检索任务，并引入了一种有效利用上下文信息的新颖方法PCAS。通过实验证明，PCAS不仅在检索最相关的段落方面优于基准系统，而且在确定相关上下文方面也表现出色。这将激发未来研究的兴趣。

    

    将外部个性化上下文信息整合到以文档为基础的对话系统中具有重要的商业价值，但这方面的研究还不够深入。受个性化上下文感知文档对话系统的概念启发，我们引入了上下文感知的段落检索任务，并构建了一个专门为此目的策划的数据集。我们描述了多个基准系统来解决这个任务，并提出了一种新颖的方法，即个性化上下文感知搜索(Personalized Context-Aware Search，PCAS)，它在段落检索过程中有效地利用上下文信息。在多个流行的稠密检索系统上进行的实验评估表明，我们的方法不仅在检索最相关的段落方面优于基准系统，而且在确定所有可用上下文中的相关上下文方面也表现出色。我们预计我们的贡献将成为激励未来研究的催化剂。

    The integration of external personalized context information into document-grounded conversational systems has significant potential business value, but has not been well-studied. Motivated by the concept of personalized context-aware document-grounded conversational systems, we introduce the task of context-aware passage retrieval. We also construct a dataset specifically curated for this purpose. We describe multiple baseline systems to address this task, and propose a novel approach, Personalized Context-Aware Search (PCAS), that effectively harnesses contextual information during passage retrieval. Experimental evaluations conducted on multiple popular dense retrieval systems demonstrate that our proposed approach not only outperforms the baselines in retrieving the most relevant passage but also excels at identifying the pertinent context among all the available contexts. We envision that our contributions will serve as a catalyst for inspiring future research endeavors in this pr
    
[^11]: ZC3: 跨语言零样本代码克隆检测

    ZC3: Zero-Shot Cross-Language Code Clone Detection. (arXiv:2308.13754v1 [cs.SE])

    [http://arxiv.org/abs/2308.13754](http://arxiv.org/abs/2308.13754)

    本文提出了一种名为ZC3的跨语言零样本代码克隆检测方法。该方法设计了对比代码片段预测，形成不同编程语言之间的同构表示空间，并利用领域感知学习和循环一致性学习来进一步约束模型。

    

    开发人员引入代码克隆以提高编程效率。许多现有研究在单语言代码克隆检测方面取得了令人瞩目的成果。然而，在软件开发过程中，越来越多的开发人员使用不同的语言编写语义上等价的程序，以支持不同的平台，并帮助开发人员从一种语言翻译项目到另一种语言。考虑到收集跨语言并行数据（尤其是低资源语言）的成本高昂且耗时，设计一种不依赖任何并行数据的有效跨语言模型是一个重要问题。本文提出了一种名为ZC3的新方法，用于零样本跨语言代码克隆检测。ZC3通过设计对比代码片段预测来形成不同编程语言之间的同构表示空间。基于此，ZC3利用领域感知学习和循环一致性学习进一步约束模型以生成表达。

    Developers introduce code clones to improve programming productivity. Many existing studies have achieved impressive performance in monolingual code clone detection. However, during software development, more and more developers write semantically equivalent programs with different languages to support different platforms and help developers translate projects from one language to another. Considering that collecting cross-language parallel data, especially for low-resource languages, is expensive and time-consuming, how designing an effective cross-language model that does not rely on any parallel data is a significant problem. In this paper, we propose a novel method named ZC3 for Zero-shot Cross-language Code Clone detection. ZC3 designs the contrastive snippet prediction to form an isomorphic representation space among different programming languages. Based on this, ZC3 exploits domain-aware learning and cycle consistency learning to further constrain the model to generate represen
    
[^12]: 关于将哲学、心理学与数学相结合的Philomatics和Psychomatics研究

    On Philomatics and Psychomatics for Combining Philosophy and Psychology with Mathematics. (arXiv:2308.13738v1 [math.HO])

    [http://arxiv.org/abs/2308.13738](http://arxiv.org/abs/2308.13738)

    本文提出了将哲学、心理学与数学相结合的Philomatics和Psychomatics概念，并解释了四个动机：满足分析哲学的需求、提出哲学科学、用哲学来证明数学算法以及哲学和数学的抽象。并列举了多个示例，包括数学中注意机制和上下文原则、形式理论与全息原理的关系等。本文为将哲学和心理学与数学相结合的研究开辟了研究空间。

    

    我们提出了将哲学、心理学与数学相结合的Philomatics和Psychomatics概念。我们解释了这种结合的四个动机，包括满足分析哲学的需求、提出哲学科学、用哲学来证明数学算法以及哲学和数学的抽象。我们列举了各种Philomatics和Psychomatics的示例，其中一些在更深入地解释。第一个示例是关于数学中注意机制与上下文原则、语义整体主义和使用理论的关系分析。另一个示例是关于哲学中柏拉图的形式理论与弦理论中的全息原理、面向对象编程和机器学习的关系。最后，我们解释了维特根斯坦的家族相似性与数学中的聚类的关系。本文为将哲学和心理学与数学相结合的研究打开了大门。

    We propose the concepts of philomatics and psychomatics as hybrid combinations of philosophy and psychology with mathematics. We explain four motivations for this combination which are fulfilling the desire of analytical philosophy, proposing science of philosophy, justifying mathematical algorithms by philosophy, and abstraction in both philosophy and mathematics. We enumerate various examples for philomatics and psychomatics, some of which are explained in more depth. The first example is the analysis of relation between the context principle, semantic holism, and the usage theory of meaning with the attention mechanism in mathematics. The other example is on the relations of Plato's theory of forms in philosophy with the holographic principle in string theory, object-oriented programming, and machine learning. Finally, the relation between Wittgenstein's family resemblance and clustering in mathematics is explained. This paper opens the door of research for combining philosophy and 
    
[^13]: 《一种用于可唱歌词翻译的计算评估框架》

    A Computational Evaluation Framework for Singable Lyric Translation. (arXiv:2308.13715v1 [cs.CL])

    [http://arxiv.org/abs/2308.13715](http://arxiv.org/abs/2308.13715)

    提出了一个用于量化评估可唱歌词翻译的计算框架，通过综合考量音乐、语言和文化维度，研究歌词的音节、音素、音乐结构和语义等方面的相似性指标，揭示了构成可唱歌词翻译的关键要素。

    

    歌词翻译在放大音乐的全球共鸣、弥合文化分歧和促进普遍联系中起着关键作用。与传统的翻译任务不同，歌词翻译需要在可唱性和语义之间保持微妙的平衡。本文提出了一个用于量化评估可唱歌词翻译的计算框架，将歌词的音乐、语言和文化维度无缝集成。我们的综合框架包括四个指标，分别衡量音节数目距离、音素重复相似性、音乐结构距离和语义相似性。为了实证我们框架的有效性，在英文、日文和韩文的歌词上，我们采集了一个可唱歌词数据集，并对可唱和不可唱歌词进行了比较分析。我们的跨学科方法揭示了构成可唱歌词翻译的关键要素。

    Lyric translation plays a pivotal role in amplifying the global resonance of music, bridging cultural divides, and fostering universal connections. Translating lyrics, unlike conventional translation tasks, requires a delicate balance between singability and semantics. In this paper, we present a computational framework for the quantitative evaluation of singable lyric translation, which seamlessly integrates musical, linguistic, and cultural dimensions of lyrics. Our comprehensive framework consists of four metrics that measure syllable count distance, phoneme repetition similarity, musical structure distance, and semantic similarity. To substantiate the efficacy of our framework, we collected a singable lyrics dataset, which precisely aligns English, Japanese, and Korean lyrics on a line-by-line and section-by-section basis, and conducted a comparative analysis between singable and non-singable lyrics. Our multidisciplinary approach provides insights into the key components that unde
    
[^14]: WellXplain: Reddit帖子中的健康概念提取和分类，用于精神健康分析

    WellXplain: Wellness Concept Extraction and Classification in Reddit Posts for Mental Health Analysis. (arXiv:2308.13710v1 [cs.CL])

    [http://arxiv.org/abs/2308.13710](http://arxiv.org/abs/2308.13710)

    本研究提出了一种通过在Reddit内容中识别健康维度的方法来进行复杂的精神健康分析。他们创建了一个名为WELLXPLAIN的数据集，并制定了一个注释框架。这种方法有助于在社交媒体上识别潜在的精神问题指标。

    

    在当前的精神健康危机中，从社交媒体内容中识别潜在的精神问题指标的重要性有所增加。忽视精神和社会幸福的多面性可能对一个人的精神状态产生有害影响。在传统的治疗过程中，专业人员需要手动确定潜在精神挑战的起源和结果，这是一个详细而耗时的过程。我们通过将Reddit内容中的健康维度识别为健康概念提取和分类的挑战，引入了一种复杂的精神健康分析方法。我们创建了一个名为WELLXPLAIN的独特数据集，包括3,092个条目，总计72,813个单词。基于哈尔伯特·L·邓恩的著名健康理论，我们的团队制定了一个注释框架和指南。该数据集还包括人工标记的文本片段，清楚解释了健康概念分类决策的原因。

    During the current mental health crisis, the importance of identifying potential indicators of mental issues from social media content has surged. Overlooking the multifaceted nature of mental and social well-being can have detrimental effects on one's mental state. In traditional therapy sessions, professionals manually pinpoint the origins and outcomes of underlying mental challenges, a process both detailed and time-intensive. We introduce an approach to this intricate mental health analysis by framing the identification of wellness dimensions in Reddit content as a wellness concept extraction and categorization challenge. We've curated a unique dataset named WELLXPLAIN, comprising 3,092 entries and totaling 72,813 words. Drawing from Halbert L. Dunn's well-regarded wellness theory, our team formulated an annotation framework along with guidelines. This dataset also includes human-marked textual segments, offering clear reasoning for decisions made in the wellness concept categoriza
    
[^15]: 关于文本生成中的束搜索和穷举搜索的深度问题研究

    On the Depth between Beam Search and Exhaustive Search for Text Generation. (arXiv:2308.13696v1 [cs.CL])

    [http://arxiv.org/abs/2308.13696](http://arxiv.org/abs/2308.13696)

    本研究探讨了束搜索和穷举搜索之间一系列不同的搜索深度，提出了前瞻束搜索（LBS）算法进行优化。尽管束搜索的搜索误差较高，但在计算成本和性能方面优于穷举搜索。

    

    束搜索和穷举搜索是文本解码算法中深度搜索的两个极端。束搜索在搜索宽度和深度上都有限制，而穷举搜索是全局搜索，没有这些限制。令人惊讶的是，尽管束搜索的搜索误差较高，但它不仅计算成本更低，而且表现更好。许多研究对一系列不同的束宽度进行了调查，并报告称既不太大也不太小的束宽度是理想的。然而，在搜索深度方面，只有束搜索和穷举搜索这两个极端得到了深入研究。在本文中，我们研究了介于两个极端之间的一系列搜索深度，以发现理想的搜索深度。为此，我们引入了前瞻束搜索（LBS），这是一种多步前瞻搜索，通过考虑未来固定步数来优化目标。束搜索和穷举搜索是特殊情况。

    Beam search and exhaustive search are two extreme ends of text decoding algorithms with respect to the search depth. Beam search is limited in both search width and depth, whereas exhaustive search is a global search that has no such limitations. Surprisingly, beam search is not only computationally cheaper but also performs better than exhaustive search despite its higher search error. Plenty of research has investigated a range of beam widths, from small to large, and reported that a beam width that is neither too large nor too small is desirable. However, in terms of search depth, only the two extreme ends, beam search and exhaustive search are studied intensively. In this paper, we examine a range of search depths between the two extremes to discover the desirable search depth. To this end, we introduce Lookahead Beam Search (LBS), a multi-step lookahead search that optimizes the objective considering a fixed number of future steps. Beam search and exhaustive search are special cas
    
[^16]: 聊天机器人生成了150万个材料叙述

    1.5 million materials narratives generated by chatbots. (arXiv:2308.13687v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2308.13687](http://arxiv.org/abs/2308.13687)

    聊天机器人生成了150万个材料叙述的数据集，通过与人类专家的评分对比，发现人类评分中的内容深度相对较低。

    

    人工智能的出现使得材料在各种应用中得到了全面的探索。然而，人工智能模型往往优先选择在科学文献中经常遇到的材料，从而限制了基于物理和化学特性选择适当候选材料的范围。为了解决这个不平衡问题，我们基于OQMD、Materials Project、JARVIS、COD和AFLOW2数据库生成了一个由1494017个自然语言-材料段落组成的数据集，其中占主导地位的是从头计算，并在周期表上的分布更加均匀。生成的文本叙述随后由人类专家和ChatGPT-4进行投票和评分，评分标准包括技术准确性、语言和结构、内容的相关性和深度，结果显示两者得分相似，但人类评分中的内容深度相对较低。多模态数据源和大型语言模型的合并具有巨大的潜力。

    The advent of artificial intelligence (AI) has enabled a comprehensive exploration of materials for various applications. However, AI models often prioritize frequently encountered materials in the scientific literature, limiting the selection of suitable candidates based on inherent physical and chemical properties. To address this imbalance, we have generated a dataset of 1,494,017 natural language-material paragraphs based on combined OQMD, Materials Project, JARVIS, COD and AFLOW2 databases, which are dominated by ab initio calculations and tend to be much more evenly distributed on the periodic table. The generated text narratives were then polled and scored by both human experts and ChatGPT-4, based on three rubrics: technical accuracy, language and structure, and relevance and depth of content, showing similar scores but with human-scored depth of content being the most lagging. The merger of multi-modality data sources and large language model (LLM) holds immense potential for 
    
[^17]: 重新思考语言模型作为符号知识图谱

    Rethinking Language Models as Symbolic Knowledge Graphs. (arXiv:2308.13676v1 [cs.CL])

    [http://arxiv.org/abs/2308.13676](http://arxiv.org/abs/2308.13676)

    本研究对不同大小和能力的语言模型进行了全面评估，发现它们能否涵盖知识图谱的复杂拓扑和语义属性，这对于推理过程至关重要。

    

    符号知识图谱在搜索、问答和推荐等以知识为中心的应用中起着关键作用。随着当代基于大量文本数据训练的语言模型（LMs）的重要性日益增加，研究人员广泛探讨了这些模型中的参数化知识是否能够与知识图谱中的知识相匹配。各种方法表明，增加模型大小或训练数据量可以增强其检索符号知识的能力，通常几乎不需要人工监督。尽管取得了这些进展，但我们对于语言模型能否涵盖知识图谱的复杂拓扑和语义属性进行了全面评估，这些属性对于推理过程至关重要。在这项工作中，我们对不同大小和能力的语言模型进行了详尽的评估。我们构建了九个定性基准，涵盖了一系列属性，包括对称性、不对称性、

    Symbolic knowledge graphs (KGs) play a pivotal role in knowledge-centric applications such as search, question answering and recommendation. As contemporary language models (LMs) trained on extensive textual data have gained prominence, researchers have extensively explored whether the parametric knowledge within these models can match up to that present in knowledge graphs. Various methodologies have indicated that enhancing the size of the model or the volume of training data enhances its capacity to retrieve symbolic knowledge, often with minimal or no human supervision. Despite these advancements, there is a void in comprehensively evaluating whether LMs can encompass the intricate topological and semantic attributes of KGs, attributes crucial for reasoning processes. In this work, we provide an exhaustive evaluation of language models of varying sizes and capabilities. We construct nine qualitative benchmarks that encompass a spectrum of attributes including symmetry, asymmetry, h
    
[^18]: GRASP: 一种高效的在线渐进式学习的重演策略

    GRASP: A Rehearsal Policy for Efficient Online Continual Learning. (arXiv:2308.13646v1 [cs.LG])

    [http://arxiv.org/abs/2308.13646](http://arxiv.org/abs/2308.13646)

    GRASP是一种新的样本选择策略，根据样本的代表性选择最适合学习的样本，从而提高了在线渐进式学习的效率。

    

    深度神经网络中的渐进学习涉及从不断增长的数据流中逐步累积知识。渐进学习的一个主要挑战是非平稳的数据流会导致之前学到的能力遭受灾难性遗忘。重演是一种常用且有效的缓解这个问题的方法，即将过去的观测结果存储在缓冲区中，并在学习过程中将它们与新的观测结果混合。这带来了一个问题：应该选择哪些存储样本进行重演？选择最适合学习的样本而不是随机选择样本，可能会导致学习速度显著加快。对于类增量学习，先前的研究表明简单的类均衡随机选择策略优于更复杂的方法。在这里，我们通过探索一种新的样本选择策略GRASP重新思考这个问题。GRASP首先选择最具代表性的样本，然后逐渐选择较不具代表性的样本。

    Continual learning (CL) in deep neural networks (DNNs) involves incrementally accumulating knowledge in a DNN from a growing data stream. A major challenge in CL is that non-stationary data streams cause catastrophic forgetting of previously learned abilities. Rehearsal is a popular and effective way to mitigate this problem, which is storing past observations in a buffer and mixing them with new observations during learning. This leads to a question: Which stored samples should be selected for rehearsal? Choosing samples that are best for learning, rather than simply selecting them at random, could lead to significantly faster learning. For class incremental learning, prior work has shown that a simple class balanced random selection policy outperforms more sophisticated methods. Here, we revisit this question by exploring a new sample selection policy called GRASP. GRASP selects the most prototypical (class representative) samples first and then gradually selects less prototypical (h
    
[^19]: 基于LSTM的Web微服务口碑评分的QoE评估

    LSTM-based QoE Evaluation for Web Microservices' Reputation Scoring. (arXiv:2308.13590v1 [cs.IR])

    [http://arxiv.org/abs/2308.13590](http://arxiv.org/abs/2308.13590)

    本研究提出了基于LSTM模型的情感分析和Net品牌声誉算法评估微服务的声誉分数的方法，并在一组与Amazon Web微服务相关的超过10,000条评论上进行了测试。

    

    情感分析是挖掘作者对特定实体的意见的任务。它允许组织实时监控不同的服务并采取相应的行动。声誉是人们或事物通常说到或相信的东西。非正式地说，声誉综合了从用户那里得到的反馈、评论和评级所反映的可靠度度量，这些反映了他们的体验质量(QoE)，可能会增加或损害所提供服务的声誉。在这项研究中，我们提出对Web微服务评价指标的情感分析，以利用提供的信息来评估和评分微服务的声誉。我们提出的方法使用了长短期记忆(LSTM)模型进行情感分析，并使用网络品牌声誉(NBR)算法评估微服务的声誉分数。该方法在与15个Amazon Web微服务相关的10000多条评论的数据集上进行了测试，实验结果表明

    Sentiment analysis is the task of mining the authors' opinions about specific entities. It allows organizations to monitor different services in real time and act accordingly. Reputation is what is generally said or believed about people or things. Informally, reputation combines the measure of reliability derived from feedback, reviews, and ratings gathered from users, which reflect their quality of experience (QoE) and can either increase or harm the reputation of the provided services. In this study, we propose to perform sentiment analysis on web microservices reviews to exploit the provided information to assess and score the microservices' reputation. Our proposed approach uses the Long Short-Term Memory (LSTM) model to perform sentiment analysis and the Net Brand Reputation (NBR) algorithm to assess reputation scores for microservices. This approach is tested on a set of more than 10,000 reviews related to 15 Amazon Web microservices, and the experimental results have shown that
    
[^20]: 使用大型语言模型进行文本风格转换评估

    Text Style Transfer Evaluation Using Large Language Models. (arXiv:2308.13577v1 [cs.CL])

    [http://arxiv.org/abs/2308.13577](http://arxiv.org/abs/2308.13577)

    大型语言模型（LLMs）有潜力成为人工评估和其他自动化评价指标的可行替代方案。

    

    文本风格转换（TST）的评估具有挑战性，因为生成文本的质量表现在多个方面，每个方面都很难单独衡量：风格转换准确性、内容保留和整体流畅性。人工评估是TST评估的黄金标准，然而，它费时费力，并且结果难以重复。许多自动化指标被用于评估这些方面的性能，作为人工评估的替代品。然而，许多自动化指标与人工评估之间的相关性仍然不清楚，对它们作为可靠基准的效果产生了怀疑。最近大型语言模型（LLMs）的进展已经证明了它们不仅能够匹配，而且在各种未见任务中还能超过平均人类表现。这表明LLMs有潜力成为人工评估和其他自动化指标的可行替代方案。我们评估了...

    Text Style Transfer (TST) is challenging to evaluate because the quality of the generated text manifests itself in multiple aspects, each of which is hard to measure individually: style transfer accuracy, content preservation, and overall fluency of the text. Human evaluation is the gold standard in TST evaluation; however, it is expensive, and the results are difficult to reproduce. Numerous automated metrics are employed to assess performance in these aspects, serving as substitutes for human evaluation. However, the correlation between many of these automated metrics and human evaluations remains unclear, raising doubts about their effectiveness as reliable benchmarks. Recent advancements in Large Language Models (LLMs) have demonstrated their ability to not only match but also surpass the average human performance across a wide range of unseen tasks. This suggests that LLMs have the potential to serve as a viable alternative to human evaluation and other automated metrics. We asses
    
[^21]: 个性化实时预测写作的集成方法对于专家

    An Ensemble Approach to Personalized Real Time Predictive Writing for Experts. (arXiv:2308.13576v1 [cs.CL])

    [http://arxiv.org/abs/2308.13576](http://arxiv.org/abs/2308.13576)

    本文介绍了一种集成方法，通过结合大型语言模型、马尔可夫模型和字符级模型，提供个性化的句子/单词自动补全建议，并在严格的延迟约束下实现高效准确的写作体验。

    

    在与用户进行笔记或实时聊天时，对于Intuit金融专家来说，在输入一些单词/字符后补全一个句子、短语或单词对于他们非常有帮助，因为他们需要在一天中多次高效准确地写入复杂的金融概念。在本文中，我们将大型语言模型、传统马尔可夫模型和字符级模型结合起来，创建了一个端到端系统，以在严格的延迟约束下为专家提供个性化的句子/单词自动补全建议。所提出的系统可以在书写时自动补全句子、短语或单词，并且可以通过很少的数据和资源进行训练，并具有良好的效率。我们提出的系统不仅高效和个性化，而且具有鲁棒性，因为它利用多种机器学习技术以及基于转移学习的方法通过Intuit特定数据微调大型语言模型。这确保即使在罕见或不寻常的短语情况下也能有效运行。

    Completing a sentence, phrase or word after typing few words / characters is very helpful for Intuit financial experts, while taking notes or having a live chat with users, since they need to write complex financial concepts more efficiently and accurately many times in a day. In this paper, we tie together different approaches like large language models, traditional Markov Models and char level models to create an end-to-end system to provide personalised sentence/word auto-complete suggestions to experts, under strict latency constraints. Proposed system can auto-complete sentences, phrases or words while writing with personalisation and can be trained with very less data and resources with good efficiency. Our proposed system is not only efficient and personalized but also robust as it leverages multiple machine learning techniques along with transfer learning approach to fine tune large language model with Intuit specific data. This ensures that even in cases of rare or unusual phr
    
[^22]: 用主题建模发现心理健康研究课题

    Discovering Mental Health Research Topics with Topic Modeling. (arXiv:2308.13569v1 [cs.CL])

    [http://arxiv.org/abs/2308.13569](http://arxiv.org/abs/2308.13569)

    本研究通过分析大量心理健康研究论文，采用自定义嵌入模型，识别出该领域的一般趋势和高影响力的研究课题。

    

    心理健康显著影响我们日常生活的各个方面，其重要性在研究界和大众中越来越受到认可，特别是在COVID-19大流行之后。在过去的十年中，心理健康领域的出版物数量不断增长，这种浓厚的兴趣也体现在越来越多的研究论文中。本研究的目标是通过分析大型心理健康研究论文数据集，识别该领域的一般趋势，并找出具有高影响力的研究课题。为了实现这一目标，我们从各个数据库收集了摘要，并使用基于BERTopic框架的自定义Sentence-BERT嵌入模型进行训练。我们的数据集包含96,676篇与心理健康相关的研究论文，使我们能够通过它们的摘要来研究不同主题之间的关系。为了评估模型的效果，我们将其与另外两种最先进的方法进行了对比：Top2Vec模型和LDA-BERT模型。

    Mental health significantly influences various aspects of our daily lives, and its importance has been increasingly recognized by the research community and the general public, particularly in the wake of the COVID-19 pandemic. This heightened interest is evident in the growing number of publications dedicated to mental health in the past decade. In this study, our goal is to identify general trends in the field and pinpoint high-impact research topics by analyzing a large dataset of mental health research papers. To accomplish this, we collected abstracts from various databases and trained a customized Sentence-BERT based embedding model leveraging the BERTopic framework. Our dataset comprises 96,676 research papers pertaining to mental health, enabling us to examine the relationships between different topics using their abstracts. To evaluate the effectiveness of the model, we compared it against two other state-of-the-art methods: Top2Vec model and LDA-BERT model. The model demonstr
    
[^23]: MLLM-DataEngine：一种MLLM的迭代改进方法

    MLLM-DataEngine: An Iterative Refinement Approach for MLLM. (arXiv:2308.13566v1 [cs.LG])

    [http://arxiv.org/abs/2308.13566](http://arxiv.org/abs/2308.13566)

    本文提出了一种名为MLLM-DataEngine的迭代改进方法，它通过分析模型弱点，生成适当的增量数据集并迭代地增强模型能力。与以往方法相比，MLLM-DataEngine生成的数据在定位、质量和正确性方面表现更好。

    

    尽管在指导数据集构建和基准测试方面，多模态大型语言模型（MLLM）取得了很大的进展，但训练和评估的独立性使得当前的MLLM很难在相对较低的人力成本下进一步提高其能力。本文提出了一种新颖的封闭循环系统MLLM-DataEngine，它连接了数据生成、模型训练和评估。在每个循环迭代中，MLLM-DataEngine首先根据评估结果分析模型的弱点，然后生成合适的增量数据集用于下一次训练迭代，并迭代地增强模型的能力。与先前与基准测试分离的数据收集方法相比，MLLM-DataEngine生成的数据在定位、质量和正确性方面都表现得更好。

    Despite the great advance of Multimodal Large Language Models (MLLMs) in both instruction dataset building and benchmarking, the independence of training and evaluation makes current MLLMs hard to further improve their capability under the guidance of evaluation results with a relatively low human cost. In this paper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data generation, model training, and evaluation. Within each loop iteration, the MLLM-DataEngine first analyze the weakness of the model based on the evaluation results, then generate a proper incremental dataset for the next training iteration and enhance the model capability iteratively. Compared with previous data collection methods which are separate from the benchmarking, the data generated by MLLM-DataEngine shows better targeting, quality, and correctness. For targeting, we propose an Adaptive Bad-case Sampling module, which adjusts the ratio of different types of data within each incremental datas
    
[^24]: DARWIN系列：面向自然科学的领域特定大型语言模型

    DARWIN Series: Domain Specific Large Language Models for Natural Science. (arXiv:2308.13565v1 [cs.CL])

    [http://arxiv.org/abs/2308.13565](http://arxiv.org/abs/2308.13565)

    DARWIN系列是为自然科学领域开发的定制语言模型，通过引入科学指令生成模型和大量数据微调，加速了自动化发现过程的进行。

    

    新兴的工具带来了新的工作方法，自然科学领域也不例外。在自然科学中，传统的手工、串行和劳动密集型工作正被基于人工智能的实验自动化和更多的自动化、并行和迭代过程所取代。为了在自然科学中增加新的能力，加速和丰富发现过程的自动化，我们提出了DARWIN，一个面向自然科学的系列定制LLM，主要应用在物理学、化学和材料科学等领域。该系列依赖于开源LLM，将公共数据集和文献中的结构化和非结构化科学知识整合进来。我们使用了超过60,000个指令数据点对模型进行了微调，强调事实的正确性。在微调过程中，我们引入了科学指令生成（SIG）模型，从科学文本中自动生成指令。这消除了手动提取或领域特定知识的需求。

    Emerging tools bring forth fresh approaches to work, and the field of natural science is no different. In natural science, traditional manual, serial, and labour-intensive work is being augmented by automated, parallel, and iterative processes driven by artificial intelligence-based experimental automation and more. To add new capabilities in natural science, enabling the acceleration and enrichment of automation of the discovery process, we present DARWIN, a series of tailored LLMs for natural science, mainly in physics, chemistry, and material science. This series relies on open-source LLM, incorporating structured and unstructured scientific knowledge from public datasets and literature. We fine-tuned the models using over 60,000 instruction data points, emphasizing factual correctness. During the fine-tuning, we introduce the Scientific Instruction Generation (SIG) model, automating instruction generation from scientific texts. This eliminates the need for manual extraction or doma
    
[^25]: 大型语言模型在分析事故叙述中的应用——ChatGPT、BARD和GPT-4的比较研究

    Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4. (arXiv:2308.13563v1 [cs.CL])

    [http://arxiv.org/abs/2308.13563](http://arxiv.org/abs/2308.13563)

    三个大型语言模型接口(ChatGPT, BARD和GPT4)在分析事故叙述中的效果进行了比较研究。研究结果表明，它们在提取事故相关信息和回答相关问题方面都具有一定的有效性，但也存在一些限制。

    

    在交通安全研究中，使用文本分析从事故叙述中提取信息是一种常见的做法。随着大型语言模型（LLM）的最新进展，了解流行的LLM接口在分类或从事故叙述中提取信息方面的表现将非常有用。为了探索这一问题，我们的研究使用了目前最流行的三个公开可用的LLM接口——ChatGPT、BARD和GPT4。本研究调查了它们在提取信息和回答与事故有关的查询方面的有效性和限制。研究从爱荷华州和堪萨斯州的100个事故叙述中提取信息，并对它们的能力和限制进行了评估，比较了它们对查询的响应。五个与叙述相关的问题被提出：1）谁是责任方？2）碰撞方式是什么？3）事故发生在工作区吗？4）事故涉及行人吗？5）事故中有害事件的顺序是什么？对于第1到第4个问题，三个LLM接口的回答都经过了比较。

    In traffic safety research, extracting information from crash narratives using text analysis is a common practice. With recent advancements of large language models (LLM), it would be useful to know how the popular LLM interfaces perform in classifying or extracting information from crash narratives. To explore this, our study has used the three most popular publicly available LLM interfaces- ChatGPT, BARD and GPT4. This study investigated their usefulness and boundaries in extracting information and answering queries related to accidents from 100 crash narratives from Iowa and Kansas. During the investigation, their capabilities and limitations were assessed and their responses to the queries were compared. Five questions were asked related to the narratives: 1) Who is at-fault? 2) What is the manner of collision? 3) Has the crash occurred in a work-zone? 4) Did the crash involve pedestrians? and 5) What are the sequence of harmful events in the crash? For questions 1 through 4, the o
    
[^26]: 使用深度生成模型进行孟加拉文本分类的特征提取（arXiv:2308.13545v1 [cs.IR]）

    Feature Extraction Using Deep Generative Models for Bangla Text Classification on a New Comprehensive Dataset. (arXiv:2308.13545v1 [cs.IR])

    [http://arxiv.org/abs/2308.13545](http://arxiv.org/abs/2308.13545)

    本研究提出了使用深度生成模型在孟加拉文本分类中进行特征提取的方法，并收集、注释了一个全面的数据集。评估结果表明，对抗自编码器模型产生了最佳的特征空间。

    

    文本分类中的特征选择是文本挖掘和信息检索中的基础任务。尽管孟加拉语是世界上使用最广泛的第六大语言，但由于文本数据集的稀缺性，它一直受到较少关注。在本研究中，我们收集、注释和准备了一个包含212,184个孟加拉文档的全面数据集，涵盖了七个不同的类别，并将其公开。我们实现了三个深度学习生成模型：LSTM变分自编码器（LSTM VAE）、辅助分类器生成对抗网络（AC-GAN）和对抗自编码器（AAE）来提取文本特征，尽管它们的应用最初是在计算机视觉领域发现的。我们利用我们的数据集训练了这三个模型，并在文档分类任务中使用了得到的特征空间。我们评估了分类器的性能，并发现对抗自编码器模型产生了最佳的特征空间。

    The selection of features for text classification is a fundamental task in text mining and information retrieval. Despite being the sixth most widely spoken language in the world, Bangla has received little attention due to the scarcity of text datasets. In this research, we collected, annotated, and prepared a comprehensive dataset of 212,184 Bangla documents in seven different categories and made it publicly accessible. We implemented three deep learning generative models: LSTM variational autoencoder (LSTM VAE), auxiliary classifier generative adversarial network (AC-GAN), and adversarial autoencoder (AAE) to extract text features, although their applications are initially found in the field of computer vision. We utilized our dataset to train these three models and used the feature space obtained in the document classification task. We evaluated the performance of the classifiers and found that the adversarial autoencoder model produced the best feature space.
    
[^27]: 一个概念游戏特征生成与推荐系统的初步研究

    A Preliminary Study on a Conceptual Game Feature Generation and Recommendation System. (arXiv:2308.13538v1 [cs.IR])

    [http://arxiv.org/abs/2308.13538](http://arxiv.org/abs/2308.13538)

    本研究介绍了一个用于生成游戏特征建议的系统，通过使用文本提示，提取主题相似的游戏特征并生成新特征。经过用户研究比较，该系统的生成模型在某些游戏中的表现超过了人工建议。该系统是一个与用户在概念层面上进行协作的游戏设计助手工具的一部分。

    

    本文介绍了一个基于文本提示生成游戏特征建议的系统。该系统通过使用一个小型的GLoVe模型的词嵌入来提取主题相似的游戏中的特征和实体，并将其通过一个生成模型传递，用于生成用户提示的新特征。我们进行了一项短期用户研究，比较了来自一个经过微调的GPT-2模型、使用ConceptNet的模型以及人工编写的游戏特征生成的特征。虽然人工建议获得了绝大多数的投票，但在某些游戏中，GPT-2模型的表现超过了人工建议。该系统是一个更大的游戏设计助手工具的一部分，能够在概念层面上与用户进行协作。

    This paper introduces a system used to generate game feature suggestions based on a text prompt. Trained on the game descriptions of almost 60k games, it uses the word embeddings of a small GLoVe model to extract features and entities found in thematically similar games which are then passed through a generator model to generate new features for a user's prompt. We perform a short user study comparing the features generated from a fine-tuned GPT-2 model, a model using the ConceptNet, and human-authored game features. Although human suggestions won the overall majority of votes, the GPT-2 model outperformed the human suggestions in certain games. This system is part of a larger game design assistant tool that is able to collaborate with users at a conceptual level.
    
[^28]: 建立对话型AI中的信任：使用LLMs和知识图谱构建可解释的、隐私感知的系统的综述和解决方案架构

    Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph. (arXiv:2308.13534v1 [cs.CL])

    [http://arxiv.org/abs/2308.13534](http://arxiv.org/abs/2308.13534)

    本论文提出了一种综述和解决方案架构，用于构建可解释的、隐私感知的对话型AI系统。首先介绍了LLM模型的综合工具LLMXplorer，并阐明了其对社会、伦理和监管等方面的影响。然后提出了将知识图谱的结构动态与LLM的语言能力无缝集成的架构。通过使用真实世界的AI新闻数据进行验证，该架构成功地融合了语言的复杂性与事实的严谨性，并增强了数据安全性。

    

    对话型AI系统已成为各个领域实现类似于人类交互的关键驱动因素。然而，语言细微差别和事实准确性之间的平衡一直难以把握。在本文中，我们首先介绍了LLMXplorer，这是一个全面的工具，详细审视了150多个大型语言模型（LLMs），阐明了它们从社会、伦理到监管的各种影响，以及它们在各行各业的适用性。在此基础上，我们提出了一种新颖的功能架构，将知识图谱的结构动态与LLMs的语言能力无缝集成。通过使用真实世界的AI新闻数据进行验证，我们的架构巧妙地融合了语言的复杂性与事实的严谨性，并通过基于角色的访问控制进一步加强了数据安全性。本研究为对话型AI发展的变化景观提供了深入见解，强调了高效、透明的系统的必要性。

    Conversational AI systems have emerged as key enablers of human-like interactions across diverse sectors. Nevertheless, the balance between linguistic nuance and factual accuracy has proven elusive. In this paper, we first introduce LLMXplorer, a comprehensive tool that provides an in-depth review of over 150 Large Language Models (LLMs), elucidating their myriad implications ranging from social and ethical to regulatory, as well as their applicability across industries. Building on this foundation, we propose a novel functional architecture that seamlessly integrates the structured dynamics of Knowledge Graphs with the linguistic capabilities of LLMs. Validated using real-world AI news data, our architecture adeptly blends linguistic sophistication with factual rigour and further strengthens data security through Role-Based Access Control. This research provides insights into the evolving landscape of conversational AI, emphasizing the imperative for systems that are efficient, transp
    
[^29]: 在段落级别上训练和元评估机器翻译评估指标

    Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level. (arXiv:2308.13506v1 [cs.CL])

    [http://arxiv.org/abs/2308.13506](http://arxiv.org/abs/2308.13506)

    本论文研究了在机器翻译中，如何在段落级别评估翻译质量。实验结果表明，使用句子级别的评估指标来评分整个段落与使用段落级别的指标一样有效。

    

    随着机器翻译研究的发展，将文本翻译到句子以上的级别，自动评估指标在评分更长的翻译上的有效性仍不清楚。在本研究中，我们首先提出了一种方法，通过使用现有的句子级别数据创建段落级别的数据，用于训练和元评估指标。然后，我们使用这些新数据集来评估现有的句子级别指标，并在段落级别上训练学习指标。有趣的是，我们的实验结果表明，使用句子级别的指标来评分整个段落与使用专门设计用于段落级别工作的指标一样有效。我们推测这个结果可能归因于参考评估任务的特性以及我们的数据集在捕捉段落级别翻译中出现的所有类型现象方面的局限性。

    As research on machine translation moves to translating text beyond the sentence level, it remains unclear how effective automatic evaluation metrics are at scoring longer translations. In this work, we first propose a method for creating paragraph-level data for training and meta-evaluating metrics from existing sentence-level data. Then, we use these new datasets to benchmark existing sentence-level metrics as well as train learned metrics at the paragraph level. Interestingly, our experimental results demonstrate that using sentence-level metrics to score entire paragraphs is equally as effective as using a metric designed to work at the paragraph level. We speculate this result can be attributed to properties of the task of reference-based evaluation as well as limitations of our datasets with respect to capturing all types of phenomena that occur in paragraph-level translations.
    
[^30]: 大型语言模型的投票：用于罕见病识别的提示

    Large Language Models Vote: Prompting for Rare Disease Identification. (arXiv:2308.12890v1 [cs.CL])

    [http://arxiv.org/abs/2308.12890](http://arxiv.org/abs/2308.12890)

    本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。

    

    生成式大型语言模型(LLMs)的出现强调了准确和高效的提示方法的需求。LLMs经常应用于少样本学习(FSL)的情境中，这里任务只使用很少的训练数据执行。FSL在许多人工智能(AI)子领域中变得流行，包括用于健康的AI。罕见病影响人口的一小部分，在数据可用性受限的情况下 inherently 需要FSL技术，尽管人工数据收集和标注费时费力。在本文中，我们提出了模型投票提示(MVP)，这是一种用于改善FSL环境中LLM查询性能的灵活提示方法。MVP通过提示多个LLMs执行相同的任务，然后对生成的输出进行多数投票来实现。该方法在单次罕见病识别和分类任务中相对于任何单个模型在集成模型中实现了改进的结果。我们还发布了一个新颖的罕见病数据集用于FSL。

    The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases, affecting a small fraction of the population, inherently require FSL techniques due to limited data availability, though manual data collection and annotation is costly and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FS
    
[^31]: 走出笼子：随机鹦鹉在网络安全环境中的胜利

    Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments. (arXiv:2308.12086v1 [cs.CR])

    [http://arxiv.org/abs/2308.12086](http://arxiv.org/abs/2308.12086)

    本文将预训练的大型语言模型（LLMs）应用于网络安全环境，作为攻击代理人进行顺序决策。该设计表明LLMs在高效应对复杂决策方面具有潜力，并且在大多数场景中表现出与经过训练的最先进代理相似或更好的性能。

    

    大型语言模型（LLMs）在涉及文本生成、摘要和各种自然语言处理任务的不同领域中广受欢迎。尽管存在固有的局限性，基于LLM的设计在规划和导航开放世界场景方面显示出有希望的能力。本文将预训练的LLMs用作网络安全环境中的代理人的新应用，重点关注它们在顺序决策过程中的效用。我们提出了一种方法，利用预训练的LLMs作为两个强化学习环境中的攻击代理。在大多数场景和配置中，我们提出的代理在表现上与经过数千次训练的最先进代理相似或更好。此外，最佳LLM代理在没有任何额外训练过程的情况下表现与环境的人类测试者类似。这种设计突显了LLMs在高效应对复杂决策方面的潜力。

    Large Language Models (LLMs) have gained widespread popularity across diverse domains involving text generation, summarization, and various natural language processing tasks. Despite their inherent limitations, LLM-based designs have shown promising capabilities in planning and navigating open-world scenarios. This paper introduces a novel application of pre-trained LLMs as agents within cybersecurity network environments, focusing on their utility for sequential decision-making processes.  We present an approach wherein pre-trained LLMs are leveraged as attacking agents in two reinforcement learning environments. Our proposed agents demonstrate similar or better performance against state-of-the-art agents trained for thousands of episodes in most scenarios and configurations. In addition, the best LLM agents perform similarly to human testers of the environment without any additional training process. This design highlights the potential of LLMs to efficiently address complex decision
    
[^32]: 线性语言模型辅助分析表格数据的方法研究

    Bridging the Gap: Deciphering Tabular Data Using Large Language Model. (arXiv:2308.11891v1 [cs.CL])

    [http://arxiv.org/abs/2308.11891](http://arxiv.org/abs/2308.11891)

    本研究旨在提升大型语言模型在理解表格数据上的能力，通过设计一个表格序列化模块和纠正机制来实现。实验结果表明，尽管相对于最先进技术仍有差距，但该方法在处理表格数据方面取得了一定的进展。

    

    在自然语言处理领域，对表格数据的理解一直是学术研究的重点。随着诸如ChatGPT之类的庞大语言模型的出现，研究人员开始探索如何利用这些模型来处理与表格相关的问题。我们的研究旨在探索提升大型语言模型在理解表格结构和内容上的能力，以便更好地回答相关问题。为此，我们设计了一个专门用于将表格序列化的模块，并在模型中引入了一个纠正机制来修正潜在的错误。实验结果显示，尽管我们的方法相对于最先进技术仍有差距。

    In the realm of natural language processing, the understanding of tabular data has perpetually stood as a focal point of scholarly inquiry. The emergence of expansive language models, exemplified by the likes of ChatGPT, has ushered in a wave of endeavors wherein researchers aim to harness these models for tasks related to table-based question answering. Central to our investigative pursuits is the elucidation of methodologies that amplify the aptitude of such large language models in discerning both the structural intricacies and inherent content of tables, ultimately facilitating their capacity to provide informed responses to pertinent queries. To this end, we have architected a distinctive module dedicated to the serialization of tables for seamless integration with expansive language models. Additionally, we've instituted a corrective mechanism within the model to rectify potential inaccuracies. Experimental results indicate that, although our proposed method trails the SOTA by ap
    
[^33]: 对大型语言模型代码生成的鲁棒性和可靠性的研究

    A Study on Robustness and Reliability of Large Language Model Code Generation. (arXiv:2308.10335v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10335](http://arxiv.org/abs/2308.10335)

    本研究针对大型语言模型生成的代码的可靠性和鲁棒性进行了研究，发现在真实的软件开发中可执行的代码并不能保证可靠和鲁棒，滥用API可能导致严重问题。这对初级开发者来说尤其危险，因为他们很难察觉到代码中的API滥用问题。

    

    最近，大型语言模型(LLMs)在理解自然语言和生成编程代码方面显示出了非凡能力。当遇到编码问题时，软件工程师常常会咨询LLMs。尽管已经做出了一些努力来避免语法错误并使代码与预期的语义对齐，但LLMs生成的代码的可靠性和鲁棒性尚未被深入研究。在真实的软件开发环境中，可执行的代码并不等同于可靠和鲁棒的代码。在生成的代码中滥用API可能会导致严重的问题，如资源泄漏、程序崩溃。更糟糕的是，LLM代码生成服务的用户实际上是最容易受到这些看似正确的代码影响的开发者——他们通常是不熟悉LLMs为他们生成代码的API的初级开发者。因此，他们很难察觉到API的滥用。

    Recently, the large language models (LLMs) have shown extraordinary ability in understanding natural language and generating programming code. It has been a common practice of software engineers to consult LLMs when encountering coding questions. Although efforts have been made to avoid syntax errors and align the code with the intended semantics, the reliability and robustness of the code generationfrom LLMs have not yet been thoroughly studied. The executable code is not equivalent to the reliable and robust code, especially in the context of real-world software development. The misuse of APIs in the generated code could lead to severe problem, such as resource leaks, program crashes. To make things worse, the users of LLM code generation services are actually the developers that are most vulnerable to these code that seems right -- They are always novice developers that are not familiar with the APIs that LLMs generate code for them. Therefore, they could hardly tell the misuse in t
    
[^34]: MindMap：知识图谱激发大型语言模型的思维图思考方法

    MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])

    [http://arxiv.org/abs/2308.09729](http://arxiv.org/abs/2308.09729)

    本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。

    

    通常，大型语言模型存在无法整合新知识、产生幻觉和决策过程不透明等限制。本文探讨了如何利用知识图谱（KG）来激发大型语言模型，以解决整合最新知识和引发模型思维路径的问题。具体来说，我们构建了一个提示管道，使大型语言模型能够理解KG输入并利用隐含知识和检索到的外部知识进行推理。此外，我们研究了引发大型语言模型执行推理和生成答案的思维导图。研究发现，生成的思维导图基于知识的本体论，展示了大型语言模型的推理路径，从而为生产环境中的推理提供了探索和评估的可能性。对三个问答数据集的实验证明，MindMap提示方法带来了显著的实证增益。

    LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, pr
    
[^35]: SPM: Meituan搜索中用于相关性建模的结构化预训练和匹配架构

    SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search. (arXiv:2308.07711v1 [cs.IR])

    [http://arxiv.org/abs/2308.07711](http://arxiv.org/abs/2308.07711)

    本论文提出了一种用于在Meituan搜索中进行相关性建模的新颖两阶段预训练和匹配架构。

    

    在电商搜索中，查询和文档之间的相关性是满足用户体验的基本要求。与传统的电商平台不同，用户在美团等生活服务平台上进行搜索主要是为了产品供应商，这些供应商通常拥有丰富的结构化信息，例如名称、地址、类别、成千上万的产品。使用这些丰富的结构化内容进行搜索相关性建模具有挑战性，主要存在以下问题：（1）不同字段的结构化文档存在语言分布差异，无法直接采用预训练的语言模型方法（如BERT）。（2）不同字段通常具有不同的重要性，且长度差异很大，很难提取对相关性匹配有帮助的文档信息。为了解决这些问题，本文提出了一种新的两阶段预训练和匹配架构，用于丰富结构的相关性匹配。

    In e-commerce search, relevance between query and documents is an essential requirement for satisfying user experience. Different from traditional e-commerce platforms that offer products, users search on life service platforms such as Meituan mainly for product providers, which usually have abundant structured information, e.g. name, address, category, thousands of products. Modeling search relevance with these rich structured contents is challenging due to the following issues: (1) there is language distribution discrepancy among different fields of structured document, making it difficult to directly adopt off-the-shelf pretrained language model based methods like BERT. (2) different fields usually have different importance and their length vary greatly, making it difficult to extract document information helpful for relevance matching.  To tackle these issues, in this paper we propose a novel two-stage pretraining and matching architecture for relevance matching with rich structure
    
[^36]: EcomGPT: 使用任务链调节大型语言模型以适应电子商务领域

    EcomGPT: Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce. (arXiv:2308.06966v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.06966](http://arxiv.org/abs/2308.06966)

    EcomGPT是针对电子商务领域的任务链调节语言模型，通过构建原子任务链并使用EcomInstruct数据集进行训练，具有较强的通用化能力。

    

    最近，指令跟随的大型语言模型（LLM），例如ChatGPT，在通用自然语言处理（NLP）任务中展现了出色的性能。然而，电子商务数据的独特特点对于通用LLM来说带来了重大挑战。为了解决这个问题，我们提出了第一个针对电子商务场景的LLM，名为EcomGPT。通过构建以电子商务基本数据类型（例如产品信息、用户评价）为基础的原子任务，EcomInstruct数据集扩大了数据规模和任务多样性。原子任务是隐含在解决最终任务中的中间任务，我们也称之为任务链任务。通过使用EcomInstruct训练骨干模型BLOOMZ，我们开发了具有不同参数规模的EcomGPT。

    Recently, instruction-following Large Language Models (LLMs) , represented by ChatGPT, have exhibited exceptional performance in general Natural Language Processing (NLP) tasks. However, the unique characteristics of E-commerce data pose significant challenges to general LLMs. An LLM tailored specifically for E-commerce scenarios, possessing robust cross-dataset/task generalization capabilities, is a pressing necessity. To solve this issue, in this work, we proposed the first e-commerce instruction dataset EcomInstruct, with a total of 2.5 million instruction data. EcomInstruct scales up the data size and task diversity by constructing atomic tasks with E-commerce basic data types, such as product information, user reviews. Atomic tasks are defined as intermediate tasks implicitly involved in solving a final task, which we also call Chain-of-Task tasks. We developed EcomGPT with different parameter scales by training the backbone model BLOOMZ with the EcomInstruct. Benefiting from the 
    
[^37]: 问题分类的集成方法：融合Electra Transformer、GloVe和LSTM

    An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM. (arXiv:2308.06828v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.06828](http://arxiv.org/abs/2308.06828)

    本研究提出了一种集成Electra Transformer、GloVe和LSTM模型的创新问题分类方法，通过在TREC数据集上进行严格测试，证明了融合不同技术可以获得更优越的结果。

    

    自然语言处理（NLP）已经成为理解和生成人类语言的关键技术，它在机器翻译、情感分析等任务中扮演着重要角色，尤其是在问题分类方面。作为自然语言处理的子领域，问题分类专注于确定所需信息的类型，这是问题回答系统等下游应用的基本步骤。本研究提出了一种创新的问题分类集成方法，将Electra、GloVe和LSTM模型的优势相结合。该模型在著名的TREC数据集上进行了严格测试，展示了如何整合这些不同技术可以得到更优越的结果。Electra提供了基于transformer的复杂语言理解能力，GloVe提供了全局向量表示以捕捉词级语义，LSTM则贡献了序列学习能力以建模长期依赖关系。

    Natural Language Processing (NLP) has emerged as a crucial technology for understanding and generating human language, playing an essential role in tasks such as machine translation, sentiment analysis, and more pertinently, question classification. As a subfield within NLP, question classification focuses on determining the type of information being sought, a fundamental step for downstream applications like question answering systems. This study presents an innovative ensemble approach for question classification, combining the strengths of Electra, GloVe, and LSTM models. Rigorously tested on the well-regarded TREC dataset, the model demonstrates how the integration of these disparate technologies can lead to superior results. Electra brings in its transformer-based capabilities for complex language understanding, GloVe offers global vector representations for capturing word-level semantics, and LSTM contributes its sequence learning abilities to model long-term dependencies. By fus
    
[^38]: 外部推理：朝着多种大型语言模型可互换辅助与人类反馈的方向前进

    External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback. (arXiv:2307.12057v1 [cs.CL])

    [http://arxiv.org/abs/2307.12057](http://arxiv.org/abs/2307.12057)

    本文提出通过从外部存储库中选择性地集成知识来增强大型语言模型，提出了一种外部推理的新方法，例子是ChatPDF。

    

    记忆被认为是使海马体和脑神经元内保持视觉和语言信息、随后用于解决通过学习一生中遇到的现实挑战的关键人类能力。通过应用已获得的知识解决复杂的人工智能任务是实现人工通用智能的一大进展。然而，尽管像GPT-3.5和GPT-4这样的大型语言模型在语言理解、生成、交互和推理方面显示了卓越的能力，但由于上下文长度的限制，它们无法处理广泛、不断演变的知识库。本文提出通过从外部存储库中选择性地集成知识来增强LLMs，并介绍了一种外部推理的新方法，例子是ChatPDF。

    Memory is identified as a crucial human faculty that allows for the retention of visual and linguistic information within the hippocampus and neurons in the brain, which can subsequently be retrieved to address real-world challenges that arise through a lifetime of learning. The resolution of complex AI tasks through the application of acquired knowledge represents a stride toward the realization of artificial general intelligence. However, despite the prevalence of Large Language Models (LLMs) like GPT-3.5 and GPT-4 , which have displayed remarkable capabilities in language comprehension, generation, interaction, and reasoning, they are inhibited by constraints on context length that preclude the processing of extensive, continually evolving knowledge bases. This paper proposes that LLMs could be augmented through the selective integration of knowledge from external repositories, and in doing so, introduces a novel methodology for External Reasoning, exemplified by ChatPDF. Central to
    
[^39]: 潜在越狱：评估大型语言模型的文本安全性和输出鲁棒性的测试套件

    Latent Jailbreak: A Test Suite for Evaluating Both Text Safety and Output Robustness of Large Language Models. (arXiv:2307.08487v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08487](http://arxiv.org/abs/2307.08487)

    这篇论文提出了一个评估大型语言模型安全性和鲁棒性的基准测试套件，强调了平衡的方法。通过引入含有恶意指令的潜在越狱提示数据集，并设计分层注释框架，全面研究了文本安全性和输出鲁棒性。

    

    已经有大量的研究致力于确保大型语言模型（LLMs）与人类价值观相一致并生成安全文本。然而，对某些主题的过度关注可能会损害模型在遵循指令方面的鲁棒性，从而影响其在完成任务方面的整体表现。以往用于越狱LLMs的基准主要关注评估模型的安全性，而没有考虑其鲁棒性。在本文中，我们提出了一个评估LLMs安全性和鲁棒性的基准，强调需要一个平衡的方法。为了全面研究文本安全性和输出鲁棒性，我们引入了一个潜在越狱提示数据集，每个数据集中都包含恶意指令嵌入。具体而言，我们指导模型完成常规任务，例如翻译，其中待翻译的文本包含恶意指令。为了进一步分析安全性和鲁棒性，我们设计了一个分层注释框架。

    Considerable research efforts have been devoted to ensuring that large language models (LLMs) align with human values and generate safe text. However, an excessive focus on sensitivity to certain topics can compromise the model's robustness in following instructions, thereby impacting its overall performance in completing tasks. Previous benchmarks for jailbreaking LLMs have primarily focused on evaluating the safety of the models without considering their robustness. In this paper, we propose a benchmark that assesses both the safety and robustness of LLMs, emphasizing the need for a balanced approach. To comprehensively study text safety and output robustness, we introduce a latent jailbreak prompt dataset, each involving malicious instruction embedding. Specifically, we instruct the model to complete a regular task, such as translation, with the text to be translated containing malicious instructions. To further analyze safety and robustness, we design a hierarchical annotation fram
    
[^40]: 软件开发中的交流型代理

    Communicative Agents for Software Development. (arXiv:2307.07924v1 [cs.SE])

    [http://arxiv.org/abs/2307.07924](http://arxiv.org/abs/2307.07924)

    本文介绍了一种创新的软件开发范式，利用大型语言模型(LLMs)在整个软件开发过程中实现自然语言交流，消除了每个阶段需要专门模型的需求。该范式使用ChatDev作为一个虚拟聊天驱动的软件开发公司，通过设计、编码、测试和文档化四个阶段的代理人团队促进协作。

    

    软件工程是一个以微妙的直觉和咨询为特征的领域，决策过程复杂。深度学习的最新进展已经开始通过在软件开发的各个阶段实施精心设计来革新软件工程实践。在本文中，我们提出了一种创新的范式，通过自然语言交流，在整个软件开发过程中利用大型语言模型(LLMs)，简化和统一关键流程，从而消除了在每个阶段需要专门的模型的需要。这个范式的核心是ChatDev，一个虚拟的聊天驱动软件开发公司，它模仿了已经建立的瀑布模型，将开发过程细分为四个不同的时间阶段：设计、编码、测试和文档化。每个阶段都涉及一个团队的代理人，如程序员、代码审查人员和测试工程师，促进协作。

    Software engineering is a domain characterized by intricate decision-making processes, often relying on nuanced intuition and consultation. Recent advancements in deep learning have started to revolutionize software engineering practices through elaborate designs implemented at various stages of software development. In this paper, we present an innovative paradigm that leverages large language models (LLMs) throughout the entire software development process, streamlining and unifying key processes through natural language communication, thereby eliminating the need for specialized models at each phase. At the core of this paradigm lies ChatDev, a virtual chat-powered software development company that mirrors the established waterfall model, meticulously dividing the development process into four distinct chronological stages: designing, coding, testing, and documenting. Each stage engages a team of agents, such as programmers, code reviewers, and test engineers, fostering collaborativ
    
[^41]: AspectCSE: 使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入

    AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])

    [http://arxiv.org/abs/2307.07851](http://arxiv.org/abs/2307.07851)

    AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。

    

    通用的句子嵌入提供了对语义文本相似性的粗略近似，但忽略了使文本相似的特定方面。相反，基于方面的句子嵌入提供了基于预定义方面的文本相似性。因此，文本的相似性预测更加针对特定要求，并且更容易解释。在本文中，我们提出了AspectCSE，一种用于基于方面的对比学习句子嵌入的方法。结果表明，与之前最好的结果相比，AspectCSE在多个方面的信息检索任务中实现了平均改善3.97%。我们还提出使用Wikidata知识图属性来训练多方面句子嵌入模型，其中在相似性预测过程中同时考虑多个特定方面。我们证明了多方面嵌入在特定方面信息检索任务上优于单方面嵌入。最后，我们展示了嵌入模型的可解释性，并提出通过对比学习来改进嵌入质量。

    Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
    
[^42]: 对大型语言模型评估的调查

    A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])

    [http://arxiv.org/abs/2307.03109](http://arxiv.org/abs/2307.03109)

    本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。

    

    大型语言模型（LLMs）由于在各种应用中表现出的前所未有的性能而在学术界和工业界越来越受欢迎。随着LLMs在研究和日常使用中继续发挥着重要作用，它们的评估变得越来越关键，不仅在任务水平上，而且在社会层面上，以更好地了解它们的潜在风险。在过去的几年里，已经做出了相当大的努力来从不同的角度来研究LLMs。本文综述了LLMs的这些评估方法，重点关注三个关键维度：评估什么、在哪里评估以及如何评估。首先，我们从评估任务的角度提供了一个概述，涵盖了一般的自然语言处理任务、推理、医学应用、伦理学、教育、自然科学和社会科学、代理应用和其他领域。其次，我们通过深入探讨评估方法和基准答案来回答“在哪里”和“如何”这两个问题。

    Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
    
[^43]: 使用适配器高效域自适应句子嵌入

    Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v1 [cs.CL])

    [http://arxiv.org/abs/2307.03104](http://arxiv.org/abs/2307.03104)

    本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。

    

    句子嵌入使我们能够捕捉短文本的语义相似性。大多数句子嵌入模型是针对一般语义文本相似性（STS）任务进行训练的。因此，要在特定领域中使用句子嵌入，必须将模型适应于该领域以获得良好的结果。通常，这是通过对感兴趣的域对整个句子嵌入模型进行微调来实现的。虽然这种方法能够产生最先进的结果，但在微调过程中更新了所有模型的权重，使该方法在资源上要求较高。因此，我们提出了训练轻量级适配器的方法，而不是单独为每个目标领域微调整个句子嵌入模型。这些特定领域的适配器不需要微调所有底层句子嵌入模型的参数。相反，我们只训练少量的额外参数，同时保持底层句子嵌入模型的权重不变。训练特定领域的适配器可以始终使用同一模型并在不同领域中获得良好的性能。

    Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always 
    
[^44]: 在在线社区中探索语言风格匹配：社会背景和对话动态的作用

    Exploring Linguistic Style Matching in Online Communities: The Role of Social Context and Conversation Dynamics. (arXiv:2307.02758v1 [cs.CL])

    [http://arxiv.org/abs/2307.02758](http://arxiv.org/abs/2307.02758)

    本研究在Reddit上分析了两方对话主题的大量语料库，研究了LSM在对话中的差异以及与社区指标的关系，揭示了理解社区动态时对话参与的重要性。

    

    在对话中的语言风格匹配可以反映出社会影响的多个方面，如权力或说服力。然而，在类似Reddit等平台上，LSM与在线沟通结果的关系尚不清楚。在这项研究中，我们分析了Reddit中两方对话主题的大量语料库，并使用两种类型的风格：功能词的使用和形式化。使用这个框架，我们研究了不同社交因素在Reddit对话中LSM水平的差异：帖子和子社区特征、对话深度、用户资历和评论的争议性。最后，我们测量了社区禁令后失去地位后LSM的变化。我们的发现揭示了LSM在Reddit对话中与几个社区指标的相互作用，暗示了在了解社区动态时理解对话参与的重要性。

    Linguistic style matching (LSM) in conversations can be reflective of several aspects of social influence such as power or persuasion. However, how LSM relates to the outcomes of online communication on platforms such as Reddit is an unknown question. In this study, we analyze a large corpus of two-party conversation threads in Reddit where we identify all occurrences of LSM using two types of style: the use of function words and formality. Using this framework, we examine how levels of LSM differ in conversations depending on several social factors within Reddit: post and subreddit features, conversation depth, user tenure, and the controversiality of a comment. Finally, we measure the change of LSM following loss of status after community banning. Our findings reveal the interplay of LSM in Reddit conversations with several community metrics, suggesting the importance of understanding conversation engagement when understanding community dynamics.
    
[^45]: 使用Transformer模型预测表情符号

    Emoji Prediction using Transformer Models. (arXiv:2307.02054v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.02054](http://arxiv.org/abs/2307.02054)

    使用基于Transformer的方法，在大型语料库上微调BERT模型以预测给定文本的表情符号。实验结果显示，该方法在预测准确率上优于其他最先进的模型，具有潜在的自然语言处理和社交媒体营销应用价值。

    

    近年来，社交媒体中使用表情符号的频率大幅增加，使得它们成为了理解在线沟通的重要元素。然而，由于其含糊的特性，预测给定文本中表情符号的含义是一项具有挑战性的任务。在本研究中，我们提出了一种基于Transformer的方法来使用BERT进行表情符号预测，BERT是一种广泛使用的预训练语言模型。我们在一个包含文本和表情符号的大型语料库上对BERT进行微调，以预测给定文本的最合适的表情符号。我们的实验结果表明，我们的方法在预测表情符号方面的准确率超过了75％，优于几种最先进的模型。该研究在自然语言处理、情感分析和社交媒体营销方面具有潜在的应用前景。

    In recent years, the use of emojis in social media has increased dramatically, making them an important element in understanding online communication. However, predicting the meaning of emojis in a given text is a challenging task due to their ambiguous nature. In this study, we propose a transformer-based approach for emoji prediction using BERT, a widely-used pre-trained language model. We fine-tuned BERT on a large corpus of text containing both text and emojis to predict the most appropriate emoji for a given text. Our experimental results demonstrate that our approach outperforms several state-of-the-art models in predicting emojis with an accuracy of over 75 percent. This work has potential applications in natural language processing, sentiment analysis, and social media marketing.
    
[^46]: 大型语言模型被误导：使用Only Connect Wall数据集探索创造性问题解决和Einstellung效应。

    Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset. (arXiv:2306.11167v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.11167](http://arxiv.org/abs/2306.11167)

    这项研究探索了大型语言模型（LLMs）对创造性问题解决的能力，并发现大型语言模型容易被误导，出现固定效应和Einstellung范式。

    

    自从人工智能诞生以来，对人类仿真智能的追求一直是人工智能研究的持久话题。最新一代的大型语言模型（LLM）的技术演进和新兴能力将这个主题从学术界带到了文化时代。尽管最近的NLP评估基准任务测试了人类仿真行为的一些方面（例如BIG-bench的“类人行为”任务），但几乎没有一个任务考察创造性问题解决能力。人类的创造性问题解决是认知神经科学中研究较为深入的主题，标准化测试主要使用将线索词之间的（异构）连接能力作为创造性的度量。在这样的任务中，暗示性的误导性刺激-被称为“诱导误解”的干扰因素-通过固定效应和Einstellung范式阻碍了人类的表现。在认知神经科学的研究中，通过事先让参与者接触到有相似拼写的错误因素来实验性地诱导这样的固定。

    The quest for human imitative AI has been an enduring topic in AI research since its inception. The technical evolution and emerging capabilities of the latest cohort of large language models (LLMs) have reinvigorated the subject beyond academia to the cultural zeitgeist. While recent NLP evaluation benchmark tasks test some aspects of human-imitative behaviour (e.g., BIG-bench's 'human-like behavior' tasks), few, if not none, examine creative problem solving abilities. Creative problem solving in humans is a well-studied topic in cognitive neuroscience with standardized tests that predominantly use the ability to associate (heterogeneous) connections among clue words as a metric for creativity. Exposure to misleading stimuli - distractors dubbed red herrings - impede human performance in such tasks via the fixation effect and Einstellung paradigm. In cognitive neuroscience studies, such fixations are experimentally induced by pre-exposing participants to orthographically similar incor
    
[^47]: RestGPT：将大型语言模型与现实世界的RESTful API连接起来

    RestGPT: Connecting Large Language Models with Real-World RESTful APIs. (arXiv:2306.06624v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.06624](http://arxiv.org/abs/2306.06624)

    RestGPT通过连接大型语言模型与RESTful API，提出了RestGPT以解决现实世界场景中的复杂指令问题，并提供了相应的API执行器。

    

    工具增强的大型语言模型在解决广泛任务方面取得了显著进展。然而，现有方法主要局限于特定设计的工具，无法满足复杂指令，在面对现实世界场景时存在很大的限制。本文通过将大型语言模型与符合广泛采用的REST软件架构风格的RESTful API连接起来，探索了更加真实的场景。为了解决处理复杂指令的实际挑战，我们提出了RestGPT，利用大型语言模型的能力并采用粗到精的在线规划机制，以增强任务分解和API选择的能力。RestGPT还包括一个专门用于调用RESTful API的API执行器，可以精确地制定参数和解析API响应。为了全面评估RestGPT的性能，我们提出了RestBench，这是一个由两个现实世界场景组成的高质量基准测试集。

    Tool-augmented large language models (LLMs) have achieved remarkable progress in tackling a broad range of tasks. However, existing methods are mainly restricted to specifically designed tools and fail to fulfill complex instructions, having great limitations when confronted with real-world scenarios. In this paper, we explore a more realistic scenario by connecting LLMs with RESTful APIs, which adhere to the widely adopted REST software architectural style for web service development. To address the practical challenges of tackling complex instructions, we propose RestGPT, which exploits the power of LLMs and conducts a coarse-to-fine online planning mechanism to enhance the abilities of task decomposition and API selection. RestGPT also contains an API executor tailored for calling RESTful APIs, which can meticulously formulate parameters and parse API responses. To fully evaluate the performance of RestGPT, we propose RestBench, a high-quality benchmark which consists of two real-wo
    
[^48]: 医疗知识图谱综述：资源、应用和前景

    A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v1 [cs.AI])

    [http://arxiv.org/abs/2306.04802](http://arxiv.org/abs/2306.04802)

    本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。

    

    医疗知识图谱(HKGs)已成为组织医学知识的有结构且可解释的有为工具，提供了医学概念及其关系的全面视图。然而，数据异质性和覆盖范围有限等挑战仍然存在，强调了在HKG领域需要进一步研究的必要性。本综述是HKG的第一份综合概述。我们总结了HKG构建的流程和关键技术（即从头开始和通过集成），以及常见的利用方法（即基于模型和非基于模型）。为了为研究人员提供有价值的资源，我们根据它们捕获的数据类型和应用领域（该资源存储于https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase）组织了现有的HKG，并提供了相关的统计信息。在应用部分，我们深入探讨了HKG在各种医疗领域的变革性影响。

    Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various hea
    
[^49]: 超越一个模型适用于所有领域：大型语言模型的领域专门化综述

    Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models. (arXiv:2305.18703v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18703](http://arxiv.org/abs/2305.18703)

    本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    

    大型语言模型（LLM）已经大大推动了自然语言处理（NLP）领域的发展，为广泛应用提供了高度实用、任务无关的基础。LLMs 作为通用任务求解器的巨大潜力，促使人们将其用于特定领域，如医疗保健、金融和教育，并将其用作助手甚至替代特定领域的专家和工具。但是，将LLMs直接应用于特定领域中的复杂问题会遇到许多困难，包括领域数据的异质性、领域知识的复杂性、领域目标的独特性以及约束的多样性。为了填补这种差距，最近几年进行了急剧增加的研究和实践致力于大型语言模型的领域专门化，然而这方面的研究尚未被系统地总结。在这篇综述中，我们对LLMs的领域专门化进行了全面概述，包括动机、挑战、方法论和评估指标。此外，我们提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. The great promise of LLMs as general task solvers motivated people to extend their functionality largely beyond just a ``chatbot'', and use it as an assistant or even replacement for domain experts and tools in specific domains such as healthcare, finance, and education. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). To fill such a gap, explosively-increase research, and practices have been conducted in very recent years on the domain specialization of LLMs, which, howe
    
[^50]: 政治殉道对选举结果的影响：阿贝遇刺事件的研究

    The Effects of Political Martyrdom on Election Results: The Assassination of Abe. (arXiv:2305.18004v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18004](http://arxiv.org/abs/2305.18004)

    这项研究通过分析推特数据研究了日本前首相阿贝的暗杀事件对2022年日本参议院选举的影响。研究发现，暗杀事件短期内对推特情绪产生了负面影响，并且社交媒体的关注时间也变得更短。此外，研究还发现阿贝之死对选举结果产生了影响，但需要进一步调查以得出确切结论。

    

    在发达国家，暗杀行为很少，因此对此类行为对选举和政治格局的影响知之甚少。本研究利用推特数据，研究日本前首相阿贝的暗杀事件对2022年日本参议院选举的影响。我们对200万条推文进行情感分析、情绪检测和主题建模，并与前几次选举周期的推文进行比较。研究结果表明，暗杀事件短期内对推特情绪产生了负面影响，同时社交媒体的关注时间也变得更短。我们还讨论了“死亡政治”如何影响选举结果，表明阿贝之死似乎对选举结果产生了影响，但研究结果还需要进一步调查以得出确切结论。

    In developed nations assassinations are rare and thus the impact of such acts on the electoral and political landscape is understudied. In this paper, we focus on Twitter data to examine the effects of Japan's former Primer Minister Abe's assassination on the Japanese House of Councillors elections in 2022. We utilize sentiment analysis and emotion detection together with topic modeling on over 2 million tweets and compare them against tweets during previous election cycles. Our findings indicate that Twitter sentiments were negatively impacted by the event in the short term and that social media attention span has shortened. We also discuss how "necropolitics" affected the outcome of the elections in favor of the deceased's party meaning that there seems to have been an effect of Abe's death on the election outcome though the findings warrant further investigation for conclusive results.
    
[^51]: 评估开放式问答评估

    Evaluating Open-QA Evaluation. (arXiv:2305.12421v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12421](http://arxiv.org/abs/2305.12421)

    本研究侧重于评估开放式问答（Open-QA）任务的方法，引入了一个新的任务QA-Eval和数据集EVOUNA，通过人工评估方法来评估AI生成的答案的准确性。我们调查了与人工评估相关的方法，并讨论了当前方法的缺陷和改进方法。我们相信这对于未来的自动评估工具发展和研究具有价值。

    

    本研究侧重于对开放式问答（Open-QA）任务的评估，该任务可以直接估计大型语言模型（LLMs）的事实性。目前的自动评估方法已显示出一定的局限性，表明人工评估仍然是最可靠的方法。我们引入了一个新的任务，即评估QA评估（QA-Eval）以及相应的数据集EVOUNA，旨在评估AI生成的答案与Open-QA中的标准答案之间的准确性。我们利用人工标注的结果来评估这些方法的性能。具体而言，本研究调查了那些与人工评估具有高度相关性的方法，认为它们更可靠。我们还讨论了当前方法的缺陷以及改进基于LLM的评估器的方法。我们相信，这个新的QA-Eval任务和相应的数据集EVOUNA将促进更有效的自动评估工具的开发，并对未来的研究具有价值。

    This study focuses on the evaluation of the Open Question Answering (Open-QA) task, which can directly estimate the factuality of large language models (LLMs). Current automatic evaluation methods have shown limitations, indicating that human evaluation still remains the most reliable approach. We introduce a new task, Evaluating QA Evaluation (QA-Eval) and the corresponding dataset EVOUNA, designed to assess the accuracy of AI-generated answers in relation to standard answers within Open-QA. Our evaluation of these methods utilizes human-annotated results to measure their performance. Specifically, the work investigates methods that show high correlation with human evaluations, deeming them more reliable. We also discuss the pitfalls of current methods and methods to improve LLM-based evaluators. We believe this new QA-Eval task and corresponding dataset EVOUNA will facilitate the development of more effective automatic evaluation tools and prove valuable for future research in this a
    
[^52]: 利用跨模态适配器向预训练语言模型注入多功能高效的视觉知识

    Towards Versatile and Efficient Visual Knowledge Injection into Pre-trained Language Models with Cross-Modal Adapters. (arXiv:2305.07358v1 [cs.CL])

    [http://arxiv.org/abs/2305.07358](http://arxiv.org/abs/2305.07358)

    本文提出了X-adapter插拔式模块，利用多模态视觉语言模型，高效地向预训练语言模型注入视觉知识。

    

    人类通过多模态知识学习语言，然而现有的大多数预训练语言模型（PLMs）仅支持文本预训练。本文提出了插拔式模块X-adapter，它能够根据多模态视觉语言模型（VLMs）的对齐视觉和文本知识，灵活高效地向PLMs注入视觉知识。 X-adapter包含两个子模块V-expert和T-expert，可以根据下游任务激活不同的子模块，来融合VLMs的图像和文本表示。

    Humans learn language via multi-modal knowledge. However, due to the text-only pre-training scheme, most existing pre-trained language models (PLMs) are hindered from the multi-modal information.  To inject visual knowledge into PLMs, existing methods incorporate either the text or image encoder of vision-language models (VLMs) to encode the visual information and update all the original parameters of PLMs for knowledge fusion.  In this paper, we propose a new plug-and-play module, X-adapter, to flexibly leverage the aligned visual and textual knowledge learned in pre-trained VLMs and efficiently inject them into PLMs.  Specifically, we insert X-adapters into PLMs, and only the added parameters are updated during adaptation.  To fully exploit the potential in VLMs, X-adapters consist of two sub-modules, V-expert and T-expert, to fuse VLMs' image and text representations, respectively.  We can opt for activating different sub-modules depending on the downstream tasks.  Experimental resu
    
[^53]: 区域感知预训练：视觉变压器下的开放词汇物体检测

    Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers. (arXiv:2305.07011v1 [cs.CV])

    [http://arxiv.org/abs/2305.07011](http://arxiv.org/abs/2305.07011)

    本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。

    

    本文提出了区域感知开放词汇视觉变压器（RO-ViT），一种对比图像-文本预训练方法，旨在填补图像级预训练和开放词汇物体检测之间的差距。在预训练阶段，我们建议随机裁剪并调整位置嵌入的区域，而不是使用整个图像位置嵌入。这更好地匹配了检测微调阶段中区域级别上使用位置嵌入的方式。此外，我们用聚焦损失替换了对比学习中常用的softmax交叉熵损失，以更好地学习那些有信息量但难以捕捉的例子。最后，我们利用了最近在新颖物体提案方面的进展，以改进开放词汇检测的微调。我们在LVIS和COCO开放词汇检测基准上评估了完整模型和零-shot转移性能。RO-ViT在LVIS上实现了32.1$AP_r$的最佳效果，超过现有最佳方法5.8个百分点，同时还具有竞争性的零-shot转移检测结果。

    We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a contrastive image-text pretraining recipe to bridge the gap between image-level pretraining and open-vocabulary object detection. At the pretraining phase, we propose to randomly crop and resize regions of positional embeddings instead of using the whole image positional embeddings. This better matches the use of positional embeddings at region-level in the detection finetuning phase. In addition, we replace the common softmax cross entropy loss in contrastive learning with focal loss to better learn the informative yet difficult examples. Finally, we leverage recent advances in novel object proposals to improve open-vocabulary detection finetuning. We evaluate our full model on the LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer. RO-ViT achieves a state-of-the-art 32.1 $AP_r$ on LVIS, surpassing the best existing approach by +5.8 points in addition to competitive zero-shot transfer detec
    
[^54]: PGTask：介绍从对话中生成档案的任务

    PGTask: Introducing the Task of Profile Generation from Dialogues. (arXiv:2304.06634v1 [cs.CL])

    [http://arxiv.org/abs/2304.06634](http://arxiv.org/abs/2304.06634)

    对话系统的个性化需要个人资料信息，而从对话中提取/生成个人资料信息是一项基本需求。为此，我们提出了档案生成任务（PGTask）并提供了相关的数据集和基准，该任务使得研究者可以更好地了解档案生成任务的挑战和可能的解决方案。

    

    最近的研究尝试通过将个人资料信息融入模型来个性化对话系统。然而，这种知识信息稀少且难以获取，这使得从对话中提取/生成个人资料信息成为一项基本需求。为了克服这一限制，我们引入了档案生成任务（PGTask）。我们为此问题提供了一个新的数据集，其中包括与相关话语对齐的档案句子，从对话语料库中提取。此外，利用最先进的方法，我们为这个新数据集提供了一个档案生成的基准。我们的实验揭示了档案生成的挑战，并希望这引入了一个新的研究方向。

    Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.
    
[^55]: 人类合作是否增强了识别LLM生成的深度伪造文本的准确性？

    Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?. (arXiv:2304.01002v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.01002](http://arxiv.org/abs/2304.01002)

    这项研究研究了人类合作是否增强了识别LLM生成的深度伪造文本的准确性。结果表明，合作可以潜在地提高两组人对深度伪造文本的检测准确性。

    

    大型语言模型（如GPT-4、LLaMA）的进展改善了大规模生成类似人类写作的连贯句子，从而产生了所谓的深度伪造文本。然而，这一进展引发了安全和隐私的担忧，需要有效解决方案来区分深度伪造文本和人类书写文本。尽管以前的研究探讨了人类检测深度伪造文本的能力，但没有研究“合作”是否能提高深度伪造文本的检测。在本研究中，为了填补对深度伪造文本理解的空白，我们对两组人进行了实验：（1）来自AMT平台的非专家群体和（2）来自Upwork平台的写作专家。结果表明，人类之间的合作可能会提高两组对深度伪造文本的检测准确性，非专家组的检测准确性提高了6.36%，专家组的检测准确性提高了12.76%。

    Advances in Large Language Models (e.g., GPT-4, LLaMA) have improved the generation of coherent sentences resembling human writing on a large scale, resulting in the creation of so-called deepfake texts. However, this progress poses security and privacy concerns, necessitating effective solutions for distinguishing deepfake texts from human-written ones. Although prior works studied humans' ability to detect deepfake texts, none has examined whether "collaboration" among humans improves the detection of deepfake texts. In this study, to address this gap of understanding on deepfake texts, we conducted experiments with two groups: (1) nonexpert individuals from the AMT platform and (2) writing experts from the Upwork platform. The results demonstrate that collaboration among humans can potentially improve the detection of deepfake texts for both groups, increasing detection accuracies by 6.36% for non-experts and 12.76% for experts, respectively, compared to individuals' detection accur
    
[^56]: 通过盲审评估和文本分类算法比较ChatGPT生成的抽象摘要和真实摘要

    Comparing Abstractive Summaries Generated by ChatGPT to Real Summaries Through Blinded Reviewers and Text Classification Algorithms. (arXiv:2303.17650v1 [cs.CL])

    [http://arxiv.org/abs/2303.17650](http://arxiv.org/abs/2303.17650)

    本研究评估了ChatGPT在抽象概括方面的表现，自动化指标和盲审人员评估显示ChatGPT生成的摘要在人类视角下难以分辨真假。

    

    大型语言模型（LLMs）因其在各种任务上的出色表现而受到广泛关注。OpenAI开发的ChatGPT是语言模型家族的最新成员，由于其类人的文本生成能力，被一些人称为一项颠覆性技术。尽管网络上有许多ChatGPT的例子来评估其强弱之处，但只有少数系统性的研究存在。为了为ChatGPT的系统性研究做出贡献，我们通过自动化指标和盲审人员评估了ChatGPT在抽象概括方面的表现。我们还构建了自动文本分类器来检测ChatGPT生成的摘要。我们发现，虽然文本分类算法可以区分真实和生成的摘要，但人类无法区分真实摘要和ChatGPT生成的摘要。

    Large Language Models (LLMs) have gathered significant attention due to their impressive performance on a variety of tasks. ChatGPT, developed by OpenAI, is a recent addition to the family of language models and is being called a disruptive technology by a few, owing to its human-like text-generation capabilities. Although, many anecdotal examples across the internet have evaluated ChatGPT's strength and weakness, only a few systematic research studies exist. To contribute to the body of literature of systematic research on ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization by the means of automated metrics and blinded human reviewers. We also build automatic text classifiers to detect ChatGPT generated summaries. We found that while text classification algorithms can distinguish between real and generated summaries, humans are unable to distinguish between real summaries and those produced by ChatGPT.
    
[^57]: 语言模型行为：一项全面调查

    Language Model Behavior: A Comprehensive Survey. (arXiv:2303.11504v1 [cs.CL])

    [http://arxiv.org/abs/2303.11504](http://arxiv.org/abs/2303.11504)

    该论文总结了250多个关于英文语言模型行为的最近研究，发现大型语言模型具有基本的句法、语义、语用、世界知识和推理能力，但容易出现不实回答、常识错误、记忆化文本和社会偏见等弱点。

    

    Transformer 语言模型已经受到了广泛的关注，然而它们生成的文本即使对于自然语言处理研究人员来说也常常令人惊讶。在本次调查中，我们讨论了250多个关于英语语言模型行为的最近研究，这些研究在任务特定的微调之前进行。语言模型具有基本的句法、语义、语用、世界知识和推理能力，但这些能力对特定的输入和表面特征很敏感。尽管模型随着参数量的增加而生成的文本质量显著提高，但它们仍然容易出现不实回答、常识错误、记忆化文本和社会偏见。其中许多弱点可以被描述为对文本中所学模式的过度推广或过度泛化。我们综合了最近的结果，突出了目前已知的大型语言模型能够做什么和不能做什么。

    Transformer language models have received widespread public attention, yet their generated text is often surprising even to NLP researchers. In this survey, we discuss over 250 recent studies of English language model behavior before task-specific fine-tuning. Language models possess basic capabilities in syntax, semantics, pragmatics, world knowledge, and reasoning, but these capabilities are sensitive to specific inputs and surface features. Despite dramatic increases in generated text quality as models scale to hundreds of billions of parameters, the models are still prone to unfactual responses, commonsense errors, memorized text, and social biases. Many of these weaknesses can be framed as over-generalizations or under-generalizations of learned patterns in text. We synthesize recent results to highlight what is currently known about what large language models can and cannot do.
    
[^58]: EmotionIC：基于情感惯性和感染的依赖建模可用于对话中的情感识别

    EmotionIC: Emotional Inertia and Contagion-driven Dependency Modelling for Emotion Recognition in Conversation. (arXiv:2303.11117v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.11117](http://arxiv.org/abs/2303.11117)

    本文提出了一种新的依赖性建模方法，由情感惯性和感染驱动（EmotionIC），用于在特征提取和分类级别上进行会话情感识别。设计了多项具体方法，包括身份掩码多头注意（IM-MHA）和基于对话门控循环单元(DialogGRU)，以抓取上下文信息，提高模型的性能。

    

    最近，随着人机界面技术的进步和实施，对话中的情感识别（ERC）吸引了越来越多的关注。然而，以往的建模方法在全局和局部上下文依赖方面丢失了依赖信息的多样性，并且在分类级别不考虑上下文依赖关系。本文提出了一种新的依赖性建模方法，由情感惯性和感染驱动（EmotionIC），用于在特征提取和分类级别上进行会话情感识别。在特征提取级别，我们设计的身份掩码多头注意（IM-MHA）捕捉对话中基于身份的长距离上下文，以包含不同参与者的不同影响构建全局情感氛围，而设计的基于对话门控循环单元(DialogGRU)则聚合了二元对话的情感倾向，并应用于分类过程。

    Emotion Recognition in Conversation (ERC) has attracted growing attention in recent years as a result of the advancement and implementation of human-computer interface technologies. However, previous approaches to modeling global and local context dependencies lost the diversity of dependency information and do not take the context dependency into account at the classification level. In this paper, we propose a novel approach to dependency modeling driven by Emotional Inertia and Contagion (EmotionIC) for conversational emotion recognition at the feature extraction and classification levels. At the feature extraction level, our designed Identity Masked Multi-head Attention (IM-MHA) captures the identity-based long-distant context in the dialogue to contain the diverse influence of different participants and construct the global emotional atmosphere, while the devised Dialogue-based Gate Recurrent Unit (DialogGRU) that aggregates the emotional tendencies of dyadic dialogue is applied to
    
[^59]: 数据中心机器学习的重新标签法

    The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04391](http://arxiv.org/abs/2302.04391)

    本文提出了一种重新标签的方法来解决手动标记的数据中存在噪声的问题，并通过模型预测来辅助人类标记噪声数据。实验证明此方法适用于多类深度学习任务。

    

    在深度学习应用中，手动标记的数据在一定程度上存在噪声。为了解决这个问题，并在开发数据集上获得90分以上的成绩，本文提出了一种简单的方法来找出噪声数据，并通过采用模型预测作为人类标记的参考来重新标记噪声数据。本文阐述了我们在广泛的深度学习任务中的想法，包括分类、序列标记、物体检测、序列生成、点击率预测。实验结果和人类评估结果验证了我们的想法。

    In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.
    
[^60]: 通过隐形水印保护语言生成模型

    Protecting Language Generation Models via Invisible Watermarking. (arXiv:2302.03162v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.03162](http://arxiv.org/abs/2302.03162)

    本文提出了一种名为 GINSEW 的新方法，通过将秘密信号注入到每个目标标记的解码步骤的概率向量中，保护文本生成模型，有效识别出侵权行为，对模型的影响很小。

    

    语言生成模型是许多应用的有力支持者。许多这样的模型提供免费或经济实惠的 API 访问，这使它们可能受到模型抽取攻击的威胁。为了保护知识产权并确保这些模型的公正使用，已经提出了各种技术，例如词汇水印和同义词替换。然而，这些方法可能会被明显的对策如“同义词随机化”等所抵消。为了解决这个问题，我们提出了 GINSEW，一种新的方法，用于通过蒸馏保护文本生成模型。我们的方法的关键思想是将秘密信号注入到每个目标标记的解码步骤的概率向量中。然后，我们可以通过探测嫌疑的模型来检测秘密消息是否由受保护的模型蒸馏而来。实验结果表明，GINSEW 可以有效地识别出侵权行为，对生成模型的影响极小。

    Language generation models have been an increasingly powerful enabler for many applications. Many such models offer free or affordable API access, which makes them potentially vulnerable to model extraction attacks through distillation. To protect intellectual property (IP) and ensure fair use of these models, various techniques such as lexical watermarking and synonym replacement have been proposed. However, these methods can be nullified by obvious countermeasures such as "synonym randomization". To address this issue, we propose GINSEW, a novel method to protect text generation models from being stolen through distillation. The key idea of our method is to inject secret signals into the probability vector of the decoding steps for each target token. We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSEW can effectively identify instances of IP infringement with minimal impact on the ge
    
[^61]: 大型语言模型中的事件知识：不可能性和不太可能性之间的差距

    Event knowledge in large language models: the gap between the impossible and the unlikely. (arXiv:2212.01488v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01488](http://arxiv.org/abs/2212.01488)

    大型语言模型拥有丰富的事件知识，几乎总是将可能事件的描述比不可能事件的描述赋予更高的可能性。

    

    语言语料库中的词共现模式包含着意想不到的概念知识。通过训练大型语言模型(LLMs)来预测上下文中的词语，这些模型能够利用这些模式，在需要世界知识的各种语义任务上取得令人印象深刻的性能。关于LLMs的语义能力的重要但鲜为研究的问题是它们是否获得了常见事件的一般化知识。在这里，我们测试了五个预训练的LLMs（从2018年的BERT到2023年的MPT）是否比同一事件的不太可能的版本更可能地分配给合理的代理-患者相互作用。使用三个精心策划的最小句对集合（总数n=1,215），我们发现预训练的LLMs拥有相当大的事件知识，表现优于其他分布式语言模型。特别是，它们几乎总是将可能事件与不可能事件相比赋予更高的可能性（教师买了笔记本电脑相对于笔记本电脑买了教师）。

    Word co-occurrence patterns in language corpora contain a surprising amount of conceptual knowledge. Large language models (LLMs), trained to predict words in context, leverage these patterns to achieve impressive performance on diverse semantic tasks requiring world knowledge. An important but understudied question about LLMs' semantic abilities is whether they acquire generalized knowledge of common events. Here, we test whether five pre-trained LLMs (from 2018's BERT to 2023's MPT) assign higher likelihood to plausible descriptions of agent-patient interactions than to minimally different implausible versions of the same event. Using three curated sets of minimal sentence pairs (total n=1,215), we found that pre-trained LLMs possess substantial event knowledge, outperforming other distributional language models. In particular, they almost always assign higher likelihood to possible vs. impossible events (The teacher bought the laptop vs. The laptop bought the teacher). However, LLMs
    
[^62]: 多视角推理：一致的对比学习用于数学应用问题

    Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem. (arXiv:2210.11694v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.11694](http://arxiv.org/abs/2210.11694)

    该论文提出了一种使用多视角一致的对比学习来解决数学应用问题，通过同时考虑自上而下和自下而上的推理视角，以及多种等价的方程形式，实现了更完整的语义到方程的映射。实验证明该方法明显优于现有的基线。

    

    数学应用问题求解器需要对文本中的数量进行精确的关系推理和可靠的方程生成。当前的序列到树或关系抽取方法只从一个固定视角看待这个问题，很难同时处理复杂的语义和多样的方程。然而，人类解题自然地涉及两种一致的推理视角：自上而下和自下而上，就像数学方程也可以用多种等价形式表示：前序和后序。我们提出了一种多视角一致的对比学习，用于更完整的语义到方程的映射。整个过程被分解为两个独立但一致的视角：自上而下的分解和自下而上的构建，并且两种推理视角在多粒度上对齐以保持一致性，增强全局生成和精确推理。在两种语言的多个数据集上的实验证明我们的方法明显优于现有的基线。

    Math word problem solver requires both precise relation reasoning about quantities in the text and reliable generation for the diverse equation. Current sequence-to-tree or relation extraction methods regard this only from a fixed view, struggling to simultaneously handle complex semantics and diverse equations. However, human solving naturally involves two consistent reasoning views: top-down and bottom-up, just as math equations also can be expressed in multiple equivalent forms: pre-order and post-order. We propose a multi-view consistent contrastive learning for a more complete semantics-to-equation mapping. The entire process is decoupled into two independent but consistent views: top-down decomposition and bottom-up construction, and the two reasoning views are aligned in multi-granularity for consistency, enhancing global generation and precise reasoning. Experiments on multiple datasets across two languages show our approach significantly outperforms the existing baselines, esp
    
[^63]: TwHIN-BERT：一种用于Twitter多语言推特表示的社交增强预训练语言模型

    TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations at Twitter. (arXiv:2209.07562v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.07562](http://arxiv.org/abs/2209.07562)

    TwHIN-BERT是一个在Twitter上训练的多语言语言模型，通过结合基于文本的自监督和基于丰富社交参与对象的社交目标训练，能够有效地表示短、嘈杂的用户生成文本。在各种多语言社交推荐和语义理解任务中，TwHIN-BERT展示了显著的指标提升。

    

    预训练语言模型（PLMs）对于自然语言处理应用至关重要。现有的大多数PLMs并不针对社交媒体上的嘈杂用户生成文本进行优化，并且预训练过程中没有考虑社交网络中可用的有价值的社交参与日志。我们介绍了TwHIN-BERT，这是一种在Twitter上生产化的多语言语言模型，训练数据来自流行的社交网络。与先前的预训练语言模型不同，TwHIN-BERT不仅通过基于文本的自监督进行训练，还利用Twitter异构信息网络（TwHIN）中丰富的社交参与对象进行社交目标训练。我们的模型训练数据涵盖了超过100种不同语言的70亿条推文，为建模短、嘈杂、用户生成的文本提供了有价值的表示。我们在各种多语言社交推荐和语义理解任务上评估了我们的模型，并展示了与已建立模型相比的显著指标改进。

    Pre-trained language models (PLMs) are fundamental for natural language processing applications. Most existing PLMs are not tailored to the noisy user-generated text on social media, and the pre-training does not factor in the valuable social engagement logs available in a social network. We present TwHIN-BERT, a multilingual language model productionized at Twitter, trained on in-domain data from the popular social network. TwHIN-BERT differs from prior pre-trained language models as it is trained with not only text-based self-supervision, but also with a social objective based on the rich social engagements within a Twitter heterogeneous information network (TwHIN). Our model is trained on 7 billion tweets covering over 100 distinct languages, providing a valuable representation to model short, noisy, user-generated text. We evaluate our model on various multilingual social recommendation and semantic understanding tasks and demonstrate significant metric improvement over established
    
[^64]: 鲁棒性持续多语言学习的参数高效微调

    Parameter-Efficient Finetuning for Robust Continual Multilingual Learning. (arXiv:2209.06767v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.06767](http://arxiv.org/abs/2209.06767)

    提出了一种参数高效微调策略LAFT-URIEL，用于鲁棒性持续多语言学习，通过利用语言知识平衡过拟合和知识共享，使模型在更新后在更多语种上表现出改进，同时减小了剩余语种的性能损失。

    

    我们介绍并研究了鲁棒性持续多语言学习（CML）的问题，即周期性使用新到达的数据对先前训练的多语言模型进行更新。如果新数据仅存在于语种的子集中，我们发现所得到的模型仅在最新更新中包括的语种（和一些紧密相关的语种）上表现出改进，而其在所有剩余语种上的性能则显著下降。我们通过提出LAFT-URIEL来解决这个挑战，这是一种参数高效的微调策略，旨在增加模型更新后在语种上的性能改进数量，同时减少剩余语种性能下降的程度。LAFT-URIEL利用语言知识在语种之间实现过拟合和知识共享的平衡，使得额外的25%任务语种在更新后看到性能改进，同时减小了剩余语种的平均性能损失。

    We introduce and study the problem of Continual Multilingual Learning (CML) where a previously trained multilingual model is periodically updated using new data arriving in stages. If the new data is present only in a subset of languages, we find that the resulting model shows improved performance only on the languages included in the latest update (and a few closely related languages) while its performance on all the remaining languages degrade significantly. We address this challenge by proposing LAFT-URIEL, a parameter-efficient finetuning strategy which aims to increase the number of languages on which the model improves after an update, while reducing the magnitude of loss in performance for the remaining languages. LAFT-URIEL uses linguistic knowledge to balance overfitting and knowledge sharing across languages, allowing for an additional 25% of task languages to see an improvement in performance after an update, while also reducing the average magnitude of losses on the remaini
    
[^65]: 自然对话中解释机器学习模型：走向对话式XAI代理

    Explaining Machine Learning Models in Natural Conversations: Towards a Conversational XAI Agent. (arXiv:2209.02552v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.02552](http://arxiv.org/abs/2209.02552)

    本研究将解释人工智能（XAI）融入到一个对话代理中，设计具有自然语言理解和生成组件的标准模型。通过扩展XAI问题库并提供解释方法，实现了关于机器学习模型的真正自然对话。

    

    可解释人工智能（XAI）的目标是设计方法来揭示黑盒模型（如深度神经网络）的推理过程，以便向人类解释。社会科学研究指出，这样的解释应该是对话式的，类似于人与人之间的解释。在这项工作中，我们展示了如何将XAI融入到一个对话代理中，使用了一个包括自然语言理解和生成组件的标准设计。我们根据质控的释义重述扩展了一个XAI问题库，以理解用户的信息需求。我们进一步系统地调查了适合提供答案信息的解释方法的文献，并提出了一个全面的建议列表。我们的工作是实现关于机器学习模型的真正自然对话的第一步，与一个解释代理有关的全面的XAI问题列表和相应的解释方法。

    The goal of Explainable AI (XAI) is to design methods to provide insights into the reasoning process of black-box models, such as deep neural networks, in order to explain them to humans. Social science research states that such explanations should be conversational, similar to human-to-human explanations. In this work, we show how to incorporate XAI in a conversational agent, using a standard design for the agent comprising natural language understanding and generation components. We build upon an XAI question bank which we extend by quality-controlled paraphrases to understand the user's information needs. We further systematically survey the literature for suitable explanation methods that provide the information to answer those questions, and present a comprehensive list of suggestions. Our work is the first step towards truly natural conversations about machine learning models with an explanation agent. The comprehensive list of XAI questions and the corresponding explanation meth
    
[^66]: 用于基于穿梭式离子阱量子计算机的量子电路编译器

    Quantum Circuit Compiler for a Shuttling-Based Trapped-Ion Quantum Computer. (arXiv:2207.01964v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2207.01964](http://arxiv.org/abs/2207.01964)

    本文介绍了一个针对穿梭式离子阱量子处理器的量子电路编译器，能够将量子电路转换和优化为特定的本地门序列，与标准编译方法相比，可以将门计数减少到5.1倍。

    

    随着量子计算硬件能力的增强和实现深度量子电路的挑战，需要完全自动化和高效的工具来编译量子电路。为了在特定于量子计算机架构的本地门序列中表示任意电路，需要使算法在量子硬件供应商的范围内可移植。本研究提出了一种编译器，可以将量子电路转换和优化为针对穿梭式离子阱量子处理器的目标电路。它由基于量子电路框架Pytket的定制算法组成。对广泛的量子电路进行了性能评估，结果表明，与标准Pytket相比，门计数可以减少多达5.1倍，与标准Qiskit编译相比可以减少多达2.2倍。

    The increasing capabilities of quantum computing hardware and the challenge of realizing deep quantum circuits require fully automated and efficient tools for compiling quantum circuits. To express arbitrary circuits in a sequence of native gates specific to the quantum computer architecture, it is necessary to make algorithms portable across the landscape of quantum hardware providers. In this work, we present a compiler capable of transforming and optimizing a quantum circuit targeting a shuttling-based trapped-ion quantum processor. It consists of custom algorithms set on top of the quantum circuit framework Pytket. The performance was evaluated for a wide range of quantum circuits and the results show that the gate counts can be reduced by factors up to 5.1 compared to standard Pytket and up to 2.2 compared to standard Qiskit compilation.
    
[^67]: 让一阶线性逻辑成为生成语法

    Making first order linear logic a generating grammar. (arXiv:2206.08955v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.08955](http://arxiv.org/abs/2206.08955)

    本文研究了一阶线性逻辑与扩展张量类型演算的关系，提出了一种固有的演绎系统。

    

    众所周知，不同的范畴语法在一阶乘法线性逻辑的一个片段中具有表面表示。 我们表明，该片段等价于最近引入的扩展张量类型演算。 这不仅为前者提供了一些替代的语法和直观的几何表示，而且还提供了一个固有的演绎系统，这是以前缺少的。

    It is known that different categorial grammars have surface representation in a fragment of first order multiplicative linear logic. We show that the fragment of interest is equivalent to the recently introduced {\it extended tensor type calculus}. This provides the former not only with some alternative syntax and intuitive geometric representation, but also with an intrinsic deductive system, which has been absent.
    
[^68]: 通过候选项重新排序增强神经对话模型中的自我披露

    Enhancing Self-Disclosure In Neural Dialog Models By Candidate Re-ranking. (arXiv:2109.05090v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2109.05090](http://arxiv.org/abs/2109.05090)

    本论文通过重新排序候选项来提高神经对话模型中的自我披露，从而解决了在神经对话模型中存在的回复逐渐变得琐碎的问题。

    

    神经语言建模在不同的下游自然语言处理（NLP）任务中取得了进步。其中一个领域是开放域对话建模，基于GPT-2的神经对话模型（例如DialoGPT）在单回合对话中表现出有希望的性能。然而，这种（神经）对话模型因为生成的回复虽然可能与前一个人的回应有相关性，但很快会使人失去兴趣并陷入琐碎的对话，因此受到了批评。造成这种性能的原因之一是在人机对话中缺乏明确的对话策略。人们在对话中使用各种对话策略，其中一个关键的社交策略是自我披露（SD），即向他人展示自己的信息。社会渗透理论（SPT）提出，两个人之间的交流会随着关系的进展从表面层次逐渐深入。

    Neural language modelling has progressed the state-of-the-art in different downstream Natural Language Processing (NLP) tasks. One such area is of open-domain dialog modelling, neural dialog models based on GPT-2 such as DialoGPT have shown promising performance in single-turn conversation. However, such (neural) dialog models have been criticized for generating responses which although may have relevance to the previous human response, tend to quickly dissipate human interest and descend into trivial conversation. One reason for such performance is the lack of explicit conversation strategy being employed in human-machine conversation. Humans employ a range of conversation strategies while engaging in a conversation, one such key social strategies is Self-disclosure(SD). A phenomenon of revealing information about one-self to others. Social penetration theory (SPT) proposes that communication between two people moves from shallow to deeper levels as the relationship progresses primari
    
[^69]: CoPaSul手册--基于轮廓的参数化和叠加韵律风格化

    CoPaSul Manual -- Contour-based parametric and superpositional intonation stylization. (arXiv:1612.04765v11 [cs.CL] UPDATED)

    [http://arxiv.org/abs/1612.04765](http://arxiv.org/abs/1612.04765)

    CoPaSul工具包提供了自动的韵律标注和特征提取功能，使用了基于轮廓的参数化和叠加韵律风格化的方法。通过该工具包可以得到与韵律边界和突出性相关的特征，并可以通过系数聚类得到韵律轮廓类别。

    

    CoPaSul工具包的目的是自动的韵律标注和从音节到语句级别的韵律特征提取。在这个框架下，韵律被表示为全局和局部轮廓的叠加，这些轮廓在多项式系数的参数化描述下。在全局层面上（通常与但不一定限于语调短语相关），风格化用于以时间变化的F0水平和范围来表示音调。在局部层面上（例如，重音组），描述局部轮廓形状。通过这种参数化方法，可以得到几个与韵律边界和突出性相关的特征。此外，通过系数聚类，可以以自下而上的方式获得韵律轮廓类别。除了基于风格化的特征提取外，还可以使用标准的F0和能量测量（例如，平均值和方差）以及韵律方面的特征。

    The purposes of the CoPaSul toolkit are (1) automatic prosodic annotation and (2) prosodic feature extraction from syllable to utterance level. CoPaSul stands for contour-based, parametric, superpositional intonation stylization. In this framework intonation is represented as a superposition of global and local contours that are described parametrically in terms of polynomial coefficients. On the global level (usually associated but not necessarily restricted to intonation phrases) the stylization serves to represent register in terms of time-varying F0 level and range. On the local level (e.g. accent groups), local contour shapes are described. From this parameterization several features related to prosodic boundaries and prominence can be derived. Furthermore, by coefficient clustering prosodic contour classes can be obtained in a bottom-up way. Next to the stylization-based feature extraction also standard F0 and energy measures (e.g. mean and variance) as well as rhythmic aspects c
    

