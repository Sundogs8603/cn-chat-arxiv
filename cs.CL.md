# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [On the Efficacy of Sampling Adapters.](http://arxiv.org/abs/2307.03749) | 本研究提出了采样适配器，一种用于改善语言生成的技术，通过改变模型的采样分布来生成质量更高的文本。这种转变可以视为精确度和召回率的权衡，从而提高了期望文本的质量。 |
| [^2] | [QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models.](http://arxiv.org/abs/2307.03738) | QIGen是一种用于支持大型语言模型量化推理的自动代码生成方法，通过考虑目标架构和性能模型，实现了高性能和高准确性，并在LLaMA模型的基于CPU的推理任务上取得了比现有开源解决方案更好的效果。 |
| [^3] | [Improving Automatic Quotation Attribution in Literary Novels.](http://arxiv.org/abs/2307.03734) | 本研究通过将引用标注视为四个相互关联的子任务，改进了文学小说中的自动引用标注。实证结果表明，一个简单的顺序预测模型能够达到与最先进模型相似的准确性得分。 |
| [^4] | [INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers.](http://arxiv.org/abs/2307.03712) | INT-FP-QSim是一个开源模拟器，用于评估大型语言模型和视觉转换器在不同精度和格式下的性能。通过使用不同的数值格式，我们研究了4位权重和4位或8位激活对模型性能的影响，并比较了不同方法的效果。 |
| [^5] | [Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media.](http://arxiv.org/abs/2307.03699) | 这项研究首次系统地利用大型语言模型(ChatGPT)检测社交媒体上的非法毒品贩运活动。通过利用知识驱动的提示，该方法能够解决传统监督学习方法在数据获取和识别欺骗性语言方面的限制。 |
| [^6] | [Becoming self-instruct: introducing early stopping criteria for minimal instruct tuning.](http://arxiv.org/abs/2307.03692) | 该论文引入了一个用于检测语言模型遵循指令能力的度量标准，并将其用作早停标准进行指令调整。实验证明模型能够相对早期地学会遵循指令，并且进一步微调可能导致语义变化。 |
| [^7] | [Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review.](http://arxiv.org/abs/2307.03691) | 该论文提出了一个模型，利用用户评论和相关项目特征生成对比评价句子，以帮助用户找到最适合的产品。该模型包括项目编码模块、比较生成模块和个性化解码方法，并通过人类评估验证了生成句子的相关性和真实性。 |
| [^8] | [Leveraging text data for causal inference using electronic health records.](http://arxiv.org/abs/2307.03687) | 利用文本数据支持电子健康数据的因果推断，在临床研究中提供了宝贵的患者信息，为匹配分析引入了文本，改善了处理缺失数据的效果，并增强了匹配过程的合理性。 |
| [^9] | [Undecimated Wavelet Transform for Word Embedded Semantic Marginal Autoencoder in Security improvement and Denoising different Languages.](http://arxiv.org/abs/2307.03679) | 本研究提出了一种将不可降解小波变换与嵌入语义边缘自动编码器相结合的新策略，用于改善多语言安全措施和降噪。该系统通过提取特征并保留数据中的时间和地理链接，成功捕获重要信息，并提高了系统检测异常和区分合法内容与危险威胁的能力。 |
| [^10] | [Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations.](http://arxiv.org/abs/2307.03678) | 本研究评估了大型语言模型在表示几何和空间关系文本描述中的有效性，发现虽然这些模型能够捕捉一些空间关系，但在估计数值和检索相关对象方面仍存在挑战。 |
| [^11] | [Testing the Predictions of Surprisal Theory in 11 Languages.](http://arxiv.org/abs/2307.03667) | 本研究填补了现有文献中的空白，通过研究11种不同语言之间的surprisal与阅读时间之间的关系，测试了Surprisal理论的三个预测，并发现了其他语言特征对阅读时间的影响。 |
| [^12] | [The distribution of discourse relations within and across turns in spontaneous conversation.](http://arxiv.org/abs/2307.03645) | 本文研究了自发对话中语篇关系的分布。研究发现，不同的对话环境会产生不同的语篇关系分布。此外，注释的语篇关系质量足以通过嵌入学习预测。 |
| [^13] | [Text Simplification of Scientific Texts for Non-Expert Readers.](http://arxiv.org/abs/2307.03569) | 这篇论文介绍了针对非专业读者的科学文本简化任务。通过重新表述科学摘要，以满足非专业人士的阅读需求。该研究利用各类模型进行摘要生成和复杂短语识别，以提供更易懂的信息。 |
| [^14] | [DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling.](http://arxiv.org/abs/2307.03550) | 本文介绍了我们通过基于风格的数据采样来增强主观性检测任务的方法。我们使用GPT-3模型根据新闻记者视角的主观性检查清单生成额外的训练材料，并使用扩展的训练集微调语言特定的变形器模型。我们的实验结果表明，不同主观风格在所有语言中都是有效的，并且基于风格的过采样在土耳其语和英语中的效果优于改写方法。然而，在非英语语言中，GPT-3模型有时会生成乏味的结果。 |
| [^15] | [Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers.](http://arxiv.org/abs/2307.03539) | 这项工作提出了一个基于大型语言模型的零-shot技能提取系统，通过生成ESCO技能的合成训练数据和使用相似性检索器，实现了从职位描述中提取技能的目标。 |
| [^16] | [Quantifying the perceptual value of lexical and non-lexical channels in speech.](http://arxiv.org/abs/2307.03534) | 本文研究了语音中词汇和非词汇信道的知觉价值。通过量化非词汇信息对对话期望的影响，我们发现非词汇信息虽然在区分性转变判断方面表现不如词汇内容，但能够在参与者之间产生更高的共识。 |
| [^17] | [Derivative Free Weight-space Ensembling.](http://arxiv.org/abs/2307.03506) | 本文引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。通过在几个不同的知识库的角度上对专家模型进行微调，并使用无梯度优化算法进行线性插值，我们有效地找到了一个好的模型权重插值，从而在FETA-Friends上超过了标准的预训练-微调方法。 |
| [^18] | [AI-UPV at EXIST 2023 -- Sexism Characterization Using Large Language Models Under The Learning with Disagreements Regime.](http://arxiv.org/abs/2307.03385) | 以学习与分歧的机制为框架，使用大型语言模型进行性别歧视识别和表征的研究，以推动更具包容性和尊重性的在线环境。 |
| [^19] | [A Side-by-side Comparison of Transformers for English Implicit Discourse Relation Classification.](http://arxiv.org/abs/2307.03378) | 本研究对七个预训练语言模型进行了直接细调比较，提出了一种针对英语隐式篇章关系分类的新方法，并获得了显著提升的准确度。与之前的报道不同，本研究发现句子级预训练目标失败的情况下，采用了类似规模的PLMs，并且使用了MLM和完全注意机制的模型表现更好。 |
| [^20] | [Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection.](http://arxiv.org/abs/2307.03377) | 本文提出了一种基于任务感知的方法，用于解决性别歧视、仇恨言论和有害语言检测中的负面迁移问题，并能够减少负面迁移并提高性能。 |
| [^21] | [Evaluating Biased Attitude Associations of Language Models in an Intersectional Context.](http://arxiv.org/abs/2307.03360) | 这篇论文以已建立的文献为基础，量化了英语语言模型中社会群体的情绪关联，并发现语言模型对性别认同、社会阶级和性取向的信号表现出最大的偏见态度。 |
| [^22] | [Token-Level Serialized Output Training for Joint Streaming ASR and ST Leveraging Textual Alignments.](http://arxiv.org/abs/2307.03354) | 本文提出了一种流式Transformer-Transducer，同时生成自动语音识别（ASR）和语音翻译（ST）输出的方法。通过联合的标记级串行输出训练方法，结合现成的文本对齐器，实现了最佳的质量-延迟平衡，并在多语环境下取得了良好的效果。 |
| [^23] | [BiPhone: Modeling Inter Language Phonetic Influences in Text.](http://arxiv.org/abs/2307.03322) | 这篇论文提出了一种模拟跨语言影响的方法，通过挖掘L1和L2之间的音素歧义，生成合成的受干扰的L2文本。通过人工评估和实验结果表明，该方法可以生成可信的受干扰的L2文本，并对流行的语言理解模型造成负面影响。 |
| [^24] | [Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment.](http://arxiv.org/abs/2307.03319) | 这篇论文致力于自动生成重点间隙问题（GFQ），通过定义任务、提出模型并与人工生成问题进行比较，证明了竞争性的性能。 |
| [^25] | [InfoSync: Information Synchronization across Multilingual Semi-structured Tables.](http://arxiv.org/abs/2307.03313) | 该论文提出了一个名为InfoSync的新数据集和一种两步方法，用于跨语言半结构化表格的信息同步。通过信息对齐和信息更新，该方法在InfoSync数据集上获得了高效的性能，验证了其有效性。 |
| [^26] | [Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment.](http://arxiv.org/abs/2307.03296) | 该研究提出了一种使用Gamma音图表示语音的方法，通过卷积神经网络实现了语音识别、说话人识别和可理解性评估的功能。 |
| [^27] | [It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos.](http://arxiv.org/abs/2307.03274) | 在TikTok视频中，我们引入了一个名为SexTok的数据集，用于区分性暗示内容和虚拟性教育视频。我们发现这是一个具有挑战性但可学习的任务。 |
| [^28] | [Vision Language Transformers: A Survey.](http://arxiv.org/abs/2307.03254) | 视觉语言转换器是将预训练的transformer架构应用于视觉语言建模的研究领域，通过迁移学习，在同时进行视觉和语言任务中取得了显著改进。 |
| [^29] | [PREADD: Prefix-Adaptive Decoding for Controlled Text Generation.](http://arxiv.org/abs/2307.03214) | PREADD是一种前缀自适应解码方法，用于控制性文本生成，相比现有方法，PREADD不需要外部模型，能够实现对任何属性的正向和负向控制，并在多个任务上表现出较高的性能提升。 |
| [^30] | [Extracting Multi-valued Relations from Language Models.](http://arxiv.org/abs/2307.03122) | 该论文研究了从预训练语言模型中提取多值关系的问题，并通过排名和选择任务的方法解决了这个问题。结果表明，选择具有特定关系阈值以上的对象可以达到49.5%的F1得分，这对于将语言模型应用于多值槽位填充任务而言是具有挑战性的。该研究为从潜在语言表示中提取关系知识开辟了进一步研究的道路。 |
| [^31] | [The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection.](http://arxiv.org/abs/2307.02892) | 本研究发现抑郁症会改变从语音中提取的特征之间的相关性，同时利用这种洞察力可以通过改进特征相关性来提高抑郁症检测器的训练速度和性能。 |
| [^32] | [What Should Data Science Education Do with Large Language Models?.](http://arxiv.org/abs/2307.02792) | 大型语言模型（LLM）正在改变数据科学家的责任和数据科学教育模式，从动手编码和标准分析转变为评估和管理自动化AI执行的分析。这种转变要求数据科学教育注重培养学生的多样化技能，如创造力、批判性思维和AI引导的编程。 |
| [^33] | [Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard.](http://arxiv.org/abs/2307.02288) | 本文对OpenAI ChatGPT、Microsoft Bing Chat和Google Bard这三种大型语言模型在VNHSGE英文数据集上的性能进行了比较，结果显示Bing Chat优于ChatGPT和Bard。研究结果还表明，这些语言模型在英语语言教育中具有潜力，可以作为高中英语教学和学习的有效工具。 |
| [^34] | [LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT.](http://arxiv.org/abs/2306.17103) | LyricWhiz是一种鲁棒、多语言、零射击的自动歌词转录方法，通过使用Whisper作为"耳朵"和GPT-4作为"大脑"，它在各种数据集上实现了最先进的性能，同时还实现了在多种语言中进行歌词转录的能力，并创建了第一个大规模多语言歌词转录数据集。 |
| [^35] | [KoLA: Carefully Benchmarking World Knowledge of Large Language Models.](http://arxiv.org/abs/2306.09296) | 本研究提出了一个针对大型语言模型的知识导向评估基准 (KoLA)，通过模仿人类认知构建了四级知识相关能力的分类体系，并使用维基百科和新兴语料库进行评估。这个基准旨在全面、公正和实用地评估LLM的能力，以处理未见数据和不断发展的知识。 |
| [^36] | [Automated Labeling of German Chest X-Ray Radiology Reports using Deep Learning.](http://arxiv.org/abs/2306.05997) | 本研究使用基于深度学习的CheXpert标签预测模型进行弱监督，显着优于基于规则的模型，在自动标注德语胸部X射线医学报告方面具有潜在价值。 |
| [^37] | [MISGENDERED: Limits of Large Language Models in Understanding Pronouns.](http://arxiv.org/abs/2306.03950) | 本文全面评估了广受欢迎的语言模型正确使用英语性别中立代词和新代词的能力，以及考虑到非二元性别身份的重要性，引入了MISGENDERED框架，用于评估大型语言模型正确使用首选代词的能力。 |
| [^38] | [BigTranslate: Augmenting Large Language Models with Multilingual Translation Capability over 100 Languages.](http://arxiv.org/abs/2305.18098) | BigTranslate是一个基于LLaMA的大型语言模型，在原有的基础上通过继续训练和指导微调实现了对100多种语言的多语言翻译能力，初步实验结果显示其性能接近于ChatGPT和谷歌翻译。 |
| [^39] | [Language Models are Bounded Pragmatic Speakers.](http://arxiv.org/abs/2305.17760) | 本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。经过人类反馈的强化学习微调的大型语言模型具有概念上类似于 快与慢思考模型的思维模型，而这种思维模型被归因于人类。此研究凸显了采用认知概率建模方法对语言模型的理解、评估和推进的价值。 |
| [^40] | [Weaker Than You Think: A Critical Look at Weakly Supervised Learning.](http://arxiv.org/abs/2305.17442) | 这篇论文批判性地研究了弱监督学习方法，发现这些方法的好处被高估了，大多数优势可以通过简单地利用干净的训练数据实现。 |
| [^41] | [Code-Switched Text Synthesis in Unseen Language Pairs.](http://arxiv.org/abs/2305.16724) | 本文介绍了GLOSS模型，旨在解决在缺乏训练数据的情况下合成混合代码文本的问题，并且可以推广到更广泛的语言对。该模型在四个未见过的语言对上的实验中优于其他基线模型和在单语文本上运行的生成模型。 |
| [^42] | [Evaluating Open-Domain Question Answering in the Era of Large Language Models.](http://arxiv.org/abs/2305.06984) | 本文评估了开放领域问答中的大语言模型，发现词汇匹配作为评估方法在这些模型中的作用有限，提出了一种手动评估方法，并发现其中一个零-shot模型的性能大幅度提升。 |
| [^43] | [Evaluating Embedding APIs for Information Retrieval.](http://arxiv.org/abs/2305.06300) | 本篇论文旨在通过对语义嵌入API在实际检索场景中的分析,为从业者和研究人员找到适当的服务。结果表明，在英语上使用API重新排名BM25的结果是一种预算友好的最优做法。 |
| [^44] | [ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit.](http://arxiv.org/abs/2304.04596) | ESPnet-ST-v2是一个开源的多功能口语翻译工具包，支持多种翻译任务，采用了先进的架构和技术，具有非常高的性能表现。 |
| [^45] | [Federated Learning Based Multilingual Emoji Prediction In Clean and Attack Scenarios.](http://arxiv.org/abs/2304.01005) | 本文提出了一种基于联邦学习的多语言表情符号预测方法，在干净或攻击情境下均有效，同时保护了用户数据隐私。 |
| [^46] | [Guiding Large Language Models via Directional Stimulus Prompting.](http://arxiv.org/abs/2302.11520) | 该文介绍了一个新的框架，用于通过生成定向刺激来指导大型语言模型在下游任务中生成所需的输出。通过策略语言模型的训练，该框架可以适应于各种语言模型和任务，并在摘要和对话生成任务中取得了最先进的表现。 |
| [^47] | [Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model.](http://arxiv.org/abs/2212.09811) | 本研究提出了一种节约内存的NLLB-200模型修剪方法，可在保持翻译质量的同时移除多达80％的专家，使得在单个32GB的GPU上运行模型成为可能。这对于大规模多语言机器翻译具有重要的意义。 |
| [^48] | [WACO: Word-Aligned Contrastive Learning for Speech Translation.](http://arxiv.org/abs/2212.09359) | WACO是一种用于极低资源语音到文本翻译的简单而有效的方法，通过对比学习将语音和文本的词级表示连接起来，实验证明WACO在极低资源条件下比基线方法提高了9+ BLEU分。 |
| [^49] | [SESCORE2: Learning Text Generation Evaluation via Synthesizing Realistic Mistakes.](http://arxiv.org/abs/2212.09305) | 这项研究提出了一种自监督方法SESCORE2，通过合成真实的模型错误来训练用于评估文本生成质量的度量标准。SESCORE2在多个语言和任务上的评估中表现出色，并优于其他无监督和有监督的方法。 |
| [^50] | [ALERT: Adapting Language Models to Reasoning Tasks.](http://arxiv.org/abs/2212.08286) | 该论文介绍了ALERT，它是一个用于评估语言模型在推理任务上能力的基准和分析工具。通过对预训练模型和微调模型在复杂任务上的比较，研究发现语言模型学会了更多推理技能，并提供了一个测试平台来评估模型在细粒度推理技能上的表现。 |
| [^51] | [Calibrated Interpretation: Confidence Estimation in Semantic Parsing.](http://arxiv.org/abs/2211.07443) | 该论文研究了常见的生成模型在四个流行的语义解析数据集上的校准性，并分析了与校准误差相关的因素。为了方便将校准纳入语义解析评估中，作者们发布了一个计算校准度量的库。 |
| [^52] | [Breadth-First Pipeline Parallelism.](http://arxiv.org/abs/2211.05953) | 宽度优先的流水线并行计算方法结合了流水线和数据并行计算，通过在每个GPU上使用小批量大小和完全分片的数据并行计算，以提高训练吞吐量。在实验中，与Megatron-LM相比，在一个520亿参数的模型上，使用小批量大小每个GPU的训练吞吐量增加了高达43%。 |
| [^53] | [Word to Sentence Visual Semantic Similarity for Caption Generation: Lessons Learned.](http://arxiv.org/abs/2209.12817) | 本文提出了一种通过选择最相关的输出来改进图像标题生成系统的方法，同时采用视觉语义度量来匹配图像中的相关信息与合适的标题。 |
| [^54] | [Bridging the Gap Between Indexing and Retrieval for Differentiable Search Index with Query Generation.](http://arxiv.org/abs/2206.10128) | 本文识别和解决了当前可微搜索索引模型的一个重要问题：在索引和检索过程中存在的数据分布不匹配。为了解决这个问题，提出了一个简单而有效的索引框架。 |
| [^55] | [End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models.](http://arxiv.org/abs/2205.12487) | 端到端的多模态事实检查和解释生成。构建了Mocheg数据集，包含15,601个主张，33,880个文本段落和12,112个图像作为证据。通过三个子任务取得了良好性能。 |

# 详细

[^1]: 采样适配器的效能研究

    On the Efficacy of Sampling Adapters. (arXiv:2307.03749v1 [cs.CL])

    [http://arxiv.org/abs/2307.03749](http://arxiv.org/abs/2307.03749)

    本研究提出了采样适配器，一种用于改善语言生成的技术，通过改变模型的采样分布来生成质量更高的文本。这种转变可以视为精确度和召回率的权衡，从而提高了期望文本的质量。

    

    采样是从概率模型生成文本的常见策略，但标准的祖先采样往往导致文本不连贯或不符合语法。为了缓解这个问题，提出了各种修改模型采样分布的技术，如核心或top-k采样，并广泛应用于语言生成系统中。我们提出了一个统一的框架来理解这些技术，称之为采样适配器。采样适配器通常可以生成质量更高的文本，这引发了一个问题：从形式的角度来看，它们是如何改变语言生成模型的（子）词级分布的？为什么这些局部改变会导致更高质量的文本？我们认为，它们所强制执行的转变可以被视为精确度和召回率之间的权衡：虽然模型失去了产生某些字符串的能力，但对于期望的文本，其精确率提高了。尽管这种权衡在标准的距离度量中没有反映出来，但它确实对生成的文本质量起到了重要作用。

    Sampling is a common strategy for generating text from probabilistic models, yet standard ancestral sampling often results in text that is incoherent or ungrammatical. To alleviate this issue, various modifications to a model's sampling distribution, such as nucleus or top-k sampling, have been introduced and are now ubiquitously used in language generation systems. We propose a unified framework for understanding these techniques, which we term sampling adapters. Sampling adapters often lead to qualitatively better text, which raises the question: From a formal perspective, how are they changing the (sub)word-level distributions of language generation models? And why do these local changes lead to higher-quality text? We argue that the shift they enforce can be viewed as a trade-off between precision and recall: while the model loses its ability to produce certain strings, its precision rate on desirable text increases. While this trade-off is not reflected in standard metrics of dist
    
[^2]: QIGen：用于大型语言模型的量化推理的高效内核生成

    QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models. (arXiv:2307.03738v1 [cs.LG])

    [http://arxiv.org/abs/2307.03738](http://arxiv.org/abs/2307.03738)

    QIGen是一种用于支持大型语言模型量化推理的自动代码生成方法，通过考虑目标架构和性能模型，实现了高性能和高准确性，并在LLaMA模型的基于CPU的推理任务上取得了比现有开源解决方案更好的效果。

    

    我们提出了一种新的自动代码生成方法，用于支持LLMs（如LLaMA或OPT）在现成的CPU上进行量化生成推理。我们的方法根据目标架构和性能模型进行设计，包括硬件特性和方法特定的准确性约束。在LLaMA模型的基于CPU的推理任务上的实验结果表明，我们的方法可以实现高性能和高准确性，与现有最佳开源解决方案相比更具优势。我们的初步实现代码可在https://github.com/IST-DASLab/QIGen找到。

    We present ongoing work on a new automatic code generation approach for supporting quantized generative inference on LLMs such as LLaMA or OPT on off-the-shelf CPUs. Our approach is informed by the target architecture and a performance model, including both hardware characteristics and method-specific accuracy constraints. Results on CPU-based inference for LLaMA models show that our approach can lead to high performance and high accuracy, comparing favorably to the best existing open-source solution. A preliminary implementation is available at https://github.com/IST-DASLab/QIGen.
    
[^3]: 在文学小说中改进自动引用标注

    Improving Automatic Quotation Attribution in Literary Novels. (arXiv:2307.03734v1 [cs.CL])

    [http://arxiv.org/abs/2307.03734](http://arxiv.org/abs/2307.03734)

    本研究通过将引用标注视为四个相互关联的子任务，改进了文学小说中的自动引用标注。实证结果表明，一个简单的顺序预测模型能够达到与最先进模型相似的准确性得分。

    

    当前文学小说中的引用标注模型假设其训练和测试数据具有不同程度的可用信息，这给野外推理带来了挑战。在本文中，我们将引用标注视为四个相互关联的子任务：角色识别、共指消解、引语识别和说话者归属。我们使用文学小说中注释的共指和引语的大型数据集（项目言对小说语料库）在每个子任务上对最先进的模型进行基准测试。我们还特别训练和评估说话者归属任务的模型，结果显示一个简单的顺序预测模型的准确性得分与最先进的模型相当。

    Current models for quotation attribution in literary novels assume varying levels of available information in their training and test data, which poses a challenge for in-the-wild inference. Here, we approach quotation attribution as a set of four interconnected sub-tasks: character identification, coreference resolution, quotation identification, and speaker attribution. We benchmark state-of-the-art models on each of these sub-tasks independently, using a large dataset of annotated coreferences and quotations in literary novels (the Project Dialogism Novel Corpus). We also train and evaluate models for the speaker attribution task in particular, showing that a simple sequential prediction model achieves accuracy scores on par with state-of-the-art models.
    
[^4]: INT-FP-QSim: 大型语言模型和视觉转换器的混合精度和格式

    INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers. (arXiv:2307.03712v1 [cs.LG])

    [http://arxiv.org/abs/2307.03712](http://arxiv.org/abs/2307.03712)

    INT-FP-QSim是一个开源模拟器，用于评估大型语言模型和视觉转换器在不同精度和格式下的性能。通过使用不同的数值格式，我们研究了4位权重和4位或8位激活对模型性能的影响，并比较了不同方法的效果。

    

    大型语言模型的崛起导致了减少精度的运行的增加。降低精度的运行方式支持资源约束，并促进其民主化，使用户可以在个人设备上运行数十亿参数的语言模型。为了补充这一持续努力，我们提出了INT-FP-QSim：一个开源模拟器，可以灵活评估不同数值精度和格式下的语言模型和视觉转换器。INT-FP-QSim利用现有的开源库，如TensorRT、QPytorch和AIMET，实现了支持各种浮点和整数格式的组合模拟器。借助我们的模拟器，我们调查了不同数值格式对4位权重和4位或8位激活的语言模型和视觉转换器性能的影响。我们还比较了最近提出的方法，如自适应块浮点、SmoothQuant、GPTQ和RPTQ在模型性能上的差异。我们希望INT-FP-QSim能为研究人员和从业者在低精度环境下评估大型语言模型和视觉转换器的性能提供帮助。

    The recent rise of large language models (LLMs) has resulted in increased efforts towards running LLMs at reduced precision. Running LLMs at lower precision supports resource constraints and furthers their democratization, enabling users to run billion-parameter LLMs on their personal devices. To supplement this ongoing effort, we propose INT-FP-QSim: an open-source simulator that enables flexible evaluation of LLMs and vision transformers at various numerical precisions and formats. INT-FP-QSim leverages existing open-source repositories such as TensorRT, QPytorch and AIMET for a combined simulator that supports various floating point and integer formats. With the help of our simulator, we survey the impact of different numerical formats on the performance of LLMs and vision transformers at 4-bit weights and 4-bit or 8-bit activations. We also compare recently proposed methods like Adaptive Block Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We hope INT-FP-QSim
    
[^5]: 揭示知识激发的ChatGPT在增强社交媒体上的毒品贩运检测中的潜力

    Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media. (arXiv:2307.03699v1 [cs.CL])

    [http://arxiv.org/abs/2307.03699](http://arxiv.org/abs/2307.03699)

    这项研究首次系统地利用大型语言模型(ChatGPT)检测社交媒体上的非法毒品贩运活动。通过利用知识驱动的提示，该方法能够解决传统监督学习方法在数据获取和识别欺骗性语言方面的限制。

    

    社交媒体平台如Instagram和Twitter已经成为毒品营销和非法销售的关键渠道。检测和标记在线非法毒品贩运活动对解决这个问题至关重要。然而，传统的监督学习方法在检测毒品贩运方面的有效性在很大程度上依赖于获得大量标记数据，而数据注释是耗时且资源密集的过程。此外，当毒贩使用欺骗性语言和委婉语避免被检测时，这些模型通常面临着准确识别贩运活动的挑战。为了克服这个限制，我们进行了第一次系统研究，利用ChatGPT等大型语言模型(LLMs)来检测社交媒体上的非法毒品贩运活动。我们提出了一个分析框架，用于组成知识驱动的提示，这些提示作为人类与LLMs交互的接口来执行检测任务。

    Social media platforms such as Instagram and Twitter have emerged as critical channels for drug marketing and illegal sale. Detecting and labeling online illicit drug trafficking activities becomes important in addressing this issue. However, the effectiveness of conventional supervised learning methods in detecting drug trafficking heavily relies on having access to substantial amounts of labeled data, while data annotation is time-consuming and resource-intensive. Furthermore, these models often face challenges in accurately identifying trafficking activities when drug dealers use deceptive language and euphemisms to avoid detection. To overcome this limitation, we conduct the first systematic study on leveraging large language models (LLMs), such as ChatGPT, to detect illicit drug trafficking activities on social media. We propose an analytical framework to compose \emph{knowledge-informed prompts}, which serve as the interface that humans can interact with and use LLMs to perform t
    
[^6]: 成为自学者：引入最小指令调整的早停标准

    Becoming self-instruct: introducing early stopping criteria for minimal instruct tuning. (arXiv:2307.03692v1 [cs.CL])

    [http://arxiv.org/abs/2307.03692](http://arxiv.org/abs/2307.03692)

    该论文引入了一个用于检测语言模型遵循指令能力的度量标准，并将其用作早停标准进行指令调整。实验证明模型能够相对早期地学会遵循指令，并且进一步微调可能导致语义变化。

    

    在本文中，我们引入了指令跟随得分（IFS），一种检测语言模型遵循指令能力的度量标准。该度量标准具有双重目的。首先，IFS可以用于区分基础模型和指令模型。我们对公开可用的基础模型和指令模型进行了基准测试，并显示出良好格式化响应与部分和完整句子的比例可以作为这两种模型类别之间的有效衡量指标。其次，该度量标准可以用作指令调整的早停标准。我们计算了7B和13B LLaMA模型的有监督微调的IFS，显示模型在训练过程中相对早期就学会了遵循指令，并且进一步微调可能导致基础模型语义的变化。作为语义变化的示例，我们展示了由辅助度量标准ObjecQA定义的模型预测的客观性。我们表明在这种特定情况下，当IFS倾向于p时，语义变化最为剧烈。

    In this paper, we introduce the Instruction Following Score (IFS), a metric that detects language models' ability to follow instructions. The metric has a dual purpose. First, IFS can be used to distinguish between base and instruct models. We benchmark publicly available base and instruct models, and show that the ratio of well formatted responses to partial and full sentences can be an effective measure between those two model classes. Secondly, the metric can be used as an early stopping criteria for instruct tuning. We compute IFS for Supervised Fine-Tuning (SFT) of 7B and 13B LLaMA models, showing that models learn to follow instructions relatively early in the training process, and the further finetuning can result in changes in the underlying base model semantics. As an example of semantics change we show the objectivity of model predictions, as defined by an auxiliary metric ObjecQA. We show that in this particular case, semantic changes are the steepest when the IFS tends to p
    
[^7]: 将苹果与苹果进行比较：从用户评论生成纵向感知的比较句子

    Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review. (arXiv:2307.03691v1 [cs.CL])

    [http://arxiv.org/abs/2307.03691](http://arxiv.org/abs/2307.03691)

    该论文提出了一个模型，利用用户评论和相关项目特征生成对比评价句子，以帮助用户找到最适合的产品。该模型包括项目编码模块、比较生成模块和个性化解码方法，并通过人类评估验证了生成句子的相关性和真实性。

    

    在众多相似的选择中找到最佳产品是非常耗时的。比较句子可以帮助我们以突出的方式对比一个项目与其他项目，在此过程中强调出重要特征。基于用户对一个或多个项目的评论及相关项目特征，我们生成比较评论句子来帮助用户找到最适合的产品。具体来说，我们的模型包括三个连续组件：（i）一个项目编码模块用于对项目进行编码比较，（ii）一个比较生成模块以自回归的方式生成比较句子，（iii）一种用于用户个性化的新型解码方法。我们展示了我们的流程能够生成流畅且多样的比较句子。我们进行了人类评估研究来验证我们生成的句子的相关性和真实性，结果表明我们的算法能够生成相关且真实的比较评论句子。

    It is time-consuming to find the best product among many similar alternatives. Comparative sentences can help to contrast one item from others in a way that highlights important features of an item that stand out. Given reviews of one or multiple items and relevant item features, we generate comparative review sentences to aid users to find the best fit. Specifically, our model consists of three successive components in a transformer: (i) an item encoding module to encode an item for comparison, (ii) a comparison generation module that generates comparative sentences in an autoregressive manner, (iii) a novel decoding method for user personalization. We show that our pipeline generates fluent and diverse comparative sentences. We run experiments on the relevance and fidelity of our generated sentences in a human evaluation study and find that our algorithm creates comparative review sentences that are relevant and truthful.
    
[^8]: 利用文本数据进行电子医疗记录的因果推断

    Leveraging text data for causal inference using electronic health records. (arXiv:2307.03687v1 [cs.CL])

    [http://arxiv.org/abs/2307.03687](http://arxiv.org/abs/2307.03687)

    利用文本数据支持电子健康数据的因果推断，在临床研究中提供了宝贵的患者信息，为匹配分析引入了文本，改善了处理缺失数据的效果，并增强了匹配过程的合理性。

    

    文本是医疗数据中普遍存在的组成部分，包含了有关患者特征和治疗的宝贵信息，这些信息通常在结构化图表数据中缺失。尽管如此丰富，但由于其复杂性，它很少在临床研究中使用。利用大量患者记录和治疗历史的数据库，以及陪护医生和护士的广泛笔记，我们展示了如何在电子健康数据中利用文本数据支持因果推断的各个阶段，从构思和设计到分析和解释，仅需很少的额外工作。我们重点关注使用配对匹配进行因果推断的研究。我们通过三种方式将文本纳入经典配对分析中：通过使用文本补充多重插补程序，改善了对处理缺失数据的插补值的准确性；通过在匹配阶段中纳入文本，增强了匹配过程的合理性；通过对文本进行条件处理，我们可以估计...

    Text is a ubiquitous component of medical data, containing valuable information about patient characteristics and care that are often missing from structured chart data. Despite this richness, it is rarely used in clinical research, owing partly to its complexity. Using a large database of patient records and treatment histories accompanied by extensive notes by attendant physicians and nurses, we show how text data can be used to support causal inference with electronic health data in all stages, from conception and design to analysis and interpretation, with minimal additional effort. We focus on studies using matching for causal inference. We augment a classic matching analysis by incorporating text in three ways: by using text to supplement a multiple imputation procedure, we improve the fidelity of imputed values to handle missing data; by incorporating text in the matching stage, we strengthen the plausibility of the matching procedure; and by conditioning on text, we can estimat
    
[^9]: 嵌入语义边缘自动编码器中的不可降解小波变换对多语言安全改进和降噪的研究

    Undecimated Wavelet Transform for Word Embedded Semantic Marginal Autoencoder in Security improvement and Denoising different Languages. (arXiv:2307.03679v1 [cs.CL])

    [http://arxiv.org/abs/2307.03679](http://arxiv.org/abs/2307.03679)

    本研究提出了一种将不可降解小波变换与嵌入语义边缘自动编码器相结合的新策略，用于改善多语言安全措施和降噪。该系统通过提取特征并保留数据中的时间和地理链接，成功捕获重要信息，并提高了系统检测异常和区分合法内容与危险威胁的能力。

    

    通过将不可降解小波变换与嵌入语义边缘自动编码器（WESMA）相结合，本研究提出了一种改善安全措施和降噪多种语言的新策略。这些策略的整合旨在解决数据处理应用中的鲁棒性、隐私性和多语言性问题。不可降解小波变换被用作特征提取工具，以识别输入数据中突出的语言模式和结构特性。通过采用这种变换，提议的系统可以在保留数据中的时间和地理链接的同时，成功捕获重要信息。这通过增加系统检测异常、发现隐藏模式以及区分合法内容和危险威胁的能力来改善安全措施。嵌入语义边缘自动编码器还可以作为一个智能框架来降维和降噪数据。

    By combining the undecimated wavelet transform within a Word Embedded Semantic Marginal Autoencoder (WESMA), this research study provides a novel strategy for improving security measures and denoising multiple languages. The incorporation of these strategies is intended to address the issues of robustness, privacy, and multilingualism in data processing applications. The undecimated wavelet transform is used as a feature extraction tool to identify prominent language patterns and structural qualities in the input data. The proposed system may successfully capture significant information while preserving the temporal and geographical links within the data by employing this transform. This improves security measures by increasing the system's ability to detect abnormalities, discover hidden patterns, and distinguish between legitimate content and dangerous threats. The Word Embedded Semantic Marginal Autoencoder also functions as an intelligent framework for dimensionality and noise redu
    
[^10]: 评估大型语言模型在表示几何和空间关系的文本描述中的有效性

    Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations. (arXiv:2307.03678v1 [cs.CL])

    [http://arxiv.org/abs/2307.03678](http://arxiv.org/abs/2307.03678)

    本研究评估了大型语言模型在表示几何和空间关系文本描述中的有效性，发现虽然这些模型能够捕捉一些空间关系，但在估计数值和检索相关对象方面仍存在挑战。

    

    本研究旨在评估大型语言模型（LLMs）在表示几何和空间关系方面的能力。我们利用包括GPT-2和BERT在内的LLMs对几何的文本格式进行编码，然后将它们的嵌入输入分类器和回归器，以评估LLMs生成的嵌入在几何属性方面的有效性。实验表明，尽管LLMs生成的嵌入能够保留几何类型并捕捉一些空间关系（准确度高达73%），但在估计数值和检索空间相关对象方面仍存在挑战。本研究凸显了在捕捉底层地理空间数据的细微差别和复杂性以及整合领域知识以支持使用基础模型的各种GeoAI应用方面的改进需求。

    This research focuses on assessing the ability of large language models (LLMs) in representing geometries and their spatial relations. We utilize LLMs including GPT-2 and BERT to encode the well-known text (WKT) format of geometries and then feed their embeddings into classifiers and regressors to evaluate the effectiveness of the LLMs-generated embeddings for geometric attributes. The experiments demonstrate that while the LLMs-generated embeddings can preserve geometry types and capture some spatial relations (up to 73% accuracy), challenges remain in estimating numeric values and retrieving spatially related objects. This research highlights the need for improvement in terms of capturing the nuances and complexities of the underlying geospatial data and integrating domain knowledge to support various GeoAI applications using foundation models.
    
[^11]: 在11种语言中测试Surprisal理论的预测

    Testing the Predictions of Surprisal Theory in 11 Languages. (arXiv:2307.03667v1 [cs.CL])

    [http://arxiv.org/abs/2307.03667](http://arxiv.org/abs/2307.03667)

    本研究填补了现有文献中的空白，通过研究11种不同语言之间的surprisal与阅读时间之间的关系，测试了Surprisal理论的三个预测，并发现了其他语言特征对阅读时间的影响。

    

    心理语言学的一个基本结果是，可预测性较低的词语需要更长时间来处理。Surprisal理论（Hale, 2001; Levy, 2008）是对这一发现的一个理论解释，它将一个词的可预测性量化为其surprisal，即在给定上下文的情况下，其负对数概率。虽然有大量的证据支持Surprisal理论的预测，但大多数研究都集中在一个非常有限的数据范围内，即以英语为母语的人阅读英语文本。事实上，目前还没有全面的多语言分析。我们通过研究在五个语言家族中分布的十一种不同语言中surprisal与阅读时间之间的关系来填补当前文献中的这一空白。通过从单语和多语语料库训练的语言模型中推导估计值，我们测试了与surprisal理论相关的三个预测：(i) surprisal是否能够预测阅读时间；(ii) 预期surprisal，即上下文熵，是否影响阅读时间；(iii) 与surprisal相关的其他语言特征是否可以解释阅读时间。

    A fundamental result in psycholinguistics is that less predictable words take a longer time to process. One theoretical explanation for this finding is Surprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's predictability as its surprisal, i.e. its negative log-probability given a context. While evidence supporting the predictions of Surprisal Theory have been replicated widely, most have focused on a very narrow slice of data: native English speakers reading English texts. Indeed, no comprehensive multilingual analysis exists. We address this gap in the current literature by investigating the relationship between surprisal and reading times in eleven different languages, distributed across five language families. Deriving estimates from language models trained on monolingual and multilingual corpora, we test three predictions associated with surprisal theory: (i) whether surprisal is predictive of reading times; (ii) whether expected surprisal, i.e. contextual entropy, i
    
[^12]: 自发对话中语篇关系的分布在对话转折中的分布及其影响

    The distribution of discourse relations within and across turns in spontaneous conversation. (arXiv:2307.03645v1 [cs.CL])

    [http://arxiv.org/abs/2307.03645](http://arxiv.org/abs/2307.03645)

    本文研究了自发对话中语篇关系的分布。研究发现，不同的对话环境会产生不同的语篇关系分布。此外，注释的语篇关系质量足以通过嵌入学习预测。

    

    时间压力和话题协商可能会对人们在自发对话中利用语篇关系(DRs)施加限制。在这项工作中，我们利用新手注释者的众包注释，将书面语言的DR系统适用于自发对话。然后，我们测试了在多语言环境中不同类型的多句话上，语篇关系的使用是否不同。我们比较了在发言人内部和跨发言人之间、在发言轮内部和跨发言轮之间的DR注释模式。最终，我们发现不同的语篇环境产生了不同的语篇关系分布，其中单一发言轮注释对注释者产生了最大的不确定性。此外，我们发现语篇关系的注释质量足以从语篇单元的嵌入中进行预测。

    Time pressure and topic negotiation may impose constraints on how people leverage discourse relations (DRs) in spontaneous conversational contexts. In this work, we adapt a system of DRs for written language to spontaneous dialogue using crowdsourced annotations from novice annotators. We then test whether discourse relations are used differently across several types of multi-utterance contexts. We compare the patterns of DR annotation within and across speakers and within and across turns. Ultimately, we find that different discourse contexts produce distinct distributions of discourse relations, with single-turn annotations creating the most uncertainty for annotators. Additionally, we find that the discourse relation annotations are of sufficient quality to predict from embeddings of discourse units.
    
[^13]: 面向非专业读者的科学文本简化

    Text Simplification of Scientific Texts for Non-Expert Readers. (arXiv:2307.03569v1 [cs.CL])

    [http://arxiv.org/abs/2307.03569](http://arxiv.org/abs/2307.03569)

    这篇论文介绍了针对非专业读者的科学文本简化任务。通过重新表述科学摘要，以满足非专业人士的阅读需求。该研究利用各类模型进行摘要生成和复杂短语识别，以提供更易懂的信息。

    

    阅读水平因语言、个人认知能力或对某一主题的了解而有很大差异。文本简化是将文本重新表述以更好地适应特定目标读者群体能力的任务。科学摘要的简化有助于非专业人士通过跳过需要领域或专家知识的表述来获取核心信息，尤其对于读者阅读关于新型治疗选择的癌症患者来说尤为重要。SimpleText实验室主办了针对非专业人士的科学摘要简化比赛（Task 3）以推动该领域的发展。我们贡献了三个运行实例，分别基于T5的两个和基于PEGASUS的一个的出箱摘要模型，并利用ChatGPT进行复杂短语识别的一个运行实例。

    Reading levels are highly individual and can depend on a text's language, a person's cognitive abilities, or knowledge on a topic. Text simplification is the task of rephrasing a text to better cater to the abilities of a specific target reader group. Simplification of scientific abstracts helps non-experts to access the core information by bypassing formulations that require domain or expert knowledge. This is especially relevant for, e.g., cancer patients reading about novel treatment options. The SimpleText lab hosts the simplification of scientific abstracts for non-experts (Task 3) to advance this field. We contribute three runs employing out-of-the-box summarization models (two based on T5, one based on PEGASUS) and one run using ChatGPT with complex phrase identification.
    
[^14]: DWReCO在CheckThat! 2023中通过基于风格的数据采样增强客观性检测

    DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling. (arXiv:2307.03550v1 [cs.CL])

    [http://arxiv.org/abs/2307.03550](http://arxiv.org/abs/2307.03550)

    本文介绍了我们通过基于风格的数据采样来增强主观性检测任务的方法。我们使用GPT-3模型根据新闻记者视角的主观性检查清单生成额外的训练材料，并使用扩展的训练集微调语言特定的变形器模型。我们的实验结果表明，不同主观风格在所有语言中都是有效的，并且基于风格的过采样在土耳其语和英语中的效果优于改写方法。然而，在非英语语言中，GPT-3模型有时会生成乏味的结果。

    

    本文描述了我们在CheckThat!实验室主观性检测任务中的提交。为了解决任务中的类别不平衡问题，我们使用基于新闻记者视角的主观性检查清单，使用不同风格的提示来生成额外的训练材料，使用GPT-3模型。我们使用扩展的训练集来微调语言特定的变形器模型。我们在英语、德语和土耳其语上的实验表明，不同的主观风格在所有语言中都是有效的。此外，我们观察到，在土耳其语和英语中，基于风格的过采样比改写更好。最后，我们发现在非英语语言中，GPT-3模型有时会生成乏味的结果。

    This paper describes our submission for the subjectivity detection task at the CheckThat! Lab. To tackle class imbalances in the task, we have generated additional training materials with GPT-3 models using prompts of different styles from a subjectivity checklist based on journalistic perspective. We used the extended training set to fine-tune language-specific transformer models. Our experiments in English, German and Turkish demonstrate that different subjective styles are effective across all languages. In addition, we observe that the style-based oversampling is better than paraphrasing in Turkish and English. Lastly, the GPT-3 models sometimes produce lacklustre results when generating style-based texts in non-English languages.
    
[^15]: 大型语言模型作为一体化零-shot ESCO技能匹配器

    Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers. (arXiv:2307.03539v1 [cs.CL])

    [http://arxiv.org/abs/2307.03539](http://arxiv.org/abs/2307.03539)

    这项工作提出了一个基于大型语言模型的零-shot技能提取系统，通过生成ESCO技能的合成训练数据和使用相似性检索器，实现了从职位描述中提取技能的目标。

    

    理解劳动力市场动态需要准确地识别劳动力所需的技能。越来越多的自动化技术被开发出来支持这个工作。然而，由于现有技能的数量庞大，从职位发布中自动提取技能是具有挑战性的。ESCO（欧洲技能、能力、资格和职业）框架提供了一个有用的参考，列出了超过13,000个独立的技能。然而，技能提取仍然困难，并且准确地将工作岗位与ESCO分类进行匹配是一个悬而未决的问题。在这项工作中，我们提出了一个基于大型语言模型（LLM）的零-shot技能提取系统。我们生成ESCO技能的合成训练数据，并训练一个分类器从职位发布中提取技能提及。我们还使用相似性检索器生成技能候选项，然后使用第二个LLM进行重新排序。使用合成数据实现了技能提取的良好效果。

    Understanding labour market dynamics requires accurately identifying the skills required for and possessed by the workforce. Automation techniques are increasingly being developed to support this effort. However, automatically extracting skills from job postings is challenging due to the vast number of existing skills. The ESCO (European Skills, Competences, Qualifications and Occupations) framework provides a useful reference, listing over 13,000 individual skills. However, skills extraction remains difficult and accurately matching job posts to the ESCO taxonomy is an open problem. In this work, we propose an end-to-end zero-shot system for skills extraction from job descriptions based on large language models (LLMs). We generate synthetic training data for the entirety of ESCO skills and train a classifier to extract skill mentions from job posts. We also employ a similarity retriever to generate skill candidates which are then re-ranked using a second LLM. Using synthetic data achi
    
[^16]: 量化语音中词汇和非词汇信道的知觉价值

    Quantifying the perceptual value of lexical and non-lexical channels in speech. (arXiv:2307.03534v1 [cs.CL])

    [http://arxiv.org/abs/2307.03534](http://arxiv.org/abs/2307.03534)

    本文研究了语音中词汇和非词汇信道的知觉价值。通过量化非词汇信息对对话期望的影响，我们发现非词汇信息虽然在区分性转变判断方面表现不如词汇内容，但能够在参与者之间产生更高的共识。

    

    语音是一种基本的沟通方式，可以看作为传递信息提供了两种信道：词汇信道是指所说的词汇，非词汇信道是指说话的方式。这两种信道都会塑造听众对即将到来的沟通的期望，然而直接量化它们对期望的相对影响是具有挑战性的。先前的尝试需要通过词汇等效的对话转变或明显的声学处理来实现。本文提出了一个广义的范式，用于研究对话中非词汇信息的价值，包括不受限制的词汇内容。通过使用准确度和熵减少量化非词汇信道的知觉价值，我们发现非词汇信息对即将到来的对话产生了一致的影响：即使它导致较词汇内容单独时更差的区分性转变判断，仍然得到了参与者之间更高的共识。

    Speech is a fundamental means of communication that can be seen to provide two channels for transmitting information: the lexical channel of which words are said, and the non-lexical channel of how they are spoken. Both channels shape listener expectations of upcoming communication; however, directly quantifying their relative effect on expectations is challenging. Previous attempts require spoken variations of lexically-equivalent dialogue turns or conspicuous acoustic manipulations. This paper introduces a generalised paradigm to study the value of non-lexical information in dialogue across unconstrained lexical content. By quantifying the perceptual value of the non-lexical channel with both accuracy and entropy reduction, we show that non-lexical information produces a consistent effect on expectations of upcoming dialogue: even when it leads to poorer discriminative turn judgements than lexical content alone, it yields higher consensus among participants.
    
[^17]: 无导数的权重空间集成

    Derivative Free Weight-space Ensembling. (arXiv:2307.03506v1 [cs.CL])

    [http://arxiv.org/abs/2307.03506](http://arxiv.org/abs/2307.03506)

    本文引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。通过在几个不同的知识库的角度上对专家模型进行微调，并使用无梯度优化算法进行线性插值，我们有效地找到了一个好的模型权重插值，从而在FETA-Friends上超过了标准的预训练-微调方法。

    

    最近的研究表明，在两个专门的语言模型的权重之间插值可以在任务之间传递知识，但很少有人探索在两个以上模型之间插值，每个模型都有一个不同的知识库。在本文中，我们引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。我们的框架创建了一组多样化的专家语言模型，这些模型是使用预定义的一组源任务进行训练的。接下来，我们对每个专家模型在目标任务上进行微调，从几个不同的知识库的角度来处理目标任务。最后，我们使用无梯度优化算法在模型权重之间进行线性插值，以高效地找到一个好的插值权重。我们在FETA-Friends上展示了该方法的有效性，优于标准的预训练-微调方法。

    Recent work suggests that interpolating between the weights of two specialized language models can transfer knowledge between tasks in a way that multi-task learning cannot. However, very few have explored interpolation between more than two models, where each has a distinct knowledge base. In this paper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new few-sample task transfer approach for open-domain dialogue. Our framework creates a set of diverse expert language models trained using a predefined set of source tasks. Next, we finetune each of the expert models on the target task, approaching the target task from several distinct knowledge bases. Finally, we linearly interpolate between the model weights using a gradient-free-optimization algorithm, to efficiently find a good interpolation weighting. We demonstrate the effectiveness of the method on FETA-Friends outperforming the standard pretrain-finetune approach.
    
[^18]: AI-UPV在EXIST 2023中使用大型语言模型在“学习与分歧”的框架下对性别歧视进行表征

    AI-UPV at EXIST 2023 -- Sexism Characterization Using Large Language Models Under The Learning with Disagreements Regime. (arXiv:2307.03385v1 [cs.CL])

    [http://arxiv.org/abs/2307.03385](http://arxiv.org/abs/2307.03385)

    以学习与分歧的机制为框架，使用大型语言模型进行性别歧视识别和表征的研究，以推动更具包容性和尊重性的在线环境。

    

    随着社交媒体平台的不断影响力增加，开发能够检测性别歧视和其他不尊重和仇恨行为的自动化系统，以促进更具包容性和尊重性的在线环境变得至关重要。然而，考虑到不同的仇恨类别和作者的意图，尤其是在学习与分歧的机制下，这些任务相当具有挑战性。本文描述了AI-UPV团队在CLEF 2023的EXIST（社交网络中的性别歧视识别）实验室中的参与情况。所提出的方法旨在通过直接从具有分歧的数据中进行训练，而不使用任何聚合标签，来处理性别歧视识别和表征的任务。同时，报告了考虑软性和硬性评估的性能。所提出的系统使用大型语言模型（如mBERT和XLM-RoBERTa）和集成策略来进行性别歧视识别和表征。

    With the increasing influence of social media platforms, it has become crucial to develop automated systems capable of detecting instances of sexism and other disrespectful and hateful behaviors to promote a more inclusive and respectful online environment. Nevertheless, these tasks are considerably challenging considering different hate categories and the author's intentions, especially under the learning with disagreements regime. This paper describes AI-UPV team's participation in the EXIST (sEXism Identification in Social neTworks) Lab at CLEF 2023. The proposed approach aims at addressing the task of sexism identification and characterization under the learning with disagreements paradigm by training directly from the data with disagreements, without using any aggregated label. Yet, performances considering both soft and hard evaluations are reported. The proposed system uses large language models (i.e., mBERT and XLM-RoBERTa) and ensemble strategies for sexism identification and 
    
[^19]: 英语隐式篇章关系分类的Transformer模型比较

    A Side-by-side Comparison of Transformers for English Implicit Discourse Relation Classification. (arXiv:2307.03378v1 [cs.CL])

    [http://arxiv.org/abs/2307.03378](http://arxiv.org/abs/2307.03378)

    本研究对七个预训练语言模型进行了直接细调比较，提出了一种针对英语隐式篇章关系分类的新方法，并获得了显著提升的准确度。与之前的报道不同，本研究发现句子级预训练目标失败的情况下，采用了类似规模的PLMs，并且使用了MLM和完全注意机制的模型表现更好。

    

    尽管篇章解析可以帮助多个自然语言处理领域，但对于隐式篇章关系分类，尚未进行全面的语言模型搜索。这阻碍了研究人员充分利用公开可用的模型进行篇章分析。本研究是对七个预训练语言模型的直接细调比较。我们使用了PDTB-3数据集，这是一个流行的篇章关系注释数据集。通过我们的模型搜索，我们将SOTA提升到了0.671的准确度，并获得了新的观察结果。其中一些与之前的报道相反（Shi and Demberg, 2019b），即句子级预训练目标（NSP, SBO, SOP）通常无法产生最佳的隐式篇章关系分类模型。出乎意料的是，具有类似规模的PLMs，并且使用了MLM和完全注意机制，表现更好。

    Though discourse parsing can help multiple NLP fields, there has been no wide language model search done on implicit discourse relation classification. This hinders researchers from fully utilizing public-available models in discourse analysis. This work is a straightforward, fine-tuned discourse performance comparison of seven pre-trained language models. We use PDTB-3, a popular discourse relation annotated dataset. Through our model search, we raise SOTA to 0.671 ACC and obtain novel observations. Some are contrary to what has been reported before (Shi and Demberg, 2019b), that sentence-level pre-training objectives (NSP, SBO, SOP) generally fail to produce the best performing model for implicit discourse relation classification. Counterintuitively, similar-sized PLMs with MLM and full attention led to better performance.
    
[^20]: 缓解任务感知对性别歧视、仇恨言论和有害语言检测的负面迁移问题

    Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection. (arXiv:2307.03377v1 [cs.CL])

    [http://arxiv.org/abs/2307.03377](http://arxiv.org/abs/2307.03377)

    本文提出了一种基于任务感知的方法，用于解决性别歧视、仇恨言论和有害语言检测中的负面迁移问题，并能够减少负面迁移并提高性能。

    

    本文提出了一种新颖的方法来缓解负面迁移问题。在机器学习领域，通常的策略是采用单任务学习方法，训练一个监督模型来解决特定的任务。训练一个强大的模型需要大量的数据和大量的计算资源，这使得在数据不可用或收集成本高的情况下，这种解决方案不可行。因此，另一种基于任务之间信息共享的解决方案已经被开发出来：多任务学习（MTL）。尽管在MTL方面已经有了一些最新的进展，负面迁移问题仍然需要解决。负面迁移是一种现象，当噪声信息在任务之间共享时，会导致性能下降。本文提出了一种基于任务感知概念的新方法来缓解负面迁移问题。所提出的方法能够减少负面迁移，并提高性能。

    This paper proposes a novelty approach to mitigate the negative transfer problem. In the field of machine learning, the common strategy is to apply the Single-Task Learning approach in order to train a supervised model to solve a specific task. Training a robust model requires a lot of data and a significant amount of computational resources, making this solution unfeasible in cases where data are unavailable or expensive to gather. Therefore another solution, based on the sharing of information between tasks, has been developed: Multi-Task Learning (MTL). Despite the recent developments regarding MTL, the problem of negative transfer has still to be solved. Negative transfer is a phenomenon that occurs when noisy information is shared between tasks, resulting in a drop in performance. This paper proposes a new approach to mitigate the negative transfer problem based on the task awareness concept. The proposed approach results in diminishing the negative transfer together with an impro
    
[^21]: 在交叉问答背景下评估语言模型中的偏见态度关联

    Evaluating Biased Attitude Associations of Language Models in an Intersectional Context. (arXiv:2307.03360v1 [cs.CY])

    [http://arxiv.org/abs/2307.03360](http://arxiv.org/abs/2307.03360)

    这篇论文以已建立的文献为基础，量化了英语语言模型中社会群体的情绪关联，并发现语言模型对性别认同、社会阶级和性取向的信号表现出最大的偏见态度。

    

    语言模型是在大规模语料库上训练的，这些语料库中嵌入了心理学中已经记录的隐含偏见。社会群体的情绪关联（愉快/不愉快）决定了社会认知中对群体和概念的偏见态度。在此基础上，我们通过提供一个交叉问答背景的句子模板，量化了英语语言模型中社会群体的情绪关联。我们研究了与年龄、教育、性别、身高、智力、文化素养、种族、宗教、性别、性取向、社会阶级和体重有关的偏见。我们采用概念投影方法通过语言模型的上下文化词向量捕捉情绪关联的子空间。将基于投影的方法调整为量化偏见的嵌入关联测试，我们发现语言模型对性别认同、社会阶级和性取向的信号表现出最大的偏见态度。我们发现最大和表现最好的模型是...

    Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model
    
[^22]: 在联合流畅的ASR和ST中，基于文本对齐的标记级串行输出训练

    Token-Level Serialized Output Training for Joint Streaming ASR and ST Leveraging Textual Alignments. (arXiv:2307.03354v1 [cs.CL])

    [http://arxiv.org/abs/2307.03354](http://arxiv.org/abs/2307.03354)

    本文提出了一种流式Transformer-Transducer，同时生成自动语音识别（ASR）和语音翻译（ST）输出的方法。通过联合的标记级串行输出训练方法，结合现成的文本对齐器，实现了最佳的质量-延迟平衡，并在多语环境下取得了良好的效果。

    

    在实际应用中，用户通常需要同时翻译和转录语音以增强其理解能力，特别是在需要增量生成的流式场景中。本文介绍了一种流式Transformer-Transducer，它利用一个单一的解码器同时生成自动语音识别（ASR）和语音翻译（ST）输出。为了以最小的延迟有效地产生ASR和ST内容，我们提出了一种联合的标记级串行输出训练方法，通过利用现成的文本对齐器交错源词和目标词。在单语（it-en）和多语（{de,es,it}-en）设置下的实验证明，我们的方法实现了最佳的质量-延迟平衡。在平均ASR延迟为1秒和ST延迟为1.3秒的情况下，我们的模型与单独的ASR和ST模型相比，没有降低，甚至提高了输出质量，在多语言情况下，平均WER提高了1.1，BLEU提高了0.4。

    In real-world applications, users often require both translations and transcriptions of speech to enhance their comprehension, particularly in streaming scenarios where incremental generation is necessary. This paper introduces a streaming Transformer-Transducer that jointly generates automatic speech recognition (ASR) and speech translation (ST) outputs using a single decoder. To produce ASR and ST content effectively with minimal latency, we propose a joint token-level serialized output training method that interleaves source and target words by leveraging an off-the-shelf textual aligner. Experiments in monolingual (it-en) and multilingual (\{de,es,it\}-en) settings demonstrate that our approach achieves the best quality-latency balance. With an average ASR latency of 1s and ST latency of 1.3s, our model shows no degradation or even improves output quality compared to separate ASR and ST models, yielding an average improvement of 1.1 WER and 0.4 BLEU in the multilingual case.
    
[^23]: BiPhone:模拟语音学关系模型 L2 文本中的跨语言影响

    BiPhone: Modeling Inter Language Phonetic Influences in Text. (arXiv:2307.03322v1 [cs.CL])

    [http://arxiv.org/abs/2307.03322](http://arxiv.org/abs/2307.03322)

    这篇论文提出了一种模拟跨语言影响的方法，通过挖掘L1和L2之间的音素歧义，生成合成的受干扰的L2文本。通过人工评估和实验结果表明，该方法可以生成可信的受干扰的L2文本，并对流行的语言理解模型造成负面影响。

    

    由于技术不对称性，许多人被迫在自己不擅长的语言中使用网络。这些用户在第二语言(L2)中的书面文本通常包含大量受其母语(L1)影响的错误。我们提出了一种方法，用于挖掘L1和L2对之间的音素歧义(可能导致L1说话者混淆的L2语音)。然后，将这些歧义插入一个生成模型(Bi-Phone)中，用于合成被破坏的L2文本。通过人工评估，我们展示了Bi-Phone生成的破坏是可信的，并且在不同的L1上有广泛的覆盖性。我们还通过使用我们的技术(Phonetically Noised GLUE的FunGLUE)破坏了流行的语言理解基准SuperGLUE，并展示了当前最佳的语言理解模型性能较差。最后，我们还引入了一项新的音素预测预训练任务，帮助字节模型恢复接近SuperGLUE的性能。

    A large number of people are forced to use the Web in a language they have low literacy in due to technology asymmetries. Written text in the second language (L2) from such users often contains a large number of errors that are influenced by their native language (L1). We propose a method to mine phoneme confusions (sounds in L2 that an L1 speaker is likely to conflate) for pairs of L1 and L2. These confusions are then plugged into a generative model (Bi-Phone) for synthetically producing corrupted L2 text. Through human evaluations, we show that Bi-Phone generates plausible corruptions that differ across L1s and also have widespread coverage on the Web. We also corrupt the popular language understanding benchmark SuperGLUE with our technique (FunGLUE for Phonetically Noised GLUE) and show that SoTA language understating models perform poorly. We also introduce a new phoneme prediction pre-training task which helps byte models to recover performance close to SuperGLUE. Finally, we also
    
[^24]: 掩盖罕见领域：针对答案评估的重点间隙问题生成

    Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment. (arXiv:2307.03319v1 [cs.CL])

    [http://arxiv.org/abs/2307.03319](http://arxiv.org/abs/2307.03319)

    这篇论文致力于自动生成重点间隙问题（GFQ），通过定义任务、提出模型并与人工生成问题进行比较，证明了竞争性的性能。

    

    人类交流通常涉及对话者之间的信息差距。例如，在教育对话中，学生通常提供一个不完整的答案，与教师期望的完美答案之间存在差距。成功的对话依赖于老师有效地询问这个差距，从而创建一个丰富和互动的教育经验。我们专注于自动生成这种重点间隙问题（GFQ）的问题。我们定义了任务，强调了一个好的GFQ的关键方面，并提出了一个满足这些要求的模型。最后，我们通过人类注释员对我们生成的问题与人类生成的问题进行了评估，证明了竞争性的性能。

    Human communication often involves information gaps between the interlocutors. For example, in an educational dialogue, a student often provides an answer that is incomplete, and there is a gap between this answer and the perfect one expected by the teacher. Successful dialogue then hinges on the teacher asking about this gap in an effective manner, thus creating a rich and interactive educational experience. We focus on the problem of generating such gap-focused questions (GFQs) automatically. We define the task, highlight key desired aspects of a good GFQ, and propose a model that satisfies these. Finally, we provide an evaluation by human annotators of our generated questions compared against human generated ones, demonstrating competitive performance.
    
[^25]: InfoSync：跨多语言半结构化表格的信息同步

    InfoSync: Information Synchronization across Multilingual Semi-structured Tables. (arXiv:2307.03313v1 [cs.CL])

    [http://arxiv.org/abs/2307.03313](http://arxiv.org/abs/2307.03313)

    该论文提出了一个名为InfoSync的新数据集和一种两步方法，用于跨语言半结构化表格的信息同步。通过信息对齐和信息更新，该方法在InfoSync数据集上获得了高效的性能，验证了其有效性。

    

    跨语言半结构化数据的信息同步是具有挑战性的。例如，应该跨语言同步维基百科表格。为解决这个问题，我们引入了一个新的数据集InfoSyncC，并提出了一种两步方法实现表格同步。InfoSync包含了14种语言的10万个以实体为中心的表格（维基百科Infoboxes），其中一部分（3.5K对）是手动注释的。提出的方法包括1）信息对齐来映射行和2）信息更新来更新跨多语言表格中对齐表格中的缺失/过时信息。在InfoSync上进行评估时，信息对齐实现了87.91的F1得分（英文<->非英文）。为了评估信息更新，我们对603个表格对的Infoboxes进行了人工辅助的维基百科编辑。我们的方法在维基百科上取得了77.28%的接受率，显示出了方法的有效性。

    Information Synchronization of semi-structured data across languages is challenging. For instance, Wikipedia tables in one language should be synchronized across languages. To address this problem, we introduce a new dataset InfoSyncC and a two-step method for tabular synchronization. InfoSync contains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages, of which a subset (3.5K pairs) are manually annotated. The proposed method includes 1) Information Alignment to map rows and 2) Information Update for updating missing/outdated information for aligned tables across multilingual tables. When evaluated on InfoSync, information alignment achieves an F1 score of 87.91 (en <-> non-en). To evaluate information updation, we perform human-assisted Wikipedia edits on Infoboxes for 603 table pairs. Our approach obtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of the proposed method.
    
[^26]: 用于端到端功能性言语处理任务的Gamma音图表示：语音识别、说话人识别和可理解性评估

    Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment. (arXiv:2307.03296v1 [eess.AS])

    [http://arxiv.org/abs/2307.03296](http://arxiv.org/abs/2307.03296)

    该研究提出了一种使用Gamma音图表示语音的方法，通过卷积神经网络实现了语音识别、说话人识别和可理解性评估的功能。

    

    发音障碍是一种影响人类言语系统并降低个人发音质量和可理解性的残疾。由于这种影响，常规的言语处理系统无法在受损的言语上正常工作。这种残疾通常与身体残疾相关。因此，设计一个能够通过接收语音命令在智能家居中执行一些任务的系统，将是一个重要的成就。在这项工作中，我们引入了Gamma音图作为一种有效的方法来表示具有区分性细节的音频文件，该方法用作卷积神经网络的输入。换句话说，我们将每个语音文件转换成图像，并提出了图像识别系统来对不同场景下的语音进行分类。所提出的卷积神经网络基于预训练的Alexnet的迁移学习方法。在这项研究中，评估了所提出系统在语音识别、说话人识别和可理解性评估方面的效率。

    Dysarthria is a disability that causes a disturbance in the human speech system and reduces the quality and intelligibility of a person's speech. Because of this effect, the normal speech processing systems can not work properly on impaired speech. This disability is usually associated with physical disabilities. Therefore, designing a system that can perform some tasks by receiving voice commands in the smart home can be a significant achievement. In this work, we introduce gammatonegram as an effective method to represent audio files with discriminative details, which is used as input for the convolutional neural network. On the other word, we convert each speech file into an image and propose image recognition system to classify speech in different scenarios. Proposed CNN is based on the transfer learning method on the pre-trained Alexnet. In this research, the efficiency of the proposed system for speech recognition, speaker identification, and intelligibility assessment is evaluat
    
[^27]: 不是性暗示，是教育。在TikTok视频中分离性教育和暗示性内容。

    It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos. (arXiv:2307.03274v1 [cs.CV])

    [http://arxiv.org/abs/2307.03274](http://arxiv.org/abs/2307.03274)

    在TikTok视频中，我们引入了一个名为SexTok的数据集，用于区分性暗示内容和虚拟性教育视频。我们发现这是一个具有挑战性但可学习的任务。

    

    我们引入了一个名为SexTok的多模式数据集，其中包含被标记为性暗示（从注释者的角度来看），性教育内容或两者都不是的TikTok视频。这样的数据集是为了解决在TikTok上区分性暗示内容和虚拟性教育视频的挑战。儿童接触性暗示的视频已被证明对他们的发展有不利影响。与此同时，对于LGBTQIA+社区更相关的虚拟性教育非常有价值。平台的当前系统删除或惩罚这两种类型的视频，尽管它们有不同的目的。我们的数据集包含视频URL，并且还有音频转录。为了验证其重要性，我们探索了两个基于转换器的模型来对视频进行分类。我们的初步结果表明区分这些类型的视频是可学习但具有挑战性的任务。这些实验表明...

    We introduce SexTok, a multi-modal dataset composed of TikTok videos labeled as sexually suggestive (from the annotator's point of view), sex-educational content, or neither. Such a dataset is necessary to address the challenge of distinguishing between sexually suggestive content and virtual sex education videos on TikTok. Children's exposure to sexually suggestive videos has been shown to have adversarial effects on their development. Meanwhile, virtual sex education, especially on subjects that are more relevant to the LGBTQIA+ community, is very valuable. The platform's current system removes or penalizes some of both types of videos, even though they serve different purposes. Our dataset contains video URLs, and it is also audio transcribed. To validate its importance, we explore two transformer-based models for classifying the videos. Our preliminary results suggest that the task of distinguishing between these types of videos is learnable but challenging. These experiments sugge
    
[^28]: 视觉语言转换器：一项调查

    Vision Language Transformers: A Survey. (arXiv:2307.03254v1 [cs.CV])

    [http://arxiv.org/abs/2307.03254](http://arxiv.org/abs/2307.03254)

    视觉语言转换器是将预训练的transformer架构应用于视觉语言建模的研究领域，通过迁移学习，在同时进行视觉和语言任务中取得了显著改进。

    

    视觉语言任务，如回答关于图像的问题或生成描述图像的标题，是计算机难以完成的任务。最近的研究将预训练的transformer架构应用于视觉语言建模。相比以前的视觉语言模型，transformer模型在性能和多功能性方面有很大提高。它们通过在大型通用数据集上进行预训练，并在架构和参数值上进行微小改变后，将学习转移到新任务中。这种迁移学习已成为自然语言处理和计算机视觉中的标准建模实践。视觉语言转换器承诺在需要同时进行视觉和语言的任务中产生类似的进展。本文对目前可用的视觉语言转换器模型的研究进行了广泛综合，并对其优势进行了分析。

    Vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform. A relatively recent body of research has adapted the pretrained transformer architecture introduced in \citet{vaswani2017attention} to vision language modeling. Transformer models have greatly improved performance and versatility over previous vision language models. They do so by pretraining models on a large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks which require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strength
    
[^29]: PREADD: 控制性文本生成的前缀自适应解码方法

    PREADD: Prefix-Adaptive Decoding for Controlled Text Generation. (arXiv:2307.03214v1 [cs.CL])

    [http://arxiv.org/abs/2307.03214](http://arxiv.org/abs/2307.03214)

    PREADD是一种前缀自适应解码方法，用于控制性文本生成，相比现有方法，PREADD不需要外部模型，能够实现对任何属性的正向和负向控制，并在多个任务上表现出较高的性能提升。

    

    我们提出了一种名为PREADD的前缀自适应解码方法，用于控制性文本生成。与现有的使用辅助专家模型来控制属性的方法不同，PREADD不需要外部模型，而是依靠线性组合多个提示的输出概率来实现。具体来说，PREADD通过比较使用原始提示生成的输出概率和使用前缀前置提示生成的输出概率来实现对任何由前缀封装的属性的正向和负向控制。我们在三个任务上评估了PREADD，包括毒性输出减轻、性别偏见减少和情感控制，并发现PREADD在每个任务的主要指标上相对收益比提示基线和辅助专家控制方法高出12%或更多。

    We propose Prefix-Adaptive Decoding (PREADD), a flexible method for controlled text generation. Unlike existing methods that use auxiliary expert models to control for attributes, PREADD does not require an external model, instead relying on linearly combining output logits from multiple prompts. Specifically, PREADD contrasts the output logits generated using a raw prompt against those generated using a prefix-prepended prompt, enabling both positive and negative control with respect to any attribute encapsulated by the prefix. We evaluate PREADD on three tasks -- toxic output mitigation, gender bias reduction, and sentiment control -- and find that PREADD outperforms not only prompting baselines, but also an auxiliary-expert control method, by 12% or more in relative gain on our main metrics for each task.
    
[^30]: 从语言模型中提取多值关系

    Extracting Multi-valued Relations from Language Models. (arXiv:2307.03122v1 [cs.CL])

    [http://arxiv.org/abs/2307.03122](http://arxiv.org/abs/2307.03122)

    该论文研究了从预训练语言模型中提取多值关系的问题，并通过排名和选择任务的方法解决了这个问题。结果表明，选择具有特定关系阈值以上的对象可以达到49.5%的F1得分，这对于将语言模型应用于多值槽位填充任务而言是具有挑战性的。该研究为从潜在语言表示中提取关系知识开辟了进一步研究的道路。

    

    广泛使用预训练语言模型（LMs）的潜在语言表示表明它们是一种有前景的结构化知识来源。然而，现有方法仅关注每个主题-关系对中的单个对象，尽管通常有多个对象是正确的。为了克服这个限制，我们分析这些表示以了解它们产生多对象关系知识的潜力。我们将该问题制定为一个排名-选择任务。对于排名候选对象，我们评估现有的提示技术并提出了融入领域知识的新技术。在选择方法中，我们发现选择具有高于学习到的关系特定阈值的对象可以达到49.5%的F1得分。我们的结果突显了使用LMs进行多值槽位填充任务的困难，并为从潜在语言表示中提取关系知识的进一步研究铺平了道路。

    The widespread usage of latent language representations via pre-trained language models (LMs) suggests that they are a promising source of structured knowledge. However, existing methods focus only on a single object per subject-relation pair, even though often multiple objects are correct. To overcome this limitation, we analyze these representations for their potential to yield materialized multi-object relational knowledge. We formulate the problem as a rank-then-select task. For ranking candidate objects, we evaluate existing prompting techniques and propose new ones incorporating domain knowledge. Among the selection methods, we find that choosing objects with a likelihood above a learned relation-specific threshold gives a 49.5% F1 score. Our results highlight the difficulty of employing LMs for the multi-valued slot-filling task and pave the way for further research on extracting relational knowledge from latent language representations.
    
[^31]: 抑郁症对语音特征的相关性产生影响: 通过改进特征相关性来提高抑郁症检测的速度和性能

    The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection. (arXiv:2307.02892v1 [cs.CL])

    [http://arxiv.org/abs/2307.02892](http://arxiv.org/abs/2307.02892)

    本研究发现抑郁症会改变从语音中提取的特征之间的相关性，同时利用这种洞察力可以通过改进特征相关性来提高抑郁症检测器的训练速度和性能。

    

    本研究表明，抑郁症会改变从语音中提取的特征之间的相关性。此外，它还表明利用这样的洞察力可以提高基于SVM和LSTMs的抑郁症检测器的训练速度和性能。实验是在Androids Corpus上进行的，这是一个涉及112名说话者的公开数据集，其中包括58名由专业精神病学家诊断为抑郁症的人。结果显示，实验中使用的模型在训练速度和性能方面都得到了改善，与使用特征向量相比，使用特征相关性矩阵作为输入时，错误率相对减少了23.1％到26.6％，具体取决于模型。可能的解释是，在抑郁的说话者中，特征相关性矩阵似乎更加多变。相应地，这种现象可以被视为抑郁症的一个标记。

    This work shows that depression changes the correlation between features extracted from speech. Furthermore, it shows that using such an insight can improve the training speed and performance of depression detectors based on SVMs and LSTMs. The experiments were performed over the Androids Corpus, a publicly available dataset involving 112 speakers, including 58 people diagnosed with depression by professional psychiatrists. The results show that the models used in the experiments improve in terms of training speed and performance when fed with feature correlation matrices rather than with feature vectors. The relative reduction of the error rate ranges between 23.1% and 26.6% depending on the model. The probable explanation is that feature correlation matrices appear to be more variable in the case of depressed speakers. Correspondingly, such a phenomenon can be thought of as a depression marker.
    
[^32]: 大规模语言模型对数据科学教育应该做什么？

    What Should Data Science Education Do with Large Language Models?. (arXiv:2307.02792v1 [cs.CY])

    [http://arxiv.org/abs/2307.02792](http://arxiv.org/abs/2307.02792)

    大型语言模型（LLM）正在改变数据科学家的责任和数据科学教育模式，从动手编码和标准分析转变为评估和管理自动化AI执行的分析。这种转变要求数据科学教育注重培养学生的多样化技能，如创造力、批判性思维和AI引导的编程。

    

    大型语言模型（LLM），如ChatGPT等的快速发展正在改变数据科学和统计学。这些最先进的工具可以简化复杂的流程，从而重塑了数据科学家的角色。我们认为LLM正在转变数据科学家的责任，将他们的重点从动手编码、数据整理和进行标准分析转变为评估和管理这些自动化AI执行的分析。这种角色的演变类似于从软件工程师转变为产品经理。我们在本文中使用LLM在数据科学案例研究中说明了这种转变。这些发展要求数据科学教育有意义地发展。教育方法现在必须更加注重培养学生的多样化技能，如LLM启发的创造力、批判性思维、AI引导的编程。LLM还可以在课堂上起到重要的作用，作为互动式教学和...

    The rapid advances of large language models (LLMs), such as ChatGPT, are revolutionizing data science and statistics. These state-of-the-art tools can streamline complex processes. As a result, it reshapes the role of data scientists. We argue that LLMs are transforming the responsibilities of data scientists, shifting their focus from hands-on coding, data-wrangling and conducting standard analyses to assessing and managing analyses performed by these automated AIs. This evolution of roles is reminiscent of the transition from a software engineer to a product manager. We illustrate this transition with concrete data science case studies using LLMs in this paper. These developments necessitate a meaningful evolution in data science education. Pedagogy must now place greater emphasis on cultivating diverse skillsets among students, such as LLM-informed creativity, critical thinking, AI-guided programming. LLMs can also play a significant role in the classroom as interactive teaching and
    
[^33]: 大型语言模型在VNHSGE英文数据集上的性能比较：OpenAI ChatGPT、Microsoft Bing Chat和Google Bard

    Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard. (arXiv:2307.02288v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.02288](http://arxiv.org/abs/2307.02288)

    本文对OpenAI ChatGPT、Microsoft Bing Chat和Google Bard这三种大型语言模型在VNHSGE英文数据集上的性能进行了比较，结果显示Bing Chat优于ChatGPT和Bard。研究结果还表明，这些语言模型在英语语言教育中具有潜力，可以作为高中英语教学和学习的有效工具。

    

    本文介绍了三种大型语言模型（LLMs），分别是OpenAI ChatGPT、Microsoft Bing Chat和Google Bard，在VNHSGE英文数据集上的性能比较。结果表明，Bing Chat优于ChatGPT和Bard。因此，在ChatGPT尚未在越南正式发布之前，Bing Chat和Bard可以替代它。研究结果还表明，ChatGPT、Bing Chat和Bard在英语语言能力方面超过了越南学生。本研究的发现有助于理解LLMs在英语语言教育中的潜力。ChatGPT、Bing Chat和Bard的出色表现证明了它们作为高中英语教学和学习的有效工具的潜力。

    This paper presents a performance comparison of three large language models (LLMs), namely OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard, on the VNHSGE English dataset. The results show that BingChat is better than ChatGPT and Bard. Therefore, BingChat and Bard can replace ChatGPT while ChatGPT is not yet officially available in Vietnam. The results also indicate that ChatGPT, Bing Chat, and Bard outperform Vietnamese students in English language proficiency. The findings of this study contribute to the understanding of the potential of LLMs in English language education. The remarkable performance of ChatGPT, Bing Chat, and Bard demonstrates their potential as effective tools for teaching and learning English at the high school level.
    
[^34]: LyricWhiz: 通过向ChatGPT耳语进行鲁棒的多语言零射击歌词转录

    LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT. (arXiv:2306.17103v1 [cs.CL])

    [http://arxiv.org/abs/2306.17103](http://arxiv.org/abs/2306.17103)

    LyricWhiz是一种鲁棒、多语言、零射击的自动歌词转录方法，通过使用Whisper作为"耳朵"和GPT-4作为"大脑"，它在各种数据集上实现了最先进的性能，同时还实现了在多种语言中进行歌词转录的能力，并创建了第一个大规模多语言歌词转录数据集。

    

    我们介绍了一种名为LyricWhiz的鲁棒、多语言、零射击的自动歌词转录方法，该方法在各种歌词转录数据集上实现了最先进的性能，即使在具有挑战性的流派如摇滚和金属中也是如此。我们的全新、无需训练的方法利用了Whisper，一种弱监督的鲁棒语音识别模型，以及GPT-4，当今最性能卓越的基于聊天的大型语言模型。在该方法中，Whisper充当“耳朵”，负责转录语音，而GPT-4则作为“大脑”，作为一种具有强大性能的上下文输出选择和校正的注释器。我们的实验结果表明，与现有方法相比，LyricWhiz在英语中显著降低了词错误率，并且可以有效地转录多种语言的歌词。此外，我们使用LyricWhiz创建了第一个具有CC-BY-NC-SA版权许可的公开可用的大规模多语言歌词转录数据集，基于MTG-Jamendo，并提供了h

    We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal. Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model. In the proposed method, Whisper functions as the "ear" by transcribing the audio, while GPT-4 serves as the "brain," acting as an annotator with a strong performance for contextualized output selection and correction. Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a h
    
[^35]: KoLA: 认真基准大型语言模型的世界知识

    KoLA: Carefully Benchmarking World Knowledge of Large Language Models. (arXiv:2306.09296v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.09296](http://arxiv.org/abs/2306.09296)

    本研究提出了一个针对大型语言模型的知识导向评估基准 (KoLA)，通过模仿人类认知构建了四级知识相关能力的分类体系，并使用维基百科和新兴语料库进行评估。这个基准旨在全面、公正和实用地评估LLM的能力，以处理未见数据和不断发展的知识。

    

    大型语言模型 (LLM) 的前所未有的性能需要改进评估。我们认为，除了探索LLM能力的广度之外，细致和深思熟虑的设计对于全面、公正和实用的评估是必要的。鉴于全球知识对LLM的重要性，我们构建了一个以知识为导向的LLM评估基准(KoLA)，其中我们精心设计了三个关键因素：(1) 对于能力建模，我们模仿人类认知构建了一个四级知识相关能力的分类体系，涵盖了19个任务。(2) 对于数据，为了确保公正比较，我们使用了维基百科作为LLM普遍预训练的语料库，同时还使用了持续收集的新兴语料库，旨在评估处理未见数据和不断发展的知识的能力。(3) 对于评估标准，我们采用了对比系统，包括整体标准分数，以实现在任务和模型之间更好的数值比较性，以及独特的自对照指标。

    The unprecedented performance of large language models (LLMs) necessitates improvements in evaluations. Rather than merely exploring the breadth of LLM abilities, we believe meticulous and thoughtful designs are essential to thorough, unbiased, and applicable evaluations. Given the importance of world knowledge to LLMs, we construct a Knowledge-oriented LLM Assessment benchmark (KoLA), in which we carefully design three crucial factors: (1) For ability modeling, we mimic human cognition to form a four-level taxonomy of knowledge-related abilities, covering $19$ tasks. (2) For data, to ensure fair comparisons, we use both Wikipedia, a corpus prevalently pre-trained by LLMs, along with continuously collected emerging corpora, aiming to evaluate the capacity to handle unseen data and evolving knowledge. (3) For evaluation criteria, we adopt a contrastive system, including overall standard scores for better numerical comparability across tasks and models and a unique self-contrast metric f
    
[^36]: 基于深度学习的德语胸部X射线医学报告自动标注

    Automated Labeling of German Chest X-Ray Radiology Reports using Deep Learning. (arXiv:2306.05997v1 [cs.CL])

    [http://arxiv.org/abs/2306.05997](http://arxiv.org/abs/2306.05997)

    本研究使用基于深度学习的CheXpert标签预测模型进行弱监督，显着优于基于规则的模型，在自动标注德语胸部X射线医学报告方面具有潜在价值。

    

    世界范围内放射科医生短缺，深度学习模型作为临床决策支持系统的一部分，提供了解决这一问题的有希望的解决方案。然而，培训这样的模型往往需要耗费昂贵和耗时的手动标记大型数据集。从放射学报告中自动提取标签可以减少获得标记数据集所需的时间，但由于语义上相似的词和缺少注释数据而任务具有挑战性。在这项工作中，我们探讨了基于规则的标签器的弱监督深度学习标签预测模型的潜力。我们提出了一种基于深度学习的CheXpert标签预测模型，该模型在由基于规则的德语CheXpert模型标记的报告上进行了预训练，并在少量手动标记的报告数据集上进行了微调。我们的结果证明了我们的方法的有效性，在所有三个任务上显着优于基于规则的模型。我们的发现突出了使用深度学习技术的优点。

    Radiologists are in short supply globally, and deep learning models offer a promising solution to address this shortage as part of clinical decision-support systems. However, training such models often requires expensive and time-consuming manual labeling of large datasets. Automatic label extraction from radiology reports can reduce the time required to obtain labeled datasets, but this task is challenging due to semantically similar words and missing annotated data. In this work, we explore the potential of weak supervision of a deep learning-based label prediction model, using a rule-based labeler. We propose a deep learning-based CheXpert label prediction model, pre-trained on reports labeled by a rule-based German CheXpert model and fine-tuned on a small dataset of manually labeled reports. Our results demonstrate the effectiveness of our approach, which significantly outperformed the rule-based model on all three tasks. Our findings highlight the benefits of employing deep learni
    
[^37]: MISGENDERED：大型语言模型在理解代词方面的局限性

    MISGENDERED: Limits of Large Language Models in Understanding Pronouns. (arXiv:2306.03950v1 [cs.CL])

    [http://arxiv.org/abs/2306.03950](http://arxiv.org/abs/2306.03950)

    本文全面评估了广受欢迎的语言模型正确使用英语性别中立代词和新代词的能力，以及考虑到非二元性别身份的重要性，引入了MISGENDERED框架，用于评估大型语言模型正确使用首选代词的能力。

    

    内容警告:本文包含可能令人不悦和潜在引发情感问题的错误称呼和抹杀的例子. 性别偏见在语言技术中被广泛研究，但研究大多限于二元性别范式。考虑非二元性别身份也是至关重要的，因为排除他们可能会进一步伤害这个已经被边缘化的群体。在本文中，我们全面评估了广受欢迎的语言模型正确使用英语性别中立代词（例如单数they、them）和新代词（例如ze、xe、thon）的能力，这些代词是由那些性别认同不为二元性别所代表的个体使用。我们引入了MISGENDERED，一个用于评估大型语言模型正确使用首选代词的框架，它包括(i)陈述个体代词的实例，后面跟着一个缺少代词的句子，以及(ii)评估掩盖和自回归语言生成系统的实验设定。

    Content Warning: This paper contains examples of misgendering and erasure that could be offensive and potentially triggering.  Gender bias in language technologies has been widely studied, but research has mostly been restricted to a binary paradigm of gender. It is essential also to consider non-binary gender identities, as excluding them can cause further harm to an already marginalized group. In this paper, we comprehensively evaluate popular language models for their ability to correctly use English gender-neutral pronouns (e.g., singular they, them) and neo-pronouns (e.g., ze, xe, thon) that are used by individuals whose gender identity is not represented by binary pronouns. We introduce MISGENDERED, a framework for evaluating large language models' ability to correctly use preferred pronouns, consisting of (i) instances declaring an individual's pronoun, followed by a sentence with a missing pronoun, and (ii) an experimental setup for evaluating masked and auto-regressive languag
    
[^38]: BigTranslate：通过多语言翻译增强超过100种语言的大型语言模型

    BigTranslate: Augmenting Large Language Models with Multilingual Translation Capability over 100 Languages. (arXiv:2305.18098v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18098](http://arxiv.org/abs/2305.18098)

    BigTranslate是一个基于LLaMA的大型语言模型，在原有的基础上通过继续训练和指导微调实现了对100多种语言的多语言翻译能力，初步实验结果显示其性能接近于ChatGPT和谷歌翻译。

    

    大型语言模型（LLM）在各种自然语言之间展示了令人期待的翻译性能。然而，许多LLM，特别是开源的，比如BLOOM和LLaMA，都以英语为主导，并且只支持几十种自然语言，使得LLM在语言翻译方面的潜力不太被探索。在这项工作中，我们介绍了BigTranslate，它采用了LLaMA模型，该模型仅覆盖20种语言，并在100多种语言上增强了其多语言翻译能力。BigTranslate是建立在LLaMA-13B之上，并通过三个步骤进行优化。首先，我们利用大规模的中文单语数据继续训练LLaMA。其次，我们使用覆盖102种自然语言的大规模平行数据集继续训练模型。第三，我们使用多语言翻译指令对基础模型进行指导微调，得到了我们的BigTranslate模型。多语言翻译的初步实验结果显示，BigTranslate与ChatGPT和谷歌翻译的性能相当。

    Large language models (LLMs) demonstrate promising translation performance among various natural languages. However, many LLMs especially the open-sourced ones, such as BLOOM and LLaMA, are English-dominant and support only dozens of natural languages, making the potential of LLMs on language translation less explored. In this work, we present BigTranslate which adapts LLaMA that covers only 20 languages and enhances it with multilingual translation capability on more than 100 languages. BigTranslate is built upon LLaMA-13B and it is optimized in three steps. First, we continue training LLaMA with massive Chinese monolingual data. Second, we continue training the model with a large-scale parallel dataset that covers 102 natural languages. Third, we instruct-tune the foundation model with multilingual translation instructions, leading to our BigTranslate model. The preliminary experiments on multilingual translation show that BigTranslate performs comparably with ChatGPT and Google Tran
    
[^39]: 语言模型是有限实用说话者

    Language Models are Bounded Pragmatic Speakers. (arXiv:2305.17760v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17760](http://arxiv.org/abs/2305.17760)

    本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。经过人类反馈的强化学习微调的大型语言模型具有概念上类似于 快与慢思考模型的思维模型，而这种思维模型被归因于人类。此研究凸显了采用认知概率建模方法对语言模型的理解、评估和推进的价值。

    

    本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。特别地，我们展示了经过人类反馈的强化学习微调的大型语言模型（Ouyang等人，2022）具有概念上类似于 快与慢思考模型（Kahneman，2011）的思维模型，而这种思维模型被心理学家们归因于人类。我们讨论了从人类反馈中的强化学习作为快与慢思考模型的局限性，并提出了扩展这个框架的途径。本研究实质上凸显了采用认知概率建模方法来获得对语言模型的理解、评估和推进方面的深刻见解的价值。

    How do language models "think"? This paper formulates a probabilistic cognitive model called the bounded pragmatic speaker, which can characterize the operation of different variations of language models. Specifically, we demonstrate that large language models fine-tuned with reinforcement learning from human feedback (Ouyang et al., 2022) embody a model of thought that conceptually resembles a fast-and-slow model (Kahneman, 2011), which psychologists have attributed to humans. We discuss the limitations of reinforcement learning from human feedback as a fast-and-slow model of thought and propose avenues for expanding this framework. In essence, our research highlights the value of adopting a cognitive probabilistic modeling approach to gain insights into the comprehension, evaluation, and advancement of language models.
    
[^40]: 比你想的要弱：对弱监督学习的批判性研究

    Weaker Than You Think: A Critical Look at Weakly Supervised Learning. (arXiv:2305.17442v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17442](http://arxiv.org/abs/2305.17442)

    这篇论文批判性地研究了弱监督学习方法，发现这些方法的好处被高估了，大多数优势可以通过简单地利用干净的训练数据实现。

    

    弱监督学习是一种在资源有限的情况下训练机器学习模型的流行方法。它允许使用从各种弱标注源获得的嘈杂标注来训练模型，而不是要求高质量但昂贵的人工标注。最近，许多精巧的方法已经被提出来在标签噪声下进行强大的训练，并报告了令人印象深刻的结果。在本文中，我们重新审视了这些方法的设置，并发现这些方法所带来的好处被显著高估了。具体来说，我们发现现有的弱监督学习方法的成功在很大程度上依赖于可用的干净验证样本，正如我们所展示的，我们可以通过简单地在其上进行训练来更有效地利用这些干净标签。在使用这些干净标签进行训练后，使用这些精巧方法的优势大部分被消除了。即使将可用的干净数据的大小减少到每类只有五个样本，这仍然成立。

    Weakly supervised learning is a popular approach for training machine learning models in low-resource settings. Instead of requesting high-quality yet costly human annotations, it allows training models with noisy annotations obtained from various weak sources. Recently, many sophisticated approaches have been proposed for robust training under label noise, reporting impressive results. In this paper, we revisit the setup of these approaches and find that the benefits brought by these approaches are significantly overestimated. Specifically, we find that the success of existing weakly supervised learning approaches heavily relies on the availability of clean validation samples which, as we show, can be leveraged much more efficiently by simply training on them. After using these clean labels in training, the advantages of using these sophisticated approaches are mostly wiped out. This remains true even when reducing the size of the available clean data to just five samples per class, m
    
[^41]: 未见过的语言对中的混合代码文本合成

    Code-Switched Text Synthesis in Unseen Language Pairs. (arXiv:2305.16724v1 [cs.CL])

    [http://arxiv.org/abs/2305.16724](http://arxiv.org/abs/2305.16724)

    本文介绍了GLOSS模型，旨在解决在缺乏训练数据的情况下合成混合代码文本的问题，并且可以推广到更广泛的语言对。该模型在四个未见过的语言对上的实验中优于其他基线模型和在单语文本上运行的生成模型。

    

    现有的针对混合代码文本合成的研究大多需要在目标语言对中的混合代码文本上进行训练，这限制了模型在缺乏混合代码数据的情况下的部署。在本文中，我们研究了在缺乏训练数据的情况下合成混合代码文本的问题。我们介绍了GLOSS，这是一个建立在预训练多语言机器翻译模型（PMMTM）之上，并带有额外的代码切换模块的模型。这个模块，无论是适配器还是额外的前缀，在训练过程中从混合代码数据中学习代码切换模式，而GLOSS的主要组成部分PMMTM被冻结。我们只调整代码切换模块的设计，防止模型过度拟合针对混合代码训练数据的约束。因此，GLOSS表现出了跨更广泛的语言对进行归纳和合成混合代码文本的能力。此外，我们还开发了一种基于目标语言单语文本的自训练算法，以提高模型性能。我们对四个未见过的语言对进行的实验证明，GLOSS优于其他从具有混合代码数据的语言对中调整的模型和在单语文本上运行的生成模型等多个基线模型。

    Existing efforts on text synthesis for code-switching mostly require training on code-switched texts in the target language pairs, limiting the deployment of the models to cases lacking code-switched data. In this work, we study the problem of synthesizing code-switched texts for language pairs absent from the training data. We introduce GLOSS, a model built on top of a pre-trained multilingual machine translation model (PMMTM) with an additional code-switching module. This module, either an adapter or extra prefixes, learns code-switching patterns from code-switched data during training, while the primary component of GLOSS, i.e., the PMMTM, is frozen. The design of only adjusting the code-switching module prevents our model from overfitting to the constrained training data for code-switching. Hence, GLOSS exhibits the ability to generalize and synthesize code-switched texts across a broader spectrum of language pairs. Additionally, we develop a self-training algorithm on target langu
    
[^42]: 在大语言模型时代评估开放领域问答

    Evaluating Open-Domain Question Answering in the Era of Large Language Models. (arXiv:2305.06984v1 [cs.CL])

    [http://arxiv.org/abs/2305.06984](http://arxiv.org/abs/2305.06984)

    本文评估了开放领域问答中的大语言模型，发现词汇匹配作为评估方法在这些模型中的作用有限，提出了一种手动评估方法，并发现其中一个零-shot模型的性能大幅度提升。

    

    词汇匹配仍是开放领域问答（QA）的事实评估方法。然而，当一个合理的候选答案未出现在金标准答案列表中时，词汇匹配完全失败，随着我们从抽取模型转向生成模型，这种情况越来越普遍。大语言模型（LLMs）在QA中的最近成功加剧了词汇匹配的失败，因为候选答案变得更长，因此与金标准答案的匹配变得更加具有挑战性。缺乏准确的评估，开放领域QA的真正进展仍然未知。本文通过在NQ-open的一个子集上手动评估各种开放领域QA模型（包括LLMs）的答案进行了彻底分析。我们的评估揭示，尽管所有模型的真实性能被显着低估，但InstructGPT（零-shot）LLM的性能增加了近60％，使其与现有的顶级模型并驾齐驱，而I

    Lexical matching remains the de facto evaluation method for open-domain question answering (QA). Unfortunately, lexical matching fails completely when a plausible candidate answer does not appear in the list of gold answers, which is increasingly the case as we shift from extractive to generative models. The recent success of large language models (LLMs) for QA aggravates lexical matching failures since candidate answers become longer, thereby making matching with the gold answers even more challenging. Without accurate evaluation, the true progress in open-domain QA remains unknown. In this paper, we conduct a thorough analysis of various open-domain QA models, including LLMs, by manually evaluating their answers on a subset of NQ-open, a popular benchmark. Our assessments reveal that while the true performance of all models is significantly underestimated, the performance of the InstructGPT (zero-shot) LLM increases by nearly +60%, making it on par with existing top models, and the I
    
[^43]: 评估信息检索的嵌入式API

    Evaluating Embedding APIs for Information Retrieval. (arXiv:2305.06300v1 [cs.IR])

    [http://arxiv.org/abs/2305.06300](http://arxiv.org/abs/2305.06300)

    本篇论文旨在通过对语义嵌入API在实际检索场景中的分析,为从业者和研究人员找到适当的服务。结果表明，在英语上使用API重新排名BM25的结果是一种预算友好的最优做法。

    

    语言模型不断增大使得其普及化成为了一项挑战，因此许多公司和初创企业通过API向社区提供大型语言模型的访问权限。其中一个适用于密集检索的特定API是语义嵌入式API，其可构建给定文本的向量表示。在拥有越来越多API的情况下，本文旨在分析在实际检索场景中语义嵌入式API以帮助从业者和研究人员根据他们的需求找到适当的服务。具体而言，我们希望调查现有API在领域泛化和多语言检索方面的能力。为此，我们在两个标准基准BEIR和MIRACL上评估了嵌入式API。我们发现，使用API重新排名BM25结果是一种预算友好的方法，并且在英语上最有效，与标准做法即作为第一阶段检索器不同。

    The ever-increasing size of language models curtails their widespread access to the community, thereby galvanizing many companies and startups into offering access to large language models through APIs. One particular API, suitable for dense retrieval, is the semantic embedding API that builds vector representations of a given text. With a growing number of APIs at our disposal, in this paper, our goal is to analyze semantic embedding APIs in realistic retrieval scenarios in order to assist practitioners and researchers in finding suitable services according to their needs. Specifically, we wish to investigate the capabilities of existing APIs on domain generalization and multilingual retrieval. For this purpose, we evaluate the embedding APIs on two standard benchmarks, BEIR, and MIRACL. We find that re-ranking BM25 results using the APIs is a budget-friendly approach and is most effective on English, in contrast to the standard practice, i.e., employing them as first-stage retrievers
    
[^44]: ESPnet-ST-v2：多功能口语翻译工具包

    ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit. (arXiv:2304.04596v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2304.04596](http://arxiv.org/abs/2304.04596)

    ESPnet-ST-v2是一个开源的多功能口语翻译工具包，支持多种翻译任务，采用了先进的架构和技术，具有非常高的性能表现。

    

    ESPnet-ST-v2是一个开源的口语翻译工具包，支持离线语音到文本翻译（ST）、同步语音到文本翻译（SST）和离线语音到语音翻译（S2ST）。与其他开源口语翻译工具包不同的是，ESPnet-ST-v2采用了许多先进的架构，包括转录器、混合CTC/attention、多解码器、时间同步分块CTC/attention、Translatotron模型和直接离散单元模型。

    ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) -- each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at https://github.com/espnet/espnet.
    
[^45]: 基于联邦学习的干净和攻击情景下的多语言表情符号预测

    Federated Learning Based Multilingual Emoji Prediction In Clean and Attack Scenarios. (arXiv:2304.01005v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.01005](http://arxiv.org/abs/2304.01005)

    本文提出了一种基于联邦学习的多语言表情符号预测方法，在干净或攻击情境下均有效，同时保护了用户数据隐私。

    

    联邦学习是机器学习社区中一个日益增长的领域，由于其分散和私密的设计而得到发展。联邦学习中的模型训练分布在多个客户端上，从而提供了大量客户端数据的访问，同时保护了每个客户端数据的隐私性。然后，服务器聚合了在这些多个客户端上进行的训练，而不访问它们的数据，这些数据可能是在任何社交媒体服务和即时通讯平台中广泛使用的表情符号，以表达用户的情感。本文提出了一种基于联邦学习的干净和攻击情境下的多语言表情符号预测。表情符号预测数据从Twitter和SemEval表情符号数据集中获取。使用这些数据来训练和评估不同大小的转换器模型，包括在所有客户端中假定数据干净或在一些客户端中进行标签翻转攻击的稀疏激活转换器。对这些模型的实验结果表明，在干净或攻击情境下，联邦学习可以有效地预测多语言表情符号，同时保持数据隐私。

    Federated learning is a growing field in the machine learning community due to its decentralized and private design. Model training in federated learning is distributed over multiple clients giving access to lots of client data while maintaining privacy. Then, a server aggregates the training done on these multiple clients without access to their data, which could be emojis widely used in any social media service and instant messaging platforms to express users' sentiments. This paper proposes federated learning-based multilingual emoji prediction in both clean and attack scenarios. Emoji prediction data have been crawled from both Twitter and SemEval emoji datasets. This data is used to train and evaluate different transformer model sizes including a sparsely activated transformer with either the assumption of clean data in all clients or poisoned data via label flipping attack in some clients. Experimental results on these models show that federated learning in either clean or attack
    
[^46]: 通过定向刺激引导大型语言模型

    Guiding Large Language Models via Directional Stimulus Prompting. (arXiv:2302.11520v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.11520](http://arxiv.org/abs/2302.11520)

    该文介绍了一个新的框架，用于通过生成定向刺激来指导大型语言模型在下游任务中生成所需的输出。通过策略语言模型的训练，该框架可以适应于各种语言模型和任务，并在摘要和对话生成任务中取得了最先进的表现。

    

    我们引入了一个新的框架，称为定向刺激引导，它使用可调节的语言模型来为下游任务的黑盒冻结大型语言模型提供指导。与以往手动或自动找到每个任务的最优提示的方法不同，我们训练一个策略语言模型来生成离散的token作为每个输入的定向刺激，这是一种提示或提示，例如文章的关键词用于摘要。然后将定向刺激与原始输入组合，并输入到LLM中，以指导其向所需目标生成。策略LM可以通过1）从注释数据中的监督学习和2）从离线和在线奖励中的强化学习进行训练，以探索更好地与人类偏好相匹配的定向刺激。该框架可灵活适用于各种LM和任务。为了验证其效果，我们将我们的框架应用于摘要和对话响应生成任务。实验结果表明，我们的方法在两个任务上均取得了最先进的性能。

    We introduce a new framework, Directional Stimulus Prompting, that uses a tuneable language model (LM) to provide guidance for the black-box frozen large language model (LLM) on downstream tasks. Unlike prior work that manually or automatically finds the optimal prompt for each task, we train a policy LM to generate discrete tokens as directional stimulus of each input, which is a hint/cue such as keywords of an article for summarization. The directional stimulus is then combined with the original input and fed into the LLM to guide its generation toward the desired target. The policy LM can be trained through 1) supervised learning from annotated data and 2) reinforcement learning from offline and online rewards to explore directional stimulus that better aligns LLMs with human preferences. This framework is flexibly applicable to various LMs and tasks. To verify its effectiveness, we apply our framework to summarization and dialogue response generation tasks. Experimental results dem
    
[^47]: 高效节约内存的NLLB-200：针对大规模多语言机器翻译模型的语言特定专家删减

    Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model. (arXiv:2212.09811v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09811](http://arxiv.org/abs/2212.09811)

    本研究提出了一种节约内存的NLLB-200模型修剪方法，可在保持翻译质量的同时移除多达80％的专家，使得在单个32GB的GPU上运行模型成为可能。这对于大规模多语言机器翻译具有重要的意义。

    

    与传统的双语翻译系统相比，大规模多语言机器翻译具有吸引力，因为一个单一模型可以翻译成多种语言，并从知识转移中获益，尤其是对于低资源语言。然而，大规模多语言模型受到多语言性的限制，除非进行大规模扩展，否则会增加训练和推理成本。稀疏的专家混合模型是一种在不需要大量计算的情况下大幅增加模型容量的方法。最近发布的NLLB-200是这样一个模型的例子。它涵盖了202种语言，但仅推理就需要至少四个32GB的GPU。在这项工作中，我们提出了一种修剪方法，允许删除多达80％的专家，但翻译质量几乎没有损失，这使得在单个32GB的GPU上运行该模型成为可能。进一步分析表明，我们的修剪度量指标可以识别出语言特定的专家

    Compared to conventional bilingual translation systems, massively multilingual machine translation is appealing because a single model can translate into multiple languages and benefit from knowledge transfer for low resource languages. On the other hand, massively multilingual models suffer from the curse of multilinguality, unless scaling their size massively, which increases their training and inference costs. Sparse Mixture-of-Experts models are a way to drastically increase model capacity without the need for a proportional amount of computing. The recently released NLLB-200 is an example of such a model. It covers 202 languages but requires at least four 32GB GPUs just for inference. In this work, we propose a pruning method that allows the removal of up to 80\% of experts with a negligible loss in translation quality, which makes it feasible to run the model on a single 32GB GPU. Further analysis suggests that our pruning metrics allow to identify language-specific experts and p
    
[^48]: WACO: 用于语音翻译的词对齐对比学习

    WACO: Word-Aligned Contrastive Learning for Speech Translation. (arXiv:2212.09359v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09359](http://arxiv.org/abs/2212.09359)

    WACO是一种用于极低资源语音到文本翻译的简单而有效的方法，通过对比学习将语音和文本的词级表示连接起来，实验证明WACO在极低资源条件下比基线方法提高了9+ BLEU分。

    

    端到端语音翻译（E2E ST）旨在直接将源语音转化为目标文本。当仅有极少的语音文本数据用于训练时，现有的ST方法的表现很差。我们观察到ST模型的性能与其语音和源文本之间的嵌入相似度密切相关。在本文中，我们提出了一种名为Word-Aligned COntrastive learning（WACO）的简单有效的极低资源语音到文本翻译方法。我们的关键思想是通过对比学习来建立语音和文本模态的词级表示之间的桥梁。我们在MuST-C数据集上评估了WACO和其他方法，该数据集是一个广泛使用的ST基准，并在从IWSLT 2023获取的低资源方向的马耳他语-英语翻译上进行了评估。我们的实验表明，WACO仅使用1小时的并行ST数据，比最好的基准提高了9+ BLEU分。代码可在https://github.com/owaski/WACO上找到。

    End-to-end Speech Translation (E2E ST) aims to directly translate source speech into target text. Existing ST methods perform poorly when only extremely small speech-text data are available for training. We observe that an ST model's performance closely correlates with its embedding similarity between speech and source transcript. In this paper, we propose Word-Aligned COntrastive learning (WACO), a simple and effective method for extremely low-resource speech-to-text translation. Our key idea is bridging word-level representations for both speech and text modalities via contrastive learning. We evaluate WACO and other methods on the MuST-C dataset, a widely used ST benchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our experiments demonstrate that WACO outperforms the best baseline by 9+ BLEU points with only 1-hour parallel ST data. Code is available at https://github.com/owaski/WACO.
    
[^49]: SESCORE2: 通过合成真实错误来学习文本生成评估

    SESCORE2: Learning Text Generation Evaluation via Synthesizing Realistic Mistakes. (arXiv:2212.09305v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09305](http://arxiv.org/abs/2212.09305)

    这项研究提出了一种自监督方法SESCORE2，通过合成真实的模型错误来训练用于评估文本生成质量的度量标准。SESCORE2在多个语言和任务上的评估中表现出色，并优于其他无监督和有监督的方法。

    

    是否可能在没有人工评分的情况下训练一个用于评估文本生成质量的通用度量标准？现有的学习度量标准在文本生成任务上表现不理想，或者需要人工评分来训练特定任务。在本文中，我们提出了SESCORE2，一种自监督的方法，用于训练基于模型的文本生成评估度量标准。其关键概念是通过扰动从语料库中检索到的句子来合成真实的模型错误。SESCORE2的主要优点是其易于扩展到许多其他语言，并提供可靠的严重性估计。我们在三种语言的四个文本生成任务上评估了SESCORE2和以前的方法。SESCORE2在四个文本生成评估基准测试上优于无监督度量标准PRISM，肯德尔改进为0.078。令人惊讶的是，SESCORE2甚至在多个文本生成任务上优于有监督度量标准BLEURT和COMET。代码和数据可在https:获取。

    Is it possible to train a general metric for evaluating text generation quality without human annotated ratings? Existing learned metrics either perform unsatisfactorily across text generation tasks or require human ratings for training on specific tasks. In this paper, we propose SESCORE2, a self-supervised approach for training a model-based metric for text generation evaluation. The key concept is to synthesize realistic model mistakes by perturbing sentences retrieved from a corpus. The primary advantage of the SESCORE2 is its ease of extension to many other languages while providing reliable severity estimation. We evaluate SESCORE2 and previous methods on four text generation tasks across three languages. SESCORE2 outperforms unsupervised metric PRISM on four text generation evaluation benchmarks, with a Kendall improvement of 0.078. Surprisingly, SESCORE2 even outperforms the supervised BLEURT and COMET on multiple text generation tasks. The code and data are available at https:
    
[^50]: ALERT：将语言模型适应推理任务

    ALERT: Adapting Language Models to Reasoning Tasks. (arXiv:2212.08286v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08286](http://arxiv.org/abs/2212.08286)

    该论文介绍了ALERT，它是一个用于评估语言模型在推理任务上能力的基准和分析工具。通过对预训练模型和微调模型在复杂任务上的比较，研究发现语言模型学会了更多推理技能，并提供了一个测试平台来评估模型在细粒度推理技能上的表现。

    

    当前的大型语言模型在需要逐步推理和少样本学习的复杂任务上表现得相当不错。这些模型是应用了他们在预训练中学到的推理技巧并在他们的训练上下文之外进行推理，还是仅仅在更细粒度上记住了他们的训练语料库并学会了更好地理解上下文？为了分解这些可能性，我们引入了ALERT，一个用于评估语言模型推理能力的基准和一套分析工具，比较了预训练模型和微调模型在需要推理技能解决的复杂任务上的表现。ALERT提供了一个测试平台，可以评估任何语言模型在细粒度推理技能上的表现，它涵盖了20个数据集和10种不同的推理技能。我们利用ALERT进一步对微调的作用进行研究。通过广泛的经验分析，我们发现语言模型学会了更多的推理技能，例如文本蕴涵、演绎推理和类比推理。

    Current large language models can perform reasonably well on complex tasks that require step-by-step reasoning with few-shot learning. Are these models applying reasoning skills they have learnt during pre-training and reason outside of their training context, or are they simply memorizing their training corpus at finer granularity and have learnt to better understand their context? To tease apart these possibilities, we introduce ALERT, a benchmark and suite of analyses for assessing language models' reasoning ability comparing pre-trained and finetuned models on complex tasks that require reasoning skills to solve. ALERT provides a test bed to asses any language model on fine-grained reasoning skills, which spans over 20 datasets and covers 10 different reasoning skills. We leverage ALERT to further investigate the role of finetuning. With extensive empirical analysis we find that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogi
    
[^51]: 校准解释：语义解析中的置信度估计

    Calibrated Interpretation: Confidence Estimation in Semantic Parsing. (arXiv:2211.07443v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07443](http://arxiv.org/abs/2211.07443)

    该论文研究了常见的生成模型在四个流行的语义解析数据集上的校准性，并分析了与校准误差相关的因素。为了方便将校准纳入语义解析评估中，作者们发布了一个计算校准度量的库。

    

    序列生成模型越来越被用来将语言翻译成可执行程序，即执行语义解析。语义解析旨在执行现实世界中的动作，因此开发安全系统是有必要的，而测量校准则是安全的核心组成部分，因此尤其重要。我们研究常见生成模型在四个流行的语义解析数据集上的校准性，发现其在模型和数据集之间变化巨大。然后，我们分析与校准误差相关的因素，并发布了两个解析数据集的基于置信度的挑战拆分。为了方便将校准纳入语义解析评估中，我们发布了一个用于计算校准度量的库。

    Sequence generation models are increasingly being used to translate language into executable programs, i.e. to perform executable semantic parsing. The fact that semantic parsing aims to execute actions in the real world motivates developing safe systems, which in turn makes measuring calibration -- a central component to safety -- particularly important. We investigate the calibration of common generation models across four popular semantic parsing datasets, finding that it varies across models and datasets. We then analyze factors associated with calibration error and release new confidence-based challenge splits of two parsing datasets. To facilitate the inclusion of calibration in semantic parsing evaluations, we release a library for computing calibration metrics.
    
[^52]: 宽度优先的流水线并行计算方法

    Breadth-First Pipeline Parallelism. (arXiv:2211.05953v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2211.05953](http://arxiv.org/abs/2211.05953)

    宽度优先的流水线并行计算方法结合了流水线和数据并行计算，通过在每个GPU上使用小批量大小和完全分片的数据并行计算，以提高训练吞吐量。在实验中，与Megatron-LM相比，在一个520亿参数的模型上，使用小批量大小每个GPU的训练吞吐量增加了高达43%。

    

    我们引入了一种新的训练调度方法——宽度优先的流水线并行计算，该方法优化了流水线和数据并行计算的结合。宽度优先的流水线并行计算通过在每个GPU上使用较小的批量大小并结合完全分片的数据并行计算，实现了高GPU利用率、降低训练时间、成本和内存使用。实验证明，相对于Megatron-LM，对于一个520亿参数的模型，使用较小的批量大小每个GPU的训练吞吐量增加了高达43%，从而在大型GPU集群上将训练时间和成本同样降低了。

    We introduce Breadth-First Pipeline Parallelism, a novel training schedule which optimizes the combination of pipeline and data parallelism. Breadth-First Pipeline Parallelism lowers training time, cost and memory usage by combining a high GPU utilization with a small batch size per GPU, and by making use of fully sharded data parallelism. Experimentally, we observed an increase of up to 43% in training throughput for a 52 billion-parameter model using a small batch size per GPU compared to Megatron-LM, which would reduce the training time and cost by the same amount on a large GPU cluster.
    
[^53]: 图像标题生成的词语与句子视觉语义相似度：经验教训

    Word to Sentence Visual Semantic Similarity for Caption Generation: Lessons Learned. (arXiv:2209.12817v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.12817](http://arxiv.org/abs/2209.12817)

    本文提出了一种通过选择最相关的输出来改进图像标题生成系统的方法，同时采用视觉语义度量来匹配图像中的相关信息与合适的标题。

    

    本文的重点是增强图像标题生成系统生成的标题。我们提出了一种方法，通过选择与图像最相关的输出而不是模型产生的最可能输出来改进标题生成系统。我们的模型从视觉背景的角度重新调整了语言生成输出的波束搜索。我们以词语和句子级别上的视觉语义度量来匹配图像中的相关信息与合适的标题。这种方法可以作为后处理的基于方法应用于任何标题系统中。

    This paper focuses on enhancing the captions generated by image-caption generation systems. We propose an approach for improving caption generation systems by choosing the most closely related output to the image rather than the most likely output produced by the model. Our model revises the language generation output beam search from a visual context perspective. We employ a visual semantic measure in a word and sentence level manner to match the proper caption to the related information in the image. The proposed approach can be applied to any caption system as a post-processing based method.
    
[^54]: 将索引和检索桥接起来，为具有查询生成的可微搜索索引填补差距

    Bridging the Gap Between Indexing and Retrieval for Differentiable Search Index with Query Generation. (arXiv:2206.10128v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2206.10128](http://arxiv.org/abs/2206.10128)

    本文识别和解决了当前可微搜索索引模型的一个重要问题：在索引和检索过程中存在的数据分布不匹配。为了解决这个问题，提出了一个简单而有效的索引框架。

    

    可微搜索索引(DSI)是一种新兴的信息检索范式。与传统的检索架构不同，其中索引和检索是两个不同的组件，DSI使用单个transformer模型来执行索引和检索。在本文中，我们确定并解决了当前DSI模型的一个重要问题：DSI索引和检索过程之间出现的数据分布不匹配。具体而言，我们认为，在索引过程中，当前DSI方法学习构建长文档的文本与文档标识符之间的连接，但检索过程中使用的查询通常比索引的文档要短得多。当将DSI用于跨语言检索时，这个问题进一步加剧，因为文档文本和查询文本处于不同的语言中。为了解决当前DSI模型的这个根本问题，我们提出了一个简单而有效的DSI索引框架，c

    The Differentiable Search Index (DSI) is an emerging paradigm for information retrieval. Unlike traditional retrieval architectures where index and retrieval are two different and separate components, DSI uses a single transformer model to perform both indexing and retrieval.  In this paper, we identify and tackle an important issue of current DSI models: the data distribution mismatch that occurs between the DSI indexing and retrieval processes. Specifically, we argue that, at indexing, current DSI methods learn to build connections between the text of long documents and the identifier of the documents, but then retrieval of document identifiers is based on queries that are commonly much shorter than the indexed documents. This problem is further exacerbated when using DSI for cross-lingual retrieval, where document text and query text are in different languages.  To address this fundamental problem of current DSI models, we propose a simple yet effective indexing framework for DSI, c
    
[^55]: 端到端的多模态事实检查和解释生成：一个具有挑战性的数据集和模型

    End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models. (arXiv:2205.12487v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12487](http://arxiv.org/abs/2205.12487)

    端到端的多模态事实检查和解释生成。构建了Mocheg数据集，包含15,601个主张，33,880个文本段落和12,112个图像作为证据。通过三个子任务取得了良好性能。

    

    我们提出了端到端的多模态事实检查和解释生成，其中输入是一个主张和一个包含文章、图像、视频和推文的大型网络资源集合，目标是通过检索相关证据并预测一个真实性标签（例如，支持、反驳或信息不足），以及生成一条陈述来总结和解释推理和裁决过程。为了支持这项研究，我们构建了Mocheg，一个包含15,601个主张的大规模数据集，每个主张都标有真实性标签和裁决陈述，以及总共33,880个文本段落和12,112个图像作为证据。为了在Mocheg上建立基线性能，我们在三个分步子任务上使用了几种最先进的神经网络架构进行实验：多模态证据检索、主张验证和解释生成，并证明了最先进的端到端多模态方法的性能。

    We propose end-to-end multimodal fact-checking and explanation generation, where the input is a claim and a large collection of web sources, including articles, images, videos, and tweets, and the goal is to assess the truthfulness of the claim by retrieving relevant evidence and predicting a truthfulness label (e.g., support, refute or not enough information), and to generate a statement to summarize and explain the reasoning and ruling process. To support this research, we construct Mocheg, a large-scale dataset consisting of 15,601 claims where each claim is annotated with a truthfulness label and a ruling statement, and 33,880 textual paragraphs and 12,112 images in total as evidence. To establish baseline performances on Mocheg, we experiment with several state-of-the-art neural architectures on the three pipelined subtasks: multimodal evidence retrieval, claim verification, and explanation generation, and demonstrate that the performance of the state-of-the-art end-to-end multimo
    

