# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Otter: A Multi-Modal Model with In-Context Instruction Tuning.](http://arxiv.org/abs/2305.03726) | Otter是一种多模态模型，引入了指令调整方法，基于OpenFlamingo训练，能够更好地指令跟随和上下文学习。 |
| [^2] | [Large Language Models in Ambulatory Devices for Home Health Diagnostics: A case study of Sickle Cell Anemia Management.](http://arxiv.org/abs/2305.03715) | 本研究提出在居家健康诊断设备中应用大型语言模型，以实时评估镰刀细胞病患者的贫血程度，并提供实时信息，以便减少血管阻塞性危机发作的频率。 |
| [^3] | [Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements.](http://arxiv.org/abs/2305.03695) | 本文提出了Vera模型，它是一个通用模型，可以基于常识知识估计陈述性语句的可信度。在解决验证格式的常识问题时，Vera明显优于现有的模型，并展现了对未见任务的泛化能力和良好的标定输出。 |
| [^4] | [DAMO-NLP at SemEval-2023 Task 2: A Unified Retrieval-augmented System for Multilingual Named Entity Recognition.](http://arxiv.org/abs/2305.03688) | DAMO-NLP团队的U-RaNER是一种统一的多语言命名实体识别系统，它通过加入带有实体为中心的Wikidata知识库并采用infusion方法来增强检索上下文，解决了其他系统存在的知识不足、上下文长度有限和单一检索策略等问题。 |
| [^5] | [A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding.](http://arxiv.org/abs/2305.03668) | 该论文提出了一个名为 WikiWeb2M 的 2M 个多模态网页数据集，针对该数据集，设计了三个生成任务并验证了成功性。论文提出了一种名为 Prefix Global 的新颖注意机制，也对数据集和实验结果进行了分析，为多模态网页理解任务研究提供了有价值的数据和实验基础。 |
| [^6] | [Predicting COVID-19 and pneumonia complications from admission texts.](http://arxiv.org/abs/2305.03661) | 本文提出一种基于入院记录进行患者并发症风险评估的新方法，并使用Longformer神经网络计算患者的风险评分。该方法在多个欧洲医院的患者数据中表现出优异的性能，具有泛化能力和其他优势。 |
| [^7] | [Retrieval Augmented Chest X-Ray Report Generation using OpenAI GPT models.](http://arxiv.org/abs/2305.03660) | 该研究提出了一种检索增强的方法，利用对比预训练的视觉语言模型的多模态对齐嵌入来检索相应的候选放射学文本，并使用通用领域生成模型来生成报告，可抑制虚构的生成，实现更好的临床指标。 |
| [^8] | [White-Box Multi-Objective Adversarial Attack on Dialogue Generation.](http://arxiv.org/abs/2305.03655) | 该论文提出了一种新的白盒多目标对话生成对抗攻击方法，DGSlow。通过平衡生成准确性和长度两个目标，DGSlow利用生成更长的输出来提高攻击效果。 |
| [^9] | [Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs.](http://arxiv.org/abs/2305.03642) | 本文提出了一种基于LLM调整的文本到文本模型，共同提取RCT报告中的干预、结果和发现信息，实现相当大的性能提升。 |
| [^10] | [Data Curation for Image Captioning with Text-to-Image Generative Models.](http://arxiv.org/abs/2305.03610) | 本论文探究了通过数据整合来提高图像字幕质量的方案，并使用现有资源训练了比基准模型更好的模型。 |
| [^11] | [A Dual Semantic-Aware Recurrent Global-Adaptive Network For Vision-and-Language Navigation.](http://arxiv.org/abs/2305.03602) | 本文提出了一种双重语义感知的全局适应循环网络，通过引入指导语言模块和外观语义视觉模块，以及全局自适应聚合模块，提高了在视觉语言导航中的语义学习。 |
| [^12] | [NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports.](http://arxiv.org/abs/2305.03598) | 本文提出了一种面向临床试验报告的自然语言推理模型，通过检索支持事实来确定自然语言陈述和CTR之间的推理关系。 |
| [^13] | [Now It Sounds Like You: Learning Personalized Vocabulary On Device.](http://arxiv.org/abs/2305.03584) | 这项研究提出了一种称为“生词扩展”的技术，通过个性化的“生词适配器”来学习个性化词汇，提高了生词覆盖率并显著提高了模型准确度。 |
| [^14] | [In-context Learning as Maintaining Coherency: A Study of On-the-fly Machine Translation Using Large Language Models.](http://arxiv.org/abs/2305.03573) | 本文探究了机器翻译的在语境学习现象，提出了在语境学习应该是保持结果与其语境具有连贯性的生成任务。实验结果表明，将具有长期连贯性的样例用于翻译可以提高翻译性能。 |
| [^15] | [Leveraging BERT Language Model for Arabic Long Document Classification.](http://arxiv.org/abs/2305.03519) | 本文研究了定制化的阿拉伯语长文档分类模型，提出了两个简单却有效的模型，并与Longformer和RoBERT进行了比较。结果表明，我们的模型在两个数据集上都优于Longformer和RoBERT。 |
| [^16] | [Black-box Prompt Tuning with Subspace Learning.](http://arxiv.org/abs/2305.03518) | 本文提出了基于子空间学习的黑匣子提示调优（BSL）框架，通过元学习在相似任务的集合中识别子空间，以改善黑匣子提示调优的通用性，在下游任务和LLMs上都能够持续达到竞争性的表现水平。 |
| [^17] | [Few-shot Domain-Adaptive Visually-fused Event Detection from Text.](http://arxiv.org/abs/2305.03517) | 本文提出了一种基于视觉融合和领域自适应的事件检测方法，可以用少量标记数据训练并且适应于新领域。 |
| [^18] | [Can Large Language Models Transform Computational Social Science?.](http://arxiv.org/abs/2305.03514) | 本文研究了大型语言模型作为计算社会科学工具的潜力。虽然在分类任务上没有优势，但在自由形式编码任务上表现优异，今后可以作为零-shot检测工具进行使用， |
| [^19] | [ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs.](http://arxiv.org/abs/2305.03513) | ChatGraph通过将ChatGPT的知识转换为图形，提高了文本分类的可解释性和性能 |
| [^20] | [Building Multimodal AI Chatbots.](http://arxiv.org/abs/2305.03512) | 本研究提出了一个多模态AI聊天机器人，使用两个深度学习模型，实现了图像检索和响应生成功能，并在PhotoChat数据集上得到了较好的结果。 |
| [^21] | [Parameter-Efficient Cross-lingual Transfer of Vision and Language Models via Translation-based Alignment.](http://arxiv.org/abs/2305.03510) | 本文提出了一个通过翻译对齐的方式实现参数高效、跨语言的迁移学习框架，实验结果显示该框架能够显著减少多语言之间的性能差异。 |
| [^22] | [Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion.](http://arxiv.org/abs/2305.03509) | Diffusion Explainer是第一个可交互的可视化工具，用于解释稳定扩散如何将文本提示转化为图像，用户可以通过动画和交互元素流畅地在多个抽象级别之间过渡，从而更好地理解提示对图像生成的影响。 |
| [^23] | [CiteCaseLAW: Citation Worthiness Detection in Caselaw for Legal Assistive Writing.](http://arxiv.org/abs/2305.03508) | 本研究旨在解决法律写作中引用值的鉴别问题，通过使用一个包含 178M 句子的标记数据集并测试多种深度学习模型的性能，结果表明专门针对该领域预训练的模型优于其他模型。 |
| [^24] | [Read it Twice: Towards Faithfully Interpretable Fact Verification by Revisiting Evidence.](http://arxiv.org/abs/2305.03507) | 本研究提出了一种名为“ ReRead”的事实验证模型，其以两个阶段（证据检索和声明验证）实现准确且可解释的事实验证，并在FEVER数据集上实现了最先进的结果。 |
| [^25] | [SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation.](http://arxiv.org/abs/2305.03506) | SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。 |
| [^26] | [Think Rationally about What You See: Continuous Rationale Extraction for Relation Extraction.](http://arxiv.org/abs/2305.03503) | 本研究提出了一种新颖的关系提取的理据抽取框架RE2，利用两个连续性和稀疏性因素从句子中获取相关而连贯的理据，解决了如何保留相关内容并从句子中去掉噪音段落的问题。实验结果显示我们的模型优于现有的最先进方法，并且提取出的理据对于推理和解释是有用的。 |
| [^27] | [Explore the difficulty of words and its influential attributes based on the Wordle game.](http://arxiv.org/abs/2305.03502) | 本文探究了基于Wordle游戏的词语难度预测方法及其影响因素，并通过因子分析与线性回归建立了关系。 |
| [^28] | [Cancer Hallmark Classification Using Bidirectional Encoder Representations From Transformers.](http://arxiv.org/abs/2305.03501) | 本文通过在小型癌症生物医学文本语料库上微调BERT模型，提出了一种高精度分类癌症标志的方法，并在实验中取得了94.45%的精度，比以往文献的研究结果高出至少8.04%。 |
| [^29] | [Training Natural Language Processing Models on Encrypted Text for Enhanced Privacy.](http://arxiv.org/abs/2305.03497) | 本研究提出了一种在加密文本数据上训练NLP模型的方法，以缓解数据隐私问题，同时保持与非加密数据训练模型相似的性能。 |
| [^30] | [Automatic Prompt Optimization with "Gradient Descent" and Beam Search.](http://arxiv.org/abs/2305.03495) | 在基于大型语言模型的自然语言处理中，使用梯度下降和 beam search 的自动提示优化方法可以自动改进提示，提高性能。 |
| [^31] | [Interactive Acquisition of Fine-grained Visual Concepts by Exploiting Semantics of Generic Characterizations in Discourse.](http://arxiv.org/abs/2305.03461) | 本文研究了交互式任务学习中的符号接地任务，在教师的泛指语句和上下文中的暗示下实现了更高效的数据接地结果。 |
| [^32] | [Multi-View Graph Representation Learning for Answering Hybrid Numerical Reasoning Question.](http://arxiv.org/abs/2305.03458) | 本文提出了一种基于多视角图形表示学习的混合型数值推理问答模型，能够从表格视角、关系视角和数值视角捕捉混合数据之间的粒度关系和空间结构信息，能够有效提高数值推理任务的准确率。 |
| [^33] | [T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering.](http://arxiv.org/abs/2305.03453) | 本研究使用大型语言模型信号教育科学问题回答的链式思维推理，通过生成高质量COT合理化信号，同时降低了人工注释的需求。 |
| [^34] | [LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models.](http://arxiv.org/abs/2305.03445) | 本文研究调查了具身化策略对语言模型解释比喻性语言的影响。结果表明，更大的模型在处理行为更具体化的隐喻性句子时表现更佳。 |
| [^35] | [Using ChatGPT for Entity Matching.](http://arxiv.org/abs/2305.03423) | 本研究探究使用ChatGPT进行实体匹配的可行性，相较于传统方法更为有效，不需大量微调数据，且更加健壮。 |
| [^36] | [Online Gesture Recognition using Transformer and Natural Language Processing.](http://arxiv.org/abs/2305.03407) | 本文研究了使用Transformer架构实现在线手势识别，并结合自然语言处理，提出一种解决多级分割问题的机器翻译框架，使用大型解码空间提高对语法规则和缺损输入的鲁棒性。实验结果表明，该方法具有良好的泛化性能，能够用于多种语言和通用手写识别任务。 |
| [^37] | [The MuSe 2023 Multimodal Sentiment Analysis Challenge: Mimicked Emotions, Cross-Cultural Humour, and Personalisation.](http://arxiv.org/abs/2305.03369) | MuSe 2023是一组共享任务，涉及三个当代多模态情感和情绪分析问题：模拟情感、跨文化幽默和个性化。参与者需要在各自的子挑战中预测情感目标、跨文化幽默和个性化的信号。 |
| [^38] | [From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering over Knowledge Base.](http://arxiv.org/abs/2305.03356) | 本文提出了一种名为解析-执行-优化（Parse-Execute-Refine）的范式，通过向知识库问题应答模型演示执行中间推理步骤，可以提高复杂推理的能力。 |
| [^39] | [MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic.](http://arxiv.org/abs/2305.03353) | 本文利用动态认知逻辑在自然语言处理模型中探讨了理解心智理论的方法。虽然GPT-4表现出改进的能力，但需要进一步提高。 |
| [^40] | [QCRI at SemEval-2023 Task 3: News Genre, Framing and Persuasion Techniques Detection using Multilingual Models.](http://arxiv.org/abs/2305.03336) | 本文介绍了QCRI在SemEval-2023任务3中使用多语言模型成功排名前三的结果，并展示了去解决分析和验证在线新闻传播的难题。 |
| [^41] | [HiPool: Modeling Long Documents Using Graph Neural Networks.](http://arxiv.org/abs/2305.03319) | 本论文提出了一种基于图神经网络的方法来模拟长文档，解决了顺序模型中的长期依赖问题，在新提出的基准测试中达到了最先进的性能。 |
| [^42] | [LLM-RM at SemEval-2023 Task 2: Multilingual Complex NER using XLM-RoBERTa.](http://arxiv.org/abs/2305.03300) | 本文介绍了LLM-RM团队参加SemEval2023任务2的成果，在跨语言多复杂命名实体识别方面，通过fine-tuning XLM-Roberta的交叉语言表示，得到了良好的效果。 |
| [^43] | [Open Information Extraction via Chunks.](http://arxiv.org/abs/2305.03299) | 本文提出了一种句子作为块序列的方法，将块的跨度识别为元组关系和参数，采用Chunk-OIE进行元组提取并取得了最先进的结果。 |
| [^44] | [Low-Resource Multi-Granularity Academic Function Recognition Based on Multiple Prompt Knowledge.](http://arxiv.org/abs/2305.03287) | 本研究提出了 Mix Prompt Tuning（MPT）方法，通过将手动提示模板与自动学习的连续提示模板相结合，提高多粒度学术功能识别任务的性能，并减轻对注释数据的依赖。 |
| [^45] | [Expository Text Generation: Imitate, Retrieve, Paraphrase.](http://arxiv.org/abs/2305.03276) | 该论文介绍了一项名为“专业性文本生成”的任务，目的在于从知识来源自动生成准确、信息丰富的文档，研究者提出的IRP框架能够克服语言模型的缺点，实现了内容规划、事实选择 和改写步骤分别处理，使得生成的文档具有较高的质量。 |
| [^46] | [Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework.](http://arxiv.org/abs/2305.03268) | 本文介绍了Verify-and-Edit框架，该框架通过根据外部知识后编辑推理链，提高CoT提示的预测准确性。 |
| [^47] | [Rescue Conversations from Dead-ends: Efficient Exploration for Task-oriented Dialogue Policy Optimization.](http://arxiv.org/abs/2305.03262) | 本文提出了一种死角复活（DDR）算法，可以及时高效地检测起始死角状态，并提供拯救行动以引导和纠正对话探索方向，同时防止对话策略不断犯同样的错误。 |
| [^48] | [Stylized Data-to-Text Generation: A Case Study in the E-Commerce Domain.](http://arxiv.org/abs/2305.03256) | 该论文提出了一个新的任务——风格化数据文本生成，旨在根据特定风格为给定的非语言数据生成连贯的文本。作者还提出了一种新颖模型来解决该任务的难题。 |
| [^49] | [VicunaNER: Zero/Few-shot Named Entity Recognition using Vicuna.](http://arxiv.org/abs/2305.03253) | 本文提出了基于Vicuna的零/小样本NER框架VicunaNER，具有优异的零样本和小样本能力，并在多个数据集上进行了评估和全面的研究。 |
| [^50] | [Out-of-Domain Intent Detection Considering Multi-turn Dialogue Contexts.](http://arxiv.org/abs/2305.03237) | 本文提出了一个上下文感知的OOD意图检测框架（Caro），用于模拟OOD意图检测任务中的多轮对话上下文，并在提取稳健的表示时删除与意图检测无关的多余信息。Caro在多个标准数据集上表现出最先进的性能，并超越了先前方法。 |
| [^51] | [A Survey on Out-of-Distribution Detection in NLP.](http://arxiv.org/abs/2305.03236) | 这篇论文首次综述了最新的OOD检测方法在自然语言处理中的应用。根据算法使用的数据，将方法分成三类，并介绍了相关数据集、应用和度量方法。 |
| [^52] | [Neuromodulation Gated Transformer.](http://arxiv.org/abs/2305.03232) | 本文介绍了一种新型的神经调节门控Transformer架构，通过乘法效应实现了神经调节，在SuperGLUE基准验证集上表现最优。 |
| [^53] | [AttentionViz: A Global View of Transformer Attention.](http://arxiv.org/abs/2305.03210) | 这篇论文介绍了AttentionViz，一种以联合嵌入为基础的交互式可视化工具，用于帮助研究人员理解Transformer中的自我注意机制。该方法使得可以全局分析多个输入序列的注意力模式，提高对模型的理解并通过多个应用场景和专家反馈提供新的交互见解。 |
| [^54] | [Investigating Lexical Sharing in Multilingual Machine Translation for Indian Languages.](http://arxiv.org/abs/2305.03207) | 本文研究了印度语系多语言机器翻译中的词汇共享问题，探索了数据采样和词汇量之间的翻译性能权衡，以及字母转写是否有助于促进跨脚本概括，发现字母转写对跨脚本翻译效果没有明显改进，对于较低资源的语言，多语言机器翻译模型训练在原始脚本上似乎已经能够抵抗脚本差异。 |
| [^55] | [VideoOFA: Two-Stage Pre-Training for Video-to-Text Generation.](http://arxiv.org/abs/2305.03204) | 本文提出了一个用于视频到文本生成的两阶段预训练模型，能够学习视频特定的技能，取得了四项视频字幕基准测试的最先进性能，同时在两个开放式视频问答数据集上表现优异。 |
| [^56] | [Enhancing Pashto Text Classification using Language Processing Techniques for Single And Multi-Label Analysis.](http://arxiv.org/abs/2305.03201) | 研究旨在建立一个普什图语文本的自动分类系统，最终通过应用多层感知器分类器获得了94％的平均测试准确率。 |
| [^57] | [Employing Hybrid Deep Neural Networks on Dari Speech.](http://arxiv.org/abs/2305.03200) | 本研究使用深度神经网络模型和Mel频率倒谱系数特征提取方法对Dari语音中的单词进行识别，在孤立Dari词语语料库上实现了高准确性的识别。 |
| [^58] | [Gpt-4: A Review on Advancements and Opportunities in Natural Language Processing.](http://arxiv.org/abs/2305.03195) | GPT-4是OpenAI开发的第四代GPT语言模型，具有超过1万亿的模型规模、更好的多语言能力和改进的语境理解和推理能力。它有望应用于聊天机器人、个人助理、语言翻译、文本摘要和问答系统，但也存在计算要求、数据要求和道德问题等挑战和限制。 |
| [^59] | [Sensitive Data Detection with High-Throughput Machine Learning Models in Electrical Health Records.](http://arxiv.org/abs/2305.03169) | 该论文使用机器学习算法来识别结构化数据中的敏感变量，以便便于去身份化过程。该算法可以解决不同数据集PHI字段异质性的问题。 |
| [^60] | [Influence of various text embeddings on clustering performance in NLP.](http://arxiv.org/abs/2305.03144) | 研究探索了不同文本嵌入对聚类算法（KMeans、单链接聚合等级、DBSCAN和HDBSCAN）性能的影响，并应用于评论聚类领域。 |
| [^61] | [The Role of Global and Local Context in Named Entity Recognition.](http://arxiv.org/abs/2305.03132) | 研究者探讨了全局文档上下文与局部上下文在命名实体识别中的作用，发现正确检索全局文档上下文对提高性能至关重要。 |
| [^62] | [Chain-of-Skills: A Configurable Model for Open-domain Question Answering.](http://arxiv.org/abs/2305.03130) | 本论文提出了一种模块化检索器可以在数据集间重复使用，支持针对目标领域的灵活技能配置，通过自我监督预训练和微调多个 ODQA 数据集，实现了最新颖的微调检索性能。 |
| [^63] | [ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review.](http://arxiv.org/abs/2305.03123) | 本文研究关注ChatGPT面临的可持续性、隐私、数字鸿沟和伦理问题，提出了SPADE评估的必要性，并给出了缓解和建议。 |
| [^64] | [Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs.](http://arxiv.org/abs/2305.03111) | 本文提出了一个大型的基准测试Bird，可以用于大规模数据库文本到SQL的任务，突出了数据库值理解和SQL效率等领域的挑战。 |
| [^65] | [Hybrid Transducer and Attention based Encoder-Decoder Modeling for Speech-to-Text Tasks.](http://arxiv.org/abs/2305.03101) | 本论文提出了一种结合了变换器和AED框架的新方案，利用AED的序列到序列学习的优势，同时保留了变换器的流式属性，旨在提高语音到文本任务的性能。 |
| [^66] | [Curating corpora with classifiers: A case study of clean energy sentiment online.](http://arxiv.org/abs/2305.03092) | 本文介绍了利用分类器来快速选择最佳的相关文档语料库进行分析的方法，探索了过滤掉不相关的推文的方法，以进行在线清洁能源情感分析。 |
| [^67] | [Modeling What-to-ask and How-to-ask for Answer-unaware Conversational Question Generation.](http://arxiv.org/abs/2305.03088) | 本文提出了一种新的方法来共同建模“要问什么”和“如何问”的问题，在不明确答案的设置中非常实用。 |
| [^68] | [Automated Code generation for Information Technology Tasks in YAML through Large Language Models.](http://arxiv.org/abs/2305.02783) | 这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。 |
| [^69] | [Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge.](http://arxiv.org/abs/2305.02459) | 本文提出并探究了基于转移和主动学习的稀有类问题的解决方案，包括利用在密切相关任务上训练的模型和评估获取策略来解决共振检测的稀有类问题，并且发现了一种名为PRC的有效的策略来指导注释。 |
| [^70] | [A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Linguistically Complex Text.](http://arxiv.org/abs/2305.02265) | 提出了一种神经分治推理框架NDCR，通过将语言复杂文本视为由多个简单命题句组成的复合命题文本，将图像检索问题分为三个步骤：分治、征服和组合。该框架在解决语言复杂文本问题时具有较好的性能。 |
| [^71] | [UNTER: A Unified Knowledge Interface for Enhancing Pre-trained Language Models.](http://arxiv.org/abs/2305.01624) | 本篇论文提出了一种名为UNTER的统一知识接口，可以同时利用结构化和非结构化知识，从而提高预训练语言模型（PLMs）性能，在实验中表现出不断的改进。 |
| [^72] | [Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks.](http://arxiv.org/abs/2304.14732) | 提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。 |
| [^73] | [Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4.](http://arxiv.org/abs/2304.03439) | 本文分析了多个逻辑推理数据集，评估了ChatGPT和GPT-4在逻辑推理任务上的表现，并构造了一个逻辑推理的分布之外的数据集来研究它们的鲁棒性。实验结果显示，ChatGPT在大多数逻辑推理基准测试中的表现远优于RoBERTa微调方法，而GPT-4的表现则更高。 |
| [^74] | [DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains.](http://arxiv.org/abs/2304.00958) | 本文提出了DrBERT，用于生物医学和临床领域的健壮的法语预训练模型，并通过对公共数据和医疗机构的私有数据进行性能比较，证明了在特定领域数据上进一步预训练PLMs可以显著提高性能。最终，发布了首个用于生物医学领域的法语专用PLMs，以及最大的医学数据语料库。 |
| [^75] | [Language Models are Few-shot Learners for Prognostic Prediction.](http://arxiv.org/abs/2302.12692) | 本研究探索了语言模型在免疫治疗预后预测中的应用，研究了小样本学习面临的挑战，对比了基线和语言模型的有效性，并发现在准确度方面有显著的改进，突出了自然语言处理在临床研究中改善早期检测和干预不同疾病的潜力。 |
| [^76] | [Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection.](http://arxiv.org/abs/2302.12173) | 本文揭示了一种新的攻击向量：间接提示注入，它可以通过在可能检索到的数据中策略性地注入提示来远程利用 LLM 集成应用程序。该攻击对数据盗窃、蠕虫、信息生态系统污染等造成威胁。 |
| [^77] | [On the Blind Spots of Model-Based Evaluation Metrics for Text Generation.](http://arxiv.org/abs/2212.10020) | 本文研究了针对文本生成评价指标的鲁棒性分析方法，使用合成数据进行压力测试，发现现有评价指标存在一些盲点和偏见，例如BERTScore对摘要中的截断误差无法很好地处理，MAUVE对于生成的开头或中间的误差不敏感，本文提出了实用的解决方案以实现更可靠的文本生成评价。 |
| [^78] | [PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism.](http://arxiv.org/abs/2212.09086) | 该论文提出了一个名为PVGRU的组件，可以通过引入汇总变量来聚合子序列的累积分布变化，从而优化基于生成的聊天机器人的多轮对话回复，提高对话模型的多样性和相关性。 |
| [^79] | [Can In-context Learners Learn a Reasoning Concept from Demonstrations?.](http://arxiv.org/abs/2212.01692) | 本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。 |
| [^80] | [xTrimoABFold: De novo Antibody Structure Prediction without MSA.](http://arxiv.org/abs/2212.00735) | xTrimoABFold是一种基于深度抗体语言模型的新型抗体结构预测方法，无需多序列比对，有望促进高通量药物设计的应用。 |
| [^81] | [Rethinking the Event Coding Pipeline with Prompt Entailment.](http://arxiv.org/abs/2210.05257) | 提出了一种名为PR-ENT的事件编码方法，用于从非结构化全文事件描述中提取事件类型。该方法利用预训练语言模型填充事件描述中的模板，并在文本隐含关系任务中选择答案候选项，同时保持了高准确性和资源效率。 |
| [^82] | [Don't Lose Yourself! Empathetic Response Generation via Explicit Self-Other Awareness.](http://arxiv.org/abs/2210.03884) | 通过明确的自我他人意识生成共情回应，提高了聊天机器人生成共情回应的能力。 |
| [^83] | [Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification.](http://arxiv.org/abs/2204.03954) | 本文比较了用于文本分类的词袋、序列、图形和分层方法，发现基于图形的方法无法超越现代预训练语言模型并且甚至有时表现不如标准机器学习方法，质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。 |
| [^84] | [Learning Discriminative Representations and Decision Boundaries for Open Intent Detection.](http://arxiv.org/abs/2203.05823) | 本论文提出了一个名为DA-ADB的框架，通过学习距离感知意图表示和自适应决策边界来解决开放式意图检测中的两大挑战。在三个公共数据集上的实验证明了该框架的有效性和优越性。 |
| [^85] | [LOGEN: Few-shot Logical Knowledge-Conditioned Text Generation with Self-training.](http://arxiv.org/abs/2112.01404) | 本文提出了一种基于少样本的逻辑知识条件下文本生成的统一框架LOGEN，通过自训练和基于内容和结构一致性抽样伪逻辑形式，实现了在少量样本下的文本生成。 |
| [^86] | [AVATAR: A Parallel Corpus for Java-Python Program Translation.](http://arxiv.org/abs/2108.11590) | AVATAR是一个 Java-Python平行语料库，包含 9,515个编程问题和解决方案，可用于有监督学习和评估无监督方法的程序翻译模型，并且微调的模型在编程语言翻译的质量上优于无监督模型。 |

# 详细

[^1]: Otter: 一种多模态模型及其上下文指令调整方法

    Otter: A Multi-Modal Model with In-Context Instruction Tuning. (arXiv:2305.03726v1 [cs.CV])

    [http://arxiv.org/abs/2305.03726](http://arxiv.org/abs/2305.03726)

    Otter是一种多模态模型，引入了指令调整方法，基于OpenFlamingo训练，能够更好地指令跟随和上下文学习。

    

    巨大的语言模型(LLMs)由于预训练了大量文本数据而展示出在各种任务中以零/少数据学习的显著普适能力，例如GPT-3，它推出了InstrctGPT和ChatGPT，能够通过自然语言指令完成真实世界的任务。本文提出了将指令调整引入到多模态模型中的想法，受到Flamingo模型上游交替格式预训练数据集的启发。我们采用类似的方法构建了我们的MultI-Modal In-Context Instruction Tuning (MIMIC-IT)数据集。我们提出了Otter，一种基于OpenFlamingo的多模态模型(DeepMind的Flamingo的开源版本)，它在MIMIC-IT上进行训练，并展示了更好的指令跟随能力和上下文学习能力。我们还针对研究人员优化了OpenFlamingo的实现，将所需的训练资源从1个A100 GPU降至4个RTX-3090 GPU，从而使研究更具民主性。

    Large language models (LLMs) have demonstrated significant universal capabilities as few/zero-shot learners in various tasks due to their pre-training on vast amounts of text data, as exemplified by GPT-3, which boosted to InstrctGPT and ChatGPT, effectively following natural language instructions to accomplish real-world tasks. In this paper, we propose to introduce instruction tuning into multi-modal models, motivated by the Flamingo model's upstream interleaved format pretraining dataset. We adopt a similar approach to construct our MultI-Modal In-Context Instruction Tuning (MIMIC-IT) dataset. We then introduce Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following ability and in-context learning. We also optimize OpenFlamingo's implementation for researchers, democratizing the required training resources from 1$\times$ A100 GPU to 4$\times$ RTX-3090 GPUs, and integrate both Op
    
[^2]: 应用大型语言模型于居家健康诊断设备中：以镰刀细胞贫血管理为例

    Large Language Models in Ambulatory Devices for Home Health Diagnostics: A case study of Sickle Cell Anemia Management. (arXiv:2305.03715v1 [cs.CL])

    [http://arxiv.org/abs/2305.03715](http://arxiv.org/abs/2305.03715)

    本研究提出在居家健康诊断设备中应用大型语言模型，以实时评估镰刀细胞病患者的贫血程度，并提供实时信息，以便减少血管阻塞性危机发作的频率。

    

    本研究探讨了一种居家设备的潜力，它将大型语言模型(Large Language Models, LLMs)与其他专门的机器学习模型结合使用，实时评估镰刀细胞病患者的贫血程度。该设备依赖测量血管生成物水平的传感器数据来评估贫血程度，为患者和临床医生提供实时信息，以减少血管阻塞性危机发作的频率，因为早期发现贫血程度，允许及时干预，可能降低严重并发症的发生率。开发这种设备的主要挑战是创建一个可靠的非侵入性工具来评估血管生成物水平，建立一个生物物理模型，以及考虑LLM如何代表一个无法行动的患者与急救人员进行通信等实际考虑。本研究提出了一种可能的系统，并讨论了这种方法的局限性。

    This study investigates the potential of an ambulatory device that incorporates Large Language Models (LLMs) in cadence with other specialized ML models to assess anemia severity in sickle cell patients in real time. The device would rely on sensor data that measures angiogenic material levels to assess anemia severity, providing real-time information to patients and clinicians to reduce the frequency of vaso-occlusive crises because of the early detection of anemia severity, allowing for timely interventions and potentially reducing the likelihood of serious complications. The main challenges in developing such a device are the creation of a reliable non-invasive tool for angiogenic level assessment, a biophysics model and the practical consideration of an LLM communicating with emergency personnel on behalf of an incapacitated patient. A possible system is proposed, and the limitations of this approach are discussed.
    
[^3]: Vera：一个用于通用常识语句可信度评估的模型

    Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements. (arXiv:2305.03695v1 [cs.CL])

    [http://arxiv.org/abs/2305.03695](http://arxiv.org/abs/2305.03695)

    本文提出了Vera模型，它是一个通用模型，可以基于常识知识估计陈述性语句的可信度。在解决验证格式的常识问题时，Vera明显优于现有的模型，并展现了对未见任务的泛化能力和良好的标定输出。

    

    尽管当今的语言模型在许多方面表现出色，但它们仍然容易出现荒谬和意外的常识失败。本文提出了一种回顾性验证方法，反思LM输出的正确性，并引入了Vera，一个通用模型，它基于常识知识估计陈述性语句的可信度。通过使用19个QA数据集和两个大规模知识库创建的约700万条常识语句以及三个训练目标的组合进行训练，Vera是一个多功能模型，可以有效地区分各种常识领域中的正确和错误语句。当应用于解决验证格式的常识问题时，Vera明显优于现有的可重用于常识验证的模型，并且它进一步展示了对未见任务的泛化能力并提供了良好的标定输出。我们发现Vera在过滤LM生成的常识知识方面表现突出，可以潜在地增强它们的可信度和实际应用。

    Despite the much discussed capabilities of today's language models, they are still prone to silly and unexpected commonsense failures. We consider a retrospective verification approach that reflects on the correctness of LM outputs, and introduce Vera, a general-purpose model that estimates the plausibility of declarative statements based on commonsense knowledge. Trained on ~7M commonsense statements created from 19 QA datasets and two large-scale knowledge bases, and with a combination of three training objectives, Vera is a versatile model that effectively separates correct from incorrect statements across diverse commonsense domains. When applied to solving commonsense problems in the verification format, Vera substantially outperforms existing models that can be repurposed for commonsense verification, and it further exhibits generalization capabilities to unseen tasks and provides well-calibrated outputs. We find that Vera excels at filtering LM-generated commonsense knowledge an
    
[^4]: SemEval-2023任务2中的DAMO-NLP: 一种多语言命名实体识别的统一检索增强系统

    DAMO-NLP at SemEval-2023 Task 2: A Unified Retrieval-augmented System for Multilingual Named Entity Recognition. (arXiv:2305.03688v1 [cs.CL])

    [http://arxiv.org/abs/2305.03688](http://arxiv.org/abs/2305.03688)

    DAMO-NLP团队的U-RaNER是一种统一的多语言命名实体识别系统，它通过加入带有实体为中心的Wikidata知识库并采用infusion方法来增强检索上下文，解决了其他系统存在的知识不足、上下文长度有限和单一检索策略等问题。

    

    MultiCoNER 2共享任务旨在解决多语言命名实体识别的细粒度和嘈杂情况，并继承了MultiCoNER 1任务的语义歧义和低上下文环境。针对这些问题，MultiCoNER 1中的前几个顶尖系统要么纳入知识库或专有名词表，但它们仍然存在知识不足、上下文长度有限以及单一检索策略等问题。在本文中，我们的DAMO-NLP团队提出了一种用于多语言的细粒度命名实体识别的统一检索增强系统（U-RaNER）。我们对上述几个顶尖系统进行了错误分析，发现它们的性能瓶颈在于知识不足，而且有限的上下文长度使得检索知识对模型不可见。为了增强检索上下文，我们加入了以实体为中心的Wikidata知识库，并采用infusion方法来拓宽上下文引用。

    The MultiCoNER \RNum{2} shared task aims to tackle multilingual named entity recognition (NER) in fine-grained and noisy scenarios, and it inherits the semantic ambiguity and low-context setting of the MultiCoNER \RNum{1} task. To cope with these problems, the previous top systems in the MultiCoNER \RNum{1} either incorporate the knowledge bases or gazetteers. However, they still suffer from insufficient knowledge, limited context length, single retrieval strategy. In this paper, our team \textbf{DAMO-NLP} proposes a unified retrieval-augmented system (U-RaNER) for fine-grained multilingual NER. We perform error analysis on the previous top systems and reveal that their performance bottleneck lies in insufficient knowledge. Also, we discover that the limited context length causes the retrieval knowledge to be invisible to the model. To enhance the retrieval context, we incorporate the entity-centric Wikidata knowledge base, while utilizing the infusion approach to broaden the contextua
    
[^5]: 一个多层多模态网页生成任务套件

    A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding. (arXiv:2305.03668v1 [cs.CL])

    [http://arxiv.org/abs/2305.03668](http://arxiv.org/abs/2305.03668)

    该论文提出了一个名为 WikiWeb2M 的 2M 个多模态网页数据集，针对该数据集，设计了三个生成任务并验证了成功性。论文提出了一种名为 Prefix Global 的新颖注意机制，也对数据集和实验结果进行了分析，为多模态网页理解任务研究提供了有价值的数据和实验基础。

    

    网页一直以来都是一种可扩展的视觉-语言和纯语言任务资源，但只有图像-标题对、长文本文章或原始HTML等部分组成的网页得以保存，没有一个包含全部信息的网页。因此，网页任务在多模态数据结构及图像-文本数据利用方面一直受到关注的较少。为了研究多模态网页理解，我们介绍了 Wikipedia Webpage 套件 (WikiWeb2M) ，包含 2M 个页面。我们在三个生成任务上验证其实用性: 页面描述生成、章节摘要和环境图像字幕。我们设计了一种新型注意机制 Prefix Global，它选择最相关的图像和文本内容作为全局标记，以便于关注网页的其余部分以获取上下文。通过使用页面结构来分离这些标记，它比全注意力具有更低的计算复杂度，表现更好。实验表明，与先前的工作相比，WikiWeb2M 的新注释改进了任务性能。我们还对不同实验设置进行了分析。

    Webpages have been a rich, scalable resource for vision-language and language only tasks. Yet only pieces of webpages are kept: image-caption pairs, long text articles, or raw HTML, never all in one place. Webpage tasks have resultingly received little attention and structured image-text data left underused. To study multimodal webpage understanding, we introduce the Wikipedia Webpage suite (WikiWeb2M) of 2M pages. We verify its utility on three generative tasks: page description generation, section summarization, and contextual image captioning. We design a novel attention mechanism Prefix Global, which selects the most relevant image and text content as global tokens to attend to the rest of the webpage for context. By using page structure to separate such tokens, it performs better than full attention with lower computational complexity. Experiments show that the new annotations from WikiWeb2M improve task performance compared to data from prior work. We also include ablations on se
    
[^6]: 从入院记录预测COVID-19和肺炎并发症

    Predicting COVID-19 and pneumonia complications from admission texts. (arXiv:2305.03661v1 [cs.CL])

    [http://arxiv.org/abs/2305.03661](http://arxiv.org/abs/2305.03661)

    本文提出一种基于入院记录进行患者并发症风险评估的新方法，并使用Longformer神经网络计算患者的风险评分。该方法在多个欧洲医院的患者数据中表现出优异的性能，具有泛化能力和其他优势。

    

    本文提出了一种基于入院报告的风险评估新方法，用于预测因肺炎或COVID-19而住院的患者的并发症风险。我们将Longformer神经网络应用于入院记录和其他可用的文本数据，计算出患者的风险评分。我们使用多个欧洲医院的患者数据证明了我们的方法优于Transformer基线模型。我们的实验表明，该模型在多个机构和诊断中具有泛化能力。此外，本文还介绍了我们的方法具有的其他优势。

    In this paper we present a novel approach to risk assessment for patients hospitalized with pneumonia or COVID-19 based on their admission reports. We applied a Longformer neural network to admission reports and other textual data available shortly after admission to compute risk scores for the patients. We used patient data of multiple European hospitals to demonstrate that our approach outperforms the Transformer baselines. Our experiments show that the proposed model generalises across institutions and diagnoses. Also, our method has several other advantages described in the paper.
    
[^7]: 利用OpenAI GPT模型的检索增强的胸部X射线报告生成

    Retrieval Augmented Chest X-Ray Report Generation using OpenAI GPT models. (arXiv:2305.03660v1 [cs.CL])

    [http://arxiv.org/abs/2305.03660](http://arxiv.org/abs/2305.03660)

    该研究提出了一种检索增强的方法，利用对比预训练的视觉语言模型的多模态对齐嵌入来检索相应的候选放射学文本，并使用通用领域生成模型来生成报告，可抑制虚构的生成，实现更好的临床指标。

    

    我们提出了一种名为Retrieval Augmented Generation (RAG) 的方法来自动生成放射学报告，该方法利用对比预训练的视觉语言模型的多模态对齐嵌入来检索相应的候选放射学文本，并使用像OpenAI text-davinci-003、gpt-3.5-turbo和gpt-4这样的通用领域生成模型来生成报告。该方法可以抑制虚构的生成并提供指令跟随能力，以我们所需的格式生成报告内容。我们的方法实现了更好的临床指标，BERTScore为0.2865（Δ+25.88%），Semb Score为0.4026（Δ+6.31%）。我们的方法可以广泛应用于不同的临床设置，因为它允许增强自动生成的放射学报告过程，同时具备适合该设置的相关内容的能力。

    We propose Retrieval Augmented Generation (RAG) as an approach for automated radiology report writing that leverages multimodally aligned embeddings from a contrastively pretrained vision language model for retrieval of relevant candidate radiology text for an input radiology image and a general domain generative model like OpenAI text-davinci-003, gpt-3.5-turbo and gpt-4 for report generation using the relevant radiology text retrieved. This approach keeps hallucinated generations under check and provides capabilities to generate report content in the format we desire leveraging the instruction following capabilities of these generative models. Our approach achieves better clinical metrics with a BERTScore of 0.2865 ({\Delta}+ 25.88%) and Semb score of 0.4026 ({\Delta}+ 6.31%). Our approach can be broadly relevant for different clinical settings as it allows to augment the automated radiology report generation process with content relevant for that setting while also having the abilit
    
[^8]: 白盒多目标对话生成对抗攻击

    White-Box Multi-Objective Adversarial Attack on Dialogue Generation. (arXiv:2305.03655v1 [cs.CL])

    [http://arxiv.org/abs/2305.03655](http://arxiv.org/abs/2305.03655)

    该论文提出了一种新的白盒多目标对话生成对抗攻击方法，DGSlow。通过平衡生成准确性和长度两个目标，DGSlow利用生成更长的输出来提高攻击效果。

    

    预训练的转换器在最先进的对话生成系统中很受欢迎。 然而，这种语言模型容易受到各种对抗样本的攻击，这在传统任务（如文本分类）中已经得到了研究，这激发了我们对它们在DG系统中的鲁棒性的好奇心。 其中一个主要的挑战是攻击DG模型的时候，对当前句子的扰动几乎不会降低响应的准确性，因为未改变的聊天记录也会被考虑进行决策。我们观察到，通过精心制作对抗样本来迫使生成更长的输出，有利于攻击的有效性 - 生成的响应通常是不相关、冗长和重复的。因此，我们提出了一种名为DGSlow的白盒多目标攻击方法。具体来说，DGSlow通过基于梯度的多目标优化器平衡两个目标 - 生成准确度和长度，并使用自适应方法实施攻击。

    Pre-trained transformers are popular in state-of-the-art dialogue generation (DG) systems. Such language models are, however, vulnerable to various adversarial samples as studied in traditional tasks such as text classification, which inspires our curiosity about their robustness in DG systems. One main challenge of attacking DG models is that perturbations on the current sentence can hardly degrade the response accuracy because the unchanged chat histories are also considered for decision-making. Instead of merely pursuing pitfalls of performance metrics such as BLEU, ROUGE, we observe that crafting adversarial samples to force longer generation outputs benefits attack effectiveness -- the generated responses are typically irrelevant, lengthy, and repetitive. To this end, we propose a white-box multi-objective attack method called DGSlow. Specifically, DGSlow balances two objectives -- generation accuracy and length, via a gradient-based multi-objective optimizer and applies an adapti
    
[^9]: LLM模型共同提取RCT报告中干预、结果和发现信息

    Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs. (arXiv:2305.03642v1 [cs.CL])

    [http://arxiv.org/abs/2305.03642](http://arxiv.org/abs/2305.03642)

    本文提出了一种基于LLM调整的文本到文本模型，共同提取RCT报告中的干预、结果和发现信息，实现相当大的性能提升。

    

    随机对照试验（RCT）的结果确定干预措施的相对有效性，进而成为基于证据的医疗保健的关键输入。然而，RCT结果以（通常是非结构化的）自然语言文章的形式呈现，描述试验的设计、执行和结果；临床医生必须从这些文章中手动提取有关所关注的干预措施和结果的发现。这种繁琐的手动过程促使人们利用（半）自动化的方式从试验报告中提取结构化证据。在这项工作中，我们提出并评估了一个基于调整的大型语言模型（LLMs）的文本到文本模型，用于从临床摘要中共同提取干预措施、结果和比较因素（ICO元素），并推断相关的结果。人工（专家）和自动评估表明，将证据提取框架作为条件生成任务，为此目的微调LLMs可以实现相当大的（约20个点）性能提升。

    Results from Randomized Controlled Trials (RCTs) establish the comparative effectiveness of interventions, and are in turn critical inputs for evidence-based care. However, results from RCTs are presented in (often unstructured) natural language articles describing the design, execution, and outcomes of trials; clinicians must manually extract findings pertaining to interventions and outcomes of interest from such articles. This onerous manual process has motivated work on (semi-)automating extraction of structured evidence from trial reports. In this work we propose and evaluate a text-to-text model built on instruction-tuned Large Language Models (LLMs) to jointly extract Interventions, Outcomes, and Comparators (ICO elements) from clinical abstracts, and infer the associated results reported. Manual (expert) and automated evaluations indicate that framing evidence extraction as a conditional generation task and fine-tuning LLMs for this purpose realizes considerable ($\sim$20 point 
    
[^10]: 使用文本到图像生成模型进行图像字幕数据管理

    Data Curation for Image Captioning with Text-to-Image Generative Models. (arXiv:2305.03610v1 [cs.CV])

    [http://arxiv.org/abs/2305.03610](http://arxiv.org/abs/2305.03610)

    本论文探究了通过数据整合来提高图像字幕质量的方案，并使用现有资源训练了比基准模型更好的模型。

    

    最近，图像字幕技术的发展主要依赖于大规模的视觉-语言预训练，并且日益依赖于计算资源和越来越大的多模态数据集。本文通过数据整合的两种方法探究了如何通过提高现有数据集中的样本质量来改善性能：一种方法假定由于图像和字幕之间的不匹配，某些示例应该避免使用，另一种方法则假定不匹配可以通过替换图像来解决。

    Recent advances in image captioning are mainly driven by large-scale vision-language pretraining, relying heavily on computational resources and increasingly large multimodal datasets. Instead of scaling up pretraining data, we ask whether it is possible to improve performance by improving the quality of the samples in existing datasets. We pursue this question through two approaches to data curation: one that assumes that some examples should be avoided due to mismatches between the image and caption, and one that assumes that the mismatch can be addressed by replacing the image, for which we use the state-of-the-art Stable Diffusion model. These approaches are evaluated using the BLIP model on MS COCO and Flickr30K in both finetuning and few-shot learning settings. Our simple yet effective approaches consistently outperform baselines, indicating that better image captioning models can be trained by curating existing resources. Finally, we conduct a human study to understand the error
    
[^11]: 一种双重语义感知的全局适应循环网络用于视觉语言导航

    A Dual Semantic-Aware Recurrent Global-Adaptive Network For Vision-and-Language Navigation. (arXiv:2305.03602v1 [cs.CV])

    [http://arxiv.org/abs/2305.03602](http://arxiv.org/abs/2305.03602)

    本文提出了一种双重语义感知的全局适应循环网络，通过引入指导语言模块和外观语义视觉模块，以及全局自适应聚合模块，提高了在视觉语言导航中的语义学习。

    

    视觉语言导航是一项现实但具有挑战性的任务，需要代理使用语言和视觉线索定位目标区域。本文提出了一种双重语义感知的全局适应循环网络 (DSRG) 来解决该问题。首先，DSRG 提出了一个指导语言模块 (IGL) 和一个外观语义视觉模块 (ASV) 分别提高视觉和语言语义学习。对于内存机制，还引入了全局自适应聚合模块 (GAA)。

    Vision-and-Language Navigation (VLN) is a realistic but challenging task that requires an agent to locate the target region using verbal and visual cues. While significant advancements have been achieved recently, there are still two broad limitations: (1) The explicit information mining for significant guiding semantics concealed in both vision and language is still under-explored; (2) The previously structured map method provides the average historical appearance of visited nodes, while it ignores distinctive contributions of various images and potent information retention in the reasoning process. This work proposes a dual semantic-aware recurrent global-adaptive network (DSRG) to address the above problems. First, DSRG proposes an instruction-guidance linguistic module (IGL) and an appearance-semantics visual module (ASV) for boosting vision and language semantic learning respectively. For the memory mechanism, a global adaptive aggregation module (GAA) is devised for explicit pano
    
[^12]: NLI4CT：面向临床试验报告的多证据自然语言推理

    NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports. (arXiv:2305.03598v1 [cs.CL])

    [http://arxiv.org/abs/2305.03598](http://arxiv.org/abs/2305.03598)

    本文提出了一种面向临床试验报告的自然语言推理模型，通过检索支持事实来确定自然语言陈述和CTR之间的推理关系。

    

    如何解释和检索用于支持临床决策的医学证据？多年来，积累下来的临床试验报告包含了发展个性化医学所必需的信息。然而，为了找到最佳的实验治疗证据，手动检查超过400,000个临床试验报告是实际上不可行的。自然语言推理（NLI）提供了一个潜在的解决方案，通过允许可扩展计算文本蕴含关系。然而，现有的NLI模型在生物医学语料库上表现不佳，之前发布的数据集无法捕捉CTR推理的全部复杂性。在本文中，我们提出了一种新的资源，以推进关于CTR推理的NLI研究。该资源包括两个主要任务。首先，确定自然语言陈述和CTR之间的推理关系。其次，检索支持事实以证明预测的关系。我们提供了NLI4CT，一个基于CTR的语料库。

    How can we interpret and retrieve medical evidence to support clinical decisions? Clinical trial reports (CTR) amassed over the years contain indispensable information for the development of personalized medicine. However, it is practically infeasible to manually inspect over 400,000+ clinical trial reports in order to find the best evidence for experimental treatments. Natural Language Inference (NLI) offers a potential solution to this problem, by allowing the scalable computation of textual entailment. However, existing NLI models perform poorly on biomedical corpora, and previously published datasets fail to capture the full complexity of inference over CTRs. In this work, we present a novel resource to advance research on NLI for reasoning on CTRs. The resource includes two main tasks. Firstly, to determine the inference relation between a natural language statement, and a CTR. Secondly, to retrieve supporting facts to justify the predicted relation. We provide NLI4CT, a corpus of
    
[^13]: 现在它听起来像你了：在设备上学习个性化词汇

    Now It Sounds Like You: Learning Personalized Vocabulary On Device. (arXiv:2305.03584v1 [cs.CL])

    [http://arxiv.org/abs/2305.03584](http://arxiv.org/abs/2305.03584)

    这项研究提出了一种称为“生词扩展”的技术，通过个性化的“生词适配器”来学习个性化词汇，提高了生词覆盖率并显著提高了模型准确度。

    

    近年来，联邦学习在进行各种自然语言处理任务方面已经显示出显著进展。这项工作侧重于应用个性化联邦学习进行设备端语言建模。由于内存和延迟的限制，这些模型无法支持子单词标记或波束搜索解码的复杂性，因此决定部署封闭词汇的语言模型。然而，封闭词汇模型无法处理特定用户的生词，为了解决这个问题，我们提出了一种称为“生词扩展”的新技术，该技术提高了生词覆盖率，增加了模型的准确性，同时最大程度地减少了对内存和延迟的影响。这种方法引入了个性化的“生词适配器”，有效地从中央模型传输知识，并为个性化词汇学习单词嵌入。在一组常见的联邦学习基准测试中，生词扩展方法明显优于标准个性化联邦学习方法。

    In recent years, Federated Learning (FL) has shown significant advancements in its ability to perform various natural language processing (NLP) tasks. This work focuses on applying personalized FL for on-device language modeling. Due to limitations of memory and latency, these models cannot support the complexity of sub-word tokenization or beam search decoding, resulting in the decision to deploy a closed-vocabulary language model. However, closed-vocabulary models are unable to handle out-of-vocabulary (OOV) words belonging to specific users. To address this issue, We propose a novel technique called "OOV expansion" that improves OOV coverage and increases model accuracy while minimizing the impact on memory and latency. This method introduces a personalized "OOV adapter" that effectively transfers knowledge from a central model and learns word embedding for personalized vocabulary. OOV expansion significantly outperforms standard FL personalization methods on a set of common FL benc
    
[^14]: 在语境学习中保持连贯性：使用大型语言模型进行即席机器翻译的研究

    In-context Learning as Maintaining Coherency: A Study of On-the-fly Machine Translation Using Large Language Models. (arXiv:2305.03573v1 [cs.CL])

    [http://arxiv.org/abs/2305.03573](http://arxiv.org/abs/2305.03573)

    本文探究了机器翻译的在语境学习现象，提出了在语境学习应该是保持结果与其语境具有连贯性的生成任务。实验结果表明，将具有长期连贯性的样例用于翻译可以提高翻译性能。

    

    通常把在语境学习现象看做是“从例子中学习”。本文研究了机器翻译的学习过程，将在语境学习看作是生成结果任务，要求结果与其语境具有连贯性。我们通过对4个领域的随机样例的研究发现，当显示领域内样例时，翻译性能得到了提升。接下来，我们研究了具有移动窗口的领域内设置中的连贯性，并将其与文献中先前确定的其他因素如长度、表面相似性和句子嵌入相似性进行了比较。我们的结果显示，在3个模型（GPTNeo2.7B、Bloom3B、XGLM2.9B）和3个翻译方向（en→{pt，de，fr}）中，样例与测试句子的长期连贯性是流向翻译性能的良好指标。

    The phenomena of in-context learning has typically been thought of as "learning from examples". In this work which focuses on Machine Translation, we present a perspective of in-context learning as the desired generation task maintaining coherency with its context, i.e., the prompt examples. We first investigate randomly sampled prompts across 4 domains, and find that translation performance improves when shown in-domain prompts. Next, we investigate coherency for the in-domain setting, which uses prompt examples from a moving window. We study this with respect to other factors that have previously been identified in the literature such as length, surface similarity and sentence embedding similarity. Our results across 3 models (GPTNeo2.7B, Bloom3B, XGLM2.9B), and three translation directions (\texttt{en}$\rightarrow$\{\texttt{pt, de, fr}\}) suggest that the long-term coherency of the prompts and the test sentence is a good indicator of downstream translation performance. In doing so, 
    
[^15]: 利用BERT语言模型对阿拉伯语长文档进行分类

    Leveraging BERT Language Model for Arabic Long Document Classification. (arXiv:2305.03519v1 [cs.CL])

    [http://arxiv.org/abs/2305.03519](http://arxiv.org/abs/2305.03519)

    本文研究了定制化的阿拉伯语长文档分类模型，提出了两个简单却有效的模型，并与Longformer和RoBERT进行了比较。结果表明，我们的模型在两个数据集上都优于Longformer和RoBERT。

    

    考虑到全球阿拉伯语使用者的数量以及在某些领域（如法律、医学甚至新闻）中网上的内容数量显著增长，长文档会被定期产生。使用传统学习模型对这些文档进行分类通常是不切实际的，因为文档的长度增加会使计算要求持续上升。因此，有必要专门为长文本文档定制这些模型。在本文中，我们提出了两个简单但有效的模型来分类阿拉伯语的长文档。我们还微调了两个不同的模型，即Longformer和RoBERT，完成了同样的任务，并将它们的结果与我们的模型进行了比较。我们的两个模型在两个不同的数据集中都优于Longformer和RoBERT。

    Given the number of Arabic speakers worldwide and the notably large amount of content in the web today in some fields such as law, medicine, or even news, documents of considerable length are produced regularly. Classifying those documents using traditional learning models is often impractical since extended length of the documents increases computational requirements to an unsustainable level. Thus, it is necessary to customize these models specifically for long textual documents. In this paper we propose two simple but effective models to classify long length Arabic documents. We also fine-tune two different models-namely, Longformer and RoBERT, for the same task and compare their results to our models. Both of our models outperform the Longformer and RoBERT in this task over two different datasets.
    
[^16]: 基于子空间学习的黑匣子提示调优

    Black-box Prompt Tuning with Subspace Learning. (arXiv:2305.03518v1 [cs.CL])

    [http://arxiv.org/abs/2305.03518](http://arxiv.org/abs/2305.03518)

    本文提出了基于子空间学习的黑匣子提示调优（BSL）框架，通过元学习在相似任务的集合中识别子空间，以改善黑匣子提示调优的通用性，在下游任务和LLMs上都能够持续达到竞争性的表现水平。

    

    黑匣子提示调优使用无导数优化算法在低维子空间中学习提示，而不是通过大语言模型（LLM）的网络进行反向传播。最近的研究发现黑匣子提示调优在不同任务和LLMs上缺乏通用性，这与不恰当的子空间选择有关。本文提出了基于子空间学习的黑匣子提示调优（BSL）来改善黑匣子提示调优的通用性。基于相似任务的集合上进行元学习以确定子空间可以识别类似任务的最优提示，并且可以保证在相似任务上进行子空间优化找到一个在目标任务上表现良好的提示。实验结果表明，我们的BSL框架无论在下游任务和LLMs上都能够持续达到竞争性的表现水平。

    Black-box prompt tuning uses derivative-free optimization algorithms to learn prompts in low-dimensional subspaces instead of back-propagating through the network of Large Language Models (LLMs). Recent studies have found that black-box prompt tuning lacks versatility across tasks and LLMs, which we believe is related to the inappropriate choice of subspaces. In this paper, we propose Black-box prompt tuning with Subspace Learning (BSL) to improve the versatility of black-box prompt tuning. Based on the assumption that nearly optimal prompts for similar tasks exist in a common subspace, we propose identifying such subspaces by meta-learning on a set of similar source tasks. Therefore, for a target task that shares similarities with source tasks, we guarantee that optimizing in the subspace can find a prompt that performs well on the target task. Experiments confirm that our BSL framework consistently achieves competitive performance regardless of downstream tasks and LLMs.
    
[^17]: 从文本中实现少样本领域自适应视觉融合事件检测

    Few-shot Domain-Adaptive Visually-fused Event Detection from Text. (arXiv:2305.03517v1 [cs.CL])

    [http://arxiv.org/abs/2305.03517](http://arxiv.org/abs/2305.03517)

    本文提出了一种基于视觉融合和领域自适应的事件检测方法，可以用少量标记数据训练并且适应于新领域。

    

    近年来，将辅助模态如图像整合到事件检测模型中已经引起人们的越来越多的关注。自然语言描述情境的复杂性促使研究人员利用相关的视觉上下文来提高事件检测的性能。然而，目前这个领域的方法在数据稀缺性方面存在问题，需要许多标记好的文本-图像对来训练模型。此外，在推断时无法获得视觉上下文的限制也会对这些模型的性能产生负面影响，使其在实际场景中难以应用。本文提出了一种新颖的领域自适应视觉融合事件检测方法，可以用很少的标记图像-文本配对数据点进行训练。具体来说，我们引入了一种称为视觉想象器的方法，它可以在没有视觉上下文的情况下从文本中合成图像，并且可以根据需要定制到特定的领域。通过这种方法，我们的方法消除了需要大量标记数据的需求，并且只需少量的标记图像-文本对就可以适应于新领域。我们在基准数据集上评估了我们的方法，并显示其优于现有的最先进的领域自适应事件检测方法。

    Incorporating auxiliary modalities such as images into event detection models has attracted increasing interest over the last few years. The complexity of natural language in describing situations has motivated researchers to leverage the related visual context to improve event detection performance. However, current approaches in this area suffer from data scarcity, where a large amount of labelled text-image pairs are required for model training. Furthermore, limited access to the visual context at inference time negatively impacts the performance of such models, which makes them practically ineffective in real-world scenarios. In this paper, we present a novel domain-adaptive visually-fused event detection approach that can be trained on a few labelled image-text paired data points. Specifically, we introduce a visual imaginator method that synthesises images from text in the absence of visual context. Moreover, the imaginator can be customised to a specific domain. In doing so, our
    
[^18]: 大型语言模型能否改变计算社会科学？

    Can Large Language Models Transform Computational Social Science?. (arXiv:2305.03514v1 [cs.CL])

    [http://arxiv.org/abs/2305.03514](http://arxiv.org/abs/2305.03514)

    本文研究了大型语言模型作为计算社会科学工具的潜力。虽然在分类任务上没有优势，但在自由形式编码任务上表现优异，今后可以作为零-shot检测工具进行使用，

    

    ChatGPT等大型语言模型(LLMs)能够成功地在许多语言处理任务中进行零-shot操作（无需训练数据）。如果这种能力也适用于对说服力和政治意识形态等社会现象的编码，那么LLMs就可以有效地改变计算社会科学(CSS)。本研究提供了使用LLMs作为CSS工具的路线图。为此，我们提供了一组优秀的提示实践以及一个广泛的评估流程，以测量13种语言模型在24个代表性的CSS基准测试上的零-shot性能。在分类任务上，LLMs无法超越最佳微调模型，但仍然与人类达成了公平的协议水平。在自由形式的编码任务（生成）上，LLMs生成的解释常常超过了工作者的黄金参考的质量。我们得出结论，今天的LLMs可以通过两种方式从根本上增强CSS研究流程：(1)作为零-shot检测工具进行无缝工作。

    Large Language Models (LLMs) like ChatGPT are capable of successfully performing many language processing tasks zero-shot (without the need for training data). If this capacity also applies to the coding of social phenomena like persuasiveness and political ideology, then LLMs could effectively transform Computational Social Science (CSS). This work provides a road map for using LLMs as CSS tools. Towards this end, we contribute a set of prompting best practices and an extensive evaluation pipeline to measure the zero-shot performance of 13 language models on 24 representative CSS benchmarks. On taxonomic labeling tasks (classification), LLMs fail to outperform the best fine-tuned models but still achieve fair levels of agreement with humans. On free-form coding tasks (generation), LLMs produce explanations that often exceed the quality of crowdworkers' gold references. We conclude that today's LLMs can radically augment the CSS research pipeline in two ways: (1) serving as zero-shot d
    
[^19]: ChatGraph: 通过将ChatGPT的知识转换为图形来实现可解释的文本分类

    ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs. (arXiv:2305.03513v1 [cs.CL])

    [http://arxiv.org/abs/2305.03513](http://arxiv.org/abs/2305.03513)

    ChatGraph通过将ChatGPT的知识转换为图形，提高了文本分类的可解释性和性能

    

    ChatGPT作为最近推出的大型语言模型（LLM），在各种自然语言处理（NLP）任务中展现出卓越的性能。然而，存在两个主要限制阻碍了它的潜在应用：（1）在下游任务上微调的不灵活性和（2）在决策过程中缺乏可解释性。为了解决这些限制，我们提出了一种新颖的框架，利用ChatGPT的能力来进行特定任务（如文本分类），同时提高其可解释性。

    ChatGPT, as a recently launched large language model (LLM), has shown superior performance in various natural language processing (NLP) tasks. However, two major limitations hinder its potential applications: (1) the inflexibility of finetuning on downstream tasks and (2) the lack of interpretability in the decision-making process. To tackle these limitations, we propose a novel framework that leverages the power of ChatGPT for specific tasks, such as text classification, while improving its interpretability. The proposed framework conducts a knowledge graph extraction task to extract refined and structural knowledge from the raw data using ChatGPT. The rich knowledge is then converted into a graph, which is further used to train an interpretable linear classifier to make predictions. To evaluate the effectiveness of our proposed method, we conduct experiments on four datasets. The result shows that our method can significantly improve the performance compared to directly utilizing Cha
    
[^20]: 构建多模态AI聊天机器人

    Building Multimodal AI Chatbots. (arXiv:2305.03512v1 [cs.CL])

    [http://arxiv.org/abs/2305.03512](http://arxiv.org/abs/2305.03512)

    本研究提出了一个多模态AI聊天机器人，使用两个深度学习模型，实现了图像检索和响应生成功能，并在PhotoChat数据集上得到了较好的结果。

    

    本研究旨在创建一个多模态AI系统，与人类进行聊天并分享相关照片。早期的工作仅限于关于图像中特定对象或场景的对话，而最近的工作已将图像纳入开放域对话中。然而，它们的响应生成器是单模态的，仅接受文本输入而不接受图像输入，因此容易生成与对话中分享的图像相矛盾的响应。因此，本研究提出了一个完整的聊天机器人系统，使用两个多模态深度学习模型：一个理解文本的图像检索器和一个理解图像的响应生成器。 图像检索器由ViT和BERT实现，根据对话历史记录和图像数据库选择最相关的图像。 响应生成器由ViT和GPT-2/DialoGPT实现，生成根据对话历史和最近检索的图像合适的响应。这两个模型在带有成对图像的开放域对话数据集PhotoChat上进行了培训和评估。结果表明，所提出的多模态系统优于仅文本和单模态系统，达到了更高的图像基础准确性和更好的对话连贯性。

    This work aims to create a multimodal AI system that chats with humans and shares relevant photos. While earlier works were limited to dialogues about specific objects or scenes within images, recent works have incorporated images into open-domain dialogues. However, their response generators are unimodal, accepting text input but no image input, thus prone to generating responses contradictory to the images shared in the dialogue. Therefore, this work proposes a complete chatbot system using two multimodal deep learning models: an image retriever that understands texts and a response generator that understands images. The image retriever, implemented by ViT and BERT, selects the most relevant image given the dialogue history and a database of images. The response generator, implemented by ViT and GPT-2/DialoGPT, generates an appropriate response given the dialogue history and the most recently retrieved image. The two models are trained and evaluated on PhotoChat, an open-domain dialo
    
[^21]: 基于翻译对齐的视觉语言模型跨语言迁移的参数高效方法

    Parameter-Efficient Cross-lingual Transfer of Vision and Language Models via Translation-based Alignment. (arXiv:2305.03510v1 [cs.CL])

    [http://arxiv.org/abs/2305.03510](http://arxiv.org/abs/2305.03510)

    本文提出了一个通过翻译对齐的方式实现参数高效、跨语言的迁移学习框架，实验结果显示该框架能够显著减少多语言之间的性能差异。

    

    预训练的视觉语言模型（如CLIP）在连接图像和英语文本方面取得了显著的成功。尽管最近试图扩展CLIP以支持其他语言，但由于资源不平衡，观察到了不同语言之间的性能差异。此外，当前的预训练模型的跨语言迁移方法会消耗大量资源。因此，我们提出了一种新的参数高效的跨语言迁移学习框架，利用基于翻译的对齐方法来减轻多语言差异，并探索参数高效的微调方法来实现参数高效的跨语言迁移。在XTD和Multi30K数据集上进行了广泛的实验，涵盖了零-shot、few-shot和全数据集学习场景下的11种语言，结果显示我们的框架显著减少了语言之间的多语言差异，并提高了性能。

    Pre-trained vision and language models such as CLIP have witnessed remarkable success in connecting images and texts with a primary focus on English texts. Despite recent efforts to extend CLIP to support other languages, disparities in performance among different languages have been observed due to uneven resource availability. Additionally, current cross-lingual transfer methods of those pre-trained models would consume excessive resources for a large number of languages. Therefore, we propose a new parameter-efficient cross-lingual transfer learning framework that utilizes a translation-based alignment method to mitigate multilingual disparities and explores parameter-efficient fine-tuning methods for parameter-efficient cross-lingual transfer. Extensive experiments on XTD and Multi30K datasets, covering 11 languages under zero-shot, few-shot, and full-dataset learning scenarios, show that our framework significantly reduces the multilingual disparities among languages and improves 
    
[^22]: Diffusion Explainer：用于文本到图像稳定扩散的可视化解释工具

    Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion. (arXiv:2305.03509v1 [cs.CL])

    [http://arxiv.org/abs/2305.03509](http://arxiv.org/abs/2305.03509)

    Diffusion Explainer是第一个可交互的可视化工具，用于解释稳定扩散如何将文本提示转化为图像，用户可以通过动画和交互元素流畅地在多个抽象级别之间过渡，从而更好地理解提示对图像生成的影响。

    

    基于扩散的生成模型通过创造逼真的图像而获得了全球关注。然而，它们复杂的内部结构和操作往往使得非专业人员难以理解。我们提出了 Diffusion Explainer，这是第一个交互式可视化工具，用于解释稳定扩散如何将文本提示转化为图像。Diffusion Explainer紧密地将稳定扩散的复杂组件的视觉概述与其潜在操作的详细说明相结合，通过动画和交互元素使用户可以流畅地在多个抽象级别之间过渡。通过比较由两个相关文本提示引导的图像表示的演变来指导精细时间步长，用户可以发现提示对图像生成的影响。Diffusion Explainer在用户的Web浏览器中本地运行，无需安装或专门的硬件，扩大了公众对现代人工智能技术的教育获取。

    Diffusion-based generative models' impressive ability to create convincing images has captured global attention. However, their complex internal structures and operations often make them difficult for non-experts to understand. We present Diffusion Explainer, the first interactive visualization tool that explains how Stable Diffusion transforms text prompts into images. Diffusion Explainer tightly integrates a visual overview of Stable Diffusion's complex components with detailed explanations of their underlying operations, enabling users to fluidly transition between multiple levels of abstraction through animations and interactive elements. By comparing the evolutions of image representations guided by two related text prompts over refinement timesteps, users can discover the impact of prompts on image generation. Diffusion Explainer runs locally in users' web browsers without the need for installation or specialized hardware, broadening the public's education access to modern AI tec
    
[^23]: CiteCaseLAW: 用于法律辅助写作的判例法引用值检测

    CiteCaseLAW: Citation Worthiness Detection in Caselaw for Legal Assistive Writing. (arXiv:2305.03508v1 [cs.CL])

    [http://arxiv.org/abs/2305.03508](http://arxiv.org/abs/2305.03508)

    本研究旨在解决法律写作中引用值的鉴别问题，通过使用一个包含 178M 句子的标记数据集并测试多种深度学习模型的性能，结果表明专门针对该领域预训练的模型优于其他模型。

    

    在法律文件撰写中，正确引用案例法和其他来源以证明声明和论点是其中的一个关键要素。理解法律领域并识别适当的引用上下文或值得引用的句子是需要昂贵的手动注释的具有挑战性的任务。法律术语、语义和高度特异性的存在使得法律语言变得复杂，从而使任何相关的法律任务难以自动化。本研究关注的是引用值鉴别的问题。它旨在成为当今引文推荐系统中的初始步骤，以减轻提取足够的引文上下文的负担。为此，我们从 Caselaw 访问项目 (CAP) 中引入了一个包含 178M 句子的标记数据集，用于法律领域中的引文值检测。在这个全新的数据集上，我们检查了各种深度学习模型的性能。专门针对该领域预训练的模型往往优于其他模型。

    In legal document writing, one of the key elements is properly citing the case laws and other sources to substantiate claims and arguments. Understanding the legal domain and identifying appropriate citation context or cite-worthy sentences are challenging tasks that demand expensive manual annotation. The presence of jargon, language semantics, and high domain specificity makes legal language complex, making any associated legal task hard for automation. The current work focuses on the problem of citation-worthiness identification. It is designed as the initial step in today's citation recommendation systems to lighten the burden of extracting an adequate set of citation contexts. To accomplish this, we introduce a labeled dataset of 178M sentences for citation-worthiness detection in the legal domain from the Caselaw Access Project (CAP). The performance of various deep learning models was examined on this novel dataset. The domain-specific pre-trained model tends to outperform other
    
[^24]: 读两遍：通过重新审视证据实现准确且可解释的事实验证

    Read it Twice: Towards Faithfully Interpretable Fact Verification by Revisiting Evidence. (arXiv:2305.03507v1 [cs.CL])

    [http://arxiv.org/abs/2305.03507](http://arxiv.org/abs/2305.03507)

    本研究提出了一种名为“ ReRead”的事实验证模型，其以两个阶段（证据检索和声明验证）实现准确且可解释的事实验证，并在FEVER数据集上实现了最先进的结果。

    

    现实世界中的事实验证任务旨在通过从原始文档中检索证据来验证声明的事实性。 检索到的证据的质量在该任务中起着重要作用。 理想情况下，检索到的证据应该是可信的（反映了模型在声明验证中的决策过程）且合理的（对人类有说服力），并能提高验证任务的准确性。 尽管现有的方法利用声明和文档之间的语义或表面形式的相似性度量来检索证据，但它们都依赖于某些启发式方法，这些方法会阻止它们满足所有三个要求。 鉴于此，我们提出了一种名为“ ReRead”的事实验证模型，以检索证据并验证声明，该模型具有以下两个阶段：1）证据检索阶段，该阶段通过使用忠实且合理的证据取回器来获取可解释的证据；2）声明验证阶段，该阶段重新审视检索到的证据以验证声明。 我们在广泛使用的FEVER数据集上验证了所提出的模型，实验结果表明，我们的模型取得了最先进的结果。

    Real-world fact verification task aims to verify the factuality of a claim by retrieving evidence from the source document. The quality of the retrieved evidence plays an important role in claim verification. Ideally, the retrieved evidence should be faithful (reflecting the model's decision-making process in claim verification) and plausible (convincing to humans), and can improve the accuracy of verification task. Although existing approaches leverage the similarity measure of semantic or surface form between claims and documents to retrieve evidence, they all rely on certain heuristics that prevent them from satisfying all three requirements. In light of this, we propose a fact verification model named ReRead to retrieve evidence and verify claim that: (1) Train the evidence retriever to obtain interpretable evidence (i.e., faithfulness and plausibility criteria); (2) Train the claim verifier to revisit the evidence retrieved by the optimized evidence retriever to improve the accura
    
[^25]: SI-LSTM: 用于对话情感识别的说话人混合长短期记忆和跨模态注意力机制

    SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation. (arXiv:2305.03506v1 [cs.CL])

    [http://arxiv.org/abs/2305.03506](http://arxiv.org/abs/2305.03506)

    SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    

    跨模态的对话情感识别对于智能医疗、对话人工智能和聊天历史观点挖掘等应用至关重要。本文提出了一种基于说话人信息增强长短期记忆（SI-LSTM）的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    Emotion Recognition in Conversation~(ERC) across modalities is of vital importance for a variety of applications, including intelligent healthcare, artificial intelligence for conversation, and opinion mining over chat history. The crux of ERC is to model both cross-modality and cross-time interactions throughout the conversation. Previous methods have made progress in learning the time series information of conversation while lacking the ability to trace down the different emotional states of each speaker in a conversation. In this paper, we propose a recurrent structure called Speaker Information Enhanced Long-Short Term Memory (SI-LSTM) for the ERC task, where the emotional states of the distinct speaker can be tracked in a sequential way to enhance the learning of the emotion in conversation. Further, to improve the learning of multimodal features in ERC, we utilize a cross-modal attention component to fuse the features between different modalities and model the interaction of the 
    
[^26]: 合理看待所看到的：关系提取的连续理据抽取

    Think Rationally about What You See: Continuous Rationale Extraction for Relation Extraction. (arXiv:2305.03503v1 [cs.CL])

    [http://arxiv.org/abs/2305.03503](http://arxiv.org/abs/2305.03503)

    本研究提出了一种新颖的关系提取的理据抽取框架RE2，利用两个连续性和稀疏性因素从句子中获取相关而连贯的理据，解决了如何保留相关内容并从句子中去掉噪音段落的问题。实验结果显示我们的模型优于现有的最先进方法，并且提取出的理据对于推理和解释是有用的。

    

    关系提取旨在根据两个实体的语境提取潜在关系，因此，从句子中推导出合理的语境非常重要。以往的研究要么专注于如何利用实体信息（例如，实体类型，实体用语）来推断关系，但忽略了以语境为重点的内容，要么使用反事实思维来消除模型对实体潜在关系的偏见，但关系推理过程仍会受到无关内容的干扰。因此，如何保留有关内容并从句子中去掉噪音段落是一项关键任务。此外，保留的内容需要足够流畅，以保持语义的连贯性和可解释性。在这项工作中，我们提出了一种新颖的理据抽取框架RE2，它利用两个连续性和稀疏性因素从句子中获取相关而连贯的理据。为了解决黄金理据未标记的问题，RE2应用一种无监督方法生成候选理据，并选择最相关和连贯的理据来指导RE模型。两个基准数据集上的实验结果表明，我们的模型优于现有的最先进方法，并且提取出的理据对于推理和解释是有用的。

    Relation extraction (RE) aims to extract potential relations according to the context of two entities, thus, deriving rational contexts from sentences plays an important role. Previous works either focus on how to leverage the entity information (e.g., entity types, entity verbalization) to inference relations, but ignore context-focused content, or use counterfactual thinking to remove the model's bias of potential relations in entities, but the relation reasoning process will still be hindered by irrelevant content. Therefore, how to preserve relevant content and remove noisy segments from sentences is a crucial task. In addition, retained content needs to be fluent enough to maintain semantic coherence and interpretability. In this work, we propose a novel rationale extraction framework named RE2, which leverages two continuity and sparsity factors to obtain relevant and coherent rationales from sentences. To solve the problem that the gold rationales are not labeled, RE2 applies an
    
[^27]: 基于Wordle游戏探究词语难度及其影响因素

    Explore the difficulty of words and its influential attributes based on the Wordle game. (arXiv:2305.03502v1 [cs.CL])

    [http://arxiv.org/abs/2305.03502](http://arxiv.org/abs/2305.03502)

    本文探究了基于Wordle游戏的词语难度预测方法及其影响因素，并通过因子分析与线性回归建立了关系。

    

    本文采用Wordle游戏中猜测次数的分布和期望作为衡量词语难度的度量标准，并探究了影响词语难度的因素。我们利用Monte Carlo模拟玩家的猜测过程预测难度分布，利用Markov来生成词语的关联性，缩小每个词语猜测次数的实际分布与原始分布之间的差距，然后使用套索回归预测猜测次数期望的偏差，并利用二次规划获得原始分布的修正。我们首先使用分层聚类方法将词语按猜测次数期望值分为不同的难度级别，然后利用因子分析降低词汇属性变量的数量，显著的因素包括邻近词汇的数量、字母相似性、子串相似性和词频。最后，我们使用线性回归模型建立了上述影响因素与词语难度之间的关系。

    We adopt the distribution and expectation of guessing times in game Wordle as metrics to predict the difficulty of words and explore their influence factors. In order to predictthe difficulty distribution, we use Monte Carlo to simulate the guessing process of players and then narrow the gap between raw and actual distribution of guessing times for each word with Markov which generates the associativity of words. Afterwards, we take advantage of lasso regression to predict the deviation of guessing times expectation and quadratic programming to obtain the correction of the original distribution.To predict the difficulty levels, we first use hierarchical clustering to classify the difficulty levels based on the expectation of guessing times. Afterwards we downscale the variables of lexical attributes based on factor analysis. Significant factors include the number of neighboring words, letter similarity, sub-string similarity, and word frequency. Finally, we build the relationship betwe
    
[^28]: 利用Transformers双向编码器表征的癌症标志分类方法

    Cancer Hallmark Classification Using Bidirectional Encoder Representations From Transformers. (arXiv:2305.03501v1 [cs.CL])

    [http://arxiv.org/abs/2305.03501](http://arxiv.org/abs/2305.03501)

    本文通过在小型癌症生物医学文本语料库上微调BERT模型，提出了一种高精度分类癌症标志的方法，并在实验中取得了94.45%的精度，比以往文献的研究结果高出至少8.04%。

    

    本文提出了一种新的方法来精确地分类癌症的标志，这是癌症研究中至关重要的任务。我们提出的方法利用了双向编码器表征的Transformers（BERT）架构，在小型癌症生物医学文本语料库上进行预训练模型的微调。实验结果表明，我们的方法取得了94.45%的显著精度，这比文献中几乎所有之前的研究结果都要高出至少8.04%。这些发现突显了我们提出的模型在准确分类和理解癌症研究文本文献方面的有效性，因此对该领域做出了显著贡献。由于癌症仍然是全球十大死因之一，我们的方法在推进癌症研究方面具有巨大的潜力。

    This paper presents a novel approach to accurately classify the hallmarks of cancer, which is a crucial task in cancer research. Our proposed method utilizes the Bidirectional Encoder Representations from Transformers (BERT) architecture, which has shown exceptional performance in various downstream applications. By applying transfer learning, we fine-tuned the pre-trained BERT model on a small corpus of biomedical text documents related to cancer. The outcomes of our experimental investigations demonstrate that our approach attains a noteworthy accuracy of 94.45%, surpassing almost all prior findings with a substantial increase of at least 8.04% as reported in the literature. These findings highlight the effectiveness of our proposed model in accurately classifying and comprehending text documents for cancer research, thus contributing significantly to the field. As cancer remains one of the top ten leading causes of death globally, our approach holds great promise in advancing cancer
    
[^29]: 在加密文本上训练自然语言处理模型以增强隐私保护

    Training Natural Language Processing Models on Encrypted Text for Enhanced Privacy. (arXiv:2305.03497v1 [cs.CL])

    [http://arxiv.org/abs/2305.03497](http://arxiv.org/abs/2305.03497)

    本研究提出了一种在加密文本数据上训练NLP模型的方法，以缓解数据隐私问题，同时保持与非加密数据训练模型相似的性能。

    

    随着云服务在训练和部署机器学习模型中的不断增加，数据隐私已成为一个主要关注点。这对于自然语言处理（NLP）模型尤为重要，因为这些模型通常处理涉及个人通信和机密文件等敏感信息。本研究提出了一种在加密文本数据上训练NLP模型的方法，以缓解数据隐私问题，同时保持与非加密数据训练模型相似的性能。我们使用两种不同的架构，即Doc2Vec + XGBoost和Doc2Vec + LSTM，演示了我们的方法，并在20 Newsgroups数据集上评估了模型。我们的结果表明，加密和非加密模型均可实现相似的性能，说明我们的加密方法在保持模型准确性的同时有效地维护了数据隐私。为了复制我们的实验，我们在以下地址提供了Colab笔记本：https://t.ly/lR-TP

    With the increasing use of cloud-based services for training and deploying machine learning models, data privacy has become a major concern. This is particularly important for natural language processing (NLP) models, which often process sensitive information such as personal communications and confidential documents. In this study, we propose a method for training NLP models on encrypted text data to mitigate data privacy concerns while maintaining similar performance to models trained on non-encrypted data. We demonstrate our method using two different architectures, namely Doc2Vec+XGBoost and Doc2Vec+LSTM, and evaluate the models on the 20 Newsgroups dataset. Our results indicate that both encrypted and non-encrypted models achieve comparable performance, suggesting that our encryption method is effective in preserving data privacy without sacrificing model accuracy. In order to replicate our experiments, we have provided a Colab notebook at the following address: https://t.ly/lR-TP
    
[^30]: 基于“梯度下降”与 beam search 的自动提示优化

    Automatic Prompt Optimization with "Gradient Descent" and Beam Search. (arXiv:2305.03495v1 [cs.CL])

    [http://arxiv.org/abs/2305.03495](http://arxiv.org/abs/2305.03495)

    在基于大型语言模型的自然语言处理中，使用梯度下降和 beam search 的自动提示优化方法可以自动改进提示，提高性能。

    

    大型语言模型（LLM）在通用智能方面展现了出色性能，但其能力仍高度依赖于手写的提示，需要大量的试错尝试。我们提出了一个简单而非参数化的解决方案——自动提示优化（APO），其灵感来自于使用数值梯度下降自动改进提示。

    Large Language Models (LLMs) have shown impressive performance as general purpose agents, but their abilities remain highly dependent on prompts which are hand written with onerous trial-and-error effort. We propose a simple and nonparametric solution to this problem, Automatic Prompt Optimization (APO), which is inspired by numerical gradient descent to automatically improve prompts, assuming access to training data and an LLM API. The algorithm uses minibatches of data to form natural language ``gradients'' that criticize the current prompt. The gradients are then ``propagated'' into the prompt by editing the prompt in the opposite semantic direction of the gradient. These gradient descent steps are guided by a beam search and bandit selection procedure which significantly improves algorithmic efficiency. Preliminary results across three benchmark NLP tasks and the novel problem of LLM jailbreak detection suggest that Automatic Prompt Optimization can outperform prior prompt editing 
    
[^31]: 通过利用语境中的泛指表达探究交互式获取精细视觉概念

    Interactive Acquisition of Fine-grained Visual Concepts by Exploiting Semantics of Generic Characterizations in Discourse. (arXiv:2305.03461v1 [cs.CL])

    [http://arxiv.org/abs/2305.03461](http://arxiv.org/abs/2305.03461)

    本文研究了交互式任务学习中的符号接地任务，在教师的泛指语句和上下文中的暗示下实现了更高效的数据接地结果。

    

    交互式任务学习涉及通过与人类用户自然交互来学习未知领域概念。本文中，我们在ITL的限制下，探索了一项具有挑战性的符号接地任务——区分外观非常相似的物体类别。我们通过实证证明，利用教师的泛指语句（例如，“X具有属性Z。”）以及它们在上下文中的暗示（例如，“X和Y有什么不同？”的回答是，“推断Y不具备属性Z”）可以获得更高效的数据接地结果。

    Interactive Task Learning (ITL) concerns learning about unforeseen domain concepts via natural interactions with human users. The learner faces a number of significant constraints: learning should be online, incremental and few-shot, as it is expected to perform tangible belief updates right after novel words denoting unforeseen concepts are introduced. In this work, we explore a challenging symbol grounding task--discriminating among object classes that look very similar--within the constraints imposed by ITL. We demonstrate empirically that more data-efficient grounding results from exploiting the truth-conditions of the teacher's generic statements (e.g., "Xs have attribute Z.") and their implicatures in context (e.g., as an answer to "How are Xs and Ys different?", one infers Y lacks attribute Z).
    
[^32]: 多视角图形表示学习用于解决混合型数值推理问答问题

    Multi-View Graph Representation Learning for Answering Hybrid Numerical Reasoning Question. (arXiv:2305.03458v1 [cs.CL])

    [http://arxiv.org/abs/2305.03458](http://arxiv.org/abs/2305.03458)

    本文提出了一种基于多视角图形表示学习的混合型数值推理问答模型，能够从表格视角、关系视角和数值视角捕捉混合数据之间的粒度关系和空间结构信息，能够有效提高数值推理任务的准确率。

    

    混合型问答 (HybridQA) 数据含有文本与表格数据，需要模型选择合适证据进行数值推理任务。现有的基于编码器-解码器框架的方法使用基于表达树的解码器来解决数值推理问题。然而，编码器更倾向于使用机器阅读理解(MRC)方法,它以表格序列和文本拼接作为输入，破坏了表格和文本之间的粒度关系以及表格本身的空间结构信息。为了解决这些问题，本文提出了多视角图形 (MVG) 编码器来考虑粒度之间关系并从多个视角捕捉关系。通过使用MVGE作为模块，我们构建了面向保留混合数据原始特征的表格视图、关系视图和数值视图。我们在公开的表格文本混合QA数据集上验证了我们的模型，并显示我们提出的MVGE在数值推理子任务上优于现有最先进方法，准确率相对提高了27.0%。

    Hybrid question answering (HybridQA) over the financial report contains both textual and tabular data, and requires the model to select the appropriate evidence for the numerical reasoning task. Existing methods based on encoder-decoder framework employ a expression tree-based decoder to solve numerical reasoning problems. However, encoders rely more on Machine Reading Comprehension (MRC) methods, which take table serialization and text splicing as input, damaging the granularity relationship between table and text as well as the spatial structure information of table itself. In order to solve these problems, the paper proposes a Multi-View Graph (MVG) Encoder to take the relations among the granularity into account and capture the relations from multiple view. By utilizing MVGE as a module, we constuct Tabular View, Relation View and Numerical View which aim to retain the original characteristics of the hybrid data. We validate our model on the publicly available table-text hybrid QA 
    
[^33]: T-SciQ: 使用大型语言模型信号教授多模态链式思维推理在科学问题回答中的应用

    T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering. (arXiv:2305.03453v1 [cs.CL])

    [http://arxiv.org/abs/2305.03453](http://arxiv.org/abs/2305.03453)

    本研究使用大型语言模型信号教育科学问题回答的链式思维推理，通过生成高质量COT合理化信号，同时降低了人工注释的需求。

    

    大型语言模型(LLMs)近期在各种自然语言处理(NLP)任务中展示了出色的性能。他们还展示了执行链式思维推理以解决复杂问题的能力。最近的研究探索了复杂多模态场景下的链式思维推理，例如通过用高质量人工注释的链式思路来调整多模型模型进行科学问题回答等任务。然而，收集高质量COT合理化通常是耗时且昂贵的。此外，由于涉及冗余信息或丢失重要信息，注释合理化通常不太准确。为了解决这些问题，我们提出了一种新的方法，称为T-SciQ，旨在使用LLM信号教授科学问题回答。T-SciQ方法生成高质量的CoT合理化信号，并先进地训练较小的模型以在复杂模态中执行CoT思维推理。另外，我们引入了一种显着提高模型泛化能力的技术，从而显着减少了对人工注释合理的需求。

    Large Language Models (LLMs) have recently demonstrated exceptional performance in various Natural Language Processing (NLP) tasks. They have also shown the ability to perform chain-of-thought (CoT) reasoning to solve complex problems. Recent studies have explored CoT reasoning in complex multimodal scenarios, such as the science question answering task, by fine-tuning multimodal models with high-quality human-annotated CoT rationales. However, collecting high-quality COT rationales is usually time-consuming and costly. Besides, the annotated rationales are hardly accurate due to the redundant information involved or the essential information missed. To address these issues, we propose a novel method termed \emph{T-SciQ} that aims at teaching science question answering with LLM signals. The T-SciQ approach generates high-quality CoT rationales as teaching signals and is advanced to train much smaller models to perform CoT reasoning in complex modalities. Additionally, we introduce a no
    
[^34]: LMs固守阵地：探究具身化对语言模型理解比喻性语言的影响

    LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models. (arXiv:2305.03445v1 [cs.CL])

    [http://arxiv.org/abs/2305.03445](http://arxiv.org/abs/2305.03445)

    本文研究调查了具身化策略对语言模型解释比喻性语言的影响。结果表明，更大的模型在处理行为更具体化的隐喻性句子时表现更佳。

    

    比喻语言是语言模型的挑战，因为其解释基于单词的使用方式偏离了它们的常规顺序和含义。然而，人类可以轻松理解和诠释隐喻、比喻或习语，因为它们可以从具身隐喻中推导出来。语言是具身化的代理，如果隐喻是传统的和词汇化的，那么一个没有身体的系统就更容易理解具身概念。本文研究表明，在比喻性句子的行动更具体化时，更大的语言模型在解释隐喻句子时表现更好，并排除了与其他特征（例如单词长度或具体性）的多重共线性。

    Figurative language is a challenge for language models since its interpretation is based on the use of words in a way that deviates from their conventional order and meaning. Yet, humans can easily understand and interpret metaphors, similes or idioms as they can be derived from embodied metaphors. Language is a proxy for embodiment and if a metaphor is conventional and lexicalised, it becomes easier for a system without a body to make sense of embodied concepts. Yet, the intricate relation between embodiment and features such as concreteness or age of acquisition has not been studied in the context of figurative language interpretation concerning language models. Hence, the presented study shows how larger language models perform better at interpreting metaphoric sentences when the action of the metaphorical sentence is more embodied. The analysis rules out multicollinearity with other features (e.g. word length or concreteness) and provides initial evidence that larger language model
    
[^35]: 使用ChatGPT进行实体匹配

    Using ChatGPT for Entity Matching. (arXiv:2305.03423v1 [cs.CL])

    [http://arxiv.org/abs/2305.03423](http://arxiv.org/abs/2305.03423)

    本研究探究使用ChatGPT进行实体匹配的可行性，相较于传统方法更为有效，不需大量微调数据，且更加健壮。

    

    实体匹配是判断两个实体描述是否指向同一个真实世界实体的任务。目前最先进的实体匹配方法往往依赖于微调诸如BERT或RoBERTa之类的转换器模型。使用这些模型进行实体匹配的两个主要缺点是，（i）这些模型需要大量的微调数据才能达到良好的性能，（ii）微调后的模型对于分布外的实体不太健壮。在本文中，我们研究了使用ChatGPT进行实体匹配，作为传统转换器模型的更为健壮、数据高效的替代技术。我们从三个维度进行实验：（i）一般提示设计，（ii）上下文学习，以及（iii）提供更高级的匹配知识。我们表明 ChatGPT 与经过微调的 RoBERTa 模型具有竞争力，在一个具有挑战性的匹配任务中达到了平均的零样本性能，为83%的F1值，而 RoBERTa 需要2000个训练样本才能达到类似的性能。

    Entity Matching is the task of deciding if two entity descriptions refer to the same real-world entity. State-of-the-art entity matching methods often rely on fine-tuning Transformer models such as BERT or RoBERTa. Two major drawbacks of using these models for entity matching are that (i) the models require significant amounts of fine-tuning data for reaching a good performance and (ii) the fine-tuned models are not robust concerning out-of-distribution entities. In this paper, we investigate using ChatGPT for entity matching as a more robust, training data-efficient alternative to traditional Transformer models. We perform experiments along three dimensions: (i) general prompt design, (ii) in-context learning, and (iii) provision of higher-level matching knowledge. We show that ChatGPT is competitive with a fine-tuned RoBERTa model, reaching an average zero-shot performance of 83% F1 on a challenging matching task on which RoBERTa requires 2000 training examples for reaching a similar
    
[^36]: 基于Transformer和自然语言处理的在线手势识别

    Online Gesture Recognition using Transformer and Natural Language Processing. (arXiv:2305.03407v1 [cs.CL])

    [http://arxiv.org/abs/2305.03407](http://arxiv.org/abs/2305.03407)

    本文研究了使用Transformer架构实现在线手势识别，并结合自然语言处理，提出一种解决多级分割问题的机器翻译框架，使用大型解码空间提高对语法规则和缺损输入的鲁棒性。实验结果表明，该方法具有良好的泛化性能，能够用于多种语言和通用手写识别任务。

    

    本文使用Transformer架构为自然语言句子的字形笔画提供了强大的在线手写手势机器翻译框架。通过注意力机制，成功地利用了端到端编码器-解码器模型的潜在表示，解决了多级分割问题，同样学习了一些语言特征和句法规则。此外，使用了一些学习的Byte-Pair-Encoding（BPE）的大型解码空间，提供了对语法规则和缺损输入的鲁棒性。编码器堆栈直接获取时空数据令牌，潜在地形成了一个无限大的输入词汇表，这种方法的应用超出了本文的范围。文章还展示了编码器迁移学习的能力，可用于多种语言，结果更快的优化和共享参数。使用了一个新的在线手写手势的监督数据集，适用于通用手写识别任务。

    The Transformer architecture is shown to provide a powerful machine transduction framework for online handwritten gestures corresponding to glyph strokes of natural language sentences. The attention mechanism is successfully used to create latent representations of an end-to-end encoder-decoder model, solving multi-level segmentation while also learning some language features and syntax rules. The additional use of a large decoding space with some learned Byte-Pair-Encoding (BPE) is shown to provide robustness to ablated inputs and syntax rules. The encoder stack was directly fed with spatio-temporal data tokens potentially forming an infinitely large input vocabulary, an approach that finds applications beyond that of this work. Encoder transfer learning capabilities is also demonstrated on several languages resulting in faster optimisation and shared parameters. A new supervised dataset of online handwriting gestures suitable for generic handwriting recognition tasks was used to succ
    
[^37]: MuSe 2023多模态情感分析挑战赛：模拟情感、跨文化幽默和个性化

    The MuSe 2023 Multimodal Sentiment Analysis Challenge: Mimicked Emotions, Cross-Cultural Humour, and Personalisation. (arXiv:2305.03369v1 [cs.LG])

    [http://arxiv.org/abs/2305.03369](http://arxiv.org/abs/2305.03369)

    MuSe 2023是一组共享任务，涉及三个当代多模态情感和情绪分析问题：模拟情感、跨文化幽默和个性化。参与者需要在各自的子挑战中预测情感目标、跨文化幽默和个性化的信号。

    

    MuSe 2023是一组共享任务，涉及三个当代多模态情感和情绪分析问题：在模拟情感子挑战（MuSe-Mimic）中，参与者预测三个连续情感目标。这个子挑战利用了Hume-Vidmimic数据集，其中包含用户生成的视频。对于跨文化幽默检测子挑战（MuSe-Humour），提供了Passau Spontaneous Football Coach Humour（Passau-SFCH）数据集的扩展。参与者需要预测跨文化环境中自发幽默的出现。个性化子挑战（MuSe-Personalisation）基于Ulm-Trier Social Stress Test（Ulm-TSST）数据集，该数据集包含处于紧张状态下的被试录音。在这里，需要预测唤醒和价值信号，而部分测试标签则可用于促进个性化。MuSe 2023旨在将来自不同研究社区的广泛受众汇聚在一起。

    The MuSe 2023 is a set of shared tasks addressing three different contemporary multimodal affect and sentiment analysis problems: In the Mimicked Emotions Sub-Challenge (MuSe-Mimic), participants predict three continuous emotion targets. This sub-challenge utilises the Hume-Vidmimic dataset comprising of user-generated videos. For the Cross-Cultural Humour Detection Sub-Challenge (MuSe-Humour), an extension of the Passau Spontaneous Football Coach Humour (Passau-SFCH) dataset is provided. Participants predict the presence of spontaneous humour in a cross-cultural setting. The Personalisation Sub-Challenge (MuSe-Personalisation) is based on the Ulm-Trier Social Stress Test (Ulm-TSST) dataset, featuring recordings of subjects in a stressed situation. Here, arousal and valence signals are to be predicted, whereas parts of the test labels are made available in order to facilitate personalisation. MuSe 2023 seeks to bring together a broad audience from different research communities such as
    
[^38]: 从解析-执行到解析-执行-优化：提高复杂问题答案基于知识库的语义解析器

    From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering over Knowledge Base. (arXiv:2305.03356v1 [cs.CL])

    [http://arxiv.org/abs/2305.03356](http://arxiv.org/abs/2305.03356)

    本文提出了一种名为解析-执行-优化（Parse-Execute-Refine）的范式，通过向知识库问题应答模型演示执行中间推理步骤，可以提高复杂推理的能力。

    

    把问题解析成可执行的逻辑形式对于知识库问题应答有了显著的结果。然而，复杂的知识库问题应答是一项更具挑战性的任务，需要进行复杂的多步推理。最近，提出了一种名为KoPL的新型语义解析器，旨在显式地模拟推理过程，在复杂知识库问题应答领域实现了最先进的结果。本文进一步探讨了如何通过一种简单的解析-执行-优化范式来开发语义解析器的推理能力。我们通过向知识库问题应答模型演示执行中间推理步骤来完善和改进KoPL解析器。我们表明，这样简单的策略可以显著提高复杂推理的能力。具体而言，我们提出了三个组成部分：解析阶段，执行阶段和优化阶段，以增强复杂推理的能力。解析器使用KoPL生成透明的逻辑形式。然后，执行阶段对齐和执行这些逻辑形式。

    Parsing questions into executable logical forms has showed impressive results for knowledge-base question answering (KBQA). However, complex KBQA is a more challenging task that requires to perform complex multi-step reasoning. Recently, a new semantic parser called KoPL has been proposed to explicitly model the reasoning processes, which achieved the state-of-the-art on complex KBQA. In this paper, we further explore how to unlock the reasoning ability of semantic parsers by a simple proposed parse-execute-refine paradigm. We refine and improve the KoPL parser by demonstrating the executed intermediate reasoning steps to the KBQA model. We show that such simple strategy can significantly improve the ability of complex reasoning. Specifically, we propose three components: a parsing stage, an execution stage and a refinement stage, to enhance the ability of complex reasoning. The parser uses the KoPL to generate the transparent logical forms. Then, the execution stage aligns and execute
    
[^39]: MindGames：利用动态认知模态逻辑在大型语言模型中针对心智理论进行研究

    MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic. (arXiv:2305.03353v1 [cs.CL])

    [http://arxiv.org/abs/2305.03353](http://arxiv.org/abs/2305.03353)

    本文利用动态认知逻辑在自然语言处理模型中探讨了理解心智理论的方法。虽然GPT-4表现出改进的能力，但需要进一步提高。

    

    心智理论(ToM)是智能的重要组成部分，但准确度量它仍然是一个争议话题。先前的研究尝试将人类ToM评估应用于自然语言处理模型，使用人类创建的标准化测试或基于规则的模板。然而，这些方法主要集中在简单的推理上，并需要进一步验证。在本研究中，我们利用具有与ToM重叠的动态认知逻辑来生成更复杂的问题。我们还引入新的语言技巧来用自然语言表达这些问题。我们的研究结果表明，特定的语言模型缩放（从70M到6B和350M到174B）并不一致地产生比随机结果更好的结果。虽然GPT-4展示了改进的认知推理能力，但仍有提升空间。我们的代码和数据集可在以下链接公开获取：https://github.com/antoinelrnld/modlog https://huggingface.co/datasets/sileo

    Theory of Mind (ToM) is a critical component of intelligence, yet accurately measuring it continues to be a subject of debate. Prior research has attempted to apply human ToM assessments to natural language processing models using either human-created standardized tests or rule-based templates. However, these methods primarily focus on simplistic reasoning and require further validation. In this study, we utilize dynamic epistemic logic, which has established overlaps with ToM, to generate more intricate problems. We also introduce novel verbalization techniques to express these problems using natural language. Our findings indicate that certain language model scaling (from 70M to 6B and 350M to 174B) does not consistently yield results better than random chance. While GPT-4 demonstrates improved epistemic reasoning capabilities, there is still room for enhancement. Our code and datasets are publicly available https://github.com/antoinelrnld/modlog https://huggingface.co/datasets/sileo
    
[^40]: QCRI在SemEval-2023任务3 中的表现：使用多语言模型检测新闻类型、框架和说服技巧

    QCRI at SemEval-2023 Task 3: News Genre, Framing and Persuasion Techniques Detection using Multilingual Models. (arXiv:2305.03336v1 [cs.CL])

    [http://arxiv.org/abs/2305.03336](http://arxiv.org/abs/2305.03336)

    本文介绍了QCRI在SemEval-2023任务3中使用多语言模型成功排名前三的结果，并展示了去解决分析和验证在线新闻传播的难题。

    

    主流和社交媒体中的虚假信息传播一直以来以不同的方式误导用户。由记者和事实核查员进行手动检测和验证的努力已经无法应对虚假信息的快速扩散和大规模传播。这激励了研究和工业界的努力，以开发用于分析和验证在线新闻传播的系统。 SemEval-2023任务3 尝试解决在这个总体问题下的几个子任务，针对新闻文章中使用的写作技巧以影响读者的观点。该任务使用六种语言来解决三个子任务，此外还有三种“出人意料”的测试语言，共计27种不同的测试环境。本文描述了我们参与该任务的系统。我们团队是6个成功提交所有环境运行的团队之一。官方结果显示我们的系统在27种测试环境中有10个排名在前三位。

    Misinformation spreading in mainstream and social media has been misleading users in different ways. Manual detection and verification efforts by journalists and fact-checkers can no longer cope with the great scale and quick spread of misleading information. This motivated research and industry efforts to develop systems for analyzing and verifying news spreading online. The SemEval-2023 Task 3 is an attempt to address several subtasks under this overarching problem, targeting writing techniques used in news articles to affect readers' opinions. The task addressed three subtasks with six languages, in addition to three ``surprise'' test languages, resulting in 27 different test setups. This paper describes our participating system to this task. Our team is one of the 6 teams that successfully submitted runs for all setups. The official results show that our system is ranked among the top 3 systems for 10 out of the 27 setups.
    
[^41]: HiPool：利用图神经网络对长文档进行建模

    HiPool: Modeling Long Documents Using Graph Neural Networks. (arXiv:2305.03319v1 [cs.CL])

    [http://arxiv.org/abs/2305.03319](http://arxiv.org/abs/2305.03319)

    本论文提出了一种基于图神经网络的方法来模拟长文档，解决了顺序模型中的长期依赖问题，在新提出的基准测试中达到了最先进的性能。

    

    在自然语言处理中，编码长序列是一个具有挑战性的问题。虽然最近的预训练语言模型在许多NLP任务中达到了令人满意的表现，但它们仍受到预定义的最大长度的限制，使得它们难以扩展到更长的序列。因此，一些最近的工作利用层次结构来建模长序列。然而，它们大多数是对上层使用顺序模型，面临着长期依赖问题。在本文中，我们通过一种基于图的方法来缓解这些问题。我们首先使用固定长度对序列进行分块，以模拟句子级别的信息。然后，我们利用图来模拟句内和跨句的关联性，并使用一种新的注意力机制。此外，由于长文档分类的基准测试数据较少，我们提出了一个新的有挑战性的基准测试，共计六个数据集，样本总数达53000个，平均标记长度为4034个。评估结果显示，我们的模型在所有基准测试中均优于竞争基线方法，实现了最先进的性能。

    Encoding long sequences in Natural Language Processing (NLP) is a challenging problem. Though recent pretraining language models achieve satisfying performances in many NLP tasks, they are still restricted by a pre-defined maximum length, making them challenging to be extended to longer sequences. So some recent works utilize hierarchies to model long sequences. However, most of them apply sequential models for upper hierarchies, suffering from long dependency issues. In this paper, we alleviate these issues through a graph-based method. We first chunk the sequence with a fixed length to model the sentence-level information. We then leverage graphs to model intra- and cross-sentence correlations with a new attention mechanism. Additionally, due to limited standard benchmarks for long document classification (LDC), we propose a new challenging benchmark, totaling six datasets with up to 53k samples and 4034 average tokens' length. Evaluation shows our model surpasses competitive baselin
    
[^42]: 使用XLM-RoBERTa进行跨语言多复杂命名实体识别的LLM-RM参加SemEval-2023任务2

    LLM-RM at SemEval-2023 Task 2: Multilingual Complex NER using XLM-RoBERTa. (arXiv:2305.03300v1 [cs.CL])

    [http://arxiv.org/abs/2305.03300](http://arxiv.org/abs/2305.03300)

    本文介绍了LLM-RM团队参加SemEval2023任务2的成果，在跨语言多复杂命名实体识别方面，通过fine-tuning XLM-Roberta的交叉语言表示，得到了良好的效果。

    

    命名实体识别（NER）是识别句子中标记级别实体的任务。本文专注于解决多语言设置下的复杂命名实体的NER任务。我们的团队LLM-RM参加了最近举办的SemEval 2023任务2：MultiCoNER II，多语言复杂命名实体识别。我们通过利用对所有12种提供的语言（孟加拉语、中文、英语、波斯语、法语、德语、印地语、意大利语、葡萄牙语、西班牙语、瑞典语和乌克兰语）的数据集进行的XLM-Roberta基础模型的交叉语言表示来解决问题。

    Named Entity Recognition(NER) is a task of recognizing entities at a token level in a sentence. This paper focuses on solving NER tasks in a multilingual setting for complex named entities. Our team, LLM-RM participated in the recently organized SemEval 2023 task, Task 2: MultiCoNER II,Multilingual Complex Named Entity Recognition. We approach the problem by leveraging cross-lingual representation provided by fine-tuning XLM-Roberta base model on datasets of all of the 12 languages provided -- Bangla, Chinese, English, Farsi, French, German, Hindi, Italian, Portuguese, Spanish, Swedish and Ukrainian
    
[^43]: 基于块的开放式信息抽取

    Open Information Extraction via Chunks. (arXiv:2305.03299v1 [cs.CL])

    [http://arxiv.org/abs/2305.03299](http://arxiv.org/abs/2305.03299)

    本文提出了一种句子作为块序列的方法，将块的跨度识别为元组关系和参数，采用Chunk-OIE进行元组提取并取得了最先进的结果。

    

    开放式信息抽取(OIE)致力于从开放领域的句子中提取关系元组。现有的OIE系统将句子拆成标记后识别标记的跨度作为元组关系和参数。相反，我们提出句子作为块序列(SaC)，并将块的跨度识别为元组关系和参数。我们认为，SaC对于OIE具有比标记序列更好的定量和定性特性，并针对四种块的选择（即CoNLL块、简单短语、NP块和SpanOIE的跨度）针对gold OIE元组进行评估。因此，我们提出了一种基于BERT的句子分块模型，并提出了在SaC之上进行的元组提取的Chunk-OIE。Chunk-OIE在多个OIE数据集上取得了最先进的成果，显示了SaC对OIE任务的益处。

    Open Information Extraction (OIE) aims to extract relational tuples from open-domain sentences. Existing OIE systems split a sentence into tokens and recognize token spans as tuple relations and arguments. We instead propose Sentence as Chunk sequence (SaC) and recognize chunk spans as tuple relations and arguments. We argue that SaC has better quantitative and qualitative properties for OIE than sentence as token sequence, and evaluate four choices of chunks (i.e., CoNLL chunks, simple phrases, NP chunks, and spans from SpanOIE) against gold OIE tuples. Accordingly, we propose a simple BERT-based model for sentence chunking, and propose Chunk-OIE for tuple extraction on top of SaC. Chunk-OIE achieves state-of-the-art results on multiple OIE datasets, showing that SaC benefits OIE task.
    
[^44]: 基于多个提示知识的低资源多粒度学术功能识别

    Low-Resource Multi-Granularity Academic Function Recognition Based on Multiple Prompt Knowledge. (arXiv:2305.03287v1 [cs.CL])

    [http://arxiv.org/abs/2305.03287](http://arxiv.org/abs/2305.03287)

    本研究提出了 Mix Prompt Tuning（MPT）方法，通过将手动提示模板与自动学习的连续提示模板相结合，提高多粒度学术功能识别任务的性能，并减轻对注释数据的依赖。

    

    在科学领域的自然语言处理任务中，Fine-tuning 预训练语言模型（PLMs），如 SciBERT，通常需要大量注释数据才能实现最先进的性能。但是，获取科学 NLP 任务的 fine-tune 数据仍然具有挑战性和昂贵性。受提示学习的最新进展启发，本文提出了 Mix Prompt Tuning（MPT）方法，这是一种半监督方法，旨在减轻对注释数据的依赖，并使用很少数量的标记示例提高多粒度学术功能识别任务的性能。具体而言，所提出的方法通过将手动提示模板与自动学习的连续提示模板相结合，提供多方面的表示，以帮助给定的学术功能识别任务充分利用 PLMs 中的知识。基于这些提示模板和 fine-tuned PLM，大量的伪标签被分配给未标记的实例，以提高性能。

    Fine-tuning pre-trained language models (PLMs), e.g., SciBERT, generally requires large numbers of annotated data to achieve state-of-the-art performance on a range of NLP tasks in the scientific domain. However, obtaining the fine-tune data for scientific NLP task is still challenging and expensive. Inspired by recent advancement in prompt learning, in this paper, we propose the Mix Prompt Tuning (MPT), which is a semi-supervised method to alleviate the dependence on annotated data and improve the performance of multi-granularity academic function recognition tasks with a small number of labeled examples. Specifically, the proposed method provides multi-perspective representations by combining manual prompt templates with automatically learned continuous prompt templates to help the given academic function recognition task take full advantage of knowledge in PLMs. Based on these prompt templates and the fine-tuned PLM, a large number of pseudo labels are assigned to the unlabeled exam
    
[^45]: 专业性文本生成：模仿、检索、改写

    Expository Text Generation: Imitate, Retrieve, Paraphrase. (arXiv:2305.03276v1 [cs.CL])

    [http://arxiv.org/abs/2305.03276](http://arxiv.org/abs/2305.03276)

    该论文介绍了一项名为“专业性文本生成”的任务，目的在于从知识来源自动生成准确、信息丰富的文档，研究者提出的IRP框架能够克服语言模型的缺点，实现了内容规划、事实选择 和改写步骤分别处理，使得生成的文档具有较高的质量。

    

    专业性文档是向读者传达复杂信息的重要资源。尽管它们很有用，但手动编写专业性文献是耗时且劳动强度大的过程，需要对所涉领域有深入了解、精心规划内容、以及能够从多个来源综合信息的能力。为了减轻负担，我们介绍了专业性文本生成任务，它旨在从知识来源自动生成准确、信息丰富的专业性文档。我们通过开发IRP解决了这个任务，IRP是一个迭代框架，克服了语言模型的局限，分别处理了内容规划、事实选择和改写的步骤。通过对三个不同的数据集进行实验，我们证明IRP可以生成高质量的专业性文档，准确地向读者传递信息。

    Expository documents are vital resources for conveying complex information to readers. Despite their usefulness, writing expository documents by hand is a time-consuming and labor-intensive process that requires knowledge of the domain of interest, careful content planning, and the ability to synthesize information from multiple sources. To ease these burdens, we introduce the task of expository text generation, which seeks to automatically generate an accurate and informative expository document from a knowledge source. We solve our task by developing IRP, an iterative framework that overcomes the limitations of language models and separately tackles the steps of content planning, fact selection, and rephrasing. Through experiments on three diverse datasets, we demonstrate that IRP produces high-quality expository documents that accurately inform readers.
    
[^46]: Verify-and-Edit: 一种知识增强的思路链框架

    Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework. (arXiv:2305.03268v1 [cs.CL])

    [http://arxiv.org/abs/2305.03268](http://arxiv.org/abs/2305.03268)

    本文介绍了Verify-and-Edit框架，该框架通过根据外部知识后编辑推理链，提高CoT提示的预测准确性。

    

    随着大规模语言模型（LLMs）在NLP中成为常态，在生成和推理任务中表现良好，其最致命的缺点之一是缺乏事实正确性。生成不准确的文本不仅导致表现下降，而且降低了其应用的信任和有效性。思路链（CoT）提示通过生成可解释的推理链，在复杂的推理任务上提高信任和模型性能，但在知识密集型任务中仍存在事实问题。本文提出了Verify-and-Edit框架，用于CoT提示，该框架通过根据外部知识后编辑推理链，从而提高预测的准确性。在GPT-3的基础上构建的我们的框架在多个开放领域的问答任务中提高了准确性。

    As large language models (LLMs) have become the norm in NLP, demonstrating good performance in generation and reasoning tasks, one of its most fatal disadvantages is the lack of factual correctness. Generating unfactual texts not only leads to lower performances but also degrades the trust and validity of their applications. Chain-of-Thought (CoT) prompting improves trust and model performance on complex reasoning tasks by generating interpretable reasoning chains, but still suffers from factuality concerns in knowledge-intensive tasks. In this paper, we propose the Verify-and-Edit framework for CoT prompting, which seeks to increase prediction factuality by post-editing reasoning chains according to external knowledge. Building on top of GPT-3, our framework lead to accuracy improvements in multiple open-domain question-answering tasks.
    
[^47]: 从死角中解救对话：面向任务型对话策略优化的高效探索

    Rescue Conversations from Dead-ends: Efficient Exploration for Task-oriented Dialogue Policy Optimization. (arXiv:2305.03262v1 [cs.HC])

    [http://arxiv.org/abs/2305.03262](http://arxiv.org/abs/2305.03262)

    本文提出了一种死角复活（DDR）算法，可以及时高效地检测起始死角状态，并提供拯救行动以引导和纠正对话探索方向，同时防止对话策略不断犯同样的错误。

    

    使用深度强化学习训练对话策略需要对环境进行大量探索。无效的探索浪费了很多时间，使得学习效率低下。本文发现并定义了无效探索的一个重要原因：死角。当对话进入死角状态时，不管之后采取什么行动，它都将继续沿着死角轨迹，直到智能体达到终止状态或最大次数。我们提出了一种死角复活算法（DDR），及时高效地检测起始死角状态，并提供拯救行动以引导和纠正探索方向。为了防止对话策略不断犯同样的错误，DDR 还通过添加包含死角状态的相关经验进行对话数据扩充。本文首先验证了死角检测的可靠性，然后通过报告实验结果证明了该方法的有效性和普适性。

    Training a dialogue policy using deep reinforcement learning requires a lot of exploration of the environment. The amount of wasted invalid exploration makes their learning inefficient. In this paper, we find and define an important reason for the invalid exploration: dead-ends. When a conversation enters a dead-end state, regardless of the actions taken afterward, it will continue in a dead-end trajectory until the agent reaches a termination state or maximum turn. We propose a dead-end resurrection (DDR) algorithm that detects the initial dead-end state in a timely and efficient manner and provides a rescue action to guide and correct the exploration direction. To prevent dialogue policies from repeatedly making the same mistake, DDR also performs dialogue data augmentation by adding relevant experiences containing dead-end states. We first validate the dead-end detection reliability and then demonstrate the effectiveness and generality of the method by reporting experimental results
    
[^48]: 风格化数据文本生成：基于电商领域的案例研究

    Stylized Data-to-Text Generation: A Case Study in the E-Commerce Domain. (arXiv:2305.03256v1 [cs.CL])

    [http://arxiv.org/abs/2305.03256](http://arxiv.org/abs/2305.03256)

    该论文提出了一个新的任务——风格化数据文本生成，旨在根据特定风格为给定的非语言数据生成连贯的文本。作者还提出了一种新颖模型来解决该任务的难题。

    

    现有的数据文本生成主要集中于从非语言输入数据（例如表格和属性值对）生成连贯的文本，但忽视了不同应用场景可能需要不同风格的文本。因此，我们提出了一个新的任务，即风格化数据文本生成，其任务是根据特定风格为给定的非语言数据生成连贯的文本。为了解决这一挑战，我们提出了一种名为StyleD2T的新颖模型，包括三个组件：逻辑规划增强的数据嵌入、基于掩码的风格嵌入和非偏置式风格化文本生成。

    Existing data-to-text generation efforts mainly focus on generating a coherent text from non-linguistic input data, such as tables and attribute-value pairs, but overlook that different application scenarios may require texts of different styles. Inspired by this, we define a new task, namely stylized data-to-text generation, whose aim is to generate coherent text for the given non-linguistic data according to a specific style. This task is non-trivial, due to three challenges: the logic of the generated text, unstructured style reference, and biased training samples. To address these challenges, we propose a novel stylized data-to-text generation model, named StyleD2T, comprising three components: logic planning-enhanced data embedding, mask-based style embedding, and unbiased stylized text generation. In the first component, we introduce a graph-guided logic planner for attribute organization to ensure the logic of generated text. In the second component, we devise feature-level mask
    
[^49]: VicunaNER: 使用Vicuna进行零/小样本命名实体识别

    VicunaNER: Zero/Few-shot Named Entity Recognition using Vicuna. (arXiv:2305.03253v1 [cs.CL])

    [http://arxiv.org/abs/2305.03253](http://arxiv.org/abs/2305.03253)

    本文提出了基于Vicuna的零/小样本NER框架VicunaNER，具有优异的零样本和小样本能力，并在多个数据集上进行了评估和全面的研究。

    

    大型语言模型（LLMs，例如ChatGPT）在命名实体识别（NER）中展现出了令人印象深刻的零/小样本能力。然而，这些模型只能通过在线API访问，这可能会导致数据泄漏和无法重现的问题。本文提出了基于新发布的开源LLM--Vicuna的零/小样本NER框架VicunaNER。VicunaNER是一个两阶段框架，其中每个阶段利用多轮与Vicuna的对话从文本中识别实体。我们将第二阶段命名为重新识别，它识别第一阶段（即识别）中未识别的实体。此外，我们在每个阶段设置实体正确性检查对话框以过滤错误实体。我们在涉及5个领域的10个数据集上评估了VicunaNER的零样本能力和Few-NERD的小样本能力。实验结果表明，VicunaNER在两种情况下均取得了优越的性能。此外，我们对VicunaNER进行了全面的研究。

    Large Language Models (LLMs, e.g., ChatGPT) have shown impressive zero- and few-shot capabilities in Named Entity Recognition (NER). However, these models can only be accessed via online APIs, which may cause data leak and non-reproducible problems. In this paper, we propose VicunaNER, a zero/few-shot NER framework based on the newly released open-source LLM -- Vicuna. VicunaNER is a two-phase framework, where each phase leverages multi-turn dialogues with Vicuna to recognize entities from texts. We name the second phase as Re-Recognition, which recognizes those entities not recognized in the first phase (a.k.a. Recognition). Moreover, we set entity correctness check dialogues in each phase to filter out wrong entities. We evaluate VicunaNER's zero-shot capacity on 10 datasets crossing 5 domains and few-shot capacity on Few-NERD. Experimental results demonstrate that VicunaNER achieves superior performance in both shot settings. Additionally, we conduct comprehensive investigations on 
    
[^50]: 考虑多轮对话上下文的领域外意图检测

    Out-of-Domain Intent Detection Considering Multi-turn Dialogue Contexts. (arXiv:2305.03237v1 [cs.CL])

    [http://arxiv.org/abs/2305.03237](http://arxiv.org/abs/2305.03237)

    本文提出了一个上下文感知的OOD意图检测框架（Caro），用于模拟OOD意图检测任务中的多轮对话上下文，并在提取稳健的表示时删除与意图检测无关的多余信息。Caro在多个标准数据集上表现出最先进的性能，并超越了先前方法。

    

    领域外（OOD）意图检测对于实用的对话系统非常重要，通常需要考虑多轮对话上下文。然而，大多数先前的OOD意图检测方法仅限于单轮对话。在本文中，我们介绍了一个上下文感知的OOD意图检测（Caro）框架，用于对OOD意图检测任务中的多轮上下文进行建模。具体地，我们遵循信息瓶颈原则从多轮对话上下文中提取稳健的表示。每个输入样本构建了两个不同的视角，使用多视图信息瓶颈损失删除与意图检测无关的多余信息。此外，我们还探索了在Caro中利用未标记的数据。引入了一个两阶段训练过程来从这些未标记的数据中挖掘OOD样本，并使用自举方法用这些OOD样本来训练生成的模型。全面的实验表明，Caro在OOD意图检测任务的几个基准数据集上建立了最先进的性能，并超越了仅考虑单轮上下文的先前方法。

    Out-of-Domain (OOD) intent detection is vital for practical dialogue systems, and it usually requires considering multi-turn dialogue contexts. However, most previous OOD intent detection approaches are limited to single dialogue turns. In this paper, we introduce a context-aware OOD intent detection (Caro) framework to model multi-turn contexts in OOD intent detection tasks. Specifically, we follow the information bottleneck principle to extract robust representations from multi-turn dialogue contexts. Two different views are constructed for each input sample and the superfluous information not related to intent detection is removed using a multi-view information bottleneck loss. Moreover, we also explore utilizing unlabeled data in Caro. A two-stage training process is introduced to mine OOD samples from these unlabeled data, and these OOD samples are used to train the resulting model with a bootstrapping approach. Comprehensive experiments demonstrate that Caro establishes state-of-
    
[^51]: 自然语言处理中基于外部分布检测的综述

    A Survey on Out-of-Distribution Detection in NLP. (arXiv:2305.03236v1 [cs.CL])

    [http://arxiv.org/abs/2305.03236](http://arxiv.org/abs/2305.03236)

    这篇论文首次综述了最新的OOD检测方法在自然语言处理中的应用。根据算法使用的数据，将方法分成三类，并介绍了相关数据集、应用和度量方法。

    

    在现实世界中，基于外部分布（OOD）的检测对于机器学习系统的可靠和安全的部署至关重要。过去几年取得了极大进展。本文重点关注自然语言处理方法，并首次综述了OOD检测方面的最新进展。首先，我们给出OOD检测的正式定义，并讨论了几个相关领域。然后，根据算法使用的数据，将最近的算法分成三类：（1）可用OOD数据，（2）OOD数据不可用+内部分布（ID）标签可用，（3）OOD数据不可用+ID标签不可用。第三，介绍数据集、应用和度量方法。最后，总结现有工作并提出潜在的未来研究课题。

    Out-of-distribution (OOD) detection is essential for the reliable and safe deployment of machine learning systems in the real world. Great progress has been made over the past years. This paper presents the first review of recent advances in OOD detection with a particular focus on natural language processing approaches. First, we provide a formal definition of OOD detection and discuss several related fields. We then categorize recent algorithms into three classes according to the data they used: (1) OOD data available, (2) OOD data unavailable + in-distribution (ID) label available, and (3) OOD data unavailable + ID label unavailable. Third, we introduce datasets, applications, and metrics. Finally, we summarize existing work and present potential future research topics.
    
[^52]: 神经调节门控Transformer

    Neuromodulation Gated Transformer. (arXiv:2305.03232v1 [cs.CL])

    [http://arxiv.org/abs/2305.03232](http://arxiv.org/abs/2305.03232)

    本文介绍了一种新型的神经调节门控Transformer架构，通过乘法效应实现了神经调节，在SuperGLUE基准验证集上表现最优。

    

    我们引入了一种新颖的架构，即神经调节门控Transformer（NGT），它通过一种乘法效应，实现了Transformer中的神经调节的简单实现。我们将其与基准模型进行比较，并展示其在SuperGLUE基准验证集上达到最佳平均性能。

    We introduce a novel architecture, the Neuromodulation Gated Transformer (NGT), which is a simple implementation of neuromodulation in transformers via a multiplicative effect. We compare it to baselines and show that it results in the best average performance on the SuperGLUE benchmark validation sets.
    
[^53]: AttentionViz：Transformer Attention的全局视图

    AttentionViz: A Global View of Transformer Attention. (arXiv:2305.03210v1 [cs.HC])

    [http://arxiv.org/abs/2305.03210](http://arxiv.org/abs/2305.03210)

    这篇论文介绍了AttentionViz，一种以联合嵌入为基础的交互式可视化工具，用于帮助研究人员理解Transformer中的自我注意机制。该方法使得可以全局分析多个输入序列的注意力模式，提高对模型的理解并通过多个应用场景和专家反馈提供新的交互见解。

    

    Transformer模型正在革新机器学习，但它们的内部运作仍然神秘莫测。在本文中，我们提出了一种新的可视化技术，旨在帮助研究人员理解Transformer中的自我注意机制，使这些模型能够学习序列中元素之间丰富的上下文关系。我们方法的主要思想是可视化Transformer模型用于计算注意力的查询和键向量的联合嵌入。与以前的注意力可视化技术不同，我们的方法能够分析多个输入序列的全局模式。我们基于这些联合查询-键嵌入创建了一个交互式可视化工具AttentionViz，并将其用于研究语言和视觉变压器中的注意机制。通过几个应用场景和专家反馈，我们展示了我们的方法在提高模型理解和提供有关查询-键交互的新见解方面的实用性。

    Transformer models are revolutionizing machine learning, but their inner workings remain mysterious. In this work, we present a new visualization technique designed to help researchers understand the self-attention mechanism in transformers that allows these models to learn rich, contextual relationships between elements of a sequence. The main idea behind our method is to visualize a joint embedding of the query and key vectors used by transformer models to compute attention. Unlike previous attention visualization techniques, our approach enables the analysis of global patterns across multiple input sequences. We create an interactive visualization tool, AttentionViz, based on these joint query-key embeddings, and use it to study attention mechanisms in both language and vision transformers. We demonstrate the utility of our approach in improving model understanding and offering new insights about query-key interactions through several application scenarios and expert feedback.
    
[^54]: 研究印度语系多语言机器翻译中的词汇共享

    Investigating Lexical Sharing in Multilingual Machine Translation for Indian Languages. (arXiv:2305.03207v1 [cs.CL])

    [http://arxiv.org/abs/2305.03207](http://arxiv.org/abs/2305.03207)

    本文研究了印度语系多语言机器翻译中的词汇共享问题，探索了数据采样和词汇量之间的翻译性能权衡，以及字母转写是否有助于促进跨脚本概括，发现字母转写对跨脚本翻译效果没有明显改进，对于较低资源的语言，多语言机器翻译模型训练在原始脚本上似乎已经能够抵抗脚本差异。

    

    多语言语言模型表现出惊人的跨语言转移能力。为了改进这些模型的跨语言能力，一些策略包括改进字符细分而不是子词和对字母转写的使用。在本文中，我们研究了从印地语、古吉拉特语、尼泊尔语到英语的多语言机器翻译中的词汇共享。我们探讨了在数据采样和词汇量之间存在的翻译性能权衡，并探讨了字母转写是否有助于促进跨脚本概括。我们还验证了不同设置如何推广到看不见的语言（马拉地语和孟加拉语）。我们发现字母转写没有明显的改进，我们的分析表明，我们的多语言机器翻译模型在原始脚本上训练时，即使对于相对低资源的语言，似乎已经能够抵抗脚本差异。

    Multilingual language models have shown impressive cross-lingual transfer ability across a diverse set of languages and tasks. To improve the cross-lingual ability of these models, some strategies include transliteration and finer-grained segmentation into characters as opposed to subwords. In this work, we investigate lexical sharing in multilingual machine translation (MT) from Hindi, Gujarati, Nepali into English. We explore the trade-offs that exist in translation performance between data sampling and vocabulary size, and we explore whether transliteration is useful in encouraging cross-script generalisation. We also verify how the different settings generalise to unseen languages (Marathi and Bengali). We find that transliteration does not give pronounced improvements and our analysis suggests that our multilingual MT models trained on original scripts seem to already be robust to cross-script differences even for relatively low-resource languages
    
[^55]: VideoOFA：用于视频到文本生成的两阶段预训练模型

    VideoOFA: Two-Stage Pre-Training for Video-to-Text Generation. (arXiv:2305.03204v1 [cs.CV])

    [http://arxiv.org/abs/2305.03204](http://arxiv.org/abs/2305.03204)

    本文提出了一个用于视频到文本生成的两阶段预训练模型，能够学习视频特定的技能，取得了四项视频字幕基准测试的最先进性能，同时在两个开放式视频问答数据集上表现优异。

    

    我们提出了一个新的两阶段预训练框架，用于视频字幕和视频问答等任务的视频到文本生成：首先，一个生成式编码器-解码器模型在大规模的图像-文本数据上进行联合预训练，以学习基本的视觉语言概念，然后在一个中间的视频-文本预训练阶段对视频数据进行调整，以学习视频特定的技能，如时空推理。因此，我们的VideoOFA模型在四个视频字幕基准测试中实现了新的最先进的性能，在CIDEr分数上平均击败了先前的工艺水平9.7个收益点。它还在两个开放式视频问答数据集上表现优异，展示了它作为通用视频到文本模型的泛化能力。

    We propose a new two-stage pre-training framework for video-to-text generation tasks such as video captioning and video question answering: A generative encoder-decoder model is first jointly pre-trained on massive image-text data to learn fundamental vision-language concepts, and then adapted to video data in an intermediate video-text pre-training stage to learn video-specific skills such as spatio-temporal reasoning. As a result, our VideoOFA model achieves new state-of-the-art performance on four Video Captioning benchmarks, beating prior art by an average of 9.7 points in CIDEr score. It also outperforms existing models on two open-ended Video Question Answering datasets, showcasing its generalization capability as a universal video-to-text model.
    
[^56]: 利用语言处理技术增强普什图语的单标签和多标签文本分类

    Enhancing Pashto Text Classification using Language Processing Techniques for Single And Multi-Label Analysis. (arXiv:2305.03201v1 [cs.CL])

    [http://arxiv.org/abs/2305.03201](http://arxiv.org/abs/2305.03201)

    研究旨在建立一个普什图语文本的自动分类系统，最终通过应用多层感知器分类器获得了94％的平均测试准确率。

    

    文本分类已成为各个领域中至关重要的任务，导致了大量研究开发自动化文本分类系统以支持国内外的语言。然而，需要自动化文本分类系统来处理本地语言的需求越来越大。本研究旨在建立一个普什图语文本的自动分类系统。为了实现这一目标，我们构建了一个普什图语文档数据集，并应用了各种模型，包括统计和神经机器学习模型，如DistilBERT-base-multilingual-cased、多层感知器、支持向量机、K最近邻、决策树、高斯朴素贝叶斯、多项式朴素贝叶斯、随机森林和逻辑回归，来确定最有效的方法。我们还评估了两种不同的特征提取方法，即词袋和词频逆向文档频率。研究表明，使用多层感知器分类器，测试准确率平均值达到了94％。

    Text classification has become a crucial task in various fields, leading to a significant amount of research on developing automated text classification systems for national and international languages. However, there is a growing need for automated text classification systems that can handle local languages. This study aims to establish an automated classification system for Pashto text. To achieve this goal, we constructed a dataset of Pashto documents and applied various models, including statistical and neural machine learning models such as DistilBERT-base-multilingual-cased, Multilayer Perceptron, Support Vector Machine, K Nearest Neighbor, decision tree, Gaussian na\"ive Bayes, multinomial na\"ive Bayes, random forest, and logistic regression, to identify the most effective approach. We also evaluated two different feature extraction methods, bag of words and Term Frequency Inverse Document Frequency. The study achieved an average testing accuracy rate of 94% using the MLP class
    
[^57]: 使用混合深度神经网络处理Dari语言语音

    Employing Hybrid Deep Neural Networks on Dari Speech. (arXiv:2305.03200v1 [eess.AS])

    [http://arxiv.org/abs/2305.03200](http://arxiv.org/abs/2305.03200)

    本研究使用深度神经网络模型和Mel频率倒谱系数特征提取方法对Dari语音中的单词进行识别，在孤立Dari词语语料库上实现了高准确性的识别。

    

    本文是我们之前会议论文的延伸。近年来，研究人员对于开发和改进语音识别系统以促进和增强人机交互的兴趣日益增长。如今，自动语音识别（ASR）系统已普及，并在游戏、翻译系统、机器人等方面使用。然而，关于低资源语言的语音识别系统仍需要大量研究。本文通过使用Mel频率倒谱系数（MFCCs）特征提取方法和三种不同的深度神经网络模型：卷积神经网络（CNN）、循环神经网络（RNN）和多层感知机（MLP），以及两种结合CNN和RNN的混合模型，来识别Dari语言中的单词。我们使用自己创建的孤立Dari词语语料库对这些模型进行评估，该语料库包括20个短语Dari词汇的1000个话语。研究结果显示，我们的模型取得了极高的识别准确率。

    This paper is an extension of our previous conference paper. In recent years, there has been a growing interest among researchers in developing and improving speech recognition systems to facilitate and enhance human-computer interaction. Today, Automatic Speech Recognition (ASR) systems have become ubiquitous, used in everything from games to translation systems, robots, and more. However, much research is still needed on speech recognition systems for low-resource languages. This article focuses on the recognition of individual words in the Dari language using the Mel-frequency cepstral coefficients (MFCCs) feature extraction method and three different deep neural network models: Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Multilayer Perceptron (MLP), as well as two hybrid models combining CNN and RNN. We evaluate these models using an isolated Dari word corpus that we have created, consisting of 1000 utterances for 20 short Dari terms. Our study achieved 
    
[^58]: Gpt-4：自然语言处理中的进展和机遇综述

    Gpt-4: A Review on Advancements and Opportunities in Natural Language Processing. (arXiv:2305.03195v1 [cs.CL])

    [http://arxiv.org/abs/2305.03195](http://arxiv.org/abs/2305.03195)

    GPT-4是OpenAI开发的第四代GPT语言模型，具有超过1万亿的模型规模、更好的多语言能力和改进的语境理解和推理能力。它有望应用于聊天机器人、个人助理、语言翻译、文本摘要和问答系统，但也存在计算要求、数据要求和道德问题等挑战和限制。

    

    “生成式预训练变换器”（GPT）系列的第四代语言模型GPT-4由OpenAI开发，有望在自然语言处理领域实现显著进展。本研究论文讨论了GPT-4的特点、潜在应用以及可能面临的挑战，并将GPT-4与其前身GPT-3进行了比较。相比GPT-3，GPT-4具有更大的模型规模（超过1万亿）、更好的多语言能力、改进的语境理解和推理能力。GPT-4的一些潜在应用包括聊天机器人、个人助理、语言翻译、文本摘要和问答系统。然而，GPT-4也存在诸多挑战和限制，如计算要求、数据要求和道德问题。

    Generative Pre-trained Transformer 4 (GPT-4) is the fourth-generation language model in the GPT series, developed by OpenAI, which promises significant advancements in the field of natural language processing (NLP). In this research article, we have discussed the features of GPT-4, its potential applications, and the challenges that it might face. We have also compared GPT-4 with its predecessor, GPT-3. GPT-4 has a larger model size (more than one trillion), better multilingual capabilities, improved contextual understanding, and reasoning capabilities than GPT-3. Some of the potential applications of GPT-4 include chatbots, personal assistants, language translation, text summarization, and question-answering. However, GPT-4 poses several challenges and limitations such as computational requirements, data requirements, and ethical concerns.
    
[^59]: 机器学习模型在电子健康记录中的敏感数据检测

    Sensitive Data Detection with High-Throughput Machine Learning Models in Electrical Health Records. (arXiv:2305.03169v1 [cs.CR])

    [http://arxiv.org/abs/2305.03169](http://arxiv.org/abs/2305.03169)

    该论文使用机器学习算法来识别结构化数据中的敏感变量，以便便于去身份化过程。该算法可以解决不同数据集PHI字段异质性的问题。

    

    在大数据时代，医疗保健提供者、社区和研究人员需要分享数据并合作改善健康结果、获取有价值的见解和推进研究。1996年《健康保险流通与责任法案》(HIPAA)是一项联邦法律，旨在通过制定保护健康信息的规定来保护敏感健康信息。然而，在数据共享之前，HIPAA没有提供有效的检测或删除PHI的工具。本文旨在探讨使用机器学习算法来识别结构化数据中的敏感变量，从而便于去身份化过程。

    In the era of big data, there is an increasing need for healthcare providers, communities, and researchers to share data and collaborate to improve health outcomes, generate valuable insights, and advance research. The Health Insurance Portability and Accountability Act of 1996 (HIPAA) is a federal law designed to protect sensitive health information by defining regulations for protected health information (PHI). However, it does not provide efficient tools for detecting or removing PHI before data sharing. One of the challenges in this area of research is the heterogeneous nature of PHI fields in data across different parties. This variability makes rule-based sensitive variable identification systems that work on one database fail on another. To address this issue, our paper explores the use of machine learning algorithms to identify sensitive variables in structured data, thus facilitating the de-identification process. We made a key observation that the distributions of metadata of
    
[^60]: 文本嵌入对NLP聚类性能的影响。

    Influence of various text embeddings on clustering performance in NLP. (arXiv:2305.03144v1 [cs.LG])

    [http://arxiv.org/abs/2305.03144](http://arxiv.org/abs/2305.03144)

    研究探索了不同文本嵌入对聚类算法（KMeans、单链接聚合等级、DBSCAN和HDBSCAN）性能的影响，并应用于评论聚类领域。

    

    随着电子商务平台的出现，评论对于顾客评估产品的可信度至关重要。但是，星级评分并不总是与顾客编写的评论文本相匹配。在本研究中，我们探索了选择不同文本嵌入来表示这些评论的任务，并探究了嵌入选择对各种类型聚类算法性能的影响。我们使用上下文（BERT）和非上下文（Word2Vec）文本嵌入来表示文本，并测量它们对三种聚类算法（基于分区的KMeans、单链接聚合等级和密度基础的DBSCAN和HDBSCAN）在不同实验设置下的影响。

    With the advent of e-commerce platforms, reviews are crucial for customers to assess the credibility of a product. The star ratings do not always match the review text written by the customer. For example, a three star rating (out of five) may be incongruous with the review text, which may be more suitable for a five star review. A clustering approach can be used to relabel the correct star ratings by grouping the text reviews into individual groups. In this work, we explore the task of choosing different text embeddings to represent these reviews and also explore the impact the embedding choice has on the performance of various classes of clustering algorithms. We use contextual (BERT) and non-contextual (Word2Vec) text embeddings to represent the text and measure their impact of three classes on clustering algorithms - partitioning based (KMeans), single linkage agglomerative hierarchical, and density based (DBSCAN and HDBSCAN), each with various experimental settings. We use the sil
    
[^61]: 全局和局部文脉在命名实体识别中的作用。

    The Role of Global and Local Context in Named Entity Recognition. (arXiv:2305.03132v1 [cs.CL])

    [http://arxiv.org/abs/2305.03132](http://arxiv.org/abs/2305.03132)

    研究者探讨了全局文档上下文与局部上下文在命名实体识别中的作用，发现正确检索全局文档上下文对提高性能至关重要。

    

    最近，预训练的基于转换器的模型在命名实体识别方面表现出色。由于其自我注意力机制的复杂性，它们不能一次处理长文档，因此这些模型通常是按顺序应用的。这种方法不幸地只包含局部上下文，并阻碍了利用全局文档上下文的可能性，这可能会妨碍性能。在本文中，我们探讨了全局文档上下文的影响及其与局部上下文的关系。我们发现，正确检索全局文档上下文对性能的影响大于仅利用局部文本。这促使进一步研究如何更好地检索上下文。

    Pre-trained transformer-based models have recently shown great performance when applied to Named Entity Recognition (NER). As the complexity of their self-attention mechanism prevents them from processing long documents at once, these models are usually applied in a sequential fashion. Such an approach unfortunately only incorporates local context and prevents leveraging global document context in long documents such as novels, which might hinder performance. In this article, we explore the impact of global document context, and its relationships with local context. We find that correctly retrieving global document context has a greater impact on performance than only leveraging local context, prompting for further research on how to better retrieve that context.
    
[^62]: Chain-of-Skills: 一个可配置的用于开放领域问答的模型

    Chain-of-Skills: A Configurable Model for Open-domain Question Answering. (arXiv:2305.03130v1 [cs.CL])

    [http://arxiv.org/abs/2305.03130](http://arxiv.org/abs/2305.03130)

    本论文提出了一种模块化检索器可以在数据集间重复使用，支持针对目标领域的灵活技能配置，通过自我监督预训练和微调多个 ODQA 数据集，实现了最新颖的微调检索性能。

    

    在实际的知识密集任务中，如开放领域问答（ODQA），检索模型是不可或缺的组件。由于不同数据集的注释有着不同的检索技能，近期的工作侧重于定制方法，限制了模型的可转移性和可扩展性。在这项工作中，我们提出了一种模块化检索器，其中各个模块对应于可以在数据集之间重复使用的关键技能。我们的方法支持基于目标领域的灵活技能配置，以提高性能。为了减轻任务干扰，我们设计了一种受稀疏 Transformer 启发的新型模块化参数化方法。我们证明了我们的模型可以在维基百科上进行自我监督预训练，并在多个 ODQA 数据集上进行微调，具有多任务的特点。我们的方法在零样例评估中优于最近的自我监督检索器，并在 NQ、HotpotQA 和 OTT-QA 上获得了最先进的微调检索性能。

    The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transferability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.
    
[^63]: ChatGPT 需要进行SPADE（可持续性、隐私、数字鸿沟和伦理）评估：一项综述。

    ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review. (arXiv:2305.03123v1 [cs.CY])

    [http://arxiv.org/abs/2305.03123](http://arxiv.org/abs/2305.03123)

    本文研究关注ChatGPT面临的可持续性、隐私、数字鸿沟和伦理问题，提出了SPADE评估的必要性，并给出了缓解和建议。

    

    ChatGPT是另一个大型语言模型（LLM），由于其性能和有效的对话能力，在研究和工业界中得到了巨大的关注。最近，许多研究已经发表，以展示ChatGPT和其他LLMs的有效性、效率、集成和情感。相反，本研究关注的是大多数被忽视的重要方面，即可持续性、隐私、数字鸿沟和伦理，并建议不仅仅是ChatGPT，而是在对话机器人类别中的每一个后续入口都应该进行SPADE评估。本文详细讨论了关于ChatGPT的问题和关注点与上述特征一致。我们通过一些初步的数据收集和可视化以及假设的事实来支持我们的假设。我们还为每个问题提出了缓解和建议。此外，我们还提供了一些未来方向和开放问题的探讨。

    ChatGPT is another large language model (LLM) inline but due to its performance and ability to converse effectively, it has gained a huge popularity amongst research as well as industrial community. Recently, many studies have been published to show the effectiveness, efficiency, integration, and sentiments of chatGPT and other LLMs. In contrast, this study focuses on the important aspects that are mostly overlooked, i.e. sustainability, privacy, digital divide, and ethics and suggests that not only chatGPT but every subsequent entry in the category of conversational bots should undergo Sustainability, PrivAcy, Digital divide, and Ethics (SPADE) evaluation. This paper discusses in detail about the issues and concerns raised over chatGPT in line with aforementioned characteristics. We support our hypothesis by some preliminary data collection and visualizations along with hypothesized facts. We also suggest mitigations and recommendations for each of the concerns. Furthermore, we also s
    
[^64]: LLM能否作为数据库接口？大型数据库基础文本到SQL的基准测试。

    Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs. (arXiv:2305.03111v1 [cs.CL])

    [http://arxiv.org/abs/2305.03111](http://arxiv.org/abs/2305.03111)

    本文提出了一个大型的基准测试Bird，可以用于大规模数据库文本到SQL的任务，突出了数据库值理解和SQL效率等领域的挑战。

    

    近年来，文本到SQL解析受到越来越多的关注，旨在将自然语言指令转换为可执行的SQL命令。本文提出了一个大型基准测试Bird，它包含旨在大规模数据库基础的12,751对文本到SQL数据和95个数据库，总大小为33.4GB，涵盖37个专业领域。与现有基准测试相比，Bird强调数据库值的理解，突出了脏数据库内容、NL问题和数据库内容之间的外部知识以及SQL效率等新挑战。解决这些问题，文本到SQL模型必须具备数据库值理解和语义解析的能力。

    Text-to-SQL parsing, which aims at converting natural language instructions into executable SQLs, has gained increasing attention in recent years. In particular, Codex and ChatGPT have shown impressive results in this task. However, most of the prevalent benchmarks, i.e., Spider, and WikiSQL, focus on database schema with few rows of database contents leaving the gap between academic study and real-world applications. To mitigate this gap, we present Bird, a big benchmark for large-scale database grounded in text-to-SQL tasks, containing 12,751 pairs of text-to-SQL data and 95 databases with a total size of 33.4 GB, spanning 37 professional domains. Our emphasis on database values highlights the new challenges of dirty database contents, external knowledge between NL questions and database contents, and SQL efficiency, particularly in the context of massive databases. To solve these problems, text-to-SQL models must feature database value comprehension in addition to semantic parsing. 
    
[^65]: 混合变换器和注意力编码器-解码器模型用于语音到文本任务

    Hybrid Transducer and Attention based Encoder-Decoder Modeling for Speech-to-Text Tasks. (arXiv:2305.03101v1 [cs.CL])

    [http://arxiv.org/abs/2305.03101](http://arxiv.org/abs/2305.03101)

    本论文提出了一种结合了变换器和AED框架的新方案，利用AED的序列到序列学习的优势，同时保留了变换器的流式属性，旨在提高语音到文本任务的性能。

    

    变换器和注意力编码器-解码器（AED）是用于语音到文本任务的两种广泛使用的框架。 它们针对不同的目的进行设计，每种方法在语音到文本任务中都有其优点和缺点。为了利用两种建模方法的优势，我们提出了一种通过结合变换器和注意力编码器-解码器（TAED）处理语音到文本任务的解决方案。该新方法利用了AED中关于非单调序列到序列学习的优势，同时保留了变换器的流式属性。在所提出的框架中，变换器和AED共享同一个语音编码器。变换器中的预测器被AED模型中的解码器所取代，解码器的输出是基于语音输入而不是基于无条件的语言模型输出的。所提出的解决方案确保了通过涵盖所有可能的读取/写入场景来优化模型，并为流式应用程序创造了匹配的环境。我们对所提出的方法进行了评估。

    Transducer and Attention based Encoder-Decoder (AED) are two widely used frameworks for speech-to-text tasks. They are designed for different purposes and each has its own benefits and drawbacks for speech-to-text tasks. In order to leverage strengths of both modeling methods, we propose a solution by combining Transducer and Attention based Encoder-Decoder (TAED) for speech-to-text tasks. The new method leverages AED's strength in non-monotonic sequence to sequence learning while retaining Transducer's streaming property. In the proposed framework, Transducer and AED share the same speech encoder. The predictor in Transducer is replaced by the decoder in the AED model, and the outputs of the decoder are conditioned on the speech inputs instead of outputs from an unconditioned language model. The proposed solution ensures that the model is optimized by covering all possible read/write scenarios and creates a matched environment for streaming applications. We evaluate the proposed appro
    
[^66]: 利用分类器来筛选语料库：以在线清洁能源情感分析为例

    Curating corpora with classifiers: A case study of clean energy sentiment online. (arXiv:2305.03092v1 [cs.CL])

    [http://arxiv.org/abs/2305.03092](http://arxiv.org/abs/2305.03092)

    本文介绍了利用分类器来快速选择最佳的相关文档语料库进行分析的方法，探索了过滤掉不相关的推文的方法，以进行在线清洁能源情感分析。

    

    精心策划的、大规模的社交媒体帖子语料库是补充传统调查的替代数据来源，可以提供广泛的公众意见。虽然调查在收集代表性样本和实现高准确率方面很有效，但运行成本很高，而且会滞后于公众意见数天或数周。这两个缺点可以通过实时、高容量的数据流和快速的分析管道克服。在组织这样的数据管道方面的一个核心挑战是设计一种有效的方法，快速选择最佳的相关文档语料库进行分析。仅仅通过关键词查询往往会包括不相关的文档，而这些文档很难用词袋自然语言处理方法消歧。在这里，我们使用预先训练的基于转换器的模型，通过在手动标注的推文上对其进行微调，探索了语料库策划的方法，以过滤掉不相关的推文。我们能够实现高达0.8以上的F1得分。

    Well curated, large-scale corpora of social media posts containing broad public opinion offer an alternative data source to complement traditional surveys. While surveys are effective at collecting representative samples and are capable of achieving high accuracy, they can be both expensive to run and lag public opinion by days or weeks. Both of these drawbacks could be overcome with a real-time, high volume data stream and fast analysis pipeline. A central challenge in orchestrating such a data pipeline is devising an effective method for rapidly selecting the best corpus of relevant documents for analysis. Querying with keywords alone often includes irrelevant documents that are not easily disambiguated with bag-of-words natural language processing methods. Here, we explore methods of corpus curation to filter irrelevant tweets using pre-trained transformer-based models, fine-tuned for our binary classification task on hand-labeled tweets. We are able to achieve F1 scores of up to 0.
    
[^67]: 面向无答案的会话问答生成的“要问什么”和“如何问”的建模

    Modeling What-to-ask and How-to-ask for Answer-unaware Conversational Question Generation. (arXiv:2305.03088v1 [cs.CL])

    [http://arxiv.org/abs/2305.03088](http://arxiv.org/abs/2305.03088)

    本文提出了一种新的方法来共同建模“要问什么”和“如何问”的问题，在不明确答案的设置中非常实用。

    

    会话问答生成（CQG）是机器通过对话帮助人类满足信息需求的关键任务。这个任务一般分为两种不同的设置：明确答案和不明确答案。虽然前者通过暴露预期答案来帮助模型，但后者更加现实并最近受到越来越多的关注。在不明确答案的设置中，“要问什么”和“如何问”是两个主要挑战。为了解决第一个挑战，现有的方法主要将上下文中的连续句子作为理由选择。我们认为，使用这种朴素的启发式方法生成的对话可能不够自然，因为在现实中，对话者经常谈论相关的内容，这些内容不一定是连续的。此外，先前的方法隐含决定要生成的问题类型（布尔/跨度），显式建模问题类型至关重要，因为答案（提示模型生成某种类型的问题）在无答案设置中不可用。为此，我们提出了一种新的方法，以端对端的方式共同模拟“要问什么”和“如何问”。具体而言，我们引入了一种新的理由选择方法，利用上下文和候选句子之间的相关性进行更自然的对话生成。此外，我们设计了一个问题类型预测器来明确模型中的目标问题类型。两个基准数据集上的广泛实验证明了我们提出的方法的有效性。

    Conversational Question Generation (CQG) is a critical task for machines to assist humans in fulfilling their information needs through conversations. The task is generally cast into two different settings: answer-aware and answer-unaware. While the former facilitates the models by exposing the expected answer, the latter is more realistic and receiving growing attentions recently. What-to-ask and how-to-ask are the two main challenges in the answer-unaware setting. To address the first challenge, existing methods mainly select sequential sentences in context as the rationales. We argue that the conversation generated using such naive heuristics may not be natural enough as in reality, the interlocutors often talk about the relevant contents that are not necessarily sequential in context. Additionally, previous methods decide the type of question to be generated (boolean/span-based) implicitly. Modeling the question type explicitly is crucial as the answer, which hints the models to ge
    
[^68]: 大语言模型在信息技术任务中自动生成YAML代码

    Automated Code generation for Information Technology Tasks in YAML through Large Language Models. (arXiv:2305.02783v1 [cs.SE])

    [http://arxiv.org/abs/2305.02783](http://arxiv.org/abs/2305.02783)

    这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。

    

    由于大语言模型在代码生成方面的不断提升，在通用编程语言方面的受益最大，而针对IT自动化等领域特定语言的研究较少。本研究聚焦于Ansible-YAML的生成，提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，旨在提高IT自动化生产力。研究采用基于Transformer的模型，并通过新的包含Ansible-YAML的数据集进行扩展训练。同时，还开发了两个用于捕捉此领域特征的YAML和Ansible性能指标。结果表明，Ansible Wisdom可以精确地从自然语言提示中生成Ansible脚本，并且其性能可与现有技术的状态相媲美或更好。

    The recent improvement in code generation capabilities due to the use of large language models has mainly benefited general purpose programming languages. Domain specific languages, such as the ones used for IT Automation, have received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible-YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible-YAML code generation tool, aimed at improving IT automation productivity. Ansible Wisdom is a transformer-based model, extended by training with a new dataset containing Ansible-YAML. We also develop two novel performance metrics for YAML and Ansible to capture the specific characteristics of this domain. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code 
    
[^69]: 转移学习与主动学习用于共鸣检测：解决稀有类挑战

    Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge. (arXiv:2305.02459v1 [cs.CL])

    [http://arxiv.org/abs/2305.02459](http://arxiv.org/abs/2305.02459)

    本文提出并探究了基于转移和主动学习的稀有类问题的解决方案，包括利用在密切相关任务上训练的模型和评估获取策略来解决共振检测的稀有类问题，并且发现了一种名为PRC的有效的策略来指导注释。

    

    尽管基于变压器的系统使得使用更少的训练样例能够得到更高的准确性，但对于稀有类任务（即类别标签非常少见的情况，例如<5%的样本），数据采集障碍仍然存在。主动学习一般被提出用于缓解这种挑战，但选择策略，即选择稀有类示例的标准，尚未得到系统评估。此外，变压器可以实现迭代迁移学习方法。我们提出并研究了转移和主动学习解决了通过利用在密切相关任务上训练的模型和评估获取策略来解决共振检测的稀有类问题，其中包括一种提出的稀有类概率（PRC）方法。我们针对特定的稀有类问题（从社交媒体中收集认知共振的语言样本）进行了这些实验。我们发现PRC是指导注释的简单而有效的策略，最终可以提高性能，并且转移学习可以在稀缺数据情况下提供显著的改进。

    While transformer-based systems have enabled greater accuracies with fewer training examples, data acquisition obstacles still persist for rare-class tasks -- when the class label is very infrequent (e.g. < 5% of samples). Active learning has in general been proposed to alleviate such challenges, but choice of selection strategy, the criteria by which rare-class examples are chosen, has not been systematically evaluated. Further, transformers enable iterative transfer-learning approaches. We propose and investigate transfer- and active learning solutions to the rare class problem of dissonance detection through utilizing models trained on closely related tasks and the evaluation of acquisition strategies, including a proposed probability-of-rare-class (PRC) approach. We perform these experiments for a specific rare class problem: collecting language samples of cognitive dissonance from social media. We find that PRC is a simple and effective strategy to guide annotations and ultimately
    
[^70]: 一种面向语言复杂的图像检索的神经分治推理框架

    A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Linguistically Complex Text. (arXiv:2305.02265v1 [cs.CL])

    [http://arxiv.org/abs/2305.02265](http://arxiv.org/abs/2305.02265)

    提出了一种神经分治推理框架NDCR，通过将语言复杂文本视为由多个简单命题句组成的复合命题文本，将图像检索问题分为三个步骤：分治、征服和组合。该框架在解决语言复杂文本问题时具有较好的性能。

    

    预训练视觉语言模型（VLMs）在图像检索方面取得了显着的性能。但是，当面对难以理解的语言复杂文本时，它们的性能会急剧下降。本文受到分治算法和双过程理论的启发，将语言复杂文本视为由多个简单命题句组成的复合命题文本，并提出了一个端到端的神经分治推理框架NDCR。它包括三个主要组件：1）分治：命题生成器将复合命题文本分为简单命题句，并生成它们的对应表示，2）征服：基于预训练视觉语言交互器实现分解命题句和图像之间的交互，3）组合：神经符号推理器采用神经逻辑推理方法将上述推理状态组合，获得最终解决方案。

    Pretrained Vision-Language Models (VLMs) have achieved remarkable performance in image retrieval from text. However, their performance drops drastically when confronted with linguistically complex texts that they struggle to comprehend. Inspired by the Divide-and-Conquer algorithm and dual-process theory, in this paper, we regard linguistically complex texts as compound proposition texts composed of multiple simple proposition sentences and propose an end-to-end Neural Divide-and-Conquer Reasoning framework, dubbed NDCR. It contains three main components: 1)Divide: a proposition generator divides the compound proposition text into simple proposition sentences and produces their corresponding representations, 2)Conquer: a pretrained VLMs-based visual-linguistic interactor achieves the interaction between decomposed proposition sentences and images, 3)Combine: a neural-symbolic reasoner combines the above reasoning states to obtain the final solution via a neural logic reasoning approach
    
[^71]: UNTER: 一种用于增强预训练语言模型的统一知识接口

    UNTER: A Unified Knowledge Interface for Enhancing Pre-trained Language Models. (arXiv:2305.01624v1 [cs.CL])

    [http://arxiv.org/abs/2305.01624](http://arxiv.org/abs/2305.01624)

    本篇论文提出了一种名为UNTER的统一知识接口，可以同时利用结构化和非结构化知识，从而提高预训练语言模型（PLMs）性能，在实验中表现出不断的改进。

    

    最近的研究表明，外部知识注入可以提高预训练语言模型（PLMs）在各种下游NLP任务中的性能。但是，现有的知识注入方法适用于结构化知识或非结构化知识，缺乏统一的使用方式。本文提出了一种名为UNTER的统一知识接口，以提供利用结构化知识和非结构化知识的统一视角。在UNTER中，我们采用解码器作为统一的知识接口，将从编码器获取的跨度表示与其对应的知识进行对齐。这种方法使编码器能够从其参数中统一调用下游应用程序的跨度相关的知识。实验结果表明，通过注入两种形式的知识，UNTER在一系列知识驱动的NLP任务中获得了不断的改进，包括实体类型、命名实体识别和关系抽取，尤其在低资源场景中效果明显。

    Recent research demonstrates that external knowledge injection can advance pre-trained language models (PLMs) in a variety of downstream NLP tasks. However, existing knowledge injection methods are either applicable to structured knowledge or unstructured knowledge, lacking a unified usage. In this paper, we propose a UNified knowledge inTERface, UNTER, to provide a unified perspective to exploit both structured knowledge and unstructured knowledge. In UNTER, we adopt the decoder as a unified knowledge interface, aligning span representations obtained from the encoder with their corresponding knowledge. This approach enables the encoder to uniformly invoke span-related knowledge from its parameters for downstream applications. Experimental results show that, with both forms of knowledge injected, UNTER gains continuous improvements on a series of knowledge-driven NLP tasks, including entity typing, named entity recognition and relation extraction, especially in low-resource scenarios.
    
[^72]: 基于SearChain的复杂知识密集型任务中精确、可信和可追溯内容生成的研究

    Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks. (arXiv:2304.14732v1 [cs.CL])

    [http://arxiv.org/abs/2304.14732](http://arxiv.org/abs/2304.14732)

    提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。

    

    随着ChatGPT等大型语言模型（LLM）的广泛应用，如何使LLM生成的内容准确可信在复杂知识密集型任务中变得非常重要。本文提出了一种名为Search-in-the-Chain（SearChain）的新型框架，以改进多跳问题回答等典型复杂知识密集型任务中LLM生成内容的准确性、可信度和可追溯性。SearChain是一个深度集成LLM和信息检索（IR）的框架。在SearChain中，LLM构建查询链，作为多跳问题的分解。链的每个节点都是由IR导向的查询-答案对，以及由LLM生成的该查询的答案。IR验证、完善和跟踪链中每个节点的信息，以指导LLM构建正确的查询链，并最终回答多跳问题。SearChain使LLM从一次性答案转变为多步答案，从而提高了生成内容的准确性和可信度。实验结果表明，SearChain在准确性和可靠性方面优于其他最先进的方法。

    With the wide application of Large Language Models (LLMs) such as ChatGPT, how to make the contents generated by LLM accurate and credible becomes very important, especially in complex knowledge-intensive tasks. In this paper, we propose a novel framework called Search-in-the-Chain (SearChain) to improve the accuracy, credibility and traceability of LLM-generated content for multi-hop question answering, which is a typical complex knowledge-intensive task. SearChain is a framework that deeply integrates LLM and information retrieval (IR). In SearChain, LLM constructs a chain-of-query, which is the decomposition of the multi-hop question. Each node of the chain is a query-answer pair consisting of an IR-oriented query and the answer generated by LLM for this query. IR verifies, completes, and traces the information of each node of the chain, so as to guide LLM to construct the correct chain-of-query, and finally answer the multi-hop question. SearChain makes LLM change from trying to gi
    
[^73]: 评估ChatGPT和GPT-4的逻辑推理能力

    Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. (arXiv:2304.03439v1 [cs.CL])

    [http://arxiv.org/abs/2304.03439](http://arxiv.org/abs/2304.03439)

    本文分析了多个逻辑推理数据集，评估了ChatGPT和GPT-4在逻辑推理任务上的表现，并构造了一个逻辑推理的分布之外的数据集来研究它们的鲁棒性。实验结果显示，ChatGPT在大多数逻辑推理基准测试中的表现远优于RoBERTa微调方法，而GPT-4的表现则更高。

    

    利用逻辑推理能力是一个全面的自然语言理解任务。随着先进的生成预训练转换器4（GPT-4）的发布，我们渴望了解GPT-4在各种逻辑推理任务上的表现。本文分析了多个逻辑推理数据集，包括LogiQA和ReClor等常用基准测试，以及像AR-LSAT这样的新发布的数据集。我们对需要逻辑推理的基准测试进行了多项选择阅读理解和自然语言推理任务测试。我们进一步构造了一个逻辑推理的分布之外的数据集，以研究ChatGPT和GPT-4的鲁棒性。我们还进行了ChatGPT和GPT-4之间的性能比较。实验结果表明，在大多数逻辑推理基准测试中，ChatGPT的表现远远优于RoBERTa微调方法。GPT-4在我们的手动测试中表现更高。在基准测试中，ChatGPT和GPT-4的表现相对较为均衡。

    Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as "advanced" at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs significantly better than the RoBERTa fine-tuning method on most logical reasoning benchmarks. GPT-4 shows even higher performance on our manual tests. Among benchmarks, ChatGPT and GPT-4 do relatively w
    
[^74]: DrBERT:用于生物医学和临床领域的健壮的法语预训练模型

    DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains. (arXiv:2304.00958v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.00958](http://arxiv.org/abs/2304.00958)

    本文提出了DrBERT，用于生物医学和临床领域的健壮的法语预训练模型，并通过对公共数据和医疗机构的私有数据进行性能比较，证明了在特定领域数据上进一步预训练PLMs可以显著提高性能。最终，发布了首个用于生物医学领域的法语专用PLMs，以及最大的医学数据语料库。

    

    近年来，预训练语言模型（PLMs）在自然语言处理（NLP）任务中取得了最好的性能。虽然最初的模型是使用通用领域数据训练的，但专用于特定领域的模型已经出现，以更有效地处理特定领域的任务。在本文中，我们提出了对法语生物医学领域中PLMs的原始研究。我们首次比较了在公共网络数据和医疗机构的私有数据上训练的PLMs的性能。我们还评估了不同的学习策略在一组生物医学任务上的效果。特别是，我们展示了我们可以利用已经存在的外语生物医学PLMs，并在我们的目标数据上进一步预训练它。最后，我们发布了第一个用于生物医学领域的法语专用PLMs，称为DrBERT，以及这些模型所训练的最大的医学数据语料库。

    In recent years, pre-trained language models (PLMs) achieve the best performance on a wide range of natural language processing (NLP) tasks. While the first models were trained on general domain data, specialized ones have emerged to more effectively treat specific domains. In this paper, we propose an original study of PLMs in the medical domain on French language. We compare, for the first time, the performance of PLMs trained on both public data from the web and private data from healthcare establishments. We also evaluate different learning strategies on a set of biomedical tasks. In particular, we show that we can take advantage of already existing biomedical PLMs in a foreign language by further pre-train it on our targeted data. Finally, we release the first specialized PLMs for the biomedical field in French, called DrBERT, as well as the largest corpus of medical data under free license on which these models are trained.
    
[^75]: 语言模型在预后预测中的小样本学习能力

    Language Models are Few-shot Learners for Prognostic Prediction. (arXiv:2302.12692v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12692](http://arxiv.org/abs/2302.12692)

    本研究探索了语言模型在免疫治疗预后预测中的应用，研究了小样本学习面临的挑战，对比了基线和语言模型的有效性，并发现在准确度方面有显著的改进，突出了自然语言处理在临床研究中改善早期检测和干预不同疾病的潜力。

    

    临床预测是医疗保健行业中的关键任务。然而，迄今为止，建立在理论框架Transformers之上的大型语言模型的成功并未延伸到这个领域。本研究利用真实世界中患者的临床数据和分子特征探索了Transformers和语言模型在免疫治疗预后预测中的应用。本文研究了Transformers相对于常规机器学习方法在临床预测中的潜力，并发现了在预测罕见疾病领域下小样本学习面临的挑战。该研究对比了基线和语言模型在多种癌症类型的预后预测中的有效性，并研究了在小样本情况下不同预先训练的语言模型的影响。结果表明在准确度方面有显著的改进，并突出了自然语言处理在临床研究中改善早期检测和干预不同疾病的潜力。

    Clinical prediction is an essential task in the healthcare industry. However, the recent success of transformers, on which large language models are built, has not been extended to this domain. In this research, we explore the use of transformers and language models in prognostic prediction for immunotherapy using real-world patients' clinical data and molecular profiles. This paper investigates the potential of transformers to improve clinical prediction compared to conventional machine learning approaches and addresses the challenge of few-shot learning in predicting rare disease areas. The study benchmarks the efficacy of baselines and language models on prognostic prediction across multiple cancer types and investigates the impact of different pretrained language models under few-shot regimes. The results demonstrate significant improvements in accuracy and highlight the potential of NLP in clinical research to improve early detection and intervention for different diseases.
    
[^76]: 不是你所签署的：间接提示注入妨害现实世界 LLM 一体化应用

    Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection. (arXiv:2302.12173v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.12173](http://arxiv.org/abs/2302.12173)

    本文揭示了一种新的攻击向量：间接提示注入，它可以通过在可能检索到的数据中策略性地注入提示来远程利用 LLM 集成应用程序。该攻击对数据盗窃、蠕虫、信息生态系统污染等造成威胁。

    

    大型语言模型 (LLM) 日益被整合到各种应用程序中。最近的 LLM 可以通过自然语言提示灵活调节功能。这使它们容易受到针对性的对抗性提示攻击，例如 Prompt Injection (PI) 攻击使攻击者能够覆盖原始指令和使用的控件。迄今为止，人们认为用户直接提示 LLM。但是，如果不是用户提示呢？我们认为 LLM 一体化应用程序模糊了数据和指令之间的界限。我们揭示了使用间接提示注入的新攻击向量，使攻击者能够通过在可能检索到的数据中策略性地注入提示来远程（没有直接接口）利用 LLM 集成应用程序。我们从计算机安全的角度推导出一个全面的分类法，以系统地调查影响和漏洞，包括数据盗窃、蠕虫、信息生态系统污染以及其他创新性的威胁。

    Large Language Models (LLMs) are increasingly being integrated into various applications. The functionalities of recent LLMs can be flexibly modulated via natural language prompts. This renders them susceptible to targeted adversarial prompting, e.g., Prompt Injection (PI) attacks enable attackers to override original instructions and employed controls. So far, it was assumed that the user is directly prompting the LLM. But, what if it is not the user prompting? We argue that LLM-Integrated Applications blur the line between data and instructions. We reveal new attack vectors, using Indirect Prompt Injection, that enable adversaries to remotely (without a direct interface) exploit LLM-integrated applications by strategically injecting prompts into data likely to be retrieved. We derive a comprehensive taxonomy from a computer security perspective to systematically investigate impacts and vulnerabilities, including data theft, worming, information ecosystem contamination, and other nove
    
[^77]: 论基于模型的文本生成评价指标的盲点问题

    On the Blind Spots of Model-Based Evaluation Metrics for Text Generation. (arXiv:2212.10020v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10020](http://arxiv.org/abs/2212.10020)

    本文研究了针对文本生成评价指标的鲁棒性分析方法，使用合成数据进行压力测试，发现现有评价指标存在一些盲点和偏见，例如BERTScore对摘要中的截断误差无法很好地处理，MAUVE对于生成的开头或中间的误差不敏感，本文提出了实用的解决方案以实现更可靠的文本生成评价。

    

    本文探讨了一种有用但常常被忽略的文本生成评价指标鲁棒性分析方法：使用合成数据进行压力测试。我们随机设计并合成了各种可能的误差，并检查它们是否会导致评价指标分数的显著下降。我们研究了基于预训练语言模型的一系列最新评价指标，用于开放式生成、翻译和摘要等任务。实验揭示了现有评价指标中有趣的不敏感、偏见、甚至漏洞。例如，我们发现BERTScore对摘要中的截断误差感到困惑，而在生成的开头或中间存在误差时MAUVE（基于GPT-2）则不敏感。进一步，我们研究了这些盲点背后的原因，并提出了实用的解决方案，以实现更可靠的文本生成评价。我们已在https://github.com/cloudygoose/blindspot_nlg 上发布了我们的代码和数据。

    In this work, we explore a useful but often neglected methodology for robustness analysis of text generation evaluation metrics: stress tests with synthetic data. Basically, we design and synthesize a wide range of potential errors and check whether they result in a commensurate drop in the metric scores. We examine a range of recently proposed evaluation metrics based on pretrained language models, for the tasks of open-ended generation, translation, and summarization. Our experiments reveal interesting insensitivities, biases, or even loopholes in existing metrics. For example, we find that BERTScore is confused by truncation errors in summarization, and MAUVE (built on top of GPT-2) is insensitive to errors at the beginning or middle of generations. Further, we investigate the reasons behind these blind spots and suggest practical workarounds for a more reliable evaluation of text generation. We have released our code and data at https://github.com/cloudygoose/blindspot_nlg.
    
[^78]: PVGRU：通过Pseudo-Variational机制生成多样且相关的对话回复

    PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism. (arXiv:2212.09086v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09086](http://arxiv.org/abs/2212.09086)

    该论文提出了一个名为PVGRU的组件，可以通过引入汇总变量来聚合子序列的累积分布变化，从而优化基于生成的聊天机器人的多轮对话回复，提高对话模型的多样性和相关性。

    

    我们研究了基于生成的聊天机器人中用于多轮对话的回复生成。现有的基于RNN（循环神经网络）的生成模型通常使用最后隐藏的状态来汇总序列，这使得模型无法捕捉不同对话中观察到的微妙变化，并且不能区分在构成方面相似的对话之间的差异。在本文中，我们提出了一种Pseudo-Variational Gated Recurrent Unit（PVGRU）组件，无需后验知识即可将汇总变量引入GRU，其可以聚合子序列的累积分布变化。 PVGRU可以通过总结变量感知微妙的语义变化，这些变化是通过设计的分布一致性和重构目标进行优化的。此外，我们基于PVGRU构建了Pseudo-Variational Hierarchical Dialogue（PVHD）模型。实验结果表明，PVGRU可以广泛提高对话模型的多样性和相关性。

    We investigate response generation for multi-turn dialogue in generative-based chatbots. Existing generative models based on RNNs (Recurrent Neural Networks) usually employ the last hidden state to summarize the sequences, which makes models unable to capture the subtle variability observed in different dialogues and cannot distinguish the differences between dialogues that are similar in composition. In this paper, we propose a Pseudo-Variational Gated Recurrent Unit (PVGRU) component without posterior knowledge through introducing a recurrent summarizing variable into the GRU, which can aggregate the accumulated distribution variations of subsequences. PVGRU can perceive the subtle semantic variability through summarizing variables that are optimized by the devised distribution consistency and reconstruction objectives. In addition, we build a Pseudo-Variational Hierarchical Dialogue (PVHD) model based on PVGRU. Experimental results demonstrate that PVGRU can broadly improve the dive
    
[^79]: 在场学习者能否从演示中学习推理概念？

    Can In-context Learners Learn a Reasoning Concept from Demonstrations?. (arXiv:2212.01692v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01692](http://arxiv.org/abs/2212.01692)

    本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。

    

    大型语言模型展示了从少量输入-输出演示中学习新任务的新能力。然而，最近的研究表明，在场学习者大部分依赖于他们的预训练知识，如标签的情感，而不是在输入中找到新的关联性。然而，常用的少样本评估设置使用随机选择的在场演示无法区分模型从演示中学习新技能的能力，因为大部分随机选择的演示并不呈现超越暴露于新任务分布的预测的关系。为了在模型记忆独立的情况下区分模型的在场学习能力，我们引入了一个概念性少样本学习方法，选择与预测示例共享可能信息的演示。我们从注释解释中提取了一组这样的概念，并测量了模型展示这些概念可以获得多少好处。

    Large language models show an emergent ability to learn a new task from a small number of input-output demonstrations. However, recent work shows that in-context learners largely rely on their pre-trained knowledge, such as the sentiment of the labels, instead of finding new associations in the input. However, the commonly-used few-shot evaluation settings using a random selection of in-context demonstrations can not disentangle models' ability to learn a new skill from demonstrations, as most of the randomly-selected demonstrations do not present relations informative for prediction beyond exposing the new task distribution.  To disentangle models' in-context learning ability independent of models' memory, we introduce a Conceptual few-shot learning method selecting the demonstrations sharing a possibly-informative concept with the predicted sample. We extract a set of such concepts from annotated explanations and measure how much can models benefit from presenting these concepts in f
    
[^80]: xTrimoABFold：无多序列比对的新型抗体结构预测方法

    xTrimoABFold: De novo Antibody Structure Prediction without MSA. (arXiv:2212.00735v2 [q-bio.QM] CROSS LISTED)

    [http://arxiv.org/abs/2212.00735](http://arxiv.org/abs/2212.00735)

    xTrimoABFold是一种基于深度抗体语言模型的新型抗体结构预测方法，无需多序列比对，有望促进高通量药物设计的应用。

    

    在抗体工程领域，设计一个新型抗体以正确地结合特定抗原的表位是一项重要的任务。了解抗体结构和其表位可以促进对其功能的机制理解。因此，从其序列预测抗体结构一直是一项高度有价值的任务，而AlphaFold2提供了一种基于蛋白质序列预测蛋白质结构的解决方案，但对于抗体，特别是对于抗体的互补决定区（CDRs），其预测效率和准确性有限制。

    In the field of antibody engineering, an essential task is to design a novel antibody whose paratopes bind to a specific antigen with correct epitopes. Understanding antibody structure and its paratope can facilitate a mechanistic understanding of its function. Therefore, antibody structure prediction from its sequence alone has always been a highly valuable problem for de novo antibody design. AlphaFold2, a breakthrough in the field of structural biology, provides a solution to predict protein structure based on protein sequences and computationally expensive coevolutionary multiple sequence alignments (MSAs). However, the computational efficiency and undesirable prediction accuracy of antibodies, especially on the complementarity-determining regions (CDRs) of antibodies limit their applications in the industrially high-throughput drug design. To learn an informative representation of antibodies, we employed a deep antibody language model (ALM) on curated sequences from the observed a
    
[^81]: 用提示蕴涵重新思考事件编码管道

    Rethinking the Event Coding Pipeline with Prompt Entailment. (arXiv:2210.05257v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.05257](http://arxiv.org/abs/2210.05257)

    提出了一种名为PR-ENT的事件编码方法，用于从非结构化全文事件描述中提取事件类型。该方法利用预训练语言模型填充事件描述中的模板，并在文本隐含关系任务中选择答案候选项，同时保持了高准确性和资源效率。

    

    为了监测危机，政治事件从新闻中提取。庞大的非结构化全文事件描述使得逐案分析难以控制，尤其是对于低资源的人道主义援助组织来说。这就需要对事件进行分类，这一任务被称为事件编码。在这项工作中，我们提出了PR-ENT，这是一种新的事件编码方法，更加灵活和资源高效，同时保持了竞争性的准确性。

    For monitoring crises, political events are extracted from the news. The large amount of unstructured full-text event descriptions makes a case-by-case analysis unmanageable, particularly for low-resource humanitarian aid organizations. This creates a demand to classify events into event types, a task referred to as event coding. Typically, domain experts craft an event type ontology, annotators label a large dataset and technical experts develop a supervised coding system. In this work, we propose PR-ENT, a new event coding approach that is more flexible and resource-efficient, while maintaining competitive accuracy: first, we extend an event description such as "Military injured two civilians'' by a template, e.g. "People were [Z]" and prompt a pre-trained (cloze) language model to fill the slot Z. Second, we select answer candidates Z* = {"injured'', "hurt"...} by treating the event description as premise and the filled templates as hypothesis in a textual entailment task. This allo
    
[^82]: 不要失去自我！通过明确的自我他人意识生成共情回应

    Don't Lose Yourself! Empathetic Response Generation via Explicit Self-Other Awareness. (arXiv:2210.03884v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.03884](http://arxiv.org/abs/2210.03884)

    通过明确的自我他人意识生成共情回应，提高了聊天机器人生成共情回应的能力。

    

    为了实现类似于人的聊天机器人，共情回应的生成成为了一个关键步骤。之前的尝试不够完整，不能引起共情，因为它们只关注于通过其他感知来自动模仿用户的情绪和思想。然而，它们忽略了维持和考虑系统自身观点的重要过程，这是实现自我他人意识的共情关键。为此，我们提出了使用明确的自我他人意识（EmpSOA）生成共情回应。具体地，设计了三个阶段：自我他人区别、自我他人调节和自我他人生成，以清晰地维护、调节和注入自我他人感知信息到共情回应生成的过程中。基准数据集上的自动和人工评估均表明，EmpSOA生成了更具共情的回应，具有明显的优越性。

    As a critical step to achieve human-like chatbots, empathetic response generation has attained increasing interests. Previous attempts are incomplete and not sufficient enough to elicit empathy because they only focus on the initial aspect of empathy to automatically mimic the feelings and thoughts of the user via other-awareness. However, they ignore to maintain and take the own views of the system into account, which is a crucial process to achieve the empathy called self-other awareness. To this end, we propose to generate Empathetic response with explicit Self-Other Awareness (EmpSOA). Specifically, three stages, self-other differentiation, self-other modulation and self-other generation, are devised to clearly maintain, regulate and inject the self-other aware information into the process of empathetic response generation. Both automatic and human evaluations on the benchmark dataset demonstrate the superiority of EmpSOA to generate more empathetic responses.
    
[^83]: 我们真的取得了很大的进展吗？针对单标签和多标签文本分类的词袋、序列、图和层次结构的比较

    Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification. (arXiv:2204.03954v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.03954](http://arxiv.org/abs/2204.03954)

    本文比较了用于文本分类的词袋、序列、图形和分层方法，发现基于图形的方法无法超越现代预训练语言模型并且甚至有时表现不如标准机器学习方法，质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。

    

    图神经网络的流行引发了单标签和多标签文本分类的图形方法的复苏。然而，这些基于图形的方法是否比标准机器学习方法和现代预训练语言模型更有益仍不清楚。本文比较了用于文本分类的丰富的词袋、基于序列、基于图形和分层方法。我们聚合了来自文献的结果，在5个单标签和7个多标签数据集上运行了我们自己的实验。我们的研究结果明确表明，在单标签和多标签分类任务中，基于图形的方法无法超越精调的语言模型，有时甚至表现不如词袋上的标准机器学习方法，这质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。

    The popularity of graph neural networks has triggered a resurgence of graph-based methods for single-label and multi-label text classification. However, it is unclear whether these graph-based methods are beneficial compared to standard machine learning methods and modern pretrained language models. We compare a rich selection of bag-of-words, sequence-based, graph-based, and hierarchical methods for text classification. We aggregate results from the literature over 5 single-label and 7 multi-label datasets and run our own experiments. Our findings unambiguously demonstrate that for single-label and multi-label classification tasks, the graph-based methods fail to outperform fine-tuned language models and sometimes even perform worse than standard machine learning methods like multilayer perceptron (MLP) on a bag-of-words. This questions the enormous amount of effort put into the development of new graph-based methods in the last years and the promises they make for text classification
    
[^84]: 学习区分性表示和边界以进行开放式意图检测

    Learning Discriminative Representations and Decision Boundaries for Open Intent Detection. (arXiv:2203.05823v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.05823](http://arxiv.org/abs/2203.05823)

    本论文提出了一个名为DA-ADB的框架，通过学习距离感知意图表示和自适应决策边界来解决开放式意图检测中的两大挑战。在三个公共数据集上的实验证明了该框架的有效性和优越性。

    

    开放式意图检测是自然语言理解中的一个重大问题，旨在识别未知的开放式意图，同时确保已知意图的识别性能。然而，当前的方法面临两个主要挑战。首先，它们无法学习友好的表示以在只有已知意图的先验知识下检测开放式意图。其次，缺乏获得已知意图的特定而紧凑的决策边界的有效方法。为了解决这些问题，本论文提出了一个名为DA-ADB的原始框架，该框架成功地学习了用于开放式意图检测的距离感知意图表示和自适应决策边界。具体而言，我们首先利用距离信息增强了意图表示的区分能力。然后，我们设计了一种新的损失函数，通过平衡经验和开放空间风险来获得适当的决策边界。广泛的实验证明了我们的框架在三个公共数据集上的有效性，它显著优于现有的最先进方法。

    Open intent detection is a significant problem in natural language understanding, which aims to identify the unseen open intent while ensuring known intent identification performance. However, current methods face two major challenges. Firstly, they struggle to learn friendly representations to detect the open intent with prior knowledge of only known intents. Secondly, there is a lack of an effective approach to obtaining specific and compact decision boundaries for known intents. To address these issues, this paper presents an original framework called DA-ADB, which successively learns distance-aware intent representations and adaptive decision boundaries for open intent detection. Specifically, we first leverage distance information to enhance the distinguishing capability of the intent representations. Then, we design a novel loss function to obtain appropriate decision boundaries by balancing both empirical and open space risks. Extensive experiments demonstrate the effectiveness 
    
[^85]: LOGEN：基于逻辑知识条件的自训练文本生成在少样本下的应用

    LOGEN: Few-shot Logical Knowledge-Conditioned Text Generation with Self-training. (arXiv:2112.01404v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.01404](http://arxiv.org/abs/2112.01404)

    本文提出了一种基于少样本的逻辑知识条件下文本生成的统一框架LOGEN，通过自训练和基于内容和结构一致性抽样伪逻辑形式，实现了在少量样本下的文本生成。

    

    结构化数据的自然语言生成主要集中在表面层面描述，其存在控制内容选择困难和低保真度的问题。先前的研究利用逻辑形式来促进逻辑知识条件下的文本生成。虽然取得了显著进展，但是它们对数据的需求量较大，这使得在有限数据情况下应用于现实世界应用变得具有挑战性。为此，本文提出了一种基于少样本的逻辑知识条件下文本生成的统一框架。我们的方法只使用少量种子逻辑形式（如20/100种子） ，并利用自训练和基于内容和结构一致性抽样伪逻辑形式。实验结果表明，我们的方法可以比基准方法获得更好的少样本性能。

    Natural language generation from structured data mainly focuses on surface-level descriptions, suffering from uncontrollable content selection and low fidelity. Previous works leverage logical forms to facilitate logical knowledge-conditioned text generation. Though achieving remarkable progress, they are data-hungry, which makes the adoption for real-world applications challenging with limited data. To this end, this paper proposes a unified framework for logical knowledge-conditioned text generation in the few-shot setting. With only a few seeds logical forms (e.g., 20/100 shot), our approach leverages self-training and samples pseudo logical forms based on content and structure consistency. Experimental results demonstrate that our approach can obtain better few-shot performance than baselines.
    
[^86]: AVATAR：Java-Python程序翻译的平行语料库

    AVATAR: A Parallel Corpus for Java-Python Program Translation. (arXiv:2108.11590v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2108.11590](http://arxiv.org/abs/2108.11590)

    AVATAR是一个 Java-Python平行语料库，包含 9,515个编程问题和解决方案，可用于有监督学习和评估无监督方法的程序翻译模型，并且微调的模型在编程语言翻译的质量上优于无监督模型。

    

    程序翻译指将源代码从一种编程语言迁移到另一种编程语言。它在软件开发中具有巨大的实用价值，因为跨语言移植软件耗时且成本高昂。自动进行程序翻译在软件迁移中至关重要，最近研究人员由于找不到平行语料库而探索了无监督方法。然而，预先训练的编程语言语言模型的可用性使得用少量标记样本进行有监督的微调成为可能。因此，我们提出了AVATAR，包含9,515个使用两种流行语言（Java和Python）编写的编程问题及其解决方案的集合。AVATAR从竞技编程网站、在线平台和开源存储库中收集。此外，AVATAR还包含了250个示例的单元测试，以便进行功能正确性评估。我们对AVATAR微调了几个预训练语言模型并进行了基准测试。实验结果表明，微调的模型在程序翻译质量上明显优于无监督模型。AVATAR可以促进程序翻译模型的有监督学习，并作为评估无监督方法的基准。

    Program translation refers to migrating source code from one programming language to another. It has tremendous practical value in software development, as porting software across languages is time-consuming and costly. Automating program translation is of paramount importance in software migration, and recently researchers explored unsupervised approaches due to the unavailability of parallel corpora. However, the availability of pre-trained language models for programming languages enables supervised fine-tuning with a small number of labeled examples. Therefore, we present AVATAR, a collection of 9,515 programming problems and their solutions written in two popular languages, Java and Python. AVATAR is collected from competitive programming sites, online platforms, and open-source repositories. Furthermore, AVATAR includes unit tests for 250 examples to facilitate functional correctness evaluation. We benchmark several pre-trained language models fine-tuned on AVATAR. Experiment res
    

