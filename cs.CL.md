# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DeepFilterNet: Perceptually Motivated Real-Time Speech Enhancement.](http://arxiv.org/abs/2305.08227) | DeepFilterNet是一个基于感知的实时语音增强框架，利用语音生产和心理声学感知领域的知识实现高效率。在单线程笔记本电脑上实现了0.19的实时因子，在匹配最先进的语音增强基准方面表现出色。 |
| [^2] | [Learning to Generalize for Cross-domain QA.](http://arxiv.org/abs/2305.08208) | 提出了一种不增加训练成本的跨域问答泛化学习方法，通过结合提示方法和线性探测再微调策略，有效提高了产生式和判别式模型的泛化能力，取得了优于基准方法4.5%-7.9%的结果。 |
| [^3] | [A Cognitive Stimulation Dialogue System with Multi-source Knowledge Fusion for Elders with Cognitive Impairment.](http://arxiv.org/abs/2305.08200) | 本研究提出了一个多源知识融合的认知刺激对话系统，面向认知损伤的老年人。通过构建一个CSConv数据集，我们使得系统可以在提供情感支持的同时进行对话，并采用外部知识来预测目标响应的CS原则和情感支持策略以生成开放式回复。 |
| [^4] | [Learning to Simulate Natural Language Feedback for Interactive Semantic Parsing.](http://arxiv.org/abs/2305.08195) | 本研究提出了通过模拟自然语言反馈来进行交互式语义解析的新任务，该方法可以在低数据情况下取得与使用人工注释反馈数据训练所获得的相当的错误纠正性能。 |
| [^5] | [CroSentiNews 2.0: A Sentence-Level News Sentiment Corpus.](http://arxiv.org/abs/2305.08187) | CroSentiNews 2.0 是一个句子级新闻情感语料库，包含14.5K条已标注的新闻句子，标记有5类情感，并提供了基准分数和注释者一致性。 |
| [^6] | [Croatian Film Review Dataset (Cro-FiReDa): A Sentiment Annotated Dataset of Film Reviews.](http://arxiv.org/abs/2305.08173) | 介绍了一份注释了情感极性的克罗地亚电影评论数据集，并提供了基于变压器微调方法的基准结果。 |
| [^7] | [STORYWARS: A Dataset and Instruction Tuning Baselines for Collaborative Story Understanding and Generation.](http://arxiv.org/abs/2305.08152) | 该论文提出了一个名为STORYWARS的新数据集，可以用于协作故事理解和生成任务。作者通过指令调整的方式建立了 INSTRUCTSTORY 模型，成功地在全监督、少样本和零样本场景下处理故事任务。 |
| [^8] | [ParaLS: Lexical Substitution via Pretrained Paraphraser.](http://arxiv.org/abs/2305.08146) | 本研究提出了一种词汇替换方法，使用释义生成器生成替代词候选项，并提出两种解码策略，实验结果表明优于基于预训练语言模型的最新方法。 |
| [^9] | [Distinguish Before Answer: Generating Contrastive Explanation as Knowledge for Commonsense Question Answering.](http://arxiv.org/abs/2305.08135) | 提出了一种基于概念中心提示的对比解释生成模型CPACE，旨在将获得的符号知识转化为对比解释，用于更好地区分常识问答中的差异。 |
| [^10] | [Self-supervised Neural Factor Analysis for Disentangling Utterance-level Speech Representations.](http://arxiv.org/abs/2305.08099) | 本文提出了一种自监督神经因子分析模型，使用HuBERT中的聚类方法来发现隐藏的声学单元，并使用这些单元对齐SSL模型的特征，从而产生解耦后的语音表示，从而为专门任务提供了一种基于Utterance水平的无监督学习目标。实验结果表明，SSNFA模型在说话人识别、语言识别和情感识别等各种任务中均显著优于现有的SSL模型，并且没有任何特定任务的微调或监督。 |
| [^11] | [Towards Understanding and Improving Knowledge Distillation for Neural Machine Translation.](http://arxiv.org/abs/2305.08096) | 本文揭示了神经机器翻译中知识蒸馏的本质，即来自于教师模型的top-1预测。同时，指出了当前基于词级别的知识蒸馏存在的问题，并提出了一种新方法——Top-1 Information。 |
| [^12] | [Make Prompt-based Black-Box Tuning Colorful: Boosting Model Generalization from Three Orthogonal Perspectives.](http://arxiv.org/abs/2305.08088) | 本文提出了BBT-RGB，一套用于增强黑盒优化效率和性能的直接且互补技术套件，包括两阶段无导数优化策略、自动语言转化器构建及其在少样本设置中的新用法以及更好的提示初始化。 |
| [^13] | [Improving End-to-End SLU performance with Prosodic Attention and Distillation.](http://arxiv.org/abs/2305.08067) | 本文提出了韵律关注和韵律蒸馏方法来利用韵律特征提高端到端语义理解（SLU）的性能，其中韵律蒸馏方法相对于基线方法在SLURP和STOP数据集上提高了8％和2％的意图分类准确性。 |
| [^14] | [Semantic-aware Dynamic Retrospective-Prospective Reasoning for Event-level Video Question Answering.](http://arxiv.org/abs/2305.08059) | 本文提出了一种用于视频问答的语义感知动态回顾-前瞻推理方法，通过明确使用问题的语义角色标注（SRL）结构，根据问题SRL结构的哪一部分被关注来促进跨视频帧的复杂推理，实验结果显示性能优越。 |
| [^15] | [ProKnow: Process Knowledge for Safety Constrained and Explainable Question Generation for Mental Health Diagnostic Assistance.](http://arxiv.org/abs/2305.08010) | 本论文提出了ProKnow的概念，它可以提高虚拟心理健康助手的安全性和专业性。同时开发了自然语言问题生成算法，通过明确建模安全性、知识捕获和可解释性来模拟流程知识。在抑郁症和焦虑症中的实验表明，使用ProKnow引导的算法可以生成更安全的问题。 |
| [^16] | [Beyond the Safeguards: Exploring the Security Risks of ChatGPT.](http://arxiv.org/abs/2305.08005) | 本文探讨了ChatGPT的多种安全风险和绕过保护措施的潜在方法，发现即使保护措施存在，LLMs仍存在伦理和安全风险。本研究为减轻这些风险提供了潜在策略。 |
| [^17] | [Multilingual Previously Fact-Checked Claim Retrieval.](http://arxiv.org/abs/2305.07991) | 本文介绍了一个新的多语种数据集MultiClaim，用于先前事实核查的检索，通过不同的无监督方法及一个经过监督微调的方法对其进行了评估。 |
| [^18] | [Self-Supervised Sentence Compression for Meeting Summarization.](http://arxiv.org/abs/2305.07988) | 本论文提出了一种自监督学习的会议摘要框架SVB，通过三个过程压缩冗余内容并保留关键信息。其中，滑动窗口对话恢复与评分、通道重要性得分投票和相对位置分箱等算法用于实现这个框架。 |
| [^19] | [Zero-shot Faithful Factual Error Correction.](http://arxiv.org/abs/2305.07982) | 零样本的忠实事实性错误纠正框架超越完全监督方法，具有较高的及解释性和忠实性评估标准，适用于维护文本知识库和预防序列到序列模型中的幻觉。 |
| [^20] | [Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis.](http://arxiv.org/abs/2305.07972) | 本文介绍了一个新的金融数据集，并开展了一项新的“鹰派-鸽派”分类任务。我们使用RoBERTa-large模型构建了FOMC文件发布日的货币政策立场指数，并对其对国库市场、股票市场和宏观经济指标的影响进行了研究。 |
| [^21] | [GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content.](http://arxiv.org/abs/2305.07969) | GPT-Sentinel通过语言模型检测ChatGPT生成的文本和人类编写的文本，其模型在测试数据集上准确率超过了97％，并且揭示了区分这两种文本关键特征的能力。 |
| [^22] | [Leveraging Large Language Models in Conversational Recommender Systems.](http://arxiv.org/abs/2305.07961) | 本文提出了一种使用大型语言模型构建端到端大规模对话推荐系统的路线图，解决在该系统中有效利用大型语言模型所面临的技术挑战。 |
| [^23] | [AMTSS: An Adaptive Multi-Teacher Single-Student Knowledge Distillation Framework For Multilingual Language Inference.](http://arxiv.org/abs/2305.07928) | AMTSS是一种自适应多教师单学生知识蒸馏框架，可以在多语言设置下支持成本效益的语言推理，并取得了在XNLI数据集和AliExpress中竞争性的结果。 |
| [^24] | [RC3: Regularized Contrastive Cross-lingual Cross-modal Pre-training.](http://arxiv.org/abs/2305.07927) | 本文提出了RC3预训练方法，通过规则化对比跨语言跨模态学习，有效利用弱对准的多语种图像-文本对，从而在多语种V&L任务中取得了更好的性能。 |
| [^25] | [CodeT5+: Open Code Large Language Models for Code Understanding and Generation.](http://arxiv.org/abs/2305.07922) | CodeT5+是一组灵活组合的编码器-解码器LLM族，用于代码，混合了多种不同的预训练目标，包括代码生成、自然语言处理和程序合成，可以适应多种不同的下游代码任务，并且在实验中比现有代码-specific LLMs实现了最先进的性能。 |
| [^26] | [Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion.](http://arxiv.org/abs/2305.07912) | 这篇论文提出了一种基于提示的预训练语言模型（PPT），用于时间知识图谱补全。通过遮盖策略，将TKGC任务转换为遮盖词预测任务，可以利用预训练语言模型中的语义信息。 |
| [^27] | [On the Hidden Mystery of OCR in Large Multimodal Models.](http://arxiv.org/abs/2305.07895) | 本研究全面评估了现有大型多模态模型在文本相关的视觉任务中的表现，结果显示这些模型虽然在语义理解方面表现优异，但对单个字符形状的感知有限，对图像的细粒度特征检测能力也不足，不能与传统领域特定方法相匹配，并仍需进一步探索它们在OCR中的表现。 |
| [^28] | [PESTS: Persian_English Cross Lingual Corpus for Semantic Textual Similarity.](http://arxiv.org/abs/2305.07893) | 本研究提出了跨语言的语义相似性模型PESTS，并通过波斯语-英语的跨语言语料库来验证模型的准确性。 |
| [^29] | [Dual Use Concerns of Generative AI and Large Language Models.](http://arxiv.org/abs/2305.07882) | 本文建议将双重使用研究框架应用于生成式人工智能和大型语言模型，提出了具体的应用建议，以加强人工智能治理并增强社会对其影响的认识。 |
| [^30] | [Bridging History with AI A Comparative Evaluation of GPT 3.5, GPT4, and GoogleBARD in Predictive Accuracy and Fact Checking.](http://arxiv.org/abs/2305.07868) | 本研究比较评估了三种大型语言模型的性能，结果表明AI技术在历史事实核查和填补空白方面有着巨大的潜力，其中GPT 4表现最为优异，这说明需要进一步探索AI技术在历史研究中的应用，以便丰富我们对过去的理解和弥合历史知识差距。 |
| [^31] | [The Geometry of Multilingual Language Models: An Equality Lens.](http://arxiv.org/abs/2305.07839) | 本研究在欧几里得空间中分析了三种多语言语言模型的几何，发现尽管语言往往根据它们的语言家族更加接近，但它们几乎可以被从其他语言家族的语言分离出来。同时，低资源语言的表现普遍不如高资源语言的表现好。 |
| [^32] | [Frequency-aware Dimension Selection for Static Word Embedding by Mixed Product Distance.](http://arxiv.org/abs/2305.07826) | 本论文研究了词频对维度选择的影响，在此基础上提出了一种使用混合积距离的静态词向量维度选择方法，通过降低词频的影响，实现了比现有方法更好的性能。 |
| [^33] | [A Simple and Plug-and-play Method for Unsupervised Sentence Representation Enhancement.](http://arxiv.org/abs/2305.07824) | 本文提出了一种名为 RepAL 的简单易用的无监督方法，用于增强句子表示。通过减弱句子嵌入中的冗余信息，可以提高语义匹配和检索的效果。该方法无须训练，可与大多数现有的无监督句子学习模型结合使用。 |
| [^34] | [Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation.](http://arxiv.org/abs/2305.07804) | 本论文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，以改善小语言模型的性能，特别是在医学问答任务中。这种方法在微调后使模型性能提高，并提出了在特定领域问答任务中使用LLM所面临的挑战和潜在的研究方向。 |
| [^35] | [ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems.](http://arxiv.org/abs/2305.07797) | ACCENT是一种基于常识知识库的事件常识评价方法，通过对话中提取的事件-关系元组与CSKB的兼容性评估响应，是一种有效的评价方法。 |
| [^36] | [Constructing Holistic Measures for Social Biases in Masked Language Models.](http://arxiv.org/abs/2305.07795) | 本文提出了KLDivS和JSDivS这两个评估指标，将掩码语言模型输出的刻板印象和反刻板印象样本的对数似然函数视为高斯分布，可以更稳定、可解释地评估MLMs中的社会偏见。 |
| [^37] | [Answering Complex Questions over Text by Hybrid Question Parsing and Execution.](http://arxiv.org/abs/2305.07789) | 提出了一种混合问题解析和执行框架，在文字问答系统中实现回答复杂问题，通过解析问题为H表达式并设计混合执行器实现。在基准数据集中实现了最先进的准确率和效率表现。 |
| [^38] | [NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models.](http://arxiv.org/abs/2305.07766) | 本研究提出了一种NL到TL的转换框架，使用大型语言模型在数据集和模型训练中，可以准确并且具有普适性地转换复杂的高级系统规范。 |
| [^39] | [Knowledge Authoring for Rules and Actions.](http://arxiv.org/abs/2305.07763) | KALMRA是一个工具，它扩展了英语命令的功能，以允许在KALM中进行规则和操作的创作，并通过规则和操作的创作任务数据集的评估显示出较高的准确性和表现。 |
| [^40] | [TinyStories: How Small Can Language Models Be and Still Speak Coherent English?.](http://arxiv.org/abs/2305.07759) | 本文针对小型语言模型生成连贯的英文文本难题，引入了一个合成故事数据集 TinyStories，并探索小型模型规模、结构复杂度和训练数据规模对于语言模型表现的影响，证明了仅含 200 万参数的简单语言模型也能产生连贯的短故事。 |
| [^41] | [Using Language Models to Detect Alarming Student Responses.](http://arxiv.org/abs/2305.07709) | 本文介绍了一种利用自然语言处理技术识别危险学生回复的系统，该系统采用经过微调的语言模型进行训练，能够显著提高准确性。 |
| [^42] | [Masked Audio Text Encoders are Effective Multi-Modal Rescorers.](http://arxiv.org/abs/2305.07677) | 本文提出了Masked Audio Text Encoders（MATE），一个多模态掩码语言模型重新打分器，将声学表示形式并入到MLM的输入空间中。使用MATE对自动语音识别（ASR）系统进行多模态打分，即使在目标域数据不足的情况下，也可以提高系统的领域泛化能力，并且可以在非常有限的训练数据量下就将单词错误率（WER）降低。 |
| [^43] | [Imitation versus Innovation: What children can do that large language and language-and-vision models cannot (yet)?.](http://arxiv.org/abs/2305.07666) | 本研究探讨了大型语言和语言视觉模型的局限性，以及机器与人类儿童在模仿和创新方面的不同表现。结果表明，机器需要更多的信息才能达到孩子所能做到的水平。 |
| [^44] | [Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation.](http://arxiv.org/abs/2305.07375) | 本文对ChatGPT的因果推理能力进行了首次全面评估，实验证明ChatGPT是一个好的因果解释者，但不是一个好的因果推理者，存在严重的因果幻觉问题，对于明确的因果关系表现良好。 |
| [^45] | [Evaluating Open-Domain Question Answering in the Era of Large Language Models.](http://arxiv.org/abs/2305.06984) | 本文评估了开放领域问答中的大语言模型，发现词汇匹配作为评估方法在这些模型中的作用有限，提出了一种手动评估方法，并发现其中一个零-shot模型的性能大幅度提升。 |
| [^46] | [COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP tasks.](http://arxiv.org/abs/2305.06754) | COCKATIEL是一种连续概念排名带归因性解释的技术，基于概念，用于从NLP分类任务的神经网络模型的最后一层中生成有意义的解释，且不会影响准确性或需要新模型，已证明比现有方法产生更有信息量和可靠的解释。 |
| [^47] | [How to Index Item IDs for Recommendation Foundation Models.](http://arxiv.org/abs/2305.06569) | 本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。 |
| [^48] | [Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge.](http://arxiv.org/abs/2305.05976) | 本文研究了大型语言模型(LLMs)对负面常识知识的了解程度，发现LLMs在生成基于负面知识的有效句子方面存在困难，但在回答极性问题方面表现良好，这种信念冲突主要源于语言预训练时的统计快捷方式和否定报告偏见。 |
| [^49] | [Beyond Good Intentions: Reporting the Research Landscape of NLP for Social Good.](http://arxiv.org/abs/2305.05471) | 本文介绍了NLP4SGPAPERS数据集，通过对解决社会问题的论文进行分类、可持续发展目标映射、任务及方法的确定，使用最先进的NLP模型在整个ACL文集上进行处理，提供了一个可视化工作区，展示了NLP4SG领域的全貌。 |
| [^50] | [VCSUM: A Versatile Chinese Meeting Summarization Dataset.](http://arxiv.org/abs/2305.05280) | 介绍了一个多功能的中文会议摘要数据集VCSum，包括239个现实生活中的会议，总时长超过230小时。该数据集可以适应各种摘要任务或方法，包括基于分割的摘要、多粒度摘要和检索-生成摘要。数据集和代码将在GitHub上发布。 |
| [^51] | [ANALOGICAL - A New Benchmark for Analogy of Long Text for Large Language Models.](http://arxiv.org/abs/2305.05050) | 本文介绍了一种名为“ANALOGICAL”的新型基准，用以内在评估LLMs在长文本类比中的能力，包括六个复杂级别的长文本类比分类，并使用13个数据集和三种距离度量方法来评估8个LLMs在语义向量空间中识别类比对的能力。 |
| [^52] | [A transformer-based method for zero and few-shot biomedical named entity recognition.](http://arxiv.org/abs/2305.04928) | 本文提出了一种基于Transformer的生物医学领域零样本和少样本NER方法。此方法利用预训练学习给定和潜在类别之间的语义关系，将多类标记分类任务转换为二元标记分类，能够在不同数量的样本情况下达到良好的识别效果。 |
| [^53] | [MultiTACRED: A Multilingual Version of the TAC Relation Extraction Dataset.](http://arxiv.org/abs/2305.04582) | 该论文介绍了一个名为MultiTACRED的多语言版本的数据集，通过机器翻译和自动注释，该数据集涵盖了12种语言，填补了多语言情况下关系抽取领域缺乏资源的问题。研究表明机器翻译是可行的，而单语RE模型的性能与英文原版相当。 |
| [^54] | [AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment.](http://arxiv.org/abs/2305.04476) | 本文提出了基于跨模态对齐的STS模型AlignSTS，通过一种新颖的节奏适配器来预测目标节奏表示以弥合内容和音高之间的模态差距，并使用交叉注意力重新对齐内容进行跨模态融合重新合成。该模型表现优异。 |
| [^55] | [LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models.](http://arxiv.org/abs/2305.03445) | 本文研究调查了具身化策略对语言模型解释比喻性语言的影响。结果表明，更大的模型在处理行为更具体化的隐喻性句子时表现更佳。 |
| [^56] | [HiPool: Modeling Long Documents Using Graph Neural Networks.](http://arxiv.org/abs/2305.03319) | 本论文提出了一种基于图神经网络的方法来模拟长文档，解决了顺序模型中的长期依赖问题，在新提出的基准测试中达到了最先进的性能。 |
| [^57] | [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds.](http://arxiv.org/abs/2305.00969) | CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。 |
| [^58] | [Constructing a Knowledge Graph from Textual Descriptions of Software Vulnerabilities in the National Vulnerability Database.](http://arxiv.org/abs/2305.00382) | 本文提出了一种从国家漏洞数据库信息中构建漏洞知识图谱的新方法，结合了命名实体识别、关系提取和实体预测。该方法有助于解决网络安全知识图谱中缺失实体的问题。 |
| [^59] | [SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish.](http://arxiv.org/abs/2304.13994) | SweCTRL-Mini是一种基于Transformer的大型瑞典语言模型，用户可以控制它生成的文本流派，完全开放下载。生成能力比较GPT-3。 |
| [^60] | [Measuring Massive Multitask Chinese Understanding.](http://arxiv.org/abs/2304.12986) | 本研究提出了一项测试，以衡量大型中文语言模型的多任务准确性，测试涵盖医学、法律、心理学和教育四个主要领域，结果表明所有模型在法律领域中表现都很差，建议研究人员应该开发更加多样化和均衡的多任务中文理解模型。 |
| [^61] | [Generating Post-hoc Explanations for Skip-gram-based Node Embeddings by Identifying Important Nodes with Bridgeness.](http://arxiv.org/abs/2304.12036) | 本文提出了一种解释Skip-gram节点嵌入的方法，即通过计算桥接度识别重要节点，并提出了一种新型基于梯度的解释方法GRAPH-wGD，有效地提供全局性解释。 |
| [^62] | [Global Prompt Cell: A Portable Control Module for Effective Prompt.](http://arxiv.org/abs/2304.05642) | 全局提示单元(GPC)是一种用于调整预训练模型的可移植控制模块。它可以在所有编码器层中选择性地保留提示信息，从而提高了 5.8% 的 SuperGLUE 数据集的性能表现。 |
| [^63] | [Natural Language Reasoning, A Survey.](http://arxiv.org/abs/2303.14725) | 本综述论文从哲学和NLP场景出发，提供了自然语言推理在NLP中明确的定义，阐述了自然语言推理任务的类型和一种推理分类法，并探讨了经典逻辑推理、自然语言推理、多跳问题回答和常识推理四个方面的研究现状和未来方向。 |
| [^64] | [Deep RL with Hierarchical Action Exploration for Dialogue Generation.](http://arxiv.org/abs/2303.13465) | 本篇论文提出了一种新的方法，通过分层行为探索，从多个奖励函数中进行离线学习，并成功地解决了在对话生成中行为采样效率低下的问题，可以更好地识别人类情感细节。 |
| [^65] | [Evaluating Transformer Models and Human Behaviors on Chinese Character Naming.](http://arxiv.org/abs/2303.12294) | 本研究评估了一组 transformer 模型，在未知的中文字符命名任务中，这些模型表现得与人类很相似，能够很好地捕捉人类字符命名行为。 |
| [^66] | [Toward Artificial Empathy for Human-Centered Design: A Framework.](http://arxiv.org/abs/2303.10583) | 本文提出了一个框架，旨在从人工智能研究中引入人工共情的思想进入人本设计，以帮助设计师更好地理解用户的需求。 |
| [^67] | [Diffusion Models for Non-autoregressive Text Generation: A Survey.](http://arxiv.org/abs/2303.06574) | 本文综述了扩散模型在非自回归文本生成中的最新进展，包括两种主流扩散模型，以及语言预训练模型在文本扩散模型中的应用和文本数据的优化技术。 |
| [^68] | [Double Permutation Equivariance for Knowledge Graph Completion.](http://arxiv.org/abs/2302.01313) | 本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。 |
| [^69] | [Parallel Context Windows for Large Language Models.](http://arxiv.org/abs/2212.10947) | PCW方法可以缓解现成LLM的上下文窗口限制，将长上下文划分为块并在每个窗口内重用位置嵌入，提高了处理长文本的性能表现。 |
| [^70] | [Ontologically Faithful Generation of Non-Player Character Dialogues.](http://arxiv.org/abs/2212.10618) | 该论文介绍了一个与流行视频游戏环境相关的语言生成任务，该任务包括非线性的角色对话树生成，并要求对话忠实于游戏的角色形象和实体关系，对话必须准确向玩家揭示新的任务细节。神经生成模型的结果表明，该模型能够胜任这个任务但还有进一步的改进空间。 |
| [^71] | [Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers.](http://arxiv.org/abs/2212.10559) | 本文将语言模型解释为元优化器，并将上下文学习理解为隐式微调，通过实验证据支持了这一理解。 |
| [^72] | [Defending Against Misinformation Attacks in Open-Domain Question Answering.](http://arxiv.org/abs/2212.10002) | 本文提出了一种使用查询扩充来搜索冗余信息、并通过新颖的置信度方法将其集成到模型中的方法，可以有效防御开放域问答系统中的污染攻击，精确匹配率可提高近20%。 |
| [^73] | [Unsupervised Summarization Re-ranking.](http://arxiv.org/abs/2212.09593) | 该论文提出了一种无监督的摘要再排序方法，可以将无监督模型的摘要表现提高，缩小其与有监督模型之间的性能差距。 |
| [^74] | [PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism.](http://arxiv.org/abs/2212.09086) | 该论文提出了一个名为PVGRU的组件，可以通过引入汇总变量来聚合子序列的累积分布变化，从而优化基于生成的聊天机器人的多轮对话回复，提高对话模型的多样性和相关性。 |
| [^75] | [Advancing Multilingual Pre-training: TRIP Triangular Document-level Pre-training for Multilingual Language Models.](http://arxiv.org/abs/2212.07752) | TRIP模型利用文档级三语言平行语料库改进序列到序列的多语言预训练，获得了在多项任务上的最优结果。 |
| [^76] | [Causes and Cures for Interference in Multilingual Translation.](http://arxiv.org/abs/2212.07530) | 研究探究了多语言机器翻译中干扰的主要因素，通过系统化试验发现使用不到10亿参数的标准Transformer配置可以在很大程度上缓解干扰并促进协同，同时发现调整采样温度以控制数据中每个语言对所占比例的方法是平衡语言对之间关系的关键。 |
| [^77] | [Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning.](http://arxiv.org/abs/2212.03760) | 本文研究发现，用户历史语言建模可以在不同推荐任务中取得优异结果，并且利用任务无关的用户历史还可以提供显著的性能优势。该方法具有广泛的现实世界迁移学习能力。 |
| [^78] | [Logic and Commonsense-Guided Temporal Knowledge Graph Completion.](http://arxiv.org/abs/2211.16865) | 本文提出一种"逻辑和常识引导的嵌入模型"（LCGE），通过共同学习时间敏感性表示（涉及时态和因果性的事件表示）与常识角度上的时间无关表示，解决了时间知识图谱补全中表示事件的实时性和因果性的挑战。 |
| [^79] | [data2vec-aqc: Search for the right Teaching Assistant in the Teacher-Student training setup.](http://arxiv.org/abs/2211.01246) | 本文提出了一种新的自我监督学习算法data2vec-aqc，用于从未标记的语音数据中学习语音表示，该算法在语音识别领域取得了显著的性能提高。 |
| [^80] | [How do we get there? Evaluating transformer neural networks as cognitive models for English past tense inflection.](http://arxiv.org/abs/2210.09167) | 本研究通过训练变压器模型的不同设置来评估模型在英语过去式词形变化任务上的表现，结果发现模型在未见过的规则动词上有很高的准确率，在非规则动词上的表现略有提高。不同行为表明模型具有一定程度的符号学习。 |
| [^81] | [KALM: Knowledge-Aware Integration of Local, Document, and Global Contexts for Long Document Understanding.](http://arxiv.org/abs/2210.04105) | KALM是一种知识感知语言模型，可以在本地、文档级别和全局语境中联合利用知识，用于长文档理解。 |
| [^82] | [CCC-wav2vec 2.0: Clustering aided Cross Contrastive Self-supervised learning of speech representations.](http://arxiv.org/abs/2210.02592) | 本论文提出了一种基于聚类的交叉对比自监督学习语音表示的方法，引入了增强散度、交叉对比损失和聚类模块，相对于wav2vec 2.0基线在LibriSpeech测试集上取得了超过12%的WER改进。 |
| [^83] | [What Makes Pre-trained Language Models Better Zero-shot Learners?.](http://arxiv.org/abs/2209.15206) | 本文提出一个理论框架来解释prompt learning在零样本/少样本场景下的有效性，并基于此提出了一个注释无关的模板选择方法。 |
| [^84] | [Revamping Multilingual Agreement Bidirectionally via Switched Back-translation for Multilingual Neural Machine Translation.](http://arxiv.org/abs/2209.13940) | 提出了一种名为 BMA-SBT 的新型通用多语言协议框架，通过使用 switched BT 方法，使得不需要平行数据就可以建立多语言协议，同时使用 Kullback-Leibler 散度损失双向优化协议，在 MNMT 任务上明显改善了强基线的效果。 |
| [^85] | [Rethinking Round-Trip Translation for Machine Translation Evaluation.](http://arxiv.org/abs/2209.07351) | 本文研究了往返翻译方法在机器翻译评估中的应用，发现去除统计机器翻译中的复制机制后，往返翻译可以恰当地反映前向翻译的性能，该方法可以在低资源语言的情况下进行自动评估。 |
| [^86] | [Pre-trained Language Models for the Legal Domain: A Case Study on Indian Law.](http://arxiv.org/abs/2209.06049) | 本研究针对印度法律文本，重新训练和从零开始训练了两个PLMs，即LegalBERT和CaseLawBERT，并采用基于印度法律文本的词汇表训练了一个模型。我们在几项基准法律NLP任务中，对印度和非印度的法律文本进行了应用。 |
| [^87] | [StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing.](http://arxiv.org/abs/2208.13423) | 本文提出了StoryTrans模型，用于解决非平行故事作者风格转换的任务。该模型利用语篇表示和可学习的风格嵌入实现源内容信息到目标风格的转换，并引入了一个内容增强模块以提高语义一致性。在两个数据集上的评测中，该模型表现出了显著的性能优势。 |
| [^88] | [Learning Dynamic Contextualised Word Embeddings via Template-based Temporal Adaptation.](http://arxiv.org/abs/2208.10734) | 本文提出一种基于时间适应的动态上下文词嵌入学习方法，使用感知时间的模板生成提示，通过微调预训练的MLM得到DCWE，实验结果表明该方法在困惑度和下游任务上优于现有方法。 |
| [^89] | [CASE: Aligning Coarse-to-Fine Cognition and Affection for Empathetic Response Generation.](http://arxiv.org/abs/2208.08845) | 本研究提出了用于共情对话生成的CASE模型，通过调整用户的粗细粒度的认知和情感的匹配，可以生成更具共情和信息性的响应。 |
| [^90] | [Automated Audio Captioning and Language-Based Audio Retrieval.](http://arxiv.org/abs/2207.04156) | 该论文描述了在DCASE 2022比赛中参加了自动音频字幕和基于语言的音频检索两个子任务，并使用Clotho数据集进行了评估。对于这两个子任务，我们修改了基线模型，得到了良好的性能提升。 |
| [^91] | [Predicting Hate Intensity of Twitter Conversation Threads.](http://arxiv.org/abs/2206.08406) | 本文提出了DRAGNET++, 通过考虑对话线程的语义、传播结构和用户交互，以预测推文的回复链中可能存在的仇恨程度，并在两个公开数据集上的实验中表现出优越性能。该模型可为社交媒体平台提供在恶意对话升级之前识别和管理的工具。 |
| [^92] | [COOL, a Context Outlooker, and its Application to Question Answering and other Natural Language Processing Tasks.](http://arxiv.org/abs/2204.09593) | COOL是一种上下文观察器，用于编码局部句法上下文，能够改进基于Transformer的模型在自然语言处理任务中的性能，包括问答。 |
| [^93] | [PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations.](http://arxiv.org/abs/2203.16965) | 本文提出了PADA方法，在自监督语音表示学习领域自适应方面加入剪枝策略，使用CD-TAW方法从精细调整的OOT模型中获得初始剪枝掩码，并取得良好效果。 |
| [^94] | [AxoNN: An asynchronous, message-driven parallel framework for extreme-scale deep learning.](http://arxiv.org/abs/2110.13005) | AxoNN是一种利用异步性和消息驱动执行调度每个GPU上神经网络操作的并行深度学习框架，将CPU内存作为冗余空间，降低GPU内存消耗，同时将每个GPU的参数数量增加4倍，从而减少了必需的GPU数量和训练时间。 |
| [^95] | [Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems.](http://arxiv.org/abs/2106.01263) | 论文提出一种新的响应选择范例Uni-Encoder，解决了Cross-Encoder多次编码相同上下文计算成本高和Poly-Encoder性能下降的问题。该范例在一次前向传递中对所有候选与上下文进行编码。 |
| [^96] | [Quinductor: a multilingual data-driven method for generating reading-comprehension questions using Universal Dependencies.](http://arxiv.org/abs/2103.10121) | Quinductor是一种多语言数据驱动的阅读理解问题生成方法，使用依存树，适用于资源较少的语言，比之前文献报道的QG基线效果更好。 |
| [^97] | [Multi-Task Attentive Residual Networks for Argument Mining.](http://arxiv.org/abs/2102.12227) | 本文提出了一种多任务注意力残差网络架构，通过利用集成方法、注意力机制和多任务学习，无需假设文档或论据结构，成功应用于多个论述挖掘任务中，成为了一种既通用又高性能的架构。 |

# 详细

[^1]: DeepFilterNet: 基于感知的实时语音增强

    DeepFilterNet: Perceptually Motivated Real-Time Speech Enhancement. (arXiv:2305.08227v1 [eess.AS])

    [http://arxiv.org/abs/2305.08227](http://arxiv.org/abs/2305.08227)

    DeepFilterNet是一个基于感知的实时语音增强框架，利用语音生产和心理声学感知领域的知识实现高效率。在单线程笔记本电脑上实现了0.19的实时因子，在匹配最先进的语音增强基准方面表现出色。

    

    单通道语音增强的多帧算法能够利用语音信号中的短时相关性。Deep Filtering(DF) 提出了直接在频域估计复杂滤波器以利用这些相关性。本文提出了使用DeepFilterNet进行实时语音增强的演示。DeepFilterNet的效率是通过利用语音生产和心理声学感知领域的知识实现的。我们的模型能够匹配最先进的语音增强基准，同时在单线程笔记本电脑上实现了0.19的实时因子。该框架以及预先训练的权重已经发表了开源许可证。

    Multi-frame algorithms for single-channel speech enhancement are able to take advantage from short-time correlations within the speech signal. Deep Filtering (DF) was proposed to directly estimate a complex filter in frequency domain to take advantage of these correlations. In this work, we present a real-time speech enhancement demo using DeepFilterNet. DeepFilterNet's efficiency is enabled by exploiting domain knowledge of speech production and psychoacoustic perception. Our model is able to match state-of-the-art speech enhancement benchmarks while achieving a real-time-factor of 0.19 on a single threaded notebook CPU. The framework as well as pretrained weights have been published under an open source license.
    
[^2]: 跨域问答泛化学习

    Learning to Generalize for Cross-domain QA. (arXiv:2305.08208v1 [cs.CL])

    [http://arxiv.org/abs/2305.08208](http://arxiv.org/abs/2305.08208)

    提出了一种不增加训练成本的跨域问答泛化学习方法，通过结合提示方法和线性探测再微调策略，有效提高了产生式和判别式模型的泛化能力，取得了优于基准方法4.5%-7.9%的结果。

    

    自然语言处理模型的跨域泛化能力，尤其是在问答任务中，一直存在着越来越大的担忧。当前的合成数据增强方法受到了增加训练成本的限制。为了解决这个问题，我们提出了一种结合提示方法和线性探测再微调策略的新方法，该方法不需要额外的成本。我们的方法在理论上和实证上都被证明有效，可以增强产生式和判别式模型的泛化能力。我们的方法优于现有的基准方法，F1得分平均提高了4.5%-7.9%。同时，我们的方法可以轻松地集成到任何预训练模型中，并为未充分开发的跨域问答任务提供了有前途的解决方案。我们在GitHub上公开了我们的源代码*。

    There have been growing concerns regarding the out-of-domain generalization ability of natural language processing (NLP) models, particularly in question-answering (QA) tasks. Current synthesized data augmentation methods for QA are hampered by increased training costs. To address this issue, we propose a novel approach that combines prompting methods and linear probing then fine-tuning strategy, which does not entail additional cost. Our method has been theoretically and empirically shown to be effective in enhancing the generalization ability of both generative and discriminative models. Our approach outperforms state-of-the-art baselines, with an average increase in F1 score of 4.5%-7.9%. Furthermore, our method can be easily integrated into any pre-trained models and offers a promising solution to the under-explored cross-domain QA task. We release our source code at GitHub*.
    
[^3]: 一种多源知识融合的认知刺激对话系统，面向认知损伤的老年人

    A Cognitive Stimulation Dialogue System with Multi-source Knowledge Fusion for Elders with Cognitive Impairment. (arXiv:2305.08200v1 [cs.CL])

    [http://arxiv.org/abs/2305.08200](http://arxiv.org/abs/2305.08200)

    本研究提出了一个多源知识融合的认知刺激对话系统，面向认知损伤的老年人。通过构建一个CSConv数据集，我们使得系统可以在提供情感支持的同时进行对话，并采用外部知识来预测目标响应的CS原则和情感支持策略以生成开放式回复。

    

    与认知障碍的老年人交流时，认知刺激（CS）有助于维护老年人的认知健康。数据稀缺是构建基于CS的对话系统的主要挑战，特别是在中文方面。为了填补这一空白，我们构建了一份中国CS对话（CSConv）数据集，其中包含约2.6K组具有CS原则和情感支持策略标签的对话。在提供情感支持的同时聊天是大多数现有认知对话系统所忽视的。在本文中，我们提出了一种多源知识融合的认知刺激对话（CSD）方法，以生成在CS原则和情感支持策略指导下的开放式回复。我们首先使用基于外部知识的渐进式遮盖方法来学习编码器作为有效的分类器，这是预测目标响应的CS原则和情感支持策略的前提。然后，解码器与感知的CS原则相互作用来生成响应。

    When communicating with elders with cognitive impairment, cognitive stimulation (CS) help to maintain the cognitive health of elders. Data sparsity is the main challenge in building CS-based dialogue systems, particularly in the Chinese language. To fill this gap, we construct a Chinese CS conversation (CSConv) dataset, which contains about 2.6K groups of dialogues with CS principles and emotional support strategy labels. Making chit chat while providing emotional support is overlooked by the majority of existing cognitive dialogue systems. In this paper, we propose a multi-source knowledge fusion method for CS dialogue (CSD), to generate open-ended responses guided by the CS principle and emotional support strategy. We first use a progressive mask method based on external knowledge to learn encoders as effective classifiers, which is the prerequisite to predict the CS principle and emotional support strategy of the target response. Then a decoder interacts with the perceived CS princi
    
[^4]: 学习模拟自然语言反馈以进行交互式语义解析

    Learning to Simulate Natural Language Feedback for Interactive Semantic Parsing. (arXiv:2305.08195v1 [cs.CL])

    [http://arxiv.org/abs/2305.08195](http://arxiv.org/abs/2305.08195)

    本研究提出了通过模拟自然语言反馈来进行交互式语义解析的新任务，该方法可以在低数据情况下取得与使用人工注释反馈数据训练所获得的相当的错误纠正性能。

    

    基于自然语言反馈的交互式语义解析已经成为比传统的一次语义解析更实用的场景，其中用户提供反馈来纠正解析器的错误。然而，以往的研究极大地依赖于人工注释的反馈数据来训练交互式语义解析器，这种方法代价高昂且不可扩展。在本研究中，我们提出了一个新任务，即模拟自然语言反馈以用于交互式语义解析。我们配合该任务使用了一个新的反馈评估器。该评估器专门设计用于评估模拟反馈的质量，基于此我们可以决定最佳的反馈模拟器。在一个文本到SQL的数据集上，我们展示了我们的反馈模拟器可以生成高质量的自然语言反馈以增强特定解析器的错误纠正能力。在低数据情况下，我们的反馈模拟器可以帮助达到与使用代价高昂的完整人工注释反馈数据训练所获得的相当的错误纠正性能。

    Interactive semantic parsing based on natural language (NL) feedback, where users provide feedback to correct the parser mistakes, has emerged as a more practical scenario than the traditional one-shot semantic parsing. However, prior work has heavily relied on human-annotated feedback data to train the interactive semantic parser, which is prohibitively expensive and not scalable. In this work, we propose a new task of simulating NL feedback for interactive semantic parsing. We accompany the task with a novel feedback evaluator. The evaluator is specifically designed to assess the quality of the simulated feedback, based on which we decide the best feedback simulator from our proposed variants. On a text-to-SQL dataset, we show that our feedback simulator can generate high-quality NL feedback to boost the error correction ability of a specific parser. In low-data settings, our feedback simulator can help achieve comparable error correction performance as trained using the costly, full
    
[^5]: CroSentiNews 2.0: 一份句子级新闻情感语料库

    CroSentiNews 2.0: A Sentence-Level News Sentiment Corpus. (arXiv:2305.08187v1 [cs.CL])

    [http://arxiv.org/abs/2305.08187](http://arxiv.org/abs/2305.08187)

    CroSentiNews 2.0 是一个句子级新闻情感语料库，包含14.5K条已标注的新闻句子，标记有5类情感，并提供了基准分数和注释者一致性。

    

    本文介绍了一个针对克罗地亚新闻领域的句子级情感数据集。除了已有的 3 千条已标注文本外，我们的数据集还包括了 14.5 千个注释的句子出现，标记有 5 类情感。我们提供了基准分数，并介绍了注释过程和注释者之间的一致性。

    This article presents a sentence-level sentiment dataset for the Croatian news domain. In addition to the 3K annotated texts already present, our dataset contains 14.5K annotated sentence occurrences that have been tagged with 5 classes. We provide baseline scores in addition to the annotation process and inter-annotator agreement.
    
[^6]: 克罗地亚电影评论数据集（Cro-FiReDa）：一份注释了情感极性的电影评论数据集

    Croatian Film Review Dataset (Cro-FiReDa): A Sentiment Annotated Dataset of Film Reviews. (arXiv:2305.08173v1 [cs.CL])

    [http://arxiv.org/abs/2305.08173](http://arxiv.org/abs/2305.08173)

    介绍了一份注释了情感极性的克罗地亚电影评论数据集，并提供了基于变压器微调方法的基准结果。

    

    本文介绍了Cro-FiReDa，一个在电影评论领域中对克罗地亚语进行情感极性注释的数据集。该数据集包含超过10,000个句子，并在句子级别上进行了注释。除了介绍整个注释过程外，我们还基于变压器微调方法提供了基准结果。

    This paper introduces Cro-FiReDa, a sentiment- annotated dataset for Croatian in the domain of movie reviews. The dataset, which contains over 10,000 sentences, has been annotated at the sentence level. In addition to presenting the overall annotation process, we also present benchmark results based on the transformer- based fine-tuning approach
    
[^7]: STORYWARS: 一个协作故事理解和生成的数据集和指令调整基线

    STORYWARS: A Dataset and Instruction Tuning Baselines for Collaborative Story Understanding and Generation. (arXiv:2305.08152v1 [cs.CL])

    [http://arxiv.org/abs/2305.08152](http://arxiv.org/abs/2305.08152)

    该论文提出了一个名为STORYWARS的新数据集，可以用于协作故事理解和生成任务。作者通过指令调整的方式建立了 INSTRUCTSTORY 模型，成功地在全监督、少样本和零样本场景下处理故事任务。

    

    协作故事是由多名不同写作风格和意图的作者共同创作的文本，对自然语言处理模型提出了独特的挑战。由于缺乏开放领域语料库，理解和生成此类故事仍然是一个较少涉足的领域。为了解决这个问题，我们引入了 STORYWARS，这是一个由在线平台上的9,400多位不同作者撰写的超过40,000个协作故事的新数据集。我们在 STORYWARS 上设计了12种任务类型，包括7种理解和5种生成任务类型，总共推导出101种多样的故事相关任务作为覆盖所有全监督、少样本和零样本场景的多任务基准测试。此外，我们提出了我们的指令调整模型 INSTRUCTSTORY，用于展示处理故事任务，当在零样本和少样本场景下取得卓越结果时，指令调整不仅能够在全监督任务中获得最佳性能，还可以建立强大的多任务基线。

    Collaborative stories, which are texts created through the collaborative efforts of multiple authors with different writing styles and intentions, pose unique challenges for NLP models. Understanding and generating such stories remains an underexplored area due to the lack of open-domain corpora. To address this, we introduce STORYWARS, a new dataset of over 40,000 collaborative stories written by 9,400 different authors from an online platform. We design 12 task types, comprising 7 understanding and 5 generation task types, on STORYWARS, deriving 101 diverse story-related tasks in total as a multi-task benchmark covering all fully-supervised, few-shot, and zero-shot scenarios. Furthermore, we present our instruction-tuned model, INSTRUCTSTORY, for the story tasks showing that instruction tuning, in addition to achieving superior results in zero-shot and few-shot scenarios, can also obtain the best performance on the fully-supervised tasks in STORYWARS, establishing strong multi-task b
    
[^8]: ParaLS：基于预训练释义生成器的词汇替换

    ParaLS: Lexical Substitution via Pretrained Paraphraser. (arXiv:2305.08146v1 [cs.CL])

    [http://arxiv.org/abs/2305.08146](http://arxiv.org/abs/2305.08146)

    本研究提出了一种词汇替换方法，使用释义生成器生成替代词候选项，并提出两种解码策略，实验结果表明优于基于预训练语言模型的最新方法。

    

    词汇替换 (LS) 旨在找到句子中目标词的适当替代词。最近，基于预训练语言模型的 LS 方法取得了显著进展，通过分析目标词周围的语境生成潜在的替代词。然而，这些方法在生成替代词时往往忽视了句子含义的保留。本研究探讨了如何从释义生成器中生成替代词候选项，因为释义生成器生成的释义包含了词汇选择的变化并保留了句子的含义。由于我们无法直接通过常用的解码策略生成替代词，因此提出了两种简单的解码策略，专注于解码过程中目标词的变化。实验结果表明，我们的方法在三个基准测试中优于基于预训练语言模型的 LS 最新方法。

    Lexical substitution (LS) aims at finding appropriate substitutes for a target word in a sentence. Recently, LS methods based on pretrained language models have made remarkable progress, generating potential substitutes for a target word through analysis of its contextual surroundings. However, these methods tend to overlook the preservation of the sentence's meaning when generating the substitutes. This study explores how to generate the substitute candidates from a paraphraser, as the generated paraphrases from a paraphraser contain variations in word choice and preserve the sentence's meaning. Since we cannot directly generate the substitutes via commonly used decoding strategies, we propose two simple decoding strategies that focus on the variations of the target word during decoding. Experimental results show that our methods outperform state-of-the-art LS methods based on pre-trained language models on three benchmarks.
    
[^9]: 区分先于回答：生成对比解释作为常识问答的知识

    Distinguish Before Answer: Generating Contrastive Explanation as Knowledge for Commonsense Question Answering. (arXiv:2305.08135v1 [cs.CL])

    [http://arxiv.org/abs/2305.08135](http://arxiv.org/abs/2305.08135)

    提出了一种基于概念中心提示的对比解释生成模型CPACE，旨在将获得的符号知识转化为对比解释，用于更好地区分常识问答中的差异。

    

    现有的知识增强方法通过从不同的知识库获取不同的知识，在某些问答任务中取得了显著的成果。然而，受到检索知识的特性限制，它们仍然难以同时从知识相关性和区分性方面受益。为了解决这个挑战，我们提出了CPACE，一种基于概念中心提示的对比解释生成模型，旨在将获得的符号知识转化为对比解释，用于更好地区分给定候选者之间的差异。

    Existing knowledge-enhanced methods have achieved remarkable results in certain QA tasks via obtaining diverse knowledge from different knowledge bases. However, limited by the properties of retrieved knowledge, they still have trouble benefiting from both the knowledge relevance and distinguishment simultaneously. To address the challenge, we propose CPACE, a Concept-centric Prompt-bAsed Contrastive Explanation Generation model, which aims to convert obtained symbolic knowledge into a contrastive explanation for better distinguishing the differences among given candidates. Firstly, following previous works, we retrieve different types of symbolic knowledge with a concept-centric knowledge extraction module. After that, we generate corresponding contrastive explanations using acquired symbolic knowledge and explanation prompts as guidance for better modeling the knowledge distinguishment and interpretability. Finally, we regard the generated contrastive explanation as external knowledg
    
[^10]: 自监督神经因子分析解耦语音表示

    Self-supervised Neural Factor Analysis for Disentangling Utterance-level Speech Representations. (arXiv:2305.08099v1 [cs.SD])

    [http://arxiv.org/abs/2305.08099](http://arxiv.org/abs/2305.08099)

    本文提出了一种自监督神经因子分析模型，使用HuBERT中的聚类方法来发现隐藏的声学单元，并使用这些单元对齐SSL模型的特征，从而产生解耦后的语音表示，从而为专门任务提供了一种基于Utterance水平的无监督学习目标。实验结果表明，SSNFA模型在说话人识别、语言识别和情感识别等各种任务中均显著优于现有的SSL模型，并且没有任何特定任务的微调或监督。

    

    自监督学习技术在自动语音识别方面已经展示了出色的性能，在低标注资源情况下证明非常有用，本文针对该技术在说话人、情感和语言识别等任务中的性能问题进行了探究。本文提出了一种因子分析模型，使用HuBERT中的聚类方法来发现隐藏的声学单元，并使用这些单元对齐SSL模型的特征，从而产生解耦后的语音表示，从而为专门任务提供了一种基于Utterance水平的无监督学习目标。实验结果表明，SSNFA模型在说话人识别、语言识别和情感识别等各种任务中均显著优于现有的SSL模型，并且没有任何特定任务的微调或监督。

    Self-supervised learning (SSL) speech models such as wav2vec and HuBERT have demonstrated state-of-the-art performance on automatic speech recognition (ASR) and proved to be extremely useful in low label-resource settings. However, the success of SSL models has yet to transfer to utterance-level tasks such as speaker, emotion, and language recognition, which still require supervised fine-tuning of the SSL models to obtain good performance. We argue that the problem is caused by the lack of disentangled representations and an utterance-level learning objective for these tasks. Inspired by how HuBERT uses clustering to discover hidden acoustic units, we formulate a factor analysis (FA) model that uses the discovered hidden acoustic units to align the SSL features. The underlying utterance-level representations are disentangled from the content of speech using probabilistic inference on the aligned features. Furthermore, the variational lower bound derived from the FA model provides an ut
    
[^11]: 探究和改进神经机器翻译中知识蒸馏

    Towards Understanding and Improving Knowledge Distillation for Neural Machine Translation. (arXiv:2305.08096v1 [cs.CL])

    [http://arxiv.org/abs/2305.08096](http://arxiv.org/abs/2305.08096)

    本文揭示了神经机器翻译中知识蒸馏的本质，即来自于教师模型的top-1预测。同时，指出了当前基于词级别的知识蒸馏存在的问题，并提出了一种新方法——Top-1 Information。

    

    知识蒸馏在神经机器翻译领域中是一种有前途的模型压缩技术。然而，知识在哪里隐藏的问题仍不清楚，这可能会阻碍知识蒸馏的发展。在本研究中，我们首先从实证角度揭开了这个谜团，并展示了知识来自教师的top-1预测，这也帮助我们建立了词级和序列级蒸馏之间的潜在连接。此外，我们基于这一发现指出了基础词级蒸馏中存在的两个问题。首先，知识的当前目标是将注意力扩散到整个分布上学习知识，但缺乏对最关键的top-1信息的特殊处理。其次，由于大多数教师的top-1预测与地面实况标记重叠，因此知识被黄金信息所占据，进一步限制了知识蒸馏的潜力。为解决这些问题，我们提出了一种名为\textbf{T}op-1 \textbf{I}nformation的新方法。

    Knowledge distillation (KD) is a promising technique for model compression in neural machine translation. However, where the knowledge hides in KD is still not clear, which may hinder the development of KD. In this work, we first unravel this mystery from an empirical perspective and show that the knowledge comes from the top-1 predictions of teachers, which also helps us build a potential connection between word- and sequence-level KD. Further, we point out two inherent issues in vanilla word-level KD based on this finding. Firstly, the current objective of KD spreads its focus to whole distributions to learn the knowledge, yet lacks special treatment on the most crucial top-1 information. Secondly, the knowledge is largely covered by the golden information due to the fact that most top-1 predictions of teachers overlap with ground-truth tokens, which further restricts the potential of KD. To address these issues, we propose a novel method named \textbf{T}op-1 \textbf{I}nformation \te
    
[^12]: 使基于提示的黑盒调优更加丰富多彩：从三个正交角度提高模型泛化能力

    Make Prompt-based Black-Box Tuning Colorful: Boosting Model Generalization from Three Orthogonal Perspectives. (arXiv:2305.08088v1 [cs.CL])

    [http://arxiv.org/abs/2305.08088](http://arxiv.org/abs/2305.08088)

    本文提出了BBT-RGB，一套用于增强黑盒优化效率和性能的直接且互补技术套件，包括两阶段无导数优化策略、自动语言转化器构建及其在少样本设置中的新用法以及更好的提示初始化。

    

    大型语言模型在各种自然语言处理任务中已经展现出越来越强大的能力。然而，调整这些模型以用于下游任务通常需要巨额的代价或由于商业考虑而不可用。最近，提出了黑盒调优来解决这个问题，通过优化任务特定的提示而不访问梯度和隐藏表示。然而，大多数现有的作品还没有充分利用少样本学习场景下无梯度优化的潜力。在本文中，我们描述了BBT-RGB，这是一个用于增强黑盒优化效率和性能的直接且互补技术套件。具体来说，我们的方法包括三个即插即用的组件：（1）两阶段无导数优化策略，有助于快速收敛并缓解过拟合；（2）自动语言转化器构建及其在少样本设置中的新用法；（3）更好的提示初始化，基于未标记数据的语言学动机句法模式。

    Large language models (LLMs) have shown increasing power on various natural language processing (NLP) tasks. However, tuning these models for downstream tasks usually needs exorbitant costs or is unavailable due to commercial considerations. Recently, black-box tuning has been proposed to address this problem by optimizing task-specific prompts without accessing the gradients and hidden representations. However, most existing works have yet fully exploited the potential of gradient-free optimization under the scenario of few-shot learning. In this paper, we describe BBT-RGB, a suite of straightforward and complementary techniques for enhancing the efficiency and performance of black-box optimization. Specifically, our method includes three plug-and-play components: (1) Two-stage derivative-free optimization strategy that facilitates fast convergence and mitigates overfitting; (2) Automatic verbalizer construction with its novel usage under few-shot settings; (3) Better prompt initializ
    
[^13]: 利用韵律关注和蒸馏来提高端到端语义理解性能

    Improving End-to-End SLU performance with Prosodic Attention and Distillation. (arXiv:2305.08067v1 [cs.CL])

    [http://arxiv.org/abs/2305.08067](http://arxiv.org/abs/2305.08067)

    本文提出了韵律关注和韵律蒸馏方法来利用韵律特征提高端到端语义理解（SLU）的性能，其中韵律蒸馏方法相对于基线方法在SLURP和STOP数据集上提高了8％和2％的意图分类准确性。

    

    大多数端到端语义理解（SLU）方法依赖于预训练的自动语音识别或语言模型功能来进行意图预测。然而，语音中的其他重要信息，如韵律，经常被忽视。最近的研究表明，将韵律信息合并到对话行为分类中可以获得改进的结果。本文提出了韵律关注，它使用不同的方式利用韵律特征来生成跨时间帧的注意力图。然后，我们提出了韵律蒸馏，来明确地学习声学编码器中的韵律信息，而不是连接隐含的韵律特征。两种方法都提高了基线结果，其中韵律蒸馏方法在SLURP和STOP数据集上相对于韵律基线提高了8％和2％的意图分类准确性。

    Most End-to-End SLU methods depend on the pretrained ASR or language model features for intent prediction. However, other essential information in speech, such as prosody, is often ignored. Recent research has shown improved results in classifying dialogue acts by incorporating prosodic information. The margins of improvement in these methods are minimal as the neural models ignore prosodic features. In this work, we propose prosody-attention, which uses the prosodic features differently to generate attention maps across time frames of the utterance. Then we propose prosody-distillation to explicitly learn the prosodic information in the acoustic encoder rather than concatenating the implicit prosodic features. Both the proposed methods improve the baseline results, and the prosody-distillation method gives an intent classification accuracy improvement of 8\% and 2\% on SLURP and STOP datasets over the prosody baseline.
    
[^14]: 事件级视频问答的语义感知动态回顾-前瞻推理

    Semantic-aware Dynamic Retrospective-Prospective Reasoning for Event-level Video Question Answering. (arXiv:2305.08059v1 [cs.CV])

    [http://arxiv.org/abs/2305.08059](http://arxiv.org/abs/2305.08059)

    本文提出了一种用于视频问答的语义感知动态回顾-前瞻推理方法，通过明确使用问题的语义角色标注（SRL）结构，根据问题SRL结构的哪一部分被关注来促进跨视频帧的复杂推理，实验结果显示性能优越。

    

    事件级视频问答需要跨越视频事件进行复杂推理，以获取提供最佳答案所需的视觉信息。然而，尽管模型性能取得了显著进展，但很少有研究关注在事件层面上使用问题和视觉信息之间的显式语义联系。有必要利用这种语义联系，促进跨视频帧的复杂推理。因此，我们提出了一种面向视频问答的语义感知动态回顾-前瞻推理方法。具体来说，我们在动态推理过程中明确使用问题的语义角色标注（SRL）结构，根据问题SRL结构的哪一部分（agent、verb、patient等）被关注来决定是否移动到下一帧。我们在基准EVQA数据集——TrafficQA上进行了实验。结果表明，我们提出的方法取得了卓越的性能。

    Event-Level Video Question Answering (EVQA) requires complex reasoning across video events to obtain the visual information needed to provide optimal answers. However, despite significant progress in model performance, few studies have focused on using the explicit semantic connections between the question and visual information especially at the event level. There is need for using such semantic connections to facilitate complex reasoning across video frames. Therefore, we propose a semantic-aware dynamic retrospective-prospective reasoning approach for video-based question answering. Specifically, we explicitly use the Semantic Role Labeling (SRL) structure of the question in the dynamic reasoning process where we decide to move to the next frame based on which part of the SRL structure (agent, verb, patient, etc.) of the question is being focused on. We conduct experiments on a benchmark EVQA dataset - TrafficQA. Results show that our proposed approach achieves superior performance 
    
[^15]: ProKnow：用于安全限制和可解释问题生成的流程知识在心理健康诊断辅助中的应用

    ProKnow: Process Knowledge for Safety Constrained and Explainable Question Generation for Mental Health Diagnostic Assistance. (arXiv:2305.08010v1 [cs.CL])

    [http://arxiv.org/abs/2305.08010](http://arxiv.org/abs/2305.08010)

    本论文提出了ProKnow的概念，它可以提高虚拟心理健康助手的安全性和专业性。同时开发了自然语言问题生成算法，通过明确建模安全性、知识捕获和可解释性来模拟流程知识。在抑郁症和焦虑症中的实验表明，使用ProKnow引导的算法可以生成更安全的问题。

    

    目前的虚拟心理健康助手（VMHA）提供辅导和建议护理。它们不进行患者诊断协助，因为它们缺乏安全受限和专业临床流程知识的培训。 在这项工作中，我们定义Proknow为一组有序信息，它映射到领域专家的基于证据的指南或概念理解类别。我们还介绍了一种由安全限制和Proknow引导的诊断对话的新数据集，这是医疗保健专业人员使用的。我们开发了一种自然语言问题生成（NLG）方法，可以与患者交互收集诊断信息。我们证明了在此数据集上使用最先进的大规模语言模型（LM）的局限性。我们的算法通过明确地建模安全性，知识捕获和可解释性来模拟流程知识。使用ProKnow引导的LM增强方法在抑郁症和焦虑症中生成了89％更安全的问题。

    Current Virtual Mental Health Assistants (VMHAs) provide counseling and suggestive care. They refrain from patient diagnostic assistance because they lack training in safety-constrained and specialized clinical process knowledge. In this work, we define Proknow as an ordered set of information that maps to evidence-based guidelines or categories of conceptual understanding to experts in a domain. We also introduce a new dataset of diagnostic conversations guided by safety constraints and Proknow that healthcare professionals use. We develop a method for natural language question generation (NLG) that collects diagnostic information from the patient interactively. We demonstrate the limitations of using state-of-the-art large-scale language models (LMs) on this dataset. Our algorithm models the process knowledge through explicitly modeling safety, knowledge capture, and explainability. LMs augmented with ProKnow guided method generated 89% safer questions in the depression and anxiety d
    
[^16]: 超越保障：探索ChatGPT的安全风险

    Beyond the Safeguards: Exploring the Security Risks of ChatGPT. (arXiv:2305.08005v1 [cs.CR])

    [http://arxiv.org/abs/2305.08005](http://arxiv.org/abs/2305.08005)

    本文探讨了ChatGPT的多种安全风险和绕过保护措施的潜在方法，发现即使保护措施存在，LLMs仍存在伦理和安全风险。本研究为减轻这些风险提供了潜在策略。

    

    越来越多的人开始关注大型语言模型（LLMs）如ChatGPT的安全性、安全风险和伦理影响。本文旨在提供有关ChatGPT相关的不同类型安全风险的概述，包括恶意文本和代码生成、私人数据披露、欺诈性服务、信息搜集和生成不道德内容等。我们进行了实证研究，检查了ChatGPT内容过滤器的有效性，并探讨了绕过这些保护的潜在方法，展示了当保护措施存在时LLMs中仍存在的伦理和安全风险。根据安全风险的定性分析，我们讨论了减轻这些风险的潜在策略，并向研究人员、政策制定者和行业专业人员介绍了像ChatGPT这样的LLMs所面临的复杂安全挑战。本研究有助于对LLMs带来的伦理和安全问题进行持续的讨论。

    The increasing popularity of large language models (LLMs) such as ChatGPT has led to growing concerns about their safety, security risks, and ethical implications. This paper aims to provide an overview of the different types of security risks associated with ChatGPT, including malicious text and code generation, private data disclosure, fraudulent services, information gathering, and producing unethical content. We present an empirical study examining the effectiveness of ChatGPT's content filters and explore potential ways to bypass these safeguards, demonstrating the ethical implications and security risks that persist in LLMs even when protections are in place. Based on a qualitative analysis of the security implications, we discuss potential strategies to mitigate these risks and inform researchers, policymakers, and industry professionals about the complex security challenges posed by LLMs like ChatGPT. This study contributes to the ongoing discussion on the ethical and security 
    
[^17]: 多语种先前事实核查索引

    Multilingual Previously Fact-Checked Claim Retrieval. (arXiv:2305.07991v1 [cs.CL])

    [http://arxiv.org/abs/2305.07991](http://arxiv.org/abs/2305.07991)

    本文介绍了一个新的多语种数据集MultiClaim，用于先前事实核查的检索，通过不同的无监督方法及一个经过监督微调的方法对其进行了评估。

    

    事实核查员常常受到需要进行核查的在线内容数量的限制。NLP可以通过检索与正在调查的内容相关的已存在的事实核查来帮助他们。本文介绍了一个新的多语种数据集MultiClaim——用于先前事实核查检索。我们收集了来自社交媒体的27种语言的28k篇文章、39种语言的206k篇由专业事实核查员撰写的事实核查以及这两个组之间的31k个连接。这是迄今为止最广泛、语言多元化的数据集。我们评估了不同的无监督方法在这个数据集及其各自的维度上的表现。我们展示了评估这样一个多样化的数据集的复杂性，并且在解释结果之前需要采取适当的措施。我们还评估了一种经过监督微调的方法，在这个方法上得到了显著的改进。

    Fact-checkers are often hampered by the sheer amount of online content that needs to be fact-checked. NLP can help them by retrieving already existing fact-checks relevant to the content being investigated. This paper introduces a new multilingual dataset -- MultiClaim -- for previously fact-checked claim retrieval. We collected 28k posts in 27 languages from social media, 206k fact-checks in 39 languages written by professional fact-checkers, as well as 31k connections between these two groups. This is the most extensive and the most linguistically diverse dataset of this kind to date. We evaluated how different unsupervised methods fare on this dataset and its various dimensions. We show that evaluating such a diverse dataset has its complexities and proper care needs to be taken before interpreting the results. We also evaluated a supervised fine-tuning approach, improving upon the unsupervised method significantly.
    
[^18]: 自监督的句子压缩用于会议摘要

    Self-Supervised Sentence Compression for Meeting Summarization. (arXiv:2305.07988v1 [cs.CL])

    [http://arxiv.org/abs/2305.07988](http://arxiv.org/abs/2305.07988)

    本论文提出了一种自监督学习的会议摘要框架SVB，通过三个过程压缩冗余内容并保留关键信息。其中，滑动窗口对话恢复与评分、通道重要性得分投票和相对位置分箱等算法用于实现这个框架。

    

    传统总结模型往往无法捕捉到会议记录中的关键信息，因为会议语料库通常涉及多个参与者的冗长对话并充斥着冗余和琐碎的内容。为了解决这个问题，我们提出了SVB，一个有效且高效的会议摘要框架，通过三个过程“压缩”冗余而保留重要内容：滑动窗口对话恢复与评分、通道重要性得分投票和相对位置分箱。具体来说，在自监督范式下，滑动窗口评分旨在从多个视角评估每个标记的重要性。然后通过通道投票聚合这些评分。具有高评分的标记将被视为显着信息并标记为“anchers”。最后，为了使输入长度适合语言模型的长度限制，采用了相对位置分箱算法。

    The conventional summarization model often fails to capture critical information in meeting transcripts, as meeting corpus usually involves multiple parties with lengthy conversations and is stuffed with redundant and trivial content. To tackle this problem, we present SVB, an effective and efficient framework for meeting summarization that `compress' the redundancy while preserving important content via three processes: sliding-window dialogue restoration and \textbf{S}coring, channel-wise importance score \textbf{V}oting, and relative positional \textbf{B}ucketing. Specifically, under the self-supervised paradigm, the sliding-window scoring aims to rate the importance of each token from multiple views. Then these ratings are aggregated by channel-wise voting. Tokens with high ratings will be regarded as salient information and labeled as \textit{anchors}. Finally, to tailor the lengthy input to an acceptable length for the language model, the relative positional bucketing algorithm i
    
[^19]: 零样本信实事实纠错

    Zero-shot Faithful Factual Error Correction. (arXiv:2305.07982v1 [cs.CL])

    [http://arxiv.org/abs/2305.07982](http://arxiv.org/abs/2305.07982)

    零样本的忠实事实性错误纠正框架超越完全监督方法，具有较高的及解释性和忠实性评估标准，适用于维护文本知识库和预防序列到序列模型中的幻觉。

    

    忠实地纠正事实性错误对于维护文本知识库的完整性和防止序列到序列模型中的幻觉至关重要。借鉴人类识别和纠正事实错误的能力，我们提出了一个零样本框架，该框架制定有关输入声明的问题，查找给定证据中的正确答案，并根据其与证据的一致性评估每个纠正的信实性。我们的零样本框架在FEVER和SciFact数据集上进行的实验中比完全监督的方法表现更好，证明了我们的输出更加忠实。更重要的是，我们框架的可分解性天然提供了可解释性。此外，为了揭示评估事实错误修正的最合适度量标准，我们分析了常用度量标准与三个不同维度的人类判断之间的相关性，包括可理解性和忠实性。

    Faithfully correcting factual errors is critical for maintaining the integrity of textual knowledge bases and preventing hallucinations in sequence-to-sequence models. Drawing on humans' ability to identify and correct factual errors, we present a zero-shot framework that formulates questions about input claims, looks for correct answers in the given evidence, and assesses the faithfulness of each correction based on its consistency with the evidence. Our zero-shot framework outperforms fully-supervised approaches, as demonstrated by experiments on the FEVER and SciFact datasets, where our outputs are shown to be more faithful. More importantly, the decomposability nature of our framework inherently provides interpretability. Additionally, to reveal the most suitable metrics for evaluating factual error corrections, we analyze the correlation between commonly used metrics with human judgments in terms of three different dimensions regarding intelligibility and faithfulness.
    
[^20]: 千亿美元的话语：一个新的金融数据集，任务和市场分析

    Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis. (arXiv:2305.07972v1 [cs.CL])

    [http://arxiv.org/abs/2305.07972](http://arxiv.org/abs/2305.07972)

    本文介绍了一个新的金融数据集，并开展了一项新的“鹰派-鸽派”分类任务。我们使用RoBERTa-large模型构建了FOMC文件发布日的货币政策立场指数，并对其对国库市场、股票市场和宏观经济指标的影响进行了研究。

    

    联邦公开市场委员会（FOMC）的货币政策声明是金融市场回报的主要驱动因素。为了更好地了解货币政策如何影响金融市场，我们构建了FOMC演讲、会议记录和新闻发布会记录的最大化文本标注数据集。在本研究中，我们开发了一项新的任务 - “鹰派-鸽派”分类，并在提议的数据集上对各种预训练语言模型进行基准测试。使用效果最好的模型（RoBERTa-large），我们构建了FOMC文件发布日的货币政策立场指数。为了评估构建的指数，我们研究了它对国库市场、股票市场和宏观经济指标的影响。我们的数据集、模型和代码在Huggingface和GitHub上以CC BY-NC 4.0许可证公开提供。

    Monetary policy pronouncements by Federal Open Market Committee (FOMC) are a major driver of financial market returns. We construct the largest tokenized and annotated dataset of FOMC speeches, meeting minutes, and press conference transcripts in order to understand how monetary policy influences financial markets. In this study, we develop a novel task of hawkish-dovish classification and benchmark various pre-trained language models on the proposed dataset. Using the best-performing model (RoBERTa-large), we construct a measure of monetary policy stance for the FOMC document release days. To evaluate the constructed measure, we study its impact on the treasury market, stock market, and macroeconomic indicators. Our dataset, models, and code are publicly available on Huggingface and GitHub under CC BY-NC 4.0 license.
    
[^21]: GPT-Sentinel：区分人类和ChatGPT生成内容的方法

    GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content. (arXiv:2305.07969v1 [cs.CL])

    [http://arxiv.org/abs/2305.07969](http://arxiv.org/abs/2305.07969)

    GPT-Sentinel通过语言模型检测ChatGPT生成的文本和人类编写的文本，其模型在测试数据集上准确率超过了97％，并且揭示了区分这两种文本关键特征的能力。

    

    本文提出了一种使用语言模型来检测ChatGPT生成的文本与人类编写文本的新方法。我们首先收集和发布了一个预处理数据集OpenGPTText，其中包含使用ChatGPT生成的重新表述内容。然后，我们设计、实现、训练了两个不同的文本分类模型，分别使用Robustly Optimized BERT Pretraining Approach（RoBERTa）和Text-to-Text Transfer Transformer（T5）。我们的模型在测试数据集上取得了显著的结果，通过各种指标进行评估，准确率超过了97%。此外，我们进行了可解释性研究，展示了我们的模型提取和区分人类编写和ChatGPT生成文本之间关键特征的能力。我们的发现为使用语言模型检测生成文本提供了重要的见解。

    This paper presents a novel approach for detecting ChatGPT-generated vs. human-written text using language models. To this end, we first collected and released a pre-processed dataset named OpenGPTText, which consists of rephrased content generated using ChatGPT. We then designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively. Our models achieved remarkable results, with an accuracy of over 97% on the test dataset, as evaluated through various metrics. Furthermore, we conducted an interpretability study to showcase our model's ability to extract and differentiate key features between human-written and ChatGPT-generated text. Our findings provide important insights into the effective use of language models to detect generated text.
    
[^22]: 在对话推荐系统中利用大型语言模型

    Leveraging Large Language Models in Conversational Recommender Systems. (arXiv:2305.07961v1 [cs.IR])

    [http://arxiv.org/abs/2305.07961](http://arxiv.org/abs/2305.07961)

    本文提出了一种使用大型语言模型构建端到端大规模对话推荐系统的路线图，解决在该系统中有效利用大型语言模型所面临的技术挑战。

    

    对话推荐系统通过启用实时的多轮对话使用户更加透明和掌控。最近，大型语言模型展现了与人类对话自然的能力，并将世界知识和常识推理融入到语言理解中，进一步释放了这一范式的潜力。然而，在对话推荐系统中有效利用大型语言模型引入了新的技术挑战，包括适当地理解和控制复杂的对话和从外部信息源检索。由于大而不断增长的项目语料库和缺乏对话数据进行训练，这些问题加剧了。在本文中，我们提供了使用大型语言模型构建端到端大规模对话推荐系统的路线图。特别地，我们提出了用户偏好理解、灵活的对话管理和可解释的推荐作为整个系统的一部分的新实现方式。

    A Conversational Recommender System (CRS) offers increased transparency and control to users by enabling them to engage with the system through a real-time multi-turn dialogue. Recently, Large Language Models (LLMs) have exhibited an unprecedented ability to converse naturally and incorporate world knowledge and common-sense reasoning into language understanding, unlocking the potential of this paradigm. However, effectively leveraging LLMs within a CRS introduces new technical challenges, including properly understanding and controlling a complex conversation and retrieving from external sources of information. These issues are exacerbated by a large, evolving item corpus and a lack of conversational data for training. In this paper, we provide a roadmap for building an end-to-end large-scale CRS using LLMs. In particular, we propose new implementations for user preference understanding, flexible dialogue management and explainable recommendations as part of an integrated architecture
    
[^23]: AMTSS：一种适用于多语言语言推理的自适应多教师单学生知识蒸馏框架

    AMTSS: An Adaptive Multi-Teacher Single-Student Knowledge Distillation Framework For Multilingual Language Inference. (arXiv:2305.07928v1 [cs.CL])

    [http://arxiv.org/abs/2305.07928](http://arxiv.org/abs/2305.07928)

    AMTSS是一种自适应多教师单学生知识蒸馏框架，可以在多语言设置下支持成本效益的语言推理，并取得了在XNLI数据集和AliExpress中竞争性的结果。

    

    知识蒸馏对于推出多语言预训练语言模型的实际应用至关重要。为支持多语言设置下的成本效益的语言推理，我们提出了AMTSS，一种自适应多教师单学生蒸馏框架，它允许从多个老师中提炼知识到一个学生中。我们首先引入一种自适应学习策略和教师重要性权重，使学生能够有效地从最大边缘老师中学习，并轻松适应新语言。此外，我们提出了一个共享的学生编码器，以不同的投影层支持多种语言，这有助于大大降低开发和机器成本。实验结果显示，AMTSS在公共XNLI数据集和真实的电子商务行业数据集AliExpress（AE）中获得了竞争性的结果。

    Knowledge distillation is of key importance to launching multilingual pre-trained language models for real applications. To support cost-effective language inference in multilingual settings, we propose AMTSS, an adaptive multi-teacher single-student distillation framework, which allows distilling knowledge from multiple teachers to a single student. We first introduce an adaptive learning strategy and teacher importance weight, which enables a student to effectively learn from max-margin teachers and easily adapt to new languages. Moreover, we present a shared student encoder with different projection layers in support of multiple languages, which contributes to largely reducing development and machine cost. Experimental results show that AMTSS gains competitive results on the public XNLI dataset and the realistic industrial dataset AliExpress (AE) in the E-commerce scenario.
    
[^24]: RC3: 规则化对比跨语言跨模态预训练

    RC3: Regularized Contrastive Cross-lingual Cross-modal Pre-training. (arXiv:2305.07927v1 [cs.CL])

    [http://arxiv.org/abs/2305.07927](http://arxiv.org/abs/2305.07927)

    本文提出了RC3预训练方法，通过规则化对比跨语言跨模态学习，有效利用弱对准的多语种图像-文本对，从而在多语种V&L任务中取得了更好的性能。

    

    多语种视觉-语言（V&L）预训练已经在跨不同语言和模态中实现了显著进展。尽管最近取得了成功，但仍存在挑战限制了V&L预训练模型在多语种环境中的进一步改进。本文提出规则化对比跨语言跨模态（RC^3）预训练，进一步利用更丰富的弱对准多语种图像-文本对。具体来说，设计一种规则化的跨语言视觉-文本对比学习目标，根据文本相关性约束弱对准视觉-文本输入的表示接近度。此外，现有的V&L预训练方法大多依赖于英语为中心的数据集，但收集和翻译严格对齐的多语种图像-文本对的成本通常是难以承受的。

    Multilingual vision-language (V&L) pre-training has achieved remarkable progress in learning universal representations across different modalities and languages. In spite of recent success, there still remain challenges limiting further improvements of V&L pre-trained models in multilingual settings. Particularly, current V&L pre-training methods rely heavily on strictly-aligned multilingual image-text pairs generated from English-centric datasets through machine translation. However, the cost of collecting and translating such strictly-aligned datasets is usually unbearable. In this paper, we propose Regularized Contrastive Cross-lingual Cross-modal (RC^3) pre-training, which further exploits more abundant weakly-aligned multilingual image-text pairs. Specifically, we design a regularized cross-lingual visio-textual contrastive learning objective that constrains the representation proximity of weakly-aligned visio-textual inputs according to textual relevance. Besides, existing V&L pr
    
[^25]: CodeT5+: 用于代码理解和生成的开放代码大型语言模型

    CodeT5+: Open Code Large Language Models for Code Understanding and Generation. (arXiv:2305.07922v1 [cs.CL])

    [http://arxiv.org/abs/2305.07922](http://arxiv.org/abs/2305.07922)

    CodeT5+是一组灵活组合的编码器-解码器LLM族，用于代码，混合了多种不同的预训练目标，包括代码生成、自然语言处理和程序合成，可以适应多种不同的下游代码任务，并且在实验中比现有代码-specific LLMs实现了最先进的性能。

    

    预训练在大量源代码上的大型语言模型(LLMs)在代码智能方面取得了显著进展。然而，现有的代码LLM在架构和预训练任务方面有两个主要限制。首先，它们通常采用特定的架构(仅编码器或仅解码器)或依赖于不同下游任务的统一编码器-解码器网络。前一种范式受到应用灵活性的限制，而在后一种范式中，模型被视为所有任务的单一系统，导致在某些任务的子集上性能不优。其次，它们通常采用有限的预训练目标，这些目标可能与某些下游任务不相关，因此会导致性能显著下降。为了解决这些限制，我们提出了“CodeT5+”，这是一组编码器-解码器LLM族，用于代码，其中组件模块可以灵活组合以适应各种下游代码任务。这种灵活性是通过我们提出的混合预训练目标实现的，包括代码生成，自然语言处理和程序合成。我们在几个与代码相关的下游任务上进行了广泛实验，证明CodeT5+相对于现有的代码特定LLM实现了最先进的性能。

    Large language models (LLMs) pretrained on vast source code have achieved prominent progress in code intelligence. However, existing code LLMs have two main limitations in terms of architecture and pretraining tasks. First, they often adopt a specific architecture (encoder-only or decoder-only) or rely on a unified encoder-decoder network for different downstream tasks. The former paradigm is limited by inflexibility in applications while in the latter, the model is treated as a single system for all tasks, leading to suboptimal performance on a subset of tasks. Secondly, they often employ a limited set of pretraining objectives which might not be relevant to some downstream tasks and hence result in substantial performance degrade. To address these limitations, we propose ``CodeT5+'', a family of encoder-decoder LLMs for code in which component modules can be flexibly combined to suit a wide range of downstream code tasks. Such flexibility is enabled by our proposed mixture of pretrai
    
[^26]: 基于提示的预训练语言模型用于时间知识图谱补全

    Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion. (arXiv:2305.07912v1 [cs.CL])

    [http://arxiv.org/abs/2305.07912](http://arxiv.org/abs/2305.07912)

    这篇论文提出了一种基于提示的预训练语言模型（PPT），用于时间知识图谱补全。通过遮盖策略，将TKGC任务转换为遮盖词预测任务，可以利用预训练语言模型中的语义信息。

    

    时间知识图谱补全（TKGC）是一项重要的任务，它涉及在已知的时间戳上进行推理，以完成缺失部分的事实，并在近年来越来越受到关注。大多数现有方法都集中于基于图神经网络的学习表示，同时粗略地提取时间戳中的信息，并不充分利用关系中隐含的信息。为了解决这些问题，我们提出了一种新的TKGC模型，即基于提示的预训练语言模型（PPT）。我们将一系列采样的四元组转换为预训练语言模型的输入，并将时间戳之间的间隔转换为不同的提示，以形成带有隐含语义信息的连贯句子。我们使用遮盖策略训练我们的模型，将TKGC任务转换为遮盖词预测任务，从而可以利用预训练语言模型中的语义信息。实验结果和广泛的分析表明，

    Temporal Knowledge graph completion (TKGC) is a crucial task that involves reasoning at known timestamps to complete the missing part of facts and has attracted more and more attention in recent years. Most existing methods focus on learning representations based on graph neural networks while inaccurately extracting information from timestamps and insufficiently utilizing the implied information in relations. To address these problems, we propose a novel TKGC model, namely Pre-trained Language Model with Prompts for TKGC (PPT). We convert a series of sampled quadruples into pre-trained language model inputs and convert intervals between timestamps into different prompts to make coherent sentences with implicit semantic information. We train our model with a masking strategy to convert TKGC task into a masked token prediction task, which can leverage the semantic information in pre-trained language models. Experiments on three benchmark datasets and extensive analysis demonstrate that 
    
[^27]: 关于大型多模态模型中OCR的隐秘之谜

    On the Hidden Mystery of OCR in Large Multimodal Models. (arXiv:2305.07895v1 [cs.CV])

    [http://arxiv.org/abs/2305.07895](http://arxiv.org/abs/2305.07895)

    本研究全面评估了现有大型多模态模型在文本相关的视觉任务中的表现，结果显示这些模型虽然在语义理解方面表现优异，但对单个字符形状的感知有限，对图像的细粒度特征检测能力也不足，不能与传统领域特定方法相匹配，并仍需进一步探索它们在OCR中的表现。

    

    近来，大型模型在自然语言处理和多模态视觉语言学习中扮演着支配性的角色。关于它们在文本相关的视觉任务中有效性的探索仍不够。我们对现有公开可用的多模态模型进行了全面的研究，评估了它们在文本识别、基于文本的视觉问答和关键信息提取方面的表现。我们的研究结果揭示了这些模型的优劣势，它们主要依赖于语义理解来识别单词，并表现出较差的对单个字符形状的感知。它们对文本长度漠不关心，在检测图像的细粒度特征方面具有有限的能力。因此，这些结果表明，即使当前最强大的大型多模态模型也无法与传统文本任务的领域特定方法相匹配，并在更复杂的任务中面临更大的挑战。最重要的是，本研究展示的基线结果揭示了大型多模态模型中OCR的隐秘之谜，仍需要进一步探索。

    Large models have recently played a dominant role in natural language processing and multimodal vision-language learning. It remains less explored about their efficacy in text-related visual tasks. We conducted a comprehensive study of existing publicly available multimodal models, evaluating their performance in text recognition, text-based visual question answering, and key information extraction. Our findings reveal strengths and weaknesses in these models, which primarily rely on semantic understanding for word recognition and exhibit inferior perception of individual character shapes. They also display indifference towards text length and have limited capabilities in detecting fine-grained features in images. Consequently, these results demonstrate that even the current most powerful large multimodal models cannot match domain-specific methods in traditional text tasks and face greater challenges in more complex tasks. Most importantly, the baseline results showcased in this study
    
[^28]: PESTS: 波斯语-英语跨语言语料库用于语义文本相似度

    PESTS: Persian_English Cross Lingual Corpus for Semantic Textual Similarity. (arXiv:2305.07893v1 [cs.CL])

    [http://arxiv.org/abs/2305.07893](http://arxiv.org/abs/2305.07893)

    本研究提出了跨语言的语义相似性模型PESTS，并通过波斯语-英语的跨语言语料库来验证模型的准确性。

    

    近来，语义文本相似度成为自然语言处理中备受关注的组件。在计算语言学和自然语言处理中，评估单词、短语、段落和文本之间的语义相似性很重要。同时，语义相似性度量要求在源和目标语言中提供具有一定语义相似性的句子对。许多跨语言的语义相似度模型使用机器翻译来弥补跨语言语料库不可用的不足，但机器翻译的误差会降低模型的准确性。然而，在使用语义相似度特征实现机器翻译时，用相同的机器翻译模型可以提高结果的准确性。

    One of the components of natural language processing that has received a lot of investigation recently is semantic textual similarity. In computational linguistics and natural language processing, assessing the semantic similarity of words, phrases, paragraphs, and texts is crucial. Calculating the degree of semantic resemblance between two textual pieces, paragraphs, or phrases provided in both monolingual and cross-lingual versions is known as semantic similarity. Cross lingual semantic similarity requires corpora in which there are sentence pairs in both the source and target languages with a degree of semantic similarity between them. Many existing cross lingual semantic similarity models use a machine translation due to the unavailability of cross lingual semantic similarity dataset, which the propagation of the machine translation error reduces the accuracy of the model. On the other hand, when we want to use semantic similarity features for machine translation the same machine t
    
[^29]: 生成式人工智能和大型语言模型的双重使用问题：实现“受关注的双重使用研究”框架的建议

    Dual Use Concerns of Generative AI and Large Language Models. (arXiv:2305.07882v1 [cs.CY])

    [http://arxiv.org/abs/2305.07882](http://arxiv.org/abs/2305.07882)

    本文建议将双重使用研究框架应用于生成式人工智能和大型语言模型，提出了具体的应用建议，以加强人工智能治理并增强社会对其影响的认识。

    

    我们建议将原本设计用于生命科学领域的“受关注的双重使用研究”（DURC）框架应用于生成式人工智能，具体关注大型语言模型（LLM）。通过在生物研究领域的优势和缺点的证明，我们相信DURC标准可以为LLM重新定义，可能有助于改善人工智能治理。在使用DURC框架时需要权衡的情况下，我们强调其在提高社会对生成式人工智能影响的认识方面的重要政治作用。最后，我们提供一系列具体的建议，以将DURC方法应用于LLM的研究中。

    We suggest the implementation of the Dual Use Research of Concern (DURC) framework, originally designed for life sciences, to the domain of generative AI, with a specific focus on Large Language Models (LLMs). With its demonstrated advantages and drawbacks in biological research, we believe the DURC criteria can be effectively redefined for LLMs, potentially contributing to improved AI governance. Acknowledging the balance that must be struck when employing the DURC framework, we highlight its crucial political role in enhancing societal awareness of the impact of generative AI. As a final point, we offer a series of specific recommendations for applying the DURC approach to LLM research.
    
[^30]: AI技术在历史事实核查中的应用——GPT 3.5、GPT4和GoogleBARD的比较评估

    Bridging History with AI A Comparative Evaluation of GPT 3.5, GPT4, and GoogleBARD in Predictive Accuracy and Fact Checking. (arXiv:2305.07868v1 [cs.CL])

    [http://arxiv.org/abs/2305.07868](http://arxiv.org/abs/2305.07868)

    本研究比较评估了三种大型语言模型的性能，结果表明AI技术在历史事实核查和填补空白方面有着巨大的潜力，其中GPT 4表现最为优异，这说明需要进一步探索AI技术在历史研究中的应用，以便丰富我们对过去的理解和弥合历史知识差距。

    

    数字时代信息的迅速扩散凸显了准确的历史记录和解释的重要性。虽然人工智能已在各个领域展示出了潜力，但其在历史事实核查和填补空白方面的潜力仍然不为人知。本研究评估了三种大型语言模型LLMs，即 GPT 3.5、GPT 4和GoogleBARD，它们能够根据给定数据预测和验证历史事件的表现。引入了一种新的评估指标：与现实的距离（DTR），用于评估模型的输出结果与已有的历史事实是否一致。结果显示，AI在历史研究中具有巨大的潜力，其中GPT 4表现最为优异。本文强调了需要进一步研究AI在丰富我们对过去的理解和弥合历史知识差距方面的作用。

    The rapid proliferation of information in the digital era underscores the importance of accurate historical representation and interpretation. While artificial intelligence has shown promise in various fields, its potential for historical fact-checking and gap-filling remains largely untapped. This study evaluates the performance of three large language models LLMs GPT 3.5, GPT 4, and GoogleBARD in the context of predicting and verifying historical events based on given data. A novel metric, Distance to Reality (DTR), is introduced to assess the models' outputs against established historical facts. The results reveal a substantial potential for AI in historical studies, with GPT 4 demonstrating superior performance. This paper underscores the need for further research into AI's role in enriching our understanding of the past and bridging historical knowledge gaps.
    
[^31]: 多语言语言模型的几何：以平等的视角

    The Geometry of Multilingual Language Models: An Equality Lens. (arXiv:2305.07839v1 [cs.CL])

    [http://arxiv.org/abs/2305.07839](http://arxiv.org/abs/2305.07839)

    本研究在欧几里得空间中分析了三种多语言语言模型的几何，发现尽管语言往往根据它们的语言家族更加接近，但它们几乎可以被从其他语言家族的语言分离出来。同时，低资源语言的表现普遍不如高资源语言的表现好。

    

    理解多语言语言模型中不同语言的表示对于理解它们的跨语言属性、预测其在下游任务中的表现以及识别各种语言之间的任何偏见至关重要。在本研究中，我们在欧几里得空间中分析了三种多语言语言模型的几何，发现所有语言都由唯一的几何形状表示。通过使用几何可分离性指数，我们发现尽管语言往往根据它们的语言家族更加接近，但是它们几乎可以被从其他语言家族的语言分离出来。我们还引入了一个跨语言相似度指数来测量语义空间中语言之间的距离。我们的研究结果表明，在任何模型中，低资源语言的表示不如高资源语言的表示好。

    Understanding the representations of different languages in multilingual language models is essential for comprehending their cross-lingual properties, predicting their performance on downstream tasks, and identifying any biases across languages. In our study, we analyze the geometry of three multilingual language models in Euclidean space and find that all languages are represented by unique geometries. Using a geometric separability index we find that although languages tend to be closer according to their linguistic family, they are almost separable with languages from other families. We also introduce a Cross-Lingual Similarity Index to measure the distance of languages with each other in the semantic space. Our findings indicate that the low-resource languages are not represented as good as high resource languages in any of the models
    
[^32]: 基于混合积距离的静态词向量频率感知的维度选择

    Frequency-aware Dimension Selection for Static Word Embedding by Mixed Product Distance. (arXiv:2305.07826v1 [cs.CL])

    [http://arxiv.org/abs/2305.07826](http://arxiv.org/abs/2305.07826)

    本论文研究了词频对维度选择的影响，在此基础上提出了一种使用混合积距离的静态词向量维度选择方法，通过降低词频的影响，实现了比现有方法更好的性能。

    

    对于无法使用上下文的任务，静态词向量仍然有用，因为在没有上下文可用的情况下，预训练的语言模型往往比静态词向量表现得更差。尽管维度是确定静态词向量质量的关键因素，但自动维度选择很少被讨论。本文研究了词频对维度选择的影响，并经验证明了词频是非常关键的，需要在维度选择时进行考量。基于这样的实证发现，该论文提出了一种维度选择方法，使用一种度量（混合积距离，MPD）来为字嵌入算法选择适当的维度，而无需训练任何词向量。通过对预测矩阵应用后处理函数，基于MPD的方法可以降低词频的影响。针对无上下文和有上下文任务的实验表明，与现有的词向量方法相比，我们的方法表现更佳。

    Static word embedding is still useful, particularly for context-unavailable tasks, because in the case of no context available, pre-trained language models often perform worse than static word embeddings. Although dimension is a key factor determining the quality of static word embeddings, automatic dimension selection is rarely discussed. In this paper, we investigate the impact of word frequency on the dimension selection, and empirically find that word frequency is so vital that it needs to be taken into account during dimension selection. Based on such an empirical finding, this paper proposes a dimension selection method that uses a metric (Mixed Product Distance, MPD) to select a proper dimension for word embedding algorithms without training any word embedding. Through applying a post-processing function to oracle matrices, the MPD-based method can de-emphasize the impact of word frequency. Experiments on both context-unavailable and context-available tasks demonstrate the bette
    
[^33]: 一种简单易用的无监督方法用于增强句子表示

    A Simple and Plug-and-play Method for Unsupervised Sentence Representation Enhancement. (arXiv:2305.07824v1 [cs.CL])

    [http://arxiv.org/abs/2305.07824](http://arxiv.org/abs/2305.07824)

    本文提出了一种名为 RepAL 的简单易用的无监督方法，用于增强句子表示。通过减弱句子嵌入中的冗余信息，可以提高语义匹配和检索的效果。该方法无须训练，可与大多数现有的无监督句子学习模型结合使用。

    

    通过无监督的方式生成句子的嵌入对于实际应用中的语义匹配和检索问题是有益的。本文提出了 Representation ALchemy (RepAL)，这是一种非常简单的用于增强句子表示的后处理方法。RepAL 的基本思想是减弱预先训练模型生成的句子嵌入中冗余信息的重要性。通过全面的实验，我们展示了 RepAL 是一种不需要训练且可以与大多数现有的无监督句子学习模型结合使用的即插即用方法。我们还进行了深入的分析以理解 RepAL。

    Generating proper embedding of sentences through an unsupervised way is beneficial to semantic matching and retrieval problems in real-world scenarios. This paper presents Representation ALchemy (RepAL), an extremely simple post-processing method that enhances sentence representations. The basic idea in RepAL is to de-emphasize redundant information of sentence embedding generated by pre-trained models. Through comprehensive experiments, we show that RepAL is free of training and is a plug-and-play method that can be combined with most existing unsupervised sentence learning models. We also conducted in-depth analysis to understand RepAL.
    
[^34]: Dr. LLaMA：通过生成式数据增强改善特定领域QA中的小语言模型

    Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation. (arXiv:2305.07804v1 [cs.CL])

    [http://arxiv.org/abs/2305.07804](http://arxiv.org/abs/2305.07804)

    本论文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，以改善小语言模型的性能，特别是在医学问答任务中。这种方法在微调后使模型性能提高，并提出了在特定领域问答任务中使用LLM所面临的挑战和潜在的研究方向。

    

    大型语言模型在自然语言处理方面取得了重大进展，但随着其规模的增长，也面临着计算开销和效率的挑战，特别是在特定领域的任务中。另一方面，小型语言模型由于容量和训练数据的限制，在这些任务中往往表现不佳。本文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，聚焦医学问答任务和PubMedQA数据集，以改善小语言模型的性能。我们的发现表明，LLM有效地细化和扩展现有的问题-答案对，在微调后，使得小型模型在特定领域QA数据集上性能提高。本研究强调了在特定领域问答任务中使用LLM面临的挑战，并提出了潜在的研究方向，最终旨在为专业应用创建更高效和能力更强的模型。

    Large Language Models (LLMs) have made significant strides in natural language processing but face challenges in terms of computational expense and inefficiency as they grow in size, especially in domain-specific tasks. Small Language Models (SLMs), on the other hand, often struggle in these tasks due to limited capacity and training data. In this paper, we introduce Dr. LLaMA, a method for improving SLMs through generative data augmentation using LLMs, focusing on medical question-answering tasks and the PubMedQA dataset. Our findings indicate that LLMs effectively refine and diversify existing question-answer pairs, resulting in improved performance of a much smaller model on domain-specific QA datasets after fine-tuning. This study highlights the challenges of using LLMs for domain-specific question answering and suggests potential research directions to address these limitations, ultimately aiming to create more efficient and capable models for specialized applications. We have als
    
[^35]: ACCENT:一种开放领域对话系统的自动事件常识评价方法。

    ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems. (arXiv:2305.07797v1 [cs.CL])

    [http://arxiv.org/abs/2305.07797](http://arxiv.org/abs/2305.07797)

    ACCENT是一种基于常识知识库的事件常识评价方法，通过对话中提取的事件-关系元组与CSKB的兼容性评估响应，是一种有效的评价方法。

    

    常识推理在人类交流中普遍存在，因此对于开放领域的对话系统来说是一个重要特征。但是，评估对话系统中的常识推理仍然是一个挑战。我们首先关注事件常识，它考虑事件及其关系，在对话和一般常识推理中至关重要。我们提出ACCENT，一种受常识知识库 (CSKBs) 授权的事件常识评价指标。ACCENT首先从对话中提取事件-关系元组，然后通过计算它们与CSKB的兼容性来评估响应。为了评估ACCENT，我们构建了第一个面向开放域对话的事件常识评价数据集。我们的实验结果表明，ACCENT是一种有效的事件常识评估指标，比现有基线模型更能与人类判断相关联。

    Commonsense reasoning is omnipresent in human communications and thus is an important feature for open-domain dialogue systems. However, evaluating commonsense in dialogue systems is still an open challenge. We take the first step by focusing on event commonsense that considers events and their relations, and is crucial in both dialogues and general commonsense reasoning. We propose ACCENT, an event commonsense evaluation metric empowered by commonsense knowledge bases (CSKBs). ACCENT first extracts event-relation tuples from a dialogue, and then evaluates the response by scoring the tuples in terms of their compatibility with the CSKB. To evaluate ACCENT, we construct the first public event commonsense evaluation dataset for open-domain dialogues. Our experiments show that ACCENT is an efficient metric for event commonsense evaluation, which achieves higher correlations with human judgments than existing baselines.
    
[^36]: 构建掩码语言模型中社会偏见的整体评估指标

    Constructing Holistic Measures for Social Biases in Masked Language Models. (arXiv:2305.07795v1 [cs.CL])

    [http://arxiv.org/abs/2305.07795](http://arxiv.org/abs/2305.07795)

    本文提出了KLDivS和JSDivS这两个评估指标，将掩码语言模型输出的刻板印象和反刻板印象样本的对数似然函数视为高斯分布，可以更稳定、可解释地评估MLMs中的社会偏见。

    

    掩码语言模型（MLMs）在许多自然语言处理任务中取得了成功。然而，由于从大型文本语料库中学习，MLMs 很可能反映现实中的刻板印象偏见。过去提出的大多数评估指标采用不同的掩码策略，设计了MLMs 的对数似然函数。这些指标缺乏对刻板印象和反刻板印象样本变化的考虑。本文将MLMs输出的刻板印象和反刻板印象样本的对数似然函数视为高斯分布，提出了两个评估指标——Kullback Leibler 散度得分（KLDivS）和Jensen Shannon 距离得分（JSDivS），以评估MLMs中的社会偏见。StereoSet 和CrowS-Pairs的公共数据集上的实验结果表明，与过去提出的指标相比，KLDivS和JSDivS更加稳定和可解释。

    Masked Language Models (MLMs) have been successful in many natural language processing tasks. However, real-world stereotype biases are likely to be reflected in MLMs due to their learning from large text corpora. Most of the evaluation metrics proposed in the past adopt different masking strategies, designed with the log-likelihood of MLMs. They lack holistic considerations such as variance for stereotype bias and anti-stereotype bias samples. In this paper, the log-likelihoods of stereotype bias and anti-stereotype bias samples output by MLMs are considered Gaussian distributions. Two evaluation metrics, Kullback Leibler Divergence Score (KLDivS) and Jensen Shannon Divergence Score (JSDivS) are proposed to evaluate social biases in MLMs The experimental results on the public datasets StereoSet and CrowS-Pairs demonstrate that KLDivS and JSDivS are more stable and interpretable compared to the metrics proposed in the past.
    
[^37]: 混合问题解析与执行答案复杂问题的文字问答系统

    Answering Complex Questions over Text by Hybrid Question Parsing and Execution. (arXiv:2305.07789v1 [cs.CL])

    [http://arxiv.org/abs/2305.07789](http://arxiv.org/abs/2305.07789)

    提出了一种混合问题解析和执行框架，在文字问答系统中实现回答复杂问题，通过解析问题为H表达式并设计混合执行器实现。在基准数据集中实现了最先进的准确率和效率表现。

    

    文本问答系统的主导模式是基于端到端的神经网络，其在回答自然语言问题方面表现突出，但在回答复杂问题方面表现不足。这与基于语义解析的方法在结构化数据源（如关系数据库、知识图谱）上广泛适应形成对比，后者将自然语言问题转换为逻辑形式，并利用查询引擎进行执行。为了结合神经和符号方法的优势，我们提出了一种在文本问答系统中进行解析和执行问题的框架。它包括两个中心支柱：（1）我们将各种复杂问题解析成中间表示，称为H表达式，它由简单问题组成原语和表示它们之间关系的符号操作组成；（2）为了执行产生的H表达式，我们设计了一个混合执行器，它集成了确定规则来翻译符号操作，与处理原始问题的插入神经模块。我们在包含复杂问题的大规模基准数据集上评估了我们的方法，并在准确性和效率指标方面取得了最先进的表现。

    The dominant paradigm of textual question answering systems is based on end-to-end neural networks, which excels at answering natural language questions but falls short on complex ones. This stands in contrast to the broad adaptation of semantic parsing approaches over structured data sources (e.g., relational database, knowledge graphs), that convert natural language questions to logical forms and execute them with query engines. Towards combining the strengths of neural and symbolic methods, we propose a framework of question parsing and execution on textual QA. It comprises two central pillars: (1) We parse the question of varying complexity into an intermediate representation, named H-expression, which is composed of simple questions as the primitives and symbolic operations representing the relationships among them; (2) To execute the resulting H-expressions, we design a hybrid executor, which integrates the deterministic rules to translate the symbolic operations with a drop-in n
    
[^38]: NL2TL：使用大型语言模型将自然语言转化为时态逻辑

    NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models. (arXiv:2305.07766v1 [cs.CL])

    [http://arxiv.org/abs/2305.07766](http://arxiv.org/abs/2305.07766)

    本研究提出了一种NL到TL的转换框架，使用大型语言模型在数据集和模型训练中，可以准确并且具有普适性地转换复杂的高级系统规范。

    

    时态逻辑（TL）可用于在许多工程应用中严格指定复杂的高级系统规范。由于缺乏跨不同应用领域的数据集和可推广的模型，自然语言（NL）和TL之间的转换一直未被充分探索。在本文中，我们提出了一个准确且具有普适性的英文指令从NL到TL的转换框架，并探索了在多个阶段使用大型语言模型（LLMs）的方法。我们的贡献有两个方面。首先，我们开发了一个框架来创建NL-TL对数据集，结合了LLMs和人工注释。我们发布了一个具有28K个NL-TL对的数据集。然后，我们在NL和TL的提升版本上微调了T5模型（即，特定原子命题（AP）被隐藏）。增强的普适性源自两个方面：1）使用提升的NL-TL表征常见的逻辑结构，没有特定领域的约束。2）在数据集创建中应用LLMs。

    Temporal Logic (TL) can be used to rigorously specify complex high-level specification for systems in many engineering applications. The translation between natural language (NL) and TL has been under-explored due to the lack of dataset and generalizable model across different application domains. In this paper, we propose an accurate and generalizable transformation framework of English instructions from NL to TL, exploring the use of Large Language Models (LLMs) at multiple stages. Our contributions are twofold. First, we develop a framework to create a dataset of NL-TL pairs combining LLMs and human annotation. We publish a dataset with 28K NL-TL pairs. Then, we finetune T5 models on the lifted versions (i.e., the specific Atomic Propositions (AP) are hidden) of the NL and TL. The enhanced generalizability originates from two aspects: 1) Usage of lifted NL-TL characterizes common logical structures, without constraints of specific domains. 2) Application of LLMs in dataset creation 
    
[^39]: 规则和操作的知识创作

    Knowledge Authoring for Rules and Actions. (arXiv:2305.07763v1 [cs.CL])

    [http://arxiv.org/abs/2305.07763](http://arxiv.org/abs/2305.07763)

    KALMRA是一个工具，它扩展了英语命令的功能，以允许在KALM中进行规则和操作的创作，并通过规则和操作的创作任务数据集的评估显示出较高的准确性和表现。

    

    知识表示和推理系统以事实和规则的形式描述和推理复杂的概念和关系。然而，广泛部署知识表示和推理系统时，领域专家往往很难构建正确的逻辑表示。我们提出了KALMRA来解决这些限制，以实现在KALM中进行规则和操作的创作。

    Knowledge representation and reasoning (KRR) systems describe and reason with complex concepts and relations in the form of facts and rules. Unfortunately, wide deployment of KRR systems runs into the problem that domain experts have great difficulty constructing correct logical representations of their domain knowledge. Knowledge engineers can help with this construction process, but there is a deficit of such specialists. The earlier Knowledge Authoring Logic Machine (KALM) based on Controlled Natural Language (CNL) was shown to have very high accuracy for authoring facts and questions. More recently, KALMFL, a successor of KALM, replaced CNL with factual English, which is much less restrictive and requires very little training from users. However, KALMFL has limitations in representing certain types of knowledge, such as authoring rules for multi-step reasoning or understanding actions with timestamps. To address these limitations, we propose KALMRA to enable authoring of rules and 
    
[^40]: TinyStories: 语言模型能简小到什么程度却依然能够讲述连贯的英文故事？

    TinyStories: How Small Can Language Models Be and Still Speak Coherent English?. (arXiv:2305.07759v1 [cs.CL])

    [http://arxiv.org/abs/2305.07759](http://arxiv.org/abs/2305.07759)

    本文针对小型语言模型生成连贯的英文文本难题，引入了一个合成故事数据集 TinyStories，并探索小型模型规模、结构复杂度和训练数据规模对于语言模型表现的影响，证明了仅含 200 万参数的简单语言模型也能产生连贯的短故事。

    

    语言模型是自然语言处理中强大的工具，但在小型化时经常难以产生连贯和流畅的文本。本文引入了一个名为 TinyStories 的合成故事数据集，用于训练和评估规模小、复杂度低的语言模型对于短故事的生成能力。

    Language models (LMs) are powerful tools for natural language processing, but they often struggle to produce coherent and fluent text when they are small. Models with around 125M parameters such as GPT-Neo (small) or GPT-2 (small) can rarely generate coherent and consistent English text beyond a few words even after extensive training. This raises the question of whether the emergence of the ability to produce coherent English text only occurs at larger scales (with hundreds of millions of parameters or more) and complex architectures (with many layers of global attention).  In this work, we introduce TinyStories, a synthetic dataset of short stories that only contain words that a typical 3 to 4-year-olds usually understand, generated by GPT-3.5 and GPT-4. We show that TinyStories can be used to train and evaluate LMs that are much smaller than the state-of-the-art models (below 10 million total parameters), or have much simpler architectures (with only one transformer block), yet stil
    
[^41]: 使用语言模型检测危险的学生回复

    Using Language Models to Detect Alarming Student Responses. (arXiv:2305.07709v1 [cs.CL])

    [http://arxiv.org/abs/2305.07709](http://arxiv.org/abs/2305.07709)

    本文介绍了一种利用自然语言处理技术识别危险学生回复的系统，该系统采用经过微调的语言模型进行训练，能够显著提高准确性。

    

    本文详细介绍了一种利用人工智能识别危险学生回复的系统的进展。该系统集成在我们的评估平台中，用于评估学生的回复是否表明他们对自己或他人构成威胁。这些回复可能包括关于暴力威胁、严重抑郁、自杀风险和虐待描述的细节。最新模型是一个经过微调的语言模型，它是在由学生回复和补充文本构成的大型语料库上训练而成。我们证明，使用语言模型比此前版本的系统能够大幅提高准确性。

    This article details the advances made to a system that uses artificial intelligence to identify alarming student responses. This system is built into our assessment platform to assess whether a student's response indicates they are a threat to themselves or others. Such responses may include details concerning threats of violence, severe depression, suicide risks, and descriptions of abuse. Driven by advances in natural language processing, the latest model is a fine-tuned language model trained on a large corpus consisting of student responses and supplementary texts. We demonstrate that the use of a language model delivers a substantial improvement in accuracy over the previous iterations of this system.
    
[^42]: Masked Audio Text Encoders 在多模态重打分中是有效的。

    Masked Audio Text Encoders are Effective Multi-Modal Rescorers. (arXiv:2305.07677v1 [cs.SD])

    [http://arxiv.org/abs/2305.07677](http://arxiv.org/abs/2305.07677)

    本文提出了Masked Audio Text Encoders（MATE），一个多模态掩码语言模型重新打分器，将声学表示形式并入到MLM的输入空间中。使用MATE对自动语音识别（ASR）系统进行多模态打分，即使在目标域数据不足的情况下，也可以提高系统的领域泛化能力，并且可以在非常有限的训练数据量下就将单词错误率（WER）降低。

    

    掩码语言模型（MLM）已被证明对于自动语音识别（ASR）系统的二次打分非常有效。在这项工作中，我们提出 Masked Audio Text Encoder（MATE），它是一个多模态掩码语言模型重新打分器，将声学表示形式并入到MLM的输入空间中。我们采用对比学习来通过学习共享表示来有效地对齐各种模态。我们发现，当目标域数据不可用时，使用多模态重新打分器对ASR系统的领域泛化很有好处。与仅文本的基线相比，在域内数据组上，MATE 可以将单词错误率（WER）降低4％-16％，在域外数据组上可将WER降低3％-7％。此外，仅使用非常有限的训练数据（0.8小时），MATE就可以将WER比一次打分的基线降低8％-23％。

    Masked Language Models (MLMs) have proven to be effective for second-pass rescoring in Automatic Speech Recognition (ASR) systems. In this work, we propose Masked Audio Text Encoder (MATE), a multi-modal masked language model rescorer which incorporates acoustic representations into the input space of MLM. We adopt contrastive learning for effectively aligning the modalities by learning shared representations. We show that using a multi-modal rescorer is beneficial for domain generalization of the ASR system when target domain data is unavailable. MATE reduces word error rate (WER) by 4%-16% on in-domain, and 3%-7% on out-of-domain datasets, over the text-only baseline. Additionally, with very limited amount of training data (0.8 hours), MATE achieves a WER reduction of 8%-23% over the first-pass baseline.
    
[^43]: 模仿与创新：孩子们能做到的，大型语言模型和语言视觉模型尚不能做到的是什么？

    Imitation versus Innovation: What children can do that large language and language-and-vision models cannot (yet)?. (arXiv:2305.07666v1 [cs.AI])

    [http://arxiv.org/abs/2305.07666](http://arxiv.org/abs/2305.07666)

    本研究探讨了大型语言和语言视觉模型的局限性，以及机器与人类儿童在模仿和创新方面的不同表现。结果表明，机器需要更多的信息才能达到孩子所能做到的水平。

    

    大型语言模型和语言视觉模型是否是智能体一直备受关注。本研究提供了一种替代视角，认为这些人工智能模型是在现代世界中增强文化传播的文化技术，是高效的模仿引擎。通过评估AI模型设计新工具和发现新的因果结构的能力，我们探讨了AI模型对模仿和创新的影响，并将其与人类儿童的反应进行对比。我们的工作是确定从特定的学习技术和数据中可推导出哪些特定表示和能力，以及哪些知识或技能的第一步。关键在于，我们的研究结果表明，机器可能需要更多的大规模语言和图像，才能达到一个孩子所能做到的水平。

    Much discussion about large language models and language-and-vision models has focused on whether these models are intelligent agents. We present an alternative perspective. We argue that these artificial intelligence models are cultural technologies that enhance cultural transmission in the modern world, and are efficient imitation engines. We explore what AI models can tell us about imitation and innovation by evaluating their capacity to design new tools and discover novel causal structures, and contrast their responses with those of human children. Our work serves as a first step in determining which particular representations and competences, as well as which kinds of knowledge or skill, can be derived from particular learning techniques and data. Critically, our findings suggest that machines may need more than large scale language and images to achieve what a child can do.
    
[^44]: ChatGPT是一个好的因果推断器吗？全面评估

    Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation. (arXiv:2305.07375v1 [cs.CL])

    [http://arxiv.org/abs/2305.07375](http://arxiv.org/abs/2305.07375)

    本文对ChatGPT的因果推理能力进行了首次全面评估，实验证明ChatGPT是一个好的因果解释者，但不是一个好的因果推理者，存在严重的因果幻觉问题，对于明确的因果关系表现良好。

    

    因果推理能力对于众多NLP应用至关重要。尽管ChatGPT在各种NLP任务中表现出令人印象深刻的新兴能力，但ChatGPT在因果推理方面的表现如何仍不清楚。本文对ChatGPT的因果推理能力进行了首次全面评估。实验证明，ChatGPT不是一个好的因果推理者，但是是一个好的因果解释者。此外，ChatGPT在因果推理方面存在严重的幻觉，可能是由于自然语言中因果关系和非因果关系的报告偏见，以及ChatGPT的升级过程，如RLHF。在上下文学习（ICL）和思维链（COT）技术方面，可能会进一步加剧这种因果幻觉。此外，ChatGPT的因果推理能力对于在提示中表达因果概念的词语非常敏感，并且封闭提示比开放提示表现更好。对于句子中的事件，ChatGPT擅长捕捉明确的因果关系。

    Causal reasoning ability is crucial for numerous NLP applications. Despite the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear how well ChatGPT performs in causal reasoning. In this paper, we conduct the first comprehensive evaluation of the ChatGPT's causal reasoning capabilities. Experiments show that ChatGPT is not a good causal reasoner, but a good causal interpreter. Besides, ChatGPT has a serious hallucination on causal reasoning, possibly due to the reporting biases between causal and non-causal relationships in natural language, as well as ChatGPT's upgrading processes, such as RLHF. The In-Context Learning (ICL) and Chain-of-Though (COT) techniques can further exacerbate such causal hallucination. Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts. For events in sentences, ChatGPT excels at capturing explicit caus
    
[^45]: 在大语言模型时代评估开放领域问答

    Evaluating Open-Domain Question Answering in the Era of Large Language Models. (arXiv:2305.06984v1 [cs.CL])

    [http://arxiv.org/abs/2305.06984](http://arxiv.org/abs/2305.06984)

    本文评估了开放领域问答中的大语言模型，发现词汇匹配作为评估方法在这些模型中的作用有限，提出了一种手动评估方法，并发现其中一个零-shot模型的性能大幅度提升。

    

    词汇匹配仍是开放领域问答（QA）的事实评估方法。然而，当一个合理的候选答案未出现在金标准答案列表中时，词汇匹配完全失败，随着我们从抽取模型转向生成模型，这种情况越来越普遍。大语言模型（LLMs）在QA中的最近成功加剧了词汇匹配的失败，因为候选答案变得更长，因此与金标准答案的匹配变得更加具有挑战性。缺乏准确的评估，开放领域QA的真正进展仍然未知。本文通过在NQ-open的一个子集上手动评估各种开放领域QA模型（包括LLMs）的答案进行了彻底分析。我们的评估揭示，尽管所有模型的真实性能被显着低估，但InstructGPT（零-shot）LLM的性能增加了近60％，使其与现有的顶级模型并驾齐驱，而I

    Lexical matching remains the de facto evaluation method for open-domain question answering (QA). Unfortunately, lexical matching fails completely when a plausible candidate answer does not appear in the list of gold answers, which is increasingly the case as we shift from extractive to generative models. The recent success of large language models (LLMs) for QA aggravates lexical matching failures since candidate answers become longer, thereby making matching with the gold answers even more challenging. Without accurate evaluation, the true progress in open-domain QA remains unknown. In this paper, we conduct a thorough analysis of various open-domain QA models, including LLMs, by manually evaluating their answers on a subset of NQ-open, a popular benchmark. Our assessments reveal that while the true performance of all models is significantly underestimated, the performance of the InstructGPT (zero-shot) LLM increases by nearly +60%, making it on par with existing top models, and the I
    
[^46]: COCKATIEL:用可解释元素对NLP任务中的神经网络分类器进行连续概念排名带归因性解释

    COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP tasks. (arXiv:2305.06754v1 [cs.CL])

    [http://arxiv.org/abs/2305.06754](http://arxiv.org/abs/2305.06754)

    COCKATIEL是一种连续概念排名带归因性解释的技术，基于概念，用于从NLP分类任务的神经网络模型的最后一层中生成有意义的解释，且不会影响准确性或需要新模型，已证明比现有方法产生更有信息量和可靠的解释。

    

    Transformer结构复杂，其在NLP中的使用虽然取得了许多成功，但其可解释性或可解释性较为棘手。最近的争论表明，注意力图和归因方法不可靠，而我们在本文中介绍了其中一些局限性，同时介绍了COCKATIEL这一新型的模型无关的可解释性技术，它是一种后期方法，基于概念，用于从经过NLP分类任务训练的神经网络模型的最后一层中生成有意义的解释，通过使用非负矩阵分解(NMF)来发现模型利用来进行预测的概念，并利用敏感性分析来准确估计每个概念对模型的重要性，而不会影响底层模型的准确性或需要训练新模型。我们在单一和多方面的情感分析中进行实验，证明COCKATIEL比现有方法产生更有信息量和可靠的解释。

    Transformer architectures are complex and their use in NLP, while it has engendered many successes, makes their interpretability or explainability challenging. Recent debates have shown that attention maps and attribution methods are unreliable (Pruthi et al., 2019; Brunner et al., 2019). In this paper, we present some of their limitations and introduce COCKATIEL, which successfully addresses some of them. COCKATIEL is a novel, post-hoc, concept-based, model-agnostic XAI technique that generates meaningful explanations from the last layer of a neural net model trained on an NLP classification task by using Non-Negative Matrix Factorization (NMF) to discover the concepts the model leverages to make predictions and by exploiting a Sensitivity Analysis to estimate accurately the importance of each of these concepts for the model. It does so without compromising the accuracy of the underlying model or requiring a new one to be trained. We conduct experiments in single and multi-aspect sent
    
[^47]: 如何为推荐基础模型索引项目ID

    How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])

    [http://arxiv.org/abs/2305.06569](http://arxiv.org/abs/2305.06569)

    本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。

    

    推荐基础模型将推荐任务转换为自然语言任务，利用大型语言模型（LLM）进行推荐。它通过直接生成建议的项目而不是计算传统推荐模型中每个候选项目的排名得分，简化了推荐管道，避免了多段过滤的问题。为了避免在决定要推荐哪些项目时生成过长的文本，为推荐基础模型创建LLM兼容的项目ID是必要的。本研究系统地研究了推荐基础模型的项目索引问题，以P5为代表的主干模型，并使用各种索引方法复制其结果。我们首先讨论了几种微不足道的项目索引方法（如独立索引、标题索引和随机索引）的问题，并表明它们不适用于推荐基础模型，然后提出了一种新的索引方法，称为上下文感知索引。我们表明，这种索引方法在项目推荐准确性和文本生成质量方面优于其他索引方法。

    Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
    
[^48]: 说到做到! 大型语言模型在负面常识知识方面存在太过乐观的表述

    Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge. (arXiv:2305.05976v1 [cs.CL])

    [http://arxiv.org/abs/2305.05976](http://arxiv.org/abs/2305.05976)

    本文研究了大型语言模型(LLMs)对负面常识知识的了解程度，发现LLMs在生成基于负面知识的有效句子方面存在困难，但在回答极性问题方面表现良好，这种信念冲突主要源于语言预训练时的统计快捷方式和否定报告偏见。

    

    大型语言模型(LLMs)因能够存储和利用正面知识而被广泛研究。但是，负面知识，如“狮子不生活在海洋中”，也是世界上无处不在的，但很少在文本中明确提到。LLMs对负面常识知识了解多少？本文研究了LLMs对负面常识知识的了解能力。我们设计了一个有限制的关键词到句子生成任务(CG)和一个布尔型问答任务(QA)来探测LLMs。我们的实验揭示，LLMs经常无法生成基于负面常识知识的有效句子，但它们可以正确地回答极性的是或否问题。我们将这一现象称为LLMs的信念冲突。我们的进一步分析表明，语言建模预训练阶段的统计快捷方式和否定报告偏见引起了这种冲突。

    Large language models (LLMs) have been widely studied for their ability to store and utilize positive knowledge. However, negative knowledge, such as "lions don't live in the ocean", is also ubiquitous in the world but rarely mentioned explicitly in the text. What do LLMs know about negative knowledge? This work examines the ability of LLMs to negative commonsense knowledge. We design a constrained keywords-to-sentence generation task (CG) and a Boolean question-answering task (QA) to probe LLMs. Our experiments reveal that LLMs frequently fail to generate valid sentences grounded in negative commonsense knowledge, yet they can correctly answer polar yes-or-no questions. We term this phenomenon the belief conflict of LLMs. Our further analysis shows that statistical shortcuts and negation reporting bias from language modeling pre-training cause this conflict.
    
[^49]: 超越善意：NLP用于社会公益的研究现状报告

    Beyond Good Intentions: Reporting the Research Landscape of NLP for Social Good. (arXiv:2305.05471v1 [cs.CL])

    [http://arxiv.org/abs/2305.05471](http://arxiv.org/abs/2305.05471)

    本文介绍了NLP4SGPAPERS数据集，通过对解决社会问题的论文进行分类、可持续发展目标映射、任务及方法的确定，使用最先进的NLP模型在整个ACL文集上进行处理，提供了一个可视化工作区，展示了NLP4SG领域的全貌。

    

    随着自然语言处理(NLP)的最新进展，越来越多的应用程序出现在各种用例中。在众多的NLP应用中，许多学术研究人员受到激励，希望通过工作具有积极的社会影响，符合NLP for Social Good (NLP4SG)的最新倡议。然而，研究人员并不总是清楚地了解自己的研究工作如何解决当今的重大社会问题。因此，在本文中，我们介绍NLP4SGPAPERS，这是一个具有三个相关任务的科学数据集，可以帮助识别NLP4SG论文，并通过以下几个方面对NLP4SG进行描述: (1)确定解决社会问题的论文，(2)将它们映射到相应的联合国可持续发展目标(SDGs)，以及(3)识别它们正在解决的任务和使用的方法。我们使用最先进的NLP模型，解决了每个任务，并将它们用于整个ACL文集，从而产生一个可视化工作区，为研究人员提供了对NLP4SG领域的鸟瞰图。

    With the recent advances in natural language processing (NLP), a vast number of applications have emerged across various use cases. Among the plethora of NLP applications, many academic researchers are motivated to do work that has a positive social impact, in line with the recent initiatives of NLP for Social Good (NLP4SG). However, it is not always obvious to researchers how their research efforts are tackling today's big social problems. Thus, in this paper, we introduce NLP4SGPAPERS, a scientific dataset with three associated tasks that can help identify NLP4SG papers and characterize the NLP4SG landscape by: (1) identifying the papers that address a social problem, (2) mapping them to the corresponding UN Sustainable Development Goals (SDGs), and (3) identifying the task they are solving and the methods they are using. Using state-of-the-art NLP models, we address each of these tasks and use them on the entire ACL Anthology, resulting in a visualization workspace that gives resear
    
[^50]: VCSUM：一个多功能的中文会议摘要数据集

    VCSUM: A Versatile Chinese Meeting Summarization Dataset. (arXiv:2305.05280v1 [cs.CL])

    [http://arxiv.org/abs/2305.05280](http://arxiv.org/abs/2305.05280)

    介绍了一个多功能的中文会议摘要数据集VCSum，包括239个现实生活中的会议，总时长超过230小时。该数据集可以适应各种摘要任务或方法，包括基于分割的摘要、多粒度摘要和检索-生成摘要。数据集和代码将在GitHub上发布。

    

    与新闻和聊天摘要相比，由于数据受限，会议摘要的发展受到极大的减速。为此，我们介绍了一个多功能的中文会议摘要数据集VCSum，包括239个现实生活中的会议，总时长超过230小时。我们声称我们的数据集是多功能的，因为我们为每个会议的文本提供了主题划分、头条、分段摘要、整个会议摘要和显要句子等注释。因此，该数据集可以适应各种摘要任务或方法，包括基于分割的摘要、多粒度摘要和检索-生成摘要。我们的分析证实了VCSum的有效性和稳健性。我们还提供了一组关于不同下游摘要任务的基准模型，以便进一步研究VCSum。数据集和代码将在 \url{https://github.com/hahahawu/VCSum} 上发布。

    Compared to news and chat summarization, the development of meeting summarization is hugely decelerated by the limited data. To this end, we introduce a versatile Chinese meeting summarization dataset, dubbed VCSum, consisting of 239 real-life meetings, with a total duration of over 230 hours. We claim our dataset is versatile because we provide the annotations of topic segmentation, headlines, segmentation summaries, overall meeting summaries, and salient sentences for each meeting transcript. As such, the dataset can adapt to various summarization tasks or methods, including segmentation-based summarization, multi-granularity summarization and retrieval-then-generate summarization. Our analysis confirms the effectiveness and robustness of VCSum. We also provide a set of benchmark models regarding different downstream summarization tasks on VCSum to facilitate further research. The dataset and code will be released at \url{https://github.com/hahahawu/VCSum}.
    
[^51]: ANALOGICAL- 一种新的大语言模型文本类比评测基准

    ANALOGICAL - A New Benchmark for Analogy of Long Text for Large Language Models. (arXiv:2305.05050v1 [cs.CL])

    [http://arxiv.org/abs/2305.05050](http://arxiv.org/abs/2305.05050)

    本文介绍了一种名为“ANALOGICAL”的新型基准，用以内在评估LLMs在长文本类比中的能力，包括六个复杂级别的长文本类比分类，并使用13个数据集和三种距离度量方法来评估8个LLMs在语义向量空间中识别类比对的能力。

    

    在过去的十年中，以词级别的类比为形式的类比在衡量诸如word2vec之类的词嵌入方法的质量方面发挥了重要作用。然而，现代的大型语言模型(LLMs)主要根据GLUE和SuperGLUE等基准的外在量度进行评估，而在LLMs是否能够在长文本中绘制类比的方面，只有少数几项研究。本文介绍了一种名为“ANALOGICAL”的新型基准，以六个复杂级别的长文本类比分类对LLMs进行内在评估，分别为 (i)单词、(ii)单词vs句子、(iii)语法、(iv)否定、(v)蕴含和(vi)隐喻。利用13个数据集和三种不同的距离度量方法，我们评估了8个LLMs在语义向量空间中识别类比对的能力(例如，“我能说两种语言”应该更接近“我是双语的”，而“我喜欢巧克力”和“我不喜欢巧克力”应该是正交的)。

    Over the past decade, analogies, in the form of word-level analogies, have played a significant role as an intrinsic measure of evaluating the quality of word embedding methods such as word2vec. Modern large language models (LLMs), however, are primarily evaluated on extrinsic measures based on benchmarks such as GLUE and SuperGLUE, and there are only a few investigations on whether LLMs can draw analogies between long texts. In this paper, we present ANALOGICAL, a new benchmark to intrinsically evaluate LLMs across a taxonomy of analogies of long text with six levels of complexity -- (i) word, (ii) word vs. sentence, (iii) syntactic, (iv) negation, (v) entailment, and (vi) metaphor. Using thirteen datasets and three different distance measures, we evaluate the abilities of eight LLMs in identifying analogical pairs in the semantic vector space (e.g., "I can speak two languages" should be closer to "I am bilingual" while "I like chocolate" and "I do not like chocolate" should be orthog
    
[^52]: 基于Transformer的零样本和少样本生物医学命名实体识别方法

    A transformer-based method for zero and few-shot biomedical named entity recognition. (arXiv:2305.04928v1 [cs.CL])

    [http://arxiv.org/abs/2305.04928](http://arxiv.org/abs/2305.04928)

    本文提出了一种基于Transformer的生物医学领域零样本和少样本NER方法。此方法利用预训练学习给定和潜在类别之间的语义关系，将多类标记分类任务转换为二元标记分类，能够在不同数量的样本情况下达到良好的识别效果。

    

    在生物医学领域中，有监督的命名实体识别（NER）依赖于具有给定命名实体的大量注释文本，其创建可能耗时且昂贵。此外，提取新实体通常需要进行额外的注释任务和重新训练模型。为解决这些挑战，本文提出了一种基于Transformer的生物医学领域零样本和少样本NER方法。该方法基于将多类标记分类任务转换为二元标记分类（标记包含搜索的实体或不包含搜索的实体），并在更多的数据集和生物医学实体上进行预训练，从而可学习到给定和潜在类别之间的语义关系。在9种不同的生物医学实体上，我们在零样本NER、一次样本NER、10次样本NER和100次样本NER上实现了平均F1得分分别为35.44％、50.10％、69.94％和79.51％。

    Supervised named entity recognition (NER) in the biomedical domain is dependent on large sets of annotated texts with the given named entities, whose creation can be time-consuming and expensive. Furthermore, the extraction of new entities often requires conducting additional annotation tasks and retraining the model. To address these challenges, this paper proposes a transformer-based method for zero- and few-shot NER in the biomedical domain. The method is based on transforming the task of multi-class token classification into binary token classification (token contains the searched entity or does not contain the searched entity) and pre-training on a larger amount of datasets and biomedical entities, from where the method can learn semantic relations between the given and potential classes. We have achieved average F1 scores of 35.44% for zero-shot NER, 50.10% for one-shot NER, 69.94% for 10-shot NER, and 79.51% for 100-shot NER on 9 diverse evaluated biomedical entities with PubMed
    
[^53]: MultiTACRED: TAC关系抽取数据集的多语言版本

    MultiTACRED: A Multilingual Version of the TAC Relation Extraction Dataset. (arXiv:2305.04582v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04582](http://arxiv.org/abs/2305.04582)

    该论文介绍了一个名为MultiTACRED的多语言版本的数据集，通过机器翻译和自动注释，该数据集涵盖了12种语言，填补了多语言情况下关系抽取领域缺乏资源的问题。研究表明机器翻译是可行的，而单语RE模型的性能与英文原版相当。

    

    关系抽取是信息提取中的一个基本任务，其在多语言环境下的扩展受到缺乏与TACRED（Zhang等人，2017）等大型英语数据集相媲美的监督资源的限制。为填补这一空白，我们介绍MultiTACRED数据集，涵盖来自9个语系的12种语言。该数据集是通过机器翻译TACRED实例和自动投影其实体注释而创建的。我们分析了翻译和注释投影的质量，确定了错误类别，并在常见的迁移学习场景中实验评估了微调预训练的单语和多语言语言模型的性能。我们的分析表明，机器翻译是传递RE实例的可行策略，母语人士判断超过83％的翻译实例在语言和语义上都是可接受的。我们发现单语RE模型的性能与英文原版相当。

    Relation extraction (RE) is a fundamental task in information extraction, whose extension to multilingual settings has been hindered by the lack of supervised resources comparable in size to large English datasets such as TACRED (Zhang et al., 2017). To address this gap, we introduce the MultiTACRED dataset, covering 12 typologically diverse languages from 9 language families, which is created by machine-translating TACRED instances and automatically projecting their entity annotations. We analyze translation and annotation projection quality, identify error categories, and experimentally evaluate fine-tuned pretrained mono- and multilingual language models in common transfer learning scenarios. Our analyses show that machine translation is a viable strategy to transfer RE instances, with native speakers judging more than 83% of the translated instances to be linguistically and semantically acceptable. We find monolingual RE model performance to be comparable to the English original fo
    
[^54]: AlignSTS：通过跨模态对齐实现语音转唱

    AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment. (arXiv:2305.04476v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2305.04476](http://arxiv.org/abs/2305.04476)

    本文提出了基于跨模态对齐的STS模型AlignSTS，通过一种新颖的节奏适配器来预测目标节奏表示以弥合内容和音高之间的模态差距，并使用交叉注意力重新对齐内容进行跨模态融合重新合成。该模型表现优异。

    

    语音转唱 (STS) 任务旨在在面对一个主要挑战时，生成与语音录音相对应的唱歌样本：在没有文本的情况下，目标（唱歌）音高轮廓和源（语音）内容之间的对齐难以学习。本文提出了基于显式跨模态对齐的STS模型AlignSTS，将语音变化（如音高和内容）视为不同的模态。受人类如何唱出旋律的歌词机制的启发，AlignSTS: 1）采用一种新颖的节奏适配器来预测目标节奏表示，以弥合内容和音高之间的模态差距，其中节奏表示以简单而有效的方式计算，并量化为离散空间；2）使用预测的节奏表示基于交叉注意力重新对齐内容，并进行跨模态融合重新合成。广泛的实验表明，AlignSTS取得了优越的性能。

    The speech-to-singing (STS) voice conversion task aims to generate singing samples corresponding to speech recordings while facing a major challenge: the alignment between the target (singing) pitch contour and the source (speech) content is difficult to learn in a text-free situation. This paper proposes AlignSTS, an STS model based on explicit cross-modal alignment, which views speech variance such as pitch and content as different modalities. Inspired by the mechanism of how humans will sing the lyrics to the melody, AlignSTS: 1) adopts a novel rhythm adaptor to predict the target rhythm representation to bridge the modality gap between content and pitch, where the rhythm representation is computed in a simple yet effective way and is quantized into a discrete space; and 2) uses the predicted rhythm representation to re-align the content based on cross-attention and conducts a cross-modal fusion for re-synthesize. Extensive experiments show that AlignSTS achieves superior performanc
    
[^55]: LMs固守阵地：探究具身化对语言模型理解比喻性语言的影响

    LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models. (arXiv:2305.03445v1 [cs.CL])

    [http://arxiv.org/abs/2305.03445](http://arxiv.org/abs/2305.03445)

    本文研究调查了具身化策略对语言模型解释比喻性语言的影响。结果表明，更大的模型在处理行为更具体化的隐喻性句子时表现更佳。

    

    比喻语言是语言模型的挑战，因为其解释基于单词的使用方式偏离了它们的常规顺序和含义。然而，人类可以轻松理解和诠释隐喻、比喻或习语，因为它们可以从具身隐喻中推导出来。语言是具身化的代理，如果隐喻是传统的和词汇化的，那么一个没有身体的系统就更容易理解具身概念。本文研究表明，在比喻性句子的行动更具体化时，更大的语言模型在解释隐喻句子时表现更好，并排除了与其他特征（例如单词长度或具体性）的多重共线性。

    Figurative language is a challenge for language models since its interpretation is based on the use of words in a way that deviates from their conventional order and meaning. Yet, humans can easily understand and interpret metaphors, similes or idioms as they can be derived from embodied metaphors. Language is a proxy for embodiment and if a metaphor is conventional and lexicalised, it becomes easier for a system without a body to make sense of embodied concepts. Yet, the intricate relation between embodiment and features such as concreteness or age of acquisition has not been studied in the context of figurative language interpretation concerning language models. Hence, the presented study shows how larger language models perform better at interpreting metaphoric sentences when the action of the metaphorical sentence is more embodied. The analysis rules out multicollinearity with other features (e.g. word length or concreteness) and provides initial evidence that larger language model
    
[^56]: HiPool：利用图神经网络对长文档进行建模

    HiPool: Modeling Long Documents Using Graph Neural Networks. (arXiv:2305.03319v1 [cs.CL])

    [http://arxiv.org/abs/2305.03319](http://arxiv.org/abs/2305.03319)

    本论文提出了一种基于图神经网络的方法来模拟长文档，解决了顺序模型中的长期依赖问题，在新提出的基准测试中达到了最先进的性能。

    

    在自然语言处理中，编码长序列是一个具有挑战性的问题。虽然最近的预训练语言模型在许多NLP任务中达到了令人满意的表现，但它们仍受到预定义的最大长度的限制，使得它们难以扩展到更长的序列。因此，一些最近的工作利用层次结构来建模长序列。然而，它们大多数是对上层使用顺序模型，面临着长期依赖问题。在本文中，我们通过一种基于图的方法来缓解这些问题。我们首先使用固定长度对序列进行分块，以模拟句子级别的信息。然后，我们利用图来模拟句内和跨句的关联性，并使用一种新的注意力机制。此外，由于长文档分类的基准测试数据较少，我们提出了一个新的有挑战性的基准测试，共计六个数据集，样本总数达53000个，平均标记长度为4034个。评估结果显示，我们的模型在所有基准测试中均优于竞争基线方法，实现了最先进的性能。

    Encoding long sequences in Natural Language Processing (NLP) is a challenging problem. Though recent pretraining language models achieve satisfying performances in many NLP tasks, they are still restricted by a pre-defined maximum length, making them challenging to be extended to longer sequences. So some recent works utilize hierarchies to model long sequences. However, most of them apply sequential models for upper hierarchies, suffering from long dependency issues. In this paper, we alleviate these issues through a graph-based method. We first chunk the sequence with a fixed length to model the sentence-level information. We then leverage graphs to model intra- and cross-sentence correlations with a new attention mechanism. Additionally, due to limited standard benchmarks for long document classification (LDC), we propose a new challenging benchmark, totaling six datasets with up to 53k samples and 4034 average tokens' length. Evaluation shows our model surpasses competitive baselin
    
[^57]: CryCeleb: 基于婴儿哭声的说话人认证数据集

    CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds. (arXiv:2305.00969v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2305.00969](http://arxiv.org/abs/2305.00969)

    CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。

    

    本文描述了Ubenwa CryCeleb数据集——一个标记的婴儿哭声收集，以及附带的CryCeleb 2023任务——一个基于婴儿哭声的公共说话人验证挑战。我们释放出786名新生儿超过6小时的手动分割哭声，以鼓励婴儿哭声分析方面的研究。

    This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.
    
[^58]: 从国家漏洞数据库的文本描述中构建知识图谱

    Constructing a Knowledge Graph from Textual Descriptions of Software Vulnerabilities in the National Vulnerability Database. (arXiv:2305.00382v1 [cs.CR])

    [http://arxiv.org/abs/2305.00382](http://arxiv.org/abs/2305.00382)

    本文提出了一种从国家漏洞数据库信息中构建漏洞知识图谱的新方法，结合了命名实体识别、关系提取和实体预测。该方法有助于解决网络安全知识图谱中缺失实体的问题。

    

    知识图谱已经显示出了在多个网络安全领域，例如漏洞评估和威胁分析方面的潜力。在本文中，我们提出了一种从国家漏洞数据库的信息中构建漏洞知识图谱的新方法。我们的方法结合了命名实体识别（NER）、关系提取（RE）、以及使用神经模型、启发式规则和知识图谱嵌入的实体预测。我们演示了我们的方法如何有助于解决网络安全知识图谱中缺失实体的问题，并对其性能进行了评估。

    Knowledge graphs have shown promise for several cybersecurity tasks, such as vulnerability assessment and threat analysis. In this work, we present a new method for constructing a vulnerability knowledge graph from information in the National Vulnerability Database (NVD). Our approach combines named entity recognition (NER), relation extraction (RE), and entity prediction using a combination of neural models, heuristic rules, and knowledge graph embeddings. We demonstrate how our method helps to fix missing entities in knowledge graphs used for cybersecurity and evaluate the performance.
    
[^59]: SweCTRL-Mini：一种基于Transformer的数据透明的大型语言模型，用于控制性文本生成的瑞典语言版

    SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish. (arXiv:2304.13994v1 [cs.CL])

    [http://arxiv.org/abs/2304.13994](http://arxiv.org/abs/2304.13994)

    SweCTRL-Mini是一种基于Transformer的大型瑞典语言模型，用户可以控制它生成的文本流派，完全开放下载。生成能力比较GPT-3。

    

    我们介绍了SweCTRL-Mini，它是一个大规模的瑞典语言模型，可用于单个消费级GPU上的推理和fine-tuning。该模型基于由Keskar、McCann、Varshney、Xiong和Socher（2019）开发的CTRL体系结构，这意味着SweCTRL-Mini模型的用户可以通过在生成提示中插入特殊标记来控制生成文本的流派。SweCTRL-Mini在瑞典部分mC4语料库和一组瑞典小说的子集上进行了训练，我们在本文中提供了(1)所使用的训练数据和文本预处理步骤的详细说明，以使可以检查特定短语/来源是否是训练数据的一部分;(2)使用自动评估方法进行辨别性任务的模型评估，使用人工裁判进行生成性任务的评估;我们还将模型的生成能力与GPT-3的生成能力进行了比较。SweCTRL-Mini 是完全开放的，可供下载。

    We present SweCTRL-Mini, a large Swedish language model that can be used for inference and fine-tuning on a single consumer-grade GPU. The model is based on the CTRL architecture by Keskar, McCann, Varshney, Xiong, and Socher (2019), which means that users of the SweCTRL-Mini model can control the genre of the generated text by inserting special tokens in the generation prompts. SweCTRL-Mini is trained on a subset of the Swedish part of the mC4 corpus and a set of Swedish novels. In this article, we provide (1) a detailed account of the utilized training data and text pre-processing steps, to the extent that it is possible to check whether a specific phrase/source was a part of the training data, and (2) an evaluation of the model on both discriminative tasks, using automatic evaluation methods, and generative tasks, using human referees. We also compare the generative capabilities of the model with those of GPT-3. SweCTRL-Mini is fully open and available for download.
    
[^60]: 测量大规模多任务中文理解能力

    Measuring Massive Multitask Chinese Understanding. (arXiv:2304.12986v1 [cs.CL])

    [http://arxiv.org/abs/2304.12986](http://arxiv.org/abs/2304.12986)

    本研究提出了一项测试，以衡量大型中文语言模型的多任务准确性，测试涵盖医学、法律、心理学和教育四个主要领域，结果表明所有模型在法律领域中表现都很差，建议研究人员应该开发更加多样化和均衡的多任务中文理解模型。

    

    大规模中文语言模型的研发正蓬勃发展，但缺乏相应的能力评估。因此，我们提出了一个测试，以衡量大型中文语言模型的多任务准确性。该测试涵盖了医学、法律、心理学和教育四个主要领域，在医学领域有15个子任务，在教育领域有8个子任务。我们发现，在零样本设置下表现最佳的模型平均比表现最差的模型高出近22个百分点。在四个主要领域中，所有模型的平均零样本准确度均未超过0.5。在子领域中，只有GPT-3.5-turbo模型在临床医学中实现了0.703的零样本准确度，这是所有模型在所有子任务中最高的准确度。所有模型在法律领域中表现都很差，最高的零样本准确度仅达到0.259。通过全面评估多个学科的广度和深度的知识，我们建议研究人员应该开发更加多样化和均衡的多任务中文理解模型。

    The development of large-scale Chinese language models is flourishing, yet there is a lack of corresponding capability assessments. Therefore, we propose a test to measure the multitask accuracy of large Chinese language models. This test encompasses four major domains, including medicine, law, psychology, and education, with 15 subtasks in medicine and 8 subtasks in education. We found that the best-performing models in the zero-shot setting outperformed the worst-performing models by nearly 22 percentage points on average. Across the four major domains, the average zero-shot accuracy of all models did not exceed 0.5. In the subdomains, only the GPT-3.5-turbo model achieved a zero-shot accuracy of 0.703 in clinical medicine, which was the highest accuracy among all models across all subtasks. All models performed poorly in the legal domain, with the highest zero-shot accuracy reaching only 0.259. By comprehensively evaluating the breadth and depth of knowledge across multiple discipli
    
[^61]: 通过识别桥接度重要节点生成Skip-gram节点嵌入的后续解释

    Generating Post-hoc Explanations for Skip-gram-based Node Embeddings by Identifying Important Nodes with Bridgeness. (arXiv:2304.12036v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.12036](http://arxiv.org/abs/2304.12036)

    本文提出了一种解释Skip-gram节点嵌入的方法，即通过计算桥接度识别重要节点，并提出了一种新型基于梯度的解释方法GRAPH-wGD，有效地提供全局性解释。

    

    网络中的节点表示学习是编码连续矢量空间中的关系信息同时保留网络固有属性和结构的重要机器学习技术。最近，DeepWalk、LINE、struc2vec、PTE、UserItem2vec和RWJBG等无监督节点嵌入方法从Skip-gram模型中出现，并在诸如节点分类和链接预测等下游任务中表现出更好的性能。然而，由于缺乏适用于嵌入的解释方法和理论研究，提供Skip-gram嵌入的后续解释仍然是一个具有挑战性的问题。本文首先表明可以通过在谱聚类感知局部扰动下计算桥接度来找到Skip-gram嵌入的全局解释。此外，还提出了一种名为GRAPH-wGD的新型基于梯度的解释方法，允许检索top-q全局性解释，并通过实验证明了其有效性。

    Node representation learning in a network is an important machine learning technique for encoding relational information in a continuous vector space while preserving the inherent properties and structures of the network. Recently, unsupervised node embedding methods such as DeepWalk, LINE, struc2vec, PTE, UserItem2vec, and RWJBG have emerged from the Skip-gram model and perform better performance in several downstream tasks such as node classification and link prediction than the existing relational models. However, providing post-hoc explanations of Skip-gram-based embeddings remains a challenging problem because of the lack of explanation methods and theoretical studies applicable for embeddings. In this paper, we first show that global explanations to the Skip-gram-based embeddings can be found by computing bridgeness under a spectral cluster-aware local perturbation. Moreover, a novel gradient-based explanation method, which we call GRAPH-wGD, is proposed that allows the top-q glo
    
[^62]: 全局提示单元：一种有效的移植控制模块

    Global Prompt Cell: A Portable Control Module for Effective Prompt. (arXiv:2304.05642v1 [cs.CL])

    [http://arxiv.org/abs/2304.05642](http://arxiv.org/abs/2304.05642)

    全局提示单元(GPC)是一种用于调整预训练模型的可移植控制模块。它可以在所有编码器层中选择性地保留提示信息，从而提高了 5.8% 的 SuperGLUE 数据集的性能表现。

    

    全局提示单元(Global Prompt Cell, GPC)是一种用于调整预训练模型的可移植控制模块，可以在下游任务中冻结参数并在第一层的输入中插入可训练的嵌入向量。为了解决预训练模型的信息利用问题，GPC可以在所有编码器层中选择性地保留提示信息。实验结果表明，与普通提示调整相比，GPC 在 SuperGLUE 数据集上取得了 5.8% 的提高。

    As a novel approach to tuning pre-trained models, prompt tuning involves freezing the parameters in downstream tasks while inserting trainable embeddings into inputs in the first layer.However,previous methods have mainly focused on the initialization of prompt embeddings. The question of how to train and utilize prompt embeddings in a reasonable way has become aa limiting factor in the effectiveness of prompt tuning. To address this issue, we introduce the Global Prompt Cell (GPC), a portable control module for prompt tuning that selectively preserves prompt information across all encoder layers. Our experimental results demonstrate a 5.8% improvement on SuperGLUE datasets compared to vanilla prompt tuning.
    
[^63]: 自然语言推理综述——从哲学到实践

    Natural Language Reasoning, A Survey. (arXiv:2303.14725v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.14725](http://arxiv.org/abs/2303.14725)

    本综述论文从哲学和NLP场景出发，提供了自然语言推理在NLP中明确的定义，阐述了自然语言推理任务的类型和一种推理分类法，并探讨了经典逻辑推理、自然语言推理、多跳问题回答和常识推理四个方面的研究现状和未来方向。

    

    本综述论文提出了自然语言处理领域中自然语言推理概念的更为清晰的视角，旨在从概念和实践两个方面探讨自然语言推理。在概念方面，本文根据哲学和NLP场景提供了自然语言推理在NLP中的明确定义，讨论了哪些类型的任务需要推理，并介绍了一种推理分类法。在实践方面，本文对NLP中的自然语言推理进行了全面的文献综述，主要涵盖了经典逻辑推理、自然语言推理、多跳问题回答和常识推理。本文还将强大的多步推理模式——反向推理等视为未来自然语言推理研究的重要方向，并将可撤销推理介绍为其中最重要的未来方向之一。本文关注单模态非结构化自然语言文本，不包括神经符号技术和数学推理。

    This survey paper proposes a clearer view of natural language reasoning in the field of Natural Language Processing (NLP), both conceptually and practically. Conceptually, we provide a distinct definition for natural language reasoning in NLP, based on both philosophy and NLP scenarios, discuss what types of tasks require reasoning, and introduce a taxonomy of reasoning. Practically, we conduct a comprehensive literature review on natural language reasoning in NLP, mainly covering classical logical reasoning, natural language inference, multi-hop question answering, and commonsense reasoning. The paper also identifies and views backward reasoning, a powerful paradigm for multi-step reasoning, and introduces defeasible reasoning as one of the most important future directions in natural language reasoning research. We focus on single-modality unstructured natural language text, excluding neuro-symbolic techniques and mathematical reasoning.
    
[^64]: 使用分层行为探索的深度强化学习在对话生成中的应用

    Deep RL with Hierarchical Action Exploration for Dialogue Generation. (arXiv:2303.13465v1 [cs.CL])

    [http://arxiv.org/abs/2303.13465](http://arxiv.org/abs/2303.13465)

    本篇论文提出了一种新的方法，通过分层行为探索，从多个奖励函数中进行离线学习，并成功地解决了在对话生成中行为采样效率低下的问题，可以更好地识别人类情感细节。

    

    自然语言的行为空间极其庞大，因此在对话生成中，近似动态规划必须使用策略改进和行为采样。但是，由于有价值的回应非常稀疏，因此使用随机采样的贪心策略效率低下。本文提出了双粒度的 Q-function 并通过探索最有前途的回应类别来缓解这个局限性。该算法从识别人类情感细节的多个奖励函数中进行离线学习。实证研究表明，该算法优于基线方法。

    Conventionally, since the natural language action space is astronomical, approximate dynamic programming applied to dialogue generation involves policy improvement with action sampling. However, such a practice is inefficient for reinforcement learning (RL) because the eligible (high action value) responses are very sparse, and the greedy policy sustained by the random sampling is flabby. This paper shows that the performance of dialogue policy positively correlated with sampling size by theoretical and experimental. We introduce a novel dual-granularity Q-function to alleviate this limitation by exploring the most promising response category to intervene in the sampling. It extracts the actions following the grained hierarchy, which can achieve the optimum with fewer policy iterations. Our approach learns in the way of offline RL from multiple reward functions designed to recognize human emotional details. Empirical studies demonstrate that our algorithm outperforms the baseline metho
    
[^65]: 评估变换器模型和人类行为在中文字符命名方面的表现。

    Evaluating Transformer Models and Human Behaviors on Chinese Character Naming. (arXiv:2303.12294v1 [cs.CL])

    [http://arxiv.org/abs/2303.12294](http://arxiv.org/abs/2303.12294)

    本研究评估了一组 transformer 模型，在未知的中文字符命名任务中，这些模型表现得与人类很相似，能够很好地捕捉人类字符命名行为。

    

    对于许多字母语言，已经提出了神经网络模型来解释人类的字素-音素映射过程。这些模型不仅成功地学习了字母字符串及其发音的对应关系，而且还捕捉了人类在短暂单词命名任务中的行为。本研究中，我们评估了一组变换器模型，并将它们的表现与人类在未知中文字符命名任务中的表现进行比较。我们发现，模型和人类的行为非常相似，它们在每个字符的准确度分布方面具有类似的准确度，并且在答案上有很大的重叠。此外，模型的答案与人类的答案高度相关。这些结果表明，变换器模型能够很好地捕捉人类的字符命名行为。

    Neural network models have been proposed to explain the grapheme-phoneme mapping process in humans for many alphabet languages. These models not only successfully learned the correspondence of the letter strings and their pronunciation, but also captured human behavior in nonce word naming tasks. How would the neural models perform for a non-alphabet language (e.g., Chinese) unknown character task? How well would the model capture human behavior? In this study, we evaluate a set of transformer models and compare their performances with human behaviors on an unknown Chinese character naming task. We found that the models and humans behaved very similarly, that they had similar accuracy distribution for each character, and had a substantial overlap in answers. In addition, the models' answers are highly correlated with humans' answers. These results suggested that the transformer models can well capture human's character naming behavior.
    
[^66]: 人本设计中的人工共情：一个框架

    Toward Artificial Empathy for Human-Centered Design: A Framework. (arXiv:2303.10583v1 [cs.HC])

    [http://arxiv.org/abs/2303.10583](http://arxiv.org/abs/2303.10583)

    本文提出了一个框架，旨在从人工智能研究中引入人工共情的思想进入人本设计，以帮助设计师更好地理解用户的需求。

    

    设计过程的早期阶段，设计师通过发现未满足的需求和开发创新的概念作为潜在的解决方案来探索机会。从人本设计的角度来看，设计师必须与人发展共情，才能真正理解他们的需求。然而，发展共情是一个复杂而主观的过程，非常依赖于设计师的共情能力。因此，共情的发展是直觉性的，潜在需求的发现往往是偶然的。本文旨在提供人工智能研究的见解，以指出以共情为核心的人本设计人工智能驱动的发展方向。具体而言，我们进行了跨学科研究，包括数据驱动的用户研究、共情理解的发展和人工共情等研究领域。基于这个基础，我们讨论了人工共情在人本设计中可以发挥的作用，并提出了一个在设计过程中开发人工共情的框架。

    In the early stages of the design process, designers explore opportunities by discovering unmet needs and developing innovative concepts as potential solutions. From a human-centered design perspective, designers must develop empathy with people to truly understand their needs. However, developing empathy is a complex and subjective process that relies heavily on the designer's empathetic capability. Therefore, the development of empathetic understanding is intuitive, and the discovery of underlying needs is often serendipitous. This paper aims to provide insights from artificial intelligence research to indicate the future direction of AI-driven human-centered design, taking into account the essential role of empathy. Specifically, we conduct an interdisciplinary investigation of research areas such as data-driven user studies, empathetic understanding development, and artificial empathy. Based on this foundation, we discuss the role that artificial empathy can play in human-centered 
    
[^67]: 非自回归文本生成的扩散模型: 一项综述

    Diffusion Models for Non-autoregressive Text Generation: A Survey. (arXiv:2303.06574v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.06574](http://arxiv.org/abs/2303.06574)

    本文综述了扩散模型在非自回归文本生成中的最新进展，包括两种主流扩散模型，以及语言预训练模型在文本扩散模型中的应用和文本数据的优化技术。

    

    非自回归（NAR）文本生成在自然语言处理领域引起了广泛关注，大大降低了推理延迟，但不得不牺牲生成准确性。最近，一类潜变量生成模型——扩散模型已被引入到NAR文本生成中，展现了更好的文本生成质量。本综述对扩散模型在NAR文本生成中最近的进展进行了回顾。我们首先介绍了扩散模型的通用定义和文本扩散模型，并讨论了它们在NAR生成中的优点。随后，我们介绍了现有文本扩散工作中两种主流扩散模型，并回顾了扩散过程的关键设计。此外，我们讨论了语言预训练模型（PLMs）在文本扩散模型中的使用，并介绍了文本数据的优化技术。最后，我们讨论了几个有希望的方向，并作出结论。

    Non-autoregressive (NAR) text generation has attracted much attention in the field of natural language processing, which greatly reduces the inference latency but has to sacrifice the generation accuracy. Recently, diffusion models, a class of latent variable generative models, have been introduced into NAR text generation, showing an improved text generation quality. In this survey, we review the recent progress in diffusion models for NAR text generation. As the background, we first present the general definition of diffusion models and the text diffusion models, and then discuss their merits for NAR generation. As the core content, we further introduce two mainstream diffusion models in existing work of text diffusion, and review the key designs of the diffusion process. Moreover, we discuss the utilization of pre-trained language models (PLMs) for text diffusion models and introduce optimization techniques for text data. Finally, we discuss several promising directions and conclude
    
[^68]: 双排列等变性在知识图谱补全中的应用

    Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01313](http://arxiv.org/abs/2302.01313)

    本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。

    

    本研究将知识图谱(KGs)形式化为一种新型的图，并称之为双交换属性图，其中节点和二元（两个节点之间的）表示必须对节点号和边（及节点）属性（关系和节点特征）的排列等变。双重排列等变的KG表示在KG中开辟了新的研究方向。我们展示了这种等变性对关系的结构表示产生的影响，从而使神经网络能够在KG中执行复杂的逻辑推理任务。最后，我们介绍了一种通用的等变表示蓝图，并测试了一种简单的基于GNN的双排列等变神经结构，在WN18RR、FB237和NELL995归纳KG完成任务中实现了最先进的Hits@10测试准确率，并能够准确执行现有方法无法执行的逻辑推理任务。

    This work provides a formalization of Knowledge Graphs (KGs) as a new class of graphs that we denote doubly exchangeable attributed graphs, where node and pairwise (joint 2-node) representations must be equivariant to permutations of both node ids and edge (& node) attributes (relations & node features). Double-permutation equivariant KG representations open a new research direction in KGs. We show that this equivariance imposes a structural representation of relations that allows neural networks to perform complex logical reasoning tasks in KGs. Finally, we introduce a general blueprint for such equivariant representations and test a simple GNN-based double-permutation equivariant neural architecture that achieve state-of-the-art Hits@10 test accuracy in the WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately perform logical reasoning tasks that no existing methods can perform, to the best of our knowledge.
    
[^69]: 大型语言模型的并行上下文窗口

    Parallel Context Windows for Large Language Models. (arXiv:2212.10947v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10947](http://arxiv.org/abs/2212.10947)

    PCW方法可以缓解现成LLM的上下文窗口限制，将长上下文划分为块并在每个窗口内重用位置嵌入，提高了处理长文本的性能表现。

    

    处理长文本时，大型语言模型（LLM）受到上下文窗口的限制。现有的解决这个问题的方法包括训练专门的架构，但不能轻松地应用于现成的LLM。我们提出了并行上下文窗口（PCW）方法，可以缓解任何现成LLM的上下文窗口限制，而无需进行进一步训练。这种方法的关键在于将长上下文划分为块（“窗口”），限制注意机制仅在每个窗口内应用，并跨窗口重用位置嵌入。我们的主要结果是在750万到1780亿个参数范围内的模型上测试PCW方法，并展示其在输入和输出空间不同的任务中带来了显著的改进。我们在其他需要长上下文窗口的情况下，如多跳问题和使用多个检索的检索增强型问答中展示了额外的好处。

    When applied for processing long text, Large Language Models (LLMs) are limited by their context window. Existing efforts to address this limitation involve training specialized architectures, and cannot be easily applied to off-the-shelf LLMs. We present Parallel Context Windows (PCW), a method that alleviates the context window restriction for any off-the-shelf LLM without further training. The key to the approach is to carve a long context into chunks (``windows''), restrict the attention mechanism to apply only within each window, and re-use the positional embeddings across the windows. Our main results test the PCW approach on in-context learning with models that range in size between 750 million and 178 billion parameters, and show substantial improvements for tasks with diverse input and output spaces. We show additional benefits in other settings where long context windows may be beneficial: multi-hop questions and retrieval-augmented question answering with multiple retrieved 
    
[^70]: 非玩家角色对话的本体论生成

    Ontologically Faithful Generation of Non-Player Character Dialogues. (arXiv:2212.10618v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10618](http://arxiv.org/abs/2212.10618)

    该论文介绍了一个与流行视频游戏环境相关的语言生成任务，该任务包括非线性的角色对话树生成，并要求对话忠实于游戏的角色形象和实体关系，对话必须准确向玩家揭示新的任务细节。神经生成模型的结果表明，该模型能够胜任这个任务但还有进一步的改进空间。

    

    我们引入了一项与流行视频游戏环境相关的语言生成任务。KNUDGE (KNowledge Constrained User-NPC Dialogue GEneration) 要求模型产生反映自然语言中规定任务和实体规范的视频游戏角色之间对话树。KNUDGE 是从 Obsidian Entertainment's The Outer Worlds 的游戏数据中直接提取的副任务对话构建的，导致在生成过程中存在现实世界的复杂性：(1) 对话是分支树，而不是线性的发言链; (2) 话语必须忠实于游戏世界——角色形象、背景和实体关系;以及(3) 对话必须准确地向玩家揭示新的任务细节。我们报告了一组使用监督和上下文学习技术的神经生成模型的结果；我们发现这些模型可以胜任这个任务但还存在改进空间，以应对创建逼真的、高质量的游戏对话方面的挑战。

    We introduce a language generation task grounded in a popular video game environment. KNUDGE (KNowledge Constrained User-NPC Dialogue GEneration) requires models to produce trees of dialogue between video game characters that accurately reflect quest and entity specifications stated in natural language. KNUDGE is constructed from side quest dialogues drawn directly from game data of Obsidian Entertainment's The Outer Worlds, leading to real-world complexities in generation: (1) dialogues are branching trees as opposed to linear chains of utterances; (2) utterances must remain faithful to the game lore- character personas, backstories, and entity relationships; and (3) a dialogue must accurately reveal new quest details to the human player. We report results for a set of neural generation models using supervised and in-context learning techniques; we find competent performance but room for future work addressing the challenges of creating realistic, game-quality dialogues.
    
[^71]: 为什么GPT能够学习上下文？语言模型隐式地作为元优化器执行梯度下降。

    Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers. (arXiv:2212.10559v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10559](http://arxiv.org/abs/2212.10559)

    本文将语言模型解释为元优化器，并将上下文学习理解为隐式微调，通过实验证据支持了这一理解。

    

    大型预训练语言模型展示了惊人的上下文学习能力。它们可以通过几个演示的输入-标签对，在没有参数更新的情况下预测未见过的输入的标签。尽管在性能方面取得了巨大的成功，但其工作机制仍然是一个未解决的问题。本文将语言模型解释为元优化器，并将上下文学习理解为隐式微调。理论上，我们发现Transformer注意力有梯度下降的双重形式。在此基础上，我们将ICL如下理解：GPT首先根据演示示例产生元梯度，然后将这些元梯度应用于原始GPT，构建ICL模型。我们全面比较了实际任务中上下文学习和显式微调的行为，提供了支持我们理解的经验证据。实验结果表明，上下文学习在多个方面表现出与显式微调类似的行为。

    Large pretrained language models have shown surprising in-context learning (ICL) ability. With a few demonstration input-label pairs, they can predict the label for an unseen input without parameter updates. Despite the great success in performance, its working mechanism still remains an open question. In this paper, we explain language models as meta-optimizers and understand in-context learning as implicit finetuning. Theoretically, we figure out that Transformer attention has a dual form of gradient descent. On top of it, we understand ICL as follows: GPT first produces meta-gradients according to the demonstration examples, and then these meta-gradients are applied to the original GPT to build an ICL model. We comprehensively compare the behaviors of in-context learning and explicit finetuning on real tasks to provide empirical evidence that supports our understanding. Experimental results show that in-context learning behaves similarly to explicit finetuning from multiple perspect
    
[^72]: 在开放域问答中防御误导性攻击

    Defending Against Misinformation Attacks in Open-Domain Question Answering. (arXiv:2212.10002v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10002](http://arxiv.org/abs/2212.10002)

    本文提出了一种使用查询扩充来搜索冗余信息、并通过新颖的置信度方法将其集成到模型中的方法，可以有效防御开放域问答系统中的污染攻击，精确匹配率可提高近20%。

    

    最近在开放域问答领域中的研究表明，对于搜索集合进行的敌对污染可能会导致生产系统的精度大幅下降。然而，几乎没有工作提出防御这些攻击的方法。为了解决这个问题，我们依赖于大型语料库中存在冗余信息的直觉。为了找到这些信息，我们引入了一种使用查询扩充来搜索可能回答原始问题的多样化段落集合的方法，但是不太可能被污染。我们通过设计一种新型的置信度方法（比较预测答案与其在检索到的上下文中出现的情况——我们称之为答案冗余置信度，即CAR）将这些新段落集成到模型中。这些方法共同构成了一种简单但有效的方式，用于防御污染攻击，可在不同水平的数据污染/知识冲突下提供近20％的精确匹配增益。

    Recent work in open-domain question answering (ODQA) has shown that adversarial poisoning of the search collection can cause large drops in accuracy for production systems. However, little to no work has proposed methods to defend against these attacks. To do so, we rely on the intuition that redundant information often exists in large corpora. To find it, we introduce a method that uses query augmentation to search for a diverse set of passages that could answer the original question but are less likely to have been poisoned. We integrate these new passages into the model through the design of a novel confidence method, comparing the predicted answer to its appearance in the retrieved contexts (what we call \textit{Confidence from Answer Redundancy}, i.e. CAR). Together these methods allow for a simple but effective way to defend against poisoning attacks that provides gains of nearly 20\% exact match across varying levels of data poisoning/knowledge conflicts.
    
[^73]: 无监督摘要再排序

    Unsupervised Summarization Re-ranking. (arXiv:2212.09593v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09593](http://arxiv.org/abs/2212.09593)

    该论文提出了一种无监督的摘要再排序方法，可以将无监督模型的摘要表现提高，缩小其与有监督模型之间的性能差距。

    

    随着任务特定的预训练目标的兴起，像PEGASUS这样的抽象摘要模型在下游摘要任务中提供了令人满意的零样本性能。然而，这些无监督模型的性能仍然明显落后于它们的有监督对应物。本文提出了一种无监督的摘要再排序方法，旨在缩小无监督和有监督模型之间的性能差距。我们的方法在四个被广泛采用的摘要基准测试中，将PEGASUS的相对平均ROUGE提高了最多7.27％，ChatGPT提高了最多6.86％；并且在30种零样本转移设置（在一个数据集上微调，另一个数据集上评估）中，平均获得了7.51％的相对增益（从XSum到WikiHow最高可达23.73％）。

    With the rise of task-specific pre-training objectives, abstractive summarization models like PEGASUS offer appealing zero-shot performance on downstream summarization tasks. However, the performance of such unsupervised models still lags significantly behind their supervised counterparts. Similarly to the supervised setup, we notice a very high variance in quality among summary candidates from these models while only one candidate is kept as the summary output. In this paper, we propose to re-rank summary candidates in an unsupervised manner, aiming to close the performance gap between unsupervised and supervised models. Our approach improves the unsupervised PEGASUS by up to 7.27% and ChatGPT by up to 6.86% relative mean ROUGE across four widely-adopted summarization benchmarks ; and achieves relative gains of 7.51% (up to 23.73% from XSum to WikiHow) averaged over 30 zero-shot transfer setups (finetuning on a dataset, evaluating on another).
    
[^74]: PVGRU：通过Pseudo-Variational机制生成多样且相关的对话回复

    PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism. (arXiv:2212.09086v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09086](http://arxiv.org/abs/2212.09086)

    该论文提出了一个名为PVGRU的组件，可以通过引入汇总变量来聚合子序列的累积分布变化，从而优化基于生成的聊天机器人的多轮对话回复，提高对话模型的多样性和相关性。

    

    我们研究了基于生成的聊天机器人中用于多轮对话的回复生成。现有的基于RNN（循环神经网络）的生成模型通常使用最后隐藏的状态来汇总序列，这使得模型无法捕捉不同对话中观察到的微妙变化，并且不能区分在构成方面相似的对话之间的差异。在本文中，我们提出了一种Pseudo-Variational Gated Recurrent Unit（PVGRU）组件，无需后验知识即可将汇总变量引入GRU，其可以聚合子序列的累积分布变化。 PVGRU可以通过总结变量感知微妙的语义变化，这些变化是通过设计的分布一致性和重构目标进行优化的。此外，我们基于PVGRU构建了Pseudo-Variational Hierarchical Dialogue（PVHD）模型。实验结果表明，PVGRU可以广泛提高对话模型的多样性和相关性。

    We investigate response generation for multi-turn dialogue in generative-based chatbots. Existing generative models based on RNNs (Recurrent Neural Networks) usually employ the last hidden state to summarize the sequences, which makes models unable to capture the subtle variability observed in different dialogues and cannot distinguish the differences between dialogues that are similar in composition. In this paper, we propose a Pseudo-Variational Gated Recurrent Unit (PVGRU) component without posterior knowledge through introducing a recurrent summarizing variable into the GRU, which can aggregate the accumulated distribution variations of subsequences. PVGRU can perceive the subtle semantic variability through summarizing variables that are optimized by the devised distribution consistency and reconstruction objectives. In addition, we build a Pseudo-Variational Hierarchical Dialogue (PVHD) model based on PVGRU. Experimental results demonstrate that PVGRU can broadly improve the dive
    
[^75]: 推动多语言预训练：TRIP三角形文档级多语言预训练模型

    Advancing Multilingual Pre-training: TRIP Triangular Document-level Pre-training for Multilingual Language Models. (arXiv:2212.07752v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07752](http://arxiv.org/abs/2212.07752)

    TRIP模型利用文档级三语言平行语料库改进序列到序列的多语言预训练，获得了在多项任务上的最优结果。

    

    尽管多语言序列到序列预训练获得成功，但大多数现有方法依赖于包含多种语言的单语言文档级语料库、句子级双语语料库，有时还利用合成的文档级双语语料库。这阻碍了跨语言文档级任务（如文档级翻译）的性能。因此，我们提出了利用文档级三语言平行语料库改进序列到序列的多语言预训练的TRIP框架。该框架通过新颖的三角形预训练模式利用三语平行语料库。在各种跨语言基准测试中，我们通过广泛的实验证明了我们方法的有效性，在一些任务上取得了最优结果。

    Despite the success of multilingual sequence-to-sequence pre-training, most existing approaches rely on document-level monolingual corpora in many different languages, sentence-level bilingual corpora,\footnote{In this paper, we use `bilingual corpora' to denote parallel corpora with `bilingual translation pairs' in many different language pairs, each consisting of two sentences/documents with the same meaning written in different languages. We use `trilingual corpora' to denote parallel corpora with `trilingual translation pairs' in many different language combinations, each consisting of three sentences/documents.} and sometimes synthetic document-level bilingual corpora. This hampers the performance with cross-lingual document-level tasks such as document-level translation. Therefore, we propose to mine and leverage document-level trilingual parallel corpora to improve sequence-to-sequence multilingual pre-training. We present \textbf{Tri}angular Document-level \textbf{P}re-training
    
[^76]: 多语言翻译中干扰的原因和解决方法探究

    Causes and Cures for Interference in Multilingual Translation. (arXiv:2212.07530v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07530](http://arxiv.org/abs/2212.07530)

    研究探究了多语言机器翻译中干扰的主要因素，通过系统化试验发现使用不到10亿参数的标准Transformer配置可以在很大程度上缓解干扰并促进协同，同时发现调整采样温度以控制数据中每个语言对所占比例的方法是平衡语言对之间关系的关键。

    

    多语言机器翻译模型可以从不同语言对之间的协同中获益，但同时也会受到干扰的影响。虽然目前有越来越多的先进方法旨在消除干扰，但我们对干扰现象的理解仍然有限。本研究确定了导致多语言机器翻译中干扰的主要因素。通过系统化试验，我们发现干扰（或协同）主要由模型大小、数据大小和每个语言对在总数据集中所占比例来决定。我们观察到，当模型相对于可用的训练数据非常小的时候，会出现严重的干扰，而使用不到10亿参数的标准Transformer配置可以在很大程度上缓解干扰并促进协同。此外，我们还展示了通过调整采样温度以控制数据中每个语言对所占比例的方法是平衡语言对之间关系的关键。

    Multilingual machine translation models can benefit from synergy between different language pairs, but also suffer from interference. While there is a growing number of sophisticated methods that aim to eliminate interference, our understanding of interference as a phenomenon is still limited. This work identifies the main factors that contribute to interference in multilingual machine translation. Through systematic experimentation, we find that interference (or synergy) are primarily determined by model size, data size, and the proportion of each language pair within the total dataset. We observe that substantial interference occurs mainly when the model is very small with respect to the available training data, and that using standard transformer configurations with less than one billion parameters largely alleviates interference and promotes synergy. Moreover, we show that tuning the sampling temperature to control the proportion of each language pair in the data is key to balancin
    
[^77]: 语言建模在推荐系统中的关键作用：丰富任务特定和任务无关的表示学习

    Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning. (arXiv:2212.03760v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2212.03760](http://arxiv.org/abs/2212.03760)

    本文研究发现，用户历史语言建模可以在不同推荐任务中取得优异结果，并且利用任务无关的用户历史还可以提供显著的性能优势。该方法具有广泛的现实世界迁移学习能力。

    

    最近的研究提出了利用来自各种应用程序的用户行为数据的统一用户建模框架。其中许多受益于将用户行为序列作为纯文本使用，代表着任何领域或系统中的丰富信息而不失通用性。因此，一个问题产生了：用户历史语言建模能否帮助改善推荐系统？虽然语言建模的多功能性已在许多领域广泛研究，但其在推荐系统中的应用仍未深入探讨。我们展示了直接应用于任务特定用户历史的语言建模在不同的推荐任务上可以取得优异的结果。此外，利用任务无关的用户历史还可以提供显著的性能优势。我们进一步证明了我们的方法可以为广泛的现实世界推荐系统提供有前途的迁移学习能力，甚至在未知域和服务上也可以实现。

    Recent studies have proposed unified user modeling frameworks that leverage user behavior data from various applications. Many of them benefit from utilizing users' behavior sequences as plain texts, representing rich information in any domain or system without losing generality. Hence, a question arises: Can language modeling for user history corpus help improve recommender systems? While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored. We show that language modeling applied directly to task-specific user histories achieves excellent results on diverse recommendation tasks. Also, leveraging additional task-agnostic user histories delivers significant performance benefits. We further demonstrate that our approach can provide promising transfer learning capabilities for a broad spectrum of real-world recommender systems, even on unseen domains and services.
    
[^78]: 逻辑和常识引导的时间知识图谱补全

    Logic and Commonsense-Guided Temporal Knowledge Graph Completion. (arXiv:2211.16865v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.16865](http://arxiv.org/abs/2211.16865)

    本文提出一种"逻辑和常识引导的嵌入模型"（LCGE），通过共同学习时间敏感性表示（涉及时态和因果性的事件表示）与常识角度上的时间无关表示，解决了时间知识图谱补全中表示事件的实时性和因果性的挑战。

    

    时间知识图谱（TKG）存储与时间有关的数据事件。预测事件由于其时态特性而极具挑战性。此外，以往的TKG补全方法无法同时表示事件的实时性和因果性。为了解决这些问题，我们提出了一种“逻辑和常识引导的嵌入模型”（LCGE），能够共同学习事件的时间敏感性表示（涉及时态和因果性的事件表示）与常识角度上的时间无关表示。具体来说，我们设计了一个时间规则学习算法，构建了一个规则引导的谓词嵌入规范策略，学习事件之间的因果关系。此外，我们通过辅助常识知识能够准确评估事件的合理性。实验结果表明，我们的模型在TKGC任务中实现了显著的性能提升。

    A temporal knowledge graph (TKG) stores the events derived from the data involving time. Predicting events is extremely challenging due to the time-sensitive property of events. Besides, the previous TKG completion (TKGC) approaches cannot represent both the timeliness and the causality properties of events, simultaneously. To address these challenges, we propose a Logic and Commonsense-Guided Embedding model (LCGE) to jointly learn the time-sensitive representation involving timeliness and causality of events, together with the time-independent representation of events from the perspective of commonsense. Specifically, we design a temporal rule learning algorithm to construct a rule-guided predicate embedding regularization strategy for learning the causality among events. Furthermore, we could accurately evaluate the plausibility of events via auxiliary commonsense knowledge. The experimental results of TKGC task illustrate the significant performance improvements of our model compar
    
[^79]: data2vec-aqc：在师生训练中寻找合适的助教。

    data2vec-aqc: Search for the right Teaching Assistant in the Teacher-Student training setup. (arXiv:2211.01246v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.01246](http://arxiv.org/abs/2211.01246)

    本文提出了一种新的自我监督学习算法data2vec-aqc，用于从未标记的语音数据中学习语音表示，该算法在语音识别领域取得了显著的性能提高。

    

    本文提出了一种新的自我监督学习算法——data2vec-aqc，用于从未标记的语音数据中学习语音表示。我们的目标是改进在标记和未标记的数据都很有限的语音领域的自我监督学习。在最近引入的data2vec的基础上，我们引入了额外的模块来利用数据增强、量化表示和聚类的优势。这些模块之间的交互帮助解决了交叉对比损失作为额外的自我监督目标。在没有使用任何语言模型(LM)的情况下，data2vec-aqc在LibriSpeech的test-clean集和test-other集上相对于现有最先进的data2vec系统分别取得了14.1％和20.9％的相对WER提高。我们提出的模型在Switchboard数据集的子集上微调时也可以获得高达17.8％的相对WER收益。

    In this paper, we propose a new Self-Supervised Learning (SSL) algorithm called data2vec-aqc, for speech representation learning from unlabeled speech data. Our goal is to improve SSL for speech in domains where both unlabeled and labeled data are limited. Building on the recently introduced data2vec, we introduce additional modules to the data2vec framework that leverage the benefit of data augmentations, quantized representations, and clustering. The interaction between these modules helps solve the cross-contrastive loss as an additional self-supervised objective. data2vec-aqc achieves up to 14.1% and 20.9% relative WER improvement over the existing state-of-the-art data2vec system over the test-clean and test-other sets, respectively of LibriSpeech, without the use of any language model (LM). Our proposed model also achieves up to 17.8\% relative WER gains over the baseline data2vec when fine-tuned on a subset of the Switchboard dataset. Code: https://github.com/Speech-Lab-IITM/dat
    
[^80]: 我们如何到达那里？评估变压器神经网络作为英语过去式词形变化的认知模型。

    How do we get there? Evaluating transformer neural networks as cognitive models for English past tense inflection. (arXiv:2210.09167v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.09167](http://arxiv.org/abs/2210.09167)

    本研究通过训练变压器模型的不同设置来评估模型在英语过去式词形变化任务上的表现，结果发现模型在未见过的规则动词上有很高的准确率，在非规则动词上的表现略有提高。不同行为表明模型具有一定程度的符号学习。

    

    对于神经网络是否能像人类一样掌握语言的准正则性一直存在争议。在典型的准正则性任务，英语的过去式词形变化中，神经网络模型长期以来一直受到批评，认为它只学习了最常见的模式，而不是规则的模式，因此无法学习正则和非正则的抽象类别，与人类表现不同。在这项工作中，我们训练了一组具有不同设置的变压器模型，以检查它们在这项任务上的行为。这些模型对未见过的规则动词的准确率很高，对未见过的非规则动词的准确率略有提高。模型在规则动词上的表现受到类型频率和比率的影响，而不是令牌频率和比率，而在非规则动词上则相反。模型在规则动词和非规则动词上不同的行为表明它们在动词的规则性方面具有一定程度的符号学习。此外，模型之间存在微弱的相关性。

    There is an ongoing debate on whether neural networks can grasp the quasi-regularities in languages like humans. In a typical quasi-regularity task, English past tense inflections, the neural network model has long been criticized that it learns only to generalize the most frequent pattern, but not the regular pattern, thus can not learn the abstract categories of regular and irregular and is dissimilar to human performance. In this work, we train a set of transformer models with different settings to examine their behavior on this task. The models achieved high accuracy on unseen regular verbs and some accuracy on unseen irregular verbs. The models' performance on the regulars is heavily affected by type frequency and ratio but not token frequency and ratio, and vice versa for the irregulars. The different behaviors on the regulars and irregulars suggest that the models have some degree of symbolic learning on the regularity of the verbs. In addition, the models are weakly correlated 
    
[^81]: KALM: 知识感知的本地、文档和全局背景集成，用于长文档理解

    KALM: Knowledge-Aware Integration of Local, Document, and Global Contexts for Long Document Understanding. (arXiv:2210.04105v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04105](http://arxiv.org/abs/2210.04105)

    KALM是一种知识感知语言模型，可以在本地、文档级别和全局语境中联合利用知识，用于长文档理解。

    

    随着预训练语言模型 (LMs) 的出现，越来越多的研究工作集中于将常识和领域特定知识注入到 LMs 中以准备下游任务。这些工作试图利用知识图谱，即符号知识表示的事实标准，以及预训练 LMs。尽管现有方法已经利用了外部知识，但目前如何共同结合代表不同语境的知识图谱，从本地 (例如，句子)、文档级别、全局知识等方面进行知识丰富的交换仍然是一个开放的问题。这样的丰富语境化对于长文档理解任务尤其有益，因为标准预先训练的 LMs 通常受限于输入序列长度。考虑到这些挑战，我们提出了 KALM，一种知识感知语言模型，它联合利用本地、文档级别和全局语境中的知识，用于长文档理解。

    With the advent of pretrained language models (LMs), increasing research efforts have been focusing on infusing commonsense and domain-specific knowledge to prepare LMs for downstream tasks. These works attempt to leverage knowledge graphs, the de facto standard of symbolic knowledge representation, along with pretrained LMs. While existing approaches have leveraged external knowledge, it remains an open question how to jointly incorporate knowledge graphs representing varying contexts, from local (e.g., sentence), to document-level, to global knowledge, to enable knowledge-rich exchange across these contexts. Such rich contextualization can be especially beneficial for long document understanding tasks since standard pretrained LMs are typically bounded by the input sequence length. In light of these challenges, we propose KALM, a Knowledge-Aware Language Model that jointly leverages knowledge in local, document-level, and global contexts for long document understanding. KALM first en
    
[^82]: CCC-wav2vec 2.0：基于聚类的交叉对比自监督学习语音表示的方法

    CCC-wav2vec 2.0: Clustering aided Cross Contrastive Self-supervised learning of speech representations. (arXiv:2210.02592v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.02592](http://arxiv.org/abs/2210.02592)

    本论文提出了一种基于聚类的交叉对比自监督学习语音表示的方法，引入了增强散度、交叉对比损失和聚类模块，相对于wav2vec 2.0基线在LibriSpeech测试集上取得了超过12%的WER改进。

    

    在利用大量未标注数据的情况下，自监督学习已经帮助我们从中受益。本文提出了一种新的预训练策略，即ccc-wav2vec 2.0，该策略使用聚类和基于增强的交叉对比损失作为其自监督目标。通过聚类模块，我们降低了与正样本高度相似的负样本的影响。交叉对比损失在原始样本的编码器输出和其增强版的量化器输出之间以及反之计算，从而为预训练策略带来了鲁棒性。ccc-wav2vec 2.0在LibriSpeech的测试-干净集和测试-其他集上相对于wav2vec 2.0基线分别取得了15.6％和12.7％的相对WER改进，而不需要任何语言模型。当在Switchboard上微调时，该方法还可以相对于wav2vec 2.0基线取得高达14.9％的相对WER改进。

    While Self-Supervised Learning has helped reap the benefit of the scale from the available unlabeled data, the learning paradigms are continuously being bettered. We present a new pre-training strategy named ccc-wav2vec 2.0, which uses clustering and an augmentation-based cross-contrastive loss as its self-supervised objective. Through the clustering module, we scale down the influence of those negative examples that are highly similar to the positive. The Cross-Contrastive loss is computed between the encoder output of the original sample and the quantizer output of its augmentation and vice-versa, bringing robustness to the pre-training strategy. ccc-wav2vec 2.0 achieves up to 15.6% and 12.7% relative WER improvement over the baseline wav2vec 2.0 on the test-clean and test-other sets, respectively, of LibriSpeech, without the use of any language model. The proposed method also achieves up to 14.9% relative WER improvement over the baseline wav2vec 2.0 when fine-tuned on Switchboard d
    
[^83]: 预训练语言模型为什么更适合零样本学习？

    What Makes Pre-trained Language Models Better Zero-shot Learners?. (arXiv:2209.15206v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.15206](http://arxiv.org/abs/2209.15206)

    本文提出一个理论框架来解释prompt learning在零样本/少样本场景下的有效性，并基于此提出了一个注释无关的模板选择方法。

    

    本文提出了一个理论框架来解释prompt learning在零样本/少样本场景下的有效性。首先，我们证明传统的预训练和微调范式在少样本场景下会因为过拟合不具代表性的标注数据而失败。然后，我们详细阐述了prompt learning更有效的假设，因为它使建立在海量文本语料库和领域相关人类知识的预训练语言模型可以更多地参与预测，从而减少小型训练集提供的有限标签信息的影响。我们进一步假设，语言差异可以衡量提示质量。我们进行了全面的实验证明了我们的假设。更为重要的是，受到理论框架的启发，我们提出了一种基于困惑度的注释无关的模板选择方法，可以事先“预测”提示性能。这种方法特别值得鼓励。

    In this paper, we propose a theoretical framework to explain the efficacy of prompt learning in zero/few-shot scenarios. First, we prove that conventional pre-training and fine-tuning paradigm fails in few-shot scenarios due to overfitting the unrepresentative labelled data. We then detail the assumption that prompt learning is more effective because it empowers pre-trained language model that is built upon massive text corpora, as well as domain-related human knowledge to participate more in prediction and thereby reduces the impact of limited label information provided by the small training set. We further hypothesize that language discrepancy can measure the quality of prompting. Comprehensive experiments are performed to verify our assumptions. More remarkably, inspired by the theoretical framework, we propose an annotation-agnostic template selection method based on perplexity, which enables us to ``forecast'' the prompting performance in advance. This approach is especially encou
    
[^84]: 通过 Switched Back-translation 对多语言神经机器翻译进行双向升级的多语言协议

    Revamping Multilingual Agreement Bidirectionally via Switched Back-translation for Multilingual Neural Machine Translation. (arXiv:2209.13940v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.13940](http://arxiv.org/abs/2209.13940)

    提出了一种名为 BMA-SBT 的新型通用多语言协议框架，通过使用 switched BT 方法，使得不需要平行数据就可以建立多语言协议，同时使用 Kullback-Leibler 散度损失双向优化协议，在 MNMT 任务上明显改善了强基线的效果。

    

    尽管多语言协议 (MA) 在多语言神经机器翻译 (MNMT) 中显示出其重要性，但当前领域中的方法存在两个缺点：(i)需要多个语言对之间的平行数据，这并不总是现实，并且(ii)在一个模棱两可的方向上优化协议，这会妨碍翻译的性能。我们提出了一种全新的通用多语言协议框架，名为经由 Switched Back-translation 的双向多语言协议 (BMA-SBT)，用于微调预训练的 MNMT 模型，它通过使用一种名为 switched BT 的新方法，在另一种源语言中创建用于翻译目标的合成文本，使得不需要前述的平行数据，并使用 Kullback-Leibler 散度损失双向优化协议。实验表明，BMA-SBT 在 MNMT 任务上明显改善了强基线的效果。

    Despite the fact that multilingual agreement (MA) has shown its importance for multilingual neural machine translation (MNMT), current methodologies in the field have two shortages: (i) require parallel data between multiple language pairs, which is not always realistic and (ii) optimize the agreement in an ambiguous direction, which hampers the translation performance. We present \textbf{B}idirectional \textbf{M}ultilingual \textbf{A}greement via \textbf{S}witched \textbf{B}ack-\textbf{t}ranslation (\textbf{BMA-SBT}), a novel and universal multilingual agreement framework for fine-tuning pre-trained MNMT models, which (i) exempts the need for aforementioned parallel data by using a novel method called switched BT that creates synthetic text written in another source language using the translation target and (ii) optimizes the agreement bidirectionally with the Kullback-Leibler Divergence loss. Experiments indicate that BMA-SBT clearly improves the strong baselines on the task of MNMT 
    
[^85]: 重新思考机器翻译评估的往返翻译方法

    Rethinking Round-Trip Translation for Machine Translation Evaluation. (arXiv:2209.07351v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.07351](http://arxiv.org/abs/2209.07351)

    本文研究了往返翻译方法在机器翻译评估中的应用，发现去除统计机器翻译中的复制机制后，往返翻译可以恰当地反映前向翻译的性能，该方法可以在低资源语言的情况下进行自动评估。

    

    在低资源语言翻译的自动评估中存在平行语料库的不足。往返翻译可以作为一种巧妙且简单的技术来缓解平行评估语料库的需求。然而，在统计机器翻译 (SMT) 时代，前向翻译和往返翻译的评估得分之间存在着模糊的相关性观察。在本文中，我们报告了一个惊人的发现：往返翻译可以用于自动评估而不需要参考文献。首先，我们重新审视了 SMT 评估中的往返翻译，揭示了其长期存在的误解实质上是由复制机制引起的。在去除SMT中的复制机制后，往返翻译评分可以恰当地反映前向翻译的性能。然后，我们证明了修正是过期的，因为往返翻译可以从多个机器翻译评估任务中受益。

    Automatic evaluation on low-resource language translation suffers from a deficiency of parallel corpora. Round-trip translation could be served as a clever and straightforward technique to alleviate the requirement of the parallel evaluation corpus. However, there was an observation of obscure correlations between the evaluation scores by forward and round-trip translations in the era of statistical machine translation (SMT). In this paper, we report the surprising finding that round-trip translation can be used for automatic evaluation without the references. Firstly, our revisit on the round-trip translation in SMT evaluation unveils that its long-standing misunderstanding is essentially caused by copying mechanism. After removing copying mechanism in SMT, round-trip translation scores can appropriately reflect the forward translation performance. Then, we demonstrate the rectification is overdue as round-trip translation could benefit multiple machine translation evaluation tasks. T
    
[^86]: 面向法律领域的预训练语言模型研究：以印度法律为例

    Pre-trained Language Models for the Legal Domain: A Case Study on Indian Law. (arXiv:2209.06049v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.06049](http://arxiv.org/abs/2209.06049)

    本研究针对印度法律文本，重新训练和从零开始训练了两个PLMs，即LegalBERT和CaseLawBERT，并采用基于印度法律文本的词汇表训练了一个模型。我们在几项基准法律NLP任务中，对印度和非印度的法律文本进行了应用。

    

    随着基于Transformer预训练语言模型（PLMs）在法律领域中应用的增多，特别是在欧美法律文本方面，PLMs获得了显著的成功。然而，印度等其他国家的法律文本具有很多特殊特征，因此也需要在这些方面进行预训练。本文尝试在印度法律领域进行预训练。我们在印度法律数据上重新训练（继续预训练）了两个流行的法律PLMs, LegalBERT和CaseLawBERT，以及使用基于印度法律文本的词汇表从零开始训练了一个模型。我们将这些PLMs应用于三个基准法律NLP任务——从事实中识别法律法规、对法院判决文件进行语义分割，以及预测法院上诉判决--在印度和非印度的文本上。

    NLP in the legal domain has seen increasing success with the emergence of Transformer-based Pre-trained Language Models (PLMs) pre-trained on legal text. PLMs trained over European and US legal text are available publicly; however, legal text from other domains (countries), such as India, have a lot of distinguishing characteristics. With the rapidly increasing volume of Legal NLP applications in various countries, it has become necessary to pre-train such LMs over legal text of other countries as well. In this work, we attempt to investigate pre-training in the Indian legal domain. We re-train (continue pre-training) two popular legal PLMs, LegalBERT and CaseLawBERT, on Indian legal data, as well as train a model from scratch with a vocabulary based on Indian legal text. We apply these PLMs over three benchmark legal NLP tasks -Legal Statute Identification from facts, Semantic Segmentation of Court Judgment Documents, and Court Appeal Judgment Prediction -- over both Indian and non-
    
[^87]: StoryTrans: 带语篇表示和内容增强的非平行故事作者风格转换

    StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing. (arXiv:2208.13423v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.13423](http://arxiv.org/abs/2208.13423)

    本文提出了StoryTrans模型，用于解决非平行故事作者风格转换的任务。该模型利用语篇表示和可学习的风格嵌入实现源内容信息到目标风格的转换，并引入了一个内容增强模块以提高语义一致性。在两个数据集上的评测中，该模型表现出了显著的性能优势。

    

    非平行文本风格转换是自然语言生成中的重要任务。然而，以往的研究集中在单词或句子级别上，例如句子情感和形式转换，但忽略了在语篇级别上较长的风格转换。长文本通常涉及更为复杂的作者语言偏好，例如语篇结构。本文提出了非平行故事作者风格转换的任务，需要将输入故事转换为指定作者的风格，同时保持源语义。为了解决这个问题，我们提出了一个生成模型，名为StoryTrans，它利用语篇表示来捕捉源内容信息，并使用可学习风格嵌入将它们转换为目标风格。我们使用了额外的训练目标来将风格特征从学习的语篇表示中解开，以防止模型退化为自动编码器。此外，为了强化内容保留，我们引入了一个内容增强模块，改善了输入和输出故事之间的语义一致性。两个数据集上的实验结果表明，我们提出的模型在自动指标和人类评估方面均优于最先进的基线模型。

    Non-parallel text style transfer is an important task in natural language generation. However, previous studies concentrate on the token or sentence level, such as sentence sentiment and formality transfer, but neglect long style transfer at the discourse level. Long texts usually involve more complicated author linguistic preferences such as discourse structures than sentences. In this paper, we formulate the task of non-parallel story author-style transfer, which requires transferring an input story into a specified author style while maintaining source semantics. To tackle this problem, we propose a generation model, named StoryTrans, which leverages discourse representations to capture source content information and transfer them to target styles with learnable style embeddings. We use an additional training objective to disentangle stylistic features from the learned discourse representation to prevent the model from degenerating to an auto-encoder. Moreover, to enhance content pr
    
[^88]: 基于模板化时间适应的动态上下文词嵌入学习方法

    Learning Dynamic Contextualised Word Embeddings via Template-based Temporal Adaptation. (arXiv:2208.10734v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.10734](http://arxiv.org/abs/2208.10734)

    本文提出一种基于时间适应的动态上下文词嵌入学习方法，使用感知时间的模板生成提示，通过微调预训练的MLM得到DCWE，实验结果表明该方法在困惑度和下游任务上优于现有方法。

    

    动态上下文词嵌入（DCWE）表示单词的语义随时间的变化。本文提出了一种使用感知时间的模板学习预训练掩蔽语言模型（MLM）得到DCWE的方法。本文首先提出一种无监督方法，通过选择与$C_1$和$C_2$相关的“枢轴”（pivot）术语和在各个快照中与特定枢轴术语相关的“锚”（anchor）术语来生成提示。然后，本文提出了一种自动学习时间敏感的模板的方法，从$C_1$和$C_2$中进行学习，无需任何人工监督。接下来，本文使用这些生成的提示通过微调来适应预训练的MLM到$T_2$。多个实验证明，我们的方法在超过强基线9.2点的同时降低了$C_1$测试句子的困惑度，优于现有的动态上下文词嵌入方法。此外，我们还证明了我们的方法对情感分析和命名实体识别等下游任务是有用的。

    Dynamic contextualised word embeddings (DCWEs) represent the temporal semantic variations of words. We propose a method for learning DCWEs by time-adapting a pretrained Masked Language Model (MLM) using time-sensitive templates. Given two snapshots $C_1$ and $C_2$ of a corpus taken respectively at two distinct timestamps $T_1$ and $T_2$, we first propose an unsupervised method to select (a) \emph{pivot} terms related to both $C_1$ and $C_2$, and (b) \emph{anchor} terms that are associated with a specific pivot term in each individual snapshot. We then generate prompts by filling manually compiled templates using the extracted pivot and anchor terms. Moreover, we propose an automatic method to learn time-sensitive templates from $C_1$ and $C_2$, without requiring any human supervision. Next, we use the generated prompts to adapt a pretrained MLM to $T_2$ by fine-tuning using those prompts. Multiple experiments show that our proposed method reduces the perplexity of test sentences in $C_
    
[^89]: CASE：调整粗细粒度认知和情感的匹配以产生共情响应

    CASE: Aligning Coarse-to-Fine Cognition and Affection for Empathetic Response Generation. (arXiv:2208.08845v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.08845](http://arxiv.org/abs/2208.08845)

    本研究提出了用于共情对话生成的CASE模型，通过调整用户的粗细粒度的认知和情感的匹配，可以生成更具共情和信息性的响应。

    

    共情交流应该是共情认知和情感的有意识调整和交互的结果。然而，现有的共情对话模型通常只考虑情感方面或在认知和情感上单独处理，这限制了共情响应生成的能力。在本研究中，我们提出了用于共情对话生成的CASE模型。它首先建立在常识认知图和情感概念图的基础上，然后在粗细的两个层面上对用户的认知和情感进行匹配。通过自动和手动评估，我们证明CASE优于共情对话的最新基线，并且可以产生更具共情和信息性的响应。

    Empathetic conversation is psychologically supposed to be the result of conscious alignment and interaction between the cognition and affection of empathy. However, existing empathetic dialogue models usually consider only the affective aspect or treat cognition and affection in isolation, which limits the capability of empathetic response generation. In this work, we propose the CASE model for empathetic dialogue generation. It first builds upon a commonsense cognition graph and an emotional concept graph and then aligns the user's cognition and affection at both the coarse-grained and fine-grained levels. Through automatic and manual evaluation, we demonstrate that CASE outperforms state-of-the-art baselines of empathetic dialogues and can generate more empathetic and informative responses.
    
[^90]: 自动音频字幕和基于语言的音频检索

    Automated Audio Captioning and Language-Based Audio Retrieval. (arXiv:2207.04156v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2207.04156](http://arxiv.org/abs/2207.04156)

    该论文描述了在DCASE 2022比赛中参加了自动音频字幕和基于语言的音频检索两个子任务，并使用Clotho数据集进行了评估。对于这两个子任务，我们修改了基线模型，得到了良好的性能提升。

    

    本项目参加了DCASE 2022竞赛（任务6），其分为两个子任务：（1）自动音频字幕和（2）基于语言的音频检索。第一个子任务涉及为音频样本生成文本描述，而第二个子任务的目标是在固定数据集中查找与给定描述相匹配的音频样本。对于这两个子任务，使用了Clotho数据集。对于音频字幕，我们评估了BLEU1，BLEU2，BLEU3，ROUGEL，METEOR，CIDEr，SPICE和SPIDEr得分，而音频检索评估了R1，R5，R10和mARP10得分。我们进行了一些修改这些任务的基线模型的实验。我们针对自动音频字幕的最终架构接近于基线性能，而我们针对基于语言的音频检索的模型已超越了其对应模型。

    This project involved participation in the DCASE 2022 Competition (Task 6) which had two subtasks: (1) Automated Audio Captioning and (2) Language-Based Audio Retrieval. The first subtask involved the generation of a textual description for audio samples, while the goal of the second was to find audio samples within a fixed dataset that match a given description. For both subtasks, the Clotho dataset was used. The models were evaluated on BLEU1, BLEU2, BLEU3, ROUGEL, METEOR, CIDEr, SPICE, and SPIDEr scores for audio captioning and R1, R5, R10 and mARP10 scores for audio retrieval. We have conducted a handful of experiments that modify the baseline models for these tasks. Our final architecture for Automated Audio Captioning is close to the baseline performance, while our model for Language-Based Audio Retrieval has surpassed its counterpart.
    
[^91]: 预测Twitter对话线程中的仇恨强度

    Predicting Hate Intensity of Twitter Conversation Threads. (arXiv:2206.08406v3 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2206.08406](http://arxiv.org/abs/2206.08406)

    本文提出了DRAGNET++, 通过考虑对话线程的语义、传播结构和用户交互，以预测推文的回复链中可能存在的仇恨程度，并在两个公开数据集上的实验中表现出优越性能。该模型可为社交媒体平台提供在恶意对话升级之前识别和管理的工具。

    

    推文是在线社交媒体中最简洁的交流形式，一条推文有可能是对话中打造或破坏讨论的潜在媒介。在线仇恨言论比以往任何时候都更容易获得，阻止其传播对于社交媒体公司和用户来说是极为重要的，可以推进良好的交流方式。目前除了最近的一些研究外，大部分研究都专注于分类单个推文，而忽略了推文之间的对话线程/上下文。我们提出了DRAGNET++，旨在通过推文的回复链预测它可能带来的仇恨程度，同时考虑到对话线程的语义和传播结构以及线程中的用户交互。我们在两个公开数据集上的实验表明DRAGNET++的表现优于现有的方法，我们认为社交媒体平台可以利用我们提出的方法，预测和管理恶意对话。

    Tweets are the most concise form of communication in online social media, wherein a single tweet has the potential to make or break the discourse of the conversation. Online hate speech is more accessible than ever, and stifling its propagation is of utmost importance for social media companies and users for congenial communication. Most of the research barring a recent few has focused on classifying an individual tweet regardless of the tweet thread/context leading up to that point. One of the classical approaches to curb hate speech is to adopt a reactive strategy after the hate speech postage. The ex-post facto strategy results in neglecting subtle posts that do not show the potential to instigate hate speech on their own but may portend in the subsequent discussion ensuing in the post's replies. In this paper, we propose DRAGNET++, which aims to predict the intensity of hatred that a tweet can bring in through its reply chain in the future. It uses the semantic and propagating stru
    
[^92]: COOL：一种上下文观察器及其在问答和其他自然语言处理任务中的应用

    COOL, a Context Outlooker, and its Application to Question Answering and other Natural Language Processing Tasks. (arXiv:2204.09593v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.09593](http://arxiv.org/abs/2204.09593)

    COOL是一种上下文观察器，用于编码局部句法上下文，能够改进基于Transformer的模型在自然语言处理任务中的性能，包括问答。

    

    视觉上下文观察器通过添加一个局部注意力形式的观察注意力改进了视觉Transformer的性能。与计算机视觉和其他领域一样，在自然语言处理中，基于Transformer的模型构成了大多数处理任务的最先进技术。我们提出了一种自然语言处理的观察注意力机制COOL。COOL添加到基于Transformer的模型的自我注意力层之上，考虑单词的接近性和更多的成对约束，编码局部句法上下文。使用不同的基于Transformer的模型对COOL的实现进行比较实证性能评估，证实其在各种自然语言处理任务中改进基线模型的机会，包括问答。

    Vision outlooker improves the performance of vision transformers, which implements a self-attention mechanism by adding an outlook attention, a form of local attention.  In natural language processing, as has been the case in computer vision and other domains, transformer-based models constitute the state-of-the-art for most processing tasks. In this domain, too, many authors have argued and demonstrated the importance of local context.  We present an outlook attention mechanism, COOL, for natural language processing. COOL, added on top of the self-attention layers of a transformer-based model, encodes local syntactic context considering word proximity and more pair-wise constraints than dynamic convolution used by existing approaches.  A comparative empirical performance evaluation of an implementation of COOL with different transformer-based models confirms the opportunity for improvement over a baseline using the original models alone for various natural language processing tasks, i
    
[^93]: PADA: 基于剪枝的自监督语音表示学习领域自适应

    PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations. (arXiv:2203.16965v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.16965](http://arxiv.org/abs/2203.16965)

    本文提出了PADA方法，在自监督语音表示学习领域自适应方面加入剪枝策略，使用CD-TAW方法从精细调整的OOT模型中获得初始剪枝掩码，并取得良好效果。

    

    自监督语音表示学习模型可用于多种下游任务，但这些模型常常会出现对未标注数据来源领域的过拟合现象。为缓解这个问题，本文提出了PADA (Pruning Assisted Domain Adaptation)，并从经过大量OOT(Out-of-domain)数据预训练的模型中减去多余的权重，为目标领域的ASR微调腾出空间。可以通过各种剪枝策略来识别冗余权重，本文详细讨论了最近发现的Task-Agnostic和Task-Aware剪枝对PADA的影响，并提出了一种新的基于后者的剪枝范式，称为Cross-Domain Task-Aware Pruning(CD-TAW)。CD-TAW从精细调整的OOT模型中获得初始剪枝掩码，这使其与本文中讨论的剪枝策略截然不同。我们提出的PADA方法可以通过微调模型和利用剪枝技术来消除不必要的权重，从而提高自监督语音表示学习模型的泛化能力。使用CD-TAW剪枝策略可以显著提高模型性能。

    While self-supervised speech representation learning (SSL) models serve a variety of downstream tasks, these models have been observed to overfit to the domain from which the unlabelled data originates. To alleviate this issue, we propose PADA (Pruning Assisted Domain Adaptation) and zero out redundant weights from models pre-trained on large amounts of out-of-domain (OOD) data. Intuitively, this helps to make space for the target-domain ASR finetuning. The redundant weights can be identified through various pruning strategies which have been discussed in detail as a part of this work. Specifically, we investigate the effect of the recently discovered Task-Agnostic and Task-Aware pruning on PADA and propose a new pruning paradigm based on the latter, which we call Cross-Domain Task-Aware Pruning (CD-TAW). CD-TAW obtains the initial pruning mask from a well fine-tuned OOD model, which makes it starkly different from the rest of the pruning strategies discussed in the paper. Our proposed
    
[^94]: AxoNN: 一种异步、消息驱动的极规模深度学习并行框架

    AxoNN: An asynchronous, message-driven parallel framework for extreme-scale deep learning. (arXiv:2110.13005v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.13005](http://arxiv.org/abs/2110.13005)

    AxoNN是一种利用异步性和消息驱动执行调度每个GPU上神经网络操作的并行深度学习框架，将CPU内存作为冗余空间，降低GPU内存消耗，同时将每个GPU的参数数量增加4倍，从而减少了必需的GPU数量和训练时间。

    

    近年来，训练最先进的神经网络所需的存储器容量已远远超出现代硬件加速器的DRAM容量。这促使我们在大规模基于GPU的集群上开发高效算法并行训练这些神经网络。在现代GPU上，计算相对廉价，为了提取最大性能，设计和实现这些并行训练算法中极其高效的通信是至关重要的。本文介绍了AxoNN，一种利用异步性和消息驱动执行调度每个GPU上神经网络操作的并行深度学习框架，从而减少GPU空闲时间，最大化硬件效率。通过使用CPU内存作为冗余空间，在训练期间定期卸载数据，AxoNN能够将GPU内存消耗降低4倍。这使得我们能够将每个GPU的参数数量增加4倍，从而减少了必需的GPU数量和训练时间。

    In the last few years, the memory requirements to train state-of-the-art neural networks have far exceeded the DRAM capacities of modern hardware accelerators. This has necessitated the development of efficient algorithms to train these neural networks in parallel on large-scale GPU-based clusters. Since computation is relatively inexpensive on modern GPUs, designing and implementing extremely efficient communication in these parallel training algorithms is critical for extracting the maximum performance. This paper presents AxoNN, a parallel deep learning framework that exploits asynchrony and message-driven execution to schedule neural network operations on each GPU, thereby reducing GPU idle time and maximizing hardware efficiency. By using the CPU memory as a scratch space for offloading data periodically during training, AxoNN is able to reduce GPU memory consumption by four times. This allows us to increase the number of parameters per GPU by four times, thus reducing the amount 
    
[^95]: Uni-Encoder: 一种用于生成型对话系统的快速准确响应选择范例

    Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems. (arXiv:2106.01263v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2106.01263](http://arxiv.org/abs/2106.01263)

    论文提出一种新的响应选择范例Uni-Encoder，解决了Cross-Encoder多次编码相同上下文计算成本高和Poly-Encoder性能下降的问题。该范例在一次前向传递中对所有候选与上下文进行编码。

    

    样本与排序是现代生成型对话系统的关键解码策略，通过从生成的少量候选答案中选择一个答案来实现多样化和高质量的响应。当前最先进的排序方法主要使用称为交叉编码器的编码范例，该编码器分别对每个上下文-候选对进行编码，并根据其适应度得分对候选进行排序。然而，交叉编码器为每个候选重复编码相同的冗长上下文，导致计算成本高。Poly-Encoder通过减少上下文和候选之间的交互来解决上述问题，但代价是性能下降。在这项工作中，我们开发了一种新的范例，称为Uni-Encoder，它像交叉编码器一样完全关注每个候选对，同时像Poly-编码器一样只编码一次上下文。Uni-Encoder在一次前向传递中对所有候选与上下文进行编码。我们针对所有候选使用相同的位置嵌入。

    Sample-and-rank is a key decoding strategy for modern generation-based dialogue systems. It helps achieve diverse and high-quality responses by selecting an answer from a small pool of generated candidates. The current state-of-the-art ranking methods mainly use an encoding paradigm called Cross-Encoder, which separately encodes each context-candidate pair and ranks the candidates according to their fitness scores. However, Cross-Encoder repeatedly encodes the same lengthy context for each candidate, resulting in high computational costs. Poly-Encoder addresses the above problems by reducing the interaction between context and candidates, but with a price of performance drop. In this work, we develop a new paradigm called Uni-Encoder, that keeps the full attention over each pair as in Cross-Encoder while only encoding the context once, as in Poly-Encoder. Uni-Encoder encodes all the candidates with the context in one forward pass. We use the same positional embedding for all candidates
    
[^96]: Quinductor:基于通用依存语法的多语言数据驱动阅读理解问题生成方法

    Quinductor: a multilingual data-driven method for generating reading-comprehension questions using Universal Dependencies. (arXiv:2103.10121v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2103.10121](http://arxiv.org/abs/2103.10121)

    Quinductor是一种多语言数据驱动的阅读理解问题生成方法，使用依存树，适用于资源较少的语言，比之前文献报道的QG基线效果更好。

    

    我们提出了一种使用依存树生成阅读理解问题的多语言数据驱动方法。我们的方法提供了一个强大、大部分确定性和训练成本低廉的基线方法，适用于资源较少的语言。虽然仍需要特定语言的语料库，但其大小远远不及现代神经问答生成（QG）体系结构所需的大小。我们的方法超过了先前文献报道的QG基线，并在人类评估方面表现良好。

    We propose a multilingual data-driven method for generating reading comprehension questions using dependency trees. Our method provides a strong, mostly deterministic, and inexpensive-to-train baseline for less-resourced languages. While a language-specific corpus is still required, its size is nowhere near those required by modern neural question generation (QG) architectures. Our method surpasses QG baselines previously reported in the literature and shows a good performance in terms of human evaluation.
    
[^97]: 多任务注意力残差网络用于论述挖掘

    Multi-Task Attentive Residual Networks for Argument Mining. (arXiv:2102.12227v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2102.12227](http://arxiv.org/abs/2102.12227)

    本文提出了一种多任务注意力残差网络架构，通过利用集成方法、注意力机制和多任务学习，无需假设文档或论据结构，成功应用于多个论述挖掘任务中，成为了一种既通用又高性能的架构。

    

    本文探讨了多任务注意力残差网络在多个论述挖掘任务中的应用。我们提出了一种残差架构，利用了注意力、多任务学习，并使用集成方法，不对文档或论据结构做任何假设。我们在五个不同的用户生成评论、科学出版物和劝说性论文语料库上进行了广泛的实验评估。我们的结果表明，我们的方法是针对具有更高计算印记或特定于语料库设计的最先进架构的强有力的竞争对手，代表了通用性、性能精度和减少模型大小之间的有趣折衷。

    We explore the use of residual networks and neural attention for multiple argument mining tasks. We propose a residual architecture that exploits attention, multi-task learning, and makes use of ensemble, without any assumption on document or argument structure. We present an extensive experimental evaluation on five different corpora of user-generated comments, scientific publications, and persuasive essays. Our results show that our approach is a strong competitor against state-of-the-art architectures with a higher computational footprint or corpus-specific design, representing an interesting compromise between generality, performance accuracy and reduced model size.
    

