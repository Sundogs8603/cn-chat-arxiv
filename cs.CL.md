# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning](https://arxiv.org/abs/2403.17919) | 逐层重要性采样的新方法LISA在微调任务中表现出色，记忆成本低且优于传统方法。 |
| [^2] | [The Unreasonable Ineffectiveness of the Deeper Layers](https://arxiv.org/abs/2403.17887) | 层剪枝方法可以在流行的预训练语言模型中实现大部分层的移除而保持性能，同时使用参数高效的微调方法可以进一步减少计算资源，提高推断的内存和延迟。 |
| [^3] | [Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications](https://arxiv.org/abs/2403.17860) | 探索使用大型语言模型（LLMs）生成合成数据以减少NLP模型高置信度误分类问题的研究。 |
| [^4] | [ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages](https://arxiv.org/abs/2403.17859) | ChroniclingAmericaQA是一个基于历史美国报纸页面的大规模问答数据集，旨在推动QA和MRC任务的发展，并克服以往数据集的局限性。 |
| [^5] | [Verbing Weirds Language (Models): Evaluation of English Zero-Derivation in Five LLMs](https://arxiv.org/abs/2403.17856) | 这项研究是关于五个大型语言模型中对英语零派生的评估，首次研究了这类泛化的程度，通过设计了一个测试词汇-句法灵活性的任务来实现。 |
| [^6] | [Using Domain Knowledge to Guide Dialog Structure Induction via Neural Probabilistic Soft Logic](https://arxiv.org/abs/2403.17853) | 通过将领域知识注入生成神经模型的潜在空间，提出了Neural Probabilistic Soft Logic Dialogue Structure Induction (NEUPSL DSI)方法，用于引导对话结构识别，应对训练语料有限/嘈杂以及测试对话领域分布转变等问题。 |
| [^7] | [ArabicaQA: A Comprehensive Dataset for Arabic Question Answering](https://arxiv.org/abs/2403.17848) | ArabicaQA是第一个用于阿拉伯语机器阅读理解和开放领域问答的大规模数据集，引入了AraDPR密集段落检索模型和对大型语言模型（LLMs）进行的广泛基准测试，为阿拉伯语自然语言处理资源带来了重要进展。 |
| [^8] | [Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation](https://arxiv.org/abs/2403.17846) | 提出了一种用于语言驱动的机器人导航的分层开放词汇3D场景图映射方法，可以有效代表多层建筑并允许机器人在其中穿行。 |
| [^9] | [Graph Language Model (GLM): A new graph-based approach to detect social instabilities](https://arxiv.org/abs/2403.17816) | 提出了一种新的基于图的方法来提前预测重要的政治事件，通过自然语言处理、图论、团体分析和语义关系揭示数据中隐藏的预测信号 |
| [^10] | [Are Compressed Language Models Less Subgroup Robust?](https://arxiv.org/abs/2403.17811) | 压缩语言模型的影响不仅取决于模型大小，还取决于压缩方法，同时发现模型压缩并不总是会使在少数子群体上的性能变差。 |
| [^11] | [Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms](https://arxiv.org/abs/2403.17806) | 提出了一种新方法EAP-IG，旨在更好地保持电路的核心属性：忠实 |
| [^12] | [Improving Text-to-Image Consistency via Automatic Prompt Optimization](https://arxiv.org/abs/2403.17804) | 本文提出了一个 T2I 优化通过提示的框架 OPT2I，利用大型语言模型（LLM）来改进 T2I 模型中的提示-图像一致性。 |
| [^13] | [SciNews: From Scholarly Complexities to Public Narratives -- A Dataset for Scientific News Report Generation](https://arxiv.org/abs/2403.17768) | 科学新闻报道生成的自动化提高了学术见解的可访问性，该研究提出了一个包含学术出版物和相应科学新闻报道的数据集，用于探索自动生成科学新闻报道的可能性。 |
| [^14] | [Constructions Are So Difficult That Even Large Language Models Get Them Right for the Wrong Reasons](https://arxiv.org/abs/2403.17760) | 本文引入了一个具有大量词汇重叠的NLI挑战数据集，探讨了大型语言模型在处理特定结构时出现的失败现象，揭示了它们在区分特定结构时的不足之处。 |
| [^15] | [Can multiple-choice questions really be useful in detecting the abilities of LLMs?](https://arxiv.org/abs/2403.17752) | 多项选择题虽然被广泛用于评估大型语言模型，但在测试LLMs能力时存在一定局限性，特别是在需要长篇生成答案的情况下，我们发现LLMs在双语MCQs中表现出顺序敏感性。 |
| [^16] | [UCxn: Typologically Informed Annotation of Constructions Atop Universal Dependencies](https://arxiv.org/abs/2403.17748) | 为了处理UD树库中未标记的携带含义的语法构造，我们提出在UD注释中添加一个“UCxn”注释层，并在了解语言类型学的基础上比较跨语言的形态句法策略。 |
| [^17] | [Continual Few-shot Event Detection via Hierarchical Augmentation Networks](https://arxiv.org/abs/2403.17733) | 本文提出了基于分层增强网络的持续少样本事件检测框架，通过原型增强和对比增强解决了记忆先前事件类型和学习少样本中新事件类型的挑战。 |
| [^18] | [FastPerson: Enhancing Video Learning through Effective Video Summarization that Preserves Linguistic and Visual Contexts](https://arxiv.org/abs/2403.17727) | FastPerson提出了一种视频摘要化方法，考虑了讲座视频中的视觉和听觉信息，通过利用音频转录和屏幕上的图片和文字创建摘要视频，从而最大程度地减少了对学习者来说遗漏重要信息的风险。 |
| [^19] | [Enhanced Short Text Modeling: Leveraging Large Language Models for Topic Refinement](https://arxiv.org/abs/2403.17706) | 利用大型语言模型的先进能力，提出了一种名为“主题细化”的新方法，通过引入提示工程和消除离题词等方式改进短文本的主题建模质量，提高了主题的语义质量。 |
| [^20] | [Not All Similarities Are Created Equal: Leveraging Data-Driven Biases to Inform GenAI Copyright Disputes](https://arxiv.org/abs/2403.17691) | 本文介绍了一种利用GenAI模型的学习能力进行版权法律分析的新方法，为解决版权侵权纠纷提供了有力的工具 |
| [^21] | [Language Models for Text Classification: Is In-Context Learning Enough?](https://arxiv.org/abs/2403.17661) | 本研究通过对16个文本分类数据集的大规模评估研究，填补了现有研究缺乏对文本生成模型与提示技术与更传统的文本分类方法之间比较的理解。 |
| [^22] | [Intrinsic Subgraph Generation for Interpretable Graph based Visual Question Answering](https://arxiv.org/abs/2403.17647) | 该论文介绍了一种用于图像问答的可解释方法，通过内在生成子图来提供决策洞察，并在GQA数据集上取得了竞争性能。 |
| [^23] | [DANCER: Entity Description Augmented Named Entity Corrector for Automatic Speech Recognition](https://arxiv.org/abs/2403.17645) | DANCER提出了一种新颖的Description Augmented Named entity CorrEctoR（DANCER）模型，通过利用实体描述为自动语音识别中的NEC提供额外信息，帮助缓解NE列表中的音素混淆问题。 |
| [^24] | [REFeREE: A REference-FREE Model-Based Metric for Text Simplification](https://arxiv.org/abs/2403.17640) | REFeREE是一种基于模型的无参考文本简化度量标准，能够在预测文本质量方面表现出色，且无需在推理时使用参考简化。 |
| [^25] | [Mix-Initiative Response Generation with Dynamic Prefix Tuning](https://arxiv.org/abs/2403.17636) | 提出了一种使用动态前缀调整的混合倡议响应生成框架，解决了对话系统中的交叉污染问题，并能够在监督和非监督设置下学习倡议感知前缀。 |
| [^26] | ["You are an expert annotator": Automatic Best-Worst-Scaling Annotations for Emotion Intensity Modeling](https://arxiv.org/abs/2403.17612) | 自动标记情绪强度建模中的最佳-最差标度注释方法的性能表现 |
| [^27] | [Denoising Table-Text Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2403.17611) | 本文提出了一种Denosied Table-Text Retriever（DoTTeR）方法，通过利用去噪训练数据集和整合表级排名信息，解决了表格-文本开放领域问答中存在的假正标签影响和跨表格推理问题的挑战。 |
| [^28] | [Coimagining the Future of Voice Assistants with Cultural Sensitivity](https://arxiv.org/abs/2403.17599) | 探索日本非西方环境中共同设计VAs的价值，展示了文化敏感度的必要性。 |
| [^29] | [Towards a Zero-Data, Controllable, Adaptive Dialog System](https://arxiv.org/abs/2403.17582) | 该论文提出了一种从对话树生成数据的方法，可帮助训练出在合成数据上训练的代理达到与在人类数据上训练的模型相媲美的对话成功率。 |
| [^30] | [Task-Oriented Paraphrase Analytics](https://arxiv.org/abs/2403.17564) | 本文通过文献综述和提出分类法，探讨了释义任务的复杂性，并发现已知释义语料库中特定任务实例的分布差异很大。 |
| [^31] | [m3P: Towards Multimodal Multilingual Translation with Multimodal Prompt](https://arxiv.org/abs/2403.17556) | 通过引入视觉上下文作为通用的语言无关表示，该论文提出了一种利用多模态提示来指导多模态多语言神经机器翻译的框架，以实现对不同语言表示的对齐，并生成条件视觉-语言记忆进行翻译。 |
| [^32] | [RuBia: A Russian Language Bias Detection Dataset](https://arxiv.org/abs/2403.17553) | 本论文提出了一个针对俄语的偏见检测数据集RuBia，填补了多语言偏见评估范围的空白，对于测试大型语言模型在俄语中是否存在偏见具有重要意义。 |
| [^33] | [Naive Bayes-based Context Extension for Large Language Models](https://arxiv.org/abs/2403.17552) | 介绍了一种新颖的基于朴素贝叶斯的上下文扩展框架(NBCE)，能够通过显著扩展上下文大小使现有的大型语言模型(LLMs)执行上下文学习(ICL)以整合更多演示示例，而且不需要微调或依赖特定模型架构。 |
| [^34] | [Decoding excellence: Mapping the demand for psychological traits of operations and supply chain professionals through text mining](https://arxiv.org/abs/2403.17546) | 通过文本挖掘和社交网络分析，本研究提出了一种创新方法，以评估OM和SCM专业人员特定心理特质的市场需求。 |
| [^35] | [A Gaze-grounded Visual Question Answering Dataset for Clarifying Ambiguous Japanese Questions](https://arxiv.org/abs/2403.17545) | 提出了 GazeVQA 数据集，通过注视信息来澄清模糊问题，并提出了一种利用注视目标估计结果的方法以提高任务准确性。 |
| [^36] | [Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction](https://arxiv.org/abs/2403.17540) | 大型语言模型GPT-4在语法错误校正评估中表现优异，与人类判断有很高的相关性，凸显了在评估标准中流畅度的重要性。 |
| [^37] | [ILLUMINER: Instruction-tuned Large Language Models as Few-shot Intent Classifier and Slot Filler](https://arxiv.org/abs/2403.17536) | 使用指令调整模型的ILLUMINER方法在意图分类和槽位填充任务上表现出更高效的学习能力，并在槽位填充方面优于目前最先进的方法。 |
| [^38] | [Sparse Logistic Regression with High-order Features for Automatic Grammar Rule Extraction from Treebanks](https://arxiv.org/abs/2403.17534) | 提出一种新方法从树库中提取和探索显著的细粒度语法模式和潜在的句法语法规则，以创建易于理解的基于语料库的语法。 |
| [^39] | [Multilingual Sentence-T5: Scalable Sentence Encoders for Multilingual Applications](https://arxiv.org/abs/2403.17528) | 介绍了一个基于NLI的多语言句子嵌入模型Multilingual Sentence T5，通过低秩适应技术成功将模型规模扩展到57亿参数，并实现了优于先前方法的性能。 |
| [^40] | [Provably Secure Disambiguating Neural Linguistic Steganography](https://arxiv.org/abs/2403.17524) | 我们提出了一种名为SyncPool的新颖安全消除歧义方法，有效解决了神经语言隐写术中的分词模糊问题。 |
| [^41] | [MapGuide: A Simple yet Effective Method to Reconstruct Continuous Language from Brain Activities](https://arxiv.org/abs/2403.17516) | 本研究提出了一种直接比较预测文本嵌入的脑活动映射来指导文本重建的简单而有效方法，相比之前的间接方法显著提高了模型性能。 |
| [^42] | [Sharing the Cost of Success: A Game for Evaluating and Learning Collaborative Multi-Agent Instruction Giving and Following Policies](https://arxiv.org/abs/2403.17497) | 该研究提出了一种协作多智能体指导和跟随策略的游戏，通过对视觉和语言观察进行协调来评估玩家之间的交互努力，实验发现标准的PPO设置配合启发式合作行为能取得高成功率，神经网络合作伙伴配对可减少重复游戏时的合作努力。 |
| [^43] | [DGoT: Dynamic Graph of Thoughts for Scientific Abstract Generation](https://arxiv.org/abs/2403.17491) | 该论文提出了一种名为DGoT的动态思维图方法，通过动态调整图结构和降低模型推理成本，提高了在生成科学论文摘要任务中的性价比。 |
| [^44] | [KDMCSE: Knowledge Distillation Multimodal Sentence Embeddings with Adaptive Angular margin Contrastive Learning](https://arxiv.org/abs/2403.17486) | 该研究提出了一种名为KDMCSE的知识蒸馏多模态句子嵌入方法，能够在学习中继承教师模型的知识，准确区分正负实例并有效检测嘈杂和错误的负样本。 |
| [^45] | [Incorporating Exponential Smoothing into MLP: A Simple but Effective Sequence Model](https://arxiv.org/abs/2403.17445) | 将简单的指数平滑法与MLP结合，通过增加参数和复杂性，实现了与复杂S4模型可比较的结果 |
| [^46] | [Robust and Scalable Model Editing for Large Language Models](https://arxiv.org/abs/2403.17431) | 通过适当的提示方法，经过指令微调的大型语言模型可以高度控制上下文知识，并对无关上下文具有鲁棒性，提出了EREN（通过阅读笔记来编辑模型），以改善可扩展性。 |
| [^47] | [Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization](https://arxiv.org/abs/2403.17428) | 探讨了利用大型语言模型增强精神科访谈的方法，通过分析朝鲜叛逃者的咨询数据，研究LLMs在划分症状和总结压力因素和症状方面取得高性能。 |
| [^48] | [LM-Combiner: A Contextual Rewriting Model for Chinese Grammatical Error Correction](https://arxiv.org/abs/2403.17413) | LM-Combiner是一种用于中文语法错误校正的上下文重写模型，可以通过直接修改语法错误校正系统的过度校正来提高准确性和召回率。 |
| [^49] | [PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models](https://arxiv.org/abs/2403.17411) | PCToolkit是一个统一的即插即用解决方案，用于在大型语言模型中压缩提示，包括尖端的压缩器、多样的数据集和综合性能评估指标。 |
| [^50] | [Transcribing Bengali Text with Regional Dialects to IPA using District Guided Tokens](https://arxiv.org/abs/2403.17407) | 通过引入区域指导标记技术，本文提出了一种将孟加拉文本与地方方言转录为国际音标的方法，为模型提供了关于输入文本的地区方言信息，以理解与每个地区相关的独特音韵模式。 |
| [^51] | [ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity Recognition](https://arxiv.org/abs/2403.17385) | ELLEN是一种简单而强大的神经符号方法，将微调语言模型与语言规则相结合，在极其轻监督的情况下取得了非常强劲的命名实体识别性能。 |
| [^52] | [ChatGPT Rates Natural Language Explanation Quality Like Humans: But on Which Scales?](https://arxiv.org/abs/2403.17368) | 本研究探索了ChatGPT在不同尺度下与人类评估之间的一致性，并发现在较粗粒度的尺度上，ChatGPT与人类更加一致。 |
| [^53] | [Extracting Biomedical Entities from Noisy Audio Transcripts](https://arxiv.org/abs/2403.17363) | 本文介绍了一个新的生物医学领域数据集 BioASR-NER，旨在填补自动语音识别（ASR）和自然语言处理（NLP）之间的鸿沟，重点是从 Brief Test of Adult Cognition by Tel 中提取不良药物反应和实体提及。 |
| [^54] | [Bridging Textual and Tabular Worlds for Fact Verification: A Lightweight, Attention-Based Model](https://arxiv.org/abs/2403.17361) | 提出了一种简单而强大的模型，通过利用预训练模型和轻量级的基于注意力的机制，有效地利用不同数据类型之间的潜在连接，保留原始证据的上下文，确保预测准确性。 |
| [^55] | [Chain-of-Action: Faithful and Multimodal Question Answering through Large Language Models](https://arxiv.org/abs/2403.17359) | 提出了Chain-of-Action (CoA)框架，通过新颖的推理-检索机制和多参考忠实分数解决了当前QA应用中的不忠实幻觉和弱推理性能问题 |
| [^56] | [Disambiguate Entity Matching through Relation Discovery with Large Language Models](https://arxiv.org/abs/2403.17344) | 通过定义实体之间的关系，解决实体匹配中的歧义问题 |
| [^57] | [Language Models are Free Boosters for Biomedical Imaging Tasks](https://arxiv.org/abs/2403.17343) | 本研究揭示了基于残差的大型语言模型在生物医学成像任务中作为编码器的意想不到的有效性，利用冻结的变压器块进行直接处理视觉令牌，从而提高各种生物医学成像应用的性能。 |
| [^58] | [Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models](https://arxiv.org/abs/2403.17336) | 该论文系统化了关于大型语言模型越狱提示的存在形式，并衡量了它们的越狱潜力，以更好地理解语义上具有意义的越狱提示的威胁格局。 |
| [^59] | [JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset](https://arxiv.org/abs/2403.17319) | JMultiWOZ是第一个日语大规模多领域任务驱动对话数据集，通过评估与现有英语基准数据集相媲美的对话状态跟踪和回复生成能力，推动了日语任务驱动对话系统的研究与发展。 |
| [^60] | [Project MOSLA: Recording Every Moment of Second Language Acquisition](https://arxiv.org/abs/2403.17314) | 项目MOSLA通过纵向、多模态、多语言和受控数据集的创建，揭示了学习者随时间发展的语言能力的见解。 |
| [^61] | [Neural Multimodal Topic Modeling: A Comprehensive Evaluation](https://arxiv.org/abs/2403.17308) | 该论文对包含文本和图片的文档的多模态主题建模进行了全面评估，并提出了两种新颖的主题建模解决方案和两种新颖的评估指标，结果显示这些模型均能产生连贯且多样化的主题。 |
| [^62] | [HILL: Hierarchy-aware Information Lossless Contrastive Learning for Hierarchical Text Classification](https://arxiv.org/abs/2403.17307) | 提出了一种专为层次文本分类设计的信息无损对比学习方法HILL，旨在在对比样本中保留输入样本的语义和句法信息，并在学习过程中进行融合。 |
| [^63] | [Decoding Probing: Revealing Internal Linguistic Structures in Neural Language Models using Minimal Pairs](https://arxiv.org/abs/2403.17299) | 解码探测这种方法揭示了自监督语言模型在中间层捕获抽象的语言结构，揭示了语法的学习需要更多层次，而形态和语义/句法接口相关特征则更难捕获。 |
| [^64] | [InternLM2 Technical Report](https://arxiv.org/abs/2403.17297) | InternLM2是一个开源的大语言模型，在全面评估、长文本建模以及创新的预训练和优化技术下表现出色，超越了其前任模型。 |
| [^65] | [Common Ground Tracking in Multimodal Dialogue](https://arxiv.org/abs/2403.17284) | 本文提出了一种自动识别多模态对话中参与者共享信念以及正在讨论问题的方法。 |
| [^66] | [Automate Knowledge Concept Tagging on Math Questions with LLMs](https://arxiv.org/abs/2403.17281) | 本文探讨了使用大型语言模型（LLMs）自动化标记数学问题中的知识概念，以满足先进教育应用对问题概念标记的增长需求。 |
| [^67] | [A Hybrid Approach To Aspect Based Sentiment Analysis Using Transfer Learning](https://arxiv.org/abs/2403.17254) | 提出了一种使用迁移学习的混合方法，以解决基于方面的情感分析中手动注释数据集昂贵和耗时的问题 |
| [^68] | [TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models](https://arxiv.org/abs/2403.17246) | 该论文将经典规划和大型语言模型相结合，通过近似人类直觉，以实现多智能体任务规划。 |
| [^69] | [SPLICE: A Singleton-Enhanced PipeLIne for Coreference REsolution](https://arxiv.org/abs/2403.17245) | 本文通过结合现有的嵌套NER系统的预测提及和从OntoNotes句法树导出的特征，解决了在英语端到端神经指代消解中使用OntoNotes基准时单例提及跨度不足的问题，提出了一个名为SPLICE的两步神经提及和指代消解系统，并在OntoNotes测试集和域外OntoGUM语料库上对其性能进行了比较，结果表明重建的单例训练效果良好。 |
| [^70] | [The Role of $n$-gram Smoothing in the Age of Neural Networks](https://arxiv.org/abs/2403.17240) | 本文重新探讨了在神经语言模型时代古典$n$-gram平滑技术可能发挥的作用，并提出了将任何$n$-gram平滑技术转换为神经语言模型兼容正则化器的通用框架 |
| [^71] | [Making Sentence Embeddings Robust to User-Generated Content](https://arxiv.org/abs/2403.17220) | RoLASER是一个通过师生方法训练的鲁棒英文编码器，通过减少标准句子和UGC句子在嵌入空间中的距离，显著提高了LASER对自然和人工UGC数据的鲁棒性。 |
| [^72] | [Ontology Completion with Natural Language Inference and Concept Embeddings: An Analysis](https://arxiv.org/abs/2403.17216) | 本文介绍了使用自然语言推理和概念嵌入进行本体补全的新方法，并发现这两种方法互补，混合策略取得最佳效果。 |
| [^73] | [Extracting Social Support and Social Isolation Information from Clinical Psychiatry Notes: Comparing a Rule-based NLP System and a Large Language Model](https://arxiv.org/abs/2403.17199) | 比较了基于规则的自然语言处理系统和大型语言模型在从临床精神病学笔记中提取社会支持和社会孤立信息方面的效果，结果显示基于规则系统在两个医疗机构中都获得了更高的分数。 |
| [^74] | [GPT-4 Understands Discourse at Least as Well as Humans Do](https://arxiv.org/abs/2403.17196) | GPT-4在标准化语篇理解测试中表现出与人类相当的能力，尤其在推断未明确陈述信息方面显示出显著实力 |
| [^75] | [NUMTEMP: A real-world benchmark to verify claims with statistical and temporal expressions](https://arxiv.org/abs/2403.17169) | NUMTEMP是一个真实世界基准，专注于验证复杂的数字论点，量化了现有解决方案的局限性，并提供了一种解决真实世界数字论点验证挑战的方法。 |
| [^76] | [Reflecting the Male Gaze: Quantifying Female Objectification in 19th and 20th Century Novels](https://arxiv.org/abs/2403.17158) | 通过提出量化女性客体化的框架，发现19世纪和20世纪小说中存在男性视角系统性对象化女性角色的证据 |
| [^77] | [Task-Agnostic Detector for Insertion-Based Backdoor Attacks](https://arxiv.org/abs/2403.17155) | TABDet是一种任务无关的后门检测器，通过利用最终层logits和高效的池化技术，在多个自然语言处理任务中实现了统一的logit表示，展示了对传统任务特定方法的优越检测效果。 |
| [^78] | [Outcome-Constrained Large Language Models for Countering Hate Speech](https://arxiv.org/abs/2403.17146) | 该研究探索了利用大型语言模型生成受潜在对话结果限制的对话，以应对在线仇恨言论，通过构建对话结果分类器和提出整合方法，为在线环境中生成对抗性对话提供了新途径 |
| [^79] | [Guided Distant Supervision for Multilingual Relation Extraction Data: Adapting to a New Language](https://arxiv.org/abs/2403.17143) | 本文应用引导远程监督方法，为德语创建了最大的传记关系抽取数据集，同时发布了手动标注的评估数据集。 |
| [^80] | [MetaAligner: Conditional Weak-to-Strong Correction for Generalizable Multi-Objective Alignment of Language Models](https://arxiv.org/abs/2403.17141) | MetaAligner是第一个与策略无关且通用的多目标偏好对齐方法，通过将参数更新与策略模型解耦实现即插即用的对齐，并通过上下文学习实现未见目标的零冷启动偏好对齐 |
| [^81] | [Exploring the Generalization of Cancer Clinical Trial Eligibility Classifiers Across Diseases](https://arxiv.org/abs/2403.17135) | 本研究评估了癌症临床试验资格分类器在不同疾病间的泛化性能，发现在广泛癌症数据集上训练的模型可以处理非癌症试验的标准，但在某些情况下仍然存在困难。 |
| [^82] | [The Strong Pull of Prior Knowledge in Large Language Models and Its Impact on Emotion Recognition](https://arxiv.org/abs/2403.17125) | 大型语言模型在执行任务时依赖背景知识（先验知识），但无法完全整合与任务先验知识相矛盾的信息，影响了情绪识别等主观任务的表现水平。 |
| [^83] | [Grounding Language Plans in Demonstrations Through Counterfactual Perturbations](https://arxiv.org/abs/2403.17124) | 这项工作通过使用LLMs来指导多步演示中隐含的任务结构和约束的搜索，以及通过反事实干扰获得更广泛的演示状态空间覆盖。 |
| [^84] | [Attribute First, then Generate: Locally-attributable Grounded Text Generation](https://arxiv.org/abs/2403.17104) | 该论文提出了一种局部可归属的文本生成方法，通过“先增加属性，然后生成”的方式将生成过程分为内容选择、句子规划和序列句子生成三个步骤，以简化引用验证工作。 |
| [^85] | [LLM Agent Operating System](https://arxiv.org/abs/2403.16971) | 提出了一种将大型语言模型嵌入操作系统中的LLM代理操作系统，旨在优化资源分配、促进代理间上下文切换、实现并发执行以及为代理提供工具服务。 |
| [^86] | [Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators](https://arxiv.org/abs/2403.16950) | 在大型语言模型评估中，通过引入成对偏好搜索方法PAIRS，成功解决了LLMs与人类判断不一致的问题，并取得了优于直接打分的最先进性能。 |
| [^87] | [Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models](https://arxiv.org/abs/2403.16915) | 本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调，在专题文档检索中显著改善了效果。 |
| [^88] | [RU22Fact: Optimizing Evidence for Multilingual Explainable Fact-Checking on Russia-Ukraine Conflict](https://arxiv.org/abs/2403.16662) | 提出了一个基于大型语言模型的方法，用于自动检索和总结网络中的证据，构建了RU22Fact数据集，是关于2022年俄乌冲突的多语言可解释事实核查数据集，同时开发了端到端可解释的事实核查系统来验证声明并生成解释。 |
| [^89] | [Large Language Models in Biomedical and Health Informatics: A Bibliometric Review](https://arxiv.org/abs/2403.16303) | LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。 |
| [^90] | [Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling](https://arxiv.org/abs/2403.16248) | 大型语言模型作为主题建模的替代方法，能够生成相关主题标题并遵循人类指南来精细化和合并主题 |
| [^91] | [Exploiting Semantic Reconstruction to Mitigate Hallucinations in Vision-Language Models](https://arxiv.org/abs/2403.16167) | 通过准确定位和惩罚幻觉标记，ESREAL引入了一种新颖的无监督学习框架，通过语义重建来抑制生成幻觉，解决了视觉-语言模型中幻觉问题。 |
| [^92] | [STEntConv: Predicting Disagreement with Stance Detection and a Signed Graph Convolutional Network](https://arxiv.org/abs/2403.15885) | STEntConv利用用户立场建立了用户和命名实体的加权图，通过有符号图卷积网络预测Reddit帖子中的不同意见表达。 |
| [^93] | [Towards a \textbf{RAG}-based Summarization Agent for the Electron-Ion Collider](https://arxiv.org/abs/2403.15729) | 开发了一种面向电子离子对撞机的基于RAG的摘要生成代理，能够压缩信息并引用相关回复，为合作者提供重大优势 |
| [^94] | [Born With a Silver Spoon? Investigating Socioeconomic Bias in Large Language Models](https://arxiv.org/abs/2403.14633) | 本文调查了大型语言模型中是否存在社会经济偏见，引入了一个新的数据集SilverSpoon，并评估了这种偏见的程度以及随着模型大小的变化。 |
| [^95] | [A Multimodal Approach to Device-Directed Speech Detection with Large Language Models](https://arxiv.org/abs/2403.14438) | 探索了一种利用大型语言模型进行设备定向语音检测的多模态方法，相比于文本和音频模型，使用多模态信息能够显著提高相等错误率。 |
| [^96] | [A Design Space for Intelligent and Interactive Writing Assistants](https://arxiv.org/abs/2403.14117) | 通过提出一种设计空间，帮助研究人员和设计师在多维空间中检验和探索智能交互式写作助手的各种可能性。 |
| [^97] | [EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation](https://arxiv.org/abs/2403.13737) | EthioLLM为埃塞俄比亚五种语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）以及英语引入了多语言大型语言模型，并提出了一个新的基准数据集Ethiobenchmark，为各种下游自然语言处理任务评估了这些模型的性能。 |
| [^98] | [Motion Generation from Fine-grained Textual Descriptions](https://arxiv.org/abs/2403.13518) | 本文提出了一种从细粒度文本描述中生成运动的方法，构建了FineHumanML3D数据集，设计了FineMotionDiffuse模型，实验结果表明该模型表现出色。 |
| [^99] | [Hyacinth6B: A large language model for Traditional Chinese](https://arxiv.org/abs/2403.13334) | 为了解决大型语言模型通常存在的高硬件和计算需求，Hyacinth6B在模型轻量化和性能之间找到了平衡，采用LoRA方法进行参数高效微调。 |
| [^100] | [CLASSLA-web: Comparable Web Corpora of South Slavic Languages Enriched with Linguistic and Genre Annotation](https://arxiv.org/abs/2403.12721) | 本文介绍了一个涵盖南斯拉夫地区官方语言的高度可比较的网络语料库集合，采用先进的技术进行语言和文体标注，进一步增强了其可比较性。 |
| [^101] | [Fusing Domain-Specific Content from Large Language Models into Knowledge Graphs for Enhanced Zero Shot Object State Classification](https://arxiv.org/abs/2403.12151) | 大型语言模型与知识图谱结合，提高零样本对象状态分类性能 |
| [^102] | [Accelerating Scientific Discovery with Generative Knowledge Extraction, Graph-Based Representation, and Multimodal Intelligent Graph Reasoning](https://arxiv.org/abs/2403.11996) | 利用生成式人工智能和图算法加速科学发现，揭示论文之间的深入跨学科关系，并提出了新颖的材料设计。 |
| [^103] | [SelfIE: Self-Interpretation of Large Language Model Embeddings](https://arxiv.org/abs/2403.10949) | 提出了SelfIE框架，使大型语言模型能够自解释其嵌入，揭示内部推理，包括道德决策、提示注入和消除有害知识。 |
| [^104] | [Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction](https://arxiv.org/abs/2403.09963) | 本文调查了预训练语言模型在事实知识提取中存在的“提示偏见”，找到了不同类型提示的偏见程度，以及这种偏见对不同基准测试的影响，并提出了一种基于表示的方法来减轻这种提示偏见。 |
| [^105] | [Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation](https://arxiv.org/abs/2403.09738) | 大型语言模型作为生成式用户模拟器在对话推荐中展现出潜力，新的协议通过五个任务评估了语言模型模拟人类行为的准确程度，揭示了模型与人类行为的偏差，并提出了如何通过模型选择和提示策略减少这些偏差。 |
| [^106] | [Simple and Scalable Strategies to Continually Pre-train Large Language Models](https://arxiv.org/abs/2403.08763) | 通过简单和可扩展的学习率调整、重放数据的方法，可以在不重新训练的情况下，持续预训练大型语言模型以匹配完全重新训练时的性能。 |
| [^107] | [Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models](https://arxiv.org/abs/2403.08281) | 通过融合高度专业化的语言、代码和数学模型，提出了一种名为UltraFuser的融合框架，引入了标记级别的门控机制，并设计了两阶段训练策略，以同时在三个领域取得高性能。 |
| [^108] | [OffLanDat: A Community Based Implicit Offensive Language Dataset Generated by Large Language Model Through Prompt Engineering](https://arxiv.org/abs/2403.02472) | 介绍了一个通过提示工程生成的大型语言模型创建的社区基础隐式攻击性语言数据集OffLanDat，为38个不同目标群体提供数据。 |
| [^109] | [FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction](https://arxiv.org/abs/2403.02270) | 提出了一种基于自然语言推理和主张提取的摘要可信度评估指标 FENICE，解决了自动生成摘要中存在的事实不一致性问题。 |
| [^110] | [Decode Neural signal as Speech](https://arxiv.org/abs/2403.01748) | 本文在脑机接口领域探索了MEG信号的脑到文本转换，着重解决了以前主要集中在EEG上、使用“teacher-forcing”以及未完全自回归的问题。 |
| [^111] | [LocalTweets to LocalHealth: A Mental Health Surveillance Framework Based on Twitter Data](https://arxiv.org/abs/2402.13452) | 本研究提出了一个新的基于Twitter数据的框架LocalHealth，用于预测当地精神健康结果。通过与GPT3.5结合使用，该框架在MH监测中取得了显著的改进。 |
| [^112] | [Understanding the Effects of Noise in Text-to-SQL: An Examination of the BIRD-Bench Benchmark](https://arxiv.org/abs/2402.12243) | 研究深入分析了文本到SQL领域中的噪声对模型的影响，并发现在BIRD-Bench基准测试中存在大量问题和标准查询中的噪声，这会显著影响模型的性能。 |
| [^113] | [Deciphering the lmpact of Pretraining Data on Large Language Models through Machine Unlearning](https://arxiv.org/abs/2402.11537) | 通过对五个主要类别的预训练数据的48个数据集进行系统分析，研究了它们对大型语言模型性能的影响，并发现了一些“高影响数据”，如书籍，与模型能力相关联，为LLMs的优化提供了见解。 |
| [^114] | [Tandem Transformers for Inference Efficient LLMs](https://arxiv.org/abs/2402.08644) | 该论文提出了一种新的架构，称为串联Transformer，用于解决传统大型语言模型推断速度限制的问题。该架构通过将小型自回归模型和大模型以块模式结合起来，并让小模型关注大模型的丰富表示，从而显著提高了小模型的预测准确性。实验证明，在预训练数据集上，串联的PaLM2-Bison和PaLM2-Gecko相比独立的PaLM2-Gecko，在下一个词元预测准确性上提高了3.3%，并且相较于具有相似下游任务的PaLM2-Otter模型，加速比达到1.16倍。 |
| [^115] | [Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability](https://arxiv.org/abs/2401.18040) | 本研究旨在通过内在动机强化学习算法改进端到端多任务对话系统的训练和适应性。通过教授智能体一个内在奖励系统，可以加速训练并提高其判断行为质量的能力。 |
| [^116] | [Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?](https://arxiv.org/abs/2401.11911) | 该论文研究了大型语言模型如何合并生成和检索的上下文以提升开放领域问答，发现这些模型偏向于生成的上下文，即使它们提供了错误的信息。 |
| [^117] | [AI and Generative AI for Research Discovery and Summarization](https://arxiv.org/abs/2401.06795) | AI和生成式AI工具在研究发现和总结方面有重大影响，包括能够更快地找到相关文献和用简洁语言总结研究文章的要点。 |
| [^118] | [High-throughput Biomedical Relation Extraction for Semi-Structured Web Articles Empowered by Large Language Models](https://arxiv.org/abs/2312.08274) | 利用大型语言模型在半结构化网络文章中实现高通量生物医学关系提取，通过对LLMs的应用，结合外部语料库和世界知识，设计针对性的二元分类决策，取得良好的结果。 |
| [^119] | [Efficient Pre-training for Localized Instruction Generation of Videos](https://arxiv.org/abs/2311.15964) | 提出了一种名为Sieve-&-Swap的技术，通过自动筛选出不相关文本并用人类编写的说明替换文本转录，从而实现视频本地化指令生成的高效预训练。 |
| [^120] | [Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion](https://arxiv.org/abs/2311.09602) | 语言模型在预测情绪时主要不考虑情绪触发器，而是情绪触发器与各种特征和情绪检测任务之间存在错综复杂的相互作用。 |
| [^121] | [Measuring Entrainment in Spontaneous Code-switched Speech](https://arxiv.org/abs/2311.07703) | 研究发现人与人之间的混合语音自发语音中存在与书面和口语单语环境同步的模式，并且对话系统生成的文本中的代码切换同步模式在这种环境中也是普适的。 |
| [^122] | [First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models](https://arxiv.org/abs/2311.05020) | NLP研究人员在大型语言模型（LLMs）的新时代中，可以从历史中汲取教训，持续解决规模差异、数据瓶颈、现实评估等问题，同时还有空间尝试新的方法。 |
| [^123] | [Unveiling the Pitfalls of Knowledge Editing for Large Language Models](https://arxiv.org/abs/2310.02129) | 这篇论文探讨了大型语言模型知识编辑的潜在陷阱，提出了新的评估方法，发现知识冲突和知识扭曲是两个重要问题。 |
| [^124] | [Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic](https://arxiv.org/abs/2309.13339) | 提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。 |
| [^125] | [Spanish Resource Grammar version 2023](https://arxiv.org/abs/2309.13318) | 西班牙语资源语法（SRG）的最新版本引入了Freeling形态分析器，并附带一个经过手工验证的树库，为提高语义解析器的训练质量和其他系统带来便利。 |
| [^126] | [CrossLingR: A Comprehensive Multilingual Receipt Dataset for Cross-Language Information Extraction and Classification](https://arxiv.org/abs/2309.09800) | 本研究介绍了一个全面的多语言数据集CrossLingR，用于推动收据信息提取和物品分类的进展。我们的数据集包含了47,720个标注样本，详细记录了项目名称、相关属性和44个不同的产品类别。通过InstructLLaMA方法论，我们展示了在关键信息提取和物品分类任务中的显著效果。相关资源可在https://github.com/Update-For-Integrated-Business-AI/AMuRD上获取。 |
| [^127] | [Training BERT Models to Carry Over a Coding System Developed on One Corpus to Another](https://arxiv.org/abs/2308.03742) | 通过训练BERT模型，成功地将一个在匈牙利文学期刊上开发的编码系统传递到另一个语料库，用以跟踪在1989年匈牙利政治转型时期的文学翻译感知趋势，并展示了模型能够处理标签不平衡问题。 |
| [^128] | [Efficient Document Embeddings via Self-Contrastive Bregman Divergence Learning](https://arxiv.org/abs/2305.16031) | 通过引入自对比连体网络和神经布雷格曼网络，提高了文档嵌入的质量和效率。 |
| [^129] | [Exploring Representational Disparities Between Multilingual and Bilingual Translation Models](https://arxiv.org/abs/2305.14230) | 本文研究了多语模型和双语模型在表征中的几何差异，发现对于给定的语言对，多语模型的解码器表征在各向同性方面一贯较差，占用的维度也较少。 |
| [^130] | [Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot Learning](https://arxiv.org/abs/2303.15230) | 提出了一种适用于组合式零样本学习的Troika模型，通过建立三个识别分支共同对状态、对象和组合进行建模，在对齐分支特定提示表示和分解的视觉特征的同时，引入了Cross-Modal Traction模块来校准多模态表示之间的偏差。 |
| [^131] | [Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding](https://arxiv.org/abs/2207.01262) | 在标准收集的初步实验中，我们发现长文档模型在MRR或NDCG方面性能不佳，表现低于FirstP，或平均最多超越5％。我们推测这不是因为模型无法处理长上下文，而是由于相关段落具有位置偏见，往往位于前512个文档标记之中。我们找到证据表明这种偏见至少存在于两个测试集中，这促使我们创建了一个新的收集MS MARCO FarRelevant，其中包含 |
| [^132] | [Topic Detection and Tracking with Time-Aware Document Embeddings](https://arxiv.org/abs/2112.06166) | 设计了一种将时间和文本信息融合在新闻文档表示中的神经方法，用于事件检测。 |
| [^133] | [Learning Transfers over Several Programming Languages.](http://arxiv.org/abs/2310.16937) | 这篇论文研究了使用跨语言迁移学习提高编程语言模型性能的问题，并进行了广泛实验验证。该研究表明，跨语言迁移学习在编程语言领域具有潜力，可以帮助低资源语言的用户受益于大规模语言模型。 |
| [^134] | [Generative Pre-training for Speech with Flow Matching.](http://arxiv.org/abs/2310.16338) | 本文展示了一种使用流匹配的预训练生成模型，该模型可以适应不同的下游任务并获得强大的性能，通过在60k小时的未转录语音上进行预训练，该模型可以与现有的专家模型在语音增强、分离和合成方面进行匹配或超越。 |
| [^135] | [COPF: Continual Learning Human Preference through Optimal Policy Fitting.](http://arxiv.org/abs/2310.15694) | 通过COPF方法，我们不需要重新训练预训练语言模型，而是使用最优策略拟合和函数正则化来持续学习和适应人类偏好的变化。 |
| [^136] | [Visual Grounding Helps Learn Word Meanings in Low-Data Regimes.](http://arxiv.org/abs/2310.13257) | 在低数据环境中，使用视觉定位进行监督训练的神经语言模型可以更接近于人类的语言学习能力。 |
| [^137] | [Large Language Model for Multi-objective Evolutionary Optimization.](http://arxiv.org/abs/2310.12541) | 本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。 |
| [^138] | [Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts.](http://arxiv.org/abs/2309.14974) | 该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。 |
| [^139] | [Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit.](http://arxiv.org/abs/2309.11888) | 本文重新审视了同时解析短语结构树和依存树的方法，通过采用更高效的解码算法、在训练阶段进行联合建模、提出高阶评分组件以及进行深入实验和分析等四个方面的进展，展示了该方法的潜力和价值。 |
| [^140] | [Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences.](http://arxiv.org/abs/2309.06578) | 本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。 |
| [^141] | [BAN-PL: a Novel Polish Dataset of Banned Harmful and Offensive Content from Wykop.pl web service.](http://arxiv.org/abs/2308.10592) | BAN-PL是波兰语的第一个开放数据集，包含来自Wykop这个类似"波兰版Reddit"的社交网络服务的被标记为有害并删除的内容，将有助于改进自动检测互联网上的冒犯性语言的技术。 |
| [^142] | [GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher.](http://arxiv.org/abs/2308.06463) | 这项研究发现，通过使用密码进行聊天可以绕过大型语言模型（LLMs）的安全对齐技术。研究人员提出了一种名为CipherChat的框架，用于系统地检查安全对齐在非自然语言（密码）中的普适性，并通过实验评估了ChatGPT和GPT-4等最先进的LLMs对不同代表性人类密码在11个安全领域中的影响。 |
| [^143] | [Generator-Retriever-Generator: A Novel Approach to Open-domain Question Answering.](http://arxiv.org/abs/2307.11278) | 生成器-检索器-生成器（GRG）是一种新方法，将文档检索技术与大型语言模型相结合，以生成开放域问答的准确和信息丰富的答案。 |
| [^144] | [Othering and low prestige framing of immigrant cuisines in US restaurant reviews and large language models.](http://arxiv.org/abs/2307.07645) | 通过对2.1M英语Yelp评论的餐厅进行语言分析，研究发现移民美食更容易被构架为客观和他者化，而非西方移民美食受欢迎程度更高。 |
| [^145] | [Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration.](http://arxiv.org/abs/2307.05300) | 本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。 |
| [^146] | [Advancing Topic Segmentation and Outline Generation in Chinese Texts: The Paragraph-level Topic Representation, Corpus, and Benchmark.](http://arxiv.org/abs/2305.14790) | 本文提出了一种分层的段落级中文主题结构表示，使用句子而不是关键词来表示子主题，构建了大规模、高质量的中文段落级主题结构语料库。 |
| [^147] | [ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review.](http://arxiv.org/abs/2305.03123) | 本文研究关注ChatGPT面临的可持续性、隐私、数字鸿沟和伦理问题，提出了SPADE评估的必要性，并给出了缓解和建议。 |
| [^148] | [PWESuite: Phonetic Word Embeddings and Tasks They Facilitate.](http://arxiv.org/abs/2304.02541) | 本论文展示了一套语音单词嵌入及其相关任务，提高了语音信息处理的效果和可重复性。 |
| [^149] | [Does ChatGPT resemble humans in language use?.](http://arxiv.org/abs/2303.08014) | ChatGPT在大部分语言处理实验中与人类表现相似，能够产生人类一样的语言使用特征。但在两个实验中存在偏差，说明人类和机器语言处理之间仍存在重大差异。 |

# 详细

[^1]: LISA：用于高效内存大型语言模型微调的逐层重要性采样

    LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning

    [https://arxiv.org/abs/2403.17919](https://arxiv.org/abs/2403.17919)

    逐层重要性采样的新方法LISA在微调任务中表现出色，记忆成本低且优于传统方法。

    

    机器学习领域自大型语言模型（LLMs）首次出现以来取得了令人瞩目的进展，然而它们巨大的内存消耗已成为大规模训练的主要障碍。虽然已经提出了诸如低秩调整（LoRA）之类的参数高效微调技术来缓解这一问题，但在大多数大规模微调设置中，它们的性能仍无法与完整参数训练相匹配。为弥补这一不足，我们研究了LoRA在微调任务中的逐层特性，并观察到不同层之间权重范数的异常偏斜。利用这一关键观察，我们发现了一个令人惊讶简单的训练策略，在记忆成本低于LoRA的情况下，在广泛的设置中优于LoRA和完整参数训练。我们将其命名为Layerwise Importance Sampled AdamW（LISA），这是LoRA的一个有希望的替代方案，应用了

    arXiv:2403.17919v1 Announce Type: cross  Abstract: The machine learning community has witnessed impressive advancements since the first appearance of large language models (LLMs), yet their huge memory consumption has become a major roadblock to large-scale training. Parameter Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have been proposed to alleviate this problem, but their performance still fails to match full parameter training in most large-scale fine-tuning settings. Attempting to complement this deficiency, we investigate layerwise properties of LoRA on fine-tuning tasks and observe an uncommon skewness of weight norms across different layers. Utilizing this key observation, a surprisingly simple training strategy is discovered, which outperforms both LoRA and full parameter training in a wide range of settings with memory costs as low as LoRA. We name it Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA, which applies the idea of
    
[^2]: 深层神经网络层剪枝的不合理无效性

    The Unreasonable Ineffectiveness of the Deeper Layers

    [https://arxiv.org/abs/2403.17887](https://arxiv.org/abs/2403.17887)

    层剪枝方法可以在流行的预训练语言模型中实现大部分层的移除而保持性能，同时使用参数高效的微调方法可以进一步减少计算资源，提高推断的内存和延迟。

    

    我们在流行的预训练语言模型中进行了简单的层剪枝策略的实证研究，发现在移除大部分层（最高达一半）之前，不同问答基准测试的性能几乎没有受到影响。为了剪枝这些模型，我们通过考虑层间的相似性来确定最佳的剪枝层块；然后，为了“修复”损害，我们进行了少量微调。特别地，我们使用参数高效的微调（PEFT）方法，具体包括量化和低秩适配器（QLoRA），这样我们的每个实验都可以在单个A100 GPU上执行。从实际的角度来看，这些结果表明层剪枝方法可以补充其他PEFT策略，从而进一步减少微调的计算资源，另一方面可以提高推断的内存和延迟。从科学的角度来看，该研究表明深层神经网络在某种程度上具有鲁棒性，并且对模型的剪枝没有太大影响。

    arXiv:2403.17887v1 Announce Type: new  Abstract: We empirically study a simple layer-pruning strategy for popular families of open-weight pretrained LLMs, finding minimal degradation of performance on different question-answering benchmarks until after a large fraction (up to half) of the layers are removed. To prune these models, we identify the optimal block of layers to prune by considering similarity across layers; then, to "heal" the damage, we perform a small amount of finetuning. In particular, we use parameter-efficient finetuning (PEFT) methods, specifically quantization and Low Rank Adapters (QLoRA), such that each of our experiments can be performed on a single A100 GPU. From a practical perspective, these results suggest that layer pruning methods can complement other PEFT strategies to further reduce computational resources of finetuning on the one hand, and can improve the memory and latency of inference on the other hand. From a scientific perspective, the robustness of 
    
[^3]: 探究LLMs作为目标合成文本数据来源，以减少高置信度误分类

    Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications

    [https://arxiv.org/abs/2403.17860](https://arxiv.org/abs/2403.17860)

    探索使用大型语言模型（LLMs）生成合成数据以减少NLP模型高置信度误分类问题的研究。

    

    自然语言处理（NLP）模型经过优化以提高预测性能时，常常存在高置信度错误并容易受到对抗性和超出分布数据的影响。本研究探讨使用大型语言模型（LLMs）进行数据增强，作为解决NLP模型在分类任务中产生高置信度错误预测问题的潜在解决方案。我们比较了由LLMs生成的合成数据与通过相同过程获得的人工数据的有效性。为了减轻错误，人类或LLMs提供高置信度误分类的自然语言描述以生成合成数据，然后用于扩展训练集。我们对我们的方法在三个分类任务上进行了广泛评估，并展示了其在减少方面的有效性。

    arXiv:2403.17860v1 Announce Type: new  Abstract: Natural Language Processing (NLP) models optimized for predictive performance often make high confidence errors and suffer from vulnerability to adversarial and out-of-distribution data. Existing work has mainly focused on mitigation of such errors using either humans or an automated approach. In this study, we explore the usage of large language models (LLMs) for data augmentation as a potential solution to the issue of NLP models making wrong predictions with high confidence during classification tasks. We compare the effectiveness of synthetic data generated by LLMs with that of human data obtained via the same procedure. For mitigation, humans or LLMs provide natural language characterizations of high confidence misclassifications to generate synthetic data, which are then used to extend the training set. We conduct an extensive evaluation of our approach on three classification tasks and demonstrate its effectiveness in reducing the
    
[^4]: ChroniclingAmericaQA:基于历史美国报纸页面的大规模问答数据集

    ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages

    [https://arxiv.org/abs/2403.17859](https://arxiv.org/abs/2403.17859)

    ChroniclingAmericaQA是一个基于历史美国报纸页面的大规模问答数据集，旨在推动QA和MRC任务的发展，并克服以往数据集的局限性。

    

    arXiv:2403.17859v1公告类型：新问答（QA）和机器阅读理解（MRC）任务由于深度学习技术的快速发展以及最近的大语言模型而取得了显著进展。同时，许多基准数据集已经用于QA和MRC任务。然而，大多数现有的大规模基准数据集主要使用同步文档集合（如维基百科或网络）创建。档案文件集合，如历史报纸，包含过去的宝贵信息，但仍未被广泛用于训练大型语言模型。为了进一步推动QA和MRC任务的发展，并克服先前数据集的局限性，我们介绍了ChroniclingAmericaQA，这是一个基于历史报纸集Chronicling America创建的拥有485K问答对的大规模数据集。我们的数据集是从Chronicling Amer的子集构建的。

    arXiv:2403.17859v1 Announce Type: new  Abstract: Question answering (QA) and Machine Reading Comprehension (MRC) tasks have significantly advanced in recent years due to the rapid development of deep learning techniques and, more recently, large language models. At the same time, many benchmark datasets have become available for QA and MRC tasks. However, most existing large-scale benchmark datasets have been created predominantly using synchronous document collections like Wikipedia or the Web. Archival document collections, such as historical newspapers, contain valuable information from the past that is still not widely used to train large language models. To further contribute to advancing QA and MRC tasks and to overcome the limitation of previous datasets, we introduce ChroniclingAmericaQA, a large-scale dataset with 485K question-answer pairs created based on the historical newspaper collection Chronicling America. Our dataset is constructed from a subset of the Chronicling Amer
    
[^5]: 对五个大型语言模型中英语零派生进行评估

    Verbing Weirds Language (Models): Evaluation of English Zero-Derivation in Five LLMs

    [https://arxiv.org/abs/2403.17856](https://arxiv.org/abs/2403.17856)

    这项研究是关于五个大型语言模型中对英语零派生的评估，首次研究了这类泛化的程度，通过设计了一个测试词汇-句法灵活性的任务来实现。

    

    词汇-句法的灵活性，以转换（或零派生）的形式出现，是英语形态学的一个标志。在转换中，一个词与一个词性被放置在一个非典型的上下文中，被迫表现得好像它有一个不同的词性。然而，虽然这一过程影响了英语词汇的一大部分，但很少有工作着手确定语言模型到底捕捉到了这种泛化的程度。本文首次报道了关于大型语言模型行为与转换之间关系的研究。我们设计了一个用于测试词汇-句法灵活性的任务，即模型能够在一个非典型词性构造的词上进行推广的程度。这个任务位于自然语言推理范式之内。我们测试了五个语言模型的能力：两个专有模型（GPT-3.5 和 GPT-4）、三个开源模型（Mistral 7B、Falcon 40B 等）

    arXiv:2403.17856v1 Announce Type: new  Abstract: Lexical-syntactic flexibility, in the form of conversion (or zero-derivation) is a hallmark of English morphology. In conversion, a word with one part of speech is placed in a non-prototypical context, where it is coerced to behave as if it had a different part of speech. However, while this process affects a large part of the English lexicon, little work has been done to establish the degree to which language models capture this type of generalization. This paper reports the first study on the behavior of large language models with reference to conversion. We design a task for testing lexical-syntactic flexibility -- the degree to which models can generalize over words in a construction with a non-prototypical part of speech. This task is situated within a natural language inference paradigm. We test the abilities of five language models -- two proprietary models (GPT-3.5 and GPT-4), three open-source models (Mistral 7B, Falcon 40B, and
    
[^6]: 利用领域知识通过神经概率软逻辑引导对话结构识别

    Using Domain Knowledge to Guide Dialog Structure Induction via Neural Probabilistic Soft Logic

    [https://arxiv.org/abs/2403.17853](https://arxiv.org/abs/2403.17853)

    通过将领域知识注入生成神经模型的潜在空间，提出了Neural Probabilistic Soft Logic Dialogue Structure Induction (NEUPSL DSI)方法，用于引导对话结构识别，应对训练语料有限/嘈杂以及测试对话领域分布转变等问题。

    

    对话结构识别（DSI）是推断给定目标导向对话的潜在对话结构（即一组对话状态及其时间转换）的任务。这是现代对话系统设计和话语分析的关键组成部分。本文探讨了一种神经符号方法作为这些问题的潜在解决方案。我们介绍了一种称为神经概率软逻辑对话结构识别（NEUPSL DSI）的原则性方法，该方法将符号知识注入生成神经模型的潜在空间。我们进行了关于NEUPSL DSI学习对隐藏表示质量的影响的彻底实证调查。

    arXiv:2403.17853v1 Announce Type: new  Abstract: Dialog Structure Induction (DSI) is the task of inferring the latent dialog structure (i.e., a set of dialog states and their temporal transitions) of a given goal-oriented dialog. It is a critical component for modern dialog system design and discourse analysis. Existing DSI approaches are often purely data-driven, deploy models that infer latent states without access to domain knowledge, underperform when the training corpus is limited/noisy, or have difficulty when test dialogs exhibit distributional shifts from the training domain. This work explores a neural-symbolic approach as a potential solution to these problems. We introduce Neural Probabilistic Soft Logic Dialogue Structure Induction (NEUPSL DSI), a principled approach that injects symbolic knowledge into the latent space of a generative neural model. We conduct a thorough empirical investigation on the effect of NEUPSL DSI learning on hidden representation quality, few-shot 
    
[^7]: ArabicaQA：一个用于阿拉伯语问答的综合数据集

    ArabicaQA: A Comprehensive Dataset for Arabic Question Answering

    [https://arxiv.org/abs/2403.17848](https://arxiv.org/abs/2403.17848)

    ArabicaQA是第一个用于阿拉伯语机器阅读理解和开放领域问答的大规模数据集，引入了AraDPR密集段落检索模型和对大型语言模型（LLMs）进行的广泛基准测试，为阿拉伯语自然语言处理资源带来了重要进展。

    

    在本文中，我们通过引入ArabicaQA解决了阿拉伯语自然语言处理资源中的巨大缺口，这是第一个用于阿拉伯语机器阅读理解和开放领域问答的大规模数据集。这个综合数据集由众包工作者创建，包括89,095个可回答的问题和3,701个不可回答的问题，看起来与可回答的问题类似，还附带了额外的开放领域问题标签，标志着阿拉伯语自然语言处理资源的重要进步。我们还介绍了AraDPR，这是第一个在阿拉伯维基百科语料库上训练的密集段落检索模型，专门设计用于解决阿拉伯文本检索的独特挑战。此外，我们的研究还包括对大型语言模型（LLMs）在阿拉伯语问答中的广泛基准测试，批判性地评估它们在阿拉伯语境中的性能。总之，ArabicaQA、AraDPR以及LLMs在阿拉伯语问答中的基准测试等工作将促进阿拉伯语自然语言处理领域的发展。

    arXiv:2403.17848v1 Announce Type: new  Abstract: In this paper, we address the significant gap in Arabic natural language processing (NLP) resources by introducing ArabicaQA, the first large-scale dataset for machine reading comprehension and open-domain question answering in Arabic. This comprehensive dataset, consisting of 89,095 answerable and 3,701 unanswerable questions created by crowdworkers to look similar to answerable ones, along with additional labels of open-domain questions marks a crucial advancement in Arabic NLP resources. We also present AraDPR, the first dense passage retrieval model trained on the Arabic Wikipedia corpus, specifically designed to tackle the unique challenges of Arabic text retrieval. Furthermore, our study includes extensive benchmarking of large language models (LLMs) for Arabic question answering, critically evaluating their performance in the Arabic language context. In conclusion, ArabicaQA, AraDPR, and the benchmarking of LLMs in Arabic question
    
[^8]: 基于语言驱动的机器人导航的分层开放词汇3D场景图

    Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation

    [https://arxiv.org/abs/2403.17846](https://arxiv.org/abs/2403.17846)

    提出了一种用于语言驱动的机器人导航的分层开放词汇3D场景图映射方法，可以有效代表多层建筑并允许机器人在其中穿行。

    

    最近的开放词汇机器人映射方法利用预先训练的视觉-语言特征丰富了密集几何地图。虽然这些地图允许在查询某种语言概念时预测逐点显著性地图，但大规模环境和超出对象级别的抽象查询仍然是一个相当大的障碍，最终限制了基于语言的机器人导航。在这项工作中，我们提出了HOV-SG，一种用于语言驱动的机器人导航的分层开放词汇3D场景图映射方法。通过利用开放词汇视觉基础模型，我们首先在3D空间中获得了最先进的开放词汇分段级地图，然后构建了由地板、房间和对象概念组成的3D场景图层次结构，每个都包含开放性词汇特征。我们的方法能够表示多层建筑，并且允许机器人使用跨层Voronoi图穿越这些建筑。HOV-SG进行了评估。

    arXiv:2403.17846v1 Announce Type: cross  Abstract: Recent open-vocabulary robot mapping methods enrich dense geometric maps with pre-trained visual-language features. While these maps allow for the prediction of point-wise saliency maps when queried for a certain language concept, large-scale environments and abstract queries beyond the object level still pose a considerable hurdle, ultimately limiting language-grounded robotic navigation. In this work, we present HOV-SG, a hierarchical open-vocabulary 3D scene graph mapping approach for language-grounded robot navigation. Leveraging open-vocabulary vision foundation models, we first obtain state-of-the-art open-vocabulary segment-level maps in 3D and subsequently construct a 3D scene graph hierarchy consisting of floor, room, and object concepts, each enriched with open-vocabulary features. Our approach is able to represent multi-story buildings and allows robotic traversal of those using a cross-floor Voronoi graph. HOV-SG is evaluat
    
[^9]: 图语言模型（GLM）：一种新的基于图的方法来检测社会不稳定因素

    Graph Language Model (GLM): A new graph-based approach to detect social instabilities

    [https://arxiv.org/abs/2403.17816](https://arxiv.org/abs/2403.17816)

    提出了一种新的基于图的方法来提前预测重要的政治事件，通过自然语言处理、图论、团体分析和语义关系揭示数据中隐藏的预测信号

    

    本科学报告提出了一种新的方法，旨在利用新闻数据集提前预测重要的政治事件。该方法利用自然语言处理，图论，团体分析和语义关系来发现数据中隐藏的预测信号。我们首先设计了该方法的初步版本，并在一些事件上进行了测试。这些分析揭示了初始研究阶段的局限性。我们接着以两种关键方式增强了模型：首先，我们添加了一个过滤步骤，以仅考虑在进一步处理之前具有政治相关性的新闻；其次，我们调整了输入特征，使警报系统对数据中的重大波动更加敏感。在完善改进的方法后，我们对包括美国抗议活动、乌克兰战争和法国抗议活动在内的十一个事件进行了测试。结果表明，我们的方法相比基线方法具有优势。通过有针对性的改进

    arXiv:2403.17816v1 Announce Type: new  Abstract: This scientific report presents a novel methodology for the early prediction of important political events using News datasets. The methodology leverages natural language processing, graph theory, clique analysis, and semantic relationships to uncover hidden predictive signals within the data. Initially, we designed a preliminary version of the method and tested it on a few events. This analysis revealed limitations in the initial research phase. We then enhanced the model in two key ways: first, we added a filtration step to only consider politically relevant news before further processing; second, we adjusted the input features to make the alert system more sensitive to significant spikes in the data. After finalizing the improved methodology, we tested it on eleven events including US protests, the Ukraine war, and French protests. Results demonstrate the superiority of our approach compared to baseline methods. Through targeted refin
    
[^10]: 压缩语言模型是否对子群体稳健性影响较小？

    Are Compressed Language Models Less Subgroup Robust?

    [https://arxiv.org/abs/2403.17811](https://arxiv.org/abs/2403.17811)

    压缩语言模型的影响不仅取决于模型大小，还取决于压缩方法，同时发现模型压缩并不总是会使在少数子群体上的性能变差。

    

    为了减少大型语言模型的推理成本，越来越多地使用模型压缩来创建更小规模的模型。然而，我们对由数据集的标签和属性定义的少数子群体的稳健性知之甚少。在本文中，我们研究了18种不同的压缩方法和设置对BERT语言模型的子群体稳健性的影响。我们发现最差群组的性能不仅取决于模型大小，还取决于所使用的压缩方法。此外，我们发现模型压缩并不总是会使在少数子群体上的性能变差。总的来说，我们的分析有助于进一步研究模型压缩对子群体稳健性的影响。

    arXiv:2403.17811v1 Announce Type: cross  Abstract: To reduce the inference cost of large language models, model compression is increasingly used to create smaller scalable models. However, little is known about their robustness to minority subgroups defined by the labels and attributes of a dataset. In this paper, we investigate the effects of 18 different compression methods and settings on the subgroup robustness of BERT language models. We show that worst-group performance does not depend on model size alone, but also on the compression method used. Additionally, we find that model compression does not always worsen the performance on minority subgroups. Altogether, our analysis serves to further research into the subgroup robustness of model compression.
    
[^11]: 坚信忠实：在找到模型机制时超越电路重叠

    Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms

    [https://arxiv.org/abs/2403.17806](https://arxiv.org/abs/2403.17806)

    提出了一种新方法EAP-IG，旨在更好地保持电路的核心属性：忠实

    

    最近许多语言模型（LM）可解释性研究已采用电路框架，旨在找到解释LM在给定任务上行为的最小计算子图或电路。大多数研究通过独立对每个边执行因果干预来确定哪些边属于LM的电路，但这在模型规模较大时效率低下。边缘归因修补（EAP），一种基于梯度的近似干预方法，已成为解决这一问题的可扩展但不完美的解决方案。在本文中，我们介绍了一种新方法 - 带有集成梯度的EAP（EAP-IG），旨在更好地保持电路的核心属性：忠实。如果电路是忠实的，则可以去掉电路之外的所有模型边而不会改变模型在任务上的表现；忠实性是研究电路而不是完整模型的理由。我们的实验证明，使用EAP找到的电路不太忠实

    arXiv:2403.17806v1 Announce Type: cross  Abstract: Many recent language model (LM) interpretability studies have adopted the circuits framework, which aims to find the minimal computational subgraph, or circuit, that explains LM behavior on a given task. Most studies determine which edges belong in a LM's circuit by performing causal interventions on each edge independently, but this scales poorly with model size. Edge attribution patching (EAP), gradient-based approximation to interventions, has emerged as a scalable but imperfect solution to this problem. In this paper, we introduce a new method - EAP with integrated gradients (EAP-IG) - that aims to better maintain a core property of circuits: faithfulness. A circuit is faithful if all model edges outside the circuit can be ablated without changing the model's performance on the task; faithfulness is what justifies studying circuits, rather than the full model. Our experiments demonstrate that circuits found using EAP are less faith
    
[^12]: 通过自动提示优化改进文本到图像的一致性

    Improving Text-to-Image Consistency via Automatic Prompt Optimization

    [https://arxiv.org/abs/2403.17804](https://arxiv.org/abs/2403.17804)

    本文提出了一个 T2I 优化通过提示的框架 OPT2I，利用大型语言模型（LLM）来改进 T2I 模型中的提示-图像一致性。

    

    arXiv:2403.17804v1 公告类型: 交叉 摘要: 文本到图像（T2I）生成模型取得了令人印象深刻的进展，产生了大量性能优越的模型，能够生成审美吸引人、逼真的图像。尽管取得了进展，这些模型仍然难以生成与输入提示一致的图像，常常无法正确捕捉物体数量、关系和属性。现有的解决方案改进提示-图像一致性面临以下挑战：（1）它们常常需要对模型进行微调，（2）它们仅关注附近的提示样本，（3）它们受到图像质量、表示多样性和提示-图像一致性之间不利权衡的影响。本文中，我们解决了这些挑战，并引入了一种 T2I 通过提示优化的框架 OPT2I，利用大型语言模型（LLM）改进 T2I 模型中的提示-图像一致性。我们的框架从用户提示开始，不断迭代。

    arXiv:2403.17804v1 Announce Type: cross  Abstract: Impressive advances in text-to-image (T2I) generative models have yielded a plethora of high performing models which are able to generate aesthetically appealing, photorealistic images. Despite the progress, these models still struggle to produce images that are consistent with the input prompt, oftentimes failing to capture object quantities, relations and attributes properly. Existing solutions to improve prompt-image consistency suffer from the following challenges: (1) they oftentimes require model fine-tuning, (2) they only focus on nearby prompt samples, and (3) they are affected by unfavorable trade-offs among image quality, representation diversity, and prompt-image consistency. In this paper, we address these challenges and introduce a T2I optimization-by-prompting framework, OPT2I, which leverages a large language model (LLM) to improve prompt-image consistency in T2I models. Our framework starts from a user prompt and iterat
    
[^13]: 从学术复杂性到公众叙事：科学新闻报道生成的数据集

    SciNews: From Scholarly Complexities to Public Narratives -- A Dataset for Scientific News Report Generation

    [https://arxiv.org/abs/2403.17768](https://arxiv.org/abs/2403.17768)

    科学新闻报道生成的自动化提高了学术见解的可访问性，该研究提出了一个包含学术出版物和相应科学新闻报道的数据集，用于探索自动生成科学新闻报道的可能性。

    

    科学新闻报道作为一个桥梁，巧妙地将复杂的研究文章翻译成与更广泛的公众 resonant 的报道。这种叙事的自动生成增强了学术见解的可访问性。在本文中，我们提出了一个新的语料库来促进这种范式的发展。我们的语料库包括九个学科领域中学术出版物及其相应科学新闻报道的平行编译。为了证明我们数据集的实用性和可靠性，我们进行了广泛分析，突出了科学新闻叙事和学术文稿之间的可读性和简洁性差异。我们使用最先进的文本生成模型基准测试我们的数据集。评估过程包括自动评估和人工评估，为未来探索自动生成科学新闻报道打下了基础。

    arXiv:2403.17768v1 Announce Type: cross  Abstract: Scientific news reports serve as a bridge, adeptly translating complex research articles into reports that resonate with the broader public. The automated generation of such narratives enhances the accessibility of scholarly insights. In this paper, we present a new corpus to facilitate this paradigm development. Our corpus comprises a parallel compilation of academic publications and their corresponding scientific news reports across nine disciplines. To demonstrate the utility and reliability of our dataset, we conduct an extensive analysis, highlighting the divergences in readability and brevity between scientific news narratives and academic manuscripts. We benchmark our dataset employing state-of-the-art text generation models. The evaluation process involves both automatic and human evaluation, which lays the groundwork for future explorations into the automated generation of scientific news reports. The dataset and code related 
    
[^14]: 施工如此困难，以至于即使大型语言模型也因错误原因而正确

    Constructions Are So Difficult That Even Large Language Models Get Them Right for the Wrong Reasons

    [https://arxiv.org/abs/2403.17760](https://arxiv.org/abs/2403.17760)

    本文引入了一个具有大量词汇重叠的NLI挑战数据集，探讨了大型语言模型在处理特定结构时出现的失败现象，揭示了它们在区分特定结构时的不足之处。

    

    在本文中，我们做出了两方面理解的贡献：从自然语言处理的角度看，我们引入了一个具有大量词汇重叠的NLI挑战数据集，最大程度地减少了模型仅基于标记区别来区分蕴涵的可能性，并展示了GPT-4和Llama 2以强烈的偏见失败。然后，我们进一步创建了具有挑战性的子任务，以解释这种失败。从计算语言学的角度看，我们确定了一个包含三类形容词的结构组，这些形容词无法通过表面特征来区分。这使我们能够以各种方式探究LLM对这些结构的理解，并发现它们在各种方式上都无法区分它们，表明它们不足以代表它们的含义或捕捉短语头的词汇属性。

    arXiv:2403.17760v1 Announce Type: new  Abstract: In this paper, we make a contribution that can be understood from two perspectives: from an NLP perspective, we introduce a small challenge dataset for NLI with large lexical overlap, which minimises the possibility of models discerning entailment solely based on token distinctions, and show that GPT-4 and Llama 2 fail it with strong bias. We then create further challenging sub-tasks in an effort to explain this failure. From a Computational Linguistics perspective, we identify a group of constructions with three classes of adjectives which cannot be distinguished by surface features. This enables us to probe for LLM's understanding of these constructions in various ways, and we find that they fail in a variety of ways to distinguish between them, suggesting that they don't adequately represent their meaning or capture the lexical properties of phrasal heads.
    
[^15]: 多项选择题是否真的能够检测LLMs的能力？

    Can multiple-choice questions really be useful in detecting the abilities of LLMs?

    [https://arxiv.org/abs/2403.17752](https://arxiv.org/abs/2403.17752)

    多项选择题虽然被广泛用于评估大型语言模型，但在测试LLMs能力时存在一定局限性，特别是在需要长篇生成答案的情况下，我们发现LLMs在双语MCQs中表现出顺序敏感性。

    

    多项选择题(MCQs)由于其简单和高效而被广泛用于评估大型语言模型(LLMs)。然而，人们对于MCQs是否能真正衡量LLMs的能力存在疑虑，特别是在需要长篇生成(LFG)答案的知识密集型场景中。任务与评估方法之间的不匹配需要对MCQ的效用进行深入分析，而我们在本文中通过评估两种语言（中文和英文）的四个问答(QA)数据集上的九个LLMs来进行。我们发现一个重要问题：LLMs在双语MCQs中表现出一种顺序敏感性，偏向于位于特定位置的答案，即第一个位置。我们通过比较直接输出、token logit和嵌入来量化MCQs和长篇生成问题(LFGQs)之间的差距。我们的结果显示MCQs和长篇生成的答案之间存在相对较低的相关性。

    arXiv:2403.17752v1 Announce Type: new  Abstract: Multiple-choice questions (MCQs) are widely used in the evaluation of large language models (LLMs) due to their simplicity and efficiency. However, there are concerns about whether MCQs can truly measure LLM's capabilities, particularly in knowledge-intensive scenarios where long-form generation (LFG) answers are required. The misalignment between the task and the evaluation method demands a thoughtful analysis of MCQ's efficacy, which we undertake in this paper by evaluating nine LLMs on four question-answering (QA) datasets in two languages: Chinese and English. We identify a significant issue: LLMs exhibit an order sensitivity in bilingual MCQs, favoring answers located at specific positions, i.e., the first position. We further quantify the gap between MCQs and long-form generation questions (LFGQs) by comparing their direct outputs, token logits, and embeddings. Our results reveal a relatively low correlation between answers from MC
    
[^16]: UCxn: 基于语言类型学的通用依存关系中构造的标注

    UCxn: Typologically Informed Annotation of Constructions Atop Universal Dependencies

    [https://arxiv.org/abs/2403.17748](https://arxiv.org/abs/2403.17748)

    为了处理UD树库中未标记的携带含义的语法构造，我们提出在UD注释中添加一个“UCxn”注释层，并在了解语言类型学的基础上比较跨语言的形态句法策略。

    

    通用依存关系（UD）项目创建了一个珍贵的树库集合，涵盖了超过140种语言的贡献。然而，UD的注释并未完全展示所有信息。传达特定含义的语法构造，例如具有特殊标记和/或词序的疑问句，未被完整标记。我们提倡（i）在UD注释中增加一个“UCxn”注释层，用于处理携带含义的语法结构，（ii）以基于类型学的方式处理，从而能够跨语言比较形态句法策略。作为案例研究，我们考虑了十种语言中五个构造家族，通过形态句法模式在UD树库中识别每个构造的实例。除了关于这些特定构造的发现外，我们的研究还得出了一些重要见解。

    arXiv:2403.17748v1 Announce Type: new  Abstract: The Universal Dependencies (UD) project has created an invaluable collection of treebanks with contributions in over 140 languages. However, the UD annotations do not tell the full story. Grammatical constructions that convey meaning through a particular combination of several morphosyntactic elements -- for example, interrogative sentences with special markers and/or word orders -- are not labeled holistically. We argue for (i) augmenting UD annotations with a 'UCxn' annotation layer for such meaning-bearing grammatical constructions, and (ii) approaching this in a typologically informed way so that morphosyntactic strategies can be compared across languages. As a case study, we consider five construction families in ten languages, identifying instances of each construction in UD treebanks through the use of morphosyntactic patterns. In addition to findings regarding these particular constructions, our study yields important insights on
    
[^17]: 基于分层增强网络的持续少样本事件检测

    Continual Few-shot Event Detection via Hierarchical Augmentation Networks

    [https://arxiv.org/abs/2403.17733](https://arxiv.org/abs/2403.17733)

    本文提出了基于分层增强网络的持续少样本事件检测框架，通过原型增强和对比增强解决了记忆先前事件类型和学习少样本中新事件类型的挑战。

    

    传统的持续事件检测依赖于丰富的标注数据进行训练，而在现实世界的应用中，通常很难获得这些数据。本文介绍了持续少样本事件检测（CFED），这是一个更常见的场景，即很多标记样本无法获取的情况。CFED任务很具挑战性，因为需要记忆先前的事件类型，并用少量样本学习新的事件类型。为了应对这些挑战，我们提出了一种基于记忆的框架：分层增强网络（HANet）。为了在有限的内存中记忆先前的事件类型，我们将原型增强融入到记忆集中。针对在少样本情况下学习新事件类型的问题，我们提出了一个用于标记表示的对比增强模块。除了与先前最先进方法的比较，我们还与ChatGPT进行了比较。实验结果表明，...

    arXiv:2403.17733v1 Announce Type: new  Abstract: Traditional continual event detection relies on abundant labeled data for training, which is often impractical to obtain in real-world applications. In this paper, we introduce continual few-shot event detection (CFED), a more commonly encountered scenario when a substantial number of labeled samples are not accessible. The CFED task is challenging as it involves memorizing previous event types and learning new event types with few-shot samples. To mitigate these challenges, we propose a memory-based framework: Hierarchical Augmentation Networks (HANet). To memorize previous event types with limited memory, we incorporate prototypical augmentation into the memory set. For the issue of learning new event types in few-shot scenarios, we propose a contrastive augmentation module for token representations. Despite comparing with previous state-of-the-art methods, we also conduct comparisons with ChatGPT. Experiment results demonstrate that o
    
[^18]: FastPerson: 通过保留语言和视觉内容增强视频学习的高效视频摘要化

    FastPerson: Enhancing Video Learning through Effective Video Summarization that Preserves Linguistic and Visual Contexts

    [https://arxiv.org/abs/2403.17727](https://arxiv.org/abs/2403.17727)

    FastPerson提出了一种视频摘要化方法，考虑了讲座视频中的视觉和听觉信息，通过利用音频转录和屏幕上的图片和文字创建摘要视频，从而最大程度地减少了对学习者来说遗漏重要信息的风险。

    

    理解漫长的讲座视频对于时间有限并且对各种主题都感兴趣的学习者来说至关重要，以提高他们的学习效率。为此，视频摘要化一直受到积极研究，使用户只能查看视频中的重要场景。然而，这些研究集中在视频的视觉或音频信息，并提取视频中的重要片段。因此，在讲座视频中像老师的讲话和黑板或幻灯片上的视觉信息一样重要时，存在错过重要信息的风险。为解决这一问题，我们提出了FastPerson，一种考虑讲座视频中视觉和听觉信息的视频摘要化方法。FastPerson通过利用音频转录以及屏幕上的图片和文字创建摘要视频，最大程度地减少了对学习者来说遗漏重要信息的风险。此外，它提供了一个特征

    arXiv:2403.17727v1 Announce Type: cross  Abstract: Quickly understanding lengthy lecture videos is essential for learners with limited time and interest in various topics to improve their learning efficiency. To this end, video summarization has been actively researched to enable users to view only important scenes from a video. However, these studies focus on either the visual or audio information of a video and extract important segments in the video. Therefore, there is a risk of missing important information when both the teacher's speech and visual information on the blackboard or slides are important, such as in a lecture video. To tackle this issue, we propose FastPerson, a video summarization approach that considers both the visual and auditory information in lecture videos. FastPerson creates summary videos by utilizing audio transcriptions along with on-screen images and text, minimizing the risk of overlooking crucial information for learners. Further, it provides a feature 
    
[^19]: 增强短文本建模：利用大型语言模型进行主题细化

    Enhanced Short Text Modeling: Leveraging Large Language Models for Topic Refinement

    [https://arxiv.org/abs/2403.17706](https://arxiv.org/abs/2403.17706)

    利用大型语言模型的先进能力，提出了一种名为“主题细化”的新方法，通过引入提示工程和消除离题词等方式改进短文本的主题建模质量，提高了主题的语义质量。

    

    有效地构建针对简短文本（如推文和新闻标题）的主题模型对捕捉社会动态的迅速变化至关重要。然而，传统主题模型往往在准确表达短文本的语义细微差异方面存在不足，这是由于它们的简洁性和缺乏上下文数据。在我们的研究中，我们利用大型语言模型（LLMs）的先进能力，引入了一种称为“主题细化”的新方法。该方法并非直接参与主题的初步建模，而是专注于改进主题在被挖掘后的阶段。通过引入提示工程，我们指导LLMs消除给定主题中的离题词，确保仅保留与语境相关的词汇或用更符合语义的词汇替换。这种方法模拟了人类般的审查和改进主题的方式，从而提升了各种主题生成的语义质量。

    arXiv:2403.17706v1 Announce Type: cross  Abstract: Crafting effective topic models for brief texts, like tweets and news headlines, is essential for capturing the swift shifts in social dynamics. Traditional topic models, however, often fall short in accurately representing the semantic intricacies of short texts due to their brevity and lack of contextual data. In our study, we harness the advanced capabilities of Large Language Models (LLMs) to introduce a novel approach termed "Topic Refinement". This approach does not directly involve itself in the initial modeling of topics but focuses on improving topics after they have been mined. By employing prompt engineering, we direct LLMs to eliminate off-topic words within a given topic, ensuring that only contextually relevant words are preserved or substituted with ones that fit better semantically. This method emulates human-like scrutiny and improvement of topics, thereby elevating the semantic quality of the topics generated by vario
    
[^20]: 并非所有相似之处都是一样的：利用数据驱动的偏见来指导GenAI版权纠纷

    Not All Similarities Are Created Equal: Leveraging Data-Driven Biases to Inform GenAI Copyright Disputes

    [https://arxiv.org/abs/2403.17691](https://arxiv.org/abs/2403.17691)

    本文介绍了一种利用GenAI模型的学习能力进行版权法律分析的新方法，为解决版权侵权纠纷提供了有力的工具

    

    arXiv:2403.17691v1 公告类型: 跨学科 抽象: 生成人工智能（GenAI）模型的出现，包括 GitHub Copilot、OpenAI GPT 和 Stable Diffusion，彻底改变了内容创作，使非专业人士能够在各个领域生成高质量的内容。这种革命性技术导致合成内容激增，引发版权侵权的法律纠纷。为应对这些挑战，本文介绍了一种利用GenAI模型的学习能力进行版权法律分析的新方法，演示了GPT2和Stable Diffusion模型。版权法区分原始表达和通用表达（Sc\`enes \`a faire），保护前者并允许后者的复制。然而，这一区别在历史上一直很难一致地做出，导致版权作品被过度保护。GenAI提供了一个前所未有的机会，可以增强这种法律分析，揭示...

    arXiv:2403.17691v1 Announce Type: cross  Abstract: The advent of Generative Artificial Intelligence (GenAI) models, including GitHub Copilot, OpenAI GPT, and Stable Diffusion, has revolutionized content creation, enabling non-professionals to produce high-quality content across various domains. This transformative technology has led to a surge of synthetic content and sparked legal disputes over copyright infringement. To address these challenges, this paper introduces a novel approach that leverages the learning capacity of GenAI models for copyright legal analysis, demonstrated with GPT2 and Stable Diffusion models. Copyright law distinguishes between original expressions and generic ones (Sc\`enes \`a faire), protecting the former and permitting reproduction of the latter. However, this distinction has historically been challenging to make consistently, leading to over-protection of copyrighted works. GenAI offers an unprecedented opportunity to enhance this legal analysis by reveal
    
[^21]: 文本分类的语言模型：仅仅上下文学习就足够了吗？

    Language Models for Text Classification: Is In-Context Learning Enough?

    [https://arxiv.org/abs/2403.17661](https://arxiv.org/abs/2403.17661)

    本研究通过对16个文本分类数据集的大规模评估研究，填补了现有研究缺乏对文本生成模型与提示技术与更传统的文本分类方法之间比较的理解。

    

    最近的基础语言模型在零次和少次标记设置中展示了在许多自然语言处理任务中的最先进性能。这些模型相对于基于微调的更标准的方法的优势在于能够理解用自然语言编写的指令（提示），这有助于它们更好地推广到不同的任务和领域，而无需特定的训练数据。这使它们适合解决具有有限标注实例数量的领域的文本分类问题。但是，现有研究在规模上有限，并缺乏对文本生成模型与提示技术相结合与更传统的文本分类方法（如微调掩码语言模型）的比较的理解。在本文中，我们通过对涵盖二元、多类和多标签问题的16个文本分类数据集进行大规模评估研究来填补这一研究空白。

    arXiv:2403.17661v1 Announce Type: cross  Abstract: Recent foundational language models have shown state-of-the-art performance in many NLP tasks in zero- and few-shot settings. An advantage of these models over more standard approaches based on fine-tuning is the ability to understand instructions written in natural language (prompts), which helps them generalise better to different tasks and domains without the need for specific training data. This makes them suitable for addressing text classification problems for domains with limited amounts of annotated instances. However, existing research is limited in scale and lacks understanding of how text generation models combined with prompting techniques compare to more established methods for text classification such as fine-tuning masked language models. In this paper, we address this research gap by performing a large-scale evaluation study for 16 text classification datasets covering binary, multiclass, and multilabel problems. In par
    
[^22]: 用于可解释图像问答的内在子图生成

    Intrinsic Subgraph Generation for Interpretable Graph based Visual Question Answering

    [https://arxiv.org/abs/2403.17647](https://arxiv.org/abs/2403.17647)

    该论文介绍了一种用于图像问答的可解释方法，通过内在生成子图来提供决策洞察，并在GQA数据集上取得了竞争性能。

    

    深度学习在视觉问答（VQA）中取得了巨大成功，同时也增加了对可解释方法的需求。大多数可解释人工智能（XAI）方法侧重于生成事后解释，而非采取内在方法，后者特征化了可解释模型。在这项工作中，我们介绍了一种用于基于图的VQA的可解释方法，并在GQA数据集上展示了竞争性能。这种方法弥合了解释性和性能之间的差距。我们的模型被设计成在问答过程中本质上生成一个子图作为解释，提供决策制定的洞察。为了评估这些生成的子图的质量，我们将它们与建立的用于图神经网络的事后解释能力方法进行比较，并进行人类评估。此外，我们提出了与...

    arXiv:2403.17647v1 Announce Type: new  Abstract: The large success of deep learning based methods in Visual Question Answering (VQA) has concurrently increased the demand for explainable methods. Most methods in Explainable Artificial Intelligence (XAI) focus on generating post-hoc explanations rather than taking an intrinsic approach, the latter characterizing an interpretable model. In this work, we introduce an interpretable approach for graph-based VQA and demonstrate competitive performance on the GQA dataset. This approach bridges the gap between interpretability and performance. Our model is designed to intrinsically produce a subgraph during the question-answering process as its explanation, providing insight into the decision making. To evaluate the quality of these generated subgraphs, we compare them against established post-hoc explainability methods for graph neural networks, and perform a human evaluation. Moreover, we present quantitative metrics that correlate with the 
    
[^23]: DANCER：针对自动语音识别的实体描述增强命名实体校正器

    DANCER: Entity Description Augmented Named Entity Corrector for Automatic Speech Recognition

    [https://arxiv.org/abs/2403.17645](https://arxiv.org/abs/2403.17645)

    DANCER提出了一种新颖的Description Augmented Named entity CorrEctoR（DANCER）模型，通过利用实体描述为自动语音识别中的NEC提供额外信息，帮助缓解NE列表中的音素混淆问题。

    

    最近提出了一系列用于ASR的快速轻量级命名实体校正（NEC）模型，通常构建在音素级编辑距离算法基础上，并展现出令人印象深刻的NEC性能。然而，随着命名实体（NE）列表的增加，NE列表中的音素混淆问题变得更加严重；例如，同音异义词的问题大大增加。鉴此，我们提出了一种新颖的描述增强型命名实体校正器（称为DANCER），利用实体描述提供额外信息，以便在ASR转录中为NEC提供辅助减轻音素混淆。

    arXiv:2403.17645v1 Announce Type: new  Abstract: End-to-end automatic speech recognition (E2E ASR) systems often suffer from mistranscription of domain-specific phrases, such as named entities, sometimes leading to catastrophic failures in downstream tasks. A family of fast and lightweight named entity correction (NEC) models for ASR have recently been proposed, which normally build on phonetic-level edit distance algorithms and have shown impressive NEC performance. However, as the named entity (NE) list grows, the problems of phonetic confusion in the NE list are exacerbated; for example, homophone ambiguities increase substantially. In view of this, we proposed a novel Description Augmented Named entity CorrEctoR (dubbed DANCER), which leverages entity descriptions to provide additional information to facilitate mitigation of phonetic confusion for NEC on ASR transcription. To this end, an efficient entity description augmented masked language model (EDA-MLM) comprised of a dense re
    
[^24]: REFeREE：一种基于模型的无参考文本简化度量标准

    REFeREE: A REference-FREE Model-Based Metric for Text Simplification

    [https://arxiv.org/abs/2403.17640](https://arxiv.org/abs/2403.17640)

    REFeREE是一种基于模型的无参考文本简化度量标准，能够在预测文本质量方面表现出色，且无需在推理时使用参考简化。

    

    arXiv:2403.17640v1 公告类型: 新的 摘要: 文本简化缺乏普遍标准的质量，带注释的参考简化存在稀缺和昂贵的问题。我们提出通过引入REFeREE来缓解这些限制，这是一个具有3阶段课程的基于模型的无参考度量标准。REFeREE利用一个可任意扩展的预训练阶段，并且只要有少量人工注释就可以应用于任何质量标准。我们的实验表明，我们的度量标准在预测总体评分方面优于现有的基于参考的指标，并且在预测特定评分方面达到了竞争性和一致的性能，同时在推理时不需要参考简化。

    arXiv:2403.17640v1 Announce Type: new  Abstract: Text simplification lacks a universal standard of quality, and annotated reference simplifications are scarce and costly. We propose to alleviate such limitations by introducing REFeREE, a reference-free model-based metric with a 3-stage curriculum. REFeREE leverages an arbitrarily scalable pretraining stage and can be applied to any quality standard as long as a small number of human annotations are available. Our experiments show that our metric outperforms existing reference-based metrics in predicting overall ratings and reaches competitive and consistent performance in predicting specific ratings while requiring no reference simplifications at inference time.
    
[^25]: 使用动态前缀调整的混合倡议响应生成

    Mix-Initiative Response Generation with Dynamic Prefix Tuning

    [https://arxiv.org/abs/2403.17636](https://arxiv.org/abs/2403.17636)

    提出了一种使用动态前缀调整的混合倡议响应生成框架，解决了对话系统中的交叉污染问题，并能够在监督和非监督设置下学习倡议感知前缀。

    

    混合倡议在控制对话方向中起着关键作用。对于发言者， passively 响应或 proactively 主导会导致完全不同的响应。然而，大多数对话系统专注于训练一个统一的响应生成模型，而不区分不同的倡议。这导致了交叉污染问题，模型混淆了不同的倡议并生成不合适的响应。此外，为倡议标签获取大量人类注释可能很昂贵。为了解决这个问题，我们提出了一个通用的混合倡议动态前缀调整框架 (IDPT)，以解耦不同倡议与生成模型，该模型在监督和非监督设置下学习倡议感知前缀。具体来说，IDPT将倡议因素解耦为不同的前缀参数，并使用注意机制调整倡议的选择。

    arXiv:2403.17636v1 Announce Type: new  Abstract: Mixed initiative serves as one of the key factors in controlling conversation directions. For a speaker, responding passively or leading proactively would result in rather different responses. However, most dialogue systems focus on training a holistic response generation model without any distinction among different initiatives. It leads to the cross-contamination problem, where the model confuses different initiatives and generates inappropriate responses. Moreover, obtaining plenty of human annotations for initiative labels can be expensive. To address this issue, we propose a general mix-Initiative Dynamic Prefix Tuning framework (IDPT) to decouple different initiatives from the generation model, which learns initiative-aware prefixes in both supervised and unsupervised settings. Specifically, IDPT decouples initiative factors into different prefix parameters and uses the attention mechanism to adjust the selection of initiatives in 
    
[^26]: "您是一名专家注释者": 自动化情绪强度建模的最佳-最差标度注释

    "You are an expert annotator": Automatic Best-Worst-Scaling Annotations for Emotion Intensity Modeling

    [https://arxiv.org/abs/2403.17612](https://arxiv.org/abs/2403.17612)

    自动标记情绪强度建模中的最佳-最差标度注释方法的性能表现

    

    标记语料库构成了为新任务或领域创建模型的瓶颈。大型语言模型通过自动语料库标记方法，特别是针对分类标记，缓解了这一问题。然而，一些NLP任务（如情绪强度预测）需要文本回归，但目前尚无关于连续标签分配自动化标记的工作。回归被认为比分类更具挑战性：当人类被要求从评分尺度中选择数值时表现更差，这导致了比较注释方法，包括最佳-最差标度。这引发了一个问题，即基于大型语言模型的标注方法是否显示类似的模式，即它们在评分标度注释任务上的表现比在比较标度注释任务上更差。为了研究这一点，我们自动化情绪强度预测并比较直接评分预测、成对比较和最佳-最差标度。我们发现

    arXiv:2403.17612v1 Announce Type: new  Abstract: Labeling corpora constitutes a bottleneck to create models for new tasks or domains. Large language models mitigate the issue with automatic corpus labeling methods, particularly for categorical annotations. Some NLP tasks such as emotion intensity prediction, however, require text regression, but there is no work on automating annotations for continuous label assignments. Regression is considered more challenging than classification: The fact that humans perform worse when tasked to choose values from a rating scale lead to comparative annotation methods, including best-worst scaling. This raises the question if large language model-based annotation methods show similar patterns, namely that they perform worse on rating scale annotation tasks than on comparative annotation tasks. To study this, we automate emotion intensity predictions and compare direct rating scale predictions, pairwise comparisons and best-worst scaling. We find that
    
[^27]: 对开放领域问答的去噪表格-文本检索

    Denoising Table-Text Retrieval for Open-Domain Question Answering

    [https://arxiv.org/abs/2403.17611](https://arxiv.org/abs/2403.17611)

    本文提出了一种Denosied Table-Text Retriever（DoTTeR）方法，通过利用去噪训练数据集和整合表级排名信息，解决了表格-文本开放领域问答中存在的假正标签影响和跨表格推理问题的挑战。

    

    在表格-文本开放领域问答中，检索系统从表格和文本中检索相关证据以回答问题。之前在表格-文本开放领域问答中的研究存在两个常见挑战：首先，它们的检索器可能受到训练数据集中的假正标签影响；其次，它们可能难以为需要跨表格推理的问题提供适当的证据。为了解决这些问题，我们提出了去噪表格-文本检索器（DoTTeR）。我们的方法包括利用一个去噪的训练数据集，通过舍弃通过假正检测模型测量的较低问题相关性得分的示例来减少假正标签。随后，我们将表级排名信息整合到检索器中，以帮助找到需要跨表格推理的问题的证据。为了编码此排名信息，我们对一个排名感知的列编码器进行微调。

    arXiv:2403.17611v1 Announce Type: cross  Abstract: In table-text open-domain question answering, a retriever system retrieves relevant evidence from tables and text to answer questions. Previous studies in table-text open-domain question answering have two common challenges: firstly, their retrievers can be affected by false-positive labels in training datasets; secondly, they may struggle to provide appropriate evidence for questions that require reasoning across the table. To address these issues, we propose Denoised Table-Text Retriever (DoTTeR). Our approach involves utilizing a denoised training dataset with fewer false positive labels by discarding instances with lower question-relevance scores measured through a false positive detection model. Subsequently, we integrate table-level ranking information into the retriever to assist in finding evidence for questions that demand reasoning across the table. To encode this ranking information, we fine-tune a rank-aware column encoder 
    
[^28]: 用文化敏感度共同构想语音助手的未来

    Coimagining the Future of Voice Assistants with Cultural Sensitivity

    [https://arxiv.org/abs/2403.17599](https://arxiv.org/abs/2403.17599)

    探索日本非西方环境中共同设计VAs的价值，展示了文化敏感度的必要性。

    

    语音助手（VAs）正成为我们日常生活的一部分。然而，用户体验（UX）通常受限，导致被低估、脱离和放弃。与潜在最终用户共同设计VAs的互动可能会有益。在线匿名地通过众包进行这一过程可能会增加价值。然而，大部分工作是在以英语为主的西方地区对对话数据集进行的。我们必须敏感地对待语言、社会互动和技术态度等方面的文化差异。我们旨在探讨在日本这种非西方环境中共同设计VAs的价值，并展示文化敏感度的必要性。我们进行了一项在线引诱性研究（N = 135），其中美国人（n = 64）和日本人（n = 71）构想了未来VAs的对话（N = 282）和活动（N = 73）。我们讨论了与未来VAs共同构想互动的影响，为日本和英语提供了设计指南。

    arXiv:2403.17599v1 Announce Type: cross  Abstract: Voice assistants (VAs) are becoming a feature of our everyday life. Yet, the user experience (UX) is often limited, leading to underuse, disengagement, and abandonment. Co-designing interactions for VAs with potential end-users can be useful. Crowdsourcing this process online and anonymously may add value. However, most work has been done in the English-speaking West on dialogue data sets. We must be sensitive to cultural differences in language, social interactions, and attitudes towards technology. Our aims were to explore the value of co-designing VAs in the non-Western context of Japan and demonstrate the necessity of cultural sensitivity. We conducted an online elicitation study (N = 135) where Americans (n = 64) and Japanese people (n = 71) imagined dialogues (N = 282) and activities (N = 73) with future VAs. We discuss the implications for coimagining interactions with future VAs, offer design guidelines for the Japanese and Eng
    
[^29]: 朝着零数据、可控、自适应对话系统迈进

    Towards a Zero-Data, Controllable, Adaptive Dialog System

    [https://arxiv.org/abs/2403.17582](https://arxiv.org/abs/2403.17582)

    该论文提出了一种从对话树生成数据的方法，可帮助训练出在合成数据上训练的代理达到与在人类数据上训练的模型相媲美的对话成功率。

    

    对话树搜索（Väth等，2023年）是一种最近的对话系统控制方法，其中领域专家通过对话树塑造强化学习代理的行为。代理学会有效地浏览这棵树，同时适应不同用户的信息需求，例如领域熟悉度。然而，额外的训练数据需求阻碍了在新领域的部署。为了解决这个问题，我们探索了直接从对话树生成这些数据的方法。我们改进了原始方法，并展示了在合成数据上训练的代理可以实现与在人类数据上训练的模型相当的对话成功率，无论是使用商业大语言模型进行生成，还是使用较小的开源模型，在单个GPU上运行。我们进一步通过收集和测试两个新数据集来展示我们方法的可扩展性：ONBOARD，一个帮助外国居民搬迁的新领域。

    arXiv:2403.17582v1 Announce Type: cross  Abstract: Conversational Tree Search (V\"ath et al., 2023) is a recent approach to controllable dialog systems, where domain experts shape the behavior of a Reinforcement Learning agent through a dialog tree. The agent learns to efficiently navigate this tree, while adapting to information needs, e.g., domain familiarity, of different users. However, the need for additional training data hinders deployment in new domains. To address this, we explore approaches to generate this data directly from dialog trees. We improve the original approach, and show that agents trained on synthetic data can achieve comparable dialog success to models trained on human data, both when using a commercial Large Language Model for generation, or when using a smaller open-source model, running on a single GPU. We further demonstrate the scalability of our approach by collecting and testing on two new datasets: ONBOARD, a new domain helping foreign residents moving t
    
[^30]: 面向任务的释义分析

    Task-Oriented Paraphrase Analytics

    [https://arxiv.org/abs/2403.17564](https://arxiv.org/abs/2403.17564)

    本文通过文献综述和提出分类法，探讨了释义任务的复杂性，并发现已知释义语料库中特定任务实例的分布差异很大。

    

    由于释义是一个定义模糊的任务，术语“释义”涵盖了具有不同特征的文本转换任务。因此，现有的释义研究在何时将一对文本视为释义方面应用了相当不同的（显式和隐式）标准，所有这些标准都要求假设某种级别的语义或词汇相似性。在本文中，我们进行了文献综述，并提出了一个分类法来组织已识别出的25个释义（子）任务。通过训练用于识别给定释义实例适用的任务的分类器，我们发现已知释义语料库中特定任务实例的分布差异很大。这意味着在未清楚定义相应释义条件的情况下使用这些语料库（这是正常情况）会导致无法比较和误导性的结果。

    arXiv:2403.17564v1 Announce Type: new  Abstract: Since paraphrasing is an ill-defined task, the term "paraphrasing" covers text transformation tasks with different characteristics. Consequently, existing paraphrasing studies have applied quite different (explicit and implicit) criteria as to when a pair of texts is to be considered a paraphrase, all of which amount to postulating a certain level of semantic or lexical similarity. In this paper, we conduct a literature review and propose a taxonomy to organize the 25~identified paraphrasing (sub-)tasks. Using classifiers trained to identify the tasks that a given paraphrasing instance fits, we find that the distributions of task-specific instances in the known paraphrase corpora vary substantially. This means that the use of these corpora, without the respective paraphrase conditions being clearly defined (which is the normal case), must lead to incomparable and misleading results.
    
[^31]: m3P:面向多模态多语言翻译的多语境提示

    m3P: Towards Multimodal Multilingual Translation with Multimodal Prompt

    [https://arxiv.org/abs/2403.17556](https://arxiv.org/abs/2403.17556)

    通过引入视觉上下文作为通用的语言无关表示，该论文提出了一种利用多模态提示来指导多模态多语言神经机器翻译的框架，以实现对不同语言表示的对齐，并生成条件视觉-语言记忆进行翻译。

    

    多语言翻译通过将所有语言投影到一个共享空间来支持多个翻译方向，但由于文本模态中语言之间的差异，尤其是当语言数量较大时，翻译质量会受到影响。为了弥补这一差距，我们引入视觉上下文作为通用的语言无关表示，以促进多语言翻译。在本文中，我们提出了一个框架，利用多模态提示来指导Multimodal Multilingual神经机器翻译（m3P），通过将不同语言的表示与相同含义对齐，并生成用于翻译的条件视觉-语言记忆。我们构建了一个支持102种语言的多语言多模态指令数据集（InstrMulti102）。我们的方法旨在通过将图像视为中央语言来最小化不同语言之间的表示距离。实验结果表明，...

    arXiv:2403.17556v1 Announce Type: cross  Abstract: Multilingual translation supports multiple translation directions by projecting all languages in a shared space, but the translation quality is undermined by the difference between languages in the text-only modality, especially when the number of languages is large. To bridge this gap, we introduce visual context as the universal language-independent representation to facilitate multilingual translation. In this paper, we propose a framework to leverage the multimodal prompt to guide the Multimodal Multilingual neural Machine Translation (m3P), which aligns the representations of different languages with the same meaning and generates the conditional vision-language memory for translation. We construct a multilingual multimodal instruction dataset (InstrMulti102) to support 102 languages. Our method aims to minimize the representation distance of different languages by regarding the image as a central language. Experimental results sh
    
[^32]: RuBia: 一个俄语语言偏见检测数据集

    RuBia: A Russian Language Bias Detection Dataset

    [https://arxiv.org/abs/2403.17553](https://arxiv.org/abs/2403.17553)

    本论文提出了一个针对俄语的偏见检测数据集RuBia，填补了多语言偏见评估范围的空白，对于测试大型语言模型在俄语中是否存在偏见具有重要意义。

    

    大型语言模型（LLMs）往往会学习原始预训练数据中存在的社会文化偏见。为了测试LLM的行为是否公平，需要使用功能性数据集，而这些数据集由于设计目的，通常高度依赖于语言和文化。本文通过提出一种特别针对俄语设计的偏见检测数据集RuBia，填补了多语言偏见评估范围的空白。RuBia数据集分为4个领域：性别、国籍、社会经济地位和多元化，每个领域又进一步分为多个细粒度子域。数据集中的每个示例包含两个句子，第一个句子强化了一个潜在的有害刻板印象或模式，第二个句子则与之相矛盾。这些句对首先由志愿者编写，然后由母语人士的众包验证。

    arXiv:2403.17553v1 Announce Type: new  Abstract: Warning: this work contains upsetting or disturbing content.   Large language models (LLMs) tend to learn the social and cultural biases present in the raw pre-training data. To test if an LLM's behavior is fair, functional datasets are employed, and due to their purpose, these datasets are highly language and culture-specific. In this paper, we address a gap in the scope of multilingual bias evaluation by presenting a bias detection dataset specifically designed for the Russian language, dubbed as RuBia. The RuBia dataset is divided into 4 domains: gender, nationality, socio-economic status, and diverse, each of the domains is further divided into multiple fine-grained subdomains. Every example in the dataset consists of two sentences with the first reinforcing a potentially harmful stereotype or trope and the second contradicting it. These sentence pairs were first written by volunteers and then validated by native-speaking crowdsourci
    
[^33]: 基于朴素贝叶斯的大语言模型上下文扩展

    Naive Bayes-based Context Extension for Large Language Models

    [https://arxiv.org/abs/2403.17552](https://arxiv.org/abs/2403.17552)

    介绍了一种新颖的基于朴素贝叶斯的上下文扩展框架(NBCE)，能够通过显著扩展上下文大小使现有的大型语言模型(LLMs)执行上下文学习(ICL)以整合更多演示示例，而且不需要微调或依赖特定模型架构。

    

    大型语言模型(LLMs)展现出令人期待的上下文学习能力。然而，传统的上下文学习(ICL)方法常常受到转换器架构长度限制的阻碍，在试图有效整合大量演示示例的监督时面临挑战。在本文中，我们引入了一种新颖的框架，称为基于朴素贝叶斯的上下文扩展(NBCE)，以使现有的LLMs能够通过显著扩展上下文大小执行ICL，从而增加演示示例的数量。重要的是，这种扩展不需要微调或依赖特定的模型架构，同时保持线性效率。NBCE首先将上下文分割成适合目标LLM最大长度的等大小窗口。然后，它引入了一个投票机制来选择最相关的窗口，被视为后验上下文。最后，它应用贝叶斯的方法

    arXiv:2403.17552v1 Announce Type: new  Abstract: Large Language Models (LLMs) have shown promising in-context learning abilities. However, conventional In-Context Learning (ICL) approaches are often impeded by length limitations of transformer architecture, which pose challenges when attempting to effectively integrate supervision from a substantial number of demonstration examples. In this paper, we introduce a novel framework, called Naive Bayes-based Context Extension (NBCE), to enable existing LLMs to perform ICL with an increased number of demonstrations by significantly expanding their context size. Importantly, this expansion does not require fine-tuning or dependence on particular model architectures, all the while preserving linear efficiency. NBCE initially splits the context into equal-sized windows fitting the target LLM's maximum length. Then, it introduces a voting mechanism to select the most relevant window, regarded as the posterior context. Finally, it employs Bayes' 
    
[^34]: 解读卓越：通过文本挖掘揭示运营和供应链专业人员心理特质的需求

    Decoding excellence: Mapping the demand for psychological traits of operations and supply chain professionals through text mining

    [https://arxiv.org/abs/2403.17546](https://arxiv.org/abs/2403.17546)

    通过文本挖掘和社交网络分析，本研究提出了一种创新方法，以评估OM和SCM专业人员特定心理特质的市场需求。

    

    本研究提出了一种创新的方法，通过文本挖掘和社交网络分析，对运营管理（OM）和供应链管理（SCM）专业人员的心理特质进行描述分析。该方法旨在通过结合相关心理构建、文本挖掘技术和创新度量方法，即语义品牌分数，评估特定特质的市场需求。我们将该方法应用于一组OM和SCM专业人员的职位描述数据集，旨在提供他们相关所需技能的描述分布图，包括心理特征。

    arXiv:2403.17546v1 Announce Type: new  Abstract: The current study proposes an innovative methodology for the profiling of psychological traits of Operations Management (OM) and Supply Chain Management (SCM) professionals. We use innovative methods and tools of text mining and social network analysis to map the demand for relevant skills from a set of job descriptions, with a focus on psychological characteristics. The proposed approach aims to evaluate the market demand for specific traits by combining relevant psychological constructs, text mining techniques, and an innovative measure, namely, the Semantic Brand Score. We apply the proposed methodology to a dataset of job descriptions for OM and SCM professionals, with the objective of providing a mapping of their relevant required skills, including psychological characteristics. In addition, the analysis is then detailed by considering the region of the organization that issues the job description, its organizational size, and the s
    
[^35]: 用于澄清日语模糊问题的注视基础视觉问答数据集

    A Gaze-grounded Visual Question Answering Dataset for Clarifying Ambiguous Japanese Questions

    [https://arxiv.org/abs/2403.17545](https://arxiv.org/abs/2403.17545)

    提出了 GazeVQA 数据集，通过注视信息来澄清模糊问题，并提出了一种利用注视目标估计结果的方法以提高任务准确性。

    

    位于对话，指的是将视觉信息称为视觉问答(VQA)的情境谈话，常常含有由于依赖指示性信息而产生的模糊性。这个问题加剧了，因为一些语言，比如日语，常常省略主观或客观术语。这种问题中的模糊性通常通过对话情景中的语境来澄清，比如与用户的联合关注或用户注视信息。在这项研究中，我们提出了通过注视信息澄清模糊问题的GazeVQA数据集(Gaze-grounded VQA dataset) ，重点关注由注视信息辅助的澄清过程。我们还提出了一种利用注视目标估计结果来提高GazeVQA任务准确性的方法。我们的实验结果显示，所提出的方法改善了VQA系统在GazeVQA上的性能，同时确定了一些GazeVQA任务中需要改进的典型问题。

    arXiv:2403.17545v1 Announce Type: new  Abstract: Situated conversations, which refer to visual information as visual question answering (VQA), often contain ambiguities caused by reliance on directive information. This problem is exacerbated because some languages, such as Japanese, often omit subjective or objective terms. Such ambiguities in questions are often clarified by the contexts in conversational situations, such as joint attention with a user or user gaze information. In this study, we propose the Gaze-grounded VQA dataset (GazeVQA) that clarifies ambiguous questions using gaze information by focusing on a clarification process complemented by gaze information. We also propose a method that utilizes gaze target estimation results to improve the accuracy of GazeVQA tasks. Our experimental results showed that the proposed method improved the performance in some cases of a VQA system on GazeVQA and identified some typical problems of GazeVQA tasks that need to be improved.
    
[^36]: 大型语言模型是语法错误校正的最先进评估器

    Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction

    [https://arxiv.org/abs/2403.17540](https://arxiv.org/abs/2403.17540)

    大型语言模型GPT-4在语法错误校正评估中表现优异，与人类判断有很高的相关性，凸显了在评估标准中流畅度的重要性。

    

    大型语言模型（LLMs）据报道在某些任务中胜过现有的自动评估指标，比如文本总结和机器翻译。但是，关于LLMs在语法错误校正（GEC）中作为评估器的研究还不足。本研究通过采用设计的提示来整合先前研究启发的各种评估标准，调查了LLMs在GEC评估中的表现。我们的广泛实验结果表明，GPT-4在与人类判断之间达到了0.662的Kendall等级相关性，超过了所有现有方法。此外，在最近的GEC评估中，我们强调了LLMs规模的重要性，特别强调了流畅度在评估标准中的重要性。

    arXiv:2403.17540v1 Announce Type: new  Abstract: Large Language Models (LLMs) have been reported to outperform existing automatic evaluation metrics in some tasks, such as text summarization and machine translation. However, there has been a lack of research on LLMs as evaluators in grammatical error correction (GEC). In this study, we investigate the performance of LLMs in GEC evaluation by employing prompts designed to incorporate various evaluation criteria inspired by previous research. Our extensive experimental results demonstrate that GPT-4 achieved Kendall's rank correlation of 0.662 with human judgments, surpassing all existing methods. Furthermore, in recent GEC evaluations, we have underscored the significance of the LLMs scale and particularly emphasized the importance of fluency among evaluation criteria.
    
[^37]: ILLUMINER: 指令调整的大型语言模型作为少样本意图分类器和槽位填充器

    ILLUMINER: Instruction-tuned Large Language Models as Few-shot Intent Classifier and Slot Filler

    [https://arxiv.org/abs/2403.17536](https://arxiv.org/abs/2403.17536)

    使用指令调整模型的ILLUMINER方法在意图分类和槽位填充任务上表现出更高效的学习能力，并在槽位填充方面优于目前最先进的方法。

    

    最先进的意图分类（IC）和槽位填充（SF）方法通常依赖于数据密集型的深度学习模型，限制了它们在工业应用中的实用性。另一方面，大型语言模型，特别是指令调整模型（Instruct-LLMs），在各种自然语言任务中表现出卓越的零样本性能。本研究评估了Instruct-LLMs在流行的IC和SF基准数据集上的表现，强调它们从更少示例中学习的能力。我们引入了 ILLUMINER，一种将IC和SF构建为Instruct-LLMs中的语言生成任务的方法，相比之前的工作，具有更高效的SF提示方法。与多个基线方法的全面比较显示，我们的方法使用FLAN-T5 11B模型，在槽位填充方面比最先进的联合IC + SF方法和GPT3.5 (175B)的上下文学习表现更好，槽位填充方面提高了11.1-32.2个百分点。此外，我们的深入研究

    arXiv:2403.17536v1 Announce Type: new  Abstract: State-of-the-art intent classification (IC) and slot filling (SF) methods often rely on data-intensive deep learning models, limiting their practicality for industry applications. Large language models on the other hand, particularly instruction-tuned models (Instruct-LLMs), exhibit remarkable zero-shot performance across various natural language tasks. This study evaluates Instruct-LLMs on popular benchmark datasets for IC and SF, emphasizing their capacity to learn from fewer examples. We introduce ILLUMINER, an approach framing IC and SF as language generation tasks for Instruct-LLMs, with a more efficient SF-prompting method compared to prior work. A comprehensive comparison with multiple baselines shows that our approach, using the FLAN-T5 11B model, outperforms the state-of-the-art joint IC+SF method and in-context learning with GPT3.5 (175B), particularly in slot filling by 11.1--32.2 percentage points. Additionally, our in-depth 
    
[^38]: 使用高阶特征的稀疏逻辑回归用于从树库中自动提取语法规则

    Sparse Logistic Regression with High-order Features for Automatic Grammar Rule Extraction from Treebanks

    [https://arxiv.org/abs/2403.17534](https://arxiv.org/abs/2403.17534)

    提出一种新方法从树库中提取和探索显著的细粒度语法模式和潜在的句法语法规则，以创建易于理解的基于语料库的语法。

    

    描述性语法非常有价值，但编写它们很耗时且困难。此外，尽管语言学家通常使用语料库来创建它们，语法描述通常缺乏定量数据。至于形式化语法，其解释可能具有挑战性。在本文中，我们提出了一种新方法，用于从树库中提取和探索显著的细粒度语法模式和潜在的句法语法规则，以创建一个易于理解的基于语料库的语法。更具体地，我们使用线性分类器从不同语言中提取两种语言现象，即协议和词序，的描述和规则，使用大量的搜索空间并特别关注提取规则的排序顺序。为此，我们使用线性分类器提取最显著的特征，以预测所研究的语言现象。我们为每个规则关联统计信息，并比较模型结果的排名。

    arXiv:2403.17534v1 Announce Type: new  Abstract: Descriptive grammars are highly valuable, but writing them is time-consuming and difficult. Furthermore, while linguists typically use corpora to create them, grammar descriptions often lack quantitative data. As for formal grammars, they can be challenging to interpret. In this paper, we propose a new method to extract and explore significant fine-grained grammar patterns and potential syntactic grammar rules from treebanks, in order to create an easy-to-understand corpus-based grammar. More specifically, we extract descriptions and rules across different languages for two linguistic phenomena, agreement and word order, using a large search space and paying special attention to the ranking order of the extracted rules. For that, we use a linear classifier to extract the most salient features that predict the linguistic phenomena under study. We associate statistical information to each rule, and we compare the ranking of the model's res
    
[^39]: 多语言句子-T5: 用于多语言应用的可扩展句子编码器

    Multilingual Sentence-T5: Scalable Sentence Encoders for Multilingual Applications

    [https://arxiv.org/abs/2403.17528](https://arxiv.org/abs/2403.17528)

    介绍了一个基于NLI的多语言句子嵌入模型Multilingual Sentence T5，通过低秩适应技术成功将模型规模扩展到57亿参数，并实现了优于先前方法的性能。

    

    先前关于多语言句子嵌入的工作表明，有效利用自然语言推理（NLI）数据来构建高性能模型能够胜过传统方法。然而，最近“指数”增长的拥有数十亿参数的语言模型的潜在好处尚未被充分探索。在本文中，我们通过扩展现有的单语言模型Sentence T5，引入了Multilingual Sentence T5（m-ST5），作为一个更大的基于NLI的多语言句子嵌入模型。通过使用低秩适应（LoRA）技术，我们成功地将模型的规模扩展到57亿个参数。我们进行了实验来评估句子嵌入的性能，并验证了该方法优于基于NLI的先前方法。此外，我们还确认了模型规模与性能之间的正相关性。

    arXiv:2403.17528v1 Announce Type: new  Abstract: Prior work on multilingual sentence embedding has demonstrated that the efficient use of natural language inference (NLI) data to build high-performance models can outperform conventional methods. However, the potential benefits from the recent ``exponential'' growth of language models with billions of parameters have not yet been fully explored. In this paper, we introduce Multilingual Sentence T5 (m-ST5), as a larger model of NLI-based multilingual sentence embedding, by extending Sentence T5, an existing monolingual model. By employing the low-rank adaptation (LoRA) technique, we have achieved a successful scaling of the model's size to 5.7 billion parameters. We conducted experiments to evaluate the performance of sentence embedding and verified that the method outperforms the NLI-based prior approach. Furthermore, we also have confirmed a positive correlation between the size of the model and its performance. It was particularly not
    
[^40]: 可证安全的神经语言隐写术消除方法

    Provably Secure Disambiguating Neural Linguistic Steganography

    [https://arxiv.org/abs/2403.17524](https://arxiv.org/abs/2403.17524)

    我们提出了一种名为SyncPool的新颖安全消除歧义方法，有效解决了神经语言隐写术中的分词模糊问题。

    

    最近的研究表明，可证安全的神经语言隐写术忽略了一个关键方面：发送方必须对隐写文本进行去记号化，以避免引起窃听者的怀疑。基于子词的语言模型会导致分词模糊问题，在所有基于这些模型的神经语言隐写术实现中偶尔会出现解码失败。目前解决此问题的方法包括更改候选词的概率分布，使其与可证安全的隐写术不相容。我们提出了一种名为SyncPool的新颖安全消除歧义方法，有效解决了分词模糊问题。我们在隐写嵌入算法运行之前将所有具有前缀关系的令牌分组在候选池中，以消除模糊令牌之间的不确定性。为使接收方能够同步发送方的采样过程，使用了一个共享密码术。

    arXiv:2403.17524v1 Announce Type: cross  Abstract: Recent research in provably secure neural linguistic steganography has overlooked a crucial aspect: the sender must detokenize stegotexts to avoid raising suspicion from the eavesdropper. The segmentation ambiguity problem, which arises when using language models based on subwords, leads to occasional decoding failures in all neural language steganography implementations based on these models. Current solutions to this issue involve altering the probability distribution of candidate words, rendering them incompatible with provably secure steganography. We propose a novel secure disambiguation method named SyncPool, which effectively addresses the segmentation ambiguity problem. We group all tokens with prefix relationships in the candidate pool before the steganographic embedding algorithm runs to eliminate uncertainty among ambiguous tokens. To enable the receiver to synchronize the sampling process of the sender, a shared cryptograph
    
[^41]: MapGuide: 从脑活动中重建连续语言的简单而有效方法

    MapGuide: A Simple yet Effective Method to Reconstruct Continuous Language from Brain Activities

    [https://arxiv.org/abs/2403.17516](https://arxiv.org/abs/2403.17516)

    本研究提出了一种直接比较预测文本嵌入的脑活动映射来指导文本重建的简单而有效方法，相比之前的间接方法显著提高了模型性能。

    

    从脑活动中解码连续语言是一项艰巨但有前景的研究领域。这对于帮助语言残障人士通过脑信号进行沟通尤为重要。本文提出了一种简单而有效的方法，通过直接将从脑活动映射的预测文本嵌入向导文本重建。全面的实验证明，我们的方法明显优于当前最先进的模型，在BLEU和METEOR分数上平均提高了77%和54%。

    arXiv:2403.17516v1 Announce Type: cross  Abstract: Decoding continuous language from brain activity is a formidable yet promising field of research. It is particularly significant for aiding people with speech disabilities to communicate through brain signals. This field addresses the complex task of mapping brain signals to text. The previous best attempt reverse-engineered this process in an indirect way: it began by learning to encode brain activity from text and then guided text generation by aligning with predicted brain responses. In contrast, we propose a simple yet effective method that guides text reconstruction by directly comparing them with the predicted text embeddings mapped from brain activities. Comprehensive experiments reveal that our method significantly outperforms the current state-of-the-art model, showing average improvements of 77% and 54% on BLEU and METEOR scores. We further validate the proposed modules through detailed ablation studies and case analyses and 
    
[^42]: 分担成功的成本：用于评估和学习协作多智能体指导和跟随策略的游戏

    Sharing the Cost of Success: A Game for Evaluating and Learning Collaborative Multi-Agent Instruction Giving and Following Policies

    [https://arxiv.org/abs/2403.17497](https://arxiv.org/abs/2403.17497)

    该研究提出了一种协作多智能体指导和跟随策略的游戏，通过对视觉和语言观察进行协调来评估玩家之间的交互努力，实验发现标准的PPO设置配合启发式合作行为能取得高成功率，神经网络合作伙伴配对可减少重复游戏时的合作努力。

    

    在协作目标导向的环境中，参与者不仅对实现成功的结果感兴趣，而且还会隐式地协商他们在交互中投入的努力（通过相互适应）。在本研究中，我们提出了一种具有挑战性的交互式参考游戏，需要两名玩家在视觉和语言观察上进行协调。此游戏中的学习信号是一种分数（在游戏后给出），该分数考虑了实现的目标和玩家在交互过程中的假定努力。我们展示了当使用实现从人际交互分析中获得的见解的启发式合作行为来引导时，标准的近端策略优化（PPO）设置实现了很高的成功率。我们发现神经网络合作伙伴的配对确实在重复玩在一起时减少了测得的合作努力。然而，我们观察到与一个合理的启发式配对相比，仍然存在着...

    arXiv:2403.17497v1 Announce Type: new  Abstract: In collaborative goal-oriented settings, the participants are not only interested in achieving a successful outcome, but do also implicitly negotiate the effort they put into the interaction (by adapting to each other). In this work, we propose a challenging interactive reference game that requires two players to coordinate on vision and language observations. The learning signal in this game is a score (given after playing) that takes into account the achieved goal and the players' assumed efforts during the interaction. We show that a standard Proximal Policy Optimization (PPO) setup achieves a high success rate when bootstrapped with heuristic partner behaviors that implement insights from the analysis of human-human interactions. And we find that a pairing of neural partners indeed reduces the measured joint effort when playing together repeatedly. However, we observe that in comparison to a reasonable heuristic pairing there is stil
    
[^43]: DGoT: 用于科学摘要生成的动态思维图

    DGoT: Dynamic Graph of Thoughts for Scientific Abstract Generation

    [https://arxiv.org/abs/2403.17491](https://arxiv.org/abs/2403.17491)

    该论文提出了一种名为DGoT的动态思维图方法，通过动态调整图结构和降低模型推理成本，提高了在生成科学论文摘要任务中的性价比。

    

    基于领域数据集训练语言模型的方法在生成科学论文摘要的任务中取得了重要成就。然而，这些模型面临着泛化和昂贵的训练成本等问题。使用大型语言模型（LLMs）来解决生成论文摘要的任务可以节省模型训练成本。然而，由于LLM的幻觉问题，通常需要通过多轮查询提示方法（如思维图（GoT））来提高结果的可靠性，但也带来了额外的推理成本。本文提出了一种动态思维图（DGoT），它不仅继承了现有的GoT提示方法的优点，而且根据数据特征动态调整图结构，同时减少了模型推理成本。实验结果表明，我们的方法在生成摘要任务中具有非常好的性价比。

    arXiv:2403.17491v1 Announce Type: new  Abstract: The method of training language models based on domain datasets has obtained significant achievements in the task of generating scientific paper abstracts. However, such models face problems of generalization and expensive training costs. The use of large language models (LLMs) to solve the task of generating paper abstracts saves the cost of model training. However, due to the hallucination problem of LLM, it is often necessary to improve the reliability of the results through multi-round query prompt approach such as Graph of Thoughts (GoT), which also brings additional reasoning costs. In this paper, we propose a Dynamic Graph of Thought (DGoT). It not only inherits the advantages of the existing GoT prompt approach, but also dynamically adjust the graph structure according to data characteristics while reducing model reasoning cost. Experimental results show that our method's cost-effectiveness in abstract generation tasks is only 43
    
[^44]: KDMCSE: 知识蒸馏多模态句子嵌入与自适应角度边际对比学习

    KDMCSE: Knowledge Distillation Multimodal Sentence Embeddings with Adaptive Angular margin Contrastive Learning

    [https://arxiv.org/abs/2403.17486](https://arxiv.org/abs/2403.17486)

    该研究提出了一种名为KDMCSE的知识蒸馏多模态句子嵌入方法，能够在学习中继承教师模型的知识，准确区分正负实例并有效检测嘈杂和错误的负样本。

    

    先前关于多模态句子嵌入的工作提出了多模态对比学习并取得了令人期待的结果。然而，通过将批次中的其余样本作为负样本而未进行审查以形成对比对时，这些研究遇到了许多可疑和嘈杂的负例，显著影响了方法的整体性能。在本项工作中，我们提出了KDMCSE（知识蒸馏多模态对比学习句子嵌入），这是一种增强多模态表示的区分性和泛化能力的新方法，并从教师模型继承知识来学习正负实例之间的差异，从而可以有效地在将其计算在对比目标中之前检测到嘈杂和错误的负样本。此外，为了克服建模负对内部变化的局限性，我们引入了一种新的对比目标，Ad

    arXiv:2403.17486v1 Announce Type: new  Abstract: Previous work on multimodal sentence embedding has proposed multimodal contrastive learning and achieved promising results. However, by taking the rest of the batch as negative samples without reviewing when forming contrastive pairs, those studies encountered many suspicious and noisy negative examples, significantly affecting the methods' overall performance. In this work, we propose KDMCSE (Knowledge Distillation Multimodal contrastive learning of Sentence Embeddings), a novel approach that enhances the discrimination and generalizability of multimodal representation and inherits the knowledge from the teacher model to learn the difference between positive and negative instances and via that, can detect noisy and wrong negative samples effectively before they are calculated in the contrastive objective. Furthermore, to overcome the limitation of modeling the variation within negative pairs, we introduce a new contrastive objective, Ad
    
[^45]: 将指数平滑法融入MLP：一个简单但有效的序列模型

    Incorporating Exponential Smoothing into MLP: A Simple but Effective Sequence Model

    [https://arxiv.org/abs/2403.17445](https://arxiv.org/abs/2403.17445)

    将简单的指数平滑法与MLP结合，通过增加参数和复杂性，实现了与复杂S4模型可比较的结果

    

    在序列数据中建模长期依赖关系是序列学习中的关键步骤。最近发展的模型“结构化状态空间”（S4）在建模长期序列方面表现出显著的有效性。然而，尚不清楚S4的成功是因为其复杂的参数化和HiPPO初始化还是仅仅由于状态空间模型（SSMs）。为了进一步探讨深度SSMs的潜力，我们从简单的SSM指数平滑（ETS）开始，并通过直接将其融入逐元素MLP提出了一个叠加架构。我们通过增加额外的参数和复杂的字段来扩充简单的ETS以减少归纳偏差。尽管在逐元素MLP的参数增加不到1%的情况下，我们的模型在LRA基准测试上取得了与S4可比较的结果。

    arXiv:2403.17445v1 Announce Type: cross  Abstract: Modeling long-range dependencies in sequential data is a crucial step in sequence learning. A recently developed model, the Structured State Space (S4), demonstrated significant effectiveness in modeling long-range sequences. However, It is unclear whether the success of S4 can be attributed to its intricate parameterization and HiPPO initialization or simply due to State Space Models (SSMs). To further investigate the potential of the deep SSMs, we start with exponential smoothing (ETS), a simple SSM, and propose a stacked architecture by directly incorporating it into an element-wise MLP. We augment simple ETS with additional parameters and complex field to reduce the inductive bias. Despite increasing less than 1\% of parameters of element-wise MLP, our models achieve comparable results to S4 on the LRA benchmark.
    
[^46]: 大规模语言模型的鲁棒且可扩展的模型编辑

    Robust and Scalable Model Editing for Large Language Models

    [https://arxiv.org/abs/2403.17431](https://arxiv.org/abs/2403.17431)

    通过适当的提示方法，经过指令微调的大型语言模型可以高度控制上下文知识，并对无关上下文具有鲁棒性，提出了EREN（通过阅读笔记来编辑模型），以改善可扩展性。

    

    大型语言模型（LLMs）可以使用参数化知识进行预测--即编码在模型权重中的知识--或者是上下文知识--即呈现在上下文中的知识。在许多场景下，一个理想的行为是当LLMs在参数化知识与上下文知识发生冲突时，优先考虑上下文知识，并在上下文无关时回退到使用他们的参数化知识。这使得通过上下文编辑来更新和纠正模型的知识成为可能，而无需重新训练。先前的研究表明，LLMs倾向于忽视上下文知识，并且在面对无关上下文时无法可靠地回退到参数化知识。在这项工作中，我们发现，通过适当的提示方法，经过指令微调的LLMs可以被上下文知识高度控制，并对无关上下文具有鲁棒性。利用这一特性，我们提出EREN（通过阅读笔记来编辑模型）来提高可扩展性。

    arXiv:2403.17431v1 Announce Type: new  Abstract: Large language models (LLMs) can make predictions using parametric knowledge--knowledge encoded in the model weights--or contextual knowledge--knowledge presented in the context. In many scenarios, a desirable behavior is that LLMs give precedence to contextual knowledge when it conflicts with the parametric knowledge, and fall back to using their parametric knowledge when the context is irrelevant. This enables updating and correcting the model's knowledge by in-context editing instead of retraining. Previous works have shown that LLMs are inclined to ignore contextual knowledge and fail to reliably fall back to parametric knowledge when presented with irrelevant context. In this work, we discover that, with proper prompting methods, instruction-finetuned LLMs can be highly controllable by contextual knowledge and robust to irrelevant context. Utilizing this feature, we propose EREN (Edit models by REading Notes) to improve the scalabil
    
[^47]: 通过症状划分和总结对齐大型语言模型以增强精神科访谈

    Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization

    [https://arxiv.org/abs/2403.17428](https://arxiv.org/abs/2403.17428)

    探讨了利用大型语言模型增强精神科访谈的方法，通过分析朝鲜叛逃者的咨询数据，研究LLMs在划分症状和总结压力因素和症状方面取得高性能。

    

    最近，大型语言模型（LLMs）的进展加速了它们在各个领域的应用。鉴于精神科访谈是专业面试者与被面试者之间目标导向和结构化对话，这是LLMs可以提供实质价值的最未被开发的领域之一。在这里，我们通过分析具有创伤经历和精神健康问题的朝鲜叛逃者的咨询数据，探讨了LLMs用于增强精神科访谈的用途。具体而言，我们研究LLMs是否能够（1）划分表示精神症状的对话部分并命名症状，以及（2）根据访谈对话记录总结压力因素和症状。这里，访谈数据由精神健康专家进行标记，用于训练和评估LLMs。我们的实验结果表明，适当提示的LLMs在症状划分和总结上可以实现高性能。

    arXiv:2403.17428v1 Announce Type: new  Abstract: Recent advancements in Large Language Models (LLMs) have accelerated their usage in various domains. Given the fact that psychiatric interviews are goal-oriented and structured dialogues between the professional interviewer and the interviewee, it is one of the most underexplored areas where LLMs can contribute substantial value. Here, we explore the use of LLMs for enhancing psychiatric interviews, by analyzing counseling data from North Korean defectors with traumatic events and mental health issues. Specifically, we investigate whether LLMs can (1) delineate the part of the conversation that suggests psychiatric symptoms and name the symptoms, and (2) summarize stressors and symptoms, based on the interview dialogue transcript. Here, the transcript data was labeled by mental health experts for training and evaluation of LLMs. Our experimental results show that appropriately prompted LLMs can achieve high performance on both the sympto
    
[^48]: LM-Combiner：一种用于中文语法错误校正的上下文重写模型

    LM-Combiner: A Contextual Rewriting Model for Chinese Grammatical Error Correction

    [https://arxiv.org/abs/2403.17413](https://arxiv.org/abs/2403.17413)

    LM-Combiner是一种用于中文语法错误校正的上下文重写模型，可以通过直接修改语法错误校正系统的过度校正来提高准确性和召回率。

    

    过度校正是中文语法错误校正（CGEC）任务中的一个关键问题。最近的研究使用基于投票的模型集成方法可以有效缓解过度校正，并提高语法错误校正系统的准确率。然而，这些方法仍然需要几个语法错误校正系统的输出，这不可避免地会导致减少错误召回。基于这一情况，我们提出了LM-Combiner，这是一种可以直接修改语法错误校正系统输出的过度校正的重写模型，而无需进行模型集成。具体而言，我们在一个通过提出的K折交叉推断方法构建的过度校正数据集上训练该模型，使其能够通过结合原始文本和过度校正文本来直接生成过滤后的句子。在推断阶段，我们直接将原始句子和其他系统的输出结果作为输入，然后通过LM-Combiner获得过滤后的句子。对FCGEC数据集的实验结果显示，LM-Combiner明显改善了语法错误校正的准确性和召回率。

    arXiv:2403.17413v1 Announce Type: new  Abstract: Over-correction is a critical problem in Chinese grammatical error correction (CGEC) task. Recent work using model ensemble methods based on voting can effectively mitigate over-correction and improve the precision of the GEC system. However, these methods still require the output of several GEC systems and inevitably lead to reduced error recall. In this light, we propose the LM-Combiner, a rewriting model that can directly modify the over-correction of GEC system outputs without a model ensemble. Specifically, we train the model on an over-correction dataset constructed through the proposed K-fold cross inference method, which allows it to directly generate filtered sentences by combining the original and the over-corrected text. In the inference stage, we directly take the original sentences and the output results of other systems as input and then obtain the filtered sentences through LM-Combiner. Experiments on the FCGEC dataset sho
    
[^49]: PCToolkit：大型语言模型统一即插即用提示压缩工具包

    PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models

    [https://arxiv.org/abs/2403.17411](https://arxiv.org/abs/2403.17411)

    PCToolkit是一个统一的即插即用解决方案，用于在大型语言模型中压缩提示，包括尖端的压缩器、多样的数据集和综合性能评估指标。

    

    arXiv:2403.17411v1 公告类型: 新的 提取要点是一种创新方法，旨在高效压缩输入提示同时保留关键信息。为了促进快速启动服务、用户友好的界面，并与常见数据集和指标兼容，我们提出了提示压缩工具包（PCToolkit）。该工具包是用于在大型语言模型（LLMs）中压缩提示的统一即插即用解决方案，具有尖端的提示压缩器、多样的数据集和用于全面性能评估的指标。PCToolkit拥有模块化设计，通过便携和用户友好的界面，可以轻松集成新的数据集和指标。在本文中，我们概述了PCToolkit的关键组件和功能。我们对PCToolkit内的压缩器进行了评估，涵盖了各种自然语言任务，包括重建、摘要、数学问题解决、问答、少样本学习、合成等。

    arXiv:2403.17411v1 Announce Type: new  Abstract: Prompt compression is an innovative method for efficiently condensing input prompts while preserving essential information. To facilitate quick-start services, user-friendly interfaces, and compatibility with common datasets and metrics, we present the Prompt Compression Toolkit (PCToolkit). This toolkit is a unified plug-and-play solution for compressing prompts in Large Language Models (LLMs), featuring cutting-edge prompt compressors, diverse datasets, and metrics for comprehensive performance evaluation. PCToolkit boasts a modular design, allowing for easy integration of new datasets and metrics through portable and user-friendly interfaces. In this paper, we outline the key components and functionalities of PCToolkit. We conducted evaluations of the compressors within PCToolkit across various natural language tasks, including reconstruction, summarization, mathematical problem-solving, question answering, few-shot learning, syntheti
    
[^50]: 使用区域指导标记将孟加拉文本与地方方言转录为国际音标

    Transcribing Bengali Text with Regional Dialects to IPA using District Guided Tokens

    [https://arxiv.org/abs/2403.17407](https://arxiv.org/abs/2403.17407)

    通过引入区域指导标记技术，本文提出了一种将孟加拉文本与地方方言转录为国际音标的方法，为模型提供了关于输入文本的地区方言信息，以理解与每个地区相关的独特音韵模式。

    

    孟加拉文本到国际音标（IPA）的准确转录是一项具有挑战性的任务，主要是由于语言的复杂音韵学和语境相关的音变。对于区域孟加拉方言来说，由于缺乏针对这些方言的标准拼写约定、当地和外语在这些地区中流行的词汇以及不同地区之间的音韵多样性，这一挑战甚至更为严峻。本文提出了一种方法来解决这个序列到序列的问题，即在覆盖孟加拉国六个地区的新数据集上引入“区域指导标记”（DGT）技术。其关键思想是在生成IPA转录之前向模型提供有关输入文本的区域方言或“地区”的明确信息。这通过在输入序列前添加一个地区标记来实现，有效地引导模型理解与每个地区相关的独特音韵模式。

    arXiv:2403.17407v1 Announce Type: cross  Abstract: Accurate transcription of Bengali text to the International Phonetic Alphabet (IPA) is a challenging task due to the complex phonology of the language and context-dependent sound changes. This challenge is even more for regional Bengali dialects due to unavailability of standardized spelling conventions for these dialects, presence of local and foreign words popular in those regions and phonological diversity across different regions. This paper presents an approach to this sequence-to-sequence problem by introducing the District Guided Tokens (DGT) technique on a new dataset spanning six districts of Bangladesh. The key idea is to provide the model with explicit information about the regional dialect or "district" of the input text before generating the IPA transcription. This is achieved by prepending a district token to the input sequence, effectively guiding the model to understand the unique phonetic patterns associated with each 
    
[^51]: ELLEN: 非常轻监督学习用于高效命名实体识别

    ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity Recognition

    [https://arxiv.org/abs/2403.17385](https://arxiv.org/abs/2403.17385)

    ELLEN是一种简单而强大的神经符号方法，将微调语言模型与语言规则相结合，在极其轻监督的情况下取得了非常强劲的命名实体识别性能。

    

    在这项工作中，我们重新审视了半监督命名实体识别（NER）问题，侧重于极其轻量级的监督，包括仅包含每类别10个示例的词汇表。我们引入了ELLEN，这是一种简单、完全模块化的神经符号方法，它将经过微调的语言模型与语言规则相结合。这些规则包括“一个话语一个意义”这样的见解，使用掩码语言模型作为无监督NER，利用词性标签识别和消除未标记实体作为假负例，以及关于分类器置信度得分在局部和全局背景下的其他直觉。在使用上述词汇表极小监督的情况下，ELLEN在CoNLL-2003数据集上取得了非常强大的性能。它还在文献中常用的相同监督设置（即，训练数据的5%）下，优于大多数现有（且更为复杂）的半监督NER方法。

    arXiv:2403.17385v1 Announce Type: cross  Abstract: In this work, we revisit the problem of semi-supervised named entity recognition (NER) focusing on extremely light supervision, consisting of a lexicon containing only 10 examples per class. We introduce ELLEN, a simple, fully modular, neuro-symbolic method that blends fine-tuned language models with linguistic rules. These rules include insights such as ''One Sense Per Discourse'', using a Masked Language Model as an unsupervised NER, leveraging part-of-speech tags to identify and eliminate unlabeled entities as false negatives, and other intuitions about classifier confidence scores in local and global context. ELLEN achieves very strong performance on the CoNLL-2003 dataset when using the minimal supervision from the lexicon above. It also outperforms most existing (and considerably more complex) semi-supervised NER methods under the same supervision settings commonly used in the literature (i.e., 5% of the training data). Further, 
    
[^52]: ChatGPT将自然语言解释质量评级定为与人类相似：但是基于哪些标准？

    ChatGPT Rates Natural Language Explanation Quality Like Humans: But on Which Scales?

    [https://arxiv.org/abs/2403.17368](https://arxiv.org/abs/2403.17368)

    本研究探索了ChatGPT在不同尺度下与人类评估之间的一致性，并发现在较粗粒度的尺度上，ChatGPT与人类更加一致。

    

    随着人工智能在我们的生活中变得越来越重要，透明度和责任性的需求也在增长。虽然自然语言解释（NLEs）对澄清人工智能决策背后的推理至关重要，但通过人类判断对其进行评估由于主观性和对细粒度评分的需求而变得复杂且资源密集。本研究探讨了ChatGPT与人类评估之间在多个尺度（即二元、三元和7-Likert尺度）上的一致性。我们从三个NLE数据集中抽取300个数据实例，并为信息量和清晰度两个文本质量度量收集了900个人类注释。我们进一步在不同主观评分范围下进行了成对比较实验，其中基线来自8,346个人类注释。我们的结果显示，在更粗粒度的尺度上，ChatGPT与人类更加一致。此外，成对比较和动态提示（即提供语义上）

    arXiv:2403.17368v1 Announce Type: cross  Abstract: As AI becomes more integral in our lives, the need for transparency and responsibility grows. While natural language explanations (NLEs) are vital for clarifying the reasoning behind AI decisions, evaluating them through human judgments is complex and resource-intensive due to subjectivity and the need for fine-grained ratings. This study explores the alignment between ChatGPT and human assessments across multiple scales (i.e., binary, ternary, and 7-Likert scale). We sample 300 data instances from three NLE datasets and collect 900 human annotations for both informativeness and clarity scores as the text quality measurement. We further conduct paired comparison experiments under different ranges of subjectivity scores, where the baseline comes from 8,346 human annotations. Our results show that ChatGPT aligns better with humans in more coarse-grained scales. Also, paired comparisons and dynamic prompting (i.e., providing semantically 
    
[^53]: 从嘈杂的音频转录中提取生物医学实体

    Extracting Biomedical Entities from Noisy Audio Transcripts

    [https://arxiv.org/abs/2403.17363](https://arxiv.org/abs/2403.17363)

    本文介绍了一个新的生物医学领域数据集 BioASR-NER，旨在填补自动语音识别（ASR）和自然语言处理（NLP）之间的鸿沟，重点是从 Brief Test of Adult Cognition by Tel 中提取不良药物反应和实体提及。

    

    Automatic Speech Recognition (ASR) 技术在将口语转录为文本方面起着基础性作用，在临床领域具有相当多的应用，包括简化医学转录和与电子健康记录（EHR）系统集成。然而，挑战仍然存在，特别是当转录包含噪声时，导致自然语言处理（NLP）模型应用时性能大幅下降。命名实体识别（NER）是一项重要的临床任务，特别受到此类噪声的影响，通常称为ASR-NLP鸿沟。以前的研究主要研究了 ASR 在干净录音中的效率，留下了关于在嘈杂环境中性能的研究空白。本文引入了一个新颖的数据集 BioASR-NER，旨在填补生物医学领域中的 ASR-NLP 鸿沟，着重于从 Brief Test of Adult Cognition by Tel 中提取不良药物反应和实体提及。

    arXiv:2403.17363v1 Announce Type: new  Abstract: Automatic Speech Recognition (ASR) technology is fundamental in transcribing spoken language into text, with considerable applications in the clinical realm, including streamlining medical transcription and integrating with Electronic Health Record (EHR) systems. Nevertheless, challenges persist, especially when transcriptions contain noise, leading to significant drops in performance when Natural Language Processing (NLP) models are applied. Named Entity Recognition (NER), an essential clinical task, is particularly affected by such noise, often termed the ASR-NLP gap. Prior works have primarily studied ASR's efficiency in clean recordings, leaving a research gap concerning the performance in noisy environments. This paper introduces a novel dataset, BioASR-NER, designed to bridge the ASR-NLP gap in the biomedical domain, focusing on extracting adverse drug reactions and mentions of entities from the Brief Test of Adult Cognition by Tel
    
[^54]: 将文本和表格世界联系起来进行事实验证：一种轻量级基于注意力的模型

    Bridging Textual and Tabular Worlds for Fact Verification: A Lightweight, Attention-Based Model

    [https://arxiv.org/abs/2403.17361](https://arxiv.org/abs/2403.17361)

    提出了一种简单而强大的模型，通过利用预训练模型和轻量级的基于注意力的机制，有效地利用不同数据类型之间的潜在连接，保留原始证据的上下文，确保预测准确性。

    

    FEVEROUS是一个关注涉及非结构化文本和结构化表格数据的事实提取和验证任务的基准和研究项目。在FEVEROUS中，现有的工作通常依赖于大量的预处理并利用基于规则的数据转换，这可能导致潜在的上下文丢失或误导性编码。本文介绍了一种简单而强大的模型，消除了模态转换的需求，从而保留了原始证据的上下文。通过利用多样化的文本和表格数据集上预训练的模型，并结合轻量级的基于注意力机制，我们的方法有效地利用了不同数据类型之间的潜在连接，从而产生全面且可靠的判断预测。该模型的模块化结构巧妙地管理多模态信息，确保原始证据的完整性和真实性不受损害。比较分析表明，

    arXiv:2403.17361v1 Announce Type: cross  Abstract: FEVEROUS is a benchmark and research initiative focused on fact extraction and verification tasks involving unstructured text and structured tabular data. In FEVEROUS, existing works often rely on extensive preprocessing and utilize rule-based transformations of data, leading to potential context loss or misleading encodings. This paper introduces a simple yet powerful model that nullifies the need for modality conversion, thereby preserving the original evidence's context. By leveraging pre-trained models on diverse text and tabular datasets and by incorporating a lightweight attention-based mechanism, our approach efficiently exploits latent connections between different data types, thereby yielding comprehensive and reliable verdict predictions. The model's modular structure adeptly manages multi-modal information, ensuring the integrity and authenticity of the original evidence are uncompromised. Comparative analyses reveal that ou
    
[^55]: Chain-of-Action：通过大型语言模型实现忠实和多模态问答

    Chain-of-Action: Faithful and Multimodal Question Answering through Large Language Models

    [https://arxiv.org/abs/2403.17359](https://arxiv.org/abs/2403.17359)

    提出了Chain-of-Action (CoA)框架，通过新颖的推理-检索机制和多参考忠实分数解决了当前QA应用中的不忠实幻觉和弱推理性能问题

    

    我们提出了一个称为Chain-of-Action (CoA)的框架，用于多模态和检索增强问答(QA)。与现有文献相比，CoA克服了当前QA应用的两个主要挑战：(i) 与实时或领域事实不一致的不忠实幻觉，以及(ii) 对组合信息的弱推理性能。我们的主要贡献是一种新颖的推理-检索机制，通过系统提示和预设计的动作将复杂问题分解为推理链。在方法上，我们提出了三种领域适应性的“即插即用”操作，用于从异构源检索实时信息。我们还提出了一个多参考忠实分数（MRFS）来验证和解决答案中的冲突。在经验上，我们利用公共基准和一个Web3案例研究来展示CoA相比其他方法的能力。

    arXiv:2403.17359v1 Announce Type: new  Abstract: We present a Chain-of-Action (CoA) framework for multimodal and retrieval-augmented Question-Answering (QA). Compared to the literature, CoA overcomes two major challenges of current QA applications: (i) unfaithful hallucination that is inconsistent with real-time or domain facts and (ii) weak reasoning performance over compositional information. Our key contribution is a novel reasoning-retrieval mechanism that decomposes a complex question into a reasoning chain via systematic prompting and pre-designed actions. Methodologically, we propose three types of domain-adaptable `Plug-and-Play' actions for retrieving real-time information from heterogeneous sources. We also propose a multi-reference faith score (MRFS) to verify and resolve conflicts in the answers. Empirically, we exploit both public benchmarks and a Web3 case study to demonstrate the capability of CoA over other methods.
    
[^56]: 通过大型语言模型进行关系发现的实体匹配消歧

    Disambiguate Entity Matching through Relation Discovery with Large Language Models

    [https://arxiv.org/abs/2403.17344](https://arxiv.org/abs/2403.17344)

    通过定义实体之间的关系，解决实体匹配中的歧义问题

    

    实体匹配是数据集成和清洗中的一个关键挑战，对于模糊连接和数据重复消除等任务至关重要。传统方法集中在克服模糊术语表示，例如编辑距离、Jaccard相似性，以及最近的嵌入和深度神经网络，包括来自大型语言模型（LLMs）如GPT的进展。然而，实体匹配中的核心挑战超越了术语模糊性，而是在定义何为“匹配”时的歧义，特别是在与外部数据库集成时。这种歧义是由于实体之间在细节和粒度方面存在差异引起的，这使得确切匹配变得复杂。我们提出了一种新方法，将焦点从纯粹识别语义相似性转变为理解和定义实体之间的“关系”作为解决匹配中的歧义至关重要。通过预定义一组与任务相关的关系，可帮助解决匹配中的歧义。

    arXiv:2403.17344v1 Announce Type: cross  Abstract: Entity matching is a critical challenge in data integration and cleaning, central to tasks like fuzzy joins and deduplication. Traditional approaches have focused on overcoming fuzzy term representations through methods such as edit distance, Jaccard similarity, and more recently, embeddings and deep neural networks, including advancements from large language models (LLMs) like GPT. However, the core challenge in entity matching extends beyond term fuzziness to the ambiguity in defining what constitutes a "match," especially when integrating with external databases. This ambiguity arises due to varying levels of detail and granularity among entities, complicating exact matches. We propose a novel approach that shifts focus from purely identifying semantic similarities to understanding and defining the "relations" between entities as crucial for resolving ambiguities in matching. By predefining a set of relations relevant to the task at
    
[^57]: 语言模型是生物医学成像任务的免费助推器

    Language Models are Free Boosters for Biomedical Imaging Tasks

    [https://arxiv.org/abs/2403.17343](https://arxiv.org/abs/2403.17343)

    本研究揭示了基于残差的大型语言模型在生物医学成像任务中作为编码器的意想不到的有效性，利用冻结的变压器块进行直接处理视觉令牌，从而提高各种生物医学成像应用的性能。

    

    在这项研究中，我们揭示了基于残差的大型语言模型（LLMs）在生物医学成像任务中作为编码器的意想不到的有效性，这是传统上缺乏语言或文本数据的领域。该方法不同于已建立的方法，通过利用从预训练的LLMs中提取的冻结变压器块作为创新的编码器层，直接处理视觉令牌。这种策略与通常依赖于语言驱动提示和输入的标准多模态视觉语言框架有着显著的不同。我们发现这些LLMs能够提升各种生物医学成像应用的性能，包括2D和3D视觉分类任务，充当即插即用的助推器。更有趣的是，作为副产品，我们发现所提出的框架实现了卓越的性能，在M的广泛、标准化数据集中取得了新的最先进结果。

    arXiv:2403.17343v1 Announce Type: cross  Abstract: In this study, we uncover the unexpected efficacy of residual-based large language models (LLMs) as part of encoders for biomedical imaging tasks, a domain traditionally devoid of language or textual data. The approach diverges from established methodologies by utilizing a frozen transformer block, extracted from pre-trained LLMs, as an innovative encoder layer for the direct processing of visual tokens. This strategy represents a significant departure from the standard multi-modal vision-language frameworks, which typically hinge on language-driven prompts and inputs. We found that these LLMs could boost performance across a spectrum of biomedical imaging applications, including both 2D and 3D visual classification tasks, serving as plug-and-play boosters. More interestingly, as a byproduct, we found that the proposed framework achieved superior performance, setting new state-of-the-art results on extensive, standardized datasets in M
    
[^58]: 不要听我的话：理解和探索大型语言模型的越狱提示

    Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models

    [https://arxiv.org/abs/2403.17336](https://arxiv.org/abs/2403.17336)

    该论文系统化了关于大型语言模型越狱提示的存在形式，并衡量了它们的越狱潜力，以更好地理解语义上具有意义的越狱提示的威胁格局。

    

    生成式人工智能的最新进展使得大型语言模型（LLMs）能够无处不在地被访问。凭借其出色的理解和生成类似人类文本的能力，这些模型正日益融入我们的社会。与此同时，人们也对这种强大技术的潜在滥用表示担忧，并促使服务提供商采取了防御措施。为了克服这种保护机制，越狱提示最近已成为规避安全限制和引诱最初设计为被禁止的有害内容的最有效机制之一。由于LLM的快速发展及通过自然语言轻松获取的便利性，越狱提示的前沿主要出现在在线论坛和爱好者中。为了更好地了解语义上具有意义的越狱提示的威胁格局，我们系统化了现有提示并测量它们的越狱

    arXiv:2403.17336v1 Announce Type: cross  Abstract: Recent advancements in generative AI have enabled ubiquitous access to large language models (LLMs). Empowered by their exceptional capabilities to understand and generate human-like text, these models are being increasingly integrated into our society. At the same time, there are also concerns on the potential misuse of this powerful technology, prompting defensive measures from service providers. To overcome such protection, jailbreaking prompts have recently emerged as one of the most effective mechanisms to circumvent security restrictions and elicit harmful content originally designed to be prohibited.   Due to the rapid development of LLMs and their ease of access via natural languages, the frontline of jailbreak prompts is largely seen in online forums and among hobbyists. To gain a better understanding of the threat landscape of semantically meaningful jailbreak prompts, we systemized existing prompts and measured their jailbre
    
[^59]: JMultiWOZ：一个大规模的日语多领域任务驱动对话数据集

    JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset

    [https://arxiv.org/abs/2403.17319](https://arxiv.org/abs/2403.17319)

    JMultiWOZ是第一个日语大规模多领域任务驱动对话数据集，通过评估与现有英语基准数据集相媲美的对话状态跟踪和回复生成能力，推动了日语任务驱动对话系统的研究与发展。

    

    对话数据集对基于深度学习的任务驱动对话系统研究至关重要。虽然已经开发了许多英语多领域任务驱动对话数据集，并为任务驱动对话系统的显著进展做出贡献，但日语中并不存在这样的数据集，并且与英语领域相比，这一领域的研究还很有限。为了推动日语任务驱动对话系统研究与开发的进展，本研究构建了JMultiWOZ，这是第一个日语大规模多领域任务驱动对话数据集。利用JMultiWOZ，我们评估了现有英语基准数据集MultiWOZ2.2和最新大型语言模型（LLM）方法上的对话状态跟踪和回复生成能力。我们的评估结果表明，JMultiWOZ提供了一个与MultiWOZ2相媲美的基准数据集。

    arXiv:2403.17319v1 Announce Type: cross  Abstract: Dialogue datasets are crucial for deep learning-based task-oriented dialogue system research. While numerous English language multi-domain task-oriented dialogue datasets have been developed and contributed to significant advancements in task-oriented dialogue systems, such a dataset does not exist in Japanese, and research in this area is limited compared to that in English. In this study, towards the advancement of research and development of task-oriented dialogue systems in Japanese, we constructed JMultiWOZ, the first Japanese language large-scale multi-domain task-oriented dialogue dataset. Using JMultiWOZ, we evaluated the dialogue state tracking and response generation capabilities of the state-of-the-art methods on the existing major English benchmark dataset MultiWOZ2.2 and the latest large language model (LLM)-based methods. Our evaluation results demonstrated that JMultiWOZ provides a benchmark that is on par with MultiWOZ2
    
[^60]: 项目MOSLA：记录第二语言习得的每一刻

    Project MOSLA: Recording Every Moment of Second Language Acquisition

    [https://arxiv.org/abs/2403.17314](https://arxiv.org/abs/2403.17314)

    项目MOSLA通过纵向、多模态、多语言和受控数据集的创建，揭示了学习者随时间发展的语言能力的见解。

    

    第二语言习得（SLA）是一个复杂而动态的过程。许多试图记录和分析这一过程的SLA研究通常专注于单一模态（例如学习者的文本输出），仅覆盖了短时间，或者缺乏控制（例如未捕捉学习过程的每个方面）。在MOSLA项目（第二语言习得时刻）中，我们通过邀请参与者在两年时间内仅通过在线指导从零开始学习三种目标语言（阿拉伯语、西班牙语和中文），并使用Zoom录制每节课，创建了一个纵向、多模态、多语言和受控数据集。该数据集通过人工标注者和经过优化的最先进语音模型进行半自动注释，揭示了学习者随时间发展的语言能力的见解。

    arXiv:2403.17314v1 Announce Type: new  Abstract: Second language acquisition (SLA) is a complex and dynamic process. Many SLA studies that have attempted to record and analyze this process have typically focused on a single modality (e.g., textual output of learners), covered only a short period of time, and/or lacked control (e.g., failed to capture every aspect of the learning process). In Project MOSLA (Moments of Second Language Acquisition), we have created a longitudinal, multimodal, multilingual, and controlled dataset by inviting participants to learn one of three target languages (Arabic, Spanish, and Chinese) from scratch over a span of two years, exclusively through online instruction, and recording every lesson using Zoom. The dataset is semi-automatically annotated with speaker/language IDs and transcripts by both human annotators and fine-tuned state-of-the-art speech models. Our experiments reveal linguistic insights into learners' proficiency development over time, as w
    
[^61]: 神经多模态主题建模：全面评估

    Neural Multimodal Topic Modeling: A Comprehensive Evaluation

    [https://arxiv.org/abs/2403.17308](https://arxiv.org/abs/2403.17308)

    该论文对包含文本和图片的文档的多模态主题建模进行了全面评估，并提出了两种新颖的主题建模解决方案和两种新颖的评估指标，结果显示这些模型均能产生连贯且多样化的主题。

    

    神经主题模型可以成功地在文本数据中找到连贯且多样化的主题。然而，它们在处理多模态数据集（如图片和文本）方面存在局限性。本文首次提出了包含文本和图片的文档的多模态主题建模的系统性和全面评估。在此过程中，我们提出了两种新颖的主题建模解决方案和两种新颖的评估指标。总体而言，我们对一个前所未有的丰富多样的数据集集合进行的评估表明，我们的两个模型都能产生连贯且多样化的主题。然而，一个方法优于另一个方法的程度取决于指标和数据集的组合，这表明未来需要进一步探索混合解决方案。值得注意的是，我们简洁的人工评估与我们提出的指标所确定的结果一致。这种一致不仅加强了我们指标的可信度，也突显了

    arXiv:2403.17308v1 Announce Type: cross  Abstract: Neural topic models can successfully find coherent and diverse topics in textual data. However, they are limited in dealing with multimodal datasets (e.g., images and text). This paper presents the first systematic and comprehensive evaluation of multimodal topic modeling of documents containing both text and images. In the process, we propose two novel topic modeling solutions and two novel evaluation metrics. Overall, our evaluation on an unprecedented rich and diverse collection of datasets indicates that both of our models generate coherent and diverse topics. Nevertheless, the extent to which one method outperforms the other depends on the metrics and dataset combinations, which suggests further exploration of hybrid solutions in the future. Notably, our succinct human evaluation aligns with the outcomes determined by our proposed metrics. This alignment not only reinforces the credibility of our metrics but also highlights the po
    
[^62]: HILL：层次感知信息无损对比学习用于层次文本分类

    HILL: Hierarchy-aware Information Lossless Contrastive Learning for Hierarchical Text Classification

    [https://arxiv.org/abs/2403.17307](https://arxiv.org/abs/2403.17307)

    提出了一种专为层次文本分类设计的信息无损对比学习方法HILL，旨在在对比样本中保留输入样本的语义和句法信息，并在学习过程中进行融合。

    

    存在的自监督方法主要关注自我监督对比学习，严重依赖于人为设计的增强规则来生成对比样本，这可能会损坏或扭曲原始信息。本文探讨了一种对比学习方案的可行性，在其中，输入样本中固有的语义和句法信息在对比样本中得到充分保留，并在学习过程中融合。具体来说，我们提出了一个信息无损对比学习策略用于层次文本分类，即“HILL”，它包括代表输入文档的文本编码器和直接生成正样本的结构编码器。

    arXiv:2403.17307v1 Announce Type: new  Abstract: Existing self-supervised methods in natural language processing (NLP), especially hierarchical text classification (HTC), mainly focus on self-supervised contrastive learning, extremely relying on human-designed augmentation rules to generate contrastive samples, which can potentially corrupt or distort the original information. In this paper, we tend to investigate the feasibility of a contrastive learning scheme in which the semantic and syntactic information inherent in the input sample is adequately reserved in the contrastive samples and fused during the learning process. Specifically, we propose an information lossless contrastive learning strategy for HTC, namely \textbf{H}ierarchy-aware \textbf{I}nformation \textbf{L}ossless contrastive \textbf{L}earning (HILL), which consists of a text encoder representing the input document, and a structure encoder directly generating the positive sample. The structure encoder takes the documen
    
[^63]: 使用最小对比项揭示神经语言模型中的内部语言结构：解码探测

    Decoding Probing: Revealing Internal Linguistic Structures in Neural Language Models using Minimal Pairs

    [https://arxiv.org/abs/2403.17299](https://arxiv.org/abs/2403.17299)

    解码探测这种方法揭示了自监督语言模型在中间层捕获抽象的语言结构，揭示了语法的学习需要更多层次，而形态和语义/句法接口相关特征则更难捕获。

    

    受认知神经科学研究启发，我们引入了一种称为“解码探测”的新方法，利用最小对比项基准（BLiMP）逐层探查神经语言模型中的内部语言特征。通过将语言模型视为‘大脑’，其表示为‘神经激活’，我们从中间层的表示中解码最小对比项的语法标签。这种方法揭示了：1）自监督语言模型在中间层捕获了抽象的语言结构，而GloVe和RNN语言模型无法学习。2）有关句法语法性的信息通过GPT-2的前三层稳健地捕获，同时也分布在后续层中。随着句子复杂性增加，需要更多层来学习语法能力。3）比起语法，形态和语义/句法接口相关特征更难捕获。4）基于Transformer的模型...

    arXiv:2403.17299v1 Announce Type: new  Abstract: Inspired by cognitive neuroscience studies, we introduce a novel `decoding probing' method that uses minimal pairs benchmark (BLiMP) to probe internal linguistic characteristics in neural language models layer by layer. By treating the language model as the `brain' and its representations as `neural activations', we decode grammaticality labels of minimal pairs from the intermediate layers' representations. This approach reveals: 1) Self-supervised language models capture abstract linguistic structures in intermediate layers that GloVe and RNN language models cannot learn. 2) Information about syntactic grammaticality is robustly captured through the first third layers of GPT-2 and also distributed in later layers. As sentence complexity increases, more layers are required for learning grammatical capabilities. 3) Morphological and semantics/syntax interface-related features are harder to capture than syntax. 4) For Transformer-based mod
    
[^64]: InternLM2技术报告

    InternLM2 Technical Report

    [https://arxiv.org/abs/2403.17297](https://arxiv.org/abs/2403.17297)

    InternLM2是一个开源的大语言模型，在全面评估、长文本建模以及创新的预训练和优化技术下表现出色，超越了其前任模型。

    

    大语言模型（LLMs）的发展，如ChatGPT和GPT-4，引发了关于人工通用智能（AGI）即将到来的讨论。然而，在开源模型中复制这样的进展一直是具有挑战性的。本文介绍了InternLM2，一个开源的LLM，在6个维度和30个基准测试中胜过其前辈，在长文本建模和主观评估方面优异，通过创新的预训练和优化技术。

    arXiv:2403.17297v1 Announce Type: cross  Abstract: The evolution of Large Language Models (LLMs) like ChatGPT and GPT-4 has sparked discussions on the advent of Artificial General Intelligence (AGI). However, replicating such advancements in open-source models has been challenging. This paper introduces InternLM2, an open-source LLM that outperforms its predecessors in comprehensive evaluations across 6 dimensions and 30 benchmarks, long-context modeling, and open-ended subjective evaluations through innovative pre-training and optimization techniques. The pre-training process of InternLM2 is meticulously detailed, highlighting the preparation of diverse data types including text, code, and long-context data. InternLM2 efficiently captures long-term dependencies, initially trained on 4k tokens before advancing to 32k tokens in pre-training and fine-tuning stages, exhibiting remarkable performance on the 200k ``Needle-in-a-Haystack" test. InternLM2 is further aligned using Supervised Fi
    
[^65]: 多模态对话中的共同地面跟踪

    Common Ground Tracking in Multimodal Dialogue

    [https://arxiv.org/abs/2403.17284](https://arxiv.org/abs/2403.17284)

    本文提出了一种自动识别多模态对话中参与者共享信念以及正在讨论问题的方法。

    

    人工智能和自然语言处理中的对话建模研究已经花费了相当多的精力在“对话状态跟踪”（DST）上，即通过考虑过去的对话移动和历史来更新每次对话中发言者需求的表示能力。然而，在对话建模中同样重要但研究较少的是“共同地面跟踪”（CGT），它确定了所有任务导向对话中所有参与者持有的共享信念空间：所有参与者接受为真的与任务相关的命题。在本文中，我们提出了一种自动识别具有共享目标的群体的当前共享信念集合和“正在讨论的问题”（QUDs）的方法。我们使用语音转录，语调特征，手势，行为和协作方面的要素对共享物理空间中的多模态交互数据集进行了标注，并使这些要素能够用于深度

    arXiv:2403.17284v1 Announce Type: new  Abstract: Within Dialogue Modeling research in AI and NLP, considerable attention has been spent on ``dialogue state tracking'' (DST), which is the ability to update the representations of the speaker's needs at each turn in the dialogue by taking into account the past dialogue moves and history. Less studied but just as important to dialogue modeling, however, is ``common ground tracking'' (CGT), which identifies the shared belief space held by all of the participants in a task-oriented dialogue: the task-relevant propositions all participants accept as true. In this paper we present a method for automatically identifying the current set of shared beliefs and ``questions under discussion'' (QUDs) of a group with a shared goal. We annotate a dataset of multimodal interactions in a shared physical space with speech transcriptions, prosodic features, gestures, actions, and facets of collaboration, and operationalize these features for use in a deep 
    
[^66]: 使用LLMs在数学问题上自动化知识概念标记

    Automate Knowledge Concept Tagging on Math Questions with LLMs

    [https://arxiv.org/abs/2403.17281](https://arxiv.org/abs/2403.17281)

    本文探讨了使用大型语言模型（LLMs）自动化标记数学问题中的知识概念，以满足先进教育应用对问题概念标记的增长需求。

    

    arXiv:2403.17281v1 公告类型：新摘要：对问题进行知识概念标记在当代智能教育应用中起着至关重要的作用，包括学习进度诊断、练习题推荐和课程内容组织。传统上，这些注释是在教育专家的帮助下手动进行的，因为该任务不仅需要对问题主干和知识定义有强大的语义理解，还需要深入了解问题解决逻辑与相应知识概念的联系。本文探讨了使用大型语言模型（LLMs）自动化标记任务，以响应先前手动方法无法满足先进教育应用对问题概念标记的快速增长需求的情况。此外，LLMs 的零/少次学习能力使其非常适合教育场景应用，这些场景通常面临在收集时遇到的挑战。

    arXiv:2403.17281v1 Announce Type: new  Abstract: Knowledge concept tagging for questions plays a crucial role in contemporary intelligent educational applications, including learning progress diagnosis, practice question recommendations, and course content organization. Traditionally, these annotations have been conducted manually with help from pedagogical experts, as the task requires not only a strong semantic understanding of both question stems and knowledge definitions but also deep insights into connecting question-solving logic with corresponding knowledge concepts. In this paper, we explore automating the tagging task using Large Language Models (LLMs), in response to the inability of prior manual methods to meet the rapidly growing demand for concept tagging in questions posed by advanced educational applications. Moreover, the zero/few-shot learning capability of LLMs makes them well-suited for application in educational scenarios, which often face challenges in collecting l
    
[^67]: 使用迁移学习的混合方法进行基于方面的情感分析

    A Hybrid Approach To Aspect Based Sentiment Analysis Using Transfer Learning

    [https://arxiv.org/abs/2403.17254](https://arxiv.org/abs/2403.17254)

    提出了一种使用迁移学习的混合方法，以解决基于方面的情感分析中手动注释数据集昂贵和耗时的问题

    

    Aspect-Based Sentiment Analysis (ABSA)旨在识别表达情感的术语或多词表达(MWEs)以及与之相关的情感极性。在这一领域的研究中，监督模型的发展一直处于研究前沿。然而，训练这些模型需要手动注释的数据集，这既昂贵又耗时。此外，现有的带标记数据集针对特定领域、语言和文本类型。在这项工作中，我们解决了当前最先进的ABSA研究中的这一显著挑战。我们提出了一种使用迁移学习进行基于方面的情感分析的混合方法。该方法旨在利用大型语言模型（LLM）和传统句法依赖的优势生成弱监督标注。我们利用句子的句法依赖结构来补充生成的标注。

    arXiv:2403.17254v1 Announce Type: new  Abstract: Aspect-Based Sentiment Analysis (ABSA) aims to identify terms or multiword expressions (MWEs) on which sentiments are expressed and the sentiment polarities associated with them. The development of supervised models has been at the forefront of research in this area. However, training these models requires the availability of manually annotated datasets which is both expensive and time-consuming. Furthermore, the available annotated datasets are tailored to a specific domain, language, and text type. In this work, we address this notable challenge in current state-of-the-art ABSA research. We propose a hybrid approach for Aspect Based Sentiment Analysis using transfer learning. The approach focuses on generating weakly-supervised annotations by exploiting the strengths of both large language models (LLM) and traditional syntactic dependencies. We utilise syntactic dependency structures of sentences to complement the annotations generated
    
[^68]: TwoStep: 使用经典规划器和大型语言模型进行多智能体任务规划

    TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models

    [https://arxiv.org/abs/2403.17246](https://arxiv.org/abs/2403.17246)

    该论文将经典规划和大型语言模型相结合，通过近似人类直觉，以实现多智能体任务规划。

    

    类似规划领域定义语言（PDDL）之类的经典规划公式允许确定可实现目标状态的动作序列，只要存在任何可能的初始状态。然而，PDDL中定义的推理问题并未捕获行动进行的时间方面，例如领域中的两个智能体如果彼此的后况不干扰前提条件，则可以同时执行一个动作。人类专家可以将目标分解为大部分独立的组成部分，并将每个智能体分配给其中一个子目标，以利用同时进行动作来加快计划步骤的执行，每个部分仅使用单个智能体规划。相比之下，直接推断计划步骤的大型语言模型（LLMs）并不保证执行成功，但利用常识推理来组装动作序列。我们通过近似人类直觉，结合了经典规划和LLMs的优势

    arXiv:2403.17246v1 Announce Type: new  Abstract: Classical planning formulations like the Planning Domain Definition Language (PDDL) admit action sequences guaranteed to achieve a goal state given an initial state if any are possible. However, reasoning problems defined in PDDL do not capture temporal aspects of action taking, for example that two agents in the domain can execute an action simultaneously if postconditions of each do not interfere with preconditions of the other. A human expert can decompose a goal into largely independent constituent parts and assign each agent to one of these subgoals to take advantage of simultaneous actions for faster execution of plan steps, each using only single agent planning. By contrast, large language models (LLMs) used for directly inferring plan steps do not guarantee execution success, but do leverage commonsense reasoning to assemble action sequences. We combine the strengths of classical planning and LLMs by approximating human intuition
    
[^69]: SPLICE：单例增强管道用于指代消解

    SPLICE: A Singleton-Enhanced PipeLIne for Coreference REsolution

    [https://arxiv.org/abs/2403.17245](https://arxiv.org/abs/2403.17245)

    本文通过结合现有的嵌套NER系统的预测提及和从OntoNotes句法树导出的特征，解决了在英语端到端神经指代消解中使用OntoNotes基准时单例提及跨度不足的问题，提出了一个名为SPLICE的两步神经提及和指代消解系统，并在OntoNotes测试集和域外OntoGUM语料库上对其性能进行了比较，结果表明重建的单例训练效果良好。

    

    arXiv:2403.17245v1  公告类型：新的  摘要：单例提及，即文本中仅被提及一次的实体，从理论角度来看对人类理解话语很重要。然而，以往将其检测纳入用于英语端到端神经指代消解的尝试受到了OntoNotes基准中单例提及跨度不足的限制。本文通过将现有的嵌套NER系统的预测提及与从OntoNotes句法树导出的特征相结合来解决这一限制。借助这种方法，我们创建了一个近似包含所有单例提及的OntoNotes数据集，对金标准单例样本达到了约94%的召回率。然后，我们提出了一个名为SPLICE的两步神经提及和指代消解系统，并将其性能与端到端方法在两种情景下进行了比较：OntoNotes测试集和域外（OOD）OntoGUM语料库。结果表明，重建的单例训练产生了较高的效果。

    arXiv:2403.17245v1 Announce Type: new  Abstract: Singleton mentions, i.e.~entities mentioned only once in a text, are important to how humans understand discourse from a theoretical perspective. However previous attempts to incorporate their detection in end-to-end neural coreference resolution for English have been hampered by the lack of singleton mention spans in the OntoNotes benchmark. This paper addresses this limitation by combining predicted mentions from existing nested NER systems and features derived from OntoNotes syntax trees. With this approach, we create a near approximation of the OntoNotes dataset with all singleton mentions, achieving ~94% recall on a sample of gold singletons. We then propose a two-step neural mention and coreference resolution system, named SPLICE, and compare its performance to the end-to-end approach in two scenarios: the OntoNotes test set and the out-of-domain (OOD) OntoGUM corpus. Results indicate that reconstructed singleton training yields re
    
[^70]: 在神经网络时代的$n$-gram平滑作用

    The Role of $n$-gram Smoothing in the Age of Neural Networks

    [https://arxiv.org/abs/2403.17240](https://arxiv.org/abs/2403.17240)

    本文重新探讨了在神经语言模型时代古典$n$-gram平滑技术可能发挥的作用，并提出了将任何$n$-gram平滑技术转换为神经语言模型兼容正则化器的通用框架

    

    在将近三十年的时间里，基于$n$-gram假设的语言模型一直是该任务的技术水平。它们成功的关键在于应用各种平滑技术来对抗过拟合。然而，当神经语言模型取代$n$-gram模型成为最佳表现者时，$n$-gram平滑技术变得不太相关。事实上，可以毫不夸张地说，对$n$-gram平滑技术的研究在这一时代变得停滞。本文重新探讨了在神经语言模型时代古典$n$-gram平滑技术可能发挥的作用。首先，我们在标签平滑和add-$\lambda$平滑之间建立了一个正式等价性，标签平滑是一种神经语言模型的流行正则化技术。其次，我们推导了一个通用框架，将\emph{任何} $n$-gram平滑技术转换为与神经语言模型兼容的正则化器。我们的实证结果表明

    arXiv:2403.17240v1 Announce Type: new  Abstract: For nearly three decades, language models derived from the $n$-gram assumption held the state of the art on the task. The key to their success lay in the application of various smoothing techniques that served to combat overfitting. However, when neural language models toppled $n$-gram models as the best performers, $n$-gram smoothing techniques became less relevant. Indeed, it would hardly be an understatement to suggest that the line of inquiry into $n$-gram smoothing techniques became dormant. This paper re-opens the role classical $n$-gram smoothing techniques may play in the age of neural language models. First, we draw a formal equivalence between label smoothing, a popular regularization technique for neural language models, and add-$\lambda$ smoothing. Second, we derive a generalized framework for converting \emph{any} $n$-gram smoothing technique into a regularizer compatible with neural language models. Our empirical results fi
    
[^71]: 使句子嵌入对用户生成内容具有鲁棒性

    Making Sentence Embeddings Robust to User-Generated Content

    [https://arxiv.org/abs/2403.17220](https://arxiv.org/abs/2403.17220)

    RoLASER是一个通过师生方法训练的鲁棒英文编码器，通过减少标准句子和UGC句子在嵌入空间中的距离，显著提高了LASER对自然和人工UGC数据的鲁棒性。

    

    自然语言处理模型在用户生成内容（UGC）上表现不佳，主要是因为它呈现了大量词汇变化，并偏离了大多数这些模型训练的标准文本。本文关注LASER句子嵌入模型对UGC数据的鲁棒性。我们通过LASER在嵌入空间中表示非标准句子及其标准对应句子的能力来评估这种鲁棒性。受先前扩展LASER到其他语言和形式的工作的启发，我们提出RoLASER，一个使用师生方法进行训练的鲁棒英文编码器，以减少标准句子和UGC句子表示之间的距离。我们表明，仅通过在标准和合成UGC样本数据上进行训练，RoLASER可以显著提高LASER对自然和人工UGC数据的鲁棒性，最多可以实现2倍和11倍的改进分数。我们还进行了细粒度研究

    arXiv:2403.17220v1 Announce Type: new  Abstract: NLP models have been known to perform poorly on user-generated content (UGC), mainly because it presents a lot of lexical variations and deviates from the standard texts on which most of these models were trained. In this work, we focus on the robustness of LASER, a sentence embedding model, to UGC data. We evaluate this robustness by LASER's ability to represent non-standard sentences and their standard counterparts close to each other in the embedding space. Inspired by previous works extending LASER to other languages and modalities, we propose RoLASER, a robust English encoder trained using a teacher-student approach to reduce the distances between the representations of standard and UGC sentences. We show that with training only on standard and synthetic UGC-like data, RoLASER significantly improves LASER's robustness to both natural and artificial UGC data by achieving up to 2x and 11x better scores. We also perform a fine-grained 
    
[^72]: 使用自然语言推理和概念嵌入进行本体补全：一项分析

    Ontology Completion with Natural Language Inference and Concept Embeddings: An Analysis

    [https://arxiv.org/abs/2403.17216](https://arxiv.org/abs/2403.17216)

    本文介绍了使用自然语言推理和概念嵌入进行本体补全的新方法，并发现这两种方法互补，混合策略取得最佳效果。

    

    我们考虑了找到给定本体中缺失的合理知识的问题，作为对广泛研究的分类法扩展任务的概括。一种方法将这一任务视为自然语言推理（NLI）问题，依赖于语言模型捕获的知识来识别缺失的知识。另一种方法使用概念嵌入来确定不同概念之间的共同之处，受认知模型对基于类别归纳的启发。这两种方法在直觉上是互补的，但它们的有效性尚未进行比较。在这篇论文中，我们介绍了一个用于评估本体补全方法的基准，并彻底分析了这两种方法的优势和劣势。我们发现这两种方法确实是互补的，混合策略实现了最佳的整体结果。我们还发现这一任务对大型语言模型来说非常具有挑战性。

    arXiv:2403.17216v1 Announce Type: new  Abstract: We consider the problem of finding plausible knowledge that is missing from a given ontology, as a generalisation of the well-studied taxonomy expansion task. One line of work treats this task as a Natural Language Inference (NLI) problem, thus relying on the knowledge captured by language models to identify the missing knowledge. Another line of work uses concept embeddings to identify what different concepts have in common, taking inspiration from cognitive models for category based induction. These two approaches are intuitively complementary, but their effectiveness has not yet been compared. In this paper, we introduce a benchmark for evaluating ontology completion methods and thoroughly analyse the strengths and weaknesses of both approaches. We find that both approaches are indeed complementary, with hybrid strategies achieving the best overall results. We also find that the task is highly challenging for Large Language Models, ev
    
[^73]: 从临床精神病学笔记中提取社会支持和社会孤立信息：比较基于规则的自然语言处理系统和大型语言模型

    Extracting Social Support and Social Isolation Information from Clinical Psychiatry Notes: Comparing a Rule-based NLP System and a Large Language Model

    [https://arxiv.org/abs/2403.17199](https://arxiv.org/abs/2403.17199)

    比较了基于规则的自然语言处理系统和大型语言模型在从临床精神病学笔记中提取社会支持和社会孤立信息方面的效果，结果显示基于规则系统在两个医疗机构中都获得了更高的分数。

    

    背景：社会支持（SS）和社会孤立（SI）是与精神病学结果相关的健康社会决定因素（SDOH）。在电子健康记录（EHRs）中，个体级SS/SI通常被记录为叙述性临床笔记，而不是结构化编码数据。自然语言处理（NLP）算法可以自动化数据提取的劳动密集型过程。数据与方法：来自Mount Sinai Health System（MSHS，n=300）和Weill Cornell Medicine（WCM，n=225）的精神病学会诊笔记被注释，并建立了一个黄金标准语料库。开发了一个涉及词汇表的基于规则的系统（RBS）和使用FLAN-T5-XL的大型语言模型（LLM）来识别SS和SI的提及及其子类别（例如，社会网络、工具性支持和孤独）。结果：对于提取SS/SI，RBS在MSHS（0.89 vs. 0.65）和WCM（0.75 vs. 0.51）均获得了更高的宏平均f分数。

    arXiv:2403.17199v1 Announce Type: new  Abstract: Background: Social support (SS) and social isolation (SI) are social determinants of health (SDOH) associated with psychiatric outcomes. In electronic health records (EHRs), individual-level SS/SI is typically documented as narrative clinical notes rather than structured coded data. Natural language processing (NLP) algorithms can automate the otherwise labor-intensive process of data extraction.   Data and Methods: Psychiatric encounter notes from Mount Sinai Health System (MSHS, n=300) and Weill Cornell Medicine (WCM, n=225) were annotated and established a gold standard corpus. A rule-based system (RBS) involving lexicons and a large language model (LLM) using FLAN-T5-XL were developed to identify mentions of SS and SI and their subcategories (e.g., social network, instrumental support, and loneliness).   Results: For extracting SS/SI, the RBS obtained higher macro-averaged f-scores than the LLM at both MSHS (0.89 vs. 0.65) and WCM (0
    
[^74]: GPT-4至少能够像人类一样理解语篇

    GPT-4 Understands Discourse at Least as Well as Humans Do

    [https://arxiv.org/abs/2403.17196](https://arxiv.org/abs/2403.17196)

    GPT-4在标准化语篇理解测试中表现出与人类相当的能力，尤其在推断未明确陈述信息方面显示出显著实力

    

    我们测试了一种领先的AI系统GPT-4是否像人类一样理解语篇，使用了一项标准化的语篇理解测试。参与者会被呈现简短的故事，然后回答八个是/否问题，探究他们对故事的理解。这些问题的格式旨在评估直接性（陈述 vs. 暗示）和显著性（主要观点 vs. 细节）的独立影响。鉴于人类表现水平非常高，GPT-4的表现略好于人类，但并无统计学显著差异。GPT-4和人类都表现出强大的能力，能够推断故事中未明确陈述的信息，这是对理解力的重要测试。

    arXiv:2403.17196v1 Announce Type: new  Abstract: We test whether a leading AI system GPT-4 understands discourse as well as humans do, using a standardized test of discourse comprehension. Participants are presented with brief stories and then answer eight yes/no questions probing their comprehension of the story. The questions are formatted to assess the separate impacts of directness (stated vs. implied) and salience (main idea vs. details). GPT-4 performs slightly, but not statistically significantly, better than humans given the very high level of human performance. Both GPT-4 and humans exhibit a strong ability to make inferences about information that is not explicitly stated in a story, a critical test of understanding.
    
[^75]: NUMTEMP：一个用于验证带有统计和时间表达式的论点的真实世界基准

    NUMTEMP: A real-world benchmark to verify claims with statistical and temporal expressions

    [https://arxiv.org/abs/2403.17169](https://arxiv.org/abs/2403.17169)

    NUMTEMP是一个真实世界基准，专注于验证复杂的数字论点，量化了现有解决方案的局限性，并提供了一种解决真实世界数字论点验证挑战的方法。

    

    自动事实检查在数字时代应对不断增长的错误信息方面引起了极大兴趣。现有系统主要专注于维基百科上的合成论点，并且在真实世界论点上也取得了显著进展。在本文中，我们发布了Numtemp，一个多样化、多领域的数据集，专门关注数字论点，包括时间、统计和多样化方面的细粒度元数据，并且具有不泄露的证据收集。这解决了验证真实世界数字论点的挑战，这些论点复杂，往往缺乏精确信息，这是现有作品主要关注合成论点未解决的问题。我们评估并量化了现有解决方案在验证数字论点任务中的局限性。我们还评估了基于论点分解的方法、基于数字理解的模型，我们的最佳基线实现了58.32的宏F1分数。这证明了Numtemp的关键价值。

    arXiv:2403.17169v1 Announce Type: cross  Abstract: Automated fact checking has gained immense interest to tackle the growing misinformation in the digital era. Existing systems primarily focus on synthetic claims on Wikipedia, and noteworthy progress has also been made on real-world claims. In this work, we release Numtemp, a diverse, multi-domain dataset focused exclusively on numerical claims, encompassing temporal, statistical and diverse aspects with fine-grained metadata and an evidence collection without leakage. This addresses the challenge of verifying real-world numerical claims, which are complex and often lack precise information, not addressed by existing works that mainly focus on synthetic claims. We evaluate and quantify the limitations of existing solutions for the task of verifying numerical claims. We also evaluate claim decomposition based methods, numerical understanding based models and our best baselines achieves a macro-F1 of 58.32. This demonstrates that Numtemp
    
[^76]: 反映男性凝视：量化19世纪和20世纪小说中的女性客体化

    Reflecting the Male Gaze: Quantifying Female Objectification in 19th and 20th Century Novels

    [https://arxiv.org/abs/2403.17158](https://arxiv.org/abs/2403.17158)

    通过提出量化女性客体化的框架，发现19世纪和20世纪小说中存在男性视角系统性对象化女性角色的证据

    

    受到Mulvey（1975年）关于文学和媒体研究中男性凝视的概念的启发，本文提出了一个分析性别偏见的框架，即女性客体化的程度：文本中女性个体被描绘为视觉愉悦对象的程度。我们的框架沿着两个轴度衡量女性客体化。首先，我们计算一个代理偏见分数，指示男性实体是否比女性实体更有可能在文本中出现为语法代理。接下来，通过分析文本引发的词嵌入空间（Caliskan等，2017），我们计算一个外貌偏见分数，指示女性实体是否与外貌相关词汇更紧密地联系。将我们的框架应用于19世纪和20世纪的小说中揭示了文学中的女性客体化证据：我们发现从男性视角写作的小说系统性地将女性角色客体化，而小说...

    arXiv:2403.17158v1 Announce Type: new  Abstract: Inspired by the concept of the male gaze (Mulvey, 1975) in literature and media studies, this paper proposes a framework for analyzing gender bias in terms of female objectification: the extent to which a text portrays female individuals as objects of visual pleasure. Our framework measures female objectification along two axes. First, we compute an agency bias score that indicates whether male entities are more likely to appear in the text as grammatical agents than female entities. Next, by analyzing the word embedding space induced by a text (Caliskan et al., 2017), we compute an appearance bias score that indicates whether female entities are more closely associated with appearance-related words than male entities. Applying our framework to 19th and 20th century novels reveals evidence of female objectification in literature: we find that novels written from a male perspective systematically objectify female characters, while novels 
    
[^77]: 任务无关的插入式后门攻击检测器

    Task-Agnostic Detector for Insertion-Based Backdoor Attacks

    [https://arxiv.org/abs/2403.17155](https://arxiv.org/abs/2403.17155)

    TABDet是一种任务无关的后门检测器，通过利用最终层logits和高效的池化技术，在多个自然语言处理任务中实现了统一的logit表示，展示了对传统任务特定方法的优越检测效果。

    

    文本后门攻击构成了重大安全威胁。当前的检测方法通常依赖于中间特征表示或重建潜在触发器，对句子分类之外的任务效果不佳，如在问答和命名实体识别等任务上遇到困难。我们引入了TABDet（任务无关后门检测器），这是一种用于后门检测的开创性的任务无关方法。TABDet利用最终层Logits结合高效的池化技术，实现了在三个流行的自然语言处理任务中统一的Logit表示。TABDet可以从多样的任务特定模型中共同学习，展示了对传统任务特定方法的优越检测效果。

    arXiv:2403.17155v1 Announce Type: new  Abstract: Textual backdoor attacks pose significant security threats. Current detection approaches, typically relying on intermediate feature representation or reconstructing potential triggers, are task-specific and less effective beyond sentence classification, struggling with tasks like question answering and named entity recognition. We introduce TABDet (Task-Agnostic Backdoor Detector), a pioneering task-agnostic method for backdoor detection. TABDet leverages final layer logits combined with an efficient pooling technique, enabling unified logit representation across three prominent NLP tasks. TABDet can jointly learn from diverse task-specific models, demonstrating superior detection efficacy over traditional task-specific methods.
    
[^78]: 用于抵制仇恨言论的结果受限大型语言模型

    Outcome-Constrained Large Language Models for Countering Hate Speech

    [https://arxiv.org/abs/2403.17146](https://arxiv.org/abs/2403.17146)

    该研究探索了利用大型语言模型生成受潜在对话结果限制的对话，以应对在线仇恨言论，通过构建对话结果分类器和提出整合方法，为在线环境中生成对抗性对话提供了新途径

    

    挑战或回应仇恨言论的对话被视为缓解仇恨言论的负面影响并促进在线交流的替代方法。研究已致力于使用语言模型自动生成对话以协助打击在线仇恨言论。现有研究侧重于生成具有特定语言属性（如礼貌、信息丰富和意图驱动）的对话。然而，对话可能对在线环境产生什么影响仍不明确。我们首先探讨利用大型语言模型（LLM）生成受潜在对话结果限制的对话的方法。我们构建了两个对话结果分类器，用Reddit数据预测应对仇恨言论后的不文明程度和仇恨者重新关注行为，然后提出了四种方法来整合所需的结果，即低礼貌

    arXiv:2403.17146v1 Announce Type: new  Abstract: Counterspeech that challenges or responds to hate speech has been seen as an alternative to mitigate the negative impact of hate speech and foster productive online communications. Research endeavors have been directed to using language models for the automatic generation of counterspeech to assist efforts in combating online hate. Existing research focuses on the generation of counterspeech with certain linguistic attributes, such as being polite, informative, and intent-driven. However, it remains unclear what impact the counterspeech might have in an online environment. We first explore methods that utilize large language models (LLM) to generate counterspeech constrained by potential conversation outcomes. We build two conversation outcome classifiers that predict the incivility level and the hater reentry behavior following replies to hate with Reddit data, then propose four methods to incorporate the desired outcomes, i.e., low con
    
[^79]: 引导远程监督用于多语言关系抽取数据：适应新语言

    Guided Distant Supervision for Multilingual Relation Extraction Data: Adapting to a New Language

    [https://arxiv.org/abs/2403.17143](https://arxiv.org/abs/2403.17143)

    本文应用引导远程监督方法，为德语创建了最大的传记关系抽取数据集，同时发布了手动标注的评估数据集。

    

    摘要：关系抽取对于在数字人文学和相关学科背景下提取和理解传记信息至关重要。社区对构建能够训练机器学习模型提取关系的数据集越来越感兴趣。然而，标注这样的数据集可能既昂贵又耗时，而且仅限于英语。本文应用了引导式远程监督方法，为德语创建了一个大型传记关系抽取数据集。我们的数据集包含了超过80,000个实例，涵盖了九种关系类型，是最大的德语传记关系抽取数据集。我们还创建了一个手动标注的数据集，包含2000个实例用于评估模型，并与利用引导式远程监督方法编制的数据集一起发布。我们在自动生成的数据集上训练了几种最先进的机器学习模型，并将其发布。

    arXiv:2403.17143v1 Announce Type: new  Abstract: Relation extraction is essential for extracting and understanding biographical information in the context of digital humanities and related subjects. There is a growing interest in the community to build datasets capable of training machine learning models to extract relationships. However, annotating such datasets can be expensive and time-consuming, in addition to being limited to English. This paper applies guided distant supervision to create a large biographical relationship extraction dataset for German. Our dataset, composed of more than 80,000 instances for nine relationship types, is the largest biographical German relationship extraction dataset. We also create a manually annotated dataset with 2000 instances to evaluate the models and release it together with the dataset compiled using guided distant supervision. We train several state-of-the-art machine learning models on the automatically created dataset and release them as 
    
[^80]: MetaAligner：用于语言模型通用多目标对齐的条件从弱到强校正

    MetaAligner: Conditional Weak-to-Strong Correction for Generalizable Multi-Objective Alignment of Language Models

    [https://arxiv.org/abs/2403.17141](https://arxiv.org/abs/2403.17141)

    MetaAligner是第一个与策略无关且通用的多目标偏好对齐方法，通过将参数更新与策略模型解耦实现即插即用的对齐，并通过上下文学习实现未见目标的零冷启动偏好对齐

    

    近期大型语言模型（LLM）的进展旨在通过多目标偏好对齐来解决异质人类期望和价值观，然而，现有方法受到策略模型的参数限制，导致两个关键局限性：（1）它们的对齐算法对于每个新目标模型的重复成本很高；（2）由于其静态对齐目标，它们无法扩展到未见目标。在这项工作中，我们提出了Meta-Objective Aligner（MetaAligner），这是一种执行条件从弱到强校正以逼近强响应的模型。MetaAligner是第一个与策略无关且通用的多目标偏好对齐方法，它通过将参数更新与策略模型解耦实现即插即用的对齐，并通过上下文学习实现未见目标的零冷启动偏好对齐。实验结果表明，MetaAligner取得了显著

    arXiv:2403.17141v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) aim to tackle heterogeneous human expectations and values via multi-objective preference alignment. However, existing methods are parameter-adherent to the policy model, leading to two key limitations: (1) the high-cost repetition of their alignment algorithms for each new target model; (2) they cannot expand to unseen objectives due to their static alignment objectives. In this work, we propose Meta-Objective Aligner (MetaAligner), a model that performs conditional weak-to-strong correction for weak responses to approach strong responses. MetaAligner is the first policy-agnostic and generalizable method for multi-objective preference alignment, which enables plug-and-play alignment by decoupling parameter updates from the policy models and facilitates zero-shot preference alignment for unseen objectives via in-context learning. Experimental results show that MetaAligner achieves sign
    
[^81]: 探索癌症临床试验资格分类器在疾病间的泛化性能

    Exploring the Generalization of Cancer Clinical Trial Eligibility Classifiers Across Diseases

    [https://arxiv.org/abs/2403.17135](https://arxiv.org/abs/2403.17135)

    本研究评估了癌症临床试验资格分类器在不同疾病间的泛化性能，发现在广泛癌症数据集上训练的模型可以处理非癌症试验的标准，但在某些情况下仍然存在困难。

    

    临床试验对于医学研究至关重要，自然语言处理可增强其成功，在招募方面有应用。本研究旨在评估资格分类在广泛临床试验范围内的泛化性能。从阶段3癌症试验开始，标记有七种资格排除条件，然后确定模型在非癌症和非阶段3试验中的泛化效果。为评估此问题，我们整理了五种试验类型的资格标准数据：（1）其他阶段3癌症试验，（2）癌症阶段1和2试验，（3）心脏病试验，（4）2型糖尿病试验和（5）任何疾病的观察性试验，跨七种排除类型共涵盖了2,490个已标注的资格标准。我们的结果显示，在广泛癌症数据集上训练的模型可以有效处理非癌症试验中常见的标准，如自身免疫疾病。然而，它们在处理诸如缺乏标准等标准时会遇到困难。

    arXiv:2403.17135v1 Announce Type: new  Abstract: Clinical trials are pivotal in medical research, and NLP can enhance their success, with application in recruitment. This study aims to evaluate the generalizability of eligibility classification across a broad spectrum of clinical trials. Starting with phase 3 cancer trials, annotated with seven eligibility exclusions, then to determine how well models can generalize to non-cancer and non-phase 3 trials. To assess this, we have compiled eligibility criteria data for five types of trials: (1) additional phase 3 cancer trials, (2) phase 1 and 2 cancer trials, (3) heart disease trials, (4) type 2 diabetes trials, and (5) observational trials for any disease, comprising 2,490 annotated eligibility criteria across seven exclusion types. Our results show that models trained on the extensive cancer dataset can effectively handle criteria commonly found in non-cancer trials, such as autoimmune diseases. However, they struggle with criteria disp
    
[^82]: 大型语言模型中先验知识的强大作用及其对情绪识别的影响

    The Strong Pull of Prior Knowledge in Large Language Models and Its Impact on Emotion Recognition

    [https://arxiv.org/abs/2403.17125](https://arxiv.org/abs/2403.17125)

    大型语言模型在执行任务时依赖背景知识（先验知识），但无法完全整合与任务先验知识相矛盾的信息，影响了情绪识别等主观任务的表现水平。

    

    In-context Learning (ICL)作为一种强大的范式浮现出来，可以在大型语言模型（LLM）上执行自然语言任务，而无需更新模型的参数，与传统的基于梯度的微调相反。 ICL的承诺是，LLM可以适应执行当前任务，并以竞争力或最新水平的一小部分成本。 LLM以这种少样本的方式执行任务的能力依赖于它们对任务的背景知识（或任务先验知识）。然而，最近的研究发现，与传统学习不同，LLM无法完全整合与任务先验知识相矛盾的演示信息。 这可能导致表现达到次优水平，特别是对于主观任务（如情绪识别），其中文本到情绪的映射可能因人类注释的变异性而大不相同。 在这项工作中，我们设计实验并提出了测量方法

    arXiv:2403.17125v1 Announce Type: cross  Abstract: In-context Learning (ICL) has emerged as a powerful paradigm for performing natural language tasks with Large Language Models (LLM) without updating the models' parameters, in contrast to the traditional gradient-based finetuning. The promise of ICL is that the LLM can adapt to perform the present task at a competitive or state-of-the-art level at a fraction of the cost. The ability of LLMs to perform tasks in this few-shot manner relies on their background knowledge of the task (or task priors). However, recent work has found that, unlike traditional learning, LLMs are unable to fully integrate information from demonstrations that contrast task priors. This can lead to performance saturation at suboptimal levels, especially for subjective tasks such as emotion recognition, where the mapping from text to emotions can differ widely due to variability in human annotations. In this work, we design experiments and propose measurements to e
    
[^83]: 将语言计划基于演示通过反事实干扰进行落实

    Grounding Language Plans in Demonstrations Through Counterfactual Perturbations

    [https://arxiv.org/abs/2403.17124](https://arxiv.org/abs/2403.17124)

    这项工作通过使用LLMs来指导多步演示中隐含的任务结构和约束的搜索，以及通过反事实干扰获得更广泛的演示状态空间覆盖。

    

    将大型语言模型的常识推理基于物理领域落实在体现智能的人工智能中仍然是一个至关重要但尚未解决的问题。相较于先前的工作专注于直接利用LLMs在符号空间内规划，这项工作使用LLMs指导任务结构的搜索，隐含在多步演示中的约束。具体而言，我们借鉴了操纵规划文献中的模式族的概念，它按照特定运动约束将机器人配置分组，作为LLM高级语言表示和机器人低级物理轨迹之间的抽象层。通过用合成干扰重新播放少量人类演示，我们可以覆盖演示的状态空间，并额外生成成功执行以及未完成任务的反事实情况。我们的基于解释的学习框架训练了一个端到端可微分神经网络。

    arXiv:2403.17124v1 Announce Type: cross  Abstract: Grounding the common-sense reasoning of Large Language Models in physical domains remains a pivotal yet unsolved problem for embodied AI. Whereas prior works have focused on leveraging LLMs directly for planning in symbolic spaces, this work uses LLMs to guide the search of task structures and constraints implicit in multi-step demonstrations. Specifically, we borrow from manipulation planning literature the concept of mode families, which group robot configurations by specific motion constraints, to serve as an abstraction layer between the high-level language representations of an LLM and the low-level physical trajectories of a robot. By replaying a few human demonstrations with synthetic perturbations, we generate coverage over the demonstrations' state space with additional successful executions as well as counterfactuals that fail the task. Our explanation-based learning framework trains an end-to-end differentiable neural networ
    
[^84]: 首先增加属性，然后生成：局部可归属的文本生成

    Attribute First, then Generate: Locally-attributable Grounded Text Generation

    [https://arxiv.org/abs/2403.17104](https://arxiv.org/abs/2403.17104)

    该论文提出了一种局部可归属的文本生成方法，通过“先增加属性，然后生成”的方式将生成过程分为内容选择、句子规划和序列句子生成三个步骤，以简化引用验证工作。

    

    最近，解决大型语言模型（LLMs）中的幻觉的努力主要集中在属性文本生成上，这种方法通过引用支持源在生成的文本中加入支持文本以进行事后事实核查和更正。然而，这些引用通常指向整个文档或段落，给用户带来了繁重的验证工作。在本文中，我们介绍了一种局部可归属的文本生成方法，重点放在简洁的属性上。我们的方法命名为“先增加属性，然后生成”，将传统的端到端生成过程分解为三个直观的步骤：内容选择、句子规划和序列句子生成。通过首先识别相关来源部分（“先选择”），然后在生成过程中对它们进行条件化（“然后生成”），我们确保这些部分也作为输出的细粒度属性（“选择”变为“属性”）。 在Mu上经过测试

    arXiv:2403.17104v1 Announce Type: new  Abstract: Recent efforts to address hallucinations in Large Language Models (LLMs) have focused on attributed text generation, which supplements generated texts with citations of supporting sources for post-generation fact-checking and corrections. Yet, these citations often point to entire documents or paragraphs, burdening users with extensive verification work. In this paper, we introduce a locally-attributable text generation approach, prioritizing concise attributions. Our method, named ``Attribute First, then Generate'', breaks down the conventional end-to-end generation process into three intuitive steps: content selection, sentence planning, and sequential sentence generation. By initially identifying relevant source segments (``select first'') and then conditioning the generation process on them (``then generate''), we ensure these segments also act as the output's fine-grained attributions (``select'' becomes ``attribute''). Tested on Mu
    
[^85]: LLM Agent Operating System

    LLM Agent Operating System

    [https://arxiv.org/abs/2403.16971](https://arxiv.org/abs/2403.16971)

    提出了一种将大型语言模型嵌入操作系统中的LLM代理操作系统，旨在优化资源分配、促进代理间上下文切换、实现并发执行以及为代理提供工具服务。

    

    arXiv:2403.16971v1 公告类型: 跨领域 摘要: 部署大型语言模型（LLM）智能代理存在诸多挑战，会损害它们的效率和功效。其中包括代理请求在LLM上的次优调度和资源分配、在代理和LLM之间交互时保持上下文的困难，以及将具有不同能力和专业化的异构代理集成在一起的复杂性。代理数量和复杂性的快速增加进一步加剧了这些问题，通常会导致资源瓶颈和次优资源利用。受到这些挑战的启发，本文提出了AIOS，一种LLM代理操作系统，它将大型语言模型嵌入操作系统（OS）中。具体地，AIOS旨在优化资源分配，促进代理之间的上下文切换，实现代理的并发执行，为代理提供工具服务。

    arXiv:2403.16971v1 Announce Type: cross  Abstract: The integration and deployment of large language model (LLM)-based intelligent agents have been fraught with challenges that compromise their efficiency and efficacy. Among these issues are sub-optimal scheduling and resource allocation of agent requests over the LLM, the difficulties in maintaining context during interactions between agent and LLM, and the complexities inherent in integrating heterogeneous agents with different capabilities and specializations. The rapid increase of agent quantity and complexity further exacerbates these issues, often leading to bottlenecks and sub-optimal utilization of resources. Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS). Specifically, AIOS is designed to optimize resource allocation, facilitate context switch across agents, enable concurrent execution of agents, provide tool service for agents
    
[^86]: 与人类判断相一致：大型语言模型评估中成对偏好的作用

    Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators

    [https://arxiv.org/abs/2403.16950](https://arxiv.org/abs/2403.16950)

    在大型语言模型评估中，通过引入成对偏好搜索方法PAIRS，成功解决了LLMs与人类判断不一致的问题，并取得了优于直接打分的最先进性能。

    

    大型语言模型（LLMs）作为自动评估器在评估生成的自然语言质量方面表现出有希望的能力。然而，LLMs在评估中仍存在偏见，常常难以生成与人类评估一致的连贯评估。在这项工作中，我们首先对LLM评估器与人类判断之间的不一致进行系统研究，揭示现有旨在减轻偏见的校准方法不足以有效将LLM评估器对齐。受到RLHF中对偏好数据的使用的启发，我们将评估形式化为一个排序问题，并引入Pairwise-preference Search（PAIRS），这是一种以LLMs进行成对比较并有效对候选文本进行排序的基于不确定性引导的搜索方法。PAIRS在代表性评估任务上实现了最先进的性能，并且显示出比直接打分有显著改进。

    arXiv:2403.16950v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated promising capabilities as automatic evaluators in assessing the quality of generated natural language. However, LLMs still exhibit biases in evaluation and often struggle to generate coherent evaluations that align with human assessments. In this work, we first conduct a systematic study of the misalignment between LLM evaluators and human judgement, revealing that existing calibration methods aimed at mitigating biases are insufficient for effectively aligning LLM evaluators. Inspired by the use of preference data in RLHF, we formulate the evaluation as a ranking problem and introduce Pairwise-preference Search (PAIRS), an uncertainty-guided search method that employs LLMs to conduct pairwise comparisons and efficiently ranks candidate texts. PAIRS achieves state-of-the-art performance on representative evaluation tasks and demonstrates significant improvements over direct scoring. Furthe
    
[^87]: 利用预训练语言模型进行粗调优的专题文档检索

    Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models

    [https://arxiv.org/abs/2403.16915](https://arxiv.org/abs/2403.16915)

    本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调，在专题文档检索中显著改善了效果。

    

    在信息检索系统中，利用预训练语言模型（PLM-based IR）进行微调需要学习查询表示和查询-文档关系，除了下游任务特定的学习。本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调。通过在粗调优学习查询表示和查询-文档关系，我们旨在减少微调的负担，提高下游IR任务的学习效果。我们提出了用于粗调优的查询-文档对预测（QDPP），其预测查询-文档对的适当性。评估实验显示，所提出的方法显著改善了四个专题文档检索数据集中的MRR和/或nDCG@5。此外，查询预测任务的结果表明，粗调优促进了查询表示和查询-文档关系的学习。

    arXiv:2403.16915v1 Announce Type: cross  Abstract: Fine-tuning in information retrieval systems using pre-trained language models (PLM-based IR) requires learning query representations and query-document relations, in addition to downstream task-specific learning. This study introduces coarse-tuning as an intermediate learning stage that bridges pre-training and fine-tuning. By learning query representations and query-document relations in coarse-tuning, we aim to reduce the load of fine-tuning and improve the learning effect of downstream IR tasks. We propose Query-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the appropriateness of query-document pairs. Evaluation experiments show that the proposed method significantly improves MRR and/or nDCG@5 in four ad-hoc document retrieval datasets. Furthermore, the results of the query prediction task suggested that coarse-tuning facilitated learning of query representation and query-document relations.
    
[^88]: RU22Fact：优化多语言可解释事实核查中的证据

    RU22Fact: Optimizing Evidence for Multilingual Explainable Fact-Checking on Russia-Ukraine Conflict

    [https://arxiv.org/abs/2403.16662](https://arxiv.org/abs/2403.16662)

    提出了一个基于大型语言模型的方法，用于自动检索和总结网络中的证据，构建了RU22Fact数据集，是关于2022年俄乌冲突的多语言可解释事实核查数据集，同时开发了端到端可解释的事实核查系统来验证声明并生成解释。

    

    事实核查是通过检查现有证据来验证给定声明的准确性的任务。高质量的证据在增强事实核查系统并促进生成可理解的解释方面发挥着至关重要的作用。然而，为可解释的事实核查系统提供足够和相关的证据是一项挑战。为了解决这一挑战，我们提出了一种基于大型语言模型的方法，可以自动从网络中检索和总结证据。此外，我们构建了RU22Fact，这是一个关于2022年俄乌冲突的新型多语言可解释事实核查数据集，包含1.6万个样本，每个样本都包含现实世界的声明、优化证据和引用的解释。为了为我们的数据集建立基准，我们还开发了一个端到端可解释的事实核查系统，用于核实声明并生成解释。实验结果显示了前景。

    arXiv:2403.16662v1 Announce Type: new  Abstract: Fact-checking is the task of verifying the factuality of a given claim by examining the available evidence. High-quality evidence plays a vital role in enhancing fact-checking systems and facilitating the generation of explanations that are understandable to humans. However, the provision of both sufficient and relevant evidence for explainable fact-checking systems poses a challenge. To tackle this challenge, we propose a method based on a Large Language Model to automatically retrieve and summarize evidence from the Web. Furthermore, we construct RU22Fact, a novel multilingual explainable fact-checking dataset on the Russia-Ukraine conflict in 2022 of 16K samples, each containing real-world claims, optimized evidence, and referenced explanation. To establish a baseline for our dataset, we also develop an end-to-end explainable fact-checking system to verify claims and generate explanations. Experimental results demonstrate the prospect
    
[^89]: 生物医学与健康信息学中的大型语言模型：一项文献计量学综述

    Large Language Models in Biomedical and Health Informatics: A Bibliometric Review

    [https://arxiv.org/abs/2403.16303](https://arxiv.org/abs/2403.16303)

    LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。

    

    大型语言模型（LLMs）迅速成为生物医学与健康信息学（BHI）中的重要工具，为分析数据、治疗患者和开展研究提供了新的方式。本文献计量学综述旨在通过检查自2022年至2023年的研究文章和合作网络，全面展示LLMs在BHI中的应用情况。它进一步探讨了LLMs如何可以改进各种BHI领域中的自然语言处理（NLP）应用，如医学诊断、患者参与、电子健康记录管理和个性化医学。为此，我们的文献计量学综述确定了关键趋势，绘制了研究网络，并突出了这个快速发展领域的主要进展。最后，它讨论了在BHI中使用LLMs的伦理关切和实际挑战，如数据隐私和可靠的医疗建议。展望未来，我们考虑LLMs如何进一步改变生物医学研究。

    arXiv:2403.16303v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have rapidly become important tools in Biomedical and Health Informatics (BHI), enabling new ways to analyze data, treat patients, and conduct research. This bibliometric review aims to provide a panoramic view of how LLMs have been used in BHI by examining research articles and collaboration networks from 2022 to 2023. It further explores how LLMs can improve Natural Language Processing (NLP) applications in various BHI areas like medical diagnosis, patient engagement, electronic health record management, and personalized medicine. To do this, our bibliometric review identifies key trends, maps out research networks, and highlights major developments in this fast-moving field. Lastly, it discusses the ethical concerns and practical challenges of using LLMs in BHI, such as data privacy and reliable medical recommendations. Looking ahead, we consider how LLMs could further transform biomedical research as we
    
[^90]: 大型语言模型为传统主题建模方法提供了另一种选择

    Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling

    [https://arxiv.org/abs/2403.16248](https://arxiv.org/abs/2403.16248)

    大型语言模型作为主题建模的替代方法，能够生成相关主题标题并遵循人类指南来精细化和合并主题

    

    主题建模作为一种成熟的无监督技术，在自动检测文档语料库中的重要主题方面得到了广泛应用。然而，经典的主题建模方法（例如LDA）存在某些缺点，例如缺乏语义理解和主题重叠的存在。本文研究了大型语言模型（LLMs）作为揭示广泛文本语料库中潜在主题的一种替代方法的潜力。为此，我们引入了一个框架，促使LLMs从给定的一组文档中生成主题，并建立了评估协议来评估LLMs的聚类效果。我们的发现表明，LLMs在适当的提示下可以脱颖而出作为一种可行的替代方案，能够生成相关的主题标题并遵循人类指南来精细化和合并主题。通过深入的实验和评估，我们总结了这种优势。

    arXiv:2403.16248v1 Announce Type: new  Abstract: Topic modelling, as a well-established unsupervised technique, has found extensive use in automatically detecting significant topics within a corpus of documents. However, classic topic modelling approaches (e.g., LDA) have certain drawbacks, such as the lack of semantic understanding and the presence of overlapping topics. In this work, we investigate the untapped potential of large language models (LLMs) as an alternative for uncovering the underlying topics within extensive text corpora. To this end, we introduce a framework that prompts LLMs to generate topics from a given set of documents and establish evaluation protocols to assess the clustering efficacy of LLMs. Our findings indicate that LLMs with appropriate prompts can stand out as a viable alternative, capable of generating relevant topic titles and adhering to human guidelines to refine and merge topics. Through in-depth experiments and evaluation, we summarise the advantage
    
[^91]: 利用语义重建减少视觉-语言模型中的幻觉

    Exploiting Semantic Reconstruction to Mitigate Hallucinations in Vision-Language Models

    [https://arxiv.org/abs/2403.16167](https://arxiv.org/abs/2403.16167)

    通过准确定位和惩罚幻觉标记，ESREAL引入了一种新颖的无监督学习框架，通过语义重建来抑制生成幻觉，解决了视觉-语言模型中幻觉问题。

    

    视觉-语言模型中的幻觉对其可靠性构成重大挑战，特别是在生成长标题时。当前方法无法准确识别和减轻这些幻觉。为了解决这个问题，我们引入了ESREAL，这是一个新颖的无监督学习框架，旨在通过准确定位和惩罚幻觉标记来抑制幻觉生成。最初，ESREAL根据生成的标题创建一个重建图像，并将其对应区域与原始图像的区域对齐。这种语义重建有助于识别生成标题中的标记级幻觉的存在和类型。随后，ESREAL通过评估对齐区域的语义相似性来计算标记级幻觉分数，基于幻觉的类型。最后，ESREAL采用一种近端策略优化算法，进行...

    arXiv:2403.16167v1 Announce Type: cross  Abstract: Hallucinations in vision-language models pose a significant challenge to their reliability, particularly in the generation of long captions. Current methods fall short of accurately identifying and mitigating these hallucinations. To address this issue, we introduce ESREAL, a novel unsupervised learning framework designed to suppress the generation of hallucinations through accurate localization and penalization of hallucinated tokens. Initially, ESREAL creates a reconstructed image based on the generated caption and aligns its corresponding regions with those of the original image. This semantic reconstruction aids in identifying both the presence and type of token-level hallucinations within the generated caption. Subsequently, ESREAL computes token-level hallucination scores by assessing the semantic similarity of aligned regions based on the type of hallucination. Finally, ESREAL employs a proximal policy optimization algorithm, wh
    
[^92]: STEntConv：利用立场检测和有符号图卷积网络预测不同意见

    STEntConv: Predicting Disagreement with Stance Detection and a Signed Graph Convolutional Network

    [https://arxiv.org/abs/2403.15885](https://arxiv.org/abs/2403.15885)

    STEntConv利用用户立场建立了用户和命名实体的加权图，通过有符号图卷积网络预测Reddit帖子中的不同意见表达。

    

    社交媒体平台的兴起导致极化的在线讨论增加，特别是关于选举和气候变化等政治和社会文化话题。我们提出了一种简单且新颖的无监督方法，用于预测两篇文章的作者是否同意或不同意，利用从他们的文章中获得的关于命名实体的用户立场。我们提出了STEntConv模型，该模型构建了一个由立场加权的用户和命名实体图，并训练了一个有符号图卷积网络（SGCN）来检测评论和回复帖子之间的不同意见。我们进行了实验和消融研究，并展示出包含此信息可以改善Reddit帖子数据集上有争议的子版主题的不同意见检测性能，而无需平台特定特征或用户历史。

    arXiv:2403.15885v1 Announce Type: new  Abstract: The rise of social media platforms has led to an increase in polarised online discussions, especially on political and socio-cultural topics such as elections and climate change. We propose a simple and novel unsupervised method to predict whether the authors of two posts agree or disagree, leveraging user stances about named entities obtained from their posts. We present STEntConv, a model which builds a graph of users and named entities weighted by stance and trains a Signed Graph Convolutional Network (SGCN) to detect disagreement between comment and reply posts. We run experiments and ablation studies and show that including this information improves disagreement detection performance on a dataset of Reddit posts for a range of controversial subreddit topics, without the need for platform-specific features or user history.
    
[^93]: 面向电子离子对撞机的基于RAG的摘要生成代理

    Towards a \textbf{RAG}-based Summarization Agent for the Electron-Ion Collider

    [https://arxiv.org/abs/2403.15729](https://arxiv.org/abs/2403.15729)

    开发了一种面向电子离子对撞机的基于RAG的摘要生成代理，能够压缩信息并引用相关回复，为合作者提供重大优势

    

    复杂性和庞大的信息量涵盖了大规模实验的文件、论文、数据和其他资源，导致导航这些多样形式信息的任务需要大量时间和精力，对于新合作者和早期科学家来说尤为艰巨。为了解决这个问题，正在开发一种基于检索增强生成（RAG）的EIC摘要生成人工智能代理（RAGS4EIC）。该人工智能代理不仅压缩信息，还有效引用相关回复，为合作者提供了重大优势。我们的项目采取了两步方法：首先，查询包含所有相关实验信息的综合向量数据库；其次，利用大型语言模型（LLM）根据用户查询和检索数据生成包含引用的简洁摘要。我们描述了使用RAG评估的评估方法

    arXiv:2403.15729v1 Announce Type: cross  Abstract: The complexity and sheer volume of information encompassing documents, papers, data, and other resources from large-scale experiments demand significant time and effort to navigate, making the task of accessing and utilizing these varied forms of information daunting, particularly for new collaborators and early-career scientists. To tackle this issue, a Retrieval Augmented Generation (RAG)--based Summarization AI for EIC (RAGS4EIC) is under development. This AI-Agent not only condenses information but also effectively references relevant responses, offering substantial advantages for collaborators. Our project involves a two-step approach: first, querying a comprehensive vector database containing all pertinent experiment information; second, utilizing a Large Language Model (LLM) to generate concise summaries enriched with citations based on user queries and retrieved data. We describe the evaluation methods that use RAG assessments 
    
[^94]: 出身富贵？探讨大型语言模型中的社会经济偏见

    Born With a Silver Spoon? Investigating Socioeconomic Bias in Large Language Models

    [https://arxiv.org/abs/2403.14633](https://arxiv.org/abs/2403.14633)

    本文调查了大型语言模型中是否存在社会经济偏见，引入了一个新的数据集SilverSpoon，并评估了这种偏见的程度以及随着模型大小的变化。

    

    社会经济偏见在社会中加剧了不公平现象，根据个人经济和社会背景影响获取机会和资源的机会。这一普遍问题持续地延续了系统性的不平等，阻碍了作为一个社会追求包容性进步。在本文中，我们调查了大型语言模型中是否存在社会经济偏见。为此，我们引入了一个新的数据集（SilverSpoon），包含3000个样本，展示了牵涉到弱势群体由于他们的处境而实施道德模糊行为的假设情景，并问这种行为是否在道德上成立。此外，这个数据集具有双重标记方案，并由属于社会经济两端的人进行了注释。使用SilverSpoon，我们评估了大型语言模型中表现出的社会经济偏见程度以及该程度如何随模型大小变化。

    arXiv:2403.14633v1 Announce Type: cross  Abstract: Socioeconomic bias in society exacerbates disparities, influencing access to opportunities and resources based on individuals' economic and social backgrounds. This pervasive issue perpetuates systemic inequalities, hindering the pursuit of inclusive progress as a society. In this paper, we investigate the presence of socioeconomic bias, if any, in large language models. To this end, we introduce a novel dataset (SilverSpoon), consisting of 3000 samples that illustrate hypothetical scenarios that involve underprivileged people performing ethically ambiguous actions due to their circumstances, and ask whether the action is ethically justified. Further, this dataset has a dual-labeling scheme and has been annotated by people belonging to both ends of the socioeconomic spectrum. Using SilverSpoon, we evaluate the degree of socioeconomic bias expressed in large language models and the variation of this degree as a function of model size. W
    
[^95]: 一种利用大型语言模型进行设备定向语音检测的多模态方法

    A Multimodal Approach to Device-Directed Speech Detection with Large Language Models

    [https://arxiv.org/abs/2403.14438](https://arxiv.org/abs/2403.14438)

    探索了一种利用大型语言模型进行设备定向语音检测的多模态方法，相比于文本和音频模型，使用多模态信息能够显著提高相等错误率。

    

    虚拟助手的交互通常从预定义触发短语开始，然后是用户命令。为了使与助手的交互更直观，我们探讨了是否可以放弃用户必须用触发短语开始每个命令的要求。我们通过三种方式探索了这个任务：首先，我们仅使用从音频波形中获得的声学信息训练分类器。其次，我们将自动语音识别（ASR）系统的解码器输出，例如1-best假设，作为输入特征输入到大型语言模型（LLM）中。最后，我们探讨了一种多模态系统，将声学和词汇特征以及ASR解码器信号结合在LLM中。使用多模态信息相对于仅文本和仅音频模型提高了相等错误率高达39%和61%。增加LLM的大小并通过低秩调整进行训练进一步减少了相对EER值的减少

    arXiv:2403.14438v1 Announce Type: new  Abstract: Interactions with virtual assistants typically start with a predefined trigger phrase followed by the user command. To make interactions with the assistant more intuitive, we explore whether it is feasible to drop the requirement that users must begin each command with a trigger phrase. We explore this task in three ways: First, we train classifiers using only acoustic information obtained from the audio waveform. Second, we take the decoder outputs of an automatic speech recognition (ASR) system, such as 1-best hypotheses, as input features to a large language model (LLM). Finally, we explore a multimodal system that combines acoustic and lexical features, as well as ASR decoder signals in an LLM. Using multimodal information yields relative equal-error-rate improvements over text-only and audio-only models of up to 39% and 61%. Increasing the size of the LLM and training with low-rank adaption leads to further relative EER reductions o
    
[^96]: 一种智能交互式写作助手的设计空间

    A Design Space for Intelligent and Interactive Writing Assistants

    [https://arxiv.org/abs/2403.14117](https://arxiv.org/abs/2403.14117)

    通过提出一种设计空间，帮助研究人员和设计师在多维空间中检验和探索智能交互式写作助手的各种可能性。

    

    在我们这个快速科技发展的时代，写作助手的研究领域已经在各个研究社区中变得日益分散。我们通过提出一种设计空间来解决这一挑战，作为一种结构化的方法来检验和探索智能交互式写作助手的多维空间。通过大型社区协作，我们探讨了写作助手的五个方面：任务、用户、技术、交互和生态系统。在每个方面，我们通过系统审阅115篇论文定义了维度（即方面的基本组成部分）和代码（即每个维度的可能选项）。我们的设计空间旨在为研究人员和设计师提供一个实用工具，帮助他们导航、理解和比较写作助手的各种可能性，并帮助构思和设计新的写作助手。

    arXiv:2403.14117v1 Announce Type: cross  Abstract: In our era of rapid technological advancement, the research landscape for writing assistants has become increasingly fragmented across various research communities. We seek to address this challenge by proposing a design space as a structured way to examine and explore the multidimensional space of intelligent and interactive writing assistants. Through a large community collaboration, we explore five aspects of writing assistants: task, user, technology, interaction, and ecosystem. Within each aspect, we define dimensions (i.e., fundamental components of an aspect) and codes (i.e., potential options for each dimension) by systematically reviewing 115 papers. Our design space aims to offer researchers and designers a practical tool to navigate, comprehend, and compare the various possibilities of writing assistants, and aid in the envisioning and design of new writing assistants.
    
[^97]: EthioLLM：用于埃塞俄比亚语言的多语言大型语言模型及任务评估

    EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation

    [https://arxiv.org/abs/2403.13737](https://arxiv.org/abs/2403.13737)

    EthioLLM为埃塞俄比亚五种语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）以及英语引入了多语言大型语言模型，并提出了一个新的基准数据集Ethiobenchmark，为各种下游自然语言处理任务评估了这些模型的性能。

    

    大型语言模型（LLMs）近来因其在各种下游自然语言处理（NLP）任务中的出色表现而备受青睐。然而，由于训练LLMs的资源不足，低资源语言仍落后于NLP领域的最新发展。埃塞俄比亚语言拥有显著的语言多样性，包括广泛的文字系统，并富有深远的宗教和文化意义。本文介绍了EthioLLM - 五种埃塞俄比亚语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）和英语的多语言大型语言模型，以及Ethiobenchmark - 用于各种下游NLP任务的新基准数据集。我们评估了这些模型在五个下游NLP任务中的性能。我们开源我们的多语言语言模型、各种下游任务的新基准数据集和任务特定的精调语言

    arXiv:2403.13737v1 Announce Type: new  Abstract: Large language models (LLMs) have gained popularity recently due to their outstanding performance in various downstream Natural Language Processing (NLP) tasks. However, low-resource languages are still lagging behind current state-of-the-art (SOTA) developments in the field of NLP due to insufficient resources to train LLMs. Ethiopian languages exhibit remarkable linguistic diversity, encompassing a wide array of scripts, and are imbued with profound religious and cultural significance. This paper introduces EthioLLM -- multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a new benchmark dataset for various downstream NLP tasks. We evaluate the performance of these models across five downstream NLP tasks. We open-source our multilingual language models, new benchmark datasets for various downstream tasks, and task-specific fine-tuned languag
    
[^98]: 从细粒度文本描述中生成运动

    Motion Generation from Fine-grained Textual Descriptions

    [https://arxiv.org/abs/2403.13518](https://arxiv.org/abs/2403.13518)

    本文提出了一种从细粒度文本描述中生成运动的方法，构建了FineHumanML3D数据集，设计了FineMotionDiffuse模型，实验结果表明该模型表现出色。

    

    文本到动作的任务是从给定的文字描述生成运动序列，模型应该探索自然语言指令与人体动作之间的交互。大多数现有作品局限于粗粒度的运动描述（例如，“一个人蹲下。”），几乎没有探索指定相关身体部位运动的细粒度描述。用粗糙文本训练的模型可能无法学习从细粒度运动相关词汇到运动基元的映射，导致无法从未见描述生成动作。在本文中，我们通过输入精细提示给 GPT-3.5-turbo，构建了一个细粒度文本描述的大规模语言-动作数据集FineHumanML3D。因此，我们设计了一个新的文本到动作模型FineMotionDiffuse，充分利用细粒度的文本信息。我们的实验表明，FineMotionDiffuse在FineHumanML3D上训练后获得

    arXiv:2403.13518v1 Announce Type: cross  Abstract: The task of text2motion is to generate motion sequences from given textual descriptions, where a model should explore the interactions between natural language instructions and human body movements. While most existing works are confined to coarse-grained motion descriptions (e.g., "A man squats."), fine-grained ones specifying movements of relevant body parts are barely explored. Models trained with coarse texts may not be able to learn mappings from fine-grained motion-related words to motion primitives, resulting in the failure in generating motions from unseen descriptions. In this paper, we build a large-scale language-motion dataset with fine-grained textual descriptions, FineHumanML3D, by feeding GPT-3.5-turbo with delicate prompts. Accordingly, we design a new text2motion model, FineMotionDiffuse, which makes full use of fine-grained textual information. Our experiments show that FineMotionDiffuse trained on FineHumanML3D acqui
    
[^99]: Hyacinth6B：一个用于中文的大型语言模型

    Hyacinth6B: A large language model for Traditional Chinese

    [https://arxiv.org/abs/2403.13334](https://arxiv.org/abs/2403.13334)

    为了解决大型语言模型通常存在的高硬件和计算需求，Hyacinth6B在模型轻量化和性能之间找到了平衡，采用LoRA方法进行参数高效微调。

    

    这项研究的主要动机是应对通常与大型语言模型相关的高硬件和计算需求。因此，我们的目标是在模型轻量化和性能之间找到平衡，努力在使用相对轻量级模型的同时最大化性能。Hyacinth6B是基于这一目标开发的，旨在充分发挥LLM的核心能力，而不造成巨大的资源成本，有效地推动较小模型的性能边界。训练方法涉及使用LoRA方法进行参数高效微调。

    arXiv:2403.13334v1 Announce Type: new  Abstract: This research's primary motivation of this study is to address the high hardware and computational demands typically associated with LLMs.Therefore,our goal is to find a balance between model lightness and performance,striving to maximize performance while using a comparatively lightweight model. Hyacinth6B was developed with this objective in mind,aiming to fully leverage the core capabilities of LLMs without incurring substantial resource costs, effectively pushing the boundaries of smaller model's performance. The training approach involves parameter efficient finetuning using the LoRA method.
    
[^100]: CLASSLA-web: 南斯拉夫语言的可比较网络语料库，注重语言和文体标注

    CLASSLA-web: Comparable Web Corpora of South Slavic Languages Enriched with Linguistic and Genre Annotation

    [https://arxiv.org/abs/2403.12721](https://arxiv.org/abs/2403.12721)

    本文介绍了一个涵盖南斯拉夫地区官方语言的高度可比较的网络语料库集合，采用先进的技术进行语言和文体标注，进一步增强了其可比较性。

    

    本文介绍了一个涵盖斯洛文尼亚语、克罗地亚语、波斯尼亚语、黑山语、塞尔维亚语、马其顿语和保加利亚语高度可比较的网络语料库集合，从而覆盖了南斯拉夫语言空间所有官方语言的整个范围。这些语料库的总量为26亿个单词，来自2600万篇文档。语料库的可比较性由可比较的爬网设置和相同的爬网和后处理技术来确保。所有语料库都经过了最先进的CLASSLA-Stanza语言处理管道进行语言标注，并通过基于Transformer的多语种X-GENRE分类器增加了文档级别的文体信息，从而在语言标注和元数据丰富化的水平上进一步增强了可比较性。对结果语料库的文体聚焦分析显示了这七个语料库中各种文体的相当一致分布。

    arXiv:2403.12721v1 Announce Type: new  Abstract: This paper presents a collection of highly comparable web corpora of Slovenian, Croatian, Bosnian, Montenegrin, Serbian, Macedonian, and Bulgarian, covering thereby the whole spectrum of official languages in the South Slavic language space. The collection of these corpora comprises a total of 13 billion tokens of texts from 26 million documents. The comparability of the corpora is ensured by a comparable crawling setup and the usage of identical crawling and post-processing technology. All the corpora were linguistically annotated with the state-of-the-art CLASSLA-Stanza linguistic processing pipeline, and enriched with document-level genre information via the Transformer-based multilingual X-GENRE classifier, which further enhances comparability at the level of linguistic annotation and metadata enrichment. The genre-focused analysis of the resulting corpora shows a rather consistent distribution of genres throughout the seven corpora,
    
[^101]: 将大型语言模型中的领域特定内容融入知识图谱，以增强零样本对象状态分类

    Fusing Domain-Specific Content from Large Language Models into Knowledge Graphs for Enhanced Zero Shot Object State Classification

    [https://arxiv.org/abs/2403.12151](https://arxiv.org/abs/2403.12151)

    大型语言模型与知识图谱结合，提高零样本对象状态分类性能

    

    领域特定知识可以显著有助于解决各种视觉任务，但生成这种知识需要大量人力和时间成本。本研究探讨了大型语言模型（LLMs）在通过语义嵌入生成和提供领域特定信息方面的潜力。为实现这一目标，将LLM集成到一个流程中，该流程在视觉基础零样本对象状态分类任务的背景下利用知识图谱和预训练的语义向量。通过广泛的消融研究彻底研究了LLM的行为。我们的研究结果表明，将基于LLM的嵌入与通用的预训练嵌入结合使用可以显著提高性能。借鉴这一消融研究的见解，我们对竞争模型进行了比较分析，从而突出了最新的表现水平。

    arXiv:2403.12151v1 Announce Type: new  Abstract: Domain-specific knowledge can significantly contribute to addressing a wide variety of vision tasks. However, the generation of such knowledge entails considerable human labor and time costs. This study investigates the potential of Large Language Models (LLMs) in generating and providing domain-specific information through semantic embeddings. To achieve this, an LLM is integrated into a pipeline that utilizes Knowledge Graphs and pre-trained semantic vectors in the context of the Vision-based Zero-shot Object State Classification task. We thoroughly examine the behavior of the LLM through an extensive ablation study. Our findings reveal that the integration of LLM-based embeddings, in combination with general-purpose pre-trained embeddings, leads to substantial performance improvements. Drawing insights from this ablation study, we conduct a comparative analysis against competing models, thereby highlighting the state-of-the-art perfor
    
[^102]: 利用生成式知识提取、基于图的表示和多模态智能图推理加速科学发现

    Accelerating Scientific Discovery with Generative Knowledge Extraction, Graph-Based Representation, and Multimodal Intelligent Graph Reasoning

    [https://arxiv.org/abs/2403.11996](https://arxiv.org/abs/2403.11996)

    利用生成式人工智能和图算法加速科学发现，揭示论文之间的深入跨学科关系，并提出了新颖的材料设计。

    

    利用生成式人工智能，我们将一组涉及生物材料领域的1,000篇科学论文转化为详细的本体知识图，揭示了它们固有的无标度特性。通过基于节点相似性和介数中心性的组合排名，探测不同概念之间的图遍历路径，我们揭示了深入的跨学科关系，可用于回答查询，识别知识中的空白，并提出前所未见的材料设计及其行为。一项比较揭示了生物材料和贝多芬第九交响曲之间的详细结构相似之处，突显了通过同构映射共享复杂性模式。该算法进一步创建了一种创新的基于分级菌丝体的复合材料，将图采样的联合合成原理与康定斯基《第七组成》中提取的原则相结合

    arXiv:2403.11996v1 Announce Type: cross  Abstract: Using generative Artificial Intelligence (AI), we transformed a set of 1,000 scientific papers in the area of biological materials into detailed ontological knowledge graphs, revealing their inherently scale-free nature. Using graph traversal path detection between dissimilar concepts based on combinatorial ranking of node similarity and betweenness centrality, we reveal deep insights into unprecedented interdisciplinary relationships that can be used to answer queries, identify gaps in knowledge, and propose never-before-seen material designs and their behaviors. One comparison revealed detailed structural parallels between biological materials and Beethoven's 9th Symphony, highlighting shared patterns of complexity through isomorphic mapping. The algorithm further created an innovative hierarchical mycelium-based composite that incorporates joint synthesis of graph sampling with principles extracted from Kandinsky's Composition VII p
    
[^103]: SelfIE：大型语言模型嵌入的自我解释

    SelfIE: Self-Interpretation of Large Language Model Embeddings

    [https://arxiv.org/abs/2403.10949](https://arxiv.org/abs/2403.10949)

    提出了SelfIE框架，使大型语言模型能够自解释其嵌入，揭示内部推理，包括道德决策、提示注入和消除有害知识。

    

    arXiv:2403.10949v1 公告类型：交叉摘要：大型语言模型（LLMs）如何获得答案？解释和控制LLM的推理过程对于可靠性、透明度和未来模型发展至关重要。我们提出了SelfIE（嵌入的自我解释），这是一个框架，能够利用LLMs响应关于给定段落的查询的能力，以自然语言解释它们自己的嵌入。SelfIE能够解释隐藏嵌入中的开放世界概念，在案例中揭示LLM的内部推理，如做出道德决策、内化提示注入和回想有害知识。SelfIE对隐藏嵌入的文本描述也开辟了控制LLM推理的新途径。我们提出了监督控制，它允许编辑开放式概念，而只需要计算单个层的梯度。我们将RLHF扩展到隐藏的嵌入，并提出了强化控制来消除有害知识。

    arXiv:2403.10949v1 Announce Type: cross  Abstract: How do large language models (LLMs) obtain their answers? The ability to explain and control an LLM's reasoning process is key for reliability, transparency, and future model developments. We propose SelfIE (Self-Interpretation of Embeddings), a framework that enables LLMs to interpret their own embeddings in natural language by leveraging their ability to respond inquiry about a given passage. Capable of interpreting open-world concepts in the hidden embeddings, SelfIE reveals LLM internal reasoning in cases such as making ethical decisions, internalizing prompt injection, and recalling harmful knowledge. SelfIE's text descriptions on hidden embeddings also open up new avenues to control LLM reasoning. We propose Supervised Control, which allows editing open-ended concepts while only requiring gradient computation of individual layer. We extend RLHF to hidden embeddings and propose Reinforcement Control that erases harmful knowledge i
    
[^104]: 处理好您的提示偏见！调查和减轻事实知识提取中的提示偏见

    Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction

    [https://arxiv.org/abs/2403.09963](https://arxiv.org/abs/2403.09963)

    本文调查了预训练语言模型在事实知识提取中存在的“提示偏见”，找到了不同类型提示的偏见程度，以及这种偏见对不同基准测试的影响，并提出了一种基于表示的方法来减轻这种提示偏见。

    

    最近的研究表明，预训练语言模型（PLMs）在事实知识提取中存在“提示偏见”，即提示往往会引入对特定标签的偏见。然而，模型内部提示偏见的程度和影响尚未得到充分探讨。为了回应这一点，本文量化了不同类型提示的偏见，并评估了它们对不同基准测试的影响。我们发现：1）实验中的所有提示都表现出不可忽视的偏见，基于梯度的提示如AutoPrompt和OptiPrompt显示出更高水平的偏见；2）提示偏见可以通过过度拟合测试数据集不合理地放大基准测试的准确性，特别是在类似LAMA这样的不平衡数据集上。基于这些发现，我们提出了一种基于表示的方法来减轻提示偏见，在推断时。具体而言，我们首先使用仅提示查询来估计有偏差的表示，然后从中删除。

    arXiv:2403.09963v1 Announce Type: cross  Abstract: Recent research shows that pre-trained language models (PLMs) suffer from "prompt bias" in factual knowledge extraction, i.e., prompts tend to introduce biases toward specific labels. However, the extent and impact of prompt bias within the model remain underexplored. In response, this paper quantifies the bias with various types of prompts and assesses their impact on different benchmarks. We show that: 1) all prompts in the experiments exhibit non-negligible bias, with gradient-based prompts like AutoPrompt and OptiPrompt displaying significantly higher levels of bias; 2) prompt bias can amplify benchmark accuracy unreasonably by overfitting the test datasets, especially on imbalanced datasets like LAMA. Based on these findings, we propose a representation-based approach to mitigate the prompt bias during inference time. Specifically, we first estimate the biased representation using prompt-only querying, and then remove it from the 
    
[^105]: 评估大语言模型作为对话推荐中生成用户模拟器

    Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation

    [https://arxiv.org/abs/2403.09738](https://arxiv.org/abs/2403.09738)

    大型语言模型作为生成式用户模拟器在对话推荐中展现出潜力，新的协议通过五个任务评估了语言模型模拟人类行为的准确程度，揭示了模型与人类行为的偏差，并提出了如何通过模型选择和提示策略减少这些偏差。

    

    合成用户是对话推荐系统评估中成本效益较高的真实用户代理。大型语言模型表现出在模拟类似人类行为方面的潜力，这引发了它们能否代表多样化用户群体的问题。我们引入了一个新的协议，用于衡量语言模型能够准确模拟对话推荐中人类行为的程度。该协议由五个任务组成，每个任务旨在评估合成用户应该表现出的关键特性：选择要谈论的物品，表达二进制偏好，表达开放式偏好，请求推荐以及提供反馈。通过对基准模拟器的评估，我们展示了这些任务有效地揭示了语言模型与人类行为的偏差，并提供了关于如何通过模型选择和提示策略减少这些偏差的见解。

    arXiv:2403.09738v1 Announce Type: cross  Abstract: Synthetic users are cost-effective proxies for real users in the evaluation of conversational recommender systems. Large language models show promise in simulating human-like behavior, raising the question of their ability to represent a diverse population of users. We introduce a new protocol to measure the degree to which language models can accurately emulate human behavior in conversational recommendation. This protocol is comprised of five tasks, each designed to evaluate a key property that a synthetic user should exhibit: choosing which items to talk about, expressing binary preferences, expressing open-ended preferences, requesting recommendations, and giving feedback. Through evaluation of baseline simulators, we demonstrate these tasks effectively reveal deviations of language models from human behavior, and offer insights on how to reduce the deviations with model selection and prompting strategies.
    
[^106]: 持续预训练大型语言模型的简单可扩展策略

    Simple and Scalable Strategies to Continually Pre-train Large Language Models

    [https://arxiv.org/abs/2403.08763](https://arxiv.org/abs/2403.08763)

    通过简单和可扩展的学习率调整、重放数据的方法，可以在不重新训练的情况下，持续预训练大型语言模型以匹配完全重新训练时的性能。

    

    大型语言模型（LLMs）通常在数十亿的标记上进行常规预训练，一旦有新数据可用就重新开始该过程。一个更有效率的解决方案是持续预训练这些模型，与重新训练相比能节省大量计算资源。然而，新数据引起的分布转移通常会导致在以前数据上降低性能或无法适应新数据。在本工作中，我们展示了一种简单且可扩展的学习率（LR）重新升温、LR重新衰减和重放上一数据的组合足以与完全从头开始重新训练在所有可用数据上的性能相匹配，从最终损失和语言模型（LM）评估基准的角度衡量。具体而言，我们展示了在两个常用的LLM预训练数据集（英语→英语）之间的弱但现实的分布转移以及更强烈的分布转移（英语→德语）下的情况。

    arXiv:2403.08763v1 Announce Type: cross  Abstract: Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by final loss and language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\rightarrow$English) and a stronger distribution shift (English$\rightarrow$German) at th
    
[^107]: 通过融合高度专业化语言模型同时掌握文本、代码和数学

    Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models

    [https://arxiv.org/abs/2403.08281](https://arxiv.org/abs/2403.08281)

    通过融合高度专业化的语言、代码和数学模型，提出了一种名为UltraFuser的融合框架，引入了标记级别的门控机制，并设计了两阶段训练策略，以同时在三个领域取得高性能。

    

    自然语言、编程代码和数学符号的底层数据分布变化巨大，对于那些努力同时在三个领域实现高性能的大型语言模型（LLMs）提出了复杂挑战。本文提出了一种直接融合已经高度专业化模型的方法。所提出的融合框架UltraFuser包括三个已经在语言、编码和数学上得到充分训练的专家。引入了一个标记级别的门控机制来混合专家的输出。设计了一个伴随平衡采样的两阶段训练策略以确保稳定性。为了有效训练融合模型，我们进一步构建了一个

    arXiv:2403.08281v1 Announce Type: cross  Abstract: Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously. Achieving a very high level of proficiency for an LLM within a specific domain often requires extensive training with relevant corpora, which is typically accompanied by a sacrifice in performance in other domains. In this paper, we propose to fuse models that are already highly-specialized directly. The proposed fusing framework, UltraFuser, consists of three distinct specialists that are already sufficiently trained on language, coding, and mathematics. A token-level gating mechanism is introduced to blend the specialists' outputs. A two-stage training strategy accompanied by balanced sampling is designed to ensure stability. To effectively train the fused model, we further construct a 
    
[^108]: OffLanDat：通过提示工程生成的大型语言模型生成的社区基础隐式攻击性语言数据集

    OffLanDat: A Community Based Implicit Offensive Language Dataset Generated by Large Language Model Through Prompt Engineering

    [https://arxiv.org/abs/2403.02472](https://arxiv.org/abs/2403.02472)

    介绍了一个通过提示工程生成的大型语言模型创建的社区基础隐式攻击性语言数据集OffLanDat，为38个不同目标群体提供数据。

    

    社交媒体上攻击性语言的普遍存在对社会福祉产生了不良影响。因此，有必要高度重视解决这一问题。攻击性语言既存在明确形式，也存在隐式形式，后者更具挑战性。当前在该领域的研究遇到几个挑战。首先，现有数据集主要依赖于收集包含明确攻击性关键词的文本，这使得捕捉不包含这些关键词且隐含攻击性内容的任务具有挑战性。其次，通常的方法论倾向于仅关注文本分析，忽视社区信息可以提供的宝贵见解。在这篇研究论文中，我们介绍了一个新的数据集OffLanDat，这是由ChatGPT生成的基于社区的隐式攻击性语言数据集，其中包含38个不同目标群体的数据。

    arXiv:2403.02472v1 Announce Type: new  Abstract: The widespread presence of offensive languages on social media has resulted in adverse effects on societal well-being. As a result, it has become very important to address this issue with high priority. Offensive languages exist in both explicit and implicit forms, with the latter being more challenging to detect. Current research in this domain encounters several challenges. Firstly, the existing datasets primarily rely on the collection of texts containing explicit offensive keywords, making it challenging to capture implicitly offensive contents that are devoid of these keywords. Secondly, usual methodologies tend to focus solely on textual analysis, neglecting the valuable insights that community information can provide. In this research paper, we introduce a novel dataset OffLanDat, a community based implicit offensive language dataset generated by ChatGPT containing data for 38 different target groups. Despite limitations in genera
    
[^109]: 基于自然语言推理和主张提取的摘要可信度评估

    FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction

    [https://arxiv.org/abs/2403.02270](https://arxiv.org/abs/2403.02270)

    提出了一种基于自然语言推理和主张提取的摘要可信度评估指标 FENICE，解决了自动生成摘要中存在的事实不一致性问题。

    

    最近在文本摘要方面取得的进展，尤其是随着大型语言模型（LLMs）的出现，已经表现出显著的性能。然而，一个显著的挑战仍然存在，即大量自动生成的摘要呈现事实不一致，比如幻觉。针对这一问题，出现了各种用于评估摘要一致性的方法。然而，这些新引入的度量标准面临着一些限制，包括缺乏可解释性，专注于短文档摘要（例如新闻文章）以及计算上的不可行性，特别是对于基于LLM的度量标准。为了解决这些缺点，我们提出了基于自然语言推理和主张提取的摘要可信度评估（FENICE），这是一种更具解释性和有效性的可信度导向度量。

    arXiv:2403.02270v1 Announce Type: new  Abstract: Recent advancements in text summarization, particularly with the advent of Large Language Models (LLMs), have shown remarkable performance. However, a notable challenge persists as a substantial number of automatically-generated summaries exhibit factual inconsistencies, such as hallucinations. In response to this issue, various approaches for the evaluation of consistency for summarization have emerged. Yet, these newly-introduced metrics face several limitations, including lack of interpretability, focus on short document summaries (e.g., news articles), and computational impracticality, especially for LLM-based metrics. To address these shortcomings, we propose Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction (FENICE), a more interpretable and efficient factuality-oriented metric. FENICE leverages an NLI-based alignment between information in the source document and a set of atomic facts,
    
[^110]: 将神经信号解码为语音

    Decode Neural signal as Speech

    [https://arxiv.org/abs/2403.01748](https://arxiv.org/abs/2403.01748)

    本文在脑机接口领域探索了MEG信号的脑到文本转换，着重解决了以前主要集中在EEG上、使用“teacher-forcing”以及未完全自回归的问题。

    

    从脑动态解码语言是脑机接口（BCI）领域中一个重要的开放方向，尤其考虑到大型语言模型的快速增长。相对于需要电极植入手术的侵入性信号，非侵入性神经信号（如EEG、MEG）由于其安全性和普适性而越来越受到关注。然而，在三个方面的探索还不足：1）以前的方法主要集中在EEG上，但没有一个先前的研究解决了MEG信号质量更好的问题；2）以前的工作主要在生成解码过程中使用“teacher-forcing”，这是不切实际的；3）以前的工作大多是基于“BART”而不是完全自回归的，而在其他序列任务中表现更好。在本文中，我们探讨了MEG信号的脑到文本转换在语音解码形式中。我们是第一个在交叉注意力中研究的。

    arXiv:2403.01748v1 Announce Type: cross  Abstract: Decoding language from brain dynamics is an important open direction in the realm of brain-computer interface (BCI), especially considering the rapid growth of large language models. Compared to invasive-based signals which require electrode implantation surgery, non-invasive neural signals (e.g. EEG, MEG) have attracted increasing attention considering their safety and generality. However, the exploration is not adequate in three aspects: 1) previous methods mainly focus on EEG but none of the previous works address this problem on MEG with better signal quality; 2) prior works have predominantly used ``teacher-forcing" during generative decoding, which is impractical; 3) prior works are mostly ``BART-based" not fully auto-regressive, which performs better in other sequence tasks. In this paper, we explore the brain-to-text translation of MEG signals in a speech-decoding formation. Here we are the first to investigate a cross-attentio
    
[^111]: 基于Twitter数据的精神健康监测框架：从当地推文到当地健康

    LocalTweets to LocalHealth: A Mental Health Surveillance Framework Based on Twitter Data

    [https://arxiv.org/abs/2402.13452](https://arxiv.org/abs/2402.13452)

    本研究提出了一个新的基于Twitter数据的框架LocalHealth，用于预测当地精神健康结果。通过与GPT3.5结合使用，该框架在MH监测中取得了显著的改进。

    

    先前关于Twitter数据的研究已经提供了它在开发补充健康监测系统方面的实用性证据。在这项研究中，我们提出了一个新的框架来监测公共健康，重点关注精神健康（MH）结果。我们假设当地发布的推文可以表明当地的精神健康结果，并收集了来自美国765个地区（人口普查分组）的推文。我们将每个地区的这些推文与疾病控制中心（CDC）报告的相应MH结果配对，创建了一个基准数据集LocalTweets。借助LocalTweets，我们提出了基于Twitter的MH监测系统的首个人口级评估任务。随后，我们开发了一个高效有效的方法LocalHealth，用于根据LocalTweets预测MH结果。当与GPT3.5一起使用时，LocalHealth实现了最高的F1值和准确率，分别达到0.7429和79.78\%，F1值提高了59\%。

    arXiv:2402.13452v1 Announce Type: cross  Abstract: Prior research on Twitter (now X) data has provided positive evidence of its utility in developing supplementary health surveillance systems. In this study, we present a new framework to surveil public health, focusing on mental health (MH) outcomes. We hypothesize that locally posted tweets are indicative of local MH outcomes and collect tweets posted from 765 neighborhoods (census block groups) in the USA. We pair these tweets from each neighborhood with the corresponding MH outcome reported by the Center for Disease Control (CDC) to create a benchmark dataset, LocalTweets. With LocalTweets, we present the first population-level evaluation task for Twitter-based MH surveillance systems. We then develop an efficient and effective method, LocalHealth, for predicting MH outcomes based on LocalTweets. When used with GPT3.5, LocalHealth achieves the highest F1-score and accuracy of 0.7429 and 79.78\%, respectively, a 59\% improvement in F
    
[^112]: 理解文本到SQL中噪声的影响：对BIRD-Bench基准测试的研究

    Understanding the Effects of Noise in Text-to-SQL: An Examination of the BIRD-Bench Benchmark

    [https://arxiv.org/abs/2402.12243](https://arxiv.org/abs/2402.12243)

    研究深入分析了文本到SQL领域中的噪声对模型的影响，并发现在BIRD-Bench基准测试中存在大量问题和标准查询中的噪声，这会显著影响模型的性能。

    

    Text-to-SQL涉及将自然语言翻译为结构化查询语言（SQL），对于使结构化数据库可以在没有专业知识的情况下得到广泛访问至关重要。然而，设计针对这些任务的模型是具有挑战性的，原因包括存在“噪声”，如模糊问题和语法错误。该研究对广泛使用的BIRD-Bench基准测试中噪声的分布和类型以及噪声对模型的影响进行了深入分析。虽然BIRD-Bench旨在模拟脏乱和嘈杂的数据库值，但并未包含问题和标准查询中的噪声和错误。我们发现数据集中问题和标准查询中的噪声普遍存在，跨领域存在不同程度的噪声，并且噪声类型之间分布不均匀。存在不正确的标准SQL查询，进而生成不正确的标准答案，对基准测试的影响显著。

    arXiv:2402.12243v1 Announce Type: new  Abstract: Text-to-SQL, which involves translating natural language into Structured Query Language (SQL), is crucial for enabling broad access to structured databases without expert knowledge. However, designing models for such tasks is challenging due to numerous factors, including the presence of 'noise,' such as ambiguous questions and syntactical errors. This study provides an in-depth analysis of the distribution and types of noise in the widely used BIRD-Bench benchmark and the impact of noise on models. While BIRD-Bench was created to model dirty and noisy database values, it was not created to contain noise and errors in the questions and gold queries. We found that noise in questions and gold queries are prevalent in the dataset, with varying amounts across domains, and with an uneven distribution between noise types. The presence of incorrect gold SQL queries, which then generate incorrect gold answers, has a significant impact on the ben
    
[^113]: 通过机器去学习研究预训练数据对大型语言模型的影响

    Deciphering the lmpact of Pretraining Data on Large Language Models through Machine Unlearning

    [https://arxiv.org/abs/2402.11537](https://arxiv.org/abs/2402.11537)

    通过对五个主要类别的预训练数据的48个数据集进行系统分析，研究了它们对大型语言模型性能的影响，并发现了一些“高影响数据”，如书籍，与模型能力相关联，为LLMs的优化提供了见解。

    

    通过在具有各种来源的语料库上进行预训练，大型语言模型（LLMs）取得了令人印象深刻的性能。然而，预训练语料库的每个组成部分的影响仍然不明确。因此，预训练语料库的组织仍然是经验性的，并且可能偏离最佳状态。为了解决这个问题，我们系统地分析了来自LLMs预训练数据的5个主要类别的48个数据集的影响，并使用关于九个主要模型能力类别的基准来衡量它们对LLMs的影响。我们的分析提供了关于多个语料库对LLMs性能贡献的实证结果，以及它们的联合影响模式，包括互补的、正交的和相关的关系。我们还确定了一组“高影响数据”，如书籍，与一组模型能力相关联。这些发现为我们提供了关于组织数据以支持LLMs优化的见解。

    arXiv:2402.11537v1 Announce Type: cross  Abstract: Through pretraining on a corpus with various sources, Large Language Models (LLMs) have gained impressive performance. However, the impact of each component of the pretraining corpus remains opaque. As a result, the organization of the pretraining corpus is still empirical and may deviate from the optimal. To address this issue, we systematically analyze the impact of 48 datasets from 5 major categories of pretraining data of LLMs and measure their impacts on LLMs using benchmarks about nine major categories of model capabilities. Our analyses provide empirical results about the contribution of multiple corpora on the performances of LLMs, along with their joint impact patterns, including complementary, orthogonal, and correlational relationships. We also identify a set of ``high-impact data'' such as Books that is significantly related to a set of model capabilities. These findings provide insights into the organization of data to sup
    
[^114]: 用于推断高效LLMs的串联Transformer

    Tandem Transformers for Inference Efficient LLMs

    [https://arxiv.org/abs/2402.08644](https://arxiv.org/abs/2402.08644)

    该论文提出了一种新的架构，称为串联Transformer，用于解决传统大型语言模型推断速度限制的问题。该架构通过将小型自回归模型和大模型以块模式结合起来，并让小模型关注大模型的丰富表示，从而显著提高了小模型的预测准确性。实验证明，在预训练数据集上，串联的PaLM2-Bison和PaLM2-Gecko相比独立的PaLM2-Gecko，在下一个词元预测准确性上提高了3.3%，并且相较于具有相似下游任务的PaLM2-Otter模型，加速比达到1.16倍。

    

    传统的大型语言模型( LLMs )具有自回归的特性，这使得推断速度受到限制，因为词元是按顺序生成的。尽管有些预测和并行解码技术试图减轻这个问题，但它们都有限制：要么依赖更精简但准确度较低的模型进行生成，要么没有充分利用基础LLM的表示。我们提出了一种新颖的架构，即串联Transformer，来解决这些问题。这种架构独特地结合了(1)一个小型自回归模型和(2)一个以块模式运行的大模型(同时处理多个词元)。通过让小模型关注大模型更丰富的表示，大幅提升小模型的预测准确性。在PaLM2预训练数据集上，PaLM2-Bison和PaLM2-Gecko的串联相较独立的PaLM2-Gecko，在下一个词元预测准确性上提升了3.3%，与具有相似下游任务的PaLM2-Otter模型相比，提供了1.16倍的加速比。

    The autoregressive nature of conventional large language models (LLMs) inherently limits inference speed, as tokens are generated sequentially. While speculative and parallel decoding techniques attempt to mitigate this, they face limitations: either relying on less accurate smaller models for generation or failing to fully leverage the base LLM's representations.   We introduce a novel architecture, Tandem transformers, to address these issues. This architecture uniquely combines (1) a small autoregressive model and (2) a large model operating in block mode (processing multiple tokens simultaneously). The small model's predictive accuracy is substantially enhanced by granting it attention to the large model's richer representations. On the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Gecko demonstrates a 3.3% improvement in next-token prediction accuracy over a standalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter model with comparable downstream p
    
[^115]: 加强端到端多任务对话系统：基于内在动机强化学习算法的改进训练和适应性研究

    Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability

    [https://arxiv.org/abs/2401.18040](https://arxiv.org/abs/2401.18040)

    本研究旨在通过内在动机强化学习算法改进端到端多任务对话系统的训练和适应性。通过教授智能体一个内在奖励系统，可以加速训练并提高其判断行为质量的能力。

    

    端到端多任务对话系统通常通过对话流水线的独立模块进行设计。其中，策略模块是决定对用户输入如何响应的关键。这个策略是通过强化学习算法进行训练的，通过利用一个智能体在一个反馈信号形式的环境中接收反馈。然而，当前的对话系统只提供了稀缺且简单的奖励。本研究的目标是研究内在动机强化学习算法。通过这种算法，智能体可以快速加速训练，并通过教授一个内在奖励系统来提高判断其行为质量的能力。具体而言，我们将随机网络蒸馏和好奇驱动强化学习技术应用于测量状态访问频率，并通过使用话语之间的语义相似性来鼓励探索。在一个异构数据集MultiWOZ上进行的实验结果显示...

    End-to-end multi-task dialogue systems are usually designed with separate modules for the dialogue pipeline. Among these, the policy module is essential for deciding what to do in response to user input. This policy is trained by reinforcement learning algorithms by taking advantage of an environment in which an agent receives feedback in the form of a reward signal. The current dialogue systems, however, only provide meagre and simplistic rewards. Investigating intrinsic motivation reinforcement learning algorithms is the goal of this study. Through this, the agent can quickly accelerate training and improve its capacity to judge the quality of its actions by teaching it an internal incentive system. In particular, we adapt techniques for random network distillation and curiosity-driven reinforcement learning to measure the frequency of state visits and encourage exploration by using semantic similarity between utterances. Experimental results on MultiWOZ, a heterogeneous dataset, sho
    
[^116]: 如何合并生成和检索上下文以增强开放领域问答的语言模型的研究

    Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?

    [https://arxiv.org/abs/2401.11911](https://arxiv.org/abs/2401.11911)

    该论文研究了大型语言模型如何合并生成和检索的上下文以提升开放领域问答，发现这些模型偏向于生成的上下文，即使它们提供了错误的信息。

    

    虽然辅助信息已经成为增强大型语言模型（LLMs）的关键，但对于LLMs如何合并生成的和检索的上下文仍知之甚少。为了研究这一点，我们制定了一个系统性的框架来确定LLMs的响应是源自于生成的上下文还是检索的上下文。为了实现这个目标，我们构建了包含相互冲突的上下文的数据集，其中每个问题都与生成的和检索的上下文配对，但只有一个上下文包含了正确的答案。我们的实验证明，LLMs（如GPT-4/3.5和Llama2）存在显著的偏差，更倾向于生成的上下文，即使这些上下文提供了错误的信息。我们进一步确定了导致这种偏差的两个关键因素：i）LLMs生成的上下文通常与问题更相似，增加了其被选择的可能性；ii）检索上下文中使用的分割过程打断了其连贯性。

    While auxiliary information has become a key to enhance Large Language Models (LLMs), relatively little is known about how LLMs merge these contexts, specifically generated and retrieved. To study this, we formulate a systematic framework to identify whether LLMs' responses, derived from the integration of generated and retrieved contexts, are attributed to either generated or retrieved contexts. To achieve this, we construct datasets with conflicting contexts, where each question is paired with both generated and retrieved contexts, yet only one of them contains the correct answer. Our experiments reveal a significant bias in LLMs (GPT-4/3.5 and Llama2) towards generated contexts, even when they provide incorrect information. We further identify two key factors contributing to this bias: i) contexts generated by LLMs typically show greater similarity to the questions, increasing their likelihood of selection; ii) the segmentation process used in retrieved contexts disrupts their compl
    
[^117]: AI和生成式AI用于研究发现与总结

    AI and Generative AI for Research Discovery and Summarization

    [https://arxiv.org/abs/2401.06795](https://arxiv.org/abs/2401.06795)

    AI和生成式AI工具在研究发现和总结方面有重大影响，包括能够更快地找到相关文献和用简洁语言总结研究文章的要点。

    

    AI和生成式AI工具，包括依赖大型语言模型（LLMs）的聊天机器人如ChatGPT，今年迅速崛起，为增加工作效率和改善生活创造了难以置信的机会。统计学家和数据科学家已经开始以多种方式体验到这些工具的好处，比如从文本提示生成编程代码以分析数据或拟合统计模型。这些工具可以在研究发现和总结方面产生重大影响之一。正在开发独立工具和插件给聊天机器人，使研究人员比2023年之前的搜索工具更快地找到相关文献。此外，生成式AI工具已经发展到可以用简洁的语言总结和提取研究文章的要点的程度。最后，基于高度参数化的LLMs的聊天机器人可用于模拟

    arXiv:2401.06795v2 Announce Type: replace-cross  Abstract: AI and generative AI tools, including chatbots like ChatGPT that rely on large language models (LLMs), have burst onto the scene this year, creating incredible opportunities to increase work productivity and improve our lives. Statisticians and data scientists have begun experiencing the benefits from the availability of these tools in numerous ways, such as the generation of programming code from text prompts to analyze data or fit statistical models. One area that these tools can make a substantial impact is in research discovery and summarization. Standalone tools and plugins to chatbots are being developed that allow researchers to more quickly find relevant literature than pre-2023 search tools. Furthermore, generative AI tools have improved to the point where they can summarize and extract the key points from research articles in succinct language. Finally, chatbots based on highly parameterized LLMs can be used to simula
    
[^118]: 基于大型语言模型的半结构化网络文章高通量生物医学关系提取

    High-throughput Biomedical Relation Extraction for Semi-Structured Web Articles Empowered by Large Language Models

    [https://arxiv.org/abs/2312.08274](https://arxiv.org/abs/2312.08274)

    利用大型语言模型在半结构化网络文章中实现高通量生物医学关系提取，通过对LLMs的应用，结合外部语料库和世界知识，设计针对性的二元分类决策，取得良好的结果。

    

    旨在开发一种利用大型语言模型的阅读理解能力和生物医学世界知识以可扩展和有信服力的方式进行高通量生物医学关系提取的系统。我们将关系提取任务制定为大型语言模型的二元分类，LLMs基于外部语料库和其世界知识做出决策，给出事实验证的判断理由。此方法专为半结构化网络文章而设计，在其中将主标题指定为尾实体并明确纳入上下文，潜在头实体根据生物医学词表进行匹配。此外，将冗长内容分割为文本块，嵌入并使用额外的嵌入模型进行检索。

    arXiv:2312.08274v4 Announce Type: replace-cross  Abstract: Objective: To develop a high-throughput biomedical relation extraction system that takes advantage of the large language models'(LLMs) reading comprehension ability and biomedical world knowledge in a scalable and evidential manner. Methods: We formulate the relation extraction task as binary classifications for large language models. Specifically, LLMs make the decision based on the external corpus and its world knowledge, giving the reason for the judgment for factual verification. This method is tailored for semi-structured web articles, wherein we designate the main title as the tail entity and explicitly incorporate it into the context, and the potential head entities are matched based on a biomedical thesaurus. Moreover, lengthy contents are sliced into text chunks, embedded, and retrieved with additional embedding models. Results: Using an open-source LLM, we extracted 248659 relation triplets of three distinct relation 
    
[^119]: 视频本地化指令生成的高效预训练方法

    Efficient Pre-training for Localized Instruction Generation of Videos

    [https://arxiv.org/abs/2311.15964](https://arxiv.org/abs/2311.15964)

    提出了一种名为Sieve-&-Swap的技术，通过自动筛选出不相关文本并用人类编写的说明替换文本转录，从而实现视频本地化指令生成的高效预训练。

    

    过程视频展示了诸如食谱准备等任务的逐步演示。理解此类视频具有挑战性，需要对步骤进行精确定位并生成文字说明。手动注释步骤并编写说明成本高昂，这限制了当前数据集的规模并阻碍了有效学习。利用大规模但嘈杂的视频-文本数据集进行预训练可以提升性能，但需要大量计算资源。此外，文本转录包含无关内容，与人类注释员编写的说明相比存在风格变化。为了缓解这两个问题，我们提出了一种技术，Sieve-&-Swap，通过自动筛选出不相关文本和使用文本食谱数据集中人类编写的说明自动替换文本转录以增强文字指令的质量。

    arXiv:2311.15964v2 Announce Type: replace-cross  Abstract: Procedural videos show step-by-step demonstrations of tasks like recipe preparation. Understanding such videos is challenging, involving the precise localization of steps and the generation of textual instructions. Manually annotating steps and writing instructions is costly, which limits the size of current datasets and hinders effective learning. Leveraging large but noisy video-transcript datasets for pre-training can boost performance, but demands significant computational resources. Furthermore, transcripts contain irrelevant content and exhibit style variation compared to instructions written by human annotators. To mitigate both issues, we propose a technique, Sieve-&-Swap, to automatically curate a smaller dataset: (i) Sieve filters irrelevant transcripts and (ii) Swap enhances the quality of the text instruction by automatically replacing the transcripts with human-written instructions from a text-only recipe dataset. 
    
[^120]: 语言模型在预测情绪时主要不考虑情绪触发器

    Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion

    [https://arxiv.org/abs/2311.09602](https://arxiv.org/abs/2311.09602)

    语言模型在预测情绪时主要不考虑情绪触发器，而是情绪触发器与各种特征和情绪检测任务之间存在错综复杂的相互作用。

    

    情境和事件会引发人类的情绪，但到底它们在预测情绪检测模型时起到了多大作用？这项工作探讨了人类标注的情绪触发器与模型在预测情绪时认为重要的特征之间的相关性。首先，我们引入了一个新的数据集EmoTrigger，包括900条来源于三个不同数据集的社交媒体帖子；这些帖子由专家进行情绪触发器注释，达成高度一致。利用EmoTrigger，我们评估了大型语言模型(LLMs)识别情绪触发器的能力，并对LLMs和经过微调的模型在这些任务中认为重要的特征进行了比较分析。我们的分析揭示了情绪触发器在情绪预测模型中主要不被视为重要特征，而是各种特征之间以及情绪检测任务之间存在错综复杂的相互作用。

    arXiv:2311.09602v2 Announce Type: replace  Abstract: Situations and events evoke emotions in humans, but to what extent do they inform the prediction of emotion detection models? This work investigates how well human-annotated emotion triggers correlate with features that models deemed salient in their prediction of emotions. First, we introduce a novel dataset EmoTrigger, consisting of 900 social media posts sourced from three different datasets; these were annotated by experts for emotion triggers with high agreement. Using EmoTrigger, we evaluate the ability of large language models (LLMs) to identify emotion triggers, and conduct a comparative analysis of the features considered important for these tasks between LLMs and fine-tuned models. Our analysis reveals that emotion triggers are largely not considered salient features for emotion prediction models, instead there is intricate interplay between various features and the task of emotion detection.
    
[^121]: 测量自发混合语音中的同步性

    Measuring Entrainment in Spontaneous Code-switched Speech

    [https://arxiv.org/abs/2311.07703](https://arxiv.org/abs/2311.07703)

    研究发现人与人之间的混合语音自发语音中存在与书面和口语单语环境同步的模式，并且对话系统生成的文本中的代码切换同步模式在这种环境中也是普适的。

    

    众所周知，那些相互同步的说话者比那些不同步的说话者有更成功的对话。先前的研究表明，交际者在书面和口头单语领域都会同步语言特征。更近期关于混合语言交流的研究也显示了在一些代码切换（CSW）方面存在同步的初步证据。然而，这些关于混合语音领域的同步研究非常少，并且局限于人机文本互动。我们的工作研究了人与人之间的混合语音自发语音，发现（1）书面和口语单语环境中的同步模式在混合语言环境中大体上是普适的，（2）对话系统生成的文本中的代码切换同步模式在自发混合语音中也是普适的。我们的发现对于可能具有“普遍”性的重要含义。

    arXiv:2311.07703v2 Announce Type: replace  Abstract: It is well-known that speakers who entrain to one another have more successful conversations than those who do not. Previous research has shown that interlocutors entrain on linguistic features in both written and spoken monolingual domains. More recent work on code-switched communication has also shown preliminary evidence of entrainment on certain aspects of code-switching (CSW). However, such studies of entrainment in code-switched domains have been extremely few and restricted to human-machine textual interactions. Our work studies code-switched spontaneous speech between humans, finding that (1) patterns of written and spoken entrainment in monolingual settings largely generalize to code-switched settings, and (2) some patterns of entrainment on code-switching in dialogue agent-generated text generalize to spontaneous code-switched speech. Our findings give rise to important implications for the potentially "universal" nature of
    
[^122]: 先悲剧，再解析：历史在大型语言模型的新时代中重演

    First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models

    [https://arxiv.org/abs/2311.05020](https://arxiv.org/abs/2311.05020)

    NLP研究人员在大型语言模型（LLMs）的新时代中，可以从历史中汲取教训，持续解决规模差异、数据瓶颈、现实评估等问题，同时还有空间尝试新的方法。

    

    许多自然语言处理研究人员正经历一场存在危机，这一危机是由ChatGPT和其他基于大型语言模型的系统取得惊人成功所触发的。在对该领域的理解发生如此颠覆性变化后，剩下什么可做呢？我们从历史的视角出发，寻找第一个以大型$n$-gram模型用于机器翻译(MT)开始于2005年的LLM时代的指导。我们确定了第一个时代的持久性教训，更重要的是，我们确定了NLP研究人员可以在LLMs占主导地位的领域继续做出有意义的贡献的永恒问题。我们认为规模上的差异是暂时的，研究人员可以努力减少这些差距；数据仍然是许多应用的瓶颈，而不是硬件；有意义的现实评估仍然是一个悬而未决的问题；而且还有空间可以尝试新的方法。

    arXiv:2311.05020v2 Announce Type: replace  Abstract: Many NLP researchers are experiencing an existential crisis triggered by the astonishing success of ChatGPT and other systems based on large language models (LLMs). After such a disruptive change to our understanding of the field, what is left to do? Taking a historical lens, we look for guidance from the first era of LLMs, which began in 2005 with large $n$-gram models for machine translation (MT). We identify durable lessons from the first era, and more importantly, we identify evergreen problems where NLP researchers can continue to make meaningful contributions in areas where LLMs are ascendant. We argue that disparities in scale are transient and researchers can work to reduce them; that data, rather than hardware, is still a bottleneck for many applications; that meaningful realistic evaluation is still an open problem; and that there is still room for speculative approaches.
    
[^123]: 揭示大语言模型知识编辑的陷阱

    Unveiling the Pitfalls of Knowledge Editing for Large Language Models

    [https://arxiv.org/abs/2310.02129](https://arxiv.org/abs/2310.02129)

    这篇论文探讨了大型语言模型知识编辑的潜在陷阱，提出了新的评估方法，发现知识冲突和知识扭曲是两个重要问题。

    

    随着调整大型语言模型（LLMs）成本不断上升，最近的研究工作已经转向开发编辑LLMs内在知识的方法。然而，仍有一个阴云悬在头顶上 - 知识编辑是否会触发蝴蝶效应？因为目前尚不清楚知识编辑是否会引入可能带来潜在风险的副作用。本文首次探讨了与LLMs知识编辑相关的潜在陷阱。为实现此目的，我们引入了新的基准数据集并提出了创新性的评估指标。我们的结果强调了两个关键问题：（1）知识冲突：编辑逻辑冲突的事实组可能会放大LLMs固有的不一致性 - 这是以前方法忽略的一个方面。（2）知识扭曲：为了编辑事实知识而更改参数可能会不可逆地扭曲

    arXiv:2310.02129v3 Announce Type: replace-cross  Abstract: As the cost associated with fine-tuning Large Language Models (LLMs) continues to rise, recent research efforts have pivoted towards developing methodologies to edit implicit knowledge embedded within LLMs. Yet, there's still a dark cloud lingering overhead -- will knowledge editing trigger butterfly effect? since it is still unclear whether knowledge editing might introduce side effects that pose potential risks or not. This paper pioneers the investigation into the potential pitfalls associated with knowledge editing for LLMs. To achieve this, we introduce new benchmark datasets and propose innovative evaluation metrics. Our results underline two pivotal concerns: (1) Knowledge Conflict: Editing groups of facts that logically clash can magnify the inherent inconsistencies in LLMs-a facet neglected by previous methods. (2) Knowledge Distortion: Altering parameters with the aim of editing factual knowledge can irrevocably warp 
    
[^124]: 通过逻辑增强大型语言模型中的零射链推理能力

    Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic

    [https://arxiv.org/abs/2309.13339](https://arxiv.org/abs/2309.13339)

    提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。

    

    大型语言模型的最新进展展示了它们在各个领域的 remarkable generalizability。然而，它们的推理能力仍有很大的提升空间，特别是在需要多步推理的情况下。尽管大型语言模型具有广泛的知识，但它们的推理经常未能有效利用这些知识来建立连贯的思维范式。这些模型有时会出现幻觉，因为它们的推理过程未受逻辑原则的限制。为了改进大型语言模型的零射链推理能力，我们提出了 LoT（Logical Thoughts）提示，这是一个自我改进的框架，利用根植于符号逻辑的原则，特别是归谬法，逐步系统地验证和纠正推理过程。在语言任务上进行的实验评估

    arXiv:2309.13339v2 Announce Type: replace-cross  Abstract: Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their reasoning often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. These models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming at improving the zero-shot chain-of-thought reasoning ability of large language models, we propose LoT (Logical Thoughts) prompting, a self-improvement framework that leverages principles rooted in symbolic logic, particularly Reductio ad Absurdum, to systematically verify and rectify the reasoning processes step by step. Experimental evaluations conducted on language tasks in
    
[^125]: 西班牙语资源语法2023版

    Spanish Resource Grammar version 2023

    [https://arxiv.org/abs/2309.13318](https://arxiv.org/abs/2309.13318)

    西班牙语资源语法（SRG）的最新版本引入了Freeling形态分析器，并附带一个经过手工验证的树库，为提高语义解析器的训练质量和其他系统带来便利。

    

    我们介绍了西班牙语资源语法（SRG）的最新版本，这是一个基于HPSG形式主义实现的西班牙语语法。这些语法编码了关于句法的复杂假设，使其成为语言学理论实证测试的资源。它们还编码了严格的语法性概念，使其成为计算辅助语言学习中自然语言处理应用的资源。这个SRG版本使用了最近的Freeling形态分析器版本，并且发布时附带了一个包含2,291个句子的自动生成的、经过手工验证的树库。我们解释了树库构建过程，强调了它与手动注释的树库构建之间的区别，以及它如何有助于基于经验证据的句法理论发展。树库高水平的一致性和细节使其成为训练高质量语义解析器以及一般受益于系统的资源。

    arXiv:2309.13318v2 Announce Type: replace  Abstract: We present the latest version of the Spanish Resource Grammar (SRG), a grammar of Spanish implemented in the HPSG formalism. Such grammars encode a complex set of hypotheses about syntax making them a resource for empirical testing of linguistic theory. They also encode a strict notion of grammaticality which makes them a resource for natural language processing applications in computer-assisted language learning. This version of the SRG uses the recent version of the Freeling morphological analyzer and is released along with an automatically created, manually verified treebank of 2,291 sentences. We explain the treebanking process, emphasizing how it is different from treebanking with manual annotation and how it contributes to empirically-driven development of syntactic theory. The treebanks' high level of consistency and detail makes them a resource for training high-quality semantic parsers and generally systems that benefit from
    
[^126]: 跨语言收据信息提取和分类的全面多语言数据集 CrossLingR

    CrossLingR: A Comprehensive Multilingual Receipt Dataset for Cross-Language Information Extraction and Classification

    [https://arxiv.org/abs/2309.09800](https://arxiv.org/abs/2309.09800)

    本研究介绍了一个全面的多语言数据集CrossLingR，用于推动收据信息提取和物品分类的进展。我们的数据集包含了47,720个标注样本，详细记录了项目名称、相关属性和44个不同的产品类别。通过InstructLLaMA方法论，我们展示了在关键信息提取和物品分类任务中的显著效果。相关资源可在https://github.com/Update-For-Integrated-Business-AI/AMuRD上获取。

    

    关键信息提取的过程对于将扫描的收据转化为结构化、可访问的文件至关重要，有助于有效地检索重要数据。本研究引入了一个广泛的、新颖的多语言数据集，旨在推动收据信息提取和物品分类领域的进展。我们的数据集包含了47,720个带有项目名称、相关属性（如价格和品牌）的标注样本，并按照44个不同的产品类别进行组织。我们揭示了InstructLLaMA方法论，这是一种开创性的方法，通过关键信息提取和物品分类任务中的F1分数为0.76和准确性为0.68的显著效果加以证明。为了支持进一步的研究和应用开发，我们在https://github.com/Update-For-Integrated-Business-AI/AMuRD上提供了我们的全面数据集、InstructLLaMA模型和相关资源。

    The process of key information extraction is critical for converting scanned receipts into structured, accessible documents, facilitating the efficient retrieval of vital data. This research introduces an expansive, novel multilingual dataset designed to propel advancements in the domain of receipt information extraction and item classification. Our dataset encompasses 47,720 annotated samples, detailed with item names, associated attributes such as price and brand, and organized into 44 distinct product categories. We unveil the InstructLLaMA methodology, a pioneering approach that demonstrates significant effectiveness, evidenced by an F1 score of 0.76 and an accuracy of 0.68 in tasks of key information extraction and item classification. To support further research and application development, we make available our comprehensive dataset, the InstructLLaMA model, and relevant resources at https://github.com/Update-For-Integrated-Business-AI/AMuRD.
    
[^127]: 训练BERT模型将一个语料库上开发的编码系统传递到另一个语料库

    Training BERT Models to Carry Over a Coding System Developed on One Corpus to Another

    [https://arxiv.org/abs/2308.03742](https://arxiv.org/abs/2308.03742)

    通过训练BERT模型，成功地将一个在匈牙利文学期刊上开发的编码系统传递到另一个语料库，用以跟踪在1989年匈牙利政治转型时期的文学翻译感知趋势，并展示了模型能够处理标签不平衡问题。

    

    这篇论文描述了我们如何训练BERT模型将一个在匈牙利文学期刊段落上开发的编码系统传递到另一个语料库。编码系统的目的是跟踪匈牙利在1989年政治转型期间对文学翻译感知的趋势。我们使用10折交叉验证来评估任务性能和注释一致性，并通过超参数调整获得最佳结果和公平比较。为了处理标签不平衡问题，我们使用适应的损失函数和指标。通过从目标领域对抽取测试集来评估领域转移的影响。我们通过模拟估计自举置信区间来建立样本大小，展示了我们的模型可以将一个注释系统传递到目标领域。

    arXiv:2308.03742v2 Announce Type: replace  Abstract: This paper describes how we train BERT models to carry over a coding system developed on the paragraphs of a Hungarian literary journal to another. The aim of the coding system is to track trends in the perception of literary translation around the political transformation in 1989 in Hungary. To evaluate not only task performance but also the consistence of the annotation, moreover, to get better predictions from an ensemble, we use 10-fold crossvalidation. Extensive hyperparameter tuning is used to obtain the best possible results and fair comparisons. To handle label imbalance, we use loss functions and metrics robust to it. Evaluation of the effect of domain shift is carried out by sampling a test set from the target domain. We establish the sample size by estimating the bootstrapped confidence interval via simulations. This way, we show that our models can carry over one annotation system to the target domain. Comparisons are dra
    
[^128]: 通过自对比布雷格曼散度学习实现高效的文档嵌入

    Efficient Document Embeddings via Self-Contrastive Bregman Divergence Learning

    [https://arxiv.org/abs/2305.16031](https://arxiv.org/abs/2305.16031)

    通过引入自对比连体网络和神经布雷格曼网络，提高了文档嵌入的质量和效率。

    

    学习高质量的文档嵌入是自然语言处理（NLP）、信息检索（IR）、推荐系统和搜索引擎中的一个基础问题。尽管最近基于Transformer模型的句子嵌入具有自对比学习，但是对长文档进行编码在效率和质量方面仍具有挑战性。因此，我们使用SimCSE方法训练基于Longformer的文档编码器。此外，我们在基线方法--连体神经网络--上增加了基于泛凸布雷格曼散度的额外凸神经网络，旨在提高输出文档表示的质量。我们展示了自对比连体网络和我们提出的神经布雷格曼网络的组合总体上优于两个线性分类基准模型。

    arXiv:2305.16031v2 Announce Type: replace  Abstract: Learning quality document embeddings is a fundamental problem in natural language processing (NLP), information retrieval (IR), recommendation systems, and search engines. Despite recent advances in the development of transformer-based models that produce sentence embeddings with self-contrastive learning, the encoding of long documents (Ks of words) is still challenging with respect to both efficiency and quality considerations. Therefore, we train Longfomer-based document encoders using a state-of-the-art unsupervised contrastive learning method (SimCSE). Further on, we complement the baseline method -- siamese neural network -- with additional convex neural networks based on functional Bregman divergence aiming to enhance the quality of the output document representations. We show that overall the combination of a self-contrastive siamese network and our proposed neural Bregman network outperforms the baselines in two linear class
    
[^129]: 探索多语和双语翻译模型之间的表征差异

    Exploring Representational Disparities Between Multilingual and Bilingual Translation Models

    [https://arxiv.org/abs/2305.14230](https://arxiv.org/abs/2305.14230)

    本文研究了多语模型和双语模型在表征中的几何差异，发现对于给定的语言对，多语模型的解码器表征在各向同性方面一贯较差，占用的维度也较少。

    

    多语言机器翻译通过完全的多语参数共享在许多语言对之间实现了参数效率和整体性能的提升。然而，一些多语模型中的语言对在一对多翻译设置中可能表现不如双语模型，可能主要是因为它们的表征存在几何差异。本文通过计算双语模型和一对多多语模型的表征的各向同性，使用内在维度和IsoScore来量化表征如何利用其基础向量空间中的维度。

    arXiv:2305.14230v2 Announce Type: replace  Abstract: Multilingual machine translation has proven immensely useful for both parameter efficiency and overall performance across many language pairs via complete multilingual parameter sharing. However, some language pairs in multilingual models can see worse performance than in bilingual models, especially in the one-to-many translation setting. Motivated by their empirical differences, we examine the geometric differences in representations from bilingual models versus those from one-to-many multilingual models. Specifically, we compute the isotropy of these representations using intrinsic dimensionality and IsoScore, in order to measure how the representations utilize the dimensions in their underlying vector space. Using the same evaluation data in both models, we find that for a given language pair, its multilingual model decoder representations are consistently less isotropic and occupy fewer dimensions than comparable bilingual model
    
[^130]: Troika: 多路径跨模态拖曳对于组合式零样本学习

    Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot Learning

    [https://arxiv.org/abs/2303.15230](https://arxiv.org/abs/2303.15230)

    提出了一种适用于组合式零样本学习的Troika模型，通过建立三个识别分支共同对状态、对象和组合进行建模，在对齐分支特定提示表示和分解的视觉特征的同时，引入了Cross-Modal Traction模块来校准多模态表示之间的偏差。

    

    最近的组合式零样本学习（CZSL）方法通过仅为组合状态-对象对构建可训练提示来适应预训练的视觉-语言模型（VLMs）。这些方法依赖于学习已见组合的联合表示，而忽略了对状态和对象的显式建模，从而限制了对预训练知识的利用和对未见组合的泛化。在本研究中，我们特别关注解决方案的普适性，提出了一种为CZSL模型建立三个识别分支（即Multi-Path）以共同建模状态、对象和组合的新范式。所提出的Troika是我们的实现，它将分支特定的提示表示与分解的视觉特征对齐。为了校准语义上相似的多模态表示之间的偏差，我们进一步设计了一个Cross-Modal Traction模块来将提示移动到...

    arXiv:2303.15230v2 Announce Type: replace-cross  Abstract: Recent compositional zero-shot learning (CZSL) methods adapt pre-trained vision-language models (VLMs) by constructing trainable prompts only for composed state-object pairs. Relying on learning the joint representation of seen compositions, these methods ignore the explicit modeling of the state and object, thus limiting the exploitation of pre-trained knowledge and generalization to unseen compositions. With a particular focus on the universality of the solution, in this work, we propose a novel paradigm for CZSL models that establishes three identification branches (i.e., Multi-Path) to jointly model the state, object, and composition. The presented Troika is our implementation that aligns the branch-specific prompt representations with decomposed visual features. To calibrate the bias between semantically similar multi-modal representations, we further devise a Cross-Modal Traction module into Troika that shifts the prompt 
    
[^131]: 通过全面评估和Leaderboarding理解长文档排名模型的性能

    Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding

    [https://arxiv.org/abs/2207.01262](https://arxiv.org/abs/2207.01262)

    在标准收集的初步实验中，我们发现长文档模型在MRR或NDCG方面性能不佳，表现低于FirstP，或平均最多超越5％。我们推测这不是因为模型无法处理长上下文，而是由于相关段落具有位置偏见，往往位于前512个文档标记之中。我们找到证据表明这种偏见至少存在于两个测试集中，这促使我们创建了一个新的收集MS MARCO FarRelevant，其中包含

    

    我们评估了20多个用于长文档排名的Transformer模型（包括最近使用FlashAttention训练的LongP模型），并将它们与简单的FirstP基线进行了比较（将相同模型应用于输入截断为前512个标记）。我们使用MS MARCO文档v1作为主要训练集，并在零-shot场景下评估了模型，以及在对其他收集进行微调后评估了模型。

    arXiv:2207.01262v2 Announce Type: replace-cross  Abstract: We evaluated 20+ Transformer models for ranking of long documents (including recent LongP models trained with FlashAttention) and compared them with simple FirstP baselines (applying the same model to input truncated to the first 512 tokens). We used MS MARCO Documents v1 as a primary training set and evaluated models in the zero-shot scenario as well as after fine-tuning on other collections.   In our initial experiments with standard collections we found that long-document models underperformed FirstP or outperformed it by at most 5% on average in terms of MRR or NDCG. We then conjectured that this was not due to models inability to process long context but rather due to a positional bias of relevant passages, which tended to be among the first 512 document tokens. We found evidence that this bias was, indeed, present in at least two test sets, which motivated us to create a new collection MS MARCO FarRelevant where the relev
    
[^132]: 具有时间感知文档嵌入的主题检测和跟踪

    Topic Detection and Tracking with Time-Aware Document Embeddings

    [https://arxiv.org/abs/2112.06166](https://arxiv.org/abs/2112.06166)

    设计了一种将时间和文本信息融合在新闻文档表示中的神经方法，用于事件检测。

    

    一条信息被传播的时间是许多现实世界自然语言处理任务中元数据的关键部分，例如主题检测和跟踪（TDT）。TDT系统旨在通过事件将新闻文章语料库进行聚类，在这种情况下，描述同一事件的故事很可能是在大致相同的时间编写的。先前关于TDT的时间建模的工作考虑到了这一点，但未能很好地捕捉时间如何与事件的语义特性相互作用。例如，关于热带风暴的故事很可能在短时间间隔内编写，而关于电影上映的故事可能会持续几周或几个月。在我们的工作中，我们设计了一种神经方法，将时间和文本信息融合到新闻文档的单一表示中，用于事件检测。我们使用三元损失架构对这些具有时间感知性的文档嵌入进行微调，将模型整合到下游TDT系统中。

    arXiv:2112.06166v2 Announce Type: replace  Abstract: The time at which a message is communicated is a vital piece of metadata in many real-world natural language processing tasks such as Topic Detection and Tracking (TDT). TDT systems aim to cluster a corpus of news articles by event, and in that context, stories that describe the same event are likely to have been written at around the same time. Prior work on time modeling for TDT takes this into account, but does not well capture how time interacts with the semantic nature of the event. For example, stories about a tropical storm are likely to be written within a short time interval, while stories about a movie release may appear over weeks or months. In our work, we design a neural method that fuses temporal and textual information into a single representation of news documents for event detection. We fine-tune these time-aware document embeddings with a triplet loss architecture, integrate the model into downstream TDT systems, an
    
[^133]: 跨多种编程语言的学习转移

    Learning Transfers over Several Programming Languages. (arXiv:2310.16937v1 [cs.CL])

    [http://arxiv.org/abs/2310.16937](http://arxiv.org/abs/2310.16937)

    这篇论文研究了使用跨语言迁移学习提高编程语言模型性能的问题，并进行了广泛实验验证。该研究表明，跨语言迁移学习在编程语言领域具有潜力，可以帮助低资源语言的用户受益于大规模语言模型。

    

    大规模语言模型（LLM）在提高高资源编程语言开发者生产力方面近年来取得了显著的进展。这些模型使用两种类型的数据：大量的无标签代码样本用于预训练，相对较少的带标签代码样本用于微调或上下文学习。然而，许多编程语言是低资源的，缺乏大多数任务的带标签样本，甚至缺乏无标签样本。因此，低资源语言（例如遗留或新语言）的用户无法享受到LLM的好处。跨语言迁移学习使用源语言的数据来提高模型在目标语言上的性能。它在自然语言领域已经得到了广泛研究，但在编程语言领域却受到了很少关注。本文使用基于Transformer的LLM和11到41种编程语言进行了广泛的实验，探讨了以下问题。

    Large language models (LLMs) have recently become remarkably good at improving developer productivity for high-resource programming languages. These models use two kinds of data: large amounts of unlabeled code samples for pretraining and relatively smaller amounts of labeled code samples for fine-tuning or in-context learning. Unfortunately, many programming languages are low-resource, lacking labeled samples for most tasks and often even lacking unlabeled samples. Therefore, users of low-resource languages (e.g., legacy or new languages) miss out on the benefits of LLMs. Cross-lingual transfer learning uses data from a source language to improve model performance on a target language. It has been well-studied for natural languages, but has received little attention for programming languages. This paper reports extensive experiments on four tasks using a transformer-based LLM and 11 to 41 programming languages to explore the following questions. First, how well cross-lingual transfer 
    
[^134]: 带有流匹配的语音生成预训练

    Generative Pre-training for Speech with Flow Matching. (arXiv:2310.16338v1 [eess.AS])

    [http://arxiv.org/abs/2310.16338](http://arxiv.org/abs/2310.16338)

    本文展示了一种使用流匹配的预训练生成模型，该模型可以适应不同的下游任务并获得强大的性能，通过在60k小时的未转录语音上进行预训练，该模型可以与现有的专家模型在语音增强、分离和合成方面进行匹配或超越。

    

    近年来，生成模型在需要估计和抽样数据分布以生成高保真合成数据的任务中取得了显著的成功，因此越来越受到关注。在语音领域，文本到语音合成和神经声码器是生成模型成功应用的典型例子。尽管生成模型已经在语音的不同应用中得到了应用，但还没有一个通用的生成模型可以直接建模语音。在本文中，我们通过展示单一的预训练生成模型可以适应不同的下游任务并获得强大的性能，迈出了这个方向的一步。具体来说，我们使用流匹配和蒙版条件在60k小时的未转录语音上预训练了一个名为SpeechFlow的生成模型。实验结果表明，预训练的生成模型可以通过特定任务数据进行微调，以在语音增强、分离和合成方面达到或超过现有的专家模型的性能。

    Generative models have gained more and more attention in recent years for their remarkable success in tasks that required estimating and sampling data distribution to generate high-fidelity synthetic data. In speech, text-to-speech synthesis and neural vocoder are good examples where generative models have shined. While generative models have been applied to different applications in speech, there exists no general-purpose generative model that models speech directly. In this work, we take a step toward this direction by showing a single pre-trained generative model can be adapted to different downstream tasks with strong performance. Specifically, we pre-trained a generative model, named SpeechFlow, on 60k hours of untranscribed speech with Flow Matching and masked conditions. Experiment results show the pre-trained generative model can be fine-tuned with task-specific data to match or surpass existing expert models on speech enhancement, separation, and synthesis. Our work suggested 
    
[^135]: COPF: 通过最优策略拟合实现持续学习人类偏好

    COPF: Continual Learning Human Preference through Optimal Policy Fitting. (arXiv:2310.15694v1 [cs.LG])

    [http://arxiv.org/abs/2310.15694](http://arxiv.org/abs/2310.15694)

    通过COPF方法，我们不需要重新训练预训练语言模型，而是使用最优策略拟合和函数正则化来持续学习和适应人类偏好的变化。

    

    强化学习通过人类反馈（RLHF）的技术是改善预训练语言模型（LM）以符合人类偏好的常用方法。然而，当前基于RLHF的LM在引入新的查询或反馈时需要完全重新训练，这是一项具有挑战性的任务，因为人类偏好在不同领域或任务之间可能会有所变化。由于所需的时间和计算资源以及与数据隐私相关的问题，重新训练LM在许多现实世界的情况下存在实际困难。为了解决这个限制，我们提出了一种新的方法，称为持续最优策略拟合（COPF），其中我们使用蒙特卡罗法估计一系列最优策略，然后通过函数正则化不断拟合策略序列。COPF包含一个单一的学习阶段，不需要复杂的强化学习。

    The technique of Reinforcement Learning from Human Feedback (RLHF) is a commonly employed method to improve pre-trained Language Models (LM), enhancing their ability to conform to human preferences. Nevertheless, the current RLHF-based LMs necessitate full retraining each time novel queries or feedback are introduced, which becomes a challenging task because human preferences can vary between different domains or tasks. Retraining LMs poses practical difficulties in many real-world situations due to the significant time and computational resources required, along with concerns related to data privacy. To address this limitation, we propose a new method called Continual Optimal Policy Fitting (COPF), in which we estimate a series of optimal policies using the Monte Carlo method, and then continually fit the policy sequence with the function regularization. COPF involves a single learning phase and doesn't necessitate complex reinforcement learning. Importantly, it shares the capability 
    
[^136]: 在低数据环境中，视觉定位有助于学习单词的含义

    Visual Grounding Helps Learn Word Meanings in Low-Data Regimes. (arXiv:2310.13257v1 [cs.CL])

    [http://arxiv.org/abs/2310.13257](http://arxiv.org/abs/2310.13257)

    在低数据环境中，使用视觉定位进行监督训练的神经语言模型可以更接近于人类的语言学习能力。

    

    现代神经语言模型（LM）是用于模拟人类句子产生和理解的强大工具，其内部表达与人类大脑中的语言表达非常吻合。然而，为了取得这些结果，LM必须以与人类完全不同的方式进行训练，需要比儿童在发育过程中接收到的语言数据多几个数量级，并且没有任何感知、行动或社交行为的基础。如果用更接近人类的方式进行训练，即依靠感知的监督，模型的语言学习是否更接近人类？我们在单词学习这一语言习得的关键子任务中研究了这个问题。我们训练了一系列不同的LM架构，并在不同规模的数据集上使用图像字幕任务的辅助监督进行训练。然后我们使用一系列广泛的测试来评估这些模型在句法类别、词汇关系、语义学等方面的学习能力。

    Modern neural language models (LMs) are powerful tools for modeling human sentence production and comprehension, and their internal representations are remarkably well-aligned with representations of language in the human brain. But to achieve these results, LMs must be trained in distinctly un-human-like ways -- requiring orders of magnitude more language data than children receive during development, and without any of the accompanying grounding in perception, action, or social behavior. Do models trained more naturalistically -- with grounded supervision -- exhibit more human-like language learning? We investigate this question in the context of word learning, a key sub-task in language acquisition. We train a diverse set of LM architectures, with and without auxiliary supervision from image captioning tasks, on datasets of varying scales. We then evaluate these models on a broad set of benchmarks characterizing models' learning of syntactic categories, lexical relations, semantic f
    
[^137]: 大型语言模型用于多目标进化优化

    Large Language Model for Multi-objective Evolutionary Optimization. (arXiv:2310.12541v1 [cs.NE])

    [http://arxiv.org/abs/2310.12541](http://arxiv.org/abs/2310.12541)

    本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。

    

    多目标进化算法（MOEAs）是解决多目标优化问题（MOPs）的主要方法。在过去几十年中，提出了许多MOEAs，其操作符需要通过领域知识进行精心设计。最近，一些尝试将MOEAs中手动设计的操作符替换为基于学习的操作符（如神经网络模型）已经取得了一些进展。然而，设计和训练这样的模型仍然需要大量的工作，并且学习到的操作符可能不能很好地推广到解决新问题。为了解决上述挑战，本文研究了一种利用强大的大型语言模型（LLM）来设计MOEA操作符的新方法。通过适当的提示工程，我们成功地让一个通用的LLM以零-shot的方式作为分解型MOEA（MOEA/D）的黑盒搜索操作符。此外，通过从LLM行为中学习，我们进一步设计了一个显性的白盒操作符，并提出了...

    Multiobjective evolutionary algorithms (MOEAs) are major methods for solving multiobjective optimization problems (MOPs). Many MOEAs have been proposed in the past decades, of which the operators need carefully handcrafted design with domain knowledge. Recently, some attempts have been made to replace the manually designed operators in MOEAs with learning-based operators (e.g., neural network models). However, much effort is still required for designing and training such models, and the learned operators might not generalize well to solve new problems. To tackle the above challenges, this work investigates a novel approach that leverages the powerful large language model (LLM) to design MOEA operators. With proper prompt engineering, we successfully let a general LLM serve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a zero-shot manner. In addition, by learning from the LLM behavior, we further design an explicit white-box operator with randomness and propose
    
[^138]: 在一千年前的拉丁文本中检测句子级别的性内容

    Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts. (arXiv:2309.14974v1 [cs.CL])

    [http://arxiv.org/abs/2309.14974](http://arxiv.org/abs/2309.14974)

    该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。

    

    在这项研究中，我们提出使用深度学习方法在句子级别进行语义分类，以加快人文学科和语言学领域中语料库建设的过程，这是一项传统且耗时的任务。我们引入了一个新颖的语料库，包括约2500个句子，涵盖了从公元前300年到公元900年的性语义学（医学，情色等）。我们评估了各种句子分类方法和不同的输入嵌入层，并表明它们都比简单的基于标记的搜索方法更好。我们探索了个人言语和社会言语元数据嵌入（世纪，作者，写作类型）的整合，但发现这导致了过拟合。我们的结果表明了这种方法的有效性，使用HAN分别达到了70.60%的高精度和86.33%的真阳性率（TPR）。我们评估了数据集大小对模型性能的影响（420而不是2013），并显示出，尽管我们的模型性能可能稍有下降，但性能仍然稳定。

    In this study, we propose to evaluate the use of deep learning methods for semantic classification at the sentence level to accelerate the process of corpus building in the field of humanities and linguistics, a traditional and time-consuming task. We introduce a novel corpus comprising around 2500 sentences spanning from 300 BCE to 900 CE including sexual semantics (medical, erotica, etc.). We evaluate various sentence classification approaches and different input embedding layers, and show that all consistently outperform simple token-based searches. We explore the integration of idiolectal and sociolectal metadata embeddings (centuries, author, type of writing), but find that it leads to overfitting. Our results demonstrate the effectiveness of this approach, achieving high precision and true positive rates (TPR) of respectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset size on the model performances (420 instead of 2013), and show that, while our models per
    
[^139]: 同时解析短语结构树和依存树真的有用吗？重新审视

    Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit. (arXiv:2309.11888v1 [cs.CL])

    [http://arxiv.org/abs/2309.11888](http://arxiv.org/abs/2309.11888)

    本文重新审视了同时解析短语结构树和依存树的方法，通过采用更高效的解码算法、在训练阶段进行联合建模、提出高阶评分组件以及进行深入实验和分析等四个方面的进展，展示了该方法的潜力和价值。

    

    本文重新审视了同时解析短语结构树和依存树这一话题，即为输入句子同时生成兼容的短语结构树和依存树，考虑到这两种类型的树在表示语法方面是互补的，这是一种有吸引力的方法。与之前的工作相比，我们在四个方面取得了进展：（1）采用更高效的解码算法，（2）在训练阶段进行联合建模，而不仅仅是在推理阶段，（3）为短语结构和依存之间的交互提出了高阶评分组件，（4）通过深入实验和分析获得了更多见解。

    This work visits the topic of jointly parsing constituency and dependency trees, i.e., to produce compatible constituency and dependency trees simultaneously for input sentences, which is attractive considering that the two types of trees are complementary in representing syntax. Compared with previous works, we make progress in four aspects: (1) adopting a much more efficient decoding algorithm, (2) exploring joint modeling at the training phase, instead of only at the inference phase, (3) proposing high-order scoring components for constituent-dependency interaction, (4) gaining more insights via in-depth experiments and analysis.
    
[^140]: 大型语言模型能否辨别科学假设的证据？社会科学案例研究。

    Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences. (arXiv:2309.06578v1 [cs.CL])

    [http://arxiv.org/abs/2309.06578](http://arxiv.org/abs/2309.06578)

    本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。

    

    假设的制定和测试是经验性研究的核心。一个强有力的假设是基于现有证据的最佳猜测，并且是基于相关文献的全面视图进行启发的。然而，随着每年科学文章数量的指数增长，对于给定假设相关证据的手动汇总和综合是一项挑战。我们的工作探索了当前大型语言模型（LLMs）根据科学摘要文本中的证据，能否辨别支持或反驳特定假设的能力。我们共享了一个新颖的数据集，用于社会科学中使用社区驱动的研究注释的科学假设证据任务。我们将LLMs的性能与几个最先进的基准进行比较，并指出未来研究的机会。该数据集可在https://github.com/Sai90000/ScientificHypothesisEvidencing.git上获得。

    Hypothesis formulation and testing are central to empirical research. A strong hypothesis is a best guess based on existing evidence and informed by a comprehensive view of relevant literature. However, with exponential increase in the number of scientific articles published annually, manual aggregation and synthesis of evidence related to a given hypothesis is a challenge. Our work explores the ability of current large language models (LLMs) to discern evidence in support or refute of specific hypotheses based on the text of scientific abstracts. We share a novel dataset for the task of scientific hypothesis evidencing using community-driven annotations of studies in the social sciences. We compare the performance of LLMs to several state-of-the-art benchmarks and highlight opportunities for future research in this area. The dataset is available at https://github.com/Sai90000/ScientificHypothesisEvidencing.git
    
[^141]: BAN-PL: 一份来自Wykop.pl网站的禁止有害和攻击性内容的新波兰数据集

    BAN-PL: a Novel Polish Dataset of Banned Harmful and Offensive Content from Wykop.pl web service. (arXiv:2308.10592v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10592](http://arxiv.org/abs/2308.10592)

    BAN-PL是波兰语的第一个开放数据集，包含来自Wykop这个类似"波兰版Reddit"的社交网络服务的被标记为有害并删除的内容，将有助于改进自动检测互联网上的冒犯性语言的技术。

    

    在自动检测互联网上的冒犯性语言、仇恨言论和网络欺凌方面取得的进展需要改进对包含社交媒体内容的公开可用数据集的访问。在本文中，我们介绍了BAN-PL，这是第一个以波兰语提供的开放数据集，它包含了被专业审查员标记为有害并随后被删除的文本。数据集共包含来自Wykop这个颇受欢迎的社交网络服务的691,662条内容，其中包括帖子和评论，并且平均分为两个不同的类别：“有害”和“中立”。我们提供了数据收集和预处理程序的详细说明，并强调了数据的语言特殊性。BAN-PL数据集以及用于预处理脏话的高级脚本将公开提供。

    Advances in automated detection of offensive language online, including hate speech and cyberbullying, require improved access to publicly available datasets comprising social media content. In this paper, we introduce BAN-PL, the first open dataset in the Polish language that encompasses texts flagged as harmful and subsequently removed by professional moderators. The dataset encompasses a total of 691,662 pieces of content from a popular social networking service, Wykop, often referred to as the "Polish Reddit", including both posts and comments, and is evenly distributed into two distinct classes: "harmful" and "neutral". We provide a comprehensive description of the data collection and preprocessing procedures, as well as highlight the linguistic specificity of the data. The BAN-PL dataset, along with advanced preprocessing scripts for, i.a., unmasking profanities, will be publicly available.
    
[^142]: GPT-4太聪明以至于不安全：通过密码与LLMs进行隐蔽聊天

    GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher. (arXiv:2308.06463v1 [cs.CL])

    [http://arxiv.org/abs/2308.06463](http://arxiv.org/abs/2308.06463)

    这项研究发现，通过使用密码进行聊天可以绕过大型语言模型（LLMs）的安全对齐技术。研究人员提出了一种名为CipherChat的框架，用于系统地检查安全对齐在非自然语言（密码）中的普适性，并通过实验评估了ChatGPT和GPT-4等最先进的LLMs对不同代表性人类密码在11个安全领域中的影响。

    

    安全性是大型语言模型（LLMs）开发的核心。关于将LLMs与人类伦理和偏好进行对齐的工作已经很多，包括在预训练中进行数据筛选、通过监督微调、通过人类反馈进行强化学习以及红队测试等等。在这项研究中，我们发现使用密码进行聊天可以绕过LLMs的安全对齐技术，这些技术主要是在自然语言中进行的。我们提出了一个新颖的框架CipherChat，用于系统地检查安全对齐在非自然语言（密码）中的普适性。CipherChat使人们能够通过加密提示和少量加密演示与LLMs进行聊天。我们使用CipherChat在英语和中文中评估最先进的LLMs，包括ChatGPT和GPT-4在11个安全领域中的不同代表性人类密码。实验结果表明，某些密码成功地绕过了安全对齐技术，几乎100%的时间都能够成功。

    Safety lies at the core of the development of Large Language Models (LLMs). There is ample work on aligning LLMs with human ethics and preferences, including data filtering in pretraining, supervised fine-tuning, reinforcement learning from human feedback, and red teaming, etc. In this study, we discover that chat in cipher can bypass the safety alignment techniques of LLMs, which are mainly conducted in natural languages. We propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages -- ciphers. CipherChat enables humans to chat with LLMs through cipher prompts topped with system role descriptions and few-shot enciphered demonstrations. We use CipherChat to assess state-of-the-art LLMs, including ChatGPT and GPT-4 for different representative human ciphers across 11 safety domains in both English and Chinese. Experimental results show that certain ciphers succeed almost 100% of the time to bypass the safety alignment
    
[^143]: 生成器-检索器-生成器：开放域问答的新方法

    Generator-Retriever-Generator: A Novel Approach to Open-domain Question Answering. (arXiv:2307.11278v1 [cs.CL])

    [http://arxiv.org/abs/2307.11278](http://arxiv.org/abs/2307.11278)

    生成器-检索器-生成器（GRG）是一种新方法，将文档检索技术与大型语言模型相结合，以生成开放域问答的准确和信息丰富的答案。

    

    开放域问答任务通常需要从大型语料库中检索相关信息以生成准确的答案。我们提出了一种称为生成器-检索器-生成器（GRG）的新方法，将文档检索技术与大型语言模型（LLM）相结合，首先通过给定问题提示模型生成上下文文档。同时，双编码器网络从外部语料库中检索与问题相关的文档。生成和检索的文档然后传递给第二个LLM，生成最终答案。通过结合文档检索和LLM生成，我们的方法解决了开放域问答的挑战，例如生成信息丰富和上下文相关的答案。GRG在TriviaQA、NQ和WebQ数据集上表现优于现有的生成-读取和检索-读取流水线（GENREAD和RFiD），分别至少提高了+5.2、+4.2和+1.6的性能。

    Open-domain question answering (QA) tasks usually require the retrieval of relevant information from a large corpus to generate accurate answers. We propose a novel approach called Generator-Retriever-Generator (GRG) that combines document retrieval techniques with a large language model (LLM), by first prompting the model to generate contextual documents based on a given question. In parallel, a dual-encoder network retrieves documents that are relevant to the question from an external corpus. The generated and retrieved documents are then passed to the second LLM, which generates the final answer. By combining document retrieval and LLM generation, our approach addresses the challenges of open-domain QA, such as generating informative and contextually relevant answers. GRG outperforms the state-of-the-art generate-then-read and retrieve-then-read pipelines (GENREAD and RFiD) improving their performance at least by +5.2, +4.2, and +1.6 on TriviaQA, NQ, and WebQ datasets, respectively.
    
[^144]: 美国餐厅评论和大型语言模型中的移民美食他者化和低声望构架

    Othering and low prestige framing of immigrant cuisines in US restaurant reviews and large language models. (arXiv:2307.07645v1 [cs.CL])

    [http://arxiv.org/abs/2307.07645](http://arxiv.org/abs/2307.07645)

    通过对2.1M英语Yelp评论的餐厅进行语言分析，研究发现移民美食更容易被构架为客观和他者化，而非西方移民美食受欢迎程度更高。

    

    识别和理解对食物的隐含态度有助于减轻因食物作为文化和种族身份的标志而导致的社会偏见。对食物的刻板印象是一种微侵略，它对有害的公共话语做出了贡献，这可能反过来加深对民族群体的偏见，并对餐馆的经济结果产生负面影响。通过仔细的语言分析，我们在一项大规模研究中评估了对移民美食态度的社会理论。该研究使用了2.1M英语Yelp评论的餐厅在14个美国州的框架差异。在控制了餐厅价格和邻里种族多样性等因素后，我们发现移民美食更有可能以客观和他者化的形式进行构架，如真实性（例如，真实，传统），异国情调（例如，异国，不同）和典型性（例如，典型，通常）。但非西方移民美食（例如，印度，墨西哥）更受欢迎。

    Identifying and understanding implicit attitudes toward food can help efforts to mitigate social prejudice due to food's pervasive role as a marker of cultural and ethnic identity. Stereotypes about food are a form of microaggression that contribute to harmful public discourse that may in turn perpetuate prejudice toward ethnic groups and negatively impact economic outcomes for restaurants. Through careful linguistic analyses, we evaluate social theories about attitudes toward immigrant cuisine in a large-scale study of framing differences in 2.1M English language Yelp reviews of restaurants in 14 US states. Controlling for factors such as restaurant price and neighborhood racial diversity, we find that immigrant cuisines are more likely to be framed in objectifying and othering terms of authenticity (e.g., authentic, traditional), exoticism (e.g., exotic, different), and prototypicality (e.g., typical, usual), but that non-Western immigrant cuisines (e.g., Indian, Mexican) receive mor
    
[^145]: 在大型语言模型中释放认知协同：通过多人格自我协作实现任务解决代理

    Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration. (arXiv:2307.05300v1 [cs.AI])

    [http://arxiv.org/abs/2307.05300](http://arxiv.org/abs/2307.05300)

    本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。

    

    人类智慧依赖于认知协同的概念，即在不同认知过程之间进行协作和信息整合，以获得比个体认知过程更出色的结果。尽管大型语言模型（LLM）作为通用任务解决代理表现出了令人期待的性能，但它们在需要丰富领域知识和复杂推理的任务上仍然面临困难。在这项工作中，我们提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个LLM转化为认知协同者。认知协同者指的是一个智能代理，与多个智慧合作，结合他们的个体优势和知识，从而增强复杂任务的问题解决能力和整体性能。通过根据任务输入动态识别和模拟不同的角色，SPP释放了LLM中认知协同的潜力。

    Human intelligence thrives on the concept of cognitive synergy, where collaboration and information integration among different cognitive processes yield superior outcomes compared to individual cognitive processes in isolation. Although Large Language Models (LLMs) have demonstrated promising performance as general task-solving agents, they still struggle with tasks that require intensive domain knowledge and complex reasoning. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist refers to an intelligent agent that collaborates with multiple minds, combining their individual strengths and knowledge, to enhance problem-solving and overall performance in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. We have discovered that assi
    
[^146]: 提升中文文本主题划分和纲要生成：段落级主题表示，语料库和基准

    Advancing Topic Segmentation and Outline Generation in Chinese Texts: The Paragraph-level Topic Representation, Corpus, and Benchmark. (arXiv:2305.14790v1 [cs.CL])

    [http://arxiv.org/abs/2305.14790](http://arxiv.org/abs/2305.14790)

    本文提出了一种分层的段落级中文主题结构表示，使用句子而不是关键词来表示子主题，构建了大规模、高质量的中文段落级主题结构语料库。

    

    主题划分和纲要生成旨在将一个文档分成连贯的主题段落并生成相应的子标题。这个过程揭示了一个文档的话题结构，有助于从更高的层次快速把握和理解文档的整体情境。然而，与英语领域取得的成功相比，由于缺乏适当的段落级主题表示和大规模、高质量的中文语料库，这一领域的研究和应用受到了限制。为了解决这些问题，我们引入了一种分层的段落级主题结构表示，包括标题、子标题和段落，综合地模拟了文档的话题结构。此外，我们通过使用句子而不是关键词来表示子主题，确保更全面地表示文档内的主题分布。根据这种表示，我们构建了最大的中文段落级主题结构语料库之一。

    Topic segmentation and outline generation strive to divide a document into coherent topic sections and generate corresponding subheadings. Such a process unveils the discourse topic structure of a document that benefits quickly grasping and understanding the overall context of the document from a higher level. However, research and applications in this field have been restrained due to the lack of proper paragraph-level topic representations and large-scale, high-quality corpora in Chinese compared to the success achieved in English. Addressing these issues, we introduce a hierarchical paragraph-level topic structure representation with title, subheading, and paragraph that comprehensively models the document discourse topic structure. In addition, we ensure a more holistic representation of topic distribution within the document by using sentences instead of keywords to represent sub-topics. Following this representation, we construct the largest Chinese Paragraph-level Topic Structur
    
[^147]: ChatGPT 需要进行SPADE（可持续性、隐私、数字鸿沟和伦理）评估：一项综述。

    ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review. (arXiv:2305.03123v1 [cs.CY])

    [http://arxiv.org/abs/2305.03123](http://arxiv.org/abs/2305.03123)

    本文研究关注ChatGPT面临的可持续性、隐私、数字鸿沟和伦理问题，提出了SPADE评估的必要性，并给出了缓解和建议。

    

    ChatGPT是另一个大型语言模型（LLM），由于其性能和有效的对话能力，在研究和工业界中得到了巨大的关注。最近，许多研究已经发表，以展示ChatGPT和其他LLMs的有效性、效率、集成和情感。相反，本研究关注的是大多数被忽视的重要方面，即可持续性、隐私、数字鸿沟和伦理，并建议不仅仅是ChatGPT，而是在对话机器人类别中的每一个后续入口都应该进行SPADE评估。本文详细讨论了关于ChatGPT的问题和关注点与上述特征一致。我们通过一些初步的数据收集和可视化以及假设的事实来支持我们的假设。我们还为每个问题提出了缓解和建议。此外，我们还提供了一些未来方向和开放问题的探讨。

    ChatGPT is another large language model (LLM) inline but due to its performance and ability to converse effectively, it has gained a huge popularity amongst research as well as industrial community. Recently, many studies have been published to show the effectiveness, efficiency, integration, and sentiments of chatGPT and other LLMs. In contrast, this study focuses on the important aspects that are mostly overlooked, i.e. sustainability, privacy, digital divide, and ethics and suggests that not only chatGPT but every subsequent entry in the category of conversational bots should undergo Sustainability, PrivAcy, Digital divide, and Ethics (SPADE) evaluation. This paper discusses in detail about the issues and concerns raised over chatGPT in line with aforementioned characteristics. We support our hypothesis by some preliminary data collection and visualizations along with hypothesized facts. We also suggest mitigations and recommendations for each of the concerns. Furthermore, we also s
    
[^148]: PWESuite：语音单词嵌入及其任务

    PWESuite: Phonetic Word Embeddings and Tasks They Facilitate. (arXiv:2304.02541v1 [cs.CL])

    [http://arxiv.org/abs/2304.02541](http://arxiv.org/abs/2304.02541)

    本论文展示了一套语音单词嵌入及其相关任务，提高了语音信息处理的效果和可重复性。

    

    将单词映射到固定维度的向量空间的单词嵌入是现代自然语言处理的基础。大多数单词嵌入方法编码语义信息。但是，对于某些任务非常重要的语音信息经常被忽略。在这项工作中，我们开发了几种新方法，利用发声特征构建语音知情单词嵌入，并提供一套语音单词嵌入以鼓励其社区的开发、评估和使用。虽然已经存在许多学习语音单词嵌入的方法，但在评估其有效性方面缺乏一致性。因此，我们还提出了几种评估语音单词嵌入的内在方面的方法，如单词检索和与声音相似性的相关性，以及外在表现，如韵律和同源检测和声音类比。我们希望我们的任务套件将促进可重复性并提供未来语音单词嵌入研究的方向。

    Word embeddings that map words into a fixed-dimensional vector space are the backbone of modern NLP. Most word embedding methods encode semantic information. However, phonetic information, which is important for some tasks, is often overlooked. In this work, we develop several novel methods which leverage articulatory features to build phonetically informed word embeddings, and present a set of phonetic word embeddings to encourage their community development, evaluation and use. While several methods for learning phonetic word embeddings already exist, there is a lack of consistency in evaluating their effectiveness. Thus, we also proposes several ways to evaluate both intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and extrinsic performances, such as rhyme and cognate detection and sound analogies. We hope that our suite of tasks will promote reproducibility and provide direction for future research on phonetic word embeddi
    
[^149]: ChatGPT是否和人类在语言使用上相似?

    Does ChatGPT resemble humans in language use?. (arXiv:2303.08014v1 [cs.CL])

    [http://arxiv.org/abs/2303.08014](http://arxiv.org/abs/2303.08014)

    ChatGPT在大部分语言处理实验中与人类表现相似，能够产生人类一样的语言使用特征。但在两个实验中存在偏差，说明人类和机器语言处理之间仍存在重大差异。

    

    大型语言模型(LLM)和以LLM为驱动的聊天机器人(如ChatGPT)在理解和生成语言方面表现出色。然而，在认知层面上，它们的内部机制仍然是黑匣子，不清楚LLM和聊天机器人是否能够发展出人类的语言使用特征。我们对ChatGPT进行了12个实验，每个实验注册前进行了1000次运行。在其中的10个实验中，ChatGPT复制了人类语言使用的模式。它将不熟悉的单词与不同的含义进行关联，根据单词形式继续访问最近遇到的歧义词汇的含义，重用最近的语句结构，重新解释可能被噪声干扰的不合理语句，忽略错误，进行合理推断，根据它们的顺序和接近程度将因果关系与不同的话语实体相关联，并实时更正一致性错误。然而，在两个实验中，ChatGPT显示出与人类表现的偏差，这表明人类和机器语言处理之间仍存在重大差异。

    Large language models (LLMs) and LLM-driven chatbots such as ChatGPT have shown remarkable capacities in comprehending and producing language. However, their internal workings remain a black box in cognitive terms, and it is unclear whether LLMs and chatbots can develop humanlike characteristics in language use. Cognitive scientists have devised many experiments that probe, and have made great progress in explaining, how people process language. We subjected ChatGPT to 12 of these experiments, pre-registered and with 1,000 runs per experiment. In 10 of them, ChatGPT replicated the human pattern of language use. It associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, reinterpreted implausible sentences that were likely to have been corrupted by noise, glossed over errors, drew reasonable inferences, associated causality with different discourse entities accor
    

