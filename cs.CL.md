# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent.](http://arxiv.org/abs/2309.12311) | LLM-Grounder是一种零样本、开放词汇的基于大型语言模型的3D视觉定位流程，通过利用语言模型分解查询并使用视觉定位工具识别物体，实现了在没有标记训练数据的情况下对新场景和文本查询的有效定位。在ScanRefer基准上取得了最先进的零样本定位准确性。 |
| [^2] | [Rehearsal: Simulating Conflict to Teach Conflict Resolution.](http://arxiv.org/abs/2309.12309) | 演练是一个系统，通过模拟冲突和提供反馈，教授用户冲突解决的技能。利用演练，用户可以练习处理各种冲突场景，并学习如何运用冲突策略。 |
| [^3] | [LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models.](http://arxiv.org/abs/2309.12307) | LongLoRA是一种高效的精细调整方法，可以在有限的计算成本下扩展预训练的大型语言模型的上下文大小。它通过稀疏的局部注意力实现精细调整，并使用移动短注意力有效实现上下文扩展，与传统方法具有相似的性能。 |
| [^4] | [Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models.](http://arxiv.org/abs/2309.12294) | 本研究提出了一种新颖的生成和重新排序方法，用于解决大型语言模型在从逻辑形式中生成自然语言方面的质量不一致问题。通过对候选输出进行重新排序，我们的方法能够更好地体现逻辑形式的语义，并提升生成结果的质量。 |
| [^5] | [The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A".](http://arxiv.org/abs/2309.12288) | LLMs模型在训练中只能学习到"A是B"的结构，无法自动推广到"B是A"。这表明模型在逻辑推断上存在基本失败和训练集中模式的推广问题。 |
| [^6] | [MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models.](http://arxiv.org/abs/2309.12284) | MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。 |
| [^7] | [Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition.](http://arxiv.org/abs/2309.12278) | 本文提出了一种通过外部知识激发大型语言模型在生物医学命名实体识别中的应用方法，通过分解NER任务为实体跨度提取和实体类型确定两步骤，并引入领域知识来增强实体类别确定性能，取得了显著的改进。 |
| [^8] | [LLMR: Real-time Prompting of Interactive Worlds using Large Language Models.](http://arxiv.org/abs/2309.12276) | LLMR是一个用于实时创建和修改交互式混合现实体验的框架，通过利用大型语言模型和新颖的策略，它能够解决训练数据稀缺和设计目标复杂的问题，并在性能上超过标准的GPT-4。我们展示了LLMR的跨平台互操作性，并通过评估和用户研究证明了其对于生成和编辑各种对象、工具和场景的能力。 |
| [^9] | [Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports.](http://arxiv.org/abs/2309.12273) | 通过自适应的NLP模型选择和临床专家规则的分类器，该研究提出一种改进VTE识别的新方法，在放射学报告中准确识别VTE事件的准确性得到提高。 |
| [^10] | [The Cambridge Law Corpus: A Corpus for Legal AI Research.](http://arxiv.org/abs/2309.12269) | 剑桥法律语料库是一个用于法律人工智能研究的语料库，包含来自英国的超过250,000个法庭案例。在该语料库的基础上，我们提供了案例结果的专家注解，并使用多个模型进行了案例结果提取的训练和评估，为研究提供了基准。 |
| [^11] | [On the Relationship between Skill Neurons and Robustness in Prompt Tuning.](http://arxiv.org/abs/2309.12263) | 本文研究了Prompt Tuning在与"技能神经元"的关系中的鲁棒性，发现特定任务的调整指令在相同类型的任务上具有传递性，但对于对抗性数据的鲁棒性不高，其中T5的鲁棒性比RoBERTa更高，并且发现T5和RoBERTa中都存在技能神经元。 |
| [^12] | [SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References.](http://arxiv.org/abs/2309.12250) | 提出了一种新的问答系统评估指标SQuArE，使用多个参考答案进行句子级问答评估，实现了高度相关性的评估结果。 |
| [^13] | [Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection.](http://arxiv.org/abs/2309.12247) | 大型语言模型对于假新闻检测的潜力仍未得到充分探索。实证研究发现，尽管复杂的大型语言模型能够揭示假新闻并提供多角度解释，但仍不如经过fine-tuned的小型语言模型表现出色。当前的大型语言模型可能无法取代小型语言模型，但可以作为一个良好的辅助顾问。 |
| [^14] | [ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events.](http://arxiv.org/abs/2309.12244) | ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。 |
| [^15] | [Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition.](http://arxiv.org/abs/2309.12234) | 本研究提出了一种同步双语CTC框架，用于桥接语音翻译任务中的模态和语言差距，并在资源有限情况下取得了state-of-the-art表现。同时，该方法还在语音识别性能上展示了显著的提升。 |
| [^16] | [Towards Answering Health-related Questions from Medical Videos: Datasets and Approaches.](http://arxiv.org/abs/2309.12224) | 本文旨在通过提供医学视频中的视觉答案来回答公众提出的健康相关问题，其中关键挑战是医学领域缺乏大规模数据集。我们提出了两个大规模数据集，并使用单模态和多模态方法有效地提供视觉答案。 |
| [^17] | [Code Soliloquies for Accurate Calculations in Large Language Models.](http://arxiv.org/abs/2309.12161) | 该论文介绍了一种应对大型语言模型在处理复杂计算方面的限制性的创新方法，通过生成模拟对话，并在每个学生回答触发自言自语来提高性能。 |
| [^18] | [OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media.](http://arxiv.org/abs/2309.12137) | 该论文介绍了一个用于阿拉伯多方言在线社交媒体对话的机器翻译数据集，指出了阿拉伯语资源不足的问题以及现有机器翻译系统在处理阿拉伯方言时的困难。该研究的重点在于开发能够有效处理阿拉伯各种方言的机器翻译系统。 |
| [^19] | [How-to Guides for Specific Audiences: A Corpus and Initial Findings.](http://arxiv.org/abs/2309.12117) | 本文研究了来自wikiHow平台的如何指南在实践中面向特定受众的差异。研究发现这些指南受到微妙的偏见的影响，旨在引起人们对这些不平等问题的关注，并为未来的工作解决这些问题铺平道路。 |
| [^20] | [PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models.](http://arxiv.org/abs/2309.12109) | 本研究在低资源语言模型如藏语中进行了高效微调策略的研究，填补了这一重要空白。 |
| [^21] | [A Computational Analysis of Vagueness in Revisions of Instructional Texts.](http://arxiv.org/abs/2309.12107) | 本文通过研究修订历史来分析教学文本修订中的模糊性。通过采用成对排名任务，神经模型在区分指令的不同版本上表现出了改进。 |
| [^22] | [SemEval-2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts.](http://arxiv.org/abs/2309.12102) | SemEval-2022任务7旨在识别指导文本中暗含或不明确短语的合理解释。通过人类评判和参与系统的自动判断，最好的系统在此任务上达到了68.9%的准确率。同时，还发现了有多个合理解释的上下文可以以75.2%的准确率被排名前的参与团队的预测所识别出来。 |
| [^23] | [Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models.](http://arxiv.org/abs/2309.12075) | 本研究通过Benchmark测试，发现使用Prompt Tuning的预训练语言模型在多标签文本分类任务中具有较好的性能和计算效率。同时，提出了使用Trie搜索来解决生成标签匹配问题的限制。 |
| [^24] | [Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam.](http://arxiv.org/abs/2309.12071) | 本研究对基于量化LLaMa模型的大型语言模型在巴西中学考试上进行了性能评估。评估结果表明，最佳表现的模型在原版葡萄牙语问题和其英文翻译上的准确率约为46%。同时，作者还评估了这些模型的计算效率。 |
| [^25] | [BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision.](http://arxiv.org/abs/2309.12056) | BELT是一种通过自然语言监督进行脑电图到语言解码和零样本情感分类的引导式模型和学习框架。它利用现成的大规模预训练语言模型来改进脑电信号的理解，从而推动了大脑-计算机界面的应用和发展。 |
| [^26] | [AceGPT, Localizing Large Language Models in Arabic.](http://arxiv.org/abs/2309.12053) | 本研究旨在开发阿拉伯文的本地化大型语言模型(AceGPT)，通过预训练、监督微调和增强学习方法来培养具备文化意识和价值观一致的阿拉伯文模型，以满足阿拉伯语社区特定应用需求。评估结果表明，AceGPT在各项基准测试中都是最先进的阿拉伯文模型。 |
| [^27] | [CAMERA: A Multimodal Dataset and Benchmark for Ad Text Generation.](http://arxiv.org/abs/2309.12030) | 本文介绍了一个重新设计的任务和构建了一个基准，通过引入CA Multimodal Evaluation for Ad Text GeneRAtion (CAMERA)数据集，推动了广告文本生成领域的发展并解决了现有基准中的缺陷。 |
| [^28] | [LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset.](http://arxiv.org/abs/2309.11998) | LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。 |
| [^29] | [Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics.](http://arxiv.org/abs/2309.11981) | 这篇论文重新思考了人工智能系统中自然语言理解的评估框架，提出了以语言习得为核心的全面框架，旨在解决传统度量方法面临的问题，并借鉴了大型语言模型的进展。 |
| [^30] | [Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT.](http://arxiv.org/abs/2309.11979) | 本论文通过构建自然语言处理模型BERT并对其进行fine-tune，实现了股市情绪的分类和基于该模型的回测分析。实验结果显示，fine-tuned模型相比原始模型和基准模型有不同程度的性能改进。 |
| [^31] | [Scaling up COMETKIWI: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task.](http://arxiv.org/abs/2309.11925) | Unbabel和Instituto Superior Técnico提交了Unbabel-IST 2023年参加WMT 2023年质量评估共享任务的成果，他们在所有任务中排名第一，在质量评估中取得了单词、跨度和句子级别的最新最好表现。 |
| [^32] | [InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework.](http://arxiv.org/abs/2309.11911) | InstructERC是一种使用大型语言模型(LLMs)的生成式框架，通过引入检索模板模块和额外的情感对齐任务，改革了对话中的情绪识别。 |
| [^33] | [Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection.](http://arxiv.org/abs/2309.11896) | FiADD是一种新颖的焦点推理注入与易处理密度区分框架，通过将隐性仇恨言论的表面形式与暗示的形式更接近，同时增加不同类别标签之间的集群间距，显著改进了隐性仇恨分类任务的性能。 |
| [^34] | [Audio Contrastive based Fine-tuning.](http://arxiv.org/abs/2309.11895) | 本论文提出了一种基于音频对比的微调方法（AudioConFit），通过借助对比学习的可转移性，该方法在各种音频分类任务中表现出强大的泛化能力，并在不同设置下实现了最先进的结果。 |
| [^35] | [Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit.](http://arxiv.org/abs/2309.11888) | 本文重新审视了同时解析短语结构树和依存树的方法，通过采用更高效的解码算法、在训练阶段进行联合建模、提出高阶评分组件以及进行深入实验和分析等四个方面的进展，展示了该方法的潜力和价值。 |
| [^36] | [Syntactic Variation Across the Grammar: Modelling a Complex Adaptive System.](http://arxiv.org/abs/2309.11869) | 本文对一个复杂自适应系统-语法之间的句法变异进行了建模和研究，结果表明句法变异不仅涉及个别节点，还涉及整个语法结构的相互作用。 |
| [^37] | [BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework.](http://arxiv.org/abs/2309.11853) | BitCoin是一种创新的基于双向标记和监督对比学习的联合关系三元组提取框架，用于解决关系三元组提取中的问题和局限性。通过设计监督对比学习方法，考虑了每个锚点的多个正例，提高了提取的效果。 |
| [^38] | [Knowledge Sanitization of Large Language Models.](http://arxiv.org/abs/2309.11852) | 这项研究探索了一种用于减轻大型语言模型（LLM）隐私问题的知识净化方法。通过微调模型，使其在被询问敏感信息时生成无害回答，从而有效地减少知识泄漏并保持整体性能。 |
| [^39] | [A Discourse-level Multi-scale Prosodic Model for Fine-grained Emotion Analysis.](http://arxiv.org/abs/2309.11849) | 本文提出了一种话语级多尺度韵律模型，用于细粒度情感分析。通过预测适当的韵律特征，该模型可以指导语音合成模型生成更富有表现力的语音。实验证明，多尺度文本信息对于预测情感韵律特征具有有效性。 |
| [^40] | [Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues.](http://arxiv.org/abs/2309.11838) | 本文研究了在信息搜索对话中使用大型语言模型进行基于文档的响应生成，并通过人工评估了其性能。 |
| [^41] | [A Chinese Prompt Attack Dataset for LLMs with Evil Content.](http://arxiv.org/abs/2309.11830) | 这个论文介绍了一个用于LLMs的中文Prompt Attack数据集，该数据集旨在评估防御提示攻击的能力。 |
| [^42] | [Word Embedding with Neural Probabilistic Prior.](http://arxiv.org/abs/2309.11824) | 提出了一种可以与词嵌入模型无缝集成的神经概率先验，能够增强嵌入向量的表示，提高模型的鲁棒性和稳定性，实验证明了该方法在各种任务上提高了词表示。 |
| [^43] | [SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features.](http://arxiv.org/abs/2309.11791) | 这项研究提出了一种方法，通过结合知识图谱的结构信息和本体类名的语义和词汇特征，将Wikipedia的分类和列表映射到DBpedia，以构建一个完善和细粒度的知识图谱。 |
| [^44] | [ContextRef: Evaluating Referenceless Metrics For Image Description Generation.](http://arxiv.org/abs/2309.11710) | 本文介绍了ContextRef，用于评估图像描述生成的无参考度量。ContextRef包括人类评分和鲁棒性检查，同时考虑了上下文，通过精心微调可以取得实质性改善。 |
| [^45] | [Memory-Augmented LLM Personalization with Short- and Long-Term Memory Coordination.](http://arxiv.org/abs/2309.11696) | 本研究提出了一种计算仿生记忆机制，配备了参数高效的微调模式，用于个性化LLMs。实验证明了该方法的有效性和可行性。 |
| [^46] | [Semi-supervised News Discourse Profiling with Contrastive Learning.](http://arxiv.org/abs/2309.11692) | 本文提出了一种使用对比学习的半监督新闻话语特征提取方法，通过利用新闻文章的结构特点来解决注释数据不足的问题，并在评估中证明了该方法的有效性。 |
| [^47] | [LLM Guided Inductive Inference for Solving Compositional Problems.](http://arxiv.org/abs/2309.11688) | LLM引导的归纳推理方法REBEL通过递归问题分解和利用外部工具进行推理，能够解决组合问题和对话环境中的深度推理任务。 |
| [^48] | [A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models.](http://arxiv.org/abs/2309.11674) | 本论文提出了一种基于先进语言模型的翻译器(ALMA)的微调方法，可以提升大型语言模型在翻译任务上的性能，消除了对大量平行数据的依赖。 |
| [^49] | [Construction of Paired Knowledge Graph-Text Datasets Informed by Cyclic Evaluation.](http://arxiv.org/abs/2309.11669) | 本文通过循环评估验证了训练在等价性较差的数据集上的模型可能导致更多虚构和更差召回的问题。在此基础上，提出了一个改进的数据集LAGRANGE，使用启发式方法提高KG和文本之间的等价性。 |
| [^50] | [Towards Effective Disambiguation for Machine Translation with Large Language Models.](http://arxiv.org/abs/2309.11668) | 本文研究了大型语言模型(LLMs)在翻译歧义句子方面的能力，并通过上下文学习和歧义数据集微调提出了改进处理歧义的方法。实验证明，这些方法在多个语言方向上有着与最先进系统相当甚至超越的表现。这些研究为机器翻译的有效消歧提供了宝贵的见解。 |
| [^51] | [Hate speech detection in algerian dialect using deep learning.](http://arxiv.org/abs/2309.11611) | 本研究提出了一个完整的方法，通过深度学习来检测在线阿尔及利亚信息中的仇恨言论。通过对阿尔及利亚社交网络上的语料库进行评估，我们获得了令人鼓舞的结果。 |
| [^52] | [SpeechAlign: a Framework for Speech Translation Alignment Evaluation.](http://arxiv.org/abs/2309.11585) | SpeechAlign是一个用于评估语音模型中源目标对齐的框架，通过引入新的数据集和指标，为模型评估提供了一个可访问的评估框架，并且用于基准测试开源的语音翻译模型。 |
| [^53] | [Incorporating Singletons and Mention-based Features in Coreference Resolution via Multi-task Learning for Better Generalization.](http://arxiv.org/abs/2309.11582) | 本文通过多任务学习的方法，将单例和基于提及的特征纳入共指消解中，从而提高了泛化能力。模型在OntoGUM基准测试中取得了新的最高分，并在多个领域外数据集上增强了鲁棒性。 |
| [^54] | [Examining the Limitations of Computational Rumor Detection Models Trained on Static Datasets.](http://arxiv.org/abs/2309.11576) | 本文通过深入评估基于内容和基于上下文模型在检测新的未知谣言上的性能差距，发现基于上下文的模型过度依赖来源帖子信息并忽略了上下文信息的重要作用。实验结果也提出了减小时间概念影响的实际建议。 |
| [^55] | [BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model.](http://arxiv.org/abs/2309.11568) | BTLM-3B-8K是一个30亿参数的开源语言模型，相对于其他30亿和70亿参数模型，它在下游任务中表现出2-5.5%的性能提升，同时在长文本任务上也具有出色的表现。这种将70亿参数的模型压缩到30亿参数，并且性能几乎没有受到影响的方法具有重要意义。 |
| [^56] | [SignBank+: Multilingual Sign Language Translation Dataset.](http://arxiv.org/abs/2309.11566) | 该论文介绍了SignBank+，这是一个经过优化的手语翻译数据集，通过简化文本对文本翻译方法，提升了手语机器翻译模型的性能，并为未来的研究提供了一个开放的资源。 |
| [^57] | [Hierarchical reinforcement learning with natural language subgoals.](http://arxiv.org/abs/2309.11564) | 本文介绍了一种层次强化学习的新方法，使用来自人类解决任务的数据来监督一组长程任务的目标空间，并使用自然语言来描述这个空间，该方法在克隆专家行为的代理和无监督子目标空间的层次强化学习中表现出色。 |
| [^58] | [Towards LLM-based Autograding for Short Textual Answers.](http://arxiv.org/abs/2309.11508) | 本文评估了大型语言模型（LLMs）在自动评分中的应用，并强调了它们如何支持教育工作者验证评分程序。研究结果表明，“开箱即用”的LLMs作为补充视角提供了有价值的工具，但仍需进一步优化其可用性和性能。 |
| [^59] | [Matching Table Metadata with Business Glossaries Using Large Language Models.](http://arxiv.org/abs/2309.11506) | 本研究探讨了将表元数据与业务词汇进行匹配的问题，通过匹配可以在不请求访问数据内容之前或之后，有效利用可用的业务词汇进行检索和分析。 |
| [^60] | [Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning.](http://arxiv.org/abs/2309.11489) | Text2Reward是一个无需数据的自动化框架，可以根据大型语言模型自动生成可解释、自由形式的密集奖励函数，广泛适用于各种任务，并允许人类反馈进行迭代改进。 |
| [^61] | [You Only Look at Screens: Multimodal Chain-of-Action Agents.](http://arxiv.org/abs/2309.11436) | 本论文提出了一种名为Auto-UI的多模态动作链机器人，通过直接与界面交互，避免了环境解析或依赖于应用程序API的需要，并引入了动作链技术来帮助模型进行决策。 |
| [^62] | [Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering.](http://arxiv.org/abs/2309.11206) | 提出了一种提高知识图谱问答任务性能的增强型LLMs框架，通过转化KG知识为文本化陈述的方式，实现了对答案敏感的KG-to-Text方法。 |
| [^63] | [Fake News BR: A Fake News Detection Platform for Brazilian Portuguese.](http://arxiv.org/abs/2309.11052) | 本研究提出了一个用于巴西葡萄牙语的假新闻检测平台，采用机器学习和自然语言处理技术，能够高效准确地识别假新闻，同时提供实时分析和验证新闻文章真实性的用户友好平台。 |
| [^64] | [Localize, Retrieve and Fuse: A Generalized Framework for Free-Form Question Answering over Tables.](http://arxiv.org/abs/2309.11049) | 本文提出了一个广义框架，用于处理表格上的自由形式问答，在选取相关的表格单元、检索外部知识、以及推理集成时面临的挑战进行了探索。 |
| [^65] | [What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples.](http://arxiv.org/abs/2309.10916) | 本文将图像处理领域中的对抗子空间技术应用于自然语言处理，提出了基于最近邻和影响函数的检测器，并通过使用影响函数揭示了自然语言处理中的对抗样本子空间与图像处理中的子空间的关系和任务差异。 |
| [^66] | [L1-aware Multilingual Mispronunciation Detection Framework.](http://arxiv.org/abs/2309.07719) | 本文介绍了一种L1感知的多语言发音错误检测框架，该框架通过注意力机制对齐输入音频和参考音素序列，并将预训练的辅助模型提取的L1-L2语音嵌入与主要网络进行融合。该框架在英文、阿拉伯语和普通话上的统一多语言音素识别任务中取得了良好的效果。 |
| [^67] | [CPPF: A contextual and post-processing-free model for automatic speech recognition.](http://arxiv.org/abs/2309.07413) | CPPF是一种上下文和后处理无关的自动语音识别模型，它整合了多个与语音识别相关的ASR文本处理任务，提供了一种优化流程、避免级联错误传播且识别性能几乎没有损失的解决方案。 |
| [^68] | [ConDA: Contrastive Domain Adaptation for AI-generated Text Detection.](http://arxiv.org/abs/2309.03992) | 创新点：提出了一种基于对比域适应的框架 ConDA，用于检测由大型语言模型生成的新闻文本。这种方法解决了获取标记训练数据的困难，通过利用未标记的目标数据进行无监督域适应。 |
| [^69] | [Empowering Refugee Claimants and their Lawyers: Using Machine Learning to Examine Decision-Making in Refugee Law.](http://arxiv.org/abs/2308.11531) | 这项研究的目标是通过使用机器学习来提高难民法决策的智能化和透明度，实现更好的决策结果。研究涉及检索过去的案例和分析加拿大案例数据集的法律决策流程。通过基于自然语言处理的解决方案和新的基准，研究希望为所有相关利益相关者带来包容性和预期的好处。 |
| [^70] | [LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete Information from Lateral Thinking Puzzles.](http://arxiv.org/abs/2308.10855) | LatEval是一个新颖的LLMs评估基准，通过侧思维谜题挑战模型的横向思考能力，在交互过程中考验模型提出问题的质量和整合信息解决问题的能力。研究发现，几乎所有LLMs在横向思考方面存在困难，即使是最先进的GPT-4模型相比人类也有明显差距。这个基准测试对于有效的AI助理至关重要。 |
| [^71] | [Instruction Tuning for Large Language Models: A Survey.](http://arxiv.org/abs/2308.10792) | 本文调查了指令调优这一关键技术在增强大型语言模型能力和可控性方面的研究工作，包括方法、数据集构建、模型训练和应用，以及对结果影响的分析。同时回顾了可能的问题和批评，并指出了目前的不足。 |
| [^72] | [Scope is all you need: Transforming LLMs for HPC Code.](http://arxiv.org/abs/2308.09440) | 本研究旨在质疑现有大型语言模型（LLMs）在高性能计算（HPC）领域中的应用，并通过开发针对特定领域的小型LLMs来解决该问题。具体而言，我们为HPC开发了一种名为Tokompiler的新型标记器，用于代码预处理和编译任务。 |
| [^73] | [Turning Whisper into Real-Time Transcription System.](http://arxiv.org/abs/2307.14743) | 本文介绍了一个基于Whisper的实时语音转录和翻译系统Whisper-Streaming，通过使用本地协议策略和自适应延迟，实现了流式转录。实验结果表明Whisper-Streaming在未分割的长篇演讲转录测试集上具有高质量和低延迟，并且在实际多语种会议中的应用也具有鲁棒性和实用性。 |
| [^74] | [Can large language models generate salient negative statements?.](http://arxiv.org/abs/2305.16755) | 本研究探讨了大型语言模型生成真实实体的显著负面陈述的能力，在不同领域中进行了评估，结果发现大型语言模型在处理否定陈述中的事实概念上仍有困难。 |
| [^75] | [Navigating Prompt Complexity for Zero-Shot Classification: A Study of Large Language Models in Computational Social Science.](http://arxiv.org/abs/2305.14310) | 本研究通过评估两个大型语言模型在六个计算社会科学分类任务中的零样本性能，并研究了各种提示策略的影响。结果显示，当前的大型语言模型在零样本设置下无法与较小的微调基线模型相媲美。 |
| [^76] | [The Impact of Incumbent/Opposition Status and Ideological Similitude on Emotions in Political Manifestos.](http://arxiv.org/abs/2305.08383) | 本研究分析了英国保守党和工党大选宣言中的情感语言，并发现现任党派更倾向于使用积极情感词汇，而反对派党派更倾向于使用负面情感词汇。同时，意识形态相似的党派也更多地使用积极语言。 |
| [^77] | [ERNIE-Music: Text-to-Waveform Music Generation with Diffusion Models.](http://arxiv.org/abs/2302.04456) | 本文提出了ERNIE-Music，一种基于扩散模型的文本到波形音乐生成模型。通过创新地利用自由形式的文本提示作为条件因素，我们成功实现了从文本到音乐波形的生成。通过利用网络资源构建数据集并采用弱监督技术，我们解决了有限的文本-音乐平行数据的挑战。我们还对比了两种不同的文本条件格式的有效性，为该领域的研究提供了实证结果。 |
| [^78] | [Faithful Chain-of-Thought Reasoning.](http://arxiv.org/abs/2301.13379) | 这篇论文提出了一种忠实的推理链思考框架，通过翻译和问题求解两个阶段，确保推理链能忠实解释最终答案。它在复杂推理任务上的性能得到了提升，并在多个基准测试上超过了标准的推理链方法。 |
| [^79] | [Survey of Aspect-based Sentiment Analysis Datasets.](http://arxiv.org/abs/2204.05232) | 本研究汇总了65个公开可用的ABSA数据集，包括45个英文数据集和20个其他语言数据集，提供了一个可以用于训练和评估自主ABSA系统的数据库。 |
| [^80] | [Grammatical cues to subjecthood are redundant in a majority of simple clauses across languages.](http://arxiv.org/abs/2201.12911) | 借助语法线索来确定句子的主语在大多数简单从句中是多余的，这个冗余性在跨语言中也存在。在这项研究中，通过行为实验和计算分析，我们发现这种冗余性的发生频率很高，这有助于揭示语法的功能和演化。 |

# 详细

[^1]: LLM-Grounder: 利用大型语言模型作为代理的开放词汇3D视觉定位

    LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent. (arXiv:2309.12311v1 [cs.CV])

    [http://arxiv.org/abs/2309.12311](http://arxiv.org/abs/2309.12311)

    LLM-Grounder是一种零样本、开放词汇的基于大型语言模型的3D视觉定位流程，通过利用语言模型分解查询并使用视觉定位工具识别物体，实现了在没有标记训练数据的情况下对新场景和文本查询的有效定位。在ScanRefer基准上取得了最先进的零样本定位准确性。

    

    3D视觉定位是家用机器人的重要能力，可以使其在环境中导航、操作物体并根据环境回答问题。现有的方法通常依赖于大量标记的数据，或者在处理复杂语言查询时存在一定限制。我们提出了LLM-Grounder，一种新颖的零样本、开放词汇的基于大型语言模型的3D视觉定位流程。LLM-Grounder利用一个LLM将复杂的自然语言查询分解为语义成分，并使用诸如OpenScene或LERF之类的视觉定位工具来识别3D场景中的物体。然后，LLM评估所提出的物体之间的空间和常识关系，以做出最终的定位决策。我们的方法不需要任何标记的训练数据，并且可以推广到新的3D场景和任意文本查询。我们在ScanRefer基准上评估了LLM-Grounder，并展示了最先进的零样本定位准确性。我们的研究结果表明LLMs在3D视觉定位中的有效性。

    3D visual grounding is a critical skill for household robots, enabling them to navigate, manipulate objects, and answer questions based on their environment. While existing approaches often rely on extensive labeled data or exhibit limitations in handling complex language queries, we propose LLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model (LLM)-based 3D visual grounding pipeline. LLM-Grounder utilizes an LLM to decompose complex natural language queries into semantic constituents and employs a visual grounding tool, such as OpenScene or LERF, to identify objects in a 3D scene. The LLM then evaluates the spatial and commonsense relations among the proposed objects to make a final grounding decision. Our method does not require any labeled training data and can generalize to novel 3D scenes and arbitrary text queries. We evaluate LLM-Grounder on the ScanRefer benchmark and demonstrate state-of-the-art zero-shot grounding accuracy. Our findings indicate that LLMs si
    
[^2]: 演练：通过模拟冲突来教授冲突解决方法

    Rehearsal: Simulating Conflict to Teach Conflict Resolution. (arXiv:2309.12309v1 [cs.HC])

    [http://arxiv.org/abs/2309.12309](http://arxiv.org/abs/2309.12309)

    演练是一个系统，通过模拟冲突和提供反馈，教授用户冲突解决的技能。利用演练，用户可以练习处理各种冲突场景，并学习如何运用冲突策略。

    

    人际冲突是一种令人不舒服但不可避免的生活事实。成功地处理冲突是一种技能，可以通过刻意练习来学习，但是很少有人能够获得有效的培训或反馈。为了扩大这种机会，我们介绍了演练（Rehearsal）系统，该系统允许用户与可信的模拟对话者一起排练冲突，探索如果情况如何的“假设”场景以识别替代的对话路径，并通过反馈学习何时以及如何应用特定的冲突策略。用户可以使用演练来练习处理各种已定义的冲突场景，从办公室争议到情感问题，或者他们也可以选择创建自己的冲突场景。为了实现演练，我们开发了IRP提示方法，该方法通过冲突解决中具有影响力的利益-权力-能力（IRP）理论来调节大型语言模型的输出。演练使用IRP生成基于冲突解决理论的话语，引导用户实践应用冲突解决策略。

    Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users t
    
[^3]: LongLoRA: 高效的长上下文大型语言模型的精细调整

    LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models. (arXiv:2309.12307v1 [cs.CL])

    [http://arxiv.org/abs/2309.12307](http://arxiv.org/abs/2309.12307)

    LongLoRA是一种高效的精细调整方法，可以在有限的计算成本下扩展预训练的大型语言模型的上下文大小。它通过稀疏的局部注意力实现精细调整，并使用移动短注意力有效实现上下文扩展，与传统方法具有相似的性能。

    

    我们提出了一种高效的精细调整方法——LongLoRA，可以在有限的计算成本下扩展预训练的大型语言模型(LLM)的上下文大小。通常，使用长上下文大小训练LLM的计算成本很高，需要大量的训练时间和GPU资源。本文中，我们在两个方面加快了LLM的上下文扩展。一方面，尽管推理过程中需要稠密的全局注意力，但模型的精细调整可以通过稀疏的局部注意力有效且高效地完成。所提出的移动短注意力有效地实现了上下文的扩展，在与使用传统注意力进行精细调整时具有相似的性能，同时可以在训练中只用两行代码实现，在推理中是可选的。另一方面，我们重新审视了参数效率问题。

    We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost. Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-effici
    
[^4]: 大型语言模型在从逻辑形式中生成自然语言方面的重新排序研究

    Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models. (arXiv:2309.12294v1 [cs.CL])

    [http://arxiv.org/abs/2309.12294](http://arxiv.org/abs/2309.12294)

    本研究提出了一种新颖的生成和重新排序方法，用于解决大型语言模型在从逻辑形式中生成自然语言方面的质量不一致问题。通过对候选输出进行重新排序，我们的方法能够更好地体现逻辑形式的语义，并提升生成结果的质量。

    

    大型语言模型（LLMs）在自然语言生成方面展现出了引人注目的能力。然而，它们的输出质量不一致，给从逻辑形式（LFs）生成自然语言带来了挑战。这个任务要求生成的输出体现LFs的确切语义，不遗漏任何LF语义或产生任何幻象。在这项工作中，我们通过提出一种新颖的生成和重新排序方法来解决这个问题。我们的方法涉及通过提示LLM初始化生成一组候选输出，然后使用特定任务的重新排序模型对它们进行重新排序。此外，我们创建了一个手动收集的数据集，用于评估不同排序指标与人类判断之间的一致性。所选择的排序指标被用于增强重新排序模型的训练和评估。通过对三个不同数据集进行广泛的实验，我们证明了我们的重新排序模型选择的候选项优于那些选项.

    Large language models (LLMs) have demonstrated impressive capabilities in natural language generation. However, their output quality can be inconsistent, posing challenges for generating natural language from logical forms (LFs). This task requires the generated outputs to embody the exact semantics of LFs, without missing any LF semantics or creating any hallucinations. In this work, we tackle this issue by proposing a novel generate-and-rerank approach. Our approach involves initially generating a set of candidate outputs by prompting an LLM and subsequently reranking them using a task-specific reranker model. In addition, we curate a manually collected dataset to evaluate the alignment between different ranking metrics and human judgements. The chosen ranking metrics are utilized to enhance the training and evaluation of the reranker model. By conducting extensive experiments on three diverse datasets, we demonstrate that the candidates selected by our reranker outperform those sele
    
[^5]: 翻转诅咒: 在大型语言模型中训练的"A是B"无法学习"B是A"

    The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A". (arXiv:2309.12288v1 [cs.CL])

    [http://arxiv.org/abs/2309.12288](http://arxiv.org/abs/2309.12288)

    LLMs模型在训练中只能学习到"A是B"的结构，无法自动推广到"B是A"。这表明模型在逻辑推断上存在基本失败和训练集中模式的推广问题。

    

    我们揭示了自回归大型语言模型（LLM）在泛化上的令人惊讶的失败。如果一个模型是基于"A是B"形式的句子进行训练，它不会自动推广到相反的方向"B是A"。这就是翻转诅咒。例如，如果一个模型是基于"Olaf Scholz是德国第九任总理"进行训练的，它不会自动能够回答问题"谁是德国第九任总理？"。此外，正确答案（"Olaf Scholz"）的可能性不会比随机名字更高。因此，模型在逻辑推断上存在基本失败，并且不会推广到它们训练集中的普遍模式（即如果出现"A是B"，则"B是A"更可能出现）。我们通过在虚构的陈述（如"Uriah Hawthorne是'Abyssal Melodies'的作曲家"）上对GPT-3和Llama-1进行微调，并展示它们无法正确回答"谁创作了'Abyssal Melodies'?"来提供翻转诅咒的证据。

    We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form "A is B", it will not automatically generalize to the reverse direction "B is A". This is the Reversal Curse. For instance, if a model is trained on "Olaf Scholz was the ninth Chancellor of Germany", it will not automatically be able to answer the question, "Who was the ninth Chancellor of Germany?". Moreover, the likelihood of the correct answer ("Olaf Scholz") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if "A is B'' occurs, "B is A" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as "Uriah Hawthorne is the composer of 'Abyssal Melodies'" and showing that they fail to correctly answer "Who composed 'Abyssal Melodies?'". The Reversal Cu
    
[^6]: MetaMath：为大型语言模型创建自己的数学问题

    MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models. (arXiv:2309.12284v1 [cs.CL])

    [http://arxiv.org/abs/2309.12284](http://arxiv.org/abs/2309.12284)

    MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。

    

    大型语言模型（LLMs）推动了自然语言理解的极限，并展示了出色的问题解决能力。尽管取得了巨大的成功，但大多数现有的开源LLMs（例如LLaMA-2）在解决数学问题方面仍然远远不够令人满意，原因是复杂的推理过程。为了弥合这一鸿沟，我们提出了MetaMath，一种专门用于数学推理的微调语言模型。具体而言，我们通过在没有额外知识的情况下以多个角度重新写入问题来引导数学问题，从而产生了一个名为MetaMathQA的新数据集。然后我们在MetaMathQA上对LLaMA-2模型进行了微调。对于数学推理的两个流行基准测试（即GSM8K和MATH），实验结果表明MetaMath在性能上明显优于一套开源LLMs。我们的MetaMath-7B模型在GSM8K上达到了66.4％，在MATH上达到了19.4％，超过了相同规模的最先进模型。

    Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\%$ on GSM8K and $19.4\%$ on MATH, exceeding the state-of-the-art models of the same size by 
    
[^7]: 通过外部知识激发大型语言模型在生物医学命名实体识别中的应用

    Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition. (arXiv:2309.12278v1 [cs.CL])

    [http://arxiv.org/abs/2309.12278](http://arxiv.org/abs/2309.12278)

    本文提出了一种通过外部知识激发大型语言模型在生物医学命名实体识别中的应用方法，通过分解NER任务为实体跨度提取和实体类型确定两步骤，并引入领域知识来增强实体类别确定性能，取得了显著的改进。

    

    大型语言模型在许多自然语言处理任务中表现出优越的性能，尤其是在生成性任务方面。然而，在一些信息提取任务中，它们往往表现不佳，特别是那些需要领域特定知识的任务，如生物医学命名实体识别。本文受到思维链的启发，我们将大型语言模型应用于生物医学命名实体识别中，通过分解NER任务为实体跨度提取和实体类型确定两步骤来解决。此外，为了解决大型语言模型在预测实体类别时缺乏领域知识的问题，我们引入了实体知识。实验结果显示，与之前的少样本大型语言模型基准相比，我们的两步骤BioNER方法取得了显著的改进。此外，外部知识的整合显著提高了实体类型确定的性能。

    Large language models (LLMs) have demonstrated dominating performance in many NLP tasks, especially on generative tasks. However, they often fall short in some information extraction tasks, particularly those requiring domain-specific knowledge, such as Biomedical Named Entity Recognition (NER). In this paper, inspired by Chain-of-thought, we leverage the LLM to solve the Biomedical NER step-by-step: break down the NER task into entity span extraction and entity type determination. Additionally, for entity type determination, we inject entity knowledge to address the problem that LLM's lack of domain knowledge when predicting entity category. Experimental results show a significant improvement in our two-step BioNER approach compared to previous few-shot LLM baseline. Additionally, the incorporation of external knowledge significantly enhances entity category determination performance.
    
[^8]: LLMR：使用大型语言模型实时提示交互式世界的框架

    LLMR: Real-time Prompting of Interactive Worlds using Large Language Models. (arXiv:2309.12276v1 [cs.HC])

    [http://arxiv.org/abs/2309.12276](http://arxiv.org/abs/2309.12276)

    LLMR是一个用于实时创建和修改交互式混合现实体验的框架，通过利用大型语言模型和新颖的策略，它能够解决训练数据稀缺和设计目标复杂的问题，并在性能上超过标准的GPT-4。我们展示了LLMR的跨平台互操作性，并通过评估和用户研究证明了其对于生成和编辑各种对象、工具和场景的能力。

    

    我们提出了用于混合现实场景的大型语言模型(LLMR)，这是一个框架，用于实时创建和修改交互式混合现实体验。LLMR利用了新颖的策略来解决训练数据稀缺或设计目标需要合成内部动态、直观分析或高级交互的困难情况。我们的框架依赖于文本交互和Unity游戏引擎。通过融合场景理解、任务规划、自我调试和内存管理技术，LLMR在平均错误率上比标准的GPT-4提高了4倍。我们展示了LLMR与几个示例世界的跨平台互操作性，并通过多个创建和修改任务对其进行了评估，以展示它能够生成和编辑各种对象、工具和场景。最后，我们进行了一个有多样性的可用性研究（N=11），揭示了参与者对该系统有积极的体验，并愿意再次使用它。

    We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.
    
[^9]: 通过自适应的NLP模型选择和基于临床专家规则的分类器改进VTE的识别

    Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports. (arXiv:2309.12273v1 [cs.CL])

    [http://arxiv.org/abs/2309.12273](http://arxiv.org/abs/2309.12273)

    通过自适应的NLP模型选择和临床专家规则的分类器，该研究提出一种改进VTE识别的新方法，在放射学报告中准确识别VTE事件的准确性得到提高。

    

    快速准确地识别静脉血栓栓塞（VTE），包括深静脉血栓（DVT）和肺栓塞（PE），对于有效治疗非常重要。利用自然语言处理（NLP）在放射学报告中，自动化方法已经在从回顾性数据集中识别VTE事件或帮助临床专家识别放射学报告中的VTE事件方面展示了有希望的进展。然而，由于标记有限的医学文本数据、放射学报告的复杂性和异质性以及数据不平衡，有效训练深度学习（DL）和NLP模型存在挑战。本研究提出了DL方法的新的组合方法，结合数据增强、自适应预训练的NLP模型选择和临床专家NLP基于规则的分类器，以提高非结构化（自由文本）放射学报告中VTE识别的准确性。我们的实验结果证明了该模型的有效性。

    Rapid and accurate identification of Venous thromboembolism (VTE), a severe cardiovascular condition including deep vein thrombosis (DVT) and pulmonary embolism (PE), is important for effective treatment. Leveraging Natural Language Processing (NLP) on radiology reports, automated methods have shown promising advancements in identifying VTE events from retrospective data cohorts or aiding clinical experts in identifying VTE events from radiology reports. However, effectively training Deep Learning (DL) and the NLP models is challenging due to limited labeled medical text data, the complexity and heterogeneity of radiology reports, and data imbalance. This study proposes novel method combinations of DL methods, along with data augmentation, adaptive pre-trained NLP model selection, and a clinical expert NLP rule-based classifier, to improve the accuracy of VTE identification in unstructured (free-text) radiology reports. Our experimental results demonstrate the model's efficacy, achievi
    
[^10]: 剑桥法律语料库：用于法律人工智能研究的语料库

    The Cambridge Law Corpus: A Corpus for Legal AI Research. (arXiv:2309.12269v1 [cs.CL])

    [http://arxiv.org/abs/2309.12269](http://arxiv.org/abs/2309.12269)

    剑桥法律语料库是一个用于法律人工智能研究的语料库，包含来自英国的超过250,000个法庭案例。在该语料库的基础上，我们提供了案例结果的专家注解，并使用多个模型进行了案例结果提取的训练和评估，为研究提供了基准。

    

    我们介绍了剑桥法律语料库（CLC），这是一个用于法律人工智能研究的语料库。它包含了来自英国的超过250,000个法庭案例。大部分案例来自21世纪，但该语料库包括了16世纪以来的案例。本文介绍了该语料库的首次发布，包括原始文本和元数据。在语料库的基础上，我们提供了638个案例的法律专家对案例结果的注解。我们使用我们的标注数据，训练和评估了GPT-3、GPT-4和RoBERTa模型进行案例结果提取，以提供基准。我们还进行了广泛的法律和伦理讨论，以解决这些材料可能具有敏感性的问题。因此，该语料库只会在一定限制下用于研究目的。

    We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.
    
[^11]: 关于技能神经元与Prompt Tuning中的鲁棒性的关系研究

    On the Relationship between Skill Neurons and Robustness in Prompt Tuning. (arXiv:2309.12263v1 [cs.CL])

    [http://arxiv.org/abs/2309.12263](http://arxiv.org/abs/2309.12263)

    本文研究了Prompt Tuning在与"技能神经元"的关系中的鲁棒性，发现特定任务的调整指令在相同类型的任务上具有传递性，但对于对抗性数据的鲁棒性不高，其中T5的鲁棒性比RoBERTa更高，并且发现T5和RoBERTa中都存在技能神经元。

    

    Prompt Tuning是一种用于预训练大型语言模型(PLMs)的参数高效微调方法。最近，通过对RoBERTa的实验，有人认为Prompt Tuning激活了Transformer前馈网络中特定的神经元，这些神经元对给定任务具有高预测能力和选择性。本文中，我们使用RoBERTa和T5来研究Prompt Tuning与这些“技能神经元”的鲁棒性关系。我们发现特定任务的调整指令在相同类型的任务上具有传递性，但对于对抗性数据的鲁棒性不高，其中T5的鲁棒性比RoBERTa更高。同时，我们重现了RoBERTa中的技能神经元存在，并进一步展示了T5中也存在技能神经元。有趣的是，T5在非对抗性数据上确定的技能神经元也是对抗性数据上预测性最强的神经元，而这在RoBERTa中不是这种情况。我们得出结论，更高的对抗鲁棒性可能与技能神经元的存在相关。

    Prompt Tuning is a popular parameter-efficient finetuning method for pre-trained large language models (PLMs). Recently, based on experiments with RoBERTa, it has been suggested that Prompt Tuning activates specific neurons in the transformer's feed-forward networks, that are highly predictive and selective for the given task. In this paper, we study the robustness of Prompt Tuning in relation to these "skill neurons", using RoBERTa and T5. We show that prompts tuned for a specific task are transferable to tasks of the same type but are not very robust to adversarial data, with higher robustness for T5 than RoBERTa. At the same time, we replicate the existence of skill neurons in RoBERTa and further show that skill neurons also seem to exist in T5. Interestingly, the skill neurons of T5 determined on non-adversarial data are also among the most predictive neurons on the adversarial data, which is not the case for RoBERTa. We conclude that higher adversarial robustness may be related to
    
[^12]: SQUARE: 使用多个正负参考答案自动评估问答系统

    SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References. (arXiv:2309.12250v1 [cs.CL])

    [http://arxiv.org/abs/2309.12250](http://arxiv.org/abs/2309.12250)

    提出了一种新的问答系统评估指标SQuArE，使用多个参考答案进行句子级问答评估，实现了高度相关性的评估结果。

    

    问答系统的评估是非常具有挑战性和昂贵的，最可靠的方法是通过人工标注问题的答案的正确性。最近的研究表明，基于Transformer LM编码器的相似性度量在问答评估中具有良好的迁移性，但它们的使用受限于单个正确参考答案。我们提出了一种新的评估指标：SQuArE（句子级问答评估），使用多个参考答案（组合多个正确和错误的参考答案）进行句子形式的问答评估。我们在句子级提取式（答案选择）和生成式（GenQA）问答系统上评估了SQuArE，在多个学术和工业数据集上，结果表明它优于先前的基准，并与人工标注具有最高的相关性。

    Evaluation of QA systems is very challenging and expensive, with the most reliable approach being human annotations of correctness of answers for questions. Recent works (AVA, BEM) have shown that transformer LM encoder based similarity metrics transfer well for QA evaluation, but they are limited by the usage of a single correct reference answer. We propose a new evaluation metric: SQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference answers (combining multiple correct and incorrect references) for sentence-form QA. We evaluate SQuArE on both sentence-level extractive (Answer Selection) and generative (GenQA) QA systems, across multiple academic and industrial datasets, and show that it outperforms previous baselines and obtains the highest correlation with human annotations.
    
[^13]: 坏角色好顾问：探索大型语言模型在假新闻检测中的作用

    Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. (arXiv:2309.12247v1 [cs.CL])

    [http://arxiv.org/abs/2309.12247](http://arxiv.org/abs/2309.12247)

    大型语言模型对于假新闻检测的潜力仍未得到充分探索。实证研究发现，尽管复杂的大型语言模型能够揭示假新闻并提供多角度解释，但仍不如经过fine-tuned的小型语言模型表现出色。当前的大型语言模型可能无法取代小型语言模型，但可以作为一个良好的辅助顾问。

    

    检测假新闻需要对多样线索有敏锐的感知和对现实世界背景有深入的理解，对于基于小型语言模型的检测器来说，由于其知识和能力的限制，这仍然是具有挑战性的。近期大型语言模型的进步在各种任务中表现出了卓越的性能，但大型语言模型能否以及如何帮助假新闻检测仍然未经过深入研究。在本文中，我们研究了大型语言模型在假新闻检测中的潜力。首先，我们进行了实证研究，发现像GPT 3.5这样的复杂大型语言模型通常能够揭示假新闻并提供理想的多角度解释，但仍然不如基础小型语言模型fine-tuned BERT表现出色。我们随后的分析将这种差距归因于大型语言模型不能正确选择并整合证据以得出结论。基于这些发现，我们提出当前的大型语言模型可能无法取代在假新闻检测中经过fine-tuned的小型语言模型，但可以作为一个良好的辅助顾问。

    Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good a
    
[^14]: ChaCha：利用大型语言模型引导儿童分享与个人事件相关的情绪

    ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events. (arXiv:2309.12244v1 [cs.HC])

    [http://arxiv.org/abs/2309.12244](http://arxiv.org/abs/2309.12244)

    ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。

    

    儿童通常通过与家人或他人分享故事和感受来学习辨识和表达情绪，然而，由于儿童正在发展他们的交流技能，父母或兄弟姐妹很难与他们进行情感沟通。本文介绍了ChaCha，一个鼓励和引导儿童分享个人事件和相关情绪的聊天机器人。ChaCha结合了状态机和大型语言模型（LLMs），在进行自由对话的同时保持对话的方向性。通过与20名年龄在8-12岁的儿童进行的探索性研究，我们研究了ChaCha如何促使儿童分享个人事件并引导他们描述相关情绪。参与者认为ChaCha就像一个亲密的朋友，并分享了各种主题的故事，如家庭旅行和个人成就。基于定量和定性发现，我们讨论了利用LLMs设计适合儿童的聊天机器人的机遇。

    Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to
    
[^15]: 桥接模态和语言差距：同步双语CTC用于语音翻译和语音识别

    Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition. (arXiv:2309.12234v1 [cs.CL])

    [http://arxiv.org/abs/2309.12234](http://arxiv.org/abs/2309.12234)

    本研究提出了一种同步双语CTC框架，用于桥接语音翻译任务中的模态和语言差距，并在资源有限情况下取得了state-of-the-art表现。同时，该方法还在语音识别性能上展示了显著的提升。

    

    本研究提出了同步双语CTC，这是一种创新的框架，利用双重CTC来弥合语音翻译任务中模态和语言之间的差距。通过将转写和翻译作为CTC的并行目标，我们的模型桥接了音频和文本之间的差距，以及源语言和目标语言之间的差距。在CTC应用的最新进展基础上，我们开发了一种改进的变体BiL-CTC+，在资源受限的场景下在MuST-C语音翻译基准测试中取得了新的最佳表现。有趣的是，我们的方法在语音识别性能上也取得了显著的提升，揭示了跨语言学习对转录的影响并展示了其广泛的适用性。

    In this study, we present synchronous bilingual Connectionist Temporal Classification (CTC), an innovative framework that leverages dual CTC to bridge the gaps of both modality and language in the speech translation (ST) task. Utilizing transcript and translation as concurrent objectives for CTC, our model bridges the gap between audio and text as well as between source and target languages. Building upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios. Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability. The source code is available at https://github.com/xuchennlp/S2T.
    
[^16]: 从医学视频中回答健康相关问题：数据集和方法

    Towards Answering Health-related Questions from Medical Videos: Datasets and Approaches. (arXiv:2309.12224v1 [cs.CL])

    [http://arxiv.org/abs/2309.12224](http://arxiv.org/abs/2309.12224)

    本文旨在通过提供医学视频中的视觉答案来回答公众提出的健康相关问题，其中关键挑战是医学领域缺乏大规模数据集。我们提出了两个大规模数据集，并使用单模态和多模态方法有效地提供视觉答案。

    

    在线视频的增加改变了我们获取信息和知识的方式。越来越多的人现在喜欢使用教学视频，因为它们提供了一系列逐步操作的步骤来完成特定任务。医学领域的教学视频可能提供了关于急救、医疗急症和医学教育问题的最佳视觉答案。本文旨在通过提供医学视频中的视觉答案来回答公众提出的健康相关问题。医学领域缺乏大规模数据集是阻碍开发能够帮助公众解答健康相关问题的应用的关键挑战。为了解决这个问题，我们首先提出了一个流水线方法来创建两个大规模数据集：HealthVidQA-CRF和HealthVidQA-Prompt。接下来，我们提出了单模态和多模态方法，可以有效地从医学视频中提供视觉答案。

    The increase in the availability of online videos has transformed the way we access information and knowledge. A growing number of individuals now prefer instructional videos as they offer a series of step-by-step procedures to accomplish particular tasks. The instructional videos from the medical domain may provide the best possible visual answers to first aid, medical emergency, and medical education questions. Toward this, this paper is focused on answering health-related questions asked by the public by providing visual answers from medical videos. The scarcity of large-scale datasets in the medical domain is a key challenge that hinders the development of applications that can help the public with their health-related questions. To address this issue, we first proposed a pipelined approach to create two large-scale datasets: HealthVidQA-CRF and HealthVidQA-Prompt. Later, we proposed monomodal and multimodal approaches that can effectively provide visual answers from medical videos
    
[^17]: 大型语言模型中准确计算的代码独白

    Code Soliloquies for Accurate Calculations in Large Language Models. (arXiv:2309.12161v1 [cs.CL])

    [http://arxiv.org/abs/2309.12161](http://arxiv.org/abs/2309.12161)

    该论文介绍了一种应对大型语言模型在处理复杂计算方面的限制性的创新方法，通过生成模拟对话，并在每个学生回答触发自言自语来提高性能。

    

    高质量的对话数据集对于采用大型语言模型（LLM）后端的智能辅导系统（ITS）的成功开发至关重要。当这些数据集用于对LLM后端进行细调时，显着提高了学生和ITS之间的互动质量。开发这些数据集的常见策略涉及使用先进的GPT-4模型生成合成的学生-教师对话。然而，当这些对话需要进行物理等科目中常见的复杂计算时，就会出现挑战。尽管其先进的功能，GPT-4在可靠处理甚至简单的乘法任务方面的表现还不够，这是其在这些科目中的局限性。为了解决这些挑战，本文介绍了一种创新的有状态提示设计。我们的方法生成了一个由GPT-4模拟的学生和导师机器人之间的模拟对话。每个学生的回答都会触发一个自言自语（内心独白）。

    High-quality conversational datasets are integral to the successful development of Intelligent Tutoring Systems (ITS) that employ a Large Language Model (LLM) backend. These datasets, when used to fine-tune the LLM backend, significantly enhance the quality of interactions between students and ITS. A common strategy for developing these datasets involves generating synthetic student-teacher dialogues using advanced GPT-4 models. However, challenges arise when these dialogues demand complex calculations, common in subjects like physics. Despite its advanced capabilities, GPT-4's performance falls short in reliably handling even simple multiplication tasks, marking a significant limitation in its utility for these subjects. To address these challenges, this paper introduces an innovative stateful prompt design. Our approach generates a mock conversation between a student and a tutorbot, both roles simulated by GPT-4. Each student response triggers a soliloquy (an inner monologue) in the 
    
[^18]: OSN-MDAD：用于在线社交媒体上阿拉伯多方言对话的机器翻译数据集

    OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media. (arXiv:2309.12137v1 [cs.CL])

    [http://arxiv.org/abs/2309.12137](http://arxiv.org/abs/2309.12137)

    该论文介绍了一个用于阿拉伯多方言在线社交媒体对话的机器翻译数据集，指出了阿拉伯语资源不足的问题以及现有机器翻译系统在处理阿拉伯方言时的困难。该研究的重点在于开发能够有效处理阿拉伯各种方言的机器翻译系统。

    

    虽然英语资源在社交媒体上理解内容相对充足，但阿拉伯语的资源仍不足够成熟。阿拉伯语资源不足的主要原因是，阿拉伯语除了标准版本（MSA）外，还有许多方言。阿拉伯人在日常交流中不使用MSA，而是使用方言版本。不幸的是，社交媒体用户也将这种现象引入到他们对社交媒体平台的使用中，这进而引发了对于构建适用于语言相关应用的合适AI模型的迫切需求。现有为MSA设计的机器翻译（MT）系统无法很好地处理阿拉伯方言。鉴于此，有必要通过开发能够有效处理阿拉伯各种方言的MT系统来适应社交网络上的非正式交流方式。与在MT系统中对MSA显示出先进进展不同，利用阿拉伯方言进行MT系统的利用所付出的努力不多。

    While resources for English language are fairly sufficient to understand content on social media, similar resources in Arabic are still immature. The main reason that the resources in Arabic are insufficient is that Arabic has many dialects in addition to the standard version (MSA). Arabs do not use MSA in their daily communications; rather, they use dialectal versions. Unfortunately, social users transfer this phenomenon into their use of social media platforms, which in turn has raised an urgent need for building suitable AI models for language-dependent applications. Existing machine translation (MT) systems designed for MSA fail to work well with Arabic dialects. In light of this, it is necessary to adapt to the informal nature of communication on social networks by developing MT systems that can effectively handle the various dialects of Arabic. Unlike for MSA that shows advanced progress in MT systems, little effort has been exerted to utilize Arabic dialects for MT systems. Whil
    
[^19]: 面向特定受众的"如何指南"：一个语料库和初步发现。

    How-to Guides for Specific Audiences: A Corpus and Initial Findings. (arXiv:2309.12117v1 [cs.CL])

    [http://arxiv.org/abs/2309.12117](http://arxiv.org/abs/2309.12117)

    本文研究了来自wikiHow平台的如何指南在实践中面向特定受众的差异。研究发现这些指南受到微妙的偏见的影响，旨在引起人们对这些不平等问题的关注，并为未来的工作解决这些问题铺平道路。

    

    面向特定目标群体的指导性文本应该根据读者的先前知识和需求来有效地引导他们实现其期望的目标。然而，针对特定群体也会存在反映不同社会规范和微妙刻板印象的风险。在本文中，我们调查了来自wikiHow平台的特定受众的如何指南在实践中的差异程度。我们进行了两个案例研究，研究了针对特定受众撰写的文本的定性特点。在一个概括性研究中，我们调查了哪些差异也可以通过计算方法系统地展示出来。我们的研究结果显示，来自wikiHow的指南，像其他文本流派一样，也受到微妙偏见的影响。我们的目标是提高对这些不平等问题的意识，作为解决这些问题的第一步。

    Instructional texts for specific target groups should ideally take into account the prior knowledge and needs of the readers in order to guide them efficiently to their desired goals. However, targeting specific groups also carries the risk of reflecting disparate social norms and subtle stereotypes. In this paper, we investigate the extent to which how-to guides from one particular platform, wikiHow, differ in practice depending on the intended audience. We conduct two case studies in which we examine qualitative features of texts written for specific audiences. In a generalization study, we investigate which differences can also be systematically demonstrated using computational methods. The results of our studies show that guides from wikiHow, like other text genres, are subject to subtle biases. We aim to raise awareness of these inequalities as a first step to addressing them in future work.
    
[^20]: PEFTT: 多参数效率的低资源藏语预训练语言模型微调

    PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models. (arXiv:2309.12109v1 [cs.CL])

    [http://arxiv.org/abs/2309.12109](http://arxiv.org/abs/2309.12109)

    本研究在低资源语言模型如藏语中进行了高效微调策略的研究，填补了这一重要空白。

    

    在大语言模型时代，传统模型训练对于普通用户和机构而言越来越难以想象。在这些模型上，对于高资源语言的高效微调的探索是一个不可否认的趋势，而这种趋势正逐渐流行起来。然而，对于低资源语言，如藏语，目前的研究非常有限。藏语自然语言处理的研究本就稀缺而受限。尽管目前由于其低资源性质，还没有现有的大语言模型用于藏语，但这一天毫无疑问会到来。因此，对于像藏语这样的低资源语言模型的高效微调研究非常必要。我们的研究可以作为填补这一重要空白的参考。

    In this era of large language models (LLMs), the traditional training of models has become increasingly unimaginable for regular users and institutions. The exploration of efficient fine-tuning for high-resource languages on these models is an undeniable trend that is gradually gaining popularity. However, there has been very little exploration for various low-resource languages, such as Tibetan. Research in Tibetan NLP is inherently scarce and limited. While there is currently no existing large language model for Tibetan due to its low-resource nature, that day will undoubtedly arrive. Therefore, research on efficient fine-tuning for low-resource language models like Tibetan is highly necessary. Our research can serve as a reference to fill this crucial gap. Efficient fine-tuning strategies for pre-trained language models (PLMs) in Tibetan have seen minimal exploration. We conducted three types of efficient fine-tuning experiments on the publicly available TNCC-title dataset: "prompt-
    
[^21]: 论文标题：一项关于教学文本修订中模糊性的计算分析

    A Computational Analysis of Vagueness in Revisions of Instructional Texts. (arXiv:2309.12107v1 [cs.CL])

    [http://arxiv.org/abs/2309.12107](http://arxiv.org/abs/2309.12107)

    本文通过研究修订历史来分析教学文本修订中的模糊性。通过采用成对排名任务，神经模型在区分指令的不同版本上表现出了改进。

    

    WikiHow是一个开放领域的教学文章库，用于各种任务，用户可以对其进行修订。本文从修订历史的噪声数据集中提取了一对一的版本，即修订之前和修订之后的指令。我们特别提取并分析涉及指令模糊性的编辑。通过采用之前工作中的一种成对排名任务，并展示对现有基线的改进，进一步研究了神经模型在我们的数据中区分两个版本的指令的能力。

    WikiHow is an open-domain repository of instructional articles for a variety of tasks, which can be revised by users. In this paper, we extract pairwise versions of an instruction before and after a revision was made. Starting from a noisy dataset of revision histories, we specifically extract and analyze edits that involve cases of vagueness in instructions. We further investigate the ability of a neural model to distinguish between two versions of an instruction in our data by adopting a pairwise ranking task from previous work and showing improvements over existing baselines.
    
[^22]: SemEval-2022任务7：识别指导文本中暗含或不明确短语的合理解释

    SemEval-2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts. (arXiv:2309.12102v1 [cs.CL])

    [http://arxiv.org/abs/2309.12102](http://arxiv.org/abs/2309.12102)

    SemEval-2022任务7旨在识别指导文本中暗含或不明确短语的合理解释。通过人类评判和参与系统的自动判断，最好的系统在此任务上达到了68.9%的准确率。同时，还发现了有多个合理解释的上下文可以以75.2%的准确率被排名前的参与团队的预测所识别出来。

    

    我们介绍了SemEval-2022任务7，这是一个关于评估指导文本中解释的合理性的共享任务。这个任务的数据集包括手动澄清的操作指南，我们生成了替代的解释并收集了人类的合理性判断。参与系统的任务是在相应的上下文中自动确定解释的合理性。总共有21个参与者参与了这个任务，最好的系统的准确率达到了68.9%。本报告总结了来自8个团队的结果和发现，以及他们的系统描述。最后，我们进行了额外的评估，显示出排名前的参与团队的预测能以75.2%的准确率识别出有多个合理解释的上下文。

    We describe SemEval-2022 Task 7, a shared task on rating the plausibility of clarifications in instructional texts. The dataset for this task consists of manually clarified how-to guides for which we generated alternative clarifications and collected human plausibility judgements. The task of participating systems was to automatically determine the plausibility of a clarification in the respective context. In total, 21 participants took part in this task, with the best system achieving an accuracy of 68.9%. This report summarizes the results and findings from 8 teams and their system descriptions. Finally, we show in an additional evaluation that predictions by the top participating team make it possible to identify contexts with multiple plausible clarifications with an accuracy of 75.2%.
    
[^23]: 使用Prompt调优的预训练语言模型加速主题投资

    Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models. (arXiv:2309.12075v1 [cs.CL])

    [http://arxiv.org/abs/2309.12075](http://arxiv.org/abs/2309.12075)

    本研究通过Benchmark测试，发现使用Prompt Tuning的预训练语言模型在多标签文本分类任务中具有较好的性能和计算效率。同时，提出了使用Trie搜索来解决生成标签匹配问题的限制。

    

    Prompt Tuning作为一种可扩展且成本效益高的方法，正在成为细调预训练语言模型（PLMs）的一种流行方法。本研究基于多标签文本分类任务对Prompt Tuning和基准方法的性能和计算效率进行了基准测试。将其应用于将公司分类为投资公司专有的行业分类法，以支持其主题投资策略。在多标签分类问题中，使用PLMs进行文本到文本分类经常被报告为优于使用分类头进行分类，但在每个标签由多个令牌组成的多标签分类问题中，存在一些限制：（a）生成的标签可能不匹配行业分类法中的任何标签；（b）在细调阶段，必须以任意顺序提供多个标签；（c）模型为每个标签提供二进制决策，而不是适当的置信度分数。通过应用Trie搜索来解决限制（a）。

    Prompt Tuning is emerging as a scalable and cost-effective method to fine-tune Pretrained Language Models (PLMs). This study benchmarks the performance and computational efficiency of Prompt Tuning and baseline methods on a multi-label text classification task. This is applied to the use case of classifying companies into an investment firm's proprietary industry taxonomy, supporting their thematic investment strategy. Text-to-text classification with PLMs is frequently reported to outperform classification with a classification head, but has several limitations when applied to a multi-label classification problem where each label consists of multiple tokens: (a) Generated labels may not match any label in the industry taxonomy; (b) During fine-tuning, multiple labels must be provided in an arbitrary order; (c) The model provides a binary decision for each label, rather than an appropriate confidence score. Limitation (a) is addressed by applying constrained decoding using Trie Search,
    
[^24]: 在巴西中学考试上对基于量化LLaMa模型的基准测试

    Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam. (arXiv:2309.12071v1 [cs.AI])

    [http://arxiv.org/abs/2309.12071](http://arxiv.org/abs/2309.12071)

    本研究对基于量化LLaMa模型的大型语言模型在巴西中学考试上进行了性能评估。评估结果表明，最佳表现的模型在原版葡萄牙语问题和其英文翻译上的准确率约为46%。同时，作者还评估了这些模型的计算效率。

    

    尽管大型语言模型(LLM)在我们与计算机交互的方式上代表了一场革命，允许构建复杂问题并能够对一系列陈述进行推理，但由于需要专门的硬件执行，它们的使用受到限制。在这项研究中，我们评估了基于70亿和130亿LLaMA模型的LLMs在量化处理和运行在家庭硬件上的性能。考虑到的模型有Alpaca、Koala和Vicuna。为了评估这些模型的有效性，我们开发了一个包含1006个问题的数据库，这些问题来自巴西国家中学考试(ENEM)。我们的分析发现，表现最佳的模型在原版葡萄牙语问题和其英文翻译上的准确率约为46%，另外，我们通过测量执行所需的时间来评估模型的计算效率。在平均情况下，70亿和130亿LLMs需要约

    Although Large Language Models (LLMs) represent a revolution in the way we interact with computers, allowing the construction of complex questions and the ability to reason over a sequence of statements, their use is restricted due to the need for dedicated hardware for execution. In this study, we evaluate the performance of LLMs based on the 7 and 13 billion LLaMA models, subjected to a quantization process and run on home hardware. The models considered were Alpaca, Koala, and Vicuna. To evaluate the effectiveness of these models, we developed a database containing 1,006 questions from the ENEM (Brazilian National Secondary School Exam). Our analysis revealed that the best performing models achieved an accuracy of approximately 46% for the original texts of the Portuguese questions and 49% on their English translations. In addition, we evaluated the computational efficiency of the models by measuring the time required for execution. On average, the 7 and 13 billion LLMs took approxi
    
[^25]: BELT: 通过自然语言监督进行脑电图到语言解码和零样本情感分类的引导式模型和学习框架

    BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision. (arXiv:2309.12056v1 [cs.AI])

    [http://arxiv.org/abs/2309.12056](http://arxiv.org/abs/2309.12056)

    BELT是一种通过自然语言监督进行脑电图到语言解码和零样本情感分类的引导式模型和学习框架。它利用现成的大规模预训练语言模型来改进脑电信号的理解，从而推动了大脑-计算机界面的应用和发展。

    

    本文介绍了BELT，这是一个针对大脑到语言翻译研究的重要主题的新模型和学习框架。将非侵入性脑信号翻译成可读的自然语言有潜力推动大脑-计算机界面（BCI）的应用场景和发展。脑信号解码或脑-语言翻译中的关键问题是从有限规模和质量的数据集中获得语义适当且具有区分性的脑电图表示。所提出的BELT方法是一个通用且高效的框架，利用现成的大规模预训练语言模型（LM）引导脑电图表示学习。通过利用训练在互联网规模数据集上的大规模LM理解语义信息和零样本泛化能力，BELT极大改进了对脑电信号的理解。具体而言，BELT模型由一个深度神经网络组成，其中包含一个解码神经网络和一个预训练LM。

    This paper presents BELT, a novel model and learning framework for the pivotal topic of brain-to-language translation research. The translation from noninvasive brain signals into readable natural language has the potential to promote the application scenario as well as the development of brain-computer interfaces (BCI) as a whole. The critical problem in brain signal decoding or brain-to-language translation is the acquisition of semantically appropriate and discriminative EEG representation from a dataset of limited scale and quality. The proposed BELT method is a generic and efficient framework that bootstraps EEG representation learning using off-the-shelf large-scale pretrained language models (LMs). With a large LM's capacity for understanding semantic information and zero-shot generalization, BELT utilizes large LMs trained on Internet-scale datasets to bring significant improvements to the understanding of EEG signals.  In particular, the BELT model is composed of a deep confor
    
[^26]: AceGPT：将大型语言模型本地化为阿拉伯文

    AceGPT, Localizing Large Language Models in Arabic. (arXiv:2309.12053v1 [cs.CL])

    [http://arxiv.org/abs/2309.12053](http://arxiv.org/abs/2309.12053)

    本研究旨在开发阿拉伯文的本地化大型语言模型(AceGPT)，通过预训练、监督微调和增强学习方法来培养具备文化意识和价值观一致的阿拉伯文模型，以满足阿拉伯语社区特定应用需求。评估结果表明，AceGPT在各项基准测试中都是最先进的阿拉伯文模型。

    

    本文探讨了开发适用于阿拉伯文的本地化大型语言模型(LLM)的迫切需求和方法论，阿拉伯文具有独特的文化特征，这些特征目前的主流模型如ChatGPT并未充分解决。在考虑文化敏感性和本地价值观时还存在关键问题。为此，本文提出了一个打包解决方案，包括进一步使用阿拉伯文本进行预训练、使用本地阿拉伯指令和阿拉伯语GPT-4回应进行监督微调(SFT)，以及使用对本地文化和价值观敏感的奖励模型进行增强学习与人工智能反馈(RLAIF)。目标是训练具备文化意识和与价值观一致的阿拉伯文LLM，以满足阿拉伯语社区多样化的特定应用需求。广泛的评估表明，所得到的名为AceGPT的阿拉伯文LLM在各种基准测试中均是最先进的。

    This paper explores the imperative need and methodology for developing a localized Large Language Model (LLM) tailored for Arabic, a language with unique cultural characteristics that are not adequately addressed by current mainstream models like ChatGPT. Key concerns additionally arise when considering cultural sensitivity and local values. To this end, the paper outlines a packaged solution, including further pre-training with Arabic texts, supervised fine-tuning (SFT) using native Arabic instructions and GPT-4 responses in Arabic, and reinforcement learning with AI feedback (RLAIF) using a reward model that is sensitive to local culture and values. The objective is to train culturally aware and value-aligned Arabic LLMs that can serve the diverse application-specific needs of Arabic-speaking communities.  Extensive evaluations demonstrated that the resulting LLM called `\textbf{AceGPT}' is the SOTA open Arabic LLM in various benchmarks, including instruction-following benchmark (i.e
    
[^27]: CAMERA：广告文本生成的多模态数据集和基准

    CAMERA: A Multimodal Dataset and Benchmark for Ad Text Generation. (arXiv:2309.12030v1 [cs.CL])

    [http://arxiv.org/abs/2309.12030](http://arxiv.org/abs/2309.12030)

    本文介绍了一个重新设计的任务和构建了一个基准，通过引入CA Multimodal Evaluation for Ad Text GeneRAtion (CAMERA)数据集，推动了广告文本生成领域的发展并解决了现有基准中的缺陷。

    

    在响应手动在线广告制作的限制时，已经在自动广告文本生成（ATG）领域进行了大量研究。然而，由于缺乏涵盖整个领域的基准以及没有明确定义的问题集和清晰的模型输入和输出，比较不同方法一直是一项挑战。为了解决这些问题，本文旨在通过引入重新设计的任务和构建一个基准来推动ATG领域的发展。具体而言，我们将ATG定义为一个跨应用任务，涵盖互联网广告的各个方面。作为我们的贡献的一部分，我们提出了一个第一个基准数据集，名为CA Multimodal Evaluation for Ad Text GeneRAtion（CAMERA），为ATG精心设计，可以利用多模态信息并进行行业评估。此外，我们通过使用多个基线模型进行评估实验证明了我们提出的基准的有用性，这些模型在术语上有所不同。

    In response to the limitations of manual online ad production, significant research has been conducted in the field of automatic ad text generation (ATG). However, comparing different methods has been challenging because of the lack of benchmarks encompassing the entire field and the absence of well-defined problem sets with clear model inputs and outputs. To address these challenges, this paper aims to advance the field of ATG by introducing a redesigned task and constructing a benchmark. Specifically, we defined ATG as a cross-application task encompassing various aspects of the Internet advertising. As part of our contribution, we propose a first benchmark dataset, CA Multimodal Evaluation for Ad Text GeneRAtion (CAMERA), carefully designed for ATG to be able to leverage multi-modal information and conduct an industry-wise evaluation. Furthermore, we demonstrate the usefulness of our proposed benchmark through evaluation experiments using multiple baseline models, which vary in term
    
[^28]: LMSYS-Chat-1M：一个大规模实际语言模型对话数据集

    LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset. (arXiv:2309.11998v1 [cs.CL])

    [http://arxiv.org/abs/2309.11998](http://arxiv.org/abs/2309.11998)

    LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。

    

    随着大规模语言模型（LLM）在各种应用中的广泛使用，研究人们如何在实际场景中与其交互变得越来越重要。在本文中，我们介绍了LMSYS-Chat-1M，这是一个包含一百万个与25个最先进的LLM进行的实际对话的大规模数据集。这个数据集是从我们的Vicuna演示和Chatbot Arena网站上的21万个独立IP地址中收集而来的。我们提供了数据集内容的概述，包括其策划过程、基本统计数据和主题分布，强调其多样性、独特性和规模。我们通过四个用例展示了它的多样性：开发与GPT-4表现相似的内容过滤模型、构建一个安全基准、训练与Vicuna表现相似的指令跟随模型、创建具有挑战性的基准问题。我们相信这个数据集将成为我们理解和推进LLM能力的宝贵资源。

    Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is pub
    
[^29]: 重新思考人工智能系统中自然语言理解的评估框架：以语言习得为未来度量的核心

    Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics. (arXiv:2309.11981v1 [cs.CL])

    [http://arxiv.org/abs/2309.11981](http://arxiv.org/abs/2309.11981)

    这篇论文重新思考了人工智能系统中自然语言理解的评估框架，提出了以语言习得为核心的全面框架，旨在解决传统度量方法面临的问题，并借鉴了大型语言模型的进展。

    

    在人工智能领域，大型语言模型在自然语言处理方面取得了前所未有的进展，这为重新审视传统的机器智能度量方法提供了机会。本文提出了一个新的评估框架，从传统的图灵测试转向以语言习得为核心的全面框架，并借鉴了最近在大型语言模型方面的进展。本文深受多个学科的卓越工作的影响，指出了保持跨学科桥梁开放的必要性，并勾勒了一个更加稳健和可持续的方法。

    In the burgeoning field of artificial intelligence (AI), the unprecedented progress of large language models (LLMs) in natural language processing (NLP) offers an opportunity to revisit the entire approach of traditional metrics of machine intelligence, both in form and content. As the realm of machine cognitive evaluation has already reached Imitation, the next step is an efficient Language Acquisition and Understanding. Our paper proposes a paradigm shift from the established Turing Test towards an all-embracing framework that hinges on language acquisition, taking inspiration from the recent advancements in LLMs. The present contribution is deeply tributary of the excellent work from various disciplines, point out the need to keep interdisciplinary bridges open, and delineates a more robust and sustainable approach.
    
[^30]: 股市情绪分类与基于Fine-tuned BERT的回测

    Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT. (arXiv:2309.11979v1 [q-fin.CP])

    [http://arxiv.org/abs/2309.11979](http://arxiv.org/abs/2309.11979)

    本论文通过构建自然语言处理模型BERT并对其进行fine-tune，实现了股市情绪的分类和基于该模型的回测分析。实验结果显示，fine-tuned模型相比原始模型和基准模型有不同程度的性能改进。

    

    随着大数据和计算设备的快速发展，基于实时信息获取的低延迟自动交易平台成为股票交易市场的主要组成部分，因此量化交易的主题得到了广泛关注。对于非强有效的交易市场来说，人类情绪和期望总是主导市场趋势和交易决策。因此，本文从情绪理论出发，以东方财富为例，从其对应的股吧爬取用户评论标题数据并进行数据清洗。随后，构建了自然语言处理模型BERT，并使用现有的带有标注数据集对BERT模型进行fine-tune。实验结果表明，与原始模型和基准模型相比，fine-tuned模型有不同程度的性能改进。随后，在以上模型的基础上，对爬取的用户评论数据进行了情绪极性标注。

    With the rapid development of big data and computing devices, low-latency automatic trading platforms based on real-time information acquisition have become the main components of the stock trading market, so the topic of quantitative trading has received widespread attention. And for non-strongly efficient trading markets, human emotions and expectations always dominate market trends and trading decisions. Therefore, this paper starts from the theory of emotion, taking East Money as an example, crawling user comment titles data from its corresponding stock bar and performing data cleaning. Subsequently, a natural language processing model BERT was constructed, and the BERT model was fine-tuned using existing annotated data sets. The experimental results show that the fine-tuned model has different degrees of performance improvement compared to the original model and the baseline model. Subsequently, based on the above model, the user comment data crawled is labeled with emotional pola
    
[^31]: 扩展COMETKIWI：Unbabel-IST 2023年质量评估共享任务的提交

    Scaling up COMETKIWI: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task. (arXiv:2309.11925v1 [cs.CL])

    [http://arxiv.org/abs/2309.11925](http://arxiv.org/abs/2309.11925)

    Unbabel和Instituto Superior Técnico提交了Unbabel-IST 2023年参加WMT 2023年质量评估共享任务的成果，他们在所有任务中排名第一，在质量评估中取得了单词、跨度和句子级别的最新最好表现。

    

    我们介绍了Unbabel和Instituto Superior Técnico共同为WMT 2023年质量评估（QE）共享任务做出的贡献。我们的团队参与了所有任务：句子和单词水平的质量预测任务（任务1）以及细粒度错误跨度检测任务（任务2）。对于所有任务，我们基于COMETKIWI-22模型（Rei等，2022b）进行改进。我们的多语种方法在所有任务中排名第一，达到单词、跨度和句子级粒度的质量评估的最新表现水平。与之前的最新COMETKIWI-22相比，我们在与人类判断的相关性上有很大的改进（最高可达10个Spearman点）。此外，我们超过了第二名的多语种提交，在绝对分数上提高了3.8个点。

    We present the joint contribution of Unbabel and Instituto Superior T\'ecnico to the WMT 2023 Shared Task on Quality Estimation (QE). Our team participated on all tasks: sentence- and word-level quality prediction (task 1) and fine-grained error span detection (task 2). For all tasks, we build on the COMETKIWI-22 model (Rei et al., 2022b). Our multilingual approaches are ranked first for all tasks, reaching state-of-the-art performance for quality estimation at word-, span- and sentence-level granularity. Compared to the previous state-of-the-art COMETKIWI-22, we show large improvements in correlation with human judgements (up to 10 Spearman points). Moreover, we surpass the second-best multilingual submission to the shared-task with up to 3.8 absolute points.
    
[^32]: InstructERC：借助检索多任务LLMs框架改革对话中的情绪识别

    InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework. (arXiv:2309.11911v1 [cs.CL])

    [http://arxiv.org/abs/2309.11911](http://arxiv.org/abs/2309.11911)

    InstructERC是一种使用大型语言模型(LLMs)的生成式框架，通过引入检索模板模块和额外的情感对齐任务，改革了对话中的情绪识别。

    

    对话情绪识别(ERC)的发展一直受到管道设计复杂性的阻碍，导致ERC模型往往对特定数据集和对话模式过拟合。在本研究中，我们提出了一种新方法，即InstructERC，将ERC任务从判别式框架转化为基于大型语言模型(LLMs)的生成式框架。InstructERC有两个重要贡献：首先，InstructERC引入了一个简单而有效的检索模板模块，通过将历史对话内容、标签语句和情感领域演示与高语义相似性进行拼接，帮助模型明确地集成多粒度对话监督信息。此外，我们引入了两个额外的情感对齐任务，即说话人识别和情感预测任务，以隐式地建模对话角色关系和未来对话情绪倾向。我们的基于LLM的方法

    The development of emotion recognition in dialogue (ERC) has been consistently hindered by the complexity of pipeline designs, leading to ERC models that often overfit to specific datasets and dialogue patterns. In this study, we propose a novel approach, namely  InstructERC, to reformulates the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs) . InstructERC has two significant contributions: Firstly, InstructERC introduces a simple yet effective retrieval template module, which helps the model explicitly integrate multi-granularity dialogue supervision information by concatenating the historical dialog content, label statement, and emotional domain demonstrations with high semantic similarity. Furthermore, we introduce two additional emotion alignment tasks, namely speaker identification and emotion prediction tasks, to implicitly model the dialogue role relationships and future emotional tendencies in conversations. Our LLM-based
    
[^33]: 针对隐性仇恨言论的焦点推理注入与易处理密度区分

    Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection. (arXiv:2309.11896v1 [cs.CL])

    [http://arxiv.org/abs/2309.11896](http://arxiv.org/abs/2309.11896)

    FiADD是一种新颖的焦点推理注入与易处理密度区分框架，通过将隐性仇恨言论的表面形式与暗示的形式更接近，同时增加不同类别标签之间的集群间距，显著改进了隐性仇恨分类任务的性能。

    

    虽然预训练的大型语言模型（PLMs）在许多NLP任务上取得了最先进的成果，但它们缺乏对隐性仇恨言论微妙表达的理解。这样微妙而隐性的仇恨经常被错误地分类为非仇恨。通过增加外部的上下文或通过基于距离的度量强制标签分离，已经尝试过各种方法来增强（隐性）仇恨内容的检测。我们将这两种方法结合起来并引入了一种新颖的焦点推理适应密度区分框架（FiADD）。FiADD通过将隐性仇恨言论的表面形式与暗示的形式更接近，同时增加不同类别标签之间的集群间距，来增强PLM微调管道。我们在三个隐性仇恨数据集上测试了FiADD，并观察到在两类和三类仇恨分类任务中的显著改进。我们进一步对FiADD在三个其他任务上的泛化性进行了实验，即检测讽刺、讽刺和立场。

    Although pre-trained large language models (PLMs) have achieved state-of-the-art on many NLP tasks, they lack understanding of subtle expressions of implicit hate speech. Such nuanced and implicit hate is often misclassified as non-hate. Various attempts have been made to enhance the detection of (implicit) hate content by augmenting external context or enforcing label separation via distance-based metrics. We combine these two approaches and introduce FiADD, a novel Focused Inferential Adaptive Density Discrimination framework. FiADD enhances the PLM finetuning pipeline by bringing the surface form of an implicit hate speech closer to its implied form while increasing the inter-cluster distance among various class labels. We test FiADD on three implicit hate datasets and observe significant improvement in the two-way and three-way hate classification tasks. We further experiment on the generalizability of FiADD on three other tasks, namely detecting sarcasm, irony, and stance, in whic
    
[^34]: 基于音频对比的微调方法

    Audio Contrastive based Fine-tuning. (arXiv:2309.11895v1 [cs.SD])

    [http://arxiv.org/abs/2309.11895](http://arxiv.org/abs/2309.11895)

    本论文提出了一种基于音频对比的微调方法（AudioConFit），通过借助对比学习的可转移性，该方法在各种音频分类任务中表现出强大的泛化能力，并在不同设置下实现了最先进的结果。

    

    音频分类在语音和声音处理任务中起着至关重要的作用，具有广泛的应用。在将模型拟合到训练数据（避免过拟合）并使其能够良好地泛化到新领域之间仍然存在着平衡的挑战。借助对比学习的可转移性，我们引入了基于音频对比的微调方法（AudioConFit），这种方法具有强大的泛化能力。对各种音频分类任务的实证实验表明了我们方法的有效性和鲁棒性，在不同设置下取得了最先进的结果。

    Audio classification plays a crucial role in speech and sound processing tasks with a wide range of applications. There still remains a challenge of striking the right balance between fitting the model to the training data (avoiding overfitting) and enabling it to generalise well to a new domain. Leveraging the transferability of contrastive learning, we introduce Audio Contrastive-based Fine-tuning (AudioConFit), an efficient approach characterised by robust generalisability. Empirical experiments on a variety of audio classification tasks demonstrate the effectiveness and robustness of our approach, which achieves state-of-the-art results in various settings.
    
[^35]: 同时解析短语结构树和依存树真的有用吗？重新审视

    Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit. (arXiv:2309.11888v1 [cs.CL])

    [http://arxiv.org/abs/2309.11888](http://arxiv.org/abs/2309.11888)

    本文重新审视了同时解析短语结构树和依存树的方法，通过采用更高效的解码算法、在训练阶段进行联合建模、提出高阶评分组件以及进行深入实验和分析等四个方面的进展，展示了该方法的潜力和价值。

    

    本文重新审视了同时解析短语结构树和依存树这一话题，即为输入句子同时生成兼容的短语结构树和依存树，考虑到这两种类型的树在表示语法方面是互补的，这是一种有吸引力的方法。与之前的工作相比，我们在四个方面取得了进展：（1）采用更高效的解码算法，（2）在训练阶段进行联合建模，而不仅仅是在推理阶段，（3）为短语结构和依存之间的交互提出了高阶评分组件，（4）通过深入实验和分析获得了更多见解。

    This work visits the topic of jointly parsing constituency and dependency trees, i.e., to produce compatible constituency and dependency trees simultaneously for input sentences, which is attractive considering that the two types of trees are complementary in representing syntax. Compared with previous works, we make progress in four aspects: (1) adopting a much more efficient decoding algorithm, (2) exploring joint modeling at the training phase, instead of only at the inference phase, (3) proposing high-order scoring components for constituent-dependency interaction, (4) gaining more insights via in-depth experiments and analysis.
    
[^36]: 语法之间的句法变异：对一个复杂自适应系统进行建模

    Syntactic Variation Across the Grammar: Modelling a Complex Adaptive System. (arXiv:2309.11869v1 [cs.CL])

    [http://arxiv.org/abs/2309.11869](http://arxiv.org/abs/2309.11869)

    本文对一个复杂自适应系统-语法之间的句法变异进行了建模和研究，结果表明句法变异不仅涉及个别节点，还涉及整个语法结构的相互作用。

    

    虽然语言是一个复杂的自适应系统，但大部分关于句法变异的研究都是独立地观察几个单个的结构，而忽视了整个语法的连接网络。本文通过系统地模拟英语使用者16个国家的49个当地群体的方言变异，量化了这种简化的影响。我们通过对整个语法以及语法内部的独立节点进行方言分类，以描述这些方言之间的句法差异。结果表明，首先，语法内的许多独立节点都受到变异的影响，但独立地来看，没有一个节点的表现能够与整个语法相比。这表明句法变异的一个重要部分是语法不同部分之间的相互作用。其次，结果表明相似的语言之间的语法差异和区别不只是个别节点的差异，而是整个语法结构的差异。

    While language is a complex adaptive system, most work on syntactic variation observes a few individual constructions in isolation from the rest of the grammar. This means that the grammar, a network which connects thousands of structures at different levels of abstraction, is reduced to a few disconnected variables. This paper quantifies the impact of such reductions by systematically modelling dialectal variation across 49 local populations of English speakers in 16 countries. We perform dialect classification with both an entire grammar as well as with isolated nodes within the grammar in order to characterize the syntactic differences between these dialects. The results show, first, that many individual nodes within the grammar are subject to variation but, in isolation, none perform as well as the grammar as a whole. This indicates that an important part of syntactic variation consists of interactions between different parts of the grammar. Second, the results show that the simila
    
[^37]: BitCoin: 基于双向标记和监督对比学习的联合关系三元组提取框架

    BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework. (arXiv:2309.11853v1 [cs.CL])

    [http://arxiv.org/abs/2309.11853](http://arxiv.org/abs/2309.11853)

    BitCoin是一种创新的基于双向标记和监督对比学习的联合关系三元组提取框架，用于解决关系三元组提取中的问题和局限性。通过设计监督对比学习方法，考虑了每个锚点的多个正例，提高了提取的效果。

    

    关系三元组提取是信息提取和知识图谱构建中的一项关键任务。尽管最近有了一些进展，但现有方法仍存在一定的局限性。它们仅使用泛化的预训练模型，并未考虑RTE任务的特殊性。此外，现有的基于标记的方法通常将RTE任务分解为两个子任务，首先识别主体，然后识别客体和关系。它们仅关注从主体到客体的关系三元组的提取，忽视了一旦主体提取失败，就无法提取与该主体相关的所有三元组的情况。为了解决这些问题，我们提出了BitCoin，这是一种创新的基于双向标记和监督对比学习的联合关系三元组提取框架。具体而言，我们设计了一种监督对比学习方法，该方法考虑了每个锚点的多个正例，而不仅仅限于一个正例。

    Relation triple extraction (RTE) is an essential task in information extraction and knowledge graph construction. Despite recent advancements, existing methods still exhibit certain limitations. They just employ generalized pre-trained models and do not consider the specificity of RTE tasks. Moreover, existing tagging-based approaches typically decompose the RTE task into two subtasks, initially identifying subjects and subsequently identifying objects and relations. They solely focus on extracting relational triples from subject to object, neglecting that once the extraction of a subject fails, it fails in extracting all triples associated with that subject. To address these issues, we propose BitCoin, an innovative Bidirectional tagging and supervised Contrastive learning based joint relational triple extraction framework. Specifically, we design a supervised contrastive learning method that considers multiple positives per anchor rather than restricting it to just one positive. Furt
    
[^38]: 大型语言模型的知识净化

    Knowledge Sanitization of Large Language Models. (arXiv:2309.11852v1 [cs.CL])

    [http://arxiv.org/abs/2309.11852](http://arxiv.org/abs/2309.11852)

    这项研究探索了一种用于减轻大型语言模型（LLM）隐私问题的知识净化方法。通过微调模型，使其在被询问敏感信息时生成无害回答，从而有效地减少知识泄漏并保持整体性能。

    

    我们探索了一种知识净化方法，以减轻与大型语言模型（LLM）相关的隐私问题。在大规模Web数据语料库上训练的LLMs可以记住并潜在地透露敏感或机密信息，引发关键的安全问题。我们的技术通过微调这些模型，促使它们在被询问特定信息时生成无害的回答，例如“我不知道”。在封闭式问答任务的实验结果中，我们简单的方法不仅最大程度地减少了特定知识泄漏，还保留了LLM的整体性能。这两个优点加强了对提取攻击的防御，并减少了产生幻觉等有害内容的发送。

    We explore a knowledge sanitization approach to mitigate the privacy concerns associated with large language models (LLMs). LLMs trained on a large corpus of Web data can memorize and potentially reveal sensitive or confidential information, raising critical security concerns. Our technique fine-tunes these models, prompting them to generate harmless responses such as ``I don't know'' when queried about specific information. Experimental results in a closed-book question-answering task show that our straightforward method not only minimizes particular knowledge leakage but also preserves the overall performance of LLM. These two advantages strengthen the defense against extraction attacks and reduces the emission of harmful content such as hallucinations.
    
[^39]: 一种用于细粒度情感分析的话语级多尺度韵律模型

    A Discourse-level Multi-scale Prosodic Model for Fine-grained Emotion Analysis. (arXiv:2309.11849v1 [cs.SD])

    [http://arxiv.org/abs/2309.11849](http://arxiv.org/abs/2309.11849)

    本文提出了一种话语级多尺度韵律模型，用于细粒度情感分析。通过预测适当的韵律特征，该模型可以指导语音合成模型生成更富有表现力的语音。实验证明，多尺度文本信息对于预测情感韵律特征具有有效性。

    

    本文探讨了从话语级文本预测适当的韵律特征用于细粒度情感分析的方法。通过使用风格转移模型，我们从语音中提取了音素级的本地韵律嵌入序列 (LPEs) 和全局风格嵌入作为韵律语音特征，以作为我们模型的预测值。我们提出了一种话语级多尺度文本韵律模型 (D-MPM)，通过利用多尺度文本来预测这两个韵律特征。该模型可以用于分析更好的情感韵律特征，并指导语音合成模型合成更富有表现力的语音。为了定量评估所提出的模型，我们提供了一个全新且大规模的话语级中文有声书 (DCA) 数据集，其中包含超过13,000个标注序列用于评估所提出的模型。在DCA数据集上的实验结果表明，多尺度文本信息有效地提高了情感韵律特征的预测性能。

    This paper explores predicting suitable prosodic features for fine-grained emotion analysis from the discourse-level text. To obtain fine-grained emotional prosodic features as predictive values for our model, we extract a phoneme-level Local Prosody Embedding sequence (LPEs) and a Global Style Embedding as prosodic speech features from the speech with the help of a style transfer model. We propose a Discourse-level Multi-scale text Prosodic Model (D-MPM) that exploits multi-scale text to predict these two prosodic features. The proposed model can be used to analyze better emotional prosodic features and thus guide the speech synthesis model to synthesize more expressive speech. To quantitatively evaluate the proposed model, we contribute a new and large-scale Discourse-level Chinese Audiobook (DCA) dataset with more than 13,000 utterances annotated sequences to evaluate the proposed model. Experimental results on the DCA dataset show that the multi-scale text information effectively h
    
[^40]: 在信息搜索对话中评估大型语言模型用于基于文档的响应生成

    Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues. (arXiv:2309.11838v1 [cs.CL])

    [http://arxiv.org/abs/2309.11838](http://arxiv.org/abs/2309.11838)

    本文研究了在信息搜索对话中使用大型语言模型进行基于文档的响应生成，并通过人工评估了其性能。

    

    本文研究了在信息搜索对话的背景下，使用类似ChatGPT的大型语言模型（LLM）进行基于文档的响应生成。我们使用了先前在DialDoc 2022共享任务中使用的四个社会服务领域的任务导向对话的MultiDoc2Dial语料库进行评估。信息搜索对话的转换以多个提供相关信息的文档为基础。我们通过使用两种方法Chat-Completion和LlamaIndex，通过激发ChatGPT模型来生成对话完成响应。ChatCompletion使用ChatGPT模型的预训练知识，而LlamaIndex还从文档中提取相关信息。我们观察到，通过LLM进行基于文档的响应生成不能通过自动评估指标充分评估，因为它们更加冗长，所以我们进行了人工评估，其中评估员对共享任务的获奖系统、两个Chat-GPT变体的输出以及人类响应进行评级。

    In this paper, we investigate the use of large language models (LLMs) like ChatGPT for document-grounded response generation in the context of information-seeking dialogues. For evaluation, we use the MultiDoc2Dial corpus of task-oriented dialogues in four social service domains previously used in the DialDoc 2022 Shared Task. Information-seeking dialogue turns are grounded in multiple documents providing relevant information. We generate dialogue completion responses by prompting a ChatGPT model, using two methods: Chat-Completion and LlamaIndex. ChatCompletion uses knowledge from ChatGPT model pretraining while LlamaIndex also extracts relevant information from documents. Observing that document-grounded response generation via LLMs cannot be adequately assessed by automatic evaluation metrics as they are significantly more verbose, we perform a human evaluation where annotators rate the output of the shared task winning system, the two Chat-GPT variants outputs, and human responses.
    
[^41]: 一个用于具有恶意内容的LLMs的中文提示攻击数据集

    A Chinese Prompt Attack Dataset for LLMs with Evil Content. (arXiv:2309.11830v1 [cs.CL])

    [http://arxiv.org/abs/2309.11830](http://arxiv.org/abs/2309.11830)

    这个论文介绍了一个用于LLMs的中文Prompt Attack数据集，该数据集旨在评估防御提示攻击的能力。

    

    大型语言模型（LLMs）在文本理解和生成方面具有重要优点。然而，LLMs在应用中存在生成有害内容的风险，尤其是在使用Prompt Attack等黑盒攻击方法时。研究人员对LLMs的Prompt Attack和Defense很感兴趣，但目前没有公开可用的数据集来评估防御Prompt Attack的能力。在本文中，我们介绍了一个用于LLMs的中文Prompt Attack数据集，称为CPAD。我们的提示旨在引导LLMs生成具有多个精心设计的提示攻击方法和广泛关注的攻击内容的意外输出。与以前涉及安全估计的数据集不同，我们构建的提示考虑了三个维度：内容、攻击方法和目标，因此可以轻松评估响应。

    Large Language Models (LLMs) present significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers with harmful contents. Researchers are interested in Prompt Attack and Defense with LLMs, while there is no publicly available dataset to evaluate the abilities of defending prompt attack. In this paper, we introduce a Chinese Prompt Attack Dataset for LLMs, called CPAD. Our prompts aim to induce LLMs to generate unexpected outputs with several carefully designed prompt attack approaches and widely concerned attacking contents. Different from previous datasets involving safety estimation, We construct the prompts considering three dimensions: contents, attacking methods and goals, thus the responses can be easily evaluated and a
    
[^42]: 使用神经概率先验的词嵌入

    Word Embedding with Neural Probabilistic Prior. (arXiv:2309.11824v1 [cs.CL])

    [http://arxiv.org/abs/2309.11824](http://arxiv.org/abs/2309.11824)

    提出了一种可以与词嵌入模型无缝集成的神经概率先验，能够增强嵌入向量的表示，提高模型的鲁棒性和稳定性，实验证明了该方法在各种任务上提高了词表示。

    

    为了改进词表示学习，我们提出了一种可以与词嵌入模型无缝集成的概率先验。不同于以往的方法，词嵌入被视为一个概率生成模型，这使得我们能够对词表示学习进行先验正则化。所提出的先验不仅增强了嵌入向量的表示，还提高了模型的鲁棒性和稳定性。所提出的先验结构简单有效，可以轻松实现并灵活地插入到大多数现有的词嵌入模型中。大量实验证明了所提出的方法在各种任务上提高了词表示。

    To improve word representation learning, we propose a probabilistic prior which can be seamlessly integrated with word embedding models. Different from previous methods, word embedding is taken as a probabilistic generative model, and it enables us to impose a prior regularizing word representation learning. The proposed prior not only enhances the representation of embedding vectors but also improves the model's robustness and stability. The structure of the proposed prior is simple and effective, and it can be easily implemented and flexibly plugged in most existing word embedding models. Extensive experiments show the proposed method improves word representation on various tasks.
    
[^43]: SLHCat: 利用语义、词汇和层次特征将Wikipedia的分类和列表映射到DBpedia

    SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features. (arXiv:2309.11791v1 [cs.DL])

    [http://arxiv.org/abs/2309.11791](http://arxiv.org/abs/2309.11791)

    这项研究提出了一种方法，通过结合知识图谱的结构信息和本体类名的语义和词汇特征，将Wikipedia的分类和列表映射到DBpedia，以构建一个完善和细粒度的知识图谱。

    

    Wikipedia的文章通过分类和列表进行层次化组织，提供了其中一个最全面和普遍的分类系统，但其开放性导致了重复和不一致的问题。将DBpedia的类别分配给Wikipedia的分类和列表可以缓解这个问题，实现一个对实体链接和类型分类数字内容至关重要的大型知识图谱。然而，现有的CaLiGraph方法产生了不完整和非细粒度的映射。在本文中，我们将这个问题看作本体对齐，利用知识图谱的结构信息和本体类名的词汇和语义特征，发现自信映射，然后利用这些映射以远程监督方式对预训练的语言模型进行微调。我们的方法SLHCat包括两个主要部分：1）通过利用知识图谱的结构、语义相似性和命名实体自动生成训练数据

    Wikipedia articles are hierarchically organized through categories and lists, providing one of the most comprehensive and universal taxonomy, but its open creation is causing redundancies and inconsistencies. Assigning DBPedia classes to Wikipedia categories and lists can alleviate the problem, realizing a large knowledge graph which is essential for categorizing digital contents through entity linking and typing. However, the existing approach of CaLiGraph is producing incomplete and non-fine grained mappings. In this paper, we tackle the problem as ontology alignment, where structural information of knowledge graphs and lexical and semantic features of ontology class names are utilized to discover confident mappings, which are in turn utilized for finetuing pretrained language models in a distant supervision fashion. Our method SLHCat consists of two main parts: 1) Automatically generating training data by leveraging knowledge graph structure, semantic similarities, and named entity 
    
[^44]: ContextRef: 评估图像描述生成的无参考度量

    ContextRef: Evaluating Referenceless Metrics For Image Description Generation. (arXiv:2309.11710v1 [cs.CL])

    [http://arxiv.org/abs/2309.11710](http://arxiv.org/abs/2309.11710)

    本文介绍了ContextRef，用于评估图像描述生成的无参考度量。ContextRef包括人类评分和鲁棒性检查，同时考虑了上下文，通过精心微调可以取得实质性改善。

    

    无参考度量（例如CLIPScore）使用预训练的视觉-语言模型直接评估图像描述，而无需昂贵的真实参考文本。这样的方法可以促进快速进步，但前提是它们真正与人的偏好判断相吻合。在本文中，我们介绍了ContextRef，一个用于评估无参考度量以实现此对齐的基准。ContextRef有两个组成部分：基于各种已建立的质量维度的人类评分，以及设计了十种不同的鲁棒性检查，旨在发现基本弱点。ContextRef的一个关键方面是图像和描述以上下文方式呈现，反映了先前的研究表明上下文对描述质量的重要性。使用ContextRef，我们评估了各种预训练模型、评分函数和整合上下文的技术。但是，没有一种方法在ContextRef上获得成功，但我们表明经过精心微调可以取得实质性的改善。ContextRef仍然是一个具有挑战性的基准数据集。

    Referenceless metrics (e.g., CLIPScore) use pretrained vision--language models to assess image descriptions directly without costly ground-truth reference texts. Such methods can facilitate rapid progress, but only if they truly align with human preference judgments. In this paper, we introduce ContextRef, a benchmark for assessing referenceless metrics for such alignment. ContextRef has two components: human ratings along a variety of established quality dimensions, and ten diverse robustness checks designed to uncover fundamental weaknesses. A crucial aspect of ContextRef is that images and descriptions are presented in context, reflecting prior work showing that context is important for description quality. Using ContextRef, we assess a variety of pretrained models, scoring functions, and techniques for incorporating context. None of the methods is successful with ContextRef, but we show that careful fine-tuning yields substantial improvements. ContextRef remains a challenging bench
    
[^45]: 带有短期和长期记忆协作的增强记忆型LLM个性化

    Memory-Augmented LLM Personalization with Short- and Long-Term Memory Coordination. (arXiv:2309.11696v1 [cs.CL])

    [http://arxiv.org/abs/2309.11696](http://arxiv.org/abs/2309.11696)

    本研究提出了一种计算仿生记忆机制，配备了参数高效的微调模式，用于个性化LLMs。实验证明了该方法的有效性和可行性。

    

    大型语言模型（LLMs），如GPT3.5，在理解和生成自然语言方面表现出卓越的能力。然而，它们的非个性化生成方式可能导致用户特定结果的亚优化。通常，用户根据自己的知识和偏好以不同的方式进行对话。这就需要增强面向用户的LLM的任务，但这方面的研究尚未深入探索。之前的研究已经探索了基于记忆的方法来存储和检索知识，以增强生成而无需为新的查询进行重新训练。然而，我们认为仅仅使用记忆模块无法理解用户的偏好，并且完全训练一个LLM可能成本过高。在本研究中，我们提出了一种新颖的计算仿生记忆机制，配备了一个参数高效的微调模式，用于个性化LLMs。我们广泛的实验结果证明了该方法的有效性和可行性。

    Large Language Models (LLMs), such as GPT3.5, have exhibited remarkable proficiency in comprehending and generating natural language. However, their unpersonalized generation paradigm may result in suboptimal user-specific outcomes. Typically, users converse differently based on their knowledge and preferences. This necessitates the task of enhancing user-oriented LLM which remains unexplored. While one can fully train an LLM for this objective, the resource consumption is unaffordable. Prior research has explored memory-based methods to store and retrieve knowledge to enhance generation without retraining for new queries. However, we contend that a mere memory module is inadequate to comprehend a user's preference, and fully training an LLM can be excessively costly. In this study, we propose a novel computational bionic memory mechanism, equipped with a parameter-efficient fine-tuning schema, to personalize LLMs. Our extensive experimental results demonstrate the effectiveness and su
    
[^46]: 使用对比学习的半监督新闻话语特征提取

    Semi-supervised News Discourse Profiling with Contrastive Learning. (arXiv:2309.11692v1 [cs.CL])

    [http://arxiv.org/abs/2309.11692](http://arxiv.org/abs/2309.11692)

    本文提出了一种使用对比学习的半监督新闻话语特征提取方法，通过利用新闻文章的结构特点来解决注释数据不足的问题，并在评估中证明了该方法的有效性。

    

    新闻话语特征提取旨在审查新闻文章中每个句子的事件相关角色，并已在各种下游应用中证明其有用性。具体而言，在给定新闻话语的情境中，每个句子都被分配到一个预定义的类别，取决于其对新闻事件结构的描述。然而，由于生成话语级注释的繁琐和耗时性质，现有方法存在可用人工注释数据的不足。在本文中，我们提出了一种新颖方法，称为内部文档对比学习与蒸馏（ICLD），用于解决新闻话语特征提取任务，利用其独特的结构特点。值得注意的是，我们是第一个在这个任务范式中应用半监督方法的研究，并且评估结果表明了该方法的有效性。

    News Discourse Profiling seeks to scrutinize the event-related role of each sentence in a news article and has been proven useful across various downstream applications. Specifically, within the context of a given news discourse, each sentence is assigned to a pre-defined category contingent upon its depiction of the news event structure. However, existing approaches suffer from an inadequacy of available human-annotated data, due to the laborious and time-intensive nature of generating discourse-level annotations. In this paper, we present a novel approach, denoted as Intra-document Contrastive Learning with Distillation (ICLD), for addressing the news discourse profiling task, capitalizing on its unique structural characteristics. Notably, we are the first to apply a semi-supervised methodology within this task paradigm, and evaluation demonstrates the effectiveness of the presented approach.
    
[^47]: LLM引导的归纳推理解决组合问题

    LLM Guided Inductive Inference for Solving Compositional Problems. (arXiv:2309.11688v1 [cs.CL])

    [http://arxiv.org/abs/2309.11688](http://arxiv.org/abs/2309.11688)

    LLM引导的归纳推理方法REBEL通过递归问题分解和利用外部工具进行推理，能够解决组合问题和对话环境中的深度推理任务。

    

    虽然大型语言模型（LLMs）在问答任务中表现出令人印象深刻的性能，但当问题需要通过直接观察或与真实世界的交互来获取模型训练数据中不包括的知识时，它们的性能受到限制。现有的方法通过顺序调用模块来对推理任务进行分解，限制了它们回答深度推理任务的能力。我们引入了一种方法，基于递归的可扩展LLM（REBEL），通过使用动态规划和前向链接策略等自动推理技术处理开放世界的深度推理任务。REBEL通过递归问题分解和利用外部工具进行推理。REBEL使用的工具仅通过自然语言描述来指定。我们进一步在组合和对话环境中的一组需要深度嵌套的外部工具使用问题上展示了REBEL的能力。

    While large language models (LLMs) have demonstrated impressive performance in question-answering tasks, their performance is limited when the questions require knowledge that is not included in the model's training data and can only be acquired through direct observation or interaction with the real world. Existing methods decompose reasoning tasks through the use of modules invoked sequentially, limiting their ability to answer deep reasoning tasks. We introduce a method, Recursion based extensible LLM (REBEL), which handles open-world, deep reasoning tasks by employing automated reasoning techniques like dynamic planning and forward-chaining strategies. REBEL allows LLMs to reason via recursive problem decomposition and utilization of external tools. The tools that REBEL uses are specified only by natural language description. We further demonstrate REBEL capabilities on a set of problems that require a deeply nested use of external tools in a compositional and conversational settin
    
[^48]: 机器翻译中的范式转变：提升大型语言模型的翻译性能

    A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models. (arXiv:2309.11674v1 [cs.CL])

    [http://arxiv.org/abs/2309.11674](http://arxiv.org/abs/2309.11674)

    本论文提出了一种基于先进语言模型的翻译器(ALMA)的微调方法，可以提升大型语言模型在翻译任务上的性能，消除了对大量平行数据的依赖。

    

    生成式大型语言模型(LLMs)在各种NLP任务中取得了显著进展。然而，在翻译任务中，尤其是那些具有适度模型大小（即7B或13B参数）的任务，这些进展尚未得到反映，仍然落后于传统的有监督编码器-解码器翻译模型。先前的研究试图改善这些适度LLMs的翻译能力，但其增益受到限制。在本研究中，我们提出了一种新颖的LLMs微调方法，专为翻译任务而设计，消除了传统翻译模型通常依赖大量平行数据的需求。我们的方法包括两个微调阶段：在单语数据上进行初始微调，然后在一小部分高质量平行数据上进行后续微调。我们通过这种策略开发的LLM被称为基于先进语言模型的翻译器(ALMA)。

    Generative Large Language Models (LLMs) have achieved remarkable advancements in various NLP tasks. However, these advances have not been reflected in the translation task, especially those with moderate model sizes (i.e., 7B or 13B parameters), which still lag behind conventional supervised encoder-decoder translation models. Previous studies have attempted to improve the translation capabilities of these moderate LLMs, but their gains have been limited. In this study, we propose a novel fine-tuning approach for LLMs that is specifically designed for the translation task, eliminating the need for the abundant parallel data that traditional translation models usually depend on. Our approach consists of two fine-tuning stages: initial fine-tuning on monolingual data followed by subsequent fine-tuning on a small set of high-quality parallel data. We introduce the LLM developed through this strategy as Advanced Language Model-based trAnslator (ALMA). Based on LLaMA-2 as our underlying mod
    
[^49]: 基于循环评估的配对知识图谱-文本数据集构建

    Construction of Paired Knowledge Graph-Text Datasets Informed by Cyclic Evaluation. (arXiv:2309.11669v1 [cs.CL])

    [http://arxiv.org/abs/2309.11669](http://arxiv.org/abs/2309.11669)

    本文通过循环评估验证了训练在等价性较差的数据集上的模型可能导致更多虚构和更差召回的问题。在此基础上，提出了一个改进的数据集LAGRANGE，使用启发式方法提高KG和文本之间的等价性。

    

    将知识图谱（KG）和文本配对的数据集（KG-T）可用于训练生成KG文本和相反的神经模型。然而，在KG和文本配对不等效的数据集上训练的模型可能导致更多的虚构和更差的召回。本文通过生成具有不同噪声级别的数据集来经验证实了这一点，并发现更嘈杂的数据集确实会导致更多的虚构。我们认为，训练在数据集上能够循环生成源KG或文本的正向和反向模型的能力是衡量KG和文本之间等价性的代理。通过循环评估，我们发现手动创建的WebNLG要比自动创建的TeKGen和T-REx好得多。在这些观察的指导下，我们使用旨在提高KG和文本等价性的启发式方法构建了一个新的、改进的数据集LAGRANGE，并展示了每个启发式方法对循环评估的影响。

    Datasets that pair Knowledge Graphs (KG) and text together (KG-T) can be used to train forward and reverse neural models that generate text from KG and vice versa. However models trained on datasets where KG and text pairs are not equivalent can suffer from more hallucination and poorer recall. In this paper, we verify this empirically by generating datasets with different levels of noise and find that noisier datasets do indeed lead to more hallucination. We argue that the ability of forward and reverse models trained on a dataset to cyclically regenerate source KG or text is a proxy for the equivalence between the KG and the text in the dataset. Using cyclic evaluation we find that manually created WebNLG is much better than automatically created TeKGen and T-REx. Guided by these observations, we construct a new, improved dataset called LAGRANGE using heuristics meant to improve equivalence between KG and text and show the impact of each of the heuristics on cyclic evaluation. We als
    
[^50]: 面向大型语言模型的机器翻译消歧效果研究

    Towards Effective Disambiguation for Machine Translation with Large Language Models. (arXiv:2309.11668v1 [cs.CL])

    [http://arxiv.org/abs/2309.11668](http://arxiv.org/abs/2309.11668)

    本文研究了大型语言模型(LLMs)在翻译歧义句子方面的能力，并通过上下文学习和歧义数据集微调提出了改进处理歧义的方法。实验证明，这些方法在多个语言方向上有着与最先进系统相当甚至超越的表现。这些研究为机器翻译的有效消歧提供了宝贵的见解。

    

    在机器翻译领域，解决语义歧义一直被认为是一个核心挑战。最近在歧义句子的翻译性能基准测试中，传统神经机器翻译系统的局限性暴露出来，无法捕捉到其中许多情况。大型语言模型(LLMs)已经成为一个有希望的替代方案，表现出与传统NMT模型相当的性能，并引入了控制目标输出的新范式。本文研究了LLMs在翻译包含多义词和稀有词义的歧义句子方面的能力，并提出了两种通过上下文学习和精心策划的歧义数据集微调来改进处理此类歧义的方法。实验证明，我们的方法在五个语言方向中有四个方向能够与DeepL和NLLB等最先进系统匹敌甚至超越。我们的研究为 effective disambiguation for machine translation 提供了有价值的见解。

    Resolving semantic ambiguity has long been recognised as a central challenge in the field of machine translation. Recent work on benchmarking translation performance on ambiguous sentences has exposed the limitations of conventional Neural Machine Translation (NMT) systems, which fail to capture many of these cases. Large language models (LLMs) have emerged as a promising alternative, demonstrating comparable performance to traditional NMT models while introducing new paradigms for controlling the target outputs. In this paper, we study the capabilities of LLMs to translate ambiguous sentences containing polysemous words and rare word senses. We also propose two ways to improve the handling of such ambiguity through in-context learning and fine-tuning on carefully curated ambiguous datasets. Experiments show that our methods can match or outperform state-of-the-art systems such as DeepL and NLLB in four out of five language directions. Our research provides valuable insights into effec
    
[^51]: 使用深度学习在阿尔及利亚方言中检测仇恨言论

    Hate speech detection in algerian dialect using deep learning. (arXiv:2309.11611v1 [cs.CL])

    [http://arxiv.org/abs/2309.11611](http://arxiv.org/abs/2309.11611)

    本研究提出了一个完整的方法，通过深度学习来检测在线阿尔及利亚信息中的仇恨言论。通过对阿尔及利亚社交网络上的语料库进行评估，我们获得了令人鼓舞的结果。

    

    随着社交网络上仇恨言论以不同的形式蔓延，如辱骂语言、网络欺凌和暴力等，人们在暴力方面经历了显著增加，使他们处于不适和威胁的境地。在过去几年中，人们已经投入大量的努力来克服这一现象，以检测不同结构语言（如英语、法语、阿拉伯语等）中的仇恨言论，并为阿拉伯方言（如突尼斯、埃及和海湾）进行了较少的研究。为了填补这一空白，我们在本文中提出了一个完整的方法，用于检测在线阿尔及利亚信息中的仇恨言论。我们评估了许多基于深度学习的架构，这些架构是从一些阿尔及利亚社交网络（Facebook、YouTube和Twitter）中创建的语料库上进行的。该语料库包含13.5K多篇阿拉伯语的阿尔及利亚方言文档，被标记为仇恨或非仇恨。我们获得了令人鼓舞的结果，显示出了该方法的有效性。

    With the proliferation of hate speech on social networks under different formats, such as abusive language, cyberbullying, and violence, etc., people have experienced a significant increase in violence, putting them in uncomfortable situations and threats. Plenty of efforts have been dedicated in the last few years to overcome this phenomenon to detect hate speech in different structured languages like English, French, Arabic, and others. However, a reduced number of works deal with Arabic dialects like Tunisian, Egyptian, and Gulf, mainly the Algerian ones. To fill in the gap, we propose in this work a complete approach for detecting hate speech on online Algerian messages. Many deep learning architectures have been evaluated on the corpus we created from some Algerian social networks (Facebook, YouTube, and Twitter). This corpus contains more than 13.5K documents in Algerian dialect written in Arabic, labeled as hateful or non-hateful. Promising results are obtained, which show the e
    
[^52]: SpeechAlign:一种用于语音翻译对齐评估的框架

    SpeechAlign: a Framework for Speech Translation Alignment Evaluation. (arXiv:2309.11585v1 [cs.CL])

    [http://arxiv.org/abs/2309.11585](http://arxiv.org/abs/2309.11585)

    SpeechAlign是一个用于评估语音模型中源目标对齐的框架，通过引入新的数据集和指标，为模型评估提供了一个可访问的评估框架，并且用于基准测试开源的语音翻译模型。

    

    语音到语音和语音到文本翻译目前是研究的动态领域。为了对这些领域做出贡献，我们提出了SpeechAlign，一种评估语音模型中源目标对齐这一未被充分研究的领域的框架。我们的框架有两个核心组成部分。首先，为了解决缺乏合适的评估数据集的问题，我们介绍了Speech Gold Alignment数据集，该数据集是在英德文本翻译的黄金对齐数据集基础上构建的。其次，我们引入了两个新的指标，语音对齐错误率（SAER）和时间加权语音对齐错误率（TW-SAER），用于评估语音模型中的对齐质量。通过发布SpeechAlign，我们提供了一个可访问的评估框架用于模型评估，并且我们使用它来对开源的语音翻译模型进行基准测试。

    Speech-to-Speech and Speech-to-Text translation are currently dynamic areas of research. To contribute to these fields, we present SpeechAlign, a framework to evaluate the underexplored field of source-target alignment in speech models. Our framework has two core components. First, to tackle the absence of suitable evaluation datasets, we introduce the Speech Gold Alignment dataset, built upon a English-German text translation gold alignment dataset. Secondly, we introduce two novel metrics, Speech Alignment Error Rate (SAER) and Time-weighted Speech Alignment Error Rate (TW-SAER), to evaluate alignment quality in speech models. By publishing SpeechAlign we provide an accessible evaluation framework for model assessment, and we employ it to benchmark open-source Speech Translation models.
    
[^53]: 通过多任务学习将单例和基于提及的特征纳入共指消解，以实现更好的泛化能力

    Incorporating Singletons and Mention-based Features in Coreference Resolution via Multi-task Learning for Better Generalization. (arXiv:2309.11582v1 [cs.CL])

    [http://arxiv.org/abs/2309.11582](http://arxiv.org/abs/2309.11582)

    本文通过多任务学习的方法，将单例和基于提及的特征纳入共指消解中，从而提高了泛化能力。模型在OntoGUM基准测试中取得了新的最高分，并在多个领域外数据集上增强了鲁棒性。

    

    先前在英语端到端神经共指消解中将提及检测步骤纳入其中的尝试由于缺乏单例提及段数据以及其他实体信息而受到阻碍。本文提出了一种共指模型，通过基于多任务学习的方法学习单例以及特征，例如实体类型和信息状态。与仅进行名词对匹配相比，此方法在OntoGUM基准测试中实现了新的最高分（+2.7分），并在多个领域外数据集上增强了鲁棒性（平均增加了2.3分），可能是由于提及检测的更好泛化能力以及更多单例数据的利用。

    Previous attempts to incorporate a mention detection step into end-to-end neural coreference resolution for English have been hampered by the lack of singleton mention span data as well as other entity information. This paper presents a coreference model that learns singletons as well as features such as entity type and information status via a multi-task learning-based approach. This approach achieves new state-of-the-art scores on the OntoGUM benchmark (+2.7 points) and increases robustness on multiple out-of-domain datasets (+2.3 points on average), likely due to greater generalizability for mention detection and utilization of more data from singletons when compared to only coreferent mention pair matching.
    
[^54]: 考察基于静态数据集训练的计算化谣言检测模型的局限性

    Examining the Limitations of Computational Rumor Detection Models Trained on Static Datasets. (arXiv:2309.11576v1 [cs.CL])

    [http://arxiv.org/abs/2309.11576](http://arxiv.org/abs/2309.11576)

    本文通过深入评估基于内容和基于上下文模型在检测新的未知谣言上的性能差距，发现基于上下文的模型过度依赖来源帖子信息并忽略了上下文信息的重要作用。实验结果也提出了减小时间概念影响的实际建议。

    

    谣言检测模型的一个关键方面是其泛化能力，特别是其能够检测出新出现的、以前未知的谣言的能力。过去的研究表明，仅基于内容（即仅使用来源帖子作为输入）的谣言检测模型在未知谣言上的表现效果较差。与此同时，基于上下文的模型的潜力尚未充分利用。本文的主要贡献在于深入评估基于内容和基于上下文模型在特别是检测新的未知谣言上的性能差距。我们的实证研究结果表明，基于上下文的模型仍然过度依赖来自谣言来源帖子的信息，并倾向于忽略上下文信息可能发挥的重要作用。我们还研究了数据拆分策略对分类器性能的影响。根据我们的实验结果，本文还提出了如何减小时间概念影响的实际建议。

    A crucial aspect of a rumor detection model is its ability to generalize, particularly its ability to detect emerging, previously unknown rumors. Past research has indicated that content-based (i.e., using solely source posts as input) rumor detection models tend to perform less effectively on unseen rumors. At the same time, the potential of context-based models remains largely untapped. The main contribution of this paper is in the in-depth evaluation of the performance gap between content and context-based models specifically on detecting new, unseen rumors. Our empirical findings demonstrate that context-based models are still overly dependent on the information derived from the rumors' source post and tend to overlook the significant role that contextual information can play. We also study the effect of data split strategies on classifier performance. Based on our experimental results, the paper also offers practical suggestions on how to minimize the effects of temporal concept d
    
[^55]: BTLM-3B-8K: 一个3B参数模型中使用7B参数性能的研究

    BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model. (arXiv:2309.11568v1 [cs.AI])

    [http://arxiv.org/abs/2309.11568](http://arxiv.org/abs/2309.11568)

    BTLM-3B-8K是一个30亿参数的开源语言模型，相对于其他30亿和70亿参数模型，它在下游任务中表现出2-5.5%的性能提升，同时在长文本任务上也具有出色的表现。这种将70亿参数的模型压缩到30亿参数，并且性能几乎没有受到影响的方法具有重要意义。

    

    我们介绍了Bittensor语言模型, 名为"BTLM-3B-8K", 这是一个新的、拥有30亿参数的开源语言模型. BTLM-3B-8K在SlimPajama数据集上进行了训练，训练数据为627B个token，采用了2048和8192的混合上下文长度. BTLM-3B-8K在下游任务中的表现比所有现有的30亿参数模型提高了2-5.5% ，甚至与一些70亿参数模型相媲美. 另外，BTLM-3B-8K在长文本上的表现也很好，在长度为8192的任务上超过了MPT-7B-8K和XGen-7B-8K. 我们在清理和去重的SlimPajama数据集上训练了模型，对µP超参数和调度进行了调优，使用了ALiBi位置嵌入和SwiGLU非线性. 在Hugging Face上，最受欢迎的模型是70亿参数，这表明用户更倾向于质量大小比为70亿参数的模型. 将70亿参数模型压缩为30亿参数，性能几乎没有影响，这是一个重要的里程碑.

    We introduce the Bittensor Language Model, called "BTLM-3B-8K", a new state-of-the-art 3 billion parameter open-source language model. BTLM-3B-8K was trained on 627B tokens from the SlimPajama dataset with a mixture of 2,048 and 8,192 context lengths. BTLM-3B-8K outperforms all existing 3B parameter models by 2-5.5% across downstream tasks. BTLM-3B-8K is even competitive with some 7B parameter models. Additionally, BTLM-3B-8K provides excellent long context performance, outperforming MPT-7B-8K and XGen-7B-8K on tasks up to 8,192 context length. We trained the model on a cleaned and deduplicated SlimPajama dataset; aggressively tuned the \textmu P hyperparameters and schedule; used ALiBi position embeddings; and adopted the SwiGLU nonlinearity.  On Hugging Face, the most popular models have 7B parameters, indicating that users prefer the quality-size ratio of 7B models. Compacting the 7B parameter model to one with 3B parameters, with little performance impact, is an important milestone
    
[^56]: SignBank +：多语种手语翻译数据集

    SignBank+: Multilingual Sign Language Translation Dataset. (arXiv:2309.11566v1 [cs.CL])

    [http://arxiv.org/abs/2309.11566](http://arxiv.org/abs/2309.11566)

    该论文介绍了SignBank+，这是一个经过优化的手语翻译数据集，通过简化文本对文本翻译方法，提升了手语机器翻译模型的性能，并为未来的研究提供了一个开放的资源。

    

    该研究通过关注数据集的质量和简化翻译系统，推进手语机器翻译领域。我们引入了SignBank+，这是SignBank数据集的优化版本，经过清理以适用于机器翻译。与以往采用复杂的分解技术进行翻译的方法不同，我们主张采用简化的文本对文本翻译方法。我们的评估表明，在SignBank+数据集上训练的模型超过了原始数据集上的模型，建立了一个新的基准，并为未来的研究提供了一个开放的资源。

    This work advances the field of sign language machine translation by focusing on dataset quality and simplification of the translation system. We introduce SignBank+, a clean version of the SignBank dataset, optimized for machine translation. Contrary to previous works that employ complex factorization techniques for translation, we advocate for a simplified text-to-text translation approach. Our evaluation shows that models trained on SignBank+ surpass those on the original dataset, establishing a new benchmark and providing an open resource for future research.
    
[^57]: 带有自然语言子目标的层次强化学习

    Hierarchical reinforcement learning with natural language subgoals. (arXiv:2309.11564v1 [cs.LG])

    [http://arxiv.org/abs/2309.11564](http://arxiv.org/abs/2309.11564)

    本文介绍了一种层次强化学习的新方法，使用来自人类解决任务的数据来监督一组长程任务的目标空间，并使用自然语言来描述这个空间，该方法在克隆专家行为的代理和无监督子目标空间的层次强化学习中表现出色。

    

    层次强化学习一直是一种实现长序列动作目标导向行为的有吸引力的方法。然而，在现实或开放环境中实现层次强化学习是具有挑战性的。主要的挑战之一是找到适合实例化层次的子目标空间。我们提出了一种新方法，利用人类解决这些任务的数据，对3D躯体环境中一组长程任务的目标空间进行软监督。特别是，我们使用非约束的自然语言来参数化这个空间。这有两个优点：首先，可以从天真的人类参与者那里轻松生成这些数据；其次，它足够灵活，能够表示人类相关任务中的一大范围子目标。我们的方法在这些任务上优于克隆专家行为的代理和没有这种受监督子目标空间的从头开始的层次强化学习方法。我们的工作提出了一种将人类专家监督与这种受益相结合的新方法。

    Hierarchical reinforcement learning has been a compelling approach for achieving goal directed behavior over long sequences of actions. However, it has been challenging to implement in realistic or open-ended environments. A main challenge has been to find the right space of sub-goals over which to instantiate a hierarchy. We present a novel approach where we use data from humans solving these tasks to softly supervise the goal space for a set of long range tasks in a 3D embodied environment. In particular, we use unconstrained natural language to parameterize this space. This has two advantages: first, it is easy to generate this data from naive human participants; second, it is flexible enough to represent a vast range of sub-goals in human-relevant tasks. Our approach outperforms agents that clone expert behavior on these tasks, as well as HRL from scratch without this supervised sub-goal space. Our work presents a novel approach to combining human expert supervision with the benefi
    
[^58]: 基于LLM的短文本答案自动评分方法研究

    Towards LLM-based Autograding for Short Textual Answers. (arXiv:2309.11508v1 [cs.CL])

    [http://arxiv.org/abs/2309.11508](http://arxiv.org/abs/2309.11508)

    本文评估了大型语言模型（LLMs）在自动评分中的应用，并强调了它们如何支持教育工作者验证评分程序。研究结果表明，“开箱即用”的LLMs作为补充视角提供了有价值的工具，但仍需进一步优化其可用性和性能。

    

    考试的评分是一项重要的、劳动密集的、主观的、重复的且常常具有挑战性的任务。大型语言模型（LLMs）如ChatGPT的可用性和数字化带来的大量数据的涌入， greatly increased autograding textual responses的可行性。然而，将决策角色交给AI模型引起了伦理考虑，主要源于潜在偏见和生成虚假信息的问题。因此，在本文中，我们评估了一个大型语言模型用于自动评分，同时强调了LLMs如何支持教育工作者验证其评分程序。我们的评估针对自动短文本答案评分（ASAG），涵盖了两个不同课程的各种语言和考试。我们的研究结果表明，“开箱即用”的LLMs提供了一个有价值的工具，可以提供补充的视角，但它们的可用性和性能在实际应用中还需进一步优化。

    Grading of exams is an important, labor intensive, subjective, repetitive and frequently challenging task. The feasibility of autograding textual responses has greatly increased thanks to the availability of large language models (LLMs) such as ChatGPT and because of the substantial influx of data brought about by digitalization. However, entrusting AI models with decision-making roles raises ethical considerations, mainly stemming from potential biases and issues related to generating false information. Thus, in this manuscript we provide an evaluation of a large language model for the purpose of autograding, while also highlighting how LLMs can support educators in validating their grading procedures. Our evaluation is targeted towards automatic short textual answers grading (ASAG), spanning various languages and examinations from two distinct courses. Our findings suggest that while "out-of-the-box" LLMs provide a valuable tool to provide a complementary perspective, their readiness
    
[^59]: 使用大型语言模型将表元数据与业务词汇匹配

    Matching Table Metadata with Business Glossaries Using Large Language Models. (arXiv:2309.11506v1 [cs.IR])

    [http://arxiv.org/abs/2309.11506](http://arxiv.org/abs/2309.11506)

    本研究探讨了将表元数据与业务词汇进行匹配的问题，通过匹配可以在不请求访问数据内容之前或之后，有效利用可用的业务词汇进行检索和分析。

    

    企业通常拥有大量的结构化数据，以大型数据库或企业数据湖的形式存在。这些数据集往往具有有限的元数据和严格的访问策略，这可能限制对数据内容的访问，并因此限制了经典的检索和分析解决方案的应用。因此，需要能够有效利用可用元数据的解决方案。本文研究了将表元数据与包含数据标签和描述的业务词汇匹配的问题。通过匹配，可以在不请求访问数据内容之前或之后，利用可用或策划的业务词汇进行检索和分析。解决这个问题的一种方法是使用手动定义的规则或相似度度量在列名和词汇描述（或它们的向量嵌入）之间找到最匹配的项。然而，这种方法需要通过手动标注进行调整，并且不能处理许多业务词汇。

    Enterprises often own large collections of structured data in the form of large databases or an enterprise data lake. Such data collections come with limited metadata and strict access policies that could limit access to the data contents and, therefore, limit the application of classic retrieval and analysis solutions. As a result, there is a need for solutions that can effectively utilize the available metadata. In this paper, we study the problem of matching table metadata to a business glossary containing data labels and descriptions. The resulting matching enables the use of an available or curated business glossary for retrieval and analysis without or before requesting access to the data contents. One solution to this problem is to use manually-defined rules or similarity measures on column names and glossary descriptions (or their vector embeddings) to find the closest match. However, such approaches need to be tuned through manual labeling and cannot handle many business gloss
    
[^60]: Text2Reward：针对强化学习的自动生成密集奖励函数的自动化框架

    Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning. (arXiv:2309.11489v1 [cs.LG])

    [http://arxiv.org/abs/2309.11489](http://arxiv.org/abs/2309.11489)

    Text2Reward是一个无需数据的自动化框架，可以根据大型语言模型自动生成可解释、自由形式的密集奖励函数，广泛适用于各种任务，并允许人类反馈进行迭代改进。

    

    设计奖励函数是强化学习中长期以来的挑战；它需要专业知识或领域数据，导致开发成本高。为了解决这个问题，我们引入了Text2Reward，一个无需数据的框架，可基于大型语言模型（LLM）自动生成密集奖励函数。给定自然语言描述的目标，Text2Reward生成作为环境紧凑表示的可执行程序的密集奖励函数。与逆强化学习和最近使用LLM编写稀疏奖励代码的工作不同，Text2Reward生成可解释的、自由形式的密集奖励代码，可涵盖各种任务，利用现有软件包，并允许通过人类反馈进行迭代改进。我们在两个机器人操作基准（ManiSkill2，MetaWorld）和两个MuJoCo的运动环境上评估了Text2Reward。在17个操作任务中的13个任务中，使用生成的奖励代码训练的政策实现了类似或更好的性能。

    Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development. To address this, we introduce Text2Reward, a data-free framework that automates the generation of dense reward functions based on large language models (LLMs). Given a goal described in natural language, Text2Reward generates dense reward functions as an executable program grounded in a compact representation of the environment. Unlike inverse RL and recent work that uses LLMs to write sparse reward codes, Text2Reward produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback. We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2, MetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17 manipulation tasks, policies trained with generated reward codes achieve similar or better
    
[^61]: 你仅关注屏幕：多模态动作链机器人

    You Only Look at Screens: Multimodal Chain-of-Action Agents. (arXiv:2309.11436v1 [cs.CL])

    [http://arxiv.org/abs/2309.11436](http://arxiv.org/abs/2309.11436)

    本论文提出了一种名为Auto-UI的多模态动作链机器人，通过直接与界面交互，避免了环境解析或依赖于应用程序API的需要，并引入了动作链技术来帮助模型进行决策。

    

    自主用户界面（UI）机器人旨在通过与用户界面进行交互，实现任务自动化，无需手动干预。最近的研究探讨了利用大型语言模型（LLM）的能力，以在多样环境中有效参与。为了符合LLM的输入-输出要求，现有方法在沙盒环境中开发，依赖于外部工具和应用程序特定的API将环境解析为文本元素，并解释预测的动作。因此，这些方法常常受到推理效率低和错误传播风险的困扰。为了缓解这些挑战，我们引入了Auto-UI，一种多模态解决方案，它直接与界面交互，避免了对环境解析或依赖于应用程序相关的API的需求。此外，我们提出了一种动作链技术，利用一系列中间先前动作历史和未来动作计划，以帮助模型进行决策。

    Autonomous user interface (UI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To align with the input-output requirement of LLMs, existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions. Consequently, those approaches often grapple with inference inefficiency and error propagation risks. To mitigate the challenges, we introduce Auto-UI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs. Moreover, we propose a chain-of-action technique -leveraging a series of intermediate previous action histories and future action plans -- to help the age
    
[^62]: 提取-改写-回答：一种用于知识图谱问答的增强型LLMs框架

    Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering. (arXiv:2309.11206v1 [cs.CL])

    [http://arxiv.org/abs/2309.11206](http://arxiv.org/abs/2309.11206)

    提出了一种提高知识图谱问答任务性能的增强型LLMs框架，通过转化KG知识为文本化陈述的方式，实现了对答案敏感的KG-to-Text方法。

    

    尽管大型语言模型（LLMs）在知识密集型任务上表现出色，但仍然存在在记忆所有世界知识，尤其是长尾知识方面的局限性。本文研究了基于知识图谱增强语言模型的方法，用于解决需要丰富世界知识的知识图谱问答（KGQA）任务。现有的工作表明，检索知识图谱（KG）以增强LLMs提示可以显著改善KGQA中LLMs的性能。然而，他们的方法缺乏基于文本的合理表述KG知识，即忽略了KG表示和文本表示之间的差距。为此，我们提出了一种对答案敏感的KG-to-Text方法，可以将KG知识转化为最具信息量的文本化陈述，用于KGQA。基于该方法，我们提出了一种用于解决KGQA任务的增强型KG-to-Text LLMS框架。在几个KGQA基准上的实验表明，所提出的KG-to-Text增强LLMs方法在性能上表现优异。

    Despite their competitive performance on knowledge-intensive tasks, large language models (LLMs) still have limitations in memorizing all world knowledge especially long tail knowledge. In this paper, we study the KG-augmented language model approach for solving the knowledge graph question answering (KGQA) task that requires rich world knowledge. Existing work has shown that retrieving KG knowledge to enhance LLMs prompting can significantly improve LLMs performance in KGQA. However, their approaches lack a well-formed verbalization of KG knowledge, i.e., they ignore the gap between KG representations and textual representations. To this end, we propose an answer-sensitive KG-to-Text approach that can transform KG knowledge into well-textualized statements most informative for KGQA. Based on this approach, we propose a KG-to-Text enhanced LLMs framework for solving the KGQA task. Experiments on several KGQA benchmarks show that the proposed KG-to-Text augmented LLMs approach outperfor
    
[^63]: Fake News BR: 一种用于巴西葡萄牙语的假新闻检测平台

    Fake News BR: A Fake News Detection Platform for Brazilian Portuguese. (arXiv:2309.11052v1 [cs.CL])

    [http://arxiv.org/abs/2309.11052](http://arxiv.org/abs/2309.11052)

    本研究提出了一个用于巴西葡萄牙语的假新闻检测平台，采用机器学习和自然语言处理技术，能够高效准确地识别假新闻，同时提供实时分析和验证新闻文章真实性的用户友好平台。

    

    由于假新闻传播误导公众舆论的潜力，其传播已成为近期关注的一个重要问题。本文对巴西葡萄牙语中的假新闻检测进行了全面的研究，重点关注新闻类型。我们提出了一种基于机器学习的方法，利用自然语言处理技术，包括TF-IDF和Word2Vec，从文本数据中提取特征。我们评估了各种分类算法的性能，如逻辑回归、支持向量机、随机森林、AdaBoost和LightGBM，使用包含真实和假新闻文章的数据集。所提出的方法在准确率和F1得分上都取得了高水平，证明了其识别假新闻的有效性。此外，我们开发了一个用户友好的网站平台FAKENEWSBR.COM，以便验证新闻文章的真实性。我们的平台提供实时分析，允许用户检查新闻文章的真实性。

    The proliferation of fake news has become a significant concern in recent times due to its potential to spread misinformation and manipulate public opinion. In this paper, we present a comprehensive study on the detection of fake news in Brazilian Portuguese, focusing on journalistic-type news. We propose a machine learning-based approach that leverages natural language processing techniques, including TF-IDF and Word2Vec, to extract features from textual data. We evaluate the performance of various classification algorithms, such as logistic regression, support vector machine, random forest, AdaBoost, and LightGBM, on a dataset containing both true and fake news articles. The proposed approach achieves a high level of accuracy and F1-Score, demonstrating its effectiveness in identifying fake news. Additionally, we develop a user-friendly web platform, FAKENEWSBR.COM, to facilitate the verification of news articles' veracity. Our platform provides real-time analysis, allowing users to 
    
[^64]: 本文提出了一个广义框架，用于通过表格进行自由形式问答：定位、检索和融合。

    Localize, Retrieve and Fuse: A Generalized Framework for Free-Form Question Answering over Tables. (arXiv:2309.11049v1 [cs.CL])

    [http://arxiv.org/abs/2309.11049](http://arxiv.org/abs/2309.11049)

    本文提出了一个广义框架，用于处理表格上的自由形式问答，在选取相关的表格单元、检索外部知识、以及推理集成时面临的挑战进行了探索。

    

    近年来，表格数据上的问答（TableQA）已经引起了越来越多的关注。现有的工作倾向于从一个或几个表格单元中提取信息，生成事实性的简短答案，而缺乏对选定表格单元进行推理的能力。然而，自由形式的TableQA需要更复杂的相关表格单元选择策略和独立信息的复杂集成和推理，这方面的研究还不充分。为此，本文提出了一个广义的三阶段方法：表格到图的转换和单元定位、外部知识检索和表格-文本融合（称为TAG-QA），以解决生成式TableQA中针对长自由形式答案的推理挑战。具体而言，TAG-QA (1) 使用图神经网络定位相关表格单元，以收集相关行和列之间的交叉单元；(2) 利用维基百科的外部知识；(3)...

    Question answering on tabular data (TableQA), which aims at generating answers to questions grounded on a given table, has attracted increasing attention in recent years. Existing work tends to generate factual short-form answers by extracting information from one or a few table cells without reasoning over selected table cells. However, the free-form TableQA, requiring a more complex relevant table cell selection strategy and the complex integration and inference of separate pieces of information, has been under-explored. To this end, this paper proposes a generalized three-stage approach: Table-to-Graph conversion and cell localizing, external knowledge retrieval and table-text fusion (called TAG-QA), addressing the challenge of inferring long free-form answer for generative TableQA. In particular, TAG-QA (1) locates relevant table cells using a graph neural network to gather intersecting cells between relevant rows and columns; (2) leverages external knowledge from Wikipedia and (3)
    
[^65]: 通过学习表示和影响函数，我们能从对抗样本中获得什么信息

    What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples. (arXiv:2309.10916v1 [cs.LG])

    [http://arxiv.org/abs/2309.10916](http://arxiv.org/abs/2309.10916)

    本文将图像处理领域中的对抗子空间技术应用于自然语言处理，提出了基于最近邻和影响函数的检测器，并通过使用影响函数揭示了自然语言处理中的对抗样本子空间与图像处理中的子空间的关系和任务差异。

    

    对抗样本是通过微小扰动来欺骗深度神经网络的，起初在图像处理领域进行研究，最近在自然语言处理领域也开始关注。尽管在自然语言处理中检测对抗样本的方法主要依赖于输入扰动的搜索，但图像处理领域已经发展出一系列技术来表征学习表示中的对抗子空间。本文将这两种方法应用于自然语言处理，一种基于最近邻和影响函数，一种基于马氏距离。特别是前者相比几个强基准产生了最先进的检测器；此外，对影响函数的新颖使用揭示了自然语言处理中的对抗样本子空间与图像处理中的子空间的关系，并展示了它们根据不同自然语言处理任务的差异。

    Adversarial examples, deliberately crafted using small perturbations to fool deep neural networks, were first studied in image processing and more recently in NLP. While approaches to detecting adversarial examples in NLP have largely relied on search over input perturbations, image processing has seen a range of techniques that aim to characterise adversarial subspaces over the learned representations.  In this paper, we adapt two such approaches to NLP, one based on nearest neighbors and influence functions and one on Mahalanobis distances. The former in particular produces a state-of-the-art detector when compared against several strong baselines; moreover, the novel use of influence functions provides insight into how the nature of adversarial example subspaces in NLP relate to those in image processing, and also how they differ depending on the kind of NLP task.
    
[^66]: L1感知多语言发音错误检测框架

    L1-aware Multilingual Mispronunciation Detection Framework. (arXiv:2309.07719v1 [cs.CL])

    [http://arxiv.org/abs/2309.07719](http://arxiv.org/abs/2309.07719)

    本文介绍了一种L1感知的多语言发音错误检测框架，该框架通过注意力机制对齐输入音频和参考音素序列，并将预训练的辅助模型提取的L1-L2语音嵌入与主要网络进行融合。该框架在英文、阿拉伯语和普通话上的统一多语言音素识别任务中取得了良好的效果。

    

    说话者的母语(L1)和非母语(L2)之间的语音差异是发音错误的主要因素。本文介绍了一种新颖的多语言MDD架构——L1-MultiMDD框架，该框架通过L1感知的语音表示进行增强。首先，通过注意力机制将输入音频与参考音素序列进行对齐。然后，从在多任务设置中预先训练的辅助模型中提取L1-L2语音嵌入，并将其与主要网络进行融合。最后，通过连接时序分类(CTC)损失优化L1-MultiMDD框架，用于目标语言英文、阿拉伯语和普通话的统一多语言音素识别任务。实验证明了所提出的L1-MultiMDD框架在已见数据集L2-ARTIC、LATIC和AraVoiceL2上的有效性。

    The phonological discrepancies between a speaker's native (L1) and the non-native language (L2) serves as a major factor for mispronunciation. This paper introduces a novel multilingual MDD architecture, L1-MultiMDD, enriched with L1-aware speech representation. An end-to-end speech encoder is trained on the input signal and its corresponding reference phoneme sequence. First, an attention mechanism is deployed to align the input audio with the reference phoneme sequence. Afterwards, the L1-L2-speech embedding are extracted from an auxiliary model, pretrained in a multi-task setup identifying L1 and L2 language, and are infused with the primary network. Finally, the L1-MultiMDD is then optimized for a unified multilingual phoneme recognition task using connectionist temporal classification (CTC) loss for the target languages: English, Arabic, and Mandarin. Our experiments demonstrate the effectiveness of the proposed L1-MultiMDD framework on both seen -- L2-ARTIC, LATIC, and AraVoiceL2
    
[^67]: CPPF: 一种上下文和后处理无关的自动语音识别模型

    CPPF: A contextual and post-processing-free model for automatic speech recognition. (arXiv:2309.07413v1 [cs.CL])

    [http://arxiv.org/abs/2309.07413](http://arxiv.org/abs/2309.07413)

    CPPF是一种上下文和后处理无关的自动语音识别模型，它整合了多个与语音识别相关的ASR文本处理任务，提供了一种优化流程、避免级联错误传播且识别性能几乎没有损失的解决方案。

    

    近年来，ASR系统变得越来越广泛应用。然而，它们的文本输出通常需要经过后处理任务才能实际利用。为了解决这个问题，我们从LLMs和Whisper的多方面能力中获得启发，专注于将与语音识别相关的多个ASR文本处理任务整合到ASR模型中。这种整合不仅缩短了多阶段的流程，还防止了级联错误的传播，从而直接生成后处理过的文本。本研究重点关注与ASR相关的处理任务，包括上下文ASR和多个ASR后处理任务。为了实现这一目标，我们引入了CPPF模型，它提供了一种多功能和高效的ASR处理替代方案。CPPF无缝地整合了这些任务，而且识别性能几乎没有明显的损失。

    ASR systems have become increasingly widespread in recent years. However, their textual outputs often require post-processing tasks before they can be practically utilized. To address this issue, we draw inspiration from the multifaceted capabilities of LLMs and Whisper, and focus on integrating multiple ASR text processing tasks related to speech recognition into the ASR model. This integration not only shortens the multi-stage pipeline, but also prevents the propagation of cascading errors, resulting in direct generation of post-processed text. In this study, we focus on ASR-related processing tasks, including Contextual ASR and multiple ASR post processing tasks. To achieve this objective, we introduce the CPPF model, which offers a versatile and highly effective alternative to ASR processing. CPPF seamlessly integrates these tasks without any significant loss in recognition performance.
    
[^68]: ConDA: 基于对比域适应的AI生成文本检测

    ConDA: Contrastive Domain Adaptation for AI-generated Text Detection. (arXiv:2309.03992v1 [cs.CL])

    [http://arxiv.org/abs/2309.03992](http://arxiv.org/abs/2309.03992)

    创新点：提出了一种基于对比域适应的框架 ConDA，用于检测由大型语言模型生成的新闻文本。这种方法解决了获取标记训练数据的困难，通过利用未标记的目标数据进行无监督域适应。

    

    大型语言模型（LLMs）越来越多地被用于各种用途的文本生成，包括新闻报道。鉴于这些LLMs可能被恶意使用来大规模生成虚假信息，构建有效的检测AI生成文本的工具显得尤为重要。由于新的LLMs不断被开发，获取用于监督式检测器的标记训练数据成为一个瓶颈。然而，可能存在大量未标记的文本数据，没有关于其生成器的信息。在这项工作中，我们解决了此数据问题，即检测AI生成的新闻文本，并将问题框架化为无监督域适应任务。这里的域是不同的文本生成器，即LLMs，我们假设只能访问标记的源数据和未标记的目标数据。我们开发了一个名为ConDA的对比域适应框架，将标准的域适应技术与表示能力相结合。

    Large language models (LLMs) are increasingly being used for generating text in a variety of use cases, including journalistic news articles. Given the potential malicious nature in which these LLMs can be used to generate disinformation at scale, it is important to build effective detectors for such AI-generated text. Given the surge in development of new LLMs, acquiring labeled training data for supervised detectors is a bottleneck. However, there might be plenty of unlabeled text data available, without information on which generator it came from. In this work we tackle this data problem, in detecting AI-generated news text, and frame the problem as an unsupervised domain adaptation task. Here the domains are the different text generators, i.e. LLMs, and we assume we have access to only the labeled source data and unlabeled target data. We develop a Contrastive Domain Adaptation framework, called ConDA, that blends standard domain adaptation techniques with the representation power 
    
[^69]: 授权难民申请者及其律师：使用机器学习研究难民法决策

    Empowering Refugee Claimants and their Lawyers: Using Machine Learning to Examine Decision-Making in Refugee Law. (arXiv:2308.11531v1 [cs.CL])

    [http://arxiv.org/abs/2308.11531](http://arxiv.org/abs/2308.11531)

    这项研究的目标是通过使用机器学习来提高难民法决策的智能化和透明度，实现更好的决策结果。研究涉及检索过去的案例和分析加拿大案例数据集的法律决策流程。通过基于自然语言处理的解决方案和新的基准，研究希望为所有相关利益相关者带来包容性和预期的好处。

    

    我们的项目旨在通过数据驱动的智能来帮助和支持难民地位审理的相关利益相关者，如律师、法官、管理机构和申请人，以便更好地做出决策，并增加难民申请流程的理解和透明度。这个博士项目有两个主要目标：（1）检索过去的案例，（2）在加拿大案例数据集上分析法律决策流程。在本文中，我们介绍了我们工作的当前状态，包括对（1）部分的完成试验和与（2）部分相关的持续努力。我们相信基于自然语言处理的解决方案很适合应对这些挑战，并研究了自动化所涉及的所有步骤的可行性。此外，我们介绍了未来难民法自然语言处理研究的新基准。我们的方法旨在包容所有最终用户和利益相关者，并带来预期的好处，包括减少决策时间，更公平地决策过程。

    Our project aims at helping and supporting stakeholders in refugee status adjudications, such as lawyers, judges, governing bodies, and claimants, in order to make better decisions through data-driven intelligence and increase the understanding and transparency of the refugee application process for all involved parties. This PhD project has two primary objectives: (1) to retrieve past cases, and (2) to analyze legal decision-making processes on a dataset of Canadian cases. In this paper, we present the current state of our work, which includes a completed experiment on part (1) and ongoing efforts related to part (2). We believe that NLP-based solutions are well-suited to address these challenges, and we investigate the feasibility of automating all steps involved. In addition, we introduce a novel benchmark for future NLP research in refugee law. Our methodology aims to be inclusive to all end-users and stakeholders, with expected benefits including reduced time-to-decision, fairer a
    
[^70]: LatEval: 一个带有来自侧思维谜题的不完整信息的交互式LLMs评估基准

    LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete Information from Lateral Thinking Puzzles. (arXiv:2308.10855v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10855](http://arxiv.org/abs/2308.10855)

    LatEval是一个新颖的LLMs评估基准，通过侧思维谜题挑战模型的横向思考能力，在交互过程中考验模型提出问题的质量和整合信息解决问题的能力。研究发现，几乎所有LLMs在横向思考方面存在困难，即使是最先进的GPT-4模型相比人类也有明显差距。这个基准测试对于有效的AI助理至关重要。

    

    随着LLMs的不断发展和改进，它们被赋予了令人印象深刻的逻辑推理或纵向思维能力。但它们能否跳出固定模式思考？它们是否具备高超的横向思考能力？在侧思维谜题的基础上，我们提出了一个新颖的评估基准，称为LatEval，它在一个交互式框架中评估模型的横向思考能力。在我们的基准测试中，我们向LLMs提出了两个方面的挑战：模型提出的问题的质量和模型在解决问题时整合信息的能力。我们发现几乎所有的LLMs在交互过程中都很难运用横向思考。例如，即使是最先进的模型GPT-4，在某种程度上也具有优势，但与人类相比仍存在明显差距。这个评估基准为LLMs提供了一个极具挑战性和独特的任务，对于有效的人工智能助理至关重要。

    With the continuous evolution and refinement of LLMs, they are endowed with impressive logical reasoning or vertical thinking capabilities. But can they think out of the box? Do they possess proficient lateral thinking abilities? Following the setup of Lateral Thinking Puzzles, we propose a novel evaluation benchmark, LatEval, which assesses the model's lateral thinking within an interactive framework. In our benchmark, we challenge LLMs with 2 aspects: the quality of questions posed by the model and the model's capability to integrate information for problem-solving. We find that nearly all LLMs struggle with employing lateral thinking during interactions. For example, even the most advanced model, GPT-4, exhibits the advantage to some extent, yet still maintain a noticeable gap when compared to human. This evaluation benchmark provides LLMs with a highly challenging and distinctive task that is crucial to an effective AI assistant.
    
[^71]: 大型语言模型的指令调优：一项调研

    Instruction Tuning for Large Language Models: A Survey. (arXiv:2308.10792v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10792](http://arxiv.org/abs/2308.10792)

    本文调查了指令调优这一关键技术在增强大型语言模型能力和可控性方面的研究工作，包括方法、数据集构建、模型训练和应用，以及对结果影响的分析。同时回顾了可能的问题和批评，并指出了目前的不足。

    

    本文调查了指令调优（IT）这一快速发展的领域中的研究工作，这是一种增强大型语言模型（LLM）能力和可控性的关键技术。指令调优是指以监督方式在包含“指令-输出”对的数据集上进一步训练LLM，这将LLM的下一个词预测目标与用户希望LLM遵守人类指令的目标之间的差距。本文对IT的常规方法、IT数据集的构建、IT模型的训练以及应用于不同模态、领域和应用的情况进行了系统的文献综述，并对影响IT结果的各个方面进行了分析（例如，指令输出的生成、指令数据集的大小等）。我们还回顾了IT的潜在问题以及针对其的批评，以及指出当前不足的努力。

    This paper surveys research works in the quickly advancing field of instruction tuning (IT), a crucial technique to enhance the capabilities and controllability of large language models (LLMs). Instruction tuning refers to the process of further training LLMs on a dataset consisting of \textsc{(instruction, output)} pairs in a supervised fashion, which bridges the gap between the next-word prediction objective of LLMs and the users' objective of having LLMs adhere to human instructions. In this work, we make a systematic review of the literature, including the general methodology of IT, the construction of IT datasets, the training of IT models, and applications to different modalities, domains and applications, along with an analysis on aspects that influence the outcome of IT (e.g., generation of instruction outputs, size of the instruction dataset, etc). We also review the potential pitfalls of IT along with criticism against it, along with efforts pointing out current deficiencies 
    
[^72]: Scope is all you need: Transforming LLMs for HPC Code (arXiv:2308.09440v2 [cs.CL] UPDATED)

    Scope is all you need: Transforming LLMs for HPC Code. (arXiv:2308.09440v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.09440](http://arxiv.org/abs/2308.09440)

    本研究旨在质疑现有大型语言模型（LLMs）在高性能计算（HPC）领域中的应用，并通过开发针对特定领域的小型LLMs来解决该问题。具体而言，我们为HPC开发了一种名为Tokompiler的新型标记器，用于代码预处理和编译任务。

    

    随着强大计算资源的更容易获取，AI领域的软件开发越来越倾向于开发更大的语言模型（LLMs）来解决各种编程任务。即使应用于高性能计算（HPC）领域的LLMs也非常庞大（例如，数十亿个参数），并且需要昂贵的计算资源进行训练。我们发现这种设计选择令人困惑-为什么我们需要在与HPC不相关的自然语言和编程语言上训练的大型LLMs来处理HPC特定任务？在这一系列工作中，我们旨在质疑现有LLMs所做的设计选择，通过为特定领域开发更小的LLMs-我们称之为领域特定LLMs。具体而言，我们以HPC为领域开始，并提出了一种名为Tokompiler的新型标记器，专门用于HPC中的代码预处理和编译中心任务。Tokompiler利用语言原语的知识生成面向语言的标记，提供了一种新的预处理方法。

    With easier access to powerful compute resources, there is a growing trend in the field of AI for software development to develop larger and larger language models (LLMs) to address a variety of programming tasks. Even LLMs applied to tasks from the high-performance computing (HPC) domain are huge in size (e.g., billions of parameters) and demand expensive compute resources for training. We found this design choice confusing - why do we need large LLMs trained on natural languages and programming languages unrelated to HPC for HPC-specific tasks? In this line of work, we aim to question design choices made by existing LLMs by developing smaller LLMs for specific domains - we call them domain-specific LLMs. Specifically, we start off with HPC as a domain and propose a novel tokenizer named Tokompiler, designed specifically for preprocessing code in HPC and compilation-centric tasks. Tokompiler leverages knowledge of language primitives to generate language-oriented tokens, providing a c
    
[^73]: 将Whisper转化为实时转录系统

    Turning Whisper into Real-Time Transcription System. (arXiv:2307.14743v1 [cs.CL])

    [http://arxiv.org/abs/2307.14743](http://arxiv.org/abs/2307.14743)

    本文介绍了一个基于Whisper的实时语音转录和翻译系统Whisper-Streaming，通过使用本地协议策略和自适应延迟，实现了流式转录。实验结果表明Whisper-Streaming在未分割的长篇演讲转录测试集上具有高质量和低延迟，并且在实际多语种会议中的应用也具有鲁棒性和实用性。

    

    Whisper是最近的一种最先进的多语种语音识别和翻译模型，然而，它并不适用于实时转录。在本文中，我们在Whisper的基础上构建了Whisper-Streaming，这是一个实时语音转录和翻译实现Whisper类模型的系统。Whisper-Streaming使用本地协议策略和自适应延迟，实现了流式转录。我们展示了Whisper-Streaming在未分割的长篇演讲转录测试集上达到了高质量和3.3秒的延迟，并展示了它作为一个多语种会议实时转录服务组件的鲁棒性和实用性。

    Whisper is one of the recent state-of-the-art multilingual speech recognition and translation models, however, it is not designed for real time transcription. In this paper, we build on top of Whisper and create Whisper-Streaming, an implementation of real-time speech transcription and translation of Whisper-like models. Whisper-Streaming uses local agreement policy with self-adaptive latency to enable streaming transcription. We show that Whisper-Streaming achieves high quality and 3.3 seconds latency on unsegmented long-form speech transcription test set, and we demonstrate its robustness and practical usability as a component in live transcription service at a multilingual conference.
    
[^74]: 大型语言模型能够生成显著的负面声明吗？

    Can large language models generate salient negative statements?. (arXiv:2305.16755v1 [cs.CL])

    [http://arxiv.org/abs/2305.16755](http://arxiv.org/abs/2305.16755)

    本研究探讨了大型语言模型生成真实实体的显著负面陈述的能力，在不同领域中进行了评估，结果发现大型语言模型在处理否定陈述中的事实概念上仍有困难。

    

    我们研究了大型语言模型（LLMs）生成关于现实世界实体的显著（有趣的）负面陈述的能力; 这是过去几年中涌现出的一个研究课题。我们使用零点和k次无约束探针来探测LLMs，并与传统的否定生成方法，即基于模式的文本提取和基于知识图的推理以及众包金标语句进行比较。我们评估了来自不同领域的主题生成列表的正确性和显着性。我们的评估表明，有指导的探针确实提高了生成的负面陈述的质量，与无指导的变体相比。然而，使用这两个提示，LLMs仍然难以处理负面事实的概念，常常生成许多含糊不清的陈述，或者带有负面关键词但具有积极意义的陈述。

    We examine the ability of large language models (LLMs) to generate salient (interesting) negative statements about real-world entities; an emerging research topic of the last few years. We probe the LLMs using zero- and k-shot unconstrained probes, and compare with traditional methods for negation generation, i.e., pattern-based textual extractions and knowledge-graph-based inferences, as well as crowdsourced gold statements. We measure the correctness and salience of the generated lists about subjects from different domains. Our evaluation shows that guided probes do in fact improve the quality of generated negatives, compared to the zero-shot variant. Nevertheless, using both prompts, LLMs still struggle with the notion of factuality of negatives, frequently generating many ambiguous statements, or statements with negative keywords but a positive meaning.
    
[^75]: 零样本分类中的提示复杂性导航：一项关于大型语言模型在计算社会科学中的研究

    Navigating Prompt Complexity for Zero-Shot Classification: A Study of Large Language Models in Computational Social Science. (arXiv:2305.14310v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14310](http://arxiv.org/abs/2305.14310)

    本研究通过评估两个大型语言模型在六个计算社会科学分类任务中的零样本性能，并研究了各种提示策略的影响。结果显示，当前的大型语言模型在零样本设置下无法与较小的微调基线模型相媲美。

    

    语言调整的大型语言模型(LLMs)展示出了令人印象深刻的语言理解能力，并且具有根据特定提示生成响应的能力。然而，由于训练这些模型所需的计算需求，它们的应用通常采用零样本设置。在本文中，我们评估了两个公开可访问的LLM，ChatGPT和OpenAssistant在六个计算社会科学分类任务的零样本性能，同时还研究了各种提示策略的影响。我们的实验调查了提示复杂性的影响，包括在提示中加入标签定义的效果；使用标签名称的同义词；以及在基础模型训练过程中整合过去记忆的影响。研究结果表明，在零样本设置下，目前的LLMs无法达到较小的微调基线转换模型（如BERT-large）的性能。此外，我们发现...

    Instruction-tuned Large Language Models (LLMs) have exhibited impressive language understanding and the capacity to generate responses that follow specific prompts. However, due to the computational demands associated with training these models, their applications often adopt a zero-shot setting. In this paper, we evaluate the zero-shot performance of two publicly accessible LLMs, ChatGPT and OpenAssistant, in the context of six Computational Social Science classification tasks, while also investigating the effects of various prompting strategies. Our experiments investigate the impact of prompt complexity, including the effect of incorporating label definitions into the prompt; use of synonyms for label names; and the influence of integrating past memories during foundation model training. The findings indicate that in a zero-shot setting, current LLMs are unable to match the performance of smaller, fine-tuned baseline transformer models (such as BERT-large). Additionally, we find tha
    
[^76]: 在政治宣言中，现任/反对派地位和意识形态相似度对情绪的影响

    The Impact of Incumbent/Opposition Status and Ideological Similitude on Emotions in Political Manifestos. (arXiv:2305.08383v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08383](http://arxiv.org/abs/2305.08383)

    本研究分析了英国保守党和工党大选宣言中的情感语言，并发现现任党派更倾向于使用积极情感词汇，而反对派党派更倾向于使用负面情感词汇。同时，意识形态相似的党派也更多地使用积极语言。

    

    本研究分析了英国保守党和工党2000年至2019年的大选宣言中与情绪相关的语言。虽然以前的研究已经表明意识形态定位和公共政策的重叠之间存在一般的相关性，但在这类宣言中涉及情感方面仍存在矛盾的结果。利用新的数据，我们展示了党派地位对情感价值水平的影响，现任党派呈现更多与积极情绪相关的词语，而反对派党派中更多负面情绪相关的词语。我们还证明了意识形态相似的党派更多地使用积极语言，进一步增加了情绪与党派地位之间关系的文献。

    The study involved the analysis of emotion-associated language in the UK Conservative and Labour party general election manifestos between 2000 to 2019. While previous research have shown a general correlation between ideological positioning and overlap of public policies, there are still conflicting results in matters of sentiments in such manifestos. Using new data, we present how valence level can be swayed by party status within government with incumbent parties presenting a higher frequency in positive emotion-associated words while negative emotion-associated words are more prevalent in opposition parties. We also demonstrate that parties with ideological similitude use positive language prominently further adding to the literature on the relationship between sentiments and party status.
    
[^77]: ERNIE-Music: 使用扩散模型的文本到波形音乐生成

    ERNIE-Music: Text-to-Waveform Music Generation with Diffusion Models. (arXiv:2302.04456v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2302.04456](http://arxiv.org/abs/2302.04456)

    本文提出了ERNIE-Music，一种基于扩散模型的文本到波形音乐生成模型。通过创新地利用自由形式的文本提示作为条件因素，我们成功实现了从文本到音乐波形的生成。通过利用网络资源构建数据集并采用弱监督技术，我们解决了有限的文本-音乐平行数据的挑战。我们还对比了两种不同的文本条件格式的有效性，为该领域的研究提供了实证结果。

    

    近年来，对扩散模型的兴趣日益增加，这导致了图像和语音生成方面的重大进展。然而，从无限制的文本提示直接合成音乐波形仍然是一个相对未被充分探索的领域。为了填补这一空白，本文介绍了一种创新性贡献，即以扩散模型为基础的文本到波形音乐生成模型。我们的方法依赖于将自由形式的文本提示作为有条件的因素，以指导扩散模型框架内的波形生成过程。为了解决有限的文本-音乐平行数据的挑战，我们通过利用网络资源来创建一个数据集，这一任务得到了弱监督技术的帮助。此外，我们进行了严格的实证调查，对比了两种不同的文本条件格式的有效性，即音乐标签和无约束的文本描述。

    In recent years, the burgeoning interest in diffusion models has led to significant advances in image and speech generation. Nevertheless, the direct synthesis of music waveforms from unrestricted textual prompts remains a relatively underexplored domain. In response to this lacuna, this paper introduces a pioneering contribution in the form of a text-to-waveform music generation model, underpinned by the utilization of diffusion models. Our methodology hinges on the innovative incorporation of free-form textual prompts as conditional factors to guide the waveform generation process within the diffusion model framework. Addressing the challenge of limited text-music parallel data, we undertake the creation of a dataset by harnessing web resources, a task facilitated by weak supervision techniques. Furthermore, a rigorous empirical inquiry is undertaken to contrast the efficacy of two distinct prompt formats for text conditioning, namely, music tags and unconstrained textual description
    
[^78]: 忠实的推理链思考

    Faithful Chain-of-Thought Reasoning. (arXiv:2301.13379v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13379](http://arxiv.org/abs/2301.13379)

    这篇论文提出了一种忠实的推理链思考框架，通过翻译和问题求解两个阶段，确保推理链能忠实解释最终答案。它在复杂推理任务上的性能得到了提升，并在多个基准测试上超过了标准的推理链方法。

    

    虽然思考链（CoT）提示可以增强语言模型（LM）在各种复杂推理任务上的性能，但生成的推理链不一定反映模型如何得出答案（即忠实性）。我们提出了忠实的CoT，这是一个涉及两个阶段的推理框架：翻译（自然语言查询$\rightarrow$符号推理链）和问题求解（推理链$\rightarrow$答案），分别使用一个语言模型和一个确定性求解器。这保证了推理链提供了对最终答案的忠实解释。除了可解释性外，忠实的CoT还提高了经验性能：它在来自4个不同领域的10个基准测试中，优于标准的CoT，数学问题（MWP）的相对准确性提高了6.3％，规划提高了3.4％，多跳问答（QA）提高了5.5％，关系推理提高了21.4％。此外，借助GPT-4和Codex，在7个数据集上获得了最新的少样本性能.

    While Chain-of-Thought (CoT) prompting boosts Language Models' (LM) performance on a gamut of complex reasoning tasks, the generated reasoning chain does not necessarily reflect how the model arrives at the answer (aka. faithfulness). We propose Faithful CoT, a reasoning framework involving two stages: Translation (Natural Language query $\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning chain $\rightarrow$ answer), using an LM and a deterministic solver respectively. This guarantees that the reasoning chain provides a faithful explanation of the final answer. Aside from interpretability, Faithful CoT also improves empirical performance: it outperforms standard CoT on 9 of 10 benchmarks from 4 diverse domains, with a relative accuracy gain of 6.3% on Math Word Problems (MWP), 3.4% on Planning, 5.5% on Multi-hop Question Answering (QA), and 21.4% on Relational Inference. Furthermore, with GPT-4 and Codex, it sets the new state-of-the-art few-shot performance on 7 dat
    
[^79]: 面向方面的情感分析数据集调查

    Survey of Aspect-based Sentiment Analysis Datasets. (arXiv:2204.05232v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.05232](http://arxiv.org/abs/2204.05232)

    本研究汇总了65个公开可用的ABSA数据集，包括45个英文数据集和20个其他语言数据集，提供了一个可以用于训练和评估自主ABSA系统的数据库。

    

    面向方面的情感分析(ABSA)是一个自然语言处理问题，需要分析用户生成的评论以确定：a)正在审查的目标实体，b)属于哪个高级方面，c)对目标和方面表达的情感。ABSA的众多但分散的语料库使研究人员很难快速确定最适合特定ABSA子任务的语料库。本研究旨在提供一个可以用于训练和评估自主ABSA系统的数据库。此外，我们提供了ABSA和其子任务的主要语料库概述，并强调研究人员在选择语料库时应考虑的几个特征。最后，我们讨论了当前收集方法的优缺点并为未来语料库创建提出建议。本调查审核了65个公开可用的ABSA数据集，涵盖25个领域，包括45个英语和20个其他语言的数据集。

    Aspect-based sentiment analysis (ABSA) is a natural language processing problem that requires analyzing user-generated reviews to determine: a) The target entity being reviewed, b) The high-level aspect to which it belongs, and c) The sentiment expressed toward the targets and the aspects. Numerous yet scattered corpora for ABSA make it difficult for researchers to identify corpora best suited for a specific ABSA subtask quickly. This study aims to present a database of corpora that can be used to train and assess autonomous ABSA systems. Additionally, we provide an overview of the major corpora for ABSA and its subtasks and highlight several features that researchers should consider when selecting a corpus. Finally, we discuss the advantages and disadvantages of current collection approaches and make recommendations for future corpora creation. This survey examines 65 publicly available ABSA datasets covering over 25 domains, including 45 English and 20 other languages datasets.
    
[^80]: 跨语言情况下，大多数简单从句中的语法线索是多余的

    Grammatical cues to subjecthood are redundant in a majority of simple clauses across languages. (arXiv:2201.12911v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.12911](http://arxiv.org/abs/2201.12911)

    借助语法线索来确定句子的主语在大多数简单从句中是多余的，这个冗余性在跨语言中也存在。在这项研究中，通过行为实验和计算分析，我们发现这种冗余性的发生频率很高，这有助于揭示语法的功能和演化。

    

    在自然语言中，语法线索有时与词义重复。例如，英语的词序规则限制了句子的词序，即使可以从世界知识和可信性推断出"dog"作为主语，"bone"作为宾语的状态。量化这种冗余的发生频率，以及冗余水平在不同类型的语言中如何变化，可以揭示语法的功能和演化。为此，我们在英语和俄语中进行了一项行为实验，并进行了跨语言的计算分析，测量从语料库文本中提取的及物从句中语法线索的冗余程度。英语和俄语的参与者（n = 484）被呈现由自然发生的句子中提取的主语、动词和宾语（以随机顺序和删除形态标记），并被要求确定哪个名词是行为的主语。两种语言的准确率都很高（〜

    Grammatical cues are sometimes redundant with word meanings in natural language. For instance, English word order rules constrain the word order of a sentence like "The dog chewed the bone" even though the status of "dog" as subject and "bone" as object can be inferred from world knowledge and plausibility. Quantifying how often this redundancy occurs, and how the level of redundancy varies across typologically diverse languages, can shed light on the function and evolution of grammar. To that end, we performed a behavioral experiment in English and Russian and a cross-linguistic computational analysis measuring the redundancy of grammatical cues in transitive clauses extracted from corpus text. English and Russian speakers (n=484) were presented with subjects, verbs, and objects (in random order and with morphological markings removed) extracted from naturally occurring sentences and were asked to identify which noun is the subject of the action. Accuracy was high in both languages (~
    

