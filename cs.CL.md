# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Text2Cohort: Democratizing the NCI Imaging Data Commons with Natural Language Cohort Discovery.](http://arxiv.org/abs/2305.07637) | Text2Cohort是一个基于大语言模型的工具箱，可以将用户输入转化为IDC数据库查询，促进自然语言队列发现，减少研究人员查询IDC数据库的学习曲线，实现了癌症成像数据的民主化。 |
| [^2] | [PALR: Personalization Aware LLMs for Recommendation.](http://arxiv.org/abs/2305.07622) | 本文提出了一个称为PALR的框架，将用户的历史行为与LLMs相结合，生成用户喜欢的物品的推荐。与现有的推荐方法相比，我们的PALR框架实现了最先进的性能。 |
| [^3] | [What are the Desired Characteristics of Calibration Sets? Identifying Correlates on Long Form Scientific Summarization.](http://arxiv.org/abs/2305.07615) | 现有的总结模型由于训练过程中单个参考的可能性，生成的文本与质量指标不匹配。本文通过对不同校准集的研究，找出了最佳设置的共同特点，即在校准前将正负分开，谨慎选择负例，大胆对待正例。 |
| [^4] | [NevIR: Negation in Neural Information Retrieval.](http://arxiv.org/abs/2305.07614) | 本研究探讨了否定在神经信息检索中的影响，构建了基准模型，结果表明当前信息检索模型大多数都没有考虑否定，而交叉编码器是目前表现最好的架构。 |
| [^5] | [Multimodal Sentiment Analysis: A Survey.](http://arxiv.org/abs/2305.07611) | 本综述介绍了多模态情感分析的定义、发展和挑战，讨论了最新的数据集和先进模型，并提出了有前途的研究方向和构建更好性能的建议。 |
| [^6] | [Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation.](http://arxiv.org/abs/2305.07609) | 这篇论文介绍了一种新的推荐范式——通过LLM进行推荐，但由于LLMs可能存在社会偏见，需要进一步调查RecLLM所做推荐的公正性。为此，作者提出了一个新的公平性基准——FaiRLLM，并针对音乐和电影推荐场景中的八个敏感属性进行了评估。 |
| [^7] | [A Memory Model for Question Answering from Streaming Data Supported by Rehearsal and Anticipation of Coreference Information.](http://arxiv.org/abs/2305.07565) | 该论文提出了一种记忆模型，在处理流式数据时，通过排练和预期来记忆有关问题回答任务的重要信息。该模型应用自监督机制，通过核指代信息的屏蔽建模任务训练，成功通过短序列数据集和大型基准测试。 |
| [^8] | [Measuring Progress in Fine-grained Vision-and-Language Understanding.](http://arxiv.org/abs/2305.07558) | 本文旨在量化测量细粒度视觉语言理解方面的进展，探究了四个竞争的V&L模型在四个精细基准任务上的表现。研究发现X-VLM模型始终优于其他模型，并强调了新颖的损失和丰富的数据源对于学习细粒度技能的重要性。同时，该研究还揭示了部分模型在某些任务上存在视觉和语言之间的潜在分离。 |
| [^9] | [LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development.](http://arxiv.org/abs/2305.07507) | 本文对面向法律的预训练语言模型进行了详细分析，发布了一个跨国英语法律文集和一个法律知识探针基准，发现探针性能与上游性能强相关，下游性能主要由模型的大小和先前的法律知识驱动。 |
| [^10] | [A Comprehensive Analysis of Adapter Efficiency.](http://arxiv.org/abs/2305.07491) | 适配器虽然是一种参数有效的微调方法，但是在训练/部署效率和可维护性/可扩展性方面并没有实现PEFT的优势，相对的，可以使用更简单的方法，如多任务训练来实现可维护性/可扩展性的优势。 |
| [^11] | [ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4.](http://arxiv.org/abs/2305.07490) | ArtGPT-4是一种基于适配器增强的MiniGPT-4模型，专注于解决图像理解方面的问题，能够在短时间内训练出具备良好视觉语言理解能力的多模态模型。 |
| [^12] | [Comprehensive Solution Program Centric Pretraining for Table-and-Text Hybrid Numerical Reasoning.](http://arxiv.org/abs/2305.07475) | 本文提出了面向表格与文本混合数值推理的全面预训练解决方案，通过变量完整性排序、变量运算预测和变量关键词屏蔽等任务鼓励模型关注有用的变量和确定子程序来源的关键证据，实验结果超过了基于Transformer的模型基线。 |
| [^13] | [BactInt: A domain driven transfer learning approach and a corpus for extracting inter-bacterial interactions from biomedical text.](http://arxiv.org/abs/2305.07468) | BactInt是一种面向领域的自动化方法，使用迁移学习从生物医学文本中提取细菌间相互作用并挖掘特定细菌群之间的关系。公开可用的BactInt语料库标注了1200篇PubMed摘要。 |
| [^14] | [Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation.](http://arxiv.org/abs/2305.07457) | 本文介绍了一种透明、无监督的词级质量估计方法，它可以通过分析扰动的输入源句子上机器翻译系统输出来工作，并可以评估任何类型的黑盒机器翻译系统。使用该方法作为反馈信号，可以在无监督的领域自适应中改进机器翻译系统的质量。 |
| [^15] | [Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation.](http://arxiv.org/abs/2305.07455) | 该论文提出了一种基于级联的语音翻译系统，使用完全非配对的数据来训练无监督系统。通过采用去噪反向翻译技术，成功提高了所有三个翻译方向的BLEU得分0.7-0.9。 |
| [^16] | [QVoice: Arabic Speech Pronunciation Learning Application.](http://arxiv.org/abs/2305.07445) | QVoice是一种阿拉伯语发音学习应用程序，旨在帮助非母语者提高发音技能，同时帮助母语者避免地区方言对现代标准阿拉伯语发音的影响。 |
| [^17] | [Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding.](http://arxiv.org/abs/2305.07424) | 本文提出了IS-CSE方法，通过实例平滑对比学习来学习无监督句子嵌入，以平滑嵌入在特征空间中的边界，从而提高模型的泛化性能。在标准的STS任务中取得了良好的得分。 |
| [^18] | [Two-in-One: A Model Hijacking Attack Against Text Generation Models.](http://arxiv.org/abs/2305.07406) | 本文扩展了模型劫持攻击的范围，提出了一种名为Ditto的攻击方法，能够将不同的文本分类任务劫持为多个生成任务，并使用多个基准数据集验证了攻击的成功性。 |
| [^19] | [Knowledge Refinement via Interaction Between Search Engines and Large Language Models.](http://arxiv.org/abs/2305.07402) | 本文介绍了一种新的框架InteR，通过搜索引擎和大型语言模型之间的交互促进知识精炼，从而提高检索准确性。 |
| [^20] | [Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation.](http://arxiv.org/abs/2305.07393) | 本文提出了一种提示学习方法，以解决开放域非英语语言对话系统中少量数据下的跨语言迁移学习和多任务学习中的灾难性遗忘问题，并在六种语言上的实验中证明了其有效性。 |
| [^21] | [Investigating the Sensitivity of Automatic Speech Recognition Systems to Phonetic Variation in L2 Englishes.](http://arxiv.org/abs/2305.07389) | 本文旨在探索自然语言处理的语音识别系统对L2英语语音变体的敏感度，提高识别准确率和手动纠正的效率，为冷门语言的自然语言处理提供了新思路。 |
| [^22] | [Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation.](http://arxiv.org/abs/2305.07375) | 本文对ChatGPT的因果推理能力进行了首次全面评估，实验证明ChatGPT是一个好的因果解释者，但不是一个好的因果推理者，存在严重的因果幻觉问题，对于明确的因果关系表现良好。 |
| [^23] | [Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations.](http://arxiv.org/abs/2305.07372) | 本文介绍一种交互机制，允许用户直接编辑一步步解释错误SQL以修复SQL错误，实验证明方法提高了31.6％的执行准确性。用户研究表明，该方法帮助用户以更少的时间和更高的信心解决了更多的SQL任务。 |
| [^24] | [Towards Transliteration between Sindhi Scripts from Devanagari to Perso-Arabic.](http://arxiv.org/abs/2305.07365) | 本文提出了一种将天城文辛迪转换为波斯-阿拉伯文辛迪的技术，通过混合使用基于规则和概率模型，系统取得了99.64％的准确率。 |
| [^25] | [Improving the Quality of Neural Machine Translation Through Proper Translation of Name Entities.](http://arxiv.org/abs/2305.07360) | 本文提出了一种方法，通过将命名实体作为预处理步骤进行翻译/音译，以提高神经机器翻译的质量，实验结果显示该方法能够正确翻译大多数的命名实体，准确率高达99.52％。 |
| [^26] | [Towards Versatile and Efficient Visual Knowledge Injection into Pre-trained Language Models with Cross-Modal Adapters.](http://arxiv.org/abs/2305.07358) | 本文提出了X-adapter插拔式模块，利用多模态视觉语言模型，高效地向预训练语言模型注入视觉知识。 |
| [^27] | [ZARA: Improving Few-Shot Self-Rationalization for Small Language Models.](http://arxiv.org/abs/2305.07355) | 本文提出了一种名为ZARA的方法，其可以通过将合理性判断问题转化为自然语言推理来自动构建伪平行数据进行自我训练，从而提高小型语言模型的少样本自我解释性能，实验结果表明ZARA在任务准确性和解释质量上都表现出SOTA水平。 |
| [^28] | [Model-based Programming: Redefining the Atomic Unit of Programming for the Deep Learning Era.](http://arxiv.org/abs/2305.07341) | 本文提出一种新的编程范式——基于模型的编程，旨在解决深度学习模型部署过程中的问题。推出的M语言将模型作为基本的计算单位，加强了开发人员进行关键任务的效率，这种创新的编程范式将彻底改变我们使用深度学习模型的方式。 |
| [^29] | [Improving Zero-shot Multilingual Neural Machine Translation by Leveraging Cross-lingual Consistency Regularization.](http://arxiv.org/abs/2305.07310) | 本文提出了一种跨语言一致性规范化方法CrossConST，用于改进零样本多语言神经机器翻译模型的性能。实验结果表明，CrossConST可以缩小语言之间的表示差距，提高零样本翻译的准确性和多样性。 |
| [^30] | [Multi-Relational Hyperbolic Word Embeddings from Natural Language Definitions.](http://arxiv.org/abs/2305.07303) | 本论文提出了一种从自然语言定义中学习多关系双曲词向量的框架，以捕捉由定义所引起的分层和多分辨率结构。 |
| [^31] | [RepCL: Exploring Effective Representation for Continual Text Classification.](http://arxiv.org/abs/2305.07289) | 本文探讨了类增量设置下的持续文本分类问题中的表示偏见，从信息瓶颈的角度提出了利用更多类相关信息消除偏见的方法，即RepCL方法，并证明了其能有效地解决遗忘问题并实现最先进的性能。 |
| [^32] | [Harvesting Event Schemas from Large Language Models.](http://arxiv.org/abs/2305.07280) | 本论文提出了一种新的事件模式诱导范式，通过从大型预训练语言模型中收割知识来自动诱导高质量和高覆盖范围的事件模式。 |
| [^33] | [Gaussian Prior Reinforcement Learning for Nested Named Entity Recognition.](http://arxiv.org/abs/2305.07266) | 该论文提出了一种嵌套命名实体识别模型GPRL，使用高斯先验调整嵌套边界标记的输出概率分布，采用强化学习方法生成实体三元组，无需考虑金标签中的实体顺序，实验结果显示其优于以前的嵌套NER模型。 |
| [^34] | [Better speech synthesis through scaling.](http://arxiv.org/abs/2305.07243) | 该论文介绍了一种将图像生成方法应用于语音合成领域的方法，提出了一个表达性强、多语音的文本转语音系统TorToise。 |
| [^35] | [When Giant Language Brains Just Aren't Enough! Domain Pizzazz with Knowledge Sparkle Dust.](http://arxiv.org/abs/2305.07230) | 本文将保险问答作为案例研究，提出了一种新模型，通过从保险政策手册中提取领域特定知识来增强LLMs的性能，实现领域适应，从而显著提高推理准确性。 |
| [^36] | [Asymmetric feature interaction for interpreting model predictions.](http://arxiv.org/abs/2305.07224) | 本文提出了一种解释模型，能够探索深度神经自然语言处理模型推理中的非对称高阶特征交互。在两个情感分类数据集上的实验结果表明，该模型在识别影响特征方面优于现有特征交互归因方法。 |
| [^37] | [OneCAD: One Classifier for All image Datasets using multimodal learning.](http://arxiv.org/abs/2305.07167) | 本文提出了一种训练和推断框架OneCAD，通过Mask-Image-Modeling(MIM)和多模态学习解决了当前架构(如ViTs和CNNs)存在的问题，并创建了一种可以适用于所有图像数据集且与类别数无关的DNN模型架构。 |
| [^38] | [Exploring Zero and Few-shot Techniques for Intent Classification.](http://arxiv.org/abs/2305.07157) | 探讨了四种零样本和小样本意图分类方法，包括领域适应、数据增强、使用大型语言模型的零样本意图分类以及指令微调语言模型的参数有效微调，结果表明这些方法在低资源环境下都是有效的。指令微调语言模型的参数有效微调性能最佳。 |
| [^39] | [Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-Text Rationales.](http://arxiv.org/abs/2305.07095) | 该论文研究了机器产生的自然语言理由对人类是否有用，发现现有理由的人类效用远低于理想状态，并提出通过估计理由在回答给定问题中的有用性来提高机器生成理由的人类效用。 |
| [^40] | [Enhancing Contrastive Learning with Noise-Guided Attack: Towards Continual Relation Extraction in the Wild.](http://arxiv.org/abs/2305.07085) | 本研究提出了一种耐噪声的对比框架 NaCl 来在嘈杂标签下学习逐步受损的关系，相比于直接丢弃或重新标记噪声，通过攻击特征空间使其适应嘈杂标签是更好的方式。 |
| [^41] | [Quran Recitation Recognition using End-to-End Deep Learning.](http://arxiv.org/abs/2305.07034) | 本文提出了一种基于端到端深度学习模型，使用CTC作为目标函数，来识别古兰经的朗诵。采用公共数据集进行实验。 |
| [^42] | [Musketeer (All for One, and One for All): A Generalist Vision-Language Model with Task Explanation Prompts.](http://arxiv.org/abs/2305.07019) | Musketeer是一种通用视觉语言模型，采用任务解释提示（TEP）机制，能够有效整合异构任务的知识，并在多个任务中表现均匀 |
| [^43] | [ChatGPT-Like Large-Scale Foundation Models for Prognostics and Health Management: A Survey and Roadmaps.](http://arxiv.org/abs/2305.06472) | 该论文综述了基于大规模基础模型（LSF-Models）如ChatGPT和DALLE-E的人工智能（AI）技术在预测与健康管理（PHM）中的广泛应用。这种技术可以实现多模态、多任务、大量数据和超大模型范式，成为AI-2.0的新时代的标志之一。 |
| [^44] | [SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models.](http://arxiv.org/abs/2305.05189) | 本文提出了一个名为SUR-adapter的微调方法，用于增强预先训练的文本到图像扩散模型的语义理解和常识推理能力，以便在生成图片时使用简短的叙述提示。作者还构建了一个新的数据集SURD，并使用大型语言模型的知识进行了优化。 |
| [^45] | [Neuromodulation Gated Transformer.](http://arxiv.org/abs/2305.03232) | 本文介绍了一种新型的神经调节门控Transformer架构，通过乘法效应实现了神经调节，在SuperGLUE基准验证集上表现最优。 |
| [^46] | [ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations.](http://arxiv.org/abs/2304.14827) | 本论文评估了ChatGPT在句子级别的时间、因果和语篇关系任务中的性能，发现其在检测和推理因果关系上表现出色，但在识别时间顺序方面可能存在问题。 |
| [^47] | [GPT-NER: Named Entity Recognition via Large Language Models.](http://arxiv.org/abs/2304.10428) | 本文提出了GPT-NER来解决大型语言模型在命名实体识别任务（NER）上表现不佳的问题，它通过将序列标记任务转化为生成任务，将LLM能够容易地适应NER任务。同时，为了有效解决LLMs“幻觉”问题，作者们提出了自我验证策略，通过提示LLMs询问自身来确定提取的实体是否属于实际存在的实体。 |
| [^48] | [PLUE: Language Understanding Evaluation Benchmark for Privacy Policies in English.](http://arxiv.org/abs/2212.10011) | PLUE是一个多任务评估基准，用于评估英文隐私政策语言理解的各种任务。研究者还收集了大量的隐私政策语料库，以支持隐私政策领域特定语言模型的预训练，持续预训练可以提高性能。 |
| [^49] | [RHO ($\rho$): Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding.](http://arxiv.org/abs/2212.01588) | 本文介绍了一种名为RHO ($\rho$)的方法，利用知识图谱中链接实体和关系谓词的表示来减少对话系统中产生的幻觉，提高了对话推理能力，并采用基于知识图谱子图漫步的回复重新排序技术。 |
| [^50] | [GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective.](http://arxiv.org/abs/2211.08073) | 本文提出了第一个创建名为方法的统一基准的尝试，用于评估NLP模型中的OOD鲁棒性，该基准包括13个公开可用的OOD测试数据集，并在21个常用的PLMs上对8个经典NLP任务进行评估。 |
| [^51] | [Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning.](http://arxiv.org/abs/2211.03044) | 该论文通过调整预训练语言模型生成大量新的训练样本，从而增强原始训练集，提高了少样本学习的性能。 |

# 详细

[^1]: Text2Cohort: 自然语言队列发现对癌症影像数据共享平台的民主化

    Text2Cohort: Democratizing the NCI Imaging Data Commons with Natural Language Cohort Discovery. (arXiv:2305.07637v1 [cs.LG])

    [http://arxiv.org/abs/2305.07637](http://arxiv.org/abs/2305.07637)

    Text2Cohort是一个基于大语言模型的工具箱，可以将用户输入转化为IDC数据库查询，促进自然语言队列发现，减少研究人员查询IDC数据库的学习曲线，实现了癌症成像数据的民主化。

    

    影像数据共享平台(IDC)是一个基于云的数据库，为研究人员提供开放获取的癌症成像数据和分析工具，旨在促进医学成像研究中的协作。然而，由于其复杂和技术性质，查询IDC数据库以进行队列发现和访问成像数据对研究人员来说具有显著的学习曲线。我们开发了基于大语言模型（LLM）的Text2Cohort工具箱，通过提示工程将用户输入转化为IDC数据库查询，并将查询的响应返回给用户，以促进自然语言队列发现。此外，实现了自动校正以解决查询中的语法和语义错误，通过将错误传回模型进行解释和校正。我们对50个自然语言用户输入进行了Text2Cohort评估，范围从信息提取到队列发现。结果查询和输出由两位计算机科学家进行了确认。

    The Imaging Data Commons (IDC) is a cloud-based database that provides researchers with open access to cancer imaging data and tools for analysis, with the goal of facilitating collaboration in medical imaging research. However, querying the IDC database for cohort discovery and access to imaging data has a significant learning curve for researchers due to its complex and technical nature. We developed Text2Cohort, a large language model (LLM) based toolkit to facilitate natural language cohort discovery by translating user input into IDC database queries through prompt engineering and returning the query's response to the user. Furthermore, autocorrection is implemented to resolve syntax and semantic errors in queries by passing the errors back to the model for interpretation and correction. We evaluate Text2Cohort on 50 natural language user inputs ranging from information extraction to cohort discovery. The resulting queries and outputs were verified by two computer scientists to me
    
[^2]: 个性化感知的推荐系统中的LMMs模型

    PALR: Personalization Aware LLMs for Recommendation. (arXiv:2305.07622v1 [cs.IR])

    [http://arxiv.org/abs/2305.07622](http://arxiv.org/abs/2305.07622)

    本文提出了一个称为PALR的框架，将用户的历史行为与LLMs相结合，生成用户喜欢的物品的推荐。与现有的推荐方法相比，我们的PALR框架实现了最先进的性能。

    

    大型语言模型(LLMs)由于其出色的性能而受到越来越多的关注。本文提出了一种新的框架PALR，将用户的历史行为与LLMs相结合，以生成用户喜欢的物品的推荐。我们首先使用用户/物品互动作为候选检索的指导，然后采用基于LLMs的排序模型生成推荐物品。实验结果表明，与现有的推荐方法相比，我们提出的PALR框架实现了最先进的性能。

    Large language models (LLMs) have recently received significant attention for their exceptional capabilities. Despite extensive efforts in developing general-purpose LLMs that can be utilized in various natural language processing (NLP) tasks, there has been less research exploring their potential in recommender systems. In this paper, we propose a novel framework, named PALR, which aiming to combine user history behaviors (such as clicks, purchases, ratings, etc.) with LLMs to generate user preferred items. Specifically, we first use user/item interactions as guidance for candidate retrieval. Then we adopt a LLM-based ranking model to generate recommended items. Unlike existing approaches that typically adopt general-purpose LLMs for zero/few-shot recommendation testing or training on small-sized language models (with less than 1 billion parameters), which cannot fully elicit LLMs' reasoning abilities and leverage rich item side parametric knowledge, we fine-tune a 7 billion parameter
    
[^3]: 标题：校准集的期望特点是什么？确定长篇科学摘要的相关因素。

    What are the Desired Characteristics of Calibration Sets? Identifying Correlates on Long Form Scientific Summarization. (arXiv:2305.07615v1 [cs.CL])

    [http://arxiv.org/abs/2305.07615](http://arxiv.org/abs/2305.07615)

    现有的总结模型由于训练过程中单个参考的可能性，生成的文本与质量指标不匹配。本文通过对不同校准集的研究，找出了最佳设置的共同特点，即在校准前将正负分开，谨慎选择负例，大胆对待正例。

    

    摘要：总结模型通常会生成与质量指标不匹配的文本，因为它们的训练是为了最大化单个参考的可能性。为了解决这个问题，最近的工作加入了一个校准步骤，让模型暴露在它自己的排名输出中，以提高相关性或改进忠实度。虽然这是有效的，但很多工作都集中在如何生成和优化这些集合上。关于为什么一种设置比另一种更有效，我们知之甚少。在这项工作中，我们揭示了有效集的基本特征。对于每个训练实例，我们形成了一个庞大、多样化的候选人池，并系统地变化了用于校准微调的子集。每种选择策略都针对集合的不同方面进行，例如词汇多样性或正负之间的差距大小。在三个不同的科学长篇摘要数据集上（涵盖生物医学、临床和COVID-19领域），我们发现最佳设置的共同特点是在校准前将正负分开，为负例选择谨慎而大胆地对待正例。

    Summarization models often generate text that is poorly calibrated to quality metrics because they are trained to maximize the likelihood of a single reference (MLE). To address this, recent work has added a calibration step, which exposes a model to its own ranked outputs to improve relevance or, in a separate line of work, contrasts positive and negative sets to improve faithfulness. While effective, much of this work has focused on how to generate and optimize these sets. Less is known about why one setup is more effective than another. In this work, we uncover the underlying characteristics of effective sets. For each training instance, we form a large, diverse pool of candidates and systematically vary the subsets used for calibration fine-tuning. Each selection strategy targets distinct aspects of the sets, such as lexical diversity or the size of the gap between positive and negatives. On three diverse scientific long-form summarization datasets (spanning biomedical, clinical, a
    
[^4]: NevIR: 神经信息检索中的否定

    NevIR: Negation in Neural Information Retrieval. (arXiv:2305.07614v1 [cs.IR])

    [http://arxiv.org/abs/2305.07614](http://arxiv.org/abs/2305.07614)

    本研究探讨了否定在神经信息检索中的影响，构建了基准模型，结果表明当前信息检索模型大多数都没有考虑否定，而交叉编码器是目前表现最好的架构。

    

    否定是一种常见而日常化的现象，也一直是语言模型的一个弱点。虽然信息检索领域采用了语言模型作为现代化架构的主干，但几乎没有研究深入了解否定对神经信息检索的影响。因此，我们构建了一个简单的基准来研究这个主题：要求信息检索模型对仅仅因为是否定而不同的两个文档进行排名。我们发现，结果根据不同的信息检索架构而有很大差异：交叉编码器表现最好，后期交互模型次之，而双编码器和稀疏神经架构排名最后。我们发现，大多数当前的信息检索模型都没有考虑否定，表现与随机排名相似或更差。我们证明，尽管在一个包含否定对照文档的数据集上继续微调明显的方法可以提高性能（模型大小也是如此），但是机器和人之间仍存在很大的差距。

    Negation is a common everyday phenomena and has been a consistent area of weakness for language models (LMs). Although the Information Retrieval (IR) community has adopted LMs as the backbone of modern IR architectures, there has been little to no research in understanding how negation impacts neural IR. We therefore construct a straightforward benchmark on this theme: asking IR models to rank two documents that differ only by negation. We show that the results vary widely according to the type of IR architecture: cross-encoders perform best, followed by late-interaction models, and in last place are bi-encoder and sparse neural architectures. We find that most current information retrieval models do not consider negation, performing similarly or worse than randomly ranking. We show that although the obvious approach of continued fine-tuning on a dataset of contrastive documents containing negations increases performance (as does model size), there is still a large gap between machine 
    
[^5]: 多模态情感分析：综述

    Multimodal Sentiment Analysis: A Survey. (arXiv:2305.07611v1 [cs.CL])

    [http://arxiv.org/abs/2305.07611](http://arxiv.org/abs/2305.07611)

    本综述介绍了多模态情感分析的定义、发展和挑战，讨论了最新的数据集和先进模型，并提出了有前途的研究方向和构建更好性能的建议。

    

    多模态情感分析已成为人工智能领域的重要研究领域。随着深度学习的最新进展，这项技术已经达到了新的高度。它在应用和研究方面具有巨大的潜力，因此成为了一个热门研究课题。本综述提供了多模态情感分析的定义、背景和发展概述。它还涵盖了最新的数据集和先进模型，强调了该技术的挑战和未来前景。最后，它展望了未来的研究方向。需要指出的是，本综述为有前途的研究方向和构建更好性能的多模态情感分析模型提供了建设性的建议，有助于该领域的研究者。

    Multimodal sentiment analysis has become an important research area in the field of artificial intelligence. With the latest advances in deep learning, this technology has reached new heights. It has great potential for both application and research, making it a popular research topic. This review provides an overview of the definition, background, and development of multimodal sentiment analysis. It also covers recent datasets and advanced models, emphasizing the challenges and future prospects of this technology. Finally, it looks ahead to future research directions. It should be noted that this review provides constructive suggestions for promising research directions and building better performing multimodal sentiment analysis models, which can help researchers in this field.
    
[^6]: ChatGPT是否公平可靠？评估大型语言模型推荐中的公平性

    Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. (arXiv:2305.07609v1 [cs.IR])

    [http://arxiv.org/abs/2305.07609](http://arxiv.org/abs/2305.07609)

    这篇论文介绍了一种新的推荐范式——通过LLM进行推荐，但由于LLMs可能存在社会偏见，需要进一步调查RecLLM所做推荐的公正性。为此，作者提出了一个新的公平性基准——FaiRLLM，并针对音乐和电影推荐场景中的八个敏感属性进行了评估。

    

    大型语言模型（LLM）的显着成就导致一种新的推荐范式——通过LLM进行推荐（RecLLM）。然而，需要注意LLMs可能包含社会偏见，因此需要进一步调查RecLLM所做推荐的公正性。为了避免RecLLM的潜在风险，有必要从用户的各种敏感属性角度评估RecLLM的公平性。由于RecLLM范式与传统推荐范式之间存在差异，因此直接使用传统推荐的公平性基准是有问题的。为了解决这个困境，我们提出了一个新的基准，称为“通过LLM的推荐的公平性”（FaiRLLM）。该基准包括精心设计的指标和数据集，涵盖两个推荐场景中的八个敏感属性：音乐和电影。通过利用我们的FaiRLLM基准，我们进行了一项评估。

    The remarkable achievements of Large Language Models (LLMs) have led to the emergence of a novel recommendation paradigm -- Recommendation via LLM (RecLLM). Nevertheless, it is important to note that LLMs may contain social prejudices, and therefore, the fairness of recommendations made by RecLLM requires further investigation. To avoid the potential risks of RecLLM, it is imperative to evaluate the fairness of RecLLM with respect to various sensitive attributes on the user side. Due to the differences between the RecLLM paradigm and the traditional recommendation paradigm, it is problematic to directly use the fairness benchmark of traditional recommendation. To address the dilemma, we propose a novel benchmark called Fairness of Recommendation via LLM (FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset that accounts for eight sensitive attributes1 in two recommendation scenarios: music and movies. By utilizing our FaiRLLM benchmark, we conducted an evaluation 
    
[^7]: 一种支持核指代信息的问答流式数据记忆模型

    A Memory Model for Question Answering from Streaming Data Supported by Rehearsal and Anticipation of Coreference Information. (arXiv:2305.07565v1 [cs.CL])

    [http://arxiv.org/abs/2305.07565](http://arxiv.org/abs/2305.07565)

    该论文提出了一种记忆模型，在处理流式数据时，通过排练和预期来记忆有关问题回答任务的重要信息。该模型应用自监督机制，通过核指代信息的屏蔽建模任务训练，成功通过短序列数据集和大型基准测试。

    

    现有的问答方法往往假设输入内容（如文件或视频）总是可访问的，以解决任务。相反，记忆网络被引入来模仿人类逐步理解和压缩信息的过程。然而，这些模型只学习如何通过整个网络反向传播错误来维护内存。相反，人类具有提高记忆容量的有效机制，例如排练和预期。受此启发，我们提出了一种记忆模型，通过排练和预期来处理输入以记忆有关问题回答任务的重要信息。所提出的机制在训练期间通过针对核指代信息的屏蔽建模任务进行自监督应用。我们在短序列（bAbI）数据集以及大型基准测试中验证了我们的模型。

    Existing question answering methods often assume that the input content (e.g., documents or videos) is always accessible to solve the task. Alternatively, memory networks were introduced to mimic the human process of incremental comprehension and compression of the information in a fixed-capacity memory. However, these models only learn how to maintain memory by backpropagating errors in the answers through the entire network. Instead, it has been suggested that humans have effective mechanisms to boost their memorization capacities, such as rehearsal and anticipation. Drawing inspiration from these, we propose a memory model that performs rehearsal and anticipation while processing inputs to memorize important information for solving question answering tasks from streaming data. The proposed mechanisms are applied self-supervised during training through masked modeling tasks focused on coreference information. We validate our model on a short-sequence (bAbI) dataset as well as large-s
    
[^8]: 在细粒度视觉语言理解方面的进展量化测量

    Measuring Progress in Fine-grained Vision-and-Language Understanding. (arXiv:2305.07558v1 [cs.CL])

    [http://arxiv.org/abs/2305.07558](http://arxiv.org/abs/2305.07558)

    本文旨在量化测量细粒度视觉语言理解方面的进展，探究了四个竞争的V&L模型在四个精细基准任务上的表现。研究发现X-VLM模型始终优于其他模型，并强调了新颖的损失和丰富的数据源对于学习细粒度技能的重要性。同时，该研究还揭示了部分模型在某些任务上存在视觉和语言之间的潜在分离。

    

    虽然利用来自Web的大规模图像文本数据进行预训练已经促进了视觉语言（V＆L）任务的快速进展，但最近的研究表明预训练模型缺乏“细粒度”理解，例如在图像中识别关系、动词和数字的能力。因此，社区对开发新的基准或模型来实现这种能力的兴趣增加。为了更好地了解和量化在这个方向上的进展，我们在四个精细的基准任务上研究了四个竞争的V＆L模型。通过我们的分析，我们发现X-VLM（Zeng等人，2022）始终优于其他基线，并且模型创新可以比扩展Web数据对表现产生更大的影响，有时甚至会降低表现。通过对X-VLM的深入研究，我们强调了新颖的损失和丰富的数据源对学习细粒度技能的重要性。最后，我们检查了训练动态，发现对于某些任务（例如动词预测），模型可以在不学习感知视觉对象的情况下实现强大的性能，表明这些模型中可能存在视觉和语言之间的潜在分离。

    While pretraining on large-scale image-text data from the Web has facilitated rapid progress on many vision-and-language (V&L) tasks, recent work has demonstrated that pretrained models lack "fine-grained" understanding, such as the ability to recognise relationships, verbs, and numbers in images. This has resulted in an increased interest in the community to either develop new benchmarks or models for such capabilities. To better understand and quantify progress in this direction, we investigate four competitive V&L models on four fine-grained benchmarks. Through our analysis, we find that X-VLM (Zeng et al., 2022) consistently outperforms other baselines, and that modelling innovations can impact performance more than scaling Web data, which even degrades performance sometimes. Through a deeper investigation of X-VLM, we highlight the importance of both novel losses and rich data sources for learning fine-grained skills. Finally, we inspect training dynamics, and discover that for so
    
[^9]: LeXFiles和LegalLAMA：促进英语跨国法律语言模型的开发

    LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development. (arXiv:2305.07507v1 [cs.CL])

    [http://arxiv.org/abs/2305.07507](http://arxiv.org/abs/2305.07507)

    本文对面向法律的预训练语言模型进行了详细分析，发布了一个跨国英语法律文集和一个法律知识探针基准，发现探针性能与上游性能强相关，下游性能主要由模型的大小和先前的法律知识驱动。

    

    本文对面向法律的预训练语言模型（PLMs）的性能进行了详细分析。我们考察了它们的原始目标、获取的知识和法律语言理解能力之间的相互作用，将其定义为上游、探针和下游性能。我们不仅考虑了模型的大小，还将预训练语料库作为研究中的重要维度。为此，我们发布了一个跨国英语法律文集（LeXFiles）和一个法律知识探针基准（LegalLAMA），以促进法律导向PLMs的训练和详细分析。我们发布了两个在LeXFiles上训练的新的法律PLMs，并在LegalLAMA和LexGLUE上进行了评估。我们发现，在相关法律主题中，探针性能与上游性能强相关。另一方面，下游性能主要由模型的大小和先前的法律知识驱动，可以通过上游和探针性能来估计。

    In this work, we conduct a detailed analysis on the performance of legal-oriented pre-trained language models (PLMs). We examine the interplay between their original objective, acquired knowledge, and legal language understanding capacities which we define as the upstream, probing, and downstream performance, respectively. We consider not only the models' size but also the pre-training corpora used as important dimensions in our study. To this end, we release a multinational English legal corpus (LeXFiles) and a legal knowledge probing benchmark (LegalLAMA) to facilitate training and detailed analysis of legal-oriented PLMs. We release two new legal PLMs trained on LeXFiles and evaluate them alongside others on LegalLAMA and LexGLUE. We find that probing performance strongly correlates with upstream performance in related legal topics. On the other hand, downstream performance is mainly driven by the model's size and prior legal knowledge which can be estimated by upstream and probing 
    
[^10]: 适配器效率的全面分析

    A Comprehensive Analysis of Adapter Efficiency. (arXiv:2305.07491v1 [cs.CL])

    [http://arxiv.org/abs/2305.07491](http://arxiv.org/abs/2305.07491)

    适配器虽然是一种参数有效的微调方法，但是在训练/部署效率和可维护性/可扩展性方面并没有实现PEFT的优势，相对的，可以使用更简单的方法，如多任务训练来实现可维护性/可扩展性的优势。

    

    适配器被定位为一种参数有效的微调方法，只需向模型添加最少量的参数即可进行微调。然而，对于PEFT在训练/部署效率和可维护性/可扩展性方面的优势，适配器并未得到足够的分析。通过对多个适配器、任务和语言的广泛实验，包括监督和跨语言零-shot设置，我们清楚地表明，在自然语言理解（NLU）任务中，适配器的参数效率不等同于与完全微调模型相比的效率提高。更明确地说，适配器的训练成本相对较高，并且具有稍高的部署延迟。此外，可以通过全面微调的多任务训练等简单方法实现适配器的可维护性/可扩展性优势，这也提供了相对较快的培训时间。因此，我们建议对于中等大小的神经网络模型，使用传统的全微调方法进行微调，避免使用适配器。

    Adapters have been positioned as a parameter-efficient fine-tuning (PEFT) approach, whereby a minimal number of parameters are added to the model and fine-tuned. However, adapters have not been sufficiently analyzed to understand if PEFT translates to benefits in training/deployment efficiency and maintainability/extensibility. Through extensive experiments on many adapters, tasks, and languages in supervised and cross-lingual zero-shot settings, we clearly show that for Natural Language Understanding (NLU) tasks, the parameter efficiency in adapters does not translate to efficiency gains compared to full fine-tuning of models. More precisely, adapters are relatively expensive to train and have slightly higher deployment latency. Furthermore, the maintainability/extensibility benefits of adapters can be achieved with simpler approaches like multi-task training via full fine-tuning, which also provide relatively faster training times. We, therefore, recommend that for moderately sized m
    
[^11]: ArtGPT-4: 基于适配器增强的MiniGPT-4模型的艺术视觉语言理解

    ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4. (arXiv:2305.07490v1 [cs.CL])

    [http://arxiv.org/abs/2305.07490](http://arxiv.org/abs/2305.07490)

    ArtGPT-4是一种基于适配器增强的MiniGPT-4模型，专注于解决图像理解方面的问题，能够在短时间内训练出具备良好视觉语言理解能力的多模态模型。

    

    近年来，大型语言模型在自然语言处理领域取得了显著进展，比如ChatGPT和GPT-4等模型在多种语言任务上取得了惊人的能力。但是，对这样的大规模模型进行训练是具有挑战性的，而找到与模型规模匹配的数据集通常也很困难。微调和使用新方法训练参数较少的模型已经成为克服这些挑战的有效方法。MiniGPT-4模型便是其中之一，该模型通过运用新颖的预训练模型和革新性的培训策略实现了与GPT-4相当的视觉语言理解能力。但是，该模型在图像理解方面仍然面临一些挑战，特别是在艺术图片方面。ArtGPT-4是一种新型的多模态模型，旨在应对这些局限。ArtGPT-4使用Tesla A100设备对图像-文本对进行训练，仅用了约200GB的数据，在2小时内就能展示出图像。

    In recent years, large language models (LLMs) have made significant progress in natural language processing (NLP), with models like ChatGPT and GPT-4 achieving impressive capabilities in various linguistic tasks. However, training models on such a large scale is challenging, and finding datasets that match the model's scale is often difficult. Fine-tuning and training models with fewer parameters using novel methods have emerged as promising approaches to overcome these challenges. One such model is MiniGPT-4, which achieves comparable vision-language understanding to GPT-4 by leveraging novel pre-training models and innovative training strategies. However, the model still faces some challenges in image understanding, particularly in artistic pictures. A novel multimodal model called ArtGPT-4 has been proposed to address these limitations. ArtGPT-4 was trained on image-text pairs using a Tesla A100 device in just 2 hours, using only about 200 GB of data. The model can depict images wit
    
[^12]: 面向表格与文本混合数值推理的解决方案全面预训练

    Comprehensive Solution Program Centric Pretraining for Table-and-Text Hybrid Numerical Reasoning. (arXiv:2305.07475v1 [cs.CL])

    [http://arxiv.org/abs/2305.07475](http://arxiv.org/abs/2305.07475)

    本文提出了面向表格与文本混合数值推理的全面预训练解决方案，通过变量完整性排序、变量运算预测和变量关键词屏蔽等任务鼓励模型关注有用的变量和确定子程序来源的关键证据，实验结果超过了基于Transformer的模型基线。

    

    对于金融报告等表格与文本混合的语境中的数值推理，存在噪声和无关变量仍然是现实的挑战和潜在应用的难点。而粗糙的整个解决方案程序的监督阻碍了模型学习潜在的数值推理过程。在本文中，我们提出了三个预训练任务，既涉及到整个程序也涉及到子程序级别的变量完整性排序、变量运算预测和变量关键词屏蔽。这些任务鼓励模型关注有用的变量、将监督分解为细粒度的单个运算符预测和确定子程序来源的关键证据。实验结果表明了我们提出的方法的有效性，超过了基于Transformer的模型基线。

    Numerical reasoning over table-and-text hybrid passages, such as financial reports, poses significant challenges and has numerous potential applications. Noise and irrelevant variables in the model input have been a hindrance to its performance. Additionally, coarse-grained supervision of the whole solution program has impeded the model's ability to learn the underlying numerical reasoning process. In this paper, we propose three pretraining tasks that operate at both the whole program and sub-program level: Variable Integrity Ranking, which guides the model to focus on useful variables; Variable Operator Prediction, which decomposes the supervision into fine-grained single operator prediction; and Variable Keyphrase Masking, which encourages the model to identify key evidence that sub-programs are derived from. Experimental results demonstrate the effectiveness of our proposed methods, surpassing transformer-based model baselines.
    
[^13]: BactInt:一种面向领域的迁移学习方法和一个语料库，用于从生物医学文本中提取细菌间相互作用

    BactInt: A domain driven transfer learning approach and a corpus for extracting inter-bacterial interactions from biomedical text. (arXiv:2305.07468v1 [cs.IR])

    [http://arxiv.org/abs/2305.07468](http://arxiv.org/abs/2305.07468)

    BactInt是一种面向领域的自动化方法，使用迁移学习从生物医学文本中提取细菌间相互作用并挖掘特定细菌群之间的关系。公开可用的BactInt语料库标注了1200篇PubMed摘要。

    

    生物学领域中不同类型微生物在生物学空间中发挥着重要作用，这些微生物之间的相互作用是微生物群落结构的基本构建单元。生物医学文本中的证据可作为预测这种相互作用的可靠来源。然而，阅读海量且不断增长的生物医学文献是一项耗时并令人望而生畏的工作。这就必然需要开发自动化方法来准确提取生物医学文献中所报道的细菌关系。本文介绍了一种从生物医学文献中自动提取微生物相互作用（特别是细菌之间）的方法以及使用迁移学习来提高其准确性的方法。我们还描述了一个管道，用于挖掘特定细菌群之间的关系。此外，我们还介绍了第一个公开可用的Bacterial Interaction (BactInt)语料库，其中包括1200篇PubMed摘要，注释有细菌间关系。

    The community of different types of microbes present in a biological niche plays a very important role in functioning of the system. The crosstalk or interactions among the different microbes contributes to the building blocks of such microbial community structures. Evidence reported in biomedical text serves as a reliable source for predicting such interactions. However, going through the vast and ever-increasing volume of biomedical literature is an intimidating and time consuming process. This necessitates development of automated methods capable of accurately extracting bacterial relations reported in biomedical literature. In this paper, we introduce a method for automated extraction of microbial interactions (specifically between bacteria) from biomedical literature along with ways of using transfer learning to improve its accuracy. We also describe a pipeline using which relations among specific bacteria groups can be mined. Additionally, we introduce the first publicly availabl
    
[^14]: 基于摄动的质量估计：一种透明、无监督的词级质量估计方法，适用于黑盒机器翻译

    Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation. (arXiv:2305.07457v1 [cs.CL])

    [http://arxiv.org/abs/2305.07457](http://arxiv.org/abs/2305.07457)

    本文介绍了一种透明、无监督的词级质量估计方法，它可以通过分析扰动的输入源句子上机器翻译系统输出来工作，并可以评估任何类型的黑盒机器翻译系统。使用该方法作为反馈信号，可以在无监督的领域自适应中改进机器翻译系统的质量。

    

    质量估计（QE）是预测机器翻译（MT）系统输出质量的任务，不使用任何黄金标准翻译参考。目前的QE模型是监督的：它们需要对一些数据集上某些MT系统输出进行人类标注质量来进行培训，使它们与域相关和MT系统相关。有研究对无监督的QE进行了研究，需要玻璃盒访问MT系统，或者使用并行MT数据来生成合成错误以训练QE模型。本文介绍了一种基于摄动的QE方法-一种词级质量估计方法，它可以通过分析扰动的输入源句子上MT系统输出来工作。我们的方法是无监督的、可解释的，并可以评估任何类型的黑盒MT系统，包括目前占主导地位的具有不透明内部过程的大型语言模型（LLMs）。对于没有标记QE数据的语言方向，我们的方法表现相似或更好的零-shot监督系统。我们还展示了如何使用基于摄动的QE作为反馈信号，在无监督的领域自适应中改进MT系统的质量。

    Quality Estimation (QE) is the task of predicting the quality of Machine Translation (MT) system output, without using any gold-standard translation references. State-of-the-art QE models are supervised: they require human-labeled quality of some MT system output on some datasets for training, making them domain-dependent and MT-system-dependent. There has been research on unsupervised QE, which requires glass-box access to the MT systems, or parallel MT data to generate synthetic errors for training QE models. In this paper, we present Perturbation-based QE - a word-level Quality Estimation approach that works simply by analyzing MT system output on perturbed input source sentences. Our approach is unsupervised, explainable, and can evaluate any type of blackbox MT systems, including the currently prominent large language models (LLMs) with opaque internal processes. For language directions with no labeled QE data, our approach has similar or better performance than the zero-shot supe
    
[^15]: 用去噪反向翻译提高级联非监督语音翻译的效果

    Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation. (arXiv:2305.07455v1 [cs.CL])

    [http://arxiv.org/abs/2305.07455](http://arxiv.org/abs/2305.07455)

    该论文提出了一种基于级联的语音翻译系统，使用完全非配对的数据来训练无监督系统。通过采用去噪反向翻译技术，成功提高了所有三个翻译方向的BLEU得分0.7-0.9。

    

    大多数语音翻译模型都严重依赖于平行语料库，对于低资源语言而言，收集这种数据非常困难。为了解决这个问题，我们提出了一种基于级联的语音翻译系统，不依赖于任何配对数据。我们使用完全非配对的数据来训练我们的无监督系统，并在 CoVoST 2 和 CVSS 上进行了评估。结果表明，在某些语言对上，我们的方法与其他一些早期监督方法相当。尽管级联系统总是存在严重的误差传播问题，但我们提出了去噪反向翻译（DBT）这种新颖的方法来构建健壮的无监督神经机器翻译（UNMT）系统。DBT成功提高了所有三个翻译方向的 BLEU 得分0.7-0.9。此外，我们简化了级联系统的流程，以降低推理延迟，并对我们工作的每个部分进行了全面的分析。我们还在EST上展示了我们的无监督语音翻译结果。

    Most of the speech translation models heavily rely on parallel data, which is hard to collect especially for low-resource languages. To tackle this issue, we propose to build a cascaded speech translation system without leveraging any kind of paired data. We use fully unpaired data to train our unsupervised systems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early supervised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT). DBT successfully increases the BLEU score by 0.7--0.9 in all three translation directions. Moreover, we simplified the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the est
    
[^16]: QVoice: 阿拉伯语语音发音学习应用

    QVoice: Arabic Speech Pronunciation Learning Application. (arXiv:2305.07445v1 [eess.AS])

    [http://arxiv.org/abs/2305.07445](http://arxiv.org/abs/2305.07445)

    QVoice是一种阿拉伯语发音学习应用程序，旨在帮助非母语者提高发音技能，同时帮助母语者避免地区方言对现代标准阿拉伯语发音的影响。

    

    本文介绍了一种新型的阿拉伯语发音学习应用程序QVoice，其配备了端到端的发音错误检测和反馈生成模块。该应用程序旨在支持非母语阿拉伯语的人提高其发音技能，并帮助阿拉伯语母语者避免地区方言对其现代标准阿拉伯语（MSA）发音的潜在影响。QVoice采用各种学习提示，帮助学习者理解含义，与其对英语语言的现有知识建立联系，并提供详细的发音纠正反馈，以及展示单词用法的上下文示例。QVoice中的学习提示涵盖了各种有意义的信息，如短语/单词及其翻译的可视化，以及音标和音译。QVoice提供字符级别的发音反馈，并对单词级别的表现进行评估。

    This paper introduces a novel Arabic pronunciation learning application QVoice, powered with end-to-end mispronunciation detection and feedback generator module. The application is designed to support non-native Arabic speakers in enhancing their pronunciation skills, while also helping native speakers mitigate any potential influence from regional dialects on their Modern Standard Arabic (MSA) pronunciation. QVoice employs various learning cues to aid learners in comprehending meaning, drawing connections with their existing knowledge of English language, and offers detailed feedback for pronunciation correction, along with contextual examples showcasing word usage. The learning cues featured in QVoice encompass a wide range of meaningful information, such as visualizations of phrases/words and their translations, as well as phonetic transcriptions and transliterations. QVoice provides pronunciation feedback at the character level and assesses performance at the word level.
    
[^17]: 无监督句子嵌入的实例平滑对比学习

    Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding. (arXiv:2305.07424v1 [cs.CL])

    [http://arxiv.org/abs/2305.07424](http://arxiv.org/abs/2305.07424)

    本文提出了IS-CSE方法，通过实例平滑对比学习来学习无监督句子嵌入，以平滑嵌入在特征空间中的边界，从而提高模型的泛化性能。在标准的STS任务中取得了良好的得分。

    

    基于对比学习的方法，如unsup-SimCSE，在学习无监督句子嵌入方面取得了最先进（SOTA）的性能。然而，在以前的研究中，用于对比学习的每个嵌入仅来自于一个句子实例，我们称这些嵌入为实例级嵌入。换句话说，在这种情况下，每个嵌入被视为是一类独特的类，这可能会损害泛化性能。在本研究中，我们提出了IS-CSE（实例平滑对比句子嵌入）来平滑特征空间中嵌入的边界。具体而言，我们根据语义相似性从动态内存缓冲区中检索嵌入以获得正嵌入组。然后我们通过自注意力操作对组中的嵌入进行聚合，以生成平滑实例嵌入以进行进一步分析。我们在标准的语义文本相似性（STS）任务中评估了我们的方法，并实现了平均78.30％，79.47％，77.73％和79.42％的得分。

    Contrastive learning-based methods, such as unsup-SimCSE, have achieved state-of-the-art (SOTA) performances in learning unsupervised sentence embeddings. However, in previous studies, each embedding used for contrastive learning only derived from one sentence instance, and we call these embeddings instance-level embeddings. In other words, each embedding is regarded as a unique class of its own, whichmay hurt the generalization performance. In this study, we propose IS-CSE (instance smoothing contrastive sentence embedding) to smooth the boundaries of embeddings in the feature space. Specifically, we retrieve embeddings from a dynamic memory buffer according to the semantic similarity to get a positive embedding group. Then embeddings in the group are aggregated by a self-attention operation to produce a smoothed instance embedding for further analysis. We evaluate our method on standard semantic text similarity (STS) tasks and achieve an average of 78.30%, 79.47%, 77.73%, and 79.42% 
    
[^18]: 两合一：一种针对文本生成模型的模型劫持攻击

    Two-in-One: A Model Hijacking Attack Against Text Generation Models. (arXiv:2305.07406v1 [cs.CR])

    [http://arxiv.org/abs/2305.07406](http://arxiv.org/abs/2305.07406)

    本文扩展了模型劫持攻击的范围，提出了一种名为Ditto的攻击方法，能够将不同的文本分类任务劫持为多个生成任务，并使用多个基准数据集验证了攻击的成功性。

    

    机器学习在各种应用中取得了显著进展，从人脸识别到文本生成。然而，它的成功也伴随着各种攻击。最近提出了一种新的攻击，即模型劫持攻击，该攻击提高了问责和寄生计算的风险。但是，该攻击仅集中于图像分类任务。在本文中，我们将此攻击的范围扩大到包括文本生成和分类模型，从而展示其更广泛的适用性。具体而言，我们提出了一种新的模型劫持攻击——Ditto，它可以将不同的文本分类任务劫持为多个生成任务，例如语言翻译、文本摘要和语言建模。我们使用一系列文本基准数据集（如SST-2、TweetEval、AGnews、QNLI和IMDB）来评估我们攻击的性能。我们的结果表明，使用Ditto，攻击者可以成功地劫持文本生成模型。

    Machine learning has progressed significantly in various applications ranging from face recognition to text generation. However, its success has been accompanied by different attacks. Recently a new attack has been proposed which raises both accountability and parasitic computing risks, namely the model hijacking attack. Nevertheless, this attack has only focused on image classification tasks. In this work, we broaden the scope of this attack to include text generation and classification models, hence showing its broader applicability. More concretely, we propose a new model hijacking attack, Ditto, that can hijack different text classification tasks into multiple generation ones, e.g., language translation, text summarization, and language modeling. We use a range of text benchmark datasets such as SST-2, TweetEval, AGnews, QNLI, and IMDB to evaluate the performance of our attacks. Our results show that by using Ditto, an adversary can successfully hijack text generation models withou
    
[^19]: 搜索引擎与大型语言模型间的交互优化知识精炼

    Knowledge Refinement via Interaction Between Search Engines and Large Language Models. (arXiv:2305.07402v1 [cs.CL])

    [http://arxiv.org/abs/2305.07402](http://arxiv.org/abs/2305.07402)

    本文介绍了一种新的框架InteR，通过搜索引擎和大型语言模型之间的交互促进知识精炼，从而提高检索准确性。

    

    信息检索在从大量数据中定位相关资源方面具有重要作用，其应用已从传统知识库发展至现代搜索引擎（SEs）。大型语言模型（LLMs）的出现进一步通过使用自然语言与搜索系统交互革命性地改变了该领域。本文探索了LLMs和SEs的优缺点，强调它们在理解用户查询和检索最新信息方面的各自优势。为了利用两种范例的优势并避免其限制，我们提出了InteR，这是一个通过SEs和LLMs之间的交互促进知识精炼的新框架。 InteR使SEs能够使用LLM生成的摘要来调整查询，同时使LLMs能够使用SE检索到的文档来增强提示。这种迭代的精炼过程增强了SEs和LLMs的输入，从而导致更准确的检索结果。

    Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern search engines (SEs). The emergence of large language models (LLMs) has further revolutionized the field by enabling users to interact with search systems in natural language. In this paper, we explore the advantages and disadvantages of LLMs and SEs, highlighting their respective strengths in understanding user-issued queries and retrieving up-to-date information. To leverage the benefits of both paradigms while circumventing their limitations, we propose InteR, a novel framework that facilitates knowledge refinement through interaction between SEs and LLMs. InteR allows SEs to refine knowledge in query using LLM-generated summaries and enables LLMs to enhance prompts using SE-retrieved documents. This iterative refinement process augments the inputs of SEs and LLMs, leading to more accurate retrieval. Ex
    
[^20]: 针对开放域对话生成的跨语言迁移中降低灾难性遗忘的提示学习

    Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation. (arXiv:2305.07393v1 [cs.CL])

    [http://arxiv.org/abs/2305.07393](http://arxiv.org/abs/2305.07393)

    本文提出了一种提示学习方法，以解决开放域非英语语言对话系统中少量数据下的跨语言迁移学习和多任务学习中的灾难性遗忘问题，并在六种语言上的实验中证明了其有效性。

    

    长期以来，非英语语言的对话系统一直未得到充分探索。本文第一次在非英语语言有限数据的开放域对话生成中研究了少样本跨语言迁移学习（FS-XLT）和多任务学习（MTL）。在初步实验中，我们发现在FS-XLT和MTL中所有的6种语言中都存在灾难性遗忘。为了减轻这一问题，我们提出了一种简单而有效的提示学习方法，通过固定提示语言模型调参和我们手工制作的提示语来弥合预训练和微调之间的差距，从而保持多语言预训练语言模型（mPLM）在FS-XLT和MTL中的多语言性。在所有6种语言上的自动和人工评估结果都证明了我们方法的有效性。我们的代码可在 https://github.com/JeremyLeiLiu/XLinguDial 上获取。

    Dialogue systems for non-English languages have long been under-explored. In this paper, we take the first step to investigate few-shot cross-lingual transfer learning (FS-XLT) and multitask learning (MTL) in the context of open-domain dialogue generation for non-English languages with limited data. We observed catastrophic forgetting in both FS-XLT and MTL for all 6 languages in our preliminary experiments. To mitigate the issue, we propose a simple yet effective prompt learning approach that can preserve the multilinguality of multilingual pre-trained language model (mPLM) in FS-XLT and MTL by bridging the gap between pre-training and fine-tuning with Fixed-prompt LM Tuning and our hand-crafted prompts. Experimental results on all 6 languages in terms of both automatic and human evaluations demonstrate the effectiveness of our approach. Our code is available at https://github.com/JeremyLeiLiu/XLinguDial.
    
[^21]: 探究自然语言处理语音识别系统对L2英语语音变体的敏感性

    Investigating the Sensitivity of Automatic Speech Recognition Systems to Phonetic Variation in L2 Englishes. (arXiv:2305.07389v1 [cs.CL])

    [http://arxiv.org/abs/2305.07389](http://arxiv.org/abs/2305.07389)

    本文旨在探索自然语言处理的语音识别系统对L2英语语音变体的敏感度，提高识别准确率和手动纠正的效率，为冷门语言的自然语言处理提供了新思路。

    

    自然语言处理的语音识别系统在能识别与其训练数据相似的语音时表现最佳。因此，地方方言、少数族裔使用英语和低资源语种等较为冷门的语言，与比较正统、主流或标准的语言相比出现更高的识别错误率。这成为将自然语言处理技术纳入大规模语言学研究的标注过程的障碍，因为手动纠正错误的自动化文本与手动转录同样需要时间和资源。因此，对自然语言处理系统的行为有更深层次的理解，无论是从语音技术角度出发，还是从标注角度出发，都有益于提高识别准确度或者为手动纠正提供线索。本文展示了一种探究自然语言处理系统的方法，以发现其如何处理一个较小语种中的语音变化。

    Automatic Speech Recognition (ASR) systems exhibit the best performance on speech that is similar to that on which it was trained. As such, underrepresented varieties including regional dialects, minority-speakers, and low-resource languages, see much higher word error rates (WERs) than those varieties seen as 'prestigious', 'mainstream', or 'standard'. This can act as a barrier to incorporating ASR technology into the annotation process for large-scale linguistic research since the manual correction of the erroneous automated transcripts can be just as time and resource consuming as manual transcriptions. A deeper understanding of the behaviour of an ASR system is thus beneficial from a speech technology standpoint, in terms of improving ASR accuracy, and from an annotation standpoint, where knowing the likely errors made by an ASR system can aid in this manual correction. This work demonstrates a method of probing an ASR system to discover how it handles phonetic variation across a n
    
[^22]: ChatGPT是一个好的因果推断器吗？全面评估

    Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation. (arXiv:2305.07375v1 [cs.CL])

    [http://arxiv.org/abs/2305.07375](http://arxiv.org/abs/2305.07375)

    本文对ChatGPT的因果推理能力进行了首次全面评估，实验证明ChatGPT是一个好的因果解释者，但不是一个好的因果推理者，存在严重的因果幻觉问题，对于明确的因果关系表现良好。

    

    因果推理能力对于众多NLP应用至关重要。尽管ChatGPT在各种NLP任务中表现出令人印象深刻的新兴能力，但ChatGPT在因果推理方面的表现如何仍不清楚。本文对ChatGPT的因果推理能力进行了首次全面评估。实验证明，ChatGPT不是一个好的因果推理者，但是是一个好的因果解释者。此外，ChatGPT在因果推理方面存在严重的幻觉，可能是由于自然语言中因果关系和非因果关系的报告偏见，以及ChatGPT的升级过程，如RLHF。在上下文学习（ICL）和思维链（COT）技术方面，可能会进一步加剧这种因果幻觉。此外，ChatGPT的因果推理能力对于在提示中表达因果概念的词语非常敏感，并且封闭提示比开放提示表现更好。对于句子中的事件，ChatGPT擅长捕捉明确的因果关系。

    Causal reasoning ability is crucial for numerous NLP applications. Despite the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear how well ChatGPT performs in causal reasoning. In this paper, we conduct the first comprehensive evaluation of the ChatGPT's causal reasoning capabilities. Experiments show that ChatGPT is not a good causal reasoner, but a good causal interpreter. Besides, ChatGPT has a serious hallucination on causal reasoning, possibly due to the reporting biases between causal and non-causal relationships in natural language, as well as ChatGPT's upgrading processes, such as RLHF. The In-Context Learning (ICL) and Chain-of-Though (COT) techniques can further exacerbate such causal hallucination. Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts. For events in sentences, ChatGPT excels at capturing explicit caus
    
[^23]: 通过可编辑的逐步解释实现交互式文本转SQL

    Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations. (arXiv:2305.07372v1 [cs.DB])

    [http://arxiv.org/abs/2305.07372](http://arxiv.org/abs/2305.07372)

    本文介绍一种交互机制，允许用户直接编辑一步步解释错误SQL以修复SQL错误，实验证明方法提高了31.6％的执行准确性。用户研究表明，该方法帮助用户以更少的时间和更高的信心解决了更多的SQL任务。

    

    关系数据库在大数据时代扮演着重要角色。然而，非专家很难完全释放关系数据库的分析能力，因为他们不熟悉SQL等数据库语言。许多技术已被提出自然语言自动生成SQL，但它们存在以下两个问题：（1）对于复杂查询它们仍会犯很多错误，（2）它们不提供一种灵活的方式，让非专家用户验证和改进不正确的查询。为了解决这些问题，我们引入了一种新的交互机制，允许用户直接编辑一步步解释错误SQL以修复SQL错误。在Spider基准测试上的实验证明，我们的方法至少比三种最先进方法在执行准确性方面提高了31.6％。24名参与者的用户研究进一步表明，我们的方法帮助用户以更少的时间和更高的信心解决了更多的SQL任务。

    Relational databases play an important role in this Big Data era. However, it is challenging for non-experts to fully unleash the analytical power of relational databases, since they are not familiar with database languages such as SQL. Many techniques have been proposed to automatically generate SQL from natural language, but they suffer from two issues: (1) they still make many mistakes, particularly for complex queries, and (2) they do not provide a flexible way for non-expert users to validate and refine the incorrect queries. To address these issues, we introduce a new interaction mechanism that allows users directly edit a step-by-step explanation of an incorrect SQL to fix SQL errors. Experiments on the Spider benchmark show that our approach outperforms three SOTA approaches by at least 31.6% in terms of execution accuracy. A user study with 24 participants further shows that our approach helped users solve significantly more SQL tasks with less time and higher confidence, demo
    
[^24]: 实现从天城文辛迪到波斯-阿拉伯文辛迪的音译

    Towards Transliteration between Sindhi Scripts from Devanagari to Perso-Arabic. (arXiv:2305.07365v1 [cs.CL])

    [http://arxiv.org/abs/2305.07365](http://arxiv.org/abs/2305.07365)

    本文提出了一种将天城文辛迪转换为波斯-阿拉伯文辛迪的技术，通过混合使用基于规则和概率模型，系统取得了99.64％的准确率。

    

    本文提出一种将天城文辛迪转换为波斯-阿拉伯文辛迪的转换技术。我们采用了一种混合方法，其中部分文本使用基于规则的方法进行转换，如果有歧义，则使用概率模型进行解决。使用这种方法，系统总体准确率达到99.64％。

    In this paper, we have shown a script conversion (transliteration) technique that converts Sindhi text in the Devanagari script to the Perso-Arabic script. We showed this by incorporating a hybrid approach where some part of the text is converted using a rule base and in case an ambiguity arises then a probabilistic model is used to resolve the same. Using this approach, the system achieved an overall accuracy of 99.64%.
    
[^25]: 通过适当翻译命名实体来提高神经机器翻译的质量

    Improving the Quality of Neural Machine Translation Through Proper Translation of Name Entities. (arXiv:2305.07360v1 [cs.CL])

    [http://arxiv.org/abs/2305.07360](http://arxiv.org/abs/2305.07360)

    本文提出了一种方法，通过将命名实体作为预处理步骤进行翻译/音译，以提高神经机器翻译的质量，实验结果显示该方法能够正确翻译大多数的命名实体，准确率高达99.52％。

    

    本文介绍了一种通过将命名实体作为预处理步骤进行翻译/音译来提高神经机器翻译质量的方法。通过实验，我们展示了我们系统的性能增益。对于评估，我们考虑了三种类型的命名实体，即人名、地名和组织名。系统能够正确地翻译大多数的命名实体。对于人名，准确率为99.86％，对于地名，准确率为99.63％，对于组织名，准确率为99.05％。总体而言，系统的准确率为99.52％。

    In this paper, we have shown a method of improving the quality of neural machine translation by translating/transliterating name entities as a preprocessing step. Through experiments we have shown the performance gain of our system. For evaluation we considered three types of name entities viz person names, location names and organization names. The system was able to correctly translate mostly all the name entities. For person names the accuracy was 99.86%, for location names the accuracy was 99.63% and for organization names the accuracy was 99.05%. Overall, the accuracy of the system was 99.52%
    
[^26]: 利用跨模态适配器向预训练语言模型注入多功能高效的视觉知识

    Towards Versatile and Efficient Visual Knowledge Injection into Pre-trained Language Models with Cross-Modal Adapters. (arXiv:2305.07358v1 [cs.CL])

    [http://arxiv.org/abs/2305.07358](http://arxiv.org/abs/2305.07358)

    本文提出了X-adapter插拔式模块，利用多模态视觉语言模型，高效地向预训练语言模型注入视觉知识。

    

    人类通过多模态知识学习语言，然而现有的大多数预训练语言模型（PLMs）仅支持文本预训练。本文提出了插拔式模块X-adapter，它能够根据多模态视觉语言模型（VLMs）的对齐视觉和文本知识，灵活高效地向PLMs注入视觉知识。 X-adapter包含两个子模块V-expert和T-expert，可以根据下游任务激活不同的子模块，来融合VLMs的图像和文本表示。

    Humans learn language via multi-modal knowledge. However, due to the text-only pre-training scheme, most existing pre-trained language models (PLMs) are hindered from the multi-modal information.  To inject visual knowledge into PLMs, existing methods incorporate either the text or image encoder of vision-language models (VLMs) to encode the visual information and update all the original parameters of PLMs for knowledge fusion.  In this paper, we propose a new plug-and-play module, X-adapter, to flexibly leverage the aligned visual and textual knowledge learned in pre-trained VLMs and efficiently inject them into PLMs.  Specifically, we insert X-adapters into PLMs, and only the added parameters are updated during adaptation.  To fully exploit the potential in VLMs, X-adapters consist of two sub-modules, V-expert and T-expert, to fuse VLMs' image and text representations, respectively.  We can opt for activating different sub-modules depending on the downstream tasks.  Experimental resu
    
[^27]: ZARA：改进小型语言模型的少样本自理性

    ZARA: Improving Few-Shot Self-Rationalization for Small Language Models. (arXiv:2305.07355v1 [cs.CL])

    [http://arxiv.org/abs/2305.07355](http://arxiv.org/abs/2305.07355)

    本文提出了一种名为ZARA的方法，其可以通过将合理性判断问题转化为自然语言推理来自动构建伪平行数据进行自我训练，从而提高小型语言模型的少样本自我解释性能，实验结果表明ZARA在任务准确性和解释质量上都表现出SOTA水平。

    

    同时生成终端任务答案和自由文本解释的语言模型被称为自我解释模型。最近的研究通过使用有理据的例子来提示语言模型，展现了少样本自我解释性能显著提高的成果。然而，只有大规模语言模型才能受益于解释，而这些模型很难被获得。本文研究利用解释来提高少样本自我解释对小型语言模型的影响。我们首先重新探讨了解释和答案之间的关系。受到人类如何评估解释的隐含思考过程的启发，我们提出了一种新的方法ZARA，即理性答案对的零样本增强，通过将合理性判断问题转化为自然语言推理来自动构建伪平行数据进行自我训练。实验结果表明，在FEB基准测试中，ZARA在任务准确性和解释质量上都取得了SOTA的表现。

    Language models (LMs) that jointly generate end-task answers as well as free-text rationales are known as self-rationalization models. Recent works demonstrate great performance gain for self-rationalization by few-shot prompting LMs with rationale-augmented exemplars. However, the ability to benefit from explanations only emerges with large-scale LMs, which have poor accessibility. In this work, we explore the less-studied setting of leveraging explanations for small LMs to improve few-shot self-rationalization. We first revisit the relationship between rationales and answers. Inspired by the implicit mental process of how human beings assess explanations, we present a novel approach, Zero-shot Augmentation of Rationale-Answer pairs (ZARA), to automatically construct pseudo-parallel data for self-training by reducing the problem of plausibility judgement to natural language inference. Experimental results show ZARA achieves SOTA performance on the FEB benchmark, for both the task accu
    
[^28]: 基于模型的编程：为深度学习时代重新定义程序的基本单位

    Model-based Programming: Redefining the Atomic Unit of Programming for the Deep Learning Era. (arXiv:2305.07341v1 [cs.LG])

    [http://arxiv.org/abs/2305.07341](http://arxiv.org/abs/2305.07341)

    本文提出一种新的编程范式——基于模型的编程，旨在解决深度学习模型部署过程中的问题。推出的M语言将模型作为基本的计算单位，加强了开发人员进行关键任务的效率，这种创新的编程范式将彻底改变我们使用深度学习模型的方式。

    

    本文介绍并探讨了一种新的编程范式——基于模型的编程，旨在解决将深度学习模型应用于实际应用时所面临的挑战。尽管深度学习模型在各种任务上取得了重大成功，但将它们部署到实际业务场景中仍然存在困难，如复杂的模型训练、大量的计算资源需求以及与现有编程语言的集成问题。为了缓解这些挑战，我们提出了“基于模型的编程”概念，并推出了一种新颖的编程语言——M语言，该语言针对预期的以模型为中心的编程范式而设计。M语言将模型视为基本的计算单位，使开发人员能够更专注于关键任务，如模型加载、微调、评估和部署，从而增强创建深度学习应用程序的效率。我们认为，这种创新的编程范式将彻底改变我们使用深度学习模型的方式。

    This paper introduces and explores a new programming paradigm, Model-based Programming, designed to address the challenges inherent in applying deep learning models to real-world applications. Despite recent significant successes of deep learning models across a range of tasks, their deployment in real business scenarios remains fraught with difficulties, such as complex model training, large computational resource requirements, and integration issues with existing programming languages. To ameliorate these challenges, we propose the concept of 'Model-based Programming' and present a novel programming language - M Language, tailored to a prospective model-centered programming paradigm. M Language treats models as basic computational units, enabling developers to concentrate more on crucial tasks such as model loading, fine-tuning, evaluation, and deployment, thereby enhancing the efficiency of creating deep learning applications. We posit that this innovative programming paradigm will 
    
[^29]: 利用跨语言一致性规范化改进零样本多语言神经机器翻译

    Improving Zero-shot Multilingual Neural Machine Translation by Leveraging Cross-lingual Consistency Regularization. (arXiv:2305.07310v1 [cs.CL])

    [http://arxiv.org/abs/2305.07310](http://arxiv.org/abs/2305.07310)

    本文提出了一种跨语言一致性规范化方法CrossConST，用于改进零样本多语言神经机器翻译模型的性能。实验结果表明，CrossConST可以缩小语言之间的表示差距，提高零样本翻译的准确性和多样性。

    

    多语言神经机器翻译（NMT）模型有很强的零样本翻译能力，能够在未经过训练的语言对之间进行直接翻译。然而，为了实现从有监督方向到零样本方向的良好转移性能，需要让多语言NMT模型学习到跨不同语言的通用表示。本文引入了跨语言一致性规范化CrossConST，以弥合不同语言之间的表示差距，并提高零样本翻译性能。理论分析表明，CrossConST隐含地最大化了零样本翻译的概率分布，并在低资源和高资源基准测试中取得了稳定的提升。实验分析还证明，CrossConST可以缩小句子表示差距并更好地对齐表示空间。鉴于所提出的方法的普适性和可扩展性，CrossConST可以方便地应用于其他多语言NMT模型中，以进一步提高零样本翻译性能。

    The multilingual neural machine translation (NMT) model has a promising capability of zero-shot translation, where it could directly translate between language pairs unseen during training. For good transfer performance from supervised directions to zero-shot directions, the multilingual NMT model is expected to learn universal representations across different languages. This paper introduces a cross-lingual consistency regularization, CrossConST, to bridge the representation gap among different languages and boost zero-shot translation performance. The theoretical analysis shows that CrossConST implicitly maximizes the probability distribution for zero-shot translation, and the experimental results on both low-resource and high-resource benchmarks show that CrossConST consistently improves the translation performance. The experimental analysis also proves that CrossConST could close the sentence representation gap and better align the representation space. Given the universality and s
    
[^30]: 从自然语言定义中学习多关系双曲词向量

    Multi-Relational Hyperbolic Word Embeddings from Natural Language Definitions. (arXiv:2305.07303v1 [cs.CL])

    [http://arxiv.org/abs/2305.07303](http://arxiv.org/abs/2305.07303)

    本论文提出了一种从自然语言定义中学习多关系双曲词向量的框架，以捕捉由定义所引起的分层和多分辨率结构。

    

    仅使用分布信息的神经词向量一直以来都能为下游任务提供有用的含义表示。然而，现有的方法通常会导致难以解释和控制的表示。相反，自然语言定义具有递归的，自说明的语义结构，可以支持能够保留向量空间中显式概念关系和约束的新型表示学习范 paradigm。本文提出了一个神经符号、多关系框架，通过联合映射定义和定义术语及其相应的语义关系，仅从自然语言定义中学习词向量。通过自动从定义语料库中提取关系，并通过一个翻译目标规范化学习问题，我们将框架专门设定为在双曲空间中捕获由定义引起的分层和多分辨率结构。

    Neural-based word embeddings using solely distributional information have consistently produced useful meaning representations for downstream tasks. However, existing approaches often result in representations that are hard to interpret and control. Natural language definitions, on the other side, possess a recursive, self-explanatory semantic structure that can support novel representation learning paradigms able to preserve explicit conceptual relations and constraints in the vector space.  This paper proposes a neuro-symbolic, multi-relational framework to learn word embeddings exclusively from natural language definitions by jointly mapping defined and defining terms along with their corresponding semantic relations. By automatically extracting the relations from definitions corpora and formalising the learning problem via a translational objective, we specialise the framework in hyperbolic space to capture the hierarchical and multi-resolution structure induced by the definitions.
    
[^31]: RepCL: 探索有效的表示方法以进行持续文本分类

    RepCL: Exploring Effective Representation for Continual Text Classification. (arXiv:2305.07289v1 [cs.CL])

    [http://arxiv.org/abs/2305.07289](http://arxiv.org/abs/2305.07289)

    本文探讨了类增量设置下的持续文本分类问题中的表示偏见，从信息瓶颈的角度提出了利用更多类相关信息消除偏见的方法，即RepCL方法，并证明了其能有效地解决遗忘问题并实现最先进的性能。

    

    持续学习旨在不断学习新知识，同时避免忘记旧任务造成的灾难性后果。本文研究的是类增量设置下的持续文本分类。最近的持续学习研究发现，为一项任务学习到的表示方法可能对其他任务不起作用，即表示偏见问题。我们首次从信息瓶颈的角度正式分析了表示偏差，并建议利用更多类相关信息来消除偏见。为此，我们提出了一种基于回放的持续文本分类方法RepCL。我们的方法利用对比和生成表示学习目标来捕获更多的类相关特征。此外，RepCL引入了对抗式回放策略以消除回放的过拟合问题。实验表明，RepCL有效地缓解了遗忘问题，并实现了最先进的性能。

    Continual learning (CL) aims to constantly learn new knowledge over time while avoiding catastrophic forgetting on old tasks. In this work, we focus on continual text classification under the class-incremental setting. Recent CL studies find that the representations learned in one task may not be effective for other tasks, namely representation bias problem. For the first time we formally analyze representation bias from an information bottleneck perspective and suggest that exploiting representations with more class-relevant information could alleviate the bias. To this end, we propose a novel replay-based continual text classification method, RepCL. Our approach utilizes contrastive and generative representation learning objectives to capture more class-relevant features. In addition, RepCL introduces an adversarial replay strategy to alleviate the overfitting problem of replay. Experiments demonstrate that RepCL effectively alleviates forgetting and achieves state-of-the-art perform
    
[^32]: 从大型语言模型中提取事件模式

    Harvesting Event Schemas from Large Language Models. (arXiv:2305.07280v1 [cs.CL])

    [http://arxiv.org/abs/2305.07280](http://arxiv.org/abs/2305.07280)

    本论文提出了一种新的事件模式诱导范式，通过从大型预训练语言模型中收割知识来自动诱导高质量和高覆盖范围的事件模式。

    

    事件模式提供了一种概念性、结构性和形式化的语言，用于表示事件和对世界事件知识进行建模。然而，由于真实世界事件的开放性、事件表达形式的多样性以及事件知识的稀疏性，自动诱导高质量和高覆盖范围的事件模式仍然具有挑战性。本文提出了一种新的事件模式诱导范式——从大型预训练语言模型中获取知识，通过从PLM中发现、概念化和结构化事件模式来有效解决上述挑战。并设计了事件模式收割机（ESHer），通过上下文生成的概念化、置信度感知的架构化以及基于图形的模式聚合来自动诱导高质量的事件模式。实验结果表明，ESHer可以在不同领域诱导高质量和高覆盖范围的事件模式。

    Event schema provides a conceptual, structural and formal language to represent events and model the world event knowledge. Unfortunately, it is challenging to automatically induce high-quality and high-coverage event schemas due to the open nature of real-world events, the diversity of event expressions, and the sparsity of event knowledge. In this paper, we propose a new paradigm for event schema induction -- knowledge harvesting from large-scale pre-trained language models, which can effectively resolve the above challenges by discovering, conceptualizing and structuralizing event schemas from PLMs. And an Event Schema Harvester (ESHer) is designed to automatically induce high-quality event schemas via in-context generation-based conceptualization, confidence-aware schema structuralization and graph-based schema aggregation. Empirical results show that ESHer can induce high-quality and high-coverage event schemas on varying domains.
    
[^33]: 高斯先验强化学习用于嵌套命名实体识别

    Gaussian Prior Reinforcement Learning for Nested Named Entity Recognition. (arXiv:2305.07266v1 [cs.CL])

    [http://arxiv.org/abs/2305.07266](http://arxiv.org/abs/2305.07266)

    该论文提出了一种嵌套命名实体识别模型GPRL，使用高斯先验调整嵌套边界标记的输出概率分布，采用强化学习方法生成实体三元组，无需考虑金标签中的实体顺序，实验结果显示其优于以前的嵌套NER模型。

    

    命名实体识别(NER)是自然语言处理中经过广泛研究的任务，最近，嵌套命名实体识别引起了更多的关注，因为它的实用性和难度。现有的嵌套NER作品忽略了嵌套实体的识别顺序和边界位置关系。为了解决这些问题，我们提出了一种新颖的seq2seq模型GPRL，将嵌套NER任务形成一个实体三元组序列生成过程。GPRL采用强化学习方法生成实体三元组，将金标签中的实体顺序解耦，并期望通过试错学习合理的实体识别顺序。基于嵌套实体边界距离的统计，GPRL设计了一个高斯先验，代表嵌套实体之间的边界距离分布，并调整嵌套边界标记的输出概率分布。在三个嵌套NER数据集上的实验证明，GPRL优于以前的嵌套NER模型。

    Named Entity Recognition (NER) is a well and widely studied task in natural language processing. Recently, the nested NER has attracted more attention since its practicality and difficulty. Existing works for nested NER ignore the recognition order and boundary position relation of nested entities. To address these issues, we propose a novel seq2seq model named GPRL, which formulates the nested NER task as an entity triplet sequence generation process. GPRL adopts the reinforcement learning method to generate entity triplets decoupling the entity order in gold labels and expects to learn a reasonable recognition order of entities via trial and error. Based on statistics of boundary distance for nested entities, GPRL designs a Gaussian prior to represent the boundary distance distribution between nested entities and adjust the output probability distribution of nested boundary tokens. Experiments on three nested NER datasets demonstrate that GPRL outperforms previous nested NER models.
    
[^34]: 通过缩放实现更好的语音合成

    Better speech synthesis through scaling. (arXiv:2305.07243v1 [cs.SD])

    [http://arxiv.org/abs/2305.07243](http://arxiv.org/abs/2305.07243)

    该论文介绍了一种将图像生成方法应用于语音合成领域的方法，提出了一个表达性强、多语音的文本转语音系统TorToise。

    

    近年来，图像生成领域在自回归变换器和DDPM的应用下得到了革命性突破。这些方法将图像生成过程建模为逐步概率过程，并利用大量的计算和数据来学习图像分布。本文将这种性能提升方法运用到语音合成中，提出了一种名为TorToise的表达性、多语音的文本转语音系统。所有模型代码和训练权重均已开源，存放于https://github.com/neonbjb/tortoise-tts。

    In recent years, the field of image generation has been revolutionized by the application of autoregressive transformers and DDPMs. These approaches model the process of image generation as a step-wise probabilistic processes and leverage large amounts of compute and data to learn the image distribution. This methodology of improving performance need not be confined to images. This paper describes a way to apply advances in the image generative domain to speech synthesis. The result is TorToise -- an expressive, multi-voice text-to-speech system.  All model code and trained weights have been open-sourced at https://github.com/neonbjb/tortoise-tts.
    
[^35]: 当超级语言模型不足以满足业务需求：领域特定知识提升自然语言处理性能

    When Giant Language Brains Just Aren't Enough! Domain Pizzazz with Knowledge Sparkle Dust. (arXiv:2305.07230v1 [cs.CL])

    [http://arxiv.org/abs/2305.07230](http://arxiv.org/abs/2305.07230)

    本文将保险问答作为案例研究，提出了一种新模型，通过从保险政策手册中提取领域特定知识来增强LLMs的性能，实现领域适应，从而显著提高推理准确性。

    

    大型语言模型（LLMs）已经显著地推动了自然语言处理领域的进展，GPT模型处于领先地位。虽然它们在许多任务上的表现令人惊叹，但将LLMs用于真实世界的业务场景仍然面临挑战，并需要进一步研究。本文提出了一种经验分析，旨在弥合将LLMs适应于实际使用情况的差距。为此，我们选择保险问答（QA）任务作为案例研究，因为它具有推理的挑战。基于该任务，我们设计了一种新模型，依赖于从保险政策手册中提取的领域特定知识，使LLMs能够理解保险的新概念进行领域适应。实际QA对的初步结果表明，从政策手册中提取的知识显著提高了GPT-3.5的推理能力，准确性提高了50.4％。分析还表明，现有的公开评估标准可能不足以评估LLMs在实际场景中的性能。

    Large language models (LLMs) have significantly advanced the field of natural language processing, with GPT models at the forefront. While their remarkable performance spans a range of tasks, adapting LLMs for real-world business scenarios still poses challenges warranting further investigation. This paper presents an empirical analysis aimed at bridging the gap in adapting LLMs to practical use cases. To do that, we select the question answering (QA) task of insurance as a case study due to its challenge of reasoning. Based on the task we design a new model relied on LLMs which are empowered by domain-specific knowledge extracted from insurance policy rulebooks. The domain-specific knowledge helps LLMs to understand new concepts of insurance for domain adaptation. Preliminary results on real QA pairs show that knowledge enhancement from policy rulebooks significantly improves the reasoning ability of GPT-3.5 of 50.4% in terms of accuracy. The analysis also indicates that existing publ
    
[^36]: 面向模型预测解释的非对称特征交互

    Asymmetric feature interaction for interpreting model predictions. (arXiv:2305.07224v1 [cs.CL])

    [http://arxiv.org/abs/2305.07224](http://arxiv.org/abs/2305.07224)

    本文提出了一种解释模型，能够探索深度神经自然语言处理模型推理中的非对称高阶特征交互。在两个情感分类数据集上的实验结果表明，该模型在识别影响特征方面优于现有特征交互归因方法。

    

    在自然语言处理领域，深度神经网络能够模拟上下文之间的复杂交互，并在一系列自然语言处理任务上取得了令人瞩目的成果。先前有关特征交互归因的研究主要集中在对称交互的研究上，它只能解释单个词汇组合后对模型预测的附加影响，而无法捕捉导致模型预测的非对称影响。在本文中，我们提出了一个非对称特征交互解释模型，旨在探索深度神经自然语言处理模型推理中的非对称高阶特征交互。通过表示我们的解释为一个有向交互图，我们实验验证了该图的可解释性，能够发现非对称特征交互作用。在两个情感分类数据集上的实验结果表明，我们的模型在识别影响特征方面优于现有特征交互归因方法。

    In natural language processing (NLP), deep neural networks (DNNs) could model complex interactions between context and have achieved impressive results on a range of NLP tasks. Prior works on feature interaction attribution mainly focus on studying symmetric interaction that only explains the additional influence of a set of words in combination, which fails to capture asymmetric influence that contributes to model prediction. In this work, we propose an asymmetric feature interaction attribution explanation model that aims to explore asymmetric higher-order feature interactions in the inference of deep neural NLP models. By representing our explanation with an directed interaction graph, we experimentally demonstrate interpretability of the graph to discover asymmetric feature interactions. Experimental results on two sentiment classification datasets show the superiority of our model against the state-of-the-art feature interaction attribution methods in identifying influential featu
    
[^37]: OneCAD: 使用多模态学习的单分类器适用于所有图像数据集

    OneCAD: One Classifier for All image Datasets using multimodal learning. (arXiv:2305.07167v1 [cs.CV])

    [http://arxiv.org/abs/2305.07167](http://arxiv.org/abs/2305.07167)

    本文提出了一种训练和推断框架OneCAD，通过Mask-Image-Modeling(MIM)和多模态学习解决了当前架构(如ViTs和CNNs)存在的问题，并创建了一种可以适用于所有图像数据集且与类别数无关的DNN模型架构。

    

    视觉变换器(ViTs)和卷积神经网络(CNNs)是广泛使用的用于分类任务的深度神经网络(DNNs)。这些模型架构依赖于它所训练的数据集中类别数的数量。类别数的任何改变都会导致模型架构的改变(部分或全部)。本文探讨了一个问题：是否可能创建一个与类别数无关的模型架构？这样可以使模型架构与其所训练的数据集无关。本文强调了当前架构(ViTs和CNNs)存在的问题。同时，提出了一个训练和推断框架- OneCAD(适用于所有图像数据集的单分类器)，以实现接近与类别数无关的变压器模型。据我们所知，这是第一个使用多模态学习进行分类任务的Mask-Image-Modeling(MIM)，以创建一个与类别数无关的DNN模型架构的工作。初步结果已在自然图像分类任务上展示。

    Vision-Transformers (ViTs) and Convolutional neural networks (CNNs) are widely used Deep Neural Networks (DNNs) for classification task. These model architectures are dependent on the number of classes in the dataset it was trained on. Any change in number of classes leads to change (partial or full) in the model's architecture. This work addresses the question: Is it possible to create a number-of-class-agnostic model architecture?. This allows model's architecture to be independent of the dataset it is trained on. This work highlights the issues with the current architectures (ViTs and CNNs). Also, proposes a training and inference framework OneCAD (One Classifier for All image Datasets) to achieve close-to number-of-class-agnostic transformer model. To best of our knowledge this is the first work to use Mask-Image-Modeling (MIM) with multimodal learning for classification task to create a DNN model architecture agnostic to the number of classes. Preliminary results are shown on natu
    
[^38]: 探索零样本和小样本技术用于意图分类

    Exploring Zero and Few-shot Techniques for Intent Classification. (arXiv:2305.07157v1 [cs.CL])

    [http://arxiv.org/abs/2305.07157](http://arxiv.org/abs/2305.07157)

    探讨了四种零样本和小样本意图分类方法，包括领域适应、数据增强、使用大型语言模型的零样本意图分类以及指令微调语言模型的参数有效微调，结果表明这些方法在低资源环境下都是有效的。指令微调语言模型的参数有效微调性能最佳。

    

    会话中自然语言理解的提供者通常需要扩展到数千个意图分类模型，其中新客户经常面临冷启动问题。在拥有这么多客户的情况下扩展，会对存储空间施加限制。本文探讨了四种不同的零样本和小样本意图分类方法，这些方法受到低资源限制的制约：1）领域适应，2）数据增强，3）使用大型语言模型（LLM）的零样本意图分类，以及4）指令微调语言模型的参数有效微调。我们的结果表明，所有这些方法在低资源环境下都是有效的，但程度不同。使用Flan-T5（Chang et al，2022）在T-few配方（Liu et al，2022）上进行参数有效微调，即使每个意图只有一个样本，性能也最佳。我们还展示了使用意图描述提示LLM的零样本方法。

    Conversational NLU providers often need to scale to thousands of intent-classification models where new customers often face the cold-start problem. Scaling to so many customers puts a constraint on storage space as well. In this paper, we explore four different zero and few-shot intent classification approaches with this low-resource constraint: 1) domain adaptation, 2) data augmentation, 3) zero-shot intent classification using descriptions large language models (LLMs), and 4) parameter-efficient fine-tuning of instruction-finetuned language models. Our results show that all these approaches are effective to different degrees in low-resource settings. Parameter-efficient fine-tuning using T-few recipe (Liu et al., 2022) on Flan-T5 (Chang et al., 2022) yields the best performance even with just one sample per intent. We also show that the zero-shot method of prompting LLMs using intent descriptions
    
[^39]: 机器理由对人类是否有用？评估和提高自然文本理由的人类效用

    Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-Text Rationales. (arXiv:2305.07095v1 [cs.CL])

    [http://arxiv.org/abs/2305.07095](http://arxiv.org/abs/2305.07095)

    该论文研究了机器产生的自然语言理由对人类是否有用，发现现有理由的人类效用远低于理想状态，并提出通过估计理由在回答给定问题中的有用性来提高机器生成理由的人类效用。

    

    在大型语言模型（LMs）的显着出现能力中，自由文本理由是其中之一；超过某个规模后，大型LMs能够生成看似有用的理由，进而可以极大地增强它们在领导榜上的表现。这种现象引发了一个问题：机器生成的理由是否也能对人类有用，特别是当普通人尝试根据这些机器理由回答问题时？我们观察到现有理由的人类效用远未令人满意，并且昂贵的人类研究才能估计。现有的评估指标，如生成理由LM的任务表现或生成理由与黄金理由之间的相似性，并不能很好地表明它们的人类效用。虽然我们观察到，理由的某些属性，如简洁性和新颖性，与它们的人类效用有关，但在没有人类参与的情况下估计它们是具有挑战性的。我们展示了如何通过估计理由在回答给定问题中的有用性来提高机器生成理由的人类效用，从而解决这个问题。

    Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond a certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards. This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales? We observe that human utility of existing rationales is far from satisfactory, and expensive to estimate with human studies. Existing metrics like task performance of the LM generating the rationales, or similarity between generated and gold rationales are not good indicators of their human utility. While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging. We show that, by estimating a rationale's helpfulness in ans
    
[^40]: 引导噪声攻击增强对比学习：朝向野外持续关系提取

    Enhancing Contrastive Learning with Noise-Guided Attack: Towards Continual Relation Extraction in the Wild. (arXiv:2305.07085v1 [cs.CL])

    [http://arxiv.org/abs/2305.07085](http://arxiv.org/abs/2305.07085)

    本研究提出了一种耐噪声的对比框架 NaCl 来在嘈杂标签下学习逐步受损的关系，相比于直接丢弃或重新标记噪声，通过攻击特征空间使其适应嘈杂标签是更好的方式。

    

    “不断关系提取”的原则是适应新兴的关系而保留旧有的知识。当前的持续关系提取工作成功地保留了旧有的知识，但在面对出现污染数据流时往往会失败。本文认为这是由于它们依赖一种人工假设，即数据流没有注释错误，这限制了持续关系提取在实际应用中的发展。考虑到实际数据集中嘈杂的标签的普遍存在，我们提出了一个更实用的学习场景，称为“噪声持续关系提取”。在这个具有挑战性的背景下，我们开发了一个耐噪声的对比框架，名为 “NACl”，用于学习逐步受损的关系。与直接丢弃噪声或无法访问的噪声重新标记相比，我们提出通过攻击来修改特征空间以匹配给定的嘈杂标签是更好的丰富对比学习。

    The principle of continual relation extraction~(CRE) involves adapting to emerging novel relations while preserving od knowledge. While current endeavors in CRE succeed in preserving old knowledge, they tend to fail when exposed to contaminated data streams. We assume this is attributed to their reliance on an artificial hypothesis that the data stream has no annotation errors, which hinders real-world applications for CRE. Considering the ubiquity of noisy labels in real-world datasets, in this paper, we formalize a more practical learning scenario, termed as \textit{noisy-CRE}. Building upon this challenging setting, we develop a noise-resistant contrastive framework named as \textbf{N}oise-guided \textbf{a}ttack in \textbf{C}ontrative \textbf{L}earning~(NaCL) to learn incremental corrupted relations. Compared to direct noise discarding or inaccessible noise relabeling, we present modifying the feature space to match the given noisy labels via attacking can better enrich contrastive 
    
[^41]: 基于端到端深度学习的古兰经朗诵识别

    Quran Recitation Recognition using End-to-End Deep Learning. (arXiv:2305.07034v1 [eess.AS])

    [http://arxiv.org/abs/2305.07034](http://arxiv.org/abs/2305.07034)

    本文提出了一种基于端到端深度学习模型，使用CTC作为目标函数，来识别古兰经的朗诵。采用公共数据集进行实验。

    

    古兰经是伊斯兰教的圣书，其朗诵是该宗教信仰的一个重要方面。由于古兰经的独特规则不适用于正常的演讲，所以自动识别古兰经的朗诵是一项具有挑战性的任务。在此之前，已进行了许多研究，但以往的研究将朗诵错误检测视为分类任务或使用传统的自动语音识别（ASR）。在本文中，我们提出了一个新的基于端到端深度学习模型来识别古兰经的朗诵。该模型是一个CNN-Bidirectional GRU编码器，使用CTC作为目标函数和基于字符的解码器，即波束搜索解码器。此外，所有以往的研究都是在由短节和几章古兰经组成的小型私人数据集上进行的。由于使用私人数据集，因此没有进行任何比较。为了解决这个问题，我们使用了最近发布的公共数据集（Ar-DAD）作为实验数据。

    The Quran is the holy scripture of Islam, and its recitation is an important aspect of the religion. Recognizing the recitation of the Holy Quran automatically is a challenging task due to its unique rules that are not applied in normal speaking speeches. A lot of research has been done in this domain, but previous works have detected recitation errors as a classification task or used traditional automatic speech recognition (ASR). In this paper, we proposed a novel end-to-end deep learning model for recognizing the recitation of the Holy Quran. The proposed model is a CNN-Bidirectional GRU encoder that uses CTC as an objective function, and a character-based decoder which is a beam search decoder. Moreover, all previous works were done on small private datasets consisting of short verses and a few chapters of the Holy Quran. As a result of using private datasets, no comparisons were done. To overcome this issue, we used a public dataset that has recently been published (Ar-DAD) and co
    
[^42]: Musketeer（一人之力，万人之力）：具有任务解释提示的通用视觉语言模型

    Musketeer (All for One, and One for All): A Generalist Vision-Language Model with Task Explanation Prompts. (arXiv:2305.07019v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2305.07019](http://arxiv.org/abs/2305.07019)

    Musketeer是一种通用视觉语言模型，采用任务解释提示（TEP）机制，能够有效整合异构任务的知识，并在多个任务中表现均匀

    

    我们提出了一种序列到序列的视觉语言模型，其参数在所有任务上进行联合训练（万人之力），并在多个任务之间完全共享（一人之力），从而产生了一个名为Musketeer的单一模型。

    We present a sequence-to-sequence vision-language model whose parameters are jointly trained on all tasks (all for one) and fully shared among multiple tasks (one for all), resulting in a single model which we named Musketeer. The integration of knowledge across heterogeneous tasks is enabled by a novel feature called Task Explanation Prompt (TEP). TEP reduces interference among tasks, allowing the model to focus on their shared structure. With a single model, Musketeer achieves results comparable to or better than strong baselines trained on single tasks, almost uniformly across multiple tasks.
    
[^43]: ChatGPT式的大规模基础模型在预测与健康管理中的应用：综述与路线图

    ChatGPT-Like Large-Scale Foundation Models for Prognostics and Health Management: A Survey and Roadmaps. (arXiv:2305.06472v1 [cs.LG])

    [http://arxiv.org/abs/2305.06472](http://arxiv.org/abs/2305.06472)

    该论文综述了基于大规模基础模型（LSF-Models）如ChatGPT和DALLE-E的人工智能（AI）技术在预测与健康管理（PHM）中的广泛应用。这种技术可以实现多模态、多任务、大量数据和超大模型范式，成为AI-2.0的新时代的标志之一。

    

    预测与健康管理技术在工业生产和设备维护中扮演着至关重要的角色，通过基于人工智能的PHM技术识别和预测设备故障和损坏。现在，基于大规模基础模型（LSF-Models）如ChatGPT和DALLE-E的AI技术，可以实现多模态、多任务、大规模数据和超大模型范式，成为AI-2.0的新时代的标志之一。这种技术广泛应用于各种工业领域，如铁路、能源和航空等，以提高设备的服务寿命和可靠性，同时降低生产成本和停机时间。

    Prognostics and health management (PHM) technology plays a critical role in industrial production and equipment maintenance by identifying and predicting possible equipment failures and damages, thereby allowing necessary maintenance measures to be taken to enhance equipment service life and reliability while reducing production costs and downtime. In recent years, PHM technology based on artificial intelligence (AI) has made remarkable achievements in the context of the industrial IoT and big data, and it is widely used in various industries, such as railway, energy, and aviation, for condition monitoring, fault prediction, and health management. The emergence of large-scale foundation models (LSF-Models) such as ChatGPT and DALLE-E marks the entry of AI into a new era of AI-2.0 from AI-1.0, where deep models have rapidly evolved from a research paradigm of single-modal, single-task, and limited-data to a multi-modal, multi-task, massive data, and super-large model paradigm. ChatGPT r
    
[^44]: SUR-adapter：用大型语言模型增强文本-图像预训练扩散模型

    SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models. (arXiv:2305.05189v1 [cs.CL])

    [http://arxiv.org/abs/2305.05189](http://arxiv.org/abs/2305.05189)

    本文提出了一个名为SUR-adapter的微调方法，用于增强预先训练的文本到图像扩散模型的语义理解和常识推理能力，以便在生成图片时使用简短的叙述提示。作者还构建了一个新的数据集SURD，并使用大型语言模型的知识进行了优化。

    

    扩散模型是目前流行的文本到图像生成模型，可以通过文本提示生成具有高质量和内容丰富度的图像。但是，当输入的提示为简短的叙述时，现有模型在语义理解和常识推理方面存在一定限制，导致图像生成的质量较低。为了提高叙述提示的能力，我们提出了一种简单而有效的参数高效的微调方法，称为Semantic Understanding和Reasoning adapter（SUR-adapter），用于预先训练的扩散模型。为实现这一目标，我们首先收集和注释一个新的数据集SURD，其中包含超过57,000个语义修正的多模态样本。每个样本都包含一个简单的叙述提示，一个复杂的基于关键字的提示和一个高质量的图像。然后，我们将叙述提示的语义表示与复杂提示对齐，并通过大型语言模型的知识将其转移至我们的SUR-adapter中。

    Diffusion models, which have emerged to become popular text-to-image generation models, can produce high-quality and content-rich images guided by textual prompts. However, there are limitations to semantic understanding and commonsense reasoning in existing models when the input prompts are concise narrative, resulting in low-quality image generation. To improve the capacities for narrative prompts, we propose a simple-yet-effective parameter-efficient fine-tuning approach called the Semantic Understanding and Reasoning adapter (SUR-adapter) for pre-trained diffusion models. To reach this goal, we first collect and annotate a new dataset SURD which consists of more than 57,000 semantically corrected multi-modal samples. Each sample contains a simple narrative prompt, a complex keyword-based prompt, and a high-quality image. Then, we align the semantic representation of narrative prompts to the complex prompts and transfer knowledge of large language models (LLMs) to our SUR-adapter vi
    
[^45]: 神经调节门控Transformer

    Neuromodulation Gated Transformer. (arXiv:2305.03232v1 [cs.CL])

    [http://arxiv.org/abs/2305.03232](http://arxiv.org/abs/2305.03232)

    本文介绍了一种新型的神经调节门控Transformer架构，通过乘法效应实现了神经调节，在SuperGLUE基准验证集上表现最优。

    

    我们引入了一种新颖的架构，即神经调节门控Transformer（NGT），它通过一种乘法效应，实现了Transformer中的神经调节的简单实现。我们将其与基准模型进行比较，并展示其在SuperGLUE基准验证集上达到最佳平均性能。

    We introduce a novel architecture, the Neuromodulation Gated Transformer (NGT), which is a simple implementation of neuromodulation in transformers via a multiplicative effect. We compare it to baselines and show that it results in the best average performance on the SuperGLUE benchmark validation sets.
    
[^46]: ChatGPT在句子级关系上的评估：重点关注时间、因果和语篇关系

    ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations. (arXiv:2304.14827v1 [cs.CL])

    [http://arxiv.org/abs/2304.14827](http://arxiv.org/abs/2304.14827)

    本论文评估了ChatGPT在句子级别的时间、因果和语篇关系任务中的性能，发现其在检测和推理因果关系上表现出色，但在识别时间顺序方面可能存在问题。

    

    本文旨在定量评估ChatGPT，在时间关系、因果关系和语篇关系等句间关系方面的性能。考虑到ChatGPT在各种任务中表现出色，我们在13个数据集的整个测试集上进行了广泛的评估，包括时间和因果关系、基于PDTB2.0和基于对话的语篇关系，以及关于对话理解的下游应用。为了获得可靠的结果，我们采用了三种针对每个任务的定制提示模板，包括零-shot提示模板、零-shot提示工程（PE）模板和上下文学习（ICL）提示模板，为所有流行的句对关系分类任务建立了初始基准分数。我们发现，ChatGPT在检测和推理因果关系方面表现出色，但可能不擅长识别句子间的时间顺序。ICL方法特别适用于提高一些数据集上的模型性能。我们的发现为模型改进和有效提示模板的设计提供了一些见解。

    This paper aims to quantitatively evaluate the performance of ChatGPT, an interactive large language model, on inter-sentential relations such as temporal relations, causal relations, and discourse relations. Given ChatGPT's promising performance across various tasks, we conduct extensive evaluations on the whole test sets of 13 datasets, including temporal and causal relations, PDTB2.0-based and dialogue-based discourse relations, and downstream applications on discourse understanding. To achieve reliable results, we adopt three tailored prompt templates for each task, including the zero-shot prompt template, zero-shot prompt engineering (PE) template, and in-context learning (ICL) prompt template, to establish the initial baseline scores for all popular sentence-pair relation classification tasks for the first time. We find that ChatGPT exhibits strong performance in detecting and reasoning about causal relations, while it may not be proficient in identifying the temporal order betwe
    
[^47]: GPT-NER：基于大型语言模型的命名实体识别

    GPT-NER: Named Entity Recognition via Large Language Models. (arXiv:2304.10428v1 [cs.CL])

    [http://arxiv.org/abs/2304.10428](http://arxiv.org/abs/2304.10428)

    本文提出了GPT-NER来解决大型语言模型在命名实体识别任务（NER）上表现不佳的问题，它通过将序列标记任务转化为生成任务，将LLM能够容易地适应NER任务。同时，为了有效解决LLMs“幻觉”问题，作者们提出了自我验证策略，通过提示LLMs询问自身来确定提取的实体是否属于实际存在的实体。

    

    尽管大规模语言模型（LLM）在各种NLP任务上已经实现了最先进的性能，但其NER性能仍然明显低于监督基线。这是由于命名实体识别（NER）和LLMs之间的差距：前者在本质上是序列标记任务，后者是一种文本生成模型。在本文中，我们提出了GPT-NER来解决这个问题。 GPT-NER通过将序列标记任务转换为生成任务来弥合差距，LLMs可以轻松适应。例如，将在输入文本“哥伦布是一座城市”中查找位置实体的任务转换为生成文本序列“@@哥伦布##是一座城市”，其中特殊标记@@##标记要提取的实体。为了有效解决LLMs“幻觉”问题，即LLMs有很强的倾向将空输入过度自信地标记为实体，我们提出了自我验证策略，通过提示LLMs询问自身来确定提取的实体是否属于实际存在的实体。

    Despite the fact that large-scale Language Models (LLM) have achieved SOTA performances on a variety of NLP tasks, its performance on NER is still significantly below supervised baselines. This is due to the gap between the two tasks the NER and LLMs: the former is a sequence labeling task in nature while the latter is a text-generation model.  In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the gap by transforming the sequence labeling task to a generation task that can be easily adapted by LLMs e.g., the task of finding location entities in the input text "Columbus is a city" is transformed to generate the text sequence "@@Columbus## is a city", where special tokens @@## marks the entity to extract. To efficiently address the "hallucination" issue of LLMs, where LLMs have a strong inclination to over-confidently label NULL inputs as entities, we propose a self-verification strategy by prompting LLMs to ask itself whether the extracted entities belong to a lab
    
[^48]: PLUE：英文隐私政策语言理解评估基准

    PLUE: Language Understanding Evaluation Benchmark for Privacy Policies in English. (arXiv:2212.10011v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10011](http://arxiv.org/abs/2212.10011)

    PLUE是一个多任务评估基准，用于评估英文隐私政策语言理解的各种任务。研究者还收集了大量的隐私政策语料库，以支持隐私政策领域特定语言模型的预训练，持续预训练可以提高性能。

    

    隐私政策向个人提供其权利以及如何处理与之相关的个人信息的信息。自然语言理解(NLU)技术可以帮助人们理解长且复杂的文档中描述的隐私实践。然而，现有的NLU技术在处理语言时存在一定的局限性，仅专注于特定的隐私实践任务。因此，我们引入了隐私政策语言理解评估(PLUE)基准，这是一个多任务基准，用于评估不同任务中的隐私政策语言理解。我们还收集了大量的隐私政策语料库，以支持隐私政策领域特定语言模型的预训练。我们评估了几种通用的预训练语言模型，并对其进行了收集的语料库的持续预训练。我们证明了领域特定的持续预训练在所有任务中都可以提高性能。

    Privacy policies provide individuals with information about their rights and how their personal information is handled. Natural language understanding (NLU) technologies can support individuals and practitioners to understand better privacy practices described in lengthy and complex documents. However, existing efforts that use NLU technologies are limited by processing the language in a way exclusive to a single task focusing on certain privacy practices. To this end, we introduce the Privacy Policy Language Understanding Evaluation (PLUE) benchmark, a multi-task benchmark for evaluating the privacy policy language understanding across various tasks. We also collect a large corpus of privacy policies to enable privacy policy domain-specific language model pre-training. We evaluate several generic pre-trained language models and continue pre-training them on the collected corpus. We demonstrate that domain-specific continual pre-training offers performance improvements across all tasks
    
[^49]: 《RHO ($\rho$)：利用知识链接减少开放域对话中的幻觉》

    RHO ($\rho$): Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding. (arXiv:2212.01588v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01588](http://arxiv.org/abs/2212.01588)

    本文介绍了一种名为RHO ($\rho$)的方法，利用知识图谱中链接实体和关系谓词的表示来减少对话系统中产生的幻觉，提高了对话推理能力，并采用基于知识图谱子图漫步的回复重新排序技术。

    

    对话系统可以利用大型预训练语言模型和知识库生成流畅且信息丰富的回复。然而，这些模型仍然容易产生幻觉式的回复，并严重影响应用。外部知识和对话上下文之间的异构性挑战了表征学习和源集成，进一步导致不忠实性。为了应对这一挑战并生成更忠实的回复，本文提出了一种使用知识图谱中链接实体和关系谓词的表示来减少幻觉的方法，即RHO ($\rho$)。我们提出了(1)本地知识基础，将文本嵌入与对应的知识图谱嵌入相结合；以及(2)全局知识基础，通过注意机制使RHO具有多次跳推理能力。此外，我们设计了一种基于知识图谱子图漫步的回复重新排序技术，以实现更好的对话推理。

    Dialogue systems can leverage large pre-trained language models and knowledge to generate fluent and informative responses. However, these models are still prone to produce hallucinated responses not supported by the input source, which greatly hinders their application. The heterogeneity between external knowledge and dialogue context challenges representation learning and source integration, and further contributes to unfaithfulness. To handle this challenge and generate more faithful responses, this paper presents RHO ($\rho$) utilizing the representations of linked entities and relation predicates from a knowledge graph (KG). We propose (1) local knowledge grounding to combine textual embeddings with the corresponding KG embeddings; and (2) global knowledge grounding to equip RHO with multi-hop reasoning abilities via the attention mechanism. In addition, we devise a response re-ranking technique based on walks over KG sub-graphs for better conversational reasoning. Experimental re
    
[^50]: GLUE-X: 从ODD普适性角度评估自然语言理解模型

    GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective. (arXiv:2211.08073v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08073](http://arxiv.org/abs/2211.08073)

    本文提出了第一个创建名为方法的统一基准的尝试，用于评估NLP模型中的OOD鲁棒性，该基准包括13个公开可用的OOD测试数据集，并在21个常用的PLMs上对8个经典NLP任务进行评估。

    

    预训练语言模型（PLMs）通过利用大量的训练数据，已知可以提高自然语言理解模型的泛化性能。然而，许多NLP任务中的ODD普适性问题仍然存在，这限制了这些方法在现实世界中的部署。本文提出了第一个创建名为方法的统一基准的尝试，用于评估NLP模型中的OOD鲁棒性，强调OOD鲁棒性的重要性，并提供如何衡量模型的鲁棒性以及如何改善模型的见解。该基准包括13个公开可用的OOD测试数据集，并在21个常用的PLMs（包括GPT-3和GPT-3.5）上对8个经典NLP任务进行评估。我们的研究结果确认了在所有设置下，与ID准确度相比，存在显着的性能下降，需要改善NLP任务中的OOD准确度。

    Pre-trained language models (PLMs) are known to improve the generalization performance of natural language understanding models by leveraging large amounts of data during the pre-training phase. However, the out-of-distribution (OOD) generalization problem remains a challenge in many NLP tasks, limiting the real-world deployment of these methods. This paper presents the first attempt at creating a unified benchmark named \method for evaluating OOD robustness in NLP models, highlighting the importance of OOD robustness and providing insights on how to measure the robustness of a model and how to improve it. The benchmark includes 13 publicly available datasets for OOD testing, and evaluations are conducted on 8 classic NLP tasks over 21 popularly used PLMs, including GPT-3 and GPT-3.5. Our findings confirm the need for improved OOD accuracy in NLP tasks, as significant performance degradation was observed in all settings compared to in-distribution (ID) accuracy.
    
[^51]: 以训练数据生成器为调整语言模型的增强学习少样本方法

    Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning. (arXiv:2211.03044v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.03044](http://arxiv.org/abs/2211.03044)

    该论文通过调整预训练语言模型生成大量新的训练样本，从而增强原始训练集，提高了少样本学习的性能。

    

    最近的研究揭示了预训练语言模型（PLM）惊人的少样本学习能力：它们可以在以提示形式表达的少量标记数据上微调后快速适应新任务，而无需丰富的任务特定注释。尽管有着很有前途的表现，但大多数仅从少量训练集学习的现有少样本方法仍然比非平凡的全监督训练表现不佳。在本文中，我们从不同的角度研究了使用PLMs进行少样本学习：我们首先调整自回归PLM，然后使用它作为生成器，合成大量新的训练样本，以增强原始训练集。为了鼓励生成器产生具有标签区分能力的样本，我们通过加权最大似然度量训练它，在其中每个令牌的权重基于一个区分性元学习目标自动调整。然后可以在增加后的训练集上微调分类PLM。

    Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective. A classification PLM can then be fine-tuned on both the f
    

