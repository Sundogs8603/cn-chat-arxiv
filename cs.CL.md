# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [North S\'{a}mi Dialect Identification with Self-supervised Speech Models.](http://arxiv.org/abs/2305.11864) | 该论文使用自监督语音模型 successfully 区分了北萨米语言的四种方言变体，并发现这些方言受到了国家语言的影响。 |
| [^2] | [Scaling laws for language encoding models in fMRI.](http://arxiv.org/abs/2305.11863) | 本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。 |
| [^3] | [Reducing Sequence Length by Predicting Edit Operations with Large Language Models.](http://arxiv.org/abs/2305.11862) | 本文提出利用大型语言模型预测源文本中的编辑操作来减少序列长度的方法，从而减少计算成本，实验表明其达到了可比较的性能。 |
| [^4] | [Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs.](http://arxiv.org/abs/2305.11860) | 本文提出了一种名为自适应一致性 (Adaptive-Consistency) 的技术，可以动态调整每个问题的样本数量，从而有效减少样本预算，并较小程度地降低了平均准确度 |
| [^5] | [Complex Claim Verification with Evidence Retrieved in the Wild.](http://arxiv.org/abs/2305.11859) | 本文介绍了一种新的自动事实核查流程，可以通过从网络中检索原始证据来检查实际主张。我们的流程包括五个部分：主张分解，原始文档检索，细粒度证据检索，主张焦点摘要和判断真实性。研究表明，我们的流程可以改善真实性判断，我们提供的证据摘要更易于理解。 |
| [^6] | [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings.](http://arxiv.org/abs/2305.11853) | 本文针对引导LLMs进行文本到SQL的任务中提示文本构建问题展开了综合探究，从而为未来的研究提供了见解。 |
| [^7] | [Any-to-Any Generation via Composable Diffusion.](http://arxiv.org/abs/2305.11846) | CoDi是一种生成模型，通过在输入空间和输出空间中进行模态对齐，实现了可组合生成策略，从而可以生成任意组合的输出模态。 CoDi 非常灵活，能够生成多个模态，如图像、视频、语言和音频，甚至在训练数据中不存在的模态组合。 |
| [^8] | [RxnScribe: A Sequence Generation Model for Reaction Diagram Parsing.](http://arxiv.org/abs/2305.11845) | RxnScribe是一种端到端的机器学习模型，用于解析化学文献中复杂的反应图，并在交叉验证中取得了较高的分数。 |
| [^9] | [How Does Generative Retrieval Scale to Millions of Passages?.](http://arxiv.org/abs/2305.11841) | 本研究对不同语料规模下的生成式检索技术进行了实证研究，扩展到包含8.8M篇章的MS MARCO检索任务，并评估了高达11B个参数的模型大小，揭示出了在索引期间使用合成查询作为文档表示的重要性。 |
| [^10] | [SeeGULL: A Stereotype Benchmark with Broad Geo-Cultural Coverage Leveraging Generative Models.](http://arxiv.org/abs/2305.11840) | 该论文提出了一个广泛覆盖不同地理和文化背景下的刻板印象的基准测试数据集SeeGULL，使用大型语言模型生成刻板印象，针对178个国家、8个不同地缘政治地区和美国与印度的州级身份群体进行了评估，以提高NLP模型对全球多元化人群的敏感性。 |
| [^11] | [Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews.](http://arxiv.org/abs/2305.11828) | 本文研究了使用LLM协助制作医学证据综述的潜在用途和风险，指出LLM有可能自动生成文献综述，但由于可能出现虚构或遗漏信息的情况，LLM的使用需要谨慎。 |
| [^12] | [STOAT: Structured Data to Analytical Text With Controls.](http://arxiv.org/abs/2305.11826) | STOAT模型是表格和推理意识的生成模型，在数字推理、常识推理、时间推理、表格知识和实体知识方面有较好的控制，提高了分析句子生成的质量和准确度。 |
| [^13] | [Pseudo-Label Training and Model Inertia in Neural Machine Translation.](http://arxiv.org/abs/2305.11808) | 本研究着重研究了NMT中经常使用的伪标签训练（PLT），发现PLT不仅会影响质量，而且可以增强模型对模型更新和输入扰动的稳定性，形成模型惯性。 |
| [^14] | [The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics.](http://arxiv.org/abs/2305.11806) | 本文开发多种神经可解释方法，并展示了它们用于解释最先进微调神经度量的有效性，揭示了这些度量用来利用令人直接归因于翻译错误的令牌级信息。 |
| [^15] | [Chain-of-thought prompting for responding to in-depth dialogue questions with LLM.](http://arxiv.org/abs/2305.11792) | 本文提出使用思路链索引的方式来响应用户状态，以提供更个性化和更有吸引力的用户体验，用语义相似性而非测试查询做中间推理处理。 |
| [^16] | [Enhancing Few-shot NER with Prompt Ordering based Data Augmentation.](http://arxiv.org/abs/2305.11791) | 本文提出了一种基于Prompt Ordering的数据增强方法来提高Few-shot NER的鲁棒性和泛化性，不同但合理的目标序列提供了更多的多样性。实验证明该方法可扩展性好，比传统方法更有效。 |
| [^17] | [Prompting with Pseudo-Code Instructions.](http://arxiv.org/abs/2305.11790) | 本文研究了使用伪代码指令提示能否提高预训练语言模型的性能，实验证明使用伪代码提示可以在分类任务中提高7-16分，并相对改善12-38%。 |
| [^18] | [Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach.](http://arxiv.org/abs/2305.11789) | 本研究提出了一种基于讨论的方法，旨在通过人机协作解决自然语言处理难题。提出了一个可以进行对话并修正预测的系统，通过实验证明该系统可以通过与人类的讨论提高准确性高达25%。 |
| [^19] | [DMDD: A Large-Scale Dataset for Dataset Mentions Detection.](http://arxiv.org/abs/2305.11779) | DMDD是一个公开的数据集，用于数据集提及检测任务，包含31,219篇科学文章和超过449,000个弱注释的数据集提及。该数据集为该任务建立了基准性能，并且通过分析模型的表现，确定了开放问题。 |
| [^20] | [Cross-Lingual Supervision improves Large Language Models Pre-training.](http://arxiv.org/abs/2305.11778) | 本文表明，将大型语言模型的预训练中使用跨语种并行数据能提高其上下文学习能力；同时，提出了一种简单且有效的策略来学习两个目标之间的最佳混合比例。 |
| [^21] | [Enhancing Vision-Language Pre-Training with Jointly Learned Questioner and Dense Captioner.](http://arxiv.org/abs/2305.11769) | 本文提出了一种名为JADE的新方法，可以利用易于获取的图像-文本对进行的联合学习，以提升视觉和语言模态的细粒度特征对齐，从而更好地进行视觉问答和密集字幕生成。 |
| [^22] | [Generating Visual Spatial Description via Holistic 3D Scene Understanding.](http://arxiv.org/abs/2305.11768) | 本文研究将3D场景特征纳入VSD方法，构建目标对象为中心的3D空间场景图(Go3D-S2G)，提出多样化的文本生成方法，可以显著提高性能。 |
| [^23] | [ReSeTOX: Re-learning attention weights for toxicity mitigation in machine translation.](http://arxiv.org/abs/2305.11761) | ReSeTOX是一种新方法，通过重新学习关注权重，能在不重新训练的情况下，有效减少机器翻译中有毒内容的产生，实验结果表明其在164种语言上成功将有毒内容压缩57%。 |
| [^24] | [Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning.](http://arxiv.org/abs/2305.11759) | 该论文提出在大型语言模型中通过Prompt-Tuning策略来控制从中提取记忆数据的方法，提供了攻击和防御两种训练策略。在公共基准测试中展示了其在GPT-Neo模型中的有效性，攻击策略相对于基线产生了9.3%的提取率增加，而防御策略可以调整以实现不同的隐私-效用权衡，可以实现最多97.7%的提取率减少，但困惑度增加了16.9%。 |
| [^25] | [HELMA: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models.](http://arxiv.org/abs/2305.11747) | 本文介绍了一个大型语言模型幻觉评估基准（HELMA），其为标准化和可靠的估算模型幻觉问题提供了一种方法，并使用ChatGPT进行了实证研究以表明其存在幻觉的风险并为鉴别和减轻模型幻觉问题提供了一种方法。 |
| [^26] | [HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation.](http://arxiv.org/abs/2305.11746) | 本文提供了一个涵盖18个翻译方向，包括多种资源水平和脚本的机器翻译中“幻觉”和遗漏现象的手动注释数据集。同时，通过评估不同语言对的表现，为该领域研究提供可靠的基线。 |
| [^27] | [Inference-time Re-ranker Relevance Feedback for Neural Information Retrieval.](http://arxiv.org/abs/2305.11744) | 本文提出了一种利用重排器提供推理时间反馈来改进检索的方法，可以显著提高低召回率@ K下的检索性能。 |
| [^28] | [CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing.](http://arxiv.org/abs/2305.11738) | 本文提出了一个名为CRITIC的框架，使得大型语言模型可以通过与工具的交互校正自己的错误，从而避免生成出现不一致和问题行为的结果。 |
| [^29] | [S$^3$HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering.](http://arxiv.org/abs/2305.11725) | 本文提出了一种三阶段的文本表格问答框架S3HQA，该框架采用训练精细的检索器来解决标签噪声问题，采用混合选择器来选择最相关的实际知识并采用基于生成的推理器来获取答案。在WikiTableQuestions和ComplexWebQuestions数据集上实现了最先进的性能，并在很大程度上优于以前的方法。 |
| [^30] | [Information Screening whilst Exploiting! Multimodal Relation Extraction with Feature Denoising and Multimodal Topic Modeling.](http://arxiv.org/abs/2305.11719) | 该论文提出了一种新的多模态关系抽取框架，结合了内部信息筛选和外部信息利用的思想。通过视觉和文本场景图表示输入的细粒度语义结构，并利用图形信息瓶颈原理进行结构细化和特征去噪，同时运用主题建模丰富上下文，该系统在基准MRE数据集上表现优异，具有巨大的潜力。 |
| [^31] | [What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability.](http://arxiv.org/abs/2305.11707) | 本文分析了神经文本生成器与人类生产变异性之间的不确定性，通过探测生成器的输出空间来测量其对人类生产变异性的校准程度，并证明用多个样本和多个参考可以更好地了解模型的不确定性表示。 |
| [^32] | [QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set Operations.](http://arxiv.org/abs/2305.11694) | 该研究构建了一个名为QUEST的检索数据集，其中含有3357个自然语言查询，这些查询使用隐式集合操作来满足有选择性的信息需求，这个数据集要求模型匹配查询中提到的条件，并正确执行集合操作。 |
| [^33] | [Surgical-VQLA: Transformer with Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery.](http://arxiv.org/abs/2305.11692) | 本文提出了Surgical-VQLA方法，结合Transformer模型和门控视觉-语言嵌入，解决了手术VQA中对象检测稀缺、异构模态融合策略不足、定位答案缺失等问题，并在测试中实现了最好的表现。 |
| [^34] | [Recycle-and-Distill: Universal Compression Strategy for Transformer-based Speech SSL Models with Attention Map Reusing and Masking Distillation.](http://arxiv.org/abs/2305.11685) | 本研究提出了一种基于Transformer的语音自监督学习模型的通用压缩策略，通过重用注意力映射和蒸馏屏蔽来提高学生模型的语音表示质量，实现了较低的错误率。 |
| [^35] | [Sensing of inspiration events from speech: comparison of deep learning and linguistic methods.](http://arxiv.org/abs/2305.11683) | 本研究比较了使用深度学习和基于语言的方法来感知胸带传感器数据中的吸气事件，结果表明VRB方法优于传统方法。同时该研究还发现朗读和自发语言内容都具有显着的非语法性呼吸，为开发VRB方法提供了新的见解。 |
| [^36] | [Evaluating task understanding through multilingual consistency: A ChatGPT case study.](http://arxiv.org/abs/2305.11662) | 本文提出了一种新的评估大型语言模型理解能力的范例，通过评估模型自身生成的不同意义之间的一致性，探讨了多语言自我一致性作为模型理解的检验方法，同时证明了ChatGPT在多语言一致性方面的优秀性能。 |
| [^37] | [LLM-Pruner: On the Structural Pruning of Large Language Models.](http://arxiv.org/abs/2305.11627) | 本文提出了一种方法，名为LLM-Pruner，采用结构修剪的方式在保留大多数功能的同时，压缩LLM的结构，以减少LLM在部署、推理和训练阶段中的大小和复杂度。 |
| [^38] | [CCT-Code: Cross-Consistency Training for Multilingual Clone Detection and Code Search.](http://arxiv.org/abs/2305.11626) | 本研究提出了多语言克隆检测问题，并从CodeForces数据集开发了一个新的基准数据集XCD。我们使用跨语言一致性训练（CCT）方法训练了语言模型，得到了具有新颖性能的CCT-LM模型，超过了现有的方法。 |
| [^39] | [Searching by Code: a New SearchBySnippet Dataset and SnippeR Retrieval Model for Searching by Code Snippets.](http://arxiv.org/abs/2305.11625) | 本研究针对按代码片段搜索的问题，提出了一个新的基于StackOverflow数据的SearchBySnippet数据集，并开发了一个单编码器模型SnippeR，它在该数据集上具有优异的性能。 |
| [^40] | [Attributable and Scalable Opinion Summarization.](http://arxiv.org/abs/2305.11603) | 本文提出了一个可归因且可扩展的无监督意见摘要方法，可以通过编码评论句子为分层潜空间来确定常见意见，并且可以生成抽象或提取的摘要。该方法在几种基线方法中表现最佳，并且允许生成特定方面的摘要。 |
| [^41] | [Introspective Tips: Large Language Model for In-Context Decision Making.](http://arxiv.org/abs/2305.11598) | 本文研究了内省技巧对大型语言模型在上下文决策制定中的应用，通过内省轨迹生成简洁有价值的提示，不调整LLM参数就能提高代理的性能。 |
| [^42] | [Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation.](http://arxiv.org/abs/2305.11596) | 本文提出了一种缓解后门污染攻击的方法，通过减轻文本特征和分类标签之间的虚假相关性来防御攻击，可以显著降低所有后门攻击的成功率，并在插入式攻击的情况下提供了几乎完美的防御。 |
| [^43] | [Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate.](http://arxiv.org/abs/2305.11595) | 本文提出了通过辩论探究大型语言模型之间的内部一致性问题，实验证明通过严格的辩论框架可以提高模型性能和常识知识的结构化学习。 |
| [^44] | [IKDSumm: Incorporating Key-phrases into BERT for extractive Disaster Tweet Summarization.](http://arxiv.org/abs/2305.11592) | IKDSumm是一个特定于灾难事件的推文摘要框架，利用领域特定知识将关键词融合到BERT中，从而在不需要大量标记信息的情况下提高了摘要质量。 |
| [^45] | [Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment.](http://arxiv.org/abs/2305.11579) | 本文提出了SPECTRA语音文本对话预训练模型，应用了新的时间位置预测任务来捕捉语音文本对齐，同时将回答选择任务推广到服务于口语对话理解，用于丰富话语表示。 |
| [^46] | [Language-universal phonetic encoder for low-resource speech recognition.](http://arxiv.org/abs/2305.11576) | 本文利用以国际音标为基础的语言通用音素模型，为低资源语音识别提供了有效的改进方法，表现优于基线单语言模型和大多数最先进的工作。 |
| [^47] | [Language-Universal Phonetic Representation in Multilingual Speech Pretraining for Low-Resource Speech Recognition.](http://arxiv.org/abs/2305.11569) | 本文提出一种利用国际音标多语种模型为低资源语音识别任务创造帧级伪标签的方法，并以此指导隐藏单元BERT（HuBERT）的语音预训练。该方法在多语言语音（MLS）语料库中实验表明，相对于标准HuBERT，在所有目标语言上性能提高，且能节省大量受监督训练时间。 |
| [^48] | [Decouple knowledge from paramters for plug-and-play language modeling.](http://arxiv.org/abs/2305.11564) | 本文介绍了一种新的插件式预训练模型，其与模型参数中的知识存储分离，采用可编辑和可扩展的键值存储器，通过DPM中的知识检索以可解释的方式利用知识。 |
| [^49] | [Blank-regularized CTC for Frame Skipping in Neural Transducer.](http://arxiv.org/abs/2305.11558) | 本文提出两种新的正则化方法，通过限制CTC中的非空白符号的自环，明确地鼓励更多的空白符号，并成功将神经转录器的推理加速4倍，而不降低性能。 |
| [^50] | [ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings.](http://arxiv.org/abs/2305.11554) | 本论文提出了一种名为ToolkenGPT的方法，将大型语言模型（LLMs）与外部工具相结合，引入了toolken的概念，利用tool embeddings实现无缝交互，同时在各种下游任务上展示出了良好的效果。 |
| [^51] | [Unsupervised Scientific Abstract Segmentation with Normalized Mutual Information.](http://arxiv.org/abs/2305.11553) | 本论文提出了一种基于标准化互信息的无监督科技论文摘要分割方法，其中GreedyCAS在非结构化摘要和结构化摘要中均表现出色。 |
| [^52] | [Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens.](http://arxiv.org/abs/2305.11550) | 该论文引入了表征转移潜力（RTP）来衡量多语言神经机器翻译中的知识转移，发现多路并行重叠是关键特征，提出了一种新的训练方案，鼓励表征在语言之间更具不变性，并在多个数据和模型设置中提高了低资源和中资源语言的翻译质量。 |
| [^53] | [Constructing Word-Context-Coupled Space Aligned with Associative Knowledge Relations for Interpretable Language Modeling.](http://arxiv.org/abs/2305.11543) | 本文提出了一种可解释的语言建模方法，通过构建词-上下文耦合空间，并引入联想知识网络和上下文相对距离作为语义特征，实现了语言建模可解释性的提高。 |
| [^54] | [Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering.](http://arxiv.org/abs/2305.11541) | 本文提供了一个行业云特定QA数据集 MSQA，该数据集可用于评估旨在提高大规模语言模型特定领域能力的方法。本文还提出了一种新的模型交互范式，可以使大规模语言模型在其不擅长的特定任务上取得更好的性能。 |
| [^55] | [Efficient Cross-Lingual Transfer for Chinese Stable Diffusion with Images as Pivots.](http://arxiv.org/abs/2305.11540) | 本研究提出了一种经过优化的跨语言转换方法IAP，该方法使用图像作为枢纽，在中英文之间建立语义连接，将英文稳定扩散模型转化为中文。实验证明，该方法比多种强大的中文模型在生成高质量的图片方面表现更优秀。 |
| [^56] | [PORTRAIT: a hybrid aPproach tO cReate extractive ground-TRuth summAry for dIsaster evenT.](http://arxiv.org/abs/2305.11536) | PORTRAIT提出了一种混合方法来创建灾难事件的提取式基准摘要，既使用智能算法，又利用人工智能，可以显著降低标注者的人力成本并实现更可靠的基准摘要生成过程。 |
| [^57] | [A Sequence-to-Sequence Approach for Arabic Pronoun Resolution.](http://arxiv.org/abs/2305.11529) | 本文提出了一种序列到序列学习方法，用于解决阿拉伯语代词消解问题。该模型在AnATAr数据集上优于传统的机器学习模型和手工特征模型。研究者还探讨了一些对模型的修改，这些修改显著提高了模型的性能。 |
| [^58] | [InstructIE: A Chinese Instruction-based Information Extraction Dataset.](http://arxiv.org/abs/2305.11527) | 介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。 |
| [^59] | [DiffuSIA: A Spiral Interaction Architecture for Encoder-Decoder Text Diffusion.](http://arxiv.org/abs/2305.11517) | 本文提出一种名为DiffuSIA的螺旋交互架构，用于编码器-解码器文本扩散。在这个架构中，条件信息和目标信息会交互捕获，以提高条件文本生成的效果。 |
| [^60] | [Plug-and-Play Medical Dialogue System.](http://arxiv.org/abs/2305.11508) | 该论文提出了一种即插即用的医疗对话系统，使用大型语言模型实现医疗问答及诊断策略，避免了传统昂贵的LLMs微调。 |
| [^61] | [A Topic-aware Summarization Framework with Different Modal Side Information.](http://arxiv.org/abs/2305.11503) | 本文提出了一种具有灵活性的通用摘要框架，可以整合各种模态的侧面信息，以实现更好的文章摘要效果。 |
| [^62] | [From Alignment to Entailment: A Unified Textual Entailment Framework for Entity Alignment.](http://arxiv.org/abs/2305.11501) | 该论文提出了一个基于文本蕴涵的实体对齐框架，能够将实体的三元组转化为统一的文本序列，通过预训练语言模型计算实体之间的蕴涵概率进行实体对齐，能够更好地捕捉实体之间的相关信息，并且给出了文本解释说明。 |
| [^63] | [RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought.](http://arxiv.org/abs/2305.11499) | RCOT 提出了一个新的方法来检测和纠正 LLM 生成解决方案中的事实不一致性，以提高 LLM 推理能力。 |
| [^64] | [Recouple Event Field via Probabilistic Bias for Event Extraction.](http://arxiv.org/abs/2305.11498) | 提出了一种基于概率偏置的重新耦合事件场模型（ProCE），用于增强事件提取框架，以澄清来自模糊纠缠的事件字段，并重新耦合相应的澄清分布以捕获更多潜在信息字段。实验表明该方法有效且具有泛化性。 |
| [^65] | [TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding.](http://arxiv.org/abs/2305.11497) | 提示调整技术已经在视觉定位领域卓有成效，但现有的方法大多数可解释性不好。本文提出了一种新的提示构建方法，名为TreePrompt，通过将句子分解成树状结构进行逐步提示构建，提高了提示的可解释性。 |
| [^66] | [LLM Itself Can Read and Generate CXR Images.](http://arxiv.org/abs/2305.11490) | 该论文提出了一种新方法，可以在不需要进行结构更改、额外训练、或训练专门网络的情况下，通过微调预先训练的LLM来读取和生成像文本一样的图像，并应用于胸部X线（CXR）图像的生成任务中。 |
| [^67] | [Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona.](http://arxiv.org/abs/2305.11482) | 本文基于对比潜在变量模型（CLV）结合稀疏和密集人格描述以及对话历史记录来实现更丰富和准确的个性化对话生成。实验结果表明，该模型在个性化方面具有优越性。 |
| [^68] | [CCGen: Explainable Complementary Concept Generation in E-Commerce.](http://arxiv.org/abs/2305.11480) | CCGen是一个电子商务中可解释的互补概念生成算法，通过训练语言模型生成高质量的互补概念排名列表，并生成解释以证明预测的正确性。 |
| [^69] | [Graphologue: Exploring Large Language Model Responses with Interactive Diagrams.](http://arxiv.org/abs/2305.11473) | Graphologue是一个交互式系统，将大型语言模型的基于文本的响应转换为图形化图表以增强其可用性和可解释性，用户可以通过选择和突出显示特定节点和链接来与这些图表进行交互。 |
| [^70] | [Extending Memory for Language Modelling.](http://arxiv.org/abs/2305.11462) | 本论文介绍了一种名为“长期记忆网络”的方法，可用于从无限长序列中学习，以扩展归纳语言建模的记忆容量，并在三个数据集上的测试中表现优异。该方法还可用于文本生成。 |
| [^71] | [Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions.](http://arxiv.org/abs/2305.11460) | 本文提出了一种名为自我协议(Self-Agreement)的新框架，用于微调LLMs以自主地找到共识，并使用LLM自动生成的数据。 |
| [^72] | [Shattering the Agent-Environment Interface for Fine-Tuning Inclusive Language Models.](http://arxiv.org/abs/2305.11455) | 该论文提出了一种新颖的思路，将预训练的语言模型本身同时作为策略、奖励函数和转移函数，可以直接进行奖励学习和语言模型微调，可以带来巨大的统计收益。 |
| [^73] | [Analyzing and Reducing the Performance Gap in Cross-Lingual Transfer with Fine-tuning Slow and Fast.](http://arxiv.org/abs/2305.11449) | 本文分析了微调过程，提出了缓慢和快速微调的方法来解决跨语言迁移中的性能差距问题，通过减少遗忘来弥补性能差距，实验结果表明该方法的性能比基线方法好。 |
| [^74] | [Arukikata Travelogue Dataset.](http://arxiv.org/abs/2305.11444) | Arukikata旅游游记数据集是一个包含超过3100万个日文单词的数据集，包括4672个日本国内游记和9607个海外游记，为研究人员提供了可重复和透明的研究数据。 |
| [^75] | [Zero-Shot Text Classification via Self-Supervised Tuning.](http://arxiv.org/abs/2305.11442) | 本文提出了一种基于自监督调整的零样本文本分类算法，通过使用无标签数据来调整语言模型，通过学习预测段落中的第一句话，实现了对未见过任务的零样本推断，模型不需要注释数据进行元调整，对模板的选择不敏感，并在实验中取得不错的结果。 |
| [^76] | [Phonetic and Prosody-aware Self-supervised Learning Approach for Non-native Fluency Scoring.](http://arxiv.org/abs/2305.11438) | 本论文提出了一个基于音韵和韵律感知的自监督学习方法，用于非母语流畅度评分。通过在大量未标记的语音和文本提示上预训练模型，然后使用人工注释的评分数据进行微调，该方法在Pearson相关系数（PCC）方面优于基线系统。 |
| [^77] | [Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode.](http://arxiv.org/abs/2305.11435) | 本文提出采用基于视觉引导的自监督语音模型进行音节发现和跨语言泛化。使用最小割算法和2阶段聚类方法自动预测语音中的音节边界。在英语上表现优于最先进的音节分割方法，并以零样本的方式在爱沙尼亚语上泛化。在其他语言上也取得了成功。 |
| [^78] | [TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks.](http://arxiv.org/abs/2305.11430) | 本文提出了一个通用分类法，可以用来设计具有特定属性的提示来执行各种复杂任务，从而解决了LLM在执行复杂任务方面的性能变异巨大的问题。 |
| [^79] | [Post Hoc Explanations of Language Models Can Improve Language Models.](http://arxiv.org/abs/2305.11426) | 本文提出了一种新的框架AMPLIFY，利用后验解释自动化生成原因，并在多个数据集和任务上显著提高现有语言模型的性能。 |
| [^80] | [DUB: Discrete Unit Back-translation for Speech Translation.](http://arxiv.org/abs/2305.11411) | 离散单元反向翻译方法成功将有用的MT技术应用在直接ST上，平均提升了5.5 BLEU，可以缓解语音和文本之间的模态问题。 |
| [^81] | [AlignAtt: Using Attention-based Audio-Translation Alignments as a Guide for Simultaneous Speech Translation.](http://arxiv.org/abs/2305.11408) | AlignAtt是一种新型的SimulST策略，使用基于注意力的音频翻译对齐来指导模型，在BLEU和延迟方面均优于之前的策略。 |
| [^82] | [Comfort Foods and Community Connectedness: Investigating Diet Change during COVID-19 Using YouTube Videos on Twitter.](http://arxiv.org/abs/2305.11398) | 本研究利用在Twitter上的YouTube视频调查了COVID-19期间的饮食变化，发现收入较低地区的能量、脂肪和饱和脂肪摄入量下降，高糖、高蛋白和高钠的食品成为突出的话题。 |
| [^83] | [Fast-StrucTexT: An Efficient Hourglass Transformer with Modality-guided Dynamic Token Merge for Document Understanding.](http://arxiv.org/abs/2305.11392) | Fast-StrucTexT是一种高效的多模态文档理解框架，采用沙漏变压器结构和 Symmetry Cross Attention 等方法实现了多粒度表示和模态融合。 |
| [^84] | [AutoTrial: Prompting Language Models for Clinical Trial Design.](http://arxiv.org/abs/2305.11366) | AutoTrial是一种使用语言模型自动生成临床试验纳入/排除标准的方法，它可以可控生成、可扩展学习、提供推理链，实验表明，它能够生成流畅准确的标准文本，与先进方法相媲美，但资源占用更少。 |
| [^85] | [Visualizing Linguistic Diversity of Text Datasets Synthesized by Large Language Models.](http://arxiv.org/abs/2305.11364) | 该论文介绍了一种新的可视化工具，用于分析大型语言模型生成的数据集的句法多样性，可以通过分层可视化来帮助用户快速浏览概述和检查各个示例。 |
| [^86] | [MD3: The Multi-Dialect Dataset of Dialogues.](http://arxiv.org/abs/2305.11355) | MD3是一个新的多方言对话数据集，包含来自印度、尼日利亚和美国的英语方言，通过提示参与者执行信息共享任务实现了开放对话语音和面向任务的对话之间的平衡。研究发现了不同方言在句法和语篇标记的使用上的显著差异。 |
| [^87] | [Data Redaction from Conditional Generative Models.](http://arxiv.org/abs/2305.11351) | 本文研究如何对已训练好的条件生成模型进行后期编辑，以便编辑掉某些条件分支，这些条件分支很可能会生成不良内容。通过精简模型中的条件网络实现，提出的解决方案有效、高效、具有可控性和普适性，在文本到图像和文本到语音生成模型中取得了良好效果。 |
| [^88] | [Unsupervised Domain-agnostic Fake News Detection using Multi-modal Weak Signals.](http://arxiv.org/abs/2305.11349) | 本文提出了一种新的、无需监督、跨领域的虚假新闻检测框架，通过嵌入多模态信息和自监督学习技术实现，同时还提出了一种新的数据集构建技术，有效避免了现有数据集中的潜在偏见。 |
| [^89] | [In the Name of Fairness: Assessing the Bias in Clinical Record De-identification.](http://arxiv.org/abs/2305.11348) | 本文研究了临床记录去识别系统在不同人口群体中的表现差异，揭示了其在名称去识别方面存在显著的偏见。 |
| [^90] | [Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs.](http://arxiv.org/abs/2305.11334) | 本文介绍了两种新颖的方法，Tree-Search和自我上下文QA，可提高大型语言模型在问答任务中的性能。Tree-Search采样技术有助于从提示中提取多样化信息，而自我上下文QA可使模型创建自己的上下文，生成更好的开放式答案。此外，这些方法可提高健壮性和性能。 |
| [^91] | [Towards the Automatic Generation of Conversational Interfaces to Facilitate the Exploration of Tabular Data.](http://arxiv.org/abs/2305.11326) | 本文提出了使用聊天机器人作为自动化创造的会话接口来方便大众探索表格数据的方法。 |
| [^92] | [Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation.](http://arxiv.org/abs/2305.11317) | 本论文通过集成GPT-k来提高T2I生成中的编辑效率，实验证明其更擅长调整（修改）文本中的修饰语，而人类倾向于替换单词和短语。 |
| [^93] | [Improving Toponym Resolution with Better Candidate Generation, Transformer-based Reranking, and Two-Stage Resolution.](http://arxiv.org/abs/2305.11315) | 本文提出了一种名为GeoNorm的地理编码框架。通过生成和重新排序两次解析地名，GeoNorm在解析任务上表现优异。其中改进的候选生成和基于Transformer的重新排序是创新之处。 |
| [^94] | [Towards Collaborative Plan Acquisition through Theory of Mind Modeling in Situated Dialogue.](http://arxiv.org/abs/2305.11271) | 本文提出了一种协作计划获取方法，通过丰富的感知和对话历史，让代理人预测他们自己和合作伙伴缺失的任务知识，实现联合任务的完整计划获取。 |
| [^95] | [CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models.](http://arxiv.org/abs/2305.11262) | 本文介绍了一个新的中文数据集，CHBias，用于评估和缓解中文对话语言模型的偏见。实验结果表明，这些中文预训练模型可能会产生含有偏见的文本。 |
| [^96] | [Reasoning Implicit Sentiment with Chain-of-Thought Prompting.](http://arxiv.org/abs/2305.11255) | 本研究提出了一种基于思维链索引的隐式情感推断框架（THOR），通过三次跳推理模仿类人推理过程，支持常识和多跳推理以推断意见的潜在意图，并逐步诱导隐式方面、意见和最终情感极性，实现了在监督和零样本设置上大幅提高技术水平。 |
| [^97] | [Computational thematics: Comparing algorithms for clustering the genres of literary fiction.](http://arxiv.org/abs/2305.11251) | 本文比较了多种算法用于无监督学习文本之间的主题相似性，发现在采用“词频-逆文档频率”文本特征提取方法和“余弦相似度”距离度量方法的组合下，文本聚类的效果最好。 |
| [^98] | [A Parameter-Efficient Learning Approach to Arabic Dialect Identification with Pre-Trained General-Purpose Speech Model.](http://arxiv.org/abs/2305.11244) | 本文介绍了一种利用预训练通用语音模型进行阿拉伯方言识别的参数高效学习方法，通过残差适配器和模型重编程，设计了一个基于记号的标签映射，并在ADI-17数据集上实现了最高精度，同时使用PEL方法进一步减少了训练成本。 |
| [^99] | [Comparing Machines and Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA Responses.](http://arxiv.org/abs/2305.11243) | 使用儿童发展实验来评估人工智能的计算能力，同时比较LLMs和儿童可以帮助我们开发更具人类特征和可解释性的机器学习模型。 |
| [^100] | [Comparing Biases and the Impact of Multilingual Training across Multiple Languages.](http://arxiv.org/abs/2305.11242) | 本研究分析意大利语、中文、英语、希伯来语和西班牙语的偏见相似性和差异，同时调查了多语言与单语言训练数据的影响。 |
| [^101] | [Recent Trends in Unsupervised Summarization.](http://arxiv.org/abs/2305.11231) | 本文综述了无监督摘要的最新技术和模型，包括抽取式、生成式和混合模型，并提出了一个基于方法的分类法。本文还介绍了一些数据集和评估方法。 |
| [^102] | [LIMA: Less Is More for Alignment.](http://arxiv.org/abs/2305.11206) | 该论文介绍了一种使用无声调学习预训练语言模型和标准监督损失微调的方法（不使用强化学习或人类模型），并展示了在复杂任务上也有出色的表现。 |
| [^103] | [Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt.](http://arxiv.org/abs/2305.11186) | 本文提出了使用可转移提示来优化压缩的LLMs的准确性和效率的平衡问题。该方法通过选择精度更高的提示显著提高了压缩的LLM在特定查询方面的生成质量，并实现了4倍推理时间加速。 |
| [^104] | [Taxonomy Completion with Probabilistic Scorer via Box Embedding.](http://arxiv.org/abs/2305.11004) | 本文提出了一种新方法TaxBox，该方法将分类法概念映射到框嵌入中，并使用两个概率评分器来进行概念附加和插入，避免使用伪叶。实验表明，在二个基准数据集上，TaxBox在准确性和训练效率方面显著优于现有的方法。 |
| [^105] | [SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities.](http://arxiv.org/abs/2305.11000) | SpeechGPT是一个具有本质跨模态会话能力的大型语言模型，能够感知和生成多模态内容，可按照多模态人类指令的能力，并突显了使用一个模型处理多个模态的潜力。 |
| [^106] | [Making More of Little Data: Improving Low-Resource Automatic Speech Recognition Using Data Augmentation.](http://arxiv.org/abs/2305.10951) | 本研究探究了利用数据增强技术，特别是自训练方法，提高低资源语音识别的性能，取得了成功，证明这是一种可行的方法。 |
| [^107] | [Large Language Models can be Guided to Evade AI-Generated Text Detection.](http://arxiv.org/abs/2305.10847) | 本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。 |
| [^108] | [Are Large Language Models Fit For Guided Reading?.](http://arxiv.org/abs/2305.10645) | 本文评估大型语言模型在指导阅读中的应用能力，发现它们能够生成高质量的有意义问题，具有多样性且涵盖输入文本中大多数主题，同时能够有效地总结回答和推荐重新阅读的部分。 |
| [^109] | [UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective.](http://arxiv.org/abs/2305.10306) | UniEX是一种能适用于各种模式格式的信息抽取框架，并能同时解决命名实体识别、关系抽取、事件提取和情感分析等任务，在性能和推理速度上优于其他通用信息抽取模型。 |
| [^110] | [CPL-NoViD: Context-Aware Prompt-based Learning for Norm Violation Detection in Online Communities.](http://arxiv.org/abs/2305.09846) | 本文提出了一种新的方法（CPL-NoViD），通过自然语言提示将上下文融入到模型中，用于在线社区中的违规检测。该方法能够适应不同社区中的各种规则和解释的差异，在跨规则类型和跨社区的违规行为检测中表现出色，并在少样本学习场景中表现出一定的适应性。 |
| [^111] | [AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation.](http://arxiv.org/abs/2305.09515) | 本文提出了一种自回归扩散模型（AR-Diffusion）用于文本生成，通过动态数量的降噪步骤，确保左侧标记的生成影响右侧标记的生成。 |
| [^112] | [Easy-to-Hard Learning for Information Extraction.](http://arxiv.org/abs/2305.09193) | 本文提出了一种易学难学的信息抽取学习框架，分为入门、困难和主阶段，模仿人类学习过程，通过分阶段学习提高模型泛化能力。 |
| [^113] | [Parameter-Efficient Fine-Tuning with Layer Pruning on Free-Text Sequence-to-Sequence modeling.](http://arxiv.org/abs/2305.08285) | 本文提出了一个将LoRA和结构化层剪枝方法结合的框架，在保持超过92%生成质量的同时，通过调整仅0.6%的参数并剪枝超过30%的Transformer层，成功减少了50%的GPU内存使用并提升了100%的训练速度。 |
| [^114] | [FactKG: Fact Verification via Reasoning on Knowledge Graphs.](http://arxiv.org/abs/2305.06590) | FactKG是一个新的数据集，通过知识图谱推理进行事实验证，包含108k个自然语言声明和五种推理类型，可帮助社区更好地使用知识图谱进行事实验证。 |
| [^115] | [PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences.](http://arxiv.org/abs/2305.02547) | 本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。 |
| [^116] | [Explicit Planning Helps Language Models in Logical Reasoning.](http://arxiv.org/abs/2303.15714) | 本文提出了一个新的系统，使用语言模型进行多步逻辑推理，采用了显式规划来帮助做出更明智的决策，比其他竞争系统表现更好，显式规划在系统性能中起着关键作用。 |
| [^117] | [UniFLG: Unified Facial Landmark Generator from Text or Speech.](http://arxiv.org/abs/2302.14337) | 该论文提出了一个基于文本或语音驱动的UniFLG系统，将文本与语音结合起来生成面部特征点。该系统表现出比现有基于文本驱动方法更高的语音和面部表现自然度，可以从没有面部视频数据或语音数据的讲话者中生成面部特征点。 |
| [^118] | [Epicurus at SemEval-2023 Task 4: Improving Prediction of Human Values behind Arguments by Leveraging Their Definitions.](http://arxiv.org/abs/2302.13925) | 本篇论文介绍了参加SemEval-2023任务4的实验，旨在通过利用定义来提高对论据背后的人类价值观的预测，实验证明此方法可以获得更好的预测性能。 |
| [^119] | [Big Little Transformer Decoder.](http://arxiv.org/abs/2302.07863) | 提出了一种名为BiLD的框架，它由大小不同的两个模型协作生成文本。其中小型模型自回归地生成文本，而大型模型则在必要时以非自回归的方式对小型模型的预测进行微调，从而显著减少了推理延迟。 |
| [^120] | [Migration Reframed? A multilingual analysis on the stance shift in Europe during the Ukrainian crisis.](http://arxiv.org/abs/2302.02813) | 乌克兰危机引起了欧洲对移民议题态度的变化，特别是对来自乌克兰的难民。研究者运用多语言分析技术对新闻和社交媒体上的相关报道进行研究，发现了一种对移民议题讨论的重构。 |
| [^121] | [One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER.](http://arxiv.org/abs/2301.10410) | 本论文提出了基于协作域前缀调整的跨领域实体识别，使用文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务，避免了先前的为每个领域结束一个全新的NER模型的问题。 |
| [^122] | [Execution-Based Evaluation for Open-Domain Code Generation.](http://arxiv.org/abs/2212.10481) | ODEX是第一个基于开放域执行的自然语言到Python代码生成数据集。CODEX和CODEGEN分别表现不同的行为。ODEx将有助于进一步研究代码生成的开放域问题。 |
| [^123] | [Empowering Sentence Encoders with Prompting and Label Retrieval for Zero-shot Text Classification.](http://arxiv.org/abs/2212.10391) | 本文提出了一种 RaLP 框架，其使用提示和标签检索增强句子编码器进行零样本文本分类。该框架可以处理描述不当的标签，同时将提示与输入文本嵌入相似性相对较高的标签关联，取得了与较大基线竞争性能或更强的性能。 |
| [^124] | [On the Blind Spots of Model-Based Evaluation Metrics for Text Generation.](http://arxiv.org/abs/2212.10020) | 本文研究了针对文本生成评价指标的鲁棒性分析方法，使用合成数据进行压力测试，发现现有评价指标存在一些盲点和偏见，例如BERTScore对摘要中的截断误差无法很好地处理，MAUVE对于生成的开头或中间的误差不敏感，本文提出了实用的解决方案以实现更可靠的文本生成评价。 |
| [^125] | [Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy AI.](http://arxiv.org/abs/2212.09667) | 研究提出了一种新颖的FARM框架，通过利用外部知识生成能够被信任的原理，解决了不安全文本检测的问题，并能够帮助利益相关者和政策制定者保障消费者的安全。 |
| [^126] | [Causes and Cures for Interference in Multilingual Translation.](http://arxiv.org/abs/2212.07530) | 研究探究了多语言机器翻译中干扰的主要因素，通过系统化试验发现使用不到10亿参数的标准Transformer配置可以在很大程度上缓解干扰并促进协同，同时发现调整采样温度以控制数据中每个语言对所占比例的方法是平衡语言对之间关系的关键。 |
| [^127] | [ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages.](http://arxiv.org/abs/2212.06742) | ERNIE-Code是一个适用于116种自然语言和6种编程语言的统一预训练语言模型，采用了跨度损坏语言建模和基于桥接的翻译语言建模两种跨语言预训练方法，并在广泛的代码智能终端任务中优于以前的多语言LLMs。 |
| [^128] | [On Text-based Personality Computing: Challenges and Future Directions.](http://arxiv.org/abs/2212.06711) | 本文提出了15个基于文本的人格计算方面的挑战，包括人格分类法，测量质量，数据集，性能评估，建模选择以及道德和公平性，旨在激发更多的有效和可靠的TPC研究。 |
| [^129] | [SODA: A Natural Language Processing Package to Extract Social Determinants of Health for Cancer Studies.](http://arxiv.org/abs/2212.03000) | 本文介绍了一个开源的自然语言处理包SODA，可用于提取癌症患者的社会健康决定因素。该包在泛化能力方面表现良好，可以用于新的疾病领域。研究结果表明，该包在癌症人群中提取SDoH的提取率较高。 |
| [^130] | [Analysis of Utterance Embeddings and Clustering Methods Related to Intent Induction for Task-Oriented Dialogue.](http://arxiv.org/abs/2212.02021) | 本文旨在研究任务导向对话中的意图识别问题，并提出两个关键因素：聚类算法和用户话语嵌入空间。实验证明，利用预训练的MiniLM与层次聚类相结合可以显著提高意图归纳任务的效果。 |
| [^131] | [Fast Inference from Transformers via Speculative Decoding.](http://arxiv.org/abs/2211.17192) | 本文介绍了一种基于投机解码的算法，可以在不更改输出的情况下更快地从大型自回归模型（如Transformer）中采样，加速了现有的模型，而无需重新训练或进行架构更改。 |
| [^132] | [VATLM: Visual-Audio-Text Pre-Training with Unified Masked Prediction for Speech Representation Learning.](http://arxiv.org/abs/2211.11275) | 本文提出了一个名为VATLM的统一跨模式表示学习框架，利用视听文本资料的预处理与一种统一的遮蔽预测任务进行优化，以达到优秀的联合多模态表示效果。 |
| [^133] | [NLPeer: A Unified Resource for the Computational Study of Peer Review.](http://arxiv.org/abs/2211.06651) | NLPeer是一个具有跨领域挖掘能力的同行评审计算研究的统一资源，包括超过5k篇论文和11k个审稿报告的数据集，并建立了统一的数据表示。该资源提供了三个审核协助任务的实现和分析，并为更全面和系统的NLP同行评审研究铺平了道路。 |
| [^134] | [Application of Knowledge Distillation to Multi-task Speech Representation Learning.](http://arxiv.org/abs/2210.16611) | 本文研究将知识蒸馏应用于语音表示学习模型，联合微调多个下游任务，将模型大小减少75%同时精度和等误差率损失很小，并表明微调语音表示学习模型相较于冻结模型可以显著提高性能。 |
| [^135] | [Environmental Claim Detection.](http://arxiv.org/abs/2209.00507) | 为了实现绿色经济，需要可靠、可比较和可验证的环境声明。该论文介绍了环境声明检测任务，并发布了一个专家标注的数据集和训练模型。通过这些模型，我们可以检测环境声明在季度电话会议中的使用情况并发现该使用情况自2015年以来有稳步增长的趋势。 |
| [^136] | [Efficient NLP Model Finetuning via Multistage Data Filtering.](http://arxiv.org/abs/2207.14386) | 本文介绍了一种多阶段数据过滤的方法，以提高NLP模型微调效率。在各种基准测试中，该方法有效减少所需训练样例数和训练时间，同时只有轻微精度降低，即使只有一个时期的训练，也非常有效。 |
| [^137] | [Is GPT-3 all you need for Visual Question Answering in Cultural Heritage?.](http://arxiv.org/abs/2207.12101) | 本文提出了一种使用GPT-3的视觉问答方法，可以在运行时生成一个描述表以回答关于艺术品的视觉和上下文问题，避免了注释过程。 |
| [^138] | [Secondary Use of Clinical Problem List Entries for Neural Network-Based Disease Code Assignment.](http://arxiv.org/abs/2112.13756) | 本研究基于神经网络探索了使用国际疾病分类对临床问题列表条目进行自动编码，揭示了不一致的手动编码是一个主要的限制因素。 |

# 详细

[^1]: 基于自监督语音模型的北萨米语言方言识别

    North S\'{a}mi Dialect Identification with Self-supervised Speech Models. (arXiv:2305.11864v1 [eess.AS])

    [http://arxiv.org/abs/2305.11864](http://arxiv.org/abs/2305.11864)

    该论文使用自监督语音模型 successfully 区分了北萨米语言的四种方言变体，并发现这些方言受到了国家语言的影响。

    

    北萨米语言包括四种主要的方言变体，它们在语音、形态和词汇上有所不同。北萨米语言使用者的特殊地缘政治位置意味着在许多情况下，他们既是萨米语使用者，也是优势国家语言（挪威语、瑞典语或芬兰语）的双语者。本文研究了一组广泛的声学特征，包括MFCC和韵律特征，以及最先进的自监督表示方法，即XLS-R、WavLM和HuBERT，用于自动检测四种北萨米方言变体。此外，我们还研究了优势国家语言如何反映在方言变体中。我们的研究结果表明，北萨米方言受到国家语言的影响，四种北萨米方言变体是可以分离的，并且使用XLS-R模型可获得很高的分类准确性。

    The North S\'{a}mi (NS) language encapsulates four primary dialectal variants that are related but that also have differences in their phonology, morphology, and vocabulary. The unique geopolitical location of NS speakers means that in many cases they are bilingual in S\'{a}mi as well as in the dominant state language: Norwegian, Swedish, or Finnish. This enables us to study the NS variants both with respect to the spoken state language and their acoustic characteristics. In this paper, we investigate an extensive set of acoustic features, including MFCCs and prosodic features, as well as state-of-the-art self-supervised representations, namely, XLS-R, WavLM, and HuBERT, for the automatic detection of the four NS variants. In addition, we examine how the majority state language is reflected in the dialects. Our results show that NS dialects are influenced by the state language and that the four dialects are separable, reaching high classification accuracy, especially with the XLS-R mod
    
[^2]: 基于fMRI的语言编码模型的规模定律研究

    Scaling laws for language encoding models in fMRI. (arXiv:2305.11863v1 [cs.CL])

    [http://arxiv.org/abs/2305.11863](http://arxiv.org/abs/2305.11863)

    本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。

    

    基于变压器的单向语言模型的表示已被证明能够有效地预测大脑对自然语言的反应。然而，大多数比较语言模型与大脑的研究都使用了类似GPT-2大小的语言模型。本研究测试了是否更大的开源模型（如OPT和LLaMA系列）更适用于预测使用fMRI记录的大脑反应。结果显示，在从125M到30B参数模型进行规模扩展时，大脑预测性能与模型大小呈对数线性关系，跨3个受试者的保留测试集相关性表现提高了约15％。当扩展fMRI训练集的大小时，我们也观察到了类似的对数线性行为。我们还对使用HuBERT，WavLM和Whisper的声学编码模型进行了规模定律研究，发现模型大小的增加带来了类似的改进。我们还使用噪音天花板分析了这些大规模且高性能的编码模型。

    Representations from transformer-based unidirectional language models are known to be effective at predicting brain responses to natural language. However, most studies comparing language models to brains have used GPT-2 or similarly sized language models. Here we tested whether larger open-source models such as those from the OPT and LLaMA families are better at predicting brain responses recorded using fMRI. Mirroring scaling results from other contexts, we found that brain prediction performance scales log-linearly with model size from 125M to 30B parameter models, with ~15% increased encoding performance as measured by correlation with a held-out test set across 3 subjects. Similar log-linear behavior was observed when scaling the size of the fMRI training set. We also characterized scaling for acoustic encoding models that use HuBERT, WavLM, and Whisper, and we found comparable improvements with model size. A noise ceiling analysis of these large, high-performance encoding models 
    
[^3]: 利用大语言模型预测编辑操作来减少序列长度

    Reducing Sequence Length by Predicting Edit Operations with Large Language Models. (arXiv:2305.11862v1 [cs.CL])

    [http://arxiv.org/abs/2305.11862](http://arxiv.org/abs/2305.11862)

    本文提出利用大型语言模型预测源文本中的编辑操作来减少序列长度的方法，从而减少计算成本，实验表明其达到了可比较的性能。

    

    大型语言模型在各种任务中展示出了卓越的性能，并获得了显着的关注。 LLMs也被用于本地序列转换任务，包括语法错误修正（GEC）和形式风格转换，在这些任务中，源文本中的大部分记号保持不变。 然而，生成所有目标记号是低效率的，因为目标记号的预测错误可能导致在预测后续记号时出现灾难，并且随着目标序列长度的增加，计算成本呈二次增长。 本文提出了一种预测本地序列转换任务的源文本的一组编辑操作的方法。 通过表示一个编辑操作的源文本跨度和更改的记号，我们可以减少目标序列的长度，从而减少推断的计算成本。 我们在编辑操作的监督数据上应用指导调优LLMs。 实验表明，所提出的方法达到了可比较的性能。

    Large Language Models (LLMs) have demonstrated remarkable performance in various tasks and gained significant attention. LLMs are also used for local sequence transduction tasks, including grammatical error correction (GEC) and formality style transfer, where most tokens in a source text are kept unchanged. However, it is inefficient to generate all target tokens because a prediction error of a target token may cause a catastrophe in predicting subsequent tokens and because the computational cost grows quadratically with the target sequence length. This paper proposes to predict a set of edit operations for the source text for local sequence transduction tasks. Representing an edit operation with a span of the source text and changed tokens, we can reduce the length of the target sequence and thus the computational cost for inference. We apply instruction tuning for LLMs on the supervision data of edit operations. Experiments show that the proposed method achieves comparable performanc
    
[^4]: 分步采样：用自适应一致性提高大型语言模型的有效推理

    Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs. (arXiv:2305.11860v1 [cs.CL])

    [http://arxiv.org/abs/2305.11860](http://arxiv.org/abs/2305.11860)

    本文提出了一种名为自适应一致性 (Adaptive-Consistency) 的技术，可以动态调整每个问题的样本数量，从而有效减少样本预算，并较小程度地降低了平均准确度

    

    改良大型语言模型 (LLMs) 输出正确性的一个流行方法是使用自一致性——对 LLM 进行多次投票并输出最频繁的解决方案。现有的自一致性技术都是每个问题都会固定采集一定数量的样本，而更好的方法是根据已经采集到的样本之间的一致性非均匀地分配预算。为此，我们提出了一种名为自适应一致性 (Adaptive-Consistency) 的成本有效、与模型无关的技术，它使用轻量级停止准则动态调整每个问题的样本数量。我们在 13 个数据集和两个 LLM 上的实验表明，自适应一致性可以将样本预算降低多达 6 倍，并且平均准确度降低不到 0.1%。

    A popular approach for improving the correctness of output from large language models (LLMs) is Self-Consistency - poll the LLM multiple times and output the most frequent solution. Existing Self-Consistency techniques always draw a constant number of samples per question, where a better approach will be to non-uniformly distribute the available budget based on the amount of agreement in the samples drawn so far. In response, we introduce Adaptive-Consistency, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion. Our experiments over 13 datasets and two LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 6.0 times with an average accuracy drop of less than 0.1%.
    
[^5]: 在自然语言处理领域，复杂主张验证中的取证问题

    Complex Claim Verification with Evidence Retrieved in the Wild. (arXiv:2305.11859v1 [cs.CL])

    [http://arxiv.org/abs/2305.11859](http://arxiv.org/abs/2305.11859)

    本文介绍了一种新的自动事实核查流程，可以通过从网络中检索原始证据来检查实际主张。我们的流程包括五个部分：主张分解，原始文档检索，细粒度证据检索，主张焦点摘要和判断真实性。研究表明，我们的流程可以改善真实性判断，我们提供的证据摘要更易于理解。

    

    取证是自动事实核查的核心部分。 针对获取取证的假设不符合实际应用情况，之前的工作做出了简化的假设，即没有获取证据的权限，访问由人工事实核查员精简的证据，或在对主张确认之后很长时间才能获取证据。在本文中，我们提出了第一个完全自动化的流程，通过从网络中检索原始证据来检查实际主张。我们限制我们的检索器仅搜索在提出主张之前就已可提供的文档，模拟新出现的主张需要检查的真实情况。我们的流程包括五个部分：主张分解，原始文档检索，细粒度证据检索，主张焦点摘要和判断真实性。我们在ClaimDecomp数据集中对复杂政治主张进行实验，结果表明我们的流程产生的聚合证据可以改善真实性判断。人类评估发现，我们的摘要产生的证据要比由现有系统产生的证据更易于理解。

    Evidence retrieval is a core part of automatic fact-checking. Prior work makes simplifying assumptions in retrieval that depart from real-world use cases: either no access to evidence, access to evidence curated by a human fact-checker, or access to evidence available long after the claim has been made. In this work, we present the first fully automated pipeline to check real-world claims by retrieving raw evidence from the web. We restrict our retriever to only search documents available prior to the claim's making, modeling the realistic scenario where an emerging claim needs to be checked. Our pipeline includes five components: claim decomposition, raw document retrieval, fine-grained evidence retrieval, claim-focused summarization, and veracity judgment. We conduct experiments on complex political claims in the ClaimDecomp dataset and show that the aggregated evidence produced by our pipeline improves veracity judgments. Human evaluation finds the evidence summary produced by our s
    
[^6]: 如何引导LLMs进行文本到SQL的学习: 从零样本到单领域到跨领域研究

    How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings. (arXiv:2305.11853v1 [cs.CL])

    [http://arxiv.org/abs/2305.11853](http://arxiv.org/abs/2305.11853)

    本文针对引导LLMs进行文本到SQL的任务中提示文本构建问题展开了综合探究，从而为未来的研究提供了见解。

    

    具有上下文学习的大型语言模型(LLMs)在文本到SQL任务中展现了显著能力。之前的研究通过各种演示-检索策略和中间推理步骤来促使LLMs性能的提升。然而，这些工作在构建文本到SQL输入的提示文本(如数据库和演示示例)时常采用不同的策略。这导致提示文本的构建和其主要贡献的可比性不足。此外，选择有效的提示文本建设已成为未来研究中的持久问题。为了解决这个限制，我们全面调查了不同设置下提示文本结构的影响，并为未来的工作提供了见解。

    Large language models (LLMs) with in-context learning have demonstrated remarkable capability in the text-to-SQL task. Previous research has prompted LLMs with various demonstration-retrieval strategies and intermediate reasoning steps to enhance the performance of LLMs. However, those works often employ varied strategies when constructing the prompt text for text-to-SQL inputs, such as databases and demonstration examples. This leads to a lack of comparability in both the prompt constructions and their primary contributions. Furthermore, selecting an effective prompt construction has emerged as a persistent problem for future research. To address this limitation, we comprehensively investigate the impact of prompt constructions across various settings and provide insights for future work.
    
[^7]: 通过可组合扩散实现任意输入与输出之间的生成

    Any-to-Any Generation via Composable Diffusion. (arXiv:2305.11846v1 [cs.CV])

    [http://arxiv.org/abs/2305.11846](http://arxiv.org/abs/2305.11846)

    CoDi是一种生成模型，通过在输入空间和输出空间中进行模态对齐，实现了可组合生成策略，从而可以生成任意组合的输出模态。 CoDi 非常灵活，能够生成多个模态，如图像、视频、语言和音频，甚至在训练数据中不存在的模态组合。

    

    本文提出了一种新的生成模型，称之为可组合扩散（CoDi）。这个模型能够从任意输入模态和任意组合中生成各种输出模态，如语言、图像、视频或音频。与现有的生成 AI 系统不同，CoDi 可以同时生成多个模态，并且其输入不局限于文本或图像的子集。尽管很多模态的组合缺乏训练数据集，但我们提出了在输入空间和输出空间中进行模态对齐的方法，从而使 CoDi 可以自由地对任何输入组合进行条件生成，并生成任何模态组合，即使这些组合不在训练数据中。CoDi采用了一种新的可组合生成策略，通过在扩散过程中构建共享的多模态空间来实现对齐，从而实现了交织模态的同步生成，例如时间上对齐的视频和音频。高度可定制和灵活，CoDi 实现了强大的联合模态生成。

    We present Composable Diffusion (CoDi), a novel generative model capable of generating any combination of output modalities, such as language, image, video, or audio, from any combination of input modalities. Unlike existing generative AI systems, CoDi can generate multiple modalities in parallel and its input is not limited to a subset of modalities like text or image. Despite the absence of training datasets for many combinations of modalities, we propose to align modalities in both the input and output space. This allows CoDi to freely condition on any input combination and generate any group of modalities, even if they are not present in the training data. CoDi employs a novel composable generation strategy which involves building a shared multimodal space by bridging alignment in the diffusion process, enabling the synchronized generation of intertwined modalities, such as temporally aligned video and audio. Highly customizable and flexible, CoDi achieves strong joint-modality gen
    
[^8]: RxnScribe：反应图解析的序列生成模型

    RxnScribe: A Sequence Generation Model for Reaction Diagram Parsing. (arXiv:2305.11845v1 [cs.CL])

    [http://arxiv.org/abs/2305.11845](http://arxiv.org/abs/2305.11845)

    RxnScribe是一种端到端的机器学习模型，用于解析化学文献中复杂的反应图，并在交叉验证中取得了较高的分数。

    

    反应图解析是从化学文献中提取反应方案的任务。反应图可以极其复杂，因此将其稳健地解析成结构化数据是一个开放性挑战。在本文中，我们提出了RxnScribe，这是一个用于解析不同风格反应图的机器学习模型。我们采用序列生成方法来制定这个结构化预测任务，将传统的管道流程压缩为端到端的模型。我们在一个包含1,378个图的数据集上训练RxnScribe，并进行交叉验证评估，实现了80.0%的软匹配F1分数，与以前的模型相比有显著的改进。我们的代码和数据可以在https://github.com/thomas0809/RxnScribe 上公开获取。

    Reaction diagram parsing is the task of extracting reaction schemes from a diagram in the chemistry literature. The reaction diagrams can be arbitrarily complex, thus robustly parsing them into structured data is an open challenge. In this paper, we present RxnScribe, a machine learning model for parsing reaction diagrams of varying styles. We formulate this structured prediction task with a sequence generation approach, which condenses the traditional pipeline into an end-to-end model. We train RxnScribe on a dataset of 1,378 diagrams and evaluate it with cross validation, achieving an 80.0% soft match F1 score, with significant improvements over previous models. Our code and data are publicly available at https://github.com/thomas0809/RxnScribe.
    
[^9]: 生成式检索如何扩展到数百万篇文章？

    How Does Generative Retrieval Scale to Millions of Passages?. (arXiv:2305.11841v1 [cs.IR])

    [http://arxiv.org/abs/2305.11841](http://arxiv.org/abs/2305.11841)

    本研究对不同语料规模下的生成式检索技术进行了实证研究，扩展到包含8.8M篇章的MS MARCO检索任务，并评估了高达11B个参数的模型大小，揭示出了在索引期间使用合成查询作为文档表示的重要性。

    

    由可微搜索索引(Differentiable Search Index)推广而来的生成式检索的新兴范式,将经典的信息检索问题重新构造为序列到序列的建模任务，放弃了外部索引，并将整个文档语料库编码在单个Transformer中。虽然已经提出了许多不同的方法来提高生成式检索的有效性，但它们仅在约100k的文档语料库上进行了评估。我们进行了第一次根据不同的语料规模进行生成式检索技术的实证研究，最终扩展到整个8.8M篇章的MS MARCO检索任务，并评估了高达11B个参数的模型大小。我们揭示了关于将生成式检索扩展到数百万篇文章的几个发现，特别是索引期间使用合成查询作为文档表示的核心重要性，以及考虑并非现有的建议架构修改时的无效性。

    Popularized by the Differentiable Search Index, the emerging paradigm of generative retrieval re-frames the classic information retrieval problem into a sequence-to-sequence modeling task, forgoing external indices and encoding an entire document corpus within a single Transformer. Although many different approaches have been proposed to improve the effectiveness of generative retrieval, they have only been evaluated on document corpora on the order of 100k in size. We conduct the first empirical study of generative retrieval techniques across various corpus scales, ultimately scaling up to the entire MS MARCO passage ranking task with a corpus of 8.8M passages and evaluating model sizes up to 11B parameters. We uncover several findings about scaling generative retrieval to millions of passages; notably, the central importance of using synthetic queries as document representations during indexing, the ineffectiveness of existing proposed architecture modifications when accounting for c
    
[^10]: SeeGULL：利用生成模型实现广泛地理文化覆盖的刻板印象基准测试

    SeeGULL: A Stereotype Benchmark with Broad Geo-Cultural Coverage Leveraging Generative Models. (arXiv:2305.11840v1 [cs.CL])

    [http://arxiv.org/abs/2305.11840](http://arxiv.org/abs/2305.11840)

    该论文提出了一个广泛覆盖不同地理和文化背景下的刻板印象的基准测试数据集SeeGULL，使用大型语言模型生成刻板印象，针对178个国家、8个不同地缘政治地区和美国与印度的州级身份群体进行了评估，以提高NLP模型对全球多元化人群的敏感性。

    

    刻板印象基准数据集对于检测和缓解NLP模型中有关人群的社会刻板印象至关重要。然而，现有的数据集在规模和覆盖范围上存在限制，并且主要限于西方社会普遍存在的刻板印象。随着语言技术在全球范围内的普及，这一问题尤为严重。为解决这一问题，我们提出了SeeGULL，这是一个广泛覆盖的刻板印象数据集，利用大型语言模型（如PaLM和GPT-3）的生成能力，利用全球性的多样化评分池验证社会中这些刻板印象的普遍程度。SeeGULL使用英语，并包含涵盖178个国家、6个大洲和8个不同地缘政治地区的身份群体的刻板印象，以及美国和印度的州级身份。我们还包括不同刻板印象的精细冒犯分数，并展示它们之间的全球差异。此外，我们还包括比较注释。

    Stereotype benchmark datasets are crucial to detect and mitigate social stereotypes about groups of people in NLP models. However, existing datasets are limited in size and coverage, and are largely restricted to stereotypes prevalent in the Western society. This is especially problematic as language technologies gain hold across the globe. To address this gap, we present SeeGULL, a broad-coverage stereotype dataset, built by utilizing generative capabilities of large language models such as PaLM, and GPT-3, and leveraging a globally diverse rater pool to validate the prevalence of those stereotypes in society. SeeGULL is in English, and contains stereotypes about identity groups spanning 178 countries across 8 different geo-political regions across 6 continents, as well as state-level identities within the US and India. We also include fine-grained offensiveness scores for different stereotypes and demonstrate their global disparities. Furthermore, we include comparative annotations a
    
[^11]: LLM在医学系统综述中的潜在用途和风险评估

    Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews. (arXiv:2305.11828v1 [cs.CL])

    [http://arxiv.org/abs/2305.11828](http://arxiv.org/abs/2305.11828)

    本文研究了使用LLM协助制作医学证据综述的潜在用途和风险，指出LLM有可能自动生成文献综述，但由于可能出现虚构或遗漏信息的情况，LLM的使用需要谨慎。

    

    医学系统综述对于制定临床决策和医疗政策至关重要。但是制作这样的综述很费力且耗时。因此，很多问题缺乏高质量的证据综述，即使这些综述可用，在审查过程中可能已经过时。现在，大型语言模型（LLM）已经能够生成长篇文本，这意味着自动生成文献综述的诱人可能性。然而，由于虚构或遗漏重要信息，LLM有时会产生不准确（甚至可能具有误导性）的文本。在医疗保健环境中，这可能使LLM在最好情况下无法使用，在最坏情况下会带来危险。对于LLM的益处和风险的大多数讨论与具体应用脱离了关系。在这项工作中，我们试图定性描述LLM在协助制作医学证据综述方面的潜在用途和风险。我们对16位国际专家进行了半结构化访谈。

    Medical systematic reviews are crucial for informing clinical decision making and healthcare policy. But producing such reviews is onerous and time-consuming. Thus, high-quality evidence synopses are not available for many questions and may be outdated even when they are available. Large language models (LLMs) are now capable of generating long-form texts, suggesting the tantalizing possibility of automatically generating literature reviews on demand. However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucinating or omitting important information. In the healthcare context, this may render LLMs unusable at best and dangerous at worst. Most discussion surrounding the benefits and risks of LLMs have been divorced from specific applications. In this work, we seek to qualitatively characterize the potential utility and risks of LLMs for assisting in production of medical evidence reviews. We conducted 16 semi-structured interviews with international experts
    
[^12]: STOAT: 结构化数据控制性分析文本生成

    STOAT: Structured Data to Analytical Text With Controls. (arXiv:2305.11826v1 [cs.CL])

    [http://arxiv.org/abs/2305.11826](http://arxiv.org/abs/2305.11826)

    STOAT模型是表格和推理意识的生成模型，在数字推理、常识推理、时间推理、表格知识和实体知识方面有较好的控制，提高了分析句子生成的质量和准确度。

    

    最近，语言模型在结构化数据到文本生成任务中取得了巨大的进展。然而，当需要进行逻辑推理以生成描述时，这些模型仍然表现出次优的性能。在本文中，我们特别关注从结构化数据（例如表格）生成分析文本。在（Gupta et al.,2020）提出的分类基础上，我们重点关注以下推理类别的可控制表格到文本生成：数字推理、常识推理、时间推理、表格知识和实体知识。我们提出了STOAT模型，该模型具有表格和推理意识，并通过矢量量化将给定的推理类别注入输出中。我们观察到，在分析句子任务中，我们的模型在iToTTo和Infotabs的PARENT指标上分别提供了10.19％和1.13％的优化。我们还发现，与基线模型相比，我们的模型生成的描述更加准确和分析，人类评估中增加了15.3％。

    Recent language models have made tremendous progress in the structured data to text generation task. However, these models still give sub-optimal performance where logical inference is required to generate the descriptions. In this work, we specifically focus on analytical text generation from structured data such as tables. Building on the taxonomy proposed in (Gupta et al., 2020) we focus on controllable table to text generation for the following reasoning categories: numerical reasoning, commonsense reasoning, temporal reasoning, table knowledge, and entity knowledge. We propose STOAT model, which is table and reasoning aware, with vector-quantization to infuse the given reasoning categories in the output. We observe that our model provides 10.19%, 1.13% improvement on the PARENT metric in iToTTo and Infotabs for the analytical sentence task. We also found that our model generates 15.3% more faithful and analytical descriptions as compared to the baseline models in human evaluation.
    
[^13]: 神经机器翻译中伪标签训练和模型惯性研究

    Pseudo-Label Training and Model Inertia in Neural Machine Translation. (arXiv:2305.11808v1 [cs.CL])

    [http://arxiv.org/abs/2305.11808](http://arxiv.org/abs/2305.11808)

    本研究着重研究了NMT中经常使用的伪标签训练（PLT），发现PLT不仅会影响质量，而且可以增强模型对模型更新和输入扰动的稳定性，形成模型惯性。

    

    像许多其他机器学习应用一样，神经机器翻译（NMT）受益于过度参数化的深度神经模型。但是，这些模型被观察到是脆弱的：NMT模型预测对小的输入变化敏感，并且在重新训练或增量模型更新时会显示显着变化。本文研究了NMT中经常使用的伪标签训练（PLT），它是前向翻译（或自我训练）和序列级知识蒸馏等相关技术的常见训练方法。尽管PLT对质量的影响有充分的文献记载，但我们强调一个较少被人了解的影响：PLT可以增强模型对模型更新和输入扰动的稳定性，形成一组我们称之为模型惯性的特性。我们研究了不同训练设置下的惯性效应，并确定了分布简化是观察结果背后的机制。

    Like many other machine learning applications, neural machine translation (NMT) benefits from over-parameterized deep neural models. However, these models have been observed to be brittle: NMT model predictions are sensitive to small input changes and can show significant variation across re-training or incremental model updates. This work studies a frequently used method in NMT, pseudo-label training (PLT), which is common to the related techniques of forward-translation (or self-training) and sequence-level knowledge distillation. While the effect of PLT on quality is well-documented, we highlight a lesser-known effect: PLT can enhance a model's stability to model updates and input perturbations, a set of properties we call model inertia. We study inertia effects under different training settings and we identify distribution simplification as a mechanism behind the observed results.
    
[^14]: 内幕揭秘：更好理解机器翻译神经评估指标

    The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics. (arXiv:2305.11806v1 [cs.CL])

    [http://arxiv.org/abs/2305.11806](http://arxiv.org/abs/2305.11806)

    本文开发多种神经可解释方法，并展示了它们用于解释最先进微调神经度量的有效性，揭示了这些度量用来利用令人直接归因于翻译错误的令牌级信息。

    

    机器翻译评估的神经度量（如 COMET）在与传统基于词汇重叠的度量（如 BLEU）相比，与人类判断的相关性显著提高。然而，神经评估指标在很大程度上是“黑盒子”，只返回单个句子级别得分，决策过程不透明。在本研究中，我们开发和比较了多种神经可解释方法，并展示了它们用于解释最先进的微调神经度量的有效性。我们的研究揭示了这些度量利用的令人直接归因于翻译错误的令牌级信息，通过比较令牌级神经显著性图与多维质量度量（MQM）注释和合成严重翻译错误。为了方便未来的研究，我们在此发布我们的代码： https://github.com/Unbabel/COMET/tree/explainable-metrics。

    Neural metrics for machine translation evaluation, such as COMET, exhibit significant improvements in their correlation with human judgments, as compared to traditional metrics based on lexical overlap, such as BLEU. Yet, neural metrics are, to a great extent, "black boxes" returning a single sentence-level score without transparency about the decision-making process. In this work, we develop and compare several neural explainability methods and demonstrate their effectiveness for interpreting state-of-the-art fine-tuned neural metrics. Our study reveals that these metrics leverage token-level information that can be directly attributed to translation errors, as assessed through comparison of token-level neural saliency maps with Multidimensional Quality Metrics (MQM) annotations and with synthetically-generated critical translation errors. To ease future research, we release our code at: https://github.com/Unbabel/COMET/tree/explainable-metrics.
    
[^15]: LLM的思路链索引用于回答深入对话问题的提示

    Chain-of-thought prompting for responding to in-depth dialogue questions with LLM. (arXiv:2305.11792v1 [cs.CL])

    [http://arxiv.org/abs/2305.11792](http://arxiv.org/abs/2305.11792)

    本文提出使用思路链索引的方式来响应用户状态，以提供更个性化和更有吸引力的用户体验，用语义相似性而非测试查询做中间推理处理。

    

    用户提问的方式和内容可以洞察他们的当前状态，包括人格、情感和心理状态。本文提出使用思路链索引的方式来帮助大型语言模型进行推理和规划，以响应用户状态，以提供更个性化和更有吸引力的用户体验。我们首先建立了一个包括6个英语和中文的对话或问答数据集的基准，涵盖了用户状态的3个不同方面（包括人格、情感和心理）。然后，我们提示语言模型生成关于用户状态的响应作为中间推理处理。我们提出了一种使用中间推理的语义相似性而非测试查询的新颖演示选择策略。为了评估我们的方法的有效性和鲁棒性，我们进行了广泛的实验。

    The way and content in which users ask questions can provide insight into their current status, including their personality, emotions, and psychology. Instead of directly prompting the large language models (LLMs), we explore how chain-of-thought prompting helps in this scenario to perform reasoning and planning according to user status, aiming to provide a more personalized and engaging experience for the user query. To this end, we first construct a benchmark of 6 dialogue or question-answering datasets in both English and Chinese, covering 3 different aspects of user status (\textit{including} \textit{personality}, \textit{emotion}, and \textit{psychology}). Then we prompt the LLMs to generate the response regarding the user status as intermediate reasoning processing. We propose a novel demonstration selection strategy using the semantic similarity of intermediate reasoning instead of test queries. To evaluate the effectiveness and robustness of our approach, we conduct extensive e
    
[^16]: 基于Prompt Ordering的数据增强增强Few-shot NER的效果

    Enhancing Few-shot NER with Prompt Ordering based Data Augmentation. (arXiv:2305.11791v1 [cs.CL])

    [http://arxiv.org/abs/2305.11791](http://arxiv.org/abs/2305.11791)

    本文提出了一种基于Prompt Ordering的数据增强方法来提高Few-shot NER的鲁棒性和泛化性，不同但合理的目标序列提供了更多的多样性。实验证明该方法可扩展性好，比传统方法更有效。

    

    近期, 数据增强方法已被证明对于预训练语言模型在低资源环境下的Few-shot命名实体识别(NER)任务有效.然而,传统的NER数据增强方法大多针对序列标注模型即标记级分类,并且其适用性有限,难以处理嵌套的NER等任务 .本文提出,在训练过程中可以通过为模型提供更多样化但合理的目标实体序列的方式,来提高NER模型在Few-shot任务下的泛化性和鲁棒性。同时,我们提出了基于Prompt Ordering的简单实用的技术,将生成的不同目标实体序列按可理解的顺序组合,以更好地帮助模型理解NER任务。通过实验证明本方法具有优异的性能。

    Recently, data augmentation (DA) methods have been proven to be effective for pre-trained language models (PLMs) in low-resource settings, including few-shot named entity recognition (NER). However, conventional NER DA methods are mostly aimed at sequence labeling models, i.e., token-level classification, and few are compatible with unified autoregressive generation frameworks, which can handle a wider range of NER tasks, such as nested NER. Furthermore, these generation frameworks have a strong assumption that the entities will appear in the target sequence with the same left-to-right order as the source sequence. In this paper, we claim that there is no need to keep this strict order, and more diversified but reasonable target entity sequences can be provided during the training stage as a novel DA method. Nevertheless, a naive mixture of augmented data can confuse the model since one source sequence will then be paired with different target sequences. Therefore, we propose a simple 
    
[^17]: 伪代码指令提示

    Prompting with Pseudo-Code Instructions. (arXiv:2305.11790v1 [cs.CL])

    [http://arxiv.org/abs/2305.11790](http://arxiv.org/abs/2305.11790)

    本文研究了使用伪代码指令提示能否提高预训练语言模型的性能，实验证明使用伪代码提示可以在分类任务中提高7-16分，并相对改善12-38%。

    

    最近，使用自然语言指令提示已成为利用大型语言模型能力的一种流行方法。鉴于自然语言中的固有歧义，因此考虑使用更少歧义的提示样式，如伪代码提示，可能具有优势。本文探讨了通过伪代码指令提示是否有助于改善预训练语言模型的性能。我们手动创建了一个包含来自Super-NaturalInstructions数据集的132个不同任务的伪代码提示数据集，涵盖分类、QA和生成语言任务。使用这些伪代码提示以及它们的自然语言对应物，在两个LLM家族-BLOOM和CodeGen上研究它们的性能。我们的实验表明，使用伪代码指令提示会带来更好的结果，对于分类任务，F1分数平均增加（绝对值）7-16分，相对改善12-38%。

    Prompting with natural language instructions has recently emerged as a popular method of harnessing the capabilities of large language models. Given the inherent ambiguity present in natural language, it is intuitive to consider the possible advantages of prompting with less ambiguous prompt styles, such as the use of pseudo-code.  In this paper we explore if prompting via pseudo-code instructions helps improve the performance of pre-trained language models. We manually create a dataset of pseudo-code prompts for 132 different tasks spanning classification, QA and generative language tasks, sourced from the Super-NaturalInstructions dataset. Using these prompts along with their counterparts in natural language, we study their performance on two LLM families - BLOOM and CodeGen. Our experiments show that using pseudo-code instructions leads to better results, with an average increase (absolute) of 7-16 points in F1 scores for classification tasks and an improvement (relative) of 12-38% 
    
[^18]: 通过人机协作解决自然语言处理难题：一种基于讨论的方法

    Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach. (arXiv:2305.11789v1 [cs.CL])

    [http://arxiv.org/abs/2305.11789](http://arxiv.org/abs/2305.11789)

    本研究提出了一种基于讨论的方法，旨在通过人机协作解决自然语言处理难题。提出了一个可以进行对话并修正预测的系统，通过实验证明该系统可以通过与人类的讨论提高准确性高达25%。

    

    人类通过讨论、解释并相互赞同或反对等方式共同解决共同问题。同样，如果系统在解决任务时能与人类进行讨论，它可以提高系统的性能和可靠性。在之前的可解释性研究中，系统只能做出预测，人类只能就这些预测提问，而没有彼此间的意见交换。本研究旨在创建一个数据集和计算框架，使系统可以通过对话进行讨论和修正预测。通过实验证明，所提出的系统可以与人类进行有益的讨论，将自然语言推理任务的准确性提高了高达25个百分点。

    Humans work together to solve common problems by having discussions, explaining, and agreeing or disagreeing with each other. Similarly, if a system can have discussions with humans when solving tasks, it can improve the system's performance and reliability. In previous research on explainability, it has only been possible for the system to make predictions and for humans to ask questions about them rather than having a mutual exchange of opinions. This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.
    
[^19]: DMDD：面向数据集提及检测的大规模数据集

    DMDD: A Large-Scale Dataset for Dataset Mentions Detection. (arXiv:2305.11779v1 [cs.CL])

    [http://arxiv.org/abs/2305.11779](http://arxiv.org/abs/2305.11779)

    DMDD是一个公开的数据集，用于数据集提及检测任务，包含31,219篇科学文章和超过449,000个弱注释的数据集提及。该数据集为该任务建立了基准性能，并且通过分析模型的表现，确定了开放问题。

    

    数据集名称识别是科学文献自动信息提取的关键任务，可以帮助研究人员理解和识别研究机会。然而，现有的用于数据集提及检测的语料库在大小和命名多样性方面存在局限性。本文介绍了数据集提及检测数据集（DMDD），这是当前最大的公开语料库，用于处理这项任务。DMDD由DMDD主要语料库和评估集组成，其中DMDD主要语料库包括31,219篇科学文章，其中包含超过449,000个数据集提及弱注释格式的文本段，评估集包括450篇手动注释的科学文章，用于评估目的。我们使用DMDD建立了数据集提及检测和链接的基准性能。通过分析各种模型在DMDD上的表现，我们能够确定数据集提及检测中存在的问题。我们邀请社区使用我们的数据集作为挑战，开发新的数据集提及检测模型。

    The recognition of dataset names is a critical task for automatic information extraction in scientific literature, enabling researchers to understand and identify research opportunities. However, existing corpora for dataset mention detection are limited in size and naming diversity. In this paper, we introduce the Dataset Mentions Detection Dataset (DMDD), the largest publicly available corpus for this task. DMDD consists of the DMDD main corpus, comprising 31,219 scientific articles with over 449,000 dataset mentions weakly annotated in the format of in-text spans, and an evaluation set, which comprises of 450 scientific articles manually annotated for evaluation purposes. We use DMDD to establish baseline performance for dataset mention detection and linking. By analyzing the performance of various models on DMDD, we are able to identify open problems in dataset mention detection. We invite the community to use our dataset as a challenge to develop novel dataset mention detection mo
    
[^20]: 《跨语种监督提高大型语言模型预训练质量》

    Cross-Lingual Supervision improves Large Language Models Pre-training. (arXiv:2305.11778v1 [cs.CL])

    [http://arxiv.org/abs/2305.11778](http://arxiv.org/abs/2305.11778)

    本文表明，将大型语言模型的预训练中使用跨语种并行数据能提高其上下文学习能力；同时，提出了一种简单且有效的策略来学习两个目标之间的最佳混合比例。

    

    近期大型语言模型的迅速进展主要依赖于使用自监督语言建模目标（如下一个标记预测或跨度损坏）。与此相反，机器翻译系统主要使用需要源语言和目标语言之间对齐数据的跨语种监督进行训练。我们证明，在预训练过程中，将大型语言模型使用自监督语言建模目标和受监督的机器翻译目标混合，因此在预训练过程中包含跨语种并行数据，可产生更好的上下文学习能力。由于预训练是非常资源密集的过程，而在两个目标之间进行最佳混合比例的网格搜索是非常昂贵的，我们提出了一种简单而有效的策略来在预训练中学习这些知识。

    The recent rapid progress in pre-training Large Language Models has relied on using self-supervised language modeling objectives like next token prediction or span corruption. On the other hand, Machine Translation Systems are mostly trained using cross-lingual supervision that requires aligned data between source and target languages. We demonstrate that pre-training Large Language Models on a mixture of a self-supervised Language Modeling objective and the supervised Machine Translation objective, therefore including cross-lingual parallel data during pre-training, yields models with better in-context learning abilities. As pre-training is a very resource-intensive process and a grid search on the best mixing ratio between the two objectives is prohibitively expensive, we propose a simple yet effective strategy to learn it during pre-training.
    
[^21]: 提升联合学习的视觉语言预训练：基于联合学习的问答与密集字幕生成

    Enhancing Vision-Language Pre-Training with Jointly Learned Questioner and Dense Captioner. (arXiv:2305.11769v1 [cs.CV])

    [http://arxiv.org/abs/2305.11769](http://arxiv.org/abs/2305.11769)

    本文提出了一种名为JADE的新方法，可以利用易于获取的图像-文本对进行的联合学习，以提升视觉和语言模态的细粒度特征对齐，从而更好地进行视觉问答和密集字幕生成。

    

    大型预先训练的多模态模型在许多下游任务中都表现出显著的成功，包括图像字幕生成、图像文本检索和视觉问答等。然而，许多方法都依赖于从网络上收集的图像-文本对作为预先训练的数据，忽视了视觉和语言模态之间需要细粒度特征对齐的需求，这需要对图像和语言表达进行详细的理解。将视觉问答和密集字幕集成到预先训练中可以解决这个问题，但是获取图像-问题-答案以及图像-位置-字幕三元组是具有挑战性和耗时的。此外，公开可用的视觉问答和密集字幕数据集通常由于手动数据收集和标注而规模有限。在本文中，我们提出了一种新方法，称为联合问答和密集字幕生成（JADE），它利用预先训练的多模态模型和易于获取的图像-文本对来进行模型训练。

    Large pre-trained multimodal models have demonstrated significant success in a range of downstream tasks, including image captioning, image-text retrieval, visual question answering (VQA), etc. However, many of these methods rely on image-text pairs collected from the web as pre-training data and unfortunately overlook the need for fine-grained feature alignment between vision and language modalities, which requires detailed understanding of images and language expressions. While integrating VQA and dense captioning (DC) into pre-training can address this issue, acquiring image-question-answer as well as image-location-caption triplets is challenging and time-consuming. Additionally, publicly available datasets for VQA and dense captioning are typically limited in scale due to manual data collection and labeling efforts. In this paper, we propose a novel method called Joint QA and DC GEneration (JADE), which utilizes a pre-trained multimodal model and easily-crawled image-text pairs to
    
[^22]: 通过整体3D场景理解生成视觉空间描述

    Generating Visual Spatial Description via Holistic 3D Scene Understanding. (arXiv:2305.11768v1 [cs.CV])

    [http://arxiv.org/abs/2305.11768](http://arxiv.org/abs/2305.11768)

    本文研究将3D场景特征纳入VSD方法，构建目标对象为中心的3D空间场景图(Go3D-S2G)，提出多样化的文本生成方法，可以显著提高性能。

    

    视觉空间描述(VSD)的目标是生成描述图像中给定对象空间关系的文本。现有的VSD工作仅模拟2D几何视觉特征，因此不可避免地陷入目标对象空间理解倾斜的问题。本文研究了将3D场景特征纳入VSD的方法。通过外部3D场景提取器，我们获取输入图像的3D对象和场景特征，基于此构建目标对象为中心的3D空间场景图(Go3D-S2G)，从而模拟目标对象在整体3D场景中的空间语义。此外，我们提出一种场景子图选择机制，从Go3D-S2G中采样拓扑多样的子图，导航不同的局部结构特征以产生空间多样化的文本生成。对两个VSD数据集的实验结果表明，我们的框架显著优于基线，特别是在one-split情况下提高了性能。

    Visual spatial description (VSD) aims to generate texts that describe the spatial relations of the given objects within images. Existing VSD work merely models the 2D geometrical vision features, thus inevitably falling prey to the problem of skewed spatial understanding of target objects. In this work, we investigate the incorporation of 3D scene features for VSD. With an external 3D scene extractor, we obtain the 3D objects and scene features for input images, based on which we construct a target object-centered 3D spatial scene graph (Go3D-S2G), such that we model the spatial semantics of target objects within the holistic 3D scenes. Besides, we propose a scene subgraph selecting mechanism, sampling topologically-diverse subgraphs from Go3D-S2G, where the diverse local structure features are navigated to yield spatially-diversified text generation. Experimental results on two VSD datasets demonstrate that our framework outperforms the baselines significantly, especially improving on
    
[^23]: ReSeTOX：重新学习关注权重来减轻机器翻译中的毒性

    ReSeTOX: Re-learning attention weights for toxicity mitigation in machine translation. (arXiv:2305.11761v1 [cs.CL])

    [http://arxiv.org/abs/2305.11761](http://arxiv.org/abs/2305.11761)

    ReSeTOX是一种新方法，通过重新学习关注权重，能在不重新训练的情况下，有效减少机器翻译中有毒内容的产生，实验结果表明其在164种语言上成功将有毒内容压缩57%。

    

    我们提出的方法 ReSeTOX（REdo SEarch if TOXic）解决了神经机器翻译（NMT）生成包含输入中不存在的有毒单词的翻译输出的问题。其目的是通过不需要重新训练的方式缓解毒性语言的引入。在推断过程中发现有毒，ReSeTOX 会动态调整关键值自注意力权重并重新评估波束搜索假设。实验结果表明，在 164 种语言中，ReSeTOX 实现了显著的 57% 减少有毒内容的同时保持了平均 99.5% 的翻译质量。

    Our proposed method, ReSeTOX (REdo SEarch if TOXic), addresses the issue of Neural Machine Translation (NMT) generating translation outputs that contain toxic words not present in the input. The objective is to mitigate the introduction of toxic language without the need for re-training. In the case of identified added toxicity during the inference process, ReSeTOX dynamically adjusts the key-value self-attention weights and re-evaluates the beam search hypotheses. Experimental results demonstrate that ReSeTOX achieves a remarkable 57% reduction in added toxicity while maintaining an average translation quality of 99.5% across 164 languages.
    
[^24]: 通过Prompt-Tuning控制从大型语言模型中提取记忆数据

    Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning. (arXiv:2305.11759v1 [cs.CL])

    [http://arxiv.org/abs/2305.11759](http://arxiv.org/abs/2305.11759)

    该论文提出在大型语言模型中通过Prompt-Tuning策略来控制从中提取记忆数据的方法，提供了攻击和防御两种训练策略。在公共基准测试中展示了其在GPT-Neo模型中的有效性，攻击策略相对于基线产生了9.3%的提取率增加，而防御策略可以调整以实现不同的隐私-效用权衡，可以实现最多97.7%的提取率减少，但困惑度增加了16.9%。

    

    大型语言模型（LLMs）已知会记忆其训练数据的重要部分，并且简单查询模型即可提取记忆的内容，存在隐私风险。我们提出了一种新的方法，使用Prompt-Tuning来控制LLMs中记忆内容的提取率。我们提出了两个Prompt训练策略来增加和减少提取率，分别对应攻击和防御。我们使用来自GPT-Neo系列的模型在公共基准测试中展示了我们技术的有效性。对于1.3B参数的GPT-Neo模型，我们的攻击相对于基线产生了9.3个百分点的提取率增加。通过用户指定的超参数，我们的防御可以调整以实现不同的隐私-效用权衡。我们相对于基线实现了最多97.7%的提取率减少，同时困惑度增加了16.9%。

    Large Language Models (LLMs) are known to memorize significant portions of their training data. Parts of this memorized content have been shown to be extractable by simply querying the model, which poses a privacy risk. We present a novel approach which uses prompt-tuning to control the extraction rates of memorized content in LLMs. We present two prompt training strategies to increase and decrease extraction rates, which correspond to an attack and a defense, respectively. We demonstrate the effectiveness of our techniques by using models from the GPT-Neo family on a public benchmark. For the 1.3B parameter GPT-Neo model, our attack yields a 9.3 percentage point increase in extraction rate compared to our baseline. Our defense can be tuned to achieve different privacy-utility trade-offs by a user-specified hyperparameter. We achieve an extraction rate reduction of up to 97.7% relative to our baseline, with a perplexity increase of 16.9%.
    
[^25]: HELMA：大型语言模型的幻觉评估基准

    HELMA: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models. (arXiv:2305.11747v1 [cs.CL])

    [http://arxiv.org/abs/2305.11747](http://arxiv.org/abs/2305.11747)

    本文介绍了一个大型语言模型幻觉评估基准（HELMA），其为标准化和可靠的估算模型幻觉问题提供了一种方法，并使用ChatGPT进行了实证研究以表明其存在幻觉的风险并为鉴别和减轻模型幻觉问题提供了一种方法。

    

    大型语言模型（LLM），如ChatGPT，容易生成幻觉，即与源内容冲突或无法通过事实知识进行验证的内容。为了了解LLMs会产生哪种类型的内容以及在多大程度上会产生幻觉，我们引入了Hallucination Evaluation for Large Language Models（HELMA）基准，这是一个包含大量生成的和人工注释的幻觉样本集，用于评估LLMs在识别和减轻幻觉方面的性能。为了生成这些样本，我们提出了一个基于ChatGPT的两步框架，即采样-过滤。具体来说，我们首先采用两种不同的采样方法基于指令生成幻觉样本，然后使用一个示例增强过滤方法选择最好的样本。此外，我们还聘请一些人工标注员来注释ChatGPT响应中的幻觉。经验证实，ChatGPT有一定的概率产生幻觉，并存在传播错误信息的潜在风险。我们提出的HELMA基准可作为识别和减轻LLMs幻觉问题的标准化可靠评估工具。

    Large language models (LLMs), such as ChatGPT, are prone to generate hallucinations, \ie content that conflicts with the source or cannot be verified by the factual knowledge. To understand what types of content and to which extent LLMs are apt to hallucinate, we introduce the Hallucination Evaluation for Large Language Models (HELMA) benchmark, a large collection of generated and human-annotated hallucinated samples for evaluating the performance of LLMs in recognizing and alleviating hallucination. To generate these samples, we propose a ChatGPT-based two-step framework, \ie sampling-then-filtering. Specifically, we first adopt two different sampling methods to generate hallucinated samples based on instructions, and then use an example-enhanced filtering method to select the best one. Furthermore, we also hire some human labelers to annotate the hallucinations in ChatGPT responses. The empirical results suggest that ChatGPT has some probabilities to generate hallucinations and exist
    
[^26]: HalOmi：机器翻译中多语言“幻觉”和遗漏检测的手动注释基准

    HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation. (arXiv:2305.11746v1 [cs.CL])

    [http://arxiv.org/abs/2305.11746](http://arxiv.org/abs/2305.11746)

    本文提供了一个涵盖18个翻译方向，包括多种资源水平和脚本的机器翻译中“幻觉”和遗漏现象的手动注释数据集。同时，通过评估不同语言对的表现，为该领域研究提供可靠的基线。

    

    机器翻译中的“幻觉”指的是完全与输入信息无关的信息，而“遗漏”是指未包括某些输入信息的翻译。尽管这两种情况往往是破坏用户信任的灾难性错误，但这些类型的带注释数据非常稀缺，并且仅限于少数高资源语言。在本研究中，我们发布了一个标注的数据集，用于涵盖18种翻译方向的幻觉和遗漏现象，其资源水平和脚本各不相同。我们的注释涵盖了不同级别的完全幻觉、部分幻觉以及句子和单词一级的遗漏。此外，我们重访了以前的研究，展示了基于单个语言对得出的结论在大规模评估中很难成立，并建立了新的可靠基线。

    Hallucinations in machine translation are translations that contain information completely unrelated to the input. Omissions are translations that do not include some of the input information. While both cases tend to be catastrophic errors undermining user trust, annotated data with these types of pathologies is extremely scarce and is limited to a few high-resource languages. In this work, we release an annotated dataset for the hallucination and omission phenomena covering 18 translation directions with varying resource levels and scripts. Our annotation covers different levels of partial and full hallucinations as well as omissions both at the sentence and at the word level. Additionally, we revisit previous methods for hallucination and omission detection, show that conclusions made based on a single language pair largely do not hold for a large-scale evaluation, and establish new solid baselines.
    
[^27]: 面向神经信息检索的推理时间重排反馈

    Inference-time Re-ranker Relevance Feedback for Neural Information Retrieval. (arXiv:2305.11744v1 [cs.IR])

    [http://arxiv.org/abs/2305.11744](http://arxiv.org/abs/2305.11744)

    本文提出了一种利用重排器提供推理时间反馈来改进检索的方法，可以显著提高低召回率@ K下的检索性能。

    

    神经信息检索通常采用检索和重排框架：先使用双编码器网络检索K（例如100）个候选项，然后再使用更强大的交叉编码器模型对这些候选项进行重新排序，以使更好的候选项排名更高。重排器通常产生比检索器更好的候选分数，但仅限于查看前K个检索到的候选项，因此无法提高检索性能（以Recall @ K为度量）。在本文中，我们利用重排器通过提供推理时间相关反馈来改进检索。具体而言，我们利用重排器的预测对测试实例的重要信息进行了检索器查询表示的更新。我们的方法可以通过轻量级的推理时间蒸馏来实现，目的是使检索器的候选分数更接近于重排器的分数。然后使用更新后的查询向量执行第二个检索步骤。通过实验证明，我们的方法可以显著提高检索性能，特别是在低召回率@ K下。

    Neural information retrieval often adopts a retrieve-and-rerank framework: a bi-encoder network first retrieves K (e.g., 100) candidates that are then re-ranked using a more powerful cross-encoder model to rank the better candidates higher. The re-ranker generally produces better candidate scores than the retriever, but is limited to seeing only the top K retrieved candidates, thus providing no improvements in retrieval performance as measured by Recall@K. In this work, we leverage the re-ranker to also improve retrieval by providing inference-time relevance feedback to the retriever. Concretely, we update the retriever's query representation for a test instance using a lightweight inference-time distillation of the re-ranker's prediction for that instance. The distillation loss is designed to bring the retriever's candidate scores closer to those of the re-ranker. A second retrieval step is then performed with the updated query vector. We empirically show that our approach, which can 
    
[^28]: CRITIC：大型语言模型可以通过工具交互批评进行自我校正

    CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing. (arXiv:2305.11738v1 [cs.CL])

    [http://arxiv.org/abs/2305.11738](http://arxiv.org/abs/2305.11738)

    本文提出了一个名为CRITIC的框架，使得大型语言模型可以通过与工具的交互校正自己的错误，从而避免生成出现不一致和问题行为的结果。

    

    近年来，大型语言模型的发展非常引人注目。然而，这些模型有时会出现不一致和问题行为，例如出现幻觉事实，生成有缺陷的代码或创建冒犯和有害的内容。与这些模型不同，人类通常使用外部工具来交叉检查和精炼他们的初步内容，例如使用搜索引擎进行事实检查或使用代码解释器进行调试。受这一观察的启发，我们引入了一个名为CRITIC的框架，允许LLMs（实质上是“黑盒子”）以类似于人类与工具交互的方式验证和逐步修正自己的输出。更具体地说，从初始输出开始，CRITIC与适当的工具交互以评估文本的某些方面，然后根据在此验证过程中获得的反馈修改输出。涉及自由形式问答、数学程序综合和毒性检测的全面评估表明，我们的框架使LLMs能够从错误中学习并纠正自己的错误。

    Recent developments in large language models (LLMs) have been impressive. However, these models sometimes show inconsistencies and problematic behavior, such as hallucinating facts, generating flawed code, or creating offensive and toxic content. Unlike these models, humans typically utilize external tools to cross-check and refine their initial content, like using a search engine for fact-checking, or a code interpreter for debugging. Inspired by this observation, we introduce a framework called CRITIC that allows LLMs, which are essentially "black boxes" to validate and progressively amend their own outputs in a manner similar to human interaction with tools. More specifically, starting with an initial output, CRITIC interacts with appropriate tools to evaluate certain aspects of the text, and then revises the output based on the feedback obtained during this validation process. Comprehensive evaluations involving free-form question answering, mathematical program synthesis, and toxi
    
[^29]: S3HQA：一种用于文本-表格混合问答的三阶段框架

    S$^3$HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering. (arXiv:2305.11725v1 [cs.CL])

    [http://arxiv.org/abs/2305.11725](http://arxiv.org/abs/2305.11725)

    本文提出了一种三阶段的文本表格问答框架S3HQA，该框架采用训练精细的检索器来解决标签噪声问题，采用混合选择器来选择最相关的实际知识并采用基于生成的推理器来获取答案。在WikiTableQuestions和ComplexWebQuestions数据集上实现了最先进的性能，并在很大程度上优于以前的方法。

    

    回答涉及文本和表格混合事实知识的多跳问题(TextTableQA)是一项具有挑战性的任务。现有模型主要采用检索器-阅读器框架，存在几个问题，如训练检索器的嘈杂标签、对文本和表格的异构信息利用不足以及不同推理操作能力不足。本文提出了一个三阶段文本表格问答框架S3HQA，包括检索器、选择器和推理器。我们采用一个训练精细的检索器来解决嘈杂标签的问题。然后，使用一个混合选择器来考虑异构数据之间的链接关系，以选择最相关的实际知识。在最后一个阶段，我们采用一个基于生成的推理器来获取答案，而不是像之前的方法一样使用阅读理解模块。其中包括两种方法：一种是按行生成器，一种是LLM提示生成器（在这个任务中第一次使用）。在WikiTableQuestions和ComplexWebQuestions数据集上的实验结果显示，我们的S3HQA实现了最先进的性能，并在很大程度上优于以前的方法。

    Answering multi-hop questions over hybrid factual knowledge from the given text and table (TextTableQA) is a challenging task. Existing models mainly adopt a retriever-reader framework, which have several deficiencies, such as noisy labeling in training retriever, insufficient utilization of heterogeneous information over text and table, and deficient ability for different reasoning operations. In this paper, we propose a three-stage TextTableQA framework S3HQA, which comprises of retriever, selector, and reasoner. We use a retriever with refinement training to solve the noisy labeling problem. Then, a hybrid selector considers the linked relationships between heterogeneous data to select the most relevant factual knowledge. For the final stage, instead of adapting a reading comprehension module like in previous methods, we employ a generation-based reasoner to obtain answers. This includes two approaches: a row-wise generator and an LLM prompting generator~(first time used in this tas
    
[^30]: 利用特征去噪和多模态主题建模的多模态关系抽取中的信息筛选

    Information Screening whilst Exploiting! Multimodal Relation Extraction with Feature Denoising and Multimodal Topic Modeling. (arXiv:2305.11719v1 [cs.CV])

    [http://arxiv.org/abs/2305.11719](http://arxiv.org/abs/2305.11719)

    该论文提出了一种新的多模态关系抽取框架，结合了内部信息筛选和外部信息利用的思想。通过视觉和文本场景图表示输入的细粒度语义结构，并利用图形信息瓶颈原理进行结构细化和特征去噪，同时运用主题建模丰富上下文，该系统在基准MRE数据集上表现优异，具有巨大的潜力。

    

    现有的多模态关系抽取(MRE)研究面临着两个共存的挑战，即内部信息过度利用和外部信息未能充分利用。为了应对这个问题，我们提出了一个新的框架，同时实现了内部信息筛选和外部信息利用的思想。首先，我们用视觉和文本场景图表示输入图像和文本的细粒度语义结构，将其进一步融合成一个统一的跨模态图(CMG)。基于CMG，我们利用图形信息瓶颈原理进行结构细化，主动去除不太具有信息量的特征。接下来，我们对输入图像和文本进行主题建模，将潜在的多模态主题特征融入其中以丰富上下文。在基准MRE数据集上，我们的系统显著优于当前最佳模型。通过进一步深入的分析，我们揭示了我们的方法在MRE任务中具有巨大的潜力。

    Existing research on multimodal relation extraction (MRE) faces two co-existing challenges, internal-information over-utilization and external-information under-exploitation. To combat that, we propose a novel framework that simultaneously implements the idea of internal-information screening and external-information exploiting. First, we represent the fine-grained semantic structures of the input image and text with the visual and textual scene graphs, which are further fused into a unified cross-modal graph (CMG). Based on CMG, we perform structure refinement with the guidance of the graph information bottleneck principle, actively denoising the less-informative features. Next, we perform topic modeling over the input image and text, incorporating latent multimodal topic features to enrich the contexts. On the benchmark MRE dataset, our system outperforms the current best model significantly. With further in-depth analyses, we reveal the great potential of our method for the MRE task
    
[^31]: 下一个会是什么？评估神经文本生成器的不确定性与人类生产变异性对比

    What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability. (arXiv:2305.11707v1 [cs.CL])

    [http://arxiv.org/abs/2305.11707](http://arxiv.org/abs/2305.11707)

    本文分析了神经文本生成器与人类生产变异性之间的不确定性，通过探测生成器的输出空间来测量其对人类生产变异性的校准程度，并证明用多个样本和多个参考可以更好地了解模型的不确定性表示。

    

    在自然语言生成（NLG）任务中，针对任何输入，存在多个可行的交际目标，并且可以用多种方式将任何目标用语言表达出来或进行生产。我们表征了人类生产在四个NLG任务中词汇、句法和语义方面的变异程度，并将人类生产变异性与不确定性联系起来。然后，我们检查了生成系统预测的概率分布和解码算法所形成的输出字符串空间，以探究其不确定性。针对每个测试输入，我们测量了生成器对人类生产变异性的校准程度。通过这种基于实例级别的方法，我们分析了NLG模型和解码策略，证明用多个样本和多个参考对生成器进行探测，提供了理解模型不确定性表示所必需的详细级别。

    In Natural Language Generation (NLG) tasks, for any input, multiple communicative goals are plausible, and any goal can be put into words, or produced, in multiple ways. We characterise the extent to which human production varies lexically, syntactically, and semantically across four NLG tasks, connecting human production variability to aleatoric or data uncertainty. We then inspect the space of output strings shaped by a generation system's predicted probability distribution and decoding algorithm to probe its uncertainty. For each test input, we measure the generator's calibration to human production variability. Following this instance-level approach, we analyse NLG models and decoding strategies, demonstrating that probing a generator with multiple samples and, when possible, multiple references, provides the level of detail necessary to gain understanding of a model's representation of uncertainty.
    
[^32]: QUEST:一种利用隐式集合操作的实体搜索查询检索数据集( arXiv:2305.11694v1[cs.CL])

    QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set Operations. (arXiv:2305.11694v1 [cs.CL])

    [http://arxiv.org/abs/2305.11694](http://arxiv.org/abs/2305.11694)

    该研究构建了一个名为QUEST的检索数据集，其中含有3357个自然语言查询，这些查询使用隐式集合操作来满足有选择性的信息需求，这个数据集要求模型匹配查询中提到的条件，并正确执行集合操作。

    

    为满足有选择性的信息需求，我们可以使用隐式集合操作，例如交集、并集和差集。研究检索系统满足这种信息需求的能力，我们构建了QUEST数据集，其中包含3357个自然语言查询，这些查询具有隐式集合操作，同时对应于维基百科文档中的实体集。该数据集要求模型将查询中提到的多个约束条件与文档中相应的证据相匹配，并正确执行各种集合操作。该数据集是半自动构建的，使用维基百科类别名称自动组合查询，然后由众包工作者对其进行释义和自然度验证。众包工作者还根据文档评估实体的相关性，并突出显示查询的属性。

    Formulating selective information needs results in queries that implicitly specify set operations, such as intersection, union, and difference. For instance, one might search for "shorebirds that are not sandpipers" or "science-fiction films shot in England". To study the ability of retrieval systems to meet such information needs, we construct QUEST, a dataset of 3357 natural language queries with implicit set operations, that map to a set of entities corresponding to Wikipedia documents. The dataset challenges models to match multiple constraints mentioned in queries with corresponding evidence in documents and correctly perform various set operations. The dataset is constructed semi-automatically using Wikipedia category names. Queries are automatically composed from individual categories, then paraphrased and further validated for naturalness and fluency by crowdworkers. Crowdworkers also assess the relevance of entities based on their documents and highlight attribution of query c
    
[^33]: 带有门控视觉-语言嵌入的Transformer用于机器人手术中的视觉问答

    Surgical-VQLA: Transformer with Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery. (arXiv:2305.11692v1 [cs.CV])

    [http://arxiv.org/abs/2305.11692](http://arxiv.org/abs/2305.11692)

    本文提出了Surgical-VQLA方法，结合Transformer模型和门控视觉-语言嵌入，解决了手术VQA中对象检测稀缺、异构模态融合策略不足、定位答案缺失等问题，并在测试中实现了最好的表现。

    

    尽管存在着计算机辅助模拟器和手术过程的录制视频，但初级住院医师仍然严重依赖专家来回答他们的问题。然而，专家外科医生通常承担着临床和学术工作，限制了他们回答问题的时间。为此，我们开发了一种手术问答系统，以便从录制的视频中促进机器人辅助手术场景和活动理解。本文提出了一种将Transformer模型与门控视觉-语言嵌入相结合的机器人手术视觉问答方法，解决了手术对象检测模型稀缺、异构模态融合策略不足、缺失定位答案等问题，并在基准手术VQA数据集上实现了最先进的性能。

    Despite the availability of computer-aided simulators and recorded videos of surgical procedures, junior residents still heavily rely on experts to answer their queries. However, expert surgeons are often overloaded with clinical and academic workloads and limit their time in answering. For this purpose, we develop a surgical question-answering system to facilitate robot-assisted surgical scene and activity understanding from recorded videos. Most of the existing VQA methods require an object detector and regions based feature extractor to extract visual features and fuse them with the embedded text of the question for answer generation. However, (1) surgical object detection model is scarce due to smaller datasets and lack of bounding box annotation; (2) current fusion strategy of heterogeneous modalities like text and image is naive; (3) the localized answering is missing, which is crucial in complex surgical scenarios. In this paper, we propose Visual Question Localized-Answering in
    
[^34]: 回收和精馏：带有注意力映射重用和蒸馏屏蔽的基于Transformer的语音自监督学习模型的通用压缩策略

    Recycle-and-Distill: Universal Compression Strategy for Transformer-based Speech SSL Models with Attention Map Reusing and Masking Distillation. (arXiv:2305.11685v1 [eess.AS])

    [http://arxiv.org/abs/2305.11685](http://arxiv.org/abs/2305.11685)

    本研究提出了一种基于Transformer的语音自监督学习模型的通用压缩策略，通过重用注意力映射和蒸馏屏蔽来提高学生模型的语音表示质量，实现了较低的错误率。

    

    基于Transformer的语音自监督学习模型在各种语音处理任务中表现出惊人的性能。然而，语音 SSL 模型中庞大的参数数量需要压缩成更紧凑的模型，以便在学术界或小公司中更广泛地使用。本研究建议重用Transformer层之间的注意力映射，因此可以删除键和查询参数，同时保留层数。此外，我们提出了一种新的蒸馏策略，以提高学生模型的语音表示质量。我们扩展了蒸馏损失，利用遮罩和未遮罩的语音帧，充分利用教师模型的高质量表示。我们的通用压缩策略产生的学生模型在SUPERB基准测试中实现了7.72%的音素误差率（PER）和9.96%的单词错误率（WER）。

    Transformer-based speech self-supervised learning (SSL) models, such as HuBERT, show surprising performance in various speech processing tasks. However, huge number of parameters in speech SSL models necessitate the compression to a more compact model for wider usage in academia or small companies. In this study, we suggest to reuse attention maps across the Transformer layers, so as to remove key and query parameters while retaining the number of layers. Furthermore, we propose a novel masking distillation strategy to improve the student model's speech representation quality. We extend the distillation loss to utilize both masked and unmasked speech frames to fully leverage the teacher model's high-quality representation. Our universal compression strategy yields the student model that achieves phoneme error rate (PER) of 7.72% and word error rate (WER) of 9.96% on the SUPERB benchmark.
    
[^35]: 基于语音的灵感事件感知：深度学习与语言方法的比较

    Sensing of inspiration events from speech: comparison of deep learning and linguistic methods. (arXiv:2305.11683v1 [cs.SD])

    [http://arxiv.org/abs/2305.11683](http://arxiv.org/abs/2305.11683)

    本研究比较了使用深度学习和基于语言的方法来感知胸带传感器数据中的吸气事件，结果表明VRB方法优于传统方法。同时该研究还发现朗读和自发语言内容都具有显着的非语法性呼吸，为开发VRB方法提供了新的见解。

    

    呼吸胸带传感器可以用于测量呼吸率和其他呼吸健康参数。虚拟呼吸胸带（VRB）算法可以从语音音频估算出胸带传感器波形。本文比较了使用一种新颖的神经网络VRB算法和基于时间对齐语言内容的检测来自胸带传感器数据的吸气事件（IE）的能力。结果表明，VRB方法优于单词暂停检测或语法内容分割。方法的比较显示，朗读和自发语言内容都具有显着的非语法性呼吸，即呼吸事件不与语言中的语法正确的位置对齐。该研究为VRB方法的开发提供了新的见解，并增加了对语音呼吸行为的普遍理解。此外，演示了一种连续呼吸波形的重建新VRB方法VRBOLA。

    Respiratory chest belt sensor can be used to measure the respiratory rate and other respiratory health parameters. Virtual Respiratory Belt, VRB, algorithms estimate the belt sensor waveform from speech audio. In this paper we compare the detection of inspiration events (IE) from respiratory belt sensor data using a novel neural VRB algorithm and the detections based on time-aligned linguistic content. The results show the superiority of the VRB method over word pause detection or grammatical content segmentation. The comparison of the methods show that both read and spontaneous speech content has a significant amount of ungrammatical breathing, that is, breathing events that are not aligned with grammatically appropriate places in language. This study gives new insights into the development of VRB methods and adds to the general understanding of speech breathing behavior. Moreover, a new VRB method, VRBOLA, for the reconstruction of the continuous breathing waveform is demonstrated.
    
[^36]: 通过多语言一致性评估任务理解：ChatGPT案例研究

    Evaluating task understanding through multilingual consistency: A ChatGPT case study. (arXiv:2305.11662v1 [cs.CL])

    [http://arxiv.org/abs/2305.11662](http://arxiv.org/abs/2305.11662)

    本文提出了一种新的评估大型语言模型理解能力的范例，通过评估模型自身生成的不同意义之间的一致性，探讨了多语言自我一致性作为模型理解的检验方法，同时证明了ChatGPT在多语言一致性方面的优秀性能。

    

    随着大型语言模型（LLM）功能的惊人提升，创建未来可持续的评估集以评估它们的理解变得越来越具有挑战性。本文提出了一种新的评估LLM的范例，该范例利用了正确的世界理解应该在相同含义的不同（弗雷格）意义上保持一致的思想。因此，我们不是通过正确性来衡量理解，而是通过评估模型自身生成的多个意义之间的一致性来衡量。我们通过实例化一个测试展示了我们的方法，其中不同的意义是不同的语言，因此将多语言自我一致性作为模型理解的检验并同时解决多语言的重要主题。我们以最新版本的ChatGPT为我们的研究对象，在三种不同语言中评估两个不同任务的多语言一致性。我们证明了ChatGPT在多语言一致性方面的优秀性能。

    At the staggering pace with which the capabilities of large language models (LLMs) are increasing, creating future-proof evaluation sets to assess their understanding becomes more and more challenging. In this paper, we propose a novel paradigm for evaluating LLMs which leverages the idea that correct world understanding should be consistent across different (Fregean) senses of the same meaning. Accordingly, we measure understanding not in terms of correctness but by evaluating consistency across multiple senses that are generated by the model itself. We showcase our approach by instantiating a test where the different senses are different languages, hence using multilingual self-consistency as a litmus test for the model's understanding and simultaneously addressing the important topic of multilingualism. Taking one of the latest versions of ChatGPT as our object of study, we evaluate multilingual consistency for two different tasks across three different languages. We show that its m
    
[^37]: LLM-Pruner: 关于大型语言模型结构修剪的研究

    LLM-Pruner: On the Structural Pruning of Large Language Models. (arXiv:2305.11627v1 [cs.CL])

    [http://arxiv.org/abs/2305.11627](http://arxiv.org/abs/2305.11627)

    本文提出了一种方法，名为LLM-Pruner，采用结构修剪的方式在保留大多数功能的同时，压缩LLM的结构，以减少LLM在部署、推理和训练阶段中的大小和复杂度。

    

    大型语言模型(LLMs)展示出在语言理解和生成方面令人惊讶的能力。然而，这种能力通常伴随着巨大的模型大小，这在部署、推理和训练阶段都存在显著挑战。我们以任务无关的方式探索了LLM的压缩方法，旨在保留原始LLM的多任务解决和语言生成能力。我们的方法采用结构修剪，在梯度信息的支持下选择性地移除非关键的耦合结构，最大限度地保留了大多数LLM的功能。

    Large language models (LLMs) have shown remarkable capabilities in language understanding and generation. However, such impressive capability typically comes with a substantial model size, which presents significant challenges in both the deployment, inference, and training stages. With LLM being a general-purpose task solver, we explore its compression in a task-agnostic manner, which aims to preserve the multi-task solving and language generation ability of the original LLM. One challenge to achieving this is the enormous size of the training corpus of LLM, which makes both data transfer and model post-training over-burdensome. Thus, we tackle the compression of LLMs within the bound of two constraints: being task-agnostic and minimizing the reliance on the original training dataset. Our method, named LLM-Pruner, adopts structural pruning that selectively removes non-critical coupled structures based on gradient information, maximally preserving the majority of the LLM's functionalit
    
[^38]: CCT-Code：面向多语言克隆检测和代码搜索的跨语言一致性训练

    CCT-Code: Cross-Consistency Training for Multilingual Clone Detection and Code Search. (arXiv:2305.11626v1 [cs.CL])

    [http://arxiv.org/abs/2305.11626](http://arxiv.org/abs/2305.11626)

    本研究提出了多语言克隆检测问题，并从CodeForces数据集开发了一个新的基准数据集XCD。我们使用跨语言一致性训练（CCT）方法训练了语言模型，得到了具有新颖性能的CCT-LM模型，超过了现有的方法。

    

    本文考虑源代码的克隆检测和信息检索问题，这两个问题对于任何编程语言都非常重要。我们提出了多语言克隆检测问题，并从CodeForces提交数据集产生了一个新的基准数据集XCD。此外，我们提出了一种新型的训练方法，称为跨语言一致性训练（CCT），用于在不同的编程语言中训练语言模型，进而得到基于CCT-LM 模型。该模型继承了GraphCodeBERT并用CCT微调，达到了95.67\% MAP和47.18\% MRR的性能，成功创造了新的最优结果。

    We consider the clone detection and information retrieval problems for source code, well-known tasks important for any programming language. Although it is also an important and interesting problem to find code snippets that operate identically but are written in different programming languages, to the best of our knowledge multilingual clone detection has not been studied in literature. In this work, we formulate the multilingual clone detection problem and present XCD, a new benchmark dataset produced from the CodeForces submissions dataset. Moreover, we present a novel training procedure, called cross-consistency training (CCT), that we apply to train language models on source code in different programming languages. The resulting CCT-LM model, initialized with GraphCodeBERT and fine-tuned with CCT, achieves new state of the art, outperforming existing approaches on the POJ-104 clone detection benchmark with 95.67\% MAP and AdvTest code search benchmark with 47.18\% MRR; it also sho
    
[^39]: 代码搜索：一个新的SearchBySnippet数据集和SnippeR检索模型用于按代码片段搜索

    Searching by Code: a New SearchBySnippet Dataset and SnippeR Retrieval Model for Searching by Code Snippets. (arXiv:2305.11625v1 [cs.CL])

    [http://arxiv.org/abs/2305.11625](http://arxiv.org/abs/2305.11625)

    本研究针对按代码片段搜索的问题，提出了一个新的基于StackOverflow数据的SearchBySnippet数据集，并开发了一个单编码器模型SnippeR，它在该数据集上具有优异的性能。

    

    代码搜索是一个重要的任务，在近年来得到了很多发展。然而，以前的尝试主要考虑通过文本查询搜索代码的问题。我们认为，使用代码片段（可能伴随着回溯）作为查询，并寻找具有修复错误指令和代码示例的答案是一个自然的用例，而现有方法并未涵盖此类情况。此外，现有数据集使用从代码中提取的注释而不是全文描述作为文本，使它们不适用于这种用例。我们提出了一个基于StackOverflow数据实现搜索BySnippet用例的新SearchBySnippet数据集; 在这种情况下，现有体系结构即使在微调之后也不能与最简单的BM25基线相提并论。我们提出了一个新的单编码器模型SnippeR，它在SearchBySnippet数据集上优于几个强基线，结果为0.451 Recall@10; 我们建议将SearchBySnippet数据集和SnippeR作为新的重要基准数据集和模型来推广代码搜索。

    Code search is an important task that has seen many developments in recent years. However, previous attempts have mostly considered the problem of searching for code by a text query. We argue that using a code snippet (and possibly an associated traceback) as a query and looking for answers with bugfixing instructions and code samples is a natural use case that is not covered by existing approaches. Moreover, existing datasets use comments extracted from code rather than full-text descriptions as text, making them unsuitable for this use case. We present a new SearchBySnippet dataset implementing the search-by-code use case based on StackOverflow data; it turns out that in this setting, existing architectures fall short of the simplest BM25 baseline even after fine-tuning. We present a new single encoder model SnippeR that outperforms several strong baselines on the SearchBySnippet dataset with a result of 0.451 Recall@10; we propose the SearchBySnippet dataset and SnippeR as a new imp
    
[^40]: 可归因且可扩展的意见摘要方法研究

    Attributable and Scalable Opinion Summarization. (arXiv:2305.11603v1 [cs.CL])

    [http://arxiv.org/abs/2305.11603](http://arxiv.org/abs/2305.11603)

    本文提出了一个可归因且可扩展的无监督意见摘要方法，可以通过编码评论句子为分层潜空间来确定常见意见，并且可以生成抽象或提取的摘要。该方法在几种基线方法中表现最佳，并且允许生成特定方面的摘要。

    

    本文提出了一种无监督的意见摘要方法，将顾客评论中的句子编码为分层离散潜空间，然后根据其编码的频率确定常见意见。我们可以通过解码这些频繁的编码来生成抽象总结，并通过选择分配给相同频繁编码的句子来生成提取总结。由于模型将生成总结所用的句子识别为摘要过程的一部分，因此我们的方法可归因。我们的方法在潜空间中执行聚合而不是在长序列中执行聚合，因此可以轻松扩展到许多输入评论。此外，我们还展示了我们的方法可以通过将模型限制为与所需方面（例如位置或食品）相对应的编码空间部分来生成特定方面的摘要，具有一定的控制度。对来自不同领域的两个数据集的自动和人工评估表明，我们的方法优于几种竞争基线方法。

    We propose a method for unsupervised opinion summarization that encodes sentences from customer reviews into a hierarchical discrete latent space, then identifies common opinions based on the frequency of their encodings. We are able to generate both abstractive summaries by decoding these frequent encodings, and extractive summaries by selecting the sentences assigned to the same frequent encodings. Our method is attributable, because the model identifies sentences used to generate the summary as part of the summarization process. It scales easily to many hundreds of input reviews, because aggregation is performed in the latent space rather than over long sequences of tokens. We also demonstrate that our appraoch enables a degree of control, generating aspect-specific summaries by restricting the model to parts of the encoding space that correspond to desired aspects (e.g., location or food). Automatic and human evaluation on two datasets from different domains demonstrates that our m
    
[^41]: 内省技巧：上下文决策制定下的大型语言模型

    Introspective Tips: Large Language Model for In-Context Decision Making. (arXiv:2305.11598v1 [cs.AI])

    [http://arxiv.org/abs/2305.11598](http://arxiv.org/abs/2305.11598)

    本文研究了内省技巧对大型语言模型在上下文决策制定中的应用，通过内省轨迹生成简洁有价值的提示，不调整LLM参数就能提高代理的性能。

    

    大型语言模型（LLMs）的出现在自然语言处理方面产生了巨大影响，在各种任务中展示出卓越的结果。本研究利用“内省技巧”来促进LLMs在自我优化决策制定方面发挥作用。通过内省地检查轨迹，LLM生成简洁而有价值的提示来改善其策略。我们的方法通过考虑三种重要情境来提高代理在少样本和零样本学习情况下的性能：从代理过去的经验中学习、整合专家演示和在不同游戏之间进行泛化。重要的是，我们在不调整LLM参数的情况下，通过调整提示来从这三种情况中概括见解来实现这些改进。我们的框架不仅支持而且强调了在上下文决策制定中采用LLM的优势。在TextWorld中涉及超过100个游戏的实验表明了我们所提出的方法的卓越性能。

    The emergence of large language models (LLMs) has substantially influenced natural language processing, demonstrating exceptional results across various tasks. In this study, we employ ``Introspective Tips" to facilitate LLMs in self-optimizing their decision-making. By introspectively examining trajectories, LLM refines its policy by generating succinct and valuable tips. Our method enhances the agent's performance in both few-shot and zero-shot learning situations by considering three essential scenarios: learning from the agent's past experiences, integrating expert demonstrations, and generalizing across diverse games. Importantly, we accomplish these improvements without fine-tuning the LLM parameters; rather, we adjust the prompt to generalize insights from the three aforementioned situations. Our framework not only supports but also emphasizes the advantage of employing LLM in in-contxt decision-making. Experiments involving over 100 games in TextWorld illustrate the superior pe
    
[^42]: 透过虚假相关性的视角缓解后门污染攻击

    Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation. (arXiv:2305.11596v1 [cs.CL])

    [http://arxiv.org/abs/2305.11596](http://arxiv.org/abs/2305.11596)

    本文提出了一种缓解后门污染攻击的方法，通过减轻文本特征和分类标签之间的虚假相关性来防御攻击，可以显著降低所有后门攻击的成功率，并在插入式攻击的情况下提供了几乎完美的防御。

    

    现代NLP模型通常在大型不可信数据集上进行训练，这提高了恶意对手破坏模型行为的可能性。本文认为，后门污染攻击展示了简单文本特征和分类标签之间的虚假相关性，因此提出了减轻虚假相关性的方法作为防御手段。我们的实证研究表明，恶意触发器与其目标标签高度相关，因此这些相关性与良性特征得分相比极易区分，并可用于过滤可能有问题的实例。与几种现有的防御措施相比，我们的防御方法显著降低了所有后门攻击的成功率，并且在插入式攻击的情况下，我们的方法提供了几乎完美的防御。

    Modern NLP models are often trained over large untrusted datasets, raising the potential for a malicious adversary to compromise model behaviour. For instance, backdoors can be implanted through crafting training instances with a specific textual trigger and a target label. This paper posits that backdoor poisoning attacks exhibit spurious correlation between simple text features and classification labels, and accordingly, proposes methods for mitigating spurious correlation as means of defence. Our empirical study reveals that the malicious triggers are highly correlated to their target labels; therefore such correlations are extremely distinguishable compared to those scores of benign features, and can be used to filter out potentially problematic instances. Compared with several existing defences, our defence method significantly reduces attack success rates across backdoor attacks, and in the case of insertion based attacks, our method provides a near-perfect defence.
    
[^43]: 大型语言模型中的内部一致性问题研究：通过辩论进行深入分析

    Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate. (arXiv:2305.11595v1 [cs.CL])

    [http://arxiv.org/abs/2305.11595](http://arxiv.org/abs/2305.11595)

    本文提出了通过辩论探究大型语言模型之间的内部一致性问题，实验证明通过严格的辩论框架可以提高模型性能和常识知识的结构化学习。

    

    大型语言模型LLMs在各种自然语言处理NLP任务中展现出了惊人的零样本或少量样本通识推理性能。然而，尽管它们拥有强大的常识推理能力，但它们仍然存在各种不一致问题。本研究提出探索两个或多个LLMs之间的内部一致性问题，这对于不同和精确的决策过程至关重要。通过严格的辩论框架，在7个常识推理数据集上进行了广泛的实验。LLMs不仅通过妥协和反驳变得更具内部一致性，而且还实现了更高的性能和常识知识的结构化学习。

    Large language models (LLMs) have demonstrated impressive zero-shot or few-shot commonsense reasoning performance on various natural language processing (NLP) tasks. However, despite their strong commonsense reasoning abilities, LLMs still exhibit various kinds of inconsistency problems. While previous researches mainly focused on the self-consistency within a single LLM, we propose to explore the inter-consistency issue between two or more LLMs, which is critical for diverse and precise decision-making processes. Since the LLMs possess human-like intelligence after instruction tuning and reinforcement learning with human feedback (RLHF), we design a formal debate framework to delve into the inter-consistency problem among LLMs with three-stage debate: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on 7 commonsense reasoning datasets, LLMs not only become more inter-consistent by compromising and refuting but also achieve higher performance and str
    
[^44]: IKDSumm：将关键词融入BERT用于灾难推文摘要

    IKDSumm: Incorporating Key-phrases into BERT for extractive Disaster Tweet Summarization. (arXiv:2305.11592v1 [cs.CL])

    [http://arxiv.org/abs/2305.11592](http://arxiv.org/abs/2305.11592)

    IKDSumm是一个特定于灾难事件的推文摘要框架，利用领域特定知识将关键词融合到BERT中，从而在不需要大量标记信息的情况下提高了摘要质量。

    

    在灾难事件中，社交媒体平台（如Twitter）是最有价值的信息来源之一。因此，人道主义组织、政府机构和志愿者依靠这些信息（即推文）的摘要来进行有效的灾难管理。尽管存在一些现有的监督和非监督方法来实现自动推文摘要，但这些方法要么需要大量的标记信息，要么不包含有关灾难的特定领域知识。最近的灾难摘要方法提出使用基于BERT的模型来提高摘要质量。然而，为了进一步提高性能，我们引入了领域特定知识的利用，而无需进行人力努力来理解推文的重要性（突出性），这进一步有助于摘要的创建和提高摘要质量。在本文中，我们提出了一个特定于灾难的推文摘要框架IKDSumm，它用于：

    Online social media platforms, such as Twitter, are one of the most valuable sources of information during disaster events. Therefore, humanitarian organizations, government agencies, and volunteers rely on a summary of this information, i.e., tweets, for effective disaster management. Although there are several existing supervised and unsupervised approaches for automated tweet summary approaches, these approaches either require extensive labeled information or do not incorporate specific domain knowledge of disasters. Additionally, the most recent approaches to disaster summarization have proposed BERT-based models to enhance the summary quality. However, for further improved performance, we introduce the utilization of domain-specific knowledge without any human efforts to understand the importance (salience) of a tweet which further aids in summary creation and improves summary quality. In this paper, we propose a disaster-specific tweet summarization framework, IKDSumm, which init
    
[^45]: 带有显式跨模态对齐的语音文本对话预训练用于口语对话理解

    Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment. (arXiv:2305.11579v1 [cs.CL])

    [http://arxiv.org/abs/2305.11579](http://arxiv.org/abs/2305.11579)

    本文提出了SPECTRA语音文本对话预训练模型，应用了新的时间位置预测任务来捕捉语音文本对齐，同时将回答选择任务推广到服务于口语对话理解，用于丰富话语表示。

    

    最近，语音文本预训练方法在许多语音和自然语言处理任务中展现出了惊人的成功。然而，大多数先前的预训练模型通常针对一个或两个特定任务进行了定制，但未能征服各种语音文本任务。此外，现有的语音文本预训练方法未能探索对话中的情境信息以丰富话语表示。在本文中，我们提出了具有显式跨模态对齐的语音文本对话预训练模型SPECTRA，这是第一个语音文本对话预训练模型。具体而言，为了考虑语音模态的时间性，我们设计了一项新的时间位置预测任务来捕捉语音文本对齐。这种预训练任务旨在预测相应语音波形中每个文本单词的开始和结束时间。此外，为了学习口语对话的特征，我们将回答选择任务推广到服务于口语对话理解。

    Recently, speech-text pre-training methods have shown remarkable success in many speech and natural language processing tasks. However, most previous pre-trained models are usually tailored for one or two specific tasks, but fail to conquer a wide range of speech-text tasks. In addition, existing speech-text pre-training methods fail to explore the contextual information within a dialogue to enrich utterance representations. In this paper, we propose Speech-text dialog Pre-training for spoken dialog understanding with ExpliCiT cRoss-Modal Alignment (SPECTRA), which is the first-ever speech-text dialog pre-training model. Concretely, to consider the temporality of speech modality, we design a novel temporal position prediction task to capture the speech-text alignment. This pre-training task aims to predict the start and end time of each textual word in the corresponding speech waveform. In addition, to learn the characteristics of spoken dialogs, we generalize a response selection task
    
[^46]: 语言通用音素编码器用于低资源语音识别

    Language-universal phonetic encoder for low-resource speech recognition. (arXiv:2305.11576v1 [eess.AS])

    [http://arxiv.org/abs/2305.11576](http://arxiv.org/abs/2305.11576)

    本文利用以国际音标为基础的语言通用音素模型，为低资源语音识别提供了有效的改进方法，表现优于基线单语言模型和大多数最先进的工作。

    

    多语言训练对于提高低资源语音识别有效，部分原因在于语音表示在不同语言间共享。在端到端语音识别系统中，字素通常被用作基本建模单元，然而字素可能不适用于多语言音素共享。本文中，我们利用以国际音标（IPA）为基础的语言通用音素模型来提高低资源语音识别性能，这是首次应用于注意力编码器-解码器体系架构中。我们提出了一种适应性方法，采用音标IPA模型进一步改进了所提出的方法，以应对极度低资源语言。在开源MLS语料库和内部数据库上进行的实验表明，我们的方法优于基线单语言模型和大多数最先进的工作。我们的主要方法和适应性方法适用于极度低资源语言，甚至包括领域和语言不匹配的情况。

    Multilingual training is effective in improving low-resource ASR, which may partially be explained by phonetic representation sharing between languages. In end-to-end (E2E) ASR systems, graphemes are often used as basic modeling units, however graphemes may not be ideal for multilingual phonetic sharing. In this paper, we leverage International Phonetic Alphabet (IPA) based language-universal phonetic model to improve low-resource ASR performances, for the first time within the attention encoder-decoder architecture. We propose an adaptation method on the phonetic IPA model to further improve the proposed approach on extreme low-resource languages. Experiments carried out on the open-source MLS corpus and our internal databases show our approach outperforms baseline monolingual models and most state-of-the-art works. Our main approach and adaptation are effective on extremely low-resource languages, even within domain- and language-mismatched scenarios.
    
[^47]: 语言通用的国际音标表示在低资源语音识别多语种训练中的应用

    Language-Universal Phonetic Representation in Multilingual Speech Pretraining for Low-Resource Speech Recognition. (arXiv:2305.11569v1 [eess.AS])

    [http://arxiv.org/abs/2305.11569](http://arxiv.org/abs/2305.11569)

    本文提出一种利用国际音标多语种模型为低资源语音识别任务创造帧级伪标签的方法，并以此指导隐藏单元BERT（HuBERT）的语音预训练。该方法在多语言语音（MLS）语料库中实验表明，相对于标准HuBERT，在所有目标语言上性能提高，且能节省大量受监督训练时间。

    

    本文将多语言训练和自监督学习的思想融合起来，通过利用国际音标（IPA）多语种模型为无标记语音创建帧级伪标签，并以语音预训练为基础，以国际音标为依据指导隐藏单元BERT（HuBERT）的语音预训练，从而提高低资源ASR的性能。实验证明，该方法在所有目标语言上均比标准HuBERT表现更好。与标准HuBERT相比，该方法在4种语言中有3种表现更好，并能够最多节省1.5k小时（75%）的受监督训练数据。 相对于XLSR-53和基于重新训练的多语言方法，本方法在完全和限制微调数据的情况下都表现更好。

    We improve low-resource ASR by integrating the ideas of multilingual training and self-supervised learning. Concretely, we leverage an International Phonetic Alphabet (IPA) multilingual model to create frame-level pseudo labels for unlabeled speech, and use these pseudo labels to guide hidden-unit BERT (HuBERT) based speech pretraining in a phonetically-informed manner. The experiments on the Multilingual Speech (MLS) Corpus show that the proposed approach consistently outperforms the standard HuBERT on all the target languages. Moreover, on 3 of the 4 languages, comparing to the standard HuBERT, the approach performs better, meanwhile is able to save supervised training data by 1.5k hours (75%) at most. Our approach outperforms most of the state of the arts, with much less pretraining data in terms of hours and language diversity. Compared to XLSR-53 and a retraining based multilingual method, our approach performs better with full and limited finetuning data scenarios.
    
[^48]: 解耦参数中的知识：可插拔语言模型的新方法

    Decouple knowledge from paramters for plug-and-play language modeling. (arXiv:2305.11564v1 [cs.CL])

    [http://arxiv.org/abs/2305.11564](http://arxiv.org/abs/2305.11564)

    本文介绍了一种新的插件式预训练模型，其与模型参数中的知识存储分离，采用可编辑和可扩展的键值存储器，通过DPM中的知识检索以可解释的方式利用知识。

    

    预训练语言模型（PLM）在各种NLP任务中取得了令人印象深刻的成果。 揭示了这些模型成功的关键因素之一是这些模型的参数在预训练期间隐含地学习了各种知识。 然而，将知识隐含在模型参数中具有两个基本缺点。 首先，在模型训练后，无法编辑或扩展知识，特别是在知识不断发展的情况下，这是一个严重的问题。 其次，它缺乏可解释性并阻止人们了解PLM在某个问题上所需的哪些知识。 在本文中，我们介绍PlugLM，这是一种具有可微分插件存储器（DPM）的预训练模型。 关键的直觉是使用可编辑和可扩展的键值存储器将知识存储与模型参数分离，并通过DPM中的知识检索以可解释的方式利用知识。为了证明这种设计选择的合理性，我们在三个设置中进行评估，这些设置需要各种形式的知识：（1）领域适应，（2）未见实体合并，以及（3）在不遗忘旧任务的情况下适应新任务。

    Pre-trained language models(PLM) have made impressive results in various NLP tasks. It has been revealed that one of the key factors to their success is the parameters of these models implicitly learn all kinds of knowledge during pre-training. However, encoding knowledge implicitly in the model parameters has two fundamental drawbacks. First, the knowledge is neither editable nor scalable once the model is trained, which is especially problematic in that knowledge is consistently evolving. Second, it lacks interpretability and prevents humans from understanding which knowledge PLM requires for a certain problem. In this paper, we introduce PlugLM, a pre-training model with differentiable plug-in memory(DPM). The key intuition is to decouple the knowledge storage from model parameters with an editable and scalable key-value memory and leverage knowledge in an explainable manner by knowledge retrieval in the DPM. To justify this design choice, we conduct evaluations in three settings in
    
[^49]: 在神经转录器中使用空白正则化CTC解决帧跳过问题

    Blank-regularized CTC for Frame Skipping in Neural Transducer. (arXiv:2305.11558v1 [eess.AS])

    [http://arxiv.org/abs/2305.11558](http://arxiv.org/abs/2305.11558)

    本文提出两种新的正则化方法，通过限制CTC中的非空白符号的自环，明确地鼓励更多的空白符号，并成功将神经转录器的推理加速4倍，而不降低性能。

    

    神经转录器和连接时序分类（CTC）都是常见的端到端语音识别系统。由于其基于帧同步设计，引入了空白符号以解决声学帧和输出令牌之间的长度不匹配，这可能带来冗余计算。先前的研究通过丢弃由联合训练的CTC预测的空白符号，来加速神经转录器的训练和推理。然而，联合训练的CTC不能保证最大化空白符号的比例。本文提出了两种新的正则化方法，通过限制CTC中的非空白符号的自环，明确地鼓励更多的空白符号。有趣的是，神经转录器的帧降低率可以接近理论边界。在LibriSpeech语料库上的实验表明，我们的方法可以在不降低性能的情况下将神经转录器的推理加速4倍。

    Neural Transducer and connectionist temporal classification (CTC) are popular end-to-end automatic speech recognition systems. Due to their frame-synchronous design, blank symbols are introduced to address the length mismatch between acoustic frames and output tokens, which might bring redundant computation. Previous studies managed to accelerate the training and inference of neural Transducers by discarding frames based on the blank symbols predicted by a co-trained CTC. However, there is no guarantee that the co-trained CTC can maximize the ratio of blank symbols. This paper proposes two novel regularization methods to explicitly encourage more blanks by constraining the self-loop of non-blank symbols in the CTC. It is interesting to find that the frame reduction ratio of the neural Transducer can approach the theoretical boundary. Experiments on LibriSpeech corpus show that our proposed method accelerates the inference of neural Transducer by 4 times without sacrificing performance.
    
[^50]: ToolkenGPT：通过工具嵌入扩充冻结语言模型

    ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings. (arXiv:2305.11554v1 [cs.CL])

    [http://arxiv.org/abs/2305.11554](http://arxiv.org/abs/2305.11554)

    本论文提出了一种名为ToolkenGPT的方法，将大型语言模型（LLMs）与外部工具相结合，引入了toolken的概念，利用tool embeddings实现无缝交互，同时在各种下游任务上展示出了良好的效果。

    

    将大型语言模型与外部工具结合起来解决复杂问题已成为一种有前途的方法。然而，传统方法需要用工具演示数据对LLM进行微调，既费时又受限于预定义的工具集。最近的上下文学习范例缓解了这些问题，但是有限的上下文长度只允许演示几次，导致对工具的理解不够充分。此外，当有大量工具可供选择时，上下文学习可能完全无法正常工作。在本文中，我们提出了一种$\textbf{ToolkenGPT}$的替代方法，将两种方法的优点结合起来。我们的方法将每个$\underline{工具}$表示为一个$\underline{token}$（$\textit{toolken}$），并为其学习一个嵌入，使得工具调用与生成常规单词标记的方式相同。一旦触发了toolken，LLM被提示完成工具执行所需的参数。ToolkenGPT提供了以下贡献：1）引入了toolken的概念，以扩充LLM与外部工具的交互，2）提出了一种新的学习范例，利用tool embeddings实现无缝交互，3）在各种下游任务上展示了我们方法的有效性。

    Augmenting large language models (LLMs) with external tools has emerged as a promising approach to solving complex problems. However, traditional methods, which finetune LLMs with tool demonstration data, can be both costly and restricted to a predefined set of tools. Recent in-context learning paradigm alleviates these issues, but the limited context length only allows for a few shots of demonstrations, leading to suboptimal understandings of the tools. Moreover, when there are numerous tools to choose from, in-context learning could completely fail to work. In this paper, we propose an alternative approach, $\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our approach represents each $\underline{tool}$ as a to$\underline{ken}$ ($\textit{toolken}$) and learns an embedding for it, enabling tool calls in the same way as generating a regular word token. Once a toolken is triggered, the LLM is prompted to complete arguments for the tool to execute. ToolkenGPT offers the f
    
[^51]: 基于标准化互信息的无监督科技论文摘要分割

    Unsupervised Scientific Abstract Segmentation with Normalized Mutual Information. (arXiv:2305.11553v1 [cs.CL])

    [http://arxiv.org/abs/2305.11553](http://arxiv.org/abs/2305.11553)

    本论文提出了一种基于标准化互信息的无监督科技论文摘要分割方法，其中GreedyCAS在非结构化摘要和结构化摘要中均表现出色。

    

    科技论文摘要由前提和结论组成。结构化摘要明确突出结论句子，而非结构化摘要则可能在不确定位置有结论句子，这种隐含的结论位置使得科技论文摘要的自动分割成为一项具有挑战性的任务。本研究通过实证探索使用标准化互信息（NMI）进行摘要分割。我们将每个摘要视为一个循环的句子，并通过贪婪地优化前提和结论之间的NMI分数来放置分割边界。在非结构化摘要中，我们提出的无监督方法GreedyCAS在所有评估指标中表现最佳。在结构化摘要中，GreedyCAS通过$P_k$的各项基准测试中表现更好。NMI与我们的评估指标的强相关性揭示了NMI在摘要分割中的有效性。

    The abstracts of scientific papers consist of premises and conclusions. Structured abstracts explicitly highlight the conclusion sentences, whereas non-structured abstracts may have conclusion sentences at uncertain positions. This implicit nature of conclusion positions makes the automatic segmentation of scientific abstracts into premises and conclusions a challenging task. In this work, we empirically explore using Normalized Mutual Information (NMI) for abstract segmentation. We consider each abstract as a recurrent cycle of sentences and place segmentation boundaries by greedily optimizing the NMI score between premises and conclusions. On non-structured abstracts, our proposed unsupervised approach GreedyCAS achieves the best performance across all evaluation metrics; on structured abstracts, GreedyCAS outperforms all baseline methods measured by $P_k$. The strong correlation of NMI to our evaluation metrics reveals the effectiveness of NMI for abstract segmentation.
    
[^52]: 透过表征镜头看待多语言机器翻译中的知识转移

    Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens. (arXiv:2305.11550v1 [cs.CL])

    [http://arxiv.org/abs/2305.11550](http://arxiv.org/abs/2305.11550)

    该论文引入了表征转移潜力（RTP）来衡量多语言神经机器翻译中的知识转移，发现多路并行重叠是关键特征，提出了一种新的训练方案，鼓励表征在语言之间更具不变性，并在多个数据和模型设置中提高了低资源和中资源语言的翻译质量。

    

    我们认为，仅仅依靠翻译质量度量多语言神经机器翻译中的知识转移是不够的。为了支持这一观点，我们引入了表征转移潜力（RTP），它测量语言之间的表征相似度。我们展示了RTP可以测量正向和负向转移（干扰），并发现RTP与翻译质量变化强相关，表明确实存在转移。此外，我们研究了与转移相关的数据和语言特征，并发现多路并行重叠是一个重要但鲜有探索的特征。基于此，我们开发了一种新的训练方案，该方案使用辅助相似性损失，通过利用多路并行数据，鼓励表征在语言之间更具不变性。我们表明，我们的方法在多个数据和模型设置中提高了低资源和中资源语言的翻译质量。

    We argue that translation quality alone is not a sufficient metric for measuring knowledge transfer in multilingual neural machine translation. To support this claim, we introduce Representational Transfer Potential (RTP), which measures representational similarities between languages. We show that RTP can measure both positive and negative transfer (interference), and find that RTP is strongly correlated with changes in translation quality, indicating that transfer does occur. Furthermore, we investigate data and language characteristics that are relevant for transfer, and find that multi-parallel overlap is an important yet under-explored feature. Based on this, we develop a novel training scheme, which uses an auxiliary similarity loss that encourages representations to be more invariant across languages by taking advantage of multi-parallel data. We show that our method yields increased translation quality for low- and mid-resource languages across multiple data and model setups.
    
[^53]: 构建基于联想知识关系的词-上下文耦合空间用于可解释化语言建模

    Constructing Word-Context-Coupled Space Aligned with Associative Knowledge Relations for Interpretable Language Modeling. (arXiv:2305.11543v1 [cs.CL])

    [http://arxiv.org/abs/2305.11543](http://arxiv.org/abs/2305.11543)

    本文提出了一种可解释的语言建模方法，通过构建词-上下文耦合空间，并引入联想知识网络和上下文相对距离作为语义特征，实现了语言建模可解释性的提高。

    

    作为当前自然语言处理方法的基础，预训练语言模型已经取得了出色的表现。然而，预训练语言模型中深度神经网络的黑箱结构严重限制了语言建模过程的可解释性。本文通过重新审视深度神经表示和语言建模的语义逻辑之间的耦合要求，引入了词-上下文耦合空间(W2CSpace)，通过介绍可解释的统计逻辑和不可解释的神经表示之间的对齐处理来实现。此外，还设计了一种聚类过程来连接词级和上下文级语义。具体来说，在对齐词级语义的过程中引入了可解释的统计逻辑的联想知识网络(AKN)。此外，上下文相对距离被用作下游分类器的语义特征，这与当前的非解释性方法非常不同。

    As the foundation of current natural language processing methods, pre-trained language model has achieved excellent performance. However, the black-box structure of the deep neural network in pre-trained language models seriously limits the interpretability of the language modeling process. After revisiting the coupled requirement of deep neural representation and semantics logic of language modeling, a Word-Context-Coupled Space (W2CSpace) is proposed by introducing the alignment processing between uninterpretable neural representation and interpretable statistical logic. Moreover, a clustering process is also designed to connect the word- and context-level semantics. Specifically, an associative knowledge network (AKN), considered interpretable statistical logic, is introduced in the alignment process for word-level semantics. Furthermore, the context-relative distance is employed as the semantic feature for the downstream classifier, which is greatly different from the current unint
    
[^54]: 提升大规模语言模型在工业领域特定问答中的表现

    Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering. (arXiv:2305.11541v1 [cs.CL])

    [http://arxiv.org/abs/2305.11541](http://arxiv.org/abs/2305.11541)

    本文提供了一个行业云特定QA数据集 MSQA，该数据集可用于评估旨在提高大规模语言模型特定领域能力的方法。本文还提出了一种新的模型交互范式，可以使大规模语言模型在其不擅长的特定任务上取得更好的性能。

    

    大规模语言模型（LLM）在开放领域任务中获得了广泛应用和卓越的成果，但其在真实的工业特定场景中的表现通常很平庸，因为它缺乏特定领域的知识。这个问题引起了广泛关注，但相关基准测试很少。本文提供了一个名为MSQA的基准问答（QA）数据集，该数据集涉及Microsoft产品和客户遇到的IT技术问题。这个数据集包含了行业云的特定QA知识，这对于一般的LLM来说是不可用的，因此非常适合评估旨在提高LLM特定领域能力的方法。此外，我们提出了一种新的模型交互范式，可以使LLM在其不擅长的特定任务上取得更好的性能。广泛的实验表明，遵循我们的模型融合框架的方法比使用检索方法的常用LLM表现更好。

    Large Language Model (LLM) has gained popularity and achieved remarkable results in open-domain tasks, but its performance in real industrial domain-specific scenarios is average since there is no specific knowledge in it. This issue has attracted widespread attention, but there are few relevant benchmarks available. In this paper, we provide a benchmark Question Answering (QA) dataset named MSQA, which is about Microsoft products and IT technical problems encountered by customers. This dataset contains industry cloud-specific QA knowledge, which is not available for general LLM, so it is well suited for evaluating methods aimed at improving domain-specific capabilities of LLM. In addition, we propose a new model interaction paradigm that can empower LLM to achieve better performance on domain-specific tasks where it is not proficient. Extensive experiments demonstrate that the approach following our model fusion framework outperforms the commonly used LLM with retrieval methods.
    
[^55]: 以图像为枢纽的中文稳定扩散的高效跨语言转移

    Efficient Cross-Lingual Transfer for Chinese Stable Diffusion with Images as Pivots. (arXiv:2305.11540v1 [cs.CV])

    [http://arxiv.org/abs/2305.11540](http://arxiv.org/abs/2305.11540)

    本研究提出了一种经过优化的跨语言转换方法IAP，该方法使用图像作为枢纽，在中英文之间建立语义连接，将英文稳定扩散模型转化为中文。实验证明，该方法比多种强大的中文模型在生成高质量的图片方面表现更优秀。

    

    扩散模型在文本到图像合成方面取得了惊人的进展。然而，从头开始训练这样的大规模模型（例如稳定扩散）需要高昂的计算成本和海量高质量的文本-图像配对，在其他语言中则无法承受。为了解决这个挑战，我们提出了IAP，一种将英文稳定扩散转移到中文的简单而有效的方法。IAP 仅优化一个单独的中文文本编码器，所有其他参数都保持不变，以将中文语义空间与 CLIP 中的英文语义空间对齐。为了实现这一点，我们创新性地将图像视为枢纽，并最小化通过图像和每种语言之间的交叉注意力产生的注意特征的距离。通过这种方式，IAP 在 CLIP 的嵌入空间中高效地建立了中文、英语和视觉语义的连接，从而提高了使用直接中文提示生成的图像的质量。实验结果表明，我们的方法在生成高质量的中文图片方面优于几种强大的中文模型。

    Diffusion models have made impressive progress in text-to-image synthesis. However, training such large-scale models (e.g. Stable Diffusion), from scratch requires high computational costs and massive high-quality text-image pairs, which becomes unaffordable in other languages. To handle this challenge, we propose IAP, a simple but effective method to transfer English Stable Diffusion into Chinese. IAP optimizes only a separate Chinese text encoder with all other parameters fixed to align Chinese semantics space to the English one in CLIP. To achieve this, we innovatively treat images as pivots and minimize the distance of attentive features produced from cross-attention between images and each language respectively. In this way, IAP establishes connections of Chinese, English and visual semantics in CLIP's embedding space efficiently, advancing the quality of the generated image with direct Chinese prompts. Experimental results show that our method outperforms several strong Chinese d
    
[^56]: PORTRAIT: 一种混合方法来创建灾难事件的提取式基准摘要

    PORTRAIT: a hybrid aPproach tO cReate extractive ground-TRuth summAry for dIsaster evenT. (arXiv:2305.11536v1 [cs.CL])

    [http://arxiv.org/abs/2305.11536](http://arxiv.org/abs/2305.11536)

    PORTRAIT提出了一种混合方法来创建灾难事件的提取式基准摘要，既使用智能算法，又利用人工智能，可以显著降低标注者的人力成本并实现更可靠的基准摘要生成过程。

    

    灾难摘要方法提供了有关社交媒体平台上发生的灾难事件的重要信息的概述，例如 Twitter。然而，发布的信息类型根据地点、类型、严重程度等多种因素在灾难中显著变化。由于缺乏良好的数据集谱，加之缺乏基准摘要的可用性，现有的基于人工标注的基准摘要生成方法（提取式摘要的基准摘要）仍然存在两个问题：依赖于标注者的智慧和直觉，并且需要大量的人力和时间。因此，为了解决这些挑战，本文提出了一种名为PORTRAIT的混合框架，该框架使用智能算法和人工智能来创建灾难事件的基准摘要。我们的提出的框架显著降低了标注者的人力，同时实现了更可靠的基准摘要生成过程。

    Disaster summarization approaches provide an overview of the important information posted during disaster events on social media platforms, such as, Twitter. However, the type of information posted significantly varies across disasters depending on several factors like the location, type, severity, etc. Verification of the effectiveness of disaster summarization approaches still suffer due to the lack of availability of good spectrum of datasets along with the ground-truth summary. Existing approaches for ground-truth summary generation (ground-truth for extractive summarization) relies on the wisdom and intuition of the annotators. Annotators are provided with a complete set of input tweets from which a subset of tweets is selected by the annotators for the summary. This process requires immense human effort and significant time. Additionally, this intuition-based selection of the tweets might lead to a high variance in summaries generated across annotators. Therefore, to handle these
    
[^57]: 一种用于解决阿拉伯语代词消解问题的序列到序列方法

    A Sequence-to-Sequence Approach for Arabic Pronoun Resolution. (arXiv:2305.11529v1 [cs.CL])

    [http://arxiv.org/abs/2305.11529](http://arxiv.org/abs/2305.11529)

    本文提出了一种序列到序列学习方法，用于解决阿拉伯语代词消解问题。该模型在AnATAr数据集上优于传统的机器学习模型和手工特征模型。研究者还探讨了一些对模型的修改，这些修改显著提高了模型的性能。

    

    本文提出了一种序列到序列学习方法，探索了使用先进的自然语言处理(NLP)技术，特别是Bi-LSTM和BERT预训练语言模型，在解决阿拉伯语代词消解问题方面的有效性。该方法在AnATAr数据集上进行评估，并与几种基线模型进行比较，包括传统的机器学习模型和手工特征模型。我们的结果表明，该模型在所有指标上都优于基线模型，包括KNN、逻辑回归和SVM。此外，我们探讨了对模型的各种修改的有效性，包括将指代词文本与段落文本连接作为输入、添加掩码以关注候选分数以及基于指代词的性别和数量协议来过滤候选项。我们的结果表明，这些修改显著提高了模型的性能。

    This paper proposes a sequence-to-sequence learning approach for Arabic pronoun resolution, which explores the effectiveness of using advanced natural language processing (NLP) techniques, specifically Bi-LSTM and the BERT pre-trained Language Model, in solving the pronoun resolution problem in Arabic. The proposed approach is evaluated on the AnATAr dataset, and its performance is compared to several baseline models, including traditional machine learning models and handcrafted feature-based models. Our results demonstrate that the proposed model outperforms the baseline models, which include KNN, logistic regression, and SVM, across all metrics. In addition, we explore the effectiveness of various modifications to the model, including concatenating the anaphor text beside the paragraph text as input, adding a mask to focus on candidate scores, and filtering candidates based on gender and number agreement with the anaphor. Our results show that these modifications significantly improv
    
[^58]: InstructIE: 一份基于指令的中文信息提取数据集

    InstructIE: A Chinese Instruction-based Information Extraction Dataset. (arXiv:2305.11527v1 [cs.CL])

    [http://arxiv.org/abs/2305.11527](http://arxiv.org/abs/2305.11527)

    介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。

    

    我们引入了一项新的信息提取任务，称为基于指令的信息提取 (Instruction-based IE)，它旨在要求系统遵循特定的指令或指南来提取信息。为了促进该领域的研究，我们构建了一个数据集，称为InstructIE，其中包括来自中文维基百科的 270,000 个弱监督数据和 1,000 个高质量众包注释实例。我们进一步评估了各种基线模型在InstructIE数据集上的表现。结果表明，尽管当前的模型表现很有希望，但仍有改进的空间。此外，我们进行了全面的案例研究分析，强调了基于指令的信息提取任务中固有的挑战。代码和数据集可在 https://github.com/zjunlp/DeepKE/tree/main/example/llm 找到。

    We introduce a new Information Extraction (IE) task dubbed Instruction-based IE, which aims to ask the system to follow specific instructions or guidelines to extract information. To facilitate research in this area, we construct a dataset called InstructIE, consisting of 270,000 weakly supervised data from Chinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We further evaluate the performance of various baseline models on the InstructIE dataset. The results reveal that although current models exhibit promising performance, there is still room for improvement. Furthermore, we conduct a comprehensive case study analysis, underlining the challenges inherent in the Instruction-based IE task. Code and dataset are available at https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^59]: DiffuSIA：一种编码器-解码器文本扩散的螺旋交互架构

    DiffuSIA: A Spiral Interaction Architecture for Encoder-Decoder Text Diffusion. (arXiv:2305.11517v1 [cs.CL])

    [http://arxiv.org/abs/2305.11517](http://arxiv.org/abs/2305.11517)

    本文提出一种名为DiffuSIA的螺旋交互架构，用于编码器-解码器文本扩散。在这个架构中，条件信息和目标信息会交互捕获，以提高条件文本生成的效果。

    

    扩散模型已成为新一代深度生成模型的最新代表，并且近年来它们在文本生成方面的潜力引起了越来越多的关注。现有的研究大多采用单个编码器结构和部分噪声过程用于条件文本生成，但是其对于条件建模的灵活性有限。实际上，编码器-解码器架构对于它的可分离编码器和解码器模块天然更加灵活，可扩展到多语言和多模态的生成任务。然而，有条件的文本编码过程缺乏对目标文本的理解。为此，我们提出了一种用于编码器-解码器文本扩散的螺旋交互架构（DiffuSIA）。具体来说，设计了从编码器捕获条件信息并被扩散解码器捕获，以及从解码器捕获目标信息并被条件编码器捕获的机制。

    Diffusion models have emerged as the new state-of-the-art family of deep generative models, and their promising potentials for text generation have recently attracted increasing attention. Existing studies mostly adopt a single encoder architecture with partially noising processes for conditional text generation, but its degree of flexibility for conditional modeling is limited. In fact, the encoder-decoder architecture is naturally more flexible for its detachable encoder and decoder modules, which is extensible to multilingual and multimodal generation tasks for conditions and target texts. However, the encoding process of conditional texts lacks the understanding of target texts. To this end, a spiral interaction architecture for encoder-decoder text diffusion (DiffuSIA) is proposed. Concretely, the conditional information from encoder is designed to be captured by the diffusion decoder, while the target information from decoder is designed to be captured by the conditional encoder.
    
[^60]: “即插即用”医疗对话系统

    Plug-and-Play Medical Dialogue System. (arXiv:2305.11508v1 [cs.CL])

    [http://arxiv.org/abs/2305.11508](http://arxiv.org/abs/2305.11508)

    该论文提出了一种即插即用的医疗对话系统，使用大型语言模型实现医疗问答及诊断策略，避免了传统昂贵的LLMs微调。

    

    医疗对话系统旨在为患者提供准确的答案，需要特定的领域知识。大型语言模型（LLMs）的最近进展已经证明了其在医疗问答领域具有杰出的能力，表明具备了对常识的丰富理解。然而，由于缺乏诊断策略，LLMs无法直接用于诊断。传统的解决方法是昂贵的LLMs微调。另一种更具吸引力的解决方法是开发一个插件，赋予LLMs执行医疗对话任务的能力。受到上下文学习的启发，我们提出了PlugMed，一个即插即用的医疗对话系统，通过两个模块促进了LLMs的恰当对话动作：提示生成（PG）模块和回复排名（RR）模块。PG模块旨在从全局和局部角度捕获对话信息。它通过评估匹配度来选择合适的提示。

    Medical dialogue systems aim to provide accurate answers to patients, necessitating specific domain knowledge. Recent advancements in Large Language Models (LLMs) have demonstrated their exceptional capabilities in the medical Q&A domain, indicating a rich understanding of common sense. However, LLMs are insufficient for direct diagnosis due to the absence of diagnostic strategies. The conventional approach to address this challenge involves expensive fine-tuning of LLMs. Alternatively, a more appealing solution is the development of a plugin that empowers LLMs to perform medical conversation tasks. Drawing inspiration from in-context learning, we propose PlugMed, a Plug-and-Play Medical Dialogue System that facilitates appropriate dialogue actions by LLMs through two modules: the prompt generation (PG) module and the response ranking (RR) module. The PG module is designed to capture dialogue information from both global and local perspectives. It selects suitable prompts by assessing 
    
[^61]: 一种具有不同模态侧面信息的主题感知摘要框架

    A Topic-aware Summarization Framework with Different Modal Side Information. (arXiv:2305.11503v1 [cs.CL])

    [http://arxiv.org/abs/2305.11503](http://arxiv.org/abs/2305.11503)

    本文提出了一种具有灵活性的通用摘要框架，可以整合各种模态的侧面信息，以实现更好的文章摘要效果。

    

    自动摘要在网络文档的爆炸性增长中扮演重要角色。在像CNN.com和WikiHow.com这样的内容网站上，经常存在各种与主要文档一起用于吸引注意力和更易理解的侧面信息，例如视频、图像和查询。这些信息可以用于更好的摘要，因为它们常常明示或暗示文章的本质。然而，大多数现有的侧面感知摘要方法都是设计为集成单模或多模侧面信息 ，并不能有效地互相适应。在本文中，我们提出了一种通用的摘要框架，可以灵活地整合各种模态的侧面信息。设计具有侧面信息的灵活摘要模型的主要挑战包括：（1）侧面信息可以是文本或视觉格式，并且模型需要将其与文档对齐并统一为相同的语义表示。

    Automatic summarization plays an important role in the exponential document growth on the Web. On content websites such as CNN.com and WikiHow.com, there often exist various kinds of side information along with the main document for attention attraction and easier understanding, such as videos, images, and queries. Such information can be used for better summarization, as they often explicitly or implicitly mention the essence of the article. However, most of the existing side-aware summarization methods are designed to incorporate either single-modal or multi-modal side information, and cannot effectively adapt to each other. In this paper, we propose a general summarization framework, which can flexibly incorporate various modalities of side information. The main challenges in designing a flexible summarization model with side information include: (1) the side information can be in textual or visual format, and the model needs to align and unify it with the document into the same sem
    
[^62]: 从对齐到蕴涵：面向实体对齐的统一文本蕴涵框架

    From Alignment to Entailment: A Unified Textual Entailment Framework for Entity Alignment. (arXiv:2305.11501v1 [cs.CL])

    [http://arxiv.org/abs/2305.11501](http://arxiv.org/abs/2305.11501)

    该论文提出了一个基于文本蕴涵的实体对齐框架，能够将实体的三元组转化为统一的文本序列，通过预训练语言模型计算实体之间的蕴涵概率进行实体对齐，能够更好地捕捉实体之间的相关信息，并且给出了文本解释说明。

    

    实体对齐旨在发现两个知识图谱之间的等效实体。现有方法通常将实体的三元组编码为嵌入并学习对齐嵌入，这导致跨知识图谱实体的原始信息无法直接交互作用。此外，它们将实体的关系三元组和属性三元组编码为异构嵌入空间，这阻止了它们互相帮助。本文将两个三元组转换为统一的文本序列，并将EA任务建模为两个实体序列之间的双向文本蕴涵任务。具体而言，我们同时将两个实体的序列馈送到预训练语言模型（PLM）中，并提出了两种基于PLM的实体对齐器，将序列之间的蕴涵概率建模为实体之间的相似度。我们的方法捕获了两种实体信息之间的统一相关模式，并用文本解释说明了对齐的实体。在两个基准数据集上的实验结果证明了我们提出的文本蕴涵框架对EA的有效性。

    Entity Alignment (EA) aims to find the equivalent entities between two Knowledge Graphs (KGs). Existing methods usually encode the triples of entities as embeddings and learn to align the embeddings, which prevents the direct interaction between the original information of the cross-KG entities. Moreover, they encode the relational triples and attribute triples of an entity in heterogeneous embedding spaces, which prevents them from helping each other. In this paper, we transform both triples into unified textual sequences, and model the EA task as a bi-directional textual entailment task between the sequences of cross-KG entities. Specifically, we feed the sequences of two entities simultaneously into a pre-trained language model (PLM) and propose two kinds of PLM-based entity aligners that model the entailment probability between sequences as the similarity between entities. Our approach captures the unified correlation pattern of two kinds of information between entities, and explic
    
[^63]: RCOT：通过反转思维链条检测和纠正推理中的事实不一致性

    RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought. (arXiv:2305.11499v1 [cs.CL])

    [http://arxiv.org/abs/2305.11499](http://arxiv.org/abs/2305.11499)

    RCOT 提出了一个新的方法来检测和纠正 LLM 生成解决方案中的事实不一致性，以提高 LLM 推理能力。

    

    大型语言模型（LLM）通过逐步思维链（CoT）提示在算术推理任务上取得了很好的成绩。然而，LLM在推理过程中面临着维护事实一致性的挑战，表现出在给定问题上确定过度、问题误解和条件幻觉的趋势。现有方法使用粗粒度反馈（例如，答案是否正确）来提高事实一致性。本文提出RCoT（反转CoT），一种新颖的方法，通过自动检测和纠正LLM生成的解决方案中的事实不一致性来提高LLMs的推理能力。为了检测事实不一致性，RCoT首先要求LLMs基于生成的解决方案重构问题。然后，通过对比原始问题和重构问题，较为详细地揭示了原始解决方案中的事实不一致性。为了纠正解决方案，RCoT制定了检测到的fa

    Large language Models (LLMs) have achieved promising performance on arithmetic reasoning tasks by incorporating step-by-step chain-of-thought (CoT) prompting. However, LLMs face challenges in maintaining factual consistency during reasoning, exhibiting tendencies to condition overlooking, question misinterpretation, and condition hallucination over given problems. Existing methods use coarse-grained feedback (e.g., whether the answer is correct) to improve factual consistency. In this work, we propose RCoT (Reversing Chain-of-Thought), a novel method to improve LLMs' reasoning abilities by automatically detecting and rectifying factual inconsistency in LLMs' generated solutions. To detect factual inconsistency, RCoT first asks LLMs to reconstruct the problem based on generated solutions. Then fine-grained comparisons between the original problem and the reconstructed problem expose the factual inconsistency in the original solutions. To rectify the solution, RCoT formulates detected fa
    
[^64]: 基于概率偏置的事件抽取中重新耦合事件场

    Recouple Event Field via Probabilistic Bias for Event Extraction. (arXiv:2305.11498v1 [cs.CL])

    [http://arxiv.org/abs/2305.11498](http://arxiv.org/abs/2305.11498)

    提出了一种基于概率偏置的重新耦合事件场模型（ProCE），用于增强事件提取框架，以澄清来自模糊纠缠的事件字段，并重新耦合相应的澄清分布以捕获更多潜在信息字段。实验表明该方法有效且具有泛化性。

    

    事件抽取（EE）旨在从事件提及中识别和分类事件触发器和参数，已经受益于预训练语言模型（PLM）。然而，现有基于PLM的方法忽略了触发/参数字段的信息，这对于理解事件模式是至关重要的。为此，我们提出了一种概率重新耦合模型增强事件提取框架（ProCE）。具体来说，我们首先将语法相关的事件字段建模为概率偏置，以澄清来自模糊纠缠的事件字段。此外，考虑到EE中同一触发器/参数的多次出现，我们探索了同一触发器/参数的多个字段之间的概率交互策略，以重新耦合相应的澄清分布并捕获更多潜在信息字段。在EE数据集上的实验证明了我们提出的方法的有效性和泛化性。

    Event Extraction (EE), aiming to identify and classify event triggers and arguments from event mentions, has benefited from pre-trained language models (PLMs). However, existing PLM-based methods ignore the information of trigger/argument fields, which is crucial for understanding event schemas. To this end, we propose a Probabilistic reCoupling model enhanced Event extraction framework (ProCE). Specifically, we first model the syntactic-related event fields as probabilistic biases, to clarify the event fields from ambiguous entanglement. Furthermore, considering multiple occurrences of the same triggers/arguments in EE, we explore probabilistic interaction strategies among multiple fields of the same triggers/arguments, to recouple the corresponding clarified distributions and capture more latent information fields. Experiments on EE datasets demonstrate the effectiveness and generalization of our proposed approach.
    
[^65]: TreePrompt：学习生成树形提示以实现可解释的视觉定位

    TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding. (arXiv:2305.11497v1 [cs.CV])

    [http://arxiv.org/abs/2305.11497](http://arxiv.org/abs/2305.11497)

    提示调整技术已经在视觉定位领域卓有成效，但现有的方法大多数可解释性不好。本文提出了一种新的提示构建方法，名为TreePrompt，通过将句子分解成树状结构进行逐步提示构建，提高了提示的可解释性。

    

    提示调整已经在将从大型预训练的视觉语言模型中的知识转移到下游任务方面取得了巨大的成功，并且已经支配了视觉定位（VG）的表现。然而，几乎所有现有的提示调整范例都遭受着可解释性差的问题。在本文中，我们认为其可解释性差是由于全局提示生成和推理过程造成的。通过“全局”，我们是指它们通常直接学习一组向量作为提示（即提示生成），并使用学习到的全局提示增强VG模型的文本输入（即提示推理）。为此，我们提出了一种具有显式可解释性的新型提示构建范例，称为TreePrompt。具体而言，我们首先将复杂的句子分解成一棵与人类推理一致的树。然后，按照语法树，我们从底向上以结构化提示的方式构成一个提示。由于这一步骤一步一步的提示构建过程，e

    Prompt tuning has achieved great success in transferring the knowledge from large pretrained vision-language models into downstream tasks, and has dominated the performance on visual grounding (VG). However, almost all existing prompt tuning paradigms suffer from poor interpretability. In this paper, we argue that their poor interpretability is attributed to the holistic prompt generation and inference process. By "holistic", we mean that they usually directly learn a set of vectors as the prompt (i.e., prompt generation), and use the learned global prompt to augment the textual input for the VG model (i.e., prompt inference). To this end, we propose a new prompt construction paradigm with explicit explainable ability, named TreePrompt. Specifically, we first deconstruct a complex sentence into a tree, that is consistent with human reasoning. Then, following the syntax tree, we compose a structured prompt in a bottom-up manner. Thanks to this step-by-step prompt construction process, e
    
[^66]: LLM自身可读取和生成CXR图像

    LLM Itself Can Read and Generate CXR Images. (arXiv:2305.11490v1 [cs.CV])

    [http://arxiv.org/abs/2305.11490](http://arxiv.org/abs/2305.11490)

    该论文提出了一种新方法，可以在不需要进行结构更改、额外训练、或训练专门网络的情况下，通过微调预先训练的LLM来读取和生成像文本一样的图像，并应用于胸部X线（CXR）图像的生成任务中。

    

    借助于近期大语言模型（LLMs）的显著发展，人们正积极尝试将LLMs的实用性扩展到多模态任务。已经有人尝试连接语言和视觉信息，并且也在不断尝试为LLMs添加视觉能力。然而，现有的尝试只使用LLMs作为图像解码器，没有尝试通过自然语言来生成图像。通过采用VQ-GAN框架，将图像的潜在表示视为一种文本标记，我们提出了一种新方法，可以微调预先训练的LLM，以像文本一样读取和生成图像，而无需进行结构更改、额外的训练目标或训练专门的网络，同时仍保留LLM的指令跟随能力。我们将此框架应用于胸部X线（CXR）图像的生成任务中，因为这是一个复杂信息在视觉和语言之间翻译的领域。

    Building on the recent remarkable development of large language models (LLMs), active attempts are being made to extend the utility of LLMs to multimodal tasks. There have been previous efforts to link language and visual information, and attempts to add visual capabilities to LLMs are ongoing as well. However, existing attempts use LLMs only as image decoders and no attempt has been made to generate images in the same line as the natural language. By adopting a VQ-GAN framework in which latent representations of images are treated as a kind of text tokens, we present a novel method to fine-tune a pre-trained LLM to read and generate images like text without any structural changes, extra training objectives, or the need for training an ad-hoc network while still preserving the of the instruction-following capability of the LLM. We apply this framework to chest X-ray (CXR) image and report generation tasks as it is a domain in which translation of complex information between visual and 
    
[^67]: 用对比潜在变量增强个性化对话生成：结合稀疏和密集人格

    Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona. (arXiv:2305.11482v1 [cs.CL])

    [http://arxiv.org/abs/2305.11482](http://arxiv.org/abs/2305.11482)

    本文基于对比潜在变量模型（CLV）结合稀疏和密集人格描述以及对话历史记录来实现更丰富和准确的个性化对话生成。实验结果表明，该模型在个性化方面具有优越性。

    

    个性化对话探索了对话生成与个性之间的一致关系。现有的个性化对话模型从三个资源（稀疏或密集的个性描述以及对话历史记录）中建模个人资料。然而，稀疏的结构化个性属性是显性但无信息；密集的个性文本包含着丰富的个性描述与较多的噪声，而对话历史查询既嘈杂又无信息以供个性建模。本文将三个资源的优势进行结合，设计了一个基于对比潜在变量模型（CLV）的框架，将密集的个性描述聚类成稀疏的类别，然后和查询历史共同生成个性化回应。中英文数据集的实验结果表明，我们的模型在个性化上卓有成效。

    The personalized dialogue explores the consistent relationship between dialogue generation and personality. Existing personalized dialogue agents model persona profiles from three resources: sparse or dense persona descriptions and dialogue histories. However, sparse structured persona attributes are explicit but uninformative, dense persona texts contain rich persona descriptions with much noise, and dialogue history query is both noisy and uninformative for persona modeling. In this work, we combine the advantages of the three resources to obtain a richer and more accurate persona. We design a Contrastive Latent Variable-based model (CLV) that clusters the dense persona descriptions into sparse categories, which are combined with the history query to generate personalized responses. Experimental results on Chinese and English datasets demonstrate our model's superiority in personalization.
    
[^68]: CCGen：电子商务中可解释的互补概念生成

    CCGen: Explainable Complementary Concept Generation in E-Commerce. (arXiv:2305.11480v1 [cs.CL])

    [http://arxiv.org/abs/2305.11480](http://arxiv.org/abs/2305.11480)

    CCGen是一个电子商务中可解释的互补概念生成算法，通过训练语言模型生成高质量的互补概念排名列表，并生成解释以证明预测的正确性。

    

    我们提出并研究了互补概念生成（CCGen）：给定一个感兴趣的概念，例如“数码相机”，生成一系列互补的概念，例如1）相机镜头2）电池3）相机盒子4）存储卡5）电池充电器。CCGen对于诸如查询建议和物品推荐等各种应用，尤其是在电子商务领域中非常有益。为了解决CCGen，我们提出了一个两步训练策略，利用语言模型生成排名列表。我们还教授模型生成解释，通过加入从大型教师模型中提取的解释。广泛的实验和分析表明，我们的模型可以生成高质量的互补概念，同时生成解释以证明预测的正确性。

    We propose and study Complementary Concept Generation (CCGen): given a concept of interest, e.g., "Digital Cameras", generating a list of complementary concepts, e.g., 1) Camera Lenses 2) Batteries 3) Camera Cases 4) Memory Cards 5) Battery Chargers. CCGen is beneficial for various applications like query suggestion and item recommendation, especially in the e-commerce domain. To solve CCGen, we propose to train language models to generate ranked lists of concepts with a two-step training strategy. We also teach the models to generate explanations by incorporating explanations distilled from large teacher models. Extensive experiments and analysis demonstrate that our model can generate high-quality concepts complementary to the input concept while producing explanations to justify the predictions.
    
[^69]: Graphologue：用交互式图表探索大型语言模型响应

    Graphologue: Exploring Large Language Model Responses with Interactive Diagrams. (arXiv:2305.11473v1 [cs.HC])

    [http://arxiv.org/abs/2305.11473](http://arxiv.org/abs/2305.11473)

    Graphologue是一个交互式系统，将大型语言模型的基于文本的响应转换为图形化图表以增强其可用性和可解释性，用户可以通过选择和突出显示特定节点和链接来与这些图表进行交互。

    

    大型语言模型（LLM）由于易于获取和在多种应用中表现出的前所未有的智能而近来风靡一时。然而，像ChatGPT这样的LLM在支持复杂信息任务方面存在显着的限制，原因是基于文本的媒介和线性对话结构提供的功能不足。通过与十名参与者的形式化研究，我们发现LLM界面通常会呈现冗长的响应，使人们难以快速理解和灵活地与各种信息进行交互，特别是在更复杂的任务中。我们提出了Graphologue，这是一个交互式系统，将LLM的基于文本的响应转换为图形化图表，以便于信息查找和问题回答任务。Graphologue采用新颖的提示策略和界面设计，从LLM响应中提取实体和关系，并实时构建节点链接图。此外，用户可以通过选择和突出显示特定节点和链接来与这些图表进行交互，以探索相关信息和跟进问题。我们的用户研究结果表明，与传统的基于文本的界面相比，Graphologue显著提高了用户在复杂信息任务中的表现和满意度。Graphologue为增强LLM在各种应用和领域中的可用性和可解释性提供了一个有前景的方向。

    Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented intelligence exhibited on diverse applications. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts text-based responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can int
    
[^70]: 扩展语言模型的记忆容量

    Extending Memory for Language Modelling. (arXiv:2305.11462v1 [cs.CL])

    [http://arxiv.org/abs/2305.11462](http://arxiv.org/abs/2305.11462)

    本论文介绍了一种名为“长期记忆网络”的方法，可用于从无限长序列中学习，以扩展归纳语言建模的记忆容量，并在三个数据集上的测试中表现优异。该方法还可用于文本生成。

    

    深度学习和记忆网络的突破使自然语言理解取得了重大进展。语言是连续的，通过序列传递的信息可以通过记忆网络捕获。学习序列是学习语言的关键因素之一。然而，记忆网络不能在其内存中持有无限长的序列，并受到各种约束的限制，例如消失或爆炸梯度问题。因此，当面对长序列文本时，自然语言理解模型会受到影响。我们引入了长期记忆网络（LTM），以从无限长的序列中学习。 LTM 重视当前输入，以使其具有高影响力。语言建模是自然语言理解的重要因素。 LTM 在需要长期记忆的语言建模中进行了测试。 LTM 在 Penn Tree Bank 数据集，Google Billion字数据集和WikiText-2数据集上进行了测试。我们将 LTM 与其他最先进的模型进行比较，并表明 LTM 在所有三个数据集上的困惑度都比它们低，且参数更少。此外，我们还展示了 LTM 可用于文本生成。

    Breakthroughs in deep learning and memory networks have made major advances in natural language understanding. Language is sequential and information carried through the sequence can be captured through memory networks. Learning the sequence is one of the key aspects in learning the language. However, memory networks are not capable of holding infinitely long sequences in their memories and are limited by various constraints such as the vanishing or exploding gradient problem. Therefore, natural language understanding models are affected when presented with long sequential text. We introduce Long Term Memory network (LTM) to learn from infinitely long sequences. LTM gives priority to the current inputs to allow it to have a high impact. Language modeling is an important factor in natural language understanding. LTM was tested in language modeling, which requires long term memory. LTM is tested on Penn Tree bank dataset, Google Billion Word dataset and WikiText-2 dataset. We compare LTM
    
[^71]: 自我协议：微调语言模型以在不同意见之间找到共识的框架

    Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions. (arXiv:2305.11460v1 [cs.CL])

    [http://arxiv.org/abs/2305.11460](http://arxiv.org/abs/2305.11460)

    本文提出了一种名为自我协议(Self-Agreement)的新框架，用于微调LLMs以自主地找到共识，并使用LLM自动生成的数据。

    

    在多智能体系统中找到不同意见之间的共识是一个具有挑战性的话题。最近，大型语言模型(LLMs)在解决这一挑战方面表现出了巨大的潜力，因为它们在理解人类观点和生成类人文本方面具有卓越的能力。然而，它们通常依赖于大量的人工标注数据。在本文中，我们提出了一种名为自我协议(Self-Agreement)的新框架，用于微调LLMs以自主地找到共识，并使用LLM自动生成的数据。具体而言，我们的方法使用生成式预训练变压器3(GPT-3)为问题数据集中的每个问题生成多个意见，并为这些意见创建多个共识候选项。然后，基于双向编码器表示来自变压器(BERT)的模型评估每个共识候选项的一致性得分，并选择得分最高的共识候选项。这个过程产生了一个问题-意见-共识数据集，我们使用它来微调一个模型。

    Finding an agreement among diverse opinions is a challenging topic in multiagent systems. Recently, large language models (LLMs) have shown great potential in addressing this challenge due to their remarkable capabilities in comprehending human opinions and generating human-like text. However, they typically rely on extensive human-annotated data. In this paper, we propose Self-Agreement, a novel framework for fine-tuning LLMs to autonomously find agreement using data generated by LLM itself. Specifically, our approach employs the generative pre-trained transformer-3 (GPT-3) to generate multiple opinions for each question in a question dataset and create several agreement candidates among these opinions. Then, a bidirectional encoder representations from transformers (BERT)-based model evaluates the agreement score of each agreement candidate and selects the one with the highest agreement score. This process yields a dataset of question-opinion-agreements, which we use to fine-tune a p
    
[^72]: 突破智能体-环境界面，优化具有包容性的语言模型的微调

    Shattering the Agent-Environment Interface for Fine-Tuning Inclusive Language Models. (arXiv:2305.11455v1 [cs.CL])

    [http://arxiv.org/abs/2305.11455](http://arxiv.org/abs/2305.11455)

    该论文提出了一种新颖的思路，将预训练的语言模型本身同时作为策略、奖励函数和转移函数，可以直接进行奖励学习和语言模型微调，可以带来巨大的统计收益。

    

    在微调自回归语言模型中，从人类反馈的增强学习方法（RLHF）的重要组成部分是显式训练一个奖励模型来模拟人类反馈，而不是语言模型本身。然后，将这个奖励模型与策略梯度方法耦合起来，从而显著提高语言模型输出与期望响应之间的一致性。在这项工作中，我们采取了一种新颖的观点，即预训练的语言模型本身同时是策略、奖励函数和转移函数。这个观点的一个直接结果是，可以同时直接进行奖励学习和语言模型微调，无需进一步的下游策略优化。虽然这个观点确实打破了传统智能体-环境界面，但我们仍然认为，将强化学习的传统算法概念运用于这种方法中可以带来巨大的统计收益。

    A centerpiece of the ever-popular reinforcement learning from human feedback (RLHF) approach to fine-tuning autoregressive language models is the explicit training of a reward model to emulate human feedback, distinct from the language model itself. This reward model is then coupled with policy-gradient methods to dramatically improve the alignment between language model outputs and desired responses. In this work, we adopt a novel perspective wherein a pre-trained language model is itself simultaneously a policy, reward function, and transition function. An immediate consequence of this is that reward learning and language model fine-tuning can be performed jointly and directly, without requiring any further downstream policy optimization. While this perspective does indeed break the traditional agent-environment interface, we nevertheless maintain that there can be enormous statistical benefits afforded by bringing to bear traditional algorithmic concepts from reinforcement learning.
    
[^73]: 分析和减少跨语言迁移中的性能差距：缓慢和快速微调方法

    Analyzing and Reducing the Performance Gap in Cross-Lingual Transfer with Fine-tuning Slow and Fast. (arXiv:2305.11449v1 [cs.CL])

    [http://arxiv.org/abs/2305.11449](http://arxiv.org/abs/2305.11449)

    本文分析了微调过程，提出了缓慢和快速微调的方法来解决跨语言迁移中的性能差距问题，通过减少遗忘来弥补性能差距，实验结果表明该方法的性能比基线方法好。

    

    现有研究表明，多语言预训练语言模型在一个（源）语言上进行微调后，在非源语言的下游任务中也表现良好，尽管这些语言没有进行微调，但源语言和非源语言之间存在明显的性能差距。本文分析了微调过程，发现了性能差距何时改变，并确定哪些网络权重对整体性能影响最大。此外，本文试图回答通过减少遗忘来多大程度上可以缩小差距。基于分析结果，提出了一种名为缓慢和快速微调的方法，包括四种训练策略来解决这些问题。实验结果表明，与基线方法相比，该方法的性能有明显提高。

    Existing research has shown that a multilingual pre-trained language model fine-tuned with one (source) language also performs well on downstream tasks for non-source languages, even though no fine-tuning is done on these languages. However, there is a clear gap between the performance of the source language and that of the non-source languages. This paper analyzes the fine-tuning process, discovers when the performance gap changes and identifies which network weights affect the overall performance most. Additionally, the paper seeks to answer to what extent the gap can be reduced by reducing forgetting. Based on the analysis results, a method named Fine-tuning slow and fast with four training policies is proposed to address these issues. Experimental results show the proposed method outperforms baselines by a clear margin.
    
[^74]: Arukikata旅游游记数据集 (arXiv:2305.11444v1 [cs.CL])

    Arukikata Travelogue Dataset. (arXiv:2305.11444v1 [cs.CL])

    [http://arxiv.org/abs/2305.11444](http://arxiv.org/abs/2305.11444)

    Arukikata旅游游记数据集是一个包含超过3100万个日文单词的数据集，包括4672个日本国内游记和9607个海外游记，为研究人员提供了可重复和透明的研究数据。

    

    我们创建了Arukikata旅游游记数据集，并免费提供给学术研究使用。该数据集包含超过3100万个日文单词，包括4672个日本国内游记和9607个海外游记。在我们提供数据集之前，很难获得可用于研究的广泛旅游游记数据，每个研究人员都必须准备自己的数据。这阻碍了对现有研究的复制以及对实验结果进行公正比较分析。我们的数据集使得任何研究人员都可以对相同的数据进行研究，并确保研究的透明度和可重复性。 在本文中，我们描述了我们的数据集的学术意义、特点和前景。

    We have constructed Arukikata Travelogue Dataset and released it free of charge for academic research. This dataset is a Japanese text dataset with a total of over 31 million words, comprising 4,672 Japanese domestic travelogues and 9,607 overseas travelogues. Before providing our dataset, there was a scarcity of widely available travelogue data for research purposes, and each researcher had to prepare their own data. This hinders the replication of existing studies and fair comparative analysis of experimental results. Our dataset enables any researchers to conduct investigation on the same data and to ensure transparency and reproducibility in research. In this paper, we describe the academic significance, characteristics, and prospects of our dataset.
    
[^75]: 基于自监督调整的零样本文本分类算法

    Zero-Shot Text Classification via Self-Supervised Tuning. (arXiv:2305.11442v1 [cs.CL])

    [http://arxiv.org/abs/2305.11442](http://arxiv.org/abs/2305.11442)

    本文提出了一种基于自监督调整的零样本文本分类算法，通过使用无标签数据来调整语言模型，通过学习预测段落中的第一句话，实现了对未见过任务的零样本推断，模型不需要注释数据进行元调整，对模板的选择不敏感，并在实验中取得不错的结果。

    

    现有的零样本文本分类方法要么使用预训练语言模型进行提示，但这种方法对模板的选择非常敏感；要么依赖于大量相关任务的注释数据进行元调整。本文提出了一种基于自监督学习的新范式，通过使用无标签数据来调整语言模型，称为自监督调整。通过探索自由文本的内在结构，我们提出了一种新的学习目标，称为首句预测，以弥合无标签数据和文本分类任务之间的差距。调整模型以学习根据剩余文本来预测段落中的第一句话后，该模型能够推断出未见过的任务，如主题分类和情感分析。实验结果表明，我们的模型在10个任务中的7个任务上优于现有基准线。此外，分析表明，我们的模型对模板的选择不敏感，并且不需要注释数据进行元调整。

    Existing solutions to zero-shot text classification either conduct prompting with pre-trained language models, which is sensitive to the choices of templates, or rely on large-scale annotated data of relevant tasks for meta-tuning. In this work, we propose a new paradigm based on self-supervised learning to solve zero-shot text classification tasks by tuning the language models with unlabeled data, called self-supervised tuning. By exploring the inherent structure of free texts, we propose a new learning objective called first sentence prediction to bridge the gap between unlabeled data and text classification tasks. After tuning the model to learn to predict the first sentence in a paragraph based on the rest, the model is able to conduct zero-shot inference on unseen tasks such as topic classification and sentiment analysis. Experimental results show that our model outperforms the state-of-the-art baselines on 7 out of 10 tasks. Moreover, the analysis reveals that our model is less s
    
[^76]: 基于音韵和韵律感知的自监督学习方法在非母语流畅度评分中的应用

    Phonetic and Prosody-aware Self-supervised Learning Approach for Non-native Fluency Scoring. (arXiv:2305.11438v1 [cs.CL])

    [http://arxiv.org/abs/2305.11438](http://arxiv.org/abs/2305.11438)

    本论文提出了一个基于音韵和韵律感知的自监督学习方法，用于非母语流畅度评分。通过在大量未标记的语音和文本提示上预训练模型，然后使用人工注释的评分数据进行微调，该方法在Pearson相关系数（PCC）方面优于基线系统。

    

    通过分析一系列的音韵和韵律特征，可以评估说话的流畅度/不流畅度。深度神经网络通常用于将与流畅度相关的特征映射到人类评分中。然而，深度学习模型的有效性受到标记训练样本数量的限制。为了解决这个问题，我们引入了一个基于自监督学习 (SSL) 的方法，考虑了对于流畅度评分而言的音韵和韵律感知。具体而言，我们首先使用一个重建损失函数在大量未标记的语音和文本提示上联合屏蔽音素及其持续时间来预训练模型。然后，我们使用人工注释的评分数据对预训练模型进行微调。我们的实验结果，在Speechocean762等数据集上进行，显示出我们的方法在Pearson相关系数（PCC）方面优于基线系统。此外，我们还进行了消融研究，以更好地了解我们方法的作用及效果。

    Speech fluency/disfluency can be evaluated by analyzing a range of phonetic and prosodic features. Deep neural networks are commonly trained to map fluency-related features into the human scores. However, the effectiveness of deep learning-based models is constrained by the limited amount of labeled training samples. To address this, we introduce a self-supervised learning (SSL) approach that takes into account phonetic and prosody awareness for fluency scoring. Specifically, we first pre-train the model using a reconstruction loss function, by masking phones and their durations jointly on a large amount of unlabeled speech and text prompts. We then fine-tune the pre-trained model using human-annotated scoring data. Our experimental results, conducted on datasets such as Speechocean762 and our non-native datasets, show that our proposed method outperforms the baseline systems in terms of Pearson correlation coefficients (PCC). Moreover, we also conduct an ablation study to better under
    
[^77]: 基于视觉引导的自监督语音模型中的音节发现和跨语言泛化

    Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode. (arXiv:2305.11435v1 [eess.AS])

    [http://arxiv.org/abs/2305.11435](http://arxiv.org/abs/2305.11435)

    本文提出采用基于视觉引导的自监督语音模型进行音节发现和跨语言泛化。使用最小割算法和2阶段聚类方法自动预测语音中的音节边界。在英语上表现优于最先进的音节分割方法，并以零样本的方式在爱沙尼亚语上泛化。在其他语言上也取得了成功。

    

    本文表明，在使用基于视觉引导的训练目标训练自监督语音模型时，能够捕捉到表示音节的单元的表征。我们证明了几乎相同的模型结构（HuBERT），在使用掩码语言建模损失进行训练时没有表现出这种能力，这表明视觉引导目标导致了这种现象的出现。我们提出使用最小割算法自动预测语音中的音节边界，然后使用两阶段聚类方法将相同的音节组合在一起。我们展示了，我们的模型不仅在训练的语言（英语）上优于最先进的音节分割方法，而且在爱沙尼亚语上以零样本的方式进行泛化。最后，我们展示了相同的模型能够进行4种其他语言的零样本单词分割任务泛化，在某些情况下击败了先前的最先进技术。

    In this paper, we show that representations capturing syllabic units emerge when training a self-supervised speech model with a visually-grounded training objective. We demonstrate that a nearly identical model architecture (HuBERT) trained with a masked language modeling loss does not exhibit this same ability, suggesting that the visual grounding objective is responsible for the emergence of this phenomenon. We propose the use of a minimum cut algorithm to automatically predict syllable boundaries in speech, followed by a 2-stage clustering method to group identical syllables together. We show that our model not only outperforms a state-of-the-art syllabic segmentation method on the language it was trained on (English), but also generalizes in a zero-shot fashion to Estonian. Finally, we show that the same model is capable of zero-shot generalization for a word segmentation task on 4 other languages from the Zerospeech Challenge, in some cases beating the previous state-of-the-art.
    
[^78]: TELeR：用于基准测试复杂任务的LLM提示的通用分类法

    TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks. (arXiv:2305.11430v1 [cs.AI])

    [http://arxiv.org/abs/2305.11430](http://arxiv.org/abs/2305.11430)

    本文提出了一个通用分类法，可以用来设计具有特定属性的提示来执行各种复杂任务，从而解决了LLM在执行复杂任务方面的性能变异巨大的问题。

    

    尽管LLM在传统对话环境中理解和生成文本时取得了巨大成功，但它们在执行不明确的复杂任务方面的潜力仍然受到很少的研究。本文提出了一种通用分类法，可以用来设计具有特定属性的提示，以执行各种复杂任务，从而解决了使用不同提示类型/风格和提示提供的不同详细程度时LLM性能变化巨大的问题。这个分类法将使未来的基准测试研究能够报告研究中使用的特定提示类别，从而实现跨不同研究的有意义的比较。

    While LLMs have shown great success in understanding and generating text in traditional conversational settings, their potential for performing ill-defined complex tasks is largely under-studied. Indeed, we are yet to conduct comprehensive benchmarking studies with multiple LLMs that are exclusively focused on a complex task. However, conducting such benchmarking studies is challenging because of the large variations in LLMs' performance when different prompt types/styles are used and different degrees of detail are provided in the prompts. To address this issue, the paper proposes a general taxonomy that can be used to design prompts with specific properties in order to perform a wide range of complex tasks. This taxonomy will allow future benchmarking studies to report the specific categories of prompts used as part of the study, enabling meaningful comparisons across different studies. Also, by establishing a common standard through this taxonomy, researchers will be able to draw mo
    
[^79]: 后验解释可以提高语言模型的性能

    Post Hoc Explanations of Language Models Can Improve Language Models. (arXiv:2305.11426v1 [cs.CL])

    [http://arxiv.org/abs/2305.11426](http://arxiv.org/abs/2305.11426)

    本文提出了一种新的框架AMPLIFY，利用后验解释自动化生成原因，并在多个数据集和任务上显著提高现有语言模型的性能。

    

    大型语言模型在执行复杂任务方面表现出了非凡的能力。最近的研究显示，在上下文学习过程中加入人类注释的原理（例如，思维链提示）可以显著提高这些模型的性能，特别是在需要推理能力的任务上。然而，这样的原理加入在可扩展性方面存在挑战，因为这需要高度的人工参与。本文提出了一种新框架，即通过利用后验解释的上下文学习来放大模型性能，来解决上述挑战。为此，我们利用后验解释方法的结果，该方法输出称为属性分数（解释）的值，用于捕获每个输入特征对模型预测的影响。更具体地说，我们构建了自动化的自然语言原理，其中包含从属性分数中获得的信息，以便用户可以更好地理解模型的决策。实验结果表明，AMPLIFY可以在多个数据集和任务上显著提高现有语言模型的性能。

    Large Language Models (LLMs) have demonstrated remarkable capabilities in performing complex tasks. Moreover, recent research has shown that incorporating human-annotated rationales (e.g., Chain-of- Thought prompting) during in-context learning can significantly enhance the performance of these models, particularly on tasks that require reasoning capabilities. However, incorporating such rationales poses challenges in terms of scalability as this requires a high degree of human involvement. In this work, we present a novel framework, Amplifying Model Performance by Leveraging In-Context Learning with Post Hoc Explanations (AMPLIFY), which addresses the aforementioned challenges by automating the process of rationale generation. To this end, we leverage post hoc explanation methods which output attribution scores (explanations) capturing the influence of each of the input features on model predictions. More specifically, we construct automated natural language rationales that embed insi
    
[^80]: DUB: 离散单元反向翻译用于语音翻译

    DUB: Discrete Unit Back-translation for Speech Translation. (arXiv:2305.11411v1 [cs.CL])

    [http://arxiv.org/abs/2305.11411](http://arxiv.org/abs/2305.11411)

    离散单元反向翻译方法成功将有用的MT技术应用在直接ST上，平均提升了5.5 BLEU，可以缓解语音和文本之间的模态问题。

    

    如何使语音到文本翻译（ST）与机器翻译（MT）相当？关键在于弥合语音和文本之间的模态差距，使得有用的MT技术可以应用于ST。最近，用无监督离散单元表示语音方法可以缓解模态问题。这激发了我们提出了离散单元反向翻译（DUB）以回答两个问题：（1）在直接ST中，用离散单元表示语音是否比使用连续特征更好？（2）有用的MT技术可以为ST带来多少收益？通过DUB，反向翻译技术可以成功应用于直接ST，并在MuST-C En-De / Fr / Es上平均提升了5.5 BLEU。在资源受限的语言环境下，我们的方法实现了与依赖大规模外部数据的现有方法相当的性能。代码/models可在https://github.com/0nutation/DUB获取。

    How can speech-to-text translation (ST) perform as well as machine translation (MT)? The key point is to bridge the modality gap between speech and text so that useful MT techniques can be applied to ST. Recently, the approach of representing speech with unsupervised discrete units yields a new way to ease the modality problem. This motivates us to propose Discrete Unit Back-translation (DUB) to answer two questions: (1) Is it better to represent speech with discrete units than with continuous features in direct ST? (2) How much benefit can useful MT techniques bring to ST? With DUB, the back-translation technique can successfully be applied on direct ST and obtains an average boost of 5.5 BLEU on MuST-C En-De/Fr/Es. In the low-resource language scenario, our method achieves comparable performance to existing methods that rely on large-scale external data. Code and models are available at https://github.com/0nutation/DUB.
    
[^81]: AlignAtt：使用基于注意力的音频翻译对齐作为同时语音翻译的指导

    AlignAtt: Using Attention-based Audio-Translation Alignments as a Guide for Simultaneous Speech Translation. (arXiv:2305.11408v1 [cs.CL])

    [http://arxiv.org/abs/2305.11408](http://arxiv.org/abs/2305.11408)

    AlignAtt是一种新型的SimulST策略，使用基于注意力的音频翻译对齐来指导模型，在BLEU和延迟方面均优于之前的策略。

    

    注意力是当今自然语言处理中最常用的架构的核心机制，并已从许多角度进行分析，包括其在机器翻译相关任务中的有效性。在这些研究中，注意力在输入文本被替换为音频片段的情况下，也是获取有关单词对齐的有用信息的一种方式，例如语音翻译（ST）任务。在本文中，我们提出了AlignAtt，一种新颖的同时ST（SimulST）策略，它利用注意力信息来生成源-目标对齐，以在推理过程中指导模型。通过对MuST-C v1.0的8种语言对的实验，我们发现，在线下训练的模型上应用先前的最新SimulST策略，AlignAtt在BLEU方面获得了2个分数的提高，并且8种语言的延迟缩减在0.5秒到0.8秒之间。

    Attention is the core mechanism of today's most used architectures for natural language processing and has been analyzed from many perspectives, including its effectiveness for machine translation-related tasks. Among these studies, attention resulted to be a useful source of information to get insights about word alignment also when the input text is substituted with audio segments, as in the case of the speech translation (ST) task. In this paper, we propose AlignAtt, a novel policy for simultaneous ST (SimulST) that exploits the attention information to generate source-target alignments that guide the model during inference. Through experiments on the 8 language pairs of MuST-C v1.0, we show that AlignAtt outperforms previous state-of-the-art SimulST policies applied to offline-trained models with gains in terms of BLEU of 2 points and latency reductions ranging from 0.5s to 0.8s across the 8 languages.
    
[^82]: 舒适食品与社区连结：利用Twitter上的YouTube视频调查COVID-19期间的饮食变化

    Comfort Foods and Community Connectedness: Investigating Diet Change during COVID-19 Using YouTube Videos on Twitter. (arXiv:2305.11398v1 [cs.SI])

    [http://arxiv.org/abs/2305.11398](http://arxiv.org/abs/2305.11398)

    本研究利用在Twitter上的YouTube视频调查了COVID-19期间的饮食变化，发现收入较低地区的能量、脂肪和饱和脂肪摄入量下降，高糖、高蛋白和高钠的食品成为突出的话题。

    

    新冠疫情开始时空前的封锁措施已经彻底改变数百万人的日常生活方式，可能影响到重要的与健康相关的行为。本研究利用在COVID-19疫情前后发布的关于饮食、锻炼和健身的Twitter上的YouTube视频来调查疫情封锁对饮食和营养影响的因素。我们分别从视频的文字稿、描述和标题中考察所提到食物的六种营养物质（蛋白质、能量、脂肪、钠、糖和饱和脂肪）的热量值。这些营养物质值进一步与各种人口统计学数据关联起来，以评估是否会对那些可能无法获得健康食品提供特定影响。中断时间序列分析显示，在COVID-19期间，总体营养素得分出现了相当大的变化。特别是，在收入较低的地区，能量、脂肪和饱和脂肪的摄入量下降，而高糖、高蛋白和高钠的食品成为社交媒体讨论中更加突出，这可能反映了对食品偏好的变化。

    Unprecedented lockdowns at the start of the COVID-19 pandemic have drastically changed the routines of millions of people, potentially impacting important health-related behaviors. In this study, we use YouTube videos embedded in tweets about diet, exercise and fitness posted before and during COVID-19 to investigate the influence of the pandemic lockdowns on diet and nutrition. In particular, we examine the nutritional profile of the foods mentioned in the transcript, description and title of each video in terms of six macronutrients (protein, energy, fat, sodium, sugar, and saturated fat). These macronutrient values were further linked to demographics to assess if there are specific effects on those potentially having insufficient access to healthy sources of food. Interrupted time series analysis revealed a considerable shift in the aggregated macronutrient scores before and during COVID-19. In particular, whereas areas with lower incomes showed decrease in energy, fat, and saturate
    
[^83]: Fast-StrucTexT：一种带有模态引导动态标记合并的高效沙漏变压器，用于文档理解

    Fast-StrucTexT: An Efficient Hourglass Transformer with Modality-guided Dynamic Token Merge for Document Understanding. (arXiv:2305.11392v1 [cs.CV])

    [http://arxiv.org/abs/2305.11392](http://arxiv.org/abs/2305.11392)

    Fast-StrucTexT是一种高效的多模态文档理解框架，采用沙漏变压器结构和 Symmetry Cross Attention 等方法实现了多粒度表示和模态融合。

    

    变压器在文档理解方面具有很高的效果，但由于它们对序列长度的二次计算复杂度依赖，因此仍存在问题。我们提出了一种基于StrucTexT算法的高效多模态框架Fast-StrucTexT，采用沙漏变压器体系结构用于文档布局表示，设计了一个模态引导的动态标记合并块，以学习多粒度表示并修剪冗余标记。此外，我们提出了一种多模态交互模块Symmetry Cross Attention（SCA）以考虑多模态融合并有效地引导模型的学习。

    Transformers achieve promising performance in document understanding because of their high effectiveness and still suffer from quadratic computational complexity dependency on the sequence length. General efficient transformers are challenging to be directly adapted to model document. They are unable to handle the layout representation in documents, e.g. word, line and paragraph, on different granularity levels and seem hard to achieve a good trade-off between efficiency and performance. To tackle the concerns, we propose Fast-StrucTexT, an efficient multi-modal framework based on the StrucTexT algorithm with an hourglass transformer architecture, for visual document understanding. Specifically, we design a modality-guided dynamic token merging block to make the model learn multi-granularity representation and prunes redundant tokens. Additionally, we present a multi-modal interaction module called Symmetry Cross Attention (SCA) to consider multi-modal fusion and efficiently guide the 
    
[^84]: AutoTrial：用自然语言生成临床试验设计指南

    AutoTrial: Prompting Language Models for Clinical Trial Design. (arXiv:2305.11366v1 [cs.CL])

    [http://arxiv.org/abs/2305.11366](http://arxiv.org/abs/2305.11366)

    AutoTrial是一种使用语言模型自动生成临床试验纳入/排除标准的方法，它可以可控生成、可扩展学习、提供推理链，实验表明，它能够生成流畅准确的标准文本，与先进方法相媲美，但资源占用更少。

    

    临床试验对于药物开发至关重要。为患者拟定合适的纳入/排除标准是试验成功的关键。临床试验方案的正确设计应考虑到类似的先例试验及其纳入/排除标准，以确保患者的充分覆盖。本文提出了一种名为AutoTrial的方法，使用自然语言生成模型来帮助设计临床纳入/排除标准。它允许（1）通过离散和神经提示的混合进行可控的指导生成，（2）通过上下文学习进行可扩展的知识融合，以及（3）提供明确的推理链以理解输出的合理性。对超过70,000项临床试验的实验验证了AutoTrial生成的标准文本具有流畅性和连贯性，并且在捕捉目标试验相关临床概念方面准确度高。值得注意的是，我们的方法在计算资源占用更少的情况下，实现了可与最先进的方法相媲美的性能。

    Clinical trials are critical for drug development. Constructing the appropriate eligibility criteria (i.e., the inclusion/exclusion criteria for patient recruitment) is essential for the trial's success. Proper design of clinical trial protocols should consider similar precedent trials and their eligibility criteria to ensure sufficient patient coverage. In this paper, we present a method named AutoTrial to aid the design of clinical eligibility criteria using language models. It allows (1) controllable generation under instructions via a hybrid of discrete and neural prompting, (2) scalable knowledge incorporation via in-context learning, and (3) explicit reasoning chains to provide rationales for understanding the outputs. Experiments on over 70K clinical trials verify that AutoTrial generates high-quality criteria texts that are fluent and coherent and with high accuracy in capturing the relevant clinical concepts to the target trial. It is noteworthy that our method, with a much sm
    
[^85]: 大型语言模型合成文本数据集的语言多样性可视化

    Visualizing Linguistic Diversity of Text Datasets Synthesized by Large Language Models. (arXiv:2305.11364v1 [cs.CL])

    [http://arxiv.org/abs/2305.11364](http://arxiv.org/abs/2305.11364)

    该论文介绍了一种新的可视化工具，用于分析大型语言模型生成的数据集的句法多样性，可以通过分层可视化来帮助用户快速浏览概述和检查各个示例。

    

    大型语言模型（LLMs）可通过少量提示生成更精细的数据集用于基准测试、微调或其他用例。然而，理解和评估这些数据集很困难，而LLM生成数据的失败模式仍不为人们所理解。具体来说，数据可能以意外的方式变得重复，不仅语义上如此，而且在句法、词汇方面也是如此。我们提出了LinguisticLens，一种新颖的交互式可视化工具，用于理解和分析LLM生成数据集的句法多样性。 LinguisticLens沿着句法、词汇和语义轴将文本聚类。它支持文本数据集的分层可视化，允许用户快速浏览概述和检查各个示例。实时演示可在shorturl.at/zHOUV查看。

    Large language models (LLMs) can be used to generate smaller, more refined datasets via few-shot prompting for benchmarking, fine-tuning or other use cases. However, understanding and evaluating these datasets is difficult, and the failure modes of LLM-generated data are still not well understood. Specifically, the data can be repetitive in surprising ways, not only semantically but also syntactically and lexically. We present LinguisticLens, a novel inter-active visualization tool for making sense of and analyzing syntactic diversity of LLM-generated datasets. LinguisticLens clusters text along syntactic, lexical, and semantic axes. It supports hierarchical visualization of a text dataset, allowing users to quickly scan for an overview and inspect individual examples. The live demo is available at shorturl.at/zHOUV.
    
[^86]: MD3: 一个多方言对话数据集

    MD3: The Multi-Dialect Dataset of Dialogues. (arXiv:2305.11355v1 [cs.CL])

    [http://arxiv.org/abs/2305.11355](http://arxiv.org/abs/2305.11355)

    MD3是一个新的多方言对话数据集，包含来自印度、尼日利亚和美国的英语方言，通过提示参与者执行信息共享任务实现了开放对话语音和面向任务的对话之间的平衡。研究发现了不同方言在句法和语篇标记的使用上的显著差异。

    

    我们介绍了一个新的对话语音数据集，包含来自印度、尼日利亚和美国的英语方言。多方言对话数据集（MD3）通过提示参与者执行一系列短信息共享任务，实现了开放对话语音和面向任务的对话之间的新平衡。这有助于定量的跨方言比较，同时避免了对抑制方言特征表达的限制性任务结构的强加。对数据集的初步分析显示，不同方言在句法和语篇标记的使用上存在显著差异。数据集将随着本文的发表而公开发布，包括超过20个小时的音频和超过200,000个拼写转录标记。

    We introduce a new dataset of conversational speech representing English from India, Nigeria, and the United States. The Multi-Dialect Dataset of Dialogues (MD3) strikes a new balance between open-ended conversational speech and task-oriented dialogue by prompting participants to perform a series of short information-sharing tasks. This facilitates quantitative cross-dialectal comparison, while avoiding the imposition of a restrictive task structure that might inhibit the expression of dialect features. Preliminary analysis of the dataset reveals significant differences in syntax and in the use of discourse markers. The dataset, which will be made publicly available with the publication of this paper, includes more than 20 hours of audio and more than 200,000 orthographically-transcribed tokens.
    
[^87]: 有条件生成模型中的数据编辑

    Data Redaction from Conditional Generative Models. (arXiv:2305.11351v1 [cs.LG])

    [http://arxiv.org/abs/2305.11351](http://arxiv.org/abs/2305.11351)

    本文研究如何对已训练好的条件生成模型进行后期编辑，以便编辑掉某些条件分支，这些条件分支很可能会生成不良内容。通过精简模型中的条件网络实现，提出的解决方案有效、高效、具有可控性和普适性，在文本到图像和文本到语音生成模型中取得了良好效果。

    

    深度生成模型因生成不良内容而受到批评。传统的缓解方法包括重新训练、过滤或编辑；然而这些方法要么计算成本高，要么会被第三方回避。本文提出一种不同的方法，研究如何后期编辑已经训练好的条件生成模型，使其编辑掉某些条件分支，这些条件分支很可能会生成不良内容。这是通过精简模型中的条件网络来实现的，提出的解决方案既有效又高效、具有可控性和普适性，能用于一类深度生成模型。我们在文本到图像生成模型和文本到语音生成模型中进行了数据编辑实验，并表明我们的方法计算成本较低，相比基线方法具有更好的编辑质量和鲁棒性，同时仍保持高生成质量。

    Deep generative models are known to produce undesirable samples such as harmful content. Traditional mitigation methods include re-training from scratch, filtering, or editing; however, these are either computationally expensive or can be circumvented by third parties. In this paper, we take a different approach and study how to post-edit an already-trained conditional generative model so that it redacts certain conditionals that will, with high probability, lead to undesirable content. This is done by distilling the conditioning network in the models, giving a solution that is effective, efficient, controllable, and universal for a class of deep generative models. We conduct experiments on redacting prompts in text-to-image models and redacting voices in text-to-speech models. Our method is computationally light, leads to better redaction quality and robustness than baseline methods while still retaining high generation quality.
    
[^88]: 无监督跨领域的多模态弱信号假新闻检测

    Unsupervised Domain-agnostic Fake News Detection using Multi-modal Weak Signals. (arXiv:2305.11349v1 [cs.LG])

    [http://arxiv.org/abs/2305.11349](http://arxiv.org/abs/2305.11349)

    本文提出了一种新的、无需监督、跨领域的虚假新闻检测框架，通过嵌入多模态信息和自监督学习技术实现，同时还提出了一种新的数据集构建技术，有效避免了现有数据集中的潜在偏见。

    

    社交媒体作为人们获取新闻的主要平台之一的出现，促进了虚假新闻的广泛传播。这激发了大量的自动化识别虚假新闻的研究。尽管已经有了一些未经监督的虚假新闻检测尝试，但它们的性能受到未利用与新闻记录相关的各种模态知识和现有新闻数据集中存在的各种潜在偏见的影响。为了解决这些问题，本文提出了一种有效的无监督虚假新闻检测框架，首先将新闻记录中四种模态的知识嵌入，然后提出一种新颖的噪声鲁棒的自监督学习技术，从多模态嵌入中识别新闻记录的真实性。此外，我们提出了一种新颖的构建新闻数据集的技术，最小化现有新闻数据集中的潜在偏见。按照所提出的数据集构建方法，我们制作一个基于语言的新闻数据集，用于评估所提出的框架的有效性。我们的实验表明，所提出的框架显著优于最先进的无监督虚假新闻检测技术。

    The emergence of social media as one of the main platforms for people to access news has enabled the wide dissemination of fake news. This has motivated numerous studies on automating fake news detection. Although there have been limited attempts at unsupervised fake news detection, their performance suffers due to not exploiting the knowledge from various modalities related to news records and due to the presence of various latent biases in the existing news datasets. To address these limitations, this work proposes an effective framework for unsupervised fake news detection, which first embeds the knowledge available in four modalities in news records and then proposes a novel noise-robust self-supervised learning technique to identify the veracity of news records from the multi-modal embeddings. Also, we propose a novel technique to construct news datasets minimizing the latent biases in existing news datasets. Following the proposed approach for dataset construction, we produce a L
    
[^89]: 以公平名义：评估临床记录去识别中的偏见

    In the Name of Fairness: Assessing the Bias in Clinical Record De-identification. (arXiv:2305.11348v1 [cs.LG])

    [http://arxiv.org/abs/2305.11348](http://arxiv.org/abs/2305.11348)

    本文研究了临床记录去识别系统在不同人口群体中的表现差异，揭示了其在名称去识别方面存在显著的偏见。

    

    数据共享对于开放科学和可重复研究至关重要，但合法共享临床数据需要从电子健康记录中删除受保护的健康信息。这个过程，称为去识别，通常通过许多商业和开源系统使用机器学习算法来实现。虽然这些系统在平均水平上已经显示出令人信服的结果，但它们在不同的人口群体中的表现差异还没有得到彻底的检查。在这项工作中，我们通过大规模实证分析，研究了临床笔记中的名称去识别系统的偏见。为了实现这一目的，我们创建了16个名称集，涵盖了四个人口统计学维度：性别、种族、名称流行度和流行的十年。我们将这些名称插入到100个手动筛选的临床模板中，并评估了九种公共和私人去识别方法的性能。我们的发现表明，在临床记录去识别系统的名称方面存在统计显著的偏见。

    Data sharing is crucial for open science and reproducible research, but the legal sharing of clinical data requires the removal of protected health information from electronic health records. This process, known as de-identification, is often achieved through the use of machine learning algorithms by many commercial and open-source systems. While these systems have shown compelling results on average, the variation in their performance across different demographic groups has not been thoroughly examined. In this work, we investigate the bias of de-identification systems on names in clinical notes via a large-scale empirical analysis. To achieve this, we create 16 name sets that vary along four demographic dimensions: gender, race, name popularity, and the decade of popularity. We insert these names into 100 manually curated clinical templates and evaluate the performance of nine public and private de-identification methods. Our findings reveal that there are statistically significant p
    
[^90]: 编写自己的书：一种从闭合到开放式书本QA的方法，改善较小LLM的健壮性和性能。

    Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs. (arXiv:2305.11334v1 [cs.CL])

    [http://arxiv.org/abs/2305.11334](http://arxiv.org/abs/2305.11334)

    本文介绍了两种新颖的方法，Tree-Search和自我上下文QA，可提高大型语言模型在问答任务中的性能。Tree-Search采样技术有助于从提示中提取多样化信息，而自我上下文QA可使模型创建自己的上下文，生成更好的开放式答案。此外，这些方法可提高健壮性和性能。

    

    我们介绍了两种新颖的方法，Tree-Search和自我上下文QA，旨在提高大型语言模型（LLMs）在问答任务中的性能。 Tree-Search是一种采样技术，专门用于从给定提示的LLM中提取多样化的信息。自我上下文QA利用Tree-Search，使模型能够使用与提示相关的各种信息创建自己的上下文，明确评估并返回初始提示的开放式答案。我们证明了按照各种指标（包括GPT3.5（text-davinci-003）评估的准确性、信息量、连贯性和一致性）评估的生成答案质量得到了改善。此外，我们表明，我们的方法导致了增加的健壮性，并且性能与树大小呈正相关，从而有益于答案质量和健壮性。最后，我们讨论了Tree-Search的其他有 promising 应用，突出了其提高较小LLM健壮性和性能的潜力。

    We introduce two novel methods, Tree-Search and Self-contextualizing QA, designed to enhance the performance of large language models (LLMs) in question-answering tasks. Tree-Search is a sampling technique specifically created to extract diverse information from an LLM for a given prompt. Self-contextualizing QA leverages Tree-Search to enable the model to create its own context using a wide range of information relevant to the prompt, evaluate it explicitly and return a open book answer to the initial prompt . We demonstrate that the quality of generated answers improves according to various metrics, including accuracy, informativeness, coherence, and consistency, as evaluated by GPT3.5(text-davinci-003). Furthermore, we show that our methods result in increased robustness and that performance is positively correlated with tree size, benefiting both answer quality and robustness. Finally, we discuss other promising applications of Tree-Search, highlighting its potential to enhance a b
    
[^91]: 自动生成会话接口以便于探索表格数据

    Towards the Automatic Generation of Conversational Interfaces to Facilitate the Exploration of Tabular Data. (arXiv:2305.11326v1 [cs.CL])

    [http://arxiv.org/abs/2305.11326](http://arxiv.org/abs/2305.11326)

    本文提出了使用聊天机器人作为自动化创造的会话接口来方便大众探索表格数据的方法。

    

    表格数据是在线发布和交换结构化数据的最常见格式。一个明确的例子是各种类型的公共行政机构发布的开放数据门户数量的增长。但是，这些数据源的利用目前仅限于能够以程序方式处理和消化此类数据的技术人员。作为替代方案，我们建议使用聊天机器人提供会话接口，以便于探索表格数据源。通过我们的方法，任何普通公民都可以从中受益并利用它们。此外，我们的聊天机器人不是手动创建的：相反，它们是通过实例化可配置的对话模式集从数据源本身自动生成的。

    Tabular data is the most common format to publish and exchange structured data online. A clear example is the growing number of open data portals published by all types of public administrations. However, exploitation of these data sources is currently limited to technical people able to programmatically manipulate and digest such data. As an alternative, we propose the use of chatbots to offer a conversational interface to facilitate the exploration of tabular data sources. With our approach, any regular citizen can benefit and leverage them. Moreover, our chatbots are not manually created: instead, they are automatically generated from the data source itself thanks to the instantiation of a configurable collection of conversation patterns.
    
[^92]: 合作生成AI：集成GPT-k以在文本到图像生成中提高编辑效率

    Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation. (arXiv:2305.11317v1 [cs.CL])

    [http://arxiv.org/abs/2305.11317](http://arxiv.org/abs/2305.11317)

    本论文通过集成GPT-k来提高T2I生成中的编辑效率，实验证明其更擅长调整（修改）文本中的修饰语，而人类倾向于替换单词和短语。

    

    文本到图像（T2I）生成领域在研究界和用户中引起了极大关注。虽然T2I模型已经取得了很大进展，但用户常遇到的一个问题是需要重复编辑输入提示才能获得令人满意的图像，这是耗时且劳动强度大的。针对大规模语言模型（例如GPT-k）的文本生成能力，我们研究了利用这些模型来改进T2I生成中提示编辑过程的潜力。我们进行了一系列实验，比较了人类和GPT-k常见的编辑方式，评估GPT-k在推动T2I方面的性能，并检查可能影响此过程的因素。我们发现，GPT-k模型更注重插入修改器，而人类倾向于替换单词和短语，包括对主题的更改。实验结果显示，GPT-k在调整修改器方面比较有效。

    The field of text-to-image (T2I) generation has garnered significant attention both within the research community and among everyday users. Despite the advancements of T2I models, a common issue encountered by users is the need for repetitive editing of input prompts in order to receive a satisfactory image, which is time-consuming and labor-intensive. Given the demonstrated text generation power of large-scale language models, such as GPT-k, we investigate the potential of utilizing such models to improve the prompt editing process for T2I generation. We conduct a series of experiments to compare the common edits made by humans and GPT-k, evaluate the performance of GPT-k in prompting T2I, and examine factors that may influence this process. We found that GPT-k models focus more on inserting modifiers while humans tend to replace words and phrases, which includes changes to the subject matter. Experimental results show that GPT-k are more effective in adjusting modifiers rather than p
    
[^93]: 通过改进候选生成，基于Transformer的重新排序和两阶段解析方法来提高地名解析能力

    Improving Toponym Resolution with Better Candidate Generation, Transformer-based Reranking, and Two-Stage Resolution. (arXiv:2305.11315v1 [cs.CL])

    [http://arxiv.org/abs/2305.11315](http://arxiv.org/abs/2305.11315)

    本文提出了一种名为GeoNorm的地理编码框架。通过生成和重新排序两次解析地名，GeoNorm在解析任务上表现优异。其中改进的候选生成和基于Transformer的重新排序是创新之处。

    

    地理编码是将文本中的位置提及转换为编码地理空间语义的结构化数据的任务。我们提出了一种新的地理编码架构GeoNorm。GeoNorm首先使用信息检索技术从地理本体中生成候选条目列表，然后使用基于Transformer的神经网络从本体中获取信息(如条目人口)对候选条目进行重新排序。这个生成和重新排序过程应用了两次:首先解决不太含糊的国家，州和县，然后解决其余的位置提及，使用已确定的国家、州和县级信息作为上下文。我们提出的地名解析框架在多个数据集上实现了最先进的性能。代码和模型可在 \url{https://github.com/clulab/geonorm}找到。

    Geocoding is the task of converting location mentions in text into structured data that encodes the geospatial semantics. We propose a new architecture for geocoding, GeoNorm. GeoNorm first uses information retrieval techniques to generate a list of candidate entries from the geospatial ontology. Then it reranks the candidate entries using a transformer-based neural network that incorporates information from the ontology such as the entry's population. This generate-and-rerank process is applied twice: first to resolve the less ambiguous countries, states, and counties, and second to resolve the remaining location mentions, using the identified countries, states, and counties as context. Our proposed toponym resolution framework achieves state-of-the-art performance on multiple datasets. Code and models are available at \url{https://github.com/clulab/geonorm}.
    
[^94]: 面向情境对话中的心智建模，实现协同计划获取

    Towards Collaborative Plan Acquisition through Theory of Mind Modeling in Situated Dialogue. (arXiv:2305.11271v1 [cs.AI])

    [http://arxiv.org/abs/2305.11271](http://arxiv.org/abs/2305.11271)

    本文提出了一种协作计划获取方法，通过丰富的感知和对话历史，让代理人预测他们自己和合作伙伴缺失的任务知识，实现联合任务的完整计划获取。

    

    协作任务通常始于双方拥有不完全的任务知识和不完整的初始计划。为完成这些任务，代理人需要与合作伙伴进行实地交流，并协调他们的部分计划以实现联合任务目标。虽然这种协作在人与人的团队中似乎轻而易举，但对于人工智能的协作来说却具有很高的挑战性。为解决这个问题，本文提出了一种协作计划获取的方法，其中人类和代理人努力学习并相互交流，以获取联合任务的完整计划。具体地，本文提出了一种新颖的问题，让代理人基于丰富的感知和对话历史，预测他们自己和合作伙伴缺失的任务知识。我们在一个三维方块世界的对称协作任务中扩展了一个情境对话基准，并研究了计划获取的计算策略。我们的实证结果表明，预测任务知识是计划获取过程中的重点。

    Collaborative tasks often begin with partial task knowledge and incomplete initial plans from each partner. To complete these tasks, agents need to engage in situated communication with their partners and coordinate their partial plans towards a complete plan to achieve a joint task goal. While such collaboration seems effortless in a human-human team, it is highly challenging for human-AI collaboration. To address this limitation, this paper takes a step towards collaborative plan acquisition, where humans and agents strive to learn and communicate with each other to acquire a complete plan for joint tasks. Specifically, we formulate a novel problem for agents to predict the missing task knowledge for themselves and for their partners based on rich perceptual and dialogue history. We extend a situated dialogue benchmark for symmetric collaborative tasks in a 3D blocks world and investigate computational strategies for plan acquisition. Our empirical results suggest that predicting the
    
[^95]: CHBias: 中文对话语言模型的偏差评估与缓解

    CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models. (arXiv:2305.11262v1 [cs.CL])

    [http://arxiv.org/abs/2305.11262](http://arxiv.org/abs/2305.11262)

    本文介绍了一个新的中文数据集，CHBias，用于评估和缓解中文对话语言模型的偏见。实验结果表明，这些中文预训练模型可能会产生含有偏见的文本。

    

    预训练的对话代理已被暴露出安全问题，表现出一系列刻板化的人类偏见，例如性别偏见。然而，在当前研究中仍存在有限的偏见类别，而且大部分只针对英文。在本文中，我们介绍了一个新的中文数据集 CHBias，用于评估和缓解中文对话语言模型的偏见。除了之前已经深入研究的偏见类别外，CHBias包括了一些不太受关注的偏见类别，例如年龄歧视和外貌偏见。我们利用 CHBias 评估了两个流行的中文预训练对话模型 CDial-GPT 和 EVA2.0。此外，为了缓解不同的偏见，我们采用了几种去偏方法来处理中文预训练模型。实验结果表明，这些中文预训练模型可能会产生含有偏见的文本。

    \textit{\textbf{\textcolor{red}{Warning}:} This paper contains content that may be offensive or upsetting.} Pretrained conversational agents have been exposed to safety issues, exhibiting a range of stereotypical human biases such as gender bias. However, there are still limited bias categories in current research, and most of them only focus on English. In this paper, we introduce a new Chinese dataset, CHBias, for bias evaluation and mitigation of Chinese conversational language models. Apart from those previous well-explored bias categories, CHBias includes under-explored bias categories, such as ageism and appearance biases, which received less attention. We evaluate two popular pretrained Chinese conversational models, CDial-GPT and EVA2.0, using CHBias. Furthermore, to mitigate different biases, we apply several debiasing methods to the Chinese pretrained models. Experimental results show that these Chinese pretrained models are potentially risky for generating texts that contain
    
[^96]: 基于思维链索引的隐式情感推断

    Reasoning Implicit Sentiment with Chain-of-Thought Prompting. (arXiv:2305.11255v1 [cs.CL])

    [http://arxiv.org/abs/2305.11255](http://arxiv.org/abs/2305.11255)

    本研究提出了一种基于思维链索引的隐式情感推断框架（THOR），通过三次跳推理模仿类人推理过程，支持常识和多跳推理以推断意见的潜在意图，并逐步诱导隐式方面、意见和最终情感极性，实现了在监督和零样本设置上大幅提高技术水平。

    

    情感分析系统通过分析输入文本中的关键观点表达来确定给定目标的情感极性，而在隐式情感分析（ISA）中，观点提示以一种隐含和模糊的方式出现。因此，检测隐式情感需要常识和多跳推理能力来推断意见的潜在意图。受最近思维链索引（CoT）思想的启发，本研究介绍了一种三次跳推理（THOR）CoT框架，模仿ISA的类人推理过程。我们为THOR设计了一个三步提示原则，以逐步诱导隐式方面、意见和最终情感极性。我们的THOR+Flan-T5（11B）在监督设置上将技术水平推进了超过6％的F1值。更为显著的是，THOR+GPT3（175B）在零样本设置上将技术水平提升了超过50％的F1值。我们的代码位于https://github.com/scofield7419/THOR-ISA 。

    While sentiment analysis systems try to determine the sentiment polarities of given targets based on the key opinion expressions in input texts, in implicit sentiment analysis (ISA) the opinion cues come in an implicit and obscure manner. Thus detecting implicit sentiment requires the common-sense and multi-hop reasoning ability to infer the latent intent of opinion. Inspired by the recent chain-of-thought (CoT) idea, in this work we introduce a Three-hop Reasoning (THOR) CoT framework to mimic the human-like reasoning process for ISA. We design a three-step prompting principle for THOR to step-by-step induce the implicit aspect, opinion, and finally the sentiment polarity. Our THOR+Flan-T5 (11B) pushes the state-of-the-art (SoTA) by over 6% F1 on supervised setup. More strikingly, THOR+GPT3 (175B) boosts the SoTA by over 50% F1 on zero-shot setting. Our code is at https://github.com/scofield7419/THOR-ISA.
    
[^97]: 计算主题学：比较文学小说样本聚类算法

    Computational thematics: Comparing algorithms for clustering the genres of literary fiction. (arXiv:2305.11251v1 [cs.CL])

    [http://arxiv.org/abs/2305.11251](http://arxiv.org/abs/2305.11251)

    本文比较了多种算法用于无监督学习文本之间的主题相似性，发现在采用“词频-逆文档频率”文本特征提取方法和“余弦相似度”距离度量方法的组合下，文本聚类的效果最好。

    

    如何捕捉文学文本之间的主题相似性？ 本文对文本的前处理、特征提取和特征列表之间的距离测量等三个步骤的各种算法进行比较，以学习计算主题分析的最佳组合。我们发现，在使用“词频-逆文档频率”（TF-IDF）文本特征提取方法和“余弦相似度”距离度量方法的组合下，文本聚类的最有效方法得以实现。本文的研究结果为从事计算主题分析的人们提供了一些参考意见。

    What are the best methods of capturing thematic similarity between literary texts? Knowing the answer to this question would be useful for automatic clustering of book genres, or any other thematic grouping. This paper compares a variety of algorithms for unsupervised learning of thematic similarities between texts, which we call "computational thematics". These algorithms belong to three steps of analysis: text preprocessing, extraction of text features, and measuring distances between the lists of features. Each of these steps includes a variety of options. We test all the possible combinations of these options: every combination of algorithms is given a task to cluster a corpus of books belonging to four pre-tagged genres of fiction. This clustering is then validated against the "ground truth" genre labels. Such comparison of algorithms allows us to learn the best and the worst combinations for computational thematic analysis. To illustrate the sharp difference between the best and 
    
[^98]: 一种参数高效的学习方法，用于带有预训练通用语音模型的阿拉伯方言识别

    A Parameter-Efficient Learning Approach to Arabic Dialect Identification with Pre-Trained General-Purpose Speech Model. (arXiv:2305.11244v1 [cs.CL])

    [http://arxiv.org/abs/2305.11244](http://arxiv.org/abs/2305.11244)

    本文介绍了一种利用预训练通用语音模型进行阿拉伯方言识别的参数高效学习方法，通过残差适配器和模型重编程，设计了一个基于记号的标签映射，并在ADI-17数据集上实现了最高精度，同时使用PEL方法进一步减少了训练成本。

    

    本文研究了参数高效学习（PEL）技术，以重新利用通用语音模型（GSM）进行阿拉伯方言识别（ADI）。我们设计了一个基于记号的标签映射，将GSM适应于阿拉伯方言识别，通过残差适配器和模型重编程来实现。我们通过vanilla fine-tuning在ADI-17数据集上实现了新的最高精度。此外，我们通过PEL方法进一步减少了训练成本，使用额外2.5％的网络可训练参数即可达到fine-tuning精度的1.86％。我们的研究展示了如何使用小型数据集和有限的计算资源来识别阿拉伯方言。

    In this work, we explore Parameter-Efficient-Learning (PEL) techniques to repurpose a General-Purpose-Speech (GSM) model for Arabic dialect identification (ADI). Specifically, we investigate different setups to incorporate trainable features into a multi-layer encoder-decoder GSM formulation under frozen pre-trained settings. Our architecture includes residual adapter and model reprogramming (input-prompting). We design a token-level label mapping to condition the GSM for Arabic Dialect Identification (ADI). This is challenging due to the high variation in vocabulary and pronunciation among the numerous regional dialects. We achieve new state-of-the-art accuracy on the ADI-17 dataset by vanilla fine-tuning. We further reduce the training budgets with the PEL method, which performs within 1.86% accuracy to fine-tuning using only 2.5% of (extra) network trainable parameters. Our study demonstrates how to identify Arabic dialects using a small dataset and limited computation with open sou
    
[^99]: 比较机器和儿童：使用发展心理学实验评估LaMDA响应的优势和劣势

    Comparing Machines and Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA Responses. (arXiv:2305.11243v1 [cs.CL])

    [http://arxiv.org/abs/2305.11243](http://arxiv.org/abs/2305.11243)

    使用儿童发展实验来评估人工智能的计算能力，同时比较LLMs和儿童可以帮助我们开发更具人类特征和可解释性的机器学习模型。

    

    发展心理学家花费了几十年的时间设计实验来测试婴儿和儿童的智力和知识，追溯重要概念和能力的起源。我们认为，使用儿童发展的经典实验是探究人工智能模型的计算能力，尤其是LLM模型的最有效的方式之一。其次，将LLM与儿童进行比较可以帮助我们开发更具有人类特点和可解释性的机器学习模型，使它们能够嵌入到需要与人交互的实际环境中。

    Developmental psychologists have spent decades devising experiments to test the intelligence and knowledge of infants and children, tracing the origin of crucial concepts and capacities. Moreover, experimental techniques in developmental psychology have been carefully designed to discriminate the cognitive capacities that underlie particular behaviors. We propose that using classical experiments from child development is a particularly effective way to probe the computational abilities of AI models, in general, and LLMs in particular. First, the methodological techniques of developmental psychology, such as the use of novel stimuli to control for past experience or control conditions to determine whether children are using simple associations, can be equally helpful for assessing the capacities of LLMs. In parallel, testing LLMs in this way can tell us whether the information that is encoded in text is sufficient to enable particular responses, or whether those responses depend on othe
    
[^100]: 在多种语言中比较偏见及多语言训练的影响

    Comparing Biases and the Impact of Multilingual Training across Multiple Languages. (arXiv:2305.11242v1 [cs.CL])

    [http://arxiv.org/abs/2305.11242](http://arxiv.org/abs/2305.11242)

    本研究分析意大利语、中文、英语、希伯来语和西班牙语的偏见相似性和差异，同时调查了多语言与单语言训练数据的影响。

    

    自然语言处理中有关偏见和公平的研究主要考察单个语言内和/或跨少数属性（如性别，种族）的社会偏见。然而，对于单个属性，偏见可能在各种语言中表现出不同的方式。因此，有必要检查每种语言和属性内部的偏见。同样重要的是研究这些偏见在语言之间的差异以及在多语言数据和单语言数据上训练模型时这些偏见的影响。我们在意大利语、中文、英语、希伯来语和西班牙语之间对下游情感分析任务进行了偏见分析，以观察特定人口群体是否被更积极地看待。我们研究了这些语言之间的偏见相似性和差异，并调查了多语言与单语言训练数据的影响。我们将现有的英文情感偏见模板适应到意大利语、中文、希伯来语和西班牙语中，包括四个属性：种族、宗教、国籍和性别。

    Studies in bias and fairness in natural language processing have primarily examined social biases within a single language and/or across few attributes (e.g. gender, race). However, biases can manifest differently across various languages for individual attributes. As a result, it is critical to examine biases within each language and attribute. Of equal importance is to study how these biases compare across languages and how the biases are affected when training a model on multilingual data versus monolingual data. We present a bias analysis across Italian, Chinese, English, Hebrew, and Spanish on the downstream sentiment analysis task to observe whether specific demographics are viewed more positively. We study bias similarities and differences across these languages and investigate the impact of multilingual vs. monolingual training data. We adapt existing sentiment bias templates in English to Italian, Chinese, Hebrew, and Spanish for four attributes: race, religion, nationality, a
    
[^101]: 无监督摘要的最新趋势

    Recent Trends in Unsupervised Summarization. (arXiv:2305.11231v1 [cs.CL])

    [http://arxiv.org/abs/2305.11231](http://arxiv.org/abs/2305.11231)

    本文综述了无监督摘要的最新技术和模型，包括抽取式、生成式和混合模型，并提出了一个基于方法的分类法。本文还介绍了一些数据集和评估方法。

    

    无监督摘要是一种强大的技术，可以在不需要标记数据集的情况下训练摘要模型。本综述涵盖了用于无监督摘要的不同技术和模型。我们涵盖了抽取式、生成式和混合模型以及用于实现无监督摘要的策略。尽管本综述的主要重点是最新研究，但我们也介绍了一些重要的以前的研究。我们还引入了一个分类法，根据研究对无监督训练的方法进行分类。最后，我们讨论了当前的方法，并提到了一些数据集和评估方法。

    Unsupervised summarization is a powerful technique that enables training summarizing models without requiring labeled datasets. This survey covers different recent techniques and models used for unsupervised summarization. We cover extractive, abstractive, and hybrid models and strategies used to achieve unsupervised summarization. While the main focus of this survey is on recent research, we also cover some of the important previous research. We additionally introduce a taxonomy, classifying different research based on their approach to unsupervised training. Finally, we discuss the current approaches and mention some datasets and evaluation methods.
    
[^102]: LIMA: 对齐的更少即为更优（Less Is More for Alignment）

    LIMA: Less Is More for Alignment. (arXiv:2305.11206v1 [cs.CL])

    [http://arxiv.org/abs/2305.11206](http://arxiv.org/abs/2305.11206)

    该论文介绍了一种使用无声调学习预训练语言模型和标准监督损失微调的方法（不使用强化学习或人类模型），并展示了在复杂任务上也有出色的表现。

    

    大型语言模型的训练通常分为两个阶段：(1)无监督的原始文本预训练，以学习通用表示；(2)大规模的指令微调和强化学习，以更好地对齐最终任务和用户偏好。我们通过训练LIMA，一个使用标准监督损失值进行的65B参数LLaMa语言模型，仅使用1000个经过筛选的提示和回复进行微调，而不使用任何强化学习或人类偏好建模，衡量了这两个阶段之间的相对重要性。 LIMA表现出了极强的性能，仅从训练数据中的少量示例中学习到如何遵循特定的响应格式，包括从规划旅行行程到推测替代历史的复杂查询。此外，该模型倾向于良好地推广到未在训练数据中出现的任务中。在一项控制的人类研究中，与GPT-4相比，LIMA的响应在43%的情况下等效或严格优先。

    Large language models are trained in two stages: (1) unsupervised pretraining from raw text, to learn general-purpose representations, and (2) large scale instruction tuning and reinforcement learning, to better align to end tasks and user preferences. We measure the relative importance of these two stages by training LIMA, a 65B parameter LLaMa language model fine-tuned with the standard supervised loss on only 1,000 carefully curated prompts and responses, without any reinforcement learning or human preference modeling. LIMA demonstrates remarkably strong performance, learning to follow specific response formats from only a handful of examples in the training data, including complex queries that range from planning trip itineraries to speculating about alternate history. Moreover, the model tends to generalize well to unseen tasks that did not appear in the training data. In a controlled human study, responses from LIMA are either equivalent or strictly preferred to GPT-4 in 43% of c
    
[^103]: 压缩，然后提示：使用可转移提示来改善LLM推理的准确性和效率平衡

    Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt. (arXiv:2305.11186v1 [cs.CL])

    [http://arxiv.org/abs/2305.11186](http://arxiv.org/abs/2305.11186)

    本文提出了使用可转移提示来优化压缩的LLMs的准确性和效率的平衡问题。该方法通过选择精度更高的提示显著提高了压缩的LLM在特定查询方面的生成质量，并实现了4倍推理时间加速。

    

    大型语言模型（LLMs）具有数十亿的参数，表现出在各种自然语言处理（NLP）任务中的卓越性能。然而，它们在推理过程中会带来显着的计算挑战，尤其是在常见的硬件上部署（例如单个GPU）时。因此，通过压缩来最小化LLM推理的延迟，即减少计算和内存需求，变得至关重要。但是，此过程必然引发效率和精度之间的平衡，因为压缩的LLMs通常会经历预测精度下降。在这项研究中，我们提出了一个创新的视角：为了优化这种平衡，压缩的LLMs需要一种不同于原始模型的独特输入格式。我们的研究结果表明，通过选择具有精度的提示，可以显著改善压缩的LLM在特定查询方面的生成质量。基于这一发现，我们提出了一个可转移提示的方法，该方法训练模型预测有效提示。实证上，我们的方法可以在各种语言任务上生成高质量的输出，并实现了4倍速度的推理时间加速，同时保持竞争性的准确性。

    Large Language Models (LLMs), armed with billions of parameters, exhibit exceptional performance across a wide range of Natural Language Processing (NLP) tasks. However, they present a significant computational challenge during inference, especially when deploying on common hardware such as single GPUs. As such, minimizing the latency of LLM inference by curtailing computational and memory requirements, though achieved through compression, becomes critically important. However, this process inevitably instigates a trade-off between efficiency and accuracy, as compressed LLMs typically experience a reduction in predictive precision. In this research, we introduce an innovative perspective: to optimize this trade-off, compressed LLMs require a unique input format that varies from that of the original models. Our findings indicate that the generation quality in a compressed LLM can be markedly improved for specific queries by selecting prompts with precision. Capitalizing on this insight,
    
[^104]: 通过框嵌入和概率评分器完成分类法

    Taxonomy Completion with Probabilistic Scorer via Box Embedding. (arXiv:2305.11004v1 [cs.CL])

    [http://arxiv.org/abs/2305.11004](http://arxiv.org/abs/2305.11004)

    本文提出了一种新方法TaxBox，该方法将分类法概念映射到框嵌入中，并使用两个概率评分器来进行概念附加和插入，避免使用伪叶。实验表明，在二个基准数据集上，TaxBox在准确性和训练效率方面显著优于现有的方法。

    

    最近，分类法的完善任务--自动利用新的概念丰富现有分类法--已经引起了广泛的兴趣。早期的研究引入了复杂模块、外部信息和伪叶来丰富表示并统一附加和插入的匹配过程。虽然它们已经取得了良好的性能，但这些介绍可能会在训练和评分过程中带来噪音和不公平性。在本文中，我们提出了TaxBox，一种新颖的用于完成分类法的框架，它将分类法概念映射到框嵌入中，并使用两个概率评分器来进行概念附加和插入，避免使用伪叶。具体而言，TaxBox由三个组件组成：（1）图聚合模块，以利用分类法的结构信息和两个轻量级解码器，将特征映射到框嵌入，并捕捉概念之间的复杂关系；（2）两个概率评分器，分别对应附加和插入任务，设计了一种原则性方法来减轻误导信息的影响；（3）一种联合训练模型和优化两个评分器的训练算法。我们在两个基准数据集上的实验表明，TaxBox在准确性和训练效率方面显著优于现有的状态-of-the-art方法。

    Taxonomy completion, a task aimed at automatically enriching an existing taxonomy with new concepts, has gained significant interest in recent years. Previous works have introduced complex modules, external information, and pseudo-leaves to enrich the representation and unify the matching process of attachment and insertion. While they have achieved good performance, these introductions may have brought noise and unfairness during training and scoring. In this paper, we present TaxBox, a novel framework for taxonomy completion that maps taxonomy concepts to box embeddings and employs two probabilistic scorers for concept attachment and insertion, avoiding the need for pseudo-leaves. Specifically, TaxBox consists of three components: (1) a graph aggregation module to leverage the structural information of the taxonomy and two lightweight decoders that map features to box embedding and capture complex relationships between concepts; (2) two probabilistic scorers that correspond to attach
    
[^105]: SpeechGPT: 用本质跨模态会话能力赋能大型语言模型

    SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities. (arXiv:2305.11000v1 [cs.CL])

    [http://arxiv.org/abs/2305.11000](http://arxiv.org/abs/2305.11000)

    SpeechGPT是一个具有本质跨模态会话能力的大型语言模型，能够感知和生成多模态内容，可按照多模态人类指令的能力，并突显了使用一个模型处理多个模态的潜力。

    

    多模态大型语言模型被认为是迈向人工通用智能（AGI）的重要一步，随着ChatGPT的出现，它们已经引起了广泛的关注。然而，目前的语音-语言模型通常采用级联范式，阻止了跨模态知识的转移。在本文中，我们提出了SpeechGPT，这是一个具有本质跨模态会话能力的大型语言模型，能够感知和生成多模态内容。通过离散化的语音表示，我们首先构建了SpeechInstruct，一个大规模的跨模态语音指令数据集。此外，我们采用了三阶段的训练策略，包括模态自适应预训练、跨模态指令微调和模态链指令微调。实验结果表明，SpeechGPT具有按照多模态人类指令的能力，并突显了使用一个模型处理多个模态的潜力。

    Multi-modal large language models are regarded as a crucial step towards Artificial General Intelligence (AGI) and have garnered significant interest with the emergence of ChatGPT. However, current speech-language models typically adopt the cascade paradigm, preventing inter-modal knowledge transfer. In this paper, we propose SpeechGPT, a large language model with intrinsic cross-modal conversational abilities, capable of perceiving and generating multi-model content. With discrete speech representations, we first construct SpeechInstruct, a large-scale cross-modal speech instruction dataset. Additionally, we employ a three-stage training strategy that includes modality-adaptation pre-training, cross-modal instruction fine-tuning, and chain-of-modality instruction fine-tuning. The experimental results demonstrate that SpeechGPT has an impressive capacity to follow multi-modal human instructions and highlight the potential of handling multiple modalities with one model. Demos are shown 
    
[^106]: 利用数据增强提高低资源语音识别的性能

    Making More of Little Data: Improving Low-Resource Automatic Speech Recognition Using Data Augmentation. (arXiv:2305.10951v1 [cs.CL])

    [http://arxiv.org/abs/2305.10951](http://arxiv.org/abs/2305.10951)

    本研究探究了利用数据增强技术，特别是自训练方法，提高低资源语音识别的性能，取得了成功，证明这是一种可行的方法。

    

    近年来，自动语音识别（ASR）系统的性能取得了显著进展，特别是对于具有大量转录语音的语言而言。然而，对于低资源语言，如少数民族语言、地方语言或方言，ASR性能通常仍然较低。本研究探究了数据增强技术是否可以帮助提高低资源ASR性能，重点关注了四种语言或语言变体（日耳曼语系：格罗宁根语、西弗里西亚语；马来-波利尼西亚语系：贝瑟玛语、纳萨尔语）。对于这四种语言，我们研究了自训练的使用，在该方法中，使用训练集数据训练ASR系统，利用该系统生成的转录文本与原始训练数据结合，来训练新的ASR系统。对于已有文本到语音系统（TTS）的格罗宁根语，我们还研究了使用TTS来生成ASR训练数据的方法。

    The performance of automatic speech recognition (ASR) systems has advanced substantially in recent years, particularly for languages for which a large amount of transcribed speech is available. Unfortunately, for low-resource languages, such as minority languages, regional languages or dialects, ASR performance generally remains much lower. In this study, we investigate whether data augmentation techniques could help improve low-resource ASR performance, focusing on four typologically diverse minority languages or language variants (West Germanic: Gronings, West-Frisian; Malayo-Polynesian: Besemah, Nasal). For all four languages, we examine the use of self-training, where an ASR system trained with the available human-transcribed data is used to generate transcriptions, which are then combined with the original data to train a new ASR system. For Gronings, for which there was a pre-existing text-to-speech (TTS) system available, we also examined the use of TTS to generate ASR training 
    
[^107]: 大型语言模型可以被引导来规避AI生成的文本检测

    Large Language Models can be Guided to Evade AI-Generated Text Detection. (arXiv:2305.10847v1 [cs.CL])

    [http://arxiv.org/abs/2305.10847](http://arxiv.org/abs/2305.10847)

    本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。

    

    大型语言模型在包括论文写作和问答等多个任务中展现出了出色的表现。然而，必须解决这些模型潜在的误用问题，否则可能导致抄袭和垃圾信息等不良后果。本研究揭示，通过精心设计的提示语，LLMs可以有效地规避检测系统。我们提出了一种新颖的基于替换的上下文示例优化方法（SICO），用于自动生成这种提示语。在三个现实任务中，LLMs可能被误用，在SICO的帮助下，ChatGPT成功地规避了六项现有的检测器，平均导致0.54的AUC下降。令人惊讶的是，在大多数情况下，这些检测器的表现甚至比随机分类器还要差。这些结果坚定地揭示了现有检测器的脆弱性。

    Large Language Models (LLMs) have demonstrated exceptional performance in a variety of tasks, including essay writing and question answering. However, it is crucial to address the potential misuse of these models, which can lead to detrimental outcomes such as plagiarism and spamming. Recently, several detectors have been proposed, including fine-tuned classifiers and various statistical methods. In this study, we reveal that with the aid of carefully crafted prompts, LLMs can effectively evade these detection systems. We propose a novel Substitution-based In-Context example Optimization method (SICO) to automatically generate such prompts. On three real-world tasks where LLMs can be misused, SICO successfully enables ChatGPT to evade six existing detectors, causing a significant 0.54 AUC drop on average. Surprisingly, in most cases these detectors perform even worse than random classifiers. These results firmly reveal the vulnerability of existing detectors. Finally, the strong perfor
    
[^108]: 大型语言模型适合指导阅读吗？

    Are Large Language Models Fit For Guided Reading?. (arXiv:2305.10645v1 [cs.CL])

    [http://arxiv.org/abs/2305.10645](http://arxiv.org/abs/2305.10645)

    本文评估大型语言模型在指导阅读中的应用能力，发现它们能够生成高质量的有意义问题，具有多样性且涵盖输入文本中大多数主题，同时能够有效地总结回答和推荐重新阅读的部分。

    

    本文研究了大型语言模型在教育指导阅读中的应用能力。我们具体评估了它们从输入文本中生成有意义问题的能力，生成内容涵盖和问题难度多样化的问题的能力，并评估它们根据学生对问题的回答推荐应该重新阅读的文本部分的能力。在对ChatGPT和Bard的评估中，我们报告如下结果：1）大型语言模型能够生成与输入文本高相关的高质量有意义的问题，2）它们能够生成涵盖输入文本中大多数主题的多样化问题，尽管随着输入文本的增加，这种能力显著降低，3）大型语言模型能够生成低和高认知难度的问题，尽管它们显著偏向于低认知难度的问题，4）它们能够有效地总结回答并提取应该重新阅读的部分。

    This paper looks at the ability of large language models to participate in educational guided reading. We specifically, evaluate their ability to generate meaningful questions from the input text, generate diverse questions both in terms of content coverage and difficulty of the questions and evaluate their ability to recommend part of the text that a student should re-read based on the student's responses to the questions. Based on our evaluation of ChatGPT and Bard, we report that,  1) Large language models are able to generate high quality meaningful questions that have high correlation with the input text, 2) They generate diverse question that cover most topics in the input text even though this ability is significantly degraded as the input text increases, 3)The large language models are able to generate both low and high cognitive questions even though they are significantly biased toward low cognitive question, 4) They are able to effectively summarize responses and extract a p
    
[^109]: UniEX：一种基于跨度提取的统一信息抽取的有效高效框架

    UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective. (arXiv:2305.10306v1 [cs.CL])

    [http://arxiv.org/abs/2305.10306](http://arxiv.org/abs/2305.10306)

    UniEX是一种能适用于各种模式格式的信息抽取框架，并能同时解决命名实体识别、关系抽取、事件提取和情感分析等任务，在性能和推理速度上优于其他通用信息抽取模型。

    

    我们提出了一种新的通用信息抽取范式，它与任何模式格式兼容，并适用于一系列信息抽取任务，如命名实体识别、关系抽取、事件提取和情感分析。我们的方法将以文本为基础的信息抽取任务转化为 token-pair 问题，使用一种统一的提取框架 UniEX，将所有提取目标都统一分解为联合跨度检测、分类和关联问题。UniEX 可以同时编码基于模式的提示和文本信息，并使用自动编码器语言模型协同学习预定义信息的广义知识。我们开发了 traffine 注意机制，将包括任务、标签和内部 token 在内的异构因素集成起来，并通过评分矩阵获得提取目标。实验结果表明，UniEX 在 $14$个基准测试数据集上的表现和推理速度都优于基于生成的通用信息抽取模型。

    We propose a new paradigm for universal information extraction (IE) that is compatible with any schema format and applicable to a list of IE tasks, such as named entity recognition, relation extraction, event extraction and sentiment analysis. Our approach converts the text-based IE tasks as the token-pair problem, which uniformly disassembles all extraction targets into joint span detection, classification and association problems with a unified extractive framework, namely UniEX. UniEX can synchronously encode schema-based prompt and textual information, and collaboratively learn the generalized knowledge from pre-defined information using the auto-encoder language models. We develop a traffine attention mechanism to integrate heterogeneous factors including tasks, labels and inside tokens, and obtain the extraction target via a scoring matrix. Experiment results show that UniEX can outperform generative universal IE models in terms of performance and inference-speed on $14$ benchmar
    
[^110]: 基于上下文的提示式学习用于在线社区违规检测

    CPL-NoViD: Context-Aware Prompt-based Learning for Norm Violation Detection in Online Communities. (arXiv:2305.09846v1 [cs.CL])

    [http://arxiv.org/abs/2305.09846](http://arxiv.org/abs/2305.09846)

    本文提出了一种新的方法（CPL-NoViD），通过自然语言提示将上下文融入到模型中，用于在线社区中的违规检测。该方法能够适应不同社区中的各种规则和解释的差异，在跨规则类型和跨社区的违规行为检测中表现出色，并在少样本学习场景中表现出一定的适应性。

    

    在线社区中检测违规行为对于维护健康和安全的在线讨论空间至关重要。现有的机器学习方法往往难以适应不同社区之间各种规则和解释的差异，因为为这种特定上下文的任务微调模型具有困难。本文介绍了基于上下文提示的学习用于检测不同类型规则下的违规行为（CPL-NoViD），一种新的方法。CPL-NoViD通过自然语言提示来将上下文融入到模型中，对不同类型规则的表现也得到了改善，不仅在跨规则类型和跨社区的违规行为检测中表现出色，而且在少样本学习场景中也表现出一定的适应性。尤其值得注意的是，它建立了一个新的违规检测新的最高水平，超过了现有的基准。

    Detecting norm violations in online communities is critical to maintaining healthy and safe spaces for online discussions. Existing machine learning approaches often struggle to adapt to the diverse rules and interpretations across different communities due to the inherent challenges of fine-tuning models for such context-specific tasks. In this paper, we introduce Context-aware Prompt-based Learning for Norm Violation Detection (CPL-NoViD), a novel method that employs prompt-based learning to detect norm violations across various types of rules. CPL-NoViD outperforms the baseline by incorporating context through natural language prompts and demonstrates improved performance across different rule types. Significantly, it not only excels in cross-rule-type and cross-community norm violation detection but also exhibits adaptability in few-shot learning scenarios. Most notably, it establishes a new state-of-the-art in norm violation detection, surpassing existing benchmarks. Our work high
    
[^111]: AR-Diffusion：自回归扩散模型用于文本生成

    AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation. (arXiv:2305.09515v1 [cs.CL])

    [http://arxiv.org/abs/2305.09515](http://arxiv.org/abs/2305.09515)

    本文提出了一种自回归扩散模型（AR-Diffusion）用于文本生成，通过动态数量的降噪步骤，确保左侧标记的生成影响右侧标记的生成。

    

    扩散模型由于其出色的性能，在图像生成领域引起了广泛的关注。最近，这种成功已经扩展到了通过同时生成序列中的所有标记来实现文本生成。然而，自然语言相对于图像具有更为明显的序列依赖性，现有的大多数语言模型都是使用自左向右的自回归方法进行训练的。为了解决自然语言固有的序列特征，我们引入了自回归扩散（AR-Diffusion）模型。AR-Diffusion确保右侧标记的生成取决于左侧标记的生成，这种机制是通过采用动态数量的降噪步骤来实现的，这些步骤根据标记位置而变化。这导致左侧的标记经历的降噪步骤比右侧的标记少，从而使它们能够更早地生成并随后影响右侧标记的生成。

    Diffusion models have gained significant attention in the realm of image generation due to their exceptional performance. Their success has been recently expanded to text generation via generating all tokens within a sequence concurrently. However, natural language exhibits a far more pronounced sequential dependency in comparison to images, and the majority of existing language models are trained utilizing a left-to-right auto-regressive approach. To account for the inherent sequential characteristic of natural language, we introduce Auto-Regressive Diffusion (AR-Diffusion). AR-Diffusion ensures that the generation of tokens on the right depends on the generated ones on the left, a mechanism achieved through employing a dynamic number of denoising steps that vary based on token position. This results in tokens on the left undergoing fewer denoising steps than those on the right, thereby enabling them to generate earlier and subsequently influence the generation of tokens on the right.
    
[^112]: 信息抽取的易学难学学习方法

    Easy-to-Hard Learning for Information Extraction. (arXiv:2305.09193v1 [cs.CL])

    [http://arxiv.org/abs/2305.09193](http://arxiv.org/abs/2305.09193)

    本文提出了一种易学难学的信息抽取学习框架，分为入门、困难和主阶段，模仿人类学习过程，通过分阶段学习提高模型泛化能力。

    

    信息抽取是指从非结构化文本中自动提取出命名实体、实体关系和事件等结构化信息的系统。本文提出了一种模仿人类学习过程的易学难学框架，分为三个阶段：入门阶段、困难阶段和主阶段。通过分阶段学习，我们的框架促进了模型获得更广泛的信息抽取任务知识，并提高了其泛化能力。在四个信息抽取任务上进行了大量实验，证明了我们框架的有效性。

    Information extraction (IE) systems aim to automatically extract structured information, such as named entities, relations between entities, and events, from unstructured texts. While most existing work addresses a particular IE task, universally modeling various IE tasks with one model has achieved great success recently. Despite their success, they employ a one-stage learning strategy, i.e., directly learning to extract the target structure given the input text, which contradicts the human learning process. In this paper, we propose a unified easy-to-hard learning framework consisting of three stages, i.e., the easy stage, the hard stage, and the main stage, for IE by mimicking the human learning process. By breaking down the learning process into multiple stages, our framework facilitates the model to acquire general IE task knowledge and improve its generalization ability. Extensive experiments across four IE tasks demonstrate the effectiveness of our framework. We achieve new stat
    
[^113]: 无需增加模型参数的序列到序列模型微调方法：基于结构化剪枝的LoRA方法

    Parameter-Efficient Fine-Tuning with Layer Pruning on Free-Text Sequence-to-Sequence modeling. (arXiv:2305.08285v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08285](http://arxiv.org/abs/2305.08285)

    本文提出了一个将LoRA和结构化层剪枝方法结合的框架，在保持超过92%生成质量的同时，通过调整仅0.6%的参数并剪枝超过30%的Transformer层，成功减少了50%的GPU内存使用并提升了100%的训练速度。

    

    语言模型尺寸的不断增长引起了对于参数效率的微调方法的研究兴趣，本文提出了一个将LoRA和结构化层剪枝方法结合的框架。这个框架在 MIMIC-IV-Note上的两个医疗报告概述数据集和两个公共医疗对话数据集上进行了验证。通过调整原始模型的0.6%的参数并剪枝超过30%的Transformer层，我们的框架可以减少50%的GPU内存使用并提升100%的训练速度，同时保持在自由文本序列到序列任务上超过92%的生成质量。

    The increasing size of language models raises great research interests in parameter-efficient fine-tuning such as LoRA that freezes the pre-trained model, and injects small-scale trainable parameters for multiple downstream tasks (e.g., summarization, question answering and translation). To further enhance the efficiency of fine-tuning, we propose a framework that integrates LoRA and structured layer pruning. The integrated framework is validated on two created deidentified medical report summarization datasets based on MIMIC-IV-Note and two public medical dialogue datasets. By tuning 0.6% parameters of the original model and pruning over 30% Transformer-layers, our framework can reduce 50% of GPU memory usage and speed up 100% of the training phase, while preserving over 92% generation qualities on free-text sequence-to-sequence tasks.
    
[^114]: FactKG: 通过知识图谱推理进行事实验证

    FactKG: Fact Verification via Reasoning on Knowledge Graphs. (arXiv:2305.06590v1 [cs.CL])

    [http://arxiv.org/abs/2305.06590](http://arxiv.org/abs/2305.06590)

    FactKG是一个新的数据集，通过知识图谱推理进行事实验证，包含108k个自然语言声明和五种推理类型，可帮助社区更好地使用知识图谱进行事实验证。

    

    在现实应用中，知识图谱（KG）在各种领域（如医疗应用和对话代理）中被广泛使用。然而，在事实验证方面，KG尚未充分利用作为知识源。KG可以成为事实验证的有价值的知识来源，因为它们具有可靠性和广泛的适用性。KG由节点和边组成，清晰地展示了概念之间的联系，使得机器可以推理出一系列主题。然而，理解这些机器可读的概念如何映射到文本中的信息存在许多挑战。为了使社区更好地利用KG，我们介绍了一个新的数据集，FactKG:通过知识图谱推理进行事实验证，它包含108k个自然语言声明以及五种推理类型：单跳、合取、存在、多跳和否定。此外，FactKG包含各种语言模式，包括口语风格的声明和书面风格的声明，以提高实用性。

    In real world applications, knowledge graphs (KG) are widely used in various domains (e.g. medical applications and dialogue agents). However, for fact verification, KGs have not been adequately utilized as a knowledge source. KGs can be a valuable knowledge source in fact verification due to their reliability and broad applicability. A KG consists of nodes and edges which makes it clear how concepts are linked together, allowing machines to reason over chains of topics. However, there are many challenges in understanding how these machine-readable concepts map to information in text. To enable the community to better use KGs, we introduce a new dataset, FactKG: Fact Verification via Reasoning on Knowledge Graphs. It consists of 108k natural language claims with five types of reasoning: One-hop, Conjunction, Existence, Multi-hop, and Negation. Furthermore, FactKG contains various linguistic patterns, including colloquial style claims as well as written style claims to increase practica
    
[^115]: PersonaLLM: 探究GPT-3.5表达个性特征和性别差异的能力

    PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. (arXiv:2305.02547v1 [cs.CL])

    [http://arxiv.org/abs/2305.02547](http://arxiv.org/abs/2305.02547)

    本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。

    

    尽管大型语言模型在各个行业的聊天机器人设计中有许多用途，并且研究表明个性化聊天机器人在满足不同人格特征方面的重要性，但很少有研究评估个性化LLM的行为是否能够准确、一致地反映某些人格特征。我们考虑研究基于LLM的模拟代理的行为，称之为LLM personas，并使用GPT-3.5（text-davinci-003）进行案例研究，以研究LLM在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。我们创建了320个LLM personas（每种大五人格类型有5个女性和5个男性），并提示他们完成经典的44项大五人格问卷（BFI），然后撰写一个关于他们童年的800字故事。结果表明，LLM personas的自我报告的BFI分数与他们分配的人格类型一致。

    Despite the many use cases for large language models (LLMs) in the design of chatbots in various industries and the research showing the importance of personalizing chatbots to cater to different personality traits, little work has been done to evaluate whether the behaviors of personalized LLMs can reflect certain personality traits accurately and consistently. We consider studying the behavior of LLM-based simulated agents which refer to as LLM personas and present a case study with GPT-3.5 (text-davinci-003) to investigate whether LLMs can generate content with consistent, personalized traits when assigned Big Five personality types and gender roles. We created 320 LLM personas (5 females and 5 males for each of the 32 Big Five personality types) and prompted them to complete the classic 44-item Big Five Inventory (BFI) and then write an 800-word story about their childhood. Results showed that LLM personas' self-reported BFI scores are consistent with their assigned personality typ
    
[^116]: 显式规划有助于语言模型进行逻辑推理

    Explicit Planning Helps Language Models in Logical Reasoning. (arXiv:2303.15714v1 [cs.CL])

    [http://arxiv.org/abs/2303.15714](http://arxiv.org/abs/2303.15714)

    本文提出了一个新的系统，使用语言模型进行多步逻辑推理，采用了显式规划来帮助做出更明智的决策，比其他竞争系统表现更好，显式规划在系统性能中起着关键作用。

    

    语言模型在各种自然语言处理任务中表现出色。本文提出了一个新颖的系统，采用语言模型进行多步逻辑推理。我们的系统将显式规划纳入到推理过程中，因此可以通过展望未来的效果来做出更明智的决策。在实验中，我们的全套系统在多项选择题答题任务中明显优于其他竞争系统，尽管只有约15亿个参数，但与GPT-3-davinci表现相当。我们进行了多个消融研究以证明显式规划在系统性能中起着关键作用。

    Language models have been shown to perform remarkably well on a wide range of natural language processing tasks. In this paper, we propose a novel system that uses language models to perform multi-step logical reasoning. Our system incorporates explicit planning into its inference procedure, thus able to make more informed reasoning decisions at each step by looking ahead into their future effects. In our experiments, our full system significantly outperforms other competing systems. On a multiple-choice question answering task, our system performs competitively compared to GPT-3-davinci despite having only around 1.5B parameters. We conduct several ablation studies to demonstrate that explicit planning plays a crucial role in the system's performance.
    
[^117]: UniFLG: 文本或语音驱动的统一面部特征点生成器

    UniFLG: Unified Facial Landmark Generator from Text or Speech. (arXiv:2302.14337v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.14337](http://arxiv.org/abs/2302.14337)

    该论文提出了一个基于文本或语音驱动的UniFLG系统，将文本与语音结合起来生成面部特征点。该系统表现出比现有基于文本驱动方法更高的语音和面部表现自然度，可以从没有面部视频数据或语音数据的讲话者中生成面部特征点。

    

    说话的面部生成已经被广泛研究了。用于说话的两种主要框架包括驱动于文本的框架，从文本生成同步的语音和说话的面孔，以及驱动于语音的框架，从语音生成说话的面孔。为了整合这些框架，本文提出了一个统一的面部特征点生成器（UniFLG）。该系统不仅利用端到端的文本到语音来合成语音，还利用其中的一系列潜在表示来从文本和语音中提取共同的信息，并将其输入到特征点解码器中生成面部特征点。我们证明了我们的系统在语音合成和面部特征点生成方面都比最先进的基于文本驱动的方法具有更高的自然度。我们进一步证明了我们的系统可以从没有面部视频数据或甚至语音数据的讲话者的语音中生成面部特征点。

    Talking face generation has been extensively investigated owing to its wide applicability. The two primary frameworks used for talking face generation comprise a text-driven framework, which generates synchronized speech and talking faces from text, and a speech-driven framework, which generates talking faces from speech. To integrate these frameworks, this paper proposes a unified facial landmark generator (UniFLG). The proposed system exploits end-to-end text-to-speech not only for synthesizing speech but also for extracting a series of latent representations that are common to text and speech, and feeds it to a landmark decoder to generate facial landmarks. We demonstrate that our system achieves higher naturalness in both speech synthesis and facial landmark generation compared to the state-of-the-art text-driven method. We further demonstrate that our system can generate facial landmarks from speech of speakers without facial video data or even speech data.
    
[^118]: Epicurus参加SemEval-2023任务4：通过利用定义来改善预测论据背后的人类价值观

    Epicurus at SemEval-2023 Task 4: Improving Prediction of Human Values behind Arguments by Leveraging Their Definitions. (arXiv:2302.13925v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13925](http://arxiv.org/abs/2302.13925)

    本篇论文介绍了参加SemEval-2023任务4的实验，旨在通过利用定义来提高对论据背后的人类价值观的预测，实验证明此方法可以获得更好的预测性能。

    

    我们描述了针对SemEval-2023任务4（ValueEval）进行的实验，其中涉及如何确定论据背后的人类价值观。由于人类价值观是主观概念，需要精确定义，因此我们假设在模型训练过程中加入人类价值观的定义（以注释说明和已验证的调查条目的形式）可以提高预测性能。我们探讨了这个想法，并展示了我们提出的模型比挑战组织者的基准模型表现更好，宏F1得分提高了高达18%。

    We describe our experiments for SemEval-2023 Task 4 on the identification of human values behind arguments (ValueEval). Because human values are subjective concepts which require precise definitions, we hypothesize that incorporating the definitions of human values (in the form of annotation instructions and validated survey items) during model training can yield better prediction performance. We explore this idea and show that our proposed models perform better than the challenge organizers' baselines, with improvements in macro F1 scores of up to 18%.
    
[^119]: 大小不同的Transformer解码器

    Big Little Transformer Decoder. (arXiv:2302.07863v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07863](http://arxiv.org/abs/2302.07863)

    提出了一种名为BiLD的框架，它由大小不同的两个模型协作生成文本。其中小型模型自回归地生成文本，而大型模型则在必要时以非自回归的方式对小型模型的预测进行微调，从而显著减少了推理延迟。

    

    基于Transformer架构的大型语言模型的出现，使得自然语言处理领域取得了巨大的进展。然而，这些模型存在长时间的推理延迟，限制了它们的使用并且使得它们在各种实时应用中过于昂贵。在自回归生成任务中，由于模型需要迭代地运行才能逐个生成标记，因此推理延迟更加严重。为了解决这个问题，我们提出了Big Little Decoder（BiLD）框架，它可以提高各种文本生成应用的推理效率和延迟。BiLD框架包含两个不同大小的模型，它们协作地生成文本。小型模型自回归地运行以低延迟生成文本，大型模型只在需要时以非自回归的方式调整小型模型不准确的预测。为了提高训练的稳定性和改善模型性能，我们引入了一种渐进蒸馏机制，使小型模型逐渐地从大型模型中学习。实验结果证明，所提出的BiLD框架显著降低了推理延迟，同时在保持与大型自回归模型相当甚至更好的生成质量的情况下。

    The recent emergence of Large Language Models based on the Transformer architecture has enabled dramatic advancements in the field of Natural Language Processing. However, these models have long inference latency, which limits their deployment, and which makes them prohibitively expensive for various real-time applications. The inference latency is further exacerbated by autoregressive generative tasks, as models need to run iteratively to generate tokens sequentially without leveraging token-level parallelization. To address this, we propose Big Little Decoder (BiLD), a framework that can improve inference efficiency and latency for a wide range of text generation applications. The BiLD framework contains two models with different sizes that collaboratively generate text. The small model runs autoregressively to generate text with a low inference cost, and the large model is only invoked occasionally to refine the small model's inaccurate predictions in a non-autoregressive manner. To
    
[^120]: 移民议题的再定义？乌克兰危机期间欧洲态度变化的多语言分析

    Migration Reframed? A multilingual analysis on the stance shift in Europe during the Ukrainian crisis. (arXiv:2302.02813v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2302.02813](http://arxiv.org/abs/2302.02813)

    乌克兰危机引起了欧洲对移民议题态度的变化，特别是对来自乌克兰的难民。研究者运用多语言分析技术对新闻和社交媒体上的相关报道进行研究，发现了一种对移民议题讨论的重构。

    

    乌克兰战争似乎积极改变了欧洲对移民这一关键社会议题的态度——至少对来自乌克兰的难民来说如此。本研究调查了该议题在网络新闻和社交媒体上的反映，以此将网上的议题表达与社会对其的感知联系起来。为此，我们结合并改编了领先的自动文本处理技术，采用新型的多语言立场检测方法。从2021年9月开始的一年内，我们获得了565家欧洲新闻机构发布的550万条推特帖子和回复，进行了关于移民相关的媒体报道和相关社交媒体互动的多语言分析。我们的分析结果表明，实际上存在一种讨论重塑，可以通过术语的变化来说明，例如，从“移民”到“难民”，甚至常常强调“真正的难民”。

    The war in Ukraine seems to have positively changed the attitude toward the critical societal topic of migration in Europe -- at least towards refugees from Ukraine. We investigate whether this impression is substantiated by how the topic is reflected in online news and social media, thus linking the representation of the issue on the Web to its perception in society. For this purpose, we combine and adapt leading-edge automatic text processing for a novel multilingual stance detection approach. Starting from 5.5M Twitter posts published by 565 European news outlets in one year, beginning September 2021, plus replies, we perform a multilingual analysis of migration-related media coverage and associated social media interaction for Europe and selected European countries.  The results of our analysis show that there is actually a reframing of the discussion illustrated by the terminology change, e.g., from "migrant" to "refugee", often even accentuated with phrases such as "real refugees
    
[^121]: 适用于所有领域的一个模型：基于协作域前缀调整的跨领域实体识别

    One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER. (arXiv:2301.10410v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10410](http://arxiv.org/abs/2301.10410)

    本论文提出了基于协作域前缀调整的跨领域实体识别，使用文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务，避免了先前的为每个领域结束一个全新的NER模型的问题。

    

    解决实际场景中低资源问题是跨领域实体识别的一个挑战性任务。先前典型的解决方案主要通过使用来自丰富资源领域的数据进行预训练语言模型(PLMs)获得NER模型并将其适应于目标领域。由于不同领域实体类型之间的不匹配问题，先前的方法通常调整所有PLMs的参数，从而为每个领域结束一个全新的NER模型。此外，当前的模型只关注于利用一个普通来源领域中的知识，而未能成功地将来自多个来源领域的知识转移到目标上。为了解决这些问题，我们基于文本到文本生成的PLM引入了协作域前缀调整跨领域NER(CP-NER)。具体来说，我们呈现了用于文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务而无需结构修改。我们利用冻结的PLMs并进行协作域前缀调整。

    Cross-domain NER is a challenging task to address the low-resource problem in practical scenarios. Previous typical solutions mainly obtain a NER model by pre-trained language models (PLMs) with data from a rich-resource domain and adapt it to the target domain. Owing to the mismatch issue among entity types in different domains, previous approaches normally tune all parameters of PLMs, ending up with an entirely new NER model for each domain. Moreover, current models only focus on leveraging knowledge in one general source domain while failing to successfully transfer knowledge from multiple sources to the target. To address these issues, we introduce Collaborative Domain-Prefix Tuning for cross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically, we present text-to-text generation grounding domain-related instructors to transfer knowledge to new domain NER tasks without structural modifications. We utilize frozen PLMs and conduct collaborative domain-prefix tuning
    
[^122]: 基于执行的方法评估开放域代码生成

    Execution-Based Evaluation for Open-Domain Code Generation. (arXiv:2212.10481v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2212.10481](http://arxiv.org/abs/2212.10481)

    ODEX是第一个基于开放域执行的自然语言到Python代码生成数据集。CODEX和CODEGEN分别表现不同的行为。ODEx将有助于进一步研究代码生成的开放域问题。

    

    为了将编码查询的范围扩展到更加实际的环境，我们提出了ODEx，第一个基于开放域执行的自然语言（NL）到Python代码生成数据集。ODEx共有945个NL-Code对，涵盖79个不同的库，以及1,707个供执行的人工编写的测试用例。我们从StackOverflow论坛获得NL-Code对，鼓励自然和实用的编码查询。此外，ODEx支持四种自然语言，即英语、西班牙语、日语和俄语。ODEx揭示了最高执行效果代码语言模型之间的有趣行为差异。虽然CODEX的总体结果更好，但CODEGEN通过扩展而有效地提高了性能 - CODEGEN 6.1B与CODEX 12B表现相当。两个模型都显示出开放域和封闭域之间的显著差距，但CODEGEN差距往往随着模型规模的增加而减少，而CODEX差距则会增加。我们释放ODEx以促进对代码生成社区的开放域问题的研究。

    To extend the scope of coding queries to more realistic settings, we propose ODEX, the first Open-Domain EXecution-based natural language (NL) to Python code generation dataset. ODEX has 945 NL-Code pairs spanning 79 diverse libraries, along with 1,707 human-written test cases for execution. Our NL-Code pairs are harvested from StackOverflow forums to encourage natural and practical coding queries. Moreover, ODEX supports four natural languages as intents, in English, Spanish, Japanese, and Russian. ODEX unveils intriguing behavioral differences among top-performing code language models (LM). While CODEX achieves better overall results, CODEGEN improves effectively via scaling -- CODEGEN 6.1B performs comparably with CODEX 12B. Both models show substantial gaps between open and closed domains, but CODEGEN gaps tend to decrease with model size while CODEX gaps increase. We release ODEX to facilitate research into open-domain problems for the code generation community.
    
[^123]: 利用提示和标签检索增强句子编码器进行零样本文本分类

    Empowering Sentence Encoders with Prompting and Label Retrieval for Zero-shot Text Classification. (arXiv:2212.10391v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10391](http://arxiv.org/abs/2212.10391)

    本文提出了一种 RaLP 框架，其使用提示和标签检索增强句子编码器进行零样本文本分类。该框架可以处理描述不当的标签，同时将提示与输入文本嵌入相似性相对较高的标签关联，取得了与较大基线竞争性能或更强的性能。

    

    使用对比性预训练，句子编码器通常会优化以便在它们的嵌入空间中将语义相似的样本靠近彼此定位。本文关注其嵌入空间可以便于零样本文本分类的潜力，因为语义不同的样本已经被很好地分离。我们提出的框架 RaLP（使用句子编码器的标签检索增强提示）使用句子编码器对提示标签候选进行编码，然后将具有最高相似性的提示嵌入与输入文本嵌入关联为标签。为了补偿其原始格式中可能描述不当的标签，RaLP从外部语料库中检索与原始标签提示语义相似的句子，并将它们用作附加的伪标签提示。RaLP在零样本设置下的各种封闭集分类和多选题 QA 数据集上取得了至少与较大基线竞争性能或更强的性能。

    With contrastive pre-training, sentence encoders are generally optimized to locate semantically similar samples closer to each other in their embedding spaces. In this work, we focus on the potential of their embedding spaces to be readily adapted to zero-shot text classification, as semantically distinct samples are already well-separated. Our framework, RaLP (Retrieval augmented Label Prompts for sentence encoder), encodes prompted label candidates with a sentence encoder, then assigns the label whose prompt embedding has the highest similarity with the input text embedding. In order to compensate for the potentially poorly descriptive labels in their original format, RaLP retrieves sentences that are semantically similar to the original label prompt from external corpora and use them as additional pseudo-label prompts. RaLP achieves competitive or stronger performance than much larger baselines on various closed-set classification and multiple-choice QA datasets under zero-shot sett
    
[^124]: 论基于模型的文本生成评价指标的盲点问题

    On the Blind Spots of Model-Based Evaluation Metrics for Text Generation. (arXiv:2212.10020v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10020](http://arxiv.org/abs/2212.10020)

    本文研究了针对文本生成评价指标的鲁棒性分析方法，使用合成数据进行压力测试，发现现有评价指标存在一些盲点和偏见，例如BERTScore对摘要中的截断误差无法很好地处理，MAUVE对于生成的开头或中间的误差不敏感，本文提出了实用的解决方案以实现更可靠的文本生成评价。

    

    本文探讨了一种有用但常常被忽略的文本生成评价指标鲁棒性分析方法：使用合成数据进行压力测试。我们随机设计并合成了各种可能的误差，并检查它们是否会导致评价指标分数的显著下降。我们研究了基于预训练语言模型的一系列最新评价指标，用于开放式生成、翻译和摘要等任务。实验揭示了现有评价指标中有趣的不敏感、偏见、甚至漏洞。例如，我们发现BERTScore对摘要中的截断误差感到困惑，而在生成的开头或中间存在误差时MAUVE（基于GPT-2）则不敏感。进一步，我们研究了这些盲点背后的原因，并提出了实用的解决方案，以实现更可靠的文本生成评价。我们已在https://github.com/cloudygoose/blindspot_nlg 上发布了我们的代码和数据。

    In this work, we explore a useful but often neglected methodology for robustness analysis of text generation evaluation metrics: stress tests with synthetic data. Basically, we design and synthesize a wide range of potential errors and check whether they result in a commensurate drop in the metric scores. We examine a range of recently proposed evaluation metrics based on pretrained language models, for the tasks of open-ended generation, translation, and summarization. Our experiments reveal interesting insensitivities, biases, or even loopholes in existing metrics. For example, we find that BERTScore is confused by truncation errors in summarization, and MAUVE (built on top of GPT-2) is insensitive to errors at the beginning or middle of generations. Further, we investigate the reasons behind these blind spots and suggest practical workarounds for a more reliable evaluation of text generation. We have released our code and data at https://github.com/cloudygoose/blindspot_nlg.
    
[^125]: 注重视觉、属性和理性：迈向物理安全和可信的人工智能

    Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy AI. (arXiv:2212.09667v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09667](http://arxiv.org/abs/2212.09667)

    研究提出了一种新颖的FARM框架，通过利用外部知识生成能够被信任的原理，解决了不安全文本检测的问题，并能够帮助利益相关者和政策制定者保障消费者的安全。

    

    随着智能系统市场的不断增长，用户的身体安全越来越受到关注。不受限制的系统可能会向用户推荐危险的行为，导致严重的伤害。隐蔽的不安全文本是一个特别关注的领域，因为这样的文本可能会出现在日常场景中，并且很难被检测为有害。我们提出了FARM，这是一个新颖的框架，利用外部知识在安全上下文中生成可信的原理。具体而言，FARM注重于缺失的知识，以确认在特定情境中进行推理所需的信息，并通过可信源进行归因以获取此信息。这些知识用于分类原始文本的安全性并生成人类可解释的原理，揭示系统对特定用户群体的风险，并帮助利益相关者管理其系统的风险，帮助政策制定者为消费者安全提供具体的保障。我们的实验表明，FARM在识别不安全文本和生成可信的原理方面优于现有方法。

    Users' physical safety is an increasing concern as the market for intelligent systems continues to grow, where unconstrained systems may recommend users dangerous actions that can lead to serious injury. Covertly unsafe text is an area of particular interest, as such text may arise from everyday scenarios and are challenging to detect as harmful. We propose FARM, a novel framework leveraging external knowledge for trustworthy rationale generation in the context of safety. In particular, FARM foveates on missing knowledge to qualify the information required to reason in specific scenarios and retrieves this information with attribution to trustworthy sources. This knowledge is used to both classify the safety of the original text and generate human-interpretable rationales, shedding light on the risk of systems to specific user groups and helping both stakeholders manage the risks of their systems and policymakers to provide concrete safeguards for consumer safety. Our experiments show 
    
[^126]: 多语言翻译中干扰的原因和解决方法探究

    Causes and Cures for Interference in Multilingual Translation. (arXiv:2212.07530v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07530](http://arxiv.org/abs/2212.07530)

    研究探究了多语言机器翻译中干扰的主要因素，通过系统化试验发现使用不到10亿参数的标准Transformer配置可以在很大程度上缓解干扰并促进协同，同时发现调整采样温度以控制数据中每个语言对所占比例的方法是平衡语言对之间关系的关键。

    

    多语言机器翻译模型可以从不同语言对之间的协同中获益，但同时也会受到干扰的影响。虽然目前有越来越多的先进方法旨在消除干扰，但我们对干扰现象的理解仍然有限。本研究确定了导致多语言机器翻译中干扰的主要因素。通过系统化试验，我们发现干扰（或协同）主要由模型大小、数据大小和每个语言对在总数据集中所占比例来决定。我们观察到，当模型相对于可用的训练数据非常小的时候，会出现严重的干扰，而使用不到10亿参数的标准Transformer配置可以在很大程度上缓解干扰并促进协同。此外，我们还展示了通过调整采样温度以控制数据中每个语言对所占比例的方法是平衡语言对之间关系的关键。

    Multilingual machine translation models can benefit from synergy between different language pairs, but also suffer from interference. While there is a growing number of sophisticated methods that aim to eliminate interference, our understanding of interference as a phenomenon is still limited. This work identifies the main factors that contribute to interference in multilingual machine translation. Through systematic experimentation, we find that interference (or synergy) are primarily determined by model size, data size, and the proportion of each language pair within the total dataset. We observe that substantial interference occurs mainly when the model is very small with respect to the available training data, and that using standard transformer configurations with less than one billion parameters largely alleviates interference and promotes synergy. Moreover, we show that tuning the sampling temperature to control the proportion of each language pair in the data is key to balancin
    
[^127]: ERNIE-Code: 超越英语为中心的跨语言编程预训练

    ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages. (arXiv:2212.06742v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.06742](http://arxiv.org/abs/2212.06742)

    ERNIE-Code是一个适用于116种自然语言和6种编程语言的统一预训练语言模型，采用了跨度损坏语言建模和基于桥接的翻译语言建模两种跨语言预训练方法，并在广泛的代码智能终端任务中优于以前的多语言LLMs。

    

    软件工程师使用同一种编程语言可能使用不同的自然语言，这会导致沟通和工作效率的巨大障碍。最近的研究表明，在计算机程序中使用生成式预训练是有效的，然而它们总是以英语为中心。在这项工作中，我们迈出了迈向为大型语言模型（LLM）建立多语言自然语言和多语言编程语言之间桥梁的一步。我们发布了ERNIE-Code，这是一个适用于116种自然语言和6种编程语言的统一预训练语言模型。我们采用两种普遍的跨语言预训练方法：跨度损坏语言建模从单语言自然语言或编程语言中学习模式；基于桥接的翻译语言建模依靠多种自然语言和编程语言的平行数据。广泛的结果表明，ERNIE-Code在代码智能的广泛终端任务中优于以前的多语言LLMs，包括多语言代码到文本，文本到代码，代码到代码和文本到文本的转换。

    Software engineers working with the same programming language (PL) may speak different natural languages (NLs) and vice versa, erecting huge barriers to communication and working efficiency. Recent studies have demonstrated the effectiveness of generative pre-training in computer programs, yet they are always English-centric. In this work, we step towards bridging the gap between multilingual NLs and multilingual PLs for large language models (LLMs). We release ERNIE-Code, a unified pre-trained language model for 116 NLs and 6 PLs. We employ two methods for universal cross-lingual pre-training: span-corruption language modeling that learns patterns from monolingual NL or PL; and pivot-based translation language modeling that relies on parallel data of many NLs and PLs. Extensive results show that ERNIE-Code outperforms previous multilingual LLMs for PL or NL across a wide range of end tasks of code intelligence, including multilingual code-to-text, text-to-code, code-to-code, and text-
    
[^128]: 基于文本的人格计算：挑战和未来方向

    On Text-based Personality Computing: Challenges and Future Directions. (arXiv:2212.06711v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.06711](http://arxiv.org/abs/2212.06711)

    本文提出了15个基于文本的人格计算方面的挑战，包括人格分类法，测量质量，数据集，性能评估，建模选择以及道德和公平性，旨在激发更多的有效和可靠的TPC研究。

    

    基于文本的人格计算（TPC）在自然语言处理（NLP）中引起了许多研究兴趣。本文描述了15个挑战，值得研究社区的关注。这些挑战按以下主题组织：人格分类法、测量质量、数据集、性能评估、建模选择以及道德和公平性。在应对每个挑战时，我们不仅结合了NLP和社会科学的视角，还提供具体的建议。我们希望激发更多有效和可靠的TPC研究。

    Text-based personality computing (TPC) has gained many research interests in NLP. In this paper, we describe 15 challenges that we consider deserving the attention of the research community. These challenges are organized by the following topics: personality taxonomies, measurement quality, datasets, performance evaluation, modelling choices, as well as ethics and fairness. When addressing each challenge, not only do we combine perspectives from both NLP and social sciences, but also offer concrete suggestions. We hope to inspire more valid and reliable TPC research.
    
[^129]: SODA：一种自然语言处理包，用于提取癌症研究中的社会健康决定因素

    SODA: A Natural Language Processing Package to Extract Social Determinants of Health for Cancer Studies. (arXiv:2212.03000v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.03000](http://arxiv.org/abs/2212.03000)

    本文介绍了一个开源的自然语言处理包SODA，可用于提取癌症患者的社会健康决定因素。该包在泛化能力方面表现良好，可以用于新的疾病领域。研究结果表明，该包在癌症人群中提取SDoH的提取率较高。

    

    本文介绍了一个名为SODA的自然语言处理包，其中含有预训练的转换器模型，可用于提取癌症患者的社会健康决定因素（SDoH），并检验了SODA在新的疾病领域（如使用阿片类药物）的泛化能力，并评估了在癌症人群中提取SDoH的提取率。

    Objective: We aim to develop an open-source natural language processing (NLP) package, SODA (i.e., SOcial DeterminAnts), with pre-trained transformer models to extract social determinants of health (SDoH) for cancer patients, examine the generalizability of SODA to a new disease domain (i.e., opioid use), and evaluate the extraction rate of SDoH using cancer populations.  Methods: We identified SDoH categories and attributes and developed an SDoH corpus using clinical notes from a general cancer cohort. We compared four transformer-based NLP models to extract SDoH, examined the generalizability of NLP models to a cohort of patients prescribed with opioids, and explored customization strategies to improve performance. We applied the best NLP model to extract 19 categories of SDoH from the breast (n=7,971), lung (n=11,804), and colorectal cancer (n=6,240) cohorts.  Results and Conclusion: We developed a corpus of 629 cancer patients notes with annotations of 13,193 SDoH concepts/attribut
    
[^130]: 与任务导向对话的意图识别相关的话语嵌入和聚类方法的分析

    Analysis of Utterance Embeddings and Clustering Methods Related to Intent Induction for Task-Oriented Dialogue. (arXiv:2212.02021v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.02021](http://arxiv.org/abs/2212.02021)

    本文旨在研究任务导向对话中的意图识别问题，并提出两个关键因素：聚类算法和用户话语嵌入空间。实验证明，利用预训练的MiniLM与层次聚类相结合可以显著提高意图归纳任务的效果。

    

    本文重点研究无监督方法，以克服设计任务导向对话图谱中的典型挑战：为每个对话转折指定意图标签（意图聚类）并基于意图聚类方法生成一组意图（意图归纳）。我们假设自动归纳意图有两个显著因素：（1）意图标签的聚类算法和（2）用户话语嵌入空间。 我们根据DSTC11评估比较了现有的成品聚类模型和嵌入。我们的实验表明，认真考虑意图归纳任务中话语嵌入和聚类方法的综合选择是必要的。我们还发现，利用预训练的MiniLM与层次聚类相结合可显著提高意图归纳任务中的NMI，ARI，F1，准确性和示例覆盖。源代码可在https://github.com/Jeiyoon/dstc11-track2上获得。

    The focus of this work is to investigate unsupervised approaches to overcome quintessential challenges in designing task-oriented dialog schema: assigning intent labels to each dialog turn (intent clustering) and generating a set of intents based on the intent clustering methods (intent induction). We postulate there are two salient factors for automatic induction of intents: (1) clustering algorithm for intent labeling and (2) user utterance embedding space. We compare existing off-the-shelf clustering models and embeddings based on DSTC11 evaluation. Our extensive experiments demonstrate that the combined selection of utterance embedding and clustering method in the intent induction task should be carefully considered. We also present that pretrained MiniLM with Agglomerative clustering shows significant improvement in NMI, ARI, F1, accuracy and example coverage in intent induction tasks. The source codes are available at https://github.com/Jeiyoon/dstc11-track2.
    
[^131]: 基于投机解码的Transformer快速推理

    Fast Inference from Transformers via Speculative Decoding. (arXiv:2211.17192v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.17192](http://arxiv.org/abs/2211.17192)

    本文介绍了一种基于投机解码的算法，可以在不更改输出的情况下更快地从大型自回归模型（如Transformer）中采样，加速了现有的模型，而无需重新训练或进行架构更改。

    

    从Transformer等大型自回归模型中进行推理是缓慢的，因为解码K个标记需要运行K次模型。本文介绍了一种名为“投机解码”的算法，它可以在不改变输出的情况下更快地从自回归模型中采样，通过并行计算多个标记实现。我们的方法可以加速现有的模型，而无需重新训练或进行架构更改。我们在T5-XXL上进行了演示，并显示相对于标准T5X实现，其加速了2X-3X，输出相同。

    Inference from large autoregressive models like Transformers is slow decoding K tokens takes K serial runs of the model. In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs, by computing several tokens in parallel. At the heart of our approach lie the observations that (1) hard language-modeling tasks often include easier subtasks that can be approximated well by more efficient models, and (2) using speculative execution and a novel sampling method, we can make exact decoding from the large models faster, by running them in parallel on the outputs of the approximation models, potentially generating several tokens concurrently, and without changing the distribution. Our method can accelerate existing off-the-shelf models without retraining or architecture changes. We demonstrate it on T5-XXL and show a 2X-3X acceleration compared to the standard T5X implementation, with identical outputs.
    
[^132]: VATLM: 使用统一的遮蔽预测进行视听文本预训练的语音表示学习

    VATLM: Visual-Audio-Text Pre-Training with Unified Masked Prediction for Speech Representation Learning. (arXiv:2211.11275v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.11275](http://arxiv.org/abs/2211.11275)

    本文提出了一个名为VATLM的统一跨模式表示学习框架，利用视听文本资料的预处理与一种统一的遮蔽预测任务进行优化，以达到优秀的联合多模态表示效果。

    

    虽然语音是人类与外界交流的一种简单而有效的方式，但更真实的语音交互包含多模式信息，例如视觉、文本。如何设计一个统一的框架来整合不同的模态信息，利用不同的资源（例如视听对、音频文本对、未标记的语音和未标记的文本）促进语音表示学习还没有被很好地探索。本文提出了一个统一跨模式表示学习框架VATLM（Visual-Audio-Text语言模型）。所提出的VATLM采用统一的骨干网络来建模模态独立信息，并利用三个简单的模态依赖模块对视觉、语音和文本输入进行预处理。为了将这三种模态集成到一个共享语义空间中，VATLM使用我们所提出的统一分词器给出的统一令牌的遮蔽预测任务进行优化。我们在音频-视觉检索和口语理解任务上评估了预训练的VATLM，并证明了它在学习联合多模态表示方面的有效性。

    Although speech is a simple and effective way for humans to communicate with the outside world, a more realistic speech interaction contains multimodal information, e.g., vision, text. How to design a unified framework to integrate different modal information and leverage different resources (e.g., visual-audio pairs, audio-text pairs, unlabeled speech, and unlabeled text) to facilitate speech representation learning was not well explored. In this paper, we propose a unified cross-modal representation learning framework VATLM (Visual-Audio-Text Language Model). The proposed VATLM employs a unified backbone network to model the modality-independent information and utilizes three simple modality-dependent modules to preprocess visual, speech, and text inputs. In order to integrate these three modalities into one shared semantic space, VATLM is optimized with a masked prediction task of unified tokens, given by our proposed unified tokenizer. We evaluate the pre-trained VATLM on audio-vis
    
[^133]: NLPeer: 具备多领域挖掘能力的同行评审计算研究的统一资源

    NLPeer: A Unified Resource for the Computational Study of Peer Review. (arXiv:2211.06651v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.06651](http://arxiv.org/abs/2211.06651)

    NLPeer是一个具有跨领域挖掘能力的同行评审计算研究的统一资源，包括超过5k篇论文和11k个审稿报告的数据集，并建立了统一的数据表示。该资源提供了三个审核协助任务的实现和分析，并为更全面和系统的NLP同行评审研究铺平了道路。

    

    同行评审是学术出版的核心组成部分，但它需要相当的专业知识和培训，且易受错误和偏见影响。各种面向同行评审的NLP应用旨在支持审稿人在这个复杂的过程中，但缺少清晰授权的数据集和多领域语料库，阻碍了对NLP用于同行评审的系统研究。为此，我们介绍了NLPeer - 第一个包含来自五个不同场所的超过5k篇论文和11k个审稿报告的合乎道德的跨领域语料库。除了来自NLP社区的新的包括论文草稿、相机准备好的版本和同行审查意见的数据集外，我们建立了统一的数据表示，增加了先前的同行评审数据集，包括经过解析和结构化的论文表示、丰富的元数据和版本信息。我们补充了我们的资源与三个审核协助任务的执行和分析，包括创新的引导式扫描任务。我们的工作为更全面和系统的NLP同行评审研究铺平了道路，并为该领域的研究人员提供了一个统一的资源。

    Peer review constitutes a core component of scholarly publishing; yet it demands substantial expertise and training, and is susceptible to errors and biases. Various applications of NLP for peer reviewing assistance aim to support reviewers in this complex process, but the lack of clearly licensed datasets and multi-domain corpora prevent the systematic study of NLP for peer review. To remedy this, we introduce NLPeer -- the first ethically sourced multidomain corpus of more than 5k papers and 11k review reports from five different venues. In addition to the new datasets of paper drafts, camera-ready versions and peer reviews from the NLP community, we establish a unified data representation and augment previous peer review datasets to include parsed and structured paper representations, rich metadata and versioning information. We complement our resource with implementations and analysis of three reviewing assistance tasks, including a novel guided skimming task. Our work paves the pa
    
[^134]: 知识蒸馏在多任务语音表示学习中的应用

    Application of Knowledge Distillation to Multi-task Speech Representation Learning. (arXiv:2210.16611v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2210.16611](http://arxiv.org/abs/2210.16611)

    本文研究将知识蒸馏应用于语音表示学习模型，联合微调多个下游任务，将模型大小减少75%同时精度和等误差率损失很小，并表明微调语音表示学习模型相较于冻结模型可以显著提高性能。

    

    wav2vec 2.0和HuBERT等模型已提出以自监督的方式从音频波形中学习语音表示。当它们与下游任务（如关键词检测和说话人验证）相结合时，它们提供了最先进的性能。然而，这些模型使用了大量参数，其中最小版本具有9500万个参数，这对于边缘AI设备的部署构成了挑战。因此，本文研究了将知识蒸馏应用于语音表示学习模型，然后与多个下游语音激活任务进行联合微调。在两个任务的实验中，我们的方法几乎减少了75％的模型大小，同时与完整大小的模型相比，仅有0.1％的精度和0.9％的等误差率下降。此外，我们表明微调语音表示学习模型相对于使用冻结的模型会显著提高性能。

    Model architectures such as wav2vec 2.0 and HuBERT have been proposed to learn speech representations from audio waveforms in a self-supervised manner. When they are combined with downstream tasks such as keyword spotting and speaker verification, they provide state-of-the-art performance. However, these models use a large number of parameters, the smallest version of which has 95 million parameters. This constitutes a challenge for edge AI device deployments. In this paper, we investigate the application of knowledge distillation to speech representation learning (SRL) models followed by joint fine-tuning with multiple downstream voice-activated tasks. In our experiments on two such tasks, our approach results in nearly 75% reduction in model size while suffering only 0.1% accuracy and 0.9% equal error rate degradation compared to the full-size model. In addition, we show that fine-tuning the SRL models results in a significant performance boost compared to using frozen SRL models.
    
[^135]: 环境声明检测

    Environmental Claim Detection. (arXiv:2209.00507v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.00507](http://arxiv.org/abs/2209.00507)

    为了实现绿色经济，需要可靠、可比较和可验证的环境声明。该论文介绍了环境声明检测任务，并发布了一个专家标注的数据集和训练模型。通过这些模型，我们可以检测环境声明在季度电话会议中的使用情况并发现该使用情况自2015年以来有稳步增长的趋势。

    

    要实现绿色经济，公司所作出的环境声明必须是可靠、可比较和可验证的。为了大规模分析这些声明，需要自动化的方法来首先检测它们。然而，目前还不存在此类数据集或模型。因此，本文介绍了环境声明检测任务。为了配合该任务，我们发布了一个由专家标注的数据集和在该数据集上训练的模型。我们预览了此类模型的一个潜在应用：我们检测季度电话会议中所作出的环境声明，并发现自2015年巴黎协议以来环境声明的数量逐渐增加。

    To transition to a green economy, environmental claims made by companies must be reliable, comparable, and verifiable. To analyze such claims at scale, automated methods are needed to detect them in the first place. However, there exist no datasets or models for this. Thus, this paper introduces the task of environmental claim detection. To accompany the task, we release an expert-annotated dataset and models trained on this dataset. We preview one potential application of such models: We detect environmental claims made in quarterly earning calls and find that the number of environmental claims has steadily increased since the Paris Agreement in 2015.
    
[^136]: 多阶段数据过滤提高NLP模型微调效率

    Efficient NLP Model Finetuning via Multistage Data Filtering. (arXiv:2207.14386v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.14386](http://arxiv.org/abs/2207.14386)

    本文介绍了一种多阶段数据过滤的方法，以提高NLP模型微调效率。在各种基准测试中，该方法有效减少所需训练样例数和训练时间，同时只有轻微精度降低，即使只有一个时期的训练，也非常有效。

    

    针对NLP模型微调的重要性，本文旨在最大程度提高它的效率。考虑到训练样例的冗余和预训练模型的规模，我们利用了一种关键机会：仅使用重要数据进行训练。为此，我们致力于以流式方式过滤训练样例，并同时训练目标模型。我们的两个关键技术是：（1）自动确定用于跳过反向训练的训练损失阈值；（2）运行元预测器以进一步跳过前向训练。我们将上述技术集成到一个全面的三阶段训练过程中。在各种基准测试中，我们的方法将所需的训练样例减少了最多5.3倍，并将训练时间缩短了最多6.8倍，同时只看到很小的精度降低。即使只有一个时期的训练，在每个训练样例只遇到一次的情况下，我们的方法也非常有效。它很容易实现并兼容现有的微调技术。

    As model finetuning is central to the modern NLP, we set to maximize its efficiency. Motivated by redundancy in training examples and the sheer sizes of pretrained models, we exploit a key opportunity: training only on important data. To this end, we set to filter training examples in a streaming fashion, in tandem with training the target model. Our key techniques are two: (1) automatically determine a training loss threshold for skipping backward training passes; (2) run a meta predictor for further skipping forward training passes. We integrate the above techniques in a holistic, three-stage training process. On a diverse set of benchmarks, our method reduces the required training examples by up to 5.3$\times$ and training time by up to 6.8$\times$, while only seeing minor accuracy degradation. Our method is effective even when training one epoch, where each training example is encountered only once. It is simple to implement and is compatible with the existing finetuning techniques
    
[^137]: GPT-3在文化遗产视觉问答中是否足够？

    Is GPT-3 all you need for Visual Question Answering in Cultural Heritage?. (arXiv:2207.12101v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.12101](http://arxiv.org/abs/2207.12101)

    本文提出了一种使用GPT-3的视觉问答方法，可以在运行时生成一个描述表以回答关于艺术品的视觉和上下文问题，避免了注释过程。

    

    深度学习和计算机视觉在文化遗产领域中的应用在过去几年中变得越来越重要，有大量音频智能导游、互动博物馆和增强现实的应用。所有这些技术都需要大量的数据才能有效地工作并对用户有用。在艺术品的背景下，这些数据是由专家进行注释的，这是一个昂贵和耗时的过程。特别是，对于每件艺术品，都必须收集一幅艺术品的图像和一个描述表以执行常见任务，例如视觉问答。在本文中，我们提出了一种视觉问答的方法，该方法允许在运行时生成一个描述表，可用于回答有关艺术品的视觉和上下文问题，完全避免了图像和注释过程。为此，我们探索了使用GPT-3为艺术品生成描述的方法，并分析了生成的描述质量。

    The use of Deep Learning and Computer Vision in the Cultural Heritage domain is becoming highly relevant in the last few years with lots of applications about audio smart guides, interactive museums and augmented reality. All these technologies require lots of data to work effectively and be useful for the user. In the context of artworks, such data is annotated by experts in an expensive and time consuming process. In particular, for each artwork, an image of the artwork and a description sheet have to be collected in order to perform common tasks like Visual Question Answering. In this paper we propose a method for Visual Question Answering that allows to generate at runtime a description sheet that can be used for answering both visual and contextual questions about the artwork, avoiding completely the image and the annotation process. For this purpose, we investigate on the use of GPT-3 for generating descriptions for artworks analyzing the quality of generated descriptions through
    
[^138]: 基于神经网络的疾病编码分配中临床问题列表条目的二次使用

    Secondary Use of Clinical Problem List Entries for Neural Network-Based Disease Code Assignment. (arXiv:2112.13756v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.13756](http://arxiv.org/abs/2112.13756)

    本研究基于神经网络探索了使用国际疾病分类对临床问题列表条目进行自动编码，揭示了不一致的手动编码是一个主要的限制因素。

    

    临床信息系统已经成为半结构化和部分注释的电子健康记录数据的大型存储库，这些数据已经达到了一个关键的质量，使它们对于监督的数据驱动神经网络方法非常有趣。我们探索了使用国际疾病分类（ICD-10）对50个字符长的临床问题列表条目进行自动编码，并在前100个ICD-10三位码上评估了三种不同类型的网络架构。一个快速文本基线达到了0.83的宏平均F1分数，其次是一个字符级LSTM，其宏平均F1分数为0.84。表现最佳的方法使用了下游RoBERTa模型和自定义语言模型，得到了0.88的宏平均F1分数。神经网络激活分析以及对假阳性和假阴性的调查揭示了不一致的手动编码是一个主要的限制因素。

    Clinical information systems have become large repositories for semi-structured and partly annotated electronic health record data, which have reached a critical mass that makes them interesting for supervised data-driven neural network approaches. We explored automated coding of 50 character long clinical problem list entries using the International Classification of Diseases (ICD-10) and evaluated three different types of network architectures on the top 100 ICD-10 three-digit codes. A fastText baseline reached a macro-averaged F1-score of 0.83, followed by a character-level LSTM with a macro-averaged F1-score of 0.84. The top performing approach used a downstreamed RoBERTa model with a custom language model, yielding a macro-averaged F1-score of 0.88. A neural network activation analysis together with an investigation of the false positives and false negatives unveiled inconsistent manual coding as a main limiting factor.
    

