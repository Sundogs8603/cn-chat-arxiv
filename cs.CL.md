# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DreamLLM: Synergistic Multimodal Comprehension and Creation.](http://arxiv.org/abs/2309.11499) | DreamLLM是一种学习框架，实现了多模态理解与创作的协同效应。通过直接采样生成语言和图像的生成模型，避免了信息损失，并获得了更全面的多模态理解。此外，DreamLLM能够生成自由形式交织内容，展现了其在零样本多模态学习任务中的卓越性能。 |
| [^2] | [Chain-of-Verification Reduces Hallucination in Large Language Models.](http://arxiv.org/abs/2309.11495) | 该论文提出了一种链式验证方法（CoVe），通过在回答之前进行备查问题来减少大型语言模型中的幻觉。实验证明CoVe方法在各种任务中都能有效降低幻觉的发生。 |
| [^3] | [Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning.](http://arxiv.org/abs/2309.11489) | Text2Reward是一个无需数据的自动化框架，可以根据大型语言模型自动生成可解释、自由形式的密集奖励函数，广泛适用于各种任务，并允许人类反馈进行迭代改进。 |
| [^4] | [Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction.](http://arxiv.org/abs/2309.11439) | 本研究提出了一种称为Prompt Insertion (PI)的控制生成方法，以使大型语言模型能够用自然语言解释语法错误修正的原因。 |
| [^5] | [You Only Look at Screens: Multimodal Chain-of-Action Agents.](http://arxiv.org/abs/2309.11436) | 本论文提出了一种名为Auto-UI的多模态动作链机器人，通过直接与界面交互，避免了环境解析或依赖于应用程序API的需要，并引入了动作链技术来帮助模型进行决策。 |
| [^6] | [Kosmos-2.5: A Multimodal Literate Model.](http://arxiv.org/abs/2309.11419) | Kosmos-2.5是一个多模态文学模型，能够在机器阅读文本密集型图像方面表现出色，并能够生成具有空间感的文本块和结构化文本输出。该模型具有通用性，可以适应不同提示下任何文本密集型图像理解任务，并为未来的扩展提供了方向。 |
| [^7] | [Safurai 001: New Qualitative Approach for Code LLM Evaluation.](http://arxiv.org/abs/2309.11385) | Safurai-001是一种新的代码LLM评估方法，通过充分利用数据工程进展和指令调优，它能够提供与其他最新模型相媲美的性能，并在对话式交互体验方面有所提升。通过引入基于GPT4的多参数评估基准，它提供了全面洞察模型的功能和性能。在评估中，Safurai-001超过了GPT-3.5 1.58%和WizardCoder 18.78%。 |
| [^8] | [Long-Form End-to-End Speech Translation via Latent Alignment Segmentation.](http://arxiv.org/abs/2309.11384) | 本文提出了一种潜在对齐分割方法，通过将语音翻译与分割放在同一个模型中实现了低延迟的端到端语音翻译，该方法是首次实现了这种方式。 |
| [^9] | [Discuss Before Moving: Visual Language Navigation via Multi-expert Discussions.](http://arxiv.org/abs/2309.11382) | 本研究提出了一种新颖的零射击视觉语言导航框架，其中通过与大型模型进行讨论来收集必要的信息，以提升导航性能。 |
| [^10] | [Studying Lobby Influence in the European Parliament.](http://arxiv.org/abs/2309.11381) | 该论文提出了一种基于自然语言处理的方法，用于研究欧洲议会中利益集团（游说团体）的影响力。通过比较利益集团的立场文件和议员的讲话，发现了议员和游说团体之间的联系，并验证了这些联系的有效性。研究结果表明，这种方法能够准确地揭示议员与游说团体之间的关系，对于理解议会立法过程中游说的影响具有重要意义。 |
| [^11] | [Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff.](http://arxiv.org/abs/2309.11379) | 本研究提出了一种增量分块束搜索方法，用于实现同时语音翻译。该方法可以控制质量与延迟的权衡，通过引入本地一致性或保持-n策略来实现。在实验中，我们发现该方法在不改变延迟的情况下可以提高0.6-3.6 BLEU的翻译质量，或者在不改变质量的情况下可以提高0.8-1.4秒的延迟。 |
| [^12] | [GECTurk: Grammatical Error Correction and Detection Dataset for Turkish.](http://arxiv.org/abs/2309.11346) | GECTurk是一个用于土耳其语的语法错误纠正和检测数据集。它采用灵活且可扩展的合成数据生成流水线，覆盖了20多个专家策划的语法和拼写规则，并且通过手动注释电影评论创造了更真实的测试集。 |
| [^13] | [Improving Article Classification with Edge-Heterogeneous Graph Neural Networks.](http://arxiv.org/abs/2309.11341) | 本论文提出了一种使用边异构图神经网络改进文章分类的方法，通过加入高阶语义的节点特征生成，能够显著提高分类性能。 |
| [^14] | [TRAVID: An End-to-End Video Translation Framework.](http://arxiv.org/abs/2309.11338) | TRAVID是一个端到端的视频翻译框架，不仅可以翻译口语，还可以将翻译的语音与说话者的嘴唇动作同步，为学生和用户提供了一种增强的视频翻译体验。 |
| [^15] | [Leveraging Data Collection and Unsupervised Learning for Code-switched Tunisian Arabic Automatic Speech Recognition.](http://arxiv.org/abs/2309.11327) | 本研究通过收集和标注数据以及探索切换方法，提出了一种有效的突尼斯方言自动语音识别解决方案，并且通过人工评估来消除拼写不合适的干扰。 |
| [^16] | [DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services.](http://arxiv.org/abs/2309.11325) | DISC-LawLLM是一种利用大型语言模型(LLMs)为智能法律服务细调的智能法律系统，通过采用法律推理提示策略和增强的检索模块，提供了在中国司法领域多样化法律场景下的有效法律服务。 |
| [^17] | [Rating Prediction in Conversational Task Assistants with Behavioral and Conversational-Flow Features.](http://arxiv.org/abs/2309.11307) | 本文提出了一种预测对话任务助手的评分的方法，通过将对话流特征和用户行为特征结合起来，并使用真实人-机对话和评分数据进行模型训练和分析。结果表明，将对话流和行为方面的特征考虑在内的模型在离线评分预测中具有优势，并且对CTA特定行为特征的分析可以为未来的系统提供启发。 |
| [^18] | [CPLLM: Clinical Prediction with Large Language Models.](http://arxiv.org/abs/2309.11295) | CPLLM是一种使用大规模语言模型进行临床疾病预测的方法。通过量化和提示来微调语言模型，利用患者的历史诊断记录来预测目标疾病的诊断结果。实验证明，CPLLM在各项指标上均超越了其他基线模型，显示出显著的改进。 |
| [^19] | [Overview of AuTexTification at IberLEF 2023: Detection and Attribution of Machine-Generated Text in Multiple Domains.](http://arxiv.org/abs/2309.11285) | AuTexTification是IberLEF 2023研讨会的共享任务，旨在检测和归属多领域机器生成的文本。数据集包含160,000多条文本，涵盖了英语和西班牙语以及推文、评论、新闻、法律和操作指南等五个领域。共有114个团队参与，提交了175次运行结果。 |
| [^20] | [The Wizard of Curiosities: Enriching Dialogues with Fun Facts.](http://arxiv.org/abs/2309.11283) | 该论文介绍了在对话中引入趣味事实的方法，提高了用户对对话系统的参与度和整体体验，通过A/B测试显示该方法相对评分提高了9.7%。 |
| [^21] | [Grounded Complex Task Segmentation for Conversational Assistants.](http://arxiv.org/abs/2309.11271) | 本文通过将结构化指令转化为会话式指令，针对会话助手中的复杂任务分割问题进行了研究。实验结果表明基于标记的Transformer模型在计算会话步骤特征方面效果最好，并且用户研究证明提出的方法可以改善原始指令的效果。 |
| [^22] | [Sequence-to-Sequence Spanish Pre-trained Language Models.](http://arxiv.org/abs/2309.11259) | 该论文介绍了一种新的序列到序列的西班牙预训练语言模型，该模型在各种序列到序列任务中表现出了竞争性能，并提供了BART、T5和BERT2BERT-style模型的西班牙版本。 |
| [^23] | [The Scenario Refiner: Grounding subjects in images at the morphological level.](http://arxiv.org/abs/2309.11252) | 本文研究了视觉和语言（V＆L）模型在形态学层面上是否捕捉到衍生相关词的语义差异，并发现了模型与人类参与者之间的不一致性，尤其表现出一种语法偏见。该研究可为测试V＆L模型在捕捉其他微妙语言特征方面的能力提供方法。 |
| [^24] | [OpenChat: Advancing Open-source Language Models with Mixed-Quality Data.](http://arxiv.org/abs/2309.11235) | OpenChat是一种用于推进开源语言模型的新框架，能够利用混合质量数据中的信息并简化RLFT方法的求解过程。 |
| [^25] | [Speak While You Think: Streaming Speech Synthesis During Text Generation.](http://arxiv.org/abs/2309.11210) | 本论文提出了LLM2Speech，一种在文本生成过程中边合成语音的架构，通过利用隐藏嵌入来实现流式合成，从而显著减少了生成语音的延迟，并保持了高质量的生成文本。 |
| [^26] | [Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering.](http://arxiv.org/abs/2309.11206) | 提出了一种提高知识图谱问答任务性能的增强型LLMs框架，通过转化KG知识为文本化陈述的方式，实现了对答案敏感的KG-to-Text方法。 |
| [^27] | [The Languini Kitchen: Enabling Language Modelling Research at Different Scales of Compute.](http://arxiv.org/abs/2309.11197) | Languini Kitchen是一个研究集体和代码库，旨在通过等效计算来进行语言模型比较，并提供新的大规模、多样化且高质量的数据集。要点：实验协议、模型比较、等效计算、大规模数据集。 |
| [^28] | [Are Large Language Models Really Robust to Word-Level Perturbations?.](http://arxiv.org/abs/2309.11166) | 该论文提出了一种用于评估大型语言模型（LLMs）鲁棒性的新颖方法，使用预训练的奖励模型作为诊断工具。实验证明这种方法在评估LLM鲁棒性方面表现准确。 |
| [^29] | [Assessment of Pre-Trained Models Across Languages and Grammars.](http://arxiv.org/abs/2309.11165) | 本研究通过评估预训练模型在多语言和语法上的表现，发现预训练词向量对句法表示没有偏好，而语言在预训练数据中的出现频率比任务数据的数量更重要。 |
| [^30] | [CoT-BERT: Enhancing Unsupervised Sentence Representation through Chain-of-Thought.](http://arxiv.org/abs/2309.11143) | CoT-BERT提出了一种通过思维链条增强无监督句子表示的方法，通过两个阶段的处理，引入思维链条的概念进行向量化，以提高模型性能。 |
| [^31] | [Prototype of a robotic system to assist the learning process of English language with text-generation through DNN.](http://arxiv.org/abs/2309.11142) | 本文介绍了一个利用长短时记忆神经网络生成文本的机器人系统原型，可用于辅助英语学习者。实验结果表明与该系统交互的学习者的语法范围有所提升。 |
| [^32] | [Language-Oriented Communication with Semantic Coding and Knowledge Distillation for Text-to-Image Generation.](http://arxiv.org/abs/2309.11127) | 本文提出了一种基于语义编码和知识蒸馏的面向语言的通信框架，通过将大型语言模型和生成模型集成到语义通信范式中，实现了使用人类语言消息进行通信的效率。同时引入了语义源编码、语义信道编码和语义知识蒸馏等创新算法来提高通信的效果。 |
| [^33] | [AttentionMix: Data augmentation method that relies on BERT attention mechanism.](http://arxiv.org/abs/2309.11104) | AttentionMix是一种新的数据增强方法，利用了基于注意力的信息。在三个标准情感分类数据集上的评估结果表明，AttentionMix在NLP领域的数据增强中表现优于使用Mixup机制的两种基准方法和普通BERT方法。 |
| [^34] | [K-pop Lyric Translation: Dataset, Analysis, and Neural-Modelling.](http://arxiv.org/abs/2309.11093) | 研究者介绍了一种新颖的K-pop歌词翻译数据集，该数据集揭示了K-pop歌词翻译的独特特征，并构建了一个神经歌词翻译模型，强调了专用数据集的重要性。 |
| [^35] | [Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning.](http://arxiv.org/abs/2309.11082) | 本文提出了一种双模态注意增强的文本-视频检索方法，通过引入新颖的对比学习技术，能够准确衡量跨模态相似性和挖掘难负样本。 |
| [^36] | [UniPCM: Universal Pre-trained Conversation Model with Task-aware Automatic Prompt.](http://arxiv.org/abs/2309.11065) | 本论文提出了一种使用任务感知自动提示生成来扩展预训练对话模型语料库的方法，从而构建了通用预训练对话模型（UniPCM）。实验证明，UniPCM具有鲁棒性、强大的迁移能力，并在不同对话任务上取得最先进的结果。 |
| [^37] | [XATU: A Fine-grained Instruction-based Benchmark for Explainable Text Updates.](http://arxiv.org/abs/2309.11063) | XATU是第一个细粒度基于指令的可解释性文本编辑基准测试，涵盖广泛的编辑类型，并通过引入细粒度指令和黄金标准编辑说明来提高可解释性。 |
| [^38] | [Design of Chain-of-Thought in Math Problem Solving.](http://arxiv.org/abs/2309.11054) | 本论文研究了数学问题解决中思路链的设计方法，对比了自然语言思路链和程序思路链的效果，并发现程序思路链通常在数学问题解决中更加有效，特别是自我描述程序具有更大多样性且性能更高。此外，研究还发现Python是程序思路链的较好选择。实验结果为未来思路链设计提供了宝贵指导。 |
| [^39] | [Localize, Retrieve and Fuse: A Generalized Framework for Free-Form Question Answering over Tables.](http://arxiv.org/abs/2309.11049) | 本文提出了一个广义框架，用于处理表格上的自由形式问答，在选取相关的表格单元、检索外部知识、以及推理集成时面临的挑战进行了探索。 |
| [^40] | [Heterogeneous Entity Matching with Complex Attribute Associations using BERT and Neural Networks.](http://arxiv.org/abs/2309.11046) | 使用BERT和神经网络构建了一种新颖的实体匹配模型，能够处理具有不同格式和复杂属性关联的异构实体数据。 |
| [^41] | [Making Small Language Models Better Multi-task Learners with Mixture-of-Task-Adapters.](http://arxiv.org/abs/2309.11042) | 本论文提出了一种使用任务适配器的混合多任务学习方法，通过在小型语言模型上构建混合任务适配器，同时处理多个NLP任务，并通过两阶段训练方法优化适配器之间的协作，从而实现在较小的计算成本下支持多个领域特定应用。 |
| [^42] | [Named Entity Recognition via Machine Reading Comprehension: A Multi-Task Learning Approach.](http://arxiv.org/abs/2309.11027) | 这项论文提出了一种多任务学习的方法来改进基于机器阅读理解的命名实体识别(NER)，通过捕获标签依赖关系，能够更准确地识别命名实体。 |
| [^43] | [Towards Joint Modeling of Dialogue Response and Speech Synthesis based on Large Language Model.](http://arxiv.org/abs/2309.11000) | 本文通过使用大型语言模型（LLMs）同时对对话回应和语言特征进行联合建模，探索了构建统一口语对话系统的潜力。实验结果表明，基于LLM的方法是一个有前景的方向。 |
| [^44] | [MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods.](http://arxiv.org/abs/2309.10966) | 本文提出了MBR微调和QE微调方法，将训练时的质量提升蒸馏到基准模型中，从而在推断时使用高效的解码算法。实验证明，这些微调方法能显著提升模型性能，甚至超过基准模型。 |
| [^45] | [In-Context Learning for Text Classification with Many Labels.](http://arxiv.org/abs/2309.10954) | 本文通过使用预训练的密集检索模型，解决了上下文学习中的标签限制问题，并在多个意图分类数据集的少样本设置中取得了新的最佳性能，同时在某些情况下超越了微调模型的表现。研究还发现，更大规模的模型对于有效利用更长的上下文长度进行上下文学习是必要的。 |
| [^46] | [LMDX: Language Model-based Document Information Extraction and Localization.](http://arxiv.org/abs/2309.10952) | LMDX是一种基于语言模型的文档信息提取与定位方法，克服了布局编码和答案虚构的困难，能够在半结构化文档中提取关键实体。 |
| [^47] | [Benchmarks for Pir\'a 2.0, a Reading Comprehension Dataset about the Ocean, the Brazilian Coast, and Climate Change.](http://arxiv.org/abs/2309.10945) | 通过创建基准测试，我们为Pir\'a 2.0数据集定义了六个不同的问答任务的测试，可以更好地利用该数据集来评估当前机器学习模型在阅读理解方面的能力。 |
| [^48] | [A Family of Pretrained Transformer Language Models for Russian.](http://arxiv.org/abs/2309.10931) | 本文介绍了一组专门针对俄语的预训练Transformer语言模型，包括编码器、解码器和编码器-解码器模型。这些模型在俄语自然语言理解和生成方面展现了良好的泛化能力，希望能够推动俄语领域的NLP研究和工业应用的发展。 |
| [^49] | [Specializing Small Language Models towards Complex Style Transfer via Latent Attribute Pre-Training.](http://arxiv.org/abs/2309.10929) | 本文介绍了复杂文本风格转移任务的概念，并通过构建大规模数据集和使用小型模型以及隐式风格预训练进行实验来解决大型语言模型的问题。研究结果表明，我们的模型在少样本文本风格转移方面取得了最新的性能水平。 |
| [^50] | [Semi-Autoregressive Streaming ASR With Label Context.](http://arxiv.org/abs/2309.10926) | 提出了一种带有标签上下文的半自回归流式自动语音识别模型，通过使用语言模型子网络，将先前块中的标签作为额外的上下文进行建模。实验结果表明，该方法在流式自动语音识别中取得了更好的性能。 |
| [^51] | [Semi-automatic staging area for high-quality structured data extraction from scientific literature.](http://arxiv.org/abs/2309.10923) | 这篇论文介绍了一种半自动化分区平台，用于从科学文献中提取超导体实验数据。该平台通过自动和手动过程的结合，提高了数据更新效率，同时保持或提高了数据质量。评估实验表明该分区平台显著提高了数据的管理质量。 |
| [^52] | [End-to-End Speech Recognition Contextualization with Large Language Models.](http://arxiv.org/abs/2309.10917) | 本论文介绍了一种在语音识别中使用大型语言模型进行上下文化的新方法。通过整合预训练的语言模型，我们的方法在训练过程中通过提供音频特征和文本上下文，使系统隐含地学习如何利用上下文信息，并达到了显著的性能改善。 |
| [^53] | [What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples.](http://arxiv.org/abs/2309.10916) | 本文将图像处理领域中的对抗子空间技术应用于自然语言处理，提出了基于最近邻和影响函数的检测器，并通过使用影响函数揭示了自然语言处理中的对抗样本子空间与图像处理中的子空间的关系和任务差异。 |
| [^54] | [RedPenNet for Grammatical Error Correction: Outputs to Tokens, Attentions to Spans.](http://arxiv.org/abs/2309.10898) | RedPenNet是一种用于语法错误纠正的方法，解决了文本编辑任务中的架构和参数冗余问题，具有半自回归优势。 |
| [^55] | [Self-Augmentation Improves Zero-Shot Cross-Lingual Transfer.](http://arxiv.org/abs/2309.10891) | 本文提出了一种名为SALT的方法，通过结合代码切换和嵌入混合与自我增强，有效地提高了多语言预训练模型的零样本跨语言传递能力。 |
| [^56] | [Classifying Organizations for Food System Ontologies using Natural Language Processing.](http://arxiv.org/abs/2309.10880) | 本研究使用自然语言处理方法自动对食物系统本体中的组织进行分类，研究结果表明NLP模型可以在这两个分类任务中取得良好性能。 |
| [^57] | [MelodyGLM: Multi-task Pre-training for Symbolic Melody Generation.](http://arxiv.org/abs/2309.10738) | 提出了一种名为MelodyGLM的多任务预训练框架，用于生成具有长期结构的旋律。该框架通过设计音乐n-gram和长跨度抽样策略来捕捉旋律的局部和全局结构，并使用大规模符号旋律数据集进行预训练改进。 |
| [^58] | [NusaWrites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages.](http://arxiv.org/abs/2309.10661) | NusaWrites项目通过母语者段落撰写构建高质量语料库，弥补了在线爬取和翻译文档所带来的词汇多样性和文化相关性的限制。该研究在印度尼西亚地方语言上进行，并提出了“datasetname”基准，涵盖了12种被低估和极度资源匮乏的语言。 |
| [^59] | [Toward Unified Controllable Text Generation via Regular Expression Instruction.](http://arxiv.org/abs/2309.10447) | 本文通过引入正则表达式指令（REI）实现了统一可控文本生成，通过指令方式支持各种约束，无需对架构进行修改，并对各种约束组合表现出良好的性能。 |
| [^60] | [PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training.](http://arxiv.org/abs/2309.10400) | 本文介绍了一种名为PoSE的训练方法，通过在训练过程中使用固定的上下文窗口和操纵位置索引来适应极长的上下文窗口，实验证明这种方法大大减小了内存和时间开销，对性能影响较小，成功将LLaMA模型扩展到了128k个标记。 |
| [^61] | [QASnowball: An Iterative Bootstrapping Framework for High-Quality Question-Answering Data Generation.](http://arxiv.org/abs/2309.10326) | QASnowball是一个迭代自举框架，可以根据有监督的样本种子集生成大规模高质量的QA数据，并通过重新种子化进行自我增强。在高资源英文场景中进行了实验。 |
| [^62] | [Baichuan 2: Open Large-scale Language Models.](http://arxiv.org/abs/2309.10305) | Baichuan 2是一系列开放的大规模多语言模型，拥有70亿和130亿个参数，训练自26万亿个标记。Baichuan 2在公开基准测试中表现出色，并在垂直领域如医学和法律中具有优势。 |
| [^63] | [Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level.](http://arxiv.org/abs/2309.08182) | 本研究证明，使用大型语言模型(如GPT3.5)可以解决和解释物理词问题，通过对物理知识进行计算和推理，实现了接近人类水平的解决率。此外，该模型还能够总结涉及的知识、生成解释，并创造新的物理词问题。 |
| [^64] | [PromptASR for contextualized ASR with controllable style.](http://arxiv.org/abs/2309.07414) | PromptASR是一个框架，将提示集成到端到端自动语音识别系统中，实现了具有可控风格的语境化语音转录。在实验中，使用前一话语的真实文本作为内容提示时，相对于基线ASR系统，该系统在阅读图书数据集和内部数据集上分别获得了21.9％和6.8％的词错误率降低。此外，该系统可以采用单词级偏置列表作为提示来提高对罕见单词的识别准确性。同时，该系统还可以使用额外的样式提示来引导ASR系统输出不同风格的转录。 |
| [^65] | [Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation.](http://arxiv.org/abs/2308.15363) | 本文提出了一个大规模语言模型(LLMs)赋能的文本到SQL任务的基准评估，并基于实验结果提出了一种新的集成解决方案DAIL-SQL，刷新了Spider榜单并实现了86.6%的执行准确率。同时，强调了在提示工程中的词汇效率以实现高效经济的LLM-based文本到SQL解决方案，此外还对在上下文学习中应用开源LLMs进行了研究，并进行了任务特定的性能优化。 |
| [^66] | [MT4CrossOIE: Multi-stage Tuning for Cross-lingual Open Information Extraction.](http://arxiv.org/abs/2308.06552) | MT4CrossOIE是一种多阶段调优框架，用于增强跨语种开放信息提取。它通过向共享模型注入语言特定知识，并利用多个低秩语言特定模块进行模型转移。 |
| [^67] | [EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus.](http://arxiv.org/abs/2307.11760) | EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。 |
| [^68] | [Concept-Oriented Deep Learning with Large Language Models.](http://arxiv.org/abs/2306.17089) | 本文讨论了大型语言模型在概念导向深度学习中的应用，包括从文本和图像中提取概念和概念图。同时也探讨了多模态语言模型在表达人类知识方面的优势。 |
| [^69] | [Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low Resource Languages.](http://arxiv.org/abs/2305.14949) | 本文提出了一个跨语言数据增强的框架，通过利用高资源语言增强低资源语言的对话生成能力，并采用创新的架构进行多语言对齐，实验证明了模型的有效性。 |
| [^70] | [GPT-3.5, GPT-4, or BARD? Evaluating LLMs Reasoning Ability in Zero-Shot Setting and Performance Boosting Through Prompts.](http://arxiv.org/abs/2305.12477) | 本文通过在多个任务和数据集上对GPT-3.5、GPT-4和BARD进行评估，实验证明在零样本情境中，ChatGPT-4表现出了更高的性能。GPT-4相对于GPT-3.5的优势可能是由其更大的模型规模和NLP效率所引起的，但对于BARD来说并不明显。此外，这三个模型在归纳、数学和多跳推理任务上的表现有限。 |
| [^71] | [MasakhaNEWS: News Topic Classification for African languages.](http://arxiv.org/abs/2304.09972) | 该论文开发了MasakhaNEWS，它是一个覆盖16种非洲语言的新闻主题分类的基准数据集。除了评估基线模型外，还探索了适用于零样本学习和少样本学习的全面微调语言模型的替代方案。 |
| [^72] | [Evaluation of ChatGPT as a Question Answering System for Answering Complex Questions.](http://arxiv.org/abs/2303.07992) | 本论文评估了基于ChatGPT模型的问答系统在回答复杂问题方面的能力，通过一个分类框架对潜在的问题特征进行分类，通过黑盒测试规范CheckList评估模型性能。 |
| [^73] | [Analyzing And Improving Neural Speaker Embeddings for ASR.](http://arxiv.org/abs/2301.04571) | 该论文研究了将神经说话人嵌入应用于ASR系统中，并提出了改进的嵌入提取流程和集成方法，通过改进的声学模型和添加神经说话人嵌入，获得了显著的WER性能提升。 |
| [^74] | [Zero-shot Triplet Extraction by Template Infilling.](http://arxiv.org/abs/2212.10708) | 本论文提出了一种将三元组抽取任务转化为模板填充任务的框架，通过对预训练语言模型进行零样本学习，实现了在没有额外训练数据的情况下对未见关系的抽取，并在实验证明了其稳定且一致的性能表现。 |
| [^75] | [Development of Hybrid ASR Systems for Low Resource Medical Domain Conversational Telephone Speech.](http://arxiv.org/abs/2210.13397) | 本研究开发了针对低资源医疗领域会话电话语音的混合ASR系统，旨在改善患者护理并克服语言障碍。 |
| [^76] | [Attacking Open-domain Question Answering by Injecting Misinformation.](http://arxiv.org/abs/2110.07803) | 本研究探究了将错误信息注入问答系统的攻击，并发现问答模型对于错误信息具有脆弱性，即使少量错误信息的污染也会导致性能大幅下降。 |
| [^77] | [Procedures as Programs: Hierarchical Control of Situated Agents through Natural Language.](http://arxiv.org/abs/2109.08214) | 本文提出了一种以程序为过程的形式化方法，用于代理指令和控制。通过建立层级模块化网络，将自然语言意图转化为可执行程序的预测，并在两个数据集上取得了显著性能优势。 |

# 详细

[^1]: DreamLLM：协同的多模态理解与创作

    DreamLLM: Synergistic Multimodal Comprehension and Creation. (arXiv:2309.11499v1 [cs.CV])

    [http://arxiv.org/abs/2309.11499](http://arxiv.org/abs/2309.11499)

    DreamLLM是一种学习框架，实现了多模态理解与创作的协同效应。通过直接采样生成语言和图像的生成模型，避免了信息损失，并获得了更全面的多模态理解。此外，DreamLLM能够生成自由形式交织内容，展现了其在零样本多模态学习任务中的卓越性能。

    

    本文介绍了DreamLLM，一种学习框架，它首次实现了多模态大型语言模型（MLLMs），利用了多模态理解与创作之间经常被忽视的协同效应。DreamLLM遵循两个基本原则。第一个原则专注于通过在原始多模态空间中进行直接采样来生成语言和图像后验的生成建模。这种方法避免了像CLIP这样的外部特征提取器所固有的限制和信息损失，并获得了更全面的多模态理解。其次，DreamLLM促进了原始的、交织的文件生成，对文本和图像内容以及非结构化布局进行建模。这使得DreamLLM能够有效地学习所有条件、边缘和联合多模态分布。作为结果，DreamLLM是第一个能够生成自由形式交织内容的MLLM。综合实验突显了DreamLLM作为零样本多模态学习任务的卓越性能。

    This paper presents DreamLLM, a learning framework that first achieves versatile Multimodal Large Language Models (MLLMs) empowered with frequently overlooked synergy between multimodal comprehension and creation. DreamLLM operates on two fundamental principles. The first focuses on the generative modeling of both language and image posteriors by direct sampling in the raw multimodal space. This approach circumvents the limitations and information loss inherent to external feature extractors like CLIP, and a more thorough multimodal understanding is obtained. Second, DreamLLM fosters the generation of raw, interleaved documents, modeling both text and image contents, along with unstructured layouts. This allows DreamLLM to learn all conditional, marginal, and joint multimodal distributions effectively. As a result, DreamLLM is the first MLLM capable of generating free-form interleaved content. Comprehensive experiments highlight DreamLLM's superior performance as a zero-shot multimodal
    
[^2]: 链式验证减少大型语言模型中的幻觉

    Chain-of-Verification Reduces Hallucination in Large Language Models. (arXiv:2309.11495v1 [cs.CL])

    [http://arxiv.org/abs/2309.11495](http://arxiv.org/abs/2309.11495)

    该论文提出了一种链式验证方法（CoVe），通过在回答之前进行备查问题来减少大型语言模型中的幻觉。实验证明CoVe方法在各种任务中都能有效降低幻觉的发生。

    

    大型语言模型中存在生成合理但不正确的事实信息（即幻觉）的问题，我们研究了语言模型在给出回复时进行思考以纠正错误的能力。我们开发了一种链式验证（CoVe）方法，模型首先（i）起草初始回复；然后（ii）计划验证问题来事实检查草稿；（iii）独立回答这些问题，以避免答案受其他回复的影响；最后（iv）生成最终的经过验证的回答。在实验中，我们展示了CoVe在各种任务中降低了幻觉的情况，包括来自维基数据的列表问题、封闭书籍MultiSpanQA和长文本生成。

    Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response. In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation.
    
[^3]: Text2Reward：针对强化学习的自动生成密集奖励函数的自动化框架

    Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning. (arXiv:2309.11489v1 [cs.LG])

    [http://arxiv.org/abs/2309.11489](http://arxiv.org/abs/2309.11489)

    Text2Reward是一个无需数据的自动化框架，可以根据大型语言模型自动生成可解释、自由形式的密集奖励函数，广泛适用于各种任务，并允许人类反馈进行迭代改进。

    

    设计奖励函数是强化学习中长期以来的挑战；它需要专业知识或领域数据，导致开发成本高。为了解决这个问题，我们引入了Text2Reward，一个无需数据的框架，可基于大型语言模型（LLM）自动生成密集奖励函数。给定自然语言描述的目标，Text2Reward生成作为环境紧凑表示的可执行程序的密集奖励函数。与逆强化学习和最近使用LLM编写稀疏奖励代码的工作不同，Text2Reward生成可解释的、自由形式的密集奖励代码，可涵盖各种任务，利用现有软件包，并允许通过人类反馈进行迭代改进。我们在两个机器人操作基准（ManiSkill2，MetaWorld）和两个MuJoCo的运动环境上评估了Text2Reward。在17个操作任务中的13个任务中，使用生成的奖励代码训练的政策实现了类似或更好的性能。

    Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development. To address this, we introduce Text2Reward, a data-free framework that automates the generation of dense reward functions based on large language models (LLMs). Given a goal described in natural language, Text2Reward generates dense reward functions as an executable program grounded in a compact representation of the environment. Unlike inverse RL and recent work that uses LLMs to write sparse reward codes, Text2Reward produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback. We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2, MetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17 manipulation tasks, policies trained with generated reward codes achieve similar or better
    
[^4]: 在语法错误修正中通过提示插入实现自然语言解释的可控生成

    Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction. (arXiv:2309.11439v1 [cs.CL])

    [http://arxiv.org/abs/2309.11439](http://arxiv.org/abs/2309.11439)

    本研究提出了一种称为Prompt Insertion (PI)的控制生成方法，以使大型语言模型能够用自然语言解释语法错误修正的原因。

    

    在语法错误修正（GEC）中，确保用户理解修正原因至关重要。现有研究提供了基于修正原因的标记、示例和提示，但未直接解释修正原因。虽然已提出使用大型语言模型（LLMs）为各种任务提供直接的自然语言解释的方法，但在GEC领域尚无此类方法。生成GEC修正的解释涉及对齐输入和输出标记，识别修正点，并始终呈现相应的解释。然而，由于提示难以显式地控制生成，因此很难指定复杂的格式来生成解释。本研究介绍了一种称为Prompt Insertion (PI)的控制生成方法，以使LLMs能够用自然语言解释修正原因。

    In Grammatical Error Correction (GEC), it is crucial to ensure the user's comprehension of a reason for correction. Existing studies present tokens, examples, and hints as to the basis for correction but do not directly explain the reasons for corrections. Although methods that use Large Language Models (LLMs) to provide direct explanations in natural language have been proposed for various tasks, no such method exists for GEC. Generating explanations for GEC corrections involves aligning input and output tokens, identifying correction points, and presenting corresponding explanations consistently. However, it is not straightforward to specify a complex format to generate explanations, because explicit control of generation is difficult with prompts. This study introduces a method called controlled generation with Prompt Insertion (PI) so that LLMs can explain the reasons for corrections in natural language. In PI, LLMs first correct the input text, and then we automatically extract th
    
[^5]: 你仅关注屏幕：多模态动作链机器人

    You Only Look at Screens: Multimodal Chain-of-Action Agents. (arXiv:2309.11436v1 [cs.CL])

    [http://arxiv.org/abs/2309.11436](http://arxiv.org/abs/2309.11436)

    本论文提出了一种名为Auto-UI的多模态动作链机器人，通过直接与界面交互，避免了环境解析或依赖于应用程序API的需要，并引入了动作链技术来帮助模型进行决策。

    

    自主用户界面（UI）机器人旨在通过与用户界面进行交互，实现任务自动化，无需手动干预。最近的研究探讨了利用大型语言模型（LLM）的能力，以在多样环境中有效参与。为了符合LLM的输入-输出要求，现有方法在沙盒环境中开发，依赖于外部工具和应用程序特定的API将环境解析为文本元素，并解释预测的动作。因此，这些方法常常受到推理效率低和错误传播风险的困扰。为了缓解这些挑战，我们引入了Auto-UI，一种多模态解决方案，它直接与界面交互，避免了对环境解析或依赖于应用程序相关的API的需求。此外，我们提出了一种动作链技术，利用一系列中间先前动作历史和未来动作计划，以帮助模型进行决策。

    Autonomous user interface (UI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To align with the input-output requirement of LLMs, existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions. Consequently, those approaches often grapple with inference inefficiency and error propagation risks. To mitigate the challenges, we introduce Auto-UI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs. Moreover, we propose a chain-of-action technique -leveraging a series of intermediate previous action histories and future action plans -- to help the age
    
[^6]: Kosmos-2.5: 一个多模态文学模型

    Kosmos-2.5: A Multimodal Literate Model. (arXiv:2309.11419v1 [cs.CL])

    [http://arxiv.org/abs/2309.11419](http://arxiv.org/abs/2309.11419)

    Kosmos-2.5是一个多模态文学模型，能够在机器阅读文本密集型图像方面表现出色，并能够生成具有空间感的文本块和结构化文本输出。该模型具有通用性，可以适应不同提示下任何文本密集型图像理解任务，并为未来的扩展提供了方向。

    

    我们介绍了Kosmos-2.5，一个用于对文本密集型图像进行机器阅读的多模态文学模型。Kosmos-2.5在两个不同但相互合作的转录任务中表现出色：(1) 生成具有空间感的文本块，其中每个文本块都被赋予其在图像中的空间坐标，以及(2) 生成以Markdown格式捕捉样式和结构的结构化文本输出。这种统一的多模态文学能力是通过共享的Transformer架构、任务特定的提示和灵活的文本表示实现的。我们在端到端的文档级文本识别和图像到Markdown文本生成上评估了Kosmos-2.5。此外，该模型可以通过监督微调轻松适应具有不同提示的任何文本密集型图像理解任务，使其成为涉及文本丰富图像的实际应用的通用工具。这项工作还为未来的扩展铺平了道路。

    We present Kosmos-2.5, a multimodal literate model for machine reading of text-intensive images. Pre-trained on large-scale text-intensive images, Kosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1) generating spatially-aware text blocks, where each block of text is assigned its spatial coordinates within the image, and (2) producing structured text output that captures styles and structures into the markdown format. This unified multimodal literate capability is achieved through a shared Transformer architecture, task-specific prompts, and flexible text representations. We evaluate Kosmos-2.5 on end-to-end document-level text recognition and image-to-markdown text generation. Furthermore, the model can be readily adapted for any text-intensive image understanding task with different prompts through supervised fine-tuning, making it a general-purpose tool for real-world applications involving text-rich images. This work also paves the way for the future scaling o
    
[^7]: Safurai 001:代码LLM评估的新定性方法

    Safurai 001: New Qualitative Approach for Code LLM Evaluation. (arXiv:2309.11385v1 [cs.CL])

    [http://arxiv.org/abs/2309.11385](http://arxiv.org/abs/2309.11385)

    Safurai-001是一种新的代码LLM评估方法，通过充分利用数据工程进展和指令调优，它能够提供与其他最新模型相媲美的性能，并在对话式交互体验方面有所提升。通过引入基于GPT4的多参数评估基准，它提供了全面洞察模型的功能和性能。在评估中，Safurai-001超过了GPT-3.5 1.58%和WizardCoder 18.78%。

    

    本文介绍了Safurai-001，这是一个具有显著潜力的新的大型语言模型（LLM），在编码辅助领域有着重要的应用。基于最新的编码LLM进展，Safurai-001在性能上与最新模型如WizardCoder、PanguCoder和Phi-1相媲美，但旨在提供更加对话式的交互体验。通过充分利用数据工程的进展（包括最新的数据转换和提示工程技术）和指令调优，这个新模型承诺能够与最近的闭源和开源发展并驾齐驱。鉴于对编码LLM的高效评估指标的需求，本文还介绍了基于GPT4的多参数评估基准，利用多样的参数来全面了解模型的功能和性能。我们的评估结果显示，Safurai-001在性能上能够超过GPT-3.5 1.58%和WizardCoder 18.78%。

    This paper presents Safurai-001, a new Large Language Model (LLM) with significant potential in the domain of coding assistance. Driven by recent advancements in coding LLMs, Safurai-001 competes in performance with the latest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al., 2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more conversational interaction. By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning, this new model promises to stand toe-to-toe with recent closed and open source developments. Recognizing the need for an efficacious evaluation metric for coding LLMs, this paper also introduces GPT4-based MultiParameters, an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance. Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and WizardCoder by 18.78% i
    
[^8]: 通过潜在对齐分割实现长文本端到端语音翻译

    Long-Form End-to-End Speech Translation via Latent Alignment Segmentation. (arXiv:2309.11384v1 [cs.CL])

    [http://arxiv.org/abs/2309.11384](http://arxiv.org/abs/2309.11384)

    本文提出了一种潜在对齐分割方法，通过将语音翻译与分割放在同一个模型中实现了低延迟的端到端语音翻译，该方法是首次实现了这种方式。

    

    当前的同时语音翻译模型只能处理几秒钟的音频。现有数据集可以根据人工标注的转录和翻译提供句子级别的分割。然而，现实世界中并不存在句子级别的分割。目前的语音分割方法要么提供较差的分割质量，要么需要以延迟换取质量。本文提出了一种新颖的分割方法，用于低延迟的端到端语音翻译。我们利用现有的语音翻译编码器-解码器架构与 ST CTC，并证明它可以在没有监督或额外参数的情况下执行分割任务。据我们所知，我们的方法是第一个允许实际的端到端同时语音翻译的方法，因为同一个模型同时用于翻译和分割。在各种语言对和域内外数据上，我们展示了所提出方法的有效性。

    Current simultaneous speech translation models can process audio only up to a few seconds long. Contemporary datasets provide an oracle segmentation into sentences based on human-annotated transcripts and translations. However, the segmentation into sentences is not available in the real world. Current speech segmentation approaches either offer poor segmentation quality or have to trade latency for quality. In this paper, we propose a novel segmentation approach for a low-latency end-to-end speech translation. We leverage the existing speech translation encoder-decoder architecture with ST CTC and show that it can perform the segmentation task without supervision or additional parameters. To the best of our knowledge, our method is the first that allows an actual end-to-end simultaneous speech translation, as the same model is used for translation and segmentation at the same time. On a diverse set of language pairs and in- and out-of-domain data, we show that the proposed approach ac
    
[^9]: 议论再行动：多专家讨论下的视觉语言导航

    Discuss Before Moving: Visual Language Navigation via Multi-expert Discussions. (arXiv:2309.11382v1 [cs.RO])

    [http://arxiv.org/abs/2309.11382](http://arxiv.org/abs/2309.11382)

    本研究提出了一种新颖的零射击视觉语言导航框架，其中通过与大型模型进行讨论来收集必要的信息，以提升导航性能。

    

    视觉语言导航（VLN）是一项需要包括理解、感知和规划在内的广泛技能的任务。对于这样一个多方面的挑战，先前的VLN方法完全依赖于一个模型自己的思考在一个回合内进行预测。然而，现有的模型，甚至是最先进的大型语言模型GPT4，仍然难以通过单回合自我思考来处理多个任务。在这项工作中，我们从专家咨询会议中得到灵感，引入了一种新颖的零射击VLN框架。在这个框架中，具有不同能力的大型模型被作为领域专家。我们提出的导航代理DiscussNav可以在每一步之前与这些专家积极讨论，收集必要的信息再行动。这些讨论涵盖了关键的导航子任务，如指令理解、环境感知和完成估计。通过综合实验，我们证明讨论可以显著提高VLN的性能，尤其是在需要多方面决策的情况下。

    Visual language navigation (VLN) is an embodied task demanding a wide range of skills encompassing understanding, perception, and planning. For such a multifaceted challenge, previous VLN methods totally rely on one model's own thinking to make predictions within one round. However, existing models, even the most advanced large language model GPT4, still struggle with dealing with multiple tasks by single-round self-thinking. In this work, drawing inspiration from the expert consultation meeting, we introduce a novel zero-shot VLN framework. Within this framework, large models possessing distinct abilities are served as domain experts. Our proposed navigation agent, namely DiscussNav, can actively discuss with these experts to collect essential information before moving at every step. These discussions cover critical navigation subtasks like instruction understanding, environment perception, and completion estimation. Through comprehensive experiments, we demonstrate that discussions w
    
[^10]: 研究欧洲议会中游说影响的方法

    Studying Lobby Influence in the European Parliament. (arXiv:2309.11381v1 [cs.CL])

    [http://arxiv.org/abs/2309.11381](http://arxiv.org/abs/2309.11381)

    该论文提出了一种基于自然语言处理的方法，用于研究欧洲议会中利益集团（游说团体）的影响力。通过比较利益集团的立场文件和议员的讲话，发现了议员和游说团体之间的联系，并验证了这些联系的有效性。研究结果表明，这种方法能够准确地揭示议员与游说团体之间的关系，对于理解议会立法过程中游说的影响具有重要意义。

    

    我们提出了一种基于自然语言处理（NLP）的方法，用于研究欧洲议会中利益集团（游说团体）在立法过程中的影响力。我们收集和分析了游说团体的立场文件和议员的讲话，通过比较这些文本的语义相似性和蕴含关系，我们能够发现议员和游说团体之间的可解释联系。在缺乏这种联系的真实数据集的情况下，我们通过将发现的联系与我们策划的一份关于议员和游说团体之间转发链接的数据集以及议员公开披露的会议进行间接验证。我们的最佳方法达到了0.77的AUC分数，并且比几个基准方法表现得更好。此外，对于发现的链接进行的综合分析，涉及相关游说团体和议员的政治团体，与这些团体的意识形态的预期相一致（例如，中左翼团体）。

    We present a method based on natural language processing (NLP), for studying the influence of interest groups (lobbies) in the law-making process in the European Parliament (EP). We collect and analyze novel datasets of lobbies' position papers and speeches made by members of the EP (MEPs). By comparing these texts on the basis of semantic similarity and entailment, we are able to discover interpretable links between MEPs and lobbies. In the absence of a ground-truth dataset of such links, we perform an indirect validation by comparing the discovered links with a dataset, which we curate, of retweet links between MEPs and lobbies, and with the publicly disclosed meetings of MEPs. Our best method achieves an AUC score of 0.77 and performs significantly better than several baselines. Moreover, an aggregate analysis of the discovered links, between groups of related lobbies and political groups of MEPs, correspond to the expectations from the ideology of the groups (e.g., center-left grou
    
[^11]: 增量分块束搜索用于具有可控的质量-延迟权衡的同时语音翻译

    Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff. (arXiv:2309.11379v1 [cs.CL])

    [http://arxiv.org/abs/2309.11379](http://arxiv.org/abs/2309.11379)

    本研究提出了一种增量分块束搜索方法，用于实现同时语音翻译。该方法可以控制质量与延迟的权衡，通过引入本地一致性或保持-n策略来实现。在实验中，我们发现该方法在不改变延迟的情况下可以提高0.6-3.6 BLEU的翻译质量，或者在不改变质量的情况下可以提高0.8-1.4秒的延迟。

    

    最近，基于分块自注意编码模型作为一种有前途的端到端方法在同时语音翻译领域崭露头角。这些模型采用分块束搜索和假设可靠性评分来确定何时等待更多输入语音以便进一步翻译。然而，这种方法直到整个语音输入被消耗掉才能展示出单个的增量翻译，无法直接向用户展示出单个增量翻译。此外，这种方法缺乏控制质量与延迟权衡的机制。我们提出了一种改进的增量分块束搜索方法，结合了本地一致性或保持-n策略用于质量-延迟控制。我们将我们的框架应用于在线或离线翻译模型中，并证明这两种类型都可以有效地在在线模式中使用。MuST-C的实验结果显示0.6-3.6 BLEU的提升而不改变延迟，或0.8-1.4秒的延迟提升而不改变质量。

    Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \textit{incremental} translation to users. Further, this method lacks mechanisms for \textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode.  Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.
    
[^12]: GECTurk：用于土耳其语的语法错误纠正和检测数据集

    GECTurk: Grammatical Error Correction and Detection Dataset for Turkish. (arXiv:2309.11346v1 [cs.CL])

    [http://arxiv.org/abs/2309.11346](http://arxiv.org/abs/2309.11346)

    GECTurk是一个用于土耳其语的语法错误纠正和检测数据集。它采用灵活且可扩展的合成数据生成流水线，覆盖了20多个专家策划的语法和拼写规则，并且通过手动注释电影评论创造了更真实的测试集。

    

    语法错误检测和纠正（GEC）工具已经被证明对于母语使用者和第二语言学习者非常有用。开发这样的工具需要大量平行的、注释的数据，但是对于大多数语言来说，这种数据是不可得到的。合成数据生成是克服这种数据稀缺的常见做法。然而，对于土耳其语这样形态丰富的语言来说，并不直接，因为复杂的写作规则需要音韵、形态和句法信息。在这项工作中，我们提出了一个灵活且可扩展的土耳其语合成数据生成流水线，涵盖了20多个专家策划的语法和拼写规则（即写作规则），通过复杂的转换函数实现。使用这个流水线，我们从专业编辑的文章中派生出了13万条高质量的平行句子。此外，我们通过手动注释一组电影评论来创建一个更真实的测试集。我们实现了三个基准线，制定了任务的

    Grammatical Error Detection and Correction (GEC) tools have proven useful for native speakers and second language learners. Developing such tools requires a large amount of parallel, annotated data, which is unavailable for most languages. Synthetic data generation is a common practice to overcome the scarcity of such data. However, it is not straightforward for morphologically rich languages like Turkish due to complex writing rules that require phonological, morphological, and syntactic information. In this work, we present a flexible and extensible synthetic data generation pipeline for Turkish covering more than 20 expert-curated grammar and spelling rules (a.k.a., writing rules) implemented through complex transformation functions. Using this pipeline, we derive 130,000 high-quality parallel sentences from professionally edited articles. Additionally, we create a more realistic test set by manually annotating a set of movie reviews. We implement three baselines formulating the tas
    
[^13]: 用边异构图神经网络改进文章分类

    Improving Article Classification with Edge-Heterogeneous Graph Neural Networks. (arXiv:2309.11341v1 [cs.LG])

    [http://arxiv.org/abs/2309.11341](http://arxiv.org/abs/2309.11341)

    本论文提出了一种使用边异构图神经网络改进文章分类的方法，通过加入高阶语义的节点特征生成，能够显著提高分类性能。

    

    鉴于现有和新发布的文章数量庞大，将研究成果分类到特定上下文标签体系是一项具有挑战性和相关性的下游任务。我们提出了一种方法，通过使用边异构图表示来丰富简单的图神经网络（GNN）流水线，以提高文章分类的性能。我们使用SciBERT来生成节点特征，以捕捉文章的文本元数据中的高阶语义。我们在Open Graph Benchmark（OGB）ogbn-arxiv数据集和PubMed糖尿病数据集上进行了完全监督的传导式节点分类实验，分别通过Microsoft Academic Graph（MAG）和PubMed Central添加了附加元数据。结果表明，边异构图相对于边同构图，能够始终提高所有GNN模型的性能。转换后的数据使简单且浅层的GNN流水线能够与更复杂的架构相媲美的结果。

    Classifying research output into context-specific label taxonomies is a challenging and relevant downstream task, given the volume of existing and newly published articles. We propose a method to enhance the performance of article classification by enriching simple Graph Neural Networks (GNN) pipelines with edge-heterogeneous graph representations. SciBERT is used for node feature generation to capture higher-order semantics within the articles' textual metadata. Fully supervised transductive node classification experiments are conducted on the Open Graph Benchmark (OGB) ogbn-arxiv dataset and the PubMed diabetes dataset, augmented with additional metadata from Microsoft Academic Graph (MAG) and PubMed Central, respectively. The results demonstrate that edge-heterogeneous graphs consistently improve the performance of all GNN models compared to the edge-homogeneous graphs. The transformed data enable simple and shallow GNN pipelines to achieve results on par with more complex architect
    
[^14]: TRAVID：一个端到端的视频翻译框架

    TRAVID: An End-to-End Video Translation Framework. (arXiv:2309.11338v1 [cs.CL])

    [http://arxiv.org/abs/2309.11338](http://arxiv.org/abs/2309.11338)

    TRAVID是一个端到端的视频翻译框架，不仅可以翻译口语，还可以将翻译的语音与说话者的嘴唇动作同步，为学生和用户提供了一种增强的视频翻译体验。

    

    在当今全球化的世界中，与来自不同语言背景的人有效沟通变得越来越重要。虽然传统的语言翻译方法，如文字或仅声音的翻译，可以完成任务，但它们常常无法捕捉到通过面部表情和嘴唇动作传达的完整上下文和微妙信息。在本文中，我们提出了一个端到端的视频翻译系统，它不仅可以翻译口语，还可以将翻译的语音与说话者的嘴唇动作同步。我们的系统专注于翻译各种印度语言的教育讲座，并且它被设计成在资源有限的系统设置中也能有效。通过将与目标语言一致的嘴唇动作与说话者的声音进行匹配，使用语音克隆技术，我们的应用为学生和用户提供了一种增强的体验。这个附加功能创造了一个更完整的视频翻译体验。

    In today's globalized world, effective communication with people from diverse linguistic backgrounds has become increasingly crucial. While traditional methods of language translation, such as written text or voice-only translations, can accomplish the task, they often fail to capture the complete context and nuanced information conveyed through nonverbal cues like facial expressions and lip movements. In this paper, we present an end-to-end video translation system that not only translates spoken language but also synchronizes the translated speech with the lip movements of the speaker. Our system focuses on translating educational lectures in various Indian languages, and it is designed to be effective even in low-resource system settings. By incorporating lip movements that align with the target language and matching them with the speaker's voice using voice cloning techniques, our application offers an enhanced experience for students and users. This additional feature creates a mo
    
[^15]: 利用数据收集和无监督学习进行切换突尼斯阿拉伯语的自动语音识别

    Leveraging Data Collection and Unsupervised Learning for Code-switched Tunisian Arabic Automatic Speech Recognition. (arXiv:2309.11327v1 [eess.AS])

    [http://arxiv.org/abs/2309.11327](http://arxiv.org/abs/2309.11327)

    本研究通过收集和标注数据以及探索切换方法，提出了一种有效的突尼斯方言自动语音识别解决方案，并且通过人工评估来消除拼写不合适的干扰。

    

    开发能够有效识别方言的自动语音识别（ASR）解决方案需要创新的方法，不仅要解决数据稀缺问题，还要处理语言多样性的复杂性。本文针对突尼斯方言，解决了上述ASR挑战。首先，收集了文本和音频数据，并且在某些情况下进行了标注。其次，我们探索自我监督、半监督和少样本切换方法，以在不同突尼斯测试集上推动最先进的技术；涵盖不同的声学、语言和韵律条件。最后，鉴于常规拼写的缺失，我们对转录进行人工评估，以避免测试参考中的拼写不合适所带来的噪声。我们的模型可以转录突尼斯阿拉伯语、英语和法语混合语言的音频样本，并公开发布了所有训练和测试所使用的数据，供公众使用和进一步改进。

    Crafting an effective Automatic Speech Recognition (ASR) solution for dialects demands innovative approaches that not only address the data scarcity issue but also navigate the intricacies of linguistic diversity. In this paper, we address the aforementioned ASR challenge, focusing on the Tunisian dialect. First, textual and audio data is collected and in some cases annotated. Second, we explore self-supervision, semi-supervision and few-shot code-switching approaches to push the state-of-the-art on different Tunisian test sets; covering different acoustic, linguistic and prosodic conditions. Finally, and given the absence of conventional spelling, we produce a human evaluation of our transcripts to avoid the noise coming from spelling inadequacies in our testing references. Our models, allowing to transcribe audio samples in a linguistic mix involving Tunisian Arabic, English and French, and all the data used during training and testing are released for public use and further improvem
    
[^16]: DISC-LawLLM:为智能法律服务细调大型语言模型

    DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services. (arXiv:2309.11325v1 [cs.CL])

    [http://arxiv.org/abs/2309.11325](http://arxiv.org/abs/2309.11325)

    DISC-LawLLM是一种利用大型语言模型(LLMs)为智能法律服务细调的智能法律系统，通过采用法律推理提示策略和增强的检索模块，提供了在中国司法领域多样化法律场景下的有效法律服务。

    

    我们提出了DISC-LawLLM，一种利用大型语言模型(LLMs)提供各种法律服务的智能法律系统。我们采用法律推理提示策略，在中国司法领域构建了监督微调数据集，并使用具备法律推理能力的LLMs进行微调。我们利用检索模块增强了LLMs的能力，以访问和利用外部法律知识。我们还提出了一个全面的法律基准评估系统，DISC-Law-Eval，从客观和主观两个维度评估智能法律系统的性能。在DISC-Law-Eval上的定量和定性结果表明，我们的系统在为不同法律场景下的各种用户提供服务方面具有有效性。详细的资源可以在https://github.com/FudanDISC/DISC-LawLLM上查看。

    We propose DISC-LawLLM, an intelligent legal system utilizing large language models (LLMs) to provide a wide range of legal services. We adopt legal syllogism prompting strategies to construct supervised fine-tuning datasets in the Chinese Judicial domain and fine-tune LLMs with legal reasoning capability. We augment LLMs with a retrieval module to enhance models' ability to access and utilize external legal knowledge. A comprehensive legal benchmark, DISC-Law-Eval, is presented to evaluate intelligent legal systems from both objective and subjective dimensions. Quantitative and qualitative results on DISC-Law-Eval demonstrate the effectiveness of our system in serving various users across diverse legal scenarios. The detailed resources are available at https://github.com/FudanDISC/DISC-LawLLM.
    
[^17]: 使用行为和对话流特征预测对话任务助手的评分预测

    Rating Prediction in Conversational Task Assistants with Behavioral and Conversational-Flow Features. (arXiv:2309.11307v1 [cs.CL])

    [http://arxiv.org/abs/2309.11307](http://arxiv.org/abs/2309.11307)

    本文提出了一种预测对话任务助手的评分的方法，通过将对话流特征和用户行为特征结合起来，并使用真实人-机对话和评分数据进行模型训练和分析。结果表明，将对话流和行为方面的特征考虑在内的模型在离线评分预测中具有优势，并且对CTA特定行为特征的分析可以为未来的系统提供启发。

    

    预测对话任务助手（CTA）的成功对于理解用户行为并相应地采取行动至关重要。在本文中，我们提出了TB-Rater，这是一个Transformer模型，它将对话流特征与用户行为特征相结合，用于预测CTA场景中的用户评分。特别地，我们使用了在Alexa TaskBot挑战中收集的真实人-机对话和评分，这是一个新颖的多模态和多轮对话环境。我们的结果显示，将对话流和行为方面的特征模型化为单一模型对于离线评分预测具有优势。此外，对CTA特定行为特征的分析为这种设置带来了洞察，并且可以用于启动未来的系统。

    Predicting the success of Conversational Task Assistants (CTA) can be critical to understand user behavior and act accordingly. In this paper, we propose TB-Rater, a Transformer model which combines conversational-flow features with user behavior features for predicting user ratings in a CTA scenario. In particular, we use real human-agent conversations and ratings collected in the Alexa TaskBot challenge, a novel multimodal and multi-turn conversational context. Our results show the advantages of modeling both the conversational-flow and behavioral aspects of the conversation in a single model for offline rating prediction. Additionally, an analysis of the CTA-specific behavioral features brings insights into this setting and can be used to bootstrap future systems.
    
[^18]: CPLLM: 基于大规模语言模型的临床预测

    CPLLM: Clinical Prediction with Large Language Models. (arXiv:2309.11295v1 [cs.CL])

    [http://arxiv.org/abs/2309.11295](http://arxiv.org/abs/2309.11295)

    CPLLM是一种使用大规模语言模型进行临床疾病预测的方法。通过量化和提示来微调语言模型，利用患者的历史诊断记录来预测目标疾病的诊断结果。实验证明，CPLLM在各项指标上均超越了其他基线模型，显示出显著的改进。

    

    我们提出了一种使用大规模语言模型 (LLM) 进行临床疾病预测的方法，该方法包括对预训练的语言模型进行微调。我们利用量化和提示来微调LLM，任务是预测患者在下一次就诊或随后的诊断中是否会被诊断为目标疾病，并利用他们的历史诊断记录。我们将结果与多个基线模型进行了比较，包括逻辑回归、RETAIN和Med-BERT，后者是使用结构化电子病历数据进行疾病预测的当前最先进模型。实验结果显示，CPLLM在PR-AUC和ROC-AUC指标上均超过了所有测试模型，相比基线模型显示出显著的改进。

    We present Clinical Prediction with Large Language Models (CPLLM), a method that involves fine-tuning a pre-trained Large Language Model (LLM) for clinical disease prediction. We utilized quantization and fine-tuned the LLM using prompts, with the task of predicting whether patients will be diagnosed with a target disease during their next visit or in the subsequent diagnosis, leveraging their historical diagnosis records. We compared our results versus various baselines, including Logistic Regression, RETAIN, and Med-BERT, which is the current state-of-the-art model for disease prediction using structured EHR data. Our experiments have shown that CPLLM surpasses all the tested models in terms of both PR-AUC and ROC-AUC metrics, displaying noteworthy enhancements compared to the baseline models.
    
[^19]: 《IberLEF 2023的AuTexTification概述：多领域机器生成文本的检测和归属》

    Overview of AuTexTification at IberLEF 2023: Detection and Attribution of Machine-Generated Text in Multiple Domains. (arXiv:2309.11285v1 [cs.CL])

    [http://arxiv.org/abs/2309.11285](http://arxiv.org/abs/2309.11285)

    AuTexTification是IberLEF 2023研讨会的共享任务，旨在检测和归属多领域机器生成的文本。数据集包含160,000多条文本，涵盖了英语和西班牙语以及推文、评论、新闻、法律和操作指南等五个领域。共有114个团队参与，提交了175次运行结果。

    

    本文介绍了作为IberLEF 2023研讨会一部分的AuTexTification共享任务的概述，该研讨会是在SEPLN 2023会议框架内的伊比利亚语言评估论坛中进行的。AuTexTification包括两个子任务：在子任务1中，参与者需要确定一段文本是人工撰写还是由大型语言模型生成的。在子任务2中，参与者需要将机器生成的文本归属于六种不同的文本生成模型之一。我们的AuTexTification 2023数据集涵盖了两种语言（英语和西班牙语）和五个领域（推文、评论、新闻、法律和操作指南），共包含超过160,000条文本。共有114个团队报名参与，其中36个团队提交了175次运行结果，其中20个团队还提交了工作笔记。在这个概述中，我们介绍了AuTexTification数据集和任务，以及参与系统的结果。

    This paper presents the overview of the AuTexTification shared task as part of the IberLEF 2023 Workshop in Iberian Languages Evaluation Forum, within the framework of the SEPLN 2023 conference. AuTexTification consists of two subtasks: for Subtask 1, participants had to determine whether a text is human-authored or has been generated by a large language model. For Subtask 2, participants had to attribute a machine-generated text to one of six different text generation models. Our AuTexTification 2023 dataset contains more than 160.000 texts across two languages (English and Spanish) and five domains (tweets, reviews, news, legal, and how-to articles). A total of 114 teams signed up to participate, of which 36 sent 175 runs, and 20 of them sent their working notes. In this overview, we present the AuTexTification dataset and task, the submitted participating systems, and the results.
    
[^20]: 趣味事实世界的巫师：用趣闻娱乐方式丰富对话

    The Wizard of Curiosities: Enriching Dialogues with Fun Facts. (arXiv:2309.11283v1 [cs.CL])

    [http://arxiv.org/abs/2309.11283](http://arxiv.org/abs/2309.11283)

    该论文介绍了在对话中引入趣味事实的方法，提高了用户对对话系统的参与度和整体体验，通过A/B测试显示该方法相对评分提高了9.7%。

    

    在对话中引入趣味事实是以一种愉快和有趣的方式向对方传授新知识。通过将上下文相关的趣味事实融入对话中，可以提升用户对对话系统的感知和整体用户体验。本文介绍了一组定制的趣味事实，针对烹饪和DIY领域的对话进行丰富。具体而言，我们使用在亚马逊Alexa TaskBot挑战的多模态和多轮对话环境中收集到的真实人与机器人对话。根据超过1000个对话的A/B测试结果，趣味事实不仅增加了用户的参与度，还提供了平均相对评分提高了9.7%。

    Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.
    
[^21]: 为会话助手的复杂任务分割建立基础

    Grounded Complex Task Segmentation for Conversational Assistants. (arXiv:2309.11271v1 [cs.CL])

    [http://arxiv.org/abs/2309.11271](http://arxiv.org/abs/2309.11271)

    本文通过将结构化指令转化为会话式指令，针对会话助手中的复杂任务分割问题进行了研究。实验结果表明基于标记的Transformer模型在计算会话步骤特征方面效果最好，并且用户研究证明提出的方法可以改善原始指令的效果。

    

    与阅读相同的指令相比，会话助手在执行复杂指令时往往会面临注意力和记忆力短缺的问题。因此，当会话助手引导用户完成复杂任务的步骤时，需要将任务结构化为合适长度和复杂度的可管理信息。本文针对食谱领域，将结构化指令转化为会话式指令。我们根据会话场景注释了指令的结构，以了解该场景中的期望行为。为了计算上述会话步骤的特征，我们测试了各种基于Transformer的架构，结果显示基于标记的方法效果最好。进一步的用户研究表明，用户倾向于接受长度和复杂度适中的步骤，并且提出的方法可以提高原始基于网页的指令的效果。

    Following complex instructions in conversational assistants can be quite daunting due to the shorter attention and memory spans when compared to reading the same instructions. Hence, when conversational assistants walk users through the steps of complex tasks, there is a need to structure the task into manageable pieces of information of the right length and complexity. In this paper, we tackle the recipes domain and convert reading structured instructions into conversational structured ones. We annotated the structure of instructions according to a conversational scenario, which provided insights into what is expected in this setting. To computationally model the conversational step's characteristics, we tested various Transformer-based architectures, showing that a token-based approach delivers the best results. A further user study showed that users tend to favor steps of manageable complexity and length, and that the proposed methodology can improve the original web-based instructi
    
[^22]: 序列到序列的西班牙预训练语言模型

    Sequence-to-Sequence Spanish Pre-trained Language Models. (arXiv:2309.11259v1 [cs.CL])

    [http://arxiv.org/abs/2309.11259](http://arxiv.org/abs/2309.11259)

    该论文介绍了一种新的序列到序列的西班牙预训练语言模型，该模型在各种序列到序列任务中表现出了竞争性能，并提供了BART、T5和BERT2BERT-style模型的西班牙版本。

    

    近年来，预训练语言模型的重大进展为许多非英语语言版本的开发铺平了道路，其中特别关注了仅编码器和仅解码器的架构。虽然西班牙语语言模型包括BERT、RoBERTa和GPT在自然语言理解和生成方面展现出了优势，但在涉及输入输出对的序列到序列任务中，缺乏编码器-解码器模型。本文通过引入实施和评估著名的仅在西班牙语语料库上进行预训练的编码器-解码器架构，开创了新的领域。具体而言，我们提出了BART、T5和BERT2BERT风格模型的西班牙语版本，并对它们在各种序列到序列任务上进行了全面评估，包括摘要、重述和生成式问答。我们的研究结果强调了所有模型的竞争性能，其中BART和T5表现出色。

    In recent years, substantial advancements in pre-trained language models have paved the way for the development of numerous non-English language versions, with a particular focus on encoder-only and decoder-only architectures. While Spanish language models encompassing BERT, RoBERTa, and GPT have exhibited prowess in natural language understanding and generation, there remains a scarcity of encoder-decoder models designed for sequence-to-sequence tasks involving input-output pairs. This paper breaks new ground by introducing the implementation and evaluation of renowned encoder-decoder architectures, exclusively pre-trained on Spanish corpora. Specifically, we present Spanish versions of BART, T5, and BERT2BERT-style models and subject them to a comprehensive assessment across a diverse range of sequence-to-sequence tasks, spanning summarization, rephrasing, and generative question answering. Our findings underscore the competitive performance of all models, with BART and T5 emerging a
    
[^23]: 场景细化器：在形态学层面上将主题与图像相联系

    The Scenario Refiner: Grounding subjects in images at the morphological level. (arXiv:2309.11252v1 [cs.CL])

    [http://arxiv.org/abs/2309.11252](http://arxiv.org/abs/2309.11252)

    本文研究了视觉和语言（V＆L）模型在形态学层面上是否捕捉到衍生相关词的语义差异，并发现了模型与人类参与者之间的不一致性，尤其表现出一种语法偏见。该研究可为测试V＆L模型在捕捉其他微妙语言特征方面的能力提供方法。

    

    衍生的相关词，如"runner"和"running"，展示了语义上的差异，也引发了不同的视觉场景。本文探讨了视觉和语言（V＆L）模型在形态学层面上是否捕捉到这些区别，使用了一种新的方法和数据集。我们将V＆L模型的结果与人类判断结果进行比较，发现模型的预测与人类参与者的不同，尤其表现出一种语法偏见。我们进一步研究了人类模型不对齐与模型架构之间的关系。我们的方法可以进一步推广用于测试模型在捕捉其他微妙语言特征方面的能力。

    Derivationally related words, such as "runner" and "running", exhibit semantic differences which also elicit different visual scenarios. In this paper, we ask whether Vision and Language (V\&L) models capture such distinctions at the morphological level, using a a new methodology and dataset. We compare the results from V\&L models to human judgements and find that models' predictions differ from those of human participants, in particular displaying a grammatical bias. We further investigate whether the human-model misalignment is related to model architecture. Our methodology, developed on one specific morphological contrast, can be further extended for testing models on capturing other nuanced language features.
    
[^24]: OpenChat: 用混合质量数据推进开源语言模型

    OpenChat: Advancing Open-source Language Models with Mixed-Quality Data. (arXiv:2309.11235v1 [cs.CL])

    [http://arxiv.org/abs/2309.11235](http://arxiv.org/abs/2309.11235)

    OpenChat是一种用于推进开源语言模型的新框架，能够利用混合质量数据中的信息并简化RLFT方法的求解过程。

    

    如今，像LLaMA这样的开源大型语言模型已经出现。最近的发展中使用了监督微调（SFT）和强化学习微调（RLFT）来使这些模型与人类目标保持一致。然而，SFT方法将所有训练数据的混合质量等同对待，而RLFT方法则需要高质量的成对或基于排名的偏好数据。在这项研究中，我们提出了一种新的框架，名为OpenChat，用于利用混合质量数据推进开源语言模型。具体而言，我们考虑了一般的SFT训练数据，其中包含了少量的专家数据和大量的次优数据，没有任何优先级标签。我们提出了C(onditioned)-RLFT，将不同的数据源视为粗粒度的奖励标签，并学习一个条件化策略，以利用互补的数据质量信息。有趣的是，在C-RLFT中，最优策略可以通过单阶段无强化学习的监督学习轻松求解，使得该问题得到了简化。

    Nowadays, open-source large language models like LLaMA have emerged. Recent developments have incorporated supervised fine-tuning (SFT) and reinforcement learning fine-tuning (RLFT) to align these models with human goals. However, SFT methods treat all training data with mixed quality equally, while RLFT methods require high-quality pairwise or ranking-based preference data. In this study, we present a novel framework, named OpenChat, to advance open-source language models with mixed-quality data. Specifically, we consider the general SFT training data, consisting of a small amount of expert data mixed with a large proportion of sub-optimal data, without any preference labels. We propose the C(onditioned)-RLFT, which regards different data sources as coarse-grained reward labels and learns a class-conditioned policy to leverage complementary data quality information. Interestingly, the optimal policy in C-RLFT can be easily solved through single-stage, RL-free supervised learning, whic
    
[^25]: 边生成文本边合成语音：在文本生成过程中进行流式语音合成

    Speak While You Think: Streaming Speech Synthesis During Text Generation. (arXiv:2309.11210v1 [eess.AS])

    [http://arxiv.org/abs/2309.11210](http://arxiv.org/abs/2309.11210)

    本论文提出了LLM2Speech，一种在文本生成过程中边合成语音的架构，通过利用隐藏嵌入来实现流式合成，从而显著减少了生成语音的延迟，并保持了高质量的生成文本。

    

    大型语言模型（LLMs）展示了令人印象深刻的能力，但是与这些模型的交互大多通过文本进行。使用文本到语音（Text-To-Speech）来合成LLM输出通常会导致显著的延迟，这对于流利的语音对话来说是不切实际的。我们提出了LLM2Speech，一种在LLM生成文本的同时合成语音的架构，可以显著减少延迟。LLM2Speech模仿非流式教师模型的预测，同时限制对未来上下文的暴露，以实现流式合成。它利用LLM的隐藏嵌入，这是文本生成的副产品，包含有信息的语义上下文。实验结果显示，LLM2Speech保持了教师模型的质量，同时减少了延迟，使自然对话成为可能。

    Large Language Models (LLMs) demonstrate impressive capabilities, yet interaction with these models is mostly facilitated through text. Using Text-To-Speech to synthesize LLM outputs typically results in notable latency, which is impractical for fluent voice conversations. We propose LLM2Speech, an architecture to synthesize speech while text is being generated by an LLM which yields significant latency reduction. LLM2Speech mimics the predictions of a non-streaming teacher model while limiting the exposure to future context in order to enable streaming. It exploits the hidden embeddings of the LLM, a by-product of the text generation that contains informative semantic context. Experimental results show that LLM2Speech maintains the teacher's quality while reducing the latency to enable natural conversations.
    
[^26]: 提取-改写-回答：一种用于知识图谱问答的增强型LLMs框架

    Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering. (arXiv:2309.11206v1 [cs.CL])

    [http://arxiv.org/abs/2309.11206](http://arxiv.org/abs/2309.11206)

    提出了一种提高知识图谱问答任务性能的增强型LLMs框架，通过转化KG知识为文本化陈述的方式，实现了对答案敏感的KG-to-Text方法。

    

    尽管大型语言模型（LLMs）在知识密集型任务上表现出色，但仍然存在在记忆所有世界知识，尤其是长尾知识方面的局限性。本文研究了基于知识图谱增强语言模型的方法，用于解决需要丰富世界知识的知识图谱问答（KGQA）任务。现有的工作表明，检索知识图谱（KG）以增强LLMs提示可以显著改善KGQA中LLMs的性能。然而，他们的方法缺乏基于文本的合理表述KG知识，即忽略了KG表示和文本表示之间的差距。为此，我们提出了一种对答案敏感的KG-to-Text方法，可以将KG知识转化为最具信息量的文本化陈述，用于KGQA。基于该方法，我们提出了一种用于解决KGQA任务的增强型KG-to-Text LLMS框架。在几个KGQA基准上的实验表明，所提出的KG-to-Text增强LLMs方法在性能上表现优异。

    Despite their competitive performance on knowledge-intensive tasks, large language models (LLMs) still have limitations in memorizing all world knowledge especially long tail knowledge. In this paper, we study the KG-augmented language model approach for solving the knowledge graph question answering (KGQA) task that requires rich world knowledge. Existing work has shown that retrieving KG knowledge to enhance LLMs prompting can significantly improve LLMs performance in KGQA. However, their approaches lack a well-formed verbalization of KG knowledge, i.e., they ignore the gap between KG representations and textual representations. To this end, we propose an answer-sensitive KG-to-Text approach that can transform KG knowledge into well-textualized statements most informative for KGQA. Based on this approach, we propose a KG-to-Text enhanced LLMs framework for solving the KGQA task. Experiments on several KGQA benchmarks show that the proposed KG-to-Text augmented LLMs approach outperfor
    
[^27]: Languini Kitchen: 在不同计算规模上实现语言模型研究

    The Languini Kitchen: Enabling Language Modelling Research at Different Scales of Compute. (arXiv:2309.11197v1 [cs.LG])

    [http://arxiv.org/abs/2309.11197](http://arxiv.org/abs/2309.11197)

    Languini Kitchen是一个研究集体和代码库，旨在通过等效计算来进行语言模型比较，并提供新的大规模、多样化且高质量的数据集。要点：实验协议、模型比较、等效计算、大规模数据集。

    

    Languini Kitchen既是一个研究集体，又是一个代码库，旨在赋予计算资源有限的研究人员对语言模型领域做出有意义贡献的能力。我们引入了一个实验协议，使得可以基于等效计算（以加速器小时计量）来进行模型比较。模型训练的令牌数量由模型的吞吐量和选择的计算类别来定义。值得注意的是，这种方法避免了对影响总参数或浮点操作的关键超参数的限制。为了评估，我们预处理了一个现有的大规模、多样化且高质量的图书数据集，该数据集在质量、多样性和文档长度方面超过了现有的学术基准。在此基础上，我们通过不同计算水平上的实验来估计方法的经验性扩展趋势。这项工作还提供了两个基准模型：从GPT-2架构推导出的前馈模型及...

    The Languini Kitchen serves as both a research collective and codebase designed to empower researchers with limited computational resources to contribute meaningfully to the field of language modelling. We introduce an experimental protocol that enables model comparisons based on equivalent compute, measured in accelerator hours. The number of tokens on which a model is trained is defined by the model's throughput and the chosen compute class. Notably, this approach avoids constraints on critical hyperparameters which affect total parameters or floating-point operations. For evaluation, we pre-process an existing large, diverse, and high-quality dataset of books that surpasses existing academic benchmarks in quality, diversity, and document length. On it, we compare methods based on their empirical scaling trends which are estimated through experiments at various levels of compute. This work also provides two baseline models: a feed-forward model derived from the GPT-2 architecture and
    
[^28]: 大型语言模型对单词级扰动真的具有鲁棒性吗？

    Are Large Language Models Really Robust to Word-Level Perturbations?. (arXiv:2309.11166v1 [cs.CL])

    [http://arxiv.org/abs/2309.11166](http://arxiv.org/abs/2309.11166)

    该论文提出了一种用于评估大型语言模型（LLMs）鲁棒性的新颖方法，使用预训练的奖励模型作为诊断工具。实验证明这种方法在评估LLM鲁棒性方面表现准确。

    

    大型语言模型（LLMs）在规模和能力上的快速发展使它们成为各种下游任务的有前途的工具。除了追求更好的性能和避免对特定提示的激烈反馈外，确保LLM的责任性还需要关注LLMs的鲁棒性。然而，现有的评估方法大多依赖于具有预定义监督标签的传统问答数据集，这与当代LLMs的出色生成能力不一致。为了解决这个问题，我们提出了一种新颖的合理评估方法，利用预训练的奖励模型作为诊断工具来评估LLMs的鲁棒性，我们将其称为合理鲁棒性评估的奖励模型（TREvaL）。我们广泛的实证实验表明，TREval提供了一种准确评估LLM鲁棒性的方法，特别是面对更具挑战性的开放式问题时。

    The swift advancement in the scale and capabilities of Large Language Models (LLMs) positions them as promising tools for a variety of downstream tasks. In addition to the pursuit of better performance and the avoidance of violent feedback on a certain prompt, to ensure the responsibility of the LLM, much attention is drawn to the robustness of LLMs. However, existing evaluation methods mostly rely on traditional question answering datasets with predefined supervised labels, which do not align with the superior generation capabilities of contemporary LLMs. To address this issue, we propose a novel rational evaluation approach that leverages pre-trained reward models as diagnostic tools to evaluate the robustness of LLMs, which we refer to as the Reward Model for Reasonable Robustness Evaluation (TREvaL). Our extensive empirical experiments have demonstrated that TREval provides an accurate method for evaluating the robustness of an LLM, especially when faced with more challenging open 
    
[^29]: 跨语言和语法对预训练模型的评估

    Assessment of Pre-Trained Models Across Languages and Grammars. (arXiv:2309.11165v1 [cs.CL])

    [http://arxiv.org/abs/2309.11165](http://arxiv.org/abs/2309.11165)

    本研究通过评估预训练模型在多语言和语法上的表现，发现预训练词向量对句法表示没有偏好，而语言在预训练数据中的出现频率比任务数据的数量更重要。

    

    我们提出了一种评估多语言大型语言模型（LLMs）在多形式的句法结构方面学习句法的方法。我们通过将解析视为序列标记来恢复组成和依赖结构。为此，我们选择了几个LLMs，并在13个不同的UD树库用于依赖解析和10个树库用于组成解析进行研究。我们的结果显示：（i）该框架在不同编码之间具有一致性，（ii）预训练词向量不偏好依赖语法而非组成语法表示，（iii）子词标记化是表示句法的必要条件，与基于字符的模型相反，（iv）从词向量中恢复句法时，语言在预训练数据中的出现频率比任务数据的数量更重要。

    We present an approach for assessing how multilingual large language models (LLMs) learn syntax in terms of multi-formalism syntactic structures. We aim to recover constituent and dependency structures by casting parsing as sequence labeling. To do so, we select a few LLMs and study them on 13 diverse UD treebanks for dependency parsing and 10 treebanks for constituent parsing. Our results show that: (i) the framework is consistent across encodings, (ii) pre-trained word vectors do not favor constituency representations of syntax over dependencies, (iii) sub-word tokenization is needed to represent syntax, in contrast to character-based models, and (iv) occurrence of a language in the pretraining data is more important than the amount of task data when recovering syntax from the word vectors.
    
[^30]: CoT-BERT: 通过思维链条增强无监督句子表示

    CoT-BERT: Enhancing Unsupervised Sentence Representation through Chain-of-Thought. (arXiv:2309.11143v1 [cs.CL])

    [http://arxiv.org/abs/2309.11143](http://arxiv.org/abs/2309.11143)

    CoT-BERT提出了一种通过思维链条增强无监督句子表示的方法，通过两个阶段的处理，引入思维链条的概念进行向量化，以提高模型性能。

    

    无监督句子表示学习旨在将输入句子转化为富含复杂语义信息的固定长度向量，同时消除对标注数据的依赖。近年来，在对比学习和提示工程的推动下，该领域取得了显著进展，极大地缩小了无监督和有监督策略之间的差距。然而，在这个轨迹中，仍然没有充分利用思维链条的潜在能力。为了释放预训练模型（如BERT）中的潜能，我们提出了一个句子表示的两阶段方法：理解和摘要。随后，后一阶段的输出被利用为输入句子的向量化表示。为了进一步提高性能，我们对对比学习损失函数和模板去噪技术进行了精细调整。严格的实验验证了我们的方法CoT-BERT的优越性。

    Unsupervised sentence representation learning aims to transform input sentences into fixed-length vectors enriched with intricate semantic information while obviating the reliance on labeled data. Recent progress within this field, propelled by contrastive learning and prompt engineering, has significantly bridged the gap between unsupervised and supervised strategies. Nonetheless, the potential utilization of Chain-of-Thought, remains largely untapped within this trajectory. To unlock latent capabilities within pre-trained models, such as BERT, we propose a two-stage approach for sentence representation: comprehension and summarization. Subsequently, the output of the latter phase is harnessed as the vectorized representation of the input sentence. For further performance enhancement, we meticulously refine both the contrastive learning loss function and the template denoising technique for prompt engineering. Rigorous experimentation substantiates our method, CoT-BERT, transcending a
    
[^31]: 一种用DNN通过文本生成辅助英语学习过程的机器人系统的原型

    Prototype of a robotic system to assist the learning process of English language with text-generation through DNN. (arXiv:2309.11142v1 [cs.CL])

    [http://arxiv.org/abs/2309.11142](http://arxiv.org/abs/2309.11142)

    本文介绍了一个利用长短时记忆神经网络生成文本的机器人系统原型，可用于辅助英语学习者。实验结果表明与该系统交互的学习者的语法范围有所提升。

    

    在过去的几年中，自然语言处理（NLP）领域取得了显著的进展，包括英语教学。一种有效的策略是使用交互式设备来吸引学习者参与自主学习过程。本文介绍了一个工作原型，即通过使用长短时记忆（LSTM）神经网络生成文本来帮助学习英语的人。学习者通过图形用户界面与系统进行交互，该界面根据用户的英语水平生成文本。实验使用英语学习者进行，并根据国际英语语言测试系统（IELTS）评分标准进行测量。初步结果显示使用该系统的学习者的语法范围有所增加。

    In the last ongoing years, there has been a significant ascending on the field of Natural Language Processing (NLP) for performing multiple tasks including English Language Teaching (ELT). An effective strategy to favor the learning process uses interactive devices to engage learners in their self-learning process. In this work, we present a working prototype of a humanoid robotic system to assist English language self-learners through text generation using Long Short Term Memory (LSTM) Neural Networks. The learners interact with the system using a Graphic User Interface that generates text according to the English level of the user. The experimentation was conducted using English learners and the results were measured accordingly to International English Language Testing System (IELTS) rubric. Preliminary results show an increment in the Grammatical Range of learners who interacted with the system.
    
[^32]: 基于语义编码和知识蒸馏的面向语言的通信用于文本到图像生成

    Language-Oriented Communication with Semantic Coding and Knowledge Distillation for Text-to-Image Generation. (arXiv:2309.11127v1 [eess.SP])

    [http://arxiv.org/abs/2309.11127](http://arxiv.org/abs/2309.11127)

    本文提出了一种基于语义编码和知识蒸馏的面向语言的通信框架，通过将大型语言模型和生成模型集成到语义通信范式中，实现了使用人类语言消息进行通信的效率。同时引入了语义源编码、语义信道编码和语义知识蒸馏等创新算法来提高通信的效果。

    

    通过将最近的大型语言模型（LLM）和生成模型集成到新兴的语义通信（SC）范式中，本文提出了一种新颖的面向语言的语义通信（LSC）框架。在LSC中，机器使用可以通过自然语言处理（NLP）技术解释和操作的人类语言消息进行通信，以提高SC效率。为了展示LSC的潜力，我们引入了三种创新算法：1）语义源编码（SSC），将文本提示压缩成捕捉提示的句法本质的关键头词，同时保持它们的出现顺序以保持提示的上下文；2）语义信道编码（SCC），通过用更长的同义词替换头词来提高对错误的容错性；3）语义知识蒸馏（SKD），通过在上下文中学习听众的语言风格来生成定制的提示。在逐步进行的通信任务中，我们验证了LSC的潜在能力。

    By integrating recent advances in large language models (LLMs) and generative models into the emerging semantic communication (SC) paradigm, in this article we put forward to a novel framework of language-oriented semantic communication (LSC). In LSC, machines communicate using human language messages that can be interpreted and manipulated via natural language processing (NLP) techniques for SC efficiency. To demonstrate LSC's potential, we introduce three innovative algorithms: 1) semantic source coding (SSC) which compresses a text prompt into its key head words capturing the prompt's syntactic essence while maintaining their appearance order to keep the prompt's context; 2) semantic channel coding (SCC) that improves robustness against errors by substituting head words with their lenghthier synonyms; and 3) semantic knowledge distillation (SKD) that produces listener-customized prompts via in-context learning the listener's language style. In a communication task for progressive te
    
[^33]: AttentionMix: 一种基于BERT注意机制的数据增强方法

    AttentionMix: Data augmentation method that relies on BERT attention mechanism. (arXiv:2309.11104v1 [cs.CL])

    [http://arxiv.org/abs/2309.11104](http://arxiv.org/abs/2309.11104)

    AttentionMix是一种新的数据增强方法，利用了基于注意力的信息。在三个标准情感分类数据集上的评估结果表明，AttentionMix在NLP领域的数据增强中表现优于使用Mixup机制的两种基准方法和普通BERT方法。

    

    Mixup方法在计算机视觉领域已被证明是一种强大的数据增强技术，并且有许多以引导方式执行图像混合的后继方法。将Mixup思想应用于其他领域，如自然语言处理（NLP），是一个有趣的研究方向。尽管已经存在一些将Mixup应用于文本数据的方法，但仍有改进的空间。在本文中，我们介绍了AttentionMix，一种基于注意力的混合方法。虽然本文关注BERT注意机制，但所提出的方法可以应用于任何基于注意力的模型。AttentionMix在3个标准情感分类数据集上进行了评估，并在所有三种情况下表现优于利用Mixup机制和普通BERT方法的两种基准方法。结果证实，注意力的信息可以有效地用于NLP领域的数据增强。

    The Mixup method has proven to be a powerful data augmentation technique in Computer Vision, with many successors that perform image mixing in a guided manner. One of the interesting research directions is transferring the underlying Mixup idea to other domains, e.g. Natural Language Processing (NLP). Even though there already exist several methods that apply Mixup to textual data, there is still room for new, improved approaches. In this work, we introduce AttentionMix, a novel mixing method that relies on attention-based information. While the paper focuses on the BERT attention mechanism, the proposed approach can be applied to generally any attention-based model. AttentionMix is evaluated on 3 standard sentiment classification datasets and in all three cases outperforms two benchmark approaches that utilize Mixup mechanism, as well as the vanilla BERT method. The results confirm that the attention-based information can be effectively used for data augmentation in the NLP domain.
    
[^34]: K-pop歌词翻译：数据集、分析与神经建模

    K-pop Lyric Translation: Dataset, Analysis, and Neural-Modelling. (arXiv:2309.11093v1 [cs.CL])

    [http://arxiv.org/abs/2309.11093](http://arxiv.org/abs/2309.11093)

    研究者介绍了一种新颖的K-pop歌词翻译数据集，该数据集揭示了K-pop歌词翻译的独特特征，并构建了一个神经歌词翻译模型，强调了专用数据集的重要性。

    

    歌词翻译作为一个研究了一个世纪的领域，如今吸引着计算语言学研究者的注意。我们在以往研究中发现了两个限制。首先，在歌词翻译研究中，尽管K-pop非常受欢迎，但主要关注的是西方流派和语言，没有研究集中在K-pop上。其次，歌词翻译领域缺乏可公开获得的数据集；据我们所知，目前尚无此类数据集。为了拓宽歌词翻译研究的流派和语言范围，我们引入了一种新颖的可唱歌词翻译数据集，其中约89%为K-pop歌词。该数据集通过逐行和逐节对齐了韩语和英语歌词。我们利用该数据集揭示了K-pop歌词翻译的独特特征，与其他广泛研究的流派区分开，并构建了一个神经歌词翻译模型，从而强调了专用数据集的重要性。

    Lyric translation, a field studied for over a century, is now attracting computational linguistics researchers. We identified two limitations in previous studies. Firstly, lyric translation studies have predominantly focused on Western genres and languages, with no previous study centering on K-pop despite its popularity. Second, the field of lyric translation suffers from a lack of publicly available datasets; to the best of our knowledge, no such dataset exists. To broaden the scope of genres and languages in lyric translation studies, we introduce a novel singable lyric translation dataset, approximately 89\% of which consists of K-pop song lyrics. This dataset aligns Korean and English lyrics line-by-line and section-by-section. We leveraged this dataset to unveil unique characteristics of K-pop lyric translation, distinguishing it from other extensively studied genres, and to construct a neural lyric translation model, thereby underscoring the importance of a dedicated dataset for
    
[^35]: 双模态注意增强的文本-视频检索与三元部分边际对比学习

    Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning. (arXiv:2309.11082v1 [cs.CV])

    [http://arxiv.org/abs/2309.11082](http://arxiv.org/abs/2309.11082)

    本文提出了一种双模态注意增强的文本-视频检索方法，通过引入新颖的对比学习技术，能够准确衡量跨模态相似性和挖掘难负样本。

    

    近年来，网络视频的爆炸性增长使得文本-视频检索对于视频过滤、推荐和搜索变得越来越重要和流行。文本-视频检索旨在将相关的文本/视频排在不相关的文本/视频之前。该任务的核心是准确衡量文本和视频之间的跨模态相似性。最近，对比学习方法在文本-视频检索方面显示出有希望的结果，其中大部分方法侧重于构建正负样本对以学习文本和视频表示。然而，他们在关注难负样本和模拟不同层次的语义相似性方面不够，存在两个问题。为了解决这两个问题，本文使用两个新方法改进了对比学习。首先，为了利用艰难的例子来提高鲁棒的判别能力，我们提出了一种新颖的双模态注意增强模块(DMAE)，从文本和视觉线索中挖掘难负样本。通过进一步引入一个负面样本筛选机制，该方法可以建模不同级别的语义相似性。

    In recent years, the explosion of web videos makes text-video retrieval increasingly essential and popular for video filtering, recommendation, and search. Text-video retrieval aims to rank relevant text/video higher than irrelevant ones. The core of this task is to precisely measure the cross-modal similarity between texts and videos. Recently, contrastive learning methods have shown promising results for text-video retrieval, most of which focus on the construction of positive and negative pairs to learn text and video representations. Nevertheless, they do not pay enough attention to hard negative pairs and lack the ability to model different levels of semantic similarity. To address these two issues, this paper improves contrastive learning using two novel techniques. First, to exploit hard examples for robust discriminative power, we propose a novel Dual-Modal Attention-Enhanced Module (DMAE) to mine hard negative pairs from textual and visual clues. By further introducing a Negat
    
[^36]: UniPCM: 具有任务感知自动提示的通用预训练对话模型

    UniPCM: Universal Pre-trained Conversation Model with Task-aware Automatic Prompt. (arXiv:2309.11065v1 [cs.CL])

    [http://arxiv.org/abs/2309.11065](http://arxiv.org/abs/2309.11065)

    本论文提出了一种使用任务感知自动提示生成来扩展预训练对话模型语料库的方法，从而构建了通用预训练对话模型（UniPCM）。实验证明，UniPCM具有鲁棒性、强大的迁移能力，并在不同对话任务上取得最先进的结果。

    

    最近的研究表明，多任务预训练可以极大地提高模型的鲁棒性和迁移能力，这对于构建高质量的对话系统至关重要。然而，大多数先前关于多任务预训练的工作严重依赖于人为定义的输入格式或提示，这在质量和数量上都不是最佳的。在这项工作中，我们提出使用基于任务的自动提示生成（TAP）来自动生成高质量的提示。使用生成的高质量提示，我们将预训练对话模型的语料库扩展到了来自15个与对话相关任务的122个数据集，从而得到了通用预训练对话模型（UniPCM），这是一个对于各种对话任务和不同对话系统具有强大基础的模型。广泛的实验表明，UniPCM对输入提示具有鲁棒性，并且能够完成各种对话相关任务。此外，UniPCM具有很强的迁移能力，并在资源有限的场景下表现出色，在9个不同数据集上取得了最先进的结果。

    Recent research has shown that multi-task pre-training greatly improves the model's robustness and transfer ability, which is crucial for building a high-quality dialog system. However, most previous works on multi-task pre-training rely heavily on human-defined input format or prompt, which is not optimal in quality and quantity. In this work, we propose to use Task-based Automatic Prompt generation (TAP) to automatically generate high-quality prompts. Using the high-quality prompts generated, we scale the corpus of the pre-trained conversation model to 122 datasets from 15 dialog-related tasks, resulting in Universal Pre-trained Conversation Model (UniPCM), a powerful foundation model for various conversational tasks and different dialog systems. Extensive experiments have shown that UniPCM is robust to input prompts and capable of various dialog-related tasks. Moreover, UniPCM has strong transfer ability and excels at low resource scenarios, achieving SOTA results on 9 different dat
    
[^37]: XATU: 面向可解释性文本更新的细粒度基于指令的基准测试

    XATU: A Fine-grained Instruction-based Benchmark for Explainable Text Updates. (arXiv:2309.11063v1 [cs.CL])

    [http://arxiv.org/abs/2309.11063](http://arxiv.org/abs/2309.11063)

    XATU是第一个细粒度基于指令的可解释性文本编辑基准测试，涵盖广泛的编辑类型，并通过引入细粒度指令和黄金标准编辑说明来提高可解释性。

    

    文本编辑是一个关键的任务，涉及修改文本以更好地与用户意图对齐。然而，现有的文本编辑基准数据集在提供粗粒度指令方面存在局限性。因此，尽管编辑后的输出似乎合理，但往往偏离了黄金参考中列出的预期更改，导致评估分数较低。为了全面调查大型语言模型的文本编辑能力，本文引入了XATU，这是第一个专门为细粒度基于指令的可解释性文本编辑而设计的基准测试。XATU涵盖了广泛的主题和文本类型，包括词汇、句法、语义和知识密集型的编辑。为了增强可解释性，我们利用高质量的数据源和人工注释，生成了一个包含细粒度指令和黄金标准编辑说明的基准测试。通过评估现有的开放和封闭的大型语言模型对我们的基准测试进行对比

    Text editing is a crucial task that involves modifying text to better align with user intents. However, existing text editing benchmark datasets have limitations in providing only coarse-grained instructions. Consequently, although the edited output may seem reasonable, it often deviates from the intended changes outlined in the gold reference, resulting in low evaluation scores. To comprehensively investigate the text editing capabilities of large language models, this paper introduces XATU, the first benchmark specifically designed for fine-grained instruction-based explainable text editing. XATU covers a wide range of topics and text types, incorporating lexical, syntactic, semantic, and knowledge-intensive edits. To enhance interpretability, we leverage high-quality data sources and human annotation, resulting in a benchmark that includes fine-grained instructions and gold-standard edit explanations. By evaluating existing open and closed large language models against our benchmark
    
[^38]: 数学问题解决中的思路链设计

    Design of Chain-of-Thought in Math Problem Solving. (arXiv:2309.11054v1 [cs.CL])

    [http://arxiv.org/abs/2309.11054](http://arxiv.org/abs/2309.11054)

    本论文研究了数学问题解决中思路链的设计方法，对比了自然语言思路链和程序思路链的效果，并发现程序思路链通常在数学问题解决中更加有效，特别是自我描述程序具有更大多样性且性能更高。此外，研究还发现Python是程序思路链的较好选择。实验结果为未来思路链设计提供了宝贵指导。

    

    思路链在数学问题解决中扮演着至关重要的角色。我们对设计思路链的方法进行了全面的考察，比较了传统自然语言思路链和各种程序思路链，包括自我描述程序、注释描述程序和非描述程序。此外，我们还研究了编程语言对程序思路链的影响，比较了Python和Wolfram语言。通过对GSM8K、MATHQA和SVAMP进行广泛实验，我们发现程序思路链在数学问题解决中通常具有更好的效果。值得注意的是，具有30B参数的最佳组合明显超过了GPT-3.5-turbo。结果表明，自我描述程序提供了更大的多样性，因此通常可以实现更高的性能。我们还发现，Python是程序思路链的更好选择比Wolfram语言。实验结果为未来考虑因素提供了宝贵的指导。

    Chain-of-Thought (CoT) plays a crucial role in reasoning for math problem solving. We conduct a comprehensive examination of methods for designing CoT, comparing conventional natural language CoT with various program CoTs, including the self-describing program, the comment-describing program, and the non-describing program. Furthermore, we investigate the impact of programming language on program CoTs, comparing Python and Wolfram Language. Through extensive experiments on GSM8K, MATHQA, and SVAMP, we find that program CoTs often have superior effectiveness in math problem solving. Notably, the best performing combination with 30B parameters beats GPT-3.5-turbo by a significant margin. The results show that self-describing program offers greater diversity and thus can generally achieve higher performance. We also find that Python is a better choice of language than Wolfram for program CoTs. The experimental results provide a valuable guideline for future CoT designs that take into acco
    
[^39]: 本文提出了一个广义框架，用于通过表格进行自由形式问答：定位、检索和融合。

    Localize, Retrieve and Fuse: A Generalized Framework for Free-Form Question Answering over Tables. (arXiv:2309.11049v1 [cs.CL])

    [http://arxiv.org/abs/2309.11049](http://arxiv.org/abs/2309.11049)

    本文提出了一个广义框架，用于处理表格上的自由形式问答，在选取相关的表格单元、检索外部知识、以及推理集成时面临的挑战进行了探索。

    

    近年来，表格数据上的问答（TableQA）已经引起了越来越多的关注。现有的工作倾向于从一个或几个表格单元中提取信息，生成事实性的简短答案，而缺乏对选定表格单元进行推理的能力。然而，自由形式的TableQA需要更复杂的相关表格单元选择策略和独立信息的复杂集成和推理，这方面的研究还不充分。为此，本文提出了一个广义的三阶段方法：表格到图的转换和单元定位、外部知识检索和表格-文本融合（称为TAG-QA），以解决生成式TableQA中针对长自由形式答案的推理挑战。具体而言，TAG-QA (1) 使用图神经网络定位相关表格单元，以收集相关行和列之间的交叉单元；(2) 利用维基百科的外部知识；(3)...

    Question answering on tabular data (TableQA), which aims at generating answers to questions grounded on a given table, has attracted increasing attention in recent years. Existing work tends to generate factual short-form answers by extracting information from one or a few table cells without reasoning over selected table cells. However, the free-form TableQA, requiring a more complex relevant table cell selection strategy and the complex integration and inference of separate pieces of information, has been under-explored. To this end, this paper proposes a generalized three-stage approach: Table-to-Graph conversion and cell localizing, external knowledge retrieval and table-text fusion (called TAG-QA), addressing the challenge of inferring long free-form answer for generative TableQA. In particular, TAG-QA (1) locates relevant table cells using a graph neural network to gather intersecting cells between relevant rows and columns; (2) leverages external knowledge from Wikipedia and (3)
    
[^40]: 使用BERT和神经网络进行复杂属性关联的异构实体匹配

    Heterogeneous Entity Matching with Complex Attribute Associations using BERT and Neural Networks. (arXiv:2309.11046v1 [cs.CL])

    [http://arxiv.org/abs/2309.11046](http://arxiv.org/abs/2309.11046)

    使用BERT和神经网络构建了一种新颖的实体匹配模型，能够处理具有不同格式和复杂属性关联的异构实体数据。

    

    在各个领域中，来自百度百科和维基百科等不同来源的数据通常呈现出不同的形式。目前的实体匹配方法主要集中在同质化数据上，其特点是属性具有相同的结构和简洁的属性值。然而，这种取向在处理具有多样化格式的数据时面临挑战。此外，目前的方法主要通过聚合相应属性之间的属性值相似度来确定实体相似度，但往往忽视了属性之间复杂的相互关系，其中一个属性可能具有多种关联。简单的逐对属性比较方法无法充分利用实体中所蕴含的丰富信息。为了解决这些挑战，我们引入了一种新颖的实体匹配模型，称为基于BERT和神经网络捕捉复杂属性关系的实体匹配模型（EMM-CCAR），它构建在预训练模型的基础上。

    Across various domains, data from different sources such as Baidu Baike and Wikipedia often manifest in distinct forms. Current entity matching methodologies predominantly focus on homogeneous data, characterized by attributes that share the same structure and concise attribute values. However, this orientation poses challenges in handling data with diverse formats. Moreover, prevailing approaches aggregate the similarity of attribute values between corresponding attributes to ascertain entity similarity. Yet, they often overlook the intricate interrelationships between attributes, where one attribute may have multiple associations. The simplistic approach of pairwise attribute comparison fails to harness the wealth of information encapsulated within entities.To address these challenges, we introduce a novel entity matching model, dubbed Entity Matching Model for Capturing Complex Attribute Relationships(EMM-CCAR),built upon pre-trained models. Specifically, this model transforms the m
    
[^41]: 使用任务适配器的混合多任务学习使小型语言模型更好

    Making Small Language Models Better Multi-task Learners with Mixture-of-Task-Adapters. (arXiv:2309.11042v1 [cs.CL])

    [http://arxiv.org/abs/2309.11042](http://arxiv.org/abs/2309.11042)

    本论文提出了一种使用任务适配器的混合多任务学习方法，通过在小型语言模型上构建混合任务适配器，同时处理多个NLP任务，并通过两阶段训练方法优化适配器之间的协作，从而实现在较小的计算成本下支持多个领域特定应用。

    

    最近，大型语言模型（LLMs）在各种自然语言处理（NLP）任务中取得了惊人的零样本学习性能，特别是文本生成任务。然而，LLMs的尺寸通常会导致模型训练和在线部署的高计算成本。在我们的工作中，我们提出了ALTER，一个在小型语言模型（参数<1B）上有效构建混合任务适配器的多任务学习系统，以同时处理多个NLP任务，并捕捉任务之间的共同点和差异，以支持特定领域的应用。具体而言，在ALTER中，我们提出了任务适配器混合（MTA）模块，作为底层模型变压器架构的扩展，用于捕捉任务内部的知识和任务间的知识。进一步提出了一种两阶段的训练方法，以在较小的计算成本下优化适配器之间的协作。在混合NLP任务的实验结果上

    Recently, Large Language Models (LLMs) have achieved amazing zero-shot learning performance over a variety of Natural Language Processing (NLP) tasks, especially for text generative tasks. Yet, the large size of LLMs often leads to the high computational cost of model training and online deployment. In our work, we present ALTER, a system that effectively builds the multi-tAsk Learners with mixTure-of-task-adaptERs upon small language models (with <1B parameters) to address multiple NLP tasks simultaneously, capturing the commonalities and differences between tasks, in order to support domain-specific applications. Specifically, in ALTER, we propose the Mixture-of-Task-Adapters (MTA) module as an extension to the transformer architecture for the underlying model to capture the intra-task and inter-task knowledge. A two-stage training method is further proposed to optimize the collaboration between adapters at a small computational cost. Experimental results over a mixture of NLP tasks 
    
[^42]: 通过机器阅读理解实现的命名实体识别：一种多任务学习方法

    Named Entity Recognition via Machine Reading Comprehension: A Multi-Task Learning Approach. (arXiv:2309.11027v1 [cs.CL])

    [http://arxiv.org/abs/2309.11027](http://arxiv.org/abs/2309.11027)

    这项论文提出了一种多任务学习的方法来改进基于机器阅读理解的命名实体识别(NER)，通过捕获标签依赖关系，能够更准确地识别命名实体。

    

    命名实体识别(NER)旨在从文本中提取和分类实体提及，并将其归类为预定义的类型(例如，组织或个人名称)。最近，许多工作将NER塑造为机器阅读理解问题(也称为基于MRC的NER)，其中通过MRC回答与预定义实体类型相关的问题来实现实体识别，基于上下文。然而，这些工作忽视了实体类型之间的标签依赖关系，这对于准确识别命名实体至关重要。在本文中，我们提出将实体类型之间的标签依赖关系纳入到多任务学习框架中，以更好地实现基于MRC的NER。我们将基于MRC的NER分解为多个任务，并使用自注意力模块来捕获标签依赖关系。通过在嵌套NER和扁平NER数据集上进行全面实验，验证了所提出的多任务NER的有效性。实验结果表明，多任务NER能够达到更好的效果。

    Named Entity Recognition (NER) aims to extract and classify entity mentions in the text into pre-defined types (e.g., organization or person name). Recently, many works have been proposed to shape the NER as a machine reading comprehension problem (also termed MRC-based NER), in which entity recognition is achieved by answering the formulated questions related to pre-defined entity types through MRC, based on the contexts. However, these works ignore the label dependencies among entity types, which are critical for precisely recognizing named entities. In this paper, we propose to incorporate the label dependencies among entity types into a multi-task learning framework for better MRC-based NER. We decompose MRC-based NER into multiple tasks and use a self-attention module to capture label dependencies. Comprehensive experiments on both nested NER and flat NER datasets are conducted to validate the effectiveness of the proposed Multi-NER. Experimental results show that Multi-NER can ac
    
[^43]: 基于大型语言模型的对话回应和语音合成的联合建模

    Towards Joint Modeling of Dialogue Response and Speech Synthesis based on Large Language Model. (arXiv:2309.11000v1 [cs.CL])

    [http://arxiv.org/abs/2309.11000](http://arxiv.org/abs/2309.11000)

    本文通过使用大型语言模型（LLMs）同时对对话回应和语言特征进行联合建模，探索了构建统一口语对话系统的潜力。实验结果表明，基于LLM的方法是一个有前景的方向。

    

    本文探索构建一个同时“思考如何回答”和“思考如何说话”的AI口语对话系统的潜力，这与当前独立的聊天机器人和文本转语音（TTS）模块的级联流程相比更贴近人类语音生成过程。我们假设具有数十亿参数的大型语言模型（LLMs）具备重要的语音理解能力，并可以同时对对话回应和语言特征进行联合建模。我们进行了两组实验：1）韵律结构预测，这是TTS中的典型前端任务，展示了LLMs的语音理解能力；2）进一步整合对话回应和各种语言特征，使用统一的编码格式。我们的结果表明，基于LLM的方法对于构建统一的口语对话系统是一个有前景的方向。

    This paper explores the potential of constructing an AI spoken dialogue system that "thinks how to respond" and "thinks how to speak" simultaneously, which more closely aligns with the human speech production process compared to the current cascade pipeline of independent chatbot and Text-to-Speech (TTS) modules. We hypothesize that Large Language Models (LLMs) with billions of parameters possess significant speech understanding capabilities and can jointly model dialogue responses and linguistic features. We conduct two sets of experiments: 1) Prosodic structure prediction, a typical front-end task in TTS, demonstrating the speech understanding ability of LLMs, and 2) Further integrating dialogue response and a wide array of linguistic features using a unified encoding format. Our results indicate that the LLM-based approach is a promising direction for building unified spoken dialogue systems.
    
[^44]: MBR和QE微调：对最佳和最昂贵的解码方法进行训练时蒸馏

    MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods. (arXiv:2309.10966v1 [cs.CL])

    [http://arxiv.org/abs/2309.10966](http://arxiv.org/abs/2309.10966)

    本文提出了MBR微调和QE微调方法，将训练时的质量提升蒸馏到基准模型中，从而在推断时使用高效的解码算法。实验证明，这些微调方法能显著提升模型性能，甚至超过基准模型。

    

    最近在自然语言生成（NLG）任务的解码方法研究中表明，传统的波束搜索和贪婪解码算法并不是最优的，因为模型概率不总是与人类偏好一致。为了解决模型困惑度与质量不匹配的问题，提出了一些更强的解码方法，包括质量估计（QE）重排序和最小贝叶斯风险（MBR）解码。尽管这些解码方法实现了最先进的性能，但计算成本过高。在这项工作中，我们提出了MBR微调和QE微调，这些微调方法在训练时蒸馏了这些解码方法的质量提升，在推断时使用高效的解码算法。通过使用神经机器翻译（NMT）这一典型的NLG任务，我们表明即使进行自训练，这些微调方法的性能仍明显优于基准模型。此外，当使用外部LLM作为教师模型时，这些微调方法也表现出了卓越的性能。

    Recent research in decoding methods for Natural Language Generation (NLG) tasks has shown that the traditional beam search and greedy decoding algorithms are not optimal, because model probabilities do not always align with human preferences. Stronger decoding methods, including Quality Estimation (QE) reranking and Minimum Bayes' Risk (MBR) decoding, have since been proposed to mitigate the model-perplexity-vs-quality mismatch. While these decoding methods achieve state-of-the-art performance, they are prohibitively expensive to compute. In this work, we propose MBR finetuning and QE finetuning which distill the quality gains from these decoding methods at training time, while using an efficient decoding algorithm at inference time. Using the canonical NLG task of Neural Machine Translation (NMT), we show that even with self-training, these finetuning methods significantly outperform the base model. Moreover, when using an external LLM as a teacher model, these finetuning methods outp
    
[^45]: 带有多个标签的文本分类中的上下文学习

    In-Context Learning for Text Classification with Many Labels. (arXiv:2309.10954v1 [cs.CL])

    [http://arxiv.org/abs/2309.10954](http://arxiv.org/abs/2309.10954)

    本文通过使用预训练的密集检索模型，解决了上下文学习中的标签限制问题，并在多个意图分类数据集的少样本设置中取得了新的最佳性能，同时在某些情况下超越了微调模型的表现。研究还发现，更大规模的模型对于有效利用更长的上下文长度进行上下文学习是必要的。

    

    使用大型语言模型进行具有许多标签的任务的上下文学习是具有挑战性的，因为有限的上下文窗口使得在提示中难以适应足够数量的示例。在本文中，我们使用预训练的密集检索模型绕过了这个限制，每次推理调用只给模型提供了对完整标签空间的部分视图。在最近的开源语言模型(OPT, LLaMA)上进行测试，我们在三个常见的意图分类数据集的少样本设置中，无需微调即取得了最新的最佳性能。在某些情况下，我们还超越了微调性能在细粒度情感分类上的表现。我们分析了不同数量的上下文示例以及不同模型规模下的性能，表明更大规模的模型对于有效而一致地利用更长的上下文长度进行上下文学习是必要的。通过运行几个消融实验，我们分析了模型对以下内容的使用：a)上下文示例与当前输入的相似度, b) 即时查询语句的相似度。

    In-context learning (ICL) using large language models for tasks with many labels is challenging due to the limited context window, which makes it difficult to fit a sufficient number of examples in the prompt. In this paper, we use a pre-trained dense retrieval model to bypass this limitation, giving the model only a partial view of the full label space for each inference call. Testing with recent open-source LLMs (OPT, LLaMA), we set new state of the art performance in few-shot settings for three common intent classification datasets, with no finetuning. We also surpass fine-tuned performance on fine-grained sentiment classification in certain cases. We analyze the performance across number of in-context examples and different model scales, showing that larger models are necessary to effectively and consistently make use of larger context lengths for ICL. By running several ablations, we analyze the model's use of: a) the similarity of the in-context examples to the current input, b) 
    
[^46]: LMDX：基于语言模型的文档信息提取与定位

    LMDX: Language Model-based Document Information Extraction and Localization. (arXiv:2309.10952v1 [cs.CL])

    [http://arxiv.org/abs/2309.10952](http://arxiv.org/abs/2309.10952)

    LMDX是一种基于语言模型的文档信息提取与定位方法，克服了布局编码和答案虚构的困难，能够在半结构化文档中提取关键实体。

    

    大规模语言模型（LLM）在自然语言处理（NLP）中取得了革命性的进展，改进了许多现有任务的最新技术，并展示了新兴的能力。然而，LLM尚未成功应用于半结构化文档信息提取，这是许多文档处理工作流的核心，包括从视觉丰富的文档（VRD）中提取关键实体，给定预定义的目标模式。LLM在这个任务中的主要障碍是LLM中缺乏布局编码，这对于高质量的提取至关重要，以及缺乏一个基于理论的机制，确保答案不是虚构的。在本文中，我们介绍了一种基于语言模型的文档信息提取与定位（LMDX）的方法，用于将任意LLM适应文档信息提取。LMDX可以提取单一、重复和层次结构实体，无论是否有训练数据，并提供基于理论的保证。

    Large Language Models (LLM) have revolutionized Natural Language Processing (NLP), improving state-of-the-art on many existing tasks and exhibiting emergent capabilities. However, LLMs have not yet been successfully applied on semi-structured document information extraction, which is at the core of many document processing workflows and consists of extracting key entities from a visually rich document (VRD) given a predefined target schema. The main obstacles to LLM adoption in that task have been the absence of layout encoding within LLMs, critical for a high quality extraction, and the lack of a grounding mechanism ensuring the answer is not hallucinated. In this paper, we introduce Language Model-based Document Information Extraction and Localization (LMDX), a methodology to adapt arbitrary LLMs for document information extraction. LMDX can do extraction of singular, repeated, and hierarchical entities, both with and without training data, while providing grounding guarantees and lo
    
[^47]: Pir\'a 2.0的基准测试：一个关于海洋、巴西海岸和气候变化的阅读理解数据集

    Benchmarks for Pir\'a 2.0, a Reading Comprehension Dataset about the Ocean, the Brazilian Coast, and Climate Change. (arXiv:2309.10945v1 [cs.CL])

    [http://arxiv.org/abs/2309.10945](http://arxiv.org/abs/2309.10945)

    通过创建基准测试，我们为Pir\'a 2.0数据集定义了六个不同的问答任务的测试，可以更好地利用该数据集来评估当前机器学习模型在阅读理解方面的能力。

    

    Pir\'a是一个专注于海洋、巴西海岸和气候变化的阅读理解数据集，该数据集是从有关这些主题的科学摘要和报告的收藏中构建而成的。该数据集代表了一种通用的语言资源，特别适用于测试当前机器学习模型获取专家科学知识的能力。尽管具有潜力，但Pir\'a尚未开发出详细的基准测试。通过创建这些基准测试，研究人员可以更轻松地利用Pir\'a作为测试各种问答任务的机器学习模型的资源。在本文中，我们为Pir\'a数据集定义了六个基准测试，涵盖封闭生成问答、机器阅读理解、信息检索、开放式问答、答案触发和多项选择问答。作为这一努力的一部分，我们还制作了原始数据集的精选版本，其中修正了一些语法问题。

    Pir\'a is a reading comprehension dataset focused on the ocean, the Brazilian coast, and climate change, built from a collection of scientific abstracts and reports on these topics. This dataset represents a versatile language resource, particularly useful for testing the ability of current machine learning models to acquire expert scientific knowledge. Despite its potential, a detailed set of baselines has not yet been developed for Pir\'a. By creating these baselines, researchers can more easily utilize Pir\'a as a resource for testing machine learning models across a wide range of question answering tasks. In this paper, we define six benchmarks over the Pir\'a dataset, covering closed generative question answering, machine reading comprehension, information retrieval, open question answering, answer triggering, and multiple choice question answering. As part of this effort, we have also produced a curated version of the original dataset, where we fixed a number of grammar issues, r
    
[^48]: 一种针对俄语的预训练Transformer语言模型家族

    A Family of Pretrained Transformer Language Models for Russian. (arXiv:2309.10931v1 [cs.CL])

    [http://arxiv.org/abs/2309.10931](http://arxiv.org/abs/2309.10931)

    本文介绍了一组专门针对俄语的预训练Transformer语言模型，包括编码器、解码器和编码器-解码器模型。这些模型在俄语自然语言理解和生成方面展现了良好的泛化能力，希望能够推动俄语领域的NLP研究和工业应用的发展。

    

    如今，Transformer语言模型（LMs）是自然语言处理（NLP）研究方法和应用的基本组成部分。然而，专门针对俄语的这种模型的发展却受到了较少的关注。本文介绍了一组基于编码器（ruBERT, ruRoBERTa, ruELECTRA）、解码器（ruGPT-3）和编码器-解码器（ruT5, FRED-T5）模型的13个俄语Transformer LMs，具有多种尺寸。这些模型可通过HuggingFace平台轻松获取。我们提供了模型架构设计和预训练的报告，并评估了它们在俄语自然语言理解和生成数据集以及基准测试中的泛化能力。通过预训练和发布这些专门的Transformer LMs，我们希望拓宽NLP研究方向的范围，并促进针对俄语的工业解决方案的开发。

    Nowadays, Transformer language models (LMs) represent a fundamental component of the NLP research methodologies and applications. However, the development of such models specifically for the Russian language has received little attention. This paper presents a collection of 13 Russian Transformer LMs based on the encoder (ruBERT, ruRoBERTa, ruELECTRA), decoder (ruGPT-3), and encoder-decoder (ruT5, FRED-T5) models in multiple sizes. Access to these models is readily available via the HuggingFace platform. We provide a report of the model architecture design and pretraining, and the results of evaluating their generalization abilities on Russian natural language understanding and generation datasets and benchmarks. By pretraining and releasing these specialized Transformer LMs, we hope to broaden the scope of the NLP research directions and enable the development of industrial solutions for the Russian language.
    
[^49]: 通过潜在属性预训练将小型语言模型特化于复杂风格转移

    Specializing Small Language Models towards Complex Style Transfer via Latent Attribute Pre-Training. (arXiv:2309.10929v1 [cs.CL])

    [http://arxiv.org/abs/2309.10929](http://arxiv.org/abs/2309.10929)

    本文介绍了复杂文本风格转移任务的概念，并通过构建大规模数据集和使用小型模型以及隐式风格预训练进行实验来解决大型语言模型的问题。研究结果表明，我们的模型在少样本文本风格转移方面取得了最新的性能水平。

    

    在这项工作中，我们引入了复杂文本风格转移任务的概念，并基于两个广泛适用的场景构建了复杂文本数据集。我们的数据集是其类别中第一个大规模数据集，包含700个重新表述的句子和来自游戏原神的1,000个句子。尽管大型语言模型（LLM）在复杂文本风格转移方面显示出潜力，但它们存在数据隐私问题、网络不稳定性和高部署成本等缺点。为解决这些问题，我们通过对比学习探索了小型模型（小于T5-3B）在隐式风格预训练方面的有效性。我们还提出了一种基于与ChatGPT的人工评价对齐的文本生成质量自动评估方法。最后，我们将我们的方法与现有方法进行了比较，并展示了我们的模型在少样本文本风格转移模型方面达到了最新的性能水平。

    In this work, we introduce the concept of complex text style transfer tasks, and constructed complex text datasets based on two widely applicable scenarios. Our dataset is the first large-scale data set of its kind, with 700 rephrased sentences and 1,000 sentences from the game Genshin Impact. While large language models (LLM) have shown promise in complex text style transfer, they have drawbacks such as data privacy concerns, network instability, and high deployment costs. To address these issues, we explore the effectiveness of small models (less than T5-3B) with implicit style pre-training through contrastive learning. We also propose a method for automated evaluation of text generation quality based on alignment with human evaluations using ChatGPT. Finally, we compare our approach with existing methods and show that our model achieves state-of-art performances of few-shot text style transfer models.
    
[^50]: 带标签上下文的半自回归流式自动语音识别

    Semi-Autoregressive Streaming ASR With Label Context. (arXiv:2309.10926v1 [cs.CL])

    [http://arxiv.org/abs/2309.10926](http://arxiv.org/abs/2309.10926)

    提出了一种带有标签上下文的半自回归流式自动语音识别模型，通过使用语言模型子网络，将先前块中的标签作为额外的上下文进行建模。实验结果表明，该方法在流式自动语音识别中取得了更好的性能。

    

    非自回归(NAR)建模在语音处理中引起了广泛关注，因为这些模型在推断时间方面比自回归(AR)模型大大降低，同时也达到了较好的转录准确率。由于NAR自动语音识别(ASR)模型必须等待整个话语的完整完成才能进行处理，因此一些研究探索了基于块状注意力的流式NAR模型，以用于低延迟应用。然而，与流式AR和非流式NAR模型相比，流式NAR模型在准确性方面明显滞后。为了解决这个问题，我们提出了一种流式的“半自回归”ASR模型，通过使用语言模型(LM)子网络将先前块中发出的标签作为附加上下文进行建模。我们还引入了一种新颖的贪婪解码算法，能够在块之间附近处理插入和删除错误，同时不显著增加推断时间。实验结果表明，我们的方法优于现有的流式方法。

    Non-autoregressive (NAR) modeling has gained significant interest in speech processing since these models achieve dramatically lower inference time than autoregressive (AR) models while also achieving good transcription accuracy. Since NAR automatic speech recognition (ASR) models must wait for the completion of the entire utterance before processing, some works explore streaming NAR models based on blockwise attention for low-latency applications. However, streaming NAR models significantly lag in accuracy compared to streaming AR and non-streaming NAR models. To address this, we propose a streaming "semi-autoregressive" ASR model that incorporates the labels emitted in previous blocks as additional context using a Language Model (LM) subnetwork. We also introduce a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time. Experiments show that our method outperforms the existing streaming 
    
[^51]: 半自动化分区: 用于从科学文献中提取高质量结构化数据的平台

    Semi-automatic staging area for high-quality structured data extraction from scientific literature. (arXiv:2309.10923v1 [cs.CL])

    [http://arxiv.org/abs/2309.10923](http://arxiv.org/abs/2309.10923)

    这篇论文介绍了一种半自动化分区平台，用于从科学文献中提取超导体实验数据。该平台通过自动和手动过程的结合，提高了数据更新效率，同时保持或提高了数据质量。评估实验表明该分区平台显著提高了数据的管理质量。

    

    在本研究中，我们提出了一个用于从科学文章中采集超导体实验数据的 SuperCon 数据库的分区平台。我们的目标是提高更新 SuperCon 的效率，同时保持或提高数据质量。我们介绍了一个由自动和手动过程组成的工作流驱动的半自动化分区平台，用于从提取的数据库中对数据进行校验和纠错。异常检测自动过程用于预先筛选采集到的数据。用户可以通过定制的用户界面在原始 PDF 文档上进行数据验证和纠错。此外，当记录被纠错时，其原始数据被收集并用于改进机器学习模型的训练数据。评估实验表明我们的分区平台显著提高了数据的管理质量。我们将界面与传统的手动阅读 PDF 文档并在 Excel 文档中记录信息的方法进行了比较。

    In this study, we propose a staging area for ingesting new superconductors' experimental data in SuperCon that is machine-collected from scientific articles. Our objective is to enhance the efficiency of updating SuperCon while maintaining or enhancing the data quality. We present a semi-automatic staging area driven by a workflow combining automatic and manual processes on the extracted database. An anomaly detection automatic process aims to pre-screen the collected data. Users can then manually correct any errors through a user interface tailored to simplify the data verification on the original PDF documents. Additionally, when a record is corrected, its raw data is collected and utilised to improve machine learning models as training data. Evaluation experiments demonstrate that our staging area significantly improves curation quality. We compare the interface with the traditional manual approach of reading PDF documents and recording information in an Excel document. Using the in
    
[^52]: 使用大型语言模型的端到端语音识别上下文化

    End-to-End Speech Recognition Contextualization with Large Language Models. (arXiv:2309.10917v1 [eess.AS])

    [http://arxiv.org/abs/2309.10917](http://arxiv.org/abs/2309.10917)

    本论文介绍了一种在语音识别中使用大型语言模型进行上下文化的新方法。通过整合预训练的语言模型，我们的方法在训练过程中通过提供音频特征和文本上下文，使系统隐含地学习如何利用上下文信息，并达到了显著的性能改善。

    

    近年来，大型语言模型（LLMs）由于其出色的性能和泛化能力而受到研究界的广泛关注。本文介绍了一种新的方法，用于在语音识别模型中融入LLMs进行上下文化。我们的方法将语音识别视为基于预训练LLM的混合模态语言建模任务。我们提供音频特征以及可选的文本标记来训练系统以解码方式完成转录。因此，在训练过程中，系统会隐含地学习如何利用非结构化的上下文信息。我们的实证结果表明性能显著提高，当提供额外的文本上下文时，词错误率（WER）降低了6%。此外，我们发现我们的方法在竞争中表现良好，并在整体上将WER提高了7.5%，对于罕见词语的WER提高了17%，相较于基准上下文化RNN-T系统的训练结果。

    In recent years, Large Language Models (LLMs) have garnered significant attention from the research community due to their exceptional performance and generalization capabilities. In this paper, we introduce a novel method for contextualizing speech recognition models incorporating LLMs. Our approach casts speech recognition as a mixed-modal language modeling task based on a pretrained LLM. We provide audio features, along with optional text tokens for context, to train the system to complete transcriptions in a decoder-only fashion. As a result, the system is implicitly incentivized to learn how to leverage unstructured contextual information during training. Our empirical results demonstrate a significant improvement in performance, with a 6% WER reduction when additional textual context is provided. Moreover, we find that our method performs competitively and improve by 7.5% WER overall and 17% WER on rare words against a baseline contextualized RNN-T system that has been trained on
    
[^53]: 通过学习表示和影响函数，我们能从对抗样本中获得什么信息

    What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples. (arXiv:2309.10916v1 [cs.LG])

    [http://arxiv.org/abs/2309.10916](http://arxiv.org/abs/2309.10916)

    本文将图像处理领域中的对抗子空间技术应用于自然语言处理，提出了基于最近邻和影响函数的检测器，并通过使用影响函数揭示了自然语言处理中的对抗样本子空间与图像处理中的子空间的关系和任务差异。

    

    对抗样本是通过微小扰动来欺骗深度神经网络的，起初在图像处理领域进行研究，最近在自然语言处理领域也开始关注。尽管在自然语言处理中检测对抗样本的方法主要依赖于输入扰动的搜索，但图像处理领域已经发展出一系列技术来表征学习表示中的对抗子空间。本文将这两种方法应用于自然语言处理，一种基于最近邻和影响函数，一种基于马氏距离。特别是前者相比几个强基准产生了最先进的检测器；此外，对影响函数的新颖使用揭示了自然语言处理中的对抗样本子空间与图像处理中的子空间的关系，并展示了它们根据不同自然语言处理任务的差异。

    Adversarial examples, deliberately crafted using small perturbations to fool deep neural networks, were first studied in image processing and more recently in NLP. While approaches to detecting adversarial examples in NLP have largely relied on search over input perturbations, image processing has seen a range of techniques that aim to characterise adversarial subspaces over the learned representations.  In this paper, we adapt two such approaches to NLP, one based on nearest neighbors and influence functions and one on Mahalanobis distances. The former in particular produces a state-of-the-art detector when compared against several strong baselines; moreover, the novel use of influence functions provides insight into how the nature of adversarial example subspaces in NLP relate to those in image processing, and also how they differ depending on the kind of NLP task.
    
[^54]: RedPenNet用于语法错误纠正：将输出转化为单词，将注意力应用到片段上

    RedPenNet for Grammatical Error Correction: Outputs to Tokens, Attentions to Spans. (arXiv:2309.10898v1 [cs.CL])

    [http://arxiv.org/abs/2309.10898](http://arxiv.org/abs/2309.10898)

    RedPenNet是一种用于语法错误纠正的方法，解决了文本编辑任务中的架构和参数冗余问题，具有半自回归优势。

    

    文本编辑任务包括句子合并、句子分割和改写、文本简化以及语法错误纠正（GEC），它们都面临着输入和输出序列之间高度相似的特点。这一研究领域处于两个已经成熟的领域的交叉点上：（i）全自回归序列到序列的方法，常用于神经机器翻译（NMT）等任务，以及（ii）序列标注技术，常用于词性标注、命名实体识别（NER）等任务。为了设计一个平衡的架构，研究人员提出了许多富有想象力和非传统的解决方案，我们在相关工作部分进行了讨论。我们的方法称为RedPenNet，旨在减少特定的序列到编辑模型中出现的架构和参数冗余，保留它们的半自回归优势。我们的模型实现了$F_{0

    The text editing tasks, including sentence fusion, sentence splitting and rephrasing, text simplification, and Grammatical Error Correction (GEC), share a common trait of dealing with highly similar input and output sequences. This area of research lies at the intersection of two well-established fields: (i) fully autoregressive sequence-to-sequence approaches commonly used in tasks like Neural Machine Translation (NMT) and (ii) sequence tagging techniques commonly used to address tasks such as Part-of-speech tagging, Named-entity recognition (NER), and similar. In the pursuit of a balanced architecture, researchers have come up with numerous imaginative and unconventional solutions, which we're discussing in the Related Works section. Our approach to addressing text editing tasks is called RedPenNet and is aimed at reducing architectural and parametric redundancies presented in specific Sequence-To-Edits models, preserving their semi-autoregressive advantages. Our models achieve $F_{0
    
[^55]: 自我增强改进了零样本跨语言传递

    Self-Augmentation Improves Zero-Shot Cross-Lingual Transfer. (arXiv:2309.10891v1 [cs.CL])

    [http://arxiv.org/abs/2309.10891](http://arxiv.org/abs/2309.10891)

    本文提出了一种名为SALT的方法，通过结合代码切换和嵌入混合与自我增强，有效地提高了多语言预训练模型的零样本跨语言传递能力。

    

    零样本跨语言传递是多语言自然语言处理的核心任务，允许在具有更充足训练资源的语言中训练的模型推广到其他资源匮乏的语言。先前在这个任务上的努力使用平行语料库、双语词典或其他标注对齐数据来提高跨语言传递能力，这些通常是昂贵的获取方式。在本文中，我们提出了一种简单而有效的方法SALT，用于改进多语言预训练语言模型的零样本跨语言传递，而不需要这些外部数据的帮助。通过结合代码切换和嵌入混合与自我增强，SALT有效地蒸馏了多语言PLM的跨语言知识，并增强了其在下游任务中的传递能力。在XNLI和PAWS-X上的实验结果表明，我们的方法可以在没有外部数据的情况下提高零样本跨语言传递能力。我们的代码可以在https://github.com/luka-group/SALT找到。

    Zero-shot cross-lingual transfer is a central task in multilingual NLP, allowing models trained in languages with more sufficient training resources to generalize to other low-resource languages. Earlier efforts on this task use parallel corpora, bilingual dictionaries, or other annotated alignment data to improve cross-lingual transferability, which are typically expensive to obtain. In this paper, we propose a simple yet effective method, SALT, to improve the zero-shot cross-lingual transfer of the multilingual pretrained language models without the help of such external data. By incorporating code-switching and embedding mixup with self-augmentation, SALT effectively distills cross-lingual knowledge from the multilingual PLM and enhances its transferability on downstream tasks. Experimental results on XNLI and PAWS-X show that our method is able to improve zero-shot cross-lingual transferability without external data. Our code is available at https://github.com/luka-group/SALT.
    
[^56]: 使用自然语言处理对食物系统本体进行组织分类

    Classifying Organizations for Food System Ontologies using Natural Language Processing. (arXiv:2309.10880v1 [cs.CL])

    [http://arxiv.org/abs/2309.10880](http://arxiv.org/abs/2309.10880)

    本研究使用自然语言处理方法自动对食物系统本体中的组织进行分类，研究结果表明NLP模型可以在这两个分类任务中取得良好性能。

    

    我们的研究探索了使用自然语言处理（NLP）方法自动对实体进行分类，以达到知识图谱的构建和与食物系统本体的集成的目的。我们创建了能够自动将组织根据与环境问题相关的类别以及美国政府用于描述商业活动的标准产业分类（SIC）代码进行分类的NLP模型。NLP模型的输入为每个组织通过Google搜索引擎检索到的文本片段，该文本片段用作用于学习的组织的文本描述。我们的实验结果显示，NLP模型可以在这两个分类任务中实现相当好的性能，并且它们依赖于一个通用框架，该框架也可以应用于许多其他分类问题。我们相信，NLP模型代表了一种有前景的方法，可以自动收集信息。

    Our research explores the use of natural language processing (NLP) methods to automatically classify entities for the purpose of knowledge graph population and integration with food system ontologies. We have created NLP models that can automatically classify organizations with respect to categories associated with environmental issues as well as Standard Industrial Classification (SIC) codes, which are used by the U.S. government to characterize business activities. As input, the NLP models are provided with text snippets retrieved by the Google search engine for each organization, which serves as a textual description of the organization that is used for learning. Our experimental results show that NLP models can achieve reasonably good performance for these two classification tasks, and they rely on a general framework that could be applied to many other classification problems as well. We believe that NLP models represent a promising approach for automatically harvesting informatio
    
[^57]: MelodyGLM: 音乐符号旋律生成的多任务预训练

    MelodyGLM: Multi-task Pre-training for Symbolic Melody Generation. (arXiv:2309.10738v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2309.10738](http://arxiv.org/abs/2309.10738)

    提出了一种名为MelodyGLM的多任务预训练框架，用于生成具有长期结构的旋律。该框架通过设计音乐n-gram和长跨度抽样策略来捕捉旋律的局部和全局结构，并使用大规模符号旋律数据集进行预训练改进。

    

    预训练语言模型在各种音乐理解和生成任务中取得了令人印象深刻的结果。然而，现有的用于符号旋律生成的预训练方法在捕捉音符序列中的多尺度、多维结构信息方面存在困难，这是由于文本和音乐之间领域知识差异的缘故。此外，可用大规模符号旋律数据集的缺乏限制了预训练的改进。在本文中，我们提出了MelodyGLM，这是一个用于生成具有长期结构旋律的多任务预训练框架。我们设计了音乐n-gram和长跨度抽样策略，为旋律的局部和全局结构建立了局部和全局空白填充任务，以进行建模。具体而言，我们将音高n-gram、节奏n-gram及其组合的n-gram纳入音乐n-gram空白填充任务中，以建模旋律的多维结构。为此，我们构建了一个大规模符号旋律数据集。

    Pre-trained language models have achieved impressive results in various music understanding and generation tasks. However, existing pre-training methods for symbolic melody generation struggle to capture multi-scale, multi-dimensional structural information in note sequences, due to the domain knowledge discrepancy between text and music. Moreover, the lack of available large-scale symbolic melody datasets limits the pre-training improvement. In this paper, we propose MelodyGLM, a multi-task pre-training framework for generating melodies with long-term structure. We design the melodic n-gram and long span sampling strategies to create local and global blank infilling tasks for modeling the local and global structures in melodies. Specifically, we incorporate pitch n-grams, rhythm n-grams, and their combined n-grams into the melodic n-gram blank infilling tasks for modeling the multi-dimensional structures in melodies. To this end, we have constructed a large-scale symbolic melody datas
    
[^58]: NusaWrites: 为被低估和极度资源匮乏的语言构建高质量语料库

    NusaWrites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages. (arXiv:2309.10661v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.10661](http://arxiv.org/abs/2309.10661)

    NusaWrites项目通过母语者段落撰写构建高质量语料库，弥补了在线爬取和翻译文档所带来的词汇多样性和文化相关性的限制。该研究在印度尼西亚地方语言上进行，并提出了“datasetname”基准，涵盖了12种被低估和极度资源匮乏的语言。

    

    民主化自然语言处理（NLP）技术的访问至关重要，特别是对于被低估和极度资源匮乏的语言。以往的研究侧重于通过在线爬取和文件翻译为这些语言开发带标签和无标签的语料库。尽管这些方法已经被证明是有效和费用效益的，但我们发现所得到的语料库存在一些限制，包括缺乏词汇多样性和与当地社区的文化相关性。为了解决这一差距，我们在印度尼西亚的地方语言上进行了案例研究。我们比较了在线爬取、人工翻译和母语者段落撰写在构建数据集方面的效果。我们的研究结果表明，通过母语者段落撰写生成的数据集在词汇多样性和文化内容方面具有更高的质量。此外，我们还提出了“datasetname ”基准，涵盖了12个被低估和极度资源匮乏的语言。

    Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely low-resource languages. Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation. While these methods have proven effective and cost-efficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities. To address this gap, we conduct a case study on Indonesian local languages. We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets. Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content. In addition, we present the \datasetname{} benchmark, encompassing 12 underrepresented and extremely low-resource languag
    
[^59]: 通过正则表达式指令实现统一可控文本生成

    Toward Unified Controllable Text Generation via Regular Expression Instruction. (arXiv:2309.10447v1 [cs.CL])

    [http://arxiv.org/abs/2309.10447](http://arxiv.org/abs/2309.10447)

    本文通过引入正则表达式指令（REI）实现了统一可控文本生成，通过指令方式支持各种约束，无需对架构进行修改，并对各种约束组合表现出良好的性能。

    

    可控文本生成是自然语言生成的基本方面之一，已经提出了许多针对不同约束类型的方法。然而，这些方法往往需要重大的架构或解码修改，使得它们难以应用于附加约束或解决不同约束组合。为了解决这个问题，本文引入了正则表达式指令（REI），利用基于指令的机制充分利用正则表达式的优势，统一建模各种约束。具体而言，我们的REI通过正则表达式风格的指令支持所有流行的细粒度可控生成约束，即词汇、位置和长度，以及它们的复杂组合。我们的方法只需要在中等规模语言模型上进行微调或在大规模语言模型上进行少样本、上下文学习，并且在应用于各种约束组合时不需要进一步调整。实验证明了我们方法的有效性。

    Controllable text generation is a fundamental aspect of natural language generation, with numerous methods proposed for different constraint types. However, these approaches often require significant architectural or decoding modifications, making them challenging to apply to additional constraints or resolve different constraint combinations. To address this, our paper introduces Regular Expression Instruction (REI), which utilizes an instruction-based mechanism to fully exploit regular expressions' advantages to uniformly model diverse constraints. Specifically, our REI supports all popular fine-grained controllable generation constraints, i.e., lexical, positional, and length, as well as their complex combinations, via regular expression-style instructions. Our method only requires fine-tuning on medium-scale language models or few-shot, in-context learning on large language models, and requires no further adjustment when applied to various constraint combinations. Experiments demon
    
[^60]: PoSE: 通过位置跳跃式训练提高LLMs对于上下文窗口的有效拓展

    PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training. (arXiv:2309.10400v1 [cs.CL])

    [http://arxiv.org/abs/2309.10400](http://arxiv.org/abs/2309.10400)

    本文介绍了一种名为PoSE的训练方法，通过在训练过程中使用固定的上下文窗口和操纵位置索引来适应极长的上下文窗口，实验证明这种方法大大减小了内存和时间开销，对性能影响较小，成功将LLaMA模型扩展到了128k个标记。

    

    本文介绍了一种名为Positional Skip-wise (PoSE)训练的方法，用于将大型语言模型（LLMs）适应于极长的上下文窗口。PoSE通过在训练过程中使用固定的上下文窗口和操纵位置索引来模拟长输入，将训练长度与目标上下文窗口大小分离。具体而言，我们从长输入序列中选择若干短块，并引入不同的跳跃偏置项来修改每个块的位置索引。这些跳跃偏置项以及每个块的长度在每个训练样本中都会变化，使得模型能够适应目标上下文窗口中的所有位置，而无需对完整长度的输入进行训练。实验证明，与对完整长度进行微调相比，PoSE大大减小了内存和时间开销，对性能影响较小。利用这一优势，我们成功将LLaMA模型扩展到了128k个标记。此外，我们经验证实，PoSE与

    In this paper, we introduce Positional Skip-wisE (PoSE) training for efficient adaptation of large language models~(LLMs) to extremely long context windows. PoSE decouples train length from target context window size by simulating long inputs using a fixed context window with manipulated position indices during training. Concretely, we select several short chunks from a long input sequence, and introduce distinct skipping bias terms to modify the position indices of each chunk. These bias terms, along with the length of each chunk, are altered for each training example, allowing the model to adapt to all positions within the target context window without training on full length inputs. Experiments show that, compared with fine-tuning on the full length, PoSE greatly reduces memory and time overhead with minimal impact on performance. Leveraging this advantage, we have successfully extended the LLaMA model to 128k tokens. Furthermore, we empirically confirm that PoSE is compatible with 
    
[^61]: QASnowball: 一个用于高质量问答数据生成的迭代自举框架

    QASnowball: An Iterative Bootstrapping Framework for High-Quality Question-Answering Data Generation. (arXiv:2309.10326v1 [cs.CL])

    [http://arxiv.org/abs/2309.10326](http://arxiv.org/abs/2309.10326)

    QASnowball是一个迭代自举框架，可以根据有监督的样本种子集生成大规模高质量的QA数据，并通过重新种子化进行自我增强。在高资源英文场景中进行了实验。

    

    近年来，问题回答（QA）取得了成功，特别是其在应对各种自然语言处理任务中的潜力。然而，获取足够的数据来构建一个有效稳定的QA系统仍然是一个未解决的问题。针对这个问题，我们引入了一个迭代自举框架QASnowball，用于QA数据增强，它可以根据有监督的样本种子集迭代地生成大规模高质量的QA数据。具体而言，QASnowball包括三个模块：回答提取器，用于从无标签的文档中提取候选答案的核心短语；问题生成器，根据文档和候选答案生成问题；QA数据过滤器，用于过滤出高质量的QA数据。此外，QASnowball可以通过重新种子化种子集在不同迭代中进行自我增强，从而不断提高生成质量。我们在高资源英文场景中进行了实验。

    Recent years have witnessed the success of question answering (QA), especially its potential to be a foundation paradigm for tackling diverse NLP tasks. However, obtaining sufficient data to build an effective and stable QA system still remains an open problem. For this problem, we introduce an iterative bootstrapping framework for QA data augmentation (named QASnowball), which can iteratively generate large-scale high-quality QA data based on a seed set of supervised examples. Specifically, QASnowball consists of three modules, an answer extractor to extract core phrases in unlabeled documents as candidate answers, a question generator to generate questions based on documents and candidate answers, and a QA data filter to filter out high-quality QA data. Moreover, QASnowball can be self-enhanced by reseeding the seed set to fine-tune itself in different iterations, leading to continual improvements in the generation quality. We conduct experiments in the high-resource English scenario
    
[^62]: Baichuan 2: 开放的大规模语言模型

    Baichuan 2: Open Large-scale Language Models. (arXiv:2309.10305v1 [cs.CL])

    [http://arxiv.org/abs/2309.10305](http://arxiv.org/abs/2309.10305)

    Baichuan 2是一系列开放的大规模多语言模型，拥有70亿和130亿个参数，训练自26万亿个标记。Baichuan 2在公开基准测试中表现出色，并在垂直领域如医学和法律中具有优势。

    

    大型语言模型（LLMs）在仅有少量自然语言指令示例的情况下，已经在各种自然语言任务中展示出了令人瞩目的性能，减少了对广泛特征工程的需求。然而，大多数强大的LLMs是封闭源代码的，或者在除了英语以外的其他语言方面能力有限。在这篇技术报告中，我们介绍了Baichuan 2系列，这是一系列从头开始进行训练的大规模多语言模型，包含70亿和130亿个参数，使用26万亿个标记进行训练。Baichuan 2在MMLU、CMMLU、GSM8K和HumanEval等公开基准测试中与其他相同规模的开源模型相匹配或胜过。此外，Baichuan 2在医学和法律等垂直领域表现出色。我们将发布所有预训练模型检查点，以使研究界更好地理解Baichuan 2的训练动态。

    Large language models (LLMs) have demonstrated remarkable performance on a variety of natural language tasks based on just a few examples of natural language instructions, reducing the need for extensive feature engineering. However, most powerful LLMs are closed-source or limited in their capability for languages other than English. In this technical report, we present Baichuan 2, a series of large-scale multilingual language models containing 7 billion and 13 billion parameters, trained from scratch, on 2.6 trillion tokens. Baichuan 2 matches or outperforms other open-source models of similar size on public benchmarks like MMLU, CMMLU, GSM8K, and HumanEval. Furthermore, Baichuan 2 excels in vertical domains such as medicine and law. We will release all pre-training model checkpoints to benefit the research community in better understanding the training dynamics of Baichuan 2.
    
[^63]: 使用大型语言模型解决和解释物理词问题接近人类水平

    Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level. (arXiv:2309.08182v1 [cs.CL])

    [http://arxiv.org/abs/2309.08182](http://arxiv.org/abs/2309.08182)

    本研究证明，使用大型语言模型(如GPT3.5)可以解决和解释物理词问题，通过对物理知识进行计算和推理，实现了接近人类水平的解决率。此外，该模型还能够总结涉及的知识、生成解释，并创造新的物理词问题。

    

    我们的工作表明，基于文本预训练的大型语言模型(LLM)不仅可以解决纯数学题，还可以解决物理词问题-即基于先前的物理知识进行计算和推理的问题。我们收集并注释了第一个物理词问题数据集-PhysQA，其中包含超过1000个初中物理词问题（包括运动学、质量和密度、力学、热学和电学）。然后我们使用OpenAI的GPT3.5来生成这些问题的答案，发现GPT3.5可以在零样本学习上自动解决49.3%的问题，在少样本学习上则为73.2%。这个结果表明，通过使用类似问题及其答案作为提示，LLM可以解决接近人类水平的基础物理词问题。除了自动解决问题，GPT3.5还可以总结问题涉及的知识或主题，生成相关解释，并根据输入问题综合出新的物理词问题。

    Our work demonstrates that large language model (LLM) pre-trained on texts can not only solve pure math word problems, but also physics word problems-problems to be solved by calculation and inference based on some prior physical knowledge. We collect and annotate the first physics word problem dataset-PhysQA, which contains over 1000 junior high school physics word problems (on Kinematics, Mass&Density, Mechanics, Heat, Electricity). Then we use OpenAI' s GPT3.5 to generate the answer of these problems and found that GPT3.5 could automatically solve 49.3% of the problems on zero-shot learning and 73.2% on few-shot learning. This result show that by using similar problem and its answer as prompt, LLM could solve elementary physics word problems approaching human level. Besides automatically solving problems, GPT3.5 could also summarize the knowledge or topic examined by the problem, generate the relevant explanation, and synthesis new physics word problems according tothe input problem
    
[^64]: 具有可控风格的语境化自动语音识别中的PromptASR

    PromptASR for contextualized ASR with controllable style. (arXiv:2309.07414v1 [eess.AS])

    [http://arxiv.org/abs/2309.07414](http://arxiv.org/abs/2309.07414)

    PromptASR是一个框架，将提示集成到端到端自动语音识别系统中，实现了具有可控风格的语境化语音转录。在实验中，使用前一话语的真实文本作为内容提示时，相对于基线ASR系统，该系统在阅读图书数据集和内部数据集上分别获得了21.9％和6.8％的词错误率降低。此外，该系统可以采用单词级偏置列表作为提示来提高对罕见单词的识别准确性。同时，该系统还可以使用额外的样式提示来引导ASR系统输出不同风格的转录。

    

    对于大型语言模型来说，提示非常重要，因为它们提供了主题或逻辑关系等上下文信息。受此启发，我们提出了PromptASR，这是一个将提示集成到端到端自动语音识别（E2E ASR）系统中，以实现具有可控风格的语境化语音转录的框架。具体地，专用文本编码器对文本提示进行编码，并通过跨两种模态的特征交互将编码注入到语音编码器中。当使用前面话语的真实文本作为内容提示时，与基线ASR系统相比，所提出的系统在阅读图书数据集和内部数据集上分别实现了21.9％和6.8％的相对词错误率降低。系统还可以采用单词级偏置列表作为提示，以提高对罕见单词的识别准确性。还可以给文本编码器提供额外的样式提示，并引导ASR系统输出不同风格的转录。代码可供使用。

    Prompts are crucial to large language models as they provide context information such as topic or logical relationships. Inspired by this, we propose PromptASR, a framework that integrates prompts in end-to-end automatic speech recognition (E2E ASR) systems to achieve contextualized ASR with controllable style of transcriptions. Specifically, a dedicated text encoder encodes the text prompts and the encodings are injected into the speech encoder by cross-attending the features from two modalities. When using the ground truth text from preceding utterances as content prompt, the proposed system achieves 21.9% and 6.8% relative word error rate reductions on a book reading dataset and an in-house dataset compared to a baseline ASR system. The system can also take word-level biasing lists as prompt to improve recognition accuracy on rare words. An additional style prompt can be given to the text encoder and guide the ASR system to output different styles of transcriptions. The code is avai
    
[^65]: 大语言模型赋能文本到SQL的研究：一个基准评估

    Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation. (arXiv:2308.15363v1 [cs.DB])

    [http://arxiv.org/abs/2308.15363](http://arxiv.org/abs/2308.15363)

    本文提出了一个大规模语言模型(LLMs)赋能的文本到SQL任务的基准评估，并基于实验结果提出了一种新的集成解决方案DAIL-SQL，刷新了Spider榜单并实现了86.6%的执行准确率。同时，强调了在提示工程中的词汇效率以实现高效经济的LLM-based文本到SQL解决方案，此外还对在上下文学习中应用开源LLMs进行了研究，并进行了任务特定的性能优化。

    

    大语言模型(LLMs)已经成为文本到SQL任务的一种新范式。然而，缺乏一个系统性的基准阻碍了设计有效、高效和经济的LLM-based文本到SQL解决方案的发展。为了解决这一挑战，本文首先对现有的提示工程方法进行了系统性和广泛的比较，包括问题表示、示例选择和示例组织，并根据实验结果详细阐述了它们的优缺点。基于这些发现，我们提出了一种新的集成解决方案，名为DAIL-SQL，刷新了Spider榜单，达到了86.6%的执行准确率，建立了一个新的标杆。为了实现高效经济的LLM-based文本到SQL解决方案，我们强调提示工程中的词汇效率，并在此度量下比较了之前的研究。此外，我们还研究了上下文学习中的开源LLMs，并用任务特定的监督进行了进一步的性能优化。

    Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborates their pros and cons. Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6% execution accuracy and sets a new bar. Towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric. Additionally, we investigate open-source LLMs in in-context learning, and further enhance their performance with task-specific superv
    
[^66]: MT4CrossOIE: 多阶段调优用于跨语种开放信息提取

    MT4CrossOIE: Multi-stage Tuning for Cross-lingual Open Information Extraction. (arXiv:2308.06552v1 [cs.CL])

    [http://arxiv.org/abs/2308.06552](http://arxiv.org/abs/2308.06552)

    MT4CrossOIE是一种多阶段调优框架，用于增强跨语种开放信息提取。它通过向共享模型注入语言特定知识，并利用多个低秩语言特定模块进行模型转移。

    

    跨语种开放信息提取旨在从多语言的原始文本中提取结构化信息。先前的工作使用共享的跨语种预训练模型来处理不同的语言，但未充分利用语言特定表示的潜力。本文提出了一种名为MT4CrossIE的有效多阶段调优框架，旨在通过向共享模型注入语言特定知识来增强跨语种开放信息提取。具体而言，首先在固定编码器中调整跨语种预训练模型的共享语义空间（例如嵌入矩阵），然后在第二阶段优化其他组件。经过足够的训练后，我们冻结预训练模型，并使用混合LoRAs优化多个额外的低秩语言特定模块，以进行基于模型的跨语种转移。此外，我们利用两阶段提示来促使大型语言模型（LLM）注释多语种数据。

    Cross-lingual open information extraction aims to extract structured information from raw text across multiple languages. Previous work uses a shared cross-lingual pre-trained model to handle the different languages but underuses the potential of the language-specific representation. In this paper, we propose an effective multi-stage tuning framework called MT4CrossIE, designed for enhancing cross-lingual open information extraction by injecting language-specific knowledge into the shared model. Specifically, the cross-lingual pre-trained model is first tuned in a shared semantic space (e.g., embedding matrix) in the fixed encoder and then other components are optimized in the second stage. After enough training, we freeze the pre-trained model and tune the multiple extra low-rank language-specific modules using mixture-of-LoRAs for model-based cross-lingual transfer. In addition, we leverage two-stage prompting to encourage the large language model (LLM) to annotate the multi-lingual 
    
[^67]: EmotionPrompt: 通过情感刺激提升大型语言模型的关键心理学方法

    EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus. (arXiv:2307.11760v1 [cs.CL])

    [http://arxiv.org/abs/2307.11760](http://arxiv.org/abs/2307.11760)

    EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。

    

    大型语言模型（LLMs）在推理、语言理解和数学问题解决等许多领域取得了显著的性能，并被视为人工通用智能（AGI）的关键步骤。然而，LLMs对提示的敏感性仍然是其日常应用的主要瓶颈。本文从心理学中汲取灵感，提出了EmotionPrompt来探索情感智能以提升LLMs的性能。EmotionPrompt基于一个非常简单明了的原则：将情感刺激融入到提示中。实验结果表明，我们的方法在相同的单一提示模板上，与原始的零样本提示和Zero-shot-CoT相比，在8个任务上都显著优于多种模型：ChatGPT、Vicuna-13b、Bloom和T5。此外，观察到EmotionPrompt能够提高真实性和信息量。我们相信EmotionPrompt为探索跨学科知识开辟了一条新的道路。

    Large language models (LLMs) have achieved significant performance in many fields such as reasoning, language understanding, and math problem-solving, and are regarded as a crucial step to artificial general intelligence (AGI). However, the sensitivity of LLMs to prompts remains a major bottleneck for their daily adoption. In this paper, we take inspiration from psychology and propose EmotionPrompt to explore emotional intelligence to enhance the performance of LLMs. EmotionPrompt operates on a remarkably straightforward principle: the incorporation of emotional stimulus into prompts. Experimental results demonstrate that our \method, using the same single prompt templates, significantly outperforms original zero-shot prompt and Zero-shot-CoT on 8 tasks with diverse models: ChatGPT, Vicuna-13b, Bloom, and T5. Further, EmotionPrompt was observed to improve both truthfulness and informativeness. We believe that EmotionPrompt heralds a novel avenue for exploring interdisciplinary knowledg
    
[^68]: 基于大型语言模型的概念导向深度学习

    Concept-Oriented Deep Learning with Large Language Models. (arXiv:2306.17089v1 [cs.LG])

    [http://arxiv.org/abs/2306.17089](http://arxiv.org/abs/2306.17089)

    本文讨论了大型语言模型在概念导向深度学习中的应用，包括从文本和图像中提取概念和概念图。同时也探讨了多模态语言模型在表达人类知识方面的优势。

    

    大型语言模型（LLMs）已成功应用于许多自然语言任务和应用，包括文本生成和人工智能聊天机器人。它们也是概念导向深度学习（CODL）的一种有前景的新技术。然而，前提是LLMs要理解概念并确保概念一致性。本文讨论了这些问题，以及LLMs在CODL中的主要用途，包括从文本中提取概念、从文本中提取概念图和概念学习。人类知识包括符号（概念性）知识和具体（感性）知识。而仅文本的LLMs只能表示符号（概念性）知识。另一方面，多模态LLMs能够表示人类知识的完整范围（概念性和感性）。我们讨论了视觉-语言LLMs中的概念理解，这是最重要的多模态LLMs，并介绍了它们在CODL中的主要用途，包括从图像中提取概念、从图像中提取概念图。

    Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image
    
[^69]: 跨语言数据增强在低资源语言场景中的文档对话系统

    Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low Resource Languages. (arXiv:2305.14949v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14949](http://arxiv.org/abs/2305.14949)

    本文提出了一个跨语言数据增强的框架，通过利用高资源语言增强低资源语言的对话生成能力，并采用创新的架构进行多语言对齐，实验证明了模型的有效性。

    

    本文提出了一个框架，解决了文档对话系统中数据稀缺的问题。我们的模型利用高资源语言来增强低资源语言的对话生成能力。具体而言，我们提出了一个新颖的流程CLEM（跨语言增强模型），包括对抗训练的检索器和重新排序器以及融合解码器的生成器Fid（fusion-in-decoder）。为了进一步利用高资源语言，我们还提出了一种创新的架构，通过翻译训练数据在不同语言之间进行对齐。大量的实验结果表明了我们模型的有效性，并且在DialDoc 2023竞赛中获得第四名。因此，CLEM可以作为解决DGDS中资源稀缺问题的方法，并为多语言对齐任务提供有用的指导。

    This paper proposes a framework to address the issue of data scarcity in Document-Grounded Dialogue Systems(DGDS). Our model leverages high-resource languages to enhance the capability of dialogue generation in low-resource languages. Specifically, We present a novel pipeline CLEM (Cross-Lingual Enhanced Model) including adversarial training retrieval (Retriever and Re-ranker), and Fid (fusion-in-decoder) generator. To further leverage high-resource language, we also propose an innovative architecture to conduct alignment across different languages with translated training. Extensive experiment results demonstrate the effectiveness of our model and we achieved 4th place in the DialDoc 2023 Competition. Therefore, CLEM can serve as a solution to resource scarcity in DGDS and provide useful guidance for multi-lingual alignment tasks.
    
[^70]: GPT-3.5、GPT-4还是BARD？对LLM在零样本情境中的推理能力和通过提示提升性能的评估

    GPT-3.5, GPT-4, or BARD? Evaluating LLMs Reasoning Ability in Zero-Shot Setting and Performance Boosting Through Prompts. (arXiv:2305.12477v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12477](http://arxiv.org/abs/2305.12477)

    本文通过在多个任务和数据集上对GPT-3.5、GPT-4和BARD进行评估，实验证明在零样本情境中，ChatGPT-4表现出了更高的性能。GPT-4相对于GPT-3.5的优势可能是由其更大的模型规模和NLP效率所引起的，但对于BARD来说并不明显。此外，这三个模型在归纳、数学和多跳推理任务上的表现有限。

    

    大型语言模型（LLMs）在各种自然语言处理（NLP）任务中展现了显著的性能。然而，关于它们的推理能力存在着当前的热议。本文通过在十一个不同数据集上对不同的推理任务进行彻底技术评估，研究了GPT-3.5、GPT-4和BARD模型的性能。我们的研究提供了实证证据，证明在零样本情境下，ChatGPT-4相对于ChatGPT-3.5和BARD在几乎所有评估任务中表现出了更高的性能。虽然GPT-4相对于GPT-3.5的优势可能可以通过其更大的模型规模和NLP效率来解释，但对于BARD来说并不明显。我们还证明了这三个模型在归纳、数学和多跳推理任务上显示出有限的能力。为了强化我们的发现，我们对这三个模型的结果进行了详细全面的分析。此外，我们提出了一组工程化的提示方式。

    Large Language Models (LLMs) have exhibited remarkable performance on various Natural Language Processing (NLP) tasks. However, there is a current hot debate regarding their reasoning capacity. In this paper, we examine the performance of GPT-3.5, GPT-4, and BARD models, by performing a thorough technical evaluation on different reasoning tasks across eleven distinct datasets. Our paper provides empirical evidence showcasing the superior performance of ChatGPT-4 in comparison to both ChatGPT-3.5 and BARD in zero-shot setting throughout almost all evaluated tasks. While the superiority of GPT-4 compared to GPT-3.5 might be explained by its larger size and NLP efficiency, this was not evident for BARD. We also demonstrate that the three models show limited proficiency in Inductive, Mathematical, and Multi-hop Reasoning Tasks. To bolster our findings, we present a detailed and comprehensive analysis of the results from these three models. Furthermore, we propose a set of engineered prompt
    
[^71]: MasakhaNEWS：非洲语言新闻主题分类

    MasakhaNEWS: News Topic Classification for African languages. (arXiv:2304.09972v1 [cs.CL])

    [http://arxiv.org/abs/2304.09972](http://arxiv.org/abs/2304.09972)

    该论文开发了MasakhaNEWS，它是一个覆盖16种非洲语言的新闻主题分类的基准数据集。除了评估基线模型外，还探索了适用于零样本学习和少样本学习的全面微调语言模型的替代方案。

    

    由于缺乏覆盖多个NLP任务的数据集，非洲语言在NLP研究中严重受到忽视。虽然存在一些语言特定的数据集，但只有少数NLP任务（如命名实体识别和机器翻译）具有覆盖多个地理和分类多样的非洲语言的标准基准数据集。在本文中，我们开发了MasakhaNEWS - 一个新的用于涵盖非洲广泛使用的16种语言的新闻主题分类的基准数据集。我们通过训练经典的机器学习模型和微调多个语言模型来评估基线模型。此外，我们还探索了一些适用于零样本学习和少样本学习的语言模型的全面微调的替代方案，例如跨语言参数高效微调（如MAD-X）、模式利用训练（PET）、提示语言模型（如ChatGPT）和无提示句子训练（ELECTRA）等。

    African languages are severely under-represented in NLP research due to lack of datasets covering several NLP tasks. While there are individual language specific datasets that are being expanded to different tasks, only a handful of NLP tasks (e.g. named entity recognition and machine translation) have standardized benchmark datasets covering several geographical and typologically-diverse African languages. In this paper, we develop MasakhaNEWS -- a new benchmark dataset for news topic classification covering 16 languages widely spoken in Africa. We provide an evaluation of baseline models by training classical machine learning models and fine-tuning several language models. Furthermore, we explore several alternatives to full fine-tuning of language models that are better suited for zero-shot and few-shot learning such as cross-lingual parameter-efficient fine-tuning (like MAD-X), pattern exploiting training (PET), prompting language models (like ChatGPT), and prompt-free sentence tra
    
[^72]: 评估 ChatGPT 作为回答复杂问题的问答系统

    Evaluation of ChatGPT as a Question Answering System for Answering Complex Questions. (arXiv:2303.07992v1 [cs.CL])

    [http://arxiv.org/abs/2303.07992](http://arxiv.org/abs/2303.07992)

    本论文评估了基于ChatGPT模型的问答系统在回答复杂问题方面的能力，通过一个分类框架对潜在的问题特征进行分类，通过黑盒测试规范CheckList评估模型性能。

    

    ChatGPT 是一个强大的大型语言模型，已在自然语言理解方面取得了显著进展。然而，该模型的性能和局限性仍需要进行广泛评估。由于 ChatGPT 覆盖维基百科等资源并支持自然语言问答，因此它引起了作为传统知识库问答（KBQA）模型替代品的关注。复杂问题回答是 KBQA 的一项挑战性任务，全面测试了模型在语义解析和推理方面的能力。为了评估 ChatGPT 作为一个使用自己知识回答复杂问题的问答系统的性能，我们提出了一个框架来评估其回答复杂问题的能力。我们的方法涉及对复杂问题的潜在特征进行分类，并使用多个标签描述每个测试问题，以识别组合推理。根据 Ribeir 提出的 CheckList 的黑盒测试规范，我们评估了ChatGPT模型的性能。

    ChatGPT is a powerful large language model (LLM) that has made remarkable progress in natural language understanding. Nevertheless, the performance and limitations of the model still need to be extensively evaluated. As ChatGPT covers resources such as Wikipedia and supports natural language question answering, it has garnered attention as a potential replacement for traditional knowledge based question answering (KBQA) models. Complex question answering is a challenge task of KBQA, which comprehensively tests the ability of models in semantic parsing and reasoning. To assess the performance of ChatGPT as a question answering system (QAS) using its own knowledge, we present a framework that evaluates its ability to answer complex questions. Our approach involves categorizing the potential features of complex questions and describing each test question with multiple labels to identify combinatorial reasoning. Following the black-box testing specifications of CheckList proposed by Ribeir
    
[^73]: 分析和改进神经说话人嵌入用于ASR

    Analyzing And Improving Neural Speaker Embeddings for ASR. (arXiv:2301.04571v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04571](http://arxiv.org/abs/2301.04571)

    该论文研究了将神经说话人嵌入应用于ASR系统中，并提出了改进的嵌入提取流程和集成方法，通过改进的声学模型和添加神经说话人嵌入，获得了显著的WER性能提升。

    

    神经说话人嵌入通过DNN模型编码说话者的语音特征，被广泛用于说话者验证任务。然而，很少有研究探讨神经说话人嵌入在ASR系统中的使用。在这项工作中，我们将神经说话人嵌入集成到基于Conformer的混合HMM ASR系统中，并进行改进。对于ASR，我们改进了嵌入提取流程，并结合加权简单加法集成方法，使得x-vector和c-vector达到与i-vector相当的性能。我们进一步比较和分析不同的说话人嵌入。我们通过从newbob学习率调度转换为单周期学习调度来改进声学模型，在Switchboard上相对WER降低了约3%，同时减少了整体训练时间17%。通过进一步添加神经说话人嵌入，我们在Hub5'00上获得了额外约3%的相对WER改进。我们最好的基于Conformer的混合A

    Neural speaker embeddings encode the speaker's speech characteristics through a DNN model and are prevalent for speaker verification tasks. However, few studies have investigated the usage of neural speaker embeddings for an ASR system. In this work, we present our efforts w.r.t integrating neural speaker embeddings into a conformer based hybrid HMM ASR system. For ASR, our improved embedding extraction pipeline in combination with the Weighted-Simple-Add integration method results in x-vector and c-vector reaching on par performance with i-vectors. We further compare and analyze different speaker embeddings. We present our acoustic model improvements obtained by switching from newbob learning rate schedule to one cycle learning schedule resulting in a ~3% relative WER reduction on Switchboard, additionally reducing the overall training time by 17%. By further adding neural speaker embeddings, we gain additional ~3% relative WER improvement on Hub5'00. Our best Conformer-based hybrid A
    
[^74]: 零样本模板填充下的三元组抽取

    Zero-shot Triplet Extraction by Template Infilling. (arXiv:2212.10708v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10708](http://arxiv.org/abs/2212.10708)

    本论文提出了一种将三元组抽取任务转化为模板填充任务的框架，通过对预训练语言模型进行零样本学习，实现了在没有额外训练数据的情况下对未见关系的抽取，并在实验证明了其稳定且一致的性能表现。

    

    三元组抽取的任务旨在从非结构化文本中提取实体对及其对应的关系。大部分现有方法在特定目标关系的训练数据上训练抽取模型，无法提取训练时未观察到的新关系。将模型推广到未见关系通常需要对常常不可靠且噪声较大的合成训练数据进行微调。我们通过将三元组提取任务转化为基于预训练语言模型（LM）的模板填充任务，展示了可以使抽取模型具备零样本学习能力，并消除对额外训练数据的需求。我们提出了一种新的框架ZETT（Zero-shot Triplet extraction by Template infilling），将任务目标与生成式Transformer的预训练目标进行对齐，以推广到未见关系。在FewRel和Wiki-ZSL数据集上的实验证明，ZETT显示出一致且稳定的性能。

    The task of triplet extraction aims to extract pairs of entities and their corresponding relations from unstructured text. Most existing methods train an extraction model on training data involving specific target relations, and are incapable of extracting new relations that were not observed at training time. Generalizing the model to unseen relations typically requires fine-tuning on synthetic training data which is often noisy and unreliable. We show that by reducing triplet extraction to a template infilling task over a pre-trained language model (LM), we can equip the extraction model with zero-shot learning capabilities and eliminate the need for additional training data. We propose a novel framework, ZETT (ZEro-shot Triplet extraction by Template infilling), that aligns the task objective to the pre-training objective of generative transformers to generalize to unseen relations. Experiments on FewRel and Wiki-ZSL datasets demonstrate that ZETT shows consistent and stable perform
    
[^75]: 低资源医疗领域会话电话语音的混合ASR系统的开发

    Development of Hybrid ASR Systems for Low Resource Medical Domain Conversational Telephone Speech. (arXiv:2210.13397v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.13397](http://arxiv.org/abs/2210.13397)

    本研究开发了针对低资源医疗领域会话电话语音的混合ASR系统，旨在改善患者护理并克服语言障碍。

    

    语言障碍在我们日益连接和全球化的世界中带来了巨大的挑战。尤其在医疗领域，如医院或急诊室，沟通困难和延误可能导致医疗失误和非最佳的患者护理。在HYKIST项目中，我们考虑患者和医生之间的交流，具体来说是德语医生和阿拉伯语或越南语患者之间的交流。目前，医生可以打电话给Triaphon服务以获得来自翻译员的帮助，以促进沟通。HYKIST的目标是为通常没有专业背景的双语翻译员提供自动语音翻译系统，以改进患者护理并解决语言障碍。在这项工作中，我们介绍了针对医疗领域会话电话语音翻译任务的ASR系统开发工作，涉及两种语言对的数据收集、各种声学模型架构和方言引起的困难。

    Language barriers present a great challenge in our increasingly connected and global world. Especially within the medical domain, e.g. hospital or emergency room, communication difficulties and delays may lead to malpractice and non-optimal patient care. In the HYKIST project, we consider patient-physician communication, more specifically between a German-speaking physician and an Arabic- or Vietnamese-speaking patient. Currently, a doctor can call the Triaphon service to get assistance from an interpreter in order to help facilitate communication. The HYKIST goal is to support the usually non-professional bilingual interpreter with an automatic speech translation system to improve patient care and help overcome language barriers. In this work, we present our ASR system development efforts for this conversational telephone speech translation task in the medical domain for two languages pairs, data collection, various acoustic model architectures and dialect-induced difficulties.
    
[^76]: 将错误信息注入进行开放领域问答的攻击

    Attacking Open-domain Question Answering by Injecting Misinformation. (arXiv:2110.07803v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.07803](http://arxiv.org/abs/2110.07803)

    本研究探究了将错误信息注入问答系统的攻击，并发现问答模型对于错误信息具有脆弱性，即使少量错误信息的污染也会导致性能大幅下降。

    

    随着宣传、新闻和社交媒体中虚假、不准确和误导性信息的增加，现实世界中的问答系统面临着在被错误信息污染的语境中综合和推理以得出正确答案的挑战。这种紧迫性促使我们需要使问答系统对错误信息具备鲁棒性，而这是之前未被探索的一个主题。我们通过调查开放领域问答模型对带有错误信息文档的语料库污染的敏感性，来研究错误信息对问答模型的风险。我们整理了人工撰写和模型生成的虚假文档，将其注入到问答模型的证据语料库中，并评估这些系统性能的影响。实验证明，即使少量的错误信息污染也会使问答模型脆弱，所有模型的性能都会大幅度下降。当神经模型批量生成虚假文档时或攻击者针对问答模型时，错误信息攻击的威胁更大。

    With a rise in false, inaccurate, and misleading information in propaganda, news, and social media, real-world Question Answering (QA) systems face the challenges of synthesizing and reasoning over misinformation-polluted contexts to derive correct answers. This urgency gives rise to the need to make QA systems robust to misinformation, a topic previously unexplored. We study the risk of misinformation to QA models by investigating the sensitivity of open-domain QA models to corpus pollution with misinformation documents. We curate both human-written and model-generated false documents that we inject into the evidence corpus of QA models and assess the impact on the performance of these systems. Experiments show that QA models are vulnerable to even small amounts of evidence contamination brought by misinformation, with large absolute performance drops on all models. Misinformation attack brings more threat when fake documents are produced at scale by neural models or the attacker targ
    
[^77]: 以程序为过程：通过自然语言对处境代理进行层级控制

    Procedures as Programs: Hierarchical Control of Situated Agents through Natural Language. (arXiv:2109.08214v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2109.08214](http://arxiv.org/abs/2109.08214)

    本文提出了一种以程序为过程的形式化方法，用于代理指令和控制。通过建立层级模块化网络，将自然语言意图转化为可执行程序的预测，并在两个数据集上取得了显著性能优势。

    

    当人类构思执行特定任务时，他们会以层次结构的方式进行：将高级任务分解为较小的子任务。然而，在关于自然语言对处境代理的文献中，大多数研究都将要执行的过程视为简单动作的平坦序列，或者最多只有浅层的程序层次结构。在本文中，我们提出了一种将程序作为过程的形式化方法，这是一种强大而直观的表示层级过程知识以进行代理指令和控制的方法。我们进一步提出了一种层级模块化网络的建模范式，该网络由规划者和反应器组成，将自然语言意图转化为可执行程序的预测，并探测环境以获取完成程序执行所需的信息。我们在IQA和ALFRED数据集上实例化这个框架用于自然语言指令跟随。我们的模型在两个数据集上远远超过了反应式基线的性能。我们还证明了o...

    When humans conceive how to perform a particular task, they do so hierarchically: splitting higher-level tasks into smaller sub-tasks. However, in the literature on natural language (NL) command of situated agents, most works have treated the procedures to be executed as flat sequences of simple actions, or any hierarchies of procedures have been shallow at best. In this paper, we propose a formalism of procedures as programs, a powerful yet intuitive method of representing hierarchical procedural knowledge for agent command and control. We further propose a modeling paradigm of hierarchical modular networks, which consist of a planner and reactors that convert NL intents to predictions of executable programs and probe the environment for information necessary to complete the program execution. We instantiate this framework on the IQA and ALFRED datasets for NL instruction following. Our model outperforms reactive baselines by a large margin on both datasets. We also demonstrate that o
    

