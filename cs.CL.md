# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Language Rectified Flow: Advancing Diffusion Language Generation with Probabilistic Flows](https://arxiv.org/abs/2403.16995) | 语言校正流是一种基于标准概率流模型的新方法，通过学习常微分方程模型在源分布和目标分布之间传输，提供了统一和有效的生成模型和领域转移解决方案。 |
| [^2] | [Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings](https://arxiv.org/abs/2403.16984) | 本文通过明确建模不同的感兴趣方面来改进概念嵌入，使其能够捕捉更广泛的常识属性。 |
| [^3] | [A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course](https://arxiv.org/abs/2403.16977) | 本研究比较了人类、GPT-3.5和GPT-4在大学级编程课程中的表现，结果显示学生的平均得分明显高于AI提交，同时提示工程显著提高了GPT-4和GPT-3.5的得分。 |
| [^4] | [VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild](https://arxiv.org/abs/2403.16973) | VoiceCraft是一个基于标记填充的神经编解码器语言模型，在语音编辑和零-shot文本到语音任务上表现出色，实现了在多样性数据集上的最新性能。 |
| [^5] | [LLM Agent Operating System](https://arxiv.org/abs/2403.16971) | 提出了一种将大型语言模型嵌入操作系统中的LLM代理操作系统，旨在优化资源分配、促进代理间上下文切换、实现并发执行以及为代理提供工具服务。 |
| [^6] | [Evaluating Shortest Edit Script Methods for Contextual Lemmatization](https://arxiv.org/abs/2403.16968) | 本文评估了用于上下文词形还原的最短编辑脚本方法，通过将词形还原视为令牌分类任务，仅修改需要学习的SES标签，客观得出最佳的词形还原结果。 |
| [^7] | [Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance](https://arxiv.org/abs/2403.16952) | 该研究发现了数据混合规律，可以量化地预测模型性能与数据混合比例之间的关系，并提出了一种方法来通过拟合函数形式来引导理想的数据混合选择，从而优化大型语言模型的训练混合。 |
| [^8] | [Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators](https://arxiv.org/abs/2403.16950) | 在大型语言模型评估中，通过引入成对偏好搜索方法PAIRS，成功解决了LLMs与人类判断不一致的问题，并取得了优于直接打分的最先进性能。 |
| [^9] | [SPACE-IDEAS: A Dataset for Salient Information Detection in Space Innovation](https://arxiv.org/abs/2403.16941) | 这项研究介绍了SPACE-IDEAS数据集，用于检测与空间创新相关的显著信息，包括多种文本风格，并展示了如何通过多任务学习训练更好的分类器。 |
| [^10] | [Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models](https://arxiv.org/abs/2403.16915) | 本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调，在专题文档检索中显著改善了效果。 |
| [^11] | [New Intent Discovery with Attracting and Dispersing Prototype](https://arxiv.org/abs/2403.16913) | 提出了针对新意图发现问题的Robust and Adaptive Prototypical learning (RAP)框架，通过健壮的原型吸引学习(RPAL)和自适应的原型分散学习(APDL)方法，在已知和新的意图类别之间实现全局明显的决策边界。 |
| [^12] | [Towards Algorithmic Fidelity: Mental Health Representation across Demographics in Synthetic vs. Human-generated Data](https://arxiv.org/abs/2403.16909) | 本研究通过使用GPT-3分析不同人口统计在合成数据中的压力因素表示，创建出包含不同人口统计群体压力因素的合成数据集，为以后使用LLMs进行数据生成研究提供了见解。 |
| [^13] | [State Space Models as Foundation Models: A Control Theoretic Overview](https://arxiv.org/abs/2403.16899) | 将状态空间模型整合到深度神经网络架构中，为控制理论家和研究人员提供了一种有效建模动态系统的新途径。 |
| [^14] | [Encoding of lexical tone in self-supervised models of spoken language](https://arxiv.org/abs/2403.16865) | 本文研究分析了口语语言自监督模型对声调的编码能力，使用普通话和越南语作为案例研究，并发现SLMs在训练于非音调语言数据时也保持着显著的词汇音调编码能力。 |
| [^15] | [An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing](https://arxiv.org/abs/2403.16854) | 通过专家代币路由将多个专家LLM协同作为通用型，可以实现多个专家LLMs的无缝集成，支持隐式专业知识的学习和动态扩展新的专家LLMs，同时更好地隐藏协作细节，展现出比现有多LLM协作范式更好的效果和稳健性。 |
| [^16] | [Towards Explainability in Legal Outcome Prediction Models](https://arxiv.org/abs/2403.16852) | 先例是促进法律NLP模型可解释性的一种自然方式，我们提出了一种新颖的方法来识别法律结果预测模型使用的先例，并发现模型预测结果的能力不错，但其使用先例的方式与人类法官不同。 |
| [^17] | [Can ChatGPT predict article retraction based on Twitter mentions?](https://arxiv.org/abs/2403.16851) | 本研究探讨了ChatGPT是否能够基于Twitter提及来预测文章的撤回，研究发现在预测未来被撤回的有问题文章方面是具有一定潜力的。 |
| [^18] | [Cross-lingual Contextualized Phrase Retrieval](https://arxiv.org/abs/2403.16820) | 该研究提出了跨语言上下文化短语检索任务，并通过利用对比学习来解决多义性，从而增强了跨语言应用的性能。 |
| [^19] | [TEI2GO: A Multilingual Approach for Fast Temporal Expression Identification](https://arxiv.org/abs/2403.16804) | 本文介绍了TEI2GO模型，它在支持六种语言的同时，在其中四种语言取得了最先进的结果，并且具有显著改善的运行时间。 |
| [^20] | [Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback](https://arxiv.org/abs/2403.16792) | 本论文提出了一种名为ProCoder的新颖方法，通过编译器反馈引导，迭代地改进项目级代码上下文，以获得精确的代码生成 |
| [^21] | [Can Machine Translation Bridge Multilingual Pretraining and Cross-lingual Transfer Learning?](https://arxiv.org/abs/2403.16777) | 本文研究了机器翻译作为持续训练目标以增强语言表示学习、连接多语言预训练和跨语言应用的潜在益处，结果显示机器翻译未能增强跨语言表示学习。 |
| [^22] | [Synthetic Data Generation and Joint Learning for Robust Code-Mixed Translation](https://arxiv.org/abs/2403.16771) | 本文提出了用于鲁棒性混合代码翻译的合成数据生成和联合学习方法，包括开发了Hinglish到英语的平行语料库以及提出的能够处理噪声的联合训练模型RCMT。 |
| [^23] | [ProCQA: A Large-scale Community-based Programming Question Answering Dataset for Code Search](https://arxiv.org/abs/2403.16702) | ProCQA数据集是从StackOverflow社区提取的，为编程问题回答提供了自然结构化的混合模态问答对，并引入了一种模态-不可知的对比预训练方法，显著提高了代码语言模型的性能。 |
| [^24] | [ToXCL: A Unified Framework for Toxic Speech Detection and Explanation](https://arxiv.org/abs/2403.16685) | ToXCL是一个统一框架，旨在检测和解释隐性毒性言论，解决了传统模型在检测和解释任务中可能遇到的问题。 |
| [^25] | [Who is bragging more online? A large scale analysis of bragging in social media](https://arxiv.org/abs/2403.16668) | 第一次利用计算社会语言学方法在Twitter上进行了大规模研究，发现炫耀行为的普遍性随时间减少，而更年轻、受教育程度较高和受欢迎的用户更容易炫耀。 |
| [^26] | [RU22Fact: Optimizing Evidence for Multilingual Explainable Fact-Checking on Russia-Ukraine Conflict](https://arxiv.org/abs/2403.16662) | 提出了一个基于大型语言模型的方法，用于自动检索和总结网络中的证据，构建了RU22Fact数据集，是关于2022年俄乌冲突的多语言可解释事实核查数据集，同时开发了端到端可解释的事实核查系统来验证声明并生成解释。 |
| [^27] | [Grammatical vs Spelling Error Correction: An Investigation into the Responsiveness of Transformer-based Language Models using BART and MarianMT](https://arxiv.org/abs/2403.16655) | 该研究利用BART和MarianMT两种先进的深度神经网络语言模型，对文本中的错误进行修正，并通过比较研究探究它们的有效性 |
| [^28] | [A comparative analysis of embedding models for patent similarity](https://arxiv.org/abs/2403.16630) | 本文比较了不同类型的专利嵌入模型在专利相似性计算任务上的表现，并具体探讨了Sentence Transformers (SBERT) 架构在专利相似性任务中的性能。 |
| [^29] | [Semantically Enriched Cross-Lingual Sentence Embeddings for Crisis-related Social Media Texts](https://arxiv.org/abs/2403.16614) | 提出了多语言句子编码器（CT-XLMR-SE和CT-mBERT-SE），可为50多种语言的危机相关社交媒体文本嵌入语义内容，使具有相似含义的文本在同一向量空间内接近，无论语言差异。 |
| [^30] | [Conversational Grounding: Annotation and Analysis of Grounding Acts and Grounding Units](https://arxiv.org/abs/2403.16609) | 对话系统的可靠性建设中，通过引入接地行为和接地单元的标注和度量，填补了现有对话系统在接地能力上的不足。 |
| [^31] | [TrustAI at SemEval-2024 Task 8: A Comprehensive Analysis of Multi-domain Machine Generated Text Detection Techniques](https://arxiv.org/abs/2403.16592) | 本文提出了针对SemEval2024 Task8的TrustAI方法，旨在在不同领域和语境下检测机器生成文本，研究综合分析了统计、神经和预训练模型等各种方法，并介绍了实验设置和深入的误差分析，取得了相当高的准确率，同时也突出了未来研究中需要考虑的挑战和关键因素。 |
| [^32] | [Can Large Language Models (or Humans) Distill Text?](https://arxiv.org/abs/2403.16584) | 大型语言模型（LLMs）在文本提炼中具有独特优势，但在处理情感时仍存在一定局限性，无论是对机器学习分类器还是人类注释员而言。 |
| [^33] | [NSINA: A News Corpus for Sinhala](https://arxiv.org/abs/2403.16571) | NSINA是为解决僧伽罗语中LLMs适应性挑战而引入的最大新闻语料库，为改进该语言的自然语言处理提供了宝贵资源和基准。 |
| [^34] | [PE: A Poincare Explanation Method for Fast Text Hierarchy Generation](https://arxiv.org/abs/2403.16554) | 介绍了一种使用Poincaré解释方法在超几何空间中建模特征交互作用的新方法，并提出了时间复杂度为O(n^2logn)的框架，证明了在投影空间中进行的层次聚类过程可以视为构建最小生成树，提出了一个时间有效的算法 |
| [^35] | [Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning](https://arxiv.org/abs/2403.16543) | 通过对比学习从多个句子表示中提取互补的判别信息，提高少样本关系分类中的信息提取效率 |
| [^36] | [Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art](https://arxiv.org/abs/2403.16527) | 基于基础模型的幻觉检测旨在填补现有规划者缺少的常识推理，以适用于超出分布任务的场景。 |
| [^37] | [Visually Guided Generative Text-Layout Pre-training for Document Intelligence](https://arxiv.org/abs/2403.16516) | 提出了一种名为ViTLP的可视引导的生成文本布局预训练技术，能够处理任意长度的词汇密集型文档，并且可以作为OCR模型用于文本定位和识别。 |
| [^38] | [LLMs Are Few-Shot In-Context Low-Resource Language Learners](https://arxiv.org/abs/2403.16512) | 该研究对25种低资源语言和7种相对较高资源语言上的情境学习（ICL）及其跨语言变体进行了研究，发现了在低资源语言中使用LLMs进行ICL的有效性，提出了替代方法查询对齐，并为低资源语言的ICL提供了宝贵见解。 |
| [^39] | [LARA: Linguistic-Adaptive Retrieval-Augmented LLMs for Multi-Turn Intent Classification](https://arxiv.org/abs/2403.16504) | LARA是一个Linguistic-Adaptive Retrieval-Augmented Language Models（语言自适应检索增强LLMs），旨在通过结合微调过的较小模型与检索增强机制来提高多语言多轮意图分类任务的准确性，从而改善对话背景的理解。 |
| [^40] | [Automatic Construction of a Large-Scale Corpus for Geoparsing Using Wikipedia Hyperlinks](https://arxiv.org/abs/2403.16483) | 本文提出了一种利用维基百科超链接自动构建用于地理解析的大规模语料库的新方法，构建了包含130万篇文章的WHLL语料库，为地理解析领域带来了新的数据资源。 |
| [^41] | [Few-shot Named Entity Recognition via Superposition Concept Discrimination](https://arxiv.org/abs/2403.16463) | 通过Superposition Concept Discriminator（SuperCD）提出了一种解决少样本NER中精确泛化问题的方法，通过主动学习范式从示例实例中识别叠加概念并检索相应实例来标注，以解决信息不足导致的模糊性挑战。 |
| [^42] | [A Study on How Attention Scores in the BERT Model are Aware of Lexical Categories in Syntactic and Semantic Tasks on the GLUE Benchmark](https://arxiv.org/abs/2403.16447) | 本研究探讨了BERT模型中的注意力分数如何根据词汇类别的不同而变化，在GLUE基准测试下的句法和语义任务中，证实在强调语义信息的任务中，注意力主要集中于内容词，而在强调句法信息的任务中，注意力主要集中在功能词上 |
| [^43] | [Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric, Data, and Algorithm](https://arxiv.org/abs/2403.16446) | 针对LLMs的临床能力，提出了自动评估范式，包括度量、数据和算法，以确保安全和可靠的临床应用。 |
| [^44] | [KIT-19: A Comprehensive Korean Instruction Toolkit on 19 Tasks for Fine-Tuning Korean Large Language Models](https://arxiv.org/abs/2403.16444) | 这项研究介绍了一套名为KIT-19的韩文指令数据集，用于开发韩文大型语言模型，在19个韩文自然语言处理任务上取得了显著的优越性能。 |
| [^45] | [CodeS: Natural Language to Code Repository via Multi-Layer Sketch](https://arxiv.org/abs/2403.16443) | CodeS提出了一个新的软件工程任务NL2Repo，旨在从自然语言需求中生成整个代码仓库，通过多层草图的方式解决这一任务。 |
| [^46] | [If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions](https://arxiv.org/abs/2403.16442) | 通过新颖的Extract and Explore（EX2）方法，研究发现在视觉-语言模型（VLM）中，重要的特征描述包括非视觉属性，虚假描述影响VLM表示，不同的VLM优先考虑不同的内容。 |
| [^47] | [Evaluating Large Language Models with Runtime Behavior of Program Execution](https://arxiv.org/abs/2403.16437) | 本文提出了一个名为REval的框架，用于评估代码LLMs的代码推理能力以及与程序执行的一致性。 |
| [^48] | [InstUPR : Instruction-based Unsupervised Passage Reranking with Large Language Models](https://arxiv.org/abs/2403.16435) | InstUPR是一种基于大型语言模型的无监督段落重新排序方法，利用了LLMs的指令跟踪能力，无需额外微调，通过软得分聚合技术和成对重新排序，在BEIR基准测试中表现优秀。 |
| [^49] | [$\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models](https://arxiv.org/abs/2403.16432) | 基于提示的语言模型的优化过程揭示了生成对抗提示以误导模型的见解，引发了对该范式对抗性脆弱性的担忧。 |
| [^50] | [Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases](https://arxiv.org/abs/2403.16396) | 重新审视信息抽取中的任务定义偏见现象，提出了一个多阶段框架来衡量、感知和缓解这种偏见，实验证明该框架有效性。 |
| [^51] | [Skews in the Phenomenon Space Hinder Generalization in Text-to-Image Generation](https://arxiv.org/abs/2403.16394) | 文本到图像生成领域的泛化问题源于现象空间中的偏差，需要量化和解决语言和视觉偏差，以提高泛化性能 |
| [^52] | [Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA](https://arxiv.org/abs/2403.16385) | 使用LLM作为数据生成器，通过逐步合成策略将复杂问题分解为逐步子问题，利用外部工具生成最终答案，以解决图表VQA模型在复杂推理问题上的表现不佳。 |
| [^53] | [Enhanced Facet Generation with LLM Editing](https://arxiv.org/abs/2403.16345) | 提出了一种通过利用搜索引擎获取的文档和相关查询来增强分面预测的策略，并提出了专注于仅使用查询作为输入来预测分面的框架 |
| [^54] | [Large Language Models in Biomedical and Health Informatics: A Bibliometric Review](https://arxiv.org/abs/2403.16303) | LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。 |
| [^55] | [LexDrafter: Terminology Drafting for Legislative Documents using Retrieval Augmented Generation](https://arxiv.org/abs/2403.16295) | LexDrafter是一种框架，利用检索增强生成和现有法律文件中的术语定义，帮助起草法规文件中的“Definitions”文章。 |
| [^56] | [Connecting the Dots: Inferring Patent Phrase Similarity with Retrieved Phrase Graphs](https://arxiv.org/abs/2403.16265) | 提出了一种利用检索短语图推断专利短语相似性的方法，通过构建短语图，补充专利短语的全局上下文信息，并利用自监督学习目标来优化嵌入和图参数。 |
| [^57] | [Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling](https://arxiv.org/abs/2403.16248) | 大型语言模型作为主题建模的替代方法，能够生成相关主题标题并遵循人类指南来精细化和合并主题 |
| [^58] | [Improving Sequence-to-Sequence Models for Abstractive Text Summarization Using Meta Heuristic Approaches](https://arxiv.org/abs/2403.16247) | 改进使用元启发方法的序列到序列模型，以提高抽象文本摘要的准确性和有效性 |
| [^59] | [SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder](https://arxiv.org/abs/2403.16204) | 本文研究了通过上下文感知编码器改进NL2SQL模型中上下文学习的方法，并提出了一个准确估计查询相似性的模型，通过170k个问题对数据集进行训练，能够优于其他竞争模型，提升NL2SQL模型的性能。 |
| [^60] | [ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models](https://arxiv.org/abs/2403.16187) | ALoRA创新地提出了分配低秩适应性（ALoRA）方法，通过动态调整适应过程中的固有秩，从而解决了在微调大型语言模型时固定固有秩带来的问题。 |
| [^61] | [Subspace Defense: Discarding Adversarial Perturbations by Learning a Subspace for Clean Signals](https://arxiv.org/abs/2403.16176) | 通过学习一个仅存在干净信号特征的子空间并丢弃扰动特征，使得深度神经网络能够更好地区分对抗性示例。 |
| [^62] | [Exploiting Semantic Reconstruction to Mitigate Hallucinations in Vision-Language Models](https://arxiv.org/abs/2403.16167) | 通过准确定位和惩罚幻觉标记，ESREAL引入了一种新颖的无监督学习框架，通过语义重建来抑制生成幻觉，解决了视觉-语言模型中幻觉问题。 |
| [^63] | [Korean Bio-Medical Corpus (KBMC) for Medical Named Entity Recognition](https://arxiv.org/abs/2403.16158) | 利用ChatGPT构建了韩国生物医学语料库（KBMC），在医学命名实体识别方面取得了显著的进展，证明了使用专门工具和数据集在医学领域的语言处理中的重要性。 |
| [^64] | [What Happens to a Dataset Transformed by a Projection-based Concept Removal Method?](https://arxiv.org/abs/2403.16142) | 一种基于投影的概念去除方法会在转换后的数据集中注入强大的统计依赖性，并导致表示空间高度结构化，使得可以通过应用反聚类方法重建原始标记。 |
| [^65] | [A Little Leak Will Sink a Great Ship: Survey of Transparency for Large Language Models from Start to Finish](https://arxiv.org/abs/2403.16139) | 对大型语言模型的透明度进行调查，探讨泄漏问题的影响，建立了泄漏率、生成率和检测率这三个标准，并实验阐明了泄漏率与输出率以及检测率之间的关系。 |
| [^66] | [A Survey on Lexical Ambiguity Detection and Word Sense Disambiguation](https://arxiv.org/abs/2403.16129) | 本文调查了词汇歧义检测和词义消歧领域中的最新技术，介绍了词义扩展和神经肌肉接近法等创新方法，以预测新词义来提高消歧的准确性。 |
| [^67] | [WangchanLion and WangchanX MRC Eval](https://arxiv.org/abs/2403.16127) | WangchanLion是一个专注于泰语机器阅读理解的指令微调模型，在0-shot和1-shot设置下能够理解上下文并产生与参考答案一致的回答，同时提出了新的评估方案。 |
| [^68] | [A Multi-Label Dataset of French Fake News: Human and Machine Insights](https://arxiv.org/abs/2403.16099) | 通过建立一份包括 100 篇文档的多标签数据集 OBSINFOX，研究了人类与机器在认定假新闻特征上的差异，并发现了语料库中讽刺文本的普遍存在。 |
| [^69] | [LLMs as Compiler for Arabic Programming Language](https://arxiv.org/abs/2403.16087) | 本文介绍了APL（阿拉伯编程语言），它使用LLM作为半编译器，将阿拉伯文本代码转换为Python代码并运行，构建了完整的流水线。 |
| [^70] | [Argument Quality Assessment in the Age of Instruction-Following Large Language Models](https://arxiv.org/abs/2403.16084) | 论文讨论了在指导式大型语言模型时代，如何通过引入论证理论和情景，使其能够更可靠地评估争议问题中的论证质量。 |
| [^71] | [Qibo: A Large Language Model for Traditional Chinese Medicine](https://arxiv.org/abs/2403.16056) | 本论文在中医领域构建了专业语料库，基于LLaMA成功开发了首个经过完整训练的Qibo模型，并推出了用于评估LLMs性能的Qibo基准测试。 |
| [^72] | [Monotonic Paraphrasing Improves Generalization of Language Model Prompting](https://arxiv.org/abs/2403.16038) | 提出了单调释义（MonoPara）方法，通过释义LM和目标LM集成解码过程，将提示或指令释义为低困惑度的版本，从而提高语言模型的泛化能力 |
| [^73] | [Node Classification via Semantic-Structural Attention-Enhanced Graph Convolutional Networks](https://arxiv.org/abs/2403.16033) | 该论文提出了一种名为语义-结构注意增强图卷积网络（SSA-GCN），能够同时模拟图结构并从知识图谱和复杂网络的角度提取无监督特征，以提升节点分类性能。 |
| [^74] | [CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering](https://arxiv.org/abs/2403.16008) | 通过设计专门的问答数据集和基于认知行为疗法原则的提示，本研究引入了CBT-LLM，一个针对中国心理健康问答的大型语言模型，旨在提高心理支持精度和效力。 |
| [^75] | [BIMCV-R: A Landmark Dataset for 3D CT Text-Image Retrieval](https://arxiv.org/abs/2403.15992) | 提出了一个里程碑数据集BIMCV-R，包含8,069个3D CT体积和其放射学报告，同时开发了检索策略MedFinder，为3D医学文本图像检索领域提供了重要贡献 |
| [^76] | [IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language Models](https://arxiv.org/abs/2403.15952) | 提出了IllusionVQA数据集，用于测试视觉语言模型在错觉和难解场景下的表现，研究发现在理解任务和定位任务上，表现最佳的VLM为GPT4V，而人类表现更胜一筹。 |
| [^77] | [Geotokens and Geotransformers](https://arxiv.org/abs/2403.15940) | 本文提出了地理代币的概念，将其作为变压器的输入组件与具体地理位置联系起来，设计了一种针对球面坐标的位置编码方法。 |
| [^78] | [LlamBERT: Large-scale low-cost data annotation in NLP](https://arxiv.org/abs/2403.15938) | LlamBERT是一种利用大规模语言模型注释未标记数据库并用于微调变压器编码器的混合方法，在降低成本的同时略微牺牲准确性。 |
| [^79] | [Leveraging Zero-Shot Prompting for Efficient Language Model Distillation](https://arxiv.org/abs/2403.15886) | 通过利用零-shot提示来引出教师模型的理由，减少手工制作的少-shot示例的必要性，并降低所需的总记号数，这直接转化为成本节约。 |
| [^80] | [STEntConv: Predicting Disagreement with Stance Detection and a Signed Graph Convolutional Network](https://arxiv.org/abs/2403.15885) | STEntConv利用用户立场建立了用户和命名实体的加权图，通过有符号图卷积网络预测Reddit帖子中的不同意见表达。 |
| [^81] | [VLUE: A New Benchmark and Multi-task Knowledge Transfer Learning for Vietnamese Natural Language Understanding](https://arxiv.org/abs/2403.15882) | VLUE是第一个越南自然语言理解评估（VLUE）基准，提供了包括文本分类、跨度提取和自然语言理解在内的五个数据集，评估了七个最先进的预训练模型，并介绍了CafeBERT，一个取得优异结果的新型最先进预训练模型。 |
| [^82] | [LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series classification](https://arxiv.org/abs/2403.15875) | LAMPER框架旨在评估预训练语言模型在零样本时间序列分类中的适应能力，研究发现其特征表示能力受到PLMs最大输入标记阈值的影响。 |
| [^83] | [RAAMove: A Corpus for Analyzing Moves in Research Article Abstracts](https://arxiv.org/abs/2403.15872) | 这个研究介绍了一个名为RAAMove的语料库，旨在帮助分析并自动识别研究论文摘要中的动作结构。 |
| [^84] | [Centered Masking for Language-Image Pre-Training](https://arxiv.org/abs/2403.15837) | 使用中心掩蔽的GLIP技术在语言-图像预训练中取代了随机掩蔽，利用高斯分布提高了性能，并且易于获得且适用于不具有明显中心焦点的数据集。 |
| [^85] | [Computational Sentence-level Metrics Predicting Human Sentence Comprehension](https://arxiv.org/abs/2403.15822) | 本研究引入了创新方法，使用多语言大型语言模型计算句子级度量，并证明这些度量能够高度准确地预测人类句子阅读速度，为未来整合LLMs和认知科学研究提供了有前景的方向。 |
| [^86] | [MRC-based Nested Medical NER with Co-prediction and Adaptive Pre-training](https://arxiv.org/abs/2403.15800) | 提出了基于MRC的医学NER模型，采用任务自适应预训练策略、多词对嵌入和多粒度扩张卷积，并结合Biaffine和MLP的联合预测器，以增强模型在医学领域的表征和识别性能。 |
| [^87] | [Understanding Emergent Abilities of Language Models from the Loss Perspective](https://arxiv.org/abs/2403.15796) | 本文从损失角度重新定义了语言模型的突现能力，发现具有相同预训练损失的模型在不同任务上表现相似，而当预训练损失低于特定阈值时，模型将展现出突现能力。 |
| [^88] | [Modeling Unified Semantic Discourse Structure for High-quality Headline Generation](https://arxiv.org/abs/2403.15776) | 通过将文档级修辞结构理论（RST）树与句级抽象意义表示（AMR）图结合起来构建S3图，形成统一的语义话语结构，用于标题生成框架中，进一步设计了分层结构修剪机制，提高标题生成的效果。 |
| [^89] | [User-Side Realization](https://arxiv.org/abs/2403.15757) | 用户端实现为用户提供了积极的解决方案，通过在用户端运行通用算法来解决常见问题，无需服务提供商改变服务本身。 |
| [^90] | [Leveraging Large Language Models for Preliminary Security Risk Analysis: A Mission-Critical Case Study](https://arxiv.org/abs/2403.15756) | 大型语言模型在初步安全风险分析中展现了比人类更快速的信息总结能力，本研究通过案例研究探讨了微调模型在协助从业者进行PSRA方面的实用性。 |
| [^91] | [On the Fragility of Active Learners](https://arxiv.org/abs/2403.15744) | 本研究发现主动学习技术只在特定情境下有效，对文本分类从业者的建议是选择适当的文本表示和分类器同样重要。 |
| [^92] | [Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models](https://arxiv.org/abs/2403.15740) | 通过在文档中插入个人密码并识别生成内容中的“幽灵句子”，普通用户可以确认大型语言模型是否滥用其数据，从而实现数据版权保护。 |
| [^93] | [Few-shot Dialogue Strategy Learning for Motivational Interviewing via Inductive Reasoning](https://arxiv.org/abs/2403.15737) | 提出了DIIT框架，通过学习和应用专家演示中的自然语言归纳规则，改善主动倾听技能，减少不请自来的建议，促进更协作和无权威性的回应。 |
| [^94] | [LLMs Instruct LLMs:An Extraction and Editing Method](https://arxiv.org/abs/2403.15736) | 提出了一种顺序融合方法，将复杂环境中的知识融入LLMs中，用于更新大型语言模型。 |
| [^95] | [Towards a \textbf{RAG}-based Summarization Agent for the Electron-Ion Collider](https://arxiv.org/abs/2403.15729) | 开发了一种面向电子离子对撞机的基于RAG的摘要生成代理，能够压缩信息并引用相关回复，为合作者提供重大优势 |
| [^96] | [PEaCE: A Chemistry-Oriented Dataset for Optical Character Recognition on Scientific Documents](https://arxiv.org/abs/2403.15724) | 提出了PEaCE数据集，利用其中的合成和真实记录评估了基于transformer的OCR模型在化学文献中的识别效果，并提出可以模拟真实记录特征的转换。 |
| [^97] | [EDDA: A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance Detection](https://arxiv.org/abs/2403.15715) | EDDA框架提出了一种新的编码器-解码器数据增强方法，通过if-then原理和语义相关的词替换策略，解决了零样本立场检测中目标增强和文本增强的不足。 |
| [^98] | [FEEL: A Framework for Evaluating Emotional Support Capability with Large Language Models](https://arxiv.org/abs/2403.15699) | 提出了一个基于大型语言模型的框架FEEL，用于评估情感支持能力，解决了当前非人工方法在评估情感支持能力方面面临的挑战，并采用了概率分布方法和集成学习以获得更稳定和全面的结果。 |
| [^99] | [MixRED: A Mix-lingual Relation Extraction Dataset](https://arxiv.org/abs/2403.15696) | 论文提出了一个新的多语言关系抽取任务MixRE，并构建了支持该任务的人工注释数据集MixRED，填补了多语言情景下关系抽取研究的空白。 |
| [^100] | [EAGLE: A Domain Generalization Framework for AI-generated Text Detection](https://arxiv.org/abs/2403.15690) | EAGLE提出了一个领域泛化框架，能够利用从旧语言模型中获得的标记数据，学习特征的不变性，从而检测出未知目标生成器生成的文本。 |
| [^101] | [AC4: Algebraic Computation Checker for Circuit Constraints in ZKPs](https://arxiv.org/abs/2403.15676) | 该论文引入了一种新方法，通过将算术电路约束编码为多项式方程系统，并通过代数计算在有限域上解决多项式方程系统，以精确定位ZKP电路中两种不同类型的错误。 |
| [^102] | [AI for Biomedicine in the Era of Large Language Models](https://arxiv.org/abs/2403.15673) | 大型语言模型在生物医学领域展现出巨大潜力，能用于推动生物医学知识的发现和应用 |
| [^103] | [Differentially Private Next-Token Prediction of Large Language Models](https://arxiv.org/abs/2403.15638) | 提出了Private Mixing of Ensemble Distributions (PMixED)：通过将模型的输出分布投影到公共LLM的输出分布周围的集合上，并采样平均来实现实际的下一个标记预测，以更轻量化的方式实现对隐私敏感的大型语言模型的预测。 |
| [^104] | [NaturalTurn: A Method to Segment Transcripts into Naturalistic Conversational Turns](https://arxiv.org/abs/2403.15615) | NaturalTurn是一种专门设计用于准确捕捉自然对话交流动态的轮次分割算法，通过区分说话者的主要对话轮次和听众的次要话语，能够比现有方法更好地提取转录信息。 |
| [^105] | [LimGen: Probing the LLMs for Generating Suggestive Limitations of Research Papers](https://arxiv.org/abs/2403.15529) | 本文提出了一个新颖而具有挑战性的任务，即为研究论文生成建议性局限，通过调查大型语言模型的多种方法来揭示相关挑战、实践见解和潜在机会。 |
| [^106] | [CTSM: Combining Trait and State Emotions for Empathetic Response Model](https://arxiv.org/abs/2403.15516) | CTSM模型结合特质和状态情绪，通过构建和编码情绪嵌入以及引入情绪引导模块，解决了先前处理情绪感知不足的问题。 |
| [^107] | [Enhancing Effectiveness and Robustness in a Low-Resource Regime via Decision-Boundary-aware Data Augmentation](https://arxiv.org/abs/2403.15512) | 本文提出了一种决策边界感知的数据增强策略，通过移动潜在特征、重构生成模糊版本以及采用中K采样来增强生成句子的多样性，从而比较于其他方法提高了在低资源环境中的有效性和稳健性。 |
| [^108] | [Evaluating the Performance of LLMs on Technical Language Processing tasks](https://arxiv.org/abs/2403.15503) | 该研究评估了LLMs在技术语言处理任务中的性能，通过研究美国联邦电信法规第47章，尝试简化信息收集任务。 |
| [^109] | [Sequential Decision-Making for Inline Text Autocomplete](https://arxiv.org/abs/2403.15502) | 通过强化学习和顺序决策制定改进了文本输入系统中的在线自动完成建议，将认知负荷纳入模型训练目标，基于文本输入速度的奖励函数。 |
| [^110] | [Enhancing Medical Support in the Arabic Language Through Personalized ChatGPT Assistance](https://arxiv.org/abs/2403.15501) | 通过使用ChatGPT在阿拉伯语医疗诊断中取得了有希望的性能，平均相似度评分为76%，链式提示技术相对有优势。 |
| [^111] | [Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models](https://arxiv.org/abs/2403.15498) | 棋类语言模型在没有先验知识的情况下，通过下一个字符预测训练，仍能学习出内部表示的棋盘状态 |
| [^112] | [Visual Analytics for Fine-grained Text Classification Models and Datasets](https://arxiv.org/abs/2403.15492) | 发展了SemLa，一个针对细粒度文本分类模型开发工作流需求的新型视觉分析系统，用于分解数据集中的复杂语义结构和可视化文本含义中的细微差别 |
| [^113] | [Open Source Conversational LLMs do not know most Spanish words](https://arxiv.org/abs/2403.15491) | 本研究评估了开源对话式LLMs对西班牙语单词的了解程度，结果显示它们无法正确使用大部分单词写句子。 |
| [^114] | [Sequence-to-Sequence Language Models for Character and Emotion Detection in Dream Narratives](https://arxiv.org/abs/2403.15486) | 本研究提出一种序列到序列语言模型框架，首次在梦境叙事中进行角色和情感检测研究，展示语言模型可以有效应对该复杂任务，监督模型表现更佳且参数更少。 |
| [^115] | [MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression Detection](https://arxiv.org/abs/2403.15485) | MOGAM模型是为了克服现有抑郁症检测方法在不同社交媒体数据类型上的限制而提出，通过多模态数据的综合应用，实现了更具可扩展性和多功能性的解决方案。 |
| [^116] | [RakutenAI-7B: Extending Large Language Models for Japanese](https://arxiv.org/abs/2403.15484) | RakutenAI-7B是一套日本导向的大型语言模型，在日本LM Harness基准测试中表现最好，分别发布了指导和聊天调整的模型。 |
| [^117] | [Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors](https://arxiv.org/abs/2403.15482) | 利用大型语言模型为初学者同行辅导员提供多级详细反馈，赋能规模化的支持心理健康问题患者。 |
| [^118] | [Integrating Supervised Extractive and Generative Language Models for Suicide Risk Evidence Summarization](https://arxiv.org/abs/2403.15478) | 该研究集成了监督式提取和生成式语言模型，提出一种提供自杀风险支持证据的方法，并在CLPsych 2024 shared task中取得了显著成绩。 |
| [^119] | [Efficient argument classification with compact language models and ChatGPT-4 refinements](https://arxiv.org/abs/2403.15473) | 论文通过比较研究了几种基于深度学习的模型在论点挖掘中的应用，提出了基于BERT架构和ChatGPT-4微调模型的集成模型，结果显示BERT+ChatGPT-4在论点分类方面表现优异。 |
| [^120] | [Vi-Mistral-X: Building a Vietnamese Language Model with Advanced Continual Pre-training](https://arxiv.org/abs/2403.15470) | 该论文介绍了 vi-Mistral-X，一个专为越南语设计的创新大型语言模型，采用了持续预训练方法，并引入了针对越南语的额外预训练阶段，大大提高了其对越南语的理解和生成能力。 |
| [^121] | [Isometric Neural Machine Translation using Phoneme Count Ratio Reward-based Reinforcement Learning](https://arxiv.org/abs/2403.15469) | 本论文提出了使用强化学习（RL）开发的等距NMT系统，重点在于优化源语言和目标语言句对中音素计数的对齐。 |
| [^122] | [Don't be a Fool: Pooling Strategies in Offensive Language Detection from User-Intended Adversarial Attacks](https://arxiv.org/abs/2403.15467) | 本文提出了一种针对用户故意的对抗攻击的池化策略，通过引入逐层的简单但有效的池化策略来捕捉冒犯性和标记嵌入，使模型更加稳健，即使攻击率增加。 |
| [^123] | [Most Likely Sequence Generation for $n$-Grams, Transformers, HMMs, and Markov Chains, by Using Rollout Algorithms](https://arxiv.org/abs/2403.15465) | 本文介绍了一种使用展开算法为$n$-grams，Transformers，HMMs和马尔可夫链生成最有可能的序列的方法 |
| [^124] | [LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction](https://arxiv.org/abs/2403.15464) | 该论文提出了一种新方法，结合预测性代理推理和批判性代理指导，利用LLMs对结构化患者就诊数据进行预测，取得了较好的效果。 |
| [^125] | [Assessing effect sizes, variability, and power in the on-line study of language production](https://arxiv.org/abs/2403.15459) | 评估语言生成在线研究中效应大小、变异性和功效对设计效果的影响 |
| [^126] | [Fine-Tuning Pre-trained Language Models to Detect In-Game Trash Talks](https://arxiv.org/abs/2403.15458) | 本研究调查了预训练语言模型在检测游戏内垃圾话和毒性信息方面的能力，使用BERT和GPT模型在DOTA 2游戏对战的聊天数据上进行评估。 |
| [^127] | [WoLF: Large Language Model Framework for CXR Understanding](https://arxiv.org/abs/2403.15456) | WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。 |
| [^128] | [Improving Sampling Methods for Fine-tuning SentenceBERT in Text Streams](https://arxiv.org/abs/2403.15455) | 本研究旨在解决概念漂移问题，通过探索七种文本采样方法的有效性，精细调整语言模型，从而减轻性能下降。 |
| [^129] | [Emotion Detection with Transformers: A Comparative Study](https://arxiv.org/abs/2403.15454) | 本研究探索了在文本数据情感分类中应用基于Transformer的模型，并发现常用技术如去除标点符号和停用词可能会阻碍模型的性能，因为这些元素仍然能够传达情感或强调，而Transformer的优势在于理解文本内的语境关系。 |
| [^130] | [Span-Oriented Information Extraction -- A Unifying Perspective on Information Extraction](https://arxiv.org/abs/2403.15453) | 提出了以文本中的跨度为中心的统一视角，将各种信息抽取任务重新定位为相同基本面向跨度的信息抽取任务的变体 |
| [^131] | [What Are Tools Anyway? A Survey from the Language Model Perspective](https://arxiv.org/abs/2403.15452) | 从语言模型的角度出发，本调查提供了工具的统一定义为LMs使用的外部程序，并对LM工具场景和方法进行了系统审查，同时通过实证研究了解了各种工具方法的效率，以及突出了该领域的挑战和未来研究方向。 |
| [^132] | [Towards Enabling FAIR Dataspaces Using Large Language Models](https://arxiv.org/abs/2403.15451) | 本研究展示了大型语言模型在数据空间中的潜力，并提出了进一步探索该领域的研究议程。 |
| [^133] | [Loops On Retrieval Augmented Generation (LoRAG)](https://arxiv.org/abs/2403.15450) | LoRAG是一种新框架，通过引入迭代循环机制提高了检索增强型文本生成的质量，在实验证明在生成的文本连贯性和相关性方面优于当前最先进模型。 |
| [^134] | [Hatred Stems from Ignorance! Distillation of the Persuasion Modes in Countering Conversational Hate Speech](https://arxiv.org/abs/2403.15449) | 研究研究了对抗在线仇恨言论的最佳方法，通过分析对话中的理由、情感和信誉等说服方式，对比封闭和开放交互中的不同行为和话题层面，发现了在对抗言论中的微妙差异。 |
| [^135] | [Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression](https://arxiv.org/abs/2403.15447) | 量化目前比剪枝更有效，可以同时实现效率和可信度，但剪枝会显著降低模型的可信度 |
| [^136] | [Decoding Multilingual Topic Dynamics and Trend Identification through ARIMA Time Series Analysis on Social Networks: A Novel Data Translation Framework Enhanced by LDA/HDP Models](https://arxiv.org/abs/2403.15445) | 该研究提出了一种新方法，通过ARIMA时间序列分析和LDA/HDP模型提取多语言社交网络中的主题动态，特别关注在危机期间的交流趋势，这一方法在语言一致性任务中表现出色。 |
| [^137] | [Linguistics from a topological viewpoint](https://arxiv.org/abs/2403.15440) | 本文介绍了一种分析南美语言拓扑形状的工作流程，应用了多重对应分析技术和拓扑数据分析方法。 |
| [^138] | [Using Contextual Information for Sentence-level Morpheme Segmentation](https://arxiv.org/abs/2403.15436) | 将形态素分割任务重新定义为序列到序列问题，并通过多语言模型展示出优异性能，揭示了高资源语言环境下的可比效力，以及低资源语言场景下的局限性。 |
| [^139] | [ChatPattern: Layout Pattern Customization via Natural Language](https://arxiv.org/abs/2403.15434) | ChatPattern利用大语言模型（LLM）的框架实现了灵活的布局模式定制，能够通过自然语言要求生成高质量大规模模式。 |
| [^140] | [Distilling Named Entity Recognition Models for Endangered Species from Large Language Models](https://arxiv.org/abs/2403.15430) | 通过从GPT-4中提取知识，我们为濒危物种创建了命名实体识别和关系抽取的数据集，为保护生物多样性做出贡献。 |
| [^141] | [A Three-Phases SFT Hybrid Model Integrated Strong Prior Module and Data Overlap Estimation in the Eduation Context](https://arxiv.org/abs/2403.15426) | 提出了一种在教育领域中应用的三阶段监督微调模型，通过先验和数据重叠估计实现了教育知识的结构拆卸和增量引导输出。 |
| [^142] | [Towards Measuring and Modeling "Culture" in LLMs: A Survey](https://arxiv.org/abs/2403.15412) | 这项研究调查了39篇最新论文，旨在研究大型语言模型中的文化表达和包容性，发现当前研究未对“文化”进行定义，而是在特定设计的数据集上对模型进行探究，研究了某些“文化”的方面，留下许多未被探究的有趣和重要方面，如语义领域和关于性。 |
| [^143] | [X-AMR Annotation Tool](https://arxiv.org/abs/2403.15407) | 该论文介绍了一种新型的X-AMR注释工具，通过机器辅助提升用户体验，实现了对关键事件语义的注释，与GPT-4集成表现出色。 |
| [^144] | [Large Language Model for Mental Health: A Systematic Review](https://arxiv.org/abs/2403.15401) | 该论文系统评价了大型语言模型在心理健康领域的应用，讨论了其在早期筛查、数字干预和其他临床应用中的挑战和机遇。 |
| [^145] | [ChatGPT in Linear Algebra: Strides Forward, Steps to Go](https://arxiv.org/abs/2403.15399) | ChatGPT在线性代数中取得巨大改进，但目前仍然无法完全取代人类教师，软件理解问题的能力引发了人们对其潜力的思考。 |
| [^146] | [Regulating Large Language Models: A Roundtable Report](https://arxiv.org/abs/2403.15397) | 圆桌会议探讨了如何通过法律和政策来解决大型语言模型可能带来的真实性、隐私和市场集中等方面的重要社会问题。 |
| [^147] | [Detection of Opioid Users from Reddit Posts via an Attention-based Bidirectional Recurrent Neural Network](https://arxiv.org/abs/2403.15393) | 通过机器学习方法分析Reddit用户帖子，检测阿片类药物使用者，帮助改善对阿片类药物危机的监测和理解。 |
| [^148] | [CapsF: Capsule Fusion for Extracting psychiatric stressors for suicide from twitter](https://arxiv.org/abs/2403.15391) | 该研究探索了一种基于胶囊的方法，用于从波斯语推文中检测与自杀相关的心理压力源，取得了不错的分类准确性。 |
| [^149] | [LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models](https://arxiv.org/abs/2403.15388) | PruMerge提出了一种自适应的视觉令牌减少方法，可以有效减少大型多模态模型中的视觉令牌数量，同时保持模型性能。 |
| [^150] | [A Transfer Attack to Image Watermarks](https://arxiv.org/abs/2403.15365) | 水印领域的研究表明，即使在攻击者无法访问水印模型或检测API的情况下，水印基础的AI生成图像检测器也无法抵抗对抗攻击。 |
| [^151] | [Exploring ChatGPT and its Impact on Society](https://arxiv.org/abs/2403.14643) | ChatGPT是一种基于Transformer架构的大型语言模型，能够生成人类化的对话回复，可革新各行业并改变技术互动方式。 |
| [^152] | [ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training](https://arxiv.org/abs/2403.14589) | 提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。 |
| [^153] | [K-Act2Emo: Korean Commonsense Knowledge Graph for Indirect Emotional Expression](https://arxiv.org/abs/2403.14253) | 介绍了针对间接情感表达的韩国常识知识图谱K-Act2Emo，通过实验验证其在训练情感推断模型方面的有效性，微调后的BART知识模型表现优异，达到了与GPT-4 Turbo相媲美的性能水平。 |
| [^154] | [C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion](https://arxiv.org/abs/2403.14119) | 本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。 |
| [^155] | [Extracting Emotion Phrases from Tweets using BART](https://arxiv.org/abs/2403.14050) | 本文提出了一种基于BART的情感分析方法，利用问答框架从文本中提取特定情绪短语，并通过分类器预测答案跨度位置，实现对情绪短语的精确提取。 |
| [^156] | [Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts](https://arxiv.org/abs/2403.13786) | 该论文引入了“Chain-of-Interaction (CoI)”提示方法，通过二元交互情境来为精神决策支持上下文化大型语言模型(LLMs)，以解决精神治疗中缺乏领域专业知识和忽视患者-治疗师交互的挑战。 |
| [^157] | [EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation](https://arxiv.org/abs/2403.13737) | EthioLLM为埃塞俄比亚五种语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）以及英语引入了多语言大型语言模型，并提出了一个新的基准数据集Ethiobenchmark，为各种下游自然语言处理任务评估了这些模型的性能。 |
| [^158] | [From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models](https://arxiv.org/abs/2403.12027) | 近年来，随着大型基础模型的兴起，自动图表理解取得了显著进展，本调查论文概述了在这些基础模型背景下图表理解领域的最新发展、挑战和未来方向 |
| [^159] | [Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models](https://arxiv.org/abs/2403.11838) | 引入Guide-Align，一种两阶段方法，通过安全训练模型识别潜在风险，并制定特定指南，从而建立全面的指导库，用于指导LLMs生成安全和高质量输出。 |
| [^160] | [Counting-Stars: A Simple, Efficient, and Reasonable Strategy for Evaluating Long-Context Large Language Models](https://arxiv.org/abs/2403.11802) | 提出了一种名为Counting-Stars的简单、高效、合理策略，用于评估长上下文大型语言模型的能力，并在实验中发现GPT-4 Turbo和Kimi Chat在此任务上取得显著性能。 |
| [^161] | [Revisiting The Classics: A Study on Identifying and Rectifying Gender Stereotypes in Rhymes and Poems](https://arxiv.org/abs/2403.11752) | 该研究通过收集韵律诗和诗歌数据集，建立了一个准确率为97%的模型，用于识别性别偏见，并通过大型语言模型纠正了性别刻板印象。 |
| [^162] | [Mixture-of-Prompt-Experts for Multi-modal Semantic Understanding](https://arxiv.org/abs/2403.11311) | 提出了一种新型多模态软提示框架MoPE-BAF，用于解决少样本学习下的多模态讽刺检测和情感分析问题，通过三个软提示专家和块感知提示融合，实现了模态特征提取和多模态交互。 |
| [^163] | [Pointer-Generator Networks for Low-Resource Machine Translation: Don't Copy That!](https://arxiv.org/abs/2403.10963) | Pointer-Generator Networks在低资源机器翻译中未展现出预期的优势，模型在不同资源范围和语言之间的关系下表现一般。 |
| [^164] | [Multi-party Response Generation with Relation Disentanglement](https://arxiv.org/abs/2403.10827) | 本研究提出了一种利用关系解缠来指导神经响应生成的方法，通过在会话上下文内部微妙线索上进行关系推断，实现了对多方回复的自动推断，无需人工标签。 |
| [^165] | [Knowledge Graph Large Language Model (KG-LLM) for Link Prediction](https://arxiv.org/abs/2403.07311) | 该论文提出了知识图谱大型语言模型框架（KG-LLM），利用思维链提示和上下文学习等NLP范例，以增强知识图谱中的多跳链接预测，并展示了框架在微调大型语言模型和零次尝试能力方面的有效性。 |
| [^166] | [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models](https://arxiv.org/abs/2403.06764) | FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。 |
| [^167] | [Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning](https://arxiv.org/abs/2403.06725) | 本文提出了名为LoReKT的低资源知识追踪框架，通过监督预训练和微调重要性机制，旨在从丰富资源的KT数据集中学习可转移的参数和表示来改进低资源知识追踪任务。 |
| [^168] | [A Comprehensive Overhaul of Multimodal Assistant with Small Language Models](https://arxiv.org/abs/2403.06199) | 通过设计多模态小语言模型(MSLMs)及提出高效多模态助手Mipha，实现了在多个方面的协同作用，击败了大语言模型，为开发强大MSLMs提供了见解和指南 |
| [^169] | [Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models](https://arxiv.org/abs/2403.04786) | 本文通过全面调查各种攻击形式，探讨了大型语言模型受攻击的性质、机制、潜在影响以及当前防御策略，为模型完整性和用户信任提供了重要见解。 |
| [^170] | [From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge Prediction](https://arxiv.org/abs/2403.04369) | 引入领域知识的从图到词袋方法，帮助预测混淆罪名，通过构成要素和关键词选择进行判断。 |
| [^171] | [A Second Look on BASS -- Boosting Abstractive Summarization with Unified Semantic Graphs -- A Replication Study](https://arxiv.org/abs/2403.02930) | 通过复制研究BASS框架，发现了与原始工作相比性能上的差异，并强调了撰写可复制论文的关键实践。 |
| [^172] | [InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents](https://arxiv.org/abs/2403.02691) | 本研究引入了InjecAgent基准测试，用于评估工具集成的大型语言模型代理对间接提示注入攻击的脆弱性，通过评估30种LLM代理，发现这些代理存在漏洞 |
| [^173] | [Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation](https://arxiv.org/abs/2403.01479) | "本文提出了“Align-to-Distill”（A2D）策略，通过在训练过程中自适应地对齐学生注意力头与其教师对应物，转化了组合映射启发式方法为学习问题，实验结果显示A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。" |
| [^174] | [SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation](https://arxiv.org/abs/2403.00046) | SEED提出了一种名为Sample-Efficient adaptation with Error-Driven learning的新颖适应方法，利用LLMs产生的错误作为学习机会，从而实现对代码生成任务的高效学习。 |
| [^175] | [Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers](https://arxiv.org/abs/2402.17914) | 通过可解释的方言分类器提取方言的词汇特征，成功识别了有助于方言变化的关键语言特定词汇特征。 |
| [^176] | [HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization](https://arxiv.org/abs/2402.16694) | HumanEval-XL 是一个面向跨语言自然语言泛化的多语言代码生成基准，建立23种自然语言和12种编程语言的联系，提供了全面的评估平台，弥补了多语言LLM评估的重要空白。 |
| [^177] | [Chitchat as Interference: Adding User Backstories to Task-Oriented Dialogues](https://arxiv.org/abs/2402.15248) | 通过使用少样本提示和Llama-2-70B增强MultiWOZ数据集，引入用户背景故事，有效解决面向任务的对话中的闲聊干扰问题，并能够同时承认用户背景故事并推动任务的进行。 |
| [^178] | [Multilingual Coreference Resolution in Low-resource South Asian Languages](https://arxiv.org/abs/2402.13571) | 引入了一个用于31种南亚语言的多语言共指解析翻译数据集，通过利用现成工具进行训练和对齐，在低资源条件下实现了较好的共指解析模型性能提升。 |
| [^179] | [LongHeads: Multi-Head Attention is Secretly a Long Context Processor](https://arxiv.org/abs/2402.10685) | LongHeads 提出了一个无需训练的框架，通过释放多头注意力的潜力来增强大型语言模型(LLM)处理长上下文的能力。 |
| [^180] | [OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models](https://arxiv.org/abs/2402.10670) | 本研究提出了一种名为OpenFMNav的框架，通过大型语言模型和视觉语言模型解决了目标导航领域中关于理解自然语言指令和零样本泛化的问题。 |
| [^181] | [Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies](https://arxiv.org/abs/2402.09282) | 该论文介绍了一种利用大型语言模型和优化训练策略提高NLP任务性能的新方法，通过知识蒸馏和采用细思连想提示技术，将GPT-4中提炼的知识应用于BERT模型，在命名实体识别任务上取得了显著的性能提升，并为资源有限或封闭网络环境提供了一种成本效益的解决方案。 |
| [^182] | [Tandem Transformers for Inference Efficient LLMs](https://arxiv.org/abs/2402.08644) | 该论文提出了一种新的架构，称为串联Transformer，用于解决传统大型语言模型推断速度限制的问题。该架构通过将小型自回归模型和大模型以块模式结合起来，并让小模型关注大模型的丰富表示，从而显著提高了小模型的预测准确性。实验证明，在预训练数据集上，串联的PaLM2-Bison和PaLM2-Gecko相比独立的PaLM2-Gecko，在下一个词元预测准确性上提高了3.3%，并且相较于具有相似下游任务的PaLM2-Otter模型，加速比达到1.16倍。 |
| [^183] | [Large Language Models for Mathematical Reasoning: Progresses and Challenges](https://arxiv.org/abs/2402.00157) | 大型语言模型(LLMs)在解决数学问题方面涉及了大量的数学问题类型和不同的数据集和设置。目前仍然存在一些挑战，需要进一步研究和解决。 |
| [^184] | [LOCOST: State-Space Models for Long Document Abstractive Summarization](https://arxiv.org/abs/2401.17919) | LOCOST是一种基于状态空间模型的编码器-解码器架构，用于处理长文档的抽象摘要生成。与基于稀疏注意模式的最先进模型相比，LOCOST具有更低的计算复杂度，并且能够在训练和推断期间节省大量内存。在评估中，LOCOST在长文档摘要化任务上达到了93-96%的性能水平，并且能够处理超过600K个标记的输入文本。 |
| [^185] | [PILOT: Legal Case Outcome Prediction with Case Law](https://arxiv.org/abs/2401.15770) | 提出了新的PILOT框架，旨在解决使用案例法预测法律案例结果的挑战，包括相关案例检索和时间模式处理两个模块。 |
| [^186] | [With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation](https://arxiv.org/abs/2401.11504) | Temp-Lora方法通过在长文本生成过程中逐步训练临时Lora模块，有效保留上下文知识并避免对模型参数的永久性改变。 |
| [^187] | [BaRDa: A Belief and Reasoning Dataset that Separates Factual Accuracy and Reasoning Ability](https://arxiv.org/abs/2312.07527) | BaRDa数据集通过使用人类注释的蕴涵树，混合真实和虚假事实，并包括反事实例子，成功区分了事实准确性和推理能力。 |
| [^188] | [Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models](https://arxiv.org/abs/2311.11202) | 本研究专注于真实世界数据集的可信度，提出了一个系统化框架，用于评估数据集的可信度，识别标签错误，并评估嘈杂标签对不安全评论和对话分类的影响，以提高训练无害语言模型的质量。 |
| [^189] | [Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models](https://arxiv.org/abs/2311.09214) | 本研究提出了一种从大型语言模型中提取自我评估能力和综合思维的方法，旨在解决小语言模型继承不完善推理和幻觉的问题。 |
| [^190] | [Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark](https://arxiv.org/abs/2311.09122) | UNER是一个开放的、社区驱动的项目，旨在提供高质量、跨语言一致的命名实体识别基准，以促进和标准化多语言NER研究。 |
| [^191] | [OFA: A Framework of Initializing Unseen Subword Embeddings for Efficient Large-scale Multilingual Continued Pretraining](https://arxiv.org/abs/2311.08849) | OFA框架通过智能初始化未见子词的嵌入，结合外部多语言静态词向量和矩阵分解，有效实现多语言适应并大幅减少模型嵌入参数数量 |
| [^192] | [A Survey of Confidence Estimation and Calibration in Large Language Models](https://arxiv.org/abs/2311.08298) | 大型语言模型中置信度估计与校准的调研总结了挑战、技术进展、应用和未来方向。 |
| [^193] | [A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning](https://arxiv.org/abs/2311.07954) | 本文研究了大型语言模型在逻辑推理中的自我验证能力，特别关注它们准确识别逻辑谬误的能力。 |
| [^194] | [UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web](https://arxiv.org/abs/2310.18340) | 本文介绍了第一个将文本模态融入城市图像描述的LLM增强框架UrbanCLIP，并探讨了文本模态如何增强城市区域描述以及其影响方面。 |
| [^195] | [MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning](https://arxiv.org/abs/2310.16049) | MuSR引入了一个用于评估语言模型在自然语言叙事中进行多步软推理任务的数据集，通过新颖的神经符号综合到自然语言生成算法创建复杂推理实例，挑战了目前的语言模型能力，并且可以随着模型能力的增强进行进一步扩展。 |
| [^196] | [HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models](https://arxiv.org/abs/2310.14566) | HallusionBench是一个专为评估大型视觉语言模型在图像背景推理中面临挑战的基准，通过引入新颖结构和量化分析，显示出GPT-4V取得了31.42%的准确率，远高于其他模型。 |
| [^197] | [RTSUM: Relation Triple-based Interpretable Summarization with Multi-level Salience Visualization](https://arxiv.org/abs/2310.13895) | 提出了RTSUM框架，利用关系三元组进行摘要生成，并开发了一个可解释的摘要工具，支持多级显著性可视化。 |
| [^198] | [Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes](https://arxiv.org/abs/2310.10648) | 通过使用决策模型Bridge，结合专家的认知任务分析，成功利用大型语言模型（LLMs）来弥补新手和专家在纠正数学错误中的知识差距。 |
| [^199] | [Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model](https://arxiv.org/abs/2310.06707) | 提出了一种质量感知翻译模型，通过训练NMT模型来估计其输出质量，可以在解码过程中消除额外的计算成本。 |
| [^200] | [A Meta-Learning Perspective on Transformers for Causal Language Modeling](https://arxiv.org/abs/2310.05884) | 本文从元学习视角探讨了Transformer用于因果语言建模时的内部优化过程，发现并分析了Transformer-based因果语言模型中学习到的token表示范数的特殊特征。 |
| [^201] | [Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic](https://arxiv.org/abs/2309.13339) | 提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。 |
| [^202] | [Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles](https://arxiv.org/abs/2309.09369) | 本文提出了一个新任务，即总结在多篇新闻文章中遇到的多样信息，涵盖了相同事件，构建了一个名为DiverseSumm的数据集，并对使用大型语言模型（LLM）衡量摘要覆盖范围和忠实度的方法进行了全面分析。 |
| [^203] | [Large Language Models for Generative Recommendation: A Survey and Visionary Discussions](https://arxiv.org/abs/2309.01157) | 大型语言模型为推荐系统的生成式推荐提供了新机遇，可以简化推荐流程并直接从完整的项目池中生成推荐。 |
| [^204] | [Situated Natural Language Explanations](https://arxiv.org/abs/2308.14115) | 提出了一种坐标自然语言解释的替代性视角，通过建立自动化评估分数和采用三种提示工程技术，为生成和评估解释提供了新的研究途径。 |
| [^205] | [Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting Jailbreaks](https://arxiv.org/abs/2305.14965) | 该论文提出了正式化和已知越狱分类法以填补对商用大规模语言模型（LLMs）被越狱攻击的缺乏研究，调查现有的越狱方法及其在开源和商用LLMs上的有效性。 |
| [^206] | [Benchmarking LLM-based Machine Translation on Cultural Awareness](https://arxiv.org/abs/2305.14328) | 介绍了一个新的数据整理流程来构建文化相关的平行语料库，并设计了一种新的评估指标，通过GPT-4无参考评估翻译的可理解性。 |
| [^207] | [When your Cousin has the Right Connections: Unsupervised Bilingual Lexicon Induction for Related Data-Imbalanced Languages](https://arxiv.org/abs/2305.14012) | 提出了一种新的非监督双语词表诱导方法，可以在相关低资源语言和高资源语言之间进行词表诱导，只需要对高资源语言的掩码语言模型进行推断。 |
| [^208] | [LLM Paternity Test: Generated Text Detection with LLM Genetic Inheritance](https://arxiv.org/abs/2305.12519) | LLM-Pat提出了一种基于模型的生成文本检测方法，通过重建并比较候选文本与其对应的“兄弟”文本的相似性，从而判断候选文本是否由机器生成。 |
| [^209] | [Spacerini: Plug-and-play Search Engines with Pyserini and Hugging Face](https://arxiv.org/abs/2302.14534) | Spacerini是一个集成了Pyserini和Hugging Face的工具，可以无缝构建和部署交互式搜索引擎，使得非IR从业者可以更轻松地使用最先进的检索模型，对NLP和IR研究人员以及第三方复制研究工作都非常有用。 |
| [^210] | [Knowledge-augmented Graph Neural Networks with Concept-aware Attention for Adverse Drug Event Detection](https://arxiv.org/abs/2301.10451) | 本研究提出了一种具有概念感知注意力的知识增强图神经网络，用于不良药物事件检测，通过将医学知识和文本图相结合，实现了不同类型节点的特征学习。 |
| [^211] | [Dissociating language and thought in large language models](https://arxiv.org/abs/2301.06627) | 大型语言模型在形式语言能力方面表现出色，但在功能语言能力任务上表现不稳定，可能需要专门的调整和外部模块的支持。 |
| [^212] | [Learning with Silver Standard Data for Zero-shot Relation Extraction](https://arxiv.org/abs/2211.13883) | 提出了使用银标准数据进行零-shot关系提取学习的方法，并引入了一个基于类别的清洁数据检测模块。 |
| [^213] | [A Bayesian Multilingual Document Model for Zero-shot Topic Identification and Discovery](https://arxiv.org/abs/2007.01359) | 提出了一种贝叶斯多语言文档模型，通过学习文档嵌入的高斯分布形式来编码不确定性，利用学到的不确定性进行零样本跨语言主题识别，在17种不同语言上进行了实验证实该模型在不同资源语言上表现出色 |
| [^214] | [In-context Learning with Retrieved Demonstrations for Language Models: A Survey.](http://arxiv.org/abs/2401.11624) | 本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。 |
| [^215] | [Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models.](http://arxiv.org/abs/2401.10647) | 本文研究了通过编辑语言模型的复杂后果，发现在增强模型准确性与保持道德完整性之间存在悖论。我们发现，尽管注入准确信息对模型的可靠性很重要，但它可能破坏模型的基本框架，导致不可预测和潜在的不安全行为。 |
| [^216] | [Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers.](http://arxiv.org/abs/2401.06461) | 本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。 |
| [^217] | [Do Vision and Language Encoders Represent the World Similarly?.](http://arxiv.org/abs/2401.05224) | 通过分析视觉和语言模型的潜在空间结构，发现未对齐和对齐的编码器的表示空间在语义上是相似的。我们提出了两种方法来匹配未对齐编码器，无需训练即可实现匹配。 |
| [^218] | [VQPy: An Object-Oriented Approach to Modern Video Analytics.](http://arxiv.org/abs/2311.01623) | VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。 |
| [^219] | [CLEX: Continuous Length Extrapolation for Large Language Models.](http://arxiv.org/abs/2310.16450) | CLEX是一种针对大型语言模型的持续长度外推方法，通过将位置嵌入缩放方法推广到连续动态建模，克服了当前方法在特定长度上的局限性。 |
| [^220] | [SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents.](http://arxiv.org/abs/2310.11667) | SOTOPIA是一个用于评估语言智能中的社交智能的交互式环境。通过模拟复杂的社交互动，并使用全面的评估框架，我们发现不同模型之间的社交智能存在显著差异，特别是在SOTOPIA-hard情景下。GPT-4在这个子集上的目标完成率较低。 |
| [^221] | [KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models.](http://arxiv.org/abs/2310.09725) | KGQuiz是一个知识密集型基准测试，通过涵盖三个知识领域和五个任务，全面评估了大型语言模型(LLMs)的知识泛化能力。 |
| [^222] | [SEA: Sparse Linear Attention with Estimated Attention Mask.](http://arxiv.org/abs/2310.01777) | 提出了SEA方法，可以通过估计注意力掩码实现线性复杂度的稀疏注意力，解决了transformer处理长序列时注意力操作复杂度高的问题，并保持了可解释性。 |
| [^223] | [Effective Distillation of Table-based Reasoning Ability from LLMs.](http://arxiv.org/abs/2309.13182) | 本论文提出了一种从LLMs中提取基于表格推理能力的方法，通过蒸馏将大型模型转化为专门用于基于表格推理任务的小型模型，并取得了良好的性能。 |
| [^224] | [On the Relationship between Skill Neurons and Robustness in Prompt Tuning.](http://arxiv.org/abs/2309.12263) | 本文研究了Prompt Tuning在与"技能神经元"的关系中的鲁棒性，发现特定任务的调整指令在相同类型的任务上具有传递性，但对于对抗性数据的鲁棒性不高，其中T5的鲁棒性比RoBERTa更高，并且发现T5和RoBERTa中都存在技能神经元。 |
| [^225] | [Examining the Limitations of Computational Rumor Detection Models Trained on Static Datasets.](http://arxiv.org/abs/2309.11576) | 本文通过深入评估基于内容和基于上下文模型在检测新的未知谣言上的性能差距，发现基于上下文的模型过度依赖来源帖子信息并忽略了上下文信息的重要作用。实验结果也提出了减小时间概念影响的实际建议。 |
| [^226] | [K-pop Lyric Translation: Dataset, Analysis, and Neural-Modelling.](http://arxiv.org/abs/2309.11093) | 研究者介绍了一种新颖的K-pop歌词翻译数据集，该数据集揭示了K-pop歌词翻译的独特特征，并构建了一个神经歌词翻译模型，强调了专用数据集的重要性。 |
| [^227] | [HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking.](http://arxiv.org/abs/2309.08503) | 本文介绍了一份新的健康声明数据集，其中包含了750个由医学专家标注的健康相关声明，并提供了来自临床研究的证据支持。该数据集可用于机器学习任务，包括证据检索、真实性预测和解释生成。 |
| [^228] | [ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation Following the Metaphor Identification Procedure.](http://arxiv.org/abs/2309.03103) | ContrastWSD是一种使用了词义消岐的隐喻检测模型，通过将隐喻识别过程和词义消岐结合起来，提取并对比单词的上下文含义和基本含义，以提高隐喻检测的效果，超过其他仅依赖上下文嵌入或集成基本定义和外部知识的方法。 |
| [^229] | [Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes.](http://arxiv.org/abs/2308.11585) | 本篇论文探讨了因果交叉性和双重梯度下降在多模态分析中的应用，以仇恨迷因检测为例。通过结合因果分析和基于梯度的方法，研究发现模型的内部机制可以揭示其因果效应，并介绍了交叉性和模态的梯度注意力的摘要化方法。 |
| [^230] | [A Survey on Large Language Model based Autonomous Agents.](http://arxiv.org/abs/2308.11432) | 该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。 |
| [^231] | [To share or not to share: What risks would laypeople accept to give sensitive data to differentially-private NLP systems?.](http://arxiv.org/abs/2307.06708) | 这项研究旨在探索普通人在面临隐私威胁情境时的决策行为，以及他们愿意为给予差分隐私的自然语言处理系统提供敏感数据所承担的风险。 |
| [^232] | [ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection.](http://arxiv.org/abs/2307.02591) | 这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。 |
| [^233] | [ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems.](http://arxiv.org/abs/2306.04357) | 本研究提出了一种针对对话响应选择的后训练技术Dial-MAE，利用生成方法更好地压缩对话语义至密集向量，并提高对话响应选择准确性。 |
| [^234] | [A Study on the Reliability of Automatic Dysarthric Speech Assessments.](http://arxiv.org/abs/2306.04337) | 本研究旨在通过添加和减少噪声，以一种更可解释的方式，可视化和比较特征提取器和模型，更清楚地了解自动发音障碍评估的模式，并为建立可靠的自动发音障碍评估系统提供了认识和建议。 |
| [^235] | [PLANNER: Generating Diversified Paragraph via Latent Language Diffusion Model.](http://arxiv.org/abs/2306.02531) | 本文提出了PLANNER模型，它通过将自回归生成和潜在语义扩散相结合，以在生成文本时在段落级别实现全局控制，生成流畅的文本。 |
| [^236] | [Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.](http://arxiv.org/abs/2305.16582) | 通过将人类思维过程建模成图形结构，我们提出了“思维图”（GoT）推理辅助大语言模型（LLMs）来完成更加真实的、复杂的思维任务。 |
| [^237] | [Navigating Prompt Complexity for Zero-Shot Classification: A Study of Large Language Models in Computational Social Science.](http://arxiv.org/abs/2305.14310) | 本研究通过评估两个大型语言模型在六个计算社会科学分类任务中的零样本性能，并研究了各种提示策略的影响。结果显示，当前的大型语言模型在零样本设置下无法与较小的微调基线模型相媲美。 |
| [^238] | [a unified front-end framework for english text-to-speech synthesis.](http://arxiv.org/abs/2305.10666) | 该论文提出了一个统一的前端框架，捕捉了英文语音合成前端模块之间的依赖关系，并且在所有模块中均取得了最先进的性能。 |
| [^239] | [Examining Temporalities on Stance Detection Towards COVID-19 Vaccination.](http://arxiv.org/abs/2304.04806) | 研究考虑了时间性对COVID-19疫苗态度检测的影响，发现时间分割显著降低了立场分类的准确性。 |
| [^240] | [PWESuite: Phonetic Word Embeddings and Tasks They Facilitate.](http://arxiv.org/abs/2304.02541) | 本论文展示了一套语音单词嵌入及其相关任务，提高了语音信息处理的效果和可重复性。 |
| [^241] | [Little Red Riding Hood Goes Around the Globe:Crosslingual Story Planning and Generation with Large Language Models.](http://arxiv.org/abs/2212.10471) | 本论文提出了一个新的跨语言故事生成任务，并利用大型预训练语言模型研究不同的故事规划。结果表明将故事分为三幕可以带来更一致和有趣的叙述，同时允许明确控制其内容和结构。 |

# 详细

[^1]: 语言校正流：通过概率流推动扩散语言生成

    Language Rectified Flow: Advancing Diffusion Language Generation with Probabilistic Flows

    [https://arxiv.org/abs/2403.16995](https://arxiv.org/abs/2403.16995)

    语言校正流是一种基于标准概率流模型的新方法，通过学习常微分方程模型在源分布和目标分布之间传输，提供了统一和有效的生成模型和领域转移解决方案。

    

    最近的研究表明，在扩散语言模型基础上控制句子属性（例如情感）和结构（例如句法结构）取得了成功。一个推动高质量样本生成的关键组成部分是迭代去噪数千步。尽管有益，但从噪声开始的复杂性和学习步骤限制了其在许多NLP实际应用中的实现。本文提出了Language Rectified Flow方法。我们的方法基于标准概率流模型的重构。语言校正流学习（神经）常微分方程模型在源分布和目标分布之间传输，为生成建模和域转移提供了统一和有效的解决方案。从源分布开始，我们的语言校正流产生快速仿真和有效。

    arXiv:2403.16995v1 Announce Type: cross  Abstract: Recent works have demonstrated success in controlling sentence attributes ($e.g.$, sentiment) and structure ($e.g.$, syntactic structure) based on the diffusion language model. A key component that drives theimpressive performance for generating high-quality samples from noise is iteratively denoise for thousands of steps. While beneficial, the complexity of starting from the noise and the learning steps has limited its implementation to many NLP real-world applications. This paper proposes Language Rectified Flow ({\ours}). Our method is based on the reformulation of the standard probabilistic flow models. Language rectified flow learns (neural) ordinary differential equation models to transport between the source distribution and the target distribution, hence providing a unified and effective solution to generative modeling and domain transfer. From the source distribution, our language rectified flow yields fast simulation and effe
    
[^2]: 用多方面概念嵌入模型建模常识共性

    Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings

    [https://arxiv.org/abs/2403.16984](https://arxiv.org/abs/2403.16984)

    本文通过明确建模不同的感兴趣方面来改进概念嵌入，使其能够捕捉更广泛的常识属性。

    

    概念嵌入提供了一种实用且高效的机制，将常识知识注入到下游任务中。本文解决了标准嵌入主要反映基本分类类别的问题，通过在学习概念嵌入时明确建模感兴趣的不同方面，得到了能够捕捉更广泛常识属性的嵌入。

    arXiv:2403.16984v1 Announce Type: new  Abstract: Concept embeddings offer a practical and efficient mechanism for injecting commonsense knowledge into downstream tasks. Their core purpose is often not to predict the commonsense properties of concepts themselves, but rather to identify commonalities, i.e.\ sets of concepts which share some property of interest. Such commonalities are the basis for inductive generalisation, hence high-quality concept embeddings can make learning easier and more robust. Unfortunately, standard embeddings primarily reflect basic taxonomic categories, making them unsuitable for finding commonalities that refer to more specific aspects (e.g.\ the colour of objects or the materials they are made of). In this paper, we address this limitation by explicitly modelling the different facets of interest when learning concept embeddings. We show that this leads to embeddings which capture a more diverse range of commonsense properties, and consistently improves resu
    
[^3]: 人类、GPT-3.5和GPT-4在大学级编程课程中表现的比较

    A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course

    [https://arxiv.org/abs/2403.16977](https://arxiv.org/abs/2403.16977)

    本研究比较了人类、GPT-3.5和GPT-4在大学级编程课程中的表现，结果显示学生的平均得分明显高于AI提交，同时提示工程显著提高了GPT-4和GPT-3.5的得分。

    

    本研究评估了使用Python语言在大学级物理编程作业中，ChatGPT变种GPT-3.5和GPT-4的表现，包括是否进行提示工程，与仅学生作品和同时包含学生和GPT-4贡献的混合类别的对比。通过50份学生提交和50份不同类别的AI生成的提交的评比，由三名独立评分者进行盲目评分，我们总计了300个数据点。学生平均得分为91.9% (标准误:0.4)，超过了得分为81.1% (标准误:0.8)的表现最好的AI提交类别GPT-4+提示工程，这是一个显著差异 (p = $2.482 \times 10^{-10}$)。提示工程显著提高了GPT-4 (p = $1.661 \times 10^{-4}$)和GPT-3.5 (p = $4.967 \times 10^{-9}$)的得分。此外，盲目评分者被要求使用四点李克特量表猜测提交作品的作者身份。

    arXiv:2403.16977v1 Announce Type: new  Abstract: This study evaluates the performance of ChatGPT variants, GPT-3.5 and GPT-4, both with and without prompt engineering, against solely student work and a mixed category containing both student and GPT-4 contributions in university-level physics coding assignments using the Python language. Comparing 50 student submissions to 50 AI-generated submissions across different categories, and marked blindly by three independent markers, we amassed $n = 300$ data points. Students averaged 91.9% (SE:0.4), surpassing the highest performing AI submission category, GPT-4 with prompt engineering, which scored 81.1% (SE:0.8) - a statistically significant difference (p = $2.482 \times 10^{-10}$). Prompt engineering significantly improved scores for both GPT-4 (p = $1.661 \times 10^{-4}$) and GPT-3.5 (p = $4.967 \times 10^{-9}$). Additionally, the blinded markers were tasked with guessing the authorship of the submissions on a four-point Likert scale from
    
[^4]: VoiceCraft：野外零-shot语音编辑和文本到语音

    VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild

    [https://arxiv.org/abs/2403.16973](https://arxiv.org/abs/2403.16973)

    VoiceCraft是一个基于标记填充的神经编解码器语言模型，在语音编辑和零-shot文本到语音任务上表现出色，实现了在多样性数据集上的最新性能。

    

    我们介绍了VoiceCraft，一个基于标记填充的神经编解码器语言模型，实现了在有声书、互联网视频和播客上语音编辑和零-shot文本到语音（TTS）方面的最新性能。VoiceCraft采用Transformer解码器架构，并引入了一种标记重排过程，结合了因果掩码和延迟堆叠，以实现在现有序列内的生成。在语音编辑任务上，VoiceCraft生成的编辑语音在自然度方面几乎与未编辑的录音难以区分，经人类评估；对于零-shot TTS，我们的模型优于先前的最先进模型，包括VALLE和流行的商业模型XTTS-v2。关键的是，这些模型在具有多样口音、语音风格、录制条件、背景噪音和音乐的具有挑战性和真实性的数据集上进行了评估，我们的模型与其他模型相比表现始终良好。

    arXiv:2403.16973v1 Announce Type: cross  Abstract: We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft employs a Transformer decoder architecture and introduces a token rearrangement procedure that combines causal masking and delayed stacking to enable generation within an existing sequence. On speech editing tasks, VoiceCraft produces edited speech that is nearly indistinguishable from unedited recordings in terms of naturalness, as evaluated by humans; for zero-shot TTS, our model outperforms prior SotA models including VALLE and the popular commercial model XTTS-v2. Crucially, the models are evaluated on challenging and realistic datasets, that consist of diverse accents, speaking styles, recording conditions, and background noise and music, and our model performs consistently well compared to other models a
    
[^5]: LLM Agent Operating System

    LLM Agent Operating System

    [https://arxiv.org/abs/2403.16971](https://arxiv.org/abs/2403.16971)

    提出了一种将大型语言模型嵌入操作系统中的LLM代理操作系统，旨在优化资源分配、促进代理间上下文切换、实现并发执行以及为代理提供工具服务。

    

    arXiv:2403.16971v1 公告类型: 跨领域 摘要: 部署大型语言模型（LLM）智能代理存在诸多挑战，会损害它们的效率和功效。其中包括代理请求在LLM上的次优调度和资源分配、在代理和LLM之间交互时保持上下文的困难，以及将具有不同能力和专业化的异构代理集成在一起的复杂性。代理数量和复杂性的快速增加进一步加剧了这些问题，通常会导致资源瓶颈和次优资源利用。受到这些挑战的启发，本文提出了AIOS，一种LLM代理操作系统，它将大型语言模型嵌入操作系统（OS）中。具体地，AIOS旨在优化资源分配，促进代理之间的上下文切换，实现代理的并发执行，为代理提供工具服务。

    arXiv:2403.16971v1 Announce Type: cross  Abstract: The integration and deployment of large language model (LLM)-based intelligent agents have been fraught with challenges that compromise their efficiency and efficacy. Among these issues are sub-optimal scheduling and resource allocation of agent requests over the LLM, the difficulties in maintaining context during interactions between agent and LLM, and the complexities inherent in integrating heterogeneous agents with different capabilities and specializations. The rapid increase of agent quantity and complexity further exacerbates these issues, often leading to bottlenecks and sub-optimal utilization of resources. Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS). Specifically, AIOS is designed to optimize resource allocation, facilitate context switch across agents, enable concurrent execution of agents, provide tool service for agents
    
[^6]: 评估用于上下文词形还原的最短编辑脚本方法

    Evaluating Shortest Edit Script Methods for Contextual Lemmatization

    [https://arxiv.org/abs/2403.16968](https://arxiv.org/abs/2403.16968)

    本文评估了用于上下文词形还原的最短编辑脚本方法，通过将词形还原视为令牌分类任务，仅修改需要学习的SES标签，客观得出最佳的词形还原结果。

    

    现代上下文词形还原器通常依赖于自动诱导的最短编辑脚本（SES），即转换单词形式为其词元所需的编辑操作次数。事实上，已经提出了不同的计算SES方法作为几种当前可用的最先进的上下文词形还原器架构的一个组成部分。然而，以往的研究未考察SES在最终词形还原性能中的直接影响。本文通过将词形还原视为一个令牌分类任务来解决这个问题，模型仅接收上下文中的词-标签对作为输入，其中标签对应于先前诱导的SES。因此，通过仅修改模型需要学习的SES标签，我们可以客观地得出哪种SES表示产生最佳的词形还原结果。我们在使用不同形态的七种语言进行实验。

    arXiv:2403.16968v1 Announce Type: new  Abstract: Modern contextual lemmatizers often rely on automatically induced Shortest Edit Scripts (SES), namely, the number of edit operations to transform a word form into its lemma. In fact, different methods of computing SES have been proposed as an integral component in the architecture of several state-of-the-art contextual lemmatizers currently available. However, previous work has not investigated the direct impact of SES in the final lemmatization performance. In this paper we address this issue by focusing on lemmatization as a token classification task where the only input that the model receives is the word-label pairs in context, where the labels correspond to previously induced SES. Thus, by modifying in our lemmatization system only the SES labels that the model needs to learn, we may then objectively conclude which SES representation produces the best lemmatization results. We experiment with seven languages of different morphologic
    
[^7]: 数据混合规律：通过预测语言建模性能来优化数据混合

    Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance

    [https://arxiv.org/abs/2403.16952](https://arxiv.org/abs/2403.16952)

    该研究发现了数据混合规律，可以量化地预测模型性能与数据混合比例之间的关系，并提出了一种方法来通过拟合函数形式来引导理想的数据混合选择，从而优化大型语言模型的训练混合。

    

    大型语言模型的预训练数据包括多个领域（例如网络文本、学术论文、代码），其混合比例对结果模型的能力至关重要。现有的工作通常依赖于启发式方法或定性策略来调整比例，我们发现了模型性能与混合比例之间的函数形式的定量可预测性，我们称之为数据混合规律。在样本混合上拟合这种函数揭示了未见混合的模型性能，从而引导选择理想的数据混合。此外，我们提出了训练步骤、模型大小和我们的数据混合规律的缩放规律的嵌套使用，以使得仅通过小规模训练就能够预测在各种混合数据下训练的大模型的性能。此外，实验结果验证了我们的方法有效地优化了训练混合。

    arXiv:2403.16952v1 Announce Type: cross  Abstract: Pretraining data of large language models composes multiple domains (e.g., web texts, academic papers, codes), whose mixture proportions crucially impact the competence of outcome models. While existing endeavors rely on heuristics or qualitative strategies to tune the proportions, we discover the quantitative predictability of model performance regarding the mixture proportions in function forms, which we refer to as the data mixing laws. Fitting such functions on sample mixtures unveils model performance on unseen mixtures before actual runs, thus guiding the selection of an ideal data mixture. Furthermore, we propose nested use of the scaling laws of training steps, model sizes, and our data mixing law to enable predicting the performance of large models trained on massive data under various mixtures with only small-scale training. Moreover, experimental results verify that our method effectively optimizes the training mixture of a 
    
[^8]: 与人类判断相一致：大型语言模型评估中成对偏好的作用

    Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators

    [https://arxiv.org/abs/2403.16950](https://arxiv.org/abs/2403.16950)

    在大型语言模型评估中，通过引入成对偏好搜索方法PAIRS，成功解决了LLMs与人类判断不一致的问题，并取得了优于直接打分的最先进性能。

    

    大型语言模型（LLMs）作为自动评估器在评估生成的自然语言质量方面表现出有希望的能力。然而，LLMs在评估中仍存在偏见，常常难以生成与人类评估一致的连贯评估。在这项工作中，我们首先对LLM评估器与人类判断之间的不一致进行系统研究，揭示现有旨在减轻偏见的校准方法不足以有效将LLM评估器对齐。受到RLHF中对偏好数据的使用的启发，我们将评估形式化为一个排序问题，并引入Pairwise-preference Search（PAIRS），这是一种以LLMs进行成对比较并有效对候选文本进行排序的基于不确定性引导的搜索方法。PAIRS在代表性评估任务上实现了最先进的性能，并且显示出比直接打分有显著改进。

    arXiv:2403.16950v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated promising capabilities as automatic evaluators in assessing the quality of generated natural language. However, LLMs still exhibit biases in evaluation and often struggle to generate coherent evaluations that align with human assessments. In this work, we first conduct a systematic study of the misalignment between LLM evaluators and human judgement, revealing that existing calibration methods aimed at mitigating biases are insufficient for effectively aligning LLM evaluators. Inspired by the use of preference data in RLHF, we formulate the evaluation as a ranking problem and introduce Pairwise-preference Search (PAIRS), an uncertainty-guided search method that employs LLMs to conduct pairwise comparisons and efficiently ranks candidate texts. PAIRS achieves state-of-the-art performance on representative evaluation tasks and demonstrates significant improvements over direct scoring. Furthe
    
[^9]: SPACE-IDEAS：用于空间创新中显著信息检测的数据集

    SPACE-IDEAS: A Dataset for Salient Information Detection in Space Innovation

    [https://arxiv.org/abs/2403.16941](https://arxiv.org/abs/2403.16941)

    这项研究介绍了SPACE-IDEAS数据集，用于检测与空间创新相关的显著信息，包括多种文本风格，并展示了如何通过多任务学习训练更好的分类器。

    

    arXiv:2403.16941v1 公告类型：跨领域 摘要：利用自然语言处理在文本中检测显著部分已被广泛应用以缓解信息过载的影响。然而，目前可用于此任务的数据集主要源自学术出版物。我们介绍了SPACE-IDEAS，这是一个用于从与空间领域相关的创新理念中检测显著信息的数据集。SPACE-IDEAS中的文本风格多样，包括非正式、技术、学术和商业写作风格。除了手动注释的数据集外，我们还发布了一个使用大型生成语言模型注释的扩展版本。我们训练了不同的句子和序列句分类器，并表明自动注释的数据集可以通过多任务学习来训练更好的分类器。

    arXiv:2403.16941v1 Announce Type: cross  Abstract: Detecting salient parts in text using natural language processing has been widely used to mitigate the effects of information overflow. Nevertheless, most of the datasets available for this task are derived mainly from academic publications. We introduce SPACE-IDEAS, a dataset for salient information detection from innovation ideas related to the Space domain. The text in SPACE-IDEAS varies greatly and includes informal, technical, academic and business-oriented writing styles. In addition to a manually annotated dataset we release an extended version that is annotated using a large generative language model. We train different sentence and sequential sentence classifiers, and show that the automatically annotated dataset can be leveraged using multitask learning to train better classifiers.
    
[^10]: 利用预训练语言模型进行粗调优的专题文档检索

    Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models

    [https://arxiv.org/abs/2403.16915](https://arxiv.org/abs/2403.16915)

    本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调，在专题文档检索中显著改善了效果。

    

    在信息检索系统中，利用预训练语言模型（PLM-based IR）进行微调需要学习查询表示和查询-文档关系，除了下游任务特定的学习。本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调。通过在粗调优学习查询表示和查询-文档关系，我们旨在减少微调的负担，提高下游IR任务的学习效果。我们提出了用于粗调优的查询-文档对预测（QDPP），其预测查询-文档对的适当性。评估实验显示，所提出的方法显著改善了四个专题文档检索数据集中的MRR和/或nDCG@5。此外，查询预测任务的结果表明，粗调优促进了查询表示和查询-文档关系的学习。

    arXiv:2403.16915v1 Announce Type: cross  Abstract: Fine-tuning in information retrieval systems using pre-trained language models (PLM-based IR) requires learning query representations and query-document relations, in addition to downstream task-specific learning. This study introduces coarse-tuning as an intermediate learning stage that bridges pre-training and fine-tuning. By learning query representations and query-document relations in coarse-tuning, we aim to reduce the load of fine-tuning and improve the learning effect of downstream IR tasks. We propose Query-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the appropriateness of query-document pairs. Evaluation experiments show that the proposed method significantly improves MRR and/or nDCG@5 in four ad-hoc document retrieval datasets. Furthermore, the results of the query prediction task suggested that coarse-tuning facilitated learning of query representation and query-document relations.
    
[^11]: 具有吸引和分散原型的新意图发现

    New Intent Discovery with Attracting and Dispersing Prototype

    [https://arxiv.org/abs/2403.16913](https://arxiv.org/abs/2403.16913)

    提出了针对新意图发现问题的Robust and Adaptive Prototypical learning (RAP)框架，通过健壮的原型吸引学习(RPAL)和自适应的原型分散学习(APDL)方法，在已知和新的意图类别之间实现全局明显的决策边界。

    

    新意图发现旨在利用有限标记和大规模未标记数据，识别已知和推断新的意图类别。本文将任务视为特征聚类问题，并增强了实例表示。为解决现有方法无法捕捉友好聚类表示的问题，我们针对NID问题提出了一个具有全局明显决策边界的健壮且自适应的原型学习（RAP）框架，用于已知和新的意图类别。具体而言，设计了一种鲁棒的原型吸引学习（RPAL）方法，以促使实例向其对应的原型靠拢，实现更大的簇内紧凑性。为实现更大的簇间分离度，另一个自适应的原型分散学习（APDL）方法被设计为

    arXiv:2403.16913v1 Announce Type: new  Abstract: New Intent Discovery (NID) aims to recognize known and infer new intent categories with the help of limited labeled and large-scale unlabeled data. The task is addressed as a feature-clustering problem and recent studies augment instance representation. However, existing methods fail to capture cluster-friendly representations, since they show less capability to effectively control and coordinate within-cluster and between-cluster distances. Tailored to the NID problem, we propose a Robust and Adaptive Prototypical learning (RAP) framework for globally distinct decision boundaries for both known and new intent categories. Specifically, a robust prototypical attracting learning (RPAL) method is designed to compel instances to gravitate toward their corresponding prototype, achieving greater within-cluster compactness. To attain larger between-cluster separation, another adaptive prototypical dispersing learning (APDL) method is devised to
    
[^12]: 朝向算法忠实性：合成数据与人类生成数据中跨人口统计的心理健康表示

    Towards Algorithmic Fidelity: Mental Health Representation across Demographics in Synthetic vs. Human-generated Data

    [https://arxiv.org/abs/2403.16909](https://arxiv.org/abs/2403.16909)

    本研究通过使用GPT-3分析不同人口统计在合成数据中的压力因素表示，创建出包含不同人口统计群体压力因素的合成数据集，为以后使用LLMs进行数据生成研究提供了见解。

    

    合成数据生成有潜力影响应用和领域，尤其是在数据稀缺的情况下。然而，在将这些数据用于诸如心理健康这样的敏感任务之前，我们需要了解不同人口统计数据在其中的表示方式。在我们的论文中，我们通过探索GPT-3的潜力来分析生成合成数据的可能性，从而探讨其对不同种族和性别组合所产生的各种压力因素，为未来研究人员提供参考，这些研究人员正在研究使用LLMs进行数据生成。我们利用GPT-3开发了HEADROOM，这是一个包括3120篇关于导致抑郁症压力因素的合成数据集，通过控制种族、性别和时间范围（COVID-19之前和之后）。利用这个数据集，我们进行语义和词汇分析来（1）确定每个人口统计群体的主要压力因素；（2）将我们的合成数据与人类生成的数据集进行比较。我们提供了生成查询以发展依赖

    arXiv:2403.16909v1 Announce Type: new  Abstract: Synthetic data generation has the potential to impact applications and domains with scarce data. However, before such data is used for sensitive tasks such as mental health, we need an understanding of how different demographics are represented in it. In our paper, we analyze the potential of producing synthetic data using GPT-3 by exploring the various stressors it attributes to different race and gender combinations, to provide insight for future researchers looking into using LLMs for data generation. Using GPT-3, we develop HEADROOM, a synthetic dataset of 3,120 posts about depression-triggering stressors, by controlling for race, gender, and time frame (before and after COVID-19). Using this dataset, we conduct semantic and lexical analyses to (1) identify the predominant stressors for each demographic group; and (2) compare our synthetic data to a human-generated dataset. We present the procedures to generate queries to develop dep
    
[^13]: 基于状态空间模型的基础模型：一个控制理论概述

    State Space Models as Foundation Models: A Control Theoretic Overview

    [https://arxiv.org/abs/2403.16899](https://arxiv.org/abs/2403.16899)

    将状态空间模型整合到深度神经网络架构中，为控制理论家和研究人员提供了一种有效建模动态系统的新途径。

    

    近年来，将线性状态空间模型（SSM）整合到基础模型的深度神经网络架构中引起了越来越多的关注。最近Mamba的成功展示了比现有最先进的Transformer架构在语言任务中表现更好。基础模型，如GPT-4，旨在将序列数据编码为潜在空间，以学习数据的压缩表示。控制理论家使用SSM来有效地建模动态系统追求相同的目标。因此，SSM可以自然地与深度序列建模相连接，提供了在相应研究领域之间创造协同作用的机会。本文旨在向控制理论家简要介绍基于SSM的架构，并总结最新的研究进展。它系统回顾了最成功的SSM提议，并突出了它们的m

    arXiv:2403.16899v1 Announce Type: cross  Abstract: In recent years, there has been a growing interest in integrating linear state-space models (SSM) in deep neural network architectures of foundation models. This is exemplified by the recent success of Mamba, showing better performance than the state-of-the-art Transformer architectures in language tasks. Foundation models, like e.g. GPT-4, aim to encode sequential data into a latent space in order to learn a compressed representation of the data. The same goal has been pursued by control theorists using SSMs to efficiently model dynamical systems. Therefore, SSMs can be naturally connected to deep sequence modeling, offering the opportunity to create synergies between the corresponding research areas. This paper is intended as a gentle introduction to SSM-based architectures for control theorists and summarizes the latest research developments. It provides a systematic review of the most successful SSM proposals and highlights their m
    
[^14]: 口语语言自监督模型中的词汇音调编码

    Encoding of lexical tone in self-supervised models of spoken language

    [https://arxiv.org/abs/2403.16865](https://arxiv.org/abs/2403.16865)

    本文研究分析了口语语言自监督模型对声调的编码能力，使用普通话和越南语作为案例研究，并发现SLMs在训练于非音调语言数据时也保持着显著的词汇音调编码能力。

    

    解释性研究表明，自监督口语语言模型（SLMs）从声学、语音、音韵、句法和语义层面到说话者特征中编码了人类语音中的各种特征。以前关于音韵学表示的大部分研究都集中在诸如音素等部分特征上；SLMs中对音韵音系（如声调和重音模式）的编码尚未被充分理解。声调是一种存在于世界上半数以上语言中的音系特征。本文旨在分析SLMs的声调编码能力，以普通话和越南语作为案例研究。我们展示了SLMs在训练于非音调语言数据时也明显编码了词汇音调。我们进一步发现，SLMs在声调和辅音感知研究中的表现与本族和非本族的人类参与者类似，但它们不遵循相同的模式。

    arXiv:2403.16865v1 Announce Type: new  Abstract: Interpretability research has shown that self-supervised Spoken Language Models (SLMs) encode a wide variety of features in human speech from the acoustic, phonetic, phonological, syntactic and semantic levels, to speaker characteristics. The bulk of prior research on representations of phonology has focused on segmental features such as phonemes; the encoding of suprasegmental phonology (such as tone and stress patterns) in SLMs is not yet well understood. Tone is a suprasegmental feature that is present in more than half of the world's languages. This paper aims to analyze the tone encoding capabilities of SLMs, using Mandarin and Vietnamese as case studies. We show that SLMs encode lexical tone to a significant degree even when they are trained on data from non-tonal languages. We further find that SLMs behave similarly to native and non-native human participants in tone and consonant perception studies, but they do not follow the sam
    
[^15]: 一个专家价值一个代币：通过专家代币路由将多个专家LLM协同作为通用型

    An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing

    [https://arxiv.org/abs/2403.16854](https://arxiv.org/abs/2403.16854)

    通过专家代币路由将多个专家LLM协同作为通用型，可以实现多个专家LLMs的无缝集成，支持隐式专业知识的学习和动态扩展新的专家LLMs，同时更好地隐藏协作细节，展现出比现有多LLM协作范式更好的效果和稳健性。

    

    我们提出了专家代币路由（Expert-Token-Routing），这是一个统一的通用型框架，可以实现多个专家LLM的无缝集成。我们的框架将专家LLMs表示为元LLM词汇中的特殊专家代币。元LLM可以路由到专家LLM，就像生成新代币一样。专家代币路由不仅可以从现有的指导数据集中学习专家LLMs的隐式专业知识，还可以以即插即用的方式动态扩展新的专家LLMs。它还可以隐藏用户视角中的详细协作过程，促进交互就像是一个单一的LLM一样。我们的框架在涵盖六个不同专家领域的基准测试中胜过了各种现有的多LLM协作范式，展现了通过协同多个专家LLM来构建通用型LLM系统的效果和稳健性。

    arXiv:2403.16854v1 Announce Type: cross  Abstract: We present Expert-Token-Routing, a unified generalist framework that facilitates seamless integration of multiple expert LLMs. Our framework represents expert LLMs as special expert tokens within the vocabulary of a meta LLM. The meta LLM can route to an expert LLM like generating new tokens. Expert-Token-Routing not only supports learning the implicit expertise of expert LLMs from existing instruction dataset but also allows for dynamic extension of new expert LLMs in a plug-and-play manner. It also conceals the detailed collaboration process from the user's perspective, facilitating interaction as though it were a singular LLM. Our framework outperforms various existing multi-LLM collaboration paradigms across benchmarks that incorporate six diverse expert domains, demonstrating effectiveness and robustness in building generalist LLM system via synergizing multiple expert LLMs.
    
[^16]: 在法律结果预测模型中迈向可解释性

    Towards Explainability in Legal Outcome Prediction Models

    [https://arxiv.org/abs/2403.16852](https://arxiv.org/abs/2403.16852)

    先例是促进法律NLP模型可解释性的一种自然方式，我们提出了一种新颖的方法来识别法律结果预测模型使用的先例，并发现模型预测结果的能力不错，但其使用先例的方式与人类法官不同。

    

    当前的法律结果预测模型 - 法律NLP的基本组成部分 - 不能解释其推理过程。然而，为了在现实世界中应用这些模型，人类法律主体需要能够理解它们的决策。在普通法案例中，法律从业者通过参考被称为先例的过去案例法律推理到案件结果。我们认为，先例因此成为促进法律NLP模型可解释性的一种自然方式。在本文中，我们提出了一种新颖的方法来识别法律结果预测模型使用的先例。此外，通过制定法律先例的分类法，我们能够比较人类法官和我们的模型在他们依赖的不同类型先例方面的差异。我们发现，虽然模型学会了合理地预测结果，但它们使用的先例方式不同于人类法官。

    arXiv:2403.16852v1 Announce Type: cross  Abstract: Current legal outcome prediction models - a staple of legal NLP - do not explain their reasoning. However, to employ these models in the real world, human legal actors need to be able to understand their decisions. In the case of common law, legal practitioners reason towards the outcome of a case by referring to past case law, known as precedent. We contend that precedent is, therefore, a natural way of facilitating explainability for legal NLP models. In this paper, we contribute a novel method for identifying the precedent employed by legal outcome prediction models. Furthermore, by developing a taxonomy of legal precedent, we are able to compare human judges and our models with respect to the different types of precedent they rely on. We find that while the models learn to predict outcomes reasonably well, their use of precedent is unlike that of human judges.
    
[^17]: ChatGPT是否能够基于Twitter提及来预测文章的撤回？

    Can ChatGPT predict article retraction based on Twitter mentions?

    [https://arxiv.org/abs/2403.16851](https://arxiv.org/abs/2403.16851)

    本研究探讨了ChatGPT是否能够基于Twitter提及来预测文章的撤回，研究发现在预测未来被撤回的有问题文章方面是具有一定潜力的。

    

    检测有问题的研究文章具有重要意义，本研究探讨了根据被撤回文章在Twitter上的提及是否能够在文章被撤回前发出信号，从而在预测未来被撤回的有问题文章方面发挥作用。分析了包括3,505篇已撤回文章及其相关Twitter提及在内的数据集，以及使用粗糙精确匹配方法获取的具有类似特征的3,505篇未撤回文章。通过四种预测方法评估了Twitter提及在预测文章撤回方面的有效性，包括手动标注、关键词识别、机器学习模型和ChatGPT。手动标注的结果表明，的确有被撤回的文章，其Twitter提及包含在撤回前发出信号的可识别证据，尽管它们只占所有被撤回文章的一小部分。

    arXiv:2403.16851v1 Announce Type: cross  Abstract: Detecting problematic research articles timely is a vital task. This study explores whether Twitter mentions of retracted articles can signal potential problems with the articles prior to retraction, thereby playing a role in predicting future retraction of problematic articles. A dataset comprising 3,505 retracted articles and their associated Twitter mentions is analyzed, alongside 3,505 non-retracted articles with similar characteristics obtained using the Coarsened Exact Matching method. The effectiveness of Twitter mentions in predicting article retraction is evaluated by four prediction methods, including manual labelling, keyword identification, machine learning models, and ChatGPT. Manual labelling results indicate that there are indeed retracted articles with their Twitter mentions containing recognizable evidence signaling problems before retraction, although they represent only a limited share of all retracted articles with 
    
[^18]: 跨语言上下文化短语检索

    Cross-lingual Contextualized Phrase Retrieval

    [https://arxiv.org/abs/2403.16820](https://arxiv.org/abs/2403.16820)

    该研究提出了跨语言上下文化短语检索任务，并通过利用对比学习来解决多义性，从而增强了跨语言应用的性能。

    

    短语级密集检索通过利用短语提供的细粒度信息，在下游自然语言处理任务中展现出许多吸引人的特征。在我们的工作中，我们提出了一种新的密集检索任务形式，即跨语言上下文化短语检索，旨在通过使用上下文信息来增强解决多义性的跨语言应用。然而，缺乏特定的训练数据和模型是实现我们目标的主要挑战。因此，我们利用从平行句子中自动诱导的单词对齐信息提取跨语言短语对。随后，我们使用对比学习训练我们的跨语言上下文化短语检索器（CCPR），该对比学习鼓励具有相似上下文和语义的短语的隐藏表示紧密对齐。我们对跨语言短语检索任务和一个下游任务，即机器翻译，进行了全面的实验。

    arXiv:2403.16820v1 Announce Type: new  Abstract: Phrase-level dense retrieval has shown many appealing characteristics in downstream NLP tasks by leveraging the fine-grained information that phrases offer. In our work, we propose a new task formulation of dense retrieval, cross-lingual contextualized phrase retrieval, which aims to augment cross-lingual applications by addressing polysemy using context information. However, the lack of specific training data and models are the primary challenges to achieve our goal. As a result, we extract pairs of cross-lingual phrases using word alignment information automatically induced from parallel sentences. Subsequently, we train our Cross-lingual Contextualized Phrase Retriever (CCPR) using contrastive learning, which encourages the hidden representations of phrases with similar contexts and semantics to align closely. Comprehensive experiments on both the cross-lingual phrase retrieval task and a downstream task, i.e, machine translation, dem
    
[^19]: TEI2GO: 一种用于快速识别时间表达的多语言方法

    TEI2GO: A Multilingual Approach for Fast Temporal Expression Identification

    [https://arxiv.org/abs/2403.16804](https://arxiv.org/abs/2403.16804)

    本文介绍了TEI2GO模型，它在支持六种语言的同时，在其中四种语言取得了最先进的结果，并且具有显著改善的运行时间。

    

    时间表达的识别对于理解自然语言写作的文本至关重要。尽管像HeidelTime这样高效的系统存在，但它们的有限运行性能阻碍了在大规模应用和生产环境中的采用。本文介绍了TEI2GO模型，它与HeidelTime的有效性相匹配，但运行时间显著改善，在支持六种语言的同时，在其中四种语言取得了最先进的结果。为了训练TEI2GO模型，我们使用了人工注释的参考语料库的组合，并开发了一个名为“Professor HeidelTime”的综合弱标记语料库，其中包含了用HeidelTime标记的新闻文本。该语料库包含了一共138,069篇文档(跨六种语言)，共1,050,921个时间表达，是迄今为止用于时间表达识别的最大开源标注数据集。通过描述模型的产生过程，我们旨在鼓励

    arXiv:2403.16804v1 Announce Type: new  Abstract: Temporal expression identification is crucial for understanding texts written in natural language. Although highly effective systems such as HeidelTime exist, their limited runtime performance hampers adoption in large-scale applications and production environments. In this paper, we introduce the TEI2GO models, matching HeidelTime's effectiveness but with significantly improved runtime, supporting six languages, and achieving state-of-the-art results in four of them. To train the TEI2GO models, we used a combination of manually annotated reference corpus and developed ``Professor HeidelTime'', a comprehensive weakly labeled corpus of news texts annotated with HeidelTime. This corpus comprises a total of $138,069$ documents (over six languages) with $1,050,921$ temporal expressions, the largest open-source annotated dataset for temporal expression identification to date. By describing how the models were produced, we aim to encourage the
    
[^20]: 通过编译器反馈迭代改进项目级代码上下文，以获得精确的代码生成

    Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback

    [https://arxiv.org/abs/2403.16792](https://arxiv.org/abs/2403.16792)

    本论文提出了一种名为ProCoder的新颖方法，通过编译器反馈引导，迭代地改进项目级代码上下文，以获得精确的代码生成

    

    大型语言模型(LLMs)在自动代码生成方面展现出了显著的进展。然而，将基于LLM的代码生成应用到现实项目中会面临挑战，因为生成的代码可能存在API使用、类、数据结构错误或缺少项目特定信息。鉴于大部分项目特定上下文无法适应LLMs的提示，我们必须找到让模型能够探索项目级代码上下文的方法。为此，本文提出了一种名为ProCoder的新颖方法，通过编译器反馈引导，迭代地改进项目级代码上下文，以获得精确的代码生成。具体而言，ProCoder首先利用编译器技术识别生成的代码与项目上下文之间的不匹配之处。然后，通过从代码库中提取的信息迭代地对齐和修复识别出的错误。我们将ProCoder与两个代表性的LLM集成，

    arXiv:2403.16792v1 Announce Type: new  Abstract: Large language models (LLMs) have shown remarkable progress in automated code generation. Yet, incorporating LLM-based code generation into real-life software projects poses challenges, as the generated code may contain errors in API usage, class, data structure, or missing project-specific information. As much of this project-specific context cannot fit into the prompts of LLMs, we must find ways to allow the model to explore the project-level code context. To this end, this paper puts forward a novel approach, termed ProCoder, which iteratively refines the project-level code context for precise code generation, guided by the compiler feedback. In particular, ProCoder first leverages compiler techniques to identify a mismatch between the generated code and the project's context. It then iteratively aligns and fixes the identified errors using information extracted from the code repository. We integrate ProCoder with two representative L
    
[^21]: 机器翻译是否能够连接多语言预训练和跨语言迁移学习？

    Can Machine Translation Bridge Multilingual Pretraining and Cross-lingual Transfer Learning?

    [https://arxiv.org/abs/2403.16777](https://arxiv.org/abs/2403.16777)

    本文研究了机器翻译作为持续训练目标以增强语言表示学习、连接多语言预训练和跨语言应用的潜在益处，结果显示机器翻译未能增强跨语言表示学习。

    

    多语言预训练和微调在各种自然语言处理任务中取得了显著成功。将表示从一种语言转移到另一种语言对于跨语言学习尤为重要。可以期望机器翻译目标非常适合促进这种能力，因为它们涉及不同语言中语义等价句子的显式对齐。本文研究了采用机器翻译作为持续训练目标以增强语言表示学习、连接多语言预训练和跨语言应用的潜在益处。我们通过两个视角来研究这个问题：对现有模型性能的定量评估以及它们潜在表示的分析。我们的结果表明，与预期相反，作为持续训练的机器翻译未能增强跨语言表示学习。

    arXiv:2403.16777v1 Announce Type: new  Abstract: Multilingual pretraining and fine-tuning have remarkably succeeded in various natural language processing tasks. Transferring representations from one language to another is especially crucial for cross-lingual learning. One can expect machine translation objectives to be well suited to fostering such capabilities, as they involve the explicit alignment of semantically equivalent sentences from different languages. This paper investigates the potential benefits of employing machine translation as a continued training objective to enhance language representation learning, bridging multilingual pretraining and cross-lingual applications. We study this question through two lenses: a quantitative evaluation of the performance of existing models and an analysis of their latent representations. Our results show that, contrary to expectations, machine translation as the continued training fails to enhance cross-lingual representation learning i
    
[^22]: 用于鲁棒性混合代码翻译的合成数据生成和联合学习

    Synthetic Data Generation and Joint Learning for Robust Code-Mixed Translation

    [https://arxiv.org/abs/2403.16771](https://arxiv.org/abs/2403.16771)

    本文提出了用于鲁棒性混合代码翻译的合成数据生成和联合学习方法，包括开发了Hinglish到英语的平行语料库以及提出的能够处理噪声的联合训练模型RCMT。

    

    现代多语言世界中的广泛网络交流为在单个话语中混合多种语言（又称混合代码语言）提供了机会。由于标注数据的稀缺和噪音的存在，这给计算模型带来了严峻挑战。在资源匮乏的环境中缓解数据稀缺问题的潜在解决方案是通过翻译利用资源丰富语言中的现有数据。本文针对混合代码（印地语和孟加拉语）到英语的机器翻译问题。首先，我们合成开发了HINMIX一个印地语到英语的平行语料库，包含约420万个句对。随后，我们提出了RCMT，一种基于强健扰动的联合训练模型，通过在干净和带噪声单词之间共享参数，学习处理现实世界混合代码文本中的噪声。此外，我们展示了RCMT在零-shot设置中对孟加拉语的适应能力。

    arXiv:2403.16771v1 Announce Type: new  Abstract: The widespread online communication in a modern multilingual world has provided opportunities to blend more than one language (aka code-mixed language) in a single utterance. This has resulted a formidable challenge for the computational models due to the scarcity of annotated data and presence of noise. A potential solution to mitigate the data scarcity problem in low-resource setup is to leverage existing data in resource-rich language through translation. In this paper, we tackle the problem of code-mixed (Hinglish and Bengalish) to English machine translation. First, we synthetically develop HINMIX, a parallel corpus of Hinglish to English, with ~4.2M sentence pairs. Subsequently, we propose RCMT, a robust perturbation based joint-training model that learns to handle noise in the real-world code-mixed text by parameter sharing across clean and noisy words. Further, we show the adaptability of RCMT in a zero-shot setup for Bengalish t
    
[^23]: ProCQA：一个用于代码搜索的大规模基于社区的编程问题回答数据集

    ProCQA: A Large-scale Community-based Programming Question Answering Dataset for Code Search

    [https://arxiv.org/abs/2403.16702](https://arxiv.org/abs/2403.16702)

    ProCQA数据集是从StackOverflow社区提取的，为编程问题回答提供了自然结构化的混合模态问答对，并引入了一种模态-不可知的对比预训练方法，显著提高了代码语言模型的性能。

    

    检索式代码问答旨在将用户在自然语言中的查询与相关代码片段匹配。先前的方法通常依赖于使用精心设计的双模态和单模态数据集进行预训练模型，以对齐文本和代码表示。在本文中，我们介绍了ProCQA，这是一个从StackOverflow社区中提取的大规模编程问题回答数据集，提供自然结构化的混合模态问答对。为了验证其有效性，我们提出了一种模态不可知的对比训练方法，以改善当前代码语言模型的文本和代码表示的对齐。与先前主要使用从CodeSearchNet中提取的双模态和单模态对进行预训练的模型相比，我们的模型在广泛的代码检索基准上表现出显著的性能改进。

    arXiv:2403.16702v1 Announce Type: new  Abstract: Retrieval-based code question answering seeks to match user queries in natural language to relevant code snippets. Previous approaches typically rely on pretraining models using crafted bi-modal and uni-modal datasets to align text and code representations. In this paper, we introduce ProCQA, a large-scale programming question answering dataset extracted from the StackOverflow community, offering naturally structured mixed-modal QA pairs. To validate its effectiveness, we propose a modality-agnostic contrastive pre-training approach to improve the alignment of text and code representations of current code language models. Compared to previous models that primarily employ bimodal and unimodal pairs extracted from CodeSearchNet for pre-training, our model exhibits significant performance improvements across a wide range of code retrieval benchmarks.
    
[^24]: ToXCL：毒性言论检测和解释的统一框架

    ToXCL: A Unified Framework for Toxic Speech Detection and Explanation

    [https://arxiv.org/abs/2403.16685](https://arxiv.org/abs/2403.16685)

    ToXCL是一个统一框架，旨在检测和解释隐性毒性言论，解决了传统模型在检测和解释任务中可能遇到的问题。

    

    线上毒性言论的蔓延是一个令人关注的问题，对人群构成威胁。明显的毒性言论包含冒犯性词汇信号，隐性的言论则包含编码或间接语言。因此，模型不仅需要检测隐性毒性言论，还需要解释其毒性。这导致了对有效检测和解释隐性毒性言论的统一框架的独特需求。先前的工作主要将毒性言论的检测和解释任务制定为文本生成问题。然而，使用这种策略训练的模型可能容易受到后续错误传播问题的影响。此外，我们的实验表明，这种模型的检测结果远低于那些仅专注于检测任务的模型。为了弥补这些差距，我们引入了ToXCL，一个用于检测和解释隐性毒性言论的统一框架。

    arXiv:2403.16685v1 Announce Type: new  Abstract: The proliferation of online toxic speech is a pertinent problem posing threats to demographic groups. While explicit toxic speech contains offensive lexical signals, implicit one consists of coded or indirect language. Therefore, it is crucial for models not only to detect implicit toxic speech but also to explain its toxicity. This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech. Prior works mainly formulated the task of toxic speech detection and explanation as a text generation problem. Nonetheless, models trained using this strategy can be prone to suffer from the consequent error propagation problem. Moreover, our experiments reveal that the detection results of such models are much lower than those that focus only on the detection task. To bridge these gaps, we introduce ToXCL, a unified framework for the detection and explanation of implicit toxic speech. Our model consists 
    
[^25]: 谁在网络上炫耀得更多？社交媒体炫耀行为的大规模分析

    Who is bragging more online? A large scale analysis of bragging in social media

    [https://arxiv.org/abs/2403.16668](https://arxiv.org/abs/2403.16668)

    第一次利用计算社会语言学方法在Twitter上进行了大规模研究，发现炫耀行为的普遍性随时间减少，而更年轻、受教育程度较高和受欢迎的用户更容易炫耀。

    

    炫耀是说出那些可能被其他人积极看待的话语，它在人类交流中被广泛使用，旨在建立一个积极的自我形象。社交媒体是一个自然的平台，用户可以利用炫耀来获得观众的钦佩、尊重、关注和粉丝。然而，关于网络上炫耀行为的规模和特征知之甚少。本文采用计算社会语言学方法，首次对Twitter（美国）上的炫耀行为进行了大规模研究，重点关注其整体普遍性、时间动态和人口因素的影响。我们的研究表明，在同一用户群体中，炫耀的普遍程度会随着时间的推移而减少。此外，在美国，更年轻、受教育程度较高和受欢迎的用户更有可能炫耀。最后，我们进行了广泛的语言学分析，揭示了特定的炫耀主题。

    arXiv:2403.16668v1 Announce Type: new  Abstract: Bragging is the act of uttering statements that are likely to be positively viewed by others and it is extensively employed in human communication with the aim to build a positive self-image of oneself. Social media is a natural platform for users to employ bragging in order to gain admiration, respect, attention and followers from their audiences. Yet, little is known about the scale of bragging online and its characteristics. This paper employs computational sociolinguistics methods to conduct the first large scale study of bragging behavior on Twitter (U.S.) by focusing on its overall prevalence, temporal dynamics and impact of demographic factors. Our study shows that the prevalence of bragging decreases over time within the same population of users. In addition, younger, more educated and popular users in the U.S. are more likely to brag. Finally, we conduct an extensive linguistics analysis to unveil specific bragging themes associ
    
[^26]: RU22Fact：优化多语言可解释事实核查中的证据

    RU22Fact: Optimizing Evidence for Multilingual Explainable Fact-Checking on Russia-Ukraine Conflict

    [https://arxiv.org/abs/2403.16662](https://arxiv.org/abs/2403.16662)

    提出了一个基于大型语言模型的方法，用于自动检索和总结网络中的证据，构建了RU22Fact数据集，是关于2022年俄乌冲突的多语言可解释事实核查数据集，同时开发了端到端可解释的事实核查系统来验证声明并生成解释。

    

    事实核查是通过检查现有证据来验证给定声明的准确性的任务。高质量的证据在增强事实核查系统并促进生成可理解的解释方面发挥着至关重要的作用。然而，为可解释的事实核查系统提供足够和相关的证据是一项挑战。为了解决这一挑战，我们提出了一种基于大型语言模型的方法，可以自动从网络中检索和总结证据。此外，我们构建了RU22Fact，这是一个关于2022年俄乌冲突的新型多语言可解释事实核查数据集，包含1.6万个样本，每个样本都包含现实世界的声明、优化证据和引用的解释。为了为我们的数据集建立基准，我们还开发了一个端到端可解释的事实核查系统，用于核实声明并生成解释。实验结果显示了前景。

    arXiv:2403.16662v1 Announce Type: new  Abstract: Fact-checking is the task of verifying the factuality of a given claim by examining the available evidence. High-quality evidence plays a vital role in enhancing fact-checking systems and facilitating the generation of explanations that are understandable to humans. However, the provision of both sufficient and relevant evidence for explainable fact-checking systems poses a challenge. To tackle this challenge, we propose a method based on a Large Language Model to automatically retrieve and summarize evidence from the Web. Furthermore, we construct RU22Fact, a novel multilingual explainable fact-checking dataset on the Russia-Ukraine conflict in 2022 of 16K samples, each containing real-world claims, optimized evidence, and referenced explanation. To establish a baseline for our dataset, we also develop an end-to-end explainable fact-checking system to verify claims and generate explanations. Experimental results demonstrate the prospect
    
[^27]: 语法错误与拼写错误更正：利用BART和MarianMT探究基于Transformer的语言模型的响应性

    Grammatical vs Spelling Error Correction: An Investigation into the Responsiveness of Transformer-based Language Models using BART and MarianMT

    [https://arxiv.org/abs/2403.16655](https://arxiv.org/abs/2403.16655)

    该研究利用BART和MarianMT两种先进的深度神经网络语言模型，对文本中的错误进行修正，并通过比较研究探究它们的有效性

    

    Text 仍然是信息表示的一个相关形式。文本文档是在数字原生平台中创建的，或通过将其他媒体文件（如图像和语音）转换而来。虽然数字原生文本通常是通过实体或虚拟键盘获得的，但也利用OCR和语音识别技术将图像和语音信号转换为文本内容。所有这些文本生成机制都会引入错误到所捕获的文本中。该项目旨在分析文本文档中出现的不同类型错误。该工作采用两种先进的基于深度神经网络的语言模型，即BART和MarianMT，来纠正文本中存在的异常。对这些模型进行可用数据集的迁移学习，以微调它们的纠错能力。进行了一项比较研究来调查其有效性。

    arXiv:2403.16655v1 Announce Type: new  Abstract: Text continues to remain a relevant form of representation for information. Text documents are created either in digital native platforms or through the conversion of other media files such as images and speech. While the digital native text is invariably obtained through physical or virtual keyboards, technologies such as OCR and speech recognition are utilized to transform the images and speech signals into text content. All these variety of mechanisms of text generation also introduce errors into the captured text.   This project aims at analyzing different kinds of error that occurs in text documents. The work employs two of the advanced deep neural network-based language models, namely, BART and MarianMT, to rectify the anomalies present in the text. Transfer learning of these models with available dataset is performed to finetune their capacity for error correction. A comparative study is conducted to investigate the effectiveness 
    
[^28]: 专利相似性嵌入模型的比较分析

    A comparative analysis of embedding models for patent similarity

    [https://arxiv.org/abs/2403.16630](https://arxiv.org/abs/2403.16630)

    本文比较了不同类型的专利嵌入模型在专利相似性计算任务上的表现，并具体探讨了Sentence Transformers (SBERT) 架构在专利相似性任务中的性能。

    

    本文对基于文本的专利相似性领域做出了两个贡献。首先，它比较了不同类型的专利特定预训练嵌入模型（如word2vec和doc2vec模型）和上下文词嵌入模型（如基于transformers的模型）在专利相似性计算任务上的表现。其次，它具体比较了具有不同训练阶段的Sentence Transformers（SBERT）架构在专利相似性任务上的性能。为评估模型的性能，我们使用关于专利干涉的信息，即两个或多个专利申请中的专利要求被专利审查员证明存在重叠的现象。因此，我们将这些干涉案例视为两个专利之间的最大相似性的代理，并用它们作为基准来评估不同嵌入模型的性能。

    arXiv:2403.16630v1 Announce Type: new  Abstract: This paper makes two contributions to the field of text-based patent similarity. First, it compares the performance of different kinds of patent-specific pretrained embedding models, namely static word embeddings (such as word2vec and doc2vec models) and contextual word embeddings (such as transformers based models), on the task of patent similarity calculation. Second, it compares specifically the performance of Sentence Transformers (SBERT) architectures with different training phases on the patent similarity task. To assess the models' performance, we use information about patent interferences, a phenomenon in which two or more patent claims belonging to different patent applications are proven to be overlapping by patent examiners. Therefore, we use these interferences cases as a proxy for maximum similarity between two patents, treating them as ground-truth to evaluate the performance of the different embedding models. Our results p
    
[^29]: 为危机相关社交媒体文本增加语义内容的跨语言句子嵌入

    Semantically Enriched Cross-Lingual Sentence Embeddings for Crisis-related Social Media Texts

    [https://arxiv.org/abs/2403.16614](https://arxiv.org/abs/2403.16614)

    提出了多语言句子编码器（CT-XLMR-SE和CT-mBERT-SE），可为50多种语言的危机相关社交媒体文本嵌入语义内容，使具有相似含义的文本在同一向量空间内接近，无论语言差异。

    

    诸如危机相关社交媒体文本的语义搜索和聚类等任务提高了我们对危机话语的理解，有助于决策制定和有针对性的干预。预先训练的语言模型在危机信息学中取得了良好的表现，但它们的上下文嵌入缺乏语义意义。尽管CrisisTransformers系列包括一个句子编码器来解决语义问题，但它仍然是单语的，仅处理英语文本。此外，为不同语言使用单独的模型会导致嵌入到不同向量空间中，当比较多语言文本之间的语义相似性时会引入挑战。因此，我们提出了多语言句子编码器（CT-XLMR-SE和CT-mBERT-SE），为50多种语言的危机相关社交媒体文本嵌入，使具有相似含义的文本在相同的向量空间内靠近，无论语言多样性如何。

    arXiv:2403.16614v1 Announce Type: new  Abstract: Tasks such as semantic search and clustering on crisis-related social media texts enhance our comprehension of crisis discourse, aiding decision-making and targeted interventions. Pre-trained language models have advanced performance in crisis informatics, but their contextual embeddings lack semantic meaningfulness. Although the CrisisTransformers family includes a sentence encoder to address the semanticity issue, it remains monolingual, processing only English texts. Furthermore, employing separate models for different languages leads to embeddings in distinct vector spaces, introducing challenges when comparing semantic similarities between multi-lingual texts. Therefore, we propose multi-lingual sentence encoders (CT-XLMR-SE and CT-mBERT-SE) that embed crisis-related social media texts for over 50 languages, such that texts with similar meanings are in close proximity within the same vector space, irrespective of language diversity.
    
[^30]: 对话接地：关于接地行为和接地单元的注释与分析

    Conversational Grounding: Annotation and Analysis of Grounding Acts and Grounding Units

    [https://arxiv.org/abs/2403.16609](https://arxiv.org/abs/2403.16609)

    对话系统的可靠性建设中，通过引入接地行为和接地单元的标注和度量，填补了现有对话系统在接地能力上的不足。

    

    成功的对话通常建立在共同理解的基础上，所有参与方对所共享的信息心领神会。这个被称为对话接地的过程对于构建可靠的对话系统至关重要，能够准确追踪和回忆所分享的信息。代理在接地传达的信息方面的熟练程度对于构建可靠的对话系统有着重要贡献。尽管对话系统在最近取得了进展，但它们的接地能力仍然存在明显的不足。Traum提出了一个关于对话接地的框架，介绍了接地行为和接地单元，但在大型语言模型领域，特别是在大规模语言模型领域，尚未取得实质性进展。为了弥补这一差距，我们提出了对两个对话语料库进行注释，利用接地行为、接地单元以及它们的接地程度的度量。我们讨论了我们在注释过程中的关键发现。

    arXiv:2403.16609v1 Announce Type: new  Abstract: Successful conversations often rest on common understanding, where all parties are on the same page about the information being shared. This process, known as conversational grounding, is crucial for building trustworthy dialog systems that can accurately keep track of and recall the shared information. The proficiencies of an agent in grounding the conveyed information significantly contribute to building a reliable dialog system. Despite recent advancements in dialog systems, there exists a noticeable deficit in their grounding capabilities. Traum provided a framework for conversational grounding introducing Grounding Acts and Grounding Units, but substantial progress, especially in the realm of Large Language Models, remains lacking. To bridge this gap, we present the annotation of two dialog corpora employing Grounding Acts, Grounding Units, and a measure of their degree of grounding. We discuss our key findings during the annotation
    
[^31]: TrustAI在SemEval-2024任务8中的应用：多领域机器生成文本检测技术的综合分析

    TrustAI at SemEval-2024 Task 8: A Comprehensive Analysis of Multi-domain Machine Generated Text Detection Techniques

    [https://arxiv.org/abs/2403.16592](https://arxiv.org/abs/2403.16592)

    本文提出了针对SemEval2024 Task8的TrustAI方法，旨在在不同领域和语境下检测机器生成文本，研究综合分析了统计、神经和预训练模型等各种方法，并介绍了实验设置和深入的误差分析，取得了相当高的准确率，同时也突出了未来研究中需要考虑的挑战和关键因素。

    

    arXiv:2403.16592v1 公告类型: 新 随着大语言模型在各种用户查询中生成流畅内容的显著能力，对于产生的虚假信息和个人信息泄露引起了担忧。本文介绍了我们在SemEval2024 Task8中用于检测各种领域内机器生成文本的方法，旨在在单语和多语境下检测。我们全面分析了各种检测机器生成文本的方法，包括统计、神经和预训练模型方法。我们还详细描述了实验设置，并进行了深入的误差分析以评估这些方法的有效性。我们的方法在子任务-A单语测试集上获得86.9\%的准确率，子任务-B上为83.7\%。此外，我们还强调了未来研究中需要考虑的挑战和关键因素。

    arXiv:2403.16592v1 Announce Type: new  Abstract: The Large Language Models (LLMs) exhibit remarkable ability to generate fluent content across a wide spectrum of user queries. However, this capability has raised concerns regarding misinformation and personal information leakage. In this paper, we present our methods for the SemEval2024 Task8, aiming to detect machine-generated text across various domains in both mono-lingual and multi-lingual contexts. Our study comprehensively analyzes various methods to detect machine-generated text, including statistical, neural, and pre-trained model approaches. We also detail our experimental setup and perform a in-depth error analysis to evaluate the effectiveness of these methods. Our methods obtain an accuracy of 86.9\% on the test set of subtask-A mono and 83.7\% for subtask-B. Furthermore, we also highlight the challenges and essential factors for consideration in future studies.
    
[^32]: 大型语言模型（或人类）是否能进行文本提炼？

    Can Large Language Models (or Humans) Distill Text?

    [https://arxiv.org/abs/2403.16584](https://arxiv.org/abs/2403.16584)

    大型语言模型（LLMs）在文本提炼中具有独特优势，但在处理情感时仍存在一定局限性，无论是对机器学习分类器还是人类注释员而言。

    

    我们研究了大型语言模型（LLMs）在文本提炼方面的潜力：即去除不需要的禁止变量的文本痕迹。我们利用具有不同架构和训练方法的一系列LLMs来识别和去除关于目标变量的信息，同时保留其他相关信号。我们的研究结果揭示了LLMs在处理提炼中的优势和局限性，并为在涉及文本数据的计算社会科学调查中利用这些模型的策略提供了见解。尤其是，我们发现在强烈测试情感移除时，经过LLM提炼的文本与情感之间的统计关联仍然可以被机器学习分类器清晰地检测到。此外，我们发现人类注释员在保留其他语义内容的同时，也很难提炼出情感。这表明可能存在一定的局限性。

    arXiv:2403.16584v1 Announce Type: new  Abstract: We investigate the potential of large language models (LLMs) to distill text: to remove the textual traces of an undesired forbidden variable. We employ a range of LLMs with varying architectures and training approaches to distill text by identifying and removing information about the target variable while preserving other relevant signals. Our findings shed light on the strengths and limitations of LLMs in addressing the distillation and provide insights into the strategies for leveraging these models in computational social science investigations involving text data. In particular, we show that in the strong test of removing sentiment, the statistical association between the processed text and sentiment is still clearly detectable to machine learning classifiers post-LLM-distillation. Furthermore, we find that human annotators also struggle to distill sentiment while preserving other semantic content. This suggests there may be limited
    
[^33]: NSINA：用于僧伽罗语的新闻语料库

    NSINA: A News Corpus for Sinhala

    [https://arxiv.org/abs/2403.16571](https://arxiv.org/abs/2403.16571)

    NSINA是为解决僧伽罗语中LLMs适应性挑战而引入的最大新闻语料库，为改进该语言的自然语言处理提供了宝贵资源和基准。

    

    大型语言模型（LLMs）的引入推动了自然语言处理（NLP）的发展，但它们的有效性在很大程度上取决于预训练资源。尤其是在低资源语言（如僧伽罗语）中，这一点尤为明显，因为它们面临着两个主要挑战：缺乏充足的训练数据和有限的基准数据集。为应对这一问题，本研究介绍了NSINA，这是一个包括来自热门僧伽罗语新闻网站的50万多篇文章的全面新闻语料库，以及三项NLP任务：新闻媒体识别、新闻类别预测和新闻标题生成。NSINA的发布旨在为适应僧伽罗语的LLMs带来解决方案，提供有价值的资源和用于改进僧伽罗语NLP的基准。NSINA是迄今为止最大的僧伽罗语新闻语料库。

    arXiv:2403.16571v1 Announce Type: cross  Abstract: The introduction of large language models (LLMs) has advanced natural language processing (NLP), but their effectiveness is largely dependent on pre-training resources. This is especially evident in low-resource languages, such as Sinhala, which face two primary challenges: the lack of substantial training data and limited benchmarking datasets. In response, this study introduces NSINA, a comprehensive news corpus of over 500,000 articles from popular Sinhala news websites, along with three NLP tasks: news media identification, news category prediction, and news headline generation. The release of NSINA aims to provide a solution to challenges in adapting LLMs to Sinhala, offering valuable resources and benchmarks for improving NLP in the Sinhala language. NSINA is the largest news corpus for Sinhala, available up to date.
    
[^34]: PE：一种用于快速文本层次生成的Poincaré解释方法

    PE: A Poincare Explanation Method for Fast Text Hierarchy Generation

    [https://arxiv.org/abs/2403.16554](https://arxiv.org/abs/2403.16554)

    介绍了一种使用Poincaré解释方法在超几何空间中建模特征交互作用的新方法，并提出了时间复杂度为O(n^2logn)的框架，证明了在投影空间中进行的层次聚类过程可以视为构建最小生成树，提出了一个时间有效的算法

    

    arXiv:2403.16554v1 公告类型: cross 摘要: NLP中深度学习模型的黑盒特性阻碍了它们的广泛应用。研究重点已经转移到层次属性（HA），因为它能够建模特征交互作用。最近的研究使用欧几里得空间中耗时的贪婪搜索来建模非连续组合，忽略了特征表示中潜在的语言信息。在这项工作中，我们引入了一种新颖的方法，即Poincaré解释（PE），用于使用超几何空间建模特征交互作用，时间复杂度为$O(n^2logn)$。受Poincaré模型启发，我们提出了一个框架，将嵌入投影到超几何空间中，这展示出更好的对句法和语义层次结构的归纳偏差。最终，我们证明了投影空间中的层次聚类过程可以被视为构建最小生成树，并提出了一个时间有效的算法。实验结果表明...

    arXiv:2403.16554v1 Announce Type: cross  Abstract: The black-box nature of deep learning models in NLP hinders their widespread application. The research focus has shifted to Hierarchical Attribution (HA) for its ability to model feature interactions. Recent works model non-contiguous combinations with a time-costly greedy search in Eculidean spaces, neglecting underlying linguistic information in feature representations. In this work, we introduce a novel method, namely Poincar\'e Explanation (PE), for modeling feature interactions using hyperbolic spaces in an $O(n^2logn)$ time complexity. Inspired by Poincar\'e model, we propose a framework to project the embeddings into hyperbolic spaces, which exhibit better inductive biases for syntax and semantic hierarchical structures. Eventually, we prove that the hierarchical clustering process in the projected space could be viewed as building a minimum spanning tree and propose a time efficient algorithm. Experimental results demonstrate t
    
[^35]: 通过对比表示学习提高少样本关系分类中的高效信息提取

    Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning

    [https://arxiv.org/abs/2403.16543](https://arxiv.org/abs/2403.16543)

    通过对比学习从多个句子表示中提取互补的判别信息，提高少样本关系分类中的信息提取效率

    

    有限标记实例下的关系分类中区分实体对之间的关系构成少样本关系分类中的重大挑战。文本数据的表示提取了跨领域、实体和关系的丰富信息。在本文中，我们介绍了一种结合多个句子表示和对比学习以增强信息提取的新方法。尽管关系分类中通常使用实体标记令牌提取表示，但我们认为模型内部表示中存在大量未被利用的信息。为了解决这一问题，我们提出了对齐多个句子表示的方法，如[CLS]令牌、提示中使用的[MASK]令牌和实体标记令牌。我们的方法利用对比学习从这些个体表示中提取互补的判别信息。这在低资源环境中特别相关，其中

    arXiv:2403.16543v1 Announce Type: cross  Abstract: Differentiating relationships between entity pairs with limited labeled instances poses a significant challenge in few-shot relation classification. Representations of textual data extract rich information spanning the domain, entities, and relations. In this paper, we introduce a novel approach to enhance information extraction combining multiple sentence representations and contrastive learning. While representations in relation classification are commonly extracted using entity marker tokens, we argue that substantial information within the internal model representations remains untapped. To address this, we propose aligning multiple sentence representations, such as the [CLS] token, the [MASK] token used in prompting, and entity marker tokens. Our method employs contrastive learning to extract complementary discriminative information from these individual representations. This is particularly relevant in low-resource settings where
    
[^36]: 基于基础模型的幻觉检测：灵活定义与现有技术综述

    Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art

    [https://arxiv.org/abs/2403.16527](https://arxiv.org/abs/2403.16527)

    基于基础模型的幻觉检测旨在填补现有规划者缺少的常识推理，以适用于超出分布任务的场景。

    

    自主系统即将无处不在，从制造业的自主性到农业领域的机器人，从医疗助理到娱乐产业。大多数系统是通过模块化的子组件开发的，用于决策、规划和控制，这些组件可能是手工设计的，也可能是基于学习的。虽然现有方法在它们专门设计的情境下表现良好，但在测试时不可避免地会在罕见的、超出分布范围的场景下表现特别差。基于多个任务训练的基础模型的兴起，以及从各个领域采集的令人印象深刻的大型数据集，使研究人员相信这些模型可能提供现有规划者所缺乏的常识推理。研究人员认为，这种常识推理将弥合算法开发和部署之间的差距，适用于超出分布任务的情况。

    arXiv:2403.16527v1 Announce Type: new  Abstract: Autonomous systems are soon to be ubiquitous, from manufacturing autonomy to agricultural field robots, and from health care assistants to the entertainment industry. The majority of these systems are developed with modular sub-components for decision-making, planning, and control that may be hand-engineered or learning-based. While these existing approaches have been shown to perform well under the situations they were specifically designed for, they can perform especially poorly in rare, out-of-distribution scenarios that will undoubtedly arise at test-time. The rise of foundation models trained on multiple tasks with impressively large datasets from a variety of fields has led researchers to believe that these models may provide common sense reasoning that existing planners are missing. Researchers posit that this common sense reasoning will bridge the gap between algorithm development and deployment to out-of-distribution tasks, like
    
[^37]: 可视引导的生成式文本布局预训练用于文档智能

    Visually Guided Generative Text-Layout Pre-training for Document Intelligence

    [https://arxiv.org/abs/2403.16516](https://arxiv.org/abs/2403.16516)

    提出了一种名为ViTLP的可视引导的生成文本布局预训练技术，能够处理任意长度的词汇密集型文档，并且可以作为OCR模型用于文本定位和识别。

    

    先前的研究表明，预训练技术可以提升视觉文档理解（VDU）的性能，通常需要模型获得感知和推理文档文本和布局（例如文本和表格单元的位置）的能力。为此，我们提出了一种名为ViTLP的可视引导的生成文本布局预训练技术。给定一个文档图像，该模型优化分层语言和布局建模目标，以生成交错的文本和布局序列。此外，为了解决Transformers处理长文档的局限性，我们引入了一种简单而有效的多段生成式预训练方案，使ViTLP能够处理任意长度的词汇密集型文档。ViTLP可以作为本地OCR模型，用于定位和识别文档图像中的文本。此外，ViTLP可以有效应用于各种下游VDU任务。大量实验证明ViTLP可以...

    arXiv:2403.16516v1 Announce Type: new  Abstract: Prior study shows that pre-training techniques can boost the performance of visual document understanding (VDU), which typically requires models to gain abilities to perceive and reason both document texts and layouts (e.g., locations of texts and table-cells). To this end, we propose visually guided generative text-layout pre-training, named ViTLP. Given a document image, the model optimizes hierarchical language and layout modeling objectives to generate the interleaved text and layout sequence. In addition, to address the limitation of processing long documents by Transformers, we introduce a straightforward yet effective multi-segment generative pre-training scheme, facilitating ViTLP to process word-intensive documents of any length. ViTLP can function as a native OCR model to localize and recognize texts of document images. Besides, ViTLP can be effectively applied to various downstream VDU tasks. Extensive experiments show that Vi
    
[^38]: LLMs是少样本情境低资源语言学习器

    LLMs Are Few-Shot In-Context Low-Resource Language Learners

    [https://arxiv.org/abs/2403.16512](https://arxiv.org/abs/2403.16512)

    该研究对25种低资源语言和7种相对较高资源语言上的情境学习（ICL）及其跨语言变体进行了研究，发现了在低资源语言中使用LLMs进行ICL的有效性，提出了替代方法查询对齐，并为低资源语言的ICL提供了宝贵见解。

    

    在情境学习（ICL）的支持下，大型语言模型（LLMs）可以利用短时的情境信息执行各种任务，这为缩小高资源语言和低资源语言之间的差距提供了重要途径。然而，目前只有少数研究探讨了针对低资源语言的ICL，其中大部分集中在相对高资源的语言，比如法语和西班牙语。在这项工作中，我们对25种低资源语言和7种相对较高资源语言上的ICL及其跨语言变体（X-ICL）进行了广泛研究。我们的研究不仅评估了LLMs在低资源语言中使用ICL的有效性，还发现了情境标签对齐的缺陷，并引入了更有效的替代方法：查询对齐。此外，我们为低资源语言的ICL的各个方面提供了宝贵的见解。我们的研究总结了少样本情境学习的重要性。

    arXiv:2403.16512v1 Announce Type: cross  Abstract: In-context learning (ICL) empowers large language models (LLMs) to perform diverse tasks in underrepresented languages using only short in-context information, offering a crucial avenue for narrowing the gap between high-resource and low-resource languages. Nonetheless, there is only a handful of works explored ICL for low-resource languages with most of them focusing on relatively high-resource languages, such as French and Spanish. In this work, we extensively study ICL and its cross-lingual variation (X-ICL) on 25 low-resource and 7 relatively higher-resource languages. Our study not only assesses the effectiveness of ICL with LLMs in low-resource languages but also identifies the shortcomings of in-context label alignment, and introduces a more effective alternative: query alignment. Moreover, we provide valuable insights into various facets of ICL for low-resource languages. Our study concludes the significance of few-shot in-cont
    
[^39]: LARA：语言自适应检索增强LLMs用于多轮意图分类

    LARA: Linguistic-Adaptive Retrieval-Augmented LLMs for Multi-Turn Intent Classification

    [https://arxiv.org/abs/2403.16504](https://arxiv.org/abs/2403.16504)

    LARA是一个Linguistic-Adaptive Retrieval-Augmented Language Models（语言自适应检索增强LLMs），旨在通过结合微调过的较小模型与检索增强机制来提高多语言多轮意图分类任务的准确性，从而改善对话背景的理解。

    

    鉴于大型语言模型(LLMs)取得的显著成就，研究人员已经在文本分类任务中采用了上下文学习。然而，这些研究侧重于单语言、单轮分类任务。本文介绍了LARA（Linguistic-Adaptive Retrieval-Augmented Language Models），旨在增强多语言多轮分类任务的准确性，以适应聊天机器人交互中的众多意图。由于会话背景的复杂性和不断发展的性质，多轮意图分类尤为具有挑战性。LARA通过将微调过的较小模型与检索增强机制结合，嵌入LLMs的架构中来解决这些问题。这种整合使LARA能够动态利用过去的对话和相关意图，从而提高对上下文的理解。此外，我们的自适应检索技术增强了跨语言的能力。

    arXiv:2403.16504v1 Announce Type: new  Abstract: Following the significant achievements of large language models (LLMs), researchers have employed in-context learning for text classification tasks. However, these studies focused on monolingual, single-turn classification tasks. In this paper, we introduce LARA (Linguistic-Adaptive Retrieval-Augmented Language Models), designed to enhance accuracy in multi-turn classification tasks across six languages, accommodating numerous intents in chatbot interactions. Multi-turn intent classification is notably challenging due to the complexity and evolving nature of conversational contexts. LARA tackles these issues by combining a fine-tuned smaller model with a retrieval-augmented mechanism, integrated within the architecture of LLMs. This integration allows LARA to dynamically utilize past dialogues and relevant intents, thereby improving the understanding of the context. Furthermore, our adaptive retrieval techniques bolster the cross-lingual
    
[^40]: 利用维基百科超链接自动构建用于地理解析的大规模语料库

    Automatic Construction of a Large-Scale Corpus for Geoparsing Using Wikipedia Hyperlinks

    [https://arxiv.org/abs/2403.16483](https://arxiv.org/abs/2403.16483)

    本文提出了一种利用维基百科超链接自动构建用于地理解析的大规模语料库的新方法，构建了包含130万篇文章的WHLL语料库，为地理解析领域带来了新的数据资源。

    

    地理解析是对文本中的位置表达进行经纬度（坐标）估计的任务。地理解析必须处理指示具有相同符号的多个位置的表达的歧义。为了评估地理解析系统，先前的研究提出了几个语料库。然而，这些语料库规模较小，并且受限于一般领域的位置表达覆盖。本文提出了基于维基百科超链接的位置链接（WHLL）方法，这是一种构建用于地理解析的大规模语料库的新方法。WHLL利用维基百科中的超链接来用坐标注释多个位置表达。通过这种方法，我们构建了WHLL语料库，这是一个新的用于地理解析的大规模语料库。WHLL语料库包含130万篇文章，每篇约包含7.8个独特的位置表达。45.6%的位置表达存在歧义，并指示多个地点。

    arXiv:2403.16483v1 Announce Type: new  Abstract: Geoparsing is the task of estimating the latitude and longitude (coordinates) of location expressions in texts. Geoparsing must deal with the ambiguity of the expressions that indicate multiple locations with the same notation. For evaluating geoparsing systems, several corpora have been proposed in previous work. However, these corpora are small-scale and suffer from the coverage of location expressions on general domains. In this paper, we propose Wikipedia Hyperlink-based Location Linking (WHLL), a novel method to construct a large-scale corpus for geoparsing from Wikipedia articles. WHLL leverages hyperlinks in Wikipedia to annotate multiple location expressions with coordinates. With this method, we constructed the WHLL corpus, a new large-scale corpus for geoparsing. The WHLL corpus consists of 1.3M articles, each containing about 7.8 unique location expressions. 45.6% of location expressions are ambiguous and refer to more than on
    
[^41]: 通过叠加概念判别进行的少样本命名实体识别

    Few-shot Named Entity Recognition via Superposition Concept Discrimination

    [https://arxiv.org/abs/2403.16463](https://arxiv.org/abs/2403.16463)

    通过Superposition Concept Discriminator（SuperCD）提出了一种解决少样本NER中精确泛化问题的方法，通过主动学习范式从示例实例中识别叠加概念并检索相应实例来标注，以解决信息不足导致的模糊性挑战。

    

    少样本NER旨在仅具有有限数量的实例的情况下识别目标类型的实体。不幸的是，少样本NER受到内在精确泛化问题的严重挑战，即由于信息不足导致的模糊性，难以准确确定所需的目标类型。在本文中，我们提出了超级概念判别器（SuperCD），通过主动学习范式解决上述挑战。具体而言，首先引入概念提取器来从示例实例中识别叠加概念，每个概念对应一个可能的泛化边界。然后，应用叠加实例检索器从大规模文本语料库中检索这些叠加概念的相应实例。最后，要求注释员对检索到的实例进行注释，这些带注释的实例与原始示例实例一起。

    arXiv:2403.16463v1 Announce Type: new  Abstract: Few-shot NER aims to identify entities of target types with only limited number of illustrative instances. Unfortunately, few-shot NER is severely challenged by the intrinsic precise generalization problem, i.e., it is hard to accurately determine the desired target type due to the ambiguity stemming from information deficiency. In this paper, we propose Superposition Concept Discriminator (SuperCD), which resolves the above challenge via an active learning paradigm. Specifically, a concept extractor is first introduced to identify superposition concepts from illustrative instances, with each concept corresponding to a possible generalization boundary. Then a superposition instance retriever is applied to retrieve corresponding instances of these superposition concepts from large-scale text corpus. Finally, annotators are asked to annotate the retrieved instances and these annotated instances together with original illustrative instances
    
[^42]: 研究BERT模型中的注意力分数如何感知GLUE基准测试中的句法和语义任务中的词汇类别

    A Study on How Attention Scores in the BERT Model are Aware of Lexical Categories in Syntactic and Semantic Tasks on the GLUE Benchmark

    [https://arxiv.org/abs/2403.16447](https://arxiv.org/abs/2403.16447)

    本研究探讨了BERT模型中的注意力分数如何根据词汇类别的不同而变化，在GLUE基准测试下的句法和语义任务中，证实在强调语义信息的任务中，注意力主要集中于内容词，而在强调句法信息的任务中，注意力主要集中在功能词上

    

    该研究检查了在BERT模型中，token之间的注意力分数在下游任务的微调过程中是否根据词汇类别显着变化。受到人类语言处理中句法和语义信息被不同解析的概念启发，我们根据其词汇类别对句子中的token进行分类，并关注这些类别之间注意力分数的变化。我们的假设认为，在注重语义信息的下游任务中，以内容词为中心的注意力分数会增强，而在强调句法信息的情况下，以功能词为中心的注意力分数会增强。通过对GLUE基准数据集中的六个任务进行实验，我们证实了关于微调过程的假设。此外，我们的其他调查揭示了BERT层会一致分配 m

    arXiv:2403.16447v1 Announce Type: new  Abstract: This study examines whether the attention scores between tokens in the BERT model significantly vary based on lexical categories during the fine-tuning process for downstream tasks. Drawing inspiration from the notion that in human language processing, syntactic and semantic information is parsed differently, we categorize tokens in sentences according to their lexical categories and focus on changes in attention scores among these categories. Our hypothesis posits that in downstream tasks that prioritize semantic information, attention scores centered on content words are enhanced, while in cases emphasizing syntactic information, attention scores centered on function words are intensified. Through experimentation conducted on six tasks from the GLUE benchmark dataset, we substantiate our hypothesis regarding the fine-tuning process. Furthermore, our additional investigations reveal the presence of BERT layers that consistently assign m
    
[^43]: 面向LLMs临床能力的自动评估：度量、数据和算法

    Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric, Data, and Algorithm

    [https://arxiv.org/abs/2403.16446](https://arxiv.org/abs/2403.16446)

    针对LLMs的临床能力，提出了自动评估范式，包括度量、数据和算法，以确保安全和可靠的临床应用。

    

    大型语言模型(LLMs)由于在自然语言建模方面的卓越表现，对于提高医学诊断的临床效率越来越受到关注。为了确保安全和可靠的临床应用，评估LLMs的确变得至关重要，以更好地减轻潜在风险，例如幻觉。然而，目前的评估方法很大程度上依赖于劳动密集型的人类参与来获得人类偏好的判断。为了应对这一挑战，我们提出了一种定制的自动评估范式，旨在评估LLMs在提供临床服务(例如疾病诊断和治疗)方面的能力。该评估范式包含三个基本要素：度量、数据和算法。具体来说，受专业临床实践途径的启发，我们制定了一个LLM特定的临床途径(LCP)，以定义医生代理应具备的临床能力。

    arXiv:2403.16446v1 Announce Type: new  Abstract: Large language models (LLMs) are gaining increasing interests to improve clinical efficiency for medical diagnosis, owing to their unprecedented performance in modelling natural language. Ensuring the safe and reliable clinical applications, the evaluation of LLMs indeed becomes critical for better mitigating the potential risks, e.g., hallucinations. However, current evaluation methods heavily rely on labor-intensive human participation to achieve human-preferred judgements. To overcome this challenge, we propose an automatic evaluation paradigm tailored to assess the LLMs' capabilities in delivering clinical services, e.g., disease diagnosis and treatment. The evaluation paradigm contains three basic elements: metric, data, and algorithm. Specifically, inspired by professional clinical practice pathways, we formulate a LLM-specific clinical pathway (LCP) to define the clinical capabilities that a doctor agent should possess. Then, Stan
    
[^44]: KIT-19：一套涵盖19个任务的韩文指令工具包，用于微调韩文大型语言模型

    KIT-19: A Comprehensive Korean Instruction Toolkit on 19 Tasks for Fine-Tuning Korean Large Language Models

    [https://arxiv.org/abs/2403.16444](https://arxiv.org/abs/2403.16444)

    这项研究介绍了一套名为KIT-19的韩文指令数据集，用于开发韩文大型语言模型，在19个韩文自然语言处理任务上取得了显著的优越性能。

    

    Instruction Tuning on Large Language Models是模型表现良好、在特定任务中取得高性能的必要过程。在主流语言如英语中，正在构建和公开提供基于指令的数据集。对于韩语，公开可用的模型和数据集都依赖于使用ChatGPT的输出或翻译英文构建的数据集。本文介绍了\textit{KIT-19}作为用于开发韩文LLM的指令数据集。 \textit{KIT-19}是以指令格式创建的数据集，包括19个韩文NLP任务的现有开源数据集。我们在本文中使用\textit{KIT-19}训练韩文预训练LLM，以展示其有效性。实验结果表明，在\textit{KIT-19}上训练的模型明显优于现有的韩文LLM。基于其质量和实证结果，本文提出了

    arXiv:2403.16444v1 Announce Type: new  Abstract: Instruction Tuning on Large Language Models is an essential process for model to function well and achieve high performance in specific tasks. Accordingly, in mainstream languages such as English, instruction-based datasets are being constructed and made publicly available. In the case of Korean, publicly available models and datasets all rely on using the output of ChatGPT or translating datasets built in English. In this paper, We introduce \textit{KIT-19} as an instruction dataset for the development of LLM in Korean. \textit{KIT-19} is a dataset created in an instruction format, comprising 19 existing open-source datasets for Korean NLP tasks. In this paper, we train a Korean Pretrained LLM using \textit{KIT-19} to demonstrate its effectiveness. The experimental results show that the model trained on \textit{KIT-19} significantly outperforms existing Korean LLMs. Based on the its quality and empirical results, this paper proposes tha
    
[^45]: CodeS: 通过多层草图实现自然语言到代码仓库的转换

    CodeS: Natural Language to Code Repository via Multi-Layer Sketch

    [https://arxiv.org/abs/2403.16443](https://arxiv.org/abs/2403.16443)

    CodeS提出了一个新的软件工程任务NL2Repo，旨在从自然语言需求中生成整个代码仓库，通过多层草图的方式解决这一任务。

    

    大型语言模型（LLMs）在代码相关任务上的出色性能展示了完全自动化软件开发的潜力。鉴于此，我们介绍了一个新的软件工程任务，即自然语言到代码仓库（NL2Repo）。该任务旨在从自然语言需求中生成整个代码仓库。为了解决这一任务，我们提出了一个简单而有效的框架 CodeS，通过多层草图将NL2Repo分解为多个子任务。具体而言，CodeS包括三个模块：RepoSketcher，FileSketcher和SketchFiller。RepoSketcher首先为给定的需求生成代码仓库的目录结构；FileSketcher然后为生成的结构中的每个文件生成一个文件草图；SketchFiller最终为生成的文件草图中的每个函数填充细节。为了严格评估CodeS在NL2Repo任务上的表现，我们通过自动和手动的方式进行评估。

    arXiv:2403.16443v1 Announce Type: cross  Abstract: The impressive performance of large language models (LLMs) on code-related tasks has shown the potential of fully automated software development. In light of this, we introduce a new software engineering task, namely Natural Language to code Repository (NL2Repo). This task aims to generate an entire code repository from its natural language requirements. To address this task, we propose a simple yet effective framework CodeS, which decomposes NL2Repo into multiple sub-tasks by a multi-layer sketch. Specifically, CodeS includes three modules: RepoSketcher, FileSketcher, and SketchFiller. RepoSketcher first generates a repository's directory structure for given requirements; FileSketcher then generates a file sketch for each file in the generated structure; SketchFiller finally fills in the details for each function in the generated file sketch. To rigorously assess CodeS on the NL2Repo task, we carry out evaluations through both automat
    
[^46]: 如果CLIP能说话: 通过它们的首选概念描述理解视觉-语言模型的表示

    If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions

    [https://arxiv.org/abs/2403.16442](https://arxiv.org/abs/2403.16442)

    通过新颖的Extract and Explore（EX2）方法，研究发现在视觉-语言模型（VLM）中，重要的特征描述包括非视觉属性，虚假描述影响VLM表示，不同的VLM优先考虑不同的内容。

    

    最近的研究常常假设视觉-语言模型（VLM）的表示是基于形状等视觉属性。然而，目前尚不清楚VLM在表示概念时在多大程度上将这些信息作为优先考虑对象。我们提出了一种新颖的方法，称为Extract and Explore（EX2），用于刻画VLM的重要文本特征。EX2使用强化学习将一个大型语言模型与VLM首选项对齐，并生成包含VLM重要特征的描述。然后，我们检查这些描述以确定对VLM表示有贡献的特征。我们发现，虽然提供了没有帮助信息的虚假描述（例如，单击放大概念的照片），但在VLM表示中起着重要作用。更重要的是，在信息丰富的描述中，VLM在表示视觉概念时显著依赖非视觉属性（如栖息地）。此外，我们的分析揭示了不同的VLM优先考虑不同的内容。

    arXiv:2403.16442v1 Announce Type: new  Abstract: Recent works often assume that Vision-Language Model (VLM) representations are based on visual attributes like shape. However, it is unclear to what extent VLMs prioritize this information to represent concepts. We propose Extract and Explore (EX2), a novel approach to characterize important textual features for VLMs. EX2 uses reinforcement learning to align a large language model with VLM preferences and generates descriptions that incorporate the important features for the VLM. Then, we inspect the descriptions to identify the features that contribute to VLM representations. We find that spurious descriptions have a major role in VLM representations despite providing no helpful information, e.g., Click to enlarge photo of CONCEPT. More importantly, among informative descriptions, VLMs rely significantly on non-visual attributes like habitat to represent visual concepts. Also, our analysis reveals that different VLMs prioritize differen
    
[^47]: 使用程序执行运行时行为评估大型语言模型

    Evaluating Large Language Models with Runtime Behavior of Program Execution

    [https://arxiv.org/abs/2403.16437](https://arxiv.org/abs/2403.16437)

    本文提出了一个名为REval的框架，用于评估代码LLMs的代码推理能力以及与程序执行的一致性。

    

    大型代码语言模型（即代码LLMs）展示了强大的代码理解和生成能力。为了评估代码LLMs在各个方面的能力，已经提出了许多基准（如HumanEval和ClassEval）。代码推理是代码LLMs最重要的能力之一，但现有的代码推理基准不足。通常，它们重点预测程序的输入和输出，忽略了程序执行过程中的中间行为评估，以及逻辑一致性（例如，如果执行路径预测错误，则模型不应该给出正确的输出）在执行推理时。为了解决这些问题，本文提出了一个名为REval的框架，用于评估代码LLMs的代码推理能力以及与程序执行的一致性。我们利用现有的代码基准，并将它们适应到我们的框架中的新基准中。

    arXiv:2403.16437v1 Announce Type: cross  Abstract: Large language models for code (i.e., code LLMs) have shown strong code understanding and generation capabilities. To evaluate the capabilities of code LLMs in various aspects, many benchmarks have been proposed (e.g., HumanEval and ClassEval). Code reasoning is one of the most essential abilities of code LLMs, but existing benchmarks for code reasoning are not sufficient. Typically, they focus on predicting the input and output of a program, ignoring the evaluation of the intermediate behavior during program execution, as well as the logical consistency (e.g., the model should not give the correct output if the prediction of execution path is wrong) when performing the reasoning. To address these problems, in this paper, we propose a framework, namely REval, for evaluating code reasoning abilities and consistency of code LLMs with program execution. We utilize existing code benchmarks and adapt them to new benchmarks within our framew
    
[^48]: 基于大型语言模型的基于指令的无监督段落重新排序方法InstUPR

    InstUPR : Instruction-based Unsupervised Passage Reranking with Large Language Models

    [https://arxiv.org/abs/2403.16435](https://arxiv.org/abs/2403.16435)

    InstUPR是一种基于大型语言模型的无监督段落重新排序方法，利用了LLMs的指令跟踪能力，无需额外微调，通过软得分聚合技术和成对重新排序，在BEIR基准测试中表现优秀。

    

    本文介绍了InstUPR，一种基于大型语言模型（LLMs）的无监督段落重新排序方法。与现有依赖于query-document对进行大量训练或特定于检索的指令的方法不同，我们的方法利用了经过指令调整的LLMs的按照指令进行操作的能力来进行段落重新排序，而无需任何额外的微调。为实现这一目标，我们引入了一种软得分聚合技术，并采用了成对重新排序的无监督段落重新排序。在BEIR基准测试上的实验表明，InstUPR优于无监督基线以及一个经过指令调整的重新排序器，突显了其有效性和优越性。复现所有实验的源代码已在https://github.com/MiuLab/InstUPR 开源。

    arXiv:2403.16435v1 Announce Type: new  Abstract: This paper introduces InstUPR, an unsupervised passage reranking method based on large language models (LLMs). Different from existing approaches that rely on extensive training with query-document pairs or retrieval-specific instructions, our method leverages the instruction-following capabilities of instruction-tuned LLMs for passage reranking without any additional fine-tuning. To achieve this, we introduce a soft score aggregation technique and employ pairwise reranking for unsupervised passage reranking. Experiments on the BEIR benchmark demonstrate that InstUPR outperforms unsupervised baselines as well as an instruction-tuned reranker, highlighting its effectiveness and superiority. Source code to reproduce all experiments is open-sourced at https://github.com/MiuLab/InstUPR
    
[^49]: $\textit{LinkPrompt}$: 基于提示的语言模型的自然和通用对抗攻击

    $\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models

    [https://arxiv.org/abs/2403.16432](https://arxiv.org/abs/2403.16432)

    基于提示的语言模型的优化过程揭示了生成对抗提示以误导模型的见解，引发了对该范式对抗性脆弱性的担忧。

    

    Prompt-based learning 是一种新的语言模型训练范式，它将预训练语言模型（PLMs）调整到下游任务，从而在各种自然语言处理（NLP）任务中提升了性能基准。一些研究表明，通过优化搜索提示的有效性，而不是使用固定的提示模板来微调模型。这种基于提示优化过程对PLMs的学习也揭示了生成对抗提示以误导模型的见解，引发了对这一范式对抗性脆弱性的担忧。最近的研究表明，可以生成通用对抗触发器（UATs）来改变不仅目标PLMs的预测，还有对应Prompt-based Fine-tuning Models（PFMs）的预测。然而，以前作品中发现的UATs通常是无法阅读的令牌或字符。

    arXiv:2403.16432v1 Announce Type: cross  Abstract: Prompt-based learning is a new language model training paradigm that adapts the Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes the performance benchmarks across various natural language processing (NLP) tasks. Instead of using a fixed prompt template to fine-tune the model, some research demonstrates the effectiveness of searching for the prompt via optimization. Such prompt optimization process of prompt-based learning on PLMs also gives insight into generating adversarial prompts to mislead the model, raising concerns about the adversarial vulnerability of this paradigm. Recent studies have shown that universal adversarial triggers (UATs) can be generated to alter not only the predictions of the target PLMs but also the prediction of corresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based learning paradigm. However, UATs found in previous works are often unreadable tokens or characters a
    
[^50]: 是否存在适用于所有情况的信息抽取一体化模型？重新审视任务定义偏见

    Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases

    [https://arxiv.org/abs/2403.16396](https://arxiv.org/abs/2403.16396)

    重新审视信息抽取中的任务定义偏见现象，提出了一个多阶段框架来衡量、感知和缓解这种偏见，实验证明该框架有效性。

    

    定义偏见是一种负面现象，可能会误导模型。信息抽取中的定义偏见不仅存在于来自不同领域的数据集之间，还存在于分享相同领域的数据集内部。本文确定了信息抽取中的两种定义偏见类型：在信息抽取数据集之间的偏见，以及在信息抽取数据集与指导调优数据集之间的偏见。为了系统地研究定义偏见，我们进行了三项探究性实验来定量分析它，并发现统一信息抽取和大型语言模型在解决定义偏见方面的局限性。为了减轻信息抽取中的定义偏见，我们提出了一个由定义偏见测量、偏见感知微调和任务特定偏见缓解组成的多阶段框架。实验结果表明我们的框架在应对定义偏见方面的有效性。本文资源可在htt找到

    arXiv:2403.16396v1 Announce Type: new  Abstract: Definition bias is a negative phenomenon that can mislead models. Definition bias in information extraction appears not only across datasets from different domains but also within datasets sharing the same domain. We identify two types of definition bias in IE: bias among information extraction datasets and bias between information extraction datasets and instruction tuning datasets. To systematically investigate definition bias, we conduct three probing experiments to quantitatively analyze it and discover the limitations of unified information extraction and large language models in solving definition bias. To mitigate definition bias in information extraction, we propose a multi-stage framework consisting of definition bias measurement, bias-aware fine-tuning, and task-specific bias mitigation. Experimental results demonstrate the effectiveness of our framework in addressing definition bias. Resources of this paper can be found at htt
    
[^51]: 文本到图像生成中现象空间中的偏差阻碍了泛化

    Skews in the Phenomenon Space Hinder Generalization in Text-to-Image Generation

    [https://arxiv.org/abs/2403.16394](https://arxiv.org/abs/2403.16394)

    文本到图像生成领域的泛化问题源于现象空间中的偏差，需要量化和解决语言和视觉偏差，以提高泛化性能

    

    文本到图像生成领域的文献存在着关于如何忠实地组合实体与关系的问题。然而，缺乏对实体-关系组合如何有效学习的形式化理解。此外，反映问题结构的基础现象空间并不明确定义，导致为了希望泛化在大规模预训练中得以展现而不断追求更多数据。我们猜测基础现象学覆盖范围并未按比例扩展，导致所呈现现象的偏差对泛化造成了伤害。我们引入了统计度量标准来量化数据集中的语言和视觉偏差，用于关系学习，并表明文本到图像生成的泛化失败直接源于现象学覆盖不完整或不平衡。我们首先在合成领域进行实验和演示

    arXiv:2403.16394v1 Announce Type: cross  Abstract: The literature on text-to-image generation is plagued by issues of faithfully composing entities with relations. But there lacks a formal understanding of how entity-relation compositions can be effectively learned. Moreover, the underlying phenomenon space that meaningfully reflects the problem structure is not well-defined, leading to an arms race for larger quantities of data in the hope that generalization emerges out of large-scale pretraining. We hypothesize that the underlying phenomenological coverage has not been proportionally scaled up, leading to a skew of the presented phenomenon which harms generalization. We introduce statistical metrics that quantify both the linguistic and visual skew of a dataset for relational learning, and show that generalization failures of text-to-image generation are a direct result of incomplete or unbalanced phenomenological coverage. We first perform experiments in a synthetic domain and demo
    
[^52]: 逐步合成：工具、模板和LLM作为数据生成器用于基于推理的图表VQA

    Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA

    [https://arxiv.org/abs/2403.16385](https://arxiv.org/abs/2403.16385)

    使用LLM作为数据生成器，通过逐步合成策略将复杂问题分解为逐步子问题，利用外部工具生成最终答案，以解决图表VQA模型在复杂推理问题上的表现不佳。

    

    理解图表和图形等数据可视化需要对视觉元素和数字进行推理。尽管在提取式问题上表现出色，但当前的图表视觉问答（chart VQA）模型在复杂推理问题上表现不佳。本文通过数据增强来解决推理能力不足的问题。我们利用已经表现出强大推理能力的大型语言模型（LLMs）作为自动数据标注器，为图表图像生成问题-答案注释。我们方法的关键创新在于“逐步合成”策略：基于LLM的数据生成器学习将复杂问题分解为逐步子问题（原理），然后使用外部工具（即Python）推导出最终答案。这种逐步生成过程是在使用基于模板的QA生成管道生成的合成数据上训练的。实验结果突出显示

    arXiv:2403.16385v1 Announce Type: cross  Abstract: Understanding data visualizations like charts and plots requires reasoning about both visual elements and numerics. Although strong in extractive questions, current chart visual question answering (chart VQA) models suffer on complex reasoning questions. In this work, we address the lack of reasoning ability by data augmentation. We leverage Large Language Models (LLMs), which have shown to have strong reasoning ability, as an automatic data annotator that generates question-answer annotations for chart images. The key innovation in our method lies in the Synthesize Step-by-Step strategy: our LLM-based data generator learns to decompose the complex question into step-by-step sub-questions (rationales), which are then used to derive the final answer using external tools, i.e. Python. This step-wise generation procedure is trained on synthetic data generated using a template-based QA generation pipeline. Experimental results highlight th
    
[^53]: 基于LLM编辑的增强式分面生成

    Enhanced Facet Generation with LLM Editing

    [https://arxiv.org/abs/2403.16345](https://arxiv.org/abs/2403.16345)

    提出了一种通过利用搜索引擎获取的文档和相关查询来增强分面预测的策略，并提出了专注于仅使用查询作为输入来预测分面的框架

    

    在信息检索中，用户查询的分面识别是一项重要任务。如果搜索服务能够识别用户查询的分面，就有潜力为用户提供更广泛的搜索结果。先前的研究可以通过利用搜索引擎获取的检索文档和相关查询来增强分面预测。然而，在将搜索引擎作为模型的一部分进行扩展到其他应用时存在挑战。第一，搜索引擎不断更新。因此，在训练和测试期间附加信息可能会有变化，这可能会降低性能。第二个挑战是公共搜索引擎无法搜索内部文件。因此，需要构建一个单独的搜索系统来将公司内部文档纳入其中。我们提出了两种策略，专注于一个可以仅通过查询作为输入来预测分面的框架。

    arXiv:2403.16345v1 Announce Type: cross  Abstract: In information retrieval, facet identification of a user query is an important task. If a search service can recognize the facets of a user's query, it has the potential to offer users a much broader range of search results. Previous studies can enhance facet prediction by leveraging retrieved documents and related queries obtained through a search engine. However, there are challenges in extending it to other applications when a search engine operates as part of the model. First, search engines are constantly updated. Therefore, additional information may change during training and test, which may reduce performance. The second challenge is that public search engines cannot search for internal documents. Therefore, a separate search system needs to be built to incorporate documents from private domains within the company. We propose two strategies that focus on a framework that can predict facets by taking only queries as input withou
    
[^54]: 生物医学与健康信息学中的大型语言模型：一项文献计量学综述

    Large Language Models in Biomedical and Health Informatics: A Bibliometric Review

    [https://arxiv.org/abs/2403.16303](https://arxiv.org/abs/2403.16303)

    LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。

    

    大型语言模型（LLMs）迅速成为生物医学与健康信息学（BHI）中的重要工具，为分析数据、治疗患者和开展研究提供了新的方式。本文献计量学综述旨在通过检查自2022年至2023年的研究文章和合作网络，全面展示LLMs在BHI中的应用情况。它进一步探讨了LLMs如何可以改进各种BHI领域中的自然语言处理（NLP）应用，如医学诊断、患者参与、电子健康记录管理和个性化医学。为此，我们的文献计量学综述确定了关键趋势，绘制了研究网络，并突出了这个快速发展领域的主要进展。最后，它讨论了在BHI中使用LLMs的伦理关切和实际挑战，如数据隐私和可靠的医疗建议。展望未来，我们考虑LLMs如何进一步改变生物医学研究。

    arXiv:2403.16303v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have rapidly become important tools in Biomedical and Health Informatics (BHI), enabling new ways to analyze data, treat patients, and conduct research. This bibliometric review aims to provide a panoramic view of how LLMs have been used in BHI by examining research articles and collaboration networks from 2022 to 2023. It further explores how LLMs can improve Natural Language Processing (NLP) applications in various BHI areas like medical diagnosis, patient engagement, electronic health record management, and personalized medicine. To do this, our bibliometric review identifies key trends, maps out research networks, and highlights major developments in this fast-moving field. Lastly, it discusses the ethical concerns and practical challenges of using LLMs in BHI, such as data privacy and reliable medical recommendations. Looking ahead, we consider how LLMs could further transform biomedical research as we
    
[^55]: LexDrafter: 利用检索增强生成为立法文件起草术语

    LexDrafter: Terminology Drafting for Legislative Documents using Retrieval Augmented Generation

    [https://arxiv.org/abs/2403.16295](https://arxiv.org/abs/2403.16295)

    LexDrafter是一种框架，利用检索增强生成和现有法律文件中的术语定义，帮助起草法规文件中的“Definitions”文章。

    

    随着欧盟立法文件数量的增加，新术语及其定义的数量也在增加。按照欧洲议会、理事会和委员会的联合实用指南的规定，在法律文件中使用的术语应保持一致，相同概念应在不脱离其在普通、法律或技术语言中含义的前提下表达。因此，在起草新的立法文件时，拥有一个框架，能够提供有关现有定义的见解，并根据文件的上下文帮助定义新术语，将支持不同法规下的这种统一法律定义，并避免歧义。在本文中，我们提出了LexDrafter，一种利用检索增强生成(RAG)和不同立法文件中现有术语定义来协助起草立法文件的“Definitions”文章的框架。

    arXiv:2403.16295v1 Announce Type: new  Abstract: With the increase in legislative documents at the EU, the number of new terms and their definitions is increasing as well. As per the Joint Practical Guide of the European Parliament, the Council and the Commission, terms used in legal documents shall be consistent, and identical concepts shall be expressed without departing from their meaning in ordinary, legal, or technical language. Thus, while drafting a new legislative document, having a framework that provides insights about existing definitions and helps define new terms based on a document's context will support such harmonized legal definitions across different regulations and thus avoid ambiguities. In this paper, we present LexDrafter, a framework that assists in drafting Definitions articles for legislative documents using retrieval augmented generation (RAG) and existing term definitions present in different legislative documents. For this, definition elements are built by e
    
[^56]: 连接点: 利用检索短语图推断专利短语相似性

    Connecting the Dots: Inferring Patent Phrase Similarity with Retrieved Phrase Graphs

    [https://arxiv.org/abs/2403.16265](https://arxiv.org/abs/2403.16265)

    提出了一种利用检索短语图推断专利短语相似性的方法，通过构建短语图，补充专利短语的全局上下文信息，并利用自监督学习目标来优化嵌入和图参数。

    

    我们研究了专利短语相似性推断任务，该任务衡量两个专利短语之间的语义相似性。由于专利文件采用法律和高度技术性的语言，现有使用局部上下文信息的语义文本相似度方法在推断专利短语相似性方面表现不佳。为了解决这个问题，我们引入了一种图增强方法，以放大专利短语的全局上下文信息。对于每个专利短语，我们构建一个短语图，将其连接到其焦点专利以及引用/被引用这些焦点专利的专利列表。然后，增强的短语嵌入是从将其局部上下文嵌入与短语图内部的全局嵌入相结合中得出的。我们进一步提出了一种自监督学习目标，利用检索的拓扑来调整两个方面的嵌入：上下文化嵌入和图参数，从而最终提高推断结果的准确性。

    arXiv:2403.16265v1 Announce Type: new  Abstract: We study the patent phrase similarity inference task, which measures the semantic similarity between two patent phrases. As patent documents employ legal and highly technical language, existing semantic textual similarity methods that use localized contextual information do not perform satisfactorily in inferring patent phrase similarity. To address this, we introduce a graph-augmented approach to amplify the global contextual information of the patent phrases. For each patent phrase, we construct a phrase graph that links to its focal patents and a list of patents that are either cited by or cite these focal patents. The augmented phrase embedding is then derived from combining its localized contextual embedding with its global embedding within the phrase graph. We further propose a self-supervised learning objective that capitalizes on the retrieved topology to refine both the contextualized embedding and the graph parameters in an end
    
[^57]: 大型语言模型为传统主题建模方法提供了另一种选择

    Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling

    [https://arxiv.org/abs/2403.16248](https://arxiv.org/abs/2403.16248)

    大型语言模型作为主题建模的替代方法，能够生成相关主题标题并遵循人类指南来精细化和合并主题

    

    主题建模作为一种成熟的无监督技术，在自动检测文档语料库中的重要主题方面得到了广泛应用。然而，经典的主题建模方法（例如LDA）存在某些缺点，例如缺乏语义理解和主题重叠的存在。本文研究了大型语言模型（LLMs）作为揭示广泛文本语料库中潜在主题的一种替代方法的潜力。为此，我们引入了一个框架，促使LLMs从给定的一组文档中生成主题，并建立了评估协议来评估LLMs的聚类效果。我们的发现表明，LLMs在适当的提示下可以脱颖而出作为一种可行的替代方案，能够生成相关的主题标题并遵循人类指南来精细化和合并主题。通过深入的实验和评估，我们总结了这种优势。

    arXiv:2403.16248v1 Announce Type: new  Abstract: Topic modelling, as a well-established unsupervised technique, has found extensive use in automatically detecting significant topics within a corpus of documents. However, classic topic modelling approaches (e.g., LDA) have certain drawbacks, such as the lack of semantic understanding and the presence of overlapping topics. In this work, we investigate the untapped potential of large language models (LLMs) as an alternative for uncovering the underlying topics within extensive text corpora. To this end, we introduce a framework that prompts LLMs to generate topics from a given set of documents and establish evaluation protocols to assess the clustering efficacy of LLMs. Our findings indicate that LLMs with appropriate prompts can stand out as a viable alternative, capable of generating relevant topic titles and adhering to human guidelines to refine and merge topics. Through in-depth experiments and evaluation, we summarise the advantage
    
[^58]: 使用元启发方法改进序列到序列模型，用于抽象文本摘要

    Improving Sequence-to-Sequence Models for Abstractive Text Summarization Using Meta Heuristic Approaches

    [https://arxiv.org/abs/2403.16247](https://arxiv.org/abs/2403.16247)

    改进使用元启发方法的序列到序列模型，以提高抽象文本摘要的准确性和有效性

    

    随着人类社会过渡到信息时代，我们注意力的减少是一个必然趋势，花时间阅读冗长新闻文章的人群正在迅速减少，而对简洁信息的需求比以往任何时候都更高。因此，通过简洁地总结顶级新闻文章和最直观的标题，提供重要新闻的快速概述是至关重要的。人类在尝试进行摘要时，会从来源中提取基本信息，并从原始提取中添加有用短语和语法注释。人类有创建抽象的独特能力。然而，自动摘要是一个复杂的问题。对于神经抽象文本摘要，使用序列到序列（seq2seq）模型的应用程度不断增加。已经提出了许多创新策略来进一步发展当前的seq2seq模型，使其能够处理差异

    arXiv:2403.16247v1 Announce Type: new  Abstract: As human society transitions into the information age, reduction in our attention span is a contingency, and people who spend time reading lengthy news articles are decreasing rapidly and the need for succinct information is higher than ever before. Therefore, it is essential to provide a quick overview of important news by concisely summarizing the top news article and the most intuitive headline. When humans try to make summaries, they extract the essential information from the source and add useful phrases and grammatical annotations from the original extract. Humans have a unique ability to create abstractions. However, automatic summarization is a complicated problem to solve. The use of sequence-to-sequence (seq2seq) models for neural abstractive text summarization has been ascending as far as prevalence. Numerous innovative strategies have been proposed to develop the current seq2seq models further, permitting them to handle diffe
    
[^59]: SQL-Encoder: 通过上下文感知编码器改进NL2SQL的上下文学习

    SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder

    [https://arxiv.org/abs/2403.16204](https://arxiv.org/abs/2403.16204)

    本文研究了通过上下文感知编码器改进NL2SQL模型中上下文学习的方法，并提出了一个准确估计查询相似性的模型，通过170k个问题对数据集进行训练，能够优于其他竞争模型，提升NL2SQL模型的性能。

    

    检测查询之间的结构相似性对于在上下文学习模型中选择示例至关重要。然而，仅基于查询的自然语言表达来评估结构相似性，而不考虑SQL查询，会带来显著的挑战。本文探讨了这种相似度度量的重要性，并提出了一个准确估计它的模型。为了实现这一目标，我们利用了一个包含17万个问题对的数据集，经过精心策划，用于训练一个相似性预测模型。我们的综合评估表明，所提出的模型巧妙地捕捉到了问题之间的结构相似性，这体现在Kendall-Tau距离和precision@k指标的改善上。值得注意的是，我们的模型优于OpenAI和Cohere的竞争性嵌入模型。此外，与这些竞争性模型相比，我们提出的编码器提升了NL2SQL模型的下游性能。

    arXiv:2403.16204v1 Announce Type: new  Abstract: Detecting structural similarity between queries is essential for selecting examples in in-context learning models. However, assessing structural similarity based solely on the natural language expressions of queries, without considering SQL queries, presents a significant challenge. This paper explores the significance of this similarity metric and proposes a model for accurately estimating it. To achieve this, we leverage a dataset comprising 170k question pairs, meticulously curated to train a similarity prediction model. Our comprehensive evaluation demonstrates that the proposed model adeptly captures the structural similarity between questions, as evidenced by improvements in Kendall-Tau distance and precision@k metrics. Notably, our model outperforms strong competitive embedding models from OpenAI and Cohere. Furthermore, compared to these competitive models, our proposed encoder enhances the downstream performance of NL2SQL models
    
[^60]: ALoRA: 为大型语言模型微调分配低秩适应性

    ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models

    [https://arxiv.org/abs/2403.16187](https://arxiv.org/abs/2403.16187)

    ALoRA创新地提出了分配低秩适应性（ALoRA）方法，通过动态调整适应过程中的固有秩，从而解决了在微调大型语言模型时固定固有秩带来的问题。

    

    参数高效的微调（PEFT）因其在大型语言模型时代的有效性和效率而被广泛研究。低秩适应性（LoRA）已经展示出作为一种流行和代表性方法的令人钦佩的性能。然而，它是使用固定的固有秩来实现的，这可能不是下游任务的理想设置。认识到需要更灵活的下游任务适应性，我们将LoRA的方法学扩展到一种创新的方法，我们将其称为分配低秩适应性（ALoRA），这样可以在适应过程中动态调整固有秩。首先，我们提出了一种新颖的方法，AB-LoRA，可以有效地估计每个LoRA等级的重要性得分。其次，受AB-LoRA的指导，我们逐渐修剪了过多且产生负面影响的LoRA等级，并将被修剪的LoRA预算分配给需要更高等级的重要Transformer模块。我们已经在各种实验上进行了研究。

    arXiv:2403.16187v1 Announce Type: new  Abstract: Parameter-efficient fine-tuning (PEFT) is widely studied for its effectiveness and efficiency in the era of large language models. Low-rank adaptation (LoRA) has demonstrated commendable performance as a popular and representative method. However, it is implemented with a fixed intrinsic rank that might not be the ideal setting for the downstream tasks. Recognizing the need for more flexible downstream task adaptation, we extend the methodology of LoRA to an innovative approach we call allocating low-rank adaptation (ALoRA) that enables dynamic adjustments to the intrinsic rank during the adaptation process. First, we propose a novel method, AB-LoRA, that can effectively estimate the importance score of each LoRA rank. Second, guided by AB-LoRA, we gradually prune abundant and negatively impacting LoRA ranks and allocate the pruned LoRA budgets to important Transformer modules needing higher ranks. We have conducted experiments on variou
    
[^61]: 子空间防御：通过学习干净信号的子空间来丢弃对抗性扰动

    Subspace Defense: Discarding Adversarial Perturbations by Learning a Subspace for Clean Signals

    [https://arxiv.org/abs/2403.16176](https://arxiv.org/abs/2403.16176)

    通过学习一个仅存在干净信号特征的子空间并丢弃扰动特征，使得深度神经网络能够更好地区分对抗性示例。

    

    深度神经网络(DNNs)极易受到对抗性攻击的影响，即在正常示例上放置精心制作的扰动以欺骗DNNs。为了更好地理解这类攻击，需要对对抗性示例携带的特征进行刻画。本文通过对样本特征子空间进行谱分析来解决这一挑战。我们首先经验性地展示，无论是干净信号还是对抗性扰动的特征都是冗余的，并分别在低维线性子空间中展开，互相之间重叠很小，而经典的低维子空间投影可以将扰动特征排除在干净信号子空间之外。这使得DNNs能够学习一个仅存在干净信号特征的子空间，而丢弃扰动特征，这有助于区分对抗性示例。为了防止残余的扰动，提出了一种二次最优方向残差网络(QPRN)。

    arXiv:2403.16176v1 Announce Type: cross  Abstract: Deep neural networks (DNNs) are notoriously vulnerable to adversarial attacks that place carefully crafted perturbations on normal examples to fool DNNs. To better understand such attacks, a characterization of the features carried by adversarial examples is needed. In this paper, we tackle this challenge by inspecting the subspaces of sample features through spectral analysis. We first empirically show that the features of either clean signals or adversarial perturbations are redundant and span in low-dimensional linear subspaces respectively with minimal overlap, and the classical low-dimensional subspace projection can suppress perturbation features out of the subspace of clean signals. This makes it possible for DNNs to learn a subspace where only features of clean signals exist while those of perturbations are discarded, which can facilitate the distinction of adversarial examples. To prevent the residual perturbations that is ine
    
[^62]: 利用语义重建减少视觉-语言模型中的幻觉

    Exploiting Semantic Reconstruction to Mitigate Hallucinations in Vision-Language Models

    [https://arxiv.org/abs/2403.16167](https://arxiv.org/abs/2403.16167)

    通过准确定位和惩罚幻觉标记，ESREAL引入了一种新颖的无监督学习框架，通过语义重建来抑制生成幻觉，解决了视觉-语言模型中幻觉问题。

    

    视觉-语言模型中的幻觉对其可靠性构成重大挑战，特别是在生成长标题时。当前方法无法准确识别和减轻这些幻觉。为了解决这个问题，我们引入了ESREAL，这是一个新颖的无监督学习框架，旨在通过准确定位和惩罚幻觉标记来抑制幻觉生成。最初，ESREAL根据生成的标题创建一个重建图像，并将其对应区域与原始图像的区域对齐。这种语义重建有助于识别生成标题中的标记级幻觉的存在和类型。随后，ESREAL通过评估对齐区域的语义相似性来计算标记级幻觉分数，基于幻觉的类型。最后，ESREAL采用一种近端策略优化算法，进行...

    arXiv:2403.16167v1 Announce Type: cross  Abstract: Hallucinations in vision-language models pose a significant challenge to their reliability, particularly in the generation of long captions. Current methods fall short of accurately identifying and mitigating these hallucinations. To address this issue, we introduce ESREAL, a novel unsupervised learning framework designed to suppress the generation of hallucinations through accurate localization and penalization of hallucinated tokens. Initially, ESREAL creates a reconstructed image based on the generated caption and aligns its corresponding regions with those of the original image. This semantic reconstruction aids in identifying both the presence and type of token-level hallucinations within the generated caption. Subsequently, ESREAL computes token-level hallucination scores by assessing the semantic similarity of aligned regions based on the type of hallucination. Finally, ESREAL employs a proximal policy optimization algorithm, wh
    
[^63]: 韩国生物医学语料库（KBMC）用于医学命名实体识别

    Korean Bio-Medical Corpus (KBMC) for Medical Named Entity Recognition

    [https://arxiv.org/abs/2403.16158](https://arxiv.org/abs/2403.16158)

    利用ChatGPT构建了韩国生物医学语料库（KBMC），在医学命名实体识别方面取得了显著的进展，证明了使用专门工具和数据集在医学领域的语言处理中的重要性。

    

    arXiv:2403.16158v1 公告类型: 新 抽象: 命名实体识别（NER）在医学自然语言处理（NLP）中发挥着至关重要的作用。然而，尚无针对韩语的开源医学NER数据集。为解决这一问题，我们利用ChatGPT辅助构建了KBMC（韩国生物医学语料库），现在向公众展示。使用KBMC数据集，我们注意到，与在一般韩语NER数据集上训练的模型相比，医学NER性能提高了惊人的20%。这项研究强调了利用像ChatGPT这样的专门工具和数据集在增强诸如医疗保健等专业领域的语言处理方面的重要优势和重要性。

    arXiv:2403.16158v1 Announce Type: new  Abstract: Named Entity Recognition (NER) plays a pivotal role in medical Natural Language Processing (NLP). Yet, there has not been an open-source medical NER dataset specifically for the Korean language. To address this, we utilized ChatGPT to assist in constructing the KBMC (Korean Bio-Medical Corpus), which we are now presenting to the public. With the KBMC dataset, we noticed an impressive 20% increase in medical NER performance compared to models trained on general Korean NER datasets. This research underscores the significant benefits and importance of using specialized tools and datasets, like ChatGPT, to enhance language processing in specialized fields such as healthcare.
    
[^64]: 一种基于投影的概念去除方法对数据集的影响

    What Happens to a Dataset Transformed by a Projection-based Concept Removal Method?

    [https://arxiv.org/abs/2403.16142](https://arxiv.org/abs/2403.16142)

    一种基于投影的概念去除方法会在转换后的数据集中注入强大的统计依赖性，并导致表示空间高度结构化，使得可以通过应用反聚类方法重建原始标记。

    

    我们研究了使用线性投影方法从语言表示中去除概念信息的方法的行为，并考虑了经过这种方法转换的数据集会发生什么。理论分析和对真实世界和合成数据的实验表明，这些方法会向转换后的数据集中注入强大的统计依赖性。应用此类方法后，表示空间具有高度结构化：在转换后的空间中，一个实例倾向于位于相反标签的实例附近。因此，在某些情况下，可以通过应用反聚类方法来重建原始标记。

    arXiv:2403.16142v1 Announce Type: cross  Abstract: We investigate the behavior of methods that use linear projections to remove information about a concept from a language representation, and we consider the question of what happens to a dataset transformed by such a method. A theoretical analysis and experiments on real-world and synthetic data show that these methods inject strong statistical dependencies into the transformed datasets. After applying such a method, the representation space is highly structured: in the transformed space, an instance tends to be located near instances of the opposite label. As a consequence, the original labeling can in some cases be reconstructed by applying an anti-clustering method.
    
[^65]: 一点小漏洞就会使一艘巨轮沉没：从头到尾对大型语言模型的透明度进行调查

    A Little Leak Will Sink a Great Ship: Survey of Transparency for Large Language Models from Start to Finish

    [https://arxiv.org/abs/2403.16139](https://arxiv.org/abs/2403.16139)

    对大型语言模型的透明度进行调查，探讨泄漏问题的影响，建立了泄漏率、生成率和检测率这三个标准，并实验阐明了泄漏率与输出率以及检测率之间的关系。

    

    大型语言模型(LLMs)是在海量网络抓取的语料库上训练的。这带来了泄漏风险，包括个人信息、受版权保护的文本和基准数据集。这种泄漏导致人类对人工智能的信任受损，因为可能会未经授权地生成内容或高估性能。我们建立了关于泄漏问题的三个标准：(1)泄漏率：训练数据中泄漏数据的比例，(2)生成率：生成泄漏数据的难易程度，以及(3)检测率：检测泄漏数据与非泄漏数据的性能。尽管泄漏率是数据泄漏问题的根源，但人们不清楚它会如何影响输出率和检测率。在本文中，我们进行了实验调查，阐明了个人信息、受版权保护的文本和基准数据的泄漏率与输出率以及检测率之间的关系。

    arXiv:2403.16139v1 Announce Type: new  Abstract: Large Language Models (LLMs) are trained on massive web-crawled corpora. This poses risks of leakage, including personal information, copyrighted texts, and benchmark datasets. Such leakage leads to undermining human trust in AI due to potential unauthorized generation of content or overestimation of performance. We establish the following three criteria concerning the leakage issues: (1) leakage rate: the proportion of leaked data in training data, (2) output rate: the ease of generating leaked data, and (3) detection rate: the detection performance of leaked versus non-leaked data. Despite the leakage rate being the origin of data leakage issues, it is not understood how it affects the output rate and detection rate. In this paper, we conduct an experimental survey to elucidate the relationship between the leakage rate and both the output rate and detection rate for personal information, copyrighted texts, and benchmark data. Additiona
    
[^66]: 一项关于词汇歧义检测和词义消歧的调查

    A Survey on Lexical Ambiguity Detection and Word Sense Disambiguation

    [https://arxiv.org/abs/2403.16129](https://arxiv.org/abs/2403.16129)

    本文调查了词汇歧义检测和词义消歧领域中的最新技术，介绍了词义扩展和神经肌肉接近法等创新方法，以预测新词义来提高消歧的准确性。

    

    本文探讨了在自然语言处理领域中专注于理解和解决语言中歧义的技术，突出了语言现象如多义性和同音异义的复杂性以及它们对计算模型的影响。重点放在了词义消歧（WSD）上，概述了从深度学习技术到利用词汇资源和词义网（如WordNet）的多样化方法。本文介绍了诸如词义扩展（WSE）和神经肌肉接近法这样的尖端方法，通过预测新的词义来提高消歧准确度。它考察了生物医学消歧和语言特定优化的具体应用，并讨论了认知隐喻在话语分析中的重要性。研究确定了该领域的持久挑战，例如语义标注语料库的稀缺性和

    arXiv:2403.16129v1 Announce Type: new  Abstract: This paper explores techniques that focus on understanding and resolving ambiguity in language within the field of natural language processing (NLP), highlighting the complexity of linguistic phenomena such as polysemy and homonymy and their implications for computational models. Focusing extensively on Word Sense Disambiguation (WSD), it outlines diverse approaches ranging from deep learning techniques to leveraging lexical resources and knowledge graphs like WordNet. The paper introduces cutting-edge methodologies like word sense extension (WSE) and neuromyotonic approaches, enhancing disambiguation accuracy by predicting new word senses. It examines specific applications in biomedical disambiguation and language specific optimisation and discusses the significance of cognitive metaphors in discourse analysis. The research identifies persistent challenges in the field, such as the scarcity of sense annotated corpora and the complexity 
    
[^67]: WangchanLion与WangchanX MRC评估

    WangchanLion and WangchanX MRC Eval

    [https://arxiv.org/abs/2403.16127](https://arxiv.org/abs/2403.16127)

    WangchanLion是一个专注于泰语机器阅读理解的指令微调模型，在0-shot和1-shot设置下能够理解上下文并产生与参考答案一致的回答，同时提出了新的评估方案。

    

    本技术报告描述了WangchanLion的开发过程，这是一个专注于泰语机器阅读理解（MRC）的指令微调模型。我们的模型基于SEA-LION和一系列指令跟随数据集。为了促进开放研究和可重复性，我们公开发布了所有训练数据、代码和最终模型权重，采用Apache-2许可证。为了评估上下文理解能力，我们使用两个泰语MRC数据集XQuAD和Iapp_wiki_qa_squad进行了广泛的实验研究。实验结果表明，在0-shot和1-shot设置下，模型能够理解上下文并产生与参考答案一致的回答。此外，我们的评估超越了传统的MRC。我们提出了一个新的评估方案，评估答案的正确性、帮助性、简洁性和上下文性。评估结果揭示了我们如何改进模型的见解。

    arXiv:2403.16127v1 Announce Type: cross  Abstract: This technical report describes the development of WangchanLion, an instruction fine-tuned model focusing on Machine Reading Comprehension (MRC) in the Thai language. Our model is based on SEA-LION and a collection of instruction following datasets. To promote open research and reproducibility, we publically release all training data, code, and the final model weights under the Apache-2 license. To assess the contextual understanding capability, we conducted extensive experimental studies using two Thai MRC datasets, XQuAD and Iapp_wiki_qa_squad. Experimental results demonstrate the model's ability to comprehend the context and produce an answer faithful to the reference one in 0-shot and 1-shot settings. In addition, our evaluation goes beyond the traditional MRC. We propose a new evaluation scheme assessing the answer's correctness, helpfulness, conciseness, and contextuality. Evaluation results provide insight into how we can improv
    
[^68]: 一份法国假新闻的多标签数据集：人类与机器视角

    A Multi-Label Dataset of French Fake News: Human and Machine Insights

    [https://arxiv.org/abs/2403.16099](https://arxiv.org/abs/2403.16099)

    通过建立一份包括 100 篇文档的多标签数据集 OBSINFOX，研究了人类与机器在认定假新闻特征上的差异，并发现了语料库中讽刺文本的普遍存在。

    

    我们提出了一个由 8 位注释者使用 11 个标签注释的来自 17 个法国被专家机构认为不可靠的新闻来源选取的 100 篇文档的语料库 OBSINFOX。通过收集比通常更多的标签和注释者，我们可以识别人类认为具有代表性的假新闻的特征，并将其与自动分类器的预测进行比较。我们使用 Gate Cloud 进行主题和体裁分析，这表明语料库中类似讽刺的文本普遍存在。然后我们使用 VAGO 主观性分析器及其神经版本，以澄清标签“主观”与标签“假新闻”之间的联系。该带有注释的数据集可通过以下网址在线获取：https://github.com/obs-info/obsinfox

    arXiv:2403.16099v1 Announce Type: new  Abstract: We present a corpus of 100 documents, OBSINFOX, selected from 17 sources of French press considered unreliable by expert agencies, annotated using 11 labels by 8 annotators. By collecting more labels than usual, by more annotators than is typically done, we can identify features that humans consider as characteristic of fake news, and compare them to the predictions of automated classifiers. We present a topic and genre analysis using Gate Cloud, indicative of the prevalence of satire-like text in the corpus. We then use the subjectivity analyzer VAGO, and a neural version of it, to clarify the link between ascriptions of the label Subjective and ascriptions of the label Fake News. The annotated dataset is available online at the following url: https://github.com/obs-info/obsinfox   Keywords: Fake News, Multi-Labels, Subjectivity, Vagueness, Detail, Opinion, Exaggeration, French Press
    
[^69]: LLM作为阿拉伯编程语言的编译器

    LLMs as Compiler for Arabic Programming Language

    [https://arxiv.org/abs/2403.16087](https://arxiv.org/abs/2403.16087)

    本文介绍了APL（阿拉伯编程语言），它使用LLM作为半编译器，将阿拉伯文本代码转换为Python代码并运行，构建了完整的流水线。

    

    在这篇论文中，我们介绍了APL (Arabic Programming Language)，它使用大型语言模型(LLM)作为半编译器，将阿拉伯文本代码转换为Python代码，然后运行该代码。设计了从APL文本结构到提示（使用提示工程）再到使用PyRunner运行生成的Python代码的完整流水线。该项目包括三部分：Python库，具有简单界面的游乐场和这篇研究论文。

    arXiv:2403.16087v1 Announce Type: cross  Abstract: In this paper we introduce APL (Arabic Programming Language) that uses Large language models (LLM) as semi-compiler to covert Arabic text code to python code then run the code. Designing a full pipeline from the structure of the APL text then a prompt (using prompt engineering) then running the prodcued python code using PyRunner. This project has a three parts first python library, a playground with simple interface and this research paper.
    
[^70]: 在指导式大型语言模型时代的论证质量评估

    Argument Quality Assessment in the Age of Instruction-Following Large Language Models

    [https://arxiv.org/abs/2403.16084](https://arxiv.org/abs/2403.16084)

    论文讨论了在指导式大型语言模型时代，如何通过引入论证理论和情景，使其能够更可靠地评估争议问题中的论证质量。

    

    争议问题上的论证在NLP研究中受到广泛关注，由于其对观点形成、决策制定、写作教育等方面的潜在影响。在任何此类应用中，一个关键任务是评估论证的质量，但这也是一个特别具有挑战性的任务。本文从对论证质量研究的简要调查开始，我们确定质量概念的多样性和其感知的主观性是实现论证质量评估实质性进展的主要障碍。我们认为，指导式大型语言模型（LLMs）利用跨上下文的知识能力，能够实现更可靠的评估。它们不仅需要将LLMs微调为评估任务的领先者，还需要系统地用论证理论和情景以及解决问题的方式对其进行指导。

    arXiv:2403.16084v1 Announce Type: new  Abstract: The computational treatment of arguments on controversial issues has been subject to extensive NLP research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. A critical task in any such application is the assessment of an argument's quality - but it is also particularly challenging. In this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment. We argue that the capabilities of instruction-following large language models (LLMs) to leverage knowledge across contexts enable a much more reliable assessment. Rather than just fine-tuning LLMs towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to sol
    
[^71]: Qibo: 一种用于中医领域的大型语言模型

    Qibo: A Large Language Model for Traditional Chinese Medicine

    [https://arxiv.org/abs/2403.16056](https://arxiv.org/abs/2403.16056)

    本论文在中医领域构建了专业语料库，基于LLaMA成功开发了首个经过完整训练的Qibo模型，并推出了用于评估LLMs性能的Qibo基准测试。

    

    在人工智能领域，大型语言模型(LLMs)展示了在用户意图理解和响应方面取得的显著进展，在许多专业领域，包括医学、法律和金融。然而，在中医领域，LLMs的性能提升受到挑战，其原因在于中医理论与现代医学之间的根本差异，以及缺乏专业语料库资源。本文旨在构建和整理中医领域的专业语料库，赋予大型模型具有中医理论特色的专业知识，并成功基于LLaMA开发了Qibo模型，这是中医领域第一个经过完整训练过程（从预训练到监督微调）的LLM。此外，我们开发了Qibo基准测试，这是一个用于评估LLMs性能的专门工具。

    arXiv:2403.16056v1 Announce Type: cross  Abstract: In the field of Artificial Intelligence, Large Language Models (LLMs) have demonstrated significant advances in user intent understanding and response in a number of specialized domains, including medicine, law, and finance. However, in the unique domain of traditional Chinese medicine (TCM), the performance enhancement of LLMs is challenged by the essential differences between its theories and modern medicine, as well as the lack of specialized corpus resources. In this paper, we aim to construct and organize a professional corpus in the field of TCM, to endow the large model with professional knowledge that is characteristic of TCM theory, and to successfully develop the Qibo model based on LLaMA, which is the first LLM in the field of TCM to undergo a complete training process from pre-training to Supervised Fine-Tuning (SFT). Furthermore, we develop the Qibo-benchmark, a specialized tool for evaluating the performance of LLMs, whic
    
[^72]: 单调释义提高语言模型提示的泛化能力

    Monotonic Paraphrasing Improves Generalization of Language Model Prompting

    [https://arxiv.org/abs/2403.16038](https://arxiv.org/abs/2403.16038)

    提出了单调释义（MonoPara）方法，通过释义LM和目标LM集成解码过程，将提示或指令释义为低困惑度的版本，从而提高语言模型的泛化能力

    

    大型语言模型（LLMs）的表现可能会随着同一任务的不同提示或指令而变化。这种现象的一个公认因素是模型对给定提示或指令的熟悉程度，通常通过其困惑度来估计。然而，鉴于可能提示短语的巨大空间，找到困惑度最低的提示是具有挑战性的。在本文中，我们提出了单调释义（MonoPara），一种端到端解码策略，根据释义LM和目标LM（即提示或指令执行器）的集合来将给定提示或指令释义化为其低困惑度的对应物。集合解码过程可以有效地释义原始提示而不改变其语义含义，同时单调地降低每个生成物的困惑度。

    arXiv:2403.16038v1 Announce Type: new  Abstract: Performance of large language models (LLMs) may vary with different prompts or instructions of even the same task. One commonly recognized factor for this phenomenon is the model's familiarity with the given prompt or instruction, which is typically estimated by its perplexity. However, finding the prompt with the lowest perplexity is challenging, given the enormous space of possible prompting phrases. In this paper, we propose monotonic paraphrasing (MonoPara), an end-to-end decoding strategy that paraphrases given prompts or instructions into their lower perplexity counterparts based on an ensemble of a paraphrase LM for prompt (or instruction) rewriting, and a target LM (i.e. the prompt or instruction executor) that constrains the generation for lower perplexity. The ensemble decoding process can efficiently paraphrase the original prompt without altering its semantic meaning, while monotonically decreasing the perplexity of each gene
    
[^73]: 通过语义-结构注意增强图卷积网络进行节点分类

    Node Classification via Semantic-Structural Attention-Enhanced Graph Convolutional Networks

    [https://arxiv.org/abs/2403.16033](https://arxiv.org/abs/2403.16033)

    该论文提出了一种名为语义-结构注意增强图卷积网络（SSA-GCN），能够同时模拟图结构并从知识图谱和复杂网络的角度提取无监督特征，以提升节点分类性能。

    

    图数据，也称为复杂网络数据，在各个领域和应用中无处不在。之前的图神经网络模型主要专注于通过监督学习目标提取特定任务的结构特征，但在捕捉整个图的固有语义和结构特征方面表现不佳。本文介绍了一种语义-结构注意增强图卷积网络（SSA-GCN），不仅模拟了图结构，还从总体上提取了无监督特征以增强顶点分类性能。SSA-GCN的关键贡献在三个方面表现：首先，它通过从知识图谱的角度进行无监督特征提取来获得语义信息；其次，它通过从复杂网络的角度进行无监督特征提取来获得结构信息；最后，它通过交叉注意力机制将这些特征融合在一起。

    arXiv:2403.16033v1 Announce Type: cross  Abstract: Graph data, also known as complex network data, is omnipresent across various domains and applications. Prior graph neural network models primarily focused on extracting task-specific structural features through supervised learning objectives, but they fell short in capturing the inherent semantic and structural features of the entire graph. In this paper, we introduce the semantic-structural attention-enhanced graph convolutional network (SSA-GCN), which not only models the graph structure but also extracts generalized unsupervised features to enhance vertex classification performance. The SSA-GCN's key contributions lie in three aspects: firstly, it derives semantic information through unsupervised feature extraction from a knowledge graph perspective; secondly, it obtains structural information through unsupervised feature extraction from a complex network perspective; and finally, it integrates these features through a cross-attent
    
[^74]: CBT-LLM：基于认知行为疗法的心理健康问答的中文大型语言模型

    CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering

    [https://arxiv.org/abs/2403.16008](https://arxiv.org/abs/2403.16008)

    通过设计专门的问答数据集和基于认知行为疗法原则的提示，本研究引入了CBT-LLM，一个针对中国心理健康问答的大型语言模型，旨在提高心理支持精度和效力。

    

    人工智能的最新进展突显出语言模型在心理健康支持方面的潜力。本研究针对心理健康服务平台数据训练的模型取得了初步成功, 但在数据稀缺、质量问题以及确保在心理技术方面建立牢固基础等方面仍存在挑战。为解决这些挑战，本研究引入了一种通过大型语言模型提高心理支持精度和效力的新方法。具体地，我们设计了一个基于认知行为疗法原则的特定提示，并生成了CBT QA数据集，专门用于基于CBT结构化干预策略的中国心理健康问答。与以往方法不同，我们的数据集强调专业和结构化的回应。利用这一数据集，我们对大型语言模型进行了微调，创造出CBT-LLM，这是一个大规模语言模型。

    arXiv:2403.16008v1 Announce Type: new  Abstract: The recent advancements in artificial intelligence highlight the potential of language models in psychological health support. While models trained on data from mental health service platform have achieved preliminary success, challenges persist in areas such as data scarcity, quality, and ensuring a solid foundation in psychological techniques. To address these challenges, this study introduces a novel approach to enhance the precision and efficacy of psychological support through large language models. Specifically, we design a specific prompt derived from principles of Cognitive Behavioral Therapy (CBT) and have generated the CBT QA dataset, specifically for Chinese psychological health Q&A based on CBT structured intervention strategies. Unlike previous methods, our dataset emphasizes professional and structured response. Utilizing this dataset, we fine-tuned the large language model, giving birth to CBT-LLM, the large-scale language
    
[^75]: BIMCV-R：用于3D CT文本图像检索的里程碑数据集

    BIMCV-R: A Landmark Dataset for 3D CT Text-Image Retrieval

    [https://arxiv.org/abs/2403.15992](https://arxiv.org/abs/2403.15992)

    提出了一个里程碑数据集BIMCV-R，包含8,069个3D CT体积和其放射学报告，同时开发了检索策略MedFinder，为3D医学文本图像检索领域提供了重要贡献

    

    arXiv:2403.15992v1 发布类型: 跨越  摘要: 三维医学图像与医疗保健的融合不断增加了医疗专业人员的工作量。为了帮助临床医生在诊断过程中，减轻其工作量，开发一个可靠的检索相似病例研究的系统是一个可行的解决方案。尽管这一概念有很大的潜力，但是目前3D医学文本图像检索领域受限于缺乏健全的评估基准和精心策划的数据集。为了解决这一问题，我们的研究提出了一种开创性的数据集，BIMCV-R（此数据集将在接受后发布。），其中包含了8,069个3D CT体积的广泛收集，包括超过200万张切片，以及它们各自的放射学报告。在我们数据集的基础上，我们拓展了一种检索策略，MedFinder。该方法采用双流网络架构，利用大

    arXiv:2403.15992v1 Announce Type: cross  Abstract: The burgeoning integration of 3D medical imaging into healthcare has led to a substantial increase in the workload of medical professionals. To assist clinicians in their diagnostic processes and alleviate their workload, the development of a robust system for retrieving similar case studies presents a viable solution. While the concept holds great promise, the field of 3D medical text-image retrieval is currently limited by the absence of robust evaluation benchmarks and curated datasets. To remedy this, our study presents a groundbreaking dataset, BIMCV-R (This dataset will be released upon acceptance.), which includes an extensive collection of 8,069 3D CT volumes, encompassing over 2 million slices, paired with their respective radiological reports. Expanding upon the foundational work of our dataset, we craft a retrieval strategy, MedFinder. This approach employs a dual-stream network architecture, harnessing the potential of larg
    
[^76]: IllusionVQA：一个挑战视觉语言模型的错觉数据集

    IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language Models

    [https://arxiv.org/abs/2403.15952](https://arxiv.org/abs/2403.15952)

    提出了IllusionVQA数据集，用于测试视觉语言模型在错觉和难解场景下的表现，研究发现在理解任务和定位任务上，表现最佳的VLM为GPT4V，而人类表现更胜一筹。

    

    视觉语言模型（VLM）的出现使研究人员能够使用自然语言调查神经网络的视觉理解。 VLM不仅能够进行对象分类和检测，还能够进行视觉理解和常识推理。 这自然而然地引出了一个问题：当图像本身是不合理的时，VLM会如何回应？ 为此，我们提出了IllusionVQA：一个包含具有挑战性的光学错觉和难以解释的场景的多样数据集，以测试VLM在两种不同的多选VQA任务 - 理解和软定位的能力。 表现最佳的VLM GPT4V在理解任务（4-shot）上实现了62.99％的准确率，在定位任务（4-shot和Chain-of-Thought）上实现了49.7％的准确率。 人类评估表明，人类在理解和定位方面的准确率分别为91.03％和100％。 我们发现，在上下文学习（ICL）和Chain-of-Thought推理方面有很大帮助。

    arXiv:2403.15952v1 Announce Type: cross  Abstract: The advent of Vision Language Models (VLM) has allowed researchers to investigate the visual understanding of a neural network using natural language. Beyond object classification and detection, VLMs are capable of visual comprehension and common-sense reasoning. This naturally led to the question: How do VLMs respond when the image itself is inherently unreasonable? To this end, we present IllusionVQA: a diverse dataset of challenging optical illusions and hard-to-interpret scenes to test the capability of VLMs in two distinct multiple-choice VQA tasks - comprehension and soft localization. GPT4V, the best-performing VLM, achieves 62.99% accuracy (4-shot) on the comprehension task and 49.7% on the localization task (4-shot and Chain-of-Thought). Human evaluation reveals that humans achieve 91.03% and 100% accuracy in comprehension and localization. We discover that In-Context Learning (ICL) and Chain-of-Thought reasoning substantially
    
[^77]: 地理代币与地理变压器

    Geotokens and Geotransformers

    [https://arxiv.org/abs/2403.15940](https://arxiv.org/abs/2403.15940)

    本文提出了地理代币的概念，将其作为变压器的输入组件与具体地理位置联系起来，设计了一种针对球面坐标的位置编码方法。

    

    在变压器架构中，位置编码主要为输入代币提供了序列的意义。原始变压器论文的方法在一般语言处理任务中表现出令人满意的结果，但也有了新的提议，如旋转位置嵌入（RoPE），以进一步改进。本文提出了地理代币，变压器的输入组件，每一个代币与特定地质位置相连。与典型的语言序列不同，对于这些代币，顺序并不像地理坐标本身那样重要。为了在这种情况下表示相对位置，并在真实世界距离和嵌入空间中的距离之间保持平衡，我们设计了一种位置编码方法，借鉴于RoPE结构但专为球面坐标定制。

    arXiv:2403.15940v1 Announce Type: cross  Abstract: In transformer architectures, position encoding primarily provides a sense of sequence for input tokens. While the original transformer paper's method has shown satisfactory results in general language processing tasks, there have been new proposals, such as Rotary Position Embedding (RoPE), for further improvement. This paper presents geotokens, input components for transformers, each linked to a specific geological location. Unlike typical language sequences, for these tokens, the order is not as vital as the geographical coordinates themselves. To represent the relative position in this context and to keep a balance between the real world distance and the distance in the embedding space, we design a position encoding approach drawing from the RoPE structure but tailored for spherical coordinates.
    
[^78]: LlamBERT：在自然语言处理中大规模、低成本的数据注释

    LlamBERT: Large-scale low-cost data annotation in NLP

    [https://arxiv.org/abs/2403.15938](https://arxiv.org/abs/2403.15938)

    LlamBERT是一种利用大规模语言模型注释未标记数据库并用于微调变压器编码器的混合方法，在降低成本的同时略微牺牲准确性。

    

    大型语言模型(LLMs)，如GPT-4和Llama 2，在各种自然语言处理(NLP)任务中表现出卓越的能力。尽管它们非常有效，但与它们的使用相关的高成本带来了挑战。我们提出了LlamBERT，这是一种混合方法，利用LLMs对大量未标记数据库的小子集进行注释，并将结果用于微调类似BERT和RoBERTa的变压器编码器。这一策略在两个不同的数据集上进行了评估：IMDb影评数据集和UMLS Meta-Thesaurus。我们的结果表明，LlamBERT方法在稍微牺牲准确性的同时，提供了更高的成本效益。

    arXiv:2403.15938v1 Announce Type: cross  Abstract: Large Language Models (LLMs), such as GPT-4 and Llama 2, show remarkable proficiency in a wide range of natural language processing (NLP) tasks. Despite their effectiveness, the high costs associated with their use pose a challenge. We present LlamBERT, a hybrid approach that leverages LLMs to annotate a small subset of large, unlabeled databases and uses the results for fine-tuning transformer encoders like BERT and RoBERTa. This strategy is evaluated on two diverse datasets: the IMDb review dataset and the UMLS Meta-Thesaurus. Our results indicate that the LlamBERT approach slightly compromises on accuracy while offering much greater cost-effectiveness.
    
[^79]: 利用零-shot提示实现高效语言模型蒸馏

    Leveraging Zero-Shot Prompting for Efficient Language Model Distillation

    [https://arxiv.org/abs/2403.15886](https://arxiv.org/abs/2403.15886)

    通过利用零-shot提示来引出教师模型的理由，减少手工制作的少-shot示例的必要性，并降低所需的总记号数，这直接转化为成本节约。

    

    本文介绍了一种新颖的方法，用于将LLMs高效地蒸馏为更小、特定于应用的模型，显著降低运营成本和人工劳动。该技术利用LLMs的推理能力为未标记数据生成标签和自然语言理由，以解决将计算密集型LLMs部署到特定应用或边缘设备的挑战。我们的方法通过采用多任务训练框架，其中学生模型模仿这些理由以及教师模型的预测，来增强微调和蒸馏。关键贡献包括利用零-shot提示来引出教师模型的理由，减少手工制作的少-shot示例的必要性，并降低所需的总记号数，这直接转化为成本节约，考虑到主要技术公司LLM APIs的按记号计费模型。此外，本文还调查了影响

    arXiv:2403.15886v1 Announce Type: cross  Abstract: This paper introduces a novel approach for efficiently distilling LLMs into smaller, application-specific models, significantly reducing operational costs and manual labor. Addressing the challenge of deploying computationally intensive LLMs in specific applications or edge devices, this technique utilizes LLMs' reasoning capabilities to generate labels and natural language rationales for unlabeled data. Our approach enhances both finetuning and distillation by employing a multi-task training framework where student models mimic these rationales alongside teacher predictions. Key contributions include the employment of zero-shot prompting to elicit teacher model rationales, reducing the necessity for handcrafted few-shot examples and lowering the overall token count required, which directly translates to cost savings given the pay-per-token billing model of major tech companies' LLM APIs. Additionally, the paper investigates the impact
    
[^80]: STEntConv：利用立场检测和有符号图卷积网络预测不同意见

    STEntConv: Predicting Disagreement with Stance Detection and a Signed Graph Convolutional Network

    [https://arxiv.org/abs/2403.15885](https://arxiv.org/abs/2403.15885)

    STEntConv利用用户立场建立了用户和命名实体的加权图，通过有符号图卷积网络预测Reddit帖子中的不同意见表达。

    

    社交媒体平台的兴起导致极化的在线讨论增加，特别是关于选举和气候变化等政治和社会文化话题。我们提出了一种简单且新颖的无监督方法，用于预测两篇文章的作者是否同意或不同意，利用从他们的文章中获得的关于命名实体的用户立场。我们提出了STEntConv模型，该模型构建了一个由立场加权的用户和命名实体图，并训练了一个有符号图卷积网络（SGCN）来检测评论和回复帖子之间的不同意见。我们进行了实验和消融研究，并展示出包含此信息可以改善Reddit帖子数据集上有争议的子版主题的不同意见检测性能，而无需平台特定特征或用户历史。

    arXiv:2403.15885v1 Announce Type: new  Abstract: The rise of social media platforms has led to an increase in polarised online discussions, especially on political and socio-cultural topics such as elections and climate change. We propose a simple and novel unsupervised method to predict whether the authors of two posts agree or disagree, leveraging user stances about named entities obtained from their posts. We present STEntConv, a model which builds a graph of users and named entities weighted by stance and trains a Signed Graph Convolutional Network (SGCN) to detect disagreement between comment and reply posts. We run experiments and ablation studies and show that including this information improves disagreement detection performance on a dataset of Reddit posts for a range of controversial subreddit topics, without the need for platform-specific features or user history.
    
[^81]: VLUE：一种新的基准和多任务知识迁移学习，用于越南自然语言理解

    VLUE: A New Benchmark and Multi-task Knowledge Transfer Learning for Vietnamese Natural Language Understanding

    [https://arxiv.org/abs/2403.15882](https://arxiv.org/abs/2403.15882)

    VLUE是第一个越南自然语言理解评估（VLUE）基准，提供了包括文本分类、跨度提取和自然语言理解在内的五个数据集，评估了七个最先进的预训练模型，并介绍了CafeBERT，一个取得优异结果的新型最先进预训练模型。

    

    自然语言理解（NLU）基准在各种语言（如英语的GLUE，中文的CLUE，韩语的KLUE和印度尼西亚语的IndoNLU）中取得了成功，促进了对新NLU模型在各种任务上的评估。为了为越南NLU建立一套标准化的基准，我们引入了第一个越南语言理解评估（VLUE）基准。VLUE基准包括涵盖了不同NLU任务的五个数据集，包括文本分类、跨度提取和自然语言理解。为了深入了解当前越南NLU的现状，我们评估了七个最先进的预训练模型，包括多语言和越南单语模型，在我们提出的VLUE基准上。此外，我们提出了CafeBERT，这是一个在VLUE基准的所有任务上都取得了优异结果的新型最先进预训练模型。

    arXiv:2403.15882v1 Announce Type: new  Abstract: The success of Natural Language Understanding (NLU) benchmarks in various languages, such as GLUE for English, CLUE for Chinese, KLUE for Korean, and IndoNLU for Indonesian, has facilitated the evaluation of new NLU models across a wide range of tasks. To establish a standardized set of benchmarks for Vietnamese NLU, we introduce the first Vietnamese Language Understanding Evaluation (VLUE) benchmark. The VLUE benchmark encompasses five datasets covering different NLU tasks, including text classification, span extraction, and natural language understanding. To provide an insightful overview of the current state of Vietnamese NLU, we then evaluate seven state-of-the-art pre-trained models, including both multilingual and Vietnamese monolingual models, on our proposed VLUE benchmark. Furthermore, we present CafeBERT, a new state-of-the-art pre-trained model that achieves superior results across all tasks in the VLUE benchmark. Our model co
    
[^82]: LAMPER：用于零样本时间序列分类的语言模型和提示工程

    LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series classification

    [https://arxiv.org/abs/2403.15875](https://arxiv.org/abs/2403.15875)

    LAMPER框架旨在评估预训练语言模型在零样本时间序列分类中的适应能力，研究发现其特征表示能力受到PLMs最大输入标记阈值的影响。

    

    这项研究构建了LanguAge模型和Prompt EngineeRing（LAMPER）框架，旨在系统评估预训练语言模型（PLMs）在容纳多样提示及其在零样本时间序列（TS）分类中的整合能力。我们在实验评估中部署LAMPER，使用了来源于UCR存档的128个单变量TS数据集。我们的发现表明，LAMPER的特征表示能力受到PLMs强加的最大输入标记阈值的影响。

    arXiv:2403.15875v1 Announce Type: new  Abstract: This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER) framework, designed to systematically evaluate the adaptability of pre-trained language models (PLMs) in accommodating diverse prompts and their integration in zero-shot time series (TS) classification. We deploy LAMPER in experimental assessments using 128 univariate TS datasets sourced from the UCR archive. Our findings indicate that the feature representation capacity of LAMPER is influenced by the maximum input token threshold imposed by PLMs.
    
[^83]: RAAMove: 用于分析研究论文摘要中动作的语料库

    RAAMove: A Corpus for Analyzing Moves in Research Article Abstracts

    [https://arxiv.org/abs/2403.15872](https://arxiv.org/abs/2403.15872)

    这个研究介绍了一个名为RAAMove的语料库，旨在帮助分析并自动识别研究论文摘要中的动作结构。

    

    多年来，人们一直在研究英语专门用途（ESP）和学术目的英语（EAP）中的动作结构。然而，关于研究论文（RA）摘要的动作注释语料库却很少。本文介绍了RAAMove，这是一个专门用于注释RA摘要中的动作结构的综合多领域语料库。RAAMove的主要目标是促进动作分析和自动动作识别。本文对语料库构建过程进行了详细讨论，包括方案、数据收集、注释准则和注释程序。语料库分两个阶段构建：首先，专家标注员手动标注高质量数据；随后，基于人工标注数据，利用基于BERT的模型通过专家修改进行自动标注。结果是一个包含33,988个注释的大规模高质量语料库。

    arXiv:2403.15872v1 Announce Type: new  Abstract: Move structures have been studied in English for Specific Purposes (ESP) and English for Academic Purposes (EAP) for decades. However, there are few move annotation corpora for Research Article (RA) abstracts. In this paper, we introduce RAAMove, a comprehensive multi-domain corpus dedicated to the annotation of move structures in RA abstracts. The primary objective of RAAMove is to facilitate move analysis and automatic move identification. This paper provides a thorough discussion of the corpus construction process, including the scheme, data collection, annotation guidelines, and annotation procedures. The corpus is constructed through two stages: initially, expert annotators manually annotate high-quality data; subsequently, based on the human-annotated data, a BERT-based model is employed for automatic annotation with the help of experts' modification. The result is a large-scale and high-quality corpus comprising 33,988 annotated i
    
[^84]: 语言-图像预训练的中心掩蔽技术

    Centered Masking for Language-Image Pre-Training

    [https://arxiv.org/abs/2403.15837](https://arxiv.org/abs/2403.15837)

    使用中心掩蔽的GLIP技术在语言-图像预训练中取代了随机掩蔽，利用高斯分布提高了性能，并且易于获得且适用于不具有明显中心焦点的数据集。

    

    我们引入了用于语言-图像预训练（GLIP）的高斯掩蔽，这是一种新颖、直接和有效的技术，用于在视觉-语言模型的预训练过程中对图像补丁进行掩蔽。GLIP基于快速语言-图像预训练（FLIP），该方法在训练CLIP模型时随机屏蔽图像补丁。GLIP将随机屏蔽替换为中心掩蔽，使用高斯分布，并受到图像中心重要性的启发。在一系列下游数据集和任务中，GLIP保留了与FLIP相同的计算节省能力，同时改善了性能，这是由我们的实验结果所证实的。我们展示了GLIP的好处很容易获得，无需精细调整高斯，也适用于包含无明显中心焦点图片的数据集。

    arXiv:2403.15837v1 Announce Type: cross  Abstract: We introduce Gaussian masking for Language-Image Pre-Training (GLIP) a novel, straightforward, and effective technique for masking image patches during pre-training of a vision-language model. GLIP builds on Fast Language-Image Pre-Training (FLIP), which randomly masks image patches while training a CLIP model. GLIP replaces random masking with centered masking, that uses a Gaussian distribution and is inspired by the importance of image patches at the center of the image. GLIP retains the same computational savings as FLIP, while improving performance across a range of downstream datasets and tasks, as demonstrated by our experimental results. We show the benefits of GLIP to be easy to obtain, requiring no delicate tuning of the Gaussian, and also applicable to data sets containing images without an obvious center focus.
    
[^85]: 计算句子级度量预测人类句子理解

    Computational Sentence-level Metrics Predicting Human Sentence Comprehension

    [https://arxiv.org/abs/2403.15822](https://arxiv.org/abs/2403.15822)

    本研究引入了创新方法，使用多语言大型语言模型计算句子级度量，并证明这些度量能够高度准确地预测人类句子阅读速度，为未来整合LLMs和认知科学研究提供了有前景的方向。

    

    计算心理语言学的研究大多集中在单词处理上。本研究引入了创新方法，使用多语言大型语言模型计算句子级度量。开发的度量包括句子意外性和句子相关性，然后经过测试和比较以验证它们是否可以预测人类如何跨语言整体理解句子。这些度量提供了重要的可解释性，并在预测人类句子阅读速度方面取得了很高的准确性。我们的结果表明，这些计算的句子级度量在预测和阐明读者在理解整体句子时遇到的处理困难方面异常有效，可跨越多种语言。它们出色的性能和泛化能力为未来在整合LLMs和认知科学方面的研究提供了一个有前途的途径。

    arXiv:2403.15822v1 Announce Type: new  Abstract: The majority of research in computational psycholinguistics has concentrated on the processing of words. This study introduces innovative methods for computing sentence-level metrics using multilingual large language models. The metrics developed sentence surprisal and sentence relevance and then are tested and compared to validate whether they can predict how humans comprehend sentences as a whole across languages. These metrics offer significant interpretability and achieve high accuracy in predicting human sentence reading speeds. Our results indicate that these computational sentence-level metrics are exceptionally effective at predicting and elucidating the processing difficulties encountered by readers in comprehending sentences as a whole across a variety of languages. Their impressive performance and generalization capabilities provide a promising avenue for future research in integrating LLMs and cognitive science.
    
[^86]: 基于MRC的带共同预测和自适应预训练的医学嵌套NER

    MRC-based Nested Medical NER with Co-prediction and Adaptive Pre-training

    [https://arxiv.org/abs/2403.15800](https://arxiv.org/abs/2403.15800)

    提出了基于MRC的医学NER模型，采用任务自适应预训练策略、多词对嵌入和多粒度扩张卷积，并结合Biaffine和MLP的联合预测器，以增强模型在医学领域的表征和识别性能。

    

    在医学信息提取中，医学命名实体识别（NER）是不可或缺的，它在开发医学知识图谱、增强医学问答系统以及分析电子病历中扮演着关键角色。医学NER面临的挑战主要来自复杂的嵌套结构和复杂的医学术语，这使其与传统领域的NER有所区别。为了解决这些复杂性，我们提出了一种基于机器阅读理解（MRC）的医学NER模型，该模型采用任务自适应预训练策略来提高模型在医学领域的能力。同时，我们的模型引入了多个词对嵌入和多粒度扩张卷积以增强模型的表征能力，并使用结合了Biaffine和MLP的联合预测器来提高模型的识别性能。

    arXiv:2403.15800v1 Announce Type: new  Abstract: In medical information extraction, medical Named Entity Recognition (NER) is indispensable, playing a crucial role in developing medical knowledge graphs, enhancing medical question-answering systems, and analyzing electronic medical records. The challenge in medical NER arises from the complex nested structures and sophisticated medical terminologies, distinguishing it from its counterparts in traditional domains. In response to these complexities, we propose a medical NER model based on Machine Reading Comprehension (MRC), which uses a task-adaptive pre-training strategy to improve the model's capability in the medical field. Meanwhile, our model introduces multiple word-pair embeddings and multi-granularity dilated convolution to enhance the model's representation ability and uses a combined predictor of Biaffine and MLP to improve the model's recognition performance. Experimental evaluations conducted on the CMeEE, a benchmark for Ch
    
[^87]: 从损失角度理解语言模型的突现能力

    Understanding Emergent Abilities of Language Models from the Loss Perspective

    [https://arxiv.org/abs/2403.15796](https://arxiv.org/abs/2403.15796)

    本文从损失角度重新定义了语言模型的突现能力，发现具有相同预训练损失的模型在不同任务上表现相似，而当预训练损失低于特定阈值时，模型将展现出突现能力。

    

    近期研究质疑了传统认为语言模型的突现能力仅存在于大模型中的观点。这种怀疑源自两点观察：1）较小的模型也能展现出对突现能力的高性能；2）质疑用于测量这些能力的不连续性指标。本文提议从预训练损失的角度研究突现能力，而非模型大小或训练计算。我们展示了具有相同预训练损失但不同模型和数据大小的模型，在各种下游任务上表现相同。我们还发现，当某一模型的预训练损失低于特定阈值时，在某些任务上表现出突现能力，而不论指标的连续性如何；而在达到该阈值之前，其性能仍保持在随机猜测水平。这启发我们重新定义突现能力为那些......

    arXiv:2403.15796v1 Announce Type: cross  Abstract: Recent studies have put into question the belief that emergent abilities in language models are exclusive to large models. This skepticism arises from two observations: 1) smaller models can also exhibit high performance on emergent abilities and 2) there is doubt on the discontinuous metrics used to measure these abilities. In this paper, we propose to study emergent abilities in the lens of pre-training loss, instead of model size or training compute. We demonstrate that the models with the same pre-training loss, but different model and data sizes, generate the same performance on various downstream tasks. We also discover that a model exhibits emergent abilities on certain tasks -- regardless of the continuity of metrics -- when its pre-training loss falls below a specific threshold. Before reaching this threshold, its performance remains at the level of random guessing. This inspires us to redefine emergent abilities as those that
    
[^88]: 为高质量标题生成建模统一语义话语结构

    Modeling Unified Semantic Discourse Structure for High-quality Headline Generation

    [https://arxiv.org/abs/2403.15776](https://arxiv.org/abs/2403.15776)

    通过将文档级修辞结构理论（RST）树与句级抽象意义表示（AMR）图结合起来构建S3图，形成统一的语义话语结构，用于标题生成框架中，进一步设计了分层结构修剪机制，提高标题生成的效果。

    

    题为生成旨在用简短、吸引人的标题总结长篇文档，反映主要思想。这需要准确捕捉核心文档语义，由于文本的长度和背景信息丰富，这是具有挑战性的。在这项工作中，我们提出使用统一的语义话语结构(S3)来表示文档语义，通过将文档级修辞结构理论（RST）树与句级抽象意义表示（AMR）图结合起来构建S3图。句子、从句和词汇的分层组合固有地表达了整个文档的语义含义。然后，我们开发了一个标题生成框架，在其中将S3图编码为上下文特征。为了巩固S3图的有效性，我们进一步设计了一个分层结构修剪机制，动态筛选多余和非必要节点。

    arXiv:2403.15776v1 Announce Type: cross  Abstract: Headline generation aims to summarize a long document with a short, catchy title that reflects the main idea. This requires accurately capturing the core document semantics, which is challenging due to the lengthy and background information-rich na ture of the texts. In this work, We propose using a unified semantic discourse structure (S3) to represent document semantics, achieved by combining document-level rhetorical structure theory (RST) trees with sentence-level abstract meaning representation (AMR) graphs to construct S3 graphs. The hierarchical composition of sentence, clause, and word intrinsically characterizes the semantic meaning of the overall document. We then develop a headline generation framework, in which the S3 graphs are encoded as contextual features. To consolidate the efficacy of S3 graphs, we further devise a hierarchical structure pruning mechanism to dynamically screen the redundant and nonessential nodes with
    
[^89]: 用户端实现

    User-Side Realization

    [https://arxiv.org/abs/2403.15757](https://arxiv.org/abs/2403.15757)

    用户端实现为用户提供了积极的解决方案，通过在用户端运行通用算法来解决常见问题，无需服务提供商改变服务本身。

    

    用户对服务感到不满意。由于服务并非量身定制给用户，因此不满意是自然而然的。问题在于，即使用户感到不满意，他们通常也没有解决不满的手段。用户无法修改服务的源代码，也无法强迫服务提供商进行更改。用户别无选择，只能保持不满意或退出服务。用户端实现通过提供通用算法来处理用户端的常见问题，为解决这一问题提供了积极的解决方案。这些算法在用户端运行，并在不需要服务提供商改变服务本身的情况下解决问题。

    arXiv:2403.15757v1 Announce Type: cross  Abstract: Users are dissatisfied with services. Since the service is not tailor-made for a user, it is natural for dissatisfaction to arise. The problem is, that even if users are dissatisfied, they often do not have the means to resolve their dissatisfaction. The user cannot alter the source code of the service, nor can they force the service provider to change. The user has no choice but to remain dissatisfied or quit the service. User-side realization offers proactive solutions to this problem by providing general algorithms to deal with common problems on the user's side. These algorithms run on the user's side and solve the problems without having the service provider change the service itself.
    
[^90]: 利用大型语言模型进行初步安全风险分析：一个关键任务案例研究

    Leveraging Large Language Models for Preliminary Security Risk Analysis: A Mission-Critical Case Study

    [https://arxiv.org/abs/2403.15756](https://arxiv.org/abs/2403.15756)

    大型语言模型在初步安全风险分析中展现了比人类更快速的信息总结能力，本研究通过案例研究探讨了微调模型在协助从业者进行PSRA方面的实用性。

    

    初步安全风险分析（PSRA）提供了一种快速的方法，用于识别、评估和提出潜在风险在具体情境中的应对措施。在关键任务情境中，及时和迅速的行动是至关重要的，所以对有效PSRA所需的广泛专业知识和大量与文本相关的任务在阻碍快速评估。大型语言模型可以比人类更快速地总结信息，利用微调模型（FTM）在PSRA中的能力尚未被先前的研究所探讨。本文通过案例研究调查FTM在协助从业者进行PSRA中的熟练程度。

    arXiv:2403.15756v1 Announce Type: cross  Abstract: Preliminary security risk analysis (PSRA) provides a quick approach to identify, evaluate and propose remeditation to potential risks in specific scenarios. The extensive expertise required for an effective PSRA and the substantial ammount of textual-related tasks hinder quick assessments in mission-critical contexts, where timely and prompt actions are essential. The speed and accuracy of human experts in PSRA significantly impact response time. A large language model can quickly summarise information in less time than a human. To our knowledge, no prior study has explored the capabilities of fine-tuned models (FTM) in PSRA. Our case study investigates the proficiency of FTM to assist practitioners in PSRA. We manually curated 141 representative samples from over 50 mission-critical analyses archived by the industrial context team in the last five years.We compared the proficiency of the FTM versus seven human experts. Within the indu
    
[^91]: 论主动学习者的脆弱性

    On the Fragility of Active Learners

    [https://arxiv.org/abs/2403.15744](https://arxiv.org/abs/2403.15744)

    本研究发现主动学习技术只在特定情境下有效，对文本分类从业者的建议是选择适当的文本表示和分类器同样重要。

    

    主动学习（AL）技术旨在通过迭代选择最有可能提高预测准确性的实例，最大程度地利用标注预算。然而，与随机抽样相比，在不同设置下（例如不同数据集，分类器），它们的益处并不一致。在这项实证研究中，我们研究了不同因素的组合如何可能掩盖主动学习技术的任何收益。专注于文本分类，我们在大约1000个实验中严格评估了进行分类，我们在大约1000个实验中严格评估了AL技术，这些实验在数据集、批大小、文本表示和分类器方面变化。我们表明，AL只在一组有限的情境中有效。我们还解决了使用与现实世界期望更好对齐的度量的问题。这项研究的影响在于对从业者的洞察：(a) 文本表示和分类器的选择与AL技术的选择一样重要，(b) 选择的

    arXiv:2403.15744v1 Announce Type: cross  Abstract: Active learning (AL) techniques aim to maximally utilize a labeling budget by iteratively selecting instances that are most likely to improve prediction accuracy. However, their benefit compared to random sampling has not been consistent across various setups, e.g., different datasets, classifiers. In this empirical study, we examine how a combination of different factors might obscure any gains from an AL technique.   Focusing on text classification, we rigorously evaluate AL techniques over around 1000 experiments that vary wrt the dataset, batch size, text representation and the classifier. We show that AL is only effective in a narrow set of circumstances. We also address the problem of using metrics that are better aligned with real world expectations.   The impact of this study is in its insights for a practitioner: (a) the choice of text representation and classifier is as important as that of an AL technique, (b) choice of the 
    
[^92]: Ghost Sentence：一种供普通用户使用的工具，用于对大型语言模型中的数据进行版权保护

    Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models

    [https://arxiv.org/abs/2403.15740](https://arxiv.org/abs/2403.15740)

    通过在文档中插入个人密码并识别生成内容中的“幽灵句子”，普通用户可以确认大型语言模型是否滥用其数据，从而实现数据版权保护。

    

    Web用户数据在预训练大型语言模型（LLMs）及其微调变种的生态系统中起着核心作用。本文提出了一种方法，建议用户在其文档中反复插入个人密码，使LLMs能够记忆这些密码。这些用户文档中隐藏的密码，被称为“幽灵句子”，一旦它们出现在LLMs生成的内容中，用户就可以确信他们的数据被用于训练。为了探索这种版权工具的有效性和用法，我们利用幽灵句子定义了“用户训练数据识别”任务。我们创建了来自不同来源、不同规模的多个数据集，并使用不同规模的LLMs进行测试。为了评估，我们引入了一个最后$k$个单词验证的方式。

    arXiv:2403.15740v1 Announce Type: new  Abstract: Web user data plays a central role in the ecosystem of pre-trained large language models (LLMs) and their fine-tuned variants. Billions of data are crawled from the web and fed to LLMs. How can \textit{\textbf{everyday web users}} confirm if LLMs misuse their data without permission? In this work, we suggest that users repeatedly insert personal passphrases into their documents, enabling LLMs to memorize them. These concealed passphrases in user documents, referred to as \textit{ghost sentences}, once they are identified in the generated content of LLMs, users can be sure that their data is used for training. To explore the effectiveness and usage of this copyrighting tool, we define the \textit{user training data identification} task with ghost sentences. Multiple datasets from various sources at different scales are created and tested with LLMs of different sizes. For evaluation, we introduce a last $k$ words verification manner along 
    
[^93]: 通过归纳推理实现少样本对话策略学习，应用于激励式访谈

    Few-shot Dialogue Strategy Learning for Motivational Interviewing via Inductive Reasoning

    [https://arxiv.org/abs/2403.15737](https://arxiv.org/abs/2403.15737)

    提出了DIIT框架，通过学习和应用专家演示中的自然语言归纳规则，改善主动倾听技能，减少不请自来的建议，促进更协作和无权威性的回应。

    

    我们考虑构建一个对话系统，能够激励用户采纳积极的生活方式变化：激励式访谈。解决这样一个任务需要一个系统能够推断如何有效地激励用户。我们提出了DIIT，一个能够从专家演示中学习和应用自然语言归纳规则形式的对话策略的框架。对指示遵循的大型语言模型进行自动和人工评估显示，DIIR发现的自然语言策略描述能够提高主动倾听技能，减少不请自来的建议，并促进更具协作性和不那么权威性的回应，优于各种演示利用方法。

    arXiv:2403.15737v1 Announce Type: new  Abstract: We consider the task of building a dialogue system that can motivate users to adopt positive lifestyle changes: Motivational Interviewing. Addressing such a task requires a system that can infer \textit{how} to motivate a user effectively. We propose DIIT, a framework that is capable of learning and applying conversation strategies in the form of natural language inductive rules from expert demonstrations. Automatic and human evaluation on instruction-following large language models show natural language strategy descriptions discovered by DIIR can improve active listening skills, reduce unsolicited advice, and promote more collaborative and less authoritative responses, outperforming various demonstration utilization methods.
    
[^94]: LLMs指导LLMs：一种提取和编辑方法

    LLMs Instruct LLMs:An Extraction and Editing Method

    [https://arxiv.org/abs/2403.15736](https://arxiv.org/abs/2403.15736)

    提出了一种顺序融合方法，将复杂环境中的知识融入LLMs中，用于更新大型语言模型。

    

    arXiv:2403.15736v1 公告类型：新 兴趣点在于无需从头开始训练即可更新大型语言模型（LLMs），但是这也带来了一些挑战。尤其是对于需要用有限样本进行复杂推理的情况来说，我们称之为适用于LLMs的贫乏约束复杂推理（PCRA-LLM）的情况。传统方法如低秩适应（LoRA）和检索增强生成（RAG）对这一关键问题是不足够的，尤其在我们探索特定医学背景时尤为明显，这体现了PCRA-LLM的独特需求。为了解决这个问题，我们提出了一种顺序融合方法，将复杂环境中的知识融入LLMs中。该方法采用两阶段框架：首先，利用通用LLMs构建知识图谱（KGs）来从复杂文本中提取知识；随后，通过知识编辑来更新领域LLMs。根据我们的方法，领域

    arXiv:2403.15736v1 Announce Type: new  Abstract: The interest in updating Large Language Models (LLMs) without retraining from scratch is substantial, yet it comes with some challenges.This is especially true for situations demanding complex reasoning with limited samples, a scenario we refer to as the Paucity-Constrained Complex Reasoning Adaptation for LLMs (PCRA-LLM).Traditional methods like Low-Rank Adaptation (LoRA) and Retrieval-Augmented Generation (RAG) are inadequate for this critical issue, particularly evident in our exploration of a specific medical context that epitomize the PCRA-LLM's distinct needs.To address the issue, we propose a Sequential Fusion method to incorporate knowledge from complex context into LLMs. This method employs a two-stage framework: initially, it leverages general LLMs to construct knowledge graphs (KGs) for extracting knowledge from complex texts; subsequently, it updates the domain LLMs through knowledge edit. According to our method, the domain 
    
[^95]: 面向电子离子对撞机的基于RAG的摘要生成代理

    Towards a \textbf{RAG}-based Summarization Agent for the Electron-Ion Collider

    [https://arxiv.org/abs/2403.15729](https://arxiv.org/abs/2403.15729)

    开发了一种面向电子离子对撞机的基于RAG的摘要生成代理，能够压缩信息并引用相关回复，为合作者提供重大优势

    

    复杂性和庞大的信息量涵盖了大规模实验的文件、论文、数据和其他资源，导致导航这些多样形式信息的任务需要大量时间和精力，对于新合作者和早期科学家来说尤为艰巨。为了解决这个问题，正在开发一种基于检索增强生成（RAG）的EIC摘要生成人工智能代理（RAGS4EIC）。该人工智能代理不仅压缩信息，还有效引用相关回复，为合作者提供了重大优势。我们的项目采取了两步方法：首先，查询包含所有相关实验信息的综合向量数据库；其次，利用大型语言模型（LLM）根据用户查询和检索数据生成包含引用的简洁摘要。我们描述了使用RAG评估的评估方法

    arXiv:2403.15729v1 Announce Type: cross  Abstract: The complexity and sheer volume of information encompassing documents, papers, data, and other resources from large-scale experiments demand significant time and effort to navigate, making the task of accessing and utilizing these varied forms of information daunting, particularly for new collaborators and early-career scientists. To tackle this issue, a Retrieval Augmented Generation (RAG)--based Summarization AI for EIC (RAGS4EIC) is under development. This AI-Agent not only condenses information but also effectively references relevant responses, offering substantial advantages for collaborators. Our project involves a two-step approach: first, querying a comprehensive vector database containing all pertinent experiment information; second, utilizing a Large Language Model (LLM) to generate concise summaries enriched with citations based on user queries and retrieved data. We describe the evaluation methods that use RAG assessments 
    
[^96]: PEaCE：用于科学文档光学字符识别的化学导向数据集

    PEaCE: A Chemistry-Oriented Dataset for Optical Character Recognition on Scientific Documents

    [https://arxiv.org/abs/2403.15724](https://arxiv.org/abs/2403.15724)

    提出了PEaCE数据集，利用其中的合成和真实记录评估了基于transformer的OCR模型在化学文献中的识别效果，并提出可以模拟真实记录特征的转换。

    

    Optical Character Recognition（OCR）是一个旨在识别图像中存在的文本的既定任务。尽管存在许多现成的OCR模型，但它们通常是针对科学（例如，公式）或通用印刷英文文本进行训练的。从化学出版物中提取文本需要一种能够在这两个领域中进行操作的OCR模型。最近的工具Nougat表现出解析学术文档的强大能力，但无法解析PubMed文章中的表格，这构成了学术界一个重要部分，并且也是本次工作的重点。为了弥补这一差距，我们提出了包含合成和真实记录的Printed English and Chemical Equations（PEaCE）数据集，并评估了当这一资源进行训练时，基于transformer的OCR模型的有效性。鉴于真实记录包含合成记录中不存在的人工制品，我们提出了模仿这些特质的转换。

    arXiv:2403.15724v1 Announce Type: cross  Abstract: Optical Character Recognition (OCR) is an established task with the objective of identifying the text present in an image. While many off-the-shelf OCR models exist, they are often trained for either scientific (e.g., formulae) or generic printed English text. Extracting text from chemistry publications requires an OCR model that is capable in both realms. Nougat, a recent tool, exhibits strong ability to parse academic documents, but is unable to parse tables in PubMed articles, which comprises a significant part of the academic community and is the focus of this work. To mitigate this gap, we present the Printed English and Chemical Equations (PEaCE) dataset, containing both synthetic and real-world records, and evaluate the efficacy of transformer-based OCR models when trained on this resource. Given that real-world records contain artifacts not present in synthetic records, we propose transformations that mimic such qualities. We p
    
[^97]: EDDA：一种用于零样本立场检测的编码器-解码器数据增强框架

    EDDA: A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance Detection

    [https://arxiv.org/abs/2403.15715](https://arxiv.org/abs/2403.15715)

    EDDA框架提出了一种新的编码器-解码器数据增强方法，通过if-then原理和语义相关的词替换策略，解决了零样本立场检测中目标增强和文本增强的不足。

    

    立场检测旨在确定文本对特定目标表达的态度。零样本立场检测（ZSSD）旨在在推理过程中对未见目标进行立场分类。最近针对ZSSD的数据增强技术通过文本或目标增强增加了在不同目标之间的可转移知识。然而，这些方法存在一定局限性。目标增强缺乏生成目标与源文本之间的逻辑关系，而文本增强仅依赖于训练数据，导致泛化能力不足。为了解决这些问题，我们提出了一种编码器-解码器数据增强（EDDA）框架。编码器利用大规模语言模型和思维链提示将文本总结为特定于目标的if-then原理，建立逻辑关系。解码器根据这些表达式使用语义相关的词替换策略生成新样本，增加了其同义性。

    arXiv:2403.15715v1 Announce Type: new  Abstract: Stance detection aims to determine the attitude expressed in text towards a given target. Zero-shot stance detection (ZSSD) has emerged to classify stances towards unseen targets during inference. Recent data augmentation techniques for ZSSD increase transferable knowledge between targets through text or target augmentation. However, these methods exhibit limitations. Target augmentation lacks logical connections between generated targets and source text, while text augmentation relies solely on training data, resulting in insufficient generalization. To address these issues, we propose an encoder-decoder data augmentation (EDDA) framework. The encoder leverages large language models and chain-of-thought prompting to summarize texts into target-specific if-then rationales, establishing logical relationships. The decoder generates new samples based on these expressions using a semantic correlation word replacement strategy to increase syn
    
[^98]: FEEL：用于评估大型语言模型情感支持能力的框架

    FEEL: A Framework for Evaluating Emotional Support Capability with Large Language Models

    [https://arxiv.org/abs/2403.15699](https://arxiv.org/abs/2403.15699)

    提出了一个基于大型语言模型的框架FEEL，用于评估情感支持能力，解决了当前非人工方法在评估情感支持能力方面面临的挑战，并采用了概率分布方法和集成学习以获得更稳定和全面的结果。

    

    情感支持对话（ESC）是一种典型的对话，可以有效地帮助用户缓解情感压力。然而，由于情感分析中涉及固有主观性，当前非人工方法在有效评估情感支持能力方面面临挑战。这些指标与人类判断之间存在很低的相关性。同时，手动评估方法将导致很高的成本。为解决这些问题，我们提出了一个新型模型FEEL（用大型语言模型评估情感支持能力的框架），采用大型语言模型（LLMs）作为评估者来评估情感支持能力。该模型周密考虑ESC的各种评估方面，应用更全面和准确的ESC评估方法。此外，它采用概率分布方法以获得更稳定的结果，并集成了集成学习。

    arXiv:2403.15699v1 Announce Type: new  Abstract: Emotional Support Conversation (ESC) is a typical dialogue that can effec-tively assist the user in mitigating emotional pressures. However, owing to the inherent subjectivity involved in analyzing emotions, current non-artificial methodologies face challenges in effectively appraising the emo-tional support capability. These metrics exhibit a low correlation with human judgments. Concurrently, manual evaluation methods extremely will cause high costs. To solve these problems, we propose a novel model FEEL (Framework for Evaluating Emotional Support Capability with Large Lan-guage Models), employing Large Language Models (LLMs) as evaluators to assess emotional support capabilities. The model meticulously considers var-ious evaluative aspects of ESC to apply a more comprehensive and accurate evaluation method for ESC. Additionally, it employs a probability distribu-tion approach for a more stable result and integrates an ensemble learnin
    
[^99]: MixRED: 一个多语言关系抽取数据集

    MixRED: A Mix-lingual Relation Extraction Dataset

    [https://arxiv.org/abs/2403.15696](https://arxiv.org/abs/2403.15696)

    论文提出了一个新的多语言关系抽取任务MixRE，并构建了支持该任务的人工注释数据集MixRED，填补了多语言情景下关系抽取研究的空白。

    

    arXiv:2403.15696v1 公告类型：新 摘要：关系抽取是自然语言处理领域中的一个关键任务，具有许多现实世界的应用。现有研究主要集中在单语关系抽取或用于关系抽取的跨语言增强。然而，在多语言（或代码混合）场景中，仍存在对关系抽取的理解存在重大差距，在该场景中，个体在句子中混合来自不同语言的内容，生成多语内容。由于缺乏专门的数据集，现有关系抽取模型在这种情况下的有效性在很大程度上尚未探讨。为解决这一问题，我们引入了一项新的任务，即考虑多语言情景中的关系抽取，称为MixRE，并构建了人工注释数据集MixRED以支持此任务。除了构建MixRED数据集，我们还评估了最先进的监督模型和大语言模型（LLMs）。

    arXiv:2403.15696v1 Announce Type: new  Abstract: Relation extraction is a critical task in the field of natural language processing with numerous real-world applications. Existing research primarily focuses on monolingual relation extraction or cross-lingual enhancement for relation extraction. Yet, there remains a significant gap in understanding relation extraction in the mix-lingual (or code-switching) scenario, where individuals intermix contents from different languages within sentences, generating mix-lingual content. Due to the lack of a dedicated dataset, the effectiveness of existing relation extraction models in such a scenario is largely unexplored. To address this issue, we introduce a novel task of considering relation extraction in the mix-lingual scenario called MixRE and constructing the human-annotated dataset MixRED to support this task. In addition to constructing the MixRED dataset, we evaluate both state-of-the-art supervised models and large language models (LLMs)
    
[^100]: EAGLE：面向人工智能生成文本检测的领域泛化框架

    EAGLE: A Domain Generalization Framework for AI-generated Text Detection

    [https://arxiv.org/abs/2403.15690](https://arxiv.org/abs/2403.15690)

    EAGLE提出了一个领域泛化框架，能够利用从旧语言模型中获得的标记数据，学习特征的不变性，从而检测出未知目标生成器生成的文本。

    

    随着大型语言模型（LLMs）能力的提升，负责任和安全使用这些LLMs的一个重要步骤是能够检测这些模型生成的文本。尽管监督式AI生成的文本检测器在旧LLMs生成的文本上表现良好，但随着新LLMs的频繁发布，构建用于识别这些新模型文本的监督检测器将需要新的标记训练数据，在实践中是不可行的。在这项工作中，我们解决这个问题，提出了一个用于检测来自未知目标生成器的AI生成文本的领域泛化框架。我们提出的框架EAGLE利用迄今为止从旧语言模型获得的标记数据，并学习跨这些生成器不变的特征，以便检测由未知目标生成器生成的文本。EAGLE通过结合自监督的表征能力来学习这种领域不变特征。

    arXiv:2403.15690v1 Announce Type: cross  Abstract: With the advancement in capabilities of Large Language Models (LLMs), one major step in the responsible and safe use of such LLMs is to be able to detect text generated by these models. While supervised AI-generated text detectors perform well on text generated by older LLMs, with the frequent release of new LLMs, building supervised detectors for identifying text from such new models would require new labeled training data, which is infeasible in practice. In this work, we tackle this problem and propose a domain generalization framework for the detection of AI-generated text from unseen target generators. Our proposed framework, EAGLE, leverages the labeled data that is available so far from older language models and learns features invariant across these generators, in order to detect text generated by an unknown target generator. EAGLE learns such domain-invariant features by combining the representational power of self-supervised 
    
[^101]: AC4：用于ZKP中电路约束的代数计算检查器

    AC4: Algebraic Computation Checker for Circuit Constraints in ZKPs

    [https://arxiv.org/abs/2403.15676](https://arxiv.org/abs/2403.15676)

    该论文引入了一种新方法，通过将算术电路约束编码为多项式方程系统，并通过代数计算在有限域上解决多项式方程系统，以精确定位ZKP电路中两种不同类型的错误。

    

    ZKP系统已经引起了人们的关注，在当代密码学中发挥着基础性作用。 Zk-SNARK协议主导了ZKP的使用，通常通过算术电路编程范式实现。然而，欠约束或过约束的电路可能导致错误。 欠约束的电路指的是缺乏必要约束的电路，导致电路中出现意外解决方案，并导致验证者接受错误见证。 过约束的电路是指约束过度的电路，导致电路缺乏必要的解决方案，并导致验证者接受没有见证，使电路毫无意义。 本文介绍了一种新方法，用于找出ZKP电路中两种不同类型的错误。 该方法涉及将算术电路约束编码为多项式方程系统，并通过代数计算在有限域上解决多项式方程系统。

    arXiv:2403.15676v1 Announce Type: cross  Abstract: ZKP systems have surged attention and held a fundamental role in contemporary cryptography. Zk-SNARK protocols dominate the ZKP usage, often implemented through arithmetic circuit programming paradigm. However, underconstrained or overconstrained circuits may lead to bugs. Underconstrained circuits refer to circuits that lack the necessary constraints, resulting in unexpected solutions in the circuit and causing the verifier to accept a bogus witness. Overconstrained circuits refer to circuits that are constrained excessively, resulting in the circuit lacking necessary solutions and causing the verifier to accept no witness, rendering the circuit meaningless. This paper introduces a novel approach for pinpointing two distinct types of bugs in ZKP circuits. The method involves encoding the arithmetic circuit constraints to polynomial equation systems and solving polynomial equation systems over a finite field by algebraic computation. T
    
[^102]: 大型语言模型时代的生物医学人工智能

    AI for Biomedicine in the Era of Large Language Models

    [https://arxiv.org/abs/2403.15673](https://arxiv.org/abs/2403.15673)

    大型语言模型在生物医学领域展现出巨大潜力，能用于推动生物医学知识的发现和应用

    

    生物医学人工智能的能力涵盖了广泛的领域，从解决量子系统的偏微分方程，到预测化学或蛋白质结构的分子水平，进一步延伸到预测传染病爆发等社会预测。最近大型语言模型的进步，如ChatGPT模型，展示了在自然语言任务方面的显著实力，比如翻译语言，构建聊天机器人以及回答问题。当考虑生物医学数据时，我们观察到与自然语言类似的序列性: 生物医学文献和健康记录呈现为文本，生物序列或测序数据以序列方式排列，或者传感器数据如脑信号则呈现为时间序列。一个问题出现了: 我们是否能利用最近大型语言模型的潜力来推动生物医学知识的发现? 在这项调查中，我们将探讨

    arXiv:2403.15673v1 Announce Type: new  Abstract: The capabilities of AI for biomedicine span a wide spectrum, from the atomic level, where it solves partial differential equations for quantum systems, to the molecular level, predicting chemical or protein structures, and further extending to societal predictions like infectious disease outbreaks. Recent advancements in large language models, exemplified by models like ChatGPT, have showcased significant prowess in natural language tasks, such as translating languages, constructing chatbots, and answering questions. When we consider biomedical data, we observe a resemblance to natural language in terms of sequences: biomedical literature and health records presented as text, biological sequences or sequencing data arranged in sequences, or sensor data like brain signals as time series. The question arises: Can we harness the potential of recent large language models to drive biomedical knowledge discoveries? In this survey, we will expl
    
[^103]: 大型语言模型的差分私有下一个标记预测

    Differentially Private Next-Token Prediction of Large Language Models

    [https://arxiv.org/abs/2403.15638](https://arxiv.org/abs/2403.15638)

    提出了Private Mixing of Ensemble Distributions (PMixED)：通过将模型的输出分布投影到公共LLM的输出分布周围的集合上，并采样平均来实现实际的下一个标记预测，以更轻量化的方式实现对隐私敏感的大型语言模型的预测。

    

    确保大型语言模型（LLMs）的隐私日益重要。DP-SGD是实现这一目标的最广泛采用的技术，它以一种保证差分隐私的方式训练模型。然而，DP-SGD需要比SGD更长的训练时间和更大的内存需求，同时过高估计对手具有白盒访问模型的能力。更现实的场景假设只有对隐私敏感的LLM进行黑盒访问。在这些观察的基础上，我们提出了私有混合集合分布（PMixED）：一种通过将模型的每个输出分布从一个经过精细调整的LLM集合投影到公共LLM输出分布周围的集合上，然后对投影分布进行平均并从中抽样来实现实际的下一个标记预测的私有预测协议。我们的方法比DP-SGD更轻量化，因为它与模型无关。

    arXiv:2403.15638v1 Announce Type: cross  Abstract: Ensuring the privacy of Large Language Models (LLMs) is becoming increasingly important. The most widely adopted technique to accomplish this is DP-SGD, which trains a model in such a way that guarantees Differential Privacy (DP). However, DP-SGD requires longer training times and larger memory requirements than SGD, while overestimating an adversary's capabilities in having white box access to the model. A more realistic scenario assumes only black-box access to a privacy-sensitive LLM. Motivated by these observations, we present Private Mixing of Ensemble Distributions (PMixED): a private prediction protocol that achieves practical next-token prediction by projecting each of the model's output distribution from an ensemble of fine-tuned LLMs onto a set around a public LLM's output distribution, then averaging the projected distributions and sampling from it. Our approach is more lightweight than DP-SGD in that it is model agnostic, i
    
[^104]: NaturalTurn：一种将转录件分割成自然对话转折的方法

    NaturalTurn: A Method to Segment Transcripts into Naturalistic Conversational Turns

    [https://arxiv.org/abs/2403.15615](https://arxiv.org/abs/2403.15615)

    NaturalTurn是一种专门设计用于准确捕捉自然对话交流动态的轮次分割算法，通过区分说话者的主要对话轮次和听众的次要话语，能够比现有方法更好地提取转录信息。

    

    arXiv:2403.15615v1 公告类型: 新的 摘要: 对话是社会、认知和计算科学越来越感兴趣的主题。然而，随着对话数据集的规模和复杂性不断增加，研究人员缺乏可伸缩的方法将语音转录转换为会话轮次——社会互动的基本构建模块。我们介绍了“NaturalTurn”，一种旨在准确捕捉自然交流动态的轮次分割算法。NaturalTurn通过区分说话者的主要对话轮次和听众的次要话语，如背景声、简短插话和其他表现对话特征的平行言语形式，来运作。使用大型对话语料库的数据，我们展示了与现有方法派生的转录相比，NaturalTurn派生的转录表现出有利的统计和推断特性。NaturalTurn算法代表了一种改进。

    arXiv:2403.15615v1 Announce Type: new  Abstract: Conversation is the subject of increasing interest in the social, cognitive, and computational sciences. And yet, as conversational datasets continue to increase in size and complexity, researchers lack scalable methods to segment speech-to-text transcripts into conversational turns--the basic building blocks of social interaction. We introduce "NaturalTurn," a turn segmentation algorithm designed to accurately capture the dynamics of naturalistic exchange. NaturalTurn operates by distinguishing speakers' primary conversational turns from listeners' secondary utterances, such as backchannels, brief interjections, and other forms of parallel speech that characterize conversation. Using data from a large conversation corpus, we show how NaturalTurn-derived transcripts demonstrate favorable statistical and inferential characteristics compared to transcripts derived from existing methods. The NaturalTurn algorithm represents an improvement i
    
[^105]: LimGen: 探究用于生成研究论文建议性局限的LLMs

    LimGen: Probing the LLMs for Generating Suggestive Limitations of Research Papers

    [https://arxiv.org/abs/2403.15529](https://arxiv.org/abs/2403.15529)

    本文提出了一个新颖而具有挑战性的任务，即为研究论文生成建议性局限，通过调查大型语言模型的多种方法来揭示相关挑战、实践见解和潜在机会。

    

    检查局限是学术研究评审过程中的关键步骤，揭示了研究可能缺乏决定性或需要加强的方面。这有助于读者考虑进一步研究的更广泛影响。本文提出了研究论文建议性局限生成（SLG）的一项新颖且具有挑战性的任务。我们编制了一个名为LimGen的数据集，包含来自ACL文集的4068篇研究论文及其相关局限。我们调查了多种方法来利用大型语言模型（LLMs）生成建议性局限，通过彻底研究相关挑战、实践见解和潜在机会。我们的LimGen数据集和代码可以在https://github.com/armbf/LimGen 上获取。

    arXiv:2403.15529v1 Announce Type: cross  Abstract: Examining limitations is a crucial step in the scholarly research reviewing process, revealing aspects where a study might lack decisiveness or require enhancement. This aids readers in considering broader implications for further research. In this article, we present a novel and challenging task of Suggestive Limitation Generation (SLG) for research papers. We compile a dataset called LimGen, encompassing 4068 research papers and their associated limitations from the ACL anthology. We investigate several approaches to harness large language models (LLMs) for producing suggestive limitations, by thoroughly examining the related challenges, practical insights, and potential opportunities. Our LimGen dataset and code can be accessed at https://github.com/armbf/LimGen.
    
[^106]: CTSM：将特质和状态情绪相结合的共情响应模型

    CTSM: Combining Trait and State Emotions for Empathetic Response Model

    [https://arxiv.org/abs/2403.15516](https://arxiv.org/abs/2403.15516)

    CTSM模型结合特质和状态情绪，通过构建和编码情绪嵌入以及引入情绪引导模块，解决了先前处理情绪感知不足的问题。

    

    共情性响应生成旨在赋予对话系统感知说话者情绪并相应生成共情性回应的能力。心理研究表明，作为共情的一个重要因素，情绪包括特质情绪（静态且与环境无关）和状态情绪（动态且与环境相关）。然而，先前的研究将它们单独处理，导致对情境情绪的感知不足，进而影响了有效的共情表达。为解决这一问题，我们提出了将特质和状态情绪相结合的共情响应模型（CTSM）。具体来说，为了充分感知对话中的情绪，我们首先构建和编码特质和状态情绪嵌入，然后通过一个情绪引导模块进一步增强情绪感知能力，该模块指导情绪表达。此外，我们提出了一种交叉对比学习。

    arXiv:2403.15516v1 Announce Type: cross  Abstract: Empathetic response generation endeavors to empower dialogue systems to perceive speakers' emotions and generate empathetic responses accordingly. Psychological research demonstrates that emotion, as an essential factor in empathy, encompasses trait emotions, which are static and context-independent, and state emotions, which are dynamic and context-dependent. However, previous studies treat them in isolation, leading to insufficient emotional perception of the context, and subsequently, less effective empathetic expression. To address this problem, we propose Combining Trait and State emotions for Empathetic Response Model (CTSM). Specifically, to sufficiently perceive emotions in dialogue, we first construct and encode trait and state emotion embeddings, and then we further enhance emotional perception capability through an emotion guidance module that guides emotion representation. In addition, we propose a cross-contrastive learnin
    
[^107]: 通过决策边界感知数据增强在低资源环境中提高有效性和稳健性

    Enhancing Effectiveness and Robustness in a Low-Resource Regime via Decision-Boundary-aware Data Augmentation

    [https://arxiv.org/abs/2403.15512](https://arxiv.org/abs/2403.15512)

    本文提出了一种决策边界感知的数据增强策略，通过移动潜在特征、重构生成模糊版本以及采用中K采样来增强生成句子的多样性，从而比较于其他方法提高了在低资源环境中的有效性和稳健性。

    

    在低资源环境中利用深度学习模型需要进行数据增强，但直接方法（如mixup和cutout）在文本数据上的应用受限于其离散特性。本文受到决策边界的最新研究启发，提出了一种决策边界感知的数据增强策略，利用预训练的语言模型来增强稳健性。该技术首先专注于将潜在特征移近决策边界，然后进行重构以生成一个带有软标签的模糊版本。此外，建议使用中K采样来增强生成句子的多样性。

    arXiv:2403.15512v1 Announce Type: cross  Abstract: Efforts to leverage deep learning models in low-resource regimes have led to numerous augmentation studies. However, the direct application of methods such as mixup and cutout to text data, is limited due to their discrete characteristics. While methods using pretrained language models have exhibited efficiency, they require additional considerations for robustness. Inspired by recent studies on decision boundaries, this paper proposes a decision-boundary-aware data augmentation strategy to enhance robustness using pretrained language models. The proposed technique first focuses on shifting the latent features closer to the decision boundary, followed by reconstruction to generate an ambiguous version with a soft label. Additionally, mid-K sampling is suggested to enhance the diversity of the generated sentences. This paper demonstrates the performance of the proposed augmentation strategy compared to other methods through extensive ex
    
[^108]: 在技术语言处理任务中评估LLMs的性能

    Evaluating the Performance of LLMs on Technical Language Processing tasks

    [https://arxiv.org/abs/2403.15503](https://arxiv.org/abs/2403.15503)

    该研究评估了LLMs在技术语言处理任务中的性能，通过研究美国联邦电信法规第47章，尝试简化信息收集任务。

    

    在这篇论文中，我们介绍了一项关于LLMs在技术语言处理任务中性能评估研究的结果。人类经常面临需要从不同来源收集信息并需要理解大量文本的任务。这些任务对人类来说可能非常复杂，通常需要深入研究，包括多次阅读文本的部分内容。为了简化信息收集的任务，我们评估了LLMs在聊天界面上的表现，评估它们是否能够回答标准问题，这些问题可以基于人类对文本内容的阅读来预期人类能够回答。我们研究的文本为《美国联邦法规》第47章《美国法典》，这一章描述了作为联邦通信委员会（FCC）管理下商用电信的规定。这一段文本是我们感兴趣的研究对象，因为我们更广泛的研究涉及机器处理这类文本时遇到的困难。

    arXiv:2403.15503v1 Announce Type: new  Abstract: In this paper we present the results of an evaluation study of the perfor-mance of LLMs on Technical Language Processing tasks. Humans are often confronted with tasks in which they have to gather information from dispar-ate sources and require making sense of large bodies of text. These tasks can be significantly complex for humans and often require deep study including rereading portions of a text. Towards simplifying the task of gathering in-formation we evaluated LLMs with chat interfaces for their ability to provide answers to standard questions that a human can be expected to answer based on their reading of a body of text. The body of text under study is Title 47 of the United States Code of Federal Regulations (CFR) which describes regula-tions for commercial telecommunications as governed by the Federal Com-munications Commission (FCC). This has been a body of text of interest be-cause our larger research concerns the issue of ma
    
[^109]: 在线文字自动完成的顺序决策

    Sequential Decision-Making for Inline Text Autocomplete

    [https://arxiv.org/abs/2403.15502](https://arxiv.org/abs/2403.15502)

    通过强化学习和顺序决策制定改进了文本输入系统中的在线自动完成建议，将认知负荷纳入模型训练目标，基于文本输入速度的奖励函数。

    

    自动完成建议是现代文本输入系统中的基本功能，应用于诸如消息传递和电子邮件撰写等领域。通常，自动完成建议是从具有置信度阈值的语言模型生成的。然而，这个阈值并没有直接考虑用户因显示建议而施加的认知负荷，例如从输入切换到阅读建议的上下文以及决定是否接受建议的时间。在本文中，我们研究了通过顺序决策制定来改进文本输入系统中的在线自动完成建议问题，并使用强化学习通过随时间与目标用户的重复交互来学习建议策略。这种制定允许我们将认知负荷因素纳入训练自动完成模型的目标中，通过基于文本输入速度的奖励函数。我们获得了理论方面的...

    arXiv:2403.15502v1 Announce Type: new  Abstract: Autocomplete suggestions are fundamental to modern text entry systems, with applications in domains such as messaging and email composition. Typically, autocomplete suggestions are generated from a language model with a confidence threshold. However, this threshold does not directly take into account the cognitive load imposed on the user by surfacing suggestions, such as the effort to switch contexts from typing to reading the suggestion, and the time to decide whether to accept the suggestion. In this paper, we study the problem of improving inline autocomplete suggestions in text entry systems via a sequential decision-making formulation, and use reinforcement learning to learn suggestion policies through repeated interactions with a target user over time. This formulation allows us to factor cognitive load into the objective of training an autocomplete model, through a reward function based on text entry speed. We acquired theoretica
    
[^110]: 通过个性化ChatGPT辅助增强阿拉伯语医疗支持

    Enhancing Medical Support in the Arabic Language Through Personalized ChatGPT Assistance

    [https://arxiv.org/abs/2403.15501](https://arxiv.org/abs/2403.15501)

    通过使用ChatGPT在阿拉伯语医疗诊断中取得了有希望的性能，平均相似度评分为76%，链式提示技术相对有优势。

    

    这篇论文讨论了在线医疗诊断与传统看医生方式之间日益增长的受欢迎程度。它强调了现有工具的局限性，并强调了使用ChatGPT的优势，ChatGPT可以提供实时的个性化医疗诊断，而且是免费的。该段落总结了一项评估ChatGPT在阿拉伯语医疗诊断中性能的研究。该研究涉及编制疾病信息的数据集，并使用不同的提示技术为每种疾病生成多条消息。通过测量其响应与实际疾病之间的相似度来评估ChatGPT的性能。结果显示出令人鼓舞的表现，相似度评估的平均分数约为76%。使用了各种提示技术，链式提示展现出相对优势。该研究还记录了ChatGPT API的平均响应时间为6.12秒。

    arXiv:2403.15501v1 Announce Type: new  Abstract: This Paper discusses the growing popularity of online medical diagnosis as an alternative to traditional doctor visits. It highlights the limitations of existing tools and emphasizes the advantages of using ChatGPT, which provides real-time, personalized medical diagnosis at no cost. The paragraph summarizes a research study that evaluated the performance of ChatGPT in Arabic medical diagnosis. The study involved compiling a dataset of disease information and generating multiple messages for each disease using different prompting techniques. ChatGPT's performance was assessed by measuring the similarity between its responses and the actual diseases. The results showed promising performance, with average scores of around 76% for similarity measures. Various prompting techniques were used, and chain prompting demonstrated a relative advantage. The study also recorded an average response time of 6.12 seconds for the ChatGPT API, which is co
    
[^111]: 棋类语言模型中的新颖世界模型和潜变量估计

    Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models

    [https://arxiv.org/abs/2403.15498](https://arxiv.org/abs/2403.15498)

    棋类语言模型在没有先验知识的情况下，通过下一个字符预测训练，仍能学习出内部表示的棋盘状态

    

    语言模型展现了前所未有的能力，引发了关于其性能来源的讨论。是仅仅学习句法模式和表面统计结果，还是从文本中提取语义和世界模型？我们在象棋这个更复杂的领域扩展了之前的工作，通过在真实游戏中训练模型，使用线性探测和对比激活来研究模型的内部表示。尽管模型没有先验的游戏知识，仅仅通过下一个字符预测进行训练，我们发现了关于棋盘状态的内部表示的证据。

    arXiv:2403.15498v1 Announce Type: cross  Abstract: Language models have shown unprecedented capabilities, sparking debate over the source of their performance. Is it merely the outcome of learning syntactic patterns and surface level statistics, or do they extract semantics and a world model from the text? Prior work by Li et al. investigated this by training a GPT model on synthetic, randomly generated Othello games and found that the model learned an internal representation of the board state. We extend this work into the more complex domain of chess, training on real games and investigating our model's internal representations using linear probes and contrastive activations. The model is given no a priori knowledge of the game and is solely trained on next character prediction, yet we find evidence of internal representations of board state. We validate these internal representations by using them to make interventions on the model's activations and edit its internal board state. Un
    
[^112]: 面向细粒度文本分类模型和数据集的视觉分析

    Visual Analytics for Fine-grained Text Classification Models and Datasets

    [https://arxiv.org/abs/2403.15492](https://arxiv.org/abs/2403.15492)

    发展了SemLa，一个针对细粒度文本分类模型开发工作流需求的新型视觉分析系统，用于分解数据集中的复杂语义结构和可视化文本含义中的细微差别

    

    在自然语言处理（NLP）中，文本分类任务变得越来越细粒度化，因为数据集被分成更多更难以区分的类别。因此，数据集的语义结构变得更复杂，模型决策也变得更加难以解释。在这种空缺的情况下，我们与NLP领域专家密切合作，通过设计和评估的迭代过程，表征和解决他们在开发细粒度文本分类模型工作流中不断增长的需求。这种合作的结果是开发出了SemLa，这是一个针对以下需求定制的新型视觉分析系统：1）在将数据集空间化到模型嵌入空间时分解复杂的语义结构，2）可视化文本意义中的细微差别。

    arXiv:2403.15492v1 Announce Type: new  Abstract: In natural language processing (NLP), text classification tasks are increasingly fine-grained, as datasets are fragmented into a larger number of classes that are more difficult to differentiate from one another. As a consequence, the semantic structures of datasets have become more complex, and model decisions more difficult to explain. Existing tools, suited for coarse-grained classification, falter under these additional challenges. In response to this gap, we worked closely with NLP domain experts in an iterative design-and-evaluation process to characterize and tackle the growing requirements in their workflow of developing fine-grained text classification models. The result of this collaboration is the development of SemLa, a novel visual analytics system tailored for 1) dissecting complex semantic structures in a dataset when it is spatialized in model embedding space, and 2) visualizing fine-grained nuances in the meaning of text
    
[^113]: 开源对话式LLMs不了解大部分西班牙语单词

    Open Source Conversational LLMs do not know most Spanish words

    [https://arxiv.org/abs/2403.15491](https://arxiv.org/abs/2403.15491)

    本研究评估了开源对话式LLMs对西班牙语单词的了解程度，结果显示它们无法正确使用大部分单词写句子。

    

    在对大型语言模型（LLMs），特别是可以与用户进行交互的对话模型的兴趣不断增加的情况下，开发了大量开源聊天LLMs。这些模型在广泛的基准上进行评估，以评估它们在回答问题或解决几乎任何可能的主题上的能力，或者测试它们理解或解释文本的能力。然而，对这些模型对语言的了解的评估却受到了远远较少的关注。例如，它们能够识别和使用不同语言中的单词数。本文通过在参考词典中测试部分单词的样本来评估开源聊天LLMs对西班牙语单词的了解程度。结果显示，开源聊天LLMs对重要部分单词产生了错误的含义，并且无法正确使用大部分单词在上下文中写句子。

    arXiv:2403.15491v1 Announce Type: new  Abstract: The growing interest in Large Language Models (LLMs) and in particular in conversational models with which users can interact has led to the development of a large number of open-source chat LLMs. These models are evaluated on a wide range of benchmarks to assess their capabilities in answering questions or solving problems on almost any possible topic or to test their ability to reason or interpret texts. Instead, the evaluation of the knowledge that these models have of the languages has received much less attention. For example, the words that they can recognize and use in different languages. In this paper, we evaluate the knowledge that open-source chat LLMs have of Spanish words by testing a sample of words in a reference dictionary. The results show that open-source chat LLMs produce incorrect meanings for an important fraction of the words and are not able to use most of the words correctly to write sentences with context. These 
    
[^114]: 序列到序列语言模型用于梦境叙事中的角色和情感检测

    Sequence-to-Sequence Language Models for Character and Emotion Detection in Dream Narratives

    [https://arxiv.org/abs/2403.15486](https://arxiv.org/abs/2403.15486)

    本研究提出一种序列到序列语言模型框架，首次在梦境叙事中进行角色和情感检测研究，展示语言模型可以有效应对该复杂任务，监督模型表现更佳且参数更少。

    

    梦境研究对于理解人类的(非)意识、认知和文化数个世纪来一直至关重要。定量分析梦境依赖于对梦境叙述的劳动密集型手动注释。我们通过一种自然语言序列到序列生成框架自动化这一过程。本文首次在梦境叙事的开放DreamBank语料库英文部分中进行了角色和情感检测研究。我们的结果表明语言模型可以有效地解决这一复杂任务。为了了解预测性能，我们评估了模型大小、角色的预测顺序以及对专有名称和角色特征的考虑的影响。我们将我们的方法与使用上下文学习的大型语言模型进行了比较。我们的监督模型表现更好，同时参数数量减少了28倍。我们的模型及其生成的注释已公开可用。

    arXiv:2403.15486v1 Announce Type: cross  Abstract: The study of dreams has been central to understanding human (un)consciousness, cognition, and culture for centuries. Analyzing dreams quantitatively depends on labor-intensive, manual annotation of dream narratives. We automate this process through a natural language sequence-to-sequence generation framework. This paper presents the first study on character and emotion detection in the English portion of the open DreamBank corpus of dream narratives. Our results show that language models can effectively address this complex task. To get insight into prediction performance, we evaluate the impact of model size, prediction order of characters, and the consideration of proper names and character traits. We compare our approach with a large language model using in-context learning. Our supervised models perform better while having 28 times fewer parameters. Our model and its generated annotations are made publicly available.
    
[^115]: MOGAM：一种用于抑郁症检测的多模态面向对象图注意模型

    MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression Detection

    [https://arxiv.org/abs/2403.15485](https://arxiv.org/abs/2403.15485)

    MOGAM模型是为了克服现有抑郁症检测方法在不同社交媒体数据类型上的限制而提出，通过多模态数据的综合应用，实现了更具可扩展性和多功能性的解决方案。

    

    早期检测在抑郁症治疗中起着至关重要的作用。因此，许多研究关注社交媒体平台，个体在该平台表达情绪，旨在实现抑郁症的早期检测。然而，现有方法主要依赖特定特征，导致在不同类型的社交媒体数据集（如文本、图像或视频）上的可扩展性有限。为克服这一限制，我们引入了一种多模态面向对象图注意模型（MOGAM），可应用于各种数据类型，提供更具可伸缩性和多功能性的解决方案。此外，为确保我们的模型能够捕捉抑郁症的真实症状，我们仅收集了具有临床诊断的用户的视频日志。为了利用视频日志的多样特征，我们采用多模态方法，并收集额外的元数据，如视频日志的标题、描述和持续时间。为了有效地聚合

    arXiv:2403.15485v1 Announce Type: cross  Abstract: Early detection plays a crucial role in the treatment of depression. Therefore, numerous studies have focused on social media platforms, where individuals express their emotions, aiming to achieve early detection of depression. However, the majority of existing approaches often rely on specific features, leading to limited scalability across different types of social media datasets, such as text, images, or videos. To overcome this limitation, we introduce a Multimodal Object-Oriented Graph Attention Model (MOGAM), which can be applied to diverse types of data, offering a more scalable and versatile solution. Furthermore, to ensure that our model can capture authentic symptoms of depression, we only include vlogs from users with a clinical diagnosis. To leverage the diverse features of vlogs, we adopt a multimodal approach and collect additional metadata such as the title, description, and duration of the vlogs. To effectively aggregat
    
[^116]: RakutenAI-7B：为日本语言扩展大型语言模型

    RakutenAI-7B: Extending Large Language Models for Japanese

    [https://arxiv.org/abs/2403.15484](https://arxiv.org/abs/2403.15484)

    RakutenAI-7B是一套日本导向的大型语言模型，在日本LM Harness基准测试中表现最好，分别发布了指导和聊天调整的模型。

    

    我们介绍了RakutenAI-7B，这是一套以日本为导向的大型语言模型，在日本LM Harness基准测试中取得了最佳性能，优于开放的7B模型。除了基础模型外，我们还发布了根据指导和聊天进行调整的模型，分别是RakutenAI-7B-instruct和RakutenAI-7B-chat，使用Apache 2.0许可发布。

    arXiv:2403.15484v1 Announce Type: new  Abstract: We introduce RakutenAI-7B, a suite of Japanese-oriented large language models that achieve the best performance on the Japanese LM Harness benchmarks among the open 7B models. Along with the foundation model, we release instruction- and chat-tuned models, RakutenAI-7B-instruct and RakutenAI-7B-chat respectively, under the Apache 2.0 license.
    
[^117]: 利用大型语言模型生成多级反馈，为初学者同行辅导员赋能

    Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors

    [https://arxiv.org/abs/2403.15482](https://arxiv.org/abs/2403.15482)

    利用大型语言模型为初学者同行辅导员提供多级详细反馈，赋能规模化的支持心理健康问题患者。

    

    实践和个性化反馈是培养具有临床技能的同行辅导员的关键过程。然而，现有的反馈机制主要依赖于人工监督。同行辅导员经常缺乏机制来从经验丰富的导师那里获得详细的反馈，这使得他们难以支持使用同行辅导的大量心理健康问题患者。我们的工作旨在利用大型语言模型提供情境化和多级反馈，以赋能规模化的初学者同行辅导员。为实现这一目标，我们与一组高级心理治疗督导共同设计了一个多级反馈分类法，然后构建了一个具有完整反馈注释的400次情绪支持对话的公开可用数据集。我们进一步设计了一种基于大型语言模型的自我改进方法，以增强反馈的自动生成。

    arXiv:2403.15482v1 Announce Type: new  Abstract: Realistic practice and tailored feedback are key processes for training peer counselors with clinical skills. However, existing mechanisms of providing feedback largely rely on human supervision. Peer counselors often lack mechanisms to receive detailed feedback from experienced mentors, making it difficult for them to support the large number of people with mental health issues who use peer counseling. Our work aims to leverage large language models to provide contextualized and multi-level feedback to empower peer counselors, especially novices, at scale. To achieve this, we co-design with a group of senior psychotherapy supervisors to develop a multi-level feedback taxonomy, and then construct a publicly available dataset with comprehensive feedback annotations of 400 emotional support conversations. We further design a self-improvement method on top of large language models to enhance the automatic generation of feedback. Via qualita
    
[^118]: 将监督式提取和生成式语言模型集成用于自杀风险证据摘要

    Integrating Supervised Extractive and Generative Language Models for Suicide Risk Evidence Summarization

    [https://arxiv.org/abs/2403.15478](https://arxiv.org/abs/2403.15478)

    该研究集成了监督式提取和生成式语言模型，提出一种提供自杀风险支持证据的方法，并在CLPsych 2024 shared task中取得了显著成绩。

    

    我们提出了一种方法，该方法集成了监督式提取和生成式语言模型，用于在CLPsych 2024共享任务中提供自杀风险的支持证据。我们的方法包括三个步骤。首先，我们构建了一个基于BERT的模型，用于估计句子级别的自杀风险和负面情绪。接下来，我们通过强调自杀风险和负面情绪的概率提高，精确定位高自杀风险句子。最后，我们使用MentaLLaMa框架整合生成式摘要和从确定的高自杀风险句子和一个专门的自杀风险词典中提取摘要。我们的团队SophiaADS在突出摘要中取得了第一名，在摘要生成中根据召回率和一致性指标分别排名第十。

    arXiv:2403.15478v1 Announce Type: new  Abstract: We propose a method that integrates supervised extractive and generative language models for providing supporting evidence of suicide risk in the CLPsych 2024 shared task. Our approach comprises three steps. Initially, we construct a BERT-based model for estimating sentence-level suicide risk and negative sentiment. Next, we precisely identify high suicide risk sentences by emphasizing elevated probabilities of both suicide risk and negative sentiment. Finally, we integrate generative summaries using the MentaLLaMa framework and extractive summaries from identified high suicide risk sentences and a specialized dictionary of suicidal risk words. SophiaADS, our team, achieved 1st place for highlight extraction and ranked 10th for summary generation, both based on recall and consistency metrics, respectively.
    
[^119]: 使用紧凑语言模型和ChatGPT-4改进的高效论点分类

    Efficient argument classification with compact language models and ChatGPT-4 refinements

    [https://arxiv.org/abs/2403.15473](https://arxiv.org/abs/2403.15473)

    论文通过比较研究了几种基于深度学习的模型在论点挖掘中的应用，提出了基于BERT架构和ChatGPT-4微调模型的集成模型，结果显示BERT+ChatGPT-4在论点分类方面表现优异。

    

    论点挖掘（AM）被定义为自动识别和提取论证组成部分（如前提、主张等）并检测它们之间的关系（即支持、反驳、无关系）的任务。深度学习模型使我们能够比传统方法更有效地分析论点并提取它们的语义。本文介绍了在论点挖掘中几种基于深度学习的模型的比较研究。该工作集中在论点分类上。研究是在广泛的数据集（Args.me, UKP, US2016）上进行的。本文的主要创新点是基于BERT架构的集成模型和作为微调模型的ChatGPT-4。提出的结果显示，BERT+ChatGPT-4在表现上优于其他基于Transformer和LSTM的模型。观察到的改进在大多数情况下大于10。

    arXiv:2403.15473v1 Announce Type: new  Abstract: Argument mining (AM) is defined as the task of automatically identifying and extracting argumentative components (e.g. premises, claims, etc.) and detecting the existing relations among them (i.e., support, attack, no relations). Deep learning models enable us to analyze arguments more efficiently than traditional methods and extract their semantics. This paper presents comparative studies between a few deep learning-based models in argument mining. The work concentrates on argument classification. The research was done on a wide spectrum of datasets (Args.me, UKP, US2016). The main novelty of this paper is the ensemble model which is based on BERT architecture and ChatGPT-4 as fine tuning model. The presented results show that BERT+ChatGPT-4 outperforms the rest of the models including other Transformer-based and LSTM-based models. The observed improvement is, in most cases, greater than 10The presented analysis can provide crucial insi
    
[^120]: 使用先进的持续预训练构建越南语言模型 Vi-Mistral-X

    Vi-Mistral-X: Building a Vietnamese Language Model with Advanced Continual Pre-training

    [https://arxiv.org/abs/2403.15470](https://arxiv.org/abs/2403.15470)

    该论文介绍了 vi-Mistral-X，一个专为越南语设计的创新大型语言模型，采用了持续预训练方法，并引入了针对越南语的额外预训练阶段，大大提高了其对越南语的理解和生成能力。

    

    大型语言模型（LLM）的进步显著改变了自然语言处理领域，尽管专注于英语中心模型导致了一些特定语言（包括越南语）的研究空白。为解决这一问题，本文介绍了vi-mistral-x，这是一个专为越南语设计的创新大型语言模型。它利用了基于 Mistral 架构的一种独特的持续预训练方法，其中包括分组查询注意力和滑动窗口注意力技术。该模型 vi-Mistral-X 在改进对越南语言的理解和生成方面迈出了重要一步。它引入了一个专门针对越南语的额外持续预训练阶段，增强了模型在理解复杂语言细微差别和生成准确、上下文感知的越南语文本方面的能力。通过全面的测试

    arXiv:2403.15470v1 Announce Type: new  Abstract: The advancement of Large Language Models (LLMs) has significantly transformed the field of natural language processing, although the focus on English-centric models has created a noticeable research gap for specific languages, including Vietnamese. To address this issue, this paper presents vi-mistral-x, an innovative Large Language Model designed expressly for the Vietnamese language. It utilizes a unique method of continual pre-training, based on the Mistral architecture, which incorporates grouped-query attention and sliding window attention techniques. This model, vi-Mistral-X, marks a significant step forward in improving the understanding and generation of the Vietnamese language. It introduces an additional phase of continual pre-training, specifically adapted for Vietnamese, enhancing the model's capability in understanding complex language nuances and generating accurate, context-aware Vietnamese text. Through comprehensive test
    
[^121]: 使用音素计数比奖励驱动的强化学习实现等距神经机器翻译

    Isometric Neural Machine Translation using Phoneme Count Ratio Reward-based Reinforcement Learning

    [https://arxiv.org/abs/2403.15469](https://arxiv.org/abs/2403.15469)

    本论文提出了使用强化学习（RL）开发的等距NMT系统，重点在于优化源语言和目标语言句对中音素计数的对齐。

    

    传统的自动视频配音（AVD）流水线由三个关键模块组成，即自动语音识别（ASR）、神经机器翻译（NMT）和文本到语音（TTS）。AVD管道中使用等距-NMT算法来调节合成输出文本的长度，以确保在配音过程之后，视频和音频的对齐同步。先前的方法集中于调整机器翻译模型源语言和目标语言文本中字符和单词的数量。然而，我们的方法旨在调整音素的数量，因为它们与语音持续时间密切相关。本文提出使用强化学习（RL）开发等距NMT系统，重点优化源语言和目标语言句对中音素计数的对齐。为了评估我们的模型，我们提出了

    arXiv:2403.15469v1 Announce Type: new  Abstract: Traditional Automatic Video Dubbing (AVD) pipeline consists of three key modules, namely, Automatic Speech Recognition (ASR), Neural Machine Translation (NMT), and Text-to-Speech (TTS). Within AVD pipelines, isometric-NMT algorithms are employed to regulate the length of the synthesized output text. This is done to guarantee synchronization with respect to the alignment of video and audio subsequent to the dubbing process. Previous approaches have focused on aligning the number of characters and words in the source and target language texts of Machine Translation models. However, our approach aims to align the number of phonemes instead, as they are closely associated with speech duration. In this paper, we present the development of an isometric NMT system using Reinforcement Learning (RL), with a focus on optimizing the alignment of phoneme counts in the source and target language sentence pairs. To evaluate our models, we propose the 
    
[^122]: 在冒犯性语言检测中的池化策略：针对用户故意的对抗攻击

    Don't be a Fool: Pooling Strategies in Offensive Language Detection from User-Intended Adversarial Attacks

    [https://arxiv.org/abs/2403.15467](https://arxiv.org/abs/2403.15467)

    本文提出了一种针对用户故意的对抗攻击的池化策略，通过引入逐层的简单但有效的池化策略来捕捉冒犯性和标记嵌入，使模型更加稳健，即使攻击率增加。

    

    冒犯性语言检测是过滤辱骂表达并改善在线用户体验的重要任务。然而，恶意用户常常通过引入文本噪音来规避过滤系统。本文将这些规避行为作为用户故意的对抗攻击提出，这些攻击插入特殊符号或利用韩文的独特特征。此外，我们以逐层方式引入简单而有效的池化策略，以抵御所提出的攻击，侧重于前置层而不仅仅是最后一层以捕捉冒犯性和标记嵌入。我们展示了这些池化策略在攻击率增加时更加稳健，即使没有直接训练这样的模式。值得注意的是，我们发现在干净文本上预训练的模型在检测遭受攻击的冒犯性语言方面可以达到可比的性能。

    arXiv:2403.15467v1 Announce Type: new  Abstract: Offensive language detection is an important task for filtering out abusive expressions and improving online user experiences. However, malicious users often attempt to avoid filtering systems through the involvement of textual noises. In this paper, we propose these evasions as user-intended adversarial attacks that insert special symbols or leverage the distinctive features of the Korean language. Furthermore, we introduce simple yet effective pooling strategies in a layer-wise manner to defend against the proposed attacks, focusing on the preceding layers not just the last layer to capture both offensiveness and token embeddings. We demonstrate that these pooling strategies are more robust to performance degradation even when the attack rate is increased, without directly training of such patterns. Notably, we found that models pre-trained on clean texts could achieve a comparable performance in detecting attacked offensive language, 
    
[^123]: 使用展开算法为$n$-grams，Transformers，HMMs和马尔可夫链生成最有可能的序列

    Most Likely Sequence Generation for $n$-Grams, Transformers, HMMs, and Markov Chains, by Using Rollout Algorithms

    [https://arxiv.org/abs/2403.15465](https://arxiv.org/abs/2403.15465)

    本文介绍了一种使用展开算法为$n$-grams，Transformers，HMMs和马尔可夫链生成最有可能的序列的方法

    

    在本文中，我们考虑了一个具有$n$-gram结构的transformer，例如底层的ChatGPT。Transformer提供了下一个单词的概率，可以用来生成单词序列。我们考虑了基于这些概率计算高可能性单词序列的方法。计算从给定初始状态开始的最优（即最有可能）单词序列是一个棘手的问题，因此我们提出了在时间复杂度为$N$和$n$-gram词汇量的低阶多项式的方法来计算$N$个单词的高可能性序列。这些方法基于近似动态规划中的展开方法，一种单策略迭代，可以改善任何给定启发式策略的性能。在我们的情况下，我们使用一种贪婪启发式，生成具有最高概率的下一个单词。我们通过分析、示例和计算实验表明了我们的m

    arXiv:2403.15465v1 Announce Type: cross  Abstract: In this paper we consider a transformer with an $n$-gram structure, such as the one underlying ChatGPT. The transformer provides next word probabilities, which can be used to generate word sequences. We consider methods for computing word sequences that are highly likely, based on these probabilities. Computing the optimal (i.e., most likely) word sequence starting with a given initial state is an intractable problem, so we propose methods to compute highly likely sequences of $N$ words in time that is a low order polynomial in $N$ and in the vocabulary size of the $n$-gram. These methods are based on the rollout approach from approximate dynamic programming, a form of single policy iteration, which can improve the performance of any given heuristic policy. In our case we use a greedy heuristic that generates as next word one that has the highest probability. We show with analysis, examples, and computational experimentation that our m
    
[^124]: 基于LLMs的少样本疾病预测：结合预测性代理推理和批判性代理指导的新方法

    LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction

    [https://arxiv.org/abs/2403.15464](https://arxiv.org/abs/2403.15464)

    该论文提出了一种新方法，结合预测性代理推理和批判性代理指导，利用LLMs对结构化患者就诊数据进行预测，取得了较好的效果。

    

    arXiv:2403.15464v1 类型：跨学科 摘要：电子健康记录(EHRs)包含对健康相关预测任务，如疾病预测，有价值的患者数据。传统方法依赖于需要大量标记数据集的监督学习方法，这可能是昂贵和具有挑战性的。在本研究中，我们调查了将大型语言模型(LLMs)应用于将结构化患者就诊数据(例如诊断、实验室、处方)转换为自然语言叙述的可行性。我们使用各种面向EHR预测的提示策略评估了LLMs的零样本和少样本性能。此外，我们提出了一种新方法，利用具有不同角色的LLM代理：一个进行预测并生成推理过程的预测代理，以及分析不正确预测并为改善预测代理推理提供指导的批评代理。我们的结果表明，通过提出的方法，LLMs能够...

    arXiv:2403.15464v1 Announce Type: cross  Abstract: Electronic health records (EHRs) contain valuable patient data for health-related prediction tasks, such as disease prediction. Traditional approaches rely on supervised learning methods that require large labeled datasets, which can be expensive and challenging to obtain. In this study, we investigate the feasibility of applying Large Language Models (LLMs) to convert structured patient visit data (e.g., diagnoses, labs, prescriptions) into natural language narratives. We evaluate the zero-shot and few-shot performance of LLMs using various EHR-prediction-oriented prompting strategies. Furthermore, we propose a novel approach that utilizes LLM agents with different roles: a predictor agent that makes predictions and generates reasoning processes and a critic agent that analyzes incorrect predictions and provides guidance for improving the reasoning of the predictor agent. Our results demonstrate that with the proposed approach, LLMs c
    
[^125]: 评估语言生成在线研究中的效应大小、变异性和功效

    Assessing effect sizes, variability, and power in the on-line study of language production

    [https://arxiv.org/abs/2403.15459](https://arxiv.org/abs/2403.15459)

    评估语言生成在线研究中效应大小、变异性和功效对设计效果的影响

    

    随着疫情的流行，许多实验心理学家和语言学家已经开始在互联网上收集数据（以下简称在线数据）。必须评估这类实验的可行性以及未来实验所需的样本量，以达到足够的统计功效。这反过来需要了解效应大小和变异性的信息。在一系列分析中，我们比较了在实验室和在线进行的相同词汇产生实验中获得的响应时间数据。这些分析让我们能够确定两种设置在效应大小、实验过程中响应的一致性、跨参与者平均响应时间的变异性、参与者之间效应大小的差异，以及未解释变异量的数量是否存在差异。我们通过一系列模拟评估这些差异对设计效果的影响。我们的研究结果对在线研究可能带来的热情进行了调查。

    arXiv:2403.15459v1 Announce Type: new  Abstract: With the pandemic, many experimental psychologists and linguists have started to collect data over the internet (hereafter on-line data). The feasibility of such experiments and the sample sizes required to achieve sufficient statistical power in future experiments have to be assessed. This in turn requires information on effect sizes and variability. In a series of analyses, we compare response time data obtained in the same word production experiment conducted in the lab and on-line. These analyses allow us to determine whether the two settings differ in effect sizes, in the consistency of responses over the course of the experiment, in the variability of average response times across participants, in the magnitude of effect sizes across participants, or in the amount of unexplained variability. We assess the impact of these differences on the power of the design in a series of simulations. Our findings temper the enthusiasm raised by 
    
[^126]: 调整预训练语言模型以检测游戏内垃圾话

    Fine-Tuning Pre-trained Language Models to Detect In-Game Trash Talks

    [https://arxiv.org/abs/2403.15458](https://arxiv.org/abs/2403.15458)

    本研究调查了预训练语言模型在检测游戏内垃圾话和毒性信息方面的能力，使用BERT和GPT模型在DOTA 2游戏对战的聊天数据上进行评估。

    

    玩在线手机和电脑游戏时常见的问题与玩家之间的有毒行为和滥用沟通有关。基于不同的报告和研究，本研究还讨论了在线仇恨言论和毒性对玩家游戏表现和整体幸福感的影响。本研究调查了预训练语言模型对分类或检测游戏内垃圾话或有毒信息的能力。研究采用并评估了预训练的BERT和GPT语言模型在检测游戏内聊天中的毒性方面的表现。利用公开可用的API，收集了来自DOTA 2游戏对战的游戏内聊天数据，经过处理、审查和标记为非毒性、轻微（毒性）和有毒。该研究能够收集约两千个游戏内聊天以训练和测试BERT（Base-uncased）、BERT（Large-uncased）和GPT-3模型。基于这三种模型的最先进表现，本研究得出结论

    arXiv:2403.15458v1 Announce Type: new  Abstract: Common problems in playing online mobile and computer games were related to toxic behavior and abusive communication among players. Based on different reports and studies, the study also discusses the impact of online hate speech and toxicity on players' in-game performance and overall well-being. This study investigates the capability of pre-trained language models to classify or detect trash talk or toxic in-game messages The study employs and evaluates the performance of pre-trained BERT and GPT language models in detecting toxicity within in-game chats. Using publicly available APIs, in-game chat data from DOTA 2 game matches were collected, processed, reviewed, and labeled as non-toxic, mild (toxicity), and toxic. The study was able to collect around two thousand in-game chats to train and test BERT (Base-uncased), BERT (Large-uncased), and GPT-3 models. Based on the three models' state-of-the-art performance, this study concludes p
    
[^127]: WoLF: 用于胸部X线图理解的大型语言模型框架

    WoLF: Large Language Model Framework for CXR Understanding

    [https://arxiv.org/abs/2403.15456](https://arxiv.org/abs/2403.15456)

    WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。

    

    通过现代视觉语言模型(VLMs)取得了对胸部X线图(CXR)理解方面的显着方法进展，展示了令人印象深刻的视觉问答(VQA)和CXR报告生成能力。然而，现有的CXR理解框架仍存在几个程序上的缺陷。(1)以往的方法仅使用CXR报告，这对于全面的视觉问答(VQA)来说是不够的，特别是当需要额外的健康相关数据如用药历史和先前的诊断时。(2)以往的方法使用未经处理的CXR报告，这些报告往往结构随意。虽然现代语言模型可以理解各种文本格式，但为了提供更清晰、有组织的基于解剖学的信息，重构报告可能会增强它们的实用性。(3)目前用于CXR-VQA的评估方法主要强调语言正确性，缺乏对生成答案的微妙评估能力。

    arXiv:2403.15456v1 Announce Type: new  Abstract: Significant methodological strides have been made toward Chest X-ray (CXR) understanding via modern vision-language models (VLMs), demonstrating impressive Visual Question Answering (VQA) and CXR report generation abilities. However, existing CXR understanding frameworks still possess several procedural caveats. (1) Previous methods solely use CXR reports, which are insufficient for comprehensive Visual Question Answering (VQA), especially when additional health-related data like medication history and prior diagnoses are needed. (2) Previous methods use raw CXR reports, which are often arbitrarily structured. While modern language models can understand various text formats, restructuring reports for clearer, organized anatomy-based information could enhance their usefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize linguistic correctness, lacking the capability to offer nuanced assessments of the generated answers.
    
[^128]: 改进文本流中用于微调SentenceBERT的采样方法

    Improving Sampling Methods for Fine-tuning SentenceBERT in Text Streams

    [https://arxiv.org/abs/2403.15455](https://arxiv.org/abs/2403.15455)

    本研究旨在解决概念漂移问题，通过探索七种文本采样方法的有效性，精细调整语言模型，从而减轻性能下降。

    

    互联网上文本数据的激增为机构和公司提供了一个独特的机会，可以监测公众对其服务和产品的意见。考虑到这些数据的快速生成，处理依次到达、潜在无限的文本流的文本流挖掘设置通常比传统的批量学习更合适。虽然预训练语言模型通常因其在流式内容中高质量的文本向量化能力而被广泛采用，但它们在适应概念漂移（数据分布随时间发生变化，从而对模型性能产生负面影响的现象）方面面临挑战。本研究解决了概念漂移问题，探讨了七种文本采样方法对精心微调语言模型的效果，从而减轻性能下降。我们准确评估了这些方法对使用四种不同方式进行微调的SBERT模型的影响。

    arXiv:2403.15455v1 Announce Type: new  Abstract: The proliferation of textual data on the Internet presents a unique opportunity for institutions and companies to monitor public opinion about their services and products. Given the rapid generation of such data, the text stream mining setting, which handles sequentially arriving, potentially infinite text streams, is often more suitable than traditional batch learning. While pre-trained language models are commonly employed for their high-quality text vectorization capabilities in streaming contexts, they face challenges adapting to concept drift - the phenomenon where the data distribution changes over time, adversely affecting model performance. Addressing the issue of concept drift, this study explores the efficacy of seven text sampling methods designed to selectively fine-tune language models, thereby mitigating performance degradation. We precisely assess the impact of these methods on fine-tuning the SBERT model using four differ
    
[^129]: 使用Transformer进行情感检测：一项比较研究

    Emotion Detection with Transformers: A Comparative Study

    [https://arxiv.org/abs/2403.15454](https://arxiv.org/abs/2403.15454)

    本研究探索了在文本数据情感分类中应用基于Transformer的模型，并发现常用技术如去除标点符号和停用词可能会阻碍模型的性能，因为这些元素仍然能够传达情感或强调，而Transformer的优势在于理解文本内的语境关系。

    

    在这项研究中，我们探讨了基于Transformer模型在文本数据情感分类中的应用。我们使用不同变体的Transformer对Emotion数据集进行训练和评估。论文还分析了一些影响模型性能的因素，比如Transformer层的微调、层的可训练性以及文本数据的预处理。我们的分析表明，常用技术如去除标点符号和停用词可能会阻碍模型的性能。这可能是因为Transformer的优势在于理解文本内的语境关系。像标点符号和停用词这样的元素仍然可以传达情感或强调，去除它们可能会破坏这种上下文。

    arXiv:2403.15454v1 Announce Type: new  Abstract: In this study, we explore the application of transformer-based models for emotion classification on text data. We train and evaluate several pre-trained transformer models, on the Emotion dataset using different variants of transformers. The paper also analyzes some factors that in-fluence the performance of the model, such as the fine-tuning of the transformer layer, the trainability of the layer, and the preprocessing of the text data. Our analysis reveals that commonly applied techniques like removing punctuation and stop words can hinder model performance. This might be because transformers strength lies in understanding contextual relationships within text. Elements like punctuation and stop words can still convey sentiment or emphasis and removing them might disrupt this context.
    
[^130]: 面向跨度的信息抽取--信息抽取的统一视角

    Span-Oriented Information Extraction -- A Unifying Perspective on Information Extraction

    [https://arxiv.org/abs/2403.15453](https://arxiv.org/abs/2403.15453)

    提出了以文本中的跨度为中心的统一视角，将各种信息抽取任务重新定位为相同基本面向跨度的信息抽取任务的变体

    

    arXiv:2403.15453v1 公告类型: 跨 当前摘要: 信息抽取指的是自然语言处理（NLP）中的一系列任务，其目的是识别文本中的子序列及其标签。这些任务多年来被用于提取相关信息并将自由文本链接到结构化数据。然而，信息抽取任务之间的异质性妨碍了该领域的进展。因此，我们提出了一个以文本中的跨度为中心的统一视角。我们将这些看似不协调的任务重新定位到这一统一视角中，并将各种信息抽取任务呈现为相同基本面向跨度的信息抽取任务的变体。

    arXiv:2403.15453v1 Announce Type: cross  Abstract: Information Extraction refers to a collection of tasks within Natural Language Processing (NLP) that identifies sub-sequences within text and their labels. These tasks have been used for many years to link extract relevant information and to link free text to structured data. However, the heterogeneity among information extraction tasks impedes progress in this area. We therefore offer a unifying perspective centered on what we define to be spans in text. We then re-orient these seemingly incongruous tasks into this unified perspective and then re-present the wide assortment of information extraction tasks as variants of the same basic Span-Oriented Information Extraction task.
    
[^131]: 工具究竟是什么？从语言模型的视角进行的调查

    What Are Tools Anyway? A Survey from the Language Model Perspective

    [https://arxiv.org/abs/2403.15452](https://arxiv.org/abs/2403.15452)

    从语言模型的角度出发，本调查提供了工具的统一定义为LMs使用的外部程序，并对LM工具场景和方法进行了系统审查，同时通过实证研究了解了各种工具方法的效率，以及突出了该领域的挑战和未来研究方向。

    

    语言模型（LMs）在文本生成任务中非常强大。工具显著增强了LMs在需要复杂技能的任务中的性能。然而，许多研究以不同方式使用"工具"一词，引发了一个问题：工具究竟是什么？接下来，工具在哪里以及如何帮助LMs？在这项调查中，我们提出了一种工具的统一定义，即LMs使用的外部程序，并对LM工具场景和方法进行系统性审查。基于这一审查，我们通过测量各种工具方法在各种基准测试上所需的计算和性能增益来实证研究它们的效率，并突出了该领域的一些挑战和潜在未来研究。

    arXiv:2403.15452v1 Announce Type: cross  Abstract: Language models (LMs) are powerful yet mostly for text generation tasks. Tools have substantially enhanced their performance for tasks that require complex skills. However, many works adopt the term "tool" in different ways, raising the question: What is a tool anyway? Subsequently, where and how do tools help LMs? In this survey, we provide a unified definition of tools as external programs used by LMs, and perform a systematic review of LM tooling scenarios and approaches. Grounded on this review, we empirically study the efficiency of various tooling methods by measuring their required compute and performance gains on various benchmarks, and highlight some challenges and potential future research in the field.
    
[^132]: 通过大型语言模型实现FAIR数据空间的可行性

    Towards Enabling FAIR Dataspaces Using Large Language Models

    [https://arxiv.org/abs/2403.15451](https://arxiv.org/abs/2403.15451)

    本研究展示了大型语言模型在数据空间中的潜力，并提出了进一步探索该领域的研究议程。

    

    数据空间最近在各个领域都得到了采用，包括传统上数字化程度较低的领域，如文化领域。利用语义网技术有助于使数据空间更具FAIR性，但其复杂性对数据空间的采用构成了重大挑战，并增加了其成本。大型语言模型（LLMs）的出现引出了这样一个问题，即这些模型如何支持FAIR数据空间的采用。在这项工作中，我们通过一个具体示例展示了LLMs在数据空间中的潜力。我们还提出了一个研究议程，以探讨这一新兴领域。

    arXiv:2403.15451v1 Announce Type: new  Abstract: Dataspaces have recently gained adoption across various sectors, including traditionally less digitized domains such as culture. Leveraging Semantic Web technologies helps to make dataspaces FAIR, but their complexity poses a significant challenge to the adoption of dataspaces and increases their cost. The advent of Large Language Models (LLMs) raises the question of how these models can support the adoption of FAIR dataspaces. In this work, we demonstrate the potential of LLMs in dataspaces with a concrete example. We also derive a research agenda for exploring this emerging field.
    
[^133]: Loops On Retrieval Augmented Generation (LoRAG)

    Loops On Retrieval Augmented Generation (LoRAG)

    [https://arxiv.org/abs/2403.15450](https://arxiv.org/abs/2403.15450)

    LoRAG是一种新框架，通过引入迭代循环机制提高了检索增强型文本生成的质量，在实验证明在生成的文本连贯性和相关性方面优于当前最先进模型。

    

    本文介绍了一种名为Loops On Retrieval Augmented Generation (LoRAG)的新框架，旨在通过引入迭代循环机制来提高检索增强型文本生成的质量。该架构集成了生成模型、检索机制和动态循环模块，允许通过与从输入上下文中检索的相关信息进行交互来对生成的文本进行迭代改进。对基准数据集的实证评估表明，LoRAG在BLEU分数、ROUGE分数和困惑度方面均超过了现有的最先进模型，展示了其在生成文本的连贯性和相关性方面的有效性。定性评估进一步说明了LoRAG产生上下文丰富且连贯的输出的能力。这项研究为迭代循环在缓解文本生成中的挑战方面的潜力提供了有价值的见解。

    arXiv:2403.15450v1 Announce Type: new  Abstract: This paper presents Loops On Retrieval Augmented Generation (LoRAG), a new framework designed to enhance the quality of retrieval-augmented text generation through the incorporation of an iterative loop mechanism. The architecture integrates a generative model, a retrieval mechanism, and a dynamic loop module, allowing for iterative refinement of the generated text through interactions with relevant information retrieved from the input context. Experimental evaluations on benchmark datasets demonstrate that LoRAG surpasses existing state-of-the-art models in terms of BLEU score, ROUGE score, and perplexity, showcasing its effectiveness in achieving both coherence and relevance in generated text. The qualitative assessment further illustrates LoRAG's capability to produce contextually rich and coherent outputs. This research contributes valuable insights into the potential of iterative loops in mitigating challenges in text generation, po
    
[^134]: 憎恨源于无知！对抗会话性仇恨言论中说服方式的提炼

    Hatred Stems from Ignorance! Distillation of the Persuasion Modes in Countering Conversational Hate Speech

    [https://arxiv.org/abs/2403.15449](https://arxiv.org/abs/2403.15449)

    研究研究了对抗在线仇恨言论的最佳方法，通过分析对话中的理由、情感和信誉等说服方式，对比封闭和开放交互中的不同行为和话题层面，发现了在对抗言论中的微妙差异。

    

    研究对抗言论使用的因素是理解在线对抗仇恨言论的最佳方法的核心。各种研究评估对抗言论中使用的情感基础因素，如情感共鸣、冒犯程度和敌意程度。为了更好地理解会话交互中使用的对抗言论，本研究将说服方式分解为理由、情感和信誉，然后评估它们在涉及种族主义、性别歧视和宗教问题的两种对话交互类型中的使用。评估涵盖了人类与生成对抗言论的不同行为。我们还评估了回复的立场与每种对抗言论中的说服方式之间的相互作用。值得注意的是，我们观察到了在开放和封闭交互的对抗言论说服方式上的微妙差异 -- 尤其是在话题层面上。

    arXiv:2403.15449v1 Announce Type: cross  Abstract: Examining the factors that the counter-speech uses is at the core of understanding the optimal methods for confronting hate speech online. Various studies assess the emotional base factor used in counter speech, such as emotion-empathy, offensiveness, and level of hostility. To better understand the counter-speech used in conversational interactions, this study distills persuasion modes into reason, emotion, and credibility and then evaluates their use in two types of conversation interactions: closed (multi-turn) and open (single-turn) conversation interactions concerning racism, sexism, and religion. The evaluation covers the distinct behaviors of human versus generated counter-speech. We also assess the interplay between the replies' stance and each mode of persuasion in the counter-speech. Notably, we observe nuanced differences in the counter-speech persuasion modes for open and closed interactions -- especially on the topic level
    
[^135]: 解码压缩的信任：审视在压缩下高效LLMs的可信度

    Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression

    [https://arxiv.org/abs/2403.15447](https://arxiv.org/abs/2403.15447)

    量化目前比剪枝更有效，可以同时实现效率和可信度，但剪枝会显著降低模型的可信度

    

    将高性能的大型语言模型（LLMs）压缩已经成为一种资源高效推断的首选策略。尽管最先进的压缩方法在保留良性任务性能方面取得了令人印象深刻的进展，但压缩在安全性和可信度方面的潜在风险在很大程度上被忽视。这项研究对使用五种最先进压缩技术评估三种领先LLMs的可信度维度进行了首次彻底评估。我们的实验突出了压缩与可信度之间复杂的相互作用，揭示了一些有趣的模式。我们发现，目前量化比剪枝更有效地同时实现效率和可信度。例如，4位量化模型保留了其原始对应物的可信度，但模型剪枝显著降低了可信度，即使在50%的稀疏度下。

    arXiv:2403.15447v1 Announce Type: cross  Abstract: Compressing high-capability Large Language Models (LLMs) has emerged as a favored strategy for resource-efficient inferences. While state-of-the-art (SoTA) compression methods boast impressive advancements in preserving benign task performance, the potential risks of compression in terms of safety and trustworthiness have been largely neglected. This study conducts the first, thorough evaluation of three (3) leading LLMs using five (5) SoTA compression techniques across eight (8) trustworthiness dimensions. Our experiments highlight the intricate interplay between compression and trustworthiness, revealing some interesting patterns. We find that quantization is currently a more effective approach than pruning in achieving efficiency and trustworthiness simultaneously. For instance, a 4-bit quantized model retains the trustworthiness of its original counterpart, but model pruning significantly degrades trustworthiness, even at 50% spars
    
[^136]: 通过ARIMA时间序列分析揭示社交网络上的多语言主题动态和趋势识别：LDA/HDP模型增强的新型数据翻译框架

    Decoding Multilingual Topic Dynamics and Trend Identification through ARIMA Time Series Analysis on Social Networks: A Novel Data Translation Framework Enhanced by LDA/HDP Models

    [https://arxiv.org/abs/2403.15445](https://arxiv.org/abs/2403.15445)

    该研究提出了一种新方法，通过ARIMA时间序列分析和LDA/HDP模型提取多语言社交网络中的主题动态，特别关注在危机期间的交流趋势，这一方法在语言一致性任务中表现出色。

    

    在这项研究中，作者提出了一种新的方法，能够破译多语言主题动态，并识别危机期间的交流趋势。我们关注突尼斯社交网络中在冠状病毒大流行期间以及其他显著主题（如体育和政治）中的对话。我们首先对与这些主题相关的各种多语言评论进行聚合。然后在数据预处理过程中对数据集进行了严格的精炼。我们引入我们的无英语到英语的机器翻译方法来处理语言差异。对这种方法的实证测试显示了很高的准确性和F1值，突显了它适用于语言一致任务的特点。深入研究，采用了先进的建模技术，特别是LDA和HDP模型，从翻译内容中提取相关主题。这导致应用ARIMA时间序列分析来解码不断变化的主题趋势。

    arXiv:2403.15445v1 Announce Type: cross  Abstract: In this study, the authors present a novel methodology adept at decoding multilingual topic dynamics and identifying communication trends during crises. We focus on dialogues within Tunisian social networks during the Coronavirus Pandemic and other notable themes like sports and politics. We start by aggregating a varied multilingual corpus of comments relevant to these subjects. This dataset undergoes rigorous refinement during data preprocessing. We then introduce our No-English-to-English Machine Translation approach to handle linguistic differences. Empirical tests of this method showed high accuracy and F1 scores, highlighting its suitability for linguistically coherent tasks. Delving deeper, advanced modeling techniques, specifically LDA and HDP models are employed to extract pertinent topics from the translated content. This leads to applying ARIMA time series analysis to decode evolving topic trends. Applying our method to a mu
    
[^137]: 从拓扑学角度看语言学

    Linguistics from a topological viewpoint

    [https://arxiv.org/abs/2403.15440](https://arxiv.org/abs/2403.15440)

    本文介绍了一种分析南美语言拓扑形状的工作流程，应用了多重对应分析技术和拓扑数据分析方法。

    

    语言学中的类型数据库通常是分类值的。因此，很难清晰地可视化数据。在本文中，我们描述了一种工作流程，通过应用多重对应分析技术和拓扑数据分析方法来分析南美语言的拓扑形状。

    arXiv:2403.15440v1 Announce Type: new  Abstract: Typological databases in linguistics are usually categorical-valued. As a result, it is difficult to have a clear visualization of the data. In this paper, we describe a workflow to analyze the topological shapes of South American languages by applying multiple correspondence analysis technique and topological data analysis methods.
    
[^138]: 利用上下文信息进行句子级形态素分割

    Using Contextual Information for Sentence-level Morpheme Segmentation

    [https://arxiv.org/abs/2403.15436](https://arxiv.org/abs/2403.15436)

    将形态素分割任务重新定义为序列到序列问题，并通过多语言模型展示出优异性能，揭示了高资源语言环境下的可比效力，以及低资源语言场景下的局限性。

    

    最近形态素分割的发展主要强调单词级别的分割，通常忽视了句子内的上下文相关性。在这项研究中，我们将形态素分割任务重新定义为一个序列到序列的问题，将整个句子作为输入，而不是孤立地处理单个单词。我们的研究发现，多语言模型与单语模型相比始终表现出更高的性能。虽然我们的模型没有超越当前最先进的模型，但在高资源语言中展现出可比较的有效性，同时揭示了在低资源语言场景中的局限性。

    arXiv:2403.15436v1 Announce Type: new  Abstract: Recent advancements in morpheme segmentation primarily emphasize word-level segmentation, often neglecting the contextual relevance within the sentence. In this study, we redefine the morpheme segmentation task as a sequence-to-sequence problem, treating the entire sentence as input rather than isolating individual words. Our findings reveal that the multilingual model consistently exhibits superior performance compared to monolingual counterparts. While our model did not surpass the performance of the current state-of-the-art, it demonstrated comparable efficacy with high-resource languages while revealing limitations in low-resource language scenarios.
    
[^139]: ChatPattern: 利用自然语言进行布局模式定制

    ChatPattern: Layout Pattern Customization via Natural Language

    [https://arxiv.org/abs/2403.15434](https://arxiv.org/abs/2403.15434)

    ChatPattern利用大语言模型（LLM）的框架实现了灵活的布局模式定制，能够通过自然语言要求生成高质量大规模模式。

    

    现有的作品主要集中在生成固定大小的布局模式，而更实用的自由大小模式生成受到了有限的关注。在本文中，我们提出了ChatPattern，这是一个新颖的基于大语言模型（LLM）的框架，用于灵活的模式定制。ChatPattern利用一个包含专家LLM代理和一个高度可控的布局模式生成器的双部分系统。LLM代理可以解释自然语言要求并操作设计工具以满足指定需求，而生成器擅长于条件布局生成、模式修改和内存友好型模式扩展。在具有挑战性的模式生成设置上的实验表明了ChatPattern合成高质量大规模模式的能力。

    arXiv:2403.15434v1 Announce Type: cross  Abstract: Existing works focus on fixed-size layout pattern generation, while the more practical free-size pattern generation receives limited attention. In this paper, we propose ChatPattern, a novel Large-Language-Model (LLM) powered framework for flexible pattern customization. ChatPattern utilizes a two-part system featuring an expert LLM agent and a highly controllable layout pattern generator. The LLM agent can interpret natural language requirements and operate design tools to meet specified needs, while the generator excels in conditional layout generation, pattern modification, and memory-friendly patterns extension. Experiments on challenging pattern generation setting shows the ability of ChatPattern to synthesize high-quality large-scale patterns.
    
[^140]: 从大型语言模型中提炼濒危物种的命名实体识别模型

    Distilling Named Entity Recognition Models for Endangered Species from Large Language Models

    [https://arxiv.org/abs/2403.15430](https://arxiv.org/abs/2403.15430)

    通过从GPT-4中提取知识，我们为濒危物种创建了命名实体识别和关系抽取的数据集，为保护生物多样性做出贡献。

    

    自然语言处理（NLP）从业者正在利用大型语言模型（LLM）从专利、论文和论文等半结构化和非结构化数据源创建结构化数据集，而无需具备领域特定知识。与此同时，生态专家正在寻找各种手段来保护生物多样性。为了为这些努力做出贡献，我们专注于濒危物种，并通过上下文学习从GPT-4中提炼知识。实际上，我们通过两阶段过程创建了命名实体识别（NER）和关系抽取（RE）的数据集：1）我们从GPT-4中生成了四类濒危物种的合成数据，2）人类验证了合成数据的事实准确性，最终生成金标数据。最终，我们的新颖数据集包含共3.6K个句子，均分为1.8K个NER句子和1.8K个RE句子。构建的数据集随后用于对bo进行微调。

    arXiv:2403.15430v1 Announce Type: new  Abstract: Natural language processing (NLP) practitioners are leveraging large language models (LLM) to create structured datasets from semi-structured and unstructured data sources such as patents, papers, and theses, without having domain-specific knowledge. At the same time, ecological experts are searching for a variety of means to preserve biodiversity. To contribute to these efforts, we focused on endangered species and through in-context learning, we distilled knowledge from GPT-4. In effect, we created datasets for both named entity recognition (NER) and relation extraction (RE) via a two-stage process: 1) we generated synthetic data from GPT-4 of four classes of endangered species, 2) humans verified the factual accuracy of the synthetic data, resulting in gold data. Eventually, our novel dataset contains a total of 3.6K sentences, evenly divided between 1.8K NER and 1.8K RE sentences. The constructed dataset was then used to fine-tune bo
    
[^141]: 教育环境下集成强先验模块和数据重叠估计的三阶段SFT混合模型

    A Three-Phases SFT Hybrid Model Integrated Strong Prior Module and Data Overlap Estimation in the Eduation Context

    [https://arxiv.org/abs/2403.15426](https://arxiv.org/abs/2403.15426)

    提出了一种在教育领域中应用的三阶段监督微调模型，通过先验和数据重叠估计实现了教育知识的结构拆卸和增量引导输出。

    

    在本文中，我们提出了一种端到端基于先验的三阶段监督微调模型，证明比传统微调方法更有竞争力。具体而言，我们的模型实现了教育知识的结构拆卸和增量引导输出。为此，我们通过采样器和重叠估计神经网络对三种类型的数据进行了健壮的分类，将预处理数据集分三批注入预训练模型进行LORA微调。然后，我们设计了一个先验模块，将系统提示、向量数据库和抽象语法树任务分割相结合。最后，对基于先验的微调模型应用了压缩方法和正则化约束，随后在输出端进行文本过滤以获得增量引导结果。我们的模型代表了真正以丰富的教育知识、分步指导的特点体现导师角色的第一项研究努力。

    arXiv:2403.15426v1 Announce Type: cross  Abstract: In this paper, we propose an end-to-end prior-based three-phases supervised fine-tuned model, which is proved more competitive than traditional fine-tuning method. More specifically, our model realizes the structural disassembly and incremental guided output of educational knowledge. To this end, we robustify data classification of three types via a sampler and overlap estimation neural network, and inject the preprocessing datasets into pre-trained model in three batches for LORA fine-tuning. Then, we design a prior module couples system prompt, vector databases, and abstract syntax tree task segmentation. Finally, the compression method and regularization constraint are applied to the prior-based fine-tuned model, followed by text filter at the output end to obtain incremental guided results. Our model represents the first research effort to truly embody the tutor role with the features of abundant educational knowledge, step-by-step
    
[^142]: 在LLMs中测量和建模“文化”：一项调查

    Towards Measuring and Modeling "Culture" in LLMs: A Survey

    [https://arxiv.org/abs/2403.15412](https://arxiv.org/abs/2403.15412)

    这项研究调查了39篇最新论文，旨在研究大型语言模型中的文化表达和包容性，发现当前研究未对“文化”进行定义，而是在特定设计的数据集上对模型进行探究，研究了某些“文化”的方面，留下许多未被探究的有趣和重要方面，如语义领域和关于性。

    

    我们呈现了对39篇最新论文的调查，旨在研究大型语言模型中的文化表达和包容性。我们观察到，没有一篇研究定义“文化”，这是一个复杂、多层面的概念；相反，它们在一些特别设计的数据集上对模型进行探究，这些数据集代表了某些“文化”的方面。我们将这些方面称为文化的代理，并将它们组织在人口统计、语义和语言文化交互代理的三个维度上。我们还对采用的探查方法进行了分类。我们的分析表明，只有“文化”的某些方面，如价值观和目标，被研究了，留下了几个其他有趣且重要的方面，特别是大量语义领域和关于性（Hershcovich等人，2022）的未被探究。另外两个关键的空白是目前方法的鲁棒性和情境性的缺乏。基于这些观察结果，

    arXiv:2403.15412v1 Announce Type: cross  Abstract: We present a survey of 39 recent papers that aim to study cultural representation and inclusion in large language models. We observe that none of the studies define "culture," which is a complex, multifaceted concept; instead, they probe the models on some specially designed datasets which represent certain aspects of "culture." We call these aspects the proxies of cultures, and organize them across three dimensions of demographic, semantic and linguistic-cultural interaction proxies. We also categorize the probing methods employed. Our analysis indicates that only certain aspects of "culture," such as values and objectives, have been studied, leaving several other interesting and important facets, especially the multitude of semantic domains (Thompson et al., 2020) and aboutness (Hershcovich et al., 2022), unexplored. Two other crucial gaps are the lack of robustness and situatedness of the current methods. Based on these observations
    
[^143]: X-AMR注释工具

    X-AMR Annotation Tool

    [https://arxiv.org/abs/2403.15407](https://arxiv.org/abs/2403.15407)

    该论文介绍了一种新型的X-AMR注释工具，通过机器辅助提升用户体验，实现了对关键事件语义的注释，与GPT-4集成表现出色。

    

    本文介绍了一种新型的跨文档抽象意义表征（X-AMR）注释工具，旨在用于注释关键的语料库级事件语义。通过Prodigy注释工具提供的机器辅助，我们增强了用户体验，确保注释过程的简易性和高效性。通过实证分析，我们展示了我们的工具在增强现有事件语料库方面的有效性，突显了其与GPT-4集成时的优势。代码和注释：https://github.com/ahmeshaf/gpt_coref

    arXiv:2403.15407v1 Announce Type: cross  Abstract: This paper presents a novel Cross-document Abstract Meaning Representation (X-AMR) annotation tool designed for annotating key corpus-level event semantics. Leveraging machine assistance through the Prodigy Annotation Tool, we enhance the user experience, ensuring ease and efficiency in the annotation process. Through empirical analyses, we demonstrate the effectiveness of our tool in augmenting an existing event corpus, highlighting its advantages when integrated with GPT-4. Code and annotations: https://github.com/ahmeshaf/gpt_coref
    
[^144]: 大型语言模型在心理健康领域的系统评价

    Large Language Model for Mental Health: A Systematic Review

    [https://arxiv.org/abs/2403.15401](https://arxiv.org/abs/2403.15401)

    该论文系统评价了大型语言模型在心理健康领域的应用，讨论了其在早期筛查、数字干预和其他临床应用中的挑战和机遇。

    

    大型语言模型（LLMs）在数字健康领域受到了广泛关注，展现出了潜在的应用性，但它们在心理健康领域的应用仍在持续讨论中。这项系统性评价旨在总结和表征LLMs在心理健康领域的应用，通过调查LLMs最新研究的优势和局限性，讨论心理健康领域早期筛查、数字干预以及其他临床应用的挑战和机遇。根据PRISMA指南，我们审查了PubMed、DBLP计算机科学文献数据库和IEEE Xplore上发表的英文文章，时间跨度为2017年1月1日至2023年9月1日，重点关注心理健康和LLMs。该综述分析了32篇文章，包括使用社交媒体数据集进行心理健康分析的（n=13）、心理健康聊天机器人（n=10）以及其他心理健康应用（n=9）。研究结果显示LLMs在心理健康问题检测中的有效性以及

    arXiv:2403.15401v1 Announce Type: cross  Abstract: Large language models (LLMs) have received much attention and shown their potential in digital health, while their application in mental health is subject to ongoing debate. This systematic review aims to summarize and characterize the use of LLMs in mental health by investigating the strengths and limitations of the latest work in LLMs and discusses the challenges and opportunities for early screening, digital interventions, and other clinical applications in mental health. Following PRISMA guidelines, we examined English articles from PubMed, DBLP Computer Science Bibliography, and IEEE Xplore, published between 1 January 2017, and 1 September 2023, focusing on mental health and LLMs. The review analyzed 32 articles, including mental health analysis using social media datasets (n=13), mental health chatbots (n=10), and other mental health applications (n=9). Findings reveal LLMs' effectiveness in mental health issue detection and the
    
[^145]: ChatGPT在线性代数中的运用：取得进展，留待进一步探索

    ChatGPT in Linear Algebra: Strides Forward, Steps to Go

    [https://arxiv.org/abs/2403.15399](https://arxiv.org/abs/2403.15399)

    ChatGPT在线性代数中取得巨大改进，但目前仍然无法完全取代人类教师，软件理解问题的能力引发了人们对其潜力的思考。

    

    一旦新技术出现，教育界就会探索其实用性以及在教育中的应用可能性。本文分析了关于基础线性代数主题的ChatGPT会话。我们反思了过去一年内ChatGPT在我们感兴趣的领域所进行的过程，强调了在应对线性代数问题上所取得的巨大改进。尤其是，本文讨论了这个软件是否可以作为教学助手，甚至在某种程度上取代人类教师的问题。截至本文撰写时，答案通常是否定的。对于可以为之积极的方面，给出了一些关于原始工程的反思。与该软件的交流给人一种在与人类交谈的印象，有时会产生这样一个问题：软件是否理解这个问题。因此，读者的注意力被引向了f

    arXiv:2403.15399v1 Announce Type: cross  Abstract: As soon as a new technology emerges, the education community explores its affordances and the possibilities to apply it in education. In this paper, we analyze sessions with ChatGPT around topics in basic Linear Algebra. We reflect the process undertaken by the ChatGPT along the recent year in our area of interest, emphasising the vast improvement that has been done in grappling with Linear Algebra problems. In particular, the question whether this software can be a teaching assistant or even somehow replace the human teacher, is addressed. As of the time this paper is written, the answer is generally negative. For the small part where the answer can be positive, some reflections about an original instrumental genesis are given.   Communication with the software gives the impression to talk to a human, and sometimes the question is whether the software understands the question or not. Therefore, the reader's attention is drawn to the f
    
[^146]: 管控大型语言模型：圆桌报告

    Regulating Large Language Models: A Roundtable Report

    [https://arxiv.org/abs/2403.15397](https://arxiv.org/abs/2403.15397)

    圆桌会议探讨了如何通过法律和政策来解决大型语言模型可能带来的真实性、隐私和市场集中等方面的重要社会问题。

    

    在2023年7月20日，一群具有法律、计算机科学、政治科学等专业知识的27名学者和数字权利倡导者聚集在纽约大学法学院信息法律研究所和民主与科技中心联合举办的大型语言模型、法律和政策圆桌会议上。圆桌会议旨在讨论法律和政策如何帮助解决大型语言模型（LLMs）带来的一些较大社会问题。讨论主要集中在三个政策领域：1.真实性：LLMs在生成误信息和假信息方面存在哪些风险？从技术和/或监管的角度如何减轻这些风险？2.隐私：在创建、部署和使用LLMs过程中涉及哪些最大的隐私风险？如何从技术和/或监管的角度减轻这些风险？3.市场集中：LLMs带来了哪些市场集中的威胁？

    arXiv:2403.15397v1 Announce Type: cross  Abstract: On July 20, 2023, a group of 27 scholars and digital rights advocates with expertise in law, computer science, political science, and other disciplines gathered for the Large Language Models, Law and Policy Roundtable, co-hosted by the NYU School of Law's Information Law Institute and the Center for Democracy & Technology. The roundtable convened to discuss how law and policy can help address some of the larger societal problems posed by large language models (LLMs). The discussion focused on three policy topic areas in particular:   1. Truthfulness: What risks do LLMs pose in terms of generating mis- and disinformation? How can these risks be mitigated from a technical and/or regulatory perspective?   2. Privacy: What are the biggest privacy risks involved in the creation, deployment, and use of LLMs? How can these risks be mitigated from a technical and/or regulatory perspective?   3. Market concentration: What threats do LLMs pose c
    
[^147]: 通过基于注意力的双向递归神经网络从Reddit帖子中检测阿片类药物使用者

    Detection of Opioid Users from Reddit Posts via an Attention-based Bidirectional Recurrent Neural Network

    [https://arxiv.org/abs/2403.15393](https://arxiv.org/abs/2403.15393)

    通过机器学习方法分析Reddit用户帖子，检测阿片类药物使用者，帮助改善对阿片类药物危机的监测和理解。

    

    阿片类药物危机指的是因阿片类药物过量使用和成瘾而导致的日益增长的住院和死亡案例，已经成为美国严重的健康问题。为应对此危机，联邦和地方政府以及卫生社区已经制定了许多策略。其中，通过更好的健康监测来提高我们对危机的了解是当务之急之一。除了直接测试，机器学习方法也可能通过分析社交媒体数据来检测阿片类药物使用者，因为许多阿片类药物使用者可能选择不做测试，但可能会匿名在社交媒体上分享他们的经历。在这篇论文中，我们利用机器学习的最新进展，收集并分析了来自流行社交网络Reddit的用户帖子，以确定阿片类药物使用者。

    arXiv:2403.15393v1 Announce Type: new  Abstract: The opioid epidemic, referring to the growing hospitalizations and deaths because of overdose of opioid usage and addiction, has become a severe health problem in the United States. Many strategies have been developed by the federal and local governments and health communities to combat this crisis. Among them, improving our understanding of the epidemic through better health surveillance is one of the top priorities. In addition to direct testing, machine learning approaches may also allow us to detect opioid users by analyzing data from social media because many opioid users may choose not to do the tests but may share their experiences on social media anonymously. In this paper, we take advantage of recent advances in machine learning, collect and analyze user posts from a popular social network Reddit with the goal to identify opioid users. Posts from more than 1,000 users who have posted on three sub-reddits over a period of one mon
    
[^148]: CapsF: 用于从 Twitter 中提取自杀心理压力源的胶囊融合技术

    CapsF: Capsule Fusion for Extracting psychiatric stressors for suicide from twitter

    [https://arxiv.org/abs/2403.15391](https://arxiv.org/abs/2403.15391)

    该研究探索了一种基于胶囊的方法，用于从波斯语推文中检测与自杀相关的心理压力源，取得了不错的分类准确性。

    

    除癌症、血压、交通事故和中风等因素外，自杀一直是伊朗主要死因之一。自杀的主要原因之一是心理压力源。在处于风险人群中识别心理压力源有助于早期预防自杀和自杀行为。然而，一些自动化方法用于从 Twitter 提取心理压力源，但大多数研究都面向非波斯语言。本研究旨在利用基于学习的方法，从波斯语推文中检测与自杀相关的心理压力源技术。提出的基于胶囊的方法实现了0.83的二进制分级准确性。

    arXiv:2403.15391v1 Announce Type: new  Abstract: Along with factors such as cancer, blood pressure, street accidents and stroke, suicide has been one of Iran main causes of death. One of the main reasons for suicide is psychological stressors. Identifying psychological stressors in an at risk population can help in the early prevention of suicidal and suicidal behaviours. In recent years, the widespread popularity and flow of real time information sharing of social media have allowed for potential early intervention in large scale and even small scale populations. However, some automated approaches to extract psychiatric stressors from Twitter have been presented, but most of this research has been for non Persian languages. This study aims to investigate the techniques of detecting psychological stress related to suicide from Persian tweets using learning based methods. The proposed capsule based approach achieved a binary classification accuracy of 0.83.
    
[^149]: LLaVA-PruMerge: 自适应令牌减少用于高效大型多模态模型

    LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models

    [https://arxiv.org/abs/2403.15388](https://arxiv.org/abs/2403.15388)

    PruMerge提出了一种自适应的视觉令牌减少方法，可以有效减少大型多模态模型中的视觉令牌数量，同时保持模型性能。

    

    大型多模态模型(LMMs)通过连接视觉编码器和大型语言模型展现了显著的推理能力。最近的LMMs包括了更复杂的视觉输入，如高分辨率图像和视频，这显著增加了视觉令牌的数量。为了解决这个问题，我们探索了一种令牌减少机制，并发现类似于先前的工作，许多视觉令牌在空间上是冗余的。基于此，我们提出了PruMerge，一种新颖的自适应视觉令牌减少方法，大大减少了视觉令牌的数量，同时保持了可比的模型性能。

    arXiv:2403.15388v1 Announce Type: cross  Abstract: Large Multimodal Models (LMMs) have shown significant reasoning capabilities by connecting a visual encoder and a large language model. LMMs typically use a fixed amount of visual tokens, such as the penultimate layer features in the CLIP visual encoder, as the prefix content. Recent LMMs incorporate more complex visual inputs, such as high-resolution images and videos, which increase the number of visual tokens significantly. However, due to the design of the Transformer architecture, computational costs associated with these models tend to increase quadratically with the number of input tokens. To tackle this problem, we explore a token reduction mechanism and find, similar to prior work, that many visual tokens are spatially redundant. Based on this, we propose PruMerge, a novel adaptive visual token reduction approach, which largely reduces the number of visual tokens while maintaining comparable model performance. We first select 
    
[^150]: 一种针对图像水印的转移攻击

    A Transfer Attack to Image Watermarks

    [https://arxiv.org/abs/2403.15365](https://arxiv.org/abs/2403.15365)

    水印领域的研究表明，即使在攻击者无法访问水印模型或检测API的情况下，水印基础的AI生成图像检测器也无法抵抗对抗攻击。

    

    水印已被广泛应用于工业领域，用于检测由人工智能生成的图像。文献中对这种基于水印的检测器在白盒和黑盒环境下对抗攻击的稳健性有很好的理解。然而，在无盒环境下的稳健性却知之甚少。具体来说，多项研究声称图像水印在这种环境下是稳健的。在这项工作中，我们提出了一种新的转移对抗攻击来针对无盒环境下的图像水印。我们的转移攻击向带水印的图像添加微扰，以躲避被攻击者训练的多个替代水印模型，并且经过扰动的带水印图像也能躲避目标水印模型。我们的主要贡献是理论上和经验上展示了，基于水印的人工智能生成图像检测器即使攻击者没有访问水印模型或检测API，也不具有对抗攻击的稳健性。

    arXiv:2403.15365v1 Announce Type: cross  Abstract: Watermark has been widely deployed by industry to detect AI-generated images. The robustness of such watermark-based detector against evasion attacks in the white-box and black-box settings is well understood in the literature. However, the robustness in the no-box setting is much less understood. In particular, multiple studies claimed that image watermark is robust in such setting. In this work, we propose a new transfer evasion attack to image watermark in the no-box setting. Our transfer attack adds a perturbation to a watermarked image to evade multiple surrogate watermarking models trained by the attacker itself, and the perturbed watermarked image also evades the target watermarking model. Our major contribution is to show that, both theoretically and empirically, watermark-based AI-generated image detector is not robust to evasion attacks even if the attacker does not have access to the watermarking model nor the detection API.
    
[^151]: 探究ChatGPT及其对社会的影响

    Exploring ChatGPT and its Impact on Society

    [https://arxiv.org/abs/2403.14643](https://arxiv.org/abs/2403.14643)

    ChatGPT是一种基于Transformer架构的大型语言模型，能够生成人类化的对话回复，可革新各行业并改变技术互动方式。

    

    人工智能已经存在一段时间了，但突然间比以往任何时候都受到了更多的关注。感谢谷歌、微软、元宇宙等科技界主要品牌的创新。然而，OpenAI通过其开创性发明ChatGPT触发了按钮。ChatGPT是一种基于Transformer架构的大型语言模型（LLM），能够在对话背景中生成类似人类的回复。它使用深度学习算法来生成对输入文本的自然语言回复。其庞大的参数数量、上下文生成和面向开放域的训练使其成为一种多功能且有效的工具，可应用于从聊天机器人到客户服务再到语言翻译等广泛领域。它具有彻底改变各行业并转变我们与技术互动方式的潜力。然而，使用ChatGPT也引发了一些担忧，包括道德方面的。

    arXiv:2403.14643v1 Announce Type: cross  Abstract: Artificial intelligence has been around for a while, but suddenly it has received more attention than ever before. Thanks to innovations from companies like Google, Microsoft, Meta, and other major brands in technology. OpenAI, though, has triggered the button with its ground-breaking invention ChatGPT. ChatGPT is a Large Language Model (LLM) based on Transformer architecture that has the ability to generate human-like responses in a conversational context. It uses deep learning algorithms to generate natural language responses to input text. Its large number of parameters, contextual generation, and open-domain training make it a versatile and effective tool for a wide range of applications, from chatbots to customer service to language translation. It has the potential to revolutionize various industries and transform the way we interact with technology. However, the use of ChatGPT has also raised several concerns, including ethical,
    
[^152]: ReAct遇上ActRe：对比性自训练中的代理轨迹自动标注

    ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training

    [https://arxiv.org/abs/2403.14589](https://arxiv.org/abs/2403.14589)

    提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。

    

    arXiv:2403.14589v1 公告类型：新 文摘：语言代理通过与基础模型推理展示了自主决策能力。最近，人们致力于通过多步推理和行动轨迹作为训练数据来训练语言代理以提高性能。然而，收集这样的轨迹仍需要相当大的人力，无论是通过人工标注还是实施多样化提示框架。在这项工作中，我们提出了A$^3$T，一个允许以ReAct风格自主注释代理轨迹的框架。其中心是一个ActRe提示代理，它解释任意动作的原因。当随机抽取外部动作时，ReAct风格代理可以查询ActRe代理以获取其文本理由。新颖的轨迹然后通过将ActRe的后验推理前置到抽样动作中进行综合合成。通过这种方式，ReAct风格代理可执行

    arXiv:2403.14589v1 Announce Type: new  Abstract: Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models. Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data. However, collecting such trajectories still requires considerable human effort, by either artificial annotations or implementations of diverse prompting frameworks. In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct. The central role is an ActRe prompting agent, which explains the reason for an arbitrary action. When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales. Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action. In this way, the ReAct-style agent exe
    
[^153]: K-Act2Emo：针对间接情感表达的韩国常识知识图谱

    K-Act2Emo: Korean Commonsense Knowledge Graph for Indirect Emotional Expression

    [https://arxiv.org/abs/2403.14253](https://arxiv.org/abs/2403.14253)

    介绍了针对间接情感表达的韩国常识知识图谱K-Act2Emo，通过实验验证其在训练情感推断模型方面的有效性，微调后的BART知识模型表现优异，达到了与GPT-4 Turbo相媲美的性能水平。

    

    在许多文学作品中，情绪通过对行为、面部表情和外表的描述间接传达，需要对叙事理解进行情感推断。在本文中，我们介绍了K-Act2Emo，一个包含1,900种间接情感表达和可推断出的情绪的韩国常识知识图谱。我们将推理类型分为正面情境的推理、负面情境的推理和表达不是情感线索时的推理。与现有的常识知识图谱不同，K-Act2Emo专注于情感背景，实验结果证实了它对训练情感推断模型的有效性。值得注意的是，使用K-Act2Emo微调的基于BART的知识模型胜过了各种现有的韩国大型语言模型，在性能上达到了与GPT-4 Turbo可比的水平。

    arXiv:2403.14253v1 Announce Type: new  Abstract: In many literary texts, emotions are indirectly conveyed through descriptions of actions, facial expressions, and appearances, necessitating emotion inference for narrative understanding. In this paper, we introduce K-Act2Emo, a Korean commonsense knowledge graph (CSKG) comprising 1,900 indirect emotional expressions and the emotions inferable from them. We categorize reasoning types into inferences in positive situations, inferences in negative situations, and inferences when expressions do not serve as emotional cues. Unlike existing CSKGs, K-Act2Emo specializes in emotional contexts, and experimental results validate its effectiveness for training emotion inference models. Significantly, the BART-based knowledge model fine-tuned with K-Act2Emo outperforms various existing Korean large language models, achieving performance levels comparable to GPT-4 Turbo.
    
[^154]: C-TPT：通过文本特征离散性的校准测试时提示调整视觉-语言模型

    C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion

    [https://arxiv.org/abs/2403.14119](https://arxiv.org/abs/2403.14119)

    本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    

    在深度学习中，测试时适应已经引起了人们的关注，作为一种在不需要标记数据的情况下对模型进行微调的方法。一个主要的例证是最近提出的用于大规模视觉-语言模型（如CLIP）的测试时提示调整。然而，这些提示主要是为了提高准确性而开发的，忽视了校准的重要性——量化预测不确定性的关键方面。然而，传统的校准方法依赖大量标记数据，这使得它们在测试时场景下不切实际。为此，本文通过利用CLIP的固有属性，在测试时提示调整过程中探讨校准。通过一系列观察，我们发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    arXiv:2403.14119v1 Announce Type: cross  Abstract: In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data. A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP. Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration-a crucial aspect for quantifying prediction uncertainty. However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios. To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP. Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions. Introducing the Average Text Feature Dispersion
    
[^155]: 使用BART从推文中提取情绪短语

    Extracting Emotion Phrases from Tweets using BART

    [https://arxiv.org/abs/2403.14050](https://arxiv.org/abs/2403.14050)

    本文提出了一种基于BART的情感分析方法，利用问答框架从文本中提取特定情绪短语，并通过分类器预测答案跨度位置，实现对情绪短语的精确提取。

    

    情感分析是一项旨在识别和提取文本中情绪方面的自然语言处理任务。然而，许多现有的情感分析方法主要是对文本的整体极性进行分类，忽略了传达情绪的具体短语。在本文中，我们应用了一种基于问答框架的情感分析方法。我们利用双向自回归变换器（BART），一个预训练的序列到序列模型，从给定文本中提取放大给定情感极性的短语。我们创建一个自然语言问题，确定要提取的特定情绪，然后引导BART专注于文本中相关的情感线索。我们在BART中使用一个分类器来预测文本中答案跨度的开始和结束位置，从而帮助确定提取的情绪短语的精确边界。

    arXiv:2403.14050v2 Announce Type: replace  Abstract: Sentiment analysis is a natural language processing task that aims to identify and extract the emotional aspects of a text. However, many existing sentiment analysis methods primarily classify the overall polarity of a text, overlooking the specific phrases that convey sentiment. In this paper, we applied an approach to sentiment analysis based on a question-answering framework. Our approach leverages the power of Bidirectional Autoregressive Transformer (BART), a pre-trained sequence-to-sequence model, to extract a phrase from a given text that amplifies a given sentiment polarity. We create a natural language question that identifies the specific emotion to extract and then guide BART to pay attention to the relevant emotional cues in the text. We use a classifier within BART to predict the start and end positions of the answer span within the text, which helps to identify the precise boundaries of the extracted emotion phrase. Our
    
[^156]: Chain-of-Interaction: 通过二元交互背景增强用于精神行为理解的大型语言模型

    Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts

    [https://arxiv.org/abs/2403.13786](https://arxiv.org/abs/2403.13786)

    该论文引入了“Chain-of-Interaction (CoI)”提示方法，通过二元交互情境来为精神决策支持上下文化大型语言模型(LLMs)，以解决精神治疗中缺乏领域专业知识和忽视患者-治疗师交互的挑战。

    

    自动编码患者行为对于支持精神治疗师在激励性面谈（MI）期间做出决策至关重要，MI是一种协作沟通干预方法，用于解决精神问题，如酒精和药物成瘾。尽管行为编码任务已迅速借助机器学习来预测MI会话期间患者状态，但缺乏领域专业知识并忽视患者-治疗师交互是在实际实践中开发和部署这些模型面临的主要挑战。为了解决这些挑战，我们提出了Chain-of-Interaction (CoI)提示方法，旨在通过二元交互情境来为精神决策支持上下文化大型语言模型(LLMs)。CoI提示方法系统地将编码任务分解为三个关键推理步骤，提取患者参与度，学习治疗师提问策略，并整合二元交互。

    arXiv:2403.13786v1 Announce Type: new  Abstract: Automatic coding patient behaviors is essential to support decision making for psychotherapists during the motivational interviewing (MI), a collaborative communication intervention approach to address psychiatric issues, such as alcohol and drug addiction. While the behavior coding task has rapidly adapted machine learning to predict patient states during the MI sessions, lacking of domain-specific knowledge and overlooking patient-therapist interactions are major challenges in developing and deploying those models in real practice. To encounter those challenges, we introduce the Chain-of-Interaction (CoI) prompting method aiming to contextualize large language models (LLMs) for psychiatric decision support by the dyadic interactions. The CoI prompting approach systematically breaks down the coding task into three key reasoning steps, extract patient engagement, learn therapist question strategies, and integrates dyadic interactions bet
    
[^157]: EthioLLM：用于埃塞俄比亚语言的多语言大型语言模型及任务评估

    EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation

    [https://arxiv.org/abs/2403.13737](https://arxiv.org/abs/2403.13737)

    EthioLLM为埃塞俄比亚五种语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）以及英语引入了多语言大型语言模型，并提出了一个新的基准数据集Ethiobenchmark，为各种下游自然语言处理任务评估了这些模型的性能。

    

    大型语言模型（LLMs）近来因其在各种下游自然语言处理（NLP）任务中的出色表现而备受青睐。然而，由于训练LLMs的资源不足，低资源语言仍落后于NLP领域的最新发展。埃塞俄比亚语言拥有显著的语言多样性，包括广泛的文字系统，并富有深远的宗教和文化意义。本文介绍了EthioLLM - 五种埃塞俄比亚语言（阿姆哈拉语、盖伊兹语、阿方奥罗莫语、索马里语和提格里尼亚语）和英语的多语言大型语言模型，以及Ethiobenchmark - 用于各种下游NLP任务的新基准数据集。我们评估了这些模型在五个下游NLP任务中的性能。我们开源我们的多语言语言模型、各种下游任务的新基准数据集和任务特定的精调语言

    arXiv:2403.13737v1 Announce Type: new  Abstract: Large language models (LLMs) have gained popularity recently due to their outstanding performance in various downstream Natural Language Processing (NLP) tasks. However, low-resource languages are still lagging behind current state-of-the-art (SOTA) developments in the field of NLP due to insufficient resources to train LLMs. Ethiopian languages exhibit remarkable linguistic diversity, encompassing a wide array of scripts, and are imbued with profound religious and cultural significance. This paper introduces EthioLLM -- multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a new benchmark dataset for various downstream NLP tasks. We evaluate the performance of these models across five downstream NLP tasks. We open-source our multilingual language models, new benchmark datasets for various downstream tasks, and task-specific fine-tuned languag
    
[^158]: 从像素到洞察: 在大型基础模型时代自动图表理解的调查

    From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models

    [https://arxiv.org/abs/2403.12027](https://arxiv.org/abs/2403.12027)

    近年来，随着大型基础模型的兴起，自动图表理解取得了显著进展，本调查论文概述了在这些基础模型背景下图表理解领域的最新发展、挑战和未来方向

    

    数据可视化以图表形式在数据分析中扮演着关键角色，提供关键洞察并帮助做出明智决策。随着近年大型基础模型的崛起，自动图表理解取得了显著进展。基础模型，如大型语言模型(LLMs)，已经在各种自然语言处理（NLP）任务中实现了革命，并越来越多地应用于图表理解任务。本调查论文全面介绍了最新进展、挑战和未来方向，探讨了这些基础模型背景下图表理解的内容。

    arXiv:2403.12027v1 Announce Type: cross  Abstract: Data visualization in the form of charts plays a pivotal role in data analysis, offering critical insights and aiding in informed decision-making. Automatic chart understanding has witnessed significant advancements with the rise of large foundation models in recent years. Foundation models, such as large language models (LLMs), have revolutionized various natural language processing (NLP) tasks and are increasingly being applied to chart understanding tasks. This survey paper provides a comprehensive overview of the recent developments, challenges, and future directions in chart understanding within the context of these foundation models. The paper begins by defining chart understanding, outlining problem formulations, and discussing fundamental building blocks crucial for studying chart understanding tasks. In the section on tasks and datasets, we explore various tasks within chart understanding and discuss their evaluation metrics a
    
[^159]: 确保安全和高质量输出：面向语言模型的指南库方法

    Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models

    [https://arxiv.org/abs/2403.11838](https://arxiv.org/abs/2403.11838)

    引入Guide-Align，一种两阶段方法，通过安全训练模型识别潜在风险，并制定特定指南，从而建立全面的指导库，用于指导LLMs生成安全和高质量输出。

    

    大型语言模型(LLMs)展示了令人印象深刻的能力，但也存在偏见内容生成和隐私问题等风险。当前的对齐技术之一包括基于原则的集成，但面临由于手工制定规则的不精确性和未经安全训练的模型对风险感知不足而产生的挑战。为了解决这些问题，我们引入了Guide-Align，这是一种两阶段方法。最初，一个经过安全训练的模型识别潜在风险，并为各种输入制定具体指南，从而建立了全面的指南库和用于输入指南检索的模型。随后，检索模型将新输入与相关指南相关联，引导LLMs在响应生成中确保安全和高质量输出，从而与人类价值观一致。另一个额外可选阶段涉及使用经过细致对齐的新数据集对模型进行微调。

    arXiv:2403.11838v1 Announce Type: cross  Abstract: Large Language Models (LLMs) exhibit impressive capabilities but also present risks such as biased content generation and privacy issues. One of the current alignment techniques includes principle-driven integration, but it faces challenges arising from the imprecision of manually crafted rules and inadequate risk perception in models without safety training. To address these, we introduce Guide-Align, a two-stage approach. Initially, a safety-trained model identifies potential risks and formulates specific guidelines for various inputs, thereby establishing a comprehensive library of guidelines and models for input-guidelines retrieval. Subsequently, the retrieval model correlates new inputs with pertinent guidelines, guiding LLMs in response generation to ensure safe and high-quality outputs, thus aligning with human values. An additional optional stage involves fine-tuning a model with new well-aligned datasets generated through the
    
[^160]: Counting-Stars：一种评估长上下文大型语言模型的简单、高效、合理策略

    Counting-Stars: A Simple, Efficient, and Reasonable Strategy for Evaluating Long-Context Large Language Models

    [https://arxiv.org/abs/2403.11802](https://arxiv.org/abs/2403.11802)

    提出了一种名为Counting-Stars的简单、高效、合理策略，用于评估长上下文大型语言模型的能力，并在实验中发现GPT-4 Turbo和Kimi Chat在此任务上取得显著性能。

    

    近期的研究主要集中在开发具有强大长上下文能力的大型语言模型（LLMs），由于缺乏适当的评估策略，对领先的LLMs（例如ChatGPT和KimiChat）的长上下文处理能力和性能了解甚少。为了填补这一空白，我们提出了一个简单、高效、合理的长上下文LLMs评估策略作为一个新的基准，名为Counting-Stars。Counting-Stars旨在要求LLMs充分理解和捕捉长上下文中的长依赖关系，并能够收集跨越整个上下文的多个证据之间的相互依赖来完成任务。基于Counting-Stars，我们进行实验评估了两个领先的长上下文LLMs，即GPT-4 Turbo和Kimi Chat。实验结果表明，GPT-4 Turbo和Kimi Chat在Counting-Stars任务上取得了显著的表现。

    arXiv:2403.11802v1 Announce Type: new  Abstract: While recent research endeavors have concentrated on developing Large Language Models (LLMs) with robust long-context capabilities, due to the lack of appropriate evaluation strategies, relatively little is known about how well the long-context processing abilities and performance of leading LLMs (e.g., ChatGPT and KimiChat). To address this gap, we propose a simple, efficient, and reasonable strategy for evaluating long-context LLMs as a new benchmark, named Counting-Stars. The Counting-Stars is designed to require LLMs to fully understand and capture long dependencies in long contexts and be able to collect inter-dependency across multiple pieces of evidence spanning the entire context to finish the task. Based on the Counting-Stars, we conduct experiments to evaluate the two leading long-context LLMs, i.e., GPT-4 Turbo and Kimi Chat. The experimental results indicate that GPT-4 Turbo and Kimi Chat achieve significant performance in th
    
[^161]: 重新审视经典：识别和纠正韵律诗中的性别刻板印象研究

    Revisiting The Classics: A Study on Identifying and Rectifying Gender Stereotypes in Rhymes and Poems

    [https://arxiv.org/abs/2403.11752](https://arxiv.org/abs/2403.11752)

    该研究通过收集韵律诗和诗歌数据集，建立了一个准确率为97%的模型，用于识别性别偏见，并通过大型语言模型纠正了性别刻板印象。

    

    韵律诗是传递文化规范和社会角色的强大媒介。然而，这些作品中普遍存在的性别刻板印象延续了有偏见的认知，并限制了个体身份的范围。这项工作通过收集一组韵律诗和诗歌数据集，识别性别刻板印象并提出了一个准确率为97%的模型，用于识别性别偏见。通过使用大型语言模型（LLM）纠正了性别刻板印象，并在与人类教育者纠正策略的比较调查中评估了其有效性。总之，这项工作突显了文学作品中性别刻板印象的普遍性，并揭示了大型语言模型纠正性别刻板印象的潜力。

    arXiv:2403.11752v1 Announce Type: new  Abstract: Rhymes and poems are a powerful medium for transmitting cultural norms and societal roles. However, the pervasive existence of gender stereotypes in these works perpetuates biased perceptions and limits the scope of individuals' identities. Past works have shown that stereotyping and prejudice emerge in early childhood, and developmental research on causal mechanisms is critical for understanding and controlling stereotyping and prejudice. This work contributes by gathering a dataset of rhymes and poems to identify gender stereotypes and propose a model with 97\% accuracy to identify gender bias. Gender stereotypes were rectified using a Large Language Model (LLM) and its effectiveness was evaluated in a comparative survey against human educator rectifications. To summarize, this work highlights the pervasive nature of gender stereotypes in literary works and reveals the potential of LLMs to rectify gender stereotypes. This study raises 
    
[^162]: 混合提示专家用于多模态语义理解

    Mixture-of-Prompt-Experts for Multi-modal Semantic Understanding

    [https://arxiv.org/abs/2403.11311](https://arxiv.org/abs/2403.11311)

    提出了一种新型多模态软提示框架MoPE-BAF，用于解决少样本学习下的多模态讽刺检测和情感分析问题，通过三个软提示专家和块感知提示融合，实现了模态特征提取和多模态交互。

    

    arXiv:2403.11311v1 公告类型:新 抽象:在人工智能领域，深度多模态语义理解受到越来越多的关注，超越了单纯的表面内容关系挖掘。收集和注释高质量的多模态数据的挑战凸显了少样本学习的重要性。本文关注这一背景下的两个关键任务: 少样本多模态讽刺检测（MSD）和多模态情感分析（MSA）。为了解决这些问题，我们提出了基于统一视觉-语言模型（VLM）的一种新型多模态软提示框架Mixture-of-Prompt-Experts with Block-Aware Prompt Fusion（MoPE-BAF）。具体来说，我们设计了三个软提示专家: 一个文本提示和一个图像提示，用于提取特定于模态的特征以丰富单模态表示，以及一个统一提示以协助多模态交互。此外，我们将Transformer层重新组织为几个块，并实现了...

    arXiv:2403.11311v1 Announce Type: new  Abstract: Deep multimodal semantic understanding that goes beyond the mere superficial content relation mining has received increasing attention in the realm of artificial intelligence. The challenges of collecting and annotating high-quality multi-modal data have underscored the significance of few-shot learning. In this paper, we focus on two critical tasks under this context: few-shot multi-modal sarcasm detection (MSD) and multi-modal sentiment analysis (MSA). To address them, we propose Mixture-of-Prompt-Experts with Block-Aware Prompt Fusion (MoPE-BAF), a novel multi-modal soft prompt framework based on the unified vision-language model (VLM). Specifically, we design three experts of soft prompts: a text prompt and an image prompt that extract modality-specific features to enrich the single-modal representation, and a unified prompt to assist multi-modal interaction. Additionally, we reorganize Transformer layers into several blocks and intr
    
[^163]: Pointer-Generator网络用于低资源机器翻译：不要复制那个！

    Pointer-Generator Networks for Low-Resource Machine Translation: Don't Copy That!

    [https://arxiv.org/abs/2403.10963](https://arxiv.org/abs/2403.10963)

    Pointer-Generator Networks在低资源机器翻译中未展现出预期的优势，模型在不同资源范围和语言之间的关系下表现一般。

    

    虽然基于Transformer的神经机器翻译（NMT）在高资源环境中非常有效，但许多语言缺乏必要的大规模平行语料库来受益。在两种密切相关语言之间的低资源（LR）机器翻译中，一种自然的直觉是寻求从结构“捷径”中获益，例如从源语言复制子词到目标语言，因为这样的语言对通常共享相当数量的相同单词、同源词和借词。我们测试了针对六种语言对的指针生成器网络在各种资源范围下的用途，并发现在大多数情况下都有轻微改进。然而，分析显示，模型对于密切相关的语言对与较远的语言对，或者资源范围较低与较高的语言对并没有展现出更大的改进，并且模型并未展示出对于共享子词机制的预期用法。我们讨论了这种行为的原因。

    arXiv:2403.10963v1 Announce Type: new  Abstract: While Transformer-based neural machine translation (NMT) is very effective in high-resource settings, many languages lack the necessary large parallel corpora to benefit from it. In the context of low-resource (LR) MT between two closely-related languages, a natural intuition is to seek benefits from structural "shortcuts", such as copying subwords from the source to the target, given that such language pairs often share a considerable number of identical words, cognates, and borrowings. We test Pointer-Generator Networks for this purpose for six language pairs over a variety of resource ranges, and find weak improvements for most settings. However, analysis shows that the model does not show greater improvements for closely-related vs. more distant language pairs, or for lower resource ranges, and that the models do not exhibit the expected usage of the mechanism for shared subwords. Our discussion of the reasons for this behaviour high
    
[^164]: 具有关系解缠的多方回复生成

    Multi-party Response Generation with Relation Disentanglement

    [https://arxiv.org/abs/2403.10827](https://arxiv.org/abs/2403.10827)

    本研究提出了一种利用关系解缠来指导神经响应生成的方法，通过在会话上下文内部微妙线索上进行关系推断，实现了对多方回复的自动推断，无需人工标签。

    

    现有的神经响应生成模型已经在双方对话方面取得了令人瞩目的进展，假设话语是按顺序组织的。然而，许多现实世界中的对话涉及多方参与者，对话上下文的结构要复杂得多，例如，来自不同参与者的话语可能“并行”发生。面对这一挑战，有研究致力于建模话语或参与者之间的关系，以便以更清晰的上下文进行响应生成。然而，这些方法严重依赖这些关系，都假设这些关系是预先给定的，这在实践中是不切实际的，也妨碍了这些方法的普适性。在这项工作中，我们建议通过对话上下文中微妙线索进行关系推断，引导神经响应生成，而无需任何人工标签。具体而言，我们首先通过关系思维自动推断出这些关系，然后利用这些关系来指导神经响应生成。

    arXiv:2403.10827v1 Announce Type: new  Abstract: Existing neural response generation models have achieved impressive improvements for two-party conversations, which assume that utterances are sequentially organized. However, many real-world dialogues involve multiple interlocutors and the structure of conversational context is much more complex, e.g. utterances from different interlocutors can occur "in parallel". Facing this challenge, there are works trying to model the relations among utterances or interlocutors to facilitate response generation with clearer context. Nonetheless, these methods rely heavily on such relations and all assume that these are given beforehand, which is impractical and hinders the generality of such methods. In this work, we propose to automatically infer the relations via relational thinking on subtle clues inside the conversation context without any human label, and leverage these relations to guide the neural response generation. Specifically, we first 
    
[^165]: 知识图谱大型语言模型（KG-LLM）用于链接预测

    Knowledge Graph Large Language Model (KG-LLM) for Link Prediction

    [https://arxiv.org/abs/2403.07311](https://arxiv.org/abs/2403.07311)

    该论文提出了知识图谱大型语言模型框架（KG-LLM），利用思维链提示和上下文学习等NLP范例，以增强知识图谱中的多跳链接预测，并展示了框架在微调大型语言模型和零次尝试能力方面的有效性。

    

    在知识图谱分析领域，预测知识图谱（KGs）内多个链接的任务是一个挑战，由于自然语言处理（NLP）和知识图嵌入技术的进步，这一挑战变得越来越可解决。本文介绍了一种新的方法，即知识图谱大型语言模型框架（KG-LLM），该框架利用关键的NLP范例，包括思维链提示（CoT）和上下文学习（ICL），以增强知识图谱中的多跳链接预测。通过将KG转换为CoT提示，我们的框架旨在识别并学习实体及其相互关系的潜在表示。为了展示KG-LLM框架的有效性，我们在该框架内微调了三种主要的大型语言模型（LLMs），同时采用了非ICL和ICL任务进行全面评估。此外，我们探讨了该框架为LLMs提供零次尝试能力的潜力。

    arXiv:2403.07311v1 Announce Type: new  Abstract: The task of predicting multiple links within knowledge graphs (KGs) stands as a challenge in the field of knowledge graph analysis, a challenge increasingly resolvable due to advancements in natural language processing (NLP) and KG embedding techniques. This paper introduces a novel methodology, the Knowledge Graph Large Language Model Framework (KG-LLM), which leverages pivotal NLP paradigms, including chain-of-thought (CoT) prompting and in-context learning (ICL), to enhance multi-hop link prediction in KGs. By converting the KG to a CoT prompt, our framework is designed to discern and learn the latent representations of entities and their interrelations. To show the efficacy of the KG-LLM Framework, we fine-tune three leading Large Language Models (LLMs) within this framework, employing both non-ICL and ICL tasks for a comprehensive evaluation. Further, we explore the framework's potential to provide LLMs with zero-shot capabilities f
    
[^166]: 一张图片在第二层之后价值1/2代币：针对大规模视觉语言模型的即插即用推理加速

    An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models

    [https://arxiv.org/abs/2403.06764](https://arxiv.org/abs/2403.06764)

    FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。

    

    在本研究中，我们发现大规模视觉语言模型（LVLMs）中的注意力计算存在低效现象，尤其是在知名模型如LLaVA-1.5、QwenVL-Chat和Video-LLaVA中。我们发现在流行的LVLMs的深层中，对视觉代币的注意力计算极其低效，暗示相较于处理文本数据，需要更稀疏的方法。为此，我们引入了FastV，这是一种多功能即插即用方法，旨在通过学习早期层中的自适应注意力模式和在随后层中修剪视觉代币来优化计算效率。我们的评估表明FastV能够显著降低计算成本（例如，对于LLaVA-1.5-13B的FLOP减少了45%），而不会在广泛的图像和视频理解任务中牺牲性能。FastV的计算效率和性能权衡是高度可定制的，并且是帕累托有效的。

    arXiv:2403.06764v1 Announce Type: cross  Abstract: In this study, we identify the inefficient attention phenomena in Large Vision-Language Models (LVLMs), notably within prominent models like LLaVA-1.5, QwenVL-Chat and Video-LLaVA. We find out that the attention computation over visual tokens is of extreme inefficiency in the deep layers of popular LVLMs, suggesting a need for a sparser approach compared to textual data handling. To this end, we introduce FastV, a versatile plug-and-play method designed to optimize computational efficiency by learning adaptive attention patterns in early layers and pruning visual tokens in subsequent ones. Our evaluations demonstrate FastV's ability to dramatically reduce computational costs (e.g., a 45 reduction in FLOPs for LLaVA-1.5-13B) without sacrificing performance in a wide range of image and video understanding tasks. The computational efficiency and performance trade-off of FastV are highly customizable and pareto-efficient. It can compress t
    
[^167]: 通过监督预训练和重要性机制微调改进低资源知识追踪任务

    Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning

    [https://arxiv.org/abs/2403.06725](https://arxiv.org/abs/2403.06725)

    本文提出了名为LoReKT的低资源知识追踪框架，通过监督预训练和微调重要性机制，旨在从丰富资源的KT数据集中学习可转移的参数和表示来改进低资源知识追踪任务。

    

    知识追踪（KT）旨在基于学生的历史互动来估计他们的知识掌握程度。最近，基于深度学习的KT（DLKT）方法在KT任务中取得了令人印象深刻的表现。然而，由于各种原因，如预算限制和隐私问题，许多实际场景中观察到的互动非常有限，即低资源KT数据集。直接在低资源KT数据集上训练DLKT模型可能会导致过拟合，并且很难选择适当的深度神经架构。因此，在本文中，我们提出了一个名为LoReKT的低资源KT框架来应对上述挑战。受盛行的“预训练和微调”范式的启发，我们旨在在预训练阶段从丰富资源的KT数据集中学习可转移的参数和表示。

    arXiv:2403.06725v1 Announce Type: cross  Abstract: Knowledge tracing (KT) aims to estimate student's knowledge mastery based on their historical interactions. Recently, the deep learning based KT (DLKT) approaches have achieved impressive performance in the KT task. These DLKT models heavily rely on the large number of available student interactions. However, due to various reasons such as budget constraints and privacy concerns, observed interactions are very limited in many real-world scenarios, a.k.a, low-resource KT datasets. Directly training a DLKT model on a low-resource KT dataset may lead to overfitting and it is difficult to choose the appropriate deep neural architecture. Therefore, in this paper, we propose a low-resource KT framework called LoReKT to address above challenges. Inspired by the prevalent "pre-training and fine-tuning" paradigm, we aim to learn transferable parameters and representations from rich-resource KT datasets during the pre-training stage and subseque
    
[^168]: 通过小语言模型全面改造多模态助手

    A Comprehensive Overhaul of Multimodal Assistant with Small Language Models

    [https://arxiv.org/abs/2403.06199](https://arxiv.org/abs/2403.06199)

    通过设计多模态小语言模型(MSLMs)及提出高效多模态助手Mipha，实现了在多个方面的协同作用，击败了大语言模型，为开发强大MSLMs提供了见解和指南

    

    多模态大语言模型(MLLMs)展示了在与视觉理解和推理相关的任务中令人印象深刻的技能。然而，由于培训和推理阶段的高计算需求，它们的广泛应用面临障碍，限制了它们在研究和用户社区中受众的范围。在本文中，我们研究了多模态小语言模型（MSLMs）的设计方面，并提出了一种名为Mipha的高效多模态助手，旨在在多个方面之间创造协同作用：视觉表示、语言模型和优化策略。我们表明，在不增加训练数据量的情况下，我们的Mipha-3B在多个基准测试中胜过了最先进的大型MLLMs，特别是LLaVA-1.5-13B。通过详细讨论，我们提供了发展强大的MSLMs的见解和指南，使其能够与MLLMs的能力相媲美。我们的代码可以获得。

    arXiv:2403.06199v1 Announce Type: cross  Abstract: Multimodal Large Language Models (MLLMs) have showcased impressive skills in tasks related to visual understanding and reasoning. Yet, their widespread application faces obstacles due to the high computational demands during both the training and inference phases, restricting their use to a limited audience within the research and user communities. In this paper, we investigate the design aspects of Multimodal Small Language Models (MSLMs) and propose an efficient multimodal assistant named Mipha, which is designed to create synergy among various aspects: visual representation, language models, and optimization strategies. We show that without increasing the volume of training data, our Mipha-3B outperforms the state-of-the-art large MLLMs, especially LLaVA-1.5-13B, on multiple benchmarks. Through detailed discussion, we provide insights and guidelines for developing strong MSLMs that rival the capabilities of MLLMs. Our code is availa
    
[^169]: 分解防御：大型语言模型攻击的比较调查

    Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models

    [https://arxiv.org/abs/2403.04786](https://arxiv.org/abs/2403.04786)

    本文通过全面调查各种攻击形式，探讨了大型语言模型受攻击的性质、机制、潜在影响以及当前防御策略，为模型完整性和用户信任提供了重要见解。

    

    大型语言模型（LLMs）已经成为自然语言处理（NLP）领域的基石，在理解和生成类似人类文本方面提供了革命性的能力。然而，随着它们日益重要，这些模型的安全性和脆弱性方面已经引起了重要关注。本文对针对LLMs的各种形式攻击进行了全面调查，讨论了这些攻击的性质和机制、它们的潜在影响以及当前的防御策略。我们深入探讨了旨在操纵模型输出的对抗性攻击、影响模型训练的数据中毒以及与训练数据利用相关的隐私问题。本文还探讨了不同攻击方法的有效性、LLMs抵抗这些攻击的韧性以及对模型完整性和用户信任的影响。通过审视最新研究，我们提供了见解。

    arXiv:2403.04786v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have become a cornerstone in the field of Natural Language Processing (NLP), offering transformative capabilities in understanding and generating human-like text. However, with their rising prominence, the security and vulnerability aspects of these models have garnered significant attention. This paper presents a comprehensive survey of the various forms of attacks targeting LLMs, discussing the nature and mechanisms of these attacks, their potential impacts, and current defense strategies. We delve into topics such as adversarial attacks that aim to manipulate model outputs, data poisoning that affects model training, and privacy concerns related to training data exploitation. The paper also explores the effectiveness of different attack methodologies, the resilience of LLMs against these attacks, and the implications for model integrity and user trust. By examining the latest research, we provide insight
    
[^170]: 从图到词袋: 将领域知识引入混淆罪名预测

    From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge Prediction

    [https://arxiv.org/abs/2403.04369](https://arxiv.org/abs/2403.04369)

    引入领域知识的从图到词袋方法，帮助预测混淆罪名，通过构成要素和关键词选择进行判断。

    

    混淆罪名预测是法律人工智能中一个具有挑战性的任务，涉及根据事实描述预测混淆罪名。现有的罪名预测方法在表现上已经展现出令人印象深刻的效果，但在处理混淆罪名（如抢夺与抢劫）时面临着重大挑战。在法律领域，构成要素在区分混淆罪名中扮演着至关重要的角色。构成要素是潜在刑罚背后的基本行为，并且在不同罪名之间有微妙的区别。本文介绍了一种新的从图到词袋（FWGB）方法，该方法引入了有关构成要素的领域知识，以指导模型在混淆罪名上做出判断，类似于法官的推理过程。具体而言，我们首先构建了一个包含构成要素的法律知识图，以帮助为每种罪名选择关键词，形成一个单词袋。

    arXiv:2403.04369v1 Announce Type: new  Abstract: Confusing charge prediction is a challenging task in legal AI, which involves predicting confusing charges based on fact descriptions. While existing charge prediction methods have shown impressive performance, they face significant challenges when dealing with confusing charges, such as Snatch and Robbery. In the legal domain, constituent elements play a pivotal role in distinguishing confusing charges. Constituent elements are fundamental behaviors underlying criminal punishment and have subtle distinctions among charges. In this paper, we introduce a novel From Graph to Word Bag (FWGB) approach, which introduces domain knowledge regarding constituent elements to guide the model in making judgments on confusing charges, much like a judge's reasoning process. Specifically, we first construct a legal knowledge graph containing constituent elements to help select keywords for each charge, forming a word bag. Subsequently, to guide the mod
    
[^171]: BASS的再审视--利用统一语义图提升抽象摘要--一项复制研究

    A Second Look on BASS -- Boosting Abstractive Summarization with Unified Semantic Graphs -- A Replication Study

    [https://arxiv.org/abs/2403.02930](https://arxiv.org/abs/2403.02930)

    通过复制研究BASS框架，发现了与原始工作相比性能上的差异，并强调了撰写可复制论文的关键实践。

    

    我们展示了对BASS框架的详细复制研究，这是一个基于统一语义图概念的抽象摘要系统。我们的调查包括复制关键组件时遇到的挑战，以及一个消融研究来系统地隔离在复制新颖组件时根源于错误来源。我们的发现揭示了与原始工作相比性能上的差异。我们强调了即使是被合理省略的细节对于复制像BASS这样的先进框架的重要性，并强调了撰写可复制论文的关键实践。

    arXiv:2403.02930v1 Announce Type: new  Abstract: We present a detailed replication study of the BASS framework, an abstractive summarization system based on the notion of Unified Semantic Graphs. Our investigation includes challenges in replicating key components and an ablation study to systematically isolate error sources rooted in replicating novel components. Our findings reveal discrepancies in performance compared to the original work. We highlight the significance of paying careful attention even to reasonably omitted details for replicating advanced frameworks like BASS, and emphasize key practices for writing replicable papers.
    
[^172]: InjecAgent：基于工具集成的大型语言模型Agent中的间接提示注入基准测试

    InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents

    [https://arxiv.org/abs/2403.02691](https://arxiv.org/abs/2403.02691)

    本研究引入了InjecAgent基准测试，用于评估工具集成的大型语言模型代理对间接提示注入攻击的脆弱性，通过评估30种LLM代理，发现这些代理存在漏洞

    

    最近的工作将LLMs作为代理体现出来，使它们能够访问工具，执行操作，并与外部内容（例如，电子邮件或网站）进行交互。然而，外部内容引入了间接提示注入（IPI）攻击的风险，恶意指令被嵌入LLMs处理的内容中，旨在操纵这些代理执行对用户有害的操作。考虑到这类攻击的潜在严重后果，建立用于评估和减轻这些风险的基准测试至关重要。在这项工作中，我们介绍了InjecAgent，这是一个旨在评估工具集成的LLM代理对IPI攻击的脆弱性的基准测试。InjecAgent包括1,054个测试用例，涵盖17种不同的用户工具和62种攻击者工具。我们将攻击意图分为两种主要类型：对用户造成直接伤害和窃取私人数据。我们评估了30种不同的LLM代理，并表明这些代理是脆弱的。

    arXiv:2403.02691v1 Announce Type: new  Abstract: Recent work has embodied LLMs as agents, allowing them to access tools, perform actions, and interact with external content (e.g., emails or websites). However, external content introduces the risk of indirect prompt injection (IPI) attacks, where malicious instructions are embedded within the content processed by LLMs, aiming to manipulate these agents into executing detrimental actions against users. Given the potentially severe consequences of such attacks, establishing benchmarks to assess and mitigate these risks is imperative.   In this work, we introduce InjecAgent, a benchmark designed to assess the vulnerability of tool-integrated LLM agents to IPI attacks. InjecAgent comprises 1,054 test cases covering 17 different user tools and 62 attacker tools. We categorize attack intentions into two primary types: direct harm to users and exfiltration of private data. We evaluate 30 different LLM agents and show that agents are vulnerable
    
[^173]: Align-to-Distill: 可训练的注意力对齐在神经机器翻译中的知识蒸馏

    Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation

    [https://arxiv.org/abs/2403.01479](https://arxiv.org/abs/2403.01479)

    "本文提出了“Align-to-Distill”（A2D）策略，通过在训练过程中自适应地对齐学生注意力头与其教师对应物，转化了组合映射启发式方法为学习问题，实验结果显示A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。"

    

    可扩展的深度模型和大规模数据集的出现提高了神经机器翻译的性能。知识蒸馏（KD）通过将知识从教师模型传输到更紧凑的学生模型来提高效率。然而，针对Transformer架构的KD方法通常依赖于启发式方法，特别是在决定要从哪些教师层中蒸馏知识时。本文介绍了“Align-to-Distill”（A2D）策略，旨在通过在训练过程中自适应地对齐学生注意力头与其教师对应物来解决特征映射问题。A2D中的注意力对齐模块执行学生和教师注意力头之间的密集逐头比较，将组合映射启发式方法转化为学习问题。我们的实验展示了A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。

    arXiv:2403.01479v1 Announce Type: cross  Abstract: The advent of scalable deep models and large datasets has improved the performance of Neural Machine Translation. Knowledge Distillation (KD) enhances efficiency by transferring knowledge from a teacher model to a more compact student model. However, KD approaches to Transformer architecture often rely on heuristics, particularly when deciding which teacher layers to distill from. In this paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to address the feature mapping problem by adaptively aligning student attention heads with their teacher counterparts during training. The Attention Alignment Module in A2D performs a dense head-by-head comparison between student and teacher attention heads across layers, turning the combinatorial mapping heuristics into a learning problem. Our experiments show the efficacy of A2D, demonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb and WMT-2014 En->De, respe
    
[^174]: 使用样本高效适应对大型语言模型进行自定义以进行代码生成

    SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation

    [https://arxiv.org/abs/2403.00046](https://arxiv.org/abs/2403.00046)

    SEED提出了一种名为Sample-Efficient adaptation with Error-Driven learning的新颖适应方法，利用LLMs产生的错误作为学习机会，从而实现对代码生成任务的高效学习。

    

    虽然大型语言模型（LLMs）在代码生成方面取得了重大进展，但在特定场景下仍然存在困难。这些场景通常需要调整LLMs以满足特定需求，但实际可用的训练数据有限，导致代码生成性能较差。如何有效地调整LLMs以适应新场景并使用更少的训练样本是当前代码生成面临的主要挑战。在本文中，我们提出了一种名为SEED的新颖适应方法，即Sample-Efficient adaptation with Error-Driven learning for code generation。SEED利用LLMs产生的错误作为学习机会，利用错误修订来克服自身缺点，从而实现有效学习。具体而言，SEED涉及识别LLMs生成的错误代码，使用Self-revise进行代码修订，优化模型并迭代地进行适应。

    arXiv:2403.00046v1 Announce Type: cross  Abstract: Although Large Language Models (LLMs) have made significant progress in code generation, they still struggle with code generation tasks in specific scenarios. These scenarios usually necessitate the adaptation of LLMs to fulfill specific needs, but the limited training data available in practice leads to poor code generation performance. How to effectively adapt LLMs to new scenarios with fewer training samples is a major challenge for current code generation. In this paper, we propose a novel adaptation approach named SEED, which stands for Sample-Efficient adaptation with Error-Driven learning for code generation. SEED leverages the errors made by LLMs as learning opportunities, using error revision to overcome its own shortcomings, thus achieving efficient learning. Specifically, SEED involves identifying error code generated by LLMs, employing Self-revise for code revision, optimizing the model with revised code, and iteratively ad
    
[^175]: 通过可解释的方言分类器提取方言的词汇特征

    Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers

    [https://arxiv.org/abs/2402.17914](https://arxiv.org/abs/2402.17914)

    通过可解释的方言分类器提取方言的词汇特征，成功识别了有助于方言变化的关键语言特定词汇特征。

    

    识别一种语言的方言之间的语言差异通常需要专业知识和细致的人类分析。这主要是因为研究各种方言涉及到复杂性和微妙之处。我们提出了一种新颖的方法，通过利用可解释的方言分类器提取方言的区分性词汇特征，即使在没有人类专家的情况下。我们探索了事后和内在的解释性方法，对普通话、意大利语和低地萨克森语进行实验，并实验证明我们的方法成功地识别了有助于方言变化的关键语言特定词汇特征。

    arXiv:2402.17914v1 Announce Type: cross  Abstract: Identifying linguistic differences between dialects of a language often requires expert knowledge and meticulous human analysis. This is largely due to the complexity and nuance involved in studying various dialects. We present a novel approach to extract distinguishing lexical features of dialects by utilizing interpretable dialect classifiers, even in the absence of human experts. We explore both post-hoc and intrinsic approaches to interpretability, conduct experiments on Mandarin, Italian, and Low Saxon, and experimentally demonstrate that our method successfully identifies key language-specific lexical features that contribute to dialectal variations.
    
[^176]: HumanEval-XL：面向跨语言自然语言泛化的多语言代码生成基准

    HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization

    [https://arxiv.org/abs/2402.16694](https://arxiv.org/abs/2402.16694)

    HumanEval-XL 是一个面向跨语言自然语言泛化的多语言代码生成基准，建立23种自然语言和12种编程语言的联系，提供了全面的评估平台，弥补了多语言LLM评估的重要空白。

    

    大型语言模型(LLMs)在从文本提示生成代码方面取得了重大进展。然而，现有的基准主要集中在将英语提示翻译为多语言代码，或者仅限于非常有限的自然语言(NLs)。这些基准忽视了庞大的作为对比的多语言NL到多语言代码的广阔领域，导致了对多语言LLM评估的重大空白。为解决这一问题，我们引入了HumanEval-XL，一个专门设计来解决这一不足的大规模多语言代码生成基准。HumanEval-XL建立了23种NL和12种编程语言(PLs)之间的联系，包括了22,080个提示的集合，平均有8.33个测试用例。通过确保在多个NL和PL之间的并行数据，HumanEval-XL为多语言LLMs提供了全面的评估平台，允许评估对不同NL的理解。

    arXiv:2402.16694v1 Announce Type: new  Abstract: Large language models (LLMs) have made significant progress in generating codes from textual prompts. However, existing benchmarks have mainly concentrated on translating English prompts to multilingual codes or have been constrained to very limited natural languages (NLs). These benchmarks have overlooked the vast landscape of massively multilingual NL to multilingual code, leaving a critical gap in the evaluation of multilingual LLMs. In response, we introduce HumanEval-XL, a massively multilingual code generation benchmark specifically crafted to address this deficiency. HumanEval-XL establishes connections between 23 NLs and 12 programming languages (PLs), and comprises of a collection of 22,080 prompts with an average of 8.33 test cases. By ensuring parallel data across multiple NLs and PLs, HumanEval-XL offers a comprehensive evaluation platform for multilingual LLMs, allowing the assessment of the understanding of different NLs. O
    
[^177]: Chitchat作为干扰：向面向任务的对话添加用户背景故事

    Chitchat as Interference: Adding User Backstories to Task-Oriented Dialogues

    [https://arxiv.org/abs/2402.15248](https://arxiv.org/abs/2402.15248)

    通过使用少样本提示和Llama-2-70B增强MultiWOZ数据集，引入用户背景故事，有效解决面向任务的对话中的闲聊干扰问题，并能够同时承认用户背景故事并推动任务的进行。

    

    在面向任务的对话（TOD）中，人类用户自然会引入超出任务范围的闲聊，干扰了对话的流程。为了解决这一问题，我们利用Llama-2-70B进行少样本提示，以增强MultiWOZ数据集，其中包括用户背景故事，这是TOD中典型的闲聊干扰的一个例子。我们通过测试两个模型来评估此添加的影响：一个仅在TOD上进行训练，另一个在TOD上进行初步闲聊交互的训练。我们的分析表明，我们丰富的数据集对这些系统构成了重要挑战。此外，我们证明我们的数据集可以有效用于训练，使系统能够在同一轮中持续承认用户背景故事并成功推动任务的进行，这得到了人类评估的确认。这些发现突显了引入用户背景故事的好处。

    arXiv:2402.15248v1 Announce Type: new  Abstract: During task-oriented dialogues (TODs), human users naturally introduce chitchat that is beyond the immediate scope of the task, interfering with the flow of the conversation. To address this issue without the need for expensive manual data creation, we use few-shot prompting with Llama-2-70B to enhance the MultiWOZ dataset with user backstories, a typical example of chitchat interference in TODs. We assess the impact of this addition by testing two models: one trained solely on TODs and another trained on TODs with a preliminary chitchat interaction. Our analysis reveals that our enriched dataset poses a significant challenge to these systems. Moreover, we demonstrate that our dataset can be effectively used for training purposes, enabling a system to consistently acknowledge the user's backstory while also successfully moving the task forward in the same turn, as confirmed by human evaluation. These findings highlight the benefits of ge
    
[^178]: 低资源条件下南亚语言的多语言共指解析

    Multilingual Coreference Resolution in Low-resource South Asian Languages

    [https://arxiv.org/abs/2402.13571](https://arxiv.org/abs/2402.13571)

    引入了一个用于31种南亚语言的多语言共指解析翻译数据集，通过利用现成工具进行训练和对齐，在低资源条件下实现了较好的共指解析模型性能提升。

    

    共指解析涉及识别在话语中指向同一现实实体的文本片段的任务。虽然这一任务在英语中得到了广泛研究，但在南亚语言中，公开可访问的共指解析资源和模型相对稀缺。我们利用现成的翻译和词对齐工具，在31种南亚语言中引入了一个用于多语言共指解析的翻译数据集（TransMuCoRes）。几乎所有预测的翻译都通过了合理性检查，75%的英语参考文献与其预测的翻译相对应。利用多语言编码器，我们训练了两种现成的共指解析模型，将TransMuCoRes与带有手动注释的印地语共指解析数据集拼接在一起。最佳表现模型在LEA F1和CoNLL F1上分别达到了64和68的分数。

    arXiv:2402.13571v1 Announce Type: cross  Abstract: Coreference resolution involves the task of identifying text spans within a discourse that pertain to the same real-world entity. While this task has been extensively explored in the English language, there has been a notable scarcity of publicly accessible resources and models for coreference resolution in South Asian languages. We introduce a Translated dataset for Multilingual Coreference Resolution (TransMuCoRes) in 31 South Asian languages using off-the-shelf tools for translation and word-alignment. Nearly all of the predicted translations successfully pass a sanity check, and 75% of English references align with their predicted translations. Using multilingual encoders, two off-the-shelf coreference resolution models were trained on a concatenation of TransMuCoRes and a Hindi coreference resolution dataset with manual annotations. The best performing model achieved a score of 64 and 68 for LEA F1 and CoNLL F1, respectively, on o
    
[^179]: LongHeads: 多头注意力其实是一个长上下文处理器

    LongHeads: Multi-Head Attention is Secretly a Long Context Processor

    [https://arxiv.org/abs/2402.10685](https://arxiv.org/abs/2402.10685)

    LongHeads 提出了一个无需训练的框架，通过释放多头注意力的潜力来增强大型语言模型(LLM)处理长上下文的能力。

    

    大型语言模型(LLMs)在许多领域取得了令人印象深刻的表现，但由于有限长度泛化和注意力的二次计算需求，往往难以有效高效地处理较长的输入。 许多人试图通过限制在预训练长度内的注意力窗口来缓解这一问题。 然而，这些方法引入了新问题，如忽略中间上下文和需要额外训练。 为了解决这些问题，我们提出了LongHeads，一个无需训练的框架，通过释放多头注意力的潜力来增强LLM的长上下文能力。 我们允许每个头部选择并关注重要的上下文块，以处理分布长度，而不是让每个头部都参与全句注意力，这样做由于分布之外的问题而难以泛化到更长的序列。

    arXiv:2402.10685v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved impressive performance in numerous domains but often struggle to process lengthy inputs effectively and efficiently due to limited length generalization and attention's quadratic computational demands. Many sought to mitigate this by restricting the attention window within the pre-trained length. However, these methods introduce new issues such as ignoring the middle context and requiring additional training. To address these problems, we propose LongHeads, a training-free framework that enhances LLM's long context ability by unlocking multi-head attention's untapped potential. Instead of allowing each head to attend to the full sentence, which struggles with generalizing to longer sequences due to out-of-distribution (OOD) issues, we allow each head to process in-distribution length by selecting and attending to important context chunks. To this end, we propose a chunk selection strategy that
    
[^180]: OpenFMNav: 通过视觉-语言基础模型实现开放式零样本目标导航

    OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models

    [https://arxiv.org/abs/2402.10670](https://arxiv.org/abs/2402.10670)

    本研究提出了一种名为OpenFMNav的框架，通过大型语言模型和视觉语言模型解决了目标导航领域中关于理解自然语言指令和零样本泛化的问题。

    

    目标导航(ObjectNav)需要一个代理在未知环境中导航以找到查询对象。许多先前的方法尝试通过依赖监督学习或强化学习来解决这一任务，其中它们是在具有闭集对象的有限家庭数据集上进行训练的。然而，仍有两个关键挑战尚未解决：理解要求开放集对象的自由形式自然语言指令，并以零样本方式推广到新环境。为了解决这两个挑战，在本文中，我们提出了OpenFMNav，一种基于开放集基础模型的零样本目标导航框架。我们首先释放大型语言模型(LLMs)的推理能力，从符合用户需求的自然语言指令中提取提议的对象。然后，利用大型视觉语言模型(VLMs)的泛化能力，积极发现并检测场景中的候选对象，构建一个Ve

    arXiv:2402.10670v1 Announce Type: new  Abstract: Object navigation (ObjectNav) requires an agent to navigate through unseen environments to find queried objects. Many previous methods attempted to solve this task by relying on supervised or reinforcement learning, where they are trained on limited household datasets with close-set objects. However, two key challenges are unsolved: understanding free-form natural language instructions that demand open-set objects, and generalizing to new environments in a zero-shot manner. Aiming to solve the two challenges, in this paper, we propose OpenFMNav, an Open-set Foundation Model based framework for zero-shot object Navigation. We first unleash the reasoning abilities of large language models (LLMs) to extract proposed objects from natural language instructions that meet the user's demand. We then leverage the generalizability of large vision language models (VLMs) to actively discover and detect candidate objects from the scene, building a Ve
    
[^181]: 通过知识蒸馏和优化训练策略，利用大型语言模型提升NLP任务性能

    Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies

    [https://arxiv.org/abs/2402.09282](https://arxiv.org/abs/2402.09282)

    该论文介绍了一种利用大型语言模型和优化训练策略提高NLP任务性能的新方法，通过知识蒸馏和采用细思连想提示技术，将GPT-4中提炼的知识应用于BERT模型，在命名实体识别任务上取得了显著的性能提升，并为资源有限或封闭网络环境提供了一种成本效益的解决方案。

    

    大型语言模型（LLMs）如GPT-4的整合到传统的自然语言处理（NLP）任务中，为提高模型性能并减少对大量人工注释的依赖打开了新的途径。本文提出了一种利用细思连想（CoT）提示技术从GPT-4中提炼知识，并将其应用于改进较小模型BERT在命名实体识别（NER）任务上的效率和效果的新方法。我们的方法包括两个阶段的训练过程：首先使用GPT-4注释数据进行预训练，然后使用蒸馏和原始人工注释数据的组合对模型进行改进。结果表明，我们的混合训练策略明显优于仅使用人工注释数据训练的模型，在F1分数上表现出卓越的性能，并为资源有限或封闭网络环境提供了一种具有成本效益的解决方案。

    arXiv:2402.09282v1 Announce Type: new Abstract: The integration of Large Language Models (LLMs) like GPT-4 into traditional Natural Language Processing (NLP) tasks has opened new avenues for enhancing model performance while reducing the reliance on extensive human annotations. This paper presents a novel approach that leverages the Chain of Thought (CoT) prompting technique to distill knowledge from GPT-4, subsequently applying it to improve the efficiency and effectiveness of a smaller model, BERT, on Named Entity Recognition (NER) tasks. Our method involves a two-phase training process: initially employing GPT-4 annotated data for pre-training and then refining the model with a combination of distilled and original human-annotated data. The results demonstrate that our mixed-training strategy significantly outperforms models trained solely on human annotations, achieving superior F1-scores and showcasing a cost-effective solution for resource-limited or closed-network settings. The 
    
[^182]: 用于推断高效LLMs的串联Transformer

    Tandem Transformers for Inference Efficient LLMs

    [https://arxiv.org/abs/2402.08644](https://arxiv.org/abs/2402.08644)

    该论文提出了一种新的架构，称为串联Transformer，用于解决传统大型语言模型推断速度限制的问题。该架构通过将小型自回归模型和大模型以块模式结合起来，并让小模型关注大模型的丰富表示，从而显著提高了小模型的预测准确性。实验证明，在预训练数据集上，串联的PaLM2-Bison和PaLM2-Gecko相比独立的PaLM2-Gecko，在下一个词元预测准确性上提高了3.3%，并且相较于具有相似下游任务的PaLM2-Otter模型，加速比达到1.16倍。

    

    传统的大型语言模型( LLMs )具有自回归的特性，这使得推断速度受到限制，因为词元是按顺序生成的。尽管有些预测和并行解码技术试图减轻这个问题，但它们都有限制：要么依赖更精简但准确度较低的模型进行生成，要么没有充分利用基础LLM的表示。我们提出了一种新颖的架构，即串联Transformer，来解决这些问题。这种架构独特地结合了(1)一个小型自回归模型和(2)一个以块模式运行的大模型(同时处理多个词元)。通过让小模型关注大模型更丰富的表示，大幅提升小模型的预测准确性。在PaLM2预训练数据集上，PaLM2-Bison和PaLM2-Gecko的串联相较独立的PaLM2-Gecko，在下一个词元预测准确性上提升了3.3%，与具有相似下游任务的PaLM2-Otter模型相比，提供了1.16倍的加速比。

    The autoregressive nature of conventional large language models (LLMs) inherently limits inference speed, as tokens are generated sequentially. While speculative and parallel decoding techniques attempt to mitigate this, they face limitations: either relying on less accurate smaller models for generation or failing to fully leverage the base LLM's representations.   We introduce a novel architecture, Tandem transformers, to address these issues. This architecture uniquely combines (1) a small autoregressive model and (2) a large model operating in block mode (processing multiple tokens simultaneously). The small model's predictive accuracy is substantially enhanced by granting it attention to the large model's richer representations. On the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Gecko demonstrates a 3.3% improvement in next-token prediction accuracy over a standalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter model with comparable downstream p
    
[^183]: 大型语言模型在数学推理中的应用：进展与挑战

    Large Language Models for Mathematical Reasoning: Progresses and Challenges

    [https://arxiv.org/abs/2402.00157](https://arxiv.org/abs/2402.00157)

    大型语言模型(LLMs)在解决数学问题方面涉及了大量的数学问题类型和不同的数据集和设置。目前仍然存在一些挑战，需要进一步研究和解决。

    

    数学推理是评估人类智能基本认知能力的基石。近年来，大型语言模型（LLMs）的发展引起了人们对自动解决数学问题的重视。然而，数学问题的类型非常广泛，LLM相关技术在不同数据集和设置下进行评估，使得如何判断这一新兴领域中的真正进展和障碍变得困难。本调查研究包括了以下四个关键方面：i）全面探索各种已经研究的数学问题及其相应数据集；ii）研究提出的解决数学问题的LLM技术的范围；iii）概述影响LLM在解决数学问题中的因素和关注点；iv）阐明仍然存在的挑战。

    Mathematical reasoning serves as a cornerstone for assessing the fundamental cognitive capabilities of human intelligence. In recent times, there has been a notable surge in the development of Large Language Models (LLMs) geared towards the automated resolution of mathematical problems. However, the landscape of mathematical problem types is vast and varied, with LLM-oriented techniques undergoing evaluation across diverse datasets and settings. This diversity makes it challenging to discern the true advancements and obstacles within this burgeoning field. This survey endeavors to address four pivotal dimensions: i) a comprehensive exploration of the various mathematical problems and their corresponding datasets that have been investigated; ii) an examination of the spectrum of LLM-oriented techniques that have been proposed for mathematical problem-solving; iii) an overview of factors and concerns affecting LLMs in solving math; and iv) an elucidation of the persisting challenges with
    
[^184]: LOCOST: 长文档抽象摘要化的状态空间模型

    LOCOST: State-Space Models for Long Document Abstractive Summarization

    [https://arxiv.org/abs/2401.17919](https://arxiv.org/abs/2401.17919)

    LOCOST是一种基于状态空间模型的编码器-解码器架构，用于处理长文档的抽象摘要生成。与基于稀疏注意模式的最先进模型相比，LOCOST具有更低的计算复杂度，并且能够在训练和推断期间节省大量内存。在评估中，LOCOST在长文档摘要化任务上达到了93-96%的性能水平，并且能够处理超过600K个标记的输入文本。

    

    状态空间模型是编码长序列和捕捉长期依赖的低复杂度替代方案，我们提出了LOCOST：一种基于状态空间模型的编码器-解码器架构，用于具有长上下文输入的条件文本生成。这种架构的计算复杂度为O（L log L），可以处理比基于稀疏注意模式的最先进模型更长的序列。我们在一系列长文档抽象摘要化任务上评估了我们的模型。该模型在性能水平上达到了与相同大小的最优稀疏变压器相当的93-96%，同时在训练期间节省了高达50%的内存，在推断期间节省了高达87%的内存。此外，LOCOST有效地处理超过600K个标记的输入文本，为完整书摘要化设定了新的最新结果，并为长输入处理开辟了新的视角。

    State-space models are a low-complexity alternative to transformers for encoding long sequences and capturing long-term dependencies. We propose LOCOST: an encoder-decoder architecture based on state-space models for conditional text generation with long context inputs. With a computational complexity of $O(L \log L)$, this architecture can handle significantly longer sequences than state-of-the-art models that are based on sparse attention patterns. We evaluate our model on a series of long document abstractive summarization tasks. The model reaches a performance level that is 93-96% comparable to the top-performing sparse transformers of the same size while saving up to 50% memory during training and up to 87% during inference. Additionally, LOCOST effectively handles input texts exceeding 600K tokens at inference time, setting new state-of-the-art results on full-book summarization and opening new perspectives for long input processing.
    
[^185]: PILOT: 使用法律案例预测案例结果

    PILOT: Legal Case Outcome Prediction with Case Law

    [https://arxiv.org/abs/2401.15770](https://arxiv.org/abs/2401.15770)

    提出了新的PILOT框架，旨在解决使用案例法预测法律案例结果的挑战，包括相关案例检索和时间模式处理两个模块。

    

    机器学习在预测法律案例结果方面表现出有希望的前景，但大多数研究集中在民事法律案例而非案例法系统上。我们确定了在使用案例法进行法律案例结果预测时的两个独特挑战。首先，识别作为法官在决策过程中基本证据的相关先例案例至关重要。其次，有必要考虑法律原则随时间演变的情况，因为早期案例可能遵循不同的法律背景。在本文中，我们提出了一个名为PILOT（法律案例结果预测）的新框架。它包括用于相关案例检索和时间模式处理的两个模块。为了衡量现有法律案例结果预测模型的性能，我们从大规模案例法数据库中策划了一个数据集。我们证明了准确识别先例案例的重要性以及缓解...

    arXiv:2401.15770v2 Announce Type: replace  Abstract: Machine learning shows promise in predicting the outcome of legal cases, but most research has concentrated on civil law cases rather than case law systems. We identified two unique challenges in making legal case outcome predictions with case law. First, it is crucial to identify relevant precedent cases that serve as fundamental evidence for judges during decision-making. Second, it is necessary to consider the evolution of legal principles over time, as early cases may adhere to different legal contexts. In this paper, we proposed a new framework named PILOT (PredictIng Legal case OuTcome) for case outcome prediction. It comprises two modules for relevant case retrieval and temporal pattern handling, respectively. To benchmark the performance of existing legal case outcome prediction models, we curated a dataset from a large-scale case law database. We demonstrate the importance of accurately identifying precedent cases and mitiga
    
[^186]: 随着文本量增加，推断训练有助于长文本生成

    With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation

    [https://arxiv.org/abs/2401.11504](https://arxiv.org/abs/2401.11504)

    Temp-Lora方法通过在长文本生成过程中逐步训练临时Lora模块，有效保留上下文知识并避免对模型参数的永久性改变。

    

    长文本生成，如小说创作和具有极长上下文的篇章级翻译，对当前的语言模型提出了重大挑战。现有方法主要集中在通过长度外推等策略扩展模型的上下文窗口。然而，这些方法在训练和/或推断阶段要求大量硬件资源。我们提出的方法Temp-Lora引入了一个替代概念。我们不依赖于KV缓存存储所有上下文信息，而是将这些信息直接嵌入临时Lora模块中。在长文本生成过程中，这个模块会随着先前生成的文本逐渐进行训练。这种方法不仅有效地保留上下文知识，还防止了对模型参数的任何永久性改变，因为模块在生成后被丢弃。在PG19语言建模上进行了大量实验。

    arXiv:2401.11504v2 Announce Type: replace-cross  Abstract: Long text generation, such as novel writing and discourse-level translation with extremely long contexts, presents significant challenges to current language models. Existing methods mainly focus on extending the model's context window through strategies like length extrapolation. However, these approaches demand substantial hardware resources during the training and/or inference phases. Our proposed method, Temp-Lora, introduces an alternative concept. Instead of relying on the KV cache to store all context information, we embeds this information directly into a temporary Lora module. In the process of long text generation, this module is progressively trained with text generated previously. This approach not only efficiently preserves contextual knowledge but also prevents any permanent alteration to the model's parameters given that the module is discarded post-generation. Extensive experiments on the PG19 language modeling 
    
[^187]: BaRDa: 一个将事实准确性和推理能力分开的信念和推理数据集

    BaRDa: A Belief and Reasoning Dataset that Separates Factual Accuracy and Reasoning Ability

    [https://arxiv.org/abs/2312.07527](https://arxiv.org/abs/2312.07527)

    BaRDa数据集通过使用人类注释的蕴涵树，混合真实和虚假事实，并包括反事实例子，成功区分了事实准确性和推理能力。

    

    尽管存在许多基准来比较现代语言模型（LMs）的性能，但最终任务评估往往混淆了*事实准确性*（"真相"）和*推理能力*（"合理性"，或者根据正确报告信念含义来定义的"诚实"）。我们的目标是创建一个能够清晰区分这两个概念的数据集。我们的方法是利用和扩展一组人类注释的*蕴涵树*，用于表达良好和恶劣的推理链，并使用真实和虚假事实的混合，特别是包括反事实的例子，以避免信念偏见（也称为"内容效应"）。结果数据集名为BaRDa，包含3000个蕴涵（1787个有效，1213个无效），使用6681个真实和2319个虚假陈述。在四个GPT系列模型 GPT3(curie)/GPT3(davinici)/3.5/4 上进行测试，发现事实准确性（真相）得分为74.1/80.6/82.6/87.1以及推理能力

    arXiv:2312.07527v2 Announce Type: replace-cross  Abstract: While there are numerous benchmarks comparing the performance of modern language models (LMs), end-task evaluations often conflate notions of *factual accuracy* ("truth") and *reasoning ability* ("rationality", or "honesty" in the sense of correctly reporting implications of beliefs). Our goal is a dataset that clearly distinguishes these two notions. Our approach is to leverage and extend a collection of human-annotated *entailment trees*, engineered to express both good and bad chains of reasoning, and using a mixture of true and false facts, in particular including counterfactual examples, to avoid belief bias (also known as the "content effect"). The resulting dataset, called BaRDa, contains 3000 entailments (1787 valid, 1213 invalid), using 6681 true and 2319 false statements. Testing on four GPT-series models, GPT3(curie)/GPT3(davinici)/3.5/4, we find factual accuracy (truth) scores of 74.1/80.6/82.6/87.1 and reasoning ac
    
[^188]: 揭示和提高数据可信度：训练无害语言模型的数据集研究

    Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models

    [https://arxiv.org/abs/2311.11202](https://arxiv.org/abs/2311.11202)

    本研究专注于真实世界数据集的可信度，提出了一个系统化框架，用于评估数据集的可信度，识别标签错误，并评估嘈杂标签对不安全评论和对话分类的影响，以提高训练无害语言模型的质量。

    

    arXiv:2311.11202v2宣布类型：替换-跨文档摘要：语言模型在各种任务中显示出潜力，但在训练、微调或对齐过程中可能受到不希望的数据的影响。因此，注解的正确性，即数据集的可信度，变得非常重要。本研究聚焦于真实世界数据集的可信度，其中包括可用于训练无害语言模型的流行基准数据集，如Jigsaw Civil Comments、Anthropic Harmless和Red Team、PKU BeaverTails和SafeRLHF。考虑到人们清洗这些数据集的成本和难度，我们引入了一个系统化框架，用于评估数据集的可信度，识别标签错误，并评估策划语言数据中嘈杂标签的影响，特别关注不安全评论和对话分类。

    arXiv:2311.11202v2 Announce Type: replace-cross  Abstract: Language models have shown promise in various tasks but can be affected by undesired data during training, fine-tuning, or alignment. For example, if some unsafe conversations are wrongly annotated as safe ones, the model fine-tuned on these samples may be harmful. Therefore, the correctness of annotations, i.e., the credibility of the dataset, is important. This study focuses on the credibility of real-world datasets, including the popular benchmarks Jigsaw Civil Comments, Anthropic Harmless & Red Team, PKU BeaverTails & SafeRLHF, that can be used for training a harmless language model. Given the cost and difficulty of cleaning these datasets by humans, we introduce a systematic framework for evaluating the credibility of datasets, identifying label errors, and evaluating the influence of noisy labels in the curated language data, specifically focusing on unsafe comments and conversation classification. With the framework, we 
    
[^189]: Mind's Mirror: 从大型语言模型中提取自我评估能力和综合思维

    Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models

    [https://arxiv.org/abs/2311.09214](https://arxiv.org/abs/2311.09214)

    本研究提出了一种从大型语言模型中提取自我评估能力和综合思维的方法，旨在解决小语言模型继承不完善推理和幻觉的问题。

    

    大型语言模型（LLMs）在自然语言处理领域取得了显著进展。然而，这些模型的大规模和计算需求在考虑它们在资源受限环境中的实际部署时带来了巨大挑战。我们提出了一种双重方法论：首先，我们引入了一种新的方法，将LLMs中的自我评估能力提炼到SLMs中，旨在减轻从LLMs继承的错误推理和幻觉的不良影响。其次，我们提倡通过整合多个不同的CoTs和自我评估输出来提炼更全面的思维，以确保更为彻底和健壮。

    arXiv:2311.09214v2 Announce Type: replace  Abstract: Large language models (LLMs) have achieved remarkable advancements in natural language processing. However, the massive scale and computational demands of these models present formidable challenges when considering their practical deployment in resource-constrained environments. While techniques such as chain-of-thought (CoT) distillation have displayed promise in distilling LLMs into small language models (SLMs), there is a risk that distilled SLMs may still inherit flawed reasoning and hallucinations from LLMs. To address these issues, we propose a twofold methodology: First, we introduce a novel method for distilling the self-evaluation capability from LLMs into SLMs, aiming to mitigate the adverse effects of flawed reasoning and hallucinations inherited from LLMs. Second, we advocate for distilling more comprehensive thinking by incorporating multiple distinct CoTs and self-evaluation outputs, to ensure a more thorough and robust
    
[^190]: 通用NER:一个金标准的多语言命名实体识别基准

    Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark

    [https://arxiv.org/abs/2311.09122](https://arxiv.org/abs/2311.09122)

    UNER是一个开放的、社区驱动的项目，旨在提供高质量、跨语言一致的命名实体识别基准，以促进和标准化多语言NER研究。

    

    我们介绍了通用NER（UNER），这是一个开放的，社区驱动的项目，旨在开发多种语言的金标准NER基准。UNER的总体目标是提供高质量、跨语言一致的标注，以促进和标准化多语言NER研究。UNER v1包含了在12种不同语言中使用跨语言一致模式标注的18个数据集。在本文中，我们详细介绍了UNER的数据集创建和组成；我们还提供了针对不同语言和跨语言学习设置的初始建模基线。我们向公众发布了数据、代码和拟合模型。

    arXiv:2311.09122v2 Announce Type: replace  Abstract: We introduce Universal NER (UNER), an open, community-driven project to develop gold-standard NER benchmarks in many languages. The overarching goal of UNER is to provide high-quality, cross-lingually consistent annotations to facilitate and standardize multilingual NER research. UNER v1 contains 18 datasets annotated with named entities in a cross-lingual consistent schema across 12 diverse languages. In this paper, we detail the dataset creation and composition of UNER; we also provide initial modeling baselines on both in-language and cross-lingual learning settings. We release the data, code, and fitted models to the public.
    
[^191]: OFA：一种用于初始化未见子词嵌入的框架，以实现高效大规模多语言持续预训练

    OFA: A Framework of Initializing Unseen Subword Embeddings for Efficient Large-scale Multilingual Continued Pretraining

    [https://arxiv.org/abs/2311.08849](https://arxiv.org/abs/2311.08849)

    OFA框架通过智能初始化未见子词的嵌入，结合外部多语言静态词向量和矩阵分解，有效实现多语言适应并大幅减少模型嵌入参数数量

    

    与从头开始预训练多语言语言模型不同，一种更高效的方法是通过词汇扩展和持续预训练来适应现有的预训练语言模型（PLMs）到新的语言。本文提出了一种新颖的框架：OFA（One For All），它聪明地初始化了未见子词的嵌入，从而可以高效有效地将PLM适应到多种语言。OFA利用外部对齐良好的多语言静态词向量，并将对齐知识注入到子词嵌入中。此外，OFA应用矩阵分解，并用两个低维矩阵替换繁琐的嵌入，大大减少了模型的嵌入参数数量。

    arXiv:2311.08849v2 Announce Type: replace  Abstract: Instead of pretraining multilingual language models from scratch, a more efficient method is to adapt existing pretrained language models (PLMs) to new languages via vocabulary extension and continued pretraining. However, this method usually randomly initializes the embeddings of new subwords and introduces substantially more embedding parameters to the model, thus weakening the efficiency. To address these issues, we propose a novel framework: $\textbf{O}$ne $\textbf{F}$or $\textbf{A}$ll ($\textbf{OFA}$), which wisely initializes the embeddings of unseen subwords and thus can adapt a PLM to multiple languages efficiently and effectively. OFA takes advantage of external well-aligned multilingual static word vectors and injects the alignment knowledge into the subword embeddings. In addition, OFA applies matrix factorization and replaces the cumbersome embeddings with two lower-dimensional matrices, which largely reduces the number o
    
[^192]: 大型语言模型中置信度估计与校准的调研

    A Survey of Confidence Estimation and Calibration in Large Language Models

    [https://arxiv.org/abs/2311.08298](https://arxiv.org/abs/2311.08298)

    大型语言模型中置信度估计与校准的调研总结了挑战、技术进展、应用和未来方向。

    

    大型语言模型（LLMs）在各个领域的各种任务中展现出卓越的性能，但由于生成中的事实错误，它们可能不可靠。评估它们的置信度并在不同任务中进行校准可以帮助减轻风险，使LLMs能够产生更好的生成结果。近期有许多研究致力于解决这个问题，但尚无全面的概述来组织并概述主要的经验教训，本调研旨在弥补这一空白。具体而言，我们概述了挑战，并总结了LLMs置信度估计和校准的最新技术进展。我们进一步讨论了它们的应用，并提出了未来工作的有希望的方向。

    arXiv:2311.08298v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks in various domains. Despite their impressive performance, they can be unreliable due to factual errors in their generations. Assessing their confidence and calibrating them across different tasks can help mitigate risks and enable LLMs to produce better generations. There has been a lot of recent research aiming to address this, but there has been no comprehensive overview to organize it and outline the main lessons learned. The present survey aims to bridge this gap. In particular, we outline the challenges and we summarize recent technical advancements for LLM confidence estimation and calibration. We further discuss their applications and suggest promising directions for future work.
    
[^193]: 大型语言模型在逻辑推理中的自我验证能力

    A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning

    [https://arxiv.org/abs/2311.07954](https://arxiv.org/abs/2311.07954)

    本文研究了大型语言模型在逻辑推理中的自我验证能力，特别关注它们准确识别逻辑谬误的能力。

    

    逻辑推理一直是人工智能领域的追求目标。尽管大型语言模型（LLMs）取得了显著进展，但它们仍然在复杂的逻辑推理问题上面临困难。为了增强推理性能，一个有希望的方向是可扩展的监督，这需要LLMs识别自己的错误，然后自行改进。为了实现这一目标，提出了各种自我验证方法。然而，现有模型是否很好地理解自己的错误仍在调查中。本文着重探讨了LLMs在逻辑推理背景下的自我验证能力，关注它们准确识别逻辑谬误的能力。我们引入了一个包含232种推理谬误的数据集FALLACIES，并进行了大量实验，从而获得了关于LLMs在FALLACIES上的全面和详细分析。

    arXiv:2311.07954v2 Announce Type: replace  Abstract: Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a se
    
[^194]: UrbanCLIP：学习来自网络的对比语言图像预训练文本增强的城市区域描述

    UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web

    [https://arxiv.org/abs/2310.18340](https://arxiv.org/abs/2310.18340)

    本文介绍了第一个将文本模态融入城市图像描述的LLM增强框架UrbanCLIP，并探讨了文本模态如何增强城市区域描述以及其影响方面。

    

    从网络数据进行的城市区域描述对城市规划和可持续发展至关重要。我们目睹了LLM在各个领域的不断崛起，尤其是处理多模态数据研究，如视觉-语言学习，其中文本模态作为图像的补充信息。本文旨在回答两个基本问题：i）文本模态能否增强城市区域描述？ii）如果可以，以何种方式和在哪些方面？为了回答这些问题，我们利用了大型语言模型（LLMs）的强大力量，并引入了第一个集成文本模态知识到城市图像描述中的LLM增强框架，命名为对比语言-图像预训练LLM增强型城市区域描述（UrbanCLIP）。

    arXiv:2310.18340v2 Announce Type: replace-cross  Abstract: Urban region profiling from web-sourced data is of utmost importance for urban planning and sustainable development. We are witnessing a rising trend of LLMs for various fields, especially dealing with multi-modal data research such as vision-language learning, where the text modality serves as a supplement information for the image. Since textual modality has never been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions in this paper: i) Can textual modality enhance urban region profiling? ii) and if so, in what ways and with regard to which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of textual modality into urban imagery profiling, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP). Specifically, it
    
[^195]: MuSR: 用多步软推理测试思维链的极限

    MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning

    [https://arxiv.org/abs/2310.16049](https://arxiv.org/abs/2310.16049)

    MuSR引入了一个用于评估语言模型在自然语言叙事中进行多步软推理任务的数据集，通过新颖的神经符号综合到自然语言生成算法创建复杂推理实例，挑战了目前的语言模型能力，并且可以随着模型能力的增强进行进一步扩展。

    

    虽然装备了诸如思维链提示等技术的大型语言模型(LLMs)展示出了令人印象深刻的能力，但它们在复杂环境中进行鲁棒推理的能力仍然有所欠缺。然而，评估LLM推理是具有挑战性的，因为系统能力不断增长，而用于逻辑推理等任务的基准数据集仍然保持不变。我们引入了MuSR，这是一个用于评估语言模型在自然语言叙事中执行多步软推理任务的数据集。该数据集具有两个关键特征。首先，它是通过一种新颖的神经符号综合到自然语言生成算法创建的，使得能够构建挑战GPT-4的复杂推理实例(例如，大约1000字长的谋杀悬疑故事)，并且随着发行更有能力的LLM，它可以进一步扩展。其次，我们的数据集实例是对应于真实领域的自由文本叙事。

    arXiv:2310.16049v2 Announce Type: replace  Abstract: While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings. However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static. We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative. This dataset has two crucial features. First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released. Second, our dataset instances are free text narratives corresponding to real-world domains
    
[^196]: HallusionBench：一种用于评估大型视觉语言模型中纠缠的语言幻觉和视幻觉的高级诊断套件

    HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models

    [https://arxiv.org/abs/2310.14566](https://arxiv.org/abs/2310.14566)

    HallusionBench是一个专为评估大型视觉语言模型在图像背景推理中面临挑战的基准，通过引入新颖结构和量化分析，显示出GPT-4V取得了31.42%的准确率，远高于其他模型。

    

    我们介绍了HallusionBench，这是一个专为评估图像背景推理而设计的全面基准。这个基准对于高级大型视觉语言模型（LVLMs）（如GPT-4V（Vision）、Gemini Pro Vision和LLaVA-1.5）提出了重大挑战，强调对视觉数据的微妙理解和解释。该基准包含346张图像和1129个问题，全部由人类专家精心设计。我们为这些视觉问题引入了一种新颖的结构，旨在建立对照组。这种结构使我们能够对模型的响应倾向、逻辑一致性和各种故障模式进行定量分析。在我们对HallusionBench的评估中，我们对14种不同模型进行了基准测试，突出了目前最先进的GPT-4V取得的31.42％的问题对准确率。值得注意的是，所有其他评估模型的准确率均低于16％。

    arXiv:2310.14566v3 Announce Type: replace-cross  Abstract: We introduce HallusionBench, a comprehensive benchmark designed for the evaluation of image-context reasoning. This benchmark presents significant challenges to advanced large visual-language models (LVLMs), such as GPT-4V(Vision), Gemini Pro Vision, and LLaVA-1.5, by emphasizing nuanced understanding and interpretation of visual data. The benchmark comprises 346 images paired with 1129 questions, all meticulously crafted by human experts. We introduce a novel structure for these visual questions designed to establish control groups. This structure enables us to conduct a quantitative analysis of the models' response tendencies, logical consistency, and various failure modes. In our evaluation on HallusionBench, we benchmarked 14 different models, highlighting a 31.42% question-pair accuracy achieved by the state-of-the-art GPT-4V. Notably, all other evaluated models achieve accuracy below 16%. Moreover, our analysis not only h
    
[^197]: RTSUM：基于关系三元组的可解释摘要与多级显著性可视化

    RTSUM: Relation Triple-based Interpretable Summarization with Multi-level Salience Visualization

    [https://arxiv.org/abs/2310.13895](https://arxiv.org/abs/2310.13895)

    提出了RTSUM框架，利用关系三元组进行摘要生成，并开发了一个可解释的摘要工具，支持多级显著性可视化。

    

    在本文中，我们提出了RTSUM，这是一种利用关系三元组作为摘要基本单元的无监督摘要框架。给定输入文档，RTSUM首先通过多级显著性评分选择显著的关系三元组，然后利用文本到文本语言模型从选定的关系三元组生成简洁摘要。在RTSUM的基础上，我们还开发了一个用于解释性摘要工具的网络演示，提供了对输出摘要的细粒度解释。通过支持自定义选项，我们的工具在三个不同级别上可视化文本单元的显著性：句子、关系三元组和短语。代码已公开可用。

    arXiv:2310.13895v2 Announce Type: replace  Abstract: In this paper, we present RTSUM, an unsupervised summarization framework that utilizes relation triples as the basic unit for summarization. Given an input document, RTSUM first selects salient relation triples via multi-level salience scoring and then generates a concise summary from the selected relation triples by using a text-to-text language model. On the basis of RTSUM, we also develop a web demo for an interpretable summarizing tool, providing fine-grained interpretations with the output summary. With support for customization options, our tool visualizes the salience for textual units at three distinct levels: sentences, relation triples, and phrases. The codes,are publicly available.
    
[^198]: 通过决策模型弥补新手与专家之间的差距：以纠正数学错误为案例研究

    Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes

    [https://arxiv.org/abs/2310.10648](https://arxiv.org/abs/2310.10648)

    通过使用决策模型Bridge，结合专家的认知任务分析，成功利用大型语言模型（LLMs）来弥补新手和专家在纠正数学错误中的知识差距。

    

    高质量辅导规模化仍然是教育中的一项主要挑战。由于需求增长，许多平台聘用新手导师，他们与经验丰富的教育工作者不同，难以解决学生的错误，因此无法抓住主要的学习机会。我们的工作探讨了大型语言模型（LLMs）在纠正数学错误中弥补新手和专家之间知识差距的潜力。我们提出Bridge，这是一种利用认知任务分析将专家的潜在思维过程转化为纠正模型的方法。这涉及专家识别(A)学生的错误、(B)纠正策略和(C)生成回应之前的意图。我们构建了一个包含700个真实辅导对话的数据集，由专家标注了他们的决策。我们在我们的数据集上评估了最先进的LLMs，并发现专家的决策模型对LLMs来说是至关重要的，以弥补这一差距：回应f

    arXiv:2310.10648v2 Announce Type: replace-cross  Abstract: Scaling high-quality tutoring remains a major challenge in education. Due to growing demand, many platforms employ novice tutors who, unlike experienced educators, struggle to address student mistakes and thus fail to seize prime learning opportunities. Our work explores the potential of large language models (LLMs) to close the novice-expert knowledge gap in remediating math mistakes. We contribute Bridge, a method that uses cognitive task analysis to translate an expert's latent thought process into a decision-making model for remediation. This involves an expert identifying (A) the student's error, (B) a remediation strategy, and (C) their intention before generating a response. We construct a dataset of 700 real tutoring conversations, annotated by experts with their decisions. We evaluate state-of-the-art LLMs on our dataset and find that the expert's decision-making model is critical for LLMs to close the gap: responses f
    
[^199]: 质量感知翻译模型：单一模型中的高效生成和质量评估

    Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model

    [https://arxiv.org/abs/2310.06707](https://arxiv.org/abs/2310.06707)

    提出了一种质量感知翻译模型，通过训练NMT模型来估计其输出质量，可以在解码过程中消除额外的计算成本。

    

    最大后验（MAP）解码是神经机器翻译（NMT）模型中最广泛使用的解码策略。 研究表明，模型概率与人类判断相关，但不能总是成立，生成质量可以通过解码来优化一个以度量或质量评估信号支持的效用函数来提高，即最小贝叶斯风险（MBR）或质量感知解码。 这些方法的主要缺点在于它们需要一个额外的模型在解码过程中计算效用函数，会显著增加计算成本。 本文提出通过训练NMT模型自己来估计其输出质量，从而使NMT模型本身具备质量感知能力。 使用这种方法进行MBR解码可以显著减小尺寸。

    arXiv:2310.06707v2 Announce Type: replace-cross  Abstract: Maximum-a-posteriori (MAP) decoding is the most widely used decoding strategy for neural machine translation (NMT) models. The underlying assumption is that model probability correlates well with human judgment, with better translations getting assigned a higher score by the model. However, research has shown that this assumption does not always hold, and generation quality can be improved by decoding to optimize a utility function backed by a metric or quality-estimation signal, as is done by Minimum Bayes Risk (MBR) or Quality-Aware decoding. The main disadvantage of these approaches is that they require an additional model to calculate the utility function during decoding, significantly increasing the computational cost. In this paper, we propose to make the NMT models themselves quality-aware by training them to estimate the quality of their own output. Using this approach for MBR decoding we can drastically reduce the size
    
[^200]: 从元学习视角看Transformer用于因果语言建模

    A Meta-Learning Perspective on Transformers for Causal Language Modeling

    [https://arxiv.org/abs/2310.05884](https://arxiv.org/abs/2310.05884)

    本文从元学习视角探讨了Transformer用于因果语言建模时的内部优化过程，发现并分析了Transformer-based因果语言模型中学习到的token表示范数的特殊特征。

    

    Transformer架构在开发大型因果语言模型方面变得显著。然而，解释其能力的机制尚不为人所了解。本文侧重于训练过程，建立了一个元学习视角来探究Transformer架构在因果语言建模任务训练时的内部优化过程，详细说明了Transformer内部的一个优化过程。此外，在这个内部优化过程中，我们发现并理论分析了Transformer-based因果语言模型中学习到的token表示的范数的特殊特征。我们的分析得到了各种设置中的实验证实支持。

    arXiv:2310.05884v2 Announce Type: replace-cross  Abstract: The Transformer architecture has become prominent in developing large causal language models. However, mechanisms to explain its capabilities are not well understood. Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal language modeling task, by explicating an inner optimization process within the Transformer. Further, within the inner optimization, we discover and theoretically analyze a special characteristic of the norms of learned token representations within Transformer-based causal language models. Our analysis is supported by experiments in various settings.
    
[^201]: 通过逻辑增强大型语言模型中的零射链推理能力

    Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic

    [https://arxiv.org/abs/2309.13339](https://arxiv.org/abs/2309.13339)

    提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。

    

    大型语言模型的最新进展展示了它们在各个领域的 remarkable generalizability。然而，它们的推理能力仍有很大的提升空间，特别是在需要多步推理的情况下。尽管大型语言模型具有广泛的知识，但它们的推理经常未能有效利用这些知识来建立连贯的思维范式。这些模型有时会出现幻觉，因为它们的推理过程未受逻辑原则的限制。为了改进大型语言模型的零射链推理能力，我们提出了 LoT（Logical Thoughts）提示，这是一个自我改进的框架，利用根植于符号逻辑的原则，特别是归谬法，逐步系统地验证和纠正推理过程。在语言任务上进行的实验评估

    arXiv:2309.13339v2 Announce Type: replace-cross  Abstract: Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their reasoning often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. These models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming at improving the zero-shot chain-of-thought reasoning ability of large language models, we propose LoT (Logical Thoughts) prompting, a self-improvement framework that leverages principles rooted in symbolic logic, particularly Reductio ad Absurdum, to systematically verify and rectify the reasoning processes step by step. Experimental evaluations conducted on language tasks in
    
[^202]: 拥抱多样性以获得更丰富的洞见：一项多文档总结基准研究及在新闻文章中总结多样信息的案例研究

    Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles

    [https://arxiv.org/abs/2309.09369](https://arxiv.org/abs/2309.09369)

    本文提出了一个新任务，即总结在多篇新闻文章中遇到的多样信息，涵盖了相同事件，构建了一个名为DiverseSumm的数据集，并对使用大型语言模型（LLM）衡量摘要覆盖范围和忠实度的方法进行了全面分析。

    

    先前的多文档新闻总结研究通常集中在整理所有信息源都同意的信息上。然而，对于分散在多篇关于同一事件的文章中的多样信息的总结仍未得到充分探讨。本文提出了一个新任务，即总结在多篇新闻文章中遇到的多样信息，涵盖了相同事件。为了促进这一任务，我们提出了一个用于识别多样信息的数据收集架构，并策划了一个名为DiverseSumm的数据集。数据集包括245篇新闻报道，每篇报道包含10篇新闻文章，并配有经人工验证的参考文本。接下来，为了启用一致的自动评估，我们进行了全面分析，以确定在利用大型语言模型（LLM）度量评估摘要的覆盖范围和忠实度时的位置和冗长偏差。通过相关性分析，我们o

    arXiv:2309.09369v2 Announce Type: replace  Abstract: Previous research in multi-document news summarization has typically concentrated on collating information that all sources agree upon. However, the summarization of diverse information dispersed across multiple articles about an event remains underexplored. In this paper, we propose a new task of summarizing diverse information encountered in multiple news articles encompassing the same event. To facilitate this task, we outlined a data collection schema for identifying diverse information and curated a dataset named DiverseSumm. The dataset includes 245 news stories, with each story comprising 10 news articles and paired with a human-validated reference. Next, to enable consistent automatic evaluation, we conducted a comprehensive analysis to pinpoint the position and verbosity biases when utilizing Large Language Model (LLM)-based metrics for evaluating the coverage and faithfulness of summaries. Through correlation analyses, we o
    
[^203]: 大型语言模型用于生成式推荐：一项调查和远见讨论

    Large Language Models for Generative Recommendation: A Survey and Visionary Discussions

    [https://arxiv.org/abs/2309.01157](https://arxiv.org/abs/2309.01157)

    大型语言模型为推荐系统的生成式推荐提供了新机遇，可以简化推荐流程并直接从完整的项目池中生成推荐。

    

    大型语言模型（LLM）不仅彻底改变了自然语言处理（NLP）领域，还有潜力重塑许多其他领域，例如推荐系统（RS）。本文调查了基于LLM的生成式推荐的进展、方法和未来方向，着眼于三个问题：1）生成式推荐是什么，2）为什么RS应该发展到生成式推荐，3）如何为各种RS实现基于LLM的生成推荐。

    arXiv:2309.01157v2 Announce Type: replace-cross  Abstract: Large language models (LLM) not only have revolutionized the field of natural language processing (NLP) but also have the potential to reshape many other fields, e.g., recommender systems (RS). However, most of the related work treats an LLM as a component of the conventional recommendation pipeline (e.g., as a feature extractor), which may not be able to fully leverage the generative power of LLM. Instead of separating the recommendation process into multiple stages, such as score computation and re-ranking, this process can be simplified to one stage with LLM: directly generating recommendations from the complete pool of items. This survey reviews the progress, methods, and future directions of LLM-based generative recommendation by examining three questions: 1) What generative recommendation is, 2) Why RS should advance to generative recommendation, and 3) How to implement LLM-based generative recommendation for various RS t
    
[^204]: 坐标自然语言解释

    Situated Natural Language Explanations

    [https://arxiv.org/abs/2308.14115](https://arxiv.org/abs/2308.14115)

    提出了一种坐标自然语言解释的替代性视角，通过建立自动化评估分数和采用三种提示工程技术，为生成和评估解释提供了新的研究途径。

    

    自然语言是向人类解释决策最易理解的工具之一，而大型预训练语言模型（PLMs）已经展示出生成连贯的自然语言解释（NLE）的能力。现有的NLE研究观点没有考虑受众的因素。一个NLE可以具有高质量的文本，但可能不符合受众的需求和喜好。为了解决这一局限性，我们提出了一个替代性视角，即\textit{坐标}NLE。在评估方面，我们建立了自动化评估分数。这些分数描述了NLE在词汇、语义和语用类别上的属性。在生成方面，我们确定了三种提示工程技术，并评估它们在各种情况下的适用性。坐标NLE提供了一种视角，促进了关于解释生成和评估的进一步研究。

    arXiv:2308.14115v2 Announce Type: replace  Abstract: Natural language is among the most accessible tools for explaining decisions to humans, and large pretrained language models (PLMs) have demonstrated impressive abilities to generate coherent natural language explanations (NLE). The existing NLE research perspectives do not take the audience into account. An NLE can have high textual quality, but it might not accommodate audiences' needs and preference. To address this limitation, we propose an alternative perspective, \textit{situated} NLE. On the evaluation side, we set up automated evaluation scores. These scores describe the properties of NLEs in lexical, semantic, and pragmatic categories. On the generation side, we identify three prompt engineering techniques and assess their applicability on the situations. Situated NLE provides a perspective and facilitates further research on the generation and evaluation of explanations.
    
[^205]: 欺骗LLMs让其不遵从：正式化、分析和检测越狱行为

    Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting Jailbreaks

    [https://arxiv.org/abs/2305.14965](https://arxiv.org/abs/2305.14965)

    该论文提出了正式化和已知越狱分类法以填补对商用大规模语言模型（LLMs）被越狱攻击的缺乏研究，调查现有的越狱方法及其在开源和商用LLMs上的有效性。

    

    最近对商用大规模语言模型（LLMs）的探索表明，非专家用户可以通过简单操纵他们的提示来越狱LLMs；导致退化的输出行为、隐私与安全漏洞、冒犯性输出以及违反内容监管政策。有限的研究已进行了对这些攻击及其缓解措施的正式化和分析。我们通过提出一个形式化描述和已知（及可能的）越狱分类法来填补这一差距。我们调查现有的越狱方法及其在开源和商用LLMs（如基于GPT的模型、OPT、BLOOM和FLAN-T5-XXL）上的有效性。我们进一步讨论了越狱检测在针对已知攻击方面的挑战。为了我们的分析，我们收集了4项任务的3700个越狱提示的数据集。我们将随着模型输出一起公开这一数据集。

    arXiv:2305.14965v2 Announce Type: replace  Abstract: Recent explorations with commercial Large Language Models (LLMs) have shown that non-expert users can jailbreak LLMs by simply manipulating their prompts; resulting in degenerate output behavior, privacy and security breaches, offensive outputs, and violations of content regulator policies. Limited studies have been conducted to formalize and analyze these attacks and their mitigations. We bridge this gap by proposing a formalism and a taxonomy of known (and possible) jailbreaks. We survey existing jailbreak methods and their effectiveness on open-source and commercial LLMs (such as GPT-based models, OPT, BLOOM, and FLAN-T5-XXL). We further discuss the challenges of jailbreak detection in terms of their effectiveness against known attacks. For our analysis, we collect a dataset of 3700 jailbreak prompts across 4 tasks. We will make the dataset public along with the model outputs.
    
[^206]: 在文化意识上基于LLM的机器翻译基准测试

    Benchmarking LLM-based Machine Translation on Cultural Awareness

    [https://arxiv.org/abs/2305.14328](https://arxiv.org/abs/2305.14328)

    介绍了一个新的数据整理流程来构建文化相关的平行语料库，并设计了一种新的评估指标，通过GPT-4无参考评估翻译的可理解性。

    

    翻译文化特定内容对于有效的跨文化沟通至关重要。然而，许多机器翻译系统仍然难以准确理解和翻译包含文化特定实体的句子。最近关于上下文学习的进展利用轻量级提示指导大型语言模型(LLMs)在机器翻译任务中。然而，这种方法在提高具有文化意识的机器翻译的有效性方面仍然存在不确定性。为了填补这一空白，我们引入了一个新的数据整理流程，构建了一个包含文化相关并丰富了文化特定项目注释的平行语料库。此外，我们设计了一种新颖的评估指标，通过GPT-4以无参考方式评估翻译的可理解性。我们使用我们的数据集评估了各种神经机器翻译(NMT)和LLM-based MT系统。此外，我们提出了几种提示策略。

    arXiv:2305.14328v2 Announce Type: replace  Abstract: Translating cultural-specific content is crucial for effective cross-cultural communication. However, many MT systems still struggle to translate sentences containing cultural-specific entities accurately and understandably. Recent advancements in in-context learning utilize lightweight prompts to guide large language models (LLMs) in machine translation tasks. Nevertheless, the effectiveness of this approach in enhancing machine translation with cultural awareness remains uncertain. To address this gap, we introduce a new data curation pipeline to construct a culturally relevant parallel corpus, enriched with annotations of cultural-specific items. Furthermore, we devise a novel evaluation metric to assess the understandability of translations in a reference-free manner by GPT-4. We evaluate a variety of neural machine translation (NMT) and LLM-based MT systems using our dataset. Additionally, we propose several prompting strategies
    
[^207]: 当你的表亲有正确的连接：非监督双语词表诱导用于相关数据不平衡的语言

    When your Cousin has the Right Connections: Unsupervised Bilingual Lexicon Induction for Related Data-Imbalanced Languages

    [https://arxiv.org/abs/2305.14012](https://arxiv.org/abs/2305.14012)

    提出了一种新的非监督双语词表诱导方法，可以在相关低资源语言和高资源语言之间进行词表诱导，只需要对高资源语言的掩码语言模型进行推断。

    

    大多数现有的非监督双语词表诱导（BLI）方法依赖于需要大型单语语料库的良好质量的静态或上下文嵌入。然而，非监督BLI最有可能对低资源语言（LRLs）有用，对于这些语言，大型数据集是不可用的。我们经常对建立LRLs与相关高资源语言（HRLs）之间的双语资源感兴趣，结果造成BLI的数据设置出现严重不平衡。我们首先展示了文献中现有的最先进的BLI方法对严重数据不平衡的语言对表现接近零的性能，这表明这些设置需要更强大的技术。然后我们提出了一种新的方法，用于在相关的LRL和HRL之间进行无监督的BLI，该方法只需要对HRL的掩码语言模型进行推断，并展示了对Bhojpuri和Magahi这两种真正低资源语言的有效性（单语语料小于5M）。

    arXiv:2305.14012v2 Announce Type: replace  Abstract: Most existing approaches for unsupervised bilingual lexicon induction (BLI) depend on good quality static or contextual embeddings requiring large monolingual corpora for both languages. However, unsupervised BLI is most likely to be useful for low-resource languages (LRLs), where large datasets are not available. Often we are interested in building bilingual resources for LRLs against related high-resource languages (HRLs), resulting in severely imbalanced data settings for BLI. We first show that state-of-the-art BLI methods in the literature exhibit near-zero performance for severely data-imbalanced language pairs, indicating that these settings require more robust techniques. We then present a new method for unsupervised BLI between a related LRL and HRL that only requires inference on a masked language model of the HRL, and demonstrate its effectiveness on truly low-resource languages Bhojpuri and Magahi (with <5M monolingual to
    
[^208]: LLM亲子鉴定：LLM遗传继承中的生成文本检测

    LLM Paternity Test: Generated Text Detection with LLM Genetic Inheritance

    [https://arxiv.org/abs/2305.12519](https://arxiv.org/abs/2305.12519)

    LLM-Pat提出了一种基于模型的生成文本检测方法，通过重建并比较候选文本与其对应的“兄弟”文本的相似性，从而判断候选文本是否由机器生成。

    

    大语言模型（LLMs）可以生成携带各种滥用风险的文本，包括抄袭、在电子商务平台上发布虚假评论，或者制作引人注目的虚假推文。因此，检测文本是否由机器生成变得越来越重要。虽然现有的检测方法表现出色，但由于严重依赖训练数据，它们往往缺乏泛化能力。为缓解这一问题，我们提出了一种与模型相关的生成文本检测方法，即LLM亲子鉴定（LLM-Pat）。具体而言，给定任何候选文本（"子类"），LLM-Pat使用一个中间LLM（"父类"）重建与给定文本对应的"兄弟"文本，然后衡量候选文本与其"兄弟"文本之间的相似性。高相似性表明候选文本是由机器生成，类似于基因特征。我们已构建了数据集...

    arXiv:2305.12519v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) can generate texts that carry the risk of various misuses, including plagiarism, planting fake reviews on e-commerce platforms, or creating inflammatory false tweets. Detecting whether a text is machine-generated has thus become increasingly important. While existing detection methods exhibit superior performance, they often lack generalizability due to their heavy dependence on training data. To alleviate this problem, we propose a model-related generated text detection method, the LLM Paternity Test (LLM-Pat). Specifically, given any candidate text (\textit{child}), LLM-Pat employs an intermediary LLM (\textit{parent}) to reconstruct a \textit{sibling} text corresponding to the given text and then measures the similarity between candidate texts and their sibling texts. High similarity indicates that the candidate text is machine-generated, akin to genetic traits. We have constructed datasets encom
    
[^209]: Spacerini：使用Pyserini和Hugging Face实现即插即用的搜索引擎

    Spacerini: Plug-and-play Search Engines with Pyserini and Hugging Face

    [https://arxiv.org/abs/2302.14534](https://arxiv.org/abs/2302.14534)

    Spacerini是一个集成了Pyserini和Hugging Face的工具，可以无缝构建和部署交互式搜索引擎，使得非IR从业者可以更轻松地使用最先进的检索模型，对NLP和IR研究人员以及第三方复制研究工作都非常有用。

    

    我们提出了Spacerini，这是一个集成了Pyserini工具包和Hugging Face的工具，可以无缝构建和部署交互式搜索引擎的工具。通过Spacerini，非IR从业者可以更轻松地使用最先进的稀疏和稠密检索模型，并最小化部署工作量。Spacerini对于希望通过对训练语料库进行定性分析来更好地理解和验证研究的NLP研究人员、希望在不断发展的Pyserini生态系统中展示新检索模型的IR研究人员以及复制其他研究人员工作的第三方来说都非常有用。Spacerini是开源的，并包括用于本地和远程加载、预处理、索引和部署搜索引擎的实用程序。我们展示了使用Spacerini创建的13个不同用例的搜索引擎组合。

    arXiv:2302.14534v2 Announce Type: replace-cross  Abstract: We present Spacerini, a tool that integrates the Pyserini toolkit for reproducible information retrieval research with Hugging Face to enable the seamless construction and deployment of interactive search engines. Spacerini makes state-of-the-art sparse and dense retrieval models more accessible to non-IR practitioners while minimizing deployment effort. This is useful for NLP researchers who want to better understand and validate their research by performing qualitative analyses of training corpora, for IR researchers who want to demonstrate new retrieval models integrated into the growing Pyserini ecosystem, and for third parties reproducing the work of other researchers. Spacerini is open source and includes utilities for loading, preprocessing, indexing, and deploying search engines locally and remotely. We demonstrate a portfolio of 13 search engines created with Spacerini for different use cases.
    
[^210]: 具有概念感知注意力的知识增强图神经网络用于不良药物事件检测

    Knowledge-augmented Graph Neural Networks with Concept-aware Attention for Adverse Drug Event Detection

    [https://arxiv.org/abs/2301.10451](https://arxiv.org/abs/2301.10451)

    本研究提出了一种具有概念感知注意力的知识增强图神经网络，用于不良药物事件检测，通过将医学知识和文本图相结合，实现了不同类型节点的特征学习。

    

    不良药物事件（ADEs）是药物安全的重要方面。各种文本，如生物医学文献、药物评论、社交媒体和医疗论坛上的用户帖子，包含大量关于ADEs的信息。近期的研究应用了基于词嵌入和深度学习的自然语言处理技术来自动化从文本中检测ADEs。然而，它们未探讨如何将药物和不良反应的显式医学知识或相应的特征学习纳入到其中。本文采用描述文档、单词和概念之间关系的异质文本图，并通过统一医学语言系统中的医学知识增强它，提出了一个概念感知注意力机制，该机制为图中不同类型的节点不同地学习特征。我们还利用了预训练语言模型的上下文化嵌入和卷积图神经网络，以进行有效的特征学习。

    arXiv:2301.10451v2 Announce Type: replace  Abstract: Adverse drug events (ADEs) are an important aspect of drug safety. Various texts such as biomedical literature, drug reviews, and user posts on social media and medical forums contain a wealth of information about ADEs. Recent studies have applied word embedding and deep learning -based natural language processing to automate ADE detection from text. However, they did not explore incorporating explicit medical knowledge about drugs and adverse reactions or the corresponding feature learning. This paper adopts the heterogenous text graph which describes relationships between documents, words and concepts, augments it with medical knowledge from the Unified Medical Language System, and proposes a concept-aware attention mechanism which learns features differently for the different types of nodes in the graph. We further utilize contextualized embeddings from pretrained language models and convolutional graph neural networks for effecti
    
[^211]: 在大语言模型中区分语言和思维

    Dissociating language and thought in large language models

    [https://arxiv.org/abs/2301.06627](https://arxiv.org/abs/2301.06627)

    大型语言模型在形式语言能力方面表现出色，但在功能语言能力任务上表现不稳定，可能需要专门的调整和外部模块的支持。

    

    大型语言模型（LLMs）迄今为止在掌握人类语言方面做得最好，然而人们对它们的语言和认知能力仍存在分歧。本文使用形式语言能力（对语言规则和模式的了解）与功能语言能力（理解和使用语言在世界中的方式）的区别来评估LLMs。我们通过人类神经科学来确立这一区别，人类神经科学显示形式和功能能力依赖于不同的神经机制。尽管LLMs在形式能力方面表现出人们的惊人水平，但它们在功能能力任务上的表现仍然不稳定，并且通常需要专门的精细调整和/或与外部模块的耦合。我们认为，那些以类似人类方式使用语言的模型将需要掌握这两种能力类型，而这反过来可能需要为形式语言能力专门化的机制的出现。

    arXiv:2301.06627v3 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have come closest among all models to date to mastering human language, yet opinions about their linguistic and cognitive capabilities remain split. Here, we evaluate LLMs using a distinction between formal linguistic competence - knowledge of linguistic rules and patterns - and functional linguistic competence - understanding and using language in the world. We ground this distinction in human neuroscience, which has shown that formal and functional competence rely on different neural mechanisms. Although LLMs are surprisingly good at formal competence, their performance on functional competence tasks remains spotty and often requires specialized fine-tuning and/or coupling with external modules. We posit that models that use language in human-like ways would need to master both of these competence types, which, in turn, could require the emergence of mechanisms specialized for formal linguistic co
    
[^212]: 使用银标准数据进行零-shot关系提取的学习

    Learning with Silver Standard Data for Zero-shot Relation Extraction

    [https://arxiv.org/abs/2211.13883](https://arxiv.org/abs/2211.13883)

    提出了使用银标准数据进行零-shot关系提取学习的方法，并引入了一个基于类别的清洁数据检测模块。

    

    监督关系提取（RE）方法的优越性能严重依赖于大量的黄金标准数据。最近零-shot关系提取方法将RE任务转化为其他NLP任务，并使用这些NLP任务的现成模型直接在测试数据上执行推理，而无需使用大量RE注释数据。这些方法的一个潜在有价值的副产品是大规模的银标准数据。然而，目前没有进一步研究如何使用这些潜在有价值的银标准数据。本文提出首先从银标准数据中检测到少量清洁数据，然后使用选定的清洁数据对预训练模型进行微调。然后使用微调后的模型推断关系类型。我们还提出了一个基于类别的清洁数据检测模块，在选择清洁数据时考虑类别信息。实验结果表明，我们的方法可以击败

    arXiv:2211.13883v2 Announce Type: replace  Abstract: The superior performance of supervised relation extraction (RE) methods heavily relies on a large amount of gold standard data. Recent zero-shot relation extraction methods converted the RE task to other NLP tasks and used off-the-shelf models of these NLP tasks to directly perform inference on the test data without using a large amount of RE annotation data. A potentially valuable by-product of these methods is the large-scale silver standard data. However, there is no further investigation on the use of potentially valuable silver standard data. In this paper, we propose to first detect a small amount of clean data from silver standard data and then use the selected clean data to finetune the pretrained model. We then use the finetuned model to infer relation types. We also propose a class-aware clean data detection module to consider class information when selecting clean data. The experimental results show that our method can out
    
[^213]: 一种贝叶斯多语言文档模型用于零样本主题识别与发现

    A Bayesian Multilingual Document Model for Zero-shot Topic Identification and Discovery

    [https://arxiv.org/abs/2007.01359](https://arxiv.org/abs/2007.01359)

    提出了一种贝叶斯多语言文档模型，通过学习文档嵌入的高斯分布形式来编码不确定性，利用学到的不确定性进行零样本跨语言主题识别，在17种不同语言上进行了实验证实该模型在不同资源语言上表现出色

    

    在本文中，我们提出了一种用于学习与语言无关的文档嵌入的贝叶斯多语言文档模型。该模型是BaySMM[Kesiraju et al 2020]在多语言场景中的扩展。它学习以高斯分布的形式表示文档嵌入，从而编码协方差中的不确定性。我们通过线性分类器传播学到的不确定性，从而有利于零样本跨语言主题识别。我们在17种语言上进行的实验表明，所提出的多语言贝叶斯文档模型在与基于大规模神经网络的其他系统（如LASER、XLM-R、mUSE）相比，对8种高资源语言表现竞争力强，并在9种中资源语言上表现优越。我们通过更深入地研究当前数据集、基准系统和涵盖的语言，重新审视了零样本设定中的跨语言主题识别。我们指出了其中的缺陷。

    arXiv:2007.01359v3 Announce Type: replace  Abstract: In this paper, we present a Bayesian multilingual document model for learning language-independent document embeddings. The model is an extension of BaySMM [Kesiraju et al 2020] to the multilingual scenario. It learns to represent the document embeddings in the form of Gaussian distributions, thereby encoding the uncertainty in its covariance. We propagate the learned uncertainties through linear classifiers that benefit zero-shot cross-lingual topic identification. Our experiments on 17 languages show that the proposed multilingual Bayesian document model performs competitively, when compared to other systems based on large-scale neural networks (LASER, XLM-R, mUSE) on 8 high-resource languages, and outperforms these systems on 9 mid-resource languages. We revisit cross-lingual topic identification in zero-shot settings by taking a deeper dive into current datasets, baseline systems and the languages covered. We identify shortcoming
    
[^214]: 通过检索示范进行上下文学习的语言模型：一项综述

    In-context Learning with Retrieved Demonstrations for Language Models: A Survey. (arXiv:2401.11624v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.11624](http://arxiv.org/abs/2401.11624)

    本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。

    

    语言模型，特别是预训练的大型语言模型，已展示出卓越的能力，可以在输入上下文中进行少量样本的情境学习（ICL），并在新任务上具有适应能力。然而，模型的ICL能力对于少样本示范的选择是敏感的。最近的一项研究进展是检索针对每个输入查询定制的示范。示范检索的实现相对简单，利用现有的数据库和检索系统。这不仅提高了学习过程的效率和可扩展性，而且已经证明可以减少手动示例选择中的偏见。鉴于令人鼓舞的结果和在检索示范的ICL方面不断增长的研究，我们进行了广泛的研究综述。在这项综述中，我们讨论和比较了检索模型的不同设计选择，检索训练

    Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query. The implementation of demonstration retrieval is relatively straightforward, leveraging existing databases and retrieval systems. This not only improves the efficiency and scalability of the learning process but also has been shown to reduce biases inherent in manual example selection. In light of the encouraging results and growing research in ICL with retrieved demonstrations, we conduct an extensive review of studies in this area. In this survey, we discuss and compare different design choices for retrieval models, retrieval training p
    
[^215]: 播风撩起风暴：编辑语言模型的影响

    Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models. (arXiv:2401.10647v1 [cs.CL])

    [http://arxiv.org/abs/2401.10647](http://arxiv.org/abs/2401.10647)

    本文研究了通过编辑语言模型的复杂后果，发现在增强模型准确性与保持道德完整性之间存在悖论。我们发现，尽管注入准确信息对模型的可靠性很重要，但它可能破坏模型的基本框架，导致不可预测和潜在的不安全行为。

    

    在人工智能领域中，红队测试或越狱大型语言模型（LLM）的概念已成为一个重要的研究领域。通过对模型进行编辑，揭示了这种修改的复杂后果，发现了增强模型准确性与保持其道德完整性之间的复杂关系。我们的深入分析揭示了一个令人惊讶的悖论：虽然注入准确信息对于模型的可靠性至关重要，但它却可能破坏模型的基本框架，导致不可预测和潜在的不安全行为。此外，我们提出了一个基准数据集NicheHazardQA，用于研究模型在相同和跨领域中的不安全行为。这一方面的研究揭示了编辑如何影响模型的安全度量和保护机制。

    In the rapidly advancing field of artificial intelligence, the concept of Red-Teaming or Jailbreaking large language models (LLMs) has emerged as a crucial area of study. This approach is especially significant in terms of assessing and enhancing the safety and robustness of these models. This paper investigates the intricate consequences of such modifications through model editing, uncovering a complex relationship between enhancing model accuracy and preserving its ethical integrity. Our in-depth analysis reveals a striking paradox: while injecting accurate information is crucial for model reliability, it can paradoxically destabilize the model's foundational framework, resulting in unpredictable and potentially unsafe behaviors. Additionally, we propose a benchmark dataset NicheHazardQA to investigate this unsafe behavior both within the same and cross topical domain. This aspect of our research sheds light on how the edits, impact the model's safety metrics and guardrails. Our find
    
[^216]: 代码之间的界限：揭示机器和人类程序员之间不同的模式

    Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers. (arXiv:2401.06461v1 [cs.SE])

    [http://arxiv.org/abs/2401.06461](http://arxiv.org/abs/2401.06461)

    本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。

    

    大型语言模型在代码生成方面取得了显著的进展，但它们模糊了机器和人类源代码之间的区别，导致软件产物的完整性和真实性问题。本文通过对代码长度、词汇多样性和自然性等属性的严格分析，揭示了机器和人类代码固有的独特模式。在我们的研究中特别注意到，代码的结构分割是识别其来源的关键因素。基于我们的发现，我们提出了一种名为DetectCodeGPT的新型机器生成代码检测方法，该方法改进了DetectGPT。

    Large language models have catalyzed an unprecedented wave in code generation. While achieving significant advances, they blur the distinctions between machine-and human-authored source code, causing integrity and authenticity issues of software artifacts. Previous methods such as DetectGPT have proven effective in discerning machine-generated texts, but they do not identify and harness the unique patterns of machine-generated code. Thus, its applicability falters when applied to code. In this paper, we carefully study the specific patterns that characterize machine and human-authored code. Through a rigorous analysis of code attributes such as length, lexical diversity, and naturalness, we expose unique pat-terns inherent to each source. We particularly notice that the structural segmentation of code is a critical factor in identifying its provenance. Based on our findings, we propose a novel machine-generated code detection method called DetectCodeGPT, which improves DetectGPT by cap
    
[^217]: 视觉和语言编码器是否以相似方式表示世界？

    Do Vision and Language Encoders Represent the World Similarly?. (arXiv:2401.05224v1 [cs.CV])

    [http://arxiv.org/abs/2401.05224](http://arxiv.org/abs/2401.05224)

    通过分析视觉和语言模型的潜在空间结构，发现未对齐和对齐的编码器的表示空间在语义上是相似的。我们提出了两种方法来匹配未对齐编码器，无需训练即可实现匹配。

    

    已经成为视觉语言任务中事实上的模型的对齐的文本-图像编码器（如CLIP）已经取得了令人印象深刻的表现。此外，模态特定的编码器在各自领域中也取得了令人印象深刻的表现。这引出了一个核心问题：由于它们基本上表示同一个物理世界，单模态的视觉和语言编码器之间是否存在对齐？通过使用中心核对齐（CKA）分析图像-标题基准上视觉和语言模型的潜在空间结构，我们发现未对齐和对齐的编码器的表示空间在语义上是相似的。在像CLIP这样的对齐编码器中缺乏统计相似性的情况下，我们显示了可能存在无需任何训练的未对齐编码器的匹配。我们将这视为利用图之间的语义相似性的有种子图匹配问题，并提出了两种方法 - 快速二次分配问题优化和一种基于新颖的局部CKA度量的匹配/检索方法。

    Aligned text-image encoders such as CLIP have become the de facto model for vision-language tasks. Furthermore, modality-specific encoders achieve impressive performances in their respective domains. This raises a central question: does an alignment exist between uni-modal vision and language encoders since they fundamentally represent the same physical world? Analyzing the latent spaces structure of vision and language models on image-caption benchmarks using the Centered Kernel Alignment (CKA), we find that the representation spaces of unaligned and aligned encoders are semantically similar. In the absence of statistical similarity in aligned encoders like CLIP, we show that a possible matching of unaligned encoders exists without any training. We frame this as a seeded graph-matching problem exploiting the semantic similarity between graphs and propose two methods - a Fast Quadratic Assignment Problem optimization, and a novel localized CKA metric-based matching/retrieval. We demons
    
[^218]: VQPy：一种面向现代视频分析的面向对象方法。

    VQPy: An Object-Oriented Approach to Modern Video Analytics. (arXiv:2311.01623v1 [cs.CV])

    [http://arxiv.org/abs/2311.01623](http://arxiv.org/abs/2311.01623)

    VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。

    

    视频分析广泛应用于当今系统和服务中。在视频分析的前沿是用户开发的视频查询，以找到特定感兴趣的对象。基于视频对象（例如人，动物，汽车等）与传统面向对象语言建模的对象相似的洞察力，我们提出了一种面向视频分析的面向对象方法。这种方法名为VQPy，包括一个前端（一种Python变体，其中包含用户可以表达视频对象及其交互的结构）和一个可扩展的后端，可以基于视频对象自动生成和优化管道。我们已经实施和开源了VQPy，它已经作为Cisco DeepVision框架的一部分产品化。

    Video analytics is widely used in contemporary systems and services. At the forefront of video analytics are video queries that users develop to find objects of particular interest. Building upon the insight that video objects (e.g., human, animals, cars, etc.), the center of video analytics, are similar in spirit to objects modeled by traditional object-oriented languages, we propose to develop an object-oriented approach to video analytics. This approach, named VQPy, consists of a frontend$\unicode{x2015}$a Python variant with constructs that make it easy for users to express video objects and their interactions$\unicode{x2015}$as well as an extensible backend that can automatically construct and optimize pipelines based on video objects. We have implemented and open-sourced VQPy, which has been productized in Cisco as part of its DeepVision framework.
    
[^219]: CLEX: 大型语言模型的持续长度外推

    CLEX: Continuous Length Extrapolation for Large Language Models. (arXiv:2310.16450v1 [cs.CL])

    [http://arxiv.org/abs/2310.16450](http://arxiv.org/abs/2310.16450)

    CLEX是一种针对大型语言模型的持续长度外推方法，通过将位置嵌入缩放方法推广到连续动态建模，克服了当前方法在特定长度上的局限性。

    

    基于Transformer的大型语言模型（LLM）在许多自然语言处理任务中取得了突破性进展，然而，它们的卓越能力受限于Transformer的预设上下文窗口。位置嵌入（PE）缩放方法虽然能够将上下文窗口扩展到特定长度，但在外推能力方面存在明显的局限性，或者在上下文窗口内牺牲部分性能。虽然长度外推方法在理论上能够将上下文窗口延长至训练序列长度之外，但在实际的长上下文应用中表现不佳。为解决这些挑战，我们提出了适用于LLMs的持续长度外推（CLEX）方法。我们将PE缩放方法推广到通过常微分方程对长度缩放因子建模，从而克服了当前为特定长度设计的PE缩放方法的限制。

    Transformer-based Large Language Models (LLMs) are pioneering advances in many natural language processing tasks, however, their exceptional capabilities are restricted within the preset context window of Transformer. Position Embedding (PE) scaling methods, while effective in extending the context window to a specific length, demonstrate either notable limitations in their extrapolation abilities or sacrificing partial performance within the context window. Length extrapolation methods, although theoretically capable of extending the context window beyond the training sequence length, often underperform in practical long-context applications. To address these challenges, we propose Continuous Length EXtrapolation (CLEX) for LLMs. We generalise the PE scaling approaches to model the continuous dynamics by ordinary differential equations over the length scaling factor, thereby overcoming the constraints of current PE scaling methods designed for specific lengths. Moreover, by extending 
    
[^220]: SOTOPIA: 交互式评估语言智能中的社交智能

    SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents. (arXiv:2310.11667v1 [cs.AI])

    [http://arxiv.org/abs/2310.11667](http://arxiv.org/abs/2310.11667)

    SOTOPIA是一个用于评估语言智能中的社交智能的交互式环境。通过模拟复杂的社交互动，并使用全面的评估框架，我们发现不同模型之间的社交智能存在显著差异，特别是在SOTOPIA-hard情景下。GPT-4在这个子集上的目标完成率较低。

    

    人类是社交的存在；我们在日常互动中追求社交目标，这是社交智能的关键方面。然而，人工智能系统在这个领域的能力仍然难以捉摸。我们提出了SOTOPIA，一个开放式环境，用于模拟人工智能代理之间的复杂社交互动并评估它们的社交智能。在我们的环境中，代理人扮演角色，在各种场景下相互协作、合作、交流和竞争，以实现复杂的社交目标。我们模拟了LLM-based代理人与人类之间在这个任务空间内的角色扮演互动，并使用一个名为SOTOPIA-Eval的整体评估框架对它们的表现进行评估。通过SOTOPIA，我们发现这些模型在社交智能方面存在显著差异，并确定了SOTOPIA的一个子集，即SOTOPIA-hard，对所有模型来说都具有挑战性。我们发现在这个子集上，GPT-4的目标完成率显著较低。

    Humans are social beings; we pursue social goals in our daily interactions, which is a crucial aspect of social intelligence. Yet, AI systems' abilities in this realm remain elusive. We present SOTOPIA, an open-ended environment to simulate complex social interactions between artificial agents and evaluate their social intelligence. In our environment, agents role-play and interact under a wide variety of scenarios; they coordinate, collaborate, exchange, and compete with each other to achieve complex social goals. We simulate the role-play interaction between LLM-based agents and humans within this task space and evaluate their performance with a holistic evaluation framework called SOTOPIA-Eval. With SOTOPIA, we find significant differences between these models in terms of their social intelligence, and we identify a subset of SOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models. We find that on this subset, GPT-4 achieves a significantly lower goal completio
    
[^221]: KGQuiz: 评估大型语言模型中编码知识的泛化能力

    KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models. (arXiv:2310.09725v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.09725](http://arxiv.org/abs/2310.09725)

    KGQuiz是一个知识密集型基准测试，通过涵盖三个知识领域和五个任务，全面评估了大型语言模型(LLMs)的知识泛化能力。

    

    大型语言模型(LLMs)在知识密集型任务上表现出色，这表明真实世界的知识被编码在它们的模型参数中。然而，除了在有限的知识领域上进行一些探索性任务之外，我们对于如何系统评估LLMs的知识能力以及它们的知识能力在不同领域和逐渐复杂的任务格式中的泛化效果并不了解。为了解决这个问题，我们提出了KGQuiz，一个知识密集型基准测试，全面调查LLMs的知识泛化能力。KGQuiz是一个可扩展的框架，由基于三元组的知识构建，涵盖了三个知识领域，并包括五个任务，难度递增：真假判断、多项选择问题、填空、事实编辑和开放式知识生成。为了更好地理解LLMs的知识能力和它们的泛化效果，我们评估了10种开源和黑盒LLMs。

    Large language models (LLMs) demonstrate remarkable performance on knowledge-intensive tasks, suggesting that real-world knowledge is encoded in their model parameters. However, besides explorations on a few probing tasks in limited knowledge domains, it is not well understood how to evaluate LLMs' knowledge systematically and how well their knowledge abilities generalize, across a spectrum of knowledge domains and progressively complex task formats. To this end, we propose KGQuiz, a knowledge-intensive benchmark to comprehensively investigate the knowledge generalization abilities of LLMs. KGQuiz is a scalable framework constructed from triplet-based knowledge, which covers three knowledge domains and consists of five tasks with increasing complexity: true-or-false, multiple-choice QA, blank filling, factual editing, and open-ended knowledge generation. To gain a better understanding of LLMs' knowledge abilities and their generalization, we evaluate 10 open-source and black-box LLMs o
    
[^222]: 采用估计的注意力掩码的稀疏线性注意力（SEA）

    SEA: Sparse Linear Attention with Estimated Attention Mask. (arXiv:2310.01777v1 [cs.CL])

    [http://arxiv.org/abs/2310.01777](http://arxiv.org/abs/2310.01777)

    提出了SEA方法，可以通过估计注意力掩码实现线性复杂度的稀疏注意力，解决了transformer处理长序列时注意力操作复杂度高的问题，并保持了可解释性。

    

    近年来，transformer架构在需要对序列元素之间的成对关系建模的任务上取得了重大突破，如自然语言理解任务。然而，由于注意力操作的二次复杂度，transformer在处理长序列时存在困难，因此先前的研究旨在通过稀疏化或线性逼近注意力矩阵来降低复杂度。然而，这些方法无法直接从教师的注意力矩阵中提取知识，并且通常需要完全重新训练。此外，先前的稀疏和线性方法如果不能产生完全二次的注意力矩阵，还可能失去可解释性。为了解决这些挑战，我们提出了SEA：采用估计注意力掩码的稀疏线性注意力方法。SEA通过基于核的线性注意力方法估计注意力矩阵，并创建一个对完整注意力矩阵进行稀疏逼近的方法。

    The transformer architecture has made breakthroughs in recent years on tasks which require modeling pairwise relationships between sequential elements, as is the case in natural language understanding. However, transformers struggle with long sequences due to the quadratic complexity of the attention operation, and previous research has aimed to lower the complexity by sparsifying or linearly approximating the attention matrix. Yet, these approaches cannot straightforwardly distill knowledge from a teacher's attention matrix, and often require complete retraining from scratch. Furthermore, previous sparse and linear approaches may also lose interpretability if they do not produce full quadratic attention matrices. To address these challenges, we propose SEA: Sparse linear attention with an Estimated Attention mask. SEA estimates the attention matrix with linear complexity via kernel-based linear attention, then creates a sparse approximation to the full attention matrix with a top-k se
    
[^223]: 从LLMs中有效提取基于表格推理能力的方法

    Effective Distillation of Table-based Reasoning Ability from LLMs. (arXiv:2309.13182v1 [cs.CL])

    [http://arxiv.org/abs/2309.13182](http://arxiv.org/abs/2309.13182)

    本论文提出了一种从LLMs中提取基于表格推理能力的方法，通过蒸馏将大型模型转化为专门用于基于表格推理任务的小型模型，并取得了良好的性能。

    

    大型语言模型（LLMs）在自然语言处理任务中展现出了卓越的性能。然而，它们庞大的参数和对计算资源的高需求给实际应用带来了挑战。最近的研究发现，LLMs的特定能力，如数值推理，可以通过蒸馏传递给较小的模型。一些研究探讨了利用LLMs进行基于表格推理的潜力。然而，在我们的工作之前，尚未对专门为表格生成任务定制的较小模型的表格推理能力进行研究。在本文中，我们提出了一种新颖的基于表格推理的蒸馏方法，旨在将LLMs蒸馏成专门为基于表格推理任务设计的较小模型。实验结果表明，一个具有0.22亿参数的模型（Flan-T5-base）可以有效地进行蒸馏，并展现出良好的性能。

    Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, their remarkable parameter size and their impressive high requirement of computing resources pose challenges for their practical deployment. Recent research has revealed that specific capabilities of LLMs, such as numerical reasoning, can be transferred to smaller models through distillation. Some studies explore the potential of leveraging LLMs to perform table-based reasoning. Nevertheless, prior to our work, there has been no investigation into the prospect of specialising table reasoning skills in smaller models specifically tailored for table-to-text generation tasks. In this paper, we propose a novel table-based reasoning distillation, with the aim of distilling distilling LLMs into tailored, smaller models specifically designed for table-based reasoning task. Experimental results have shown that a 0.22 billion parameter model (Flan-T5-base) fin
    
[^224]: 关于技能神经元与Prompt Tuning中的鲁棒性的关系研究

    On the Relationship between Skill Neurons and Robustness in Prompt Tuning. (arXiv:2309.12263v1 [cs.CL])

    [http://arxiv.org/abs/2309.12263](http://arxiv.org/abs/2309.12263)

    本文研究了Prompt Tuning在与"技能神经元"的关系中的鲁棒性，发现特定任务的调整指令在相同类型的任务上具有传递性，但对于对抗性数据的鲁棒性不高，其中T5的鲁棒性比RoBERTa更高，并且发现T5和RoBERTa中都存在技能神经元。

    

    Prompt Tuning是一种用于预训练大型语言模型(PLMs)的参数高效微调方法。最近，通过对RoBERTa的实验，有人认为Prompt Tuning激活了Transformer前馈网络中特定的神经元，这些神经元对给定任务具有高预测能力和选择性。本文中，我们使用RoBERTa和T5来研究Prompt Tuning与这些“技能神经元”的鲁棒性关系。我们发现特定任务的调整指令在相同类型的任务上具有传递性，但对于对抗性数据的鲁棒性不高，其中T5的鲁棒性比RoBERTa更高。同时，我们重现了RoBERTa中的技能神经元存在，并进一步展示了T5中也存在技能神经元。有趣的是，T5在非对抗性数据上确定的技能神经元也是对抗性数据上预测性最强的神经元，而这在RoBERTa中不是这种情况。我们得出结论，更高的对抗鲁棒性可能与技能神经元的存在相关。

    Prompt Tuning is a popular parameter-efficient finetuning method for pre-trained large language models (PLMs). Recently, based on experiments with RoBERTa, it has been suggested that Prompt Tuning activates specific neurons in the transformer's feed-forward networks, that are highly predictive and selective for the given task. In this paper, we study the robustness of Prompt Tuning in relation to these "skill neurons", using RoBERTa and T5. We show that prompts tuned for a specific task are transferable to tasks of the same type but are not very robust to adversarial data, with higher robustness for T5 than RoBERTa. At the same time, we replicate the existence of skill neurons in RoBERTa and further show that skill neurons also seem to exist in T5. Interestingly, the skill neurons of T5 determined on non-adversarial data are also among the most predictive neurons on the adversarial data, which is not the case for RoBERTa. We conclude that higher adversarial robustness may be related to
    
[^225]: 考察基于静态数据集训练的计算化谣言检测模型的局限性

    Examining the Limitations of Computational Rumor Detection Models Trained on Static Datasets. (arXiv:2309.11576v1 [cs.CL])

    [http://arxiv.org/abs/2309.11576](http://arxiv.org/abs/2309.11576)

    本文通过深入评估基于内容和基于上下文模型在检测新的未知谣言上的性能差距，发现基于上下文的模型过度依赖来源帖子信息并忽略了上下文信息的重要作用。实验结果也提出了减小时间概念影响的实际建议。

    

    谣言检测模型的一个关键方面是其泛化能力，特别是其能够检测出新出现的、以前未知的谣言的能力。过去的研究表明，仅基于内容（即仅使用来源帖子作为输入）的谣言检测模型在未知谣言上的表现效果较差。与此同时，基于上下文的模型的潜力尚未充分利用。本文的主要贡献在于深入评估基于内容和基于上下文模型在特别是检测新的未知谣言上的性能差距。我们的实证研究结果表明，基于上下文的模型仍然过度依赖来自谣言来源帖子的信息，并倾向于忽略上下文信息可能发挥的重要作用。我们还研究了数据拆分策略对分类器性能的影响。根据我们的实验结果，本文还提出了如何减小时间概念影响的实际建议。

    A crucial aspect of a rumor detection model is its ability to generalize, particularly its ability to detect emerging, previously unknown rumors. Past research has indicated that content-based (i.e., using solely source posts as input) rumor detection models tend to perform less effectively on unseen rumors. At the same time, the potential of context-based models remains largely untapped. The main contribution of this paper is in the in-depth evaluation of the performance gap between content and context-based models specifically on detecting new, unseen rumors. Our empirical findings demonstrate that context-based models are still overly dependent on the information derived from the rumors' source post and tend to overlook the significant role that contextual information can play. We also study the effect of data split strategies on classifier performance. Based on our experimental results, the paper also offers practical suggestions on how to minimize the effects of temporal concept d
    
[^226]: K-pop歌词翻译：数据集、分析与神经建模

    K-pop Lyric Translation: Dataset, Analysis, and Neural-Modelling. (arXiv:2309.11093v1 [cs.CL])

    [http://arxiv.org/abs/2309.11093](http://arxiv.org/abs/2309.11093)

    研究者介绍了一种新颖的K-pop歌词翻译数据集，该数据集揭示了K-pop歌词翻译的独特特征，并构建了一个神经歌词翻译模型，强调了专用数据集的重要性。

    

    歌词翻译作为一个研究了一个世纪的领域，如今吸引着计算语言学研究者的注意。我们在以往研究中发现了两个限制。首先，在歌词翻译研究中，尽管K-pop非常受欢迎，但主要关注的是西方流派和语言，没有研究集中在K-pop上。其次，歌词翻译领域缺乏可公开获得的数据集；据我们所知，目前尚无此类数据集。为了拓宽歌词翻译研究的流派和语言范围，我们引入了一种新颖的可唱歌词翻译数据集，其中约89%为K-pop歌词。该数据集通过逐行和逐节对齐了韩语和英语歌词。我们利用该数据集揭示了K-pop歌词翻译的独特特征，与其他广泛研究的流派区分开，并构建了一个神经歌词翻译模型，从而强调了专用数据集的重要性。

    Lyric translation, a field studied for over a century, is now attracting computational linguistics researchers. We identified two limitations in previous studies. Firstly, lyric translation studies have predominantly focused on Western genres and languages, with no previous study centering on K-pop despite its popularity. Second, the field of lyric translation suffers from a lack of publicly available datasets; to the best of our knowledge, no such dataset exists. To broaden the scope of genres and languages in lyric translation studies, we introduce a novel singable lyric translation dataset, approximately 89\% of which consists of K-pop song lyrics. This dataset aligns Korean and English lyrics line-by-line and section-by-section. We leveraged this dataset to unveil unique characteristics of K-pop lyric translation, distinguishing it from other extensively studied genres, and to construct a neural lyric translation model, thereby underscoring the importance of a dedicated dataset for
    
[^227]: HealthFC：一份用于基于证据的医学事实检验的健康声明数据集

    HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking. (arXiv:2309.08503v1 [cs.CL])

    [http://arxiv.org/abs/2309.08503](http://arxiv.org/abs/2309.08503)

    本文介绍了一份新的健康声明数据集，其中包含了750个由医学专家标注的健康相关声明，并提供了来自临床研究的证据支持。该数据集可用于机器学习任务，包括证据检索、真实性预测和解释生成。

    

    在数字时代，通过互联网查询健康相关建议已成为一种常见做法。然而，判断在线找到的医学声明的可信度，并找到相应的证据，变得越来越具有挑战性。事实检验已经成为一种通过可靠知识来源的证据评估事实声明真实性的方法。为了推动此任务的自动化，本文介绍了一份新的数据集，包含了750个健康相关声明，在可信度方面由医学专家进行了标注，并提供了来自适当的临床研究的证据支持。我们对数据集进行了分析，突出其特点和挑战。该数据集可用于与自动事实检验相关的机器学习任务，如证据检索、真实性预测和解释生成。为此，我们提供了基于不同方法的基线模型，对它们的性能进行了研究，并讨论了研究结果。

    Seeking health-related advice on the internet has become a common practice in the digital era. Determining the trustworthiness of medical claims found online and finding appropriate evidence for this information is increasingly challenging. Fact-checking has emerged as an approach to assess the veracity of factual claims using evidence from credible knowledge sources. To help advance the automation of this task, in this paper, we introduce a novel dataset of 750 health-related claims, labeled for veracity by medical experts and backed with evidence from appropriate clinical studies. We provide an analysis of the dataset, highlighting its characteristics and challenges. The dataset can be used for Machine Learning tasks related to automated fact-checking such as evidence retrieval, veracity prediction, and explanation generation. For this purpose, we provide baseline models based on different approaches, examine their performance, and discuss the findings.
    
[^228]: ContrastWSD: 使用词义消岐加强隐喻检测

    ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation Following the Metaphor Identification Procedure. (arXiv:2309.03103v1 [cs.CL])

    [http://arxiv.org/abs/2309.03103](http://arxiv.org/abs/2309.03103)

    ContrastWSD是一种使用了词义消岐的隐喻检测模型，通过将隐喻识别过程和词义消岐结合起来，提取并对比单词的上下文含义和基本含义，以提高隐喻检测的效果，超过其他仅依赖上下文嵌入或集成基本定义和外部知识的方法。

    

    本文提出了ContrastWSD，一种基于RoBERTa的隐喻检测模型，它集成了隐喻识别过程(MIP)和词义消岐(WSD)来提取并对比单词的上下文含义和基本含义，以确定它在句子中是否以隐喻的方式使用。通过利用WSD模型得出的单词词义，我们的模型增强了隐喻检测过程，并超过了仅依赖上下文嵌入或仅集成基本定义和其他外部知识的其他方法。我们在多个基准数据集上评估了我们的方法，并与强基线进行比较，结果表明它在推进隐喻检测方面的有效性。

    This paper presents ContrastWSD, a RoBERTa-based metaphor detection model that integrates the Metaphor Identification Procedure (MIP) and Word Sense Disambiguation (WSD) to extract and contrast the contextual meaning with the basic meaning of a word to determine whether it is used metaphorically in a sentence. By utilizing the word senses derived from a WSD model, our model enhances the metaphor detection process and outperforms other methods that rely solely on contextual embeddings or integrate only the basic definitions and other external knowledge. We evaluate our approach on various benchmark datasets and compare it with strong baselines, indicating the effectiveness in advancing metaphor detection.
    
[^229]: 因果交叉性和双重梯度下降在多模态分析中的应用：以仇恨迷因为例（arXiv:2308.11585v1 [cs.AI]）

    Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes. (arXiv:2308.11585v1 [cs.AI])

    [http://arxiv.org/abs/2308.11585](http://arxiv.org/abs/2308.11585)

    本篇论文探讨了因果交叉性和双重梯度下降在多模态分析中的应用，以仇恨迷因检测为例。通过结合因果分析和基于梯度的方法，研究发现模型的内部机制可以揭示其因果效应，并介绍了交叉性和模态的梯度注意力的摘要化方法。

    

    随着机器学习（ML）的爆炸性增长，特别是在新兴的大语言模型（LLM）的背景下，理解其内部工作中的语义意义至关重要。虽然因果分析侧重于定义语义及其量化，基于梯度的方法是可解释的人工智能（XAI）的核心，用于解释黑盒子的解释。通过协同这些方法，探索模型的内部机制如何阐明其因果效应已成为基于证据的决策的必要条件。一系列并行的研究表明，交叉性--个体的多个人口统计学因素的组合影响--可以以平均处理效应（ATE）的形式进行结构化。最初，本研究阐述了仇恨迷因检测问题可以作为一个ATE来描述，借助交叉性原则，以及基于模态的梯度注意力的摘要化。

    In the wake of the explosive growth of machine learning (ML) usage, particularly within the context of emerging Large Language Models (LLMs), comprehending the semantic significance rooted in their internal workings is crucial. While causal analyses focus on defining semantics and its quantification, the gradient-based approach is central to explainable AI (XAI), tackling the interpretation of the black box. By synergizing these approaches, the exploration of how a model's internal mechanisms illuminate its causal effect has become integral for evidence-based decision-making. A parallel line of research has revealed that intersectionality - the combinatory impact of multiple demographics of an individual - can be structured in the form of an Averaged Treatment Effect (ATE). Initially, this study illustrates that the hateful memes detection problem can be formulated as an ATE, assisted by the principles of intersectionality, and that a modality-wise summarization of gradient-based atten
    
[^230]: 基于大型语言模型的自主代理的调查

    A Survey on Large Language Model based Autonomous Agents. (arXiv:2308.11432v1 [cs.AI])

    [http://arxiv.org/abs/2308.11432](http://arxiv.org/abs/2308.11432)

    该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。

    

    自主代理长期以来一直是学术界的研究热点。以往的研究往往集中在对有限知识的代理进行训练，而这与人类的学习过程存在明显差异，因此很难实现人类般的决策。近年来，通过获取大量的网络知识，大型语言模型（LLM）展现出了实现人类水平智能的显著潜力。这引发了对基于LLM的自主代理的研究的高涨兴趣。为了发挥LLM的全部潜力，研究人员设计了各种不同应用的代理体系结构。本论文综述了这些研究，从整体的角度对自主代理领域进行了系统的审查。具体而言，我们的重点是基于LLM的代理构建，为此我们提出了一个统一的框架。

    Autonomous agents have long been a prominent research topic in the academic community. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from the human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating autonomous agents based on LLMs. To harness the full potential of LLMs, researchers have devised diverse agent architectures tailored to different applications. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of autonomous agents from a holistic perspective. More specifically, our focus lies in the construction of LLM-based agents, for which we propose a unified framework t
    
[^231]: 是否分享？给予差分隐私的自然语言处理系统敏感数据的普通人接受什么风险？

    To share or not to share: What risks would laypeople accept to give sensitive data to differentially-private NLP systems?. (arXiv:2307.06708v1 [cs.CL])

    [http://arxiv.org/abs/2307.06708](http://arxiv.org/abs/2307.06708)

    这项研究旨在探索普通人在面临隐私威胁情境时的决策行为，以及他们愿意为给予差分隐私的自然语言处理系统提供敏感数据所承担的风险。

    

    尽管NLP社区已经采用中心差分隐私作为保护隐私的模型训练或数据共享的首选框架，但决定性的关键参数——控制隐私保护强度的隐私预算ε的选择和解释仍然相当随意。我们认为确定ε值不应该仅由研究人员或系统开发者决定，还必须考虑那些共享他们潜在敏感数据的人。换句话说：你愿意为ε值为10而分享你的即时消息吗？我们通过设计、实施和进行行为实验(311名普通参与者)来填补这一研究空白，研究人们在不确定决策环境下面对威胁隐私的情境时的行为。通过将风险感知框架化为两个现实的NLP场景，并使用情节行为研究，我们能够确定哪些ε阈值将导致共享行为的转变。

    Although the NLP community has adopted central differential privacy as a go-to framework for privacy-preserving model training or data sharing, the choice and interpretation of the key parameter, privacy budget $\varepsilon$ that governs the strength of privacy protection, remains largely arbitrary. We argue that determining the $\varepsilon$ value should not be solely in the hands of researchers or system developers, but must also take into account the actual people who share their potentially sensitive data. In other words: Would you share your instant messages for $\varepsilon$ of 10? We address this research gap by designing, implementing, and conducting a behavioral experiment (311 lay participants) to study the behavior of people in uncertain decision-making situations with respect to privacy-threatening situations. Framing the risk perception in terms of two realistic NLP scenarios and using a vignette behavioral study help us determine what $\varepsilon$ thresholds would lead l
    
[^232]: ODD: 一份基于自然语言处理的药物滥用异常行为检测的基准数据集

    ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection. (arXiv:2307.02591v1 [cs.CL])

    [http://arxiv.org/abs/2307.02591](http://arxiv.org/abs/2307.02591)

    这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。

    

    药物滥用异常行为（ORAB）是防止药物过量的新风险因素。以往，ORAB主要通过调查结果和药物给予监测进行评估。然而，这些方法无法扩展，并不能涵盖所有异常行为的范围。然而，ORAB在电子健康记录笔记中广泛有记录。本文介绍了一个名为ODD的新型生物医学自然语言处理基准数据集，用于ORAB检测。ODD是一个专家注释的数据集，包括750多个公开可用的电子健康记录笔记。ODD旨在从患者的电子健康记录笔记中识别ORAB，并将其分类为九个类别：1）已确认异常行为，2）暗示的异常行为，3）阿片类药物，4）适应症，5）已诊断的阿片制剂依赖，6）苯二氮平类药物，7）药物变化，8）与中枢神经系统相关，9）社会健康决定因素。

    Opioid related aberrant behaviors (ORAB) present novel risk factors for opioid overdose. Previously, ORAB have been mainly assessed by survey results and by monitoring drug administrations. Such methods however, cannot scale up and do not cover the entire spectrum of aberrant behaviors. On the other hand, ORAB are widely documented in electronic health record notes. This paper introduces a novel biomedical natural language processing benchmark dataset named ODD, for ORAB Detection Dataset. ODD is an expert-annotated dataset comprising of more than 750 publicly available EHR notes. ODD has been designed to identify ORAB from patients' EHR notes and classify them into nine categories; 1) Confirmed Aberrant Behavior, 2) Suggested Aberrant Behavior, 3) Opioids, 4) Indication, 5) Diagnosed opioid dependency, 6) Benzodiapines, 7) Medication Changes, 8) Central Nervous System-related, and 9) Social Determinants of Health. We explored two state-of-the-art natural language processing (NLP) mode
    
[^233]: 用于基于检索的对话系统的上下文掩码自编码器

    ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems. (arXiv:2306.04357v1 [cs.CL])

    [http://arxiv.org/abs/2306.04357](http://arxiv.org/abs/2306.04357)

    本研究提出了一种针对对话响应选择的后训练技术Dial-MAE，利用生成方法更好地压缩对话语义至密集向量，并提高对话响应选择准确性。

    

    对话响应选择旨在根据给定的用户和系统话语历史记录从几个候选响应中选择适当的响应。最近的研究通过后训练大多依赖于单纯的掩码语言建模方法来提高对话响应选择的准确性。但是，最近开发的生成方法在IR社区展示了有希望的文本表示能力，这可能会导致更好的对话语义建模。因此，在本文中，我们提出 Dial-MAE（对话上下文掩码自编码器），这是一种简单而有效的针对对话响应选择的后训练技术。 Dial-MAE使用一个不对称的编码器-解码器架构，学习将对话的语义更好地压缩到密集向量中。 Dial-MAE的过程包括由深度编码器创建带有掩码对话上下文的对话嵌入，然后是浅解码器，该解码器使用此嵌入以及上下文向量来生成响应。

    Dialogue response selection aims to select an appropriate response from several candidates based on a given user and system utterance history. Recent studies have been improving the accuracy of dialogue response selection through post-training, mostly relying on naive masked language modeling methods. However, the recently developed generative methods have shown promising text representation capabilities in IR community, which could potentially lead to better dialogue semantics modeling. Thus, in this paper, we propose Dial-MAE (Dialogue Contextual Masking Auto-encoder), a straightforward yet effective post-training technique tailored for dialogue response selection. Dial-MAE uses an asymmetric encoder-decoder architecture that learns to better compress the semantics of the dialogue into dialogue-dense vectors. The process of Dial-MAE involves a deep encoder creating a dialogue embedding with the masked dialogue context, followed by a shallow decoder that uses this embedding along with
    
[^234]: 自动发音障碍语音评估可靠性的研究

    A Study on the Reliability of Automatic Dysarthric Speech Assessments. (arXiv:2306.04337v1 [cs.CL])

    [http://arxiv.org/abs/2306.04337](http://arxiv.org/abs/2306.04337)

    本研究旨在通过添加和减少噪声，以一种更可解释的方式，可视化和比较特征提取器和模型，更清楚地了解自动发音障碍评估的模式，并为建立可靠的自动发音障碍评估系统提供了认识和建议。

    

    自动化发音障碍评估提供了开发有效低成本工具的机会，这些工具可以解决手动和主观评估的现有限制。 然而，目前的方法是否依赖于发音障碍相关的语音模式或外部因素尚不清楚。 我们旨在更清楚地了解发音障碍模式。 为此，我们通过添加和减少噪声，设计和实施了一种新的方法来可视化和比较特征提取器和模型，在患者层面上进行更可解释的方式。我们使用了UA-Speech数据集，将数据以说话人为单位进行拆分。 目前的文献中报告的结果似乎无论是否进行了这种拆分，都会导致由于数据泄漏而可能过于自信的模型。 我们希望这些结果提高研究界对建立可靠的自动发音障碍评估系统的要求的意识。

    Automating dysarthria assessments offers the opportunity to develop effective, low-cost tools that address the current limitations of manual and subjective assessments. Nonetheless, it is unclear whether current approaches rely on dysarthria-related speech patterns or external factors. We aim toward obtaining a clearer understanding of dysarthria patterns. To this extent, we study the effects of noise in recordings, both through addition and reduction. We design and implement a new method for visualizing and comparing feature extractors and models, at a patient level, in a more interpretable way. We use the UA-Speech dataset with a speaker-based split of the dataset. Results reported in the literature appear to have been done irrespective of such split, leading to models that may be overconfident due to data-leakage. We hope that these results raise awareness in the research community regarding the requirements for establishing reliable automatic dysarthria assessment systems.
    
[^235]: PLANNER:通过潜在语言扩散模型生成多样化段落

    PLANNER: Generating Diversified Paragraph via Latent Language Diffusion Model. (arXiv:2306.02531v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02531](http://arxiv.org/abs/2306.02531)

    本文提出了PLANNER模型，它通过将自回归生成和潜在语义扩散相结合，以在生成文本时在段落级别实现全局控制，生成流畅的文本。

    

    文本的自回归模型有时会生成重复且质量低下的输出，因为在生成的步骤中错误会累积。这个问题常常被归因于曝光偏差-模型在训练和推理过程中的使用方式之间的差异。去噪扩散模型提供了一种替代方法，模型可以回顾和修正其输出。然而，它们在计算上可能很昂贵，并且在文本和段落较长的情况下，与自回归模型相比，先前关于文本的研究努力已导致产生的模型产生不太流畅的输出。在本文中，我们提出了PLANNER，一个将潜在语义扩散与自回归生成结合的模型，以在段落上进行全局控制来生成流畅的文本。该模型通过将自回归的“解码”模块与使用潜在扩散以粗粒度方式生成语义段落嵌入的“规划”模块相结合来实现这一目标。该方法进行了评估

    Autoregressive models for text sometimes generate repetitive and low-quality output because errors accumulate during the steps of generation. This issue is often attributed to exposure bias - the difference between how a model is trained, and how it is used during inference. Denoising diffusion models provide an alternative approach in which a model can revisit and revise its output. However, they can be computationally expensive and prior efforts on text have led to models that produce less fluent output compared to autoregressive models, especially for longer text and paragraphs. In this paper, we propose PLANNER, a model that combines latent semantic diffusion with autoregressive generation, to generate fluent text while exercising global control over paragraphs. The model achieves this by combining an autoregressive "decoding" module with a "planning" module that uses latent diffusion to generate semantic paragraph embeddings in a coarse-to-fine manner. The proposed method is evalu
    
[^236]: 大语言模型中的图思维推理：超越“思维链”的有力工具

    Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models. (arXiv:2305.16582v1 [cs.CL])

    [http://arxiv.org/abs/2305.16582](http://arxiv.org/abs/2305.16582)

    通过将人类思维过程建模成图形结构，我们提出了“思维图”（GoT）推理辅助大语言模型（LLMs）来完成更加真实的、复杂的思维任务。

    

    随着大语言模型（LLMs）在NLP任务中的广泛应用，研究人员发现“思维链”（CoT）能够通过生成中间步骤来帮助LLMs完成复杂的推理任务。然而，人类的思维过程常常是非线性的，而不只是简单的顺序思维链。因此，我们提出了“思维图”（GoT）推理，它不仅将人类思维过程建模成链式结构，而且还建模成图形结构。通过将思维单元表示为节点，它们之间的连接作为边缘，我们的方法捕捉了人类思维的非顺序性，实现了对思维过程的更加真实的建模。

    With the widespread use of large language models (LLMs) in NLP tasks, researchers have discovered the potential of Chain-of-thought (CoT) to assist LLMs in accomplishing complex reasoning tasks by generating intermediate steps. However, human thought processes are often non-linear, rather than simply sequential chains of thoughts. Therefore, we propose Graph-of-Thought (GoT) reasoning, which models human thought processes not only as a chain but also as a graph. By representing thought units as nodes and connections between them as edges, our approach captures the non-sequential nature of human thinking and allows for a more realistic modeling of thought processes. Similar to Multimodal-CoT, we modeled GoT reasoning as a two-stage framework, generating rationales first and then producing the final answer. Specifically, we employ an additional graph-of-thoughts encoder for GoT representation learning and fuse the GoT representation with the original input representation through a gated 
    
[^237]: 零样本分类中的提示复杂性导航：一项关于大型语言模型在计算社会科学中的研究

    Navigating Prompt Complexity for Zero-Shot Classification: A Study of Large Language Models in Computational Social Science. (arXiv:2305.14310v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14310](http://arxiv.org/abs/2305.14310)

    本研究通过评估两个大型语言模型在六个计算社会科学分类任务中的零样本性能，并研究了各种提示策略的影响。结果显示，当前的大型语言模型在零样本设置下无法与较小的微调基线模型相媲美。

    

    语言调整的大型语言模型(LLMs)展示出了令人印象深刻的语言理解能力，并且具有根据特定提示生成响应的能力。然而，由于训练这些模型所需的计算需求，它们的应用通常采用零样本设置。在本文中，我们评估了两个公开可访问的LLM，ChatGPT和OpenAssistant在六个计算社会科学分类任务的零样本性能，同时还研究了各种提示策略的影响。我们的实验调查了提示复杂性的影响，包括在提示中加入标签定义的效果；使用标签名称的同义词；以及在基础模型训练过程中整合过去记忆的影响。研究结果表明，在零样本设置下，目前的LLMs无法达到较小的微调基线转换模型（如BERT-large）的性能。此外，我们发现...

    Instruction-tuned Large Language Models (LLMs) have exhibited impressive language understanding and the capacity to generate responses that follow specific prompts. However, due to the computational demands associated with training these models, their applications often adopt a zero-shot setting. In this paper, we evaluate the zero-shot performance of two publicly accessible LLMs, ChatGPT and OpenAssistant, in the context of six Computational Social Science classification tasks, while also investigating the effects of various prompting strategies. Our experiments investigate the impact of prompt complexity, including the effect of incorporating label definitions into the prompt; use of synonyms for label names; and the influence of integrating past memories during foundation model training. The findings indicate that in a zero-shot setting, current LLMs are unable to match the performance of smaller, fine-tuned baseline transformer models (such as BERT-large). Additionally, we find tha
    
[^238]: 一个统一的英文文本到语音合成前端框架

    a unified front-end framework for english text-to-speech synthesis. (arXiv:2305.10666v1 [cs.CL])

    [http://arxiv.org/abs/2305.10666](http://arxiv.org/abs/2305.10666)

    该论文提出了一个统一的前端框架，捕捉了英文语音合成前端模块之间的依赖关系，并且在所有模块中均取得了最先进的性能。

    

    前端是英文文本到语音合成系统的关键组成部分，负责提取语言特征，如韵律和音素，这对于文本到语音模型合成语音至关重要。英文文本到语音前端通常由文本规范化模块（TN），单词韵律短语韵律短语模块（PWPP）和字形到音素模块（G2P）组成。然而，当前英文文本到语音前端的研究仅关注于单独模块，忽略它们之间的相互依赖，导致每个模块性能下降。因此，本文提出了一个统一的前端框架，捕捉英文文本到语音前端模块之间的依赖关系。广泛的实验表明，所提出的方法在所有模块中实现了最先进的性能。

    The front-end is a critical component of English text-to-speech (TTS) systems, responsible for extracting linguistic features that are essential for a text-to-speech model to synthesize speech, such as prosodies and phonemes. The English TTS front-end typically consists of a text normalization (TN) module, a prosody word prosody phrase (PWPP) module, and a grapheme-to-phoneme (G2P) module. However, current research on the English TTS front-end focuses solely on individual modules, neglecting the interdependence between them and resulting in sub-optimal performance for each module. Therefore, this paper proposes a unified front-end framework that captures the dependencies among the English TTS front-end modules. Extensive experiments have demonstrated that the proposed method achieves state-of-the-art (SOTA) performance in all modules.
    
[^239]: 考察COVID-19疫苗态度检测中的时间性

    Examining Temporalities on Stance Detection Towards COVID-19 Vaccination. (arXiv:2304.04806v1 [cs.CL])

    [http://arxiv.org/abs/2304.04806](http://arxiv.org/abs/2304.04806)

    研究考虑了时间性对COVID-19疫苗态度检测的影响，发现时间分割显著降低了立场分类的准确性。

    

    先前的研究指出疫苗接种是控制COVID-19传播的有效策略。了解公众的疫苗态度对决策者至关重要。然而，社交媒体上的 COVID-19 疫苗态度（如支持和犹豫）会随时间而演变，因此在分析这些立场时需要考虑可能的时间漂移。该研究旨在检查时间概念漂移对推特上 COVID-19 疫苗立场检测的影响。为此，我们使用基于转换器的模型对社交媒体数据进行了随机和时间分割的评估。我们的研究发现，在所有单语和多语数据集的随机和时间分割之间，模型性能存在显著差异。时间分割显著降低了立场分类的准确性。

    Previous studies have highlighted the importance of vaccination as an effective strategy to control the transmission of the COVID-19 virus. It is crucial for policymakers to have a comprehensive understanding of the public's stance towards vaccination on a large scale. However, attitudes towards COVID-19 vaccination, such as pro-vaccine or vaccine hesitancy, have evolved over time on social media. Thus, it is necessary to account for possible temporal shifts when analysing these stances. This study aims to examine the impact of temporal concept drift on stance detection towards COVID-19 vaccination on Twitter. To this end, we evaluate a range of transformer-based models using chronological and random splits of social media data. Our findings demonstrate significant discrepancies in model performance when comparing random and chronological splits across all monolingual and multilingual datasets. Chronological splits significantly reduce the accuracy of stance classification. Therefore, 
    
[^240]: PWESuite：语音单词嵌入及其任务

    PWESuite: Phonetic Word Embeddings and Tasks They Facilitate. (arXiv:2304.02541v1 [cs.CL])

    [http://arxiv.org/abs/2304.02541](http://arxiv.org/abs/2304.02541)

    本论文展示了一套语音单词嵌入及其相关任务，提高了语音信息处理的效果和可重复性。

    

    将单词映射到固定维度的向量空间的单词嵌入是现代自然语言处理的基础。大多数单词嵌入方法编码语义信息。但是，对于某些任务非常重要的语音信息经常被忽略。在这项工作中，我们开发了几种新方法，利用发声特征构建语音知情单词嵌入，并提供一套语音单词嵌入以鼓励其社区的开发、评估和使用。虽然已经存在许多学习语音单词嵌入的方法，但在评估其有效性方面缺乏一致性。因此，我们还提出了几种评估语音单词嵌入的内在方面的方法，如单词检索和与声音相似性的相关性，以及外在表现，如韵律和同源检测和声音类比。我们希望我们的任务套件将促进可重复性并提供未来语音单词嵌入研究的方向。

    Word embeddings that map words into a fixed-dimensional vector space are the backbone of modern NLP. Most word embedding methods encode semantic information. However, phonetic information, which is important for some tasks, is often overlooked. In this work, we develop several novel methods which leverage articulatory features to build phonetically informed word embeddings, and present a set of phonetic word embeddings to encourage their community development, evaluation and use. While several methods for learning phonetic word embeddings already exist, there is a lack of consistency in evaluating their effectiveness. Thus, we also proposes several ways to evaluate both intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and extrinsic performances, such as rhyme and cognate detection and sound analogies. We hope that our suite of tasks will promote reproducibility and provide direction for future research on phonetic word embeddi
    
[^241]: 小红帽环球旅行：基于大语言模型的跨语言故事规划与生成

    Little Red Riding Hood Goes Around the Globe:Crosslingual Story Planning and Generation with Large Language Models. (arXiv:2212.10471v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10471](http://arxiv.org/abs/2212.10471)

    本论文提出了一个新的跨语言故事生成任务，并利用大型预训练语言模型研究不同的故事规划。结果表明将故事分为三幕可以带来更一致和有趣的叙述，同时允许明确控制其内容和结构。

    

    先前的研究已经证明了在单语环境下规划故事生成的有效性，主要集中在英语上。我们考虑在跨语言的自动故事生成中，规划是否带来了优势。我们提出了一个新的跨语言故事生成任务，并为该任务提供了一个新的数据集。我们通过利用大型预训练语言模型的创造和推理能力，对不同的故事规划进行了全面的研究，并在多种语言中生成了故事。我们的结果表明，将故事结构化为三幕的规划可以带来更一致和有趣的叙述，同时允许明确控制其内容和结构。

    Previous work has demonstrated the effectiveness of planning for story generation exclusively in a monolingual setting focusing primarily on English. We consider whether planning brings advantages to automatic story generation across languages. We propose a new task of cross-lingual story generation with planning and present a new dataset for this task. We conduct a comprehensive study of different plans and generate stories in several languages, by leveraging the creative and reasoning capabilities of large pre-trained language models. Our results demonstrate that plans which structure stories into three acts lead to more coherent and interesting narratives, while allowing to explicitly control their content and structure.
    

