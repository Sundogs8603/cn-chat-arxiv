# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Arabic Fine-Grained Entity Recognition.](http://arxiv.org/abs/2310.17333) | 本论文提出了一种阿拉伯精细化实体识别方法，通过扩展现有的阿拉伯命名实体语料库，将地缘政治实体、位置、组织和设施等四种主要实体类型扩展为31个子类型，并通过评估评注者一致性证明了扩展后的效果。 |
| [^2] | [PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models.](http://arxiv.org/abs/2310.12439) | PoisonPrompt是一种新的后门攻击方法，能够成功地破坏基于提示的大型语言模型，该攻击方法的有效性、保真度和鲁棒性经过了广泛实验验证，强调了基于提示的语言模型面临的安全威胁和进一步研究的必要性。 |
| [^3] | [Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity.](http://arxiv.org/abs/2310.07521) | 这项调查研究了大型语言模型（LLMs）中的事实性问题，包括其可能带来的后果和挑战，以及存储、处理和评估事实的方法。同时，提出了一些增强LLM事实性的策略，涵盖了不同领域的需求。 |
| [^4] | [Recurrent Neural Language Models as Probabilistic Finite-state Automata.](http://arxiv.org/abs/2310.05161) | 本文研究了循环神经网络语言模型（RNN LMs）作为概率有限状态自动机的能力，并发现它们只能表示有限状态模型所能表达的概率分布的一个严格子集。 |
| [^5] | [Zero Resource Code-switched Speech Benchmark Using Speech Utterance Pairs For Multiple Spoken Languages.](http://arxiv.org/abs/2310.03018) | 本论文介绍了一个新的零资源切换语音基准，用于评估自监督语音编码器的切换语言能力，研究了预训练语言和模型大小对基准性能的影响，结果显示多语言预训练的语音编码器在切换语言场景中表现优于单语变体，但仍有改进空间。 |
| [^6] | [RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds.](http://arxiv.org/abs/2309.17176) | RLAdapter引入了一个框架，将大型语言模型（LLM）与强化学习相结合，以提高在稀疏奖励环境中的策略学习性能。这通过解决LLM在理解下游任务方面的困难，以及通过避免使用不可访问的模型权重或大量计算资源来微调LLM的方式实现。 |
| [^7] | [High-Fidelity Speech Synthesis with Minimal Supervision: All Using Diffusion Models.](http://arxiv.org/abs/2309.15512) | 提出一种使用最少监督的扩散模型实现高保真度语音合成的方法，通过组合离散语音表示和利用序列到序列任务进行训练，解决了语义表示中的信息冗余和维度爆炸以及离散声学表示中的高频波形失真等问题。该方法中的非自回归框架增强了可控性，而持续时间扩散模型实现了音频的多样化控制。 |
| [^8] | [Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning.](http://arxiv.org/abs/2309.11082) | 本文提出了一种双模态注意增强的文本-视频检索方法，通过引入新颖的对比学习技术，能够准确衡量跨模态相似性和挖掘难负样本。 |
| [^9] | [DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning.](http://arxiv.org/abs/2309.05173) | DePT通过将软提示分解为较短的软提示和一对低秩矩阵，并用两个不同的学习率来优化，以解决提示调整对训练和推理时间以及内存使用的影响，从而实现更好的性能。 |
| [^10] | [CPSP: Learning Speech Concepts From Phoneme Supervision.](http://arxiv.org/abs/2309.00424) | 论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。 |
| [^11] | [When Do Program-of-Thoughts Work for Reasoning?.](http://arxiv.org/abs/2308.15452) | 提出了复杂性影响推理分数（CIRS）来衡量编程语言对推理能力的影响，发现并非所有复杂性的代码数据都可以被学习或理解，适当的复杂性水平对于改善推理能力至关重要。 |
| [^12] | [How to Evaluate the Generalization of Detection? A Benchmark for Comprehensive Open-Vocabulary Detection.](http://arxiv.org/abs/2308.13177) | 提出了一个名为OVDEval的新的基准测试方法，用于全面开放词汇检测。该方法包括9个子任务，并引入了常识知识、属性理解、位置理解、对象关系理解等方面的评估。数据集被精心创建以提供具有挑战性的负例，考验模型对视觉和语言输入的真正理解。此外，该方法发现了平均精确度（AP）指标在这些细粒度标签数据集上的问题，并提出了一种新指标。 |
| [^13] | [Audio Generation with Multiple Conditional Diffusion Model.](http://arxiv.org/abs/2308.11940) | 本论文提出了一种使用多条件扩散模型进行音频生成的方法。通过引入内容和风格等额外条件，增强了现有模型的可控性。这种方法可以精确控制生成音频的时间顺序、音高和能量。由于缺乏合适的数据集和评估指标，作者整合了现有数据集并进行了实验验证。 |
| [^14] | [Knowledge Graph Prompting for Multi-Document Question Answering.](http://arxiv.org/abs/2308.11730) | 这篇论文提出了一种知识图谱引导的方法，用于在多文档问答任务中为大型语言模型（LLMs）提示正确的上下文。通过构建多个文档上的知识图谱，并设计基于语言模型的图遍历器，该方法能够帮助LLMs在MD-QA中进行答案预测。 |
| [^15] | [BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions.](http://arxiv.org/abs/2308.09936) | BLIVA是一个简单的多模态LLM模型，用于更好地处理嵌入了文本的图像上下文场景。它通过引入InstructBLIP的查询嵌入和LLaVA的编码补丁嵌入技术来改进视觉语言模型，从而有效解决了文本丰富的视觉问题。 |
| [^16] | [On the Unexpected Abilities of Large Language Models.](http://arxiv.org/abs/2308.09720) | 大型语言模型展示了与其训练任务不直接相关的广泛能力，通过间接获取过程使其拥有综合能力的发展，这些能力在一定程度上可预测，并且与人类认知有关。 |
| [^17] | [Chinese Spelling Correction as Rephrasing Language Model.](http://arxiv.org/abs/2308.08796) | 本文提出了一种新颖的中文拼写纠错方法，通过改写语言建模来重新表达整个句子，而不是仅仅依赖错误模式进行字符级别标注，取得了最新的最优结果。 |
| [^18] | [Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling.](http://arxiv.org/abs/2308.06077) | 本文提出了一种经济有效的语言模型选择框架（CELMOC），通过元模型预测在不同输入上表现良好的语言模型，从而在低成本下实现高整体性能。 |
| [^19] | [ETHER: Aligning Emergent Communication for Hindsight Experience Replay.](http://arxiv.org/abs/2307.15494) | 本文提出了ETHER，通过对齐紧急沟通来解决回顾性经验重演中的问题，克服了先前架构依赖预设函数的限制，并提高了数据效率和性能。 |
| [^20] | [Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding.](http://arxiv.org/abs/2307.15484) | 本文提出了两种语音合成方法来解决自回归和非自回归模型中的问题，并在语义编码方面进行了比较研究。 |
| [^21] | [Learning to Rank in Generative Retrieval.](http://arxiv.org/abs/2306.15222) | 这篇论文介绍了一种将生成式检索和经典的学习排序范例相结合的方法，通过使用段落排序损失来训练自回归模型，直接优化自回归模型朝着最优解优化。 |
| [^22] | [ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding.](http://arxiv.org/abs/2305.14196) | ZeroSCROLLS是一个用于长文本自然语言理解的零Shot基准测试，包括六个任务和四个数据集，能够评估大型语言模型的性能。当前，GPT-4的平均得分最高，但在聚合任务等多个挑战上，仍有改进的空间。 |
| [^23] | [IMAD: IMage-Augmented multi-modal Dialogue.](http://arxiv.org/abs/2305.10512) | 该论文提出了一种新颖的多模态对话系统视角，其中图像解释是基于对话上下文的，同时提出了一个两阶段观点来构建多模态对话数据集。 |
| [^24] | [ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4.](http://arxiv.org/abs/2305.07490) | ArtGPT-4是一种基于适配器增强的MiniGPT-4模型，专注于解决图像理解方面的问题，能够在短时间内训练出具备良好视觉语言理解能力的多模态模型。 |
| [^25] | [Knowledge-enhanced Agents for Interactive Text Games.](http://arxiv.org/abs/2305.05091) | 本文提出了一个知识加强的代理框架，用于加强代理在文本游戏中的功能基础，具有记忆先前操作和环境对象可行性两项领域知识，支持三个代表性模型类。 |
| [^26] | [T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering.](http://arxiv.org/abs/2305.03453) | 本研究使用大型语言模型信号教育科学问题回答的链式思维推理，通过生成高质量COT合理化信号，同时降低了人工注释的需求。 |
| [^27] | [UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation.](http://arxiv.org/abs/2303.08518) | UPRISE是一种通用的检索器，可自动为给定的零样本任务输入检索提示，从而提高大型语言模型的零样本评估。它通过跨任务和跨模型的实验展示了其通用性和潜力，同时表明具有减轻幻觉问题和提高LLM性能的能力。 |
| [^28] | [Editing Language Model-based Knowledge Graph Embeddings.](http://arxiv.org/abs/2301.10405) | 本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。 |
| [^29] | [Meta-Referential Games to Learn Compositional Learning Behaviours.](http://arxiv.org/abs/2207.08012) | 本论文提出了一种元元反游戏学习的方法来解决组合学习行为的问题，通过解决绑定问题来支持人工智能代理展示组合学习行为的能力。 |

# 详细

[^1]: 阿拉伯精细化实体识别

    Arabic Fine-Grained Entity Recognition. (arXiv:2310.17333v1 [cs.CL])

    [http://arxiv.org/abs/2310.17333](http://arxiv.org/abs/2310.17333)

    本论文提出了一种阿拉伯精细化实体识别方法，通过扩展现有的阿拉伯命名实体语料库，将地缘政治实体、位置、组织和设施等四种主要实体类型扩展为31个子类型，并通过评估评注者一致性证明了扩展后的效果。

    

    传统的NER系统通常被训练来识别粗粒度实体，并且对将实体分类为细粒度的低层级子类型的关注较少。本文旨在通过精细化实体提升阿拉伯NER。我们选择扩展Wojood（一个开源的嵌套阿拉伯命名实体语料库）的子类型。尤其是，Wojood中的四种主要实体类型，地缘政治实体（GPE），位置（LOC），组织（ORG）和设施（FAC），被扩展为31个子类型。为了做到这一点，我们首先修订了Wojood对GPE，LOC，ORG和FAC的注释，使其与LDC的ACE指南兼容，结果有5614处更改。其次，我们人工注释了Wojood中所有GPE，LOC，ORG和FAC的提及（约44K），使用LDC的ACE子类型。我们将这个扩展版本的Wojood称为WojoodFine。为了评估我们的注释，我们使用Cohen's Kappa和F1得分来测量评注者一致性（IAA），结果分别为0.9861和0.9889

    Traditional NER systems are typically trained to recognize coarse-grained entities, and less attention is given to classifying entities into a hierarchy of fine-grained lower-level subtypes. This article aims to advance Arabic NER with fine-grained entities. We chose to extend Wojood (an open-source Nested Arabic Named Entity Corpus) with subtypes. In particular, four main entity types in Wojood, geopolitical entity (GPE), location (LOC), organization (ORG), and facility (FAC), are extended with 31 subtypes. To do this, we first revised Wojood's annotations of GPE, LOC, ORG, and FAC to be compatible with the LDC's ACE guidelines, which yielded 5, 614 changes. Second, all mentions of GPE, LOC, ORG, and FAC (~44K) in Wojood are manually annotated with the LDC's ACE sub-types. We refer to this extended version of Wojood as WojoodF ine. To evaluate our annotations, we measured the inter-annotator agreement (IAA) using both Cohen's Kappa and F1 score, resulting in 0.9861 and 0.9889, respect
    
[^2]: PoisonPrompt: 基于提示的大型语言模型的后门攻击

    PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models. (arXiv:2310.12439v1 [cs.CL])

    [http://arxiv.org/abs/2310.12439](http://arxiv.org/abs/2310.12439)

    PoisonPrompt是一种新的后门攻击方法，能够成功地破坏基于提示的大型语言模型，该攻击方法的有效性、保真度和鲁棒性经过了广泛实验验证，强调了基于提示的语言模型面临的安全威胁和进一步研究的必要性。

    

    最近，提示显著改善了预训练大型语言模型（LLM）在各种下游任务上的性能，使得它们在各种LLM应用场景中变得越来越不可或缺。然而，对于基于提示的LLM而言，后门漏洞——一种可以恶意更改受害模型正常预测的严重安全威胁——尚未得到充分的探索。本文提出了一种新颖的后门攻击POISONPROMPT，能够成功地破坏硬件和软件基于提示的LLM。我们通过对三种流行的提示方法、六个数据集和三种广泛使用的LLM进行广泛实验来评估POISONPROMPT的有效性、保真度和鲁棒性。我们的研究结果强调了基于提示的LLM受到后门攻击的潜在安全威胁，并强调了在这个领域需要进一步研究的必要性。

    Prompts have significantly improved the performance of pretrained Large Language Models (LLMs) on various downstream tasks recently, making them increasingly indispensable for a diverse range of LLM application scenarios. However, the backdoor vulnerability, a serious security threat that can maliciously alter the victim model's normal predictions, has not been sufficiently explored for prompt-based LLMs. In this paper, we present POISONPROMPT, a novel backdoor attack capable of successfully compromising both hard and soft prompt-based LLMs. We evaluate the effectiveness, fidelity, and robustness of POISONPROMPT through extensive experiments on three popular prompt methods, using six datasets and three widely used LLMs. Our findings highlight the potential security threats posed by backdoor attacks on prompt-based LLMs and emphasize the need for further research in this area.
    
[^3]: 大型语言模型中的事实性调查：知识、检索和领域专属性

    Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity. (arXiv:2310.07521v1 [cs.CL])

    [http://arxiv.org/abs/2310.07521](http://arxiv.org/abs/2310.07521)

    这项调查研究了大型语言模型（LLMs）中的事实性问题，包括其可能带来的后果和挑战，以及存储、处理和评估事实的方法。同时，提出了一些增强LLM事实性的策略，涵盖了不同领域的需求。

    

    本调查研究了大型语言模型（LLMs）中的关键问题，即事实性。由于LLMs在不同领域中都有应用，它们的输出的可靠性和准确性变得至关重要。我们将事实性问题定义为LLMs产生与已确立事实不一致的内容的概率。我们首先深入探讨了这些不准确性的含义，突出了事实错误在LLMs输出中可能带来的潜在后果和挑战。随后，我们分析了LLMs存储和处理事实的机制，寻找事实错误的主要原因。我们的讨论随后转向评估LLM事实性的方法论，强调关键指标、基准和研究。我们进一步探讨了增强LLM事实性的策略，包括针对特定领域的方法。我们重点关注两种主要的LLM配置，独立LLMs和利用外部数据的检索增强LLMs，详细介绍它们的独特挑战和潜在解决方法。

    This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential 
    
[^4]: 循环神经语言模型作为概率有限状态自动机

    Recurrent Neural Language Models as Probabilistic Finite-state Automata. (arXiv:2310.05161v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05161](http://arxiv.org/abs/2310.05161)

    本文研究了循环神经网络语言模型（RNN LMs）作为概率有限状态自动机的能力，并发现它们只能表示有限状态模型所能表达的概率分布的一个严格子集。

    

    通过以容易理解的形式来研究语言模型（LMs）可以使我们精确地描述它们的能力和局限性。先前的研究已经考察了循环神经网络（RNN）语言模型在识别无权重形式语言的能力。然而，LMs并不描述无权重形式语言，而是定义了对字符串的概率分布。在本研究中，我们研究了RNN LMs可以表示哪些类的概率分布，这使得我们可以更直接地陈述它们的能力。我们证明了简单的RNN等价于概率有限状态自动机的一个子类，因此只能模拟有限状态模型所能表达的概率分布的一个严格子集。此外，我们研究了用RNNs表示有限状态LMs的空间复杂度。我们证明了，为了表示一个任意确定的有限状态LMs，其中有$N$个状态且字符集为$\Sigma$的RNN requir

    Studying language models (LMs) in terms of well-understood formalisms allows us to precisely characterize their abilities and limitations. Previous work has investigated the representational capacity of recurrent neural network (RNN) LMs in terms of their capacity to recognize unweighted formal languages. However, LMs do not describe unweighted formal languages -- rather, they define probability distributions over strings. In this work, we study what classes of such probability distributions RNN LMs can represent, which allows us to make more direct statements about their capabilities. We show that simple RNNs are equivalent to a subclass of probabilistic finite-state automata, and can thus model a strict subset of probability distributions expressible by finite-state models. Furthermore, we study the space complexity of representing finite-state LMs with RNNs. We show that, to represent an arbitrary deterministic finite-state LM with $N$ states over an alphabet $\Sigma$, an RNN requir
    
[^5]: 使用语音语句对的零资源切换语音基准进行多语言评估

    Zero Resource Code-switched Speech Benchmark Using Speech Utterance Pairs For Multiple Spoken Languages. (arXiv:2310.03018v1 [eess.AS])

    [http://arxiv.org/abs/2310.03018](http://arxiv.org/abs/2310.03018)

    本论文介绍了一个新的零资源切换语音基准，用于评估自监督语音编码器的切换语言能力，研究了预训练语言和模型大小对基准性能的影响，结果显示多语言预训练的语音编码器在切换语言场景中表现优于单语变体，但仍有改进空间。

    

    我们引入了一个新的零资源切换语音基准，旨在直接评估自监督语音编码器的切换语言能力。我们展示了一种基于离散单元语言建模的基线系统，以展示如何以零资源的方式评估语音编码器的切换语言能力。我们的实验涵盖了各种知名的语音编码器，包括Wav2vec 2.0、HuBERT、XLSR等。我们研究了预训练语言和模型大小对基准性能的影响。值得注意的是，尽管我们的结果表明，在切换语言场景中，具有多语言预训练的语音编码器（例如XLSR）优于单语变体（Wav2vec 2.0、HuBERT），但它们的切换语言能力仍有很大的改进空间。

    We introduce a new zero resource code-switched speech benchmark designed to directly assess the code-switching capabilities of self-supervised speech encoders. We showcase a baseline system of language modeling on discrete units to demonstrate how the code-switching abilities of speech encoders can be assessed in a zero-resource manner. Our experiments encompass a variety of well-known speech encoders, including Wav2vec 2.0, HuBERT, XLSR, etc. We examine the impact of pre-training languages and model size on benchmark performance. Notably, though our results demonstrate that speech encoders with multilingual pre-training, exemplified by XLSR, outperform monolingual variants (Wav2vec 2.0, HuBERT) in code-switching scenarios, there is still substantial room for improvement in their code-switching linguistic abilities.
    
[^6]: RLAdapter：在开放环境中将大型语言模型与强化学习相结合

    RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds. (arXiv:2309.17176v1 [cs.AI])

    [http://arxiv.org/abs/2309.17176](http://arxiv.org/abs/2309.17176)

    RLAdapter引入了一个框架，将大型语言模型（LLM）与强化学习相结合，以提高在稀疏奖励环境中的策略学习性能。这通过解决LLM在理解下游任务方面的困难，以及通过避免使用不可访问的模型权重或大量计算资源来微调LLM的方式实现。

    

    强化学习在决策问题中取得了显著的成功，但通常需要与环境进行大量的交互，在稀疏奖励环境中学习有意义的策略是具有挑战性的。大型语言模型（LLM）可以为代理提供有价值的指导，从而增强RL算法在这些环境中的性能。然而，LLM通常在理解下游任务方面遇到困难，这阻碍了它们在这些任务中最优地帮助代理的能力。缓解这个问题的常见方法是使用与任务相关的数据来微调LLM，使其能够为RL代理提供有用的指导。然而，这种方法遇到了一些困难，比如无法访问的模型权重或需要大量的计算资源，使其不切实际。在这项工作中，我们引入了RLAdapter，这是一个框架，在RL算法和LLM之间建立更好的连接，从而整合它们的优势和能力。

    While reinforcement learning (RL) shows remarkable success in decision-making problems, it often requires a lot of interactions with the environment, and in sparse-reward environments, it is challenging to learn meaningful policies. Large Language Models (LLMs) can potentially provide valuable guidance to agents in learning policies, thereby enhancing the performance of RL algorithms in such environments. However, LLMs often encounter difficulties in understanding downstream tasks, which hinders their ability to optimally assist agents in these tasks. A common approach to mitigating this issue is to fine-tune the LLMs with task-related data, enabling them to offer useful guidance for RL agents. However, this approach encounters several difficulties, such as inaccessible model weights or the need for significant computational resources, making it impractical. In this work, we introduce RLAdapter, a framework that builds a better connection between RL algorithms and LLMs by incorporating
    
[^7]: 使用最少监督的扩散模型实现高保真度语音合成

    High-Fidelity Speech Synthesis with Minimal Supervision: All Using Diffusion Models. (arXiv:2309.15512v1 [cs.SD])

    [http://arxiv.org/abs/2309.15512](http://arxiv.org/abs/2309.15512)

    提出一种使用最少监督的扩散模型实现高保真度语音合成的方法，通过组合离散语音表示和利用序列到序列任务进行训练，解决了语义表示中的信息冗余和维度爆炸以及离散声学表示中的高频波形失真等问题。该方法中的非自回归框架增强了可控性，而持续时间扩散模型实现了音频的多样化控制。

    

    文字转语音（TTS）方法在语音克隆方面取得了有希望的结果，但需要大量标记的文本-语音对。最小监督的语音合成通过组合两种类型的离散语音表示（语义和声学），并使用两种序列到序列任务，以实现最少监督的训练。然而，现有方法存在语义表示中的信息冗余和维度爆炸，以及离散声学表示中的高频波形失真。自回归框架具有典型的不稳定性和不可控性问题。非自回归框架受到持续预测模型引起的韵律平均化的影响。为了解决这些问题，我们提出了一种最小监督的高保真度语音合成方法，其中所有模块基于扩散模型构建。非自回归框架增强了可控性，而持续时间扩散模型实现了音频的多样化控制。

    Text-to-speech (TTS) methods have shown promising results in voice cloning, but they require a large number of labeled text-speech pairs. Minimally-supervised speech synthesis decouples TTS by combining two types of discrete speech representations(semantic \& acoustic) and using two sequence-to-sequence tasks to enable training with minimal supervision. However, existing methods suffer from information redundancy and dimension explosion in semantic representation, and high-frequency waveform distortion in discrete acoustic representation. Autoregressive frameworks exhibit typical instability and uncontrollability issues. And non-autoregressive frameworks suffer from prosodic averaging caused by duration prediction models. To address these issues, we propose a minimally-supervised high-fidelity speech synthesis method, where all modules are constructed based on the diffusion models. The non-autoregressive framework enhances controllability, and the duration diffusion model enables diver
    
[^8]: 双模态注意增强的文本-视频检索与三元部分边际对比学习

    Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning. (arXiv:2309.11082v1 [cs.CV])

    [http://arxiv.org/abs/2309.11082](http://arxiv.org/abs/2309.11082)

    本文提出了一种双模态注意增强的文本-视频检索方法，通过引入新颖的对比学习技术，能够准确衡量跨模态相似性和挖掘难负样本。

    

    近年来，网络视频的爆炸性增长使得文本-视频检索对于视频过滤、推荐和搜索变得越来越重要和流行。文本-视频检索旨在将相关的文本/视频排在不相关的文本/视频之前。该任务的核心是准确衡量文本和视频之间的跨模态相似性。最近，对比学习方法在文本-视频检索方面显示出有希望的结果，其中大部分方法侧重于构建正负样本对以学习文本和视频表示。然而，他们在关注难负样本和模拟不同层次的语义相似性方面不够，存在两个问题。为了解决这两个问题，本文使用两个新方法改进了对比学习。首先，为了利用艰难的例子来提高鲁棒的判别能力，我们提出了一种新颖的双模态注意增强模块(DMAE)，从文本和视觉线索中挖掘难负样本。通过进一步引入一个负面样本筛选机制，该方法可以建模不同级别的语义相似性。

    In recent years, the explosion of web videos makes text-video retrieval increasingly essential and popular for video filtering, recommendation, and search. Text-video retrieval aims to rank relevant text/video higher than irrelevant ones. The core of this task is to precisely measure the cross-modal similarity between texts and videos. Recently, contrastive learning methods have shown promising results for text-video retrieval, most of which focus on the construction of positive and negative pairs to learn text and video representations. Nevertheless, they do not pay enough attention to hard negative pairs and lack the ability to model different levels of semantic similarity. To address these two issues, this paper improves contrastive learning using two novel techniques. First, to exploit hard examples for robust discriminative power, we propose a novel Dual-Modal Attention-Enhanced Module (DMAE) to mine hard negative pairs from textual and visual clues. By further introducing a Negat
    
[^9]: DePT:分解提示调整以实现参数高效微调

    DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning. (arXiv:2309.05173v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05173](http://arxiv.org/abs/2309.05173)

    DePT通过将软提示分解为较短的软提示和一对低秩矩阵，并用两个不同的学习率来优化，以解决提示调整对训练和推理时间以及内存使用的影响，从而实现更好的性能。

    

    提示调整（PT）是一种将可训练的少量软提示向量附加到语言模型（LM）输入中的参数高效微调（PEFT）方法，已在各种任务和模型中显示出了有希望的结果。 与其他PEFT方法相比，PT的竞争性能可以在可训练参数更少的情况下保持，并且随着模型规模的扩大，其参数并不会显著增加。 但是，PT引入了额外的软提示标记，导致输入序列变长，这对于Transformer的二次复杂度而言，在训练和推理时间以及内存使用方面会产生显著影响。 这对于面临大量每日查询的大型语言模型（LLMs）尤其令人担忧。

    Prompt tuning (PT), where a small amount of trainable soft (continuous) prompt vectors is affixed to the input of language models (LM), has shown promising results across various tasks and models for parameter-efficient fine-tuning (PEFT). PT stands out from other PEFT approaches because it maintains competitive performance with fewer trainable parameters and does not drastically scale up its parameters as the model size expands. However, PT introduces additional soft prompt tokens, leading to longer input sequences, which significantly impacts training and inference time and memory usage due to the Transformer's quadratic complexity. Particularly concerning for Large Language Models (LLMs) that face heavy daily querying. To address this issue, we propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt into a shorter soft prompt and a pair of low-rank matrices that are then optimised with two different learning rates. This allows DePT to achieve better performance whi
    
[^10]: CPSP: 从音素监督中学习语音概念

    CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])

    [http://arxiv.org/abs/2309.00424](http://arxiv.org/abs/2309.00424)

    论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。

    

    对于诸如最小监督的文本转语音（TTS）、语音转换（VC）和自动语音识别（ASR）等细粒度生成和识别任务，从语音中提取的中间表示应包含介于文本编码和声学编码之间的信息。语言内容突出，而发言人身份和声学细节等语音信息应该被去除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余性过高和维度爆炸的问题。此外，音频领域中现有的对比学习方法主要关注提取用于下游音频分类任务的全局描述信息，不适合TTS、VC和ASR任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练（CPSP）的方法，该方法使用三个编码器、一个解码器和对比学习来将音素和语音信息相结合。

    For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representation extracted from speech should contain information that is between text coding and acoustic coding. The linguistic content is salient, while the paralinguistic information such as speaker identity and acoustic details should be removed. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Additionally, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named Contrastive Phoneme-Speech Pretraining (CPSP), which uses three encoders, one decoder, and contrastive learning to bring phoneme and speech
    
[^11]: 什么时候编程思维对推理起作用?

    When Do Program-of-Thoughts Work for Reasoning?. (arXiv:2308.15452v1 [cs.CL])

    [http://arxiv.org/abs/2308.15452](http://arxiv.org/abs/2308.15452)

    提出了复杂性影响推理分数（CIRS）来衡量编程语言对推理能力的影响，发现并非所有复杂性的代码数据都可以被学习或理解，适当的复杂性水平对于改善推理能力至关重要。

    

    大型语言模型（LLM）的推理能力在体现出人工智能领域中起着关键作用。尽管像编程思维提示这样的方法对于使用编程语言来解决复杂推理任务的LLM非常有效，但代码数据对推理能力的具体影响仍未充分探索。为了填补这一空白，我们提出了复杂性影响推理分数（CIRS），它结合了结构和逻辑属性，以衡量代码和推理能力之间的相关性。具体而言，我们使用抽象语法树来编码结构信息，并通过考虑难度和圈复杂度来计算逻辑复杂性。通过实证分析，我们发现并非所有复杂性的代码数据都可以被LLM学习或理解。最佳复杂性水平对于通过编程辅助提示改善推理能力至关重要。然后我们设计了一个自动合成的方法...

    The reasoning capabilities of Large Language Models (LLMs) play a pivotal role in the realm of embodied artificial intelligence. Although there are effective methods like program-of-thought prompting for LLMs which uses programming language to tackle complex reasoning tasks, the specific impact of code data on the improvement of reasoning capabilities remains under-explored. To address this gap, we propose complexity-impacted reasoning score (CIRS), which combines structural and logical attributes, to measure the correlation between code and reasoning abilities. Specifically, we use the abstract syntax tree to encode the structural information and calculate logical complexity by considering the difficulty and the cyclomatic complexity. Through an empirical analysis, we find not all code data of complexity can be learned or understood by LLMs. Optimal level of complexity is critical to the improvement of reasoning abilities by program-aided prompting. Then we design an auto-synthesizing
    
[^12]: 如何评估检测的泛化能力？一种用于全面开放词汇检测的基准测试方法

    How to Evaluate the Generalization of Detection? A Benchmark for Comprehensive Open-Vocabulary Detection. (arXiv:2308.13177v1 [cs.CV])

    [http://arxiv.org/abs/2308.13177](http://arxiv.org/abs/2308.13177)

    提出了一个名为OVDEval的新的基准测试方法，用于全面开放词汇检测。该方法包括9个子任务，并引入了常识知识、属性理解、位置理解、对象关系理解等方面的评估。数据集被精心创建以提供具有挑战性的负例，考验模型对视觉和语言输入的真正理解。此外，该方法发现了平均精确度（AP）指标在这些细粒度标签数据集上的问题，并提出了一种新指标。

    

    计算机视觉中的目标检测在近年取得了显著的进展，从基于封闭集标签到基于大规模视觉语言预训练的开放词汇检测（OVD）。然而，当前的评估方法和数据集仅限于测试对象类型和引用表达的泛化能力，无法提供OVD模型能力的系统、细粒度和准确的基准。在本文中，我们提出了一个名为OVDEval的新基准测试方法，包括9个子任务，并引入了常识知识、属性理解、位置理解、对象关系理解等方面的评估。数据集被精心创建以提供具有挑战性的负例，考验模型对视觉和语言输入的真正理解。此外，我们还发现了在这些细粒度标签数据集上对模型进行基准测试时普遍使用的平均精确度（AP）指标存在的问题，并提出了一种名为非极大值抑制的新指标。

    Object detection (OD) in computer vision has made significant progress in recent years, transitioning from closed-set labels to open-vocabulary detection (OVD) based on large-scale vision-language pre-training (VLP). However, current evaluation methods and datasets are limited to testing generalization over object types and referral expressions, which do not provide a systematic, fine-grained, and accurate benchmark of OVD models' abilities. In this paper, we propose a new benchmark named OVDEval, which includes 9 sub-tasks and introduces evaluations on commonsense knowledge, attribute understanding, position understanding, object relation comprehension, and more. The dataset is meticulously created to provide hard negatives that challenge models' true understanding of visual and linguistic input. Additionally, we identify a problem with the popular Average Precision (AP) metric when benchmarking models on these fine-grained label datasets and propose a new metric called Non-Maximum Su
    
[^13]: 使用多条件扩散模型进行音频生成

    Audio Generation with Multiple Conditional Diffusion Model. (arXiv:2308.11940v1 [cs.SD])

    [http://arxiv.org/abs/2308.11940](http://arxiv.org/abs/2308.11940)

    本论文提出了一种使用多条件扩散模型进行音频生成的方法。通过引入内容和风格等额外条件，增强了现有模型的可控性。这种方法可以精确控制生成音频的时间顺序、音高和能量。由于缺乏合适的数据集和评估指标，作者整合了现有数据集并进行了实验验证。

    

    基于文本的音频生成模型有其局限性，因为它们无法包含音频中的所有信息，仅依靠文本会导致受控性受限。为了解决这个问题，我们提出了一种新颖的模型，通过引入额外的条件（包括内容（时间戳）和风格（音高曲线和能量曲线））作为文本的补充，增强了现有预训练文本到音频模型的可控性。这种方法实现了对生成音频的时间顺序、音高和能量的精细控制。为了保持生成的多样性，我们使用一个可训练的控制条件编码器，该编码器由一个大型语言模型增强，并使用一个可训练的融合网络来编码和融合额外的条件，同时保持预训练文本到音频模型的权重不变。由于缺乏合适的数据集和评估指标，我们将现有数据集整合为一个新的数据集，包括音频和相应的条件，并使用一个可训练的控制条件编码器，该编码器由一个大型语言模型增强，并使用一个可训练的融合网络来编码和融合额外的条件，同时保持预训练文本到音频模型的权重不变。

    Text-based audio generation models have limitations as they cannot encompass all the information in audio, leading to restricted controllability when relying solely on text. To address this issue, we propose a novel model that enhances the controllability of existing pre-trained text-to-audio models by incorporating additional conditions including content (timestamp) and style (pitch contour and energy contour) as supplements to the text. This approach achieves fine-grained control over the temporal order, pitch, and energy of generated audio. To preserve the diversity of generation, we employ a trainable control condition encoder that is enhanced by a large language model and a trainable Fusion-Net to encode and fuse the additional conditions while keeping the weights of the pre-trained text-to-audio model frozen. Due to the lack of suitable datasets and evaluation metrics, we consolidate existing datasets into a new dataset comprising the audio and corresponding conditions and use a 
    
[^14]: 多文档问答中的知识图谱引导

    Knowledge Graph Prompting for Multi-Document Question Answering. (arXiv:2308.11730v1 [cs.CL])

    [http://arxiv.org/abs/2308.11730](http://arxiv.org/abs/2308.11730)

    这篇论文提出了一种知识图谱引导的方法，用于在多文档问答任务中为大型语言模型（LLMs）提示正确的上下文。通过构建多个文档上的知识图谱，并设计基于语言模型的图遍历器，该方法能够帮助LLMs在MD-QA中进行答案预测。

    

    大型语言模型（LLMs）的“预训练、提示、预测”范式在开放域问答（OD-QA）中取得了显著的成功。然而，很少有工作在多文档问答（MD-QA）场景下探索这个范式，这是一个要求对不同文档的内容和结构之间的逻辑关联有深入理解的任务。为了填补这一重要的空白，我们提出了一种知识图谱引导（KGP）方法，用于在MD-QA中为LLMs提示正确的上下文，该方法包括图构建模块和图遍历模块。对于图构建，我们使用节点来表示文段或文档结构（例如，页面/表格），而使用边来表示文段之间的语义/词汇相似性或者文档内的结构关系。对于图遍历，我们设计了一个基于LM的图遍历器，它在节点之间导航并收集支持性的文段，以帮助LLMs在MD-QA中进行答案预测。

    The 'pre-train, prompt, predict' paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in the scenario of multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of different documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or intra-document structural relations. For graph traversal, we design an LM-guided graph traverser that navigates across nodes and gathers supporting passages assisting LLMs in MD
    
[^15]: BLIVA: 一个简单的多模态LLM用于更好地处理文本丰富的视觉问题

    BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions. (arXiv:2308.09936v1 [cs.CV])

    [http://arxiv.org/abs/2308.09936](http://arxiv.org/abs/2308.09936)

    BLIVA是一个简单的多模态LLM模型，用于更好地处理嵌入了文本的图像上下文场景。它通过引入InstructBLIP的查询嵌入和LLaVA的编码补丁嵌入技术来改进视觉语言模型，从而有效解决了文本丰富的视觉问题。

    

    视觉语言模型（VLM）通过整合视觉理解能力扩展了大规模语言模型（LLM），在解决开放式视觉问答（VQA）任务方面取得了显著进展。然而，这些模型无法准确解释嵌入文本的图像，这在现实场景中经常发生。从图像中提取信息的标准流程通常涉及学习一组固定的查询嵌入。这些嵌入被设计为封装图像上下文，并随后用作LLM中的软提示输入。然而，这个过程受令牌数量的限制，可能限制对文本丰富的上下文场景的识别。为了改进这一点，本研究引入了BLIVA：InstructBLIP with Visual Assistant的增强版本。BLIVA集成了来自InstructBLIP的查询嵌入，并将编码的补丁嵌入直接投影到LLM中，这是受到LLaVA的启发的一种技术。这种方法有助于处理文本丰富的视觉问题。

    Vision Language Models (VLMs), which extend Large Language Models (LLM) by incorporating visual understanding capability, have demonstrated significant advancements in addressing open-ended visual question-answering (VQA) tasks. However, these models cannot accurately interpret images infused with text, a common occurrence in real-world scenarios. Standard procedures for extracting information from images often involve learning a fixed set of query embeddings. These embeddings are designed to encapsulate image contexts and are later used as soft prompt inputs in LLMs. Yet, this process is limited to the token count, potentially curtailing the recognition of scenes with text-rich context. To improve upon them, the present study introduces BLIVA: an augmented version of InstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings from InstructBLIP and also directly projects encoded patch embeddings into the LLM, a technique inspired by LLaVA. This approach assists the mode
    
[^16]: 关于大型语言模型的意想不到能力

    On the Unexpected Abilities of Large Language Models. (arXiv:2308.09720v1 [cs.AI])

    [http://arxiv.org/abs/2308.09720](http://arxiv.org/abs/2308.09720)

    大型语言模型展示了与其训练任务不直接相关的广泛能力，通过间接获取过程使其拥有综合能力的发展，这些能力在一定程度上可预测，并且与人类认知有关。

    

    大型语言模型能展示出与其训练任务（预测人类书写文本的下一个单词）不直接相关的广泛能力。本文讨论了这种间接获取过程的性质及其与其他已知间接过程的关系。文章主张这种间接获取的一个重要副作用是综合能力的发展。本文还讨论了大型语言模型所开发的能力在多大程度上是可预测的。最后，文章简要讨论了这些系统所获得的认知技能与人类认知之间的关系。

    Large language models are capable of displaying a wide range of abilities that are not directly connected with the task for which they are trained: predicting the next words of human-written texts. In this article, I discuss the nature of this indirect acquisition process and its relation to other known indirect processes. I argue that an important side effect of such indirect acquisition is the development of integrated abilities. I discuss the extent to which the abilities developed by large language models are predictable. Finally, I briefly discuss the relation between the cognitive skills acquired by these systems and human cognition.
    
[^17]: 《中文拼写纠错作为改写语言模型》

    Chinese Spelling Correction as Rephrasing Language Model. (arXiv:2308.08796v1 [cs.CL])

    [http://arxiv.org/abs/2308.08796](http://arxiv.org/abs/2308.08796)

    本文提出了一种新颖的中文拼写纠错方法，通过改写语言建模来重新表达整个句子，而不是仅仅依赖错误模式进行字符级别标注，取得了最新的最优结果。

    

    本文研究了中文拼写纠错（CSC），旨在检测和纠正给定句子中的潜在拼写错误。目前最先进的方法将CSC视为序列标注任务，并在句子对上微调基于BERT的模型。然而，我们注意到在将一个字符标记为另一个字符的过程中存在一个关键缺陷，即纠正过程过于依赖错误。这与人类思维相反，人们根据句子的语义重新表达整个句子，而不仅仅是基于之前记忆的错误模式。这种违反直觉的学习过程导致机器拼写纠错的泛化能力和可迁移性受到限制。为了解决这个问题，我们提出了“改写语言建模”（ReLM），其中模型通过填充额外的位置来重新表达整个句子，而不是进行字符级别的标注。这种新颖的训练范式在微调后取得了最新的最优结果。

    This paper studies Chinese Spelling Correction (CSC), which aims to detect and correct potential spelling errors in a given sentence. Current state-of-the-art methods regard CSC as a sequence tagging task and fine-tune BERT-based models on sentence pairs. However, we note a critical flaw in the process of tagging one character to another, that the correction is excessively conditioned on the error. This is opposite from human mindset, where individuals rephrase the complete sentence based on its semantics, rather than solely on the error patterns memorized before. Such a counter-intuitive learning process results in the bottleneck of generalizability and transferability of machine spelling correction. To address this, we propose $Rephrasing Language Modeling$ (ReLM), where the model is trained to rephrase the entire sentence by infilling additional slots, instead of character-to-character tagging. This novel training paradigm achieves the new state-of-the-art results across fine-tuned 
    
[^18]: 飞拍或大炮？通过元模型选择经济有效的语言模型

    Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling. (arXiv:2308.06077v1 [cs.CL])

    [http://arxiv.org/abs/2308.06077](http://arxiv.org/abs/2308.06077)

    本文提出了一种经济有效的语言模型选择框架（CELMOC），通过元模型预测在不同输入上表现良好的语言模型，从而在低成本下实现高整体性能。

    

    生成式语言模型在数据科学领域中变得无处不在。对于各种任务，可以将输入作为自然语言提示，通过LM的输出来提取解决方案。LM的性能随着模型大小的增加而不断提高，但同时查询越来越大的模型的经济成本也在增加。然而，不是所有的输入都很难：有些输入需要更大的LM才能获得令人满意的解决方案，而对于其他输入，较小的LM就足够了。基于这个事实，我们设计了一个经济有效的语言模型选择框架（CELMOC）。给定一组输入和一组候选LM，CELMOC根据所谓的元模型聪明地将每个输入分配给一个在该输入上预测表现良好的LM，以期在低成本下实现高整体性能。用户可以灵活调整成本与性能的权衡。选项包括，最大化总体性能（或处理输入的数量）等。

    Generative language models (LMs) have become omnipresent across data science. For a wide variety of tasks, inputs can be phrased as natural language prompts for an LM, from whose output the solution can then be extracted. LM performance has consistently been increasing with model size - but so has the monetary cost of querying the ever larger models. Importantly, however, not all inputs are equally hard: some require larger LMs for obtaining a satisfactory solution, whereas for others smaller LMs suffice. Based on this fact, we design a framework for Cost-Effective Language Model Choice (CELMOC). Given a set of inputs and a set of candidate LMs, CELMOC judiciously assigns each input to an LM predicted to do well on the input according to a so-called meta-model, aiming to achieve high overall performance at low cost. The cost-performance trade-off can be flexibly tuned by the user. Options include, among others, maximizing total expected performance (or the number of processed inputs) w
    
[^19]: ETHER: 对于回顾性经验重演的紧密沟通对齐

    ETHER: Aligning Emergent Communication for Hindsight Experience Replay. (arXiv:2307.15494v1 [cs.CL])

    [http://arxiv.org/abs/2307.15494](http://arxiv.org/abs/2307.15494)

    本文提出了ETHER，通过对齐紧急沟通来解决回顾性经验重演中的问题，克服了先前架构依赖预设函数的限制，并提高了数据效率和性能。

    

    自然语言指令的跟随对于实现人工智能代理和人类之间的合作至关重要。自然语言条件下的强化学习代理展示了自然语言的特性，如组合性，能够提供学习复杂策略的强归纳偏好。先前的架构如HIGhER结合了语言条件与回顾性经验重演（HER）来处理稀疏奖励环境。然而，与HER类似，HIGhER依赖于一个预设的函数来提供反馈信号，指示哪种语言描述在哪种状态下有效。这种依赖于预设函数的限制限制了其应用。此外，HIGhER只利用成功的强化学习轨迹中包含的语言信息，从而影响了其最终性能和数据效率。没有早期成功轨迹，HIGhER并不比其构建于之上的DQN更好。在本文中，我们提出了紧密文本回顾性经验。

    Natural language instruction following is paramount to enable collaboration between artificial agents and human beings. Natural language-conditioned reinforcement learning (RL) agents have shown how natural languages' properties, such as compositionality, can provide a strong inductive bias to learn complex policies. Previous architectures like HIGhER combine the benefit of language-conditioning with Hindsight Experience Replay (HER) to deal with sparse rewards environments. Yet, like HER, HIGhER relies on an oracle predicate function to provide a feedback signal highlighting which linguistic description is valid for which state. This reliance on an oracle limits its application. Additionally, HIGhER only leverages the linguistic information contained in successful RL trajectories, thus hurting its final performance and data-efficiency. Without early successful trajectories, HIGhER is no better than DQN upon which it is built. In this paper, we propose the Emergent Textual Hindsight Ex
    
[^20]: 用条件扩散模型和语言模型进行最小监督语音合成：基于语义编码的比较研究

    Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding. (arXiv:2307.15484v1 [cs.SD])

    [http://arxiv.org/abs/2307.15484](http://arxiv.org/abs/2307.15484)

    本文提出了两种语音合成方法来解决自回归和非自回归模型中的问题，并在语义编码方面进行了比较研究。

    

    近年来，对于能够采用最小监督训练方法的文本到语音(TTS)技术越来越受关注，该方法通过结合两种离散语音表示并使用两种序列到序列任务来解耦TTS。为了解决离散表示中的高维度和波形失真的挑战，我们提出了Diff-LM-Speech方法，该方法基于扩散模型将语义嵌入模型为基于mel频谱图，并引入基于变分自动编码器和韵律瓶颈的提示编码结构，以提高提示表示能力。自回归语言模型常常遇到缺失和重复单词的问题，而非自回归框架由于预测模型的存在导致表达平均问题。为了解决这些问题，我们提出了Tetra-Diff-Speech，该方法设计了一个时长扩散模型以实现多样化的韵律表达。我们期望语义编码的信息内容介于...

    Recently, there has been a growing interest in text-to-speech (TTS) methods that can be trained with minimal supervision by combining two types of discrete speech representations and using two sequence-to-sequence tasks to decouple TTS. To address the challenges associated with high dimensionality and waveform distortion in discrete representations, we propose Diff-LM-Speech, which models semantic embeddings into mel-spectrogram based on diffusion models and introduces a prompt encoder structure based on variational autoencoders and prosody bottlenecks to improve prompt representation capabilities. Autoregressive language models often suffer from missing and repeated words, while non-autoregressive frameworks face expression averaging problems due to duration prediction models. To address these issues, we propose Tetra-Diff-Speech, which designs a duration diffusion model to achieve diverse prosodic expressions. While we expect the information content of semantic coding to be between t
    
[^21]: 学习在生成式检索中进行排序

    Learning to Rank in Generative Retrieval. (arXiv:2306.15222v1 [cs.CL])

    [http://arxiv.org/abs/2306.15222](http://arxiv.org/abs/2306.15222)

    这篇论文介绍了一种将生成式检索和经典的学习排序范例相结合的方法，通过使用段落排序损失来训练自回归模型，直接优化自回归模型朝着最优解优化。

    

    生成式检索是一种有前景的文本检索范例，它将相关段落的标识符字符串生成为检索目标。这种范例利用强大的生成模型，并代表了与传统的学习排序方法有所不同的新范例。然而，尽管其快速发展，当前的生成式检索方法仍存在局限性。它们通常依赖启发式函数将预测的标识符转换为段落排序列表，这在生成式检索的学习目标与期望的段落排序目标之间产生了差距。此外，文本生成的固有曝光偏差问题在生成式检索中仍然存在。为了解决这些问题，我们提出了一种新颖的框架，称为LTRGR，它将生成式检索与经典的学习排序范例相结合。我们的方法涉及使用段落排序损失训练一个自回归模型，该损失直接优化自回归模型朝着最优解优化。

    Generative retrieval is a promising new paradigm in text retrieval that generates identifier strings of relevant passages as the retrieval target. This paradigm leverages powerful generation models and represents a new paradigm distinct from traditional learning-to-rank methods. However, despite its rapid development, current generative retrieval methods are still limited. They typically rely on a heuristic function to transform predicted identifiers into a passage rank list, which creates a gap between the learning objective of generative retrieval and the desired passage ranking target. Moreover, the inherent exposure bias problem of text generation also persists in generative retrieval. To address these issues, we propose a novel framework, called LTRGR, that combines generative retrieval with the classical learning-to-rank paradigm. Our approach involves training an autoregressive model using a passage rank loss, which directly optimizes the autoregressive model toward the optimal 
    
[^22]: ZeroSCROLLS：一个用于长文本理解的零Shot基准测试

    ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding. (arXiv:2305.14196v1 [cs.CL])

    [http://arxiv.org/abs/2305.14196](http://arxiv.org/abs/2305.14196)

    ZeroSCROLLS是一个用于长文本自然语言理解的零Shot基准测试，包括六个任务和四个数据集，能够评估大型语言模型的性能。当前，GPT-4的平均得分最高，但在聚合任务等多个挑战上，仍有改进的空间。

    

    我们介绍了 ZeroSCROLLS，这是一个用于长文本自然语言理解的零Shot基准测试，仅包含测试集而没有训练或开发数据。我们从SCROLLS基准测试中适应了六个任务，并添加了四个新数据集，包括两个新的信息融合任务，例如聚合正面评价的百分比。使用ZeroSCROLLS，我们对开源和闭源大型语言模型进行了全面评估，发现Claude优于ChatGPT，并且GPT-4获得了最高的平均分数。然而，在ZeroSCROLLS的多个开放挑战方面（例如，聚合任务），还有改进的空间，因为模型很难通过朴素的基准测试。由于最先进的技术还在不断更新，我们邀请研究人员在实时的ZeroSCROLLS排行榜上评估他们的想法。

    We introduce ZeroSCROLLS, a zero-shot benchmark for natural language understanding over long texts, which contains only test sets, without training or development data. We adapt six tasks from the SCROLLS benchmark, and add four new datasets, including two novel information fusing tasks, such as aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a comprehensive evaluation of both open-source and closed large language models, finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest average score. However, there is still room for improvement on multiple open challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to pass the naive baseline. As the state of the art is a moving target, we invite researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard
    
[^23]: IMAD: 图像增强的多模式对话

    IMAD: IMage-Augmented multi-modal Dialogue. (arXiv:2305.10512v1 [cs.CL])

    [http://arxiv.org/abs/2305.10512](http://arxiv.org/abs/2305.10512)

    该论文提出了一种新颖的多模态对话系统视角，其中图像解释是基于对话上下文的，同时提出了一个两阶段观点来构建多模态对话数据集。

    

    目前，对话系统已经在处理基于文本的通讯方面取得了高性能。然而，它们还没有有效地融合视觉信息，这是一个重要的挑战。此外，现有的在对话生成中融合图像的模型专注于讨论图像本身。我们提出的方法提供了一种新颖的多模态对话系统视角，解释了对话中图像的上下文。通过这样做，我们旨在扩展当前对话系统的能力，从单一模式（文本）向多模态转换。然而，缺乏包含图像和对话上下文的经过验证的英文数据集是这项任务的难点。因此，我们提出了一个两阶段的方法来自动构建多模态对话数据集。在第一阶段，我们利用文本到图像的相似性和句子相似性来识别哪些话语可以用图像替换。在第二阶段，我们替换那些话语。

    Currently, dialogue systems have achieved high performance in processing text-based communication. However, they have not yet effectively incorporated visual information, which poses a significant challenge. Furthermore, existing models that incorporate images in dialogue generation focus on discussing the image itself. Our proposed approach presents a novel perspective on multi-modal dialogue systems, which interprets the image in the context of the dialogue. By doing so, we aim to expand the capabilities of current dialogue systems and transition them from single modality (text) to multi-modality. However, there is a lack of validated English datasets that contain both images and dialogue contexts for this task. Thus, we propose a two-stage approach to automatically construct a multi-modal dialogue dataset. In the first stage, we utilize text-to-image similarity and sentence similarity to identify which utterances could be replaced with an image. In the second stage, we replace those
    
[^24]: ArtGPT-4: 基于适配器增强的MiniGPT-4模型的艺术视觉语言理解

    ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4. (arXiv:2305.07490v1 [cs.CL])

    [http://arxiv.org/abs/2305.07490](http://arxiv.org/abs/2305.07490)

    ArtGPT-4是一种基于适配器增强的MiniGPT-4模型，专注于解决图像理解方面的问题，能够在短时间内训练出具备良好视觉语言理解能力的多模态模型。

    

    近年来，大型语言模型在自然语言处理领域取得了显著进展，比如ChatGPT和GPT-4等模型在多种语言任务上取得了惊人的能力。但是，对这样的大规模模型进行训练是具有挑战性的，而找到与模型规模匹配的数据集通常也很困难。微调和使用新方法训练参数较少的模型已经成为克服这些挑战的有效方法。MiniGPT-4模型便是其中之一，该模型通过运用新颖的预训练模型和革新性的培训策略实现了与GPT-4相当的视觉语言理解能力。但是，该模型在图像理解方面仍然面临一些挑战，特别是在艺术图片方面。ArtGPT-4是一种新型的多模态模型，旨在应对这些局限。ArtGPT-4使用Tesla A100设备对图像-文本对进行训练，仅用了约200GB的数据，在2小时内就能展示出图像。

    In recent years, large language models (LLMs) have made significant progress in natural language processing (NLP), with models like ChatGPT and GPT-4 achieving impressive capabilities in various linguistic tasks. However, training models on such a large scale is challenging, and finding datasets that match the model's scale is often difficult. Fine-tuning and training models with fewer parameters using novel methods have emerged as promising approaches to overcome these challenges. One such model is MiniGPT-4, which achieves comparable vision-language understanding to GPT-4 by leveraging novel pre-training models and innovative training strategies. However, the model still faces some challenges in image understanding, particularly in artistic pictures. A novel multimodal model called ArtGPT-4 has been proposed to address these limitations. ArtGPT-4 was trained on image-text pairs using a Tesla A100 device in just 2 hours, using only about 200 GB of data. The model can depict images wit
    
[^25]: 交互式文本游戏中基于知识增强的代理

    Knowledge-enhanced Agents for Interactive Text Games. (arXiv:2305.05091v1 [cs.CL])

    [http://arxiv.org/abs/2305.05091](http://arxiv.org/abs/2305.05091)

    本文提出了一个知识加强的代理框架，用于加强代理在文本游戏中的功能基础，具有记忆先前操作和环境对象可行性两项领域知识，支持三个代表性模型类。

    

    自然语言的交流是智能不可或缺的一个方面，需要计算模型学习和推理有关世界概念的知识，其监督程度也各不相同。本文提出了一个框架，以加强代理在基于文本的游戏中的功能基础。具体而言，我们考虑将两种领域知识注入基于学习的代理中：先前正确操作的记忆和环境中相关对象的可行性。我们的框架支持三个代表性模型类：`纯`强化学习模型，基于记忆的序列到序列 (seq2seq) 模型和基于注意机制的 seq2seq模型。

    Communication via natural language is a crucial aspect of intelligence, and it requires computational models to learn and reason about world concepts, with varying levels of supervision. While there has been significant progress made on fully-supervised non-interactive tasks, such as question-answering and procedural text understanding, much of the community has turned to various sequential interactive tasks, as in semi-Markov text-based games, which have revealed limitations of existing approaches in terms of coherence, contextual awareness, and their ability to learn effectively from the environment. In this paper, we propose a framework for enabling improved functional grounding of agents in text-based games. Specifically, we consider two forms of domain knowledge that we inject into learning-based agents: memory of previous correct actions and affordances of relevant objects in the environment. Our framework supports three representative model classes: `pure' reinforcement learning
    
[^26]: T-SciQ: 使用大型语言模型信号教授多模态链式思维推理在科学问题回答中的应用

    T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering. (arXiv:2305.03453v1 [cs.CL])

    [http://arxiv.org/abs/2305.03453](http://arxiv.org/abs/2305.03453)

    本研究使用大型语言模型信号教育科学问题回答的链式思维推理，通过生成高质量COT合理化信号，同时降低了人工注释的需求。

    

    大型语言模型(LLMs)近期在各种自然语言处理(NLP)任务中展示了出色的性能。他们还展示了执行链式思维推理以解决复杂问题的能力。最近的研究探索了复杂多模态场景下的链式思维推理，例如通过用高质量人工注释的链式思路来调整多模型模型进行科学问题回答等任务。然而，收集高质量COT合理化通常是耗时且昂贵的。此外，由于涉及冗余信息或丢失重要信息，注释合理化通常不太准确。为了解决这些问题，我们提出了一种新的方法，称为T-SciQ，旨在使用LLM信号教授科学问题回答。T-SciQ方法生成高质量的CoT合理化信号，并先进地训练较小的模型以在复杂模态中执行CoT思维推理。另外，我们引入了一种显着提高模型泛化能力的技术，从而显着减少了对人工注释合理的需求。

    Large Language Models (LLMs) have recently demonstrated exceptional performance in various Natural Language Processing (NLP) tasks. They have also shown the ability to perform chain-of-thought (CoT) reasoning to solve complex problems. Recent studies have explored CoT reasoning in complex multimodal scenarios, such as the science question answering task, by fine-tuning multimodal models with high-quality human-annotated CoT rationales. However, collecting high-quality COT rationales is usually time-consuming and costly. Besides, the annotated rationales are hardly accurate due to the redundant information involved or the essential information missed. To address these issues, we propose a novel method termed \emph{T-SciQ} that aims at teaching science question answering with LLM signals. The T-SciQ approach generates high-quality CoT rationales as teaching signals and is advanced to train much smaller models to perform CoT reasoning in complex modalities. Additionally, we introduce a no
    
[^27]: UPRISE: 通用提示检索以提高零样本评估

    UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation. (arXiv:2303.08518v1 [cs.CL])

    [http://arxiv.org/abs/2303.08518](http://arxiv.org/abs/2303.08518)

    UPRISE是一种通用的检索器，可自动为给定的零样本任务输入检索提示，从而提高大型语言模型的零样本评估。它通过跨任务和跨模型的实验展示了其通用性和潜力，同时表明具有减轻幻觉问题和提高LLM性能的能力。

    

    大型语言模型因其出色的能力而受欢迎，但需要特定模型的微调或任务特定提示工程可能会阻碍其一般化。我们提出了UPRISE（通用提示检索以提高零样本评估），该方法调整了轻量级和多功能的检索器，以自动检索给定零样本任务输入的提示。具体而言，在跨任务和跨模型方案中展示了通用性：检索器针对各种任务进行微调，但在看不见的任务类型上进行测试；我们在一个小型冻结LLM——GPT-Neo-2.7B上调整检索器，但在不同规模的LLM上测试检索器，例如BLOOM-7.1B、OPT-66B和GPT3-175B。此外，我们展示了UPRISE在我们与ChatGPT的实验中减轻了幻觉问题，表明它有潜力改进甚至是最强的LLM。

    Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs.
    
[^28]: 基于语言模型的知识图谱嵌入编辑

    Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10405](http://arxiv.org/abs/2301.10405)

    本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。

    

    近几十年来，使用语言模型进行知识图谱（KG）嵌入已经取得了实证成功。但是，基于语言模型的KG嵌入通常作为静态工件部署，修改起来具有挑战性，需要重新训练。为了解决这个问题，本文提出了一种新的任务，即编辑基于语言模型的KG嵌入。该任务旨在实现对KG嵌入的数据高效和快速更新，而不影响其余部分的性能。我们构建了四个新数据集：E-FB15k237、A-FB15k237、E-WN18RR 和 A-WN18RR，并评估了几种知识编辑基线，证明了之前的模型处理该任务的能力有限。我们进一步提出了一个简单但强大的基线——KGEditor，它利用超网络的附加参数层来编辑/添加事实。全面的实验结果表明，当更新特定事实而不影响其余部分的性能时，KGEditor 的表现更好。

    Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
    
[^29]: 元元反游戏学习组合学习行为

    Meta-Referential Games to Learn Compositional Learning Behaviours. (arXiv:2207.08012v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.08012](http://arxiv.org/abs/2207.08012)

    本论文提出了一种元元反游戏学习的方法来解决组合学习行为的问题，通过解决绑定问题来支持人工智能代理展示组合学习行为的能力。

    

    人类利用组合性从过去的经验中推广到新颖的经验。我们假设我们的经验可以分解为基本的原子组件，这些组件可以以新颖的方式重新组合，以支持我们参与新颖经验的能力。我们将这视为学习以组合方式泛化的能力，并将利用这种能力的行为称为组合学习行为（CLBs）。学习CLBs的一个核心问题是解决绑定问题（BP）。尽管这是人类轻松完成的智能壮举，但对于现有技术的人工智能代理来说并非如此。因此，为了构建能够与人类合作的人工智能代理，我们建议开发一个新的基准来研究代理商通过解决BP的领域无关版本来展示CLBs的能力。我们受到指代游戏的语言涌现和基础架构框架的启发，提出了一个元学习扩展方案

    Human beings use compositionality to generalise from past experiences to novel experiences. We assume a separation of our experiences into fundamental atomic components that can be recombined in novel ways to support our ability to engage with novel experiences. We frame this as the ability to learn to generalise compositionally, and we will refer to behaviours making use of this ability as compositional learning behaviours (CLBs). A central problem to learning CLBs is the resolution of a binding problem (BP). While it is another feat of intelligence that human beings perform with ease, it is not the case for state-of-the-art artificial agents. Thus, in order to build artificial agents able to collaborate with human beings, we propose to develop a novel benchmark to investigate agents' abilities to exhibit CLBs by solving a domain-agnostic version of the BP. We take inspiration from the language emergence and grounding framework of referential games and propose a meta-learning extensio
    

