# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Cross-Modal Retrieval for Motion and Text via MildTriple Loss.](http://arxiv.org/abs/2305.04195) | 本论文提出了一个创新模型，使用MildTriple Loss捕捉长期依赖并模拟跨模态人类动作序列与文本检索任务，具有重要的应用价值。 |
| [^2] | [OpenViVQA: Task, Dataset, and Multimodal Fusion Models for Visual Question Answering in Vietnamese.](http://arxiv.org/abs/2305.04183) | 本文介绍了针对低资源语言的视觉问答任务和数据集——OpenViVQA，并提出了两种使用注意机制融合问题和图像特征生成答案的多模态融合模型。实验结果表明了所提出模型的有效性和OpenViVQA数据集在未来低资源语言VQA研究中的潜力。 |
| [^3] | [Shall We Trust All Relational Tuples by Open Information Extraction? A Study on Speculation Detection.](http://arxiv.org/abs/2305.04181) | 本文研究了开放信息抽取中的猜测检测，提出了元组级别猜测检测的研究问题，并提出了名为OIE-Spec的基准模型。 |
| [^4] | [MIReAD: Simple Method for Learning High-quality Representations from Scientific Documents.](http://arxiv.org/abs/2305.04177) | MIReAD是通过微调变形金刚模型来预测期刊类别，从而学习科学论文高质量表示的简单方法，可用于论文检索和文献搜索。 |
| [^5] | [UIT-OpenViIC: A Novel Benchmark for Evaluating Image Captioning in Vietnamese.](http://arxiv.org/abs/2305.04166) | 这篇论文介绍了一种新颖的越南语图像字幕数据集UIT-OpenViIC，这是为了解决目前在越南低资源研究社区中存在的困境而引入的。该数据集包括越南的复杂场景，并仅由越南人根据严格的规则和监督进行手动注释。数据集对于最新的最先进的翻译模型而言具有挑战性。 |
| [^6] | [X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages.](http://arxiv.org/abs/2305.04160) | 本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。 |
| [^7] | [Controllable Mixed-Initiative Dialogue Generation through Prompting.](http://arxiv.org/abs/2305.04147) | 提出了一种新的生成方式，使用大型语言模型作为条件生成微调的替代方案，通过提示构造来实现可控的混合主动对话生成并获得了较好的性能表现。 |
| [^8] | [Exploring Human-Like Translation Strategy with Large Language Models.](http://arxiv.org/abs/2305.04118) | 本文提出了一个名为MAPS的框架，使LLMs能够模仿人类翻译的过程，该过程包括分析源文本并提取关键词、主题和相关演示以指导翻译过程。该框架实验结果显示明显优于多个强基线，为开展使用LLM实现人类化翻译策略的有前途的方向提供了启示。 |
| [^9] | ["When Words Fail, Emojis Prevail": Generating Sarcastic Utterances with Emoji Using Valence Reversal and Semantic Incongruity.](http://arxiv.org/abs/2305.04105) | 本文提出了一种使用情感反转和语义不一致性从非讽刺性输入句子生成带有表情符号的讽刺性句子的架构，具有广泛的应用前景。 |
| [^10] | [Rhetorical Role Labeling of Legal Documents using Transformers and Graph Neural Networks.](http://arxiv.org/abs/2305.04100) | 本文尝试使用图神经网络和Transformer改进法律文件的文本分类准确性，以解决长、密集、包含行话术语的法律文件的修辞角色标注问题。 |
| [^11] | [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models.](http://arxiv.org/abs/2305.04091) | 本研究提出了一种计划和解决的提示方法来改善零样本思考链推理，该方法包括两个组成部分：制定计划将任务划分为子任务，并按计划执行子任务；将输入提示扩展到包括简单算术计算的示例。实验结果显示，该方法胜过了零样本-CoT。 |
| [^12] | [Self-Edit: Fault-Aware Code Editor for Code Generation.](http://arxiv.org/abs/2305.04087) | 本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。 |
| [^13] | [A Minimal Approach for Natural Language Action Space in Text-based Games.](http://arxiv.org/abs/2305.04082) | 本文介绍了一种在文本游戏中自然语言动作空间的简化方法，提出了 ε-可接受的探索方法，并提出了一种不需要语言模型或知识图谱的文本角色-评论（TAC）代理。实验表明，该方法可以优于使用语言模型和知识图谱的最先进代理。 |
| [^14] | [SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition.](http://arxiv.org/abs/2305.04076) | 本文提出了一种处理Distantly-Supervised Named Entity Recognition中错误和不完整标注噪声的分离策略，使用不同的模型构建来应对两种类型的噪声。 |
| [^15] | [Reactive Perturbation Defocusing for Textual Adversarial Defense.](http://arxiv.org/abs/2305.04067) | RPD对大型预训练语言模型的漏洞进行了防御，通过识别对抗性示例并注入安全扰动来减少误防御，成功地修复了高达97%的对抗性示例，在自然示例的性能仅降低了约2%。 |
| [^16] | [Actively Discovering New Slots for Task-oriented Conversation.](http://arxiv.org/abs/2305.04049) | 该论文探讨了如何主动发现面向任务对话的新槽位，以提高交互性能。由于实际应用中新的用户需求和不断变化的场景，使现有的对话搜索系统变得无法满足。其提出了一种通用的新插槽发现任务，通过信息提取的方式进行。 |
| [^17] | [Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation.](http://arxiv.org/abs/2305.04044) | 本文提出了Diffusion-NAT，将离散扩散模型引入非自回归文本生成中，并结合BART实现统一的推理和去噪过程，在此基础上提出了迭代的自我提示策略来进一步提高生成质量。 |
| [^18] | [Refining the Responses of LLMs by Themselves.](http://arxiv.org/abs/2305.04039) | 本文提出了一种利用自我优化机制来改善大型语言模型响应质量的方法，实验证明在GPT-3.5模型上使用此方法，生成的结果质量可以与甚至超过GPT-4模型。 |
| [^19] | [ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification.](http://arxiv.org/abs/2305.04003) | 本文介绍了一种名为ANTONIO的Python库，它基于抽象解释方法提供了一种实用的方法和启发式规则，以便为自然语言处理（NLP）数据集和模型生成已知验证方法的基准。因为其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。 |
| [^20] | [Replicating Complex Dialogue Policy of Humans via Offline Imitation Learning with Supervised Regularization.](http://arxiv.org/abs/2305.03987) | 本文提出了一个离线模仿学习模型，通过监督正则化来解决协变量漂移问题，该模型能够复制人类复杂的对话策略，并在基准数据集上获得了最新的结果。 |
| [^21] | [Pre-training Language Model as a Multi-perspective Course Learner.](http://arxiv.org/abs/2305.03981) | 本文提出了一种多角度课程学习的方法，使用三个自监督课程和两个自我修正课程，以平衡标签和充分利用生成器和辨别器之间的关系进行高效的预训练。 |
| [^22] | [An Adversarial Non-Autoregressive Model for Text Generation with Incomplete Information.](http://arxiv.org/abs/2305.03977) | 提出了一种新的对抗非自回归Transformer模型用于对不完整信息的文本生成，其具有位置感知自调节和依赖接口网络，能够在与其他主流模型相比更快的解码时间内获得可比较性能，具有在潜在插值等应用中的巨大潜力。 |
| [^23] | [DiscoPrompt: Path Prediction Prompt Tuning for Implicit Discourse Relation Recognition.](http://arxiv.org/abs/2305.03973) | DiscoPrompt是一种新的方法，通过预测层次结构内部的路径来识别隐含语篇关系，相比于以往的纯文本分类方法更加有效。 |
| [^24] | [Adaptive loose optimization for robust question answering.](http://arxiv.org/abs/2305.03971) | 本论文提出了一种简单而有效的自适应宽松优化损失函数，用于为问答系统综合内外分布的最佳表现，并显示了对对抗攻击的强韧性。 |
| [^25] | [NER-to-MRC: Named-Entity Recognition Completely Solving as Machine Reading Comprehension.](http://arxiv.org/abs/2305.03970) | 该论文提出了一种称为NER-to-MRC的方法，将命名实体识别问题完全作为机器阅读理解问题来解决。该方法采用一种新的跨度相关表示学习模块和预训练过程，提高了NER的性能，并且只使用了一小部分额外数据。 |
| [^26] | [Beyond Rule-based Named Entity Recognition and Relation Extraction for Process Model Generation from Natural Language Text.](http://arxiv.org/abs/2305.03960) | 本文扩展了PET数据集，通过聚类流程实体的提及，提出了一种新的基线技术流程提取方法，该方法避免了手动创建业务流程模型的繁琐工作，同时解决了同一流程实体重复提及的歧义问题。 |
| [^27] | [Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization.](http://arxiv.org/abs/2305.03937) | 本文提出了一种基于残差重参数化的Prompt Tuning改进方法-Residual Prompt Tuning，能够显著提高调优的性能和稳定性，在超过Prompt Tuning 7个点，且可以缩短Prompt长度10倍而不影响性能，同时对于学习率和Prompt初始化的选择具有鲁棒性。 |
| [^28] | [Active Continual Learning: Labelling Queries in a Sequence of Tasks.](http://arxiv.org/abs/2305.03923) | 本文考虑了一系列主动学习任务的主动连续学习问题，研究了不同场景下多种主动和连续学习算法之间的有效性和相互作用，并提出了遗忘-学习曲线方法来平衡不忘旧知识和快速学习的两个目标。 |
| [^29] | [HateMM: A Multi-Modal Dataset for Hate Video Classification.](http://arxiv.org/abs/2305.03915) | 仇恨言论的研究主要集中在文本媒体上，使用多模态检测仇恨视频并从视频共享平台中删除仇恨内容成为重点。因为仇恨视频的图像和音频中存在各种线索，因此我们构建了深度学习的多模态模型进行研究。 |
| [^30] | [Fairness in Image Search: A Study of Occupational Stereotyping in Image Retrieval and its Debiasing.](http://arxiv.org/abs/2305.03881) | 本文针对职业模式刻板印象问题，研究了网络搜索中的偏见和公平性问题。实验表明当前的图像搜索引擎存在相当严重的职业模式刻板印象，提出了一种去偏见方法以减轻此类偏见并提高图像搜索引擎的公平性。 |
| [^31] | [NorBench -- A Benchmark for Norwegian Language Models.](http://arxiv.org/abs/2305.03880) | NorBench是用来评估挪威语言模型的基准测试，其中包括简化的自然语言处理任务和探测套件，可以用于评估各种挪威语言模型的标准数据和评估指标。 |
| [^32] | [Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages.](http://arxiv.org/abs/2305.03873) | 该论文研究了利用多种丰富资源语言的翻译资源来最大限度地提高极少资源语言的翻译质量，以减少人工翻译的工作量。 |
| [^33] | [Large Language Models in Sport Science & Medicine: Opportunities, Risks and Considerations.](http://arxiv.org/abs/2305.03851) | 运动科学和医学领域中，大型语言模型可以提供支持和增强从业者知识的潜力，为个性化训练计划提供建议，并向发展中国家的从业者分发高质量信息，但使用和开发LLM存在风险，需要进一步研究。 |
| [^34] | [CLaC at SemEval-2023 Task 2: Comparing Span-Prediction and Sequence-Labeling approaches for NER.](http://arxiv.org/abs/2305.03845) | 本文比较了命名实体识别中的序列标记和跨度预测两种方法，在测试数据中跨度预测表现略优，并且使用更大版本的XLM RoBERTa可以显著提高性能。 |
| [^35] | [Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data.](http://arxiv.org/abs/2305.03827) | 本文提出了基于不确定性感知的Bootstrap学习用于远程监督数据联合抽取。通过探索数据不确定性和自我集成正则化器，使得模型在早期快速收敛并且缓解了噪声标签产生的模型不确定性，并在两个大型数据集上实验表明该方法在实体对抽取和关系抽取方面的F1得分分别提高了4.43%和4.92%。 |
| [^36] | [Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces.](http://arxiv.org/abs/2305.03819) | 本文研究将变压器语言模型应用于脑机界面预测式打字任务中。在评估几个单词级变压器语言模型后，GPT-2在干净印刷体上表现最佳，但是不同的变压器模型在嘈杂的历史轨迹上有不同的反应。 |
| [^37] | [Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation.](http://arxiv.org/abs/2305.03796) | 本文提出了一个名为RegularGPT的新型Transformer变体，其通过Weigh-Sharing、Adaptive-Depth和Sliding-Dilated-Attention的新颖组合，沿深度维度构建工作记忆，从而成功地建模了正则语言，如PARITY，并在自然语言长度外推任务中表现出良好效果。 |
| [^38] | [Towards Zero-Shot Frame Semantic Parsing with Task Agnostic Ontologies and Simple Labels.](http://arxiv.org/abs/2305.03793) | 本文提出了一种名为OpenFSP的框架，可以通过一些简单的标签方便地创建新领域，并在给定注释后，利用句子编码器的匹配算法预测由终端用户定义的领域的意图和插槽，从而解决了当前模型需要大量训练数据的问题。 |
| [^39] | [Harnessing the Power of BERT in the Turkish Clinical Domain: Pretraining Approaches for Limited Data Scenarios.](http://arxiv.org/abs/2305.03788) | 本研究针对土耳其临床语言模型在有限数据场景下的性能问题，探讨了不同预训练方法的影响，并指出利用大量通用领域语料库知识的BERTurk和TurkRadBERT-task v1表现最佳。 |
| [^40] | [Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming.](http://arxiv.org/abs/2305.03742) | 本文提出一种新的可微分符号推理框架，DSR-LM，用于提高预训练语言模型的逻辑推理能力，不像以往的研究依赖手工制定的逻辑规则，该框架有效地学习加权规则，并应用语义损失进一步改善LMs的逻辑推理能力。 |
| [^41] | [Tuning Traditional Language Processing Approaches for Pashto Text Classification.](http://arxiv.org/abs/2305.03737) | 本研究建立了一个普什图语自动文本分类系统，通过比较不同模型和特征提取方法，实验结果表明使用tf-idf特征提取方法的SVM模型在普什图语文本分类中取得了最高的准确率。 |
| [^42] | [Assessing Working Memory Capacity of ChatGPT.](http://arxiv.org/abs/2305.03731) | 本文评估了最先进语言模型ChatGPT的工作记忆容量，结果显示其在N-back任务的行为表现与人类参与者相似，这为设计具有人类级认知能力的人工智能系统提供了关键洞察。 |
| [^43] | [White-Box Multi-Objective Adversarial Attack on Dialogue Generation.](http://arxiv.org/abs/2305.03655) | 该论文提出了一种新的白盒多目标对话生成对抗攻击方法，DGSlow。通过平衡生成准确性和长度两个目标，DGSlow利用生成更长的输出来提高攻击效果。 |
| [^44] | [Big Data and Large Numbers. Interpreting Zipf's Law.](http://arxiv.org/abs/2305.02687) | 该论文揭示了大数性质对于解释齐普夫定律的影响，指出齐普夫定律噪音是这种影响的例子，并分析了权力分布和类似分布在种群是有限的、排名和元素计数是自然数的情况下的特性。 |
| [^45] | [Neighboring Words Affect Human Interpretation of Saliency Explanations.](http://arxiv.org/abs/2305.02679) | 相邻单词可以影响解释者对单词重要性的理解，应该考虑文本中其他因素的影响来替代单词级别的显著性解释方法。 |
| [^46] | [Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents.](http://arxiv.org/abs/2305.02412) | 本文介绍了Plan，Eliminate，和Track（PET）框架，该框架利用预先训练的大型语言模型（LLM）帮助智能体简化控制任务，从而解决了LLM直接作为智能体所面临的一些限制和问题。 |
| [^47] | [Using Language Models on Low-end Hardware.](http://arxiv.org/abs/2305.02350) | 本论文评估了在低端硬件上使用固定语言模型来训练文本分类网络的可行性，并发现在某些情况下，不对语言模型进行微调可以在更快的训练中产生竞争性的效果，仅需要原先内存的四分之一即可。 |
| [^48] | [Causality-aware Concept Extraction based on Knowledge-guided Prompting.](http://arxiv.org/abs/2305.01876) | 该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。 |
| [^49] | [A Study on the Integration of Pipeline and E2E SLU systems for Spoken Semantic Parsing toward STOP Quality Challenge.](http://arxiv.org/abs/2305.01620) | 本文介绍了针对ICASSP信号处理大挑战2023中的口语语言理解大挑战的质量轨迹（Track 1）提出的口语语义解析系统。使用了端到端和pipeline系统，并在SLU框架中使用了强大的自动语音识别（ASR）模型和预训练的语言模型（LM）等方法，最终获得了80.8的精确匹配度，获得了挑战的第一名。 |
| [^50] | [Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models.](http://arxiv.org/abs/2305.01219) | 本研究提出一种新颖有效的“ProAttack”方法来执行干净标签的后门攻击，使用的是提示本身作为触发器。该方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性，相比于现有的后门攻击方法有显著提升。 |
| [^51] | [Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023).](http://arxiv.org/abs/2305.00217) | 本研究为对Kauhanen、Einhaus和Walkden（2023）的回应，仍然没有证据表明大量的L2用户影响语言复杂性。 |
| [^52] | [Causal Reasoning and Large Language Models: Opening a New Frontier for Causality.](http://arxiv.org/abs/2305.00050) | 大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。 |
| [^53] | [Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement.](http://arxiv.org/abs/2304.14391) | 本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。 |
| [^54] | [From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping.](http://arxiv.org/abs/2304.13273) | 本研究提出了一种从关联到生成的零-shot方法：通过将图像/视频投影到语言模态并在生成任务中生成描述性字幕。该方法在多个基准数据集上显著优于现有的最先进方法，为无监督跨模态映射提供了一个新的视角，并具有在视频字幕，图像合成和文本到图像生成等领域的潜在应用。 |
| [^55] | [RenderDiffusion: Text Generation as Image Generation.](http://arxiv.org/abs/2304.12519) | 本文提出了一种新的扩散方法——\textsc{RenderDiffusion}，通过文本引导的图像生成进行文本生成。它将连续扩散模型应用于离散文本并实现了条件文本生成作为字形图像生成问题。 |
| [^56] | [Romanian Multiword Expression Detection Using Multilingual Adversarial Training and Lateral Inhibition.](http://arxiv.org/abs/2304.11350) | 本文使用多语言对抗训练和横向抑制技术对罗马尼亚语多词表达进行自动识别，提高了已有模型在未见过的多词表达上的F1分数，达到了最先进水平。 |
| [^57] | [A Large-Scale Comparative Study of Accurate COVID-19 Information versus Misinformation.](http://arxiv.org/abs/2304.04811) | 本文通过大规模比较研究表明，COVID-19错误信息的分布、传播能力、语言分析与准确信息不同，并且研制了一个新的分类数据集，该数据集平均提高了9%以上的错误信息分类能力。 |
| [^58] | [Examining Temporalities on Stance Detection Towards COVID-19 Vaccination.](http://arxiv.org/abs/2304.04806) | 研究考虑了时间性对COVID-19疫苗态度检测的影响，发现时间分割显著降低了立场分类的准确性。 |
| [^59] | [LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models.](http://arxiv.org/abs/2304.01933) | 本文提出了LLM-Adapters，一个将适配器集成到LLMs中进行参数高效微调的易于使用的框架，实现了比现有方法更少的参数和训练时间，在多个基准测试上取得了最先进的结果。 |
| [^60] | [Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam Detection.](http://arxiv.org/abs/2304.01238) | 本文通过比较不同类型的大型语言模型和传统机器学习技术在邮件垃圾检测中的表现，发现大多数情况下，大型语言模型优于传统技术，特别是在样本有限的情况下。同时，本文还介绍了经过改进和微调的Spam-T5模型，该模型具有出色的性能表现。 |
| [^61] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^62] | [Bias or Diversity? Unraveling Semantic Discrepancy in U.S. News Headlines.](http://arxiv.org/abs/2303.15708) | 本研究通过收集180万份美国主要媒体机构的新闻标题，揭示了美国新闻媒体中的语义差异，并发现在国内政治和社会问题上，差异可以在一定程度上归因于媒体偏见。 |
| [^63] | [Deep RL with Hierarchical Action Exploration for Dialogue Generation.](http://arxiv.org/abs/2303.13465) | 本篇论文提出了一种新的方法，通过分层行为探索，从多个奖励函数中进行离线学习，并成功地解决了在对话生成中行为采样效率低下的问题，可以更好地识别人类情感细节。 |
| [^64] | [Trained on 100 million words and still in shape: BERT meets British National Corpus.](http://arxiv.org/abs/2303.09859) | 本文探讨了在英国国家语料库上预训练的效果，并展示它可以比原始BERT模型达到更好的表现。在公平、可重复且数据有效的比较研究中，他们证明了这样的语料库有作为语言建模基准的巨大潜力。他们提出了一个经过优化的LM体系结构称为LTG-BERT。 |
| [^65] | [SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference.](http://arxiv.org/abs/2303.09266) | SmartBERT是一种改进的动态早期退出与层跳过机制，可以自适应地跳过一些层并自适应地选择是否退出，以加速BERT模型的推理速度。 |
| [^66] | [SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models.](http://arxiv.org/abs/2303.08896) | SelfCheckGPT是一种简单的基于采样的方法，可以以零资源的方式检查黑盒模型的幻觉现象。 |
| [^67] | [Geolocation Predicting of Tweets Using BERT-Based Models.](http://arxiv.org/abs/2303.07865) | 该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。 |
| [^68] | [Beyond Single Items: Exploring User Preferences in Item Sets with the Conversational Playlist Curation Dataset.](http://arxiv.org/abs/2303.06791) | 该论文提出了一种有效收集用户对项目集偏好数据的方法，用于构建对话式播放列表构建数据集。该数据集能够超越单项偏好，更加全面有效地了解用户需求。 |
| [^69] | [Refined Vision-Language Modeling for Fine-grained Multi-modal Pre-training.](http://arxiv.org/abs/2303.05313) | 本文提出了一种无需对象注释的精细化VLP方案，提出了同义词句子重写算法，设计了三种精细任务以提高精细监督的效果，并在多个任务中取得了最先进的性能。 |
| [^70] | [SemEval-2023 Task 10: Explainable Detection of Online Sexism.](http://arxiv.org/abs/2303.04222) | 本文介绍了SemEval任务10：可解释的在线性别歧视检测，创新地提出了具有可解释性的性别歧视内容的层次分类法，以及新的标签细粒度的数据集，可帮助解决二分类检测忽略了多样性的问题。 |
| [^71] | [Language Model Analysis for Ontology Subsumption Inference.](http://arxiv.org/abs/2302.06761) | 本文研究了语言模型对本体子类推断的理解能力，提出了一套涉及原子概念和复合概念的推理任务，并证明语言模型对子类推断背景知识的记忆相对较少，但在给定少量样本的情况下可显著提高准确率。 |
| [^72] | [The Re-Label Method For Data-Centric Machine Learning.](http://arxiv.org/abs/2302.04391) | 本文提出了一种重新标签的方法来解决手动标记的数据中存在噪声的问题，并通过模型预测来辅助人类标记噪声数据。实验证明此方法适用于多类深度学习任务。 |
| [^73] | [Double Permutation Equivariance for Knowledge Graph Completion.](http://arxiv.org/abs/2302.01313) | 本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。 |
| [^74] | [ALCAP: Alignment-Augmented Music Captioner.](http://arxiv.org/abs/2212.10901) | 本文提出了一种基于对齐的音乐字幕生成器，通过对比学习显式学习音频和歌词的对应关系，并生成高质量的字幕，取得了两个音乐字幕数据集上的最新领先水平。 |
| [^75] | [Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective.](http://arxiv.org/abs/2212.10529) | 本文从心理学角度评估大型语言模型的安全性，发现所有模型在短暗三合一测验上的得分都高于人类平均水平，存在相对较暗的人格模式。尽管经过指标微调，两种模型仍呈现隐含的黑暗人格模式。同时，本文观察到GPT-3和InstructGPT的幸福感得分持续增加。 |
| [^76] | [On Event Individuation for Document-Level Information Extraction.](http://arxiv.org/abs/2212.09702) | 提出了问题──事件个体化对于模板填充任务是否适用，通过注释研究和误差分析，我们发现这引发了对模板填充度量的有效性、任务数据集的质量以及模型学习能力的担忧。 |
| [^77] | [Reasoning with Language Model Prompting: A Survey.](http://arxiv.org/abs/2212.09597) | 本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。 |
| [^78] | [Large Language Models Meet NL2Code: A Survey.](http://arxiv.org/abs/2212.09420) | 本文综述了27个大型语言模型对于NL2Code的应用，总结出这些模型成功的三大关键因素：巨大的模型尺寸、高质量的数据和专家的调整。同时，本文还讨论了模型和人类之间的差距，并提供了一个用于追踪最新进展的网站。 |
| [^79] | [Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model.](http://arxiv.org/abs/2212.09146) | 本论文研究了检索增强语言模型的推理能力，发现检索器和语言模型之间存在推卸责任的问题，且检索器选择的句子和语言模型不考虑句子之间的复杂关系都会影响推理性能。针对这些问题，本文提出了一种新的框架ReForMask，采用掩码检索方法来更好地捕捉语句之间的复杂关系并在多个任务上实现了显著优化。 |
| [^80] | [Robustness of Learning from Task Instructions.](http://arxiv.org/abs/2212.03813) | 本文提出了一种鲁棒的方法来从任务说明中学习，以处理说明的变化并提高对新任务的泛化能力。 |
| [^81] | [Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning.](http://arxiv.org/abs/2212.03760) | 本文研究发现，用户历史语言建模可以在不同推荐任务中取得优异结果，并且利用任务无关的用户历史还可以提供显著的性能优势。该方法具有广泛的现实世界迁移学习能力。 |
| [^82] | [Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations.](http://arxiv.org/abs/2211.08794) | 本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。 |
| [^83] | [Investigating Content-Aware Neural Text-To-Speech MOS Prediction Using Prosodic and Linguistic Features.](http://arxiv.org/abs/2211.00342) | 本文提出探究声调和语言特征如何影响神经文本朗读自然度预测，通过加入这些特征，相较于基于频谱特征的基线模型 MOSNet，在 MOS 预测中取得了平均12%无公害提高。 |
| [^84] | [Multitask Pre-training of Modular Prompt for Chinese Few-Shot Learning.](http://arxiv.org/abs/2210.07565) | 本文提出了多任务预训练模块化提示方法（MP2），用于解决在中文少样本学习中提示调整的不足。MP2是一组在38个中文任务上预训练的可组合提示，能够在面对未见过的任务时具备强大的组合泛化能力。在两种学习范式下的实验中，MP2在少样本情形下显著优于其他方法。 |
| [^85] | [Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods.](http://arxiv.org/abs/2210.07321) | 本文主要调查了机器生成文本对社会和网络安全所带来的威胁，提供了最完整的机器生成文本检测方法评估，为应对威胁模型和解决检测问题提供了强有力的指导。 |
| [^86] | [How Far Are We from Real Synonym Substitution Attacks?.](http://arxiv.org/abs/2210.02844) | 本文探讨同义词替换攻击的现状，发现当前方法存在无解决的障碍，生成的敌对样本效果不佳，需要在未来改进。 |
| [^87] | [Music-to-Text Synaesthesia: Generating Descriptive Text from Music Recordings.](http://arxiv.org/abs/2210.00434) | 本文提出了音乐文本视觉交感问题，收集了对齐的数据集，构建了一个计算模型来生成描述音乐录音内容的句子，并设计了群拓扑保持损失来解决高非判别性的古典音乐。 |
| [^88] | [Vega-MT: The JD Explore Academy Translation System for WMT22.](http://arxiv.org/abs/2209.09444) | Vega-MT是JD Explore Academy为WMT22共享的翻译任务开发的系统。该系统扩大了语言对和模型大小，实现了“双向”到“多向”的拓展并采取了数据增强策略，从而提高翻译质量。 |
| [^89] | [Shortcut Learning of Large Language Models in Natural Language Understanding.](http://arxiv.org/abs/2208.11857) | 本文综述了大型语言模型中快捷学习和鲁棒性挑战的解决方法和相关研究，包括识别其快捷学习行为、原因和解决方案，并探讨了领域的主要研究挑战和潜在研究方向。 |
| [^90] | [Persuasion Strategies in Advertisements.](http://arxiv.org/abs/2208.09626) | 本论文提出了一个广告图片语料库和说服策略预测任务。通过设计多任务注意力融合模型，可以预测广告中的说服策略。 |
| [^91] | [General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase Generation.](http://arxiv.org/abs/2208.09606) | 本文提出了一种三阶段流程，通过领域通用短语预训练、迁移标记和有限真实标注数据微调来适应新领域，使关键短语生成（KPG）模型具备更强的可迁移性。 |
| [^92] | [Delving into the Openness of CLIP.](http://arxiv.org/abs/2206.01986) | 本研究探究了CLIP模型的开放性，并通过词汇扩展来评估模型的可扩展性。研究发现，类似于CLIP的模型并不真正开放，并且随着词汇表的扩展其性能会恶化。此外，研究还揭示了CLIP表示在不变性和特定性之间存在权衡。 |
| [^93] | [Helpfulness and Fairness of Task-Oriented Dialogue Systems.](http://arxiv.org/abs/2205.12554) | 本文研究任务导向对话系统的帮助性和公平性。作者定义了对话系统的帮助性，使用分类器自动确定帮助性，并提出使用帮助级别来衡量对话系统的公平性。实验结果表明，现有系统更容易为来自发达国家概念的问题提供帮助。 |
| [^94] | [A Large and Diverse Arabic Corpus for Language Modeling.](http://arxiv.org/abs/2201.09227) | 该论文介绍了一个大规模的阿拉伯语语料库，旨在提高大规模语言模型的跨领域知识和推理能力。 |

# 详细

[^1]: MildTriple Loss模型下的运动和文本跨模态检索

    Cross-Modal Retrieval for Motion and Text via MildTriple Loss. (arXiv:2305.04195v1 [cs.CV])

    [http://arxiv.org/abs/2305.04195](http://arxiv.org/abs/2305.04195)

    本论文提出了一个创新模型，使用MildTriple Loss捕捉长期依赖并模拟跨模态人类动作序列与文本检索任务，具有重要的应用价值。

    

    跨模态检索已成为计算机视觉和自然语言处理中的重要研究课题，随着图像文本和视频文本检索技术的进步。尽管在虚拟现实等广泛应用中具有重要价值，但人类动作序列与文本之间的跨模态检索尚未引起足够的关注。这个任务存在一些挑战，包括对两种语言的共同建模，要求从文本中理解以人为中心的信息，并从三维人体运动序列中学习行为特征。以往的运动数据建模主要依赖于自回归特征提取器，这可能会遗忘以前的信息，而我们提出了一种创新模型，其中包括简单而强大的基于变换器的运动和文本编码器，可以从两种不同的模态中学习表示并捕捉长期依赖

    Cross-modal retrieval has become a prominent research topic in computer vision and natural language processing with advances made in image-text and video-text retrieval technologies. However, cross-modal retrieval between human motion sequences and text has not garnered sufficient attention despite the extensive application value it holds, such as aiding virtual reality applications in better understanding users' actions and language. This task presents several challenges, including joint modeling of the two modalities, demanding the understanding of person-centered information from text, and learning behavior features from 3D human motion sequences. Previous work on motion data modeling mainly relied on autoregressive feature extractors that may forget previous information, while we propose an innovative model that includes simple yet powerful transformer-based motion and text encoders, which can learn representations from the two different modalities and capture long-term dependencie
    
[^2]: OpenViVQA：越南语视觉问答任务、数据集和多模态融合模型

    OpenViVQA: Task, Dataset, and Multimodal Fusion Models for Visual Question Answering in Vietnamese. (arXiv:2305.04183v1 [cs.CL])

    [http://arxiv.org/abs/2305.04183](http://arxiv.org/abs/2305.04183)

    本文介绍了针对低资源语言的视觉问答任务和数据集——OpenViVQA，并提出了两种使用注意机制融合问题和图像特征生成答案的多模态融合模型。实验结果表明了所提出模型的有效性和OpenViVQA数据集在未来低资源语言VQA研究中的潜力。

    

    在近年来，视觉问答 (VQA) 由于其高潜在应用（例如智能车上的虚拟助手、盲人辅助装置或使用自然语言作为查询的文档图像信息检索等）和挑战性而引起研究界的关注。VQA 任务需要具有从问题和图像中融合信息以生成适当答案的方法。 神经视觉问答模型在大规模数据集上的应用已经取得了巨大的发展，这些数据集多数为资源丰富的语言，如英语。然而，现有的数据集将 VQA 任务缩小为答案选择任务或答案分类任务，而这种形式的 VQA 远远不能与人类能力相提并论，通过仅选择答案而不是生成答案来消除 VQA 任务中的回答方面的挑战。在本文中，我们引入了 OpenViVQA （开放领域越南语视觉问答）任务和数据集，这旨在推广越南语和其他低资源语言中的 VQA 研究。我们还提出了两种多模态融合模型，这些模型使用注意机制组合不同的问题和图像特征以生成 OpenViVQA 任务的答案。实验结果证明了所提出模型的有效性以及 OpenViVQA 数据集在低资源语言 VQA 的未来研究中的潜力。

    In recent years, visual question answering (VQA) has attracted attention from the research community because of its highly potential applications (such as virtual assistance on intelligent cars, assistant devices for blind people, or information retrieval from document images using natural language as queries) and challenge. The VQA task requires methods that have the ability to fuse the information from questions and images to produce appropriate answers. Neural visual question answering models have achieved tremendous growth on large-scale datasets which are mostly for resource-rich languages such as English. However, available datasets narrow the VQA task as the answers selection task or answer classification task. We argue that this form of VQA is far from human ability and eliminates the challenge of the answering aspect in the VQA task by just selecting answers rather than generating them. In this paper, we introduce the OpenViVQA (Open-domain Vietnamese Visual Question Answering
    
[^3]: 我们应该相信开放信息抽取提取的所有关系元组吗？对猜测检测的研究

    Shall We Trust All Relational Tuples by Open Information Extraction? A Study on Speculation Detection. (arXiv:2305.04181v1 [cs.CL])

    [http://arxiv.org/abs/2305.04181](http://arxiv.org/abs/2305.04181)

    本文研究了开放信息抽取中的猜测检测，提出了元组级别猜测检测的研究问题，并提出了名为OIE-Spec的基准模型。

    

    开放信息抽取（OIE）旨在从开放域句子中提取事实关系元组。下游任务使用提取的OIE元组作为事实，而不考虑这些事实的确定性。然而，不确定性/猜测是一种常见的语言现象。现有的猜测检测研究是在句子级别上定义的，但即使确定了一个句子是猜测的，也不是从其中提取的所有元组都是猜测的。在本文中，我们提出研究OIE中的猜测，并旨在确定提取的元组是否存在猜测。我们正式定义了元组级别猜测检测的研究问题，并对包含猜测元组标签的LSOIE数据集进行了详细的数据分析。最后，我们提出了一个名为OIE-Spec的基准模型用于这个新的研究任务。

    Open Information Extraction (OIE) aims to extract factual relational tuples from open-domain sentences. Downstream tasks use the extracted OIE tuples as facts, without examining the certainty of these facts. However, uncertainty/speculation is a common linguistic phenomenon. Existing studies on speculation detection are defined at sentence level, but even if a sentence is determined to be speculative, not all tuples extracted from it may be speculative. In this paper, we propose to study speculations in OIE and aim to determine whether an extracted tuple is speculative. We formally define the research problem of tuple-level speculation detection and conduct a detailed data analysis on the LSOIE dataset which contains labels for speculative tuples. Lastly, we propose a baseline model OIE-Spec for this new research task.
    
[^4]: MIReAD: 从科学文献中学习高质量表示的简单方法

    MIReAD: Simple Method for Learning High-quality Representations from Scientific Documents. (arXiv:2305.04177v1 [cs.CL])

    [http://arxiv.org/abs/2305.04177](http://arxiv.org/abs/2305.04177)

    MIReAD是通过微调变形金刚模型来预测期刊类别，从而学习科学论文高质量表示的简单方法，可用于论文检索和文献搜索。

    

    从科学文献中学习语义上有意义的表示可以促进学术文献搜索并提高推荐系统的性能。我们提出了MIReAD，一种简单的方法，通过微调变形金刚模型来预测基于摘要的目标期刊类别，从而学习科学论文的高质量表示。我们在超过2,000个期刊类别的500,000多个PubMed和arXiv摘要上对MIReAD进行训练。我们表明MIReAD产生的表示可用于类似论文检索、主题分类和文献搜索。我们提出的方法在四个评价标准下优于现有的六种科学文献表示学习模型。

    Learning semantically meaningful representations from scientific documents can facilitate academic literature search and improve performance of recommendation systems. Pre-trained language models have been shown to learn rich textual representations, yet they cannot provide powerful document-level representations for scientific articles. We propose MIReAD, a simple method that learns high-quality representations of scientific papers by fine-tuning transformer model to predict the target journal class based on the abstract. We train MIReAD on more than 500,000 PubMed and arXiv abstracts across over 2,000 journal classes. We show that MIReAD produces representations that can be used for similar papers retrieval, topic categorization and literature search. Our proposed approach outperforms six existing models for representation learning on scientific documents across four evaluation standards.
    
[^5]: UIT-OpenViIC：一种用于评估越南语图像字幕的新型基准

    UIT-OpenViIC: A Novel Benchmark for Evaluating Image Captioning in Vietnamese. (arXiv:2305.04166v1 [cs.CV])

    [http://arxiv.org/abs/2305.04166](http://arxiv.org/abs/2305.04166)

    这篇论文介绍了一种新颖的越南语图像字幕数据集UIT-OpenViIC，这是为了解决目前在越南低资源研究社区中存在的困境而引入的。该数据集包括越南的复杂场景，并仅由越南人根据严格的规则和监督进行手动注释。数据集对于最新的最先进的翻译模型而言具有挑战性。

    

    图像字幕是一种仍然吸引全球研究社区兴趣的视觉语言任务。虽然MS-COCO字幕基准是在2015年发布的，但它仍然被广泛使用来评估高级字幕模型的性能。然而，仅在MS-COCO字幕数据集上训练的最新字幕模型仅在英语语言模式方面表现良好；它们在越南捕捉的上下文或使用越南语流畅字幕图像方面的表现并不好。为了贡献于像越南这样的低资源研究社区，我们引入了一种新颖的越南语图像字幕数据集，UIT-OpenViIC。我们的数据集包括越南的复杂场景，并由越南人根据严格的规则和监督进行手动注释。在本文中，我们更详细地介绍了数据集的创建过程。从初步分析中，我们展示了我们的数据集对于最新的最先进的翻译模型而言具有挑战性。

    Image Captioning is one of the vision-language tasks that still interest the research community worldwide in the 2020s. MS-COCO Caption benchmark is commonly used to evaluate the performance of advanced captioning models, although it was published in 2015. Recent captioning models trained on the MS-COCO Caption dataset only have good performance in language patterns of English; they do not have such good performance in contexts captured in Vietnam or fluently caption images using Vietnamese. To contribute to the low-resources research community as in Vietnam, we introduce a novel image captioning dataset in Vietnamese, the Open-domain Vietnamese Image Captioning dataset (UIT-OpenViIC). The introduced dataset includes complex scenes captured in Vietnam and manually annotated by Vietnamese under strict rules and supervision. In this paper, we present in more detail the dataset creation process. From preliminary analysis, we show that our dataset is challenging to recent state-of-the-art 
    
[^6]: X-LLM: 通过将多模态视为外语引入大型语言模型来启动高级大型语言模型

    X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages. (arXiv:2305.04160v1 [cs.CL])

    [http://arxiv.org/abs/2305.04160](http://arxiv.org/abs/2305.04160)

    本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。

    

    大型语言模型（LLM）展示了卓越的语言能力。基于高级LLM的GPT-4表现出超常的多模态能力，超越了以往的视觉语言模型。我们将这归功于与以前的多模态模型相比使用了更先进的LLM。但不幸的是，GPT-4的模型架构和训练策略是未知的。为了赋予LLM多模态能力，我们提出了X-LLM，通过使用X2L接口将多模态（图像、语音、视频）转换为外语并将其输入到大型语言模型（ChatGLM）中。具体而言，X-LLM使用X2L接口将多个冻结的单模态编码器和冻结的LLM对齐，其中“X”表示多模态，例如图像、语音和视频，“L”表示语言。X-LLM的训练由三个阶段组成：（1）转换多模态信息：第一阶段分别训练每个X2L接口与其各自的单模态编码器对齐，将多模态信息转换为外语输入到ChatGLM中。...

    Large language models (LLMs) have demonstrated remarkable language abilities. GPT-4, based on advanced LLMs, exhibits extraordinary multimodal capabilities beyond previous visual language models. We attribute this to the use of more advanced LLMs compared with previous multimodal models. Unfortunately, the model architecture and training strategies of GPT-4 are unknown. To endow LLMs with multimodal capabilities, we propose X-LLM, which converts Multi-modalities (images, speech, videos) into foreign languages using X2L interfaces and inputs them into a large Language model (ChatGLM). Specifically, X-LLM aligns multiple frozen single-modal encoders and a frozen LLM using X2L interfaces, where ``X'' denotes multi-modalities such as image, speech, and videos, and ``L'' denotes languages. X-LLM's training consists of three stages: (1) Converting Multimodal Information: The first stage trains each X2L interface to align with its respective single-modal encoder separately to convert multimod
    
[^7]: 通过提示实现可控的混合主动对话生成

    Controllable Mixed-Initiative Dialogue Generation through Prompting. (arXiv:2305.04147v1 [cs.CL])

    [http://arxiv.org/abs/2305.04147](http://arxiv.org/abs/2305.04147)

    提出了一种新的生成方式，使用大型语言模型作为条件生成微调的替代方案，通过提示构造来实现可控的混合主动对话生成并获得了较好的性能表现。

    

    混合主动对话任务涉及重复交换信息和对话控制。会话代理通过生成响应来获得控制，这些响应按照策略规划器规定的特定对话意图或策略进行。标准方法是微调预训练的语言模型以执行基于这些意图的生成。然而，这些受监督的生成模型受数据注释成本和质量的限制。我们提出用大型语言模型作为条件生成微调的替代方案。我们为可控混合主动对话形式化提示构造。我们的研究表明，在PersuasionForGood和Emotional Support Conversations两个任务中，我们的方法在人类评估和自动指标方面均显示出比微调和真实响应更好的性能。

    Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation. We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations.
    
[^8]: 使用大型语言模型探索人类化翻译策略

    Exploring Human-Like Translation Strategy with Large Language Models. (arXiv:2305.04118v1 [cs.CL])

    [http://arxiv.org/abs/2305.04118](http://arxiv.org/abs/2305.04118)

    本文提出了一个名为MAPS的框架，使LLMs能够模仿人类翻译的过程，该过程包括分析源文本并提取关键词、主题和相关演示以指导翻译过程。该框架实验结果显示明显优于多个强基线，为开展使用LLM实现人类化翻译策略的有前途的方向提供了启示。

    

    大型语言模型（LLMs）在各种场景下展现出了惊人的能力，表现出了接近甚至超越人类智能的水平。在其多种技能中，LLM的翻译能力受到了广泛的关注。与传统的机器翻译仅关注源目标映射不同，基于LLM的翻译可以潜在地模仿人类翻译的过程，该过程会采取许多准备步骤以确保高质量的翻译。本文旨在通过提出MAPS框架（Multi-Aspect Prompting and Selection）探索这种可能性。具体来说，我们使LLM首先分析给定源文本并提取三个与翻译相关的知识方面：关键词、主题和相关演示以指导翻译过程。为了过滤掉噪声和无用的知识，我们采用基于质量估计的选择机制。实验证明，我们的框架在多个语言对和翻译方向上显着优于多个强基线。这项工作为开展使用LLM实现人类化翻译策略的有前途的方向提供了启示。

    Large language models (LLMs) have demonstrated impressive capabilities in general scenarios, exhibiting a level of aptitude that approaches, in some aspects even surpasses, human-level intelligence. Among their numerous skills, the translation abilities of LLMs have received considerable attention. In contrast to traditional machine translation that focuses solely on source-target mapping, LLM-based translation can potentially mimic the human translation process that takes many preparatory steps to ensure high-quality translation. This work aims to explore this possibility by proposing the MAPS framework, which stands for Multi-Aspect Prompting and Selection. Specifically, we enable LLMs to first analyze the given source text and extract three aspects of translation-related knowledge: keywords, topics and relevant demonstrations to guide the translation process. To filter out the noisy and unhelpful knowledge, we employ a selection mechanism based on quality estimation. Experiments sug
    
[^9]: "当文字难以表达时，表情符号称霸": 利用情感反转和语义不一致生成带有表情符号的讽刺话语

    "When Words Fail, Emojis Prevail": Generating Sarcastic Utterances with Emoji Using Valence Reversal and Semantic Incongruity. (arXiv:2305.04105v1 [cs.CL])

    [http://arxiv.org/abs/2305.04105](http://arxiv.org/abs/2305.04105)

    本文提出了一种使用情感反转和语义不一致性从非讽刺性输入句子生成带有表情符号的讽刺性句子的架构，具有广泛的应用前景。

    

    讽刺是个体用来表达与含义相反的事情的微妙形式。本文提出了一种使用表情符号从非讽刺性输入句子生成讽刺性句子的新颖架构。我们将生成任务分为两个子任务：一个用于生成文本讽刺，另一个用于收集与这些讽刺句子相关的表情符号。讽刺的两个关键元素被纳入到文本讽刺生成任务中：情感反转和语义不一致性与语境，其中语境可能涉及演讲者和听众之间共享的常识或一般知识。大多数现有的讽刺生成作品都集中在这种文本形式上。然而，在现实世界中，当书面文本无法有效地捕捉口头和面对面交流的情感线索时，人们经常选择表情符号来准确地表达他们的情感。由于表情符号的广泛应用，合理地纳入适当的表情符号很重要。

    Sarcasm pertains to the subtle form of language that individuals use to express the opposite of what is implied. We present a novel architecture for sarcasm generation with emoji from a non-sarcastic input sentence. We divide the generation task into two sub tasks: one for generating textual sarcasm and another for collecting emojis associated with those sarcastic sentences. Two key elements of sarcasm are incorporated into the textual sarcasm generation task: valence reversal and semantic incongruity with context, where the context may involve shared commonsense or general knowledge between the speaker and their audience. The majority of existing sarcasm generation works have focused on this textual form. However, in the real world, when written texts fall short of effectively capturing the emotional cues of spoken and face-to-face communication, people often opt for emojis to accurately express their emotions. Due to the wide range of applications of emojis, incorporating appropriate
    
[^10]: 基于Transformer和图神经网络的法律文件修辞角色标注

    Rhetorical Role Labeling of Legal Documents using Transformers and Graph Neural Networks. (arXiv:2305.04100v1 [cs.CL])

    [http://arxiv.org/abs/2305.04100](http://arxiv.org/abs/2305.04100)

    本文尝试使用图神经网络和Transformer改进法律文件的文本分类准确性，以解决长、密集、包含行话术语的法律文件的修辞角色标注问题。

    

    通常，法律文件冗长而密集，需要人力成本来解析。此外，法律文件还包含大量行话术语，使用现有模型来从中获得洞察的方法表现不佳。本文介绍了在 SemEval Task 6: understanding legal texts, shared subtask A 的印度法院判决中进行修辞角色标注任务所采用的方法。我们尝试了基于图的方法，如图卷积网络和标签传播算法，以及基于Transformer的方法，包括BERT的变体，以提高针对复杂法律文件的文本分类的准确性分数。

    A legal document is usually long and dense requiring human effort to parse it. It also contains significant amounts of jargon which make deriving insights from it using existing models a poor approach. This paper presents the approaches undertaken to perform the task of rhetorical role labelling on Indian Court Judgements as part of SemEval Task 6: understanding legal texts, shared subtask A. We experiment with graph based approaches like Graph Convolutional Networks and Label Propagation Algorithm, and transformer-based approaches including variants of BERT to improve accuracy scores on text classification of complex legal documents.
    
[^11]: 计划和解决提示：通过大型语言模型改善零样本思考链推理

    Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. (arXiv:2305.04091v1 [cs.CL])

    [http://arxiv.org/abs/2305.04091](http://arxiv.org/abs/2305.04091)

    本研究提出了一种计划和解决的提示方法来改善零样本思考链推理，该方法包括两个组成部分：制定计划将任务划分为子任务，并按计划执行子任务；将输入提示扩展到包括简单算术计算的示例。实验结果显示，该方法胜过了零样本-CoT。

    

    最近，大型语言模型（LLMs）在各种自然语言处理任务中表现出惊人的性能。为了解决多步骤推理任务，少样本的思维链（CoT）提示包括一些手工制作的逐步推理演示，使LLMs能够明确生成推理步骤并提高其推理任务准确性。为了消除手动劳动，零样本思维链将目标问题陈述与“让我们逐步思考”连接起来作为输入提示LLMs。尽管零样本-CoT取得了成功，但仍存在计算错误、缺失步骤错误和语义误解错误的问题。为了解决缺失步骤错误，我们提出了计划和解决（PS）提示。它包含两个组成部分：首先，制定计划将整个任务划分为较小的子任务，然后按照计划执行子任务。为了解决计算错误并提高生成推理步骤的质量，我们将输入提示扩展到包括简单算术计算的示例。我们的实验表明，PS提示在思维链推理任务的准确性方面胜过了零样本CoT。

    Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual effort, Zero-shot-CoT concatenates the target problem statement with "Let's think step by step" as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend 
    
[^12]: 自我编辑：针对代码生成的故障感知式代码编辑器

    Self-Edit: Fault-Aware Code Editor for Code Generation. (arXiv:2305.04087v1 [cs.SE])

    [http://arxiv.org/abs/2305.04087](http://arxiv.org/abs/2305.04087)

    本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。

    

    大型语言模型（LLMs）在竞技编程任务中生成代码的能力已经得到证明，但由于样本数量有限，LLMs仍然存在较低的准确性。受人类编程过程的启发，我们提出了一种生成和编辑的方法，利用LLMs生成的代码的执行结果来提高竞技编程任务的代码质量。我们在问题中提供的示例测试用例上执行生成的代码，并将执行结果包含在补充性注释中。利用这个注释作为指导，我们的故障感知式代码编辑器用于纠正生成的代码中的错误。我们在两个竞技编程数据集上进行了广泛的评估，涵盖了九个不同的LLMs。与直接从LLMs生成相比，我们的方法可以在APPS-dev上将pass@1的平均值提高89％，在APPS-test上提高31％，在HumanEval上提高48％，超过了九个流行的代码生成LLMs，参数大小范围为110M-t。

    Large language models (LLMs) have demonstrated an impressive ability to generate codes on competitive programming tasks. However, with limited sample numbers, LLMs still suffer from poor accuracy. Inspired by the process of human programming, we propose a generate-and-edit approach that utilizes execution results of the generated code from LLMs to improve the code quality on the competitive programming task. We execute the generated code on the example test case provided in the question and wrap execution results into a supplementary comment. Utilizing this comment as guidance, our fault-aware code editor is employed to correct errors in the generated code. We perform extensive evaluations across two competitive programming datasets with nine different LLMs. Compared to directly generating from LLMs, our approach can improve the average of pass@1 by 89\% on APPS-dev, 31\% on APPS-test, and 48\% on HumanEval over nine popular code generation LLMs with parameter sizes ranging from 110M t
    
[^13]: 一种文本游戏中自然语言动作空间的简化方法

    A Minimal Approach for Natural Language Action Space in Text-based Games. (arXiv:2305.04082v1 [cs.LG])

    [http://arxiv.org/abs/2305.04082](http://arxiv.org/abs/2305.04082)

    本文介绍了一种在文本游戏中自然语言动作空间的简化方法，提出了 ε-可接受的探索方法，并提出了一种不需要语言模型或知识图谱的文本角色-评论（TAC）代理。实验表明，该方法可以优于使用语言模型和知识图谱的最先进代理。

    

    文本游戏是基于自然语言的强化学习交互环境。虽然语言模型和知识图谱通常被用于处理文本游戏中的大量动作空间，但目前仍不确定这些技术是否必要或被过度使用。本文重新思考了在文本游戏中探索动作空间的挑战，并提出了 ε-可接受的探索方法，这是一种利用可接受的动作的最小化方法进行训练。此外，我们提出了一种文本角色-评论（TAC）代理，该代理仅从游戏观察中生成文本命令，而无需任何语言模型或知识图谱。在 Jericho 的 10 种游戏中，我们的方法的表现优于强基线和使用语言模型和知识图谱的最先进代理。我们的方法凸显出，对于有效地探索指数级动作空间，更轻量化的模型设计和利用环境信息的新视角是足够的。

    Text-based games (TGs) are language-based interactive environments for reinforcement learning. While language models (LMs) and knowledge graphs (KGs) are commonly used for handling large action space in TGs, it is unclear whether these techniques are necessary or overused. In this paper, we revisit the challenge of exploring the action space in TGs and propose $ \epsilon$-admissible exploration, a minimal approach of utilizing admissible actions, for training phase. Additionally, we present a text-based actor-critic (TAC) agent that produces textual commands for game, solely from game observations, without requiring any KG or LM. Our method, on average across 10 games from Jericho, outperforms strong baselines and state-of-the-art agents that use LM and KG. Our approach highlights that a much lighter model design, with a fresh perspective on utilizing the information within the environments, suffices for an effective exploration of exponentially large action spaces.
    
[^14]: SANTA：Distantly-Supervised Named Entity Recognition中处理错误和不完整标注噪声的分离策略

    SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition. (arXiv:2305.04076v1 [cs.CL])

    [http://arxiv.org/abs/2305.04076](http://arxiv.org/abs/2305.04076)

    本文提出了一种处理Distantly-Supervised Named Entity Recognition中错误和不完整标注噪声的分离策略，使用不同的模型构建来应对两种类型的噪声。

    

    远程监督命名实体识别有效地减轻了监督设置中耗时且昂贵的注释负担，但是无上下文的匹配过程和知识库的有限覆盖引入了不准确和不完整的标注噪音。本研究提出了使用不同的策略来处理两种类型的噪声的SANTA，以解决由不准确和不完整标注带来的挑战。

    Distantly-Supervised Named Entity Recognition effectively alleviates the burden of time-consuming and expensive annotation in the supervised setting. But the context-free matching process and the limited coverage of knowledge bases introduce inaccurate and incomplete annotation noise respectively. Previous studies either considered only incomplete annotation noise or indiscriminately handle two types of noise with the same strategy. In this paper, we argue that the different causes of two types of noise bring up the requirement of different strategies in model architecture. Therefore, we propose the SANTA to handle these two types of noise separately with (1) Memory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity problem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate decision boundary shifting problem caused by incomplete annotation and a noise-tolerant loss to improve the robustness. Benefiting from our separate tailored strategies, we co
    
[^15]: 反应性摄入扰动：对抗文本防御的一种方法

    Reactive Perturbation Defocusing for Textual Adversarial Defense. (arXiv:2305.04067v1 [cs.CL])

    [http://arxiv.org/abs/2305.04067](http://arxiv.org/abs/2305.04067)

    RPD对大型预训练语言模型的漏洞进行了防御，通过识别对抗性示例并注入安全扰动来减少误防御，成功地修复了高达97%的对抗性示例，在自然示例的性能仅降低了约2%。

    

    最近的研究表明，大型预训练语言模型容易受到对抗性攻击。现有的方法试图重构对抗性示例，但这些方法通常在防御对抗性示例方面性能有限，同时也会对自然示例的性能产生负面影响。为了解决这个问题，我们提出了一种称为反应性摄入扰动 (RPD) 的方法。RPD 使用对抗检测器识别对抗性示例，并减少在自然示例上的误防御。RPD 不是重构对手，而是在对抗性示例中注入安全扰动，以分散目标模型对恶意扰动的注意力。我们在三个数据集、两个目标模型和各种对抗性攻击上的实验表明，我们提出的框架成功地修复了大约 97% 的正确识别的对抗性示例，并且自然示例的性能仅降低了约 2%。

    Recent studies have shown that large pre-trained language models are vulnerable to adversarial attacks. Existing methods attempt to reconstruct the adversarial examples. However, these methods usually have limited performance in defense against adversarial examples, while also negatively impacting the performance on natural examples. To overcome this problem, we propose a method called Reactive Perturbation Defocusing (RPD). RPD uses an adversarial detector to identify adversarial examples and reduce false defenses on natural examples. Instead of reconstructing the adversaries, RPD injects safe perturbations into adversarial examples to distract the objective models from the malicious perturbations. Our experiments on three datasets, two objective models, and various adversarial attacks show that our proposed framework successfully repairs up to approximately 97% of correctly identified adversarial examples with only about a 2% performance decrease on natural examples. We also provide 
    
[^16]: 主动发现面向任务对话的新槽位

    Actively Discovering New Slots for Task-oriented Conversation. (arXiv:2305.04049v1 [cs.CL])

    [http://arxiv.org/abs/2305.04049](http://arxiv.org/abs/2305.04049)

    该论文探讨了如何主动发现面向任务对话的新槽位，以提高交互性能。由于实际应用中新的用户需求和不断变化的场景，使现有的对话搜索系统变得无法满足。其提出了一种通用的新插槽发现任务，通过信息提取的方式进行。

    

    现有的面向任务的对话搜索系统严重依赖于具有预定义插槽和候选值集的领域本体论。在实际应用中，由于新的用户需求和不断变化的场景，这些先决条件很难满足。为了缓解这些问题，以获得更好的交互性能，一些工作致力于在无监督或半监督学习范式下检测词汇表外的值或发现新的插槽位置。然而，仅仅过分强调对话数据模式会导致这些方法产生嘈杂和任意的插槽结果。为了促进实际应用，现实世界的系统 tend to 提供严格的人工标注配额，这提供了一种权威的方式来获得准确和有意义的插槽分配。然而，这也提出了高要求，即高效利用这种配额。因此，我们以信息提取的方式形成一个通用的新插槽发现任务。

    Existing task-oriented conversational search systems heavily rely on domain ontologies with pre-defined slots and candidate value sets. In practical applications, these prerequisites are hard to meet, due to the emerging new user requirements and ever-changing scenarios. To mitigate these issues for better interaction performance, there are efforts working towards detecting out-of-vocabulary values or discovering new slots under unsupervised or semi-supervised learning paradigm. However, overemphasizing on the conversation data patterns alone induces these methods to yield noisy and arbitrary slot results. To facilitate the pragmatic utility, real-world systems tend to provide a stringent amount of human labelling quota, which offers an authoritative way to obtain accurate and meaningful slot assignments. Nonetheless, it also brings forward the high requirement of utilizing such quota efficiently. Hence, we formulate a general new slot discovery task in an information extraction fashio
    
[^17]: Diffusion-NAT: 自我启发离散扩散的非自回归文本生成

    Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation. (arXiv:2305.04044v1 [cs.CL])

    [http://arxiv.org/abs/2305.04044](http://arxiv.org/abs/2305.04044)

    本文提出了Diffusion-NAT，将离散扩散模型引入非自回归文本生成中，并结合BART实现统一的推理和去噪过程，在此基础上提出了迭代的自我提示策略来进一步提高生成质量。

    

    最近，将连续扩散模型引入非自回归文本生成中，但文本的离散性增加了生成连贯和流畅文本的难度，并引起了扩散模型与NLP技术中的兼容性问题。为了解决这个问题，我们提出了Diffusion-NAT，将离散扩散模型引入非自回归文本生成中，并集成BART来提高性能。通过修改BART解码过程和DDM的典型设置，我们将BART的推理过程和DDM的去噪过程统一为相同的NAR掩码令牌还原任务。这样，DDM就可以依靠BART执行去噪，既可以从BART的丰富预学习知识中受益，也可以从DDM的迭代细化范例中受益。此外，我们还提出了迭代的自我提示策略来进一步提高生成质量。

    Recently, continuous diffusion models (CDM) have been introduced into non-autoregressive (NAR) text-to-text generation. However, the discrete nature of text increases the difficulty of CDM to generate coherent and fluent texts, and also causes the incompatibility problem between CDM and advanced NLP techniques, especially the popular pre-trained language models~(PLMs). To solve it, we propose Diffusion-NAT, which introduces discrete diffusion models~(DDM) into NAR text-to-text generation and integrates BART to improve the performance. By revising the decoding process of BART and the typical settings of DDM, we unify the inference process of BART and the denoising process of DDM into the same NAR masked tokens recovering task. In this way, DDM can rely on BART to perform denoising, which can benefit from both the rich pre-learned knowledge of BART and the iterative refining paradigm of DDM. Besides, we also propose the iterative self-prompting strategy to further improve the generation 
    
[^18]: 通过自我优化来提升LLMs的响应质量

    Refining the Responses of LLMs by Themselves. (arXiv:2305.04039v1 [cs.CL])

    [http://arxiv.org/abs/2305.04039](http://arxiv.org/abs/2305.04039)

    本文提出了一种利用自我优化机制来改善大型语言模型响应质量的方法，实验证明在GPT-3.5模型上使用此方法，生成的结果质量可以与甚至超过GPT-4模型。

    

    本文提出了一种基于提示工程的简单而高效的方法，利用大型语言模型本身来优化其答案，而不依赖于辅助模型。我们引入了一种迭代的自我评估优化机制，随着迭代的推进，具有改善输出质量的潜力，无需手动干预。实验结果表明，在GPT-3.5模型上使用我们的响应优化框架产生的结果与甚至超过先进的GPT-4模型生成的结果。提供了详细的实施策略和说明性示例，以证明我们提出的解决方案的优越性。

    In this paper, we propose a simple yet efficient approach based on prompt engineering that leverages the large language model itself to optimize its answers without relying on auxiliary models. We introduce an iterative self-evaluating optimization mechanism, with the potential for improved output quality as iterations progress, removing the need for manual intervention. The experiment's findings indicate that utilizing our response refinement framework on the GPT-3.5 model yields results that are on par with, or even surpass, those generated by the cutting-edge GPT-4 model. Detailed implementation strategies and illustrative examples are provided to demonstrate the superiority of our proposed solution.
    
[^19]: ANTONIO:面向NLP验证的系统化基准生成方法

    ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification. (arXiv:2305.04003v1 [cs.CL])

    [http://arxiv.org/abs/2305.04003](http://arxiv.org/abs/2305.04003)

    本文介绍了一种名为ANTONIO的Python库，它基于抽象解释方法提供了一种实用的方法和启发式规则，以便为自然语言处理（NLP）数据集和模型生成已知验证方法的基准。因为其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。

    

    自然语言处理（NLP）中使用的机器学习模型的验证被认为是一个难题。现有的神经网络验证方法常用于计算机视觉和其他数字数据集，但并不适用于NLP。本研究探讨了造成这一问题的技术原因，并在此基础上提出了实用的方法和启发式规则，以便将NLP数据集和模型准备为适合基于抽象解释的已知验证方法。我们将这些方法实现为一个名为ANTONIO的Python库，该库连接到神经网络验证器ERAN和Marabou。我们使用一个名为R-U-A-Robot的NLP数据集对工具进行了评估，该数据集被提议作为验证具有法律重要性的NLP应用的基准。我们希望，由于其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。

    Verification of machine learning models used in Natural Language Processing (NLP) is known to be a hard problem. In particular, many known neural network verification methods that work for computer vision and other numeric datasets do not work for NLP. Here, we study technical reasons that underlie this problem. Based on this analysis, we propose practical methods and heuristics for preparing NLP datasets and models in a way that renders them amenable to known verification methods based on abstract interpretation. We implement these methods as a Python library called ANTONIO that links to the neural network verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP applications. We hope that, thanks to its general applicability, this work will open novel possibilities for including NLP verification problems into neural network verification competitions, and will popularise NLP problems withi
    
[^20]: 通过离线模仿学习与监督正则化复制人类复杂的对话策略

    Replicating Complex Dialogue Policy of Humans via Offline Imitation Learning with Supervised Regularization. (arXiv:2305.03987v1 [cs.CL])

    [http://arxiv.org/abs/2305.03987](http://arxiv.org/abs/2305.03987)

    本文提出了一个离线模仿学习模型，通过监督正则化来解决协变量漂移问题，该模型能够复制人类复杂的对话策略，并在基准数据集上获得了最新的结果。

    

    本文提出了一个离线模仿学习模型，通过监督正则化来解决协变量漂移问题，从而学习真实对话数据集中的策略。这个模型不需要用户模拟器，并在基准数据集上获得了与现有方法相比的最新结果。

    Policy learning (PL) is a module of a task-oriented dialogue system that trains an agent to make actions in each dialogue turn. Imitating human action is a fundamental problem of PL. However, both supervised learning (SL) and reinforcement learning (RL) frameworks cannot imitate humans well. Training RL models require online interactions with user simulators, while simulating complex human policy is hard. Performances of SL-based models are restricted because of the covariate shift problem. Specifically, a dialogue is a sequential decision-making process where slight differences in current utterances and actions will cause significant differences in subsequent utterances. Therefore, the generalize ability of SL models is restricted because statistical characteristics of training and testing dialogue data gradually become different. This study proposed an offline imitation learning model that learns policy from real dialogue datasets and does not require user simulators. It also utilize
    
[^21]: 作为多角度课程学习机器的预训练语言模型

    Pre-training Language Model as a Multi-perspective Course Learner. (arXiv:2305.03981v1 [cs.CL])

    [http://arxiv.org/abs/2305.03981](http://arxiv.org/abs/2305.03981)

    本文提出了一种多角度课程学习的方法，使用三个自监督课程和两个自我修正课程，以平衡标签和充分利用生成器和辨别器之间的关系进行高效的预训练。

    

    ELECTRA是一个生成器-鉴别器的预训练框架，已经在各种下游任务中取得了令人印象深刻的语义构建能力。尽管性能令人信服，但ELECTRA仍面临单调的训练和不足的交互挑战。只有掩码语言建模（MLM）的生成器会导致对于辨别器的学习效率下降的偏向性学习和标签不平衡;同时没有明确的辨别器到生成器的反馈环路导致这两个组件之间的差距，未充分利用课程学习。因此，本研究提出了一种多角度课程学习（MCL）方法，以多个角度获取样本高效预训练，并充分利用生成器和辨别器之间的关系。具体而言，设计了三个自监督课程来减轻MLM的固有缺陷，并以多角度方式平衡标签。此外，还提出了两种自我修正课程来弥合辨别器和生成器之间的差距，从而充分利用课程学习。

    ELECTRA, the generator-discriminator pre-training framework, has achieved impressive semantic construction capability among various downstream tasks. Despite the convincing performance, ELECTRA still faces the challenges of monotonous training and deficient interaction. Generator with only masked language modeling (MLM) leads to biased learning and label imbalance for discriminator, decreasing learning efficiency; no explicit feedback loop from discriminator to generator results in the chasm between these two components, underutilizing the course learning. In this study, a multi-perspective course learning (MCL) method is proposed to fetch a many degrees and visual angles for sample-efficient pre-training, and to fully leverage the relationship between generator and discriminator. Concretely, three self-supervision courses are designed to alleviate inherent flaws of MLM and balance the label in a multi-perspective way. Besides, two self-correction courses are proposed to bridge the cha
    
[^22]: 一种带有不完整信息的文本生成对抗非自回归模型

    An Adversarial Non-Autoregressive Model for Text Generation with Incomplete Information. (arXiv:2305.03977v1 [cs.CL])

    [http://arxiv.org/abs/2305.03977](http://arxiv.org/abs/2305.03977)

    提出了一种新的对抗非自回归Transformer模型用于对不完整信息的文本生成，其具有位置感知自调节和依赖接口网络，能够在与其他主流模型相比更快的解码时间内获得可比较性能，具有在潜在插值等应用中的巨大潜力。

    

    非自回归模型在完整信息情况（CIS）下已广泛研究，其中模型具有完整的输入信息来获取相应的输出。然而，它们在不完整信息情况（IIS）下的探索极为有限。我们的分析表明，IIS中不完整的输入信息将增加在最大似然估计下训练的现有非自回归模型的固有限制。在本文中，我们针对IIS提出了一种对抗非自回归Transformer （ANT）模型，具有两个新特性：1）位置感知自调节，可以提供更合理的隐藏表示；2）依赖性前馈网络，可以增强其依赖性建模能力。我们将ANT与IIS中的其他主流模型进行比较，并证明ANT可以实现可比较性能，同时也可以比其他模型更快地进行解码。此外，我们展示了ANT在潜在插值等各种应用方面的巨大潜力。

    Non-autoregressive models have been widely studied in the Complete Information Scenario (CIS), in which the models have complete input information to obtain corresponding output. However, their explorations in the Incomplete Information Scenario (IIS) are extremely limited. Our analyses reveal that the IIS's incomplete input information will augment the inherent limitations of existing non-autoregressive models trained under Maximum Likelihood Estimation. In this paper, we propose for the IIS an Adversarial Non-autoregressive Transformer (ANT) which has two novel features: 1) Position Aware Self-Modulation to provide more reasonable hidden representations, and 2) Dependency Feed Forward Network to strengthen its capacity in dependency modeling. We compare ANT with other mainstream models in the IIS and demonstrate that ANT can achieve comparable performance with much fewer decoding iterations. Furthermore, we show its great potential in various applications like latent interpolation an
    
[^23]: DiscoPrompt: 隐含语篇关系识别中的路径预测提示优化

    DiscoPrompt: Path Prediction Prompt Tuning for Implicit Discourse Relation Recognition. (arXiv:2305.03973v1 [cs.CL])

    [http://arxiv.org/abs/2305.03973](http://arxiv.org/abs/2305.03973)

    DiscoPrompt是一种新的方法，通过预测层次结构内部的路径来识别隐含语篇关系，相比于以往的纯文本分类方法更加有效。

    

    隐含语篇关系识别(IDRR)是一项复杂而具有挑战性的任务，用于识别参数之间的话语关系，其中不存在话语连接词。在注释过程中，每个话语关系的语义标签遵循一种层次分类体系(Prasad等人，2008)，形成了一个层次结构。大多数现有作品没有很好地整合这种层次结构，而是专注于纯文本分类中的句法特征和连词的先验知识。我们认为，预测层次结构内部的路径(例如，“比较->对比->然而”)比预测平面标签(例如，对比)或连词(例如，然而)更有效。我们提出了一种基于提示的路径预测方法，利用IDRR中层次结构之间的交互信息和内在语义。这是第一个通过提示优化将这种结构信息注入预训练语言模型中的工作。

    Implicit Discourse Relation Recognition (IDRR) is a sophisticated and challenging task to recognize the discourse relations between the arguments with the absence of discourse connectives. The sense labels for each discourse relation follow a hierarchical classification scheme in the annotation process (Prasad et al., 2008), forming a hierarchy structure. Most existing works do not well incorporate the hierarchy structure but focus on the syntax features and the prior knowledge of connectives in the manner of pure text classification. We argue that it is more effective to predict the paths inside the hierarchical tree (e.g., "Comparison -> Contrast -> however") rather than flat labels (e.g., Contrast) or connectives (e.g., however). We propose a prompt-based path prediction method to utilize the interactive information and intrinsic senses among the hierarchy in IDRR. This is the first work that injects such structure information into pre-trained language models via prompt tuning, and 
    
[^24]: 自适应宽松优化用于强韧问答系统

    Adaptive loose optimization for robust question answering. (arXiv:2305.03971v1 [cs.CL])

    [http://arxiv.org/abs/2305.03971](http://arxiv.org/abs/2305.03971)

    本论文提出了一种简单而有效的自适应宽松优化损失函数，用于为问答系统综合内外分布的最佳表现，并显示了对对抗攻击的强韧性。

    

    问答方法以利用数据偏差为特点，如视觉问答中的语言先验和机器阅读理解（抽取式问答）中的位置偏差。目前的去偏方法往往以在分布内表现不佳为代价获得有利的分布外泛化能力，而不去偏方法则在获得高分布内表现的同时牺牲了相当数量的分布外表现。因此，它们难以应对复杂变化的现实世界情况。本文提出了一种简单而有效的新型自适应宽松优化损失函数，为问答系统综合两者最佳表现而努力。我们的主要技术贡献是根据小批量训练数据上先前和当前优化状态之间的比率自适应地减少损失。这种宽松优化可以用来防止非凸优化陷入局部最小值，并帮助模型学习更好的表示。实验证明，我们的方法在各种基准测试中与最先进的方法具有竞争性能，同时表现出对对抗性攻击的强韧性。

    Question answering methods are well-known for leveraging data bias, such as the language prior in visual question answering and the position bias in machine reading comprehension (extractive question answering). Current debiasing methods often come at the cost of significant in-distribution performance to achieve favorable out-of-distribution generalizability, while non-debiasing methods sacrifice a considerable amount of out-of-distribution performance in order to obtain high in-distribution performance. Therefore, it is challenging for them to deal with the complicated changing real-world situations. In this paper, we propose a simple yet effective novel loss function with adaptive loose optimization, which seeks to make the best of both worlds for question answering. Our main technical contribution is to reduce the loss adaptively according to the ratio between the previous and current optimization state on mini-batch training data. This loose optimization can be used to prevent non
    
[^25]: 从命名实体识别到机器阅读理解：一个完整解决命名实体识别问题的方法

    NER-to-MRC: Named-Entity Recognition Completely Solving as Machine Reading Comprehension. (arXiv:2305.03970v1 [cs.CL])

    [http://arxiv.org/abs/2305.03970](http://arxiv.org/abs/2305.03970)

    该论文提出了一种称为NER-to-MRC的方法，将命名实体识别问题完全作为机器阅读理解问题来解决。该方法采用一种新的跨度相关表示学习模块和预训练过程，提高了NER的性能，并且只使用了一小部分额外数据。

    

    命名实体识别（NER）是自然语言处理（NLP）中的一个基本模块，用于检测带有预定义语义标签的文本。然而，最近的NER研究集中于利用大量额外的数据，包括预训练语料库和集成搜索引擎等。然而，这些方法面临着与数据收集和预训练相关的高成本，以及从搜索引擎检索的数据的额外训练过程。为解决上述问题，我们通过借鉴机器阅读理解（MRC）和它的有效利用现有数据的能力，将NER完全框架为MRC问题，称之为NER-to-MRC。虽然之前的MRC研究致力于使用MRC解决NER问题，但仍存在几个挑战：i）依赖手动设计的提示；ii）限制MRC方法对数据重建的能力，无法达到利用大量额外数据的方法的表现水平。因此，我们的NER-to-MRC方法提出了一种将NER问题重新阐释为MRC中的跨度提取任务的方法，利用了一种新的跨度相关表示学习模块和预训练过程。我们的方法仅使用了一小部分额外数据，就实现了比以前的NER作品更先进的性能。

    Named-entity recognition (NER) detects texts with predefined semantic labels and is an essential building block for natural language processing (NLP). Notably, recent NER research focuses on utilizing massive extra data, including pre-training corpora and incorporating search engines. However, these methods suffer from high costs associated with data collection and pre-training, and additional training process of the retrieved data from search engines. To address the above challenges, we completely frame NER as a machine reading comprehension (MRC) problem, called NER-to-MRC, by leveraging MRC with its ability to exploit existing data efficiently. Several prior works have been dedicated to employing MRC-based solutions for tackling the NER problem, several challenges persist: i) the reliance on manually designed prompts; ii) the limited MRC approaches to data reconstruction, which fails to achieve performance on par with methods utilizing extensive additional data. Thus, our NER-to-MRC
    
[^26]: 从自然语言文本中生成流程模型的方法——基于规则之外的命名实体识别和关系抽取(arXiv:2305.03960v1 [cs.CL])

    Beyond Rule-based Named Entity Recognition and Relation Extraction for Process Model Generation from Natural Language Text. (arXiv:2305.03960v1 [cs.CL])

    [http://arxiv.org/abs/2305.03960](http://arxiv.org/abs/2305.03960)

    本文扩展了PET数据集，通过聚类流程实体的提及，提出了一种新的基线技术流程提取方法，该方法避免了手动创建业务流程模型的繁琐工作，同时解决了同一流程实体重复提及的歧义问题。

    

    从自然语言文本自动生成业务流程模型是一种新兴方法，可避免手动创建形式化业务流程模型。为此，需要从文本流程描述中提取出流程实体（如参与者、活动、对象等）和它们之间的关系。一个高质量的带有文本流程描述的注释语料库(PET)已经出版，其伴随着一种基本的流程提取方法。然而，在其当前状态下，PET缺乏有关两个提及是否指代了相同或不同的流程实体的信息，这对于是否在目标模型中创建一个或两个建模元素的重要决策相对应。因此，例如，两个数据处理的提及是否意味着处理不同或相同的数据是不确定的。在本文中，我们通过聚类流程实体的提及来扩展PET数据集，并提出了一种新的基线技术流程提取方法，其中包含一个

    Automated generation of business process models from natural language text is an emerging methodology for avoiding the manual creation of formal business process models. For this purpose, process entities like actors, activities, objects etc., and relations among them are extracted from textual process descriptions. A high-quality annotated corpus of textual process descriptions (PET) has been published accompanied with a basic process extraction approach. In its current state, however, PET lacks information about whether two mentions refer to the same or different process entities, which corresponds to the crucial decision of whether to create one or two modeling elements in the target model. Consequently, it is ambiguous whether, for instance, two mentions of data processing mean processing of different, or the same data. In this paper, we extend the PET dataset by clustering mentions of process entities and by proposing a new baseline technique for process extraction equipped with a
    
[^27]: 基于残差重参数化的Prompt Tuning改进方法

    Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization. (arXiv:2305.03937v1 [cs.CL])

    [http://arxiv.org/abs/2305.03937](http://arxiv.org/abs/2305.03937)

    本文提出了一种基于残差重参数化的Prompt Tuning改进方法-Residual Prompt Tuning，能够显著提高调优的性能和稳定性，在超过Prompt Tuning 7个点，且可以缩短Prompt长度10倍而不影响性能，同时对于学习率和Prompt初始化的选择具有鲁棒性。

    

    Prompt Tuning是目前增强预训练语言模型参数效率的一种成功方法。尽管其参数效率最高（调整的soft prompts不到总参数的0.1%），但它通常表现比其他效率高的调优方法更差，并且对超参数非常敏感。本文提出了一种简单高效的Residual Prompt Tuning方法，可显著改善Prompt Tuning的性能和稳定性。我们提出使用带有残差连接的浅层网络对软Prompt的重参数化嵌入。我们的实验表明，在SuperGLUE基准测试中，Residual Prompt Tuning明显优于Prompt Tuning。值得注意的是，我们的方法与T5-Base相比，在不影响性能的情况下将Prompt长度缩短了10倍，且对于学习率和Prompt初始化的选择具有鲁棒性，并且在少样本学习方面也非常有效。

    Prompt tuning is one of the successful approaches for parameter-efficient tuning of pre-trained language models. Despite being arguably the most parameter-efficient (tuned soft prompts constitute <0.1% of total parameters), it typically performs worse than other efficient tuning methods and is quite sensitive to hyper-parameters. In this work, we introduce Residual Prompt Tuning - a simple and efficient method that significantly improves the performance and stability of prompt tuning. We propose to reparameterize soft prompt embeddings using a shallow network with a residual connection. Our experiments show that Residual Prompt Tuning significantly outperforms prompt tuning on SuperGLUE benchmark. Notably, our method reaches +7 points improvement over prompt tuning with T5-Base and allows to reduce the prompt length by 10x without hurting performance. In addition, we show that our approach is robust to the choice of learning rate and prompt initialization, and is effective in few-shot 
    
[^28]: 主动的连续学习：在任务序列中标记查询。

    Active Continual Learning: Labelling Queries in a Sequence of Tasks. (arXiv:2305.03923v1 [cs.LG])

    [http://arxiv.org/abs/2305.03923](http://arxiv.org/abs/2305.03923)

    本文考虑了一系列主动学习任务的主动连续学习问题，研究了不同场景下多种主动和连续学习算法之间的有效性和相互作用，并提出了遗忘-学习曲线方法来平衡不忘旧知识和快速学习的两个目标。

    

    在连续学习（CL）中，获取新知识并不忘记已学内容是其核心。而任务是按顺序出现的，训练数据的准备和注释则通常是独立的，因此需要连续学习来适应新的监督学习任务。本文考虑了一系列主动学习（AL）任务的主动连续学习（ACL）中未被充分探索的问题，每个任务包括一个未标记的数据池和一个注释预算。我们研究了几种AL和CL算法在不同领域，类别和任务增量场景中的有效性和相互作用。实验揭示了不忘旧知识和快速学习在CL和AL中之间的权衡。尽管在以前任务的注释收集上条件查询策略会提高领域和任务增量学习的任务性能，但我们提出的遗忘-学习曲线则更好地平衡了这两个目标。

    Acquiring new knowledge without forgetting what has been learned in a sequence of tasks is the central focus of continual learning (CL). While tasks arrive sequentially, the training data are often prepared and annotated independently, leading to CL of incoming supervised learning tasks. This paper considers the under-explored problem of active continual learning (ACL) for a sequence of active learning (AL) tasks, where each incoming task includes a pool of unlabelled data and an annotation budget. We investigate the effectiveness and interplay between several AL and CL algorithms in the domain, class and task-incremental scenarios. Our experiments reveal the trade-off between two contrasting goals of not forgetting the old knowledge and the ability to quickly learn in CL and AL. While conditioning the query strategy on the annotations collected for the previous tasks leads to improved task performance on the domain and task incremental learning, our proposed forgetting-learning profil
    
[^29]: HateMM：用于仇恨视频分类的多模态数据集

    HateMM: A Multi-Modal Dataset for Hate Video Classification. (arXiv:2305.03915v1 [cs.CV])

    [http://arxiv.org/abs/2305.03915](http://arxiv.org/abs/2305.03915)

    仇恨言论的研究主要集中在文本媒体上，使用多模态检测仇恨视频并从视频共享平台中删除仇恨内容成为重点。因为仇恨视频的图像和音频中存在各种线索，因此我们构建了深度学习的多模态模型进行研究。

    

    仇恨言论已成为现代社会中最重要的问题之一，对线上和线下世界都产生了影响。由于这一点，近来对仇恨言论的研究引起了广泛关注。然而，大部分工作主要集中在文本媒体上，对图像和视频的研究相对较少。因此，需要早期的自动化视频审核技术来处理被上传的视频，以保持平台的安全和健康。我们的工作旨在使用多模式检测仇恨视频并从视频共享平台中检测和删除仇恨内容。为此，我们从BitChute中策划了约43个小时的视频，并手动注释了它们是否属于仇恨或非仇恨，并提供了可以解释标注决策的帧跨度。我们利用仇恨词汇表的搜索关键字收集相关的视频，观察到在仇恨视频的图像和音频中存在各种线索。此外，我们构建了深度学习的多模态模型。

    Hate speech has become one of the most significant issues in modern society, having implications in both the online and the offline world. Due to this, hate speech research has recently gained a lot of traction. However, most of the work has primarily focused on text media with relatively little work on images and even lesser on videos. Thus, early stage automated video moderation techniques are needed to handle the videos that are being uploaded to keep the platform safe and healthy. With a view to detect and remove hateful content from the video sharing platforms, our work focuses on hate video detection using multi-modalities. To this end, we curate ~43 hours of videos from BitChute and manually annotate them as hate or non-hate, along with the frame spans which could explain the labelling decision. To collect the relevant videos we harnessed search keywords from hate lexicons. We observe various cues in images and audio of hateful videos. Further, we build deep learning multi-modal
    
[^30]: 图像搜索中的公平性：关于从图像检索与去偏见角度探究职业模式刻板印象的研究。

    Fairness in Image Search: A Study of Occupational Stereotyping in Image Retrieval and its Debiasing. (arXiv:2305.03881v1 [cs.IR])

    [http://arxiv.org/abs/2305.03881](http://arxiv.org/abs/2305.03881)

    本文针对职业模式刻板印象问题，研究了网络搜索中的偏见和公平性问题。实验表明当前的图像搜索引擎存在相当严重的职业模式刻板印象，提出了一种去偏见方法以减轻此类偏见并提高图像搜索引擎的公平性。

    

    多模式搜索引擎近年来经历了显著的增长和广泛的使用，成为继信息检索之后第二常见的互联网使用方式。尽管搜索引擎系统提供了一系列服务，但图像搜索领域最近成为信息检索社区的焦点，因为常言道“一图胜千言”。虽然像谷歌这样的流行搜索引擎在图像搜索精度和敏捷性方面表现出色，但人们对它们的搜索结果是否会存在性别、语言、人口统计、社会文化方面的偏见存在争议。这种潜在的偏见可能会对个人的认知产生重要影响，并影响他们的视角。本文主要研究网络搜索中的偏见和公平性问题，重点关注基于关键字的图像搜索方面。我们首先讨论了搜索系统中存在的几种偏见类型以及为什么有必要加以缓解。我们将研究重点缩小到评估和缓解图像检索中的职业模式刻板印象。我们的实验表明，当前的图像搜索引擎存在相当严重的职业模式刻板印象，这可能对个人和整个社会产生不利影响。我们提出了一种去偏见方法，以减轻此类偏见并提高图像搜索引擎的公平性。

    Multi-modal search engines have experienced significant growth and widespread use in recent years, making them the second most common internet use. While search engine systems offer a range of services, the image search field has recently become a focal point in the information retrieval community, as the adage goes, "a picture is worth a thousand words". Although popular search engines like Google excel at image search accuracy and agility, there is an ongoing debate over whether their search results can be biased in terms of gender, language, demographics, socio-cultural aspects, and stereotypes. This potential for bias can have a significant impact on individuals' perceptions and influence their perspectives.  In this paper, we present our study on bias and fairness in web search, with a focus on keyword-based image search. We first discuss several kinds of biases that exist in search systems and why it is important to mitigate them. We narrow down our study to assessing and mitigat
    
[^31]: NorBench--挪威语言模型基准测试。

    NorBench -- A Benchmark for Norwegian Language Models. (arXiv:2305.03880v1 [cs.CL])

    [http://arxiv.org/abs/2305.03880](http://arxiv.org/abs/2305.03880)

    NorBench是用来评估挪威语言模型的基准测试，其中包括简化的自然语言处理任务和探测套件，可以用于评估各种挪威语言模型的标准数据和评估指标。

    

    我们提出了NorBench：一个简化的NLP任务和探测套件，用于在标准数据划分和评估指标上评估挪威语言模型（LMs）。 我们还引入了一系列新的挪威语言模型（基于编码器和编码器-解码器）。 最后，我们比较和分析它们的表现，以及其他现有的LMs，在NorBench的不同基准测试中。

    We present NorBench: a streamlined suite of NLP tasks and probes for evaluating Norwegian language models (LMs) on standardized data splits and evaluation metrics. We also introduce a range of new Norwegian language models (both encoder and encoder-decoder based). Finally, we compare and analyze their performance, along with other existing LMs, across the different benchmark tests of NorBench.
    
[^32]: 全球训练，本地定制：极少资源语言的极简多语言翻译

    Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages. (arXiv:2305.03873v1 [cs.CL])

    [http://arxiv.org/abs/2305.03873](http://arxiv.org/abs/2305.03873)

    该论文研究了利用多种丰富资源语言的翻译资源来最大限度地提高极少资源语言的翻译质量，以减少人工翻译的工作量。

    

    在许多人道主义场景中，向极度低资源的语言进行翻译通常不需要通用的翻译引擎，而是需要专门的文本特定翻译引擎。我们尝试利用多种丰富资源语言的翻译资源，高效地在新的极少资源语言中为一个已知的文本产生最好的可能翻译质量。

    In many humanitarian scenarios, translation into severely low resource languages often does not require a universal translation engine, but a dedicated text-specific translation engine. For example, healthcare records, hygienic procedures, government communication, emergency procedures and religious texts are all limited texts. While generic translation engines for all languages do not exist, translation of multilingually known limited texts into new, endangered languages may be possible and reduce human translation effort. We attempt to leverage translation resources from many rich resource languages to efficiently produce best possible translation quality for a well known text, which is available in multiple languages, in a new, severely low resource language. We examine two approaches: 1. best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and 2. we adapt large general multilingua
    
[^33]: 运动科学与医学中的大型语言模型：机遇、风险和考虑因素

    Large Language Models in Sport Science & Medicine: Opportunities, Risks and Considerations. (arXiv:2305.03851v1 [cs.CL])

    [http://arxiv.org/abs/2305.03851](http://arxiv.org/abs/2305.03851)

    运动科学和医学领域中，大型语言模型可以提供支持和增强从业者知识的潜力，为个性化训练计划提供建议，并向发展中国家的从业者分发高质量信息，但使用和开发LLM存在风险，需要进一步研究。

    

    本文探讨了在运动科学和医学领域使用大型语言模型（LLM）所面临的潜在机遇、风险和挑战。LLM是大规模神经网络，采用转换器风格的架构，在大量文本数据上训练，并通常通过人类反馈进行改进。LLM可以执行大量的自然语言处理任务。在运动科学和医学领域，LLM具有支持和增强运动医学从业者知识的潜力，为个性化训练计划提供建议，并潜在地向发展中国家的从业者分发高质量信息。但是，使用和开发LLM也存在潜在风险，包括基于用于创建模型的数据集的偏见，泄露机密数据的风险，生成有害输出的风险，以及需要通过反馈使这些模型与人类喜好相一致的需求。需要进一步研究来全面了解LLM的使用。

    This paper explores the potential opportunities, risks, and challenges associated with the use of large language models (LLMs) in sports science and medicine. LLMs are large neural networks with transformer style architectures trained on vast amounts of textual data, and typically refined with human feedback. LLMs can perform a large range of natural language processing tasks. In sports science and medicine, LLMs have the potential to support and augment the knowledge of sports medicine practitioners, make recommendations for personalised training programs, and potentially distribute high-quality information to practitioners in developing countries. However, there are also potential risks associated with the use and development of LLMs, including biases in the dataset used to create the model, the risk of exposing confidential data, the risk of generating harmful output, and the need to align these models with human preferences through feedback. Further research is needed to fully unde
    
[^34]: SemEval-2023任务2中CLaC：比较序列标记和跨度预测方法用于命名实体识别

    CLaC at SemEval-2023 Task 2: Comparing Span-Prediction and Sequence-Labeling approaches for NER. (arXiv:2305.03845v1 [cs.CL])

    [http://arxiv.org/abs/2305.03845](http://arxiv.org/abs/2305.03845)

    本文比较了命名实体识别中的序列标记和跨度预测两种方法，在测试数据中跨度预测表现略优，并且使用更大版本的XLM RoBERTa可以显著提高性能。

    

    本文总结了CLaC对于MultiCoNER 2任务的提交，该任务涉及复杂的细粒度命名实体的识别。我们比较了命名实体识别中两种流行的方法，即序列标记和跨度预测。我们发现，在测试数据上，我们最好的跨度预测系统的表现略优于我们最好的序列标记系统。此外，我们发现使用更大版本的XLM RoBERTa可以显著提高性能。后续的实验表明，当使用XLM-RoBERTa的特殊输入标记（<s>和</s>）时，跨度预测和序列标记方法都会得到改进。所有模型训练，预处理和后处理的代码都可以在https://github.com/harshshredding/semeval2023-multiconer-paper找到。

    This paper summarizes the CLaC submission for the MultiCoNER 2 task which concerns the recognition of complex, fine-grained named entities. We compare two popular approaches for NER, namely Sequence Labeling and Span Prediction. We find that our best Span Prediction system performs slightly better than our best Sequence Labeling system on test data. Moreover, we find that using the larger version of XLM RoBERTa significantly improves performance. Post-competition experiments show that Span Prediction and Sequence Labeling approaches improve when they use special input tokens (<s> and </s>) of XLM-RoBERTa. The code for training all models, preprocessing, and post-processing is available at https://github.com/harshshredding/semeval2023-multiconer-paper.
    
[^35]: 基于不确定性感知的Bootstrap学习用于远程监督数据联合抽取

    Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data. (arXiv:2305.03827v1 [cs.CL])

    [http://arxiv.org/abs/2305.03827](http://arxiv.org/abs/2305.03827)

    本文提出了基于不确定性感知的Bootstrap学习用于远程监督数据联合抽取。通过探索数据不确定性和自我集成正则化器，使得模型在早期快速收敛并且缓解了噪声标签产生的模型不确定性，并在两个大型数据集上实验表明该方法在实体对抽取和关系抽取方面的F1得分分别提高了4.43%和4.92%。

    

    在处理带有模糊或噪声标签的远程监督数据时，联合抽取实体对及其关系是具有挑战性的。为了缓解这种影响，我们提出了基于不确定性感知的Bootstrap学习，其动机是根据直觉，一个实例的不确定性越高，模型置信度与真实标签不一致的可能性就越大。具体而言，我们首先探索实例级别的数据不确定性，创建一个高置信的初始样例集。这样的子集用于过滤噪声实例，并有助于模型在早期快速收敛。在Bootstrap学习期间，我们提出自我集成作为正则化器，以减轻噪声标签产生的模型间不确定性。我们进一步定义联合标记概率的概率方差，以估计内部模型参数的不确定性，用于选择和建立新的可靠训练实例进行下一次迭代。两个大型数据集的实验结果表明，我们的方法明显优于最先进的基准方法，在实体对抽取和关系抽取方面的F1得分分别提高了4.43%和4.92%。

    Jointly extracting entity pairs and their relations is challenging when working on distantly-supervised data with ambiguous or noisy labels. To mitigate such impact, we propose uncertainty-aware bootstrap learning, which is motivated by the intuition that the higher uncertainty of an instance, the more likely the model confidence is inconsistent with the ground truths. Specifically, we first explore instance-level data uncertainty to create an initial high-confident examples. Such subset serves as filtering noisy instances and facilitating the model to converge fast at the early stage. During bootstrap learning, we propose self-ensembling as a regularizer to alleviate inter-model uncertainty produced by noisy labels. We further define probability variance of joint tagging probabilities to estimate inner-model parametric uncertainty, which is used to select and build up new reliable training instances for the next iteration. Experimental results on two large datasets reveal that our app
    
[^36]: 适应变压器语言模型用于脑机界面预测式打字

    Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces. (arXiv:2305.03819v1 [cs.CL])

    [http://arxiv.org/abs/2305.03819](http://arxiv.org/abs/2305.03819)

    本文研究将变压器语言模型应用于脑机界面预测式打字任务中。在评估几个单词级变压器语言模型后，GPT-2在干净印刷体上表现最佳，但是不同的变压器模型在嘈杂的历史轨迹上有不同的反应。

    

    脑机界面是许多人重要的替代和辅助交流方式。与键盘不同，许多脑机界面系统不会一次显示甚至英语中的26个字母，更不要说所有符号了。因此，使用语言模型进行字符级预测可以极大地加速BCI打字。本文将几个单词级变压器语言模型适应为字符预测，并在打字任务中对它们进行评估。其中，GPT-2在干净文本上表现最佳，但不同的语言模型对嘈杂的历史反应不同。我们进一步分析了单词中的字符位置和上下文长度的影响。

    Brain-computer interfaces (BCI) are an important mode of alternative and augmentative communication for many people. Unlike keyboards, many BCI systems do not display even the 26 letters of English at one time, let alone all the symbols in more complex systems. Using language models to make character-level predictions, therefore, can greatly speed up BCI typing (Ghosh and Kristensson, 2017). While most existing BCI systems employ character n-gram models or no LM at all, this paper adapts several wordpiece-level Transformer LMs to make character predictions and evaluates them on typing tasks. GPT-2 fares best on clean text, but different LMs react differently to noisy histories. We further analyze the effect of character positions in a word and context lengths.
    
[^37]: Transformer工作记忆使得正则语言推理和自然语言长度外推成为可能

    Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation. (arXiv:2305.03796v1 [cs.CL])

    [http://arxiv.org/abs/2305.03796](http://arxiv.org/abs/2305.03796)

    本文提出了一个名为RegularGPT的新型Transformer变体，其通过Weigh-Sharing、Adaptive-Depth和Sliding-Dilated-Attention的新颖组合，沿深度维度构建工作记忆，从而成功地建模了正则语言，如PARITY，并在自然语言长度外推任务中表现出良好效果。

    

    不同于循环模型，普遍认为Transformer不能完美地建模正则语言。受到工作记忆的启发，我们提出了一种名为RegularGPT的新型Transformer变种。通过Weigh-Sharing、Adaptive-Depth和Sliding-Dilated-Attention的新颖组合，RegularGPT沿深度维度构建工作记忆，从而能够有效地成功地建模正则语言，如PARITY。我们进一步在自然语言长度外推任务上测试了RegularGPT，令人惊讶的是，它重新发现了先前工作中被认为对于长度外推至关重要的局部窗口注意力效应。

    Unlike recurrent models, conventional wisdom has it that Transformers cannot perfectly model regular languages. Inspired by the notion of working memory, we propose a new Transformer variant named RegularGPT. With its novel combination of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY. We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.
    
[^38]: 采用任务不可知本体和简单标签的零样本帧语义解析技术

    Towards Zero-Shot Frame Semantic Parsing with Task Agnostic Ontologies and Simple Labels. (arXiv:2305.03793v1 [cs.CL])

    [http://arxiv.org/abs/2305.03793](http://arxiv.org/abs/2305.03793)

    本文提出了一种名为OpenFSP的框架，可以通过一些简单的标签方便地创建新领域，并在给定注释后，利用句子编码器的匹配算法预测由终端用户定义的领域的意图和插槽，从而解决了当前模型需要大量训练数据的问题。

    

    帧语义解析是面向任务的对话系统的重要组成部分。当前的模型需要大量的训练数据才能成功地识别用户输入话语中的意图和插槽。这在将新领域添加到虚拟助手功能时会产生重要障碍，因为这些数据的创建需要高度专业化的自然语言处理技能。在本文中，我们提出了OpenFSP，这是一个框架，可以从少量能够在不需要NLP知识的情况下生成的简单标签中方便地创建新领域。我们的方法依赖于创建一个小而富有表现力的、与领域无关的插槽类型集，以实现对新领域的简单注释。在给定这样的注释后，依赖于句子编码器的匹配算法预测由终端用户定义的领域的意图和插槽。在TopV2数据集上进行了深入的实验，结果表明我们的模型在这种简单标签设置下优于强基线模型。

    Frame semantic parsing is an important component of task-oriented dialogue systems. Current models rely on a significant amount training data to successfully identify the intent and slots in the user's input utterance. This creates a significant barrier for adding new domains to virtual assistant capabilities, as creation of this data requires highly specialized NLP expertise. In this work we propose OpenFSP, a framework that allows for easy creation of new domains from a handful of simple labels that can be generated without specific NLP knowledge. Our approach relies on creating a small, but expressive, set of domain agnostic slot types that enables easy annotation of new domains. Given such annotation, a matching algorithm relying on sentence encoders predicts the intent and slots for domains defined by end-users. Extensive experiments on the TopV2 dataset shows that our model outperforms strong baselines in this simple labels setting.
    
[^39]: 在土耳其临床领域中利用BERT的力量：面向有限数据场景的预训练方法研究

    Harnessing the Power of BERT in the Turkish Clinical Domain: Pretraining Approaches for Limited Data Scenarios. (arXiv:2305.03788v1 [cs.CL])

    [http://arxiv.org/abs/2305.03788](http://arxiv.org/abs/2305.03788)

    本研究针对土耳其临床语言模型在有限数据场景下的性能问题，探讨了不同预训练方法的影响，并指出利用大量通用领域语料库知识的BERTurk和TurkRadBERT-task v1表现最佳。

    

    近年来，自然语言处理(NLP)方面的主要进展受到了大型语言模型(LLMs)的推动，这在该领域的研究和发展中有着显著的革命性影响。本研究基于这一进展，探讨了不同预训练方法对土耳其临床语言模型在包含放射学报告的多标签分类任务中表现的影响，并重点关注解决有限语言资源带来的挑战。此外，我们第一次利用有限的临床任务数据来评估同时预训练的方法。我们开发了四个模型，包括TurkRadBERT-task v1、TurkRadBERT-task v2、TurkRadBERT-sim v1和TurkRadBERT-sim v2。我们的研究结果表明，利用大量通用领域语料库知识的泛用性土耳其BERT模型(BERTurk)和TurkRadBERT-task v1表现最佳。虽然任务自适应预训练方法的性能也有所提高，但仍不如上述模型。

    In recent years, major advancements in natural language processing (NLP) have been driven by the emergence of large language models (LLMs), which have significantly revolutionized research and development within the field. Building upon this progress, our study delves into the effects of various pre-training methodologies on Turkish clinical language models' performance in a multi-label classification task involving radiology reports, with a focus on addressing the challenges posed by limited language resources. Additionally, we evaluated the simultaneous pretraining approach by utilizing limited clinical task data for the first time. We developed four models, including TurkRadBERT-task v1, TurkRadBERT-task v2, TurkRadBERT-sim v1, and TurkRadBERT-sim v2. Our findings indicate that the general Turkish BERT model (BERTurk) and TurkRadBERT-task v1, both of which utilize knowledge from a substantial general-domain corpus, demonstrate the best overall performance. Although the task-adaptive
    
[^40]: 不同iable符号编程提高语言模型的逻辑推理能力

    Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming. (arXiv:2305.03742v1 [cs.AI])

    [http://arxiv.org/abs/2305.03742](http://arxiv.org/abs/2305.03742)

    本文提出一种新的可微分符号推理框架，DSR-LM，用于提高预训练语言模型的逻辑推理能力，不像以往的研究依赖手工制定的逻辑规则，该框架有效地学习加权规则，并应用语义损失进一步改善LMs的逻辑推理能力。

    

    尽管语言模型在规模和组合性方面取得了进展，但预训练的大型语言模型仍然难以可靠地执行逻辑推理。本文基于符号编程的视角解决了这一挑战。我们提出了DSR-LM，一种可微分的符号推理框架，其中预训练的LMs管理事实知识的感知，符号模块执行演绎推理。与依赖手工制定的逻辑规则的作品不同，我们的可微分符号推理框架有效地学习加权规则，并应用语义损失进一步改善LMs。DSR-LM具有可扩展性、可解释性，并允许轻松集成先前的知识，从而支持广泛的符号编程，以稳健地推出逻辑结论。我们的实验结果表明，DSR-LM提高了预训练语言模型的逻辑推理能力，在演绎推理基准测试中的准确性显著提高了20%以上。此外，DSR-LM还可以有效处理自然语言解释问题，包括开放式的逻辑推理任务。

    Pre-trained large language models (LMs) struggle to perform logical reasoning reliably despite advances in scale and compositionality. In this work, we tackle this challenge through the lens of symbolic programming. We propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning. In contrast to works that rely on hand-crafted logic rules, our differentiable symbolic reasoning framework efficiently learns weighted rules and applies semantic loss to further improve LMs. DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion. The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks. Furthermore, DSR
    
[^41]: 调整传统语言处理方法以适用于普什图语文本分类

    Tuning Traditional Language Processing Approaches for Pashto Text Classification. (arXiv:2305.03737v1 [cs.CL])

    [http://arxiv.org/abs/2305.03737](http://arxiv.org/abs/2305.03737)

    本研究建立了一个普什图语自动文本分类系统，通过比较不同模型和特征提取方法，实验结果表明使用tf-idf特征提取方法的SVM模型在普什图语文本分类中取得了最高的准确率。

    

    文本分类在很多领域中都是一个重要的任务。因此，已经进行了多项研究来开发国际和本地语言的自动文本分类系统。然而，需要为本地语言建立一个自动文本分类系统。本研究的主要目的是建立一个普什图语自动文本分类系统。为了实现这个目标, 我们建立了一个普什图语语料库，这是由于普什图语文本文档的公共数据集不可用。此外，本研究比较了包括多层感知器(MLP)、支持向量机(SVM)、K近邻(KNN)、决策树, 高斯朴素贝叶斯, 多项式朴素贝叶斯, 随机森林和逻辑回归在内的多个模型，以发现最有效的方法。此外，本研究还评估了两种不同的特征提取方法，包括词袋和tf-idf。实验结果表明，在普什图语文本分类中，使用tf-idf特征提取方法的SVM模型取得了最高的97.19%的准确率。

    Today text classification becomes critical task for concerned individuals for numerous purposes. Hence, several researches have been conducted to develop automatic text classification for national and international languages. However, the need for an automatic text categorization system for local languages is felt. The main aim of this study is to establish a Pashto automatic text classification system. In order to pursue this work, we built a Pashto corpus which is a collection of Pashto documents due to the unavailability of public datasets of Pashto text documents. Besides, this study compares several models containing both statistical and neural network machine learning techniques including Multilayer Perceptron (MLP), Support Vector Machine (SVM), K Nearest Neighbor (KNN), decision tree, gaussian na\"ive Bayes, multinomial na\"ive Bayes, random forest, and logistic regression to discover the most effective approach. Moreover, this investigation evaluates two different feature extr
    
[^42]: 评估ChatGPT的工作记忆容量

    Assessing Working Memory Capacity of ChatGPT. (arXiv:2305.03731v1 [cs.AI])

    [http://arxiv.org/abs/2305.03731](http://arxiv.org/abs/2305.03731)

    本文评估了最先进语言模型ChatGPT的工作记忆容量，结果显示其在N-back任务的行为表现与人类参与者相似，这为设计具有人类级认知能力的人工智能系统提供了关键洞察。

    

    工作记忆是人类智能和人工智能的关键方面，它作为信息临时存储和操作的工作空间。本文通过检查ChatGPT在N-back任务上的表现，调查了这一最先进语言模型的工作记忆容量。我们首先讨论了工作记忆对人类和人工智能的重要性，接着介绍了评估ChatGPT工作记忆容量的方法。研究比较了ChatGPT在言语和空间N- back任务上的行为表现与文献报道的人类参与者的表现，发现了显著的相似之处。我们的发现为设计具有人类级认知能力的人工智能系统的当前进展提供了关键洞察，并为通过人工智能模型理解人类工作记忆的未来努力提供了前景。

    Working memory is a critical aspect of both human intelligence and artificial intelligence (AI), serving as a workspace for the temporary storage and manipulation of information. This paper investigates working memory capacity of ChatGPT, a state-of-the-art language model, by examining its performance on N-back tasks. We begin by discussing the importance of working memory to humans and AI, followed by the methods employed to assess working memory capacity of ChatGPT. Our study compares behavioral performance of ChatGPT on verbal and spatial N-back tasks to that of human participants reported in the literature, revealing notable similarities. Our findings offer crucial insights into the current progress in designing AI systems with human-level cognitive abilities and hold promise for informing future endeavors aimed at enhancing AI working memory and understanding human working memory through AI models.
    
[^43]: 白盒多目标对话生成对抗攻击

    White-Box Multi-Objective Adversarial Attack on Dialogue Generation. (arXiv:2305.03655v1 [cs.CL])

    [http://arxiv.org/abs/2305.03655](http://arxiv.org/abs/2305.03655)

    该论文提出了一种新的白盒多目标对话生成对抗攻击方法，DGSlow。通过平衡生成准确性和长度两个目标，DGSlow利用生成更长的输出来提高攻击效果。

    

    预训练的转换器在最先进的对话生成系统中很受欢迎。 然而，这种语言模型容易受到各种对抗样本的攻击，这在传统任务（如文本分类）中已经得到了研究，这激发了我们对它们在DG系统中的鲁棒性的好奇心。 其中一个主要的挑战是攻击DG模型的时候，对当前句子的扰动几乎不会降低响应的准确性，因为未改变的聊天记录也会被考虑进行决策。我们观察到，通过精心制作对抗样本来迫使生成更长的输出，有利于攻击的有效性 - 生成的响应通常是不相关、冗长和重复的。因此，我们提出了一种名为DGSlow的白盒多目标攻击方法。具体来说，DGSlow通过基于梯度的多目标优化器平衡两个目标 - 生成准确度和长度，并使用自适应方法实施攻击。

    Pre-trained transformers are popular in state-of-the-art dialogue generation (DG) systems. Such language models are, however, vulnerable to various adversarial samples as studied in traditional tasks such as text classification, which inspires our curiosity about their robustness in DG systems. One main challenge of attacking DG models is that perturbations on the current sentence can hardly degrade the response accuracy because the unchanged chat histories are also considered for decision-making. Instead of merely pursuing pitfalls of performance metrics such as BLEU, ROUGE, we observe that crafting adversarial samples to force longer generation outputs benefits attack effectiveness -- the generated responses are typically irrelevant, lengthy, and repetitive. To this end, we propose a white-box multi-objective attack method called DGSlow. Specifically, DGSlow balances two objectives -- generation accuracy and length, via a gradient-based multi-objective optimizer and applies an adapti
    
[^44]: 大数据和大数的解释：解读齐普夫定律

    Big Data and Large Numbers. Interpreting Zipf's Law. (arXiv:2305.02687v1 [physics.soc-ph])

    [http://arxiv.org/abs/2305.02687](http://arxiv.org/abs/2305.02687)

    该论文揭示了大数性质对于解释齐普夫定律的影响，指出齐普夫定律噪音是这种影响的例子，并分析了权力分布和类似分布在种群是有限的、排名和元素计数是自然数的情况下的特性。

    

    一些大数据领域的实证事实属于大数性质的影响。齐普夫定律噪音就是这种现象的例子。我们揭示了权力分布和类似分布的几个特性，这些分布发生在种群是有限的、排名和元素计数是自然数的情况下。讨论了这些特性对解释齐普夫定律的影响。

    It turns out that some empirical facts in Big Data are the effects of properties of large numbers. Zipf's law noise is an example of such an artefact. We expose several properties of the power law distributions and of similar distribution that occur when the population is finite and the rank and counts of elements in the population are natural numbers. Consequences in the interpretation of Zipf's law are discussed.
    
[^45]: 相邻单词影响人类对显著性解释的理解

    Neighboring Words Affect Human Interpretation of Saliency Explanations. (arXiv:2305.02679v1 [cs.CL])

    [http://arxiv.org/abs/2305.02679](http://arxiv.org/abs/2305.02679)

    相邻单词可以影响解释者对单词重要性的理解，应该考虑文本中其他因素的影响来替代单词级别的显著性解释方法。

    

    单词级别的显著性解释（“单词热图”）经常用于在基于文本的模型中传达特征归因。最近的研究发现，诸如单词长度等表面因素可能会扭曲传达的显著性评分的人类解读。我们进行了一项用户研究，以研究一个单词的相邻单词的标记如何影响解释者对显著性解释中单词的重要性的感知。我们发现相邻单词对单词的重要性评分有显著影响。具体来说，我们确定了影响基于相邻方向（左侧与右侧）以及短语和搭配的先验语言和计算度量值（与不相关的相邻单词）。我们的结果让人质疑在文本为基础的显著性解释是否应该继续在单词级别上进行传达，并为替代显著性解释方法的未来研究提供信息。

    Word-level saliency explanations ("heat maps over words") are often used to communicate feature-attribution in text-based models. Recent studies found that superficial factors such as word length can distort human interpretation of the communicated saliency scores. We conduct a user study to investigate how the marking of a word's neighboring words affect the explainee's perception of the word's importance in the context of a saliency explanation. We find that neighboring words have significant effects on the word's importance rating. Concretely, we identify that the influence changes based on neighboring direction (left vs. right) and a-priori linguistic and computational measures of phrases and collocations (vs. unrelated neighboring words). Our results question whether text-based saliency explanations should be continued to be communicated at word level, and inform future research on alternative saliency explanation methods.
    
[^46]: 计划、消除和跟踪——语言模型是具备体验的智能体的良师益友。

    Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. (arXiv:2305.02412v1 [cs.CL])

    [http://arxiv.org/abs/2305.02412](http://arxiv.org/abs/2305.02412)

    本文介绍了Plan，Eliminate，和Track（PET）框架，该框架利用预先训练的大型语言模型（LLM）帮助智能体简化控制任务，从而解决了LLM直接作为智能体所面临的一些限制和问题。

    

    预训练的大型语言模型(LLMs)可以捕捉到关于世界的程序化知识。最近的研究利用LLM产生的抽象计划来简化具有挑战性的控制任务，通过动作打分或动作建模（微调）来实现。然而，变压器架构继承了几个限制，使得LLM难以直接作为智能体：例如有限的输入长度，微调的效率，预训练的偏见以及与非文本环境的不兼容性。为了与低级别可训练的执行器保持兼容性，我们建议使用LLMs中的知识来简化控制问题，而不是解决问题。 我们提出了Plan，Eliminate和Track（PET）框架。计划模块将任务描述转化为高层次子任务的列表。消除模块从当前子任务的观察中屏蔽不相关的对象和容器。最后，跟踪模块确定智能体是否已经实现了当前子任务。

    Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accompli
    
[^47]: 在低端硬件上使用语言模型

    Using Language Models on Low-end Hardware. (arXiv:2305.02350v1 [cs.CL])

    [http://arxiv.org/abs/2305.02350](http://arxiv.org/abs/2305.02350)

    本论文评估了在低端硬件上使用固定语言模型来训练文本分类网络的可行性，并发现在某些情况下，不对语言模型进行微调可以在更快的训练中产生竞争性的效果，仅需要原先内存的四分之一即可。

    

    本文评估了在低端硬件上使用固定语言模型来训练文本分类网络的可行性。我们将语言模型与CNN架构相结合，并组成了包括单标签和多标签分类的话题、情感和风格的8组数据集的综合基准。我们的观察总结成一个权衡列表，并得出结论，即在某些情况下，不对语言模型进行微调可以在更快的训练中产生竞争性的效果，仅需要原先内存的四分之一即可。

    This paper evaluates the viability of using fixed language models for training text classification networks on low-end hardware. We combine language models with a CNN architecture and put together a comprehensive benchmark with 8 datasets covering single-label and multi-label classification of topic, sentiment, and genre. Our observations are distilled into a list of trade-offs, concluding that there are scenarios, where not fine-tuning a language model yields competitive effectiveness at faster training, requiring only a quarter of the memory compared to fine-tuning.
    
[^48]: 基于因果感知的知识引导句子提取

    Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v1 [cs.CL])

    [http://arxiv.org/abs/2305.01876](http://arxiv.org/abs/2305.01876)

    该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。

    

    概念有助于自然语言理解，但现有的知识图谱（KG）中远未完善。最近，预训练语言模型（PLM）已被广泛用于基于文本的概念提取（CE）。然而，PLM往往从大量语料库的共现关联中进行预训练知识挖掘，而非Token之间的真实因果关系。因此，预训练知识混淆了PLM，导致提取基于虚假共现相关性的有偏概念，不可避免地导致低精度。本文通过结构因果模型（SCM）提出了一种知识引导提示方法，将其作为干预器装备到基于PLM的提取器中，以减轻概念偏差。提示采用现有KG中的给定实体主题来缓解实体和有偏概念之间的虚假共现相关性。我们在代表性的多语言KG数据集上进行了广泛的实验，证明了我们提出的提示显著改进了提取性能，并达到了最先进的结果。

    Concepts benefit natural language understanding but are far from complete in existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs) have been widely used in text-based concept extraction (CE). However, PLMs tend to mine the co-occurrence associations from massive corpus as pre-trained knowledge rather than the real causal effect between tokens.As a result, the pre-trained knowledge confounds PLMs to extract biased concepts based on spurious co-occurrence correlations, inevitably resulting in low precision. In this paper, through the lens of a Structural Causal Model (SCM), we propose equipping the PLM-based extractor with a knowledge-guided prompt as an intervention to alleviate concept bias. The prompt adopts the topic of the given entity from the existing knowledge in KGs to mitigate the spurious co-occurrence correlations between entities and biased concepts. Our extensive experiments on representative multilingual KG datasets justify that our proposed prompt 
    
[^49]: 一项关于将Pipeline和E2E SLU系统整合用于口语语义解析的研究：STOP品质挑战

    A Study on the Integration of Pipeline and E2E SLU systems for Spoken Semantic Parsing toward STOP Quality Challenge. (arXiv:2305.01620v1 [cs.CL])

    [http://arxiv.org/abs/2305.01620](http://arxiv.org/abs/2305.01620)

    本文介绍了针对ICASSP信号处理大挑战2023中的口语语言理解大挑战的质量轨迹（Track 1）提出的口语语义解析系统。使用了端到端和pipeline系统，并在SLU框架中使用了强大的自动语音识别（ASR）模型和预训练的语言模型（LM）等方法，最终获得了80.8的精确匹配度，获得了挑战的第一名。

    

    最近，有一些新的基准任务被引入用于口语理解（SLU），例如语义解析。本文介绍了我们针对ICASSP信号处理大挑战2023中的口语语言理解大挑战的质量轨迹（Track 1）提出的口语语义解析系统。我们尝试了端到端和pipeline系统来完成这项任务。我们在SLU框架中使用了强大的自动语音识别（ASR）模型，如Whisper，以及预训练的语言模型（LM），如BART，来提高性能。我们还研究了不同模型的输出级别组合，以获得80.8的精确匹配度，这使我们在挑战中获得了第一名。

    Recently there have been efforts to introduce new benchmark tasks for spoken language understanding (SLU), like semantic parsing. In this paper, we describe our proposed spoken semantic parsing system for the quality track (Track 1) in Spoken Language Understanding Grand Challenge which is part of ICASSP Signal Processing Grand Challenge 2023. We experiment with both end-to-end and pipeline systems for this task. Strong automatic speech recognition (ASR) models like Whisper and pretrained Language models (LM) like BART are utilized inside our SLU framework to boost performance. We also investigate the output level combination of various models to get an exact match accuracy of 80.8, which won the 1st place at the challenge.
    
[^50]: 触发词作为后门攻击的触发器：检查语言模型的脆弱性

    Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v1 [cs.CL])

    [http://arxiv.org/abs/2305.01219](http://arxiv.org/abs/2305.01219)

    本研究提出一种新颖有效的“ProAttack”方法来执行干净标签的后门攻击，使用的是提示本身作为触发器。该方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性，相比于现有的后门攻击方法有显著提升。

    

    基于提示的学习范例弥合了预训练和微调之间的差距，在几个NLP任务中取得了最先进的性能，尤其是在少样本情况下。尽管应用广泛，但基于提示的学习容易受到后门攻击。文本后门攻击旨在通过注入触发器并修改标签来在模型中引入有针对性的漏洞。然而，由于触发器的存在和毒瘤数据标注不正确等缺陷，这种攻击存在异常的自然语言表达。在本研究中，我们提出了一种新颖有效的“ProAttack”方法，基于提示来执行干净标签的后门攻击，使用的是提示本身作为触发器。我们的方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性。通过在丰富的资源和少样本文本语料库上的广泛实验，我们证明了ProAttack方法在保持干净数据一致性的同时显著优于现有的后门攻击方式。

    The prompt-based learning paradigm, which bridges the gap between pre-training and fine-tuning, achieves state-of-the-art performance on several NLP tasks, particularly in few-shot settings. Despite being widely applied, prompt-based learning is vulnerable to backdoor attacks. Textual backdoor attacks are designed to introduce targeted vulnerabilities into models by poisoning a subset of training samples through trigger injection and label modification. However, they suffer from flaws such as abnormal natural language expressions resulting from the trigger and incorrect labeling of poisoned samples. In this study, we propose {\bf ProAttack}, a novel and efficient method for performing clean-label backdoor attacks based on the prompt, which uses the prompt itself as a trigger. Our method does not require external triggers and ensures correct labeling of poisoned samples, improving the stealthy nature of the backdoor attack. With extensive experiments on rich-resource and few-shot text c
    
[^51]: 对Kauhanen、Einhaus和Walkden（2023年）的回应：仍然没有证据证明非母语用户比例对语言复杂度有影响（arXiv:2305.00217v1 [cs.CL]）

    Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023). (arXiv:2305.00217v1 [cs.CL])

    [http://arxiv.org/abs/2305.00217](http://arxiv.org/abs/2305.00217)

    本研究为对Kauhanen、Einhaus和Walkden（2023）的回应，仍然没有证据表明大量的L2用户影响语言复杂性。

    

    近期在《语言进化杂志》发表的一篇论文中，Kauhanen、Einhaus和Walkden（https://doi.org/10.1093/jole/lzad005，KEW）挑战了我在一篇论文中（Koplenig，Royal Society Open Science，6，181274（2019），https://doi.org/10.1098/rsos.181274）所呈现的结果。在该论文中，我试图通过一系列的统计分析来表明大量L2（第二语言）用户似乎不会影响语言的（语法或统计）复杂性。为此，我专注于Ethnologue评估语言地位的方式：如果一种语言除了被L1（第一语言）使用者之外，还应该有大量的L2使用者，那么该语言就被描述为传播性的。KEW批评了将传播性作为语言是否拥有大量L2使用者（二元）指标的使用，以及在直接估计L2比例的情况下，将L2用户比例归为非传播性语言的想法。

    In a recent paper published in the Journal of Language Evolution, Kauhanen, Einhaus & Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the results presented in one of my papers (Koplenig, Royal Society Open Science, 6, 181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show through a series of statistical analyses that large numbers of L2 (second language) speakers do not seem to affect the (grammatical or statistical) complexity of a language. To this end, I focus on the way in which the Ethnologue assesses language status: a language is characterised as vehicular if, in addition to being used by L1 (first language) speakers, it should also have a significant number of L2 users. KEW criticise both the use of vehicularity as a (binary) indicator of whether a language has a significant number of L2 users and the idea of imputing a zero proportion of L2 speakers to non-vehicular languages whenever a direct estimate of that proportion is unavailable. Whi
    
[^52]: 因果推理与大型语言模型：开启因果研究的新篇章

    Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v1 [cs.AI])

    [http://arxiv.org/abs/2305.00050](http://arxiv.org/abs/2305.00050)

    大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。

    

    大型语言模型的因果能力备受争议，并且对将其应用于医学、科学、法律和政策等具有社会影响力的领域具有重要意义。我们进一步探讨了LLMs及其因果推理的区别，以及潜在的建构和测量效度威胁。基于GPT-3.5和4的算法在多个因果基准测试上取得了新的最高准确率。与此同时，LLMs展示了难以预测的失败模式，我们提供了一些技术来解释它们的鲁棒性。

    The causal capabilities of large language models (LLMs) is a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We further our understanding of LLMs and their causal implications, considering the distinctions between different types of causal reasoning tasks, as well as the entangled threats of construct and measurement validity. LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain), and actual causality (86% accuracy in determining necessary and sufficient causes in vignettes). At the same time, LLMs exhibit unpredictable failure modes and we provide some techniques to interpret their robustness.  Crucially, LLMs perform these causal tasks while relying on sources of knowledg
    
[^53]: 基于能量模型的零样本场景重新排列规划器

    Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v1 [cs.RO])

    [http://arxiv.org/abs/2304.14391](http://arxiv.org/abs/2304.14391)

    本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    

    本文致力于开发一个场景重排框架，可以解释长指令以及在训练时从未见过的空间概念组合。我们提出使用相对对象排列的能量函数来表示语言指导的空间概念。语言解析器将指令映射到相应的能量函数，而开放式视觉语言模型将它们的参数基于场景中的相关对象进行修正。通过梯度下降求解能量函数的总和，并利用基于本地计算机视觉的策略将对象重新定位到推断的目标位置，即可生成目标场景配置。我们在已建立的指令导向操作基准测试以及我们提出的组合指令基准测试中测试了模型，结果表明，我们的模型的绩效优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    Language is compositional; an instruction can express multiple relation constraints to hold among objects in a scene that a robot is tasked to rearrange. Our focus in this work is an instructable scene rearranging framework that generalizes to longer instructions and to spatial concept compositions never seen at training time. We propose to represent language-instructed spatial concepts with energy functions over relative object arrangements. A language parser maps instructions to corresponding energy functions and an open-vocabulary visual-language model grounds their arguments to relevant objects in the scene. We generate goal scene configurations by gradient descent on the sum of energy functions, one per language predicate in the instruction. Local vision-based policies then relocate objects to the inferred goal locations. We test our model on established instruction-guided manipulation benchmarks, as well as benchmarks of compositional instructions we introduce. We show our model 
    
[^54]: 从关联到生成：无监督跨模态映射的纯文本字幕生成

    From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping. (arXiv:2304.13273v1 [cs.CV])

    [http://arxiv.org/abs/2304.13273](http://arxiv.org/abs/2304.13273)

    本研究提出了一种从关联到生成的零-shot方法：通过将图像/视频投影到语言模态并在生成任务中生成描述性字幕。该方法在多个基准数据集上显著优于现有的最先进方法，为无监督跨模态映射提供了一个新的视角，并具有在视频字幕，图像合成和文本到图像生成等领域的潜在应用。

    

    随着以CLIP和ALIGN为代表的视觉-语言预训练模型的发展，CLIP的零-shot能力在图像分类和图像-文本检索等基于关联的视觉任务中取得了重大突破。但是，CLIP难以应用于基于生成的任务。这是由于缺乏解码器架构和生成的预训练任务。我们提出了K最近邻跨模态映射（Knight），一种从关联到生成的零-shot方法。通过窄字幕任务的纯文本无监督预训练来有效地将图像/视频投影到语言模态并在生成任务中生成描述性字幕。实验结果表明，Knight在多个基准数据集上显著优于现有的最先进方法。我们的方法为无监督跨模态映射提供了一个新的视角，并且将在视频字幕，图像合成和文本到图像生成等领域具有潜在应用。

    With the development of Vision-Language Pre-training Models (VLPMs) represented by CLIP and ALIGN, significant breakthroughs have been achieved for association-based visual tasks such as image classification and image-text retrieval by the zero-shot capability of CLIP without fine-tuning. However, CLIP is hard to apply to generation-based tasks. This is due to the lack of decoder architecture and pre-training tasks for generation. Although previous works have created generation capacity for CLIP through additional language models, a modality gap between the CLIP representations of different modalities and the inability of CLIP to model the offset of this gap, which fails the concept to transfer across modalities. To solve the problem, we try to map images/videos to the language modality and generate captions from the language modality. In this paper, we propose the K-nearest-neighbor Cross-modality Mapping (Knight), a zero-shot method from association to generation. With text-only unsu
    
[^55]: RenderDiffusion: 文本生成作为图像生成

    RenderDiffusion: Text Generation as Image Generation. (arXiv:2304.12519v1 [cs.CL])

    [http://arxiv.org/abs/2304.12519](http://arxiv.org/abs/2304.12519)

    本文提出了一种新的扩散方法——\textsc{RenderDiffusion}，通过文本引导的图像生成进行文本生成。它将连续扩散模型应用于离散文本并实现了条件文本生成作为字形图像生成问题。

    

    扩散模型已成为文本生成的新生成范式。考虑到文本的离散分类特性，在本文中，我们提出了一种新颖的扩散方法——\textsc{RenderDiffusion}，通过文本引导的图像生成进行文本生成。我们的关键思路是将目标文本呈现为包含视觉语言内容的"字形图像"。这样，条件化的文本生成可以被形式化为一个字形图像生成任务，然后自然地将连续扩散模型应用于离散文本。

    Diffusion models have become a new generative paradigm for text generation. Considering the discrete categorical nature of text, in this paper, we propose \textsc{RenderDiffusion}, a novel diffusion approach for text generation via text-guided image generation. Our key idea is to render the target text as a \emph{glyph image} containing visual language content. In this way, conditional text generation can be cast as a glyph image generation task, and it is then natural to apply continuous diffusion models to discrete texts. Specially, we utilize a cascaded architecture (\ie a base and a super-resolution diffusion model) to generate high-fidelity glyph images, conditioned on the input text. Furthermore, we design a text grounding module to transform and refine the visual language content from generated glyph images into the final texts. In experiments over four conditional text generation tasks and two classes of metrics (\ie quality and diversity), \textsc{RenderDiffusion} can achieve 
    
[^56]: 利用多语言对抗训练和横向抑制技术的方法优化罗马尼亚语多词表达的识别

    Romanian Multiword Expression Detection Using Multilingual Adversarial Training and Lateral Inhibition. (arXiv:2304.11350v1 [cs.CL])

    [http://arxiv.org/abs/2304.11350](http://arxiv.org/abs/2304.11350)

    本文使用多语言对抗训练和横向抑制技术对罗马尼亚语多词表达进行自动识别，提高了已有模型在未见过的多词表达上的F1分数，达到了最先进水平。

    

    多词表达是开发大规模、语言学上可靠的自然语言处理技术的关键因素。本文描述了我们在PARSEM v1.2共享任务语料库上自动识别罗马尼亚语多词表达方面所做的改进。我们的方法基于最近引入的横向抑制层和对抗训练的多语言视角，以提高所采用的多语言语言模型的性能。在这两种方法的帮助下，我们提高了XLM-RoBERTa在未见过的多词表达方面的F1分数，也就是PARSEME 1.2版本的主要任务，约为2.7%。此外，我们的结果可以被认为是最先进技术，因为它们超过了本次比赛中参赛者在罗马尼亚语方面的先前结果。

    Multiword expressions are a key ingredient for developing large-scale and linguistically sound natural language processing technology. This paper describes our improvements in automatically identifying Romanian multiword expressions on the corpus released for the PARSEME v1.2 shared task. Our approach assumes a multilingual perspective based on the recently introduced lateral inhibition layer and adversarial training to boost the performance of the employed multilingual language models. With the help of these two methods, we improve the F1-score of XLM-RoBERTa by approximately 2.7% on unseen multiword expressions, the main task of the PARSEME 1.2 edition. In addition, our results can be considered SOTA performance, as they outperform the previous results on Romanian obtained by the participants in this competition.
    
[^57]: 准确的COVID-19信息与错误信息的大规模比较研究

    A Large-Scale Comparative Study of Accurate COVID-19 Information versus Misinformation. (arXiv:2304.04811v1 [cs.CL])

    [http://arxiv.org/abs/2304.04811](http://arxiv.org/abs/2304.04811)

    本文通过大规模比较研究表明，COVID-19错误信息的分布、传播能力、语言分析与准确信息不同，并且研制了一个新的分类数据集，该数据集平均提高了9%以上的错误信息分类能力。

    

    COVID-19疫情导致信息泛滥，大量与COVID-19相关的内容被通过社交媒体高速传播，这让公众难以区分COVID-19的准确和错误信息。为此，本文通过对超过2.42亿条推特进行大规模计算分析，对COVID-19错误和准确信息的特征进行了比较研究。研究涵盖四个方面: 1)主题的分布，2)推特的实时性，3)语言分析和4)时间上的传播能力。本文还创造了一个新的COVID-19错误信息分类数据集，最后演示了该数据集能够通过平均F1指标将错误信息分类提高9%以上。

    The COVID-19 pandemic led to an infodemic where an overwhelming amount of COVID-19 related content was being disseminated at high velocity through social media. This made it challenging for citizens to differentiate between accurate and inaccurate information about COVID-19. This motivated us to carry out a comparative study of the characteristics of COVID-19 misinformation versus those of accurate COVID-19 information through a large-scale computational analysis of over 242 million tweets. The study makes comparisons alongside four key aspects: 1) the distribution of topics, 2) the live status of tweets, 3) language analysis and 4) the spreading power over time. An added contribution of this study is the creation of a COVID-19 misinformation classification dataset. Finally, we demonstrate that this new dataset helps improve misinformation classification by more than 9% based on average F1 measure.
    
[^58]: 考察COVID-19疫苗态度检测中的时间性

    Examining Temporalities on Stance Detection Towards COVID-19 Vaccination. (arXiv:2304.04806v1 [cs.CL])

    [http://arxiv.org/abs/2304.04806](http://arxiv.org/abs/2304.04806)

    研究考虑了时间性对COVID-19疫苗态度检测的影响，发现时间分割显著降低了立场分类的准确性。

    

    先前的研究指出疫苗接种是控制COVID-19传播的有效策略。了解公众的疫苗态度对决策者至关重要。然而，社交媒体上的 COVID-19 疫苗态度（如支持和犹豫）会随时间而演变，因此在分析这些立场时需要考虑可能的时间漂移。该研究旨在检查时间概念漂移对推特上 COVID-19 疫苗立场检测的影响。为此，我们使用基于转换器的模型对社交媒体数据进行了随机和时间分割的评估。我们的研究发现，在所有单语和多语数据集的随机和时间分割之间，模型性能存在显著差异。时间分割显著降低了立场分类的准确性。

    Previous studies have highlighted the importance of vaccination as an effective strategy to control the transmission of the COVID-19 virus. It is crucial for policymakers to have a comprehensive understanding of the public's stance towards vaccination on a large scale. However, attitudes towards COVID-19 vaccination, such as pro-vaccine or vaccine hesitancy, have evolved over time on social media. Thus, it is necessary to account for possible temporal shifts when analysing these stances. This study aims to examine the impact of temporal concept drift on stance detection towards COVID-19 vaccination on Twitter. To this end, we evaluate a range of transformer-based models using chronological and random splits of social media data. Our findings demonstrate significant discrepancies in model performance when comparing random and chronological splits across all monolingual and multilingual datasets. Chronological splits significantly reduce the accuracy of stance classification. Therefore, 
    
[^59]: LLM-Adapters：大型语言模型参数高效微调的适配器系列

    LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models. (arXiv:2304.01933v1 [cs.CL])

    [http://arxiv.org/abs/2304.01933](http://arxiv.org/abs/2304.01933)

    本文提出了LLM-Adapters，一个将适配器集成到LLMs中进行参数高效微调的易于使用的框架，实现了比现有方法更少的参数和训练时间，在多个基准测试上取得了最先进的结果。

    

    像GPT-3和ChatGPT这样的大型语言模型（LLMs）的成功，导致了许多经济实惠和易于访问的替代品的开发，这些替代品是通过利用任务特定数据（例如ChatDoctor）或指导数据（例如Alpaca）微调开放式LLMs而创建的。在各种微调方法中，基于适配器的参数高效微调（PEFT）无疑是最有吸引力的研究主题之一，因为它只需要微调少量外部参数而不是整个LLMs，同时实现可比甚至更好的性能。为了进一步研究LLMs的PEFT方法，本文提出了LLM-Adapters，这是一个易于使用的框架，将各种适配器集成到LLMs中，并且可以为不同任务执行这些适配器的PEFT方法。该框架包括最先进的开放式LLMs，例如LLaMA，BLOOM，OPT和GPT-J，以及广泛使用的适配器，例如串联适配器，并联适配器和LoRA。该框架旨在高效且灵活，使用户可以使用最少的附加训练数据或计算资源轻松微调LLMs以适应不同的任务。对多个基准测试的实验表明，LLM-Adapters可以比现有方法使用更少的参数和训练时间取得最先进的结果。

    The success of large language models (LLMs), like GPT-3 and ChatGPT, has led to the development of numerous cost-effective and accessible alternatives that are created by fine-tuning open-access LLMs with task-specific data (e.g., ChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning methods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly one of the most attractive topics, as it only requires fine-tuning a few external parameters instead of the entire LLMs while achieving comparable or even better performance. To enable further research on PEFT methods of LLMs, this paper presents LLM-Adapters, an easy-to-use framework that integrates various adapters into LLMs and can execute these adapter-based PEFT methods of LLMs for different tasks. The framework includes state-of-the-art open-access LLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such as Series adapter, Parallel adapter, and LoRA. The framework is designed to
    
[^60]: Spam-T5：基于小样本的邮件垃圾检测的大型语言模型基准测试

    Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam Detection. (arXiv:2304.01238v1 [cs.CL])

    [http://arxiv.org/abs/2304.01238](http://arxiv.org/abs/2304.01238)

    本文通过比较不同类型的大型语言模型和传统机器学习技术在邮件垃圾检测中的表现，发现大多数情况下，大型语言模型优于传统技术，特别是在样本有限的情况下。同时，本文还介绍了经过改进和微调的Spam-T5模型，该模型具有出色的性能表现。

    

    本文通过比较三种不同类型的大型语言模型（BERT-like、Sentence Transformers和Seq2Seq）以及传统机器学习技术（如朴素贝叶斯和LightGBM）在邮件垃圾检测中的有效性，研究了大型语言模型在邮件垃圾检测中的作用。同时，我们还评估了这些模型在四个公共数据集上的表现，并使用不同数量的训练样本（完整训练集和小样本）进行了测试。 发现在大多数情况下，LLMs优于基线技术，特别是在小样本情况下。这种适应性使LLMs在邮件垃圾检测任务中具有独特的优势，因为标记样本数量有限，并且模型需要经常更新。此外，我们介绍了Spam-T5模型，该模型是专门为检测电子邮件垃圾而进行了改进和微调。我们的结果表明，Spam-T5模型具有出色的性能。

    This paper investigates the effectiveness of large language models (LLMs) in email spam detection by comparing prominent models from three distinct families: BERT-like, Sentence Transformers, and Seq2Seq. Additionally, we examine well-established machine learning techniques for spam detection, such as Na\"ive Bayes and LightGBM, as baseline methods. We assess the performance of these models across four public datasets, utilizing different numbers of training samples (full training set and few-shot settings). Our findings reveal that, in the majority of cases, LLMs surpass the performance of the popular baseline techniques, particularly in few-shot scenarios. This adaptability renders LLMs uniquely suited to spam detection tasks, where labeled samples are limited in number and models require frequent updates. Additionally, we introduce Spam-T5, a Flan-T5 model that has been specifically adapted and fine-tuned for the purpose of detecting email spam. Our results demonstrate that Spam-T5 
    
[^61]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^62]: 偏见还是多样性？揭示美国新闻标题中的语义差异

    Bias or Diversity? Unraveling Semantic Discrepancy in U.S. News Headlines. (arXiv:2303.15708v1 [cs.CL])

    [http://arxiv.org/abs/2303.15708](http://arxiv.org/abs/2303.15708)

    本研究通过收集180万份美国主要媒体机构的新闻标题，揭示了美国新闻媒体中的语义差异，并发现在国内政治和社会问题上，差异可以在一定程度上归因于媒体偏见。

    

    普遍一致认为新闻媒体在其新闻文章中采用意识形态偏见。然而，在测量媒体机构之间的差异并进一步解剖语义差异的源头方面，先前的研究受到了样本大小的限制和范围的限制。在本研究中，我们收集了180万份美国主要媒体机构从2014年至2022年的新闻标题的大型数据集，以全面跟踪和解剖美国新闻媒体中的语义差异。我们采用多元对应分析(MCA)来量化与四个突出主题相关的语义差异 - 国内政治、经济问题、社会问题和外交事务。此外，我们比较媒体标题中最常见的n-gram，提供进一步的定性分析。我们的研究结果表明，在国内政治和社会问题上，差异可以在一定程度上归因于媒体偏见。与此同时，外交报道中的差异则更多地反映了多样性。

    There is a broad consensus that news media outlets incorporate ideological biases in their news articles. However, prior studies on measuring the discrepancies among media outlets and further dissecting the origins of semantic differences suffer from small sample sizes and limited scope. In this study, we collect a large dataset of 1.8 million news headlines from major U.S. media outlets spanning from 2014 to 2022 to thoroughly track and dissect the semantic discrepancy in U.S. news media. We employ multiple correspondence analysis (MCA) to quantify the semantic discrepancy relating to four prominent topics - domestic politics, economic issues, social issues, and foreign affairs. Additionally, we compare the most frequent n-grams in media headlines to provide further qualitative insights into our analysis. Our findings indicate that on domestic politics and social issues, the discrepancy can be attributed to a certain degree of media bias. Meanwhile, the discrepancy in reporting foreig
    
[^63]: 使用分层行为探索的深度强化学习在对话生成中的应用

    Deep RL with Hierarchical Action Exploration for Dialogue Generation. (arXiv:2303.13465v1 [cs.CL])

    [http://arxiv.org/abs/2303.13465](http://arxiv.org/abs/2303.13465)

    本篇论文提出了一种新的方法，通过分层行为探索，从多个奖励函数中进行离线学习，并成功地解决了在对话生成中行为采样效率低下的问题，可以更好地识别人类情感细节。

    

    自然语言的行为空间极其庞大，因此在对话生成中，近似动态规划必须使用策略改进和行为采样。但是，由于有价值的回应非常稀疏，因此使用随机采样的贪心策略效率低下。本文提出了双粒度的 Q-function 并通过探索最有前途的回应类别来缓解这个局限性。该算法从识别人类情感细节的多个奖励函数中进行离线学习。实证研究表明，该算法优于基线方法。

    Conventionally, since the natural language action space is astronomical, approximate dynamic programming applied to dialogue generation involves policy improvement with action sampling. However, such a practice is inefficient for reinforcement learning (RL) because the eligible (high action value) responses are very sparse, and the greedy policy sustained by the random sampling is flabby. This paper shows that the performance of dialogue policy positively correlated with sampling size by theoretical and experimental. We introduce a novel dual-granularity Q-function to alleviate this limitation by exploring the most promising response category to intervene in the sampling. It extracts the actions following the grained hierarchy, which can achieve the optimum with fewer policy iterations. Our approach learns in the way of offline RL from multiple reward functions designed to recognize human emotional details. Empirical studies demonstrate that our algorithm outperforms the baseline metho
    
[^64]: 经过训练的1亿单词仍然保持状态：BERT结合英国国家语料库

    Trained on 100 million words and still in shape: BERT meets British National Corpus. (arXiv:2303.09859v1 [cs.CL])

    [http://arxiv.org/abs/2303.09859](http://arxiv.org/abs/2303.09859)

    本文探讨了在英国国家语料库上预训练的效果，并展示它可以比原始BERT模型达到更好的表现。在公平、可重复且数据有效的比较研究中，他们证明了这样的语料库有作为语言建模基准的巨大潜力。他们提出了一个经过优化的LM体系结构称为LTG-BERT。

    

    当前，现代遮蔽语言模型（LMs）训练的语料库规模越来越大。在本文中，我们探讨了缩小训练规模到一个规模适中、代表性好、平衡性好且公开可用的英文文本源-英国国家语料库的效果。我们展示了在这个精心策划的语料库上预训练可以达到比原始BERT模型更好的表现。我们认为这种类型的语料库具有作为语言建模基准的巨大潜力。为了展示这种潜力，我们以公平、可重复和数据有效的比较研究为特色，在其中评估了几个训练目标和模型架构，并以系统性的方式复制了先前的经验结果。我们提出了一个经过优化的LM体系结构称为LTG-BERT。

    While modern masked language models (LMs) are trained on ever larger corpora, we here explore the effects of down-scaling training to a modestly-sized but representative, well-balanced, and publicly available English text source -the British National Corpus. We show that pre-training on this carefully curated corpus can reach better performance than the original BERT model. We argue that this type of corpora has great potential as a language modeling benchmark. To showcase this potential, we present fair, reproducible and data-efficient comparative studies of LMs, in which we evaluate several training objectives and model architectures and replicate previous empirical results in a systematic way. We propose an optimized LM architecture called LTG-BERT.
    
[^65]: SmartBERT：用于加速BERT推理的动态早期退出机制的改进

    SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference. (arXiv:2303.09266v1 [cs.CL])

    [http://arxiv.org/abs/2303.09266](http://arxiv.org/abs/2303.09266)

    SmartBERT是一种改进的动态早期退出与层跳过机制，可以自适应地跳过一些层并自适应地选择是否退出，以加速BERT模型的推理速度。

    

    动态早期退出被证明可以提高预训练语言模型（如BERT）的推理速度。然而，所有样本在早期退出之前都必须经过所有连续层，较复杂的样本通常会经历更多的层，仍然存在冗余计算。本文提出了一种名为SmartBERT的Bert推理的新型动态早期退出与层跳过相结合的机制，它将跳过门和退出算子加入到BERT的每一层中。SmartBERT可以自适应地跳过一些层并自适应地选择是否退出。此外，我们提出了跨层对比学习，并将其结合到我们的训练阶段中，以提高中间层和分类器，这对于早期退出是有益的。为了保持训练和推理阶段跳过门的一致使用，我们在训练阶段提出了一种硬权重机制。我们在GLUE基准测试的八个分类数据集上进行了实验。

    Dynamic early exiting has been proven to improve the inference speed of the pre-trained language model like BERT. However, all samples must go through all consecutive layers before early exiting and more complex samples usually go through more layers, which still exists redundant computation. In this paper, we propose a novel dynamic early exiting combined with layer skipping for BERT inference named SmartBERT, which adds a skipping gate and an exiting operator into each layer of BERT. SmartBERT can adaptively skip some layers and adaptively choose whether to exit. Besides, we propose cross-layer contrastive learning and combine it into our training phases to boost the intermediate layers and classifiers which would be beneficial for early exiting. To keep the consistent usage of skipping gates between training and inference phases, we propose a hard weight mechanism during training phase. We conduct experiments on eight classification datasets of the GLUE benchmark. Experimental resul
    
[^66]: SelfCheckGPT: 零资源黑盒幻觉检测方法用于生成式大语言模型

    SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models. (arXiv:2303.08896v1 [cs.CL])

    [http://arxiv.org/abs/2303.08896](http://arxiv.org/abs/2303.08896)

    SelfCheckGPT是一种简单的基于采样的方法，可以以零资源的方式检查黑盒模型的幻觉现象。

    

    生成式大语言模型（LLM）例如GPT-3，能够对各种用户提示进行高度流畅的响应。然而，LLM已知会产生幻觉事实和非事实陈述，这可能会削弱对它们的输出的信任。现有的事实检查方法要么需要访问令牌级输出概率分布（这可能对于ChatGPT等系统来说不可用），要么需要通过单独的通常复杂的模块接口的外部数据库。在这项工作中，我们提出了一种简单的基于采样的方法，称为“SelfCheckGPT”，可以以零资源的方式检查黑盒模型，即不需要外部数据库。 SelfCheckGPT利用一个简单的思想：如果LLM具有特定概念的知识，则采样的响应可能类似并包含一致的事实。但是，对于幻觉的事实，随机采样的响应可能会发散并相互矛盾。我们通过使用GP-T-3模型为例来研究此方法，并在常见任务上进行广泛实验，结果表明SelfCheckGPT能够有效地检测模型的幻觉现象，且在保持准确性的同时保持良好的效率。

    Generative Large Language Models (LLMs) such as GPT-3 are capable of generating highly fluent responses to a wide variety of user prompts. However, LLMs are known to hallucinate facts and make non-factual statements which can undermine trust in their output. Existing fact-checking approaches either require access to token-level output probability distribution (which may not be available for systems such as ChatGPT) or external databases that are interfaced via separate, often complex, modules. In this work, we propose "SelfCheckGPT", a simple sampling-based approach that can be used to fact-check black-box models in a zero-resource fashion, i.e. without an external database. SelfCheckGPT leverages the simple idea that if a LLM has knowledge of a given concept, sampled responses are likely to be similar and contain consistent facts. However, for hallucinated facts, stochastically sampled responses are likely to diverge and contradict one another. We investigate this approach by using GP
    
[^67]: 基于BERT模型的推文地理位置预测

    Geolocation Predicting of Tweets Using BERT-Based Models. (arXiv:2303.07865v1 [cs.CL])

    [http://arxiv.org/abs/2303.07865](http://arxiv.org/abs/2303.07865)

    该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。

    

    该研究旨在解决推文/用户地理位置预测任务，并提供了处理文本大数据地理标记的灵活方法。该方法采用基于神经网络的自然语言处理来估计坐标对（经度，纬度）和二维高斯混合模型（GMM）。提出的模型的范围已经在Twitter数据集上使用预训练的BERT模型进行调整。性能指标表明，对于在推文内容和元数据上训练和评估的模型，全球范围内的中位误差小于30公里，美国范围内的中位误差小于15公里。

    This research is aimed to solve the tweet/user geolocation prediction task and provide a flexible methodology for the geotagging of textual big data. The suggested approach implements neural networks for natural language processing (NLP) to estimate the location as coordinate pairs (longitude, latitude) and two-dimensional Gaussian Mixture Models (GMMs). The scope of proposed models has been finetuned on a Twitter dataset using pretrained Bidirectional Encoder Representations from Transformers (BERT) as base models. Performance metrics show a median error of fewer than 30 km on a worldwide-level, and fewer than 15 km on the US-level datasets for the models trained and evaluated on text features of tweets' content and metadata context.
    
[^68]: 超越单项：使用对话式音乐播放列表构建数据探索用户对项目集的偏好

    Beyond Single Items: Exploring User Preferences in Item Sets with the Conversational Playlist Curation Dataset. (arXiv:2303.06791v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2303.06791](http://arxiv.org/abs/2303.06791)

    该论文提出了一种有效收集用户对项目集偏好数据的方法，用于构建对话式播放列表构建数据集。该数据集能够超越单项偏好，更加全面有效地了解用户需求。

    

    在音乐等消费领域，用户通常能够更有效地提供对一组项目（例如播放列表或广播）的偏好而不是对单个项目（例如歌曲）。不幸的是，这是一个未被充分研究的领域，大多数现有的推荐系统仅限于了解单个项目的偏好。我们提出了一种新的数据收集方法，通过观察项目级和集合级反馈，有效地在会话环境中收集关于项目集的真实偏好信息。我们将这项任务称为对话式项目集合作，并将其应用于音乐推荐，构建了对话式播放列表构建数据集（CPC）。

    Users in consumption domains, like music, are often able to more efficiently provide preferences over a set of items (e.g. a playlist or radio) than over single items (e.g. songs). Unfortunately, this is an underexplored area of research, with most existing recommendation systems limited to understanding preferences over single items. Curating an item set exponentiates the search space that recommender systems must consider (all subsets of items!): this motivates conversational approaches-where users explicitly state or refine their preferences and systems elicit preferences in natural language-as an efficient way to understand user needs. We call this task conversational item set curation and present a novel data collection methodology that efficiently collects realistic preferences about item sets in a conversational setting by observing both item-level and set-level feedback. We apply this methodology to music recommendation to build the Conversational Playlist Curation Dataset (CPC
    
[^69]: 精细化多模态预训练的改进视觉语言建模方法

    Refined Vision-Language Modeling for Fine-grained Multi-modal Pre-training. (arXiv:2303.05313v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.05313](http://arxiv.org/abs/2303.05313)

    本文提出了一种无需对象注释的精细化VLP方案，提出了同义词句子重写算法，设计了三种精细任务以提高精细监督的效果，并在多个任务中取得了最先进的性能。

    

    基于对象注释的精细化监督在视觉和语言预训练中已被广泛使用，但在实际应用场景中，对齐的多模态数据通常以图像标题格式呈现，仅提供粗糙的监督。收集对象注释并为不同场景构建对象注释预提取器既昂贵又计算昂贵。本文从语言角度提出了一种无需对象注释的精细化VLP方案。我们首先提出了同义词句子重写算法HSR，提供了基于词元级别的监督。接着，我们提出了精细化视觉-语言建模（RVLM）框架，以利用词元级别的监督，设计了三个精细任务，即精细的图像-文本对比（RITC）、精细的图像-文本匹配（RITM）和替换语言建模（RLM）方法，以进一步增强精细化监督。实验证明，我们的方法在多个任务中达到了最先进的性能。

    Fine-grained supervision based on object annotations has been widely used for vision and language pre-training (VLP). However, in real-world application scenarios, aligned multi-modal data is usually in the image-caption format, which only provides coarse-grained supervision. It is not only cost-expensive but also compute-expensive to collect object annotations and build object annotation pre-extractor for different scenarios. In this paper, we propose a fine-grained VLP scheme without object annotations from the linguistic perspective. First, we propose a homonym sentence rewriting (HSR) algorithm to provide token-level supervision. The algorithm replaces a verb/noun/adjective/quantifier word of the caption with its homonyms from WordNet. Correspondingly, we propose refined vision-language modeling (RVLM) framework to exploit the token-level supervision. Three refined tasks, i.e., refined image-text contrastive (RITC), refined image-text matching (RITM), and replace language modeling 
    
[^70]: SemEval-2023任务10：可解释的在线性别歧视检测

    SemEval-2023 Task 10: Explainable Detection of Online Sexism. (arXiv:2303.04222v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04222](http://arxiv.org/abs/2303.04222)

    本文介绍了SemEval任务10：可解释的在线性别歧视检测，创新地提出了具有可解释性的性别歧视内容的层次分类法，以及新的标签细粒度的数据集，可帮助解决二分类检测忽略了多样性的问题。

    

    在线性别歧视是一种广泛且有害的现象。自动化工具可以协助大规模检测性别歧视。然而，二分类检测忽略了性别歧视内容的多样性，并且无法清楚地解释为什么某些内容是性别歧视的。为了解决这个问题，我们介绍了SemEval任务10：对可解释的在线性别歧视检测（EDOS）进行了三个主要贡献：i）一种新的性别歧视内容的层次分类法，其中包括性别歧视向量以帮助解释； ii）一个新的包含细粒度标签的2万个社交媒体评论数据集，以及用于模型适应的更大的未标记数据集；和 iii）基线模型以及对参与者提交的任务的方法、结果和错误的分析。

    Online sexism is a widespread and harmful phenomenon. Automated tools can assist the detection of sexism at scale. Binary detection, however, disregards the diversity of sexist content, and fails to provide clear explanations for why something is sexist. To address this issue, we introduce SemEval Task 10 on the Explainable Detection of Online Sexism (EDOS). We make three main contributions: i) a novel hierarchical taxonomy of sexist content, which includes granular vectors of sexism to aid explainability; ii) a new dataset of 20,000 social media comments with fine-grained labels, along with larger unlabelled datasets for model adaptation; and iii) baseline models as well as an analysis of the methods, results and errors for participant submissions to our task.
    
[^71]: 语言模型分析本体子类推断

    Language Model Analysis for Ontology Subsumption Inference. (arXiv:2302.06761v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.06761](http://arxiv.org/abs/2302.06761)

    本文研究了语言模型对本体子类推断的理解能力，提出了一套涉及原子概念和复合概念的推理任务，并证明语言模型对子类推断背景知识的记忆相对较少，但在给定少量样本的情况下可显著提高准确率。

    

    最近，研究人员开始探究预训练的语言模型是否能够作为知识库的替代。然而，现有的研究都关注于简单的三元组关系型知识库，忽略了更为复杂、逻辑为基础、概念化的 OWL 本体等知识库。为了研究语言模型对于本体的了解，我们提出 OntoLAMA，它包含基于推理的一系列测试任务和数据集，从涉及原子概念和复合概念的子类推断公理出发。我们对不同领域和规模的本体进行了大量实验，结果表明，相比传统的自然语言推理，语言模型对子类推断的背景知识记忆相对较少，但是在给定少量样本的情况下，可以显著提高子类推断的准确率。我们将公开源码和数据集。

    Investigating whether pre-trained language models (LMs) can function as knowledge bases (KBs) has raised wide research interests recently. However, existing works focus on simple, triple-based, relational KBs, but omit more sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts. We conduct extensive experiments on ontologies of different domains and scales, and our results demonstrate that LMs encode relatively less background knowledge of Subsumption Inference (SI) than traditional Natural Language Inference (NLI) but can improve on SI significantly when a small number of samples are given. We will open-source our code and datasets.
    
[^72]: 数据中心机器学习的重新标签法

    The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04391](http://arxiv.org/abs/2302.04391)

    本文提出了一种重新标签的方法来解决手动标记的数据中存在噪声的问题，并通过模型预测来辅助人类标记噪声数据。实验证明此方法适用于多类深度学习任务。

    

    在深度学习应用中，手动标记的数据在一定程度上存在噪声。为了解决这个问题，并在开发数据集上获得90分以上的成绩，本文提出了一种简单的方法来找出噪声数据，并通过采用模型预测作为人类标记的参考来重新标记噪声数据。本文阐述了我们在广泛的深度学习任务中的想法，包括分类、序列标记、物体检测、序列生成、点击率预测。实验结果和人类评估结果验证了我们的想法。

    In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.
    
[^73]: 双排列等变性在知识图谱补全中的应用

    Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01313](http://arxiv.org/abs/2302.01313)

    本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。

    

    本研究将知识图谱(KGs)形式化为一种新型的图，并称之为双交换属性图，其中节点和二元（两个节点之间的）表示必须对节点号和边（及节点）属性（关系和节点特征）的排列等变。双重排列等变的KG表示在KG中开辟了新的研究方向。我们展示了这种等变性对关系的结构表示产生的影响，从而使神经网络能够在KG中执行复杂的逻辑推理任务。最后，我们介绍了一种通用的等变表示蓝图，并测试了一种简单的基于GNN的双排列等变神经结构，在WN18RR、FB237和NELL995归纳KG完成任务中实现了最先进的Hits@10测试准确率，并能够准确执行现有方法无法执行的逻辑推理任务。

    This work provides a formalization of Knowledge Graphs (KGs) as a new class of graphs that we denote doubly exchangeable attributed graphs, where node and pairwise (joint 2-node) representations must be equivariant to permutations of both node ids and edge (& node) attributes (relations & node features). Double-permutation equivariant KG representations open a new research direction in KGs. We show that this equivariance imposes a structural representation of relations that allows neural networks to perform complex logical reasoning tasks in KGs. Finally, we introduce a general blueprint for such equivariant representations and test a simple GNN-based double-permutation equivariant neural architecture that achieve state-of-the-art Hits@10 test accuracy in the WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately perform logical reasoning tasks that no existing methods can perform, to the best of our knowledge.
    
[^74]: ALCAP: 基于对齐的音乐字幕生成器

    ALCAP: Alignment-Augmented Music Captioner. (arXiv:2212.10901v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2212.10901](http://arxiv.org/abs/2212.10901)

    本文提出了一种基于对齐的音乐字幕生成器，通过对比学习显式学习音频和歌词的对应关系，并生成高质量的字幕，取得了两个音乐字幕数据集上的最新领先水平。

    

    随着音乐流媒体平台用于音乐搜索和推荐的日益普及，需要新方法来解释音乐，同时考虑歌词和音频。然而，许多先前的研究关注于精细调整将音乐映射到字幕记号的编码器-解码器架构的各个组件，忽略了音频和歌词之间对应的潜在益处。本文提出了一种通过对比学习来显式学习多模态对齐的方法。通过学习音频-歌词的对应关系，使模型指导学习更好的跨模态一致性，从而生成高质量的字幕。我们提供了理论和经验结果，证明了所提出方法的优势，并在两个音乐字幕数据集上达到了新的状态-最先进水平。

    Growing popularity of streaming media platforms for music search and recommendations has led to a need for novel methods for interpreting music that take into account both lyrics and audio. However, many previous works focus on refining individual components of encoder-decoder architecture that maps music to caption tokens, ignoring the potential benefits of correspondence between audio and lyrics. In this paper, we propose to explicitly learn the multimodal alignment through contrastive learning. By learning audio-lyrics correspondence, the model is guided to learn better cross-modal consistency, thus generating high-quality captions. We provide both theoretical and empirical results demonstrating the advantage of the proposed method, and achieve new state-of-the-art on two music captioning datasets.
    
[^75]: GPT-3是否展示出精神病态？从心理学角度评估大型语言模型

    Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective. (arXiv:2212.10529v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10529](http://arxiv.org/abs/2212.10529)

    本文从心理学角度评估大型语言模型的安全性，发现所有模型在短暗三合一测验上的得分都高于人类平均水平，存在相对较暗的人格模式。尽管经过指标微调，两种模型仍呈现隐含的黑暗人格模式。同时，本文观察到GPT-3和InstructGPT的幸福感得分持续增加。

    

    本文旨在从心理学角度确定大型语言模型（LLMs）的安全性。我们设计了无偏的提示来系统性地评估LLMs。首先，我们使用了两个人格测试——短暗三合一测验（SD-3）和大五人格问卷（BFI）测试了三个不同的LLMs。所有模型在SD-3上的得分都高于人类平均水平，表明存在相对较暗的人格模式。尽管经过指标微调以减少毒性，InstructGPT和FLAN-T5仍然呈现出隐含的黑暗人格模式；在SD-3的玛基雅维利主义和自恋狂特征上，这两种模型的得分都高于自监督GPT-3。然后，我们使用幸福感测试评估了GPT-3系列中的LLMs，以研究更多训练数据的微调对其影响。我们观察到GPT-3和InstructGPT的幸福感得分持续增加。鉴于这些观察结果，我们展示了使用正面回答从而指标微调FLAN-T5的方法。

    In this work, we determined whether large language models (LLMs) are psychologically safe. We designed unbiased prompts to systematically evaluate LLMs from a psychological perspective. First, we tested three different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT and FLAN-T5 still showed implicit dark personality patterns; both models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT-3 series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT-3 and InstructGPT. Following these observations, we showed that instruction fine-tuning FLAN-T5 with positive answers from 
    
[^76]: 论文信息提取中的事件个体化问题

    On Event Individuation for Document-Level Information Extraction. (arXiv:2212.09702v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09702](http://arxiv.org/abs/2212.09702)

    提出了问题──事件个体化对于模板填充任务是否适用，通过注释研究和误差分析，我们发现这引发了对模板填充度量的有效性、任务数据集的质量以及模型学习能力的担忧。

    

    随着信息提取系统在处理整个文件方面越来越熟练，传统的模板填充任务作为文件级信息提取的基准任务再次引起了人们的关注。在本文中，我们质疑了模板填充任务在这方面的适用性。我们认为该任务要求对事件个体化问题提供明确的答案——即区分不同的事件——而即使是人类专家在这个问题上也存在分歧。通过注释研究和误差分析，我们展示了这引发了对模板填充度量的有效性、任务数据集的质量以及模型学习能力的担忧。最后，我们考虑了可能的解决方案。

    As information extraction (IE) systems have grown more adept at processing whole documents, the classic task of template filling has seen renewed interest as benchmark for document-level IE. In this position paper, we call into question the suitability of template filling for this purpose. We argue that the task demands definitive answers to thorny questions of event individuation -- the problem of distinguishing distinct events -- about which even human experts disagree. Through an annotation study and error analysis, we show that this raises concerns about the usefulness of template filling metrics, the quality of datasets for the task, and the ability of models to learn it. Finally, we consider possible solutions.
    
[^77]: 使用语言模型提示进行推理：一项调查

    Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09597](http://arxiv.org/abs/2212.09597)

    本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。

    

    推理作为复杂问题解决的重要能力，可以为医疗诊断、谈判等各种实际应用提供后端支持。本文对使用语言模型提示进行推理的前沿研究进行了综合调查。我们介绍了研究成果的比较和总结，并提供了系统资源以帮助初学者。我们还讨论了新兴推理能力出现的潜在原因，并突出了未来的研究方向。资源可在 https://github.com/zjunlp/Prompt4ReasoningPapers 上获取（定期更新）。

    Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
    
[^78]: 大型语言模型遇见NL2Code：综述

    Large Language Models Meet NL2Code: A Survey. (arXiv:2212.09420v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2212.09420](http://arxiv.org/abs/2212.09420)

    本文综述了27个大型语言模型对于NL2Code的应用，总结出这些模型成功的三大关键因素：巨大的模型尺寸、高质量的数据和专家的调整。同时，本文还讨论了模型和人类之间的差距，并提供了一个用于追踪最新进展的网站。

    

    从自然语言描述生成代码，即NL2Code，被视为代码智能中紧迫且重要的挑战。由于预训练技术的快速发展，涌现出了为代码提供支持的大型语言模型，进一步推动了NL2Code的进展。为了促进此领域的进一步研究和应用，本文综述了27个现有的NL2Code大型语言模型，并回顾了基准和度量标准。我们在HumanEval基准测试中提供了对所有现有模型的直观比较。通过深入观察和分析，我们提供了一些见解，总结了大型语言模型为NL2Code成功的关键因素是“巨大尺寸、高质量数据、专家调整”。此外，我们讨论了模型与人类之间差距的挑战和机会。我们还创建了一个网站 https://nl2code.github.io，通过众包评估来追踪最新进展。

    The task of generating code from a natural language description, or NL2Code, is considered a pressing and significant challenge in code intelligence. Thanks to the rapid development of pre-training techniques, surging large language models are being proposed for code, sparking the advances in NL2Code. To facilitate further research and applications in this field, in this paper, we present a comprehensive survey of 27 existing large language models for NL2Code, and also review benchmarks and metrics. We provide an intuitive comparison of all existing models on the HumanEval benchmark. Through in-depth observation and analysis, we provide some insights and conclude that the key factors contributing to the success of large language models for NL2Code are "Large Size, Premium Data, Expert Tuning". In addition, we discuss challenges and opportunities regarding the gap between models and humans. We also create a website https://nl2code.github.io to track the latest progress through crowd-sou
    
[^79]: 检索增强语言模型是否具备推理能力？检索模块和语言模型之争

    Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model. (arXiv:2212.09146v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09146](http://arxiv.org/abs/2212.09146)

    本论文研究了检索增强语言模型的推理能力，发现检索器和语言模型之间存在推卸责任的问题，且检索器选择的句子和语言模型不考虑句子之间的复杂关系都会影响推理性能。针对这些问题，本文提出了一种新的框架ReForMask，采用掩码检索方法来更好地捕捉语句之间的复杂关系并在多个任务上实现了显著优化。

    

    预先训练的语言模型采用检索器来选择支持文档，在解决常见的NLP问题（包括语言建模和问答）方面表现出良好的效果，并且具有可解释性。本文首先研究了检索增强语言模型（REALM，kNN-LM，FiD和DPR，ATLAS和Flan-T5和Contriever耦合）在不同任务中推理检索语句的优点和局限性。我们展示了检索-阅读模型在推理方面的局限性既来自检索模块，也来自语言模型。实验结果表明，检索器使用的相似度度量通常不足以用于推理任务。此外，我们发现，检索增强模型中的语言模型不考虑语句之间的复杂关系，导致即使使用较大的模型，推理性能也不佳。此外，我们发现检索器和语言模型在推理中面临着“责怪游戏”的问题：当检索器选择正确的语句时，语言模型可以进行良好的推理；当检索器选择错误的语句时，语言模型无法进行良好的推理。为解决这些问题，我们提出了一种新的框架ReForMask，采用掩码检索方法来更好地捕捉语句之间的复杂关系。我们的实验结果表明，ReForMask在多种常见的NLP任务上显著优于现有的检索增强模型。

    Augmenting pretrained language models with retrievers to select the supporting documents has shown promise in effectively solving common NLP problems, including language modeling and question answering, in an interpretable way. In this paper, we first study the strengths and weaknesses of different retriever-augmented language models (REALM, $k$NN-LM, FiD coupled with DPR, and ATLAS and Flan-T5 coupled with Contriever) in reasoning over the retrieved statements in different tasks. We show how the retrieve-then-read models' limitations in reasoning are rooted both in the retriever module as well as the language model. Our experimental results demonstrate that the similarity metric used by the retrievers is generally insufficient for reasoning tasks. Additionally, we show that the language models in retriever-augmented models do not take the complicated relations between the statements into account, which leads to poor reasoning performance even when using the larger models. Moreover, we
    
[^80]: 从任务说明书中学习的鲁棒性

    Robustness of Learning from Task Instructions. (arXiv:2212.03813v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.03813](http://arxiv.org/abs/2212.03813)

    本文提出了一种鲁棒的方法来从任务说明中学习，以处理说明的变化并提高对新任务的泛化能力。

    

    传统的监督学习大多在个别任务上进行，并需要在大量的任务特定示例上训练。这种范式严重阻碍了任务概括的发展，因为准备任务特定示例集是昂贵的。为了构建一个可以快速轻松地推广到新任务的系统，最近采用了任务说明作为监督的新兴趋势。这些说明给模型定义了任务，并允许模型根据说明和输入输出适当的答案。然而，任务说明通常以不同形式表达，可以从两个线索中解释：首先，一些说明是短句，并且是预训练的语言模型（PLM）导向，例如提示，而其他说明是段落，并且是人为导向的，例如亚马逊的MTurk; 其次，不同的最终用户很可能用不同的文本表达方式解释相同的任务。需要一种鲁棒的学习方法来解决任务说明的可变性。在本文中，作者提出了一种鲁棒的方法来从任务说明中学习，可以处理说明的变化并改善对新任务的概括。

    Traditional supervised learning mostly works on individual tasks and requires training on a large set of task-specific examples. This paradigm seriously hinders the development of task generalization since preparing a task-specific example set is costly. To build a system that can quickly and easily generalize to new tasks, task instructions have been adopted as an emerging trend of supervision recently. These instructions give the model the definition of the task and allow the model to output the appropriate answer based on the instructions and inputs. However, task instructions are often expressed in different forms, which can be interpreted from two threads: first, some instructions are short sentences and are pretrained language model (PLM) oriented, such as prompts, while other instructions are paragraphs and are human-oriented, such as those in Amazon MTurk; second, different end-users very likely explain the same task with instructions of different textual expressions. A robust 
    
[^81]: 语言建模在推荐系统中的关键作用：丰富任务特定和任务无关的表示学习

    Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning. (arXiv:2212.03760v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2212.03760](http://arxiv.org/abs/2212.03760)

    本文研究发现，用户历史语言建模可以在不同推荐任务中取得优异结果，并且利用任务无关的用户历史还可以提供显著的性能优势。该方法具有广泛的现实世界迁移学习能力。

    

    最近的研究提出了利用来自各种应用程序的用户行为数据的统一用户建模框架。其中许多受益于将用户行为序列作为纯文本使用，代表着任何领域或系统中的丰富信息而不失通用性。因此，一个问题产生了：用户历史语言建模能否帮助改善推荐系统？虽然语言建模的多功能性已在许多领域广泛研究，但其在推荐系统中的应用仍未深入探讨。我们展示了直接应用于任务特定用户历史的语言建模在不同的推荐任务上可以取得优异的结果。此外，利用任务无关的用户历史还可以提供显著的性能优势。我们进一步证明了我们的方法可以为广泛的现实世界推荐系统提供有前途的迁移学习能力，甚至在未知域和服务上也可以实现。

    Recent studies have proposed unified user modeling frameworks that leverage user behavior data from various applications. Many of them benefit from utilizing users' behavior sequences as plain texts, representing rich information in any domain or system without losing generality. Hence, a question arises: Can language modeling for user history corpus help improve recommender systems? While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored. We show that language modeling applied directly to task-specific user histories achieves excellent results on diverse recommendation tasks. Also, leveraging additional task-agnostic user histories delivers significant performance benefits. We further demonstrate that our approach can provide promising transfer learning capabilities for a broad spectrum of real-world recommender systems, even on unseen domains and services.
    
[^82]: 多视角压缩表示的鲁棒性低资源微调研究

    Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations. (arXiv:2211.08794v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08794](http://arxiv.org/abs/2211.08794)

    本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。

    

    由于参数的巨大数量，预训练语言模型（PLMs）的微调容易在低资源场景中出现过度拟合的问题。本文提出了一种新方法，该方法在PLM的隐藏表示上操作，以减少过拟合。在微调过程中，我们的方法在PLM的隐藏层之间插入随机自编码器，将来自前一层的激活转换为多视角压缩表示，然后将其馈送到上层。微调结束后，自编码器会被移除掉，因此我们的方法在推理过程中不会增加额外的参数或计算成本。我们的方法在一系列序列和标记级别的低资源NLP任务中展现了出色的性能提升。

    Due to the huge amount of parameters, fine-tuning of pretrained language models (PLMs) is prone to overfitting in the low resource scenarios. In this work, we present a novel method that operates on the hidden representations of a PLM to reduce overfitting. During fine-tuning, our method inserts random autoencoders between the hidden layers of a PLM, which transform activations from the previous layers into a multi-view compressed representation before feeding it into the upper layers. The autoencoders are plugged out after fine-tuning, so our method does not add extra parameters or increase computation cost during inference. Our method demonstrates promising performance improvement across a wide range of sequence- and token-level low-resource NLP tasks.
    
[^83]: 探究基于声调和语言特征的神经文本朗读自然度评估方法

    Investigating Content-Aware Neural Text-To-Speech MOS Prediction Using Prosodic and Linguistic Features. (arXiv:2211.00342v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.00342](http://arxiv.org/abs/2211.00342)

    本文提出探究声调和语言特征如何影响神经文本朗读自然度预测，通过加入这些特征，相较于基于频谱特征的基线模型 MOSNet，在 MOS 预测中取得了平均12%无公害提高。

    

    自动化合成音声的最新评估方法是基于 MOS 预测神经模型，其中 MOSNet 和 LDNet 使用频谱特征作为输入，而 SSL-MOS 则依赖于预训练的自监督学习模型，直接使用语音信号作为输入。在现代高质量的神经 TTS 系统中，就发音内容而言，声调的适当性是决定性的因素。为此，我们建议在 MOS 预测系统中包括声调和语言特征作为额外的输入，并评估它们对预测结果的影响。我们考虑了音素级的 F0 和持续时间特征作为声调输入，以及 Tacotron 编码器输出、POS 标记和 BERT 嵌入作为更高级别的语言输入。所有 MOS 预测系统均在 SOMOS 上进行训练，该数据集仅有神经语音合成技术和众包自然度 MOS 评估数据。结果表明，所提出的额外特征能够有利于提高 MOS 预测结果，相对于仅使用频谱特征的基线 MOSNet，平均提高了12%。

    Current state-of-the-art methods for automatic synthetic speech evaluation are based on MOS prediction neural models. Such MOS prediction models include MOSNet and LDNet that use spectral features as input, and SSL-MOS that relies on a pretrained self-supervised learning model that directly uses the speech signal as input. In modern high-quality neural TTS systems, prosodic appropriateness with regard to the spoken content is a decisive factor for speech naturalness. For this reason, we propose to include prosodic and linguistic features as additional inputs in MOS prediction systems, and evaluate their impact on the prediction outcome. We consider phoneme level F0 and duration features as prosodic inputs, as well as Tacotron encoder outputs, POS tags and BERT embeddings as higher-level linguistic inputs. All MOS prediction systems are trained on SOMOS, a neural TTS-only dataset with crowdsourced naturalness MOS evaluations. Results show that the proposed additional features are benefi
    
[^84]: “多任务预训练模块化提示在中文少样本学习中的应用”

    Multitask Pre-training of Modular Prompt for Chinese Few-Shot Learning. (arXiv:2210.07565v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07565](http://arxiv.org/abs/2210.07565)

    本文提出了多任务预训练模块化提示方法（MP2），用于解决在中文少样本学习中提示调整的不足。MP2是一组在38个中文任务上预训练的可组合提示，能够在面对未见过的任务时具备强大的组合泛化能力。在两种学习范式下的实验中，MP2在少样本情形下显著优于其他方法。

    

    提示调整是一种参数效率高的方法，用于将预训练的语言模型适应于下游任务。虽然在训练数据充足时，提示调整已经被证明可以与完全模型调整的性能相匹配，但在少样本学习环境下，它往往难以胜任。本文提出了一种名为多任务预训练模块化提示（MP2）的方法，用于增强提示调整在少样本学习中的表现。MP2是一组在38个中文任务上预训练的可组合提示。在下游任务中，预训练的提示可以被选择性地激活和组合，从而在面对未见过的任务时具备强大的组合泛化能力。为弥合预训练和微调之间的差距，我们将上游和下游任务统一为机器阅读理解任务。在两种学习范式即梯度下降和黑盒调整下的广泛实验表明，MP2在少样本情形下显著优于提示调整、完全模型调整和先前的提示预训练方法。

    Prompt tuning is a parameter-efficient approach to adapting pre-trained language models to downstream tasks. Although prompt tuning has been shown to match the performance of full model tuning when training data is sufficient, it tends to struggle in few-shot learning settings. In this paper, we present Multi-task Pre-trained Modular Prompt (MP2) to boost prompt tuning for few-shot learning. MP2 is a set of combinable prompts pre-trained on 38 Chinese tasks. On downstream tasks, the pre-trained prompts are selectively activated and combined, leading to strong compositional generalization to unseen tasks. To bridge the gap between pre-training and fine-tuning, we formulate upstream and downstream tasks into a unified machine reading comprehension task. Extensive experiments under two learning paradigms, i.e., gradient descent and black-box tuning, show that MP2 significantly outperforms prompt tuning, full model tuning, and prior prompt pre-training methods in few-shot settings. In addi
    
[^85]: 机器生成文本：威胁模型和检测方法的综合调查

    Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods. (arXiv:2210.07321v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07321](http://arxiv.org/abs/2210.07321)

    本文主要调查了机器生成文本对社会和网络安全所带来的威胁，提供了最完整的机器生成文本检测方法评估，为应对威胁模型和解决检测问题提供了强有力的指导。

    

    机器生成的文本越来越难以与人类撰写的文本区分开来。功能强大的开源模型可以免费使用，可民主化访问生成模型的用户友好工具正在迅速增多。本次调查的第一版面世后不久，发布了ChatGPT，这一趋势被彰显出来。最先进的自然语言生成（NLG）系统的巨大潜力被各种滥用途径所抑制。检测机器生成文本是减少NLG模型滥用的主要对策，但也面临着重大技术挑战和众多未解决问题。我们提供了一份综合调查，包括1）对当代NLG系统造成威胁模型的广泛分析和2）截至目前为止关于机器生成文本检测方法的最完整的综述。这份调查将机器生成文本置于其网络安全和社会背景之中，并为未来解决最重要威胁模型提供了强有力的指导，并概述了最有前途的检测方法。

    Machine generated text is increasingly difficult to distinguish from human authored text. Powerful open-source models are freely available, and user-friendly tools that democratize access to generative models are proliferating. ChatGPT, which was released shortly after the first edition of this survey, epitomizes these trends. The great potential of state-of-the-art natural language generation (NLG) systems is tempered by the multitude of avenues for abuse. Detection of machine generated text is a key countermeasure for reducing abuse of NLG models, with significant technical challenges and numerous open problems. We provide a survey that includes both 1) an extensive analysis of threat models posed by contemporary NLG systems, and 2) the most complete review of machine generated text detection methods to date. This survey places machine generated text within its cybersecurity and social context, and provides strong guidance for future work addressing the most critical threat models, a
    
[^86]: 离真正的同义词替换攻击还有多远？

    How Far Are We from Real Synonym Substitution Attacks?. (arXiv:2210.02844v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.02844](http://arxiv.org/abs/2210.02844)

    本文探讨同义词替换攻击的现状，发现当前方法存在无解决的障碍，生成的敌对样本效果不佳，需要在未来改进。

    

    本文探讨一个问题：我们距离真正的同义词替换攻击有多远？我们通过研究同义词替换攻击如何替换原始句子来探讨这个问题，并显示当前同义词替换攻击仍存在未解决的障碍使得生成的敌对样本是无效的。我们揭示了四种广泛使用的单词替换方法生成大量无效替换词，这些词是不合语法的或不符合原始句子的语义。接下来，我们展示了在检测无效敌对样本方面，SSA所使用的语义和语法约束是高度不足的。我们的工作是未来构建更好的SSA的重要基石。

    In this paper, we explore the following question: how far are we from real synonym substitution attacks (SSAs). We approach this question by examining how SSAs replace words in the original sentence and show that there are still unresolved obstacles that make current SSAs generate invalid adversarial samples. We reveal that four widely used word substitution methods generate a large fraction of invalid substitution words that are ungrammatical or do not preserve the original sentence's semantics. Next, we show that the semantic and grammatical constraints used in SSAs for detecting invalid word replacements are highly insufficient in detecting invalid adversarial samples. Our work is an important stepping stone to constructing better SSAs in the future.
    
[^87]: 音乐文本视觉交感：从音乐录音中生成描述性文本

    Music-to-Text Synaesthesia: Generating Descriptive Text from Music Recordings. (arXiv:2210.00434v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2210.00434](http://arxiv.org/abs/2210.00434)

    本文提出了音乐文本视觉交感问题，收集了对齐的数据集，构建了一个计算模型来生成描述音乐录音内容的句子，并设计了群拓扑保持损失来解决高非判别性的古典音乐。

    

    本文提出了一个新的研究问题：音乐文本视觉交感。不同于把音乐录音分类到预定义的类别的经典音乐标记问题，音乐文本视觉交感旨在生成具有相同情感的音乐录音的描述性文本，以便进一步理解。由于现有的音乐相关数据集不包含音乐录音的语义描述，我们收集了一个包含1,955个古典音乐录音与文本描述的对齐数据集。基于此，我们构建了一个计算模型来生成可以描述音乐录音内容的句子。为了解决高度非判别性的古典音乐，我们设计了一个群拓扑保持损失，它考虑更多的样本作为群组参考，并保留不同样本之间的相对拓扑。广泛的实验结果定性和定量地证明了我们提出的模型在五个不同的指标上的有效性。

    In this paper, we consider a novel research problem: music-to-text synaesthesia. Different from the classical music tagging problem that classifies a music recording into pre-defined categories, music-to-text synaesthesia aims to generate descriptive texts from music recordings with the same sentiment for further understanding. As existing music-related datasets do not contain the semantic descriptions on music recordings, we collect a new dataset that contains 1,955 aligned pairs of classical music recordings and text descriptions. Based on this, we build a computational model to generate sentences that can describe the content of the music recording. To tackle the highly non-discriminative classical music, we design a group topology-preservation loss, which considers more samples as a group reference and preserves the relative topology among different samples. Extensive experimental results qualitatively and quantitatively demonstrate the effectiveness of our proposed model over five
    
[^88]: Vega-MT: JD Explore Academy的WMT22翻译系统

    Vega-MT: The JD Explore Academy Translation System for WMT22. (arXiv:2209.09444v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.09444](http://arxiv.org/abs/2209.09444)

    Vega-MT是JD Explore Academy为WMT22共享的翻译任务开发的系统。该系统扩大了语言对和模型大小，实现了“双向”到“多向”的拓展并采取了数据增强策略，从而提高翻译质量。

    

    本文描述了JD Explore Academy参加WMT 2022共享翻译任务的情况。我们参加了所有的高资源轨道和一个中资源轨道，包括中英文、德英文、捷英文、俄英文和日英文。我们通过扩展语言对和模型大小这两个主要因素，即Vega-MT系统，来推动我们之前进行的翻译的双向训练的极限。就语言对而言，我们将“双向”扩展到“多向”设置，涵盖了所有参与的语言，以利用跨语言的共同知识，并将其转移到下游的双语任务中。就模型大小而言，我们将Transformer-Big扩展到几乎拥有47亿参数的极大模型，以充分提升我们的Vega-MT的模型容量。同时，我们采取数据增强策略，如单语数据的循环翻译和双语自我训练等方法。

    We describe the JD Explore Academy's submission of the WMT 2022 shared general translation task. We participated in all high-resource tracks and one medium-resource track, including Chinese-English, German-English, Czech-English, Russian-English, and Japanese-English. We push the limit of our previous work -- bidirectional training for translation by scaling up two main factors, i.e. language pairs and model sizes, namely the \textbf{Vega-MT} system. As for language pairs, we scale the "bidirectional" up to the "multidirectional" settings, covering all participating languages, to exploit the common knowledge across languages, and transfer them to the downstream bilingual tasks. As for model sizes, we scale the Transformer-Big up to the extremely large model that owns nearly 4.7 Billion parameters, to fully enhance the model capacity for our Vega-MT. Also, we adopt the data augmentation strategies, e.g. cycle translation for monolingual data, and bidirectional self-training for bilingua
    
[^89]: 自然语言理解中大型语言模型的快捷学习

    Shortcut Learning of Large Language Models in Natural Language Understanding. (arXiv:2208.11857v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.11857](http://arxiv.org/abs/2208.11857)

    本文综述了大型语言模型中快捷学习和鲁棒性挑战的解决方法和相关研究，包括识别其快捷学习行为、原因和解决方案，并探讨了领域的主要研究挑战和潜在研究方向。

    

    大型语言模型(LLMs)在一系列自然语言理解任务中取得了最先进的性能。然而，这些LLMs可能会依赖于数据集的偏见和缺陷作为预测的快捷方式。这显著地影响了它们的泛化能力和对抗鲁棒性。本文综述了最近解决LLMs快捷学习和鲁棒性挑战的发展。我们首先介绍语言模型的快捷学习概念。然后介绍了识别语言模型快捷学习行为的方法，表征快捷学习的原因，并介绍了缓解解决方案。最后，我们讨论了LLMs领域的主要研究挑战和潜在研究方向。

    Large language models (LLMs) have achieved state-of-the-art performance on a series of natural language understanding tasks. However, these LLMs might rely on dataset bias and artifacts as shortcuts for prediction. This has significantly affected their generalizability and adversarial robustness. In this paper, we provide a review of recent developments that address the shortcut learning and robustness challenge of LLMs. We first introduce the concepts of shortcut learning of language models. We then introduce methods to identify shortcut learning behavior in language models, characterize the reasons for shortcut learning, as well as introduce mitigation solutions. Finally, we discuss key research challenges and potential research directions in order to advance the field of LLMs.
    
[^90]: 广告中的说服策略

    Persuasion Strategies in Advertisements. (arXiv:2208.09626v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.09626](http://arxiv.org/abs/2208.09626)

    本论文提出了一个广告图片语料库和说服策略预测任务。通过设计多任务注意力融合模型，可以预测广告中的说服策略。

    

    研究广告中的说服力对于研究宣传、社会心理学和营销至关重要。然而，由于缺乏具有与广告相关的说服策略的基准数据集，计算机视觉中的说服建模仍处于起步阶段。本文提出了广泛的说服策略词汇，并建立了第一个注释有说服策略的广告图片语料库。我们进一步提出了一种多模态学习的说服策略预测任务，并设计了一种多任务注意力融合模型，它可以利用其他广告理解任务来预测说服策略。

    Modeling what makes an advertisement persuasive, i.e., eliciting the desired response from consumer, is critical to the study of propaganda, social psychology, and marketing. Despite its importance, computational modeling of persuasion in computer vision is still in its infancy, primarily due to the lack of benchmark datasets that can provide persuasion-strategy labels associated with ads. Motivated by persuasion literature in social psychology and marketing, we introduce an extensive vocabulary of persuasion strategies and build the first ad image corpus annotated with persuasion strategies. We then formulate the task of persuasion strategy prediction with multi-modal learning, where we design a multi-task attention fusion model that can leverage other ad-understanding tasks to predict persuasion strategies. Further, we conduct a real-world case study on 1600 advertising campaigns of 30 Fortune-500 companies where we use our model's predictions to analyze which strategies work with di
    
[^91]: 面向领域适应关键短语生成的通用到特定迁移标记方法

    General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase Generation. (arXiv:2208.09606v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.09606](http://arxiv.org/abs/2208.09606)

    本文提出了一种三阶段流程，通过领域通用短语预训练、迁移标记和有限真实标注数据微调来适应新领域，使关键短语生成（KPG）模型具备更强的可迁移性。

    

    训练关键短语生成（KPG）模型需要大量的注释数据，这可能会成为限制其通用性的障碍，并且这些数据通常限定在特定的领域。本研究首先证明不同领域之间的大规模分布转变会严重阻碍KPG模型的可迁移性。然后我们提出了一个三阶段的流程，该流程通过高效利用数据，逐步引导KPG模型学习焦点从通用的句法特征到与领域相关的语义。我们使用领域通用短语预训练，利用网络上广泛可用的通用短语注释对序列到序列模型进行预训练，从而使模型能够在各种领域生成短语。生成的模型然后在迁移标记阶段中应用于产生领域特定的伪关键短语，这有助于将模型适应到一个新领域。最后，我们使用有限的数据对真实标签进行微调，以充分适应目标领域。我们的实验结果显示...

    Training keyphrase generation (KPG) models require a large amount of annotated data, which can be prohibitively expensive and often limited to specific domains. In this study, we first demonstrate that large distribution shifts among different domains severely hinder the transferability of KPG models. We then propose a three-stage pipeline, which gradually guides KPG models' learning focus from general syntactical features to domain-related semantics, in a data-efficient manner. With Domain-general Phrase pre-training, we pre-train Sequence-to-Sequence models with generic phrase annotations that are widely available on the web, which enables the models to generate phrases in a wide range of domains. The resulting model is then applied in the Transfer Labeling stage to produce domain-specific pseudo keyphrases, which help adapt models to a new domain. Finally, we fine-tune the model with limited data with true labels to fully adapt it to the target domain. Our experiment results show th
    
[^92]: 探究CLIP的开放性

    Delving into the Openness of CLIP. (arXiv:2206.01986v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.01986](http://arxiv.org/abs/2206.01986)

    本研究探究了CLIP模型的开放性，并通过词汇扩展来评估模型的可扩展性。研究发现，类似于CLIP的模型并不真正开放，并且随着词汇表的扩展其性能会恶化。此外，研究还揭示了CLIP表示在不变性和特定性之间存在权衡。

    

    对比语言-图像预训练（CLIP）将图像分类作为一项图像到文本匹配任务，即将图像与相应的自然语言描述进行匹配，而不是离散的类别ID。这使得模型可以以零-shot方式从开放类集（也称为开放词汇表）中识别图像。然而，评估类似于CLIP的模型的开放性很具有挑战性，因为这些模型理论上对任意词汇开放，但在实践中其精度有所变化。为解决这个问题，我们采用了递增的视角通过词汇扩展来评估开放性，并定义了可扩展性来衡量模型处理新类的能力。我们的评估结果表明，类似于CLIP的模型并不真正开放，并且随着词汇表的扩展其性能会恶化。我们进一步从表示对齐和统一性的角度剖析了CLIP的特征空间。我们的研究揭示CLIP表示在不监督的预训练中在不变性和特定性之间存在权衡，通过微调可提高其特定性。

    Contrastive Language-Image Pre-training (CLIP) formulates image classification as an image-to-text matching task, i.e., matching images to the corresponding natural language descriptions instead of discrete category IDs. This allows for open-vocabulary visual recognition, where the model can recognize images from an open class set (also known as an open vocabulary) in a zero-shot manner. However, evaluating the openness of CLIP-like models is challenging, as the models are open to arbitrary vocabulary in theory, but their accuracy varies in practice. To address this, we resort to an incremental perspective to assess the openness through vocabulary expansions, and define extensibility to measure a model's ability to handle novel classes. Our evaluation shows that CLIP-like models are not truly open, and their performance deteriorates as the vocabulary expands. We further dissect the feature space of CLIP from the perspectives of representation alignment and uniformity. Our investigation
    
[^93]: 任务导向对话系统的帮助性和公平性研究

    Helpfulness and Fairness of Task-Oriented Dialogue Systems. (arXiv:2205.12554v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12554](http://arxiv.org/abs/2205.12554)

    本文研究任务导向对话系统的帮助性和公平性。作者定义了对话系统的帮助性，使用分类器自动确定帮助性，并提出使用帮助级别来衡量对话系统的公平性。实验结果表明，现有系统更容易为来自发达国家概念的问题提供帮助。

    

    目标导向的对话系统旨在帮助用户实现某些目标，因此人们对其帮助性的感知很重要。然而，目前尚未对目标导向对话系统的人类感知帮助性以及其公平性影响进行深入研究。本文研究了帮助性的计算度量，并通过人类注释构建分类器，自动确定响应的帮助性。我们进一步提出使用对不同用户查询的帮助级别来衡量对话系统的公平性。实验表明，现有系统在三种信息查询场景下更容易为来自发达国家概念的问题提供帮助。

    Goal-oriented dialogue systems aim to help users achieve certain goals. Therefore, how humans perceive their helpfulness is important. However, neither the human-perceived helpfulness of goal-oriented dialogue systems nor its fairness implication has been well studied. In this paper, we study computational measurements of helpfulness. We first formally define a dialogue response as helpful if it is relevant & coherent, useful, and informative to a query. Then, we collect human annotations for the helpfulness of dialogue responses based on our definition and build a classifier to automatically determine the helpfulness of a response. We further propose to use the helpfulness level of a dialogue system towards different user queries to measure the fairness of a dialogue system. Experiments with state-of-the-art dialogue systems under three information-seeking scenarios reveal that existing systems tend to be more helpful for questions regarding concepts from highly-developed countries th
    
[^94]: 一个大规模多元化的阿拉伯语语料库用于语言建模

    A Large and Diverse Arabic Corpus for Language Modeling. (arXiv:2201.09227v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.09227](http://arxiv.org/abs/2201.09227)

    该论文介绍了一个大规模的阿拉伯语语料库，旨在提高大规模语言模型的跨领域知识和推理能力。

    

    语言模型（LM）引入了自然语言处理（NLP）建模的重大范式转变，其中大型预先训练的LM已经成为大多数NLP任务不可分割的组成部分。LM足够智能，可以在没有任何监督的情况下找到语言的有用和相关表示。这些模型被用于对常规NLP任务进行微调，相对于传统方法，具有显着更高的准确性。相反，这些模型的训练需要一个大规模的语料库，这个语料库可以很好地代表阿拉伯语。由于英语语料库可获得大量资源，因此英语LM通常比其他语言LM表现更好。本文详细描述了一个大型阿拉伯语语料库的设计和开发。它由超过500GB的已加工的阿拉伯文本组成，旨在提高大规模语言模型的跨领域知识和下游推理能力。此外，该语料库还用于训练大型阿拉伯语LM。

    Language models (LMs) have introduced a major paradigm shift in Natural Language Processing (NLP) modeling where large pre-trained LMs became integral to most of the NLP tasks. The LMs are intelligent enough to find useful and relevant representations of the language without any supervision. Perhaps, these models are used to fine-tune typical NLP tasks with significantly high accuracy as compared to the traditional approaches. Conversely, the training of these models requires a massively large corpus that is a good representation of the language. English LMs generally perform better than their other language counterparts, due to the availability of massive English corpora. This work elaborates on the design and development of a large Arabic corpus. It consists of over 500 GB of Arabic cleaned text targeted at improving cross-domain knowledge and downstream generalization capability of large-scale language models. Moreover, the corpus is utilized in the training of a large Arabic LM. In
    

