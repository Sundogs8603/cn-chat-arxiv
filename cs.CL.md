# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark.](http://arxiv.org/abs/2304.03279) | 本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。 |
| [^2] | [Instruction Tuning with GPT-4.](http://arxiv.org/abs/2304.03277) | 本文提出使用GPT-4生成指令遵循数据进行LLM微调，实验表明GPT-4所生成的指令数据优于以往最先进模型生成的数据，在新任务中表现卓越。 |
| [^3] | [Large language models effectively leverage document-level context for literary translation, but critical errors persist.](http://arxiv.org/abs/2304.03245) | 该研究通过人工评估发现，大型语言模型在进行文学段落翻译时会利用更多的文档级上下文，从而减少关键错误。然而，一些与上下文和意义相关的错误仍然存在。 |
| [^4] | [FedBot: Enhancing Privacy in Chatbots with Federated Learning.](http://arxiv.org/abs/2304.03228) | 本论文提出了一个利用联邦学习保护用户隐私的聊天机器人FedBot。它结合了Deep Bidirectional Transformer模型和联邦学习算法，在联合模型训练过程中保护客户数据隐私。 |
| [^5] | [On the Pareto Front of Multilingual Neural Machine Translation.](http://arxiv.org/abs/2304.03216) | 本研究针对多语言神经机器翻译的数据不平衡问题，提出双重幂律方法用于预测独特的性能权衡前沿，并建立基于该方法的样本比例选择优化问题，取得更好的结果。 |
| [^6] | [Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster.](http://arxiv.org/abs/2304.03208) | 本论文介绍了从111M到13B参数的开放计算优化语言模型 Cerebras-GPT，它采用了高效的预训练方法和缩放规则，具有最先进的训练效率和可预测性，这是一个开放可复现的工作。 |
| [^7] | [Selective Data Augmentation for Robust Speech Translation.](http://arxiv.org/abs/2304.03169) | 本文提出了一种针对英印ST的e2e架构，同时将两个不完美的机器翻译服务用于生成并行数据，并且提出了一种数据增强策略以提高鲁棒性，结果呈现出比基准方法更好的性能。 |
| [^8] | [Bridging the Language Gap: Knowledge Injected Multilingual Question Answering.](http://arxiv.org/abs/2304.03159) | 本文提出了一个跨越语言鸿沟的通用问答框架，通过知识注入帮助模型更好地理解不同语言问答之间的知识迁移。 |
| [^9] | [Zero-Shot Next-Item Recommendation using Large Pretrained Language Models.](http://arxiv.org/abs/2304.03153) | 本研究通过提出零样本下一个项目推荐策略，解决了使用大型预训练语言模型进行下一个项目推荐中遇到的挑战。 |
| [^10] | [Evaluating the Robustness of Machine Reading Comprehension Models to Low Resource Entity Renaming.](http://arxiv.org/abs/2304.03145) | 本研究探讨了MRC模型对低资源地区重命名实体的鲁棒性，提出了EntSwap扰动测试集的方法，发现大型模型具有较强的新实体适应性。 |
| [^11] | [Static Fuzzy Bag-of-Words: a lightweight sentence embedding algorithm.](http://arxiv.org/abs/2304.03098) | 本文提出了一种静态模糊词袋模型，可提供预定义维度的句子嵌入。该模型在语义文本相似性基准测试中表现出竞争力，并要求低计算资源。 |
| [^12] | [Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media.](http://arxiv.org/abs/2304.03087) | 本文研究了利用ChatGPT进行立场检测中，无参数的思维链（CoT）方法的有效性，证明其表现优越，并探讨了相关挑战。 |
| [^13] | [ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model.](http://arxiv.org/abs/2304.03086) | 本文讨论了利用LLMs在牙科临床领域实现自动化和跨模态诊断的可能性，介绍了利用跨模态编码器进行高级自然语言推理的多模态LLM AI系统，展示了其在牙科临床中的巨大潜力。 |
| [^14] | [ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments.](http://arxiv.org/abs/2304.03047) | ETPNav是一个能够在连续环境中进行视觉语言导航的新导航框架，它具有两个关键技能：能够抽象环境与生成长程导航计划以及在连续环境中避障控制的能力。ETPNav使用演化算法优化拓扑规划模块并在Matterport3D模拟器上实现了最先进的性能，达到了人类水平的VLN-CE任务性能。 |
| [^15] | [Compression of enumerations and gain.](http://arxiv.org/abs/2304.03030) | 本文研究了枚举的可压缩性对于计算可枚举集合的相对Kolmogorov复杂度的影响，并证明了任何计算可枚举集合都可以进行强压缩和无增益弱压缩。 |
| [^16] | [Natural Language Robot Programming: NLP integrated with autonomous robotic grasping.](http://arxiv.org/abs/2304.02993) | 本文提出了一种基于语法的自然语言机器人编程框架，并通过模拟和实际实验验证了其高可用性，用于规定pick-and-place任务的joint space trajectories。该框架使用自定义词典，可以轻松扩展，并且无需依赖于大型数据集或迁移学习。 |
| [^17] | [Leveraging Social Interactions to Detect Misinformation on Social Media.](http://arxiv.org/abs/2304.02983) | 该论文针对社交媒体上的虚假信息检测问题，结合社交信息和文本特征，利用深度神经网络进行多输入模型，实现了对信息传播的早期阶段的有效检测。 |
| [^18] | [Multi-label classification of open-ended questions with BERT.](http://arxiv.org/abs/2304.02945) | 本研究针对多标签的问卷答案进行分类研究，从试验结果中发现基于转换器的架构BERT相较传统算法在分类效果上更加优秀。 |
| [^19] | [SpanRE: Entities and Overlapping Relations Extraction Based on Spans and Entity Attention.](http://arxiv.org/abs/2304.02901) | 本研究提出了一种称作SpanRE的实体和重叠关系提取方法，运用标准span机制提取候选主题，然后结合实体关注机制和带标签的span机制从句子中提取对象和关系。在两个公共数据集上的测试表明该方法取得了最佳性能。 |
| [^20] | [Affect as a proxy for literary mood.](http://arxiv.org/abs/2304.02894) | 该研究提出使用情感作为文学文本情绪的代理，并能通过扩展情感词典在考虑文本语义转移和领域的前提下，提供近期和现代分析的实际可行结果。 |
| [^21] | [Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts.](http://arxiv.org/abs/2304.02886) | 本文针对法语临床文本自动关联ICD代码的问题，提出了一种基于最新自然语言处理和多标签分类技术的模型，相比于现有技术结果，F1分数提高了55％以上。 |
| [^22] | [Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions.](http://arxiv.org/abs/2304.02868) | 本文探究大型语言模型在玩文字游戏的能力，并发现其表现有竞争力，但仍然缺乏智能，有待提升。 |
| [^23] | [GPT detectors are biased against non-native English writers.](http://arxiv.org/abs/2304.02819) | 该研究发现，GPT检测器对非英语母语作者存在偏见，容易将其内容错误地分类为AI生成的内容。此外，简单的提示策略可以缓解这种偏见，同时规避GPT检测器，这表明GPT检测器可能会惩罚具有受限语言表达能力的作者。 |
| [^24] | [Pragmatically Appropriate Diversity for Dialogue Evaluation.](http://arxiv.org/abs/2304.02812) | 论文提出了实用适当性多样性的概念，这是一个用于评估对话多样性的新方法。研究使用人类创建的数据集证明了基本语言行为提供了多个下一步响应的多样性信号。同时，作者提出了一个新的评估任务，使用创意作家来评判多样性的程度，并且实用适当性多样性被证明是比现有方法更好的衡量对话质量的指标。 |
| [^25] | [Context-Aware Classification of Legal Document Pages.](http://arxiv.org/abs/2304.02787) | 本文提出一种新方法，使用额外的标记增强输入，引入循环，可以使用预训练的 Transformer 模型（如 BERT）进行上下文感知的法律文件页面分类。 |
| [^26] | [Performance of Data Augmentation Methods for Brazilian Portuguese Text Classification.](http://arxiv.org/abs/2304.02785) | 本文分析了不同的数据增强方法在巴西葡萄牙语文本分类中的表现，揭示了一些方法的改进之处，同时也指出了需要更多利用语言偏见和非英语文本数据的稀缺性。 |
| [^27] | [Application of Transformers based methods in Electronic Medical Records: A Systematic Literature Review.](http://arxiv.org/abs/2304.02768) | 这篇论文综述了基于Transformer的自然语言处理技术在电子病历领域中的应用，并提出了目前研究中的限制和未来研究的方向。 |
| [^28] | [The Saudi Privacy Policy Dataset.](http://arxiv.org/abs/2304.02757) | 本文介绍了由沙特阿拉伯不同领域的阿拉伯语隐私政策组成的数据集，该数据集根据个人数据保护法的10个原则进行了注释。该数据集可用于评估隐私政策遵守性、行业隐私实践基准测试以及开发监测数据保护法规遵守性的自动化工具。 |
| [^29] | [Behavioral estimates of conceptual structure are robust across tasks in humans but not large language models.](http://arxiv.org/abs/2304.02754) | 本研究使用两种经典认知心理学技术来估算人类和GPT-3等大型语言模型的词汇语义结构，结果表明人类的概念结构稳健鲁棒，而大型语言模型的行为估算结构更多取决于具体任务。 |
| [^30] | [Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP dalam bahasa Indonesia.](http://arxiv.org/abs/2304.02746) | 本文概述了印尼语自然语言处理技术的历史和发展，包括基础技术、实际应用和挑战。未来的研究应该拓展更有效率的方法和技术，并扩大NLP的应用范围。 |
| [^31] | [Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks.](http://arxiv.org/abs/2304.02739) | 本文研究使用半监督生成对抗网络以少量数据分类孟加拉语假评论和真实评论的潜力，并提出了BanglaBERT与半监督GAN相结合的解决方案，实验结果表明其准确率达到83.59％，f1分数达到84.89％。 |
| [^32] | [Core Challenges in Embodied Vision-Language Planning.](http://arxiv.org/abs/2304.02738) | 本文讨论了具身视觉语言规划（EVLP）任务领域的挑战和机会，旨在共同利用计算机视觉和自然语言进行物理环境交互。 |
| [^33] | [To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency.](http://arxiv.org/abs/2304.02721) | 本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。 |
| [^34] | [ParroT: Translating During Chat Using Large Language Models.](http://arxiv.org/abs/2304.02426) | ParroT提出了一种基于开源LLM和人工编写的翻译评估数据的聊天翻译框架，可以将翻译数据转化为指令执行样式，并引入额外要求来规范翻译过程。在使用相对较少的训练数据的情况下，实验结果表明 ParroT 可以大幅提高翻译质量。 |
| [^35] | [Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT.](http://arxiv.org/abs/2304.02213) | 本文介绍了一个新的自然语言处理任务——结构化信息推理（SIS），利用GPT-3模型能够准确提取材料科学设备层面的信息，并通过实验预测PCE和反向预测参数，展示了大型语言模型在材料学中的巨大潜力。 |
| [^36] | [Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing.](http://arxiv.org/abs/2304.02017) | 本文全面探讨了ChatGPT在自然语言处理中的应用、优点和局限性，强调了使用这个强大工具时的道德考虑，为人工智能和NLP领域的讨论做出了贡献。 |
| [^37] | [RPTQ: Reorder-based Post-training Quantization for Large Language Models.](http://arxiv.org/abs/2304.01089) | 本研究提出了一种新的基于重排的量化方法RPTQ，目的是解决大型语言模型在量化时由于信道激活范围不同而产生的问题。实现该方法后，我们将LLL模型推动到3位激活。 |
| [^38] | [ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance.](http://arxiv.org/abs/2303.16894) | 本文提出了ViewRefer，这是一个多视角的三维视觉定位框架，利用大规模语言模型和多视角原型，从文本和3D模态中获取视角知识并增强框架的表现。 |
| [^39] | [Task-oriented Memory-efficient Pruning-Adapter.](http://arxiv.org/abs/2303.14704) | 本文提出了一种面向任务的剪枝适配器方法，既实现了训练和内存的高效率，又加快了训练时间，并且在 GLUE 任务中没有显著降低准确性。 |
| [^40] | [Return of the RNN: Residual Recurrent Networks for Invertible Sentence Embeddings.](http://arxiv.org/abs/2303.13570) | 本研究提出了一种使用残差循环神经网络的新型模型，实现了可逆的句子嵌入。与其他神经机器翻译模型不同，该方法使用基于回归的输出层重建输入序列的单词向量，其具有高准确度和快速训练速度。这种方法适合各种自然语言处理应用，特别是对需要高质量句嵌入的神经网络系统的使用具有潜在优势。 |
| [^41] | [Zero-Shot Cross-Lingual Summarization via Large Language Models.](http://arxiv.org/abs/2302.14229) | 本文实验性地使用各种提示来指导大型语言模型从不同的范式执行零样本跨语言摘要，并成功提高了它们的CLS性能。其中，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。 |
| [^42] | [Dataless Knowledge Fusion by Merging Weights of Language Models.](http://arxiv.org/abs/2212.09849) | 本文提出了一种无数据知识融合方法，可以合并在不同训练数据集上建立的单个模型，以得到一个在所有数据集领域上表现良好且可以推广到域外数据的单一模型。 |
| [^43] | [From exemplar to copy: the scribal appropriation of a Hadewijch manuscript computationally explored.](http://arxiv.org/abs/2210.14061) | 本文研究了中世纪神秘作家Hadewijch的手稿副本之间微妙的语言变化和抄写者的拼写惯例差异，并运用计算分析方法进行了探究。 |
| [^44] | [Toxicity in Multilingual Machine Translation at Scale.](http://arxiv.org/abs/2210.03070) | 本文研究了在大规模多语言机器翻译中一种关键错误类型——添加毒性。自动和人工评估均表明低资源语言和特定人口统计轴，如性取向、性别和能力等，往往会出现更多的毒性。为了更好地解释这些结果，我们使用了度量翻译源贡献量的方法。 |
| [^45] | [Sparse*BERT: Sparse Models Generalize To New tasks and Domains.](http://arxiv.org/abs/2205.12452) | 本文研究了使用渐进非结构化幅值修剪进行修剪的模型如何在领域和任务之间进行转移。使用遮蔽语言模型进行预训练的被修剪模型能够在不进行广泛的超参数探索或专门方法的情况下转移到新的领域和任务。在生物医学NLP任务中，Sparse*BERT可以达到或超过BioBERT的性能。 |
| [^46] | [Term Rewriting Based On Set Automaton Matching.](http://arxiv.org/abs/2202.08687) | 本文描述了如何利用集合自动机构造重写系统的左侧，从而高效查找术语中的所有红块，并提供了一个在最外层重写下具有竞争力的有效实现方法。 |

# 详细

[^1]: 奖励是否合理？在 MACHIAVELLI 基准测试中衡量奖励与道德行为之间的权衡

    Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark. (arXiv:2304.03279v1 [cs.LG])

    [http://arxiv.org/abs/2304.03279](http://arxiv.org/abs/2304.03279)

    本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。

    

    传统上，人工智能代理被训练成最大化奖励，这可能会激励追求权力和欺骗行为，类似于语言模型中的下一个标记预测可能会激励有害行为。那么代理是否自然而然地学会了马基雅维利行为？我们如何在 GPT-4 等通用模型中衡量这些行为呢？为回答这些问题，我们引入了 MACHIAVELLI 基准测试，该测试涵盖了超过一百万个多样化的情景，重点关注社会决策制定，用于衡量人工代理是否表现出马基雅维利行为。我们数学化了数十种有害行为，并使用我们的注释来评估代理倾向于追求权力，造成功能不良和违反伦理的倾向。我们观察到最大化奖励和行为的道德性之间存在一些紧张关系。为了改善这种权衡，我们研究了基于语言模型的方法，以使代理趋向于采取更少的有害行为。我们的结果显示，MACHIAVELLI 是评估人工代理马基雅维利行为水平的有用基准测试。

    Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making. Scenario labeling is automated with LMs, which are more performant than human annotators. We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations. We observe some tension between maximizing reward and behaving ethically. To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors. Our results sh
    
[^2]: GPT-4指令调优

    Instruction Tuning with GPT-4. (arXiv:2304.03277v1 [cs.CL])

    [http://arxiv.org/abs/2304.03277](http://arxiv.org/abs/2304.03277)

    本文提出使用GPT-4生成指令遵循数据进行LLM微调，实验表明GPT-4所生成的指令数据优于以往最先进模型生成的数据，在新任务中表现卓越。

    

    先前的工作表明，使用机器生成的指令遵循数据对大型语言模型（LLM）进行微调可以使这些模型在新任务上实现显著的零-shot能力，不需要人类编写的指令。在本文中，我们首次尝试使用GPT-4生成指令遵循数据进行LLM微调。我们在指令调优的LLaMA模型上进行的早期实验表明，GPT-4生成的52K英语和中文指令遵循数据优于以前最先进模型生成的指令遵循数据，可以在新任务中实现卓越的零-shot表现。我们还收集了来自GPT-4的反馈和比较数据，以实现全面的评估和奖励模型训练。我们公开提供了使用GPT-4生成的数据以及我们的代码库。

    Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed. In this paper, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning. Our early experiments on instruction-tuned LLaMA models show that the 52K English and Chinese instruction-following data generated by GPT-4 leads to superior zero-shot performance on new tasks to the instruction-following data generated by previous state-of-the-art models. We also collect feedback and comparison data from GPT-4 to enable a comprehensive evaluation and reward model training. We make our data generated using GPT-4 as well as our codebase publicly available.
    
[^3]: 大型语言模型在文学翻译中高效利用文档级上下文，但关键错误仍然存在

    Large language models effectively leverage document-level context for literary translation, but critical errors persist. (arXiv:2304.03245v1 [cs.CL])

    [http://arxiv.org/abs/2304.03245](http://arxiv.org/abs/2304.03245)

    该研究通过人工评估发现，大型语言模型在进行文学段落翻译时会利用更多的文档级上下文，从而减少关键错误。然而，一些与上下文和意义相关的错误仍然存在。

    

    大型语言模型（LLMs）在许多句子级别的翻译数据集上与现有技术水平相当。然而，它们在段落和文档翻译方面的能力尚未得到探究，因为这些环境下的评估代价高且困难。通过一项严谨的人工评估，我们展示了要求Gpt-3.5（text-davinci-003）LLM将整个文学段落（例如，从小说中）进行翻译的结果比标准的逐句翻译在18个语言对（例如，日语、波兰语和英语的翻译）上产生更高质量的翻译。我们的评估需要约350个小时的注释和分析工作，通过聘请熟练掌握源语言和目标语言的译者，并要求他们提供跨度级别的错误注释以及哪种系统的翻译更好的偏好判断。我们观察到，篇章级别的LLM翻译在文学段落的翻译中出现的关键错误更少，但仍存在一些与上下文和意义相关的错误。

    Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer 
    
[^4]: FedBot：利用联邦学习增强聊天机器人的隐私保护

    FedBot: Enhancing Privacy in Chatbots with Federated Learning. (arXiv:2304.03228v1 [cs.CL])

    [http://arxiv.org/abs/2304.03228](http://arxiv.org/abs/2304.03228)

    本论文提出了一个利用联邦学习保护用户隐私的聊天机器人FedBot。它结合了Deep Bidirectional Transformer模型和联邦学习算法，在联合模型训练过程中保护客户数据隐私。

    

    聊天机器人主要依赖于包含敏感信息的话语的数据推动，但是在共享数据上训练深度学习模型可能会侵犯用户隐私。本文提出FedBot，一个利用大规模客户支持数据实现隐私保护的聊天机器人的概念验证，它结合了Deep Bidirectional Transformer模型和联邦学习算法，在联合模型训练过程中保护客户数据隐私。概念验证的结果展示了隐私保护聊天机器人能够通过改变客户支持行业的潜力。

    Chatbots are mainly data-driven and usually based on utterances that might be sensitive. However, training deep learning models on shared data can violate user privacy. Such issues have commonly existed in chatbots since their inception. In the literature, there have been many approaches to deal with privacy, such as differential privacy and secure multi-party computation, but most of them need to have access to users' data. In this context, Federated Learning (FL) aims to protect data privacy through distributed learning methods that keep the data in its location. This paper presents Fedbot, a proof-of-concept (POC) privacy-preserving chatbot that leverages large-scale customer support data. The POC combines Deep Bidirectional Transformer models and federated learning algorithms to protect customer data privacy during collaborative model training. The results of the proof-of-concept showcase the potential for privacy-preserving chatbots to transform the customer support industry by de
    
[^5]: 关于多语言神经机器翻译的Pareto前沿研究

    On the Pareto Front of Multilingual Neural Machine Translation. (arXiv:2304.03216v1 [cs.CL])

    [http://arxiv.org/abs/2304.03216](http://arxiv.org/abs/2304.03216)

    本研究针对多语言神经机器翻译的数据不平衡问题，提出双重幂律方法用于预测独特的性能权衡前沿，并建立基于该方法的样本比例选择优化问题，取得更好的结果。

    

    本研究探讨了在多语言神经机器翻译中，给定方向的泛化性能如何随其采样比例的变化而变化。通过训练200多个具有不同模型大小、方向和总任务数量的多语言模型，我们发现在训练语料库存在数据不平衡时，标量化导致了一个多任务权衡前沿，该前沿偏离了传统的Pareto前沿。基于我们的观察，我们提出了双重幂律来预测MNMT中独特的性能权衡前沿，该方法在各种语言、数据充足性和任务数量方面都很鲁棒。最后，我们将MNMT中的样本比例选择问题建模为基于双重幂律的优化问题，取得了更好的结果。

    In this work, we study how the generalization performance of a given direction changes with its sampling ratio in Multilingual Neural Machine Translation (MNMT). By training over 200 multilingual models with various model sizes, directions, and total numbers of tasks, we find that scalarization leads to a multitask trade-off front that deviates from the traditional Pareto front when there exists data imbalance in the training corpus. That is, the performance of certain translation directions does not improve with the increase of its weight in the multi-task optimization objective, which poses greater challenge to improve the overall performance of all directions. Based on our observations, we propose the Double Power Law to predict the unique performance trade-off front in MNMT, which is robust across various languages, data adequacy and number of tasks. Finally, we formulate sample ratio selection in MNMT as an optimization problem based on the Double Power Law, which achieves better 
    
[^6]: 基于 Cerebras Wafer-Scale Cluster 的开放计算优化语言模型 Cerebras-GPT 的研究

    Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster. (arXiv:2304.03208v1 [cs.LG])

    [http://arxiv.org/abs/2304.03208](http://arxiv.org/abs/2304.03208)

    本论文介绍了从111M到13B参数的开放计算优化语言模型 Cerebras-GPT，它采用了高效的预训练方法和缩放规则，具有最先进的训练效率和可预测性，这是一个开放可复现的工作。

    

    本文研究了最近改善大型语言模型的有效预训练和扩展以及开放数据集和工具的研究进展。同时结合这些进展，介绍了一系列从111M到13B参数的开放计算优化语言模型 Cerebras-GPT。我们根据 DeepMind 的 Chinchilla 缩放规则对 Eleuther Pile 数据集进行训练，达到了在给定计算预算下最高精度的高效预训练。我们表征了可预测的幂律缩放规律，并与其他公开可用模型进行比较，展示了 Cerebras-GPT 具有最先进的预训练和下游目标训练效率。我们描述了我们的发现，包括最大更新参数化($\mu$P)如何进一步提高大型模型扩展的精度和超参数可预测性。我们发布了预训练模型和代码，使本文成为关于在亿级参数规模下比较计算优化语言模型的首个开放可复现的工作。

    We study recent research advances that improve large language models through efficient pre-training and scaling, and open datasets and tools. We combine these advances to introduce Cerebras-GPT, a family of open compute-optimal language models scaled from 111M to 13B parameters. We train Cerebras-GPT models on the Eleuther Pile dataset following DeepMind Chinchilla scaling rules for efficient pre-training (highest accuracy for a given compute budget). We characterize the predictable power-law scaling and compare Cerebras-GPT with other publicly-available models to show all Cerebras-GPT models have state-of-the-art training efficiency on both pre-training and downstream objectives. We describe our learnings including how Maximal Update Parameterization ($\mu$P) can further improve large model scaling, improving accuracy and hyperparameter predictability at scale. We release our pre-trained models and code, making this paper the first open and reproducible work comparing compute-optimal 
    
[^7]: 针对鲁棒语音翻译的选择性数据增强

    Selective Data Augmentation for Robust Speech Translation. (arXiv:2304.03169v1 [cs.CL])

    [http://arxiv.org/abs/2304.03169](http://arxiv.org/abs/2304.03169)

    本文提出了一种针对英印ST的e2e架构，同时将两个不完美的机器翻译服务用于生成并行数据，并且提出了一种数据增强策略以提高鲁棒性，结果呈现出比基准方法更好的性能。

    

    语音翻译系统将一种语言的语音转化为另一种语言的文字。端到端（e2e）语音翻译系统由于具有减少延迟和计算成本的优越性能而比串联系统受到欢迎。虽然资源密集型，但e2e-ST系统具有保留语音的参数和非语言特征的内在能力，与串联系统不同。本文提出使用e2e架构来进行英印（en-hi）ST。我们使用两个不完美的机器翻译服务将Libri-trans en文本翻译成hi文本。虽然每个服务都会单独提供MT数据以生成并行ST数据，但我们提出了一种噪声MT数据的数据增强策略来帮助鲁棒ST。本文的主要贡献是提出了一种数据增强策略。我们表明，这导致比强力MT数据增强更好的ST（BLEU得分）。我们观察到我们的方法比基准方法提高了1.59 BLEU得分。

    Speech translation (ST) systems translate speech in one language to text in another language. End-to-end ST systems (e2e-ST) have gained popularity over cascade systems because of their enhanced performance due to reduced latency and computational cost. Though resource intensive, e2e-ST systems have the inherent ability to retain para and non-linguistic characteristics of the speech unlike cascade systems. In this paper, we propose to use an e2e architecture for English-Hindi (en-hi) ST. We use two imperfect machine translation (MT) services to translate Libri-trans en text into hi text. While each service gives MT data individually to generate parallel ST data, we propose a data augmentation strategy of noisy MT data to aid robust ST. The main contribution of this paper is the proposal of a data augmentation strategy. We show that this results in better ST (BLEU score) compared to brute force augmentation of MT data. We observed an absolute improvement of 1.59 BLEU score with our appr
    
[^8]: 跨越语言鸿沟：注入知识的多语言问答

    Bridging the Language Gap: Knowledge Injected Multilingual Question Answering. (arXiv:2304.03159v1 [cs.CL])

    [http://arxiv.org/abs/2304.03159](http://arxiv.org/abs/2304.03159)

    本文提出了一个跨越语言鸿沟的通用问答框架，通过知识注入帮助模型更好地理解不同语言问答之间的知识迁移。

    

    问答（QA）是一种自动回答人类自然语言问题的任务。提取式问答任务（Extractive QA）已经成为自然语言处理任务中备受关注的一个重要方向。与此同时，随着世界的不断发展，不同语言间的通用跨语言转移（G-XLT）带来了跨语言转移（XLT）无法解决的一些独特挑战。本文提出了一个通用的G-XLT框架，通过知识注入的方式，丰富模型对不同语言问答中的知识迁移的理解，从而为实现跨语言的QA任务提供了一些新思路。

    Question Answering (QA) is the task of automatically answering questions posed by humans in natural languages. There are different settings to answer a question, such as abstractive, extractive, boolean, and multiple-choice QA. As a popular topic in natural language processing tasks, extractive question answering task (extractive QA) has gained extensive attention in the past few years. With the continuous evolvement of the world, generalized cross-lingual transfer (G-XLT), where question and answer context are in different languages, poses some unique challenges over cross-lingual transfer (XLT), where question and answer context are in the same language. With the boost of corresponding development of related benchmarks, many works have been done to improve the performance of various language QA tasks. However, only a few works are dedicated to the G-XLT task. In this work, we propose a generalized cross-lingual transfer framework to enhance the model's ability to understand different
    
[^9]: 利用大型预训练语言模型进行零样本下一个项目推荐

    Zero-Shot Next-Item Recommendation using Large Pretrained Language Models. (arXiv:2304.03153v1 [cs.IR])

    [http://arxiv.org/abs/2304.03153](http://arxiv.org/abs/2304.03153)

    本研究通过提出零样本下一个项目推荐策略，解决了使用大型预训练语言模型进行下一个项目推荐中遇到的挑战。

    

    大型语言模型（LLM）在各种自然语言处理（NLP）任务中取得了令人印象深刻的零样本表现，展示了它们在没有训练示例的情况下进行推理的能力。尽管取得了成功，但尚未有研究探索LLMs在零样本情况下执行下一个项目推荐的潜力。作者们确定了必须解决的两个主要问题，以使LLMs有效地充当推荐者。

    Large language models (LLMs) have achieved impressive zero-shot performance in various natural language processing (NLP) tasks, demonstrating their capabilities for inference without training examples. Despite their success, no research has yet explored the potential of LLMs to perform next-item recommendations in the zero-shot setting. We have identified two major challenges that must be addressed to enable LLMs to act effectively as recommenders. First, the recommendation space can be extremely large for LLMs, and LLMs do not know about the target user's past interacted items and preferences. To address this gap, we propose a prompting strategy called Zero-Shot Next-Item Recommendation (NIR) prompting that directs LLMs to make next-item recommendations. Specifically, the NIR-based strategy involves using an external module to generate candidate items based on user-filtering or item-filtering. Our strategy incorporates a 3-step prompting that guides GPT-3 to carry subtasks that captur
    
[^10]: 评估机器阅读理解模型对低资源实体重命名的鲁棒性

    Evaluating the Robustness of Machine Reading Comprehension Models to Low Resource Entity Renaming. (arXiv:2304.03145v1 [cs.CL])

    [http://arxiv.org/abs/2304.03145](http://arxiv.org/abs/2304.03145)

    本研究探讨了MRC模型对低资源地区重命名实体的鲁棒性，提出了EntSwap扰动测试集的方法，发现大型模型具有较强的新实体适应性。

    

    问答（QA）模型在机器阅读理解（MRC）任务中取得了令人信服的结果。最近，这些模型已经证明在如SQuAD等数据集的测试集上表现优于人类，但它们的稳健性并不保证。当使用对抗生成的示例进行评估时，QA模型的脆弱性会暴露出来，表现出性能下降。在本研究中，我们探讨了MRC模型对来自低资源地区（如非洲）的实体重命名的鲁棒性。我们提出了EntSwap，一种测试时扰动方法，用于创建一个实体已被重命名的测试集。特别地，我们重命名类型为国家，人物，国籍，位置，组织和城市的实体，以创建AfriSQuAD2。使用扰动测试集，我们评估了三种流行的MRC模型的鲁棒性。我们发现，与基准模型相比，大模型在新实体上表现良好。此外，我们的分析表明，人名实体类型具有高度的特异性和不确定性。

    Question answering (QA) models have shown compelling results in the task of Machine Reading Comprehension (MRC). Recently these systems have proved to perform better than humans on held-out test sets of datasets e.g. SQuAD, but their robustness is not guaranteed. The QA model's brittleness is exposed when evaluated on adversarial generated examples by a performance drop. In this study, we explore the robustness of MRC models to entity renaming, with entities from low-resource regions such as Africa. We propose EntSwap, a method for test-time perturbations, to create a test set whose entities have been renamed. In particular, we rename entities of type: country, person, nationality, location, organization, and city, to create AfriSQuAD2. Using the perturbed test set, we evaluate the robustness of three popular MRC models. We find that compared to base models, large models perform well comparatively on novel entities. Furthermore, our analysis indicates that entity type person highly cha
    
[^11]: 静态模糊词袋：一种轻量级句子嵌入算法

    Static Fuzzy Bag-of-Words: a lightweight sentence embedding algorithm. (arXiv:2304.03098v1 [cs.CL])

    [http://arxiv.org/abs/2304.03098](http://arxiv.org/abs/2304.03098)

    本文提出了一种静态模糊词袋模型，可提供预定义维度的句子嵌入。该模型在语义文本相似性基准测试中表现出竞争力，并要求低计算资源。

    

    嵌入技术的引入显著推动了自然语言处理领域的发展。许多提出的解决方案都是针对单词级别的编码。然而，在过去的几年中，出现了一些新的机制来处理更高层次的信息处理，例如句子和文档级别。本文专门讨论句子嵌入问题，提出了静态模糊词袋模型。我们的模型是模糊词袋方法的一种改进，针对预定义维度提供句子嵌入。SFBoW在语义文本相似性基准测试中表现竞争力，同时要求低计算资源。

    The introduction of embedding techniques has pushed forward significantly the Natural Language Processing field. Many of the proposed solutions have been presented for word-level encoding; anyhow, in the last years, new mechanism to treat information at an higher level of aggregation, like at sentence- and document-level, have emerged. With this work we address specifically the sentence embeddings problem, presenting the Static Fuzzy Bag-of-Word model. Our model is a refinement of the Fuzzy Bag-of-Words approach, providing sentence embeddings with a predefined dimension. SFBoW provides competitive performances in Semantic Textual Similarity benchmarks, while requiring low computational resources.
    
[^12]: 利用ChatGPT探究思维链在社交媒体中的立场检测

    Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media. (arXiv:2304.03087v1 [cs.CL])

    [http://arxiv.org/abs/2304.03087](http://arxiv.org/abs/2304.03087)

    本文研究了利用ChatGPT进行立场检测中，无参数的思维链（CoT）方法的有效性，证明其表现优越，并探讨了相关挑战。

    

    立场检测是预测文本中针对目标的态度，随着社交媒体的兴起已受到关注。传统方法包括传统机器学习、早期深度神经网络和预训练微调模型。然而，随着非常大的预训练语言模型（VLPLMs）如ChatGPT（GPT-3.5）的发展，传统方法面临部署挑战。不需要反向传播训练的无参数思维链（CoT）方法已成为一种有希望的替代方法。本文研究了CoT在立场检测任务中的有效性，展示了其优越的精度并讨论了相关的挑战。

    Stance detection predicts attitudes towards targets in texts and has gained attention with the rise of social media. Traditional approaches include conventional machine learning, early deep neural networks, and pre-trained fine-tuning models. However, with the evolution of very large pre-trained language models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face deployment challenges. The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative. This paper examines CoT's effectiveness in stance detection tasks, demonstrating its superior accuracy and discussing associated challenges.
    
[^13]: ChatGPT塑造牙科未来：多模态大语言模型的潜力

    ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model. (arXiv:2304.03086v1 [cs.CL])

    [http://arxiv.org/abs/2304.03086](http://arxiv.org/abs/2304.03086)

    本文讨论了利用LLMs在牙科临床领域实现自动化和跨模态诊断的可能性，介绍了利用跨模态编码器进行高级自然语言推理的多模态LLM AI系统，展示了其在牙科临床中的巨大潜力。

    

    ChatGPT是OpenAI开发的Generative Pretrained Transformer 4（GPT-4）的精简和对话变体，具有数十亿个参数的里程碑式大语言模型之一。事实上，LLMs在自然语言处理任务中展现出的印象深刻能力引起了研究人员和实践者的极大兴趣，对各个领域产生了深远的影响。本文主要讨论LLMs在牙科领域的未来应用。我们介绍了两种主要的LLM部署方法，包括自动牙科诊断和跨模态牙科诊断，并探讨了它们的潜在应用。特别地，配备跨模态编码器，单个LLM可以管理多源数据并进行高级自然语言推理，以执行复杂的临床操作。通过一个案例来展示针对牙科临床应用的完全自动化的多模态LLM AI系统的潜力。虽然LLMs在提供巨大的潜力方面取得了显著的进展，

    The ChatGPT, as a lite and conversational variant of Generative Pretrained Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large Language Models (LLMs) with billions of parameters. LLMs, in fact, have stirred up a lot of interest among researchers and practitioners by their impressive skills in natural language processing tasks, which have a profound impact on a wide range of fields. This paper mainly discusses the future applications of LLMs in dentistry. We introduce two primary LLM deployment methods in dentistry, including automated dental diagnosis and cross-modal dental diagnosis, and examine their potential applications. Especially, equipped with a cross-modal encoder, a single LLM can manage multi-source data and conduct advanced natural language reasoning to perform complex clinical operations. A use case is presented to demonstrate the potential of a fully automatic Multi-Modal LLM AI system for dentistry clinical application. While LLMs offer significant p
    
[^14]: ETPNav: 在连续环境中演化拓扑规划的视觉语言导航

    ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments. (arXiv:2304.03047v1 [cs.CV])

    [http://arxiv.org/abs/2304.03047](http://arxiv.org/abs/2304.03047)

    ETPNav是一个能够在连续环境中进行视觉语言导航的新导航框架，它具有两个关键技能：能够抽象环境与生成长程导航计划以及在连续环境中避障控制的能力。ETPNav使用演化算法优化拓扑规划模块并在Matterport3D模拟器上实现了最先进的性能，达到了人类水平的VLN-CE任务性能。

    

    视觉语言导航需要智能体遵循指示在环境中导航，该任务在体验式人工智能领域中具有潜在应用，如自治导航、搜索与救援和人机交互。本文提出了一个更为实用但具有挑战性的情景 - 在连续环境中进行视觉语言导航（VLN-CE）。为了开发一个强大的VLN-CE代理，我们提出了一个新的导航框架ETPNav，它专注于两个关键技能：1）抽象环境和生成长程导航计划的能力；和2）在连续环境中避障控制的能力。ETPNav通过自组织沿着经过的路径预测的路标进行在线环境拓扑映射，而不需要先前的环境经验。它将导航过程分解为高层规划和低层控制。同时，ETPNav使用一种新颖的演化算法来优化拓扑规划模块，以实现有效的长期导航计划。所提出的方法在Matterport3D模拟器上实现了最先进的性能，并在任意起点和终点的VLN-CE任务中达到了人类水平的性能。

    Vision-language navigation is a task that requires an agent to follow instructions to navigate in environments. It becomes increasingly crucial in the field of embodied AI, with potential applications in autonomous navigation, search and rescue, and human-robot interaction. In this paper, we propose to address a more practical yet challenging counterpart setting - vision-language navigation in continuous environments (VLN-CE). To develop a robust VLN-CE agent, we propose a new navigation framework, ETPNav, which focuses on two critical skills: 1) the capability to abstract environments and generate long-range navigation plans, and 2) the ability of obstacle-avoiding control in continuous environments. ETPNav performs online topological mapping of environments by self-organizing predicted waypoints along a traversed path, without prior environmental experience. It privileges the agent to break down the navigation procedure into high-level planning and low-level control. Concurrently, ET
    
[^15]: 枚举压缩与增益

    Compression of enumerations and gain. (arXiv:2304.03030v1 [cs.CL])

    [http://arxiv.org/abs/2304.03030](http://arxiv.org/abs/2304.03030)

    本文研究了枚举的可压缩性对于计算可枚举集合的相对Kolmogorov复杂度的影响，并证明了任何计算可枚举集合都可以进行强压缩和无增益弱压缩。

    

    我们研究了枚举的可压缩性，以及其在计算可枚举集合的相对Kolmogorov复杂度中密度方面的作用。我们关注了强压缩和弱压缩，以及压缩枚举中嵌入的附加信息的数量：增益。我们证明了任何计算可枚举集合都可以进行强压缩和无增益弱压缩，并研究了位置游戏以理解强无增益压缩。

    We study the compressibility of enumerations, and its role in the relative Kolmogorov complexity of computably enumerable sets, with respect to density. With respect to a strong and a weak form of compression, we examine the gain: the amount of auxiliary information embedded in the compressed enumeration. Strong compression and weak gainless compression is shown for any computably enumerable set, and a positional game is studied toward understanding strong gainless compression.
    
[^16]: 自然语言机器人编程：将NLP与自主机器人抓取集成

    Natural Language Robot Programming: NLP integrated with autonomous robotic grasping. (arXiv:2304.02993v1 [cs.RO])

    [http://arxiv.org/abs/2304.02993](http://arxiv.org/abs/2304.02993)

    本文提出了一种基于语法的自然语言机器人编程框架，并通过模拟和实际实验验证了其高可用性，用于规定pick-and-place任务的joint space trajectories。该框架使用自定义词典，可以轻松扩展，并且无需依赖于大型数据集或迁移学习。

    

    本文提出了一种基于语法的自然语言机器人编程框架，特别用于拾取和放置任务。我们的方法使用自定义动作词典，设计了一种将共享意义的单词存储在一起的方式，从而通过从词汇数据库中添加更多动作词可以轻松扩展词汇量。我们使用搭载校准的手中相机和麦克风的Franka Panda机械臂，在模拟和实际实验中验证我们的自然语言机器人编程（NLRP）框架，要求参与者使用口头命令完成拾取和放置任务，将其转换为文本后通过NLRP框架处理，以获取机器人运动的关节空间轨迹。我们的结果表明，我们的方法具有很高的系统可用性评分。该框架的词典可以轻松扩展，无需依赖于迁移学习或大数据集。在未来，我们计划对不同的机器人平台和多个任务进行进一步验证。

    In this paper, we present a grammar-based natural language framework for robot programming, specifically for pick-and-place tasks. Our approach uses a custom dictionary of action words, designed to store together words that share meaning, allowing for easy expansion of the vocabulary by adding more action words from a lexical database. We validate our Natural Language Robot Programming (NLRP) framework through simulation and real-world experimentation, using a Franka Panda robotic arm equipped with a calibrated camera-in-hand and a microphone. Participants were asked to complete a pick-and-place task using verbal commands, which were converted into text using Google's Speech-to-Text API and processed through the NLRP framework to obtain joint space trajectories for the robot. Our results indicate that our approach has a high system usability score. The framework's dictionary can be easily extended without relying on transfer learning or large data sets. In the future, we plan to compar
    
[^17]: 利用社交互动检测社交媒体上的虚假信息

    Leveraging Social Interactions to Detect Misinformation on Social Media. (arXiv:2304.02983v1 [cs.CL])

    [http://arxiv.org/abs/2304.02983](http://arxiv.org/abs/2304.02983)

    该论文针对社交媒体上的虚假信息检测问题，结合社交信息和文本特征，利用深度神经网络进行多输入模型，实现了对信息传播的早期阶段的有效检测。

    

    检测虚假信息是确保社交媒体健康环境的关键。我们使用COVID-19流行期间创建的数据集解决了这个问题。它包含微弱标记为可靠或不可靠的信息级联推文，基于对信息源的先前评估。识别不可靠线程的模型通常依赖于文本特征。但是，可靠性不仅取决于文本内容，还取决于信息的发布者以及发布给谁。我们还利用网络信息。遵循同质性原则，我们假设互动的用户通常对相似的话题感兴趣，并传播类似的新闻，这些新闻通常是可靠的或不可靠的。我们测试了几种方法来学习级联内社交互动的表示，将它们与深度神经语言模型在多输入(MI)框架中结合起来。通过跟踪互动时间序列，我们提高了先前的最新水平，无论是使用纯文本分类器还是没有社交信息的多输入模型。我们展示了添加社交信息可以帮助超越其他解决方案，特别是在信息传播的早期阶段，在那里只有很少的推文可供分析。

    Detecting misinformation threads is crucial to guarantee a healthy environment on social media. We address the problem using the data set created during the COVID-19 pandemic. It contains cascades of tweets discussing information weakly labeled as reliable or unreliable, based on a previous evaluation of the information source. The models identifying unreliable threads usually rely on textual features. But reliability is not just what is said, but by whom and to whom. We additionally leverage on network information. Following the homophily principle, we hypothesize that users who interact are generally interested in similar topics and spreading similar kind of news, which in turn is generally reliable or not. We test several methods to learn representations of the social interactions within the cascades, combining them with deep neural language models in a Multi-Input (MI) framework. Keeping track of the sequence of the interactions during the time, we improve over previous state-of-th
    
[^18]: 基于BERT的开放式问题多标签分类研究

    Multi-label classification of open-ended questions with BERT. (arXiv:2304.02945v1 [stat.AP])

    [http://arxiv.org/abs/2304.02945](http://arxiv.org/abs/2304.02945)

    本研究针对多标签的问卷答案进行分类研究，从试验结果中发现基于转换器的架构BERT相较传统算法在分类效果上更加优秀。

    

    调查中的开放性问题具有重要价值，因为它们不会限制受访者的答案，从而避免偏见。然而，开放问题的答案是文本数据，更难分析。传统上，答案按照编码手册中指定的方式手动分类。大部分自动编码的工作都集中在单标签预测上，其中答案被分为一个标签。然而，需要多标签分类的开放式问题（即分配多个代码的问题）经常发生。本文针对社会科学调查中开放问卷调查的文本答案进行多标签分类研究。我们针对德语使用基于转换器的架构BERT进行性能评估，与传统的多标签算法（二进制相关性、标签幂集、ECC）进行比较，针对德国社会科学调查GLES Panel（N=17,584，55个标签）进行研究。我们发现，在BERT的分类下（强制至少一个标签），多标签文本问题的分类性能比传统算法更优秀。

    Open-ended questions in surveys are valuable because they do not constrain the respondent's answer, thereby avoiding biases. However, answers to open-ended questions are text data which are harder to analyze. Traditionally, answers were manually classified as specified in the coding manual. Most of the effort to automate coding has gone into the easier problem of single label prediction, where answers are classified into a single code. However, open-ends that require multi-label classification, i.e., that are assigned multiple codes, occur frequently. This paper focuses on multi-label classification of text answers to open-ended survey questions in social science surveys. We evaluate the performance of the transformer-based architecture BERT for the German language in comparison to traditional multi-label algorithms (Binary Relevance, Label Powerset, ECC) in a German social science survey, the GLES Panel (N=17,584, 55 labels). We find that classification with BERT (forcing at least one
    
[^19]: SpanRE: 基于Span和实体关注机制的实体和重叠关系提取

    SpanRE: Entities and Overlapping Relations Extraction Based on Spans and Entity Attention. (arXiv:2304.02901v1 [cs.CL])

    [http://arxiv.org/abs/2304.02901](http://arxiv.org/abs/2304.02901)

    本研究提出了一种称作SpanRE的实体和重叠关系提取方法，运用标准span机制提取候选主题，然后结合实体关注机制和带标签的span机制从句子中提取对象和关系。在两个公共数据集上的测试表明该方法取得了最佳性能。

    

    提取实体和关系是信息提取的基本任务。从一条句子中提取的三元组可能会有重叠。先前的方法没有解决重叠问题或解决了部分重叠问题。为了完全解决重叠问题，首先我们使用标准span机制提取候选主题。然后，我们提出了一种带标签的span机制，同时提取了对象和关系。我们使用带标签的span机制生成带标签的span，其起始和结束位置表示对象，标签对应于主题和对象的关系。此外，我们设计了实体关注机制，增强了在提取对象和关系期间主题和句子之间的信息融合。我们在两个公共数据集上测试了我们的方法，我们的方法在这两个数据集上取得了最好的性能。

    Extracting entities and relations is an essential task of information extraction. Triplets extracted from a sentence might overlap with each other. Previous methods either did not address the overlapping issues or solved overlapping issues partially. To tackle triplet overlapping problems completely, firstly we extract candidate subjects with a standard span mechanism. Then we present a labeled span mechanism to extract the objects and relations simultaneously, we use the labeled span mechanism to generate labeled spans whose start and end positions indicate the objects, and whose labels correspond to relations of subject and objects. Besides, we design an entity attention mechanism to enhance the information fusion between subject and sentence during extracting objects and relations. We test our method on two public datasets, our method achieves the best performances on these two datasets.
    
[^20]: 基于情感的文学情绪代理

    Affect as a proxy for literary mood. (arXiv:2304.02894v1 [cs.CL])

    [http://arxiv.org/abs/2304.02894](http://arxiv.org/abs/2304.02894)

    该研究提出使用情感作为文学文本情绪的代理，并能通过扩展情感词典在考虑文本语义转移和领域的前提下，提供近期和现代分析的实际可行结果。

    

    我们提出使用情感作为文学文本情绪的代理。在这项研究中，我们探讨了在计算情感与检测情绪之间的区别。从方法论的角度，我们利用情感词嵌入来观察不同文本段落中的情感分布。我们还提出了一种简单而有效的方法，用于增强情感词典，考虑了语义转移和文本领域，从而产生了与当代和现代定性分析密切匹配的现实世界一致的结果。

    We propose to use affect as a proxy for mood in literary texts. In this study, we explore the differences in computationally detecting tone versus detecting mood. Methodologically we utilize affective word embeddings to look at the affective distribution in different text segments. We also present a simple yet efficient and effective method of enhancing emotion lexicons to take both semantic shift and the domain of the text into account producing real-world congruent results closely matching both contemporary and modern qualitative analyses.
    
[^21]: 自动ICD-10编码关联：对法语临床文本的挑战性任务

    Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts. (arXiv:2304.02886v1 [cs.CL])

    [http://arxiv.org/abs/2304.02886](http://arxiv.org/abs/2304.02886)

    本文针对法语临床文本自动关联ICD代码的问题，提出了一种基于最新自然语言处理和多标签分类技术的模型，相比于现有技术结果，F1分数提高了55％以上。

    

    在医学研究中，自动将ICD代码与电子健康数据关联是一个众所周知的自然语言处理任务。最近几年，随着基于Transformer架构的预训练语言模型的出现，自然语言处理得到了显著的发展，主要应用于英文语言。本文针对法语文本自动关联ICD代码的问题，尝试使用多种神经网络架构来处理大量的输入标记和需要猜测的标签。我们提出了一种模型，将最新的自然语言处理和多标签分类技术应用于ICD-10编码关联方面。对于法语的临床数据集，公正实验表明，我们的方法使F1分数比现有技术结果提高了55％以上。

    Automatically associating ICD codes with electronic health data is a well-known NLP task in medical research. NLP has evolved significantly in recent years with the emergence of pre-trained language models based on Transformers architecture, mainly in the English language. This paper adapts these models to automatically associate the ICD codes. Several neural network architectures have been experimented with to address the challenges of dealing with a large set of both input tokens and labels to be guessed. In this paper, we propose a model that combines the latest advances in NLP and multi-label classification for ICD-10 code association. Fair experiments on a Clinical dataset in the French language show that our approach increases the $F_1$-score metric by more than 55\% compared to state-of-the-art results.
    
[^22]: 大型语言模型能否能够很好地玩文字游戏？现状和未来问题研究

    Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions. (arXiv:2304.02868v1 [cs.CL])

    [http://arxiv.org/abs/2304.02868](http://arxiv.org/abs/2304.02868)

    本文探究大型语言模型在玩文字游戏的能力，并发现其表现有竞争力，但仍然缺乏智能，有待提升。

    

    最近，诸如ChatGPT和GPT-4之类的大型语言模型展示了它们与人类用户通信的卓越能力。本技术报告旨在调查它们在玩文字游戏方面的能力，这要求玩家通过与游戏世界的对话来理解环境并对情况做出反应。我们的实验表明，与所有现有系统相比，ChatGPT表现出有竞争力，但仍然表现出较低的智能水平。确切地说，ChatGPT无法通过玩游戏或阅读游戏手册来构建世界模型；它可能无法利用它已经拥有的世界知识；它无法推断出随着游戏进展的每一步的目标。我们的结果在人工智能、机器学习和自然语言处理交叉领域开启了新的研究问题。

    Large language models (LLMs) such as ChatGPT and GPT-4 have recently demonstrated their remarkable abilities of communicating with human users. In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world. Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence. Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses. Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing.
    
[^23]: GPT检测器对非英语母语的作者存在偏见。

    GPT detectors are biased against non-native English writers. (arXiv:2304.02819v1 [cs.CL])

    [http://arxiv.org/abs/2304.02819](http://arxiv.org/abs/2304.02819)

    该研究发现，GPT检测器对非英语母语作者存在偏见，容易将其内容错误地分类为AI生成的内容。此外，简单的提示策略可以缓解这种偏见，同时规避GPT检测器，这表明GPT检测器可能会惩罚具有受限语言表达能力的作者。

    

    生成语言模型的快速推广带来了数字通信方面的实质性进展，同时也引发了AI生成内容潜在误用的担忧。虽然已经提出了许多检测方法来区分AI和人类生成的内容，但这些检测器的公平性和鲁棒性仍未得到充分探讨。在这项研究中，我们使用来自英语母语和非英语母语作者的写作样本评估了几种广泛使用的GPT检测器的性能表现。我们的研究发现，这些检测器持续将非英语母语的写作样本错误地分类为AI生成的内容，而原生写作样本则能够被准确识别。此外，我们证明了简单的提示策略不仅可以缓解这种偏见，而且还可以有效地规避GPT检测器，这表明GPT检测器可能无意中惩罚具有受限语言表达能力的作者。我们的研究结果呼吁进行更广泛的讨论。

    The rapid adoption of generative language models has brought about substantial advancements in digital communication, while simultaneously raising concerns regarding the potential misuse of AI-generated content. Although numerous detection methods have been proposed to differentiate between AI and human-generated content, the fairness and robustness of these detectors remain underexplored. In this study, we evaluate the performance of several widely-used GPT detectors using writing samples from native and non-native English writers. Our findings reveal that these detectors consistently misclassify non-native English writing samples as AI-generated, whereas native writing samples are accurately identified. Furthermore, we demonstrate that simple prompting strategies can not only mitigate this bias but also effectively bypass GPT detectors, suggesting that GPT detectors may unintentionally penalize writers with constrained linguistic expressions. Our results call for a broader conversati
    
[^24]: 对话评估中的实用适当性多样性

    Pragmatically Appropriate Diversity for Dialogue Evaluation. (arXiv:2304.02812v1 [cs.CL])

    [http://arxiv.org/abs/2304.02812](http://arxiv.org/abs/2304.02812)

    论文提出了实用适当性多样性的概念，这是一个用于评估对话多样性的新方法。研究使用人类创建的数据集证明了基本语言行为提供了多个下一步响应的多样性信号。同时，作者提出了一个新的评估任务，使用创意作家来评判多样性的程度，并且实用适当性多样性被证明是比现有方法更好的衡量对话质量的指标。

    

    语言语用学表明，对话中的基本语言行为可以限制每个回合中适当的响应类型。在生成对话回复时，神经对话代理难以产生不同的响应。目前，使用自动度量衡来评估对话的多样性，但基本语言行为并未考虑这些度量标准。为了解决这个问题，我们提出了实用适当性多样性的概念，这定义为一个对话中产生和限制多个不同响应的程度。使用人类创建的多个响应数据集，我们发现基本语言行为提供了多个下一步响应的多样性信号。在此基础上，我们提出了一个新的人类评估任务，即创意作家预测对话启发多种不同响应的程度。我们的研究发现，作家的判断与实用适当性多样性测量相一致，并且这个新的度量标准比当前的多样性度量标准更好地指示一个对话的质量。

    Linguistic pragmatics state that a conversation's underlying speech acts can constrain the type of response which is appropriate at each turn in the conversation. When generating dialogue responses, neural dialogue agents struggle to produce diverse responses. Currently, dialogue diversity is assessed using automatic metrics, but the underlying speech acts do not inform these metrics.  To remedy this, we propose the notion of Pragmatically Appropriate Diversity, defined as the extent to which a conversation creates and constrains the creation of multiple diverse responses. Using a human-created multi-response dataset, we find significant support for the hypothesis that speech acts provide a signal for the diversity of the set of next responses. Building on this result, we propose a new human evaluation task where creative writers predict the extent to which conversations inspire the creation of multiple diverse responses. Our studies find that writers' judgments align with the Pragmati
    
[^25]: 法律文件页面的上下文感知分类

    Context-Aware Classification of Legal Document Pages. (arXiv:2304.02787v1 [cs.CL])

    [http://arxiv.org/abs/2304.02787](http://arxiv.org/abs/2304.02787)

    本文提出一种新方法，使用额外的标记增强输入，引入循环，可以使用预训练的 Transformer 模型（如 BERT）进行上下文感知的法律文件页面分类。

    

    对于许多需要处理、索引和检索专业文档（如 PDF 格式等）的商业应用，将任何给定文档的页面分类为其相应类型通常是必要的。文档图像分类领域中大多数现有研究要么专注于单页文档，要么将文档中的多个页面独立处理。虽然近年来已经提出了一些技术来利用相邻页面的上下文信息来增强文档页面分类，但由于输入长度的限制，它们通常不能与大型预训练语言模型一起使用。本文提出了一种简单但有效的方法，克服了上述限制。具体而言，我们使用带有关于前一页的顺序信息的额外标记来增强输入，从而引入了循环，这使得可以使用预训练的 Transformer 模型（如 BERT）进行上下文感知的法律文件页面分类。

    For many business applications that require the processing, indexing, and retrieval of professional documents such as legal briefs (in PDF format etc.), it is often essential to classify the pages of any given document into their corresponding types beforehand. Most existing studies in the field of document image classification either focus on single-page documents or treat multiple pages in a document independently. Although in recent years a few techniques have been proposed to exploit the context information from neighboring pages to enhance document page classification, they typically cannot be utilized with large pre-trained language models due to the constraint on input length. In this paper, we present a simple but effective approach that overcomes the above limitation. Specifically, we enhance the input with extra tokens carrying sequential information about previous pages - introducing recurrence - which enables the usage of pre-trained Transformer models like BERT for context
    
[^26]: 数据增强方法在巴西葡萄牙语文本分类中的表现

    Performance of Data Augmentation Methods for Brazilian Portuguese Text Classification. (arXiv:2304.02785v1 [cs.CL])

    [http://arxiv.org/abs/2304.02785](http://arxiv.org/abs/2304.02785)

    本文分析了不同的数据增强方法在巴西葡萄牙语文本分类中的表现，揭示了一些方法的改进之处，同时也指出了需要更多利用语言偏见和非英语文本数据的稀缺性。

    

    提高机器学习性能，同时增加模型的泛化能力一直是人工智能研究人员不断追求的目标。数据增强技术通常被用于实现这一目标，而大多数评估都是使用英语语料库完成的。在这项工作中，我们利用不同的现有数据增强方法，分析其在使用巴西葡萄牙语语料库进行文本分类问题时的性能。结果表明，我们的分析显示了其中某些技术的可行改进；然而，它也表明需要进一步利用语言偏见和非英语文本数据的稀缺性。

    Improving machine learning performance while increasing model generalization has been a constantly pursued goal by AI researchers. Data augmentation techniques are often used towards achieving this target, and most of its evaluation is made using English corpora. In this work, we took advantage of different existing data augmentation methods to analyze their performances applied to text classification problems using Brazilian Portuguese corpora. As a result, our analysis shows some putative improvements in using some of these techniques; however, it also suggests further exploitation of language bias and non-English text data scarcity.
    
[^27]: 基于Transformer的方法在电子病历中的应用：系统性文献综述

    Application of Transformers based methods in Electronic Medical Records: A Systematic Literature Review. (arXiv:2304.02768v1 [cs.CL])

    [http://arxiv.org/abs/2304.02768](http://arxiv.org/abs/2304.02768)

    这篇论文综述了基于Transformer的自然语言处理技术在电子病历领域中的应用，并提出了目前研究中的限制和未来研究的方向。

    

    由于可用数据的增长和它们的非结构化性质，越来越多的自然语言处理（NLP）技术开始受到关注，以从这些数据资产中获得价值，因为这种格式不适用于统计分析。本文对不同NLP任务中基于变压器的EMR上的最新进展进行了系统性的文献综述。在最初的查询中，从三个公共数据库中选择了99篇文章，最终筛选得到了65篇文章进行详细分析。本文将从业务问题、NLP任务、模型和技术、数据集的可用性、建模的可重复性、语言和交换格式等方面对这些论文进行分析。文章提出了当前研究的一些局限性以及进一步研究的建议。

    The combined growth of available data and their unstructured nature has received increased interest in natural language processing (NLP) techniques to make value of these data assets since this format is not suitable for statistical analysis. This work presents a systematic literature review of state-of-the-art advances using transformer-based methods on electronic medical records (EMRs) in different NLP tasks. To the best of our knowledge, this work is unique in providing a comprehensive review of research on transformer-based methods for NLP applied to the EMR field. In the initial query, 99 articles were selected from three public databases and filtered into 65 articles for detailed analysis. The papers were analyzed with respect to the business problem, NLP task, models and techniques, availability of datasets, reproducibility of modeling, language, and exchange format. The paper presents some limitations of current research and some recommendations for further research.
    
[^28]: 沙特阿拉伯隐私政策数据集

    The Saudi Privacy Policy Dataset. (arXiv:2304.02757v1 [cs.CL])

    [http://arxiv.org/abs/2304.02757](http://arxiv.org/abs/2304.02757)

    本文介绍了由沙特阿拉伯不同领域的阿拉伯语隐私政策组成的数据集，该数据集根据个人数据保护法的10个原则进行了注释。该数据集可用于评估隐私政策遵守性、行业隐私实践基准测试以及开发监测数据保护法规遵守性的自动化工具。

    

    本文介绍了沙特隐私政策数据集，这是一个由来自沙特阿拉伯不同领域的阿拉伯语隐私政策组成的多样化汇编，根据个人数据保护法的10个原则进行了注释；该法规旨在与全球最综合的数据法规之一的通用数据保护条例相兼容。 数据收集自多个来源，包括沙特中央银行，沙特国家联合平台，保险卫生委员会以及使用Google和维基百科的一般网站。 最终数据集包括来自7个行业的1,000个网站，4,638行文本，775,370个标记，以及8,353 KB的语料库大小。 注释数据集为评估隐私政策遵从性，行业隐私实践基准测试以及开发监测数据保护法规遵守性的自动化工具提供了重要的重复利用潜力。

    This paper introduces the Saudi Privacy Policy Dataset, a diverse compilation of Arabic privacy policies from various sectors in Saudi Arabia, annotated according to the 10 principles of the Personal Data Protection Law (PDPL); the PDPL was established to be compatible with General Data Protection Regulation (GDPR); one of the most comprehensive data regulations worldwide. Data were collected from multiple sources, including the Saudi Central Bank, the Saudi Arabia National United Platform, the Council of Health Insurance, and general websites using Google and Wikipedia. The final dataset includes 1,000 websites belonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus size of 8,353 KB. The annotated dataset offers significant reuse potential for assessing privacy policy compliance, benchmarking privacy practices across industries, and developing automated tools for monitoring adherence to data protection regulations. By providing a comprehensive and annotated dataset o
    
[^29]: 人类和大型语言模型中的概念结构表现的差异性

    Behavioral estimates of conceptual structure are robust across tasks in humans but not large language models. (arXiv:2304.02754v1 [cs.AI])

    [http://arxiv.org/abs/2304.02754](http://arxiv.org/abs/2304.02754)

    本研究使用两种经典认知心理学技术来估算人类和GPT-3等大型语言模型的词汇语义结构，结果表明人类的概念结构稳健鲁棒，而大型语言模型的行为估算结构更多取决于具体任务。

    

    多年以来，神经网络语言模型一直被用作研究心理和脑部概念表征的工具。然而，在当代语言人工智能中，我们可以使用与人类参与者几乎相同的方法来探讨概念表征的潜在结构。本研究使用两种经典的认知心理学技术来估算和比较人类和一个著名的大型语言模型（GPT-3的DaVinci变体）的词汇语义结构。研究表明，人类的概念结构强大且鲁棒，不受文化、语言和估算方法的差异影响；大型语言模型中的行为估算结果相对稳定，但具体取决于任务本身。这些结果表明，虽然人类参与者的行为估算结果可靠，但在使用大型语言模型进行人类认知处理相关推断时，需要谨慎。

    Neural network models of language have long been used as a tool for developing hypotheses about conceptual representation in the mind and brain. For many years, such use involved extracting vector-space representations of words and using distances among these to predict or understand human behavior in various semantic tasks. In contemporary language AIs, however, it is possible to interrogate the latent structure of conceptual representations using methods nearly identical to those commonly used with human participants. The current work uses two common techniques borrowed from cognitive psychology to estimate and compare lexical-semantic structure in both humans and a well-known AI, the DaVinci variant of GPT-3. In humans, we show that conceptual structure is robust to differences in culture, language, and method of estimation. Structures estimated from AI behavior, while individually fairly consistent with those estimated from human behavior, depend much more upon the particular task 
    
[^30]: 印尼语自然语言处理技术（NLP）的历史和发展：基础技术、方法、实际应用和挑战

    Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP dalam bahasa Indonesia. (arXiv:2304.02746v1 [cs.CL])

    [http://arxiv.org/abs/2304.02746](http://arxiv.org/abs/2304.02746)

    本文概述了印尼语自然语言处理技术的历史和发展，包括基础技术、实际应用和挑战。未来的研究应该拓展更有效率的方法和技术，并扩大NLP的应用范围。

    

    本研究概述了印尼语环境下自然语言处理（NLP）的发展史，并关注已开发的基础技术、方法和实用应用。综述了基础NLP技术的发展，如词干提取、词性标注和相关方法，以及跨语言信息检索、信息提取和情感分析等实际应用，探索了在印尼语NLP研究中使用的方法和技术，如机器学习、基于统计的机器翻译和基于冲突的方法。本研究还探讨了NLP在印尼语产业和研究中的应用，并确定了印尼语NLP研究和发展中的挑战和机遇。未来印尼语NLP研究和发展的建议包括开发更有效率的方法和技术，扩大NLP的应用范围。

    This study provides an overview of the history of the development of Natural Language Processing (NLP) in the context of the Indonesian language, with a focus on the basic technologies, methods, and practical applications that have been developed. This review covers developments in basic NLP technologies such as stemming, part-of-speech tagging, and related methods; practical applications in cross-language information retrieval systems, information extraction, and sentiment analysis; and methods and techniques used in Indonesian language NLP research, such as machine learning, statistics-based machine translation, and conflict-based approaches. This study also explores the application of NLP in Indonesian language industry and research and identifies challenges and opportunities in Indonesian language NLP research and development. Recommendations for future Indonesian language NLP research and development include developing more efficient methods and technologies, expanding NLP applica
    
[^31]: 使用半监督生成对抗网络检测孟加拉语假评论

    Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks. (arXiv:2304.02739v1 [cs.CL])

    [http://arxiv.org/abs/2304.02739](http://arxiv.org/abs/2304.02739)

    本文研究使用半监督生成对抗网络以少量数据分类孟加拉语假评论和真实评论的潜力，并提出了BanglaBERT与半监督GAN相结合的解决方案，实验结果表明其准确率达到83.59％，f1分数达到84.89％。

    

    本文研究使用半监督生成对抗网络（GAN）微调预训练语言模型，以少量已注释数据来分类孟加拉语假评论和真实评论的潜力。随着社交媒体和电子商务的兴起，能够检测虚假或欺骗性评论变得越来越重要，以保护消费者免受虚假信息的误导。任何机器学习模型在识别假评论方面都会遇到困难，特别是对于像孟加拉语这样的低资源语言。我们证明了所提出的半监督GAN-LM体系结构（预训练语言模型之上的生成对抗网络）是一个可行的解决方案，实验结果表明，即使只有1024个已注释的样本，使用半监督GAN的BanglaBERT的准确率达到83.59％，f1分数达到84.89％，优于其他预训练语言模型BanglaBERT生成器。

    This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data. With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information. Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali. We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models BanglaBERT generator,
    
[^32]: 具身视觉语言规划中的核心挑战

    Core Challenges in Embodied Vision-Language Planning. (arXiv:2304.02738v1 [cs.RO])

    [http://arxiv.org/abs/2304.02738](http://arxiv.org/abs/2304.02738)

    本文讨论了具身视觉语言规划（EVLP）任务领域的挑战和机会，旨在共同利用计算机视觉和自然语言进行物理环境交互。

    

    多模式机器学习和人工智能领域的最新进展，引发了计算机视觉、自然语言处理和机器人技术交叉领域中的一系列挑战性任务。虽然许多方法和以前的调查追求已将其中一两个维度进行了描述，但还没有对所有三个维度进行全面分析。此外，即使考虑这些主题的组合，更多的关注点放在描述当前的体系结构方法上，而不是说明该领域的高层次挑战和机会。在本次调查中，我们讨论了具身视觉语言规划（EVLP）任务，这是一系列重要的具身导航和操作问题，共同利用计算机视觉和自然语言进行物理环境交互。我们提出了一个分类法来统一这些任务，并对当前的和新的算法应用进行了深入分析和比较。

    Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics. Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three. Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field. In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments. We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic app
    
[^33]: 超越不对称性：结构剪枝提高序列到序列模型的推断效率

    To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency. (arXiv:2304.02721v1 [cs.CL])

    [http://arxiv.org/abs/2304.02721](http://arxiv.org/abs/2304.02721)

    本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。

    

    序列到序列语言模型可以用于生成连贯，相关和简洁的抽象摘要。但是，模型大小可能使得在延迟敏感或 Web 规模的实现中部署变得困难。本文研究了模型大小、结构化剪枝、推断效率和广泛使用的摘要数据集上的摘要准确性之间的关系。我们表明，模型准确性与编码器大小有关，而推理效率与解码器有关。使用不对称剪枝可导致推断延迟的近3倍提高，Rouge-2的损失约为1点。此外，我们发现，平均性能降低和不对称性的作用在模型大小和数据集变化方面是一致的。

    Sequence-to-sequence language models can be used to produce abstractive summaries which are coherent, relevant, and concise. Still, model sizes can make deployment in latency-sensitive or web-scale implementations difficult. This paper studies the relationship between model size, structured pruning, inference efficiency, and summarization accuracy on widely used summarization datasets. We show that model accuracy is tied to the encoder size while inference efficiency is connected to the decoder. Using asymmetric pruning can lead to nearly 3x improvement in inference latency with ~1 point loss in Rouge-2. Moreover, we find both the average degradation and the role of asymmetry to be consistent across model sizes and variations in datasets.
    
[^34]: ParroT: 使用大型语言模型进行聊天翻译

    ParroT: Translating During Chat Using Large Language Models. (arXiv:2304.02426v1 [cs.CL])

    [http://arxiv.org/abs/2304.02426](http://arxiv.org/abs/2304.02426)

    ParroT提出了一种基于开源LLM和人工编写的翻译评估数据的聊天翻译框架，可以将翻译数据转化为指令执行样式，并引入额外要求来规范翻译过程。在使用相对较少的训练数据的情况下，实验结果表明 ParroT 可以大幅提高翻译质量。

    

    大型语言模型（LLM）如 ChatGPT 和 GPT-4 在各种自然语言处理（NLP）任务上展现出了卓越的能力，包括在聊天过程中完成各种机器翻译能力。然而，这些模型只能通过受限的API访问，这为新的研究和领域进展带来了障碍。因此，我们提出了 ParroT 框架，基于开源LLM（如LLaMA-7b）和人工编写的翻译评估数据来增强和规范聊天翻译能力。具体而言，ParroT将翻译数据转化为指令执行的样式，并引入 "Hint " 字段以加入额外要求来规范翻译过程。因此，我们提出了三种指令类型来微调 ParroT 模型，包括翻译指令、对比指令和误差引导指令。在两个 Flores 子集和 WMT22 测试集上的实验证明，使用 ParroT 可以大幅提高翻译质量，且需要相对较少的训练数据。

    Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose the $\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a "Hint" field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on two Flores subsets and WMT22 test sets suggest that tr
    
[^35]: 大型语言模型作为钥匙：用GPT解密材料科学的秘密。

    Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT. (arXiv:2304.02213v1 [cs.CL])

    [http://arxiv.org/abs/2304.02213](http://arxiv.org/abs/2304.02213)

    本文介绍了一个新的自然语言处理任务——结构化信息推理（SIS），利用GPT-3模型能够准确提取材料科学设备层面的信息，并通过实验预测PCE和反向预测参数，展示了大型语言模型在材料学中的巨大潜力。

    

    本文介绍了一个新的自然语言处理（NLP）任务——结构化信息推理（SIS），以解决材料科学设备层面信息提取的复杂性。我们使用现有的钙钛矿太阳能电池FAIR数据集对GPT-3进行微调，获得了91.8 F1得分，并更新了数据集，包括迄今为止所有相关科学论文。所生成的数据集已被格式化和标准化，使得它可以直接作为后续数据分析的输入。这个特性将使材料科学家通过选择高质量的领域评论文章来开发其自己的模型。此外，我们设计了实验来预测PCE和反向预测参数，并获得了与DFT相当的性能，这证明了大型语言模型能够像材料学家一样评判材料和设计新材料。

    This article presents a new NLP task called structured information inference (SIS) to address the complexities of information extraction at the device level in materials science. We accomplished this task by finetuning GPT-3 on a exsiting perovskite solar cell FAIR dataset with 91.8 F1-score and we updated the dataset with all related scientific papers up to now. The produced dataset is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature will enable materials scientists to develop their own models by selecting high-quality review papers within their domain. Furthermore, we designed experiments to predict PCE and reverse-predict parameters and obtained comparable performance with DFT, which demonstrates the potential of large language models to judge materials and design new materials like a materials scientist.
    
[^36]: 解锁ChatGPT的潜力：对其在自然语言处理中应用、优点、局限性和未来方向的全面探讨

    Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing. (arXiv:2304.02017v1 [cs.CL])

    [http://arxiv.org/abs/2304.02017](http://arxiv.org/abs/2304.02017)

    本文全面探讨了ChatGPT在自然语言处理中的应用、优点和局限性，强调了使用这个强大工具时的道德考虑，为人工智能和NLP领域的讨论做出了贡献。

    

    ChatGPT是人工智能领域中广泛应用的强大工具，已成功应用于聊天机器人、内容生成、语言翻译、个性化推荐和医疗诊断治疗。它的多功能性和准确性使其成为自然语言处理（NLP）的强大工具。但是，ChatGPT也存在局限性，例如其倾向于产生有偏见的响应以及存在潜在的有害语言模式。本文全面概述了ChatGPT及其应用、优点和局限性，并强调了在真实场景中使用这个强大工具时道德考虑的重要性。最后，本文通过提供提示工程技术的见解，为关于人工智能及其对视觉和NLP领域的影响的持续讨论做出了贡献。

    ChatGPT is a powerful tool in the field of artificial intelligence that has been widely used in various applications. ChatGPT has been applied successfully in chatbots, content generation, language translation, personalized recommendations, and medical diagnosis and treatment. Its versatility and accuracy make it a powerful tool for natural language processing (NLP). However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns. This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations. Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios. Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques.
    
[^37]: 基于重排的后训练量化方法在大型语言模型中的应用

    RPTQ: Reorder-based Post-training Quantization for Large Language Models. (arXiv:2304.01089v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.01089](http://arxiv.org/abs/2304.01089)

    本研究提出了一种新的基于重排的量化方法RPTQ，目的是解决大型语言模型在量化时由于信道激活范围不同而产生的问题。实现该方法后，我们将LLL模型推动到3位激活。

    

    大型语言模型在各种任务上表现出色，但由于其巨大的模型大小而引发的部署挑战。本文指出，LLL模型量化的主要难点在于信道之间不同的激活范围，而不仅仅是离群值问题。我们提出了一种新颖的基于重排的量化方法RPTQ，用于解决LLL模型量化问题。RPTQ通过重新排列激活中的信道，并按簇量化信道，从而减少信道范围差异的影响。此外，我们通过避免显式重排减少存储和计算开销。实现了该方法后，我们首次将LLL模型推动到3位激活。

    Large-scale language models (LLMs) have demonstrated outstanding performance on various tasks, but their deployment poses challenges due to their enormous model size. In this paper, we identify that the main challenge in quantizing LLMs stems from the different activation ranges between the channels, rather than just the issue of outliers.We propose a novel reorder-based quantization approach, RPTQ, that addresses the issue of quantizing the activations of LLMs. RPTQ rearranges the channels in the activations and then quantizing them in clusters, thereby reducing the impact of range difference of channels. In addition, we reduce the storage and computation overhead by avoiding explicit reordering. By implementing this approach, we achieved a significant breakthrough by pushing LLM models to 3 bit activation for the first time.
    
[^38]: ViewRefer: 基于GPT和样例引导的多视角知识处理的三维视觉定位

    ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance. (arXiv:2303.16894v1 [cs.CV])

    [http://arxiv.org/abs/2303.16894](http://arxiv.org/abs/2303.16894)

    本文提出了ViewRefer，这是一个多视角的三维视觉定位框架，利用大规模语言模型和多视角原型，从文本和3D模态中获取视角知识并增强框架的表现。

    

    通过利用多视角输入的3D场景，可以缓解3D视觉定位中的视角差异问题。然而，现有方法通常忽略了嵌入在文本模态中的视角线索，并且未能权衡不同视图的相对重要性。本文提出了ViewRefer，这是一个多视角的三维视觉定位框架，探索如何从文本和3D模态中获取视角知识。其中，ViewRefer利用大规模语言模型（例如GPT）的多样化语言知识，将单一的定位文本扩展为多个几何一致的描述；同时，在3D模态中，引入了基于Transformer的融合模块和视图间注意力，以增强视图之间物体的交互。此外，还提出了一组可学习的多视角原型，用于记忆不同视角下的场景无关知识，从两个方面增强了框架。

    Understanding 3D scenes from multi-view inputs has been proven to alleviate the view discrepancy issue in 3D visual grounding. However, existing methods normally neglect the view cues embedded in the text modality and fail to weigh the relative importance of different views. In this paper, we propose ViewRefer, a multi-view framework for 3D visual grounding exploring how to grasp the view knowledge from both text and 3D modalities. For the text branch, ViewRefer leverages the diverse linguistic knowledge of large-scale language models, e.g., GPT, to expand a single grounding text to multiple geometry-consistent descriptions. Meanwhile, in the 3D modality, a transformer fusion module with inter-view attention is introduced to boost the interaction of objects across views. On top of that, we further present a set of learnable multi-view prototypes, which memorize scene-agnostic knowledge for different views, and enhance the framework from two perspectives: a view-guided attention module 
    
[^39]: 面向任务的内存高效剪枝适配器

    Task-oriented Memory-efficient Pruning-Adapter. (arXiv:2303.14704v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.14704](http://arxiv.org/abs/2303.14704)

    本文提出了一种面向任务的剪枝适配器方法，既实现了训练和内存的高效率，又加快了训练时间，并且在 GLUE 任务中没有显著降低准确性。

    

    大型语言模型的出色性能和不断增长的规模导致了对参数高效学习的 increased attention。主要的两种方法是适配器和剪枝。适配器是在模型上冻结并给它一个新的权重矩阵，在训练时间和内存方面可以显著降低成本，但这样会增加评估和测试的时间和内存消耗。剪枝是截断一些权重并重新分配剩余的权重，这样可以牺牲训练的复杂度，以极高的内存和训练时间为代价，使评估和测试的成本相对较低。因此，训练和推理的效率无法同时得到。在这项工作中，我们提出了一种面向任务的剪枝适配器方法，实现了训练和内存的高内存效率，加快了训练时间，并确保在 GLUE 任务中准确性没有显著下降，实现了训练和推理的效率。

    The Outstanding performance and growing size of Large Language Models has led to increased attention in parameter efficient learning. The two predominant approaches are Adapters and Pruning. Adapters are to freeze the model and give it a new weight matrix on the side, which can significantly reduce the time and memory of training, but the cost is that the evaluation and testing will increase the time and memory consumption. Pruning is to cut off some weight and re-distribute the remaining weight, which sacrifices the complexity of training at the cost of extremely high memory and training time, making the cost of evaluation and testing relatively low. So efficiency of training and inference can't be obtained in the same time. In this work, we propose a task-oriented Pruning-Adapter method that achieve a high memory efficiency of training and memory, and speeds up training time and ensures no significant decrease in accuracy in GLUE tasks, achieving training and inference efficiency at 
    
[^40]: RNN 的回归：用可逆句嵌入的残差循环神经网络

    Return of the RNN: Residual Recurrent Networks for Invertible Sentence Embeddings. (arXiv:2303.13570v1 [cs.CL])

    [http://arxiv.org/abs/2303.13570](http://arxiv.org/abs/2303.13570)

    本研究提出了一种使用残差循环神经网络的新型模型，实现了可逆的句子嵌入。与其他神经机器翻译模型不同，该方法使用基于回归的输出层重建输入序列的单词向量，其具有高准确度和快速训练速度。这种方法适合各种自然语言处理应用，特别是对需要高质量句嵌入的神经网络系统的使用具有潜在优势。

    

    本研究提出了一种新型模型，使用残差循环神经网络在无监督编码任务上进行训练，以生成可逆的句子嵌入。相比于神经机器翻译模型中常见的概率输出，我们的方法采用基于回归的输出层来重建输入序列的单词向量。该模型在使用 ADAM 优化器进行快速训练的同时，取得了高准确度的结果。我们引入了残差连接和“match drop”技术，即只计算错误单词的梯度。我们的方法在各种自然语言处理应用中表现出潜在优势，特别是在需要高质量句嵌入的神经网络系统中。

    This study presents a novel model for invertible sentence embeddings using a residual recurrent network trained on an unsupervised encoding task. Rather than the probabilistic outputs common to neural machine translation models, our approach employs a regression-based output layer to reconstruct the input sequence's word vectors. The model achieves high accuracy and fast training with the ADAM optimizer, a significant finding given that RNNs typically require memory units, such as LSTMs, or second-order optimization methods. We incorporate residual connections and introduce a "match drop" technique, where gradients are calculated only for incorrect words. Our approach demonstrates potential for various natural language processing applications, particularly in neural network-based systems that require high-quality sentence embeddings.
    
[^41]: 基于大语言模型的零样本跨语言摘要

    Zero-Shot Cross-Lingual Summarization via Large Language Models. (arXiv:2302.14229v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14229](http://arxiv.org/abs/2302.14229)

    本文实验性地使用各种提示来指导大型语言模型从不同的范式执行零样本跨语言摘要，并成功提高了它们的CLS性能。其中，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。

    

    给定一个源语言文本，跨语言摘要（CLS）旨在生成另一种目标语言的摘要。最近，大型语言模型（LLM）的出现，比如GPT-3.5、ChatGPT和GPT-4，引起了计算语言学界的广泛关注。然而，目前尚不清楚LLM在CLS上的表现如何。本文实验性地使用各种提示来指导LLM从不同的范式（即端到端和流水线）执行零样本CLS，并对生成的摘要进行初步评估。我们发现，ChatGPT和GPT-4原本更喜欢生成详细信息的长摘要。但这两个LLM在交互式提示的帮助下可以进一步平衡信息量和简洁性，显著提高它们的CLS性能。在三个广泛使用的CLS数据集上的实验结果表明，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。

    Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language. Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community. However, it is not yet known the performance of LLMs on CLS. In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries. We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information. These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance. Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with th
    
[^42]: 通过合并语言模型的权重实现无数据知识融合

    Dataless Knowledge Fusion by Merging Weights of Language Models. (arXiv:2212.09849v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09849](http://arxiv.org/abs/2212.09849)

    本文提出了一种无数据知识融合方法，可以合并在不同训练数据集上建立的单个模型，以得到一个在所有数据集领域上表现良好且可以推广到域外数据的单一模型。

    

    微调预训练语言模型已成为构建下游NLP模型的流行范式。通常情况下，经过微调的模型已经可用，但其训练数据不可用，由于数据隐私或知识产权问题。这就造成了跨模型融合知识以产生更好的单一模型的障碍。在本文中，我们研究了建立在不同训练数据集上的单个模型之间合并的问题，以得到一个在所有数据集领域上表现良好且可以推广到域外数据的单一模型。我们提出了一种无数据知识融合方法，该方法在参数空间中合并模型，由权重引导，以最小化合并模型和单个模型之间的预测差异。在一系列评估设置中，我们展示了该方法显著优于如Fisher加权平均或模型集成等基线。此外，我们发现我们的方法是一个有前途的多语言微调替代方案，因为它可以在不需要任何额外注释数据的情况下实现可比的性能。

    Fine-tuning pre-trained language models has become the prevalent paradigm for building downstream NLP models. Oftentimes fine-tuned models are readily available but their training data is not, due to data privacy or intellectual property concerns. This creates a barrier to fusing knowledge across individual models to yield a better single model. In this paper, we study the problem of merging individual models built on different training data sets to obtain a single model that performs well both across all data set domains and can generalize on out-of-domain data. We propose a dataless knowledge fusion method that merges models in their parameter space, guided by weights that minimize prediction differences between the merged model and the individual models. Over a battery of evaluation settings, we show that the proposed method significantly outperforms baselines such as Fisher-weighted averaging or model ensembling. Further, we find that our method is a promising alternative to multi-
    
[^43]: 从范例到抄本：计算探究Hadewijch手稿的抄写者拓本

    From exemplar to copy: the scribal appropriation of a Hadewijch manuscript computationally explored. (arXiv:2210.14061v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.14061](http://arxiv.org/abs/2210.14061)

    本文研究了中世纪神秘作家Hadewijch的手稿副本之间微妙的语言变化和抄写者的拼写惯例差异，并运用计算分析方法进行了探究。

    

    本研究致力于研究中世纪神秘作家Hadewijch的作品被保存的两份最古老的已知手稿：布鲁塞尔KBR2879-2880（ms.A）和布鲁塞尔KBR 2877-2878（ms.B）。基于编码学和语境论证，我们假定制作B的抄写员使用A作为范本。尽管两个手稿在布局和内容方面的相似之处令人惊叹，但本文旨在确定它们之间的差异。毕竟，无论有意制作一个紧密跟随范本的副本，微妙的语言变化都显而易见。差异涉及拼写惯例，但也涉及单词缩写的方式（以及缩写的程度）。本研究以计算的方式调查了制作mss.A和B的抄写员的拼写配置文件。在本研究的第一部分，我们将更详细地介绍这两个手稿，然后考虑有关抄写员和抄写实践以及Hadewijch作品的先前研究。然后，我们将概述我们的方法并呈现计算分析的结果。最后，我们将讨论我们的发现对中世纪手稿文化和文本传播研究的影响。

    This study is devoted to two of the oldest known manuscripts in which the oeuvre of the medieval mystical author Hadewijch has been preserved: Brussels, KBR, 2879-2880 (ms. A) and Brussels, KBR, 2877-2878 (ms. B). On the basis of codicological and contextual arguments, it is assumed that the scribe who produced B used A as an exemplar. While the similarities in both layout and content between the two manuscripts are striking, the present article seeks to identify the differences. After all, regardless of the intention to produce a copy that closely follows the exemplar, subtle linguistic variation is apparent. Divergences relate to spelling conventions, but also to the way in which words are abbreviated (and the extent to which abbreviations occur). The present study investigates the spelling profiles of the scribes who produced mss. A and B in a computational way. In the first part of this study, we will present both manuscripts in more detail, after which we will consider prior resea
    
[^44]: 大规模多语言机器翻译中的毒性问题

    Toxicity in Multilingual Machine Translation at Scale. (arXiv:2210.03070v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.03070](http://arxiv.org/abs/2210.03070)

    本文研究了在大规模多语言机器翻译中一种关键错误类型——添加毒性。自动和人工评估均表明低资源语言和特定人口统计轴，如性取向、性别和能力等，往往会出现更多的毒性。为了更好地解释这些结果，我们使用了度量翻译源贡献量的方法。

    

    机器翻译系统可能会产生不同类型的错误，其中某些被称为关键或灾难性错误，因为它们可能对用户产生特定的负面影响。本文重点研究一种关键错误类型：添加的毒性。我们评估和分析了将一个大型评估数据集（HOLISTICBIAS，超过472k句，覆盖13个人口统计轴）从英语翻译成164种语言时添加毒性的情况。自动毒性评估显示，跨语言的添加毒性在0％至5％之间变化。添加毒性最严重的输出语言往往是低资源语言，而添加毒性最多的人口统计轴包括性取向，性别和能力。我们还对8个翻译方向的子集进行了人工评估，确认了真正存在添加毒性的现象。我们使用了对翻译的源贡献量的度量，其中低的源贡献意味着幻觉，以解释结果。

    Machine Translation systems can produce different types of errors, some of which are characterized as critical or catastrophic due to the specific negative impact that they can have on users. In this paper we focus on one type of critical error: added toxicity. We evaluate and analyze added toxicity when translating a large evaluation dataset (HOLISTICBIAS, over 472k sentences, covering 13 demographic axes) from English into 164 languages. An automatic toxicity evaluation shows that added toxicity across languages varies from 0% to 5%. The output languages with the most added toxicity tend to be low-resource ones, and the demographic axes with the most added toxicity include sexual orientation, gender and sex, and ability. We also perform human evaluation on a subset of 8 translation directions, confirming the prevalence of true added toxicity. We use a measurement of the amount of source contribution to the translation, where a low source contribution implies hallucination, to interpr
    
[^45]: 稀疏*BERT：稀疏模型能够泛化到新的任务和领域（翻译自arXiv:2205.12452v2 [cs.CL] UPDATED）

    Sparse*BERT: Sparse Models Generalize To New tasks and Domains. (arXiv:2205.12452v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12452](http://arxiv.org/abs/2205.12452)

    本文研究了使用渐进非结构化幅值修剪进行修剪的模型如何在领域和任务之间进行转移。使用遮蔽语言模型进行预训练的被修剪模型能够在不进行广泛的超参数探索或专门方法的情况下转移到新的领域和任务。在生物医学NLP任务中，Sparse*BERT可以达到或超过BioBERT的性能。

    

    大型语言模型已经成为大多数现代自然语言处理（NLP）系统的核心架构。这些模型可以在任务和领域之间始终提供卓越的准确性和鲁棒性，但其高计算开销可能会使推理变得困难和昂贵。为了使使用这些模型成本更低，近期的研究探讨了利用结构化和非结构化修剪、量化和蒸馏来提高推理速度并减小模型大小。本文研究了使用渐进非结构化幅值修剪进行修剪的模型如何在领域和任务之间进行转移。我们的实验表明，使用遮蔽语言模型进行预训练的被修剪模型能够在不进行广泛的超参数探索或专门方法的情况下转移到新的领域和任务。我们演示了我们的稀疏通用模型Sparse*BERT可以通过在非结构化生物医学文本上预训练压缩的架构而成为SparseBioBERT，并且在多种生物医学NLP任务中可以达到或超过BioBERT的性能。

    Large Language Models have become the core architecture upon which most modern natural language processing (NLP) systems build. These models can consistently deliver impressive accuracy and robustness across tasks and domains, but their high computational overhead can make inference difficult and expensive. To make using these models less costly, recent work has explored leveraging structured and unstructured pruning, quantization, and distillation to improve inference speed and decrease size. This paper studies how models pruned using Gradual Unstructured Magnitude Pruning can transfer between domains and tasks. Our experimentation shows that models that are pruned during pretraining using general domain masked language models can transfer to novel domains and tasks without extensive hyperparameter exploration or specialized approaches. We demonstrate that our general sparse model Sparse*BERT can become SparseBioBERT simply by pretraining the compressed architecture on unstructured bi
    
[^46]: 基于集合自动机匹配的术语重写

    Term Rewriting Based On Set Automaton Matching. (arXiv:2202.08687v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.08687](http://arxiv.org/abs/2202.08687)

    本文描述了如何利用集合自动机构造重写系统的左侧，从而高效查找术语中的所有红块，并提供了一个在最外层重写下具有竞争力的有效实现方法。

    

    本文研究了如何利用子项模式匹配算法来实现高效的术语重写程序。从重写系统的左侧构造集合自动机，以便有效地查找所有术语中的红块。我们正式描述了一个过程，给定重写策略，交替进行模式匹配和重写步骤，从而顺利地集成了红块发现和子项替换。然后，我们提出了一种高效的实现，将此过程实例化为最外层重写，并呈现了一些实验结果。我们的实现表现出与可比工具相当的竞争力。

    In this article we investigate how a subterm pattern matching algorithm can be exploited to implement efficient term rewriting procedures. From the left-hand sides of the rewrite system we construct a set automaton, which can be used to find all redexes in a term efficiently. We formally describe a procedure that, given a rewrite strategy, interleaves pattern matching steps and rewriting steps and thus smoothly integrates redex discovery and subterm replacement. We then present an efficient implementation that instantiates this procedure with outermost rewriting, and present the results of some experiments. Our implementation shows to be competitive with comparable tools.
    

