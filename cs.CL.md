# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Gender-specific Machine Translation with Large Language Models.](http://arxiv.org/abs/2309.03175) | 基于大型语言模型的性别特定机器翻译研究发现，LLaMa能够以竞争性准确性和性别偏差缓解生成性别特定的翻译，并在性别模糊的情境中保持稳健性能。 |
| [^2] | [J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News.](http://arxiv.org/abs/2309.03164) | J-Guard是一个能够在AI生成新闻中检测AI生成文本的框架，通过引入新闻属性和提高对抗鲁棒性，解决了现有方法的不可靠性和误报问题。 |
| [^3] | [Everyone Deserves A Reward: Learning Customized Human Preferences.](http://arxiv.org/abs/2309.03126) | 该论文研究了定制化的人类偏好学习问题，通过收集领域特定偏好数据集，并提出了一个三阶段的定制化奖励模型学习方案，从而解决了当前语言模型训练中忽视多样性的问题。 |
| [^4] | [Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs.](http://arxiv.org/abs/2309.03118) | 本文提出了一种名为Knowledge Solver（KSL）的方法，通过利用大型语言模型（LLMs）的泛化能力，教导LLMs从外部知识库中搜索关键知识，从而解决了LLMs缺乏领域特定知识的问题。 |
| [^5] | [ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation Following the Metaphor Identification Procedure.](http://arxiv.org/abs/2309.03103) | ContrastWSD是一种使用了词义消岐的隐喻检测模型，通过将隐喻识别过程和词义消岐结合起来，提取并对比单词的上下文含义和基本含义，以提高隐喻检测的效果，超过其他仅依赖上下文嵌入或集成基本定义和外部知识的方法。 |
| [^6] | [GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models.](http://arxiv.org/abs/2309.03079) | 本论文利用大型语言模型分析股票市场上上市公司的年度报告，生成洞察，并通过历史股价数据训练机器学习模型，取得相对标普500指数的超额回报。 |
| [^7] | [A Multimodal Analysis of Influencer Content on Twitter.](http://arxiv.org/abs/2309.03064) | 本研究通过引入一个新的Twitter数据集，结合文本和视觉信息，实验了多种预测模型，旨在自动检测影响者内容中的商业推广行为。 |
| [^8] | [Persona-aware Generative Model for Code-mixed Language.](http://arxiv.org/abs/2309.02915) | 本论文提出了一种针对混合语言的人物感知生成模型PARADOX，它能够生成类似于真实个体代码混合文本的文本。该模型以用户的人物形象为条件来编码对话，并生成不带单语参考数据的代码混合文本。模型还进行对齐，使生成的文本更接近真实的代码混合文本。这种方法在语义上更有意义，在语言上更有效。 |
| [^9] | [Leave no Place Behind: Improved Geolocation in Humanitarian Documents.](http://arxiv.org/abs/2309.02914) | 本研究通过开发经过注释的资源，对命名实体识别工具进行微调，提出了一种地理编码方法，以改善人道主义文档的地理定位。结果表明，该方法提高了分类器性能，减轻了现有工具的偏见，对西方以外的资源需求更大。 |
| [^10] | [On the Challenges of Building Datasets for Hate Speech Detection.](http://arxiv.org/abs/2309.02912) | 本研究旨在分析仇恨言论检测中的问题，并提出了一种综合框架来指导未来构建仇恨言论数据集的最佳实践。 |
| [^11] | [ViCGCN: Graph Convolutional Network with Contextualized Language Models for Social Media Mining in Vietnamese.](http://arxiv.org/abs/2309.02902) | 本研究提出了一种基于上下文化语言模型和图卷积网络的创新方法，能够解决越南社交媒体文本中的数据不平衡和噪声问题，并捕捉语义信息。 |
| [^12] | [A deep Natural Language Inference predictor without language-specific training data.](http://arxiv.org/abs/2309.02887) | 本文介绍了一种处理目标语言句子对之间推理关系问题的新方法，该方法不需要特定语言的训练数据集。通过利用一个通用的翻译数据集和两个预训练模型的实例，模型可以在不同任务上展现出通用性，且在多个数据集上得到了验证。 |
| [^13] | [Aligning Large Language Models for Clinical Tasks.](http://arxiv.org/abs/2309.02884) | 该论文讨论了对于临床任务的大型语言模型(LLMs)的对齐问题，提出了一种名为"expand-guess-refine"的医学问答对齐策略，并通过组合使用指令调优和in-prompt策略等技术来提高LLMs的性能。 |
| [^14] | [Promoting Open-domain Dialogue Generation through Learning Pattern Information between Contexts and Responses.](http://arxiv.org/abs/2309.02823) | 本文通过学习上下文和回复之间的隐式模式信息提高了开放领域对话生成模型的质量，采用了改进的预训练模型的计划采样方法，使生成的回复更加生动和信息丰富。 |
| [^15] | [Agent-based simulation of pedestrians' earthquake evacuation; application to Beirut, Lebanon.](http://arxiv.org/abs/2309.02812) | 本研究开发了一个跨学科的代理模型，用于模拟城市规模的地震期间行人疏散，以黎巴嫩贝鲁特为例。模型综合考虑了地震危险、物理易损性以及个体行为和活动能力。这对于定量风险评估研究来说是重要而创新的。 |
| [^16] | [Norm Tweaking: High-performance Low-bit Quantization of Large Language Models.](http://arxiv.org/abs/2309.02784) | 本文介绍了一种称为“norm tweaking”的技术，通过调整量化的激活分布来实现高精度的低比特量化，以提高大型语言模型的压缩性能。 |
| [^17] | [GRASS: Unified Generation Model for Speech Semantic Understanding.](http://arxiv.org/abs/2309.02780) | 本文介绍了一个统一的端到端框架，通过指令微调技术实现了语音语义理解任务。实验证明该模型在微调下游任务后明显优于最先进的模型，并在零样本和少样本场景中取得了竞争性的性能。 |
| [^18] | [Improving Code Generation by Dynamic Temperature Sampling.](http://arxiv.org/abs/2309.02772) | 通过动态温度采样的AdapT方法，我们提出了一种针对代码生成的新的解码策略，通过调整温度系数来解决难以预测的代码标记，并取得了显著效果。 |
| [^19] | [Rubric-Specific Approach to Automated Essay Scoring with Augmentation Training.](http://arxiv.org/abs/2309.02740) | 本文提出一种用于自动评分的细分标准特定方法，通过增强培训和测试数据来学习之前研究中忽视的特征和功能，达到了最新性能。 |
| [^20] | [HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus.](http://arxiv.org/abs/2309.02731) | 本文介绍了HC3 Plus，一个语义不变的人类ChatGPT对比语料库。与以往的工作相比，该语料库考虑了更多类型的任务，包括语义不变任务。研究发现，在语义不变任务中检测模型生成的文本更加困难。通过大量任务指令微调和Tk-instruct，建立了一个更强大的模型。 |
| [^21] | [Large Language Models for Automated Open-domain Scientific Hypotheses Discovery.](http://arxiv.org/abs/2309.02726) | 这项研究提出了用于社会科学学术假设发现的第一个自然语言处理数据集，旨在开发一个系统，能够基于原始网络语料库自动生成有效、新颖且对人类研究者有帮助的假设。 |
| [^22] | [Offensive Hebrew Corpus and Detection using BERT.](http://arxiv.org/abs/2309.02724) | 本研究提出了一个新的希伯来语侮辱性语料库，并使用两个希伯来语BERT模型（HeBERT和AlephBERT）进行了微调。我们观察到，我们的数据结合D_OLaH可以提高HeBERT模型的性能2%。此外，我们的数据对AlephBERT模型也具有一定的泛化性能。 |
| [^23] | [HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models.](http://arxiv.org/abs/2309.02706) | HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。 |
| [^24] | [Certifying LLM Safety against Adversarial Prompting.](http://arxiv.org/abs/2309.02705) | 本研究提出了首个具有可验证安全保证的框架——消除和检查，用于对抗敌对提示。通过逐个消除标记并使用安全过滤器检查生成的子序列，确保任何敌对修改的有害输入提示都能被正确标识为有害。 |
| [^25] | [A Joint Study of Phrase Grounding and Task Performance in Vision and Language Models.](http://arxiv.org/abs/2309.02691) | 这项研究提出了一个框架来研究视觉和语言模型中短语定位和任务性能之间的关系，并且通过验证实验发现了当代模型在短语定位和任务求解方面的不一致性。 |
| [^26] | [Zero-Resource Hallucination Prevention for Large Language Models.](http://arxiv.org/abs/2309.02654) | 本论文提出了一种零资源幻觉预防方法，通过评估模型对输入指令中概念的熟悉程度，在遇到不熟悉的概念时不生成响应，从而解决了大型语言模型中的幻觉问题。 |
| [^27] | [Epi-Curriculum: Episodic Curriculum Learning for Low-Resource Domain Adaptation in Neural Machine Translation.](http://arxiv.org/abs/2309.02640) | Epi-Curriculum是一种用于神经机器翻译中低资源领域自适应的方法，通过分集训练和去噪的课程学习，提高了模型对领域变化的鲁棒性和适应性。 |
| [^28] | [Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning.](http://arxiv.org/abs/2309.02591) | CM3Leon是一个缩放自回归多模态语言模型，通过预训练和指令调整实现了高质量的文本和图像的生成和填充，达到了文本到图像生成方面的最先进性能，而计算资源开销较小。 |
| [^29] | [Automating Behavioral Testing in Machine Translation.](http://arxiv.org/abs/2309.02553) | 本文提出了一种利用大型语言模型自动生成源句子的方法，以测试机器翻译模型在多种情况下的行为。通过对多个机器翻译系统应用该方法，发现在测试结果与传统准确率度量存在差异的情况下，仍可观察到一致的趋势。 |
| [^30] | [Minimal Effective Theory for Phonotactic Memory: Capturing Local Correlations due to Errors in Speech.](http://arxiv.org/abs/2309.02466) | 这是一个关于语音规则记忆的最小有效理论的研究，通过构建一个局部连接的张量网络模型，利用局部语音相关性来促进口语单词的学习，并提供了可能产生的错误的层次结构。 |
| [^31] | [Towards Foundational AI Models for Additive Manufacturing: Language Models for G-Code Debugging, Manipulation, and Comprehension.](http://arxiv.org/abs/2309.02465) | 本文针对三维打印的G代码文件提出了六种基础大型语言模型（LLMs），通过评估它们在G代码调试和操作方面的性能，包括错误检测和修正以及几何变换等。结果表明这些模型具有潜力应用于增材制造领域。 |
| [^32] | [Text-Only Domain Adaptation for End-to-End Speech Recognition through Down-Sampling Acoustic Representation.](http://arxiv.org/abs/2309.02459) | 本文提出了一种通过下采样声学表示来对齐文本模态的方法，以实现纯文本领域自适应的端到端语音识别。实验结果表明，该方法在新领域数据上取得了良好的效果。 |
| [^33] | [Substitution-based Semantic Change Detection using Contextual Embeddings.](http://arxiv.org/abs/2309.02403) | 使用基于上下文嵌入的替代词来测量语义变化，不仅直观易懂，而且存储效率更高，在一些数据集中表现更好，并且能够进行更细致的变化分析。 |
| [^34] | [CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models.](http://arxiv.org/abs/2309.01940) | CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。 |
| [^35] | [Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition and Translation.](http://arxiv.org/abs/2309.01860) | 本文提出了一种注意力驱动的多模态融合机制，通过将光流信息与RGB图像相结合，丰富了连续手语识别和翻译流程中的特征。该方法在手语识别任务中降低了WER 0.9，在翻译任务中提高了测试集上大多数BLEU分数约0.6。 |
| [^36] | [An Empirical Analysis for Zero-Shot Multi-Label Classification on COVID-19 CT Scans and Uncurated Reports.](http://arxiv.org/abs/2309.01740) | 本研究通过对比性视觉语言学习，在COVID-19 CT扫描和非标准化报告中应用零样本多标签分类，以发现肺栓塞和细微的肺部细节，为医学图像分析领域带来了新的发展机遇。 |
| [^37] | [CPSP: Learning Speech Concepts From Phoneme Supervision.](http://arxiv.org/abs/2309.00424) | 论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。 |
| [^38] | [BatchPrompt: Accomplish more with less.](http://arxiv.org/abs/2309.00384) | BatchPrompt是一种提示策略，它通过将多个数据点批量打包到一个提示中来提高LLM的令牌资源利用效率，从而缓解由于令牌计数差异导致的成本效率问题，提高推理速度和计算预算的利用率。 |
| [^39] | [Large Language Models on Wikipedia-Style Survey Generation: an Evaluation in NLP Concepts.](http://arxiv.org/abs/2308.10410) | 本研究评估了大型语言模型在自然语言处理领域生成调研文章的效果，发现GPT-4优于GPT-3.5，并且指出了GPT在信息完整性和事实准确性方面的一些缺陷。 |
| [^40] | [Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias.](http://arxiv.org/abs/2308.04566) | 本论文针对机器阅读理解中的答案位置偏倚问题，提出了一种名为单句阅读器的新方法，该方法使用六种不同模型实现。实验证明，单句阅读器与传统训练集上训练的模型几乎具有相当的性能，有效解决了答案位置偏倚问题。 |
| [^41] | [Large-scale Language Model Rescoring on Long-form Data.](http://arxiv.org/abs/2306.08133) | 本文研究了大规模语言模型对长视频ASR的影响，证明与最大熵基线相比，使用LLM能够最多减少8％的Word Error Rate和30％的Salient Term Error Rate。经过改进的格处理和携带上下文的组合可以获得更好的效果。 |
| [^42] | [Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering.](http://arxiv.org/abs/2306.00526) | 该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。 |
| [^43] | [ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?.](http://arxiv.org/abs/2303.05382) | 本文探讨了ChatGPT在解决交通问题方面的应用。通过利用具有跨模态编码器的LLM，可以处理来自不同模态的交通数据并执行交通运营。作者提供了一个基于智能手机的碰撞报告自动生成和分析框架作为用例展示了这种潜力。 |
| [^44] | [NNKGC: Improving Knowledge Graph Completion with Node Neighborhoods.](http://arxiv.org/abs/2302.06132) | NNKGC是一种通过节点邻居进行知识图谱补全并引入边连接预测任务的框架，简单而有效，可以预测出可解释的结果。 |
| [^45] | [Learning to Select from Multiple Options.](http://arxiv.org/abs/2212.00301) | 本文提出了一个上下文化的文本蕴涵（TE）模型（Context-TE），通过考虑其他选项作为当前建模的上下文，它能够解决TE方法中的两个限制。这个模型可以学习到更可靠的选项决策，并且通过加速推理过程来提高效率。 |
| [^46] | [A Survey on Measuring and Mitigating Reasoning Shortcuts in Machine Reading Comprehension.](http://arxiv.org/abs/2209.01824) | 这篇综述论文调查了机器阅读理解中测量和减轻推理捷径的技术，并强调了缺乏公共挑战集和其他领域减轻技术的问题。 |

# 详细

[^1]: 基于大型语言模型的性别特定机器翻译

    Gender-specific Machine Translation with Large Language Models. (arXiv:2309.03175v1 [cs.CL])

    [http://arxiv.org/abs/2309.03175](http://arxiv.org/abs/2309.03175)

    基于大型语言模型的性别特定机器翻译研究发现，LLaMa能够以竞争性准确性和性别偏差缓解生成性别特定的翻译，并在性别模糊的情境中保持稳健性能。

    

    解码器专用的大型语言模型（LLM）已经展示了在机器翻译中的潜力，尽管性能略低于传统的编码器-解码器神经机器翻译（NMT）系统。然而，LLM具有独特的优势：通过提示控制输出的特性。在这项研究中，我们利用这种灵活性来探索LLaMa在具有语法性别的语言中生成性别特定翻译的能力。我们的结果表明，与最先进的多语种机器翻译系统NLLB相比，LLaMa可以以有竞争力的准确性和性别偏差缓解生成性别特定的翻译。此外，我们的实验证明，LLaMa的翻译结果是稳健的，在性别模糊的数据集中，评估与相反性别参考翻译时会出现显著性能下降，但在不太模糊的上下文中保持一致。这项研究提供了使用LLM进行性别特定翻译的潜力和挑战的见解。

    Decoder-only Large Language Models (LLMs) have demonstrated potential in machine translation (MT), albeit with performance slightly lagging behind traditional encoder-decoder Neural Machine Translation (NMT) systems. However, LLMs offer a unique advantage: the ability to control the properties of the output through prompts. In this study, we harness this flexibility to explore LLaMa's capability to produce gender-specific translations for languages with grammatical gender. Our results indicate that LLaMa can generate gender-specific translations with competitive accuracy and gender bias mitigation when compared to NLLB, a state-of-the-art multilingual NMT system. Furthermore, our experiments reveal that LLaMa's translations are robust, showing significant performance drops when evaluated against opposite-gender references in gender-ambiguous datasets but maintaining consistency in less ambiguous contexts. This research provides insights into the potential and challenges of using LLMs f
    
[^2]: J-Guard：新闻指导的对抗鲁棒AI生成新闻检测

    J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News. (arXiv:2309.03164v1 [cs.CL])

    [http://arxiv.org/abs/2309.03164](http://arxiv.org/abs/2309.03164)

    J-Guard是一个能够在AI生成新闻中检测AI生成文本的框架，通过引入新闻属性和提高对抗鲁棒性，解决了现有方法的不可靠性和误报问题。

    

    AI生成文本在网络上的迅速扩张正在深刻地改变信息格局。在各种类型的AI生成文本中，AI生成新闻作为一种显著的来源，对网络上的误导信息构成了重大威胁。虽然最近有一些努力致力于对AI生成文本的检测，但考虑到其面临的简单对抗攻击的易受攻击性，这些方法需要更高的可靠性。此外，由于新闻写作的特异性，将这些检测方法应用于AI生成新闻可能会产生误报，潜在地破坏新闻机构的声誉。为解决这些挑战，我们利用一个跨学科团队的专门知识来开发一个名为J-Guard的框架，该框架可以引导现有的基于监督的AI文本检测器以检测AI生成新闻，并提升对抗鲁棒性。通过引入受独特新闻属性启发的文体暗示，J-Guard能有效抵制对抗攻击并降低误报率。

    The rapid proliferation of AI-generated text online is profoundly reshaping the information landscape. Among various types of AI-generated text, AI-generated news presents a significant threat as it can be a prominent source of misinformation online. While several recent efforts have focused on detecting AI-generated text in general, these methods require enhanced reliability, given concerns about their vulnerability to simple adversarial attacks. Furthermore, due to the eccentricities of news writing, applying these detection methods for AI-generated news can produce false positives, potentially damaging the reputation of news organizations. To address these challenges, we leverage the expertise of an interdisciplinary team to develop a framework, J-Guard, capable of steering existing supervised AI text detectors for detecting AI-generated news while boosting adversarial robustness. By incorporating stylistic cues inspired by the unique journalistic attributes, J-Guard effectively dis
    
[^3]: 每个人都应该得到奖励：学习定制的人类偏好

    Everyone Deserves A Reward: Learning Customized Human Preferences. (arXiv:2309.03126v1 [cs.CL])

    [http://arxiv.org/abs/2309.03126](http://arxiv.org/abs/2309.03126)

    该论文研究了定制化的人类偏好学习问题，通过收集领域特定偏好数据集，并提出了一个三阶段的定制化奖励模型学习方案，从而解决了当前语言模型训练中忽视多样性的问题。

    

    奖励模型在提高大型语言模型与人类偏好的交互质量方面起着关键作用。然而，现实世界是多元的，这导致了基于不同宗教、政治、文化等的多样化人类偏好。此外，每个人对各种主题都可以有自己独特的偏好。当前的语言模型训练过程忽视了人类偏好的多样性，只使用一个通用的奖励模型，这对于定制或个性化应用场景来说是不够满意的。为了探索定制化的偏好学习，我们收集了一个领域特定的偏好数据集，该数据集收集了来自四个实际领域中对每个给定查询的首选响应。此外，从数据效率的角度出发，我们提出了一个三阶段的定制化奖励模型学习方案，并在通用偏好数据集和我们的领域特定偏好数据集上对其有效性进行了实证验证。

    Reward models (RMs) are crucial in aligning large language models (LLMs) with human preferences for improving interaction quality. However, the real world is pluralistic, which leads to diversified human preferences based on different religions, politics, cultures, etc. Moreover, each individual can have their own unique preferences on various topics. Neglecting the diversity of human preferences, current LLM training processes only use a general reward model, which is below satisfaction for customized or personalized application scenarios. To explore customized preference learning, we collect a domain-specific preference (DSP) dataset, which collects preferred responses to each given query from four practical domains. Besides, from the perspective of data efficiency, we proposed a three-stage customized RM learning scheme, whose effectiveness is empirically verified on both general preference datasets and our DSP set. Furthermore, we test multiple training and data strategies on the t
    
[^4]: 知识求解器：教授LLMs从知识图谱中搜索领域知识

    Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs. (arXiv:2309.03118v1 [cs.CL])

    [http://arxiv.org/abs/2309.03118](http://arxiv.org/abs/2309.03118)

    本文提出了一种名为Knowledge Solver（KSL）的方法，通过利用大型语言模型（LLMs）的泛化能力，教导LLMs从外部知识库中搜索关键知识，从而解决了LLMs缺乏领域特定知识的问题。

    

    大型语言模型（LLMs）如ChatGPT和GPT-4由于其新兴能力和泛化能力而具有多功能性，可以解决不同的任务。然而，LLMs有时缺乏领域特定的知识来执行任务，这也会导致推理过程中出现虚假信息。在一些先前的工作中，额外的模块如图神经网络（GNNs）被训练用于从外部知识库中检索知识，旨在缓解缺乏领域特定知识的问题。然而，将额外的模块纳入: 1）在遇到新领域时需要重新训练额外的模块; 2）会成为瓶颈，因为LLMs的强大能力没有充分利用于检索。在本文中，我们提出了一种名为Knowledge Solver（KSL）的范式，通过利用LLMs自身的强大泛化能力，教导LLMs从外部知识库中搜索关键知识。具体而言，我们设计了一个简单而有效的提示来将检索转化为多跳的形式。

    Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and can solve different tasks due to their emergent ability and generalizability. However, LLMs sometimes lack domain-specific knowledge to perform tasks, which would also cause hallucination during inference. In some previous works, additional modules like graph neural networks (GNNs) are trained on retrieved knowledge from external knowledge bases, aiming to mitigate the problem of lacking domain-specific knowledge. However, incorporating additional modules: 1) would need retraining additional modules when encountering novel domains; 2) would become a bottleneck since LLMs' strong abilities are not fully utilized for retrieval. In this paper, we propose a paradigm, termed Knowledge Solver (KSL), to teach LLMs to search for essential knowledge from external knowledge bases by harnessing their own strong generalizability. Specifically, we design a simple yet effective prompt to transform retrieval into a multi-hop d
    
[^5]: ContrastWSD: 使用词义消岐加强隐喻检测

    ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation Following the Metaphor Identification Procedure. (arXiv:2309.03103v1 [cs.CL])

    [http://arxiv.org/abs/2309.03103](http://arxiv.org/abs/2309.03103)

    ContrastWSD是一种使用了词义消岐的隐喻检测模型，通过将隐喻识别过程和词义消岐结合起来，提取并对比单词的上下文含义和基本含义，以提高隐喻检测的效果，超过其他仅依赖上下文嵌入或集成基本定义和外部知识的方法。

    

    本文提出了ContrastWSD，一种基于RoBERTa的隐喻检测模型，它集成了隐喻识别过程(MIP)和词义消岐(WSD)来提取并对比单词的上下文含义和基本含义，以确定它在句子中是否以隐喻的方式使用。通过利用WSD模型得出的单词词义，我们的模型增强了隐喻检测过程，并超过了仅依赖上下文嵌入或仅集成基本定义和其他外部知识的其他方法。我们在多个基准数据集上评估了我们的方法，并与强基线进行比较，结果表明它在推进隐喻检测方面的有效性。

    This paper presents ContrastWSD, a RoBERTa-based metaphor detection model that integrates the Metaphor Identification Procedure (MIP) and Word Sense Disambiguation (WSD) to extract and contrast the contextual meaning with the basic meaning of a word to determine whether it is used metaphorically in a sentence. By utilizing the word senses derived from a WSD model, our model enhances the metaphor detection process and outperforms other methods that rely solely on contextual embeddings or integrate only the basic definitions and other external knowledge. We evaluate our approach on various benchmark datasets and compare it with strong baselines, indicating the effectiveness in advancing metaphor detection.
    
[^6]: GPT-InvestAR: 利用大型语言模型增强股票投资策略通过年度报告分析

    GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models. (arXiv:2309.03079v1 [q-fin.ST])

    [http://arxiv.org/abs/2309.03079](http://arxiv.org/abs/2309.03079)

    本论文利用大型语言模型分析股票市场上上市公司的年度报告，生成洞察，并通过历史股价数据训练机器学习模型，取得相对标普500指数的超额回报。

    

    上市公司的年度报告包含了关于其财务状况的重要信息，可以帮助评估其对股票价格的潜在影响。这些报告的内容非常全面，有时甚至超过100页。即使对于一个公司来说，分析这些报告也是一项繁琐的工作，更不用说整个公司群体了。多年来，金融专家已经能够相对快速地从这些文件中提取有价值的信息。然而，这需要多年的实践和经验。本文旨在通过利用大型语言模型（LLMs）的能力，简化对所有公司年度报告的评估过程。LLM生成的洞察力被汇编在一个量化风格的数据集中，并通过历史股价数据进行补充。然后使用LLM输出作为特征训练一种机器学习模型。前向测试结果显示相对于标普500指数获得了有希望的超额回报。本文旨在

    Annual Reports of publicly listed companies contain vital information about their financial health which can help assess the potential impact on Stock price of the firm. These reports are comprehensive in nature, going up to, and sometimes exceeding, 100 pages. Analysing these reports is cumbersome even for a single firm, let alone the whole universe of firms that exist. Over the years, financial experts have become proficient in extracting valuable information from these documents relatively quickly. However, this requires years of practice and experience. This paper aims to simplify the process of assessing Annual Reports of all the firms by leveraging the capabilities of Large Language Models (LLMs). The insights generated by the LLM are compiled in a Quant styled dataset and augmented by historical stock price data. A Machine Learning model is then trained with LLM outputs as features. The walkforward test results show promising outperformance wrt S&P500 returns. This paper intends
    
[^7]: 在Twitter上对影响者内容的多模态分析

    A Multimodal Analysis of Influencer Content on Twitter. (arXiv:2309.03064v1 [cs.CL])

    [http://arxiv.org/abs/2309.03064](http://arxiv.org/abs/2309.03064)

    本研究通过引入一个新的Twitter数据集，结合文本和视觉信息，实验了多种预测模型，旨在自动检测影响者内容中的商业推广行为。

    

    影响者营销涉及一系列的策略，品牌与受欢迎的内容创作者（即影响者）合作，利用他们的影响力、信任度和对他们的受众的影响力，推广和背书产品或服务。由于影响者的粉丝在接收到真实的产品认可后更有可能购买产品，而不是明确的直接产品推广，个人观点与商业内容推广之间的界限经常模糊。这使得自动检测与影响者广告相关的监管合规违规行为（例如误导性广告或隐藏赞助）尤为困难。在这项工作中，我们（1）引入了一个新的Twitter（现在是X）数据集，其中包含15,998个影响者的帖子，分为商业和非商业类别，以协助自动检测商业影响者内容；（2）尝试了一系列结合文本和视觉信息的预测模型实验。

    Influencer marketing involves a wide range of strategies in which brands collaborate with popular content creators (i.e., influencers) to leverage their reach, trust, and impact on their audience to promote and endorse products or services. Because followers of influencers are more likely to buy a product after receiving an authentic product endorsement rather than an explicit direct product promotion, the line between personal opinions and commercial content promotion is frequently blurred. This makes automatic detection of regulatory compliance breaches related to influencer advertising (e.g., misleading advertising or hidden sponsorships) particularly difficult. In this work, we (1) introduce a new Twitter (now X) dataset consisting of 15,998 influencer posts mapped into commercial and non-commercial categories for assisting in the automatic detection of commercial influencer content; (2) experiment with an extensive set of predictive models that combine text and visual information 
    
[^8]: 《针对混合语言的人物感知生成模型》

    Persona-aware Generative Model for Code-mixed Language. (arXiv:2309.02915v1 [cs.CL])

    [http://arxiv.org/abs/2309.02915](http://arxiv.org/abs/2309.02915)

    本论文提出了一种针对混合语言的人物感知生成模型PARADOX，它能够生成类似于真实个体代码混合文本的文本。该模型以用户的人物形象为条件来编码对话，并生成不带单语参考数据的代码混合文本。模型还进行对齐，使生成的文本更接近真实的代码混合文本。这种方法在语义上更有意义，在语言上更有效。

    

    在在线社交网络和多语言社会中，代码混合和脚本混合非常普遍。然而，用户对于代码混合的偏好取决于用户的社会经济地位、人口统计信息和当地环境，而现有的生成模型在生成代码混合文本时大多忽视了这些因素。在这项工作中，我们首次尝试开发一种人物感知的生成模型，以生成类似于真实个体代码混合文本的文本。我们提出了一种针对代码混合生成的人物感知生成模型（PARADOX），这是一种基于Transformer编码器-解码器的新型模型，该模型在给定用户的人物形象的条件下对话进行编码，并生成不带单语参考数据的代码混合文本。我们提出了一个对齐模块，对生成的序列进行重新校准，使其更接近真实的代码混合文本。PARADOX生成的代码混合文本在语义上更有意义，在语言上更有效。

    Code-mixing and script-mixing are prevalent across online social networks and multilingual societies. However, a user's preference toward code-mixing depends on the socioeconomic status, demographics of the user, and the local context, which existing generative models mostly ignore while generating code-mixed texts. In this work, we make a pioneering attempt to develop a persona-aware generative model to generate texts resembling real-life code-mixed texts of individuals. We propose a Persona-aware Generative Model for Code-mixed Generation, PARADOX, a novel Transformer-based encoder-decoder model that encodes an utterance conditioned on a user's persona and generates code-mixed texts without monolingual reference data. We propose an alignment module that re-calibrates the generated sequence to resemble real-life code-mixed texts. PARADOX generates code-mixed texts that are semantically more meaningful and linguistically more valid. To evaluate the personification capabilities of PARAD
    
[^9]: 无所遗漏：改进的人道主义文档地理定位

    Leave no Place Behind: Improved Geolocation in Humanitarian Documents. (arXiv:2309.02914v1 [cs.CL])

    [http://arxiv.org/abs/2309.02914](http://arxiv.org/abs/2309.02914)

    本研究通过开发经过注释的资源，对命名实体识别工具进行微调，提出了一种地理编码方法，以改善人道主义文档的地理定位。结果表明，该方法提高了分类器性能，减轻了现有工具的偏见，对西方以外的资源需求更大。

    

    地理位置是人道主义应对的关键要素，描述了脆弱人口、正在发生的事件和可用资源。自然语言处理领域的最新进展可以帮助从人道部门产生的报告和文档的泛滥中提取重要信息。然而，现有的最先进的信息提取工具的性能和偏见是未知的。在这项工作中，我们开发了经过注释的资源，对流行的命名实体识别（NER）工具Spacy和roBERTa进行微调，以执行人道主义文本的地理标记。然后，我们提出了一个地理编码方法FeatureRank，将候选位置链接到GeoNames数据库。我们发现，人道主义领域的数据不仅改善了分类器的性能（F1 = 0.92），而且还减轻了现有工具的偏见，这些工具错误地偏向于西方国家的位置。因此，我们得出结论，需要更多来自非西方的资源。

    Geographical location is a crucial element of humanitarian response, outlining vulnerable populations, ongoing events, and available resources. Latest developments in Natural Language Processing may help in extracting vital information from the deluge of reports and documents produced by the humanitarian sector. However, the performance and biases of existing state-of-the-art information extraction tools are unknown. In this work, we develop annotated resources to fine-tune the popular Named Entity Recognition (NER) tools Spacy and roBERTa to perform geotagging of humanitarian texts. We then propose a geocoding method FeatureRank which links the candidate locations to the GeoNames database. We find that not only does the humanitarian-domain data improves the performance of the classifiers (up to F1 = 0.92), but it also alleviates some of the bias of the existing tools, which erroneously favor locations in the Western countries. Thus, we conclude that more resources from non-Western doc
    
[^10]: 关于构建仇恨言论检测数据集的挑战

    On the Challenges of Building Datasets for Hate Speech Detection. (arXiv:2309.02912v1 [cs.CL])

    [http://arxiv.org/abs/2309.02912](http://arxiv.org/abs/2309.02912)

    本研究旨在分析仇恨言论检测中的问题，并提出了一种综合框架来指导未来构建仇恨言论数据集的最佳实践。

    

    仇恨言论的检测被提出为自然语言处理的一个独立应用，并采用了不同的方法来识别目标群体、获取原始数据、定义标记过程、选择检测算法以及评估所需环境下的性能。然而，与其他下游任务不同，由于任务的高度主观性，仇恨言论的数据集缺乏大规模、精心筛选、具有普适性的特点。本文通过数据为中心的视角首先分析了围绕仇恨言论检测的问题。然后，我们提出了一个综合性框架，以仇恨言论对性少数群体的特定示例为例，概括了涵盖七个方面的数据创建流程。我们认为从未来构建仇恨言论数据集的最佳实践角度出发，从业者将受益于遵循这一框架。

    Detection of hate speech has been formulated as a standalone application of NLP and different approaches have been adopted for identifying the target groups, obtaining raw data, defining the labeling process, choosing the detection algorithm, and evaluating the performance in the desired setting. However, unlike other downstream tasks, hate speech suffers from the lack of large-sized, carefully curated, generalizable datasets owing to the highly subjective nature of the task. In this paper, we first analyze the issues surrounding hate speech detection through a data-centric lens. We then outline a holistic framework to encapsulate the data creation pipeline across seven broad dimensions by taking the specific example of hate speech towards sexual minorities. We posit that practitioners would benefit from following this framework as a form of best practice when creating hate speech datasets in the future.
    
[^11]: ViCGCN: 基于上下文化语言模型的社交媒体挖掘中文本图卷积网络

    ViCGCN: Graph Convolutional Network with Contextualized Language Models for Social Media Mining in Vietnamese. (arXiv:2309.02902v1 [cs.CL])

    [http://arxiv.org/abs/2309.02902](http://arxiv.org/abs/2309.02902)

    本研究提出了一种基于上下文化语言模型和图卷积网络的创新方法，能够解决越南社交媒体文本中的数据不平衡和噪声问题，并捕捉语义信息。

    

    社交媒体处理是自然语言处理中的一个基本任务，具有众多的应用。随着越南社交媒体和信息科学的快速发展，对越南社交媒体进行基于信息的挖掘变得至关重要。然而，现有的研究面临着一些重要的缺点，包括社交媒体平台上的数据不平衡和噪声数据。在越南社交媒体文本中，数据不平衡和噪声是需要解决的两个重要问题。图卷积网络可以通过利用数据的图结构来解决社交媒体文本分类中的数据不平衡和噪声问题。本研究提出了一种基于上下文化语言模型（PhoBERT）和基于图的方法（图卷积网络）的创新方法。特别地，所提出的方法ViCGCN通过联合训练上下文嵌入的能力和图卷积网络（GCN）的能力，捕捉越南社交媒体文本的语义信息。

    Social media processing is a fundamental task in natural language processing with numerous applications. As Vietnamese social media and information science have grown rapidly, the necessity of information-based mining on Vietnamese social media has become crucial. However, state-of-the-art research faces several significant drawbacks, including imbalanced data and noisy data on social media platforms. Imbalanced and noisy are two essential issues that need to be addressed in Vietnamese social media texts. Graph Convolutional Networks can address the problems of imbalanced and noisy data in text classification on social media by taking advantage of the graph structure of the data. This study presents a novel approach based on contextualized language model (PhoBERT) and graph-based method (Graph Convolutional Networks). In particular, the proposed approach, ViCGCN, jointly trained the power of Contextualized embeddings with the ability of Graph Convolutional Networks, GCN, to capture mor
    
[^12]: 一种没有语言特定训练数据的深度自然语言推理预测器

    A deep Natural Language Inference predictor without language-specific training data. (arXiv:2309.02887v1 [cs.CL])

    [http://arxiv.org/abs/2309.02887](http://arxiv.org/abs/2309.02887)

    本文介绍了一种处理目标语言句子对之间推理关系问题的新方法，该方法不需要特定语言的训练数据集。通过利用一个通用的翻译数据集和两个预训练模型的实例，模型可以在不同任务上展现出通用性，且在多个数据集上得到了验证。

    

    本文介绍了一种处理目标语言句子对之间推理关系（NLI）问题的自然语言处理技术，无需语言特定的训练数据集。我们利用一个通用的手动翻译数据集，并利用同一个预训练模型的两个实例——第一个用于生成源语言的句子嵌入，第二个在目标语言上进行微调以模仿第一个实例。这种技术称为知识蒸馏。我们将模型在机器翻译的斯坦福NLI测试数据集、机器翻译的多类型NLI测试数据集和手动翻译的RTE3-ITA测试数据集上进行了评估。我们还在不同任务上测试了所提出的体系结构，以实证地展示NLI任务的通用性。模型在意大利本地的ABSITA数据集上的情感分析、基于方面的情感分析和主题识别任务上进行了评估。

    In this paper we present a technique of NLP to tackle the problem of inference relation (NLI) between pairs of sentences in a target language of choice without a language-specific training dataset. We exploit a generic translation dataset, manually translated, along with two instances of the same pre-trained model - the first to generate sentence embeddings for the source language, and the second fine-tuned over the target language to mimic the first. This technique is known as Knowledge Distillation. The model has been evaluated over machine translated Stanford NLI test dataset, machine translated Multi-Genre NLI test dataset, and manually translated RTE3-ITA test dataset. We also test the proposed architecture over different tasks to empirically demonstrate the generality of the NLI task. The model has been evaluated over the native Italian ABSITA dataset, on the tasks of Sentiment Analysis, Aspect-Based Sentiment Analysis, and Topic Recognition. We emphasise the generality and explo
    
[^13]: 对于临床任务的大型语言模型的对齐

    Aligning Large Language Models for Clinical Tasks. (arXiv:2309.02884v1 [cs.CL])

    [http://arxiv.org/abs/2309.02884](http://arxiv.org/abs/2309.02884)

    该论文讨论了对于临床任务的大型语言模型(LLMs)的对齐问题，提出了一种名为"expand-guess-refine"的医学问答对齐策略，并通过组合使用指令调优和in-prompt策略等技术来提高LLMs的性能。

    

    大型语言模型(LLMs)展示出了令人瞩目的适应性，展示了它们在没有明确训练的任务中表现出色的能力。然而，尽管它们具有令人印象深刻的自然语言处理(NLP)能力，但有效地对齐LLM仍然是在特定临床应用中部署它们的关键挑战。生成具有事实准确内容的响应和从事非平凡推理步骤的能力对于LLMs能否适用于临床医学应用至关重要。采用一系列技术，包括指令调优和少量示例和思路链接等in-prompt策略，显著提高了LLMs的性能。我们提出的医学问答对齐策略被称为“ expand-guess-refine”，提供了一种参数和数据高效的解决方案。对这种方法的初步分析表明，它在问题子集上取得了出色的表现，得分为70.63％。

    Large Language Models (LLMs) have demonstrated remarkable adaptability, showcasing their capacity to excel in tasks for which they were not explicitly trained. However, despite their impressive natural language processing (NLP) capabilities, effective alignment of LLMs remains a crucial challenge when deploying them for specific clinical applications. The ability to generate responses with factually accurate content and to engage in non-trivial reasoning steps are crucial for the LLMs to be eligible for applications in clinical medicine. Employing a combination of techniques including instruction-tuning and in-prompt strategies like few-shot and chain of thought prompting has significantly enhanced the performance of LLMs. Our proposed alignment strategy for medical question-answering, known as 'expand-guess-refine', offers a parameter and data-efficient solution. A preliminary analysis of this method demonstrated outstanding performance, achieving a score of 70.63% on a subset of ques
    
[^14]: 通过学习上下文和回复之间的模式信息促进开放领域对话生成

    Promoting Open-domain Dialogue Generation through Learning Pattern Information between Contexts and Responses. (arXiv:2309.02823v1 [cs.CL])

    [http://arxiv.org/abs/2309.02823](http://arxiv.org/abs/2309.02823)

    本文通过学习上下文和回复之间的隐式模式信息提高了开放领域对话生成模型的质量，采用了改进的预训练模型的计划采样方法，使生成的回复更加生动和信息丰富。

    

    近年来，利用深度神经网络构建开放领域对话模型已成为热门话题。然而，这些模型生成的回复存在许多问题，如缺乏上下文化和容易生成缺乏信息内容的通用回复，严重影响用户体验。因此，许多研究试图引入更多信息到对话模型中，使生成的回复更加生动和信息丰富。与它们不同，本文通过学习训练样本中上下文和回复之间的隐式模式信息来提高生成的回复质量。首先，我们基于预训练语言模型（即GPT-2）构建了一个开放领域对话模型。然后，提出了一种改进的预训练模型的计划采样方法，通过该方法，在训练阶段可以利用生成的回复来指导回复生成，同时避免暴露偏差问题。更重要的是，我们将这种方法与传统的基于最大似然估计的方法进行了比较，并表明了我们方法的优势。

    Recently, utilizing deep neural networks to build the opendomain dialogue models has become a hot topic. However, the responses generated by these models suffer from many problems such as responses not being contextualized and tend to generate generic responses that lack information content, damaging the user's experience seriously. Therefore, many studies try introducing more information into the dialogue models to make the generated responses more vivid and informative. Unlike them, this paper improves the quality of generated responses by learning the implicit pattern information between contexts and responses in the training samples. In this paper, we first build an open-domain dialogue model based on the pre-trained language model (i.e., GPT-2). And then, an improved scheduled sampling method is proposed for pre-trained models, by which the responses can be used to guide the response generation in the training phase while avoiding the exposure bias problem. More importantly, we de
    
[^15]: 基于代理模型的行人地震疏散仿真：以黎巴嫩贝鲁特为例

    Agent-based simulation of pedestrians' earthquake evacuation; application to Beirut, Lebanon. (arXiv:2309.02812v1 [cs.CL])

    [http://arxiv.org/abs/2309.02812](http://arxiv.org/abs/2309.02812)

    本研究开发了一个跨学科的代理模型，用于模拟城市规模的地震期间行人疏散，以黎巴嫩贝鲁特为例。模型综合考虑了地震危险、物理易损性以及个体行为和活动能力。这对于定量风险评估研究来说是重要而创新的。

    

    大多数地震风险评估方法着重于估计建筑环境的损失和相应的社会经济损失，而没有充分考虑社会风险因素。然而，人类行为是预测地震对人类影响的关键因素，因此，在定量风险评估研究中包含它是重要的。本研究采用一种跨学科的方法，利用代理模型模拟城市规模的行人地震疏散。该模型整合了地震危险、物理易损性以及个体行为和活动能力。模拟器应用于黎巴嫩贝鲁特的案例。黎巴嫩位于黎凡特断裂带系统的核心地区，该断裂带已经发生过多次Mw>7的地震，最近一次是在1759年。黎巴嫩是地中海地区地震风险最高的国家之一，这是由于建筑物的高地震易损性以及缺乏强制性的建筑规定所致。

    Most seismic risk assessment methods focus on estimating the damages to the built environment and the consequent socioeconomic losses without fully taking into account the social aspect of risk. Yet, human behaviour is a key element in predicting the human impact of an earthquake, therefore, it is important to include it in quantitative risk assessment studies. In this study, an interdisciplinary approach simulating pedestrians' evacuation during earthquakes at the city scale is developed using an agent-based model. The model integrates the seismic hazard, the physical vulnerability as well as individuals' behaviours and mobility. The simulator is applied to the case of Beirut, Lebanon. Lebanon is at the heart of the Levant fault system that has generated several Mw>7 earthquakes, the latest being in 1759. It is one of the countries with the highest seismic risk in the Mediterranean region. This is due to the high seismic vulnerability of the buildings due to the absence of mandatory s
    
[^16]: Norm调整：大型语言模型的高性能低比特量化

    Norm Tweaking: High-performance Low-bit Quantization of Large Language Models. (arXiv:2309.02784v1 [cs.LG])

    [http://arxiv.org/abs/2309.02784](http://arxiv.org/abs/2309.02784)

    本文介绍了一种称为“norm tweaking”的技术，通过调整量化的激活分布来实现高精度的低比特量化，以提高大型语言模型的压缩性能。

    

    随着大型语言模型（LLMs）的尺寸不断增大，在保持精度的前提下进行模型压缩已成为部署的关键挑战。虽然一些量化方法，如GPTQ，在实现可接受的4比特权重量化方面取得了进展，但尝试更低位的量化往往导致严重的性能降低。在本文中，我们引入了一种称为“norm tweaking”的技术，它可以作为当前PTQ方法的插件，实现高精度和成本高效。我们的方法受到一项观察的启示，即使调整量化的激活分布以与其浮点对应物匹配，也可以恢复LLMs的准确性。为了实现这一点，我们精心设计了一个调整策略，包括生成校准数据和通道距离约束，以更新归一化层的权重以获得更好的泛化性能。我们在各种数据集上进行了大量实验，使用了几个开源的LLMs。

    As the size of large language models (LLMs) continues to grow, model compression without sacrificing accuracy has become a crucial challenge for deployment. While some quantization methods, such as GPTQ, have made progress in achieving acceptable 4-bit weight-only quantization, attempts at lower bit quantization often result in severe performance degradation. In this paper, we introduce a technique called norm tweaking, which can be used as a plugin in current PTQ methods to achieve high precision while being cost-efficient. Our approach is inspired by the observation that rectifying the quantized activation distribution to match its float counterpart can readily restore accuracy for LLMs. To achieve this, we carefully design a tweaking strategy that includes calibration data generation and channel-wise distance constraint to update the weights of normalization layers for better generalization. We conduct extensive experiments on various datasets using several open-sourced LLMs. Our me
    
[^17]: GRASS: 语音语义理解统一生成模型

    GRASS: Unified Generation Model for Speech Semantic Understanding. (arXiv:2309.02780v1 [cs.CL])

    [http://arxiv.org/abs/2309.02780](http://arxiv.org/abs/2309.02780)

    本文介绍了一个统一的端到端框架，通过指令微调技术实现了语音语义理解任务。实验证明该模型在微调下游任务后明显优于最先进的模型，并在零样本和少样本场景中取得了竞争性的性能。

    

    本文通过引入一个统一的端到端框架，探索了语音语义理解的指令微调技术，该框架根据与任务相关的提示为音频数据生成语义标签。我们使用大量多样的数据进行预训练，其中指令-语音对是通过文本转语音系统构建的。大量实验证明，我们提出的模型在微调下游任务后明显优于最先进的模型。此外，所提出的模型在零样本和少样本场景中实现了竞争性的性能。为了促进未来在语音到语义任务的指令微调方面的研究，我们发布了我们的指令数据集和代码。

    This paper explores the instruction fine-tuning technique for speech semantic understanding by introducing a unified end-to-end (E2E) framework that generates semantic labels conditioned on a task-related prompt for audio data. We pre-train the model using large and diverse data, where instruction-speech pairs are constructed via a text-to-speech (TTS) system. Extensive experiments demonstrate that our proposed model significantly outperforms state-of-the-art (SOTA) models after fine-tuning downstream tasks. Furthermore, the proposed model achieves competitive performance in zero-shot and few-shot scenarios. To facilitate future work on instruction fine-tuning for speech-to-semantic tasks, we release our instruction dataset and code.
    
[^18]: 通过动态温度采样改进代码生成

    Improving Code Generation by Dynamic Temperature Sampling. (arXiv:2309.02772v1 [cs.SE])

    [http://arxiv.org/abs/2309.02772](http://arxiv.org/abs/2309.02772)

    通过动态温度采样的AdapT方法，我们提出了一种针对代码生成的新的解码策略，通过调整温度系数来解决难以预测的代码标记，并取得了显著效果。

    

    最近，大型语言模型（LLM）在代码生成方面取得了令人印象深刻的结果。然而，现有的解码策略是针对自然语言生成设计的，忽视了自然语言和编程语言之间的差异。由于这个疏忽，如何设计更好的代码生成解码策略仍然是一个未解决的问题。在本文中，我们进行了第一次系统研究，探索了一种专门用于代码生成的解码策略。通过对代码标记丢失分布的分析，我们发现代码标记可以分为两类：难以预测的挑战性标记和易于推断的自信标记。其中，挑战性标记主要出现在代码块的开头。受到上述发现的启发，我们提出了一种简单而有效的方法：自适应温度（AdapT）采样，它在解码不同的标记时动态调整温度系数。我们在采样挑战性标记时应用较大的温度值。同时，在采样自信标记时应用较小的温度值。

    Recently, Large Language Models (LLMs) have shown impressive results in code generation. However, existing decoding strategies are designed for Natural Language (NL) generation, overlooking the differences between NL and programming languages (PL). Due to this oversight, a better decoding strategy for code generation remains an open question. In this paper, we conduct the first systematic study to explore a decoding strategy specialized in code generation. With an analysis of loss distributions of code tokens, we find that code tokens can be divided into two categories: challenging tokens that are difficult to predict and confident tokens that can be easily inferred. Among them, the challenging tokens mainly appear at the beginning of a code block. Inspired by the above findings, we propose a simple yet effective method: Adaptive Temperature (AdapT) sampling, which dynamically adjusts the temperature coefficient when decoding different tokens. We apply a larger temperature when samplin
    
[^19]: 用细分标准特定方法进行增强培训的自动化作文评分

    Rubric-Specific Approach to Automated Essay Scoring with Augmentation Training. (arXiv:2309.02740v1 [cs.CL])

    [http://arxiv.org/abs/2309.02740](http://arxiv.org/abs/2309.02740)

    本文提出一种用于自动评分的细分标准特定方法，通过增强培训和测试数据来学习之前研究中忽视的特征和功能，达到了最新性能。

    

    相比于传统的基于规则和特征工程的解决方案，基于神经网络的主观答案自动评估方法表现出更优异的性能和效率。然而，最近的研究并没有妥善考虑到在模型训练和验证过程中对于自动化作文评分至关重要的细分标准。在本文中，我们提出了一系列数据增强操作，通过训练和测试一个自动评分模型，学习了之前研究中忽视的特征和功能，同时在自动化学生评估奖数据集中取得了最新的性能。

    Neural based approaches to automatic evaluation of subjective responses have shown superior performance and efficiency compared to traditional rule-based and feature engineering oriented solutions. However, it remains unclear whether the suggested neural solutions are sufficient replacements of human raters as we find recent works do not properly account for rubric items that are essential for automated essay scoring during model training and validation. In this paper, we propose a series of data augmentation operations that train and test an automated scoring model to learn features and functions overlooked by previous works while still achieving state-of-the-art performance in the Automated Student Assessment Prize dataset.
    
[^20]: HC3 Plus：一个语义不变的人类ChatGPT对比语料库

    HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus. (arXiv:2309.02731v1 [cs.CL])

    [http://arxiv.org/abs/2309.02731](http://arxiv.org/abs/2309.02731)

    本文介绍了HC3 Plus，一个语义不变的人类ChatGPT对比语料库。与以往的工作相比，该语料库考虑了更多类型的任务，包括语义不变任务。研究发现，在语义不变任务中检测模型生成的文本更加困难。通过大量任务指令微调和Tk-instruct，建立了一个更强大的模型。

    

    ChatGPT因其出色的性能而引起了人们的广泛关注，但人们对其潜在风险，尤其是对AI生成内容（AIGC）的检测越来越关注，这对未经训练的人类来说往往很难识别。目前用于检测ChatGPT生成文本的数据集主要集中在问答方面，但往往忽视了具有语义不变性的任务，如摘要、翻译和改写。我们的研究表明，在语义不变任务上检测模型生成的文本更加困难。为了填补这一空白，我们引入了一个更广泛、更全面的数据集，考虑了比以前的工作更多类型的任务，包括语义不变任务。此外，经过大量任务指令微调的模型表现出很强的性能。基于以前的成功，我们进一步指导微调了Tk-instruct，并构建了一个更强大的模型。

    ChatGPT has gained significant interest due to its impressive performance, but people are increasingly concerned about its potential risks, particularly around the detection of AI-generated content (AIGC), which is often difficult for untrained humans to identify. Current datasets utilized for detecting ChatGPT-generated text primarily center around question-answering, yet they tend to disregard tasks that possess semantic-invariant properties, such as summarization, translation, and paraphrasing. Our primary studies demonstrate that detecting model-generated text on semantic-invariant tasks is more difficult. To fill this gap, we introduce a more extensive and comprehensive dataset that considers more types of tasks than previous work, including semantic-invariant tasks. In addition, the model after a large number of task instruction fine-tuning shows a strong powerful performance. Owing to its previous success, we further instruct fine-tuning Tk-instruct and built a more powerful det
    
[^21]: 用于自动开放领域科学假设发现的大语言模型

    Large Language Models for Automated Open-domain Scientific Hypotheses Discovery. (arXiv:2309.02726v1 [cs.CL])

    [http://arxiv.org/abs/2309.02726](http://arxiv.org/abs/2309.02726)

    这项研究提出了用于社会科学学术假设发现的第一个自然语言处理数据集，旨在开发一个系统，能够基于原始网络语料库自动生成有效、新颖且对人类研究者有帮助的假设。

    

    当科学家观察世界并试图提出解释这些观察结果的假设时，假设归纳被认为是主要的推理类型。过去关于假设归纳的研究存在以下限制：（1）数据集的观察注释不是原始的网络语料库，而是手动选择的句子（导致了一个封闭领域的设置）；（2）实际的假设注释主要是常识知识，使得任务不太具有挑战性。在本文中，我们提出了第一个用于社会科学学术假设发现的自然语言处理数据集，包含50篇发表在顶级社会科学期刊上的最新论文。数据集中还收集了开发论文中的假设所需的原始网络语料库，最终目标是创建一个系统，仅通过一堆原始网络语料库就可以自动生成有效、新颖且对人类研究者有帮助的假设。这个新数据集可以解决以前关于假设归纳的研究所面临的限制问题。

    Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction has a limited setting that (1) the observation annotations of the dataset are not raw web corpus but are manually selected sentences (resulting in a close-domain setting); and (2) the ground truth hypotheses annotations are mostly commonsense knowledge, making the task less challenging. In this work, we propose the first NLP dataset for social science academic hypotheses discovery, consisting of 50 recent papers published in top social science journals. Raw web corpora that are necessary for developing hypotheses in the published papers are also collected in the dataset, with the final goal of creating a system that automatically generates valid, novel, and helpful (to human researchers) hypotheses, given only a pile of raw web corpora. The new dataset can tackle the previou
    
[^22]: 希伯来语侮辱性语料库及BERT模型的检测

    Offensive Hebrew Corpus and Detection using BERT. (arXiv:2309.02724v1 [cs.CL])

    [http://arxiv.org/abs/2309.02724](http://arxiv.org/abs/2309.02724)

    本研究提出了一个新的希伯来语侮辱性语料库，并使用两个希伯来语BERT模型（HeBERT和AlephBERT）进行了微调。我们观察到，我们的数据结合D_OLaH可以提高HeBERT模型的性能2%。此外，我们的数据对AlephBERT模型也具有一定的泛化性能。

    

    侮辱性语言检测在许多语言中已经有很多研究，但在低资源语言(如希伯来语)中仍有所滞后。本文介绍了一个新的希伯来语侮辱性语料库，从Twitter上收集了15881条推文。每条推文都由阿拉伯-希伯来双语人士标记为五个类别(辱骂、仇恨、暴力、色情或非侮辱性)。标注过程具有挑战性，因为每个标注者都需要熟悉以色列的文化、政治和实践，以理解每条推文的背景。我们使用提出的数据集和另一个已发布的数据集对两个希伯来语BERT模型(HeBERT和AlephBERT)进行微调。我们观察到，我们的数据与D_OLaH结合后，提高了HeBERT模型2%的性能。在我们的数据上对AlephBERT进行微调并在D_OLaH上进行测试，准确率达到69%，而在D_OLaH上进行微调并在我们的数据上进行测试时，准确率为57%，这可能表明我们的数据具有一定的泛化性能。

    Offensive language detection has been well studied in many languages, but it is lagging behind in low-resource languages, such as Hebrew. In this paper, we present a new offensive language corpus in Hebrew. A total of 15,881 tweets were retrieved from Twitter. Each was labeled with one or more of five classes (abusive, hate, violence, pornographic, or none offensive) by Arabic-Hebrew bilingual speakers. The annotation process was challenging as each annotator is expected to be familiar with the Israeli culture, politics, and practices to understand the context of each tweet. We fine-tuned two Hebrew BERT models, HeBERT and AlephBERT, using our proposed dataset and another published dataset. We observed that our data boosts HeBERT performance by 2% when combined with D_OLaH. Fine-tuning AlephBERT on our data and testing on D_OLaH yields 69% accuracy, while fine-tuning on D_OLaH and testing on our data yields 57% accuracy, which may be an indication to the generalizability our data offer
    
[^23]: HAE-RAE Bench: 评估语言模型对韩国知识的表现

    HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models. (arXiv:2309.02706v1 [cs.CL])

    [http://arxiv.org/abs/2309.02706](http://arxiv.org/abs/2309.02706)

    HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。

    

    在大规模预训练的语言模型(LLMs)在各种任务中展现出了显著的能力，但是对非英语语言的关注在这个领域的研究中有限。为了弥补这一空白并评估语言模型在韩语语言和文化方面的熟练程度，我们提出了HAE-RAE Bench，在词汇、历史和一般知识等6个任务上进行评估。我们对语言模型在这个基准上的评估突出了使用大型特定语言模型(LLSMs)与像GPT-3.5这样的全面通用模型相比的潜在优势。值得注意的是，我们的研究发现，比GPT-3.5约小13倍的模型，可以在语言特定知识检索方面展现出类似的性能水平。这一观察强调了在训练专业级语言特定模型时同质语料库的重要性。相反，当这些较小的模型在......

    Large Language Models (LLMs) pretrained on massive corpora exhibit remarkable capabilities across a wide range of tasks, however, the attention given to non-English languages has been limited in this field of research. To address this gap and assess the proficiency of language models in the Korean language and culture, we present HAE-RAE Bench, covering 6 tasks including vocabulary, history, and general knowledge. Our evaluation of language models on this benchmark highlights the potential advantages of employing Large Language-Specific Models(LLSMs) over a comprehensive, universal model like GPT-3.5. Remarkably, our study reveals that models approximately 13 times smaller than GPT-3.5 can exhibit similar performance levels in terms of language-specific knowledge retrieval. This observation underscores the importance of homogeneous corpora for training professional-level language-specific models. On the contrary, we also observe a perplexing performance dip in these smaller LMs when th
    
[^24]: 证明LLM对抗敌对提示的安全性

    Certifying LLM Safety against Adversarial Prompting. (arXiv:2309.02705v1 [cs.CL])

    [http://arxiv.org/abs/2309.02705](http://arxiv.org/abs/2309.02705)

    本研究提出了首个具有可验证安全保证的框架——消除和检查，用于对抗敌对提示。通过逐个消除标记并使用安全过滤器检查生成的子序列，确保任何敌对修改的有害输入提示都能被正确标识为有害。

    

    为了确保语言模型的输出安全，公开使用的大型语言模型（LLM）引入了所谓的“模型对齐”防护措施。一个对齐的语言模型应该拒绝用户的请求生成有害内容。然而，这种安全措施容易受到敌对提示的攻击，敌对提示包含恶意设计的标记序列，以规避模型的安全防护并导致生成有害内容。在这项工作中，我们介绍了可验证安全保证的第一个对抗敌对提示的框架——消除和检查。我们逐个消除标记，并使用安全过滤器检查生成的子序列。如果安全过滤器检测到任何子序列或输入提示有害，我们的过程将将输入提示标记为有害。这保证了对于某个特定大小的有害输入提示的任何敌对修改也将被标记为有害。我们对抗三种攻击模式：i)敌对后缀，即附加敌对序列…

    Large language models (LLMs) released for public use incorporate guardrails to ensure their output is safe, often referred to as "model alignment." An aligned language model should decline a user's request to produce harmful content. However, such safety measures are vulnerable to adversarial prompts, which contain maliciously designed token sequences to circumvent the model's safety guards and cause it to produce harmful content. In this work, we introduce erase-and-check, the first framework to defend against adversarial prompts with verifiable safety guarantees. We erase tokens individually and inspect the resulting subsequences using a safety filter. Our procedure labels the input prompt as harmful if any subsequences or the input prompt are detected as harmful by the filter. This guarantees that any adversarial modification of a harmful prompt up to a certain size is also labeled harmful. We defend against three attack modes: i) adversarial suffix, which appends an adversarial seq
    
[^25]: 视觉和语言模型中短语定位和任务表现的联合研究

    A Joint Study of Phrase Grounding and Task Performance in Vision and Language Models. (arXiv:2309.02691v1 [cs.CL])

    [http://arxiv.org/abs/2309.02691](http://arxiv.org/abs/2309.02691)

    这项研究提出了一个框架来研究视觉和语言模型中短语定位和任务性能之间的关系，并且通过验证实验发现了当代模型在短语定位和任务求解方面的不一致性。

    

    在需要对视觉背景中的自然语言进行推理的任务中，关键是将单词和短语与图像区域联系起来。然而，即使通常预期以有助于泛化的方式解决任务，观察到当代模型中的这种定位也是复杂的。我们提出了一个框架来共同研究任务执行和短语定位，并提出了三个基准来研究两者之间的关系。我们的结果表明，当代模型在定位短语和解决任务的能力之间存在不一致性。我们展示了如何通过对定位标注进行强制性训练来解决这个问题，并分析了它所创建的动态。代码可在https://github.com/lil-lab/phrase_grounding获得。

    Key to tasks that require reasoning about natural language in visual contexts is grounding words and phrases to image regions. However, observing this grounding in contemporary models is complex, even if it is generally expected to take place if the task is addressed in a way that is conductive to generalization. We propose a framework to jointly study task performance and phrase grounding, and propose three benchmarks to study the relation between the two. Our results show that contemporary models demonstrate inconsistency between their ability to ground phrases and solve tasks. We show how this can be addressed through brute-force training on ground phrasing annotations, and analyze the dynamics it creates. Code and at available at https://github.com/lil-lab/phrase_grounding.
    
[^26]: 针对大型语言模型的零资源幻觉预防

    Zero-Resource Hallucination Prevention for Large Language Models. (arXiv:2309.02654v1 [cs.CL])

    [http://arxiv.org/abs/2309.02654](http://arxiv.org/abs/2309.02654)

    本论文提出了一种零资源幻觉预防方法，通过评估模型对输入指令中概念的熟悉程度，在遇到不熟悉的概念时不生成响应，从而解决了大型语言模型中的幻觉问题。

    

    在各个领域中广泛使用大型语言模型(LLMs)引起了“幻觉”问题的关注，这指的是LLMs生成事实不准确或没有根据的信息的情况。现有的语言助手中幻觉检测技术依赖于复杂的模糊、基于自由语言的思维链条(CoT)技术或基于参数的方法，存在解释性问题。此外，识别生成后幻觉的方法无法预防其发生，并且由于指令格式和模型风格的影响，性能不一致。在本文中，我们介绍一种新颖的预检测自我评估技术，称为{\method}，它专注于评估模型对输入指令中概念的熟悉程度，并在遇到不熟悉的概念时不生成响应。这种方法模拟了人类能够在没有把握时不作回应的能力。

    The prevalent use of large language models (LLMs) in various domains has drawn attention to the issue of "hallucination," which refers to instances where LLMs generate factually inaccurate or ungrounded information. Existing techniques for hallucination detection in language assistants rely on intricate fuzzy, specific free-language-based chain of thought (CoT) techniques or parameter-based methods that suffer from interpretability issues. Additionally, the methods that identify hallucinations post-generation could not prevent their occurrence and suffer from inconsistent performance due to the influence of the instruction format and model style. In this paper, we introduce a novel pre-detection self-evaluation technique, referred to as {\method}, which focuses on evaluating the model's familiarity with the concepts present in the input instruction and withholding the generation of response in case of unfamiliar concepts. This approach emulates the human ability to refrain from respond
    
[^27]: Epi-Curriculum: 用于神经机器翻译中低资源领域自适应的分集课程学习

    Epi-Curriculum: Episodic Curriculum Learning for Low-Resource Domain Adaptation in Neural Machine Translation. (arXiv:2309.02640v1 [cs.LG])

    [http://arxiv.org/abs/2309.02640](http://arxiv.org/abs/2309.02640)

    Epi-Curriculum是一种用于神经机器翻译中低资源领域自适应的方法，通过分集训练和去噪的课程学习，提高了模型对领域变化的鲁棒性和适应性。

    

    神经机器翻译（NMT）模型非常成功，但在限定数量的数据上进行新领域的翻译时，其性能仍然较差。本文提出了一种新颖的方法Epi-Curriculum，用于解决低资源领域自适应（DA），它包含一个新的分集训练框架和去噪的课程学习。我们的分集训练框架通过周期性地将编码器/解码器暴露给经验不足的解码器/编码器，增强了模型对领域变化的鲁棒性。去噪的课程学习通过逐步引导学习过程从简单到更复杂的任务，进一步提高了模型的适应性。在英德和英罗马尼亚翻译方向上的实验证明：（i）Epi-Curriculum在已见和未见领域中提高了模型的鲁棒性和适应性；（ii）我们的分集训练框架增强了编码器和解码器对领域变化的鲁棒性。

    Neural Machine Translation (NMT) models have become successful, but their performance remains poor when translating on new domains with a limited number of data. In this paper, we present a novel approach Epi-Curriculum to address low-resource domain adaptation (DA), which contains a new episodic training framework along with denoised curriculum learning. Our episodic training framework enhances the model's robustness to domain shift by episodically exposing the encoder/decoder to an inexperienced decoder/encoder. The denoised curriculum learning filters the noised data and further improves the model's adaptability by gradually guiding the learning process from easy to more difficult tasks. Experiments on English-German and English-Romanian translation show that: (i) Epi-Curriculum improves both model's robustness and adaptability in seen and unseen domains; (ii) Our episodic training framework enhances the encoder and decoder's robustness to domain shift.
    
[^28]: 缩放自回归多模态模型: 预训练和指令调整

    Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning. (arXiv:2309.02591v1 [cs.LG])

    [http://arxiv.org/abs/2309.02591](http://arxiv.org/abs/2309.02591)

    CM3Leon是一个缩放自回归多模态语言模型，通过预训练和指令调整实现了高质量的文本和图像的生成和填充，达到了文本到图像生成方面的最先进性能，而计算资源开销较小。

    

    我们提出了CM3Leon（发音为"Chameleon"），一个检索增强的基于令牌的解码器多模态语言模型，能够生成和填充文本和图像。CM3Leon使用了CM3多模态架构，同时展示了在更多样化的指令风格数据上的扩展和调整的巨大优势。它是第一个使用从纯文本语言模型中改编的配方进行训练的多模态模型，包括大规模的检索增强预训练阶段和第二个多任务监督微调阶段。它也是一个通用模型，可以进行文本到图像和图像到文本的生成，使我们能够引入自包含的对比解码方法，产生高质量的输出。广泛的实验表明，这个配方对于多模态模型非常有效。CM3Leon在文本到图像的生成方面取得了最先进的性能，训练计算量比类似方法少5倍（零样本MS-COCO FID）

    We present CM3Leon (pronounced "Chameleon"), a retrieval-augmented, token-based, decoder-only multi-modal language model capable of generating and infilling both text and images. CM3Leon uses the CM3 multi-modal architecture but additionally shows the extreme benefits of scaling up and tuning on more diverse instruction-style data. It is the first multi-modal model trained with a recipe adapted from text-only language models, including a large-scale retrieval-augmented pre-training stage and a second multi-task supervised fine-tuning (SFT) stage. It is also a general-purpose model that can do both text-to-image and image-to-text generation, allowing us to introduce self-contained contrastive decoding methods that produce high-quality outputs. Extensive experiments demonstrate that this recipe is highly effective for multi-modal models. CM3Leon achieves state-of-the-art performance in text-to-image generation with 5x less training compute than comparable methods (zero-shot MS-COCO FID o
    
[^29]: 自动化机器翻译的行为测试

    Automating Behavioral Testing in Machine Translation. (arXiv:2309.02553v1 [cs.CL])

    [http://arxiv.org/abs/2309.02553](http://arxiv.org/abs/2309.02553)

    本文提出了一种利用大型语言模型自动生成源句子的方法，以测试机器翻译模型在多种情况下的行为。通过对多个机器翻译系统应用该方法，发现在测试结果与传统准确率度量存在差异的情况下，仍可观察到一致的趋势。

    

    NLP中的行为测试通过分析输入-输出行为来细粒度评估系统的语言能力。然而，目前关于机器翻译中行为测试的研究仅限于手工设计的测试范围有限、涵盖的语言种类也有限。为了解决这一限制，我们提出利用大型语言模型生成多样化的源句子，以测试机器翻译模型在不同情况下的行为。然后，我们可以使用相同的语言模型生成备选集，以验证机器翻译模型是否表现出预期的行为。我们的方法旨在使机器翻译系统的行为测试实际可行，同时只需要最少的人力投入。在实验中，我们将提出的评估框架应用于多个可用的机器翻译系统，结果显示，尽管总体上通过率与传统准确率度量可观察到的趋势相符，但仍存在差异。

    Behavioral testing in NLP allows fine-grained evaluation of systems by examining their linguistic capabilities through the analysis of input-output behavior. Unfortunately, existing work on behavioral testing in Machine Translation (MT) is currently restricted to largely handcrafted tests covering a limited range of capabilities and languages. To address this limitation, we propose to use Large Language Models (LLMs) to generate a diverse set of source sentences tailored to test the behavior of MT models in a range of situations. We can then verify whether the MT model exhibits the expected behavior through matching candidate sets that are also generated using LLMs. Our approach aims to make behavioral testing of MT systems practical while requiring only minimal human effort. In our experiments, we apply our proposed evaluation framework to assess multiple available MT systems, revealing that while in general pass-rates follow the trends observable from traditional accuracy-based metri
    
[^30]: 语音规则记忆的最小有效理论：捕捉由语音错误引起的局部关联

    Minimal Effective Theory for Phonotactic Memory: Capturing Local Correlations due to Errors in Speech. (arXiv:2309.02466v1 [eess.AS])

    [http://arxiv.org/abs/2309.02466](http://arxiv.org/abs/2309.02466)

    这是一个关于语音规则记忆的最小有效理论的研究，通过构建一个局部连接的张量网络模型，利用局部语音相关性来促进口语单词的学习，并提供了可能产生的错误的层次结构。

    

    口语语言的演化受限于语音经济性，这取决于人类口腔的结构等因素。这导致了口语单词中的局部语音相关性。我们在这里通过构建一个局部连接的张量网络模型来证明，这些局部关联通过减少口语单词的信息内容来促进口语单词的学习。该模型受到了许多体物理学中使用的类似变分模型的启发，利用这些局部语音相关性来促进口语单词的学习。因此，该模型是语音记忆的最小模型，"学习发音"和"学习一个单词"是同一回事。其结果是，学会产生对目标语言来说在语音上合理的新单词；并且提供了在语音操作过程中可能产生的最有可能的错误的层次结构。我们对拉丁语和土耳其语单词进行了模型测试。（代码可在Gi上找到）

    Spoken language evolves constrained by the economy of speech, which depends on factors such as the structure of the human mouth. This gives rise to local phonetic correlations in spoken words. Here we demonstrate that these local correlations facilitate the learning of spoken words by reducing their information content. We do this by constructing a locally-connected tensor-network model, inspired by similar variational models used for many-body physics, which exploits these local phonetic correlations to facilitate the learning of spoken words. The model is therefore a minimal model of phonetic memory, where "learning to pronounce" and "learning a word" are one and the same. A consequence of which is the learned ability to produce new words which are phonetically reasonable for the target language; as well as providing a hierarchy of the most likely errors that could be produced during the action of speech. We test our model against Latin and Turkish words. (The code is available on Gi
    
[^31]: 面向增材制造的基础AI模型：用于G代码调试、操作和理解的语言模型

    Towards Foundational AI Models for Additive Manufacturing: Language Models for G-Code Debugging, Manipulation, and Comprehension. (arXiv:2309.02465v1 [cs.SE])

    [http://arxiv.org/abs/2309.02465](http://arxiv.org/abs/2309.02465)

    本文针对三维打印的G代码文件提出了六种基础大型语言模型（LLMs），通过评估它们在G代码调试和操作方面的性能，包括错误检测和修正以及几何变换等。结果表明这些模型具有潜力应用于增材制造领域。

    

    三维打印或增材制造是一项革命性的技术，它可以从数字模型中创建物理对象。然而，三维打印的质量和准确性取决于G代码的正确性和效率，G代码是一种低级数控编程语言，指导三维打印机如何移动和挤出材料。调试G代码是一项具有挑战性的任务，它需要对G代码格式和所打印零件的几何形状的语法和语义理解。在本文中，我们对六种最先进的基础大型语言模型（LLMs）进行了首次广泛评估，用于理解和调试三维打印的G代码文件。我们设计了有效的提示，使预训练的LLMs能够理解和操作G代码，并在G代码调试和操作的各个方面，包括检测和修正常见错误以及执行几何变换方面测试了它们的性能。我们对它们的优点进行了分析。

    3D printing or additive manufacturing is a revolutionary technology that enables the creation of physical objects from digital models. However, the quality and accuracy of 3D printing depend on the correctness and efficiency of the G-code, a low-level numerical control programming language that instructs 3D printers how to move and extrude material. Debugging G-code is a challenging task that requires a syntactic and semantic understanding of the G-code format and the geometry of the part to be printed. In this paper, we present the first extensive evaluation of six state-of-the-art foundational large language models (LLMs) for comprehending and debugging G-code files for 3D printing. We design effective prompts to enable pre-trained LLMs to understand and manipulate G-code and test their performance on various aspects of G-code debugging and manipulation, including detection and correction of common errors and the ability to perform geometric transformations. We analyze their strength
    
[^32]: 通过下采样的声学表示进行纯文本领域自适应的端到端语音识别

    Text-Only Domain Adaptation for End-to-End Speech Recognition through Down-Sampling Acoustic Representation. (arXiv:2309.02459v1 [cs.SD])

    [http://arxiv.org/abs/2309.02459](http://arxiv.org/abs/2309.02459)

    本文提出了一种通过下采样声学表示来对齐文本模态的方法，以实现纯文本领域自适应的端到端语音识别。实验结果表明，该方法在新领域数据上取得了良好的效果。

    

    将两种形式的资料，声音和文本，映射到共享的表示空间中，是一种利用纯文本数据提高端到端自动语音识别(ASR)性能的研究课题。然而，声音和文本的表示长度不一致。虽然先前的方法通过上采样文本表示来与音频模态进行对齐，但可能不匹配预期的实际持续时间。在本文中，我们提出了通过下采样声学表示来与文本模态对齐的新型表示匹配策略。通过引入连续积分-火炮 (CIF) 模块生成与标记长度一致的声学表示，我们的ASR模型可以更好地从两种模态中学习统一的表示，从而能够使用目标领域的纯文本数据进行领域自适应。新领域数据的实验结果证明了所提方法的有效性。

    Mapping two modalities, speech and text, into a shared representation space, is a research topic of using text-only data to improve end-to-end automatic speech recognition (ASR) performance in new domains. However, the length of speech representation and text representation is inconsistent. Although the previous method up-samples the text representation to align with acoustic modality, it may not match the expected actual duration. In this paper, we proposed novel representations match strategy through down-sampling acoustic representation to align with text modality. By introducing a continuous integrate-and-fire (CIF) module generating acoustic representations consistent with token length, our ASR model can learn unified representations from both modalities better, allowing for domain adaptation using text-only data of the target domain. Experiment results of new domain data demonstrate the effectiveness of the proposed method.
    
[^33]: 基于上下文嵌入的替代词语义变化检测

    Substitution-based Semantic Change Detection using Contextual Embeddings. (arXiv:2309.02403v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.02403](http://arxiv.org/abs/2309.02403)

    使用基于上下文嵌入的替代词来测量语义变化，不仅直观易懂，而且存储效率更高，在一些数据集中表现更好，并且能够进行更细致的变化分析。

    

    迄今为止，使用上下文嵌入的方法在测量语义变化方面一直难以改进比简单的仅依赖于静态词向量的技术。此外，之前提出的许多方法在可扩展性和解释性方面存在问题。我们提出了一种简化的方法，利用上下文嵌入测量语义变化，仅依赖于对掩码词最可能的替代词。这种方法不仅直接解释，而且在存储方面更为高效，在最常引用的数据集中表现优越，在变化解释方面比静态词向量更为细致。

    Measuring semantic change has thus far remained a task where methods using contextual embeddings have struggled to improve upon simpler techniques relying only on static word vectors. Moreover, many of the previously proposed approaches suffer from downsides related to scalability and ease of interpretation. We present a simplified approach to measuring semantic change using contextual embeddings, relying only on the most probable substitutes for masked terms. Not only is this approach directly interpretable, it is also far more efficient in terms of storage, achieves superior average performance across the most frequently cited datasets for this task, and allows for more nuanced investigation of change than is possible with static word vectors.
    
[^34]: CodeApex：用于大型语言模型的双语编程评估基准

    CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models. (arXiv:2309.01940v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01940](http://arxiv.org/abs/2309.01940)

    CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。

    

    随着大型语言模型（LLM）的出现，模型的编程能力得到了显著提升，吸引了研究人员日益增长的关注。我们提出了CodeApex，一种双语基准数据集，专注于LLM的编程理解和代码生成能力。CodeApex包括三种类型的多项选择题：概念理解、常识推理和多跳推理，旨在评估LLM在编程理解任务上的能力。此外，CodeApex利用算法问题和相应的测试用例来评估LLM生成的代码质量。我们评估了14个最先进的LLM，包括通用和专门化模型。GPT展现出最佳的编程能力，在这两个任务上的准确率分别达到了约50%和56%。编程任务仍有很大的改进空间。我们希望CodeApex能够为评估编程能力提供参考。

    With the emergence of Large Language Models (LLMs), there has been a significant improvement in the programming capabilities of models, attracting growing attention from researchers. We propose CodeApex, a bilingual benchmark dataset focusing on the programming comprehension and code generation abilities of LLMs. CodeApex comprises three types of multiple-choice questions: conceptual understanding, commonsense reasoning, and multi-hop reasoning, designed to evaluate LLMs on programming comprehension tasks. Additionally, CodeApex utilizes algorithmic questions and corresponding test cases to assess the code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs, including both general-purpose and specialized models. GPT exhibits the best programming capabilities, achieving approximate accuracies of 50% and 56% on the two tasks, respectively. There is still significant room for improvement in programming tasks. We hope that CodeApex can serve as a reference for evaluating the co
    
[^35]: 基于注意力驱动的多模态融合：增强手语识别和翻译

    Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition and Translation. (arXiv:2309.01860v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.01860](http://arxiv.org/abs/2309.01860)

    本文提出了一种注意力驱动的多模态融合机制，通过将光流信息与RGB图像相结合，丰富了连续手语识别和翻译流程中的特征。该方法在手语识别任务中降低了WER 0.9，在翻译任务中提高了测试集上大多数BLEU分数约0.6。

    

    本文中，我们设计了一种机制，用于将多模态信息与现有的连续手语识别和翻译流程相结合。在我们的过程中，我们将光流信息与RGB图像结合，以丰富具有与运动相关信息的特征。该工作通过使用跨模态编码器研究了这种模态包含的可行性。我们使用的插件非常轻量级，并且不需要以端到端的方式为新模态包括一个单独的特征提取器。我们在手语识别和翻译中应用了这些改变，改善了每个任务的结果。我们在RWTH-PHOENIX-2014数据集上评估了性能，用于手语识别，并在RWTH-PHOENIX-2014T数据集上评估了翻译任务。在识别任务上，我们的方法将WER降低了0.9，在翻译任务上，我们的方法将大部分BLEU分数在测试集上提高了约0.6。

    In this paper, we devise a mechanism for the addition of multi-modal information with an existing pipeline for continuous sign language recognition and translation. In our procedure, we have incorporated optical flow information with RGB images to enrich the features with movement-related information. This work studies the feasibility of such modality inclusion using a cross-modal encoder. The plugin we have used is very lightweight and doesn't need to include a separate feature extractor for the new modality in an end-to-end manner. We have applied the changes in both sign language recognition and translation, improving the result in each case. We have evaluated the performance on the RWTH-PHOENIX-2014 dataset for sign language recognition and the RWTH-PHOENIX-2014T dataset for translation. On the recognition task, our approach reduced the WER by 0.9, and on the translation task, our approach increased most of the BLEU scores by ~0.6 on the test set.
    
[^36]: 零样本多标签分类 COVID-19 CT扫描和非标准化报告的实证分析

    An Empirical Analysis for Zero-Shot Multi-Label Classification on COVID-19 CT Scans and Uncurated Reports. (arXiv:2309.01740v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2309.01740](http://arxiv.org/abs/2309.01740)

    本研究通过对比性视觉语言学习，在COVID-19 CT扫描和非标准化报告中应用零样本多标签分类，以发现肺栓塞和细微的肺部细节，为医学图像分析领域带来了新的发展机遇。

    

    大流行导致了包括医学检查增加在内的大量非结构化数据，包括放射学报告。尽管与计算机断层扫描（CT）相比，X射线图像的精确度较低，但以往关于 COVID-19 的自动诊断研究主要集中在 X射线图像上。在本研究中，我们利用医院的非结构化数据，利用 CT 扫描提供的细节进行基于对比性视觉语言学习的零样本多标签分类。与人类专家合作，我们调查了多种零样本模型的有效性，以帮助放射科医生检测肺栓塞，并识别诸如地玻璃状浑浊和实变等细微的肺部细节。我们的实证分析提供了目前在医学多模态预训练文献中被忽视的解决这些细粒度任务的可能方案。我们的研究为医学图像分析领域的未来发展带来了希望。

    The pandemic resulted in vast repositories of unstructured data, including radiology reports, due to increased medical examinations. Previous research on automated diagnosis of COVID-19 primarily focuses on X-ray images, despite their lower precision compared to computed tomography (CT) scans. In this work, we leverage unstructured data from a hospital and harness the fine-grained details offered by CT scans to perform zero-shot multi-label classification based on contrastive visual language learning. In collaboration with human experts, we investigate the effectiveness of multiple zero-shot models that aid radiologists in detecting pulmonary embolisms and identifying intricate lung details like ground glass opacities and consolidations. Our empirical analysis provides an overview of the possible solutions to target such fine-grained tasks, so far overlooked in the medical multimodal pretraining literature. Our investigation promises future advancements in the medical image analysis co
    
[^37]: CPSP: 从音素监督中学习语音概念

    CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])

    [http://arxiv.org/abs/2309.00424](http://arxiv.org/abs/2309.00424)

    论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。

    

    对于诸如最小监督的文本转语音（TTS）、语音转换（VC）和自动语音识别（ASR）等细粒度生成和识别任务，从语音中提取的中间表示应包含介于文本编码和声学编码之间的信息。语言内容突出，而发言人身份和声学细节等语音信息应该被去除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余性过高和维度爆炸的问题。此外，音频领域中现有的对比学习方法主要关注提取用于下游音频分类任务的全局描述信息，不适合TTS、VC和ASR任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练（CPSP）的方法，该方法使用三个编码器、一个解码器和对比学习来将音素和语音信息相结合。

    For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representation extracted from speech should contain information that is between text coding and acoustic coding. The linguistic content is salient, while the paralinguistic information such as speaker identity and acoustic details should be removed. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Additionally, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named Contrastive Phoneme-Speech Pretraining (CPSP), which uses three encoders, one decoder, and contrastive learning to bring phoneme and speech
    
[^38]: BatchPrompt: 用更少的资源实现更多任务的策略

    BatchPrompt: Accomplish more with less. (arXiv:2309.00384v1 [cs.CL])

    [http://arxiv.org/abs/2309.00384](http://arxiv.org/abs/2309.00384)

    BatchPrompt是一种提示策略，它通过将多个数据点批量打包到一个提示中来提高LLM的令牌资源利用效率，从而缓解由于令牌计数差异导致的成本效率问题，提高推理速度和计算预算的利用率。

    

    许多LLM（Language Model）被训练来使用基于指令的提示实现零样本或少样本推理。为这些LLM制作提示通常需要用户提供详细的任务描述、上下文和完成示例以及推理上下文的单个示例。本文将这种常规提示基准称为SinglePrompt。然而，在每个推理数据点不一定很长的NLP任务中，提示中的指令和少样本示例的令牌计数可能比数据点的令牌计数大得多，与Fine-tuned BERT等基于编码器的模型相比，导致令牌资源利用率降低。这个成本效率问题影响了推理速度和计算预算，抵消了LLM所能提供的许多好处。本文旨在通过将多个数据点批量打包到一个提示中来缓解上述问题，我们将这种提示策略称为BatchPrompt。这种策略增加了数据点的密度，

    Many LLMs are trained to perform zero-shot or few-shot inference using instruction-based prompts. Crafting prompts for these LLMs typically requires the user to provide a detailed task description, examples of context and completion, and single example of context for inference. This regular prompt baseline is referred to as SinglePrompt in this paper. However, for NLP tasks where each data point for inference is not necessarily lengthy, the token count for instructions and few-shot examples in the prompt may be considerably larger than that of the data point, resulting in lower token-resource utilization compared with encoder-based models like fine-tuned BERT. This cost-efficiency issue, affecting inference speed and compute budget, counteracts the many benefits LLMs have to offer. This paper aims to alleviate the preceding problem by batching multiple data points into a single prompt, a prompting strategy we refer to as BatchPrompt. This strategy increases the density of data points, 
    
[^39]: 基于维基百科风格的调研生成的大型语言模型：在自然语言处理概念中的评估

    Large Language Models on Wikipedia-Style Survey Generation: an Evaluation in NLP Concepts. (arXiv:2308.10410v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10410](http://arxiv.org/abs/2308.10410)

    本研究评估了大型语言模型在自然语言处理领域生成调研文章的效果，发现GPT-4优于GPT-3.5，并且指出了GPT在信息完整性和事实准确性方面的一些缺陷。

    

    大型语言模型（LLMs）在各种自然语言处理（NLP）任务中取得了重大成功，包括问答、摘要和机器翻译等。虽然LLMs在一般任务中表现出色，但它们在特定领域应用中的效果仍在探索中。此外，LLM生成的文本有时会出现幻觉和不实信息等问题。在本研究中，我们评估了LLMs在计算机科学-NLP领域中生成简洁调研文章的能力，重点关注20个选定的主题。自动评估表明，GPT-4在与真实数据进行基准测试时优于GPT-3.5。此外，四位人类评估者从四个模型配置的六个角度提供了见解。通过案例研究，我们证明了虽然GPT通常能产生可称赞的结果，但也存在一些缺点，如信息不完整和事实准确性方面的漏洞。

    Large Language Models (LLMs) have achieved significant success across various natural language processing (NLP) tasks, encompassing question-answering, summarization, and machine translation, among others. While LLMs excel in general tasks, their efficacy in domain-specific applications remains under exploration. Additionally, LLM-generated text sometimes exhibits issues like hallucination and disinformation. In this study, we assess LLMs' capability of producing concise survey articles within the computer science-NLP domain, focusing on 20 chosen topics. Automated evaluations indicate that GPT-4 outperforms GPT-3.5 when benchmarked against the ground truth. Furthermore, four human evaluators provide insights from six perspectives across four model configurations. Through case studies, we demonstrate that while GPT often yields commendable results, there are instances of shortcomings, such as incomplete information and the exhibition of lapses in factual accuracy.
    
[^40]: 单句阅读器：解决答案位置偏倚的新方法

    Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias. (arXiv:2308.04566v1 [cs.CL])

    [http://arxiv.org/abs/2308.04566](http://arxiv.org/abs/2308.04566)

    本论文针对机器阅读理解中的答案位置偏倚问题，提出了一种名为单句阅读器的新方法，该方法使用六种不同模型实现。实验证明，单句阅读器与传统训练集上训练的模型几乎具有相当的性能，有效解决了答案位置偏倚问题。

    

    机器阅读理解（MRC）模型往往利用伪相关性（也称为数据集偏差或研究界的标注工件）。因此，这些模型可能在不完全理解给定的上下文和问题的情况下执行MRC任务，这是不可取的，因为它可能导致对分布转移的低稳健性。本文深入探讨了答案位置偏倚的概念，其中训练问题中有相当比例的答案仅位于上下文的第一句。我们提出了一种名为单句阅读器的新方法来解决MRC中的答案位置偏倚问题。我们使用六种不同模型来实现这种方法，并对其性能进行了彻底分析。值得注意的是，我们提出的单句阅读器的结果几乎与传统训练集上训练的模型相当，证明了其有效性。我们的研究还讨论了我们的单句阅读器遇到的几个挑战和提出的应对策略。

    Machine Reading Comprehension (MRC) models tend to take advantage of spurious correlations (also known as dataset bias or annotation artifacts in the research community). Consequently, these models may perform the MRC task without fully comprehending the given context and question, which is undesirable since it may result in low robustness against distribution shift. This paper delves into the concept of answer-position bias, where a significant percentage of training questions have answers located solely in the first sentence of the context. We propose a Single-Sentence Reader as a new approach for addressing answer position bias in MRC. We implement this approach using six different models and thoroughly analyze their performance. Remarkably, our proposed Single-Sentence Readers achieve results that nearly match those of models trained on conventional training sets, proving their effectiveness. Our study also discusses several challenges our Single-Sentence Readers encounter and prop
    
[^41]: 基于大规模语言模型的长形式数据重新评分研究

    Large-scale Language Model Rescoring on Long-form Data. (arXiv:2306.08133v1 [eess.AS])

    [http://arxiv.org/abs/2306.08133](http://arxiv.org/abs/2306.08133)

    本文研究了大规模语言模型对长视频ASR的影响，证明与最大熵基线相比，使用LLM能够最多减少8％的Word Error Rate和30％的Salient Term Error Rate。经过改进的格处理和携带上下文的组合可以获得更好的效果。

    

    本文研究了大规模语言模型（LLM）对YouTube视频的自动语音识别（ASR）的影响，这些视频被用作长形式ASR的源。我们证明在美国英语（en-us）和印度英语（en-in）长形式ASR测试集上，相对于基于最大熵的语言模型强一次通过基线，我们实现了高达8％的相对Word Error Rate（WER）降低和高达30％的相对Salient Term Error Rate（STER）降低。经过改进的格处理导致带有正确（非树形）有向图拓扑和携带前一段最佳假设的上下文的格的显着获胜。我们还发现，基于大量可用数据（如C4）的LLMs和传统神经LMs的组合的性能提升是累加的，并且显着优于具有最大熵LM的强一次通过基线。

    In this work, we study the impact of Large-scale Language Models (LLM) on Automated Speech Recognition (ASR) of YouTube videos, which we use as a source for long-form ASR. We demonstrate up to 8\% relative reduction in Word Error Eate (WER) on US English (en-us) and code-switched Indian English (en-in) long-form ASR test sets and a reduction of up to 30\% relative on Salient Term Error Rate (STER) over a strong first-pass baseline that uses a maximum-entropy based language model. Improved lattice processing that results in a lattice with a proper (non-tree) digraph topology and carrying context from the 1-best hypothesis of the previous segment(s) results in significant wins in rescoring with LLMs. We also find that the gains in performance from the combination of LLMs trained on vast quantities of available data (such as C4) and conventional neural LMs is additive and significantly outperforms a strong first-pass baseline with a maximum entropy LM.
    
[^42]: 布局和任务感知的零样本文档图像问答指导模型

    Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering. (arXiv:2306.00526v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00526](http://arxiv.org/abs/2306.00526)

    该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。

    

    基于布局感知多模态预训练模型的预训练-微调范式在文档图像问答方面取得了显著进展。然而，领域预训练和任务微调对于额外的视觉、布局和任务模块阻止了其直接利用现成的指导调优语言基础模型，而这些模型最近在零样本学习方面显示出了良好的潜力。与将语言模型与文档图像问答领域对齐相反，我们将文档图像问答与现成的指导调优语言基础模型对齐，利用其零样本能力。具体而言，我们提出了布局和任务感知的指导提示模型，称为LATIN-Prompt，它包括布局感知的文档内容和任务感知的描述。前者通过适当的空格和换行符从OCR工具中恢复文本片段之间的布局信息。后者确保模型生成符合任务需求的答案。

    The pre-training-fine-tuning paradigm based on layout-aware multimodal pre-trained models has achieved significant progress on document image question answering. However, domain pre-training and task fine-tuning for additional visual, layout, and task modules prevent them from directly utilizing off-the-shelf instruction-tuning language foundation models, which have recently shown promising potential in zero-shot learning. Contrary to aligning language models to the domain of document image question answering, we align document image question answering to off-the-shell instruction-tuning language foundation models to utilize their zero-shot capability. Specifically, we propose layout and task aware instruction prompt called LATIN-Prompt, which consists of layout-aware document content and task-aware descriptions. The former recovers the layout information among text segments from OCR tools by appropriate spaces and line breaks. The latter ensures that the model generates answers that m
    
[^43]: ChatGPT已在地平线上：大语言模型是否就是我们需要的智能交通解决方案？

    ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?. (arXiv:2303.05382v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.05382](http://arxiv.org/abs/2303.05382)

    本文探讨了ChatGPT在解决交通问题方面的应用。通过利用具有跨模态编码器的LLM，可以处理来自不同模态的交通数据并执行交通运营。作者提供了一个基于智能手机的碰撞报告自动生成和分析框架作为用例展示了这种潜力。

    

    ChatGPT是由OpenAI开发的具有60亿参数的重要大语言模型之一。ChatGPT展示了LLM的卓越的语言理解能力，特别是在生成对话响应方面。随着LLM在各种研究或工程领域越来越受到关注，现在是时候设想LLM如何革新我们处理智能交通系统的方式了。本文探讨了LLM在解决关键交通问题方面的未来应用。通过利用具有跨模态编码器的LLM，智能系统还可以处理来自不同模态的交通数据并通过LLM执行交通运营。我们提出并验证了LLM装备的这些潜在的交通应用。为了进一步证明这种潜力，我们还提供了一个具体的基于智能手机的碰撞报告自动生成和分析框架作为用例。尽管存在潜在的益处，但与数据隐私相关的挑战仍然存在。

    ChatGPT, developed by OpenAI, is one of the milestone large language models (LLMs) with 6 billion parameters. ChatGPT has demonstrated the impressive language understanding capability of LLM, particularly in generating conversational response. As LLMs start to gain more attention in various research or engineering domains, it is time to envision how LLM may revolutionize the way we approach intelligent transportation systems. This paper explores the future applications of LLM in addressing key transportation problems. By leveraging LLM with cross-modal encoder, an intelligent system can also process traffic data from different modalities and execute transportation operations through an LLM. We present and validate these potential transportation applications equipped by LLM. To further demonstrate this potential, we also provide a concrete smartphone-based crash report auto-generation and analysis framework as a use case. Despite the potential benefits, challenges related to data privac
    
[^44]: NNKGC: 用节点邻居改进知识图谱补全

    NNKGC: Improving Knowledge Graph Completion with Node Neighborhoods. (arXiv:2302.06132v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.06132](http://arxiv.org/abs/2302.06132)

    NNKGC是一种通过节点邻居进行知识图谱补全并引入边连接预测任务的框架，简单而有效，可以预测出可解释的结果。

    

    知识图谱补全旨在发现查询实体的缺失关系。目前的基于文本的模型利用实体名称和描述推断头实体和特定关系给定的尾实体。现有方法还考虑了头实体的邻居。然而，这些方法往往使用扁平结构模拟邻居，且仅限于1跳邻居。在这项工作中，我们提出了一种增强知识图谱补全的节点邻居框架。它利用图神经网络对头实体邻居进行多跳建模，以丰富头节点信息。此外，我们引入了额外的边连接预测任务来改进知识图谱补全。在两个公共数据集上的评估表明，该框架简单而有效。案例研究还表明，模型能够预测可解释的预测结果。

    Knowledge graph completion (KGC) aims to discover missing relations of query entities. Current text-based models utilize the entity name and description to infer the tail entity given the head entity and a certain relation. Existing approaches also consider the neighborhood of the head entity. However, these methods tend to model the neighborhood using a flat structure and are only restricted to 1-hop neighbors. In this work, we propose a node neighborhood-enhanced framework for knowledge graph completion. It models the head entity neighborhood from multiple hops using graph neural networks to enrich the head node information. Moreover, we introduce an additional edge link prediction task to improve KGC. Evaluation on two public datasets shows that this framework is simple yet effective. The case study also shows that the model is able to predict explainable predictions.
    
[^45]: 学习从多个选项中选择

    Learning to Select from Multiple Options. (arXiv:2212.00301v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.00301](http://arxiv.org/abs/2212.00301)

    本文提出了一个上下文化的文本蕴涵（TE）模型（Context-TE），通过考虑其他选项作为当前建模的上下文，它能够解决TE方法中的两个限制。这个模型可以学习到更可靠的选项决策，并且通过加速推理过程来提高效率。

    

    许多自然语言处理任务可以看作是从一组选项中进行选择，比如分类任务、多项选择题等。文本蕴涵（TE）被证明是处理这些选择问题的最先进方法。TE将输入文本视为前提（P），选项视为假设（H），然后通过对（P，H）进行配对建模来处理选择问题。然而，TE方法存在两个限制：首先，配对建模无法意识到其他选项，这不够直观，因为人们常常通过比较竞争候选项来确定最佳选项；其次，配对TE的推理过程耗时，特别是当选项空间较大时。为了解决这两个问题，本文首先提出了一种上下文化的TE模型（Context-TE），通过将其他k个选项附加为当前（P，H）建模的上下文来进行建模。Context-TE能够通过考虑不同的上下文来学习到更可靠的H决策。其次，我们通过提出Pa

    Many NLP tasks can be regarded as a selection problem from a set of options, such as classification tasks, multi-choice question answering, etc. Textual entailment (TE) has been shown as the state-of-the-art (SOTA) approach to dealing with those selection problems. TE treats input texts as premises (P), options as hypotheses (H), then handles the selection problem by modeling (P, H) pairwise. Two limitations: first, the pairwise modeling is unaware of other options, which is less intuitive since humans often determine the best options by comparing competing candidates; second, the inference process of pairwise TE is time-consuming, especially when the option space is large. To deal with the two issues, this work first proposes a contextualized TE model (Context-TE) by appending other k options as the context of the current (P, H) modeling. Context-TE is able to learn more reliable decision for the H since it considers various context. Second, we speed up Context-TE by coming up with Pa
    
[^46]: 在机器阅读理解中测量和减轻推理捷径的调查

    A Survey on Measuring and Mitigating Reasoning Shortcuts in Machine Reading Comprehension. (arXiv:2209.01824v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.01824](http://arxiv.org/abs/2209.01824)

    这篇综述论文调查了机器阅读理解中测量和减轻推理捷径的技术，并强调了缺乏公共挑战集和其他领域减轻技术的问题。

    

    快捷学习的问题在自然语言处理领域广为人知，并且近年来一直是重要的研究重点。数据中的无意间相关性使得模型能够轻松解决原本应该展示高级语言理解和推理能力的任务。在这篇综述论文中，我们关注于机器阅读理解（MRC）领域，这是一个展示高水平语言理解能力的重要任务，同时也受到了各种捷径的影响。我们总结了测量和减轻捷径的现有技术，并在最后提出了对进一步的捷径研究的建议。重要的是，我们强调了机器阅读理解中两个对于减轻捷径的关注点：(1)缺乏公共挑战集，这是有效和可重用评估的必要组成部分；(2)缺乏其他领域突出的某些减轻技术。

    The issue of shortcut learning is widely known in NLP and has been an important research focus in recent years. Unintended correlations in the data enable models to easily solve tasks that were meant to exhibit advanced language understanding and reasoning capabilities. In this survey paper, we focus on the field of machine reading comprehension (MRC), an important task for showcasing high-level language understanding that also suffers from a range of shortcuts. We summarize the available techniques for measuring and mitigating shortcuts and conclude with suggestions for further progress in shortcut research. Importantly, we highlight two concerns for shortcut mitigation in MRC: (1) the lack of public challenge sets, a necessary component for effective and reusable evaluation, and (2) the lack of certain mitigation techniques that are prominent in other areas.
    

