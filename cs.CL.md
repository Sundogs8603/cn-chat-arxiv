# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [OUTFOX: LLM-generated Essay Detection through In-context Learning with Adversarially Generated Examples.](http://arxiv.org/abs/2307.11729) | OUTFOX是一个新的框架，通过允许检测器和攻击者考虑彼此的输出，提高了LLM生成文本检测器的鲁棒性。攻击者利用检测器的预测标签作为示例进行上下文学习，并生成难以检测的对抗生成的论文。 |
| [^2] | [Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts.](http://arxiv.org/abs/2307.11661) | 本文展示了如何利用GPT-4生成具有视觉描述性的文本，并将其用于适应CLIP到下游任务。与CLIP的默认提示相比，在专门细粒度数据集上显示了较大的0-shot迁移准确性改进。 |
| [^3] | [OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?.](http://arxiv.org/abs/2307.11636) | OxfordTVG-HIC是一个用于幽默生成和理解的大规模数据集，通过提供广泛的情感和语义多样性，特别适合生成幽默的脱离上下文的例子，并用于训练通用幽默字幕生成模型。 |
| [^4] | [CausE: Towards Causal Knowledge Graph Embedding.](http://arxiv.org/abs/2307.11610) | CausE是一个采用因果知识图谱嵌入和嵌入解缠的框架，利用因果干预进行稳定预测，并在知识图谱完整性任务上取得了最先进的性能。 |
| [^5] | [A Change of Heart: Improving Speech Emotion Recognition through Speech-to-Text Modality Conversion.](http://arxiv.org/abs/2307.11584) | 本研究通过语音到文本的模态转换方法，在MELD数据集上提高了语音情感识别的性能，超过了基于语音的最先进方法。这表明了模态转换在替代模态任务中的潜力。 |
| [^6] | [Advancing Visual Grounding with Scene Knowledge: Benchmark and Method.](http://arxiv.org/abs/2307.11558) | 本文提出了一种基于场景知识的视觉对齐新基准SK-VG，通过迫使模型具备对长篇场景知识进行推理的能力，对图像和文本进行细粒度对齐。 |
| [^7] | [Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation.](http://arxiv.org/abs/2307.11545) | 本研究针对引用图像分割问题进行了参数高效调整的探索。我们提出了一种名为 Bridger 的适配器，在模型中实现了跨模态信息交换和任务特定信息注入，并设计了一个轻量级的图像分割解码器。通过仅进行1.61％ 至 3.38％ 的主干参数更新，我们的方法在挑战性基准测试中实现了可比或更优的性能。 |
| [^8] | [Multi-modal Hate Speech Detection using Machine Learning.](http://arxiv.org/abs/2307.11519) | 本研究提出了一种使用多模态系统的方法，通过提取图像特征、音频特征值和文本，结合机器学习和自然语言处理技术，来检测视频内容中的仇恨言论。 |
| [^9] | [IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making.](http://arxiv.org/abs/2307.11516) | IndigoVX是一种将人类智慧与人工智能相结合的最优决策方法，通过迭代反馈循环，利用人类专家的背景知识和人工智能的数据驱动洞见，制定和优化朝着明确定义的目标的策略，并使用定量化的三分数模式进行评估和改进。 |
| [^10] | [Incorporating Human Translator Style into English-Turkish Literary Machine Translation.](http://arxiv.org/abs/2307.11457) | 本论文研究了英土文学翻译，在机器翻译模型中采用翻译家的风格特征，并通过微调预训练模型获得了高度还原人类译者风格的机器翻译效果。 |
| [^11] | [Topic Identification For Spontaneous Speech: Enriching Audio Features With Embedded Linguistic Information.](http://arxiv.org/abs/2307.11450) | 本研究探讨了自发语音中主题识别的解决方案，通过比较纯音频和混合多模态技术的效果。实验结果表明，在资源有限的情况下，纯音频解决方案是可行的选项，而混合多模态解决方案获得了最佳结果。 |
| [^12] | [MeetEval: A Toolkit for Computation of Word Error Rates for Meeting Transcription Systems.](http://arxiv.org/abs/2307.11394) | MeetEval是一个计算会议转录系统字错误率的工具包，它通过时间约束来提高匹配质量并加速匹配算法。 |
| [^13] | [Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect ChatGPT-Generated Text.](http://arxiv.org/abs/2307.11380) | 本研究针对ChatGPT在文本生成中的作用进行了研究，提出了一种新的测量方法“波兰比率”，用于检测ChatGPT生成的文本中的涉及程度。同时，还引入了一个新的数据集HPPT，用于构建更稳健的检测器。 |
| [^14] | [CohortGPT: An Enhanced GPT for Participant Recruitment in Clinical Study.](http://arxiv.org/abs/2307.11346) | CohortGPT是一种增强型GPT，用于解决临床研究中的参与者招募任务。此研究发现传统的大型语言模型在医疗文本分类中的性能一般，这可能是由于它们忽略了语言中的上下文信息。 |
| [^15] | [DEFTri: A Few-Shot Label Fused Contextual Representation Learning For Product Defect Triage in e-Commerce.](http://arxiv.org/abs/2307.11344) | 本文提出了一个使用标签融合文本嵌入和优化上下文表示的DEFTri框架，以改进电子商务中的产品缺陷分类。同时，通过少样本训练和弱监督学习，引入了沃尔玛的专有数据集。 |
| [^16] | [Making Pre-trained Language Models both Task-solvers and Self-calibrators.](http://arxiv.org/abs/2307.11316) | 该论文研究了如何使预训练语言模型成为任务解决器和自校准器，在有限的训练样本、数据不平衡和其他实际挑战下进行了探索。 |
| [^17] | [Generating Image-Specific Text Improves Fine-grained Image Classification.](http://arxiv.org/abs/2307.11315) | 本文提出了一种名为GIST的方法，用于从仅图像数据集中生成图像特定的细粒度文本描述，并通过将其用于微调视觉语言模型来改进图像分类的效果。 |
| [^18] | [Generator-Retriever-Generator: A Novel Approach to Open-domain Question Answering.](http://arxiv.org/abs/2307.11278) | 生成器-检索器-生成器（GRG）是一种新方法，将文档检索技术与大型语言模型相结合，以生成开放域问答的准确和信息丰富的答案。 |
| [^19] | [A Systematic Evaluation of Federated Learning on Biomedical Natural Language Processing.](http://arxiv.org/abs/2307.11254) | 本研究对医学领域中的联邦学习在生物医学自然语言处理中的应用进行了系统评估，结果显示联邦学习模型优于单独训练的模型，并且在考虑数据隐私的情况下仍能取得良好的效果。 |
| [^20] | [Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models.](http://arxiv.org/abs/2307.11224) | Jina Embeddings是一组高性能的句子嵌入模型，能够捕捉文本的语义本质。该论文详细介绍了Jina Embeddings的开发过程，并通过性能评估验证了其优越性能。 |
| [^21] | [UMLS-KGI-BERT: Data-Centric Knowledge Integration in Transformers for Biomedical Entity Recognition.](http://arxiv.org/abs/2307.11170) | 这项工作提出了一种数据中心范式，通过从UMLS中提取文本序列来丰富生物医学转换器编码器LMs的语言表示。 |
| [^22] | [(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs.](http://arxiv.org/abs/2307.10490) | 本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。 |
| [^23] | [PharmacyGPT: The AI Pharmacist.](http://arxiv.org/abs/2307.10432) | PharmacyGPT是一个新颖的框架，利用大型语言模型（LLM）来仿真临床药师的角色。通过生成患者群集、制定用药计划和预测患者结果，PharmacyGPT在临床药学中具有潜在应用和限制，为促进负责任和有效使用人工智能技术做出贡献。 |
| [^24] | [Mutual Reinforcement Effects in Japanese Sentence Classification and Named Entity Recognition Tasks.](http://arxiv.org/abs/2307.10291) | 该研究提出了一个综合分析方法，将句子分类和命名实体识别结合起来，并揭示了这两个信息提取子任务之间的相互增强效应。 |
| [^25] | [ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats.](http://arxiv.org/abs/2307.09782) | ZeroQuant-FP通过使用浮点格式进行LLMs训练后量化，解决了在大型语言模型中平衡计算效率和保持模型质量的挑战，并发现FP8激活优于INT8，并且FP4权重表现与INT4相当甚至更优。 |
| [^26] | [Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations.](http://arxiv.org/abs/2307.06576) | 本文介绍了一种名为GLORY的模型，通过全局图与本地表示相结合，增强了个性化推荐系统。该模型通过构建全局感知历史新闻编码器来融合历史新闻表示，并考虑了用户隐藏的动机和行为。 |
| [^27] | [GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models.](http://arxiv.org/abs/2306.17519) | 本论文介绍了使用大型语言模型和上下文学习框架进行金融关系提取的解决方案。通过两种检索策略，无需学习的密集检索器和基于学习的检索器，我们能够从训练数据中找到与给定测试示例相关的上下文学习示范。 |
| [^28] | [Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models.](http://arxiv.org/abs/2306.14096) | 本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。 |
| [^29] | [Towards Robust Aspect-based Sentiment Analysis through Non-counterfactual Augmentations.](http://arxiv.org/abs/2306.13971) | 本研究提出了一种非反事实数据增强的替代方法，该方法使用保留目标方面相关语义的有噪声、成本效益较高的数据增强，通过对数据的不同版本之间的不变性进行建模以提高其鲁棒性，在标准和强度特定数据集上都显著改进了强预训练基线的性能。 |
| [^30] | [FAIR: A Causal Framework for Accurately Inferring Judgments Reversals.](http://arxiv.org/abs/2306.11585) | 本文提出了一个用于推断判例颠倒的因果框架（FAIR），通过采用因果推断方法挖掘判例颠倒的原因，并将因果关系注入神经网络，有效提高了神经网络的性能。 |
| [^31] | [Large Language Model Augmented Narrative Driven Recommendations.](http://arxiv.org/abs/2306.02250) | 这个论文研究了如何使用大型语言模型（LLMs）为基于叙事的推荐系统提供数据增强，以解决其缺乏训练数据的问题。 |
| [^32] | [Enhancing Coherence of Extractive Summarization with Multitask Learning.](http://arxiv.org/abs/2305.12851) | 本研究提出了一种使用多任务学习架构来增强抽取式摘要的连贯性的方法。实验证明，该方法显著提高了抽取式摘要的连贯性，并在其他评价指标方面也表现出良好的性能。 |
| [^33] | [Editable User Profiles for Controllable Text Recommendation.](http://arxiv.org/abs/2304.04250) | 本文提出了一种新的概念值瓶颈模型LACE，用于可控文本推荐。该模型基于用户文档学习个性化的概念表示，并通过多种交互方式为用户提供了控制推荐的机制，验证了在离线和在线实验中该模型的推荐质量和有效性。 |
| [^34] | [NusaCrowd: Open Source Initiative for Indonesian NLP Resources.](http://arxiv.org/abs/2212.09648) | NusaCrowd是一个印尼自然语言处理资源的开源倡议，已汇集137个数据集和118个数据加载程序，为印尼语和印度尼西亚本地语言的自然语言处理研究提供了多种实验手段。 |
| [^35] | [ClueReader: Heterogeneous Graph Attention Network for Multi-hop Machine Reading Comprehension.](http://arxiv.org/abs/2107.00841) | ClueReader是一种新型的异构图注意力网络模型，利用谱模型和注意机制，通过模拟祖母细胞概念来提升多跳机器阅读理解任务的推理能力和结果。 |
| [^36] | [Forecasting consumer confidence through semantic network analysis of online news.](http://arxiv.org/abs/2105.04900) | 本研究使用语义网络分析在线新闻对消费者信心的影响，结果表明该方法能够预测消费者对经济形势的判断，提供了一种补充方法来估计消费者信心。 |

# 详细

[^1]: OUTFOX: 基于上下文学习和对抗生成例子的LLM生成论文检测

    OUTFOX: LLM-generated Essay Detection through In-context Learning with Adversarially Generated Examples. (arXiv:2307.11729v1 [cs.CL])

    [http://arxiv.org/abs/2307.11729](http://arxiv.org/abs/2307.11729)

    OUTFOX是一个新的框架，通过允许检测器和攻击者考虑彼此的输出，提高了LLM生成文本检测器的鲁棒性。攻击者利用检测器的预测标签作为示例进行上下文学习，并生成难以检测的对抗生成的论文。

    

    大型语言模型(LLMs)已经达到了与人类写作相当的流利程度，很难区分人类写作和LLM生成的文本。这增加了LLMs被误用的风险，并需要开发检测器来识别LLM生成的文本。然而，现有的检测器通过简单地改写LLM生成的文本来降低检测准确性。此外，这些检测器在学生在写作作业（如论文）中使用LLMs并迅速学会如何规避这些检测器的真实生活情况下的有效性尚未被探讨。在本文中，我们提出了OUTFOX，一个新的框架，通过允许检测器和攻击者考虑彼此的输出并将其应用于学生论文领域来提高LLM生成文本检测器的鲁棒性。在我们的框架中，攻击者使用检测器的预测标签作为上下文学习的示例，并对难以检测的对抗生成论文进行生成。

    Large Language Models (LLMs) have achieved human-level fluency in text generation, making it difficult to distinguish between human-written and LLM-generated texts. This poses a growing risk of misuse of LLMs and demands the development of detectors to identify LLM-generated texts. However, existing detectors degrade detection accuracy by simply paraphrasing LLM-generated texts. Furthermore, the effectiveness of these detectors in real-life situations, such as when students use LLMs for writing homework assignments (e.g., essays) and quickly learn how to evade these detectors, has not been explored. In this paper, we propose OUTFOX, a novel framework that improves the robustness of LLM-generated-text detectors by allowing both the detector and the attacker to consider each other's output and apply this to the domain of student essays. In our framework, the attacker uses the detector's prediction labels as examples for in-context learning and adversarially generates essays that are hard
    
[^2]: 用GPT-4增强CLIP：利用视觉描述作为提示

    Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts. (arXiv:2307.11661v1 [cs.CV])

    [http://arxiv.org/abs/2307.11661](http://arxiv.org/abs/2307.11661)

    本文展示了如何利用GPT-4生成具有视觉描述性的文本，并将其用于适应CLIP到下游任务。与CLIP的默认提示相比，在专门细粒度数据集上显示了较大的0-shot迁移准确性改进。

    

    对比预训练的大型视觉-语言模型（VLMs）如CLIP在下游数据集上提供了良好性能，从而革新了视觉表示学习。VLMs通过设计与数据集相关的提示来0-shot适应下游数据集。这种提示工程利用了领域专业知识和验证数据集。同时，像GPT-4这样的生成预训练模型的最新发展意味着它们可以用作先进的互联网搜索工具。它们还可以被操作以提供任何结构化的视觉信息。在这项工作中，我们展示了如何利用GPT-4生成具有视觉描述性的文本，并将其用于适应CLIP到下游任务。与CLIP的默认提示相比，我们在专门细粒度数据集（如EuroSAT（~7％）、DTD（~7％）、SUN397（~4.6％）和CUB（~3.3％））上显示出了较大的0-shot迁移准确性改进。我们还设计了一个简单的少量样本适配器，它可以学习选择最佳的s

    Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have revolutionized visual representation learning by providing good performance on downstream datasets. VLMs are 0-shot adapted to a downstream dataset by designing prompts that are relevant to the dataset. Such prompt engineering makes use of domain expertise and a validation dataset. Meanwhile, recent developments in generative pretrained models like GPT-4 mean they can be used as advanced internet search tools. They can also be manipulated to provide visual information in any structure. In this work, we show that GPT-4 can be used to generate text that is visually descriptive and how this can be used to adapt CLIP to downstream tasks. We show considerable improvements in 0-shot transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD (~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt. We also design a simple few-shot adapter that learns to choose the best possible s
    
[^3]: OxfordTVG-HIC: 机器能否从图像中生成幽默的标题？

    OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?. (arXiv:2307.11636v1 [cs.CV])

    [http://arxiv.org/abs/2307.11636](http://arxiv.org/abs/2307.11636)

    OxfordTVG-HIC是一个用于幽默生成和理解的大规模数据集，通过提供广泛的情感和语义多样性，特别适合生成幽默的脱离上下文的例子，并用于训练通用幽默字幕生成模型。

    

    本文介绍了OxfordTVG-HIC（Humorous Image Captions）这个大规模的用于幽默生成和理解的数据集。幽默是一个抽象、主观和与上下文相关的认知构建，涉及多个认知因素，使得生成和解释幽默成为一项具有挑战性的任务。因此，幽默生成和理解可以作为评估深度学习方法处理抽象和主观信息能力的新任务。由于数据的稀缺性，与幽默相关的生成任务（如字幕生成）仍未得到充分探索。为填补这一空白，OxfordTVG-HIC提供了约290万个图像-文本对，并附带幽默评分，用于训练一个具有通用幽默字幕生成能力的模型。与现有的字幕数据集不同，OxfordTVG-HIC具有广泛的情感和语义多样性，导致一些脱离上下文的例子，特别适合生成幽默。此外，OxfordTVG-HIC经过精心策划，不含冒犯性内容。我们还展示了如何使用Oxf

    This paper presents OxfordTVG-HIC (Humorous Image Captions), a large-scale dataset for humour generation and understanding. Humour is an abstract, subjective, and context-dependent cognitive construct involving several cognitive factors, making it a challenging task to generate and interpret. Hence, humour generation and understanding can serve as a new task for evaluating the ability of deep-learning methods to process abstract and subjective information. Due to the scarcity of data, humour-related generation tasks such as captioning remain under-explored. To address this gap, OxfordTVG-HIC offers approximately 2.9M image-text pairs with humour scores to train a generalizable humour captioning model. Contrary to existing captioning datasets, OxfordTVG-HIC features a wide range of emotional and semantic diversity resulting in out-of-context examples that are particularly conducive to generating humour. Moreover, OxfordTVG-HIC is curated devoid of offensive content. We also show how Oxf
    
[^4]: CausE: 朝向因果知识图谱嵌入的方向

    CausE: Towards Causal Knowledge Graph Embedding. (arXiv:2307.11610v1 [cs.CL])

    [http://arxiv.org/abs/2307.11610](http://arxiv.org/abs/2307.11610)

    CausE是一个采用因果知识图谱嵌入和嵌入解缠的框架，利用因果干预进行稳定预测，并在知识图谱完整性任务上取得了最先进的性能。

    

    知识图谱嵌入（KGE）的重点是将知识图谱（KG）中的实体和关系表示为连续的向量空间，这可以用于预测缺失的三元组以实现知识图谱完整性（KGC）。然而，KGE模型通常只是简单地学习三元组数据的结构关联，并且在现实世界的KG中，嵌入可能会被微不足道的模式和噪声链接所误导。为了解决这个问题，我们在因果性和嵌入解缠方面建立了KGE的新模式。我们进一步提出了Causality-enhanced knowledge graph Embedding（CausE）框架。CausE使用因果干预来估计混杂嵌入的因果效应，并设计新的训练目标来进行稳定预测。实验结果表明，CausE可以优于基线模型，并实现最先进的KGC性能。我们在https://github.com/zjukg/CausE上发布了我们的代码。

    Knowledge graph embedding (KGE) focuses on representing the entities and relations of a knowledge graph (KG) into the continuous vector spaces, which can be employed to predict the missing triples to achieve knowledge graph completion (KGC). However, KGE models often only briefly learn structural correlations of triple data and embeddings would be misled by the trivial patterns and noisy links in real-world KGs. To address this issue, we build the new paradigm of KGE in the context of causality and embedding disentanglement. We further propose a Causality-enhanced knowledge graph Embedding (CausE) framework. CausE employs causal intervention to estimate the causal effect of the confounder embeddings and design new training objectives to make stable predictions. Experimental results demonstrate that CausE could outperform the baseline models and achieve state-of-the-art KGC performance. We release our code in https://github.com/zjukg/CausE.
    
[^5]: 心态转变：通过语音到文本的模态转换提高语音情感识别的性能

    A Change of Heart: Improving Speech Emotion Recognition through Speech-to-Text Modality Conversion. (arXiv:2307.11584v1 [cs.SD])

    [http://arxiv.org/abs/2307.11584](http://arxiv.org/abs/2307.11584)

    本研究通过语音到文本的模态转换方法，在MELD数据集上提高了语音情感识别的性能，超过了基于语音的最先进方法。这表明了模态转换在替代模态任务中的潜力。

    

    语音情感识别（SER）是一项具有挑战性的任务。本文介绍了一种模态转换的概念，旨在提高在MELD数据集上的情感识别性能。我们通过两个实验评估了我们的方法：第一个实验使用自动语音识别（ASR）系统和文本分类器实现的称为模态转换的方法；第二个实验假设有完美的ASR输出，并研究了模态转换对SER的影响，此方法称为模态转换++。我们的研究结果表明，第一个方法取得了显著的成果，而第二个方法在MELD数据集上的SER加权-F1（WF1）得分方面超越了最先进的基于语音的方法。这项研究突出了模态转换在可以使用替代模态进行的任务中的潜力。

    Speech Emotion Recognition (SER) is a challenging task. In this paper, we introduce a modality conversion concept aimed at enhancing emotion recognition performance on the MELD dataset. We assess our approach through two experiments: first, a method named Modality-Conversion that employs automatic speech recognition (ASR) systems, followed by a text classifier; second, we assume perfect ASR output and investigate the impact of modality conversion on SER, this method is called Modality-Conversion++. Our findings indicate that the first method yields substantial results, while the second method outperforms state-of-the-art (SOTA) speech-based approaches in terms of SER weighted-F1 (WF1) score on the MELD dataset. This research highlights the potential of modality conversion for tasks that can be conducted in alternative modalities.
    
[^6]: 通过场景知识推进视觉对齐：基准与方法

    Advancing Visual Grounding with Scene Knowledge: Benchmark and Method. (arXiv:2307.11558v1 [cs.CV])

    [http://arxiv.org/abs/2307.11558](http://arxiv.org/abs/2307.11558)

    本文提出了一种基于场景知识的视觉对齐新基准SK-VG，通过迫使模型具备对长篇场景知识进行推理的能力，对图像和文本进行细粒度对齐。

    

    视觉对齐旨在建立视觉和语言之间的细粒度对齐。在理想情况下，它可以成为对视觉和语言模型进行评估的基准，以评估它们对图像和文本的理解以及它们在联合空间上的推理能力。然而，大多数现有的视觉对齐数据集是使用简单的描述文本构建的，这些文本不需要对图像和文本进行足够的推理。在最近的一项研究中~\cite{luo2022goes}，已经证明了一个简单的基于LSTM的文本编码器在主流视觉对齐数据集上可以取得最先进的性能，而无需预训练。因此，在本文中，我们提出了一种新的\textbf{S}cene \textbf{K}nowledge-guided \textbf{V}isual \textbf{G}rounding (SK-VG)的基准，其中图像内容和引用表达不足以对齐目标对象，迫使模型对长篇场景知识进行推理能力。为了完成这个任务，我们提出了两种方法来接受t

    Visual grounding (VG) aims to establish fine-grained alignment between vision and language. Ideally, it can be a testbed for vision-and-language models to evaluate their understanding of the images and texts and their reasoning abilities over their joint space. However, most existing VG datasets are constructed using simple description texts, which do not require sufficient reasoning over the images and texts. This has been demonstrated in a recent study~\cite{luo2022goes}, where a simple LSTM-based text encoder without pretraining can achieve state-of-the-art performance on mainstream VG datasets. Therefore, in this paper, we propose a novel benchmark of \underline{S}cene \underline{K}nowledge-guided \underline{V}isual \underline{G}rounding (SK-VG), where the image content and referring expressions are not sufficient to ground the target objects, forcing the models to have a reasoning ability on the long-form scene knowledge. To perform this task, we propose two approaches to accept t
    
[^7]: 桥接视觉和语言编码器：参数高效的引用图像分割调整

    Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation. (arXiv:2307.11545v1 [cs.CV])

    [http://arxiv.org/abs/2307.11545](http://arxiv.org/abs/2307.11545)

    本研究针对引用图像分割问题进行了参数高效调整的探索。我们提出了一种名为 Bridger 的适配器，在模型中实现了跨模态信息交换和任务特定信息注入，并设计了一个轻量级的图像分割解码器。通过仅进行1.61％ 至 3.38％ 的主干参数更新，我们的方法在挑战性基准测试中实现了可比或更优的性能。

    

    参数高效调整 (PET) 在减少参数数量的同时保持性能和提供更好的硬件资源节省方面引起了人们的关注，但很少研究密集预测任务和模态之间的交互。本文探讨了引用图像分割上的高效调整问题。我们提出了一种名为 Bridger 的新型适配器，用于促进跨模态信息交换并将任务特定信息注入预训练模型。我们还为图像分割设计了一个轻量级解码器。我们的方法在挑战性基准测试中通过仅进行1.61％ 至 3.38％ 的主干参数更新，实现了可比或更优的性能。代码可在 \url{https://github.com/kkakkkka/ETRIS} 获取。

    Parameter Efficient Tuning (PET) has gained attention for reducing the number of parameters while maintaining performance and providing better hardware resource savings, but few studies investigate dense prediction tasks and interaction between modalities. In this paper, we do an investigation of efficient tuning problems on referring image segmentation. We propose a novel adapter called Bridger to facilitate cross-modal information exchange and inject task-specific information into the pre-trained model. We also design a lightweight decoder for image segmentation. Our approach achieves comparable or superior performance with only 1.61\% to 3.38\% backbone parameter updates, evaluated on challenging benchmarks. The code is available at \url{https://github.com/kkakkkka/ETRIS}.
    
[^8]: 使用机器学习进行多模态仇恨言论检测

    Multi-modal Hate Speech Detection using Machine Learning. (arXiv:2307.11519v1 [cs.AI])

    [http://arxiv.org/abs/2307.11519](http://arxiv.org/abs/2307.11519)

    本研究提出了一种使用多模态系统的方法，通过提取图像特征、音频特征值和文本，结合机器学习和自然语言处理技术，来检测视频内容中的仇恨言论。

    

    随着互联网用户和媒体内容的不断增长，追踪音频和视频中的仇恨言论变得非常困难。将视频或音频转换为文本并不能准确检测到仇恨言论，因为人们有时会将仇恨词汇作为幽默或愉快的意味使用，并在视频中使用不同的声调或展示不同的动作。当前最先进的仇恨言论检测模型大多是基于单一模态的。本研究提出了一种多模态系统的综合方法，通过提取图像特征、音频中的特征值、文本和使用机器学习和自然语言处理来检测视频内容中的仇恨言论。

    With the continuous growth of internet users and media content, it is very hard to track down hateful speech in audio and video. Converting video or audio into text does not detect hate speech accurately as human sometimes uses hateful words as humorous or pleasant in sense and also uses different voice tones or show different action in the video. The state-ofthe-art hate speech detection models were mostly developed on a single modality. In this research, a combined approach of multimodal system has been proposed to detect hate speech from video contents by extracting feature images, feature values extracted from the audio, text and used machine learning and Natural language processing.
    
[^9]: IndigoVX: 人类智慧与人工智能相结合的最优决策方法

    IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making. (arXiv:2307.11516v1 [cs.AI])

    [http://arxiv.org/abs/2307.11516](http://arxiv.org/abs/2307.11516)

    IndigoVX是一种将人类智慧与人工智能相结合的最优决策方法，通过迭代反馈循环，利用人类专家的背景知识和人工智能的数据驱动洞见，制定和优化朝着明确定义的目标的策略，并使用定量化的三分数模式进行评估和改进。

    

    本文定义了一种新的方法，通过将人类智慧与人工智能相结合，实现最优目标解决。我们提出的人工智能系统，Indigo，是指通过迭代目标导向优化进行知情数值决策。当与人类协作者结合时，我们将这个联合系统命名为IndigoVX，即虚拟专家。该系统概念简单。我们设想该方法可以应用于游戏或商业策略，人类提供战略背景，而人工智能提供最佳的数据驱动移动。Indigo通过迭代反馈循环运作，利用人类专家的背景知识和人工智能的数据驱动洞见，制定和优化朝着明确定义的目标的策略。使用定量化的三分数模式，这种混合化允许联合团队评估策略并改进计划，同时实时适应挑战和变化。

    This paper defines a new approach for augmenting human intelligence with AI for optimal goal solving. Our proposed AI, Indigo, is an acronym for Informed Numerical Decision-making through Iterative Goal-Oriented optimization. When combined with a human collaborator, we term the joint system IndigoVX, for Virtual eXpert. The system is conceptually simple. We envisage this method being applied to games or business strategies, with the human providing strategic context and the AI offering optimal, data-driven moves. Indigo operates through an iterative feedback loop, harnessing the human expert's contextual knowledge and the AI's data-driven insights to craft and refine strategies towards a well-defined goal. Using a quantified three-score schema, this hybridization allows the combined team to evaluate strategies and refine their plan, while adapting to challenges and changes in real-time.
    
[^10]: 将人类翻译风格融入英土文学机器翻译

    Incorporating Human Translator Style into English-Turkish Literary Machine Translation. (arXiv:2307.11457v1 [cs.CL])

    [http://arxiv.org/abs/2307.11457](http://arxiv.org/abs/2307.11457)

    本论文研究了英土文学翻译，在机器翻译模型中采用翻译家的风格特征，并通过微调预训练模型获得了高度还原人类译者风格的机器翻译效果。

    

    尽管机器翻译系统主要设计用于一般领域，但存在将这些系统适应其他领域（如文学翻译）的趋势。本文着重研究英土文学翻译，并开发考虑翻译家风格特征的机器翻译模型。我们通过人工对齐的特定译者作品来微调预训练的机器翻译模型。我们对手动对齐、自动对齐、数据增强方法和语料库大小对翻译效果进行了详细分析。我们提出了一种基于风格特征的方法来评估译者在输出翻译中的风格。我们展示了通过将模型适应到译者的风格，可以高度重现人类译者的风格在目标机器翻译中的效果。

    Although machine translation systems are mostly designed to serve in the general domain, there is a growing tendency to adapt these systems to other domains like literary translation. In this paper, we focus on English-Turkish literary translation and develop machine translation models that take into account the stylistic features of translators. We fine-tune a pre-trained machine translation model by the manually-aligned works of a particular translator. We make a detailed analysis of the effects of manual and automatic alignments, data augmentation methods, and corpus size on the translations. We propose an approach based on stylistic features to evaluate the style of a translator in the output translations. We show that the human translator style can be highly recreated in the target machine translations by adapting the models to the style of the translator.
    
[^11]: 自发语音的主题识别：用嵌入式语言信息丰富音频特征

    Topic Identification For Spontaneous Speech: Enriching Audio Features With Embedded Linguistic Information. (arXiv:2307.11450v1 [eess.AS])

    [http://arxiv.org/abs/2307.11450](http://arxiv.org/abs/2307.11450)

    本研究探讨了自发语音中主题识别的解决方案，通过比较纯音频和混合多模态技术的效果。实验结果表明，在资源有限的情况下，纯音频解决方案是可行的选项，而混合多模态解决方案获得了最佳结果。

    

    传统的音频主题识别解决方案依赖于自动语音识别系统（ASR）生成用作文本模型输入的转录。这些方法在高资源场景下效果良好，其中有足够的数据来训练管道的两个组件。然而，在低资源情况下，即使ASR系统可用，也会产生低质量的转录，导致文本分类器效果不佳。此外，包含停顿的自发语音进一步降低了ASR模型的性能。本文通过比较仅使用音频和混合多模态技术来探讨替代标准仅文本解决方案的方法。在自发的芬兰语音上评估的模型表明，当ASR组件不可用时，纯音频解决方案是一个可行的选项，而混合多模态解决方案获得了最佳结果。

    Traditional topic identification solutions from audio rely on an automatic speech recognition system (ASR) to produce transcripts used as input to a text-based model. These approaches work well in high-resource scenarios, where there are sufficient data to train both components of the pipeline. However, in low-resource situations, the ASR system, even if available, produces low-quality transcripts, leading to a bad text-based classifier. Moreover, spontaneous speech containing hesitations can further degrade the performance of the ASR model. In this paper, we investigate alternatives to the standard text-only solutions by comparing audio-only and hybrid techniques of jointly utilising text and audio features. The models evaluated on spontaneous Finnish speech demonstrate that purely audio-based solutions are a viable option when ASR components are not available, while the hybrid multi-modal solutions achieve the best results.
    
[^12]: MeetEval: 一种用于会议转录系统字错误率计算的工具包

    MeetEval: A Toolkit for Computation of Word Error Rates for Meeting Transcription Systems. (arXiv:2307.11394v1 [cs.CL])

    [http://arxiv.org/abs/2307.11394](http://arxiv.org/abs/2307.11394)

    MeetEval是一个计算会议转录系统字错误率的工具包，它通过时间约束来提高匹配质量并加速匹配算法。

    

    MeetEval是一个开源工具包，用于评估各种会议转录系统。它提供了一个统一的界面，用于计算常用的字错误率（WER），包括cpWER、ORC WER和MIMO WER等其他WER定义。我们通过时间约束扩展了cpWER的计算，以确保只有在时间对齐合理的情况下才将单词识别为正确。这样可以更好地匹配假设字符串与参考字符串，更接近实际的转录质量，并且如果系统提供了不准确的时间标注，将对其进行惩罚。由于通常没有单词级别的时间信息，我们提供了一种从片段级别时间（例如一个句子）近似到确切的单词级时间的方法，并且证明了近似方法与具有确切单词级别注释的匹配导致类似的WER。与此同时，时间约束还导致匹配算法的加速，这超过了倾向拼凑的时间约束。

    MeetEval is an open-source toolkit to evaluate all kinds of meeting transcription systems. It provides a unified interface for the computation of commonly used Word Error Rates (WERs), specifically cpWER, ORC WER and MIMO WER along other WER definitions. We extend the cpWER computation by a temporal constraint to ensure that only words are identified as correct when the temporal alignment is plausible. This leads to a better quality of the matching of the hypothesis string to the reference string that more closely resembles the actual transcription quality, and a system is penalized if it provides poor time annotations. Since word-level timing information is often not available, we present a way to approximate exact word-level timings from segment-level timings (e.g., a sentence) and show that the approximation leads to a similar WER as a matching with exact word-level annotations. At the same time, the time constraint leads to a speedup of the matching algorithm, which outweighs the a
    
[^13]: 聊天GPT生成的文本中是否涉及ChatGPT？通过测量“波兰比率”来检测ChatGPT生成的文本

    Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect ChatGPT-Generated Text. (arXiv:2307.11380v1 [cs.CL])

    [http://arxiv.org/abs/2307.11380](http://arxiv.org/abs/2307.11380)

    本研究针对ChatGPT在文本生成中的作用进行了研究，提出了一种新的测量方法“波兰比率”，用于检测ChatGPT生成的文本中的涉及程度。同时，还引入了一个新的数据集HPPT，用于构建更稳健的检测器。

    

    大规模语言模型如ChatGPT在文本生成方面具有显著能力，这激发了研究人员开发检测器以减轻潜在风险，包括错误信息、网络钓鱼和学术不诚实。然而，大多数以前的研究主要针对区分纯粹由ChatGPT生成的文本和人工撰写的文本的检测器。然而，这种方法在区分通过人机协作生成的文本（例如ChatGPT润色的文本）上失效。为了填补这一空白，我们引入了一个新颖的数据集HPPT（ChatGPT润色的学术摘要），以构建更强大的检测器。该数据集与现有语料库不同，它包括人工撰写的文本和ChatGPT润色的摘要对，而不仅仅是ChatGPT生成的文本。此外，我们提出了“波兰比率”的方法，这是一种衡量ChatGPT在文本生成中参与程度的创新指标。

    The remarkable capabilities of large-scale language models, such as ChatGPT, in text generation have incited awe and spurred researchers to devise detectors to mitigate potential risks, including misinformation, phishing, and academic dishonesty. Despite this, most previous studies, including HC3, have been predominantly geared towards creating detectors that differentiate between purely ChatGPT-generated texts and human-authored texts. This approach, however, fails to work on discerning texts generated through human-machine collaboration, such as ChatGPT-polished texts. Addressing this gap, we introduce a novel dataset termed HPPT (ChatGPT-polished academic abstracts), facilitating the construction of more robust detectors. It diverges from extant corpora by comprising pairs of human-written and ChatGPT-polished abstracts instead of purely ChatGPT-generated texts. Additionally, we propose the "Polish Ratio" method, an innovative measure of ChatGPT's involvement in text generation base
    
[^14]: CohortGPT：一种用于临床研究参与者招募的增强型GPT

    CohortGPT: An Enhanced GPT for Participant Recruitment in Clinical Study. (arXiv:2307.11346v1 [cs.CL])

    [http://arxiv.org/abs/2307.11346](http://arxiv.org/abs/2307.11346)

    CohortGPT是一种增强型GPT，用于解决临床研究中的参与者招募任务。此研究发现传统的大型语言模型在医疗文本分类中的性能一般，这可能是由于它们忽略了语言中的上下文信息。

    

    基于非结构化医疗文本（如临床记录和放射学报告）进行参与者招募是临床研究中具有挑战性但重要的任务。最近，大型语言模型（LLMs）如ChatGPT在语言理解、推理和生成方面取得了巨大成功。因此，有必要测试它们在解决临床研究中的参与者招募任务中的可行性。然而，当应用于知识密集型问题设置（如医疗文本分类）时，LLMs的性能一般。可能的解释是LLMs仅使用医疗文本，忽略了语言中丰富的上下文信息。

    Participant recruitment based on unstructured medical texts such as clinical notes and radiology reports has been a challenging yet important task for the cohort establishment in clinical research. Recently, Large Language Models (LLMs) such as ChatGPT have achieved tremendous success in various downstream tasks thanks to their promising performance in language understanding, inference, and generation. It is then natural to test their feasibility in solving the cohort recruitment task, which involves the classification of a given paragraph of medical text into disease label(s). However, when applied to knowledge-intensive problem settings such as medical text classification, where the LLMs are expected to understand the decision made by human experts and accurately identify the implied disease labels, the LLMs show a mediocre performance. A possible explanation is that, by only using the medical text, the LLMs neglect to use the rich context of additional information that languages aff
    
[^15]: DEFTri: 电子商务中产品缺陷分类的少样本标签融合上下文表示学习

    DEFTri: A Few-Shot Label Fused Contextual Representation Learning For Product Defect Triage in e-Commerce. (arXiv:2307.11344v1 [cs.SE])

    [http://arxiv.org/abs/2307.11344](http://arxiv.org/abs/2307.11344)

    本文提出了一个使用标签融合文本嵌入和优化上下文表示的DEFTri框架，以改进电子商务中的产品缺陷分类。同时，通过少样本训练和弱监督学习，引入了沃尔玛的专有数据集。

    

    在大规模敏捷软件开发生命周期的电子商务中，缺陷分类是一个时间敏感且关键的过程。该领域由于人为和流程依赖性而引起的低效性，已经激发了使用机器学习的自动化方法来准确地将缺陷分配给符合条件的团队的研究。本文提出了一个新的框架DEFTri，使用经过微调的先进预训练BERT模型在标签融合的文本嵌入中改进了人工生成的产品缺陷的上下文表示。对于我们的多标签文本分类缺陷分类任务，我们还在少样本设置下使用了沃尔玛的专有产品缺陷数据集，并使用了弱监督和对抗性学习。

    Defect Triage is a time-sensitive and critical process in a large-scale agile software development lifecycle for e-commerce. Inefficiencies arising from human and process dependencies in this domain have motivated research in automated approaches using machine learning to accurately assign defects to qualified teams. This work proposes a novel framework for automated defect triage (DEFTri) using fine-tuned state-of-the-art pre-trained BERT on labels fused text embeddings to improve contextual representations from human-generated product defects. For our multi-label text classification defect triage task, we also introduce a Walmart proprietary dataset of product defects using weak supervision and adversarial learning, in a few-shot setting.
    
[^16]: 使预训练语言模型成为任务解决器和自校准器

    Making Pre-trained Language Models both Task-solvers and Self-calibrators. (arXiv:2307.11316v1 [cs.CL])

    [http://arxiv.org/abs/2307.11316](http://arxiv.org/abs/2307.11316)

    该论文研究了如何使预训练语言模型成为任务解决器和自校准器，在有限的训练样本、数据不平衡和其他实际挑战下进行了探索。

    

    预训练语言模型（PLMs）在各种实际系统中作为骨干。对于高风险应用，合理的置信度估计对于预测同样重要。虽然PLMs的常规置信度分数已经可以有效利用，但它们在错误预测中始终变得过于自信，这在实践中是不可取的。之前的工作表明，引入额外的校准任务可以缓解这个问题。基本思想是获得额外的数据来训练模型，以预测其初始预测的置信度。然而，它只是展示了这种方法的可行性，假设引入的校准任务有丰富的额外可用样本。在这项工作中，我们考虑到实际情况，我们需要有效利用训练样本，使PLMs成为任务解决器和自校准器。提出了三个挑战，包括有限的训练样本、数据不平衡和…

    Pre-trained language models (PLMs) serve as backbones for various real-world systems. For high-stake applications, it's equally essential to have reasonable confidence estimations in predictions. While the vanilla confidence scores of PLMs can already be effectively utilized, PLMs consistently become overconfident in their wrong predictions, which is not desirable in practice. Previous work shows that introducing an extra calibration task can mitigate this issue. The basic idea involves acquiring additional data to train models in predicting the confidence of their initial predictions. However, it only demonstrates the feasibility of this kind of method, assuming that there are abundant extra available samples for the introduced calibration task. In this work, we consider the practical scenario that we need to effectively utilize training samples to make PLMs both task-solvers and self-calibrators. Three challenges are presented, including limited training samples, data imbalance, and 
    
[^17]: 生成图像特定文本改善细粒度图像分类

    Generating Image-Specific Text Improves Fine-grained Image Classification. (arXiv:2307.11315v1 [cs.CV])

    [http://arxiv.org/abs/2307.11315](http://arxiv.org/abs/2307.11315)

    本文提出了一种名为GIST的方法，用于从仅图像数据集中生成图像特定的细粒度文本描述，并通过将其用于微调视觉语言模型来改进图像分类的效果。

    

    最近的视觉语言模型在许多图像分类任务上优于仅视觉模型。然而，由于缺乏配对的文本/图像描述，对于细粒度图像分类来说，仍然很难对这些模型进行微调。在这项工作中，我们提出了一种名为GIST的方法，用于从仅图像数据集中生成图像特定的细粒度文本描述，并表明这些文本描述可以用于改善分类。我们方法的关键部分包括：1. 使用特定领域的提示为预训练的大型语言模型生成多样的细粒度文本描述，以及2. 使用预训练的视觉语言模型将每个图像与保留标签的文本描述进行匹配，这些描述捕捉了图像中相关的视觉特征。我们通过在图像和生成的文本对上微调视觉语言模型来学习一个对齐的视觉语言表示空间，以实现改进的分类。我们评估了GIST的效果。

    Recent vision-language models outperform vision-only models on many image classification tasks. However, because of the absence of paired text/image descriptions, it remains difficult to fine-tune these models for fine-grained image classification. In this work, we propose a method, GIST, for generating image-specific fine-grained text descriptions from image-only datasets, and show that these text descriptions can be used to improve classification. Key parts of our method include 1. prompting a pretrained large language model with domain-specific prompts to generate diverse fine-grained text descriptions for each class and 2. using a pretrained vision-language model to match each image to label-preserving text descriptions that capture relevant visual features in the image. We demonstrate the utility of GIST by fine-tuning vision-language models on the image-and-generated-text pairs to learn an aligned vision-language representation space for improved classification. We evaluate our l
    
[^18]: 生成器-检索器-生成器：开放域问答的新方法

    Generator-Retriever-Generator: A Novel Approach to Open-domain Question Answering. (arXiv:2307.11278v1 [cs.CL])

    [http://arxiv.org/abs/2307.11278](http://arxiv.org/abs/2307.11278)

    生成器-检索器-生成器（GRG）是一种新方法，将文档检索技术与大型语言模型相结合，以生成开放域问答的准确和信息丰富的答案。

    

    开放域问答任务通常需要从大型语料库中检索相关信息以生成准确的答案。我们提出了一种称为生成器-检索器-生成器（GRG）的新方法，将文档检索技术与大型语言模型（LLM）相结合，首先通过给定问题提示模型生成上下文文档。同时，双编码器网络从外部语料库中检索与问题相关的文档。生成和检索的文档然后传递给第二个LLM，生成最终答案。通过结合文档检索和LLM生成，我们的方法解决了开放域问答的挑战，例如生成信息丰富和上下文相关的答案。GRG在TriviaQA、NQ和WebQ数据集上表现优于现有的生成-读取和检索-读取流水线（GENREAD和RFiD），分别至少提高了+5.2、+4.2和+1.6的性能。

    Open-domain question answering (QA) tasks usually require the retrieval of relevant information from a large corpus to generate accurate answers. We propose a novel approach called Generator-Retriever-Generator (GRG) that combines document retrieval techniques with a large language model (LLM), by first prompting the model to generate contextual documents based on a given question. In parallel, a dual-encoder network retrieves documents that are relevant to the question from an external corpus. The generated and retrieved documents are then passed to the second LLM, which generates the final answer. By combining document retrieval and LLM generation, our approach addresses the challenges of open-domain QA, such as generating informative and contextually relevant answers. GRG outperforms the state-of-the-art generate-then-read and retrieve-then-read pipelines (GENREAD and RFiD) improving their performance at least by +5.2, +4.2, and +1.6 on TriviaQA, NQ, and WebQ datasets, respectively.
    
[^19]: 对生物医学自然语言处理中的联邦学习进行系统评估

    A Systematic Evaluation of Federated Learning on Biomedical Natural Language Processing. (arXiv:2307.11254v1 [cs.CL])

    [http://arxiv.org/abs/2307.11254](http://arxiv.org/abs/2307.11254)

    本研究对医学领域中的联邦学习在生物医学自然语言处理中的应用进行了系统评估，结果显示联邦学习模型优于单独训练的模型，并且在考虑数据隐私的情况下仍能取得良好的效果。

    

    语言模型（LM）如BERT和GPT已经改变了自然语言处理（NLP）。然而，隐私敏感的领域，特别是医疗领域，由于有限的数据访问和由《健康保险便携性和责任法案》（HIPPA）和《通用数据保护条例》（GDPR）等法规的隐私约束，面临着训练LM的挑战。联邦学习（FL）提供了一种分散的解决方案，既能够实现协同学习，又能够确保数据隐私的保护。在本研究中，我们对医学中的FL进行了系统评估，涵盖了六个生物医学NLP任务，使用了八个语料库和六个LM。我们的结果表明：1）FL模型始终优于单个客户端数据训练的LM，并且有时能够与使用汇总数据训练的模型匹配；2）在总数据量固定的情况下，使用更多客户端进行FL训练的LM表现出较差的性能，但基于预训练的转换器模型表现出更强的鲁棒性；3）LM们

    Language models (LMs) like BERT and GPT have revolutionized natural language processing (NLP). However, privacy-sensitive domains, particularly the medical field, face challenges to train LMs due to limited data access and privacy constraints imposed by regulations like the Health Insurance Portability and Accountability Act (HIPPA) and the General Data Protection Regulation (GDPR). Federated learning (FL) offers a decentralized solution that enables collaborative learning while ensuring the preservation of data privacy. In this study, we systematically evaluate FL in medicine across $2$ biomedical NLP tasks using $6$ LMs encompassing $8$ corpora. Our results showed that: 1) FL models consistently outperform LMs trained on individual client's data and sometimes match the model trained with polled data; 2) With the fixed number of total data, LMs trained using FL with more clients exhibit inferior performance, but pre-trained transformer-based models exhibited greater resilience. 3) LMs
    
[^20]: Jina Embeddings:一种新颖的高性能句子嵌入模型

    Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models. (arXiv:2307.11224v1 [cs.CL])

    [http://arxiv.org/abs/2307.11224](http://arxiv.org/abs/2307.11224)

    Jina Embeddings是一组高性能的句子嵌入模型，能够捕捉文本的语义本质。该论文详细介绍了Jina Embeddings的开发过程，并通过性能评估验证了其优越性能。

    

    Jina Embeddings由一组高性能的句子嵌入模型组成，能够将各种文本输入转化为数值表示，从而捕捉文本的语义本质。虽然这些模型并非专门设计用于文本生成，但在密集检索和语义文本相似性等应用中表现出色。本文详细介绍了Jina Embeddings的开发过程，从创建高质量的成对和三元数据集开始。它强调了数据清理在数据集准备中的关键作用，并对模型训练过程进行了深入探讨，最后利用Massive Textual Embedding Benchmark（MTEB）进行了全面的性能评估。

    Jina Embeddings constitutes a set of high-performance sentence embedding models adept at translating various textual inputs into numerical representations, thereby capturing the semantic essence of the text. While these models are not exclusively designed for text generation, they excel in applications such as dense retrieval and semantic textual similarity. This paper details the development of Jina Embeddings, starting with the creation of a high-quality pairwise and triplet dataset. It underlines the crucial role of data cleaning in dataset preparation, gives in-depth insights into the model training process, and concludes with a comprehensive performance evaluation using the Massive Textual Embedding Benchmark (MTEB).
    
[^21]: UMLS-KGI-BERT：基于转化器的生物医学实体识别中的数据中心知识整合

    UMLS-KGI-BERT: Data-Centric Knowledge Integration in Transformers for Biomedical Entity Recognition. (arXiv:2307.11170v1 [cs.CL])

    [http://arxiv.org/abs/2307.11170](http://arxiv.org/abs/2307.11170)

    这项工作提出了一种数据中心范式，通过从UMLS中提取文本序列来丰富生物医学转换器编码器LMs的语言表示。

    

    在应用领域的自然语言处理中，预训练的转化器语言模型（LMs）已成为主导范式。这些模型在信息提取、问答、情感分析、文档分类等任务上取得了最先进的性能。在生物医学领域，已经取得了重要进展，将该范式适应于需要结合领域特定知识以及语言的统计建模的NLP任务。具体而言，该领域的研究重点是如何最好地构建LMs，既考虑医学文本中令牌分布的模式，又考虑UMLS等术语资源中包含的丰富结构化信息。本研究提出了一种数据中心范式，通过从UMLS中提取文本序列来丰富生物医学转换器编码器LMs的语言表示。这使得可以应用基于图的学习目标。

    Pre-trained transformer language models (LMs) have in recent years become the dominant paradigm in applied NLP. These models have achieved state-of-the-art performance on tasks such as information extraction, question answering, sentiment analysis, document classification and many others. In the biomedical domain, significant progress has been made in adapting this paradigm to NLP tasks that require the integration of domain-specific knowledge as well as statistical modelling of language. In particular, research in this area has focused on the question of how best to construct LMs that take into account not only the patterns of token distribution in medical text, but also the wealth of structured information contained in terminology resources such as the UMLS. This work contributes a data-centric paradigm for enriching the language representations of biomedical transformer-encoder LMs by extracting text sequences from the UMLS. This allows for graph-based learning objectives to be comb
    
[^22]: 图像和声音的滥用用于在多模态LLMs中进行间接指令注入

    (Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v1 [cs.CR])

    [http://arxiv.org/abs/2307.10490](http://arxiv.org/abs/2307.10490)

    本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。

    

    我们展示了如何利用图像和声音在多模态LLMs中进行间接提示和指令注入。攻击者生成与提示相对应的对抗扰动，并将其融入图像或音频录音中。当用户向（未修改的良性）模型询问被扰动的图像或音频时，扰动会引导模型输出攻击者选择的文本和/或使后续对话遵循攻击者的指令。我们用几个概念验证示例针对LLaVa和PandaGPT来说明这种攻击。

    We demonstrate how images and sounds can be used for indirect prompt and instruction injection in multi-modal LLMs. An attacker generates an adversarial perturbation corresponding to the prompt and blends it into an image or audio recording. When the user asks the (unmodified, benign) model about the perturbed image or audio, the perturbation steers the model to output the attacker-chosen text and/or make the subsequent dialog follow the attacker's instruction. We illustrate this attack with several proof-of-concept examples targeting LLaVa and PandaGPT.
    
[^23]: PharmacyGPT：AI药师

    PharmacyGPT: The AI Pharmacist. (arXiv:2307.10432v1 [cs.CL])

    [http://arxiv.org/abs/2307.10432](http://arxiv.org/abs/2307.10432)

    PharmacyGPT是一个新颖的框架，利用大型语言模型（LLM）来仿真临床药师的角色。通过生成患者群集、制定用药计划和预测患者结果，PharmacyGPT在临床药学中具有潜在应用和限制，为促进负责任和有效使用人工智能技术做出贡献。

    

    本研究介绍了PharmacyGPT，这是一个新颖的框架，用于评估大型语言模型（LLM）（如ChatGPT和GPT-4）在仿真临床药师角色方面的能力。我们的方法包括利用LLM生成可理解的患者群集、制定用药计划和预测患者结果。我们使用从北卡罗来纳大学教堂山医院（UNC）重症监护病房（ICU）获取的真实数据进行调查。我们的分析提供了对LLM在临床药学领域潜在应用和限制的有价值见解，对患者护理和未来基于AI的医疗解决方案的开发具有重要意义。通过评估PharmacyGPT的性能，我们旨在为有关在医疗保健环境中整合人工智能的持续讨论做出贡献，最终促进负责任和有效使用此类技术。

    In this study, we introduce PharmacyGPT, a novel framework to assess the capabilities of large language models (LLMs) such as ChatGPT and GPT-4 in emulating the role of clinical pharmacists. Our methodology encompasses the utilization of LLMs to generate comprehensible patient clusters, formulate medication plans, and forecast patient outcomes. We conduct our investigation using real data acquired from the intensive care unit (ICU) at the University of North Carolina Chapel Hill (UNC) Hospital. Our analysis offers valuable insights into the potential applications and limitations of LLMs in the field of clinical pharmacy, with implications for both patient care and the development of future AI-driven healthcare solutions. By evaluating the performance of PharmacyGPT, we aim to contribute to the ongoing discourse surrounding the integration of artificial intelligence in healthcare settings, ultimately promoting the responsible and efficacious use of such technologies.
    
[^24]: 日语句子分类和命名实体识别任务中的相互增强效应

    Mutual Reinforcement Effects in Japanese Sentence Classification and Named Entity Recognition Tasks. (arXiv:2307.10291v1 [cs.CL])

    [http://arxiv.org/abs/2307.10291](http://arxiv.org/abs/2307.10291)

    该研究提出了一个综合分析方法，将句子分类和命名实体识别结合起来，并揭示了这两个信息提取子任务之间的相互增强效应。

    

    信息提取（IE）是自然语言处理中的重要领域。然而，对于传统分段方法在句子分类和命名实体识别任务中的复杂互动，目前研究尚不充分。本研究提出了一个综合分析方法，将句子分类和命名实体识别结合起来，旨在揭示和理解这两个信息提取子任务之间的相互增强效应。为了实现这个目标，我们引入了一个句子分类和命名实体识别多任务（SCNM）方法，结合了句子分类（SC）和命名实体识别（NER）。我们为SCNM开发了一个句子到标签生成（SLG）框架，并构建了一个包含SC和NER的维基百科数据集。通过格式转换器统一输入格式，使用生成模型生成SC标签、NER标签和相关文本段落。我们提出了一种新的神经网络模型，应用于日语句子分类和命名实体识别的任务，该模型利用了相互增强效应。

    Information extraction(IE) is a crucial subfield within natural language processing. However, for the traditionally segmented approach to sentence classification and Named Entity Recognition, the intricate interactions between these individual subtasks remain largely uninvestigated. In this study, we propose an integrative analysis, converging sentence classification with Named Entity Recognition, with the objective to unveil and comprehend the mutual reinforcement effect within these two information extraction subtasks. To achieve this, we introduce a Sentence Classification and Named Entity Recognition Multi-task (SCNM) approach that combines Sentence Classification (SC) and Named Entity Recognition (NER). We develop a Sentence-to-Label Generation (SLG) framework for SCNM and construct a Wikipedia dataset containing both SC and NER. Using a format converter, we unify input formats and employ a generative model to generate SC-labels, NER-labels, and associated text segments. We propos
    
[^25]: ZeroQuant-FP: 使用浮点格式进行LLMs训练后量化的一项飞跃

    ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats. (arXiv:2307.09782v1 [cs.LG])

    [http://arxiv.org/abs/2307.09782](http://arxiv.org/abs/2307.09782)

    ZeroQuant-FP通过使用浮点格式进行LLMs训练后量化，解决了在大型语言模型中平衡计算效率和保持模型质量的挑战，并发现FP8激活优于INT8，并且FP4权重表现与INT4相当甚至更优。

    

    在大型语言模型（LLMs）的复杂领域中，平衡计算效率和保持模型质量是一个巨大的挑战。本研究通过探讨浮点（FP）量化的可行性，特别关注FP8和FP4，以应对均匀量化的固有限制，尤其是处理离群值，并受到NVIDIA H100硬件的启发。我们的全面调查发现，在LLMs中，FP8激活始终优于其整数（INT8）等效，性能优势在包含超过十亿参数的模型中更为明显。对于权重量化，我们的研究结果表明，FP4的性能与INT4相当，甚至更优，简化了在像H100这样支持FP的硬件上的部署。为了减少由权重和激活之间差异引起的精度对齐开销，我们提出了两个缩放约束。

    In the complex domain of large language models (LLMs), striking a balance between computational efficiency and maintaining model quality is a formidable challenge. Navigating the inherent limitations of uniform quantization, particularly when dealing with outliers, and motivated by the launch of NVIDIA's H100 hardware, this study delves into the viability of floating-point (FP) quantization, particularly focusing on FP8 and FP4, as a potential solution. Our comprehensive investigation reveals that for LLMs, FP8 activation consistently outshines its integer (INT8) equivalent, with the performance edge becoming more noticeable in models possessing parameters beyond one billion. For weight quantization, our findings indicate that FP4 exhibits comparable, if not superior, performance to INT4, simplifying deployment on FP-supported hardware like H100. To mitigate the overhead from precision alignment caused by the disparity between weights and activations, we propose two scaling constraints
    
[^26]: 超越本地范围：全球图增强个性化新闻推荐

    Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v1 [cs.IR])

    [http://arxiv.org/abs/2307.06576](http://arxiv.org/abs/2307.06576)

    本文介绍了一种名为GLORY的模型，通过全局图与本地表示相结合，增强了个性化推荐系统。该模型通过构建全局感知历史新闻编码器来融合历史新闻表示，并考虑了用户隐藏的动机和行为。

    

    精确地向用户推荐候选新闻文章一直是个性化新闻推荐系统的核心挑战。大多数近期的研究主要集中在使用先进的自然语言处理技术从丰富的文本数据中提取语义信息，使用从本地历史新闻派生的基于内容的方法。然而，这种方法缺乏全局视角，未能考虑用户隐藏的动机和行为，超越语义信息。为了解决这个问题，我们提出了一种新颖的模型 GLORY（Global-LOcal news Recommendation sYstem），它结合了从其他用户学到的全局表示和本地表示，来增强个性化推荐系统。我们通过构建一个全局感知历史新闻编码器来实现这一目标，其中包括一个全局新闻图，并使用门控图神经网络来丰富新闻表示，从而通过历史新闻聚合器融合历史新闻表示。

    Precisely recommending candidate news articles to users has always been a core challenge for personalized news recommendation systems. Most recent works primarily focus on using advanced natural language processing techniques to extract semantic information from rich textual data, employing content-based methods derived from local historical news. However, this approach lacks a global perspective, failing to account for users' hidden motivations and behaviors beyond semantic information. To address this challenge, we propose a novel model called GLORY (Global-LOcal news Recommendation sYstem), which combines global representations learned from other users with local representations to enhance personalized recommendation systems. We accomplish this by constructing a Global-aware Historical News Encoder, which includes a global news graph and employs gated graph neural networks to enrich news representations, thereby fusing historical news representations by a historical news aggregator.
    
[^27]: GPT-FinRE: 使用大型语言模型进行金融关系提取的上下文学习

    GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models. (arXiv:2306.17519v1 [cs.CL])

    [http://arxiv.org/abs/2306.17519](http://arxiv.org/abs/2306.17519)

    本论文介绍了使用大型语言模型和上下文学习框架进行金融关系提取的解决方案。通过两种检索策略，无需学习的密集检索器和基于学习的检索器，我们能够从训练数据中找到与给定测试示例相关的上下文学习示范。

    

    关系提取（RE）是自然语言处理（NLP）中的一个关键任务，旨在识别和分类文本中提及的实体之间的关系。在金融领域，关系提取在从财经文件（如新闻文章、盈利报告和公司申报）中提取有价值信息方面起着至关重要的作用。本文描述了我们在一个名为REFinD的数据集上进行关系提取的解决方案。该数据集是作为SIGIR 2023举办的第四届从非结构化数据中发现知识的研讨会的共享任务的一部分发布的。我们在本文中采用了OpenAI模型，并应用了上下文学习（ICL）框架。我们利用两种检索策略从训练数据中找出与给定测试示例相关的前K个上下文学习示范/示例。第一个检索机制是无需学习的密集检索器，而另一个系统是基于学习的检索器。

    Relation extraction (RE) is a crucial task in natural language processing (NLP) that aims to identify and classify relationships between entities mentioned in text. In the financial domain, relation extraction plays a vital role in extracting valuable information from financial documents, such as news articles, earnings reports, and company filings. This paper describes our solution to relation extraction on one such dataset REFinD. The dataset was released along with shared task as a part of the Fourth Workshop on Knowledge Discovery from Unstructured Data in Financial Services, co-located with SIGIR 2023. In this paper, we employed OpenAI models under the framework of in-context learning (ICL). We utilized two retrieval strategies to find top K relevant in-context learning demonstrations / examples from training data for a given test example. The first retrieval mechanism, we employed, is a learning-free dense retriever and the other system is a learning-based retriever. We were able
    
[^28]: 基于大语言模型的中文细粒度金融情感分析

    Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models. (arXiv:2306.14096v1 [cs.CL])

    [http://arxiv.org/abs/2306.14096](http://arxiv.org/abs/2306.14096)

    本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。

    

    金融领域实体级别的细粒度情感分析是情感分析的重要子任务，目前面临着众多挑战。其中主要挑战之一来自于缺乏专门设计用于金融文本情感分析的高质量大规模标注语料库，这限制了开发有效文本处理技术所需的数据的可用性。大语言模型（LLMs）的最新进展在自然语言处理任务中取得了显著的性能，主要集中在语言模式匹配方面。在本文中，我们提出了一个新颖的、广泛的中文细粒度金融情感分析数据集FinChina SA，用于企业预警。我们对流行的现有开源LLMs使用我们的数据集进行了全面的评估和实验。我们坚信，我们的数据集将成为推动真实世界金融情感分析任务探索的宝贵资源。

    Entity-level fine-grained sentiment analysis in the financial domain is a crucial subtask of sentiment analysis and currently faces numerous challenges. The primary challenge stems from the lack of high-quality and large-scale annotated corpora specifically designed for financial text sentiment analysis, which in turn limits the availability of data necessary for developing effective text processing techniques. Recent advancements in large language models (LLMs) have yielded remarkable performance in natural language processing tasks, primarily centered around language pattern matching. In this paper, we propose a novel and extensive Chinese fine-grained financial sentiment analysis dataset, FinChina SA, for enterprise early warning. We thoroughly evaluate and experiment with well-known existing open-source LLMs using our dataset. We firmly believe that our dataset will serve as a valuable resource to advance the exploration of real-world financial sentiment analysis tasks, which shoul
    
[^29]: 非反事实增强在强健性方面对基于方面的情感分析的改进

    Towards Robust Aspect-based Sentiment Analysis through Non-counterfactual Augmentations. (arXiv:2306.13971v1 [cs.CL])

    [http://arxiv.org/abs/2306.13971](http://arxiv.org/abs/2306.13971)

    本研究提出了一种非反事实数据增强的替代方法，该方法使用保留目标方面相关语义的有噪声、成本效益较高的数据增强，通过对数据的不同版本之间的不变性进行建模以提高其鲁棒性，在标准和强度特定数据集上都显著改进了强预训练基线的性能。

    

    尽管最先进的自然语言处理模型在基于方面的情感分析（ABSA）方面表现出色，但有大量证据表明它们缺乏鲁棒性。特别是在面对分布外数据时，其性能显著降低。最近的解决方案依赖于反事实增强数据集展现了良好的结果，但由于无法访问显式的因果结构，它们本质上是有限的。在本文中，我们提出了一种替代方法，该方法依赖于非反事实数据增强。我们的提议依赖于使用带有噪声的，成本效益较高的数据增强来保留与目标方面相关联的语义。然后，我们的方法依赖于对数据的不同版本之间的不变性进行建模，从而提高其鲁棒性。一组全面的实验表明，我们的提议在标准和强度特定数据集上都显著改进了强预训练基线的性能。

    While state-of-the-art NLP models have demonstrated excellent performance for aspect based sentiment analysis (ABSA), substantial evidence has been presented on their lack of robustness. This is especially manifested as significant degradation in performance when faced with out-of-distribution data. Recent solutions that rely on counterfactually augmented datasets show promising results, but they are inherently limited because of the lack of access to explicit causal structure. In this paper, we present an alternative approach that relies on non-counterfactual data augmentation. Our proposal instead relies on using noisy, cost-efficient data augmentations that preserve semantics associated with the target aspect. Our approach then relies on modelling invariances between different versions of the data to improve robustness. A comprehensive suite of experiments shows that our proposal significantly improves upon strong pre-trained baselines on both standard and robustness-specific datase
    
[^30]: FAIR:用于准确推断判例颠倒的因果框架

    FAIR: A Causal Framework for Accurately Inferring Judgments Reversals. (arXiv:2306.11585v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.11585](http://arxiv.org/abs/2306.11585)

    本文提出了一个用于推断判例颠倒的因果框架（FAIR），通过采用因果推断方法挖掘判例颠倒的原因，并将因果关系注入神经网络，有效提高了神经网络的性能。

    

    最近几年，人工智能研究人员在法律智能方面取得了重大进展。然而，现有研究并未关注判例颠倒中所蕴含的重要价值，这限制了法律智能效率的提高。本文提出了一个可用于推断判例颠倒的因果框架（FAIR），该框架基于真实的中国判例对判例颠倒问题进行建模。我们使用因果推断方法挖掘判例颠倒的原因，并将得到的因果关系注入神经网络作为先验知识。然后，我们的框架在一个具有挑战性的数据集上作为法律判例预测任务进行验证。实验结果表明，我们的框架能够挖掘出判例颠倒中最关键的因素，得到的因果关系能够有效提高神经网络的性能。此外，我们还讨论了大型语言模型在法律领域的泛化能力。

    Artificial intelligence researchers have made significant advances in legal intelligence in recent years. However, the existing studies have not focused on the important value embedded in judgments reversals, which limits the improvement of the efficiency of legal intelligence. In this paper, we propose a causal Framework for Accurately Inferring case Reversals (FAIR), which models the problem of judgments reversals based on real Chinese judgments. We mine the causes of judgments reversals by causal inference methods and inject the obtained causal relationships into the neural network as a priori knowledge. And then, our framework is validated on a challenging dataset as a legal judgment prediction task. The experimental results show that our framework can tap the most critical factors in judgments reversal, and the obtained causal relationships can effectively improve the neural network's performance. In addition, we discuss the generalization ability of large language models for lega
    
[^31]: 大型语言模型增强的基于叙事的推荐系统

    Large Language Model Augmented Narrative Driven Recommendations. (arXiv:2306.02250v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.02250](http://arxiv.org/abs/2306.02250)

    这个论文研究了如何使用大型语言模型（LLMs）为基于叙事的推荐系统提供数据增强，以解决其缺乏训练数据的问题。

    

    基于叙事的推荐系统是一个信息获取问题，用户通过详细描述他们的偏好和背景来请求推荐，比如旅行者在描述他们的喜好、不喜欢和旅行情况时请求景点的推荐。随着自然语言对话界面在搜索和推荐系统中的兴起，这些请求变得越来越重要。然而，基于叙事的推荐系统缺乏丰富的训练数据，并且当前的平台通常不支持这些请求。幸运的是，传统的用户-物品交互数据集包含了丰富的文本数据，例如评论，这些评论经常描述了用户的偏好和背景 - 这些数据可以用来为基于叙事的推荐模型进行训练。在这项工作中，我们探索使用大型语言模型 (LLMs) 来进行数据增强，以训练基于叙事的推荐模型。

    Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context - this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with few-shot prompting and train retri
    
[^32]: 使用多任务学习增强抽取式摘要的连贯性

    Enhancing Coherence of Extractive Summarization with Multitask Learning. (arXiv:2305.12851v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12851](http://arxiv.org/abs/2305.12851)

    本研究提出了一种使用多任务学习架构来增强抽取式摘要的连贯性的方法。实验证明，该方法显著提高了抽取式摘要的连贯性，并在其他评价指标方面也表现出良好的性能。

    

    本研究提出了一种使用多任务学习架构来增强抽取式摘要的连贯性的方法。该架构包含一个抽取式摘要生成器和一个连贯性判别器模块。连贯性判别器通过在线训练增强了对输入句子连贯性的判断能力。同时，我们通过更新摘要生成器的参数来最大化连贯性判别器的连贯性分数。为了能够以可微分的方式训练抽取式摘要，我们引入了两种策略，包括预训练转换模型和转换矩阵方法，用于合并句子表示。实验证明，我们提出的方法显著提高了抽取式摘要中连贯句子在原始文章中按位置的比例（即自动句子级连贯度指标），而在其他自动评价指标方面也表现出良好的性能。

    This study proposes a multitask learning architecture for extractive summarization with coherence boosting. The architecture contains an extractive summarizer and coherent discriminator module. The coherent discriminator is trained online on the sentence vectors of the augmented textual input, thus improving its general ability of judging whether the input sentences are coherent. Meanwhile, we maximize the coherent scores from the coherent discriminator by updating the parameters of the summarizer. To make the extractive sentences trainable in a differentiable manner, we introduce two strategies, including pre-trained converting model (model-based) and converting matrix (MAT-based) that merge sentence representations. Experiments show that our proposed method significantly improves the proportion of consecutive sentences in the extracted summaries based on their positions in the original article (i.e., automatic sentence-level coherence metric), while the goodness in terms of other aut
    
[^33]: 可编辑用户档案的可控文本推荐方法

    Editable User Profiles for Controllable Text Recommendation. (arXiv:2304.04250v1 [cs.IR])

    [http://arxiv.org/abs/2304.04250](http://arxiv.org/abs/2304.04250)

    本文提出了一种新的概念值瓶颈模型LACE，用于可控文本推荐。该模型基于用户文档学习个性化的概念表示，并通过多种交互方式为用户提供了控制推荐的机制，验证了在离线和在线实验中该模型的推荐质量和有效性。

    

    实现高质量推荐的方法通常依赖于从交互数据中学习潜在表示。然而这些方法没有提供给用户控制所接收的推荐的机制。本文提出了LACE，一种新颖的概念值瓶颈模型，用于可控文本推荐。LACE基于用户交互的文档检索，将每个用户表示为简洁的可读的概念集，并基于用户文档学习概念的个性化表示。该基于概念的用户档案被利用来做出推荐。我们的模型设计通过透明的用户档案，提供了控制推荐的多种直观交互方式。我们首先在三个推荐任务（温启动、冷启动和零样本）的六个数据集上进行了离线评估，验证了从LACE获得的推荐质量。接下来，我们在在线实验中验证了LACE的有效性和用户控制能力。

    Methods for making high-quality recommendations often rely on learning latent representations from interaction data. These methods, while performant, do not provide ready mechanisms for users to control the recommendation they receive. Our work tackles this problem by proposing LACE, a novel concept value bottleneck model for controllable text recommendations. LACE represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents and learns personalized representations of the concepts based on user documents. This concept based user profile is then leveraged to make recommendations. The design of our model affords control over the recommendations through a number of intuitive interactions with a transparent user profile. We first establish the quality of recommendations obtained from LACE in an offline evaluation on three recommendation tasks spanning six datasets in warm-start, cold-start, and zero-shot setups. Next, we validate the 
    
[^34]: NusaCrowd：印尼自然语言处理资源的开源倡议

    NusaCrowd: Open Source Initiative for Indonesian NLP Resources. (arXiv:2212.09648v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09648](http://arxiv.org/abs/2212.09648)

    NusaCrowd是一个印尼自然语言处理资源的开源倡议，已汇集137个数据集和118个数据加载程序，为印尼语和印度尼西亚本地语言的自然语言处理研究提供了多种实验手段。

    

    我们提出了NusaCrowd，这是一个协作倡议，旨在收集和统一印尼语言的现有资源，包括开放以前非公开的资源。通过该倡议，我们汇集了137个数据集和118个标准化数据加载程序。数据集的质量已经经过手动和自动评估，它们的价值通过多个实验得到了证明。NusaCrowd的数据收集使得可以创建印尼语和印度尼西亚本地语言的零样本自然语言理解和生成基准，进一步推动了印尼语和印度尼西亚本地语言的多语言自动语音识别基准的创建。我们的工作致力于推进对在使用广泛的语言的自然语言处理（NLP）研究的发展，从而使之受到更多关注。

    We present NusaCrowd, a collaborative initiative to collect and unify existing resources for Indonesian languages, including opening access to previously non-public resources. Through this initiative, we have brought together 137 datasets and 118 standardized data loaders. The quality of the datasets has been assessed manually and automatically, and their value is demonstrated through multiple experiments. NusaCrowd's data collection enables the creation of the first zero-shot benchmarks for natural language understanding and generation in Indonesian and the local languages of Indonesia. Furthermore, NusaCrowd brings the creation of the first multilingual automatic speech recognition benchmark in Indonesian and the local languages of Indonesia. Our work strives to advance natural language processing (NLP) research for languages that are under-represented despite being widely spoken.
    
[^35]: ClueReader: 多跳机器阅读理解的异构图注意力网络

    ClueReader: Heterogeneous Graph Attention Network for Multi-hop Machine Reading Comprehension. (arXiv:2107.00841v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2107.00841](http://arxiv.org/abs/2107.00841)

    ClueReader是一种新型的异构图注意力网络模型，利用谱模型和注意机制，通过模拟祖母细胞概念来提升多跳机器阅读理解任务的推理能力和结果。

    

    多跳机器阅读理解是自然语言处理中一项具有挑战性的任务，因为它需要在多个文档之间进行更多的推理能力。基于图卷积网络的谱模型展现了良好的推理能力，并取得了竞争性的结果。然而，一些模型的分析和推理与人类的不一致。受认知神经科学中祖母细胞的概念启发，我们提出了一种名为ClueReader的异构图注意力网络模型，来模拟祖母细胞的概念。该模型旨在将多级表示中的语义特征组合起来，并通过注意机制自动集中或减轻信息以进行推理。ClueReader的命名是对模型模式的隐喻：它将查询的主题视为线索的起点，将推理实体视为桥梁点，将潜在候选实体视为祖母细胞，线索结束之后进行推理。

    Multi-hop machine reading comprehension is a challenging task in natural language processing as it requires more reasoning ability across multiple documents. Spectral models based on graph convolutional networks have shown good inferring abilities and lead to competitive results. However, the analysis and reasoning of some are inconsistent with those of humans. Inspired by the concept of grandmother cells in cognitive neuroscience, we propose a heterogeneous graph attention network model named ClueReader to imitate the grandmother cell concept. The model is designed to assemble the semantic features in multi-level representations and automatically concentrate or alleviate information for reasoning through the attention mechanism. The name ClueReader is a metaphor for the pattern of the model: it regards the subjects of queries as the starting points of clues, takes the reasoning entities as bridge points, considers the latent candidate entities as grandmother cells, and the clues end u
    
[^36]: 通过在线新闻的语义网络分析预测消费者信心

    Forecasting consumer confidence through semantic network analysis of online news. (arXiv:2105.04900v2 [econ.GN] UPDATED)

    [http://arxiv.org/abs/2105.04900](http://arxiv.org/abs/2105.04900)

    本研究使用语义网络分析在线新闻对消费者信心的影响，结果表明该方法能够预测消费者对经济形势的判断，提供了一种补充方法来估计消费者信心。

    

    本研究通过语义网络分析研究在线新闻对社会经济消费者态度的影响。使用覆盖四年的意大利媒体上的超过180万篇在线文章，我们计算特定经济相关关键词的语义重要性，以确定文章中出现的词语是否能够预测消费者对经济形势和消费者信心指数的判断。我们运用创新方法分析大规模文本数据，结合了文本挖掘和社会网络分析的方法和工具。结果显示，该指标对于判断当前家庭和国家情况具有较强的预测能力。我们的指标为消费者信心的估计提供了一种补充方法，减轻了传统基于调查的方法的局限性。

    This research studies the impact of online news on social and economic consumer perceptions through semantic network analysis. Using over 1.8 million online articles on Italian media covering four years, we calculate the semantic importance of specific economic-related keywords to see if words appearing in the articles could anticipate consumers' judgments about the economic situation and the Consumer Confidence Index. We use an innovative approach to analyze big textual data, combining methods and tools of text mining and social network analysis. Results show a strong predictive power for the judgments about the current households and national situation. Our indicator offers a complementary approach to estimating consumer confidence, lessening the limitations of traditional survey-based methods.
    

