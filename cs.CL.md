# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding.](http://arxiv.org/abs/2306.06094) | 本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。 |
| [^2] | [Trapping LLM Hallucinations Using Tagged Context Prompts.](http://arxiv.org/abs/2306.06085) | 本文提出一种使用标记的上下文提示的新方法，可以显著减少生成语言模型中的妄想症，提高对话代理的准确性和有效性。 |
| [^3] | [Improving Fairness and Robustness in End-to-End Speech Recognition through unsupervised clustering.](http://arxiv.org/abs/2306.06083) | 该论文提出了一种隐私保护的方法，通过无监督聚类提高端到端语音识别中的公平性和鲁棒性，并可以对所有人口统计学方面都有提高的效果。 |
| [^4] | [Visually-Grounded Descriptions Improve Zero-Shot Image Classification.](http://arxiv.org/abs/2306.06077) | 本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。 |
| [^5] | [Mind2Web: Towards a Generalist Agent for the Web.](http://arxiv.org/abs/2306.06070) | Mind2Web是第一个用于开发和评估通用Web代理的数据集，可以按照语言指令完成任意网站上的复杂任务。此数据集提供了三个必要元素：1）多样的领域、网站和任务，2）使用真实网站而非模拟和简化网站，3）广泛的用户交互模式。研究者使用Mind2Web进行了初步探索，使用小型LM过滤可以显着提高任务完成率的效果。 |
| [^6] | [Assisting Language Learners: Automated Trans-Lingual Definition Generation via Contrastive Prompt Learning.](http://arxiv.org/abs/2306.06058) | 本研究提出了一个Trans-Lingual Definition Generation (TLDG)任务，通过对比提示学习实现的自动跨语言定义生成。该方法通过生成母语使用者的语言的定义，协助语言学习者理解生僻词汇，实验证明对于生成更高质量的跨语言定义方面有显著的优越性。 |
| [^7] | [FinGPT: Open-Source Financial Large Language Models.](http://arxiv.org/abs/2306.06031) | FinGPT是一个开源的金融大型语言模型，提供了可访问和透明的资源来开发金融LLMs，其重要性在于自动数据筛选管道和轻量级低秩适应技术。 |
| [^8] | [HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine.](http://arxiv.org/abs/2306.06029) | HiTZ@Antidote采用深度学习和论证理论，提供数字医疗领域高质量的可解释AI预测解释。 |
| [^9] | [Automated Labeling of German Chest X-Ray Radiology Reports using Deep Learning.](http://arxiv.org/abs/2306.05997) | 本研究使用基于深度学习的CheXpert标签预测模型进行弱监督，显着优于基于规则的模型，在自动标注德语胸部X射线医学报告方面具有潜在价值。 |
| [^10] | [Language Models Can Learn Exceptions to Syntactic Rules.](http://arxiv.org/abs/2306.05969) | 语言模型能够通过分布特性学习规则的例外情况，通过研究动词在主动语态和被动语态中的相对可接受性和相对出现频率的正相关性进行支持。 |
| [^11] | [An Efficient Speech Separation Network Based on Recurrent Fusion Dilated Convolution and Channel Attention.](http://arxiv.org/abs/2306.05887) | 本文提出了一种使用循环融合扩张卷积和通道注意力的高效语音分离神经网络，其结构为编码器-解码器结构，具有较高的表现力和鲁棒性，可作为当前主流模型的有效替代模型。 |
| [^12] | [Good, but not always Fair: An Evaluation of Gender Bias for three commercial Machine Translation Systems.](http://arxiv.org/abs/2306.05882) | 本文对三个商业机器翻译系统进行了细致评估，在关注性别翻译和偏见的前提下，揭示了它们性别翻译方面的显着差异和偏见，这一点不会因为它们整体翻译质量的好坏而有所改变。 |
| [^13] | [Towards a Robust Detection of Language Model Generated Text: Is ChatGPT that Easy to Detect?.](http://arxiv.org/abs/2306.05871) | 本文提出了一种针对法语文本的 ChatGPT 检测器开发和评估方法，结果表明这些检测器可以有效地检测 ChatGPT 生成的文本，在域内环境下具有一定的抗攻击技术的鲁棒性，但在域外环境中存在明显的漏洞。 |
| [^14] | [Efficient Encoder-Decoder and Dual-Path Conformer for Comprehensive Feature Learning in Speech Enhancement.](http://arxiv.org/abs/2306.05861) | 本文提出了一个具有高效编码-解码和全面特征学习能力的语音增强模型，该模型使用改进的密集连接块、双通路模块、卷积增强变压器、通道关注和空间关注等技术。实验结果表明，在VCTK+DEMAND数据集上，该模型比现有技术表现更好。 |
| [^15] | [Can Large Language Models Infer Causation from Correlation?.](http://arxiv.org/abs/2306.05836) | 本文提出了一个新的任务（Corr2Cause），用于测量大型语言模型的因果推断能力，并通过实验发现这些模型在这个任务上表现很差。 |
| [^16] | [Towards the Exploitation of LLM-based Chatbot for Providing Legal Support to Palestinian Cooperatives.](http://arxiv.org/abs/2306.05827) | 本论文针对巴勒斯坦合作社提出了一个法律问答聊天机器人，基于LLM技术开发，在评估中表现出良好的答案匹配性，可为用户提供法律支持。 |
| [^17] | [Causality between Sentiment and Cryptocurrency Prices.](http://arxiv.org/abs/2306.05803) | 本研究通过将主题建模和情感分析相结合，建立了关于加密货币的多个叙述，并发现这些叙述与加密货币价格之间存在强大的联系。 |
| [^18] | [Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation.](http://arxiv.org/abs/2306.05783) | Xiezhi是一种全面综合的评估套件，设有516个多项选择问题，覆盖了从13个不同学科跨越的15个专业领域，并对47个先进的LLMs进行评估，结果表明LLMs在大多数领域超越人类，但在一些领域表现不佳。 |
| [^19] | [Transformer-based Time-to-Event Prediction for Chronic Kidney Disease Deterioration.](http://arxiv.org/abs/2306.05779) | 本论文提出了基于Transformer的STRAFE模型，用于慢性肾脏疾病恶化时间的生存分析预测，并在真实数据集上进行了验证，表明其在预测特定事件的确切时间方面具有较好性能。 |
| [^20] | [Challenges and Opportunities for the Design of Smart Speakers.](http://arxiv.org/abs/2306.05741) | 本文通过对35篇论文的文献综述以及15名智能音箱用户的访谈，总结出了智能音箱设计中的五个主题和四个设计挑战，同时提出了四个设计机遇空间，如提供信息支持，在设计中融入用户的心理模型以及整合平静的设计原则等。 |
| [^21] | [Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests.](http://arxiv.org/abs/2306.05715) | 研究探究了大型语言模型（LLMs）对学生程序员求助请求的回应能力，评估了其在识别学生问题代码方面的表现。GPT-3.5在大多数方面表现优于Codex，两个LLM经常在每个学生程序中找到至少一个实际问题，但都未能找到全部问题。 |
| [^22] | [Learning Emotional Representations from Imbalanced Speech Data for Speech Emotion Recognition and Emotional Text-to-Speech.](http://arxiv.org/abs/2306.05709) | 本文提出了一种情感提取器，用于从不平衡数据集中提取有效且具有可泛化性的情感表示。情感提取器在三个不平衡数据集中超过了现有的基线模型，并有利于情感语音合成。 |
| [^23] | [Judging LLM-as-a-judge with MT-Bench and Chatbot Arena.](http://arxiv.org/abs/2306.05685) | 研究使用强大的LLM作为评判员，通过引入两个基准测试来确认LLM评判员和人类偏好之间的一致性，并可调整聊天助手的模型架构和微调方法来提高其性能。 |
| [^24] | [COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models.](http://arxiv.org/abs/2306.05659) | 本文提出了一种启发式贪心对抗攻击，针对基于提示的模板在PLMs中可能存在的漏洞，通过字符级和单词级的破坏方法进行攻击，取得了较高的攻击成功率。 |
| [^25] | [Privacy Aware Question-Answering System for Online Mental Health Risk Assessment.](http://arxiv.org/abs/2306.05652) | 本研究提出了一种利用问答（QA）方法进行心理健康风险评估的技术，在保护用户数据的前提下，通过预训练的语言模型对用户社交媒体数据进行分类，并且应用于两个大型心理健康数据集。结果表明，该方法对于心理健康用例尤其有效。 |
| [^26] | [WSPAlign: Word Alignment Pre-training via Large-Scale Weakly Supervised Span Prediction.](http://arxiv.org/abs/2306.05644) | 本文提出了一种名为WSPAlign的无需手动数据的预训练词对齐方法，通过用大规模弱监督数据中的跨度预测进行预训练，取得了比当前最佳方法更好的效果。 |
| [^27] | [Customizing General-Purpose Foundation Models for Medical Report Generation.](http://arxiv.org/abs/2306.05642) | 这项工作中，我们提出了一种自定义通用基础模型以用于医疗报告生成的方法，其利用轻量级查询Transformer连接两个FMs，并在三个基准数据集上实现了最先进的结果。 |
| [^28] | [Low-rank Adaptation Method for Wav2vec2-based Fake Audio Detection.](http://arxiv.org/abs/2306.05617) | 本论文提出了一种基于低秩适应性的Wav2vec2声音伪造检测方法，通过注入可训练秩分解矩阵到变压器结构的每一层中来减少可训练参数数量，可以有效缓解微调预训练模型时过长训练时间和高内存消耗的问题。 |
| [^29] | [Word sense extension.](http://arxiv.org/abs/2306.05609) | 本文提出了词义扩展（WSE）的范例，使词汇能够向新语境产生新的意义，通过首先将多义词类型划分为两个伪记号以标记其不同的意义，然后推断一个伪符号的含义是否可以被扩展以传达来自同一词类型划分出的符号所表示的意义。 |
| [^30] | [A Unified Generative Approach to Product Attribute-Value Identification.](http://arxiv.org/abs/2306.05605) | 本文探索了一种生成式方法来统一处理电子商务平台上产品属性值识别任务，实验结果表明该方法在大规模真实世界数据集上的表现优于现有的基于提取和分类的方法。 |
| [^31] | [LOST: A Mental Health Dataset of Low Self-esteem in Reddit Posts.](http://arxiv.org/abs/2306.05596) | 研究介绍了一个专家注释的数据集LoST：Reddit帖子中低自尊心、受挫的归属感和感知的负担的精神健康数据集。该数据集可帮助更准确地识别可能需要干预的个体。 |
| [^32] | [Privacy- and Utility-Preserving NLP with Anonymized Data: A case study of Pseudonymization.](http://arxiv.org/abs/2306.05561) | 本研究研究了不同的伪名化技术在NLP任务中的效果，并提供了关于数据保护和效用保护之间权衡的见解。 |
| [^33] | [Emotion and Sentiment Guided Paraphrasing.](http://arxiv.org/abs/2306.05556) | 本研究提出了一种情感和情绪引导的改写框架，实现了细粒度的情感调节，可用于多种场景，通过添加细粒度情感标签可以提高结果质量。 |
| [^34] | [ChatGPT for Us: Preserving Data Privacy in ChatGPT via Dialogue Text Ambiguation to Expand Mental Health Care Delivery.](http://arxiv.org/abs/2306.05552) | 本研究提出了一个文本模糊化框架，以保护用户隐私并扩展心理保健交付。结果表明即使不提供原始用户文本，ChatGPT的建议仍然能够适度地有帮助和相关性。 |
| [^35] | [Bias Against 93 Stigmatized Groups in Masked Language Models and Downstream Sentiment Classification Tasks.](http://arxiv.org/abs/2306.05550) | 本研究研究了英语预训练的Masked Language Models（MLMs）以及它们的下游情感分类任务对美国93个社会污名化群体的偏见，为了评估93个污名化条件的偏见存在，我们对它们进行了比较分析，找到了偏见存在的表现。 |
| [^36] | [DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text.](http://arxiv.org/abs/2306.05540) | 作者提出了两种零样本方法，DetectLLM-LRR和DetectLLM-NPR，可以通过利用日志排名信息来检测机器生成的文本，实验表明这些方法在检测效果上超过了现有的最佳方法。 |
| [^37] | [Instruction Tuned Models are Quick Learners.](http://arxiv.org/abs/2306.05539) | 本文研究了指令调节模型在各种任务中的效率，结果表明，在单任务学习（STL）设置下，配备25％下游训练数据的指令调节模型超过了最先进的监督性能。 |
| [^38] | [AaKOS: Aspect-adaptive Knowledge-based Opinion Summarization.](http://arxiv.org/abs/2306.05537) | 本文提出了一个方面自适应的知识驱动意见摘要方法，通过结合预训练语言模型和丰富的知识库来有效地生成简短但显著的摘要，提高了意见摘要的准确性和适应性。 |
| [^39] | [Detecting Check-Worthy Claims in Political Debates, Speeches, and Interviews Using Audio Data.](http://arxiv.org/abs/2306.05535) | 政治辩论、演讲和访谈中的值得核实的论断可以使用音频数据进行检测和确认，这可帮助主持人、记者和事实核查组织进行工作。 |
| [^40] | [FACTIFY3M: A Benchmark for Multimodal Fact Verification with Explainability through 5W Question-Answering.](http://arxiv.org/abs/2306.05523) | FACTIFY3M是一个以多模式虚假信息验证为目标的数据集。虚假信息如今已成为当下重大的社会问题，这一数据集旨在通过多模式验证来及时识别和缓解虚假信息。 |
| [^41] | [Word-Level Explanations for Analyzing Bias in Text-to-Image Models.](http://arxiv.org/abs/2306.05500) | 本文探讨了文本到图像模型中存在的少数族裔偏见，提出了一种利用屏蔽语言模型计算提示中单词得分的方法，并通过实验证明其可以识别生成的图像中存在的社会刻板印象。 |
| [^42] | [Prompt Injection attack against LLM-integrated Applications.](http://arxiv.org/abs/2306.05499) | 本研究分析了LLM集成应用中的提示注入攻击的复杂性和影响，提出了一种新颖的黑盒提示注入攻击技术HouYi，并揭示了应用程序提示机制中以前未知和严重低估的漏洞。我们的研究呼吁进一步开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。 |
| [^43] | [Hexatagging: Projective Dependency Parsing as Tagging.](http://arxiv.org/abs/2306.05477) | 六边形标注器是一种新颖的依存分析器，可以在训练时实现完全并行化，具有线性时间复杂度和空间复杂度。使用预训练语言模型的特征进行预测。在 Penn Treebank 测试集上取得了最先进的性能。 |
| [^44] | [Latent Phrase Matching for Dysarthric Speech.](http://arxiv.org/abs/2306.05446) | 患有语言障碍的人在现有消费类语音识别系统中表现不佳，作者提出了一种基于个性化短语识别系统用于适应其非典型的语音模式，其具有很好的泛化性能，并在数据集上有很好的表现。 |
| [^45] | [PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance.](http://arxiv.org/abs/2306.05443) | 本文介绍了PIXIU框架，其中包括基于Fine-tuning LLaMA的第一个金融语言模型、包含136K数据样本用于Fine-tuning的第一个指令数据，以及具有5个任务和9个数据集的评估基准。通过对各种金融任务、金融文档类型和金融数据模态考虑，构建了大规模的多任务指令数据集，利用该数据集提出了名为FinMA的金融语言模型，以便对各种金融任务进行指令跟随。 |
| [^46] | [How Good is the Model in Model-in-the-loop Event Coreference Resolution Annotation?.](http://arxiv.org/abs/2306.05434) | 本论文提出了一种模型在环节中事件共指关系注释方法，通过机器学习模型只建议可能的共指事件对，将完全手动注释过程所需的工作量大幅度减少，同时实现97％的召回率。 |
| [^47] | [Towards End-to-end Speech-to-text Summarization.](http://arxiv.org/abs/2306.05432) | 该论文提出了一种迈向端到端语音到文本摘要技术的方法，这种技术可以用于过滤和跟踪每天上传在线的广播新闻，并能够产生丰富的潜在表示，但需要进一步的研究来提高其有效性和鲁棒性。 |
| [^48] | [LexGPT 0.1: pre-trained GPT-J models with Pile of Law.](http://arxiv.org/abs/2306.05431) | 本研究旨在构建专门用于法律领域的生成语言模型。此发展基前提模型是为了在法律领域开发未来的应用，如通过人类反馈进行强化学习进一步培训。此外，通过“无代码”方法，法律专业人员可以轻松地为下游任务创建定制化的语言模型。虽然性能低于最先进的结果，但本文研究如何在不修改模型或其源代码的情况下改进LexGPT模型的下游任务性能。 |
| [^49] | [RRWKV: Capturing Long-range Dependencies in RWKV.](http://arxiv.org/abs/2306.05176) | 本文介绍了一种新的RRWKV架构，它在保持记忆和计算效率的同时，通过加入回顾能力有效地捕捉长距离依赖关系。 |
| [^50] | [On the Reliability of Watermarks for Large Language Models.](http://arxiv.org/abs/2306.04634) | 本文研究了大型语言模型水印在混合其他文本来源时的可靠性，并提供了在实际应用中的建议。 |
| [^51] | [Toward More Accurate and Generalizable Evaluation Metrics for Task-Oriented Dialogs.](http://arxiv.org/abs/2306.03984) | 本文提出了一种新的对话质量注释工作流程称为DQA，能够更准确和可推广地评估对话质量，尤其是通过一些客观对话属性的判断。 |
| [^52] | [CELDA: Leveraging Black-box Language Model as Enhanced Classifier without Labels.](http://arxiv.org/abs/2306.02693) | 本文提出 CELDA 方法，通过提取精细的伪标签数据集并利用聚类增强的判别学习算法进行训练，在没有标签的情况下提高文本分类效果。 |
| [^53] | [COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements.](http://arxiv.org/abs/2306.01985) | COBRA框架是第一个上下文感知的形式主义，用于解释攻击性或有偏见陈述的意图、反应和危害，COBRACORPUS数据集包含3.3万个潜在有害陈述和机器上下文及其有害性、隐含偏见、说话意图和听众反应的自由文本解释，研究发现，攻击性陈述可以传达不同的偏见、意图和危害，取决于社交和情境背景，凸显了在有害语言侦测和管理中需要上下文感知的模型。 |
| [^54] | [Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning.](http://arxiv.org/abs/2305.18170) | 本文研究了两种方法来在少样本提示场景中利用有更好覆盖率的训练数据：动态规划提示和程序蒸馏。这能够在数学词问题 (MWP) 的解决方案中通过程序执行来验证答案正确性。 |
| [^55] | [HiTIN: Hierarchy-aware Tree Isomorphism Network for Hierarchical Text Classification.](http://arxiv.org/abs/2305.15182) | 本文提出了一种针对层次文本分类的简洁的模型 HiTIN，该模型利用无权树结构的编码树来增强文本表示，不需要先前的统计数据或标签语义，显著降低了内存开销。 |
| [^56] | [Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment.](http://arxiv.org/abs/2305.11579) | 本文提出了SPECTRA语音文本对话预训练模型，应用了新的时间位置预测任务来捕捉语音文本对齐，同时将回答选择任务推广到服务于口语对话理解，用于丰富话语表示。 |
| [^57] | [Reasoning Implicit Sentiment with Chain-of-Thought Prompting.](http://arxiv.org/abs/2305.11255) | 本研究提出了一种基于思维链索引的隐式情感推断框架（THOR），通过三次跳推理模仿类人推理过程，支持常识和多跳推理以推断意见的潜在意图，并逐步诱导隐式方面、意见和最终情感极性，实现了在监督和零样本设置上大幅提高技术水平。 |
| [^58] | [How Do In-Context Examples Affect Compositional Generalization?.](http://arxiv.org/abs/2305.04835) | 本文提出了CoFe测试套件来调查上下文组合泛化。实验结果表明，上下文示例应该在结构上与测试用例类似，相互之间应该不同，而且单独地简单。 |
| [^59] | [Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data.](http://arxiv.org/abs/2305.03827) | 本文提出了基于不确定性感知的Bootstrap学习用于远程监督数据联合抽取。通过探索数据不确定性和自我集成正则化器，使得模型在早期快速收敛并且缓解了噪声标签产生的模型不确定性，并在两个大型数据集上实验表明该方法在实体对抽取和关系抽取方面的F1得分分别提高了4.43%和4.92%。 |
| [^60] | [How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?.](http://arxiv.org/abs/2305.01555) | 本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。 |
| [^61] | [Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models.](http://arxiv.org/abs/2304.13835) | 本文通过收集和评估多方对话情况，探讨了模型在群体对话中需要具备的技能，发现新数据集MultiLIGHT可以在这个领域带来显着的进展。 |
| [^62] | [AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model.](http://arxiv.org/abs/2303.06245) | AUTODIAL是一种多任务对话模型，通过使用并行解码器来执行对话任务，从而显著减少内存占用并实现更快的推理时间。与现有的生成方法相比，AUTODIAL在三个对话任务上提供了3-6倍的速度提升，同时具有11倍的参数减少。这表明将当前的对话模型扩展为具有并行解码器可以成为在资源受限环境中部署它们的可行替代方案。 |
| [^63] | [Visual Abstraction and Reasoning through Language.](http://arxiv.org/abs/2303.04091) | 本论文提出了一种通过自然语言描述任务的通用框架来解决Abstraction and Reasoning Corpus（ARC）问题，虽然还没有在ARC上击败最先进的DSL模型，但我们展示了我们的方法具有巨大的潜力，可以解决先前未解决的任务。 |
| [^64] | [Probing Out-of-Distribution Robustness of Language Models with Parameter-Efficient Transfer Learning.](http://arxiv.org/abs/2301.11660) | 本文评估了各种参数高效的迁移学习方法对不同规模的语言模型在三个不同的意图分类任务中检测超分布（OOD）的能力，旨在为语言模型的超分布鲁棒性提供参考。 |
| [^65] | [Privacy-Preserving Domain Adaptation of Semantic Parsers.](http://arxiv.org/abs/2212.10520) | 本文提出了一个隐私保护的语义解析器领域自适应的方法，通过合成真实用户语句来帮助增加系统的语言和功能覆盖范围，同时不会危及实际用户的隐私。 |
| [^66] | [Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization.](http://arxiv.org/abs/2212.10449) | 本论文介绍了一种面向问题驱动的无监督预训练方法，名为Socratic预训练，用于提高摘要任务的可控性，并演示了该方法通过在多个控制策略上进行广泛实验得出的优于其他方法的结果。 |
| [^67] | [Unsupervised Discontinuous Constituency Parsing with Mildly Context-Sensitive Grammars.](http://arxiv.org/abs/2212.09140) | 本文研究了使用轻度上下文敏感语法进行无监督间断性组块句法分析的语法归纳。在保证规则结构的前提下，我们用最大似然方法进行参数学习，实验证明该方法对大量非终结符具有扩展灵活性。 |
| [^68] | [Arithmetic-Based Pretraining -- Improving Numeracy of Pretrained Language Models.](http://arxiv.org/abs/2205.06733) | 本论文提出了一种新的扩展预训练方法——基于算术的预训练，它可以同时解决数字表达能力和数值能力不足的问题，而不需要进行架构变化或重新预训练。实验结果表明，基于算术的预训练在三个不同的任务中都非常有效。 |
| [^69] | [Delving Deeper into Cross-lingual Visual Question Answering.](http://arxiv.org/abs/2202.07630) | 本文探究了跨语言VQA的几个方面，包括建模方法和学习偏差，发现简单修改可以减少到单语英语性能的差距，从而提高准确度。 |
| [^70] | [Machine Semiotics.](http://arxiv.org/abs/2008.10522) | 本文提出机器符号学的思想，即机器不需要理解话语的传统意义，而是能够以格里斯语用学的方式绘制会话蕴涵说明。这个过程可以形式化为话语-意义对（UMP）的强化学习。 |

# 详细

[^1]: 利用大型语言模型进行可伸缩矢量图驱动的图像理解

    Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding. (arXiv:2306.06094v1 [cs.CV])

    [http://arxiv.org/abs/2306.06094](http://arxiv.org/abs/2306.06094)

    本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。

    

    最近，大型语言模型(LLMs)在自然语言理解和生成方面取得了显著进展。然而，它们在计算机视觉领域的潜力仍然很大程度上没有被开发。本文介绍了一种新的探索性方法，使得LLMs能够使用可伸缩矢量图(SVG)格式处理图像。通过利用基于XML的SVG表述的文本描述而不是光栅图像，我们旨在弥合视觉和文本模态之间的差距，使LLMs能够直接理解和操作图像，而无需使用参数化的视觉组件。我们的方法仅利用LLMs的能力进行简单的图像分类、生成和上下文学习。我们展示了方法在判别和生成任务中的优异表现，重点介绍了它(i)对分布转移的鲁棒性，(ii)通过利用LLMs的上下文学习能力实现的显著改进，以及(iii)图像杂乱程度上的显著性能提高。

    Recently, large language models (LLMs) have made significant advancements in natural language understanding and generation. However, their potential in computer vision remains largely unexplored. In this paper, we introduce a new, exploratory approach that enables LLMs to process images using the Scalable Vector Graphics (SVG) format. By leveraging the XML-based textual descriptions of SVG representations instead of raster images, we aim to bridge the gap between the visual and textual modalities, allowing LLMs to directly understand and manipulate images without the need for parameterized visual components. Our method facilitates simple image classification, generation, and in-context learning using only LLM capabilities. We demonstrate the promise of our approach across discriminative and generative tasks, highlighting its (i) robustness against distribution shift, (ii) substantial improvements achieved by tapping into the in-context learning abilities of LLMs, and (iii) image unders
    
[^2]: 使用标记的上下文提示捕捉LLM妄想症

    Trapping LLM Hallucinations Using Tagged Context Prompts. (arXiv:2306.06085v1 [cs.CL])

    [http://arxiv.org/abs/2306.06085](http://arxiv.org/abs/2306.06085)

    本文提出一种使用标记的上下文提示的新方法，可以显著减少生成语言模型中的妄想症，提高对话代理的准确性和有效性。

    

    大型语言模型（LLM）的最新进展，例如ChatGPT，已经导致高度复杂的对话代理。但是，这些模型受到“妄想症”的困扰，即模型生成虚假或捏造的信息。解决这一挑战非常关键，特别是在各个领域采用AI驱动的平台时。本文提出了一种新方法，用于识别和标记LLM在其领域知识范围之外的问题，确保用户获得准确的信息。我们发现，结合嵌入的标记和上下文来对抗生成语言模型中的妄想症可以成功地应对。为此，我们使用生成的URL作为易于测试的捏造数据指标，在没有上下文提示-响应对的情况下基线依赖性妄想频率。我们观察到，在为测试的生成引擎提供问题提示时提供上下文可以显著减少总体妄想症。最后，我们评估了在上下文提示中放置标记如何影响检测妄想症。我们的实验表明，在LLM中标记的上下文提示提高了检测妄想症的准确性和有效性。

    Recent advances in large language models (LLMs), such as ChatGPT, have led to highly sophisticated conversation agents. However, these models suffer from "hallucinations," where the model generates false or fabricated information. Addressing this challenge is crucial, particularly with AI-driven platforms being adopted across various sectors. In this paper, we propose a novel method to recognize and flag instances when LLMs perform outside their domain knowledge, and ensuring users receive accurate information.  We find that the use of context combined with embedded tags can successfully combat hallucinations within generative language models. To do this, we baseline hallucination frequency in no-context prompt-response pairs using generated URLs as easily-tested indicators of fabricated data. We observed a significant reduction in overall hallucination when context was supplied along with question prompts for tested generative engines. Lastly, we evaluated how placing tags within cont
    
[^3]: 通过无监督聚类提高端到端语音识别中的公平性和鲁棒性

    Improving Fairness and Robustness in End-to-End Speech Recognition through unsupervised clustering. (arXiv:2306.06083v1 [cs.SD])

    [http://arxiv.org/abs/2306.06083](http://arxiv.org/abs/2306.06083)

    该论文提出了一种隐私保护的方法，通过无监督聚类提高端到端语音识别中的公平性和鲁棒性，并可以对所有人口统计学方面都有提高的效果。

    

    当自动语音识别（ASR）系统不能为所有人群子组织提供同样出色的性能时，就会出现公平性挑战。近年来，虽然在整体语音识别质量方面已经有很多改进，但并没有特别关注为系统无法表现良好的所有用户组推进公平和平等方面的改进。因此，ASR的公平性也是一个鲁棒性问题。同时，数据隐私在生产系统中也是首要问题。本文提出了一种隐私保护方法，可以在不使用元数据、邮政编码甚至不直接使用说话人或话语嵌入的情况下，提高端到端ASR的公平性和鲁棒性。我们使用在公共数据集上训练的说话人ID模型来提取话语级别的嵌入，然后以无监督的方式使用它们来创建声学聚类。我们在模型训练期间使用聚类ID而不是说话人话语嵌入作为额外的特征，这表现出了对所有人口统计学方面都有提高的效果。

    The challenge of fairness arises when Automatic Speech Recognition (ASR) systems do not perform equally well for all sub-groups of the population. In the past few years there have been many improvements in overall speech recognition quality, but without any particular focus on advancing Equality and Equity for all user groups for whom systems do not perform well. ASR fairness is therefore also a robustness issue. Meanwhile, data privacy also takes priority in production systems. In this paper, we present a privacy preserving approach to improve fairness and robustness of end-to-end ASR without using metadata, zip codes, or even speaker or utterance embeddings directly in training. We extract utterance level embeddings using a speaker ID model trained on a public dataset, which we then use in an unsupervised fashion to create acoustic clusters. We use cluster IDs instead of speaker utterance embeddings as extra features during model training, which shows improvements for all demographic
    
[^4]: 视觉词汇描述提升零样本图像分类

    Visually-Grounded Descriptions Improve Zero-Shot Image Classification. (arXiv:2306.06077v1 [cs.CV])

    [http://arxiv.org/abs/2306.06077](http://arxiv.org/abs/2306.06077)

    本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。

    

    语言视觉模型如CLIP在零样本视觉任务（例如零样本图像分类ZSIC）方面取得了显著进展。然而，生成具体和富有表现力的类别描述仍然是一个主要挑战。现有方法存在粒度和标签歧义等问题。为了解决这些挑战，我们提出了一种新方法V-GLOSS：Visual Glosses，它利用现代语言模型和语义知识库来生成具有视觉基础的类别描述。我们通过在基准ZSIC数据集（包括ImageNet和STL-10）上实现最先进的结果来展示V-GLOSS的有效性。此外，我们引入了一个由V-GLOSS生成的带有类别描述的银标准数据集，并展示其用于视觉任务的有用性。我们提供了源代码和数据集。

    Language-vision models like CLIP have made significant progress in zero-shot vision tasks, such as zero-shot image classification (ZSIC). However, generating specific and expressive class descriptions remains a major challenge. Existing approaches suffer from granularity and label ambiguity issues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel method leveraging modern language models and semantic knowledge bases to produce visually-grounded class descriptions. We demonstrate V-GLOSS's effectiveness by achieving state-of-the-art results on benchmark ZSIC datasets including ImageNet and STL-10. In addition, we introduce a silver dataset with class descriptions generated by V-GLOSS, and show its usefulness for vision tasks. We make available our code and dataset.
    
[^5]: Mind2Web：面向Web的通用代理

    Mind2Web: Towards a Generalist Agent for the Web. (arXiv:2306.06070v1 [cs.CL])

    [http://arxiv.org/abs/2306.06070](http://arxiv.org/abs/2306.06070)

    Mind2Web是第一个用于开发和评估通用Web代理的数据集，可以按照语言指令完成任意网站上的复杂任务。此数据集提供了三个必要元素：1）多样的领域、网站和任务，2）使用真实网站而非模拟和简化网站，3）广泛的用户交互模式。研究者使用Mind2Web进行了初步探索，使用小型LM过滤可以显着提高任务完成率的效果。

    

    我们介绍了Mind2Web，这是第一个用于开发和评估通用Web代理的数据集，可以按照语言指令完成任意网站上的复杂任务。现有的Web代理数据集要么使用模拟网站，要么仅覆盖有限的网站和任务，因此不适合通用Web代理。通过收集来自31个领域、137个网站的超过2,000个开放式任务和任务的众包操作序列，Mind2Web为构建通用Web代理提供了三个必要元素：1）多样的领域、网站和任务，2）使用真实网站而非模拟和简化网站，3）广泛的用户交互模式。基于Mind2Web，我们进行了使用大型语言模型（LLMs）构建通用Web代理的初步探索。虽然现实世界网站的原始HTML往往太大而无法提供给LLMs，但我们展示了首先用小型LM过滤可以显着提高任务完成率的效果。

    We introduce Mind2Web, the first dataset for developing and evaluating generalist agents for the web that can follow language instructions to complete complex tasks on any website. Existing datasets for web agents either use simulated websites or only cover a limited set of websites and tasks, thus not suitable for generalist web agents. With over 2,000 open-ended tasks collected from 137 websites spanning 31 domains and crowdsourced action sequences for the tasks, Mind2Web provides three necessary ingredients for building generalist web agents: 1) diverse domains, websites, and tasks, 2) use of real-world websites instead of simulated and simplified ones, and 3) a broad spectrum of user interaction patterns. Based on Mind2Web, we conduct an initial exploration of using large language models (LLMs) for building generalist web agents. While the raw HTML of real-world websites are often too large to be fed to LLMs, we show that first filtering it with a small LM significantly improves th
    
[^6]: 协助语言学习者：通过对比提示学习实现的自动跨语言定义生成

    Assisting Language Learners: Automated Trans-Lingual Definition Generation via Contrastive Prompt Learning. (arXiv:2306.06058v1 [cs.CL])

    [http://arxiv.org/abs/2306.06058](http://arxiv.org/abs/2306.06058)

    本研究提出了一个Trans-Lingual Definition Generation (TLDG)任务，通过对比提示学习实现的自动跨语言定义生成。该方法通过生成母语使用者的语言的定义，协助语言学习者理解生僻词汇，实验证明对于生成更高质量的跨语言定义方面有显著的优越性。

    

    标准的定义生成任务要求自动生成单语言定义（例如，英文单词的英文定义），但忽略了生成的定义对于语言学习者同样存在生僻词汇。本研究提出了一项新的跨语言定义生成（TLDG）任务，旨在生成另一种语言的定义，即母语使用者的语言。我们首先探索了这项任务的非监督方式，并建立了一个简单的实现方法，即微调多语言机器翻译模型。然后，我们开发了两种新方法，Prompt Combination和Contrastive Prompt Learning，以进一步提高生成的质量。我们将我们的方法与基线管道方法在丰富和低资源环境下进行了评估，并在实践中证明了它在生成更高质量的跨语言定义方面的优越性。

    The standard definition generation task requires to automatically produce mono-lingual definitions (e.g., English definitions for English words), but ignores that the generated definitions may also consist of unfamiliar words for language learners. In this work, we propose a novel task of Trans-Lingual Definition Generation (TLDG), which aims to generate definitions in another language, i.e., the native speaker's language. Initially, we explore the unsupervised manner of this task and build up a simple implementation of fine-tuning the multi-lingual machine translation model. Then, we develop two novel methods, Prompt Combination and Contrastive Prompt Learning, for further enhancing the quality of the generation. Our methods are evaluated against the baseline Pipeline method in both rich- and low-resource settings, and we empirically establish its superiority in generating higher-quality trans-lingual definitions.
    
[^7]: FinGPT：开源金融大型语言模型

    FinGPT: Open-Source Financial Large Language Models. (arXiv:2306.06031v1 [q-fin.ST])

    [http://arxiv.org/abs/2306.06031](http://arxiv.org/abs/2306.06031)

    FinGPT是一个开源的金融大型语言模型，提供了可访问和透明的资源来开发金融LLMs，其重要性在于自动数据筛选管道和轻量级低秩适应技术。

    

    大型语言模型（LLMs）展示了在各个领域革新自然语言处理任务的潜力，引起了金融领域的浓厚兴趣。获得高质量的金融数据是金融LLMs（FinLLMs）的第一个挑战。在这篇论文中，我们提出了一个针对金融领域的开源大型语言模型FinGPT。与专有模型不同，FinGPT采用数据为中心的方法，为研究人员和从业者提供可访问和透明的资源来开发他们的金融LLMs。我们强调自动数据筛选管道和轻量级低秩适应技术在建立FinGPT中的重要性。此外，我们展示了几个潜在的应用作为用户的基础，如机器顾问、算法交易和论 。

    Large language models (LLMs) have shown the potential of revolutionizing natural language processing tasks in diverse domains, sparking great interest in finance. Accessing high-quality financial data is the first challenge for financial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken advantage of their unique data accumulation, such privileged access calls for an open-source alternative to democratize Internet-scale financial data.  In this paper, we present an open-source large language model, FinGPT, for the finance sector. Unlike proprietary models, FinGPT takes a data-centric approach, providing researchers and practitioners with accessible and transparent resources to develop their FinLLMs. We highlight the importance of an automatic data curation pipeline and the lightweight low-rank adaptation technique in building FinGPT. Furthermore, we showcase several potential applications as stepping stones for users, such as robo-advising, algorithmic trading, and l
    
[^8]: HiTZ@Antidote: 面向数字医疗的基于论证的可解释人工智能

    HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine. (arXiv:2306.06029v1 [cs.CL])

    [http://arxiv.org/abs/2306.06029](http://arxiv.org/abs/2306.06029)

    HiTZ@Antidote采用深度学习和论证理论，提供数字医疗领域高质量的可解释AI预测解释。

    

    基于机器学习的AI预测提供高质量的解释是一个具有挑战性和复杂性的任务。要使其正常工作，需要选择适当的解释泛化/细化水平；考虑解释受益者对所考虑的AI任务的熟悉程度的假设；涉及到对促成决策的具体元素的引用；利用可能不是预测过程的一部分的其他知识（例如专家证据）；并以清晰易懂、可能具说服力的方式表述解释。鉴于这些考虑因素，ANTIDOTE在可解释AI方面培育了一个综合的视角，将深度学习过程的低级特征与人类论证能力的更高级别方案相结合。ANTIDOTE将利用深度学习和论证理论的跨学科竞争优势，解决数字医学领域提供高质量AI预测解释的挑战。

    Providing high quality explanations for AI predictions based on machine learning is a challenging and complex task. To work well it requires, among other factors: selecting a proper level of generality/specificity of the explanation; considering assumptions about the familiarity of the explanation beneficiary with the AI task under consideration; referring to specific elements that have contributed to the decision; making use of additional knowledge (e.g. expert evidence) which might not be part of the prediction process; and providing evidence supporting negative hypothesis. Finally, the system needs to formulate the explanation in a clearly interpretable, and possibly convincing, way. Given these considerations, ANTIDOTE fosters an integrated vision of explainable AI, where low-level characteristics of the deep learning process are combined with higher level schemes proper of the human argumentation capacity. ANTIDOTE will exploit cross-disciplinary competences in deep learning and a
    
[^9]: 基于深度学习的德语胸部X射线医学报告自动标注

    Automated Labeling of German Chest X-Ray Radiology Reports using Deep Learning. (arXiv:2306.05997v1 [cs.CL])

    [http://arxiv.org/abs/2306.05997](http://arxiv.org/abs/2306.05997)

    本研究使用基于深度学习的CheXpert标签预测模型进行弱监督，显着优于基于规则的模型，在自动标注德语胸部X射线医学报告方面具有潜在价值。

    

    世界范围内放射科医生短缺，深度学习模型作为临床决策支持系统的一部分，提供了解决这一问题的有希望的解决方案。然而，培训这样的模型往往需要耗费昂贵和耗时的手动标记大型数据集。从放射学报告中自动提取标签可以减少获得标记数据集所需的时间，但由于语义上相似的词和缺少注释数据而任务具有挑战性。在这项工作中，我们探讨了基于规则的标签器的弱监督深度学习标签预测模型的潜力。我们提出了一种基于深度学习的CheXpert标签预测模型，该模型在由基于规则的德语CheXpert模型标记的报告上进行了预训练，并在少量手动标记的报告数据集上进行了微调。我们的结果证明了我们的方法的有效性，在所有三个任务上显着优于基于规则的模型。我们的发现突出了使用深度学习技术的优点。

    Radiologists are in short supply globally, and deep learning models offer a promising solution to address this shortage as part of clinical decision-support systems. However, training such models often requires expensive and time-consuming manual labeling of large datasets. Automatic label extraction from radiology reports can reduce the time required to obtain labeled datasets, but this task is challenging due to semantically similar words and missing annotated data. In this work, we explore the potential of weak supervision of a deep learning-based label prediction model, using a rule-based labeler. We propose a deep learning-based CheXpert label prediction model, pre-trained on reports labeled by a rule-based German CheXpert model and fine-tuned on a small dataset of manually labeled reports. Our results demonstrate the effectiveness of our approach, which significantly outperformed the rule-based model on all three tasks. Our findings highlight the benefits of employing deep learni
    
[^10]: 语言模型能够学习语法规则的例外情况

    Language Models Can Learn Exceptions to Syntactic Rules. (arXiv:2306.05969v1 [cs.CL])

    [http://arxiv.org/abs/2306.05969](http://arxiv.org/abs/2306.05969)

    语言模型能够通过分布特性学习规则的例外情况，通过研究动词在主动语态和被动语态中的相对可接受性和相对出现频率的正相关性进行支持。

    

    人工神经网络可以生产性地概括新的上下文。它们能否也学习这些生产性规则的例外情况？我们以英语被动式句法限制为例（例如，“The vacation lasted five days”是语法正确的，但“*Five days was lasted by the vacation”不是）。我们收集了多种动词格的人类接受度判断数据，并展示了语言模型GPT-2定义的概率分布与人的接受度判断高度相关。我们还展示了一个动词在主动语态和被动语态中的相对可接受性与其在这些语态中的相对出现频率呈正相关关系。这些结果初步支持扎根假设，即学习者能够跟踪和使用他们输入的分布特性，以学习规则的例外情况。同时，这个假设无法解释负面例外情况的数量级。

    Artificial neural networks can generalize productively to novel contexts. Can they also learn exceptions to those productive rules? We explore this question using the case of restrictions on English passivization (e.g., the fact that "The vacation lasted five days" is grammatical, but "*Five days was lasted by the vacation" is not). We collect human acceptability judgments for passive sentences with a range of verbs, and show that the probability distribution defined by GPT-2, a language model, matches the human judgments with high correlation. We also show that the relative acceptability of a verb in the active vs. passive voice is positively correlated with the relative frequency of its occurrence in those voices. These results provide preliminary support for the entrenchment hypothesis, according to which learners track and uses the distributional properties of their input to learn negative exceptions to rules. At the same time, this hypothesis fails to explain the magnitude of unpa
    
[^11]: 基于循环融合扩张卷积和通道注意力的高效语音分离神经网络

    An Efficient Speech Separation Network Based on Recurrent Fusion Dilated Convolution and Channel Attention. (arXiv:2306.05887v1 [eess.AS])

    [http://arxiv.org/abs/2306.05887](http://arxiv.org/abs/2306.05887)

    本文提出了一种使用循环融合扩张卷积和通道注意力的高效语音分离神经网络，其结构为编码器-解码器结构，具有较高的表现力和鲁棒性，可作为当前主流模型的有效替代模型。

    

    我们提出了一种高效的语音分离神经网络，ARFDCN，它结合了扩张卷积，多尺度融合（MSF）和通道注意力，以克服基于卷积的网络的有限感受野和基于transformer的网络的高计算成本。所提出的网络结构是编码器-解码器结构。通过使用逐渐增加的扩张值的扩张卷积来学习局部和全局特征并在相邻阶段进行融合，模型可以学习到丰富的特征内容。同时，通过将通道注意力模块添加到网络中，模型可以提取通道权重，学习更重要的特征，从而提高其表现力和鲁棒性。实验结果表明，该模型在性能和计算效率之间达到了不错的平衡，成为当前实际应用中有前景的替代模型。

    We present an efficient speech separation neural network, ARFDCN, which combines dilated convolutions, multi-scale fusion (MSF), and channel attention to overcome the limited receptive field of convolution-based networks and the high computational cost of transformer-based networks. The suggested network architecture is encoder-decoder based. By using dilated convolutions with gradually increasing dilation value to learn local and global features and fusing them at adjacent stages, the model can learn rich feature content. Meanwhile, by adding channel attention modules to the network, the model can extract channel weights, learn more important features, and thus improve its expressive power and robustness. Experimental results indicate that the model achieves a decent balance between performance and computational efficiency, making it a promising alternative to current mainstream models for practical applications.
    
[^12]: 好的，但并非总是公正：对三个商业机器翻译系统性别偏见的评估

    Good, but not always Fair: An Evaluation of Gender Bias for three commercial Machine Translation Systems. (arXiv:2306.05882v1 [cs.CL])

    [http://arxiv.org/abs/2306.05882](http://arxiv.org/abs/2306.05882)

    本文对三个商业机器翻译系统进行了细致评估，在关注性别翻译和偏见的前提下，揭示了它们性别翻译方面的显着差异和偏见，这一点不会因为它们整体翻译质量的好坏而有所改变。

    

    机器翻译（MT）在质量方面继续取得重大进展，并且正在越来越大规模地被采用。因此，分析已转向更微妙的方面、复杂的现象以及可能从广泛使用MT工具中产生的风险。本文针对三个商业MT系统 - Google Translate、DeepL和Modern MT进行了细致的评估，重点关注性别翻译和偏见。对于三种语言对（英语/西班牙语、英语/意大利语和英语/法语），我们在各种自然语境下的性别现象的多个粒度级别上审查了这些系统的行为。我们的研究考虑了在线MT工具的当前状态，揭示了三个系统性别翻译方面的显着差异，尽管它们的整体翻译质量不错，但是每个系统都表现出不同程度的偏见。

    Machine Translation (MT) continues to make significant strides in quality and is increasingly adopted on a larger scale. Consequently, analyses have been redirected to more nuanced aspects, intricate phenomena, as well as potential risks that may arise from the widespread use of MT tools. Along this line, this paper offers a meticulous assessment of three commercial MT systems - Google Translate, DeepL, and Modern MT - with a specific focus on gender translation and bias. For three language pairs (English/Spanish, English/Italian, and English/French), we scrutinize the behavior of such systems at several levels of granularity and on a variety of naturally occurring gender phenomena in translation. Our study takes stock of the current state of online MT tools, by revealing significant discrepancies in the gender translation of the three systems, with each system displaying varying degrees of bias despite their overall translation quality.
    
[^13]: 实现对语言模型生成文本的鲁棒检测：ChatGPT 容易被发现吗？

    Towards a Robust Detection of Language Model Generated Text: Is ChatGPT that Easy to Detect?. (arXiv:2306.05871v1 [cs.CL])

    [http://arxiv.org/abs/2306.05871](http://arxiv.org/abs/2306.05871)

    本文提出了一种针对法语文本的 ChatGPT 检测器开发和评估方法，结果表明这些检测器可以有效地检测 ChatGPT 生成的文本，在域内环境下具有一定的抗攻击技术的鲁棒性，但在域外环境中存在明显的漏洞。

    

    自然语言处理 (NLP) 的最新进展推动了大型语言模型 (LLM) 的发展，例如 ChatGPT。本文提出了一种针对法语文本开发和评估 ChatGPT 检测器的方法，重点研究它们对域外数据和常见攻击方案的鲁棒性。所提出的方法包括将英语数据集翻译为法语并在翻译数据上训练分类器。结果表明，检测器可以有效地检测 ChatGPT 生成的文本，在域内环境下具有一定的抗攻击技术的鲁棒性。然而，在域外环境中存在明显的漏洞，凸显了检测对抗性文本的挑战性。该研究强调了谨慎将域内测试结果应用于更广泛的内容上。我们提供了翻译的数据集和模型作为开源资源。

    Recent advances in natural language processing (NLP) have led to the development of large language models (LLMs) such as ChatGPT. This paper proposes a methodology for developing and evaluating ChatGPT detectors for French text, with a focus on investigating their robustness on out-of-domain data and against common attack schemes. The proposed method involves translating an English dataset into French and training a classifier on the translated data. Results show that the detectors can effectively detect ChatGPT-generated text, with a degree of robustness against basic attack techniques in in-domain settings. However, vulnerabilities are evident in out-of-domain contexts, highlighting the challenge of detecting adversarial text. The study emphasizes caution when applying in-domain testing results to a wider variety of content. We provide our translated datasets and models as open-source resources. https://gitlab.inria.fr/wantoun/robust-chatgpt-detection
    
[^14]: 高效编码-解码和双通路Conformer用于语音增强中的综合特征学习

    Efficient Encoder-Decoder and Dual-Path Conformer for Comprehensive Feature Learning in Speech Enhancement. (arXiv:2306.05861v1 [eess.AS])

    [http://arxiv.org/abs/2306.05861](http://arxiv.org/abs/2306.05861)

    本文提出了一个具有高效编码-解码和全面特征学习能力的语音增强模型，该模型使用改进的密集连接块、双通路模块、卷积增强变压器、通道关注和空间关注等技术。实验结果表明，在VCTK+DEMAND数据集上，该模型比现有技术表现更好。

    

    当前的语音增强(SE)研究很大程度上忽略了通道关注和空间关注，基于编码器-解码器的网络也没有充分考虑如何为中间的增强层提供高效的输入。为了解决这些问题，本文提出了一个时频(T-F)领域的SE网络(DPCFCS-Net)，它包含了改进的密集连接块、双通路模块、卷积增强变压器(conformers)、通道关注和空间关注。与之前的模型相比，我们提出的模型具有更高效的编码器-解码器并能够学习综合特征。在VCTK+DEMAND数据集上的实验结果表明，我们的方法在SE性能方面优于现有技术。此外，本研究发展的改进的密集连接块和二维关注模块非常适应，易于集成到现有网络中。

    Current speech enhancement (SE) research has largely neglected channel attention and spatial attention, and encoder-decoder architecture-based networks have not adequately considered how to provide efficient inputs to the intermediate enhancement layer. To address these issues, this paper proposes a time-frequency (T-F) domain SE network (DPCFCS-Net) that incorporates improved densely connected blocks, dual-path modules, convolution-augmented transformers (conformers), channel attention, and spatial attention. Compared with previous models, our proposed model has a more efficient encoder-decoder and can learn comprehensive features. Experimental results on the VCTK+DEMAND dataset demonstrate that our method outperforms existing techniques in SE performance. Furthermore, the improved densely connected block and two dimensions attention module developed in this work are highly adaptable and easily integrated into existing networks.
    
[^15]: 大型语言模型能否从相关性中推断出因果关系?

    Can Large Language Models Infer Causation from Correlation?. (arXiv:2306.05836v1 [cs.CL])

    [http://arxiv.org/abs/2306.05836](http://arxiv.org/abs/2306.05836)

    本文提出了一个新的任务（Corr2Cause），用于测量大型语言模型的因果推断能力，并通过实验发现这些模型在这个任务上表现很差。

    

    因果推断是人类智慧的标志之一。虽然CausalNLP领域近年来引起了广泛关注，但NLP中现有的因果推断数据集主要依赖于从经验知识（例如常识知识）中发现因果关系。在本文中，我们提出了第一个基准数据集，用于测试大型语言模型（LLM）的纯因果推断能力。具体而言，我们制定了一个新的任务Corr2Cause，它采用一组相关语句并确定变量之间的因果关系。我们策划了一个大规模的数据集，其中包含超过400K个样本，我们在其中评估了17个现有的LLMs。通过我们的实验，我们确定了LLMs在因果推断技能方面的一个关键缺陷，并表明这些模型在该任务上的表现几乎接近随机。当我们尝试通过微调将LLMs重新用于这种技能时，这种缺陷在某种程度上得到了缓解，但我们发现这些模型仍然失败了。

    Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 400K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fa
    
[^16]: 面向基于LLM技术的聊天机器人以为巴勒斯坦合作社提供法律支持

    Towards the Exploitation of LLM-based Chatbot for Providing Legal Support to Palestinian Cooperatives. (arXiv:2306.05827v1 [cs.CL])

    [http://arxiv.org/abs/2306.05827](http://arxiv.org/abs/2306.05827)

    本论文针对巴勒斯坦合作社提出了一个法律问答聊天机器人，基于LLM技术开发，在评估中表现出良好的答案匹配性，可为用户提供法律支持。

    

    随着自然语言处理（NLP）的不断应用，我们近年来开始目睹对于法律文件交互方式的重大变革。该技术推动了对复杂法律术语和场景的分析和理解。最新的大型语言模型（LLM）的开发，特别是ChatGPT的出现，也对处理和理解法律文件的方式提出了革命性的贡献。在本文中，我们提出了一个合作社法律问答LLM聊天机器人的工作，其中我们开发了一组关于巴勒斯坦合作社及其规定的法律问题，并将聊天机器人自动生成的答案与由法律专家设计的相应答案进行了比较。为了评估所提出的聊天机器人，我们使用了由法律专家生成的50个查询，并将图表产生的答案与它们的相关性判断进行了比较。结果表明

    With the ever-increasing utilization of natural language processing (NLP), we started to witness over the past few years a significant transformation in our interaction with legal texts. This technology has advanced the analysis and enhanced the understanding of complex legal terminology and contexts. The development of recent large language models (LLMs), particularly ChatGPT, has also introduced a revolutionary contribution to the way that legal texts can be processed and comprehended. In this paper, we present our work on a cooperative-legal question-answering LLM-based chatbot, where we developed a set of legal questions about Palestinian cooperatives, associated with their regulations and compared the auto-generated answers by the chatbot to their correspondences that are designed by a legal expert. To evaluate the proposed chatbot, we have used 50 queries generated by the legal expert and compared the answers produced by the chart to their relevance judgments. Finding demonstrate
    
[^17]: 情感和加密货币价格之间的因果关系

    Causality between Sentiment and Cryptocurrency Prices. (arXiv:2306.05803v1 [q-fin.CP])

    [http://arxiv.org/abs/2306.05803](http://arxiv.org/abs/2306.05803)

    本研究通过将主题建模和情感分析相结合，建立了关于加密货币的多个叙述，并发现这些叙述与加密货币价格之间存在强大的联系。

    

    本研究调查了微博平台（Twitter）传递的叙述与加密资产价值之间的关系。我们的研究采用了一种独特的技术，将短文本的主题建模与情感分析相结合，建立了关于加密货币的叙述。首先，我们使用了一种无监督的机器学习算法，从Twitter的大规模和嘈杂文本数据中发现潜在主题，然后我们揭示了4-5个与加密货币相关的叙述，包括与加密货币相关的金融投资、技术进步、金融和政治监管、加密资产和媒体报道。在许多情况下，我们注意到我们的叙述与加密货币价格之间存在强大的联系。我们的工作将最新的经济学创新——叙事经济学与主题建模和情感分析相结合的新领域联系起来，以关联消费者行为和叙述。

    This study investigates the relationship between narratives conveyed through microblogging platforms, namely Twitter, and the value of crypto assets. Our study provides a unique technique to build narratives about cryptocurrency by combining topic modelling of short texts with sentiment analysis. First, we used an unsupervised machine learning algorithm to discover the latent topics within the massive and noisy textual data from Twitter, and then we revealed 4-5 cryptocurrency-related narratives, including financial investment, technological advancement related to crypto, financial and political regulations, crypto assets, and media coverage. In a number of situations, we noticed a strong link between our narratives and crypto prices. Our work connects the most recent innovation in economics, Narrative Economics, to a new area of study that combines topic modelling and sentiment analysis to relate consumer behaviour to narratives.
    
[^18]: Xiezhi：一种全面更新的综合领域知识评估基准

    Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation. (arXiv:2306.05783v1 [cs.CL])

    [http://arxiv.org/abs/2306.05783](http://arxiv.org/abs/2306.05783)

    Xiezhi是一种全面综合的评估套件，设有516个多项选择问题，覆盖了从13个不同学科跨越的15个专业领域，并对47个先进的LLMs进行评估，结果表明LLMs在大多数领域超越人类，但在一些领域表现不佳。

    

    随着大型语言模型（LLM）的快速发展，急需新的自然语言处理（NLP）基准来实现对齐。我们提出了Xiezhi，这是一个最全面的评估套件，旨在评估综合领域知识。Xiezhi包括跨越13个不同学科的516个多项选择问题，包括22万个问题，并且附带Xiezhi-Specialty和Xiezhi-Interdiscipline，均有15,000个问题。我们对47个先进的LLM在Xiezhi上进行了评估。结果表明，LLM在科学、工程、农学、医学和艺术方面超过了人类的平均表现，但在经济学、法学、教育学、文学、历史和管理方面则表现不佳。我们期望Xiezhi将有助于分析LLM的重要优点和不足之处，该基准已在https://github.com/MikeGu721/XiezhiBenchmark发布。

    New Natural Langauge Process~(NLP) benchmarks are urgently needed to align with the rapid development of large language models (LLMs). We present Xiezhi, the most comprehensive evaluation suite designed to assess holistic domain knowledge. Xiezhi comprises multiple-choice questions across 516 diverse disciplines ranging from 13 different subjects with 220,000 questions and accompanied by Xiezhi-Specialty and Xiezhi-Interdiscipline, both with 15k questions. We conduct evaluation of the 47 cutting-edge LLMs on Xiezhi. Results indicate that LLMs exceed average performance of humans in science, engineering, agronomy, medicine, and art, but fall short in economics, jurisprudence, pedagogy, literature, history, and management. We anticipate Xiezhi will help analyze important strengths and shortcomings of LLMs, and the benchmark is released in https://github.com/MikeGu721/XiezhiBenchmark .
    
[^19]: 基于Transformer的慢性肾脏疾病恶化时间预测

    Transformer-based Time-to-Event Prediction for Chronic Kidney Disease Deterioration. (arXiv:2306.05779v1 [cs.LG])

    [http://arxiv.org/abs/2306.05779](http://arxiv.org/abs/2306.05779)

    本论文提出了基于Transformer的STRAFE模型，用于慢性肾脏疾病恶化时间的生存分析预测，并在真实数据集上进行了验证，表明其在预测特定事件的确切时间方面具有较好性能。

    

    深度学习技术，尤其是Transformer模型，已在增强纵向健康记录的预测性能方面显示出巨大潜力。虽然先前的方法主要集中在固定时间风险预测上，但时间到达事件预测（也称为生存分析）往往更适合于临床场景。在这里，我们提出了一个新的深度学习架构，名为STRAFE，这是一种基于Transformer的通用生存分析体系结构，用于电子健康记录。使用超过130,000人的真实世界索赔数据集评估了STRAFE的性能，这些人患有3期慢性肾脏疾病（CKD），发现其在预测到达5期的恶化的确切时间方面优于其他时间到达事件预测算法。此外，STRAFE在预测固定时间风险方面也优于二元结果算法，可能是由于其能够对被审查数据进行训练的能力。我们展示STRAFE的预测可以提高阳性预测。

    Deep-learning techniques, particularly the transformer model, have shown great potential in enhancing the prediction performance of longitudinal health records. While previous methods have mainly focused on fixed-time risk prediction, time-to-event prediction (also known as survival analysis) is often more appropriate for clinical scenarios. Here, we present a novel deep-learning architecture we named STRAFE, a generalizable survival analysis transformer-based architecture for electronic health records. The performance of STRAFE was evaluated using a real-world claim dataset of over 130,000 individuals with stage 3 chronic kidney disease (CKD) and was found to outperform other time-to-event prediction algorithms in predicting the exact time of deterioration to stage 5. Additionally, STRAFE was found to outperform binary outcome algorithms in predicting fixed-time risk, possibly due to its ability to train on censored data. We show that STRAFE predictions can improve the positive predic
    
[^20]: 智能音箱设计的挑战与机遇

    Challenges and Opportunities for the Design of Smart Speakers. (arXiv:2306.05741v1 [cs.HC])

    [http://arxiv.org/abs/2306.05741](http://arxiv.org/abs/2306.05741)

    本文通过对35篇论文的文献综述以及15名智能音箱用户的访谈，总结出了智能音箱设计中的五个主题和四个设计挑战，同时提出了四个设计机遇空间，如提供信息支持，在设计中融入用户的心理模型以及整合平静的设计原则等。

    

    语音技术和语音用户界面（VUI），如Alexa、Siri和Google Home等的进步，为许多新类型的交互提供了潜力。然而，尽管市场越来越大，VUI研究越来越多，但人们仍然感到这项技术被低估了。在本文中，我们对35篇论文进行了系统性的文献综述，将127个VUI设计指南综合成了五个主题。此外，我们还对15名智能音箱用户进行了半结构化访谈，以了解他们对技术的使用和不使用情况。通过访谈，我们总结出了四个对不使用技术做出最大贡献的设计挑战。基于他们的使用情况，我们确定了四个设计机遇空间，例如专注于在多任务（烹饪、驾驶、育儿等）中提供信息支持，将用户的智能音箱心理模型融入设计当中，以及整合平静的设计原则。

    Advances in voice technology and voice user interfaces (VUIs) -- such as Alexa, Siri, and Google Home -- have opened up the potential for many new types of interaction. However, despite the potential of these devices reflected by the growing market and body of VUI research, there is a lingering sense that the technology is still underused. In this paper, we conducted a systematic literature review of 35 papers to identify and synthesize 127 VUI design guidelines into five themes. Additionally, we conducted semi-structured interviews with 15 smart speaker users to understand their use and non-use of the technology. From the interviews, we distill four design challenges that contribute the most to non-use. Based on their (non-)use, we identify four opportunity spaces for designers to explore such as focusing on information support while multitasking (cooking, driving, childcare, etc), incorporating users' mental models for smart speakers, and integrating calm design principles.
    
[^21]: 探究大型语言模型对初学者程序员求助请求的回应

    Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests. (arXiv:2306.05715v1 [cs.CY])

    [http://arxiv.org/abs/2306.05715](http://arxiv.org/abs/2306.05715)

    研究探究了大型语言模型（LLMs）对学生程序员求助请求的回应能力，评估了其在识别学生问题代码方面的表现。GPT-3.5在大多数方面表现优于Codex，两个LLM经常在每个学生程序中找到至少一个实际问题，但都未能找到全部问题。

    

    背景和背景：在过去的一年中，大型语言模型（LLM）席卷全球。在计算机教育中，就像在生活的其他方面一样，许多机遇和威胁出现了。目标：本文中，我们探讨了一个特定领域中的机遇和威胁：回应学生程序员的求助请求。更具体地说，我们评估了LLM在识别学生请求帮助的问题代码方面的能力。方法：我们从在线编程课程中收集了求助请求和代码样本。然后促使两个不同的LLM（OpenAI Codex和GPT-3.5）识别和解释学生代码中的问题，并定量和定性评估了LLM生成的答案。发现：GPT-3.5在大多数方面表现优于Codex。两个LLM经常在每个学生程序中找到至少一个实际问题（GPT-3.5在90％的情况下） 。

    Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence.  Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers' help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on.  Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students' code and assessed the LLM-generated answers both quantitatively and qualitatively.  Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 
    
[^22]: 在不平衡的语音数据中学习情感表示以用于语音情感识别和情感语音合成

    Learning Emotional Representations from Imbalanced Speech Data for Speech Emotion Recognition and Emotional Text-to-Speech. (arXiv:2306.05709v1 [eess.AS])

    [http://arxiv.org/abs/2306.05709](http://arxiv.org/abs/2306.05709)

    本文提出了一种情感提取器，用于从不平衡数据集中提取有效且具有可泛化性的情感表示。情感提取器在三个不平衡数据集中超过了现有的基线模型，并有利于情感语音合成。

    

    有效的语音情感表示对于语音情感识别（SER）和情感语音合成（TTS）任务至关重要。然而，情感语音样本比中性样式语音更难以获取且成本更高，这导致一个问题，即大多数相关工作不幸地忽略了不平衡的数据集。这导致模型可能过度拟合于大多数中性类别并无法产生强健和有效的情感表示。本文提出了一种情感提取器以解决这个问题。我们使用增强方法训练模型，并使其能够从不平衡的数据集中提取出有效且具有可泛化性的情感表示。我们的实证结果表明：（1）对于SER任务，该情感提取器在三个不平衡数据集上超过了现有的基线模型；（2）从我们的情感提取器产生的表示有利于TTS模型，并使之能够合成更具表现力的语音。

    Effective speech emotional representations play a key role in Speech Emotion Recognition (SER) and Emotional Text-To-Speech (TTS) tasks. However, emotional speech samples are more difficult and expensive to acquire compared with Neutral style speech, which causes one issue that most related works unfortunately neglect: imbalanced datasets. Models might overfit to the majority Neutral class and fail to produce robust and effective emotional representations. In this paper, we propose an Emotion Extractor to address this issue. We use augmentation approaches to train the model and enable it to extract effective and generalizable emotional representations from imbalanced datasets. Our empirical results show that (1) for the SER task, the proposed Emotion Extractor surpasses the state-of-the-art baseline on three imbalanced datasets; (2) the produced representations from our Emotion Extractor benefit the TTS model, and enable it to synthesize more expressive speech.
    
[^23]: 用MT-Bench和Chatbot Arena评估以LLM为基础的聊天助手

    Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. (arXiv:2306.05685v1 [cs.CL])

    [http://arxiv.org/abs/2306.05685](http://arxiv.org/abs/2306.05685)

    研究使用强大的LLM作为评判员，通过引入两个基准测试来确认LLM评判员和人类偏好之间的一致性，并可调整聊天助手的模型架构和微调方法来提高其性能。

    

    评估基于大语言模型（LLM）的聊天助手会面临挑战，因为它们具有广泛的功能，而现有的基准无法衡量人类偏好。为了解决这个问题，我们探索使用强大的LLM作为评判员，在更加开放的问题上评估这些模型。我们研究了LLM作为评判员的使用和局限性，如位置和冗余偏见以及有限的推理能力，并提出解决方案来迁移其中一些问题。然后，我们通过引入两个基准测试（一个多轮问答集和一个众包竞技平台）来确认LLM评判员和人类偏好之间的一致性。我们的结果显示，像GPT-4这样的强大LLM评判员可以很好地匹配受控和众包人类偏好，达到了80％以上的一致性，与人类一致性水平相同。因此，LLM作为评判员是一种可扩展且可解释的逼近人类偏好的方式，而这些偏好是非常昂贵获取的。此外，我们证明，通过使用LLM作为评判员，可以通过调整聊天助手的模型架构和微调方法来提高其性能。

    Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, such as position and verbosity biases and limited reasoning ability, and propose solutions to migrate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we
    
[^24]: COVER：一种启发式贪心对抗攻击预训练语言模型中的基于提示学习

    COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models. (arXiv:2306.05659v1 [cs.CL])

    [http://arxiv.org/abs/2306.05659](http://arxiv.org/abs/2306.05659)

    本文提出了一种启发式贪心对抗攻击，针对基于提示的模板在PLMs中可能存在的漏洞，通过字符级和单词级的破坏方法进行攻击，取得了较高的攻击成功率。

    

    基于提示的学习已被证明是预训练语言模型（PLMs）中一种有效的方式，特别是在像少量样本场景这样的低资源情况下。然而，PLMs的可信度至关重要，并且在基于模板的提示中已经显示出了潜在的漏洞，可能会误导语言模型的预测，引起严重的安全问题。本文通过在黑盒场景中提出基于提示的对抗攻击手段，揭示了PLMs的一些漏洞。首先，我们设计了字符级别和单词级别的启发式方法来破坏手动模板。然后，我们基于上述启发式破坏方法提出了一种贪心算法进行攻击。最后，我们使用BERT系列模型的三个变种和八个数据集的分类任务评估了我们的方法。广泛的实验结果证明了我们的方法在攻击成功率方面的有效性。

    Prompt-based learning has been proved to be an effective way in pre-trained language models (PLMs), especially in low-resource scenarios like few-shot settings. However, the trustworthiness of PLMs is of paramount significance and potential vulnerabilities have been shown in prompt-based templates that could mislead the predictions of language models, causing serious security concerns. In this paper, we will shed light on some vulnerabilities of PLMs, by proposing a prompt-based adversarial attack on manual templates in black box scenarios. First of all, we design character-level and word-level heuristic approaches to break manual templates separately. Then we present a greedy algorithm for the attack based on the above heuristic destructive approaches. Finally, we evaluate our approach with the classification tasks on three variants of BERT series models and eight datasets. And comprehensive experimental results justify the effectiveness of our approach in terms of attack success rate
    
[^25]: 在线心理健康风险评估的隐私感知问答系统

    Privacy Aware Question-Answering System for Online Mental Health Risk Assessment. (arXiv:2306.05652v1 [cs.CL])

    [http://arxiv.org/abs/2306.05652](http://arxiv.org/abs/2306.05652)

    本研究提出了一种利用问答（QA）方法进行心理健康风险评估的技术，在保护用户数据的前提下，通过预训练的语言模型对用户社交媒体数据进行分类，并且应用于两个大型心理健康数据集。结果表明，该方法对于心理健康用例尤其有效。

    

    社交媒体平台使患有精神疾病的人分享生活经历并找到在线支持以应对疾病。然而，许多用户未能获得真正的临床支持，从而加剧了他们的症状。基于用户在网上发布的内容进行筛选可以帮助提供者进行有针对性的医疗保健，并尽量减少虚假阳性。预训练的语言模型（LMs）可以评估用户的社交媒体数据，并将其分类为其心理健康风险。我们提出了一种使用统一问答（Unified-QA）模型的问答方法来评估心理健康风险，应用于两个大型心理健康数据集。为了保护用户数据，我们扩展了Unified-QA，并使用差分隐私对模型训练过程进行了匿名化处理。我们的结果表明，将风险评估建模为问答任务对于心理健康用例特别有效。此外，包含差分隐私后，模型性能下降不到1%。

    Social media platforms have enabled individuals suffering from mental illnesses to share their lived experiences and find the online support necessary to cope. However, many users fail to receive genuine clinical support, thus exacerbating their symptoms. Screening users based on what they post online can aid providers in administering targeted healthcare and minimize false positives. Pre-trained Language Models (LMs) can assess users' social media data and classify them in terms of their mental health risk. We propose a Question-Answering (QA) approach to assess mental health risk using the Unified-QA model on two large mental health datasets. To protect user data, we extend Unified-QA by anonymizing the model training process using differential privacy. Our results demonstrate the effectiveness of modeling risk assessment as a QA task, specifically for mental health use cases. Furthermore, the model's performance decreases by less than 1% with the inclusion of differential privacy. T
    
[^26]: WSPAlign: 大规模弱监督跨度预测下的词对齐预训练

    WSPAlign: Word Alignment Pre-training via Large-Scale Weakly Supervised Span Prediction. (arXiv:2306.05644v1 [cs.CL])

    [http://arxiv.org/abs/2306.05644](http://arxiv.org/abs/2306.05644)

    本文提出了一种名为WSPAlign的无需手动数据的预训练词对齐方法，通过用大规模弱监督数据中的跨度预测进行预训练，取得了比当前最佳方法更好的效果。

    

    大多数现有的词对齐方法依赖于手动对齐数据集或平行语料库，这限制了它们的实用性。为了缓解对手动数据的依赖，我们通过放宽对正确、完全对齐和平行句子的要求，扩大了监督数据的来源。具体而言，我们生成了带有噪声、部分对齐和非平行段落作为大规模弱监督数据集，通过跨度预测对词对齐进行预训练。广泛的实验表明，我们的方法名为WSPAlign，是一种有效且可扩展的无需手动数据的预训练词对齐方法。在标准基准测试中fine-tuning时，WSPAlign在F1和AER两个指标上的最佳监督基线分别提高了3.3~6.1和1.5~6.1个点，成为了新的最优结果。此外，WSPAlign在少样本、零样本和跨语言测试中也获得了与相应基线相同的竞争性能。

    Most existing word alignment methods rely on manual alignment datasets or parallel corpora, which limits their usefulness. Here, to mitigate the dependence on manual data, we broaden the source of supervision by relaxing the requirement for correct, fully-aligned, and parallel sentences. Specifically, we make noisy, partially aligned, and non-parallel paragraphs. We then use such a large-scale weakly-supervised dataset for word alignment pre-training via span prediction. Extensive experiments with various settings empirically demonstrate that our approach, which is named WSPAlign, is an effective and scalable way to pre-train word aligners without manual data. When fine-tuned on standard benchmarks, WSPAlign has set a new state-of-the-art by improving upon the best-supervised baseline by 3.3~6.1 points in F1 and 1.5~6.1 points in AER. Furthermore, WSPAlign also achieves competitive performance compared with the corresponding baselines in few-shot, zero-shot and cross-lingual tests, whi
    
[^27]: 面向医疗报告生成的通用基础模型自定义

    Customizing General-Purpose Foundation Models for Medical Report Generation. (arXiv:2306.05642v1 [cs.CV])

    [http://arxiv.org/abs/2306.05642](http://arxiv.org/abs/2306.05642)

    这项工作中，我们提出了一种自定义通用基础模型以用于医疗报告生成的方法，其利用轻量级查询Transformer连接两个FMs，并在三个基准数据集上实现了最先进的结果。

    

    医疗字幕预测，也被视为医疗报告生成（MRG）的任务，需要为给定的医疗图像自动生成连贯准确的字幕。然而，标记的医疗图像-报告对的稀缺性在深度和大规模神经网络的开发中提出了巨大挑战，这些网络可以利用大型语言模型（LLM）这样的人工智能潜力。在这项工作中，我们建议将通用的面向计算机视觉和自然语言处理的基础模型进行定制，特别关注医疗报告生成。具体来说，我们根据BLIP-2提出了基于编码器-解码器的MRG模型，该模型利用轻量级查询Transformer连接两个FMs：巨型视觉Transformer EVA-ViT-g和双语LLM，该LLM被训练用于与人类意图对齐（称为T5-base-CN）。实验结果表明，我们提出的方法在三个医疗报告生成基准数据集上实现了最先进的结果，这表明了将基础模型适应于此任务的有效性。

    Medical caption prediction which can be regarded as a task of medical report generation (MRG), requires the automatic generation of coherent and accurate captions for the given medical images. However, the scarcity of labelled medical image-report pairs presents great challenges in the development of deep and large-scale neural networks capable of harnessing the potential artificial general intelligence power like large language models (LLMs). In this work, we propose customizing off-the-shelf general-purpose large-scale pre-trained models, i.e., foundation models (FMs), in computer vision and natural language processing with a specific focus on medical report generation. Specifically, following BLIP-2, a state-of-the-art vision-language pre-training approach, we introduce our encoder-decoder-based MRG model. This model utilizes a lightweight query Transformer to connect two FMs: the giant vision Transformer EVA-ViT-g and a bilingual LLM trained to align with human intentions (referred
    
[^28]: 基于低秩适应性的Wav2vec2声音伪造检测方法

    Low-rank Adaptation Method for Wav2vec2-based Fake Audio Detection. (arXiv:2306.05617v1 [cs.SD])

    [http://arxiv.org/abs/2306.05617](http://arxiv.org/abs/2306.05617)

    本论文提出了一种基于低秩适应性的Wav2vec2声音伪造检测方法，通过注入可训练秩分解矩阵到变压器结构的每一层中来减少可训练参数数量，可以有效缓解微调预训练模型时过长训练时间和高内存消耗的问题。

    

    自监督语音模型是声音伪造检测中快速发展的研究主题。许多预训练模型可以作为特征提取器，学习更丰富和更高级别的语音特征。然而，在微调预先训练的模型时，通常存在过长的训练时间和高内存消耗的挑战，而完全微调也非常昂贵。为了缓解这个问题，我们应用低秩适应（LoRA）到wav2vec2模型中，冻结预训练模型的权重，并将可训练秩分解矩阵注入到变压器结构的每一层中，从而大大减少了下游任务的可训练参数数量。与使用包含317M训练参数的wav2vec2模型上的Adam微调相比，LoRA通过将可训练参数数量减少198倍，实现了类似的性能。

    Self-supervised speech models are a rapidly developing research topic in fake audio detection. Many pre-trained models can serve as feature extractors, learning richer and higher-level speech features. However,when fine-tuning pre-trained models, there is often a challenge of excessively long training times and high memory consumption, and complete fine-tuning is also very expensive. To alleviate this problem, we apply low-rank adaptation(LoRA) to the wav2vec2 model, freezing the pre-trained model weights and injecting a trainable rank-decomposition matrix into each layer of the transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared with fine-tuning with Adam on the wav2vec2 model containing 317M training parameters, LoRA achieved similar performance by reducing the number of trainable parameters by 198 times.
    
[^29]: 词义扩展

    Word sense extension. (arXiv:2306.05609v1 [cs.CL])

    [http://arxiv.org/abs/2306.05609](http://arxiv.org/abs/2306.05609)

    本文提出了词义扩展（WSE）的范例，使词汇能够向新语境产生新的意义，通过首先将多义词类型划分为两个伪记号以标记其不同的意义，然后推断一个伪符号的含义是否可以被扩展以传达来自同一词类型划分出的符号所表示的意义。

    

    人类常常用词语表达新颖的意思。自然语言处理领域长期以来一直在关注词义消岐（WSD），但对于如何将一个词的意义扩展至新的含义，却鲜有探索。我们提出了词义扩展（WSE）的范例，使词汇能够向新语境产生新的意义。我们开发了一个框架，它通过首先将多义词类型划分为两个伪记号以标记其不同的意义，然后推断一个伪符号的含义是否可以被扩展以传达来自同一词类型划分出的符号所表示的意义。我们的框架将链接的认知模型与学习方案相结合，从而转换一个语言模型嵌入空间以支持各种类型的词义扩展。我们针对几个竞争基线评估我们的框架，并表明它在预测新颖词义的可信翻译方面优于其他基线。

    Humans often make creative use of words to express novel senses. A long-standing effort in natural language processing has been focusing on word sense disambiguation (WSD), but little has been explored about how the sense inventory of a word may be extended toward novel meanings. We present a paradigm of word sense extension (WSE) that enables words to spawn new senses toward novel context. We develop a framework that simulates novel word sense extension by first partitioning a polysemous word type into two pseudo-tokens that mark its different senses, and then inferring whether the meaning of a pseudo-token can be extended to convey the sense denoted by the token partitioned from the same word type. Our framework combines cognitive models of chaining with a learning scheme that transforms a language model embedding space to support various types of word sense extension. We evaluate our framework against several competitive baselines and show that it is superior in predicting plausible
    
[^30]: 产品属性值识别的统一生成方法

    A Unified Generative Approach to Product Attribute-Value Identification. (arXiv:2306.05605v1 [cs.CL])

    [http://arxiv.org/abs/2306.05605](http://arxiv.org/abs/2306.05605)

    本文探索了一种生成式方法来统一处理电子商务平台上产品属性值识别任务，实验结果表明该方法在大规模真实世界数据集上的表现优于现有的基于提取和分类的方法。

    

    产品属性值识别（PAVI）旨在使用产品文本作为线索将电子商务网站上的产品与其属性值（例如<Material，Cotton>）链接起来。现实世界电子商务平台的技术需求要求PAVI方法处理未见过的值、多属性值和规范化的值，而这些仅在现有的基于提取和分类的方法中部分得到解决。因此，我们提出了一种生成式方法来处理PAVI任务。

    Product attribute-value identification (PAVI) has been studied to link products on e-commerce sites with their attribute values (e.g., <Material, Cotton>) using product text as clues. Technical demands from real-world e-commerce platforms require PAVI methods to handle unseen values, multi-attribute values, and canonicalized values, which are only partly addressed in existing extraction- and classification-based approaches. Motivated by this, we explore a generative approach to the PAVI task. We finetune a pre-trained generative model, T5, to decode a set of attribute-value pairs as a target sequence from the given product text. Since the attribute value pairs are unordered set elements, how to linearize them will matter; we, thus, explore methods of composing an attribute-value pair and ordering the pairs for the task. Experimental results confirm that our generation-based approach outperforms the existing extraction and classification-based methods on large-scale real-world datasets 
    
[^31]: LOST: Reddit帖子中低自尊心精神健康数据集

    LOST: A Mental Health Dataset of Low Self-esteem in Reddit Posts. (arXiv:2306.05596v1 [cs.CL])

    [http://arxiv.org/abs/2306.05596](http://arxiv.org/abs/2306.05596)

    研究介绍了一个专家注释的数据集LoST：Reddit帖子中低自尊心、受挫的归属感和感知的负担的精神健康数据集。该数据集可帮助更准确地识别可能需要干预的个体。

    

    低自尊和人际需求（即受挫的归属感和感知的负担）对抑郁和自杀企图产生重大影响。个体在社交媒体上寻求社交连结以增强和缓解他们的孤独感。社交媒体平台使人们能够表达他们的想法、经验、信仰和情感。社交媒体上的心理健康研究集中在症状、原因和障碍上。而初步的社交媒体内容筛选出人际风险因素和低自尊心可能会引发心理障碍者的早期警报，并指派治疗师对其进行干预。标准化量表使用心理学理论制定的问题来衡量自尊心和人际需求。在目前的研究中，我们介绍了一个基于心理学和专家注释的数据集LoST：低自尊心，用于研究和检测Reddit上的低自尊心。通过一种注释方法，该注释包括对注释的一致性、正确性和相关性的检查，我们确保了数据集的高质量。我们的数据集包括10,000个Reddit帖子，这些帖子标注了低自尊心、受挫的归属感和感知的负担。数据集由心理学专家进行注释，他们遵循了成熟的心理学理论，用于低自尊心识别和人际需求评估。我们介绍了数据集的统计信息，并评估低自尊心检测的基线方法。我们的结果强调了需要针对低自尊心的数据集，以更准确地识别可能需要干预的个体。

    Low self-esteem and interpersonal needs (i.e., thwarted belongingness (TB) and perceived burdensomeness (PB)) have a major impact on depression and suicide attempts. Individuals seek social connectedness on social media to boost and alleviate their loneliness. Social media platforms allow people to express their thoughts, experiences, beliefs, and emotions. Prior studies on mental health from social media have focused on symptoms, causes, and disorders. Whereas an initial screening of social media content for interpersonal risk factors and low self-esteem may raise early alerts and assign therapists to at-risk users of mental disturbance. Standardized scales measure self-esteem and interpersonal needs from questions created using psychological theories. In the current research, we introduce a psychology-grounded and expertly annotated dataset, LoST: Low Self esTeem, to study and detect low self-esteem on Reddit. Through an annotation approach involving checks on coherence, correctness,
    
[^32]: 匿名化数据的隐私和效用保护：伪名化的案例研究

    Privacy- and Utility-Preserving NLP with Anonymized Data: A case study of Pseudonymization. (arXiv:2306.05561v1 [cs.CL])

    [http://arxiv.org/abs/2306.05561](http://arxiv.org/abs/2306.05561)

    本研究研究了不同的伪名化技术在NLP任务中的效果，并提供了关于数据保护和效用保护之间权衡的见解。

    

    本研究调查了不同伪名化技术（从基于规则的替代到使用预训练的大型语言模型（LLMs））在用于两个广泛使用的NLP任务（文本分类和摘要）的各种数据集和模型上的有效性。我们的工作提供了关于原始数据与匿名化数据（重点放在伪名化技术上）和模型质量之间差距的重要见解，并促进了未来对更高质量的匿名化技术进行研究，以更好地平衡数据保护和效用保护之间的权衡。我们公开提供了我们的代码、伪名化数据集和下游模型。

    This work investigates the effectiveness of different pseudonymization techniques, ranging from rule-based substitutions to using pre-trained Large Language Models (LLMs), on a variety of datasets and models used for two widely used NLP tasks: text classification and summarization. Our work provides crucial insights into the gaps between original and anonymized data (focusing on the pseudonymization technique) and model quality and fosters future research into higher-quality anonymization techniques to better balance the trade-offs between data protection and utility preservation. We make our code, pseudonymized datasets, and downstream models publicly available
    
[^33]: 情感和情绪引导的改写

    Emotion and Sentiment Guided Paraphrasing. (arXiv:2306.05556v1 [cs.CL])

    [http://arxiv.org/abs/2306.05556](http://arxiv.org/abs/2306.05556)

    本研究提出了一种情感和情绪引导的改写框架，实现了细粒度的情感调节，可用于多种场景，通过添加细粒度情感标签可以提高结果质量。

    

    改写生成是自然语言处理中常见且重要的任务，它可以对文本进行修改同时保留原本的意思。情绪改写可用于多种场景，包括调节在线对话和防止网络欺凌。本文提出了一种新的任务——细粒度情绪改写，可以在保留原文意义的同时，平滑地改变其情感强度，从而实现细粒度的情感调节。我们通过添加细粒度情感标签对几个常用的改写数据集进行了重建。然后，利用预训练语言模型进行有条件的文本生成，提出了一种情感和情绪引导的改写框架。对调整后的模型进行广泛的评估表明，将细粒度情感标签包含在改写训练中可以提高结果质量。

    Paraphrase generation, a.k.a. paraphrasing, is a common and important task in natural language processing. Emotional paraphrasing, which changes the emotion embodied in a piece of text while preserving its meaning, has many potential applications, including moderating online dialogues and preventing cyberbullying. We introduce a new task of fine-grained emotional paraphrasing along emotion gradients, that is, altering the emotional intensities of the paraphrases in fine-grained settings following smooth variations in affective dimensions while preserving the meaning of the original text. We reconstruct several widely used paraphrasing datasets by augmenting the input and target texts with their fine-grained emotion labels. Then, we propose a framework for emotion and sentiment guided paraphrasing by leveraging pre-trained language models for conditioned text generation. Extensive evaluation of the fine-tuned models suggests that including fine-grained emotion labels in the paraphrase t
    
[^34]: ChatGPT for Us: 通过对话文本模糊化扩展心理保健交付以保护数据隐私

    ChatGPT for Us: Preserving Data Privacy in ChatGPT via Dialogue Text Ambiguation to Expand Mental Health Care Delivery. (arXiv:2306.05552v1 [cs.CL])

    [http://arxiv.org/abs/2306.05552](http://arxiv.org/abs/2306.05552)

    本研究提出了一个文本模糊化框架，以保护用户隐私并扩展心理保健交付。结果表明即使不提供原始用户文本，ChatGPT的建议仍然能够适度地有帮助和相关性。

    

    大型语言模型对于扩展心理保健交付非常有用。尤其是ChatGPT因其生成人类对话的能力而备受欢迎。然而，数据敏感的领域，包括但不限于医疗保健，由于隐私和数据所有权问题，无法使用ChatGPT。为了使其得到利用，我们提出了一个文本模糊化框架，以保护用户的隐私。我们把这个框架用于解决用户提供的压力问题，以展示这种隐私保护生成的可行性和有益性。我们的结果表明，即使不提供原始用户文本，ChatGPT的建议仍然能够适度地有帮助和相关性。

    Large language models have been useful in expanding mental health care delivery. ChatGPT, in particular, has gained popularity for its ability to generate human-like dialogue. However, data-sensitive domains -- including but not limited to healthcare -- face challenges in using ChatGPT due to privacy and data-ownership concerns. To enable its utilization, we propose a text ambiguation framework that preserves user privacy. We ground this in the task of addressing stress prompted by user-provided texts to demonstrate the viability and helpfulness of privacy-preserved generations. Our results suggest that chatGPT recommendations are still able to be moderately helpful and relevant, even when the original user text is not provided.
    
[^35]: 对带“标记语言模型”中93个受歧视群体的偏见及其对下游情感分类任务的影响

    Bias Against 93 Stigmatized Groups in Masked Language Models and Downstream Sentiment Classification Tasks. (arXiv:2306.05550v1 [cs.CY])

    [http://arxiv.org/abs/2306.05550](http://arxiv.org/abs/2306.05550)

    本研究研究了英语预训练的Masked Language Models（MLMs）以及它们的下游情感分类任务对美国93个社会污名化群体的偏见，为了评估93个污名化条件的偏见存在，我们对它们进行了比较分析，找到了偏见存在的表现。

    

    人工智能模型的快速部署需要对这些模型固有的偏见和风险进行彻底的调查，以了解它们对个人和社会的影响。本研究通过对大规模社会污名化的偏见进行研究，扩展了已有工作对偏见评估的焦点。它关注美国93个社会污名化群体，包括与疾病、残疾、药物使用、心理疾病、宗教、性取向、社会经济地位和其他相关因素有关的一系列情况。我们研究了英语预训练的Masked Language Models（MLMs）以及它们的下游情感分类任务对这些群体的偏见。为了评估93个污名化条件的偏见存在，我们确定了29个非污名化条件进行比较分析。基于社会排斥的心理学尺度-社会距离量表，我们对六个MLMs进行了提示：RoBERTa-base、RoBERTa-large、XLNet-large、BERTweet-base、BERTweet-la。

    The rapid deployment of artificial intelligence (AI) models demands a thorough investigation of biases and risks inherent in these models to understand their impact on individuals and society. This study extends the focus of bias evaluation in extant work by examining bias against social stigmas on a large scale. It focuses on 93 stigmatized groups in the United States, including a wide range of conditions related to disease, disability, drug use, mental illness, religion, sexuality, socioeconomic status, and other relevant factors. We investigate bias against these groups in English pre-trained Masked Language Models (MLMs) and their downstream sentiment classification tasks. To evaluate the presence of bias against 93 stigmatized conditions, we identify 29 non-stigmatized conditions to conduct a comparative analysis. Building upon a psychology scale of social rejection, the Social Distance Scale, we prompt six MLMs: RoBERTa-base, RoBERTa-large, XLNet-large, BERTweet-base, BERTweet-la
    
[^36]: DetectLLM：基于对数秩信息的零样本检测机器生成文本

    DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text. (arXiv:2306.05540v1 [cs.CL])

    [http://arxiv.org/abs/2306.05540](http://arxiv.org/abs/2306.05540)

    作者提出了两种零样本方法，DetectLLM-LRR和DetectLLM-NPR，可以通过利用日志排名信息来检测机器生成的文本，实验表明这些方法在检测效果上超过了现有的最佳方法。

    

    随着大型语言模型（LLM）的快速进展和所生成的文本数量的巨大增加，人工区分文本是否为机器生成变得越来越不切实际。考虑到LLM在社交媒体和教育中的广泛应用，促使我们开发检测机器生成文本的方法，以防止恶意使用，如抄袭、虚假信息和宣传。以前的研究已经研究了几种零样本的方法，这些方法不需要训练数据。这些方法取得了良好的性能，但还有很大的改进空间。本文介绍了两种新的零样本方法，用于利用对数秩信息检测机器生成文本。其中一个称为DetectLLM-LRR，快速高效，另一个称为DetectLLM-NPR，更精确，但需要扰动，因此速度更慢。我们在三个数据集和七个语言模型上的实验表明，我们提出的方法在零样本检测机器生成文本方面超过了现有的最佳效果。

    With the rapid progress of large language models (LLMs) and the huge amount of text they generated, it becomes more and more impractical to manually distinguish whether a text is machine-generated. Given the growing use of LLMs in social media and education, it prompts us to develop methods to detect machine-generated text, preventing malicious usage such as plagiarism, misinformation, and propaganda. Previous work has studied several zero-shot methods, which require no training data. These methods achieve good performance, but there is still a lot of room for improvement. In this paper, we introduce two novel zero-shot methods for detecting machine-generated text by leveraging the log rank information. One is called DetectLLM-LRR, which is fast and efficient, and the other is called DetectLLM-NPR, which is more accurate, but slower due to the need for perturbations. Our experiments on three datasets and seven language models show that our proposed methods improve over the state of the
    
[^37]: 指令调节模型是快速学习者

    Instruction Tuned Models are Quick Learners. (arXiv:2306.05539v1 [cs.CL])

    [http://arxiv.org/abs/2306.05539](http://arxiv.org/abs/2306.05539)

    本文研究了指令调节模型在各种任务中的效率，结果表明，在单任务学习（STL）设置下，配备25％下游训练数据的指令调节模型超过了最先进的监督性能。

    

    通过在上下文学习中使用少量示例展示了语言模型的指令调节如何增强模型对未见任务的概括能力。然而，通常的监督学习仍需要大量的下游训练数据进行微调。在现实世界的情况下，微调往往仅有少量数据可用，介于少样本推理和完全监督微调之间。在本文中，我们展示了指令调节模型在各种任务中的效率，通过估计其执行转移学习并匹配最先进监督模型所需的最小下游训练数据。我们在单任务学习（STL）和多任务学习（MTL）设置下，在来自超级自然指令（SuperNI）的119个任务上进行了实验。我们的发现表明，在STL设置下，配备25％下游训练数据的指令调节模型超过了最先进的监督性能。

    Instruction tuning of language models has demonstrated the ability to enhance model generalization to unseen tasks via in-context learning using a few examples. However, typical supervised learning still requires a plethora of downstream training data for finetuning. Often in real-world situations, there is a scarcity of data available for finetuning, falling somewhere between few shot inference and fully supervised finetuning. In this work, we demonstrate the sample efficiency of instruction tuned models over various tasks by estimating the minimal downstream training data required by them to perform transfer learning and match the performance of state-of-the-art (SOTA) supervised models. We conduct experiments on 119 tasks from Super Natural Instructions (SuperNI) in both the single task learning (STL) and multi task learning (MTL) settings. Our findings reveal that, in the STL setting, instruction tuned models equipped with 25% of the downstream train data surpass the SOTA performan
    
[^38]: AaKOS: 方面自适应知识驱动的意见摘要

    AaKOS: Aspect-adaptive Knowledge-based Opinion Summarization. (arXiv:2306.05537v1 [cs.CL])

    [http://arxiv.org/abs/2306.05537](http://arxiv.org/abs/2306.05537)

    本文提出了一个方面自适应的知识驱动意见摘要方法，通过结合预训练语言模型和丰富的知识库来有效地生成简短但显著的摘要，提高了意见摘要的准确性和适应性。

    

    互联网上信息的快速增长导致各种活动、产品和服务上有压倒性的意见和评论。这使得用户在做决策时处理所有可用信息变得困难和耗时。文本摘要是一项自然语言处理任务，已被广泛探索，可通过从长文档或多个文件中生成简短而显著的内容来帮助用户快速检索相关信息。最近预训练语言模型（如ChatGPT）的进展展示了大型语言模型（LLMs）在文本生成方面的潜力。然而，LLMs需要大量的数据和资源，并且难以作为离线应用实现。此外，现有的文本摘要方法常常缺乏“自适应”能力，无法捕捉到多样化的方面，这对具有特定要求或偏好的用户特别不利。本文提出了一种方面自适应的知识驱动意见摘要方法。

    The rapid growth of information on the Internet has led to an overwhelming amount of opinions and comments on various activities, products, and services. This makes it difficult and time-consuming for users to process all the available information when making decisions. Text summarization, a Natural Language Processing (NLP) task, has been widely explored to help users quickly retrieve relevant information by generating short and salient content from long or multiple documents. Recent advances in pre-trained language models, such as ChatGPT, have demonstrated the potential of Large Language Models (LLMs) in text generation. However, LLMs require massive amounts of data and resources and are challenging to implement as offline applications. Furthermore, existing text summarization approaches often lack the ``adaptive" nature required to capture diverse aspects in opinion summarization, which is particularly detrimental to users with specific requirements or preferences. In this paper, w
    
[^39]: 使用音频数据检测政治辩论、演讲和访谈中值得核实的论断

    Detecting Check-Worthy Claims in Political Debates, Speeches, and Interviews Using Audio Data. (arXiv:2306.05535v1 [cs.CL])

    [http://arxiv.org/abs/2306.05535](http://arxiv.org/abs/2306.05535)

    政治辩论、演讲和访谈中的值得核实的论断可以使用音频数据进行检测和确认，这可帮助主持人、记者和事实核查组织进行工作。

    

    社会的一大部分团结在相同的愿景和思想周围，具有巨大的能量。这正是政治人物希望为他们的事业所累积的。为了达到这个目标，他们有时会使用扭曲或隐藏真相的手段，无论是无意的还是有意的，这为错误信息和误导开了大门。自动检测值得核实的论断的工具将对辩论主持人、记者和事实核查组织有很大帮助。虽然以前关于检测值得核实的论断的工作重点是文本，但在这里，我们探讨了音频信号作为额外信息源的实用性。我们创建了一个新的多模态数据集（英语文本和音频），包含48小时的演讲。我们的评估结果表明，在多个演讲者的情况下，音频模态与文本结合使用比仅使用文本具有改进效果。此外，单声道音频模型可以胜过单声道文本模型。

    A large portion of society united around the same vision and ideas carries enormous energy. That is precisely what political figures would like to accumulate for their cause. With this goal in mind, they can sometimes resort to distorting or hiding the truth, unintentionally or on purpose, which opens the door for misinformation and disinformation. Tools for automatic detection of check-worthy claims would be of great help to moderators of debates, journalists, and fact-checking organizations. While previous work on detecting check-worthy claims has focused on text, here we explore the utility of the audio signal as an additional information source. We create a new multimodal dataset (text and audio in English) containing 48 hours of speech. Our evaluation results show that the audio modality together with text yields improvements over text alone in the case of multiple speakers. Moreover, an audio-only model could outperform a text-only one for a single speaker.
    
[^40]: FACTIFY3M: 通过5W问答解释的多模式事实验证基准

    FACTIFY3M: A Benchmark for Multimodal Fact Verification with Explainability through 5W Question-Answering. (arXiv:2306.05523v1 [cs.CL])

    [http://arxiv.org/abs/2306.05523](http://arxiv.org/abs/2306.05523)

    FACTIFY3M是一个以多模式虚假信息验证为目标的数据集。虚假信息如今已成为当下重大的社会问题，这一数据集旨在通过多模式验证来及时识别和缓解虚假信息。

    

    打击虚假信息是当前亟待解决的社会危机之一——大约67%的美国人认为虚假信息会产生大量的不确定性，其中有10%的人有意识地传播虚假信息。证据表明，虚假信息可以操纵民主进程和公众舆论，并在危机期间引起股市动荡、社会恐慌甚至死亡。因此，应及时识别并尽可能缓解虚假信息。然而，由于社交媒体平台每天分享大约32亿张图像和720,000 小时的视频，因此对于多模式虚假信息的可扩展性检测需要高效的事实验证。尽管在文本模式下自动事实验证取得了进展(例如，FEVER, LIAR)，但学术界在多模式事实验证方面缺乏实质性的努力。为了填补这一空白，我们引入了FACTIFY3M数据集，该数据集包含300万个样本，通过多种模式和5W问答提高了事实验证领域的极限。

    Combating disinformation is one of the burning societal crises -- about 67% of the American population believes that disinformation produces a lot of uncertainty, and 10% of them knowingly propagate disinformation. Evidence shows that disinformation can manipulate democratic processes and public opinion, causing disruption in the share market, panic and anxiety in society, and even death during crises. Therefore, disinformation should be identified promptly and, if possible, mitigated. With approximately 3.2 billion images and 720,000 hours of video shared online daily on social media platforms, scalable detection of multimodal disinformation requires efficient fact verification. Despite progress in automatic text-based fact verification (e.g., FEVER, LIAR), the research community lacks substantial effort in multimodal fact verification. To address this gap, we introduce FACTIFY 3M, a dataset of 3 million samples that pushes the boundaries of the domain of fact verification via a multi
    
[^41]: 文本到图像模型中分析偏见的单词级解释

    Word-Level Explanations for Analyzing Bias in Text-to-Image Models. (arXiv:2306.05500v1 [cs.CL])

    [http://arxiv.org/abs/2306.05500](http://arxiv.org/abs/2306.05500)

    本文探讨了文本到图像模型中存在的少数族裔偏见，提出了一种利用屏蔽语言模型计算提示中单词得分的方法，并通过实验证明其可以识别生成的图像中存在的社会刻板印象。

    

    文本到图像模型接收一句话（即提示）并生成与该输入提示相关联的图像。但是，这些模型可以生成基于种族和性别而偏袒少数族裔的图像。本文研究了输入提示中哪个单词导致生成图像出现偏见。我们引入了一种计算提示中每个单词得分的方法；这些得分代表其在模型输出偏差中的影响。我们的方法遵循“删除解释”的原则，利用屏蔽语言模型计算影响得分。我们在稳定扩散上进行实验，证明我们的方法可以识别生成的图像中复制社会刻板印象。

    Text-to-image models take a sentence (i.e., prompt) and generate images associated with this input prompt. These models have created award wining-art, videos, and even synthetic datasets. However, text-to-image (T2I) models can generate images that underrepresent minorities based on race and sex. This paper investigates which word in the input prompt is responsible for bias in generated images. We introduce a method for computing scores for each word in the prompt; these scores represent its influence on biases in the model's output. Our method follows the principle of \emph{explaining by removing}, leveraging masked language models to calculate the influence scores. We perform experiments on Stable Diffusion to demonstrate that our method identifies the replication of societal stereotypes in generated images.
    
[^42]: LLM集成应用中的提示注入攻击研究

    Prompt Injection attack against LLM-integrated Applications. (arXiv:2306.05499v1 [cs.CR])

    [http://arxiv.org/abs/2306.05499](http://arxiv.org/abs/2306.05499)

    本研究分析了LLM集成应用中的提示注入攻击的复杂性和影响，提出了一种新颖的黑盒提示注入攻击技术HouYi，并揭示了应用程序提示机制中以前未知和严重低估的漏洞。我们的研究呼吁进一步开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。

    

    大语言模型(LLM)因其卓越的语言理解和生成能力而在它们周围刺激了一个充满活力的应用生态系统。然而，它们在各种服务中的广泛融合带来了重大的安全风险。本研究将解构实际LLM集成应用中的提示注入攻击的复杂性和影响。最初，我们对十个商业应用程序进行了探索性分析，突出了目前攻击策略在实践中的约束条件。受这些限制的启发，我们随后制定了HouYi，一种新颖的黑盒提示注入攻击技术，它借鉴了传统的Web注入攻击。HouYi分为三个关键元素: 一个无缝集成的预构建提示、一个注入提示诱导上下文分区以及一个恶意载荷，旨在实现攻击目标。利用HouYi，我们揭示了应用程序提示机制中以前未知和严重低估的漏洞，并演示了绕过最先进的检测机制的可行性。我们的研究呼吁进一步研究开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。

    Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HouYi, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HouYi is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HouYi, we unveil previously unknown and sev
    
[^43]: 六边形标注：将投影依存句法分析作为标注

    Hexatagging: Projective Dependency Parsing as Tagging. (arXiv:2306.05477v1 [cs.CL])

    [http://arxiv.org/abs/2306.05477](http://arxiv.org/abs/2306.05477)

    六边形标注器是一种新颖的依存分析器，可以在训练时实现完全并行化，具有线性时间复杂度和空间复杂度。使用预训练语言模型的特征进行预测。在 Penn Treebank 测试集上取得了最先进的性能。

    

    我们介绍了一种新颖的依存分析器——六边形标注器，它通过将句子中的单词标记为来自可能标记有限集合中的元素来构建依存树。与许多处理依存性分析的方法不同，我们的方法在训练时是完全可并行化的，即用于构建依存分析所需的结构构建操作可以相互并行预测。此外，确切解码的时间和空间复杂度都是线性的。此外，我们导出了一种概率依存分析器，它使用预训练语言模型的特征来预测六边标记，而不需要专为此任务明确设计的定制体系结构。尽管我们的方法具有通用性和简单性，但在 Penn Treebank 测试集上，我们实现了 96.4 LAS 和 97.4 UAS 的最先进性能。此外，我们的分析器的线性时间复杂度和并行性显著提高了计算效率，速度提高了大约十倍。

    We introduce a novel dependency parser, the hexatagger, that constructs dependency trees by tagging the words in a sentence with elements from a finite set of possible tags. In contrast to many approaches to dependency parsing, our approach is fully parallelizable at training time, i.e., the structure-building actions needed to build a dependency parse can be predicted in parallel to each other. Additionally, exact decoding is linear in time and space complexity. Furthermore, we derive a probabilistic dependency parser that predicts hexatags using no more than a linear model with features from a pretrained language model, i.e., we forsake a bespoke architecture explicitly designed for the task. Despite the generality and simplicity of our approach, we achieve state-of-the-art performance of 96.4 LAS and 97.4 UAS on the Penn Treebank test set. Additionally, our parser's linear time complexity and parallelism significantly improve computational efficiency, with a roughly 10-times speed-u
    
[^44]: 患语言障碍者的潜在短语匹配系统

    Latent Phrase Matching for Dysarthric Speech. (arXiv:2306.05446v1 [eess.AS])

    [http://arxiv.org/abs/2306.05446](http://arxiv.org/abs/2306.05446)

    患有语言障碍的人在现有消费类语音识别系统中表现不佳，作者提出了一种基于个性化短语识别系统用于适应其非典型的语音模式，其具有很好的泛化性能，并在数据集上有很好的表现。

    

    很多消费类语音识别系统不能为语言障碍患者提供良好的体验和识别效果，尤其是对于语言障碍情况更为严重的人。最近的研究集中于个性化语音模型的探索，以便更好地适应非典型的语音模式。我们提出了一种基于示例的个性化短语识别系统，该系统使用少量的语音进行训练，不依赖于传统发音词典，不受不同语言影响，且在各种语音障碍情况下具有很好的泛化性能。在32名患有言语困难的人员的内部数据集上，该方法不受严重程度影响，与商业语音识别系统相比，召回率提高了60%。在公共EasyCall数据集上，我们的方法将精度提高了30.5%。当训练50个独特短语时，性能随短语数量增加而下降，但始终优于ASR系统。

    Many consumer speech recognition systems are not tuned for people with speech disabilities, resulting in poor recognition and user experience, especially for severe speech differences. Recent studies have emphasized interest in personalized speech models from people with atypical speech patterns. We propose a query-by-example-based personalized phrase recognition system that is trained using small amounts of speech, is language agnostic, does not assume a traditional pronunciation lexicon, and generalizes well across speech difference severities. On an internal dataset collected from 32 people with dysarthria, this approach works regardless of severity and shows a 60% improvement in recall relative to a commercial speech recognition system. On the public EasyCall dataset of dysarthric speech, our approach improves accuracy by 30.5%. Performance degrades as the number of phrases increases, but consistently outperforms ASR systems when trained with 50 unique phrases.
    
[^45]: PIXIU：面向金融领域的大型语言模型、指令数据和评估基准

    PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance. (arXiv:2306.05443v1 [cs.CL])

    [http://arxiv.org/abs/2306.05443](http://arxiv.org/abs/2306.05443)

    本文介绍了PIXIU框架，其中包括基于Fine-tuning LLaMA的第一个金融语言模型、包含136K数据样本用于Fine-tuning的第一个指令数据，以及具有5个任务和9个数据集的评估基准。通过对各种金融任务、金融文档类型和金融数据模态考虑，构建了大规模的多任务指令数据集，利用该数据集提出了名为FinMA的金融语言模型，以便对各种金融任务进行指令跟随。

    

    虽然大型语言模型在金融领域的自然语言处理方面表现出色，但缺乏公开的面向金融的语言模型、指令调优数据集和评估基准，这对于不断推进金融人工智能开源发展至关重要。本文提出了PIXIU框架，其中包括基于Fine-tuning LLaMA的第一个金融语言模型、包含136K数据样本用于Fine-tuning的第一个指令数据，以及具有5个任务和9个数据集的评估基准。我们首先考虑各种金融任务、金融文档类型和金融数据模态，构建了大规模的多任务指令数据集。然后，我们利用构建的数据集通过Fine-tuning LLaMA提出了名为FinMA的金融语言模型，以便对各种金融任务进行指令跟随。为了支持金融语言模型的评估

    Although large language models (LLMs) has shown great performance on natural language processing (NLP) in the financial domain, there are no publicly available financial tailtored LLMs, instruction tuning datasets, and evaluation benchmarks, which is critical for continually pushing forward the open-source development of financial artificial intelligence (AI). This paper introduces PIXIU, a comprehensive framework including the first financial LLM based on fine-tuning LLaMA with instruction data, the first instruction data with 136K data samples to support the fine-tuning, and an evaluation benchmark with 5 tasks and 9 datasets. We first construct the large-scale multi-task instruction data considering a variety of financial tasks, financial document types, and financial data modalities. We then propose a financial LLM called FinMA by fine-tuning LLaMA with the constructed dataset to be able to follow instructions for various financial tasks. To support the evaluation of financial LLMs
    
[^46]: 模型在环节内事件共指关系注释中表现如何？

    How Good is the Model in Model-in-the-loop Event Coreference Resolution Annotation?. (arXiv:2306.05434v1 [cs.CL])

    [http://arxiv.org/abs/2306.05434](http://arxiv.org/abs/2306.05434)

    本论文提出了一种模型在环节中事件共指关系注释方法，通过机器学习模型只建议可能的共指事件对，将完全手动注释过程所需的工作量大幅度减少，同时实现97％的召回率。

    

    注释跨文档事件共指链接是一项费时且认知要求高的任务，可能会影响注释质量和效率。为了解决这个问题，我们提出了一种模型在环节中事件共指关系注释方法，其中机器学习模型只建议可能的共指事件对。我们通过首先模拟注释过程，然后使用一种新颖的注释者为中心的召回-注释工作量平衡度量来比较不同基础模型和数据集的结果，评估了这种方法的有效性。最后，我们提出了一种方法，可以在大幅减少完全手动注释过程所需的工作量的同时，实现97％的召回率。 代码和数据可在 https://github.com/ahmeshaf/model_in_coref 找到。

    Annotating cross-document event coreference links is a time-consuming and cognitively demanding task that can compromise annotation quality and efficiency. To address this, we propose a model-in-the-loop annotation approach for event coreference resolution, where a machine learning model suggests likely corefering event pairs only. We evaluate the effectiveness of this approach by first simulating the annotation process and then, using a novel annotator-centric Recall-Annotation effort trade-off metric, we compare the results of various underlying models and datasets. We finally present a method for obtaining 97\% recall while substantially reducing the workload required by a fully manual annotation process. Code and data can be found at https://github.com/ahmeshaf/model_in_coref
    
[^47]: 迈向端到端语音到文本摘要技术

    Towards End-to-end Speech-to-text Summarization. (arXiv:2306.05432v1 [cs.CL])

    [http://arxiv.org/abs/2306.05432](http://arxiv.org/abs/2306.05432)

    该论文提出了一种迈向端到端语音到文本摘要技术的方法，这种技术可以用于过滤和跟踪每天上传在线的广播新闻，并能够产生丰富的潜在表示，但需要进一步的研究来提高其有效性和鲁棒性。

    

    语音到文本（S2T）摘要是一种节省时间的技术，可用于过滤和跟踪每天上传在线的广播新闻。最近深度学习中出现了具有出色文本生成能力的大型语言模型，引起了对产生简洁文档版本的摘要系统的研究重点，也称为抽象摘要。端到端（E2E）建模的S2T抽象摘要是一种有前途的方法，它提供了产生丰富潜在表示的可能性，这些表示利用了非语言和声学信息，而不是仅使用级联系统中自动生成的转录文本的语言信息。然而，文献中关于这项任务的E2E建模很少探索不同的领域，特别是广播新闻是一个具有挑战性的领域，每天向用户呈现大量和多样化的数据。我们采用级联翻译方法和端到端方法建模S2T摘要，并在广播新闻的新数据集上进行了评估。我们的结果显示，E2E方法具有更好的表现潜力，但需要进一步的研究来提高其在不同领域中的有效性和鲁棒性。

    Speech-to-text (S2T) summarization is a time-saving technique for filtering and keeping up with the broadcast news uploaded online on a daily basis. The rise of large language models from deep learning with impressive text generation capabilities has placed the research focus on summarization systems that produce paraphrased compact versions of the document content, also known as abstractive summaries. End-to-end (E2E) modelling of S2T abstractive summarization is a promising approach that offers the possibility of generating rich latent representations that leverage non-verbal and acoustic information, as opposed to the use of only linguistic information from automatically generated transcripts in cascade systems. However, the few literature on E2E modelling of this task fails on exploring different domains, namely broadcast news, which is challenging domain where large and diversified volumes of data are presented to the user every day. We model S2T summarization both with a cascade 
    
[^48]: LexGPT 0.1：基于Pile of Law的预训练GPT-J模型（arXiv:2306.05431v1 [cs.CL]）

    LexGPT 0.1: pre-trained GPT-J models with Pile of Law. (arXiv:2306.05431v1 [cs.CL])

    [http://arxiv.org/abs/2306.05431](http://arxiv.org/abs/2306.05431)

    本研究旨在构建专门用于法律领域的生成语言模型。此发展基前提模型是为了在法律领域开发未来的应用，如通过人类反馈进行强化学习进一步培训。此外，通过“无代码”方法，法律专业人员可以轻松地为下游任务创建定制化的语言模型。虽然性能低于最先进的结果，但本文研究如何在不修改模型或其源代码的情况下改进LexGPT模型的下游任务性能。

    

    本研究旨在构建专门用于法律领域的生成语言模型。本文介绍了基于GPT-J模型并使用Pile of Law进行预训练的LexGPT模型的开发过程。本文所构建的基础模型是未来在法律领域开发应用的初始步骤，例如通过人类反馈进行强化学习的进一步培训。本文的另一个目标是通过“无代码”方法帮助法律专业人员利用语言模型。通过使用专门数据进行精调并且不修改任何源代码，法律专业人员可以轻松地为下游任务创建定制化的语言模型，减少技术知识和投入的最小化。本文中的下游任务是将LexGPT模型转换为分类器，尽管性能明显低于最先进的结果。如何在不修改模型或其源代码的情况下提高下游任务性能是一个研究重点。

    This research aims to build generative language models specialized for the legal domain. The manuscript presents the development of LexGPT models based on GPT-J models and pre-trained with Pile of Law. The foundation model built in this manuscript is the initial step for the development of future applications in the legal domain, such as further training with reinforcement learning from human feedback. Another objective of this manuscript is to assist legal professionals in utilizing language models through the ``No Code'' approach. By fine-tuning models with specialized data and without modifying any source code, legal professionals can create custom language models for downstream tasks with minimum effort and technical knowledge. The downstream task in this manuscript is to turn a LexGPT model into a classifier, although the performance is notably lower than the state-of-the-art result. How to enhance downstream task performance without modifying the model or its source code is a res
    
[^49]: RRWKV：在RWKV中捕捉长距离依赖关系

    RRWKV: Capturing Long-range Dependencies in RWKV. (arXiv:2306.05176v1 [cs.CL])

    [http://arxiv.org/abs/2306.05176](http://arxiv.org/abs/2306.05176)

    本文介绍了一种新的RRWKV架构，它在保持记忆和计算效率的同时，通过加入回顾能力有效地捕捉长距离依赖关系。

    

    由于Transformer惊人的点积注意力，它已经成为各种自然语言处理（NLP）任务中的主要架构。最近，Receptance Weighted Key Value（RWKV）架构遵循非Transformer架构，消除了点积注意力的缺点，其中存储和计算复杂度随着序列长度呈二次扩展。尽管RWKV利用了线性张量积注意机制并通过部署时间序列模式实现了并行计算，但与标准Transformer中直接交互获得的完整信息相比，它无法捕捉长距离依赖关系，因为其受限于向后查看先前信息的能力。因此，本文通过将回顾能力纳入RWKV中来设计Retrospected Receptance Weighted Key Value（RRWKV）架构，以有效地吸收信息，同时保持记忆和计算效率。

    Owing to the impressive dot-product attention, the Transformers have been the dominant architectures in various natural language processing (NLP) tasks. Recently, the Receptance Weighted Key Value (RWKV) architecture follows a non-transformer architecture to eliminate the drawbacks of dot-product attention, where memory and computational complexity exhibits quadratic scaling with sequence length. Although RWKV has exploited a linearly tensor-product attention mechanism and achieved parallelized computations by deploying the time-sequential mode, it fails to capture long-range dependencies because of its limitation on looking back at previous information, compared with full information obtained by direct interactions in the standard transformer. Therefore, the paper devises the Retrospected Receptance Weighted Key Value (RRWKV) architecture via incorporating the retrospecting ability into the RWKV to effectively absorb information, which maintains memory and computational efficiency as 
    
[^50]: 论大型语言模型水印的可靠性

    On the Reliability of Watermarks for Large Language Models. (arXiv:2306.04634v1 [cs.LG])

    [http://arxiv.org/abs/2306.04634](http://arxiv.org/abs/2306.04634)

    本文研究了大型语言模型水印在混合其他文本来源时的可靠性，并提供了在实际应用中的建议。

    

    大型语言模型(LLMs)已经开始应用于日常使用，并有能力在未来的十年内产生大量的文本。机器生成的文本可能会取代互联网上的人类写作文本，并有可能被用于恶意目的，如钓鱼攻击和社交媒体机器人。水印是一种简单有效的策略，通过使LLM生成的文本可检测和可记录，来降低这些伤害。然而，一个关键问题仍然存在：在现实中混合了其他的文本来源，被人类写作者或其他语言模型改写，被用于社交和技术领域的各种应用时，水印在实际设置中的可靠性如何？在本文中，我们探讨了不同的检测方案，量化了它们检测水印的能力，并确定在每个情况下需要观察多少机器生成的文本才能可靠地检测水印。我们特别强调了当水印与其他文本来源混合时水印的可靠性，并提供了未来使用LLM生成的文本水印的建议。

    Large language models (LLMs) are now deployed to everyday use and positioned to produce large quantities of text in the coming decade. Machine-generated text may displace human-written text on the internet and has the potential to be used for malicious purposes, such as spearphishing attacks and social media bots. Watermarking is a simple and effective strategy for mitigating such harms by enabling the detection and documentation of LLM-generated text. Yet, a crucial question remains: How reliable is watermarking in realistic settings in the wild? There, watermarked text might be mixed with other text sources, paraphrased by human writers or other language models, and used for applications in a broad number of domains, both social and technical. In this paper, we explore different detection schemes, quantify their power at detecting watermarks, and determine how much machine-generated text needs to be observed in each scenario to reliably detect the watermark. We especially highlight o
    
[^51]: 面向任务型对话的更准确和可推广的评估指标探索

    Toward More Accurate and Generalizable Evaluation Metrics for Task-Oriented Dialogs. (arXiv:2306.03984v1 [cs.CL])

    [http://arxiv.org/abs/2306.03984](http://arxiv.org/abs/2306.03984)

    本文提出了一种新的对话质量注释工作流程称为DQA，能够更准确和可推广地评估对话质量，尤其是通过一些客观对话属性的判断。

    

    评估交互质量对于改进口语对话系统至关重要。现有的对话质量估计方法要么侧重于评估单个对话轮次的质量，要么从终端用户立即在交互之后收集对话级别的质量测量数据。与这些方法相比，我们引入了一种新的对话级别注释工作流程称为对话质量注释（DQA）。DQA专家注释员评估整个对话的质量，并标记对话的目标完成和用户情感等属性。本文的贡献是，我们展示了：（i）尽管对话质量不能完全分解成对话级别属性，但某些客观对话属性与对话质量的判断之间存在着强关系；（ii）对于对话级别质量估计任务，一个在对话级别注释上训练的监督模型优于仅基于聚合轮次级别特征的方法；以及（iii）使用DQA相比现有方法能够得到更准确和可推广的对话质量评估。

    Measurement of interaction quality is a critical task for the improvement of spoken dialog systems. Existing approaches to dialog quality estimation either focus on evaluating the quality of individual turns, or collect dialog-level quality measurements from end users immediately following an interaction. In contrast to these approaches, we introduce a new dialog-level annotation workflow called Dialog Quality Annotation (DQA). DQA expert annotators evaluate the quality of dialogs as a whole, and also label dialogs for attributes such as goal completion and user sentiment. In this contribution, we show that: (i) while dialog quality cannot be completely decomposed into dialog-level attributes, there is a strong relationship between some objective dialog attributes and judgments of dialog quality; (ii) for the task of dialog-level quality estimation, a supervised model trained on dialog-level annotations outperforms methods based purely on aggregating turn-level features; and (iii) the 
    
[^52]: CELDA: 在没有标签的情况下利用黑匣子语言模型进行增强分类的方法

    CELDA: Leveraging Black-box Language Model as Enhanced Classifier without Labels. (arXiv:2306.02693v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02693](http://arxiv.org/abs/2306.02693)

    本文提出 CELDA 方法，通过提取精细的伪标签数据集并利用聚类增强的判别学习算法进行训练，在没有标签的情况下提高文本分类效果。

    

    利用API公开的现代化语言模型进行文本分类的任务正在受到研究人员的广泛关注。在标签数据稀缺或不可用的情况下，已有的提示方法可以提高分类性能，但其效果仍不如完全监督的分类器，并且在数据微小变化下表现欠佳。本文提出一种新颖的方法，Clustering-enhanced Linear Discriminative Analysis，通过提取精细的伪标签数据集并利用聚类增强的判别学习算法进行训练，实现了在非常弱的监督信号条件下（即标签名）提高文本分类准确性的目的。

    Utilizing language models (LMs) without internal access is becoming an attractive paradigm in the field of NLP as many cutting-edge LMs are released through APIs and boast a massive scale. The de-facto method in this type of black-box scenario is known as prompting, which has shown progressive performance enhancements in situations where data labels are scarce or unavailable. Despite their efficacy, they still fall short in comparison to fully supervised counterparts and are generally brittle to slight modifications. In this paper, we propose Clustering-enhanced Linear Discriminative Analysis, a novel approach that improves the text classification accuracy with a very weak-supervision signal (i.e., name of the labels). Our framework draws a precise decision boundary without accessing weights or gradients of the LM model or data labels. The core ideas of CELDA are twofold: (1) extracting a refined pseudo-labeled dataset from an unlabeled dataset, and (2) training a lightweight and robus
    
[^53]: COBRA框架：有关攻击性陈述影响和危害的情境推理

    COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements. (arXiv:2306.01985v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.01985](http://arxiv.org/abs/2306.01985)

    COBRA框架是第一个上下文感知的形式主义，用于解释攻击性或有偏见陈述的意图、反应和危害，COBRACORPUS数据集包含3.3万个潜在有害陈述和机器上下文及其有害性、隐含偏见、说话意图和听众反应的自由文本解释，研究发现，攻击性陈述可以传达不同的偏见、意图和危害，取决于社交和情境背景，凸显了在有害语言侦测和管理中需要上下文感知的模型。

    

    警告：本文包含可能令人不适或冒犯的内容。理解陈述的危害和冒犯性需要对陈述的社交和情境背景进行推理。例如，"你的英语非常好"这句话在白人对非白色同事说出时可能暗示着侮辱，但在ESL老师对学生说出时则被解释为真诚的赞美。先前的有关有害语言侦测的方法很大程度上忽略了这些情境因素。我们引入了COBRA框架，第一个基于社交和情境背景解释攻击性或有偏见陈述意图，反应和危害的上下文感知形式主义。我们创建了COBRACORPUS，一个包含3.3万个潜在有害陈述和机器生成的上下文及其有害性、隐含偏见、说话意图和听众反应的自由文本解释数据集。为了研究有害语言的情境动态，我们使用COBRA框架分析并比较不同情境下攻击性陈述的危害和解释，包括个人交谈、社交媒体和新闻文章等。我们的研究结果表明，攻击性陈述可以传达不同的偏见、意图和危害，取决于社交和情境背景，凸显了在有害语言侦测和管理中需要上下文感知的模型。

    Warning: This paper contains content that may be offensive or upsetting. Understanding the harms and offensiveness of statements requires reasoning about the social and situational context in which statements are made. For example, the utterance "your English is very good" may implicitly signal an insult when uttered by a white man to a non-white colleague, but uttered by an ESL teacher to their student would be interpreted as a genuine compliment. Such contextual factors have been largely ignored by previous approaches to toxic language detection. We introduce COBRA frames, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions. To study the contextual dynamics of o
    
[^54]: 利用训练数据进行少样本启发式数值推理

    Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning. (arXiv:2305.18170v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18170](http://arxiv.org/abs/2305.18170)

    本文研究了两种方法来在少样本提示场景中利用有更好覆盖率的训练数据：动态规划提示和程序蒸馏。这能够在数学词问题 (MWP) 的解决方案中通过程序执行来验证答案正确性。

    

    大型语言模型的CoT prompting已被证明在许多自然语言处理任务中具有高效性，但在广泛问题类型上设计能够很好概括的提示可能会具有挑战性，特别是在数学词问题 (MWP) 的解决方案中。此外，通常有大量的训练数据具有更好的多样性覆盖率，但缺乏CoT注释，这限制了监督学习技术的使用。为了解决这些问题，我们研究了两种方法，以在少数样本提示场景中利用训练数据：动态规划提示和程序蒸馏。

    Chain-of-thought (CoT) prompting with large language models has proven effective in numerous natural language processing tasks, but designing prompts that generalize well to diverse problem types can be challenging, especially in the context of math word problem (MWP) solving. Additionally, it is common to have a large amount of training data that have a better diversity coverage but CoT annotations are not available, which limits the use of supervised learning techniques. To address these issues, we investigate two approaches to leverage the training data in a few-shot prompting scenario: dynamic program prompting and program distillation. Our approach is largely inspired by Gao et al., (2022), where they proposed to replace the CoT with the programs as the intermediate reasoning step. Such a prompting strategy allows us to accurately verify the answer correctness through program execution in MWP solving. Our dynamic program prompting involves annotating the training data by sampling 
    
[^55]: HiTIN: 针对层次文本分类的分层树同构网络

    HiTIN: Hierarchy-aware Tree Isomorphism Network for Hierarchical Text Classification. (arXiv:2305.15182v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15182](http://arxiv.org/abs/2305.15182)

    本文提出了一种针对层次文本分类的简洁的模型 HiTIN，该模型利用无权树结构的编码树来增强文本表示，不需要先前的统计数据或标签语义，显著降低了内存开销。

    

    层次文本分类是多标签分类中具有挑战性的子任务，因为标签形成了复杂的层次结构。现有的双编码器方法在HTC中取得了弱的性能增益，但具有巨大的内存开销，其结构编码器严重依赖领域知识。在这种情况下，我们倾向于研究一种具有强大泛化能力的内存友好型模型，该模型不需要先前的统计数据或标签语义即可提高HTC的性能。本文提出了一种分层树同构网络（HiTIN），以只使用标签层次结构的句法信息来增强文本表示。具体而言，我们利用结构熵在指导下将标签层次结构转换为一个无权树结构，称为编码树。然后我们设计了一个结构编码器，将编码树中的层次感知信息与文本表示相结合。除文本编码器外，HiTIN仅包含一个特征编码器，显着降低了内存开销。

    Hierarchical text classification (HTC) is a challenging subtask of multi-label classification as the labels form a complex hierarchical structure. Existing dual-encoder methods in HTC achieve weak performance gains with huge memory overheads and their structure encoders heavily rely on domain knowledge. Under such observation, we tend to investigate the feasibility of a memory-friendly model with strong generalization capability that could boost the performance of HTC without prior statistics or label semantics. In this paper, we propose Hierarchy-aware Tree Isomorphism Network (HiTIN) to enhance the text representations with only syntactic information of the label hierarchy. Specifically, we convert the label hierarchy into an unweighted tree structure, termed coding tree, with the guidance of structural entropy. Then we design a structure encoder to incorporate hierarchy-aware information in the coding tree into text representations. Besides the text encoder, HiTIN only contains a fe
    
[^56]: 带有显式跨模态对齐的语音文本对话预训练用于口语对话理解

    Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment. (arXiv:2305.11579v1 [cs.CL])

    [http://arxiv.org/abs/2305.11579](http://arxiv.org/abs/2305.11579)

    本文提出了SPECTRA语音文本对话预训练模型，应用了新的时间位置预测任务来捕捉语音文本对齐，同时将回答选择任务推广到服务于口语对话理解，用于丰富话语表示。

    

    最近，语音文本预训练方法在许多语音和自然语言处理任务中展现出了惊人的成功。然而，大多数先前的预训练模型通常针对一个或两个特定任务进行了定制，但未能征服各种语音文本任务。此外，现有的语音文本预训练方法未能探索对话中的情境信息以丰富话语表示。在本文中，我们提出了具有显式跨模态对齐的语音文本对话预训练模型SPECTRA，这是第一个语音文本对话预训练模型。具体而言，为了考虑语音模态的时间性，我们设计了一项新的时间位置预测任务来捕捉语音文本对齐。这种预训练任务旨在预测相应语音波形中每个文本单词的开始和结束时间。此外，为了学习口语对话的特征，我们将回答选择任务推广到服务于口语对话理解。

    Recently, speech-text pre-training methods have shown remarkable success in many speech and natural language processing tasks. However, most previous pre-trained models are usually tailored for one or two specific tasks, but fail to conquer a wide range of speech-text tasks. In addition, existing speech-text pre-training methods fail to explore the contextual information within a dialogue to enrich utterance representations. In this paper, we propose Speech-text dialog Pre-training for spoken dialog understanding with ExpliCiT cRoss-Modal Alignment (SPECTRA), which is the first-ever speech-text dialog pre-training model. Concretely, to consider the temporality of speech modality, we design a novel temporal position prediction task to capture the speech-text alignment. This pre-training task aims to predict the start and end time of each textual word in the corresponding speech waveform. In addition, to learn the characteristics of spoken dialogs, we generalize a response selection task
    
[^57]: 基于思维链索引的隐式情感推断

    Reasoning Implicit Sentiment with Chain-of-Thought Prompting. (arXiv:2305.11255v1 [cs.CL])

    [http://arxiv.org/abs/2305.11255](http://arxiv.org/abs/2305.11255)

    本研究提出了一种基于思维链索引的隐式情感推断框架（THOR），通过三次跳推理模仿类人推理过程，支持常识和多跳推理以推断意见的潜在意图，并逐步诱导隐式方面、意见和最终情感极性，实现了在监督和零样本设置上大幅提高技术水平。

    

    情感分析系统通过分析输入文本中的关键观点表达来确定给定目标的情感极性，而在隐式情感分析（ISA）中，观点提示以一种隐含和模糊的方式出现。因此，检测隐式情感需要常识和多跳推理能力来推断意见的潜在意图。受最近思维链索引（CoT）思想的启发，本研究介绍了一种三次跳推理（THOR）CoT框架，模仿ISA的类人推理过程。我们为THOR设计了一个三步提示原则，以逐步诱导隐式方面、意见和最终情感极性。我们的THOR+Flan-T5（11B）在监督设置上将技术水平推进了超过6％的F1值。更为显著的是，THOR+GPT3（175B）在零样本设置上将技术水平提升了超过50％的F1值。我们的代码位于https://github.com/scofield7419/THOR-ISA 。

    While sentiment analysis systems try to determine the sentiment polarities of given targets based on the key opinion expressions in input texts, in implicit sentiment analysis (ISA) the opinion cues come in an implicit and obscure manner. Thus detecting implicit sentiment requires the common-sense and multi-hop reasoning ability to infer the latent intent of opinion. Inspired by the recent chain-of-thought (CoT) idea, in this work we introduce a Three-hop Reasoning (THOR) CoT framework to mimic the human-like reasoning process for ISA. We design a three-step prompting principle for THOR to step-by-step induce the implicit aspect, opinion, and finally the sentiment polarity. Our THOR+Flan-T5 (11B) pushes the state-of-the-art (SoTA) by over 6% F1 on supervised setup. More strikingly, THOR+GPT3 (175B) boosts the SoTA by over 50% F1 on zero-shot setting. Our code is at https://github.com/scofield7419/THOR-ISA.
    
[^58]: 如何影响上下文范例在组合通用性中的作用？

    How Do In-Context Examples Affect Compositional Generalization?. (arXiv:2305.04835v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04835](http://arxiv.org/abs/2305.04835)

    本文提出了CoFe测试套件来调查上下文组合泛化。实验结果表明，上下文示例应该在结构上与测试用例类似，相互之间应该不同，而且单独地简单。

    

    组合泛化——理解看不见的已知原始组合——是人类智能中的一个重要推理能力。AI社区主要通过在许多训练样本上微调神经网络来研究这种能力，然而还不清楚上下文学习——基于大型语言模型的主要少样本范式——是否展示组合泛化。在本文中，我们提出了CoFe，一个测试套件来调查上下文组合泛化。我们发现，组合泛化性能很容易受到上下文示例选择的影响，因此提出了研究问题：什么是在组合泛化中制作好的上下文示例的关键因素。我们研究了三个潜在因素：相似性、多样性和复杂性。我们的系统实验表明，在组合通用性中，上下文示例应该在结构上与测试用例类似，相互之间应该不同，而且单独地简单。

    Compositional generalization--understanding unseen combinations of seen primitives--is an essential reasoning capability in human intelligence. The AI community mainly studies this capability by fine-tuning neural networks on lots of training samples, while it is still unclear whether and how in-context learning--the prevailing few-shot paradigm based on large language models--exhibits compositional generalization. In this paper, we present CoFe, a test suite to investigate in-context compositional generalization. We find that the compositional generalization performance can be easily affected by the selection of in-context examples, thus raising the research question what the key factors are to make good in-context examples for compositional generalization. We study three potential factors: similarity, diversity and complexity. Our systematic experiments indicate that in-context examples should be structurally similar to the test case, diverse from each other, and individually simple.
    
[^59]: 基于不确定性感知的Bootstrap学习用于远程监督数据联合抽取

    Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data. (arXiv:2305.03827v1 [cs.CL])

    [http://arxiv.org/abs/2305.03827](http://arxiv.org/abs/2305.03827)

    本文提出了基于不确定性感知的Bootstrap学习用于远程监督数据联合抽取。通过探索数据不确定性和自我集成正则化器，使得模型在早期快速收敛并且缓解了噪声标签产生的模型不确定性，并在两个大型数据集上实验表明该方法在实体对抽取和关系抽取方面的F1得分分别提高了4.43%和4.92%。

    

    在处理带有模糊或噪声标签的远程监督数据时，联合抽取实体对及其关系是具有挑战性的。为了缓解这种影响，我们提出了基于不确定性感知的Bootstrap学习，其动机是根据直觉，一个实例的不确定性越高，模型置信度与真实标签不一致的可能性就越大。具体而言，我们首先探索实例级别的数据不确定性，创建一个高置信的初始样例集。这样的子集用于过滤噪声实例，并有助于模型在早期快速收敛。在Bootstrap学习期间，我们提出自我集成作为正则化器，以减轻噪声标签产生的模型间不确定性。我们进一步定义联合标记概率的概率方差，以估计内部模型参数的不确定性，用于选择和建立新的可靠训练实例进行下一次迭代。两个大型数据集的实验结果表明，我们的方法明显优于最先进的基准方法，在实体对抽取和关系抽取方面的F1得分分别提高了4.43%和4.92%。

    Jointly extracting entity pairs and their relations is challenging when working on distantly-supervised data with ambiguous or noisy labels. To mitigate such impact, we propose uncertainty-aware bootstrap learning, which is motivated by the intuition that the higher uncertainty of an instance, the more likely the model confidence is inconsistent with the ground truths. Specifically, we first explore instance-level data uncertainty to create an initial high-confident examples. Such subset serves as filtering noisy instances and facilitating the model to converge fast at the early stage. During bootstrap learning, we propose self-ensembling as a regularizer to alleviate inter-model uncertainty produced by noisy labels. We further define probability variance of joint tagging probabilities to estimate inner-model parametric uncertainty, which is used to select and build up new reliable training instances for the next iteration. Experimental results on two large datasets reveal that our app
    
[^60]: 如何发挥大语言模型在少样本关系抽取中的能力？

    How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])

    [http://arxiv.org/abs/2305.01555](http://arxiv.org/abs/2305.01555)

    本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。

    

    语言模型的扩展已经彻底改变了广泛的自然语言处理任务，但是使用大型语言模型进行少样本关系抽取还没有得到全面探索。本文通过详细实验，研究了使用GPT-3.5进行少样本关系抽取的基本方法——上下文学习和数据生成。为了增强少样本性能，我们进一步提出了与任务相关的指导说明和约束模式下的数据生成。我们观察到，在上下文学习的情况下，可以实现与以前的提示学习方法相当的性能，而使用大型语言模型的数据生成可以推动以前的解决方案以在四个广泛研究的关系抽取数据集上获得新的最先进的少样本结果。我们希望我们的工作可以激发未来对大型语言模型在少样本关系抽取中的能力的研究。代码可以在 \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm} 中找到。

    Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction. Code is available in \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^61]: 多方聊天：人类和模型中的群聊对话代理

    Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models. (arXiv:2304.13835v1 [cs.CL])

    [http://arxiv.org/abs/2304.13835](http://arxiv.org/abs/2304.13835)

    本文通过收集和评估多方对话情况，探讨了模型在群体对话中需要具备的技能，发现新数据集MultiLIGHT可以在这个领域带来显着的进展。

    

    当前的对话研究主要研究成对（双方）对话，并没有涉及到多于两个人在一起对话的日常情景。本文使用LIGHT环境构建接地对话来收集和评估多方对话情况。我们对比在新数据集MultiLIGHT上训练的模型和现有的成对训练的对话模型以及带有少量提示的大型语言模型。我们发现，我们将公开发布MultiLIGHT数据集，这将有助于在群体设置中带来显着的改进。

    Current dialogue research primarily studies pairwise (two-party) conversations, and does not address the everyday setting where more than two speakers converse together. In this work, we both collect and evaluate multi-party conversations to study this more general case. We use the LIGHT environment to construct grounded conversations, where each participant has an assigned character to role-play. We thus evaluate the ability of language models to act as one or more characters in such conversations. Models require two skills that pairwise-trained models appear to lack: (1) being able to decide when to talk; (2) producing coherent utterances grounded on multiple characters. We compare models trained on our new dataset to existing pairwise-trained dialogue models, as well as large language models with few-shot prompting. We find that our new dataset, MultiLIGHT, which we will publicly release, can help bring significant improvements in the group setting.
    
[^62]: AUTODIAL: 高效异步任务导向的对话模型

    AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model. (arXiv:2303.06245v1 [cs.CL])

    [http://arxiv.org/abs/2303.06245](http://arxiv.org/abs/2303.06245)

    AUTODIAL是一种多任务对话模型，通过使用并行解码器来执行对话任务，从而显著减少内存占用并实现更快的推理时间。与现有的生成方法相比，AUTODIAL在三个对话任务上提供了3-6倍的速度提升，同时具有11倍的参数减少。这表明将当前的对话模型扩展为具有并行解码器可以成为在资源受限环境中部署它们的可行替代方案。

    AUTODIAL is a multi-task dialogue model that significantly reduces memory footprint and achieves faster inference times by using parallel decoders to perform dialogue tasks. Compared to existing generative approach, AUTODIAL provides 3-6x speedups during inference while having 11x fewer parameters on three dialogue tasks. This suggests that extending current dialogue models to have parallel decoders can be a viable alternative for deploying them in resource-constrained environments.

    随着大型对话模型在实践中变得普遍，训练、推理和更大的内存占用的高计算要求问题仍然存在。在这项工作中，我们提出了AUTODIAL，一种多任务对话模型，解决了部署对话模型的挑战。AUTODIAL利用并行解码器执行诸如对话行为预测、领域预测、意图预测和对话状态跟踪等任务。使用分类解码器而不是生成解码器使AUTODIAL能够显著减少内存占用，并在推理时间上实现比现有生成方法（即SimpleTOD）更快的速度。我们证明，将当前的对话模型扩展为具有并行解码器可以成为在资源受限环境中部署它们的可行替代方案。

    As large dialogue models become commonplace in practice, the problems surrounding high compute requirements for training, inference and larger memory footprint still persists. In this work, we present AUTODIAL, a multi-task dialogue model that addresses the challenges of deploying dialogue model. AUTODIAL utilizes parallel decoders to perform tasks such as dialogue act prediction, domain prediction, intent prediction, and dialogue state tracking. Using classification decoders over generative decoders allows AUTODIAL to significantly reduce memory footprint and achieve faster inference times compared to existing generative approach namely SimpleTOD. We demonstrate that AUTODIAL provides 3-6x speedups during inference while having 11x fewer parameters on three dialogue tasks compared to SimpleTOD. Our results show that extending current dialogue models to have parallel decoders can be a viable alternative for deploying them in resource-constrained environments.
    
[^63]: 通过语言实现视觉抽象和推理技术

    Visual Abstraction and Reasoning through Language. (arXiv:2303.04091v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.04091](http://arxiv.org/abs/2303.04091)

    本论文提出了一种通过自然语言描述任务的通用框架来解决Abstraction and Reasoning Corpus（ARC）问题，虽然还没有在ARC上击败最先进的DSL模型，但我们展示了我们的方法具有巨大的潜力，可以解决先前未解决的任务。

    

    尽管人工智能（AI）模型在局限应用中已经达到了人类甚至超越人类的性能，但它们仍然难以展现更广泛和更灵活的智能。Abstraction and Reasoning Corpus（ARC）旨在评估AI系统与人类类似的认知能力。目前大多数方法依赖于精心设计的特定领域语言（DSL），用于暴力解决ARC中的任务。在这项工作中，我们提出了一个基于任务自然语言描述的通用框架来解决ARC问题。虽然还没有在ARC上击败最先进的DSL模型，但我们展示了我们的方法具有巨大的潜力，可以解决先前未解决的任务。

    While Artificial Intelligence (AI) models have achieved human or even superhuman performance in narrowly defined applications, they still struggle to show signs of broader and more flexible intelligence. The Abstraction and Reasoning Corpus (ARC), introduced by Fran\c{c}ois Chollet, aims to assess how close AI systems are to human-like cognitive abilities. Most current approaches rely on carefully handcrafted domain-specific languages (DSLs), which are used to brute-force solutions to the tasks present in ARC. In this work, we propose a general framework for solving ARC based on natural language descriptions of the tasks. While not yet beating state-of-the-art DSL models on ARC, we demonstrate the immense potential of our approach hinted at by the ability to solve previously unsolved tasks.
    
[^64]: 使用参数高效的迁移学习评估语言模型的超分布鲁棒性

    Probing Out-of-Distribution Robustness of Language Models with Parameter-Efficient Transfer Learning. (arXiv:2301.11660v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11660](http://arxiv.org/abs/2301.11660)

    本文评估了各种参数高效的迁移学习方法对不同规模的语言模型在三个不同的意图分类任务中检测超分布（OOD）的能力，旨在为语言模型的超分布鲁棒性提供参考。

    

    随着预训练语言模型（PLM）的规模不断增加，最近提出了许多参数高效的迁移学习方法，以弥补微调成本的巨大代价。尽管大型预训练语言模型（PLMs）和各种参数高效的迁移学习（PETL）方法在各种基准测试中取得了令人印象深刻的结果，但它们是否能有效地处理已分布改变的输入仍不清楚。在本研究中，我们系统地探讨了随着PLM大小增长或改变传输方法，检测超分布（OOD）的能力如何改变。具体而言，我们评估了各种PETL技术，包括微调、Adapter、LoRA和前缀调整，在三个不同的意图分类任务上进行了评估，每个任务都使用不同规模的语言模型。

    As the size of the pre-trained language model (PLM) continues to increase, numerous parameter-efficient transfer learning methods have been proposed recently to compensate for the tremendous cost of fine-tuning. Despite the impressive results achieved by large pre-trained language models (PLMs) and various parameter-efficient transfer learning (PETL) methods on sundry benchmarks, it remains unclear if they can handle inputs that have been distributionally shifted effectively. In this study, we systematically explore how the ability to detect out-of-distribution (OOD) changes as the size of the PLM grows or the transfer methods are altered. Specifically, we evaluated various PETL techniques, including fine-tuning, Adapter, LoRA, and prefix-tuning, on three different intention classification tasks, each utilizing various language models with different scales.
    
[^65]: 隐私保护的语义解析器领域自适应研究

    Privacy-Preserving Domain Adaptation of Semantic Parsers. (arXiv:2212.10520v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10520](http://arxiv.org/abs/2212.10520)

    本文提出了一个隐私保护的语义解析器领域自适应的方法，通过合成真实用户语句来帮助增加系统的语言和功能覆盖范围，同时不会危及实际用户的隐私。

    

    任务导向的对话系统通常辅助用户处理个人或机密事务。因此，此类系统的开发人员通常被禁止观察实际使用情况。那么，他们如何知道系统在哪些方面存在失败并需要更多的训练数据或新功能呢？在这项工作中，我们研究了如何合成真实用户语句来帮助增加系统的语言和功能覆盖范围，同时不会危及实际用户的隐私。为此，我们提出了一种两阶段差分隐私生成方法，首先生成潜在的语义解析，然后根据解析生成语句。我们的方法在私有合成数据生成方面相对于当前方法提高了MAUVE 2.5倍和语义覆盖1.3倍，提高了流畅性和语义覆盖度。我们进一步在一个实际的领域适应任务中验证了我们的方法，即添加新功能。

    Task-oriented dialogue systems often assist users with personal or confidential matters. For this reason, the developers of such a system are generally prohibited from observing actual usage. So how can they know where the system is failing and needs more training data or new functionality? In this work, we study ways in which realistic user utterances can be generated synthetically, to help increase the linguistic and functional coverage of the system, without compromising the privacy of actual users. To this end, we propose a two-stage Differentially Private (DP) generation method which first generates latent semantic parses, and then generates utterances based on the parses. Our proposed approach improves MAUVE by 2.5X and parse tree function type overlap by 1.3X relative to current approaches for private synthetic data generation, improving both on fluency and semantic coverage. We further validate our approach on a realistic domain adaptation task of adding new functionality from 
    
[^66]: Socratic预训练：面向可控摘要的问题驱动预训练

    Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization. (arXiv:2212.10449v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10449](http://arxiv.org/abs/2212.10449)

    本论文介绍了一种面向问题驱动的无监督预训练方法，名为Socratic预训练，用于提高摘要任务的可控性，并演示了该方法通过在多个控制策略上进行广泛实验得出的优于其他方法的结果。

    

    在标注数据稀缺的情况下，对于长篇文档的可控摘要，预训练模型很难适应任务并有效地响应用户查询。在本文中，我们介绍了Socratic预训练，一种面向问题驱动的无监督预训练方法，旨在提高摘要任务的可控性。通过训练模型生成和回答给定上下文中的相关问题，Socratic预训练使模型能够更有效地遵循用户提供的查询，并确定需要摘要的相关内容。我们通过在两个摘要域上进行广泛实验，即短篇故事和对话，并使用关键词、问题和事实QA对多个控制策略进行了演示。我们的预训练方法只依赖于无标注文档和问题生成系统，表现优于使用额外的监督数据的预精调方法。此外，我们的结果表明，Socratic预训练可以显著提高模型生成遵守用户指定约束条件的摘要的能力。

    In long document controllable summarization, where labeled data is scarce, pretrained models struggle to adapt to the task and effectively respond to user queries. In this paper, we introduce Socratic pretraining, a question-driven, unsupervised pretraining objective specifically designed to improve controllability in summarization tasks. By training a model to generate and answer relevant questions in a given context, Socratic pretraining enables the model to more effectively adhere to user-provided queries and identify relevant content to be summarized. We demonstrate the effectiveness of this approach through extensive experimentation on two summarization domains, short stories and dialogue, and multiple control strategies: keywords, questions, and factoid QA pairs. Our pretraining method relies only on unlabeled documents and a question generation system and outperforms pre-finetuning approaches that use additional supervised data. Furthermore, our results show that Socratic pretra
    
[^67]: 无监督间断性组块句法分析及其与轻度上下文有关的语法

    Unsupervised Discontinuous Constituency Parsing with Mildly Context-Sensitive Grammars. (arXiv:2212.09140v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09140](http://arxiv.org/abs/2212.09140)

    本文研究了使用轻度上下文敏感语法进行无监督间断性组块句法分析的语法归纳。在保证规则结构的前提下，我们用最大似然方法进行参数学习，实验证明该方法对大量非终结符具有扩展灵活性。

    

    本文研究了使用轻度上下文敏感语法进行无监督间断性组块句法分析的语法归纳。我们使用概率线性上下文无关重写系统 (LCFRS) 形式，在保证规则结构的前提下，重点关注最大似然的参数学习。为了降低解析和参数估计的计算复杂度，我们将语法形式限制为 LCFRS-2 (即，具有两个扇出的二元 LCFRS) 并且丢弃需要 O(n^6) 的解析时间的规则，将推理降低到 O(n^5)。我们发现使用大量非终结符是有益的，因此利用基于张量分解的秩空间动态规划和基于嵌入的规则概率参数化来扩大非终结符的数量。对德语和荷兰语的实验证明，我们的方法能够诱导出具有连续和不连续结构的语言学意义的树状结果。

    We study grammar induction with mildly context-sensitive grammars for unsupervised discontinuous parsing. Using the probabilistic linear context-free rewriting system (LCFRS) formalism, our approach fixes the rule structure in advance and focuses on parameter learning with maximum likelihood. To reduce the computational complexity of both parsing and parameter estimation, we restrict the grammar formalism to LCFRS-2 (i.e., binary LCFRS with fan-out two) and further discard rules that require O(n^6) time to parse, reducing inference to O(n^5). We find that using a large number of nonterminals is beneficial and thus make use of tensor decomposition-based rank-space dynamic programming with an embedding-based parameterization of rule probabilities to scale up the number of nonterminals. Experiments on German and Dutch show that our approach is able to induce linguistically meaningful trees with continuous and discontinuous structures
    
[^68]: 基于算术的预训练——提高预训练语言模型的数字能力

    Arithmetic-Based Pretraining -- Improving Numeracy of Pretrained Language Models. (arXiv:2205.06733v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.06733](http://arxiv.org/abs/2205.06733)

    本论文提出了一种新的扩展预训练方法——基于算术的预训练，它可以同时解决数字表达能力和数值能力不足的问题，而不需要进行架构变化或重新预训练。实验结果表明，基于算术的预训练在三个不同的任务中都非常有效。

    

    目前最先进的预训练语言模型在需要理解和使用数字的任务上表现不佳。最近的研究表明，这主要有两个原因：(1)常用的分词算法对数字的表达能力有限，(2)常见的预训练目标不针对数值能力。解决这些缺点的方法通常需要架构变化或重新预训练。本文提出了一种新的扩展预训练方法，称为基于算术的预训练，它可以在一个扩展的预训练步骤中同时解决这两个缺点，而不需要架构变化或重新预训练。基于算术的预训练将对比学习与新的可推断数预测任务的预训练目标相结合，以改进数字能力。实验结果表明，基于算术的预训练在三个不同的任务中都非常有效。

    State-of-the-art pretrained language models tend to perform below their capabilities when applied out-of-the-box on tasks that require understanding and working with numbers. Recent work suggests two main reasons for this: (1) popular tokenisation algorithms have limited expressiveness for numbers, and (2) common pretraining objectives do not target numeracy. Approaches that address these shortcomings usually require architectural changes or pretraining from scratch. In this paper, we propose a new extended pretraining approach called Arithmetic-Based Pretraining that jointly addresses both in one extended pretraining step without requiring architectural changes or pretraining from scratch. Arithmetic-Based Pretraining combines contrastive learning to improve the number representation, and a novel extended pretraining objective called Inferable Number Prediction Task to improve numeracy. Our experiments show the effectiveness of Arithmetic-Based Pretraining in three different tasks tha
    
[^69]: 更深入地探究跨语言视觉问答

    Delving Deeper into Cross-lingual Visual Question Answering. (arXiv:2202.07630v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.07630](http://arxiv.org/abs/2202.07630)

    本文探究了跨语言VQA的几个方面，包括建模方法和学习偏差，发现简单修改可以减少到单语英语性能的差距，从而提高准确度。

    

    视觉问答（VQA）是关键的视觉与语言任务之一。然而，现有的VQA研究主要集中在英语上，因缺乏合适的评估资源。先前的跨语言VQA研究报道了当前多语言多模态Transformer的零样本转移性能差，与单语性能存在较大差距，但没有进行深入的分析。在本文中，我们更深入地探究了跨语言VQA的不同方面，旨在了解1）建模方法和选择，包括体系结构、归纳偏见和微调；2）学习偏差：包括跨语言设置中的问题类型和模态偏差。我们分析的主要结果是：1）我们显示出标准训练设置的简单修改可以大大减少转移到单语英语性能的差距，从现有方法中获得+10的准确度；2）我们分析了不同问题类型的跨语言VQA。

    Visual question answering (VQA) is one of the crucial vision-and-language tasks. Yet, existing VQA research has mostly focused on the English language, due to a lack of suitable evaluation resources. Previous work on cross-lingual VQA has reported poor zero-shot transfer performance of current multilingual multimodal Transformers with large gaps to monolingual performance, without any deeper analysis. In this work, we delve deeper into the different aspects of cross-lingual VQA, aiming to understand the impact of 1) modeling methods and choices, including architecture, inductive bias, fine-tuning; 2) learning biases: including question types and modality biases in cross-lingual setups. The key results of our analysis are: 1) We show that simple modifications to the standard training setup can substantially reduce the transfer gap to monolingual English performance, yielding +10 accuracy points over existing methods. 2) We analyze cross-lingual VQA across different question types of var
    
[^70]: 机器符号学

    Machine Semiotics. (arXiv:2008.10522v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2008.10522](http://arxiv.org/abs/2008.10522)

    本文提出机器符号学的思想，即机器不需要理解话语的传统意义，而是能够以格里斯语用学的方式绘制会话蕴涵说明。这个过程可以形式化为话语-意义对（UMP）的强化学习。

    

    认识到人类和机器符号学的基本差异为克服当前语音辅助设备的缺点提供了可能。对于机器而言，（人类）话语的意义由其自身的行动范围定义。因此，机器不需要理解话语的传统意义。相反，它们以（新）格里斯语用学的意义绘制会话蕴涵说明。对于语音辅助设备而言，学习人类话语的机器特定含义，即通过词汇化的尝试和误差将会话蕴涵说明变成传统化的含义，似乎已经足够了。通过一个相当琐碎的认知加热设备的例子，我们展示了，基于动态语义学，这个过程可以形式化为话语-意义对（UMP）的强化学习。

    Recognizing a basic difference between the semiotics of humans and machines presents a possibility to overcome the shortcomings of current speech assistive devices. For the machine, the meaning of a (human) utterance is defined by its own scope of actions. Machines, thus, do not need to understand the conventional meaning of an utterance. Rather, they draw conversational implicatures in the sense of (neo-)Gricean pragmatics. For speech assistive devices, the learning of machine-specific meanings of human utterances, i.e. the fossilization of conversational implicatures into conventionalized ones by trial and error through lexicalization appears to be sufficient. Using the quite trivial example of a cognitive heating device, we show that - based on dynamic semantics - this process can be formalized as the reinforcement learning of utterance-meaning pairs (UMP).
    

