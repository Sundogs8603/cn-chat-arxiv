# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ViMQ: A Vietnamese Medical Question Dataset for Healthcare Dialogue System Development.](http://arxiv.org/abs/2304.14405) | 该论文介绍了一个医学问题数据集ViMQ，该数据集涵盖了越南患者的医学问题，并提供了意图分类和命名实体识别任务的标签集，有助于促进医疗聊天机器人的发展。 |
| [^2] | [LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions.](http://arxiv.org/abs/2304.14402) | 本文提出的LaMini-LM是一种基于大规模指令的多样性压缩模型群集，从指令微调过的LLMs中提取知识到更小的模型中，其在15个不同的NLP基准测试中与其他竞争基线的表现相当，但体积约小了10倍。 |
| [^3] | [We're Afraid Language Models Aren't Modeling Ambiguity.](http://arxiv.org/abs/2304.14399) | 本研究旨在探讨语言模型处理歧义的问题。我们通过AmbiEnt基准数据集设计了一系列测试来评估GPT-4和其他预训练语言模型对歧义的识别和分离能力。结果表明，这是一个极具挑战性的任务，目前的语言模型还无法准确处理歧义。 |
| [^4] | [Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement.](http://arxiv.org/abs/2304.14391) | 本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。 |
| [^5] | [CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants.](http://arxiv.org/abs/2304.14364) | 本文提出了一种名为CONSCENDI的蒸馏方法，用于构建防护栏模型，以监控任务型虚拟助手的输出。关键方法包括场景增强生成和对比训练样例。这种方法产生了一组多样化的违反规则的对话训练集，并且可以更好地检测代理的输出是否符合设计者指定的规则。 |
| [^6] | [Industrial Engineering with Large Language Models: A case study of ChatGPT's performance on Oil & Gas problems.](http://arxiv.org/abs/2304.14354) | 大型语言模型在工业工程中的应用领域初现，本文研究了ChatGPT在油气问题中的表现，并确定LLM最有效的领域。 |
| [^7] | [The Dark Side of ChatGPT: Legal and Ethical Challenges from Stochastic Parrots and Hallucination.](http://arxiv.org/abs/2304.14347) | ChatGPT带来的大语言模型(LLMs)虽然有很多优势，但是随机鹦鹉和幻觉等新的法律和伦理风险也随之而来。欧洲AI监管范式需要进一步发展以减轻这些风险。 |
| [^8] | [MarsEclipse at SemEval-2023 Task 3: Multi-Lingual and Multi-Label Framing Detection with Contrastive Learning.](http://arxiv.org/abs/2304.14339) | 本文描述了一种在多语言设置下使用多标签对比损失来微调大型预训练语言模型的方法，取得了在五种语言上最好的结果。 |
| [^9] | [Idioms, Probing and Dangerous Things: Towards Structural Probing for Idiomaticity in Vector Space.](http://arxiv.org/abs/2304.14333) | 本文利用结构探测方法研究了成语在静态和上下文嵌入中的编码情况，并发现仍未确定成语性是否在向量范数中编码，提出了改进数据集以进行探测分析的方向。 |
| [^10] | [q2d: Turning Questions into Dialogs to Teach Models How to Search.](http://arxiv.org/abs/2304.14318) | 本文提出了q2d方法，通过自动生成含有查询的对话来教导模型如何发出搜索查询。实验表明，该方法的模型性能接近使用人类标注数据训练的模型，而且具有更好的控制和扩展性。 |
| [^11] | [Large Language Models Are State-of-the-Art Evaluators of Code Generation.](http://arxiv.org/abs/2304.14317) | 本文提出了一个基于 GPT-3.5 的评估框架，解决了现有方法在代码生成任务上的局限性，取得了更好的相关性。 |
| [^12] | [Controlled Text Generation with Natural Language Instructions.](http://arxiv.org/abs/2304.14293) | InstructCTG是一个可以通过自然语言描述和演示来控制文本生成并满足不同约束条件的框架，它有效地解决了现有搜索或得分方法所存在的问题。 |
| [^13] | [Semantic Frame Induction with Deep Metric Learning.](http://arxiv.org/abs/2304.14286) | 本文提出了一种深度度量学习的模型，通过对上下文嵌入模型进行微调，并应用于语义框架感知，实现语义框架感知，并在FrameNet上的实验表明效果优于其他最先进的方法。 |
| [^14] | [AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays.](http://arxiv.org/abs/2304.14276) | ChatGPT生成的文章质量比人类写作的文章更高，写作风格更流畅，语法和拼写错误更少。 |
| [^15] | [What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models through User-Provided Names in CAD Files.](http://arxiv.org/abs/2304.14275) | 本文提出，计算机辅助设计（CAD）软件中的自然语言名称是部件关联的宝贵来源，大型语言模型（LLM）提供了一种处理这种数据的有用的领域专业知识。通过自然语言名称的预训练模型可在三个自监督任务上表现出色，微调还可以提高所有任务的性能，提高了文本数据的价值。此外，提出了手动注释的新数据集 CAD-120，其中包含 120 个装配，并提供了语义关系注释。 |
| [^16] | [Entity-Level Sentiment Analysis (ELSA): An exploratory task survey.](http://arxiv.org/abs/2304.14241) | 本文探索了实体级情感分析（ELSA）的任务，即识别文档中自愿实体（人和组织）所表达总体情绪的能力。虽然对于像推文这样的较短文本识别对实体表达情感已经有了较多研究，但我们发现对于在文本中多次提及同一实体的较长文本，几乎没有相关研究。作者注释了一组专业评论以评估现有任务和模型是否可以推导出ELSA，结果表明没有单一代理任务能够以令人满意的表现提供这种我们寻求的对实体的总体情感。 |
| [^17] | [The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who.](http://arxiv.org/abs/2304.14238) | 本文分析了100篇高被引论文，发现自动化事实核查工具的使用往往缺乏充分讨论。文章提出缺乏充分讨论的现象鼓励了过度宣传，限制了批评并阻止了利益相关者的反馈。作者提出了关于事实核查工具使用的几项建议。 |
| [^18] | [Large Language Models are Strong Zero-Shot Retriever.](http://arxiv.org/abs/2304.14233) | 本文提出了一种在零-shot场景下利用大型语言模型（LLM）进行大规模检索的方法。该方法通过使用查询和查询的候选答案的组合作为提示，使LLM生成更精确的答案。由于自监督检索器在零-shot场景中性能较差，因此LameR优于自监督检索器。 |
| [^19] | [A Modular Approach for Multilingual Timex Detection and Normalization using Deep Learning and Grammar-based methods.](http://arxiv.org/abs/2304.14221) | 本文介绍了一个模块化的多语言时间处理系统，该系统结合了基于深度学习的检测方法和基于文法的规范化方法，能够有效地进行时态表达式检测和规范化，并在金标准 timex 规范化、timex 检测和类型识别方面取得了最佳结果。 |
| [^20] | [UIO at SemEval-2023 Task 12: Multilingual fine-tuning for sentiment classification in low-resource languages.](http://arxiv.org/abs/2304.14189) | 本文介绍了通过使用多语言大语言模型进行非洲低资源语言情感分类的方法，并发现在提供的数据集中，使用单语微调的方法可以达到最佳结果。 |
| [^21] | [NAP at SemEval-2023 Task 3: Is Less Really More? (Back-)Translation as Data Augmentation Strategies for Detecting Persuasion Techniques.](http://arxiv.org/abs/2304.14179) | 本文旨在探讨用少量数据在多语言环境下检测说服技巧的挑战，提出利用（回）翻译作为数据增强的策略，并证实平衡人工和机器生成数据的重要性。 |
| [^22] | [mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality.](http://arxiv.org/abs/2304.14178) | 本文介绍了一种名为mPLUG-Owl的训练范式，它通过模块化学习基础LLM、视觉知识模块和视觉抽象器模块，赋予LLMs多模态的能力。实验结果表明，mPLUG-Owl在图像字幕和视觉问答任务中表现优于基线模型，并在某些情况下达到了最先进的性能水平。 |
| [^23] | [ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task.](http://arxiv.org/abs/2304.14177) | 本研究比较了ChatGPT和现有模型在关键短语生成任务上的性能，并发现ChatGPT在所有测试数据集和环境中的表现均优于现有模型，适用于不同领域和文档长度的关键短语生成。 |
| [^24] | [DataComp: In search of the next generation of multimodal datasets.](http://arxiv.org/abs/2304.14108) | DataComp是一个基准测试，旨在通过提出新的训练集来解决数据集在机器学习生态系统中的缺陷。它提供了一个多规模设计的实验测试平台，使用12.8B个图像-文本对的新候选池，让研究人员可以通过设计新的过滤技术或策划新的数据源并评估它们的新数据集来进行创新。 |
| [^25] | [ChatLog: Recording and Analyzing ChatGPT Across Time.](http://arxiv.org/abs/2304.14106) | ChatLog是一个分析ChatGPT随时间变化的数据集，通过提取ChatGPT知识和语言特征发现了一些稳定的特征，提高了RoBERTa-based detector在新版本ChatGPT上的鲁棒性。 |
| [^26] | [Learning Human-Human Interactions in Images from Weak Textual Supervision.](http://arxiv.org/abs/2304.14104) | 本文提出了一种新的范式，从单一的静态图像中学习自由文本的形式来灵活建模人际互动。并通过知识蒸馏生成伪标签来训练一种字幕模型，用于有效理解图像中的人际互动，具有较高的预测文本和语义质量，并在此任务上优于SOTA的图像字幕和情境识别模型。 |
| [^27] | [Origin Tracing and Detecting of LLMs.](http://arxiv.org/abs/2304.14072) | 本文提出了一种有效的方法来跟踪和检测语言模型（LLMs）生成的AI文本，使其来源可以被容易追踪。这种方法可以在各种LLMs上广泛推广，且仅需要有限的数据量。 |
| [^28] | [SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish.](http://arxiv.org/abs/2304.13994) | SweCTRL-Mini是一种基于Transformer的大型瑞典语言模型，用户可以控制它生成的文本流派，完全开放下载。生成能力比较GPT-3。 |
| [^29] | [Cross-Domain Evaluation of POS Taggers: From Wall Street Journal to Fandom Wiki.](http://arxiv.org/abs/2304.13989) | 该论文通过创建适度的数据集，使用'Elder Scrolls Fandom'的数据评估了两个在华尔街日报数据集上训练的词性标注器在领域外的表现，并显示它们的表现几乎与领域内相当，但在未知区域表现不佳。两个标注器都难以处理专有名词和不一致的大写形式。 |
| [^30] | [Learning and Reasoning Multifaceted and Longitudinal Data for Poverty Estimates and Livelihood Capabilities of Lagged Regions in Rural India.](http://arxiv.org/abs/2304.13958) | 该项目旨在综合多种数据源评估1990-2022年印度农村的贫困情况，包括常规的家庭调查、人口普查以及来自卫星图像和通信网络的代理变量。通过将县区划分为不同的区域，确定落后地区并深入研究其导致贫穷的因素。 |
| [^31] | [Retrieval-based Knowledge Augmented Vision Language Pre-training.](http://arxiv.org/abs/2304.13923) | 本文提出了一种基于检索的知识增强视觉语言预训练模型，将从知识图谱中检索到的世界知识融入视觉语言预训练中，将明确的知识与视觉语言对融合，通过四个知识感知的自监督任务推动多模态数据和知识的相互整合。 |
| [^32] | [Controllable Data Augmentation for Context-Dependent Text-to-SQL.](http://arxiv.org/abs/2304.13902) | 提出了ConDA方法，可以生成交互式问题和相应的SQL结果，并设计了SQL对话状态和过滤方法来增强数据多样性和质量，能够提高复杂问题的性能。 |
| [^33] | [Neural Keyphrase Generation: Analysis and Evaluation.](http://arxiv.org/abs/2304.13883) | 本文分析了三种神经网络模型（T5、CatSeq-Transformer、ExHiRD）在关键词生成任务中的性能和行为，并提出了一个新的评估框架SoftKeyScore来衡量两组关键词的相似度。 |
| [^34] | [MasonNLP+ at SemEval-2023 Task 8: Extracting Medical Questions, Experiences and Claims from Social Media using Knowledge-Augmented Pre-trained Language Models.](http://arxiv.org/abs/2304.13875) | 本研究提出了一种知识增强的预训练语言模型MasonNLP+，能够从社交媒体中提取医疗问题、经验和声明，并在SemEval-2023任务8的两个子任务中取得了最先进的性能。 |
| [^35] | [Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks.](http://arxiv.org/abs/2304.13861) | 本文使用GPT-4和ChatGPT对低资源分类任务进行数据增强，通过简单的提示将小型标记数据集扩充为合成数据集，在保留原始标签分布或平衡分布的情况下，产生了良好的下游性能。在测试集上，GPT-4和ChatGPT表现出出色的零-shot性能，尤其在低资源设置中能够较好地识别罕见类别。 |
| [^36] | [Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3.](http://arxiv.org/abs/2304.13846) | 该论文提出了一种通过利用GPT-3语言模型从科学文献中自动化地提取金纳米棒合成信息的方法。这种方法可以实现高通量的探索金纳米棒的种子介导生长过程以及结果。 |
| [^37] | [Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models.](http://arxiv.org/abs/2304.13835) | 本文通过收集和评估多方对话情况，探讨了模型在群体对话中需要具备的技能，发现新数据集MultiLIGHT可以在这个领域带来显着的进展。 |
| [^38] | [Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models.](http://arxiv.org/abs/2304.13803) | 本研究提出了一个使用预训练语言模型的零射多语言词义消歧方法，该方法在无需额外训练或微调的情况下，在XL-WSD数据集的18种语言上实现了超越完全监督基线的召回率。 |
| [^39] | [Fine Tuning with Abnormal Examples.](http://arxiv.org/abs/2304.13783) | 通过识别出数据集中的异常例子，我们提出了一种系统修剪数据集的方法，这可以使得以这些数据集子集作为训练集微调模型的性能更优。 |
| [^40] | [The Internal State of an LLM Knows When its Lying.](http://arxiv.org/abs/2304.13734) | 该论文研究了LLM生成不准确或虚假信息的问题，提出了一种简单而有效的方法，利用LLM的隐藏层激活来确定语句的真实性。在实验中，该方法表现出较好的检测效果，并有利于提高LLM的可信度。 |
| [^41] | [Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model.](http://arxiv.org/abs/2304.13731) | 本研究提出了一种使用指令调整的LLM Flan-T5作为文本编码器和基于潜在扩散模型(LDM)的方法TANGO生成文本到音频(TTA)的新方法，在AudioCaps测试集上表现优于先进的AudioLDM。 |
| [^42] | [Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.](http://arxiv.org/abs/2304.13712) | 本文提供了一个LLMs的使用综述，探讨了在各种自然语言处理任务中的使用和限制。 |
| [^43] | [From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping.](http://arxiv.org/abs/2304.13273) | 本研究提出了一种从关联到生成的零-shot方法：通过将图像/视频投影到语言模态并在生成任务中生成描述性字幕。该方法在多个基准数据集上显著优于现有的最先进方法，为无监督跨模态映射提供了一个新的视角，并具有在视频字幕，图像合成和文本到图像生成等领域的潜在应用。 |
| [^44] | [Extreme Classification for Answer Type Prediction in Question Answering.](http://arxiv.org/abs/2304.12395) | 本文提出了使用Transformer模型（XBERT）进行极端多标签分类，通过将KG类型基于问题文本使用结构和语义特征进行聚类，以提高问题回答（QA）系统中语义答案类型预测（SMART）任务的性能，并获得最先进的结果。 |
| [^45] | [Graph Neural Networks for Text Classification: A Survey.](http://arxiv.org/abs/2304.11534) | 该综述介绍了基于图神经网络的文本分类技术，该技术可以直接处理复杂结构化文本数据并利用全局信息。许多真实的文本分类应用程序可以自然地表示为一个图。本综述覆盖到2023年的方法，包括语料库级别和文档级别的图神经网络，并详细讨论了每种方法的图构建机制和基于图的学习过程。涵盖了数据集、评估指标和实验设计，并总结了在公开可用的基准数据集上发布的性能。 |
| [^46] | [DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction.](http://arxiv.org/abs/2304.11015) | DIN-SQL通过将复杂的文本到SQL任务分解为子问题，并将这些子问题的解决方案馈入到大型语言模型中，显著提高了它们的表现，使准确性超过了当前最先进的技术。 |
| [^47] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^48] | [PheME: A deep ensemble framework for improving phenotype prediction from multi-modal data.](http://arxiv.org/abs/2303.10794) | 本文提出了PheME，一种利用多模态数据进行表型预测的深度集成框架。该框架采用多个深度神经网络和集成学习，可以从EHR数据中准确且高效地提取表型信息。 |
| [^49] | [Symbolic Discovery of Optimization Algorithms.](http://arxiv.org/abs/2302.06675) | 该论文提出了一种将算法发现视为程序搜索的方法，并用于发现深度神经网络训练的优化算法。他们的方法发现了一种简单而有效的优化算法Lion，它比Adam更节省内存并且在ImageNet上的准确率提高了2％，并且预训练的计算时间也减少了多达5倍。 |
| [^50] | [Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning.](http://arxiv.org/abs/2301.13808) | 这篇论文介绍了利用大型语言模型作为分解器，解决基于表格推理中的性能下降和复杂问题的问题，并在多个基准数据集上显著优于现有方法。 |
| [^51] | [Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making using Language Guided World Modelling.](http://arxiv.org/abs/2301.12050) | 本论文研究使用少量的大型语言模型来提高强化学习代理的样本效率。通过假设抽象世界模型并通过代理的世界经验进行验证，可以进行规划和探索。这种方法不仅可提高样本效率一个数量级，而且还具有稳健性。 |
| [^52] | [Democratizing Neural Machine Translation with OPUS-MT.](http://arxiv.org/abs/2212.01936) | 本文介绍了OPUS-MT生态系统的发展，包括开放式机器翻译模型和工具的开发，以及它们与最终用户应用程序、开发平台和专业工作流程的整合。通过增加语言覆盖范围和翻译质量，实现了神经机器翻译的民主化。 |
| [^53] | [Communication breakdown: On the low mutual intelligibility between human and neural captioning.](http://arxiv.org/abs/2210.11512) | 研究表明，给定相同的字幕，神经图像检索器的性能比人类要高得多，而人类在给定相同的神经字幕时的表现几乎与随机无异。 |
| [^54] | [Context Generation Improves Open Domain Question Answering.](http://arxiv.org/abs/2210.06349) | 该论文提出了一个两阶段的闭式问答框架，首先通过生成上下文来提取相关知识，然后使用这个知识回答问题，实验证明该方法在三个问答基准测试上明显优于以往的封闭式问答方法，并且与开放式方法持平。 |
| [^55] | [The Parallelism Tradeoff: Limitations of Log-Precision Transformers.](http://arxiv.org/abs/2207.00729) | 证明了在对数精度下，Transformer的计算能力存在限制，这是因为Transformer架构的高并行性使其遵守一个基本的并行性掉价，即模型架构越可并行化，就越会受到精度的限制。 |
| [^56] | [PREME: Preference-based Meeting Exploration through an Interactive Questionnaire.](http://arxiv.org/abs/2205.02370) | 本论文提出了一个新的端到端框架，通过生成交互式问卷，实现基于偏好的会议探索，帮助用户快速探索会议内容。 |
| [^57] | [BiTimeBERT: Extending Pre-Trained Language Representations with Bi-Temporal Information.](http://arxiv.org/abs/2204.13032) | 本论文介绍了一种新颖的语言表示模型BiTimeBERT，使用长跨度时间新闻文章集合构建单词表示，并通过两个新的预训练任务，利用两个不同的时间信号构建时间感知的语言表示。BiTimeBERT在时间相关任务中具有显著性能优势。 |
| [^58] | [GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models.](http://arxiv.org/abs/2203.07281) | GrIPS是一种基于编辑的无梯度搜索方法，用于改进大型语言模型的任务指令，显著提高性能。 |

# 详细

[^1]: ViMQ：面向医疗对话系统开发的越南医学问题数据集

    ViMQ: A Vietnamese Medical Question Dataset for Healthcare Dialogue System Development. (arXiv:2304.14405v1 [cs.CL])

    [http://arxiv.org/abs/2304.14405](http://arxiv.org/abs/2304.14405)

    该论文介绍了一个医学问题数据集ViMQ，该数据集涵盖了越南患者的医学问题，并提供了意图分类和命名实体识别任务的标签集，有助于促进医疗聊天机器人的发展。

    

    现有的医疗文本数据集通常采用问题和答案对的形式，支持自然语言生成任务，但缺乏医学术语的组合注释。在本研究中，我们发布了一个越南医学问题数据集，具有针对意图分类和命名实体识别任务的句子级和实体级注释。两个任务的标签集均属于医学领域，并能够促进面向任务的医疗聊天机器人从患者查询中更好地理解其含义。我们对两个任务进行了基线模型训练，并提出了一种简单的自监督训练策略，通过跨度噪声建模显着提高了性能。数据集和代码将发布在 https://github.com/tadeephuy/ViMQ。

    Existing medical text datasets usually take the form of ques- tion and answer pairs that support the task of natural language gener- ation, but lacking the composite annotations of the medical terms. In this study, we publish a Vietnamese dataset of medical questions from patients with sentence-level and entity-level annotations for the Intent Classification and Named Entity Recognition tasks. The tag sets for two tasks are in medical domain and can facilitate the development of task- oriented healthcare chatbots with better comprehension of queries from patients. We train baseline models for the two tasks and propose a simple self-supervised training strategy with span-noise modelling that substan- tially improves the performance. Dataset and code will be published at https://github.com/tadeephuy/ViMQ
    
[^2]: LaMini-LM: 基于大规模指令的多样性压缩模型群集

    LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions. (arXiv:2304.14402v1 [cs.CL])

    [http://arxiv.org/abs/2304.14402](http://arxiv.org/abs/2304.14402)

    本文提出的LaMini-LM是一种基于大规模指令的多样性压缩模型群集，从指令微调过的LLMs中提取知识到更小的模型中，其在15个不同的NLP基准测试中与其他竞争基线的表现相当，但体积约小了10倍。

    

    指令微调的大型语言模型表现出优秀的生成能力，但是这些模型需要大量的资源。为了减轻这个问题，我们探索从微调过的LLMs中提取知识到更小的模型中。为此，我们仔细开发了一组258万份基于现有和新生成的指令。除了规模大之外，我们还设计了广泛的话题，以确保指令的多样性，并使用gpt-3.5-turbo为这些指令生成响应。我们使用这些指令来微调多个模型，即LaMini-LM，包括编码器-解码器和仅解码器系列。我们对这些模型进行自动（在15个不同的NLP基准测试中）和手动评估。结果表明，我们提出的LaMini-LM与其他竞争基线的表现相当，而且体积约小了10倍。

    Large language models (LLMs) with instruction finetuning demonstrate superior generative capabilities. However, these models are resource intensive. To alleviate this issue, we explore distilling knowledge from instruction-tuned LLMs to much smaller ones. To this end, we carefully develop a large set of 2.58M instructions based on both existing and newly-generated instructions. In addition to being sizeable, we design our instructions to cover a broad set of topics to ensure. A thorough investigation of our instruction data demonstrate their diversity, and we generate responses for these instructions using gpt-3.5-turbo. We then exploit the instructions to tune a host of models, dubbed LaMini-LM, of varying sizes, both from the encoder-decoder as well as the decoder-only families. We evaluate our models both automatically (on 15 different NLP benchmarks) and manually. Results show that our proposed LaMini-LM are on par with competitive baselines while being nearly 10 times smaller in s
    
[^3]: 我们担心语言模型无法建模歧义

    We're Afraid Language Models Aren't Modeling Ambiguity. (arXiv:2304.14399v1 [cs.CL])

    [http://arxiv.org/abs/2304.14399](http://arxiv.org/abs/2304.14399)

    本研究旨在探讨语言模型处理歧义的问题。我们通过AmbiEnt基准数据集设计了一系列测试来评估GPT-4和其他预训练语言模型对歧义的识别和分离能力。结果表明，这是一个极具挑战性的任务，目前的语言模型还无法准确处理歧义。

    

    歧义是自然语言的内在特征。管理歧义是人类语言理解的关键部分，允许我们作为沟通者预期到误解，并作为听众修正我们的解释。随着语言模型（LM）越来越多地被用作对话界面和写作助手，处理含糊不清的语言对它们的成功至关重要。我们通过与另一句子的蕴含关系来描述句子中的歧义，并收集了一组包含1,645个不同类型歧义的语言学注释示例的基准数据AmbiEnt。我们设计了一系列基于AmbiEnt的测试，呈现了对预训练语言模型识别歧义和分离可能含义的第一次评估。我们发现这个任务仍然非常具有挑战性，包括最近发布的GPT-4。人类评估中，GPT-4产生的消歧被认为仅有32%是正确的，而我们的数据集中消歧的正确率为90%。最后，为了阐明我们研究的价值，

    Ambiguity is an intrinsic feature of natural language. Managing ambiguity is a key part of human language understanding, allowing us to anticipate misunderstanding as communicators and revise our interpretations as listeners. As language models (LMs) are increasingly employed as dialogue interfaces and writing aids, handling ambiguous language is critical to their success. We characterize ambiguity in a sentence by its effect on entailment relations with another sentence, and collect AmbiEnt, a linguist-annotated benchmark of 1,645 examples with diverse kinds of ambiguity. We design a suite of tests based on AmbiEnt, presenting the first evaluation of pretrained LMs to recognize ambiguity and disentangle possible meanings. We find that the task remains extremely challenging, including for the recent GPT-4, whose generated disambiguations are considered correct only 32% of the time in human evaluation, compared to 90% for disambiguations in our dataset. Finally, to illustrate the value 
    
[^4]: 基于能量模型的零样本场景重新排列规划器

    Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v1 [cs.RO])

    [http://arxiv.org/abs/2304.14391](http://arxiv.org/abs/2304.14391)

    本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    

    本文致力于开发一个场景重排框架，可以解释长指令以及在训练时从未见过的空间概念组合。我们提出使用相对对象排列的能量函数来表示语言指导的空间概念。语言解析器将指令映射到相应的能量函数，而开放式视觉语言模型将它们的参数基于场景中的相关对象进行修正。通过梯度下降求解能量函数的总和，并利用基于本地计算机视觉的策略将对象重新定位到推断的目标位置，即可生成目标场景配置。我们在已建立的指令导向操作基准测试以及我们提出的组合指令基准测试中测试了模型，结果表明，我们的模型的绩效优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    Language is compositional; an instruction can express multiple relation constraints to hold among objects in a scene that a robot is tasked to rearrange. Our focus in this work is an instructable scene rearranging framework that generalizes to longer instructions and to spatial concept compositions never seen at training time. We propose to represent language-instructed spatial concepts with energy functions over relative object arrangements. A language parser maps instructions to corresponding energy functions and an open-vocabulary visual-language model grounds their arguments to relevant objects in the scene. We generate goal scene configurations by gradient descent on the sum of energy functions, one per language predicate in the instruction. Local vision-based policies then relocate objects to the inferred goal locations. We test our model on established instruction-guided manipulation benchmarks, as well as benchmarks of compositional instructions we introduce. We show our model 
    
[^5]: CONSCENDI: 一种反对比且场景引导的蒸馏方法来为虚拟助手构建防护栏模型

    CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants. (arXiv:2304.14364v1 [cs.CL])

    [http://arxiv.org/abs/2304.14364](http://arxiv.org/abs/2304.14364)

    本文提出了一种名为CONSCENDI的蒸馏方法，用于构建防护栏模型，以监控任务型虚拟助手的输出。关键方法包括场景增强生成和对比训练样例。这种方法产生了一组多样化的违反规则的对话训练集，并且可以更好地检测代理的输出是否符合设计者指定的规则。

    

    随着GPT-4等越来越强大的语言模型的出现，新一代的基于任务的虚拟助手应运而生。这些对话系统可以根据客户的具体用例进行定制，但确保代理生成的文本仅符合提示指令中设计者指定的规则是具有挑战性的。因此，聊天机器人设计师通常使用另一个称为防护栏模型的模型来验证代理输出是否与其规则和约束对齐。我们探索了使用蒸馏方法来构建防护栏模型，以监控使用GPT-4中的训练数据的第一个模型的输出。我们发现，我们的CONSCENDI过程包括两个关键步骤：场景增强生成和对比训练样例。在生成对话数据时，我们会生成一组违反规则的场景，这些场景列举了违反规则的多样化高级方式。这种场景引导方法产生了一组多样化的违反规则的对话训练集，并且它使得模型更容易检测到代理生成的文本是否符合设计者指定的规则。

    A wave of new task-based virtual assistants has been fueled by increasingly powerful large language models, such as GPT-4. These conversational agents can be customized to serve customer-specific use cases, but ensuring that agent-generated text conforms to designer-specified rules included in prompt instructions alone is challenging. Therefore, chatbot designers often use another model, called a guardrail model, to verify that the agent output aligns with their rules and constraints. We explore using a distillation approach to guardrail models to monitor the output of the first model using training data from GPT-4. We find two crucial steps to our CONSCENDI process: scenario-augmented generation and contrastive training examples. When generating conversational data, we generate a set of rule-breaking scenarios, which enumerate a diverse set of high-level ways a rule can be violated. This scenario-guided approach produces a diverse training set of rule-violating conversations, and it p
    
[^6]: 大型语言模型在工业工程中的应用: ChatGPT在油气问题中的表现案例研究

    Industrial Engineering with Large Language Models: A case study of ChatGPT's performance on Oil & Gas problems. (arXiv:2304.14354v1 [cs.CL])

    [http://arxiv.org/abs/2304.14354](http://arxiv.org/abs/2304.14354)

    大型语言模型在工业工程中的应用领域初现，本文研究了ChatGPT在油气问题中的表现，并确定LLM最有效的领域。

    

    大型语言模型(LLM)在解决各种复杂问题方面表现出了巨大的潜力，包括油气工程以及其他工业工程学科，例如工厂自动化、PLC编程等。然而，对几个工业过程控制基础物理方程的强弱解的自动识别仍然是一个具有挑战性的任务。本文确定了当前LLM方法的局限性，特别是在油气工程等选择性实际问题上的ChatGPT表现。讨论了ChatGPT在解决油气工程中复杂问题的表现，并提出了LLM最有效的领域。

    Large Language Models (LLMs) have shown great potential in solving complex problems in various fields, including oil and gas engineering and other industrial engineering disciplines like factory automation, PLC programming etc. However, automatic identification of strong and weak solutions to fundamental physics equations governing several industrial processes remain a challenging task. This paper identifies the limitation of current LLM approaches, particularly ChatGPT in selected practical problems native to oil and gas engineering but not exclusively. The performance of ChatGPT in solving complex problems in oil and gas engineering is discussed and the areas where LLMs are most effective are presented.
    
[^7]: ChatGPT的黑暗面：来自随机鹦鹉和幻觉的法律和伦理挑战

    The Dark Side of ChatGPT: Legal and Ethical Challenges from Stochastic Parrots and Hallucination. (arXiv:2304.14347v1 [cs.CY])

    [http://arxiv.org/abs/2304.14347](http://arxiv.org/abs/2304.14347)

    ChatGPT带来的大语言模型(LLMs)虽然有很多优势，但是随机鹦鹉和幻觉等新的法律和伦理风险也随之而来。欧洲AI监管范式需要进一步发展以减轻这些风险。

    

    随着ChatGPT的推出，大语言模型（LLMs）正在动摇我们整个社会，快速改变我们的思维、创造和生活方式。然而，随着随机鹦鹉和幻觉等新的法律和伦理风险出现，新兴LLMs也带来了许多挑战。欧盟是第一个将重点放在AI模型监管上的司法管辖区。然而，新LLMs带来的风险可能会被新兴的欧盟监管范式所低估。因此，本函告警示欧洲AI监管范式必须进一步发展以减轻这些风险。

    With the launch of ChatGPT, Large Language Models (LLMs) are shaking up our whole society, rapidly altering the way we think, create and live. For instance, the GPT integration in Bing has altered our approach to online searching. While nascent LLMs have many advantages, new legal and ethical risks are also emerging, stemming in particular from stochastic parrots and hallucination. The EU is the first and foremost jurisdiction that has focused on the regulation of AI models. However, the risks posed by the new LLMs are likely to be underestimated by the emerging EU regulatory paradigm. Therefore, this correspondence warns that the European AI regulatory paradigm must evolve further to mitigate such risks.
    
[^8]: MarsEclipse在SemEval-2023任务3中的多语言和多标签框架检测及对比学习方法

    MarsEclipse at SemEval-2023 Task 3: Multi-Lingual and Multi-Label Framing Detection with Contrastive Learning. (arXiv:2304.14339v1 [cs.CL])

    [http://arxiv.org/abs/2304.14339](http://arxiv.org/abs/2304.14339)

    本文描述了一种在多语言设置下使用多标签对比损失来微调大型预训练语言模型的方法，取得了在五种语言上最好的结果。

    

    本文描述了我们在SemEval-2023任务3的子任务2上进行框架检测的系统。我们使用了多标签对比损失来微调大型预训练语言模型的多语言设置，取得了非常有竞争力的结果：我们的系统在官方测试集和官方排行榜上排名第一，对于我们有训练数据并能进行微调的六种语言中的五种语言。在这里，我们描述了我们的实验设置以及各种消融研究。我们的系统代码可在https://github.com/QishengL/SemEval2023上获得。

    This paper describes our system for SemEval-2023 Task 3 Subtask 2 on Framing Detection. We used a multi-label contrastive loss for fine-tuning large pre-trained language models in a multi-lingual setting, achieving very competitive results: our system was ranked first on the official test set and on the official shared task leaderboard for five of the six languages for which we had training data and for which we could perform fine-tuning. Here, we describe our experimental setup, as well as various ablation studies. The code of our system is available at https://github.com/QishengL/SemEval2023
    
[^9]: 成语、探测和危险的事物：基于结构探测的词向量成语性研究。

    Idioms, Probing and Dangerous Things: Towards Structural Probing for Idiomaticity in Vector Space. (arXiv:2304.14333v1 [cs.CL])

    [http://arxiv.org/abs/2304.14333](http://arxiv.org/abs/2304.14333)

    本文利用结构探测方法研究了成语在静态和上下文嵌入中的编码情况，并发现仍未确定成语性是否在向量范数中编码，提出了改进数据集以进行探测分析的方向。

    

    本文旨在通过一种结构探测方法更深入地了解成语信息如何被嵌入到词嵌入中。我们重新利用了现有的英语动词复合词语（MWE）数据集来适应探测框架，并对静态（GloVe）和上下文（BERT）嵌入进行了比较探测研究。我们的实验表明，这两种方法都以不同程度编码了一些成语信息，但对于成语性是否在向量范数中编码给出了冲突的证据，这仍然是个未解之谜。我们还确定了所使用数据集的一些局限性，并强调了改进其适用性进行探测分析的重要方向。

    The goal of this paper is to learn more about how idiomatic information is structurally encoded in embeddings, using a structural probing method. We repurpose an existing English verbal multi-word expression (MWE) dataset to suit the probing framework and perform a comparative probing study of static (GloVe) and contextual (BERT) embeddings. Our experiments indicate that both encode some idiomatic information to varying degrees, but yield conflicting evidence as to whether idiomaticity is encoded in the vector norm, leaving this an open question. We also identify some limitations of the used dataset and highlight important directions for future work in improving its suitability for a probing analysis.
    
[^10]: q2d：将问题转换为对话，教导模型如何搜索

    q2d: Turning Questions into Dialogs to Teach Models How to Search. (arXiv:2304.14318v1 [cs.CL])

    [http://arxiv.org/abs/2304.14318](http://arxiv.org/abs/2304.14318)

    本文提出了q2d方法，通过自动生成含有查询的对话来教导模型如何发出搜索查询。实验表明，该方法的模型性能接近使用人类标注数据训练的模型，而且具有更好的控制和扩展性。

    

    最近的对话语言模型有一个激动人心的能力，即能够独立地搜索相关信息，以确定给定对话的响应。然而，获取用于教导模型如何发出搜索查询的训练数据是耗费时间和资源的。在本文中，我们提出了q2d：一种自动生成从问题中获取信息的对话的数据生成流水线。我们提供给一个大型的语言模型（PaLM）来创建问答数据集的对话版本，并使用它来改进与外部搜索API通信以确定对话响应的查询生成模型。与先前依赖于人类编写的带有搜索查询的对话的方法不同，我们的方法允许自动生成基于查询的对话，从而实现更好的控制和规模。我们的实验表明：（1）针对QReCC数据集的查询生成，使用我们的合成数据训练的模型实现了从MNLI中进行传输学习的模型性能的90%--97%，而使用人工标注的查询生成数据训练的模型实现了91%--96%的性能。（2）针对QUAC和CoQA数据集的基础响应选择，使用我们自动生成的对话训练的模型性能仅比使用带有搜索查询的人类生成的对话训练的模型性能低了0.8-2.2％。

    One of the exciting capabilities of recent language models for dialog is their ability to independently search for relevant information to ground a given dialog response. However, obtaining training data to teach models how to issue search queries is time and resource consuming. In this work, we propose q2d: an automatic data generation pipeline that generates information-seeking dialogs from questions. We prompt a large language model (PaLM) to create conversational versions of question answering datasets, and use it to improve query generation models that communicate with external search APIs to ground dialog responses. Unlike previous approaches which relied on human written dialogs with search queries, our method allows to automatically generate query-based grounded dialogs with better control and scale. Our experiments demonstrate that: (1) For query generation on the QReCC dataset, models trained on our synthetically-generated data achieve 90%--97% of the performance of models tr
    
[^11]: 大型语言模型是代码生成的最先进评估器

    Large Language Models Are State-of-the-Art Evaluators of Code Generation. (arXiv:2304.14317v1 [cs.AI])

    [http://arxiv.org/abs/2304.14317](http://arxiv.org/abs/2304.14317)

    本文提出了一个基于 GPT-3.5 的评估框架，解决了现有方法在代码生成任务上的局限性，取得了更好的相关性。

    

    自然语言生成领域的最新进展推动了利用大型语言模型评估生成文本的能力。虽然这些模型在机器翻译和摘要等任务中表现出了很好的结果，但其在代码生成任务中的适用性仍然存在限制。这些任务所需的编程概念的复杂性使得开发评估指标以与人类判断相一致变得困难。以词汇匹配为基础的度量标准（如BLEU）在代码生成任务中与人工从业者的相关性较弱。此外，在低资源领域中利用人为编写的测试套件进行功能正确性评估也具有挑战性。为了克服这些障碍，我们提出了一个基于GPT-3.5的代码生成评估框架（\texttt{GPT-3.5-turbo}）。我们的框架通过取得更好的相关性来解决现有方法的局限性。

    Recent advancements in the field of natural language generation have facilitated the use of large language models to assess the quality of generated text. Although these models have shown promising results in tasks such as machine translation and summarization, their applicability in code generation tasks remains limited without human involvement. The complexity of programming concepts required for such tasks makes it difficult to develop evaluation metrics that align with human judgment. Token-matching-based metrics, such as BLEU, have demonstrated weak correlations with human practitioners in code generation tasks. Moreover, the utilization of human-written test suites to evaluate functional correctness can be challenging in domains with low resources. To overcome these obstacles, we propose a new evaluation framework based on the GPT-3.5 (\texttt{GPT-3.5-turbo}), for code generation assessments. Our framework addresses the limitations of existing approaches by achieving superior cor
    
[^12]: 用自然语言指令控制文本生成

    Controlled Text Generation with Natural Language Instructions. (arXiv:2304.14293v1 [cs.CL])

    [http://arxiv.org/abs/2304.14293](http://arxiv.org/abs/2304.14293)

    InstructCTG是一个可以通过自然语言描述和演示来控制文本生成并满足不同约束条件的框架，它有效地解决了现有搜索或得分方法所存在的问题。

    

    大型语言模型可以产生流畅的文本，并能根据自然语言指令解决各种任务，无需特定的训练。然而，控制它们的生成以满足不同应用程序所需的各种约束条件是非常困难的。本文提供了一个带约束调节的文本生成框架——InstructCTG，该框架通过基于自然语言描述和约束演示来纳入不同的约束条件。我们首先通过一系列现成的NLP工具和简单的启发式方法来提取自然文本的潜在约束条件。此外，我们将这些约束条件转化为自然语言指令，以形成弱监督的训练数据。通过添加自然语言约束描述和少量演示，我们对预训练语言模型进行了微调，以纳入各种类型的约束条件。与现有基于搜索或得分的方法相比，InstructCTG 更加有效。

    Large language models generate fluent texts and can follow natural language instructions to solve a wide range of tasks without task-specific training. Nevertheless, it is notoriously difficult to control their generation to satisfy the various constraints required by different applications. In this work, we present InstructCTG, a controlled text generation framework that incorporates different constraints by conditioning on natural language descriptions and demonstrations of the constraints. In particular, we first extract the underlying constraints of natural texts through a combination of off-the-shelf NLP tools and simple heuristics. We then verbalize the constraints into natural language instructions to form weakly supervised training data. By prepending natural language descriptions of the constraints and a few demonstrations, we fine-tune a pre-trained language model to incorporate various types of constraints. Compared to existing search-based or score-based methods, InstructCT
    
[^13]: 深度度量学习下的语义框架感知

    Semantic Frame Induction with Deep Metric Learning. (arXiv:2304.14286v1 [cs.CL])

    [http://arxiv.org/abs/2304.14286](http://arxiv.org/abs/2304.14286)

    本文提出了一种深度度量学习的模型，通过对上下文嵌入模型进行微调，并应用于语义框架感知，实现语义框架感知，并在FrameNet上的实验表明效果优于其他最先进的方法。

    

    最近的研究表明，上下文化词嵌入在无监督语义框架感知中是有用的。然而，它们也揭示了通用上下文化嵌入并不总是符合人类对语义框架的直觉，这导致基于上下文化嵌入的语义框架感知性能不佳。本文提出了一种深度度量学习模型，它使用语义帧标注数据对上下文化嵌入模型进行微调，并将微调后的上下文化嵌入应用于语义框架感知。在FrameNet上的实验表明，深度度量学习的微调显著提高了聚类评估分数，即B-cubed F分数和Purity F分数，提高了8个点以上。我们还证明了我们的模型优于包括使用上下文化嵌入的无监督方法在内的几种最先进的语义框架感知方法。

    Recent studies have demonstrated the usefulness of contextualized word embeddings in unsupervised semantic frame induction. However, they have also revealed that generic contextualized embeddings are not always consistent with human intuitions about semantic frames, which causes unsatisfactory performance for frame induction based on contextualized embeddings. In this paper, we address supervised semantic frame induction, which assumes the existence of frame-annotated data for a subset of predicates in a corpus and aims to build a frame induction model that leverages the annotated data. We propose a model that uses deep metric learning to fine-tune a contextualized embedding model, and we apply the fine-tuned contextualized embeddings to perform semantic frame induction. Our experiments on FrameNet show that fine-tuning with deep metric learning considerably improves the clustering evaluation scores, namely, the B-cubed F-score and Purity F-score, by about 8 points or more. We also dem
    
[^14]: AI，为我写一篇文章：人类写作与ChatGPT生成文章的大规模比较

    AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays. (arXiv:2304.14276v1 [cs.CL])

    [http://arxiv.org/abs/2304.14276](http://arxiv.org/abs/2304.14276)

    ChatGPT生成的文章质量比人类写作的文章更高，写作风格更流畅，语法和拼写错误更少。

    

    背景：最近，ChatGPT及类似的AI生成模型吸引了数亿用户，成为公众话题的一部分。许多人认为这样的模型将会打乱社会，导致未来教育系统和信息生成的显著变化。然而，迄今为止，这种信念基于的是口头证据或模型拥有者的基准——这两者缺乏科学严谨性。目标：通过大规模研究比较人类写作和ChatGPT生成论证性学生文章的质量，我们系统地评估了AI生成内容的质量。方法：一大批文章语料库被许多人类专家（教师）使用标准标准评分。我们在分析中加入了对生成文章的语言特征的考虑。结果：我们的结果表明，ChatGPT生成的文章比人类写作的文章质量更高。AI的写作风格更加流畅，而且比人类写作出现更少的语法和拼写错误。

    Background: Recently, ChatGPT and similar generative AI models have attracted hundreds of millions of users and become part of the public discourse. Many believe that such models will disrupt society and will result in a significant change in the education system and information generation in the future. So far, this belief is based on either colloquial evidence or benchmarks from the owners of the models -- both lack scientific rigour.  Objective: Through a large-scale study comparing human-written versus ChatGPT-generated argumentative student essays, we systematically assess the quality of the AI-generated content.  Methods: A large corpus of essays was rated using standard criteria by a large number of human experts (teachers). We augment the analysis with a consideration of the linguistic characteristics of the generated essays.  Results: Our results demonstrate that ChatGPT generates essays that are rated higher for quality than human-written essays. The writing style of the AI m
    
[^15]: 名字的意义：通过 CAD 文件中用户提供的名称评估语言模型中的装配 - 零件语义知识。

    What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models through User-Provided Names in CAD Files. (arXiv:2304.14275v1 [cs.CL])

    [http://arxiv.org/abs/2304.14275](http://arxiv.org/abs/2304.14275)

    本文提出，计算机辅助设计（CAD）软件中的自然语言名称是部件关联的宝贵来源，大型语言模型（LLM）提供了一种处理这种数据的有用的领域专业知识。通过自然语言名称的预训练模型可在三个自监督任务上表现出色，微调还可以提高所有任务的性能，提高了文本数据的价值。此外，提出了手动注释的新数据集 CAD-120，其中包含 120 个装配，并提供了语义关系注释。

    

    装配中零件之间和零件与整体之间的语义知识对于从搜索设计存储库到构建工程知识库等各种任务都非常有用。本文提出，设计师在计算机辅助设计 (CAD) 软件中使用的自然语言名称是这种知识宝贵的来源，并且大型语言模型 (LLM) 包含了用于处理此数据以及其他 CAD 和工程相关任务的有用领域专业知识。我们提取并清理了大量的自然语言零件、特征和文档名称语料库，并使用它来定量证明预训练语言模型可以在三个自监督任务上优于众多基准测试，而且从未见过这些数据。此外，我们展示了对文本数据语料库进行微调可以进一步提高所有任务的性能，从而展示了迄今为止在很大程度上被忽略的文本数据的价值。我们还确定了这个领域需要更多的基准数据集，并提出了一个名为 CAD-120 的新数据集，其中包含 120 个 CAD 装配件，具有手动注释的语义关系。

    Semantic knowledge of part-part and part-whole relationships in assemblies is useful for a variety of tasks from searching design repositories to the construction of engineering knowledge bases. In this work we propose that the natural language names designers use in Computer Aided Design (CAD) software are a valuable source of such knowledge, and that Large Language Models (LLMs) contain useful domain-specific information for working with this data as well as other CAD and engineering-related tasks.  In particular we extract and clean a large corpus of natural language part, feature and document names and use this to quantitatively demonstrate that a pre-trained language model can outperform numerous benchmarks on three self-supervised tasks, without ever having seen this data before. Moreover, we show that fine-tuning on the text data corpus further boosts the performance on all tasks, thus demonstrating the value of the text data which until now has been largely ignored. We also ide
    
[^16]: 实体级情感分析（ELSA）：一项探索性任务概述

    Entity-Level Sentiment Analysis (ELSA): An exploratory task survey. (arXiv:2304.14241v1 [cs.CL])

    [http://arxiv.org/abs/2304.14241](http://arxiv.org/abs/2304.14241)

    本文探索了实体级情感分析（ELSA）的任务，即识别文档中自愿实体（人和组织）所表达总体情绪的能力。虽然对于像推文这样的较短文本识别对实体表达情感已经有了较多研究，但我们发现对于在文本中多次提及同一实体的较长文本，几乎没有相关研究。作者注释了一组专业评论以评估现有任务和模型是否可以推导出ELSA，结果表明没有单一代理任务能够以令人满意的表现提供这种我们寻求的对实体的总体情感。

    

    本文探讨了识别文档中自愿实体（人和组织）所表达总体情绪的任务，即我们所称的实体级情感分析（ELSA）。虽然对于像推文这样的较短文本识别对实体表达情感已经有了较多研究，但我们发现对于在文本中多次提及同一实体的较长文本，几乎没有相关研究。如果现有任务和模型可以推导出ELSA，这种缺乏研究是可以理解的。为了评估这一点，我们注释了一组专业评论以了解文本中每个自愿实体的总体情感。我们从一个多领域评论语料库中已经注释为文档级、句子级和目标级情感的数据中进行采样，我们的结果表明，没有一个单一的代理任务能够以令人满意的表现提供这种我们寻求的对实体的总体情感。我们提供了一套实验。

    This paper explores the task of identifying the overall sentiment expressed towards volitional entities (persons and organizations) in a document -- what we refer to as Entity-Level Sentiment Analysis (ELSA). While identifying sentiment conveyed towards an entity is well researched for shorter texts like tweets, we find little to no research on this specific task for longer texts with multiple mentions and opinions towards the same entity. This lack of research would be understandable if ELSA can be derived from existing tasks and models. To assess this, we annotate a set of professional reviews for their overall sentiment towards each volitional entity in the text. We sample from data already annotated for document-level, sentence-level, and target-level sentiment in a multi-domain review corpus, and our results indicate that there is no single proxy task that provides this overall sentiment we seek for the entities at a satisfactory level of performance. We present a suite of experim
    
[^17]: 自动化事实核查工具的预期用途：为什么、如何以及谁使用。

    The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who. (arXiv:2304.14238v1 [cs.CL])

    [http://arxiv.org/abs/2304.14238](http://arxiv.org/abs/2304.14238)

    本文分析了100篇高被引论文，发现自动化事实核查工具的使用往往缺乏充分讨论。文章提出缺乏充分讨论的现象鼓励了过度宣传，限制了批评并阻止了利益相关者的反馈。作者提出了关于事实核查工具使用的几项建议。

    

    自动事实核查经常被呈现为一个知识工具，事实核查员、社交媒体消费者和其他利益相关者可以使用它来打击错误信息。然而，很少有论文深入讨论如何使用。我们通过分析100篇高被引用论文并注释与预期使用相关的认知元素（即手段、目的和利益相关者）来记录这一点。我们发现，忽略其中一些方面的叙事很普遍，许多论文提出的手段和目的不一致，并且推荐策略的可行性很少具有实证支持。我们认为这种模糊性主动阻碍了技术实现其目标，因为它鼓励了过度宣传，限制了批评并阻止了利益相关者的反馈。因此，我们提出了几项关于思考和撰写事实核查工具使用的建议。

    Automated fact-checking is often presented as an epistemic tool that fact-checkers, social media consumers, and other stakeholders can use to fight misinformation. Nevertheless, few papers thoroughly discuss how. We document this by analysing 100 highly-cited papers, and annotating epistemic elements related to intended use, i.e., means, ends, and stakeholders. We find that narratives leaving out some of these aspects are common, that many papers propose inconsistent means and ends, and that the feasibility of suggested strategies rarely has empirical backing. We argue that this vagueness actively hinders the technology from reaching its goals, as it encourages overclaiming, limits criticism, and prevents stakeholder feedback. Accordingly, we provide several recommendations for thinking and writing about the use of fact-checking artefacts.
    
[^18]: 大型语言模型在零-shot检索中具有较强的表现力。

    Large Language Models are Strong Zero-Shot Retriever. (arXiv:2304.14233v1 [cs.CL])

    [http://arxiv.org/abs/2304.14233](http://arxiv.org/abs/2304.14233)

    本文提出了一种在零-shot场景下利用大型语言模型（LLM）进行大规模检索的方法。该方法通过使用查询和查询的候选答案的组合作为提示，使LLM生成更精确的答案。由于自监督检索器在零-shot场景中性能较差，因此LameR优于自监督检索器。

    

    本文提出了一种简单的方法，在零-shot场景下应用大型语言模型（LLM）进行大规模检索。我们的方法，Language Model作为检索器（LameR）仅基于大语言模型而不是其他神经模型，通过将LLM与检索器的暴力组合进行分解，将零-shot检索的性能提高到在基准数据集上具有很强的竞争力。本文主要提出通过使用查询和查询的候选答案的组合作为提示，使LLM生成更精确的答案。无论候选答案是否正确，都可以通过模式模仿或候选摘要来帮助LLM产生更精确的答案。此外，由于自监督检索器在零-shot场景中性能较差，因此通过利用LLM对文本模式的强大表现能力，LameR可以优于自监督检索器。

    In this work, we propose a simple method that applies a large language model (LLM) to large-scale retrieval in zero-shot scenarios. Our method, Language language model as Retriever (LameR) is built upon no other neural models but an LLM, while breaking up brute-force combinations of retrievers with LLMs and lifting the performance of zero-shot retrieval to be very competitive on benchmark datasets. Essentially, we propose to augment a query with its potential answers by prompting LLMs with a composition of the query and the query's in-domain candidates. The candidates, regardless of correct or wrong, are obtained by a vanilla retrieval procedure on the target collection. Such candidates, as a part of prompts, are likely to help LLM generate more precise answers by pattern imitation or candidate summarization. Even if all the candidates are wrong, the prompts at least make LLM aware of in-collection patterns and genres. Moreover, due to the low performance of a self-supervised retriever
    
[^19]: 一种基于深度学习和基于文法方法的多语言时态表达式检测和规范化的模块化方法

    A Modular Approach for Multilingual Timex Detection and Normalization using Deep Learning and Grammar-based methods. (arXiv:2304.14221v1 [cs.CL])

    [http://arxiv.org/abs/2304.14221](http://arxiv.org/abs/2304.14221)

    本文介绍了一个模块化的多语言时间处理系统，该系统结合了基于深度学习的检测方法和基于文法的规范化方法，能够有效地进行时态表达式检测和规范化，并在金标准 timex 规范化、timex 检测和类型识别方面取得了最佳结果。

    

    检测和规范化时间表达式是许多自然语言处理任务中必不可少的步骤。虽然已经提出了各种检测方法，但最佳规范化方法仍然依赖于手工制定的规则。此外，它们大多数仅针对英语设计。在本文中，我们提出了一个模块化的多语言时间处理系统，结合了基于掩蔽语言模型的检测方法和基于文法的规范化方法。我们在西班牙语和英语上进行了实验，并与 HeidelTime 进行了比较，后者是多语言时间处理的最新研究成果。我们在金标准 timex 规范化、timex 检测和类型识别方面取得了最佳结果，并在组合的 TempEval-3 宽松度量上表现出竞争性的表现。详细的误差分析表明，在该指标中仅检测可提供规范化的 timexes 对其有很大的好处。这引出了一个问题，即 timex 处理的最佳策略是什么，即只检测那些可行提供规范化的 timexes 或仅检测那些易于规范化的 timexes。

    Detecting and normalizing temporal expressions is an essential step for many NLP tasks. While a variety of methods have been proposed for detection, best normalization approaches rely on hand-crafted rules. Furthermore, most of them have been designed only for English. In this paper we present a modular multilingual temporal processing system combining a fine-tuned Masked Language Model for detection, and a grammar-based normalizer. We experiment in Spanish and English and compare with HeidelTime, the state-of-the-art in multilingual temporal processing. We obtain best results in gold timex normalization, timex detection and type recognition, and competitive performance in the combined TempEval-3 relaxed value metric. A detailed error analysis shows that detecting only those timexes for which it is feasible to provide a normalization is highly beneficial in this last metric. This raises the question of which is the best strategy for timex processing, namely, leaving undetected those ti
    
[^20]: SemEval-2023 任务12：用于低资源语言情感分类的多语言微调的UIO方法(arXiv:2304.14189v1 [cs.CL])

    UIO at SemEval-2023 Task 12: Multilingual fine-tuning for sentiment classification in low-resource languages. (arXiv:2304.14189v1 [cs.CL])

    [http://arxiv.org/abs/2304.14189](http://arxiv.org/abs/2304.14189)

    本文介绍了通过使用多语言大语言模型进行非洲低资源语言情感分类的方法，并发现在提供的数据集中，使用单语微调的方法可以达到最佳结果。

    

    我们在2023年AfriSenti-SemEval分享任务12:非洲语言情感分析中的贡献，提供了一个多语言大语言模型如何成为在非预训练语言上进行情感分析的资源的见解。该任务提供了不同语系的各种非洲语言的数据集。这些语言在不同程度上与预训练所使用的语言有关，并且语言数据具有不同程度的代码切换。我们试验了单语和多语语料库进行最终微调，并发现对于包含成千上万个样本的提供数据集，单语微调产生最佳结果。

    Our contribution to the 2023 AfriSenti-SemEval shared task 12: Sentiment Analysis for African Languages, provides insight into how a multilingual large language model can be a resource for sentiment analysis in languages not seen during pretraining. The shared task provides datasets of a variety of African languages from different language families. The languages are to various degrees related to languages used during pretraining, and the language data contain various degrees of code-switching. We experiment with both monolingual and multilingual datasets for the final fine-tuning, and find that with the provided datasets that contain samples in the thousands, monolingual fine-tuning yields the best results.
    
[^21]: NAP在SemEval-2023任务3中：少是否真的更多？（回）翻译作为检测说服技巧的数据增强策略。

    NAP at SemEval-2023 Task 3: Is Less Really More? (Back-)Translation as Data Augmentation Strategies for Detecting Persuasion Techniques. (arXiv:2304.14179v1 [cs.CL])

    [http://arxiv.org/abs/2304.14179](http://arxiv.org/abs/2304.14179)

    本文旨在探讨用少量数据在多语言环境下检测说服技巧的挑战，提出利用（回）翻译作为数据增强的策略，并证实平衡人工和机器生成数据的重要性。

    

    在多语言环境下检测新闻中的说服技巧是非常困难和具有挑战性的，其中包括很少的训练数据。我们的系统成功地利用多语言变压器模型的（回）翻译作为数据增强策略，用于检测说服技巧的任务。我们的自动化和人工评估允许我们探索（回）翻译是否有助于或阻碍性能。我们的深入分析表明，两种数据增强策略都可以提高性能；然而，平衡人工生产和机器生成的数据似乎至关重要。

    Persuasion techniques detection in news in a multi-lingual setup is non-trivial and comes with challenges, including little training data. Our system successfully leverages (back-)translation as data augmentation strategies with multi-lingual transformer models for the task of detecting persuasion techniques. The automatic and human evaluation of our augmented data allows us to explore whether (back-)translation aid or hinder performance. Our in-depth analyses indicate that both data augmentation strategies boost performance; however, balancing human-produced and machine-generated data seems to be crucial.
    
[^22]: mPLUG-Owl: 模块化增强了大型语言模型的多模态能力

    mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality. (arXiv:2304.14178v1 [cs.CL])

    [http://arxiv.org/abs/2304.14178](http://arxiv.org/abs/2304.14178)

    本文介绍了一种名为mPLUG-Owl的训练范式，它通过模块化学习基础LLM、视觉知识模块和视觉抽象器模块，赋予LLMs多模态的能力。实验结果表明，mPLUG-Owl在图像字幕和视觉问答任务中表现优于基线模型，并在某些情况下达到了最先进的性能水平。

    

    大型语言模型(LLMs)已经在各种开放式任务中展示出了令人印象深刻的零-shot表现，而最近的研究还探讨了将LLMs用于多模态生成的应用。在本研究中，我们引入了一种新的训练范式mPLUG-Owl，通过基础LLM、视觉知识模块和视觉抽象器模块的模块化学习，使LLMs具备了多模态的能力。该方法可以支持多种模态，并通过模态协作促进了多单模态和多模态的能力。mPLUG-Owl的训练范式包括用于对齐图像和文本的两阶段方法，该方法利用LLM的辅助学习视觉知识，同时保持甚至改进了LLM的生成能力。在第一阶段中，使用冻结的LLM模块对视觉知识模块和抽象器模块进行训练以对齐图像和文本。在第二阶段中，使用仅语言和多模态监督数据集共同对模型进行微调。对于图像字幕和视觉问答任务的实验结果表明，mPLUG-Owl优于基线模型，在某些情况下达到了最先进的性能水平。

    Large language models (LLMs) have demonstrated impressive zero-shot abilities on a variety of open-ended tasks, while recent research has also explored the use of LLMs for multi-modal generation. In this study, we introduce mPLUG-Owl, a novel training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. This approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The training paradigm of mPLUG-Owl involves a two-stage method for aligning image and text, which learns visual knowledge with the assistance of LLM while maintaining and even improving the generation abilities of LLM. In the first stage, the visual knowledge module and abstractor module are trained with a frozen LLM module to align the image and text. In the second stage, language-only and multi-modal supervised datasets are used to jointly fine-tu
    
[^23]: ChatGPT与现有模型之间的关键短语生成任务基准研究

    ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task. (arXiv:2304.14177v1 [cs.CL])

    [http://arxiv.org/abs/2304.14177](http://arxiv.org/abs/2304.14177)

    本研究比较了ChatGPT和现有模型在关键短语生成任务上的性能，并发现ChatGPT在所有测试数据集和环境中的表现均优于现有模型，适用于不同领域和文档长度的关键短语生成。

    

    基于Transformer的语言模型，包括ChatGPT，已经在各种自然语言生成任务中展现了出色的性能。但是，在评估ChatGPT的关键短语生成能力方面，还没有多少研究，这涉及到准确反映文档内容的信息性短语的识别。本文试图通过将ChatGPT的关键短语生成表现与现有模型进行比较来解决这个问题，同时还测试了它作为解决领域适应和长文档关键短语生成两个重大挑战的潜力。我们在来自科学文章和新闻领域的六个公开数据集上进行了实验，分析了在短文档和长文档上的表现。结果表明，在所有测试的数据集和环境中，ChatGPT的性能优于当前现有模型，产生适应不同领域和文档长度的高质量关键短语。

    Transformer-based language models, including ChatGPT, have demonstrated exceptional performance in various natural language generation tasks. However, there has been limited research evaluating ChatGPT's keyphrase generation ability, which involves identifying informative phrases that accurately reflect a document's content. This study seeks to address this gap by comparing ChatGPT's keyphrase generation performance with state-of-the-art models, while also testing its potential as a solution for two significant challenges in the field: domain adaptation and keyphrase generation from long documents. We conducted experiments on six publicly available datasets from scientific articles and news domains, analyzing performance on both short and long documents. Our results show that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.
    
[^24]: DataComp：寻找下一代多模态数据集

    DataComp: In search of the next generation of multimodal datasets. (arXiv:2304.14108v1 [cs.CV])

    [http://arxiv.org/abs/2304.14108](http://arxiv.org/abs/2304.14108)

    DataComp是一个基准测试，旨在通过提出新的训练集来解决数据集在机器学习生态系统中的缺陷。它提供了一个多规模设计的实验测试平台，使用12.8B个图像-文本对的新候选池，让研究人员可以通过设计新的过滤技术或策划新的数据源并评估它们的新数据集来进行创新。

    

    大型的多模态数据集在近期的突破中起到了关键作用，比如CLIP、Stable Diffusion和GPT-4等。与此同时，数据集很少得到与模型架构或训练算法同等的研究关注。为了解决这个在机器学习生态系统中的缺陷，我们介绍了DataComp，一个基准测试，其中训练代码是固定的，研究人员通过提出新的训练集来进行创新。我们提供了一个基于Common Crawl的新候选池，其中包含12.8B个图像-文本对的数据集实验测试平台。参加我们基准测试的研究人员可以设计新的过滤技术或策划新的数据源，并通过运行我们标准化的CLIP训练代码并在38个下游测试集上进行测试来评估他们的新数据集。我们的基准测试包含多个规模，四个候选池大小和相应的计算预算，在训练期间涵盖了从12.8M到12.8B个样本。这种多规模设计有助于研究规模趋势，并为研究人员提供了更多的选择余地。

    Large multimodal datasets have been instrumental in recent breakthroughs such as CLIP, Stable Diffusion, and GPT-4. At the same time, datasets rarely receive the same research attention as model architectures or training algorithms. To address this shortcoming in the machine learning ecosystem, we introduce DataComp, a benchmark where the training code is fixed and researchers innovate by proposing new training sets. We provide a testbed for dataset experiments centered around a new candidate pool of 12.8B image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing on 38 downstream test sets. Our benchmark consists of multiple scales, with four candidate pool sizes and associated compute budgets ranging from 12.8M to 12.8B samples seen during training. This multi-scale design facilitates the study of scaling trends and makes the
    
[^25]: ChatLog: 记录和分析ChatGPT随时间的变化

    ChatLog: Recording and Analyzing ChatGPT Across Time. (arXiv:2304.14106v1 [cs.CL])

    [http://arxiv.org/abs/2304.14106](http://arxiv.org/abs/2304.14106)

    ChatLog是一个分析ChatGPT随时间变化的数据集，通过提取ChatGPT知识和语言特征发现了一些稳定的特征，提高了RoBERTa-based detector在新版本ChatGPT上的鲁棒性。

    

    尽管有大量关于在自然语言理解和生成任务中评估ChatGPT的研究，但鲜有研究调查ChatGPT的行为如何随时间变化。在本文中，我们收集了一个粗到细的时间数据集，称为ChatLog，由两个部分组成，每月和每天更新：ChatLog-Monthly是一个数据集，包括每个月收集的38,730个问题-回答对，其中包括推理和分类任务的问题。另一方面，ChatLog-Daily包括ChatGPT每天对1000个相同问题的长篇回答。我们进行全面的自动和人工评估，以提供ChatGPT进化模式存在的证据。我们进一步通过提取其知识和语言特征分析了ChatGPT随时间不变的特征。我们发现一些稳定的特征，以提高基于RoBERTa的检测器在新版本的ChatGPT上的鲁棒性。我们将继续维护我们的数据集以及随时间的分析。

    While there are abundant researches about evaluating ChatGPT on natural language understanding and generation tasks, few studies have investigated how ChatGPT's behavior changes over time. In this paper, we collect a coarse-to-fine temporal dataset called ChatLog, consisting of two parts that update monthly and daily: ChatLog-Monthly is a dataset of 38,730 question-answer pairs collected every month including questions from both the reasoning and classification tasks. ChatLog-Daily, on the other hand, consists of ChatGPT's responses to 1000 identical questions for long-form generation every day. We conduct comprehensive automatic and human evaluation to provide the evidence for the existence of ChatGPT evolving patterns. We further analyze the unchanged characteristics of ChatGPT over time by extracting its knowledge and linguistic features. We find some stable features to improve the robustness of a RoBERTa-based detector on new versions of ChatGPT. We will continuously maintain our p
    
[^26]: 从弱文本监督中学习图像中的人际互动

    Learning Human-Human Interactions in Images from Weak Textual Supervision. (arXiv:2304.14104v1 [cs.CV])

    [http://arxiv.org/abs/2304.14104](http://arxiv.org/abs/2304.14104)

    本文提出了一种新的范式，从单一的静态图像中学习自由文本的形式来灵活建模人际互动。并通过知识蒸馏生成伪标签来训练一种字幕模型，用于有效理解图像中的人际互动，具有较高的预测文本和语义质量，并在此任务上优于SOTA的图像字幕和情境识别模型。

    

    人际互动是多样且依赖于上下文的，但先前的工作将它们视为分类，忽略了可能的互动的重尾。本文提出了一种新的学习人际互动的范式，将其作为自由文本从单一的静态图像中学习，从而允许对情况和人际关系的无限空间进行灵活建模。为了克服缺乏特定于此任务的标记数据的问题，我们使用知识蒸馏应用于由大型语言模型产生的合成字幕数据，以此生成伪标签。我们展示了通过这个过程产生的伪标签可以用于训练一种字幕模型，能有效理解图像中的人际互动，通过衡量我们预测的文本和语义质量与事实的基础性的各种指标来衡量。我们进一步展示了我们的方法在这个任务上的性能优于SOTA的图像字幕和情境识别模型。我们将公开我们的代码。

    Interactions between humans are diverse and context-dependent, but previous works have treated them as categorical, disregarding the heavy tail of possible interactions. We propose a new paradigm of learning human-human interactions as free text from a single still image, allowing for flexibility in modeling the unlimited space of situations and relationships between people. To overcome the absence of data labelled specifically for this task, we use knowledge distillation applied to synthetic caption data produced by a large language model without explicit supervision. We show that the pseudo-labels produced by this procedure can be used to train a captioning model to effectively understand human-human interactions in images, as measured by a variety of metrics that measure textual and semantic faithfulness and factual groundedness of our predictions. We further show that our approach outperforms SOTA image captioning and situation recognition models on this task. We will release our c
    
[^27]: LLM的来源跟踪和检测（arXiv:2304.14072v1 [cs.CL]）

    Origin Tracing and Detecting of LLMs. (arXiv:2304.14072v1 [cs.CL])

    [http://arxiv.org/abs/2304.14072](http://arxiv.org/abs/2304.14072)

    本文提出了一种有效的方法来跟踪和检测语言模型（LLMs）生成的AI文本，使其来源可以被容易追踪。这种方法可以在各种LLMs上广泛推广，且仅需要有限的数据量。

    

    大型语言模型（LLMs）具有出色的性能，因此检测上下文是否由AI系统生成变得更为重要。更重要的是，随着越来越多的公司和机构发布自己的LLMs，其来源可能难以追踪。由于LLMs正在朝向AGI的时代前进，类似于人类学中的源追踪，追踪LLMs的来源非常重要。在本文中，我们首先提出了LLMs的来源追踪问题，并提出了一种有效的追踪和检测AI生成内容的方法。我们引入了一种新的算法，利用LLMs之间的对比特征并提取模型特征以追踪文本来源。我们提出的方法在白盒和黑盒设置下均可工作，因此可广泛推广到检测各种LLMs（例如，可以推广到不带GPT-3模型的GPT-3模型）。此外，我们提出的方法与监督学习相比仅需要有限的数据量。

    The extraordinary performance of large language models (LLMs) heightens the importance of detecting whether the context is generated by an AI system. More importantly, while more and more companies and institutions release their LLMs, the origin can be hard to trace. Since LLMs are heading towards the time of AGI, similar to the origin tracing in anthropology, it is of great importance to trace the origin of LLMs. In this paper, we first raise the concern of the origin tracing of LLMs and propose an effective method to trace and detect AI-generated contexts. We introduce a novel algorithm that leverages the contrastive features between LLMs and extracts model-wise features to trace the text origins. Our proposed method works under both white-box and black-box settings therefore can be widely generalized to detect various LLMs.(e.g. can be generalized to detect GPT-3 models without the GPT-3 models). Also, our proposed method requires only limited data compared with the supervised learn
    
[^28]: SweCTRL-Mini：一种基于Transformer的数据透明的大型语言模型，用于控制性文本生成的瑞典语言版

    SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish. (arXiv:2304.13994v1 [cs.CL])

    [http://arxiv.org/abs/2304.13994](http://arxiv.org/abs/2304.13994)

    SweCTRL-Mini是一种基于Transformer的大型瑞典语言模型，用户可以控制它生成的文本流派，完全开放下载。生成能力比较GPT-3。

    

    我们介绍了SweCTRL-Mini，它是一个大规模的瑞典语言模型，可用于单个消费级GPU上的推理和fine-tuning。该模型基于由Keskar、McCann、Varshney、Xiong和Socher（2019）开发的CTRL体系结构，这意味着SweCTRL-Mini模型的用户可以通过在生成提示中插入特殊标记来控制生成文本的流派。SweCTRL-Mini在瑞典部分mC4语料库和一组瑞典小说的子集上进行了训练，我们在本文中提供了(1)所使用的训练数据和文本预处理步骤的详细说明，以使可以检查特定短语/来源是否是训练数据的一部分;(2)使用自动评估方法进行辨别性任务的模型评估，使用人工裁判进行生成性任务的评估;我们还将模型的生成能力与GPT-3的生成能力进行了比较。SweCTRL-Mini 是完全开放的，可供下载。

    We present SweCTRL-Mini, a large Swedish language model that can be used for inference and fine-tuning on a single consumer-grade GPU. The model is based on the CTRL architecture by Keskar, McCann, Varshney, Xiong, and Socher (2019), which means that users of the SweCTRL-Mini model can control the genre of the generated text by inserting special tokens in the generation prompts. SweCTRL-Mini is trained on a subset of the Swedish part of the mC4 corpus and a set of Swedish novels. In this article, we provide (1) a detailed account of the utilized training data and text pre-processing steps, to the extent that it is possible to check whether a specific phrase/source was a part of the training data, and (2) an evaluation of the model on both discriminative tasks, using automatic evaluation methods, and generative tasks, using human referees. We also compare the generative capabilities of the model with those of GPT-3. SweCTRL-Mini is fully open and available for download.
    
[^29]: 跨域评估词性标注器：从华尔街日报到Fandom Wiki

    Cross-Domain Evaluation of POS Taggers: From Wall Street Journal to Fandom Wiki. (arXiv:2304.13989v1 [cs.CL])

    [http://arxiv.org/abs/2304.13989](http://arxiv.org/abs/2304.13989)

    该论文通过创建适度的数据集，使用'Elder Scrolls Fandom'的数据评估了两个在华尔街日报数据集上训练的词性标注器在领域外的表现，并显示它们的表现几乎与领域内相当，但在未知区域表现不佳。两个标注器都难以处理专有名词和不一致的大写形式。

    

    长期以来，Penn Treebank的华尔街日报部分一直是评估词性标注器的事实标准，并且已经报告了97％以上的准确性。然而，关于领域外标注器性能的了解较少，特别是细粒度标签集。我们使用Elder Scrolls Fandom中的数据创建了一个适度的数据集，以定性评估两个词性标注器的跨域性能：Stanford标注器（Toutanova et al.，2003）和Bilty（Plank et al.，2016），它们都是在WSJ上进行训练的。我们的分析表明，在训练中看到的标记的性能几乎与领域内性能一样好，但是未知标记的准确性从90.37％下降到78.37％（斯坦福大学），从87.84％下降到80.41％（Bilty）跨越领域。两个标注器都难以处理专有名词和不一致的大写形式。

    The Wall Street Journal section of the Penn Treebank has been the de-facto standard for evaluating POS taggers for a long time, and accuracies over 97\% have been reported. However, less is known about out-of-domain tagger performance, especially with fine-grained label sets. Using data from Elder Scrolls Fandom, a wiki about the \textit{Elder Scrolls} video game universe, we create a modest dataset for qualitatively evaluating the cross-domain performance of two POS taggers: the Stanford tagger (Toutanova et al. 2003) and Bilty (Plank et al. 2016), both trained on WSJ. Our analyses show that performance on tokens seen during training is almost as good as in-domain performance, but accuracy on unknown tokens decreases from 90.37% to 78.37% (Stanford) and 87.84\% to 80.41\% (Bilty) across domains. Both taggers struggle with proper nouns and inconsistent capitalization.
    
[^30]: 学习和推理多方面和纵向数据，以评估落后地区的印度农村贫困率和生计能力

    Learning and Reasoning Multifaceted and Longitudinal Data for Poverty Estimates and Livelihood Capabilities of Lagged Regions in Rural India. (arXiv:2304.13958v1 [cs.CL])

    [http://arxiv.org/abs/2304.13958](http://arxiv.org/abs/2304.13958)

    该项目旨在综合多种数据源评估1990-2022年印度农村的贫困情况，包括常规的家庭调查、人口普查以及来自卫星图像和通信网络的代理变量。通过将县区划分为不同的区域，确定落后地区并深入研究其导致贫穷的因素。

    

    贫困是一个多方面的现象，与家庭赚取可持续生计的能力不足有关，越来越多地使用多维指标进行评估。其空间模式取决于社会、经济、政治和区域变量。人工智能在分析贫困的复杂性和微妙性方面展示了巨大的潜力。该项目旨在基于生活质量和生计指标，研究1990-2022年印度农村的贫困情况。将县区分类为“先进”、“追赶”、“落后”和“滞后”区域。该项目拟整合多个数据源，包括常规的全国大样本家庭调查、人口普查以及来自卫星图像的日间和夜间数据，通信网络等代理变量，以提供县一级贫困的全面视图。该项目还打算研究导致贫穷的因素。

    Poverty is a multifaceted phenomenon linked to the lack of capabilities of households to earn a sustainable livelihood, increasingly being assessed using multidimensional indicators. Its spatial pattern depends on social, economic, political, and regional variables. Artificial intelligence has shown immense scope in analyzing the complexities and nuances of poverty. The proposed project aims to examine the poverty situation of rural India for the period of 1990-2022 based on the quality of life and livelihood indicators. The districts will be classified into `advanced', `catching up', `falling behind', and `lagged' regions. The project proposes to integrate multiple data sources, including conventional national-level large sample household surveys, census surveys, and proxy variables like daytime, and nighttime data from satellite images, and communication networks, to name a few, to provide a comprehensive view of poverty at the district level. The project also intends to examine caus
    
[^31]: 基于检索的知识增强视觉语言预训练模型

    Retrieval-based Knowledge Augmented Vision Language Pre-training. (arXiv:2304.13923v1 [cs.CV])

    [http://arxiv.org/abs/2304.13923](http://arxiv.org/abs/2304.13923)

    本文提出了一种基于检索的知识增强视觉语言预训练模型，将从知识图谱中检索到的世界知识融入视觉语言预训练中，将明确的知识与视觉语言对融合，通过四个知识感知的自监督任务推动多模态数据和知识的相互整合。

    

    随着大规模视觉和语言表示学习的进展，视觉语言预训练(VLP)模型在各种多模态下游任务中取得了可喜的进展。然而，这些预训练模型仍未利用世界知识，世界知识隐含在多模态数据中，但包含丰富和互补的信息。在本工作中，我们提出了一种REtrieval-based knowledge Augmented Vision Language Pre-training (REAVL)模型，它从知识图谱(KGs)中检索世界知识，并将其融入视觉语言预训练中。

    With recent progress in large-scale vision and language representation learning, Vision Language Pretraining (VLP) models have achieved promising improvements on various multi-modal downstream tasks. Albeit powerful, these pre-training models still do not take advantage of world knowledge, which is implicit in multi-modal data but comprises abundant and complementary information. In this work, we propose a REtrieval-based knowledge Augmented Vision Language Pre-training model (REAVL), which retrieves world knowledge from knowledge graphs (KGs) and incorporates them in vision-language pre-training. REAVL has two core components: a knowledge retriever that retrieves knowledge given multi-modal data, and a knowledge-augmented model that fuses multi-modal data and knowledge. By novelly unifying four knowledge-aware self-supervised tasks, REAVL promotes the mutual integration of multi-modal data and knowledge by fusing explicit knowledge with vision-language pairs for masked multi-modal dat
    
[^32]: 可控的数据增强方法用于上下文相关的文本到SQL转换

    Controllable Data Augmentation for Context-Dependent Text-to-SQL. (arXiv:2304.13902v1 [cs.CL])

    [http://arxiv.org/abs/2304.13902](http://arxiv.org/abs/2304.13902)

    提出了ConDA方法，可以生成交互式问题和相应的SQL结果，并设计了SQL对话状态和过滤方法来增强数据多样性和质量，能够提高复杂问题的性能。

    

    由于标注数据数量有限，标注复杂度高，限制了现有的上下文相关的文本到SQL转换模型的规模。数据增强是解决这个问题的常用方法。然而，当前增强方法产生的数据往往缺乏多样性。在本文中，我们介绍了ConDA，可以生成交互式的问题和相应的SQL结果，设计了SQL对话状态以通过状态转移增强数据多样性，同时，我们还提供了一种基于grounding模型的过滤器方法来确保数据质量。此外，我们利用grounding模型来识别和过滤与状态信息不匹配的低质量问题。在SParC和CoSQL数据集上的实验结果表明，ConDA将基线模型提高了平均 $3.3\%$ 的复杂问题的性能。此外，我们分析了增强数据，发现ConDA生成的数据在SQL模板匹配和语义正确性方面具有高质量。

    The limited scale of annotated data constraints existing context-dependent text-to-SQL models because of the complexity of labeling. The data augmentation method is a commonly used method to solve this problem. However, the data generated by current augmentation methods often lack diversity. In this paper, we introduce ConDA, which generates interactive questions and corresponding SQL results. We designed the SQL dialogue state to enhance the data diversity through the state transition. Meanwhile, we also present a filter method to ensure the data quality by a grounding model. Additionally, we utilize a grounding model to identify and filter low-quality questions that mismatch the state information. Experimental results on the SParC and CoSQL datasets show that ConDA boosts the baseline model to achieve an average improvement of $3.3\%$ on complex questions. Moreover, we analyze the augmented data, which reveals that the data generated by ConDA are of high quality in both SQL template 
    
[^33]: 神经关键词生成：分析与评估

    Neural Keyphrase Generation: Analysis and Evaluation. (arXiv:2304.13883v1 [cs.CL])

    [http://arxiv.org/abs/2304.13883](http://arxiv.org/abs/2304.13883)

    本文分析了三种神经网络模型（T5、CatSeq-Transformer、ExHiRD）在关键词生成任务中的性能和行为，并提出了一个新的评估框架SoftKeyScore来衡量两组关键词的相似度。

    

    关键词生成旨在通过从原始文本中复制（现有关键词）或生成捕捉文本语义意义的新关键词（缺失关键词）来生成话题短语。编码器-解码器模型在此任务中最广泛使用，因为它们具有生成缺失关键词的能力。然而，目前几乎没有对此类模型在关键词生成中的性能和行为进行分析。本文研究了三种强劲模型 T5（基于预训练变压器）、CatSeq-Transformer（非预训练变压器）和 ExHiRD（基于循环神经网络）所展示的各种趋势。我们分析了预测置信度分数、模型校准以及词元位置对关键词生成的影响。此外，我们提出并推动一个新的度量框架SoftKeyScore，通过使用 softscores 来计算部分匹配的相似度来评估两组关键词的相似性。

    Keyphrase generation aims at generating topical phrases from a given text either by copying from the original text (present keyphrases) or by producing new keyphrases (absent keyphrases) that capture the semantic meaning of the text. Encoder-decoder models are most widely used for this task because of their capabilities for absent keyphrase generation. However, there has been little to no analysis on the performance and behavior of such models for keyphrase generation. In this paper, we study various tendencies exhibited by three strong models: T5 (based on a pre-trained transformer), CatSeq-Transformer (a non-pretrained Transformer), and ExHiRD (based on a recurrent neural network). We analyze prediction confidence scores, model calibration, and the effect of token position on keyphrases generation. Moreover, we motivate and propose a novel metric framework, SoftKeyScore, to evaluate the similarity between two sets of keyphrases by using softscores to account for partial matching and 
    
[^34]: SemEval-2023第8项任务中的MasonNLP+：使用知识增强的预训练语言模型从社交媒体中提取医疗问题、经验和声明

    MasonNLP+ at SemEval-2023 Task 8: Extracting Medical Questions, Experiences and Claims from Social Media using Knowledge-Augmented Pre-trained Language Models. (arXiv:2304.13875v1 [cs.CL])

    [http://arxiv.org/abs/2304.13875](http://arxiv.org/abs/2304.13875)

    本研究提出了一种知识增强的预训练语言模型MasonNLP+，能够从社交媒体中提取医疗问题、经验和声明，并在SemEval-2023任务8的两个子任务中取得了最先进的性能。

    

    在在线论坛中，用户分享他们的医疗状况和治疗经验，包括提出声明、提问以及讨论治疗对他们的健康状况的影响。构建可理解这些信息的系统可以有效地监测错误信息的传播并验证用户的声明。 SemEval-2023的第8项任务专注于医学应用，具体包括从社交媒体用户帖子中提取与患者经验和医疗状况相关的实体。 Reddit健康在线交流（RedHot）语料库包含来自与医疗状况相关的subreddit的帖子，带有表征患者经验和医疗状况的注释。在子任务1中，患者经验通过个人经验、问题和声明来描述。在子任务2中，医疗状况通过人群、干预和结果来描述。为自动提取患者经验和医疗状况信息，我们提出了一种知识增强的预训练语言模型MasonNLP+，将领域特定的知识融入预训练过程以提高语言理解能力。我们的方法在SemEval-2023第8项任务的两个子任务中均取得了最先进的性能。

    In online forums like Reddit, users share their experiences with medical conditions and treatments, including making claims, asking questions, and discussing the effects of treatments on their health. Building systems to understand this information can effectively monitor the spread of misinformation and verify user claims. The Task-8 of the 2023 International Workshop on Semantic Evaluation focused on medical applications, specifically extracting patient experience- and medical condition-related entities from user posts on social media. The Reddit Health Online Talk (RedHot) corpus contains posts from medical condition-related subreddits with annotations characterizing the patient experience and medical conditions. In Subtask-1, patient experience is characterized by personal experience, questions, and claims. In Subtask-2, medical conditions are characterized by population, intervention, and outcome. For the automatic extraction of patient experiences and medical condition informatio
    
[^35]: 一个提示和几个示例就足够了吗？使用GPT-4进行数据增强在低资源分类任务中

    Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks. (arXiv:2304.13861v1 [cs.CL])

    [http://arxiv.org/abs/2304.13861](http://arxiv.org/abs/2304.13861)

    本文使用GPT-4和ChatGPT对低资源分类任务进行数据增强，通过简单的提示将小型标记数据集扩充为合成数据集，在保留原始标签分布或平衡分布的情况下，产生了良好的下游性能。在测试集上，GPT-4和ChatGPT表现出出色的零-shot性能，尤其在低资源设置中能够较好地识别罕见类别。

    

    在复杂的低资源领域中，获取和注释数据可能是昂贵和耗时的。我们使用GPT-4和ChatGPT通过简单的提示将小型标记数据集扩充为合成数据集，应用于三个不同的分类任务中，复杂程度各异。对于每个任务，我们随机选择了500个文本作为基本样本，生成了5,000个新的合成样本。我们探索了两种增强策略：一种保留原始标签分布，另一种平衡分布。使用逐步变大的训练样本量，我们分别在真实数据和合成数据上训练和评估了一个1.1亿参数的多语言语言模型。我们还在测试集上测试了GPT-4和ChatGPT的零-shot设置。我们发现GPT-4和ChatGPT在所有任务中都具有很强的零-shot性能。我们发现，使用合成样本增强的数据在下游任务中产生了良好的性能，尤其在识别罕见类别等低资源设置方面表现突出。

    Obtaining and annotating data can be expensive and time-consuming, especially in complex, low-resource domains. We use GPT-4 and ChatGPT to augment small labeled datasets with synthetic data via simple prompts, in three different classification tasks with varying complexity. For each task, we randomly select a base sample of 500 texts to generate 5,000 new synthetic samples. We explore two augmentation strategies: one that preserves original label distribution and another that balances the distribution. Using a progressively larger training sample size, we train and evaluate a 110M parameter multilingual language model on the real and synthetic data separately. We also test GPT-4 and ChatGPT in a zero-shot setting on the test sets. We observe that GPT-4 and ChatGPT have strong zero-shot performance across all tasks. We find that data augmented with synthetic samples yields a good downstream performance, and particularly aids in low-resource settings, such as in identifying rare classes
    
[^36]: 从文献中提取结构化的种子介导金纳米棒生长方法：基于GPT-3的研究

    Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3. (arXiv:2304.13846v1 [physics.app-ph])

    [http://arxiv.org/abs/2304.13846](http://arxiv.org/abs/2304.13846)

    该论文提出了一种通过利用GPT-3语言模型从科学文献中自动化地提取金纳米棒合成信息的方法。这种方法可以实现高通量的探索金纳米棒的种子介导生长过程以及结果。

    

    尽管金纳米棒已经成为研究的热点，但控制它们的形状，从而控制它们的光学特性的途径仍然很大程度上是基于经验的。尽管合成过程中不同试剂物之间的共存和相互作用控制着这些特性，但在实践中，探索合成空间的计算和实验方法可能会极其繁琐或耗费过多时间。因此，我们提出了一种利用科学文献中已经包含的大量合成信息来自动化提取相关结构化数据的方法，以高通量方式探寻金纳米棒种子介导生长过程以及结果。为此，我们使用强大的GPT-3语言模型提出了一种方法，来从非结构化科学文本中提取金纳米棒的结构化多步种子介导生长过程和结果。将GPT-3的提示完成进行微调，以预测JSON文档形式的合成模板。

    Although gold nanorods have been the subject of much research, the pathways for controlling their shape and thereby their optical properties remain largely heuristically understood. Although it is apparent that the simultaneous presence of and interaction between various reagents during synthesis control these properties, computational and experimental approaches for exploring the synthesis space can be either intractable or too time-consuming in practice. This motivates an alternative approach leveraging the wealth of synthesis information already embedded in the body of scientific literature by developing tools to extract relevant structured data in an automated, high-throughput manner. To that end, we present an approach using the powerful GPT-3 language model to extract structured multi-step seed-mediated growth procedures and outcomes for gold nanorods from unstructured scientific text. GPT-3 prompt completions are fine-tuned to predict synthesis templates in the form of JSON docu
    
[^37]: 多方聊天：人类和模型中的群聊对话代理

    Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models. (arXiv:2304.13835v1 [cs.CL])

    [http://arxiv.org/abs/2304.13835](http://arxiv.org/abs/2304.13835)

    本文通过收集和评估多方对话情况，探讨了模型在群体对话中需要具备的技能，发现新数据集MultiLIGHT可以在这个领域带来显着的进展。

    

    当前的对话研究主要研究成对（双方）对话，并没有涉及到多于两个人在一起对话的日常情景。本文使用LIGHT环境构建接地对话来收集和评估多方对话情况。我们对比在新数据集MultiLIGHT上训练的模型和现有的成对训练的对话模型以及带有少量提示的大型语言模型。我们发现，我们将公开发布MultiLIGHT数据集，这将有助于在群体设置中带来显着的改进。

    Current dialogue research primarily studies pairwise (two-party) conversations, and does not address the everyday setting where more than two speakers converse together. In this work, we both collect and evaluate multi-party conversations to study this more general case. We use the LIGHT environment to construct grounded conversations, where each participant has an assigned character to role-play. We thus evaluate the ability of language models to act as one or more characters in such conversations. Models require two skills that pairwise-trained models appear to lack: (1) being able to decide when to talk; (2) producing coherent utterances grounded on multiple characters. We compare models trained on our new dataset to existing pairwise-trained dialogue models, as well as large language models with few-shot prompting. We find that our new dataset, MultiLIGHT, which we will publicly release, can help bring significant improvements in the group setting.
    
[^38]: 使用预训练语言模型的零射多语言词义消歧

    Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models. (arXiv:2304.13803v1 [cs.CL])

    [http://arxiv.org/abs/2304.13803](http://arxiv.org/abs/2304.13803)

    本研究提出了一个使用预训练语言模型的零射多语言词义消歧方法，该方法在无需额外训练或微调的情况下，在XL-WSD数据集的18种语言上实现了超越完全监督基线的召回率。

    

    预训练语言模型（PLMs）学习丰富的跨语言知识，在翻译和多语言词义消歧（WSD）等多种任务上表现良好。本文提出了一项新研究，研究了如何使用上下文词级翻译（C-WLT）捕捉PLMs的跨语言词义能力。我们发现，随着模型大小的增加，PLMs编码更多的跨语言词义知识，并更好地利用上下文来提高WLT性能。在C-WLT的基础上，我们引入了一种零射WSD方法，并在XL-WSD数据集的18种语言上进行了测试。

    Pretrained Language Models (PLMs) learn rich cross-lingual knowledge and can be finetuned to perform well on diverse tasks such as translation and multilingual word sense disambiguation (WSD). However, they often struggle at disambiguating word sense in a zero-shot setting. To better understand this contrast, we present a new study investigating how well PLMs capture cross-lingual word sense with Contextual Word-Level Translation (C-WLT), an extension of word-level translation that prompts the model to translate a given word in context. We find that as the model size increases, PLMs encode more cross-lingual word sense knowledge and better use context to improve WLT performance. Building on C-WLT, we introduce a zero-shot approach for WSD, tested on 18 languages from the XL-WSD dataset. Our method outperforms fully supervised baselines on recall for many evaluation languages without additional training or finetuning. This study presents a first step towards understanding how to best le
    
[^39]: 带有异常案例的微调

    Fine Tuning with Abnormal Examples. (arXiv:2304.13783v1 [cs.CL])

    [http://arxiv.org/abs/2304.13783](http://arxiv.org/abs/2304.13783)

    通过识别出数据集中的异常例子，我们提出了一种系统修剪数据集的方法，这可以使得以这些数据集子集作为训练集微调模型的性能更优。

    

    鉴于众包劳动在自然语言处理数据集中的普遍应用，上述数据集变得越来越大。例如，SQUAD数据集当前已经超过80,000条记录。然而，由于英语的结构相对重复，因此SQUAD数据集上下文中单词频率的分布相对不变。通过测量每个句子与数据集中所有句子频率的共变距离，我们识别出了10,500个例子，为训练创造了更加均匀的分布。在这个例子的子集上微调ELECTRA [4]达到了比在所有87,000个例子上训练的模型更好的性能。因此，我们介绍了一种方法来系统地修剪用于微调的数据集，以提高外部样本的性能。

    Given the prevalence of crowd sourced labor in creating Natural Language processing datasets, these aforementioned sets have become increasingly large. For instance, the SQUAD dataset currently sits at over 80,000 records. However, because the English language is rather repetitive in structure, the distribution of word frequencies in the SQUAD dataset's contexts are relatively unchanged. By measuring each sentences distance from the co-variate distance of frequencies of all sentences in the dataset, we identify 10,500 examples that create a more uniform distribution for training. While fine-tuning ELECTRA [4] on this subset of examples reaches better performance to a model trained on all 87,000 examples. Herein we introduce a methodology for systematically pruning datasets for fine tuning reaching better out of sample performance.
    
[^40]: 一个LLM知道自己在撒谎的内部状态

    The Internal State of an LLM Knows When its Lying. (arXiv:2304.13734v1 [cs.CL])

    [http://arxiv.org/abs/2304.13734](http://arxiv.org/abs/2304.13734)

    该论文研究了LLM生成不准确或虚假信息的问题，提出了一种简单而有效的方法，利用LLM的隐藏层激活来确定语句的真实性。在实验中，该方法表现出较好的检测效果，并有利于提高LLM的可信度。

    

    虽然大型语言模型（LLM）在各种任务中表现出了卓越的性能，但它们（可能）最为突出的缺点是以自信的语气生成不准确或虚假的信息。本文假设LLM的内部状态可以用于揭示一个语句的真实性。因此，我们介绍了一种简单但有效的方法来检测LLM所生成语句的真实性，该方法利用LLM的隐藏层激活来确定语句的真实性。为了训练和评估我们的方法，我们构建了一个包含六个不同主题的数据集，其中包含真实和虚假的语句。一个分类器被训练出来，根据LLM的激活值来检测哪个语句是真实的或虚假的。具体而言，分类器接收LLM为数据集中每个语句生成的激活值作为输入。我们的实验表明，我们检测语句真实性的方法甚至比少量提示方法表现更好，凸显了利用LLM的内部状态来提高其可信度的潜力。

    While Large Language Models (LLMs) have shown exceptional performance in various tasks, their (arguably) most prominent drawback is generating inaccurate or false information with a confident tone. In this paper, we hypothesize that the LLM's internal state can be used to reveal the truthfulness of a statement. Therefore, we introduce a simple yet effective method to detect the truthfulness of LLM-generated statements, which utilizes the LLM's hidden layer activations to determine the veracity of statements. To train and evaluate our method, we compose a dataset of true and false statements in six different topics. A classifier is trained to detect which statement is true or false based on an LLM's activation values. Specifically, the classifier receives as input the activation values from the LLM for each of the statements in the dataset. Our experiments demonstrate that our method for detecting statement veracity significantly outperforms even few-shot prompting methods, highlighting
    
[^41]: 使用指令调整的LLM和潜在扩散模型生成文本到音频

    Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model. (arXiv:2304.13731v1 [eess.AS])

    [http://arxiv.org/abs/2304.13731](http://arxiv.org/abs/2304.13731)

    本研究提出了一种使用指令调整的LLM Flan-T5作为文本编码器和基于潜在扩散模型(LDM)的方法TANGO生成文本到音频(TTA)的新方法，在AudioCaps测试集上表现优于先进的AudioLDM。

    

    最近的大型语言模型(LLM)的巨大规模允许许多有趣的属性，比如，基于指令和思路链的微调，在许多自然语言处理(NLP)任务中显着提高了零次和少量训练样本的性能。受到这些成功的启发，我们采用了这样一种经过指令调整的LLM Flan-T5作为文本编码器，用于文本到音频(TTA)生成任务——目标是根据其文本描述生成音频。之前关于TTA的工作要么预先训练一个联合的文本-音频编码器，要么使用一个非指令调谐的模型，如T5。因此，我们基于潜在扩散模型(LDM)的方法TANGO在AudioCaps测试集上表现出比最先进的AudioLDM更好的大多数指标，并在其余指标上持平，尽管我们使用了63倍小的数据集来训练LDM，并保持文本编码器不变。这种改进可能还归因于采用基于音频压力级的混音训练集增强。

    The immense scale of the recent large language models (LLM) allows many interesting properties, such as, instruction- and chain-of-thought-based fine-tuning, that has significantly improved zero- and few-shot performance in many natural language processing (NLP) tasks. Inspired by such successes, we adopt such an instruction-tuned LLM Flan-T5 as the text encoder for text-to-audio (TTA) generation -- a task where the goal is to generate an audio from its textual description. The prior works on TTA either pre-trained a joint text-audio encoder or used a non-instruction-tuned model, such as, T5. Consequently, our latent diffusion model (LDM)-based approach TANGO outperforms the state-of-the-art AudioLDM on most metrics and stays comparable on the rest on AudioCaps test set, despite training the LDM on a 63 times smaller dataset and keeping the text encoder frozen. This improvement might also be attributed to the adoption of audio pressure level-based sound mixing for training set augmenta
    
[^42]: 发挥LLMs在实践中的力量：ChatGPT及其应用的综述调查

    Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond. (arXiv:2304.13712v1 [cs.CL])

    [http://arxiv.org/abs/2304.13712](http://arxiv.org/abs/2304.13712)

    本文提供了一个LLMs的使用综述，探讨了在各种自然语言处理任务中的使用和限制。

    

    本文为从事下游自然语言处理（NLP）任务的从业人员和最终用户提供了一个全面实用的指南，介绍了如何利用Large Language Models（LLMs）。我们从模型、数据和下游任务的角度提供了LLMs的使用讨论和见解。首先，我们介绍了当前的GPT和BERT样式的LLMs。然后，讨论了预训练数据、训练数据和测试数据的影响。最重要的是，我们详细讨论了大型语言模型在各种自然语言处理任务中的使用和非使用情况，例如知识密集型任务、传统自然语言理解任务、自然语言生成任务、紧急能力以及特定任务的考虑。我们呈现了各种使用和非使用情况，以说明LLMs在实际情况下的实际应用和限制。我们还试图了解数据对于LLMs应用的重要性。

    This paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and BERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a detailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities, and considerations for specific tasks.We present various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. We also try to understand the importance of dat
    
[^43]: 从关联到生成：无监督跨模态映射的纯文本字幕生成

    From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping. (arXiv:2304.13273v1 [cs.CV])

    [http://arxiv.org/abs/2304.13273](http://arxiv.org/abs/2304.13273)

    本研究提出了一种从关联到生成的零-shot方法：通过将图像/视频投影到语言模态并在生成任务中生成描述性字幕。该方法在多个基准数据集上显著优于现有的最先进方法，为无监督跨模态映射提供了一个新的视角，并具有在视频字幕，图像合成和文本到图像生成等领域的潜在应用。

    

    随着以CLIP和ALIGN为代表的视觉-语言预训练模型的发展，CLIP的零-shot能力在图像分类和图像-文本检索等基于关联的视觉任务中取得了重大突破。但是，CLIP难以应用于基于生成的任务。这是由于缺乏解码器架构和生成的预训练任务。我们提出了K最近邻跨模态映射（Knight），一种从关联到生成的零-shot方法。通过窄字幕任务的纯文本无监督预训练来有效地将图像/视频投影到语言模态并在生成任务中生成描述性字幕。实验结果表明，Knight在多个基准数据集上显著优于现有的最先进方法。我们的方法为无监督跨模态映射提供了一个新的视角，并且将在视频字幕，图像合成和文本到图像生成等领域具有潜在应用。

    With the development of Vision-Language Pre-training Models (VLPMs) represented by CLIP and ALIGN, significant breakthroughs have been achieved for association-based visual tasks such as image classification and image-text retrieval by the zero-shot capability of CLIP without fine-tuning. However, CLIP is hard to apply to generation-based tasks. This is due to the lack of decoder architecture and pre-training tasks for generation. Although previous works have created generation capacity for CLIP through additional language models, a modality gap between the CLIP representations of different modalities and the inability of CLIP to model the offset of this gap, which fails the concept to transfer across modalities. To solve the problem, we try to map images/videos to the language modality and generate captions from the language modality. In this paper, we propose the K-nearest-neighbor Cross-modality Mapping (Knight), a zero-shot method from association to generation. With text-only unsu
    
[^44]: 问题回答中的答案类型预测的极限分类

    Extreme Classification for Answer Type Prediction in Question Answering. (arXiv:2304.12395v1 [cs.CL])

    [http://arxiv.org/abs/2304.12395](http://arxiv.org/abs/2304.12395)

    本文提出了使用Transformer模型（XBERT）进行极端多标签分类，通过将KG类型基于问题文本使用结构和语义特征进行聚类，以提高问题回答（QA）系统中语义答案类型预测（SMART）任务的性能，并获得最先进的结果。

    

    语义答案类型预测（SMART）已被证明是有效的问题回答（QA）系统的有用步骤。 SMART任务涉及预测给定自然语言问题的前k个知识图（KG）类型。由于KG中存在大量类型，这是具有挑战性的。在本文中，我们提出使用Transformer模型（XBERT）进行极端多标签分类，通过将KG类型基于问题文本使用结构和语义特征进行聚类。我们具体地改善了XBERT流程的聚类阶段，利用从KG中派生的文本和结构特征。我们表明，这些特征可以提高SMART任务的端到端性能，并产生最先进的结果。

    Semantic answer type prediction (SMART) is known to be a useful step towards effective question answering (QA) systems. The SMART task involves predicting the top-$k$ knowledge graph (KG) types for a given natural language question. This is challenging due to the large number of types in KGs. In this paper, we propose use of extreme multi-label classification using Transformer models (XBERT) by clustering KG types using structural and semantic features based on question text. We specifically improve the clustering stage of the XBERT pipeline using textual and structural features derived from KGs. We show that these features can improve end-to-end performance for the SMART task, and yield state-of-the-art results.
    
[^45]: 基于图神经网络的文本分类综述

    Graph Neural Networks for Text Classification: A Survey. (arXiv:2304.11534v1 [cs.CL])

    [http://arxiv.org/abs/2304.11534](http://arxiv.org/abs/2304.11534)

    该综述介绍了基于图神经网络的文本分类技术，该技术可以直接处理复杂结构化文本数据并利用全局信息。许多真实的文本分类应用程序可以自然地表示为一个图。本综述覆盖到2023年的方法，包括语料库级别和文档级别的图神经网络，并详细讨论了每种方法的图构建机制和基于图的学习过程。涵盖了数据集、评估指标和实验设计，并总结了在公开可用的基准数据集上发布的性能。

    

    文本分类是自然语言处理中最基本和最重要的问题。虽然许多最近的文本分类模型采用了序列深度学习技术，但是基于图神经网络的模型可以直接处理复杂结构化文本数据并利用全局信息。许多真实的文本分类应用程序可以自然地表示为一个图，其中捕获了单词、文档和语料库的全局特征。本综述将覆盖到2023年的方法，包括语料库级别和文档级别的图神经网络。我们详细讨论了每种方法，包括图构建机制和基于图的学习过程。除了技术综述，我们还关注了使用图神经网络进行文本分类的问题和未来方向。我们还涵盖了数据集、评估指标和实验设计，并呈现了在公开可用的基准数据集上发布的性能总结，以更好地了解基于图神经网络的文本分类领域的最新技术发展。

    Text Classification is the most essential and fundamental problem in Natural Language Processing. While numerous recent text classification models applied the sequential deep learning technique, graph neural network-based models can directly deal with complex structured text data and exploit global information. Many real text classification applications can be naturally cast into a graph, which captures words, documents, and corpus global features. In this survey, we bring the coverage of methods up to 2023, including corpus-level and document-level graph neural networks. We discuss each of these methods in detail, dealing with the graph construction mechanisms and the graph-based learning process. As well as the technological survey, we look at issues behind and future directions addressed in text classification using graph neural networks. We also cover datasets, evaluation metrics, and experiment design and present a summary of published performance on the publicly available benchma
    
[^46]: DIN-SQL: 自纠正的文本到SQL分解式上下文学习

    DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction. (arXiv:2304.11015v1 [cs.CL])

    [http://arxiv.org/abs/2304.11015](http://arxiv.org/abs/2304.11015)

    DIN-SQL通过将复杂的文本到SQL任务分解为子问题，并将这些子问题的解决方案馈入到大型语言模型中，显著提高了它们的表现，使准确性超过了当前最先进的技术。

    

    本文研究了将复杂的文本到SQL任务分解为较小的子任务，并且这种分解如何显著提高大型语言模型在推理过程中的表现。我们展示了尽管SQL查询具有声明式结构，但可以将其分解为子问题，并将这些子问题的解决方案馈入到大型语言模型中，从而显著提高它们的表现。我们的实验表明，这种方法能够稳定提高三种大型语言模型的表现，大约提高了10％，将大型语言模型的准确性推向最新水平，并在Holdout Spider数据集上甚至超过了经过精调的大型模型。

    We study the problem of decomposing a complex text-to-sql task into smaller sub-tasks and how such a decomposition can significantly improve the performance of Large Language Models (LLMs) in the reasoning process. There is currently a significant gap between the performance of fine-tuned models and prompting approaches using LLMs on challenging text-to-sql datasets such as Spider. We show that SQL queries, despite their declarative structure, can be broken down into sub-problems and the solutions of those sub-problems can be fed into LLMs to significantly improve their performance. Our experiments with three LLMs show that this approach consistently improves their performance by roughly 10%, pushing the accuracy of LLMs towards state-of-the-art, and even beating large fine-tuned models on the holdout Spider dataset.
    
[^47]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^48]: PheME：一种深度集成框架，可从多模态数据中提高表型预测的准确性

    PheME: A deep ensemble framework for improving phenotype prediction from multi-modal data. (arXiv:2303.10794v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.10794](http://arxiv.org/abs/2303.10794)

    本文提出了PheME，一种利用多模态数据进行表型预测的深度集成框架。该框架采用多个深度神经网络和集成学习，可以从EHR数据中准确且高效地提取表型信息。

    

    详细的表型信息对于疾病的准确诊断和风险评估至关重要。作为表型信息的丰富来源，电子健康记录（EHRs）承诺赋予诊断变异解释的权力。然而，如何从异构的EHR数据中准确高效地提取表型仍然是一个挑战。在本研究中，我们提出了PheME，一种Ensemble框架，使用结构化EHR和非结构化的临床笔记的多模态数据进行准确的表型预测。首先，我们使用多个深度神经网络从稀疏的结构化EHR数据和冗余的临床笔记中学习可靠的表示。多模态模型将多模态特征对齐到同一潜在空间以预测表型。其次，我们利用集成学习来将单模型和多模型的输出相结合，以提高表型预测。我们选择了七种疾病来评估所提出的框架的表型化性能。

    Detailed phenotype information is fundamental to accurate diagnosis and risk estimation of diseases. As a rich source of phenotype information, electronic health records (EHRs) promise to empower diagnostic variant interpretation. However, how to accurately and efficiently extract phenotypes from the heterogeneous EHR data remains a challenge. In this work, we present PheME, an Ensemble framework using Multi-modality data of structured EHRs and unstructured clinical notes for accurate Phenotype prediction. Firstly, we employ multiple deep neural networks to learn reliable representations from the sparse structured EHR data and redundant clinical notes. A multi-modal model then aligns multi-modal features onto the same latent space to predict phenotypes. Secondly, we leverage ensemble learning to combine outputs from single-modal models and multi-modal models to improve phenotype predictions. We choose seven diseases to evaluate the phenotyping performance of the proposed framework. Exp
    
[^49]: 优化算法的符号式发现

    Symbolic Discovery of Optimization Algorithms. (arXiv:2302.06675v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06675](http://arxiv.org/abs/2302.06675)

    该论文提出了一种将算法发现视为程序搜索的方法，并用于发现深度神经网络训练的优化算法。他们的方法发现了一种简单而有效的优化算法Lion，它比Adam更节省内存并且在ImageNet上的准确率提高了2％，并且预训练的计算时间也减少了多达5倍。

    

    我们提出了一种将算法发现视为程序搜索的方法，并应用于发现用于深度神经网络训练的优化算法。我们利用高效搜索技术来探索无限和稀疏的程序空间。为了填补代理任务和目标任务之间巨大的泛化差距，我们还引入了程序选择和简化策略。我们的方法发现了一种简单而有效的优化算法，$ \textbf {Lion} $（$ \textit {Evo $\textbf {L} $ved S $ \textbf {i} $ gn M $ \textbf {o} $ me $ \textbf {n} $ tum} $）。它的记忆效率比Adam更高，因为它只跟踪动量。与自适应优化器不同，通过符号运算计算的每个参数的更新具有相同的大小。我们将Lion与广泛使用的优化器（例如Adam和Adafactor）进行了比较，以在不同任务上训练各种模型。在图像分类中，Lion将在ImageNet上ViT的准确性提高了最多2％，并节省了多达5倍的预训练计算时间。

    We present a method to formulate algorithm discovery as program search, and apply it to discover optimization algorithms for deep neural network training. We leverage efficient search techniques to explore an infinite and sparse program space. To bridge the large generalization gap between proxy and target tasks, we also introduce program selection and simplification strategies. Our method discovers a simple and effective optimization algorithm, $\textbf{Lion}$ ($\textit{Evo$\textbf{L}$ved S$\textbf{i}$gn M$\textbf{o}$me$\textbf{n}$tum}$). It is more memory-efficient than Adam as it only keeps track of the momentum. Different from adaptive optimizers, its update has the same magnitude for each parameter calculated through the sign operation. We compare Lion with widely used optimizers, such as Adam and Adafactor, for training a variety of models on different tasks. On image classification, Lion boosts the accuracy of ViT by up to 2% on ImageNet and saves up to 5x the pre-training compu
    
[^50]: 大型语言模型是多才多艺的分解器：将证据和问题分解为表格推理

    Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning. (arXiv:2301.13808v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13808](http://arxiv.org/abs/2301.13808)

    这篇论文介绍了利用大型语言模型作为分解器，解决基于表格推理中的性能下降和复杂问题的问题，并在多个基准数据集上显著优于现有方法。

    

    基于表格的推理已经在结合深度模型和离散推理方面取得了显著的进展，它需要对自由形式的自然语言问题和结构化表格数据进行推理。然而，以往的基于表格的推理解决方案通常会在海量证据（表格）上遭遇显著的性能退化。此外，大多数现有方法在处理复杂问题时也面临困难，因为所需信息分散在不同的位置。为了缓解上述挑战，我们利用大型语言模型（LLMs）作为有效的基于表格推理的分解器，将（i）巨大的证据（一个巨大的表格）分解成子证据（一个小表格），以减轻无用信息对表格推理的干扰；和（ii）将复杂问题分解成更简单的子问题进行文本推理。具体而言，我们首先使用LLMs分解当前问题涉及的证据（表格），保留相关证据并排除不相关部分。然后，我们使用LLMs将复杂问题重新表述为更简单的子问题，以便更精确地检索每个子问题的相应证据。我们在几个基准数据集上评估了我们的方法，实验结果表明我们的方法显著优于现有的基于表格推理的方法。

    Table-based reasoning has shown remarkable progress in combining deep models with discrete reasoning, which requires reasoning over both free-form natural language (NL) questions and structured tabular data. However, previous table-based reasoning solutions usually suffer from significant performance degradation on huge evidence (tables). In addition, most existing methods struggle to reason over complex questions since the required information is scattered in different places. To alleviate the above challenges, we exploit large language models (LLMs) as decomposers for effective table-based reasoning, which (i) decompose huge evidence (a huge table) into sub-evidence (a small table) to mitigate the interference of useless information for table reasoning; and (ii) decompose complex questions into simpler sub-questions for text reasoning. Specifically, we first use the LLMs to break down the evidence (tables) involved in the current question, retaining the relevant evidence and excludin
    
[^51]: 基于语言引导的世界模型的具身决策制定

    Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making using Language Guided World Modelling. (arXiv:2301.12050v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12050](http://arxiv.org/abs/2301.12050)

    本论文研究使用少量的大型语言模型来提高强化学习代理的样本效率。通过假设抽象世界模型并通过代理的世界经验进行验证，可以进行规划和探索。这种方法不仅可提高样本效率一个数量级，而且还具有稳健性。

    

    强化学习代理通常在没有先前的世界知识的情况下进行学习。然而，如果初始化高层子目标和子目标之间的转换知识，强化学习代理可以利用此抽象世界模型（AWM）进行规划和探索。我们提出使用少量样本的大型语言模型（LLM）来假设AWM，通过世界经验进行验证，以提高强化学习代理的样本效率。我们的DECKARD代理将LLM引导的探索应用于Minecraft中的物品制作，分为两个阶段：（1）梦想阶段，代理使用LLM将任务分解为一系列子目标，即假设的AWM；（2）唤醒阶段，代理为每个子目标学习模块化策略并验证或纠正假设的AWM。我们通过LLMs假设AWM，然后根据代理经验验证AWM的方法不仅可以将样本效率提高一个数量级，而且还具有稳健性。

    Reinforcement learning (RL) agents typically learn tabula rasa, without prior knowledge of the world. However, if initialized with knowledge of high-level subgoals and transitions between subgoals, RL agents could utilize this Abstract World Model (AWM) for planning and exploration. We propose using few-shot large language models (LLMs) to hypothesize an AWM, that will be verified through world experience, to improve sample efficiency of RL agents. Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft in two phases: (1) the Dream phase where the agent uses an LLM to decompose a task into a sequence of subgoals, the hypothesized AWM; and (2) the Wake phase where the agent learns a modular policy for each subgoal and verifies or corrects the hypothesized AWM. Our method of hypothesizing an AWM with LLMs and then verifying the AWM based on agent experience not only increases sample efficiency over contemporary methods by an order of magnitude but is also robust to
    
[^52]: 用OPUS-MT实现神经机器翻译民主化

    Democratizing Neural Machine Translation with OPUS-MT. (arXiv:2212.01936v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01936](http://arxiv.org/abs/2212.01936)

    本文介绍了OPUS-MT生态系统的发展，包括开放式机器翻译模型和工具的开发，以及它们与最终用户应用程序、开发平台和专业工作流程的整合。通过增加语言覆盖范围和翻译质量，实现了神经机器翻译的民主化。

    

    本文介绍了OPUS生态系统，重点介绍开放式机器翻译模型和工具的开发，以及它们与最终用户应用程序、开发平台和专业工作流程的整合。我们讨论了我们正在进行的增加语言覆盖范围和翻译质量的任务，还描述了正在进行的工作，包括模块化翻译模型的开发和面向常规桌面和小型设备实现实时翻译的速度优化紧凑解决方案。

    This paper presents the OPUS ecosystem with a focus on the development of open machine translation models and tools, and their integration into end-user applications, development platforms and professional workflows. We discuss our on-going mission of increasing language coverage and translation quality, and also describe on-going work on the development of modular translation models and speed-optimized compact solutions for real-time translation on regular desktops and small devices.
    
[^53]: 沟通破裂：人类和神经字幕之间的低互通性

    Communication breakdown: On the low mutual intelligibility between human and neural captioning. (arXiv:2210.11512v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.11512](http://arxiv.org/abs/2210.11512)

    研究表明，给定相同的字幕，神经图像检索器的性能比人类要高得多，而人类在给定相同的神经字幕时的表现几乎与随机无异。

    

    我们比较了基于神经字幕的图像检索器的0-shot表现，当输入人类制作的字幕或神经字幕生成的字幕时。我们在最近推出的ImageCoDe数据集上进行了这个比较(Krojer等人，2022)，该数据集包含与待检索图像几乎相同的难以区分的干扰项。我们发现，当输入神经字幕而不是人类字幕时，神经检索器的性能要高得多，尽管前者不像后者那样在生成时意识到任务变得困难的干扰项。更为明显的是，当将相同的神经字幕提供给人类受试者时，它们的检索表现几乎处于随机水平。因此，我们的研究结果是对越来越多的证据的补充，即即使神经模型的“语言”类似于英语，这种表面上的类似可能是非常误导性的。

    We compare the 0-shot performance of a neural caption-based image retriever when given as input either human-produced captions or captions generated by a neural captioner. We conduct this comparison on the recently introduced ImageCoDe data-set (Krojer et al., 2022) which contains hard distractors nearly identical to the images to be retrieved. We find that the neural retriever has much higher performance when fed neural rather than human captions, despite the fact that the former, unlike the latter, were generated without awareness of the distractors that make the task hard. Even more remarkably, when the same neural captions are given to human subjects, their retrieval performance is almost at chance level. Our results thus add to the growing body of evidence that, even when the ``language'' of neural models resembles English, this superficial resemblance might be deeply misleading.
    
[^54]: 上下文生成提高开放领域问答的效果

    Context Generation Improves Open Domain Question Answering. (arXiv:2210.06349v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06349](http://arxiv.org/abs/2210.06349)

    该论文提出了一个两阶段的闭式问答框架，首先通过生成上下文来提取相关知识，然后使用这个知识回答问题，实验证明该方法在三个问答基准测试上明显优于以往的封闭式问答方法，并且与开放式方法持平。

    

    封闭式问答需要模型在没有任何外部知识的情况下直接回答开放式领域的问题。以往的封闭式问答工作要么将预训练语言模型（LM）直接微调，要么通过提示信息来利用存储的知识。但它们没有充分利用参数化知识。为解决这个问题，我们提出了一个两阶段的闭式问答框架，它采用粗略到精细的方法来提取相关知识和回答问题。我们的方法首先通过提示预先训练的LM生成针对给定问题的相关上下文。然后，我们再使用这个LM通过生成的上下文和问题提示答案预测。此外，为了消除上下文不确定性带来的错误，我们还对生成的上下文进行了边际化处理。在三个问答基准测试上的实验结果表明，我们的方法明显优于以前的封闭式问答方法（如精确匹配 68.6% 对 55.3%），且与开放式方法持平。

    Closed-book question answering (QA) requires a model to directly answer an open-domain question without access to any external knowledge. Prior work on closed-book QA either directly finetunes or prompts a pretrained language model (LM) to leverage the stored knowledge. However, they do not fully exploit the parameterized knowledge. To address this issue, we propose a two-stage, closed-book QA framework which employs a coarse-to-fine approach to extract relevant knowledge and answer a question. Our approach first generates a related context for a given question by prompting a pretrained LM. We then prompt the same LM for answer prediction using the generated context and the question. Additionally, to eliminate failure caused by context uncertainty, we marginalize over generated contexts. Experimental results on three QA benchmarks show that our method significantly outperforms previous closed-book QA methods (e.g. exact matching 68.6% vs. 55.3%), and is on par with open-book methods th
    
[^55]: 并行性掉价：对对数精度Transformer的限制

    The Parallelism Tradeoff: Limitations of Log-Precision Transformers. (arXiv:2207.00729v4 [cs.CC] UPDATED)

    [http://arxiv.org/abs/2207.00729](http://arxiv.org/abs/2207.00729)

    证明了在对数精度下，Transformer的计算能力存在限制，这是因为Transformer架构的高并行性使其遵守一个基本的并行性掉价，即模型架构越可并行化，就越会受到精度的限制。

    

    尽管Transformer神经网络在现代自然语言处理中无处不在，但描述其计算能力仍然是一个有趣的开放问题。我们证明了，在输入令牌数的对数精度下（且其前馈网络可使用其输入的线性空间计算），可以通过常数深度的对数空间均匀阈值电路来模拟Transformer。这提供了使用复杂性理论中已知结果来了解Transformer功率的见解。例如，如果$\mathsf L \neq \mathsf P$（即，不是所有的多项式时间问题都可以使用对数空间解决），那么Transformer甚至不能准确地解决线性等式或检查任意无上下文文法的成员资格。我们的结果从Transformer架构的高并行性中直观地出现。因此，我们猜测地介绍了一个基本的并行性掉价的想法：任何像Transformer一样可并行化的模型架构都将遵守精度的限制，而具有更高精度的模型将固有地不太可并行化。

    Despite their omnipresence in modern NLP, characterizing the computational power of transformer neural nets remains an interesting open question. We prove that transformers whose arithmetic precision is logarithmic in the number of input tokens (and whose feedforward nets are computable using space linear in their input) can be simulated by constant-depth logspace-uniform threshold circuits. This provides insight on the power of transformers using known results in complexity theory. For example, if $\mathsf L \neq \mathsf P$ (i.e., not all poly-time problems can be solved using logarithmic space), then transformers cannot even accurately solve linear equalities or check membership in an arbitrary context-free grammar with empty productions. Our result intuitively emerges from the transformer architecture's high parallelizability. We thus speculatively introduce the idea of a fundamental parallelism tradeoff: any model architecture as parallelizable as the transformer will obey limitati
    
[^56]: 通过交互式问卷进行基于偏好的会议探索的PREME

    PREME: Preference-based Meeting Exploration through an Interactive Questionnaire. (arXiv:2205.02370v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.02370](http://arxiv.org/abs/2205.02370)

    本论文提出了一个新的端到端框架，通过生成交互式问卷，实现基于偏好的会议探索，帮助用户快速探索会议内容。

    

    在线会议的数量不断增加，需要自动化工具来管理和组织材料，特别是当参与者错过讨论并需要帮助快速探索时。本文提出了一种新的端到端框架，用于生成基于偏好的会议探索的交互式问卷。结果，用户会获得一个推荐问题列表，以反映他们的偏好。由于这项任务是新的，我们引入了一种自动评估策略。即，它通过度量通过问卷生成的问题有多少可回答来确保事实的正确性，并为探索源会议的深度提供了覆盖。

    The recent increase in the volume of online meetings necessitates automated tools for managing and organizing the material, especially when an attendee has missed the discussion and needs assistance in quickly exploring it. In this work, we propose a novel end-to-end framework for generating interactive questionnaires for preference-based meeting exploration. As a result, users are supplied with a list of suggested questions reflecting their preferences. Since the task is new, we introduce an automatic evaluation strategy. Namely, it measures how much the generated questions via questionnaire are answerable to ensure factual correctness and covers the source meeting for the depth of possible exploration.
    
[^57]: BiTimeBERT: 利用双重时间信息扩展预训练语言表示

    BiTimeBERT: Extending Pre-Trained Language Representations with Bi-Temporal Information. (arXiv:2204.13032v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.13032](http://arxiv.org/abs/2204.13032)

    本论文介绍了一种新颖的语言表示模型BiTimeBERT，使用长跨度时间新闻文章集合构建单词表示，并通过两个新的预训练任务，利用两个不同的时间信号构建时间感知的语言表示。BiTimeBERT在时间相关任务中具有显著性能优势。

    

    时间是文档的重要方面，并在各种NLP和IR任务中使用。本文研究了在预训练期间引入时间信息的方法，以进一步提高在时间相关任务上的性能。与利用同步文档集合（例如BookCorpus和Wikipedia）作为训练语料库的常见预训练语言模型BERT相比，我们使用长跨度时间新闻文章集合来构建单词表示。我们介绍了一种新颖的语言表示模型BiTimeBERT，在时间新闻文章集合上通过两个新的预训练任务进行训练，利用两个不同的时间信号构建时间感知的语言表示。实验结果表明，BiTimeBERT始终优于BERT和其他现有的预训练模型，在时间重要的不同下游NLP任务和应用中获得了显著的性能提升（例如与BERT相比，准确性提高了155％）。

    Time is an important aspect of documents and is used in a range of NLP and IR tasks. In this work, we investigate methods for incorporating temporal information during pre-training to further improve the performance on time-related tasks. Compared with common pre-trained language models like BERT which utilize synchronic document collections (e.g., BookCorpus and Wikipedia) as the training corpora, we use long-span temporal news article collection for building word representations. We introduce BiTimeBERT, a novel language representation model trained on a temporal collection of news articles via two new pre-training tasks, which harnesses two distinct temporal signals to construct time-aware language representations. The experimental results show that BiTimeBERT consistently outperforms BERT and other existing pre-trained models with substantial gains on different downstream NLP tasks and applications for which time is of importance (e.g., the accuracy improvement over BERT is 155\% o
    
[^58]: GrIPS：基于编辑的无梯度指令搜索，用于辅助大型语言模型

    GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models. (arXiv:2203.07281v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.07281](http://arxiv.org/abs/2203.07281)

    GrIPS是一种基于编辑的无梯度搜索方法，用于改进大型语言模型的任务指令，显著提高性能。

    

    提供自然语言指令的提示是一种改进大型语言模型在零样本设置下任务性能的有用新范例。最近的工作致力于通过手动重写或梯度调整来提高这些提示。然而，手动重写耗时且需要主观解释，而基于梯度的调整对于大型模型而言计算成本极高，对于基于API的模型来说可能不可行。在这项工作中，我们介绍了Gradient-free Instructional Prompt Search (GrIPS)，一种基于编辑的无梯度搜索方法，用于改进大型语言模型的任务指令。GrIPS接受面向人类设计的指令，并自动返回完善的编辑提示，同时允许基于API的调整。使用InstructGPT模型，在自然语言指令数据集的八个分类任务上，GrIPS将平均任务性能提高了高达4.30个百分点（OPT，BLOOM等任务也有类似的改进）

    Providing natural language instructions in prompts is a useful new paradigm for improving task performance of large language models in a zero-shot setting. Recent work has aimed to improve such prompts via manual rewriting or gradient-based tuning. However, manual rewriting is time-consuming and requires subjective interpretation, while gradient-based tuning can be extremely computationally demanding for large models and may not be feasible for API-based models. In this work, we introduce Gradient-free Instructional Prompt Search (GrIPS), a gradient-free, edit-based search approach for improving task instructions for large language models. GrIPS takes in instructions designed for humans and automatically returns an improved, edited prompt, while allowing for API-based tuning. With InstructGPT models, GrIPS improves the average task performance by up to 4.30 percentage points on eight classification tasks from the Natural Instructions dataset (with similar improvements for OPT, BLOOM, a
    

