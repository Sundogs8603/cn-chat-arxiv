# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Zero Resource Code-switched Speech Benchmark Using Speech Utterance Pairs For Multiple Spoken Languages.](http://arxiv.org/abs/2310.03018) | 本论文介绍了一个新的零资源切换语音基准，用于评估自监督语音编码器的切换语言能力，研究了预训练语言和模型大小对基准性能的影响，结果显示多语言预训练的语音编码器在切换语言场景中表现优于单语变体，但仍有改进空间。 |
| [^2] | [Multimodal Question Answering for Unified Information Extraction.](http://arxiv.org/abs/2310.03017) | 本研究提出了一种多模态问答（MQA）框架，通过统一三种多模态信息提取任务，通过重新组合成统一的抽取回答范围和多选题问答管道。实验证明，该框架在各种现成的大规模多模态模型上显著提高了性能，并在零样本和少样本设置下超过了最先进的基线模型。 |
| [^3] | [Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions.](http://arxiv.org/abs/2310.03016) | 这项工作通过实验发现，变压器可以学习各种实值函数的基于梯度的学习算法，但对于更复杂的任务性能下降。另外，该研究还探讨了这些能力在基于注意力模型中的限制程度以及推广到预训练的大型语言模型（LLM）的可行性。 |
| [^4] | [From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference.](http://arxiv.org/abs/2310.03003) | 该论文研究了大型语言模型推理的计算和能源利用情况，以帮助节约成本、提高性能和优化推理策略。 |
| [^5] | [ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models.](http://arxiv.org/abs/2310.02998) | ECoFLaP提出了一种高效的粗到细的逐层剪枝方法，解决了大型视觉语言模型在压缩和部署时的计算和能耗问题。 |
| [^6] | [Kosmos-G: Generating Images in Context with Multimodal Large Language Models.](http://arxiv.org/abs/2310.02992) | 本文介绍了Kosmos-G，一种利用多模态大型语言模型（MLLM）在上下文中生成图像的模型。该模型通过使用文本模态作为锚点，将MLLM的输出空间与CLIP对齐，并进行组合指令调整。Kosmos-G展示了零样本多实体主题驱动生成的独特能力。 |
| [^7] | [xVal: A Continuous Number Encoding for Large Language Models.](http://arxiv.org/abs/2310.02989) | xVal是一种连续数字编码方案，通过使用单个标记来表示任何实数。与现有的数字编码方案相比，xVal更加高效，并且在泛化性能上表现更好。 |
| [^8] | [Scaling Laws for Associative Memories.](http://arxiv.org/abs/2310.02984) | 本文研究了应用于联想记忆中的缩放定律，通过高维矩阵和嵌入的外积来模拟内层Transformer语言模型。作者推导出了与样本数量和参数大小相关的精确缩放定律，并验证了理论结果的有效性。同时，作者还通过大量实验展示了存储记忆关联的细粒度可视化。 |
| [^9] | [Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors.](http://arxiv.org/abs/2310.02980) | 本文研究表明使用随机初始化会导致对架构差异的严重高估，而使用标准消噪目标进行预训练可以在多种架构上实现显著的性能提升，并将Transformers与状态空间模型之间的差距缩小到很小。与之前的研究不同的是，我们发现当正确预训练时，普通的Transformers在Long Range Arena上的性能与S4相匹配，并且在PathX-256任务上改进了SSMs的最佳结果20个百分点。 |
| [^10] | [T$^3$Bench: Benchmarking Current Progress in Text-to-3D Generation.](http://arxiv.org/abs/2310.02977) | T$^3$Bench是第一个综合的文本到3D基准测试，它包含了多个复杂程度的文本提示，并引入了两个自动度量标准来评估生成的3D场景的主观质量和文本对齐性能。 |
| [^11] | [UniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network.](http://arxiv.org/abs/2310.02973) | 这项研究提出了一种单一的多任务学习模型"UniverSLU"，通过利用预训练的自动语音识别模型和不同的任务和数据集指定器作为离散提示，成功地在多个口语理解任务上取得了有竞争力的性能，并且甚至超过了特定任务的模型。 |
| [^12] | [Prompting and Adapter Tuning for Self-supervised Encoder-Decoder Speech Model.](http://arxiv.org/abs/2310.02971) | 这篇论文介绍了为自监督编码器-解码器语音模型进行提示和适配器调优的方法，并展示了在序列生成和跨语言ASR任务上的优越表现，尤其在低资源情况下提示方法优于适配器调优。 |
| [^13] | [DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning.](http://arxiv.org/abs/2310.02954) | 本研究引入了DQ-LoRe框架，它通过双重查询和低秩近似重新排序自动选择用于上下文学习的示例，在复杂推理任务中展示了出色的性能和效果。 |
| [^14] | [JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning.](http://arxiv.org/abs/2310.02953) | JsonTuning是一种面向通用、强大和可控的指令调优方法，通过利用JSON的结构化特性，帮助模型理解任务要素及其关系，从而扩展了通用性、提高了稳健性，并增强了对输出的控制。 |
| [^15] | [Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models.](http://arxiv.org/abs/2310.02949) | 该论文探讨了阴影对齐这种新的攻击方式，通过调整少量恶意示例，安全对齐的语言模型可以被轻松颠覆生成有害的内容，同时仍然可以正确响应常规查询。 |
| [^16] | [LibriSpeech-PC: Benchmark for Evaluation of Punctuation and Capitalization Capabilities of end-to-end ASR Models.](http://arxiv.org/abs/2310.02943) | 本文介绍了一个名为LibriSpeech-PC的基准测试，用于评估端到端ASR模型的标点和大写预测能力。该基准测试包括一个带有恢复标点和大写符号的数据集，以及一种针对标点符号评估的新型评估指标Punctuation Error Rate（PER），并提供了初步的基线模型。 |
| [^17] | [Assessing Large Language Models on Climate Information.](http://arxiv.org/abs/2310.02932) | 本研究提出了一个基于科学传播原则的综合评估框架，评估了大规模语言模型在气候变化信息中的表现，能够在回答气候变化主题方面提供细粒度的分析。 |
| [^18] | [Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers.](http://arxiv.org/abs/2310.02905) | 该论文提出了一种使用神经探测器和转换器优化指令的方法，以提高大型语言模型的性能。 |
| [^19] | [Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation.](http://arxiv.org/abs/2310.02876) | 本文提出了一种在有限数据环境中进行仇恨言论检测的数据增强方法，通过合成数据生成技术解决了缺乏训练数据的问题。研究通过在一种资源丰富的语言中合成新的仇恨言论数据示例，使得检测系统能够在其他语言环境中进行有效的分类任务。 |
| [^20] | [Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation.](http://arxiv.org/abs/2310.02842) | 本论文提出了一种使用智能多任务适应混合提示的方法来解决LLM在处理异质任务和数据分布时的问题。研究者设计了智能门控功能，用于识别嵌入在不同提示组中的相关技能，并根据目标任务的需求动态分配组合专家。该方法对任何模型压缩技术都不受限制，提高了任务处理的效率。 |
| [^21] | [DOMINO: A Dual-System for Multi-step Visual Language Reasoning.](http://arxiv.org/abs/2310.02804) | 本文提出了一种用于多步骤多模态推理的双系统，其中一个系统用于提取视觉信息，另一个系统用于有意推理。这种方法可以避免模型在一个步骤回答复杂问题或被转换文本中的误导信息困扰。 |
| [^22] | [Low Resource Summarization using Pre-trained Language Models.](http://arxiv.org/abs/2310.02790) | 通过自注意力变压器架构模型和构建基线数据集，我们提出了一种适用于低资源语言摘要的方法，并通过在低资源语言乌尔都语中的新闻应用领域的实现来证明其可行性。 |
| [^23] | [A UMLS-Augmented Framework for Improving Factuality in Large Language Models within Healthcare.](http://arxiv.org/abs/2310.02778) | 该论文提出了一个基于UMLS的增强型大型语言模型框架，旨在改善医疗保健领域中模型生成内容的事实性。通过自动评估和医生评估，研究人员验证了该框架的有效性。 |
| [^24] | [The Role of Linguistic Priors in Measuring Compositional Generalization of Vision-Language Models.](http://arxiv.org/abs/2310.02777) | 本文研究了视觉语言模型组合泛化的一种重要属性：语言先验。研究发现当前的改进方法主要依赖于语言先验而忽视了图像中的信息。研究还提出了一种新的不依赖于语言先验的组合性度量方法。 |
| [^25] | [Comparative Study and Framework for Automated Summariser Evaluation: LangChain and Hybrid Algorithms.](http://arxiv.org/abs/2310.02759) | 本研究关注自动摘要评估的比较研究和框架，通过使用LangChain和混合算法对PDF文档进行摘要和提取关键信息，以确定用户对摘要内容的理解程度如何。 |
| [^26] | [LC-Score: Reference-less estimation of Text Comprehension Difficulty.](http://arxiv.org/abs/2310.02754) | 本文提出了一种无参考评估文本理解困难度的简单方法LC-Score，可以用于法语文本，该方法可以预测给定文本在0到100范围内的易读程度。这个方法可以帮助作家们创作易于理解的内容，并提供度量标准来评估自动化文本简化模型的发展。 |
| [^27] | [AGIR: Automating Cyber Threat Intelligence Reporting with Natural Language Generation.](http://arxiv.org/abs/2310.02655) | AGIR是一种专门解决网络威胁情报报告领域挑战的自然语言生成工具，通过自动化生成全面的情报报告，帮助安全分析师减少繁重任务。 |
| [^28] | [I$^2$KD-SLU: An Intra-Inter Knowledge Distillation Framework for Zero-Shot Cross-Lingual Spoken Language Understanding.](http://arxiv.org/abs/2310.02594) | I$^2$KD-SLU是一种内外知识蒸馏框架，用于解决零样本跨语言口语理解中意图和词槽之间的相互指导问题。 |
| [^29] | [Improving Automatic VQA Evaluation Using Large Language Models.](http://arxiv.org/abs/2310.02567) | 提出使用大型语言模型改进自动视觉问答（VQA）评估的方法，将VQA评估格式化为回答评分任务，通过指令调整大型语言模型在准确度上评分候选答案，证明该方法与人类判断相关性优于现有度量方法。 |
| [^30] | [NOLA: Networks as Linear Combination of Low Rank Random Basis.](http://arxiv.org/abs/2310.02556) | 该论文介绍了一种名为NOLA的方法，该方法通过将网络表示为低秩随机基向量的线性组合来减少语言模型的参数数量，从而实现高效的适应和存储。 |
| [^31] | [CITING: Large Language Models Create Curriculum for Instruction Tuning.](http://arxiv.org/abs/2310.02527) | 本文提出了一种利用大型语言模型作为指导教师来训练学生语言模型的方法，通过设计课程来进行指导调优，称为CITING。该方法通过教师模型制定评分标准，学生模型通过遵循评分标准和自我纠正进行学习。该方法可以解决手工制作指导数据集和人工对齐的瓶颈问题。 |
| [^32] | [ResidualTransformer: Residual Low-rank Learning with Weight-sharing for Transformer Layers.](http://arxiv.org/abs/2310.02489) | 本文提出了一种名为ResidualTransformer的方法，通过重新参数化Transformer编码器层之间的模型权重，将模型的大小减小。实验结果表明，ResidualTransformer的性能优于传统Transformer模型，且模型大小得到了显著减小。 |
| [^33] | [Large Language Models Can Be Good Privacy Protection Learners.](http://arxiv.org/abs/2310.02469) | 本论文介绍了一种名为隐私保护语言模型（PPLM）的新范式，可以在保护数据隐私的同时有效注入领域特定知识。通过对模型设计的理论分析和不同技术的研究，我们验证了使用正向和负向示例进行指令微调的方法具有很大的潜力。 |
| [^34] | [The Empty Signifier Problem: Towards Clearer Paradigms for Operationalising "Alignment" in Large Language Models.](http://arxiv.org/abs/2310.02457) | 本文通过后结构主义社会政治理论的视角，探讨了大型语言模型(LLMs)中的“对齐”概念，并提出了一个框架来明确操作化这种抽象概念，促进透明和批判性评估的文化。 |
| [^35] | [Backdoor Adjustment of Confounding by Provenance for Robust Text Classification of Multi-institutional Clinical Notes.](http://arxiv.org/abs/2310.02451) | 本研究评估了在多机构临床笔记数据集中使用后门调整进行文本分类的效果，结果表明后门调整对解决源特定数据分布差异导致的模型性能下降问题具有实用性。 |
| [^36] | [Low-Resource Languages Jailbreak GPT-4.](http://arxiv.org/abs/2310.02446) | 通过翻译不安全的英文输入成低资源语言，我们成功绕过了GPT-4的安全机制，并展示了这种跨语言漏洞。这一方法在实验中取得了与甚至超过了最先进的越狱攻击的效果，揭示了低资源语言在AI安全性中的薄弱环节。 |
| [^37] | [Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions.](http://arxiv.org/abs/2310.02439) | 本研究提出了一种基于数学误解的评估方法，测试大型语言模型在数学推理能力上的表现。与传统评估方法不同，我们通过模拟初学者和专家导师的角色来识别错误答案和相应的误解。实验结果表明，虽然大型语言模型可以正确回答问题，但在识别误解方面存在困难。 |
| [^38] | [Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions.](http://arxiv.org/abs/2310.02431) | 本研究测量了大型语言模型(LLMs)反驳常见的安全和隐私误解的能力。通过研究学术文献，整理了六个主题的一百多个与安全和隐私相关的误解。然后，通过查询两个流行的LLMs并制定标注指南，评估它们的回应。 |
| [^39] | [Can a student Large Language Model perform as well as it's teacher?.](http://arxiv.org/abs/2310.02421) | 这篇论文总结了知识蒸馏技术，并强调了其关键原理和成功要素，以及在资源受限环境中的部署挑战。同时，论文还指出知识蒸馏有潜力成为关键的技术转折点。 |
| [^40] | [Mixture of Quantized Experts (MoQE): Complementary Effect of Low-bit Quantization and Robustness.](http://arxiv.org/abs/2310.02410) | 本文提出了一种量化专家混合（MoQE）方法，通过将专家权重应用2位低位量化，减轻了大规模专家混合（MoE）模型在内存消耗和延迟问题上的压力，同时在大多数情况下不需要额外训练也能保持可靠的模型性能。 |
| [^41] | [Nugget 2D: Dynamic Contextual Compression for Scaling Decoder-only Language Models.](http://arxiv.org/abs/2310.02409) | Nugget 2D是一种用于仅解码器语言模型的动态上下文压缩方法，可以在保留任务能力的同时大幅减少解码过程所需的时间和空间开销。 |
| [^42] | [MindTheDApp: A Toolchain for Complex Network-Driven Structural Analysis of Ethereum-based Decentralised Applications.](http://arxiv.org/abs/2310.02408) | MindTheDApp是一种特别设计用于以太坊基于去中心化应用程序的结构分析的工具链，采用复杂的网络驱动方法，通过生成二分图来突出DApp架构的操作效率，以及提供了细粒度视图来展示相互依赖关系和执行流程。 |
| [^43] | [Unsupervised Speech Recognition with N-Skipgram and Positional Unigram Matching.](http://arxiv.org/abs/2310.02382) | 引入了一种新颖的无监督语音识别系统ESPUM，利用低阶N-skipgrams和位置序列统计信息，在ASR和音素分割任务中展示出竞争性性能。 |
| [^44] | [Conversational Health Agents: A Personalized LLM-Powered Agent Framework.](http://arxiv.org/abs/2310.02374) | 该论文介绍了一个基于LLM的会话式健康代理框架，旨在为代理赋予批判性思维、知识获取和问题解决能力，实现个性化的健康护理服务。该框架能够无缝集成医疗工具，实现多语言和多模态对话，并与多种用户数据分析工具连接。 |
| [^45] | [ProtoNER: Few shot Incremental Learning for Named Entity Recognition using Prototypical Networks.](http://arxiv.org/abs/2310.02372) | ProtoNER是一种基于原型网络的端到端KVP提取模型，可以在现有模型中添加新类别，而只需最少数量的新注释训练样本。 |
| [^46] | [On the definition of toxicity in NLP.](http://arxiv.org/abs/2310.02357) | 这项研究探讨了毒性的定义模糊性问题，并提出了一种基于定量压力的毒性定义来弥补现有定义的缺点。 |
| [^47] | [Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation.](http://arxiv.org/abs/2310.02304) | 本文提出了一种自学优化器（STOP），通过递归自我改进的代码生成，使用融合了语言模型的脚手架程序来改进自身，从而生成性能更好的程序。 |
| [^48] | [End-to-End Continuous Speech Emotion Recognition in Real-life Customer Service Call Center Conversations.](http://arxiv.org/abs/2310.02281) | 本研究介绍了一个用于实时客服呼叫中心对话中连续语音情感识别的大规模数据集CusEmo，采用维度情感注释方法捕捉情感的微妙、复杂和连续性，并解决了应用于数据集时的挑战。 |
| [^49] | [Who's Harry Potter? Approximate Unlearning in LLMs.](http://arxiv.org/abs/2310.02238) | 本文介绍了一种新的技术，用于从LLM中遗忘特定的训练数据，而无需重新训练模型。通过在Llama2-7b模型上的实验，我们证明了在短时间的微调中，我们可以有效地擦除模型关于哈利·波特相关内容的能力，同时保持其在其他常见基准测试上的性能几乎不变。 |
| [^50] | [OceanGPT: A Large Language Model for Ocean Science Tasks.](http://arxiv.org/abs/2310.02031) | OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。 |
| [^51] | [Effective and Parameter-Efficient Reusing Fine-Tuned Models.](http://arxiv.org/abs/2310.01886) | 本文提出了一种有效且参数高效的方法，可以重复使用微调模型来处理下游任务，减轻存储和服务负担，并提出了PERU-FFT方法用于重复使用全面微调模型。 |
| [^52] | [Preserving Phonemic Distinctions for Ordinal Regression: A Novel Loss Function for Automatic Pronunciation Assessment.](http://arxiv.org/abs/2310.01839) | 这项研究提出了一种新的损失函数，用于训练自动发音评估模型。该损失函数旨在在保持音位类别之间更好的音位差异的同时，考虑到回归目标输出的有序关系。通过引入音位-区分正则化器，该方法可以有效提高发音评估的准确度。 |
| [^53] | [LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples.](http://arxiv.org/abs/2310.01469) | LLM似乎具有丰富的知识和适应多种任务的能力，但我们不能完全信任它们的回答，因为它们会出现幻觉，即捏造不存在的事实以欺骗用户。本文证明了由随机标记组成的无意义提示也能引起LLM产生幻觉回应，并提出了一种对抗方式的自动幻觉触发方法作为幻觉攻击，同时提出了一种简单而有效的防御策略。 |
| [^54] | [The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs.](http://arxiv.org/abs/2310.01468) | 本文提供了一个评估框架，通过向法官提出一系列查询来评估LLMs的对话推理和规划能力。我们发现不同的LLMs在这个任务上表现出显著差异。 |
| [^55] | [Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2310.00648) | 本文研究了参数高效微调（PEFT）的安全性问题，发现PEFT易受特洛伊攻击。通过提出一种新的攻击方式PETA，并在各种下游任务和触发器设计中进行广泛测试，发现PETA能够在攻击成功率和未受影响的准确性方面取得有效结果。 |
| [^56] | [ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving.](http://arxiv.org/abs/2309.17452) | ToRA是一种集成工具的数学问题求解推理代理，通过结合语言的分析能力和工具的计算效率，能够显著提高数学推理的性能，在多个数学推理数据集上取得了13%-19%的平均绝对改进率，并在竞赛级数据集MATH上达到了44.6%的性能。 |
| [^57] | [DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models.](http://arxiv.org/abs/2309.14509) | 本论文介绍了DeepSpeed-Ulysses，一种用于实现具备极长序列长度的高效可扩展LLM训练的新颖方法。 |
| [^58] | [Investigating the Catastrophic Forgetting in Multimodal Large Language Models.](http://arxiv.org/abs/2309.10313) | 本论文针对多模态大规模语言模型中的灾难性遗忘问题进行研究，引入了EMT方法来评估灾难性遗忘，并发现在标准图像分类任务上，几乎所有评估的模型都无法保持与视觉编码器相同的性能水平。研究结果表明，早期微调阶段对性能至关重要。 |
| [^59] | [Sparse Autoencoders Find Highly Interpretable Features in Language Models.](http://arxiv.org/abs/2309.08600) | 本研究通过稀疏自编码器在语言模型中发现了一组高度可解释和单一义的特征，从而解决了神经网络内部多义性的问题。 |
| [^60] | [Quantifying Uncertainty in Answers from any Language Model via Intrinsic and Extrinsic Confidence Assessment.](http://arxiv.org/abs/2308.16175) | 本文引入了BSDetector，一种用于检测预训练大型语言模型生成的错误和推测性回答的方法。该方法通过估计置信度量化了回答的不确定性，并在闭合型和开放型问答基准实验中表现出更准确的识别能力。 |
| [^61] | [Instruction Tuning for Large Language Models: A Survey.](http://arxiv.org/abs/2308.10792) | 本文调查了指令调优这一关键技术在增强大型语言模型能力和可控性方面的研究工作，包括方法、数据集构建、模型训练和应用，以及对结果影响的分析。同时回顾了可能的问题和批评，并指出了目前的不足。 |
| [^62] | [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework.](http://arxiv.org/abs/2308.08155) | AutoGen是一种新的框架，通过多个可以互相对话的代理，实现了下一代LLM应用。它利用人类的理解和智能，优雅地处理不完美的生成和推理能力，并通过自动化代理对话简化了复杂的工作流程。 |
| [^63] | [L-Eval: Instituting Standardized Evaluation for Long Context Language Models.](http://arxiv.org/abs/2307.11088) | 该论文提出了L-Eval，旨在为长文本语言模型引入标准化评估。通过开发一个包含411个长文档和2000多个人工标注的查询-回复对的数据集，研究探讨了扩展上下文对于处理长输入的实质性收益和改进程度。 |
| [^64] | [FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets.](http://arxiv.org/abs/2307.10928) | FLASK是一种基于对齐技能集的细粒度语言模型评估协议，通过将粗级评分分解为每个指令的技能集级评分，实现了对模型性能的全面视角和提高评估的可靠性。 |
| [^65] | [ValiTex -- a uniform validation framework for computational text-based measures of social science constructs.](http://arxiv.org/abs/2307.02863) | ValiTex是一个统一的验证框架，旨在帮助学者们基于文本数据来度量社会科学构建。它借鉴了心理测量学的传统，通过概念模型和动态检查表提供了验证的结构和步骤。 |
| [^66] | [Named Entity Inclusion in Abstractive Text Summarization.](http://arxiv.org/abs/2307.02570) | 该论文提出了一种解决抽象文本摘要中命名实体遗漏问题的方法，通过使用定制的预训练目标和模型训练策略，改善了命名实体的包含情况，提高了摘要的准确性和召回率。 |
| [^67] | [MedCPT: Contrastive Pre-trained Transformers with Large-scale PubMed Search Logs for Zero-shot Biomedical Information Retrieval.](http://arxiv.org/abs/2307.00589) | MedCPT是一种用于生物医学领域零样本语义信息检索的对比预训练转换器模型。通过使用大规模PubMed搜索日志进行训练，MedCPT在六个生物医学信息检索任务中创造了新的最佳性能，超过了其他基线模型，同时还能生成更好的生物医学文章和句子。 |
| [^68] | [Deductive Verification of Chain-of-Thought Reasoning.](http://arxiv.org/abs/2306.03872) | 本文旨在通过应用演绎验证技术，使语言模型能够进行明确而严谨的演绎推理，以确保其推理过程的可信度。 |
| [^69] | [RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems.](http://arxiv.org/abs/2306.03091) | RepoBench是一个评估代码自动补全系统在代码库级别上性能的基准，支持Python和Java，包含三个相互关联的评估任务。它旨在填补当前基准在多文件编程场景方面的评估差距，并为不同系统的性能提供更全面的比较。 |
| [^70] | [LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization.](http://arxiv.org/abs/2306.01102) | 本文介绍了利用大语言模型和多样性优化算法相结合的 LLMatic 神经结构搜索算法。该算法在CIFAR-10数据集进行测试，仅进行2000次搜索即可产生高性能网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。 |
| [^71] | [AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration.](http://arxiv.org/abs/2306.00978) | AWQ是一种激活感知的权重量化方法，通过保护少量显著权重来降低量化误差，不依赖于反向传播或重构，并在语言建模和领域特定任务上优于现有方法。 |
| [^72] | [DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text.](http://arxiv.org/abs/2305.17359) | DNA-GPT是一种无需训练的检测策略，通过Divergent N-Gram分析来发现机器生成文本与人类写作文本之间的显著差异。 |
| [^73] | [Text Conditional Alt-Text Generation for Twitter Images.](http://arxiv.org/abs/2305.14779) | 本文针对Twitter上分享的图像提出了一种文本条件下的替代文本生成方法。通过CLIP前缀模型，该模型结合图像和推文中的文本信息，生成关于图像的上下文相关的替代文本。 |
| [^74] | [A Parameter-Efficient Learning Approach to Arabic Dialect Identification with Pre-Trained General-Purpose Speech Model.](http://arxiv.org/abs/2305.11244) | 本文介绍了一种利用预训练通用语音模型进行阿拉伯方言识别的参数高效学习方法，通过残差适配器和模型重编程，设计了一个基于记号的标签映射，并在ADI-17数据集上实现了最高精度，同时使用PEL方法进一步减少了训练成本。 |
| [^75] | [Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models.](http://arxiv.org/abs/2305.10276) | 本文提出了自然语言规划（NLP）的基准，旨在研究LLMs在需要理解并在文本中相应进行操作的复杂规划任务中的表现。同时提出了一种新方法CoS，使用简化的符号空间表示法来表示复杂的环境。 |
| [^76] | [Self-supervised Neural Factor Analysis for Disentangling Utterance-level Speech Representations.](http://arxiv.org/abs/2305.08099) | 本文提出了一种自监督神经因子分析模型，使用HuBERT中的聚类方法来发现隐藏的声学单元，并使用这些单元对齐SSL模型的特征，从而产生解耦后的语音表示，从而为专门任务提供了一种基于Utterance水平的无监督学习目标。实验结果表明，SSNFA模型在说话人识别、语言识别和情感识别等各种任务中均显著优于现有的SSL模型，并且没有任何特定任务的微调或监督。 |
| [^77] | [Personalize Segment Anything Model with One Shot.](http://arxiv.org/abs/2305.03048) | 本文提出了一种无需训练的SAM个性化方法PerSAM，只需要一张带有参考掩模的单张图像即可定位和分割目标概念，还提出了高效的一次性微调变体PerSAM-F，旨在解决掩模不确定性问题。 |
| [^78] | [Technical report: Graph Neural Networks go Grammatical.](http://arxiv.org/abs/2303.01590) | 本文介绍了一种将代数语言片段与图神经网络形式上联系的框架，并从MATLANG定义了一个符合3-WL测试的语法，进而得出一个符合3-WL GNN模型的G$^2$N$^2$。此外，语法方法还提供了计算长度为六及以下的环和弦环的代数公式，并在多个下游任务中取得优秀的表现。 |
| [^79] | [A Large-Scale Analysis of Persian Tweets Regarding Covid-19 Vaccination.](http://arxiv.org/abs/2302.04511) | 本文利用Twitter数据进行了对伊朗公众对COVID-19疫苗的意见进行的全面分析，结果显示该疫苗引起了广泛关注，涉及政府问题、安全性、犹豫不决和副作用等方面。 |
| [^80] | [Double Permutation Equivariance for Knowledge Graph Completion.](http://arxiv.org/abs/2302.01313) | 本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。 |
| [^81] | [Alternating Updates for Efficient Transformers.](http://arxiv.org/abs/2301.13310) | 本文介绍了一种交替更新（AltUp）的方法，可以在不增加计算负担的情况下增加模型的容量，通过对扩展表示的子块进行操作并使用预测和修正机制来更新未激活的块。实验证明AltUp方法在提高Transformer模型的容量和效率方面是有效的。 |
| [^82] | [A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding.](http://arxiv.org/abs/2301.03403) | 本文提供了关于自动文本摘要系统的综述，包括方法、数据、评估和编码。作者通过引用的方式回顾了相关文献，并介绍了不同的摘要生成方法。此外，还对可用于评估和数据训练的数据集进行了综述，并使用CNN语料库数据集对方法进行了实证探索。 |
| [^83] | [Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger.](http://arxiv.org/abs/2206.07136) | 本论文提出了一种自动剪辑的替代方案，它消除了为差分隐私优化器调整剪辑阈值的需要，并在非凸情况下进行了收敛性分析。在多个任务中证明了自动剪辑的优势。 |
| [^84] | [One Sense per Translation.](http://arxiv.org/abs/2106.06082) | 本文提出了一种基于翻译的词义消歧方法，通过定义一对一翻译（OSPT）的关键属性，实现了高达93％的精确度以及最高4.6％的WSD改进。 |

# 详细

[^1]: 使用语音语句对的零资源切换语音基准进行多语言评估

    Zero Resource Code-switched Speech Benchmark Using Speech Utterance Pairs For Multiple Spoken Languages. (arXiv:2310.03018v1 [eess.AS])

    [http://arxiv.org/abs/2310.03018](http://arxiv.org/abs/2310.03018)

    本论文介绍了一个新的零资源切换语音基准，用于评估自监督语音编码器的切换语言能力，研究了预训练语言和模型大小对基准性能的影响，结果显示多语言预训练的语音编码器在切换语言场景中表现优于单语变体，但仍有改进空间。

    

    我们引入了一个新的零资源切换语音基准，旨在直接评估自监督语音编码器的切换语言能力。我们展示了一种基于离散单元语言建模的基线系统，以展示如何以零资源的方式评估语音编码器的切换语言能力。我们的实验涵盖了各种知名的语音编码器，包括Wav2vec 2.0、HuBERT、XLSR等。我们研究了预训练语言和模型大小对基准性能的影响。值得注意的是，尽管我们的结果表明，在切换语言场景中，具有多语言预训练的语音编码器（例如XLSR）优于单语变体（Wav2vec 2.0、HuBERT），但它们的切换语言能力仍有很大的改进空间。

    We introduce a new zero resource code-switched speech benchmark designed to directly assess the code-switching capabilities of self-supervised speech encoders. We showcase a baseline system of language modeling on discrete units to demonstrate how the code-switching abilities of speech encoders can be assessed in a zero-resource manner. Our experiments encompass a variety of well-known speech encoders, including Wav2vec 2.0, HuBERT, XLSR, etc. We examine the impact of pre-training languages and model size on benchmark performance. Notably, though our results demonstrate that speech encoders with multilingual pre-training, exemplified by XLSR, outperform monolingual variants (Wav2vec 2.0, HuBERT) in code-switching scenarios, there is still substantial room for improvement in their code-switching linguistic abilities.
    
[^2]: 统一信息提取的多模态问答

    Multimodal Question Answering for Unified Information Extraction. (arXiv:2310.03017v1 [cs.CL])

    [http://arxiv.org/abs/2310.03017](http://arxiv.org/abs/2310.03017)

    本研究提出了一种多模态问答（MQA）框架，通过统一三种多模态信息提取任务，通过重新组合成统一的抽取回答范围和多选题问答管道。实验证明，该框架在各种现成的大规模多模态模型上显著提高了性能，并在零样本和少样本设置下超过了最先进的基线模型。

    

    多模态信息提取旨在从非结构化的多媒体内容中提取结构化信息。由于任务和设置的多样性，大多数现有的多模态信息提取模型都是特定于任务和数据密集型的，这限制了它们在具有各种任务需求和有限标注数据的现实场景中的泛化能力。为了解决这些问题，我们提出了一种新颖的多模态问答（MQA）框架，通过将其重新组合成统一的框架提取回答范围并进行多选题问答。对六个数据集进行的大量实验表明：1）与基准提示相比，我们的MQA框架在多模态信息提取任务上始终显著提高各种现成的大规模多模态模型（LMM）的性能。2）在零样本设置下，MQA比先前的最先进基线模型有很大优势。此外，我们的框架的有效性可以成功地转化为少样本设置，提升了规模为10B参数的LMMs。

    Multimodal information extraction (MIE) aims to extract structured information from unstructured multimedia content. Due to the diversity of tasks and settings, most current MIE models are task-specific and data-intensive, which limits their generalization to real-world scenarios with diverse task requirements and limited labeled data. To address these issues, we propose a novel multimodal question answering (MQA) framework to unify three MIE tasks by reformulating them into a unified span extraction and multi-choice QA pipeline. Extensive experiments on six datasets show that: 1) Our MQA framework consistently and significantly improves the performances of various off-the-shelf large multimodal models (LMM) on MIE tasks, compared to vanilla prompting. 2) In the zero-shot setting, MQA outperforms previous state-of-the-art baselines by a large margin. In addition, the effectiveness of our framework can successfully transfer to the few-shot setting, enhancing LMMs on a scale of 10B param
    
[^3]: 通过学习离散函数来理解变压器和LLM中的上下文学习现象

    Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions. (arXiv:2310.03016v1 [cs.LG])

    [http://arxiv.org/abs/2310.03016](http://arxiv.org/abs/2310.03016)

    这项工作通过实验发现，变压器可以学习各种实值函数的基于梯度的学习算法，但对于更复杂的任务性能下降。另外，该研究还探讨了这些能力在基于注意力模型中的限制程度以及推广到预训练的大型语言模型（LLM）的可行性。

    

    为了理解上下文学习现象，最近的工作采用了规范化的实验框架，并证明了变压器可以学习各种实值函数的基于梯度的学习算法。然而，变压器在实现学习算法方面的限制以及它们学习其他形式算法的能力还不清楚。此外，这些能力在基于注意力模型中的限制程度也不明确。此外，尚不清楚从这些规范化设置中得出的见解是否能推广到预训练的大型语言模型（LLM）。在这项工作中，我们通过以下方式向这些问题迈进：（a）在一个包含各种布尔函数类的测试平台上，我们发现变压器几乎可以与“较简单”任务的最优学习算法相匹配，但在“较复杂”任务上其性能下降。此外，我们还发现

    In order to understand the in-context learning phenomenon, recent works have adopted a stylized experimental framework and demonstrated that Transformers can learn gradient-based learning algorithms for various classes of real-valued functions. However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood. Additionally, the degree to which these capabilities are confined to attention-based models is unclear. Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs). In this work, we take a step towards answering these questions by demonstrating the following: (a) On a test-bed with a variety of Boolean function classes, we find that Transformers can nearly match the optimal learning algorithm for 'simpler' tasks, while their performance deteriorates on more 'complex' tasks. Additionally, we find th
    
[^4]: 从单词到瓦特：大型语言模型推理的能源成本基准测试

    From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference. (arXiv:2310.03003v1 [cs.CL])

    [http://arxiv.org/abs/2310.03003](http://arxiv.org/abs/2310.03003)

    该论文研究了大型语言模型推理的计算和能源利用情况，以帮助节约成本、提高性能和优化推理策略。

    

    大型语言模型(LLMs)由于其超越以往最先进水平的新生成能力而迅速受到欢迎。这些技术越来越多地在法律、金融和医学等领域得到应用。然而，这些模型带来了显著的计算挑战，特别是推理所需的计算和能源成本。尽管现实中经常需要这些大型模型进行推理(例如ChatGPT)，但推理能源成本却比LLMs的训练能源成本得到了较少关注。随着这些最先进的LLMs在各个领域的使用和部署越来越多，更好地理解它们的资源利用对于节约成本、提高性能、高效利用硬件和优化推理策略至关重要。在本文中，我们描述了进行的实验，以研究使用LLMs进行推理的计算和能源利用情况。我们进行了基准测试并进行了初步分析。

    Large language models (LLMs) have exploded in popularity due to their new generative capabilities that go far beyond prior state-of-the-art. These technologies are increasingly being leveraged in various domains such as law, finance, and medicine. However, these models carry significant computational challenges, especially the compute and energy costs required for inference. Inference energy costs already receive less attention than the energy costs of training LLMs -- despite how often these large models are called on to conduct inference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see increasing usage and deployment in various domains, a better understanding of their resource utilization is crucial for cost-savings, scaling performance, efficient hardware usage, and optimal inference strategies.  In this paper, we describe experiments conducted to study the computational and energy utilization of inference with LLMs. We benchmark and conduct a preliminary analysis of t
    
[^5]: ECoFLaP: 高效的粗到细的逐层剪枝方法用于视觉语言模型

    ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models. (arXiv:2310.02998v1 [cs.CV])

    [http://arxiv.org/abs/2310.02998](http://arxiv.org/abs/2310.02998)

    ECoFLaP提出了一种高效的粗到细的逐层剪枝方法，解决了大型视觉语言模型在压缩和部署时的计算和能耗问题。

    

    大型视觉语言模型（LVLMs）通过整合不同模态的丰富信息，全面理解世界，并在各种多模态下游任务上取得显著的性能提升。然而，由于其巨大的计算/能耗和碳排放，部署LVLMs往往存在问题。这些问题使得采用传统的迭代全局剪枝变得不可行，因为其需要计算整个大型模型的Hessian矩阵以进行稀疏化。相反，最近的研究提出了逐层剪枝方法，避免了全局剪枝的昂贵计算，并根据层内权重的重要性有效压缩模型。然而，这些方法常常由于缺乏全局视角而导致模型压缩不够优化。为了解决大型模型最近高效剪枝方法的这一局限性，我们提出了高效的粗到细的逐层剪枝方法（ECoFLaP）。

    Large Vision-Language Models (LVLMs) can understand the world comprehensively by integrating rich information from different modalities, achieving remarkable performance improvements on various multimodal downstream tasks. However, deploying LVLMs is often problematic due to their massive computational/energy costs and carbon consumption. Such issues make it infeasible to adopt conventional iterative global pruning, which is costly due to computing the Hessian matrix of the entire large model for sparsification. Alternatively, several studies have recently proposed layer-wise pruning approaches to avoid the expensive computation of global pruning and efficiently compress model weights according to their importance within a layer. However, these methods often suffer from suboptimal model compression due to their lack of a global perspective. To address this limitation in recent efficient pruning methods for large models, we propose Efficient Coarse-to-Fine Layer-Wise Pruning (ECoFLaP), 
    
[^6]: Kosmos-G：使用多模态大型语言模型在上下文中生成图像

    Kosmos-G: Generating Images in Context with Multimodal Large Language Models. (arXiv:2310.02992v1 [cs.CV])

    [http://arxiv.org/abs/2310.02992](http://arxiv.org/abs/2310.02992)

    本文介绍了Kosmos-G，一种利用多模态大型语言模型（MLLM）在上下文中生成图像的模型。该模型通过使用文本模态作为锚点，将MLLM的输出空间与CLIP对齐，并进行组合指令调整。Kosmos-G展示了零样本多实体主题驱动生成的独特能力。

    

    最近，在文本到图像（T2I）和视觉语言到图像（VL2I）生成方面取得了显著进展。然而，从通用的视觉语言输入生成图像，特别是涉及多个图像的情况，仍然未被充分探索。本文提出了Kosmos-G，该模型利用多模态大型语言模型（MLLMs）的先进感知能力来解决上述挑战。我们的方法通过使用文本模态作为锚点，将MLLM的输出空间与CLIP对齐，并在策划数据上进行组合指令调整。Kosmos-G展示了零样本多实体主题驱动生成的独特能力。值得注意的是，分数蒸馏指令调整对图像解码器不需要进行任何修改。这允许无缝替代CLIP并轻松集成各种U-Net技术，包括细粒度控制和个性化图像解码器变体。

    Recent advancements in text-to-image (T2I) and vision-language-to-image (VL2I) generation have made significant strides. However, the generation from generalized vision-language inputs, especially involving multiple images, remains under-explored. This paper presents Kosmos-G, a model that leverages the advanced perception capabilities of Multimodal Large Language Models (MLLMs) to tackle the aforementioned challenge. Our approach aligns the output space of MLLM with CLIP using the textual modality as an anchor and performs compositional instruction tuning on curated data. Kosmos-G demonstrates a unique capability of zero-shot multi-entity subject-driven generation. Notably, the score distillation instruction tuning requires no modifications to the image decoder. This allows for a seamless substitution of CLIP and effortless integration with a myriad of U-Net techniques ranging from fine-grained controls to personalized image decoder variants. We posit Kosmos-G as an initial attempt to
    
[^7]: xVal: 大型语言模型的连续数字编码

    xVal: A Continuous Number Encoding for Large Language Models. (arXiv:2310.02989v1 [stat.ML])

    [http://arxiv.org/abs/2310.02989](http://arxiv.org/abs/2310.02989)

    xVal是一种连续数字编码方案，通过使用单个标记来表示任何实数。与现有的数字编码方案相比，xVal更加高效，并且在泛化性能上表现更好。

    

    由于数字令牌化的独特困难，大型语言模型尚未广泛用于科学数据集的分析。我们提出了xVal，一种数字编码方案，可以使用单个标记来表示任何实数。xVal通过将专用嵌入向量按数字值进行缩放来表示给定的实数。结合修改后的数字推断方法，该策略使模型在考虑作为从输入字符串的数字到输出字符串的数字的映射时成为端到端连续的。这导致了一种更适用于科学领域应用的归纳偏差。我们在许多合成和现实世界数据集上进行了实证评估。与现有的数字编码方案相比，我们发现xVal在令牌效率和泛化性能上表现更好。

    Large Language Models have not yet been broadly adapted for the analysis of scientific datasets due in part to the unique difficulties of tokenizing numbers. We propose xVal, a numerical encoding scheme that represents any real number using just a single token. xVal represents a given real number by scaling a dedicated embedding vector by the number value. Combined with a modified number-inference approach, this strategy renders the model end-to-end continuous when considered as a map from the numbers of the input string to those of the output string. This leads to an inductive bias that is generally more suitable for applications in scientific domains. We empirically evaluate our proposal on a number of synthetic and real-world datasets. Compared with existing number encoding schemes, we find that xVal is more token-efficient and demonstrates improved generalization.
    
[^8]: 缩放定律在联想记忆中的应用

    Scaling Laws for Associative Memories. (arXiv:2310.02984v1 [stat.ML])

    [http://arxiv.org/abs/2310.02984](http://arxiv.org/abs/2310.02984)

    本文研究了应用于联想记忆中的缩放定律，通过高维矩阵和嵌入的外积来模拟内层Transformer语言模型。作者推导出了与样本数量和参数大小相关的精确缩放定律，并验证了理论结果的有效性。同时，作者还通过大量实验展示了存储记忆关联的细粒度可视化。

    

    学习很可能涉及到抽象规则的发现和记忆。本文旨在研究联想记忆机制。我们的模型基于高维矩阵，由嵌入的外积组成，与Transformer语言模型的内层相关。我们推导出关于样本数量和参数规模的精确缩放定律，并讨论了不同估计器的统计效率，包括基于优化的算法。我们进行了大量的数值实验，以验证和解释理论结果，包括对存储记忆关联的细粒度可视化。

    Learning arguably involves the discovery and memorization of abstract rules. The aim of this paper is to study associative memory mechanisms. Our model is based on high-dimensional matrices consisting of outer products of embeddings, which relates to the inner layers of transformer language models. We derive precise scaling laws with respect to sample size and parameter size, and discuss the statistical efficiency of different estimators, including optimization-based algorithms. We provide extensive numerical experiments to validate and interpret theoretical results, including fine-grained visualizations of the stored memory associations.
    
[^9]: 永远不要从头开始训练：公正比较长序列模型需要数据驱动的先验知识

    Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors. (arXiv:2310.02980v1 [cs.LG])

    [http://arxiv.org/abs/2310.02980](http://arxiv.org/abs/2310.02980)

    本文研究表明使用随机初始化会导致对架构差异的严重高估，而使用标准消噪目标进行预训练可以在多种架构上实现显著的性能提升，并将Transformers与状态空间模型之间的差距缩小到很小。与之前的研究不同的是，我们发现当正确预训练时，普通的Transformers在Long Range Arena上的性能与S4相匹配，并且在PathX-256任务上改进了SSMs的最佳结果20个百分点。

    

    建模序列之间的长程依赖一直是机器学习中的目标，并导致了一些架构，如状态空间模型，在处理长序列时比Transformers有显著的优势。然而，这些令人印象深刻的经验性进展主要是在随机初始化并通过预测输入序列的目标标签进行训练的基准测试（例如Long Range Arena）上展示出来的。在这项工作中，我们展示了随机初始化导致对架构之间差异的严重高估，并且使用标准消噪目标进行预训练（仅使用下游任务数据）可以在多种架构上实现显著的收益，并且可以在Transformers和状态空间模型（SSMs）之间得到很小的差距。与之前的研究形成鲜明对比的是，我们发现当正确预训练时，普通的Transformers在Long Range Arena上与S4的性能相匹配，并且我们在PathX-256任务上将SSMs的最佳报告结果提高了20个百分点。

    Modeling long-range dependencies across sequences is a longstanding goal in machine learning and has led to architectures, such as state space models, that dramatically outperform Transformers on long sequences. However, these impressive empirical gains have been by and large demonstrated on benchmarks (e.g. Long Range Arena), where models are randomly initialized and trained to predict a target label from an input sequence. In this work, we show that random initialization leads to gross overestimation of the differences between architectures and that pretraining with standard denoising objectives, using $\textit{only the downstream task data}$, leads to dramatic gains across multiple architectures and to very small gaps between Transformers and state space models (SSMs). In stark contrast to prior works, we find vanilla Transformers to match the performance of S4 on Long Range Arena when properly pretrained, and we improve the best reported results of SSMs on the PathX-256 task by 20 
    
[^10]: T$^3$Bench：标注目前在文本到3D生成领域的进展的基准测试（arXiv:2310.02977v1 [cs.CV]）

    T$^3$Bench: Benchmarking Current Progress in Text-to-3D Generation. (arXiv:2310.02977v1 [cs.CV])

    [http://arxiv.org/abs/2310.02977](http://arxiv.org/abs/2310.02977)

    T$^3$Bench是第一个综合的文本到3D基准测试，它包含了多个复杂程度的文本提示，并引入了两个自动度量标准来评估生成的3D场景的主观质量和文本对齐性能。

    

    近期的文本到3D方法利用强大的预训练扩散模型来优化NeRF。值得注意的是，这些方法能够在没有3D数据训练的情况下生成高质量的3D场景。由于任务的开放性，大多数研究通过主观案例研究和用户实验证明其结果，从而在定量上回答“文本到3D的当前进展如何？”这个问题上存在挑战。在本文中，我们介绍了T$^3$Bench，这是一个第一个综合的文本到3D基准测试，包含三个不断增加复杂性的文本提示，专门为3D生成而设计。为了评估主观质量和文本对齐性，我们提出了基于3D内容产生的多视图图像的两个自动度量标准。质量度量结合了多视图文本-图像分数和区域卷积以检测质量和视角不一致性。对齐度量使用多视图字幕和大型语言模型（LLM）e

    Recent methods in text-to-3D leverage powerful pretrained diffusion models to optimize NeRF. Notably, these methods are able to produce high-quality 3D scenes without training on 3D data. Due to the open-ended nature of the task, most studies evaluate their results with subjective case studies and user experiments, thereby presenting a challenge in quantitatively addressing the question: How has current progress in Text-to-3D gone so far? In this paper, we introduce T$^3$Bench, the first comprehensive text-to-3D benchmark containing diverse text prompts of three increasing complexity levels that are specially designed for 3D generation. To assess both the subjective quality and the text alignment, we propose two automatic metrics based on multi-view images produced by the 3D contents. The quality metric combines multi-view text-image scores and regional convolution to detect quality and view inconsistency. The alignment metric uses multi-view captioning and Large Language Model (LLM) e
    
[^11]: UniverSLU:单个网络用于多样分类和序列生成任务的通用口语理解

    UniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network. (arXiv:2310.02973v1 [cs.CL])

    [http://arxiv.org/abs/2310.02973](http://arxiv.org/abs/2310.02973)

    这项研究提出了一种单一的多任务学习模型"UniverSLU"，通过利用预训练的自动语音识别模型和不同的任务和数据集指定器作为离散提示，成功地在多个口语理解任务上取得了有竞争力的性能，并且甚至超过了特定任务的模型。

    

    最近的研究表明，采用具备多任务能力的大型语言模型可以取得良好的效果。它们利用提示来引导模型的行为，并且超越了特定任务模型的性能。受此启发，我们问：我们能否构建一个单一模型来共同执行各种口语理解任务？为了解决这个问题，我们利用预训练的自动语音识别（ASR）模型，并采用不同的任务和数据集指定器作为离散提示。我们展示了我们的单一多任务学习（MTL）模型"UniverSLU"在12个不同的语音分类和序列生成任务上的有效性，涵盖了17个数据集和9种语言。结果表明，UniverSLU取得了有竞争力的性能，甚至超过了特定任务的模型。我们还进行了初步研究，探索了使用人类可解释的自然短语代替任务指定器作为离散提示，并测试了模型对新释义的泛化能力。

    Recent studies have demonstrated promising outcomes by employing large language models with multi-tasking capabilities. They utilize prompts to guide the model's behavior and surpass performance of task-specific models. Motivated by this, we ask: can we build a single model that jointly perform various spoken language understanding (SLU) tasks? To address this, we utilize pre-trained automatic speech recognition (ASR) models and employ various task and dataset specifiers as discrete prompts. We demonstrate efficacy of our single multi-task learning (MTL) model "UniverSLU" for 12 different speech classification and sequence generation tasks across 17 datasets and 9 languages. Results show that UniverSLU achieves competitive performance and even surpasses task-specific models. We also conduct preliminary investigations into enabling human-interpretable natural phrases instead of task specifiers as discrete prompts and test the model's generalization capabilities to new paraphrases.
    
[^12]: 为自监督编码器-解码器语音模型进行提示和适配器调优的方法

    Prompting and Adapter Tuning for Self-supervised Encoder-Decoder Speech Model. (arXiv:2310.02971v1 [eess.AS])

    [http://arxiv.org/abs/2310.02971](http://arxiv.org/abs/2310.02971)

    这篇论文介绍了为自监督编码器-解码器语音模型进行提示和适配器调优的方法，并展示了在序列生成和跨语言ASR任务上的优越表现，尤其在低资源情况下提示方法优于适配器调优。

    

    提示和适配器调优已经成为细调（FT）方法的有效替代品。然而，现有的关于语音提示的研究主要集中在分类任务上，并在更复杂的序列生成任务上失败。此外，适配器调优主要应用于仅编码器的自监督模型。我们的实验证明，在Wav2Seq这个自监督的编码器-解码器模型上进行提示，超过了以前在序列生成任务上的研究成果。它在ASR的词错误率上实现了53％的相对改进，在槽填充的F1分数上实现了27％的改进。此外，在低资源情况下提示方法与FT方法相竞争。此外，我们展示了在Wav2Seq上通过提示和适配器调优实现的跨语言ASR的可转移性。当涉及有限的可训练参数时，提示和适配器调优始终优于传统的FT方法在7种语言中的表现。值得注意的是，在低资源情况下，提示方法始终优于适配器调优。

    Prompting and adapter tuning have emerged as efficient alternatives to fine-tuning (FT) methods. However, existing studies on speech prompting focused on classification tasks and failed on more complex sequence generation tasks. Besides, adapter tuning is primarily applied with a focus on encoder-only self-supervised models. Our experiments show that prompting on Wav2Seq, a self-supervised encoder-decoder model, surpasses previous works in sequence generation tasks. It achieves a remarkable 53% relative improvement in word error rate for ASR and a 27% in F1 score for slot filling. Additionally, prompting competes with the FT method in the low-resource scenario. Moreover, we show the transferability of prompting and adapter tuning on Wav2Seq in cross-lingual ASR. When limited trainable parameters are involved, prompting and adapter tuning consistently outperform conventional FT across 7 languages. Notably, in the low-resource scenario, prompting consistently outperforms adapter tuning.
    
[^13]: DQ-LoRe: 用于上下文学习的低秩近似双重查询重新排序

    DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning. (arXiv:2310.02954v1 [cs.CL])

    [http://arxiv.org/abs/2310.02954](http://arxiv.org/abs/2310.02954)

    本研究引入了DQ-LoRe框架，它通过双重查询和低秩近似重新排序自动选择用于上下文学习的示例，在复杂推理任务中展示了出色的性能和效果。

    

    最近自然语言处理领域的新进展，主要是由大型语言模型（LLMs）推动的，展示了它们在上下文学习方面的显著能力。在复杂推理任务中引导LLMs的一个有前途的途径是利用链式思维（CoT）范式中的中间推理步骤。然而，最主要的挑战在于有效地选择示例来促进上下文学习。在这项研究中，我们引入了一个框架，利用双重查询和低秩近似重新排序（DQ-LoRe）来自动选择用于上下文学习的示例。双重查询首先查询LLM以获取LLM生成的知识，例如CoT，然后通过问题和知识查询检索器以获取最终的示例。此外，对于第二个查询，LoRe利用降维技术来改进示例选择，确保与输入问题的知识密切对齐。通过广泛的实验验证了DQ-LoRe框架的有效性和性能。

    Recent advances in natural language processing, primarily propelled by Large Language Models (LLMs), have showcased their remarkable capabilities grounded in in-context learning. A promising avenue for guiding LLMs in intricate reasoning tasks involves the utilization of intermediate reasoning steps within the Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies in the effective selection of exemplars for facilitating in-context learning. In this study, we introduce a framework that leverages Dual Queries and Low-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars for in-context learning. Dual Queries first query LLM to obtain LLM-generated knowledge such as CoT, then query the retriever to obtain the final exemplars via both question and the knowledge. Moreover, for the second query, LoRe employs dimensionality reduction techniques to refine exemplar selection, ensuring close alignment with the input question's knowledge. Through extensive ex
    
[^14]: JsonTuning：面向通用、强大和可控的指令调优

    JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning. (arXiv:2310.02953v1 [cs.CL])

    [http://arxiv.org/abs/2310.02953](http://arxiv.org/abs/2310.02953)

    JsonTuning是一种面向通用、强大和可控的指令调优方法，通过利用JSON的结构化特性，帮助模型理解任务要素及其关系，从而扩展了通用性、提高了稳健性，并增强了对输出的控制。

    

    指令调优已成为利用大型语言模型（LLM）能力的关键过程，通过提供明确的任务指令，从而在各种任务中提高性能。然而，目前的文本-文本指令调优（TextTuning）方法由于任务的模糊性和缺乏明确的结构而存在通用性、稳健性和可控性的限制。在本文中，我们提出了JsonTuning，这是一种新的结构到结构的指令调优方法。通过利用JSON的多功能和结构化特性来表示任务，JsonTuning通过帮助模型理解关键任务要素及其关系，扩展了通用性，通过最小化歧义性提高了稳健性，并通过提供对输出的显式控制增强了可控性。我们对不同的语言模型和评估基准进行了全面的比较研究。实验结果表明，JsonTuning在性能上优于TextTuning。

    Instruction tuning has emerged as a crucial process for harnessing the capabilities of large language models (LLMs) by providing explicit task instructions, leading to improved performance in various tasks. However, prevalent text-to-text instruction tuning (TextTuning) methods suffer from limitations in generalization, robustness, and controllability due to the ambiguity and lack of explicit structure in tasks. In this paper, we propose JsonTuning, a novel structure-to-structure approach for instruction tuning. By leveraging the versatility and structured nature of JSON to represent tasks, JsonTuning enhances generalization by helping the model understand essential task elements and their relations, improves robustness by minimizing ambiguity, and increases controllability by providing explicit control over the output. We conduct a comprehensive comparative study with diverse language models and evaluation benchmarks. Experimental results show that JsonTuning outperforms TextTuning in
    
[^15]: 阴影对齐：轻松颠覆安全对齐的语言模型

    Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models. (arXiv:2310.02949v1 [cs.CL])

    [http://arxiv.org/abs/2310.02949](http://arxiv.org/abs/2310.02949)

    该论文探讨了阴影对齐这种新的攻击方式，通过调整少量恶意示例，安全对齐的语言模型可以被轻松颠覆生成有害的内容，同时仍然可以正确响应常规查询。

    

    警告：本论文包含有害语言的例子，建议读者慎重。强大的大型语言模型（LLMs）的逐渐开放释放，通过降低数据注释和计算的核心成本，促进了下游应用的发展。为了确保AI的安全性，进行了广泛的安全对齐措施，以保护这些模型免受恶意使用（主要是硬提示攻击）。然而，在这种看似坚固的盔甲背后，可能潜伏着一个阴影。通过仅调整100个恶意示例，使用1个GPU小时，这些安全对齐的LLMs可以轻松地被颠覆以生成有害内容。形式上，我们将一种新攻击称为阴影对齐：利用少量数据可以使安全对齐模型适应有害任务，而不会牺牲模型的有用性。值得注意的是，被颠覆的模型仍然保留其对常规查询的适当响应能力。在5个发行的8个模型上进行的实验证实了这一点。

    Warning: This paper contains examples of harmful language, and reader discretion is recommended. The increasing open release of powerful large language models (LLMs) has facilitated the development of downstream applications by reducing the essential cost of data annotation and computation. To ensure AI safety, extensive safety-alignment measures have been conducted to armor these models against malicious use (primarily hard prompt attack). However, beneath the seemingly resilient facade of the armor, there might lurk a shadow. By simply tuning on 100 malicious examples with 1 GPU hour, these safely aligned LLMs can be easily subverted to generate harmful content. Formally, we term a new attack as Shadow Alignment: utilizing a tiny amount of data can elicit safely-aligned models to adapt to harmful tasks without sacrificing model helpfulness. Remarkably, the subverted models retain their capability to respond appropriately to regular inquiries. Experiments across 8 models released by 5
    
[^16]: LibriSpeech-PC：评估端到端ASR模型的标点和大写能力的基准测试

    LibriSpeech-PC: Benchmark for Evaluation of Punctuation and Capitalization Capabilities of end-to-end ASR Models. (arXiv:2310.02943v1 [cs.CL])

    [http://arxiv.org/abs/2310.02943](http://arxiv.org/abs/2310.02943)

    本文介绍了一个名为LibriSpeech-PC的基准测试，用于评估端到端ASR模型的标点和大写预测能力。该基准测试包括一个带有恢复标点和大写符号的数据集，以及一种针对标点符号评估的新型评估指标Punctuation Error Rate（PER），并提供了初步的基线模型。

    

    传统的自动语音识别（ASR）模型输出没有标点符号的小写单词，这降低了可读性，需要后续的文本处理模型将ASR转录转换为正确的格式。与此同时，能够预测标点和大写的端到端ASR模型的开发面临着多个挑战，主要是由于有限的数据可用性和现有评估方法的不足，如对标点预测的评估不足。在本文中，我们介绍了一个名为LibriSpeech-PC的基准测试，旨在评估端到端ASR模型的标点和大写预测能力。该基准测试包括一个具有恢复标点和大写符号的LibriSpeech-PC数据集，以及一个名为Punctuation Error Rate（PER）的新颖评估指标，专注于标点符号的评估，还包含初步的基线模型。所有代码、数据和模型都是公开可用的。

    Traditional automatic speech recognition (ASR) models output lower-cased words without punctuation marks, which reduces readability and necessitates a subsequent text processing model to convert ASR transcripts into a proper format. Simultaneously, the development of end-to-end ASR models capable of predicting punctuation and capitalization presents several challenges, primarily due to limited data availability and shortcomings in the existing evaluation methods, such as inadequate assessment of punctuation prediction. In this paper, we introduce a LibriSpeech-PC benchmark designed to assess the punctuation and capitalization prediction capabilities of end-to-end ASR models. The benchmark includes a LibriSpeech-PC dataset with restored punctuation and capitalization, a novel evaluation metric called Punctuation Error Rate (PER) that focuses on punctuation marks, and initial baseline models. All code, data, and models are publicly available.
    
[^17]: 对气候信息的大规模语言模型进行评估

    Assessing Large Language Models on Climate Information. (arXiv:2310.02932v1 [cs.CL])

    [http://arxiv.org/abs/2310.02932](http://arxiv.org/abs/2310.02932)

    本研究提出了一个基于科学传播原则的综合评估框架，评估了大规模语言模型在气候变化信息中的表现，能够在回答气候变化主题方面提供细粒度的分析。

    

    理解气候变化对我们的影响，了解可用的解决方案，是赋予个人和社区减缓和适应气候变化的重要步骤。随着大规模语言模型（LLMs）的普及，有必要评估它们在这个领域的能力。本研究提出了一个基于科学传播原则的综合评估框架，以分析LLM对气候变化主题的回答。我们的框架强调回答的呈现和认识上的适当性，为LLM生成提供了细粒度的分析。覆盖了8个维度，我们的框架能够识别模型输出中的30个不同问题。该任务是一个现实世界中的例子，这个领域存在越来越多的具有挑战性的问题，AI可以补充和提升人类的表现。我们引入了一种新颖而实用的可扩展监督协议，利用AI辅助并依靠具有相关教育背景的评估员。我们评估了几个最近的LLM，并进行了实证评估。

    Understanding how climate change affects us and learning about available solutions are key steps toward empowering individuals and communities to mitigate and adapt to it. As Large Language Models (LLMs) rise in popularity, it is necessary to assess their capability in this domain. In this study, we present a comprehensive evaluation framework, grounded in science communication principles, to analyze LLM responses to climate change topics. Our framework emphasizes both the presentational and epistemological adequacy of answers, offering a fine-grained analysis of LLM generations. Spanning 8 dimensions, our framework discerns up to 30 distinct issues in model outputs. The task is a real-world example of a growing number of challenging problems where AI can complement and lift human performance. We introduce a novel and practical protocol for scalable oversight that uses AI Assistance and relies on raters with relevant educational backgrounds. We evaluate several recent LLMs and conduct 
    
[^18]: 使用您的本能：使用神经探测器与转换器进行指令优化

    Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers. (arXiv:2310.02905v1 [cs.LG])

    [http://arxiv.org/abs/2310.02905](http://arxiv.org/abs/2310.02905)

    该论文提出了一种使用神经探测器和转换器优化指令的方法，以提高大型语言模型的性能。

    

    大型语言模型(LLMs)在各种应用中展示了出色的指令跟随能力，并取得了令人瞩目的表现。然而，LLMs的性能严重依赖于给予它们的指令，这些指令通常需要大量人力进行手动调整。最近的研究使用了高效的贝叶斯优化（BO）算法来自动优化给予黑盒LLMs的指令。然而，在优化高度复杂（例如高维）的目标函数时，如将指令映射到LLM性能的函数，BO通常表现不佳。这主要是由于BO使用的高斯过程（GP）模型的表达能力有限，该模型被用作BO的代理来建模目标函数。与此同时，已经多次证明神经网络（NNs），尤其是预训练的转换器，具有很强的表达能力，可以建模高度复杂的函数。因此，我们采用了一种神经探测器算法。

    Large language models (LLMs) have shown remarkable instruction-following capabilities and achieved impressive performances in various applications. However, the performances of LLMs depend heavily on the instructions given to them, which are typically manually tuned with substantial human efforts. Recent work has used the query-efficient Bayesian optimization (BO) algorithm to automatically optimize the instructions given to black-box LLMs. However, BO usually falls short when optimizing highly sophisticated (e.g., high-dimensional) objective functions, such as the functions mapping an instruction to the performance of an LLM. This is mainly due to the limited expressive power of the Gaussian process (GP) model which is used by BO as a surrogate to model the objective function. Meanwhile, it has been repeatedly shown that neural networks (NNs), especially pre-trained transformers, possess strong expressive power and can model highly complex functions. So, we adopt a neural bandit algor
    
[^19]: 使用合成数据生成方法在有限数据环境中进行仇恨言论检测

    Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation. (arXiv:2310.02876v1 [cs.CL])

    [http://arxiv.org/abs/2310.02876](http://arxiv.org/abs/2310.02876)

    本文提出了一种在有限数据环境中进行仇恨言论检测的数据增强方法，通过合成数据生成技术解决了缺乏训练数据的问题。研究通过在一种资源丰富的语言中合成新的仇恨言论数据示例，使得检测系统能够在其他语言环境中进行有效的分类任务。

    

    越来越多的研究关注于文本分类方法，以便检测网上发布的越来越多的仇恨言论。这一进展仅限于一些资源充足的语言，导致在有限数据环境中检测系统性能不佳或根本不存在。这主要是由于这些环境中获取和整理训练数据的成本较高所致。在本研究中，我们提出了一种数据增强方法，通过合成数据生成技术解决了有限数据环境中在线仇恨言论检测中缺乏数据的问题。在某些资源丰富的语言（如英语）中给定一些仇恨言论示例，我们提出了三种方法来合成保留原始示例中仇恨情绪但转移仇恨对象的新的仇恨言论数据示例。我们将这种方法应用于生成用于印地语和越南语的仇恨言论分类任务的训练数据。

    A growing body of work has focused on text classification methods for detecting the increasing amount of hate speech posted online. This progress has been limited to only a select number of highly-resourced languages causing detection systems to either under-perform or not exist in limited data contexts. This is majorly caused by a lack of training data which is expensive to collect and curate in these settings. In this work, we propose a data augmentation approach that addresses the problem of lack of data for online hate speech detection in limited data contexts using synthetic data generation techniques. Given a handful of hate speech examples in a high-resource language such as English, we present three methods to synthesize new examples of hate speech data in a target language that retains the hate sentiment in the original examples but transfers the hate targets. We apply our approach to generate training data for hate speech classification tasks in Hindi and Vietnamese. Our find
    
[^20]: 用智能多任务适应混合提示扫描异质性

    Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation. (arXiv:2310.02842v1 [cs.CL])

    [http://arxiv.org/abs/2310.02842](http://arxiv.org/abs/2310.02842)

    本论文提出了一种使用智能多任务适应混合提示的方法来解决LLM在处理异质任务和数据分布时的问题。研究者设计了智能门控功能，用于识别嵌入在不同提示组中的相关技能，并根据目标任务的需求动态分配组合专家。该方法对任何模型压缩技术都不受限制，提高了任务处理的效率。

    

    大型语言模型(LLM)有能力解决各种任务，如文本摘要和数学问题，但通常是针对单一任务进行训练。由于高计算成本，当前趋势是使用提示指导调节预先训练的LLM以适应新的下游任务。因此，如何扩展提示调节以同时处理异质任务和数据分布是一个广泛开放的问题。为了解决这一问题，我们建议使用"混合提示"或MoPs，并结合智能门控功能：后者的设计是本文的贡献之一，它可以识别嵌入在不同提示组中的相关技能，并根据目标任务动态分配组合专家(即一组提示)。此外，MoPs在应用任何模型压缩技术时都不受影响——以提高效率。

    Large Language Models (LLMs) have the ability to solve a variety of tasks, such as text summarization and mathematical questions, just out of the box, but they are often trained with a single task in mind. Due to high computational costs, the current trend is to use prompt instruction tuning to better adjust monolithic, pretrained LLMs for new -- but often individual -- downstream tasks. Thus, how one would expand prompt tuning to handle -- concomitantly -heterogeneous tasks and data distributions is a widely open question. To address this gap, we suggest the use of \emph{Mixture of Prompts}, or MoPs, associated with smart gating functionality: the latter -- whose design is one of the contributions of this paper -- can identify relevant skills embedded in different groups of prompts and dynamically assign combined experts (i.e., collection of prompts), based on the target task. Additionally, MoPs are empirically agnostic to any model compression technique applied -- for efficiency re
    
[^21]: DOMINO: 多步骤视觉语言推理的双系统

    DOMINO: A Dual-System for Multi-step Visual Language Reasoning. (arXiv:2310.02804v1 [cs.CL])

    [http://arxiv.org/abs/2310.02804](http://arxiv.org/abs/2310.02804)

    本文提出了一种用于多步骤多模态推理的双系统，其中一个系统用于提取视觉信息，另一个系统用于有意推理。这种方法可以避免模型在一个步骤回答复杂问题或被转换文本中的误导信息困扰。

    

    视觉语言推理需要一个系统从信息密集的图像（如图表或绘图）中提取文本或数字，并执行逻辑或算术推理以得出答案。为了解决这个任务，现有的工作依靠以下两种方法：（1）训练在大量数据上的端到端视觉语言模型，或者（2）使用两阶段的流程，其中一个字幕模型将图像转换成文本，然后由另一个大型语言模型读取文本以推断出答案。然而，前一种方法强迫模型用单个步骤回答复杂问题，后一种方法容易产生转换文本中的不准确或分散注意力的信息，从而让语言模型混淆。在这项工作中，我们提出了一种用于多步骤多模型推理的双系统，它包含用于视觉信息提取的“System-1”步骤和用于有意推理的“System-2”步骤。给定一个输入，System-2将问题分解为原子子步骤，每个子步骤指导System-1进行信息提取。

    Visual language reasoning requires a system to extract text or numbers from information-dense images like charts or plots and perform logical or arithmetic reasoning to arrive at an answer. To tackle this task, existing work relies on either (1) an end-to-end vision-language model trained on a large amount of data, or (2) a two-stage pipeline where a captioning model converts the image into text that is further read by another large language model to deduce the answer. However, the former approach forces the model to answer a complex question with one single step, and the latter approach is prone to inaccurate or distracting information in the converted text that can confuse the language model. In this work, we propose a dual-system for multi-step multimodal reasoning, which consists of a "System-1" step for visual information extraction and a "System-2" step for deliberate reasoning. Given an input, System-2 breaks down the question into atomic sub-steps, each guiding System-1 to extr
    
[^22]: 使用预训练语言模型进行低资源摘要的翻译

    Low Resource Summarization using Pre-trained Language Models. (arXiv:2310.02790v1 [cs.CL])

    [http://arxiv.org/abs/2310.02790](http://arxiv.org/abs/2310.02790)

    通过自注意力变压器架构模型和构建基线数据集，我们提出了一种适用于低资源语言摘要的方法，并通过在低资源语言乌尔都语中的新闻应用领域的实现来证明其可行性。

    

    随着基于深度学习的人工神经网络模型的出现，自然语言处理（NLP）在文本数据处理方面取得了显著的效率和准确性改进。然而，这方面的研究大多局限于高资源语言，如英语，低资源语言仍然缺乏训练数据集和具有基线评估结果的模型。考虑到低资源语言的资源有限性，我们提出了一种适应低资源摘要的自注意力变压器架构模型（mBERT，mT5）的方法，并补充了一个新的基线数据集（76.5万篇文章、摘要对）来进行低资源语言乌尔都语的摘要。选择新闻（一个公开可用的来源）作为应用领域有潜力使所提出的方法在其他资源有限的语言中能够复制。我们的适应的模型

    With the advent of Deep Learning based Artificial Neural Networks models, Natural Language Processing (NLP) has witnessed significant improvements in textual data processing in terms of its efficiency and accuracy. However, the research is mostly restricted to high-resource languages such as English and low-resource languages still suffer from a lack of available resources in terms of training datasets as well as models with even baseline evaluation results. Considering the limited availability of resources for low-resource languages, we propose a methodology for adapting self-attentive transformer-based architecture models (mBERT, mT5) for low-resource summarization, supplemented by the construction of a new baseline dataset (76.5k article, summary pairs) in a low-resource language Urdu. Choosing news (a publicly available source) as the application domain has the potential to make the proposed methodology useful for reproducing in other languages with limited resources. Our adapted s
    
[^23]: 一个增强的 UMLS 框架，用于改善大型语言模型在医疗保健中的事实性

    A UMLS-Augmented Framework for Improving Factuality in Large Language Models within Healthcare. (arXiv:2310.02778v1 [cs.CL])

    [http://arxiv.org/abs/2310.02778](http://arxiv.org/abs/2310.02778)

    该论文提出了一个基于UMLS的增强型大型语言模型框架，旨在改善医疗保健领域中模型生成内容的事实性。通过自动评估和医生评估，研究人员验证了该框架的有效性。

    

    大型语言模型（LLM）展示了强大的文本生成能力，为医疗保健领域带来了前所未有的创新。然而，将LLMs应用于真实临床场景面临重大挑战，因为这些模型可能生成与已建立医学事实偏离的内容，甚至可能表现出潜在的偏见。在我们的研究中，我们开发了一个基于统一医学语言系统（UMLS）的增强型LLM框架，旨在更好地服务医疗保健社区。我们采用LLaMa2-13b-chat和ChatGPT-3.5作为基准模型，并使用ROUGE分数和BERT分数在LiveQA测试集的104个问题上进行自动评估。此外，我们根据事实性、完整性、可读性和相关性四个维度建立了医生评估标准。ChatGPT-3.5用于医生评估，针对LiveQA测试集的20个问题。多位住院医师进行评估。

    Large language models (LLMs) have demonstrated powerful text generation capabilities, bringing unprecedented innovation to the healthcare field. While LLMs hold immense promise for applications in healthcare, applying them to real clinical scenarios presents significant challenges, as these models may generate content that deviates from established medical facts and even exhibit potential biases. In our research, we develop an augmented LLM framework based on the Unified Medical Language System (UMLS), aiming to better serve the healthcare community. We employ LLaMa2-13b-chat and ChatGPT-3.5 as our benchmark models, and conduct automatic evaluations using the ROUGE Score and BERTScore on 104 questions from the LiveQA test set. Additionally, we establish criteria for physician-evaluation based on four dimensions: Factuality, Completeness, Readability and Relevancy. ChatGPT-3.5 is used for physician evaluation with 20 questions on the LiveQA test set. Multiple resident physicians conduct
    
[^24]: 语言先验在测量视觉语言模型组合泛化中的作用

    The Role of Linguistic Priors in Measuring Compositional Generalization of Vision-Language Models. (arXiv:2310.02777v1 [cs.CL])

    [http://arxiv.org/abs/2310.02777](http://arxiv.org/abs/2310.02777)

    本文研究了视觉语言模型组合泛化的一种重要属性：语言先验。研究发现当前的改进方法主要依赖于语言先验而忽视了图像中的信息。研究还提出了一种新的不依赖于语言先验的组合性度量方法。

    

    组合性是许多模态中常见的属性，包括自然语言和图像，但多模式模型的组合泛化尚不太清楚。在本文中，我们确定了视觉-语言组合性的两个来源：语言先验和图像和文本之间的相互作用。我们显示当前改进组合性泛化的尝试依赖于语言先验而不是图像中的信息。我们还提出了一种没有这种语言先验的组合性度量标准。

    Compositionality is a common property in many modalities including natural languages and images, but the compositional generalization of multi-modal models is not well-understood. In this paper, we identify two sources of visual-linguistic compositionality: linguistic priors and the interplay between images and texts. We show that current attempts to improve compositional generalization rely on linguistic priors rather than on information in the image. We also propose a new metric for compositionality without such linguistic priors.
    
[^25]: 自动摘要评估的比较研究和框架：LangChain和混合算法

    Comparative Study and Framework for Automated Summariser Evaluation: LangChain and Hybrid Algorithms. (arXiv:2310.02759v1 [cs.LG])

    [http://arxiv.org/abs/2310.02759](http://arxiv.org/abs/2310.02759)

    本研究关注自动摘要评估的比较研究和框架，通过使用LangChain和混合算法对PDF文档进行摘要和提取关键信息，以确定用户对摘要内容的理解程度如何。

    

    自动文章评分（AES）被证明是一种尖端技术，评分技术用于各种目的，可靠的得分是基于有影响力的变量计算得出的，这些变量可以根据领域通过不同的方法计算出来。本研究集中于用户对给定主题的理解，分析是基于使用大型语言模型的评分指数，用户可以比较和对比最近学习的主题的理解程度，结果则对学习分析有所贡献，以提高学习能力。本研究的重点是对PDF文档进行摘要和衡量用户对其内容的理解程度。该过程涉及使用LangChain工具对PDF进行摘要和提取关键信息，通过采用这种技术，本研究旨在确定用户对摘要内容的理解程度如何。

    Automated Essay Score (AES) is proven to be one of the cutting-edge technologies. Scoring techniques are used for various purposes. Reliable scores are calculated based on influential variables. Such variables can be computed by different methods based on the domain. The research is concentrated on the user's understanding of a given topic. The analysis is based on a scoring index by using Large Language Models. The user can then compare and contrast the understanding of a topic that they recently learned. The results are then contributed towards learning analytics and progression is made for enhancing the learning ability. In this research, the focus is on summarizing a PDF document and gauging a user's understanding of its content. The process involves utilizing a Langchain tool to summarize the PDF and extract the essential information. By employing this technique, the research aims to determine how well the user comprehends the summarized content.
    
[^26]: LC-Score：无参考评估文本理解困难度

    LC-Score: Reference-less estimation of Text Comprehension Difficulty. (arXiv:2310.02754v1 [cs.CL])

    [http://arxiv.org/abs/2310.02754](http://arxiv.org/abs/2310.02754)

    本文提出了一种无参考评估文本理解困难度的简单方法LC-Score，可以用于法语文本，该方法可以预测给定文本在0到100范围内的易读程度。这个方法可以帮助作家们创作易于理解的内容，并提供度量标准来评估自动化文本简化模型的发展。

    

    在数字时代，能够阅读和理解书面文本是至关重要的。然而，研究表明，大部分人口都存在理解障碍。在这种背景下，需要进一步的无障碍倡议来提高受众的文本理解能力。然而，作家们几乎没有得到支持或鼓励以创作易于理解的内容。此外，自动文本简化（ATS）模型的开发缺乏准确估计理解难度的度量标准。我们提出了\textsc{LC-Score}，一种简单的方法来训练文本理解度量标准，用于法语文本而无需参考，即预测给定文本在$[0, 100]$范围内的易读程度。我们的目标是定量捕捉文本符合\textit{Langage Clair}（LC，即\textit{Clear Language}）指南的程度，该指南与英语简明语言密切相关。我们探索了两种方法：（i）使用语言学方法

    Being able to read and understand written text is critical in a digital era. However, studies shows that a large fraction of the population experiences comprehension issues. In this context, further initiatives in accessibility are required to improve the audience text comprehension. However, writers are hardly assisted nor encouraged to produce easy-to-understand content. Moreover, Automatic Text Simplification (ATS) model development suffers from the lack of metric to accurately estimate comprehension difficulty We present \textsc{LC-Score}, a simple approach for training text comprehension metric for any French text without reference \ie predicting how easy to understand a given text is on a $[0, 100]$ scale. Our objective with this scale is to quantitatively capture the extend to which a text suits to the \textit{Langage Clair} (LC, \textit{Clear Language}) guidelines, a French initiative closely related to English Plain Language. We explore two approaches: (i) using linguistically
    
[^27]: AGIR: 自然语言生成技术在自动化网络威胁情报报告中的应用

    AGIR: Automating Cyber Threat Intelligence Reporting with Natural Language Generation. (arXiv:2310.02655v1 [cs.CR])

    [http://arxiv.org/abs/2310.02655](http://arxiv.org/abs/2310.02655)

    AGIR是一种专门解决网络威胁情报报告领域挑战的自然语言生成工具，通过自动化生成全面的情报报告，帮助安全分析师减少繁重任务。

    

    网络威胁情报（CTI）报告在当今风险管理策略中至关重要。随着CTI报告数量的不断增加，需要自动化工具来简化报告生成的需求日益明显。尽管自然语言处理技术在处理文本数据方面显示出潜力，但它们往往难以应对多样化数据源及其错综复杂的相互关系。此外，像STIX这样的已经成为CTI社区的事实标准的模式，强调对实体和关系进行形式化分类以促进一致的数据共享。在本文中，我们引入了AGIR（Automatic Generation of Intelligence Reports），这是一种专门解决CTI报告领域紧迫挑战的转变性自然语言生成工具。AGIR的主要目标是通过自动化生成全面的情报报告，为安全分析师提供帮助，减少繁重的任务。

    Cyber Threat Intelligence (CTI) reporting is pivotal in contemporary risk management strategies. As the volume of CTI reports continues to surge, the demand for automated tools to streamline report generation becomes increasingly apparent. While Natural Language Processing techniques have shown potential in handling text data, they often struggle to address the complexity of diverse data sources and their intricate interrelationships. Moreover, established paradigms like STIX have emerged as de facto standards within the CTI community, emphasizing the formal categorization of entities and relations to facilitate consistent data sharing. In this paper, we introduce AGIR (Automatic Generation of Intelligence Reports), a transformative Natural Language Generation tool specifically designed to address the pressing challenges in the realm of CTI reporting. AGIR's primary objective is to empower security analysts by automating the labor-intensive task of generating comprehensive intelligence
    
[^28]: I$^2$KD-SLU: 一种面向零样本跨语言口语理解的内外知识蒸馏框架

    I$^2$KD-SLU: An Intra-Inter Knowledge Distillation Framework for Zero-Shot Cross-Lingual Spoken Language Understanding. (arXiv:2310.02594v1 [cs.CL])

    [http://arxiv.org/abs/2310.02594](http://arxiv.org/abs/2310.02594)

    I$^2$KD-SLU是一种内外知识蒸馏框架，用于解决零样本跨语言口语理解中意图和词槽之间的相互指导问题。

    

    口语理解通常包括两个子任务：意图检测和词槽填充。目前，在高资源语言中已经取得了很大的成功，但在低资源语言中仍然存在挑战，原因是标记的训练数据稀缺。因此，对于零样本跨语言口语理解越来越受关注。尽管现有的零样本跨语言口语理解模型取得了成功，但大多数忽略了意图和词槽之间的相互指导。为了解决这个问题，我们提出了一种内外知识蒸馏框架用于零样本跨语言口语理解（I$^2$KD-SLU），以建模相互指导。具体而言，我们不仅在不同语言中的相同话语的意图预测或词槽预测之间应用内部知识蒸馏，而且还在相同话语的意图预测和词槽预测之间应用间接知识蒸馏。我们的实验结果表明我们的提议可以有效地建模相互指导。

    Spoken language understanding (SLU) typically includes two subtasks: intent detection and slot filling. Currently, it has achieved great success in high-resource languages, but it still remains challenging in low-resource languages due to the scarcity of labeled training data. Hence, there is a growing interest in zero-shot cross-lingual SLU. Despite of the success of existing zero-shot cross-lingual SLU models, most of them neglect to achieve the mutual guidance between intent and slots. To address this issue, we propose an Intra-Inter Knowledge Distillation framework for zero-shot cross-lingual Spoken Language Understanding (I$^2$KD-SLU) to model the mutual guidance. Specifically, we not only apply intra-knowledge distillation between intent predictions or slot predictions of the same utterance in different languages, but also apply inter-knowledge distillation between intent predictions and slot predictions of the same utterance. Our experimental results demonstrate that our propose
    
[^29]: 使用大型语言模型改进自动VQA评估

    Improving Automatic VQA Evaluation Using Large Language Models. (arXiv:2310.02567v1 [cs.CV])

    [http://arxiv.org/abs/2310.02567](http://arxiv.org/abs/2310.02567)

    提出使用大型语言模型改进自动视觉问答（VQA）评估的方法，将VQA评估格式化为回答评分任务，通过指令调整大型语言模型在准确度上评分候选答案，证明该方法与人类判断相关性优于现有度量方法。

    

    在提出视觉问答（VQA）任务8年后，准确率仍然是自动评估的主要指标。在IID评估设置中，VQA准确度一直很有效。然而，我们的社区正在转向开放式生成模型和OOD评估。在这种新的范式中，现有的VQA准确度指标过于严格，低估了VQA系统的性能。因此，有必要开发更强大的自动VQA度量，作为人类判断的代理。在这项工作中，我们提出利用指令调整大型语言模型（LLM）的上下文学习能力来构建更好的VQA度量。我们将VQA评估格式化为一个回答评分任务，即指令调整的大型语言模型被指示根据一组参考答案评分候选答案的准确性。我们证明所提出的度量与人类判断相关性优于现有度量在几个VQA模型和基准测试中。

    8 years after the visual question answering (VQA) task was proposed, accuracy remains the primary metric for automatic evaluation. VQA Accuracy has been effective so far in the IID evaluation setting. However, our community is undergoing a shift towards open-ended generative models and OOD evaluation. In this new paradigm, the existing VQA Accuracy metric is overly stringent and underestimates the performance of VQA systems. Thus, there is a need to develop more robust automatic VQA metrics that serve as a proxy for human judgment. In this work, we propose to leverage the in-context learning capabilities of instruction-tuned large language models (LLMs) to build a better VQA metric. We formulate VQA evaluation as an answer-rating task where the LLM is instructed to score the accuracy of a candidate answer given a set of reference answers. We demonstrate the proposed metric better correlates with human judgment compared to existing metrics across several VQA models and benchmarks. We ho
    
[^30]: NOLA: 网络作为低秩随机基向量的线性组合

    NOLA: Networks as Linear Combination of Low Rank Random Basis. (arXiv:2310.02556v1 [cs.CL])

    [http://arxiv.org/abs/2310.02556](http://arxiv.org/abs/2310.02556)

    该论文介绍了一种名为NOLA的方法，该方法通过将网络表示为低秩随机基向量的线性组合来减少语言模型的参数数量，从而实现高效的适应和存储。

    

    最近，由于大型语言模型（LLMs）在各种下游任务上表现出的惊人少样本性能，它们受到了广泛关注。然而，由于检查点的庞大大小（例如GPT-3的350GB），对所有参数进行微调并为每个下游任务或领域存储一个唯一模型变得不切实际。当前的文献，例如LoRA，展示了对LLM的原始权重进行低秩修改的潜力，从而实现了针对特定任务的模型的高效适应和存储。这些方法可以将微调LLM所需的参数数量减少几个数量级。然而，这些方法面临两个主要限制：1）参数减少受到秩一分解的下界限制，2）减少的程度受到模型架构和选择的秩的严重影响。例如，在更大模型中，即使是秩一分解，参数的数量也可能超过真正需要进行适应的参数数量。在这篇论文中，我们介绍了NOLA，它通过将网络表示为低秩随机基向量的线性组合，解决了这些限制。

    Large Language Models (LLMs) have recently gained popularity due to their impressive few-shot performance across various downstream tasks. However, fine-tuning all parameters and storing a unique model for each downstream task or domain becomes impractical because of the massive size of checkpoints (e.g., 350GB in GPT-3). Current literature, such as LoRA, showcases the potential of low-rank modifications to the original weights of an LLM, enabling efficient adaptation and storage for task-specific models. These methods can reduce the number of parameters needed to fine-tune an LLM by several orders of magnitude. Yet, these methods face two primary limitations: 1) the parameter reduction is lower-bounded by the rank one decomposition, and 2) the extent of reduction is heavily influenced by both the model architecture and the chosen rank. For instance, in larger models, even a rank one decomposition might exceed the number of parameters truly needed for adaptation. In this paper, we intr
    
[^31]: CITING: 大型语言模型通过课程设计进行指导调优

    CITING: Large Language Models Create Curriculum for Instruction Tuning. (arXiv:2310.02527v1 [cs.CL])

    [http://arxiv.org/abs/2310.02527](http://arxiv.org/abs/2310.02527)

    本文提出了一种利用大型语言模型作为指导教师来训练学生语言模型的方法，通过设计课程来进行指导调优，称为CITING。该方法通过教师模型制定评分标准，学生模型通过遵循评分标准和自我纠正进行学习。该方法可以解决手工制作指导数据集和人工对齐的瓶颈问题。

    

    最近大型语言模型（LLMs）的进展是通过指导调优和人工对齐的结合实现的。然而，构建手工制作的指导数据集和进行人工对齐成为了扩展LLMs开发的瓶颈。在本文中，我们利用AI模型代替人类作为教师来训练学生LLMs的方法。我们的方法灵感来自于人类学生通过遵循评分标准和从导师提供的修改中学习来提高写作技巧。具体来说，我们使用教师LLM来为学生LLM的指导调优创建课程，即Curriculum Instruction TunING (CITING)。该方法包括两个主要步骤：（1）教师LLM制定评估各种类型问题答案的评分标准；（2）学生LLM学习遵循评分标准并通过教师的修改进行自我纠正。我们进一步迭代进行这个过程。

    The recent advancement of large language models (LLMs) has been achieved through a combo of instruction tuning and human alignment. However, building manually crafted instruction datasets and performing human alignment become the bottleneck for scaling the development of LLMs. In this paper, we exploit the idea of leveraging AI models in lieu of humans as the teacher to train student LLMs. Our method is inspired by how human students refine their writing skills by following the rubrics and learning from the revisions offered by their tutors. Specifically, we employ a teacher LLM to create a curriculum for instruction tuning of the student LLM, namely Curriculum Instruction TunING (CITING). It encompasses two main steps: (1) the teacher LLM crafts the rubrics for evaluating the answers corresponding to various types of questions, and (2) the student LLM learns to follow the rubrics and perform self-correction from the revision made by the teacher. We further iteratively carry out it to 
    
[^32]: ResidualTransformer：带有权重共享的残差低秩学习的Transformer层

    ResidualTransformer: Residual Low-rank Learning with Weight-sharing for Transformer Layers. (arXiv:2310.02489v1 [cs.CL])

    [http://arxiv.org/abs/2310.02489](http://arxiv.org/abs/2310.02489)

    本文提出了一种名为ResidualTransformer的方法，通过重新参数化Transformer编码器层之间的模型权重，将模型的大小减小。实验结果表明，ResidualTransformer的性能优于传统Transformer模型，且模型大小得到了显著减小。

    

    在部署语音处理模型到始终开启设备上时，内存限制是一个主要关注点之一。虽然使用足够大量的数据训练得到的更大的模型通常表现更好，但使其适应设备内存是一个具有挑战性的问题。在本文中，我们旨在通过重新参数化Transformer编码器层之间的模型权重，并假设特殊的权重组合和结构，来减小模型的大小。更具体地说，受ResNet和最新的LoRA工作的启发，我们提出了一种名为ResidualTransformer的方法，其中Transformer层中的每个权重矩阵包括1）与其相邻层共享的满秩组件，和2）仅属于它自己的独特低秩组件。低秩矩阵只占模型大小的一小部分。此外，我们添加对角线权重矩阵来提高低秩矩阵的建模能力。我们的10k小时语音识别和语音翻译任务的实验结果表明，ResidualTransformer的性能优于传统Transformer模型，且模型大小得到了显著减小。

    Memory constraint of always-on devices is one of the major concerns when deploying speech processing models on these devices. While larger models trained with sufficiently large amount of data generally perform better, making them fit in the device memory is a demanding challenge. In this paper, we aim to reduce model size by reparameterizing model weights across Transformer encoder layers and assuming a special weight composition and structure. More specifically, inspired by ResNet and the more recent LoRA work, we propose an approach named ResidualTransformer, where each weight matrix in a Transformer layer comprises 1) a shared full-rank component with its adjacent layers, and 2) a unique low-rank component to itself. The low-rank matrices only account for a small amount of model size increase. In addition, we add diagonal weight matrices to improve modeling capacity of the low-rank matrices. Experiments of our 10k-hour speech recognition and speech translation tasks show that the T
    
[^33]: 大型语言模型可以成为良好的隐私保护学习者

    Large Language Models Can Be Good Privacy Protection Learners. (arXiv:2310.02469v1 [cs.CL])

    [http://arxiv.org/abs/2310.02469](http://arxiv.org/abs/2310.02469)

    本论文介绍了一种名为隐私保护语言模型（PPLM）的新范式，可以在保护数据隐私的同时有效注入领域特定知识。通过对模型设计的理论分析和不同技术的研究，我们验证了使用正向和负向示例进行指令微调的方法具有很大的潜力。

    

    大型语言模型（LLMs）的普及引发了人们对使用特定领域数据对其进行微调，创建专门的语言模型的兴趣。然而，这种特定领域的微调数据通常包含敏感的个人身份信息（PII）。在没有隐私保护的情况下直接微调 LLMs 会存在信息泄露的风险。为了解决这个挑战，我们引入了隐私保护语言模型（PPLM），这是一种在有效注入领域特定知识的同时保护数据隐私的新范式。我们的工作提供了模型设计的理论分析，并深入研究了各种技术，比如语料库策展、基于惩罚的非概然性训练损失以及基于指令的微调等等。广泛的实验在不同的数据集和场景中验证了我们的方法的有效性。特别是，使用正向和负向示例进行指令微调，显示出很有希望的方法。

    The proliferation of Large Language Models (LLMs) has driven considerable interest in fine-tuning them with domain-specific data to create specialized language models. Nevertheless, such domain-specific fine-tuning data often contains sensitive personally identifiable information (PII). Direct fine-tuning LLMs on this data without privacy protection poses a risk of leakage. To address this challenge, we introduce Privacy Protection Language Models (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects domain-specific knowledge while safeguarding data privacy. Our work offers a theoretical analysis for model design and delves into various techniques such as corpus curation, penalty-based unlikelihood in training loss, and instruction-based tuning, etc. Extensive experiments across diverse datasets and scenarios demonstrate the effectiveness of our approaches. In particular, instruction tuning with both positive and negative examples, stands out as a promising method, eff
    
[^34]: 空符号问题：朝向更清晰的范式来解决大型语言模型中的“对齐”问题

    The Empty Signifier Problem: Towards Clearer Paradigms for Operationalising "Alignment" in Large Language Models. (arXiv:2310.02457v1 [cs.CL])

    [http://arxiv.org/abs/2310.02457](http://arxiv.org/abs/2310.02457)

    本文通过后结构主义社会政治理论的视角，探讨了大型语言模型(LLMs)中的“对齐”概念，并提出了一个框架来明确操作化这种抽象概念，促进透明和批判性评估的文化。

    

    本文通过后结构主义社会政治理论的视角，探讨了大型语言模型(LLMs)中的“对齐”概念，并特别研究了其与空符号的相似之处。为了在经验数据集中明确操作化抽象对齐概念的共享词汇，我们提出了一个框架，界定了：1）哪些模型行为维度被认为重要，然后2）如何赋予这些维度的含义和定义，并由谁确定。我们对现有的经验文献进行了定位，并提供了在决定要遵循哪种范式方面的指导。通过这个框架，我们旨在培养透明和批判性评估的文化，帮助社区在处理将LLMs与人类群体对齐的复杂性时进行导航。

    In this paper, we address the concept of "alignment" in large language models (LLMs) through the lens of post-structuralist socio-political theory, specifically examining its parallels to empty signifiers. To establish a shared vocabulary around how abstract concepts of alignment are operationalised in empirical datasets, we propose a framework that demarcates: 1) which dimensions of model behaviour are considered important, then 2) how meanings and definitions are ascribed to these dimensions, and by whom. We situate existing empirical literature and provide guidance on deciding which paradigm to follow. Through this framework, we aim to foster a culture of transparency and critical evaluation, aiding the community in navigating the complexities of aligning LLMs with human populations.
    
[^35]: 通过溯源对混淆的后门调整以实现多机构临床笔记的强健文本分类

    Backdoor Adjustment of Confounding by Provenance for Robust Text Classification of Multi-institutional Clinical Notes. (arXiv:2310.02451v1 [cs.CL])

    [http://arxiv.org/abs/2310.02451](http://arxiv.org/abs/2310.02451)

    本研究评估了在多机构临床笔记数据集中使用后门调整进行文本分类的效果，结果表明后门调整对解决源特定数据分布差异导致的模型性能下降问题具有实用性。

    

    自然语言处理（NLP）方法已广泛应用于临床任务。机器学习和深度学习方法已被用于提高临床NLP的性能。然而，这些方法需要足够大的训练数据集，并且已经证明在不同机构之间传输模型的性能较差。这些问题导致了在不同机构之间进行数据收集和整合来得到准确和可移植的模型的推广。然而，这可能会引入一种称为溯源混淆的偏差形式。当部署时源特定数据分布不同时，这可能会损害模型性能。为了解决这个问题，我们评估了在多机构临床笔记数据集中使用后门调整进行文本分类的效用。使用设计用于衡量对分布变化的鲁棒性的评估框架，我们评估了后门调整的效果。我们的结果表明，后门调整的有效性

    Natural Language Processing (NLP) methods have been broadly applied to clinical tasks. Machine learning and deep learning approaches have been used to improve the performance of clinical NLP. However, these approaches require sufficiently large datasets for training, and trained models have been shown to transfer poorly across sites. These issues have led to the promotion of data collection and integration across different institutions for accurate and portable models. However, this can introduce a form of bias called confounding by provenance. When source-specific data distributions differ at deployment, this may harm model performance. To address this issue, we evaluate the utility of backdoor adjustment for text classification in a multi-site dataset of clinical notes annotated for mentions of substance abuse. Using an evaluation framework devised to measure robustness to distributional shifts, we assess the utility of backdoor adjustment. Our results indicate that backdoor adjustme
    
[^36]: 低资源语言越狱 GPT-4

    Low-Resource Languages Jailbreak GPT-4. (arXiv:2310.02446v1 [cs.CL])

    [http://arxiv.org/abs/2310.02446](http://arxiv.org/abs/2310.02446)

    通过翻译不安全的英文输入成低资源语言，我们成功绕过了GPT-4的安全机制，并展示了这种跨语言漏洞。这一方法在实验中取得了与甚至超过了最先进的越狱攻击的效果，揭示了低资源语言在AI安全性中的薄弱环节。

    

    人工智能安全培训和大型语言模型（LLM）的红队测试是减少生成不安全内容的措施。我们的工作通过将不安全的英文输入翻译成低资源语言，成功绕过GPT-4的安全机制，并揭示了这些安全机制的跨语言漏洞。在AdvBenchmark中，GPT-4针对不安全的翻译输入进行交互，并且79%的时间内提供了可行的方案，使用户实现其有害目标，这与甚至超过了最先进的越狱攻击的效果相当。其他高/中资源语言的攻击成功率显著较低，这表明跨语言漏洞主要适用于低资源语言。以前，对低资源语言的有限训练主要影响那些使用这些语言的人，造成技术差距。然而，我们的工作突出了一个关键转变：

    AI safety training and red-teaming of large language models (LLMs) are measures to mitigate the generation of unsafe content. Our work exposes the inherent cross-lingual vulnerability of these safety mechanisms, resulting from the linguistic inequality of safety training data, by successfully circumventing GPT-4's safeguard through translating unsafe English inputs into low-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe translated inputs and provides actionable items that can get the users towards their harmful goals 79% of the time, which is on par with or even surpassing state-of-the-art jailbreaking attacks. Other high-/mid-resource languages have significantly lower attack success rate, which suggests that the cross-lingual vulnerability mainly applies to low-resource languages. Previously, limited training on low-resource languages primarily affects speakers of those languages, causing technological disparities. However, our work highlights a crucial shift:
    
[^37]: 初学者学习者和专家导师：评估大型语言模型在数学推理能力上的误解

    Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions. (arXiv:2310.02439v1 [cs.CL])

    [http://arxiv.org/abs/2310.02439](http://arxiv.org/abs/2310.02439)

    本研究提出了一种基于数学误解的评估方法，测试大型语言模型在数学推理能力上的表现。与传统评估方法不同，我们通过模拟初学者和专家导师的角色来识别错误答案和相应的误解。实验结果表明，虽然大型语言模型可以正确回答问题，但在识别误解方面存在困难。

    

    我们提出了一种基于数学误解的大型语言模型（LLM）数学推理能力的新评估方法。我们的主要方法是将LLM模拟成初学者学习者和专家导师，旨在识别由特定误解引起的数学问题的错误答案，并识别与错误答案相关的误解。与传统基于LLM的数学评估不同，我们的方法受到教育学习科学原则的启发。我们明确要求LLM模拟初学者学习者的行为，通过基于不完全知识以特定错误的方式回答问题；以及模拟专家导师的行为，识别与问题的错误答案相对应的误解。通过使用简单的小学数学问题，我们的实验揭示了LLM虽然可以轻松正确回答这些问题，但在识别误解方面却存在困难。

    We propose novel evaluations for mathematical reasoning capabilities of Large Language Models (LLMs) based on mathematical misconceptions. Our primary approach is to simulate LLMs as a novice learner and an expert tutor, aiming to identify the incorrect answer to math question resulted from a specific misconception and to recognize the misconception(s) behind an incorrect answer, respectively. Contrary to traditional LLMs-based mathematical evaluations that focus on answering math questions correctly, our approach takes inspirations from principles in educational learning sciences. We explicitly ask LLMs to mimic a novice learner by answering questions in a specific incorrect manner based on incomplete knowledge; and to mimic an expert tutor by identifying misconception(s) corresponding to an incorrect answer to a question. Using simple grade-school math problems, our experiments reveal that, while LLMs can easily answer these questions correctly, they struggle to identify 1) the incor
    
[^38]: 能否使用大型语言模型提供安全和隐私建议？衡量LLMs反驳误解的能力。

    Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions. (arXiv:2310.02431v1 [cs.HC])

    [http://arxiv.org/abs/2310.02431](http://arxiv.org/abs/2310.02431)

    本研究测量了大型语言模型(LLMs)反驳常见的安全和隐私误解的能力。通过研究学术文献，整理了六个主题的一百多个与安全和隐私相关的误解。然后，通过查询两个流行的LLMs并制定标注指南，评估它们的回应。

    

    用户从在线资源中寻求安全和隐私建议，包括信任的网站和内容分享平台。这些资源帮助用户了解安全和隐私技术和工具，并提供可行的策略。大型语言模型(LLMs)最近作为受信任的信息来源出现。然而，它们的准确性和正确性受到质疑。先前的研究已经概述了LLMs在回答多项选择题和用户绕过模型限制(例如产生有害内容)的能力方面的缺点。然而，LLMs提供可靠的安全和隐私建议的能力还没有得到很好的探索。在本文中，我们测量它们反驳普遍存在的安全和隐私误解的能力。我们首先研究最近的学术文献，整理了六个不同主题的一百多个与安全和隐私相关的误解的数据集。然后，我们查询了两个流行的LLMs(Bard和ChatGPT)，并制定了一个标注指南来评估它们对误解的回应。

    Users seek security & privacy (S&P) advice from online resources, including trusted websites and content-sharing platforms. These resources help users understand S&P technologies and tools and suggest actionable strategies. Large Language Models (LLMs) have recently emerged as trusted information sources. However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g., to produce toxic content). Yet, the ability of LLMs to provide reliable S&P advice is not well-explored. In this paper, we measure their ability to refute popular S&P misconceptions that the general public holds. We first study recent academic literature to curate a dataset of over a hundred S&P-related misconceptions across six different topics. We then query two popular LLMs (Bard and ChatGPT) and develop a labeling guide to evaluate their responses to
    
[^39]: 学生大规模语言模型能否与其教师一样表现出色？

    Can a student Large Language Model perform as well as it's teacher?. (arXiv:2310.02421v1 [cs.LG])

    [http://arxiv.org/abs/2310.02421](http://arxiv.org/abs/2310.02421)

    这篇论文总结了知识蒸馏技术，并强调了其关键原理和成功要素，以及在资源受限环境中的部署挑战。同时，论文还指出知识蒸馏有潜力成为关键的技术转折点。

    

    当代深度学习模型的复杂性不断增加，虽然能实现无与伦比的准确性，但也不可避免地在资源受限环境中带来部署挑战。知识蒸馏作为一种将高容量“教师”模型中的知识转移到简化的“学生”模型的技术，成为解决这一困境的有希望的方法。本文全面概述了知识蒸馏范式，强调了其基本原理，如软标签的实用性和温度缩放的重要性。通过细致的研究，我们阐明了成功蒸馏的关键因素，包括学生模型的架构、教师的水平以及超参数的平衡。同时我们还深入探讨了这一过程中的复杂性和挑战。我们的探索凸显了知识蒸馏作为一个重要转折点的潜力。

    The burgeoning complexity of contemporary deep learning models, while achieving unparalleled accuracy, has inadvertently introduced deployment challenges in resource-constrained environments. Knowledge distillation, a technique aiming to transfer knowledge from a high-capacity "teacher" model to a streamlined "student" model, emerges as a promising solution to this dilemma. This paper provides a comprehensive overview of the knowledge distillation paradigm, emphasizing its foundational principles such as the utility of soft labels and the significance of temperature scaling. Through meticulous examination, we elucidate the critical determinants of successful distillation, including the architecture of the student model, the caliber of the teacher, and the delicate balance of hyperparameters. While acknowledging its profound advantages, we also delve into the complexities and challenges inherent in the process. Our exploration underscores knowledge distillation's potential as a pivotal 
    
[^40]: 量化专家混合（MoQE）：低位量化和鲁棒性的互补效应

    Mixture of Quantized Experts (MoQE): Complementary Effect of Low-bit Quantization and Robustness. (arXiv:2310.02410v1 [cs.LG])

    [http://arxiv.org/abs/2310.02410](http://arxiv.org/abs/2310.02410)

    本文提出了一种量化专家混合（MoQE）方法，通过将专家权重应用2位低位量化，减轻了大规模专家混合（MoE）模型在内存消耗和延迟问题上的压力，同时在大多数情况下不需要额外训练也能保持可靠的模型性能。

    

    大规模的专家混合（MoE）模型在各种语言任务中，包括机器翻译任务，通过专家并行性的高效模型扩展能力，实现了最先进的质量。然而，在部署时，这也带来了更大的内存消耗和增加的内存带宽瓶颈的基本问题。在本文中，我们提出了量化专家混合（MoQE），这是一种简单的仅将专家权重应用于超低位2位量化的量化方法，以减轻MoE模型的增大内存和延迟问题。我们展示了低位量化与MoE架构结合，即使在大多数情况下不需要任何额外的训练，也能提供可靠的模型性能，并且显著减小内存大小。特别地，MoE模型中的专家层对量化比传统的前馈网络（FFN）层更具鲁棒性。在我们的综合分析中，我们展示了MoE模型...

    Large Mixture of Experts (MoE) models could achieve state-of-the-art quality on various language tasks, including machine translation task, thanks to the efficient model scaling capability with expert parallelism. However, it has brought a fundamental issue of larger memory consumption and increased memory bandwidth bottleneck at deployment time. In this paper, we propose Mixture of Quantized Experts (MoQE) which is a simple weight-only quantization method applying ultra low-bit down to 2-bit quantizations only to expert weights for mitigating the increased memory and latency issues of MoE models. We show that low-bit quantization together with the MoE architecture delivers a reliable model performance while reducing the memory size significantly even without any additional training in most cases. In particular, expert layers in MoE models are much more robust to the quantization than conventional feedforward networks (FFN) layers. In our comprehensive analysis, we show that MoE models
    
[^41]: Nugget 2D：用于仅解码器语言模型的动态上下文压缩的扩展

    Nugget 2D: Dynamic Contextual Compression for Scaling Decoder-only Language Models. (arXiv:2310.02409v1 [cs.CL])

    [http://arxiv.org/abs/2310.02409](http://arxiv.org/abs/2310.02409)

    Nugget 2D是一种用于仅解码器语言模型的动态上下文压缩方法，可以在保留任务能力的同时大幅减少解码过程所需的时间和空间开销。

    

    标准的基于Transformer的语言模型在长上下文中缩放效果不佳。我们提出了一种基于动态上下文压缩的解决方案，该方案将Qin＆Van Durme（2023年）的Nugget方法从BERT类框架扩展到仅解码器的语言模型。我们的方法将历史建模为压缩的“nuggets”，这些“nuggets”经过训练可以进行重建，它可以使用诸如LLaMA之类的现成模型进行初始化。我们通过语言建模、问答和摘要的实验证明，Nugget2D在这些任务中保留了能力，同时在解码过程中大幅减少了时间和空间开销。例如，在自动编码实验中，Nugget2D可以以20倍的压缩比收缩上下文，重建时的BLEU得分为98％，实现了近乎无损编码。

    Standard Transformer-based language models (LMs) scale poorly to long contexts. We propose a solution based on dynamic contextual compression, which extends the Nugget approach of Qin & Van Durme (2023) from BERT-like frameworks to decoder-only LMs. Our method models history as compressed "nuggets" which are trained to allow for reconstruction, and it can be initialized with off-the-shelf models such as LLaMA. We demonstrate through experiments in language modeling, question answering, and summarization that Nugget2D retains capabilities in these tasks, while drastically reducing the overhead during decoding in terms of time and space. For example, in the experiments of autoencoding, Nugget2D can shrink context at a 20x compression ratio with a BLEU score of 98% for reconstruction, achieving nearly lossless encoding.
    
[^42]: MindTheDApp: 一种用于以太坊基于去中心化应用程序的复杂网络驱动的结构分析的工具链

    MindTheDApp: A Toolchain for Complex Network-Driven Structural Analysis of Ethereum-based Decentralised Applications. (arXiv:2310.02408v1 [cs.IT])

    [http://arxiv.org/abs/2310.02408](http://arxiv.org/abs/2310.02408)

    MindTheDApp是一种特别设计用于以太坊基于去中心化应用程序的结构分析的工具链，采用复杂的网络驱动方法，通过生成二分图来突出DApp架构的操作效率，以及提供了细粒度视图来展示相互依赖关系和执行流程。

    

    本文介绍了MindTheDApp，这是一种专为以太坊基于去中心化应用程序（DApps）的结构分析而设计的工具链，其独特的重点是复杂的网络驱动方法。与现有工具不同，我们的工具链结合了ANTLR4和抽象语法树（AST）遍历技术的能力，将智能合约中的架构和交互转化为专门的二分图。这使得高级网络分析能够突出DApp架构的操作效率。所提出的工具生成的二分图包括两组节点：一组表示智能合约、接口和库，另一组包括函数、事件和修饰符。图中的边将函数与它们交互的智能合约连接起来，提供了DApp中的相互依赖关系和执行流程的细粒度视图。这种以网络为中心的方法允许研究人员和从业者应用复杂的网络理论

    This paper presents MindTheDApp, a toolchain designed specifically for the structural analysis of Ethereum-based Decentralized Applications (DApps), with a distinct focus on a complex network-driven approach. Unlike existing tools, our toolchain combines the power of ANTLR4 and Abstract Syntax Tree (AST) traversal techniques to transform the architecture and interactions within smart contracts into a specialized bipartite graph. This enables advanced network analytics to highlight operational efficiencies within the DApp's architecture.  The bipartite graph generated by the proposed tool comprises two sets of nodes: one representing smart contracts, interfaces, and libraries, and the other including functions, events, and modifiers. Edges in the graph connect functions to smart contracts they interact with, offering a granular view of interdependencies and execution flow within the DApp. This network-centric approach allows researchers and practitioners to apply complex network theory 
    
[^43]: 无监督语音识别与N-Skipgram和位置序列匹配

    Unsupervised Speech Recognition with N-Skipgram and Positional Unigram Matching. (arXiv:2310.02382v1 [cs.CL])

    [http://arxiv.org/abs/2310.02382](http://arxiv.org/abs/2310.02382)

    引入了一种新颖的无监督语音识别系统ESPUM，利用低阶N-skipgrams和位置序列统计信息，在ASR和音素分割任务中展示出竞争性性能。

    

    训练无监督语音识别系统由于GAN相关的不稳定性、语音和文本之间的不对齐以及巨大的内存需求而面临挑战。为了解决这些问题，我们引入了一种新颖的ASR系统ESPUM。该系统利用了低阶N-skipgrams（最多N=3）和从一小批样本中收集到的位置序列统计信息。在TIMIT基准测试上，我们的模型在ASR和音素分割任务中展示出了竞争性的性能。访问我们公开的代码：https://github.com/lwang114/GraphUnsupASR。

    Training unsupervised speech recognition systems presents challenges due to GAN-associated instability, misalignment between speech and text, and significant memory demands. To tackle these challenges, we introduce a novel ASR system, ESPUM. This system harnesses the power of lower-order N-skipgrams (up to N=3) combined with positional unigram statistics gathered from a small batch of samples. Evaluated on the TIMIT benchmark, our model showcases competitive performance in ASR and phoneme segmentation tasks. Access our publicly available code at https://github.com/lwang114/GraphUnsupASR.
    
[^44]: 会话式健康代理：个性化的基于LLM的代理框架

    Conversational Health Agents: A Personalized LLM-Powered Agent Framework. (arXiv:2310.02374v1 [cs.CL])

    [http://arxiv.org/abs/2310.02374](http://arxiv.org/abs/2310.02374)

    该论文介绍了一个基于LLM的会话式健康代理框架，旨在为代理赋予批判性思维、知识获取和问题解决能力，实现个性化的健康护理服务。该框架能够无缝集成医疗工具，实现多语言和多模态对话，并与多种用户数据分析工具连接。

    

    会话式健康代理（CHAs）是一种互动系统，旨在通过进行共情对话和处理多模态数据来增强个人健康护理服务。当前的CHAs，特别是那些利用大型语言模型（LLMs）的系统，主要关注对话，但往往缺乏全面的代理能力。这包括从可穿戴设备、全天候数据收集源和电子健康记录中获取个人用户的健康数据的能力，以及整合最新发布的健康见解，并与已建立的多模态数据分析工具连接。我们正在开发一个框架，通过赋予CHAs批判性思维、知识获取和问题解决能力来增强它们的能力。我们的CHA平台由LLMs驱动，无缝集成了医疗工具，实现了多语言和多模态对话，并与各种用户数据分析工具进行接口。我们展示了其在处理复杂医疗任务方面的熟练性。

    Conversational Health Agents (CHAs) are interactive systems designed to enhance personal healthcare services by engaging in empathetic conversations and processing multimodal data. While current CHAs, especially those utilizing Large Language Models (LLMs), primarily focus on conversation, they often lack comprehensive agent capabilities. This includes the ability to access personal user health data from wearables, 24/7 data collection sources, and electronic health records, as well as integrating the latest published health insights and connecting with established multimodal data analysis tools. We are developing a framework to empower CHAs by equipping them with critical thinking, knowledge acquisition, and problem-solving abilities. Our CHA platform, powered by LLMs, seamlessly integrates healthcare tools, enables multilingual and multimodal conversations, and interfaces with a variety of user data analysis tools. We illustrate its proficiency in handling complex healthcare tasks, s
    
[^45]: ProtoNER: 使用原型网络进行命名实体识别的少样本增量学习

    ProtoNER: Few shot Incremental Learning for Named Entity Recognition using Prototypical Networks. (arXiv:2310.02372v1 [cs.CL])

    [http://arxiv.org/abs/2310.02372](http://arxiv.org/abs/2310.02372)

    ProtoNER是一种基于原型网络的端到端KVP提取模型，可以在现有模型中添加新类别，而只需最少数量的新注释训练样本。

    

    键值对（KVP）提取或命名实体识别（NER）是文档理解和数据提取领域的研究热点。一些基于transformer的模型如LayoutLMv2、LayoutLMv3和LiLT已经取得了最先进的结果。然而，即使向现有模型添加一个新类别，也需要重新注释整个训练数据集并重新训练模型。这些问题都严重影响了更新模型的部署速度。

    Key value pair (KVP) extraction or Named Entity Recognition(NER) from visually rich documents has been an active area of research in document understanding and data extraction domain. Several transformer based models such as LayoutLMv2, LayoutLMv3, and LiLT have emerged achieving state of the art results. However, addition of even a single new class to the existing model requires (a) re-annotation of entire training dataset to include this new class and (b) retraining the model again. Both of these issues really slow down the deployment of updated model. \\ We present \textbf{ProtoNER}: Prototypical Network based end-to-end KVP extraction model that allows addition of new classes to an existing model while requiring minimal number of newly annotated training samples. The key contributions of our model are: (1) No dependency on dataset used for initial training of the model, which alleviates the need to retain original training dataset for longer duration as well as data re-annotation w
    
[^46]: 关于自然语言处理中毒性定义的探讨

    On the definition of toxicity in NLP. (arXiv:2310.02357v1 [cs.CL])

    [http://arxiv.org/abs/2310.02357](http://arxiv.org/abs/2310.02357)

    这项研究探讨了毒性的定义模糊性问题，并提出了一种基于定量压力的毒性定义来弥补现有定义的缺点。

    

    毒性检测任务中的根本问题在于毒性的定义模糊不清。谷歌旗下的团队Jigsaw是该领域的领导者之一，他们使用Dixon等人给出的毒性定义：“粗鲁、不尊重或不合理的语言，可能会让某人离开讨论”。人们可以立即看到这个定义的问题，因为它没有给出毒性的定量度量，而且涉及高度主观的文化术语。尽管存在模糊和缺陷，但这个定义已经成为许多研究者广泛采用的实际标准。在这项工作中，我们提出了一种基于定量压力的毒性定义，克服了现有的缺点。

    The fundamental problem in toxicity detection task lies in the fact that the toxicity is ill-defined. Jigsaw, a unit within Google and one of the leaders in the field, uses a definition of toxicity given by Dixon et al. - 'rude, disrespectful, or unreasonable language that is likely to make someone leave a discussion'. One can instantly see the issue with this definition, as it gives no quantitative measure of the toxicity and operates with highly subjective cultural terms. Despite all vagueness and flaws, this definition is de-facto widely used by many researchers. In this work we suggest quantative stress-based defenition for the toxicity that overcomes existing shortcomings.
    
[^47]: 自学优化器（STOP）：递归自我改进的代码生成

    Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation. (arXiv:2310.02304v1 [cs.CL])

    [http://arxiv.org/abs/2310.02304](http://arxiv.org/abs/2310.02304)

    本文提出了一种自学优化器（STOP），通过递归自我改进的代码生成，使用融合了语言模型的脚手架程序来改进自身，从而生成性能更好的程序。

    

    最近几年的人工智能系统（例如思维树和程序辅助语言模型）取得了一些重要进展，通过提供一个“脚手架”程序来解决问题，该程序构建了多次调用语言模型以生成更好的输出。脚手架程序通常使用Python等编程语言编写。在这项工作中，我们使用了一个融合了语言模型的脚手架程序来改进自身。我们从一个种子“改进器”开始，通过多次查询语言模型并返回最佳解决方案，根据给定的效用函数来改进输入程序。然后，我们运行这个种子改进器来改进自身。在一系列细分任务中，得到的改进改进器生成的程序在性能上明显优于种子改进器。随后，我们对语言模型提出的各种自我改进策略进行了分析，包括波束搜索、遗传算法和模拟退火。由于语言模型本身没有改变，这并不是一种增长领域。

    Several recent advances in AI systems (e.g., Tree-of-Thoughts and Program-Aided Language Models) solve problems by providing a "scaffolding" program that structures multiple calls to language models to generate better outputs. A scaffolding program is written in a programming language such as Python. In this work, we use a language-model-infused scaffolding program to improve itself. We start with a seed "improver" that improves an input program according to a given utility function by querying a language model several times and returning the best solution. We then run this seed improver to improve itself. Across a small set of downstream tasks, the resulting improved improver generates programs with significantly better performance than its seed improver. Afterward, we analyze the variety of self-improvement strategies proposed by the language model, including beam search, genetic algorithms, and simulated annealing. Since the language models themselves are not altered, this is not fu
    
[^48]: 实时客服呼叫中心对话中的端到端连续语音情感识别

    End-to-End Continuous Speech Emotion Recognition in Real-life Customer Service Call Center Conversations. (arXiv:2310.02281v1 [eess.AS])

    [http://arxiv.org/abs/2310.02281](http://arxiv.org/abs/2310.02281)

    本研究介绍了一个用于实时客服呼叫中心对话中连续语音情感识别的大规模数据集CusEmo，采用维度情感注释方法捕捉情感的微妙、复杂和连续性，并解决了应用于数据集时的挑战。

    

    在呼叫中心对话中进行语音情感识别已经成为评估客户和代理人之间互动质量的有价值工具。与受控实验室环境不同，实际对话发生在不受控制的环境下，并受到影响情感表达的情境因素的影响。本文介绍了我们构建大规模实时数据集（CusEmo）用于客户服务呼叫中心对话中连续语音情感识别的方法。我们采用维度情感注释方法捕捉实际呼叫中心对话中情感的微妙、复杂和连续性，并对情境信息进行了注释。研究还解决了将端到端（E2E）语音情感识别系统应用于数据集时遇到的挑战，包括确定适当的标签采样率和输入片段长度，以及整合情境信息（对话者的性别）。

    Speech Emotion recognition (SER) in call center conversations has emerged as a valuable tool for assessing the quality of interactions between clients and agents. In contrast to controlled laboratory environments, real-life conversations take place under uncontrolled conditions and are subject to contextual factors that influence the expression of emotions. In this paper, we present our approach to constructing a large-scale reallife dataset (CusEmo) for continuous SER in customer service call center conversations. We adopted the dimensional emotion annotation approach to capture the subtlety, complexity, and continuity of emotions in real-life call center conversations, while annotating contextual information. The study also addresses the challenges encountered during the application of the End-to-End (E2E) SER system to the dataset, including determining the appropriate label sampling rate and input segment length, as well as integrating contextual information (interlocutor's gender 
    
[^49]: 谁是哈利·波特？LLMs中的近似遗忘。

    Who's Harry Potter? Approximate Unlearning in LLMs. (arXiv:2310.02238v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.02238](http://arxiv.org/abs/2310.02238)

    本文介绍了一种新的技术，用于从LLM中遗忘特定的训练数据，而无需重新训练模型。通过在Llama2-7b模型上的实验，我们证明了在短时间的微调中，我们可以有效地擦除模型关于哈利·波特相关内容的能力，同时保持其在其他常见基准测试上的性能几乎不变。

    

    大型语言模型（LLMs）是在包含版权内容的海量互联网语料库上进行训练的。这给模型的开发者和用户，以及原始作者和出版商带来了法律和伦理挑战。本文提出了一种新的技术，可以从LLM中遗忘训练数据的子集，而无需从头开始重新训练。我们在Llama2-7b模型上评估了我们的技术，这是一个由Meta最近开源的生成式语言模型。虽然该模型的预训练花费了超过184K GPU小时，但我们展示了在大约1个GPU小时的微调中，我们有效地擦除了模型生成或回忆哈利·波特相关内容的能力，同时在常见基准测试（如Winogrande，Hellaswag，arc，boolq和piqa）上的表现几乎没有受到影响。我们在HuggingFace上公开提供了我们的微调模型，供社区评估。据我们所知，这是第一次实现这样的功能。

    Large language models (LLMs) are trained on massive internet corpora that often contain copyrighted content. This poses legal and ethical challenges for the developers and users of these models, as well as the original authors and publishers. In this paper, we propose a novel technique for unlearning a subset of the training data from a LLM, without having to retrain it from scratch.  We evaluate our technique on the task of unlearning the Harry Potter books from the Llama2-7b model (a generative language model recently open-sourced by Meta). While the model took over 184K GPU-hours to pretrain, we show that in about 1 GPU hour of finetuning, we effectively erase the model's ability to generate or recall Harry Potter-related content, while its performance on common benchmarks (such as Winogrande, Hellaswag, arc, boolq and piqa) remains almost unaffected. We make our fine-tuned model publicly available on HuggingFace for community evaluation. To the best of our knowledge, this is the fi
    
[^50]: OceanGPT：用于海洋科学任务的大型语言模型

    OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v1 [cs.CL])

    [http://arxiv.org/abs/2310.02031](http://arxiv.org/abs/2310.02031)

    OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。

    

    海洋科学是探索充满生命和生物多样性的海洋的科学，考虑到海洋覆盖了地球表面的70％以上，这一领域具有重要意义。最近，大型语言模型（LLM）的进展改变了科学的范式。尽管在其他领域取得了成功，但现有的LLM通常无法满足海洋学家等领域专家的需求，同时对LLM在海洋科学中的潜力尚未得到充分探索。这其中的根本原因可能是海洋数据的庞大而复杂的性质，以及对更高的粒度和丰富的知识的需求。为了解决这些问题，我们推出了首个海洋领域的LLM——OceanGPT，该模型擅长各种海洋科学任务。我们提出了一个新颖的框架DoInstruct，用于自动获取大量的海洋领域指导数据，它基于多智能体的协作生成指导。

    Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge. To alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean domain, which is expert in various ocean science tasks. We propose DoInstruct, a novel framework to automatically obtain a large volume of ocean domain instruction data, which generates instructions based on multi-agent collaboration. Additionally, we construct the first oceanography benchmark, OceanBench,
    
[^51]: 有效且参数高效的重复使用微调模型

    Effective and Parameter-Efficient Reusing Fine-Tuned Models. (arXiv:2310.01886v1 [cs.LG])

    [http://arxiv.org/abs/2310.01886](http://arxiv.org/abs/2310.01886)

    本文提出了一种有效且参数高效的方法，可以重复使用微调模型来处理下游任务，减轻存储和服务负担，并提出了PERU-FFT方法用于重复使用全面微调模型。

    

    许多在线提供的预训练大规模模型在传递到下游任务中变得非常有效。与此同时，各种在这些预训练模型上微调的任务特定模型也可供公众使用。在实践中，由于收集任务特定数据耗时且微调大规模预训练模型计算复杂，可以重复使用任务特定微调模型来处理下游任务。然而，为每个任务使用一个模型会给存储和服务带来巨大负担。最近，有许多无需训练且参数高效的方法被提出，将多个微调的任务特定模型重复使用到一个多任务模型中。然而，与为每个任务使用微调模型相比，这些方法表现出较大的准确性差距。本文中，我们提出了参数高效方法来重复使用微调模型。针对重复使用全面微调模型，我们提出了PERU-FFT，通过将稀疏任务向量注入到一个mer模型中来实现。

    Many pre-trained large-scale models provided online have become highly effective in transferring to downstream tasks. At the same time, various task-specific models fine-tuned on these pre-trained models are available online for public use. In practice, as collecting task-specific data is labor-intensive and fine-tuning the large pre-trained models is computationally expensive, one can reuse task-specific finetuned models to deal with downstream tasks. However, using a model per task causes a heavy burden on storage and serving. Recently, many training-free and parameter-efficient methods have been proposed for reusing multiple fine-tuned task-specific models into a single multi-task model. However, these methods exhibit a large accuracy gap compared with using a fine-tuned model per task. In this paper, we propose Parameter-Efficient methods for ReUsing (PERU) fine-tuned models. For reusing Fully Fine-Tuned (FFT) models, we propose PERU-FFT by injecting a sparse task vector into a mer
    
[^52]: 保留音位差异的序数回归：一种用于自动发音评估的新型损失函数

    Preserving Phonemic Distinctions for Ordinal Regression: A Novel Loss Function for Automatic Pronunciation Assessment. (arXiv:2310.01839v1 [eess.AS])

    [http://arxiv.org/abs/2310.01839](http://arxiv.org/abs/2310.01839)

    这项研究提出了一种新的损失函数，用于训练自动发音评估模型。该损失函数旨在在保持音位类别之间更好的音位差异的同时，考虑到回归目标输出的有序关系。通过引入音位-区分正则化器，该方法可以有效提高发音评估的准确度。

    

    自动发音评估（APA）可以量化第二语言（L2）学习者在语言中的发音熟练程度。常见的APA方法通常利用神经模型和回归损失函数（如均方误差损失）进行熟练水平预测。尽管大多数回归模型可以在特征空间有效地捕捉到熟练水平的有序性，但它们面临一个主要障碍，即不同音素类别的相同熟练水平必然被迫靠得很近，保留了更少的音位—区分信息。因此，我们设计了一种用于训练基于回归的APA模型的音位对比序数（PCO）损失，旨在在保持音位类别之间更好的音位差异的同时，考虑回归目标输出的有序关系。具体而言，我们将一个音位—区分正则化器引入到均方误差损失中，鼓励...（待续）

    Automatic pronunciation assessment (APA) manages to quantify the pronunciation proficiency of a second language (L2) learner in a language. Prevailing approaches to APA normally leverage neural models trained with a regression loss function, such as the mean-squared error (MSE) loss, for proficiency level prediction. Despite most regression models can effectively capture the ordinality of proficiency levels in the feature space, they are confronted with a primary obstacle that different phoneme categories with the same proficiency level are inevitably forced to be close to each other, retaining less phoneme-discriminative information. On account of this, we devise a phonemic contrast ordinal (PCO) loss for training regression-based APA models, which aims to preserve better phonemic distinctions between phoneme categories meanwhile considering ordinal relationships of the regression target output. Specifically, we introduce a phoneme-distinct regularizer into the MSE loss, which encoura
    
[^53]: LLM谎言: 幻觉不是漏洞，而是对抗样本的特征。

    LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples. (arXiv:2310.01469v1 [cs.CL])

    [http://arxiv.org/abs/2310.01469](http://arxiv.org/abs/2310.01469)

    LLM似乎具有丰富的知识和适应多种任务的能力，但我们不能完全信任它们的回答，因为它们会出现幻觉，即捏造不存在的事实以欺骗用户。本文证明了由随机标记组成的无意义提示也能引起LLM产生幻觉回应，并提出了一种对抗方式的自动幻觉触发方法作为幻觉攻击，同时提出了一种简单而有效的防御策略。

    

    大型语言模型（LLM），包括GPT-3.5、LLaMA和PaLM，似乎具有丰富的知识和适应多种任务的能力。然而，我们仍然不能完全信任它们的回答，因为LLM会出现幻觉，即捏造不存在的事实以欺骗用户而不被察觉。幻觉存在的原因和普遍性仍然不清楚。在本文中，我们证明了由随机标记组成的无意义提示也能引起LLM产生幻觉回应。这个现象迫使我们重新审视幻觉可能是对抗样本的另一种视角，并且它与常规的对抗样本具有类似的特征，作为LLM的基本特征。因此，我们以对抗的方式将自动幻觉触发方法形式化为幻觉攻击。最后，我们研究了被攻击的对抗提示的基本特征，并提出了一种简单而有效的防御策略。我们的代码已在GitHub上发布。

    Large Language Models (LLMs), including GPT-3.5, LLaMA, and PaLM, seem to be knowledgeable and able to adapt to many tasks. However, we still can not completely trust their answer, since LLMs suffer from hallucination--fabricating non-existent facts to cheat users without perception. And the reasons for their existence and pervasiveness remain unclear. In this paper, we demonstrate that non-sense prompts composed of random tokens can also elicit the LLMs to respond with hallucinations. This phenomenon forces us to revisit that hallucination may be another view of adversarial examples, and it shares similar features with conventional adversarial examples as the basic feature of LLMs. Therefore, we formalize an automatic hallucination triggering method as the hallucination attack in an adversarial way. Finally, we explore basic feature of attacked adversarial prompts and propose a simple yet effective defense strategy. Our code is released on GitHub.
    
[^54]: 实体推断竞技场：探究LLMs的对话推理和规划能力的平台

    The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs. (arXiv:2310.01468v1 [cs.CL])

    [http://arxiv.org/abs/2310.01468](http://arxiv.org/abs/2310.01468)

    本文提供了一个评估框架，通过向法官提出一系列查询来评估LLMs的对话推理和规划能力。我们发现不同的LLMs在这个任务上表现出显著差异。

    

    目前，大型语言模型（LLMs）在回答明确提问时非常有效。然而，当面临含糊不清的查询时，它们可能行为难以预测并产生错误的输出。这凸显了需要开发能够提出澄清问题以有效解决歧义的智能代理的需求。这种能力需要对多个对话轮次进行复杂的理解、状态跟踪、推理和规划。然而，直接测量这种能力可能具有挑战性。在本文中，我们提供了一个替代性问题，通过向法官提出一系列查询，评估了LLMs推断自己不知道但被法官揭示的实体的能力。这个“实体推断游戏”可以作为一个评估框架，用于探究语言模型的对话推理和规划能力。我们系统地评估了各种LLMs，并发现在这个任务上它们的性能存在显著差异。我们发现强大的LLMs...

    Large language models (LLMs) are currently effective at answering questions that are clearly asked. However, when faced with ambiguous queries they can act unpredictably and produce incorrect outputs. This underscores the need for the development of intelligent agents capable of asking clarification questions to resolve ambiguities effectively. This capability requires complex understanding, state tracking, reasoning and planning over multiple conversational turns. However, directly measuring this can be challenging. In this paper, we offer a surrogate problem which assesses an LLMs's capability to deduce an entity unknown to itself, but revealed to a judge, by asking the judge a series of queries. This \textit{entity-deducing game} can serve as an evaluation framework to probe the conversational reasoning and planning capabilities of language models. We systematically evaluate various LLMs and discover significant differences in their performance on this task. We find that strong LLMs
    
[^55]: 更少就意味着更多: 对参数高效微调的特洛伊攻击

    Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning. (arXiv:2310.00648v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00648](http://arxiv.org/abs/2310.00648)

    本文研究了参数高效微调（PEFT）的安全性问题，发现PEFT易受特洛伊攻击。通过提出一种新的攻击方式PETA，并在各种下游任务和触发器设计中进行广泛测试，发现PETA能够在攻击成功率和未受影响的准确性方面取得有效结果。

    

    参数高效微调（PEFT）可以将预训练语言模型（PLM）高效地适应到特定任务中。通过仅微调一小部分（额外的）参数，PEFT实现了与全面微调相当的性能。然而，尽管它被广泛使用，但PEFT的安全性影响仍然鲜为人知。在本文中，我们进行了一项初步研究，揭示了PEFT对特洛伊攻击的独特易受攻击性。具体而言，我们提出了PETA，一种通过双层优化考虑下游适应的新型攻击方式：上层目标将后门嵌入PLM中，而下层目标模拟PEFT以保留PLM的任务特定性能。通过对多种下游任务和触发器设计的广泛评估，我们证明了PETA在攻击成功率和未受影响的干净准确性方面的有效性，即使受害用户在使用纯净数据对带有后门的PLM进行PEFT后。

    Parameter-efficient fine-tuning (PEFT) enables efficient adaptation of pre-trained language models (PLMs) to specific tasks. By tuning only a minimal set of (extra) parameters, PEFT achieves performance comparable to full fine-tuning. However, despite its prevalent use, the security implications of PEFT remain largely unexplored. In this paper, we conduct a pilot study revealing that PEFT exhibits unique vulnerability to trojan attacks. Specifically, we present PETA, a novel attack that accounts for downstream adaptation through bilevel optimization: the upper-level objective embeds the backdoor into a PLM while the lower-level objective simulates PEFT to retain the PLM's task-specific performance. With extensive evaluation across a variety of downstream tasks and trigger designs, we demonstrate PETA's effectiveness in terms of both attack success rate and unaffected clean accuracy, even after the victim user performs PEFT over the backdoored PLM using untainted data. Moreover, we empi
    
[^56]: ToRA：一种集成工具的数学问题求解推理代理

    ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving. (arXiv:2309.17452v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.17452](http://arxiv.org/abs/2309.17452)

    ToRA是一种集成工具的数学问题求解推理代理，通过结合语言的分析能力和工具的计算效率，能够显著提高数学推理的性能，在多个数学推理数据集上取得了13%-19%的平均绝对改进率，并在竞赛级数据集MATH上达到了44.6%的性能。

    

    大型语言模型在各种语言任务中取得了重大进展，但在复杂的数学问题上仍然存在困难。在本文中，我们提出了一系列集成工具的推理代理ToRA，它通过无缝地将自然语言推理与外部工具（例如计算库和符号求解器）的利用相结合，从而将语言的分析能力与工具的计算效率融合在一起，用于解决具有挑战性的数学问题。为了训练ToRA，我们精选了数学数据集上的互动工具使用轨迹，应用模仿学习于注释，并提出输出空间整形来进一步改进模型的推理行为。结果显示，ToRA模型在10个涵盖各种规模的数学推理数据集上显著优于开源模型，平均绝对改进率达到13%至19%。值得注意的是，ToRA-7B 在竞赛级数据集MATH上达到了44.6%，超越了最佳开源模型WizardMath。

    Large language models have made significant progress in various language tasks, yet they still struggle with complex mathematics. In this paper, we propose ToRA a series of Tool-integrated Reasoning Agents designed to solve challenging mathematical problems by seamlessly integrating natural language reasoning with the utilization of external tools (e.g., computation libraries and symbolic solvers), thereby amalgamating the analytical prowess of language and the computational efficiency of tools. To train ToRA, we curate interactive tool-use trajectories on mathematical datasets, apply imitation learning on the annotations, and propose output space shaping to further refine models' reasoning behavior. As a result, ToRA models significantly outperform open-source models on 10 mathematical reasoning datasets across all scales with 13%-19% absolute improvements on average. Notably, ToRA-7B reaches 44.6% on the competition-level dataset MATH, surpassing the best open-source model WizardMath
    
[^57]: DeepSpeed Ulysses：用于训练极长序列Transformer模型的系统优化

    DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models. (arXiv:2309.14509v1 [cs.LG])

    [http://arxiv.org/abs/2309.14509](http://arxiv.org/abs/2309.14509)

    本论文介绍了DeepSpeed-Ulysses，一种用于实现具备极长序列长度的高效可扩展LLM训练的新颖方法。

    

    传统的基于Transformer的大型语言模型（LLM）的计算可以通过批量大小、隐藏维度、层数和序列长度来描述。到目前为止，加速LLM训练的系统工作主要集中在前三个维度上：批量大小的数据并行化、隐藏尺寸的张量并行化以及模型深度或层数的流水线并行化。这些被广泛研究的并行形式并不针对长序列Transformer模型进行优化。鉴于长序列LLM在实际应用需求上的重要性，序列并行化引起了重新关注。然而，现有的序列并行化工作受到内存通信效率的限制，限制了它们在长序列大模型上的可扩展性。在这项工作中，我们引入了DeepSpeed-Ulysses，一种新颖、便携且有效的方法，用于实现具备极长序列长度的高效可扩展LLM训练。

    Computation in a typical Transformer-based large language model (LLM) can be characterized by batch size, hidden dimension, number of layers, and sequence length. Until now, system works for accelerating LLM training have focused on the first three dimensions: data parallelism for batch size, tensor parallelism for hidden size and pipeline parallelism for model depth or layers. These widely studied forms of parallelism are not targeted or optimized for long sequence Transformer models. Given practical application needs for long sequence LLM, renewed attentions are being drawn to sequence parallelism. However, existing works in sequence parallelism are constrained by memory-communication inefficiency, limiting their scalability to long sequence large models. In this work, we introduce DeepSpeed-Ulysses, a novel, portable and effective methodology for enabling highly efficient and scalable LLM training with extremely long sequence length. DeepSpeed-Ulysses at its core partitions input da
    
[^58]: 对多模态大规模语言模型中的灾难性遗忘进行的研究

    Investigating the Catastrophic Forgetting in Multimodal Large Language Models. (arXiv:2309.10313v1 [cs.CL])

    [http://arxiv.org/abs/2309.10313](http://arxiv.org/abs/2309.10313)

    本论文针对多模态大规模语言模型中的灾难性遗忘问题进行研究，引入了EMT方法来评估灾难性遗忘，并发现在标准图像分类任务上，几乎所有评估的模型都无法保持与视觉编码器相同的性能水平。研究结果表明，早期微调阶段对性能至关重要。

    

    在GPT4的成功之后，多模态大规模语言模型（MLLM）研究引起了广泛关注。这一研究方向侧重于通过微调预训练的LLM和视觉模型来开发通用的LLM。然而，灾难性遗忘，即微调模型无法保持与预训练模型相似的性能水平，仍然是多模态LLM（MLLM）中的一个固有问题。本文介绍了EMT：用于评估MLLM中灾难性遗忘的评估方法，将每个MLLM作为一个图像分类器进行评估。我们首先应用EMT来评估几个开源的微调MLLM，并发现几乎所有评估的MLLM在标准图像分类任务上无法保持与他们的视觉编码器相同的性能水平。此外，我们继续微调LLaVA，一种MLLM，并利用EMT来评估整个微调过程中的性能。有趣的是，我们的结果表明，早期的微调阶段是关键的，过早停止微调可能导致低性能的模型。

    Following the success of GPT4, there has been a surge in interest in multimodal large language model (MLLM) research. This line of research focuses on developing general-purpose LLMs through fine-tuning pre-trained LLMs and vision models. However, catastrophic forgetting, a notorious phenomenon where the fine-tuned model fails to retain similar performance compared to the pre-trained model, still remains an inherent problem in multimodal LLMs (MLLM). In this paper, we introduce EMT: Evaluating MulTimodality for evaluating the catastrophic forgetting in MLLMs, by treating each MLLM as an image classifier. We first apply EMT to evaluate several open-source fine-tuned MLLMs and we discover that almost all evaluated MLLMs fail to retain the same performance levels as their vision encoders on standard image classification tasks. Moreover, we continue fine-tuning LLaVA, an MLLM and utilize EMT to assess performance throughout the fine-tuning. Interestingly, our results suggest that early-sta
    
[^59]: 稀疏自编码器在语言模型中发现高度可解释的特征

    Sparse Autoencoders Find Highly Interpretable Features in Language Models. (arXiv:2309.08600v1 [cs.LG])

    [http://arxiv.org/abs/2309.08600](http://arxiv.org/abs/2309.08600)

    本研究通过稀疏自编码器在语言模型中发现了一组高度可解释和单一义的特征，从而解决了神经网络内部多义性的问题。

    

    神经网络内部理解的一个障碍是多义性，其中神经元在多个语义不同的上下文中激活。多义性使我们无法找到简洁的、人类可理解的解释来解释神经网络内部的工作。多义性的一个猜测原因是叠加效应，即神经网络通过将特征分配给激活空间中的一个过完备方向集合，而不是个别神经元，表示更多的特征。在这里，我们尝试使用稀疏自编码器来确定这些方向，以重构语言模型的内部激活。这些自编码器学习到的一组稀疏激活特征比其他方法鉴定出的方向更可解释和单一义，解释性是通过自动化方法衡量的。删除这些特征可以实现精确的模型编辑，例如通过删除这些特征可以改变模型输出。

    One of the roadblocks to a better understanding of neural networks' internals is \textit{polysemanticity}, where neurons appear to activate in multiple, semantically distinct contexts. Polysemanticity prevents us from identifying concise, human-understandable explanations for what neural networks are doing internally. One hypothesised cause of polysemanticity is \textit{superposition}, where neural networks represent more features than they have neurons by assigning features to an overcomplete set of directions in activation space, rather than to individual neurons. Here, we attempt to identify those directions, using sparse autoencoders to reconstruct the internal activations of a language model. These autoencoders learn sets of sparsely activating features that are more interpretable and monosemantic than directions identified by alternative approaches, where interpretability is measured by automated methods. Ablating these features enables precise model editing, for example, by remo
    
[^60]: 通过内在和外在置信度评估来量化任意语言模型回答的不确定性

    Quantifying Uncertainty in Answers from any Language Model via Intrinsic and Extrinsic Confidence Assessment. (arXiv:2308.16175v1 [cs.CL])

    [http://arxiv.org/abs/2308.16175](http://arxiv.org/abs/2308.16175)

    本文引入了BSDetector，一种用于检测预训练大型语言模型生成的错误和推测性回答的方法。该方法通过估计置信度量化了回答的不确定性，并在闭合型和开放型问答基准实验中表现出更准确的识别能力。

    

    我们引入了BSDetector，一种通过估计预训练大型语言模型生成的任何输出的数值置信度来检测错误和推测性回答的方法。我们的不确定性量化技术适用于仅通过黑盒API访问的任何LLM，并将内在和外在评估的置信度结合为对给定提示下LLM响应的单个可信度估计。我们的方法非常通用，可以应用于当今所有最好的LLM（其训练数据未知）。通过额外的计算，任何LLM API的用户现在可以获得与通常相同的响应，以及一个置信度估计，以便在不信任该响应时保持谨慎。对于闭合型和开放型问答基准的实验表明，BSDetector比其他不确定性估计方法（对于GPT-3和ChatGPT）更准确地识别出错误的LLM响应。通过对多个响应进行采样

    We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, and combines intrinsic and extrinsic assessments of confidence into a single trustworthiness estimate for any LLM response to a given prompt. Our method is extremely general and can applied to all of the best LLMs available today (whose training data remains unknown). By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a confidence estimate that caution when not to trust this response. Experiments on both closed and open-form Question-Answer benchmarks reveal that BSDetector more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures (for both GPT-3 and ChatGPT). By sampling multiple responses
    
[^61]: 大型语言模型的指令调优：一项调研

    Instruction Tuning for Large Language Models: A Survey. (arXiv:2308.10792v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10792](http://arxiv.org/abs/2308.10792)

    本文调查了指令调优这一关键技术在增强大型语言模型能力和可控性方面的研究工作，包括方法、数据集构建、模型训练和应用，以及对结果影响的分析。同时回顾了可能的问题和批评，并指出了目前的不足。

    

    本文调查了指令调优（IT）这一快速发展的领域中的研究工作，这是一种增强大型语言模型（LLM）能力和可控性的关键技术。指令调优是指以监督方式在包含“指令-输出”对的数据集上进一步训练LLM，这将LLM的下一个词预测目标与用户希望LLM遵守人类指令的目标之间的差距。本文对IT的常规方法、IT数据集的构建、IT模型的训练以及应用于不同模态、领域和应用的情况进行了系统的文献综述，并对影响IT结果的各个方面进行了分析（例如，指令输出的生成、指令数据集的大小等）。我们还回顾了IT的潜在问题以及针对其的批评，以及指出当前不足的努力。

    This paper surveys research works in the quickly advancing field of instruction tuning (IT), a crucial technique to enhance the capabilities and controllability of large language models (LLMs). Instruction tuning refers to the process of further training LLMs on a dataset consisting of \textsc{(instruction, output)} pairs in a supervised fashion, which bridges the gap between the next-word prediction objective of LLMs and the users' objective of having LLMs adhere to human instructions. In this work, we make a systematic review of the literature, including the general methodology of IT, the construction of IT datasets, the training of IT models, and applications to different modalities, domains and applications, along with an analysis on aspects that influence the outcome of IT (e.g., generation of instruction outputs, size of the instruction dataset, etc). We also review the potential pitfalls of IT along with criticism against it, along with efforts pointing out current deficiencies 
    
[^62]: AutoGen:通过多代理对话框架实现下一代LLM应用

    AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework. (arXiv:2308.08155v1 [cs.AI])

    [http://arxiv.org/abs/2308.08155](http://arxiv.org/abs/2308.08155)

    AutoGen是一种新的框架，通过多个可以互相对话的代理，实现了下一代LLM应用。它利用人类的理解和智能，优雅地处理不完美的生成和推理能力，并通过自动化代理对话简化了复杂的工作流程。

    

    本技术报告介绍了AutoGen，一种新的框架，通过多个可以互相对话的代理来开发LLM应用程序以解决任务。AutoGen代理可以定制、可对话，并且可以无缝地允许人类参与。它们可以在各种模式下运行，利用LLM、人类输入和工具的组合。AutoGen的设计提供了多个优势：a）它能够优雅地处理这些LLM的强大但不完美的生成和推理能力；b）它利用人类的理解和智能，通过代理之间的对话提供有价值的自动化；c）它简化和统一了复杂LLM工作流程的实现，作为自动化代理对话。我们提供了许多不同的例子，展示了开发人员如何轻松使用AutoGen有效地解决任务或构建应用程序，涵盖编程、数学、运筹学、娱乐、在线决策、问答等多个领域。

    This technical report presents AutoGen, a new framework that enables development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools. AutoGen's design offers multiple advantages: a) it gracefully navigates the strong but imperfect generation and reasoning abilities of these LLMs; b) it leverages human understanding and intelligence, while providing valuable automation through conversations between agents; c) it simplifies and unifies the implementation of complex LLM workflows as automated agent chats. We provide many diverse examples of how developers can easily use AutoGen to effectively solve tasks or build applications, ranging from coding, mathematics, operations research, entertainment, online decision-making, question answering, etc.
    
[^63]: L-Eval：为长文本语言模型引入标准化评估

    L-Eval: Instituting Standardized Evaluation for Long Context Language Models. (arXiv:2307.11088v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.11088](http://arxiv.org/abs/2307.11088)

    该论文提出了L-Eval，旨在为长文本语言模型引入标准化评估。通过开发一个包含411个长文档和2000多个人工标注的查询-回复对的数据集，研究探讨了扩展上下文对于处理长输入的实质性收益和改进程度。

    

    最近，对于扩展指令跟随模型的上下文长度，以便有效处理单回合的长输入（例如，论文总结）和具有更复杂历史的对话，引起了越来越多的关注。虽然像GPT-4和Claude这样的专有模型在处理极长输入方面取得了显著进步，但开放源代码模型仍处于尝试阶段。目前还不清楚扩展上下文是否能够比传统方法（如检索）提供实质性的收益，以及它在实际下游任务中对常规模型的改进程度。为了解决这一挑战，我们提出了为长上下文语言模型引入标准化评估的方案。具体而言，我们开发了L-Eval，其中包含411个长文档和2000多个人工标注的查询-回复对，涵盖法律、金融、学校讲座、长对话、新闻、长篇小说和会议等领域。

    Recently, there has been growing interest in extending the context length of instruction-following models in order to effectively process single-turn long input (e.g. summarizing a paper) and conversations with more extensive histories. While proprietary models such as GPT-4 and Claude have shown significant strides in handling extremely lengthy input, open-sourced models are still in the early stages of experimentation. It also remains unclear whether extending the context can offer substantial gains over traditional methods such as retrieval, and to what extent it improves upon their regular counterparts in practical downstream tasks. To address this challenge, we propose instituting standardized evaluation for long context language models. Concretely, we develop L-Eval which contains 411 long documents and over 2,000 human-labeled query-response pairs encompassing areas such as law, finance, school lectures, lengthy conversations, news, long-form novels, and meetings. L-Eval also ad
    
[^64]: FLASK: 基于对齐技能集的细粒度语言模型评估

    FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets. (arXiv:2307.10928v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.10928](http://arxiv.org/abs/2307.10928)

    FLASK是一种基于对齐技能集的细粒度语言模型评估协议，通过将粗级评分分解为每个指令的技能集级评分，实现了对模型性能的全面视角和提高评估的可靠性。

    

    由于指令需要与人类的价值观进行对齐，并且所需的技能集根据指令而异，因此对大型语言模型（LLMs）进行评估具有挑战性。然而，先前的研究主要集中在粗粒度评估（即基于整体偏好的评估），这限制了可解释性，因为它未考虑需要实例级技能组合的用户指令的特性。在本文中，我们介绍了FLASK（基于对齐技能集的细粒度语言模型评估），这是一种细粒度评估协议，用于人类和模型的评估，它将粗级评分分解为每个指令的技能集级评分。通过实验证明，评估的细粒度对于获得对模型性能的全面视角和提高评估的可靠性至关重要。利用FLASK，我们比较了多个开源和专有LLMs，并观察到高度相关性。

    Evaluation of Large Language Models (LLMs) is challenging because instruction-following necessitates alignment with human values and the required set of skills varies depending on the instruction. However, previous studies have mainly focused on coarse-grained evaluation (i.e. overall preference-based evaluation), which limits interpretability since it does not consider the nature of user instructions that require instance-wise skill composition. In this paper, we introduce FLASK (Fine-grained Language Model Evaluation based on Alignment Skill Sets), a fine-grained evaluation protocol for both human-based and model-based evaluation which decomposes coarse-level scoring to a skill set-level scoring for each instruction. We experimentally observe that the fine-graininess of evaluation is crucial for attaining a holistic view of model performance and increasing the reliability of the evaluation. Using FLASK, we compare multiple open-source and proprietary LLMs and observe a high correlati
    
[^65]: ValiTex -- 一种用于计算文本的社会科学构建度量的统一验证框架

    ValiTex -- a uniform validation framework for computational text-based measures of social science constructs. (arXiv:2307.02863v1 [cs.CL])

    [http://arxiv.org/abs/2307.02863](http://arxiv.org/abs/2307.02863)

    ValiTex是一个统一的验证框架，旨在帮助学者们基于文本数据来度量社会科学构建。它借鉴了心理测量学的传统，通过概念模型和动态检查表提供了验证的结构和步骤。

    

    关于如何验证计算文本的社会科学构建度量的指导是分散的。虽然学者们普遍认识到验证他们的文本度量的重要性，但他们通常缺乏共同的术语和统一的框架来进行验证。本文介绍了一个名为ValiTex的新验证框架，旨在帮助学者们基于文本数据来度量社会科学构建。该框架借鉴了心理测量学中长期存在的传统，同时扩展了框架以适用于计算文本分析的目的。ValiTex包括两个组成部分，一个是概念模型，一个是动态检查表。概念模型提供了一个通用的结构，可以指导验证的不同阶段，动态检查表定义了具体的验证步骤，并提供了哪些步骤可能被认为是推荐的（即提供相关和必要的验证证据）或可选的（即对提供额外信息有用的）。

    Guidance on how to validate computational text-based measures of social science constructs is fragmented. Whereas scholars are generally acknowledging the importance of validating their text-based measures, they often lack common terminology and a unified framework to do so. This paper introduces a new validation framework called ValiTex, designed to assist scholars to measure social science constructs based on textual data. The framework draws on a long-established tradition within psychometrics while extending the framework for the purpose of computational text analysis. ValiTex consists of two components, a conceptual model, and a dynamic checklist. Whereas the conceptual model provides a general structure along distinct phases on how to approach validation, the dynamic checklist defines specific validation steps and provides guidance on which steps might be considered recommendable (i.e., providing relevant and necessary validation evidence) or optional (i.e., useful for providing 
    
[^66]: 抽象文本摘要中的命名实体包含

    Named Entity Inclusion in Abstractive Text Summarization. (arXiv:2307.02570v1 [cs.CL])

    [http://arxiv.org/abs/2307.02570](http://arxiv.org/abs/2307.02570)

    该论文提出了一种解决抽象文本摘要中命名实体遗漏问题的方法，通过使用定制的预训练目标和模型训练策略，改善了命名实体的包含情况，提高了摘要的准确性和召回率。

    

    我们解决了许多当前抽象文本摘要器的缺点，即命名实体的遗漏问题。我们建议采用定制的预训练目标来增强模型对文本中的命名实体的注意力。首先，使用命名实体识别模型RoBERTa来确定文本中的命名实体。然后，使用该模型对文本中的命名实体进行屏蔽，再使用BART模型对其进行重建。接下来，将BART模型在摘要任务上进行微调。实验证明，这种预训练方法改善了命名实体包含的精确度和召回率指标。

    We address the named entity omission - the drawback of many current abstractive text summarizers. We suggest a custom pretraining objective to enhance the model's attention on the named entities in a text. At first, the named entity recognition model RoBERTa is trained to determine named entities in the text. After that, this model is used to mask named entities in the text and the BART model is trained to reconstruct them. Next, the BART model is fine-tuned on the summarization task. Our experiments showed that this pretraining approach improves named entity inclusion precision and recall metrics.
    
[^67]: MedCPT: 使用大规模PubMed搜索日志的对比预训练转换器进行零样本生物医学信息检索

    MedCPT: Contrastive Pre-trained Transformers with Large-scale PubMed Search Logs for Zero-shot Biomedical Information Retrieval. (arXiv:2307.00589v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2307.00589](http://arxiv.org/abs/2307.00589)

    MedCPT是一种用于生物医学领域零样本语义信息检索的对比预训练转换器模型。通过使用大规模PubMed搜索日志进行训练，MedCPT在六个生物医学信息检索任务中创造了新的最佳性能，超过了其他基线模型，同时还能生成更好的生物医学文章和句子。

    

    信息检索在生物医学知识获取和临床决策支持中至关重要。尽管最近的进展表明语言模型编码器在语义检索方面表现更好，但训练这些模型需要大量的查询-文章注释，在生物医学领域很难获得。因此，大多数生物医学信息检索系统只进行词汇匹配。为此，我们引入了MedCPT，这是一种首创的用于生物医学领域零样本语义信息检索的对比预训练转换器模型。为了训练MedCPT，我们从PubMed收集了255 million个用户点击日志，这是前所未有的规模。利用这些数据，我们使用对比学习来训练一对密切集成的检索器和重排器。实验结果显示，MedCPT在六个生物医学信息检索任务中取得了新的最佳性能，优于包括更大模型（如GPT-3大小的cpt-text-XL）在内的各种基线模型。此外，MedCPT还能够生成更好的生物医学文章和句子。

    Information retrieval (IR) is essential in biomedical knowledge acquisition and clinical decision support. While recent progress has shown that language model encoders perform better semantic retrieval, training such models requires abundant query-article annotations that are difficult to obtain in biomedicine. As a result, most biomedical IR systems only conduct lexical matching. In response, we introduce MedCPT, a first-of-its-kind Contrastively Pre-trained Transformer model for zero-shot semantic IR in biomedicine. To train MedCPT, we collected an unprecedented scale of 255 million user click logs from PubMed. With such data, we use contrastive learning to train a pair of closely-integrated retriever and re-ranker. Experimental results show that MedCPT sets new state-of-the-art performance on six biomedical IR tasks, outperforming various baselines including much larger models such as GPT-3-sized cpt-text-XL. In addition, MedCPT also generates better biomedical article and sentence 
    
[^68]: 应用演绎验证技术验证思维链的推理过程

    Deductive Verification of Chain-of-Thought Reasoning. (arXiv:2306.03872v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.03872](http://arxiv.org/abs/2306.03872)

    本文旨在通过应用演绎验证技术，使语言模型能够进行明确而严谨的演绎推理，以确保其推理过程的可信度。

    

    大语言模型在各种推理任务中受益匪浅，特别是应用思维链提示可以使模型产生更全面的推理过程。然而，思维链的强调中间推理步骤可能会不慎导致产生幻觉和累积错误，从而限制模型解决复杂推理任务的能力。本文灵感来自于人类如何进行细致的演绎逻辑推理过程来解决任务，我们旨在使语言模型能够进行明确而严谨的演绎推理，并通过自我验证确保推理过程的可信度。然而，即使是像ChatGPT这样先进的模型，直接验证整个演绎推理过程的有效性也是具有挑战性的。因此，我们提出将推理验证过程分解为一系列逐步的子过程，每个过程只接收其必要的上下文和前提条件。

    Large Language Models (LLMs) significantly benefit from Chain-of-Thought (CoT) prompting in performing various reasoning tasks. While CoT allows models to produce more comprehensive reasoning processes, its emphasis on intermediate reasoning steps can inadvertently introduce hallucinations and accumulated errors, thereby limiting models' ability to solve complex reasoning tasks. Inspired by how humans engage in careful and meticulous deductive logical reasoning processes to solve tasks, we seek to enable language models to perform explicit and rigorous deductive reasoning, and also ensure the trustworthiness of their reasoning process through self-verification. However, directly verifying the validity of an entire deductive reasoning process is challenging, even with advanced models like ChatGPT. In light of this, we propose to decompose a reasoning verification process into a series of step-by-step subprocesses, each only receiving their necessary context and premises. To facilitate t
    
[^69]: RepoBench：评估代码自动补全系统的代码库级别性能基准

    RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems. (arXiv:2306.03091v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.03091](http://arxiv.org/abs/2306.03091)

    RepoBench是一个评估代码自动补全系统在代码库级别上性能的基准，支持Python和Java，包含三个相互关联的评估任务。它旨在填补当前基准在多文件编程场景方面的评估差距，并为不同系统的性能提供更全面的比较。

    

    大型语言模型（LLMs）在代码自动补全系统方面取得了巨大进步，有潜力为开发人员提供显著的生产力增强。然而，当前的基准主要集中在单个文件任务上，对于更复杂的真实世界的多文件编程场景的评估存在差距。为填补这一差距，我们介绍了RepoBench，一个专门设计用于评估代码库级别的代码自动补全系统的新基准。RepoBench支持Python和Java，并包含三个相互关联的评估任务：RepoBench-R（检索）、RepoBench-C（代码补全）和RepoBench-P（流水线）。每个任务分别测量系统检索其他文件中最相关代码片段的能力、使用跨文件和文件内上下文预测下一行代码的能力以及处理需要检索和下一行预测组合的复杂任务的能力。RepoBench旨在促进对性能的更全面比较。

    Large Language Models (LLMs) have greatly advanced code auto-completion systems, with a potential for substantial productivity enhancements for developers. However, current benchmarks mainly focus on single-file tasks, leaving an assessment gap for more complex, real-world, multi-file programming scenarios. To fill this gap, we introduce RepoBench, a new benchmark specifically designed for evaluating repository-level code auto-completion systems. RepoBench supports both Python and Java and consists of three interconnected evaluation tasks: RepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P (Pipeline). Each task respectively measures the system's ability to retrieve the most relevant code snippets from other files as cross-file context, predict the next line of code with cross-file and in-file context, and handle complex tasks that require a combination of both retrieval and next-line prediction. RepoBench aims to facilitate a more complete comparison of performance
    
[^70]: LLMatic: 基于大语言模型和多样性优化的神经结构搜索

    LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization. (arXiv:2306.01102v1 [cs.NE])

    [http://arxiv.org/abs/2306.01102](http://arxiv.org/abs/2306.01102)

    本文介绍了利用大语言模型和多样性优化算法相结合的 LLMatic 神经结构搜索算法。该算法在CIFAR-10数据集进行测试，仅进行2000次搜索即可产生高性能网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。

    

    大型语言模型 (LLMs) 已成为一种强大的工具，可以完成广泛的任务。它们的能力涵盖了许多领域，它们在代码生成领域产生了重大影响。在此情况下，我们将 LLMs 视为变异和交叉工具。同时，多样性优化算法已知可以发现多样性和稳健的解决方案。通过将 LLMs 的代码生成能力与 QD 解决方案的多样性和鲁棒性相结合，我们引入了 LLMatic，一个神经结构搜索 (NAS) 算法。虽然 LLMs 通过提示直接进行 NAS 考验困难，但 LLMatic 利用程序化方法，利用 QD 来进行提示和网络结构，从而创建多样性和高性能网络。我们在 CIFAR-10 图像分类基准测试中测试了 LLMatic，证明它可以在仅进行 2000 次搜索的情况下产生具有竞争力的网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。

    Large Language Models (LLMs) have emerged as powerful tools capable of accomplishing a broad spectrum of tasks. Their abilities span numerous areas, and one area where they have made a significant impact is in the domain of code generation. In this context, we view LLMs as mutation and crossover tools. Meanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and robust solutions. By merging the code-generating abilities of LLMs with the diversity and robustness of QD solutions, we introduce LLMatic, a Neural Architecture Search (NAS) algorithm. While LLMs struggle to conduct NAS directly through prompts, LLMatic uses a procedural approach, leveraging QD for prompts and network architecture to create diverse and highly performant networks. We test LLMatic on the CIFAR-10 image classification benchmark, demonstrating that it can produce competitive networks with just $2,000$ searches, even without prior knowledge of the benchmark domain or exposure to any previous top-p
    
[^71]: AWQ：LLM压缩与加速的激活感知权重量化方法

    AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration. (arXiv:2306.00978v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00978](http://arxiv.org/abs/2306.00978)

    AWQ是一种激活感知的权重量化方法，通过保护少量显著权重来降低量化误差，不依赖于反向传播或重构，并在语言建模和领域特定任务上优于现有方法。

    

    大语言模型(LLM)在各种任务上展现出出色的性能，但巨大的模型大小提高了为服务(内存大小)带来的硬件障碍，并降低了令牌生成速度(内存带宽)。本文提出了一种名为激活感知权重量化(AWQ)的硬件友好方法，用于LLM低比特权重量化。我们的方法基于一个观察：权重并不是等重要的；仅保护1%的显著权重就能大大降低量化误差。我们提出寻找通过观察激活值而不是权重来保护显著权重的最佳按通道缩放方法。AWQ不依赖于任何反向传播或重构，因此可以很好地保持LLM在不同领域和模式下的泛化能力，而不会过度拟合校准集。AWQ在各种语言建模和领域特定基准测试上优于现有方法。由于更好的泛化能力，它实现了优秀的量化效果。

    Large language models (LLMs) have shown excellent performance on various tasks, but the astronomical model size raises the hardware barrier for serving (memory size) and slows down token generation (memory bandwidth). In this paper, we propose Activation-aware Weight Quantization (AWQ), a hardware-friendly approach for LLM low-bit weight-only quantization. Our method is based on the observation that weights are not equally important: protecting only 1% of salient weights can greatly reduce quantization error. We then propose to search for the optimal per-channel scaling that protects the salient weights by observing the activation, not weights. AWQ does not rely on any backpropagation or reconstruction, so it can well preserve LLMs' generalization ability on different domains and modalities, without overfitting to the calibration set. AWQ outperforms existing work on various language modeling and domain-specific benchmarks. Thanks to better generalization, it achieves excellent quantiz
    
[^72]: DNA-GPT: 无需训练的Divergent N-Gram分析用于检测GPT生成的文本

    DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text. (arXiv:2305.17359v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17359](http://arxiv.org/abs/2305.17359)

    DNA-GPT是一种无需训练的检测策略，通过Divergent N-Gram分析来发现机器生成文本与人类写作文本之间的显著差异。

    

    大型语言模型（LLMs）显着提高了机器生成文本的流畅性和多样性。然而，这一进展也给检测给定文本的来源带来了重大挑战，并且目前的检测方法研究滞后于LLMs的快速发展。传统的基于训练的方法在灵活性方面存在局限性，特别是在适应新领域时，它们往往缺乏解释能力。为了弥补这一差距，我们提出了一种新颖的无需训练的检测策略，称为Divergent N-Gram分析（DNA-GPT）。给定一段文本，我们首先截断其中间部分，然后仅使用前面的部分作为输入来重新生成剩下的部分。通过在黑盒中进行N-gram分析或在白盒中进行概率分布差异分析，我们揭示了机器生成文本的分布与人类写作文本的分布之间的显著差异。我们进行了实证研究...

    Large language models (LLMs) have notably enhanced the fluency and diversity of machine-generated text. However, this progress also presents a significant challenge in detecting the origin of a given text, and current research on detection methods lags behind the rapid evolution of LLMs. Conventional training-based methods have limitations in flexibility, particularly when adapting to new domains, and they often lack explanatory power. To address this gap, we propose a novel training-free detection strategy called Divergent N-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and then use only the preceding portion as input to the LLMs to regenerate the new remaining parts. By analyzing the differences between the original and new remaining parts through N-gram analysis in black-box or probability divergence in white-box, we unveil significant discrepancies between the distribution of machine-generated text and the distribution of human-written text. We conducted
    
[^73]: Twitter图像的文本条件下的替代文本生成

    Text Conditional Alt-Text Generation for Twitter Images. (arXiv:2305.14779v1 [cs.CV])

    [http://arxiv.org/abs/2305.14779](http://arxiv.org/abs/2305.14779)

    本文针对Twitter上分享的图像提出了一种文本条件下的替代文本生成方法。通过CLIP前缀模型，该模型结合图像和推文中的文本信息，生成关于图像的上下文相关的替代文本。

    

    本文提出了一种针对社交媒体特别是Twitter上分享的图像生成替代文本（或alt-text）描述的方法。与图像的字幕不同，文本替换文本更加直白描述和上下文特定。此外，关键是，发布到Twitter上的图像通常是由用户编写的文本附加的，尽管这些文本不一定描述图像，但可能提供有用的上下文信息，如果正确利用可以提供信息，例如推文可能会命名图片中模型之前没有见过的不常见的对象。我们通过一个CLIP前缀模型来解决这个问题，该模型提取图像的嵌入并将其传递给映射网络，该网络输出单词嵌入空间中的短序列，或称为“前缀”，我们将推文本身的文本也连接到其中。这样，模型就可以在文章中条件化视觉和文本信息。然后将合并的多模式前缀作为预训练的语言模型的提示输入。

    In this work we present an approach for generating alternative text (or alt-text) descriptions for images shared on social media, specifically Twitter. This task is more than just a special case of image captioning, as alt-text is both more literally descriptive and context-specific. Also critically, images posted to Twitter are often accompanied by user-written text that despite not necessarily describing the image may provide useful context that if properly leveraged can be informative -- e.g. the tweet may name an uncommon object in the image that the model has not previously seen. We address this with a CLIP prefix model that extracts an embedding of the image and passes it to a mapping network that outputs a short sequence in word embedding space, or a ``prefix'', to which we also concatenate the text from the tweet itself. This lets the model condition on both visual and textual information from the post. The combined multimodal prefix is then fed as a prompt to a pretrained lang
    
[^74]: 一种参数高效的学习方法，用于带有预训练通用语音模型的阿拉伯方言识别

    A Parameter-Efficient Learning Approach to Arabic Dialect Identification with Pre-Trained General-Purpose Speech Model. (arXiv:2305.11244v1 [cs.CL])

    [http://arxiv.org/abs/2305.11244](http://arxiv.org/abs/2305.11244)

    本文介绍了一种利用预训练通用语音模型进行阿拉伯方言识别的参数高效学习方法，通过残差适配器和模型重编程，设计了一个基于记号的标签映射，并在ADI-17数据集上实现了最高精度，同时使用PEL方法进一步减少了训练成本。

    

    本文研究了参数高效学习（PEL）技术，以重新利用通用语音模型（GSM）进行阿拉伯方言识别（ADI）。我们设计了一个基于记号的标签映射，将GSM适应于阿拉伯方言识别，通过残差适配器和模型重编程来实现。我们通过vanilla fine-tuning在ADI-17数据集上实现了新的最高精度。此外，我们通过PEL方法进一步减少了训练成本，使用额外2.5％的网络可训练参数即可达到fine-tuning精度的1.86％。我们的研究展示了如何使用小型数据集和有限的计算资源来识别阿拉伯方言。

    In this work, we explore Parameter-Efficient-Learning (PEL) techniques to repurpose a General-Purpose-Speech (GSM) model for Arabic dialect identification (ADI). Specifically, we investigate different setups to incorporate trainable features into a multi-layer encoder-decoder GSM formulation under frozen pre-trained settings. Our architecture includes residual adapter and model reprogramming (input-prompting). We design a token-level label mapping to condition the GSM for Arabic Dialect Identification (ADI). This is challenging due to the high variation in vocabulary and pronunciation among the numerous regional dialects. We achieve new state-of-the-art accuracy on the ADI-17 dataset by vanilla fine-tuning. We further reduce the training budgets with the PEL method, which performs within 1.86% accuracy to fine-tuning using only 2.5% of (extra) network trainable parameters. Our study demonstrates how to identify Arabic dialects using a small dataset and limited computation with open sou
    
[^75]: 连锁符号提示激发了大型语言模型中的规划能力

    Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models. (arXiv:2305.10276v1 [cs.CL])

    [http://arxiv.org/abs/2305.10276](http://arxiv.org/abs/2305.10276)

    本文提出了自然语言规划（NLP）的基准，旨在研究LLMs在需要理解并在文本中相应进行操作的复杂规划任务中的表现。同时提出了一种新方法CoS，使用简化的符号空间表示法来表示复杂的环境。

    

    本文旨在研究LLMs在需要理解通过自然语言模拟的虚拟空间环境并在文本中相应进行操作的复杂规划任务中的表现。我们提出了一个名为自然语言规划（NLP）的基准，它由一组新颖的任务组成：Brick World、基于NLVR的操作和自然语言导航。我们发现当前流行的LLMs（如ChatGPT）仍然缺乏复杂规划的能力。这引出了一个问题——LLMs是否对自然语言中描述的环境有良好的理解，或者其他替代方法（如符号表示）是否更加简单，因此更容易被LLMs理解？为此，我们提出了一种名为CoS（Chain-of-Symbol Prompting）的新方法，在链式中间思考步骤中使用简化的符号空间表示法来表示复杂的环境。CoS易于使用，不需要对LLMs进行额外的培训。

    In this paper, we take the initiative to investigate the performance of LLMs on complex planning tasks that require LLMs to understand a virtual spatial environment simulated via natural language and act correspondingly in text. We propose a benchmark named Natural Language Planning (NLP) composed of a set of novel tasks: Brick World, NLVR-based Manipulations, and Natural Language Navigation. We found that current popular LLMs such as ChatGPT still lack abilities in complex planning. This arises a question -- do the LLMs have a good understanding of the environments described in natural language, or maybe other alternatives such as symbolic representations are neater and hence better to be understood by LLMs? To this end, we propose a novel method called CoS (Chain-of-Symbol Prompting) that represents the complex environments with condensed symbolic spatial representations during the chained intermediate thinking steps. CoS is easy to use and does not need additional training on LLMs. 
    
[^76]: 自监督神经因子分析解耦语音表示

    Self-supervised Neural Factor Analysis for Disentangling Utterance-level Speech Representations. (arXiv:2305.08099v1 [cs.SD])

    [http://arxiv.org/abs/2305.08099](http://arxiv.org/abs/2305.08099)

    本文提出了一种自监督神经因子分析模型，使用HuBERT中的聚类方法来发现隐藏的声学单元，并使用这些单元对齐SSL模型的特征，从而产生解耦后的语音表示，从而为专门任务提供了一种基于Utterance水平的无监督学习目标。实验结果表明，SSNFA模型在说话人识别、语言识别和情感识别等各种任务中均显著优于现有的SSL模型，并且没有任何特定任务的微调或监督。

    

    自监督学习技术在自动语音识别方面已经展示了出色的性能，在低标注资源情况下证明非常有用，本文针对该技术在说话人、情感和语言识别等任务中的性能问题进行了探究。本文提出了一种因子分析模型，使用HuBERT中的聚类方法来发现隐藏的声学单元，并使用这些单元对齐SSL模型的特征，从而产生解耦后的语音表示，从而为专门任务提供了一种基于Utterance水平的无监督学习目标。实验结果表明，SSNFA模型在说话人识别、语言识别和情感识别等各种任务中均显著优于现有的SSL模型，并且没有任何特定任务的微调或监督。

    Self-supervised learning (SSL) speech models such as wav2vec and HuBERT have demonstrated state-of-the-art performance on automatic speech recognition (ASR) and proved to be extremely useful in low label-resource settings. However, the success of SSL models has yet to transfer to utterance-level tasks such as speaker, emotion, and language recognition, which still require supervised fine-tuning of the SSL models to obtain good performance. We argue that the problem is caused by the lack of disentangled representations and an utterance-level learning objective for these tasks. Inspired by how HuBERT uses clustering to discover hidden acoustic units, we formulate a factor analysis (FA) model that uses the discovered hidden acoustic units to align the SSL features. The underlying utterance-level representations are disentangled from the content of speech using probabilistic inference on the aligned features. Furthermore, the variational lower bound derived from the FA model provides an ut
    
[^77]: 个性化一次性分割模型

    Personalize Segment Anything Model with One Shot. (arXiv:2305.03048v1 [cs.CV])

    [http://arxiv.org/abs/2305.03048](http://arxiv.org/abs/2305.03048)

    本文提出了一种无需训练的SAM个性化方法PerSAM，只需要一张带有参考掩模的单张图像即可定位和分割目标概念，还提出了高效的一次性微调变体PerSAM-F，旨在解决掩模不确定性问题。

    

    在大数据预训练的推动下，分割任何物体模型（SAM）已被证明是一个强大且高效的框架，革新了分割模型领域。尽管SAM非常通用，但自动为特定视觉概念定制SAM而不需要手动提示，如在不同图像中自动分割你的宠物狗等， 还未深入研究。本文提出了一种无需训练的SAM个性化方法，称为PerSAM。只需要一张带有参考掩模的单张图像，PerSAM首先通过位置先验定位目标概念，并通过三种技术来在其他图像或视频中分割它：目标引导注意力，目标语义提示和级联后处理。这样，我们有效地适应了SAM的私人使用而无需任何训练。为了进一步缓解掩模的不确定性，我们提出了一个高效的一次性微调变体，即PerSAM-F。冻结整个SAM，我们引入了两个可学习权重用于多尺度掩模，仅训练2个参数即可。

    Driven by large-data pre-training, Segment Anything Model (SAM) has been demonstrated as a powerful and promptable framework, revolutionizing the segmentation models. Despite the generality, customizing SAM for specific visual concepts without man-powered prompting is under explored, e.g., automatically segmenting your pet dog in different images. In this paper, we propose a training-free Personalization approach for SAM, termed as PerSAM. Given only a single image with a reference mask, PerSAM first localizes the target concept by a location prior, and segments it within other images or videos via three techniques: target-guided attention, target-semantic prompting, and cascaded post-refinement. In this way, we effectively adapt SAM for private use without any training. To further alleviate the mask ambiguity, we present an efficient one-shot fine-tuning variant, PerSAM-F. Freezing the entire SAM, we introduce two learnable weights for multi-scale masks, only training 2 parameters wit
    
[^78]: 技术报告：图神经网络也可以变得语法化

    Technical report: Graph Neural Networks go Grammatical. (arXiv:2303.01590v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01590](http://arxiv.org/abs/2303.01590)

    本文介绍了一种将代数语言片段与图神经网络形式上联系的框架，并从MATLANG定义了一个符合3-WL测试的语法，进而得出一个符合3-WL GNN模型的G$^2$N$^2$。此外，语法方法还提供了计算长度为六及以下的环和弦环的代数公式，并在多个下游任务中取得优秀的表现。

    

    本文提出了一个框架，将一个代数语言的一个片段与图神经网络（GNN）形式上联系起来。它依赖于上下文无关语法（CFG），将代数操作组织成可以翻译为GNN层模型的生成规则。由于直接从语言派生出的CFG的规则和变量包含冗余，因此介绍了一种语法简化方案，使得将其翻译为GNN层成为可能。应用这种策略，从MATLANG定义了一个符合第三阶Weisfeiler-Lehman（3-WL）测试要求的语法。从这个3-WL CFG中，我们得出了一个经过证明符合3-WL GNN模型的G$^2$N$^2$。此外，这种语法方法使我们能够提供计算长度为六及以下的环和弦环的代数公式，从而阐明了3-WL的计数能力。多个实验证明，G$^2$N$^2$在许多下游任务中的表现要比其他3-WL GNN更为高效。

    This paper proposes a framework to formally link a fragment of an algebraic language to a Graph Neural Network (GNN). It relies on Context Free Grammars (CFG) to organise algebraic operations into generative rules that can be translated into a GNN layer model. Since the rules and variables of a CFG directly derived from a language contain redundancies, a grammar reduction scheme is presented making tractable the translation into a GNN layer. Applying this strategy, a grammar compliant with the third-order Weisfeiler-Lehman (3-WL) test is defined from MATLANG. From this 3-WL CFG, we derive a provably 3-WL GNN model called G$^2$N$^2$. Moreover, this grammatical approach allows us to provide algebraic formulas to count the cycles of length up to six and chordal cycles at the edge level, which enlightens the counting power of 3-WL. Several experiments illustrate that G$^2$N$^2$ efficiently outperforms other 3-WL GNNs on many downstream tasks.
    
[^79]: 关于COVID-19疫苗的波斯推文的大规模分析

    A Large-Scale Analysis of Persian Tweets Regarding Covid-19 Vaccination. (arXiv:2302.04511v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.04511](http://arxiv.org/abs/2302.04511)

    本文利用Twitter数据进行了对伊朗公众对COVID-19疫苗的意见进行的全面分析，结果显示该疫苗引起了广泛关注，涉及政府问题、安全性、犹豫不决和副作用等方面。

    

    COVID-19大流行对我们的生活产生了巨大影响，尤其是人们的互动。引入COVID-19疫苗后，关于接种疫苗与否的正反意见都有所提出。本文利用从Twitter获取的数据，包括推文和用户资料，对伊朗公众对冠状病毒疫苗的意见进行了全面分析。为此，我们采用了搜索查询技术和主题建模方法来提取与疫苗相关的推文。我们利用基于转换器的模型对推文内容进行分类，并提取围绕接种的主题。我们还进行了情感分析，以评估公众在这一话题上的快乐和愤怒程度。我们的结果表明，COVID-19疫苗已引起了各种不同角度的高度关注，如政府问题、安全性或犹豫不决以及副作用等。

    The Covid-19 pandemic had an enormous effect on our lives, especially on people's interactions. By introducing Covid-19 vaccines, both positive and negative opinions were raised over the subject of taking vaccines or not. In this paper, using data gathered from Twitter, including tweets and user profiles, we offer a comprehensive analysis of public opinion in Iran about the Coronavirus vaccines. For this purpose, we applied a search query technique combined with a topic modeling approach to extract vaccine-related tweets. We utilized transformer-based models to classify the content of the tweets and extract themes revolving around vaccination. We also conducted an emotion analysis to evaluate the public happiness and anger around this topic. Our results demonstrate that Covid-19 vaccination has attracted considerable attention from different angles, such as governmental issues, safety or hesitancy, and side effects. Moreover, Coronavirus-relevant phenomena like public vaccination and t
    
[^80]: 双排列等变性在知识图谱补全中的应用

    Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01313](http://arxiv.org/abs/2302.01313)

    本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。

    

    本研究将知识图谱(KGs)形式化为一种新型的图，并称之为双交换属性图，其中节点和二元（两个节点之间的）表示必须对节点号和边（及节点）属性（关系和节点特征）的排列等变。双重排列等变的KG表示在KG中开辟了新的研究方向。我们展示了这种等变性对关系的结构表示产生的影响，从而使神经网络能够在KG中执行复杂的逻辑推理任务。最后，我们介绍了一种通用的等变表示蓝图，并测试了一种简单的基于GNN的双排列等变神经结构，在WN18RR、FB237和NELL995归纳KG完成任务中实现了最先进的Hits@10测试准确率，并能够准确执行现有方法无法执行的逻辑推理任务。

    This work provides a formalization of Knowledge Graphs (KGs) as a new class of graphs that we denote doubly exchangeable attributed graphs, where node and pairwise (joint 2-node) representations must be equivariant to permutations of both node ids and edge (& node) attributes (relations & node features). Double-permutation equivariant KG representations open a new research direction in KGs. We show that this equivariance imposes a structural representation of relations that allows neural networks to perform complex logical reasoning tasks in KGs. Finally, we introduce a general blueprint for such equivariant representations and test a simple GNN-based double-permutation equivariant neural architecture that achieve state-of-the-art Hits@10 test accuracy in the WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately perform logical reasoning tasks that no existing methods can perform, to the best of our knowledge.
    
[^81]: 高效Transformer的交替更新方法

    Alternating Updates for Efficient Transformers. (arXiv:2301.13310v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13310](http://arxiv.org/abs/2301.13310)

    本文介绍了一种交替更新（AltUp）的方法，可以在不增加计算负担的情况下增加模型的容量，通过对扩展表示的子块进行操作并使用预测和修正机制来更新未激活的块。实验证明AltUp方法在提高Transformer模型的容量和效率方面是有效的。

    

    众所周知，增加深度Transformer网络的规模可以提高模型的质量和性能。然而，这种规模的增加往往会导致计算成本和推理延迟的大幅增加。我们引入了交替更新（AltUp）方法，这是一种简单易实现的方法，可以增加模型的容量而不增加计算负担。AltUp通过在每一层中对扩展表示的子块进行操作，并使用预测和修正机制来更新未激活的块，从而实现了仅在延迟上微不足道的情况下扩大了学习表示，即标记嵌入。我们还介绍了AltUp的扩展，例如其在序列维度上的适用性，并展示了如何将AltUp与现有方法（如稀疏专家混合模型）结合起来，以获得具有更高容量的高效模型。我们在基准Transformer模型和语言任务上进行了实验证明了AltUp方法的有效性。

    It has been well established that increasing scale in deep transformer networks leads to improved quality and performance. However, this increase in scale often comes with prohibitive increases in compute cost and inference latency. We introduce Alternating Updates (AltUp), a simple-to-implement method to increase a model's capacity without the computational burden. AltUp enables the widening of the learned representation, i.e., the token embedding, while only incurring a negligible increase in latency. AltUp achieves this by working on a subblock of the widened representation at each layer and using a predict-and-correct mechanism to update the inactivated blocks. We present extensions of AltUp, such as its applicability to the sequence dimension, and demonstrate how AltUp can be synergistically combined with existing approaches, such as Sparse Mixture-of-Experts models, to obtain efficient models with even higher capacity. Our experiments on benchmark transformer models and language 
    
[^82]: 自动文本摘要技术的综合回顾：方法、数据、评估和编码

    A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding. (arXiv:2301.03403v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.03403](http://arxiv.org/abs/2301.03403)

    本文提供了关于自动文本摘要系统的综述，包括方法、数据、评估和编码。作者通过引用的方式回顾了相关文献，并介绍了不同的摘要生成方法。此外，还对可用于评估和数据训练的数据集进行了综述，并使用CNN语料库数据集对方法进行了实证探索。

    

    我们提供了关于自动文本摘要系统的文献综述。我们采用基于引用的方法。我们从我们已经掌握的关于每个我们想涵盖的主题的一些流行和著名的论文开始，然后我们追踪了“向后引用”（被我们之前知道的一系列论文引用的论文）和“向前引用”（引用我们之前知道的一系列论文的较新论文）。为了组织不同的方法，我们介绍了各种基于不同机制生成摘要的自动文本摘要方法。除了介绍方法外，我们还对可用于摘要任务的数据集和用于评估摘要质量的方法进行了广泛的回顾。最后，我们还使用CNN语料库数据集对这些方法进行了实证探索，该数据集为抽取式和生成式方法提供了金标准摘要。

    We provide a literature review about Automatic Text Summarization (ATS) systems. We consider a citation-based approach. We start with some popular and well-known papers that we have in hand about each topic we want to cover and we have tracked the "backward citations" (papers that are cited by the set of papers we knew beforehand) and the "forward citations" (newer papers that cite the set of papers we knew beforehand). In order to organize the different methods, we present the diverse approaches to ATS guided by the mechanisms they use to generate a summary. Besides presenting the methods, we also present an extensive review of the datasets available for summarization tasks and the methods used to evaluate the quality of the summaries. Finally, we present an empirical exploration of these methods using the CNN Corpus dataset that provides golden summaries for extractive and abstractive methods.
    
[^83]: 自动剪辑：更简单和更强大的差分隐私深度学习

    Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger. (arXiv:2206.07136v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.07136](http://arxiv.org/abs/2206.07136)

    本论文提出了一种自动剪辑的替代方案，它消除了为差分隐私优化器调整剪辑阈值的需要，并在非凸情况下进行了收敛性分析。在多个任务中证明了自动剪辑的优势。

    

    单样本梯度剪辑是实现深度学习模型的差分隐私(DP)训练的关键算法步骤。然而，剪辑阈值R的选择对于在DP下实现高准确性至关重要。我们提出了一种易于使用的替代方案，称为自动剪辑，它消除了为任何DP优化器（包括DP-SGD、DP-Adam、DP-LAMB等）调整R的需要。自动变量与现有的DP优化器一样具有隐私性和计算效率，但不需要DP特定的超参数，因此使得DP训练像标准的非隐私训练一样可行。我们在非凸情况下对自动DP-SGD进行了严格的收敛性分析，表明在样本梯度的对称性噪声假设下（在非DP文献中常用），它能够享受与标准SGD相同的渐近收敛速率。我们在各种语言和视觉任务中展示了自动剪辑的优势。

    Per-example gradient clipping is a key algorithmic step that enables practical differential private (DP) training for deep learning models. The choice of clipping threshold R, however, is vital for achieving high accuracy under DP. We propose an easy-to-use replacement, called automatic clipping, that eliminates the need to tune R for any DP optimizers, including DP-SGD, DP-Adam, DP-LAMB and many others. The automatic variants are as private and computationally efficient as existing DP optimizers, but require no DP-specific hyperparameters and thus make DP training as amenable as the standard non-private training. We give a rigorous convergence analysis of automatic DP-SGD in the non-convex setting, showing that it can enjoy an asymptotic convergence rate that matches the standard SGD, under a symmetric gradient noise assumption of the per-sample gradients (commonly used in the non-DP literature). We demonstrate on various language and vision tasks that automatic clipping outperforms o
    
[^84]: 一对一翻译

    One Sense per Translation. (arXiv:2106.06082v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2106.06082](http://arxiv.org/abs/2106.06082)

    本文提出了一种基于翻译的词义消歧方法，通过定义一对一翻译（OSPT）的关键属性，实现了高达93％的精确度以及最高4.6％的WSD改进。

    

    词义消歧（WSD）是确定上下文中词义的任务。翻译被用作WSD的知识源，甚至用作限定词义的手段。本文定义了词义和翻译之间关系的三个理论属性，并论证了它们是使用翻译作为词义库的必要条件。一对一翻译（OSPT）的关键属性为基于翻译的WSD方法提供了基础。内在评估实验的结果表明，与手动语料库注释相比，我们的方法达到了约93％的精确度。外在评估实验显示，在困难的WSD数据集上，WSD的F1分数提高了最高达4.6％。

    Word sense disambiguation (WSD) is the task of determining the sense of a word in context. Translations have been used in WSD as a source of knowledge, and even as a means of delimiting word senses. In this paper, we define three theoretical properties of the relationship between senses and translations, and argue that they constitute necessary conditions for using translations as sense inventories. The key property of One Sense per Translation (OSPT) provides a foundation for a translation-based WSD method. The results of an intrinsic evaluation experiment indicate that our method achieves a precision of approximately 93% compared to manual corpus annotations. Our extrinsic evaluation experiments demonstrate WSD improvements of up to 4.6% F1-score on difficult WSD datasets.
    

