# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health.](http://arxiv.org/abs/2306.10070) | 本文探讨了ChatGPT和大型语言模型在生物医学和健康领域的多样应用，发现在文本生成方面已经取得了重大进展，但对于其他应用进展缓慢，LLMs还没有真正彻底改变生物医学领域。 |
| [^2] | [Domain-specific ChatBots for Science using Embeddings.](http://arxiv.org/abs/2306.10067) | 本论文演示如何利用现有方法和软件工具结合嵌入技术设计面向科学领域的聊天机器人，该机器人能够处理科学文献，提供特定领域的上下文信息，并在初步研究辅助知识方面为物理科学家提供帮助。 |
| [^3] | [Revealing the structure of language model capabilities.](http://arxiv.org/abs/2306.10062) | 本文研究了大规模语言模型的能力结构，发现这些模型不是单一能力，而是由推理、理解和核心语言建模等三个明确定义的因素组成，并且这三个能力可以解释模型性能中的大部分方差。 |
| [^4] | [EM-Network: Oracle Guided Self-distillation for Sequence Learning.](http://arxiv.org/abs/2306.10058) | EM-Network是一种自我蒸馏方法，通过神谕指导能够有效利用目标信息进行监督序列到序列学习，并在语音识别和机器翻译等任务上取得了最先进的成果。 |
| [^5] | [Generate to Understand for Representation.](http://arxiv.org/abs/2306.10056) | GUR是一种预训练框架，将语言建模和对比学习目标结合在单个训练步骤中，通过从原始无标签文档中选择相似的文本对来训练模型，无需任何标记训练数据即可作为检索器超过其他预训练基线模型。 |
| [^6] | [A Practical Entity Linking System for Tables in Scientific Literature.](http://arxiv.org/abs/2306.10044) | 本文介绍了一个用于将实体链接到知识库中的通用系统，并将其适应于链接特定领域的实体，特别是 COVID-19 相关科学文献中的嵌入式实体。通过利用表格的结构和语义特征，以提高整体实体链接性能。 |
| [^7] | [A Pairing Enhancement Approach for Aspect Sentiment Triplet Extraction.](http://arxiv.org/abs/2306.10042) | 本文提出了一种配对增强方法，通过对比学习将方面-意见配对知识注入到Aspect Sentiment Triplet Extraction（ASTE）模型中，提高了三元组提取的准确性和性能。 |
| [^8] | [Demystifying GPT Self-Repair for Code Generation.](http://arxiv.org/abs/2306.09896) | 本文分析了 GPT-3.5 和 GPT-4 在 APPS 数据集上执行自我修复的能力，发现自我修复在 GPT 模型中的有效性严重取决于任务的质量和复杂性，自我修复在较短和较简单的任务中效果更好，仅在某些代码部分上应用自我修复可以非常有效，本文提出的引导修复方法在 APPS 数据集上获得性能提升。 |
| [^9] | [RED$^{\rm FM}$: a Filtered and Multilingual Relation Extraction Dataset.](http://arxiv.org/abs/2306.09802) | 本文提出了两个新的数据集，分别是自动标注的SRED$^{\rm FM}$和人工修订的RED$^{\rm FM}$。SRED$^{\rm FM}$涵盖了18种语言、400种关系类型、13种实体类型，总共超过4000万个三元组实例；RED$^{\rm FM}$是RED的精简版，可用于评估多语言关系抽取系统。实验证明，这些新数据集能有效用于建立多语言关系抽取模型。 |
| [^10] | [DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning.](http://arxiv.org/abs/2306.09030) | 本文提出一个新的对话数据集DiPlomat，用于评测机器的情境推理和对话理解能力。与先前工作相比，DiPlomat提供了一个统一的框架来实现一般的语用理解。我们的数据集通过利用亚马逊机械土耳其语（AMT）来创建，共有4,177个多轮对话。与数据集一起，我们提出了两个任务：语用识别和推理（PIR）和会话问答（CQA）。 |
| [^11] | [Unifying Large Language Models and Knowledge Graphs: A Roadmap.](http://arxiv.org/abs/2306.08302) | 本文提出了一个前瞻性的统一大型语言模型和知识图谱的路线图，通过三个框架：增强KGs的LLMs，知识增强KGs和LLMs与KGs的联合推理，综合利用两者的优点。 |
| [^12] | [A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews.](http://arxiv.org/abs/2306.07786) | 本文介绍了一种基于云的系统，利用机器学习方法从客户评论中提取见解。本研究提出的组合模型使用了转换器神经网络、向量嵌入和聚类，已经集成并进一步发展，以更好地满足高效信息提取、提取信息的主题建模和用户需求的要求。研究结果表明，本系统可以比现有的主题建模和关键字提取解决方案获得更好的效果。 |
| [^13] | [Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts.](http://arxiv.org/abs/2306.04723) | 本文提出了衡量文本内部维度的方法，应用于鲁棒性AI生成文本的检测，展示了人类文本与AI生成文本在内部维度上的差异。 |
| [^14] | [SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts.](http://arxiv.org/abs/2306.02207) | 本文探索了一个名为SpeechGen的统一框架，通过提示调节，解锁了语音语言模型的生成能力，成功地实现了直接适应连续语音到离散标记的任务，使得语音生成成为可能。 |
| [^15] | [Beam Tree Recursive Cells.](http://arxiv.org/abs/2305.19999) | 本论文提出了一种支持反向传播的递归神经网络框架——束搜索递归单元（BT-Cell），用于扩展递归神经网络，实现对潜在结构的感知；此外，我们提出了一种放松束搜索中硬前k算子的方法，以实现更好的梯度信号传递。在评估中发现，BT-Cell在合成和实际数据的多个具有结构敏感性的任务中表现优异。 |
| [^16] | [Evaluating GPT-3 Generated Explanations for Hateful Content Moderation.](http://arxiv.org/abs/2305.17680) | 本文通过调查和分析，评估了使用GPT-3生成的针对仇恨内容的解释是否准确和有用。结果显示，GPT-3生成的解释普遍存在过于模糊、聚焦不当等缺点，同时也存在不同类型仇恨言论生成的解释质量差异大的问题。 |
| [^17] | [IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages.](http://arxiv.org/abs/2305.16307) | 本研究填补了印度22种官方语言机器翻译的空白，提出了IndicTrans2系统，它在多个语言对上表现最先进并优于现有的模型，同时提供了印度语言的基准和评估脚本。 |
| [^18] | [PromptNER: Prompting For Named Entity Recognition.](http://arxiv.org/abs/2305.15444) | PromptNER是一种基于提示的命名实体识别算法，利用LLM生成潜在实体列表并提供解释，在少样本NER和跨领域NER方面实现了最先进性能。 |
| [^19] | [Exploring the Viability of Synthetic Query Generation for Relevance Prediction.](http://arxiv.org/abs/2305.11944) | 本文研究在电子商务和医疗保健等专业领域中，利用强大的模型生成高质量特定任务和领域的合成数据，探索用于预测对文档的查询分级相关性的方法，并尝试使用无监督聚类技术进一步改进对数据中相关性模式的理解。 |
| [^20] | [Large Language Models can be Guided to Evade AI-Generated Text Detection.](http://arxiv.org/abs/2305.10847) | 本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。 |
| [^21] | [Bring More Attention to Syntactic Symmetry for Automatic Postediting of High-Quality Machine Translations.](http://arxiv.org/abs/2305.10557) | 这篇论文提出了一种新的方法来解决自动后编辑系统无法处理高质量机器翻译的问题，该方法通过对给定MT进行对称自我关注的损失函数进行正则化，从而提高了自动后编辑的质量。 |
| [^22] | [On the Hidden Mystery of OCR in Large Multimodal Models.](http://arxiv.org/abs/2305.07895) | 本研究全面评估了现有大型多模态模型在文本相关的视觉任务中的表现，结果显示这些模型虽然在语义理解方面表现优异，但对单个字符形状的感知有限，对图像的细粒度特征检测能力也不足，不能与传统领域特定方法相匹配，并仍需进一步探索它们在OCR中的表现。 |
| [^23] | [Advancing Neural Encoding of Portuguese with Transformer Albertina PT-*.](http://arxiv.org/abs/2305.06721) | 本研究使用基于 Transformer 的 Albertina PT-* 模型进行了葡萄牙语的神经编码，创新性地提升了该语言在数字时代的技术准备水平，尤其是欧洲葡萄牙语和巴西的美洲葡萄牙语两个变种。 |
| [^24] | [Assessing Working Memory Capacity of ChatGPT.](http://arxiv.org/abs/2305.03731) | 本文评估了最先进语言模型ChatGPT的工作记忆容量，结果显示其在N-back任务的行为表现与人类参与者相似，这为设计具有人类级认知能力的人工智能系统提供了关键洞察。 |
| [^25] | [RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models.](http://arxiv.org/abs/2305.01146) | 本研究重点研究了轻量化策略，通过在临床文本上进行预训练和在RRS示例上进行参数高效微调，实现适应大型语言模型进行放射性报告摘要（RRS）任务。并且该方法仅微调模型的0.32％的参数，提高了表现。研究结果强调了领域适应在RRS中的重要性，并为开发更好的放射性报告摘要模型提供了有价值的见解。 |
| [^26] | [Development of a Trust-Aware User Simulator for Statistical Proactive Dialog Modeling in Human-AI Teams.](http://arxiv.org/abs/2304.11913) | 本文开发了一种用户模拟器来训练和测试主动对话策略，提供了一种探索和评估人工智能团队表现的适当主动策略的途径。 |
| [^27] | [Revisiting k-NN for Pre-trained Language Models.](http://arxiv.org/abs/2304.09058) | 本研究提出一种新方法，结合k-NN和预训练语言模型（PLMs）能够提高自然语言处理（NLP）的性能，并在多个基准数据集上得到验证。 |
| [^28] | [ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition.](http://arxiv.org/abs/2304.05934) | ASL Citizen是目前最大的独立手语识别数据集，可用于手语字典检索，利用该数据集训练的机器学习分类器在度量标准上取得显著进展，例如在训练或验证中未出现的用户的视频上，实现了62％的准确性和90％的前10项检索召回率。 |
| [^29] | [OpenAGI: When LLM Meets Domain Experts.](http://arxiv.org/abs/2304.04370) | 基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。 |
| [^30] | [Towards MoE Deployment: Mitigating Inefficiencies in Mixture-of-Expert (MoE) Inference.](http://arxiv.org/abs/2303.06182) | 本文提出了三种优化技术来缓解混合专家（MoE）模型在推理时的低效率，包括动态门控、专家缓冲和专家负载平衡。这些技术可以显著提高执行时间和减少内存使用。 |
| [^31] | [Parameter-efficient Modularised Bias Mitigation via AdapterFusion.](http://arxiv.org/abs/2302.06321) | 本文提出了一个新的去偏差方法——DAM，它采用AdapterFusion概念，将偏差修正功能封装到独立的适配器中，在不影响核心模型的情况下，实现了按需的去偏差，可以有效降低模型的偏见问题。 |
| [^32] | [MarioGPT: Open-Ended Text2Level Generation through Large Language Models.](http://arxiv.org/abs/2302.05981) | MarioGPT是第一个文本到超级马里奥兄弟游戏关卡的生成模型，通过大型语言模型实现开放式的、可控制的关卡生成。 |
| [^33] | [Compositional Exemplars for In-context Learning.](http://arxiv.org/abs/2302.05698) | 该论文提出了CEIL（Compositional Exemplars for In-context Learning）框架，利用决定性点过程（DPP）模型处理上下文示例选择问题，从而提高了大型预训练语言模型（LMs）进行上下文学习的性能。 |
| [^34] | [EXIF as Language: Learning Cross-Modal Associations Between Images and Camera Metadata.](http://arxiv.org/abs/2301.04647) | 本文通过学习图像和相机元数据之间的交叉模态关联提取相机信息，并使用得到的特征成功实现拼接图像区域的"零样本"定位。 |
| [^35] | [MULTI3NLU++: A Multilingual, Multi-Intent, Multi-Domain Dataset for Natural Language Understanding in Task-Oriented Dialogue.](http://arxiv.org/abs/2212.10455) | MULTI3NLU++是一个多语言、多意图、多域数据集。其中包含手动翻译的多种高、中、低资源语言和两个领域。该数据集能够帮助衡量任务导向对话系统的现实性能。 |
| [^36] | [Extrinsic Evaluation of Machine Translation Metrics.](http://arxiv.org/abs/2212.10297) | 论文研究了机器翻译度量在大型平台和下游任务中的可靠性，发现某些度量在句子级别上表现不佳且其有用性与下游任务有关。 |
| [^37] | [MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are Better Dense Retrievers.](http://arxiv.org/abs/2212.07841) | 本文提出了一个名为MASTER的多任务预训练模型，利用瓶颈掩蔽自编码器统一各种预训练任务，并将其集成到一个模型中。该模型在两个广泛使用的数据集上的实验表明，相比同等模型大小和预训练资源的最先进密集检索模型，MASTER表现更好。 |
| [^38] | [MoNET: Tackle State Momentum via Noise-Enhanced Training for Dialogue State Tracking.](http://arxiv.org/abs/2211.05503) | 本研究提出了MoNET，通过噪声增强训练解决了对话状态跟踪中的状态惯性问题，提高了模型修正槽值的能力。 |
| [^39] | [The Tail Wagging the Dog: Dataset Construction Biases of Social Bias Benchmarks.](http://arxiv.org/abs/2210.10040) | 研究揭示了社会偏见基准中数据集构建偏见可能对结果造成了重要影响，需要更严谨的社会偏见度量方法。 |
| [^40] | [Textual Entailment Recognition with Semantic Features from Empirical Text Representation.](http://arxiv.org/abs/2210.09723) | 本文提出了一种利用实验证据的文本表征和语义特征的新方法，通过元素曼哈顿距离向量特征识别文本-假设之间的蕴涵关系，并在基准数据集上实现了显著的F1分数提高。 |
| [^41] | [PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting.](http://arxiv.org/abs/2210.08964) | 提出了一种新的时间序列预测范式——基于提示的时间序列预测（PromptCast），将数字输入和输出转化为提示，并以句子到句子的方式提出预测任务，可以直接应用于语言模型。 |
| [^42] | [Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity.](http://arxiv.org/abs/2209.12106) | 本研究证明大型语言模型表现出道德模仿能力，会根据政治身份生成反映相应道德偏见的文本。 |
| [^43] | [Prompting as Probing: Using Language Models for Knowledge Base Construction.](http://arxiv.org/abs/2208.11057) | 本文介绍了一种利用语言模型进行知识库构建的方法，该方法采用了多种提示技术，手动提示策略的编制至关重要，并且必须鼓励语言模型给出不同长度的答案集，特别是包括空答案集。实体别名字典可以提高语言模型的得分。 |
| [^44] | [A Cognitive Study on Semantic Similarity Analysis of Large Corpora: A Transformer-based Approach.](http://arxiv.org/abs/2207.11716) | 本文通过使用Transformer在U.S Patent Phrase to Phrase Matching Dataset上进行语义相似度分析，提高了算法效率，达到了令人满意的结果。 |
| [^45] | [Probing Classifiers are Unreliable for Concept Removal and Detection.](http://arxiv.org/abs/2207.04153) | 本文研究了在文本数据上神经网络模型中的不良概念去除。对于现有的后期和对抗性方法，本文理论和实证分析表明其依赖的探测分类器可能使用非概念特征，导致无法完全去除不需要的概念。我们提出了一种直接学习从模型的表示中去除概念的方法，实验结果表明其优于最先进的后期和对抗性方法。 |
| [^46] | [Multi-aspect Multilingual and Cross-lingual Parliamentary Speech Analysis.](http://arxiv.org/abs/2207.01054) | 本研究使用先进的自然语言处理方法，对2017年至2020年间保加利亚、捷克、法国、斯洛文尼亚、西班牙和英国六个国家的议会记录进行了联合和比较分析。结果显示出了这些国家之间的差异和共同点。 |
| [^47] | [Cross-lingual AMR Aligner: Paying Attention to Cross-Attention.](http://arxiv.org/abs/2206.07587) | 本文提出了一种跨语言AMR图对齐器，采用现代Transformer解析器编码对齐信息，避免使用英语特定规则或EM算法，同时提出一种引导监督方法并在多语言语料库上实现了最先进的结果。 |
| [^48] | [Word Discovery in Visually Grounded, Self-Supervised Speech Models.](http://arxiv.org/abs/2203.15081) | 这篇论文介绍了一种基于图像-语音联合训练的自监督模型，在模型训练后实现了自动词语分割和聚类的能力，并在两个任务中表现优异。 |
| [^49] | [Error correction and extraction in request dialogs.](http://arxiv.org/abs/2004.04243) | 该论文提出了一种对话系统实用组件，可自动检测和修正用户发出的请求信息中的错误，并将修正信息进行提取对，以实现学习和避免重复开发的优势。该方法适用于多种语序列标签、序列到序列和序列分类等情形。 |

# 详细

[^1]: ChatGPT和大型语言模型在生物医学和健康领域的机遇与挑战

    Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health. (arXiv:2306.10070v1 [cs.CY])

    [http://arxiv.org/abs/2306.10070](http://arxiv.org/abs/2306.10070)

    本文探讨了ChatGPT和大型语言模型在生物医学和健康领域的多样应用，发现在文本生成方面已经取得了重大进展，但对于其他应用进展缓慢，LLMs还没有真正彻底改变生物医学领域。

    

    ChatGPT由于其卓越的文本生成能力，已经引起了公众和领域专家的广泛关注，并产生了在生物医学和健康领域的各种应用。本文探讨了大型语言模型（LLMs）如ChatGPT在生物医学和健康领域的多样应用，具体探讨生物医学信息检索、问答、医疗文本摘要、信息抽取和医学教育等领域，并研究LLMs是否具有真正的转型力量以彻底改变这些任务或者生物医学领域的独特复杂性是否提出了独特的挑战。通过广泛的文献调研，我们发现在文本生成任务方面已经取得了重大进展，超越了以前的最先进方法。对于其他应用，进展还比较缓慢。总体而言，LLMs还没有彻底改变生物医学领域。

    ChatGPT has drawn considerable attention from both the general public and domain experts with its remarkable text generation capabilities. This has subsequently led to the emergence of diverse applications in the field of biomedicine and health. In this work, we examine the diverse applications of large language models (LLMs), such as ChatGPT, in biomedicine and health. Specifically we explore the areas of biomedical information retrieval, question answering, medical text summarization, information extraction, and medical education, and investigate whether LLMs possess the transformative power to revolutionize these tasks or whether the distinct complexities of biomedical domain presents unique challenges. Following an extensive literature survey, we find that significant advances have been made in the field of text generation tasks, surpassing the previous state-of-the-art methods. For other applications, the advances have been modest. Overall, LLMs have not yet revolutionized the bio
    
[^2]: 利用嵌入技术设计面向科学领域的聊天机器人

    Domain-specific ChatBots for Science using Embeddings. (arXiv:2306.10067v1 [cs.CL])

    [http://arxiv.org/abs/2306.10067](http://arxiv.org/abs/2306.10067)

    本论文演示如何利用现有方法和软件工具结合嵌入技术设计面向科学领域的聊天机器人，该机器人能够处理科学文献，提供特定领域的上下文信息，并在初步研究辅助知识方面为物理科学家提供帮助。

    

    大语言模型(LLM)已成为强大的机器学习系统，能处理多种任务。经调整的这些系统已被转化为聊天机器人，能回答用户对广泛话题的查询，提供丰富的信息和创意回答。然而，由于它们在自然科学领域的知识仍不完整，并且面临严格需求和来源标准，因此其在物理科学研究中的应用仍受到限制。本文演示了如何轻松地将现有方法和软件工具结合起来，实现面向特定领域的聊天机器人。该系统能接受现有格式的科学文献，并使用文本嵌入查找来为LLM提供特定领域的上下文信息，以便在撰写回答时使用。我们同样证明了现有的图像嵌入方法可以用于跨出版物图片的搜索和检索。这些结果表明，在提供初步研究辅助知识方面，LLM已经适用于物理科学家的使用，并且进一步的开发可以扩展这些应用。

    Large language models (LLMs) have emerged as powerful machine-learning systems capable of handling a myriad of tasks. Tuned versions of these systems have been turned into chatbots that can respond to user queries on a vast diversity of topics, providing informative and creative replies. However, their application to physical science research remains limited owing to their incomplete knowledge in these areas, contrasted with the needs of rigor and sourcing in science domains. Here, we demonstrate how existing methods and software tools can be easily combined to yield a domain-specific chatbot. The system ingests scientific documents in existing formats, and uses text embedding lookup to provide the LLM with domain-specific contextual information when composing its reply. We similarly demonstrate that existing image embedding methods can be used for search and retrieval across publication figures. These results confirm that LLMs are already suitable for use by physical scientists in acc
    
[^3]: 揭示语言模型能力的结构

    Revealing the structure of language model capabilities. (arXiv:2306.10062v1 [cs.CL])

    [http://arxiv.org/abs/2306.10062](http://arxiv.org/abs/2306.10062)

    本文研究了大规模语言模型的能力结构，发现这些模型不是单一能力，而是由推理、理解和核心语言建模等三个明确定义的因素组成，并且这三个能力可以解释模型性能中的大部分方差。

    

    建立大规模语言模型（LLMs）能力的理论理解对于我们预测和解释这些系统的行为至关重要。在这里，我们通过从各种LLMs的个体差异模式中提取潜在能力来调查LLMs能力的结构。使用贝叶斯和频率因子分析的组合，我们分析了来自29个不同LLMs的27种认知任务的数据。我们发现，LLMs能力并非单一的，相反，它们更好地由三个明确定义的因素解释，分别代表推理、理解和核心语言建模。此外，我们发现这三个因素可以解释模型性能中的高比例方差。这些结果揭示了不同LLMs能力的一致结构，并展示了这些能力的多方面性质。我们还发现这三个功能与模型属性具有不同的关系。

    Building a theoretical understanding of the capabilities of large language models (LLMs) is vital for our ability to predict and explain the behavior of these systems. Here, we investigate the structure of LLM capabilities by extracting latent capabilities from patterns of individual differences across a varied population of LLMs. Using a combination of Bayesian and frequentist factor analysis, we analyzed data from 29 different LLMs across 27 cognitive tasks. We found evidence that LLM capabilities are not monolithic. Instead, they are better explained by three well-delineated factors that represent reasoning, comprehension and core language modeling. Moreover, we found that these three factors can explain a high proportion of the variance in model performance. These results reveal a consistent structure in the capabilities of different LLMs and demonstrate the multifaceted nature of these capabilities. We also found that the three abilities show different relationships to model prope
    
[^4]: EM-Network: 用于序列学习的自身蒸馏方法

    EM-Network: Oracle Guided Self-distillation for Sequence Learning. (arXiv:2306.10058v1 [cs.LG])

    [http://arxiv.org/abs/2306.10058](http://arxiv.org/abs/2306.10058)

    EM-Network是一种自我蒸馏方法，通过神谕指导能够有效利用目标信息进行监督序列到序列学习，并在语音识别和机器翻译等任务上取得了最先进的成果。

    

    我们引入了EM-Network，一种新颖的自我蒸馏方法，可有效利用目标信息进行监督序列到序列（seq2seq）学习，与传统方法不同的是，它是在来自目标序列的“神谕指导”下训练的。由于神谕指导紧凑地表示了目标方面的上下文，可以帮助序列模型解决任务，因此与仅使用源输入相比，EM-Network实现了更好的预测。为了使序列模型继承EM-Network的有前途的能力，我们提出了一种新的自我蒸馏策略，原始序列模型可以在一个阶段中从EM-Network的知识中获益。我们在两种seq2seq模型上进行了综合实验：用于语音识别的连接主义时间分类（CTC）和用于机器翻译的基于注意力的编码器-解码器（AED）。实验结果表明，EM-Network极大地提高了模型性能，并在各种基准数据集上取得了最先进的成果。

    We introduce EM-Network, a novel self-distillation approach that effectively leverages target information for supervised sequence-to-sequence (seq2seq) learning. In contrast to conventional methods, it is trained with oracle guidance, which is derived from the target sequence. Since the oracle guidance compactly represents the target-side context that can assist the sequence model in solving the task, the EM-Network achieves a better prediction compared to using only the source input. To allow the sequence model to inherit the promising capability of the EM-Network, we propose a new self-distillation strategy, where the original sequence model can benefit from the knowledge of the EM-Network in a one-stage manner. We conduct comprehensive experiments on two types of seq2seq models: connectionist temporal classification (CTC) for speech recognition and attention-based encoder-decoder (AED) for machine translation. Experimental results demonstrate that the EM-Network significantly advanc
    
[^5]: 为了表示而生成——一种结合对比学习的语言预训练框架

    Generate to Understand for Representation. (arXiv:2306.10056v1 [cs.CL])

    [http://arxiv.org/abs/2306.10056](http://arxiv.org/abs/2306.10056)

    GUR是一种预训练框架，将语言建模和对比学习目标结合在单个训练步骤中，通过从原始无标签文档中选择相似的文本对来训练模型，无需任何标记训练数据即可作为检索器超过其他预训练基线模型。

    

    近年来涌现了大量高质量的预训练模型，极大地影响了自然语言理解、自然语言生成和文本表示等任务。然而，传统上这些模型是在特定领域的语料库上进行预训练，并进行特定任务的微调，这导致了高昂的GPU使用和劳动力成本。文章提出了GUR：一种将语言建模和对比学习目标结合在单个训练步骤中的预训练框架。我们从原始的无标签文档中基于最长公共子字符串（LCS）选择相似的文本对，并使用掩码语言建模和无监督对比学习来训练模型。结果表明，GUR模型在没有任何标记训练数据的情况下取得了令人印象深刻的结果，作为检索器超过了所有其他预训练基线模型。

    In recent years, a significant number of high-quality pretrained models have emerged, greatly impacting Natural Language Understanding (NLU), Natural Language Generation (NLG), and Text Representation tasks. Traditionally, these models are pretrained on custom domain corpora and finetuned for specific tasks, resulting in high costs related to GPU usage and labor. Unfortunately, recent trends in language modeling have shifted towards enhancing performance through scaling, further exacerbating the associated costs.  Introducing GUR: a pretraining framework that combines language modeling and contrastive learning objectives in a single training step. We select similar text pairs based on their Longest Common Substring (LCS) from raw unlabeled documents and train the model using masked language modeling and unsupervised contrastive learning. The resulting model, GUR, achieves impressive results without any labeled training data, outperforming all other pretrained baselines as a retriever a
    
[^6]: 一种用于科学文献中表格实体链接的实用系统。

    A Practical Entity Linking System for Tables in Scientific Literature. (arXiv:2306.10044v1 [cs.IR])

    [http://arxiv.org/abs/2306.10044](http://arxiv.org/abs/2306.10044)

    本文介绍了一个用于将实体链接到知识库中的通用系统，并将其适应于链接特定领域的实体，特别是 COVID-19 相关科学文献中的嵌入式实体。通过利用表格的结构和语义特征，以提高整体实体链接性能。

    

    实体链接是构建知识图谱的重要步骤，可以方便地回答包括从这些文档中检索相关信息在内的高级问题。本文介绍了一种通用的系统，用于将实体链接到维基数据知识库中的项。它描述了如何适应该系统以链接领域特定的实体，特别是那些来自COVID-19相关科学文献中的嵌入式实体。我们描述了系统的离线实例的设置，使我们的实体链接方法在实践中更加可行。作为推断科学表格的语义含义的更广泛方法的一部分，我们利用表格的结构和语义特征来提高整体实体链接性能。

    Entity linking is an important step towards constructing knowledge graphs that facilitate advanced question answering over scientific documents, including the retrieval of relevant information included in tables within these documents. This paper introduces a general-purpose system for linking entities to items in the Wikidata knowledge base. It describes how we adapt this system for linking domain-specific entities, especially for those entities embedded within tables drawn from COVID-19-related scientific literature. We describe the setup of an efficient offline instance of the system that enables our entity-linking approach to be more feasible in practice. As part of a broader approach to infer the semantic meaning of scientific tables, we leverage the structural and semantic characteristics of the tables to improve overall entity linking performance.
    
[^7]: 一种用于Aspect Sentiment Triplet Extraction的配对增强方法

    A Pairing Enhancement Approach for Aspect Sentiment Triplet Extraction. (arXiv:2306.10042v1 [cs.IR])

    [http://arxiv.org/abs/2306.10042](http://arxiv.org/abs/2306.10042)

    本文提出了一种配对增强方法，通过对比学习将方面-意见配对知识注入到Aspect Sentiment Triplet Extraction（ASTE）模型中，提高了三元组提取的准确性和性能。

    

    Aspect Sentiment Triplet Extraction（ASTE）旨在从评论文本中提取一个方面术语、一个意见术语和它们相应的情感极性的三元组。由于语言的复杂性和单个句子中存在多个方面术语和意见术语，当前的模型经常会混淆描述它的方面术语和意见术语之间的联系。为了解决这个问题，我们提出了一种配对增强方法，它在训练阶段采用对比学习，将方面-意见配对知识注入到三元组提取模型中。实验结果表明，与几种相关经典和最先进的三元组提取方法相比，我们的方法在四个ASTE数据集（即14lap，14res，15res和16res）上表现良好。此外，消融研究进行分析并验证了对比学习相比其他配对增强方法的优势。

    Aspect Sentiment Triplet Extraction (ASTE) aims to extract the triplet of an aspect term, an opinion term, and their corresponding sentiment polarity from the review texts. Due to the complexity of language and the existence of multiple aspect terms and opinion terms in a single sentence, current models often confuse the connections between an aspect term and the opinion term describing it. To address this issue, we propose a pairing enhancement approach for ASTE, which incorporates contrastive learning during the training stage to inject aspect-opinion pairing knowledge into the triplet extraction model. Experimental results demonstrate that our approach performs well on four ASTE datasets (i.e., 14lap, 14res, 15res and 16res) compared to several related classical and state-of-the-art triplet extraction methods. Moreover, ablation studies conduct an analysis and verify the advantage of contrastive learning over other pairing enhancement approaches.
    
[^8]: 揭秘 GPT 自我修复代码生成能力

    Demystifying GPT Self-Repair for Code Generation. (arXiv:2306.09896v1 [cs.CL])

    [http://arxiv.org/abs/2306.09896](http://arxiv.org/abs/2306.09896)

    本文分析了 GPT-3.5 和 GPT-4 在 APPS 数据集上执行自我修复的能力，发现自我修复在 GPT 模型中的有效性严重取决于任务的质量和复杂性，自我修复在较短和较简单的任务中效果更好，仅在某些代码部分上应用自我修复可以非常有效，本文提出的引导修复方法在 APPS 数据集上获得性能提升。

    

    大型语言模型 (LLM) 在代码生成方面表现出色，但在挑战性编程任务上仍面临困难。自我修复——即模型调试并修复自己的代码——最近成为提高性能的一种流行方式。然而，关于自我修复如何有效地发挥作用的研究还非常有限。有人会想知道，当同一模型生成代码时，模型究竟能否提供准确的反馈。在本文中，我们分析了 GPT-3.5 和 GPT-4 在 APPS 数据集上执行自我修复的能力，这是一个由多种编码挑战组成的具有挑战性的数据集。我们首先建立了一种新的评估策略 pass@t，该策略衡量了任务通过率与从模型中抽样的总标记数，从而实现对仅基于抽样的方法的公平比较。通过这种评估策略，我们发现自我修复在 GPT 模型中的有效性严重取决于任务的质量和复杂性，并确定了影响自我修复表现的几个因素。具体而言，我们发现，在输入噪声较少且模型对初始输出不太自信的较短和较简单的任务中，自我修复效果更好。我们还表明，仅在某些代码部分上应用自我修复可以非常有效。此外，我们提出了一种新的引导修复方法，利用外部反馈来增强 GPT 模型的自我修复能力，在 APPS 数据集上获得性能提升。

    Large Language Models (LLMs) have shown remarkable aptitude in code generation but still struggle on challenging programming tasks. Self-repair -in which the model debugs and fixes mistakes in its own code -- has recently become a popular way to boost performance in these settings. However, only very limited studies on how and when self-repair works effectively exist in the literature, and one might wonder to what extent a model is really capable of providing accurate feedback on why the code is wrong when that code was generated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's ability to perform self-repair on APPS, a challenging dataset consisting of diverse coding challenges. To do so, we first establish a new evaluation strategy dubbed pass@t that measures the pass rate of the tasks against the total number of tokens sampled from the model, enabling a fair comparison to purely sampling-based approaches. With this evaluation strategy, we find that the effectiveness
    
[^9]: RED$^{\rm FM}$：一个经过滤波和多语言处理的关系抽取数据集

    RED$^{\rm FM}$: a Filtered and Multilingual Relation Extraction Dataset. (arXiv:2306.09802v1 [cs.CL])

    [http://arxiv.org/abs/2306.09802](http://arxiv.org/abs/2306.09802)

    本文提出了两个新的数据集，分别是自动标注的SRED$^{\rm FM}$和人工修订的RED$^{\rm FM}$。SRED$^{\rm FM}$涵盖了18种语言、400种关系类型、13种实体类型，总共超过4000万个三元组实例；RED$^{\rm FM}$是RED的精简版，可用于评估多语言关系抽取系统。实验证明，这些新数据集能有效用于建立多语言关系抽取模型。

    

    关系抽取旨在识别文本中实体之间的关系，从而获取关系事实，弥合自然语言和结构化知识之间的差距。然而，当前的关系抽取模型往往依赖于小型数据集，对于非英语语言的关系类型覆盖率也较低。本文提出了两个新的资源，可用于培训和评估多语言关系抽取系统。其一，我们提供了一个自动标注的数据集——SRED$^{\rm FM}$，涵盖了18种语言、400种关系类型、13种实体类型，总共超过4000万个三元组实例。其二，我们提出了一个经人工修订的、针对七种语言的数据集——RED$^{\rm FM}$，可用于多语言关系抽取系统的评估。为了展示这些新数据集的实用性，我们使用第一个端到端的多语言关系抽取模型mREBEL进行实验，包括实体类型在内的三元组被抽取出来。

    Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems. First, we present SRED$^{\rm FM}$, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED$^{\rm FM}$, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. To demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, that extracts triplets, including entity types,
    
[^10]: DiPlomat: 用于情境语用推理的对话数据集

    DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning. (arXiv:2306.09030v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.09030](http://arxiv.org/abs/2306.09030)

    本文提出一个新的对话数据集DiPlomat，用于评测机器的情境推理和对话理解能力。与先前工作相比，DiPlomat提供了一个统一的框架来实现一般的语用理解。我们的数据集通过利用亚马逊机械土耳其语（AMT）来创建，共有4,177个多轮对话。与数据集一起，我们提出了两个任务：语用识别和推理（PIR）和会话问答（CQA）。

    

    语用推理在破解实际对话中经常出现的隐含含义方面起着关键作用，并且对于发展交际社会代理人至关重要。本文介绍了一个新的挑战——DiPlomat，旨在对机器的情境推理和对话理解能力进行基准测试。与将不同的比喻表达（例如比喻、讽刺）视为单独任务的先前工作相比，DiPlomat提供了一个统一的框架来实现一般的语用理解。我们的数据集通过利用亚马逊机械土耳其语（AMT）来创建，共有4,177个多轮对话。与数据集一起，我们提出了两个任务：语用识别和推理（PIR）和会话问答（CQA）。与最先进的（SOTA）神经架构进行的实验结果揭示了几个重要发现：1）大型语言模型（LLMs）表现不佳。

    Pragmatic reasoning plays a pivotal role in deciphering implicit meanings that frequently arise in real-life conversations and is essential for the development of communicative social agents. In this paper, we introduce a novel challenge, DiPlomat, aiming at benchmarking machines' capabilities on pragmatic reasoning and situated conversational understanding. Compared with previous works that treat different figurative expressions (e.g. metaphor, sarcasm) as individual tasks, DiPlomat provides a cohesive framework towards general pragmatic understanding. Our dataset is created through the utilization of Amazon Mechanical Turk ( AMT ), resulting in a total of 4, 177 multi-turn dialogues. In conjunction with the dataset, we propose two tasks, Pragmatic Identification and Reasoning (PIR) and Conversational Question Answering (CQA). Experimental results with state-of-the-art (SOTA) neural architectures reveal several significant findings: 1) large language models ( LLMs) exhibit poor perfor
    
[^11]: 统一大型语言模型和知识图谱: 一条路线图

    Unifying Large Language Models and Knowledge Graphs: A Roadmap. (arXiv:2306.08302v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.08302](http://arxiv.org/abs/2306.08302)

    本文提出了一个前瞻性的统一大型语言模型和知识图谱的路线图，通过三个框架：增强KGs的LLMs，知识增强KGs和LLMs与KGs的联合推理，综合利用两者的优点。

    

    大型语言模型（LLM）如ChatGPT和GPT4正在自然语言处理和人工智能领域掀起新的热潮，由于它们的突现能力和一般化能力。然而，LLM是黑盒模型，往往不能捕捉和获取实际知识。相比之下，知识图谱（KGs）如维基百科和华普则是明确存储丰富实际知识的结构化知识模型。KGs可以通过为推理和可解释性提供外部知识来增强LLMs。同时，KGs的构建困难，自然而然地演化，这挑战了现有的KGs方法来生成新事实并表示未见过的知识。因此，统一LLMs和KGs并同时利用它们的优点是有益的。本文介绍了一个前瞻性的统一LLMs和KGs的路线图。我们的路线图包括三个一般框架，即1）增强KGs的LLMs，它们将知识表示为LM的一部分，从而能够捕捉丰富的实体关系，2）知识增强KGs，它们将LLMs用作知识表示学习的优秀工具，3）LLMs与KGs的联合推理，其中LLMs和KGs相互增强，从而获得更准确的推理模型。

    Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolving by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs, which incorpo
    
[^12]: 一种基于云的机器学习管道，有效从客户评论中提取见解

    A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews. (arXiv:2306.07786v1 [cs.CL])

    [http://arxiv.org/abs/2306.07786](http://arxiv.org/abs/2306.07786)

    本文介绍了一种基于云的系统，利用机器学习方法从客户评论中提取见解。本研究提出的组合模型使用了转换器神经网络、向量嵌入和聚类，已经集成并进一步发展，以更好地满足高效信息提取、提取信息的主题建模和用户需求的要求。研究结果表明，本系统可以比现有的主题建模和关键字提取解决方案获得更好的效果。

    

    随着机器学习模型的出现，特别是基于神经网络的解决方案，自然语言处理的效率有了显著提高。然而，一些任务仍然具有挑战性，特别是考虑到特定的应用领域。本文提出了一种基于云的系统，可以使用机器学习方法集成到管道中，从客户评论中提取见解。对于主题建模，我们的组合模型使用了基于转换器的自然语言处理神经网络、基于向量嵌入的关键字提取和聚类。我们的模型元素已经集成并进一步发展，以更好地满足高效信息提取、提取信息的主题建模和用户需求的要求。此外，我们的系统可以比这个任务现有的主题建模和关键字提取解决方案获得更好的结果。我们的方法在公开可用的客户评论数据集上得到验证并与其他最先进的方法进行比较。

    The efficiency of natural language processing has improved dramatically with the advent of machine learning models, particularly neural network-based solutions. However, some tasks are still challenging, especially when considering specific domains. In this paper, we present a cloud-based system that can extract insights from customer reviews using machine learning methods integrated into a pipeline. For topic modeling, our composite model uses transformer-based neural networks designed for natural language processing, vector embedding-based keyword extraction, and clustering. The elements of our model have been integrated and further developed to meet better the requirements of efficient information extraction, topic modeling of the extracted information, and user needs. Furthermore, our system can achieve better results than this task's existing topic modeling and keyword extraction solutions. Our approach is validated and compared with other state-of-the-art methods using publicly a
    
[^13]: 鲁棒性AI生成文本检测的内部维度估计

    Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts. (arXiv:2306.04723v1 [cs.CL])

    [http://arxiv.org/abs/2306.04723](http://arxiv.org/abs/2306.04723)

    本文提出了衡量文本内部维度的方法，应用于鲁棒性AI生成文本的检测，展示了人类文本与AI生成文本在内部维度上的差异。

    

    快速提高的AI生成内容的质量使得很难区分人类和AI生成的文本，这可能会对社会产生不良影响。因此，研究人类文本的不变属性变得越来越重要。本文提出了一种人类文本的不变特征，即给定文本样本嵌入集合下的流形的内部维度。我们展示了自然语言流畅文本的平均内部维度在几个基于字母的语言中约为 $9$，而中文约为 $7$，而每种语言的AI生成文本的平均内部维度较低，差约 $1.5$，并且有明显的统计分离。

    Rapidly increasing quality of AI-generated content makes it difficult to distinguish between human and AI-generated texts, which may lead to undesirable consequences for society. Therefore, it becomes increasingly important to study the properties of human texts that are invariant over text domains and various proficiency of human writers, can be easily calculated for any language, and can robustly separate natural and AI-generated texts regardless of the generation model and sampling method. In this work, we propose such an invariant of human texts, namely the intrinsic dimensionality of the manifold underlying the set of embeddings of a given text sample. We show that the average intrinsic dimensionality of fluent texts in natural language is hovering around the value $9$ for several alphabet-based languages and around $7$ for Chinese, while the average intrinsic dimensionality of AI-generated texts for each language is $\approx 1.5$ lower, with a clear statistical separation between
    
[^14]: SpeechGen: 利用提示解锁语音语言模型的生成能力

    SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts. (arXiv:2306.02207v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2306.02207](http://arxiv.org/abs/2306.02207)

    本文探索了一个名为SpeechGen的统一框架，通过提示调节，解锁了语音语言模型的生成能力，成功地实现了直接适应连续语音到离散标记的任务，使得语音生成成为可能。

    

    大型语言模型（LLM）在人工智能生成内容（AIGC）中引起了相当大的关注，特别是随着ChatGPT的出现。然而，将连续语音直接适应于处理离散标记的LLM仍然是一个未解决的挑战，这妨碍了LLM在语音生成方面的应用。高级语音LM们无法充分利用语音信号所包含的丰富信息，包括说话者和情感等，这些信息仅通过文本数据无法获取。在一些语音分类任务中，简单的提示调整已经表现出明显的参数效率和竞争性能的提高。但在多大程度上提示能够有效地激发语音LM的生成任务仍然是一个未知的问题。本文提出了一项先驱性研究，该研究在称为SpeechGen的统一框架中使用提示调节来刺激语音LM进行各种生成任务，并具有约10M可训练参数。

    Large language models (LLMs) have gained considerable attention for Artificial Intelligence Generated Content (AIGC), particularly with the emergence of ChatGPT. However, the direct adaptation of continuous speech to LLMs that process discrete tokens remains an unsolved challenge, hindering the application of LLMs for speech generation. The advanced speech LMs are in the corner, as that speech signals encapsulate a wealth of information, including speaker and emotion, beyond textual data alone. Prompt tuning has demonstrated notable gains in parameter efficiency and competitive performance on some speech classification tasks. However, the extent to which prompts can effectively elicit generation tasks from speech LMs remains an open question. In this paper, we present pioneering research that explores the application of prompt tuning to stimulate speech LMs for various generation tasks, within a unified framework called SpeechGen, with around 10M trainable parameters. The proposed unif
    
[^15]: 束搜索递归单元：一种支持反向传播的递归神经网络框架

    Beam Tree Recursive Cells. (arXiv:2305.19999v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.19999](http://arxiv.org/abs/2305.19999)

    本论文提出了一种支持反向传播的递归神经网络框架——束搜索递归单元（BT-Cell），用于扩展递归神经网络，实现对潜在结构的感知；此外，我们提出了一种放松束搜索中硬前k算子的方法，以实现更好的梯度信号传递。在评估中发现，BT-Cell在合成和实际数据的多个具有结构敏感性的任务中表现优异。

    

    本文提出了一种叫做束搜索递归单元（BT-Cell）的框架，用于扩展支持使用束搜索进行潜在结构感知的递归神经网络（RvNN）。我们进一步通过提出在束搜索中对硬性前k算子的放松来扩展此框架，以更好地传递梯度信号。我们在合成和实际数据的不同代表性分布上评估了我们的模型。实验结果表明，BT-Cell在多个具有挑战性的体现结构敏感性的任务（如ListOps和逻辑推理）上达到了几乎完美的性能，同时在实际数据上与其他基于RvNN的模型具有可比性的性能。此外，我们在ListOps中确定了神经模型在推广到未见过的参数数量上的未知失效案例。代码可在https://github.com/JRC1995/BeamTreeRecursiveCells上获得。

    We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendly framework to extend Recursive Neural Networks (RvNNs) with beam search for latent structure induction. We further extend this framework by proposing a relaxation of the hard top-k operators in beam search for better propagation of gradient signals. We evaluate our proposed models in different out-of-distribution splits in both synthetic and realistic data. Our experiments show that BTCell achieves near-perfect performance on several challenging structure-sensitive synthetic tasks like ListOps and logical inference while maintaining comparable performance in realistic data against other RvNN-based models. Additionally, we identify a previously unknown failure case for neural models in generalization to unseen number of arguments in ListOps. The code is available at: https://github.com/JRC1995/BeamTreeRecursiveCells.
    
[^16]: 评估GPT-3生成的仇恨内容审核解释

    Evaluating GPT-3 Generated Explanations for Hateful Content Moderation. (arXiv:2305.17680v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17680](http://arxiv.org/abs/2305.17680)

    本文通过调查和分析，评估了使用GPT-3生成的针对仇恨内容的解释是否准确和有用。结果显示，GPT-3生成的解释普遍存在过于模糊、聚焦不当等缺点，同时也存在不同类型仇恨言论生成的解释质量差异大的问题。

    

    最近的研究聚焦于使用基于大型语言模型（LLMs）的Fine-tune或提示生成仇恨言论的解释。尽管这个领域越来越受关注，但这些生成解释的有效性和潜在限制仍然不为人们所了解。一个关键问题是，由LLMs生成的这些解释可能会导致用户和内容审核员对标记内容本质做出错误判断。我们提出一个分析框架来检查仇恨言论解释，并进行了一个广泛的调查来评估这些解释。我们在GPT-3上输入仇恨和非仇恨内容，发现受调查者在人工审核GPT生成的解释时，将仇恨言论解释评价为不够准确和有用。

    Recent research has focused on using large language models (LLMs) to generate explanations for hate speech through fine-tuning or prompting. Despite the growing interest in this area, these generated explanations' effectiveness and potential limitations remain poorly understood. A key concern is that these explanations, generated by LLMs, may lead to erroneous judgments about the nature of flagged content by both users and content moderators. For instance, an LLM-generated explanation might inaccurately convince a content moderator that a benign piece of content is hateful. In light of this, we propose an analytical framework for examining hate speech explanations and conducted an extensive survey on evaluating such explanations. Specifically, we prompted GPT-3 to generate explanations for both hateful and non-hateful content, and a survey was conducted with 2,400 unique respondents to evaluate the generated explanations. Our findings reveal that (1) human evaluators rated the GPT-gene
    
[^17]: IndicTrans2: 为印度所有22种官方语言构建高质量可访问的机器翻译模型

    IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages. (arXiv:2305.16307v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16307](http://arxiv.org/abs/2305.16307)

    本研究填补了印度22种官方语言机器翻译的空白，提出了IndicTrans2系统，它在多个语言对上表现最先进并优于现有的模型，同时提供了印度语言的基准和评估脚本。

    

    印度有着丰富的语言景观，包括四个主要语系的语言，超过十亿人口使用。本篇论文聚焦于印度宪法列出的22种语言，被称为“官方语言”。鉴于语言多样性，高质量和可访问的机器翻译系统在印度这样的国家至关重要。在此之前，缺少（i）涵盖所有22种语言的平行训练数据，（ii）覆盖这些语言并包含印度相关内容的健壮基准，以及（iii）支持印度所有22种官方语言的现有翻译模型。本文旨在填补这一空白，并专注于启用22种印度官方语言的广泛、易于使用和开放式访问好的机器翻译系统所需的缺失部分。我们确定了四个改进关键领域：策划和创建更大的训练数据集、创建多样化和高质量的基准、跨越所有22种官方语言进行翻译，并构建高质量且可访问的机器翻译模型。我们的提议系统IndicTrans2在多个语言对上实现了最先进的性能，并且优于现有的在22种官方语言下的机器翻译模型。此外，我们提供了这些语言的基准和评估脚本，使得研究人员更容易地评价和提高关于印度语言的机器翻译模型。

    India has a rich linguistic landscape with languages from 4 major language families spoken by over a billion people. 22 of these languages are listed in the Constitution of India (referred to as scheduled languages) are the focus of this work. Given the linguistic diversity, high-quality and accessible Machine Translation (MT) systems are essential in a country like India. Prior to this work, there was (i) no parallel training data spanning all the 22 languages, (ii) no robust benchmarks covering all these languages and containing content relevant to India, and (iii) no existing translation models which support all the 22 scheduled languages of India. In this work, we aim to address this gap by focusing on the missing pieces required for enabling wide, easy, and open access to good machine translation systems for all 22 scheduled Indian languages. We identify four key areas of improvement: curating and creating larger training datasets, creating diverse and high-quality benchmarks, tra
    
[^18]: PromptNER: 基于提示的命名实体识别

    PromptNER: Prompting For Named Entity Recognition. (arXiv:2305.15444v1 [cs.CL])

    [http://arxiv.org/abs/2305.15444](http://arxiv.org/abs/2305.15444)

    PromptNER是一种基于提示的命名实体识别算法，利用LLM生成潜在实体列表并提供解释，在少样本NER和跨领域NER方面实现了最先进性能。

    

    令人惊讶的是，大型语言模型（LLMs）和越来越多的基于提示的启发式方法现在提供了强大的现成方法，为各种经典的NLP问题提供了少量样本的解决方案。然而，尽管有着令人期待的初步结果，但这些基于LLM的少样本方法在命名实体识别（NER）方面仍远未达到最先进水平，现有的方法包括通过端到端结构理解学习表示，并在标准标记语料库上进行微调。本文介绍了PromptNER，一种新的用于少样本和跨领域NER的最先进算法。为了适应任何新的NER任务，PromptNER需要提供一组实体定义，除基本的少样本样例以外。给定输入句子，PromptNER提示LLM生成一个潜在实体列表，并提供相应的解释，证明它们与提供的实体类型定义的兼容性。值得注意的是，PromptNER在少样本NER任务方面实现了最先进的性能，并在具有挑战性的WikiAnn数据集上为跨领域NER设定了新的SOTA。

    In a surprising turn, Large Language Models (LLMs) together with a growing arsenal of prompt-based heuristics now offer powerful off-the-shelf approaches providing few-shot solutions to myriad classic NLP problems. However, despite promising early results, these LLM-based few-shot methods remain far from the state of the art in Named Entity Recognition (NER), where prevailing methods include learning representations via end-to-end structural understanding and fine-tuning on standard labeled corpora. In this paper, we introduce PromptNER, a new state-of-the-art algorithm for few-Shot and cross-domain NER. To adapt to any new NER task PromptNER requires a set of entity definitions in addition to the standard few-shot examples. Given a sentence, PromptNER prompts an LLM to produce a list of potential entities along with corresponding explanations justifying their compatibility with the provided entity type definitions. Remarkably, PromptNER achieves state-of-the-art performance on few-sho
    
[^19]: 探索用于相关性预测的合成查询生成的可行性

    Exploring the Viability of Synthetic Query Generation for Relevance Prediction. (arXiv:2305.11944v1 [cs.IR])

    [http://arxiv.org/abs/2305.11944](http://arxiv.org/abs/2305.11944)

    本文研究在电子商务和医疗保健等专业领域中，利用强大的模型生成高质量特定任务和领域的合成数据，探索用于预测对文档的查询分级相关性的方法，并尝试使用无监督聚类技术进一步改进对数据中相关性模式的理解。

    

    查询-文档相关性预测是信息检索系统中的一个关键问题。这个问题越来越多地使用（预先训练的）基于转换器的模型来解决，这些模型使用大量标记数据进行微调。然而，在电子商务和医疗保健等专业领域，这种方法的可行性受到领域内大规模数据的匮乏限制。为了解决这个问题，最近的方法利用这些强大的模型生成高质量的特定任务和领域的合成数据。先前的工作主要探索了合成数据生成或用于问答和二元（是/否）相关性预测的查询生成（QGen）, 其中例如，QGen模型给出一个文档，并训练生成一个与该文档相关的查询。然而，在许多问题中，我们对相关性有一个更细粒度的概念，而不是一个简单的是/否标签。因此，在这项工作中，我们进行了详细的研究，探讨了如何利用QGen方法实现细微的相关性预测。具体而言，我们研究了使用合成查询来预测对文档的查询分级相关性的有效性，并探索使用无监督聚类技术进一步改进对数据中相关性模式的理解。

    Query-document relevance prediction is a critical problem in Information Retrieval systems. This problem has increasingly been tackled using (pretrained) transformer-based models which are finetuned using large collections of labeled data. However, in specialized domains such as e-commerce and healthcare, the viability of this approach is limited by the dearth of large in-domain data. To address this paucity, recent methods leverage these powerful models to generate high-quality task and domain-specific synthetic data. Prior work has largely explored synthetic data generation or query generation (QGen) for Question-Answering (QA) and binary (yes/no) relevance prediction, where for instance, the QGen models are given a document, and trained to generate a query relevant to that document. However in many problems, we have a more fine-grained notion of relevance than a simple yes/no label. Thus, in this work, we conduct a detailed study into how QGen approaches can be leveraged for nuanced
    
[^20]: 大型语言模型可以被引导来规避AI生成的文本检测

    Large Language Models can be Guided to Evade AI-Generated Text Detection. (arXiv:2305.10847v1 [cs.CL])

    [http://arxiv.org/abs/2305.10847](http://arxiv.org/abs/2305.10847)

    本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。

    

    大型语言模型在包括论文写作和问答等多个任务中展现出了出色的表现。然而，必须解决这些模型潜在的误用问题，否则可能导致抄袭和垃圾信息等不良后果。本研究揭示，通过精心设计的提示语，LLMs可以有效地规避检测系统。我们提出了一种新颖的基于替换的上下文示例优化方法（SICO），用于自动生成这种提示语。在三个现实任务中，LLMs可能被误用，在SICO的帮助下，ChatGPT成功地规避了六项现有的检测器，平均导致0.54的AUC下降。令人惊讶的是，在大多数情况下，这些检测器的表现甚至比随机分类器还要差。这些结果坚定地揭示了现有检测器的脆弱性。

    Large Language Models (LLMs) have demonstrated exceptional performance in a variety of tasks, including essay writing and question answering. However, it is crucial to address the potential misuse of these models, which can lead to detrimental outcomes such as plagiarism and spamming. Recently, several detectors have been proposed, including fine-tuned classifiers and various statistical methods. In this study, we reveal that with the aid of carefully crafted prompts, LLMs can effectively evade these detection systems. We propose a novel Substitution-based In-Context example Optimization method (SICO) to automatically generate such prompts. On three real-world tasks where LLMs can be misused, SICO successfully enables ChatGPT to evade six existing detectors, causing a significant 0.54 AUC drop on average. Surprisingly, in most cases these detectors perform even worse than random classifiers. These results firmly reveal the vulnerability of existing detectors. Finally, the strong perfor
    
[^21]: "自动后编辑高质量机器翻译中的句法对称性"

    Bring More Attention to Syntactic Symmetry for Automatic Postediting of High-Quality Machine Translations. (arXiv:2305.10557v1 [cs.CL])

    [http://arxiv.org/abs/2305.10557](http://arxiv.org/abs/2305.10557)

    这篇论文提出了一种新的方法来解决自动后编辑系统无法处理高质量机器翻译的问题，该方法通过对给定MT进行对称自我关注的损失函数进行正则化，从而提高了自动后编辑的质量。

    

    自动后编辑（APE）是用于改进给定机器翻译（MT）的自动化过程。最近的研究发现，即使是在有丰富数据资源的语言对（英语-德语），现有的APE系统也不擅长处理高质量的MT：给定的MT质量越高，决定哪些部分需要编辑以及如何修复这些错误就越困难。解决这个问题的一个可能的方法是将更深入的目标语言知识注入模型中。因此，我们提出了一种具有语言学动机的正则化方法，该方法可增强APE模型对目标语言的理解：通过一个鼓励对给定MT进行对称自我关注的损失函数。我们对实验结果的分析表明，所提出的方法有助于提高高质量MT的当前最先进架构的APE质量。

    Automatic postediting (APE) is an automated process to refine a given machine translation (MT). Recent findings present that existing APE systems are not good at handling high-quality MTs even for a language pair with abundant data resources, English$\unicode{x2013}$German: the better the given MT is, the harder it is to decide what parts to edit and how to fix these errors. One possible solution to this problem is to instill deeper knowledge about the target language into the model. Thus, we propose a linguistically motivated method of regularization that is expected to enhance APE models' understanding of the target language: a loss function that encourages symmetric self-attention on the given MT. Our analysis of experimental results demonstrates that the proposed method helps improving the state-of-the-art architecture's APE quality for high-quality MTs.
    
[^22]: 关于大型多模态模型中OCR的隐秘之谜

    On the Hidden Mystery of OCR in Large Multimodal Models. (arXiv:2305.07895v1 [cs.CV])

    [http://arxiv.org/abs/2305.07895](http://arxiv.org/abs/2305.07895)

    本研究全面评估了现有大型多模态模型在文本相关的视觉任务中的表现，结果显示这些模型虽然在语义理解方面表现优异，但对单个字符形状的感知有限，对图像的细粒度特征检测能力也不足，不能与传统领域特定方法相匹配，并仍需进一步探索它们在OCR中的表现。

    

    近来，大型模型在自然语言处理和多模态视觉语言学习中扮演着支配性的角色。关于它们在文本相关的视觉任务中有效性的探索仍不够。我们对现有公开可用的多模态模型进行了全面的研究，评估了它们在文本识别、基于文本的视觉问答和关键信息提取方面的表现。我们的研究结果揭示了这些模型的优劣势，它们主要依赖于语义理解来识别单词，并表现出较差的对单个字符形状的感知。它们对文本长度漠不关心，在检测图像的细粒度特征方面具有有限的能力。因此，这些结果表明，即使当前最强大的大型多模态模型也无法与传统文本任务的领域特定方法相匹配，并在更复杂的任务中面临更大的挑战。最重要的是，本研究展示的基线结果揭示了大型多模态模型中OCR的隐秘之谜，仍需要进一步探索。

    Large models have recently played a dominant role in natural language processing and multimodal vision-language learning. It remains less explored about their efficacy in text-related visual tasks. We conducted a comprehensive study of existing publicly available multimodal models, evaluating their performance in text recognition, text-based visual question answering, and key information extraction. Our findings reveal strengths and weaknesses in these models, which primarily rely on semantic understanding for word recognition and exhibit inferior perception of individual character shapes. They also display indifference towards text length and have limited capabilities in detecting fine-grained features in images. Consequently, these results demonstrate that even the current most powerful large multimodal models cannot match domain-specific methods in traditional text tasks and face greater challenges in more complex tasks. Most importantly, the baseline results showcased in this study
    
[^23]: 基于 Transformer Albertina PT-* 提升葡萄牙语的神经编码

    Advancing Neural Encoding of Portuguese with Transformer Albertina PT-*. (arXiv:2305.06721v1 [cs.CL])

    [http://arxiv.org/abs/2305.06721](http://arxiv.org/abs/2305.06721)

    本研究使用基于 Transformer 的 Albertina PT-* 模型进行了葡萄牙语的神经编码，创新性地提升了该语言在数字时代的技术准备水平，尤其是欧洲葡萄牙语和巴西的美洲葡萄牙语两个变种。

    

    本研究旨在推进葡萄牙语（PT）的神经编码，为该语言在数字时代的技术准备打下基础。我们开发了基于 Transformer 的 Albertina PT-* 基础模型，为其两个变种（葡萄牙的欧洲葡萄牙语（PT-PT）和巴西的美洲葡萄牙语（PT-BR））的神经编码创下了新的技术水平。我们使用一种强大的模型作为起点，即DeBERTa，并使用我们收集的PT-PT数据集和brWaC语料库对其进行预训练。我们通过对适用于葡萄牙语的著名下游语言处理任务进行评估，来评估Albertina和竞争模型的性能。 Albertina PT-PT和PT-BR版本均可免费分发，并在最宽松的许可以下运行于消费级硬件。

    To advance the neural encoding of Portuguese (PT), and a fortiori the technological preparation of this language for the digital age, we developed a Transformer-based foundation model that sets a new state of the art in this respect for two of its variants, namely European Portuguese from Portugal (PT-PT) and American Portuguese from Brazil (PT-BR).  To develop this encoder, which we named Albertina PT-*, a strong model was used as a starting point, DeBERTa, and its pre-training was done over data sets of Portuguese, namely over a data set we gathered for PT-PT and over the brWaC corpus for PT-BR. The performance of Albertina and competing models was assessed by evaluating them on prominent downstream language processing tasks adapted for Portuguese.  Both Albertina PT-PT and PT-BR versions are distributed free of charge and under the most permissive license possible and can be run on consumer-grade hardware, thus seeking to contribute to the advancement of research and innovation in l
    
[^24]: 评估ChatGPT的工作记忆容量

    Assessing Working Memory Capacity of ChatGPT. (arXiv:2305.03731v1 [cs.AI])

    [http://arxiv.org/abs/2305.03731](http://arxiv.org/abs/2305.03731)

    本文评估了最先进语言模型ChatGPT的工作记忆容量，结果显示其在N-back任务的行为表现与人类参与者相似，这为设计具有人类级认知能力的人工智能系统提供了关键洞察。

    

    工作记忆是人类智能和人工智能的关键方面，它作为信息临时存储和操作的工作空间。本文通过检查ChatGPT在N-back任务上的表现，调查了这一最先进语言模型的工作记忆容量。我们首先讨论了工作记忆对人类和人工智能的重要性，接着介绍了评估ChatGPT工作记忆容量的方法。研究比较了ChatGPT在言语和空间N- back任务上的行为表现与文献报道的人类参与者的表现，发现了显著的相似之处。我们的发现为设计具有人类级认知能力的人工智能系统的当前进展提供了关键洞察，并为通过人工智能模型理解人类工作记忆的未来努力提供了前景。

    Working memory is a critical aspect of both human intelligence and artificial intelligence (AI), serving as a workspace for the temporary storage and manipulation of information. This paper investigates working memory capacity of ChatGPT, a state-of-the-art language model, by examining its performance on N-back tasks. We begin by discussing the importance of working memory to humans and AI, followed by the methods employed to assess working memory capacity of ChatGPT. Our study compares behavioral performance of ChatGPT on verbal and spatial N-back tasks to that of human participants reported in the literature, revealing notable similarities. Our findings offer crucial insights into the current progress in designing AI systems with human-level cognitive abilities and hold promise for informing future endeavors aimed at enhancing AI working memory and understanding human working memory through AI models.
    
[^25]: RadAdapt：通过大型语言模型的轻量化领域自适应实现放射学报告摘要

    RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models. (arXiv:2305.01146v1 [cs.CL])

    [http://arxiv.org/abs/2305.01146](http://arxiv.org/abs/2305.01146)

    本研究重点研究了轻量化策略，通过在临床文本上进行预训练和在RRS示例上进行参数高效微调，实现适应大型语言模型进行放射性报告摘要（RRS）任务。并且该方法仅微调模型的0.32％的参数，提高了表现。研究结果强调了领域适应在RRS中的重要性，并为开发更好的放射性报告摘要模型提供了有价值的见解。

    

    本文系统地研究了轻量级策略，通过预训练（自然语言，生物医学文本，临床文本）和提示（零-shot、上下文学习）或参数高效微调（前缀微调，LoRA），来适应大型语言模型（LLMs）进行放射性报告摘要（RRS）任务。结果表明，最大程度地适应任务的方法是，通过在临床文本上预先训练，然后在RRS示例上进行参数高效微调。值得注意的是，这种方法仅微调模型的0.32％的参数，与端对端微调（100％的参数）形成对比。此外，在研究上下文示例和分布外（OOD）训练的影响后，我们进行了放射科医师读者研究和定性分析。我们的研究结果强调了领域适应在RRS中的重要性，并为开发更好的放射性报告摘要模型提供了有价值的见解。

    We systematically investigate lightweight strategies to adapt large language models (LLMs) for the task of radiology report summarization (RRS). Specifically, we focus on domain adaptation via pretraining (on natural language, biomedical text, and clinical text) and via prompting (zero-shot, in-context learning) or parameter-efficient fine-tuning (prefix tuning, LoRA). Our results on the MIMIC-III dataset consistently demonstrate best performance by maximally adapting to the task via pretraining on clinical text and parameter-efficient fine-tuning on RRS examples. Importantly, this method fine-tunes a mere 0.32% of parameters throughout the model, in contrast to end-to-end fine-tuning (100% of parameters). Additionally, we study the effect of in-context examples and out-of-distribution (OOD) training before concluding with a radiologist reader study and qualitative analysis. Our findings highlight the importance of domain adaptation in RRS and provide valuable insights toward developin
    
[^26]: 开发一种信任感感知的用户模拟器，用于统计学的主动式对话建模中的人工智能团队

    Development of a Trust-Aware User Simulator for Statistical Proactive Dialog Modeling in Human-AI Teams. (arXiv:2304.11913v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2304.11913](http://arxiv.org/abs/2304.11913)

    本文开发了一种用户模拟器来训练和测试主动对话策略，提供了一种探索和评估人工智能团队表现的适当主动策略的途径。

    

    近年来，人工智能团队的概念引起了越来越多的关注。为了实现人类和人工智能队友之间的有效协作，主动性对于紧密协调和有效沟通至关重要。然而，如何为基于人工智能的系统设计适当的主动性仍然是一个开放性问题和具有挑战性的主题。本文介绍了一个基于语料库的用户模拟器的开发，用于训练和测试主动式对话策略。该模拟器以有关主动式对话及其对用户信任度的知识为基础，模拟用户行为和个人信息，包括社会人口特征和人格特征。对比了两种不同的模拟方法，基于任务步骤的方法由于加强了顺序依赖模型，获得了更好的总体结果。这项研究为探索和评估在对话游戏环境中改善人工智能团队表现的适当主动策略提供了一个有前途的途径。

    The concept of a Human-AI team has gained increasing attention in recent years. For effective collaboration between humans and AI teammates, proactivity is crucial for close coordination and effective communication. However, the design of adequate proactivity for AI-based systems to support humans is still an open question and a challenging topic. In this paper, we present the development of a corpus-based user simulator for training and testing proactive dialog policies. The simulator incorporates informed knowledge about proactive dialog and its effect on user trust and simulates user behavior and personal information, including socio-demographic features and personality traits. Two different simulation approaches were compared, and a task-step-based approach yielded better overall results due to enhanced modeling of sequential dependencies. This research presents a promising avenue for exploring and evaluating appropriate proactive strategies in a dialog game setting for improving H
    
[^27]: 重访基于预训练语言模型的k-NN

    Revisiting k-NN for Pre-trained Language Models. (arXiv:2304.09058v1 [cs.CL])

    [http://arxiv.org/abs/2304.09058](http://arxiv.org/abs/2304.09058)

    本研究提出一种新方法，结合k-NN和预训练语言模型（PLMs）能够提高自然语言处理（NLP）的性能，并在多个基准数据集上得到验证。

    

    预训练语言模型（PLMs）作为参数化的急切学习器，已成为自然语言处理（NLP）当前范式的实际选择。与此形成对比的是，k-最近邻（k-NN）分类器作为延迟学习模型，倾向于减轻过拟合和孤立噪声。本文中我们重访了k-NN分类器，以增强基于PLMs的分类器。从方法层面上，我们提出采用文本表示的PLMs在两个步骤中采用k-NN：（1）利用k-NN作为先验知识来校准训练过程（2）线性插值k-NN预测的概率分布和PLMs分类器的概率分布。我们的方法核心是实现了k-NN校准训练，将预测结果作为训练过程中易于和难以学习的示例的指标。从应用场景多样性的角度出发，我们在各种基准数据集上进行了广泛的微调、提示微调范式和零样本任务设置的实验。我们的结果表明，结合k-NN可以在所有受到检查的设置中持续提高PLMs的性能，并且在所有受到考虑的设置中跑赢了基于普通PLMs的方法。

    Pre-trained Language Models (PLMs), as parametric-based eager learners, have become the de-facto choice for current paradigms of Natural Language Processing (NLP). In contrast, k-Nearest-Neighbor (k-NN) classifiers, as the lazy learning paradigm, tend to mitigate over-fitting and isolated noise. In this paper, we revisit k-NN classifiers for augmenting the PLMs-based classifiers. From the methodological level, we propose to adopt k-NN with textual representations of PLMs in two steps: (1) Utilize k-NN as prior knowledge to calibrate the training process. (2) Linearly interpolate the probability distribution predicted by k-NN with that of the PLMs' classifier. At the heart of our approach is the implementation of k-NN-calibrated training, which treats predicted results as indicators for easy versus hard examples during the training process. From the perspective of the diversity of application scenarios, we conduct extensive experiments on fine-tuning, prompt-tuning paradigms and zero-sh
    
[^28]: ASL Citizen: 一个推进独立手语识别的社区数据集

    ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition. (arXiv:2304.05934v1 [cs.CV])

    [http://arxiv.org/abs/2304.05934](http://arxiv.org/abs/2304.05934)

    ASL Citizen是目前最大的独立手语识别数据集，可用于手语字典检索，利用该数据集训练的机器学习分类器在度量标准上取得显著进展，例如在训练或验证中未出现的用户的视频上，实现了62％的准确性和90％的前10项检索召回率。

    

    手语被全球约7000万聋健人士用作主要语言。然而，大多数交流技术运作在口头和书面语言中，导致获取信息存在不公平。为了解决这个问题，我们发布了ASL Citizen，它是迄今为止最大的独立手语识别 (ISLR) 数据集，经过同意收集，包括52个手语者在各种环境中拍摄的2,731个不同手势的83,912个视频。我们建议将这个数据集用于美国手语 (ASL) 的手语字典检索，用户通过自己的网络摄像头演示手语，从字典中检索相匹配的手语。我们展示了利用我们的数据集对监督机器学习分类器进行训练，在与字典检索相关的度量标准上取得了显著进展，例如在训练或验证中未出现的用户的视频上，实现了62％的准确性和90％的前10项检索召回率。

    Sign languages are used as a primary language by approximately 70 million D/deaf people world-wide. However, most communication technologies operate in spoken and written languages, creating inequities in access. To help tackle this problem, we release ASL Citizen, the largest Isolated Sign Language Recognition (ISLR) dataset to date, collected with consent and containing 83,912 videos for 2,731 distinct signs filmed by 52 signers in a variety of environments. We propose that this dataset be used for sign language dictionary retrieval for American Sign Language (ASL), where a user demonstrates a sign to their own webcam with the aim of retrieving matching signs from a dictionary. We show that training supervised machine learning classifiers with our dataset greatly advances the state-of-the-art on metrics relevant for dictionary retrieval, achieving, for instance, 62% accuracy and a recall-at-10 of 90%, evaluated entirely on videos of users who are not present in the training or valida
    
[^29]: OpenAGI：当LLM遇到领域专家

    OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v1 [cs.AI])

    [http://arxiv.org/abs/2304.04370](http://arxiv.org/abs/2304.04370)

    基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。

    

    人类具有将基本技能组合成复杂技能以解决复杂任务的显著能力。这种能力对于人工智能同样重要，因此，我们断言，除了开发大型综合智能模型外，将不同领域专家模型应用于复杂任务解决能力同样关键，以在人工智能通用智能的追求中使其具备这种能力。最近的大型语言模型（LLM）的发展证明其具有出色的学习和推理能力，使它们成为选择、综合和执行外部模型以解决复杂任务的控制器的有前途的选择。在这个项目中，我们开发了一个名为OpenAGI的开源AGI研究平台，专门设计为提供复杂的多步骤任务，并配有任务特定的数据集、评估指标和各种可扩展模型。OpenAGI将复杂任务阐释为自然语言问答，旨在促进领域专家和语言模型之间的协同作用。

    Human intelligence has the remarkable ability to assemble basic skills into complex ones so as to solve complex tasks. This ability is equally important for Artificial Intelligence (AI), and thus, we assert that in addition to the development of large, comprehensive intelligent models, it is equally crucial to equip such models with the capability to harness various domain-specific expert models for complex task-solving in the pursuit of Artificial General Intelligence (AGI). Recent developments in Large Language Models (LLMs) have demonstrated remarkable learning and reasoning abilities, making them promising as a controller to select, synthesize, and execute external models to solve complex tasks. In this project, we develop OpenAGI, an open-source AGI research platform, specifically designed to offer complex, multi-step tasks and accompanied by task-specific datasets, evaluation metrics, and a diverse range of extensible models. OpenAGI formulates complex tasks as natural language q
    
[^30]: 迈向MoE部署：缓解混合专家（MoE）推理中的低效率

    Towards MoE Deployment: Mitigating Inefficiencies in Mixture-of-Expert (MoE) Inference. (arXiv:2303.06182v1 [cs.DC])

    [http://arxiv.org/abs/2303.06182](http://arxiv.org/abs/2303.06182)

    本文提出了三种优化技术来缓解混合专家（MoE）模型在推理时的低效率，包括动态门控、专家缓冲和专家负载平衡。这些技术可以显著提高执行时间和减少内存使用。

    This paper proposes three optimization techniques to mitigate inefficiencies in Mixture-of-Experts (MoE) models during inference, including dynamic gating, expert buffering, and expert load balancing. These techniques can significantly improve execution time and reduce memory usage.

    混合专家（MoE）模型最近在计算机视觉和自然语言处理的广泛任务中取得了最先进的性能。它们在训练期间有效地扩展了模型容量，同时增加的计算成本很小。然而，由于其庞大的模型大小和复杂的通信模式，部署这样的模型进行推理是困难的。在这项工作中，我们提供了两个MoE工作负载的特征化，即语言建模（LM）和机器翻译（MT），并确定了它们在部署时的低效率来源。我们提出了三种优化技术来缓解低效率的来源，即（1）动态门控，（2）专家缓冲和（3）专家负载平衡。我们展示了动态门控可以使LM的执行时间提高1.25-4倍，MT编码器提高2-5倍，MT解码器提高1.09-1.5倍。它还可以将LM的内存使用减少高达1.36倍，MT的内存使用减少高达1.1倍。

    Mixture-of-Experts (MoE) models have recently gained steam in achieving the state-of-the-art performance in a wide range of tasks in computer vision and natural language processing. They effectively expand the model capacity while incurring a minimal increase in computation cost during training. However, deploying such models for inference is difficult due to their large model size and complex communication pattern. In this work, we provide a characterization of two MoE workloads, namely Language Modeling (LM) and Machine Translation (MT) and identify their sources of inefficiencies at deployment.  We propose three optimization techniques to mitigate sources of inefficiencies, namely (1) Dynamic gating, (2) Expert Buffering, and (3) Expert load balancing. We show that dynamic gating improves execution time by 1.25-4$\times$ for LM, 2-5$\times$ for MT Encoder and 1.09-1.5$\times$ for MT Decoder. It also reduces memory usage by up to 1.36$\times$ for LM and up to 1.1$\times$ for MT. We f
    
[^31]: 通过AdapterFusion实现参数高效的模块化偏差修正

    Parameter-efficient Modularised Bias Mitigation via AdapterFusion. (arXiv:2302.06321v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.06321](http://arxiv.org/abs/2302.06321)

    本文提出了一个新的去偏差方法——DAM，它采用AdapterFusion概念，将偏差修正功能封装到独立的适配器中，在不影响核心模型的情况下，实现了按需的去偏差，可以有效降低模型的偏见问题。

    

    大型预训练语言模型存在社会偏见，并将这些偏见带给下游任务。当前的内部处理偏差修正方法（如对抗训练）通过更新模型参数来施加去偏差，从而将模型转移到新的、不可逆的去偏差状态。在本文中，我们提出了一种新颖的方法，开发出了独立的去偏差功能，与模型分离，可以按需集成到模型中，同时保持核心模型不变。借鉴多任务学习中的AdapterFusion概念，我们引入了DAM（使用适配器模块进行去偏差）——一种去偏差方法，首先将任意偏差修正功能封装到独立的适配器中，然后按需将它们添加到模型中，以实现公平性。我们在三种分类任务上进行了大量实验，保护属性为性别、种族和年龄。我们的结果表明，DAM改进或保持了模型的效果。

    Large pre-trained language models contain societal biases and carry along these biases to downstream tasks. Current in-processing bias mitigation approaches (like adversarial training) impose debiasing by updating a model's parameters, effectively transferring the model to a new, irreversible debiased state. In this work, we propose a novel approach to develop stand-alone debiasing functionalities separate from the model, which can be integrated into the model on-demand, while keeping the core model untouched. Drawing from the concept of AdapterFusion in multi-task learning, we introduce DAM (Debiasing with Adapter Modules) - a debiasing approach to first encapsulate arbitrary bias mitigation functionalities into separate adapters, and then add them to the model on-demand in order to deliver fairness qualities. We conduct a large set of experiments on three classification tasks with gender, race, and age as protected attributes. Our results show that DAM improves or maintains the effec
    
[^32]: MarioGPT: 通过大语言模型进行开放式文本关卡生成

    MarioGPT: Open-Ended Text2Level Generation through Large Language Models. (arXiv:2302.05981v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.05981](http://arxiv.org/abs/2302.05981)

    MarioGPT是第一个文本到超级马里奥兄弟游戏关卡的生成模型，通过大型语言模型实现开放式的、可控制的关卡生成。

    

    流程内容生成算法可以自动生成复杂数一致的环境。然而，使用流程内容生成方法生成反映特定意图和限制的有意义内容仍然具有挑战性。此外，许多流程内容生成算法缺乏以开放式方式生成内容的能力。最近，大型语言模型在许多不同领域都表现出了非常高的效率。这些训练有素的大型语言模型可以进行微调，重复使用信息并加速新任务的培训。在这项工作中，我们介绍了MarioGPT，这是一个经过优化的GPT2模型，用于生成基于瓷砖的游戏关卡，我们以超级马里奥兄弟的关卡为例。我们展示了MarioGPT不仅可以生成不同的游戏关卡，而且可以通过文本提示控制关卡生成，解决了当前PCG技术的主要挑战之一。据我们所知，MarioGPT是第一个文本到关卡模型。

    Procedural Content Generation (PCG) algorithms provide a technique to generate complex and diverse environments in an automated way. However, while generating content with PCG methods is often straightforward, generating meaningful content that reflects specific intentions and constraints remains challenging. Furthermore, many PCG algorithms lack the ability to generate content in an open-ended manner. Recently, Large Language Models (LLMs) have shown to be incredibly effective in many diverse domains. These trained LLMs can be fine-tuned, re-using information and accelerating training for new tasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to generate tile-based game levels, in our case Super Mario Bros levels. We show that MarioGPT can not only generate diverse levels, but can be text-prompted for controllable level generation, addressing one of the key challenges of current PCG techniques. As far as we know, MarioGPT is the first text-to-level model. We a
    
[^33]: 用于上下文学习的组合范例

    Compositional Exemplars for In-context Learning. (arXiv:2302.05698v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.05698](http://arxiv.org/abs/2302.05698)

    该论文提出了CEIL（Compositional Exemplars for In-context Learning）框架，利用决定性点过程（DPP）模型处理上下文示例选择问题，从而提高了大型预训练语言模型（LMs）进行上下文学习的性能。

    

    大型预训练语言模型已经表现出令人印象深刻的上下文学习能力，其中模型通过输入输出示例作为演示，在不进行任何参数更新的情况下学习执行看不见的任务。上下文学习的性能高度受到所选上下文示例的质量所支配。然而，以前的选择方法基本上是基于简单的启发式，导致性能次优。在这项工作中，我们将上下文示例选择形式化为子集选择问题。我们提出CEIL（Compositional Exemplars for In-context Learning），它通过决定性点过程（DPP）对所给输入和上下文示例之间的交互进行建模，并通过精心设计的对比学习目标进行优化，从而获得来自LM的偏好。我们在来自7个不同自然语言处理任务的12个分类和生成数据集上验证了CEIL，包括情感分析、释义检测、自然语言生成等任务。

    Large pretrained language models (LMs) have shown impressive In-Context Learning (ICL) ability, where the model learns to do an unseen task via a prompt consisting of input-output examples as the demonstration, without any parameter updates. The performance of ICL is highly dominated by the quality of the selected in-context examples. However, previous selection methods are mostly based on simple heuristics, leading to sub-optimal performance. In this work, we formulate in-context example selection as a subset selection problem. We propose CEIL (Compositional Exemplars for In-context Learning), which is instantiated by Determinantal Point Processes (DPPs) to model the interaction between the given input and in-context examples, and optimized through a carefully-designed contrastive learning objective to obtain preference from LMs. We validate CEIL on 12 classification and generation datasets from 7 distinct NLP tasks, including sentiment analysis, paraphrase detection, natural language
    
[^34]: EXIF作为一种语言：学习图像与相机元数据之间的交叉模态关联

    EXIF as Language: Learning Cross-Modal Associations Between Images and Camera Metadata. (arXiv:2301.04647v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.04647](http://arxiv.org/abs/2301.04647)

    本文通过学习图像和相机元数据之间的交叉模态关联提取相机信息，并使用得到的特征成功实现拼接图像区域的"零样本"定位。

    

    本文旨在学习一个视觉表示，从而提取与所记录的照片相关的相机信息。为此，我们在图像块和自动插入到图像文件中的EXIF元数据之间训练了一个多模态嵌入。我们的模型通过将元数据转换为文本，然后使用transformer进行处理来表示此元数据。我们学习的特征在下游图像取证和校准任务上明显优于其他自监督和有监督特征。特别地，我们成功地通过对图像内所有块的视觉嵌入进行聚类来实现"零样本"的拼接图像区域定位。

    We learn a visual representation that captures information about the camera that recorded a given photo. To do this, we train a multimodal embedding between image patches and the EXIF metadata that cameras automatically insert into image files. Our model represents this metadata by simply converting it to text and then processing it with a transformer. The features that we learn significantly outperform other self-supervised and supervised features on downstream image forensics and calibration tasks. In particular, we successfully localize spliced image regions "zero shot" by clustering the visual embeddings for all of the patches within an image.
    
[^35]: MULTI3NLU++：一种用于任务导向对话中的自然语言理解的多语言、多意图、多域数据集

    MULTI3NLU++: A Multilingual, Multi-Intent, Multi-Domain Dataset for Natural Language Understanding in Task-Oriented Dialogue. (arXiv:2212.10455v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10455](http://arxiv.org/abs/2212.10455)

    MULTI3NLU++是一个多语言、多意图、多域数据集。其中包含手动翻译的多种高、中、低资源语言和两个领域。该数据集能够帮助衡量任务导向对话系统的现实性能。

    

    任务导向对话系统已经被广泛地应用于许多行业中，因为它们能够提供更有效的客户支持。这些系统通常是为单个领域或语言构建的，并且在这些领域之外的推广能力很差。为了同时支持跨多种语言和领域的任务导向对话中的自然语言理解工作，我们构建了 MULTI3NLU++，这是一个多语言、多意图、多域数据集。MULTI3NLU++ 将仅限于英语的 NLU++ 数据集扩展到多种高、中、低资源语言（西班牙语、马拉地语、土耳其语和阿姆哈拉语）以及两个领域（银行和酒店）中的手动翻译。由于 MULTI3NLU++ 具有多意图的属性，因此它代表了复杂和自然的用户目标，从而使我们能够在世界语言中的各种领域中衡量 TOD 系统的现实性能。我们使用 MULTI3NLU++ 来基准测试用于意图检测和槽位标记的 NLU 任务的最先进的多语言模型。

    Task-oriented dialogue (TOD) systems have been widely deployed in many industries as they deliver more efficient customer support. These systems are typically constructed for a single domain or language and do not generalise well beyond this. To support work on Natural Language Understanding (NLU) in TOD across multiple languages and domains simultaneously, we constructed MULTI3NLU++, a multilingual, multi-intent, multi-domain dataset. MULTI3NLU++ extends the English only NLU++ dataset to include manual translations into a range of high, medium, and low resource languages (Spanish, Marathi, Turkish and Amharic), in two domains (BANKING and HOTELS). Because of its multi-intent property, MULTI3NLU++ represents complex and natural user goals, and therefore allows us to measure the realistic performance of TOD systems in a varied set of the world's languages. We use MULTI3NLU++ to benchmark state-of-the-art multilingual models for the NLU tasks of intent detection and slot labelling for TO
    
[^36]: 机器翻译度量的外在评估

    Extrinsic Evaluation of Machine Translation Metrics. (arXiv:2212.10297v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10297](http://arxiv.org/abs/2212.10297)

    论文研究了机器翻译度量在大型平台和下游任务中的可靠性，发现某些度量在句子级别上表现不佳且其有用性与下游任务有关。

    

    自动机器翻译度量通常用于在较大的测试集上比较机器翻译系统的翻译质量（系统级评估），但是，句子级别上自动度量是否能可靠地区分好翻译和差翻译仍不清楚。本文调查了在具有下游任务的大型平台上放置机器翻译组件以检测其成功的MT度量的有用性。我们在三个跨语言下游任务（对话状态跟踪，问题回答和语义解析）上评估了最广泛使用的MT量度（chrF，COMET，BERTScore等）的分段性能。对于每个任务，我们仅能访问单语种任务特定模型。我们计算在Translate-Test设置下，度量预测好/坏翻译能力与最终任务成功/失败之间的相关性。我们的实验表明，尽管某些度量在系统级评估中表现良好，但在分段评估中可能不可靠。此外，某些度量的有用性取决于下游任务。

    Automatic machine translation (MT) metrics are widely used to distinguish the translation qualities of machine translation systems across relatively large test sets (system-level evaluation). However, it is unclear if automatic metrics are reliable at distinguishing good translations from bad translations at the sentence level (segment-level evaluation). In this paper, we investigate how useful MT metrics are at detecting the success of a machine translation component when placed in a larger platform with a downstream task. We evaluate the segment-level performance of the most widely used MT metrics (chrF, COMET, BERTScore, etc.) on three downstream cross-lingual tasks (dialogue state tracking, question answering, and semantic parsing). For each task, we only have access to a monolingual task-specific model. We calculate the correlation between the metric's ability to predict a good/bad translation with the success/failure on the final task for the Translate-Test setup. Our experiments
    
[^37]: MASTER:多任务预训练的瓶颈掩蔽自编码器比密集型检索器更好

    MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are Better Dense Retrievers. (arXiv:2212.07841v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07841](http://arxiv.org/abs/2212.07841)

    本文提出了一个名为MASTER的多任务预训练模型，利用瓶颈掩蔽自编码器统一各种预训练任务，并将其集成到一个模型中。该模型在两个广泛使用的数据集上的实验表明，相比同等模型大小和预训练资源的最先进密集检索模型，MASTER表现更好。

    

    现有的密集检索方法中，预训练的Transformer（如BERT）通常用于参数初始化，最近的研究正在探索更有效的预训练任务，以进一步提高密集向量的质量。虽然已经提出了各种新颖而有效的任务，但它们不同的输入格式和学习目标使它们难以被整合起来共同提高模型性能。本文旨在将各种预训练任务统一成瓶颈掩蔽自编码器，将它们整合到一个多任务预训练模型中，名为MASTER。具体来说，MASTER利用共享编码器多解码器架构，可以构造表示瓶颈，将跨各种任务的丰富语义信息压缩成密集向量。基于此，我们整合了三种代表性的预训练任务：破损段落恢复、相关段落恢复和PLMs输出恢复，以同时进行转录、索引和QA。我们在两个广泛使用的数据集上的实验表明，MASTER在相同的模型大小和预训练资源下优于最先进的密集检索模型，表明了将各种预训练任务以统一的格式集成的有效性。

    Pre-trained Transformers (\eg BERT) have been commonly used in existing dense retrieval methods for parameter initialization, and recent studies are exploring more effective pre-training tasks for further improving the quality of dense vectors. Although various novel and effective tasks have been proposed, their different input formats and learning objectives make them hard to be integrated for jointly improving the model performance. In this work, we aim to unify a variety of pre-training tasks into the bottlenecked masked autoencoder manner, and integrate them into a multi-task pre-trained model, namely MASTER. Concretely, MASTER utilizes a shared-encoder multi-decoder architecture that can construct a representation bottleneck to compress the abundant semantic information across tasks into dense vectors. Based on it, we integrate three types of representative pre-training tasks: corrupted passages recovering, related passages recovering and PLMs outputs recovering, to characterize t
    
[^38]: MoNET：通过噪声增强的训练解决对话状态跟踪中的状态惯性问题

    MoNET: Tackle State Momentum via Noise-Enhanced Training for Dialogue State Tracking. (arXiv:2211.05503v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.05503](http://arxiv.org/abs/2211.05503)

    本研究提出了MoNET，通过噪声增强训练解决了对话状态跟踪中的状态惯性问题，提高了模型修正槽值的能力。

    

    对话状态跟踪（DST）旨在将对话历史转换为包含槽-值对的对话状态。作为所有历史信息的结构化概括信息，通常采用上一轮的对话状态作为DST模型预测当前状态的输入。但是，这些模型往往保持预测的槽值不变，这在本文中被定义为状态惯性。为了解决这个问题，我们提出了MoNET，在噪声增强训练的帮助下解决状态惯性问题。具体而言，我们使用替换一些槽值来噪声化每轮的训练数据中的上一个状态。然后，将噪声化的上一个状态作为输入，预测当前状态，从而改善模型更新和修正槽值的能力。此外，我们设计了对比上下文匹配框架来缩小...

    Dialogue state tracking (DST) aims to convert the dialogue history into dialogue states which consist of slot-value pairs. As condensed structural information memorizing all history information, the dialogue state in the last turn is typically adopted as the input for predicting the current state by DST models. However, these models tend to keep the predicted slot values unchanged, which is defined as state momentum in this paper. Specifically, the models struggle to update slot values that need to be changed and correct wrongly predicted slot values in the last turn. To this end, we propose MoNET to tackle state momentum via noise-enhanced training. First, the previous state of each turn in the training data is noised via replacing some of its slot values. Then, the noised previous state is used as the input to learn to predict the current state, improving the model's ability to update and correct slot values. Furthermore, a contrastive context matching framework is designed to narrow
    
[^39]: 数据集构建的偏见：社会偏见基准的问题

    The Tail Wagging the Dog: Dataset Construction Biases of Social Bias Benchmarks. (arXiv:2210.10040v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10040](http://arxiv.org/abs/2210.10040)

    研究揭示了社会偏见基准中数据集构建偏见可能对结果造成了重要影响，需要更严谨的社会偏见度量方法。

    

    我们能否可靠地相信从社会偏见基准得到的分数是对给定语言模型中存在的问题社会偏见的忠实指标？本文通过将社会偏见与来源于数据集构建过程中的非社会偏见进行对比研究这一问题。为此，我们根据无害的修改（如释义或随机抽样）实际模拟了给定基准的各种替代结构，这些修改保持其社会偏见的本质。在两个众所周知的社会偏见基准（Winogender和BiasNLI）中，我们观察到这些浅显的修改对各种模型中导致的偏见程度产生了惊人的影响。我们希望这些令人不安的观察结果能够激发更严谨的社会偏见度量方法。

    How reliably can we trust the scores obtained from social bias benchmarks as faithful indicators of problematic social biases in a given language model? In this work, we study this question by contrasting social biases with non-social biases stemming from choices made during dataset construction that might not even be discernible to the human eye. To do so, we empirically simulate various alternative constructions for a given benchmark based on innocuous modifications (such as paraphrasing or random-sampling) that maintain the essence of their social bias. On two well-known social bias benchmarks (Winogender and BiasNLI) we observe that these shallow modifications have a surprising effect on the resulting degree of bias across various models. We hope these troubling observations motivate more robust measures of social biases.
    
[^40]: 带有实证文本表征的语义特征的文本蕴涵识别

    Textual Entailment Recognition with Semantic Features from Empirical Text Representation. (arXiv:2210.09723v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.09723](http://arxiv.org/abs/2210.09723)

    本文提出了一种利用实验证据的文本表征和语义特征的新方法，通过元素曼哈顿距离向量特征识别文本-假设之间的蕴涵关系，并在基准数据集上实现了显著的F1分数提高。

    

    文本蕴涵识别是自然语言理解中基本的任务之一。在自动识别文本蕴含之前，理解句子的含义是必要的前提。如果前提为真，则文本蕴涵假设也为真。经典的方法通常利用来自词嵌入的每个单词的特征值来表示句子。本文提出了一种新的方法，以识别文本和假设之间的蕴含关系，并引入了一个新的实证基于阈值的语义文本表征。我们采用一个基于元素的曼哈顿距离向量特征，可以识别文本-假设对之间的语义蕴涵关系。我们对基准蕴涵分类(SICK-RTE)数据集进行了几项实验。我们使用我们提出的方法训练了几个机器学习(ML)模型，并将它们的性能与经典的和最先进的模型进行了比较。我们提出的方法在F1分数方面显著优于经典模型，并在大多数最先进的模型方面表现出色。

    Textual entailment recognition is one of the basic natural language understanding(NLU) tasks. Understanding the meaning of sentences is a prerequisite before applying any natural language processing(NLP) techniques to automatically recognize the textual entailment. A text entails a hypothesis if and only if the true value of the hypothesis follows the text. Classical approaches generally utilize the feature value of each word from word embedding to represent the sentences. In this paper, we propose a novel approach to identifying the textual entailment relationship between text and hypothesis, thereby introducing a new semantic feature focusing on empirical threshold-based semantic text representation. We employ an element-wise Manhattan distance vector-based feature that can identify the semantic entailment relationship between the text-hypothesis pair. We carried out several experiments on a benchmark entailment classification(SICK-RTE) dataset. We train several machine learning(ML) 
    
[^41]: PromptCast：一种新的基于提示的时间序列预测范式

    PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting. (arXiv:2210.08964v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2210.08964](http://arxiv.org/abs/2210.08964)

    提出了一种新的时间序列预测范式——基于提示的时间序列预测（PromptCast），将数字输入和输出转化为提示，并以句子到句子的方式提出预测任务，可以直接应用于语言模型。

    

    本文提出了一种新的时间序列预测范式——基于提示的时间序列预测（PromptCast）。在这种新的任务中，将原来的数字输入和输出转化为提示，并以句子到句子的方式提出预测任务，使得语言模型可以直接应用于预测的目的。为了支持和促进这个任务的研究，我们还提出了一个大规模的数据集（PISA）。

    This paper presents a new perspective on time series forecasting. In existing time series forecasting methods, the models take a sequence of numerical values as input and yield numerical values as output. The existing SOTA models are largely based on the Transformer architecture, modified with multiple encoding mechanisms to incorporate the context and semantics around the historical data. Inspired by the successes of pre-trained language foundation models, we pose a question about whether these models can also be adapted to solve time-series forecasting. Thus, we propose a new forecasting paradigm: prompt-based time series forecasting (PromptCast). In this novel task, the numerical input and output are transformed into prompts and the forecasting task is framed in a sentence-to-sentence manner, making it possible to directly apply language models for forecasting purposes. To support and facilitate the research of this task, we also present a large-scale dataset (PISA) that includes th
    
[^42]: 道德模仿：大型语言模型生成适应政治身份的道德辩护

    Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity. (arXiv:2209.12106v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.12106](http://arxiv.org/abs/2209.12106)

    本研究证明大型语言模型表现出道德模仿能力，会根据政治身份生成反映相应道德偏见的文本。

    

    大型语言模型(LLMs)在生成流畅文本方面表现出惊人能力，但也倾向于重复不良社会偏见。本研究调查了LLMs是否会复制与美国政治团体相关的道德偏见，即所述的更广泛的道德模仿能力。该假设在基于Transformer的LLMs家族中的GPT-3 / 3.5和OPT中得到了探讨。使用道德基础理论工具，表明这些LLMs确实是道德模仿者。当以自由主义或保守主义政治身份为提示时，模型会生成反映相应道德偏见的文本。本研究还探讨了道德模仿与模型大小的关系，以及人类和LLM道德用语的相似性。

    Large Language Models (LLMs) have demonstrated impressive capabilities in generating fluent text, as well as tendencies to reproduce undesirable social biases. This study investigates whether LLMs reproduce the moral biases associated with political groups in the United States, an instance of a broader capability herein termed moral mimicry. This hypothesis is explored in the GPT-3/3.5 and OPT families of Transformer-based LLMs. Using tools from Moral Foundations Theory, it is shown that these LLMs are indeed moral mimics. When prompted with a liberal or conservative political identity, the models generate text reflecting corresponding moral biases. This study also explores the relationship between moral mimicry and model size, and similarity between human and LLM moral word use.
    
[^43]: 提示作为探测器：利用语言模型进行知识库构建

    Prompting as Probing: Using Language Models for Knowledge Base Construction. (arXiv:2208.11057v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.11057](http://arxiv.org/abs/2208.11057)

    本文介绍了一种利用语言模型进行知识库构建的方法，该方法采用了多种提示技术，手动提示策略的编制至关重要，并且必须鼓励语言模型给出不同长度的答案集，特别是包括空答案集。实体别名字典可以提高语言模型的得分。

    

    语言模型已经被证明在各种下游应用中都很有用，例如摘要、翻译、问答和文本分类。由于它们可以存储大量信息，因此语言模型正在成为人工智能中越来越重要的工具。本文介绍了ProP（提示作为探测器），它利用OpenAI在2020年提出的大型语言模型GPT-3来执行知识库构建任务。ProP采用多步骤方法，结合各种提示技术来实现这一目标。我们的结果表明，手动提示策略的编制至关重要；必须鼓励语言模型给出不同长度的答案集，特别是包括空答案集；真/假问题是增加语言模型生成的建议的准确性的有用方法；语言模型的大小是一个至关重要的因素；实体别名字典可以提高语言模型的得分。

    Language Models (LMs) have proven to be useful in various downstream applications, such as summarisation, translation, question answering and text classification. LMs are becoming increasingly important tools in Artificial Intelligence, because of the vast quantity of information they can store. In this work, we present ProP (Prompting as Probing), which utilizes GPT-3, a large Language Model originally proposed by OpenAI in 2020, to perform the task of Knowledge Base Construction (KBC). ProP implements a multi-step approach that combines a variety of prompting techniques to achieve this. Our results show that manual prompt curation is essential, that the LM must be encouraged to give answer sets of variable lengths, in particular including empty answer sets, that true/false questions are a useful device to increase precision on suggestions generated by the LM, that the size of the LM is a crucial factor, and that a dictionary of entity aliases improves the LM score. Our evaluation stu
    
[^44]: 基于Transformer的大语料库语义相似度分析的认知研究

    A Cognitive Study on Semantic Similarity Analysis of Large Corpora: A Transformer-based Approach. (arXiv:2207.11716v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.11716](http://arxiv.org/abs/2207.11716)

    本文通过使用Transformer在U.S Patent Phrase to Phrase Matching Dataset上进行语义相似度分析，提高了算法效率，达到了令人满意的结果。

    

    语义相似度分析和建模是当今自然语言处理许多先驱应用中基本认可的任务。由于顺序模式识别的感知，许多神经网络（如RNN和LSTM）在语义相似度建模方面取得了令人满意的结果。但是，由于它们无法以非顺序方式处理信息，因此这些解决方案被认为效率低下，从而导致上下文提取不当。Transformer因其非顺序数据处理和自我关注等优势而成为最先进的架构。本文使用传统和基于transformer的技术对美国专利短语进行语义相似度分析和建模。我们对四种不同版本的解码增强BERT-DeBERTa进行实验，并通过K折交叉验证来提高其性能。实验结果证明了我们的方法的有效性。

    Semantic similarity analysis and modeling is a fundamentally acclaimed task in many pioneering applications of natural language processing today. Owing to the sensation of sequential pattern recognition, many neural networks like RNNs and LSTMs have achieved satisfactory results in semantic similarity modeling. However, these solutions are considered inefficient due to their inability to process information in a non-sequential manner, thus leading to the improper extraction of context. Transformers function as the state-of-the-art architecture due to their advantages like non-sequential data processing and self-attention. In this paper, we perform semantic similarity analysis and modeling on the U.S Patent Phrase to Phrase Matching Dataset using both traditional and transformer-based techniques. We experiment upon four different variants of the Decoding Enhanced BERT - DeBERTa and enhance its performance by performing K-Fold Cross-Validation. The experimental results demonstrate our me
    
[^45]: 探测分类器对于概念去除和检测不可靠

    Probing Classifiers are Unreliable for Concept Removal and Detection. (arXiv:2207.04153v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.04153](http://arxiv.org/abs/2207.04153)

    本文研究了在文本数据上神经网络模型中的不良概念去除。对于现有的后期和对抗性方法，本文理论和实证分析表明其依赖的探测分类器可能使用非概念特征，导致无法完全去除不需要的概念。我们提出了一种直接学习从模型的表示中去除概念的方法，实验结果表明其优于最先进的后期和对抗性方法。

    

    在文本数据上训练的神经网络模型被发现在其表示中编码了不良的语言或敏感概念，移除这些概念是不容易的，因为概念、文本输入和学习到的表示之间存在复杂的关系。最近的研究提出了后期和对抗性方法来从模型的表示中去除这些不需要的概念。通过广泛的理论和实证分析，我们表明这些方法可能是适得其反的：它们不能完全去除概念，而在最糟糕的情况下可能会破坏所有任务相关的特征。原因是这些方法依赖于一个探测分类器作为概念的代理。即使在概念相关特征在表示空间中就可以提供100%准确性的最有利条件下学习探测分类器，我们证明探测分类器很可能会使用非概念特征，因此后期或对抗性处理方法将不能完全去除不需要的概念。我们提出一种替代方法，通过在损失函数中训练正则化项来直接学习从模型表示中去除概念。我们的实验表明，这种方法在去除概念的同时保留任务相关特征方面优于最先进的后期和对抗性方法。

    Neural network models trained on text data have been found to encode undesirable linguistic or sensitive concepts in their representation. Removing such concepts is non-trivial because of a complex relationship between the concept, text input, and the learnt representation. Recent work has proposed post-hoc and adversarial methods to remove such unwanted concepts from a model's representation. Through an extensive theoretical and empirical analysis, we show that these methods can be counter-productive: they are unable to remove the concepts entirely, and in the worst case may end up destroying all task-relevant features. The reason is the methods' reliance on a probing classifier as a proxy for the concept. Even under the most favorable conditions for learning a probing classifier when a concept's relevant features in representation space alone can provide 100% accuracy, we prove that a probing classifier is likely to use non-concept features and thus post-hoc or adversarial methods wi
    
[^46]: 多方位多语言与跨语言的议会演讲分析

    Multi-aspect Multilingual and Cross-lingual Parliamentary Speech Analysis. (arXiv:2207.01054v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.01054](http://arxiv.org/abs/2207.01054)

    本研究使用先进的自然语言处理方法，对2017年至2020年间保加利亚、捷克、法国、斯洛文尼亚、西班牙和英国六个国家的议会记录进行了联合和比较分析。结果显示出了这些国家之间的差异和共同点。

    

    议会和立法辩论记录提供了有关选定政治家意见、立场和政策偏好的有价值的见解。它们对政治和社会科学以及语言学和自然语言处理（NLP）研究非常有趣。虽然现有的研究研究了个别的议会，但我们将先进的NLP方法应用于对2017年至2020年期间六个国家议会（保加利亚、捷克、法国、斯洛文尼亚、西班牙和英国）进行联合和比较分析。我们分析了ParlaMint数据集收集的记录中的情感和情绪，并评估是否可以从演讲中检测到发言者的年龄、性别和政治倾向。研究结果显示，这些分析国家之间有一些共同点和许多令人惊讶的差异。

    Parliamentary and legislative debate transcripts provide informative insight into elected politicians' opinions, positions, and policy preferences. They are interesting for political and social sciences as well as linguistics and natural language processing (NLP) research. While existing research studied individual parliaments, we apply advanced NLP methods to a joint and comparative analysis of six national parliaments (Bulgarian, Czech, French, Slovene, Spanish, and United Kingdom) between 2017 and 2020. We analyze emotions and sentiment in the transcripts from the ParlaMint dataset collection and assess if the age, gender, and political orientation of speakers can be detected from their speeches. The results show some commonalities and many surprising differences among the analyzed countries.
    
[^47]: 跨语言AMR Aligner: 重点关注交叉注意力

    Cross-lingual AMR Aligner: Paying Attention to Cross-Attention. (arXiv:2206.07587v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.07587](http://arxiv.org/abs/2206.07587)

    本文提出了一种跨语言AMR图对齐器，采用现代Transformer解析器编码对齐信息，避免使用英语特定规则或EM算法，同时提出一种引导监督方法并在多语言语料库上实现了最先进的结果。

    

    本文介绍了一种新颖的AMR图对齐器，可以跨越多种语言以扩展其规模，因此能够对不同语言的句子中的单元和跨度进行对齐。我们的方法利用基于Transformer的现代解析器，在其交叉注意力权重中固有地编码对齐信息，从而允许我们在解析过程中提取此信息。这消除了以前方法中使用的英语特定规则或期望最大化(EM)算法的需要。此外，我们提出了一种使用对齐的引导监督方法来进一步增强我们的对齐器性能。我们在AMR对齐基准测试中获得了最先进的结果，并展示了我们的对齐器跨多种语言获得这些结果的能力。我们的代码将在 \href{https://www.github.com/Babelscape/AMR-alignment}{github.com/Babelscape/AMR-alignment} 上公开提供。

    This paper introduces a novel aligner for Abstract Meaning Representation (AMR) graphs that can scale cross-lingually, and is thus capable of aligning units and spans in sentences of different languages. Our approach leverages modern Transformer-based parsers, which inherently encode alignment information in their cross-attention weights, allowing us to extract this information during parsing. This eliminates the need for English-specific rules or the Expectation Maximization (EM) algorithm that have been used in previous approaches. In addition, we propose a guided supervised method using alignment to further enhance the performance of our aligner. We achieve state-of-the-art results in the benchmarks for AMR alignment and demonstrate our aligner's ability to obtain them across multiple languages. Our code will be available at \href{https://www.github.com/Babelscape/AMR-alignment}{github.com/Babelscape/AMR-alignment}.
    
[^48]: 视觉-语音自监督模型中的词语发现

    Word Discovery in Visually Grounded, Self-Supervised Speech Models. (arXiv:2203.15081v5 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2203.15081](http://arxiv.org/abs/2203.15081)

    这篇论文介绍了一种基于图像-语音联合训练的自监督模型，在模型训练后实现了自动词语分割和聚类的能力，并在两个任务中表现优异。

    

    我们提出了一种基于图像-语音联合训练的自监督模型，能够实现词语的自动分割和聚类，并在 Buckeye 词分割和 ZeroSpeech 任务中展现了与当前已发表的方法相当的甚至更好的表现。实验表明，这种能力并未出现在基本的 HuBERT 和 wav2vec2.0 模型中，视觉联结任务是我们观察到的词语发现能力的重要组成部分。

    We present a method for visually-grounded spoken term discovery. After training either a HuBERT or wav2vec2.0 model to associate spoken captions with natural images, we show that powerful word segmentation and clustering capability emerges within the model's self-attention heads. Our experiments reveal that this ability is not present to nearly the same extent in the base HuBERT and wav2vec2.0 models, suggesting that the visual grounding task is a crucial component of the word discovery capability we observe. We also evaluate our method on the Buckeye word segmentation and ZeroSpeech spoken term discovery tasks, where we perform on par with or better than currently published methods on several metrics. Code and model weights are available at https://github.com/jasonppy/word-discovery.
    
[^49]: 请求对话的错误纠正和提取

    Error correction and extraction in request dialogs. (arXiv:2004.04243v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2004.04243](http://arxiv.org/abs/2004.04243)

    该论文提出了一种对话系统实用组件，可自动检测和修正用户发出的请求信息中的错误，并将修正信息进行提取对，以实现学习和避免重复开发的优势。该方法适用于多种语序列标签、序列到序列和序列分类等情形。

    

    我们提出了一种对话系统实用组件，可以获取用户的最后两个话语，并检测最后一句话是否是对第二句话的错误纠正。如果是，则根据最后一句话中的错误纠正来纠正第二句话。此外，所提出的组件输出了被修复和修复体的提取对。这个组件提供了两个优点，一是学习纠正的概念以避免为每个新域收集纠正，二是提取被修复和修复对，从而提供学习的可能性。对于错误纠正，我们提出了一种序列标签和两种序列到序列方法。对于错误纠正检测，这三种错误纠正方法也可以被用来，并且我们还提出了一种序列分类方法。一个错误纠正检测和一个错误纠正方法可以组合成一个流水线，或者错误纠正方法可以被分别使用。

    We propose a dialog system utility component that gets the two last utterances of a user and can detect whether the last utterance is an error correction of the second last utterance. If yes, it corrects the second last utterance according to the error correction in the last utterance. In addition, the proposed component outputs the extracted pairs of reparandum and repair entity. This component offers two advantages, learning the concept of corrections to avoid collecting corrections for every new domain and extracting reparandum and repair pairs, which offers the possibility to learn out of it.  For the error correction one sequence labeling and two sequence to sequence approaches are presented. For the error correction detection these three error correction approaches can also be used and in addition, we present a sequence classification approach. One error correction detection and one error correction approach can be combined to a pipeline or the error correction approaches can be 
    

