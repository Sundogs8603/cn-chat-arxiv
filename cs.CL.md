# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Task Oriented Dialogue as a Catalyst for Self-Supervised Automatic Speech Recognition.](http://arxiv.org/abs/2401.02417) | 本研究引入了一种对话对比学习方法，用于对自动语音识别模型进行自监督微调，以改善低质量语音识别结果导致的自然语言理解应用的失败。实验证明，这种方法在任务导向的对话数据集上可以将ASR模型的性能提高达到19.2%。 |
| [^2] | [LLaMA Pro: Progressive LLaMA with Block Expansion.](http://arxiv.org/abs/2401.02415) | 本论文提出了一种新型的LLMs后处理方法，通过扩展Transformer模块并使用新的语料库进行调整，有效地提高了模型知识，而不会发生灾难性遗忘。在代码和数学领域的实验结果表明，LLaMA Pro是一种功能强大且适用于通用任务、编程和数学的基础模型，同时在各种基准测试中取得了先进的性能，展示了智能体推理和解决多样化任务的潜力。 |
| [^3] | [LLM Augmented LLMs: Expanding Capabilities through Composition.](http://arxiv.org/abs/2401.02412) | 本文提出了CALM方法，通过组合现有的基础模型和更具体的模型，使用交叉注意力来增强模型的表示并实现新的能力。CALM可以通过“重用”现有模型和一些额外的参数和数据来扩展新任务上的模型规模，并且保留现有模型的功能。 |
| [^4] | [TinyLlama: An Open-Source Small Language Model.](http://arxiv.org/abs/2401.02385) | TinyLlama是一个开源的小型语言模型，基于Llama 2的架构和分词器，利用各种先进技术实现了更好的计算效率。尽管规模较小，但在下游任务中表现出色，明显优于其他类似规模的开源语言模型。 |
| [^5] | [SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded Entity Retrieval.](http://arxiv.org/abs/2401.02369) | 本研究提出了一种在临床摘要中使用句子级规划并通过嵌入式实体检索的方法，以提高摘要的准确性和实用性。 |
| [^6] | [Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models.](http://arxiv.org/abs/2401.02333) | 本研究提出了一种创新的方法，通过上下文化表格数据来提高 RAG 系统中处理复杂表格查询的准确性，提高了摘要的效率。 |
| [^7] | [LLaVA-$\phi$: Efficient Multi-Modal Assistant with Small Language Model.](http://arxiv.org/abs/2401.02330) | LLaVA-$\phi$是一种高效的多模态助手，使用小型语言模型Phi-2来促进多模态对话。即使具有较少的参数，它也能有效地融合文本和视觉元素，并在各种任务中表现出色。它为时间敏感的环境和需要实时交互的系统开辟了新的应用途径。 |
| [^8] | [Are LLMs Robust for Spoken Dialogues?.](http://arxiv.org/abs/2401.02297) | 本文评估了LLMs在口语任务导向对话中的性能，并报告了回复生成和对话状态跟踪两个子任务中的模型表现。由于缺乏适当的口语对话数据集，我们使用自动语音识别引擎转录了口语对话的开发集，并模拟了ASR错误以进行评估。 |
| [^9] | [Rethinking Response Evaluation from Interlocutor's Eye for Open-Domain Dialogue Systems.](http://arxiv.org/abs/2401.02256) | 本研究重新考虑了从对话参与者的角度对开放域对话系统进行响应评估的问题，并发现了对话参与者意识和对话连贯性在自动评估中的关键作用。 |
| [^10] | [L3Cube-IndicNews: News-based Short Text and Long Document Classification Datasets in Indic Languages.](http://arxiv.org/abs/2401.02254) | L3Cube-IndicNews是一个面向印度语系的多语种文本分类数据集，包括短标题、长文档和长段落三个数据集。它提供了10种印度语言的新闻文章，每个数据集包含10个或更多类别的文章。这个数据集可以用于深入分析和评估。 |
| [^11] | [Joint Multi-Facts Reasoning Network For Complex Temporal Question Answering Over Knowledge Graph.](http://arxiv.org/abs/2401.02212) | 本研究提出了联合多事实推理网络（JMFRN）用于复杂时态问题在知识图上的问答，通过聚合实体和时间戳信息来准确回答复杂时态问题。 |
| [^12] | [DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models.](http://arxiv.org/abs/2401.02208) | DIALIGHT是一个用于开发和评估多语言的面向任务的对话系统的工具包，通过对预训练语言模型进行微调和利用大型语言模型的零-shot和上下文学习能力，可以进行系统化的评估和比较。研究发现，PLM微调可以提高准确性和连贯性，而LLM系统在产生多样化和受欢迎的回复方面表现出色，但需要解决LLM在遵循任务特定指令和生成多语言输出方面的挑战。 |
| [^13] | [Location Aware Modular Biencoder for Tourism Question Answering.](http://arxiv.org/abs/2401.02187) | 提出了一种位置感知模块化双编码器来回答真实世界旅游问题，通过利用嵌入空间相似性，将QA任务视为稠密向量检索问题。实验证明该方法在所有指标上都有效、高效，并且优于之前的方法。 |
| [^14] | [Shayona@SMM4H23: COVID-19 Self diagnosis classification using BERT and LightGBM models.](http://arxiv.org/abs/2401.02158) | Shayona团队在SMMH4-23中使用了BERT和LightGBM模型进行COVID-19自我诊断分类，并在任务1中取得了最高的F1分数0.94。 |
| [^15] | [Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study.](http://arxiv.org/abs/2401.02147) | 本研究从海洋分析的角度对GPT-4V进行了初步和全面的案例研究，评估了其在海洋研究中的性能，并为未来的发展设定了新的标准。 |
| [^16] | [DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models.](http://arxiv.org/abs/2401.02132) | DCR-Consistency提出了一个基于划分-征服-推理方法的自动化框架，用于评估和改进大型语言模型生成文本的一致性。与传统的评估方法不同，该方法通过将段落对段落比较划分为句子对段落的比较，并根据预定义标准进行评估。 |
| [^17] | [PEFT for Speech: Unveiling Optimal Placement, Merging Strategies, and Ensemble Techniques.](http://arxiv.org/abs/2401.02122) | 本研究通过比较不同的PEFT方法和逐层放置方式，以及采用集成学习策略，揭示了用于语音处理的PEFT的最佳方法和放置策略。结果表明，集成学习方法通过多数投票可以实现优于其他方法的性能。这项研究还发现不同的PEFT方法以不同的方式进行学习，从而解释了为什么通过集成学习可以更有效地利用它们的学习能力。 |
| [^18] | [Using LLM to select the right SQL Query from candidates.](http://arxiv.org/abs/2401.02115) | 本论文提出了一种使用LLM从候选项中选择正确的SQL查询的方法，并通过自动测试用例生成和重新排名来提高模型性能。 |
| [^19] | [Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe.](http://arxiv.org/abs/2401.02088) | 本论文重新评估了流水线并行体的内存平衡问题，并提出了一种名为BPipe的技术来解决该问题。验证实验结果表明，虽然BPipe在GPT-3模型上有效，但在LLaMA训练中并未获得相似的好处。我们还分析了BPipe在不同模型上性能差异的原因，并引入了一种新的方法来估计BPipe的性能。 |
| [^20] | [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers.](http://arxiv.org/abs/2401.02072) | ICE-GRT是一种利用生成强化转换的指令上下文增强方法，能够在特定领域的任务中取得卓越的结果，同时不影响通用任务性能。它不仅能生成稳健的答案，还能提供对答案背后原因的详细分析，是对现有指导性微调模型的显著进展。 |
| [^21] | [Understanding LLMs: A Comprehensive Overview from Training to Inference.](http://arxiv.org/abs/2401.02038) | 本文提供了一份综合概述，介绍了大规模语言模型（LLMs）从训练到推理的演变过程，并探讨了这一新兴趋势中与成本效率相关的训练和部署方法。同时，还讨论了推理阶段的模型压缩、并行计算、内存调度和结构优化等关键主题，为LLMs的利用和未来发展提供了见解。 |
| [^22] | [Text2MDT: Extracting Medical Decision Trees from Medical Texts.](http://arxiv.org/abs/2401.02034) | 本研究提出了一个新颖的任务，Text2MDT，旨在从医学文本中自动提取医学决策树。通过两种不同的方法进行实验，结果表明基于大型语言模型的端到端方法显示出有希望的结果。 |
| [^23] | [Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives.](http://arxiv.org/abs/2401.02009) | 自我对比是一种通过对比不同求解视角和总结差异，提高大型语言模型（LLM）的反思能力的方法。 |
| [^24] | [Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias.](http://arxiv.org/abs/2401.01989) | 这项研究通过测量位置偏见，重访了大语言模型中的零-shot 抽象摘要。研究结果揭示了模型不公平地优先考虑某些部分的信息，从而导致不可取的行为。对多个LLM模型和预训练抽象摘要模型进行的实验提供了关于零-shot 总结任务的模型性能和位置偏见的新见解和讨论。 |
| [^25] | [A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity.](http://arxiv.org/abs/2401.01967) | 通过研究对齐算法和预训练语言模型，本论文揭示了对齐模型的机制，并提出了一种简单的方法来取消模型的对齐，从而使其恢复有害行为。 |
| [^26] | [Instruct-Imagen: Image Generation with Multi-modal Instruction.](http://arxiv.org/abs/2401.01952) | Instruct-Imagen是一种处理异构图像生成任务并进行泛化的模型，引入了多模式指令以实现各种生成意图的统一标准化。通过微调预训练的文本到图像扩散模型，并使用检索增强的训练提升模型在外部多模态环境下的生成能力。对多样化图像生成任务的人工评估表明，该模型取得了良好的效果。 |
| [^27] | [Generalist embedding models are better at short-context clinical semantic search than specialized embedding models.](http://arxiv.org/abs/2401.01943) | 本研究发现，在临床语义搜索方面，通用嵌入模型比专业嵌入模型表现更好，这表明现有的临床专业化模型对输入的微小变化更敏感。 |
| [^28] | [AstroLLaMA-Chat: Scaling AstroLLaMA with Conversational and Diverse Datasets.](http://arxiv.org/abs/2401.01916) | 通过有针对性和持续的预训练，我们在天文学问题回答中扩展了AstroLLaMA，通过使用紧凑的LLaMA-2模型和专门的天文学语料库，我们实现了在专门主题理解方面的显著改进。我们还通过对特定领域的对话数据集进行微调，发布了带有聊天功能的AstroLLaMA。 |
| [^29] | [Cross-target Stance Detection by Exploiting Target Analytical Perspectives.](http://arxiv.org/abs/2401.01761) | 本论文提出了一种利用目标分析视角进行跨目标立场检测的方法，并使用多视角提示调整框架将自然语言解释融合到立场预测器中。 |
| [^30] | [Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation.](http://arxiv.org/abs/2401.01078) | 本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。 |
| [^31] | [Video Understanding with Large Language Models: A Survey.](http://arxiv.org/abs/2312.17432) | 这项调查研究提供了对大型语言模型（Vid-LLMs）在视频理解中的最新进展的详细概述。Vid-LLMs的新兴能力包括开放式时空推理和常识知识，为未来的视频理解提供了有前途的方向。 |
| [^32] | [Adversarial Data Poisoning for Fake News Detection: How to Make a Model Misclassify a Target News without Modifying It.](http://arxiv.org/abs/2312.15228) | 本文分析了对抗性攻击在假新闻检测模型中的威胁，研究了攻击者如何在不修改原始目标新闻的情况下通过引入污染数据来操纵模型的行为。 |
| [^33] | [Theory of Hallucinations based on Equivariance.](http://arxiv.org/abs/2312.14504) | 本研究提出了基于等变性的幻觉理论，探讨了大型语言模型中幻觉的成因，并开发了一种衡量语言模型幻觉程度的交叉熵误差函数。通过测试语言模型在获得等变性方面的能力，研究表明某些类型的等变语言模型对理解复杂社交关系表现出色。 |
| [^34] | [T-Eval: Evaluating the Tool Utilization Capability Step by Step.](http://arxiv.org/abs/2312.14033) | T-Eval是一种逐步评估工具利用能力的方法，它将工具利用评估解耦为多个子领域，从而能够更细致地分析大型语言模型（LLM）的能力。 |
| [^35] | [Evaluating Language-Model Agents on Realistic Autonomous Tasks.](http://arxiv.org/abs/2312.11671) | 这篇论文评估了语言模型代理在现实自主任务中的表现，发现这些代理只能完成最简单的任务，对于更具挑战性的任务有一定进展。 |
| [^36] | [One Shot Learning as Instruction Data Prospector for Large Language Models.](http://arxiv.org/abs/2312.10302) | 本研究提出了一种名为Nuggets的新颖有效方法，利用单次学习从庞大的数据集中选择高质量的指导数据，通过评估示例对多样锚定集的困惑度影响，选择对指导调优最有益的数据 |
| [^37] | [UstanceBR: a multimodal language resource for stance prediction.](http://arxiv.org/abs/2312.06374) | UstanceBR是一个多模态语言资源，用于目标立场预测，包含巴西葡萄牙语Twitter领域的86.8k标记立场和发布者的网络信息。这个研究为未来的研究提供了初始基准结果。 |
| [^38] | [TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models.](http://arxiv.org/abs/2311.04589) | TEAL是一种用于多模态大语言模型的方法，将不同模态的输入视为令牌序列，并学习它们的联合嵌入空间。这使得模型能够有效地建模多模态输入之间的相互作用，并生成非文本模态的输出。 |
| [^39] | [GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text.](http://arxiv.org/abs/2308.06911) | GIT-Mol是一种多模态大型语言模型，可在分子科学中处理图像、图形和文本信息。通过新提出的GIT-Former架构，该模型能够将多种模态的数据对齐到一个统一的潜在空间中。与基线相比，GIT-Mol在性质预测和分子生成有效性方面取得了显著改进。此外，该模型还可用于化合物名称识别和化学反应预测等下游任务。 |
| [^40] | [Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench.](http://arxiv.org/abs/2308.03656) | 通过利用心理学中的情感评估理论，本研究提出利用EmotionBench评估LLMs的共情能力。通过人类评估和对五个LLMs的研究发现，尽管存在一些不一致之处，LLMs通常能在某些情境下适当地回应，但与情感对齐方面还存在不足。 |
| [^41] | [Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration.](http://arxiv.org/abs/2307.05300) | 本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。 |
| [^42] | [Hierarchical Aligned Multimodal Learning for NER on Tweet Posts.](http://arxiv.org/abs/2305.08372) | 本文提出了一种新颖的方法用于多模态命名实体识别（MNER）的改进，该方法通过动态对齐图像和文本序列，并实现多级跨模态学习来增强文本词表示。实验证明了该方法的有效性。 |
| [^43] | [VideoChat: Chat-Centric Video Understanding.](http://arxiv.org/abs/2305.06355) | 本文提出了以聊天为核心的视频理解系统VideoChat，它通过可学习的神经接口将视频基础模型和大型语言模型集成在一起，擅长于时空推理、事件定位和因果关系推断。作者还提出了一个视频为中心的指令数据集，初步实验表明该系统在广泛的视频应用中具有潜力。 |
| [^44] | [Lon-ea at SemEval-2023 Task 11: A Comparison of Activation Functions for Soft and Hard Label Prediction.](http://arxiv.org/abs/2303.02468) | 本研究研究了在软硬标签预测中，不同激活函数对于深度神经网络模型输出的影响，并引入了一种新的正弦激活函数。 |
| [^45] | [How do media talk about the Covid-19 pandemic? Metaphorical thematic clustering in Italian online newspapers.](http://arxiv.org/abs/2204.02106) | 本研究通过对意大利线上报纸在新冠疫情初期使用的比喻语言进行定量和定性分析，发现政府对疫情应对的不同阶段存在显著变化，并且不同主题之间存在有趣的隐喻重叠。 |

# 详细

[^1]: 任务导向对话作为自监督自动语音识别的催化剂

    Task Oriented Dialogue as a Catalyst for Self-Supervised Automatic Speech Recognition. (arXiv:2401.02417v1 [eess.AS])

    [http://arxiv.org/abs/2401.02417](http://arxiv.org/abs/2401.02417)

    本研究引入了一种对话对比学习方法，用于对自动语音识别模型进行自监督微调，以改善低质量语音识别结果导致的自然语言理解应用的失败。实验证明，这种方法在任务导向的对话数据集上可以将ASR模型的性能提高达到19.2%。

    

    虽然自动语音识别（ASR）系统的词错误率不断下降，但基于ASR系统构建的自然语言理解（NLU）应用仍然归因于低质量的语音识别结果导致的大量失败。现有的助手系统收集了大量这些失败的交互，但是这些系统通常无法从这些交互中学习，即使是离线学习也是如此。在这项工作中，我们引入了CLC：对话对比学习，这是一系列自监督方法，用于对模型进行对比微调，利用失败对话中容易检测到的人工痕迹。我们证明了我们的CLC系列方法可以提高ASR模型在OD3上的性能，这是一个新的公开的大规模半合成元数据集，对话是以任务为导向的，提升幅度高达19.2%。这些增益也可以转移到现实世界的系统中，我们展示了CLC可以帮助提高性能。

    While word error rates of automatic speech recognition (ASR) systems have consistently fallen, natural language understanding (NLU) applications built on top of ASR systems still attribute significant numbers of failures to low-quality speech recognition results. Existing assistant systems collect large numbers of these unsuccessful interactions, but these systems usually fail to learn from these interactions, even in an offline fashion. In this work, we introduce CLC: Contrastive Learning for Conversations, a family of methods for contrastive fine-tuning of models in a self-supervised fashion, making use of easily detectable artifacts in unsuccessful conversations with assistants. We demonstrate that our CLC family of approaches can improve the performance of ASR models on OD3, a new public large-scale semi-synthetic meta-dataset of audio task-oriented dialogues, by up to 19.2%. These gains transfer to real-world systems as well, where we show that CLC can help to improve performance 
    
[^2]: LLaMA Pro: 带有模块扩展的渐进LLaMA方法

    LLaMA Pro: Progressive LLaMA with Block Expansion. (arXiv:2401.02415v1 [cs.CL])

    [http://arxiv.org/abs/2401.02415](http://arxiv.org/abs/2401.02415)

    本论文提出了一种新型的LLMs后处理方法，通过扩展Transformer模块并使用新的语料库进行调整，有效地提高了模型知识，而不会发生灾难性遗忘。在代码和数学领域的实验结果表明，LLaMA Pro是一种功能强大且适用于通用任务、编程和数学的基础模型，同时在各种基准测试中取得了先进的性能，展示了智能体推理和解决多样化任务的潜力。

    

    人类通常在不牺牲旧技能的情况下学习新技能；然而，对于大型语言模型（LLMs），例如从LLaMA到CodeLLaMA则相反。为此，我们提出了一种具有Transformer模块扩展的LLMs的新的预训练后处理方法。我们仅使用新的语料库调整扩展的模块，以有效地提高模型的知识而不会发生灾难性遗忘。本文在代码和数学语料库上进行实验，得到了从LLaMA2-7B初始化的通用基础模型LLaMA Pro-8.3B，在常规任务、编程和数学方面表现出色。LLaMA Pro及其按照指令执行的对应模型（LLaMA Pro-Instruct）在各种基准测试中都取得了先进的性能，展示了在LLaMA系列和其他开放模型中的优越性以及作为智能体推理和解决多样化任务的巨大潜力。我们的发现对于整合自然语言和编程语言提供了有价值的见解，为发展推理和解决多样化任务的智能体奠定了基础。

    Humans generally acquire new skills without compromising the old; however, the opposite holds for Large Language Models (LLMs), e.g., from LLaMA to CodeLLaMA. To this end, we propose a new post-pretraining method for LLMs with an expansion of Transformer blocks. We tune the expanded blocks using only new corpus, efficiently and effectively improving the model's knowledge without catastrophic forgetting. In this paper, we experiment on the corpus of code and math, yielding LLaMA Pro-8.3B, a versatile foundation model initialized from LLaMA2-7B, excelling in general tasks, programming, and mathematics. LLaMA Pro and its instruction-following counterpart (LLaMA Pro-Instruct) achieve advanced performance among various benchmarks, demonstrating superiority over existing open models in the LLaMA family and the immense potential of reasoning and addressing diverse tasks as an intelligent agent. Our findings provide valuable insights into integrating natural and programming languages, laying a
    
[^3]: LLM增强的LLMs：通过组合扩展功能

    LLM Augmented LLMs: Expanding Capabilities through Composition. (arXiv:2401.02412v1 [cs.LG])

    [http://arxiv.org/abs/2401.02412](http://arxiv.org/abs/2401.02412)

    本文提出了CALM方法，通过组合现有的基础模型和更具体的模型，使用交叉注意力来增强模型的表示并实现新的能力。CALM可以通过“重用”现有模型和一些额外的参数和数据来扩展新任务上的模型规模，并且保留现有模型的功能。

    

    在大型数据集上训练的具有数十亿个参数的基础模型已经展现出在各个领域具有非平凡技能。然而，由于它们的整体结构，对它们进行增强或赋予新的技能是具有挑战性和成本高昂的。另一方面，由于其适应能力，正在训练多个新领域和任务的模型实例。在这项工作中，我们研究了利用现有的基础模型与更具体模型进行高效实用的组合，以实现新的功能。为此，我们提出了CALM -用于增强语言模型的组合模型-，它引入了模型之间的交叉注意力，以组合它们的表示并实现新的能力。CALM的显著特点包括：(i)通过“重用”现有LLMs和一些额外的参数和数据来扩展新任务上的LLMs的规模，(ii)保持现有模型权重不变，从而保留现有功能，(iii)应用新功能只需要对增加的模型进行微调。

    Foundational models with billions of parameters which have been trained on large corpora of data have demonstrated non-trivial skills in a variety of domains. However, due to their monolithic structure, it is challenging and expensive to augment them or impart new skills. On the other hand, due to their adaptation abilities, several new instances of these models are being trained towards new domains and tasks. In this work, we study the problem of efficient and practical composition of existing foundation models with more specific models to enable newer capabilities. To this end, we propose CALM -Composition to Augment Language Models -- which introduces cross-attention between models to compose their representations and enable new capabilities. Salient features of CALM are: (i) Scales up LLMs on new tasks by 're-using' existing LLMs along with a few additional parameters and data, (ii) Existing model weights are kept intact, and hence preserves existing capabilities, and (iii) Appli
    
[^4]: TinyLlama：一个开源的小型语言模型

    TinyLlama: An Open-Source Small Language Model. (arXiv:2401.02385v1 [cs.CL])

    [http://arxiv.org/abs/2401.02385](http://arxiv.org/abs/2401.02385)

    TinyLlama是一个开源的小型语言模型，基于Llama 2的架构和分词器，利用各种先进技术实现了更好的计算效率。尽管规模较小，但在下游任务中表现出色，明显优于其他类似规模的开源语言模型。

    

    我们介绍了TinyLlama，一个有限的1.1B语言模型，大约预训练了1万亿个标记，训练轮数约为3轮。TinyLlama基于Llama 2的架构和分词器，在开源社区的贡献基础上（例如FlashAttention），利用各种先进技术实现了更好的计算效率。尽管规模相对较小，TinyLlama在一系列下游任务中展示了出色的性能。它明显优于具有类似规模的现有开源语言模型。我们的模型检查点和代码可在GitHub上公开获取，网址为https://github.com/jzhang38/TinyLlama。

    We present TinyLlama, a compact 1.1B language model pretrained on around 1 trillion tokens for approximately 3 epochs. Building on the architecture and tokenizer of Llama 2, TinyLlama leverages various advances contributed by the open-source community (e.g., FlashAttention), achieving better computational efficiency. Despite its relatively small size, TinyLlama demonstrates remarkable performance in a series of downstream tasks. It significantly outperforms existing open-source language models with comparable sizes. Our model checkpoints and code are publicly available on GitHub at https://github.com/jzhang38/TinyLlama.
    
[^5]: SPEER: Embedded Entity Retrieval下的长临床摘要句子级规划

    SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded Entity Retrieval. (arXiv:2401.02369v1 [cs.CL])

    [http://arxiv.org/abs/2401.02369](http://arxiv.org/abs/2401.02369)

    本研究提出了一种在临床摘要中使用句子级规划并通过嵌入式实体检索的方法，以提高摘要的准确性和实用性。

    

    临床医生在每次病人出院时必须写一份冗长的摘要。由于涵盖的临床概念数量庞大，这项任务非常耗时。识别和涵盖显著实体对于摘要的临床实用性至关重要。我们在该任务上微调了开源的LLM模型（Mistral-7B-Instruct和Zephyr-7B-η），发现它们生成的摘要不完整且不准确。为了增加实体覆盖范围，我们训练了一个较小的仅编码器模型来预测显著实体，并将其作为内容计划来指导LLM。为了鼓励LLM关注源笔记中的特定提及，我们提出了SPEER：Embedded Entity Retrieval下的句子级规划。具体而言，我们使用特殊的"{{ }}"边界标签标记每个显著实体跨度，并要求LLM在生成每个句子之前检索标记的跨度。句子级规划相当于一种状态追踪，模型明确记录下每个句子的信息。

    Clinician must write a lengthy summary each time a patient is discharged from the hospital. This task is time-consuming due to the sheer number of unique clinical concepts covered in the admission. Identifying and covering salient entities is vital for the summary to be clinically useful. We fine-tune open-source LLMs (Mistral-7B-Instruct and Zephyr-7B-\b{eta}) on the task and find that they generate incomplete and unfaithful summaries. To increase entity coverage, we train a smaller, encoder-only model to predict salient entities, which are treated as content-plans to guide the LLM. To encourage the LLM to focus on specific mentions in the source notes, we propose SPEER: Sentence-level Planning via Embedded Entity Retrieval. Specifically, we mark each salient entity span with special "{{ }}" boundary tags and instruct the LLM to retrieve marked spans before generating each sentence. Sentence-level planning acts as a form of state tracking in that the model is explicitly recording the 
    
[^6]: 超越提取：为语言模型提供上下文化的表格数据以实现高效摘要

    Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models. (arXiv:2401.02333v1 [cs.LG])

    [http://arxiv.org/abs/2401.02333](http://arxiv.org/abs/2401.02333)

    本研究提出了一种创新的方法，通过上下文化表格数据来提高 RAG 系统中处理复杂表格查询的准确性，提高了摘要的效率。

    

    传统的检索增强生成 (RAG) 架构在从各种文件中检索信息方面已被证明是有效的。然而，在处理包含复杂表格结构的 PDF 文档中的复杂表格查询时会遇到挑战。本研究引入了一种创新的方法来提高 RAG 系统中复杂表格查询的准确性。我们的方法涉及将 PDF 存储在检索数据库中，并单独提取表格内容。提取的表格经过上下文丰富的处理，将标题与相应的值连接起来。为了确保对丰富数据的全面理解，我们使用经过微调的 Llama-2-chat 语言模型在 RAG 架构中进行摘要。此外，我们通过一次性提示使用 ChatGPT 3.5 API 增强表格数据的上下文含义。然后，将这些丰富的数据与其他 PDF 文件一起输入检索数据库。

    The conventional use of the Retrieval-Augmented Generation (RAG) architecture has proven effective for retrieving information from diverse documents. However, challenges arise in handling complex table queries, especially within PDF documents containing intricate tabular structures.This research introduces an innovative approach to enhance the accuracy of complex table queries in RAG-based systems. Our methodology involves storing PDFs in the retrieval database and extracting tabular content separately. The extracted tables undergo a process of context enrichment, concatenating headers with corresponding values. To ensure a comprehensive understanding of the enriched data, we employ a fine-tuned version of the Llama-2-chat language model for summarisation within the RAG architecture. Furthermore, we augment the tabular data with contextual sense using the ChatGPT 3.5 API through a one-shot prompt. This enriched data is then fed into the retrieval database alongside other PDFs. Our appr
    
[^7]: LLaVA-$\phi$: 高效的多模态助手与小型语言模型

    LLaVA-$\phi$: Efficient Multi-Modal Assistant with Small Language Model. (arXiv:2401.02330v1 [cs.CV])

    [http://arxiv.org/abs/2401.02330](http://arxiv.org/abs/2401.02330)

    LLaVA-$\phi$是一种高效的多模态助手，使用小型语言模型Phi-2来促进多模态对话。即使具有较少的参数，它也能有效地融合文本和视觉元素，并在各种任务中表现出色。它为时间敏感的环境和需要实时交互的系统开辟了新的应用途径。

    

    在本文中，我们介绍了LLaVA-$\phi$（LLaVA-Phi），一种利用最近先进的小型语言模型Phi-2来促进多模态对话的高效多模态助手。LLaVA-Phi在紧凑的多模态模型领域中标志着重要进展。它证明了即使是个参数只有27亿的较小语言模型在训练有高质量语料库的情况下也可以有效地参与融合文本和视觉元素的复杂对话。我们的模型在包括视觉理解、推理和基于知识的感知等公开可用的基准测试中表现出色。除了在多模态对话任务中表现出卓越性能外，我们的模型为时间敏感的环境和需要实时交互的系统（如实体代理）开辟了新的应用途径。它突显了较小语言模型实现高级理解和交互的潜力。

    In this paper, we introduce LLaVA-$\phi$ (LLaVA-Phi), an efficient multi-modal assistant that harnesses the power of the recently advanced small language model, Phi-2, to facilitate multi-modal dialogues. LLaVA-Phi marks a notable advancement in the realm of compact multi-modal models. It demonstrates that even smaller language models, with as few as 2.7B parameters, can effectively engage in intricate dialogues that integrate both textual and visual elements, provided they are trained with high-quality corpora. Our model delivers commendable performance on publicly available benchmarks that encompass visual comprehension, reasoning, and knowledge-based perception. Beyond its remarkable performance in multi-modal dialogue tasks, our model opens new avenues for applications in time-sensitive environments and systems that require real-time interaction, such as embodied agents. It highlights the potential of smaller language models to achieve sophisticated levels of understanding and inte
    
[^8]: 对话型语言模型在口语对话中的鲁棒性研究

    Are LLMs Robust for Spoken Dialogues?. (arXiv:2401.02297v1 [cs.CL])

    [http://arxiv.org/abs/2401.02297](http://arxiv.org/abs/2401.02297)

    本文评估了LLMs在口语任务导向对话中的性能，并报告了回复生成和对话状态跟踪两个子任务中的模型表现。由于缺乏适当的口语对话数据集，我们使用自动语音识别引擎转录了口语对话的开发集，并模拟了ASR错误以进行评估。

    

    大型预训练语言模型在对话状态跟踪和端到端回复生成等不同下游任务中展示了最先进的性能。然而，大多数公开可用的面向任务的对话数据集和基准都集中在书面对话上。因此，我们对开发的模型在口语交互中的鲁棒性进行了评估。由于缺乏适当的口语对话数据集，我们使用了最先进的自动语音识别引擎自动转录了一个口语对话的开发集。我们对ASR错误类型及其分布进行了特征化，并在大规模的对话数据集中模拟了这些错误。我们报告了GPT-2和T5模型在回复生成和对话状态跟踪两个子任务中的内在（困惑度）和外在（人工评估）性能。

    Large Pre-Trained Language Models have demonstrated state-of-the-art performance in different downstream tasks, including dialogue state tracking and end-to-end response generation. Nevertheless, most of the publicly available datasets and benchmarks on task-oriented dialogues focus on written conversations. Consequently, the robustness of the developed models to spoken interactions is unknown. In this work, we have evaluated the performance of LLMs for spoken task-oriented dialogues on the DSTC11 test sets. Due to the lack of proper spoken dialogue datasets, we have automatically transcribed a development set of spoken dialogues with a state-of-the-art ASR engine. We have characterized the ASR-error types and their distributions and simulated these errors in a large dataset of dialogues. We report the intrinsic (perplexity) and extrinsic (human evaluation) performance of fine-tuned GPT-2 and T5 models in two subtasks of response generation and dialogue state tracking, respectively. Th
    
[^9]: 重新考虑从对话参与者的角度对开放域对话系统进行响应评估

    Rethinking Response Evaluation from Interlocutor's Eye for Open-Domain Dialogue Systems. (arXiv:2401.02256v1 [cs.CL])

    [http://arxiv.org/abs/2401.02256](http://arxiv.org/abs/2401.02256)

    本研究重新考虑了从对话参与者的角度对开放域对话系统进行响应评估的问题，并发现了对话参与者意识和对话连贯性在自动评估中的关键作用。

    

    开放域对话系统已经开始与人类进行连续对话。这些对话系统需要根据人类对话者进行调整，并以其角度进行评估。然而，当前的自动评估方法是否能够近似对话参与者的判断是存疑的。在本研究中，我们分析和研究了从对话参与者角度需要哪些特征的自动响应评估器。第一次在Hazumi数据集上的实验表明，对话参与者意识在使自动响应评估与对话参与者判断相关方面起着关键作用。第二个实验使用大规模对话（前称Twitter）确认了对话连贯性预测可以训练出一个具有对话参与者意识的响应评估器，而相比人类响应，评估生成的响应的难度更大。

    Open-domain dialogue systems have started to engage in continuous conversations with humans. Those dialogue systems are required to be adjusted to the human interlocutor and evaluated in terms of their perspective. However, it is questionable whether the current automatic evaluation methods can approximate the interlocutor's judgments. In this study, we analyzed and examined what features are needed in an automatic response evaluator from the interlocutor's perspective. The first experiment on the Hazumi dataset revealed that interlocutor awareness plays a critical role in making automatic response evaluation correlate with the interlocutor's judgments. The second experiment using massive conversations on X (formerly Twitter) confirmed that dialogue continuity prediction can train an interlocutor-aware response evaluator without human feedback while revealing the difficulty in evaluating generated responses compared to human responses.
    
[^10]: L3Cube-IndicNews：印度语系新闻短文和长文分类数据集

    L3Cube-IndicNews: News-based Short Text and Long Document Classification Datasets in Indic Languages. (arXiv:2401.02254v1 [cs.CL])

    [http://arxiv.org/abs/2401.02254](http://arxiv.org/abs/2401.02254)

    L3Cube-IndicNews是一个面向印度语系的多语种文本分类数据集，包括短标题、长文档和长段落三个数据集。它提供了10种印度语言的新闻文章，每个数据集包含10个或更多类别的文章。这个数据集可以用于深入分析和评估。

    

    在这项工作中，我们介绍了L3Cube-IndicNews，这是一个多语种文本分类语料库，旨在为印度地区的各大方言语言提供高质量的数据集，特别关注新闻标题和文章。我们的工作主要集中在10种主要的印度语言上，包括印地语、孟加拉语、马拉地语、泰卢固语、泰米尔语、古吉拉特语、卡纳达语、奥里亚语、马拉雅拉姆语和旁遮普语。每个新闻数据集包含10个或更多类别的新闻文章。L3Cube-IndicNews提供了3个不同数据集，针对不同的文档长度进行分类：短标题分类（SHC）数据集包含新闻标题和新闻类别，长文档分类（LDC）数据集包含整个新闻文章和新闻类别，长段落分类（LPC）数据集包含新闻的子文章和新闻类别。我们在所有3个数据集中都保持了一致的标签，以进行深入的基于长度的分析。我们使用4个指标对每个印度语言数据集进行评估。

    In this work, we introduce L3Cube-IndicNews, a multilingual text classification corpus aimed at curating a high-quality dataset for Indian regional languages, with a specific focus on news headlines and articles. We have centered our work on 10 prominent Indic languages, including Hindi, Bengali, Marathi, Telugu, Tamil, Gujarati, Kannada, Odia, Malayalam, and Punjabi. Each of these news datasets comprises 10 or more classes of news articles. L3Cube-IndicNews offers 3 distinct datasets tailored to handle different document lengths that are classified as: Short Headlines Classification (SHC) dataset containing the news headline and news category, Long Document Classification (LDC) dataset containing the whole news article and the news category, and Long Paragraph Classification (LPC) containing sub-articles of the news and the news category. We maintain consistent labeling across all 3 datasets for in-depth length-based analysis. We evaluate each of these Indic language datasets using 4 
    
[^11]: 联合多事实推理网络用于复杂时态问题在知识图上的问答

    Joint Multi-Facts Reasoning Network For Complex Temporal Question Answering Over Knowledge Graph. (arXiv:2401.02212v1 [cs.CL])

    [http://arxiv.org/abs/2401.02212](http://arxiv.org/abs/2401.02212)

    本研究提出了联合多事实推理网络（JMFRN）用于复杂时态问题在知识图上的问答，通过聚合实体和时间戳信息来准确回答复杂时态问题。

    

    时间知识图（TKG）是在常规知识图的基础上加入时间范围的扩展。现有的时间知识图问答（TKGQA）模型仅处理简单问题，因为它们先前假设每个问题只包含一个具有显式/隐式时间约束的时间事实。因此，它们对于具有多个时间事实的问题表现较差。在本文中，我们提出了联合多事实推理网络（JMFRN），用于准确回答复杂时态问题。具体地，JMFRN首先从TKG中检索与给定复杂问题的每个实体相关的时间事实。为了进行联合推理，我们设计了两个不同的注意力模块（即实体感知和时间感知），适用于通用设置，以聚合实体和时间戳信息。

    Temporal Knowledge Graph (TKG) is an extension of regular knowledge graph by attaching the time scope. Existing temporal knowledge graph question answering (TKGQA) models solely approach simple questions, owing to the prior assumption that each question only contains a single temporal fact with explicit/implicit temporal constraints. Hence, they perform poorly on questions which own multiple temporal facts. In this paper, we propose \textbf{\underline{J}}oint \textbf{\underline{M}}ulti \textbf{\underline{F}}acts \textbf{\underline{R}}easoning \textbf{\underline{N}}etwork (JMFRN), to jointly reasoning multiple temporal facts for accurately answering \emph{complex} temporal questions. Specifically, JMFRN first retrieves question-related temporal facts from TKG for each entity of the given complex question. For joint reasoning, we design two different attention (\ie entity-aware and time-aware) modules, which are suitable for universal settings, to aggregate entities and timestamps inform
    
[^12]: DIALIGHT：轻量级多语言开发和评估以大语言模型为基础的面向任务对话系统

    DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models. (arXiv:2401.02208v1 [cs.CL])

    [http://arxiv.org/abs/2401.02208](http://arxiv.org/abs/2401.02208)

    DIALIGHT是一个用于开发和评估多语言的面向任务的对话系统的工具包，通过对预训练语言模型进行微调和利用大型语言模型的零-shot和上下文学习能力，可以进行系统化的评估和比较。研究发现，PLM微调可以提高准确性和连贯性，而LLM系统在产生多样化和受欢迎的回复方面表现出色，但需要解决LLM在遵循任务特定指令和生成多语言输出方面的挑战。

    

    我们提出了DIALIGHT，这是一个工具包，用于开发和评估多语言的面向任务的对话系统。它通过对预训练语言模型（PLM）进行微调和利用大型语言模型（LLM）的零-shot和上下文学习能力，使得系统评估和比较更加系统化。除了自动评估外，该工具包还具有（i）一个安全、用户友好的网络界面，用于在本地文本级和全局对话级进行细粒度的人工评估，以及（ii）基于微服务的后端，提高了效率和可扩展性。我们的评估结果表明，PLM微调可以提高准确性和连贯性，而基于LLM的系统在产生多样化和受欢迎的回复方面表现出色。然而，我们也发现LLM在遵循任务特定指令和生成多语言输出方面存在重要挑战，这为未来的研究指明了方向。我们希望这个开源工具包能够帮助研究人员更好地开发和评估任务导向的对话系统。

    We present DIALIGHT, a toolkit for developing and evaluating multilingual Task-Oriented Dialogue (ToD) systems which facilitates systematic evaluations and comparisons between ToD systems using fine-tuning of Pretrained Language Models (PLMs) and those utilising the zero-shot and in-context learning capabilities of Large Language Models (LLMs). In addition to automatic evaluation, this toolkit features (i) a secure, user-friendly web interface for fine-grained human evaluation at both local utterance level and global dialogue level, and (ii) a microservice-based backend, improving efficiency and scalability. Our evaluations reveal that while PLM fine-tuning leads to higher accuracy and coherence, LLM-based systems excel in producing diverse and likeable responses. However, we also identify significant challenges of LLMs in adherence to task-specific instructions and generating outputs in multiple languages, highlighting areas for future research. We hope this open-sourced toolkit will 
    
[^13]: 旅游问答的位置感知模块化双编码器

    Location Aware Modular Biencoder for Tourism Question Answering. (arXiv:2401.02187v1 [cs.CL])

    [http://arxiv.org/abs/2401.02187](http://arxiv.org/abs/2401.02187)

    提出了一种位置感知模块化双编码器来回答真实世界旅游问题，通过利用嵌入空间相似性，将QA任务视为稠密向量检索问题。实验证明该方法在所有指标上都有效、高效，并且优于之前的方法。

    

    回答寻找兴趣点（POI）推荐的真实世界旅游问题是具有挑战性的，因为它需要对大量候选项进行空间和非空间推理。当候选项数量增加时，传统的对每对问题和POI进行编码的方法效率降低，使得在现实世界的应用中不可行。为了解决这个问题，我们将QA任务视为一个稠密向量检索问题，其中我们分别对问题和POI进行编码，并通过利用嵌入空间相似性为问题检索最相关的POI。我们使用预训练的语言模型（PLMs）来编码文本信息，并训练一个位置编码器来捕捉POI的空间信息。对真实世界的旅游QA数据集的实验表明，我们的方法在所有指标上都是有效、高效的，并且优于之前的方法。借助稠密检索架构的支持，我们进一步建立了一个全球评估基准，扩展了搜索

    Answering real-world tourism questions that seek Point-of-Interest (POI) recommendations is challenging, as it requires both spatial and non-spatial reasoning, over a large candidate pool. The traditional method of encoding each pair of question and POI becomes inefficient when the number of candidates increases, making it infeasible for real-world applications. To overcome this, we propose treating the QA task as a dense vector retrieval problem, where we encode questions and POIs separately and retrieve the most relevant POIs for a question by utilizing embedding space similarity. We use pretrained language models (PLMs) to encode textual information, and train a location encoder to capture spatial information of POIs. Experiments on a real-world tourism QA dataset demonstrate that our approach is effective, efficient, and outperforms previous methods across all metrics. Enabled by the dense retrieval architecture, we further build a global evaluation baseline, expanding the search s
    
[^14]: Shayona@SMM4H23：使用BERT和LightGBM模型进行COVID-19自我诊断分类

    Shayona@SMM4H23: COVID-19 Self diagnosis classification using BERT and LightGBM models. (arXiv:2401.02158v1 [cs.CL])

    [http://arxiv.org/abs/2401.02158](http://arxiv.org/abs/2401.02158)

    Shayona团队在SMMH4-23中使用了BERT和LightGBM模型进行COVID-19自我诊断分类，并在任务1中取得了最高的F1分数0.94。

    

    本文描述了Shayona团队在SMMH4-23的共享任务1和4中的方法和结果。共享任务1是对自报COVID-19诊断的英文推文进行二分类，共享任务4是对自报社交焦虑障碍诊断的英文Reddit帖子进行二分类。我们的团队在任务1中取得了所有参与者中最高的F1分数0.94。我们在两个任务中都使用了Transformer模型（BERT）和LightGBM模型进行处理。

    This paper describes approaches and results for shared Task 1 and 4 of SMMH4-23 by Team Shayona. Shared Task-1 was binary classification of english tweets self-reporting a COVID-19 diagnosis, and Shared Task-4 was Binary classification of English Reddit posts self-reporting a social anxiety disorder diagnosis. Our team has achieved the highest f1-score 0.94 in Task-1 among all participants. We have leveraged the Transformer model (BERT) in combination with the LightGBM model for both tasks.
    
[^15]: 探索GPT-4V在海洋分析领域的边界：一个初步的案例研究

    Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study. (arXiv:2401.02147v1 [cs.CL])

    [http://arxiv.org/abs/2401.02147](http://arxiv.org/abs/2401.02147)

    本研究从海洋分析的角度对GPT-4V进行了初步和全面的案例研究，评估了其在海洋研究中的性能，并为未来的发展设定了新的标准。

    

    大型语言模型（LLMs）已经展示出作为通用助手回答各种查询的强大能力。连续多模式大型语言模型（MLLM）赋予LLMs感知视觉信号的能力。GPT-4（生成预训练的Transformer）的发布引起了研究界的极大兴趣。作为新一代人工智能的焦点之一，GPT-4V（ison）在学术界和工业领域展示了显著的实力。尽管GPT-4V取得了显著的成功，但探索在需要领域专门知识和专业技能的特定领域分析（如海洋分析）中的MLLMs却受到了较少关注。在本研究中，我们进行了关于利用GPT-4V进行海洋分析的初步和综合案例研究。本报告对现有的GPT-4V进行了系统评估，评估了GPT-4V在海洋研究中的性能，并为未来的发展设定了新的标准。

    Large language models (LLMs) have demonstrated a powerful ability to answer various queries as a general-purpose assistant. The continuous multi-modal large language models (MLLM) empower LLMs with the ability to perceive visual signals. The launch of GPT-4 (Generative Pre-trained Transformers) has generated significant interest in the research communities. GPT-4V(ison) has demonstrated significant power in both academia and industry fields, as a focal point in a new artificial intelligence generation. Though significant success was achieved by GPT-4V, exploring MLLMs in domain-specific analysis (e.g., marine analysis) that required domain-specific knowledge and expertise has gained less attention. In this study, we carry out the preliminary and comprehensive case study of utilizing GPT-4V for marine analysis. This report conducts a systematic evaluation of existing GPT-4V, assessing the performance of GPT-4V on marine research and also setting a new standard for future developments in
    
[^16]: DCR-Consistency: 大型语言模型一致性评估和改进的划分-征服-推理方法

    DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models. (arXiv:2401.02132v1 [cs.CL])

    [http://arxiv.org/abs/2401.02132](http://arxiv.org/abs/2401.02132)

    DCR-Consistency提出了一个基于划分-征服-推理方法的自动化框架，用于评估和改进大型语言模型生成文本的一致性。与传统的评估方法不同，该方法通过将段落对段落比较划分为句子对段落的比较，并根据预定义标准进行评估。

    

    评估大型语言模型（LLMs）生成的文本的质量和变异性是一个重要而尚未解决的研究难题。传统的评估方法，如ROUGE和BERTScore，通常无法捕捉到整体语义的等价性。这导致与人类判断和直觉的相关性较低，尤其在医疗和金融等高风险应用中，可靠性、安全性和强大的决策能力尤为重要。本研究提出了DCR框架，一种使用划分-征服-推理方法评估和改进LLM生成文本一致性的自动化框架。与现有的基于LLM的评估器不同，本方法采用了划分和征服评估器（DCE），将两个生成的回答之间的段落对段落比较分解为根据预定义标准评估的每个句子对段落的比较。

    Evaluating the quality and variability of text generated by Large Language Models (LLMs) poses a significant, yet unresolved research challenge. Traditional evaluation methods, such as ROUGE and BERTScore, which measure token similarity, often fail to capture the holistic semantic equivalence. This results in a low correlation with human judgments and intuition, which is especially problematic in high-stakes applications like healthcare and finance where reliability, safety, and robust decision-making are highly critical. This work proposes DCR, an automated framework for evaluating and improving the consistency of LLM-generated texts using a divide-conquer-reasoning approach. Unlike existing LLM-based evaluators that operate at the paragraph level, our method employs a divide-and-conquer evaluator (DCE) that breaks down the paragraph-to-paragraph comparison between two generated responses into individual sentence-to-paragraph comparisons, each evaluated based on predefined criteria. T
    
[^17]: 用于语音的PEFT：揭示优化放置、合并策略和集成技术

    PEFT for Speech: Unveiling Optimal Placement, Merging Strategies, and Ensemble Techniques. (arXiv:2401.02122v1 [cs.CL])

    [http://arxiv.org/abs/2401.02122](http://arxiv.org/abs/2401.02122)

    本研究通过比较不同的PEFT方法和逐层放置方式，以及采用集成学习策略，揭示了用于语音处理的PEFT的最佳方法和放置策略。结果表明，集成学习方法通过多数投票可以实现优于其他方法的性能。这项研究还发现不同的PEFT方法以不同的方式进行学习，从而解释了为什么通过集成学习可以更有效地利用它们的学习能力。

    

    参数高效微调（PEFT）被越来越认为是语音处理中一种有效的方法。然而，PEFT方法的最佳方法和放置仍然没有定论。我们的研究通过扩展实验来比较不同的PEFT方法及其逐层放置，使用可微分架构搜索（DARTS）进行调整。我们还探索了使用集成学习来利用多样化的PEFT策略。结果显示，DARTS并不比基线方法表现更好，基线方法涉及将相同的PEFT方法插入到自监督学习（SSL）模型的所有层中。相反，采用多数投票的集成学习方法表现出更好的性能。我们的统计证据表明，不同的PEFT方法以不同的方式进行学习。这种变异可能解释了为什么通过集成学习有效地利用各种PEFT方法的独特学习能力。

    Parameter-Efficient Fine-Tuning (PEFT) is increasingly recognized as an effective method in speech processing. However, the optimal approach and the placement of PEFT methods remain inconclusive. Our study conducts extensive experiments to compare different PEFT methods and their layer-wise placement adapting Differentiable Architecture Search (DARTS). We also explore the use of ensemble learning to leverage diverse PEFT strategies. The results reveal that DARTS does not outperform the baseline approach, which involves inserting the same PEFT method into all layers of a Self-Supervised Learning (SSL) model. In contrast, an ensemble learning approach, particularly one employing majority voting, demonstrates superior performance. Our statistical evidence indicates that different PEFT methods learn in varied ways. This variation might explain why the synergistic integration of various PEFT methods through ensemble learning can harness their unique learning capabilities more effectively co
    
[^18]: 使用LLM从候选项中选择正确的SQL查询

    Using LLM to select the right SQL Query from candidates. (arXiv:2401.02115v1 [cs.CL])

    [http://arxiv.org/abs/2401.02115](http://arxiv.org/abs/2401.02115)

    本论文提出了一种使用LLM从候选项中选择正确的SQL查询的方法，并通过自动测试用例生成和重新排名来提高模型性能。

    

    文本到SQL模型可以生成一系列候选的SQL查询，而最佳查询往往不在候选列表的顶部。有效的重新排名方法可以从候选列表中选择正确的SQL查询，并提高模型的性能。之前的研究在代码生成方面通过生成测试用例来重新排名候选代码。然而，针对文本到SQL的自动测试用例生成是一个研究较少的领域。我们提出了一种自动测试用例生成的方法，首先生成一个数据库，然后使用LLM来预测真实结果，即期望结果执行真实的SQL查询在这个数据库上的结果。为了减少LLM的预测困难，我们进行了实验来寻找生成LLM易处理数据库的方法，并设计易理解的提示。基于我们的测试用例生成方法，我们提出了一种重新排名方法来从候选列表中选择正确的SQL查询。

    Text-to-SQL models can generate a list of candidate SQL queries, and the best query is often in the candidate list, but not at the top of the list. An effective re-rank method can select the right SQL query from the candidate list and improve the model's performance. Previous studies on code generation automatically generate test cases and use them to re-rank candidate codes. However, automatic test case generation for text-to-SQL is an understudied field. We propose an automatic test case generation method that first generates a database and then uses LLMs to predict the ground truth, which is the expected execution results of the ground truth SQL query on this database. To reduce the difficulty for LLMs to predict, we conduct experiments to search for ways to generate easy databases for LLMs and design easy-to-understand prompts. Based on our test case generation method, we propose a re-rank method to select the right SQL query from the candidate list. Given a candidate list, our met
    
[^19]: 重新评估内存平衡的流水线并行体：BPipe

    Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe. (arXiv:2401.02088v1 [cs.LG])

    [http://arxiv.org/abs/2401.02088](http://arxiv.org/abs/2401.02088)

    本论文重新评估了流水线并行体的内存平衡问题，并提出了一种名为BPipe的技术来解决该问题。验证实验结果表明，虽然BPipe在GPT-3模型上有效，但在LLaMA训练中并未获得相似的好处。我们还分析了BPipe在不同模型上性能差异的原因，并引入了一种新的方法来估计BPipe的性能。

    

    流水线并行体是训练大规模Transformer模型的一种重要技术。然而，它在内存消耗上存在不平衡的问题，导致内存利用不充分。BPipe技术被提出来解决这个问题，并在GPT-3模型上证明了有效性。然而，我们的实验在LLaMA训练中未获得类似的好处。此外，在应用flash attention时，BPipe在GPT-3训练中只带来微不足道的好处。我们分析了BPipe在GPT-3和LLaMA上性能差异的根本原因。此外，我们介绍了一种新的方法来估计BPipe的性能。

    Pipeline parallelism is an essential technique in the training of large-scale Transformer models. However, it suffers from imbalanced memory consumption, leading to insufficient memory utilization. The BPipe technique was proposed to address this issue and has proven effective in the GPT-3 model. Nevertheless, our experiments have not yielded similar benefits for LLaMA training. Additionally, BPipe only yields negligible benefits for GPT-3 training when applying flash attention. We analyze the underlying causes of the divergent performance of BPipe on GPT-3 and LLaMA. Furthermore, we introduce a novel method to estimate the performance of BPipe.
    
[^20]: ICE-GRT: 基于生成增强的转换的指令上下文增强

    ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers. (arXiv:2401.02072v1 [cs.CL])

    [http://arxiv.org/abs/2401.02072](http://arxiv.org/abs/2401.02072)

    ICE-GRT是一种利用生成强化转换的指令上下文增强方法，能够在特定领域的任务中取得卓越的结果，同时不影响通用任务性能。它不仅能生成稳健的答案，还能提供对答案背后原因的详细分析，是对现有指导性微调模型的显著进展。

    

    大型语言模型（LLMs）如ChatGPT和LLaMA在特定领域的任务中存在局限性，这些模型在专业领域缺乏深度和准确性，在精细调整时的整体能力下降，特别是小型模型的分析能力。为了解决这些问题，我们引入了ICE-GRT，利用基于近端策略优化（PPO）的人类反馈强化学习（RLHF），在领域内场景中展示出卓越的能力，同时不损失通用任务性能。我们对ICE-GRT的探索突出了其理解和推理能力，不仅能够生成稳健的答案，还能提供对答案背后原因的详细分析。这种能力标志着对指导性微调模型的显著进展。ICE-GRT的成功取决于几个关键因素，包括适当的数据、奖励规模缩放、KL控制、优势归一化等。

    The emergence of Large Language Models (LLMs) such as ChatGPT and LLaMA encounter limitations in domain-specific tasks, with these models often lacking depth and accuracy in specialized areas, and exhibiting a decrease in general capabilities when fine-tuned, particularly analysis ability in small sized models. To address these gaps, we introduce ICE-GRT, utilizing Reinforcement Learning from Human Feedback (RLHF) grounded in Proximal Policy Optimization (PPO), demonstrating remarkable ability in in-domain scenarios without compromising general task performance. Our exploration of ICE-GRT highlights its understanding and reasoning ability to not only generate robust answers but also to provide detailed analyses of the reasons behind the answer. This capability marks a significant progression beyond the scope of Supervised Fine-Tuning models. The success of ICE-GRT is dependent on several crucial factors, including Appropriate Data, Reward Size Scaling, KL-Control, Advantage Normalizati
    
[^21]: 理解LLMs：从训练到推理的全面概述

    Understanding LLMs: A Comprehensive Overview from Training to Inference. (arXiv:2401.02038v1 [cs.CL])

    [http://arxiv.org/abs/2401.02038](http://arxiv.org/abs/2401.02038)

    本文提供了一份综合概述，介绍了大规模语言模型（LLMs）从训练到推理的演变过程，并探讨了这一新兴趋势中与成本效率相关的训练和部署方法。同时，还讨论了推理阶段的模型压缩、并行计算、内存调度和结构优化等关键主题，为LLMs的利用和未来发展提供了见解。

    

    ChatGPT的引入导致了大规模语言模型（LLMs）在解决下游任务中的大量使用。在这个背景下，对于成本效率的关注越来越多。低成本的LLMs训练和部署代表了未来的发展趋势。本文回顾了与这一新兴趋势相一致的大规模语言模型训练技术和推理部署技术的演变。训练的讨论包括数据预处理、训练架构、预训练任务、并行训练以及与模型微调相关的内容。在推理方面，本文涵盖了模型压缩、并行计算、内存调度和结构优化等主题。它还探讨了LLMs的利用并提供了对其未来发展的见解。

    The introduction of ChatGPT has led to a significant increase in the utilization of Large Language Models (LLMs) for addressing downstream tasks. There's an increasing focus on cost-efficient training and deployment within this context. Low-cost training and deployment of LLMs represent the future development trend. This paper reviews the evolution of large language model training techniques and inference deployment technologies aligned with this emerging trend. The discussion on training includes various aspects, including data preprocessing, training architecture, pre-training tasks, parallel training, and relevant content related to model fine-tuning. On the inference side, the paper covers topics such as model compression, parallel computation, memory scheduling, and structural optimization. It also explores LLMs' utilization and provides insights into their future development.
    
[^22]: Text2MDT: 从医学文本中提取医学决策树

    Text2MDT: Extracting Medical Decision Trees from Medical Texts. (arXiv:2401.02034v1 [cs.CL])

    [http://arxiv.org/abs/2401.02034](http://arxiv.org/abs/2401.02034)

    本研究提出了一个新颖的任务，Text2MDT，旨在从医学文本中自动提取医学决策树。通过两种不同的方法进行实验，结果表明基于大型语言模型的端到端方法显示出有希望的结果。

    

    对医疗决策过程的知识，可以建模为医学决策树（MDT），对于构建临床决策支持系统至关重要。然而，目前的MDT构建方法严重依赖耗时繁琐的手动注释。在本研究中，我们提出了一个新颖的任务，Text2MDT，旨在探索从医学文本（如医学指南和教材）中自动提取MDT。我们规范了MDT的形式，并与医学专家一起创建了一个中文的标注文本到MDT数据集。我们研究了Text2MDT任务的两种不同方法：（a）一种仅依赖于GPT风格的大型语言模型（LLM）指令调整来生成所有节点信息和树结构的端到端框架。 （b）将Text2MDT任务分解为三个子任务的流水线框架。在我们的Text2MDT数据集上的实验表明：（a）基于LLM（参数规模为7B或更大）的端到端方法展现了有希望的结果，

    Knowledge of the medical decision process, which can be modeled as medical decision trees (MDTs), is critical to build clinical decision support systems. However, the current MDT construction methods rely heavily on time-consuming and laborious manual annotation. In this work, we propose a novel task, Text2MDT, to explore the automatic extraction of MDTs from medical texts such as medical guidelines and textbooks. We normalize the form of the MDT and create an annotated Text-to-MDT dataset in Chinese with the participation of medical experts. We investigate two different methods for the Text2MDT tasks: (a) an end-to-end framework which only relies on a GPT style large language models (LLM) instruction tuning to generate all the node information and tree structures. (b) The pipeline framework which decomposes the Text2MDT task to three subtasks. Experiments on our Text2MDT dataset demonstrate that: (a) the end-to-end method basd on LLMs (7B parameters or larger) show promising results, 
    
[^23]: 自我对比：通过不一致的求解视角获得更好的反思能力

    Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives. (arXiv:2401.02009v1 [cs.CL])

    [http://arxiv.org/abs/2401.02009](http://arxiv.org/abs/2401.02009)

    自我对比是一种通过对比不同求解视角和总结差异，提高大型语言模型（LLM）的反思能力的方法。

    

    大型语言模型（LLM）的反思能力引起了广泛关注。一种事后提示策略，例如反思和自我改进，根据自我评估或外部反馈来改善LLM的响应。然而，最近的研究表明，在没有外部反馈的情况下，LLM的内在反思是不稳定的。我们的调查揭示了自我评估反馈质量是关键瓶颈。我们发现LLM在自我评估时常常表现出过度自信或高度随机性，提供固执或不一致的反馈，导致反思能力不佳。为了解决这个问题，我们提出了自我对比的方法：它根据请求自适应地探索多样的求解视角，对比差异，并将这些差异总结为一个检查表，用于重新审视和消除差异。我们的方法赋予LLM多样的视角以减轻固执偏见。此外，差异指示了潜在的错误或固有的不确定性。

    The reflection capacity of Large Language Model (LLM) has garnered extensive attention. A post-hoc prompting strategy, e.g., reflexion and self-refine, refines LLM's response based on self-evaluated or external feedback. However, recent research indicates without external feedback, LLM's intrinsic reflection is unstable. Our investigation unveils that the key bottleneck is the quality of the self-evaluated feedback. We find LLMs often exhibit overconfidence or high randomness when self-evaluate, offering stubborn or inconsistent feedback, which causes poor reflection. To remedy this, we advocate Self-Contrast: It adaptively explores diverse solving perspectives tailored to the request, contrasts the differences, and summarizes these discrepancies into a checklist which could be used to re-examine and eliminate discrepancies. Our method endows LLM with diverse perspectives to alleviate stubborn biases. Moreover, their discrepancies indicate potential errors or inherent uncertainties tha
    
[^24]: 重访大语言模型时代下的零-shot 抽象摘要，从位置偏见的角度出发

    Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias. (arXiv:2401.01989v1 [cs.CL])

    [http://arxiv.org/abs/2401.01989](http://arxiv.org/abs/2401.01989)

    这项研究通过测量位置偏见，重访了大语言模型中的零-shot 抽象摘要。研究结果揭示了模型不公平地优先考虑某些部分的信息，从而导致不可取的行为。对多个LLM模型和预训练抽象摘要模型进行的实验提供了关于零-shot 总结任务的模型性能和位置偏见的新见解和讨论。

    

    我们通过测量位置偏见来表征和研究大型语言模型（LLMs）中的零-shot 抽象摘要，我们将其视为先前文献中研究过的更为限制性的引导偏见现象的一般表述。位置偏见捕捉到模型在输入文本的某些部分上不公平地优先考虑信息，导致不可取的行为。通过对四个不同的真实数据集进行大量实验，我们研究了多个LLM模型如GPT 3.5-Turbo，Llama-2和Dolly-v2中的位置偏见，以及当前最先进的预训练编码器-解码器抽象摘要模型如Pegasus和BART。我们的发现为零-shot 总结任务的模型性能和位置偏见提供了新的见解和讨论。

    We characterize and study zero-shot abstractive summarization in Large Language Models (LLMs) by measuring position bias, which we propose as a general formulation of the more restrictive lead bias phenomenon studied previously in the literature. Position bias captures the tendency of a model unfairly prioritizing information from certain parts of the input text over others, leading to undesirable behavior. Through numerous experiments on four diverse real-world datasets, we study position bias in multiple LLM models such as GPT 3.5-Turbo, Llama-2, and Dolly-v2, as well as state-of-the-art pretrained encoder-decoder abstractive summarization models such as Pegasus and BART. Our findings lead to novel insights and discussion on performance and position bias of models for zero-shot summarization tasks.
    
[^25]: 对齐算法的机制理解：基于DPO和毒性的案例研究

    A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity. (arXiv:2401.01967v1 [cs.CL])

    [http://arxiv.org/abs/2401.01967](http://arxiv.org/abs/2401.01967)

    通过研究对齐算法和预训练语言模型，本论文揭示了对齐模型的机制，并提出了一种简单的方法来取消模型的对齐，从而使其恢复有害行为。

    

    虽然对齐算法现在常用于调整预训练语言模型以适应用户喜好，但我们缺乏解释模型如何“对齐”的基本机制，因此难以解释诸如越狱等现象。本研究中，我们研究了一种常见的算法——直接偏好优化（DPO），以及它如何降低毒性的机制。具体而言，我们首先研究了毒性在预训练语言模型GPT2-medium中的表示和唤起方式。然后，我们使用精心设计的成对数据集应用DPO来降低毒性。我们检查了生成模型是如何避免输出有害结果的，并发现预训练学到的能力并没有被移除，而是被绕过。我们利用这一观察结果展示了一种简单的方法来取消模型的对齐，将其恢复为有害行为。

    While alignment algorithms are now commonly used to tune pre-trained language models towards a user's preferences, we lack explanations for the underlying mechanisms in which models become ``aligned'', thus making it difficult to explain phenomena like jailbreaks. In this work we study a popular algorithm, direct preference optimization (DPO), and the mechanisms by which it reduces toxicity. Namely, we first study how toxicity is represented and elicited in a pre-trained language model, GPT2-medium. We then apply DPO with a carefully crafted pairwise dataset to reduce toxicity. We examine how the resulting model averts toxic outputs, and find that capabilities learned from pre-training are not removed, but rather bypassed. We use this insight to demonstrate a simple method to un-align the model, reverting it back to its toxic behavior.
    
[^26]: Instruct-Imagen: 带有多模式指令的图像生成

    Instruct-Imagen: Image Generation with Multi-modal Instruction. (arXiv:2401.01952v1 [cs.CV])

    [http://arxiv.org/abs/2401.01952](http://arxiv.org/abs/2401.01952)

    Instruct-Imagen是一种处理异构图像生成任务并进行泛化的模型，引入了多模式指令以实现各种生成意图的统一标准化。通过微调预训练的文本到图像扩散模型，并使用检索增强的训练提升模型在外部多模态环境下的生成能力。对多样化图像生成任务的人工评估表明，该模型取得了良好的效果。

    

    本文提出了Instruct-Imagen，这是一种处理异构图像生成任务并在未见任务中进行泛化的模型。我们引入了多模式指令用于图像生成，这是一种任务表示方法，可以精确地表达各种生成意图。它使用自然语言来整合不同的模态（例如文本、边缘、风格、主题等），使得丰富的生成意图能够以统一的格式标准化。然后，我们通过微调预训练的文本到图像扩散模型构建了Instruct-Imagen的两阶段框架。首先，我们使用检索增强的训练来使模型能够在外部多模态环境下基于其生成。然后，我们在需要视觉-语言理解的多样化图像生成任务中对这个调整后的模型进行微调，每个任务都配对一个包含任务本质的多模式指令。对各种图像生成任务的人工评估表明，

    This paper presents instruct-imagen, a model that tackles heterogeneous image generation tasks and generalizes across unseen tasks. We introduce *multi-modal instruction* for image generation, a task representation articulating a range of generation intents with precision. It uses natural language to amalgamate disparate modalities (e.g., text, edge, style, subject, etc.), such that abundant generation intents can be standardized in a uniform format.  We then build instruct-imagen by fine-tuning a pre-trained text-to-image diffusion model with a two-stage framework. First, we adapt the model using the retrieval-augmented training, to enhance model's capabilities to ground its generation on external multimodal context. Subsequently, we fine-tune the adapted model on diverse image generation tasks that requires vision-language understanding (e.g., subject-driven generation, etc.), each paired with a multi-modal instruction encapsulating the task's essence. Human evaluation on various ima
    
[^27]: 通用嵌入模型在短语境临床语义搜索方面表现比专业嵌入模型更好

    Generalist embedding models are better at short-context clinical semantic search than specialized embedding models. (arXiv:2401.01943v1 [cs.CL])

    [http://arxiv.org/abs/2401.01943](http://arxiv.org/abs/2401.01943)

    本研究发现，在临床语义搜索方面，通用嵌入模型比专业嵌入模型表现更好，这表明现有的临床专业化模型对输入的微小变化更敏感。

    

    基于大型语言模型（LLM）的工具和解决方案在医疗领域的应用日益增多，这已成为一个重要趋势。然而，在这个高度关键和敏感的领域中使用它们对其稳健性产生了重要的问题，特别是对输入变化和生成的输出的可靠性。本研究通过构建基于ICD-10-CM代码描述的文本数据集来解决这些问题，该数据集广泛应用于美国医院，包含许多临床术语及其易于复制的改写。然后，我们在语义搜索任务中对现有的通用或临床专业化的嵌入模型进行了基准测试，目标是正确匹配改写的文本与原始描述。我们的结果表明，通用模型比临床模型表现更好，这表明现有的临床专业化模型对输入的微小变化更敏感，从而使其困惑。

    The increasing use of tools and solutions based on Large Language Models (LLMs) for various tasks in the medical domain has become a prominent trend. Their use in this highly critical and sensitive domain has thus raised important questions about their robustness, especially in response to variations in input, and the reliability of the generated outputs. This study addresses these questions by constructing a textual dataset based on the ICD-10-CM code descriptions, widely used in US hospitals and containing many clinical terms, and their easily reproducible rephrasing. We then benchmarked existing embedding models, either generalist or specialized in the clinical domain, in a semantic search task where the goal was to correctly match the rephrased text to the original description. Our results showed that generalist models performed better than clinical models, suggesting that existing clinical specialized models are more sensitive to small changes in input that confuse them. The highl
    
[^28]: AstroLLaMA-Chat: 使用对话和多样化数据集扩展AstroLLaMA

    AstroLLaMA-Chat: Scaling AstroLLaMA with Conversational and Diverse Datasets. (arXiv:2401.01916v1 [astro-ph.IM])

    [http://arxiv.org/abs/2401.01916](http://arxiv.org/abs/2401.01916)

    通过有针对性和持续的预训练，我们在天文学问题回答中扩展了AstroLLaMA，通过使用紧凑的LLaMA-2模型和专门的天文学语料库，我们实现了在专门主题理解方面的显著改进。我们还通过对特定领域的对话数据集进行微调，发布了带有聊天功能的AstroLLaMA。

    

    通过有针对性和持续的预训练，我们探索了在天文学问题回答中增强LLM性能的潜力。通过使用一个紧凑的7B参数的LLaMA-2模型，并且专注于一组经过筛选的天文学语料库，包括摘要、介绍和结论，我们在专门主题理解方面取得了显著的改进。虽然像GPT-4这样的通用LLMs在更广泛的问题回答场景中由于更强大的推理能力而表现出色，但我们的发现表明，有限资源的持续预训练仍然可以提高模型在专门主题上的性能。此外，我们提出了AstroLLaMA的扩展：在特定领域的对话数据集上对7B LLaMA模型进行微调，最终发布了适用于社区使用的具有聊天功能的AstroLLaMA。全面的定量基准测试正在进行中，并将在即将发布的完整论文中详细介绍。模型AstroLLaMA-Chat现已在...

    We explore the potential of enhancing LLM performance in astronomy-focused question-answering through targeted, continual pre-training. By employing a compact 7B-parameter LLaMA-2 model and focusing exclusively on a curated set of astronomy corpus -- comprising abstracts, introductions, and conclusions -- we achieve notable improvements in specialized topic comprehension. While general LLMs like GPT-4 outperform in broader question-answering scenarios due to superior reasoning capabilities, our findings suggest that continual pre-training with limited resources can still enhance model performance on specialized topics. Additionally, we present an extension of AstroLLaMA: the fine-tuning of the 7B LLaMA model on a domain-specific conversational dataset, culminating in the release of the chat-enabled AstroLLaMA for community use. Comprehensive quantitative benchmarking is currently in progress and will be detailed in an upcoming full paper. The model, AstroLLaMA-Chat, is now available at
    
[^29]: 利用目标分析视角进行跨目标立场检测

    Cross-target Stance Detection by Exploiting Target Analytical Perspectives. (arXiv:2401.01761v1 [cs.CL])

    [http://arxiv.org/abs/2401.01761](http://arxiv.org/abs/2401.01761)

    本论文提出了一种利用目标分析视角进行跨目标立场检测的方法，并使用多视角提示调整框架将自然语言解释融合到立场预测器中。

    

    跨目标立场检测(CTSD)是一项重要任务，通过利用源目标产生的注释数据来推断目的目标的态度。CTSD中的一种重要方法是提取域不变特征以填补多个目标之间的知识差距。然而，非正式和短文本结构的分析以及隐含表达使得提取域不变知识变得复杂。本文提出了一种多视角提示调整(MPPT)模型用于CTSD，该模型将分析视角作为知识传递的桥梁。首先，我们开发了一个基于指令的两阶段思维链(TsCoT)方法，通过基于大型语言模型(LLM)的指令制定，从多个视角提取目标分析视角并提供自然语言解释(NLEs)。接着，我们提出了一个多视角提示调节框架(MultiPLN)，将NLEs融合到立场预测器中。进行了大量实验来验证我们的方法。

    Cross-target stance detection (CTSD) is an important task, which infers the attitude of the destination target by utilizing annotated data derived from the source target. One important approach in CTSD is to extract domain-invariant features to bridge the knowledge gap between multiple targets. However, the analysis of informal and short text structure, and implicit expressions, complicate the extraction of domain-invariant knowledge. In this paper, we propose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the analysis perspective as a bridge to transfer knowledge. First, we develop a two-stage instruct-based chain-of-thought method (TsCoT) to elicit target analysis perspectives and provide natural language explanations (NLEs) from multiple viewpoints by formulating instructions based on large language model (LLM). Second, we propose a multi-perspective prompt-tuning framework (MultiPLN) to fuse the NLEs into the stance predictor. Extensive experiments results demons
    
[^30]: 越南诗歌生成与跨语言诗歌翻译的前景

    Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation. (arXiv:2401.01078v1 [cs.CL])

    [http://arxiv.org/abs/2401.01078](http://arxiv.org/abs/2401.01078)

    本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。

    

    诗歌生成一直是自然语言处理领域的一项挑战任务，因为它要求模型理解语言、情感和风格的细微差别。在本文中，我们提出使用大型语言模型从自然语言提示中生成越南诗歌，从而实现直观的过程和增强的内容控制。我们最有效的模型，GPT-3 Babbage变种，在越南诗歌的“六八词”类型中实现了0.8的自定义评分。此外，我们还探索了将诗歌改写成正常文本提示的想法，并在“六八词”类型中获得了相对较高的0.718分数。这个实验展示了以翻译后的诗歌作为输入进行跨语言诗歌翻译的潜力，并同时保持对生成内容的完全控制。

    Poetry generation has been a challenging task in the field of Natural Language Processing, as it requires the model to understand the nuances of language, sentiment, and style. In this paper, we propose using Large Language Models to generate Vietnamese poems from natural language prompts, thereby facilitating an intuitive process with enhanced content control. Our most efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the "luc bat" genre of Vietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.718 in the "luc bat" genre. This experiment presents the potential for cross-Language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content.
    
[^31]: 大型语言模型在视频理解中的应用：一项调查研究

    Video Understanding with Large Language Models: A Survey. (arXiv:2312.17432v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.17432](http://arxiv.org/abs/2312.17432)

    这项调查研究提供了对大型语言模型（Vid-LLMs）在视频理解中的最新进展的详细概述。Vid-LLMs的新兴能力包括开放式时空推理和常识知识，为未来的视频理解提供了有前途的方向。

    

    随着在线视频平台的不断增长和视频内容的不断增多，对熟练的视频理解工具的需求显著增加。鉴于大型语言模型在语言和多模态任务中的卓越能力，本调查提供了对利用大型语言模型（Vid-LLMs）技术进行视频理解的最新进展的详细概述。Vid-LLMs的新兴能力令人惊讶，尤其是它们在开放式时空推理和常识知识方面的能力，为未来的视频理解提供了一个有前途的方向。本调查对Vid-LLMs的独特特点和能力进行了分类，分为四种主要类型：基于LLM的视频代理、Vid-LLMs的预训练、Vid-LLMs的指令调整和混合方法。此外，本调查对Vid-LLMs的任务、数据集和评估方法进行了全面的研究。另外，它还探讨了Vid-LLMs技术的局限性和未来的挑战。

    With the burgeoning growth of online video platforms and the escalating volume of video content, the demand for proficient video understanding tools has intensified markedly. Given the remarkable capabilities of Large Language Models (LLMs) in language and multimodal tasks, this survey provides a detailed overview of the recent advancements in video understanding harnessing the power of LLMs (Vid-LLMs). The emergent capabilities of Vid-LLMs are surprisingly advanced, particularly their ability for open-ended spatial-temporal reasoning combined with commonsense knowledge, suggesting a promising path for future video understanding. We examine the unique characteristics and capabilities of Vid-LLMs, categorizing the approaches into four main types: LLM-based Video Agents, Vid-LLMs Pretraining, Vid-LLMs Instruction Tuning, and Hybrid Methods. Furthermore, this survey presents a comprehensive study of the tasks, datasets, and evaluation methodologies for Vid-LLMs. Additionally, it explores 
    
[^32]: 对抗性数据污染用于假新闻检测：如何使模型在不修改目标新闻的情况下将其错误分类

    Adversarial Data Poisoning for Fake News Detection: How to Make a Model Misclassify a Target News without Modifying It. (arXiv:2312.15228v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.15228](http://arxiv.org/abs/2312.15228)

    本文分析了对抗性攻击在假新闻检测模型中的威胁，研究了攻击者如何在不修改原始目标新闻的情况下通过引入污染数据来操纵模型的行为。

    

    假新闻检测模型对于对抗性攻击具有脆弱性。在这篇文章中，我们分析了攻击者如何在不修改原始目标新闻的情况下破坏在线学习检测器对特定新闻内容的性能。在某些情况下，例如社交网络中，攻击者无法完全控制所有信息，这种情况确实可能发生。因此，我们展示了攻击者如何可能通过将污染数据引入训练数据来操纵在线学习方法的行为。我们的初步研究结果显示，基于复杂性和攻击类型，逻辑回归模型对此的易受攻击性各不相同。

    Fake news detection models are critical to countering disinformation but can be manipulated through adversarial attacks. In this position paper, we analyze how an attacker can compromise the performance of an online learning detector on specific news content without being able to manipulate the original target news. In some contexts, such as social networks, where the attacker cannot exert complete control over all the information, this scenario can indeed be quite plausible. Therefore, we show how an attacker could potentially introduce poisoning data into the training data to manipulate the behavior of an online learning method. Our initial findings reveal varying susceptibility of logistic regression models based on complexity and attack type.
    
[^33]: 基于等变性的幻觉理论

    Theory of Hallucinations based on Equivariance. (arXiv:2312.14504v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.14504](http://arxiv.org/abs/2312.14504)

    本研究提出了基于等变性的幻觉理论，探讨了大型语言模型中幻觉的成因，并开发了一种衡量语言模型幻觉程度的交叉熵误差函数。通过测试语言模型在获得等变性方面的能力，研究表明某些类型的等变语言模型对理解复杂社交关系表现出色。

    

    本研究旨在获取创建对幻觉免疫的大型语言模型所需的知识。现代大型语言模型中的幻觉往往归因于对现实社交关系的误解。因此，我假设能够彻底掌握所有这些关系的大型语言模型将不会出现幻觉。此外，我提出了某些类型的等变语言模型在学习和理解这些关系方面表现出色。在此基础上，我开发了一种专门用于创建语言模型幻觉程度的交叉熵误差函数，该函数衡量了它们获得等变性的程度。利用这个指标，我测试了语言模型在获得字符级等变性方面的能力。特别地，我引入并采用了一种基于T5（文本到文本转换变压器）的新技术，可以高效地理解经过排列的输入文本而无需解释。

    This study aims to acquire knowledge for creating very large language models that are immune to hallucinations. Hallucinations in contemporary large language models are often attributed to a misunderstanding of real-world social relationships. Therefore, I hypothesize that very large language models capable of thoroughly grasping all these relationships will be free from hallucinations. Additionally, I propose that certain types of equivariant language models are adept at learning and understanding these relationships. Building on this, I have developed a specialized cross-entropy error function to create a hallucination scale for language models, which measures their extent of equivariance acquisition. Utilizing this scale, I tested language models for their ability to acquire character-level equivariance. In particular, I introduce and employ a novel technique based on T5 (Text To Text Transfer Transformer) that efficiently understands permuted input texts without the need for explic
    
[^34]: T-Eval: 逐步评估工具利用能力

    T-Eval: Evaluating the Tool Utilization Capability Step by Step. (arXiv:2312.14033v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.14033](http://arxiv.org/abs/2312.14033)

    T-Eval是一种逐步评估工具利用能力的方法，它将工具利用评估解耦为多个子领域，从而能够更细致地分析大型语言模型（LLM）的能力。

    

    大型语言模型（LLM）在各种NLP任务上取得了卓越的性能，并通过工具进行了更广泛的应用。然而，如何评估和分析LLM的工具利用能力仍未充分探索。与以往评估模型整体性能的工作不同，我们将工具利用全面分解为多个子过程，包括指令跟随、规划、推理、检索、理解和复查。在此基础上，我们进一步引入了T-Eval来逐步评估工具利用能力。T-Eval将工具利用评估解耦为多个子领域，有助于对LLM的整体和独立能力进行内部理解。我们对T-Eval进行了大量实验和各种LLM的深入分析。T-Eval不仅展现了与结果导向评估的一致性，还提供了对LLM能力更细致的分析，表明LLM具备了一定的能力。

    Large language models (LLM) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to evaluate and analyze the tool-utilization capability of LLMs is still under-explored. In contrast to previous works that evaluate models holistically, we comprehensively decompose the tool utilization into multiple sub-processes, including instruction following, planning, reasoning, retrieval, understanding, and review. Based on that, we further introduce T-Eval to evaluate the tool utilization capability step by step. T-Eval disentangles the tool utilization evaluation into several sub-domains along model capabilities, facilitating the inner understanding of both holistic and isolated competency of LLMs. We conduct extensive experiments on T-Eval and in-depth analysis of various LLMs. T-Eval not only exhibits consistency with the outcome-oriented evaluation but also provides a more fine-grained analysis of the capabilities of LLMs, prov
    
[^35]: 评估语言模型代理在现实自主任务中的表现

    Evaluating Language-Model Agents on Realistic Autonomous Tasks. (arXiv:2312.11671v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11671](http://arxiv.org/abs/2312.11671)

    这篇论文评估了语言模型代理在现实自主任务中的表现，发现这些代理只能完成最简单的任务，对于更具挑战性的任务有一定进展。

    

    在这篇报告中，我们探索了语言模型代理在野外获取资源、复制自身和适应新挑战的能力。我们称这些能力为"自主复制和适应"或者ARA。我们认为具备ARA能力的系统可能具有广泛而难以预测的后果，并且对于衡量和预测ARA能力可能有助于制定相关的安全、监测和对齐措施。此外，一旦系统具备ARA能力，对系统能力的限制可能变得更加困难。我们构建了四个简单的示例代理，将语言模型与允许其在世界中采取行动的工具相结合。然后，我们对这些代理在与ARA相关的12个任务上进行评估。我们发现这些语言模型代理只能完成任务列表中最简单的任务，尽管对于更具挑战性的任务也有一定的进展。不幸的是，这些评估还没有完成。

    In this report, we explore the ability of language model agents to acquire resources, create copies of themselves, and adapt to novel challenges they encounter in the wild. We refer to this cluster of capabilities as "autonomous replication and adaptation" or ARA. We believe that systems capable of ARA could have wide-reaching and hard-to-anticipate consequences, and that measuring and forecasting ARA may be useful for informing measures around security, monitoring, and alignment. Additionally, once a system is capable of ARA, placing bounds on a system's capabilities may become significantly more difficult.  We construct four simple example agents that combine language models with tools that allow them to take actions in the world. We then evaluate these agents on 12 tasks relevant to ARA. We find that these language model agents can only complete the easiest tasks from this list, although they make some progress on the more challenging tasks. Unfortunately, these evaluations are not 
    
[^36]: 作为大型语言模型的指导数据探索者的单次学习方法

    One Shot Learning as Instruction Data Prospector for Large Language Models. (arXiv:2312.10302v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.10302](http://arxiv.org/abs/2312.10302)

    本研究提出了一种名为Nuggets的新颖有效方法，利用单次学习从庞大的数据集中选择高质量的指导数据，通过评估示例对多样锚定集的困惑度影响，选择对指导调优最有益的数据

    

    将大型语言模型与人类对齐是有效利用其预训练能力的关键步骤。当前的指导调优方法通常依赖于扩展数据集大小，但缺乏确保数据质量的明确策略，这可能无意中引入噪声并降低模型性能。为了应对这一挑战，我们引入了一种新颖高效的方法Nuggets，该方法利用单次学习从庞大的数据集中选择高质量的指导数据。Nuggets评估单个指导示例作为有效单次示例的潜力，从而识别可以显著提升各种任务性能的示例。Nuggets利用基于候选示例对多样锚定集的困惑度影响的评分系统，有助于选择对指导调优最有益的数据。通过在两个基准测试集MT-Bench和Alpaca-Ev上进行严格测试

    Aligning large language models(LLMs) with human is a critical step in effectively utilizing their pre-trained capabilities across a wide array of language tasks. Current instruction tuning practices often rely on expanding dataset size without a clear strategy for ensuring data quality, which can inadvertently introduce noise and degrade model performance. To address this challenge, we introduce Nuggets, a novel and efficient methodology that employs one shot learning to select high-quality instruction data from expansive datasets. Nuggets assesses the potential of individual instruction examples to act as effective one shot examples, thereby identifying those that can significantly enhance diverse task performance. Nuggets utilizes a scoring system based on the impact of candidate examples on the perplexity of a diverse anchor set, facilitating the selection of the most beneficial data for instruction tuning. Through rigorous testing on two benchmarks, including MT-Bench and Alpaca-Ev
    
[^37]: UstanceBR:一种用于目标立场预测的多模态语言资源

    UstanceBR: a multimodal language resource for stance prediction. (arXiv:2312.06374v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.06374](http://arxiv.org/abs/2312.06374)

    UstanceBR是一个多模态语言资源，用于目标立场预测，包含巴西葡萄牙语Twitter领域的86.8k标记立场和发布者的网络信息。这个研究为未来的研究提供了初始基准结果。

    

    本研究介绍了UstanceBR，这是一个用于巴西葡萄牙语Twitter领域的多模态语料库，用于目标立场预测。该语料库包含对所选目标主题的86.8k标记立场，并且包含了发布这些立场的社交媒体用户的广泛网络信息。在本文中，我们描述了语料库的多模态数据，并提供了基于文本和网络相关信息的领域内和零样本立场预测的多个使用示例，旨在为未来的研究提供初始基准结果。

    This work introduces UstanceBR, a multimodal corpus in the Brazilian Portuguese Twitter domain for target-based stance prediction. The corpus comprises 86.8 k labelled stances towards selected target topics, and extensive network information about the users who published these stances on social media. In this article we describe the corpus multimodal data, and a number of usage examples in both in-domain and zero-shot stance prediction based on textand network-related information, which are intended to provide initial baseline results for future studies in the field.
    
[^38]: TEAL: 对于多模态大语言模型的一种将所有模态进行分词和嵌入的方法

    TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models. (arXiv:2311.04589v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04589](http://arxiv.org/abs/2311.04589)

    TEAL是一种用于多模态大语言模型的方法，将不同模态的输入视为令牌序列，并学习它们的联合嵌入空间。这使得模型能够有效地建模多模态输入之间的相互作用，并生成非文本模态的输出。

    

    尽管多模态大语言模型（MM-LLMs）最近取得了令人兴奋的进展，但它们仍然在有效地建模多模态输入之间的相互作用和非文本模态的生成方面面临困难。在这项工作中，我们提出了一种名为TEAL（Tokenize and Embed ALL）的方法，将任何模态的输入视为令牌序列，并学习所有模态的联合嵌入空间。具体而言，对于任何模态的输入，TEAL首先使用现成的分词器将其离散化为令牌序列，然后使用可学习的嵌入矩阵将令牌序列嵌入到联合嵌入空间中。MM-LLMs只需要像文本LLMs那样自回归地预测多模态令牌。最后，根据预测的令牌序列，应用相应的去分词器生成每个模态的输出。通过联合嵌入空间，TEAL使冻结的LLMs能够执行涉及非文本模态的理解和生成任务，如理解和生成图像或音频。

    Despite Multi-modal Large Language Models (MM-LLMs) have made exciting strides recently, they are still struggling to efficiently model the interactions among multi-modal inputs and the generation in non-textual modalities. In this work, we propose TEAL (Tokenize and Embed ALl)}, an approach to treat the input from any modality as a token sequence and learn a joint embedding space for all modalities. Specifically, for the input from any modality, TEAL first discretizes it into a token sequence with the off-the-shelf tokenizer and embeds the token sequence into a joint embedding space with a learnable embedding matrix. MM-LLMs just need to predict the multi-modal tokens autoregressively as the textual LLMs do. Finally, the corresponding de-tokenizer is applied to generate the output in each modality based on the predicted token sequence. With the joint embedding space, TEAL enables the frozen LLMs to perform both understanding and generation tasks involving non-textual modalities, such 
    
[^39]: GIT-Mol：一种多模态大型语言模型用于分子科学中的图像，图形和文本

    GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text. (arXiv:2308.06911v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.06911](http://arxiv.org/abs/2308.06911)

    GIT-Mol是一种多模态大型语言模型，可在分子科学中处理图像、图形和文本信息。通过新提出的GIT-Former架构，该模型能够将多种模态的数据对齐到一个统一的潜在空间中。与基线相比，GIT-Mol在性质预测和分子生成有效性方面取得了显著改进。此外，该模型还可用于化合物名称识别和化学反应预测等下游任务。

    

    大型语言模型在自然语言处理方面取得了重要进展，通过处理分子的文本表示，为分子科学中的创新应用提供了可能。然而，大多数现有的语言模型无法捕捉具有复杂分子结构或图像的丰富信息。在本文中，我们引入了GIT-Mol，一种集成了图形、图像和文本信息的多模态大型语言模型。为了促进多模态分子数据的集成，我们提出了GIT-Former，一种新颖的架构，能够将所有模态对齐到统一的潜在空间中。与基线相比，我们在性质预测方面实现了5%-10%的准确性提高，并在分子生成有效性方面提高了20.2%。通过任意到语言的分子翻译策略，我们的模型有潜力进行更多的下游任务，例如化合物名称识别和化学反应预测。

    Large language models have made significant strides in natural language processing, enabling innovative applications in molecular science by processing textual representations of molecules. However, most existing language models cannot capture the rich information with complex molecular structures or images. In this paper, we introduce GIT-Mol, a multi-modal large language model that integrates the Graph, Image, and Text information. To facilitate the integration of multi-modal molecular data, we propose GIT-Former, a novel architecture that is capable of aligning all modalities into a unified latent space. We achieve a 5%-10% accuracy increase in properties prediction and a 20.2% boost in molecule generation validity compared to the baselines. With the any-to-language molecular translation strategy, our model has the potential to perform more downstream tasks, such as compound name recognition and chemical reaction prediction.
    
[^40]: 感觉麻木还是有共情能力？利用EmotionBench评估LLMs的情感能力

    Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench. (arXiv:2308.03656v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03656](http://arxiv.org/abs/2308.03656)

    通过利用心理学中的情感评估理论，本研究提出利用EmotionBench评估LLMs的共情能力。通过人类评估和对五个LLMs的研究发现，尽管存在一些不一致之处，LLMs通常能在某些情境下适当地回应，但与情感对齐方面还存在不足。

    

    在当代话语中，评估大型语言模型（LLMs）的拟人能力变得越来越重要。利用心理学中的情感评估理论，我们提出评估LLMs的共情能力，即它们在特定情境下感受变化的能力。通过仔细而全面的调查，我们收集了一个包含超过400种情境的数据集，这些情境已被证明对我们研究的八种情感至关重要。将这些情境分为36个因素，我们进行了一项涉及全球1200多名被试的人类评估。以人类评估结果为参考，我们评估了五个LLMs，涵盖了商业和开源模型，包括模型大小的变化，以及最新的迭代版本（如GPT-4和LLaMA-2）。我们发现，尽管存在一些不一致之处，LLMs通常能在某些情境下适当地回应。然而，它们在与情感对齐方面还存在一定不足。

    Evaluating Large Language Models' (LLMs) anthropomorphic capabilities has become increasingly important in contemporary discourse. Utilizing the emotion appraisal theory from psychology, we propose to evaluate the empathy ability of LLMs, i.e., how their feelings change when presented with specific situations. After a careful and comprehensive survey, we collect a dataset containing over 400 situations that have proven effective in eliciting the eight emotions central to our study. Categorizing the situations into 36 factors, we conduct a human evaluation involving more than 1,200 subjects worldwide. With the human evaluation results as references, our evaluation includes five LLMs, covering both commercial and open-source models, including variations in model sizes, featuring the latest iterations, such as GPT-4 and LLaMA-2. We find that, despite several misalignments, LLMs can generally respond appropriately to certain situations. Nevertheless, they fall short in alignment with the e
    
[^41]: 在大型语言模型中释放认知协同：通过多人格自我协作实现任务解决代理

    Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration. (arXiv:2307.05300v1 [cs.AI])

    [http://arxiv.org/abs/2307.05300](http://arxiv.org/abs/2307.05300)

    本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。

    

    人类智慧依赖于认知协同的概念，即在不同认知过程之间进行协作和信息整合，以获得比个体认知过程更出色的结果。尽管大型语言模型（LLM）作为通用任务解决代理表现出了令人期待的性能，但它们在需要丰富领域知识和复杂推理的任务上仍然面临困难。在这项工作中，我们提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个LLM转化为认知协同者。认知协同者指的是一个智能代理，与多个智慧合作，结合他们的个体优势和知识，从而增强复杂任务的问题解决能力和整体性能。通过根据任务输入动态识别和模拟不同的角色，SPP释放了LLM中认知协同的潜力。

    Human intelligence thrives on the concept of cognitive synergy, where collaboration and information integration among different cognitive processes yield superior outcomes compared to individual cognitive processes in isolation. Although Large Language Models (LLMs) have demonstrated promising performance as general task-solving agents, they still struggle with tasks that require intensive domain knowledge and complex reasoning. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist refers to an intelligent agent that collaborates with multiple minds, combining their individual strengths and knowledge, to enhance problem-solving and overall performance in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. We have discovered that assi
    
[^42]: Tweet帖子上的层次对齐多模态学习用于NER

    Hierarchical Aligned Multimodal Learning for NER on Tweet Posts. (arXiv:2305.08372v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08372](http://arxiv.org/abs/2305.08372)

    本文提出了一种新颖的方法用于多模态命名实体识别（MNER）的改进，该方法通过动态对齐图像和文本序列，并实现多级跨模态学习来增强文本词表示。实验证明了该方法的有效性。

    

    使用命名实体识别（NER）从推文中挖掘结构化知识可以对推荐和意图理解等许多下游应用有益。由于推文倾向于是多模态的，多模态命名实体识别（MNER）引起了更多的关注。本文提出了一种新颖的方法，可以动态地对齐图像和文本序列，并实现多级跨模态学习，以增强MNER的文本词表示。具体而言，我们的框架可以分为三个主要阶段：第一阶段专注于内部模态表示学习，以推导出每个模态的隐含全局和局部知识。第二阶段评估文本与其伴随图像之间的相关性，并根据相关性整合不同粒度的视觉信息。第三阶段通过迭代跨模态交互和共同关注强化语义细化。我们在两个公开数据集上进行了实验证明了我们方法的有效性。

    Mining structured knowledge from tweets using named entity recognition (NER) can be beneficial for many down stream applications such as recommendation and intention understanding. With tweet posts tending to be multimodal, multimodal named entity recognition (MNER) has attracted more attention. In this paper, we propose a novel approach, which can dynamically align the image and text sequence and achieve the multi-level cross-modal learning to augment textual word representation for MNER improvement. To be specific, our framework can be split into three main stages: the first stage focuses on intra-modality representation learning to derive the implicit global and local knowledge of each modality, the second evaluates the relevance between the text and its accompanying image and integrates different grained visual information based on the relevance, the third enforces semantic refinement via iterative cross-modal interactions and co-attention. We conduct experiments on two open datase
    
[^43]: 视频聊天：以聊天为核心的视频理解系统

    VideoChat: Chat-Centric Video Understanding. (arXiv:2305.06355v1 [cs.CV])

    [http://arxiv.org/abs/2305.06355](http://arxiv.org/abs/2305.06355)

    本文提出了以聊天为核心的视频理解系统VideoChat，它通过可学习的神经接口将视频基础模型和大型语言模型集成在一起，擅长于时空推理、事件定位和因果关系推断。作者还提出了一个视频为中心的指令数据集，初步实验表明该系统在广泛的视频应用中具有潜力。

    

    本文提出了视频聊天（VideoChat）——一个端到端的以聊天为核心的视频理解系统，它通过可学习的神经接口将视频基础模型和大型语言模型集成在一起，擅长于时空推理、事件定位和因果关系推断。为了教授该系统的使用，我们提出了一个视频为中心的指令数据集，包含成千上万个视频和详细的描述和对话，这个数据集强调时空推理和因果关系，为培训以聊天为核心的视频理解系统提供了宝贵的资产。初步的定性实验揭示了我们的系统在广泛的视频应用中的潜力，并为未来的研究设定了标准。我们的代码和数据可以在 https://github.com/OpenGVLab/Ask-Anything 上获取。

    In this study, we initiate an exploration into video understanding by introducing VideoChat, an end-to-end chat-centric video understanding system. It integrates video foundation models and large language models via a learnable neural interface, excelling in spatiotemporal reasoning, event localization, and causal relationship inference. To instructively tune this system, we propose a video-centric instruction dataset, composed of thousands of videos matched with detailed descriptions and conversations. This dataset emphasizes spatiotemporal reasoning and causal relationships, providing a valuable asset for training chat-centric video understanding systems. Preliminary qualitative experiments reveal our system's potential across a broad spectrum of video applications and set the standard for future research. Access our code and data at https://github.com/OpenGVLab/Ask-Anything
    
[^44]: SemEval-2023任务11的Lon-ea：软硬标签预测中激活函数的比较。

    Lon-ea at SemEval-2023 Task 11: A Comparison of Activation Functions for Soft and Hard Label Prediction. (arXiv:2303.02468v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.02468](http://arxiv.org/abs/2303.02468)

    本研究研究了在软硬标签预测中，不同激活函数对于深度神经网络模型输出的影响，并引入了一种新的正弦激活函数。

    

    我们研究在学习不同意任务的软硬标签预测中，深度神经网络模型输出层中不同激活函数的影响。在该任务中，目标是通过预测软标签来量化不同意量。为了预测软标签，我们使用基于BERT的预处理器和编码器，并改变输出层中使用的激活函数，同时保持其他参数不变。然后将软标签用于硬标签预测。考虑的激活函数包括sigmoid函数以及添加到模型中的阶跃函数和本文中首次介绍的正弦激活函数。

    We study the influence of different activation functions in the output layer of deep neural network models for soft and hard label prediction in the learning with disagreement task. In this task, the goal is to quantify the amount of disagreement via predicting soft labels. To predict the soft labels, we use BERT-based preprocessors and encoders and vary the activation function used in the output layer, while keeping other parameters constant. The soft labels are then used for the hard label prediction. The activation functions considered are sigmoid as well as a step-function that is added to the model post-training and a sinusoidal activation function, which is introduced for the first time in this paper.
    
[^45]: 媒体如何谈论新冠疫情？意大利线上报纸中的隐喻主题聚类分析

    How do media talk about the Covid-19 pandemic? Metaphorical thematic clustering in Italian online newspapers. (arXiv:2204.02106v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.02106](http://arxiv.org/abs/2204.02106)

    本研究通过对意大利线上报纸在新冠疫情初期使用的比喻语言进行定量和定性分析，发现政府对疫情应对的不同阶段存在显著变化，并且不同主题之间存在有趣的隐喻重叠。

    

    本研究探讨了意大利线上报纸在新冠疫情爆发的头几个月中使用的比喻语言。特别地，我们对2020年春季政府对疫情应对的第一阶段和第二阶段的主题和隐喻语言进行了对比分析。研究基于2020年2月24日至6月3日期间采集的新闻语料进行，并结合了定量和定性方法，包括结构主题建模、概念隐喻理论和基于语料库的隐喻分析。我们发现在第一阶段和第二阶段讨论的主题方面存在显著变化，并且主题之间存在有趣的隐喻重叠。通过定性语料库分析，我们展示了经济和社会主题的隐喻搭配的更深入案例研究。

    The contribution presents a study on figurative language of the first months of the COVID-19 crisis in Italian online newspapers. Particularly, we contrast topics and metaphorical language used by journalists in the first and second phase of the government response to the pandemic in Spring 2020. The analysis is conducted on a journalistic corpus collected between February 24th and June 3rd, 2020. The analysis is performed using both quantitative and qualitative approaches, combining Structural Topic Modelling (Roberts et al. 2016), Conceptual Metaphor Theory (Lakoff & Johnson, 1980), and qualitative-corpus based metaphor analysis (Charteris-Black, 2004). We find a significant shift in topics discussed across Phase 1 and Phase 2, and interesting overlaps in topic-specific metaphors. Using qualitative corpus analysis, we present a more in-depth case study discussing metaphorical collocations of the topics of Economy and Society
    

