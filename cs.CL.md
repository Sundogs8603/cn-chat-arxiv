# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Sparse Autoencoders Find Highly Interpretable Features in Language Models.](http://arxiv.org/abs/2309.08600) | 本研究通过稀疏自编码器在语言模型中发现了一组高度可解释和单一义的特征，从而解决了神经网络内部多义性的问题。 |
| [^2] | ["Merge Conflicts!" Exploring the Impacts of External Distractors to Parametric Knowledge Graphs.](http://arxiv.org/abs/2309.08594) | 本研究探索了外部干扰对参数化知识图谱的影响，通过引入不同程度、方法、位置和格式的干扰因素，发现大型语言模型倾向于产生与其参数化知识不一致的回复。 |
| [^3] | [Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings.](http://arxiv.org/abs/2309.08591) | 本文研究了多语言LLMs在对话环境中运用谚语和俗语进行推理的能力，发现mLLMs在理解比喻性谚语、选择正确答案和推理其他语言的谚语时存在困难。 |
| [^4] | [Neural Machine Translation Models Can Learn to be Few-shot Learners.](http://arxiv.org/abs/2309.08590) | 本研究展示了只需进行微调就可以训练一种更小的模型，使其具备上下文学习的能力，即使用少样本示例进行自适应，从而提高神经机器翻译的领域自适应任务的效果，并超过了传统监督技术和大型语言模型的表现。 |
| [^5] | [Chain-of-Thought Reasoning is a Policy Improvement Operator.](http://arxiv.org/abs/2309.08589) | 大型语言模型SECToR通过链式思考推理成功地自学新技能， |
| [^6] | [ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer.](http://arxiv.org/abs/2309.08583) | 本研究提出了一个框架，使用模型蒸馏增强和改进正式风格转移数据集的解释，并提出了一种新颖的方法，通过上下文学习和专家反馈进一步优化生成的解释。 |
| [^7] | [Casteist but Not Racist? Quantifying Disparities in Large Language Model Bias between India and the West.](http://arxiv.org/abs/2309.08573) | 本研究量化了大型语言模型在印度和西方上的陈规偏见差异，并开发了一个新的数据集来评估种姓和宗教上的刻板印象。研究发现大多数测试的模型在印度背景下对刻板印象有显著偏见，尤其是与西方背景相比。此外，研究探索了一种简单干预方法来减轻这种偏见的效果。 |
| [^8] | [How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?.](http://arxiv.org/abs/2309.08565) | 本文研究了如何将预训练的多语言翻译模型中的属性控制器迁移到没有监督数据的语言。通过全面分析不同数据场景下的训练和推断时控制技术，揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。 |
| [^9] | [Augmenting conformers with structured state space models for online speech recognition.](http://arxiv.org/abs/2309.08551) | 本文研究通过将结构化状态空间序列模型（S4）与卷积相结合，增强在线语音识别的神经编码器，并在Librispeech的测试集上取得了较低的识别错误率。 |
| [^10] | [When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets.](http://arxiv.org/abs/2309.08541) | 通过对11种扩展技术、12个不同分布变化的数据集和24个检索模型的全面分析，我们发现使用大型语言模型进行查询或文档扩展的效果与检索器性能相关，对于弱模型来说扩展提高了分数，但对于强模型来说扩展通常会损害分数。 |
| [^11] | [Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers.](http://arxiv.org/abs/2309.08532) | 本文提出了一种通过连接大型语言模型和进化算法进行提示优化的框架，名为EvoPrompt。通过利用大型语言模型的语言处理能力和进化算法的优化性能，EvoPrompt可以自动化处理需要连贯和可读性良好的提示，提高大型语言模型的性能。 |
| [^12] | [Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens.](http://arxiv.org/abs/2309.08531) | 本文提出了一种实现实用高效的图像到语音字幕生成的方法。通过引入来自大规模预训练的视觉语言模型的知识，并将其融入到Im2Sp模型中，以实现更好的性能。通过视觉语言预训练策略，在COOC和Flickr8k两个基准数据库上刷新了Im2Sp的最佳性能。同时，还改进了Im2Sp模型的效率。 |
| [^13] | [HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking.](http://arxiv.org/abs/2309.08503) | 本文介绍了一份新的健康声明数据集，其中包含了750个由医学专家标注的健康相关声明，并提供了来自临床研究的证据支持。该数据集可用于机器学习任务，包括证据检索、真实性预测和解释生成。 |
| [^14] | [Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata.](http://arxiv.org/abs/2309.08491) | 这项工作探索了使用大型语言模型（LLMs）进行知识工程任务的应用。通过将主题和关系对转化为字符串格式，并将它们链接到相应的Wikidata QID上，开发了LLMKE流水线方法。研究发现，LLMs的知识因领域而异，并需要进一步实验以确定其在自动知识库补全和修正方面的应用条件。此外，结果还显示了LLMs在协作知识工程方面的有希望的贡献。 |
| [^15] | [SilverRetriever: Advancing Neural Passage Retrieval for Polish Question Answering.](http://arxiv.org/abs/2309.08469) | SilverRetriever是一个特为波兰语问答系统开发的神经检索器，通过训练在多种数据集上取得了显著的改进效果，并且与更大的多语种模型具有竞争力。 |
| [^16] | [Mixture Encoder Supporting Continuous Speech Separation for Meeting Recognition.](http://arxiv.org/abs/2309.08454) | 本研究将混合编码器方法从两个说话人情况扩展到了更自然的会议环境，包括任意数量的说话人和动态重叠。实验证明，该方法在LibriCSS数据集上达到了最先进的性能，并凸显了混合编码器的优势。 |
| [^17] | [Advancing the Evaluation of Traditional Chinese Language Models: Towards a Comprehensive Benchmark Suite.](http://arxiv.org/abs/2309.08448) | 本论文提出了一套新的基准数据集，利用现有的英文数据集，针对传统中文语言模型进行全面评估。这些基准数据集涵盖了上下文问答、摘要、分类和表格理解等多个任务，为评估语言模型在不同任务下的能力提供了全面的评估框架。 |
| [^18] | [Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation.](http://arxiv.org/abs/2309.08380) | 本研究提出了一种有效地将证据纳入知识密集型对话生成的框架 (u-EIDG)，通过引入自动证据生成框架，从无标签数据中挖掘可靠的证据真实性标签，以提高对话回答的准确性。 |
| [^19] | [PatFig: Generating Short and Long Captions for Patent Figures.](http://arxiv.org/abs/2309.08379) | 本文介绍了Qatent PatFig数据集，该数据集提供了30,000多个专利图的短文和长文标题、参考编号、术语和描述图像组件之间互动的最小索赔集。在数据集上对LVLM模型进行微调后，发现引入不同基于文本的线索可以改善专利图标题生成的效果。 |
| [^20] | [DiaCorrect: Error Correction Back-end For Speaker Diarization.](http://arxiv.org/abs/2309.08377) | DiaCorrect是一个错误校正后端框架，用于改进扬声器分析系统的输出。该模型利用输入录音和初始系统输出之间的相互作用，自动纠正初始的说话者活动，以减少分析错误。 |
| [^21] | [Headless Language Models: Learning without Predicting with Contrastive Weight Tying.](http://arxiv.org/abs/2309.08351) | 该论文提出了一种无头语言模型的创新方法，通过对比权重绑定的方式对输入嵌入进行重构，从而提高了下游性能和数据效率，并且在计算预算相似的情况下，获得了显著的GLUE分数增加和LAMBADA准确性提高。 |
| [^22] | [Reward Engineering for Generating Semi-structured Explanation.](http://arxiv.org/abs/2309.08347) | 本论文提出了一种奖励工程方法，在生成语言模型的半结构化解释方面取得了增强效果，解决了模型推理能力验证的问题。 |
| [^23] | [Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases.](http://arxiv.org/abs/2309.08345) | 本文通过实验调查揭示了语言模型在与知识库进行连接时的数据分布瓶颈，包括推广到未见域、适应语言变体和在不同数据集之间的可转移性等方面。即使采用数据增强技术，先进的语言模型在多个方面表现出较差的性能。 |
| [^24] | [Distributional Inclusion Hypothesis and Quantifications: Probing Hypernymy in Functional Distributional Semantics.](http://arxiv.org/abs/2309.08325) | 本文研究了在功能分布语义中，当语料库严格遵循分布包含假设时，功能分布语义模型可以学习到上位词关系。同时，引入一种训练目标使得模型可以处理普遍量化，从而在分布包含假设的反向下实现上位词关系的学习。实验结果验证了这些假设和目标的有效性。 |
| [^25] | [Bridging Topic, Domain, and Language Shifts: An Evaluation of Comprehensive Out-of-Distribution Scenarios.](http://arxiv.org/abs/2309.08316) | 本论文评估了语言模型在跨越主题、领域和语言变化的全面非分布场景中的泛化能力，并提出了改进策略，包括基于提示的精细调节和上下文学习。 |
| [^26] | [Self-Consistent Narrative Prompts on Abductive Natural Language Inference.](http://arxiv.org/abs/2309.08303) | 该论文提出了一个考虑自洽性和句间连贯性的自然语言推理模型，并通过实验证明了其有效性。 |
| [^27] | [Structural Self-Supervised Objectives for Transformers.](http://arxiv.org/abs/2309.08272) | 本论文提出了三种替代BERT掩码语言模型的预训练目标，包括随机标记置换（RTS）、基于簇的随机标记置换（C-RTS）和交换语言建模（SLM），并且证明这些目标在保持性能的同时，需要更少的预训练时间。此外，本论文还提出了一种结构与下游应用匹配的自监督预训练任务，减少了对标记数据的需求。 |
| [^28] | [Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for Robust Polyglot Text-To-Speech.](http://arxiv.org/abs/2309.08255) | 本文提出了一个跨语言语音合成的框架，使用语音转换和文本到语音模型，优于基于多语种模型的最先进方法，特别适用于资源匮乏的情况。 |
| [^29] | [Investigating Answerability of LLMs for Long-Form Question Answering.](http://arxiv.org/abs/2309.08210) | 本研究主要探究LLMs在长篇问题回答方面的可回答性，通过提出从抽象摘要生成问题的方法，展示了从长文档摘要中生成后续问题对LLMs进行推理和推断的挑战，并确认了LLMs之间的性能差距。 |
| [^30] | [Encoded Summarization: Summarizing Documents into Continuous Vector Space for Legal Case Retrieval.](http://arxiv.org/abs/2309.08187) | 该论文提出了一种将文件编码为连续向量空间的方法，用于法律案例检索任务。实验证明，将词汇特征和神经网络生成的潜在特征相结合可以提高检索系统性能。该方法在实验数据集上取得了较高的F1分数。 |
| [^31] | [Multilingual Sentence-Level Semantic Search using Meta-Distillation Learning.](http://arxiv.org/abs/2309.08185) | 本论文提出了一种基于元蒸馏学习的对齐方法，用于多语句级语义搜索任务中的低资源情况。通过将知识从单语到双语语义搜索进行传递，并从双语到多语语义搜索进行元传递，实现了对多语境的扩展。 |
| [^32] | [Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level.](http://arxiv.org/abs/2309.08182) | 本研究证明，使用大型语言模型(如GPT3.5)可以解决和解释物理词问题，通过对物理知识进行计算和推理，实现了接近人类水平的解决率。此外，该模型还能够总结涉及的知识、生成解释，并创造新的物理词问题。 |
| [^33] | [Large Language Models for Failure Mode Classification: An Investigation.](http://arxiv.org/abs/2309.08181) | 本研究探讨了大型语言模型在故障模式分类中的应用，通过细调GPT-3.5模型在注释数据上取得了显著提升的性能，优于当前可用的文本分类模型和开箱即用的GPT-3.5模型。 |
| [^34] | [FedJudge: Federated Legal Large Language Model.](http://arxiv.org/abs/2309.08173) | 本文提出了第一个分布式法律大型语言模型（FedJudge）框架，可以通过在设备或客户端上进行本地微调，并将参数聚合和分布在中央服务器上来确保数据隐私。这解决了集中式训练法律LLMs引发的数据隐私问题和分布偏移导致的FL方法效果降低的挑战。 |
| [^35] | [LASER: LLM Agent with State-Space Exploration for Web Navigation.](http://arxiv.org/abs/2309.08172) | 本论文提出了一种基于状态空间探索的LLM代理（LASER）用于Web导航任务。该代理以灵活的方式转换状态，通过执行动作完成任务，能够轻松从错误中恢复，并取得了显著的性能提升。 |
| [^36] | [Draft & Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding.](http://arxiv.org/abs/2309.08168) | 使用自我推测解码的Draft & Verify方法能够加速大型语言模型的推理过程，同时保持输出质量，并不需要额外的训练和内存占用。 |
| [^37] | [Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models.](http://arxiv.org/abs/2309.08163) | 研究发现，使用自我评估测试对大型语言模型的人格进行测量时，不同的提示会导致非常不同的人格得分，因此缺乏客观标准来判断哪个提示更正确。 |
| [^38] | [RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue.](http://arxiv.org/abs/2309.08156) | 基于参考的对话评估（RADE）方法利用预创建的语句作为参考，以解决开放领域对话系统中的一对多问题，并通过共享编码器增强预测。 |
| [^39] | [Unimodal Aggregation for CTC-based Speech Recognition.](http://arxiv.org/abs/2309.08150) | 本文提出了一种在CTC-based语音识别中用于学习更好的特征表示和缩短序列长度的单模聚合方法(UMA)，通过分割和集成同一文本标记的特征帧，实现了更低的识别错误和计算复杂度。实验证明，UMA在普通话数据集上表现出较好的性能，并且通过集成自条件CTC可以进一步提高性能。 |
| [^40] | [Audio Difference Learning for Audio Captioning.](http://arxiv.org/abs/2309.08141) | 本研究引入了音频差异学习方法，通过创建特征表示空间来改进音频字幕生成。该方法使用参考音频和输入音频，生成描述它们差异的字幕，同时提出了一种独特的混合技术来消除差异和原始输入之间的需求。 |
| [^41] | [PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions.](http://arxiv.org/abs/2309.08140) | PromptTTS++是一种基于提示的文本转语音系统，可以使用自然语言描述控制说话者身份。与现有研究不同，该方法利用说话者提示来学习自然语言描述与声学特征的映射。 |
| [^42] | [Research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information.](http://arxiv.org/abs/2309.08100) | 该研究提出了一种联合表示学习模型，结合实体邻域信息和描述信息，解决了编程设计课程知识图谱中嵌入效果不佳的问题，并在实验中取得了优于其他基线模型的性能表现。 |
| [^43] | [Characterizing the temporal dynamics of universal speech representations for generalizable deepfake detection.](http://arxiv.org/abs/2309.08099) | 本研究刻画了通用语音表示的时序动态，提出了一种评估表示动态的新方法，该方法能够提高深度伪造检测的可推广性并在实验中取得了显著改进。 |
| [^44] | [Connecting the Dots in News Analysis: A Cross-Disciplinary Survey of Media Bias and Framing.](http://arxiv.org/abs/2309.08069) | 这篇综述论文回顾了社会科学方法和自然语言处理方法在分析媒体偏见方面的差异，并提出了解决当前方法论鸿沟的可能方向，包括模型透明度、考虑文档外部信息和跨文档推理。 |
| [^45] | [Investigating Gender Bias in News Summarization.](http://arxiv.org/abs/2309.08047) | 本研究调查了新闻概述中的性别偏见，发现大型语言模型（LLMs）会重复和强化有害的社会偏见。研究提出了一些方法来量化模型中的有偏行为，并提出了一种生成具有控制人口属性的输入文档的方法。 |
| [^46] | [AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement.](http://arxiv.org/abs/2309.08030) | 本论文提出了一种名为AV2Wav的音频-视觉语音增强方法，利用连续自监督特征和扩散模型生成干净的语音，克服了现实训练数据的挑战。与基于掩蔽的基线方法相比，该方法在声码任务上表现更好，并通过多任务训练进一步优化性能。 |
| [^47] | [An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing.](http://arxiv.org/abs/2309.08008) | 该论文通过对五个临床自然语言处理任务的实验研究，评估了不同提示工程方法在大型语言模型上的效果，为解锁临床领域中的知识提供了指导。 |
| [^48] | [DiariST: Streaming Speech Translation with Speaker Diarization.](http://arxiv.org/abs/2309.08007) | DiariST是第一个流式语音翻译和说话者分离的解决方案，通过集成标记级序列化输出训练和t向量，实现了强大的ST和SD能力。 |
| [^49] | [Exploring the Impact of Human Evaluator Group on Chat-Oriented Dialogue Evaluation.](http://arxiv.org/abs/2309.07998) | 本文通过对4个不同的评估员群体对4个最先进的对话系统进行测试，分析了评估员群体对对话系统评估的影响。结果显示，对于Likert评估，评估员群体具有稳健性，而Pairwise评估没有。此外，还发现了不同评估员之间存在差异的局限性，并且评估员的客观性是有益的。 |
| [^50] | [Leveraging Contextual Information for Effective Entity Salience Detection.](http://arxiv.org/abs/2309.07990) | 本文研究了有效的实体重要性检测方法，通过对中等规模的语言模型进行微调，比传统的特征工程方法获得了更好的性能。研究还发现使用指令调校的语言模型进行零样本提示效果较差。 |
| [^51] | [Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech Recognition for Children VS. Adults.](http://arxiv.org/abs/2309.07927) | 本文主要研究利用My Science Tutor（MyST）儿童语音语料库和更有效的数据预处理来改进自动语音识别（ASR）系统对儿童语音的识别性能。将Whisper系统整合到儿童语音识别中，显示了表现可行和高效。 |
| [^52] | [The Rise and Potential of Large Language Model Based Agents: A Survey.](http://arxiv.org/abs/2309.07864) | 基于大型语言模型的代理的崛起和潜力：一项调查。大型语言模型被认为是构建通用人工智能代理的潜在催化剂，许多研究已经取得重要进展。 |
| [^53] | [CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration.](http://arxiv.org/abs/2309.07822) | 本研究通过在小型语言模型训练数据中增加自动生成的反事实实例，提高了摘要问答模型在领域外的性能和模型校准能力，并发现性能改进与反事实实例的多样性相关。 |
| [^54] | [Usability Evaluation of Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games.](http://arxiv.org/abs/2309.07773) | 本文通过实证调查评估了移动严肃游戏应用中口语化人形机器人对可用性的影响，结果表明用户更喜欢与高人类相似度的机器人进行交互。 |
| [^55] | [Everyone Deserves A Reward: Learning Customized Human Preferences.](http://arxiv.org/abs/2309.03126) | 该论文研究了定制化的人类偏好学习问题，通过收集领域特定偏好数据集，并提出了一个三阶段的定制化奖励模型学习方案，从而解决了当前语言模型训练中忽视多样性的问题。 |
| [^56] | [HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models.](http://arxiv.org/abs/2309.02706) | HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。 |
| [^57] | [WanJuan: A Comprehensive Multimodal Dataset for Advancing English and Chinese Large Models.](http://arxiv.org/abs/2308.10755) | 本论文提出了一个名为"Wan Juan"的大规模多模态数据集，包含中英文数据。这个数据集通过各种网络来源采集，包括文本、图像文本和视频模态，总量超过2TB。它被用于训练InternLM模型，该模型在多维度评估中表现出明显优势。 |
| [^58] | [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models.](http://arxiv.org/abs/2308.09729) | 本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。 |
| [^59] | [Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification.](http://arxiv.org/abs/2308.09308) | 本研究提出了一种可微的检索增强方法，通过生成式语言建模，在电子商务查询意图分类任务中显著提升了性能，解决了检索器和下游模型之间的不可微性问题。 |
| [^60] | [Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models.](http://arxiv.org/abs/2306.14096) | 本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。 |
| [^61] | [Dynamic Masking Rate Schedules for MLM Pretraining.](http://arxiv.org/abs/2305.15096) | 本论文提出了一种动态调度掩码率的方法来改进MLM预训练的质量，通过线性降低掩码率，达到了对BERT-base和BERT-large模型分别提高0.46%和0.25%的平均GLUE准确率的效果。这种方法不仅加快了BERT-base的预训练速度，还实现了对BERT-large的帕累托改善。 |
| [^62] | [Using LLM-assisted Annotation for Corpus Linguistics: A Case Study of Local Grammar Analysis.](http://arxiv.org/abs/2305.08339) | 本文研究了使用基于大语言模型的聊天机器人自动标注文本的潜力，重点考察了从本地语法角度观察道歉言语行为构成的功能元素的程度，并比较了不同模型在注释任务中的表现，结果表明Bing聊天机器人在任务中表现优于ChatGPT和人类标注员。 |
| [^63] | [Exploring the State of the Art in Legal QA Systems.](http://arxiv.org/abs/2304.06623) | 法律问题回答系统的研究面临着复杂性和多样性等挑战，但其在客户服务、教育、研究和跨语言交流等方面具有广泛应用。 |
| [^64] | [Guiding Pretraining in Reinforcement Learning with Large Language Models.](http://arxiv.org/abs/2302.06692) | 这项研究提出了一种使用大型语言模型在强化学习中引导预训练的方法，通过奖励代理根据语言模型建议的目标来塑造探索策略，使代理朝着人类有意义且可能有用的行为方向发展，无需人类的介入。 |
| [^65] | [Diachronic Data Analysis Supports and Refines Conceptual Metaphor Theory.](http://arxiv.org/abs/2209.12234) | 该论文通过统计数据分析和实证研究支持和完善概念隐喻理论，同时也将隐喻理论作为意义出现的基础，可以定量地探索并整合到自然语言处理的框架中。 |
| [^66] | [VQA-GNN: Reasoning with Multimodal Knowledge via Graph Neural Networks for Visual Question Answering.](http://arxiv.org/abs/2205.11501) | VQA-GNN是一种通过图神经网络在非结构化和结构化多模态知识之间进行双向融合的新的VQA模型。 |
| [^67] | [Application of Quantum Density Matrix in Classical Question Answering and Classical Image Classification.](http://arxiv.org/abs/2203.11155) | 该论文将量子密度矩阵应用于经典问答和图像分类中，证明了其可以提高任务的效率，尤其在图像分类中取得了优秀的性能表现。 |
| [^68] | [AmbiFC: Fact-Checking Ambiguous Claims with Evidence.](http://arxiv.org/abs/2104.00640) | 本研究提出了一个大规模的事实核查数据集AmbiFC，用于处理现实场景中的含糊性声明核查问题，通过细粒度的证据注释和分析，提出了一种适用于含糊性声明的软标签证据核查方法，并且在注释人员争议分析中发现了相关性。 |

# 详细

[^1]: 稀疏自编码器在语言模型中发现高度可解释的特征

    Sparse Autoencoders Find Highly Interpretable Features in Language Models. (arXiv:2309.08600v1 [cs.LG])

    [http://arxiv.org/abs/2309.08600](http://arxiv.org/abs/2309.08600)

    本研究通过稀疏自编码器在语言模型中发现了一组高度可解释和单一义的特征，从而解决了神经网络内部多义性的问题。

    

    神经网络内部理解的一个障碍是多义性，其中神经元在多个语义不同的上下文中激活。多义性使我们无法找到简洁的、人类可理解的解释来解释神经网络内部的工作。多义性的一个猜测原因是叠加效应，即神经网络通过将特征分配给激活空间中的一个过完备方向集合，而不是个别神经元，表示更多的特征。在这里，我们尝试使用稀疏自编码器来确定这些方向，以重构语言模型的内部激活。这些自编码器学习到的一组稀疏激活特征比其他方法鉴定出的方向更可解释和单一义，解释性是通过自动化方法衡量的。删除这些特征可以实现精确的模型编辑，例如通过删除这些特征可以改变模型输出。

    One of the roadblocks to a better understanding of neural networks' internals is \textit{polysemanticity}, where neurons appear to activate in multiple, semantically distinct contexts. Polysemanticity prevents us from identifying concise, human-understandable explanations for what neural networks are doing internally. One hypothesised cause of polysemanticity is \textit{superposition}, where neural networks represent more features than they have neurons by assigning features to an overcomplete set of directions in activation space, rather than to individual neurons. Here, we attempt to identify those directions, using sparse autoencoders to reconstruct the internal activations of a language model. These autoencoders learn sets of sparsely activating features that are more interpretable and monosemantic than directions identified by alternative approaches, where interpretability is measured by automated methods. Ablating these features enables precise model editing, for example, by remo
    
[^2]: "合并冲突！探索外部干扰对参数化知识图谱的影响"

    "Merge Conflicts!" Exploring the Impacts of External Distractors to Parametric Knowledge Graphs. (arXiv:2309.08594v1 [cs.CL])

    [http://arxiv.org/abs/2309.08594](http://arxiv.org/abs/2309.08594)

    本研究探索了外部干扰对参数化知识图谱的影响，通过引入不同程度、方法、位置和格式的干扰因素，发现大型语言模型倾向于产生与其参数化知识不一致的回复。

    

    大型语言模型（LLMs）在预训练期间获取了广泛的知识，称为它们的参数化知识。然而，为了保持与人类指令的一致并与时俱进，LLMs在与用户交互过程中不可避免地需要外部知识的支持。这引发了一个关键问题：当外部知识干扰参数化知识时，LLMs将如何做出反应？为了研究这个问题，我们提出了一个框架，系统地挖掘LLMs的参数化知识并引入外部知识。具体而言，我们通过构建参数化知识图谱来揭示LLMs的不同知识结构，并通过不同程度、方法、位置和格式的干扰因素引入外部知识。我们在黑盒和开源模型上的实验表明，LLMs倾向于产生与其参数化知识不一致的回复，特别是在遇到直接冲突或混淆变化时。

    Large language models (LLMs) acquire extensive knowledge during pre-training, known as their parametric knowledge. However, in order to remain up-to-date and align with human instructions, LLMs inevitably require external knowledge during their interactions with users. This raises a crucial question: How will LLMs respond when external knowledge interferes with their parametric knowledge? To investigate this question, we propose a framework that systematically elicits LLM parametric knowledge and introduces external knowledge. Specifically, we uncover the impacts by constructing a parametric knowledge graph to reveal the different knowledge structures of LLMs, and introduce external knowledge through distractors of varying degrees, methods, positions, and formats. Our experiments on both black-box and open-source models demonstrate that LLMs tend to produce responses that deviate from their parametric knowledge, particularly when they encounter direct conflicts or confounding changes o
    
[^3]: 多语言LLMs是否具有文化多样性的推理能力？对多元文化谚语和俗语的调查研究

    Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings. (arXiv:2309.08591v1 [cs.CL])

    [http://arxiv.org/abs/2309.08591](http://arxiv.org/abs/2309.08591)

    本文研究了多语言LLMs在对话环境中运用谚语和俗语进行推理的能力，发现mLLMs在理解比喻性谚语、选择正确答案和推理其他语言的谚语时存在困难。

    

    大型语言模型（LLMs）在问答和推理任务方面非常擅长，但在情境背景下进行推理时，人类的期望因相关文化共同点而异。由于人类语言与多种文化相关联，LLMs也应该是具有文化多样性的推理者。在本文中，我们研究了一系列最先进的多语言LLMs（mLLMs）在对话环境中运用谚语和俗语进行推理的能力。我们的实验证明：（1）mLLMs只“知道”有限的谚语，并且仅仅记住谚语并不能在对话环境中理解它们；（2）mLLMs在推理比喻性的谚语和俗语时遇到困难，当被要求选择错误答案时，而不是选择正确答案；（3）在推理来自其他语言的谚语和俗语时，mLLMs存在“文化差距”。我们构建并发布了我们的评估数据集MAPS（多元文化谚语和俗语）。

    Large language models (LLMs) are highly adept at question answering and reasoning tasks, but when reasoning in situational context, human expectations vary depending on the relevant cultural common ground. As human languages are associated with diverse cultures, LLMs should also be culturally-diverse reasoners. In this paper, we study the ability of a wide range of state-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and sayings in a conversational context. Our experiments reveal that: (1) mLLMs 'knows' limited proverbs and memorizing proverbs does not mean understanding them within a conversational context; (2) mLLMs struggle to reason with figurative proverbs and sayings, and when asked to select the wrong answer (instead of asking it to select the correct answer); and (3) there is a "culture gap" in mLLMs when reasoning about proverbs and sayings translated from other languages. We construct and release our evaluation dataset MAPS (MulticultrAl Proverbs and Sayings) fo
    
[^4]: 神经机器翻译模型可以学会成为少样本学习器

    Neural Machine Translation Models Can Learn to be Few-shot Learners. (arXiv:2309.08590v1 [cs.CL])

    [http://arxiv.org/abs/2309.08590](http://arxiv.org/abs/2309.08590)

    本研究展示了只需进行微调就可以训练一种更小的模型，使其具备上下文学习的能力，即使用少样本示例进行自适应，从而提高神经机器翻译的领域自适应任务的效果，并超过了传统监督技术和大型语言模型的表现。

    

    大型语言模型的新兴能力是使用少量示例来学习在新领域和任务中的表现，也称为上下文学习（ICL）。在这项工作中，我们展示了一个更小的模型可以通过微调向专门的训练目标进行ICL的训练，在神经机器翻译的领域自适应任务上进行演示。通过ICL的能力，模型可以利用相关的少样本示例调整其输出以适应该领域。我们比较了这种领域自适应方法与传统的监督技术以及具有40B参数的大型语言模型的ICL的质量。我们的方法可以在多个领域中进行高效的批量推理，并在翻译质量和即时适应率方面优于最先进的基准方法，即在展示单个示例后能够重现特定术语的能力。

    The emergent ability of Large Language Models to use a small number of examples to learn to perform in novel domains and tasks, also called in-context learning (ICL). In this work, we show that a much smaller model can be trained to perform ICL by fine-tuning towards a specialized training objective, exemplified on the task of domain adaptation for neural machine translation. With this capacity for ICL, the model can take advantage of relevant few-shot examples to adapt its output towards the domain. We compare the quality of this domain adaptation to traditional supervised techniques and ICL with a 40B-parameter Large Language Model. Our approach allows efficient batch inference on a mix of domains and outperforms state-of-the-art baselines in terms of both translation quality and immediate adaptation rate, i.e. the ability to reproduce a specific term after being shown a single example.
    
[^5]: 链式思考推理是一种策略改进操作

    Chain-of-Thought Reasoning is a Policy Improvement Operator. (arXiv:2309.08589v1 [cs.LG])

    [http://arxiv.org/abs/2309.08589](http://arxiv.org/abs/2309.08589)

    大型语言模型SECToR通过链式思考推理成功地自学新技能，

    

    大型语言模型以其令人赞叹的新能力令世界为之惊叹。然而，它们目前缺乏自我学习新技能的能力，而是依赖于接受大量由人类生成的数据的训练。我们介绍了SECToR（通过链式思考推理实现自我教育），这是一个概念验证，证明语言模型可以通过链式思考推理成功地自学新技能。受到以前在强化学习（Silver等人，2017）和人类认知（Kahneman，2011）中的相关工作的启发，SECToR首先使用链式思考推理逐渐思考问题。然后，SECToR通过微调模型生成相同的答案，这次不再使用链式思考推理。通过SECToR训练的语言模型自主学会了进行多达29位数字的加法运算，而没有任何超过6位数字的基准真实示例，仅通过初始的监督微调阶段。我们的核心假设是...

    Large language models have astounded the world with fascinating new capabilities. However, they currently lack the ability to teach themselves new skills, relying instead on being trained on large amounts of human-generated data. We introduce SECToR (Self-Education via Chain-of-Thought Reasoning), a proof-of-concept demonstration that language models can successfully teach themselves new skills using chain-of-thought reasoning. Inspired by previous work in both reinforcement learning (Silver et al., 2017) and human cognition (Kahneman, 2011), SECToR first uses chain-of-thought reasoning to slowly think its way through problems. SECToR then fine-tunes the model to generate those same answers, this time without using chain-of-thought reasoning. Language models trained via SECToR autonomously learn to add up to 29-digit numbers without any access to any ground truth examples beyond an initial supervised fine-tuning phase consisting only of numbers with 6 or fewer digits. Our central hypot
    
[^6]: ICLEF: 基于专家反馈的上下文学习用于可解释风格转移

    ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer. (arXiv:2309.08583v1 [cs.CL])

    [http://arxiv.org/abs/2309.08583](http://arxiv.org/abs/2309.08583)

    本研究提出了一个框架，使用模型蒸馏增强和改进正式风格转移数据集的解释，并提出了一种新颖的方法，通过上下文学习和专家反馈进一步优化生成的解释。

    

    虽然最先进的语言模型在风格转移任务上表现出色，但当前的工作没有解决风格转移系统的可解释性问题。通过使用GPT-3.5和GPT-4等大型语言模型，可以生成解释，但是当存在更小、广泛分布且透明的替代品时，使用这样复杂的系统是低效的。我们提出了一个框架，通过从ChatGPT中进行模型蒸馏来增强和改进一个正式风格转移数据集的解释。为了进一步改善生成的解释，我们提出了一种新颖的方式，即通过上下文学习（ICLEF:基于专家反馈的上下文学习），使ChatGPT充当其自身输出的评论者。我们使用包含9960个可解释的正式风格转移实例（e-GYAFC）的数据集来展示当前公开分发的经过指导的模型（在某些设置中包括ChatGPT）在该任务上表现不佳，并且在我们的高-

    While state-of-the-art language models excel at the style transfer task, current work does not address explainability of style transfer systems. Explanations could be generated using large language models such as GPT-3.5 and GPT-4, but the use of such complex systems is inefficient when smaller, widely distributed, and transparent alternatives are available. We propose a framework to augment and improve a formality style transfer dataset with explanations via model distillation from ChatGPT. To further refine the generated explanations, we propose a novel way to incorporate scarce expert human feedback using in-context learning (ICLEF: In-Context Learning from Expert Feedback) by prompting ChatGPT to act as a critic to its own outputs. We use the resulting dataset of 9,960 explainable formality style transfer instances (e-GYAFC) to show that current openly distributed instruction-tuned models (and, in some settings, ChatGPT) perform poorly on the task, and that fine-tuning on our high-
    
[^7]: 印度也存在种姓主义但不存在种族主义吗？量化印度和西方大型语言模型偏见的差异

    Casteist but Not Racist? Quantifying Disparities in Large Language Model Bias between India and the West. (arXiv:2309.08573v1 [cs.CL])

    [http://arxiv.org/abs/2309.08573](http://arxiv.org/abs/2309.08573)

    本研究量化了大型语言模型在印度和西方上的陈规偏见差异，并开发了一个新的数据集来评估种姓和宗教上的刻板印象。研究发现大多数测试的模型在印度背景下对刻板印象有显著偏见，尤其是与西方背景相比。此外，研究探索了一种简单干预方法来减轻这种偏见的效果。

    

    大型语言模型（LLMs）现在每天被数百万用户使用，他们能够传达社会偏见，使用户遭受再现伤害。已有大量的关于LLM偏见的学术研究存在，但主要采用西方中心视角，相对较少关注全球南方地区的偏见水平和潜在伤害。在本文中，我们量化流行LLMs中的陈规偏见，采用以印度为中心的框架，并比较印度和西方背景下的偏见水平。为此，我们开发了一个新颖的数据集，称为Indian-BhED（印度偏见评估数据集），其中包含种姓和宗教上的刻板和反刻板的例子。我们发现，在印度背景下，大多数测试的LLMs对刻板印象有强烈偏见，尤其是与西方背景相比。最后，我们研究了Instruction Prompting作为一种简单的干预手段来减轻这种偏见，并发现它显著减少了刻板印象和反刻板印象。

    Large Language Models (LLMs), now used daily by millions of users, can encode societal biases, exposing their users to representational harms. A large body of scholarship on LLM bias exists but it predominantly adopts a Western-centric frame and attends comparatively less to bias levels and potential harms in the Global South. In this paper, we quantify stereotypical bias in popular LLMs according to an Indian-centric frame and compare bias levels between the Indian and Western contexts. To do this, we develop a novel dataset which we call Indian-BhED (Indian Bias Evaluation Dataset), containing stereotypical and anti-stereotypical examples for caste and religion contexts. We find that the majority of LLMs tested are strongly biased towards stereotypes in the Indian context, especially as compared to the Western context. We finally investigate Instruction Prompting as a simple intervention to mitigate such bias and find that it significantly reduces both stereotypical and anti-stereoty
    
[^8]: 预训练多语言翻译模型上的属性控制器能否迁移到其他语言？

    How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?. (arXiv:2309.08565v1 [cs.CL])

    [http://arxiv.org/abs/2309.08565](http://arxiv.org/abs/2309.08565)

    本文研究了如何将预训练的多语言翻译模型中的属性控制器迁移到没有监督数据的语言。通过全面分析不同数据场景下的训练和推断时控制技术，揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。

    

    最近，将机器翻译模型定制为符合细粒度属性（如形式）已取得了巨大进展。然而，当前方法大多依赖于至少一些带有属性注释的监督数据。因此，数据稀缺仍然是将此定制能力普及到更广泛语言范围，尤其是低资源语言的一个瓶颈。鉴于最近在预训练大规模多语言翻译模型方面取得的进展，我们将它们作为对没有监督数据的语言进行属性控制能力迁移的基础。在这项工作中，我们基于预训练的NLLB-200模型对属性控制器的迁移进行了全面分析。我们研究了在各种数据场景下的训练和推断时控制技术，并揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。我们显示出两种范式是互补的，通过一致的改进来证明。

    Customizing machine translation models to comply with fine-grained attributes such as formality has seen tremendous progress recently. However, current approaches mostly rely on at least some supervised data with attribute annotation. Data scarcity therefore remains a bottleneck to democratizing such customization possibilities to a wider range of languages, lower-resource ones in particular. Given recent progress in pretrained massively multilingual translation models, we use them as a foundation to transfer the attribute controlling capabilities to languages without supervised data. In this work, we present a comprehensive analysis of transferring attribute controllers based on a pretrained NLLB-200 model. We investigate both training- and inference-time control techniques under various data scenarios, and uncover their relative strengths and weaknesses in zero-shot performance and domain robustness. We show that both paradigms are complementary, as shown by consistent improvements o
    
[^9]: 在线语音识别中结构化状态空间模型增强构型

    Augmenting conformers with structured state space models for online speech recognition. (arXiv:2309.08551v1 [cs.CL])

    [http://arxiv.org/abs/2309.08551](http://arxiv.org/abs/2309.08551)

    本文研究通过将结构化状态空间序列模型（S4）与卷积相结合，增强在线语音识别的神经编码器，并在Librispeech的测试集上取得了较低的识别错误率。

    

    在线语音识别是一种重要且具有挑战性的ASR系统应用场景，其中模型只能访问左侧上下文。本文研究通过结合结构化状态空间序列模型（S4）增强在线ASR的神经编码器，S4是一类提供了访问任意长左侧上下文的参数高效方式的模型。我们进行了系统的消融实验，比较了S4模型的各个变种，并提出了两种将其与卷积相结合的新方法。我们发现，最有效的设计是使用具有实值循环权重的小型S4模型与本地卷积相叠加，使它们可以互补地工作。我们的最佳模型在来自Librispeech的测试集上取得了4.01%/8.53%的WER，优于经过详细调优的Conformers。

    Online speech recognition, where the model only accesses context to the left, is an important and challenging use case for ASR systems. In this work, we investigate augmenting neural encoders for online ASR by incorporating structured state-space sequence models (S4), which are a family of models that provide a parameter-efficient way of accessing arbitrarily long left context. We perform systematic ablation studies to compare variants of S4 models and propose two novel approaches that combine them with convolutions. We find that the most effective design is to stack a small S4 using real-valued recurrent weights with a local convolution, allowing them to work complementarily. Our best model achieves WERs of 4.01%/8.53% on test sets from Librispeech, outperforming Conformers with extensively tuned convolution.
    
[^10]: 生成式查询和文档扩展何时失败？方法、检索器和数据集的全面研究

    When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets. (arXiv:2309.08541v1 [cs.IR])

    [http://arxiv.org/abs/2309.08541](http://arxiv.org/abs/2309.08541)

    通过对11种扩展技术、12个不同分布变化的数据集和24个检索模型的全面分析，我们发现使用大型语言模型进行查询或文档扩展的效果与检索器性能相关，对于弱模型来说扩展提高了分数，但对于强模型来说扩展通常会损害分数。

    

    使用大型语言模型（LM）进行查询或文档扩展可以改善信息检索中的泛化能力。然而，目前尚不清楚这些技术是否普遍有益，还是仅在特定设置下有效，例如对于特定的检索模型、数据集领域或查询类型。为了回答这个问题，我们进行了第一次对基于LM的扩展的全面分析。我们发现，检索器性能与扩展的增益之间存在强烈的负相关关系：扩展改善了较弱模型的分数，但通常会损害较强模型的分数。我们展示了这一趋势在11种扩展技术、12个具有不同分布变化的数据集和24个检索模型的一组实验中成立。通过定性错误分析，我们提出了一个假设，即尽管扩展提供了额外的信息（可能改善了召回率），但它们也增加了噪声，使得很难区分出顶级相关文档（从而引入了错误的正例）

    Using large language models (LMs) for query or document expansion can improve generalization in information retrieval. However, it is unknown whether these techniques are universally beneficial or only effective in specific settings, such as for particular retrieval models, dataset domains, or query types. To answer this, we conduct the first comprehensive analysis of LM-based expansion. We find that there exists a strong negative correlation between retriever performance and gains from expansion: expansion improves scores for weaker models, but generally harms stronger models. We show this trend holds across a set of eleven expansion techniques, twelve datasets with diverse distribution shifts, and twenty-four retrieval models. Through qualitative error analysis, we hypothesize that although expansions provide extra information (potentially improving recall), they add additional noise that makes it difficult to discern between the top relevant documents (thus introducing false positiv
    
[^11]: 通过进化算法连接大型语言模型与强大的提示优化器

    Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers. (arXiv:2309.08532v1 [cs.CL])

    [http://arxiv.org/abs/2309.08532](http://arxiv.org/abs/2309.08532)

    本文提出了一种通过连接大型语言模型和进化算法进行提示优化的框架，名为EvoPrompt。通过利用大型语言模型的语言处理能力和进化算法的优化性能，EvoPrompt可以自动化处理需要连贯和可读性良好的提示，提高大型语言模型的性能。

    

    大型语言模型在各种任务中表现出色，但它们依赖于精心设计的提示，这通常需要大量的人力努力。为了自动化这个过程，本文提出了一种新颖的离散提示优化框架，称为EvoPrompt，它借鉴了进化算法的思想，因为它们表现出良好的性能和快速的收敛性。为了使进化算法能够处理需要连贯并且可读性良好的自然语言表达的离散提示，我们将大型语言模型与进化算法进行了连接。这种方法使我们可以同时利用大型语言模型的强大语言处理能力和进化算法的高效优化性能。具体而言，EvoPrompt在不使用任何梯度或参数的情况下，从一组提示中开始，并基于进化算子通过大型语言模型生成新的提示，根据开发集改进提示的种群。我们对闭源和开源的大型语言模型，包括GPT-3进行提示优化。

    Large Language Models (LLMs) excel in various tasks, but they rely on carefully crafted prompts that often demand substantial human effort. To automate this process, in this paper, we propose a novel framework for discrete prompt optimization, called EvoPrompt, which borrows the idea of evolutionary algorithms (EAs) as they exhibit good performance and fast convergence. To enable EAs to work on discrete prompts, which are natural language expressions that need to be coherent and human-readable, we connect LLMs with EAs. This approach allows us to simultaneously leverage the powerful language processing capabilities of LLMs and the efficient optimization performance of EAs. Specifically, abstaining from any gradients or parameters, EvoPrompt starts from a population of prompts and iteratively generates new prompts with LLMs based on the evolutionary operators, improving the population based on the development set. We optimize prompts for both closed- and open-source LLMs including GPT-3
    
[^12]: 实现实用高效的图像到语音字幕生成的方法：基于视觉语言预训练和多模态令牌化

    Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens. (arXiv:2309.08531v1 [cs.CV])

    [http://arxiv.org/abs/2309.08531](http://arxiv.org/abs/2309.08531)

    本文提出了一种实现实用高效的图像到语音字幕生成的方法。通过引入来自大规模预训练的视觉语言模型的知识，并将其融入到Im2Sp模型中，以实现更好的性能。通过视觉语言预训练策略，在COOC和Flickr8k两个基准数据库上刷新了Im2Sp的最佳性能。同时，还改进了Im2Sp模型的效率。

    

    在本文中，我们提出了构建强大高效的图像到语音字幕生成（Im2Sp）模型的方法。首先，我们从一个大规模预训练的视觉语言模型中引入与图像理解和语言建模有关的丰富知识并融入到Im2Sp中。我们将提出的Im2Sp的输出设置为离散化的语音单位，即自监督语音模型的量化语音特征。这些语音单位主要包含语言信息，而抑制了语音的其他特征。这使得我们能够将预训练的视觉语言模型的语言建模能力融入到Im2Sp的口语建模中。通过视觉语言预训练策略，我们在两个广泛使用的基准数据库COCO和Flickr8k上取得了新的最优Im2Sp性能。然后，我们进一步提高了Im2Sp模型的效率。类似于语音单位案例，我们将原始图像转换为图像单位，这些图像单位是通过视觉特征编码得到的。

    In this paper, we propose methods to build a powerful and efficient Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp. We set the output of the proposed Im2Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model. The speech units mainly contain linguistic information while suppressing other characteristics of speech. This allows us to incorporate the language modeling capability of the pre-trained vision-language model into the spoken language modeling of Im2Sp. With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model. Similar to the speech unit case, we convert the original image into image units, which are derived through v
    
[^13]: HealthFC：一份用于基于证据的医学事实检验的健康声明数据集

    HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking. (arXiv:2309.08503v1 [cs.CL])

    [http://arxiv.org/abs/2309.08503](http://arxiv.org/abs/2309.08503)

    本文介绍了一份新的健康声明数据集，其中包含了750个由医学专家标注的健康相关声明，并提供了来自临床研究的证据支持。该数据集可用于机器学习任务，包括证据检索、真实性预测和解释生成。

    

    在数字时代，通过互联网查询健康相关建议已成为一种常见做法。然而，判断在线找到的医学声明的可信度，并找到相应的证据，变得越来越具有挑战性。事实检验已经成为一种通过可靠知识来源的证据评估事实声明真实性的方法。为了推动此任务的自动化，本文介绍了一份新的数据集，包含了750个健康相关声明，在可信度方面由医学专家进行了标注，并提供了来自适当的临床研究的证据支持。我们对数据集进行了分析，突出其特点和挑战。该数据集可用于与自动事实检验相关的机器学习任务，如证据检索、真实性预测和解释生成。为此，我们提供了基于不同方法的基线模型，对它们的性能进行了研究，并讨论了研究结果。

    Seeking health-related advice on the internet has become a common practice in the digital era. Determining the trustworthiness of medical claims found online and finding appropriate evidence for this information is increasingly challenging. Fact-checking has emerged as an approach to assess the veracity of factual claims using evidence from credible knowledge sources. To help advance the automation of this task, in this paper, we introduce a novel dataset of 750 health-related claims, labeled for veracity by medical experts and backed with evidence from appropriate clinical studies. We provide an analysis of the dataset, highlighting its characteristics and challenges. The dataset can be used for Machine Learning tasks related to automated fact-checking such as evidence retrieval, veracity prediction, and explanation generation. For this purpose, we provide baseline models based on different approaches, examine their performance, and discuss the findings.
    
[^14]: 使用大型语言模型进行知识工程（LLMKE）：以Wikidata为案例研究

    Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata. (arXiv:2309.08491v1 [cs.CL])

    [http://arxiv.org/abs/2309.08491](http://arxiv.org/abs/2309.08491)

    这项工作探索了使用大型语言模型（LLMs）进行知识工程任务的应用。通过将主题和关系对转化为字符串格式，并将它们链接到相应的Wikidata QID上，开发了LLMKE流水线方法。研究发现，LLMs的知识因领域而异，并需要进一步实验以确定其在自动知识库补全和修正方面的应用条件。此外，结果还显示了LLMs在协作知识工程方面的有希望的贡献。

    

    在这项工作中，我们探索了在ISWC 2023 LM-KBC挑战中使用大型语言模型（LLMs）进行知识工程任务的应用。针对该任务，我们使用预训练的LLMs将来自Wikidata的主题和关系对转化为相应的字符串格式，并将它们链接到相应的Wikidata QID上。我们开发了一种使用LLMs进行知识工程的流水线（LLMKE），结合了知识探测和Wikidata实体映射。该方法在属性方面达到了0.701的宏平均F1分数，得分在1.00到0.328之间变化。这些结果表明，LLMs的知识因领域而异，需要进一步实验来确定LLMs在自动知识库（如Wikidata）补全和修正方面的应用条件。结果的调查还显示了LLMs在协作知识工程方面的有希望的贡献。LLMKE获胜

    In this work, we explore the use of Large Language Models (LLMs) for knowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge. For this task, given subject and relation pairs sourced from Wikidata, we utilize pre-trained LLMs to produce the relevant objects in string format and link them to their respective Wikidata QIDs. We developed a pipeline using LLMs for Knowledge Engineering (LLMKE), combining knowledge probing and Wikidata entity mapping. The method achieved a macro-averaged F1-score of 0.701 across the properties, with the scores varying from 1.00 to 0.328. These results demonstrate that the knowledge of LLMs varies significantly depending on the domain and that further experimentation is required to determine the circumstances under which LLMs can be used for automatic Knowledge Base (e.g., Wikidata) completion and correction. The investigation of the results also suggests the promising contribution of LLMs in collaborative knowledge engineering. LLMKE won
    
[^15]: SilverRetriever：提升波兰问答系统的神经通道检索能力

    SilverRetriever: Advancing Neural Passage Retrieval for Polish Question Answering. (arXiv:2309.08469v1 [cs.CL])

    [http://arxiv.org/abs/2309.08469](http://arxiv.org/abs/2309.08469)

    SilverRetriever是一个特为波兰语问答系统开发的神经检索器，通过训练在多种数据集上取得了显著的改进效果，并且与更大的多语种模型具有竞争力。

    

    现代开放领域的问答系统通常依赖于准确和高效的检索组件来找到包含回答问题所需事实的段落。近年来，由于其出色的性能，神经检索器比词汇替代方式更受欢迎。然而，大部分研究都集中在流行语言如英语或中文上，对于其他语言如波兰语，可用的模型很少。在本文中，我们介绍了SilverRetriever，一个基于多种手动标记或弱标记数据集训练的波兰语神经检索器。SilverRetriever在波兰语模型中取得了比其他模型更好的结果，并与更大的多语种模型具有竞争力。与该模型一起，我们还开源了五个新的段落检索数据集。

    Modern open-domain question answering systems often rely on accurate and efficient retrieval components to find passages containing the facts necessary to answer the question. Recently, neural retrievers have gained popularity over lexical alternatives due to their superior performance. However, most of the work concerns popular languages such as English or Chinese. For others, such as Polish, few models are available. In this work, we present SilverRetriever, a neural retriever for Polish trained on a diverse collection of manually or weakly labeled datasets. SilverRetriever achieves much better results than other Polish models and is competitive with larger multilingual models. Together with the model, we open-source five new passage retrieval datasets.
    
[^16]: 混合编码器支持连续语音分离用于会议识别

    Mixture Encoder Supporting Continuous Speech Separation for Meeting Recognition. (arXiv:2309.08454v1 [eess.AS])

    [http://arxiv.org/abs/2309.08454](http://arxiv.org/abs/2309.08454)

    本研究将混合编码器方法从两个说话人情况扩展到了更自然的会议环境，包括任意数量的说话人和动态重叠。实验证明，该方法在LibriCSS数据集上达到了最先进的性能，并凸显了混合编码器的优势。

    

    自动语音识别（ASR）的许多实际应用需要处理重叠的语音。一种常见的方法是首先将语音分离成无重叠的流，然后对生成的信号进行ASR。最近，提出了在ASR模型中包含混合编码器的方法。该混合编码器利用原始重叠的语音来减轻语音分离引入的伪影效果。然而，先前的方法仅针对两个说话人的情况。在这项工作中，我们将这种方法扩展到更自然的会议环境，包括任意数量的说话人和动态重叠。我们使用不同的语音分离器（包括强大的TF-GridNet模型）评估性能。实验证明，在LibriCSS数据集上达到了最先进的性能，并凸显了混合编码器的优势。此外，实验还展示了TF-GridNet的强大分离能力，大大缩小了先前方法的差距。

    Many real-life applications of automatic speech recognition (ASR) require processing of overlapped speech. A commonmethod involves first separating the speech into overlap-free streams and then performing ASR on the resulting signals. Recently, the inclusion of a mixture encoder in the ASR model has been proposed. This mixture encoder leverages the original overlapped speech to mitigate the effect of artifacts introduced by the speech separation. Previously, however, the method only addressed two-speaker scenarios. In this work, we extend this approach to more natural meeting contexts featuring an arbitrary number of speakers and dynamic overlaps. We evaluate the performance using different speech separators, including the powerful TF-GridNet model. Our experiments show state-of-the-art performance on the LibriCSS dataset and highlight the advantages of the mixture encoder. Furthermore, they demonstrate the strong separation of TF-GridNet which largely closes the gap between previous m
    
[^17]: 推进传统中文语言模型评估：迈向全面基准套件

    Advancing the Evaluation of Traditional Chinese Language Models: Towards a Comprehensive Benchmark Suite. (arXiv:2309.08448v1 [cs.CL])

    [http://arxiv.org/abs/2309.08448](http://arxiv.org/abs/2309.08448)

    本论文提出了一套新的基准数据集，利用现有的英文数据集，针对传统中文语言模型进行全面评估。这些基准数据集涵盖了上下文问答、摘要、分类和表格理解等多个任务，为评估语言模型在不同任务下的能力提供了全面的评估框架。

    

    在语言理解和生成领域中，评估大型语言模型是至关重要的任务。随着语言模型的不断发展，评估其性能的有效基准的需求变得迫切。在中文语境下，尽管存在一些基准数据集如DRCD、TTQA、CMDQA和FGC，但缺乏全面多样的基准数据集来评估语言模型的能力。为了弥补这一空白，我们提出了一套新的基准数据集，利用现有的英文数据集，针对传统中文语言模型进行评估。这些基准数据集涵盖了广泛的任务，包括上下文问答、摘要、分类和表格理解。所提出的基准数据集提供了一个全面的评估框架，可以评估语言模型在不同任务下的能力。本文中，我们评估了GPT-3.5和Taiwa的性能。

    The evaluation of large language models is an essential task in the field of language understanding and generation. As language models continue to advance, the need for effective benchmarks to assess their performance has become imperative. In the context of Traditional Chinese, there is a scarcity of comprehensive and diverse benchmarks to evaluate the capabilities of language models, despite the existence of certain benchmarks such as DRCD, TTQA, CMDQA, and FGC dataset. To address this gap, we propose a novel set of benchmarks that leverage existing English datasets and are tailored to evaluate language models in Traditional Chinese. These benchmarks encompass a wide range of tasks, including contextual question-answering, summarization, classification, and table understanding. The proposed benchmarks offer a comprehensive evaluation framework, enabling the assessment of language models' capabilities across different tasks. In this paper, we evaluate the performance of GPT-3.5, Taiwa
    
[^18]: 发掘知识密集型对话生成中证据的潜力

    Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation. (arXiv:2309.08380v1 [cs.CL])

    [http://arxiv.org/abs/2309.08380](http://arxiv.org/abs/2309.08380)

    本研究提出了一种有效地将证据纳入知识密集型对话生成的框架 (u-EIDG)，通过引入自动证据生成框架，从无标签数据中挖掘可靠的证据真实性标签，以提高对话回答的准确性。

    

    将外部知识纳入对话生成的过程对于提高回答的准确性至关重要，其中证据片段作为知识性的支撑支持对话回复的事实。然而，引入无关内容往往会对回复质量产生负面影响，并容易导致虚构的回应。先前关于证据检索与整合的对话系统的工作没有充分利用现有证据，因为模型无法准确地定位有用的片段，并忽视了KIDG数据集中的隐藏证据标签。为了充分发掘证据的潜力，我们提出了一个有效地将证据纳入知识密集型对话生成中的框架（u-EIDG）。具体而言，我们引入了一个自动证据生成的框架，利用大型语言模型（LLMs）的强大能力从无标签数据中挖掘可靠的证据真实性标签。通过利用这些证据标签，我们训练了一个可靠的证据指示器。

    Incorporating external knowledge into dialogue generation (KIDG) is crucial for improving the correctness of response, where evidence fragments serve as knowledgeable snippets supporting the factual dialogue replies. However, introducing irrelevant content often adversely impacts reply quality and easily leads to hallucinated responses. Prior work on evidence retrieval and integration in dialogue systems falls short of fully leveraging existing evidence since the model fails to locate useful fragments accurately and overlooks hidden evidence labels within the KIDG dataset. To fully Unleash the potential of evidence, we propose a framework to effectively incorporate Evidence in knowledge-Intensive Dialogue Generation (u-EIDG). Specifically, we introduce an automatic evidence generation framework that harnesses the power of Large Language Models (LLMs) to mine reliable evidence veracity labels from unlabeled data. By utilizing these evidence labels, we train a reliable evidence indicator
    
[^19]: PatFig：为专利图生成短文和长文标题

    PatFig: Generating Short and Long Captions for Patent Figures. (arXiv:2309.08379v1 [cs.CV])

    [http://arxiv.org/abs/2309.08379](http://arxiv.org/abs/2309.08379)

    本文介绍了Qatent PatFig数据集，该数据集提供了30,000多个专利图的短文和长文标题、参考编号、术语和描述图像组件之间互动的最小索赔集。在数据集上对LVLM模型进行微调后，发现引入不同基于文本的线索可以改善专利图标题生成的效果。

    

    本文介绍了Qatent PatFig，一个新颖的大规模专利图数据集，包括来自超过11,000个欧洲专利申请的30,000多个专利图。对于每个图，该数据集提供了短文和长文标题、参考编号及其相应术语，以及描述图像组件之间互动的最小索赔集。为了评估数据集的可用性，我们在Qatent PatFig上对LVLM模型进行了微调，以生成短文和长文描述，并研究了在专利图标题生成过程的预测阶段引入不同基于文本的线索的效果。

    This paper introduces Qatent PatFig, a novel large-scale patent figure dataset comprising 30,000+ patent figures from over 11,000 European patent applications. For each figure, this dataset provides short and long captions, reference numerals, their corresponding terms, and the minimal claim set that describes the interactions between the components of the image. To assess the usability of the dataset, we finetune an LVLM model on Qatent PatFig to generate short and long descriptions, and we investigate the effects of incorporating various text-based cues at the prediction stage of the patent figure captioning process.
    
[^20]: DiaCorrect：扬声器分析的错误校正后端

    DiaCorrect: Error Correction Back-end For Speaker Diarization. (arXiv:2309.08377v1 [eess.AS])

    [http://arxiv.org/abs/2309.08377](http://arxiv.org/abs/2309.08377)

    DiaCorrect是一个错误校正后端框架，用于改进扬声器分析系统的输出。该模型利用输入录音和初始系统输出之间的相互作用，自动纠正初始的说话者活动，以减少分析错误。

    

    在这项工作中，我们提出了一种名为DiaCorrect的错误校正框架，以一种简单而有效的方式改进扬声器分析系统的输出。这种方法受到自动语音识别中的错误校正技术的启发。我们的模型由两个并行的卷积编码器和一个基于转换的解码器组成。通过利用输入录音和初始系统输出之间的相互作用，DiaCorrect可以自动纠正初始的说话者活动，以最小化分析错误。在2个扬声器电话数据上的实验证明，所提出的DiaCorrect可以有效地改进初始模型的结果。我们的源代码公开可用于 https://github.com/BUTSpeechFIT/diacorrect.

    In this work, we propose an error correction framework, named DiaCorrect, to refine the output of a diarization system in a simple yet effective way. This method is inspired by error correction techniques in automatic speech recognition. Our model consists of two parallel convolutional encoders and a transform-based decoder. By exploiting the interactions between the input recording and the initial system's outputs, DiaCorrect can automatically correct the initial speaker activities to minimize the diarization errors. Experiments on 2-speaker telephony data show that the proposed DiaCorrect can effectively improve the initial model's results. Our source code is publicly available at https://github.com/BUTSpeechFIT/diacorrect.
    
[^21]: 无头语言模型：通过对比权重绑定学习而非预测

    Headless Language Models: Learning without Predicting with Contrastive Weight Tying. (arXiv:2309.08351v1 [cs.CL])

    [http://arxiv.org/abs/2309.08351](http://arxiv.org/abs/2309.08351)

    该论文提出了一种无头语言模型的创新方法，通过对比权重绑定的方式对输入嵌入进行重构，从而提高了下游性能和数据效率，并且在计算预算相似的情况下，获得了显著的GLUE分数增加和LAMBADA准确性提高。

    

    自监督的语言模型预训练通常涉及对大量单词进行概率预测。在本研究中，我们提出了一种创新的方法，将注意力从概率预测转移到通过对比权重绑定的方式对输入嵌入进行重构。我们将这种方法应用于在单语和多语境下预训练无头语言模型。我们的方法具有实际优势，可以将训练计算要求减少高达20倍，同时增强下游性能和数据效率。与在相似计算预算下的传统语言模型相比，我们观察到显著的+1.6 GLUE分数增加和显著的+2.7 LAMBADA准确性提高。

    Self-supervised pre-training of language models usually consists in predicting probability distributions over extensive token vocabularies. In this study, we propose an innovative method that shifts away from probability prediction and instead focuses on reconstructing input embeddings in a contrastive fashion via Constrastive Weight Tying (CWT). We apply this approach to pretrain Headless Language Models in both monolingual and multilingual contexts. Our method offers practical advantages, substantially reducing training computational requirements by up to 20 times, while simultaneously enhancing downstream performance and data efficiency. We observe a significant +1.6 GLUE score increase and a notable +2.7 LAMBADA accuracy improvement compared to classical LMs within similar compute budgets.
    
[^22]: 生成半结构化解释的奖励工程

    Reward Engineering for Generating Semi-structured Explanation. (arXiv:2309.08347v1 [cs.CL])

    [http://arxiv.org/abs/2309.08347](http://arxiv.org/abs/2309.08347)

    本论文提出了一种奖励工程方法，在生成语言模型的半结构化解释方面取得了增强效果，解决了模型推理能力验证的问题。

    

    半结构化解释描绘了一个推理者的隐式过程和显式表示。这种解释突出了在特定查询中可用信息如何与推理者从内部权重产生的信息相结合，以生成答案。尽管语言模型的生成能力最近有所改进，但生成结构化解释以验证模型真正的推理能力仍然是一个挑战。对于规模不是很大的语言模型而言，这个问题尤为明显，因为推理者被期望将顺序的答案与体现正确展示和正确推理过程的结构化解释相结合。在这项工作中，我们首先强调了监督微调(SFT)在应对这一挑战方面的局限性，然后在强化学习(RL)中引入了一种精心设计的奖励工程方法，以更好地解决这个问题。我们研究了多种奖励聚合方法，并提供了一种...

    Semi-structured explanation depicts the implicit process of a reasoner with an explicit representation. This explanation highlights how available information in a specific query is supplemented with information a reasoner produces from its internal weights towards generating an answer. Despite the recent improvements in generative capabilities of language models, producing structured explanations to verify model's true reasoning capabilities remains a challenge. This issue is particularly pronounced for not-so-large LMs, as the reasoner is expected to couple a sequential answer with a structured explanation which embodies both the correct presentation and the correct reasoning process. In this work, we first underscore the limitations of supervised fine-tuning (SFT) in tackling this challenge, and then introduce a carefully crafted reward engineering method in reinforcement learning (RL) to better address this problem. We investigate multiple reward aggregation methods and provide a de
    
[^23]: 语言模型在与知识库进行连接时的数据分布瓶颈

    Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases. (arXiv:2309.08345v1 [cs.CL])

    [http://arxiv.org/abs/2309.08345](http://arxiv.org/abs/2309.08345)

    本文通过实验调查揭示了语言模型在与知识库进行连接时的数据分布瓶颈，包括推广到未见域、适应语言变体和在不同数据集之间的可转移性等方面。即使采用数据增强技术，先进的语言模型在多个方面表现出较差的性能。

    

    语言模型（LM）已经展示了在理解和生成自然语言和形式语言方面的卓越能力。尽管取得了这些进展，但它们与大规模知识库等现实环境的整合仍然是一个欠发展的领域，影响了语义解析等应用，并且容易出现“产生虚假信息”的问题。本文通过实验调查揭示了LM在处理知识库问答（KBQA）任务时所遇到的健壮性挑战。研究覆盖了训练和推断之间数据分布不一致的场景，例如推广到未见域、适应各种语言变体和在不同数据集之间的可转移性。我们的全面实验揭示了即使在采用我们提出的数据增强技术的情况下，先进的小型和大型语言模型在多个方面表现出较差的性能。

    Language models (LMs) have already demonstrated remarkable abilities in understanding and generating both natural and formal language. Despite these advances, their integration with real-world environments such as large-scale knowledge bases (KBs) remains an underdeveloped area, affecting applications such as semantic parsing and indulging in "hallucinated" information. This paper is an experimental investigation aimed at uncovering the robustness challenges that LMs encounter when tasked with knowledge base question answering (KBQA). The investigation covers scenarios with inconsistent data distribution between training and inference, such as generalization to unseen domains, adaptation to various language variations, and transferability across different datasets. Our comprehensive experiments reveal that even when employed with our proposed data augmentation techniques, advanced small and large language models exhibit poor performance in various dimensions. While the LM is a promisin
    
[^24]: 分布包含假设与量化：在功能分布语义中探究上位词关系

    Distributional Inclusion Hypothesis and Quantifications: Probing Hypernymy in Functional Distributional Semantics. (arXiv:2309.08325v1 [cs.CL])

    [http://arxiv.org/abs/2309.08325](http://arxiv.org/abs/2309.08325)

    本文研究了在功能分布语义中，当语料库严格遵循分布包含假设时，功能分布语义模型可以学习到上位词关系。同时，引入一种训练目标使得模型可以处理普遍量化，从而在分布包含假设的反向下实现上位词关系的学习。实验结果验证了这些假设和目标的有效性。

    

    功能分布语义（FDS）通过真条件函数对单词的含义进行建模。当语料库严格遵循分布包含假设时，FDS模型可以学习到上位词关系。我们进一步引入了一种训练目标，使得FDS模型可以处理简单的普遍量化，从而在分布包含假设的反向下实现上位词关系的学习。对合成数据集和真实数据集的实验结果验证了我们的假设以及我们提出的目标的有效性。

    Functional Distributional Semantics (FDS) models the meaning of words by truth-conditional functions. This provides a natural representation for hypernymy, but no guarantee that it is learnt when FDS models are trained on a corpus. We demonstrate that FDS models learn hypernymy when a corpus strictly follows the Distributional Inclusion Hypothesis. We further introduce a training objective that allows FDS to handle simple universal quantifications, thus enabling hypernymy learning under the reverse of DIH. Experimental results on both synthetic and real data sets confirm our hypotheses and the effectiveness of our proposed objective.
    
[^25]: 跨越主题、领域和语言变化：对全面的非分布场景进行评估

    Bridging Topic, Domain, and Language Shifts: An Evaluation of Comprehensive Out-of-Distribution Scenarios. (arXiv:2309.08316v1 [cs.CL])

    [http://arxiv.org/abs/2309.08316](http://arxiv.org/abs/2309.08316)

    本论文评估了语言模型在跨越主题、领域和语言变化的全面非分布场景中的泛化能力，并提出了改进策略，包括基于提示的精细调节和上下文学习。

    

    语言模型在独立且同分布的训练和测试数据中表现出色。然而，在实际应用中（如争论挖掘），它们的性能经常下降。这种降级发生在新话题出现，或其他文本领域和语言变得相关的情况下。为了评估语言模型在这些非分布场景中的泛化能力，我们通过有意地保留特定实例进行测试来模拟这种分布变化，例如社交媒体领域或太阳能主题。与先前关注特定变化和度量标准的研究不同，我们全面分析了泛化问题。我们定义了三个度量标准来确定泛化缺陷，并提出了涵盖主题、领域和语言变化的十一个分类任务。总体来说，我们发现基于提示的精细调节具有更卓越的性能，特别是在训练集和测试集在语义上主要有差异的情况下。同时，在上下文学习方面也有类似的发现。

    Language models (LMs) excel in in-distribution (ID) scenarios where train and test data are independent and identically distributed. However, their performance often degrades in real-world applications like argument mining. Such degradation happens when new topics emerge, or other text domains and languages become relevant. To assess LMs' generalization abilities in such out-of-distribution (OOD) scenarios, we simulate such distribution shifts by deliberately withholding specific instances for testing, as from the social media domain or the topic Solar Energy.  Unlike prior studies focusing on specific shifts and metrics in isolation, we comprehensively analyze OOD generalization. We define three metrics to pinpoint generalization flaws and propose eleven classification tasks covering topic, domain, and language shifts. Overall, we find superior performance of prompt-based fine-tuning, notably when train and test splits primarily differ semantically. Simultaneously, in-context learning
    
[^26]: 自洽叙述式启示在演绎自然语言推理中的应用

    Self-Consistent Narrative Prompts on Abductive Natural Language Inference. (arXiv:2309.08303v1 [cs.CL])

    [http://arxiv.org/abs/2309.08303](http://arxiv.org/abs/2309.08303)

    该论文提出了一个考虑自洽性和句间连贯性的自然语言推理模型，并通过实验证明了其有效性。

    

    对于故事理解和日常情境推理，演绎一直被视为至关重要的。提出了一种基于自然语言的演绎任务 - 自然语言推理（$\alpha$NLI）任务，旨在从两个观察中推断出最合理的假设。然而，在以往的研究中，句间连贯性和模型一致性的利用并不充分。本文提出了一个考虑自洽性和句间连贯性的提示调优模型 $\alpha$-PACE。此外，还提出了一个通用的自洽框架，用于引导预训练语言模型理解输入的叙述背景，其中包括线性叙述和逆时间顺序等各种叙述序列。通过大量实验证明了 $\alpha$-PACE 的必要性和有效性。我们的方法的性能表现出显著的改善。

    Abduction has long been seen as crucial for narrative comprehension and reasoning about everyday situations. The abductive natural language inference ($\alpha$NLI) task has been proposed, and this narrative text-based task aims to infer the most plausible hypothesis from the candidates given two observations. However, the inter-sentential coherence and the model consistency have not been well exploited in the previous works on this task. In this work, we propose a prompt tuning model $\alpha$-PACE, which takes self-consistency and inter-sentential coherence into consideration. Besides, we propose a general self-consistent framework that considers various narrative sequences (e.g., linear narrative and reverse chronology) for guiding the pre-trained language model in understanding the narrative context of input. We conduct extensive experiments and thorough ablation studies to illustrate the necessity and effectiveness of $\alpha$-PACE. The performance of our method shows significant im
    
[^27]: Transformer结构自监督目标的研究

    Structural Self-Supervised Objectives for Transformers. (arXiv:2309.08272v1 [cs.CL])

    [http://arxiv.org/abs/2309.08272](http://arxiv.org/abs/2309.08272)

    本论文提出了三种替代BERT掩码语言模型的预训练目标，包括随机标记置换（RTS）、基于簇的随机标记置换（C-RTS）和交换语言建模（SLM），并且证明这些目标在保持性能的同时，需要更少的预训练时间。此外，本论文还提出了一种结构与下游应用匹配的自监督预训练任务，减少了对标记数据的需求。

    

    本论文旨在通过使用无监督原始数据改进自然语言模型的预训练，使其更高效且与下游应用更加一致。在第一部分中，我们引入了三个替代BERT的掩码语言模型（MLM）的预训练目标，分别是随机标记置换（RTS）、基于簇的随机标记置换（C-RTS）和交换语言建模（SLM）。这些目标涉及到标记的交换而不是屏蔽，其中RTS和C-RTS旨在预测标记的原始性，而SLM则预测原始标记的值。结果显示，RTS和C-RTS需要更少的预训练时间，同时保持与MLM可比较的性能。令人惊讶的是，尽管使用了相同的计算预算，SLM在某些任务上的表现优于MLM。在第二部分中，我们提出了一种结构与下游应用匹配的自监督预训练任务，从而减少了对标记数据的需求。我们使用维基百科和CC-News等大型语料库进行训练。

    This thesis focuses on improving the pre-training of natural language models using unsupervised raw data to make them more efficient and aligned with downstream applications.  In the first part, we introduce three alternative pre-training objectives to BERT's Masked Language Modeling (MLM), namely Random Token Substitution (RTS), Cluster-based Random Token Substitution (C-RTS), and Swapped Language Modeling (SLM). These objectives involve token swapping instead of masking, with RTS and C-RTS aiming to predict token originality and SLM predicting the original token values. Results show that RTS and C-RTS require less pre-training time while maintaining performance comparable to MLM. Surprisingly, SLM outperforms MLM on certain tasks despite using the same computational budget.  In the second part, we proposes self-supervised pre-training tasks that align structurally with downstream applications, reducing the need for labeled data. We use large corpora like Wikipedia and CC-News to trai
    
[^28]: 通过基于流的语音转换实现跨语言知识蒸馏，用于鲁棒的多语种语音合成

    Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for Robust Polyglot Text-To-Speech. (arXiv:2309.08255v1 [eess.AS])

    [http://arxiv.org/abs/2309.08255](http://arxiv.org/abs/2309.08255)

    本文提出了一个跨语言语音合成的框架，使用语音转换和文本到语音模型，优于基于多语种模型的最先进方法，特别适用于资源匮乏的情况。

    

    在这项工作中，我们引入了一个跨语言语音合成的框架，其中包括一个上游语音转换（VC）模型和一个下游文本到语音（TTS）模型。我们的框架包括4个阶段。在前两个阶段中，我们使用VC模型将目标区域的话语转换为目标说话者的声音。在第三个阶段，将转换后的数据与目标语言录音中的语言特征和持续时间结合起来，然后用于训练一个单说话人声学模型。最后，最后一个阶段将训练一个与语言无关的声码器。我们的评估结果显示，这种提出的范例优于基于训练大型多语种TTS模型的最先进方法。此外，我们的实验证明了我们的方法在不同的模型架构、语言、说话者和数据量方面的鲁棒性。此外，我们的解决方案在资源匮乏的情况下特别有益。

    In this work, we introduce a framework for cross-lingual speech synthesis, which involves an upstream Voice Conversion (VC) model and a downstream Text-To-Speech (TTS) model. The proposed framework consists of 4 stages. In the first two stages, we use a VC model to convert utterances in the target locale to the voice of the target speaker. In the third stage, the converted data is combined with the linguistic features and durations from recordings in the target language, which are then used to train a single-speaker acoustic model. Finally, the last stage entails the training of a locale-independent vocoder. Our evaluations show that the proposed paradigm outperforms state-of-the-art approaches which are based on training a large multilingual TTS model. In addition, our experiments demonstrate the robustness of our approach with different model architectures, languages, speakers and amounts of data. Moreover, our solution is especially beneficial in low-resource settings.
    
[^29]: 探究LLMs在长篇问题回答方面的可回答性

    Investigating Answerability of LLMs for Long-Form Question Answering. (arXiv:2309.08210v1 [cs.CL])

    [http://arxiv.org/abs/2309.08210](http://arxiv.org/abs/2309.08210)

    本研究主要探究LLMs在长篇问题回答方面的可回答性，通过提出从抽象摘要生成问题的方法，展示了从长文档摘要中生成后续问题对LLMs进行推理和推断的挑战，并确认了LLMs之间的性能差距。

    

    随着我们进入LLMs的新时代，理解它们的能力、限制和差异变得越来越重要。为了进一步在这个方向上取得进展，我们致力于更深入地了解大型LLMs（例如ChatGPT）与更小但有效的开源LLMs及其精简版本之间的差距。为此，我们特别关注长篇问题回答（LFQA），因为它在实践中有多个实际且有影响力的应用（例如故障排除、客户服务等），但对LLMs来说仍然是不够研究且具有挑战性的。我们提出了一种从抽象摘要生成问题的方法，并展示了从长文档摘要中生成后续问题可以为LLMs提供从长上下文进行推理和推断的挑战性环境。我们的实验结果证实：（1）我们提出的从抽象摘要生成问题的方法为LLMs提出了一个具有挑战性的设置，并显示了LLMs之间的性能差距

    As we embark on a new era of LLMs, it becomes increasingly crucial to understand their capabilities, limitations, and differences. Toward making further progress in this direction, we strive to build a deeper understanding of the gaps between massive LLMs (e.g., ChatGPT) and smaller yet effective open-source LLMs and their distilled counterparts. To this end, we specifically focus on long-form question answering (LFQA) because it has several practical and impactful applications (e.g., troubleshooting, customer service, etc.) yet is still understudied and challenging for LLMs. We propose a question-generation method from abstractive summaries and show that generating follow-up questions from summaries of long documents can create a challenging setting for LLMs to reason and infer from long contexts. Our experimental results confirm that: (1) our proposed method of generating questions from abstractive summaries pose a challenging setup for LLMs and shows performance gaps between LLMs li
    
[^30]: 编码概括：将文件概括为连续向量空间，用于法律案例检索

    Encoded Summarization: Summarizing Documents into Continuous Vector Space for Legal Case Retrieval. (arXiv:2309.08187v1 [cs.CL])

    [http://arxiv.org/abs/2309.08187](http://arxiv.org/abs/2309.08187)

    该论文提出了一种将文件编码为连续向量空间的方法，用于法律案例检索任务。实验证明，将词汇特征和神经网络生成的潜在特征相结合可以提高检索系统性能。该方法在实验数据集上取得了较高的F1分数。

    

    通过我们的短语评分框架和深度神经网络，我们提出了一种将文件编码为连续向量空间的方法，用于应对法律案例检索任务。另一方面，我们探索了使用词汇特征和神经网络生成的潜在特征的好处。我们的实验证明，词汇特征和神经网络生成的潜在特征相互补充，可以提高检索系统性能。此外，我们的实验结果表明，案例概括在不同方面的重要性：使用提供的概括和进行编码概括。我们的方法在法律案例检索任务的实验数据集上实现了65.6%和57.6%的F1分数。

    We present our method for tackling a legal case retrieval task by introducing our method of encoding documents by summarizing them into continuous vector space via our phrase scoring framework utilizing deep neural networks. On the other hand, we explore the benefits from combining lexical features and latent features generated with neural networks. Our experiments show that lexical features and latent features generated with neural networks complement each other to improve the retrieval system performance. Furthermore, our experimental results suggest the importance of case summarization in different aspects: using provided summaries and performing encoded summarization. Our approach achieved F1 of 65.6% and 57.6% on the experimental datasets of legal case retrieval tasks.
    
[^31]: 使用元蒸馏学习进行多语句级语义搜索

    Multilingual Sentence-Level Semantic Search using Meta-Distillation Learning. (arXiv:2309.08185v1 [cs.CL])

    [http://arxiv.org/abs/2309.08185](http://arxiv.org/abs/2309.08185)

    本论文提出了一种基于元蒸馏学习的对齐方法，用于多语句级语义搜索任务中的低资源情况。通过将知识从单语到双语语义搜索进行传递，并从双语到多语语义搜索进行元传递，实现了对多语境的扩展。

    

    多语句级语义搜索是在不同语言组合中检索与查询相关内容的任务。这需要更好地理解用户意图和上下文含义。与单语或双语搜索相比，多语句级语义搜索相对较少被探索且更具挑战性，这是由于该任务缺乏多语言并行资源和需要规避“语言偏见”。在本研究中，我们提出了一种用于低资源场景的对齐方法：MAML-Align。我们的方法利用基于元蒸馏学习的MAML，即基于优化的模型不可知元学习器，将知识从专门从单语到双语语义搜索进行传递的教师元传递模型T-MAML蒸馏到学生模型S-MAML，后者从双语到多语语义搜索进行元传递。据我们所知，我们是第一个将元蒸馏应用于多语境的研究。

    Multilingual semantic search is the task of retrieving relevant contents to a query expressed in different language combinations. This requires a better semantic understanding of the user's intent and its contextual meaning. Multilingual semantic search is less explored and more challenging than its monolingual or bilingual counterparts, due to the lack of multilingual parallel resources for this task and the need to circumvent "language bias". In this work, we propose an alignment approach: MAML-Align, specifically for low-resource scenarios. Our approach leverages meta-distillation learning based on MAML, an optimization-based Model-Agnostic Meta-Learner. MAML-Align distills knowledge from a Teacher meta-transfer model T-MAML, specialized in transferring from monolingual to bilingual semantic search, to a Student model S-MAML, which meta-transfers from bilingual to multilingual semantic search. To the best of our knowledge, we are the first to extend meta-distillation to a multilingu
    
[^32]: 使用大型语言模型解决和解释物理词问题接近人类水平

    Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level. (arXiv:2309.08182v1 [cs.CL])

    [http://arxiv.org/abs/2309.08182](http://arxiv.org/abs/2309.08182)

    本研究证明，使用大型语言模型(如GPT3.5)可以解决和解释物理词问题，通过对物理知识进行计算和推理，实现了接近人类水平的解决率。此外，该模型还能够总结涉及的知识、生成解释，并创造新的物理词问题。

    

    我们的工作表明，基于文本预训练的大型语言模型(LLM)不仅可以解决纯数学题，还可以解决物理词问题-即基于先前的物理知识进行计算和推理的问题。我们收集并注释了第一个物理词问题数据集-PhysQA，其中包含超过1000个初中物理词问题（包括运动学、质量和密度、力学、热学和电学）。然后我们使用OpenAI的GPT3.5来生成这些问题的答案，发现GPT3.5可以在零样本学习上自动解决49.3%的问题，在少样本学习上则为73.2%。这个结果表明，通过使用类似问题及其答案作为提示，LLM可以解决接近人类水平的基础物理词问题。除了自动解决问题，GPT3.5还可以总结问题涉及的知识或主题，生成相关解释，并根据输入问题综合出新的物理词问题。

    Our work demonstrates that large language model (LLM) pre-trained on texts can not only solve pure math word problems, but also physics word problems-problems to be solved by calculation and inference based on some prior physical knowledge. We collect and annotate the first physics word problem dataset-PhysQA, which contains over 1000 junior high school physics word problems (on Kinematics, Mass&Density, Mechanics, Heat, Electricity). Then we use OpenAI' s GPT3.5 to generate the answer of these problems and found that GPT3.5 could automatically solve 49.3% of the problems on zero-shot learning and 73.2% on few-shot learning. This result show that by using similar problem and its answer as prompt, LLM could solve elementary physics word problems approaching human level. Besides automatically solving problems, GPT3.5 could also summarize the knowledge or topic examined by the problem, generate the relevant explanation, and synthesis new physics word problems according tothe input problem
    
[^33]: 大型语言模型用于故障模式分类的研究

    Large Language Models for Failure Mode Classification: An Investigation. (arXiv:2309.08181v1 [cs.CL])

    [http://arxiv.org/abs/2309.08181](http://arxiv.org/abs/2309.08181)

    本研究探讨了大型语言模型在故障模式分类中的应用，通过细调GPT-3.5模型在注释数据上取得了显著提升的性能，优于当前可用的文本分类模型和开箱即用的GPT-3.5模型。

    

    本文首次研究了大型语言模型 (LLMs) 在故障模式分类 (FMC) 中的有效性。FMC 是在维护领域中自动为观测结果标记相应故障模式代码的重要任务，它可以减少可靠性工程师手动分析工作指令的时间。我们详细介绍了我们的方法，即通过提示工程来使 LLM 能够使用受限制的代码列表来预测给定观测结果的故障模式。我们证明了在注释数据上细调的 GPT-3.5 模型 (F1=0.80) 的性能显著优于当前可用的在相同注释数据集上训练的文本分类模型 (F1=0.60)。细调模型还优于开箱即用的 GPT-3.5 (F1=0.46)。该研究强调了对使用LLMs进行领域特定任务的高质量微调数据集的需求。

    In this paper we present the first investigation into the effectiveness of Large Language Models (LLMs) for Failure Mode Classification (FMC). FMC, the task of automatically labelling an observation with a corresponding failure mode code, is a critical task in the maintenance domain as it reduces the need for reliability engineers to spend their time manually analysing work orders. We detail our approach to prompt engineering to enable an LLM to predict the failure mode of a given observation using a restricted code list. We demonstrate that the performance of a GPT-3.5 model (F1=0.80) fine-tuned on annotated data is a significant improvement over a currently available text classification model (F1=0.60) trained on the same annotated data set. The fine-tuned model also outperforms the out-of-the box GPT-3.5 (F1=0.46). This investigation reinforces the need for high quality fine-tuning data sets for domain-specific tasks using LLMs.
    
[^34]: FedJudge: 分布式法律大型语言模型

    FedJudge: Federated Legal Large Language Model. (arXiv:2309.08173v1 [cs.CL])

    [http://arxiv.org/abs/2309.08173](http://arxiv.org/abs/2309.08173)

    本文提出了第一个分布式法律大型语言模型（FedJudge）框架，可以通过在设备或客户端上进行本地微调，并将参数聚合和分布在中央服务器上来确保数据隐私。这解决了集中式训练法律LLMs引发的数据隐私问题和分布偏移导致的FL方法效果降低的挑战。

    

    大型语言模型（LLMs）在法律智能领域得到了广泛应用，可以辅助法律专业人员和普通人。然而，这些法律LLMs的集中式训练引发了数据隐私问题，因为法律数据分散在包含敏感个人信息的各个机构之间。本文通过探索将法律LLMs与分布式学习（FL）方法相结合来解决这一挑战。通过使用FL，法律LLMs可以在设备或客户端上进行本地微调，其参数被聚合并分布在中央服务器上，确保数据隐私而无需直接共享原始数据。然而，计算和通信开销阻碍了LLMs在FL环境中的全面微调。此外，法律数据的分布偏移减少了FL方法的有效性。为此，在本文中，我们提出了第一个分布式法律大型语言模型（FedJudge）框架，可以对LLMs进行微调。

    Large Language Models (LLMs) have gained prominence in the field of Legal Intelligence, offering potential applications in assisting legal professionals and laymen. However, the centralized training of these Legal LLMs raises data privacy concerns, as legal data is distributed among various institutions containing sensitive individual information. This paper addresses this challenge by exploring the integration of Legal LLMs with Federated Learning (FL) methodologies. By employing FL, Legal LLMs can be fine-tuned locally on devices or clients, and their parameters are aggregated and distributed on a central server, ensuring data privacy without directly sharing raw data. However, computation and communication overheads hinder the full fine-tuning of LLMs under the FL setting. Moreover, the distribution shift of legal data reduces the effectiveness of FL methods. To this end, in this paper, we propose the first Federated Legal Large Language Model (FedJudge) framework, which fine-tunes 
    
[^35]: LASER：具有状态空间探索的LLM代理用于Web导航

    LASER: LLM Agent with State-Space Exploration for Web Navigation. (arXiv:2309.08172v1 [cs.CL])

    [http://arxiv.org/abs/2309.08172](http://arxiv.org/abs/2309.08172)

    本论文提出了一种基于状态空间探索的LLM代理（LASER）用于Web导航任务。该代理以灵活的方式转换状态，通过执行动作完成任务，能够轻松从错误中恢复，并取得了显著的性能提升。

    

    大型语言模型（LLM）已成功应用于诸如Web导航之类的交互式决策任务。尽管取得了不错的性能，但先前的方法隐含地假设模型只能以正向方式执行，在交互环境中仅提供正例轨迹作为上下文示例，教授模型如何进行推理。因此，模型无法处理更具挑战性的情况，例如错误，从而导致次优性能。为了解决这个问题，我们提出将交互任务建模为状态空间探索，其中LLM代理通过执行动作在预定义的一组状态之间进行转换以完成任务。这种形式化方法使得模型可以灵活地进行回溯，从而能够轻松从错误中恢复。我们在WebShop任务上评估我们提出的LASER代理。实验结果表明，我们的LASER代理明显优于以前的方法。

    Large language models (LLMs) have been successfully adapted for interactive decision-making tasks like web navigation. While achieving decent performance, previous methods implicitly assume a forward-only execution mode for the model, where they only provide oracle trajectories as in-context examples to teach the model how to reason in the interactive environment. Consequently, the model could not handle more challenging scenarios not covered in the in-context examples, e.g., mistakes, leading to sub-optimal performance. To address this issue, we propose to model the interactive task as state space exploration, where the LLM agent transitions among a pre-defined set of states by performing actions to complete the task. This formulation enables flexible back-tracking, allowing the model to easily recover from errors. We evaluate our proposed LLM Agent with State-Space ExploRation (LASER) on the WebShop task. Experimental results show that our LASER agent significantly outperforms previo
    
[^36]: 使用自我推测解码实现无损大型语言模型加速的Draft & Verify方法

    Draft & Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding. (arXiv:2309.08168v1 [cs.CL])

    [http://arxiv.org/abs/2309.08168](http://arxiv.org/abs/2309.08168)

    使用自我推测解码的Draft & Verify方法能够加速大型语言模型的推理过程，同时保持输出质量，并不需要额外的训练和内存占用。

    

    我们提出了一种新的推理方案，称为自我推测解码，用于加速大型语言模型（LLM），而无需辅助模型。该方法通过两个阶段的过程来实现：起草和验证。起草阶段以稍低质量但更快的速度生成草案标记，这是通过在起草过程中有选择地跳过某些中间层来实现的。随后，验证阶段使用原始LLM在一次前向传递中验证那些起草产生的输出标记。这个过程确保最终输出与未修改的LLM产生的输出完全相同，从而确保输出质量。所提出的方法不需要额外的神经网络训练和额外的内存占用，可以作为一种即插即用且具有成本效益的推理加速解决方案。

    We present a novel inference scheme, self-speculative decoding, for accelerating Large Language Models (LLMs) without the need for an auxiliary model. This approach is characterized by a two-stage process: drafting and verification. The drafting stage generates draft tokens at a slightly lower quality but more quickly, which is achieved by selectively skipping certain intermediate layers during drafting Subsequently, the verification stage employs the original LLM to validate those draft output tokens in one forward pass. This process ensures the final output remains identical to that produced by the unaltered LLM, thereby maintaining output quality. The proposed method requires no additional neural network training and no extra memory footprint, making it a plug-and-play and cost-effective solution for inference acceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a speedup up to 1.73$\times$.
    
[^37]: 研究自我评估测试在大型语言模型的人格测量中的适用性

    Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models. (arXiv:2309.08163v1 [cs.CL])

    [http://arxiv.org/abs/2309.08163](http://arxiv.org/abs/2309.08163)

    研究发现，使用自我评估测试对大型语言模型的人格进行测量时，不同的提示会导致非常不同的人格得分，因此缺乏客观标准来判断哪个提示更正确。

    

    随着大型语言模型的能力不断发展，各种最近的研究试图使用用于研究人类行为的心理工具来量化它们的行为。其中一个例子是使用人格自我评估测试来衡量大型语言模型的“人格”。在本文中，我们选择了三个关于使用人格自我评估测试来量化大型语言模型的人格的研究。我们使用这三个不同论文中使用的提示来评估同一大型语言模型的人格。我们发现，这三个提示导致了非常不同的人格得分。这一简单测试揭示了大型语言模型中的人格自我评估得分取决于提示者的主观选择。由于我们不知道大型语言模型的人格得分的真实值，因为此类问题没有正确答案，所以无法声明某个提示比其他提示更正确或更不正确。然后，我们引入了人格选项顺序对称性的属性。

    As large language models (LLM) evolve in their capabilities, various recent studies have tried to quantify their behavior using psychological tools created to study human behavior. One such example is the measurement of "personality" of LLMs using personality self-assessment tests. In this paper, we take three such studies on personality measurement of LLMs that use personality self-assessment tests created to study human behavior. We use the prompts used in these three different papers to measure the personality of the same LLM. We find that all three prompts lead very different personality scores. This simple test reveals that personality self-assessment scores in LLMs depend on the subjective choice of the prompter. Since we don't know the ground truth value of personality scores for LLMs as there is no correct answer to such questions, there's no way of claiming if one prompt is more or less correct than the other. We then introduce the property of option order symmetry for persona
    
[^38]: RADE: 基于参考的开放领域对话评估

    RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue. (arXiv:2309.08156v1 [cs.CL])

    [http://arxiv.org/abs/2309.08156](http://arxiv.org/abs/2309.08156)

    基于参考的对话评估（RADE）方法利用预创建的语句作为参考，以解决开放领域对话系统中的一对多问题，并通过共享编码器增强预测。

    

    评估开放领域的对话系统具有挑战性，原因在于一对多问题，即除了黄金回应以外还有许多适当的回应。目前，自动评估方法需要更好地与人类保持一致，而可靠的人工评估可能耗时和耗资。为此，我们提出了基于参考的对话评估（RADE）方法，该方法利用预创建的语句作为参考，而不仅仅是黄金回应，以缓解一对多问题。具体而言，

    Evaluating open-domain dialogue systems is challenging for reasons such as the one-to-many problem, i.e., many appropriate responses other than just the golden response. As of now, automatic evaluation methods need better consistency with humans, while reliable human evaluation can be time- and cost-intensive. To this end, we propose the Reference-Assisted Dialogue Evaluation (RADE) approach under the multi-task learning framework, which leverages the pre-created utterance as reference other than the gold response to relief the one-to-many problem. Specifically, RADE explicitly compares reference and the candidate response to predict their overall scores. Moreover, an auxiliary response generation task enhances prediction via a shared encoder. To support RADE, we extend three datasets with additional rated responses other than just a golden response by human annotation. Experiments on our three datasets and two existing benchmarks demonstrate the effectiveness of our method, where Pear
    
[^39]: CTC-based语音识别的单模聚合方法

    Unimodal Aggregation for CTC-based Speech Recognition. (arXiv:2309.08150v1 [cs.CL])

    [http://arxiv.org/abs/2309.08150](http://arxiv.org/abs/2309.08150)

    本文提出了一种在CTC-based语音识别中用于学习更好的特征表示和缩短序列长度的单模聚合方法(UMA)，通过分割和集成同一文本标记的特征帧，实现了更低的识别错误和计算复杂度。实验证明，UMA在普通话数据集上表现出较好的性能，并且通过集成自条件CTC可以进一步提高性能。

    

    本文针对非自回归自动语音识别进行研究。提出了一种单模聚合（UMA）方法，用于对属于同一文本标记的特征帧进行分割和集成，从而学习更好的文本标记特征表示。特征帧和权重都来自于编码器。然后，使用单模权重集成特征帧，并经过解码器进一步处理。训练时采用了连接主义时间分类（CTC）损失。与常规CTC相比，所提出的方法学习到了更好的特征表示，并缩短了序列长度，从而降低了识别错误和计算复杂度。在三个普通话数据集上的实验结果表明，UMA相比其他先进的非自回归方法（如自条件CTC）表现出更好或相当的性能。此外，通过将自条件CTC集成到所提出的框架中，性能可以进一步显著提高。

    This paper works on non-autoregressive automatic speech recognition. A unimodal aggregation (UMA) is proposed to segment and integrate the feature frames that belong to the same text token, and thus to learn better feature representations for text tokens. The frame-wise features and weights are both derived from an encoder. Then, the feature frames with unimodal weights are integrated and further processed by a decoder. Connectionist temporal classification (CTC) loss is applied for training. Compared to the regular CTC, the proposed method learns better feature representations and shortens the sequence length, resulting in lower recognition error and computational complexity. Experiments on three Mandarin datasets show that UMA demonstrates superior or comparable performance to other advanced non-autoregressive methods, such as self-conditioned CTC. Moreover, by integrating self-conditioned CTC into the proposed framework, the performance can be further noticeably improved.
    
[^40]: 音频差异学习用于音频字幕生成

    Audio Difference Learning for Audio Captioning. (arXiv:2309.08141v1 [eess.AS])

    [http://arxiv.org/abs/2309.08141](http://arxiv.org/abs/2309.08141)

    本研究引入了音频差异学习方法，通过创建特征表示空间来改进音频字幕生成。该方法使用参考音频和输入音频，生成描述它们差异的字幕，同时提出了一种独特的混合技术来消除差异和原始输入之间的需求。

    

    本研究引入了一种新的训练范式，即音频差异学习，用于改进音频字幕生成。所提出的学习方法的基本概念是创建一个保留音频之间关系的特征表示空间，从而能够生成详细描述复杂音频信息的字幕。该方法使用参考音频和输入音频，通过共享编码器将它们转换为特征表示。然后，从这些差异特征生成字幕描述它们的差异。此外，提出了一种独特的技术，涉及将输入音频与额外音频混合，并使用额外音频作为参考。这样，混合音频与参考音频之间的差异回到原始输入音频。这允许将原始输入的字幕作为其差异的字幕使用，消除了为差异添加额外注释的需求。

    This study introduces a novel training paradigm, audio difference learning, for improving audio captioning. The fundamental concept of the proposed learning method is to create a feature representation space that preserves the relationship between audio, enabling the generation of captions that detail intricate audio information. This method employs a reference audio along with the input audio, both of which are transformed into feature representations via a shared encoder. Captions are then generated from these differential features to describe their differences. Furthermore, a unique technique is proposed that involves mixing the input audio with additional audio, and using the additional audio as a reference. This results in the difference between the mixed audio and the reference audio reverting back to the original input audio. This allows the original input's caption to be used as the caption for their difference, eliminating the need for additional annotations for the difference
    
[^41]: PromptTTS++：使用自然语言描述控制提示式文本转语音中的说话者身份

    PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions. (arXiv:2309.08140v1 [eess.AS])

    [http://arxiv.org/abs/2309.08140](http://arxiv.org/abs/2309.08140)

    PromptTTS++是一种基于提示的文本转语音系统，可以使用自然语言描述控制说话者身份。与现有研究不同，该方法利用说话者提示来学习自然语言描述与声学特征的映射。

    

    我们提出了PromptTTS++，一种基于提示的文本转语音（TTS）合成系统，它允许使用自然语言描述来控制说话者身份。为了在基于提示的TTS框架中控制说话者身份，我们引入了说话者提示的概念，该提示描述了语音特征（如中性、年轻、老年和沉闷），旨在与说话风格大致独立。由于目前没有包含说话者提示的大规模数据集，我们首先使用LibriTTS-R语料库构建了一个基于手动注释的说话者提示数据集。然后，我们采用基于扩散的声学模型与混合密度网络来建模训练数据中的多样化说话者因素。与之前仅依赖样式提示的研究不同，样式提示仅描述了说话者个性化的有限方面，如音调、说话速度和能量，我们的方法利用额外的说话者提示来有效地学习从自然语言描述到声学特征的映射。

    We propose PromptTTS++, a prompt-based text-to-speech (TTS) synthesis system that allows control over speaker identity using natural language descriptions. To control speaker identity within the prompt-based TTS framework, we introduce the concept of speaker prompt, which describes voice characteristics (e.g., gender-neutral, young, old, and muffled) designed to be approximately independent of speaking style. Since there is no large-scale dataset containing speaker prompts, we first construct a dataset based on the LibriTTS-R corpus with manually annotated speaker prompts. We then employ a diffusion-based acoustic model with mixture density networks to model diverse speaker factors in the training data. Unlike previous studies that rely on style prompts describing only a limited aspect of speaker individuality, such as pitch, speaking speed, and energy, our method utilizes an additional speaker prompt to effectively learn the mapping from natural language descriptions to the acoustic f
    
[^42]: 《基于实体邻域信息和描述信息的联合表示学习方法研究》

    Research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information. (arXiv:2309.08100v1 [cs.CL])

    [http://arxiv.org/abs/2309.08100](http://arxiv.org/abs/2309.08100)

    该研究提出了一种联合表示学习模型，结合实体邻域信息和描述信息，解决了编程设计课程知识图谱中嵌入效果不佳的问题，并在实验中取得了优于其他基线模型的性能表现。

    

    为解决编程设计课程知识图谱中嵌入效果不佳的问题，提出了一种结合实体邻域信息和描述信息的联合表示学习模型。首先，采用图注意力网络获取实体邻域节点的特征，结合关系特征丰富结构信息。然后，利用BERT-WWM模型结合注意力机制获取实体描述信息的表示。最后，通过将实体邻域信息和描述信息的向量表示相结合，得到最终的实体向量表示。实验结果表明，该模型在编程设计课程的知识图谱数据集上表现出良好的性能，优于其他基线模型。

    To address the issue of poor embedding performance in the knowledge graph of a programming design course, a joint represen-tation learning model that combines entity neighborhood infor-mation and description information is proposed. Firstly, a graph at-tention network is employed to obtain the features of entity neigh-boring nodes, incorporating relationship features to enrich the structural information. Next, the BERT-WWM model is utilized in conjunction with attention mechanisms to obtain the representation of entity description information. Finally, the final entity vector representation is obtained by combining the vector representations of entity neighborhood information and description information. Experimental results demonstrate that the proposed model achieves favorable performance on the knowledge graph dataset of the pro-gramming design course, outperforming other baseline models.
    
[^43]: 刻画通用语音表示的时序动态，实现可推广的深度伪造检测

    Characterizing the temporal dynamics of universal speech representations for generalizable deepfake detection. (arXiv:2309.08099v1 [cs.SD])

    [http://arxiv.org/abs/2309.08099](http://arxiv.org/abs/2309.08099)

    本研究刻画了通用语音表示的时序动态，提出了一种评估表示动态的新方法，该方法能够提高深度伪造检测的可推广性并在实验中取得了显著改进。

    

    现有的深度伪造语音检测系统在面对未见过的攻击样本（即由训练中未见过的生成算法生成的样本）时缺乏可推广性。最近的研究探索了使用通用语音表示来解决这个问题，并取得了令人鼓舞的结果。然而，这些工作主要集中在创新下游分类器，而对表示本身几乎没有改进。在本研究中，我们认为揭示这些表示的长期时序动态对于提高可推广性至关重要，并提出了一种评估表示动态的新方法。实验表明，不同的生成模型在我们提出的方法下生成了类似的表示动态模式。在ASVspoof 2019和2021数据集上的实验验证了所提方法在检测训练中未见过的深度伪造方法方面的优势，并显著改进了多个基准方法。

    Existing deepfake speech detection systems lack generalizability to unseen attacks (i.e., samples generated by generative algorithms not seen during training). Recent studies have explored the use of universal speech representations to tackle this issue and have obtained inspiring results. These works, however, have focused on innovating downstream classifiers while leaving the representation itself untouched. In this study, we argue that characterizing the long-term temporal dynamics of these representations is crucial for generalizability and propose a new method to assess representation dynamics. Indeed, we show that different generative models generate similar representation dynamics patterns with our proposed method. Experiments on the ASVspoof 2019 and 2021 datasets validate the benefits of the proposed method to detect deepfakes from methods unseen during training, significantly improving on several benchmark methods.
    
[^44]: 在新闻分析中连接各个点：关于媒体偏见和框架的跨学科调查

    Connecting the Dots in News Analysis: A Cross-Disciplinary Survey of Media Bias and Framing. (arXiv:2309.08069v1 [cs.CL])

    [http://arxiv.org/abs/2309.08069](http://arxiv.org/abs/2309.08069)

    这篇综述论文回顾了社会科学方法和自然语言处理方法在分析媒体偏见方面的差异，并提出了解决当前方法论鸿沟的可能方向，包括模型透明度、考虑文档外部信息和跨文档推理。

    

    偏见在新闻报道中的表现和影响是社会科学几十年来的核心议题，并且近年来在自然语言处理领域引起了越来越多的关注。虽然自然语言处理可以帮助扩大分析规模或提供自动化程序来调查偏见新闻对社会的影响，但我们认为目前主导地位的方法论未能解决理论媒体研究中涉及的复杂问题和影响。在这篇综述论文中，我们回顾了社会科学方法，并将其与自然语言处理领域中用于分析媒体偏见的典型任务形式、方法和评估指标进行了比较。我们讨论了开放性问题，并提出了解决理论模型和预测模型以及它们的评估之间鸿沟的可能方向。这些包括模型的透明度、考虑文档外部信息、以及跨文档推理而非单标签分配。

    The manifestation and effect of bias in news reporting have been central topics in the social sciences for decades, and have received increasing attention in the NLP community recently. While NLP can help to scale up analyses or contribute automatic procedures to investigate the impact of biased news in society, we argue that methodologies that are currently dominant fall short of addressing the complex questions and effects addressed in theoretical media studies. In this survey paper, we review social science approaches and draw a comparison with typical task formulations, methods, and evaluation metrics used in the analysis of media bias in NLP. We discuss open questions and suggest possible directions to close identified gaps between theory and predictive models, and their evaluation. These include model transparency, considering document-external information, and cross-document reasoning rather than single-label assignment.
    
[^45]: 调查新闻概述中的性别偏见

    Investigating Gender Bias in News Summarization. (arXiv:2309.08047v1 [cs.CL])

    [http://arxiv.org/abs/2309.08047](http://arxiv.org/abs/2309.08047)

    本研究调查了新闻概述中的性别偏见，发现大型语言模型（LLMs）会重复和强化有害的社会偏见。研究提出了一些方法来量化模型中的有偏行为，并提出了一种生成具有控制人口属性的输入文档的方法。

    

    概述是大型语言模型（LLMs）的一个重要应用。以往对概述模型的评估主要关注它们在内容选择、语法正确性和连贯性方面的性能。然而，众所周知，LLMs会重复和强化有害的社会偏见。这引发了一个问题：在一个相对受限制的环境，比如概述，这些偏见会对模型的输出产生影响吗？为了解答这个问题，我们首先提出了一些关于概述模型中的有偏行为的定义，并引入了一些实际方法来量化它们。由于我们发现输入文档中存在的偏见可能干扰我们的分析，我们还提出了一种方法来生成具有仔细控制人口属性的输入文档。这使我们能够规避这个问题，同时仍然使用一些现实的输入文档进行工作。最后，我们将我们的方法应用于专门构建的概述模型和通用用途的模型生成的概述。

    Summarization is an important application of large language models (LLMs). Most previous evaluation of summarization models has focused on their performance in content selection, grammaticality and coherence. However, it is well known that LLMs reproduce and reinforce harmful social biases. This raises the question: Do these biases affect model outputs in a relatively constrained setting like summarization?  To help answer this question, we first motivate and introduce a number of definitions for biased behaviours in summarization models, along with practical measures to quantify them. Since we find biases inherent to the input document can confound our analysis, we additionally propose a method to generate input documents with carefully controlled demographic attributes. This allows us to sidestep this issue, while still working with somewhat realistic input documents.  Finally, we apply our measures to summaries generated by both purpose-built summarization models and general purpose
    
[^46]: AV2Wav：基于连续自监督特征的扩散重合成技术用于音频-视觉语音增强

    AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement. (arXiv:2309.08030v1 [eess.AS])

    [http://arxiv.org/abs/2309.08030](http://arxiv.org/abs/2309.08030)

    本论文提出了一种名为AV2Wav的音频-视觉语音增强方法，利用连续自监督特征和扩散模型生成干净的语音，克服了现实训练数据的挑战。与基于掩蔽的基线方法相比，该方法在声码任务上表现更好，并通过多任务训练进一步优化性能。

    

    语音增强系统通常使用干净和噪声语音对进行训练。在音频-视觉语音增强中，干净的数据不够多；大多数音频-视觉数据集都是在现实环境中收集的，包含背景噪声和混响，这阻碍了音频-视觉语音增强的发展。在本研究中，我们引入了AV2Wav，一种基于重合成的音频-视觉语音增强方法，可以在现实训练数据的挑战下生成干净的语音。我们使用神经质量估计器从音频-视觉语料库中获取几乎干净的语音子集，并在此子集上训练一个扩散模型，该模型可以根据来自AV-HuBERT的连续语音表示生成声波形，具有噪声鲁棒训练。我们使用连续而不是离散表示来保留韵律和说话者信息。仅仅通过声码任务，该模型就比基于掩蔽的基线更好地执行语音增强。我们进一步fine-tune模型，以转化为在多任务下进行训练，通过联合多帧声学到语音转化来提高性能。

    Speech enhancement systems are typically trained using pairs of clean and noisy speech. In audio-visual speech enhancement (AVSE), there is not as much ground-truth clean data available; most audio-visual datasets are collected in real-world environments with background noise and reverberation, hampering the development of AVSE. In this work, we introduce AV2Wav, a resynthesis-based audio-visual speech enhancement approach that can generate clean speech despite the challenges of real-world training data. We obtain a subset of nearly clean speech from an audio-visual corpus using a neural quality estimator, and then train a diffusion model on this subset to generate waveforms conditioned on continuous speech representations from AV-HuBERT with noise-robust training. We use continuous rather than discrete representations to retain prosody and speaker information. With this vocoding task alone, the model can perform speech enhancement better than a masking-based baseline. We further fine-
    
[^47]: 大型语言模型在零样本临床自然语言处理中提示策略的实证评估

    An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing. (arXiv:2309.08008v1 [cs.CL])

    [http://arxiv.org/abs/2309.08008](http://arxiv.org/abs/2309.08008)

    该论文通过对五个临床自然语言处理任务的实验研究，评估了不同提示工程方法在大型语言模型上的效果，为解锁临床领域中的知识提供了指导。

    

    大型语言模型（LLMs）在自然语言处理（NLP）领域表现出卓越的能力，尤其在标注数据稀缺或昂贵的领域，如临床领域。然而，要解锁这些LLMs中隐藏的临床知识，我们需要设计有效的提示，可以引导它们在没有任何特定任务训练数据的情况下执行特定的临床NLP任务。这被称为上下文学习，这是一门需要了解不同LLMs和提示工程方法的优点和缺点的艺术和科学。在本文中，我们提出了一个全面而系统的实验研究，针对五个临床NLP任务进行提示工程的评估：临床意义消歧、生物医学证据提取、共指消解、药物状态提取和药物属性提取。我们评估了最近文献中提出的提示方法，包括简单前缀、简单填空、思维链和预期提示，并介绍了一些新的提示方法。

    Large language models (LLMs) have shown remarkable capabilities in Natural Language Processing (NLP), especially in domains where labeled data is scarce or expensive, such as clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. In this paper, we present a comprehensive and systematic experimental study on prompt engineering for five clinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence Extraction, Coreference Resolution, Medication Status Extraction, and Medication Attribute Extraction. We assessed the prompts proposed in recent literature, including simple prefix, simple cloze, chain of thought, and anticipatory prompts, and introduce
    
[^48]: DiariST: 带有说话者分离的流式语音翻译

    DiariST: Streaming Speech Translation with Speaker Diarization. (arXiv:2309.08007v1 [eess.AS])

    [http://arxiv.org/abs/2309.08007](http://arxiv.org/abs/2309.08007)

    DiariST是第一个流式语音翻译和说话者分离的解决方案，通过集成标记级序列化输出训练和t向量，实现了强大的ST和SD能力。

    

    对于对话录音的端到端语音翻译（ST）涉及一些尚未充分研究的挑战，如没有准确的词时间戳的说话者分离（SD）和处理重叠语音的流式方式。在这项工作中，我们提出了DiariST，这是第一个流式的ST和SD解决方案。它基于基于神经传递器的流式ST系统构建，并集成了最初用于多说话人语音识别的标记级序列化输出训练和t向量。由于该领域缺乏评估基准，我们通过将AliMeeting语料库的参考中文转录成英文来构建了一个新的评估数据集DiariST-AliMeeting。我们还提出了新的指标，称为非特定说话者BLEU和特定说话者BLEU，以衡量ST的质量，并考虑SD的准确性。与基于Whisper的离线系统相比，我们的系统在进行流式推理的同时实现了强大的ST和SD能力。

    End-to-end speech translation (ST) for conversation recordings involves several under-explored challenges such as speaker diarization (SD) without accurate word time stamps and handling of overlapping speech in a streaming fashion. In this work, we propose DiariST, the first streaming ST and SD solution. It is built upon a neural transducer-based streaming ST system and integrates token-level serialized output training and t-vector, which were originally developed for multi-talker speech recognition. Due to the absence of evaluation benchmarks in this area, we develop a new evaluation dataset, DiariST-AliMeeting, by translating the reference Chinese transcriptions of the AliMeeting corpus into English. We also propose new metrics, called speaker-agnostic BLEU and speaker-attributed BLEU, to measure the ST quality while taking SD accuracy into account. Our system achieves a strong ST and SD capability compared to offline systems based on Whisper, while performing streaming inference for
    
[^49]: 探索人类评估员群体对面向对话评估的影响

    Exploring the Impact of Human Evaluator Group on Chat-Oriented Dialogue Evaluation. (arXiv:2309.07998v1 [cs.CL])

    [http://arxiv.org/abs/2309.07998](http://arxiv.org/abs/2309.07998)

    本文通过对4个不同的评估员群体对4个最先进的对话系统进行测试，分析了评估员群体对对话系统评估的影响。结果显示，对于Likert评估，评估员群体具有稳健性，而Pairwise评估没有。此外，还发现了不同评估员之间存在差异的局限性，并且评估员的客观性是有益的。

    

    人工评估被广泛接受作为评估面向对话系统的标准。然而，在以往的研究中，在招募评估员的方面存在显著的差异。评估员群体，如领域专家、大学生和专业标注员，已被用于评估和比较对话系统，尽管不清楚评估员群体的选择在多大程度上会影响结果。本文通过使用4个不同的评估员群体对4个最先进的对话系统进行测试，分析了评估员群体对对话系统评估的影响。我们的分析揭示了Likert评估在评估员群体方面的稳健性，而Pairwise评估没有这种稳健性，在更改评估员群体时只观察到了一些细微的差异。此外，我们观察到了两个显著的局限性，揭示了不同水平的聊天机器人专长的评估员之间存在差异，并表明评估员的客观性是有益的。

    Human evaluation has been widely accepted as the standard for evaluating chat-oriented dialogue systems. However, there is a significant variation in previous work regarding who gets recruited as evaluators. Evaluator groups such as domain experts, university students, and professional annotators have been used to assess and compare dialogue systems, although it is unclear to what extent the choice of an evaluator group can affect results. This paper analyzes the evaluator group impact on dialogue system evaluation by testing 4 state-of-the-art dialogue systems using 4 distinct evaluator groups. Our analysis reveals a robustness towards evaluator groups for Likert evaluations that is not seen for Pairwise, with only minor differences observed when changing evaluator groups. Furthermore, two notable limitations to this robustness are observed, which reveal discrepancies between evaluators with different levels of chatbot expertise and indicate that evaluator objectivity is beneficial fo
    
[^50]: 利用语境信息实现有效的实体重要性检测

    Leveraging Contextual Information for Effective Entity Salience Detection. (arXiv:2309.07990v1 [cs.CL])

    [http://arxiv.org/abs/2309.07990](http://arxiv.org/abs/2309.07990)

    本文研究了有效的实体重要性检测方法，通过对中等规模的语言模型进行微调，比传统的特征工程方法获得了更好的性能。研究还发现使用指令调校的语言模型进行零样本提示效果较差。

    

    在新闻文章等文本文档中，内容和关键事件通常围绕着文档中提到的一部分实体展开。这些实体通常被认为是重要的实体，对于读者来说，它们提供了关于文档内容的有用线索。识别实体的重要性在搜索、排名和基于实体的摘要等多个下游应用中都有帮助。先前的工作主要集中在需要进行大量特征工程的机器学习模型上。我们表明，使用交叉编码器风格架构对中等规模的语言模型进行微调，比特征工程方法获得了显著的性能提升。为此，我们对四个公开可用的数据集使用代表中等预训练语言模型家族的模型进行了全面的基准测试。此外，我们还表明，使用指令调校的语言模型进行零样本提示会产生较差的结果，表明指令调校的语言模型回答的问题数量过少。

    In text documents such as news articles, the content and key events usually revolve around a subset of all the entities mentioned in a document. These entities, often deemed as salient entities, provide useful cues of the aboutness of a document to a reader. Identifying the salience of entities was found helpful in several downstream applications such as search, ranking, and entity-centric summarization, among others. Prior work on salient entity detection mainly focused on machine learning models that require heavy feature engineering. We show that fine-tuning medium-sized language models with a cross-encoder style architecture yields substantial performance gains over feature engineering approaches. To this end, we conduct a comprehensive benchmarking of four publicly available datasets using models representative of the medium-sized pre-trained language model family. Additionally, we show that zero-shot prompting of instruction-tuned language models yields inferior results, indicati
    
[^51]: Kid-Whisper: 助力填补儿童与成人自动语音识别性能差距的研究

    Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech Recognition for Children VS. Adults. (arXiv:2309.07927v1 [eess.AS])

    [http://arxiv.org/abs/2309.07927](http://arxiv.org/abs/2309.07927)

    本文主要研究利用My Science Tutor（MyST）儿童语音语料库和更有效的数据预处理来改进自动语音识别（ASR）系统对儿童语音的识别性能。将Whisper系统整合到儿童语音识别中，显示了表现可行和高效。

    

    最近自动语音识别（ASR）系统的进展，例如Whisper，展示了这些系统在足够的数据条件下接近人类水平的性能潜力。然而，这一进展并不适用于儿童ASR，原因是适用于儿童的专用数据库的可用性有限，且儿童语音具有与成人不同的特征。最近的一项研究调查了利用My Science Tutor（MyST）儿童语音语料库提高Whisper识别儿童语音的性能。本文在这些研究结果的基础上，通过更有效的数据预处理增强了MyST数据集的实用性。我们还强调了改进儿童ASR性能的重要挑战。结果展示了将Whisper有效整合到儿童语音识别中的可行性和高效性。

    Recent advancements in Automatic Speech Recognition (ASR) systems, exemplified by Whisper, have demonstrated the potential of these systems to approach human-level performance given sufficient data. However, this progress doesn't readily extend to ASR for children due to the limited availability of suitable child-specific databases and the distinct characteristics of children's speech. A recent study investigated leveraging the My Science Tutor (MyST) children's speech corpus to enhance Whisper's performance in recognizing children's speech. This paper builds on these findings by enhancing the utility of the MyST dataset through more efficient data preprocessing. We also highlight important challenges towards improving children's ASR performance. The results showcase the viable and efficient integration of Whisper for effective children's speech recognition.
    
[^52]: 基于大型语言模型的代理的崛起和潜力：一项调查

    The Rise and Potential of Large Language Model Based Agents: A Survey. (arXiv:2309.07864v1 [cs.AI])

    [http://arxiv.org/abs/2309.07864](http://arxiv.org/abs/2309.07864)

    基于大型语言模型的代理的崛起和潜力：一项调查。大型语言模型被认为是构建通用人工智能代理的潜在催化剂，许多研究已经取得重要进展。

    

    长期以来，人类一直追求人工智能（AI）达到或超越人类水平的目标，而被认为是实现这一目标的有望方式的AI代理。AI代理是能感知环境、做出决策和采取行动的人工实体。自20世纪中叶以来，人们为开发智能AI代理进行了许多努力。然而，这些努力主要集中在算法或训练策略的进步上，以增强特定能力或在特定任务上的性能。实际上，社区所缺乏的是一个足够通用和强大的模型，作为设计能适应各种场景的AI代理的起点。由于展示出的多功能和显著能力，大型语言模型（LLMs）被视为人工通用智能（AGI）的潜在催化剂，为构建通用AI代理提供了希望。许多研究工作利用LLMs作为构建AI代理的基础，并且已经取得重要的进展。

    For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent AI agents since the mid-20th century. However, these efforts have mainly focused on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a sufficiently general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile and remarkable capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many research efforts have leveraged LLMs as the foundation to build AI agents and ha
    
[^53]: CATfOOD：反事实增强训练以提高领域外性能和校准能力

    CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration. (arXiv:2309.07822v1 [cs.CL])

    [http://arxiv.org/abs/2309.07822](http://arxiv.org/abs/2309.07822)

    本研究通过在小型语言模型训练数据中增加自动生成的反事实实例，提高了摘要问答模型在领域外的性能和模型校准能力，并发现性能改进与反事实实例的多样性相关。

    

    在最近的几年中，大型语言模型（LLM）在规模方面展示了显著的能力，特别是在给定提示的条件下生成文本。在我们的研究中，我们探讨了使用LLM来增强小型语言模型（SLM）的训练数据的方法，通过自动生成的反事实（CF）实例（即最小程度的改变输入），以提高SLM在摘要问答（QA）设置下的领域外（OOD）性能。我们证明，在各种LLM生成器中，这种数据增强始终能够提高OOD性能，并改进了基于置信度和基于理性增强的校准模型的模型校准能力。此外，这些性能提升与CF实例在外观形式和语义内容方面的多样性呈正相关。最后，我们证明了校准更容易的CF增强模型在分配重要性时的熵也较低，这表明理性增强的校准器更偏好简洁的解释。

    In recent years, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt. In our work, we investigate the use of LLMs to augment training data of small language models~(SLMs) with automatically generated counterfactual~(CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain~(OOD) performance of SLMs in the extractive question answering~(QA) setup. We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models. Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content. Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise ex
    
[^54]: 移动严肃游戏中口语化人形机器人对可用性的评估

    Usability Evaluation of Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games. (arXiv:2309.07773v1 [cs.HC])

    [http://arxiv.org/abs/2309.07773](http://arxiv.org/abs/2309.07773)

    本文通过实证调查评估了移动严肃游戏应用中口语化人形机器人对可用性的影响，结果表明用户更喜欢与高人类相似度的机器人进行交互。

    

    本文对移动严肃游戏应用中口语化人形机器人（HECA）对可用性的影响进行了实证调查。研究旨在评估多个机器人和人类交互幻觉对交互质量的影响。实验研究了两种机器人呈现方式：高人类相似度的机器人（HECA）和低人类相似度的机器人（文本）。实验的目的是评估高人类相似度机器人是否能够引发人类幻觉并影响可用性。高人类相似度机器人是根据ECA设计模型进行设计的，该模型是一种ECA开发的指导方针。实验结果显示，90位参与者更喜欢与HECA进行交互。两个版本之间的差异在统计学上具有显著性，效应大小较大（d=1.01），许多参与者通过解释选择来证明他们的选择。

    This paper presents an empirical investigation of the extent to which spoken Humanoid Embodied Conversational Agents (HECAs) can foster usability in mobile serious game (MSG) applications. The aim of the research is to assess the impact of multiple agents and illusion of humanness on the quality of the interaction. The experiment investigates two styles of agent presentation: an agent of high human-likeness (HECA) and an agent of low human-likeness (text). The purpose of the experiment is to assess whether and how agents of high humanlikeness can evoke the illusion of humanness and affect usability. Agents of high human-likeness were designed by following the ECA design model that is a proposed guide for ECA development. The results of the experiment with 90 participants show that users prefer to interact with the HECAs. The difference between the two versions is statistically significant with a large effect size (d=1.01), with many of the participants justifying their choice by saying
    
[^55]: 每个人都应该得到奖励：学习定制的人类偏好

    Everyone Deserves A Reward: Learning Customized Human Preferences. (arXiv:2309.03126v1 [cs.CL])

    [http://arxiv.org/abs/2309.03126](http://arxiv.org/abs/2309.03126)

    该论文研究了定制化的人类偏好学习问题，通过收集领域特定偏好数据集，并提出了一个三阶段的定制化奖励模型学习方案，从而解决了当前语言模型训练中忽视多样性的问题。

    

    奖励模型在提高大型语言模型与人类偏好的交互质量方面起着关键作用。然而，现实世界是多元的，这导致了基于不同宗教、政治、文化等的多样化人类偏好。此外，每个人对各种主题都可以有自己独特的偏好。当前的语言模型训练过程忽视了人类偏好的多样性，只使用一个通用的奖励模型，这对于定制或个性化应用场景来说是不够满意的。为了探索定制化的偏好学习，我们收集了一个领域特定的偏好数据集，该数据集收集了来自四个实际领域中对每个给定查询的首选响应。此外，从数据效率的角度出发，我们提出了一个三阶段的定制化奖励模型学习方案，并在通用偏好数据集和我们的领域特定偏好数据集上对其有效性进行了实证验证。

    Reward models (RMs) are crucial in aligning large language models (LLMs) with human preferences for improving interaction quality. However, the real world is pluralistic, which leads to diversified human preferences based on different religions, politics, cultures, etc. Moreover, each individual can have their own unique preferences on various topics. Neglecting the diversity of human preferences, current LLM training processes only use a general reward model, which is below satisfaction for customized or personalized application scenarios. To explore customized preference learning, we collect a domain-specific preference (DSP) dataset, which collects preferred responses to each given query from four practical domains. Besides, from the perspective of data efficiency, we proposed a three-stage customized RM learning scheme, whose effectiveness is empirically verified on both general preference datasets and our DSP set. Furthermore, we test multiple training and data strategies on the t
    
[^56]: HAE-RAE Bench: 评估语言模型对韩国知识的表现

    HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models. (arXiv:2309.02706v1 [cs.CL])

    [http://arxiv.org/abs/2309.02706](http://arxiv.org/abs/2309.02706)

    HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。

    

    在大规模预训练的语言模型(LLMs)在各种任务中展现出了显著的能力，但是对非英语语言的关注在这个领域的研究中有限。为了弥补这一空白并评估语言模型在韩语语言和文化方面的熟练程度，我们提出了HAE-RAE Bench，在词汇、历史和一般知识等6个任务上进行评估。我们对语言模型在这个基准上的评估突出了使用大型特定语言模型(LLSMs)与像GPT-3.5这样的全面通用模型相比的潜在优势。值得注意的是，我们的研究发现，比GPT-3.5约小13倍的模型，可以在语言特定知识检索方面展现出类似的性能水平。这一观察强调了在训练专业级语言特定模型时同质语料库的重要性。相反，当这些较小的模型在......

    Large Language Models (LLMs) pretrained on massive corpora exhibit remarkable capabilities across a wide range of tasks, however, the attention given to non-English languages has been limited in this field of research. To address this gap and assess the proficiency of language models in the Korean language and culture, we present HAE-RAE Bench, covering 6 tasks including vocabulary, history, and general knowledge. Our evaluation of language models on this benchmark highlights the potential advantages of employing Large Language-Specific Models(LLSMs) over a comprehensive, universal model like GPT-3.5. Remarkably, our study reveals that models approximately 13 times smaller than GPT-3.5 can exhibit similar performance levels in terms of language-specific knowledge retrieval. This observation underscores the importance of homogeneous corpora for training professional-level language-specific models. On the contrary, we also observe a perplexing performance dip in these smaller LMs when th
    
[^57]: WanJuan: 用于推进英文和中文大模型的综合多模态数据集

    WanJuan: A Comprehensive Multimodal Dataset for Advancing English and Chinese Large Models. (arXiv:2308.10755v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10755](http://arxiv.org/abs/2308.10755)

    本论文提出了一个名为"Wan Juan"的大规模多模态数据集，包含中英文数据。这个数据集通过各种网络来源采集，包括文本、图像文本和视频模态，总量超过2TB。它被用于训练InternLM模型，该模型在多维度评估中表现出明显优势。

    

    ChatGPT和GPT-4的普及显著加速了大模型的开发，导致了许多引人注目的大语言模型(LLMs)和多模态大语言模型(MLLMs)的创建。这些尖端模型的出色表现归功于高质量的数据。然而，领先范式中使用的训练数据的细节通常被保密。这种缺乏透明度，加上开源数据的稀缺，阻碍了社区的进一步发展。为了应对这个问题，本文介绍了一个名为"Wan Juan"的大规模多模态数据集，包含中文和英文数据，采集自广泛的网络来源。该数据集包括文本、图像文本和视频模态，总量超过2TB。它被用于训练InternLM模型，在多维度评估中表现出明显优势，与相似规模的模型相比。所有数据可在htt

    The rise in popularity of ChatGPT and GPT-4 has significantly accelerated the development of large models, leading to the creation of numerous impressive large language models(LLMs) and multimodal large language models (MLLMs). These cutting-edge models owe their remarkable performance to high-quality data. However, the details of the training data used in leading paradigms are often kept confidential. This lack of transparency, coupled with the scarcity of open-source data, impedes further developments within the community. As a response, this paper presents "Wan Juan", a large-scale multimodal dataset composed of both Chinese and English data, collected from a wide range of web sources. The dataset incorporates text, image-text, and video modalities, with a total volume exceeding 2TB. It was utilized in the training of InternLM, a model that demonstrated significant advantages in multi-dimensional evaluations when compared to models of a similar scale. All data can be accessed at htt
    
[^58]: MindMap：知识图谱激发大型语言模型的思维图思考方法

    MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])

    [http://arxiv.org/abs/2308.09729](http://arxiv.org/abs/2308.09729)

    本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。

    

    通常，大型语言模型存在无法整合新知识、产生幻觉和决策过程不透明等限制。本文探讨了如何利用知识图谱（KG）来激发大型语言模型，以解决整合最新知识和引发模型思维路径的问题。具体来说，我们构建了一个提示管道，使大型语言模型能够理解KG输入并利用隐含知识和检索到的外部知识进行推理。此外，我们研究了引发大型语言模型执行推理和生成答案的思维导图。研究发现，生成的思维导图基于知识的本体论，展示了大型语言模型的推理路径，从而为生产环境中的推理提供了探索和评估的可能性。对三个问答数据集的实验证明，MindMap提示方法带来了显著的实证增益。

    LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, pr
    
[^59]: 可微检索增强通过生成式语言建模的电子商务查询意图分类

    Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification. (arXiv:2308.09308v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2308.09308](http://arxiv.org/abs/2308.09308)

    本研究提出了一种可微的检索增强方法，通过生成式语言建模，在电子商务查询意图分类任务中显著提升了性能，解决了检索器和下游模型之间的不可微性问题。

    

    检索增强通过使用知识检索器和外部语料库来增强下游模型，而不仅仅是增加模型参数的数量，在许多自然语言处理（NLP）任务中，如文本分类、问题回答等方面已经取得了成功。然而，由于两个部分之间的不可微性，现有方法通常通过分别或异步训练检索器和下游模型来导致性能下降，与端到端联合训练相比。在本文中，我们提出了Differentiable Retrieval Augmentation via Generative lANguage modeling（Dragan），通过一种新颖的可微重构来解决这个问题。我们在电子商务搜索中的一个有挑战性的NLP任务上展示了我们提出的方法的有效性，即查询意图分类。实验结果和消融研究均表明，所提出的方法显著且合理地改进了最先进的基准模型。

    Retrieval augmentation, which enhances downstream models by a knowledge retriever and an external corpus instead of by merely increasing the number of model parameters, has been successfully applied to many natural language processing (NLP) tasks such as text classification, question answering and so on. However, existing methods that separately or asynchronously train the retriever and downstream model mainly due to the non-differentiability between the two parts, usually lead to degraded performance compared to end-to-end joint training. In this paper, we propose Differentiable Retrieval Augmentation via Generative lANguage modeling(Dragan), to address this problem by a novel differentiable reformulation. We demonstrate the effectiveness of our proposed method on a challenging NLP task in e-commerce search, namely query intent classification. Both the experimental results and ablation study show that the proposed method significantly and reasonably improves the state-of-the-art basel
    
[^60]: 基于大语言模型的中文细粒度金融情感分析

    Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models. (arXiv:2306.14096v1 [cs.CL])

    [http://arxiv.org/abs/2306.14096](http://arxiv.org/abs/2306.14096)

    本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。

    

    金融领域实体级别的细粒度情感分析是情感分析的重要子任务，目前面临着众多挑战。其中主要挑战之一来自于缺乏专门设计用于金融文本情感分析的高质量大规模标注语料库，这限制了开发有效文本处理技术所需的数据的可用性。大语言模型（LLMs）的最新进展在自然语言处理任务中取得了显著的性能，主要集中在语言模式匹配方面。在本文中，我们提出了一个新颖的、广泛的中文细粒度金融情感分析数据集FinChina SA，用于企业预警。我们对流行的现有开源LLMs使用我们的数据集进行了全面的评估和实验。我们坚信，我们的数据集将成为推动真实世界金融情感分析任务探索的宝贵资源。

    Entity-level fine-grained sentiment analysis in the financial domain is a crucial subtask of sentiment analysis and currently faces numerous challenges. The primary challenge stems from the lack of high-quality and large-scale annotated corpora specifically designed for financial text sentiment analysis, which in turn limits the availability of data necessary for developing effective text processing techniques. Recent advancements in large language models (LLMs) have yielded remarkable performance in natural language processing tasks, primarily centered around language pattern matching. In this paper, we propose a novel and extensive Chinese fine-grained financial sentiment analysis dataset, FinChina SA, for enterprise early warning. We thoroughly evaluate and experiment with well-known existing open-source LLMs using our dataset. We firmly believe that our dataset will serve as a valuable resource to advance the exploration of real-world financial sentiment analysis tasks, which shoul
    
[^61]: MLM预训练的动态掩码率调度

    Dynamic Masking Rate Schedules for MLM Pretraining. (arXiv:2305.15096v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15096](http://arxiv.org/abs/2305.15096)

    本论文提出了一种动态调度掩码率的方法来改进MLM预训练的质量，通过线性降低掩码率，达到了对BERT-base和BERT-large模型分别提高0.46%和0.25%的平均GLUE准确率的效果。这种方法不仅加快了BERT-base的预训练速度，还实现了对BERT-large的帕累托改善。

    

    大多数使用掩码语言建模（MLM）目标进行训练的transformer模型使用了原始BERT模型的固定掩码率15%。我们提出了通过训练过程中动态调整掩码率来替代固定率的方法。我们发现，在预训练过程中线性降低掩码率可以比固定率基准分别提高BERT-base和BERT-large的平均GLUE准确率0.46%和0.25%。这些提升来自于接触高和低掩码率的机制，从而在两种设置中都带来了优势。我们的结果表明，掩码率调度是提高掩码语言模型质量的简单方法，可以使BERT-base的预训练速度提高1.89倍，并对BERT-large实现了帕累托改善。

    Most works on transformers trained with the Masked Language Modeling (MLM) objective use the original BERT model's fixed masking rate of 15%. We propose to instead dynamically schedule the masking rate throughout training. We find that linearly decreasing the masking rate over the course of pretraining improves average GLUE accuracy by up to 0.46% and 0.25% in BERT-base and BERT-large, respectively, compared to fixed rate baselines. These gains come from exposure to both high and low masking rate regimes, providing benefits from both settings. Our results demonstrate that masking rate scheduling is a simple way to improve the quality of masked language models, achieving up to a 1.89x speedup in pretraining for BERT-base as well as a Pareto improvement for BERT-large.
    
[^62]: 使用LLM辅助注释进行语料库语言学研究：本地语法分析案例研究

    Using LLM-assisted Annotation for Corpus Linguistics: A Case Study of Local Grammar Analysis. (arXiv:2305.08339v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08339](http://arxiv.org/abs/2305.08339)

    本文研究了使用基于大语言模型的聊天机器人自动标注文本的潜力，重点考察了从本地语法角度观察道歉言语行为构成的功能元素的程度，并比较了不同模型在注释任务中的表现，结果表明Bing聊天机器人在任务中表现优于ChatGPT和人类标注员。

    

    基于大语言模型（LLMs）的聊天机器人在语言理解方面表现出很强的能力。本研究探索LLMs在协助基于语料库的语言学研究方面的潜力，通过将文本自动标注为特定语言信息类别。具体而言，我们研究了从本地语法的角度观察道歉言语行为构成的功能元素的程度，通过比较基于GPT-3.5的ChatGPT、基于GPT-4的Bing聊天机器人和人类编码器在注释任务中的表现。结果表明，Bing聊天机器人在任务中表现显着优于ChatGPT。与人类标注员相比，Bing聊天机器人的整体表现略低于人类标注员的表现，但已经取得了较高的F1得分:道歉标记99.95％，原因标记91.91％，道歉者标记95.35％，被道歉者标记89.74％和加强标记96.47％。这表明，在语言类别清晰且可以轻松识别的情况下，使用LLM辅助注释进行语料库语言学研究是可行的。

    Chatbots based on Large Language Models (LLMs) have shown strong capabilities in language understanding. In this study, we explore the potential of LLMs in assisting corpus-based linguistic studies through automatic annotation of texts with specific categories of linguistic information. Specifically, we examined to what extent LLMs understand the functional elements constituting the speech act of apology from a local grammar perspective, by comparing the performance of ChatGPT (powered by GPT-3.5), the Bing chatbot (powered by GPT-4), and a human coder in the annotation task. The results demonstrate that the Bing chatbot significantly outperformed ChatGPT in the task. Compared to human annotator, the overall performance of the Bing chatbot was slightly less satisfactory. However, it already achieved high F1 scores: 99.95% for the tag of APOLOGISING, 91.91% for REASON, 95.35% for APOLOGISER, 89.74% for APOLOGISEE, and 96.47% for INTENSIFIER. This suggests that it is feasible to use LLM-
    
[^63]: 探索法律问题回答系统的现状

    Exploring the State of the Art in Legal QA Systems. (arXiv:2304.06623v1 [cs.CL])

    [http://arxiv.org/abs/2304.06623](http://arxiv.org/abs/2304.06623)

    法律问题回答系统的研究面临着复杂性和多样性等挑战，但其在客户服务、教育、研究和跨语言交流等方面具有广泛应用。

    

    回答与法律领域相关的问题是一项复杂的任务，主要是由于复杂的法律文档系统的复杂性和多样性。为法律问题提供准确的答案通常需要相关领域的专业知识，这使得即使对于人类专家来说，这项任务也更具挑战性。问答系统（QA）旨在生成对以人类语言提出的问题的答案。它们使用自然语言处理来理解问题并搜索信息以找到相关答案。QA具有各种实际应用，包括客户服务、教育、研究和跨语言交流。然而，它们面临着诸如改进自然语言理解和处理复杂和模糊问题等挑战。

    Answering questions related to the legal domain is a complex task, primarily due to the intricate nature and diverse range of legal document systems. Providing an accurate answer to a legal query typically necessitates specialized knowledge in the relevant domain, which makes this task all the more challenging, even for human experts. QA (Question answering systems) are designed to generate answers to questions asked in human languages. They use natural language processing to understand questions and search through information to find relevant answers. QA has various practical applications, including customer service, education, research, and cross-lingual communication. However, they face challenges such as improving natural language understanding and handling complex and ambiguous questions. Answering questions related to the legal domain is a complex task, primarily due to the intricate nature and diverse range of legal document systems. Providing an accurate answer to a legal query
    
[^64]: 使用大型语言模型在强化学习中引导预训练

    Guiding Pretraining in Reinforcement Learning with Large Language Models. (arXiv:2302.06692v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06692](http://arxiv.org/abs/2302.06692)

    这项研究提出了一种使用大型语言模型在强化学习中引导预训练的方法，通过奖励代理根据语言模型建议的目标来塑造探索策略，使代理朝着人类有意义且可能有用的行为方向发展，无需人类的介入。

    

    强化学习算法在没有密集且形状良好的奖励函数的情况下通常很困难。通过奖励代理访问新颖状态或转换的内在动机探索方法可以解决这个限制，但在大型环境中，这些方法对下游任务的相关性有限。我们描述了一种利用文本语料库中的背景知识来塑造探索策略的方法。这种方法称为ELLM（使用LLMs进行探索），通过给代理奖励其达成由语言模型基于代理当前状态描述所提出的目标，引导代理朝着人类有意义且可能有用的行为方向发展，无需人类的介入。我们在Crafter游戏环境和Housekeep机器人模拟器中评估了ELLM，结果表明，经过ELLM训练的代理在预训练阶段有更好的常识行为覆盖率，并且通常与人类行为相匹配。

    Reinforcement learning algorithms typically struggle in the absence of a dense, well-shaped reward function. Intrinsically motivated exploration methods address this limitation by rewarding agents for visiting novel states or transitions, but these methods offer limited benefits in large environments where most discovered novelty is irrelevant for downstream tasks. We describe a method that uses background knowledge from text corpora to shape exploration. This method, called ELLM (Exploring with LLMs) rewards an agent for achieving goals suggested by a language model prompted with a description of the agent's current state. By leveraging large-scale language model pretraining, ELLM guides agents toward human-meaningful and plausibly useful behaviors without requiring a human in the loop. We evaluate ELLM in the Crafter game environment and the Housekeep robotic simulator, showing that ELLM-trained agents have better coverage of common-sense behaviors during pretraining and usually matc
    
[^65]: 跨时态数据分析支持和完善概念隐喻理论

    Diachronic Data Analysis Supports and Refines Conceptual Metaphor Theory. (arXiv:2209.12234v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.12234](http://arxiv.org/abs/2209.12234)

    该论文通过统计数据分析和实证研究支持和完善概念隐喻理论，同时也将隐喻理论作为意义出现的基础，可以定量地探索并整合到自然语言处理的框架中。

    

    作为对隐喻分析的贡献，我们引入了一种基于统计数据的研究方法，通过经验分析来探索长期以来的猜想，并首次对隐喻的系统特征进行了实证探索。反过来，这也使得隐喻理论可以作为意义出现的基础，可以通过定量的方法进行探索，并整合到自然语言处理的框架中。

    As a contribution to metaphor analysis, we introduce a statistical, data-based investigation with empirical analysis of long-standing conjectures and a first-ever empirical exploration of the systematic features of metaphors. Conversely, this also makes metaphor theory available as a basis of meaning emergence that can be quantitatively explored and integrated into the framework of NLP.
    
[^66]: VQA-GNN: 通过图神经网络推理多模态知识的视觉问答

    VQA-GNN: Reasoning with Multimodal Knowledge via Graph Neural Networks for Visual Question Answering. (arXiv:2205.11501v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.11501](http://arxiv.org/abs/2205.11501)

    VQA-GNN是一种通过图神经网络在非结构化和结构化多模态知识之间进行双向融合的新的VQA模型。

    

    视觉问答 (VQA) 需要系统通过统一非结构化（例如问题和答案的上下文 "QA上下文"）和结构化（例如QA上下文和场景的知识图 "概念图"）多模态知识来进行概念级别的推理。现有方法通常通过连接相应的视觉节点和概念节点来合并场景图和概念图，然后将QA上下文表示结合起来进行问题回答。然而，这些方法只能从非结构化知识到结构化知识进行单向融合，限制了它们捕捉多模态知识的异构联合推理的潜力。为了进行更具表达力的推理，我们提出了VQA-GNN，一种新的VQA模型，它在非结构化和结构化多模态知识之间进行双向融合，以获得统一的知识表示。具体来说，我们通过一个超链接连接场景图和概念图，实现了互连。

    Visual question answering (VQA) requires systems to perform concept-level reasoning by unifying unstructured (e.g., the context in question and answer; "QA context") and structured (e.g., knowledge graph for the QA context and scene; "concept graph") multimodal knowledge. Existing works typically combine a scene graph and a concept graph of the scene by connecting corresponding visual nodes and concept nodes, then incorporate the QA context representation to perform question answering. However, these methods only perform a unidirectional fusion from unstructured knowledge to structured knowledge, limiting their potential to capture joint reasoning over the heterogeneous modalities of knowledge. To perform more expressive reasoning, we propose VQA-GNN, a new VQA model that performs bidirectional fusion between unstructured and structured multimodal knowledge to obtain unified knowledge representations. Specifically, we inter-connect the scene graph and the concept graph through a super 
    
[^67]: 量子密度矩阵在经典问答和图像分类中的应用

    Application of Quantum Density Matrix in Classical Question Answering and Classical Image Classification. (arXiv:2203.11155v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.11155](http://arxiv.org/abs/2203.11155)

    该论文将量子密度矩阵应用于经典问答和图像分类中，证明了其可以提高任务的效率，尤其在图像分类中取得了优秀的性能表现。

    

    量子密度矩阵可表示整个量子系统的全部信息，将密度矩阵用于经典问答任务可以更加有效地实现问题回答。本论文设计了一种基于LSTM的新机制，以应对输入为矩阵的情况，并将该机制应用于卷积神经网络进行QA问题的求解，同时也证明了量子密度矩阵可以增强经典图像分类中的特征信息和特征之间的关系。实验结果表明，该新框架在CIFAR-10数据集上的性能优于传统的基于CNN的分类方法。

    Quantum density matrix represents all the information of the entire quantum system, and novel models of meaning employing density matrices naturally model linguistic phenomena such as hyponymy and linguistic ambiguity, among others in quantum question answering tasks. Naturally, we argue that applying the quantum density matrix into classical Question Answering (QA) tasks can show more effective performance. Specifically, we (i) design a new mechanism based on Long Short-Term Memory (LSTM) to accommodate the case when the inputs are matrixes; (ii) apply the new mechanism to QA problems with Convolutional Neural Network (CNN) and gain the LSTM-based QA model with the quantum density matrix. Experiments of our new model on TREC-QA and WIKI-QA data sets show encouraging results. Similarly, we argue that the quantum density matrix can also enhance the image feature information and the relationship between the features for the classical image classification. Thus, we (i) combine density mat
    
[^68]: AmbiFC: 用证据检验含糊性声明的真实性

    AmbiFC: Fact-Checking Ambiguous Claims with Evidence. (arXiv:2104.00640v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2104.00640](http://arxiv.org/abs/2104.00640)

    本研究提出了一个大规模的事实核查数据集AmbiFC，用于处理现实场景中的含糊性声明核查问题，通过细粒度的证据注释和分析，提出了一种适用于含糊性声明的软标签证据核查方法，并且在注释人员争议分析中发现了相关性。

    

    在实际场景中，自动化事实核查系统必须将声明与检索到的证据进行比较以预测真实性。检索到的证据可能无法明确支持或反驳声明，并产生各种有效解释。现有的事实核查数据集需要模型为每个声明预测单个真实性标签，并且缺乏管理此类模糊性的能力。我们提出了一个大规模的事实核查数据集AmbiFC，其中包含从完整维基百科页面中获取的经过细粒度证据注释的信息需求的现实声明。我们彻底分析了AmbiFC中涉及含糊声明引起的争议，观察到与注释人员的自我评估和专家注释的语言现象强烈相关的注释人员争议。我们引入基于证据的含糊声明的真实性核查任务，比较了三种方法，其中包含注释信号和单标签分类。

    Automated fact-checking systems in real-world scenarios must compare claims with retrieved evidence to predict the veracity. The retrieved evidence may not unambiguously support or refute the claim and yield diverse valid interpretations. Existing fact-checking datasets necessitate that models predict a single veracity label for each claim and lack the ability to manage such ambiguity. We present AmbiFC, a large-scale fact-checking dataset with realistic claims derived from real-world information needs. Our dataset contains fine-grained evidence annotations of passages from complete Wikipedia pages. We thoroughly analyze disagreements arising from ambiguous claims in AmbiFC, observing a strong correlation of annotator disagreement with their self-assessment and expert-annotated linguistic phenomena. We introduce the task of evidence-based fact-checking for ambiguous claims with soft labels, and compare three methodologies incorporating annotation signals with a single-label classificat
    

