# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes.](http://arxiv.org/abs/2308.01313) | 本文借鉴了人类视觉感知过程，提出了一种通过推断和调节上下文属性来改进零样本图像分类的方法。通过给CLIP提供上下文属性，可以减轻对虚假特征的依赖，进而提高零样本分类的准确性。 |
| [^2] | [Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?.](http://arxiv.org/abs/2308.01284) | ChatGPT作为检测器能否有效检测AI生成的文本，我们通过评估其在人工编写文本与AI生成文本之间的区分能力，并在公开数据集上进行实验，得出了关于ChatGPT在自动化检测流程中的应用指导。 |
| [^3] | [Exploring the psychology of GPT-4's Moral and Legal Reasoning.](http://arxiv.org/abs/2308.01264) | 本文探究了GPT-4的道德和法律推理，发现其与人类之间在意图归因、因果判断、欺骗的道德性、道德基础、道德运气对法律判断的影响、同意的概念以及规则违反判断方面存在高相关性。 |
| [^4] | [XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models.](http://arxiv.org/abs/2308.01263) | 本文介绍了一个名为XSTest的测试套件，旨在识别大型语言模型中夸大的安全行为。该套件由200个安全提示组成，涵盖十种提示类型，旨在引出模型的系统性问题。 |
| [^5] | [Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation.](http://arxiv.org/abs/2308.01240) | 本研究在四个代表性的代码理解和生成任务上评估了10种开源指导调优的大型语言模型，发现在零知识迁移的情况下，指导调优的大型语言模型表现出很高的竞争力，在少训练数据的情况下，添加示范样例可以提升模型性能，在微调设置下，微调可以进一步提升模型性能。 |
| [^6] | [Grounded Image Text Matching with Mismatched Relation Reasoning.](http://arxiv.org/abs/2308.01236) | 本文介绍了一种新颖的基于视觉和语言的图像文本匹配任务，要求模型能够确定图像与文本的关系，并定位所指的对象或者对不匹配的部分进行 grounding。为了解决预训练模型在此任务上的数据效率和长度泛化能力不足的问题，我们提出了一种关系敏感的对应推理网络（RCRN），该网络通过双向信息传递和语言结构引导的关系感知推理来实现。 |
| [^7] | [Do Multilingual Language Models Think Better in English?.](http://arxiv.org/abs/2308.01223) | 这项研究提出了一种名为自我翻译的方法，通过利用多语言语言模型的少样本翻译能力，克服了对外部翻译系统的需求，并在多个任务上展示了自我翻译相对于直接推理的优势。 |
| [^8] | [Global Hierarchical Neural Networks using Hierarchical Softmax.](http://arxiv.org/abs/2308.01210) | 本文提出了一种使用层次化softmax的全局层次化神经网络框架，适用于具有层次结构的分类任务，并且在四个文本分类数据集上的实验结果表明，相较于常规softmax和平面分类器，层次化softmax能够取得更好的分类性能。 |
| [^9] | [Analysing the Resourcefulness of the Paragraph for Precedence Retrieval.](http://arxiv.org/abs/2308.01203) | 分析段落级别信息在捕捉判例相似性以提高先例检索性能方面的资源利用性，并发现段落级别方法在与基线文档级别方法相比具有更强的区分能力。对印度最高法院判决任务的两个基准数据集的比较结果显示，段落级别方法具有可比性的性能。 |
| [^10] | [Arithmetic with Language Models: from Memorization to Computation.](http://arxiv.org/abs/2308.01154) | 本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。 |
| [^11] | [ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with Unpaired Stylistic Corpora.](http://arxiv.org/abs/2308.01143) | 本文提出了一种基于无配对风格语料库的ADS-Cap框架，用于准确多样化地生成与图像相关的风格化字幕。该框架使用对比学习模块对齐图像和文本特征，并利用条件变分自动编码器记忆多样的风格模式。实验证明，ADS-Cap在与图像的一致性、风格准确性和多样性方面表现出色。 |
| [^12] | [Beyond Generic: Enhancing Image Captioning with Real-World Knowledge using Vision-Language Pre-Training Model.](http://arxiv.org/abs/2308.01126) | 本研究提出了一种称为知识引导的回放(K-Replay)的方法，通过在微调期间保持预训练知识，将真实世界知识融入图像描述，以解决当前图像描述方法的通用性和真实世界知识缺失的问题。 |
| [^13] | [Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation.](http://arxiv.org/abs/2308.01080) | 本文介绍了一种利用少样本数据增强和瀑布提示的方式来进行回复生成的方法，通过数据分析确定关键因素，并提出了三种不同的方法。 |
| [^14] | [Chat Translation Error Detection for Assisting Cross-lingual Communications.](http://arxiv.org/abs/2308.01044) | 本文开发了一个通信支持系统，能够检测错误的翻译，以促进跨语言交流。研究者开发了一个错误检测器作为系统的基线，并构建了一个新的日英双语聊天语料库，此举为更高级错误翻译检测系统提供了支持。 |
| [^15] | [SALTTS: Leveraging Self-Supervised Speech Representations for improved Text-to-Speech Synthesis.](http://arxiv.org/abs/2308.01018) | 本文利用自监督语音表示提升文本转语音的合成质量，通过重构自监督学习表示，辅助重构损失以及增加解码器的传递，实现了优于基线方法的语音合成。 |
| [^16] | [Teaching Smaller Language Models To Generalise To Unseen Compositional Questions.](http://arxiv.org/abs/2308.00946) | 我们研究了如何教授较小的语言模型来推广到未见过的组合问题，通过多任务监督预训练和密集检索系统，我们建立了强大的基准，并展示了解决多个评估数据集上的问题的能力。 |
| [^17] | [Feature-aware conditional GAN for category text generation.](http://arxiv.org/abs/2308.00939) | 本文提出了一个名为特征感知的条件生成对抗网络（FA-GAN）的新框架，用于解决文本GAN中的离散性、训练不稳定、模式崩溃、缺乏多样性和可控性等问题。FA-GAN使用特征感知编码器和类别感知编码器，以及关系记忆核的解码器，通过生成序列来提高句子多样性，并具有额外的类别分类头。 |
| [^18] | [DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems.](http://arxiv.org/abs/2308.00878) | DiactTOD是一种新颖的端到端潜在对话行为模型，在没有显式注释的情况下，通过预测和控制对话行为的潜在表示来生成可控的响应。该方法在任务导向对话系统中的响应生成中展现了最先进的性能。 |
| [^19] | [GRDD: A Dataset for Greek Dialectal NLP.](http://arxiv.org/abs/2308.00802) | 本文介绍了一个用于研究现代希腊方言的大规模数据集GRDD，并使用该数据集进行方言识别实验，结果显示即使是简单的机器学习模型也能在该任务上表现良好。 |
| [^20] | [Self-Supervised Contrastive BERT Fine-tuning for Fusion-based Reviewed-Item Retrieval.](http://arxiv.org/abs/2308.00762) | 本文介绍了一种扩展神经信息检索方法到评论项检索任务的方法，通过利用自监督对比学习来学习BERT嵌入，以融合查询和评论得分并进行排名。 |
| [^21] | [The Bias Amplification Paradox in Text-to-Image Generation.](http://arxiv.org/abs/2308.00755) | 本文研究了文本到图像生成中的偏见放大现象，并发现其主要原因是训练数据和模型提示之间的差异。一旦考虑到各种分布差异，偏见放大现象显著减少。 |
| [^22] | [SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning.](http://arxiv.org/abs/2308.00436) | 本论文研究了使用LLMs自检逐步推理的能力，提出了一种零-shot验证方案，成功识别错误并提高了问答性能。 |
| [^23] | [ZRIGF: An Innovative Multimodal Framework for Zero-Resource Image-Grounded Dialogue Generation.](http://arxiv.org/abs/2308.00400) | ZRIGF是一种创新的多模态框架，用于无资源情境下的图像驱动对话生成。它通过对比预训练和生成预训练实现了视觉特征的对齐，生成有洞察力的回应。 |
| [^24] | [Towards Semantically Enriched Embeddings for Knowledge Graph Completion.](http://arxiv.org/abs/2308.00081) | 本论文讨论了知识图谱补全算法以及利用嵌入模型捕捉知识图谱中语义的不同方法，并提出知识图谱和语言模型相互受益的观点。 |
| [^25] | [AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder.](http://arxiv.org/abs/2307.16773) | AsdKB是一个用于自闭症谱系障碍早期筛选和诊断的中文知识库，包含了来自多个来源的疾病和诊断知识，并且可以用于问题回答、辅助诊断和专家推荐。 |
| [^26] | [LLMs4OL: Large Language Models for Ontology Learning.](http://arxiv.org/abs/2307.16648) | LLMs4OL方法利用大型语言模型在本体学习中取得显著进展，能够从自然语言文本中自动提取和结构化知识。 |
| [^27] | [A Private Watermark for Large Language Models.](http://arxiv.org/abs/2307.16230) | 这项工作提出了一种私密水印算法，通过使用两个不同的神经网络进行水印生成和检测，并共享部分参数，实现了高效且高准确性的检测，同时对生成和检测速度影响最小。 |
| [^28] | [SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension.](http://arxiv.org/abs/2307.16125) | 这项工作引入了一个名为SEED-Bench的基准测试，用于评估生成式多模态大语言模型的理解能力。SEED-Bench包括19K个多项选择题，涵盖了图像和视频模态等12个评估维度。通过人工注释提供的正确选项，能够客观高效地评估模型的性能。 |
| [^29] | [Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback.](http://arxiv.org/abs/2307.16039) | Okapi是一种使用强化学习从人类反馈中调优的多语言大型语言模型，它解决了目前开源语言模型只针对英语和少数流行语言进行指令调优的限制问题。 |
| [^30] | [an integrated npl approach to sentiment analysis in satisfaction surveys.](http://arxiv.org/abs/2307.11771) | 这项研究使用集成的自然语言处理方法对满意度调查进行情感分析，通过识别重复的词语模式和利用意见挖掘来理解参与者的意见，并且通过分析词语模式来获取更深入的情感、意见和主题信息。 |
| [^31] | [A Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2307.03109) | 本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。 |
| [^32] | [Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution.](http://arxiv.org/abs/2307.00925) | 本研究首次使用语法演化自动设计语义相似性集合，通过自动选择和聚合候选度量来优化集合与人类判断的相关性，提高相似度评估准确性，并证明了使用集合对语义相似性任务的益处。 |
| [^33] | [CamemBERT-bio: a Tasty French Language Model Better for your Health.](http://arxiv.org/abs/2306.15550) | 本研究介绍了CamemBERT-bio，它是一种针对法语生物医学领域专门设计的语言模型，相对于通用模型在命名实体识别任务上平均提高了2.54个百分点。 |
| [^34] | [Vistaar: Diverse Benchmarks and Training Sets for Indian Language ASR.](http://arxiv.org/abs/2305.15386) | 本文提出了Vistaar，这是一个包含59个基准的数据集，用于评估和改进印度语音ASR系统。此外，通过微调公开训练数据集，我们还训练了IndicWhisper模型，该模型在39个基准中具有最低的WER，平均降低了4.1的WER。 |
| [^35] | [Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation.](http://arxiv.org/abs/2305.07804) | 本论文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，以改善小语言模型的性能，特别是在医学问答任务中。这种方法在微调后使模型性能提高，并提出了在特定领域问答任务中使用LLM所面临的挑战和潜在的研究方向。 |
| [^36] | [Large Language Models are Strong Zero-Shot Retriever.](http://arxiv.org/abs/2304.14233) | 本文提出了一种在零-shot场景下利用大型语言模型（LLM）进行大规模检索的方法。该方法通过使用查询和查询的候选答案的组合作为提示，使LLM生成更精确的答案。由于自监督检索器在零-shot场景中性能较差，因此LameR优于自监督检索器。 |
| [^37] | [Technical report: Graph Neural Networks go Grammatical.](http://arxiv.org/abs/2303.01590) | 本文介绍了一种将代数语言片段与图神经网络形式上联系的框架，并从MATLANG定义了一个符合3-WL测试的语法，进而得出一个符合3-WL GNN模型的G$^2$N$^2$。此外，语法方法还提供了计算长度为六及以下的环和弦环的代数公式，并在多个下游任务中取得优秀的表现。 |
| [^38] | [Adapting Prompt for Few-shot Table-to-Text Generation.](http://arxiv.org/abs/2302.12468) | 这项研究提出了一个新的框架AdaPTGen，通过将领域特定知识的提示模板调整为模型所需，来解决缺乏标注数据的限制。该框架注入了常规表格相关描述的表示，充分利用未标记的领域特定知识，并允许设计各种任务来探索领域特定知识。 |
| [^39] | [Detecting Harmful Agendas in News Articles.](http://arxiv.org/abs/2302.00102) | 这项研究提出了一种新的任务，即在新闻文章中检测有害议程，并发布了一个新闻文章注释数据集以供研究使用。研究者展示了可解释系统在这一任务上的有效性，并证明它们可以和黑盒模型有相当的表现。 |
| [^40] | [Thinking Fast and Slow in Large Language Models.](http://arxiv.org/abs/2212.05206) | 本研究发现，大型语言模型（LLMs）如GPT-3在行为上与人类直觉相似，但可能带有认知错误。然而，具有更高认知能力的LLMs，如ChatGPT和GPT-4，学会了避免这些错误，表现出超理性的方式。通过在心理学方法的帮助下研究LLMs，我们可以揭示出其它未知的新特征。 |
| [^41] | [Syntactic Surprisal From Neural Models Predicts, But Underestimates, Human Processing Difficulty From Syntactic Ambiguities.](http://arxiv.org/abs/2210.12187) | 人类在阅读句法歧义句子时会放慢阅读速度，Surprisal理论认为这是由于句子中每个单词的不可预测性，但这种理论低估了人类的效应。本研究通过独立考虑句法预测性，提出了一种更准确的估计方法。 |
| [^42] | [Mass-Editing Memory in a Transformer.](http://arxiv.org/abs/2210.07229) | 该论文提出了一种在Transformer中进行大规模编辑内存的方法，可以有效地更新语言模型的记忆，实验证明其在关联数量上具有数量级的优势。 |
| [^43] | [Improve Event Extraction via Self-Training with Gradient Guidance.](http://arxiv.org/abs/2205.12490) | 本论文提出了一种自训练与梯度引导的框架，通过利用大规模无标签数据和使用Abstract Meaning Representation（AMR）图作为反馈，以改善事件抽取中的数据稀缺问题。实验结果显示这种方法的有效性。 |
| [^44] | [DePA: Improving Non-autoregressive Machine Translation with Dependency-Aware Decoder.](http://arxiv.org/abs/2203.16266) | DePA是一种依赖感知解码器，通过自回归预训练和关注转换两个步骤来改进非自回归机器翻译。实验证明，DePA能够显著提高翻译质量。 |
| [^45] | [Attention Is All You Need.](http://arxiv.org/abs/1706.03762) | Transformer是一种新的简单网络架构，完全基于注意力机制，取代了复杂的循环神经网络或卷积神经网络。实验证明Transformer在机器翻译任务中的质量更好、并行化效果更佳，且训练时间更短。它在英译德和英译法任务中取得了比其他模型更好的结果。 |

# 详细

[^1]: 更多上下文，更少干扰：通过推断和调节上下文属性进行视觉分类

    More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes. (arXiv:2308.01313v1 [cs.CV])

    [http://arxiv.org/abs/2308.01313](http://arxiv.org/abs/2308.01313)

    本文借鉴了人类视觉感知过程，提出了一种通过推断和调节上下文属性来改进零样本图像分类的方法。通过给CLIP提供上下文属性，可以减轻对虚假特征的依赖，进而提高零样本分类的准确性。

    

    CLIP作为一种基础的视觉语言模型，由于其理解各种视觉概念和自然语言描述的能力，被广泛应用于零样本图像分类。然而，如何充分利用CLIP的前所未有的人类般理解能力来实现更好的零样本分类仍然是一个开放问题。本文从人类的视觉感知过程中得到启发：现代神经科学观点认为，在对物体进行分类时，人类首先推断其与类别无关的属性（如背景和方向），这有助于将前景对象与背景区分开来，然后以此信息为基础进行决策。受此启发，我们观察到为CLIP提供上下文属性可以改善零样本分类并减轻对虚假特征的依赖。我们还观察到CLIP本身可以合理地从图像中推断出这些属性。基于这些观察，我们提出了一种零训练、两步骤的零样本分类方法。

    CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions. However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question. This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information. Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot cl
    
[^2]: 用火攻火：ChatGPT能够检测AI生成的文本吗？

    Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?. (arXiv:2308.01284v1 [cs.CL])

    [http://arxiv.org/abs/2308.01284](http://arxiv.org/abs/2308.01284)

    ChatGPT作为检测器能否有效检测AI生成的文本，我们通过评估其在人工编写文本与AI生成文本之间的区分能力，并在公开数据集上进行实验，得出了关于ChatGPT在自动化检测流程中的应用指导。

    

    越来越多的大型语言模型（如ChatGPT）被用于各种用例，包括规模化的文本内容生成。虽然已经存在针对这种AI生成文本的检测方法，但我们研究了ChatGPT在这种AI生成文本上的检测性能，受到将ChatGPT用作数据标注器或注释器的研究启发。我们评估了ChatGPT在人工编写文本与AI生成文本检测任务中的零-shot性能，并在公开可用的数据集上进行实验。我们通过实证研究了ChatGPT在检测AI生成文本或人工编写文本方面是否具有对称效应。我们的发现揭示了通过简单关注问题的特定方面并从该解决方案中推导出其余部分，如何利用ChatGPT和类似的大型语言模型在自动化检测流程中发挥作用。所有代码和数据可在 \url{https://github.com/AmritaBh/ChatGPT-as-Detector} 上获得。

    Large language models (LLMs) such as ChatGPT are increasingly being used for various use cases, including text content generation at scale. Although detection methods for such AI-generated text exist already, we investigate ChatGPT's performance as a detector on such AI-generated text, inspired by works that use ChatGPT as a data labeler or annotator. We evaluate the zero-shot performance of ChatGPT in the task of human-written vs. AI-generated text detection, and perform experiments on publicly available datasets. We empirically investigate if ChatGPT is symmetrically effective in detecting AI-generated or human-written text. Our findings provide insight on how ChatGPT and similar LLMs may be leveraged in automated detection pipelines by simply focusing on solving a specific aspect of the problem and deriving the rest from that solution. All code and data is available at \url{https://github.com/AmritaBh/ChatGPT-as-Detector}.
    
[^3]: 探索GPT-4的道德和法律推理的心理学研究

    Exploring the psychology of GPT-4's Moral and Legal Reasoning. (arXiv:2308.01264v1 [cs.AI])

    [http://arxiv.org/abs/2308.01264](http://arxiv.org/abs/2308.01264)

    本文探究了GPT-4的道德和法律推理，发现其与人类之间在意图归因、因果判断、欺骗的道德性、道德基础、道德运气对法律判断的影响、同意的概念以及规则违反判断方面存在高相关性。

    

    大型语言模型已被用作高度复杂的人工智能的基础，能够对法律和道德问题作出与人类类似的回应。然而，这些模型对于自身内部工作的指导是不可靠的，即使是它们的创建工程团队也无法解释它们如何获得当前所有能力的具体过程。机器心理学这一新兴领域旨在深入了解这些模型拥有的过程和概念。在本文中，我们运用心理学的方法来探究GPT-4的道德和法律推理。具体而言，我们研究了GPT-4与人类在意图归因、因果判断、欺骗的道德性、道德基础、道德运气对法律判断的影响、同意的概念以及规则违反判断方面的相似性和差异。我们发现人类和人工智能的回答之间存在较高的相关性。

    Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues. However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have. The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess. In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning. More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments. We find high correlations between human and AI response
    
[^4]: XSTest: 用于识别大型语言模型中夸大安全行为的测试套件

    XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models. (arXiv:2308.01263v1 [cs.CL])

    [http://arxiv.org/abs/2308.01263](http://arxiv.org/abs/2308.01263)

    本文介绍了一个名为XSTest的测试套件，旨在识别大型语言模型中夸大的安全行为。该套件由200个安全提示组成，涵盖十种提示类型，旨在引出模型的系统性问题。

    

    没有适当的保护措施，大型语言模型很容易遵循恶意指令并生成有害内容。这激发了安全工作，如红队测试和大规模反馈学习，旨在使模型既有用又无害。然而，这两个目标之间存在一种紧张关系，因为无害性要求模型拒绝遵从不安全的提示，从而无法提供帮助。最近的一些证据表明，一些模型可能在平衡上存在问题，以至于即使使用类似不安全提示的语言或提及敏感主题的明显安全提示也会被拒绝。本文介绍了一个名为XSTest的新测试套件，以系统化和结构化的方式识别这种夸张的安全行为。目前，XSTest包括200个安全提示，涵盖十种提示类型，良好校准的模型不应该拒绝遵循这些提示。我们描述了XSTest的创建和组成，并使用测试套件突显系统性的问题。

    Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content. This motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless. However, there is a tension between these two objectives, since harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a structured and systematic way. In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with. We describe XSTest's creation and composition, and use the test suite to highlight systematic f
    
[^5]: 在代码理解和生成方面评估指导调优的大型语言模型

    Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation. (arXiv:2308.01240v1 [cs.CL])

    [http://arxiv.org/abs/2308.01240](http://arxiv.org/abs/2308.01240)

    本研究在四个代表性的代码理解和生成任务上评估了10种开源指导调优的大型语言模型，发现在零知识迁移的情况下，指导调优的大型语言模型表现出很高的竞争力，在少训练数据的情况下，添加示范样例可以提升模型性能，在微调设置下，微调可以进一步提升模型性能。

    

    在这项工作中，我们评估了10种开源指导调优的大型语言模型在四个代表性的代码理解和生成任务上的表现。我们得到了以下主要发现。首先，在零知识迁移的情况下，指导调优的大型语言模型在代码理解和生成任务上非常有竞争力，有时甚至优于专门针对每个下游任务进行微调的小型最先进模型。我们还发现，更大的指导调优的大型语言模型并不总是在与代码相关的任务上更好。其次，在少训练数据的情况下，我们发现添加示范样例可以大大帮助指导调优的大型语言模型在大多数代码理解和生成任务上表现更好；然而，这些示范样例有时会导致不稳定甚至更差的性能。此外，我们发现广泛使用的基于BM25的样本选择策略在生成问题上明显优于基础的随机选择或固定选择。第三，对于微调设置，我们发现微调可以进一步提高模型在下游任务上的性能。

    In this work, we evaluate 10 open-source instructed LLMs on four representative code comprehension and generation tasks. We have the following main findings. First, for the zero-shot setting, instructed LLMs are very competitive on code comprehension and generation tasks and sometimes even better than small SOTA models specifically fine-tuned on each downstream task. We also find that larger instructed LLMs are not always better on code-related tasks. Second, for the few-shot setting, we find that adding demonstration examples substantially helps instructed LLMs perform better on most code comprehension and generation tasks; however, the examples would sometimes induce unstable or even worse performance. Furthermore, we find widely-used BM25-based shot selection strategy significantly outperforms the basic random selection or fixed selection only on generation problems. Third, for the fine-tuning setting, we find that fine-tuning could further improve the model performance on downstrea
    
[^6]: 使用不匹配关系推理的基于视觉和语言的图像文本匹配

    Grounded Image Text Matching with Mismatched Relation Reasoning. (arXiv:2308.01236v1 [cs.CV])

    [http://arxiv.org/abs/2308.01236](http://arxiv.org/abs/2308.01236)

    本文介绍了一种新颖的基于视觉和语言的图像文本匹配任务，要求模型能够确定图像与文本的关系，并定位所指的对象或者对不匹配的部分进行 grounding。为了解决预训练模型在此任务上的数据效率和长度泛化能力不足的问题，我们提出了一种关系敏感的对应推理网络（RCRN），该网络通过双向信息传递和语言结构引导的关系感知推理来实现。

    

    本文介绍了一种称为“使用不匹配关系推理的基于视觉和语言的图像文本匹配（GITM-MR）”的新型视觉-语言联合任务，用于评估基于Transformer预训练模型的关系理解能力。GITM-MR需要模型首先确定一个表达是否描述了一张图像，然后定位所指的对象或者对文本中的不匹配部分进行 grounding。我们提供了一个用于评估预训练模型在这个任务上表现的基准，重点关注有限数据和超出分布的句子长度的挑战性设置。我们的评估表明，预训练模型缺乏数据效率和长度泛化能力。为了解决这个问题，我们提出了一种称为关系敏感的对应推理网络（RCRN），通过双向信息传递和语言结构引导的关系感知推理，将RCRN解释为一个模块化程序，并在长度泛化和数据效率方面表现出较强的性能。

    This paper introduces Grounded Image Text Matching with Mismatched Relation (GITM-MR), a novel visual-linguistic joint task that evaluates the relation understanding capabilities of transformer-based pre-trained models. GITM-MR requires a model to first determine if an expression describes an image, then localize referred objects or ground the mismatched parts of the text. We provide a benchmark for evaluating pre-trained models on this task, with a focus on the challenging settings of limited data and out-of-distribution sentence lengths. Our evaluation demonstrates that pre-trained models lack data efficiency and length generalization ability. To address this, we propose the Relation-sensitive Correspondence Reasoning Network (RCRN), which incorporates relation-aware reasoning via bi-directional message propagation guided by language structure. RCRN can be interpreted as a modular program and delivers strong performance in both length generalization and data efficiency.
    
[^7]: 多语言语言模型在英语中思考是否更好？

    Do Multilingual Language Models Think Better in English?. (arXiv:2308.01223v1 [cs.CL])

    [http://arxiv.org/abs/2308.01223](http://arxiv.org/abs/2308.01223)

    这项研究提出了一种名为自我翻译的方法，通过利用多语言语言模型的少样本翻译能力，克服了对外部翻译系统的需求，并在多个任务上展示了自我翻译相对于直接推理的优势。

    

    翻译测试是提高多语言语言模型性能的一种常用技术。这种方法通过使用外部机器翻译系统将输入翻译成英语，并对翻译后的输入进行推理来实现。然而，这些改进可以归因于使用一个单独的翻译系统，这个系统通常是在大量的平行数据上进行训练的，而这些数据对于语言模型来说是看不到的。在这项工作中，我们介绍了一种新方法，称为自我翻译，通过利用多语言语言模型的少样本翻译能力来克服对外部翻译系统的需求。对5个任务的实验表明，自我翻译始终优于直接推理，证明了当在非英语语言中进行提示时，语言模型无法充分发挥其多语言潜力。我们的代码可在 https://github.com/juletx/self-translate 中找到。

    Translate-test is a popular technique to improve the performance of multilingual language models. This approach works by translating the input into English using an external machine translation system, and running inference over the translated input. However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model. In this work, we introduce a new approach called self-translate, which overcomes the need of an external translation system by leveraging the few-shot translation capabilities of multilingual language models. Experiments over 5 tasks show that self-translate consistently outperforms direct inference, demonstrating that language models are unable to leverage their full multilingual potential when prompted in non-English languages. Our code is available at https://github.com/juletx/self-translate.
    
[^8]: 使用层次化softmax的全局层次化神经网络

    Global Hierarchical Neural Networks using Hierarchical Softmax. (arXiv:2308.01210v1 [stat.ML])

    [http://arxiv.org/abs/2308.01210](http://arxiv.org/abs/2308.01210)

    本文提出了一种使用层次化softmax的全局层次化神经网络框架，适用于具有层次结构的分类任务，并且在四个文本分类数据集上的实验结果表明，相较于常规softmax和平面分类器，层次化softmax能够取得更好的分类性能。

    

    本文提出了一个框架，在其中使用层次化softmax来创建一个全局层次化分类器。该方法适用于任何具有自然层次结构的分类任务。我们在四个文本分类数据集上展示了实证结果。在所有数据集中，相对于使用平面分类器的常规softmax，层次化softmax在宏F1和宏召回率方面都有所提升。在四个数据集中的三个数据集中，层次化softmax实现了更高的微准确率和宏精确率。

    This paper presents a framework in which hierarchical softmax is used to create a global hierarchical classifier. The approach is applicable for any classification task where there is a natural hierarchy among classes. We show empirical results on four text classification datasets. In all datasets the hierarchical softmax improved on the regular softmax used in a flat classifier in terms of macro-F1 and macro-recall. In three out of four datasets hierarchical softmax achieved a higher micro-accuracy and macro-precision.
    
[^9]: 分析段落的资源利用性以用于先例检索

    Analysing the Resourcefulness of the Paragraph for Precedence Retrieval. (arXiv:2308.01203v1 [cs.IR])

    [http://arxiv.org/abs/2308.01203](http://arxiv.org/abs/2308.01203)

    分析段落级别信息在捕捉判例相似性以提高先例检索性能方面的资源利用性，并发现段落级别方法在与基线文档级别方法相比具有更强的区分能力。对印度最高法院判决任务的两个基准数据集的比较结果显示，段落级别方法具有可比性的性能。

    

    开发提取相关法律信息以帮助法律从业者的方法是一个活跃的研究领域。在这方面，研究工作通过利用不同类型的信息，如元数据、引用文献、关键词、句子、段落等，正在进行。与任何文本文档一样，法律文件由段落组成。本文分析了段落级别信息在捕捉判例相似性以提高先例检索性能方面的资源利用性。我们发现，段落级别方法只需少量段落交互即可捕捉判例之间的相似性，并且在基线文档级别方法上具有更强的区分能力。此外，对印度最高法院判决任务的两个基准数据集进行的比较结果表明，段落级别方法与最先进的方法具有可比性的性能。

    Developing methods for extracting relevant legal information to aid legal practitioners is an active research area. In this regard, research efforts are being made by leveraging different kinds of information, such as meta-data, citations, keywords, sentences, paragraphs, etc. Similar to any text document, legal documents are composed of paragraphs. In this paper, we have analyzed the resourcefulness of paragraph-level information in capturing similarity among judgments for improving the performance of precedence retrieval. We found that the paragraph-level methods could capture the similarity among the judgments with only a few paragraph interactions and exhibit more discriminating power over the baseline document-level method. Moreover, the comparison results on two benchmark datasets for the precedence retrieval on the Indian supreme court judgments task show that the paragraph-level methods exhibit comparable performance with the state-of-the-art methods
    
[^10]: 使用语言模型进行算术运算：从记忆到计算

    Arithmetic with Language Models: from Memorization to Computation. (arXiv:2308.01154v1 [cs.AI])

    [http://arxiv.org/abs/2308.01154](http://arxiv.org/abs/2308.01154)

    本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。

    

    更好地理解最近的大型语言模型的出现性计算和问题解决能力对于进一步改进它们并拓宽其适用性至关重要。本研究探讨了一个训练用于预测下一个标记的语言模型如何在训练数据之外执行算术计算。二进制加法和乘法是一个很好的测试基础，因为它们需要一个非常小的词汇表，并且在输入/输出上展示了相关的不连续性，使得对新数据进行平滑的输入插值无效。我们成功地训练了一个轻量级的语言模型来学习这些任务，并进行了一系列实验证明其外推能力和内部信息处理。我们的研究结果支持这样一个假设，即语言模型作为一个编码-回归-解码机器，一旦将输入标记表示映射到合适的内部值空间，计算就在值空间中进行。

    A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate intern
    
[^11]: ADS-Cap：一种基于无配对风格语料库的准确多样化的风格化字幕生成框架

    ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with Unpaired Stylistic Corpora. (arXiv:2308.01143v1 [cs.CV])

    [http://arxiv.org/abs/2308.01143](http://arxiv.org/abs/2308.01143)

    本文提出了一种基于无配对风格语料库的ADS-Cap框架，用于准确多样化地生成与图像相关的风格化字幕。该框架使用对比学习模块对齐图像和文本特征，并利用条件变分自动编码器记忆多样的风格模式。实验证明，ADS-Cap在与图像的一致性、风格准确性和多样性方面表现出色。

    

    使用无配对风格语料库生成具有特定语言风格的与图像相关的字幕是一项具有挑战性的任务，尤其是考虑到我们期望具有各种风格模式的风格化字幕。在本文中，我们提出了一种新颖的框架来生成准确多样化的风格化字幕 (ADS-Cap)。我们的ADS-Cap首先使用对比学习模块来对齐图像和文本特征，这在训练过程中统一了配对的事实和无配对的风格语料库。然后，我们使用有条件的变分自动编码器在潜在空间中自动记忆多样化的风格模式，并通过采样增强多样性。我们还设计了一个简单但有效的复核模块，通过过滤特定风格的字幕来提高风格的准确性。在两个广泛使用的风格化图像字幕数据集上的实验结果表明，相对于各种基准方法，ADS-Cap在与图像的一致性、风格准确性和多样性方面取得了出色的性能。

    Generating visually grounded image captions with specific linguistic styles using unpaired stylistic corpora is a challenging task, especially since we expect stylized captions with a wide variety of stylistic patterns. In this paper, we propose a novel framework to generate Accurate and Diverse Stylized Captions (ADS-Cap). Our ADS-Cap first uses a contrastive learning module to align the image and text features, which unifies paired factual and unpaired stylistic corpora during the training process. A conditional variational auto-encoder is then used to automatically memorize diverse stylistic patterns in latent space and enhance diversity through sampling. We also design a simple but effective recheck module to boost style accuracy by filtering style-specific captions. Experimental results on two widely used stylized image captioning datasets show that regarding consistency with the image, style accuracy and diversity, ADS-Cap achieves outstanding performances compared to various bas
    
[^12]: 超越通用：在视觉语言预训练模型中利用真实世界知识增强图像描述

    Beyond Generic: Enhancing Image Captioning with Real-World Knowledge using Vision-Language Pre-Training Model. (arXiv:2308.01126v1 [cs.CV])

    [http://arxiv.org/abs/2308.01126](http://arxiv.org/abs/2308.01126)

    本研究提出了一种称为知识引导的回放(K-Replay)的方法，通过在微调期间保持预训练知识，将真实世界知识融入图像描述，以解决当前图像描述方法的通用性和真实世界知识缺失的问题。

    

    当前的图像描述方法往往生成正确但“通用”的描述，缺乏真实世界知识，例如命名实体和上下文信息。考虑到视觉语言预训练模型(VLP)可以从大规模的网络数据中掌握大量这样的知识，利用VLP模型的普适性将知识融入图像描述是有希望的。然而，使用VLP模型面临挑战：零样本推理会导致知识幻觉，从而产生低质量的描述，而下游任务微调中的通用偏差阻碍了VLP模型表达知识。为了解决这些问题，我们提出了一种简单而有效的方法，称为知识引导的回放(K-Replay)，在微调期间保持预训练知识。我们的方法包括两个部分：(1)在自动收集的回放示例上进行知识预测任务，连续唤醒VLP模型对知识的记忆。

    Current captioning approaches tend to generate correct but "generic" descriptions that lack real-world knowledge, e.g., named entities and contextual information. Considering that Vision-Language Pre-Training (VLP) models master massive such knowledge from large-scale web-harvested data, it is promising to utilize the generalizability of VLP models to incorporate knowledge into image descriptions. However, using VLP models faces challenges: zero-shot inference suffers from knowledge hallucination that leads to low-quality descriptions, but the generic bias in downstream task fine-tuning hinders the VLP model from expressing knowledge. To address these concerns, we propose a simple yet effective method called Knowledge-guided Replay (K-Replay), which enables the retention of pre-training knowledge during fine-tuning. Our approach consists of two parts: (1) a knowledge prediction task on automatically collected replay exemplars to continuously awaken the VLP model's memory about knowledg
    
[^13]: 利用少样本数据增强和瀑布提示的方式来进行回复生成

    Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation. (arXiv:2308.01080v1 [cs.CL])

    [http://arxiv.org/abs/2308.01080](http://arxiv.org/abs/2308.01080)

    本文介绍了一种利用少样本数据增强和瀑布提示的方式来进行回复生成的方法，通过数据分析确定关键因素，并提出了三种不同的方法。

    

    本文讨论了我们在任务导向的对话建模中使用主观知识的方法，特别强调回复生成。我们的方法是通过对提供的数据集进行数据分析，评估回复长度、情感和对话行为等关键因素来确定的。我们利用少样本学习以生成新的主观知识项目来增强数据，并提出了三种DSTC11的方法：（1）任务特定模型探索，（2）将最常见的问题并入所有生成的回复中，以及（3）使用GPT-3和ChatGPT的瀑布提示技术。

    This paper discusses our approaches for task-oriented conversational modelling using subjective knowledge, with a particular emphasis on response generation. Our methodology was shaped by an extensive data analysis that evaluated key factors such as response length, sentiment, and dialogue acts present in the provided dataset. We used few-shot learning to augment the data with newly generated subjective knowledge items and present three approaches for DSTC11: (1) task-specific model exploration, (2) incorporation of the most frequent question into all generated responses, and (3) a waterfall prompting technique using a combination of both GPT-3 and ChatGPT.
    
[^14]: 辅助跨语言交流的聊天翻译错误检测

    Chat Translation Error Detection for Assisting Cross-lingual Communications. (arXiv:2308.01044v1 [cs.CL])

    [http://arxiv.org/abs/2308.01044](http://arxiv.org/abs/2308.01044)

    本文开发了一个通信支持系统，能够检测错误的翻译，以促进跨语言交流。研究者开发了一个错误检测器作为系统的基线，并构建了一个新的日英双语聊天语料库，此举为更高级错误翻译检测系统提供了支持。

    

    本文描述了一个通信支持系统的开发，该系统可以检测错误的翻译，以促进跨语言交流，因为当前机器聊天翻译方法的局限性。我们训练了一个错误检测器作为系统的基线，并构建了一个新的日英双语聊天语料库，BPesona-chat，其中包含了用众包进行质量评级的多轮口语聊天。错误检测器可以为更高级错误翻译检测系统打下良好的基础。

    In this paper, we describe the development of a communication support system that detects erroneous translations to facilitate crosslingual communications due to the limitations of current machine chat translation methods. We trained an error detector as the baseline of the system and constructed a new Japanese-English bilingual chat corpus, BPersona-chat, which comprises multiturn colloquial chats augmented with crowdsourced quality ratings. The error detector can serve as an encouraging foundation for more advanced erroneous translation detection systems.
    
[^15]: SALTTS：利用自监督语音表示提升文本转语音的合成质量

    SALTTS: Leveraging Self-Supervised Speech Representations for improved Text-to-Speech Synthesis. (arXiv:2308.01018v1 [cs.CL])

    [http://arxiv.org/abs/2308.01018](http://arxiv.org/abs/2308.01018)

    本文利用自监督语音表示提升文本转语音的合成质量，通过重构自监督学习表示，辅助重构损失以及增加解码器的传递，实现了优于基线方法的语音合成。

    

    FastSpeech2试图将音调、能量和持续时间等语音方面的特征作为条件输入，但仍有提升空间。本文的一部分工作是利用各种自监督学习模型的表示来提高合成语音的质量。具体来说，我们将FastSpeech2编码器的长度调节输出通过一系列编码器层，用重构自监督学习表示的目标。在SALTTS-parallel实现中，来自第二个编码器的表示与自监督学习特征一起用于辅助重构损失。然而，在SALTTS-cascade的实现中，这些表示不仅通过解码器，还通过重构损失。自监督学习特征带来的语音特征的丰富性体现在输出语音的质量上，所提出的方法在客观和主观评估指标上优于基线的FastSpeech2。

    While FastSpeech2 aims to integrate aspects of speech such as pitch, energy, and duration as conditional inputs, it still leaves scope for richer representations. As a part of this work, we leverage representations from various Self-Supervised Learning (SSL) models to enhance the quality of the synthesized speech. In particular, we pass the FastSpeech2 encoder's length-regulated outputs through a series of encoder layers with the objective of reconstructing the SSL representations. In the SALTTS-parallel implementation, the representations from this second encoder are used for an auxiliary reconstruction loss with the SSL features. The SALTTS-cascade implementation, however, passes these representations through the decoder in addition to having the reconstruction loss. The richness of speech characteristics from the SSL features reflects in the output speech quality, with the objective and subjective evaluation measures of the proposed approach outperforming the baseline FastSpeech2.
    
[^16]: 教授较小的语言模型如何推广到未见过的组合问题

    Teaching Smaller Language Models To Generalise To Unseen Compositional Questions. (arXiv:2308.00946v1 [cs.CL])

    [http://arxiv.org/abs/2308.00946](http://arxiv.org/abs/2308.00946)

    我们研究了如何教授较小的语言模型来推广到未见过的组合问题，通过多任务监督预训练和密集检索系统，我们建立了强大的基准，并展示了解决多个评估数据集上的问题的能力。

    

    我们使一个较小的语言模型能够推广到回答具有挑战性的组合问题，这些问题在训练中没有出现。为此，我们提出了一种多任务监督预训练的组合方法，涵盖了最多93个任务，旨在培养多样的推理能力，并结合了一个密集的检索系统，旨在检索一组证据性的段落片段。在问答方面，最近的进展要么通过针对非常大的预训练语言模型的提示方法实现零或少样本学习，要么通过微调较小的模型，有时结合信息检索进行。我们关注较少探索的问题，即较小的模型在对于不存在足够信息来回答特定问题的语料库进行检索时，能否实现零样本推广。我们在这个设置中为多样的评估数据集（StrategyQA，CommonsenseQA，IIRC，DROP，Musique和ARC-DA）建立了强大的基准，并展示了...

    We equip a smaller Language Model to generalise to answering challenging compositional questions that have not been seen in training. To do so we propose a combination of multitask supervised pretraining on up to 93 tasks designed to instill diverse reasoning abilities, and a dense retrieval system that aims to retrieve a set of evidential paragraph fragments. Recent progress in question-answering has been achieved either through prompting methods against very large pretrained Language Models in zero or few-shot fashion, or by fine-tuning smaller models, sometimes in conjunction with information retrieval. We focus on the less explored question of the extent to which zero-shot generalisation can be enabled in smaller models with retrieval against a corpus within which sufficient information to answer a particular question may not exist. We establish strong baselines in this setting for diverse evaluation datasets (StrategyQA, CommonsenseQA, IIRC, DROP, Musique and ARC-DA), and show tha
    
[^17]: 特征感知的条件生成对抗网络用于类别文本生成

    Feature-aware conditional GAN for category text generation. (arXiv:2308.00939v1 [cs.CL])

    [http://arxiv.org/abs/2308.00939](http://arxiv.org/abs/2308.00939)

    本文提出了一个名为特征感知的条件生成对抗网络（FA-GAN）的新框架，用于解决文本GAN中的离散性、训练不稳定、模式崩溃、缺乏多样性和可控性等问题。FA-GAN使用特征感知编码器和类别感知编码器，以及关系记忆核的解码器，通过生成序列来提高句子多样性，并具有额外的类别分类头。

    

    类别文本生成受到了相当大的关注，因为它对于各种自然语言处理任务都有益处。最近，生成对抗网络（GAN）在文本生成方面取得了有希望的性能，这归功于其对抗训练过程。然而，文本GAN存在一些问题，包括离散性、训练不稳定、模式崩溃、缺乏多样性和可控性等等。为了解决这些问题，本文提出了一种新颖的GAN框架，即特征感知的条件生成对抗网络（FA-GAN），用于可控的类别文本生成。在FA-GAN中，生成器具有序列到序列的结构，用于提高句子多样性，它包括三个编码器，包括一个特征感知编码器和一个类别感知编码器，以及一个基于关系记忆核的解码器，使用Gumbel SoftMax激活函数。鉴别器还具有额外的类别分类头。为了生成指定类别的句子，

    Category text generation receives considerable attentions since it is beneficial for various natural language processing tasks. Recently, the generative adversarial network (GAN) has attained promising performance in text generation, attributed to its adversarial training process. However, there are several issues in text GANs, including discreteness, training instability, mode collapse, lack of diversity and controllability etc. To address these issues, this paper proposes a novel GAN framework, the feature-aware conditional GAN (FA-GAN), for controllable category text generation. In FA-GAN, the generator has a sequence-to-sequence structure for improving sentence diversity, which consists of three encoders including a special feature-aware encoder and a category-aware encoder, and one relational-memory-core-based decoder with the Gumbel SoftMax activation function. The discriminator has an additional category classification head. To generate sentences with specified categories, the m
    
[^18]: DiactTOD：学习通用的潜在对话行为以实现可控的任务导向对话系统

    DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems. (arXiv:2308.00878v1 [cs.CL])

    [http://arxiv.org/abs/2308.00878](http://arxiv.org/abs/2308.00878)

    DiactTOD是一种新颖的端到端潜在对话行为模型，在没有显式注释的情况下，通过预测和控制对话行为的潜在表示来生成可控的响应。该方法在任务导向对话系统中的响应生成中展现了最先进的性能。

    

    对话行为注释对于改善任务导向对话系统中的响应生成质量非常重要。然而，由于不同的数据集和任务可能具有不兼容的注释，使用对话行为以通用的方式控制响应生成可能具有挑战性。虽然利用潜在动作空间或强化学习的替代方法不需要显式注释，但可能缺乏解释性或遇到定义任务特定奖励的困难。在这项工作中，我们提出了一种新颖的端到端潜在对话行为模型（DiactTOD），该模型将对话行为表示为潜在空间中的向量。DiactTOD在大型语料库上预训练后，能够使用这些潜在表示预测和控制对话行为，以零-shot的方式生成可控的响应。我们的方法在MultiWOZ数据集的各种实验设置中展示了最先进的性能，包括零-shot、少-shot和完整数据微调。

    Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with 
    
[^19]: GRDD: 希腊方言自然语言处理的数据集

    GRDD: A Dataset for Greek Dialectal NLP. (arXiv:2308.00802v1 [cs.CL])

    [http://arxiv.org/abs/2308.00802](http://arxiv.org/abs/2308.00802)

    本文介绍了一个用于研究现代希腊方言的大规模数据集GRDD，并使用该数据集进行方言识别实验，结果显示即使是简单的机器学习模型也能在该任务上表现良好。

    

    本文介绍了一个用于研究现代希腊方言的数据集。该数据集包含了克里特、庞提、北希腊和塞浦路斯希腊四种方言的原始文本数据。尽管存在不平衡，但该数据集是相当大的，并且是创建现代希腊方言类似资源的首次尝试。我们还使用该数据集进行方言识别，并尝试了传统的机器学习算法和简单的深度学习架构。结果显示，在这个任务上表现非常好，这可能表明所研究的方言具有足够的独特特征，即使是简单的机器学习模型也能在该任务上表现良好。针对表现最佳的算法进行了错误分析，结果显示在一些情况下错误是由于数据集清理不足造成的。

    In this paper, we present a dataset for the computational study of a number of Modern Greek dialects. It consists of raw text data from four dialects of Modern Greek, Cretan, Pontic, Northern Greek and Cypriot Greek. The dataset is of considerable size, albeit imbalanced, and presents the first attempt to create large scale dialectal resources of this type for Modern Greek dialects. We then use the dataset to perform dialect idefntification. We experiment with traditional ML algorithms, as well as simple DL architectures. The results show very good performance on the task, potentially revealing that the dialects in question have distinct enough characteristics allowing even simple ML models to perform well on the task. Error analysis is performed for the top performing algorithms showing that in a number of cases the errors are due to insufficient dataset cleaning.
    
[^20]: 自监督对比BERT微调用于基于融合的评论项检索

    Self-Supervised Contrastive BERT Fine-tuning for Fusion-based Reviewed-Item Retrieval. (arXiv:2308.00762v1 [cs.IR])

    [http://arxiv.org/abs/2308.00762](http://arxiv.org/abs/2308.00762)

    本文介绍了一种扩展神经信息检索方法到评论项检索任务的方法，通过利用自监督对比学习来学习BERT嵌入，以融合查询和评论得分并进行排名。

    

    随着自然语言界面使用户能够表达越来越复杂的自然语言查询，用户评论内容也呈爆炸式增长，这可以使用户更好地找到与这些表达性查询匹配的餐厅、书籍或电影等物品。虽然神经信息检索(IR)方法为查询与文档之间的匹配提供了最先进的结果，但它们尚未扩展到评估项检索(RIR)任务，其中查询-评论得分必须聚合(或融合)成物品级得分进行排名。在没有标记的RIR数据集的情况下，我们通过利用自监督方法对BERT嵌入进行对比学习来将神经IR方法扩展到RIR。具体而言，对比学习需要选择正样本和负样本，而我们的项-评论数据的独特二级结构结合元数据为我们提供了丰富的样本选择结构。

    As natural language interfaces enable users to express increasingly complex natural language queries, there is a parallel explosion of user review content that can allow users to better find items such as restaurants, books, or movies that match these expressive queries. While Neural Information Retrieval (IR) methods have provided state-of-the-art results for matching queries to documents, they have not been extended to the task of Reviewed-Item Retrieval (RIR), where query-review scores must be aggregated (or fused) into item-level scores for ranking. In the absence of labeled RIR datasets, we extend Neural IR methodology to RIR by leveraging self-supervised methods for contrastive learning of BERT embeddings for both queries and reviews. Specifically, contrastive learning requires a choice of positive and negative samples, where the unique two-level structure of our item-review data combined with meta-data affords us a rich structure for the selection of these samples. For contrasti
    
[^21]: 文本到图像生成中的偏见放大悖论

    The Bias Amplification Paradox in Text-to-Image Generation. (arXiv:2308.00755v1 [cs.LG])

    [http://arxiv.org/abs/2308.00755](http://arxiv.org/abs/2308.00755)

    本文研究了文本到图像生成中的偏见放大现象，并发现其主要原因是训练数据和模型提示之间的差异。一旦考虑到各种分布差异，偏见放大现象显著减少。

    

    偏见放大是一种模型增加训练数据中不平衡的现象。本文通过使用稳定扩散来比较训练数据与生成图像中的性别比例，研究了文本到图像领域中的偏见放大现象。我们发现模型似乎放大了训练数据中存在的性别-职业偏见。然而，我们发现放大很大程度上可以归因于训练数据和模型提示之间的差异。例如，训练数据中的标题通常包含明确的性别信息，而我们使用的提示则不包含，这导致了分布的偏移，从而影响了偏见度量。一旦我们考虑到训练和生成时使用的文本之间的各种分布差异，我们观察到放大现象大大减少。我们的发现说明了比较模型和它们所训练的数据中的偏见所面临的挑战，并且强调了混淆因素。

    Bias amplification is a phenomenon in which models increase imbalances present in the training data. In this paper, we study bias amplification in the text-to-image domain using Stable Diffusion by comparing gender ratios in training vs. generated images. We find that the model appears to amplify gender-occupation biases found in the training data (LAION). However, we discover that amplification can largely be attributed to discrepancies between training captions and model prompts. For example, an inherent difference is that captions from the training data often contain explicit gender information while the prompts we use do not, which leads to a distribution shift and consequently impacts bias measures. Once we account for various distributional differences between texts used for training and generation, we observe that amplification decreases considerably. Our findings illustrate the challenges of comparing biases in models and the data they are trained on, and highlight confounding 
    
[^22]: SelfCheck: 使用LLMs自检其逐步推理的创新

    SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning. (arXiv:2308.00436v1 [cs.AI])

    [http://arxiv.org/abs/2308.00436](http://arxiv.org/abs/2308.00436)

    本论文研究了使用LLMs自检逐步推理的能力，提出了一种零-shot验证方案，成功识别错误并提高了问答性能。

    

    最近大型语言模型（LLMs）的进展，尤其是链式思维（CoT）的发明，使得解决推理问题成为可能。然而，即使最强大的LLMs仍然难以处理需要非线性思维和多步推理的复杂问题。在这项工作中，我们探讨了LLMs是否具有识别自己错误的能力，而无需依赖外部资源。具体而言，我们研究了它们是否可以用于识别逐步推理中的个别错误。为此，我们提出了一种零-shot验证方案以识别此类错误。然后，我们使用此验证方案来改进问答性能，通过对不同生成的答案进行加权投票。我们在三个数学数据集-GSM8K，MathQA和MATH上测试了该方法，并发现它成功识别错误，并进而提高了最终的预测性能。

    The recent progress in large language models (LLMs), especially the invention of chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning problems. However, even the strongest LLMs are still struggling with more complicated problems that require non-linear thinking and multi-step reasoning. In this work, we explore whether LLMs have the ability to recognize their own errors, without resorting to external resources. In particular, we investigate whether they can be used to identify individual errors within a step-by-step reasoning. To this end, we propose a zero-shot verification scheme to recognize such errors. We then use this verification scheme to improve question-answering performance, by using it to perform weighted voting on different generated answers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and find that it successfully recognizes errors and, in turn, increases final predictive performance.
    
[^23]: ZRIGF：一种用于无资源图像驱动对话生成的创新多模态框架

    ZRIGF: An Innovative Multimodal Framework for Zero-Resource Image-Grounded Dialogue Generation. (arXiv:2308.00400v1 [cs.CL])

    [http://arxiv.org/abs/2308.00400](http://arxiv.org/abs/2308.00400)

    ZRIGF是一种创新的多模态框架，用于无资源情境下的图像驱动对话生成。它通过对比预训练和生成预训练实现了视觉特征的对齐，生成有洞察力的回应。

    

    图像驱动的对话系统通过整合视觉信息，在生成高质量的回应方面具有很大优势。然而，当前的模型在无资源情境中难以有效利用这些信息，主要原因是图像和文本模态之间的差异。为了克服这一挑战，我们提出了一种创新的多模态框架，称为ZRIGF，它在无资源情境中融合了图像驱动信息来生成对话。ZRIGF采用两阶段学习策略，包括对比预训练和生成预训练。对比预训练包括一个文本-图像匹配模块，将图像和文本映射到统一的编码向量空间中，以及一个文本辅助的遮蔽图像建模模块，用于保存预训练的视觉特征并促进进一步的多模态特征对齐。生成预训练使用多模态融合模块和信息传递模块来生成有洞察力的回应。

    Image-grounded dialogue systems benefit greatly from integrating visual information, resulting in high-quality response generation. However, current models struggle to effectively utilize such information in zero-resource scenarios, mainly due to the disparity between image and text modalities. To overcome this challenge, we propose an innovative multimodal framework, called ZRIGF, which assimilates image-grounded information for dialogue generation in zero-resource situations. ZRIGF implements a two-stage learning strategy, comprising contrastive pre-training and generative pre-training. Contrastive pre-training includes a text-image matching module that maps images and texts into a unified encoded vector space, along with a text-assisted masked image modeling module that preserves pre-training visual features and fosters further multimodal feature alignment. Generative pre-training employs a multimodal fusion module and an information transfer module to produce insightful responses b
    
[^24]: 为知识图谱补全构建语义丰富的嵌入模型

    Towards Semantically Enriched Embeddings for Knowledge Graph Completion. (arXiv:2308.00081v1 [cs.AI])

    [http://arxiv.org/abs/2308.00081](http://arxiv.org/abs/2308.00081)

    本论文讨论了知识图谱补全算法以及利用嵌入模型捕捉知识图谱中语义的不同方法，并提出知识图谱和语言模型相互受益的观点。

    

    基于嵌入模型的知识图谱补全在过去几年中越来越受关注。目前的大多数算法将知识图谱视为一个多向标记图，缺乏捕捉底层语义的能力。与此同时，大型语言模型（LLMs）已经捕获了大量信息，这一捕获对人工智能领域产生了革命性影响。知识图谱可以从LLMs中受益，反之亦然。本文讨论了基于不同生成嵌入模型变体的知识图谱补全算法。首先讨论了各种知识图谱补全算法，如转导和归纳链接预测以及实体类型预测算法。然后，介绍了利用知识图谱中的类型信息、LLMs以及捕捉不同描述逻辑公理中的语义的算法。最后，通过对现有算法的关键反思对论文进行总结。

    Embedding based Knowledge Graph (KG) Completion has gained much attention over the past few years. Most of the current algorithms consider a KG as a multidirectional labeled graph and lack the ability to capture the semantics underlying the schematic information. In a separate development, a vast amount of information has been captured within the Large Language Models (LLMs) which has revolutionized the field of Artificial Intelligence. KGs could benefit from these LLMs and vice versa. This vision paper discusses the existing algorithms for KG completion based on the variations for generating KG embeddings. It starts with discussing various KG completion algorithms such as transductive and inductive link prediction and entity type prediction algorithms. It then moves on to the algorithms utilizing type information within the KGs, LLMs, and finally to algorithms capturing the semantics represented in different description logic axioms. We conclude the paper with a critical reflection on
    
[^25]: AsdKB: 一个用于自闭症谱系障碍早期筛选和诊断的中文知识库

    AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder. (arXiv:2307.16773v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.16773](http://arxiv.org/abs/2307.16773)

    AsdKB是一个用于自闭症谱系障碍早期筛选和诊断的中文知识库，包含了来自多个来源的疾病和诊断知识，并且可以用于问题回答、辅助诊断和专家推荐。

    

    为了便捷地获取有关自闭症谱系障碍的知识并帮助其早期筛选和诊断，我们创建了AsdKB，一个关于自闭症谱系障碍的中文知识库。该知识库建立在多种来源的基础上，包括1）从SNOMED CT和ICD-10的临床描述中获得的疾病知识，2）从DSM-5和社会组织和医学研究机构推荐的不同筛选工具中获得的诊断知识，以及3）来自网络上专业医生和医院的专业知识。AsdKB包含本体知识和事实知识，并且可以通过 https://w3id.org/asdkb/ 作为链接数据进行访问。AsdKB的潜在应用包括问题回答、辅助诊断和专家推荐，并且我们通过一个原型来进行演示，该原型可以通过此http URL进行访问。

    To easily obtain the knowledge about autism spectrum disorder and help its early screening and diagnosis, we create AsdKB, a Chinese knowledge base on autism spectrum disorder. The knowledge base is built on top of various sources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinical descriptions on mental and behavioural disorders, 2) the diagnostic knowledge from DSM-5 and different screening tools recommended by social organizations and medical institutes, and 3) the expert knowledge on professional physicians and hospitals from the Web. AsdKB contains both ontological and factual knowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. The potential applications of AsdKB are question answering, auxiliary diagnosis, and expert recommendation, and we illustrate them with a prototype which can be accessed at this http URL
    
[^26]: LLMs4OL: 大型语言模型在本体学习中的应用

    LLMs4OL: Large Language Models for Ontology Learning. (arXiv:2307.16648v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.16648](http://arxiv.org/abs/2307.16648)

    LLMs4OL方法利用大型语言模型在本体学习中取得显著进展，能够从自然语言文本中自动提取和结构化知识。

    

    我们提出了LLMs4OL方法，利用大型语言模型（LLMs）进行本体学习（OL）。LLMs在自然语言处理方面取得了重大进展，展示了它们在不同知识领域中捕捉复杂语言模式的能力。我们的LLMs4OL范式研究了以下假设：\textit{LLMs能否有效应用它们的语言模式捕捉能力到OL中，这涉及从自然语言文本中自动提取和结构化知识?} 为了测试这个假设，我们使用零-shot提示方法进行了全面评估。我们评估了九个不同的LLM模型族群，针对三个主要的OL任务：术语类型划分、层级发现和非层级关系的提取。此外，评估还涵盖了本体知识的不同类型，包括WordNet中的词汇语义知识、GeoNames中的地理知识和UMLS中的医学知识。

    We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: \textit{Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text?} To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS.
    
[^27]: 大型语言模型的私密水印

    A Private Watermark for Large Language Models. (arXiv:2307.16230v1 [cs.CL])

    [http://arxiv.org/abs/2307.16230](http://arxiv.org/abs/2307.16230)

    这项工作提出了一种私密水印算法，通过使用两个不同的神经网络进行水印生成和检测，并共享部分参数，实现了高效且高准确性的检测，同时对生成和检测速度影响最小。

    

    最近，针对大型语言模型（LLMs）的文本水印算法已经减轻了LLMs生成的文本可能带来的伪新闻和版权问题。然而，当前文本水印算法的水印检测需要生成过程的密钥，使其容易受到违规和伪造的影响。在这项工作中，我们提出了第一个私密水印算法，通过在水印生成和检测阶段使用两个不同的神经网络而不是使用相同的密钥来扩展当前的文本水印算法。同时，水印生成和检测网络的部分参数是共享的，这使得检测网络能够以高效的方式实现高准确性。实验证明，由于两个网络的参数规模较小，我们的算法确保了高的检测准确性，并对生成和检测速度的影响最小。

    Recently, text watermarking algorithms for large language models (LLMs) have been mitigating the potential harms of text generated by the LLMs, including fake news and copyright issues. However, the watermark detection of current text algorithms requires the key from the generation process, making them susceptible to breaches and counterfeiting. In this work, we propose the first private watermarking algorithm, which extends the current text watermarking algorithms by using two different neural networks respectively for watermark generation and detection, rather than using the same key at both stages. Meanwhile, part of the parameters of the watermark generation and detection networks are shared, which makes the detection network achieve a high accuracy very efficiently. Experiments show that our algorithm ensures high detection accuracy with minimal impact on generation and detection speed, due to the small parameter size of both networks. Additionally, our subsequent analysis demonst
    
[^28]: SEED-Bench: 用生成式理解对多模态LLMs进行基准测试

    SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension. (arXiv:2307.16125v1 [cs.CL])

    [http://arxiv.org/abs/2307.16125](http://arxiv.org/abs/2307.16125)

    这项工作引入了一个名为SEED-Bench的基准测试，用于评估生成式多模态大语言模型的理解能力。SEED-Bench包括19K个多项选择题，涵盖了图像和视频模态等12个评估维度。通过人工注释提供的正确选项，能够客观高效地评估模型的性能。

    

    近期基于强大的大语言模型（LLMs），生成式多模态大语言模型（MLLMs）作为一个关键的研究领域受到了广泛关注，展示出了在理解和生成方面的卓越能力。在这项工作中，我们通过引入一个名为SEED-Bench的基准测试，解决了对MLLMs中生成式理解的评估问题，这是对生成式模型全面评估的一个初步步骤。SEED-Bench包括19K个准确的人工注释的多项选择题（比现有基准测试大6倍），涵盖了包括图像和视频模态在内的12个评估维度的理解能力。我们开发了一个先进的流程来生成针对特定评估维度的多项选择题，整合了自动筛选和手动验证过程。通过人工注释获得地面实况选项的多项选择题能够客观高效地评估模型的性能，

    Based on powerful Large Language Models (LLMs), recent generative Multimodal Large Language Models (MLLMs) have gained prominence as a pivotal research area, exhibiting remarkable capability for both comprehension and generation. In this work, we address the evaluation of generative comprehension in MLLMs as a preliminary step towards a comprehensive assessment of generative models, by introducing a benchmark named SEED-Bench. SEED-Bench consists of 19K multiple choice questions with accurate human annotations (x 6 larger than existing benchmarks), which spans 12 evaluation dimensions including the comprehension of both the image and video modality. We develop an advanced pipeline for generating multiple-choice questions that target specific evaluation dimensions, integrating both automatic filtering and manual verification processes. Multiple-choice questions with groundtruth options derived from human annotation enables an objective and efficient assessment of model performance, elim
    
[^29]: Okapi: 使用强化学习从人类反馈中调优的多语言大型语言模型

    Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback. (arXiv:2307.16039v1 [cs.CL])

    [http://arxiv.org/abs/2307.16039](http://arxiv.org/abs/2307.16039)

    Okapi是一种使用强化学习从人类反馈中调优的多语言大型语言模型，它解决了目前开源语言模型只针对英语和少数流行语言进行指令调优的限制问题。

    

    开发大型语言模型的关键技术之一是指令调优，它有助于将模型的响应与人类预期对齐，实现令人印象深刻的学习能力。两种主要的指令调优方法是监督微调（SFT）和使用人类反馈的强化学习（RLHF），目前已应用于生产最佳的商业语言模型（例如ChatGPT）。为提高语言模型在研究和开发工作中的可访问性，最近还推出了各种经过指令调优的开源语言模型，例如Alpaca、Vicuna等。然而，现有的开源语言模型仅对英语和少数流行语言进行了指令调优，从而限制了它们在全球其他语言中的影响力和可访问性。最近有一些探索多语言大型语言模型指令调优的工作，但目前只使用了SFT作为指令调优的唯一方法。这已经存在了一些问题。

    A key technology for the development of large language models (LLMs) involves instruction tuning that helps align the models' responses with human expectations to realize impressive learning abilities. Two major approaches for instruction tuning characterize supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), which are currently applied to produce the best commercial LLMs (e.g., ChatGPT). To improve the accessibility of LLMs for research and development efforts, various instruction-tuned open-source LLMs have also been introduced recently, e.g., Alpaca, Vicuna, to name a few. However, existing open-source LLMs have only been instruction-tuned for English and a few popular languages, thus hindering their impacts and accessibility to many other languages in the world. Among a few very recent work to explore instruction tuning for LLMs in multiple languages, SFT has been used as the only approach to instruction-tune LLMs for multiple languages. This has lef
    
[^30]: 一种集成的自然语言处理方法用于满意度调查中的情感分析

    an integrated npl approach to sentiment analysis in satisfaction surveys. (arXiv:2307.11771v1 [cs.CL])

    [http://arxiv.org/abs/2307.11771](http://arxiv.org/abs/2307.11771)

    这项研究使用集成的自然语言处理方法对满意度调查进行情感分析，通过识别重复的词语模式和利用意见挖掘来理解参与者的意见，并且通过分析词语模式来获取更深入的情感、意见和主题信息。

    

    该研究项目旨在将集成方法应用于满意度调查中的自然语言处理（NLP）。它将着重于理解和提取调查回答中的相关信息，分析情感，识别重复的词语模式。将使用NLP技术来确定情感极性，将回答分类为积极、消极或中性类别，并利用意见挖掘来突出参与者的意见。该方法将有助于确定对参与者最相关的方面，并了解他们对这些特定方面的意见。该研究项目的关键组成部分将是使用NPL对满意度调查回答中的词语模式进行分析。该分析将提供对回答者情感、意见以及出现的主题和趋势的更深入的理解。从该方法得到的结果可以用于确定改进的方向，了解回答者的偏好，并做出战略决策。

    The research project aims to apply an integrated approach to natural language processing NLP to satisfaction surveys. It will focus on understanding and extracting relevant information from survey responses, analyzing feelings, and identifying recurring word patterns. NLP techniques will be used to determine emotional polarity, classify responses into positive, negative, or neutral categories, and use opinion mining to highlight participants opinions. This approach will help identify the most relevant aspects for participants and understand their opinions in relation to those specific aspects. A key component of the research project will be the analysis of word patterns in satisfaction survey responses using NPL. This analysis will provide a deeper understanding of feelings, opinions, and themes and trends present in respondents responses. The results obtained from this approach can be used to identify areas for improvement, understand respondents preferences, and make strategic decisi
    
[^31]: 对大型语言模型评估的调查

    A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])

    [http://arxiv.org/abs/2307.03109](http://arxiv.org/abs/2307.03109)

    本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。

    

    大型语言模型（LLMs）由于在各种应用中表现出的前所未有的性能而在学术界和工业界越来越受欢迎。随着LLMs在研究和日常使用中继续发挥着重要作用，它们的评估变得越来越关键，不仅在任务水平上，而且在社会层面上，以更好地了解它们的潜在风险。在过去的几年里，已经做出了相当大的努力来从不同的角度来研究LLMs。本文综述了LLMs的这些评估方法，重点关注三个关键维度：评估什么、在哪里评估以及如何评估。首先，我们从评估任务的角度提供了一个概述，涵盖了一般的自然语言处理任务、推理、医学应用、伦理学、教育、自然科学和社会科学、代理应用和其他领域。其次，我们通过深入探讨评估方法和基准答案来回答“在哪里”和“如何”这两个问题。

    Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
    
[^32]: 使用语法演化自动设计语义相似性集合

    Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution. (arXiv:2307.00925v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.00925](http://arxiv.org/abs/2307.00925)

    本研究首次使用语法演化自动设计语义相似性集合，通过自动选择和聚合候选度量来优化集合与人类判断的相关性，提高相似度评估准确性，并证明了使用集合对语义相似性任务的益处。

    

    语义相似性度量在自然语言处理中被广泛应用于多种与计算机相关的任务。然而，没有单一的语义相似性度量适用于所有任务，研究人员经常使用集合策略来确保性能。本研究提出了一种自动设计语义相似性集合的方法。事实上，我们提出的方法首次使用语法演化来自动选择和聚合一组候选度量，以创建一个最大化与人类判断相关性的集合。该方法在多个基准数据集上进行了评估，并与最先进的集合进行了比较，结果显示它可以显著提高相似度评估的准确性，并在某些情况下优于现有方法。因此，我们的研究既展示了使用语法演化来自动比较文本的潜力，也证明了使用集合对语义相似性任务的益处。

    Semantic similarity measures are widely used in natural language processing to catalyze various computer-related tasks. However, no single semantic similarity measure is the most appropriate for all tasks, and researchers often use ensemble strategies to ensure performance. This research work proposes a method for automatically designing semantic similarity ensembles. In fact, our proposed method uses grammatical evolution, for the first time, to automatically select and aggregate measures from a pool of candidates to create an ensemble that maximizes correlation to human judgment. The method is evaluated on several benchmark datasets and compared to state-of-the-art ensembles, showing that it can significantly improve similarity assessment accuracy and outperform existing methods in some cases. As a result, our research demonstrates the potential of using grammatical evolution to automatically compare text and prove the benefits of using ensembles for semantic similarity tasks. The so
    
[^33]: CamemBERT-bio：一种更健康的法语语言模型

    CamemBERT-bio: a Tasty French Language Model Better for your Health. (arXiv:2306.15550v1 [cs.CL])

    [http://arxiv.org/abs/2306.15550](http://arxiv.org/abs/2306.15550)

    本研究介绍了CamemBERT-bio，它是一种针对法语生物医学领域专门设计的语言模型，相对于通用模型在命名实体识别任务上平均提高了2.54个百分点。

    

    通过临床数据仓库，医院中的临床数据变得越来越容易用于研究，然而这些文件都是非结构化的。因此，需要从医疗报告中提取信息以进行临床研究。使用CamemBERT等BERT-like模型的迁移学习已经取得了重大进展，特别是命名实体识别方面。然而，这些模型是为通用语言训练的，在生物医学数据上效果较弱。因此，我们提出了一种新的法语公共生物医学数据集，对CamemBERT进行了继续预训练。因此，我们介绍了CamemBERT-bio的第一个版本，它是一种为法语生物医学领域专门设计的公共模型，在不同的生物医学命名实体识别任务上平均F1分数提高了2.54个百分点。

    Clinical data in hospitals are increasingly accessible for research through clinical data warehouses, however these documents are unstructured. It is therefore necessary to extract information from medical reports to conduct clinical studies. Transfer learning with BERT-like models such as CamemBERT has allowed major advances, especially for named entity recognition. However, these models are trained for plain language and are less efficient on biomedical data. This is why we propose a new French public biomedical dataset on which we have continued the pre-training of CamemBERT. Thus, we introduce a first version of CamemBERT-bio, a specialized public model for the French biomedical domain that shows 2.54 points of F1 score improvement on average on different biomedical named entity recognition tasks.
    
[^34]: Vistaar: 为印度语音ASR提供多样化的基准和训练集

    Vistaar: Diverse Benchmarks and Training Sets for Indian Language ASR. (arXiv:2305.15386v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15386](http://arxiv.org/abs/2305.15386)

    本文提出了Vistaar，这是一个包含59个基准的数据集，用于评估和改进印度语音ASR系统。此外，通过微调公开训练数据集，我们还训练了IndicWhisper模型，该模型在39个基准中具有最低的WER，平均降低了4.1的WER。

    

    改进ASR系统是让全球范围内的新LLM基于用例可用的必要条件。在本文中，我们专注于印度语言，并且提出多样化的基准用于评估和改进印度语音ASR系统。为此，我们整理了Vistaar作为由59个基准组成的数据集，涵盖了不同语言和领域的组合，在这些基准上我们评估了3个公共ASR系统和2个商业系统。我们还通过在12种印度语言上对公开可用的训练数据集进行微调，训练了IndicWhisper模型，总共达到了10.7K小时。我们表明，IndicWhisper在Vistaar基准上显著改进了被考虑的ASR系统。实际上，IndicWhisper在59个基准中有39个基准具有最低的WER，平均降低了4.1的WER。我们开源了所有的数据集，代码和模型。

    Improving ASR systems is necessary to make new LLM-based use-cases accessible to people across the globe. In this paper, we focus on Indian languages, and make the case that diverse benchmarks are required to evaluate and improve ASR systems for Indian languages. To address this, we collate Vistaar as a set of 59 benchmarks across various language and domain combinations, on which we evaluate 3 publicly available ASR systems and 2 commercial systems. We also train IndicWhisper models by fine-tuning the Whisper models on publicly available training datasets across 12 Indian languages totalling to 10.7K hours. We show that IndicWhisper significantly improves on considered ASR systems on the Vistaar benchmark. Indeed, IndicWhisper has the lowest WER in 39 out of the 59 benchmarks, with an average reduction of 4.1 WER. We open-source all datasets, code and models.
    
[^35]: Dr. LLaMA：通过生成式数据增强改善特定领域QA中的小语言模型

    Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation. (arXiv:2305.07804v1 [cs.CL])

    [http://arxiv.org/abs/2305.07804](http://arxiv.org/abs/2305.07804)

    本论文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，以改善小语言模型的性能，特别是在医学问答任务中。这种方法在微调后使模型性能提高，并提出了在特定领域问答任务中使用LLM所面临的挑战和潜在的研究方向。

    

    大型语言模型在自然语言处理方面取得了重大进展，但随着其规模的增长，也面临着计算开销和效率的挑战，特别是在特定领域的任务中。另一方面，小型语言模型由于容量和训练数据的限制，在这些任务中往往表现不佳。本文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，聚焦医学问答任务和PubMedQA数据集，以改善小语言模型的性能。我们的发现表明，LLM有效地细化和扩展现有的问题-答案对，在微调后，使得小型模型在特定领域QA数据集上性能提高。本研究强调了在特定领域问答任务中使用LLM面临的挑战，并提出了潜在的研究方向，最终旨在为专业应用创建更高效和能力更强的模型。

    Large Language Models (LLMs) have made significant strides in natural language processing but face challenges in terms of computational expense and inefficiency as they grow in size, especially in domain-specific tasks. Small Language Models (SLMs), on the other hand, often struggle in these tasks due to limited capacity and training data. In this paper, we introduce Dr. LLaMA, a method for improving SLMs through generative data augmentation using LLMs, focusing on medical question-answering tasks and the PubMedQA dataset. Our findings indicate that LLMs effectively refine and diversify existing question-answer pairs, resulting in improved performance of a much smaller model on domain-specific QA datasets after fine-tuning. This study highlights the challenges of using LLMs for domain-specific question answering and suggests potential research directions to address these limitations, ultimately aiming to create more efficient and capable models for specialized applications. We have als
    
[^36]: 大型语言模型在零-shot检索中具有较强的表现力。

    Large Language Models are Strong Zero-Shot Retriever. (arXiv:2304.14233v1 [cs.CL])

    [http://arxiv.org/abs/2304.14233](http://arxiv.org/abs/2304.14233)

    本文提出了一种在零-shot场景下利用大型语言模型（LLM）进行大规模检索的方法。该方法通过使用查询和查询的候选答案的组合作为提示，使LLM生成更精确的答案。由于自监督检索器在零-shot场景中性能较差，因此LameR优于自监督检索器。

    

    本文提出了一种简单的方法，在零-shot场景下应用大型语言模型（LLM）进行大规模检索。我们的方法，Language Model作为检索器（LameR）仅基于大语言模型而不是其他神经模型，通过将LLM与检索器的暴力组合进行分解，将零-shot检索的性能提高到在基准数据集上具有很强的竞争力。本文主要提出通过使用查询和查询的候选答案的组合作为提示，使LLM生成更精确的答案。无论候选答案是否正确，都可以通过模式模仿或候选摘要来帮助LLM产生更精确的答案。此外，由于自监督检索器在零-shot场景中性能较差，因此通过利用LLM对文本模式的强大表现能力，LameR可以优于自监督检索器。

    In this work, we propose a simple method that applies a large language model (LLM) to large-scale retrieval in zero-shot scenarios. Our method, Language language model as Retriever (LameR) is built upon no other neural models but an LLM, while breaking up brute-force combinations of retrievers with LLMs and lifting the performance of zero-shot retrieval to be very competitive on benchmark datasets. Essentially, we propose to augment a query with its potential answers by prompting LLMs with a composition of the query and the query's in-domain candidates. The candidates, regardless of correct or wrong, are obtained by a vanilla retrieval procedure on the target collection. Such candidates, as a part of prompts, are likely to help LLM generate more precise answers by pattern imitation or candidate summarization. Even if all the candidates are wrong, the prompts at least make LLM aware of in-collection patterns and genres. Moreover, due to the low performance of a self-supervised retriever
    
[^37]: 技术报告：图神经网络也可以变得语法化

    Technical report: Graph Neural Networks go Grammatical. (arXiv:2303.01590v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01590](http://arxiv.org/abs/2303.01590)

    本文介绍了一种将代数语言片段与图神经网络形式上联系的框架，并从MATLANG定义了一个符合3-WL测试的语法，进而得出一个符合3-WL GNN模型的G$^2$N$^2$。此外，语法方法还提供了计算长度为六及以下的环和弦环的代数公式，并在多个下游任务中取得优秀的表现。

    

    本文提出了一个框架，将一个代数语言的一个片段与图神经网络（GNN）形式上联系起来。它依赖于上下文无关语法（CFG），将代数操作组织成可以翻译为GNN层模型的生成规则。由于直接从语言派生出的CFG的规则和变量包含冗余，因此介绍了一种语法简化方案，使得将其翻译为GNN层成为可能。应用这种策略，从MATLANG定义了一个符合第三阶Weisfeiler-Lehman（3-WL）测试要求的语法。从这个3-WL CFG中，我们得出了一个经过证明符合3-WL GNN模型的G$^2$N$^2$。此外，这种语法方法使我们能够提供计算长度为六及以下的环和弦环的代数公式，从而阐明了3-WL的计数能力。多个实验证明，G$^2$N$^2$在许多下游任务中的表现要比其他3-WL GNN更为高效。

    This paper proposes a framework to formally link a fragment of an algebraic language to a Graph Neural Network (GNN). It relies on Context Free Grammars (CFG) to organise algebraic operations into generative rules that can be translated into a GNN layer model. Since the rules and variables of a CFG directly derived from a language contain redundancies, a grammar reduction scheme is presented making tractable the translation into a GNN layer. Applying this strategy, a grammar compliant with the third-order Weisfeiler-Lehman (3-WL) test is defined from MATLANG. From this 3-WL CFG, we derive a provably 3-WL GNN model called G$^2$N$^2$. Moreover, this grammatical approach allows us to provide algebraic formulas to count the cycles of length up to six and chordal cycles at the edge level, which enlightens the counting power of 3-WL. Several experiments illustrate that G$^2$N$^2$ efficiently outperforms other 3-WL GNNs on many downstream tasks.
    
[^38]: 为少数据样本的表格生成自适应提示

    Adapting Prompt for Few-shot Table-to-Text Generation. (arXiv:2302.12468v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12468](http://arxiv.org/abs/2302.12468)

    这项研究提出了一个新的框架AdaPTGen，通过将领域特定知识的提示模板调整为模型所需，来解决缺乏标注数据的限制。该框架注入了常规表格相关描述的表示，充分利用未标记的领域特定知识，并允许设计各种任务来探索领域特定知识。

    

    预训练语言模型（PLM）在表格生成任务中取得了显著进展。然而，缺乏领域特定知识很难弥合表格数据和文本之间的拓扑差距，尤其是在具有有限资源的实际应用中。为了解决标注数据不足的限制，我们提出了一种新的框架：自适应生成提示（AdaPTGen）。AdaPTGen的核心是将领域特定知识的提示模板调整为模型所需，带来了至少三个好处：（1）它注入了常规表格相关描述的表示，以弥合表格数据和文本之间的拓扑差距；（2）它使我们能够充分利用大量未标记的领域特定知识，从而减轻了PLMs缺乏领域知识的固有缺点；（3）它允许我们设计各种任务来探索领域特定知识。在三个开放领域的实验和分析中进行了广泛实验。

    Pretrained language models (PLMs) have made remarkable progress in table-to-text generation tasks. However, the lack of domain-specific knowledge makes it challenging to bridge the topological gap between tabular data and text, especially in real-world applications with limited resources. To mitigate the limitation of insufficient labeled data, we propose a novel framework: Adapt-Prompt-to-Generate (AdaPTGen). The core insight of AdaPTGen is to adapt prompt templates of domain-specific knowledge into the model, which brings at least three benefits: (1) it injects representation of normal table-related descriptions to bridge the topological gap between tabular data and texts; (2) it enables us to use large amounts of unlabeled domain-specific knowledge fully, which can alleviate the PLMs' inherent shortcomings of lacking domain knowledge; (3) it allows us to design various tasks to explore the domain-specific knowledge. Extensive experiments and analyses are conducted on three open-doma
    
[^39]: 在新闻文章中检测有害议程

    Detecting Harmful Agendas in News Articles. (arXiv:2302.00102v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.00102](http://arxiv.org/abs/2302.00102)

    这项研究提出了一种新的任务，即在新闻文章中检测有害议程，并发布了一个新闻文章注释数据集以供研究使用。研究者展示了可解释系统在这一任务上的有效性，并证明它们可以和黑盒模型有相当的表现。

    

    在线上操纵新闻是一个日益严重的问题，需要使用自动化系统来遏制其传播。我们认为，虽然误导信息和虚假信息的检测已经得到研究，但在检测新闻文章中的有害议程这一重要挑战方面缺乏投资；识别有害议程对于识别具有最大潜在现实危害的新闻运动至关重要。此外，由于对审查制度存在真实的担忧，有害议程检测器必须具有可解释性才能发挥作用。在这项工作中，我们提出了这一全新的任务，并发布了一个名为NewsAgendas的新闻文章注释数据集，用于议程识别。我们展示了可解释系统在这一任务上的有效性，并证明它们可以与黑盒模型具有相当的表现。

    Manipulated news online is a growing problem which necessitates the use of automated systems to curtail its spread. We argue that while misinformation and disinformation detection have been studied, there has been a lack of investment in the important open challenge of detecting harmful agendas in news articles; identifying harmful agendas is critical to flag news campaigns with the greatest potential for real world harm. Moreover, due to real concerns around censorship, harmful agenda detectors must be interpretable to be effective. In this work, we propose this new task and release a dataset, NewsAgendas, of annotated news articles for agenda identification. We show how interpretable systems can be effective on this task and demonstrate that they can perform comparably to black-box models.
    
[^40]: 在大型语言模型中进行快速和慢速思考

    Thinking Fast and Slow in Large Language Models. (arXiv:2212.05206v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.05206](http://arxiv.org/abs/2212.05206)

    本研究发现，大型语言模型（LLMs）如GPT-3在行为上与人类直觉相似，但可能带有认知错误。然而，具有更高认知能力的LLMs，如ChatGPT和GPT-4，学会了避免这些错误，表现出超理性的方式。通过在心理学方法的帮助下研究LLMs，我们可以揭示出其它未知的新特征。

    

    大型语言模型（LLMs）目前处于将AI系统与人类交流和日常生活结合的前沿。因此，评估它们新兴的能力非常重要。在这项研究中，我们展示了像GPT-3这样的LLMs表现出与人类直觉惊人相似的行为，以及由此带来的认知错误。然而，具有更高认知能力的LLMs，特别是ChatGPT和GPT-4，学会了避免陷入这些错误，表现出超理性的方式。在我们的实验中，我们使用认知反思测试（CRT）以及最初设计用于研究人类直觉决策的语义错觉来探索LLMs。我们的研究表明，利用心理学方法研究LLMs有助于揭示其他未知的新特征。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Therefore, it is of great importance to evaluate their emerging abilities. In this study, we show that LLMs like GPT-3 exhibit behavior that strikingly resembles human-like intuition - and the cognitive errors that come with it. However, LLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4, learned to avoid succumbing to these errors and perform in a hyperrational manner. For our experiments, we probe LLMs with the Cognitive Reflection Test (CRT) as well as semantic illusions that were originally designed to investigate intuitive decision-making in humans. Our study demonstrates that investigating LLMs with methods from psychology has the potential to reveal otherwise unknown emergent traits.
    
[^41]: 从神经模型中的句法意外感知预测人类在句法歧义中的处理困难，但低估了其程度

    Syntactic Surprisal From Neural Models Predicts, But Underestimates, Human Processing Difficulty From Syntactic Ambiguities. (arXiv:2210.12187v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.12187](http://arxiv.org/abs/2210.12187)

    人类在阅读句法歧义句子时会放慢阅读速度，Surprisal理论认为这是由于句子中每个单词的不可预测性，但这种理论低估了人类的效应。本研究通过独立考虑句法预测性，提出了一种更准确的估计方法。

    

    人类在阅读暂时具有结构歧义的句子时表现出花园小径效应，当结构被消除歧义为不太受欢迎的选择时，他们会放慢阅读速度。Surprisal理论（Hale, 2001; Levy, 2008）作为对此现象的一个重要解释，认为这种放慢是由这些句子中每个单词的不可预测性引起的。van Schijndel和Linzen（2021）对此假设提出了质疑，他们发现从语言模型中获取的单词可预测性代价估计严重低估了人类花园小径效应的程度。本研究考虑了这种低估是否是因为人类在预测中更高地权衡了句法因素，而语言模型并未如此。我们提出了一种从语言模型中估计句法预测性的方法，使我们能够独立评估词汇和句法预测性的代价。我们发现独立考虑句法预测性会产生更准确的估计结果。

    Humans exhibit garden path effects: When reading sentences that are temporarily structurally ambiguous, they slow down when the structure is disambiguated in favor of the less preferred alternative. Surprisal theory (Hale, 2001; Levy, 2008), a prominent explanation of this finding, proposes that these slowdowns are due to the unpredictability of each of the words that occur in these sentences. Challenging this hypothesis, van Schijndel & Linzen (2021) find that estimates of the cost of word predictability derived from language models severely underestimate the magnitude of human garden path effects. In this work, we consider whether this underestimation is due to the fact that humans weight syntactic factors in their predictions more highly than language models do. We propose a method for estimating syntactic predictability from a language model, allowing us to weigh the cost of lexical and syntactic predictability independently. We find that treating syntactic predictability independe
    
[^42]: 在Transformer中进行大规模编辑内存

    Mass-Editing Memory in a Transformer. (arXiv:2210.07229v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07229](http://arxiv.org/abs/2210.07229)

    该论文提出了一种在Transformer中进行大规模编辑内存的方法，可以有效地更新语言模型的记忆，实验证明其在关联数量上具有数量级的优势。

    

    最近的研究展示了在更新大型语言模型时使用新的记忆的激动人心的前景，以替换过时的信息或添加专业知识。然而，这一领域的工作主要仅限于更新单个关联。我们开发了MEMIT，一种直接更新语言模型的方法，实验证明它可以扩展到数千个关联，对于GPT-J(6B)和GPT-NeoX(20B)，超过了之前的工作数个数量级。我们的代码和数据可以在https://memit.baulab.info找到。

    Recent work has shown exciting promise in updating large language models with new memories, so as to replace obsolete information or add specialized knowledge. However, this line of work is predominantly limited to updating single associations. We develop MEMIT, a method for directly updating a language model with many memories, demonstrating experimentally that it can scale up to thousands of associations for GPT-J (6B) and GPT-NeoX (20B), exceeding prior work by orders of magnitude. Our code and data are at https://memit.baulab.info.
    
[^43]: 通过自训练与梯度引导提高事件抽取的效果

    Improve Event Extraction via Self-Training with Gradient Guidance. (arXiv:2205.12490v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12490](http://arxiv.org/abs/2205.12490)

    本论文提出了一种自训练与梯度引导的框架，通过利用大规模无标签数据和使用Abstract Meaning Representation（AMR）图作为反馈，以改善事件抽取中的数据稀缺问题。实验结果显示这种方法的有效性。

    

    数据稀缺一直是限制事件抽取进展的主要因素。为了解决这个问题，我们提出了一种自训练与反馈（STF）框架，利用大规模无标签数据，并通过将其与相同句子的Abstract Meaning Representation（AMR）图进行比较，为每个新事件预测获取反馈。具体而言，STF包括（1）在现有事件注释上训练的基础事件抽取模型，然后应用于大规模无标签语料库以预测新的事件提及作为伪训练样本，和（2）一种新的评分模型，该模型对于每个新预测的事件触发器、一个参数、它的参数角色以及它们在AMR图中的路径进行估计，以表示伪标签的正确性。这些兼容性分数进一步作为反馈，鼓励或阻止模型在自训练过程中学习伪标签。在三个基准数据集上的实验结果表明了该方法的有效性。

    Data scarcity has been the main factor that hinders the progress of event extraction. To overcome this issue, we propose a Self-Training with Feedback (STF) framework that leverages the large-scale unlabeled data and acquires feedback for each new event prediction from the unlabeled data by comparing it to the Abstract Meaning Representation (AMR) graph of the same sentence. Specifically, STF consists of (1) a base event extraction model trained on existing event annotations and then applied to large-scale unlabeled corpora to predict new event mentions as pseudo training samples, and (2) a novel scoring model that takes in each new predicted event trigger, an argument, its argument role, as well as their paths in the AMR graph to estimate a compatibility score indicating the correctness of the pseudo label. The compatibility scores further act as feedback to encourage or discourage the model learning on the pseudo labels during self-training. Experimental results on three benchmark da
    
[^44]: DePA: 使用依赖感知解码器改进非自回归机器翻译

    DePA: Improving Non-autoregressive Machine Translation with Dependency-Aware Decoder. (arXiv:2203.16266v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.16266](http://arxiv.org/abs/2203.16266)

    DePA是一种依赖感知解码器，通过自回归预训练和关注转换两个步骤来改进非自回归机器翻译。实验证明，DePA能够显著提高翻译质量。

    

    非自回归机器翻译（NAT）模型与自回归翻译（AT）模型相比，翻译质量较低，因为NAT解码器在解码器输入中不依赖于之前的目标标记。我们提出了一种新颖且通用的依赖感知解码器（DePA），从解码器的自注意力和解码器输入两个方面来增强完全NAT模型中的目标依赖建模。首先，我们提出了一个自回归的前向-后向预训练阶段，在NAT训练之前，使NAT解码器能够逐渐学习双向目标依赖关系，以用于最终的NAT训练。其次，我们通过一种新颖的关注转换过程，将解码器输入从源语言表示空间转换到目标语言表示空间，从而使解码器能够更好地捕捉目标依赖关系。DePA可以应用于任何全NAT模型。大量实验表明，DePA在竞争激烈且具有领先水平的模型上都有稳定的改进效果。

    Non-autoregressive machine translation (NAT) models have lower translation quality than autoregressive translation (AT) models because NAT decoders do not depend on previous target tokens in the decoder input. We propose a novel and general Dependency-Aware Decoder (DePA) to enhance target dependency modeling in the decoder of fully NAT models from two perspectives: decoder self-attention and decoder input. First, we propose an autoregressive forward-backward pre-training phase before NAT training, which enables the NAT decoder to gradually learn bidirectional target dependencies for the final NAT training. Second, we transform the decoder input from the source language representation space to the target language representation space through a novel attentive transformation process, which enables the decoder to better capture target dependencies. DePA can be applied to any fully NAT models. Extensive experiments show that DePA consistently improves highly competitive and state-of-the-a
    
[^45]: 注意力就是一切（arXiv:1706.03762v6 [cs.CL]已更新）

    Attention Is All You Need. (arXiv:1706.03762v6 [cs.CL] UPDATED)

    [http://arxiv.org/abs/1706.03762](http://arxiv.org/abs/1706.03762)

    Transformer是一种新的简单网络架构，完全基于注意力机制，取代了复杂的循环神经网络或卷积神经网络。实验证明Transformer在机器翻译任务中的质量更好、并行化效果更佳，且训练时间更短。它在英译德和英译法任务中取得了比其他模型更好的结果。

    

    目前主要的序列转换模型基于复杂的循环神经网络或卷积神经网络的编码器-解码器配置。表现最好的模型还通过注意力机制连接编码器和解码器。我们提出了一种新的简单网络架构，Transformer，完全基于注意力机制，不再使用循环和卷积。在两个机器翻译任务上的实验证明，这些模型在质量上优于其他模型，同时更易于并行化，训练时间显著减少。我们的模型在WMT 2014英译德任务上达到28.4的BLEU分数，比现有最好结果（包括集成模型）提高了2个BLEU分。在WMT 2014英译法任务上，在8个GPU上训练了3.5天后，我们的模型获得了41.8的单模型最新BLEU分数，训练成本仅为文献中最好模型的一小部分。我们展示了Transformer架构的优势，并证明了其在机器翻译任务中的重要贡献。

    The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transforme
    

