# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Improving Generalization in Task-oriented Dialogues with Workflows and Action Plans.](http://arxiv.org/abs/2306.01729) | 本论文提出了在任务导向对话中提高泛化性能的方法，通过增强对话上下文，使用有效的工作流名称和行动计划编码来完成多步骤任务的执行，解决了大型预训练语言模型无法可靠执行训练期间未见过的新多步骤任务的问题。 |
| [^2] | [Distilling Efficient Language-Specific Models for Cross-Lingual Transfer.](http://arxiv.org/abs/2306.01709) | 本文提出了一种从大规模多语言模型中提取语言特定模型的方法，它通过双语蒸馏实现，可以保留原始模型的跨语言迁移能力，同时可以避免不必要的模型部署成本。 |
| [^3] | [Resolving Interference When Merging Models.](http://arxiv.org/abs/2306.01708) | 本文揭示了现有模型合并技术存在的干扰问题，提出了具有广泛适用性的解决方案，可显着提高合并后模型的性能。 |
| [^4] | [Learning Multi-step Reasoning from Arithmetic Task.](http://arxiv.org/abs/2306.01707) | 本文研究如何将相对较小的语言模型注入具有多步推理能力的合成算术任务（MsAT），从而提高LM在数学问题解决上的表现。 |
| [^5] | [Fine-Grained Human Feedback Gives Better Rewards for Language Model Training.](http://arxiv.org/abs/2306.01693) | 本文提出了Fine-Grained RLHF框架，使用精细化的人类反馈作为明确的训练信号来训练和学习语言模型。该框架提供了多个细致的奖励模型来获得更好的效果。 |
| [^6] | [DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control for Empathetic Response Generation.](http://arxiv.org/abs/2306.01657) | 本文提出了一种名为DiffusEmp的框架，该框架基于条件扩散语言模型，并使用多级控制信号来生成更加细致和个性化的共情回应。 |
| [^7] | [Learning from Partially Annotated Data: Example-aware Creation of Gap-filling Exercises for Language Learning.](http://arxiv.org/abs/2306.01584) | 本文提出了一种从已有的例子练习生成新的区别感知型填空练习，无需深度标注，特别针对语言学习中的语法练习；使用了一种新的神经网络模型并提供了相应的法语语法数据集，结果表明该模型在这类任务中表现优于竞争基准。 |
| [^8] | [EmoUS: Simulating User Emotions in Task-Oriented Dialogues.](http://arxiv.org/abs/2306.01579) | EmoUS是一种用户模拟器，可以模拟用户在任务导向对话中的行为和情感反应，通过分析用户情感与系统行为的关系来评价不同对话系统的效果。 |
| [^9] | [Comparing a composite model versus chained models to locate a nearest visual object.](http://arxiv.org/abs/2306.01551) | 该研究比较了两种架构（链式模型和组合模型）在定位最近的视觉对象方面的表现，结果显示两种架构的均方根误差（RMSE）都相同，但当任务可以分解成子任务时，链式架构的训练速度提高了12倍。 |
| [^10] | [Evaluating Machine Translation Quality with Conformal Predictive Distributions.](http://arxiv.org/abs/2306.01549) | 本文提出一种利用符合性预测分布评估机器翻译质量的新方法，同时评估翻译质量并提供可靠的置信度得分，在六种不同的语言对上的实验结果表明其优于基线方法，需要数据可交换性假设才能实现最佳性能。 |
| [^11] | [PassGPT: Password Modeling and (Guided) Generation with Large Language Models.](http://arxiv.org/abs/2306.01545) | 本研究使用大型语言模型PassGPT进行密码建模和生成，该模型比基于GAN的现有方法更准确，能生成符合任意限制的密码，为提高密码强度估计器提供了潜在的帮助。 |
| [^12] | [BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models.](http://arxiv.org/abs/2306.01506) | 本文提出了一种语言习得友好型基准，以检验自我监督口语语言模型在儿童词汇和句法经历中的表现，并提出了两个需要解决的挑战：文本和语音之间的差距和干净语音和野外语音之间的差距。 |
| [^13] | [Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations.](http://arxiv.org/abs/2306.01505) | 本文提出了一种监督式对抗性对比学习（SACL）框架，用于学习类别分布结构表示，通过联合类别分布对比学习目标，有效利用标签级特性一致性并保留细粒度的类内特性，实现了在对话情感识别中最先进的结果。 |
| [^14] | [Can LLMs like GPT-4 outperform traditional AI tools in dementia diagnosis? Maybe, but not today.](http://arxiv.org/abs/2306.01499) | 本文探讨了LLMs如GPT-4在痴呆症诊断上的潜力，发现目前还无法胜过传统AI工具。 |
| [^15] | [Data-Efficient French Language Modeling with CamemBERTa.](http://arxiv.org/abs/2306.01497) | 本文介绍了一种名为CamemBERTa的法语DeBERTa模型，相对于使用MLM训练的BERT-based模型，在相同数量的训练令牌下性能更加优秀，在多项法语下游任务中已经达到甚至超过了CamemBERT。 |
| [^16] | [GAIA Search: Hugging Face and Pyserini Interoperability for NLP Training Data Exploration.](http://arxiv.org/abs/2306.01481) | 本文提出将信息检索领域的方法与开源AI库Hugging Face和Pyserini工具集相结合，以提供一种用于NLP研究者的检索式数据分析的可靠工具。 |
| [^17] | [Guiding Text-to-Text Privatization by Syntax.](http://arxiv.org/abs/2306.01471) | 该论文介绍了一种基于语法的文本隐私保护方法，通过解决候选选择问题以提高替换的句法一致性。 |
| [^18] | [Light Coreference Resolution for Russian with Hierarchical Discourse Features.](http://arxiv.org/abs/2306.01465) | 本篇论文提出了一种通过收集自动话语分析的修辞特征来将修辞信息纳入神经指代消解模型的新方法，并取得了俄语RuCoCo-23共享任务中的最好成绩。 |
| [^19] | [Driving Context into Text-to-Text Privatization.](http://arxiv.org/abs/2306.01457) | 本文介绍了一种度量差分隐私机制，该机制在注入噪声之前加入了一个语义消歧步骤以提高歧义单词替代的有效性，并展示了在“上下文中的单词”数据集上的有效性。 |
| [^20] | [Unsupervised Extractive Summarization of Emotion Triggers.](http://arxiv.org/abs/2306.01444) | 本文介绍了一个无监督的系统，能够从文本中提取情感触发器并总结它们，以取代耗时昂贵的摘要生成过程，为灾难响应提供必要信息。 |
| [^21] | [Unsupervised Paraphrasing of Multiword Expressions.](http://arxiv.org/abs/2306.01443) | 本文提出了一种无监督的多词表达式改写方法，使用的数据和工具非常简单，且实验结果表明，该方法在熟语语义文本相似度任务中性能良好。 |
| [^22] | [Towards Robust FastSpeech 2 by Modelling Residual Multimodality.](http://arxiv.org/abs/2306.01442) | 该论文提出了一种名为TVC-GMM的三元链式高斯分布混合模型，用于解决FastSpeech 2合成表现性语音数据集时可能出现的Mel频谱平滑度差的问题，可以提高音频的听觉质量。 |
| [^23] | [Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction.](http://arxiv.org/abs/2306.01439) | 该论文介绍了一种名为NUDGE的策略，利用训练好的基于神经网络的代理来引导逻辑规则的搜索，实现了可解释和可解释的策略。 |
| [^24] | [Knowledge Graph Reasoning over Entities and Numerical Values.](http://arxiv.org/abs/2306.01399) | 本文提出了一种新方法，将数值推理纳入知识图谱推理，将数值视为一等公民并提供了一个统一的框架，用于对实体和数值进行推理，实现了对复杂查询的有效和高效回答。 |
| [^25] | [Assessing the Importance of Frequency versus Compositionality for Subword-based Tokenization in NMT.](http://arxiv.org/abs/2306.01393) | 本文通过实验发现，在NMT中基于子词的分词方法中，频率对于模型的表现贡献占据了90%-95%，因此相对于组合性，频率更为重要。 |
| [^26] | [ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?.](http://arxiv.org/abs/2306.01386) | 该论文介绍了面向零-shot对话状态跟踪的ChatGPT，该方法在初步实验中表现出最先进的性能。然而，通用模型的固有特性限制了其替代专用系统的能力，但其上下文学习能力有望成为开发专用和动态对话状态跟踪器的强大工具。 |
| [^27] | [Task-Agnostic Structured Pruning of Speech Representation Models.](http://arxiv.org/abs/2306.01385) | 本文提出了一种精细的注意力头剪枝方法和Straight-Through Estimator，用于加速模型剪枝，以解决自监督的预训练模型的大内存和强计算需求问题。在实验中表明，该模型可以在任务中取得很好的性能且参数减少且推理速度提高。 |
| [^28] | [Leveraging Auxiliary Domain Parallel Data in Intermediate Task Fine-tuning for Low-resource Translation.](http://arxiv.org/abs/2306.01382) | 本文展示了中间任务微调(ITFT)对于低资源、多语言、多领域的NMT非常有效，能够在一定程度上缓解领域分歧的影响。 |
| [^29] | [An Empirical Study on Challenging Math Problem Solving with GPT-4.](http://arxiv.org/abs/2306.01337) | 本研究探索使用GPT-4解决更复杂和有挑战性的数学问题，提出了一种名为MathChat的对话式问题求解框架，并在困难高中竞赛问题上进行了评估。 |
| [^30] | [Speech Translation with Foundation Models and Optimal Transport: UPC at IWSLT23.](http://arxiv.org/abs/2306.01327) | 本论文阐述了UPC机器翻译组使用基础模型和最优传输技术以及合成数据在IWSLT23离线语音翻译任务中的表现，最佳单模型在IWSLT.ACLdev2023上获得33.4分。 |
| [^31] | [LyricSIM: A novel Dataset and Benchmark for Similarity Detection in Spanish Song LyricS.](http://arxiv.org/abs/2306.01325) | 本文介绍了一种针对语义相似性任务的新数据集和基准，由多个本地注释者完成集体注释实验，评估了各种最先进的单语和多语言语言模型的性能，建立了基准结果。 |
| [^32] | [Text Style Transfer Back-Translation.](http://arxiv.org/abs/2306.01318) | 本研究提出了文本风格转化的Back-Translation技术（TST BT），通过使用风格转化模型改善BT数据的源语言部分，旨在提高自然输入的翻译质量。在不同的语言对上进行实验，结果表明TST BT显著提高了翻译性能，还可以用于领域适应，是一种通用的数据增强技术。 |
| [^33] | [Syntax-aware Hybrid prompt model for Few-shot multi-modal sentiment analysis.](http://arxiv.org/abs/2306.01312) | 本文提出了一种语法感知的混合提示模型，用于多模态少样本情感分析，通过融合手工提示和可学习提示，利用注意机制优化提示编码器，显著提高了分析性能。 |
| [^34] | [MetaVL: Transferring In-Context Learning Ability From Language Models to Vision-Language Models.](http://arxiv.org/abs/2306.01311) | 本文研究了如何在视觉-语言领域实现上下文学习能力，并通过在NLP任务上元训练语言模型，成功将上下文学习能力转移到VL任务上，实验结果表明，该方法具有显著优势。 |
| [^35] | [DistilXLSR: A Light Weight Cross-Lingual Speech Representation Model.](http://arxiv.org/abs/2306.01303) | 提出一种跨语言语音表示模型DistilXLSR，通过随机打乱语音中的音素，只使用英语数据来训练模型，并设计一种初始化方法，成功将参数减少50%，同时保持跨语言表达能力，适用于各种语言/教师模型并有潜力提高英语预训练模型的跨语言性能。 |
| [^36] | [Improved Training for End-to-End Streaming Automatic Speech Recognition Model with Punctuation.](http://arxiv.org/abs/2306.01296) | 本文提出了一种使用块状Transformer编码器进行训练以实现标点预测的方法，并通过联合使用块和话语的CTC损失来获得较好的预测效果。 |
| [^37] | [KL-Divergence Guided Temperature Sampling.](http://arxiv.org/abs/2306.01286) | 该论文提出了一种新的温度采样算法，通过KL-散度引导动态调整温度，从而缓解多样性和可归因性之间的权衡，实验证明该算法在对话问答和摘要任务中表现优异。 |
| [^38] | [VoteTRANS: Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations.](http://arxiv.org/abs/2306.01273) | VoteTRANS 是一种无需训练即可检测对抗性文本的方法，通过比较输入文本及其转换的硬标签实现检测，可有效应对各种最先进的攻击、模型和数据集中的对抗性文本。 |
| [^39] | [Automatic Translation of Hate Speech to Non-hate Speech in Social Media Texts.](http://arxiv.org/abs/2306.01261) | 本文介绍了一种将社交媒体文本中的恶意言论自动翻译为非恶意言论的方法，以西班牙语为例，并提供了数据集和基线结果，旨在为减少社区中恶意言论的传播贡献更有效的方法。 |
| [^40] | [How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?.](http://arxiv.org/abs/2306.01248) | 这篇论文探讨了是否可以使用预训练的抽象模型和大型语言模型来自动生成法律案例判决的摘要，并在印度的法庭案例判决中进行了相关实验分析。 |
| [^41] | [THiFLY Research at SemEval-2023 Task 7: A Multi-granularity System for CTR-based Textual Entailment and Evidence Retrieval.](http://arxiv.org/abs/2306.01245) | 本文针对NLI4CT任务，提出了一个面向CTR的文本蕴涵和证据检索的多粒度系统，使用多粒度推断网络(MGNet)和T5模型SciFive，并进行模型集成和联合推断方法以增加系统的稳定性和一致性性能。在NLI4CT数据集上实验结果表现优异。 |
| [^42] | [Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators.](http://arxiv.org/abs/2306.01242) | 本研究提出了一个基础框架-"负责任的任务自动化（ResponsibleTA）"，使大型语言模型可以负责任地作为任务协同工具。该框架增强了LLM的三种能力：预测任务可行性、验证任务完整性以及增强任务安全性。 |
| [^43] | [Adapting an Unadaptable ASR System.](http://arxiv.org/abs/2306.01208) | 本文探讨了一种适应在线服务提供商的语音识别系统的方法，采用错误纠正的方法，并以 OpenAI Whisper ASR 为例，使用 LibriSpeech 作为主要适应目标领域进行实验。结果显示该方法具有一定的泛化能力，可适用于不同体系结构的 ASR 模型。 |
| [^44] | [Estimating Semantic Similarity between In-Domain and Out-of-Domain Samples.](http://arxiv.org/abs/2306.01206) | 本文研究如何以原则性的方式分析模型在域内和域外设置下的性能，最终找出一种无监督方法识别OOD / OODist样本。 |
| [^45] | [Learning When to Speak: Latency and Quality Trade-offs for Simultaneous Speech-to-Speech Translation with Offline Models.](http://arxiv.org/abs/2306.01201) | 本文提出了一个适用于实际场景的同时语音翻译系统，支持从57种语言翻译成英语，并具有调整输出延迟的可调参数。我们展示了可以在不增加显著延迟的情况下达到离线水平的准确性。 |
| [^46] | [Multi-Dimensional Evaluation of Text Summarization with In-Context Learning.](http://arxiv.org/abs/2306.01200) | 本文研究采用基于上下文学习的大型语言模型作为文本多维度评估器的有效性，针对文本摘要任务，实验表明该方法在与学习评估框架相竞争的地位。同时，本文探究了上下文样例选择、数量以及评估零-shot摘要等方面的影响。 |
| [^47] | [Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation.](http://arxiv.org/abs/2306.01183) | 本文系统研究了使用 GPT-3 从用户社交媒体帖子中零样本估计个性特质的能力。在插入关于特质的知识后，GPT-3 性能接近于现有的预训练 SotA，但在被提示提供细粒度分类时，其性能降至基线水平。 |
| [^48] | [Hybrid Long Document Summarization using C2F-FAR and ChatGPT: A Practical Study.](http://arxiv.org/abs/2306.01169) | 本文结合最新的ChatGPT和抽取式摘要模型C2F-FAR，提出了一种混合式抽取和摘要流水线以解决长文本摘要的挑战，与getAbstract AG合作，该方法在内容覆盖率、连贯性和可读性方面表现优异。 |
| [^49] | [Leveraging Natural Language Processing For Public Health Screening On YouTube: A COVID-19 Case Study.](http://arxiv.org/abs/2306.01164) | 本研究探索利用自然语言处理技术识别COVID-19相关的YouTube视频日志内容，用于公共卫生筛查。 |
| [^50] | [Faster Causal Attention Over Large Sequences Through Sparse Flash Attention.](http://arxiv.org/abs/2306.01160) | 本文介绍了一种新的稀疏Flash注意力机制，能够快速处理大序列中的因果关系，且速度提高了多倍，可以作为任何基于Transformer的语言模型中密集自我注意力的替代方案，并在多个设置中产生了最先进的结果。 |
| [^51] | [Diverse and Faithful Knowledge-Grounded Dialogue Generation via Sequential Posterior Inference.](http://arxiv.org/abs/2306.01153) | 本文提出了一种名为SPI的端到端学习框架，能够忠实地生成多样化的基于知识的对话。 |
| [^52] | [Did You Read the Instructions? Rethinking the Effectiveness of Task Definitions in Instruction Learning.](http://arxiv.org/abs/2306.01150) | 本文研究了任务定义在指令学习中的作用，发现当删除描述任务输出的内容时模型性能才会显著下降，提出了一种自动算法可以压缩任务定义，删除60\%标记仍可以提高模型性能。 |
| [^53] | [Evaluating the Capabilities of Multi-modal Reasoning Models with Synthetic Task Data.](http://arxiv.org/abs/2306.01144) | 本研究提出一种利用合成方法生成用于评估复杂多模态推理任务的数据集，并将其应用于测试最新的视觉问答模型的表现，结果表明该模型在上下文相关的异常检测任务上表现不佳。 |
| [^54] | [Examining the Causal Effect of First Names on Language Models: The Case of Social Commonsense Reasoning.](http://arxiv.org/abs/2306.01117) | 本文研究了名字对常识推理中语言模型的影响，结果表明名字的频率会直接影响模型的预测。 |
| [^55] | [The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only.](http://arxiv.org/abs/2306.01116) | 本文发现经过适当的筛选和去重后，仅凭网络数据就能训练出强大的语言模型，这甚至明显优于使用筛选后的语料库训练。研究还表明，即使在广泛筛选后，从网络中提取的高质量数据仍然充足，这为训练更大、更强大的语言模型带来了希望。 |
| [^56] | [Revisiting Hate Speech Benchmarks: From Data Curation to System Deployment.](http://arxiv.org/abs/2306.01105) | 该论文介绍了GOTHate数据集，并详细比较了该数据集与现有的仇恨言论数据集，研究了模型如何捕捉中立的恶意内容中的仇恨信号。研究发现，GOTHate很难在纯文本环境下进行分类，并介绍了如何通过添加内生信号来提高模型性能。 |
| [^57] | [LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization.](http://arxiv.org/abs/2306.01102) | 本文介绍了利用大语言模型和多样性优化算法相结合的 LLMatic 神经结构搜索算法。该算法在CIFAR-10数据集进行测试，仅进行2000次搜索即可产生高性能网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。 |
| [^58] | [UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of Multilingual BERT for Low-resource Sentiment Analysis.](http://arxiv.org/abs/2306.01093) | 本文介绍了 UCAS-IIE-NLP 设计的 SACL-XLMR 系统，它利用词典式多语言BERT进行情感感知表示学习，使用监督性对抗式对比学习技术进行情感传播结构化表示学习，用于低资源情感分析，且在多语言和零样本情感分类子任务中表现出色，并且在零样本分类子任务中获得了第一名。 |
| [^59] | [Improving the Robustness of Summarization Systems with Dual Augmentation.](http://arxiv.org/abs/2306.01090) | 本文通过数据增强和对抗样本生成技术提出了一种用于提高摘要系统鲁棒性的双重增强方法，该方法可以有效提高模型在对抗性和噪音测试集上的性能。 |
| [^60] | [Quantization-Aware and Tensor-Compressed Training of Transformers for Natural Language Understanding.](http://arxiv.org/abs/2306.01076) | 本研究提出了一种量化感知张量压缩训练方法，用于减少基于Transformer的模型的模型大小，算术运算和最终运行时延。该方法经过逐层蒸馏后在文本蕴含和情感分析任务中表现出良好性能。 |
| [^61] | [TimelineQA: A Benchmark for Question Answering over Timelines.](http://arxiv.org/abs/2306.01069) | TimelineQA是一个用于查询生活日志的加速进展的基准测试，涉及时间和地理信息，已经公开发布，并使用两种最先进的模型进行了实验，但这两种模型均未达到人类表现水平。 |
| [^62] | [Reimagining Retrieval Augmented Language Models for Answering Queries.](http://arxiv.org/abs/2306.01061) | 研究表明，将半参数化体系结构与查询分析器/计划器以及溯源相结合，可使问题回答的系统在准确性和效率方面显著提高。 |
| [^63] | [Bypass Temporal Classification: Weakly Supervised Automatic Speech Recognition with Imperfect Transcripts.](http://arxiv.org/abs/2306.01031) | 本文提出了一种新颖的算法，用重视转录不确定性的方式解决语音识别中训练数据不完美的问题，提高了ASR系统的鲁棒性和准确性。 |
| [^64] | [PV2TEA: Patching Visual Modality to Textual-Established Information Extraction.](http://arxiv.org/abs/2306.01016) | PV2TEA提出了一种基于编码器-解码器架构的信息抽取模型，在多模态注释困难的情况下解决了跨模态集成的问题，并提出了三种偏差降低方案。 |
| [^65] | [How to Estimate Model Transferability of Pre-Trained Speech Models?.](http://arxiv.org/abs/2306.01015) | 本文介绍了一个新的框架，可以高效地评估预训练语音模型在微调目标任务时的迁移性。该框架利用两个表示理论，通过生成候选模型的排名分数，可以在不进行实际微调的情况下计算迁移性分数，实验结果表明该框架与微调基础事实之间存在很高的相关性和低的p值，是一个节省资源、高效节省时间的微调方法。 |
| [^66] | [Examining the Emergence of Deductive Reasoning in Generative Language Models.](http://arxiv.org/abs/2306.01009) | 本研究调查了不同规模的生成语言模型的演绎推理能力，发现随着规模的增加，推理能力增强，长度不会影响大部分模型表现。 |
| [^67] | [Scaling Evidence-based Instructional Design Expertise through Large Language Models.](http://arxiv.org/abs/2306.01006) | 本文探讨了如何利用大型语言模型扩展基于证据的教学设计专业知识，通过两个案例研究展示了GPT-4在教学设计中的应用，并提供了使用LLMs的最佳实践和未来LLMs为所有学习者提供个性化教育内容的愿景。 |
| [^68] | [AoM: Detecting Aspect-oriented Information for Multimodal Aspect-Based Sentiment Analysis.](http://arxiv.org/abs/2306.01004) | 本文提出了一个面向方面的方法(AoM)来检测与方面相关的语义和情感信息，并明确地将情感嵌入到AoM中。实验证明AoM在改进多模态基于方面的情感分析(MABSA)方面非常有效。 |
| [^69] | [Towards Selection of Text-to-speech Data to Augment ASR Training.](http://arxiv.org/abs/2306.00998) | 本文提出了一种从大规模文本转语音数据集中选择适当的合成语音样本作为自动语音识别（ASR）模型的补充训练数据的方法。在实验中表明，将具有相当差异的合成样本纳入ASR训练对于提高识别性能至关重要。我们提出的解决方案比其他方法能够将TTS数据的大小减少至30%以下的同时保持准确性。 |
| [^70] | [Weakly-supervised forced alignment of disfluent speech using phoneme-level modeling.](http://arxiv.org/abs/2306.00996) | 本文提出了一种使用加权有限状态转换器对CTC模型的对齐图构建进行改进的弱监督方法，可以对失语性言语进行强制对齐，减轻了对逐字转录的需求，能够有效地在实际应用中使用，并在实验中取得了显著的改进。 |
| [^71] | [TopEx: Topic-based Explanations for Model Comparison.](http://arxiv.org/abs/2306.00976) | TopEx 是一种基于无模型主题的解释方法，使得语言模型的比较更公平，并可以在不同自然语言处理任务上识别模型之间的相似性和差异。 |
| [^72] | [AfriNames: Most ASR models "butcher" African Names.](http://arxiv.org/abs/2306.00253) | 该论文探讨了自动语音识别模型在处理非洲名字时的性能问题，并提出了多语言预训练和数据增强等策略，通过微调ASR模型在多个非洲口音上，显著减少了模型误差，相对WER提高了81.5％。 |
| [^73] | [UKP-SQuARE: An Interactive Tool for Teaching Question Answering.](http://arxiv.org/abs/2305.19748) | 这篇论文介绍了UKP-SQuARE作为一个用于教授问答技术的交互式工具，学生可以通过其在不同角度了解各种QA模型，并借此获得理论概念和问题解决技能。 |
| [^74] | [KEYword based Sampling (KEYS) for Large Language Models.](http://arxiv.org/abs/2305.18679) | 本文旨在探讨如何通过结合人类生成答案的思路来生成接近人类行为和事实的答案，并探讨关键词对Q/A任务解码算法的影响。 |
| [^75] | [Faith and Fate: Limits of Transformers on Compositionality.](http://arxiv.org/abs/2305.18654) | 研究了Transformer模型在三个代表性组合型任务中的表现，发现其通过线性子图匹配解决多步组合推理问题。 |
| [^76] | [Multiscale Positive-Unlabeled Detection of AI-Generated Texts.](http://arxiv.org/abs/2305.18149) | 本文提出了一种多尺度正负样本的训练框架，以解决多尺度AI生成文本的检测问题。通过将短机器文本标记为“未标记”来重新表述文本分类问题，并提出了一个规则化损失函数来优化检测性能，有效性能显著优于现有的方法。 |
| [^77] | [Exploring Better Text Image Translation with Multimodal Codebook.](http://arxiv.org/abs/2305.17415) | 该研究提出了一个基于多模态码本的文本图片翻译模型。通过构建一个多阶段训练框架，利用了额外的双语文本和光学字符识别数据集，该模型能够将图像与相关文本关联起来，提供有用的补充信息，取得了比目前最先进的方法更好的效果。 |
| [^78] | [Motion-Based Sign Language Video Summarization using Curvature and Torsion.](http://arxiv.org/abs/2305.16801) | 该论文介绍了一种基于曲率和扭矩的手语视频摘要技术，能够选出最具信息量的关键帧。 |
| [^79] | [Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art.](http://arxiv.org/abs/2305.16259) | 本文简要概述了长文本的神经自然语言处理的现状，主要包括文档分类和摘要，涵盖了情感分析，同时还探讨了长文本NLP的主要挑战、问题和解决方案。 |
| [^80] | [Revisiting Non-Autoregressive Translation at Scale.](http://arxiv.org/abs/2305.16155) | 本文系统研究了缩放对非自回归翻译(NAT)行为的影响，证明了缩放可以提高NAT的翻译性能。通过异构体系结构可以实现有可比性的性能，同时保持标准NAT模型的高解码速度。 |
| [^81] | [Linguistic Properties of Truthful Response.](http://arxiv.org/abs/2305.15875) | 该论文研究了LLM的不真实回答现象，发现GPT-3模型对给定提示的回答在语言特性上很相似。同时，该论文证明了在没有评估内容本身的情况下，仅依赖模型回答的风格成分即可分类真实性。 |
| [^82] | [SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations.](http://arxiv.org/abs/2305.14728) | SenteCon是一种能够提供高级可解释性的方法，通过把文本编码为可解释类别的层，同时不会对下游任务的预测性能造成影响。 |
| [^83] | [Optimizing Non-Autoregressive Transformers with Contrastive Learning.](http://arxiv.org/abs/2305.13667) | 本文通过从模型分布中采样来缓解NATs学习多模态数据分布的困难，并导出对比约束来稳定训练过程。该方法在机器翻译、文本摘要和改写三个任务上优于以前的非自回归基线。 |
| [^84] | [On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation.](http://arxiv.org/abs/2305.10930) | 零样本多语言神经机器翻译容易出现“离谱问题”，本文提出的简单且有效的算法LAVS可以通过增加语言之间的KL分歧显著降低这个问题。 |
| [^85] | [Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark.](http://arxiv.org/abs/2305.10036) | 提出了一种名为 EmbMarker 的嵌入式水印方法，用于保护大型语言模型在 EaaS 中的版权。该方法可以在嵌入式上植入后门，并有效地传输和恢复。实验证明，EmbMarker 可以在维护各种 NLP 任务的性能的同时成功保护 EaaS 对 LLM 的版权。 |
| [^86] | ["I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation.](http://arxiv.org/abs/2305.09941) | 本论文研究了如何以TGNB人群的声音为中心，评估开放式语言生成中的偏见。通过理解TGNB个体的经历，提出了以TGNB人群为中心的OLG系统评估框架，并且包括一个为TGNB人群设计的调查工具和分析方法。 |
| [^87] | [Measuring Consistency in Text-based Financial Forecasting Models.](http://arxiv.org/abs/2305.08524) | 金融预测中模型的一致性对于建立用户信任至关重要，但目前金融预测方法很少考虑这一点，我们提出了一种评估金融文本逻辑一致性的评估工具FinTrust，并使用它发现最先进的金融预测NLP模型的一致性较差。 |
| [^88] | [ProKnow: Process Knowledge for Safety Constrained and Explainable Question Generation for Mental Health Diagnostic Assistance.](http://arxiv.org/abs/2305.08010) | 本论文提出了ProKnow的概念，它可以提高虚拟心理健康助手的安全性和专业性。同时开发了自然语言问题生成算法，通过明确建模安全性、知识捕获和可解释性来模拟流程知识。在抑郁症和焦虑症中的实验表明，使用ProKnow引导的算法可以生成更安全的问题。 |
| [^89] | [End-to-end spoken language understanding using joint CTC loss and self-supervised, pretrained acoustic encoders.](http://arxiv.org/abs/2305.02937) | 本文提出了一种使用联合CTC损失和预训练声学编码器的基于端到端的口语理解模型，该方法实现了在两个数据集上超越SOTA模型的效果。 |
| [^90] | [On the Possibilities of AI-Generated Text Detection.](http://arxiv.org/abs/2304.04736) | 该研究探讨了AI生成文本检测的可能性，提出了精确的样本复杂度界限，并指出了设计更准确的检测方法和提高透明度的挑战。 |
| [^91] | [Quick Dense Retrievers Consume KALE: Post Training Kullback Leibler Alignment of Embeddings for Asymmetrical dual encoders.](http://arxiv.org/abs/2304.01016) | 本文提出了一种通过结构压缩和模型尺寸不对称的双编码器模型 KALE，有效提高密集信息检索的推理效率，同时允许查询编码器的有效压缩，而无需进行全部的再训练或索引生成，此方法能够生成超过DistilBERT性能的模型。 |
| [^92] | [N-best T5: Robust ASR Error Correction using Multiple Input Hypotheses and Constrained Decoding Space.](http://arxiv.org/abs/2303.00456) | 本文提出了一种新的 N-best T5 模型，该模型利用 ASR N-best 列表作为输入，并使用受限解码过程，从而实现了针对 ASR 错误修正的强鲁棒性能。 |
| [^93] | [Fluid Transformers and Creative Analogies: Exploring Large Language Models' Capacity for Augmenting Cross-Domain Analogical Creativity.](http://arxiv.org/abs/2302.12832) | 本文系统地探讨了大语言模型增强跨领域类比创造力的能力，结果表明LLM生成的跨领域类比在问题重构中具有实际帮助，并且存在一些潜在的危害，需要注意。 |
| [^94] | [ChatGPT: Jack of all trades, master of none.](http://arxiv.org/abs/2302.10724) | 本研究检验了 ChatGPT 在 25 个不同的 NLP 任务上的性能，它是一个万能的 AI 模型，但无关紧要的表现可能会对某些任务的表现产生负面影响。 |
| [^95] | [Shades of Iteration: from Elgot to Kleene.](http://arxiv.org/abs/2301.06202) | 本文介绍了Elgot monads和Kleene monads之间的形式联系，并提出一种新的while-monad类。虽然Kleene monads是相对简单的代数描述，但是while-monads可能不符合Kleene代数定律，或者甚至不支持Kleene迭代运算符。 |
| [^96] | [True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4.](http://arxiv.org/abs/2212.10114) | 本文介绍了一项深度模因推理基准测试，由191个侦探故事谜题构成，只有47%的人能成功解决其中一个谜题。研究表明，GPT-3模型在此基准测试中准确性仅为28％，而GPT-4仅能解决38%的谜题。这表明LLMs与人类在深度推理能力上仍存在显著差距，需要进一步的研究。 |
| [^97] | [When Federated Learning Meets Pre-trained Language Models' Parameter-Efficient Tuning Methods.](http://arxiv.org/abs/2212.10025) | 本文在隐私敏感的自然语言处理任务中探讨了联邦学习如何与参数高效调整方法结合以解决数据异质性问题，在维持可接受性能的同时显著减少通信开销。 |
| [^98] | [Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text.](http://arxiv.org/abs/2211.11300) | 本文提出了一种多层知识蒸馏方法，融合了语言模型的训练和微调方法来进行文本中的离群检测，实验结果表明其有效性。 |
| [^99] | [Why Did the Chicken Cross the Road? Rephrasing and Analyzing Ambiguous Questions in VQA.](http://arxiv.org/abs/2211.07516) | 本文提出了一个新的数据集，针对图像问题的歧义性问题进行了研究，通过重新构述问题并分组答案来减少歧义。同时，开发了一种英语问题生成模型，该模型能够产生更少歧义的问题。 |
| [^100] | [REV: Information-Theoretic Evaluation of Free-Text Rationales.](http://arxiv.org/abs/2210.04982) | 本论文提出了一种名为REV的度量，用于评估自由文本解释中新颖、与标签相关的信息的数量，通过信息论的角度进行研究。实验证明REV在评估解释-标签对方面的有效性，并且与人类直觉一致。 |
| [^101] | [Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization.](http://arxiv.org/abs/2210.04492) | 本文提出了名为UDDIA的统一去毒化和去偏见框架，它能够有效地消除有毒语言和减少社会偏见，同时保持流畅性。 |
| [^102] | [ThinkSum: Probabilistic reasoning over sets using large language models.](http://arxiv.org/abs/2210.01293) | 本研究提出一种两阶段的概率推理范例ThinkSum，通过以结构化的方式对对象或事实集进行推理，实现了对多个对象或事实进行推理并进行逻辑推导的场景中的改进。 |
| [^103] | [BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models.](http://arxiv.org/abs/2206.14268) | 本文提出了一种从预训练语言模型中提取任意关系的知识图谱的方法，通过最小的关系定义输入，实现在庞大的实体对空间中搜索，提取准确的知识。 |
| [^104] | [PhysNLU: A Language Resource for Evaluating Natural Language Understanding and Explanation Coherence in Physics.](http://arxiv.org/abs/2201.04275) | 这篇论文提供了一个语言资源集合，用于评估语言模型在物理学自然语言理解和解释连贯性方面的表现。论文分析物理话语中最常见的方程和子学科，并提出了表现较差的基准，即使训练了数学自然语言任务，当代语言模型也会在物理相关的连贯性任务中面临挑战。 |
| [^105] | [Classifying YouTube Comments Based on Sentiment and Type of Sentence.](http://arxiv.org/abs/2111.01908) | 本论文提出了一种基于情感和句子类型的方法，将原始的YouTube评论分类，以帮助YouTuber找到更相关的评论，从而增加其观众群。 |
| [^106] | [Syntax-Aware Graph-to-Graph Transformer for Semantic Role Labelling.](http://arxiv.org/abs/2104.07704) | 本文提出了一种句法感知的图转换器模型用于语义角色标注任务，该模型将句法结构以嵌入的方式输入到Transformer的自注意机制中，达到了比以往方法更好的性能。 |
| [^107] | [Lessons on Parameter Sharing across Layers in Transformers.](http://arxiv.org/abs/2104.06022) | 该论文提出了一种放宽常用参数共享技术的Transformer参数共享方法，其可以提高计算时间的效率，通过三种策略来分配每个层的参数，在实验中表现出高效的参数大小和计算时间，并在使用大量训练数据的配置中同样有效。 |

# 详细

[^1]: 用工作流程与行动计划在任务导向对话中提高泛化性能

    Improving Generalization in Task-oriented Dialogues with Workflows and Action Plans. (arXiv:2306.01729v1 [cs.CL])

    [http://arxiv.org/abs/2306.01729](http://arxiv.org/abs/2306.01729)

    本论文提出了在任务导向对话中提高泛化性能的方法，通过增强对话上下文，使用有效的工作流名称和行动计划编码来完成多步骤任务的执行，解决了大型预训练语言模型无法可靠执行训练期间未见过的新多步骤任务的问题。

    

    任务导向对话的难点在于涉及理解用户意图、从用户处收集信息、执行API调用以及生成有用流畅的回应。然而，对于复杂的任务，我们必须按特定顺序在多个步骤中正确地完成所有这些事情。虽然大型预训练语言模型可以进行端到端的微调来创建生成流畅文本的多步骤任务导向对话代理，但我们的实验证实，仅通过这种方法无法可靠地执行训练期间未见过的新多步骤任务。为了解决这些限制，我们增强了给出到text2text转换器的对话上下文，其中包括已知的有效工作流名称和行动计划。行动计划包括完成任务所需的行动序列，并编码为简单的关键字序列（例如，验证身份，拉起账户，重置密码等）。我们在基于行动的对话数据集上进行了广泛的实验。

    Task-oriented dialogue is difficult in part because it involves understanding user intent, collecting information from the user, executing API calls, and generating helpful and fluent responses. However, for complex tasks one must also correctly do all of these things over multiple steps, and in a specific order. While large pre-trained language models can be fine-tuned end-to-end to create multi-step task-oriented dialogue agents that generate fluent text, our experiments confirm that this approach alone cannot reliably perform new multi-step tasks that are unseen during training. To address these limitations, we augment the dialogue contexts given to \textmd{text2text} transformers with known \textit{valid workflow names} and \textit{action plans}. Action plans consist of sequences of actions required to accomplish a task, and are encoded as simple sequences of keywords (e.g. verify-identity, pull-up-account, reset-password, etc.). We perform extensive experiments on the Action-Based
    
[^2]: 跨语言迁移的高效语言特定模型蒸馏

    Distilling Efficient Language-Specific Models for Cross-Lingual Transfer. (arXiv:2306.01709v1 [cs.CL])

    [http://arxiv.org/abs/2306.01709](http://arxiv.org/abs/2306.01709)

    本文提出了一种从大规模多语言模型中提取语言特定模型的方法，它通过双语蒸馏实现，可以保留原始模型的跨语言迁移能力，同时可以避免不必要的模型部署成本。

    

    大规模多语言Transformer（MMTs），如mBERT和XLM-R，被广泛用于跨语言迁移学习。虽然它们进行了预训练来表示数百种语言，但自然语言处理系统的最终用户通常只对个别语言感兴趣。为此，MMT的语言覆盖范围使它们在模型大小、推理时间、能源和硬件成本方面不必要地昂贵。因此，我们提出从MMTs中提取压缩的语言特定模型，保留原始MMTs在跨语言迁移方面的能力。这是通过进行双语蒸馏实现的，即仅使用源语言和目标语言的数据。具体来说，我们使用一个名为BiStil的两阶段蒸馏方法：（i）第一阶段从MMT中蒸馏出一般的双语模型，而（ii）第二阶段使用经过任务调整的原始MMT变体作为“教师”，通过稀疏精调双语“学生”模型来进行任务特定的蒸馏。我们评估了...

    Massively multilingual Transformers (MMTs), such as mBERT and XLM-R, are widely used for cross-lingual transfer learning. While these are pretrained to represent hundreds of languages, end users of NLP systems are often interested only in individual languages. For such purposes, the MMTs' language coverage makes them unnecessarily expensive to deploy in terms of model size, inference time, energy, and hardware cost. We thus propose to extract compressed, language-specific models from MMTs which retain the capacity of the original MMTs for cross-lingual transfer. This is achieved by distilling the MMT bilingually, i.e., using data from only the source and target language of interest. Specifically, we use a two-phase distillation approach, termed BiStil: (i) the first phase distils a general bilingual model from the MMT, while (ii) the second, task-specific phase sparsely fine-tunes the bilingual "student" model using a task-tuned variant of the original MMT as its "teacher". We evaluate
    
[^3]: 合并模型时如何解决干扰的问题

    Resolving Interference When Merging Models. (arXiv:2306.01708v1 [cs.LG])

    [http://arxiv.org/abs/2306.01708](http://arxiv.org/abs/2306.01708)

    本文揭示了现有模型合并技术存在的干扰问题，提出了具有广泛适用性的解决方案，可显着提高合并后模型的性能。

    

    迁移学习可以在下游任务中进一步微调预训练模型，从而获得显著的优势，包括改进下游性能，加快收敛速度和提高样本效率。然而，已有的模型合并技术往往忽视了不同模型参数之间的干扰，导致合并多个模型时性能大幅下降。本文证明，先前的合并技术由于两个主要干扰来源而不慎丢失有价值的信息：(a)冗余参数值引起的干扰和(b)表示同一参数值的符号在不同模型中的差异。

    Transfer learning - i.e., further fine-tuning a pre-trained model on a downstream task - can confer significant advantages, including improved downstream performance, faster convergence, and better sample efficiency. These advantages have led to a proliferation of task-specific fine-tuned models, which typically can only perform a single task and do not benefit from one another. Recently, model merging techniques have emerged as a solution to combine multiple task-specific models into a single multitask model without performing additional training. However, existing merging methods often ignore the interference between parameters of different models, resulting in large performance drops when merging multiple models. In this paper, we demonstrate that prior merging techniques inadvertently lose valuable information due to two major sources of interference: (a) interference due to redundant parameter values and (b) disagreement on the sign of a given parameter's values across models. To 
    
[^4]: 从算术任务中学习多步推理

    Learning Multi-step Reasoning from Arithmetic Task. (arXiv:2306.01707v1 [cs.CL])

    [http://arxiv.org/abs/2306.01707](http://arxiv.org/abs/2306.01707)

    本文研究如何将相对较小的语言模型注入具有多步推理能力的合成算术任务（MsAT），从而提高LM在数学问题解决上的表现。

    

    数学推理被认为是语言模型（LM）必要的能力。最近的研究表明，大型LM在解决数学问题方面表现出色。成功归因于它们的连续思考（CoT）推理能力，即将复杂问题分解成逐步推理链的能力，但这种能力似乎只出现在具有丰富参数的模型中。本研究研究如何将相对较小的LM与多步推理能力相结合。我们建议通过对合成数据集MsAT（多步算术任务）进行持续的预训练来注入这种能力。我们在四个数学应用题数据集上的实验表明了所提出方法在增强LM数学推理能力方面的有效性。

    Mathematical reasoning is regarded as a necessary ability for Language Models (LMs). Recent works demonstrate large LMs' impressive performance in solving math problems. The success is attributed to their Chain-of-Thought (CoT) reasoning abilities, i.e., the ability to decompose complex questions into step-by-step reasoning chains, but such ability seems only to emerge from models with abundant parameters. This work investigates how to incorporate relatively small LMs with the capabilities of multi-step reasoning. We propose to inject such abilities by continually pre-training LMs on a synthetic dataset MsAT, which stands for Multi-step Arithmetic Task. Our experiments on four math word problem datasets show the effectiveness of the proposed method in enhancing LMs' math reasoning abilities.
    
[^5]: 精细化的人类反馈可以提供更好的语言模型训练奖励

    Fine-Grained Human Feedback Gives Better Rewards for Language Model Training. (arXiv:2306.01693v1 [cs.CL])

    [http://arxiv.org/abs/2306.01693](http://arxiv.org/abs/2306.01693)

    本文提出了Fine-Grained RLHF框架，使用精细化的人类反馈作为明确的训练信号来训练和学习语言模型。该框架提供了多个细致的奖励模型来获得更好的效果。

    

    语言模型经常表现出不良的文本生成行为，包括生成虚假、有害或无关的输出。最近，从人类反馈中进行强化学习（RLHF）-其中人类对LM输出的偏好评价被转化为学习信号-已经显示出解决这些问题的潜力。然而，这种整体反馈对长文本输出传达的信息有限；它不表明输出的哪些方面影响了用户的偏好；例如，哪些部分包含什么类型的错误。本文中，我们使用精细化的人类反馈（例如，哪个句子是错误的，哪个子句是无关的）作为明确的训练信号。我们介绍了Fine-Grained RLHF，这是一个能够训练和学习与不同反馈类型相关的多个奖励模型的精细化奖励功能的框架，具有以下两个特征：（1）密度，以在生成每个段落（例如一个句子）后提供奖励； （2）并入不同反馈类型的多个奖励模型。

    Language models (LMs) often exhibit undesirable text generation behaviors, including generating false, toxic, or irrelevant outputs. Reinforcement learning from human feedback (RLHF) - where human preference judgments on LM outputs are transformed into a learning signal - has recently shown promise in addressing these issues. However, such holistic feedback conveys limited information on long text outputs; it does not indicate which aspects of the outputs influenced user preference; e.g., which parts contain what type(s) of errors. In this paper, we use fine-grained human feedback (e.g., which sentence is false, which sub-sentence is irrelevant) as an explicit training signal. We introduce Fine-Grained RLHF, a framework that enables training and learning from reward functions that are fine-grained in two respects: (1) density, providing a reward after every segment (e.g., a sentence) is generated; and (2) incorporating multiple reward models associated with different feedback types (e.
    
[^6]: DiffusEmp:一种基于扩散模型的多级控制共情回应生成框架

    DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control for Empathetic Response Generation. (arXiv:2306.01657v1 [cs.CL])

    [http://arxiv.org/abs/2306.01657](http://arxiv.org/abs/2306.01657)

    本文提出了一种名为DiffusEmp的框架，该框架基于条件扩散语言模型，并使用多级控制信号来生成更加细致和个性化的共情回应。

    

    共情是开放式交流中至关重要的因素，它自然地展示了一个人对他人的关心和理解。虽然已经提出了几种生成共情响应的方法，但现有的作品往往导致单调的共情，即指通用和安全的表达方式。本文提出使用显式控制来引导共情表达，并设计了一个DiffusEmp框架，基于条件扩散语言模型，统一了对话上下文和属性导向控制信号的利用。具体而言，引入通信机制、意图和语义框架作为多层次信号，可从粗糙到细致地控制共情实现。然后我们设计了一个特定的屏蔽策略，以反映多层次信号与响应令牌之间的关系，并将其整合到扩散模型中以影响生成过程。实验结果在基准数据集EmpatheticDialogue上表明，我们的框架优于其他共情回应生成方法。

    Empathy is a crucial factor in open-domain conversations, which naturally shows one's caring and understanding to others. Though several methods have been proposed to generate empathetic responses, existing works often lead to monotonous empathy that refers to generic and safe expressions. In this paper, we propose to use explicit control to guide the empathy expression and design a framework DiffusEmp based on conditional diffusion language model to unify the utilization of dialogue context and attribute-oriented control signals. Specifically, communication mechanism, intent, and semantic frame are imported as multi-grained signals that control the empathy realization from coarse to fine levels. We then design a specific masking strategy to reflect the relationship between multi-grained signals and response tokens, and integrate it into the diffusion model to influence the generative process. Experimental results on a benchmark dataset EmpatheticDialogue show that our framework outper
    
[^7]: 从部分标注数据中学习：面向语言学习的区别感知型填空练习自动生成

    Learning from Partially Annotated Data: Example-aware Creation of Gap-filling Exercises for Language Learning. (arXiv:2306.01584v1 [cs.CL])

    [http://arxiv.org/abs/2306.01584](http://arxiv.org/abs/2306.01584)

    本文提出了一种从已有的例子练习生成新的区别感知型填空练习，无需深度标注，特别针对语言学习中的语法练习；使用了一种新的神经网络模型并提供了相应的法语语法数据集，结果表明该模型在这类任务中表现优于竞争基准。

    

    做练习（包括练习测试）是学习的一个关键组成部分，创建这样的练习需要教师付出非常大的努力。在数字化教育工具中自动生成练习具有很大的价值。本文特别关注于无需深度标注材料情况下，通过示例练习自动创建语言学习中的填空练习，尤其是语法练习。我们提出了一种新的神经网络模型，专门用于Gap-filling exercise generation任务，并且提供了一个法语语法的现实基准数据集。我们通过实验证明，我们的模型比竞争基准在法语语法Gap-filling exercise generation任务上表现更好，同时只需对部分数据进行标注。

    Since performing exercises (including, e.g., practice tests) forms a crucial component of learning, and creating such exercises requires non-trivial effort from the teacher. There is a great value in automatic exercise generation in digital tools in education. In this paper, we particularly focus on automatic creation of gapfilling exercises for language learning, specifically grammar exercises. Since providing any annotation in this domain requires human expert effort, we aim to avoid it entirely and explore the task of converting existing texts into new gap-filling exercises, purely based on an example exercise, without explicit instruction or detailed annotation of the intended grammar topics. We contribute (i) a novel neural network architecture specifically designed for aforementioned gap-filling exercise generation task, and (ii) a real-world benchmark dataset for French grammar. We show that our model for this French grammar gap-filling exercise generation outperforms a competit
    
[^8]: EmoUS: 在任务导向对话中模拟用户情感

    EmoUS: Simulating User Emotions in Task-Oriented Dialogues. (arXiv:2306.01579v1 [cs.CL])

    [http://arxiv.org/abs/2306.01579](http://arxiv.org/abs/2306.01579)

    EmoUS是一种用户模拟器，可以模拟用户在任务导向对话中的行为和情感反应，通过分析用户情感与系统行为的关系来评价不同对话系统的效果。

    

    现有的任务导向对话系统用户模拟器 (USs) 仅在语义和自然语言层面上模拟用户行为，而不考虑用户角色和情感。通过优化与各种情感状态驱动的多样化用户行为有关的通用用户策略，可能会导致在实际部署时高失效率。因此，我们提出了 EmoUS，这是一种可以学习在用户行为中模拟用户情感的用户模拟器。EmoUS 基于用户目标、对话历史和用户角色生成用户情感、语义动作和自然语言回复。通过分析什么样的系统行为引起什么样的用户情感，我们展示了 EmoUS 能够被用作探测器来评估各种对话系统，尤其是它们对用户情感状态的影响。在大型语言模型聊天机器人和不断增长的伦理关切的时代，开发这种方法非常重要。

    Existing user simulators (USs) for task-oriented dialogue systems only model user behaviour on semantic and natural language levels without considering the user persona and emotions. Optimising dialogue systems with generic user policies, which cannot model diverse user behaviour driven by different emotional states, may result in a high drop-off rate when deployed in the real world. Thus, we present EmoUS, a user simulator that learns to simulate user emotions alongside user behaviour. EmoUS generates user emotions, semantic actions, and natural language responses based on the user goal, the dialogue history, and the user persona. By analysing what kind of system behaviour elicits what kind of user emotions, we show that EmoUS can be used as a probe to evaluate a variety of dialogue systems and in particular their effect on the user's emotional state. Developing such methods is important in the age of large language model chat-bots and rising ethical concerns.
    
[^9]: 比较组合模型和链式模型来定位最近的视觉对象

    Comparing a composite model versus chained models to locate a nearest visual object. (arXiv:2306.01551v1 [cs.CL])

    [http://arxiv.org/abs/2306.01551](http://arxiv.org/abs/2306.01551)

    该研究比较了两种架构（链式模型和组合模型）在定位最近的视觉对象方面的表现，结果显示两种架构的均方根误差（RMSE）都相同，但当任务可以分解成子任务时，链式架构的训练速度提高了12倍。

    

    从地理图像和文本中提取信息对于自动驾驶车辆事先确定沿其未来路径连接到的最佳小区站点至关重要。多个人工神经网络模型可以解决这个挑战，但对于此类用例的选择适当模型没有明确定义的指导意见。因此，我们试验了两种架构来解决这样的任务：第一种链式模型架构，其中链中的每个模型都处理任务的子任务; 第二种是单个模型架构，可处理整个任务。我们的结果表明，这两种架构的表现水平相同，均为0.055和0.056的均方根误差(RMSE)；研究结果进一步显示，当任务可以分解成子任务时，链式架构的训练速度比组合模型提高了12倍。然而，组合模型显著减轻了用户在配置链式模型时的负担。

    Extracting information from geographic images and text is crucial for autonomous vehicles to determine in advance the best cell stations to connect to along their future path. Multiple artificial neural network models can address this challenge; however, there is no definitive guidance on the selection of an appropriate model for such use cases. Therefore, we experimented two architectures to solve such a task: a first architecture with chained models where each model in the chain addresses a sub-task of the task; and a second architecture with a single model that addresses the whole task. Our results showed that these two architectures achieved the same level performance with a root mean square error (RMSE) of 0.055 and 0.056; The findings further revealed that when the task can be decomposed into sub-tasks, the chain architecture exhibits a twelve-fold increase in training speed compared to the composite model. Nevertheless, the composite model significantly alleviates the burden of 
    
[^10]: 利用符合性预测分布评估机器翻译质量

    Evaluating Machine Translation Quality with Conformal Predictive Distributions. (arXiv:2306.01549v1 [cs.CL])

    [http://arxiv.org/abs/2306.01549](http://arxiv.org/abs/2306.01549)

    本文提出一种利用符合性预测分布评估机器翻译质量的新方法，同时评估翻译质量并提供可靠的置信度得分，在六种不同的语言对上的实验结果表明其优于基线方法，需要数据可交换性假设才能实现最佳性能。

    

    本文提出了一种新的方法，通过同时评估翻译质量并提供可靠的置信度得分，来评估机器翻译中的不确定性。我们的方法利用符合性预测分布来产生具有保证覆盖率的预测区间，这意味着对于任何给定的显著性水平$\epsilon$，我们可以期望一个翻译的真实质量得分以$1-\epsilon$的速率落在区间内。在本文中，我们展示了我们的方法如何在六种不同的语言对上，在覆盖率和锐度方面优于简单但有效的基线。此外，我们验证了我们的方法需要数据可交换性假设才能实现最佳性能。

    This paper presents a new approach for assessing uncertainty in machine translation by simultaneously evaluating translation quality and providing a reliable confidence score. Our approach utilizes conformal predictive distributions to produce prediction intervals with guaranteed coverage, meaning that for any given significance level $\epsilon$, we can expect the true quality score of a translation to fall out of the interval at a rate of $1-\epsilon$. In this paper, we demonstrate how our method outperforms a simple, but effective baseline on six different language pairs in terms of coverage and sharpness. Furthermore, we validate that our approach requires the data exchangeability assumption to hold for optimal performance.
    
[^11]: PassGPT: 大语言模型中的密码建模和（引导式）生成

    PassGPT: Password Modeling and (Guided) Generation with Large Language Models. (arXiv:2306.01545v1 [cs.CL])

    [http://arxiv.org/abs/2306.01545](http://arxiv.org/abs/2306.01545)

    本研究使用大型语言模型PassGPT进行密码建模和生成，该模型比基于GAN的现有方法更准确，能生成符合任意限制的密码，为提高密码强度估计器提供了潜在的帮助。

    

    大语言模型（LLMs）可以成功地模拟自然语言，无需明确的监督，仅通过大量的文本进行训练。本文研究了LLMs在建模密码方面的有效性。我们介绍了PassGPT，它是一个在密码泄露数据上进行训练的LLM，用于生成密码。PassGPT通过猜测两倍于基于生成性对抗网络（GAN）的现有方法中的以前未见过的密码而胜过其它方法。此外，我们介绍了引导式密码生成的概念，利用PassGPT的抽样过程生成符合任意限制的密码，这在当前基于GAN的策略中是缺乏的。最后，我们对PassGPT对密码定义的熵和概率分布进行了深入分析，并讨论了其在增强现有密码强度估计器中的应用。

    Large language models (LLMs) successfully model natural language from vast amounts of text without the need for explicit supervision. In this paper, we investigate the efficacy of LLMs in modeling passwords. We present PassGPT, a LLM trained on password leaks for password generation. PassGPT outperforms existing methods based on generative adversarial networks (GAN) by guessing twice as many previously unseen passwords. Furthermore, we introduce the concept of guided password generation, where we leverage PassGPT sampling procedure to generate passwords matching arbitrary constraints, a feat lacking in current GAN-based strategies. Lastly, we conduct an in-depth analysis of the entropy and probability distribution that PassGPT defines over passwords and discuss their use in enhancing existing password strength estimators.
    
[^12]: BabySLM: 自我监督口语语言模型的语言习得友好型基准

    BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models. (arXiv:2306.01506v1 [cs.CL])

    [http://arxiv.org/abs/2306.01506](http://arxiv.org/abs/2306.01506)

    本文提出了一种语言习得友好型基准，以检验自我监督口语语言模型在儿童词汇和句法经历中的表现，并提出了两个需要解决的挑战：文本和语音之间的差距和干净语音和野外语音之间的差距。

    

    已经证明，学习语音表示的自我监督技术能够从听到的语音中发展出语言能力，而无需人类标签。为了充分发挥这些方法的潜力并进一步了解婴儿学习语言的方式，模拟必须紧密模仿现实情况，通过在开发上符合儿童语言经验典型词汇库和对应测试集进行基准测试。为此，我们提出了一种用于检测在词汇和句法层面上的口语语言模型的语言习得友好型基准。本文介绍了此基准，并总结了一系列实验，证明其有用性。此外，我们还强调了需要解决的两个挑战：填补文本和语音之间以及干净语音和野外语音之间的差距。

    Self-supervised techniques for learning speech representations have been shown to develop linguistic competence from exposure to speech without the need for human labels. In order to fully realize the potential of these approaches and further our understanding of how infants learn language, simulations must closely emulate real-life situations by training on developmentally plausible corpora and benchmarking against appropriate test sets. To this end, we propose a language-acquisition-friendly benchmark to probe spoken language models at the lexical and syntactic levels, both of which are compatible with the vocabulary typical of children's language experiences. This paper introduces the benchmark and summarizes a range of experiments showing its usefulness. In addition, we highlight two exciting challenges that need to be addressed for further progress: bridging the gap between text and speech and between clean speech and in-the-wild speech.
    
[^13]: 在对话情感识别中使用监督式对抗性对比学习

    Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations. (arXiv:2306.01505v1 [cs.CL])

    [http://arxiv.org/abs/2306.01505](http://arxiv.org/abs/2306.01505)

    本文提出了一种监督式对抗性对比学习（SACL）框架，用于学习类别分布结构表示，通过联合类别分布对比学习目标，有效利用标签级特性一致性并保留细粒度的类内特性，实现了在对话情感识别中最先进的结果。

    

    情感识别在对话中是提取泛化和稳健表示的一个重要挑战。为了解决这个问题，本文提出了一种监督式对抗性对比学习（SACL）框架，用于学习类别分布结构表示。该框架应用于对比感知对抗性训练以生成最坏情况的样本，并在原始和对抗样本上使用联合类别分布对比学习目标。它可以有效地利用标签级特性一致性并保留细粒度的类内特性。为了避免对上下文相关数据产生负面影响，我们设计了一个上下文对抗性训练策略，从上下文中学习更多不同的特征，并增强模型对上下文的容错性。在该框架下，我们开发了一个基于序列的方法SACL-LSTM，用于学习针对ERC的标签一致和上下文稳健的情感特征。在三个数据集上的实验证明，SACL-LSTM在对话情感识别方面实现了最先进的结果，优于现有的方法。

    Extracting generalized and robust representations is a major challenge in emotion recognition in conversations (ERC). To address this, we propose a supervised adversarial contrastive learning (SACL) framework for learning class-spread structured representations. The framework applies contrast-aware adversarial training to generate worst-case samples and uses a joint class-spread contrastive learning objective on both original and adversarial samples. It can effectively utilize label-level feature consistency and retain fine-grained intra-class features. To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training strategy to learn more diverse features from context and enhance the model's context robustness. We develop a sequence-based method SACL-LSTM under this framework, to learn label-consistent and context-robust emotional features for ERC. Experiments on three datasets demonstrate that SACL-LSTM achieves state-of
    
[^14]: LLMs（如GPT-4）在痴呆症诊断中能否胜过传统AI工具？或许有潜力，但现在还不行。

    Can LLMs like GPT-4 outperform traditional AI tools in dementia diagnosis? Maybe, but not today. (arXiv:2306.01499v1 [cs.CL])

    [http://arxiv.org/abs/2306.01499](http://arxiv.org/abs/2306.01499)

    本文探讨了LLMs如GPT-4在痴呆症诊断上的潜力，发现目前还无法胜过传统AI工具。

    

    最近的研究表明，大型语言模型（LLMs），特别是GPT-4，在常见的自然语言处理（NLP）任务上具有卓越的能力，还在各种专业和学术基准测试中展现出接近人类水平的性能。然而，GPT-4是否能直接用于实际应用，并替代专业领域中的传统人工智能（AI）工具，需要进一步的实验验证。本文探讨了LLMs（如GPT-4）在痴呆症诊断上胜过传统AI工具的潜力。通过对比两种工具在临床环境中的诊断准确性，全面探究了GPT-4和传统AI工具的优缺点。两个真实临床数据集上的实验结果表明，尽管像GPT-4这样的LLMs在未来的痴呆症诊断中具有潜力，但目前仍无法超过传统AI工具的性能表现。同时，本文还评估了GPT-4的解释性和可信性，同时也指出了将LLMs集成到医疗应用中面临的挑战。

    Recent investigations show that large language models (LLMs), specifically GPT-4, not only have remarkable capabilities in common Natural Language Processing (NLP) tasks but also exhibit human-level performance on various professional and academic benchmarks. However, whether GPT-4 can be directly used in practical applications and replace traditional artificial intelligence (AI) tools in specialized domains requires further experimental validation. In this paper, we explore the potential of LLMs such as GPT-4 to outperform traditional AI tools in dementia diagnosis. Comprehensive comparisons between GPT-4 and traditional AI tools are conducted to examine their diagnostic accuracy in a clinical setting. Experimental results on two real clinical datasets show that, although LLMs like GPT-4 demonstrate potential for future advancements in dementia diagnosis, they currently do not surpass the performance of traditional AI tools. The interpretability and faithfulness of GPT-4 are also eval
    
[^15]: 使用CamemBERTa实现高效的法语语言建模

    Data-Efficient French Language Modeling with CamemBERTa. (arXiv:2306.01497v1 [cs.CL])

    [http://arxiv.org/abs/2306.01497](http://arxiv.org/abs/2306.01497)

    本文介绍了一种名为CamemBERTa的法语DeBERTa模型，相对于使用MLM训练的BERT-based模型，在相同数量的训练令牌下性能更加优秀，在多项法语下游任务中已经达到甚至超过了CamemBERT。

    

    最新的自然语言处理领域的研究大大提高了语言模型在多种任务上的表现。虽然这些进展很大程度上是由于大量的数据和计算能力的可用性所推动，但它们也受益于更好的训练方法和架构的开发。本文介绍了一种CamemBERTa模型，它是一种法语DeBERTa模型，基于DeBERTaV3的架构和训练目标。作者在多个法语下游任务和数据集上评估了我们模型的性能，包括问答、词性标注、依存解析、命名实体识别和FLUE基准，并与法语最先进的单语模型CamemBERT进行了比较。结果显示，给定相同数量的训练令牌，本模型在大多数任务中优于以MLM训练的BERT-based模型。此外，本模型在下游任务中达到了与CamemBERT相似或更优的性能，尽管它是新模型。

    Recent advances in NLP have significantly improved the performance of language models on a variety of tasks. While these advances are largely driven by the availability of large amounts of data and computational power, they also benefit from the development of better training methods and architectures. In this paper, we introduce CamemBERTa, a French DeBERTa model that builds upon the DeBERTaV3 architecture and training objective. We evaluate our model's performance on a variety of French downstream tasks and datasets, including question answering, part-of-speech tagging, dependency parsing, named entity recognition, and the FLUE benchmark, and compare against CamemBERT, the state-of-the-art monolingual model for French. Our results show that, given the same amount of training tokens, our model outperforms BERT-based models trained with MLM on most tasks. Furthermore, our new model reaches similar or superior performance on downstream tasks compared to CamemBERT, despite being trained 
    
[^16]: Hugging Face和Pyserini互操作性在NLP训练数据探索中的应用

    GAIA Search: Hugging Face and Pyserini Interoperability for NLP Training Data Exploration. (arXiv:2306.01481v1 [cs.CL])

    [http://arxiv.org/abs/2306.01481](http://arxiv.org/abs/2306.01481)

    本文提出将信息检索领域的方法与开源AI库Hugging Face和Pyserini工具集相结合，以提供一种用于NLP研究者的检索式数据分析的可靠工具。

    

    我们注意到迫切需要为现代NLP的大规模文本语料库提供快速和用户友好的定性分析工具，因此提出利用信息检索（IR）领域的成熟和经过充分测试的方法 - 这是一个长期处理TB级文档集合的研究领域。我们讨论了如何集成Pyserini - 一种广泛使用的可重复IR研究工具包与开源AI库和人工智能文档生态系统Hugging Face。我们利用两个平台的现有功能，同时提出新功能，进一步促进它们的集成。我们的目标是为NLP研究人员提供工具，以便他们可以轻松灵活地开发基于检索的数据分析工具。我们通过基于Jupyter Notebook的演示步骤，展示了核心互操作特性的可用性，该演示步骤可以在GitHub上http s://github.com/huggingface/gaia上找到。然后，我们演示了我们提出的想法如何被操作化。

    Noticing the urgent need to provide tools for fast and user-friendly qualitative analysis of large-scale textual corpora of the modern NLP, we propose to turn to the mature and well-tested methods from the domain of Information Retrieval (IR) - a research field with a long history of tackling TB-scale document collections. We discuss how Pyserini - a widely used toolkit for reproducible IR research can be integrated with the Hugging Face ecosystem of open-source AI libraries and artifacts. We leverage the existing functionalities of both platforms while proposing novel features further facilitating their integration. Our goal is to give NLP researchers tools that will allow them to develop retrieval-based instrumentation for their data analytics needs with ease and agility. We include a Jupyter Notebook-based walk through the core interoperability features, available on GitHub at https://github.com/huggingface/gaia. We then demonstrate how the ideas we present can be operationalized to
    
[^17]: 基于语法的文本隐私保护方法

    Guiding Text-to-Text Privatization by Syntax. (arXiv:2306.01471v1 [cs.CL])

    [http://arxiv.org/abs/2306.01471](http://arxiv.org/abs/2306.01471)

    该论文介绍了一种基于语法的文本隐私保护方法，通过解决候选选择问题以提高替换的句法一致性。

    

    指标差分隐私是针对文本隐私保护中的独特挑战而设计的差分隐私的一种扩展。通过向嵌入的几何空间中的单词表示添加噪声，单词被替换为在噪声表示的接近位置的单词。由于嵌入式是基于单词共现进行训练的，因此这种机制确保替换源于相同的语义环境。然而，如果不考虑单词的语法类别，这种机制就无法保证替换扮演相似的句法角色。我们分析了文本隐私保护在替换后保留单词语法类别的能力，并发现代用文本中几乎完全由名词构成。由于缺少产生与敏感文本结构相关的代用文本的能力，我们通过将保护步骤转换为候选选择问题来扩展我们的分析。

    Metric Differential Privacy is a generalization of differential privacy tailored to address the unique challenges of text-to-text privatization. By adding noise to the representation of words in the geometric space of embeddings, words are replaced with words located in the proximity of the noisy representation. Since embeddings are trained based on word co-occurrences, this mechanism ensures that substitutions stem from a common semantic context. Without considering the grammatical category of words, however, this mechanism cannot guarantee that substitutions play similar syntactic roles. We analyze the capability of text-to-text privatization to preserve the grammatical category of words after substitution and find that surrogate texts consist almost exclusively of nouns. Lacking the capability to produce surrogate texts that correlate with the structure of the sensitive texts, we encompass our analysis by transforming the privatization step into a candidate selection problem in whic
    
[^18]: 带有分层话语特征的俄语轻量级指代消解

    Light Coreference Resolution for Russian with Hierarchical Discourse Features. (arXiv:2306.01465v1 [cs.CL])

    [http://arxiv.org/abs/2306.01465](http://arxiv.org/abs/2306.01465)

    本篇论文提出了一种通过收集自动话语分析的修辞特征来将修辞信息纳入神经指代消解模型的新方法，并取得了俄语RuCoCo-23共享任务中的最好成绩。

    

    指代消解是识别和分组指称同一现实世界实体的任务。以往神经模型主要集中于学习跨度表示和配对得分以进行指代消解。然而，目前的方法没有明确捕捉到层级话语中的指称选择，这是指代消解中的重要因素。本研究提出了一种新的方法，将修辞信息纳入神经指代消解模型中，收集自动话语分析的修辞特征并检查其影响。作为基线模型，我们使用部分微调的多语言实体感知语言模型LUKE实现了端到端的基于跨度的指代消解解析器。我们在俄语的RuCoCo-23共享任务中评估了我们的方法。我们最佳模型采用了提及之间的修辞距离，并在开发集（74.6％ F1）上排名第1，在测试集（73.3％ F1）上排名第2。

    Coreference resolution is the task of identifying and grouping mentions referring to the same real-world entity. Previous neural models have mainly focused on learning span representations and pairwise scores for coreference decisions. However, current methods do not explicitly capture the referential choice in the hierarchical discourse, an important factor in coreference resolution. In this study, we propose a new approach that incorporates rhetorical information into neural coreference resolution models. We collect rhetorical features from automated discourse parses and examine their impact. As a base model, we implement an end-to-end span-based coreference resolver using a partially fine-tuned multilingual entity-aware language model LUKE. We evaluate our method on the RuCoCo-23 Shared Task for coreference resolution in Russian. Our best model employing rhetorical distance between mentions has ranked 1st on the development set (74.6% F1) and 2nd on the test set (73.3% F1) of the Sh
    
[^19]: 将上下文纳入文本-文本隐私保护中

    Driving Context into Text-to-Text Privatization. (arXiv:2306.01457v1 [cs.CL])

    [http://arxiv.org/abs/2306.01457](http://arxiv.org/abs/2306.01457)

    本文介绍了一种度量差分隐私机制，该机制在注入噪声之前加入了一个语义消歧步骤以提高歧义单词替代的有效性，并展示了在“上下文中的单词”数据集上的有效性。

    

    “度量差分隐私”通过向从嵌入空间中导出的单词向量添加经过校准的噪声，并使用最近邻搜索将这些有噪声的向量投影回离散词汇，从而实现了文本到文本的隐私保护功能。由于单词是没有上下文的替代，因此该机制可能无法找到具有歧义含义的单词的替代词，例如“bank”。为了解决这些模棱两可的单词，我们利用了一种语义嵌入并在注入噪声之前加入了一个语义消歧步骤。我们还估计了隐私和实用性对隐私保护机制的修改。在“上下文中的单词”数据集上进行的单词义消歧试验中，我们证明了分类准确度的显著增加，达到了$6.05％$。

    \textit{Metric Differential Privacy} enables text-to-text privatization by adding calibrated noise to the vector of a word derived from an embedding space and projecting this noisy vector back to a discrete vocabulary using a nearest neighbor search. Since words are substituted without context, this mechanism is expected to fall short at finding substitutes for words with ambiguous meanings, such as \textit{'bank'}. To account for these ambiguous words, we leverage a sense embedding and incorporate a sense disambiguation step prior to noise injection. We encompass our modification to the privatization mechanism with an estimation of privacy and utility. For word sense disambiguation on the \textit{Words in Context} dataset, we demonstrate a substantial increase in classification accuracy by $6.05\%$.
    
[^20]: 无监督情感触发词抽取式摘要

    Unsupervised Extractive Summarization of Emotion Triggers. (arXiv:2306.01444v1 [cs.CL])

    [http://arxiv.org/abs/2306.01444](http://arxiv.org/abs/2306.01444)

    本文介绍了一个无监督的系统，能够从文本中提取情感触发器并总结它们，以取代耗时昂贵的摘要生成过程，为灾难响应提供必要信息。

    

    在大型危机事件中理解导致情绪产生的因素很重要，因为这可以为表达的情感提供基础，并随后改善对正在发生的灾害的理解。最近的方法训练了监督模型，通过摘要提取来检测情感和解释情感触发器（事件和评估）。然而，在时间敏感、高风险的情境下，获取及时和优质的摘要非常昂贵且耗时，需要经过高度训练的专家注释者。在这种情况下，这可能会阻碍必要的响应。我们转而追求从文本中提取触发器的无监督系统。首先，我们引入 CovidET-EXT 数据集，扩充了（Zhan 等人，2022）在 COVID-19 危机背景下的摘要数据集。其次，我们开发了新的无监督学习模型，可以共同检测情感并总结它们的触发器。我们最好的方法是 Emotion-Aware Pagerank，它从文本中提取情感信息。

    Understanding what leads to emotions during large-scale crises is important as it can provide groundings for expressed emotions and subsequently improve the understanding of ongoing disasters. Recent approaches trained supervised models to both detect emotions and explain emotion triggers (events and appraisals) via abstractive summarization. However, obtaining timely and qualitative abstractive summaries is expensive and extremely time-consuming, requiring highly-trained expert annotators. In time-sensitive, high-stake contexts, this can block necessary responses. We instead pursue unsupervised systems that extract triggers from text. First, we introduce CovidET-EXT, augmenting (Zhan et al. 2022)'s abstractive dataset (in the context of the COVID-19 crisis) with extractive triggers. Second, we develop new unsupervised learning models that can jointly detect emotions and summarize their triggers. Our best approach, entitled Emotion-Aware Pagerank, incorporates emotion information from 
    
[^21]: 无监督的多词表达改写方法研究

    Unsupervised Paraphrasing of Multiword Expressions. (arXiv:2306.01443v1 [cs.CL])

    [http://arxiv.org/abs/2306.01443](http://arxiv.org/abs/2306.01443)

    本文提出了一种无监督的多词表达式改写方法，使用的数据和工具非常简单，且实验结果表明，该方法在熟语语义文本相似度任务中性能良好。

    

    我们提出了一种无监督的改写多词表达式（MWEs）的方法，只使用单语料库数据和预训练语言模型（无需微调），不使用任何外部资源，如字典。我们在SemEval 2022熟语语义文本相似度任务上评估了我们的方法，并表明它优于所有无监督系统并与有监督系统相匹敌。

    We propose an unsupervised approach to paraphrasing multiword expressions (MWEs) in context. Our model employs only monolingual corpus data and pre-trained language models (without fine-tuning), and does not make use of any external resources such as dictionaries. We evaluate our method on the SemEval 2022 idiomatic semantic text similarity task, and show that it outperforms all unsupervised systems and rivals supervised systems.
    
[^22]: 通过建模残差多模态实现鲁棒的FastSpeech 2

    Towards Robust FastSpeech 2 by Modelling Residual Multimodality. (arXiv:2306.01442v1 [cs.SD])

    [http://arxiv.org/abs/2306.01442](http://arxiv.org/abs/2306.01442)

    该论文提出了一种名为TVC-GMM的三元链式高斯分布混合模型，用于解决FastSpeech 2合成表现性语音数据集时可能出现的Mel频谱平滑度差的问题，可以提高音频的听觉质量。

    

    基于FastSpeech 2的非自回归语音合成模型可以高效地合成高保真度和自然度的语音，但对于表现性语音数据集，我们观察到了特征音频失真。我们证明，这些伪影是由于过度平滑的Mel频谱预测引入的，而这是由于使用均方误差（MSE）损失来训练Mel频谱解码器所致。FastSpeech 2使用MSE损失被限制为学习训练分布的条件平均值，如果所有的调制信号后分布仍然呈现多模态分布，则这些值可能与自然样本并不接近。为了缓解这个问题，我们引入了TVC-GMM，这是一种三元链式高斯分布混合模型，用于模拟残差多模态。TVC-GMM降低了频谱的平滑性，并通过客观和主观评估证明了对表现性数据集特别有效，从而提高了听觉音频质量。

    State-of-the-art non-autoregressive text-to-speech (TTS) models based on FastSpeech 2 can efficiently synthesise high-fidelity and natural speech. For expressive speech datasets however, we observe characteristic audio distortions. We demonstrate that such artefacts are introduced to the vocoder reconstruction by over-smooth mel-spectrogram predictions, which are induced by the choice of mean-squared-error (MSE) loss for training the mel-spectrogram decoder. With MSE loss FastSpeech 2 is limited to learn conditional averages of the training distribution, which might not lie close to a natural sample if the distribution still appears multimodal after all conditioning signals. To alleviate this problem, we introduce TVC-GMM, a mixture model of Trivariate-Chain Gaussian distributions, to model the residual multimodality. TVC-GMM reduces spectrogram smoothness and improves perceptual audio quality in particular for expressive datasets as shown by both objective and subjective evaluation.
    
[^23]: 通过神经引导符号抽象实现可解释和可解释逻辑策略

    Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction. (arXiv:2306.01439v1 [cs.LG])

    [http://arxiv.org/abs/2306.01439](http://arxiv.org/abs/2306.01439)

    该论文介绍了一种名为NUDGE的策略，利用训练好的基于神经网络的代理来引导逻辑规则的搜索，实现了可解释和可解释的策略。

    

    神经网络所需要的有限先验使其成为使用强化学习（RL）编码和学习策略的主要选择。然而，它们也是黑匣子，在工作在图像级别时难以理解代理行为。因此，神经符号RL旨在首先创建可解释的策略。不幸的是，可解释性不意味着可解释性。为了实现解释性和可解释性，我们引入了神经引导可微分逻辑策略（NUDGE）。NUDGE利用训练好的基于神经网络的代理来引导候选加权逻辑规则的搜索，然后使用可微分的逻辑来训练逻辑代理。我们的实验评估表明，NUDGE代理可以产生可解释和可解释的策略，同时胜过纯神经代理，并展现出良好的灵活性，以适应不同初始状态和问题大小的环境。

    The limited priors required by neural networks make them the dominating choice to encode and learn policies using reinforcement learning (RL). However, they are also black-boxes, making it hard to understand the agent's behaviour, especially when working on the image level. Therefore, neuro-symbolic RL aims at creating policies that are interpretable in the first place. Unfortunately, interpretability is not explainability. To achieve both, we introduce Neurally gUided Differentiable loGic policiEs (NUDGE). NUDGE exploits trained neural network-based agents to guide the search of candidate-weighted logic rules, then uses differentiable logic to train the logic agents. Our experimental evaluation demonstrates that NUDGE agents can induce interpretable and explainable policies while outperforming purely neural ones and showing good flexibility to environments of different initial states and problem sizes.
    
[^24]: 实体和数字值的知识图谱推理

    Knowledge Graph Reasoning over Entities and Numerical Values. (arXiv:2306.01399v1 [cs.AI])

    [http://arxiv.org/abs/2306.01399](http://arxiv.org/abs/2306.01399)

    本文提出了一种新方法，将数值推理纳入知识图谱推理，将数值视为一等公民并提供了一个统一的框架，用于对实体和数值进行推理，实现了对复杂查询的有效和高效回答。

    

    知识图谱中的复杂逻辑查询指的是以逻辑形式表达的查询，传达复杂的含义，比如加拿大的图灵奖得主毕业于哪里？基于知识图谱推理的应用程序，例如对话系统和交互式搜索引擎，依赖于回答复杂逻辑查询作为基本任务的能力。在大多数知识图谱中，边缘通常用于描述实体之间的关系或它们的关联属性值。属性值可以是分类或数值格式，例如日期、年份、尺寸等。然而，现有的复杂查询答案（CQA）方法仅将数值与实体视为相同。这可能会导致回答某些查询的困难，例如哪个澳大利亚的普利策奖得主出生于1927年之前，哪种药物是一种止痛剂，并且副作用比布洛芬更少。本文受到数值编码最近的进展的启发，提出了一种将数值推理纳入知识图谱推理的新方法。我们的方法将数值视为一等公民，并提供了一个统一的框架，用于对实体和数值进行推理。我们在两个基准数据集WIKWD和WebQSP上进行了广泛的实验，证明了我们所提出的方法在回答涉及数值的复杂查询方面的有效性和效率。

    A complex logic query in a knowledge graph refers to a query expressed in logic form that conveys a complex meaning, such as where did the Canadian Turing award winner graduate from? Knowledge graph reasoning-based applications, such as dialogue systems and interactive search engines, rely on the ability to answer complex logic queries as a fundamental task. In most knowledge graphs, edges are typically used to either describe the relationships between entities or their associated attribute values. An attribute value can be in categorical or numerical format, such as dates, years, sizes, etc. However, existing complex query answering (CQA) methods simply treat numerical values in the same way as they treat entities. This can lead to difficulties in answering certain queries, such as which Australian Pulitzer award winner is born before 1927, and which drug is a pain reliever and has fewer side effects than Paracetamol. In this work, inspired by the recent advances in numerical encoding
    
[^25]: NMT中基于子词的分词中，频率和组合性的重要性评估

    Assessing the Importance of Frequency versus Compositionality for Subword-based Tokenization in NMT. (arXiv:2306.01393v1 [cs.CL])

    [http://arxiv.org/abs/2306.01393](http://arxiv.org/abs/2306.01393)

    本文通过实验发现，在NMT中基于子词的分词方法中，频率对于模型的表现贡献占据了90%-95%，因此相对于组合性，频率更为重要。

    

    子词分词是神经语言模型和机器翻译系统中的默认标准。频繁引用子词的优点有：对频繁词语进行更短编码，子词组合性强以及处理未知词语的能力。然而，它们的相对重要性尚不太清楚。本文提出了一种分词方法，可以将频率（第一个优点）与组合性分离开来，使用霍夫曼编码对单词进行分词，按频率顺序，使用固定数量的符号。实验表明，在CS-DE、EN-FR和EN-DE NMT中，仅频率就占了BPE得分的90%-95%，因此组合性并不像以前认为的那么重要。

    Subword tokenization is the de facto standard for tokenization in neural language models and machine translation systems. Three advantages are frequently cited in favor of subwords: shorter encoding of frequent tokens, compositionality of subwords, and ability to deal with unknown words. As their relative importance is not entirely clear yet, we propose a tokenization approach that enables us to separate frequency (the first advantage) from compositionality. The approach uses Huffman coding to tokenize words, by order of frequency, using a fixed amount of symbols. Experiments with CS-DE, EN-FR and EN-DE NMT show that frequency alone accounts for 90%-95% of the scores reached by BPE, hence compositionality has less importance than previously thought.
    
[^26]: 面向零-shot对话状态跟踪的ChatGPT: 解决方案还是机会？

    ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?. (arXiv:2306.01386v1 [cs.CL])

    [http://arxiv.org/abs/2306.01386](http://arxiv.org/abs/2306.01386)

    该论文介绍了面向零-shot对话状态跟踪的ChatGPT，该方法在初步实验中表现出最先进的性能。然而，通用模型的固有特性限制了其替代专用系统的能力，但其上下文学习能力有望成为开发专用和动态对话状态跟踪器的强大工具。

    

    最近关于对话状态跟踪（DST）的研究专注于允许少量和零-shot转移到新领域或模式的方法。然而，性能提升严重依赖于积极的数据增强和基于越来越大的语言模型的微调。相比之下，通用语言模型在大量多样化数据的基础上训练，承诺可以解决任何类型的任务而无需特定的训练。我们在ChatGPT研究预览中呈现了初步实验结果，表明ChatGPT在零-shot DST中实现了最先进的性能。尽管我们的发现如此，但我们认为通用模型固有的特性限制了它们替换专用系统的能力。我们进一步推测，这种模型的上下文学习能力可能成为支持专门和动态对话状态跟踪器开发的强大工具。

    Recent research on dialogue state tracking (DST) focuses on methods that allow few- and zero-shot transfer to new domains or schemas. However, performance gains heavily depend on aggressive data augmentation and fine-tuning of ever larger language model based architectures. In contrast, general purpose language models, trained on large amounts of diverse data, hold the promise of solving any kind of task without task-specific training. We present preliminary experimental results on the ChatGPT research preview, showing that ChatGPT achieves state-of-the-art performance in zero-shot DST. Despite our findings, we argue that properties inherent to general purpose models limit their ability to replace specialized systems. We further theorize that the in-context learning capabilities of such models will likely become powerful tools to support the development of dedicated and dynamic dialogue state trackers.
    
[^27]: 面向任务无关的语音表示模型结构剪枝

    Task-Agnostic Structured Pruning of Speech Representation Models. (arXiv:2306.01385v1 [eess.AS])

    [http://arxiv.org/abs/2306.01385](http://arxiv.org/abs/2306.01385)

    本文提出了一种精细的注意力头剪枝方法和Straight-Through Estimator，用于加速模型剪枝，以解决自监督的预训练模型的大内存和强计算需求问题。在实验中表明，该模型可以在任务中取得很好的性能且参数减少且推理速度提高。

    

    自监督的预训练模型如Wav2vec2、Hubert和WavLM已被证明能显著提高许多语音任务的性能。然而，它们庞大的内存和强大的计算需求阻碍了它们的工业应用。结构化剪枝是一种硬件友好的模型压缩技术，但通常会导致更大的精度损失。本文提出了一种精细的注意力头剪枝方法来弥补性能下降。此外，我们还在L0规则化中引入了Straight-Through Estimator来进一步加速剪枝模型。在SUPERB基准上的实验证明，我们的模型可以在多个任务上达到与密集模型相当的性能，并且平均优于Wav2vec 2.0基准模型，同时参数减少72％，推理速度提高2倍。

    Self-supervised pre-trained models such as Wav2vec2, Hubert, and WavLM have been shown to significantly improve many speech tasks. However, their large memory and strong computational requirements hinder their industrial applicability. Structured pruning is a hardware-friendly model compression technique but usually results in a larger loss of accuracy. In this paper, we propose a fine-grained attention head pruning method to compensate for the performance degradation. In addition, we also introduce the straight through estimator into the L0 regularization to further accelerate the pruned model. Experiments on the SUPERB benchmark show that our model can achieve comparable performance to the dense model in multiple tasks and outperforms the Wav2vec 2.0 base model on average, with 72% fewer parameters and 2 times faster inference speed.
    
[^28]: 利用辅助领域平行数据在中间任务微调中实现低资源翻译

    Leveraging Auxiliary Domain Parallel Data in Intermediate Task Fine-tuning for Low-resource Translation. (arXiv:2306.01382v1 [cs.CL])

    [http://arxiv.org/abs/2306.01382](http://arxiv.org/abs/2306.01382)

    本文展示了中间任务微调(ITFT)对于低资源、多语言、多领域的NMT非常有效，能够在一定程度上缓解领域分歧的影响。

    

    当没有足够的平行数据进行微调时，基于预先训练的多语种Seq-to-Seq模型的NMT系统应用困难，特别是对于这些模型中缺失/代表性不足的语言。当数据来自不同领域时，问题进一步恶化。本文展示了中间任务微调(ITFT)对于特定领域的NMT非常有益，尤其是当目标领域的数据有限/不可用，而考虑的语言在PMSS模型中缺失或代表性不足时。我们使用领域分歧测试量化了领域特定结果的变化，并且展示了ITFT能够在一定程度上缓解领域分歧的影响。

    NMT systems trained on Pre-trained Multilingual Sequence-Sequence (PMSS) models flounder when sufficient amounts of parallel data is not available for fine-tuning. This specifically holds for languages missing/under-represented in these models. The problem gets aggravated when the data comes from different domains. In this paper, we show that intermediate-task fine-tuning (ITFT) of PMSS models is extremely beneficial for domain-specific NMT, especially when target domain data is limited/unavailable and the considered languages are missing or under-represented in the PMSS model. We quantify the domain-specific results variations using a domain-divergence test, and show that ITFT can mitigate the impact of domain divergence to some extent.
    
[^29]: 基于GPT-4的复杂数学问题求解的实证研究

    An Empirical Study on Challenging Math Problem Solving with GPT-4. (arXiv:2306.01337v1 [cs.CL])

    [http://arxiv.org/abs/2306.01337](http://arxiv.org/abs/2306.01337)

    本研究探索使用GPT-4解决更复杂和有挑战性的数学问题，提出了一种名为MathChat的对话式问题求解框架，并在困难高中竞赛问题上进行了评估。

    

    使用大型语言模型（LLM）来解决数学问题是一项有趣的研究，考虑到在各种科学和工程领域中用自然语言表达的数学问题的丰富性。虽然之前有几项工作研究了使用LLM解决初等数学问题，但本研究探索了使用GPT-4解决更复杂和有挑战性的数学问题的前沿。我们评估了使用GPT-4的各种方法。其中一些是从现有工作中改编而来的，其中一个是MathChat，这是本研究新提出的一种对话式问题求解框架。我们在来自MATH数据集的困难高中竞赛问题上进行评估，表明了所提出的对话式方法的优势。

    Employing Large Language Models (LLMs) to address mathematical problems is an intriguing research endeavor, considering the abundance of math problems expressed in natural language across numerous science and engineering fields. While several prior works have investigated solving elementary mathematics using LLMs, this work explores the frontier of using GPT-4 for solving more complex and challenging math problems. We evaluate various ways of using GPT-4. Some of them are adapted from existing work, and one is \MathChat, a conversational problem-solving framework newly proposed in this work. We perform the evaluation on difficult high school competition problems from the MATH dataset, which shows the advantage of the proposed conversational approach.
    
[^30]: 使用基础模型和最优传输的语音翻译：UPC在IWSLT23的参赛

    Speech Translation with Foundation Models and Optimal Transport: UPC at IWSLT23. (arXiv:2306.01327v1 [cs.CL])

    [http://arxiv.org/abs/2306.01327](http://arxiv.org/abs/2306.01327)

    本论文阐述了UPC机器翻译组使用基础模型和最优传输技术以及合成数据在IWSLT23离线语音翻译任务中的表现，最佳单模型在IWSLT.ACLdev2023上获得33.4分。

    

    本篇论文描述了UPC机器翻译组参加IWSLT 2023离线语音翻译任务的系统。我们使用基础模型分别处理语音（wav2vec 2.0）和文本（mBART50），通过CTC和最优传输的“联体”预训练步骤，将语音表示适应到文本模型的空间，以实现最大的迁移学习。在此预训练后，我们使用交叉熵和知识蒸馏在ST上进行端到端微调系统。除了已有的ST语料库外，我们使用SegAugment创建合成数据，以更好地适应IWSLT测试集的自定义分割。我们的最佳单模型在MuST-C tst-COMMON上获得31.2 BLEU分，IWLST.tst2020上获得29.8分，在新发布的IWSLT.ACLdev2023上获得33.4分。

    This paper describes the submission of the UPC Machine Translation group to the IWSLT 2023 Offline Speech Translation task. Our Speech Translation systems utilize foundation models for speech (wav2vec 2.0) and text (mBART50). We incorporate a Siamese pretraining step of the speech and text encoders with CTC and Optimal Transport, to adapt the speech representations to the space of the text model, thus maximizing transfer learning from MT. After this pretraining, we fine-tune our system end-to-end on ST, with Cross Entropy and Knowledge Distillation. Apart from the available ST corpora, we create synthetic data with SegAugment to better adapt our models to the custom segmentations of the IWSLT test sets. Our best single model obtains 31.2 BLEU points on MuST-C tst-COMMON, 29.8 points on IWLST.tst2020 and 33.4 points on the newly released IWSLT.ACLdev2023.
    
[^31]: LyricSIM：一种用于检测西班牙歌词相似性的新数据集和基准

    LyricSIM: A novel Dataset and Benchmark for Similarity Detection in Spanish Song LyricS. (arXiv:2306.01325v1 [cs.CL])

    [http://arxiv.org/abs/2306.01325](http://arxiv.org/abs/2306.01325)

    本文介绍了一种针对语义相似性任务的新数据集和基准，由多个本地注释者完成集体注释实验，评估了各种最先进的单语和多语言语言模型的性能，建立了基准结果。

    

    本文介绍了一个新的数据集和基准，旨在针对歌词的语义相似性任务。我们的数据集最初由2775对西班牙歌曲组成，由63个本地注释者进行集体注释实验。经过收集和精细化处理数据以确保高度的共识和数据完整性，我们获得了676个高质量的标注对，用于评估各种最先进的单语和多语言语言模型的性能。因此，我们建立了基准结果，希望这些结果对该领域未来的学术和工业应用有所帮助。

    In this paper, we present a new dataset and benchmark tailored to the task of semantic similarity in song lyrics. Our dataset, originally consisting of 2775 pairs of Spanish songs, was annotated in a collective annotation experiment by 63 native annotators. After collecting and refining the data to ensure a high degree of consensus and data integrity, we obtained 676 high-quality annotated pairs that were used to evaluate the performance of various state-of-the-art monolingual and multilingual language models. Consequently, we established baseline results that we hope will be useful to the community in all future academic and industrial applications conducted in this context.
    
[^32]: 文本风格转化的Back-Translation技术

    Text Style Transfer Back-Translation. (arXiv:2306.01318v1 [cs.CL])

    [http://arxiv.org/abs/2306.01318](http://arxiv.org/abs/2306.01318)

    本研究提出了文本风格转化的Back-Translation技术（TST BT），通过使用风格转化模型改善BT数据的源语言部分，旨在提高自然输入的翻译质量。在不同的语言对上进行实验，结果表明TST BT显著提高了翻译性能，还可以用于领域适应，是一种通用的数据增强技术。

    

    Back Translation (BT)技术被广泛应用于机器翻译领域，因为它被证明能够提高翻译质量。然而，由于BT数据的源语言部分是机器翻译的，所以BT主要改善共享相似风格输入（更具体地说，是类似翻译的输入）的翻译质量。对于自然输入，BT只能带来轻微的改进，有时甚至会带来不利的影响。为了解决这个问题，我们提出了文本风格转化的Back-Translation技术（TST BT），它使用风格转换模型来修改BT数据的源语言部分。通过使源语言部分的文本风格更自然，我们旨在改善自然输入的翻译质量。我们在不同的语言对上进行了实验，包括高资源和低资源的语言对，结果表明TST BT显著提高了翻译质量。此外，TST BT还证明在领域适应方面也非常有效，因此这种策略可以被视为一种通用的数据增强技术。

    Back Translation (BT) is widely used in the field of machine translation, as it has been proved effective for enhancing translation quality. However, BT mainly improves the translation of inputs that share a similar style (to be more specific, translation-like inputs), since the source side of BT data is machine-translated. For natural inputs, BT brings only slight improvements and sometimes even adverse effects. To address this issue, we propose Text Style Transfer Back Translation (TST BT), which uses a style transfer model to modify the source side of BT data. By making the style of source-side text more natural, we aim to improve the translation of natural inputs. Our experiments on various language pairs, including both high-resource and low-resource ones, demonstrate that TST BT significantly improves translation performance against popular BT benchmarks. In addition, TST BT is proved to be effective in domain adaptation so this strategy can be regarded as a general data augmenta
    
[^33]: 语法感知的混合提示模型用于小样本多模态情感分析

    Syntax-aware Hybrid prompt model for Few-shot multi-modal sentiment analysis. (arXiv:2306.01312v1 [cs.CL])

    [http://arxiv.org/abs/2306.01312](http://arxiv.org/abs/2306.01312)

    本文提出了一种语法感知的混合提示模型，用于多模态少样本情感分析，通过融合手工提示和可学习提示，利用注意机制优化提示编码器，显著提高了分析性能。

    

    多模态情感分析在自然语言处理中是当前一个热门话题，主要针对句子和方面级别。然而，现有方法几乎都需要大规模的标记数据集，这会带来大量的时间和资源消耗。因此，研究跨模态的少样本情感分析方法是很实用的。先前的研究主要执行在文本模式，使用基于提示的方法，主要有两种类型：手工提示和可学习提示。在小样本多模态情感分析任务中，现有方法已分别使用了这两种方法。我们进一步设计了一种混合模式，可以结合一个或多个固定的手工提示和可学习提示，并利用注意机制来优化提示编码器。在句子级和方面级数据集上的实验表明，我们得到了显着的性能提升。

    Multimodal Sentiment Analysis (MSA) has been a popular topic in natural language processing nowadays, at both sentence and aspect level. However, the existing approaches almost require large-size labeled datasets, which bring about large consumption of time and resources. Therefore, it is practical to explore the method for few-shot sentiment analysis in cross-modalities. Previous works generally execute on textual modality, using the prompt-based methods, mainly two types: hand-crafted prompts and learnable prompts. The existing approach in few-shot multi-modality sentiment analysis task has utilized both methods, separately. We further design a hybrid pattern that can combine one or more fixed hand-crafted prompts and learnable prompts and utilize the attention mechanisms to optimize the prompt encoder. The experiments on both sentence-level and aspect-level datasets prove that we get a significant outperformance.
    
[^34]: MetaVL：从语言模型向视觉-语言模型中迁移上下文学习能力

    MetaVL: Transferring In-Context Learning Ability From Language Models to Vision-Language Models. (arXiv:2306.01311v1 [cs.CL])

    [http://arxiv.org/abs/2306.01311](http://arxiv.org/abs/2306.01311)

    本文研究了如何在视觉-语言领域实现上下文学习能力，并通过在NLP任务上元训练语言模型，成功将上下文学习能力转移到VL任务上，实验结果表明，该方法具有显著优势。

    

    大规模语言模型表现出通过在少量示例上进行条件训练（即上下文学习）来适应新任务的能力。然而，在视觉-语言领域中，大多数大规模预先训练的视觉-语言（VL）模型缺乏进行上下文学习的能力。本文研究了一种有趣的假设：我们能否将语言领域的上下文学习能力转移到VL领域？具体来说，我们首先在NLP任务上元训练语言模型执行上下文学习（如MetaICL）；然后通过附加视觉编码器将此模型转移到VL任务上。我们的实验表明，的确可以跨模态地转移上下文学习能力：我们的模型显着提高了VL任务的上下文学习能力，甚至可以显著弥补模型大小的不足。在VQA、OK-VQA和GQA上，我们的方法可以超越基线模型。

    Large-scale language models have shown the ability to adapt to a new task via conditioning on a few demonstrations (i.e., in-context learning). However, in the vision-language domain, most large-scale pre-trained vision-language (VL) models do not possess the ability to conduct in-context learning. How can we enable in-context learning for VL models? In this paper, we study an interesting hypothesis: can we transfer the in-context learning ability from the language domain to VL domain? Specifically, we first meta-trains a language model to perform in-context learning on NLP tasks (as in MetaICL); then we transfer this model to perform VL tasks by attaching a visual encoder. Our experiments suggest that indeed in-context learning ability can be transferred cross modalities: our model considerably improves the in-context learning capability on VL tasks and can even compensate for the size of the model significantly. On VQA, OK-VQA, and GQA, our method could outperform the baseline model 
    
[^35]: DistilXLSR：一种轻量级跨语言语音表示模型

    DistilXLSR: A Light Weight Cross-Lingual Speech Representation Model. (arXiv:2306.01303v1 [cs.CL])

    [http://arxiv.org/abs/2306.01303](http://arxiv.org/abs/2306.01303)

    提出一种跨语言语音表示模型DistilXLSR，通过随机打乱语音中的音素，只使用英语数据来训练模型，并设计一种初始化方法，成功将参数减少50%，同时保持跨语言表达能力，适用于各种语言/教师模型并有潜力提高英语预训练模型的跨语言性能。

    

    多语言自监督语音表示模型大大提高了低资源语言的语音识别能力，而这些巨大模型的压缩也已成为其工业应用的重要前提。本文提出DistilXLSR，一种经过精简的跨语言语音表示模型。通过随机打乱已有语音中的音素，减少语言信息并仅使用英语数据来蒸馏跨语言模型。同时，我们还设计了一种跳层初始化方法，以充分利用教师预训练模型的权重。在两种教师模型和15种低资源语言上的实验表明，我们的方法可以将参数降低50%，同时保持跨语言表示能力。我们的方法已被证明适用于各种语言/教师模型，并有潜力提高英语预训练模型的跨语言性能。

    Multilingual self-supervised speech representation models have greatly enhanced the speech recognition performance for low-resource languages, and the compression of these huge models has also become a crucial prerequisite for their industrial application. In this paper, we propose DistilXLSR, a distilled cross-lingual speech representation model. By randomly shuffling the phonemes of existing speech, we reduce the linguistic information and distill cross-lingual models using only English data. We also design a layer-jumping initialization method to fully leverage the teacher's pre-trained weights. Experiments on 2 kinds of teacher models and 15 low-resource languages show that our method can reduce the parameters by 50% while maintaining cross-lingual representation ability. Our method is proven to be generalizable to various languages/teacher models and has the potential to improve the cross-lingual performance of the English pre-trained models.
    
[^36]: 带标点的端到端流式自动语音识别模型的改进训练

    Improved Training for End-to-End Streaming Automatic Speech Recognition Model with Punctuation. (arXiv:2306.01296v1 [eess.AS])

    [http://arxiv.org/abs/2306.01296](http://arxiv.org/abs/2306.01296)

    本文提出了一种使用块状Transformer编码器进行训练以实现标点预测的方法，并通过联合使用块和话语的CTC损失来获得较好的预测效果。

    

    在自动语音识别中，标点文本预测对提高可读性和影响下游自然语言处理任务至关重要。在流媒体场景下，实时预测标点的能力尤为重要，但也带来了困难的技术挑战。本文提出了一种使用基于块的Transformer编码器预测标点文本的方法，该编码器使用连续时间分类（CTC）损失进行训练。通过将输入序列和目标序列连接起来训练长序列的声学模型可以更有效地学习附加在句子末尾的标点符号。此外，通过结合块和话语的CTC损失，我们实现了标点预测的改进F1得分和词错误率（WER）的双重目标。

    Punctuated text prediction is crucial for automatic speech recognition as it enhances readability and impacts downstream natural language processing tasks. In streaming scenarios, the ability to predict punctuation in real-time is particularly desirable but presents a difficult technical challenge. In this work, we propose a method for predicting punctuated text from input speech using a chunk-based Transformer encoder trained with Connectionist Temporal Classification (CTC) loss. The acoustic model trained with long sequences by concatenating the input and target sequences can learn punctuation marks attached to the end of sentences more effectively. Additionally, by combining CTC losses on the chunks and utterances, we achieved both the improved F1 score of punctuation prediction and Word Error Rate (WER).
    
[^37]: KL-Divergence引导下的温度采样

    KL-Divergence Guided Temperature Sampling. (arXiv:2306.01286v1 [cs.CL])

    [http://arxiv.org/abs/2306.01286](http://arxiv.org/abs/2306.01286)

    该论文提出了一种新的温度采样算法，通过KL-散度引导动态调整温度，从而缓解多样性和可归因性之间的权衡，实验证明该算法在对话问答和摘要任务中表现优异。

    

    温度采样是一种常规的方法，用于将大型语言模型的预测多样化。随着温度的升高，预测变得更加多样化，但也容易产生幻觉——生成看似合理但不正确的令牌。缓解幻觉的一种常见方法是提供源/基础文档，并使模型训练生成与提供的来源相关且可归因的预测。看来存在多样性和可归因性之间的权衡。为了缓解这种权衡，我们提出了一个松弛固定温度和通过KL-散度根据其与源的相关性引导动态温度的机制。我们的实验证实了这种权衡，并表明我们的采样算法在对话问答和摘要任务中优于常规的top-k和top-p算法。

    Temperature sampling is a conventional approach to diversify large language model predictions. As temperature increases, the prediction becomes diverse but also vulnerable to hallucinations -- generating tokens that are sensible but not factual. One common approach to mitigate hallucinations is to provide source/grounding documents and the model is trained to produce predictions that bind to and are attributable to the provided source. It appears that there is a trade-off between diversity and attribution. To mitigate any such trade-off, we propose to relax the constraint of having a fixed temperature over decoding steps, and a mechanism to guide the dynamic temperature according to its relevance to the source through KL-divergence. Our experiments justifies the trade-off, and shows that our sampling algorithm outperforms the conventional top-k and top-p algorithms in conversational question-answering and summarization tasks.
    
[^38]: VoteTRANS: 通过对转换的硬标签投票来检测非训练对抗性文本

    VoteTRANS: Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations. (arXiv:2306.01273v1 [cs.CL])

    [http://arxiv.org/abs/2306.01273](http://arxiv.org/abs/2306.01273)

    VoteTRANS 是一种无需训练即可检测对抗性文本的方法，通过比较输入文本及其转换的硬标签实现检测，可有效应对各种最先进的攻击、模型和数据集中的对抗性文本。

    

    对抗性攻击揭示了深度学习模型的严重缺陷。更危险的是，这些攻击保留了原始含义，逃避了人类的识别。现有的检测方法需要使用原始/对抗数据进行训练。本文提出了一种通过对转换的硬标签投票来实现无需训练的检测方法，即 VoteTRANS。具体而言，VoteTRANS 通过比较输入文本及其转换的硬标签来检测对抗性文本。评估表明，VoteTRANS 能够有效地检测各种最先进的攻击、模型和数据集中的对抗性文本。

    Adversarial attacks reveal serious flaws in deep learning models. More dangerously, these attacks preserve the original meaning and escape human recognition. Existing methods for detecting these attacks need to be trained using original/adversarial data. In this paper, we propose detection without training by voting on hard labels from predictions of transformations, namely, VoteTRANS. Specifically, VoteTRANS detects adversarial text by comparing the hard labels of input text and its transformation. The evaluation demonstrates that VoteTRANS effectively detects adversarial text across various state-of-the-art attacks, models, and datasets.
    
[^39]: 社交媒体文本中恶意言论到非恶意言论的自动翻译

    Automatic Translation of Hate Speech to Non-hate Speech in Social Media Texts. (arXiv:2306.01261v1 [cs.CL])

    [http://arxiv.org/abs/2306.01261](http://arxiv.org/abs/2306.01261)

    本文介绍了一种将社交媒体文本中的恶意言论自动翻译为非恶意言论的方法，以西班牙语为例，并提供了数据集和基线结果，旨在为减少社区中恶意言论的传播贡献更有效的方法。

    

    本文研究了恶意言论的问题，提出一种将恶意言论转化为非恶意言论文本的新方法，并保留其意义。我们以西班牙语文本为案例进行研究，提供数据集和基线结果，为进一步研究此任务提供起点。我们使用多种指标（包括BLEU分数）对基线结果进行评估。本研究旨在为减少社区中恶意言论的传播，贡献更有效的方法。

    In this paper, we investigate the issue of hate speech by presenting a novel task of translating hate speech into non-hate speech text while preserving its meaning. As a case study, we use Spanish texts. We provide a dataset and several baselines as a starting point for further research in the task. We evaluated our baseline results using multiple metrics, including BLEU scores. The aim of this study is to contribute to the development of more effective methods for reducing the spread of hate speech in online communities.
    
[^40]: 预训练的抽象模型和LLMs在法律案例判决摘要中的应用准备情况？

    How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?. (arXiv:2306.01248v1 [cs.CL])

    [http://arxiv.org/abs/2306.01248](http://arxiv.org/abs/2306.01248)

    这篇论文探讨了是否可以使用预训练的抽象模型和大型语言模型来自动生成法律案例判决的摘要，并在印度的法庭案例判决中进行了相关实验分析。

    

    自动摘要法律案例判决一直是采用抽取式摘要方法尝试解决的问题。然而，近年来，具有生成更自然和连贯摘要能力的抽象摘要模型受到越来越多的关注。现在已经有了专门用于法律领域的预训练抽象摘要模型。此外，众所周知，如ChatGPT这样的通用领域预训练大型语言模型(LLMs)能够生成高质量的文本，并具有文本摘要的能力。因此，值得问的是，这些模型是否已准备好用于自动生成案例判决的抽象摘要。为了探讨这个问题，我们将几种最先进的领域特定的抽象性摘要模型和通用领域的LLMs应用于印度法庭案例判决中，并检查所生成摘要的质量。除了摘要质量的标准度量，我们还检查了生成的摘要中可能存在的不一致性和虚构现象。

    Automatic summarization of legal case judgements has traditionally been attempted by using extractive summarization methods. However, in recent years, abstractive summarization models are gaining popularity since they can generate more natural and coherent summaries. Legal domain-specific pre-trained abstractive summarization models are now available. Moreover, general-domain pre-trained Large Language Models (LLMs), such as ChatGPT, are known to generate high-quality text and have the capacity for text summarization. Hence it is natural to ask if these models are ready for off-the-shelf application to automatically generate abstractive summaries for case judgements. To explore this question, we apply several state-of-the-art domain-specific abstractive summarization models and general-domain LLMs on Indian court case judgements, and check the quality of the generated summaries. In addition to standard metrics for summary quality, we check for inconsistencies and hallucinations in the 
    
[^41]: SemEval-2023任务7上的THiFLY研究：面向CTR的文本蕴涵和证据检索的多粒度系统

    THiFLY Research at SemEval-2023 Task 7: A Multi-granularity System for CTR-based Textual Entailment and Evidence Retrieval. (arXiv:2306.01245v1 [cs.CL])

    [http://arxiv.org/abs/2306.01245](http://arxiv.org/abs/2306.01245)

    本文针对NLI4CT任务，提出了一个面向CTR的文本蕴涵和证据检索的多粒度系统，使用多粒度推断网络(MGNet)和T5模型SciFive，并进行模型集成和联合推断方法以增加系统的稳定性和一致性性能。在NLI4CT数据集上实验结果表现优异。

    

    NLI4CT任务旨在基于临床试验报告 (CTR) 推断假设，并检索支持证明。该任务具有显著挑战，因为在 NLI4CT 任务中验证假设需要整合来自一个或两个 CTR 的多个证据，并应用不同层次的推理，包括文本和数字。为解决这些问题，本文提出了一个面向CTR的文本蕴涵和证据检索的多粒度系统。具体来说，我们构建了一个多粒度推断网络 (MGNet)，利用句子级和令牌级编码来处理文本蕴涵和证据检索任务。此外，我们利用基于T5的模型SciFive，它在医学语料库上进行了预训练，以增强系统的数值推断能力。模型集成和联合推断方法进一步增加了系统的稳定性和一致性性能。对NLI4CT数据集的实验结果表明，我们的系统与最先进的方法相比实现了竞争性能。

    The NLI4CT task aims to entail hypotheses based on Clinical Trial Reports (CTRs) and retrieve the corresponding evidence supporting the justification. This task poses a significant challenge, as verifying hypotheses in the NLI4CT task requires the integration of multiple pieces of evidence from one or two CTR(s) and the application of diverse levels of reasoning, including textual and numerical. To address these problems, we present a multi-granularity system for CTR-based textual entailment and evidence retrieval in this paper. Specifically, we construct a Multi-granularity Inference Network (MGNet) that exploits sentence-level and token-level encoding to handle both textual entailment and evidence retrieval tasks. Moreover, we enhance the numerical inference capability of the system by leveraging a T5-based model, SciFive, which is pre-trained on the medical corpus. Model ensembling and a joint inference method are further utilized in the system to increase the stability and consiste
    
[^42]: 负责任的任务自动化: 使大型语言模型成为负责任的任务自动化工具

    Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators. (arXiv:2306.01242v1 [cs.AI])

    [http://arxiv.org/abs/2306.01242](http://arxiv.org/abs/2306.01242)

    本研究提出了一个基础框架-"负责任的任务自动化（ResponsibleTA）"，使大型语言模型可以负责任地作为任务协同工具。该框架增强了LLM的三种能力：预测任务可行性、验证任务完整性以及增强任务安全性。

    

    大型语言模型（LLMs）的成功为人工智能迈出了重要的一步。它们展现了在用户指令下自动完成任务的良好前景，可以作为类似大脑的协调者。随着我们将越来越多的任务交给机器自动完成，相关的风险也逐渐显现。一个重要的问题出现了: 当机器像人类驾驶协同一样帮助人们自动完成任务时，我们如何确保机器的责任行为？在本文中，我们从可行性、完整性和安全性的角度，深入探讨这个问题。具体来说，我们提出了“负责任的任务自动化”（ResponsibleTA）作为一个基础框架，以促进LLM协调者和执行者之间的负责任协作，实现任务自动化。该框架拥有三种增强能力: 1）预测执行者命令的可行性；2）验证执行者的完整性；3）增强安全性（例如，保护隐私）。

    The recent success of Large Language Models (LLMs) signifies an impressive stride towards artificial general intelligence. They have shown a promising prospect in automatically completing tasks upon user instructions, functioning as brain-like coordinators. The associated risks will be revealed as we delegate an increasing number of tasks to machines for automated completion. A big question emerges: how can we make machines behave responsibly when helping humans automate tasks as personal copilots? In this paper, we explore this question in depth from the perspectives of feasibility, completeness and security. In specific, we present Responsible Task Automation (ResponsibleTA) as a fundamental framework to facilitate responsible collaboration between LLM-based coordinators and executors for task automation with three empowered capabilities: 1) predicting the feasibility of the commands for executors; 2) verifying the completeness of executors; 3) enhancing the security (e.g., the prote
    
[^43]: 适应一个不可适应的语音识别系统

    Adapting an Unadaptable ASR System. (arXiv:2306.01208v1 [eess.AS])

    [http://arxiv.org/abs/2306.01208](http://arxiv.org/abs/2306.01208)

    本文探讨了一种适应在线服务提供商的语音识别系统的方法，采用错误纠正的方法，并以 OpenAI Whisper ASR 为例，使用 LibriSpeech 作为主要适应目标领域进行实验。结果显示该方法具有一定的泛化能力，可适用于不同体系结构的 ASR 模型。

    

    随着语音识别模型大小和训练数据需求的增长，系统通常只能通过在线服务提供商的API获得访问权限，而无法直接访问模型。在这种情况下，将系统适应到特定目标领域是具有挑战性的。为解决这个问题，本文采用错误纠正的方法，评估 OpenAI Whisper ASR 作为大规模 ASR 系统的适应方法。该方法不需要访问模型，而是可以从通常通过 ASR API 提供的 1-best 或 N-best 输出进行训练。LibriSpeech 被用作适应的主要目标领域。然后评估了系统在两个不同方面的泛化能力：首先，纠正模型的形式是否可以移植到其他语音识别领域；其次，它是否可用于具有不同体系结构的 ASR 模型。

    As speech recognition model sizes and training data requirements grow, it is increasingly common for systems to only be available via APIs from online service providers rather than having direct access to models themselves. In this scenario it is challenging to adapt systems to a specific target domain. To address this problem we consider the recently released OpenAI Whisper ASR as an example of a large-scale ASR system to assess adaptation methods. An error correction based approach is adopted, as this does not require access to the model, but can be trained from either 1-best or N-best outputs that are normally available via the ASR API. LibriSpeech is used as the primary target domain for adaptation. The generalization ability of the system in two distinct dimensions are then evaluated. First, whether the form of correction model is portable to other speech recognition domains, and secondly whether it can be used for ASR models having a different architecture.
    
[^44]: 在域内和域外样本之间估计语义相似度

    Estimating Semantic Similarity between In-Domain and Out-of-Domain Samples. (arXiv:2306.01206v1 [cs.CL])

    [http://arxiv.org/abs/2306.01206](http://arxiv.org/abs/2306.01206)

    本文研究如何以原则性的方式分析模型在域内和域外设置下的性能，最终找出一种无监督方法识别OOD / OODist样本。

    

    先前的工作通常将来自数据集或源与训练集不同但用于同一任务的域外（OOD）或域外分布（OODist）样本描述为域外，与域内（ID）样本相比，模型在OOD样本上的表现通常较差，尽管这种观察结果并不一致。另一方面，一些研究关注于OOD检测，但大多使用有监督的方法。在这项工作中，我们首先整合并呈现了多个关于OOD和OODist的多重定义，并以原则性的方式分析了模型在ID和OOD / OODist设置下的性能。最后，我们试图识别一种无监督方法，可在不使用训练模型的情况下可靠地识别OOD / OODist样本。我们使用4个不同任务的12个数据集进行了广泛评估的结果表明，无监督度量在该任务中具有良好的潜力。

    Prior work typically describes out-of-domain (OOD) or out-of-distribution (OODist) samples as those that originate from dataset(s) or source(s) different from the training set but for the same task. When compared to in-domain (ID) samples, the models have been known to usually perform poorer on OOD samples, although this observation is not consistent. Another thread of research has focused on OOD detection, albeit mostly using supervised approaches. In this work, we first consolidate and present a systematic analysis of multiple definitions of OOD and OODist as discussed in prior literature. Then, we analyze the performance of a model under ID and OOD/OODist settings in a principled way. Finally, we seek to identify an unsupervised method for reliably identifying OOD/OODist samples without using a trained model. The results of our extensive evaluation using 12 datasets from 4 different tasks suggest the promising potential of unsupervised metrics in this task.
    
[^45]: 学习何时说话：离线模型进行同时语音翻译的延迟与质量权衡

    Learning When to Speak: Latency and Quality Trade-offs for Simultaneous Speech-to-Speech Translation with Offline Models. (arXiv:2306.01201v1 [cs.CL])

    [http://arxiv.org/abs/2306.01201](http://arxiv.org/abs/2306.01201)

    本文提出了一个适用于实际场景的同时语音翻译系统，支持从57种语言翻译成英语，并具有调整输出延迟的可调参数。我们展示了可以在不增加显著延迟的情况下达到离线水平的准确性。

    

    最近的语音翻译研究主要集中在离线场景中，在此场景中，完整的输入话语在任何输出之前都是可用的。然而，在许多实际应用场景中，这并不合理。在对延迟敏感的应用程序中，翻译应该在输入信息出现时立即发音。我们引入了一个系统，用于同时语音翻译的实际用例。我们的系统支持从57种语言翻译成英语，并具有调整输出延迟的可调参数。我们展示了这些策略达到了离线水平的准确性，同时在Greedy（wait-$k$）基线上最小化了延迟增加。我们开源了我们的评估代码和互动测试脚本，以帮助未来的SimulS2ST研究和应用程序发展。

    Recent work in speech-to-speech translation (S2ST) has focused primarily on offline settings, where the full input utterance is available before any output is given. This, however, is not reasonable in many real-world scenarios. In latency-sensitive applications, rather than waiting for the full utterance, translations should be spoken as soon as the information in the input is present. In this work, we introduce a system for simultaneous S2ST targeting real-world use cases. Our system supports translation from 57 languages to English with tunable parameters for dynamically adjusting the latency of the output -- including four policies for determining when to speak an output sequence. We show that these policies achieve offline-level accuracy with minimal increases in latency over a Greedy (wait-$k$) baseline. We open-source our evaluation code and interactive test script to aid future SimulS2ST research and application development.
    
[^46]: 基于上下文学习的文本摘要的多维评价研究

    Multi-Dimensional Evaluation of Text Summarization with In-Context Learning. (arXiv:2306.01200v1 [cs.CL])

    [http://arxiv.org/abs/2306.01200](http://arxiv.org/abs/2306.01200)

    本文研究采用基于上下文学习的大型语言模型作为文本多维度评估器的有效性，针对文本摘要任务，实验表明该方法在与学习评估框架相竞争的地位。同时，本文探究了上下文样例选择、数量以及评估零-shot摘要等方面的影响。

    

    自然语言生成（NLG）的评估是复杂而多维的，可以评估生成文本的流畅性、连贯性、事实性或任何其他感兴趣的维度。大多数执行这种多维评估的框架需要在手动或合成生成的大型数据集上进行训练。本文研究采用基于上下文学习的大型语言模型作为多维度评估器的有效性，在无需大型训练数据集的情况下，针对文本摘要这一任务，我们的实验表明基于上下文学习的评估器在诸如相关性和事实一致性等方面处于与已有的学习评估框架相竞争的地位。接着，我们分析了因素如选择和数量的上下文样例对性能的影响。最后，我们研究了采用基于上下文学习的评估器来评估诸如GPT-3这样的大型语言模型生成的零-shot摘要的有效性。

    Evaluation of natural language generation (NLG) is complex and multi-dimensional. Generated text can be evaluated for fluency, coherence, factuality, or any other dimensions of interest. Most frameworks that perform such multi-dimensional evaluation require training on large manually or synthetically generated datasets. In this paper, we study the efficacy of large language models as multi-dimensional evaluators using in-context learning, obviating the need for large training datasets. Our experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency. We then analyze the effects of factors such as the selection and number of in-context examples on performance. Finally, we study the efficacy of in-context learning based evaluators in evaluating zero-shot summaries written by large language models such as GPT-3.
    
[^47]: GPT-3对零样本个性估计的系统评估

    Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation. (arXiv:2306.01183v1 [cs.CL])

    [http://arxiv.org/abs/2306.01183](http://arxiv.org/abs/2306.01183)

    本文系统研究了使用 GPT-3 从用户社交媒体帖子中零样本估计个性特质的能力。在插入关于特质的知识后，GPT-3 性能接近于现有的预训练 SotA，但在被提示提供细粒度分类时，其性能降至基线水平。

    

    非常大的语言模型在零样本环境下表现出色，但在人类水平的 NLP 问题上，如评估个性特征，它们的表现却鲜有人知。本文通过一系列系统实验，探究了使用 GPT-3 从用户社交媒体帖子中零样本估计 Big 5 个性特质的能力。我们发现，当插入关于特质的知识后，零样本 GPT-3 性能与现有的预训练 SotA 稍有接近。但在被提示提供细粒度分类时，其性能降至接近一个简单的最常见类（MFC）基线。我们进一步分析了 GPT-3 表现比预训练词汇模型更好、更差的地方，揭示了系统误差，提出了改进 NLP 任务中的 LLM 的方法。

    Very large language models (LLMs) perform extremely well on a spectrum of NLP tasks in a zero-shot setting. However, little is known about their performance on human-level NLP problems which rely on understanding psychological concepts, such as assessing personality traits. In this work, we investigate the zero-shot ability of GPT-3 to estimate the Big 5 personality traits from users' social media posts. Through a set of systematic experiments, we find that zero-shot GPT-3 performance is somewhat close to an existing pre-trained SotA for broad classification upon injecting knowledge about the trait in the prompts. However, when prompted to provide fine-grained classification, its performance drops to close to a simple most frequent class (MFC) baseline. We further analyze where GPT-3 performs better, as well as worse, than a pretrained lexical model, illustrating systematic errors that suggest ways to improve LLMs on human-level NLP tasks.
    
[^48]: 使用C2F-FAR和ChatGPT的混合式长文本摘要：一项实用研究

    Hybrid Long Document Summarization using C2F-FAR and ChatGPT: A Practical Study. (arXiv:2306.01169v1 [cs.CL])

    [http://arxiv.org/abs/2306.01169](http://arxiv.org/abs/2306.01169)

    本文结合最新的ChatGPT和抽取式摘要模型C2F-FAR，提出了一种混合式抽取和摘要流水线以解决长文本摘要的挑战，与getAbstract AG合作，该方法在内容覆盖率、连贯性和可读性方面表现优异。

    

    文本摘要是一个要挑战语言模型理解和生成能力的下游自然语言处理（NLP）任务。自动摘要短文本（如新闻文章）取得了可圈可点的进展，但是长文本的摘要仍然是一个重大挑战。这是因为文本中复杂的上下文信息以及缺乏可用于开发和测试模型性能的开源基准数据集和评估框架。本文结合大语言模型（LLMs）领域的最新突破ChatGPT和抽取式摘要模型C2F-FAR（Coarse-to-Fine Facet-Aware Ranking），提出了一种针对商业文章和书籍等长文本的混合式抽取和摘要流水线。我们与世界知名公司getAbstract AG合作，利用其在专业书籍摘要方面的专业知识和经验。通过各种指标和人工评估进行了实际研究，结果表明，该混合方法在内容覆盖率、连贯性和可读性方面均优于抽取式和生成式方法。

    Text summarization is a downstream natural language processing (NLP) task that challenges the understanding and generation capabilities of language models. Considerable progress has been made in automatically summarizing short texts, such as news articles, often leading to satisfactory results. However, summarizing long documents remains a major challenge. This is due to the complex contextual information in the text and the lack of open-source benchmarking datasets and evaluation frameworks that can be used to develop and test model performance. In this work, we use ChatGPT, the latest breakthrough in the field of large language models (LLMs), together with the extractive summarization model C2F-FAR (Coarse-to-Fine Facet-Aware Ranking) to propose a hybrid extraction and summarization pipeline for long documents such as business articles and books. We work with the world-renowned company getAbstract AG and leverage their expertise and experience in professional book summarization. A pr
    
[^49]: 利用自然语言处理进行YouTube公共卫生筛查：COVID-19案例研究

    Leveraging Natural Language Processing For Public Health Screening On YouTube: A COVID-19 Case Study. (arXiv:2306.01164v1 [cs.CL])

    [http://arxiv.org/abs/2306.01164](http://arxiv.org/abs/2306.01164)

    本研究探索利用自然语言处理技术识别COVID-19相关的YouTube视频日志内容，用于公共卫生筛查。

    

    背景：社交媒体平台已成为医疗信息的可靠来源，患者和医疗专业人员使用它们分享与跟踪疾病相关的信息。同样，全球最大的视频分享平台YouTube包含个人讲述疾病的视频日志。我们研究的目的是利用自然语言处理（NLP）来识别与Coronavirus disease of 2019 (COVID-19)的诊断相关的YouTube视频日志内容，以进行公共卫生筛查。

    Background: Social media platforms have become a viable source of medical information, with patients and healthcare professionals using them to share health-related information and track diseases. Similarly, YouTube, the largest video-sharing platform in the world contains vlogs where individuals talk about their illnesses. The aim of our study was to investigate the use of Natural Language Processing (NLP) to identify the spoken content of YouTube vlogs related to the diagnosis of Coronavirus disease of 2019 (COVID-19) for public health screening. Methods: COVID-19 videos on YouTube were searched using relevant keywords. A total of 1000 videos being spoken in English were downloaded out of which 791 were classified as vlogs, 192 were non-vlogs, and 17 were deleted by the channel. The videos were converted into a textual format using Microsoft Streams. The textual data was preprocessed using basic and advanced preprocessing methods. A lexicon of 200 words was created which contained wo
    
[^50]: 通过稀疏Flash注意力加速处理大序列中的因果关系

    Faster Causal Attention Over Large Sequences Through Sparse Flash Attention. (arXiv:2306.01160v1 [cs.LG])

    [http://arxiv.org/abs/2306.01160](http://arxiv.org/abs/2306.01160)

    本文介绍了一种新的稀疏Flash注意力机制，能够快速处理大序列中的因果关系，且速度提高了多倍，可以作为任何基于Transformer的语言模型中密集自我注意力的替代方案，并在多个设置中产生了最先进的结果。

    

    基于Transformer的语言模型已经在处理越来越长序列的任务中被广泛应用。对于这些应用，序列长度关于的因果自注意力成为一个核心问题，因为它是唯一一个与序列长度呈二次关系的组件。虽然许多研究已经提出方案来使自注意力的注意力模式稀疏化，但这些方案通常受到实现方面的限制，并最终强加一个简单且静态的结构在关注矩阵上。相反，实现更动态的稀疏注意力通常会导致运行时间显着慢于使用Dao等人（2022）的Flash实现计算完整注意力。我们扩展了FlashAttention，以适应包含键/查询丢弃和基于哈希的注意力在内的大类稀疏注意性模式。这导致实现没有任何计算复杂度开销，并且与以前的动态稀疏注意性相比，速度提高了多倍。我们的方法可用作任何基于Transformer的语言模型中密集自我注意力的替代方案，并在多个设置中产生了最先进的结果，包括生成语言建模和长格式问答。

    Transformer-based language models have found many diverse applications requiring them to process sequences of increasing length. For these applications, the causal self-attention -- which is the only component scaling quadratically w.r.t. the sequence length -- becomes a central concern. While many works have proposed schemes to sparsify the attention patterns and reduce the computational overhead of self-attention, those are often limited by implementations concerns and end up imposing a simple and static structure over the attention matrix. Conversely, implementing more dynamic sparse attentions often results in runtimes significantly slower than computing the full attention using the Flash implementation from Dao et al. (2022). We extend FlashAttention to accommodate a large class of attention sparsity patterns that, in particular, encompass key/query dropping and hashing-based attention. This leads to implementations with no computational complexity overhead and a multi-fold runtim
    
[^51]: 通过连续后验推理实现多样和忠实的知识驱动对话生成

    Diverse and Faithful Knowledge-Grounded Dialogue Generation via Sequential Posterior Inference. (arXiv:2306.01153v1 [cs.CL])

    [http://arxiv.org/abs/2306.01153](http://arxiv.org/abs/2306.01153)

    本文提出了一种名为SPI的端到端学习框架，能够忠实地生成多样化的基于知识的对话。

    

    利用事实知识生成具有多样性和忠实性的回复对于创建类人、可信任的对话系统非常重要。本文提出一种名为"连续后验推理（SPI）"的端到端学习框架，能够通过对后验分布进行近似采样来选择知识并生成对话，与现有方法不同，SPI不需要推理网络或假设后验分布具有一个简单的几何结构，其直接查询响应生成模型的推理过程直接，从而实现准确的知识选择和生成。

    The capability to generate responses with diversity and faithfulness using factual knowledge is paramount for creating a human-like, trustworthy dialogue system. Common strategies either adopt a two-step paradigm, which optimizes knowledge selection and response generation separately, and may overlook the inherent correlation between these two tasks, or leverage conditional variational method to jointly optimize knowledge selection and response generation by employing an inference network. In this paper, we present an end-to-end learning framework, termed Sequential Posterior Inference (SPI), capable of selecting knowledge and generating dialogues by approximately sampling from the posterior distribution. Unlike other methods, SPI does not require the inference network or assume a simple geometry of the posterior distribution. This straightforward and intuitive inference procedure of SPI directly queries the response generation model, allowing for accurate knowledge selection and gener
    
[^52]: 你读懂了说明书吗？重新思考指令学习中任务定义的有效性。

    Did You Read the Instructions? Rethinking the Effectiveness of Task Definitions in Instruction Learning. (arXiv:2306.01150v1 [cs.CL])

    [http://arxiv.org/abs/2306.01150](http://arxiv.org/abs/2306.01150)

    本文研究了任务定义在指令学习中的作用，发现当删除描述任务输出的内容时模型性能才会显著下降，提出了一种自动算法可以压缩任务定义，删除60\%标记仍可以提高模型性能。

    

    大型语言模型在遵循自然语言指令解决未见过的任务方面表现出色。然而，模型是否真正理解任务定义以及人类编写的定义是否最佳仍然不清楚。本文系统研究了任务定义在指令学习中的作用。我们首先进行消融分析，通过人类注释发现只有当删除描述任务输出的内容，尤其是标签信息时，模型的性能才会显著下降。接下来，我们提出了一种自动算法，将任务定义压缩到最小的支持标记集，并发现可以删除60\%的标记而维持或提高模型性能。基于这些结果，我们提出了两种策略来帮助模型更好地利用任务指令。

    Large language models (LLMs) have shown impressive performance in following natural language instructions to solve unseen tasks. However, it remains unclear whether models truly understand task definitions and whether the human-written definitions are optimal. In this paper, we systematically study the role of task definitions in instruction learning. We first conduct an ablation analysis informed by human annotations to understand which parts of a task definition are most important, and find that model performance only drops substantially when removing contents describing the task output, in particular label information. Next, we propose an automatic algorithm to compress task definitions to a minimal supporting set of tokens, and find that 60\% of tokens can be removed while maintaining or even improving model performance. Based on these results, we propose two strategies to help models better leverage task instructions: (1) providing only key information for tasks in a common struct
    
[^53]: 用合成任务数据评估多模态推理模型的能力

    Evaluating the Capabilities of Multi-modal Reasoning Models with Synthetic Task Data. (arXiv:2306.01144v1 [cs.LG])

    [http://arxiv.org/abs/2306.01144](http://arxiv.org/abs/2306.01144)

    本研究提出一种利用合成方法生成用于评估复杂多模态推理任务的数据集，并将其应用于测试最新的视觉问答模型的表现，结果表明该模型在上下文相关的异常检测任务上表现不佳。

    

    大语言和联合语言-视觉理解模型的显着进展和应用增加了对探测其潜在推理能力方法的需求。然而，对于未被学术数据集涵盖的复杂多模态推理任务，收集自然数据的困难制约了对AI方法的评估。在本研究中，我们利用高分辨率文本-图像生成的最新进展，开发了一个用于为多模态推理任务生成评估数据的框架。我们将此框架应用于生成上下文相关的异常数据，创建了一个具有挑战性的合成数据集，该数据集在现有数据集中覆盖不足。我们对最先进的视觉问答（VQA）模型在使用此方法生成的数据上的表现进行了基准测试，并表明尽管任务是可行的，但该模型在上下文相关的异常检测任务上的表现显著低于现有的学术数据集。我们的工作突显了考虑合成任务以评估和理解AI模型的潜在能力和限制的重要性。

    The impressive advances and applications of large language and joint language-and-visual understanding models has led to an increased need for methods of probing their potential reasoning capabilities. However, the difficulty of gather naturally-occurring data for complex multi-modal reasoning tasks bottlenecks the evaluation of AI methods on tasks which are not already covered by an academic dataset. In this work, we leverage recent advances in high resolution text-to-image generation to develop a framework for generating evaluation data for multi-modal reasoning tasks. We apply this framework to generate context-dependent anomaly data, creating a synthetic dataset on a challenging task which is not well covered by existing datasets. We benchmark the performance of a state-of-the-art visual question answering (VQA) model against data generated with this method, and demonstrate that while the task is tractable, the model performs significantly worse on the context-dependent anomaly det
    
[^54]: 考察名字对语言模型的因果影响：以社交常识推理为例

    Examining the Causal Effect of First Names on Language Models: The Case of Social Commonsense Reasoning. (arXiv:2306.01117v1 [cs.CL])

    [http://arxiv.org/abs/2306.01117](http://arxiv.org/abs/2306.01117)

    本文研究了名字对常识推理中语言模型的影响，结果表明名字的频率会直接影响模型的预测。

    

    随着语言模型继续被整合到个人和社会相关的应用中，确保这些模型的可信度非常重要，尤其是要保证它们产生的输出结果不受敏感属性的影响。考虑到名字可能代表（交叉的）社会人口统计学信息，有必要研究名字对常识推理能力的影响。本文探讨了当给定不同名字时，模型在给出特定输入的推理过程中是否存在差异。我们的基本假设是，关于Alice的推理不应该不同于关于James的推理。我们提出并实现了一个受控的实验框架，以测量名字对常识推理的因果影响，从而区分由偶然和实际感兴趣的因素引起的模型预测。我们的研究结果表明，名字的频率对模型的预测有直接影响。

    As language models continue to be integrated into applications of personal and societal relevance, ensuring these models' trustworthiness is crucial, particularly with respect to producing consistent outputs regardless of sensitive attributes. Given that first names may serve as proxies for (intersectional) socio-demographic representations, it is imperative to examine the impact of first names on commonsense reasoning capabilities. In this paper, we study whether a model's reasoning given a specific input differs based on the first names provided. Our underlying assumption is that the reasoning about Alice should not differ from the reasoning about James. We propose and implement a controlled experimental framework to measure the causal effect of first names on commonsense reasoning, enabling us to distinguish between model predictions due to chance and caused by actual factors of interest. Our results indicate that the frequency of first names has a direct effect on model prediction,
    
[^55]: Falcon LLM的RefinedWeb数据集：仅凭网络数据胜过筛选后的语料库

    The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only. (arXiv:2306.01116v1 [cs.CL])

    [http://arxiv.org/abs/2306.01116](http://arxiv.org/abs/2306.01116)

    本文发现经过适当的筛选和去重后，仅凭网络数据就能训练出强大的语言模型，这甚至明显优于使用筛选后的语料库训练。研究还表明，即使在广泛筛选后，从网络中提取的高质量数据仍然充足，这为训练更大、更强大的语言模型带来了希望。

    

    大型语言模型通常由经过筛选的网络数据和经过筛选的高质量语料库（如社交媒体对话、书籍或技术论文）混合训练。这种筛选过程被认为是产生具有广泛零-shot泛化能力的高性能模型所必需的。然而，随着考虑需要预先训练数万亿个标记的更大模型，筛选的可扩展性是否会出现瓶颈以及我们是否会很快用尽独特的高质量数据仍然不清楚。与以往的想法相反，我们展示了经过适当筛选和去重的网络数据可以导致功能强大的模型；甚至明显优于训练在The Pile 上的最先进的模型。尽管经过了广泛的过滤，我们从网络中提取的高质量数据仍然很丰富，我们能够从CommonCrawl中获得五万亿个标记。我们公开发布了从我们的RefinedWeb数据集中提取的6000亿个标记的片段，以及在此数据集上训练的1.3 / 7.5B参数语言模型。

    Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.
    
[^56]: 重新审视仇恨言论基准：从数据筛选到系统应用

    Revisiting Hate Speech Benchmarks: From Data Curation to System Deployment. (arXiv:2306.01105v1 [cs.CL])

    [http://arxiv.org/abs/2306.01105](http://arxiv.org/abs/2306.01105)

    该论文介绍了GOTHate数据集，并详细比较了该数据集与现有的仇恨言论数据集，研究了模型如何捕捉中立的恶意内容中的仇恨信号。研究发现，GOTHate很难在纯文本环境下进行分类，并介绍了如何通过添加内生信号来提高模型性能。

    

    社交媒体上充斥着充满仇恨的内容，其中很多经常伴随着语言和主题的多样性。用于仇恨言论检测的基准数据集没有考虑到这种背离，因为它们主要是使用仇恨词汇编制的。然而，在中立的恶意内容中捕捉仇恨信号变得具有挑战性。因此，设计模拟仇恨现实世界变异性的模型和数据集需要进一步研究。为此，我们提出了GOTHate，这是一个综合了不同语言和主题的大规模代码混合众包数据集，用于从Twitter中检测仇恨言论，包括约51k个帖子。我们详细比较了GOTHate和现有仇恨言论数据集，突出了它的新颖性，并使用10个最近的基准线对其进行了基准测试。我们的广泛实证和基准测试实验表明，在纯文本环境下，很难对GOTHate进行分类。因此，我们研究了如何添加内生信号以增强模型的性能。

    Social media is awash with hateful content, much of which is often veiled with linguistic and topical diversity. The benchmark datasets used for hate speech detection do not account for such divagation as they are predominantly compiled using hate lexicons. However, capturing hate signals becomes challenging in neutrally-seeded malicious content. Thus, designing models and datasets that mimic the real-world variability of hate warrants further investigation.  To this end, we present GOTHate, a large-scale code-mixed crowdsourced dataset of around 51k posts for hate speech detection from Twitter. GOTHate is neutrally seeded, encompassing different languages and topics. We conduct detailed comparisons of GOTHate with the existing hate speech datasets, highlighting its novelty. We benchmark it with 10 recent baselines. Our extensive empirical and benchmarking experiments suggest that GOTHate is hard to classify in a text-only setup. Thus, we investigate how adding endogenous signals enhan
    
[^57]: LLMatic: 基于大语言模型和多样性优化的神经结构搜索

    LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization. (arXiv:2306.01102v1 [cs.NE])

    [http://arxiv.org/abs/2306.01102](http://arxiv.org/abs/2306.01102)

    本文介绍了利用大语言模型和多样性优化算法相结合的 LLMatic 神经结构搜索算法。该算法在CIFAR-10数据集进行测试，仅进行2000次搜索即可产生高性能网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。

    

    大型语言模型 (LLMs) 已成为一种强大的工具，可以完成广泛的任务。它们的能力涵盖了许多领域，它们在代码生成领域产生了重大影响。在此情况下，我们将 LLMs 视为变异和交叉工具。同时，多样性优化算法已知可以发现多样性和稳健的解决方案。通过将 LLMs 的代码生成能力与 QD 解决方案的多样性和鲁棒性相结合，我们引入了 LLMatic，一个神经结构搜索 (NAS) 算法。虽然 LLMs 通过提示直接进行 NAS 考验困难，但 LLMatic 利用程序化方法，利用 QD 来进行提示和网络结构，从而创建多样性和高性能网络。我们在 CIFAR-10 图像分类基准测试中测试了 LLMatic，证明它可以在仅进行 2000 次搜索的情况下产生具有竞争力的网络，即使没有该基准领域的先前知识或任何先前的最佳结果的曝光。

    Large Language Models (LLMs) have emerged as powerful tools capable of accomplishing a broad spectrum of tasks. Their abilities span numerous areas, and one area where they have made a significant impact is in the domain of code generation. In this context, we view LLMs as mutation and crossover tools. Meanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and robust solutions. By merging the code-generating abilities of LLMs with the diversity and robustness of QD solutions, we introduce LLMatic, a Neural Architecture Search (NAS) algorithm. While LLMs struggle to conduct NAS directly through prompts, LLMatic uses a procedural approach, leveraging QD for prompts and network architecture to create diverse and highly performant networks. We test LLMatic on the CIFAR-10 image classification benchmark, demonstrating that it can produce competitive networks with just $2,000$ searches, even without prior knowledge of the benchmark domain or exposure to any previous top-p
    
[^58]: UCAS-IIE-NLP在SemEval-2023任务12中的应用：增强低资源情感分析的多语言BERT泛化能力

    UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of Multilingual BERT for Low-resource Sentiment Analysis. (arXiv:2306.01093v1 [cs.CL])

    [http://arxiv.org/abs/2306.01093](http://arxiv.org/abs/2306.01093)

    本文介绍了 UCAS-IIE-NLP 设计的 SACL-XLMR 系统，它利用词典式多语言BERT进行情感感知表示学习，使用监督性对抗式对比学习技术进行情感传播结构化表示学习，用于低资源情感分析，且在多语言和零样本情感分类子任务中表现出色，并且在零样本分类子任务中获得了第一名。

    

    本文描述了我们为SemEval-2023任务12设计的系统：非洲语言的情感分析。该任务面临的挑战是在低资源环境下标注数据和语言资源的稀缺性。为了缓解这些问题，我们提出了一个名为SACL-XLMR的通用多语言系统，用于低资源语言的情感分析。具体而言，我们设计了一个基于词典的多语言BERT，以便进行语言适应和情感感知表示学习。此外，我们采用一个监督性的对抗式对比学习技术来学习情感传播结构化表示并增强模型的泛化能力。我们的系统在多语言和零样本情感分类子任务中表现出色，远远超过基线。值得注意的是，在官方排名中，该系统在零样本分类子任务中获得了第一名。广泛的实验表明了我们系统的有效性。

    This paper describes our system designed for SemEval-2023 Task 12: Sentiment analysis for African languages. The challenge faced by this task is the scarcity of labeled data and linguistic resources in low-resource settings. To alleviate these, we propose a generalized multilingual system SACL-XLMR for sentiment analysis on low-resource languages. Specifically, we design a lexicon-based multilingual BERT to facilitate language adaptation and sentiment-aware representation learning. Besides, we apply a supervised adversarial contrastive learning technique to learn sentiment-spread structured representations and enhance model generalization. Our system achieved competitive results, largely outperforming baselines on both multilingual and zero-shot sentiment classification subtasks. Notably, the system obtained the 1st rank on the zero-shot classification subtask in the official ranking. Extensive experiments demonstrate the effectiveness of our system.
    
[^59]: 用双重数据增强技术提高摘要系统的鲁棒性

    Improving the Robustness of Summarization Systems with Dual Augmentation. (arXiv:2306.01090v1 [cs.CL])

    [http://arxiv.org/abs/2306.01090](http://arxiv.org/abs/2306.01090)

    本文通过数据增强和对抗样本生成技术提出了一种用于提高摘要系统鲁棒性的双重增强方法，该方法可以有效提高模型在对抗性和噪音测试集上的性能。

    

    一个鲁棒的摘要系统应该能够捕捉到文档的要点，而不受特定单词选择或输入中的噪音的影响。在本文中，我们首先探索了摘要模型在包括单词级同义词替换和噪音在内的扰动下的鲁棒性。为了创建语义一致的替代词，我们提出了一种名为SummAttacker的方法，它是一种基于语言模型生成对抗样本的高效方法。实验结果显示，最先进的摘要模型在对抗性和噪音测试集上的性能显著下降。接下来，我们分析了摘要系统的弱点，并通过数据增强探索提高其鲁棒性的方法。具体来说，我们发现第一个脆弱性因素是摘要模型对输入中不常见单词的理解能力较差。相应地，我们将更多由SummAttacker在输入空间中创建的多样化案例馈入编码器。另一个因素在潜在空间中，攻击的输入会为解码器产生噪声表示。为了解决这个问题，我们提出了一种双重增强方法，该方法在训练阶段教摘要模型对随机噪声具有不变性。实验结果表明，双重增强可以显著提高摘要模型在对抗性和噪音测试集上的性能。

    A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input. In this work, we first explore the summarization models' robustness against perturbations including word-level synonym substitution and noise. To create semantic-consistent substitutes, we propose a SummAttacker, which is an efficient approach to generating adversarial samples based on language models. Experimental results show that state-of-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets. Next, we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation. Specifically, the first brittleness factor we found is the poor understanding of infrequent words in the input. Correspondingly, we feed the encoder with more diverse cases created by SummAttacker in the input space. The other factor is in the latent space, where the attacked inp
    
[^60]: 量化感知和张量压缩训练：用于自然语言理解的Transformer

    Quantization-Aware and Tensor-Compressed Training of Transformers for Natural Language Understanding. (arXiv:2306.01076v1 [cs.CL])

    [http://arxiv.org/abs/2306.01076](http://arxiv.org/abs/2306.01076)

    本研究提出了一种量化感知张量压缩训练方法，用于减少基于Transformer的模型的模型大小，算术运算和最终运行时延。该方法经过逐层蒸馏后在文本蕴含和情感分析任务中表现出良好性能。

    

    细调的Transformer模型在许多自然语言任务中表现出优越性能。然而，庞大的模型大小阻止了在资源受限设备上部署高性能Transformer模型。本文提出了一种量化感知张量压缩训练方法，以减少基于Transformer的模型的模型大小，算术运算和最终运行时延。我们将Transformer的嵌入和线性层压缩为小型低秩张量核，从而显著减少模型参数。采用可学习比例因子的量化感知训练来进一步获得张量压缩模型的低精度表示。该方法可用于端到端训练和蒸馏训练。为了提高收敛性，采用逐层蒸馏方法从预训练Transformer中提取出一个经过量化和张量压缩的学生模型。本研究在两个自然语言任务，即文本蕴含和情感分析中展示了其性能。

    Fine-tuned transformer models have shown superior performances in many natural language tasks. However, the large model size prohibits deploying high-performance transformer models on resource-constrained devices. This paper proposes a quantization-aware tensor-compressed training approach to reduce the model size, arithmetic operations, and ultimately runtime latency of transformer-based models. We compress the embedding and linear layers of transformers into small low-rank tensor cores, which significantly reduces model parameters. A quantization-aware training with learnable scale factors is used to further obtain low-precision representations of the tensor-compressed models. The developed approach can be used for both end-to-end training and distillation-based training. To improve the convergence, a layer-by-layer distillation is applied to distill a quantized and tensor-compressed student model from a pre-trained transformer. The performance is demonstrated in two natural language
    
[^61]: TimelineQA: 一个用于时间线问答的基准测试

    TimelineQA: A Benchmark for Question Answering over Timelines. (arXiv:2306.01069v1 [cs.CL])

    [http://arxiv.org/abs/2306.01069](http://arxiv.org/abs/2306.01069)

    TimelineQA是一个用于查询生活日志的加速进展的基准测试，涉及时间和地理信息，已经公开发布，并使用两种最先进的模型进行了实验，但这两种模型均未达到人类表现水平。

    

    Lifelogs（生活日志）是人们生活经历的描述，这些日志通过结合来自多个数字服务（如在线照片、地图、购物和内容流媒体服务）的数据来创建。问答技术在生活日志上的应用可以为个人助手在提供上下文方面提供关键资源。但是，由于生活日志结合了自由文本与一定程度的结构，如时间和地理信息，因此当前的问答技术无法回答此类问题。为此，我们创建并公开发布了TimelineQA，这是一个用于查询生活日志的加速进展的基准测试。TimelineQA生成虚构人物的生活日志。生活日志中的事件从高中毕业等重大生活事件到日常活动如慢跑都有所覆盖。我们进行了一系列关于TimelineQA的实验，使用了两种最先进的模型，发现这两种模型在这一任务上均未达到人类表现水平。

    Lifelogs are descriptions of experiences that a person had during their life. Lifelogs are created by fusing data from the multitude of digital services, such as online photos, maps, shopping and content streaming services. Question answering over lifelogs can offer personal assistants a critical resource when they try to provide advice in context. However, obtaining answers to questions over lifelogs is beyond the current state of the art of question answering techniques for a variety of reasons, the most pronounced of which is that lifelogs combine free text with some degree of structure such as temporal and geographical information.  We create and publicly release TimelineQA1, a benchmark for accelerating progress on querying lifelogs. TimelineQA generates lifelogs of imaginary people. The episodes in the lifelog range from major life episodes such as high school graduation to those that occur on a daily basis such as going for a run. We describe a set of experiments on TimelineQA w
    
[^62]: 重塑检索增强语言模型以回答查询问题

    Reimagining Retrieval Augmented Language Models for Answering Queries. (arXiv:2306.01061v1 [cs.CL])

    [http://arxiv.org/abs/2306.01061](http://arxiv.org/abs/2306.01061)

    研究表明，将半参数化体系结构与查询分析器/计划器以及溯源相结合，可使问题回答的系统在准确性和效率方面显著提高。

    

    我们对大型语言模型进行了现实检验，并比较了检索增强语言模型的潜力。这些语言模型是半参数化的，模型将模型参数和外部数据源的知识集成到其预测中，与香草大型语言模型的参数化性质相反。我们给出了半参数化体系结构与查询分析器/计划器以及溯源相结合可使问题回答的系统在准确性和效率方面显著提高的初步实验结果，并在潜在的其他自然语言处理任务中具有潜力。

    We present a reality check on large language models and inspect the promise of retrieval augmented language models in comparison. Such language models are semi-parametric, where models integrate model parameters and knowledge from external data sources to make their predictions, as opposed to the parametric nature of vanilla large language models. We give initial experimental findings that semi-parametric architectures can be enhanced with views, a query analyzer/planner, and provenance to make a significantly more powerful system for question answering in terms of accuracy and efficiency, and potentially for other NLP tasks
    
[^63]: 无需精确标注: 基于不完全转录的弱监督自动语音识别算法

    Bypass Temporal Classification: Weakly Supervised Automatic Speech Recognition with Imperfect Transcripts. (arXiv:2306.01031v1 [cs.CL])

    [http://arxiv.org/abs/2306.01031](http://arxiv.org/abs/2306.01031)

    本文提出了一种新颖的算法，用重视转录不确定性的方式解决语音识别中训练数据不完美的问题，提高了ASR系统的鲁棒性和准确性。

    

    本文提出了一种新颖的算法，用于使用不完美的训练数据构建自动语音识别(ASR)模型。转录不准确的语音是人工注释的语音语料库中普遍存在的问题，这会降低ASR模型的性能。我们提出了Bypass Temporal Classification(BTC)作为联结时序分类(Connectionist Temporal Classification, CTC)准则的一个扩展。BTC在训练过程中显式地编码了与转录相关的不确定性。这是通过增强训练图的灵活性来实现的，它被实现为加权有限状态转换器(WFST)组合。这种提出的算法可以提高ASR系统的鲁棒性和准确性，特别是在使用不完整转录的语音语料库时。我们的实现将成为开源软件。

    This paper presents a novel algorithm for building an automatic speech recognition (ASR) model with imperfect training data. Imperfectly transcribed speech is a prevalent issue in human-annotated speech corpora, which degrades the performance of ASR models. To address this problem, we propose Bypass Temporal Classification (BTC) as an expansion of the Connectionist Temporal Classification (CTC) criterion. BTC explicitly encodes the uncertainties associated with transcripts during training. This is accomplished by enhancing the flexibility of the training graph, which is implemented as a weighted finite-state transducer (WFST) composition. The proposed algorithm improves the robustness and accuracy of ASR systems, particularly when working with imprecisely transcribed speech corpora. Our implementation will be open-sourced.
    
[^64]: PV2TEA：将视觉模态与基于文本的信息抽取相结合

    PV2TEA: Patching Visual Modality to Textual-Established Information Extraction. (arXiv:2306.01016v1 [cs.CL])

    [http://arxiv.org/abs/2306.01016](http://arxiv.org/abs/2306.01016)

    PV2TEA提出了一种基于编码器-解码器架构的信息抽取模型，在多模态注释困难的情况下解决了跨模态集成的问题，并提出了三种偏差降低方案。

    

    信息抽取（例如属性值提取）已被广泛研究和建模，但仅基于文本。然而，许多属性可以从基于图像的提取中受益，如颜色、形状、图案等。视觉模态长期以来一直未被充分利用，主要是由于多模态注释的难度。本文旨在将视觉模态与基于文本的属性信息提取器相结合。跨模态集成面临几个独特的挑战：（C1）图像和文本描述在样本内和样本间松散匹配；（C2）图像通常包含丰富的背景，可能会误导预测；（C3）来自基于文本的提取器的弱监督标签对于多模态训练存在偏差。我们提出了PV2TEA，这是一种编码器-解码器架构，配备了三种偏差降低方案：（S1）增强的标签平滑对比，以改进松散匹配的图像和文本的交叉模态对齐; （S2）注意力剪枝方案用于在保留正确信息的同时消除一些不必要的细节；（S3）基于对抗训练的可重组卷积自适应模块，以帮助消除来自文本提取器的偏差。

    Information extraction, e.g., attribute value extraction, has been extensively studied and formulated based only on text. However, many attributes can benefit from image-based extraction, like color, shape, pattern, among others. The visual modality has long been underutilized, mainly due to multimodal annotation difficulty. In this paper, we aim to patch the visual modality to the textual-established attribute information extractor. The cross-modality integration faces several unique challenges: (C1) images and textual descriptions are loosely paired intra-sample and inter-samples; (C2) images usually contain rich backgrounds that can mislead the prediction; (C3) weakly supervised labels from textual-established extractors are biased for multimodal training. We present PV2TEA, an encoder-decoder architecture equipped with three bias reduction schemes: (S1) Augmented label-smoothed contrast to improve the cross-modality alignment for loosely-paired image and text; (S2) Attention-prunin
    
[^65]: 如何评估预训练语音模型的迁移性？

    How to Estimate Model Transferability of Pre-Trained Speech Models?. (arXiv:2306.01015v1 [cs.CL])

    [http://arxiv.org/abs/2306.01015](http://arxiv.org/abs/2306.01015)

    本文介绍了一个新的框架，可以高效地评估预训练语音模型在微调目标任务时的迁移性。该框架利用两个表示理论，通过生成候选模型的排名分数，可以在不进行实际微调的情况下计算迁移性分数，实验结果表明该框架与微调基础事实之间存在很高的相关性和低的p值，是一个节省资源、高效节省时间的微调方法。

    

    本文提出了一个“基于分数评估”的框架，用于估计预训练语音模型（PSMs）在微调目标任务时的迁移性。我们利用两个表示理论，贝叶斯似然估计和最优传输，使用提取的表示生成PSM候选的排名分数。通过假设独立性，我们的框架可以高效地计算迁移性分数，而无需实际微调候选模型或层。我们使用公共数据在交叉层和交叉模型设置中评估了一些流行的监督语音模型（例如Conformer RNN-Transducer）和自监督语音模型（例如HuBERT）。实验结果显示，我们的估计框架与微调基础事实之间存在很高的Spearman排名相关性和低的p值。我们提出的迁移性框架需要较少的计算时间和资源，因此是一个节省资源、高效节省时间的微调方法。

    In this work, we introduce a ``score-based assessment'' framework for estimating the transferability of pre-trained speech models (PSMs) for fine-tuning target tasks. We leverage upon two representation theories, Bayesian likelihood estimation and optimal transport, to generate rank scores for the PSM candidates using the extracted representations. Our framework efficiently computes transferability scores without actual fine-tuning of candidate models or layers by making a temporal independent hypothesis. We evaluate some popular supervised speech models (e.g., Conformer RNN-Transducer) and self-supervised speech models (e.g., HuBERT) in cross-layer and cross-model settings using public data. Experimental results show a high Spearman's rank correlation and low $p$-value between our estimation framework and fine-tuning ground truth. Our proposed transferability framework requires less computational time and resources, making it a resource-saving and time-efficient approach for tuning sp
    
[^66]: 探究生成语言模型的演绎推理能力

    Examining the Emergence of Deductive Reasoning in Generative Language Models. (arXiv:2306.01009v1 [cs.CL])

    [http://arxiv.org/abs/2306.01009](http://arxiv.org/abs/2306.01009)

    本研究调查了不同规模的生成语言模型的演绎推理能力，发现随着规模的增加，推理能力增强，长度不会影响大部分模型表现。

    

    我们对生成变压器模型从前提中进行演绎推理的能力进行初步调查。我们观察到不同训练设置的模型性能存在显著差异，并发现演绎推理能力随规模增加而增强。此外，我们发现，除了OpenAI GPT-3和GPT-3.5模型，模型的表现通常不会随着推理链的长度而减弱。本研究考虑了从1.17亿到1750亿个参数的各种变压器解码器模型。

    We conduct a preliminary inquiry into the ability of generative transformer models to deductively reason from premises provided. We observe notable differences in the performance of models coming from different training setups and find that the deductive reasoning ability increases with scale. Further, we discover that the performance generally does not decrease with the length of the deductive chain needed to reach the conclusion, with the exception of OpenAI GPT-3 and GPT-3.5 models. Our study considers a wide variety of transformer-decoder models, ranging from 117 million to 175 billion parameters in size.
    
[^67]: 通过大型语言模型扩展基于证据的教学设计专业知识

    Scaling Evidence-based Instructional Design Expertise through Large Language Models. (arXiv:2306.01006v1 [cs.CL])

    [http://arxiv.org/abs/2306.01006](http://arxiv.org/abs/2306.01006)

    本文探讨了如何利用大型语言模型扩展基于证据的教学设计专业知识，通过两个案例研究展示了GPT-4在教学设计中的应用，并提供了使用LLMs的最佳实践和未来LLMs为所有学习者提供个性化教育内容的愿景。

    

    本文探讨了如何利用大型语言模型（LLMs），特别是GPT-4，来拓展教学设计领域的基于证据的专业知识。我们致力于弥合理论教育研究和实际实施之间的差距，探讨了AI驱动内容生成的优缺点，并强调了人工监督来确保教育材料的质量的必要性。通过两个详细的案例研究，我们展示了如何使用GPT-4创建不同课程的复杂高阶评估和积极学习组件。从我们的经验中，我们提供了在教学设计任务中有效使用LLMs的最佳实践，如利用模板，微调，处理意外的输出，实现LLM链，引用参考文献，评估输出，创建评分标准和生成干扰项。我们还分享了一个愿景，未来LLMs可以为所有背景和水平的学习者提供易于接受和个性化的教育内容。

    This paper presents a comprehensive exploration of leveraging Large Language Models (LLMs), specifically GPT-4, in the field of instructional design. With a focus on scaling evidence-based instructional design expertise, our research aims to bridge the gap between theoretical educational studies and practical implementation. We discuss the benefits and limitations of AI-driven content generation, emphasizing the necessity of human oversight in ensuring the quality of educational materials. This work is elucidated through two detailed case studies where we applied GPT-4 in creating complex higher-order assessments and active learning components for different courses. From our experiences, we provide best practices for effectively using LLMs in instructional design tasks, such as utilizing templates, fine-tuning, handling unexpected output, implementing LLM chains, citing references, evaluating output, creating rubrics, grading, and generating distractors. We also share our vision of a f
    
[^68]: AoM：用于多模态基于方面的情感分析中检测面向方面信息

    AoM: Detecting Aspect-oriented Information for Multimodal Aspect-Based Sentiment Analysis. (arXiv:2306.01004v1 [cs.CL])

    [http://arxiv.org/abs/2306.01004](http://arxiv.org/abs/2306.01004)

    本文提出了一个面向方面的方法(AoM)来检测与方面相关的语义和情感信息，并明确地将情感嵌入到AoM中。实验证明AoM在改进多模态基于方面的情感分析(MABSA)方面非常有效。

    

    多模态基于方面的情感分析(MABSA)旨在从文本-图像对中提取方面并识别它们的情感。现有方法致力于将整个图像与相应的方面对齐。然而，图像的不同区域可能与同一句子中的不同方面相关，粗略地建立图像-方面对齐会引入噪声到基于方面的情感分析中(即视觉噪声)。此外，特定方面的情感也可能被其他方面的描述所干扰(即文本噪声)。考虑到上述噪声，本文提出了一种面向方面的方法(AoM)来检测与方面相关的语义和情感信息。具体而言，设计了一个面向方面的注意力模块，同时选择与方面有语义关联的文本令牌和图像块。为了准确地聚合情感信息，我们明确地将情感嵌入到AoM中，并使用图卷积神经网络在不同模态中捕获依赖于方面的情感表达式。两个基准数据集上的实验结果表明了AoM在改进MABSA方面的有效性。

    Multimodal aspect-based sentiment analysis (MABSA) aims to extract aspects from text-image pairs and recognize their sentiments. Existing methods make great efforts to align the whole image to corresponding aspects. However, different regions of the image may relate to different aspects in the same sentence, and coarsely establishing image-aspect alignment will introduce noise to aspect-based sentiment analysis (i.e., visual noise). Besides, the sentiment of a specific aspect can also be interfered by descriptions of other aspects (i.e., textual noise). Considering the aforementioned noises, this paper proposes an Aspect-oriented Method (AoM) to detect aspect-relevant semantic and sentiment information. Specifically, an aspect-aware attention module is designed to simultaneously select textual tokens and image blocks that are semantically related to the aspects. To accurately aggregate sentiment information, we explicitly introduce sentiment embedding into AoM, and use a graph convolut
    
[^69]: 挑选文本转语音数据以增强自动语音识别训练的方法

    Towards Selection of Text-to-speech Data to Augment ASR Training. (arXiv:2306.00998v1 [eess.AS])

    [http://arxiv.org/abs/2306.00998](http://arxiv.org/abs/2306.00998)

    本文提出了一种从大规模文本转语音数据集中选择适当的合成语音样本作为自动语音识别（ASR）模型的补充训练数据的方法。在实验中表明，将具有相当差异的合成样本纳入ASR训练对于提高识别性能至关重要。我们提出的解决方案比其他方法能够将TTS数据的大小减少至30%以下的同时保持准确性。

    

    本文提出了一种方法，用于从给定的大规模文本转语音（TTS）数据集中选择适当的合成语音样本，作为自动语音识别（ASR）模型的补充训练数据。我们训练了一种神经网络，可以使用交叉熵损失或 Arcface 损失进行优化，来衡量合成数据与真实语音的相似度。我们发现，将具有相当差异的合成样本（部分原因是由于词汇差异）纳入 ASR 训练对于提高识别性能至关重要。在 Librispeech 测试集上进行的实验结果表明，为了保持与使用所有 TTS 数据时相同的语音识别精度，我们提出的解决方案可以将 TTS 数据的大小减少至其 30％ 以下，这比几种基准方法都要优秀。

    This paper presents a method for selecting appropriate synthetic speech samples from a given large text-to-speech (TTS) dataset as supplementary training data for an automatic speech recognition (ASR) model. We trained a neural network, which can be optimised using cross-entropy loss or Arcface loss, to measure the similarity of a synthetic data to real speech. We found that incorporating synthetic samples with considerable dissimilarity to real speech, owing in part to lexical differences, into ASR training is crucial for boosting recognition performance. Experimental results on Librispeech test sets indicate that, in order to maintain the same speech recognition accuracy as when using all TTS data, our proposed solution can reduce the size of the TTS data down below its $30\,\%$, which is superior to several baseline methods.
    
[^70]: 利用音素级建模进行失语性言语弱监督强制韵律对齐

    Weakly-supervised forced alignment of disfluent speech using phoneme-level modeling. (arXiv:2306.00996v1 [eess.AS])

    [http://arxiv.org/abs/2306.00996](http://arxiv.org/abs/2306.00996)

    本文提出了一种使用加权有限状态转换器对CTC模型的对齐图构建进行改进的弱监督方法，可以对失语性言语进行强制对齐，减轻了对逐字转录的需求，能够有效地在实际应用中使用，并在实验中取得了显著的改进。

    

    语言障碍的研究可以受益于时间对齐数据。然而，失语性言语中的音频-文本不匹配会导致现代语音对齐器的性能快速下降，从而阻碍了自动方法的使用。本文提出了一个简单有效的解决方法，即使用加权有限状态转换器对CTC模型的对齐图构建进行改进。该弱监督方法减轻了对失语性言语逐字转录实现强制对齐的需求。在图的构建过程中，我们允许对常见的失语现象进行建模，即重复和省略。此外，通过使用Oracle错误率评估音频-文本不匹配程度，我们的方法可以有效地在实际应用中使用。我们对TIMIT测试集和UCLASS数据集的损坏版本进行评估，显示出显著的改进，特别是召回率方面，在相对基线上实现了23-25%的相对改进。

    The study of speech disorders can benefit greatly from time-aligned data. However, audio-text mismatches in disfluent speech cause rapid performance degradation for modern speech aligners, hindering the use of automatic approaches. In this work, we propose a simple and effective modification of alignment graph construction of CTC-based models using Weighted Finite State Transducers. The proposed weakly-supervised approach alleviates the need for verbatim transcription of speech disfluencies for forced alignment. During the graph construction, we allow the modeling of common speech disfluencies, i.e. repetitions and omissions. Further, we show that by assessing the degree of audio-text mismatch through the use of Oracle Error Rate, our method can be effectively used in the wild. Our evaluation on a corrupted version of the TIMIT test set and the UCLASS dataset shows significant improvements, particularly for recall, achieving a 23-25% relative improvement over our baselines.
    
[^71]: 基于主题的模型比较解释：TopEx

    TopEx: Topic-based Explanations for Model Comparison. (arXiv:2306.00976v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00976](http://arxiv.org/abs/2306.00976)

    TopEx 是一种基于无模型主题的解释方法，使得语言模型的比较更公平，并可以在不同自然语言处理任务上识别模型之间的相似性和差异。

    

    目前的解释方法在大量词汇或跨模型比较方面过于庞大，使人类难以有意义地比较语言模型。本文提出了一种名为 TopEx 的解释方法，基于无模型的主题实现模型之间的对比，使得比较更公平。我们演示了 TopEx 如何在各种自然语言处理任务上识别 DistilRoBERTa 和 GPT-2 之间的相似性和差异。

    Meaningfully comparing language models is challenging with current explanation methods. Current explanations are overwhelming for humans due to large vocabularies or incomparable across models. We present TopEx, an explanation method that enables a level playing field for comparing language models via model-agnostic topics. We demonstrate how TopEx can identify similarities and differences between DistilRoBERTa and GPT-2 on a variety of NLP tasks.
    
[^72]: AfriNames：大多数ASR模型“屠戮”非洲人的名字

    AfriNames: Most ASR models "butcher" African Names. (arXiv:2306.00253v1 [cs.CL])

    [http://arxiv.org/abs/2306.00253](http://arxiv.org/abs/2306.00253)

    该论文探讨了自动语音识别模型在处理非洲名字时的性能问题，并提出了多语言预训练和数据增强等策略，通过微调ASR模型在多个非洲口音上，显著减少了模型误差，相对WER提高了81.5％。

    

    有效的对话代理必须准确捕捉命名实体，以最小化下游任务的错误，例如，要求语音助手播放特定艺术家的音轨，启动导航到特定位置，或为患者记录实验室结果。但是，当出现诸如“Ukachukwu”（伊博语）、“Lakicia”（斯瓦希里语）或“Ingabire”（卢旺达语）等命名实体时，自动语音识别（ASR）模型的性能显著降低，将错误传递到下游系统。我们将这个问题建模为分布偏移，并演示了通过多语言预训练、智能数据增强策略来增加非洲命名实体的表示，并在多个非洲口音上微调多语言ASR模型可以减轻模型偏差。结果表明，与基线相比，经过微调的模型在包含非洲命名实体的样本上相对WER改进了81.5％。

    Useful conversational agents must accurately capture named entities to minimize error for downstream tasks, for example, asking a voice assistant to play a track from a certain artist, initiating navigation to a specific location, or documenting a laboratory result for a patient. However, where named entities such as ``Ukachukwu`` (Igbo), ``Lakicia`` (Swahili), or ``Ingabire`` (Rwandan) are spoken, automatic speech recognition (ASR) models' performance degrades significantly, propagating errors to downstream systems. We model this problem as a distribution shift and demonstrate that such model bias can be mitigated through multilingual pre-training, intelligent data augmentation strategies to increase the representation of African-named entities, and fine-tuning multilingual ASR models on multiple African accents. The resulting fine-tuned models show an 81.5\% relative WER improvement compared with the baseline on samples with African-named entities.
    
[^73]: UKP-SQuARE: 一个用于教授问答技术的交互式工具

    UKP-SQuARE: An Interactive Tool for Teaching Question Answering. (arXiv:2305.19748v1 [cs.CL])

    [http://arxiv.org/abs/2305.19748](http://arxiv.org/abs/2305.19748)

    这篇论文介绍了UKP-SQuARE作为一个用于教授问答技术的交互式工具，学生可以通过其在不同角度了解各种QA模型，并借此获得理论概念和问题解决技能。

    

    问答技术的指数级增长使其成为任何自然语言处理（NLP）课程中不可或缺的话题。此外，这种指数级增长所导致的问答广度使其成为教授相关NLP主题（如信息检索、可解释性和对抗攻击等）的理想场景。本文介绍了UKP-SQuARE作为QA教育平台。该平台提供了一个交互式环境，在这里学生可以运行、比较和分析不同角度的各种QA模型，如一般行为，可解释性和鲁棒性。因此，学生可以在课堂上亲身体验不同的QA技术。由于这一点，我们提出了一种以学生为中心的QA教育方法，学生可以通过交互式的探索、实验和实践任务主动学习理论概念并获得问题解决技能，而不仅仅依赖传统的讲授。

    The exponential growth of question answering (QA) has made it an indispensable topic in any Natural Language Processing (NLP) course. Additionally, the breadth of QA derived from this exponential growth makes it an ideal scenario for teaching related NLP topics such as information retrieval, explainability, and adversarial attacks among others. In this paper, we introduce UKP-SQuARE as a platform for QA education. This platform provides an interactive environment where students can run, compare, and analyze various QA models from different perspectives, such as general behavior, explainability, and robustness. Therefore, students can get a first-hand experience in different QA techniques during the class. Thanks to this, we propose a learner-centered approach for QA education in which students proactively learn theoretical concepts and acquire problem-solving skills through interactive exploration, experimentation, and practical assignments, rather than solely relying on traditional le
    
[^74]: 基于关键词的采样（KEYS）在大规模语言模型中的应用

    KEYword based Sampling (KEYS) for Large Language Models. (arXiv:2305.18679v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18679](http://arxiv.org/abs/2305.18679)

    本文旨在探讨如何通过结合人类生成答案的思路来生成接近人类行为和事实的答案，并探讨关键词对Q/A任务解码算法的影响。

    

    问答（Q/A）任务可以被看作一个生成任务，即在给定问题和文章（如果有）的情况下生成答案。最近Q/A任务的进展主要关注语言模型的改进，而很少关注其他领域，如采样。关键词在人类语言生成中起着非常重要的作用。因此，本文旨在探索如何结合人类生成答案的行为来生成接近人类行为且事实正确的答案，并讨论关键词如何影响Q/A任务的解码算法。

    Question answering (Q/A) can be formulated as a generative task (Mitra, 2017) where the task is to generate an answer given the question and the passage (knowledge, if available). Recent advances in QA task is focused a lot on language model advancements and less on other areas such as sampling(Krishna et al., 2021), (Nakano et al., 2021). Keywords play very important role for humans in language generation. (Humans formulate keywords and use grammar to connect those keywords and work). In the research community, very little focus is on how humans generate answers to a question and how this behavior can be incorporated in a language model. In this paper, we want to explore these two areas combined, i.e., how sampling can be to used generate answers which are close to human-like behavior and factually correct. Hence, the type of decoding algorithm we think should be used for Q/A tasks should also depend on the keywords. These keywords can be obtained from the question, passage or interne
    
[^75]: 信仰与命运：Transformer在组合性方面的局限性。

    Faith and Fate: Limits of Transformers on Compositionality. (arXiv:2305.18654v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18654](http://arxiv.org/abs/2305.18654)

    研究了Transformer模型在三个代表性组合型任务中的表现，发现其通过线性子图匹配解决多步组合推理问题。

    

    Transformer大型语言模型在需要复杂多步推理的任务上表现卓越，但同时在一些简单问题上也会出现失败。这引发了疑问：这些错误是偶然的，还是它们表明了更实质性的限制？为了揭示Transformer的神秘面纱，我们研究了这些模型在三个代表性的组合型任务中的极限 - 多位数乘法、逻辑网格谜题和一个经典的动态规划问题。 这些任务需要将问题分解为子步骤，并将这些步骤综合成精确的答案。我们将组合型任务转化为计算图，以系统地量化其复杂性，并将推理步骤分解为中间子程序。我们的实证结果表明，Transformer通过将多步组合推理转化为线性子图匹配来解决组合型任务。

    Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify Transformers, we investigate the limits of these models across three representative compositional tasks -- multi-digit multiplication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that Transformers solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, wi
    
[^76]: 多尺度正负样本检测AI生成文本

    Multiscale Positive-Unlabeled Detection of AI-Generated Texts. (arXiv:2305.18149v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18149](http://arxiv.org/abs/2305.18149)

    本文提出了一种多尺度正负样本的训练框架，以解决多尺度AI生成文本的检测问题。通过将短机器文本标记为“未标记”来重新表述文本分类问题，并提出了一个规则化损失函数来优化检测性能，有效性能显著优于现有的方法。

    

    最近发布的大型语言模型（LLM）如ChatGPT等在生成类似于人类的文本方面令人惊讶，但它们可能被用于制造虚假的学术文本、虚假新闻、虚假推特等。先前的作品提出了检测这些多尺度AI生成文本的方法，包括简单的ML分类器、基于预训练模型的训练不可知方法和精调的语言分类模型。然而，主流检测器在构建时没有考虑到文本长度的因素：短文本的缺乏信息特征，使其更难检测。针对多尺度文本检测的挑战，本文提出了一个多尺度正负样本（MPU）训练框架。首先，我们承认短的机器文本具有类人属性，并将文本分类重新表述为一个正负样本问题，即通过在训练期间标记这些短的机器文本为"unlabeled"来解决这个问题。在这个正负样本的背景下，我们提出了

    Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are astonishing at generating human-like texts, but they may get misused for fake scholarly texts, fake news, fake tweets, et cetera. Previous works have proposed methods to detect these multiscale AI-generated texts, including simple ML classifiers, pretrained-model-based training-agnostic methods, and finetuned language classification models. However, mainstream detectors are formulated without considering the factor of corpus length: shorter corpuses are harder to detect compared with longer ones for shortage of informative features. In this paper, a Multiscale Positive-Unlabeled (MPU) training framework is proposed to address the challenge of multiscale text detection. Firstly, we acknowledge the human-resemblance property of short machine texts, and rephrase text classification as a Positive-Unlabeled (PU) problem by marking these short machine texts as "unlabeled" during training. In this PU context, we propose the le
    
[^77]: 基于多模态码本的文本图片翻译探索

    Exploring Better Text Image Translation with Multimodal Codebook. (arXiv:2305.17415v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17415](http://arxiv.org/abs/2305.17415)

    该研究提出了一个基于多模态码本的文本图片翻译模型。通过构建一个多阶段训练框架，利用了额外的双语文本和光学字符识别数据集，该模型能够将图像与相关文本关联起来，提供有用的补充信息，取得了比目前最先进的方法更好的效果。

    

    文本图片翻译是将图像中嵌入的原始文本翻译成目标语言的任务。该任务有着广泛的应用，并具有重要的研究价值。然而，目前的文本图片翻译研究面临两个主要瓶颈：1）缺少公开的文本图片翻译数据集；2）主流模型采用级联模式构建，容易受到光字符识别错误传播的影响。本文首先注释了一个名为OCRMT30K的中英文文本图片翻译数据集，为后续研究提供了便利。然后，我们提出了一种多模态码本的文本图片翻译模型，能够将图像与相关文本关联起来，提供有用的补充信息进行翻译。此外，我们提出了一个多阶段训练框架，包括文本机器翻译、图像文本对齐和文本图片翻译任务，充分利用了额外的双语文本、光字符识别数据集和OCRMT30K数据集来训练我们的模型。扩展实验表明，我们的模型优于最先进的方法，并达到了竞争性的表现。

    Text image translation (TIT) aims to translate the source texts embedded in the image to target translations, which has a wide range of applications and thus has important research value. However, current studies on TIT are confronted with two main bottlenecks: 1) this task lacks a publicly available TIT dataset, 2) dominant models are constructed in a cascaded manner, which tends to suffer from the error propagation of optical character recognition (OCR). In this work, we first annotate a Chinese-English TIT dataset named OCRMT30K, providing convenience for subsequent studies. Then, we propose a TIT model with a multimodal codebook, which is able to associate the image with relevant texts, providing useful supplementary information for translation. Moreover, we present a multi-stage training framework involving text machine translation, image-text alignment, and TIT tasks, which fully exploits additional bilingual texts, OCR dataset and our OCRMT30K dataset to train our model. Extensi
    
[^78]: 基于曲率和扭矩的手语视频摘要技术

    Motion-Based Sign Language Video Summarization using Curvature and Torsion. (arXiv:2305.16801v1 [cs.CV])

    [http://arxiv.org/abs/2305.16801](http://arxiv.org/abs/2305.16801)

    该论文介绍了一种基于曲率和扭矩的手语视频摘要技术，能够选出最具信息量的关键帧。

    

    视频摘要技术在很多基于视频的应用中都非常有用。本文介绍了一种新的手语视频摘要技术，该技术利用从视频帧中提取的三维手部运动数据来模型化每一帧中的三维运动。基于此，本文提出了一种基于曲率和扭矩的新型信息函数，以便选择最具信息量的关键帧。

    An interesting problem in many video-based applications is the generation of short synopses by selecting the most informative frames, a procedure which is known as video summarization. For sign language videos the benefits of using the $t$-parameterized counterpart of the curvature of the 2-D signer's wrist trajectory to identify keyframes, have been recently reported in the literature. In this paper we extend these ideas by modeling the 3-D hand motion that is extracted from each frame of the video. To this end we propose a new informative function based on the $t$-parameterized curvature and torsion of the 3-D trajectory. The method to characterize video frames as keyframes depends on whether the motion occurs in 2-D or 3-D space. Specifically, in the case of 3-D motion we look for the maxima of the harmonic mean of the curvature and torsion of the target's trajectory; in the planar motion case we seek for the maxima of the trajectory's curvature. The proposed 3-D feature is experime
    
[^79]: 长文本的神经自然语言处理：现状综述

    Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art. (arXiv:2305.16259v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16259](http://arxiv.org/abs/2305.16259)

    本文简要概述了长文本的神经自然语言处理的现状，主要包括文档分类和摘要，涵盖了情感分析，同时还探讨了长文本NLP的主要挑战、问题和解决方案。

    

    在过去的十年中，深度神经网络（DNN）的采用极大地促进了自然语言处理（NLP）的发展。然而，长文本分析的需求与短文本有很大不同，而网络上传输的文档大小不断增加，使长文本的自动理解成为一项关键的研究领域。本文的两个目标是：a）概述相关的神经构建模块，作为短教程；b）总结长文本NLP的现状，主要关注两个核心任务：文档分类和文档摘要。情感分析也涵盖在内，因为它通常被视为文档分类的特例。此外，本文还讨论了长文本NLP相关的主要挑战、问题和解决方案。最后，介绍了相关的公开的注释数据集，以便促进进一步研究。

    The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural Language Processing (NLP) during the past decade. However, the demands of long document analysis are quite different from those of shorter texts, while the ever increasing size of documents uploaded on-line renders automated understanding of long texts a critical area of research. This article has two goals: a) it overviews the relevant neural building blocks, thus serving as a short tutorial, and b) it surveys the state-of-the-art in long document NLP, mainly focusing on two central tasks: document classification and document summarization. Sentiment analysis for long texts is also covered, since it is typically treated as a particular case of document classification. Additionally, this article discusses the main challenges, issues and current solutions related to long document NLP. Finally, the relevant, publicly available, annotated datasets are presented, in order to facilitate further research.
    
[^80]: 在规模上重新审视非自回归翻译

    Revisiting Non-Autoregressive Translation at Scale. (arXiv:2305.16155v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16155](http://arxiv.org/abs/2305.16155)

    本文系统研究了缩放对非自回归翻译(NAT)行为的影响，证明了缩放可以提高NAT的翻译性能。通过异构体系结构可以实现有可比性的性能，同时保持标准NAT模型的高解码速度。

    

    在实际系统中，缩放是提高自回归翻译(AT)质量的关键，但对于非自回归翻译(NAT)尚未有充分研究。本研究通过系统研究缩放对NAT行为的影响来填补这一空白。在两个先进的NAT模型上进行了六个WMT基准测试的大量实验表明，缩放可以缓解NAT模型的常见缺陷，从而提高翻译性能。为了减少缩放对解码速度的副作用，我们经验性地研究了NAT编码器和解码器对翻译性能的影响。在大规模的WMT20 En-De数据集上的实验结果表明，异构体系结构(例如更大的编码器和较小的解码器)可以实现与缩放模型相当的性能，同时保持标准NAT模型的优越解码速度。因此，我们通过验证缩放NAT模型建立了一个新的基准。

    In real-world systems, scaling has been critical for improving the translation quality in autoregressive translation (AT), which however has not been well studied for non-autoregressive translation (NAT). In this work, we bridge the gap by systematically studying the impact of scaling on NAT behaviors. Extensive experiments on six WMT benchmarks over two advanced NAT models show that scaling can alleviate the commonly-cited weaknesses of NAT models, resulting in better translation performance. To reduce the side-effect of scaling on decoding speed, we empirically investigate the impact of NAT encoder and decoder on the translation performance. Experimental results on the large-scale WMT20 En-De show that the asymmetric architecture (e.g. bigger encoder and smaller decoder) can achieve comparable performance with the scaling model, while maintaining the superiority of decoding speed with standard NAT models. To this end, we establish a new benchmark by validating scaled NAT models on th
    
[^81]: 真实回答的语言特性研究

    Linguistic Properties of Truthful Response. (arXiv:2305.15875v1 [cs.CL])

    [http://arxiv.org/abs/2305.15875](http://arxiv.org/abs/2305.15875)

    该论文研究了LLM的不真实回答现象，发现GPT-3模型对给定提示的回答在语言特性上很相似。同时，该论文证明了在没有评估内容本身的情况下，仅依赖模型回答的风格成分即可分类真实性。

    

    我们使用220个手工制作的语言特性对LLM不真实回答的现象进行了研究。我们专注于GPT-3模型，并发现不同大小的LLM对给定提示的回答在语言特性上很相似。我们通过训练只依赖模型回答的风格成分来分类陈述真实性的支持向量机扩展了这一发现。虽然数据集大小限制了我们的当前研究成果，但我们提供了有希望的证据，表明可以在不评估内容本身的情况下检测真实性。

    We investigate the phenomenon of an LLM's untruthful response using a large set of 220 handcrafted linguistic features. We focus on GPT-3 models and find that the linguistic profiles of responses are similar across model sizes. That is, how varying-sized LLMs respond to given prompts stays similar on the linguistic properties level. We expand upon this finding by training support vector machines that rely only upon the stylistic components of model responses to classify the truthfulness of statements. Though the dataset size limits our current findings, we present promising evidence that truthfulness detection is possible without evaluating the content itself.
    
[^82]: SenteCon: 利用词汇表学习人类可解释的语言表示

    SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations. (arXiv:2305.14728v1 [cs.CL])

    [http://arxiv.org/abs/2305.14728](http://arxiv.org/abs/2305.14728)

    SenteCon是一种能够提供高级可解释性的方法，通过把文本编码为可解释类别的层，同时不会对下游任务的预测性能造成影响。

    

    近年来，深度语言表示已成为语言特征化的主要形式，但在许多情况下，了解模型的决策过程是很重要的。这不仅需要一个可解释的模型，还需要可解释的特征。特别是，语言必须以可解释的方式特征化，同时仍然很好地描述原始文本。我们提出了SenteCon，一种在深度语言表示中引入人类可解释性的方法。给定一个文本段落，SenteCon将文本编码为可解释类别的层，其中每个维度对应于特定类别的相关性。我们的实证评估表明，使用SenteCon对语言进行编码可以在对下游任务的预测性能几乎没有成本的情况下提供高级可解释性。此外，我们发现，在下游性能和协议方面，SenteCon优于现有的可解释语言表示。

    Although deep language representations have become the dominant form of language featurization in recent years, in many settings it is important to understand a model's decision-making process. This necessitates not only an interpretable model but also interpretable features. In particular, language must be featurized in a way that is interpretable while still characterizing the original text well. We present SenteCon, a method for introducing human interpretability in deep language representations. Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks. Moreover, we find that SenteCon outperforms existing interpretable language representations with respect to both its downstream performance and its agr
    
[^83]: 优化对比学习的非自回归Transformer

    Optimizing Non-Autoregressive Transformers with Contrastive Learning. (arXiv:2305.13667v1 [cs.CL])

    [http://arxiv.org/abs/2305.13667](http://arxiv.org/abs/2305.13667)

    本文通过从模型分布中采样来缓解NATs学习多模态数据分布的困难，并导出对比约束来稳定训练过程。该方法在机器翻译、文本摘要和改写三个任务上优于以前的非自回归基线。

    

    非自回归Transformer (NATs) 可以同时预测所有单词，而不是按顺序预测，从而减少了自回归Transformer（ATs）的推断延迟。它们在机器翻译以及许多其他应用中取得了显着的进展。然而，NATs 长期以来面临的挑战是学习多模态数据分布，这是 NATs 和 ATs 性能差距的主要原因。本文提出通过从模型分布中采样来缓解模态学习的困难，而不是从数据分布中采样。我们导出对比约束来稳定训练过程，并将此结果的目标与最先进的 NAT 架构 DA-Transformer 集成。我们的模型在机器翻译、文本摘要和改写这3个任务中进行了检验，共使用了5种基准测试。结果表明，我们的方法在性能上显著优于以前的非自回归基线，并确立了

    Non-autoregressive Transformers (NATs) reduce the inference latency of Autoregressive Transformers (ATs) by predicting words all at once rather than in sequential order. They have achieved remarkable progress in machine translation as well as many other applications. However, a long-standing challenge for NATs is the learning of multi-modality data distribution, which is the main cause of the performance gap between NATs and ATs. In this paper, we propose to ease the difficulty of modality learning via sampling from the model distribution instead of the data distribution. We derive contrastive constraints to stabilize the training process and integrate this resulting objective with the state-of-the-art NAT architecture DA-Transformer. Our model \method is examined on 3 different tasks, including machine translation, text summarization, and paraphrasing with 5 benchmarks. Results show that our approach outperforms previous non-autoregressive baselines by a significant margin and establi
    
[^84]: 零样本多语言神经机器翻译中的“离谱问题”

    On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation. (arXiv:2305.10930v1 [cs.CL])

    [http://arxiv.org/abs/2305.10930](http://arxiv.org/abs/2305.10930)

    零样本多语言神经机器翻译容易出现“离谱问题”，本文提出的简单且有效的算法LAVS可以通过增加语言之间的KL分歧显著降低这个问题。

    

    尽管多语言神经机器翻译取得了巨大成功，但它仍然存在“离谱问题”，即将翻译输出到错误的语言中。这个问题在零样本翻译任务中更加明显。本文发现，当编码目标语言信号时失效，会导致离谱问题，并且两种语言词汇之间更接近的词汇距离（即KL分歧）与更高的离谱率有关。此外，本文还发现，仅隔离解码器中不同语言的词汇可以缓解这个问题。基于这些发现，我们提出了一种简单有效的算法Language Aware Vocabulary Sharing (LAVS)来构建多语言词汇表，通过增加语言之间的KL分歧，大大减轻了翻译模型的离谱问题。我们在11种语言的多语言翻译基准测试上进行了实验。实验结果表明，对于90个翻译任务，采用LAVS的离谱率降低了37％至90％。

    While multilingual neural machine translation has achieved great success, it suffers from the off-target issue, where the translation is in the wrong language. This problem is more pronounced on zero-shot translation tasks. In this work, we find that failing in encoding discriminative target language signal will lead to off-target and a closer lexical distance (i.e., KL-divergence) between two languages' vocabularies is related with a higher off-target rate. We also find that solely isolating the vocab of different languages in the decoder can alleviate the problem. Motivated by the findings, we propose Language Aware Vocabulary Sharing (LAVS), a simple and effective algorithm to construct the multilingual vocabulary, that greatly alleviates the off-target problem of the translation model by increasing the KL-divergence between languages. We conduct experiments on a multilingual machine translation benchmark in 11 languages. Experiments show that the off-target rate for 90 translation 
    
[^85]: 你在抄我的模型吗？基于后门水印的保护大语言模型在 EaaS 中的版权

    Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark. (arXiv:2305.10036v1 [cs.CL])

    [http://arxiv.org/abs/2305.10036](http://arxiv.org/abs/2305.10036)

    提出了一种名为 EmbMarker 的嵌入式水印方法，用于保护大型语言模型在 EaaS 中的版权。该方法可以在嵌入式上植入后门，并有效地传输和恢复。实验证明，EmbMarker 可以在维护各种 NLP 任务的性能的同时成功保护 EaaS 对 LLM 的版权。

    

    大型语言模型已经展示了在文本理解和生成方面的强大能力。公司已经开始基于这些大型语言模型提供嵌入式服务 (EaaS)，可以为客户的各种自然语言处理 (NLP) 任务带来益处。然而，先前的研究表明，EaaS 易受到模型提取攻击的攻击，这可能会对 LLM 的所有者造成巨大损失，因为训练这些模型非常昂贵。为了保护 EaaS 的 LLM 的版权，我们提出了一个名为 EmbMarker 的嵌入式水印方法，该方法在嵌入式上植入后门。我们的方法从通用文本语料库中选择一组中等频率的单词，形成触发集，然后选择一个目标嵌入作为水印，并将其插入包含触发词的文本的嵌入中作为后门。插入的重量与包含在文本中的触发词数量成比例。这使得水印后门可以有效地传输和恢复，而不影响 LLM 在各种 NLP 任务中的性能。实验证明，EmbMarker 可以在维护各种 NLP 任务的性能的同时成功保护 EaaS 对 LLM 的版权。

    Large language models (LLMs) have demonstrated powerful capabilities in both text understanding and generation. Companies have begun to offer Embedding as a Service (EaaS) based on these LLMs, which can benefit various natural language processing (NLP) tasks for customers. However, previous studies have shown that EaaS is vulnerable to model extraction attacks, which can cause significant losses for the owners of LLMs, as training these models is extremely expensive. To protect the copyright of LLMs for EaaS, we propose an Embedding Watermark method called EmbMarker that implants backdoors on embeddings. Our method selects a group of moderate-frequency words from a general text corpus to form a trigger set, then selects a target embedding as the watermark, and inserts it into the embeddings of texts containing trigger words as the backdoor. The weight of insertion is proportional to the number of trigger words included in the text. This allows the watermark backdoor to be effectively t
    
[^86]: “我全然成为我自己”：以TGNB人群为中心，评估开放式语言生成中的偏见

    "I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation. (arXiv:2305.09941v1 [cs.CL])

    [http://arxiv.org/abs/2305.09941](http://arxiv.org/abs/2305.09941)

    本论文研究了如何以TGNB人群的声音为中心，评估开放式语言生成中的偏见。通过理解TGNB个体的经历，提出了以TGNB人群为中心的OLG系统评估框架，并且包括一个为TGNB人群设计的调查工具和分析方法。

    

    跨性别和非二元（TGNB）人群在日常生活中经历了不成比例的歧视和排斥。随着语言生成技术的日益普及和应用，进一步边缘化这一人群的可能性也在增加。虽然大量的NLP公平文献着重于阐明和解决性别偏见，但评估TGNB身份所带来的性别伤害需要理解这些身份如何独特地与社会性别规范互动以及与性别二元中心的视角相区分。这样的测量框架本质上需要以TGNB声音为中心，帮助指导包容性别的自然语言处理应该为谁服务。为实现这一目标，我们以TGNB社区和现有的跨学科文献为基础，评估了TGNB个体经历边缘化所形成的社会现实是如何影响和存在于开放式语言生成（OLG）中。首先理解TGNB个体的经历，我们提出了一个评估OLG系统的框架，旨在以TGNB人群为中心，度量与该人群相关的偏见。我们的框架包括特别为TGNB人群设计的调查工具，以及交叉分析结果的交叉方法。我们相信，这项工作将有助于实现更公平、更包容的自然语言处理社区，并潜在地解决NLP研究中广泛的交叉身份问题。

    Transgender and non-binary (TGNB) individuals disproportionately experience discrimination and exclusion from daily life. Given the recent popularity and adoption of language generation technologies, the potential to further marginalize this population only grows. Although a multitude of NLP fairness literature focuses on illuminating and addressing gender biases, assessing gender harms for TGNB identities requires understanding how such identities uniquely interact with societal gender norms and how they differ from gender binary-centric perspectives. Such measurement frameworks inherently require centering TGNB voices to help guide the alignment between gender-inclusive NLP and whom they are intended to serve. Towards this goal, we ground our work in the TGNB community and existing interdisciplinary literature to assess how the social reality surrounding experienced marginalization by TGNB persons contributes to and persists within Open Language Generation (OLG). By first understandi
    
[^87]: 基于文本的金融预测模型的一致性评估

    Measuring Consistency in Text-based Financial Forecasting Models. (arXiv:2305.08524v1 [cs.CL])

    [http://arxiv.org/abs/2305.08524](http://arxiv.org/abs/2305.08524)

    金融预测中模型的一致性对于建立用户信任至关重要，但目前金融预测方法很少考虑这一点，我们提出了一种评估金融文本逻辑一致性的评估工具FinTrust，并使用它发现最先进的金融预测NLP模型的一致性较差。

    

    金融预测是机器学习研究中一个重要且活跃的领域，因为即使是最小的预测准确率提高也可以转化为巨大的财务收益。自然语言处理方面的最新进展带来了利用文本数据（如上市公司的盈利报告）来预测资产收益率的机会。然而，在处理这种敏感任务时，模型的一致性——即在输入的保留意义改变时对模型的影响是一个建立用户信任的关键属性，但当前的金融预测方法却没有考虑到这一点。因此，我们提出了FinTrust，一种评估金融文本中逻辑一致性的评估工具。使用FinTrust，我们发现目前最先进的金融预测NLP模型的一致性较差。我们对保留意义改变引起的性能降级进行分析，结果表明...

    Financial forecasting has been an important and active area of machine learning research, as even the most modest advantage in predictive accuracy can be parlayed into significant financial gains. Recent advances in natural language processing (NLP) bring the opportunity to leverage textual data, such as earnings reports of publicly traded companies, to predict the return rate for an asset. However, when dealing with such a sensitive task, the consistency of models -- their invariance under meaning-preserving alternations in input -is a crucial property for building user trust. Despite this, current financial forecasting methods do not consider consistency. To address this problem, we propose FinTrust, an evaluation tool that assesses logical consistency in financial text. Using FinTrust, we show that the consistency of state-of-the-art NLP models for financial forecasting is poor. Our analysis of the performance degradation caused by meaning-preserving alternations suggests that cur
    
[^88]: ProKnow：用于安全限制和可解释问题生成的流程知识在心理健康诊断辅助中的应用

    ProKnow: Process Knowledge for Safety Constrained and Explainable Question Generation for Mental Health Diagnostic Assistance. (arXiv:2305.08010v1 [cs.CL])

    [http://arxiv.org/abs/2305.08010](http://arxiv.org/abs/2305.08010)

    本论文提出了ProKnow的概念，它可以提高虚拟心理健康助手的安全性和专业性。同时开发了自然语言问题生成算法，通过明确建模安全性、知识捕获和可解释性来模拟流程知识。在抑郁症和焦虑症中的实验表明，使用ProKnow引导的算法可以生成更安全的问题。

    

    目前的虚拟心理健康助手（VMHA）提供辅导和建议护理。它们不进行患者诊断协助，因为它们缺乏安全受限和专业临床流程知识的培训。 在这项工作中，我们定义Proknow为一组有序信息，它映射到领域专家的基于证据的指南或概念理解类别。我们还介绍了一种由安全限制和Proknow引导的诊断对话的新数据集，这是医疗保健专业人员使用的。我们开发了一种自然语言问题生成（NLG）方法，可以与患者交互收集诊断信息。我们证明了在此数据集上使用最先进的大规模语言模型（LM）的局限性。我们的算法通过明确地建模安全性，知识捕获和可解释性来模拟流程知识。使用ProKnow引导的LM增强方法在抑郁症和焦虑症中生成了89％更安全的问题。

    Current Virtual Mental Health Assistants (VMHAs) provide counseling and suggestive care. They refrain from patient diagnostic assistance because they lack training in safety-constrained and specialized clinical process knowledge. In this work, we define Proknow as an ordered set of information that maps to evidence-based guidelines or categories of conceptual understanding to experts in a domain. We also introduce a new dataset of diagnostic conversations guided by safety constraints and Proknow that healthcare professionals use. We develop a method for natural language question generation (NLG) that collects diagnostic information from the patient interactively. We demonstrate the limitations of using state-of-the-art large-scale language models (LMs) on this dataset. Our algorithm models the process knowledge through explicitly modeling safety, knowledge capture, and explainability. LMs augmented with ProKnow guided method generated 89% safer questions in the depression and anxiety d
    
[^89]: 使用联合CTC损失和自监督预训练的声学编码器的端到端口语理解

    End-to-end spoken language understanding using joint CTC loss and self-supervised, pretrained acoustic encoders. (arXiv:2305.02937v1 [cs.CL])

    [http://arxiv.org/abs/2305.02937](http://arxiv.org/abs/2305.02937)

    本文提出了一种使用联合CTC损失和预训练声学编码器的基于端到端的口语理解模型，该方法实现了在两个数据集上超越SOTA模型的效果。

    

    在口语理解任务中，由于缺乏文本信息，直接从声音信号中提取语义意义是具有挑战性的。流行的端到端（E2E）口语理解模型利用序列到序列自动语音识别（ASR）模型提取文本嵌入作为输入来推断语义，但是这需要昂贵的自回归解码。在这项工作中，我们利用自监督声学编码器，Fine-tuned Connectionist Temporal Classification（CTC）来提取文本嵌入，并使用联合CTC和SLU损失进行话语级口语理解任务。实验表明，我们的模型在DSTC2数据集上对话行为分类模型取得了4％的绝对改进，并在SLURP数据集上超越了SOTA SLU模型1.3％的绝对改进。

    It is challenging to extract semantic meanings directly from audio signals in spoken language understanding (SLU), due to the lack of textual information. Popular end-to-end (E2E) SLU models utilize sequence-to-sequence automatic speech recognition (ASR) models to extract textual embeddings as input to infer semantics, which, however, require computationally expensive auto-regressive decoding. In this work, we leverage self-supervised acoustic encoders fine-tuned with Connectionist Temporal Classification (CTC) to extract textual embeddings and use joint CTC and SLU losses for utterance-level SLU tasks. Experiments show that our model achieves 4% absolute improvement over the the state-of-the-art (SOTA) dialogue act classification model on the DSTC2 dataset and 1.3% absolute improvement over the SOTA SLU model on the SLURP dataset.
    
[^90]: 关于AI生成文本检测的可能性的探讨

    On the Possibilities of AI-Generated Text Detection. (arXiv:2304.04736v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.04736](http://arxiv.org/abs/2304.04736)

    该研究探讨了AI生成文本检测的可能性，提出了精确的样本复杂度界限，并指出了设计更准确的检测方法和提高透明度的挑战。

    

    我们的工作着眼于检测由大型语言模型(LLM)生成的输出，以区分其与人类生成的输出。这项能力在许多应用中非常重要。然而，关于这种区分的可能性一直是该领域内的争议话题。因此，一个核心问题是我们是否能够检测到AI生成的文本，如果能，何时能检测到。在这项工作中，我们提供了证据表明，除非人类和机器生成的文本分布在整个支持中完全相同，否则几乎总是可以检测到AI生成的文本。这个观察结果来自于信息论中的标准结果，并依赖于机器生成的文本越像人类，我们就需要更多的样本来检测它。我们得出了AI生成文本检测的精确样本复杂度界限，告诉需要多少个样本才能检测到AI生成的文本。这引起了更多设计更准确的AI生成文本检测方法和提高LLM透明度的挑战。

    Our work focuses on the challenge of detecting outputs generated by Large Language Models (LLMs) to distinguish them from those generated by humans. This ability is of the utmost importance in numerous applications. However, the possibility of such discernment has been the subject of debate within the community. Therefore, a central question is whether we can detect AI-generated text and, if so, when. In this work, we provide evidence that it should almost always be possible to detect AI-generated text unless the distributions of human and machine-generated texts are exactly the same over the entire support. This observation follows from the standard results in information theory and relies on the fact that if the machine text becomes more human-like, we need more samples to detect it. We derive a precise sample complexity bound of AI-generated text detection, which tells how many samples are needed to detect AI-generated text. This gives rise to additional challenges of designing more
    
[^91]: 快速密集信息检索器利用KALE进行后置KL对齐的异形双编码器模型训练 (arXiv:2304.01016v2 [cs.CL] UPDATED)

    Quick Dense Retrievers Consume KALE: Post Training Kullback Leibler Alignment of Embeddings for Asymmetrical dual encoders. (arXiv:2304.01016v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.01016](http://arxiv.org/abs/2304.01016)

    本文提出了一种通过结构压缩和模型尺寸不对称的双编码器模型 KALE，有效提高密集信息检索的推理效率，同时允许查询编码器的有效压缩，而无需进行全部的再训练或索引生成，此方法能够生成超过DistilBERT性能的模型。

    

    本文提出了一种有结构压缩和模型尺寸不对称的双编码器模型，旨在提高基于语言模型的密集信息检索系统的推理速度。通过对MSMARCO、自然问答、问答游戏等多个数据集进行前后训练压缩实验，研究了压缩对系统推理效率的影响，结果表明密集信息检索器的双编码器结构异形化有助于提高其推理效率。基于此，我们引入了一种名为Kullback Leibler Alignment of Embeddings (KALE)的方法，通过裁剪和对齐查询编码器，提高了密集信息检索的推理效率。KALE扩展了传统的知识蒸馏方法，使得在双编码器训练后可以有效地对查询编码器进行压缩而无需进行完整的再训练或索引生成。使用KALE和不对称训练，我们可以生成超过DistilBERT性能的模型，同时模型尺寸更小。

    In this paper, we consider the problem of improving the inference latency of language model-based dense retrieval systems by introducing structural compression and model size asymmetry between the context and query encoders. First, we investigate the impact of pre and post-training compression on the MSMARCO, Natural Questions, TriviaQA, SQUAD, and SCIFACT, finding that asymmetry in the dual encoders in dense retrieval can lead to improved inference efficiency. Knowing this, we introduce Kullback Leibler Alignment of Embeddings (KALE), an efficient and accurate method for increasing the inference efficiency of dense retrieval methods by pruning and aligning the query encoder after training. Specifically, KALE extends traditional Knowledge Distillation after bi-encoder training, allowing for effective query encoder compression without full retraining or index generation. Using KALE and asymmetric training, we can generate models which exceed the performance of DistilBERT despite having 
    
[^92]: 多输入假设和受限解码空间的 N-best T5：利用多输入假设和受限解码空间的强鲁棒 ASR 错误校正

    N-best T5: Robust ASR Error Correction using Multiple Input Hypotheses and Constrained Decoding Space. (arXiv:2303.00456v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.00456](http://arxiv.org/abs/2303.00456)

    本文提出了一种新的 N-best T5 模型，该模型利用 ASR N-best 列表作为输入，并使用受限解码过程，从而实现了针对 ASR 错误修正的强鲁棒性能。

    

    错误修正模型是自动语音识别（ASR）后处理的重要部分，用于提高转录的可读性和质量。本文提出了一种新的 N-best T5 模型，该模型利用 ASR N-best 列表作为模型的输入。通过从预训练语言模型中转移知识并从 ASR 解码空间中获取更丰富的信息，所提出的方法优于强Conformer-Transducer基线。标准错误校正的另一个问题是生成过程不受良好指导。为了解决这个问题，使用基于 N-best 列表或 ASR lattice 的受限解码过程，可以传播额外的信息。

    Error correction models form an important part of Automatic Speech Recognition (ASR) post-processing to improve the readability and quality of transcriptions. Most prior works use the 1-best ASR hypothesis as input and therefore can only perform correction by leveraging the context within one sentence. In this work, we propose a novel N-best T5 model for this task, which is fine-tuned from a T5 model and utilizes ASR N-best lists as model input. By transferring knowledge from the pre-trained language model and obtaining richer information from the ASR decoding space, the proposed approach outperforms a strong Conformer-Transducer baseline. Another issue with standard error correction is that the generation process is not well-guided. To address this a constrained decoding process, either based on the N-best list or an ASR lattice, is used which allows additional information to be propagated.
    
[^93]: 流体变压器与创造性类比：探索大语言模型增强跨领域类比创造力的能力

    Fluid Transformers and Creative Analogies: Exploring Large Language Models' Capacity for Augmenting Cross-Domain Analogical Creativity. (arXiv:2302.12832v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12832](http://arxiv.org/abs/2302.12832)

    本文系统地探讨了大语言模型增强跨领域类比创造力的能力，结果表明LLM生成的跨领域类比在问题重构中具有实际帮助，并且存在一些潜在的危害，需要注意。

    

    跨领域的类比推理是一种对人类来说具有挑战性的核心创造能力。最近的研究已经证明了大语言模型（LLMs）生成跨领域类比的能力。然而，这种能力的可靠性和潜在用途的探索却鲜有系统的研究。本文系统地探讨了LLMs增强跨领域类比推理的能力。在三项研究中，我们发现：1）LLM生成的跨领域类比在问题重构任务的背景下经常被评为有帮助（中位数5个评分中有4个是有帮助的），并且通常（约80％的情况）导致问题重新制定方面的可观察变化；2）存在最多25％的输出被评为有潜在危害的上限，其中大部分是由于潜在的不安内容，而不是有偏见或有毒内容。这些结果证明了LLMs的潜在效用和风险，以增强跨领域类比推理的能力。

    Cross-domain analogical reasoning is a core creative ability that can be challenging for humans. Recent work has shown some proofs-of concept of Large language Models' (LLMs) ability to generate cross-domain analogies. However, the reliability and potential usefulness of this capacity for augmenting human creative work has received little systematic exploration. In this paper, we systematically explore LLMs capacity to augment cross-domain analogical reasoning. Across three studies, we found: 1) LLM-generated cross-domain analogies were frequently judged as helpful in the context of a problem reformulation task (median 4 out of 5 helpfulness rating), and frequently (~80% of cases) led to observable changes in problem formulations, and 2) there was an upper bound of 25% of outputs bring rated as potentially harmful, with a majority due to potentially upsetting content, rather than biased or toxic content. These results demonstrate the potential utility -- and risks -- of LLMs for augmen
    
[^94]: ChatGPT：应付千事的万能型 AI，但无所专精

    ChatGPT: Jack of all trades, master of none. (arXiv:2302.10724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.10724](http://arxiv.org/abs/2302.10724)

    本研究检验了 ChatGPT 在 25 个不同的 NLP 任务上的性能，它是一个万能的 AI 模型，但无关紧要的表现可能会对某些任务的表现产生负面影响。

    

    OpenAI 推出了聊天生成预训练 Transformer（ChatGPT），革新了人工智能与人类互动的方法。许多研究通过测试 ChatGPT 在众所周知的自然语言处理（NLP）任务中的效果，来评估该模型的效能。然而，现有的研究大多非自动化，并且规模非常有限。本研究在 25 个不同的 NLP 任务上检验了 ChatGPT 的性能，其中大多数任务甚至对人类而言都是主观的，例如情感分析、情绪识别、攻击性和立场检测。另一些任务则需要更客观的推理，如词义消歧、语言可接受性和问答。我们还对 GPT-4 模型在五个选定的 NLP 任务子集上进行了评估。我们自动化了 ChatGPT 和 GPT-4 的引导过程，并分析了超过 49k 个响应。与现有最先进的解决方案（SOTA）进行比较，我们的结果显示，在一些任务上 ChatGPT 的性能存在一定的缺陷。

    OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quali
    
[^95]: 迭代的种种：从Elgot到Kleene

    Shades of Iteration: from Elgot to Kleene. (arXiv:2301.06202v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2301.06202](http://arxiv.org/abs/2301.06202)

    本文介绍了Elgot monads和Kleene monads之间的形式联系，并提出一种新的while-monad类。虽然Kleene monads是相对简单的代数描述，但是while-monads可能不符合Kleene代数定律，或者甚至不支持Kleene迭代运算符。

    

    迭代概念从最通用的Elgot迭代到非常特定的Kleene迭代不等。 Bloom和Esik已经以迭代理论的形式广泛探讨了Elgot迭代的基本本质，而Kleene迭代则作为（无类型的）形式主义的重要组成部分变得非常流行，例如自动机理论，正则表达式和Kleene代数。在这里，我们通过Elgot单子和Kleene单子建立Elgot迭代和Kleene迭代之间的形式连接。 我们还介绍了一种新的while-monad类，类似于Kleene monads，但在代数术语中有相对简单的描述。与Elgot单子一样，while-monads涵盖了支持while循环的大量模型，但可能不符合Kleene代数定律，甚至可能根本不支持Kleene迭代运算符。

    Notions of iteration range from the arguably most general Elgot iteration to a very specific Kleene iteration. The fundamental nature of Elgot iteration has been extensively explored by Bloom and Esik in the form of iteration theories, while Kleene iteration became extremely popular as an integral part of (untyped) formalisms, such as automata theory, regular expressions and Kleene algebra. Here, we establish a formal connection between Elgot iteration and Kleene iteration in the form of Elgot monads and Kleene monads, respectively. We also introduce a novel class of while-monads, which like Kleene monads admit a relatively simple description in algebraic terms. Like Elgot monads, while-monads cover a large variety of models that meaningfully support while-loops, but may fail the Kleene algebra laws, or even fail to support a Kleen iteration operator altogether.
    
[^96]: 《真探》：一项深度模因推理基准，难倒GPT-3，对GPT-4构成挑战（arXiv：2212.10114v2 [cs.CL] UPDATED）

    True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4. (arXiv:2212.10114v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10114](http://arxiv.org/abs/2212.10114)

    本文介绍了一项深度模因推理基准测试，由191个侦探故事谜题构成，只有47%的人能成功解决其中一个谜题。研究表明，GPT-3模型在此基准测试中准确性仅为28％，而GPT-4仅能解决38%的谜题。这表明LLMs与人类在深度推理能力上仍存在显著差距，需要进一步的研究。

    

    大型语言模型（LLMs）已经证明了它们的零-shot推理能力，并在当前的测试任务中表现出色。这需要一个更具挑战性的基准测试，需要解决高度先进的推理问题。在本文中，我们介绍了这样一个基准测试，由191个包含长篇故事（平均1200个单词）的侦探谜题构成。题目来自“5分钟的谜”平台，并包括用于评估的多项选择题。仅有47%的人平均能成功解决一个谜题，而最好的人类解谜者则能够取得超过80%的成功率。我们展示了GPT-3模型在这个基准测试上的表现仅略胜于随机猜测（准确率28%），而最先进的GPT-4仅能解决38%的谜题。这表明，LLMs与人类在深度推理能力上仍存在显著差距，并凸显了对这个领域进一步研究的需求。我们的研究引入了一个具有挑战性的基准测试，为未来的研究提供了方向。

    Large language models (LLMs) have demonstrated solid zero-shot reasoning capabilities, which is reflected in their performance on the current test tasks. This calls for a more challenging benchmark requiring highly advanced reasoning ability to be solved. In this paper, we introduce such a benchmark, consisting of 191 long-form (1200 words on average) mystery narratives constructed as detective puzzles. Puzzles are sourced from the "5 Minute Mystery" platform and include a multiple-choice question for evaluation. Only 47% of humans solve a puzzle successfully on average, while the best human solvers achieve over 80% success rate. We show that GPT-3 models barely outperform random on this benchmark (with 28% accuracy) while state-of-the-art GPT-4 solves only 38% of puzzles. This indicates that there is still a significant gap in the deep reasoning abilities of LLMs and humans and highlights the need for further research in this area. Our work introduces a challenging benchmark for futur
    
[^97]: 当联邦学习遇到预训练语言模型的参数高效调整方法

    When Federated Learning Meets Pre-trained Language Models' Parameter-Efficient Tuning Methods. (arXiv:2212.10025v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10025](http://arxiv.org/abs/2212.10025)

    本文在隐私敏感的自然语言处理任务中探讨了联邦学习如何与参数高效调整方法结合以解决数据异质性问题，在维持可接受性能的同时显著减少通信开销。

    

    随着对数据隐私关注的增加，最近的研究在隐私敏感的自然语言处理（NLP）任务中使用联邦学习（FL）取得了显著进展。很多文献建议在 FL 范式中完全微调预训练语言模型（PLMs）可以缓解数据异质性问题，缩小与集中式训练的性能差距。然而，大型 PLMs 带来了沉重的通信开销和 FL 系统的本地模型适应成本。为此，我们将各种参数高效调整（PETuning）方法引入到联邦学习中。具体而言，我们提供了一个全面的经验研究，研究了 FL 中代表性的 PLMs 调整方法。实验结果覆盖了数据异质性水平、数据规模和不同 FL 场景的分析。在维持可接受性能的同时，通过本地调整和全局聚合轻量级模型参数，可以显著减少总的通信开销。

    With increasing privacy concerns on data, recent studies have made significant progress using federated learning (FL) on privacy-sensitive natural language processing (NLP) tasks. Much literature suggests fully fine-tuning pre-trained language models (PLMs) in the FL paradigm can mitigate the data heterogeneity problem and close the performance gap with centralized training. However, large PLMs bring the curse of prohibitive communication overhead and local model adaptation costs for the FL system. To this end, we introduce various parameter-efficient tuning (PETuning) methods into federated learning. Specifically, we provide a holistic empirical study of representative PLMs tuning methods in FL. The experimental results cover the analysis of data heterogeneity levels, data scales, and different FL scenarios. Overall communication overhead can be significantly reduced by locally tuning and globally aggregating lightweight model parameters while maintaining acceptable performance in var
    
[^98]: 文本中的离群检测的多层知识蒸馏

    Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text. (arXiv:2211.11300v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.11300](http://arxiv.org/abs/2211.11300)

    本文提出了一种多层知识蒸馏方法，融合了语言模型的训练和微调方法来进行文本中的离群检测，实验结果表明其有效性。

    

    自监督表示学习已经证明是只使用内分布(ID)样例文本进行离群检测的宝贵组成部分。这些方法要么从头开始训练语言模型，要么通过使用ID样例微调预训练语言模型，然后将语言模型输出的困惑度作为离群得分。本文分析了两种离群检测方法的互补特性，并提出了一种融合它们优势并减轻它们的局限性的多层知识蒸馏方法。具体而言，我们使用微调模型作为老师，在ID示例上教授一个随机初始化的学生模型。除了预测层蒸馏外，我们还提出了一种基于相似性的中间层蒸馏方法，以全面探索老师模型的表示空间。通过这种方式，学习的学生可以更好地表示ID数据流形，同时获得更强的将OoD示例映射到流形之外的能力。基准数据集上的实验结果证明了我们所提出的方法与竞争基线相比的有效性。

    Self-supervised representation learning has proved to be a valuable component for out-of-distribution (OoD) detection with only the texts of in-distribution (ID) examples. These approaches either train a language model from scratch or fine-tune a pre-trained language model using ID examples, and then take the perplexity output by the language model as OoD scores. In this paper, we analyze the complementary characteristics of both OoD detection methods and propose a multi-level knowledge distillation approach that integrates their strengths while mitigating their limitations. Specifically, we use a fine-tuned model as the teacher to teach a randomly initialized student model on the ID examples. Besides the prediction layer distillation, we present a similarity-based intermediate layer distillation method to thoroughly explore the representation space of the teacher model. In this way, the learned student can better represent the ID data manifold while gaining a stronger ability to map O
    
[^99]: 为什么小鸡要穿过马路？重述和分析 VQA 中的歧义问题。

    Why Did the Chicken Cross the Road? Rephrasing and Analyzing Ambiguous Questions in VQA. (arXiv:2211.07516v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07516](http://arxiv.org/abs/2211.07516)

    本文提出了一个新的数据集，针对图像问题的歧义性问题进行了研究，通过重新构述问题并分组答案来减少歧义。同时，开发了一种英语问题生成模型，该模型能够产生更少歧义的问题。

    

    自然语言具有歧义性，解决歧义问题对于成功回答问题至关重要。本文着眼于关于图像的问题，创建了一个歧义问题的数据集，对其进行了注释，通过重新构述问题并将答案按其所回答的问题进行分组，以减少歧义。我们的分析揭示了视觉问题中歧义原因的与语言对齐本体论。然后，我们开发了一种英语问题生成模型，通过自动和人工评估展示其能够产生较少歧义的问题。我们进一步表明，我们使用的问题生成目标允许模型在没有任何直接指导的情况下集成答案组信息。

    Natural language is ambiguous. Resolving ambiguous questions is key to successfully answering them. Focusing on questions about images, we create a dataset of ambiguous examples. We annotate these, grouping answers by the underlying question they address and rephrasing the question for each group to reduce ambiguity. Our analysis reveals a linguistically-aligned ontology of reasons for ambiguity in visual questions. We then develop an English question-generation model which we demonstrate via automatic and human evaluation produces less ambiguous questions. We further show that the question generation objective we use allows the model to integrate answer group information without any direct supervision.
    
[^100]: 用信息论评估自由文本解释的可行性

    REV: Information-Theoretic Evaluation of Free-Text Rationales. (arXiv:2210.04982v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04982](http://arxiv.org/abs/2210.04982)

    本论文提出了一种名为REV的度量，用于评估自由文本解释中新颖、与标签相关的信息的数量，通过信息论的角度进行研究。实验证明REV在评估解释-标签对方面的有效性，并且与人类直觉一致。

    

    生成自由文本解释是迈向可解释 NLP 的一个有前途的步骤，然而评估这样的解释仍然是一个挑战。现有的度量主要集中在测量解释和给定标签之间的关联性上。我们认为，理想的度量应该集中于解释中提供的新信息，这些信息在输入或标签中都没有提供。我们从信息论的角度使用条件V-信息（Hewitt et al。，2021）研究了这个研究问题。更具体地说，我们提出了一个名为REV（利用条件V-信息评估解释）的度量，用于量化理性中除了输入或标签中已有信息之外的新标签相关信息的数量。在涉及推理任务的四个基准测试中进行的实验证明了REV在评估解释-标签对方面的有效性，与现有的度量相比。我们进一步证明REV与人类直觉一致，而一些现有的度量则不一致。

    Generating free-text rationales is a promising step towards explainable NLP, yet evaluating such rationales remains a challenge. Existing metrics have mostly focused on measuring the association between the rationale and a given label. We argue that an ideal metric should focus on the new information uniquely provided in the rationale that is otherwise not provided in the input or the label. We investigate this research problem from an information-theoretic perspective using conditional V-information (Hewitt et al., 2021). More concretely, we propose a metric called REV (Rationale Evaluation with conditional V-information), to quantify the amount of new, label-relevant information in a rationale beyond the information already available in the input or the label. Experiments across four benchmarks with reasoning tasks, including chain-of-thought, demonstrate the effectiveness of REV in evaluating rationale-label pairs, compared to existing metrics. We further demonstrate REV is consiste
    
[^101]: 通过推理时自适应优化实现语言生成中的统一去毒化和去偏见

    Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization. (arXiv:2210.04492v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04492](http://arxiv.org/abs/2210.04492)

    本文提出了名为UDDIA的统一去毒化和去偏见框架，它能够有效地消除有毒语言和减少社会偏见，同时保持流畅性。

    

    近年来，预训练语言模型在各种自然语言生成任务中取得了很好的表现。然而，这些模型在训练语料库中捕捉和复制有害内容的情况普遍存在，特别是毒性语言和社会偏见，引起了严重的道德问题。此前在道德上的自然语言生成方面的工作都是分开解决去毒化和去偏见这两个问题的，但我们发现去偏见的模型仍然存在毒性，而经过去毒化的模型甚至会加剧社会偏见，这是有问题的。为了解决这个挑战，我们提出了名为UDDIA的统一去毒化和去偏见框架，将这两个问题作为纠正输出空间的关键问题联合形式化。我们在理论上将我们的框架解释为学习混合加权属性的文本分布。此外，UDDIA对少量参数进行自适应优化，从而控制每个属性的贡献。我们证明了UDDIA能够有效地消除有毒语言并减少社会偏见，同时保持流畅性。此外，UDDIA在广泛的评估中优于最先进的去毒化和去偏见方法。我们还进行了深入的分析，解释了UDDIA的行为，并为未来在道德自然语言生成方面的工作提供了见解。

    Warning: this paper contains model outputs exhibiting offensiveness and biases. Recently pre-trained language models (PLMs) have prospered in various natural language generation (NLG) tasks due to their ability to generate fairly fluent text. Nevertheless, these models are observed to capture and reproduce harmful contents in training corpora, typically toxic language and social biases, raising severe moral issues. Prior works on ethical NLG tackle detoxifying and debiasing separately, which is problematic since we find debiased models still exhibit toxicity while detoxified ones even exacerbate social biases. To address such a challenge, we propose the first unified framework of detoxifying and debiasing called UDDIA, which jointly formalizes these two problems as rectifying the output space. We theoretically interpret our framework as learning a text distribution mixing weighted attributes. Besides, UDDIA conducts adaptive optimization of only a few parameters during decoding based o
    
[^102]: ThinkSum：使用大型语言模型进行集合的概率推理

    ThinkSum: Probabilistic reasoning over sets using large language models. (arXiv:2210.01293v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.01293](http://arxiv.org/abs/2210.01293)

    本研究提出一种两阶段的概率推理范例ThinkSum，通过以结构化的方式对对象或事实集进行推理，实现了对多个对象或事实进行推理并进行逻辑推导的场景中的改进。

    

    大型语言模型（LLMs）在高级类比推理方面具有显著的能力：重现线性文本中出现在它们的训练数据（零样本评估）或提供的上下文中的模式（少量样本在上下文中学习）。然而，最近的研究表明，即使是更先进的LLMs在需要对多个对象或事实进行推理并进行逻辑推导的场景中也会失败。我们提出了一种两阶段的概率推理范例ThinkSum，它以结构化的方式对对象或事实集进行推理。在第一阶段（Think-检索关联）中，LLM在从提示或辅助模型调用提取的短语集上并行查询。在第二阶段（Sum概率推理或推理）中，聚合这些查询的结果以进行最终预测。我们在BIG-bench LLM评估任务套件上展示了ThinkSum的可能性和优势，取得了超越基准的改进。

    Large language models (LLMs) have a substantial capacity for high-level analogical reasoning: reproducing patterns in linear text that occur in their training data (zero-shot evaluation) or in the provided context (few-shot in-context learning). However, recent studies show that even the more advanced LLMs fail in scenarios that require reasoning over multiple objects or facts and making sequences of logical deductions. We propose a two-stage probabilistic inference paradigm, ThinkSum, which reasons over sets of objects or facts in a structured manner. In the first stage (Think - retrieval of associations), a LLM is queried in parallel over a set of phrases extracted from the prompt or an auxiliary model call. In the second stage (Sum probabilistic inference or reasoning), the results of these queries are aggregated to make the final prediction. We demonstrate the possibilities and advantages of ThinkSum on the BIG-bench suite of LLM evaluation tasks, achieving improvements over the 
    
[^103]: BertNet：从预训练语言模型中提取任意关系的知识图谱

    BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models. (arXiv:2206.14268v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.14268](http://arxiv.org/abs/2206.14268)

    本文提出了一种从预训练语言模型中提取任意关系的知识图谱的方法，通过最小的关系定义输入，实现在庞大的实体对空间中搜索，提取准确的知识。

    

    自动构建多种关系的知识图谱以支持知识发现和广泛应用是至关重要的。以往的知识图谱构建方法基于众包或文本挖掘，往往由于手动成本或文本语料库的限制而仅限于小型预定义关系集。最近的研究提出使用预训练的语言模型作为隐式的知识库，以接受提示的知识查询。然而，这种隐式知识缺少完整符号知识图谱的许多理想属性，如易于访问、导航、编辑和质量保证。本文提出一种新的方法，从预训练语言模型中提取大规模的任意关系的知识图谱。通过最小的关系定义输入（提示和示例实体对的短语），该方法可以有效地在庞大的实体对空间中搜索，提取所需关系的多样准确的知识。我们开发了一个有效的搜索和重新评分的机制，让这个方法更加实用。

    It is crucial to automatically construct knowledge graphs (KGs) of diverse new relations to support knowledge discovery and broad applications. Previous KG construction methods, based on either crowdsourcing or text mining, are often limited to a small predefined set of relations due to manual cost or restrictions in text corpus. Recent research proposed to use pretrained language models (LMs) as implicit knowledge bases that accept knowledge queries with prompts. Yet, the implicit knowledge lacks many desirable properties of a full-scale symbolic KG, such as easy access, navigation, editing, and quality assurance. In this paper, we propose a new approach of harvesting massive KGs of arbitrary relations from pretrained LMs. With minimal input of a relation definition (a prompt and a few shot of example entity pairs), the approach efficiently searches in the vast entity pair space to extract diverse accurate knowledge of the desired relation. We develop an effective search-and-rescore m
    
[^104]: PhysNLU：一种用于评估物理学自然语言理解和解释连贯性的语言资源

    PhysNLU: A Language Resource for Evaluating Natural Language Understanding and Explanation Coherence in Physics. (arXiv:2201.04275v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.04275](http://arxiv.org/abs/2201.04275)

    这篇论文提供了一个语言资源集合，用于评估语言模型在物理学自然语言理解和解释连贯性方面的表现。论文分析物理话语中最常见的方程和子学科，并提出了表现较差的基准，即使训练了数学自然语言任务，当代语言模型也会在物理相关的连贯性任务中面临挑战。

    

    为了让语言模型能够帮助物理研究，它们必须首先对数学和自然语言话语进行编码，从而实现连贯的解释，正确排序和陈述的相关性。我们提供了一组数据集，用于评估语言模型在这方面的性能，这些数据集衡量了句子排序，位置，部分预测和话语连贯性方面的能力。数据分析揭示了在物理话语中最常见的方程和子学科，以及方程和表达式在句子层面上的频率。我们提出了一些基准，证明了当在数学自然语言任务上得到训练时，即使是当代的语言模型也会在物理相关的连贯性任务中遇到挑战。

    In order for language models to aid physics research, they must first encode representations of mathematical and natural language discourse which lead to coherent explanations, with correct ordering and relevance of statements. We present a collection of datasets developed to evaluate the performance of language models in this regard, which measure capabilities with respect to sentence ordering, position, section prediction, and discourse coherence. Analysis of the data reveals equations and sub-disciplines which are most common in physics discourse, as well as the sentence-level frequency of equations and expressions. We present baselines that demonstrate how contemporary language models are challenged by coherence related tasks in physics, even when trained on mathematical natural language objectives.
    
[^105]: 基于情感和句子类型对YouTube评论进行分类

    Classifying YouTube Comments Based on Sentiment and Type of Sentence. (arXiv:2111.01908v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2111.01908](http://arxiv.org/abs/2111.01908)

    本论文提出了一种基于情感和句子类型的方法，将原始的YouTube评论分类，以帮助YouTuber找到更相关的评论，从而增加其观众群。

    

    随着YouTube频道的增长，每个视频都可能收集大量评论，这些评论是理解观众期望和改善频道参与度的主要手段。然而，这些评论只代表用户关于频道和内容的一般观点。许多评论构造较差，琐碎并且存在拼写和语法错误，因此，识别最能吸引内容创作者的评论是一项繁琐的工作。本文旨在通过情感和句子类型将原始评论分类，以帮助YouTuber找到更相关的评论，从而增加其观众群。

    As a YouTube channel grows, each video can potentially collect enormous amounts of comments that provide direct feedback from the viewers. These comments are a major means of understanding viewer expectations and improving channel engagement. However, the comments only represent a general collection of user opinions about the channel and the content. Many comments are poorly constructed, trivial, and have improper spellings and grammatical errors. As a result, it is a tedious job to identify the comments that best interest the content creators. In this paper, we extract and classify the raw comments into different categories based on both sentiment and sentence types that will help YouTubers find relevant comments for growing their viewership. Existing studies have focused either on sentiment analysis (positive and negative) or classification of sub-types within the same sentence types (e.g., types of questions) on a text corpus. These have limited application on non-traditional text c
    
[^106]: 句法感知的图转换器用于语义角色标注

    Syntax-Aware Graph-to-Graph Transformer for Semantic Role Labelling. (arXiv:2104.07704v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2104.07704](http://arxiv.org/abs/2104.07704)

    本文提出了一种句法感知的图转换器模型用于语义角色标注任务，该模型将句法结构以嵌入的方式输入到Transformer的自注意机制中，达到了比以往方法更好的性能。

    

    最近的模型表明，将句法知识纳入语义角色标注（SRL）任务可以显着改善性能。本文提出了一种称为 Syntax-aware Graph-to-Graph Transformer（SynG2G-Tr）的模型，它使用一种新颖的方式将图关系转换为嵌入，直接输入到Transformer的自注意机制中编码句法结构。这种方法为遵循句法结构的注意力模式增加了柔性偏差，但也允许模型利用这些信息学习替代模式。我们对基于跨度和基于依存的SRL数据集进行了评估，在CoNLL 2005和 CoNLL 2009数据集中，我们在内外领域的基准测试中均优于先前的替代方法。

    Recent models have shown that incorporating syntactic knowledge into the semantic role labelling (SRL) task leads to a significant improvement. In this paper, we propose Syntax-aware Graph-to-Graph Transformer (SynG2G-Tr) model, which encodes the syntactic structure using a novel way to input graph relations as embeddings, directly into the self-attention mechanism of Transformer. This approach adds a soft bias towards attention patterns that follow the syntactic structure but also allows the model to use this information to learn alternative patterns. We evaluate our model on both span-based and dependency-based SRL datasets, and outperform previous alternative methods in both in-domain and out-of-domain settings, on CoNLL 2005 and CoNLL 2009 datasets.
    
[^107]: Transformer层间参数共享的教训（arXiv：2104.06022v4 [cs.CL]更新）

    Lessons on Parameter Sharing across Layers in Transformers. (arXiv:2104.06022v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2104.06022](http://arxiv.org/abs/2104.06022)

    该论文提出了一种放宽常用参数共享技术的Transformer参数共享方法，其可以提高计算时间的效率，通过三种策略来分配每个层的参数，在实验中表现出高效的参数大小和计算时间，并在使用大量训练数据的配置中同样有效。

    

    我们提出了一种Transformer参数共享方法（Vaswani等人，2017）。所提出的方法放宽了一种被广泛使用的技术，即将一个层的参数与所有层共享，如通用Transformer（Dehghani等人，2019），以增加计算时间的效率。我们提出了三种策略：序列、循环和循环（反向）来分配每个层的参数。实验结果表明，所提出的策略在参数大小和计算时间上是有效的。此外，我们还表明了所提出的策略在使用许多训练数据的配置中也是有效的，例如最近的WMT比赛。

    We propose a parameter sharing method for Transformers (Vaswani et al., 2017). The proposed approach relaxes a widely used technique, which shares parameters for one layer with all layers such as Universal Transformers (Dehghani et al., 2019), to increase the efficiency in the computational time. We propose three strategies: Sequence, Cycle, and Cycle (rev) to assign parameters to each layer. Experimental results show that the proposed strategies are efficient in the parameter size and computational time. Moreover, we indicate that the proposed strategies are also effective in the configuration where we use many training data such as the recent WMT competition.
    

