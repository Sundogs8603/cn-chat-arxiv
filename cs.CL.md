# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores.](http://arxiv.org/abs/2306.01879) | 我们提出了VisualGPTScore方法，能够使用多模态生成分数捕捉文本标题可能性，并在图像条件语言模型上进行计算，具备组合推理能力。 |
| [^2] | [Knowledge of cultural moral norms in large language models.](http://arxiv.org/abs/2306.01857) | 本研究探究了英文语言模型对多文化背景下道德规范的理解程度，分析了模型对道德变化的把握能力和道德多样性以及共同倾向。研究表明，预训练的英文语言模型对跨国家的道德规范预测不如对英国道德规范的预测。 |
| [^3] | [5IDER: Unified Query Rewriting for Steering, Intent Carryover, Disfluencies, Entity Carryover and Repair.](http://arxiv.org/abs/2306.01855) | 本文介绍了一种非自回归的查询重写体系结构，该体系不仅可以处理对话引导、意图携带、语法中断、实体携带和修复这五个任务，还可以处理它们的复杂组合。 |
| [^4] | [Binary and Ternary Natural Language Generation.](http://arxiv.org/abs/2306.01841) | 本文提出了基于混合方法的二进制和三进制变压器模型，在摘要和机器翻译任务上取得了不错的效果，并在效率上获得了大幅度提升。 |
| [^5] | [Beta Thalassemia Carriers detection empowered federated Learning.](http://arxiv.org/abs/2306.01818) | 本论文介绍了一种使用联邦学习技术的方法，快速、便宜、无需移动设备地检测Beta地中海贫血携带者。 |
| [^6] | [Word Embeddings for Banking Industry.](http://arxiv.org/abs/2306.01807) | 本文研究了面向银行业的词嵌入，发现其比广泛可用的词嵌入更能捕捉银行特定语义和词相关性，因此可作为NL任务的一个良好独立来源或者补充。 |
| [^7] | [Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes.](http://arxiv.org/abs/2306.01805) | 本文研究了使用生成AI方法来扩展当前的食品计算模型，将烹饪行为纳入考虑，以实现更全面的健康食谱推荐。 |
| [^8] | [Edit Distance based RL for RNNT decoding.](http://arxiv.org/abs/2306.01789) | 本文提出了一种基于编辑距离的强化学习方法，用于最小化RNN-T训练和推理过程之间的差距，并在LibriSpeech的600M Conformer RNN-T模型上取得了最佳结果。 |
| [^9] | [Conceptual Design Generation Using Large Language Models.](http://arxiv.org/abs/2306.01779) | 本文利用大型语言模型生成解决方案，并将其与众包解决方案进行比较。专家评估表明，LLM生成的解决方案具有更高的可行性和有用性，众包的解决方案更加具有创意性。 |
| [^10] | [A Quantitative Review on Language Model Efficiency Research.](http://arxiv.org/abs/2306.01768) | 这篇论文从定量方面对基于Transformers和State Space Models的一系列研究进行了综述，并总结了如何提高语言模型效率。 |
| [^11] | [Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning.](http://arxiv.org/abs/2306.01761) | 本文提出了一种机器学习方法，可以识别出由ChatGPT生成的文本，并以11种算法进行了分类对比分析，在测试中取得了77%的准确度。 |
| [^12] | [Training Priors Predict Text-To-Image Model Performance.](http://arxiv.org/abs/2306.01755) | 本文测试了文本到图像模型对于训练先验的依赖程度，发现模型能够更好地生成与训练数据中出现频率更高的三元组对齐的图像，但这也会降低其生成以翻转三元组为基础的图像质量。 |
| [^13] | [Preconditioned Visual Language Inference with Weak Supervision.](http://arxiv.org/abs/2306.01753) | 本文提出了一个名为PVLIR的预处理视觉语言推理和合理化任务，结果揭示了当前最先进的视觉语言模型在此项任务上的缺陷，并提出了改进这些模型的挑战。 |
| [^14] | [Abugida Normalizer and Parser for Unicode texts.](http://arxiv.org/abs/2306.01743) | 本论文提出了两个针对Indic语言Unicode书写方案中常见及不常见问题的工具库，分别是纠正不一致性的规范化器和Abugida文本的字形解析器，使用这两个工具可以提高400%的速度并显著改善下游任务表现。 |
| [^15] | [Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech Detection.](http://arxiv.org/abs/2306.01742) | 本研究旨在找到计算效率高、可比或更好的希望言论检测方法，并公开了代码库。 |
| [^16] | [Comparative study on Judgment Text Classification for Transformer Based Models.](http://arxiv.org/abs/2306.01739) | 本研究对6个不同的基于自我注意力的Transformer模型进行了比较研究，并针对4种激活函数进行了调整，以用于判决文本分类。该方法可以帮助在法律诉讼中进行引用和先例参考。 |
| [^17] | [Assessing the Importance of Frequency versus Compositionality for Subword-based Tokenization in NMT.](http://arxiv.org/abs/2306.01393) | 本文通过实验发现，在NMT中基于子词的分词方法中，频率对于模型的表现贡献占据了90%-95%，因此相对于组合性，频率更为重要。 |
| [^18] | [Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction.](http://arxiv.org/abs/2306.00418) | 本文提出了一种新的方法来控制标记级的生成、提高原始学习和减少错误，其中包括蒙特卡洛dropout、边缘非似然学习和最小化熵。在四个公共数据集上的广泛实验表明，该方法有效地提高了情感四元组预测的性能。 |
| [^19] | [A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets.](http://arxiv.org/abs/2305.18486) | 本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。 |
| [^20] | [In-Context Analogical Reasoning with Pre-Trained Language Models.](http://arxiv.org/abs/2305.17626) | 本研究提出了一种基于语言模型的情境类比推理方法，通过将问题的感知特征编码成语言形式，能够实现高效的零-shot关系推理，超越传统方法和人类水平。 |
| [^21] | [Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark.](http://arxiv.org/abs/2305.17553) | 该论文探讨了大型语言模型编辑技术的现状，发现现有的特异性基准测试难以检测到不良副作用，并提出了一个改进的基准测试，该测试可以检测到动态组件，并通过基于KL散度的指标扩展了特异性的衡量方式。研究发现最近的模型编辑技术特异性较低，强调了改进特异性基准测试的重要性。 |
| [^22] | [Answering Unanswered Questions through Semantic Reformulations in Spoken QA.](http://arxiv.org/abs/2305.17393) | 本研究提出了语义问答重构模型 (SURF)，通过三个基于语言学的操作来重写口语问答中存在的词汇、命题、句法和特异性等问题，提高了回答率，能够帮助语音助手更好地回答未回答的问题。 |
| [^23] | [On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss.](http://arxiv.org/abs/2305.17182) | 无监督NMT中的复制问题通常发生在远距离语种对中且会直接复制输入句子的部分作为翻译，本研究提出了一种包含语言鉴别器损失的训练计划来缓解该问题，并提高低资源语种的翻译性能。 |
| [^24] | [Learning to Imagine: Visually-Augmented Natural Language Generation.](http://arxiv.org/abs/2305.16944) | 本研究提出了一种称为LIVE的方法，通过视觉增强学习生成自然语言的想象，并针对每个句子进行动态合成，大量实验测试表明它可以有效提高生成质量。 |
| [^25] | [NLP Reproducibility For All: Understanding Experiences of Beginners.](http://arxiv.org/abs/2305.16579) | 通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。 |
| [^26] | [Counterfactual Probing for the influence of affect and specificity on Intergroup Bias.](http://arxiv.org/abs/2305.16409) | 本文研究了特异性和情感两个语用特征在不同群体背景下是否会出现系统性变化，并将其与自然语言输出中的新群体偏见框架相联系。初步分析表明，推文的特异性和情感程度与监督的群体关系标签之间存在一定的相关性，而因果推断揭示了神经模型在分类时可靠地使用情感，但其对特异性的使用是不确定的。 |
| [^27] | [Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer.](http://arxiv.org/abs/2305.16380) | 本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。 |
| [^28] | [Improving Self-training for Cross-lingual Named Entity Recognition with Contrastive and Prototype Learning.](http://arxiv.org/abs/2305.13628) | 本文提出了一种名为ContProto的方法，通过对比自我训练和基于原型的伪标记，结合表示学习和伪标签精化，在一个一致的框架中提高了跨语言命名实体识别的自训练方法；实验结果表明，ContProto 方法在多个转移对上优于最先进的基准，并在各种基准上取得了显着的改进。 |
| [^29] | [Constructing Code-mixed Universal Dependency Forest for Unbiased Cross-lingual Relation Extraction.](http://arxiv.org/abs/2305.12258) | 本文提出了一种无偏的UD树跨语言关系抽取转移方法，通过构建混合编码UD树，有助于弥合训练和预测阶段之间差距从而实现显著的跨语言关系抽取性能提升。 |
| [^30] | [Reasoning Implicit Sentiment with Chain-of-Thought Prompting.](http://arxiv.org/abs/2305.11255) | 本研究提出了一种基于思维链索引的隐式情感推断框架（THOR），通过三次跳推理模仿类人推理过程，支持常识和多跳推理以推断意见的潜在意图，并逐步诱导隐式方面、意见和最终情感极性，实现了在监督和零样本设置上大幅提高技术水平。 |
| [^31] | [Large Language Models can be Guided to Evade AI-Generated Text Detection.](http://arxiv.org/abs/2305.10847) | 本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。 |
| [^32] | [Learning to Simulate Natural Language Feedback for Interactive Semantic Parsing.](http://arxiv.org/abs/2305.08195) | 本研究提出了通过模拟自然语言反馈来进行交互式语义解析的新任务，该方法可以在低数据情况下取得与使用人工注释反馈数据训练所获得的相当的错误纠正性能。 |
| [^33] | [A First Look at LLM-Powered Generative News Recommendation.](http://arxiv.org/abs/2305.06566) | 本文介绍了一种LLM驱动的生成式新闻推荐框架GENRE，它利用预训练语义知识丰富新闻数据，通过从模型设计转移到提示设计提供灵活而统一的解决方案，实现了个性化新闻生成、用户画像和新闻摘要。 |
| [^34] | [Boosting Radiology Report Generation by Infusing Comparison Prior.](http://arxiv.org/abs/2305.04561) | 本论文提出一种利用基于规则的标记器提取比较先验信息的方法，将其无缝地集成到transformer-based模型中，从而提高生成放射学报告的准确性和全面性，实现了在评估指标上的最先进性能。 |
| [^35] | [Target-Side Augmentation for Document-Level Machine Translation.](http://arxiv.org/abs/2305.04505) | 本文介绍了一种目标侧数据增强方法，通过引入一个数据增强模型来为每个源文档生成潜在的翻译，从而降低了文本级机器翻译的数据稀疏性的风险，得到了比以前最好的系统高2.30 s-BLEU并在基准测试中取得了新的最优结果。 |
| [^36] | [Self-Edit: Fault-Aware Code Editor for Code Generation.](http://arxiv.org/abs/2305.04087) | 本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。 |
| [^37] | [Few-shot Domain-Adaptive Visually-fused Event Detection from Text.](http://arxiv.org/abs/2305.03517) | 本文提出了一种基于视觉融合和领域自适应的事件检测方法，可以用少量标记数据训练并且适应于新领域。 |
| [^38] | [SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation.](http://arxiv.org/abs/2305.03506) | SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。 |
| [^39] | [Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat.](http://arxiv.org/abs/2305.02220) | 本文介绍了使用大型语言模型从医生-患者对话中自动生成临床笔记的研究，采用少样本上下文学习法所生成笔记表现优秀，且可与人工编写的笔记媲美。 |
| [^40] | [Impact of Position Bias on Language Models in Token Classification.](http://arxiv.org/abs/2304.13567) | 研究了语言模型在token分类任务中的位置偏差问题，通过实验表明在具体任务中，BERT、ERNIE、ELECTRA等编码器以及GPT2和BLOOM等解码器的平均性能下降了3%和9%。 |
| [^41] | [Evaluating Inter-Bilingual Semantic Parsing for Indian Languages.](http://arxiv.org/abs/2304.13005) | 本研究提出了一个11种不同的印度语言的间语言Seq2seq语义分析数据集IE-SEMPARSE，并评估了现有的多语言seq2seq模型在其中的表现。 |
| [^42] | [Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations.](http://arxiv.org/abs/2304.08216) | 本论文利用预训练变换器语言模型的上下文依赖性嵌入话语表示，从而在对话情绪识别中取得了非常良好的效果。 |
| [^43] | [Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through Japanese stylometric analysis.](http://arxiv.org/abs/2304.05534) | 本研究通过比较GPT(-3.5和-4)生成的日语文体特征与人类写作的学术论文，证明了它们在文体特征上有显著区别。 |
| [^44] | [To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency.](http://arxiv.org/abs/2304.02721) | 本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。 |
| [^45] | [Exploring Partial Knowledge Base Inference in Biomedical Entity Linking.](http://arxiv.org/abs/2303.10330) | 本文探索了生物医学实体链接中的部分知识库推理问题，发现由于精度下降导致EL性能出现灾难性下降，而且EL范例无法处理无法链接的提及，提出了两种赎回方法来解决NIL问题。 |
| [^46] | [The Science of Detecting LLM-Generated Texts.](http://arxiv.org/abs/2303.07205) | 本文综述了现有大型语言模型生成文本检测技术并提出了关键考虑因素，如开发全面评估指标和开源 LLM 所构成的威胁。 |
| [^47] | [In-context Example Selection with Influences.](http://arxiv.org/abs/2302.11042) | 本文提出使用带有影响力的示例选择方法来提高上下文学习(ICL)的性能，分析表明正面和负面示例对ICL取得的性能有高达16.3%的影响，案例研究中也发现了示例排序中的“最近性偏差”现象。 |
| [^48] | [Pre-training for Speech Translation: CTC Meets Optimal Transport.](http://arxiv.org/abs/2301.11716) | 本文提出了一种基于CTC和最优传输的语音翻译预训练方法，可以有效减小语音和文本模态之间的差距，提高最终的ST准确性。 |
| [^49] | [ExaRanker: Explanation-Augmented Neural Ranker.](http://arxiv.org/abs/2301.10521) | 本文提出了一个名为ExaRanker的解释增强型神经排序模型，使用大型语言模型增强检索数据集，可在输出相关度标签与解释时提高性能。 |
| [^50] | [Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute.](http://arxiv.org/abs/2301.10448) | 本文提出了一种检索增强的混合方法，LUMEN，它预先计算大部分检索表示，并使用一个实时编码器进行完成编码，相较于纯内存和FiD，LUMEN在多个问答任务中具有更好的性能，且成本更低。 |
| [^51] | [Multi-hop Evidence Retrieval for Cross-document Relation Extraction.](http://arxiv.org/abs/2212.10786) | 本文介绍了一个名为MR.COD的多跳证据检索方法，用于支持跨文档关系抽取。实验表明该方法有效地获取了跨文档证据，并提升了封闭和开放设置中的性能。 |
| [^52] | [Beyond Contrastive Learning: A Variational Generative Model for Multilingual Retrieval.](http://arxiv.org/abs/2212.10726) | 本文提出了一种多语言检索的变分生成模型，可以有效地鼓励源分离，并展示其与对比学习方法的比较结果，该方法在实际检索任务中表现出效果。 |
| [^53] | [BUMP: A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of Faithfulness Metrics.](http://arxiv.org/abs/2212.09955) | BUMP是一个不忠实最小对比基准，由889个人写的对比CNN / DailyMail数据集中的摘要进行微小差异处理而得。BUMP可以帮助评估自动忠实性度量，其优于现有基准数据集，因为更具挑战性，且可以表征不同类型的不忠实性。 |
| [^54] | [Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations.](http://arxiv.org/abs/2212.09865) | 本文提出了一种新的零样本上下文学习方法Z-ICL，通过构建基于原始文本的伪演示，显著提升了模型的零样本性能水平，同时支持未来优化伪演示提高上下文学习表现而无需标记数据。 |
| [^55] | [Dataless Knowledge Fusion by Merging Weights of Language Models.](http://arxiv.org/abs/2212.09849) | 本文提出了一种无数据知识融合方法，可以合并在不同训练数据集上建立的单个模型，以得到一个在所有数据集领域上表现良好且可以推广到域外数据的单一模型。 |
| [^56] | [NusaCrowd: Open Source Initiative for Indonesian NLP Resources.](http://arxiv.org/abs/2212.09648) | NusaCrowd是一个印尼自然语言处理资源的开源倡议，已汇集137个数据集和118个数据加载程序，为印尼语和印度尼西亚本地语言的自然语言处理研究提供了多种实验手段。 |
| [^57] | [APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning.](http://arxiv.org/abs/2212.09282) | 本文提出了APOLLO，一种适应性预训练语言模型，通过选择特定的Wikipedia子集进行预训练，并使用两个自监督损失函数，成功地提高了模型的逻辑推理能力。 |
| [^58] | [FiDO: Fusion-in-Decoder optimized for stronger performance and faster inference.](http://arxiv.org/abs/2212.08153) | 这项研究提出了一种名为FiDO的解码器融合模型，通过两个简单的更改，有效缓解了内存带宽约束，加快了模型的推理速度，大大提高了模型性能，达到了领先水平。 |
| [^59] | [On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning.](http://arxiv.org/abs/2212.08061) | 该论文的研究探讨了零样本推理中的偏见和有害性。通过对社会敏感领域进行的控制评估，发现使用零样本CoT推理在敏感领域中会显着增加产生有害或不良输出的可能性。同时也指出，有害的CoT随着模型大小增加而增加，但随着改进的指令遵循而减少。 |
| [^60] | [A Unified Knowledge Graph Augmentation Service for Boosting Domain-specific NLP Tasks.](http://arxiv.org/abs/2212.05251) | KnowledgeDA是一种统一的领域语言模型开发服务，通过领域知识图谱增强任务特定的训练过程，提升特定领域的自然语言处理任务的表现。 |
| [^61] | [Investigating Massive Multilingual Pre-Trained Machine Translation Models for Clinical Domain via Transfer Learning.](http://arxiv.org/abs/2210.06068) | 本研究探讨了大规模多语言预训练语言模型（MMPLM）是否可以通过转移学习在临床领域机器翻译中成功应用于完全未知的语言对。实验结果表明，fine-tune过的MMPLM在临床领域机器翻译任务中表现良好。 |
| [^62] | [MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language Representation Learning.](http://arxiv.org/abs/2210.04183) | 本文提出了一种联合掩膜多模态建模方法，以学习细粒度的多模态表示，通过隐式和显式目标来恢复联合掩膜信号以提高细化的图像-文本交互。 |
| [^63] | [UCEpic: Unifying Aspect Planning and Lexical Constraints for Generating Explanations in Recommendation.](http://arxiv.org/abs/2209.13885) | UCEpic通过将方面规划和词汇约束统一考虑，提出了一种插入式生成的个性化解释型推荐模型，显著提高了解释的流畅性、连贯性和匹配能力。 |
| [^64] | [PaLI: A Jointly-Scaled Multilingual Language-Image Model.](http://arxiv.org/abs/2209.06794) | PaLI是一种联合缩放的多语言语言-图像模型，可对图像和文本进行建模和执行许多视觉、语言和多模态任务，利用Transformer和Vision Transformer等先前的能力和成本。联合缩放在此任务中很重要，所以我们使用了一个40亿参数的Vision Transformer，以便利用更大容量的视觉模型的优势。 |
| [^65] | [Unified Generative & Dense Retrieval for Query Rewriting in Sponsored Search.](http://arxiv.org/abs/2209.05861) | 本文介绍了两种在线查询重写的范式：生成式（NLG）和密集检索（DR）方法。通过比较这两种方法并结合优势，提出了CLOVER-Unity模型，其NLG和DR组件始终优于单独训练的组件以及其他基线模型。 |
| [^66] | [Signs of Language: Embodied Sign Language Fingerspelling Acquisition from Demonstrations for Human-Robot Interaction.](http://arxiv.org/abs/2209.05135) | 本文提出了一种从视频示例学习手语拼写在机器人中的实现的方法。通过训练模仿运动的策略，利用预训练的深度视觉模型从RGB视频中提取手的三维姿态，并识别出最佳的模仿超参数集，本文成功展示了方法的普适性。 |
| [^67] | [Evaluating Generative Patent Language Models.](http://arxiv.org/abs/2206.14578) | 本文构建了生成性专利语言模型，并通过基于人类节省按键数量的度量方法评估了其表现，发现在专利领域继续增加模型大小可能是不必要的。 |
| [^68] | [Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks.](http://arxiv.org/abs/2205.15171) | 提出一种新颖的模块化偏差缓解方法，在推理时间按需集成到核心模型中的独立去偏置子网络，在性别、种族和年龄等受保护属性的分类任务中，该方法在缓解偏差方面是有效的，并且在精度和灵活性方面优于现有技术方法。 |
| [^69] | [Language Anisotropic Cross-Lingual Model Editing.](http://arxiv.org/abs/2205.12677) | 本文提出了语言各向异性跨语言模型编辑的框架，并通过在跨语言任务上的测试证明了该方法的有效性，可以针对特定输入进行校准而不影响模型的原始行为。 |
| [^70] | [UnifieR: A Unified Retriever for Large-Scale Retrieval.](http://arxiv.org/abs/2205.11194) | UnifieR是一个将PLM的密集向量和基于词汇表的检索统一到一个模型中的学习框架，在段落检索基准测试中证明了其有效性。 |
| [^71] | [Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks.](http://arxiv.org/abs/2205.10282) | 本论文提出了一种名为Heterformer的基于Transformer的深度节点表示学习方法，它可以同时处理异构结构和丰富的文本语义信息。 |
| [^72] | [A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference.](http://arxiv.org/abs/2204.05428) | 该论文提出了一种基于多语言的评价方法，以评估自然语言推理任务中归因方法的忠实度和可信度，并且通过高亮的解释扩充了XNLI数据集，研究结果表明在可信度和可信度方面表现最佳的归因方法有所不同。 |
| [^73] | [Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification.](http://arxiv.org/abs/2204.03954) | 本文比较了用于文本分类的词袋、序列、图形和分层方法，发现基于图形的方法无法超越现代预训练语言模型并且甚至有时表现不如标准机器学习方法，质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。 |
| [^74] | [MMER: Multimodal Multi-task Learning for Speech Emotion Recognition.](http://arxiv.org/abs/2203.16794) | 本研究提出了一种名为MMER的新型多模态多任务学习方法，应用于语音情感识别。该方法利用新型多模态网络和多个辅助任务提高了性能，并在IEMOCAP基准测试中表现出了领先的水平。 |
| [^75] | [Evaluating natural language processing models with generalization metrics that do not need access to any training or testing data.](http://arxiv.org/abs/2202.02842) | 本文提出了一种无需访问任何数据即可评估自然语言处理模型的泛化度量标准，并通过对Huggingface预训练变压器的模型选择，得到一个简单高效且相关性强的有用度量标准。 |
| [^76] | [Paraphrastic Representations at Scale.](http://arxiv.org/abs/2104.15114) | 该论文提出了一种允许用户在各种语言中训练自己的全球领先的近义句表示系统，并发布了训练模型，这些模型在多任务上取得了显著进展，具有比以往更快的速度和更高的性能，是没有GPU或嵌入式设备的用户的有吸引力的选择。 |

# 详细

[^1]: VisualGPTScore: 多模态生成预训练分数的视觉语义推理。

    VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores. (arXiv:2306.01879v1 [cs.CV])

    [http://arxiv.org/abs/2306.01879](http://arxiv.org/abs/2306.01879)

    我们提出了VisualGPTScore方法，能够使用多模态生成分数捕捉文本标题可能性，并在图像条件语言模型上进行计算，具备组合推理能力。

    

    本文提出了一种名为 VisualGPTScore 的方法，使用多模态生成分数来捕捉文本标题可能性，并使用图像条件语言模型在图像上运算。与传统观点认为的VLM只是无意义的单词袋模型不同，我们的 VisualGPTScore 在 ARO 和 Crepe 等最近提出的图像文本检索基准测试中展现了顶尖的性能，证明了其具备组合推理能力。

    Vision-language models (VLMs) discriminatively pre-trained with contrastive image-text matching losses such as $P(\text{match}|\text{text}, \text{image})$ have been criticized for lacking compositional understanding. This means they might output similar scores even if the original caption is rearranged into a different semantic statement. To address this, we propose to use the ${\bf V}$isual ${\bf G}$enerative ${\bf P}$re-${\bf T}$raining Score (${\bf VisualGPTScore}$) of $P(\text{text}|\text{image})$, a $\textit{multimodal generative}$ score that captures the likelihood of a text caption conditioned on an image using an image-conditioned language model. Contrary to the belief that VLMs are mere bag-of-words models, our off-the-shelf VisualGPTScore demonstrates top-tier performance on recently proposed image-text retrieval benchmarks like ARO and Crepe that assess compositional reasoning. Furthermore, we factorize VisualGPTScore into a product of the $\textit{marginal}$ P(text) and the
    
[^2]: 大型语言模型对文化道德规范的了解

    Knowledge of cultural moral norms in large language models. (arXiv:2306.01857v1 [cs.CL])

    [http://arxiv.org/abs/2306.01857](http://arxiv.org/abs/2306.01857)

    本研究探究了英文语言模型对多文化背景下道德规范的理解程度，分析了模型对道德变化的把握能力和道德多样性以及共同倾向。研究表明，预训练的英文语言模型对跨国家的道德规范预测不如对英国道德规范的预测。

    

    道德规范因文化而异。最近的一项工作表明，英文大型语言模型包含类似于人类的道德偏见，但这些研究通常不在一个多元文化背景下研究道德变化。我们研究了只会英文的语言模型对不同国家的道德规范了解程度。我们考虑两个层面：1）语言模型是否对多个主题如“同性恋”和“离婚”等在各个国家之间的细粒度道德变化有所了解；2）语言模型是否涵盖了文化多样性和共同倾向，即在哪些主题上人们在道德判断上存在分歧或共识。我们使用世界价值观调查（跨55个国家）和PEW全球调查（跨40个国家）的两个公共数据集进行分析。我们发现，预训练的英文语言模型在预测跨国家的实证道德规范方面的表现不及预测英国道德规范。

    Moral norms vary across cultures. A recent line of work suggests that English large language models contain human-like moral biases, but these studies typically do not examine moral variation in a diverse cultural setting. We investigate the extent to which monolingual English language models contain knowledge about moral norms in different countries. We consider two levels of analysis: 1) whether language models capture fine-grained moral variation across countries over a variety of topics such as ``homosexuality'' and ``divorce''; 2) whether language models capture cultural diversity and shared tendencies in which topics people around the globe tend to diverge or agree on in their moral judgment. We perform our analyses with two public datasets from the World Values Survey (across 55 countries) and PEW global surveys (across 40 countries) on morality. We find that pre-trained English language models predict empirical moral norms across countries worse than the English moral norms rep
    
[^3]: 5IDER: 统一查询重写技术用于对话引导、意图携带、语言中断、实体携带及修复

    5IDER: Unified Query Rewriting for Steering, Intent Carryover, Disfluencies, Entity Carryover and Repair. (arXiv:2306.01855v1 [cs.CL])

    [http://arxiv.org/abs/2306.01855](http://arxiv.org/abs/2306.01855)

    本文介绍了一种非自回归的查询重写体系结构，该体系不仅可以处理对话引导、意图携带、语法中断、实体携带和修复这五个任务，还可以处理它们的复杂组合。

    

    提供语音助手导航多轮对话的能力是一个具有挑战性的问题。 处理多轮互动需要系统理解各种会话用例，如对话引导、意图携带、语言中断、实体携带和修复。 这个问题的复杂性加剧了这些用例混合在一起的事实，通常同时在自然语言中出现。本文提出了一种非自回归的查询重写体系结构，可以处理五个任务以及这些用例的复杂组合。我们证明了我们提出的模型与基线方法具有相当的单任务性能，并且在用例组合方面甚至优于经过调优的T5模型，尽管在参数上小15倍，在延迟上快25倍。

    Providing voice assistants the ability to navigate multi-turn conversations is a challenging problem. Handling multi-turn interactions requires the system to understand various conversational use-cases, such as steering, intent carryover, disfluencies, entity carryover, and repair. The complexity of this problem is compounded by the fact that these use-cases mix with each other, often appearing simultaneously in natural language. This work proposes a non-autoregressive query rewriting architecture that can handle not only the five aforementioned tasks, but also complex compositions of these use-cases. We show that our proposed model has competitive single task performance compared to the baseline approach, and even outperforms a fine-tuned T5 model in use-case compositions, despite being 15 times smaller in parameters and 25 times faster in latency.
    
[^4]: 二进制和三进制自然语言生成

    Binary and Ternary Natural Language Generation. (arXiv:2306.01841v1 [cs.CL])

    [http://arxiv.org/abs/2306.01841](http://arxiv.org/abs/2306.01841)

    本文提出了基于混合方法的二进制和三进制变压器模型，在摘要和机器翻译任务上取得了不错的效果，并在效率上获得了大幅度提升。

    

    二进制和三进制神经网络具有无需乘法的计算能力，如果在专用硬件上实现，则可以比全精度网络带来数个数量级的效率提升。然而，由于参数和输出空间都高度离散化，这种网络很难进行优化。对于变压器文本生成模型这一类，由于注意力运算对量化的敏感性以及自回归解码在高基数输出空间的噪声叠加效应，这些困难变得更加复杂。我们采用基于统计的权重量化和激活弹性量化的混合方法来解决这个问题，并在摘要和机器翻译的下游任务上展示了第一个三进制和二进制变压器模型。我们的三进制BART基本模型在CNN/DailyMail基准测试中取得了41的R1得分，仅比全模型低3.9分，同时效率提升了16倍。

    Ternary and binary neural networks enable multiplication-free computation and promise multiple orders of magnitude efficiency gains over full-precision networks if implemented on specialized hardware. However, since both the parameter and the output space are highly discretized, such networks have proven very difficult to optimize. The difficulties are compounded for the class of transformer text generation models due to the sensitivity of the attention operation to quantization and the noise-compounding effects of autoregressive decoding in the high-cardinality output space. We approach the problem with a mix of statistics-based quantization for the weights and elastic quantization of the activations and demonstrate the first ternary and binary transformer models on the downstream tasks of summarization and machine translation. Our ternary BART base achieves an R1 score of 41 on the CNN/DailyMail benchmark, which is merely 3.9 points behind the full model while being 16x more efficien
    
[^5]: Beta地中海贫血携带者检测的联邦学习方法

    Beta Thalassemia Carriers detection empowered federated Learning. (arXiv:2306.01818v1 [cs.LG])

    [http://arxiv.org/abs/2306.01818](http://arxiv.org/abs/2306.01818)

    本论文介绍了一种使用联邦学习技术的方法，快速、便宜、无需移动设备地检测Beta地中海贫血携带者。

    

    地中海贫血是一组遗传性血液疾病，当携带输氧至身体各处的红细胞中的蛋白质血红蛋白不足时会发生。如果父母双方都携带地中海贫血基因，孩子患病的几率会增加。确诊和治疗地中海贫血是防止其传递给下一代的关键。目前的血液检测方法对于检测Beta地中海贫血携带者过于昂贵、耗时，且需要大量的筛查设备。高效液相色谱是标准的检测方法，但也存在成本高、时间长、需要特殊设备等问题。因此，寻找一种快速、便宜的检测Beta地中海贫血携带者的方法是至关重要的。

    Thalassemia is a group of inherited blood disorders that happen when hemoglobin, the protein in red blood cells that carries oxygen, is not made enough. It is found all over the body and is needed for survival. If both parents have thalassemia, a child's chance of getting it increases. Genetic counselling and early diagnosis are essential for treating thalassemia and stopping it from being passed on to future generations. It may be hard for healthcare professionals to differentiate between people with thalassemia carriers and those without. The current blood tests for beta thalassemia carriers are too expensive, take too long, and require too much screening equipment. The World Health Organization says there is a high death rate for people with thalassemia. Therefore, it is essential to find thalassemia carriers to act quickly. High-performance liquid chromatography (HPLC), the standard test method, has problems such as cost, time, and equipment needs. So, there must be a quick and che
    
[^6]: 面向银行业的词嵌入

    Word Embeddings for Banking Industry. (arXiv:2306.01807v1 [cs.CL])

    [http://arxiv.org/abs/2306.01807](http://arxiv.org/abs/2306.01807)

    本文研究了面向银行业的词嵌入，发现其比广泛可用的词嵌入更能捕捉银行特定语义和词相关性，因此可作为NL任务的一个良好独立来源或者补充。

    

    自然语言处理（NLP）应用广泛，从情感分析到文本分类。从静态词嵌入（如Word2Vec或GloVe）到上下文模型提取的静态词表征（如BERT或ELMo），从这些NLP任务中，从业人员往往依赖于这些广泛可用的词嵌入。这些词嵌入是从大量文本构建而成，因此可能已经捕捉了不同上下文中大部分词汇。但是，它们能多好地捕捉特定领域的语义和词相关性？本文通过创建一种银行特定的词嵌入并将其与其他来源的词嵌入（如GloVe和BERT）进行评估，探讨了这个想法。不出所料，从银行特定语料库构建的嵌入更能捕捉银行特定语义和词相关性。该发现表明，面向银行业的词嵌入在执行NL任务时可以作为一个良好的独立来源或者作为其他可广泛获得的嵌入的补充。

    Applications of Natural Language Processing (NLP) are plentiful, from sentiment analysis to text classification. Practitioners rely on static word embeddings (e.g. Word2Vec or GloVe) or static word representation from contextual models (e.g. BERT or ELMo) to perform many of these NLP tasks. These widely available word embeddings are built from large amount of text, so they are likely to have captured most of the vocabulary in different context. However, how well would they capture domain-specific semantics and word relatedness? This paper explores this idea by creating a bank-specific word embeddings and evaluates them against other sources of word embeddings such as GloVe and BERT. Not surprising that embeddings built from bank-specific corpora does a better job of capturing the bank-specific semantics and word relatedness. This finding suggests that bank-specific word embeddings could be a good stand-alone source or a complement to other widely available embeddings when performing NL
    
[^7]: Cook-Gen：从食谱中生成健康烹饪动作的鲁棒性建模

    Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes. (arXiv:2306.01805v1 [cs.CL])

    [http://arxiv.org/abs/2306.01805](http://arxiv.org/abs/2306.01805)

    本文研究了使用生成AI方法来扩展当前的食品计算模型，将烹饪行为纳入考虑，以实现更全面的健康食谱推荐。

    

    随着人们越来越关注自己的饮食选择，食品计算模型在帮助人们保持健康饮食习惯方面变得越来越流行。例如，食品推荐系统分析食谱指令以评估营养成分并提供食谱推荐。而生成AI方法（如自回归大语言模型）的成功应用可以让我们更全面地理解食谱，从而实现更为健康全面的食谱推荐。本研究探讨使用生成AI方法来扩展当前的食品计算模型，从而将烹饪行为（例如加盐、煎肉、煮蔬菜等）纳入考虑。烹饪行为由于其不规则的数据模式而难以使用统计学习方法进行建模。

    As people become more aware of their food choices, food computation models have become increasingly popular in assisting people in maintaining healthy eating habits. For example, food recommendation systems analyze recipe instructions to assess nutritional contents and provide recipe recommendations. The recent and remarkable successes of generative AI methods, such as auto-regressive large language models, can lead to robust methods for a more comprehensive understanding of recipes for healthy food recommendations beyond surface-level nutrition content assessments. In this study, we explore the use of generative AI methods to extend current food computation models, primarily involving the analysis of nutrition and ingredients, to also incorporate cooking actions (e.g., add salt, fry the meat, boil the vegetables, etc.). Cooking actions are notoriously hard to model using statistical learning methods due to irregular data patterns - significantly varying natural language descriptions f
    
[^8]: 基于编辑距离的强化学习用于RNN-T解码

    Edit Distance based RL for RNNT decoding. (arXiv:2306.01789v1 [cs.SD])

    [http://arxiv.org/abs/2306.01789](http://arxiv.org/abs/2306.01789)

    本文提出了一种基于编辑距离的强化学习方法，用于最小化RNN-T训练和推理过程之间的差距，并在LibriSpeech的600M Conformer RNN-T模型上取得了最佳结果。

    

    基于其在各种基准测试中出色的WER和支持无缝流式传输和长篇转录的能力，RNN-T目前被认为是ASR的工业标准。 然而，它最大的缺点在于训练和推理目标之间存在显着差异。为了解决这个问题，本文提出了一种最小化训练和推理时间之间差距的强化学习方法。我们的编辑距离RL (EDRL)方法基于编辑距离计算奖励，并在每个操作级别训练网络。该方法在LibriSpeech的600M Conformer RNN-T模型上获得了SoTA WERs。

    RNN-T is currently considered the industry standard in ASR due to its exceptional WERs in various benchmark tests and its ability to support seamless streaming and longform transcription. However, its biggest drawback lies in the significant discrepancy between its training and inference objectives. During training, RNN-T maximizes all alignment probabilities by teacher forcing, while during inference, it uses beam search which may not necessarily find the maximum probable alignment. Additionally, RNN-T's inability to experience mistakes during teacher forcing training makes it more problematic when a mistake occurs in inference. To address this issue, this paper proposes a Reinforcement Learning method that minimizes the gap between training and inference time. Our Edit Distance based RL (EDRL) approach computes rewards based on the edit distance, and trains the network at every action level. The proposed approach yielded SoTA WERs on LibriSpeech for the 600M Conformer RNN-T model.
    
[^9]: 基于大型语言模型的概念设计生成

    Conceptual Design Generation Using Large Language Models. (arXiv:2306.01779v1 [cs.CL])

    [http://arxiv.org/abs/2306.01779](http://arxiv.org/abs/2306.01779)

    本文利用大型语言模型生成解决方案，并将其与众包解决方案进行比较。专家评估表明，LLM生成的解决方案具有更高的可行性和有用性，众包的解决方案更加具有创意性。

    

    概念生成是概念设计阶段的创造性步骤，在这个阶段中，设计师经常尝试通过头脑风暴、思维导图或众包设计思路来补充他们自己对领域的知识。自然语言处理（NLP）和机器学习（ML）的最新进展已经导致了大型语言模型（LLM）的兴起，这些模型能够从文本提示中生成看似创造性的输出。这些模型的成功应用跨足了艺术、娱乐和其他创作工作等各个领域。本文利用LLMs为一组12个设计问题生成解决方案，并将其与众包解决方案基准进行比较。我们通过多个角度评估生成和众包设计解决方案之间的差异，包括人工专家评估和计算指标。专家评估表明，LLM生成的解决方案平均可行性和有用性更高，而众包的解决方案更加具有创意性。

    Concept generation is a creative step in the conceptual design phase, where designers often turn to brainstorming, mindmapping, or crowdsourcing design ideas to complement their own knowledge of the domain. Recent advances in natural language processing (NLP) and machine learning (ML) have led to the rise of Large Language Models (LLMs) capable of generating seemingly creative outputs from textual prompts. The success of these models has led to their integration and application across a variety of domains, including art, entertainment, and other creative work. In this paper, we leverage LLMs to generate solutions for a set of 12 design problems and compare them to a baseline of crowdsourced solutions. We evaluate the differences between generated and crowdsourced design solutions through multiple perspectives, including human expert evaluations and computational metrics. Expert evaluations indicate that the LLM-generated solutions have higher average feasibility and usefulness while th
    
[^10]: 语言模型效率研究的定量评估

    A Quantitative Review on Language Model Efficiency Research. (arXiv:2306.01768v1 [cs.LG])

    [http://arxiv.org/abs/2306.01768](http://arxiv.org/abs/2306.01768)

    这篇论文从定量方面对基于Transformers和State Space Models的一系列研究进行了综述，并总结了如何提高语言模型效率。

    

    语言模型是被扩展用于处理一些复杂、自然语言处理任务的有效工具之一。本篇论文涵盖了对于提高语言模型效率这一核心问题的研究概述，并尝试对最近的基于Transformers和State Space Models的研究进行定量分析。

    Language models (LMs) are being scaled and becoming powerful. Improving their efficiency is one of the core research topics in neural information processing systems. Tay et al. (2022) provided a comprehensive overview of efficient Transformers that have become an indispensable staple in the field of NLP. However, in the section of "On Evaluation", they left an open question "which fundamental efficient Transformer one should consider," answered by "still a mystery" because "many research papers select their own benchmarks." Unfortunately, there was not quantitative analysis about the performances of Transformers on any benchmarks. Moreover, state space models (SSMs) have demonstrated their abilities of modeling long-range sequences with non-attention mechanisms, which were not discussed in the prior review. This article makes a meta analysis on the results from a set of papers on efficient Transformers as well as those on SSMs. It provides a quantitative review on LM efficiency researc
    
[^11]: 使用机器学习区分人类生成文本和ChatGPT生成文本

    Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning. (arXiv:2306.01761v1 [cs.CL])

    [http://arxiv.org/abs/2306.01761](http://arxiv.org/abs/2306.01761)

    本文提出了一种机器学习方法，可以识别出由ChatGPT生成的文本，并以11种算法进行了分类对比分析，在测试中取得了77%的准确度。

    

    ChatGPT是预训练大语言模型家族中的一员，是一种对话人工智能。这种文本生成模型通过监督学习和强化学习进行微调，可以生成看似由自然智能撰写的文本文件。虽然这种生成模型有很多优点，但也存在一些合理的担忧。本文提出了一种基于机器学习的解决方案，可以识别出ChatGPT生成的文本与人类编写的文本，以及在分类过程中共计11种机器学习和深度学习算法的对比分析。我们在一个Kaggle数据集上测试了所提出的模型，该数据集包含10,000个文本，其中5,204个文本是人类从新闻和社交媒体上收集的写作。在由GPT-3.5生成的语料库上，所提出的算法呈现出77%的准确度。

    ChatGPT is a conversational artificial intelligence that is a member of the generative pre-trained transformer of the large language model family. This text generative model was fine-tuned by both supervised learning and reinforcement learning so that it can produce text documents that seem to be written by natural intelligence. Although there are numerous advantages of this generative model, it comes with some reasonable concerns as well. This paper presents a machine learning-based solution that can identify the ChatGPT delivered text from the human written text along with the comparative analysis of a total of 11 machine learning and deep learning algorithms in the classification process. We have tested the proposed model on a Kaggle dataset consisting of 10,000 texts out of which 5,204 texts were written by humans and collected from news and social media. On the corpus generated by GPT-3.5, the proposed algorithm presents an accuracy of 77%.
    
[^12]: 训练先验影响文本到图像模型性能

    Training Priors Predict Text-To-Image Model Performance. (arXiv:2306.01755v1 [cs.CV])

    [http://arxiv.org/abs/2306.01755](http://arxiv.org/abs/2306.01755)

    本文测试了文本到图像模型对于训练先验的依赖程度，发现模型能够更好地生成与训练数据中出现频率更高的三元组对齐的图像，但这也会降低其生成以翻转三元组为基础的图像质量。

    

    文本到图像的模型能够生成一些关系，比如“宇航员骑马”，但却不能生成由相同基本部分组成的其他关系，比如“马骑宇航员”。这些失败通常被视为模型依赖训练先验而不是构建新颖的图像组合的证据。本文直接在稳定扩散2.1文本到图像模型上进行了测试。通过观察组成这些提示的主语-谓语-宾语 (SVO) 三元组（例如，“宇航员”，“骑”，“马”），我们发现，SVO三元组在训练数据中出现的次数越多，该模型就能生成与该三元组对齐的图像就越好。在这里，通过对齐，我们的意思是每个术语在生成的图像中以正确的关系出现。然而，这种增加的频率也会减少模型能够生成与翻转三元组对齐的图像的能力。例如，如果“宇航员骑马”在训练数据中频繁出现，那么“马骑宇航员”的对齐质量就会降低。

    Text-to-image models can often generate some relations, i.e., "astronaut riding horse", but fail to generate other relations composed of the same basic parts, i.e., "horse riding astronaut". These failures are often taken as evidence that the models rely on training priors rather than constructing novel images compositionally. This paper tests this intuition directly on the stablediffusion 2.1 text-to-image model. By looking at the subject-verb-object (SVO) triads that form the backbone of these prompts (e.g., "astronaut", "ride", "horse"), we find that the more often an SVO triad appears in the training data, the better the model can generate an image aligned with that triad. Here, by aligned we mean that each of the terms appears in the generated image in the proper relation to each other. However, this increased frequency also diminishes how well the model can generate an image aligned with the flipped triad. For example, if "astronaut riding horse" appears frequently in the trainin
    
[^13]: 弱监督下的预处理视觉语言推理

    Preconditioned Visual Language Inference with Weak Supervision. (arXiv:2306.01753v1 [cs.CL])

    [http://arxiv.org/abs/2306.01753](http://arxiv.org/abs/2306.01753)

    本文提出了一个名为PVLIR的预处理视觉语言推理和合理化任务，结果揭示了当前最先进的视觉语言模型在此项任务上的缺陷，并提出了改进这些模型的挑战。

    

    人类可以通过提取每种情境下相关的前提条件来推断物体的可供性。例如，看到一张破碎杯子的照片，我们可以推断这个前提条件阻止了杯子用于饮用。自然语言处理领域研究中，模型明确获取上下文前提条件来推理常识。但是，目前最先进的视觉语言模型是否能够提取这样的前提条件并推断物体的可供性尚不清楚。本文提出了一个名为PVLIR的预处理视觉语言推理和合理化任务，并开发了三个策略的学习资源来检索该任务的弱监督信号，并制定了经过人工验证的测试集进行评估。我们的结果揭示了最先进的视觉语言模型在这项任务上的缺陷，并绘制了未来改进这些模型面临的挑战的路线图。

    Humans can infer the affordance of objects by extracting related contextual preconditions for each scenario. For example, upon seeing an image of a broken cup, we can infer that this precondition prevents the cup from being used for drinking. Reasoning with preconditions of commonsense is studied in NLP where the model explicitly gets the contextual precondition. However, it is unclear if SOTA visual language models (VLMs) can extract such preconditions and infer the affordance of objects with them. In this work, we introduce the task of preconditioned visual language inference and rationalization (PVLIR). We propose a learning resource based on three strategies to retrieve weak supervision signals for the task and develop a human-verified test set for evaluation. Our results reveal the shortcomings of SOTA VLM models in the task and draw a road map to address the challenges ahead in improving them.
    
[^14]: 一种适用于Unicode文本的Abugida规范化器和解析器

    Abugida Normalizer and Parser for Unicode texts. (arXiv:2306.01743v1 [cs.CL])

    [http://arxiv.org/abs/2306.01743](http://arxiv.org/abs/2306.01743)

    本论文提出了两个针对Indic语言Unicode书写方案中常见及不常见问题的工具库，分别是纠正不一致性的规范化器和Abugida文本的字形解析器，使用这两个工具可以提高400%的速度并显著改善下游任务表现。

    

    本文提出了两个库，以解决Indic语言基于Unicode的书写方案的常见和不常见问题。第一个是一个规范化器，通过https://pypi.org/project/bnunicodenormalizer/纠正由编码方案引起的不一致性。第二个是Abugida文本的字形解析器https://pypi.org/project/indicparser/。这两个工具比以前使用的工具更有效率和有效。我们报告了400%的速度提升，并确保不同语言模型基于下游任务表现显著提高。

    This paper proposes two libraries to address common and uncommon issues with Unicode-based writing schemes for Indic languages. The first is a normalizer that corrects inconsistencies caused by the encoding scheme https://pypi.org/project/bnunicodenormalizer/ . The second is a grapheme parser for Abugida text https://pypi.org/project/indicparser/ . Both tools are more efficient and effective than previously used tools. We report 400% increase in speed and ensure significantly better performance for different language model based downstream tasks.
    
[^15]: 超越消极情绪：关于希望言论检测的重新分析和后续实验

    Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech Detection. (arXiv:2306.01742v1 [cs.CL])

    [http://arxiv.org/abs/2306.01742](http://arxiv.org/abs/2306.01742)

    本研究旨在找到计算效率高、可比或更好的希望言论检测方法，并公开了代码库。

    

    健康专家们认为，希望在增强个人的身心健康、促进康复和恢复方面起着至关重要的作用。希望言论是指在评论、帖子和其他社交媒体消息中提供支持、安慰、建议、启示和见解的言论。希望言论的检测涉及这种文本内容的分析，旨在识别能够唤起人们积极情绪的信息。我们的研究旨在找到计算效率高、可比或更好的希望言论检测方法。我们还将我们的代码库公开在 https://github.com/aflah02/Hope_Speech_Detection 上。

    Health experts assert that hope plays a crucial role in enhancing individuals' physical and mental well-being, facilitating their recovery, and promoting restoration. Hope speech refers to comments, posts and other social media messages that offer support, reassurance, suggestions, inspiration, and insight. The detection of hope speech involves the analysis of such textual content, with the aim of identifying messages that invoke positive emotions in people. Our study aims to find computationally efficient yet comparable/superior methods for hope speech detection. We also make our codebase public at https://github.com/aflah02/Hope_Speech_Detection
    
[^16]: 基于 Transformer 模型的裁判文本分类比较研究

    Comparative study on Judgment Text Classification for Transformer Based Models. (arXiv:2306.01739v1 [cs.CL])

    [http://arxiv.org/abs/2306.01739](http://arxiv.org/abs/2306.01739)

    本研究对6个不同的基于自我注意力的Transformer模型进行了比较研究，并针对4种激活函数进行了调整，以用于判决文本分类。该方法可以帮助在法律诉讼中进行引用和先例参考。

    

    本研究利用各种自然语言处理模型，通过从判决文书中提取和摘要文本来预测特定判决的获胜者。这些文档在法律诉讼中非常有用。其中一个优点是，这些文档可用于引用和先例参考，这使得使用者可以更有力地为其案件辩护。当涉及到案例先例时，必须参考大量文档，以收集与该案件有关的法律要点。然而，由于文档的复杂词汇结构和文档大小，审查这些文档需要花费很长时间进行分析。本文涉及在4种不同激活函数下调整 6 种自我注意力的基于 Transformer 的模型，并研究它们在训练了 200 个判决上的表现，以及根据不同基准参数评估其结果。

    This work involves the usage of various NLP models to predict the winner of a particular judgment by the means of text extraction and summarization from a judgment document. These documents are useful when it comes to legal proceedings. One such advantage is that these can be used for citations and precedence reference in Lawsuits and cases which makes a strong argument for their case by the ones using it. When it comes to precedence, it is necessary to refer to an ample number of documents in order to collect legal points with respect to the case. However, reviewing these documents takes a long time to analyze due to the complex word structure and the size of the document. This work involves the comparative study of 6 different self-attention-based transformer models and how they perform when they are being tweaked in 4 different activation functions. These models which are trained with 200 judgement contexts and their results are being judged based on different benchmark parameters. 
    
[^17]: NMT中基于子词的分词中，频率和组合性的重要性评估

    Assessing the Importance of Frequency versus Compositionality for Subword-based Tokenization in NMT. (arXiv:2306.01393v1 [cs.CL])

    [http://arxiv.org/abs/2306.01393](http://arxiv.org/abs/2306.01393)

    本文通过实验发现，在NMT中基于子词的分词方法中，频率对于模型的表现贡献占据了90%-95%，因此相对于组合性，频率更为重要。

    

    子词分词是神经语言模型和机器翻译系统中的默认标准。频繁引用子词的优点有：对频繁词语进行更短编码，子词组合性强以及处理未知词语的能力。然而，它们的相对重要性尚不太清楚。本文提出了一种分词方法，可以将频率（第一个优点）与组合性分离开来，使用霍夫曼编码对单词进行分词，按频率顺序，使用固定数量的符号。实验表明，在CS-DE、EN-FR和EN-DE NMT中，仅频率就占了BPE得分的90%-95%，因此组合性并不像以前认为的那么重要。

    Subword tokenization is the de facto standard for tokenization in neural language models and machine translation systems. Three advantages are frequently cited in favor of subwords: shorter encoding of frequent tokens, compositionality of subwords, and ability to deal with unknown words. As their relative importance is not entirely clear yet, we propose a tokenization approach that enables us to separate frequency (the first advantage) from compositionality. The approach uses Huffman coding to tokenize words, by order of frequency, using a fixed amount of symbols. Experiments with CS-DE, EN-FR and EN-DE NMT show that frequency alone accounts for 90%-95% of the scores reached by BPE, hence compositionality has less importance than previously thought.
    
[^18]: “不确定性感知的非似然学习提高生成式情感四元组预测”

    Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction. (arXiv:2306.00418v1 [cs.CL])

    [http://arxiv.org/abs/2306.00418](http://arxiv.org/abs/2306.00418)

    本文提出了一种新的方法来控制标记级的生成、提高原始学习和减少错误，其中包括蒙特卡洛dropout、边缘非似然学习和最小化熵。在四个公共数据集上的广泛实验表明，该方法有效地提高了情感四元组预测的性能。

    

    最近，基于方面的情感分析领域广泛关注了情感四元组预测。现有的研究通过预训练的生成式语言模型提取出四元组，将原始句子转化为模板化的目标序列。然而，以前的研究只关注生成什么，而忽略了不需要生成的内容。我们认为考虑负样本也会带来潜在的好处。本文提出了一种模板无关的方法来控制标记级的生成，同时提高原始学习和减少错误。具体来说，我们引入了蒙特卡洛dropout来理解预训练语言模型的内置不确定性，获取噪声和错误信息。我们进一步提出边缘非似然学习来抑制不确定性感知的错误标记。最后，我们引入了最小化熵来平衡边缘非似然学习的影响。在四个公共数据集上的广泛实验表明，我们提出的方法在提高情感四元组预测的性能方面是有效的。

    Recently, aspect sentiment quad prediction has received widespread attention in the field of aspect-based sentiment analysis. Existing studies extract quadruplets via pre-trained generative language models to paraphrase the original sentence into a templated target sequence. However, previous works only focus on what to generate but ignore what not to generate. We argue that considering the negative samples also leads to potential benefits. In this work, we propose a template-agnostic method to control the token-level generation, which boosts original learning and reduces mistakes simultaneously. Specifically, we introduce Monte Carlo dropout to understand the built-in uncertainty of pre-trained language models, acquiring the noises and errors. We further propose marginalized unlikelihood learning to suppress the uncertainty-aware mistake tokens. Finally, we introduce minimization entropy to balance the effects of marginalized unlikelihood learning. Extensive experiments on four public
    
[^19]: 基准数据集上 ChatGPT 的系统研究和全面评估

    A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. (arXiv:2305.18486v1 [cs.CL])

    [http://arxiv.org/abs/2305.18486](http://arxiv.org/abs/2305.18486)

    本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。

    

    最近，如 ChatGPT 这样的大型语言模型（LLM）的开发引起了很多关注。然而，由于难以将该模型生成的产出与基本事实进行比较，因此其在基准学术数据集上的评估仍未充分探索。本文旨在对 ChatGPT 在包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务中的表现进行彻底评估。具体而言，我们在 140 个任务中评估了 ChatGPT，并分析了其在这些数据集中生成的 255K 次响应，这使我们的工作成为了在 NLP 基准测试中对 ChatGPT 进行的最大评估。简而言之，我们的研究旨在验证 ChatGPT 在各种任务中的优势和弱点，并为使用 LLM 的未来研究提供见解。我们还报告了一种新的迸发能力，即遵循多个查询指令。

    The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT's performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instruct
    
[^20]: 基于预先训练语言模型的情境类比推理研究

    In-Context Analogical Reasoning with Pre-Trained Language Models. (arXiv:2305.17626v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.17626](http://arxiv.org/abs/2305.17626)

    本研究提出了一种基于语言模型的情境类比推理方法，通过将问题的感知特征编码成语言形式，能够实现高效的零-shot关系推理，超越传统方法和人类水平。

    

    类比推理是人类认知的基本能力之一，可以通过将新的情况与过去的经验关联来进行抽象推理。虽然它被认为对于AI系统的强大推理至关重要，但传统方法需要进行大量的训练和/或固化特定的领域知识才能应用于基准任务中。受到认知科学研究发现人类语言与类比制作之间的联系的启发，我们探索使用直观的基于语言的抽象来支持人工智能系统中的类比。具体而言，我们使用大型预先训练的语言模型（PLMs）对视觉Raven的渐进矩阵（RPM）进行类比推理。通过将问题的感知特征简单地编码成语言形式，我们发现PLMs表现出了惊人的零-shot关系推理能力，超过了人类表现并接近于受监督的基于视觉的方法。我们探索了不同的编码方法，以变化抽象的水平。

    Analogical reasoning is a fundamental capacity of human cognition that allows us to reason abstractly about novel situations by relating them to past experiences. While it is thought to be essential for robust reasoning in AI systems, conventional approaches require significant training and/or hard-coding of domain knowledge to be applied to benchmark tasks. Inspired by cognitive science research that has found connections between human language and analogy-making, we explore the use of intuitive language-based abstractions to support analogy in AI systems. Specifically, we apply large pre-trained language models (PLMs) to visual Raven's Progressive Matrices (RPM), a common relational reasoning test. By simply encoding the perceptual features of the problem into language form, we find that PLMs exhibit a striking capacity for zero-shot relational reasoning, exceeding human performance and nearing supervised vision-based methods. We explore different encodings that vary the level of abs
    
[^21]: 检测大型语言模型编辑失败：一个改进的特异性基准测试

    Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark. (arXiv:2305.17553v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17553](http://arxiv.org/abs/2305.17553)

    该论文探讨了大型语言模型编辑技术的现状，发现现有的特异性基准测试难以检测到不良副作用，并提出了一个改进的基准测试，该测试可以检测到动态组件，并通过基于KL散度的指标扩展了特异性的衡量方式。研究发现最近的模型编辑技术特异性较低，强调了改进特异性基准测试的重要性。

    

    最近的模型编辑技术承诺在LLM训练过程中减轻记忆错误或过时关联的问题。然而，我们展示了这些技术可能会引入大量未被现有特异性基准测试检测到的不良副作用。我们扩展了现有的CounterFact基准测试以包括动态组件，并将我们的基准测试称为CounterFact+。此外，我们通过一个基于KL散度的本质指标扩展了用于衡量特异性的指标。我们使用这个改进的基准测试来评估最近的模型编辑技术，发现它们的特异性较低。我们的发现凸显了需要改进特异性基准测试以识别和预防不良副作用的重要性。

    Recent model editing techniques promise to mitigate the problem of memorizing false or outdated associations during LLM training. However, we show that these techniques can introduce large unwanted side effects which are not detected by existing specificity benchmarks. We extend the existing CounterFact benchmark to include a dynamic component and dub our benchmark CounterFact+. Additionally, we extend the metrics used for measuring specificity by a principled KL divergence-based metric. We use this improved benchmark to evaluate recent model editing techniques and find that they suffer from low specificity. Our findings highlight the need for improved specificity benchmarks that identify and prevent unwanted side effects.
    
[^22]: 在口语问答中通过语义重构来回答未回答的问题

    Answering Unanswered Questions through Semantic Reformulations in Spoken QA. (arXiv:2305.17393v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17393](http://arxiv.org/abs/2305.17393)

    本研究提出了语义问答重构模型 (SURF)，通过三个基于语言学的操作来重写口语问答中存在的词汇、命题、句法和特异性等问题，提高了回答率，能够帮助语音助手更好地回答未回答的问题。

    

    口语问答是语音助手的一个重要功能，通常由多个问答系统支持。用户通过自然语音询问问题，可能包含不流畅、错误和非正式的语法或措辞。这是问答系统的一个主要挑战，导致未回答的问题或无关的答案，并导致用户体验差。我们分析了未成功回答的问答请求，以确定核心挑战：词汇差距、命题类型、复杂的句法结构和高特异性。我们提出了一个语义问答重构模型 (SURF)，提供三个基于语言学的操作 (修复、句法重塑、概括) 来重写问题以便于回答。离线评估来自领先语音助手的 100 万个未回答的问题，结果显示 SURF 显著提高了回答率：高达 24% 的问题获得了相关答案 (75%)。实时部署显示出对数百万有未回答的问题的客户产生了积极的影响。

    Spoken Question Answering (QA) is a key feature of voice assistants, usually backed by multiple QA systems. Users ask questions via spontaneous speech which can contain disfluencies, errors, and informal syntax or phrasing. This is a major challenge in QA, causing unanswered questions or irrelevant answers, and leading to bad user experiences. We analyze failed QA requests to identify core challenges: lexical gaps, proposition types, complex syntactic structure, and high specificity. We propose a Semantic Question Reformulation (SURF) model offering three linguistically-grounded operations (repair, syntactic reshaping, generalization) to rewrite questions to facilitate answering. Offline evaluation on 1M unanswered questions from a leading voice assistant shows that SURF significantly improves answer rates: up to 24% of previously unanswered questions obtain relevant answers (75%). Live deployment shows positive impact for millions of customers with unanswered questions; explicit relev
    
[^23]: 无监督神经机器翻译的复制问题：具有语言鉴别器损失的训练计划

    On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss. (arXiv:2305.17182v1 [cs.CL])

    [http://arxiv.org/abs/2305.17182](http://arxiv.org/abs/2305.17182)

    无监督NMT中的复制问题通常发生在远距离语种对中且会直接复制输入句子的部分作为翻译，本研究提出了一种包含语言鉴别器损失的训练计划来缓解该问题，并提高低资源语种的翻译性能。

    

    虽然无监督神经机器翻译已在许多语种间得到成功，但复制问题（即将输入句子的某些部分直接复制作为翻译）在远距离语种对中很常见，尤其涉及低资源语种。我们发现这个问题与在线回译（BT）期间出现的预期复制行为密切相关。在这项工作中，我们提出了一个简单但有效的训练计划，它包含了一个语言鉴别器的损失函数。该损失施加约束于中间翻译，以使翻译是所需的语言。通过在不同语言对、 包括相似和远距离、高资源和低资源语言的广泛实验中，我们发现我们的方法缓解了复制问题，从而提高了对低资源语言的翻译性能。

    Although unsupervised neural machine translation (UNMT) has achieved success in many language pairs, the copying problem, i.e., directly copying some parts of the input sentence as the translation, is common among distant language pairs, especially when low-resource languages are involved. We find this issue is closely related to an unexpected copying behavior during online back-translation (BT). In this work, we propose a simple but effective training schedule that incorporates a language discriminator loss. The loss imposes constraints on the intermediate translation so that the translation is in the desired language. By conducting extensive experiments on different language pairs, including similar and distant, high and low-resource languages, we find that our method alleviates the copying problem, thus improving the translation performance on low-resource languages.
    
[^24]: 学习想象：视觉增强的自然语言生成

    Learning to Imagine: Visually-Augmented Natural Language Generation. (arXiv:2305.16944v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16944](http://arxiv.org/abs/2305.16944)

    本研究提出了一种称为LIVE的方法，通过视觉增强学习生成自然语言的想象，并针对每个句子进行动态合成，大量实验测试表明它可以有效提高生成质量。

    

    人们往往会想象相关场景来帮助写作。本研究旨在利用视觉信息以与人类相同的方式进行创作。我们提出了一个方法LIVE，使得预训练语言模型（PLMs）能够学习通过视觉增强生成自然语言的想象 。首先，我们基于文本想象场景：我们使用扩散模型依据输入文本合成高质量的图像。其次，我们使用CLIP确定文本是否能以后验方式唤起想象。最后，我们的想象是动态的，我们会针对每个句子进行合成，而不是针对整个段落生成一张图像。在技术上，我们提出了一种新的即插即用融合层，以获取每个文本的视觉增强表示。我们的视觉-文本融合层与Transformer-based架构兼容。我们使用BART和T5进行了四个生成任务的大量实验测试，自动结果和人类评估都表明LIVE能够有效提高生成质量。

    People often imagine relevant scenes to aid in the writing process. In this work, we aim to utilize visual information for composition in the same manner as humans. We propose a method, LIVE, that makes pre-trained language models (PLMs) Learn to Imagine for Visuallyaugmented natural language gEneration. First, we imagine the scene based on the text: we use a diffusion model to synthesize high-quality images conditioned on the input texts. Second, we use CLIP to determine whether the text can evoke the imagination in a posterior way. Finally, our imagination is dynamic, and we conduct synthesis for each sentence rather than generate only one image for an entire paragraph. Technically, we propose a novel plug-and-play fusion layer to obtain visually-augmented representations for each text. Our vision-text fusion layer is compatible with Transformerbased architecture. We have conducted extensive experiments on four generation tasks using BART and T5, and the automatic results and human e
    
[^25]: 人人可复现的NLP研究：初学者的需求调查

    NLP Reproducibility For All: Understanding Experiences of Beginners. (arXiv:2305.16579v1 [cs.CL])

    [http://arxiv.org/abs/2305.16579](http://arxiv.org/abs/2305.16579)

    通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。

    

    随着自然语言处理（NLP）近年来异常火爆，越来越多的人急于进入该领域，但目前的研究复现努力是否足以让这些初学者应用最新的进展还不清楚。为了了解初学者的需求，我们在一个介绍性的NLP课程中开展了一项研究，让学生复现最近NLP论文的结果。令人惊讶的是，我们发现他们的编程技能和对研究论文的理解对完成练习的付出仅有限的影响，相比之下，研究作者的可访问性努力是成功的关键，包括完整的文档、更好的编码实践和更容易获取的数据文件。前进时，我们建议NLP研究人员密切关注这些开源工作的简单方面，并使用初学者的反馈见解提供可操作的想法以更好地支持他们。

    As natural language processing (NLP) has recently seen an unprecedented level of excitement, and more people are eager to enter the field, it is unclear whether current research reproducibility efforts are sufficient for this group of beginners to apply the latest developments. To understand their needs, we conducted a study with 93 students in an introductory NLP course, where students reproduced the results of recent NLP papers. Surprisingly, we find that their programming skill and comprehension of research papers have a limited impact on their effort spent completing the exercise. Instead, we find accessibility efforts by research authors to be the key to success, including complete documentation, better coding practice, and easier access to data files. Going forward, we recommend that NLP researchers pay close attention to these simple aspects of open-sourcing their work, and use insights from beginners' feedback to provide actionable ideas on how to better support them.
    
[^26]: 因果推断方法研究特异性和情感对群体偏见的影响

    Counterfactual Probing for the influence of affect and specificity on Intergroup Bias. (arXiv:2305.16409v1 [cs.CL])

    [http://arxiv.org/abs/2305.16409](http://arxiv.org/abs/2305.16409)

    本文研究了特异性和情感两个语用特征在不同群体背景下是否会出现系统性变化，并将其与自然语言输出中的新群体偏见框架相联系。初步分析表明，推文的特异性和情感程度与监督的群体关系标签之间存在一定的相关性，而因果推断揭示了神经模型在分类时可靠地使用情感，但其对特异性的使用是不确定的。

    

    虽然研究自然语言处理中的偏见问题通常集中在负面或贬损语言的使用上，但Govindarajan等人（2023）提出了一个新的偏见框架，即以群体社会背景为基础，研究其对语言行为的影响。本文研究了两个语用特征（特异性和情感）在不同的群体上下文中是否会系统性地变化，从而将这个新的偏见框架与语言输出连接起来。初步的分析发现，推文的特异性和情感程度与监督的群体关系（IGR）标签之间存在适度的相关性。因果推断进一步揭示了，虽然被精调为IGR标签预测的神经模型可靠地使用情感进行分类，但模型使用特异性是不确定的。代码和数据可以在以下网址找到：https://github.com/venkatasg/intergroup-probing

    While existing work on studying bias in NLP focues on negative or pejorative language use, Govindarajan et al. (2023) offer a revised framing of bias in terms of intergroup social context, and its effects on language behavior. In this paper, we investigate if two pragmatic features (specificity and affect) systematically vary in different intergroup contexts -- thus connecting this new framing of bias to language output. Preliminary analysis finds modest correlations between specificity and affect of tweets with supervised intergroup relationship (IGR) labels. Counterfactual probing further reveals that while neural models finetuned for predicting IGR labels reliably use affect in classification, the model's usage of specificity is inconclusive. Code and data can be found at: https://github.com/venkatasg/intergroup-probing
    
[^27]: 扫描与拍照：理解1层Transformer中的训练动态和标记组成

    Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer. (arXiv:2305.16380v1 [cs.CL])

    [http://arxiv.org/abs/2305.16380](http://arxiv.org/abs/2305.16380)

    本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。

    

    Transformer架构在多个研究领域表现出了惊人的性能，并成为许多神经网络模型的基础。然而，我们对其如何工作的理解仍然有限。特别是，通过简单的预测性损失，表示如何从梯度训练动态中出现仍然是一个谜。在本文中，针对具有一个自我关注层和一个解码器层的1层Transformer，我们以数学严谨的方式分析其在下一个标记预测任务中的SGD训练动态。我们打开了自我关注层组合输入标记的动态过程的黑盒子，并揭示了底层归纳偏差的本质。具体而言，在没有位置编码、长输入序列和解码器层学习速度快于自我关注层的假设下，我们证明了自我关注层充当了“区分性扫描算法”：从均匀注意力开始，它逐渐关注到相关标记，排除不相关的标记，直到所有相关信息被扫描并总结在编码表示中。我们的分析还显示了标记频率和上下文如何影响注意权重，以及自我关注层初始化如何影响收敛速度。

    Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss, how the representation emerges from the gradient \emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \emph{discriminative scanning algorithm}: starting from uniform attention, it gradually attends mor
    
[^28]: 利用对比自我训练和原型学习改进跨语言命名实体识别的自训练方法

    Improving Self-training for Cross-lingual Named Entity Recognition with Contrastive and Prototype Learning. (arXiv:2305.13628v1 [cs.CL])

    [http://arxiv.org/abs/2305.13628](http://arxiv.org/abs/2305.13628)

    本文提出了一种名为ContProto的方法，通过对比自我训练和基于原型的伪标记，结合表示学习和伪标签精化，在一个一致的框架中提高了跨语言命名实体识别的自训练方法；实验结果表明，ContProto 方法在多个转移对上优于最先进的基准，并在各种基准上取得了显着的改进。

    

    在跨语言命名实体识别中，自训练通常用于通过在伪标记目标语言数据上进行训练来弥合语言差距。然而，由于目标语言性能不佳，伪标签通常存在噪声，限制了整体性能。本文旨在通过在一个一致的框架中结合表示学习和伪标签精化来改进跨语言命名实体识别的自训练方法。我们提出的方法主要包括两个组成部分：（1）对比自我训练和（2）基于原型的伪标记。我们的对比自我训练通过分离不同类别的聚类来促进跨语言转移，并通过产生源语言和目标语言之间紧密对齐的表示来增强跨语言可转移性。同时，基于原型的伪标记在训练过程中有效提高了伪标签的准确性。我们在多个转移对上评估ContProto，实验结果表明，我们的方法优于最先进的基准，并在各种基准上取得了显着的改进。

    In cross-lingual named entity recognition (NER), self-training is commonly used to bridge the linguistic gap by training on pseudo-labeled target-language data. However, due to sub-optimal performance on target languages, the pseudo labels are often noisy and limit the overall performance. In this work, we aim to improve self-training for cross-lingual NER by combining representation learning and pseudo label refinement in one coherent framework. Our proposed method, namely ContProto mainly comprises two components: (1) contrastive self-training and (2) prototype-based pseudo-labeling. Our contrastive self-training facilitates span classification by separating clusters of different classes, and enhances cross-lingual transferability by producing closely-aligned representations between the source and target language. Meanwhile, prototype-based pseudo-labeling effectively improves the accuracy of pseudo labels during training. We evaluate ContProto on multiple transfer pairs, and experim
    
[^29]: 为无偏的跨语言关系抽取构建混合编码的通用依存森林

    Constructing Code-mixed Universal Dependency Forest for Unbiased Cross-lingual Relation Extraction. (arXiv:2305.12258v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12258](http://arxiv.org/abs/2305.12258)

    本文提出了一种无偏的UD树跨语言关系抽取转移方法，通过构建混合编码UD树，有助于弥合训练和预测阶段之间差距从而实现显著的跨语言关系抽取性能提升。

    

    最近的跨语言关系抽取研究采用通用依存（UD）资源的语言一致性结构特征，但由于语言的不可避免差异，很容易遭受受偏转移（例如目标偏差或源偏差）。在本文中，我们通过构建一种类型的混合编码UD树，研究了一种无偏的UD树跨语言关系抽取转移。首先将源语言的句子翻译成平行的目标语言，对两种语言都分别解析UD树，然后将源语言/目标语言的UD结构合并为统一的混合编码UD树。通过这样的森林特征，UD树的跨语言关系抽取训练和预测阶段之间的差距可以有效缩小。我们在ACE XRE基准数据集上进行实验，结果表明，所提出的混合编码UD森林有助于无偏的UD树跨语言关系抽取转移，并实现了显着的跨语言关系抽取性能提升。

    Latest efforts on cross-lingual relation extraction (XRE) aggressively leverage the language-consistent structural features from the universal dependency (UD) resource, while they may largely suffer from biased transfer (e.g., either target-biased or source-biased) due to the inevitable linguistic disparity between languages. In this work, we investigate an unbiased UD-based XRE transfer by constructing a type of code-mixed UD forest. We first translate the sentence of the source language to the parallel target-side language, for both of which we parse the UD tree respectively. Then, we merge the source-/target-side UD structures as a unified code-mixed UD forest. With such forest features, the gaps of UD-based XRE between the training and predicting phases can be effectively closed. We conduct experiments on the ACE XRE benchmark datasets, where the results demonstrate that the proposed code-mixed UD forests help unbiased UD-based XRE transfer, with which we achieve significant XRE pe
    
[^30]: 基于思维链索引的隐式情感推断

    Reasoning Implicit Sentiment with Chain-of-Thought Prompting. (arXiv:2305.11255v1 [cs.CL])

    [http://arxiv.org/abs/2305.11255](http://arxiv.org/abs/2305.11255)

    本研究提出了一种基于思维链索引的隐式情感推断框架（THOR），通过三次跳推理模仿类人推理过程，支持常识和多跳推理以推断意见的潜在意图，并逐步诱导隐式方面、意见和最终情感极性，实现了在监督和零样本设置上大幅提高技术水平。

    

    情感分析系统通过分析输入文本中的关键观点表达来确定给定目标的情感极性，而在隐式情感分析（ISA）中，观点提示以一种隐含和模糊的方式出现。因此，检测隐式情感需要常识和多跳推理能力来推断意见的潜在意图。受最近思维链索引（CoT）思想的启发，本研究介绍了一种三次跳推理（THOR）CoT框架，模仿ISA的类人推理过程。我们为THOR设计了一个三步提示原则，以逐步诱导隐式方面、意见和最终情感极性。我们的THOR+Flan-T5（11B）在监督设置上将技术水平推进了超过6％的F1值。更为显著的是，THOR+GPT3（175B）在零样本设置上将技术水平提升了超过50％的F1值。我们的代码位于https://github.com/scofield7419/THOR-ISA 。

    While sentiment analysis systems try to determine the sentiment polarities of given targets based on the key opinion expressions in input texts, in implicit sentiment analysis (ISA) the opinion cues come in an implicit and obscure manner. Thus detecting implicit sentiment requires the common-sense and multi-hop reasoning ability to infer the latent intent of opinion. Inspired by the recent chain-of-thought (CoT) idea, in this work we introduce a Three-hop Reasoning (THOR) CoT framework to mimic the human-like reasoning process for ISA. We design a three-step prompting principle for THOR to step-by-step induce the implicit aspect, opinion, and finally the sentiment polarity. Our THOR+Flan-T5 (11B) pushes the state-of-the-art (SoTA) by over 6% F1 on supervised setup. More strikingly, THOR+GPT3 (175B) boosts the SoTA by over 50% F1 on zero-shot setting. Our code is at https://github.com/scofield7419/THOR-ISA.
    
[^31]: 大型语言模型可以被引导来规避AI生成的文本检测

    Large Language Models can be Guided to Evade AI-Generated Text Detection. (arXiv:2305.10847v1 [cs.CL])

    [http://arxiv.org/abs/2305.10847](http://arxiv.org/abs/2305.10847)

    本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。

    

    大型语言模型在包括论文写作和问答等多个任务中展现出了出色的表现。然而，必须解决这些模型潜在的误用问题，否则可能导致抄袭和垃圾信息等不良后果。本研究揭示，通过精心设计的提示语，LLMs可以有效地规避检测系统。我们提出了一种新颖的基于替换的上下文示例优化方法（SICO），用于自动生成这种提示语。在三个现实任务中，LLMs可能被误用，在SICO的帮助下，ChatGPT成功地规避了六项现有的检测器，平均导致0.54的AUC下降。令人惊讶的是，在大多数情况下，这些检测器的表现甚至比随机分类器还要差。这些结果坚定地揭示了现有检测器的脆弱性。

    Large Language Models (LLMs) have demonstrated exceptional performance in a variety of tasks, including essay writing and question answering. However, it is crucial to address the potential misuse of these models, which can lead to detrimental outcomes such as plagiarism and spamming. Recently, several detectors have been proposed, including fine-tuned classifiers and various statistical methods. In this study, we reveal that with the aid of carefully crafted prompts, LLMs can effectively evade these detection systems. We propose a novel Substitution-based In-Context example Optimization method (SICO) to automatically generate such prompts. On three real-world tasks where LLMs can be misused, SICO successfully enables ChatGPT to evade six existing detectors, causing a significant 0.54 AUC drop on average. Surprisingly, in most cases these detectors perform even worse than random classifiers. These results firmly reveal the vulnerability of existing detectors. Finally, the strong perfor
    
[^32]: 学习模拟自然语言反馈以进行交互式语义解析

    Learning to Simulate Natural Language Feedback for Interactive Semantic Parsing. (arXiv:2305.08195v1 [cs.CL])

    [http://arxiv.org/abs/2305.08195](http://arxiv.org/abs/2305.08195)

    本研究提出了通过模拟自然语言反馈来进行交互式语义解析的新任务，该方法可以在低数据情况下取得与使用人工注释反馈数据训练所获得的相当的错误纠正性能。

    

    基于自然语言反馈的交互式语义解析已经成为比传统的一次语义解析更实用的场景，其中用户提供反馈来纠正解析器的错误。然而，以往的研究极大地依赖于人工注释的反馈数据来训练交互式语义解析器，这种方法代价高昂且不可扩展。在本研究中，我们提出了一个新任务，即模拟自然语言反馈以用于交互式语义解析。我们配合该任务使用了一个新的反馈评估器。该评估器专门设计用于评估模拟反馈的质量，基于此我们可以决定最佳的反馈模拟器。在一个文本到SQL的数据集上，我们展示了我们的反馈模拟器可以生成高质量的自然语言反馈以增强特定解析器的错误纠正能力。在低数据情况下，我们的反馈模拟器可以帮助达到与使用代价高昂的完整人工注释反馈数据训练所获得的相当的错误纠正性能。

    Interactive semantic parsing based on natural language (NL) feedback, where users provide feedback to correct the parser mistakes, has emerged as a more practical scenario than the traditional one-shot semantic parsing. However, prior work has heavily relied on human-annotated feedback data to train the interactive semantic parser, which is prohibitively expensive and not scalable. In this work, we propose a new task of simulating NL feedback for interactive semantic parsing. We accompany the task with a novel feedback evaluator. The evaluator is specifically designed to assess the quality of the simulated feedback, based on which we decide the best feedback simulator from our proposed variants. On a text-to-SQL dataset, we show that our feedback simulator can generate high-quality NL feedback to boost the error correction ability of a specific parser. In low-data settings, our feedback simulator can help achieve comparable error correction performance as trained using the costly, full
    
[^33]: LLM驱动的生成式新闻推荐初探

    A First Look at LLM-Powered Generative News Recommendation. (arXiv:2305.06566v1 [cs.IR])

    [http://arxiv.org/abs/2305.06566](http://arxiv.org/abs/2305.06566)

    本文介绍了一种LLM驱动的生成式新闻推荐框架GENRE，它利用预训练语义知识丰富新闻数据，通过从模型设计转移到提示设计提供灵活而统一的解决方案，实现了个性化新闻生成、用户画像和新闻摘要。

    

    个性化的新闻推荐系统已成为用户浏览海量在线新闻内容所必需的工具，然而现有的新闻推荐系统面临着冷启动问题、用户画像建模和新闻内容理解等重大挑战。先前的研究通常通过模型设计遵循一种不灵活的例行程序来解决特定的挑战，但在理解新闻内容和捕捉用户兴趣方面存在局限性。在本文中，我们介绍了GENRE，一种LLM驱动的生成式新闻推荐框架，它利用来自大型语言模型的预训练语义知识来丰富新闻数据。我们的目标是通过从模型设计转移到提示设计来提供一种灵活而统一的新闻推荐解决方案。我们展示了GENRE在个性化新闻生成、用户画像和新闻摘要中的应用。使用各种流行的推荐模型进行的大量实验证明了GENRE的有效性。

    Personalized news recommendation systems have become essential tools for users to navigate the vast amount of online news content, yet existing news recommenders face significant challenges such as the cold-start problem, user profile modeling, and news content understanding. Previous works have typically followed an inflexible routine to address a particular challenge through model design, but are limited in their ability to understand news content and capture user interests. In this paper, we introduce GENRE, an LLM-powered generative news recommendation framework, which leverages pretrained semantic knowledge from large language models to enrich news data. Our aim is to provide a flexible and unified solution for news recommendation by moving from model design to prompt design. We showcase the use of GENRE for personalized news generation, user profiling, and news summarization. Extensive experiments with various popular recommendation models demonstrate the effectiveness of GENRE. 
    
[^34]: 基于比较先验的辅助，提高放射学报告生成质量

    Boosting Radiology Report Generation by Infusing Comparison Prior. (arXiv:2305.04561v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04561](http://arxiv.org/abs/2305.04561)

    本论文提出一种利用基于规则的标记器提取比较先验信息的方法，将其无缝地集成到transformer-based模型中，从而提高生成放射学报告的准确性和全面性，实现了在评估指标上的最先进性能。

    

    最近，基于transformer的模型在从胸部X光图像生成放射学报告方面取得了显着进展。然而，一个突出的挑战仍然存在：这些模型经常缺乏先前的知识，导致生成错误地提到不存在的先前检查的综合报告。这种差异可以归因于放射科医师和生成模型之间的知识差距。虽然放射科医生拥有患者特定的先前信息，但这些模型仅在特定时间点接收X光图像。为了解决这个问题，我们提出了一种新的方法，利用基于规则的标记器从放射学报告中提取比较先验信息。然后，将提取的比较先验无缝地集成到最先进的transformer-based模型中，从而使其能够生成更实际和全面的报告。我们的方法在英语报告数据集上进行评估，如IU X-ray和MIMIC-CXR。结果表明，我们的方法超过了基线模型，并在各种评估指标上实现了最先进的性能。

    Recent transformer-based models have made significant strides in generating radiology reports from chest X-ray images. However, a prominent challenge remains: these models often lack prior knowledge, resulting in the generation of synthetic reports that mistakenly reference non-existent prior exams. This discrepancy can be attributed to a knowledge gap between radiologists and the generation models. While radiologists possess patient-specific prior information, the models solely receive X-ray images at a specific time point. To tackle this issue, we propose a novel approach that leverages a rule-based labeler to extract comparison prior information from radiology reports. This extracted comparison prior is then seamlessly integrated into state-of-the-art transformer-based models, enabling them to produce more realistic and comprehensive reports. Our method is evaluated on English report datasets, such as IU X-ray and MIMIC-CXR. The results demonstrate that our approach surpasses baseli
    
[^35]: 面向文本级机器翻译的目标侧数据增强方法

    Target-Side Augmentation for Document-Level Machine Translation. (arXiv:2305.04505v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04505](http://arxiv.org/abs/2305.04505)

    本文介绍了一种目标侧数据增强方法，通过引入一个数据增强模型来为每个源文档生成潜在的翻译，从而降低了文本级机器翻译的数据稀疏性的风险，得到了比以前最好的系统高2.30 s-BLEU并在基准测试中取得了新的最优结果。

    

    文本级机器翻译因其长输入长度和少量的训练数据而面临数据稀疏性的挑战，增加了学习虚假模式的风险。为了应对这一挑战，我们提出了一种目标侧数据增强方法，引入了一个数据增强模型来为每个源文档生成许多潜在的翻译。在这些更广泛的翻译上进行学习，一个MT模型可以学习到一个平滑的分布，从而降低数据稀疏性的风险。我们证明了后验分布估计的DA模型大大提高了MT的性能，在新闻和欧洲议会基准测试上比以前最好的系统高2.30 s-BLEU，并取得了新的最优结果。我们的代码可在 https://github.com/baoguangsheng/target-side-augmentation 找到。

    Document-level machine translation faces the challenge of data sparsity due to its long input length and a small amount of training data, increasing the risk of learning spurious patterns. To address this challenge, we propose a target-side augmentation method, introducing a data augmentation (DA) model to generate many potential translations for each source document. Learning on these wider range translations, an MT model can learn a smoothed distribution, thereby reducing the risk of data sparsity. We demonstrate that the DA model, which estimates the posterior distribution, largely improves the MT performance, outperforming the previous best system by 2.30 s-BLEU on News and achieving new state-of-the-art on News and Europarl benchmarks. Our code is available at https://github.com/baoguangsheng/target-side-augmentation.
    
[^36]: 自我编辑：针对代码生成的故障感知式代码编辑器

    Self-Edit: Fault-Aware Code Editor for Code Generation. (arXiv:2305.04087v1 [cs.SE])

    [http://arxiv.org/abs/2305.04087](http://arxiv.org/abs/2305.04087)

    本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。

    

    大型语言模型（LLMs）在竞技编程任务中生成代码的能力已经得到证明，但由于样本数量有限，LLMs仍然存在较低的准确性。受人类编程过程的启发，我们提出了一种生成和编辑的方法，利用LLMs生成的代码的执行结果来提高竞技编程任务的代码质量。我们在问题中提供的示例测试用例上执行生成的代码，并将执行结果包含在补充性注释中。利用这个注释作为指导，我们的故障感知式代码编辑器用于纠正生成的代码中的错误。我们在两个竞技编程数据集上进行了广泛的评估，涵盖了九个不同的LLMs。与直接从LLMs生成相比，我们的方法可以在APPS-dev上将pass@1的平均值提高89％，在APPS-test上提高31％，在HumanEval上提高48％，超过了九个流行的代码生成LLMs，参数大小范围为110M-t。

    Large language models (LLMs) have demonstrated an impressive ability to generate codes on competitive programming tasks. However, with limited sample numbers, LLMs still suffer from poor accuracy. Inspired by the process of human programming, we propose a generate-and-edit approach that utilizes execution results of the generated code from LLMs to improve the code quality on the competitive programming task. We execute the generated code on the example test case provided in the question and wrap execution results into a supplementary comment. Utilizing this comment as guidance, our fault-aware code editor is employed to correct errors in the generated code. We perform extensive evaluations across two competitive programming datasets with nine different LLMs. Compared to directly generating from LLMs, our approach can improve the average of pass@1 by 89\% on APPS-dev, 31\% on APPS-test, and 48\% on HumanEval over nine popular code generation LLMs with parameter sizes ranging from 110M t
    
[^37]: 从文本中实现少样本领域自适应视觉融合事件检测

    Few-shot Domain-Adaptive Visually-fused Event Detection from Text. (arXiv:2305.03517v1 [cs.CL])

    [http://arxiv.org/abs/2305.03517](http://arxiv.org/abs/2305.03517)

    本文提出了一种基于视觉融合和领域自适应的事件检测方法，可以用少量标记数据训练并且适应于新领域。

    

    近年来，将辅助模态如图像整合到事件检测模型中已经引起人们的越来越多的关注。自然语言描述情境的复杂性促使研究人员利用相关的视觉上下文来提高事件检测的性能。然而，目前这个领域的方法在数据稀缺性方面存在问题，需要许多标记好的文本-图像对来训练模型。此外，在推断时无法获得视觉上下文的限制也会对这些模型的性能产生负面影响，使其在实际场景中难以应用。本文提出了一种新颖的领域自适应视觉融合事件检测方法，可以用很少的标记图像-文本配对数据点进行训练。具体来说，我们引入了一种称为视觉想象器的方法，它可以在没有视觉上下文的情况下从文本中合成图像，并且可以根据需要定制到特定的领域。通过这种方法，我们的方法消除了需要大量标记数据的需求，并且只需少量的标记图像-文本对就可以适应于新领域。我们在基准数据集上评估了我们的方法，并显示其优于现有的最先进的领域自适应事件检测方法。

    Incorporating auxiliary modalities such as images into event detection models has attracted increasing interest over the last few years. The complexity of natural language in describing situations has motivated researchers to leverage the related visual context to improve event detection performance. However, current approaches in this area suffer from data scarcity, where a large amount of labelled text-image pairs are required for model training. Furthermore, limited access to the visual context at inference time negatively impacts the performance of such models, which makes them practically ineffective in real-world scenarios. In this paper, we present a novel domain-adaptive visually-fused event detection approach that can be trained on a few labelled image-text paired data points. Specifically, we introduce a visual imaginator method that synthesises images from text in the absence of visual context. Moreover, the imaginator can be customised to a specific domain. In doing so, our
    
[^38]: SI-LSTM: 用于对话情感识别的说话人混合长短期记忆和跨模态注意力机制

    SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation. (arXiv:2305.03506v1 [cs.CL])

    [http://arxiv.org/abs/2305.03506](http://arxiv.org/abs/2305.03506)

    SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    

    跨模态的对话情感识别对于智能医疗、对话人工智能和聊天历史观点挖掘等应用至关重要。本文提出了一种基于说话人信息增强长短期记忆（SI-LSTM）的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    Emotion Recognition in Conversation~(ERC) across modalities is of vital importance for a variety of applications, including intelligent healthcare, artificial intelligence for conversation, and opinion mining over chat history. The crux of ERC is to model both cross-modality and cross-time interactions throughout the conversation. Previous methods have made progress in learning the time series information of conversation while lacking the ability to trace down the different emotional states of each speaker in a conversation. In this paper, we propose a recurrent structure called Speaker Information Enhanced Long-Short Term Memory (SI-LSTM) for the ERC task, where the emotional states of the distinct speaker can be tracked in a sequential way to enhance the learning of the emotion in conversation. Further, to improve the learning of multimodal features in ERC, we utilize a cross-modal attention component to fuse the features between different modalities and model the interaction of the 
    
[^39]: 利用大型语言模型从医生-患者对话中生成临床笔记：来自MEDIQA-Chat的见解

    Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat. (arXiv:2305.02220v1 [cs.CL])

    [http://arxiv.org/abs/2305.02220](http://arxiv.org/abs/2305.02220)

    本文介绍了使用大型语言模型从医生-患者对话中自动生成临床笔记的研究，采用少样本上下文学习法所生成笔记表现优秀，且可与人工编写的笔记媲美。

    

    本文描述了我们在MEDIQA-Chat 2023共享任务中提交的自动临床笔记生成方案。我们报告了两种方法的结果：第一种是在共享任务数据上微调预训练语言模型（PLM），第二种是使用大型语言模型（LLM）的少样本上下文学习（ICL）。两种方法都取得了高性能，如通过自动度量标准（例如ROUGE，BERTScore）测量，并分别在所有提交的方案中排名第二和第一。专家审核表明，通过基于ICL的方法使用GPT-4生成的笔记与人工编写的笔记一样受欢迎，这使得它成为从医生-患者对话中自动生成笔记的有前途的路径。

    This paper describes our submission to the MEDIQA-Chat 2023 shared task for automatic clinical note generation from doctor-patient conversations. We report results for two approaches: the first fine-tunes a pre-trained language model (PLM) on the shared task data, and the second uses few-shot in-context learning (ICL) with a large language model (LLM). Both achieve high performance as measured by automatic metrics (e.g. ROUGE, BERTScore) and ranked second and first, respectively, of all submissions to the shared task. Expert human scrutiny indicates that notes generated via the ICL-based approach with GPT-4 are preferred about as often as human-written notes, making it a promising path toward automated note generation from doctor-patient conversations.
    
[^40]: 位置偏差对token分类中的语言模型的影响

    Impact of Position Bias on Language Models in Token Classification. (arXiv:2304.13567v1 [cs.CL])

    [http://arxiv.org/abs/2304.13567](http://arxiv.org/abs/2304.13567)

    研究了语言模型在token分类任务中的位置偏差问题，通过实验表明在具体任务中，BERT、ERNIE、ELECTRA等编码器以及GPT2和BLOOM等解码器的平均性能下降了3%和9%。

    

    语言模型在自然语言处理任务中表现出了最先进的性能。命名实体识别(NER)或词性标注等下游任务已知存在数据不平衡问题，特别是在正负示例的比例和类不平衡方面。本文研究了语言模型的另一个特定问题，即token分类任务中正示例的位置偏差。因此，我们对基于Token分类基准测试的语言模型的性能进行了深入的位置偏差评估。我们的研究包括CoNLL03和OntoNote5.0用于NER，English Tree Bank UD_en和TweeBank用于POS标记。我们提出了一种评估方法，以研究Transformer模型中的位置偏差。我们发现像BERT、ERNIE、ELECTRA这样的编码器和像GPT2 和BLOOM这样的解码器平均性能下降了3%和9%。

    Language Models (LMs) have shown state-of-the-art performance in Natural Language Processing (NLP) tasks. Downstream tasks such as Named Entity Recognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data imbalance issues, specifically in terms of the ratio of positive to negative examples, and class imbalance. In this paper, we investigate an additional specific issue for language models, namely the position bias of positive examples in token classification tasks. Therefore, we conduct an in-depth evaluation of the impact of position bias on the performance of LMs when fine-tuned on Token Classification benchmarks. Our study includes CoNLL03 and OntoNote5.0 for NER, English Tree Bank UD_en and TweeBank for POS tagging. We propose an evaluation approach to investigate position bias in Transformer models. We show that encoders like BERT, ERNIE, ELECTRA, and decoders such as GPT2 and BLOOM can suffer from this bias with an average drop of 3\% and 9\% in their performan
    
[^41]: 评估印度语言间语义分析

    Evaluating Inter-Bilingual Semantic Parsing for Indian Languages. (arXiv:2304.13005v1 [cs.CL])

    [http://arxiv.org/abs/2304.13005](http://arxiv.org/abs/2304.13005)

    本研究提出了一个11种不同的印度语言的间语言Seq2seq语义分析数据集IE-SEMPARSE，并评估了现有的多语言seq2seq模型在其中的表现。

    

    尽管印度语言（IndicNLP）的自然语言生成取得了重大进展，但对于像语义解析这样的复杂结构任务缺乏数据集。导致此严重缺口的一个原因是逻辑形式的复杂性，这使得英语到多语言的翻译变得困难。 这个过程涉及将逻辑形式、意图和槽与翻译的非结构化话语对齐。为了解决这个问题，我们提出了一个11种不同的印度语言的间语言Seq2seq语义分析数据集IE-SEMPARSE。我们强调了所提出任务的实用性，并评估了现有的多语言seq2seq模型在几种训练-测试策略之间的性能。我们的实验揭示了原始多语言语义分析数据集（如mTOP、多语言TOP和multiATIS++）和我们提出的IE-SEMPARSE套件之间的高相关性。

    Despite significant progress in Natural Language Generation for Indian languages (IndicNLP), there is a lack of datasets around complex structured tasks such as semantic parsing. One reason for this imminent gap is the complexity of the logical form, which makes English to multilingual translation difficult. The process involves alignment of logical forms, intents and slots with translated unstructured utterance. To address this, we propose an Inter-bilingual Seq2seq Semantic parsing dataset IE-SEMPARSE for 11 distinct Indian languages. We highlight the proposed task's practicality, and evaluate existing multilingual seq2seq models across several train-test strategies. Our experiment reveals a high correlation across performance of original multilingual semantic parsing datasets (such as mTOP, multilingual TOP and multiATIS++) and our proposed IE-SEMPARSE suite.
    
[^42]: 上下文依赖性嵌入话语表示在对话情绪识别中的应用

    Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations. (arXiv:2304.08216v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08216](http://arxiv.org/abs/2304.08216)

    本论文利用预训练变换器语言模型的上下文依赖性嵌入话语表示，从而在对话情绪识别中取得了非常良好的效果。

    

    随着对话代理变得越来越普遍，对话情绪识别（ERC）越来越重要。识别情感对于有效的交流至关重要，是开发有效并且具有共情能力的对话代理的重要组成部分。对话背景的知识和理解对于识别交流者的情感非常有价值。因此，我们利用对话背景来进行ERC，即关注先前的对话回合。通常，建模对话上下文的方法是产生每个话语的上下文无关表示，然后对这些话语进行上下文模型处理。本文提出了利用预训练变换器语言模型的上下文依赖性嵌入话语表示。在我们的方法中，我们将对话背景追加到话语中，然后将其馈入基于变换器的模型中，该模型将产生相应的上下文嵌入表示。我们在三个公共数据集上评估了我们的方法，并证明在与上下文无关方法和最先进的模型相比中具有很好的效果。

    Emotion Recognition in Conversations (ERC) has been gaining increasing importance as conversational agents become more and more common. Recognizing emotions is key for effective communication, being a crucial component in the development of effective and empathetic conversational agents. Knowledge and understanding of the conversational context are extremely valuable for identifying the emotions of the interlocutor. We thus approach Emotion Recognition in Conversations leveraging the conversational context, i.e., taking into attention previous conversational turns. The usual approach to model the conversational context has been to produce context-independent representations of each utterance and subsequently perform contextual modeling of these. Here we propose context-dependent embedding representations of each utterance by leveraging the contextual representational power of pre-trained transformer language models. In our approach, we feed the conversational context appended to the ut
    
[^43]: 通过日语文体分析区分ChatGPT(-3.5,-4)的生成文本与人类写作的论文

    Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through Japanese stylometric analysis. (arXiv:2304.05534v1 [cs.CL])

    [http://arxiv.org/abs/2304.05534](http://arxiv.org/abs/2304.05534)

    本研究通过比较GPT(-3.5和-4)生成的日语文体特征与人类写作的学术论文，证明了它们在文体特征上有显著区别。

    

    文本生成的人工智能，包括OpenAI的GPT-3.5和GPT-4，引起了全球广泛关注。本研究比较了GPT(-3.5和-4)生成和人类撰写的日语文体特征。通过多维尺度分析，将216个文本（36位单一作者的72篇学术论文、72篇GPT-3.5生成的文本和72篇GPT-4生成的文本）根据词性的二元组，词尾的二元组，逗号的位置和功能词的比例分成三类，结果显示出GPT(-3.5，-4)和人类之间在文体特征上有明显差异。

    Text-generative artificial intelligence (AI), including ChatGPT, equipped with GPT-3.5 and GPT-4, from OpenAI, has attracted considerable attention worldwide. In this study, first, we compared Japanese stylometric features generated by GPT (-3.5 and -4) and those written by humans. In this work, we performed multi-dimensional scaling (MDS) to confirm the classification of 216 texts into three classes (72 academic papers written by 36 single authors, 72 texts generated by GPT-3.5, and 72 texts generated by GPT-4 on the basis of the titles of the aforementioned papers) focusing on the following stylometric features: (1) bigrams of parts-of-speech, (2) bigram of postpositional particle words, (3) positioning of commas, and (4) rate of function words. MDS revealed distinct distributions at each stylometric feature of GPT (-3.5 and -4) and human. Although GPT-4 is more powerful than GPT-3.5 because it has more parameters, both GPT (-3.5 and -4) distributions are likely to overlap. These res
    
[^44]: 超越不对称性：结构剪枝提高序列到序列模型的推断效率

    To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency. (arXiv:2304.02721v1 [cs.CL])

    [http://arxiv.org/abs/2304.02721](http://arxiv.org/abs/2304.02721)

    本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。

    

    序列到序列语言模型可以用于生成连贯，相关和简洁的抽象摘要。但是，模型大小可能使得在延迟敏感或 Web 规模的实现中部署变得困难。本文研究了模型大小、结构化剪枝、推断效率和广泛使用的摘要数据集上的摘要准确性之间的关系。我们表明，模型准确性与编码器大小有关，而推理效率与解码器有关。使用不对称剪枝可导致推断延迟的近3倍提高，Rouge-2的损失约为1点。此外，我们发现，平均性能降低和不对称性的作用在模型大小和数据集变化方面是一致的。

    Sequence-to-sequence language models can be used to produce abstractive summaries which are coherent, relevant, and concise. Still, model sizes can make deployment in latency-sensitive or web-scale implementations difficult. This paper studies the relationship between model size, structured pruning, inference efficiency, and summarization accuracy on widely used summarization datasets. We show that model accuracy is tied to the encoder size while inference efficiency is connected to the decoder. Using asymmetric pruning can lead to nearly 3x improvement in inference latency with ~1 point loss in Rouge-2. Moreover, we find both the average degradation and the role of asymmetry to be consistent across model sizes and variations in datasets.
    
[^45]: 探索生物医学实体链接中的部分知识库推理

    Exploring Partial Knowledge Base Inference in Biomedical Entity Linking. (arXiv:2303.10330v1 [cs.CL])

    [http://arxiv.org/abs/2303.10330](http://arxiv.org/abs/2303.10330)

    本文探索了生物医学实体链接中的部分知识库推理问题，发现由于精度下降导致EL性能出现灾难性下降，而且EL范例无法处理无法链接的提及，提出了两种赎回方法来解决NIL问题。

    

    生物医学实体链接（EL）包括命名实体识别（NER）和命名实体消歧（NED）。EL模型在由预定义的知识库标记的语料库上进行训练。然而，常见的情况是只有知识库的子集中的实体对利益相关者有价值。我们称这种情况为部分知识库推理：使用一个知识库对EL模型进行训练，并在没有进一步训练的情况下对其部分进行推理。在这项工作中，我们给出了这种实际上非常有价值但明显不够研究的情况的详细定义和评估方法，并评估了三个代表性的EL范例的方法。我们构建了部分知识库推理基准，并发现由于大量精度下降导致EL性能出现灾难性下降。我们的发现揭示了这些EL范例无法正确处理无法链接的提及（NIL），因此它们对部分知识库推理不具有鲁棒性。我们还提出了两种简单有效的赎回方法来解决NIL问题。

    Biomedical entity linking (EL) consists of named entity recognition (NER) and named entity disambiguation (NED). EL models are trained on corpora labeled by a predefined KB. However, it is a common scenario that only entities within a subset of the KB are precious to stakeholders. We name this scenario partial knowledge base inference: training an EL model with one KB and inferring on the part of it without further training. In this work, we give a detailed definition and evaluation procedures for this practically valuable but significantly understudied scenario and evaluate methods from three representative EL paradigms. We construct partial KB inference benchmarks and witness a catastrophic degradation in EL performance due to dramatically precision drop. Our findings reveal these EL paradigms can not correctly handle unlinkable mentions (NIL), so they are not robust to partial KB inference. We also propose two simple-and-effective redemption methods to combat the NIL issue with litt
    
[^46]: 检测大型语言模型生成文字的科学

    The Science of Detecting LLM-Generated Texts. (arXiv:2303.07205v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.07205](http://arxiv.org/abs/2303.07205)

    本文综述了现有大型语言模型生成文本检测技术并提出了关键考虑因素，如开发全面评估指标和开源 LLM 所构成的威胁。

    

    大型语言模型 (LLMs) 的出现导致了高度复杂且几乎难以区分出是否为人类创作的 LLM 生成文字。但是，这也引发了对此类文字潜在误用的担忧，例如传播错误信息和在教育系统中造成混乱。尽管已提出许多检测方法，但关于其成就和挑战的全面理解仍然缺乏。本文旨在概述现有的 LLM 生成文本检测技术，并增强对语言生成模型的控制和监管。此外，我们强调未来研究的重要考虑因素，包括开发全面评估指标和开源 LLM 所构成的威胁，以推动 LLM 生成文本检测领域的进展。

    The emergence of large language models (LLMs) has resulted in the production of LLM-generated texts that is highly sophisticated and almost indistinguishable from texts written by humans. However, this has also sparked concerns about the potential misuse of such texts, such as spreading misinformation and causing disruptions in the education system. Although many detection approaches have been proposed, a comprehensive understanding of the achievements and challenges is still lacking. This survey aims to provide an overview of existing LLM-generated text detection techniques and enhance the control and regulation of language generation models. Furthermore, we emphasize crucial considerations for future research, including the development of comprehensive evaluation metrics and the threat posed by open-source LLMs, to drive progress in the area of LLM-generated text detection.
    
[^47]: 带有影响力的上下文示例选择

    In-context Example Selection with Influences. (arXiv:2302.11042v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.11042](http://arxiv.org/abs/2302.11042)

    本文提出使用带有影响力的示例选择方法来提高上下文学习(ICL)的性能，分析表明正面和负面示例对ICL取得的性能有高达16.3%的影响，案例研究中也发现了示例排序中的“最近性偏差”现象。

    

    上下文学习(ICL)是从大语言模型(LLM)中出现的一种强大的范例。尽管有着许多有利方面，ICL的性能仍然对输入示例非常敏感。本文提出使用$\textit{上下文影响}$来直接分析少样本ICL的性能。我们提出了基于影响力的示例选择方法，可以识别出正面和负面示例，在9个SuperGLUE任务的评估中优于几种基准线。我们的分析揭示，在使用最正面示例和最负面示例之间，性能差异可高达$16.3\%$。在一个案例研究中，我们将基于影响力的框架应用于量化少样本ICL示例排序中最近性偏差的现象。

    In-context learning (ICL) is a powerful paradigm emerged from large language models (LLMs). Despite its promises, ICL performance is known to be highly sensitive to input examples. In this work, we use $\textit{in-context influences}$ to analyze few-shot ICL performance directly from the in-context examples. Our proposed influence-based example selection method can identify both positive and negative examples, outperforming several baselines when evaluated on 9 SuperGLUE tasks. Our analysis uncovers up to a $16.3\%$ performance gap between using the most negative in-context examples compared to the most positive. In a case study, we apply our influence-based framework to quantify the phenomena of recency bias in example ordering for few-shot ICL.
    
[^48]: 基于CTC和最优传输的语音翻译预训练方法

    Pre-training for Speech Translation: CTC Meets Optimal Transport. (arXiv:2301.11716v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11716](http://arxiv.org/abs/2301.11716)

    本文提出了一种基于CTC和最优传输的语音翻译预训练方法，可以有效减小语音和文本模态之间的差距，提高最终的ST准确性。

    

    语音到文本翻译(ST)中的模态差距是一个重要挑战，该文提出了一种预训练方法来减轻这个问题，无需改变ST模型的架构。首先，本文表明连接时序分类(CTC)损失可以通过设计来减小模态差距。通过与更常见的交叉熵损失的定量比较，我们证明了使用CTC进行预训练可以始终实现更好的最终ST准确性。其次，我们提出了一种结合CTC和最优传输的新型预训练方法以进一步减小这种差距。我们的实验证明了使用CTC和最优传输进行预训练相对于仅使用CTC进行预训练和没有进行预训练的基线模型均能够提供持续改进。

    The gap between speech and text modalities is a major challenge in speech-to-text translation (ST). Different methods have been proposed to reduce this gap, but most of them require architectural changes in ST training. In this work, we propose to mitigate this issue at the pre-training stage, requiring no change in the ST model. First, we show that the connectionist temporal classification (CTC) loss can reduce the modality gap by design. We provide a quantitative comparison with the more common cross-entropy loss, showing that pre-training with CTC consistently achieves better final ST accuracy. Nevertheless, CTC is only a partial solution and thus, in our second contribution, we propose a novel pre-training method combining CTC and optimal transport to further reduce this gap. Our method pre-trains a Siamese-like model composed of two encoders, one for acoustic inputs and the other for textual inputs, such that they produce representations that are close to each other in the Wassers
    
[^49]: ExaRanker: 解释增强型神经排序模型

    ExaRanker: Explanation-Augmented Neural Ranker. (arXiv:2301.10521v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10521](http://arxiv.org/abs/2301.10521)

    本文提出了一个名为ExaRanker的解释增强型神经排序模型，使用大型语言模型增强检索数据集，可在输出相关度标签与解释时提高性能。

    

    最近的研究表明，让大型语言模型在输出答案前生成解释是提高各种推理任务性能的有效策略。本文提出神经排序模型也受益于解释。我们使用GPT-3.5等语言模型来增强具有解释的检索数据集，并训练一个序列到序列的排序模型，以输出给定查询-文档对的相关度标签和解释。我们的模型被称为ExaRanker，在使用合成解释的几千个样本进行微调后，性能与无解释的3倍样本微调的模型相当。此外，ExaRanker模型在排序过程中没有额外的计算成本，并允许根据需要请求解释。

    Recent work has shown that inducing a large language model (LLM) to generate explanations prior to outputting an answer is an effective strategy to improve performance on a wide range of reasoning tasks. In this work, we show that neural rankers also benefit from explanations. We use LLMs such as GPT-3.5 to augment retrieval datasets with explanations and train a sequence-to-sequence ranking model to output a relevance label and an explanation for a given query-document pair. Our model, dubbed ExaRanker, finetuned on a few thousand examples with synthetic explanations performs on par with models finetuned on 3x more examples without explanations. Furthermore, the ExaRanker model incurs no additional computational cost during ranking and allows explanations to be requested on demand.
    
[^50]: 预计算内存或实时编码？一种检索增强的混合方法使计算资源得到最大利用

    Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute. (arXiv:2301.10448v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10448](http://arxiv.org/abs/2301.10448)

    本文提出了一种检索增强的混合方法，LUMEN，它预先计算大部分检索表示，并使用一个实时编码器进行完成编码，相较于纯内存和FiD，LUMEN在多个问答任务中具有更好的性能，且成本更低。

    

    检索增强语言模型，如解码器中的Fusion，具有强大的能力，在各种知识密集型任务中设置了最新的技术水平。然而，由于需要对大量检索到的段落进行编码，它们也非常昂贵。一些工作通过将文本语料库预编码为内存，并直接检索密集表示来避免这种成本。但是，预编码内存会导致严重的质量惩罚，因为内存表示未针对当前输入进行调整。我们提出了LUMEN，它是这两个极端之间的混合体，预先计算大部分检索表示，并使用实时编码器完成编码，该实时编码器是基于问题进行条件化的，并为任务进行了微调。我们表明，在多个问答任务中，LUMEN明显优于纯内存，同时比FiD便宜得多，并且在给定的计算资源预算下，LUMEN的效果优于两者。此外，当模型规模增大时，LUMEN相对于FiD的优势也增加。

    Retrieval-augmented language models such as Fusion-in-Decoder are powerful, setting the state of the art on a variety of knowledge-intensive tasks. However, they are also expensive, due to the need to encode a large number of retrieved passages. Some work avoids this cost by pre-encoding a text corpus into a memory and retrieving dense representations directly. However, pre-encoding memory incurs a severe quality penalty as the memory representations are not conditioned on the current input. We propose LUMEN, a hybrid between these two extremes, pre-computing the majority of the retrieval representation and completing the encoding on the fly using a live encoder that is conditioned on the question and fine-tuned for the task. We show that LUMEN significantly outperforms pure memory on multiple question-answering tasks while being much cheaper than FiD, and outperforms both for any given compute budget. Moreover, the advantage of LUMEN over FiD increases with model size.
    
[^51]: 跨文档关系抽取的多跳证据检索

    Multi-hop Evidence Retrieval for Cross-document Relation Extraction. (arXiv:2212.10786v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10786](http://arxiv.org/abs/2212.10786)

    本文介绍了一个名为MR.COD的多跳证据检索方法，用于支持跨文档关系抽取。实验表明该方法有效地获取了跨文档证据，并提升了封闭和开放设置中的性能。

    

    关系抽取(RE)已经扩展到跨文档场景中，因为许多关系不仅仅在一个文档中描述。这不可避免地带来了有效的开放空间证据检索的挑战，以支持跨文档关系的推断，同时也带来了多跳推理的挑战，以处理散布在开放式文档集中的实体和证据。为了应对这些挑战，我们提出了MR.COD(跨文档关系抽取的多跳证据检索)，这是一种基于证据路径挖掘和排序的多跳证据检索方法。我们探索了多个检索器的变体，以显示证据检索在跨文档RE中的重要性。我们还为此设置提出了一种上下文密集的检索器。在CodRED上的实验表明，MR.COD的证据检索有效地获取了跨文档证据，并提升了封闭和开放设置中的端到端RE性能。

    Relation Extraction (RE) has been extended to cross-document scenarios because many relations are not simply described in a single document. This inevitably brings the challenge of efficient open-space evidence retrieval to support the inference of cross-document relations, along with the challenge of multi-hop reasoning on top of entities and evidence scattered in an open set of documents. To combat these challenges, we propose MR.COD (Multi-hop evidence retrieval for Cross-document relation extraction), which is a multi-hop evidence retrieval method based on evidence path mining and ranking. We explore multiple variants of retrievers to show evidence retrieval is essential in cross-document RE. We also propose a contextual dense retriever for this setting. Experiments on CodRED show that evidence retrieval with MR.COD effectively acquires crossdocument evidence and boosts end-to-end RE performance in both closed and open settings.
    
[^52]: 超越对比学习：一种多语言检索的变分生成模型

    Beyond Contrastive Learning: A Variational Generative Model for Multilingual Retrieval. (arXiv:2212.10726v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10726](http://arxiv.org/abs/2212.10726)

    本文提出了一种多语言检索的变分生成模型，可以有效地鼓励源分离，并展示其与对比学习方法的比较结果，该方法在实际检索任务中表现出效果。

    

    对比学习已被成功用于检索语义对齐的句子，但往往需要大批量处理或精心的工程才能奏效。本文提出了一种生成模型，用于学习多语言文本嵌入，可以用于检索或评分句子对。我们的模型在$N$种语言的并行数据上操作，并通过我们引入的一种近似方法，在这个多语言环境中有效地鼓励源分离，将翻译之间共享的语义信息与语体或语言特定变化分开。我们展示了对比和基于生成的方法在学习多语言文本嵌入方面的大规模仔细比较，这是我们所知道的尽管这些方法十分流行却从未比较过的。我们在一系列任务上评估了这种方法，包括语义相似性，双语挖掘和跨语言问题检索——最后一个任务将展示我们的方法在实际检索任务中的有效性。

    Contrastive learning has been successfully used for retrieval of semantically aligned sentences, but it often requires large batch sizes or careful engineering to work well. In this paper, we instead propose a generative model for learning multilingual text embeddings which can be used to retrieve or score sentence pairs. Our model operates on parallel data in $N$ languages and, through an approximation we introduce, efficiently encourages source separation in this multilingual setting, separating semantic information that is shared between translations from stylistic or language-specific variation. We show careful large-scale comparisons between contrastive and generation-based approaches for learning multilingual text embeddings, a comparison that has not been done to the best of our knowledge despite the popularity of these approaches. We evaluate this method on a suite of tasks including semantic similarity, bitext mining, and cross-lingual question retrieval -- the last of which w
    
[^53]: BUMP：一种不忠实最小对比基准，用于评估忠实性度量的超验评估。

    BUMP: A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of Faithfulness Metrics. (arXiv:2212.09955v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09955](http://arxiv.org/abs/2212.09955)

    BUMP是一个不忠实最小对比基准，由889个人写的对比CNN / DailyMail数据集中的摘要进行微小差异处理而得。BUMP可以帮助评估自动忠实性度量，其优于现有基准数据集，因为更具挑战性，且可以表征不同类型的不忠实性。

    

    自动忠实性度量在摘要文本中的广泛应用产生了对基准的需求。虽然现有的基准测量了模型生成的摘要与人类忠实性判断的相关性，但它们不足以诊断指标是否：1）一致，即当错误被引入到摘要中时指出较低的忠实性；2）在人工写作文本中有效；3）对不同的错误类型敏感（因为摘要可以包含多个错误）。为了解决这些需求，我们提出了一个不忠实最小对比基准（BUMP），这是一个由889个对CNN / DailyMail数据集中的摘要进行微小差异处理而得到的，其中摘要中引入了单个错误的人写的摘要对。我们发现BUMP在许多方面补充了现有的基准：1）BUMP中的摘要更难区别，并且在SOTA摘要模型下不太可能；2）与非对比基准数据集不同，BUMP可用于衡量指标是否良好地识别不忠实性。

    The proliferation of automatic faithfulness metrics for summarization has produced a need for benchmarks to evaluate them. While existing benchmarks measure the correlation with human judgements of faithfulness on model-generated summaries, they are insufficient for diagnosing whether metrics are: 1) consistent, i.e., indicate lower faithfulness as errors are introduced into a summary, 2) effective on human-written texts, and 3) sensitive to different error types (as summaries can contain multiple errors). To address these needs, we present a benchmark of unfaithful minimal pairs (BUMP), a dataset of 889 human-written, minimally different summary pairs, where a single error is introduced to a summary from the CNN/DailyMail dataset to produce an unfaithful summary. We find BUMP complements existing benchmarks in a number of ways: 1) the summaries in BUMP are harder to discriminate and less probable under SOTA summarization models, 2) unlike non-pair-based datasets, BUMP can be used to m
    
[^54]: Z-ICL: 使用伪样本进行零样本视角下的上下文学习

    Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations. (arXiv:2212.09865v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09865](http://arxiv.org/abs/2212.09865)

    本文提出了一种新的零样本上下文学习方法Z-ICL，通过构建基于原始文本的伪演示，显著提升了模型的零样本性能水平，同时支持未来优化伪演示提高上下文学习表现而无需标记数据。

    

    虽然大型语言模型可以进行零样本和少样本学习，但当没有提供演示时，性能会显著下降。本文提出了一种新的零样本方法Z-ICL，在给定测试输入的情况下，使用原始文本语料库构建伪演示。具体地，伪演示是通过 (1) 从语料库中找到与测试输入最相近的邻居，并将它们与随机任务标签配对，以及 (2) 应用一组技术来减少模型从生成的演示中直接复制的数量来构建的。在九个分类数据集上的评估表明，Z-ICL 的表现显著优于以前的零样本方法，并在少样本设置中与使用有标记训练数据的上下文学习方法相当。总的来说，Z-ICL 提供了一个显著更高的模型零样本性能水平估计，并支持未来努力发展更好的伪演示来提高上下文学习而无需任何有标记数据。

    Although large language models can be prompted for both zero- and few-shot learning, performance drops significantly when no demonstrations are available. In this paper, we introduce Z-ICL, a new zero-shot method that closes the gap by constructing pseudo-demonstrations for a given test input using a raw text corpus. Concretely, pseudo-demonstrations are constructed by (1) finding the nearest neighbors to the test input from the corpus and pairing them with random task labels, and (2) applying a set of techniques to reduce the amount of direct copying the model does from the resulting demonstrations. Evaluation on nine classification datasets shows that Z-ICL outperforms previous zero-shot methods by a significant margin, and is on par with in-context learning with labeled training data in the few-shot setting. Overall, Z-ICL provides a significantly higher estimate of the zero-shot performance levels of a model, and supports future efforts to develop better pseudo-demonstrations that 
    
[^55]: 通过合并语言模型的权重实现无数据知识融合

    Dataless Knowledge Fusion by Merging Weights of Language Models. (arXiv:2212.09849v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09849](http://arxiv.org/abs/2212.09849)

    本文提出了一种无数据知识融合方法，可以合并在不同训练数据集上建立的单个模型，以得到一个在所有数据集领域上表现良好且可以推广到域外数据的单一模型。

    

    微调预训练语言模型已成为构建下游NLP模型的流行范式。通常情况下，经过微调的模型已经可用，但其训练数据不可用，由于数据隐私或知识产权问题。这就造成了跨模型融合知识以产生更好的单一模型的障碍。在本文中，我们研究了建立在不同训练数据集上的单个模型之间合并的问题，以得到一个在所有数据集领域上表现良好且可以推广到域外数据的单一模型。我们提出了一种无数据知识融合方法，该方法在参数空间中合并模型，由权重引导，以最小化合并模型和单个模型之间的预测差异。在一系列评估设置中，我们展示了该方法显著优于如Fisher加权平均或模型集成等基线。此外，我们发现我们的方法是一个有前途的多语言微调替代方案，因为它可以在不需要任何额外注释数据的情况下实现可比的性能。

    Fine-tuning pre-trained language models has become the prevalent paradigm for building downstream NLP models. Oftentimes fine-tuned models are readily available but their training data is not, due to data privacy or intellectual property concerns. This creates a barrier to fusing knowledge across individual models to yield a better single model. In this paper, we study the problem of merging individual models built on different training data sets to obtain a single model that performs well both across all data set domains and can generalize on out-of-domain data. We propose a dataless knowledge fusion method that merges models in their parameter space, guided by weights that minimize prediction differences between the merged model and the individual models. Over a battery of evaluation settings, we show that the proposed method significantly outperforms baselines such as Fisher-weighted averaging or model ensembling. Further, we find that our method is a promising alternative to multi-
    
[^56]: NusaCrowd：印尼自然语言处理资源的开源倡议

    NusaCrowd: Open Source Initiative for Indonesian NLP Resources. (arXiv:2212.09648v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09648](http://arxiv.org/abs/2212.09648)

    NusaCrowd是一个印尼自然语言处理资源的开源倡议，已汇集137个数据集和118个数据加载程序，为印尼语和印度尼西亚本地语言的自然语言处理研究提供了多种实验手段。

    

    我们提出了NusaCrowd，这是一个协作倡议，旨在收集和统一印尼语言的现有资源，包括开放以前非公开的资源。通过该倡议，我们汇集了137个数据集和118个标准化数据加载程序。数据集的质量已经经过手动和自动评估，它们的价值通过多个实验得到了证明。NusaCrowd的数据收集使得可以创建印尼语和印度尼西亚本地语言的零样本自然语言理解和生成基准，进一步推动了印尼语和印度尼西亚本地语言的多语言自动语音识别基准的创建。我们的工作致力于推进对在使用广泛的语言的自然语言处理（NLP）研究的发展，从而使之受到更多关注。

    We present NusaCrowd, a collaborative initiative to collect and unify existing resources for Indonesian languages, including opening access to previously non-public resources. Through this initiative, we have brought together 137 datasets and 118 standardized data loaders. The quality of the datasets has been assessed manually and automatically, and their value is demonstrated through multiple experiments. NusaCrowd's data collection enables the creation of the first zero-shot benchmarks for natural language understanding and generation in Indonesian and the local languages of Indonesia. Furthermore, NusaCrowd brings the creation of the first multilingual automatic speech recognition benchmark in Indonesian and the local languages of Indonesia. Our work strives to advance natural language processing (NLP) research for languages that are under-represented despite being widely spoken.
    
[^57]: APOLLO：面向逻辑推理的语言模型自适应预训练的简单方法

    APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning. (arXiv:2212.09282v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09282](http://arxiv.org/abs/2212.09282)

    本文提出了APOLLO，一种适应性预训练语言模型，通过选择特定的Wikipedia子集进行预训练，并使用两个自监督损失函数，成功地提高了模型的逻辑推理能力。

    

    文本的逻辑推理是一种重要的能力，需要理解文本中存在的信息、它们的相互联系，然后通过它们来推断新的结论。本文提出了APOLLO，一种适应性预训练语言模型，具有改进的逻辑推理能力。我们选择了Wikipedia的子集进行预训练，基于一组逻辑推理关键词。我们使用两个自监督损失函数：修改过的掩码语言建模损失只对可能需要更多推理而不仅仅是基本语言理解的特定词性的单词进行掩码，以及句子级分类损失，教导模型区分逻辑上连接和不连接的句子。我们的实验表明，APOLLO在多个逻辑推理数据集上优于最先进的语言模型，而不损失其在其他语言任务上的性能。

    Logical reasoning of text is an important ability that requires understanding the information present in the text, their interconnections, and then reasoning through them to infer new conclusions. Prior works on improving the logical reasoning ability of language models require complex processing of training data (e.g., aligning symbolic knowledge to text), yielding task-specific data augmentation solutions that restrict the learning of general logical reasoning skills. In this work, we propose APOLLO, an adaptively pretrained language model that has improved logical reasoning abilities. We select a subset of Wikipedia, based on a set of logical inference keywords, for continued pretraining of a language model. We use two self-supervised loss functions: a modified masked language modeling loss where only specific parts-of-speech words, that would likely require more reasoning than basic language understanding, are masked, and a sentence-level classification loss that teaches the model 
    
[^58]: FiDO：针对更强的性能和更快的推理进行优化的解码器融合模型

    FiDO: Fusion-in-Decoder optimized for stronger performance and faster inference. (arXiv:2212.08153v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08153](http://arxiv.org/abs/2212.08153)

    这项研究提出了一种名为FiDO的解码器融合模型，通过两个简单的更改，有效缓解了内存带宽约束，加快了模型的推理速度，大大提高了模型性能，达到了领先水平。

    

    Fusion-in-Decoder (FiD)是一种强大的检索增强语言模型，在许多知识密集型NLP任务上树立了业界标杆。但是，FiD所使用的架构是通过对标准T5模型做最小修改而选择的，我们的分析表明这对于一个检索增强模型来说是高度不优化的。特别地，FiD将大部分FLOPs分配给了编码器，而大多数推理时间是由于解码器中的内存带宽限制。我们提出了两个简单的更改，以缓解内存带宽约束，并使推理速度提高7倍。这使我们能够以适度的成本使用更大的解码器。我们将经过上述修改的FiD称为FiDO，并展示它在广泛的推理预算范围内比现有的FiD模型显著地提高了性能。例如，FiDO-Large-XXL比FiD-Base进行更快的推理，并实现了比FiD-Large更好的性能。

    Fusion-in-Decoder (FiD) is a powerful retrieval-augmented language model that sets the state-of-the-art on many knowledge-intensive NLP tasks. However, the architecture used for FiD was chosen by making minimal modifications to a standard T5 model, which our analysis shows to be highly suboptimal for a retrieval-augmented model. In particular, FiD allocates the bulk of FLOPs to the encoder, while the majority of inference time results from memory bandwidth constraints in the decoder. We propose two simple changes to the FiD architecture to alleviate memory bandwidth constraints, and speed up inference by 7x. This allows us to use a much larger decoder at modest cost. We denote FiD with the above modifications as FiDO, and show that it strongly improves performance over existing FiD models for a wide range of inference budgets. For example, FiDO-Large-XXL performs faster inference than FiD-Base and achieves better performance than FiD-Large.
    
[^59]: 再三考虑，我们不要按步就班地思考！零样本推理中的偏见和有害性。

    On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning. (arXiv:2212.08061v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08061](http://arxiv.org/abs/2212.08061)

    该论文的研究探讨了零样本推理中的偏见和有害性。通过对社会敏感领域进行的控制评估，发现使用零样本CoT推理在敏感领域中会显着增加产生有害或不良输出的可能性。同时也指出，有害的CoT随着模型大小增加而增加，但随着改进的指令遵循而减少。

    

    已经证明，生成“思考链”（CoT）可以在各种NLP任务的大型语言模型（LLM）上始终提高性能。然而，先前的研究主要集中在逻辑推理任务上（例如算术，常识QA）；目前尚不清楚对于更多样化的推理类型（特别是在社会情境中），该改进是否会保持。具体来说，我们进行了针对两个社会敏感领域的零样本CoT控制评估：有害问题和刻板印象基准。我们发现，零样本CoT推理在敏感领域中显着增加了模型产生有害或不良输出的可能性，这种趋势在不同的提示格式和模型变体中始终存在。此外，我们还展示了有害的CoT随着模型大小增加而增加，但随着改进的指令遵循而减少。我们的工作表明，在涉及边缘化群体或敏感话题时，应谨慎使用零样本CoT推理。

    Generating a Chain of Thought (CoT) has been shown to consistently improve large language model (LLM) performance on a wide range of NLP tasks. However, prior work has mainly focused on logical reasoning tasks (e.g. arithmetic, commonsense QA); it remains unclear whether improvements hold for more diverse types of reasoning, especially in socially situated contexts. Concretely, we perform a controlled evaluation of zero-shot CoT across two socially sensitive domains: harmful questions and stereotype benchmarks. We find that zero-shot CoT reasoning in sensitive domains significantly increases a model's likelihood to produce harmful or undesirable output, with trends holding across different prompt formats and model variants. Furthermore, we show that harmful CoTs increase with model size, but decrease with improved instruction following. Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics a
    
[^60]: 一种统一的知识图谱增强服务，用于提升特定领域的自然语言处理任务

    A Unified Knowledge Graph Augmentation Service for Boosting Domain-specific NLP Tasks. (arXiv:2212.05251v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.05251](http://arxiv.org/abs/2212.05251)

    KnowledgeDA是一种统一的领域语言模型开发服务，通过领域知识图谱增强任务特定的训练过程，提升特定领域的自然语言处理任务的表现。

    

    通过专注于特定领域语料库的预训练过程，一些领域特定的预训练语言模型（PLMs）已经取得了最先进的结果。然而，设计一种统一的范式来在PLM微调阶段注入领域知识的研究还很少。我们提出了KnowledgeDA，一种统一的领域语言模型开发服务，通过领域知识图谱增强任务特定的训练过程。给定领域特定的任务文本输入，KnowledgeDA可以自动生成一个领域特定的语言模型，分为三个步骤：（i）通过嵌入相似性方法在文本中定位领域知识实体；（ii）通过从知识图谱和训练数据的两个视角检索可替换的领域实体对来生成增强样本；（iii）通过基于置信度的评估选择高质量的增强样本进行微调。我们实现了KnowledgeDA的原型，学习两个领域的语言模型，分别为医疗保健和软件开发。

    By focusing the pre-training process on domain-specific corpora, some domain-specific pre-trained language models (PLMs) have achieved state-of-the-art results. However, it is under-investigated to design a unified paradigm to inject domain knowledge in the PLM fine-tuning stage. We propose KnowledgeDA, a unified domain language model development service to enhance the task-specific training procedure with domain knowledge graphs. Given domain-specific task texts input, KnowledgeDA can automatically generate a domain-specific language model following three steps: (i) localize domain knowledge entities in texts via an embedding-similarity approach; (ii) generate augmented samples by retrieving replaceable domain entity pairs from two views of both knowledge graph and training data; (iii) select high-quality augmented samples for fine-tuning via confidence-based assessment. We implement a prototype of KnowledgeDA to learn language models for two domains, healthcare and software developme
    
[^61]: 基于转移学习的大规模多语言预训练机器翻译模型在临床领域的应用研究

    Investigating Massive Multilingual Pre-Trained Machine Translation Models for Clinical Domain via Transfer Learning. (arXiv:2210.06068v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06068](http://arxiv.org/abs/2210.06068)

    本研究探讨了大规模多语言预训练语言模型（MMPLM）是否可以通过转移学习在临床领域机器翻译中成功应用于完全未知的语言对。实验结果表明，fine-tune过的MMPLM在临床领域机器翻译任务中表现良好。

    

    近年来，大规模多语言预训练语言模型（MMPLM）展示了它们在下游任务上表现出的超能力和预知能力。本研究探讨了MMPLM在临床领域机器翻译（MT）中是否可以通过转移学习用于完全未知的语言对。我们使用Meta-AI的MMPLM“wmt21-dense-24-wide-en-X和X-en（WMT21fb）”，这些模型预先训练了7种语言对和14个翻译方向，包括英语到捷克语、德语、豪萨语、冰岛语、日语、俄语和汉语以及相反的方向。我们对这些MMPLM进行fine-tune，针对它们原始的预训练语料库中\textit{完全不存在}的英文-\textit{西班牙语}语言对，显式和隐式地进行fine-tune。我们为此 fine-tune 做好经过仔细对齐的\textit{临床}领域数据，这与它们原始的混合领域知识不同。我们的实验结果表明，fine-tune过的MMPLM在临床领域机器翻译任务中表现良好。

    Massively multilingual pre-trained language models (MMPLMs) are developed in recent years demonstrating superpowers and the pre-knowledge they acquire for downstream tasks. This work investigates whether MMPLMs can be applied to clinical domain machine translation (MT) towards entirely unseen languages via transfer learning. We carry out an experimental investigation using Meta-AI's MMPLMs ``wmt21-dense-24-wide-en-X and X-en (WMT21fb)'' which were pre-trained on 7 language pairs and 14 translation directions including English to Czech, German, Hausa, Icelandic, Japanese, Russian, and Chinese, and the opposite direction. We fine-tune these MMPLMs towards English-\textit{Spanish} language pair which \textit{did not exist at all} in their original pre-trained corpora both implicitly and explicitly. We prepare carefully aligned \textit{clinical} domain data for this fine-tuning, which is different from their original mixed domain knowledge. Our experimental result shows that the fine-tunin
    
[^62]: MAMO：面向细粒度视觉-语言表示学习的掩膜多模态建模方法

    MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language Representation Learning. (arXiv:2210.04183v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.04183](http://arxiv.org/abs/2210.04183)

    本文提出了一种联合掩膜多模态建模方法，以学习细粒度的多模态表示，通过隐式和显式目标来恢复联合掩膜信号以提高细化的图像-文本交互。

    

    多模态表示学习在各种视觉-语言任务中展现了很大的潜力。然而，当前大部分方法都主要致力于建立全局级别的图像与语言对齐，缺乏有效的细粒度图像-文本交互。为此，本文提出了一种联合掩膜多模态建模方法，以学习细粒度的多模态表示。我们的方法对图像-文本输入进行联合掩膜，并集成了显式和隐式目标来恢复掩膜信号。其中，隐式目标为视觉和语言提供统一且无偏差的目标，模型预测未掩膜输入的潜在多模态表示；显式目标则通过恢复图像块的动量视觉特征和单词标记的概念，进一步丰富多模态表示。通过这样的掩膜建模过程，我们的模型不仅可以学习到细粒度的多模态交互，还能学习到有意义的语义信息。

    Multimodal representation learning has shown promising improvements on various vision-language tasks. Most existing methods excel at building global-level alignment between vision and language while lacking effective fine-grained image-text interaction. In this paper, we propose a jointly masked multimodal modeling method to learn fine-grained multimodal representations. Our method performs joint masking on image-text input and integrates both implicit and explicit targets for the masked signals to recover. The implicit target provides a unified and debiased objective for vision and language, where the model predicts latent multimodal representations of the unmasked input. The explicit target further enriches the multimodal representations by recovering high-level and semantically meaningful information: momentum visual features of image patches and concepts of word tokens. Through such a masked modeling process, our model not only learns fine-grained multimodal interaction, but also a
    
[^63]: UCEpic：统一考虑方面规划和词汇约束，生成解释型推荐

    UCEpic: Unifying Aspect Planning and Lexical Constraints for Generating Explanations in Recommendation. (arXiv:2209.13885v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.13885](http://arxiv.org/abs/2209.13885)

    UCEpic通过将方面规划和词汇约束统一考虑，提出了一种插入式生成的个性化解释型推荐模型，显著提高了解释的流畅性、连贯性和匹配能力。

    

    为了对解释型推荐进行个性化自然语言生成，本文提出了一种将方面规划和词汇约束统一考虑的模型UCEpic，通过插入式生成的方式生成高质量个性化的推荐结果解释。通过在模型的预训练和个性化推荐生成过程中引入词汇约束，可以显著提高生成解释的流畅性、连贯性和匹配能力。实验结果表明，UCEpic方法在两个基准数据集上显著优于现有最先进方法。

    Personalized natural language generation for explainable recommendations plays a key role in justifying why a recommendation might match a user's interests. Existing models usually control the generation process by aspect planning. While promising, these aspect-planning methods struggle to generate specific information correctly, which prevents generated explanations from being convincing. In this paper, we claim that introducing lexical constraints can alleviate the above issues. We propose a model, UCEpic, that generates high-quality personalized explanations for recommendation results by unifying aspect planning and lexical constraints in an insertion-based generation manner.  Methodologically, to ensure text generation quality and robustness to various lexical constraints, we pre-train a non-personalized text generator via our proposed robust insertion process. Then, to obtain personalized explanations under this framework of insertion-based generation, we design a method of incorp
    
[^64]: PaLI: 一种联合缩放的多语言语言-图像模型

    PaLI: A Jointly-Scaled Multilingual Language-Image Model. (arXiv:2209.06794v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.06794](http://arxiv.org/abs/2209.06794)

    PaLI是一种联合缩放的多语言语言-图像模型，可对图像和文本进行建模和执行许多视觉、语言和多模态任务，利用Transformer和Vision Transformer等先前的能力和成本。联合缩放在此任务中很重要，所以我们使用了一个40亿参数的Vision Transformer，以便利用更大容量的视觉模型的优势。

    

    有效的缩放和灵活的任务接口使得大型语言模型在许多任务上表现出色。我们提出了PaLI（Pathways Language and Image model），这是一种模型，可将这种方法扩展到语言和视觉的联合建模。PaLI基于视觉和文本输入生成文本，并通过此接口执行许多视觉、语言和多模态任务，在许多语言中完成。为了训练PaLI，我们利用了大型预训练编码器-解码器语言模型和Vision Transformers（ViT）。这使我们能够利用它们现有的能力并利用训练它们的重大成本。我们发现联合缩放视觉和语言组件很重要。由于现有的语言Transformer比它们的视觉对应物要大得多，因此我们训练了一个大型的40亿参数ViT（ViT-e）来量化即使更大容量的视觉模型的好处。为了训练PaLI，我们创建了一个基于新的图像-文本训练数据集的大型多语言的预训练任务混合。

    Effective scaling and a flexible task interface enable large language models to excel at many tasks. We present PaLI (Pathways Language and Image model), a model that extends this approach to the joint modeling of language and vision. PaLI generates text based on visual and textual inputs, and with this interface performs many vision, language, and multimodal tasks, in many languages. To train PaLI, we make use of large pre-trained encoder-decoder language models and Vision Transformers (ViTs). This allows us to capitalize on their existing capabilities and leverage the substantial cost of training them. We find that joint scaling of the vision and language components is important. Since existing Transformers for language are much larger than their vision counterparts, we train a large, 4-billion parameter ViT (ViT-e) to quantify the benefits from even larger-capacity vision models. To train PaLI, we create a large multilingual mix of pretraining tasks, based on a new image-text traini
    
[^65]: 联合生成与密集检索用于赞助搜索的查询重写

    Unified Generative & Dense Retrieval for Query Rewriting in Sponsored Search. (arXiv:2209.05861v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.05861](http://arxiv.org/abs/2209.05861)

    本文介绍了两种在线查询重写的范式：生成式（NLG）和密集检索（DR）方法。通过比较这两种方法并结合优势，提出了CLOVER-Unity模型，其NLG和DR组件始终优于单独训练的组件以及其他基线模型。

    

    赞助搜索是搜索引擎的一个关键收入来源，广告主通过竞价方式针对用户或感兴趣的搜索查询竞标关键字。然而，由于关键字空间庞大且动态变化、模糊的用户/广告主意图以及各种可能的主题和语言，找到与给定查询相关的关键字非常具有挑战性。本文介绍了在线查询重写的两种范式：生成式（NLG）和密集检索（DR）方法之间的全面比较。我们观察到两种方法都提供了互补的且可相加的优势。因此，我们展示了由这两种方法检索到的高质量关键字中有约40%是独特的，而另一种方法没有找到。为了发挥两种方法的优势，我们提出了CLOVER-Unity，这是一种将生成式与密集检索方法结合在一个模型中的新方法。通过离线实验，我们展示了CLOVER-Unity的NLG和DR组件始终优于单独训练的NLG和DR组件以及其他强基线模型，具有检索到关键字的相关性和多样性。

    Sponsored search is a key revenue source for search engines, where advertisers bid on keywords to target users or search queries of interest. However, finding relevant keywords for a given query is challenging due to the large and dynamic keyword space, ambiguous user/advertiser intents, and diverse possible topics and languages. In this work, we present a comprehensive comparison between two paradigms for online query rewriting: Generative (NLG) and Dense Retrieval (DR) methods. We observe that both methods offer complementary benefits that are additive. As a result, we show that around 40% of the high-quality keywords retrieved by the two approaches are unique and not retrieved by the other. To leverage the strengths of both methods, we propose CLOVER-Unity, a novel approach that unifies generative and dense retrieval methods in one single model. Through offline experiments, we show that the NLG and DR components of CLOVER-Unity consistently outperform individually trained NLG and DR
    
[^66]: 语言符号的表现：基于示范的人机交互中，体感手语手指拼写的翻译机器人获取

    Signs of Language: Embodied Sign Language Fingerspelling Acquisition from Demonstrations for Human-Robot Interaction. (arXiv:2209.05135v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.05135](http://arxiv.org/abs/2209.05135)

    本文提出了一种从视频示例学习手语拼写在机器人中的实现的方法。通过训练模仿运动的策略，利用预训练的深度视觉模型从RGB视频中提取手的三维姿态，并识别出最佳的模仿超参数集，本文成功展示了方法的普适性。

    

    学习机器人中细致的动作是一个具挑战性的问题，特别是在机器人手的上下文中。本文提出一种方法，通过视频示例学习无额外信息下的熟练运动模仿，以获得手语拼写在机器人中的实现。我们首先建立了一个机器人手的URDF模型，并使每个关节只有一个致动器。然后我们利用预训练的深度视觉模型从RGB视频中提取手的三维姿态。接着，我们利用最先进的强化学习算法(即近端策略优化和软演员-评论家算法)来训练一种能够复制示范运动的策略。我们基于参考运动识别出最佳的模仿超参数集。最后，我们通过对六个对应于拼写字母的不同任务进行测试，证明了我们方法的普适性。

    Learning fine-grained movements is a challenging topic in robotics, particularly in the context of robotic hands. One specific instance of this challenge is the acquisition of fingerspelling sign language in robots. In this paper, we propose an approach for learning dexterous motor imitation from video examples without additional information. To achieve this, we first build a URDF model of a robotic hand with a single actuator for each joint. We then leverage pre-trained deep vision models to extract the 3D pose of the hand from RGB videos. Next, using state-of-the-art reinforcement learning algorithms for motion imitation (namely, proximal policy optimization and soft actor-critic), we train a policy to reproduce the movement extracted from the demonstrations. We identify the optimal set of hyperparameters for imitation based on a reference motion. Finally, we demonstrate the generalizability of our approach by testing it on six different tasks, corresponding to fingerspelled letters.
    
[^67]: 评估生成专利语言模型

    Evaluating Generative Patent Language Models. (arXiv:2206.14578v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.14578](http://arxiv.org/abs/2206.14578)

    本文构建了生成性专利语言模型，并通过基于人类节省按键数量的度量方法评估了其表现，发现在专利领域继续增加模型大小可能是不必要的。

    

    生成性语言模型在各个领域辅助人类写作方面具有很大的潜力。本文旨在构建专利领域的生成性语言模型，并从人类的角度评估模型的表现。我们通过度量基于生成性专利语言模型的自动补全所能节省的按键比率来衡量模型的表现，这种以按键为基础的度量方法不同于传统的基于标记的机器-centric的度量方法。本文中构建的最大模型大小为6B，在专利领域是最先进的。基于此度量方法，我们发现最大的模型并不一定是人类-centric度量方法的最佳选择，这意味着如果目的是通过自动补全来辅助人类写作，那么在专利领域继续增加模型大小可能是不必要的。

    Generative language models are promising for assisting human writing in various domains. This manuscript aims to build generative language models in the patent domain and evaluate model performance from a human-centric perspective. The perspective is to measure the ratio of keystrokes that can be saved by autocompletion based on generative patent language models. A higher ratio means a more effective model which can save more keystrokes. This metric can be used to benchmark model performance. The metric is different from conventional machine-centric metrics that are token-based instead of keystroke-based. In terms of model size, the largest model built in this manuscript is 6B, which is state-of-the-art in the patent domain. Based on the metric, it is found that the largest model is not necessarily the best for the human-centric metric. The finding means that keeping increasing model sizes in the patent domain might be unnecessary if the purpose is to assist human writing with autocomp
    
[^68]: 带有属性删除子网络的模块化和按需偏差缓解方法

    Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks. (arXiv:2205.15171v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15171](http://arxiv.org/abs/2205.15171)

    提出一种新颖的模块化偏差缓解方法，在推理时间按需集成到核心模型中的独立去偏置子网络，在性别、种族和年龄等受保护属性的分类任务中，该方法在缓解偏差方面是有效的，并且在精度和灵活性方面优于现有技术方法。

    

    社会偏见反映在大型预训练语言模型及其在下游任务中的微调版本中。常见的处理偏差的方法引入了额外的优化标准，并更新模型以达到新的去偏置状态。然而，在实践中，最终用户和从业人员可能更喜欢切换回原始模型，或仅对特定子集的保护属性应用去偏置。为了实现这一点，我们提出了一种新颖的模块化偏差缓解方法，包括独立高度稀疏的去偏置子网络，其中每个去偏置模块可以在推理时间按需集成到核心模型中。我们的方法借鉴了“diff”剪枝的概念，并提出了一种适合于各种表示分离优化的新型训练方式。我们在具有性别、种族和年龄等受保护属性的三个分类任务上进行了实验。结果表明，我们的模块化方法在缓解偏差方面是有效的，并且在精度和灵活性方面优于现有技术方法。

    Societal biases are reflected in large pre-trained language models and their fine-tuned versions on downstream tasks. Common in-processing bias mitigation approaches, such as adversarial training and mutual information removal, introduce additional optimization criteria, and update the model to reach a new debiased state. However, in practice, end-users and practitioners might prefer to switch back to the original model, or apply debiasing only on a specific subset of protected attributes. To enable this, we propose a novel modular bias mitigation approach, consisting of stand-alone highly sparse debiasing subnetworks, where each debiasing module can be integrated into the core model on-demand at inference time. Our approach draws from the concept of \emph{diff} pruning, and proposes a novel training regime adaptable to various representation disentanglement optimizations. We conduct experiments on three classification tasks with gender, race, and age as protected attributes. The resul
    
[^69]: 《语言的各向异性跨语言模型编辑》

    Language Anisotropic Cross-Lingual Model Editing. (arXiv:2205.12677v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12677](http://arxiv.org/abs/2205.12677)

    本文提出了语言各向异性跨语言模型编辑的框架，并通过在跨语言任务上的测试证明了该方法的有效性，可以针对特定输入进行校准而不影响模型的原始行为。

    

    多语言预训练语言模型可以在多种语言中学习特定任务的能力或记住事实，但不可避免地会在使用特定输入时做出不良预测。与此类似，模型编辑旨在事后校准针对特定输入的模型，并保持模型的原始行为。然而，现有工作仅研究了单语境结构，缺乏跨语境传递性以同时执行跨语言编辑。本文重点研究跨语言模型编辑。首先，我们定义了跨语言模型编辑任务和相应的度量标准，其中一个语言的编辑会传播到其他语言。接下来，我们提出了一个框架，通过平行语料库自然地适应单语境模型编辑方法到跨语境情况。此外，我们提出了语言各向异性编辑方法，以改善跨语境编辑，通过增强每种语言的不同参数子集。在新定义的跨语境模型编辑任务中，我们的提出的框架在单语言和多语言评估中都取得了显着改进。我们的方法可以校准针对特定输入的预测，同时保持模型的原始行为，使其在实际应用中更加可靠。

    Multilingual pre-trained language models can learn task-specific abilities or memorize facts across multiple languages but inevitably make undesired predictions with specific inputs. Under similar observation, model editing aims to post-hoc calibrate a model targeted to specific inputs with keeping the model's raw behavior. However, existing work only studies the monolingual scenario, which lacks the cross-lingual transferability to perform editing simultaneously across languages. In this work, we focus on cross-lingual model editing. Firstly, we define the cross-lingual model editing task and corresponding metrics, where an edit in one language propagates to the others. Next, we propose a framework to naturally adapt monolingual model editing approaches to the cross-lingual scenario using parallel corpus. Further, we propose language anisotropic editing to improve cross-lingual editing by amplifying different subsets of parameters for each language. On the newly defined cross-lingual 
    
[^70]: 统一检索器：大规模检索的统一检索器

    UnifieR: A Unified Retriever for Large-Scale Retrieval. (arXiv:2205.11194v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2205.11194](http://arxiv.org/abs/2205.11194)

    UnifieR是一个将PLM的密集向量和基于词汇表的检索统一到一个模型中的学习框架，在段落检索基准测试中证明了其有效性。

    

    大规模检索是指在给定查询的情况下从大量文档中召回相关文档。它依赖于表征学习，将文档和查询嵌入到一个共同的语义编码空间中。根据编码空间，基于预训练语言模型（PLM）的最近检索方法可以粗略地分为密集向量或基于词汇表的范例。这两种范例在不同粒度的全局序列级压缩和局部单词级上下文中展现了PLMs的表征能力。受到它们互补的全局局部上下文化和不同的代表视角的启发，我们提出了一个新的学习框架，统一检索器，它将密集向量和基于词汇表的检索统一到一个模型中，具有双重表示能力。对段落检索基准的实验验证了它在两个范例中的有效性。进一步提出了更好的检索质量的uni-retrieval方案。最后，我们评估了该模型。

    Large-scale retrieval is to recall relevant documents from a huge collection given a query. It relies on representation learning to embed documents and queries into a common semantic encoding space. According to the encoding space, recent retrieval methods based on pre-trained language models (PLM) can be coarsely categorized into either dense-vector or lexicon-based paradigms. These two paradigms unveil the PLMs' representation capability in different granularities, i.e., global sequence-level compression and local word-level contexts, respectively. Inspired by their complementary global-local contextualization and distinct representing views, we propose a new learning framework, UnifieR which unifies dense-vector and lexicon-based retrieval in one model with a dual-representing capability. Experiments on passage retrieval benchmarks verify its effectiveness in both paradigms. A uni-retrieval scheme is further presented with even better retrieval quality. We lastly evaluate the model 
    
[^71]: Heterformer：基于Transformer的异构文本网络深度节点表示学习

    Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks. (arXiv:2205.10282v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.10282](http://arxiv.org/abs/2205.10282)

    本论文提出了一种名为Heterformer的基于Transformer的深度节点表示学习方法，它可以同时处理异构结构和丰富的文本语义信息。

    

    网络表示学习旨在为每个节点推导出有意义的向量表示，从而促进诸如链接预测、节点分类和节点聚类等下游任务。在异构文本网络中，由于文本的存在与缺失以及多种类型的节点和边缘形成的异构网络结构，这项任务更加具有挑战性。由于预训练语言模型（PLMs）已经证明了在获得广泛通用性文本表示方面的有效性，在文本丰富的网络表示学习中，人们已经付出了大量的努力来将PLMs包含到其中。然而，很少有研究可以有效地共同考虑异构结构（网络）信息和每个节点的丰富文本语义信息。本文提出了Heterformer，一种异构网络强化的Transformer，可同时处理网络结构信息和每个节点的丰富文本语义信息。

    Representation learning on networks aims to derive a meaningful vector representation for each node, thereby facilitating downstream tasks such as link prediction, node classification, and node clustering. In heterogeneous text-rich networks, this task is more challenging due to (1) presence or absence of text: Some nodes are associated with rich textual information, while others are not; (2) diversity of types: Nodes and edges of multiple types form a heterogeneous network structure. As pretrained language models (PLMs) have demonstrated their effectiveness in obtaining widely generalizable text representations, a substantial amount of effort has been made to incorporate PLMs into representation learning on text-rich networks. However, few of them can jointly consider heterogeneous structure (network) information as well as rich textual semantic information of each node effectively. In this paper, we propose Heterformer, a Heterogeneous Network-Empowered Transformer that performs cont
    
[^72]: 自然语言推理中归因方法评估的多语言视角

    A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference. (arXiv:2204.05428v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.05428](http://arxiv.org/abs/2204.05428)

    该论文提出了一种基于多语言的评价方法，以评估自然语言推理任务中归因方法的忠实度和可信度，并且通过高亮的解释扩充了XNLI数据集，研究结果表明在可信度和可信度方面表现最佳的归因方法有所不同。

    

    大多数归因方法的评估集中在英语语言上。在这项工作中，我们提出了一种多语言方法，用于评估自然语言推理（NLI）任务的归因方法的忠实度和可信度。首先，我们引入了一种基于单词对齐的新型跨语言策略来衡量忠实度，排除了删减评估的缺点。然后，我们对归因方法进行了全面的评估，考虑了不同的输出机制和聚合方法。最后，我们通过基于高亮的解释扩充了XNLI数据集，提供了一个带有高亮的多语言NLI数据集，以支持未来的ExNLP研究。我们的研究结果表明，性能最佳的归因方法对于可信度和可信度的表现是不同的。

    Most evaluations of attribution methods focus on the English language. In this work, we present a multilingual approach for evaluating attribution methods for the Natural Language Inference (NLI) task in terms of faithfulness and plausibility. First, we introduce a novel cross-lingual strategy to measure faithfulness based on word alignments, which eliminates the drawbacks of erasure-based evaluations.We then perform a comprehensive evaluation of attribution methods, considering different output mechanisms and aggregation methods. Finally, we augment the XNLI dataset with highlight-based explanations, providing a multilingual NLI dataset with highlights, to support future exNLP studies. Our results show that attribution methods performing best for plausibility and faithfulness are different.
    
[^73]: 我们真的取得了很大的进展吗？针对单标签和多标签文本分类的词袋、序列、图和层次结构的比较

    Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification. (arXiv:2204.03954v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.03954](http://arxiv.org/abs/2204.03954)

    本文比较了用于文本分类的词袋、序列、图形和分层方法，发现基于图形的方法无法超越现代预训练语言模型并且甚至有时表现不如标准机器学习方法，质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。

    

    图神经网络的流行引发了单标签和多标签文本分类的图形方法的复苏。然而，这些基于图形的方法是否比标准机器学习方法和现代预训练语言模型更有益仍不清楚。本文比较了用于文本分类的丰富的词袋、基于序列、基于图形和分层方法。我们聚合了来自文献的结果，在5个单标签和7个多标签数据集上运行了我们自己的实验。我们的研究结果明确表明，在单标签和多标签分类任务中，基于图形的方法无法超越精调的语言模型，有时甚至表现不如词袋上的标准机器学习方法，这质疑了过去几年中为开发新的图形方法投入的巨大努力以及它们为文本分类带来的承诺。

    The popularity of graph neural networks has triggered a resurgence of graph-based methods for single-label and multi-label text classification. However, it is unclear whether these graph-based methods are beneficial compared to standard machine learning methods and modern pretrained language models. We compare a rich selection of bag-of-words, sequence-based, graph-based, and hierarchical methods for text classification. We aggregate results from the literature over 5 single-label and 7 multi-label datasets and run our own experiments. Our findings unambiguously demonstrate that for single-label and multi-label classification tasks, the graph-based methods fail to outperform fine-tuned language models and sometimes even perform worse than standard machine learning methods like multilayer perceptron (MLP) on a bag-of-words. This questions the enormous amount of effort put into the development of new graph-based methods in the last years and the promises they make for text classification
    
[^74]: MMER: 面向语音情感识别的多模态多任务学习方法

    MMER: Multimodal Multi-task Learning for Speech Emotion Recognition. (arXiv:2203.16794v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.16794](http://arxiv.org/abs/2203.16794)

    本研究提出了一种名为MMER的新型多模态多任务学习方法，应用于语音情感识别。该方法利用新型多模态网络和多个辅助任务提高了性能，并在IEMOCAP基准测试中表现出了领先的水平。

    

    本文提出了MMER，一种新颖的多模态多任务学习方法，用于语音情感识别。MMER利用了基于早期融合和文本和声学模态之间的跨模态自注意力的新型多模态网络，并解决了三个新颖辅助任务，用于学习来自口语话语的情感识别。在实践中，MMER优于我们的所有基线，并在IEMOCAP基准测试中实现了最先进的性能。此外，我们进行了广泛的削减研究和结果分析，以证明我们提出的方法的有效性。

    In this paper, we propose MMER, a novel Multimodal Multi-task learning approach for Speech Emotion Recognition. MMER leverages a novel multimodal network based on early-fusion and cross-modal self-attention between text and acoustic modalities and solves three novel auxiliary tasks for learning emotion recognition from spoken utterances. In practice, MMER outperforms all our baselines and achieves state-of-the-art performance on the IEMOCAP benchmark. Additionally, we conduct extensive ablation studies and results analysis to prove the effectiveness of our proposed approach.
    
[^75]: 不需要访问任何训练或测试数据的泛化度量标准评估自然语言处理模型

    Evaluating natural language processing models with generalization metrics that do not need access to any training or testing data. (arXiv:2202.02842v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.02842](http://arxiv.org/abs/2202.02842)

    本文提出了一种无需访问任何数据即可评估自然语言处理模型的泛化度量标准，并通过对Huggingface预训练变压器的模型选择，得到一个简单高效且相关性强的有用度量标准。

    

    选择合适的结构参数和训练超参数对于提高机器学习（ML）模型的性能至关重要。最近的几项实证研究对神经网络（NNs）进行了大规模的相关分析，以寻找有效的泛化度量标准以指导模型选择。有效的度量标准通常预计与测试性能强相关。在本文中，我们通过以下目标扩展了先前的分析，进行了基于泛化度量标准的模型选择研究：（i）关注自然语言处理（NLP）任务，因为先前的工作主要集中于计算机视觉（CV）任务；（ii）考虑直接预测测试误差而非泛化差距的度量标准；（iii）探索不需要访问数据即可计算的度量标准。从这些目标出发，我们能够提供第一个使用泛化度量标准对来自Huggingface的大型预训练变压器进行模型选择的结果，并比较了许多不同的度量标准。结果表明，我们提出的有用度量标准不止与测试性能高度相关，而且更加简单高效。

    Selecting suitable architecture parameters and training hyperparameters is essential for enhancing machine learning (ML) model performance. Several recent empirical studies conduct large-scale correlational analysis on neural networks (NNs) to search for effective \emph{generalization metrics} that can guide this type of model selection. Effective metrics are typically expected to correlate strongly with test performance. In this paper, we expand on prior analyses by examining generalization-metric-based model selection with the following objectives: (i) focusing on natural language processing (NLP) tasks, as prior work primarily concentrates on computer vision (CV) tasks; (ii) considering metrics that directly predict \emph{test error} instead of the \emph{generalization gap}; (iii) exploring metrics that do not need access to data to compute. From these objectives, we are able to provide the first model selection results on large pretrained Transformers from Huggingface using general
    
[^76]: 大规模的近义句表示

    Paraphrastic Representations at Scale. (arXiv:2104.15114v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2104.15114](http://arxiv.org/abs/2104.15114)

    该论文提出了一种允许用户在各种语言中训练自己的全球领先的近义句表示系统，并发布了训练模型，这些模型在多任务上取得了显著进展，具有比以往更快的速度和更高的性能，是没有GPU或嵌入式设备的用户的有吸引力的选择。

    

    我们提出了一个系统，允许用户在各种语言中训练自己的全球领先的近义句表示。我们还发布了针对英语、阿拉伯语、德语、法语、西班牙语、俄语、土耳其语和汉语的训练模型。我们使用大量数据训练这些模型，在单语语义相似性、跨语言语义相似性和双语挖掘任务的一套模型中，取得了明显的改进性能。此外，这些模型的结果超越了所有先前的无监督语义文本相似性工作，甚至优于基于BERT的模型，如Sentence-BERT (Reimers和Gurevych, 2019)。此外，我们的模型比以前的工作快上几个数量级，并且可以在CPU上使用，推理速度几乎没有差距（在使用更多CPU核心时，比GPU速度更快），使得这些模型成为没有GPU或嵌入式设备使用的用户的有吸引力的选择。

    We present a system that allows users to train their own state-of-the-art paraphrastic sentence representations in a variety of languages. We also release trained models for English, Arabic, German, French, Spanish, Russian, Turkish, and Chinese. We train these models on large amounts of data, achieving significantly improved performance from the original papers proposing the methods on a suite of monolingual semantic similarity, cross-lingual semantic similarity, and bitext mining tasks. Moreover, the resulting models surpass all prior work on unsupervised semantic textual similarity, significantly outperforming even BERT-based models like Sentence-BERT (Reimers and Gurevych, 2019). Additionally, our models are orders of magnitude faster than prior work and can be used on CPU with little difference in inference speed (even improved speed over GPU when using more CPU cores), making these models an attractive choice for users without access to GPUs or for use on embedded devices. Finall
    

