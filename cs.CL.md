# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [In-context Autoencoder for Context Compression in a Large Language Model.](http://arxiv.org/abs/2307.06945) | 在大型语言模型中，我们提出了一种称为In-context Autoencoder (ICAE)的上下文自编码器，它通过将长上下文压缩为有限数量的内存槽，实现了$4\times$的上下文压缩，并能够根据内存槽进行条件处理以响应各种提示。 |
| [^2] | [mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs.](http://arxiv.org/abs/2307.06930) | mBLIP是第一个多语言Vision-LLM，通过在消费级硬件上使用少量训练样例的计算上高效的方式获得。 |
| [^3] | [DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual Language Grounding.](http://arxiv.org/abs/2307.06924) | DRAGON是一种基于对话的导航机器人，能够理解用户的指令并通过语言与用户沟通，为视力受损者提供导航和环境描述的帮助。 |
| [^4] | [LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT.](http://arxiv.org/abs/2307.06917) | 本文介绍了基于LLM辅助的知识图谱工程实验，展示了ChatGPT在开发和管理知识图谱方面的潜力。 |
| [^5] | [Generating Benchmarks for Factuality Evaluation of Language Models.](http://arxiv.org/abs/2307.06908) | 该论文提出了一个名为FACTOR的方法，用于生成用于语言模型事实性评估的基准数据集。通过自动转换事实语料库，评估语言模型根据语料库生成真实事实的倾向与生成不正确陈述的能力。实验结果表明，该基准数据集的分数随模型大小增加而增加，在LM与检索方法结合时性能得到改善。困惑度和基准数据集分数之间存在相关性，但不总是一致。 |
| [^6] | [DecompEval: Evaluating Generated Texts as Unsupervised Decomposed Question Answering.](http://arxiv.org/abs/2307.06869) | DecompEval提出了一种简单而有效的指标来评估自然语言生成任务，它将评估建模为一种类似指令的问答任务，并利用预训练语言模型进行衡量，以增强泛化能力和可解释性。 |
| [^7] | [Prompts Should not be Seen as Secrets: Systematically Measuring Prompt Extraction Attack Success.](http://arxiv.org/abs/2307.06865) | 本论文提出了一个系统地衡量提示提取攻击成功的框架，并通过多个实验发现，即使提示被保密，简单的基于文本的攻击仍然可以高概率地揭示提示。 |
| [^8] | [Self-consistency for open-ended generations.](http://arxiv.org/abs/2307.06857) | 本论文提出了一种改进大规模预训练语言模型生成输出质量和一致性的新方法，通过扩展自洽性框架的适用性，实现了从一个候选集中恢复最优或接近最优的生成结果，并提出了一种轻量级无参数相似性函数来改进代码生成、自动形式化和摘要任务的效果。 |
| [^9] | [Garbage in, garbage out: Zero-shot detection of crime using Large Language Models.](http://arxiv.org/abs/2307.06844) | 本文利用大型语言模型学习的常识知识，通过将视频转换为文本描述，实现了零样本推理的犯罪检测。现有的视频转文本方法质量不足以支持推理。 |
| [^10] | [Personalization for BERT-based Discriminative Speech Recognition Rescoring.](http://arxiv.org/abs/2307.06832) | 本论文提出了三种利用个性化内容提高端到端语音识别准确性的方法：词表、提示和基于交叉注意力的编码器-解码器模型。实验证明，这些方法都显著提高了词错误率，并且自然语言提示不需要训练即可改善准确率。其中，词表表现最佳，提高了10%的词错误率，同时在通用测试集上也有1%的提升。 |
| [^11] | [Negated Complementary Commonsense using Large Language Models.](http://arxiv.org/abs/2307.06794) | 本论文研究了使用大规模语言模型解决否定式互补问题的性能。作者发现，这种类型的问题会对模型的响应产生负面影响，并提出了一种模型无关的方法来改善性能。实验证明，该方法在少样本生成方面优于GPT-3，并强调了研究大规模语言模型在否定式互补问题中的重要性。 |
| [^12] | [A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media.](http://arxiv.org/abs/2307.06775) | 本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。 |
| [^13] | [Why Guided Dialog Policy Learning performs well? Understanding the role of adversarial learning and its alternative.](http://arxiv.org/abs/2307.06721) | 本论文通过分析对话策略和奖励估计器的目标函数，解释了对抗学习在对话策略学习中的作用，并提出了一种替代方法。 |
| [^14] | [Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models.](http://arxiv.org/abs/2307.06713) | 本文提出了一种使用大型语言模型进行文本分类的无监督校准方法，通过调整先验类别分布，实现在没有标记样本和仅少量领域内样本查询的情况下执行任务。 |
| [^15] | [To share or not to share: What risks would laypeople accept to give sensitive data to differentially-private NLP systems?.](http://arxiv.org/abs/2307.06708) | 这项研究旨在探索普通人在面临隐私威胁情境时的决策行为，以及他们愿意为给予差分隐私的自然语言处理系统提供敏感数据所承担的风险。 |
| [^16] | [Intent-calibrated Self-training for Answer Selection in Open-domain Dialogues.](http://arxiv.org/abs/2307.06703) | 这项研究介绍了一种名为意图校准的自我训练方法，用于改善开放领域对话中答案选择的质量。通过使用意图标签来校准答案标签，作者通过实验证明了这种方法在两个基准数据集上的效果优于基线模型。 |
| [^17] | [Parmesan: mathematical concept extraction for education.](http://arxiv.org/abs/2307.06699) | Parmesan是一个原型系统，用于在上下文中搜索和定义数学概念，特别关注范畴论领域。该系统利用自然语言处理组件进行概念提取、关系提取、定义提取和实体链接。通过该系统的开发，可以解决现有技术不能直接应用于范畴论领域的问题，并提供了两个数学语料库以支持系统的使用。 |
| [^18] | [Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations.](http://arxiv.org/abs/2307.06576) | 本文介绍了一种名为GLORY的模型，通过全局图与本地表示相结合，增强了个性化推荐系统。该模型通过构建全局感知历史新闻编码器来融合历史新闻表示，并考虑了用户隐藏的动机和行为。 |
| [^19] | [Convolutional Neural Networks for Sentiment Analysis on Weibo Data: A Natural Language Processing Approach.](http://arxiv.org/abs/2307.06540) | 本研究提出了一种基于卷积神经网络的方法，利用微博数据进行情感分析，取得了约0.73的宏平均F1分数，结果表明了CNN在情感分析任务中的有效性，对社交媒体分析、市场研究和政策研究等领域有重要意义。 |
| [^20] | [Exploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study.](http://arxiv.org/abs/2307.06530) | 本文探讨了将大型语言模型集成到自动语音识别系统以提高准确性的问题，研究结果显示利用语言模型的上下文学习来进行ASR应用仍面临挑战。 |
| [^21] | [Agreement Tracking for Multi-Issue Negotiation Dialogues.](http://arxiv.org/abs/2307.06524) | 这项工作介绍了两方多问题谈判的协议跟踪任务，通过使用GPT-3构建了一个合成数据集并迁移学习T5模型，在解决缺乏标注数据的问题上取得了强有力的初始基线。 |
| [^22] | [Misclassification in Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes We Can!.](http://arxiv.org/abs/2307.06483) | 传播学领域中的自动化内容分析常忽视了错误分类的偏差，我们介绍并测试了统计方法来纠正这种偏差，并设计了一种新方法来修复之。 |
| [^23] | [Assessing the Ability of ChatGPT to Screen Articles for Systematic Reviews.](http://arxiv.org/abs/2307.06464) | 本论文评估了聊天型AI模型ChatGPT在系统性综述（SR）文章筛选中的性能，结果表明ChatGPT是自动化SR过程的可行选择。 |
| [^24] | [No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models.](http://arxiv.org/abs/2307.06440) | 本论文重新审视了基于Transformer的语言模型的高效训练算法，包括动态架构，批量选择和高效优化器。然而，在使用这些算法预训练时，相对于基线方法，它们的训练、验证和下游收益消失了。同时，论文提出了一个评估协议来进行计算，并释放了代码来促进高效训练的研究。 |
| [^25] | [Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events.](http://arxiv.org/abs/2307.06439) | 本研究通过将大型语言模型蒸馏为特定任务的学生模型，成功地提升了在药物不良事件提取方面的性能，并在不使用标记数据的情况下达到了与监督式最先进模型相当的准确性，具有成本、效率和白盒模型访问等优势。 |
| [^26] | [A Comprehensive Overview of Large Language Models.](http://arxiv.org/abs/2307.06435) | 大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。 |
| [^27] | [The Acquisition of Semantic Relationships between words.](http://arxiv.org/abs/2307.06419) | 本文研究了词语的形态与语义关系之间的互动关系，通过探索语言形态学与语义关系之间的复杂关联，揭示了词语结构对语言理解的影响。 |
| [^28] | [Incomplete Utterance Rewriting as Sequential Greedy Tagging.](http://arxiv.org/abs/2307.06337) | 本论文提出了一种基于序列标注的模型，能够更好地从对话上下文中提取信息，并引入了区分说话者的嵌入来建模说话者的变化。实验结果表明，该模型在恢复得分方面达到了最优，并在推理速度上胜过大多数之前的模型。 |
| [^29] | [Large Language Models for Supply Chain Optimization.](http://arxiv.org/abs/2307.03875) | 这项研究研究了利用大型语言模型（LLMs）来帮助解释和解读供应链优化结果的方法。他们设计了一个框架，可以接受普通文本查询作为输入，并输出关于底层优化结果的洞察。通过定量回答假设情况，该框架在不放弃最先进的组合优化技术的情况下帮助企业运营者更好地理解和信任优化结果。 |
| [^30] | [A Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2307.03109) | 本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。 |
| [^31] | [PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation.](http://arxiv.org/abs/2307.00470) | PatternGPT是一种基于模式驱动的大型语言模型文本生成框架，通过利用大型语言模型的提取能力生成多样化的模式，并使用联邦学习的思想实现模式共享，最终通过搜索高质量模式指导生成模型。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。 |
| [^32] | [Kosmos-2: Grounding Multimodal Large Language Models to the World.](http://arxiv.org/abs/2306.14824) | Kosmos-2是一个多模态大规模语言模型，可以感知物体描述并将文本与视觉世界联系起来。它在多个任务上展示了出色表现，包括多模态接地、多模态引用、感知语言任务以及语言理解和生成。 |
| [^33] | [GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition.](http://arxiv.org/abs/2306.07848) | 本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。 |
| [^34] | [What You See is What You Read? Improving Text-Image Alignment Evaluation.](http://arxiv.org/abs/2305.10400) | 本研究介绍了SeeTRUE评估集和两种自动文本-图像对齐方法，这些方法在各种对齐任务中均取得了显着改进，在复杂组合或非自然图像的挑战性案例中表现出色。 |
| [^35] | [Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation.](http://arxiv.org/abs/2305.07804) | 本论文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，以改善小语言模型的性能，特别是在医学问答任务中。这种方法在微调后使模型性能提高，并提出了在特定领域问答任务中使用LLM所面临的挑战和潜在的研究方向。 |
| [^36] | [Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation.](http://arxiv.org/abs/2305.07457) | 本文介绍了一种透明、无监督的词级质量估计方法，它可以通过分析扰动的输入源句子上机器翻译系统输出来工作，并可以评估任何类型的黑盒机器翻译系统。使用该方法作为反馈信号，可以在无监督的领域自适应中改进机器翻译系统的质量。 |

# 详细

[^1]: 在大型语言模型中的上下文压缩的上下文自编码器

    In-context Autoencoder for Context Compression in a Large Language Model. (arXiv:2307.06945v1 [cs.CL])

    [http://arxiv.org/abs/2307.06945](http://arxiv.org/abs/2307.06945)

    在大型语言模型中，我们提出了一种称为In-context Autoencoder (ICAE)的上下文自编码器，它通过将长上下文压缩为有限数量的内存槽，实现了$4\times$的上下文压缩，并能够根据内存槽进行条件处理以响应各种提示。

    

    我们提出了一种用于大型语言模型中上下文压缩的上下文自编码器（ICAE）。 ICAE有两个模块：一个可学习的编码器，通过从LLM中采用LoRA方式将长上下文压缩为有限数量的内存槽，以及一个固定的解码器，作为目标LLM，可以根据内存槽来进行各种目的的条件处理。我们首先使用自编码和语言建模目标在大规模文本数据上预训练ICAE，使其能够生成准确和全面表示原始上下文的内存槽。然后，我们使用少量指导数据对预训练的ICAE进行微调，以增强其与各种提示的交互，从而产生理想的响应。我们的实验结果表明，使用我们提出的预训练和微调范式学习的ICAE可以有效地产生$4\times$上下文压缩的内存槽，目标LLM可以很好地对其进行条件处理，以响应各种提示。

    We propose the In-context Autoencoder (ICAE) for context compression in a large language model (LLM). The ICAE has two modules: a learnable encoder adapted with LoRA from an LLM for compressing a long context into a limited number of memory slots, and a fixed decoder which is the target LLM that can condition on the memory slots for various purposes. We first pretrain the ICAE using both autoencoding and language modeling objectives on massive text data, enabling it to generate memory slots that accurately and comprehensively represent the original context. Then, we fine-tune the pretrained ICAE on a small amount of instruct data to enhance its interaction with various prompts for producing desirable responses. Our experimental results demonstrate that the ICAE learned with our proposed pretraining and fine-tuning paradigm can effectively produce memory slots with $4\times$ context compression, which can be well conditioned on by the target LLM to respond to various prompts. The promis
    
[^2]: mBLIP: 多语言视觉-LLM的高效引导

    mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs. (arXiv:2307.06930v1 [cs.CV])

    [http://arxiv.org/abs/2307.06930](http://arxiv.org/abs/2307.06930)

    mBLIP是第一个多语言Vision-LLM，通过在消费级硬件上使用少量训练样例的计算上高效的方式获得。

    

    模块化的视觉-语言模型（Vision-LLM）将预训练的图像编码器与（预训练的）大型语言模型（LLM）对齐，是一种在计算上更高效的选择，可以代替从头开始训练大型视觉-语言模型的端到端训练方法，而后者对于大多数人来说成本太高。 Vision-LLM将LLM事后条件化为“理解”图像编码器的输出。随着现成的高质量英文图像-文本数据以及单语英语LLM的丰富性，研究重点已经放在仅英文的Vision-LLM上。而多语言视觉-语言模型仍然主要通过昂贵的端到端预训练获得，这导致了相对较小的模型，并且在有限的多语言图像数据上进行训练，同时补充了仅有文本的多语言语料库。在这项工作中，我们介绍了mBLIP，这是第一个多语言Vision-LLM，我们以计算上高效的方式获得，仅使用几百万个训练样例在消费级硬件上进行训练。

    Modular vision-language models (Vision-LLMs) align pretrained image encoders with (pretrained) large language models (LLMs), representing a computationally much more efficient alternative to end-to-end training of large vision-language models from scratch, which is prohibitively expensive for most. Vision-LLMs instead post-hoc condition LLMs to `understand' the output of an image encoder. With the abundance of readily available high-quality English image-text data as well as monolingual English LLMs, the research focus has been on English-only Vision-LLMs. Multilingual vision-language models are still predominantly obtained via expensive end-to-end pretraining, resulting in comparatively smaller models, trained on limited multilingual image data supplemented with text-only multilingual corpora. In this work, we present mBLIP, the first multilingual Vision-LLM, which we obtain in a computationally efficient manner -- on consumer hardware using only a few million training examples -- by 
    
[^3]: DRAGON: 一种基于对话的带有视觉语言关联的辅助导航机器人

    DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual Language Grounding. (arXiv:2307.06924v1 [cs.RO])

    [http://arxiv.org/abs/2307.06924](http://arxiv.org/abs/2307.06924)

    DRAGON是一种基于对话的导航机器人，能够理解用户的指令并通过语言与用户沟通，为视力受损者提供导航和环境描述的帮助。

    

    视力受损者在理解和导航周围空间方面存在困难。目前的导航技术要么只关注导航，要么提供有限的关于环境的沟通。受到最近在视觉语言关联和语义导航方面的进展的启发，我们提出了DRAGON，一种由对话系统驱动的导航机器人，并具有将环境与自然语言关联的能力。通过理解用户的指令，DRAGON能够引导用户到地图上的目标地标，描述环境，并通过视觉观察回答问题。通过有效利用对话，机器人可以将用户的自由形式描述与环境中的地标关联起来，并通过口语提供语义信息给用户。我们在日常室内环境中进行了盲目参与者的用户研究。我们的结果表明，DRAGON能够与用户顺畅地沟通，

    Persons with visual impairments (PwVI) have difficulties understanding and navigating spaces around them. Current wayfinding technologies either focus solely on navigation or provide limited communication about the environment. Motivated by recent advances in visual-language grounding and semantic navigation, we propose DRAGON, a guiding robot powered by a dialogue system and the ability to associate the environment with natural language. By understanding the commands from the user, DRAGON is able to guide the user to the desired landmarks on the map, describe the environment, and answer questions from visual observations. Through effective utilization of dialogue, the robot can ground the user's free-form descriptions to landmarks in the environment, and give the user semantic information through spoken language. We conduct a user study with blindfolded participants in an everyday indoor environment. Our results demonstrate that DRAGON is able to communicate with the user smoothly, pr
    
[^4]: 基于LLM辅助的知识图谱工程: ChatGPT实验

    LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT. (arXiv:2307.06917v1 [cs.AI])

    [http://arxiv.org/abs/2307.06917](http://arxiv.org/abs/2307.06917)

    本文介绍了基于LLM辅助的知识图谱工程实验，展示了ChatGPT在开发和管理知识图谱方面的潜力。

    

    知识图谱提供了一个结构化、灵活、透明、跨系统和协作的方式来组织社会和工业以及科学学科中各个领域的知识和数据。知识图谱在有效性方面超越了任何其他形式的表示。然而，知识图谱工程需要对图结构、网络技术、现有模型和词汇、规则集、逻辑以及最佳实践有深入的了解，同时还需要大量的工作。考虑到最近大规模语言模型（LLM）及其接口和应用的进展，我们对ChatGPT进行了全面实验，探索其在支持知识图谱工程方面的潜力。在本文中，我们展示了其中一些实验及其结果，以展示ChatGPT如何辅助我们开发和管理知识图谱。

    Knowledge Graphs (KG) provide us with a structured, flexible, transparent, cross-system, and collaborative way of organizing our knowledge and data across various domains in society and industrial as well as scientific disciplines. KGs surpass any other form of representation in terms of effectiveness. However, Knowledge Graph Engineering (KGE) requires in-depth experiences of graph structures, web technologies, existing models and vocabularies, rule sets, logic, as well as best practices. It also demands a significant amount of work. Considering the advancements in large language models (LLMs) and their interfaces and applications in recent years, we have conducted comprehensive experiments with ChatGPT to explore its potential in supporting KGE. In this paper, we present a selection of these experiments and their results to demonstrate how ChatGPT can assist us in the development and management of KGs.
    
[^5]: 生成用于语言模型事实性评估的基准数据集

    Generating Benchmarks for Factuality Evaluation of Language Models. (arXiv:2307.06908v1 [cs.CL])

    [http://arxiv.org/abs/2307.06908](http://arxiv.org/abs/2307.06908)

    该论文提出了一个名为FACTOR的方法，用于生成用于语言模型事实性评估的基准数据集。通过自动转换事实语料库，评估语言模型根据语料库生成真实事实的倾向与生成不正确陈述的能力。实验结果表明，该基准数据集的分数随模型大小增加而增加，在LM与检索方法结合时性能得到改善。困惑度和基准数据集分数之间存在相关性，但不总是一致。

    

    在将语言模型（LM）部署到特定领域之前，衡量其在该领域中生成事实错误信息的倾向很重要。现有的事实生成评估方法集中于从LM自身中采样的事实，因此无法控制评估事实的集合，并且可能低估了罕见和不太可能的事实。我们提出了FACTOR：通过语料库变换进行事实评估的方法，这是一种可扩展的方法来评估LM的事实性。FACTOR会自动将感兴趣的事实语料库转化为一个基准数据集，评估LM根据语料库生成真实事实的倾向与生成类似但不正确的陈述的能力。我们使用我们的框架创建了两个基准数据集：Wiki-FACTOR和News-FACTOR。我们的实验结果表明：（i）我们的基准数据集分数随模型大小增加而增加，并且当LM与检索方法结合使用时，性能得到改善；（ii）基准数据集分数与困惑度之间存在相关性，但这两个指标在模型排序上并不总是一致；以及（iii）当困惑度和基准数据集分数发生冲突时，基准数据集分数更能准确反映LM的事实性能。

    Before deploying a language model (LM) within a given domain, it is important to measure its tendency to generate factually incorrect information in that domain. Existing factual generation evaluation methods focus on facts sampled from the LM itself, and thus do not control the set of evaluated facts and might under-represent rare and unlikely facts. We propose FACTOR: Factual Assessment via Corpus TransfORmation, a scalable approach for evaluating LM factuality. FACTOR automatically transforms a factual corpus of interest into a benchmark evaluating an LM's propensity to generate true facts from the corpus vs. similar but incorrect statements. We use our framework to create two benchmarks: Wiki-FACTOR and News-FACTOR. We show that: (i) our benchmark scores increase with model size and improve when the LM is augmented with retrieval; (ii) benchmark score correlates with perplexity, but the two metrics do not always agree on model ranking; and (iii) when perplexity and benchmark score 
    
[^6]: DecompEval：将生成的文本作为无监督分解问答进行评估

    DecompEval: Evaluating Generated Texts as Unsupervised Decomposed Question Answering. (arXiv:2307.06869v1 [cs.CL])

    [http://arxiv.org/abs/2307.06869](http://arxiv.org/abs/2307.06869)

    DecompEval提出了一种简单而有效的指标来评估自然语言生成任务，它将评估建模为一种类似指令的问答任务，并利用预训练语言模型进行衡量，以增强泛化能力和可解释性。

    

    现有的自然语言生成（NLG）任务评估指标面临着泛化能力和可解释性的挑战。具体而言，大多数表现良好的指标需要在特定的NLG任务和评估维度的评估数据集上进行训练，这可能导致对任务特定数据集的过拟合。此外，现有的指标仅提供每个维度的评估分数，而不揭示如何获得该分数的证据。为了应对这些挑战，我们提出了一种简单而有效的指标称为DecompEval。这个指标将NLG评估建模为一种类似指令的问答任务，并利用经过指令调整的预训练语言模型（PLMs）而不是在评估数据集上进行训练，旨在增强泛化能力。为了使评估过程更具可解释性，我们将关于生成文本质量的设计指令式问题分解为衡量子问题的问题

    Existing evaluation metrics for natural language generation (NLG) tasks face the challenges on generalization ability and interpretability. Specifically, most of the well-performed metrics are required to train on evaluation datasets of specific NLG tasks and evaluation dimensions, which may cause over-fitting to task-specific datasets. Furthermore, existing metrics only provide an evaluation score for each dimension without revealing the evidence to interpret how this score is obtained. To deal with these challenges, we propose a simple yet effective metric called DecompEval. This metric formulates NLG evaluation as an instruction-style question answering task and utilizes instruction-tuned pre-trained language models (PLMs) without training on evaluation datasets, aiming to enhance the generalization ability. To make the evaluation process more interpretable, we decompose our devised instruction-style question about the quality of generated texts into the subquestions that measure th
    
[^7]: 提示不应被视为秘密：系统地衡量提示提取攻击的成功性

    Prompts Should not be Seen as Secrets: Systematically Measuring Prompt Extraction Attack Success. (arXiv:2307.06865v1 [cs.CL])

    [http://arxiv.org/abs/2307.06865](http://arxiv.org/abs/2307.06865)

    本论文提出了一个系统地衡量提示提取攻击成功的框架，并通过多个实验发现，即使提示被保密，简单的基于文本的攻击仍然可以高概率地揭示提示。

    

    大型语言模型的生成通常通过提示技术来控制，其中用户对模型的查询以旨在指导模型在该查询上的行为的提示作为前缀。公司用于指导其模型的提示通常被视为秘密，隐藏在查询的用户之外。它们甚至被视为可以买卖的商品。然而，有经验性的证据显示，即使提示被保密，用户仍然可以提取它们。在本文中，我们提出了一个系统地衡量提示提取攻击成功的框架。在使用多个提示源和多个基础语言模型的实验中，我们发现简单的基于文本的攻击实际上可以高概率地揭示提示。

    The generations of large language models are commonly controlled through prompting techniques, where a user's query to the model is prefixed with a prompt that aims to guide the model's behaviour on the query. The prompts used by companies to guide their models are often treated as secrets, to be hidden from the user making the query. They have even been treated as commodities to be bought and sold. However, there has been anecdotal evidence showing that the prompts can be extracted by a user even when they are kept secret. In this paper, we present a framework for systematically measuring the success of prompt extraction attacks. In experiments with multiple sources of prompts and multiple underlying language models, we find that simple text-based attacks can in fact reveal prompts with high probability.
    
[^8]: 自洽性方法用于无限生成问题的改进

    Self-consistency for open-ended generations. (arXiv:2307.06857v1 [cs.AI])

    [http://arxiv.org/abs/2307.06857](http://arxiv.org/abs/2307.06857)

    本论文提出了一种改进大规模预训练语言模型生成输出质量和一致性的新方法，通过扩展自洽性框架的适用性，实现了从一个候选集中恢复最优或接近最优的生成结果，并提出了一种轻量级无参数相似性函数来改进代码生成、自动形式化和摘要任务的效果。

    

    在这篇论文中，我们提出了一种改进大规模预训练语言模型生成输出的质量和一致性的新方法。自洽性已经被证明是一种有效的方法，对于具有固定答案的提示，选择得票最多的答案。我们引入了一个推广的自洽性框架，扩展了其适用性，超越了固定答案问题的范围。通过大量的模拟实验，我们证明了我们的方法能够从候选集中恢复最优或接近最优的生成结果。我们还提出了一种轻量级无参数相似性函数，即使没有访问到标记的概率，也能在代码生成、自动形式化和摘要任务中显著和一致地改进效果。我们的方法几乎没有计算开销，不需要额外的再排序模型或对现有模型的修改。

    In this paper, we present a novel approach for improving the quality and consistency of generated outputs from large-scale pre-trained language models (LLMs). Self-consistency has emerged as an effective approach for prompts with fixed answers, selecting the answer with the highest number of votes. In this paper, we introduce a generalized framework for self-consistency that extends its applicability beyond problems that have fixed-answer answers. Through extensive simulations, we demonstrate that our approach consistently recovers the optimal or near-optimal generation from a set of candidates. We also propose lightweight parameter-free similarity functions that show significant and consistent improvements across code generation, autoformalization, and summarization tasks, even without access to token log probabilities. Our method incurs minimal computational overhead, requiring no auxiliary reranker models or modifications to the existing model.
    
[^9]: 垃圾进，垃圾出：利用大型语言模型进行零样本犯罪检测

    Garbage in, garbage out: Zero-shot detection of crime using Large Language Models. (arXiv:2307.06844v1 [cs.CL])

    [http://arxiv.org/abs/2307.06844](http://arxiv.org/abs/2307.06844)

    本文利用大型语言模型学习的常识知识，通过将视频转换为文本描述，实现了零样本推理的犯罪检测。现有的视频转文本方法质量不足以支持推理。

    

    本文提出利用大型语言模型学习的常识知识，在给定监控视频的文本描述的情况下进行关于犯罪的零样本推理。我们展示了当将视频手动转换为高质量的文本描述时，大型语言模型能够仅通过零样本推理实现具有最先进性能的犯罪检测和分类。然而，现有的自动化视频转文本方法无法生成足够质量的视频描述来支持推理（垃圾视频描述进入大型语言模型后，产生的结果也是垃圾）。

    This paper proposes exploiting the common sense knowledge learned by large language models to perform zero-shot reasoning about crimes given textual descriptions of surveillance videos. We show that when video is (manually) converted to high quality textual descriptions, large language models are capable of detecting and classifying crimes with state-of-the-art performance using only zero-shot reasoning. However, existing automated video-to-text approaches are unable to generate video descriptions of sufficient quality to support reasoning (garbage video descriptions into the large language model, garbage out).
    
[^10]: 基于BERT的区分性语音识别候选修正的个性化方法

    Personalization for BERT-based Discriminative Speech Recognition Rescoring. (arXiv:2307.06832v1 [eess.AS])

    [http://arxiv.org/abs/2307.06832](http://arxiv.org/abs/2307.06832)

    本论文提出了三种利用个性化内容提高端到端语音识别准确性的方法：词表、提示和基于交叉注意力的编码器-解码器模型。实验证明，这些方法都显著提高了词错误率，并且自然语言提示不需要训练即可改善准确率。其中，词表表现最佳，提高了10%的词错误率，同时在通用测试集上也有1%的提升。

    

    在端到端语音识别中，个性化内容的识别仍然是一个挑战。我们探索了三种利用个性化内容在神经修正步骤中提高识别准确性的新方法：词表、提示和基于交叉注意力的编码器-解码器模型。我们使用内部的去标识化英语(美国)交互数据，补充个性化命名实体，以比较这些方法。在一个包含个性化命名实体的测试集上，我们展示了每种方法相对于神经修正基线可以将词错误率提高超过10%。我们还展示了在这个测试集上，自然语言提示可以提高词错误率7%，而不需要任何训练，并且在泛化方面只有微小的损失。总体而言，词表的表现最好，词错误率提高了10%，在一个通用测试集上还提高了1%。

    Recognition of personalized content remains a challenge in end-to-end speech recognition. We explore three novel approaches that use personalized content in a neural rescoring step to improve recognition: gazetteers, prompting, and a cross-attention based encoder-decoder model. We use internal de-identified en-US data from interactions with a virtual voice assistant supplemented with personalized named entities to compare these approaches. On a test set with personalized named entities, we show that each of these approaches improves word error rate by over 10%, against a neural rescoring baseline. We also show that on this test set, natural language prompts can improve word error rate by 7% without any training and with a marginal loss in generalization. Overall, gazetteers were found to perform the best with a 10% improvement in word error rate (WER), while also improving WER on a general test set by 1%.
    
[^11]: 使用大规模语言模型的否定式互补常识

    Negated Complementary Commonsense using Large Language Models. (arXiv:2307.06794v1 [cs.CL])

    [http://arxiv.org/abs/2307.06794](http://arxiv.org/abs/2307.06794)

    本论文研究了使用大规模语言模型解决否定式互补问题的性能。作者发现，这种类型的问题会对模型的响应产生负面影响，并提出了一种模型无关的方法来改善性能。实验证明，该方法在少样本生成方面优于GPT-3，并强调了研究大规模语言模型在否定式互补问题中的重要性。

    

    更大的语言模型，如GPT-3，在许多任务中表现出色。然而，我们证明，非常规问题可能会使模型失去警觉。本文主要关注在常识情景中寻找否定式互补问题的答案。我们阐述了这类问题对模型响应的不利影响。我们提出了一种模型无关的方法来提高在否定式互补情景中的性能。我们的方法在从GPT-3进行少样本生成方面表现优于（超过11个点），更重要的是，强调了研究大规模语言模型在否定式互补问题中的响应的重要性。代码、数据和实验可在以下链接找到：https://github.com/navidre/negated_complementary_commonsense。

    Larger language models, such as GPT-3, have shown to be excellent in many tasks. However, we demonstrate that out-of-ordinary questions can throw the model off guard. This work focuses on finding answers to negated complementary questions in commonsense scenarios. We illustrate how such questions adversely affect the model responses. We propose a model-agnostic methodology to improve the performance in negated complementary scenarios. Our method outperforms few-shot generation from GPT-3 (by more than 11 points) and, more importantly, highlights the significance of studying the response of large language models in negated complementary questions. The code, data, and experiments are available under: https://github.com/navidre/negated_complementary_commonsense.
    
[^12]: 一种新型的与平台无关的多模态深度学习模型，用于识别社交媒体上的促进饮食紊乱内容

    A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v1 [cs.LG])

    [http://arxiv.org/abs/2307.06775](http://arxiv.org/abs/2307.06775)

    本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。

    

    在过去的十年中，饮食紊乱的诊断和与之相关的死亡数量大幅增加，尤其是在新冠疫情期间。这种巨大增长部分来源于疫情的压力，但也与社交媒体的暴露增加有关，社交媒体上充斥着促进饮食紊乱的内容。这些内容可以诱发观看者的饮食紊乱。本研究旨在创建一个多模态深度学习模型，能够基于视觉和文本数据的组合判断给定的社交媒体帖子是否促进饮食紊乱。从Twitter收集了一个带有标签的推文数据集，对其进行了十二个深度学习模型的训练和测试。根据模型的性能，最有效的深度学习模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的多模态融合模型，准确率和F1分数分别达到95.9%和0.959。RoBERTa和MaxViT融合模型可以有效地识别社交媒体上的促进饮食紊乱的内容。

    Over the last decade, there has been a vast increase in eating disorder diagnoses and eating disorder-attributed deaths, reaching their zenith during the Covid-19 pandemic. This immense growth derived in part from the stressors of the pandemic but also from increased exposure to social media, which is rife with content that promotes eating disorders. Such content can induce eating disorders in viewers. This study aimed to create a multimodal deep learning model capable of determining whether a given social media post promotes eating disorders based on a combination of visual and textual data. A labeled dataset of Tweets was collected from Twitter, upon which twelve deep learning models were trained and tested. Based on model performance, the most effective deep learning model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, attaining accuracy and F1 scores of 95.9% and 0.959 respectively. The RoBERTa and MaxViT fusion
    
[^13]: 为什么导向式对话策略学习表现优秀？理解对抗学习及其替代方法的作用。

    Why Guided Dialog Policy Learning performs well? Understanding the role of adversarial learning and its alternative. (arXiv:2307.06721v1 [cs.CL])

    [http://arxiv.org/abs/2307.06721](http://arxiv.org/abs/2307.06721)

    本论文通过分析对话策略和奖励估计器的目标函数，解释了对抗学习在对话策略学习中的作用，并提出了一种替代方法。

    

    对话策略是根据每个对话轮次的当前状态确定系统动作的关键。近年来，强化学习 (RL) 已成为对话策略学习 (DPL) 的一种有前途的选择。在基于 RL 的 DPL 中，根据奖励更新对话策略。对于具有大量状态动作对组合的多领域任务导向型对话场景，精细构建像状态-动作相关的奖励来有效指导对话策略是具有挑战性的。一种从收集到的数据中估计奖励的方式是使用对抗学习 (AL) 同时训练奖励估计器和对话策略。尽管这种方法在实验中表现出优越的性能，但其固有的对抗学习问题（例如模式坍缩）也十分棘手。本文通过对对话策略和奖励估计器的目标函数进行详细分析，首先确定了 AL 在 DPL 中的作用。接下来，基于此，该论文提出了一种替代方法。

    Dialog policies, which determine a system's action based on the current state at each dialog turn, are crucial to the success of the dialog. In recent years, reinforcement learning (RL) has emerged as a promising option for dialog policy learning (DPL). In RL-based DPL, dialog policies are updated according to rewards. The manual construction of fine-grained rewards, such as state-action-based ones, to effectively guide the dialog policy is challenging in multi-domain task-oriented dialog scenarios with numerous state-action pair combinations. One way to estimate rewards from collected data is to train the reward estimator and dialog policy simultaneously using adversarial learning (AL). Although this method has demonstrated superior performance experimentally, it is fraught with the inherent problems of AL, such as mode collapse. This paper first identifies the role of AL in DPL through detailed analyses of the objective functions of dialog policy and reward estimator. Next, based on 
    
[^14]: 使用大型语言模型实现无监督校准的文本分类方法的先验适应

    Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models. (arXiv:2307.06713v1 [cs.CL])

    [http://arxiv.org/abs/2307.06713](http://arxiv.org/abs/2307.06713)

    本文提出了一种使用大型语言模型进行文本分类的无监督校准方法，通过调整先验类别分布，实现在没有标记样本和仅少量领域内样本查询的情况下执行任务。

    

    当前有许多自然语言任务正在使用大规模语言模型（LLM）进行研究。这些模型通常通过大量无监督文本数据进行训练，并通过微调、校准或上下文学习等方法进行适应以执行下游自然语言任务。在本研究中，我们提出了一种方法，通过调整先验类别分布，实现在没有标记样本和仅少量领域内样本查询的情况下执行文本分类任务。该方法将LLM视为黑盒，在模型屏障中添加了一个阶段，用于校准模型后验以完成任务。结果表明，这些方法在不同数量的提示训练样本和无适应数据下的校准方法中优于未适应的模型。

    A wide variety of natural language tasks are currently being addressed with large-scale language models (LLMs). These models are usually trained with a very large amount of unsupervised text data and adapted to perform a downstream natural language task using methods like fine-tuning, calibration or in-context learning. In this work, we propose an approach to adapt the prior class distribution to perform text classification tasks without the need for labelled samples and only few in-domain sample queries. The proposed approach treats the LLM as a black box, adding a stage where the model posteriors are calibrated to the task. Results show that these methods outperform the un-adapted model for different number of training shots in the prompt and a previous approach were calibration is performed without using any adaptation data.
    
[^15]: 是否分享？给予差分隐私的自然语言处理系统敏感数据的普通人接受什么风险？

    To share or not to share: What risks would laypeople accept to give sensitive data to differentially-private NLP systems?. (arXiv:2307.06708v1 [cs.CL])

    [http://arxiv.org/abs/2307.06708](http://arxiv.org/abs/2307.06708)

    这项研究旨在探索普通人在面临隐私威胁情境时的决策行为，以及他们愿意为给予差分隐私的自然语言处理系统提供敏感数据所承担的风险。

    

    尽管NLP社区已经采用中心差分隐私作为保护隐私的模型训练或数据共享的首选框架，但决定性的关键参数——控制隐私保护强度的隐私预算ε的选择和解释仍然相当随意。我们认为确定ε值不应该仅由研究人员或系统开发者决定，还必须考虑那些共享他们潜在敏感数据的人。换句话说：你愿意为ε值为10而分享你的即时消息吗？我们通过设计、实施和进行行为实验(311名普通参与者)来填补这一研究空白，研究人们在不确定决策环境下面对威胁隐私的情境时的行为。通过将风险感知框架化为两个现实的NLP场景，并使用情节行为研究，我们能够确定哪些ε阈值将导致共享行为的转变。

    Although the NLP community has adopted central differential privacy as a go-to framework for privacy-preserving model training or data sharing, the choice and interpretation of the key parameter, privacy budget $\varepsilon$ that governs the strength of privacy protection, remains largely arbitrary. We argue that determining the $\varepsilon$ value should not be solely in the hands of researchers or system developers, but must also take into account the actual people who share their potentially sensitive data. In other words: Would you share your instant messages for $\varepsilon$ of 10? We address this research gap by designing, implementing, and conducting a behavioral experiment (311 lay participants) to study the behavior of people in uncertain decision-making situations with respect to privacy-threatening situations. Framing the risk perception in terms of two realistic NLP scenarios and using a vignette behavioral study help us determine what $\varepsilon$ thresholds would lead l
    
[^16]: 意图校准的自我训练用于开放领域对话中的答案选择

    Intent-calibrated Self-training for Answer Selection in Open-domain Dialogues. (arXiv:2307.06703v1 [cs.CL])

    [http://arxiv.org/abs/2307.06703](http://arxiv.org/abs/2307.06703)

    这项研究介绍了一种名为意图校准的自我训练方法，用于改善开放领域对话中答案选择的质量。通过使用意图标签来校准答案标签，作者通过实验证明了这种方法在两个基准数据集上的效果优于基线模型。

    

    开放领域对话中的答案选择旨在从候选答案中选择准确的答案。最近答案选择模型的成功依赖于使用大量标记数据进行训练。然而，收集大规模标记数据是一项耗时且费力的工作。在本文中，我们引入了预测的意图标签以校准自我训练范式中的答案标签。具体而言，我们提出了意图校准的自我训练（ICAST）来通过意图校准的答案选择范式提高伪答案标签的质量，其中我们使用伪意图标签来帮助改进伪答案标签。我们在两个基准数据集上进行了大量实验，涉及开放领域对话。实验结果显示，在只有1％、5％和10％标记数据的情况下，ICAST始终优于基线。特别是与仅有5％标记数据的最强基线相比，它在两个数据集上将F1得分分别提高了2.06％和1.00％。

    Answer selection in open-domain dialogues aims to select an accurate answer from candidates. Recent success of answer selection models hinges on training with large amounts of labeled data. However, collecting large-scale labeled data is labor-intensive and time-consuming. In this paper, we introduce the predicted intent labels to calibrate answer labels in a self-training paradigm. Specifically, we propose the intent-calibrated self-training (ICAST) to improve the quality of pseudo answer labels through the intent-calibrated answer selection paradigm, in which we employ pseudo intent labels to help improve pseudo answer labels. We carry out extensive experiments on two benchmark datasets with open-domain dialogues. The experimental results show that ICAST outperforms baselines consistently with 1%, 5% and 10% labeled data. Specifically, it improves 2.06% and 1.00% of F1 score on the two datasets, compared with the strongest baseline with only 5% labeled data.
    
[^17]: Parmesan：教育中的数学概念提取

    Parmesan: mathematical concept extraction for education. (arXiv:2307.06699v1 [cs.CL])

    [http://arxiv.org/abs/2307.06699](http://arxiv.org/abs/2307.06699)

    Parmesan是一个原型系统，用于在上下文中搜索和定义数学概念，特别关注范畴论领域。该系统利用自然语言处理组件进行概念提取、关系提取、定义提取和实体链接。通过该系统的开发，可以解决现有技术不能直接应用于范畴论领域的问题，并提供了两个数学语料库以支持系统的使用。

    

    数学是一个高度专业化的领域，具有自己独特的挑战，但在自然语言处理领域的研究却有限。然而，数学在许多不同领域的跨学科研究中经常依赖于对数学概念的理解。为了帮助来自其他领域的研究人员，我们开发了一个原型系统，用于在上下文中搜索和定义数学概念，重点关注范畴论领域。这个系统名为Parmesan，依赖于自然语言处理组件，包括概念提取、关系提取、定义提取和实体链接。在开发这个系统的过程中，我们展示了现有技术不能直接应用于范畴论领域，并提出了一种混合技术，这种技术表现良好，但我们预计系统将随着时间的推移而不断演变。我们还提供了两个清理过的数学语料库，用于支持原型系统，这些语料库基于期刊文章。

    Mathematics is a highly specialized domain with its own unique set of challenges that has seen limited study in natural language processing. However, mathematics is used in a wide variety of fields and multidisciplinary research in many different domains often relies on an understanding of mathematical concepts. To aid researchers coming from other fields, we develop a prototype system for searching for and defining mathematical concepts in context, focusing on the field of category theory. This system, Parmesan, depends on natural language processing components including concept extraction, relation extraction, definition extraction, and entity linking. In developing this system, we show that existing techniques cannot be applied directly to the category theory domain, and suggest hybrid techniques that do perform well, though we expect the system to evolve over time. We also provide two cleaned mathematical corpora that power the prototype system, which are based on journal articles 
    
[^18]: 超越本地范围：全球图增强个性化新闻推荐

    Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v1 [cs.IR])

    [http://arxiv.org/abs/2307.06576](http://arxiv.org/abs/2307.06576)

    本文介绍了一种名为GLORY的模型，通过全局图与本地表示相结合，增强了个性化推荐系统。该模型通过构建全局感知历史新闻编码器来融合历史新闻表示，并考虑了用户隐藏的动机和行为。

    

    精确地向用户推荐候选新闻文章一直是个性化新闻推荐系统的核心挑战。大多数近期的研究主要集中在使用先进的自然语言处理技术从丰富的文本数据中提取语义信息，使用从本地历史新闻派生的基于内容的方法。然而，这种方法缺乏全局视角，未能考虑用户隐藏的动机和行为，超越语义信息。为了解决这个问题，我们提出了一种新颖的模型 GLORY（Global-LOcal news Recommendation sYstem），它结合了从其他用户学到的全局表示和本地表示，来增强个性化推荐系统。我们通过构建一个全局感知历史新闻编码器来实现这一目标，其中包括一个全局新闻图，并使用门控图神经网络来丰富新闻表示，从而通过历史新闻聚合器融合历史新闻表示。

    Precisely recommending candidate news articles to users has always been a core challenge for personalized news recommendation systems. Most recent works primarily focus on using advanced natural language processing techniques to extract semantic information from rich textual data, employing content-based methods derived from local historical news. However, this approach lacks a global perspective, failing to account for users' hidden motivations and behaviors beyond semantic information. To address this challenge, we propose a novel model called GLORY (Global-LOcal news Recommendation sYstem), which combines global representations learned from other users with local representations to enhance personalized recommendation systems. We accomplish this by constructing a Global-aware Historical News Encoder, which includes a global news graph and employs gated graph neural networks to enrich news representations, thereby fusing historical news representations by a historical news aggregator.
    
[^19]: 基于卷积神经网络的微博情感分析：一种自然语言处理方法

    Convolutional Neural Networks for Sentiment Analysis on Weibo Data: A Natural Language Processing Approach. (arXiv:2307.06540v1 [cs.CL])

    [http://arxiv.org/abs/2307.06540](http://arxiv.org/abs/2307.06540)

    本研究提出了一种基于卷积神经网络的方法，利用微博数据进行情感分析，取得了约0.73的宏平均F1分数，结果表明了CNN在情感分析任务中的有效性，对社交媒体分析、市场研究和政策研究等领域有重要意义。

    

    该研究使用卷积神经网络（CNN）对来自微博的119,988条原始推文进行了情感分析，为自然语言处理（NLP）提供了一种新的方法。数据是从百度的PaddlePaddle AI平台获取的，经过了精细的预处理、分词和情感标签分类。利用基于词嵌入的CNN模型进行特征提取和情感分类训练，该模型在测试集上获得了约0.73的宏平均F1分数，显示了对正面、中性和负面情感的平衡表现。研究结果强调了CNN在情感分析任务中的有效性，对社交媒体分析、市场研究和政策研究等实际应用有着重要意义。完整的实验内容和代码已在Kaggle数据平台上公开提供以进行进一步研究和开发。

    This study addressed the complex task of sentiment analysis on a dataset of 119,988 original tweets from Weibo using a Convolutional Neural Network (CNN), offering a new approach to Natural Language Processing (NLP). The data, sourced from Baidu's PaddlePaddle AI platform, were meticulously preprocessed, tokenized, and categorized based on sentiment labels. A CNN-based model was utilized, leveraging word embeddings for feature extraction, and trained to perform sentiment classification. The model achieved a macro-average F1-score of approximately 0.73 on the test set, showing balanced performance across positive, neutral, and negative sentiments. The findings underscore the effectiveness of CNNs for sentiment analysis tasks, with implications for practical applications in social media analysis, market research, and policy studies. The complete experimental content and code have been made publicly available on the Kaggle data platform for further research and development. Future work ma
    
[^20]: 探索将大型语言模型集成到自动语音识别系统中的实证研究

    Exploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study. (arXiv:2307.06530v1 [cs.CL])

    [http://arxiv.org/abs/2307.06530](http://arxiv.org/abs/2307.06530)

    本文探讨了将大型语言模型集成到自动语音识别系统以提高准确性的问题，研究结果显示利用语言模型的上下文学习来进行ASR应用仍面临挑战。

    

    本文探讨了将大型语言模型（LLMs）集成到自动语音识别（ASR）系统中以提高转录准确性的问题。LLMs的不断发展，以其上下文学习能力和遵循指令的行为引起了自然语言处理（NLP）领域的极大关注。我们的主要重点是研究利用LLM的上下文学习能力来提升ASR系统性能的潜力，目前这些系统面临环境噪音、说话人口音和复杂语言环境等挑战。我们使用Aishell-1和LibriSpeech数据集设计了一项研究，ChatGPT和GPT-4作为LLM能力的基准。不幸的是，我们的初步实验结果并不理想，表明利用LLM的上下文学习来进行ASR应用的复杂性。尽管我们进一步尝试了不同的设置和模型，但LLMs纠正的句子频繁出错。

    This paper explores the integration of Large Language Models (LLMs) into Automatic Speech Recognition (ASR) systems to improve transcription accuracy. The increasing sophistication of LLMs, with their in-context learning capabilities and instruction-following behavior, has drawn significant attention in the field of Natural Language Processing (NLP). Our primary focus is to investigate the potential of using an LLM's in-context learning capabilities to enhance the performance of ASR systems, which currently face challenges such as ambient noise, speaker accents, and complex linguistic contexts. We designed a study using the Aishell-1 and LibriSpeech datasets, with ChatGPT and GPT-4 serving as benchmarks for LLM capabilities. Unfortunately, our initial experiments did not yield promising results, indicating the complexity of leveraging LLM's in-context learning for ASR applications. Despite further exploration with varied settings and models, the corrected sentences from the LLMs freque
    
[^21]: 多问题谈判对话的协议跟踪

    Agreement Tracking for Multi-Issue Negotiation Dialogues. (arXiv:2307.06524v1 [cs.CL])

    [http://arxiv.org/abs/2307.06524](http://arxiv.org/abs/2307.06524)

    这项工作介绍了两方多问题谈判的协议跟踪任务，通过使用GPT-3构建了一个合成数据集并迁移学习T5模型，在解决缺乏标注数据的问题上取得了强有力的初始基线。

    

    自动化谈判支持系统的目标是帮助人类谈判者在多问题谈判中实现更有利的结果（例如，雇主和候选人在工作提议之前就薪水、工时和晋升等问题进行谈判）。为了成功，这些系统必须实时准确地跟踪参与者达成的协议。现有方法要么集中于任务导向的对话，要么产生非结构化的输出，使它们不适用于此目标。我们的工作引入了两方多问题谈判的协议跟踪的新任务，这要求在一个结构化的状态空间内连续监测协议。为了解决缺乏具有真实多问题谈判对话的标注语料库的问题，我们使用GPT-3构建了GPT-Negochat，一份我们公开的合成数据集。我们通过在MultiWOZ 2.4语料库上进行迁移学习，给出了我们任务的强有力的初始基线，对T5模型进行了预训练，包括T5-small和T5-...

    Automated negotiation support systems aim to help human negotiators reach more favorable outcomes in multi-issue negotiations (e.g., an employer and a candidate negotiating over issues such as salary, hours, and promotions before a job offer). To be successful, these systems must accurately track agreements reached by participants in real-time. Existing approaches either focus on task-oriented dialogues or produce unstructured outputs, rendering them unsuitable for this objective. Our work introduces the novel task of agreement tracking for two-party multi-issue negotiations, which requires continuous monitoring of agreements within a structured state space. To address the scarcity of annotated corpora with realistic multi-issue negotiation dialogues, we use GPT-3 to build GPT-Negochat, a synthesized dataset that we make publicly available. We present a strong initial baseline for our task by transfer-learning a T5 model trained on the MultiWOZ 2.4 corpus. Pre-training T5-small and T5-
    
[^22]: 自动化内容分析中的错误分类导致回归分析中的偏差。我们能修复吗？是的，我们能！

    Misclassification in Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes We Can!. (arXiv:2307.06483v1 [cs.LG])

    [http://arxiv.org/abs/2307.06483](http://arxiv.org/abs/2307.06483)

    传播学领域中的自动化内容分析常忽视了错误分类的偏差，我们介绍并测试了统计方法来纠正这种偏差，并设计了一种新方法来修复之。

    

    自动分类器（ACs）通常通过监督式机器学习（SML）构建，可以对从文本到图片和视频的大量数据进行分类，已经成为传播科学和相关领域中广泛流行的测量设备。尽管如此，即使是高度准确的分类器也会产生错误，这导致了错误分类的偏差和下游分析中误导性的结果，除非这些分析考虑到这些错误。通过对SML应用的系统文献综述，我们发现传播学者在很大程度上忽视了错误分类的偏差。原则上，现有的统计方法可以使用“黄金标准”验证数据（如由人类注释者创建的数据）来纠正错误分类的偏差，并产生一致的估计。我们介绍并测试了这些方法，包括我们在R包misclassificationmodels中设计和实现的一种新方法，通过蒙特卡洛模拟来揭示每种方法的局限性。

    Automated classifiers (ACs), often built via supervised machine learning (SML), can categorize large, statistically powerful samples of data ranging from text to images and video, and have become widely popular measurement devices in communication science and related fields. Despite this popularity, even highly accurate classifiers make errors that cause misclassification bias and misleading results in downstream analyses-unless such analyses account for these errors. As we show in a systematic literature review of SML applications, communication scholars largely ignore misclassification bias. In principle, existing statistical methods can use "gold standard" validation data, such as that created by human annotators, to correct misclassification bias and produce consistent estimates. We introduce and test such methods, including a new method we design and implement in the R package misclassificationmodels, via Monte Carlo simulations designed to reveal each method's limitations, which 
    
[^23]: 评估ChatGPT对于系统性综述文章筛选的能力

    Assessing the Ability of ChatGPT to Screen Articles for Systematic Reviews. (arXiv:2307.06464v1 [cs.SE])

    [http://arxiv.org/abs/2307.06464](http://arxiv.org/abs/2307.06464)

    本论文评估了聊天型AI模型ChatGPT在系统性综述（SR）文章筛选中的性能，结果表明ChatGPT是自动化SR过程的可行选择。

    

    通过在研究领域内组织知识，系统性综述（SR）为研究提供了宝贵的线索。有证据表明，SR已成为软件工程中一流的艺术品。然而，SR筛选阶段所需的繁琐手动工作使得这些研究变得昂贵且容易出错。尽管传统上认为筛选不适合自动化，但基于大型语言模型支持的生成式AI驱动的聊天机器人的出现将改变这一情况。在本报告中，我们提出了一种利用这些新技术发展自动化SR筛选的方法。我们评估了ChatGPT在SR文章筛选中的一致性、分类性能和推广能力，并将这些数据与传统用于SR自动化的分类器进行比较。我们的结果表明，ChatGPT是自动化SR过程的可行选择，但开发者在集成时需要仔细考虑。

    By organizing knowledge within a research field, Systematic Reviews (SR) provide valuable leads to steer research. Evidence suggests that SRs have become first-class artifacts in software engineering. However, the tedious manual effort associated with the screening phase of SRs renders these studies a costly and error-prone endeavor. While screening has traditionally been considered not amenable to automation, the advent of generative AI-driven chatbots, backed with large language models is set to disrupt the field. In this report, we propose an approach to leverage these novel technological developments for automating the screening of SRs. We assess the consistency, classification performance, and generalizability of ChatGPT in screening articles for SRs and compare these figures with those of traditional classifiers used in SR automation. Our results indicate that ChatGPT is a viable option to automate the SR processes, but requires careful considerations from developers when integra
    
[^24]: 没有训练就没有收益：重新审视基于Transformer的语言模型的高效训练算法

    No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models. (arXiv:2307.06440v1 [cs.LG])

    [http://arxiv.org/abs/2307.06440](http://arxiv.org/abs/2307.06440)

    本论文重新审视了基于Transformer的语言模型的高效训练算法，包括动态架构，批量选择和高效优化器。然而，在使用这些算法预训练时，相对于基线方法，它们的训练、验证和下游收益消失了。同时，论文提出了一个评估协议来进行计算，并释放了代码来促进高效训练的研究。

    

    近年来，训练Transformer-based语言模型所需的计算量急剧增加。这一趋势促使研究者们开展了针对高效训练算法的研究，旨在比标准训练更快地改善训练、验证和下游性能。在这项工作中，我们重新审视了三类这样的算法：动态架构（层叠、层丢弃）、批量选择（选择性反向传播、RHO损失）和高效优化器（Lion、Sophia）。当使用这些方法在固定计算预算下对BERT和T5进行预训练时，我们发现它们的训练、验证和下游收益相对于一个具有完全衰减学习率的基线而言会消失。我们定义了一个评估协议，可以通过将所有计算时间映射到一个称为参考系统时间的参考机器上，在任意机器上进行计算。我们讨论了我们提出的协议的局限性，并发布了我们的代码，以鼓励对高效训练的严格研究。

    The computation necessary for training Transformer-based language models has skyrocketed in recent years. This trend has motivated research on efficient training algorithms designed to improve training, validation, and downstream performance faster than standard training. In this work, we revisit three categories of such algorithms: dynamic architectures (layer stacking, layer dropping), batch selection (selective backprop, RHO loss), and efficient optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed computation budget using such methods, we find that their training, validation, and downstream gains vanish compared to a baseline with a fully-decayed learning rate. We define an evaluation protocol that enables computation to be done on arbitrary machines by mapping all computation time to a reference machine which we call reference system time. We discuss the limitations of our proposed protocol and release our code to encourage rigorous research in efficient training p
    
[^25]: 为生物医学知识提取而蒸馏大型语言模型：对药物不良事件的案例研究

    Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events. (arXiv:2307.06439v1 [cs.CL])

    [http://arxiv.org/abs/2307.06439](http://arxiv.org/abs/2307.06439)

    本研究通过将大型语言模型蒸馏为特定任务的学生模型，成功地提升了在药物不良事件提取方面的性能，并在不使用标记数据的情况下达到了与监督式最先进模型相当的准确性，具有成本、效率和白盒模型访问等优势。

    

    大型语言模型（LLMs），如GPT-4，在包括健康应用在内的各种任务中展示了卓越的能力。本文研究了如何利用LLMs来扩展生物医学知识整理。我们发现，尽管LLMs已经具备了结构化生物医学文本的良好能力，但通过自监督学习将其蒸馏为特定任务的学生模型可以取得显著的改进，同时具备成本、效率和白盒模型访问等额外优势。我们对不良药物事件（ADE）提取进行了案例研究，这是改进医疗的重要领域。在标准ADE提取评估中，经蒸馏的GPT-3.5 PubMedBERT模型在不使用任何标记数据的情况下，达到了与监督式最先进模型相当的准确性。尽管体积缩小了1000多倍，但蒸馏模型在F1指标上超过了其教师GPT-3.5约6个绝对点，超过了GPT-4约5个绝对点。

    Large language models (LLMs), such as GPT-4, have demonstrated remarkable capabilities across a wide range of tasks, including health applications. In this paper, we study how LLMs can be used to scale biomedical knowledge curation. We find that while LLMs already possess decent competency in structuring biomedical text, by distillation into a task-specific student model through self-supervised learning, substantial gains can be attained over out-of-box LLMs, with additional advantages such as cost, efficiency, and white-box model access.  We conduct a case study on adverse drug event (ADE) extraction, which is an important area for improving care. On standard ADE extraction evaluation, a GPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised state-of-the-art models without using any labeled data. Despite being over 1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by over 6 absolute points in F1 and GPT-4 by over 5 absolute points.  Ablat
    
[^26]: 大语言模型的综合概述

    A Comprehensive Overview of Large Language Models. (arXiv:2307.06435v1 [cs.CL])

    [http://arxiv.org/abs/2307.06435](http://arxiv.org/abs/2307.06435)

    大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。

    

    大语言模型（LLM）展示了出色的泛化能力，导致了众多模型的发展。这些模型提出了各种新的架构，通过改进的训练策略来调整现有的架构，增加上下文长度，使用高质量的训练数据，并增加训练时间以超越基线。分析新的发展对于识别增强训练稳定性和改进LLM泛化能力的变化至关重要。本综述论文全面分析了LLM的架构及其分类、训练策略、训练数据集和性能评估，并讨论未来的研究方向。此外，本文还讨论了LLM的基本构建块和概念，并提供了LLM的完整概述，包括其重要特点和功能。最后，本文总结了LLM研究的重要发现，并整合了关键的架构和训练策略。

    Large Language Models (LLMs) have shown excellent generalization capabilities that have led to the development of numerous models. These models propose various new architectures, tweaking existing architectures with refined training strategies, increasing context length, using high-quality training data, and increasing training time to outperform baselines. Analyzing new developments is crucial for identifying changes that enhance training stability and improve generalization in LLMs. This survey paper comprehensively analyses the LLMs architectures and their categorization, training strategies, training datasets, and performance evaluations and discusses future research directions. Moreover, the paper also discusses the basic building blocks and concepts behind LLMs, followed by a complete overview of LLMs, including their important features and functions. Finally, the paper summarizes significant findings from LLM research and consolidates essential architectural and training strateg
    
[^27]: 词汇间语义关系的获取

    The Acquisition of Semantic Relationships between words. (arXiv:2307.06419v1 [cs.CL])

    [http://arxiv.org/abs/2307.06419](http://arxiv.org/abs/2307.06419)

    本文研究了词语的形态与语义关系之间的互动关系，通过探索语言形态学与语义关系之间的复杂关联，揭示了词语结构对语言理解的影响。

    

    对语义关系的研究揭示了这些关系与语言的形态特征之间的密切联系。形态学作为语言学的一个分支，研究词语的内部结构和构成。通过深入探讨语义关系和语言形态学之间的关系，我们可以更深入地了解词语的底层结构如何影响语言的解释和理解。本文探讨了语义关系和不同语言的形态学之间的动态相互作用，通过研究语言形态学与语义关系之间复杂的关系，可以获得有关词语结构如何影响语言理解的宝贵见解。

    The study of semantic relationships has revealed a close connection between these relationships and the morphological characteristics of a language. Morphology, as a subfield of linguistics, investigates the internal structure and formation of words. By delving into the relationship between semantic relationships and language morphology, we can gain deeper insights into how the underlying structure of words contributes to the interpretation and comprehension of language. This paper explores the dynamic interplay between semantic relationships and the morphological aspects of different languages, by examining the intricate relationship between language morphology and semantic relationships, valuable insights can be gained regarding how the structure of words influences language comprehension.
    
[^28]: 不完整话语重写作为顺序贪婪标注

    Incomplete Utterance Rewriting as Sequential Greedy Tagging. (arXiv:2307.06337v1 [cs.LG])

    [http://arxiv.org/abs/2307.06337](http://arxiv.org/abs/2307.06337)

    本论文提出了一种基于序列标注的模型，能够更好地从对话上下文中提取信息，并引入了区分说话者的嵌入来建模说话者的变化。实验结果表明，该模型在恢复得分方面达到了最优，并在推理速度上胜过大多数之前的模型。

    

    不完整话语重写的任务最近受到了很多关注。之前的模型很难从对话上下文中提取信息，这在恢复得分低的情况下得以证明。为了解决这个问题，我们提出了一种新颖的基于序列标注的模型，更擅长从上下文中提取信息。同时，我们引入了区分说话者的嵌入来建模说话者的变化。在多个公开数据集上的实验表明，我们的模型在所有九个恢复得分上都达到了最优结果，同时其他指标得分也与之前最先进的模型相当。此外，得益于模型的简单性，我们的方法在推理速度上超过了大多数之前的模型。

    The task of incomplete utterance rewriting has recently gotten much attention. Previous models struggled to extract information from the dialogue context, as evidenced by the low restoration scores. To address this issue, we propose a novel sequence tagging-based model, which is more adept at extracting information from context. Meanwhile, we introduce speaker-aware embedding to model speaker variation. Experiments on multiple public datasets show that our model achieves optimal results on all nine restoration scores while having other metric scores comparable to previous state-of-the-art models. Furthermore, benefitting from the model's simplicity, our approach outperforms most previous models on inference speed.
    
[^29]: 大型语言模型用于供应链优化

    Large Language Models for Supply Chain Optimization. (arXiv:2307.03875v1 [cs.AI])

    [http://arxiv.org/abs/2307.03875](http://arxiv.org/abs/2307.03875)

    这项研究研究了利用大型语言模型（LLMs）来帮助解释和解读供应链优化结果的方法。他们设计了一个框架，可以接受普通文本查询作为输入，并输出关于底层优化结果的洞察。通过定量回答假设情况，该框架在不放弃最先进的组合优化技术的情况下帮助企业运营者更好地理解和信任优化结果。

    

    传统上，供应链操作涉及各种复杂的决策问题。在过去几十年中，供应链受益于计算技术的进步，从手动处理过渡到自动化和成本效益优化。然而，企业运营者仍然需要花费大量精力来解释和解读优化结果给相关人士。受大型语言模型(LLMs)最近的进展的启发，我们研究了这种颠覆性技术如何帮助弥合供应链自动化和人类理解与信任之间的差距。我们设计了一个名为\name{}的框架，它接受普通文本查询作为输入，并输出关于底层优化结果的洞察。我们的框架并没有放弃最先进的组合优化技术，而是利用它来定量地回答假设情况（例如，如果我们使用供应商B而不是供应商A，成本会如何变化）。

    Supply chain operations traditionally involve a variety of complex decision making problems. Over the last few decades, supply chains greatly benefited from advances in computation, which allowed the transition from manual processing to automation and cost-effective optimization. Nonetheless, business operators still need to spend substantial efforts in \emph{explaining} and interpreting the optimization outcomes to stakeholders. Motivated by the recent advances in Large Language Models (LLMs), we study how this disruptive technology can help bridge the gap between supply chain automation and human comprehension and trust thereof. We design \name{} -- a framework that accepts as input queries in plain text, and outputs insights about the underlying optimization outcomes. Our framework does not forgo the state-of-the-art combinatorial optimization technology, but rather leverages it to quantitatively answer what-if scenarios (e.g., how would the cost change if we used supplier B instead
    
[^30]: 对大型语言模型评估的调查

    A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])

    [http://arxiv.org/abs/2307.03109](http://arxiv.org/abs/2307.03109)

    本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。

    

    大型语言模型（LLMs）由于在各种应用中表现出的前所未有的性能而在学术界和工业界越来越受欢迎。随着LLMs在研究和日常使用中继续发挥着重要作用，它们的评估变得越来越关键，不仅在任务水平上，而且在社会层面上，以更好地了解它们的潜在风险。在过去的几年里，已经做出了相当大的努力来从不同的角度来研究LLMs。本文综述了LLMs的这些评估方法，重点关注三个关键维度：评估什么、在哪里评估以及如何评估。首先，我们从评估任务的角度提供了一个概述，涵盖了一般的自然语言处理任务、推理、医学应用、伦理学、教育、自然科学和社会科学、代理应用和其他领域。其次，我们通过深入探讨评估方法和基准答案来回答“在哪里”和“如何”这两个问题。

    Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
    
[^31]: PatternGPT: 一种基于模式的大型语言模型文本生成框架

    PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation. (arXiv:2307.00470v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.00470](http://arxiv.org/abs/2307.00470)

    PatternGPT是一种基于模式驱动的大型语言模型文本生成框架，通过利用大型语言模型的提取能力生成多样化的模式，并使用联邦学习的思想实现模式共享，最终通过搜索高质量模式指导生成模型。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。

    

    大型语言模型(LLMs)展示了出色的文本生成能力，能够为许多下游任务生成流畅的响应。然而，将大型语言模型应用于现实世界的关键任务仍然具有挑战性，因为它们容易出现幻觉，并且无法直接使用外部知识。为解决上述问题，本文提出了PatternGPT，一种基于模式驱动的大型语言模型文本生成框架。首先，该框架利用大型语言模型的提取能力生成丰富多样的模式，然后借鉴联邦学习的思想，使用多个代理实现共享以获取更多样的模式。最后，它使用判断标准和优化算法搜索高质量的模式，并使用搜索到的模式指导模型进行生成。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。

    Large language models(LLMS) have shown excellent text generation capabilities,capable of generating fluent responses for many downstream tasks. However,applying large language models to real-world critical tasks remains challenging due to their susceptibility to hallucinations and inability to directly use external knowledge. To address the above challenges,this paper proposes PatternGPT, a pattern-driven text generation framework for large language models. First,the framework utilizes the extraction capabilities of large language models to generate rich and diverse patterns and later draws on the idea of federated learning. Using multiple agents to achieve sharing to obtain more diverse patterns. Finally, it searches for high-quality patterns using judgment criteria and optimization algorithms and uses the searched patterns to guide the model for generation. This framework has the advantages of generating diversified patterns, protecting data privacy,combining external knowledge, and 
    
[^32]: Kosmos-2: 将多模态大规模语言模型与世界连接

    Kosmos-2: Grounding Multimodal Large Language Models to the World. (arXiv:2306.14824v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.14824](http://arxiv.org/abs/2306.14824)

    Kosmos-2是一个多模态大规模语言模型，可以感知物体描述并将文本与视觉世界联系起来。它在多个任务上展示了出色表现，包括多模态接地、多模态引用、感知语言任务以及语言理解和生成。

    

    我们介绍了Kosmos-2，一个多模态大规模语言模型（MLLM），使其能够感知物体描述（例如，边界框）并将文本与视觉世界联系起来。具体而言，我们将引用表达式表示为Markdown中的链接，即``[text span](bounding boxes)''，其中物体描述是位置标记序列。通过与多模态语料库结合，我们构建了大规模的图像文本对（称为GrIT）的数据来训练该模型。除了MLLM的现有功能（例如，感知各种模态，遵循指令和进行上下文学习）外，Kosmos-2还将接地能力集成到下游应用中。我们在广泛的任务上评估了Kosmos-2，包括多模态接地（例如，引用表达理解和短语接地），多模态引用（例如，引用表达生成），感知语言任务以及语言理解和生成。

    We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new capabilities of perceiving object descriptions (e.g., bounding boxes) and grounding text to the visual world. Specifically, we represent refer expressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where object descriptions are sequences of location tokens. Together with multimodal corpora, we construct large-scale data of grounded image-text pairs (called GrIT) to train the model. In addition to the existing capabilities of MLLMs (e.g., perceiving general modalities, following instructions, and performing in-context learning), Kosmos-2 integrates the grounding capability into downstream applications. We evaluate Kosmos-2 on a wide range of tasks, including (i) multimodal grounding, such as referring expression comprehension, and phrase grounding, (ii) multimodal referring, such as referring expression generation, (iii) perception-language tasks, and (iv) language understanding and generatio
    
[^33]: GEmo-CLAP: 面向语音情感识别的性别属性增强对比语音-语言预训练模型

    GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition. (arXiv:2306.07848v1 [cs.CL])

    [http://arxiv.org/abs/2306.07848](http://arxiv.org/abs/2306.07848)

    本文提出了GEmo-CLAP模型用于语音情感识别，结合了性别属性信息，相比于其他先进方法，该模型在IEMOCAP上实现了更优越的识别性能。

    

    对比语音-语言预训练（CLAP）最近在不同领域取得了惊人的成功。本文提出了一种名为GEmo-CLAP的高效性别属性增强CLAP模型，用于语音情感识别（SER）。具体而言，我们首先利用各种自监督学习的预训练模型构建了一种有效的情感CLAP模型（称为Emo-CLAP），用于SER。然后，考虑到在语音情感建模中性别属性的重要性，我们进一步提出了两种GEmo-CLAP方法，来整合语音信号的情感和性别信息，形成更合理的目标。在IEMOCAP语料库上进行的大量实验表明，我们提出的两种GEmo-CLAP方法始终优于基线Emo-CLAP模型（使用不同的预训练模型），同时与其他最先进的方法相比实现了更优越的识别性能。

    Contrastive Language-Audio Pretraining (CLAP) has recently exhibited impressive success in diverse fields. In this paper, we propose GEmo-CLAP, a kind of efficient gender-attribute-enhanced CLAP model for speech emotion recognition (SER). Specifically, we first build an effective emotion CLAP model termed Emo-CLAP for SER, utilizing various self-supervised learning based pre-trained models. Then, considering the importance of the gender attribute in speech emotion modeling, two GEmo-CLAP approaches are further proposed to integrate the emotion and gender information of speech signals, forming more reasonable objectives. Extensive experiments conducted on the IEMOCAP corpus demonstrate that our proposed two GEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with different pre-trained models, while also achieving superior recognition performance compared with other state-of-the-art methods.
    
[^34]: 你看到的就是你读到的? 改进文本-图像对齐评估方法

    What You See is What You Read? Improving Text-Image Alignment Evaluation. (arXiv:2305.10400v1 [cs.CL])

    [http://arxiv.org/abs/2305.10400](http://arxiv.org/abs/2305.10400)

    本研究介绍了SeeTRUE评估集和两种自动文本-图像对齐方法，这些方法在各种对齐任务中均取得了显着改进，在复杂组合或非自然图像的挑战性案例中表现出色。

    

    自动确定文本和相应的图像是否语义上对齐是视觉语言模型面临的一项重要挑战，应用于生成文本到图像和图像到文本任务。在本研究中，我们研究了自动文本-图像对齐评估方法。我们首先介绍了SeeTRUE：一个全面的评估集，涵盖了从文本到图像和图像到文本生成任务的多个数据集，并具有人类的判断，判断给定的文本-图像对是否语义上对齐。然后，我们描述了两种自动确定对齐的方法：第一种是基于问题生成和视觉问题回答模型的管道，第二种是通过微调多模态预训练模型的端到端分类方法。这两种方法在各种文本-图像对齐任务中均超越了先前的方法，在涉及复杂组合或非自然图像的挑战性案例中有显着改进。最后，我们证明即使最先进的模型在这个任务上还有很大的改进空间，这激励了未来在这个领域的研究。

    Automatically determining whether a text and a corresponding image are semantically aligned is a significant challenge for vision-language models, with applications in generative text-to-image and image-to-text tasks. In this work, we study methods for automatic text-image alignment evaluation. We first introduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasets from both text-to-image and image-to-text generation tasks, with human judgements for whether a given text-image pair is semantically aligned. We then describe two automatic methods to determine alignment: the first involving a pipeline based on question generation and visual question answering models, and the second employing an end-to-end classification approach by finetuning multimodal pretrained models. Both methods surpass prior approaches in various text-image alignment tasks, with significant improvements in challenging cases that involve complex composition or unnatural images. Finally, we demonstrate 
    
[^35]: Dr. LLaMA：通过生成式数据增强改善特定领域QA中的小语言模型

    Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation. (arXiv:2305.07804v1 [cs.CL])

    [http://arxiv.org/abs/2305.07804](http://arxiv.org/abs/2305.07804)

    本论文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，以改善小语言模型的性能，特别是在医学问答任务中。这种方法在微调后使模型性能提高，并提出了在特定领域问答任务中使用LLM所面临的挑战和潜在的研究方向。

    

    大型语言模型在自然语言处理方面取得了重大进展，但随着其规模的增长，也面临着计算开销和效率的挑战，特别是在特定领域的任务中。另一方面，小型语言模型由于容量和训练数据的限制，在这些任务中往往表现不佳。本文介绍了一种名为Dr. LLaMA的方法，通过使用大型语言模型进行生成式数据增强，聚焦医学问答任务和PubMedQA数据集，以改善小语言模型的性能。我们的发现表明，LLM有效地细化和扩展现有的问题-答案对，在微调后，使得小型模型在特定领域QA数据集上性能提高。本研究强调了在特定领域问答任务中使用LLM面临的挑战，并提出了潜在的研究方向，最终旨在为专业应用创建更高效和能力更强的模型。

    Large Language Models (LLMs) have made significant strides in natural language processing but face challenges in terms of computational expense and inefficiency as they grow in size, especially in domain-specific tasks. Small Language Models (SLMs), on the other hand, often struggle in these tasks due to limited capacity and training data. In this paper, we introduce Dr. LLaMA, a method for improving SLMs through generative data augmentation using LLMs, focusing on medical question-answering tasks and the PubMedQA dataset. Our findings indicate that LLMs effectively refine and diversify existing question-answer pairs, resulting in improved performance of a much smaller model on domain-specific QA datasets after fine-tuning. This study highlights the challenges of using LLMs for domain-specific question answering and suggests potential research directions to address these limitations, ultimately aiming to create more efficient and capable models for specialized applications. We have als
    
[^36]: 基于摄动的质量估计：一种透明、无监督的词级质量估计方法，适用于黑盒机器翻译

    Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation. (arXiv:2305.07457v1 [cs.CL])

    [http://arxiv.org/abs/2305.07457](http://arxiv.org/abs/2305.07457)

    本文介绍了一种透明、无监督的词级质量估计方法，它可以通过分析扰动的输入源句子上机器翻译系统输出来工作，并可以评估任何类型的黑盒机器翻译系统。使用该方法作为反馈信号，可以在无监督的领域自适应中改进机器翻译系统的质量。

    

    质量估计（QE）是预测机器翻译（MT）系统输出质量的任务，不使用任何黄金标准翻译参考。目前的QE模型是监督的：它们需要对一些数据集上某些MT系统输出进行人类标注质量来进行培训，使它们与域相关和MT系统相关。有研究对无监督的QE进行了研究，需要玻璃盒访问MT系统，或者使用并行MT数据来生成合成错误以训练QE模型。本文介绍了一种基于摄动的QE方法-一种词级质量估计方法，它可以通过分析扰动的输入源句子上MT系统输出来工作。我们的方法是无监督的、可解释的，并可以评估任何类型的黑盒MT系统，包括目前占主导地位的具有不透明内部过程的大型语言模型（LLMs）。对于没有标记QE数据的语言方向，我们的方法表现相似或更好的零-shot监督系统。我们还展示了如何使用基于摄动的QE作为反馈信号，在无监督的领域自适应中改进MT系统的质量。

    Quality Estimation (QE) is the task of predicting the quality of Machine Translation (MT) system output, without using any gold-standard translation references. State-of-the-art QE models are supervised: they require human-labeled quality of some MT system output on some datasets for training, making them domain-dependent and MT-system-dependent. There has been research on unsupervised QE, which requires glass-box access to the MT systems, or parallel MT data to generate synthetic errors for training QE models. In this paper, we present Perturbation-based QE - a word-level Quality Estimation approach that works simply by analyzing MT system output on perturbed input source sentences. Our approach is unsupervised, explainable, and can evaluate any type of blackbox MT systems, including the currently prominent large language models (LLMs) with opaque internal processes. For language directions with no labeled QE data, our approach has similar or better performance than the zero-shot supe
    

