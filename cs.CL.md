# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Uncertainty in Natural Language Generation: From Theory to Applications.](http://arxiv.org/abs/2307.15703) | 本文介绍了自然语言生成中不确定性的理论、应用和分类，提出了一种更详细和真实的分类法。 |
| [^2] | [Scaling Data Generation in Vision-and-Language Navigation.](http://arxiv.org/abs/2307.15644) | 这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。 |
| [^3] | [Robust Distortion-free Watermarks for Language Models.](http://arxiv.org/abs/2307.15593) | 该论文提出了一种在语言模型中添加鲁棒无畸变水印的方法，通过映射随机数序列到语言模型的样本，可以实现在不改变文本分布的前提下对水印文本进行检测，并且在多种改写攻击下依然保持较高的鲁棒性，实验证明在40-50%的随机扰动下仍可可靠地检测到水印文本。 |
| [^4] | [When to generate hedges in peer-tutoring interactions.](http://arxiv.org/abs/2307.15582) | 本研究探索了将机器学习技术应用于预测同行辅导中避免冒犯语出现的情况。研究结果显示，捕捉先前转换的语义信息的嵌入层显著提高了模型的性能。通过使用Shapley值进行特征解释，研究发现目光注视对于避免冒犯语的预测有重要影响。 |
| [^5] | [All-for-One and One-For-All: Deep learning-based feature fusion for Synthetic Speech Detection.](http://arxiv.org/abs/2307.15555) | 本文提出了一种基于深度学习的特征融合模型，用于合成语音检测任务。通过融合三个不同的特征集，该模型相比现有解决方案取得了更好的性能，并在不同场景和数据集上展示了其鲁棒性和泛化能力。 |
| [^6] | ['What are you referring to?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges.](http://arxiv.org/abs/2307.15554) | 本研究评估了多模态对话模型处理澄清交流的能力，并发现基于语言的模型在处理与对话历史相关的澄清交流时表现出色，而多模态模型则能利用额外的学习目标获取分解的对象表示。 |
| [^7] | [Oracle Computability and Turing Reducibility in the Calculus of Inductive Constructions.](http://arxiv.org/abs/2307.15543) | 本研究在Coq证明助手中的归纳构造演算（CIC）中，发展了Oracle计算可行性和图灵可归约的合成概念，并通过机器验证的方式进行了验证。这为处理高阶oracle计算提供了一种有用的策略。 |
| [^8] | [The Road to Quality is Paved with Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling.](http://arxiv.org/abs/2307.15508) | 该论文通过提出一种详细的评估方法和度量标准，对增量序列标注中的修订政策进行了研究和分析，并应用于Transformer编码器的行为分析，为未来的修订政策提供了参考。 |
| [^9] | [Exploring Format Consistency for Instruction Tuning.](http://arxiv.org/abs/2307.15504) | 本研究探究了指令调整的格式一致性，并提出了统一指令调整（UIT）框架，通过自动格式转换来提高泛化性能。该研究强调了格式一致性的重要性。 |
| [^10] | [ETHER: Aligning Emergent Communication for Hindsight Experience Replay.](http://arxiv.org/abs/2307.15494) | 本文提出了ETHER，通过对齐紧急沟通来解决回顾性经验重演中的问题，克服了先前架构依赖预设函数的限制，并提高了数据效率和性能。 |
| [^11] | [The timing bottleneck: Why timing and overlap are mission-critical for conversational user interfaces, speech recognition and dialogue systems.](http://arxiv.org/abs/2307.15493) | 本论文研究了对话系统中的时序和重叠问题对语音识别和意图识别的影响，评估了5个主要商业ASR系统的对话和多语言支持性能，并发现词错误率和重叠仍然是关键挑战。 |
| [^12] | [Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding.](http://arxiv.org/abs/2307.15484) | 本文提出了两种语音合成方法来解决自回归和非自回归模型中的问题，并在语义编码方面进行了比较研究。 |
| [^13] | [Cross-Modal Concept Learning and Inference for Vision-Language Models.](http://arxiv.org/abs/2307.15460) | 本论文提出了一种跨模态概念学习和推理（CCLI）方法，通过利用CLIP的文本-图像相关性能力，从图像中自动学习一组独特的视觉概念，并利用这些概念构建了图像的判别式表示。 |
| [^14] | [Trie-NLG: Trie Context Augmentation to Improve Personalized Query Auto-Completion for Short and Unseen Prefixes.](http://arxiv.org/abs/2307.15455) | 提出了一种基于Trie上下文增强的个性化查询自动补全算法，可以解决短前缀和未见前缀的问题，并有效利用历史查询的流行度信息。 |
| [^15] | [From Probabilistic Programming to Complexity-based Programming.](http://arxiv.org/abs/2307.15453) | CompLog是一种基于复杂性的计算框架，通过计算Kolmogorov复杂性替代概率推理，实现计算某种情况意外性的度量，并通过规范的世界和心智模型的描述生成相关描述，并提供对析取和否定的替代方法。 |
| [^16] | [CFN-ESA: A Cross-Modal Fusion Network with Emotion-Shift Awareness for Dialogue Emotion Recognition.](http://arxiv.org/abs/2307.15432) | 本文提出了一种具有情绪转移感知的跨模态融合网络（CFN-ESA）用于对话情绪识别，通过将文本模态作为主要情感信息的来源，视觉和声学模态作为次要信息的来源，并引入情绪转移模块来解决情绪转移场景下情感识别的问题。 |
| [^17] | [A Critical Review of Large Language Models: Sensitivity, Bias, and the Path Toward Specialized AI.](http://arxiv.org/abs/2307.15425) | 本文研究了专业编译语言模型和通用模型在检测可持续发展目标方面的比效率，关注了大型语言模型存在的偏见和敏感性挑战。研究强调了专业培训对于精确无偏的分析的必要性，并通过对一个公司描述数据集的案例研究对比了GPT-3.5和专业SDG检测模型的差异。研究结果强调了在模型选择时需要考虑任务要求、成本、复杂性和透明度。尽管大型语言模型的多功能性，但作者建议在需要精确性和准确性的任务中使用专业模型。 |
| [^18] | [Improving Social Media Popularity Prediction with Multiple Post Dependencies.](http://arxiv.org/abs/2307.15413) | 该论文提出了一种新型预测框架DSN，通过同时利用帖子内部和帖子间的依赖关系来改进社交媒体受欢迎程度的预测准确性。 |
| [^19] | [Investigating the Learning Behaviour of In-context Learning: A Comparison with Supervised Learning.](http://arxiv.org/abs/2307.15411) | 本研究通过对比监督学习和上下文学习，发现大型语言模型在学习行为上受到金标签的显著影响，但对于上下文学习来说，标签不平衡影响较小。实证结果显示上下文学习对标签扰动的敏感性较低。 |
| [^20] | [Towards a Fully Unsupervised Framework for Intent Induction in Customer Support Dialogues.](http://arxiv.org/abs/2307.15410) | 本文提出了一个完全无监督的对话意图诱导框架，通过预处理对话语料库和研究最常见的序列来提取意图的对话流程，适用于各行业的实际客户支持应用。 |
| [^21] | [Multilingual Tourist Assistance using ChatGPT: Comparing Capabilities in Hindi, Telugu, and Kannada.](http://arxiv.org/abs/2307.15376) | 本研究比较了ChatGPT在翻译英语成印地语、泰卢固语和卡纳达语方面的效果，发现印地语翻译具有较高的准确性和流畅性，而泰卢固语翻译表现不佳。 |
| [^22] | [Med-HALT: Medical Domain Hallucination Test for Large Language Models.](http://arxiv.org/abs/2307.15343) | Med-HALT是一个新的基准和数据集，用于评估和减少大规模语言模型中医疗领域的幻觉问题。这个数据集包括多种创新的测试模式，并评估了领先的LLMs在性能上的差异。 |
| [^23] | [Teach Me How to Improve My Argumentation Skills: A Survey on Feedback in Argumentation.](http://arxiv.org/abs/2307.15341) | 这项调查的目标是探讨当前论证计算模型提供的反馈维度，以提高学习者的批判性思维能力。 |
| [^24] | [Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding.](http://arxiv.org/abs/2307.15337) | 本研究提出了一种名为“思维的骨架”的方法，可以通过并行解码来减少大型语言模型的生成延迟。这种方法不仅显著提高了速度，还可以潜在地提高答案质量。 |
| [^25] | [BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering.](http://arxiv.org/abs/2307.15335) | BARTPhoBEiT是一个基于Transformer的越南模型，针对越南视觉问答任务进行了改进。实验证明，该模型在准确度、精确度、召回率、F1-score、WUPS 0.0和WUPS 0.9等六个指标上优于强基线模型，提升了最新技术水平。 |
| [^26] | [Tutorials on Stance Detection using Pre-trained Language Models: Fine-tuning BERT and Prompting Large Language Models.](http://arxiv.org/abs/2307.15331) | 这篇论文提供了两个教程，介绍了使用BERT微调和提示大型语言模型进行Twitter立场识别的方法。教程通过实例代码和可视化分析，展示了少样本ChatGPT和FLAN-T5的优势，同时提供了对BERT模型的训练和评估的指导。这些教程使学习者能够掌握运用先进方法进行立场识别的实践经验。 |
| [^27] | [TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety.](http://arxiv.org/abs/2307.15311) | TrafficSafetyGPT是一种通过将预训练的大型语言模型进行领域特定的监督微调，以在交通安全领域任务中提供准确响应的模型。 |
| [^28] | [WC-SBERT: Zero-Shot Text Classification via SBERT with Self-Training for Wikipedia Categories.](http://arxiv.org/abs/2307.15293) | WC-SBERT提出了一种利用SBERT和自训练解决零样本文本分类问题的方法，通过使用维基百科作为训练集和建立类别对之间的正相关关系，实现快速且准确的分类。 |
| [^29] | [ChatHome: Development and Evaluation of a Domain-Specific Language Model for Home Renovation.](http://arxiv.org/abs/2307.15290) | 本论文介绍了ChatHome，这是一个专注于家居装修领域的特定领域语言模型（DSLM）的开发和评估。通过领域自适应预训练和指导调整的方法，ChatHome可以生成与家居装修相关的高保真、精确的输出。 |
| [^30] | [Multilingual Lexical Simplification via Paraphrase Generation.](http://arxiv.org/abs/2307.15286) | 本文提出了一种基于释义生成的多语言词汇简化方法，通过释义生成多样性的词汇替代词并保留句子的意义，实验结果显示该方法在英语上显著优于其他方法。 |
| [^31] | [Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback.](http://arxiv.org/abs/2307.15217) | 本文调查了从人类反馈中进行强化学习的开放问题和基本限制，并提出了加强社会监督的审计和披露标准。 |
| [^32] | [PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization.](http://arxiv.org/abs/2307.15199) | 提出了PromptStyler，通过使用提示合成样式特征，解决了无源域泛化的问题。该方法通过学习样式词向量生成多样的样式，并通过强制样式内容特征与内容特征靠近来保证样式不会扭曲内容信息。在多个数据集上取得了最先进的结果。 |
| [^33] | [f-Divergence Minimization for Sequence-Level Knowledge Distillation.](http://arxiv.org/abs/2307.15190) | 本文提出了一个f-DISTILL框架，将序列级知识蒸馏建模为最小化广义f-分歧函数。通过在词级上计算损失，能够更好地压缩语言模型并使学生模型从教师模型中学习。提出的方法在多个数据集上表现出色。 |
| [^34] | [RCT Rejection Sampling for Causal Estimation Evaluation.](http://arxiv.org/abs/2307.15176) | 该论文提出了一种名为RCT拒绝抽样的新抽样算法，用于因果估计评估。该方法通过子抽样随机控制试验(RCT)创建混淆的观测数据集，并使用RCT的平均因果效应作为基准真实值，以进行有效比较。 |
| [^35] | [VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Leveraging BERT and Stacked Embeddings.](http://arxiv.org/abs/2307.15164) | 本研究中，我们开发了一种利用深度学习模型和词嵌入表示的策略来捕捉复杂对话中情绪表达的微妙差异。我们的实验结果在情绪检测任务中取得了良好的效果，并在小样本和不平衡的混合目标情绪数据集中得到了验证。 |
| [^36] | [Cascaded Cross-Modal Transformer for Request and Complaint Detection.](http://arxiv.org/abs/2307.15097) | 本文提出了一种级联跨模态Transformer模型，结合语音和文本转录，用于检测电话对话中的客户请求和投诉。在ACM Multimedia 2023计算语言学挑战赛的请求子挑战中，我们的系统在投诉和请求类别中达到了65.41%和85.87%的不平衡平均召回率。 |
| [^37] | [Detecting the Presence of COVID-19 Vaccination Hesitancy from South African Twitter Data Using Machine Learning.](http://arxiv.org/abs/2307.15072) | 本研究通过对南非疫苗犹豫相关推文进行情感分析和机器学习模型训练，检测出COVID-19疫苗犹豫情绪的存在并对用户生成内容进行分类。这对于应对疫苗犹豫对公共卫生工作的影响具有重要意义。 |
| [^38] | [Writer adaptation for offline text recognition: An exploration of neural network-based methods.](http://arxiv.org/abs/2307.15071) | 本研究探索了如何通过使用少量示例来实现适应新作家的手写文本识别模型。通过使用ResNet骨干网络和LSTM或Transformer序列解码器作为基础模型，并结合模型不可知元学习和作家代码的方法，实现了作家适应性。 |
| [^39] | [Matching Patients to Clinical Trials with Large Language Models.](http://arxiv.org/abs/2307.15051) | 本研究调查了使用大型语言模型（LLMs）来帮助患者和转诊医生识别合适的临床试验的潜力，并引入了TrialGPT架构，该架构能够准确预测合格性并提供解释，实验证明其有效性。 |
| [^40] | [Turkish Native Language Identification.](http://arxiv.org/abs/2307.14850) | 这项研究首次将母语识别应用于土耳其语,通过分析作者不同语言的写作来预测作者的母语。研究使用了土耳其学习者语料库和三个句法特征来展示其有效性。 |
| [^41] | [ARB: Advanced Reasoning Benchmark for Large Language Models.](http://arxiv.org/abs/2307.13692) | ARB是一个新型基准，包含了数学、物理、生物、化学和法律领域的高级推理问题。目前的语言模型在这些任务上得分远低于50%，为了提高评估能力，我们引入了基于评分标准的评估方法。 |
| [^42] | [Overview of Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems at DSTC 11 Track 4.](http://arxiv.org/abs/2306.12794) | 本文综述了DSTC 11 Track 4中针对开放域对话系统进行鲁棒性和多语言自动评估的挑战，介绍了提供给参与者的数据集和基线，并总结了表现最佳的系统及其方法。 |
| [^43] | [Boosting Local Spectro-Temporal Features for Speech Analysis.](http://arxiv.org/abs/2305.10270) | 该论文介绍了在语音识别中电话分类的问题，并探索了几组可以用于电话分类的本地谱时特征，提出了使用Haar特征和SVM分类的梯度直方图进行电话分类，并给出了一些初步结果。 |
| [^44] | [SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition.](http://arxiv.org/abs/2305.04076) | 本文提出了一种处理Distantly-Supervised Named Entity Recognition中错误和不完整标注噪声的分离策略，使用不同的模型构建来应对两种类型的噪声。 |
| [^45] | [VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping.](http://arxiv.org/abs/2304.07810) | VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。 |
| [^46] | [The Open-domain Paradox for Chatbots: Common Ground as the Basis for Human-like Dialogue.](http://arxiv.org/abs/2303.11708) | 最近研究表明，开放领域聊天机器人通过提供最少信息来实现最大化的“开放性”，在实践中导致了“开放领域悖论”——-要求用户“闲聊任何事情”会导致非常狭窄的对话形式。此研究进一步解释了共同基础理论与实现类似人类对话的关系，并提出了实现共同基础的路径。 |
| [^47] | [Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework.](http://arxiv.org/abs/2302.12247) | 通过引入信息分解框架，我们提供了一种量化和建模多模态交互的方法，通过PID统计量来度量输入模态与输出任务之间的冗余度、独特性和协同性，并引入了两个新的PID统计估计器。 |
| [^48] | [Towards Answering Climate Questionnaires from Unstructured Climate Reports.](http://arxiv.org/abs/2301.04253) | 本研究提出了一种从非结构化的气候报告中回答气候问卷的方法。研究引入两个新的大规模气候问卷数据集，并使用现有结构训练自监督模型，通过实验和人类试验验证了模型的有效性。同时，还引入了一个气候文本分类数据集的基准，以促进气候领域的自然语言处理研究。 |
| [^49] | [Rationale-Guided Few-Shot Classification to Detect Abusive Language.](http://arxiv.org/abs/2211.17046) | 本文提出了一种有理指导下的少样本分类（RGFS）方法，用于检测辱骂语言。通过多任务学习框架，该方法可以共同学习有理、目标和标签，并在性能上实现了显著的6%宏F1改进。 |
| [^50] | [Towards Multimodal Prediction of Spontaneous Humour: A Novel Dataset and First Results.](http://arxiv.org/abs/2209.14272) | 本研究提出了Passau-SFCH数据集，包含了11小时的录音，用于自发幽默的预测。通过多模态的分析和特征融合，实现了对幽默以及幽默情感的自动识别。 |
| [^51] | [Adaptive Meta-learner via Gradient Similarity for Few-shot Text Classification.](http://arxiv.org/abs/2209.04702) | 提出了一种基于梯度相似度的自适应元学习器方法（AMGS），用于改善少样本文本分类模型的泛化能力。该方法通过自监督辅助任务获得潜在语义表示，并使用梯度相似度约束基学习器的梯度，从而解决了过拟合问题。 |
| [^52] | [Automatic Lexical Simplification for Turkish.](http://arxiv.org/abs/2201.05878) | 本研究介绍了首个针对土耳其语的自动词汇简化系统，利用预训练表示模型BERT和形态特征生成正确的语法和语义简化表达。 |
| [^53] | [Learning From How Humans Correct.](http://arxiv.org/abs/2102.00225) | 本研究提出了一种从人类矫正中学习的方法。通过标注数据中的噪声数据，收集纠错信息，并将其注入至深度学习模型中，成功将文本分类准确度提升了1.7个百分点。 |

# 详细

[^1]: 自然语言生成中的不确定性：从理论到应用

    Uncertainty in Natural Language Generation: From Theory to Applications. (arXiv:2307.15703v1 [cs.CL])

    [http://arxiv.org/abs/2307.15703](http://arxiv.org/abs/2307.15703)

    本文介绍了自然语言生成中不确定性的理论、应用和分类，提出了一种更详细和真实的分类法。

    

    最近强大的语言模型的进展使得自然语言生成（NLG）作为一种重要技术崭露头角，它不仅可以执行传统任务如摘要或翻译，也可以作为一种自然语言接口应用于各种应用程序。因此，NLG系统的可靠性和可信度至关重要，例如在可能出错时指示，并支持多种观点、背景和写作风格 - 反映多元化人类亚群体。本文认为，对不确定性的原则性处理能够帮助创建与这些目标更好地对齐的系统和评估协议。我们首先介绍表示不确定性所需的基本理论、框架和词汇。然后从语言学的角度描述NLG中的主要不确定性源，并提出一个比流行的随机性/认识性二分法更详细和真实的二维分类法。

    Recent advances of powerful Language Models have allowed Natural Language Generation (NLG) to emerge as an important technology that can not only perform traditional tasks like summarisation or translation, but also serve as a natural language interface to a variety of applications. As such, it is crucial that NLG systems are trustworthy and reliable, for example by indicating when they are likely to be wrong; and supporting multiple views, backgrounds and writing styles -- reflecting diverse human sub-populations. In this paper, we argue that a principled treatment of uncertainty can assist in creating systems and evaluation protocols better aligned with these goals. We first present the fundamental theory, frameworks and vocabulary required to represent uncertainty. We then characterise the main sources of uncertainty in NLG from a linguistic perspective, and propose a two-dimensional taxonomy that is more informative and faithful than the popular aleatoric/epistemic dichotomy. Final
    
[^2]: 视觉语言导航中的数据生成规模化

    Scaling Data Generation in Vision-and-Language Navigation. (arXiv:2307.15644v1 [cs.CV])

    [http://arxiv.org/abs/2307.15644](http://arxiv.org/abs/2307.15644)

    这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。

    

    最近在语言引导的视觉导航研究中，对于遍历环境的多样性和训练可泛化代理的监督数量有了明显需求。为了解决现有视觉语言导航数据集中普遍存在的数据稀缺问题，我们提出了一种有效的范式，用于生成用于学习的大规模数据。我们应用了HM3D和Gibson数据集中的1200多个逼真的环境，并利用网络上的资源合成了490万个指令轨迹对。重要的是，我们调查了范式中每个组成部分对代理性能的影响，并研究了如何恰当地应用扩增数据来预训练和微调代理。得益于我们的大规模数据集，通过简单的模仿学习，现有代理的性能可以大幅提升（相对于之前的最佳结果绝对值增加了11%），在R2R测试集中单次运行成功率显著提升至80%。

    Recent research in language-guided visual navigation has demonstrated a significant demand for the diversity of traversable environments and the quantity of supervision for training generalizable agents. To tackle the common data scarcity issue in existing vision-and-language navigation datasets, we propose an effective paradigm for generating large-scale data for learning, which applies 1200+ photo-realistic environments from HM3D and Gibson datasets and synthesizes 4.9 million instruction trajectory pairs using fully-accessible resources on the web. Importantly, we investigate the influence of each component in this paradigm on the agent's performance and study how to adequately apply the augmented data to pre-train and fine-tune an agent. Thanks to our large-scale dataset, the performance of an existing agent can be pushed up (+11% absolute with regard to previous SoTA) to a significantly new best of 80% single-run success rate on the R2R test split by simple imitation learning. The
    
[^3]: 语言模型的鲁棒无畸变水印方法

    Robust Distortion-free Watermarks for Language Models. (arXiv:2307.15593v1 [cs.LG])

    [http://arxiv.org/abs/2307.15593](http://arxiv.org/abs/2307.15593)

    该论文提出了一种在语言模型中添加鲁棒无畸变水印的方法，通过映射随机数序列到语言模型的样本，可以实现在不改变文本分布的前提下对水印文本进行检测，并且在多种改写攻击下依然保持较高的鲁棒性，实验证明在40-50%的随机扰动下仍可可靠地检测到水印文本。

    

    我们提出了一种在自回归语言模型中添加水印的方法，并且这些水印对扰动具有鲁棒性，而不会改变文本的分布，同时保证生成预算在一定范围内。我们用随机水印密钥计算的随机数序列映射到语言模型的样本来生成带水印的文本。要检测水印文本，只要知道密钥的任何一方都可以将文本与随机数序列对齐。我们使用两种采样方案来实例化水印方法：反变换采样和指数最小采样。我们将这些水印应用于三个语言模型——OPT-1.3B、LLaMA-7B和Alpaca-7B，以实验证明它们的统计功效和对各种改写攻击的鲁棒性。值得注意的是，对于OPT-1.3B和LLaMA-7B模型，即使在随机扰动了40-50%的词元后，我们仍然可以可靠地检测到带水印的文本（$p \leq 0.01$），只需要35个词元。

    We propose a methodology for planting watermarks in text from an autoregressive language model that are robust to perturbations without changing the distribution over text up to a certain maximum generation budget. We generate watermarked text by mapping a sequence of random numbers -- which we compute using a randomized watermark key -- to a sample from the language model. To detect watermarked text, any party who knows the key can align the text to the random number sequence. We instantiate our watermark methodology with two sampling schemes: inverse transform sampling and exponential minimum sampling. We apply these watermarks to three language models -- OPT-1.3B, LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B and LLaMA-7B models, we find we can reliably detect watermarked text ($p \leq 0.01$) from $35$ tokens even after corrupting between $40$-$50$\% of the tokens via random
    
[^4]: 在同行辅导中何时产生避免冒犯语

    When to generate hedges in peer-tutoring interactions. (arXiv:2307.15582v1 [cs.CL])

    [http://arxiv.org/abs/2307.15582](http://arxiv.org/abs/2307.15582)

    本研究探索了将机器学习技术应用于预测同行辅导中避免冒犯语出现的情况。研究结果显示，捕捉先前转换的语义信息的嵌入层显著提高了模型的性能。通过使用Shapley值进行特征解释，研究发现目光注视对于避免冒犯语的预测有重要影响。

    

    本文探讨了将机器学习技术应用于预测同行辅导中避免冒犯语出现的情况。研究使用了一个自然面对面的数据集，对自然语言的转换、对话策略、辅导策略和非言语行为进行了注释。这些元素被处理成先前转换的向量表示，作为输入给多个机器学习模型。结果表明，捕捉先前转换的语义信息的嵌入层显著提高了模型的性能。此外，该研究通过使用Shapley值进行特征解释，提供了有关各种特征（如人际关系和非言语行为）在预测避免冒犯语方面的重要性的深入洞察。我们发现导师和学员的目光注视对于避免冒犯语的预测有重要影响。我们通过后续的切割研究进一步验证了这一观察结果。

    This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviours. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models. Results show that embedding layers, that capture the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviours, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.
    
[^5]: 众志成城：基于深度学习的特征融合用于合成语音检测

    All-for-One and One-For-All: Deep learning-based feature fusion for Synthetic Speech Detection. (arXiv:2307.15555v1 [cs.SD])

    [http://arxiv.org/abs/2307.15555](http://arxiv.org/abs/2307.15555)

    本文提出了一种基于深度学习的特征融合模型，用于合成语音检测任务。通过融合三个不同的特征集，该模型相比现有解决方案取得了更好的性能，并在不同场景和数据集上展示了其鲁棒性和泛化能力。

    

    最近深度学习和计算机视觉的进步使得多媒体内容的合成和伪造变得更加易于实现，可能引发来自恶意用户的威胁和危险。在音频领域，我们目睹了语音深伪造生成技术的增长，这促使研究合成语音检测算法以应对可能的恶意使用，例如欺诈或身份盗窃。本文考虑了文献中提出的三种不同的特征集，用于合成语音检测任务，并提出了一种融合它们的模型，相比于现有解决方案，其整体性能更好。通过对不同场景和数据集进行测试，证明了该系统对抗反取证攻击的鲁棒性以及其泛化能力。

    Recent advances in deep learning and computer vision have made the synthesis and counterfeiting of multimedia content more accessible than ever, leading to possible threats and dangers from malicious users. In the audio field, we are witnessing the growth of speech deepfake generation techniques, which solicit the development of synthetic speech detection algorithms to counter possible mischievous uses such as frauds or identity thefts. In this paper, we consider three different feature sets proposed in the literature for the synthetic speech detection task and present a model that fuses them, achieving overall better performances with respect to the state-of-the-art solutions. The system was tested on different scenarios and datasets to prove its robustness to anti-forensic attacks and its generalization capabilities.
    
[^6]: “你在指什么？”评估多模态对话模型处理澄清交流的能力

    'What are you referring to?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges. (arXiv:2307.15554v1 [cs.CL])

    [http://arxiv.org/abs/2307.15554](http://arxiv.org/abs/2307.15554)

    本研究评估了多模态对话模型处理澄清交流的能力，并发现基于语言的模型在处理与对话历史相关的澄清交流时表现出色，而多模态模型则能利用额外的学习目标获取分解的对象表示。

    

    当一个指称表达无法确定唯一地确定发言者的意图时，对话中出现指称歧义。通常情况下，被寻址人会立即发现这种歧义，并与发言者一起通过元沟通澄清交流（CE）来修复。CE包括澄清请求（CR）和回应。本文认为，生成和回应CR对多模态且以视觉为基础的对话模型的架构和目标函数施加了特定的约束。我们使用SIMMC 2.0数据集评估了不同最先进模型架构处理CE的能力，并使用一个指标来探测模型中由CE引起的上下文更新。我们发现，基于语言的模型能够编码简单的多模态语义信息并处理一些CE，特别是与对话历史相关的CE。而多模态模型则可以使用额外的学习目标来获取分解的对象表示。

    Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representa
    
[^7]: Oracle计算可行性和图灵可归约在归纳构造演算中的研究

    Oracle Computability and Turing Reducibility in the Calculus of Inductive Constructions. (arXiv:2307.15543v1 [cs.LO])

    [http://arxiv.org/abs/2307.15543](http://arxiv.org/abs/2307.15543)

    本研究在Coq证明助手中的归纳构造演算（CIC）中，发展了Oracle计算可行性和图灵可归约的合成概念，并通过机器验证的方式进行了验证。这为处理高阶oracle计算提供了一种有用的策略。

    

    我们在Coq证明助手中的归纳构造演算（CIC）中，发展了Oracle计算可行性和图灵可归约的合成概念。在合成方法中，我们采用基于元级函数而不是基于对象级计算模型的oracle计算定义，依赖于构造系统中的可计算性。这种方法非常适合于机器验证的证明，我们在Coq中进行了验证。在找到合适的高阶oracle计算的合成表示时存在一些紧张关系。一方面，它必须足够信息丰富以证明中心结果，确保所有概念都被忠实地捕捉到。另一方面，它必须受限以获取合成可计算性的公理的好处，这些公理通常涉及一阶对象。借鉴Andrey Bauer基于一阶对象的定义，我们得到启发...

    We develop synthetic notions of oracle computability and Turing reducibility in the Calculus of Inductive Constructions (CIC), the constructive type theory underlying the Coq proof assistant. As usual in synthetic approaches, we employ a definition of oracle computations based on meta-level functions rather than object-level models of computation, relying on the fact that in constructive systems such as CIC all definable functions are computable by construction. Such an approach lends itself well to machine-checked proofs, which we carry out in Coq.  There is a tension in finding a good synthetic rendering of the higher-order notion of oracle computability. On the one hand, it has to be informative enough to prove central results, ensuring that all notions are faithfully captured. On the other hand, it has to be restricted enough to benefit from axioms for synthetic computability, which usually concern first-order objects. Drawing inspiration from a definition by Andrej Bauer based on 
    
[^8]: 质量之路是由良好修订铺开的：增量序列标注中修订政策的详细评估方法

    The Road to Quality is Paved with Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling. (arXiv:2307.15508v1 [cs.CL])

    [http://arxiv.org/abs/2307.15508](http://arxiv.org/abs/2307.15508)

    该论文通过提出一种详细的评估方法和度量标准，对增量序列标注中的修订政策进行了研究和分析，并应用于Transformer编码器的行为分析，为未来的修订政策提供了参考。

    

    增量对话模型组件基于输入生成输出前缀的序列。由于局部歧义或错误的假设，可能会发生错误，因此修订过去的输出能力成为可管理的可取性质。在这项工作中，我们对增量序列标注中的编辑和修订进行形式化和特征化，并提出了评估修订政策的指标。然后，我们应用我们的方法来分析三个基于Transformer的编码器在各种任务中的增量行为，为更好的修订政策铺平道路。

    Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.
    
[^9]: 探索指令调整的格式一致性

    Exploring Format Consistency for Instruction Tuning. (arXiv:2307.15504v1 [cs.CL])

    [http://arxiv.org/abs/2307.15504](http://arxiv.org/abs/2307.15504)

    本研究探究了指令调整的格式一致性，并提出了统一指令调整（UIT）框架，通过自动格式转换来提高泛化性能。该研究强调了格式一致性的重要性。

    

    指令调整已经成为一种提升大型语言模型遵循人类指令能力的有前途的方法。研究表明，增加训练数据中指令的多样性和数量可以持续提升泛化性能，从而促进了最近的一项努力，即收集各种指令并将现有的指令调整数据集整合到更大的集合中。然而，不同用户有其独特的表达指令的方式，不同数据集之间通常存在指令风格和格式的变化，即格式不一致性。在这项工作中，我们研究了格式不一致性如何影响指令调整的性能。我们提出了一个名为“统一指令调整”（UIT）的框架，通过调用OpenAI的API实现在不同的指令调整数据集之间的自动格式转换。我们展示了UIT成功提高了在未见指令上的泛化性能，并强调了格式一致性的重要性。

    Instruction tuning has emerged as a promising approach to enhancing large language models in following human instructions. It is shown that increasing the diversity and number of instructions in the training data can consistently enhance generalization performance, which facilitates a recent endeavor to collect various instructions and integrate existing instruction tuning datasets into larger collections. However, different users have their unique ways of expressing instructions, and there often exist variations across different datasets in the instruction styles and formats, i.e., format inconsistency. In this work, we study how format inconsistency may impact the performance of instruction tuning. We propose a framework called "Unified Instruction Tuning" (UIT), which calls OpenAI APIs for automatic format transfer among different instruction tuning datasets. We show that UIT successfully improves the generalization performance on unseen instructions, which highlights the importance
    
[^10]: ETHER: 对于回顾性经验重演的紧密沟通对齐

    ETHER: Aligning Emergent Communication for Hindsight Experience Replay. (arXiv:2307.15494v1 [cs.CL])

    [http://arxiv.org/abs/2307.15494](http://arxiv.org/abs/2307.15494)

    本文提出了ETHER，通过对齐紧急沟通来解决回顾性经验重演中的问题，克服了先前架构依赖预设函数的限制，并提高了数据效率和性能。

    

    自然语言指令的跟随对于实现人工智能代理和人类之间的合作至关重要。自然语言条件下的强化学习代理展示了自然语言的特性，如组合性，能够提供学习复杂策略的强归纳偏好。先前的架构如HIGhER结合了语言条件与回顾性经验重演（HER）来处理稀疏奖励环境。然而，与HER类似，HIGhER依赖于一个预设的函数来提供反馈信号，指示哪种语言描述在哪种状态下有效。这种依赖于预设函数的限制限制了其应用。此外，HIGhER只利用成功的强化学习轨迹中包含的语言信息，从而影响了其最终性能和数据效率。没有早期成功轨迹，HIGhER并不比其构建于之上的DQN更好。在本文中，我们提出了紧密文本回顾性经验。

    Natural language instruction following is paramount to enable collaboration between artificial agents and human beings. Natural language-conditioned reinforcement learning (RL) agents have shown how natural languages' properties, such as compositionality, can provide a strong inductive bias to learn complex policies. Previous architectures like HIGhER combine the benefit of language-conditioning with Hindsight Experience Replay (HER) to deal with sparse rewards environments. Yet, like HER, HIGhER relies on an oracle predicate function to provide a feedback signal highlighting which linguistic description is valid for which state. This reliance on an oracle limits its application. Additionally, HIGhER only leverages the linguistic information contained in successful RL trajectories, thus hurting its final performance and data-efficiency. Without early successful trajectories, HIGhER is no better than DQN upon which it is built. In this paper, we propose the Emergent Textual Hindsight Ex
    
[^11]: 时序瓶颈：为什么时序和重叠对话系统、语音识别和对话系统至关重要

    The timing bottleneck: Why timing and overlap are mission-critical for conversational user interfaces, speech recognition and dialogue systems. (arXiv:2307.15493v1 [cs.CL])

    [http://arxiv.org/abs/2307.15493](http://arxiv.org/abs/2307.15493)

    本论文研究了对话系统中的时序和重叠问题对语音识别和意图识别的影响，评估了5个主要商业ASR系统的对话和多语言支持性能，并发现词错误率和重叠仍然是关键挑战。

    

    语音识别系统是语音驱动的人机交互的关键中间件。尽管语音识别在无污染的单向音频上表现良好，但在开放式互动环境中的真实应用场景仍然存在许多挑战。我们认为时序对对话系统至关重要，并评估了5个主要商业ASR系统在对话和多语言支持方面的表现。我们发现6种语言的自然对话数据的词错误率仍然很高，并且重叠仍然是一个重要挑战（研究1）。这尤其影响对话词的识别（研究2），进而对后续的意图识别产生严重后果（研究3）。我们的研究结果有助于评估当前对话ASR的状态，为多维度错误分析和评估做出贡献，并确定最需要关注的现象以构建强大的交互式语音技术。

    Speech recognition systems are a key intermediary in voice-driven human-computer interaction. Although speech recognition works well for pristine monologic audio, real-life use cases in open-ended interactive settings still present many challenges. We argue that timing is mission-critical for dialogue systems, and evaluate 5 major commercial ASR systems for their conversational and multilingual support. We find that word error rates for natural conversational data in 6 languages remain abysmal, and that overlap remains a key challenge (study 1). This impacts especially the recognition of conversational words (study 2), and in turn has dire consequences for downstream intent recognition (study 3). Our findings help to evaluate the current state of conversational ASR, contribute towards multidimensional error analysis and evaluation, and identify phenomena that need most attention on the way to build robust interactive speech technologies.
    
[^12]: 用条件扩散模型和语言模型进行最小监督语音合成：基于语义编码的比较研究

    Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding. (arXiv:2307.15484v1 [cs.SD])

    [http://arxiv.org/abs/2307.15484](http://arxiv.org/abs/2307.15484)

    本文提出了两种语音合成方法来解决自回归和非自回归模型中的问题，并在语义编码方面进行了比较研究。

    

    近年来，对于能够采用最小监督训练方法的文本到语音(TTS)技术越来越受关注，该方法通过结合两种离散语音表示并使用两种序列到序列任务来解耦TTS。为了解决离散表示中的高维度和波形失真的挑战，我们提出了Diff-LM-Speech方法，该方法基于扩散模型将语义嵌入模型为基于mel频谱图，并引入基于变分自动编码器和韵律瓶颈的提示编码结构，以提高提示表示能力。自回归语言模型常常遇到缺失和重复单词的问题，而非自回归框架由于预测模型的存在导致表达平均问题。为了解决这些问题，我们提出了Tetra-Diff-Speech，该方法设计了一个时长扩散模型以实现多样化的韵律表达。我们期望语义编码的信息内容介于...

    Recently, there has been a growing interest in text-to-speech (TTS) methods that can be trained with minimal supervision by combining two types of discrete speech representations and using two sequence-to-sequence tasks to decouple TTS. To address the challenges associated with high dimensionality and waveform distortion in discrete representations, we propose Diff-LM-Speech, which models semantic embeddings into mel-spectrogram based on diffusion models and introduces a prompt encoder structure based on variational autoencoders and prosody bottlenecks to improve prompt representation capabilities. Autoregressive language models often suffer from missing and repeated words, while non-autoregressive frameworks face expression averaging problems due to duration prediction models. To address these issues, we propose Tetra-Diff-Speech, which designs a duration diffusion model to achieve diverse prosodic expressions. While we expect the information content of semantic coding to be between t
    
[^13]: 跨模态概念学习和推理用于视觉-语言模型

    Cross-Modal Concept Learning and Inference for Vision-Language Models. (arXiv:2307.15460v1 [cs.CV])

    [http://arxiv.org/abs/2307.15460](http://arxiv.org/abs/2307.15460)

    本论文提出了一种跨模态概念学习和推理（CCLI）方法，通过利用CLIP的文本-图像相关性能力，从图像中自动学习一组独特的视觉概念，并利用这些概念构建了图像的判别式表示。

    

    大规模预训练的视觉-语言模型（VLMs），如CLIP，在各种下游任务中取得了显著的成功，通过微调建立了文本和图像之间的相关性。在现有的微调方法中，将特定类别的文本描述与整个图像进行匹配。我们认识到整个图像匹配并不有效，因为同一类别的图像通常包含一组不同的语义对象，而对象又包含一组语义部分或概念。个别的语义部分或概念可能出现在不同类别的图像样本中。为了解决这个问题，在本文中，我们开发了一种新的方法，称为跨模态概念学习和推理（CCLI）。利用CLIP的强大的文本-图像相关性能力，我们的方法使用一组语义文本概念从图像中自动学习一组独特的视觉概念。基于这些视觉概念，我们构建了图像的判别式表示。

    Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP, establish the correlation between texts and images, achieving remarkable success on various downstream tasks with fine-tuning. In existing fine-tuning methods, the class-specific text description is matched against the whole image. We recognize that this whole image matching is not effective since images from the same class often contain a set of different semantic objects, and an object further consists of a set of semantic parts or concepts. Individual semantic parts or concepts may appear in image samples from different classes. To address this issue, in this paper, we develop a new method called cross-model concept learning and inference (CCLI). Using the powerful text-image correlation capability of CLIP, our method automatically learns a large set of distinctive visual concepts from images using a set of semantic text concepts. Based on these visual concepts, we construct a discriminative representation of image
    
[^14]: 基于Trie上下文增强的个性化查询自动补全算法，以提升对短前缀和未见前缀的支持

    Trie-NLG: Trie Context Augmentation to Improve Personalized Query Auto-Completion for Short and Unseen Prefixes. (arXiv:2307.15455v1 [cs.CL])

    [http://arxiv.org/abs/2307.15455](http://arxiv.org/abs/2307.15455)

    提出了一种基于Trie上下文增强的个性化查询自动补全算法，可以解决短前缀和未见前缀的问题，并有效利用历史查询的流行度信息。

    

    查询自动补全(QAC)旨在为给定的查询前缀提供合理的补全建议。传统的QAC系统利用历史查询日志中的Trie数据结构来提供最受欢迎的补全建议。然而，对于任何QAC系统来说，有两种特定的场景很难处理：短前缀(本质上存在歧义)和未见前缀。最近，提出了个性化自然语言生成(NLG)模型，利用前一个会话的查询作为上下文来解决这两个挑战。然而，这样的NLG模型存在两个缺点：(1)前述会话查询可能与当前前缀的用户意图无关且包含噪声；(2)NLG模型无法直接融合历史查询的流行度。因此，我们提出了一种新颖的QAC算法Trie-NLG，该算法同时利用Trie中的流行度信息和前一个会话查询中的个性化信息。

    Query auto-completion (QAC) aims at suggesting plausible completions for a given query prefix. Traditionally, QAC systems have leveraged tries curated from historical query logs to suggest most popular completions. In this context, there are two specific scenarios that are difficult to handle for any QAC system: short prefixes (which are inherently ambiguous) and unseen prefixes. Recently, personalized Natural Language Generation (NLG) models have been proposed to leverage previous session queries as context for addressing these two challenges. However, such NLG models suffer from two drawbacks: (1) some of the previous session queries could be noisy and irrelevant to the user intent for the current prefix, and (2) NLG models cannot directly incorporate historical query popularity. This motivates us to propose a novel NLG model for QAC, Trie-NLG, which jointly leverages popularity signals from trie and personalization signals from previous session queries. We train the Trie-NLG model b
    
[^15]: 从概率编程到基于复杂性的编程

    From Probabilistic Programming to Complexity-based Programming. (arXiv:2307.15453v1 [cs.AI])

    [http://arxiv.org/abs/2307.15453](http://arxiv.org/abs/2307.15453)

    CompLog是一种基于复杂性的计算框架，通过计算Kolmogorov复杂性替代概率推理，实现计算某种情况意外性的度量，并通过规范的世界和心智模型的描述生成相关描述，并提供对析取和否定的替代方法。

    

    本文介绍了一种名为CompLog的新型计算框架的主要特点和初步实现。CompLog借鉴了概率编程系统（如ProbLog）的推理机制，并基于Simplicity理论提出了一种新的推理机制，通过ASP程序的min-path搜索计算两种Kolmogorov复杂性，而不是概率推理。该系统使用户能够计算某个情况意外性的ex-post和ex-ante度量，分别对应于后验和先验主观概率。计算基于通过描述性谓词之间的因果和描述性关系加权的世界和心智模型的规范。本文还阐述了几个应用示例：生成相关描述，并提供对析取和否定的替代方法。

    The paper presents the main characteristics and a preliminary implementation of a novel computational framework named CompLog. Inspired by probabilistic programming systems like ProbLog, CompLog builds upon the inferential mechanisms proposed by Simplicity Theory, relying on the computation of two Kolmogorov complexities (here implemented as min-path searches via ASP programs) rather than probabilistic inference. The proposed system enables users to compute ex-post and ex-ante measures of unexpectedness of a certain situation, mapping respectively to posterior and prior subjective probabilities. The computation is based on the specification of world and mental models by means of causal and descriptive relations between predicates weighted by complexity. The paper illustrates a few examples of application: generating relevant descriptions, and providing alternative approaches to disjunction and to negation.
    
[^16]: CFN-ESA：一种具有情绪转移感知的跨模态融合网络用于对话情绪识别

    CFN-ESA: A Cross-Modal Fusion Network with Emotion-Shift Awareness for Dialogue Emotion Recognition. (arXiv:2307.15432v1 [cs.CL])

    [http://arxiv.org/abs/2307.15432](http://arxiv.org/abs/2307.15432)

    本文提出了一种具有情绪转移感知的跨模态融合网络（CFN-ESA）用于对话情绪识别，通过将文本模态作为主要情感信息的来源，视觉和声学模态作为次要信息的来源，并引入情绪转移模块来解决情绪转移场景下情感识别的问题。

    

    在对话情绪识别方面，多模态情感识别受到了各领域研究界的越来越多的关注。本文提出了一种具有情绪转移感知的跨模态融合网络（CFN-ESA）用于对话情绪识别。现有方法均平等地使用每个模态而无法区分情感信息的多少，从而难以充分提取多模态数据中的互补和关联信息。为了解决这个问题，在CFN-ESA中，文本模态被视为情感信息的主要来源，而视觉和声学模态则被视为次要来源。此外，大多数多模态情感识别模型忽视了情绪转移信息，过度关注上下文信息，导致在情绪转移场景下情感识别失败。我们设计了一个情绪转移模块来应对这一挑战。CFN-ESA主要包括单模态编码器（RUME）、跨模态编码器（ACME）和情绪转移模块（LESM）。

    Multimodal Emotion Recognition in Conversation (ERC) has garnered growing attention from research communities in various fields. In this paper, we propose a cross-modal fusion network with emotion-shift awareness (CFN-ESA) for ERC. Extant approaches employ each modality equally without distinguishing the amount of emotional information, rendering it hard to adequately extract complementary and associative information from multimodal data. To cope with this problem, in CFN-ESA, textual modalities are treated as the primary source of emotional information, while visual and acoustic modalities are taken as the secondary sources. Besides, most multimodal ERC models ignore emotion-shift information and overfocus on contextual information, leading to the failure of emotion recognition under emotion-shift scenario. We elaborate an emotion-shift module to address this challenge. CFN-ESA mainly consists of the unimodal encoder (RUME), cross-modal encoder (ACME), and emotion-shift module (LESM).
    
[^17]: 大型语言模型的关键评论：敏感性、偏见和通向专业人工智能的道路

    A Critical Review of Large Language Models: Sensitivity, Bias, and the Path Toward Specialized AI. (arXiv:2307.15425v1 [cs.CL])

    [http://arxiv.org/abs/2307.15425](http://arxiv.org/abs/2307.15425)

    本文研究了专业编译语言模型和通用模型在检测可持续发展目标方面的比效率，关注了大型语言模型存在的偏见和敏感性挑战。研究强调了专业培训对于精确无偏的分析的必要性，并通过对一个公司描述数据集的案例研究对比了GPT-3.5和专业SDG检测模型的差异。研究结果强调了在模型选择时需要考虑任务要求、成本、复杂性和透明度。尽管大型语言模型的多功能性，但作者建议在需要精确性和准确性的任务中使用专业模型。

    

    本文对专业编译语言模型和OpenAI的GPT-3.5等通用模型在检测文本数据中的可持续发展目标（SDGs）方面的比效率进行了研究。它对大型语言模型（LLMs）进行了关键评论，解决了与偏见和敏感性相关的挑战。强调了精确、无偏见分析的专业培训的必要性。使用公司描述数据集的案例研究揭示了GPT-3.5和专业SDG检测模型之间的差异。虽然GPT-3.5具有更广泛的覆盖范围，但可能会识别与公司活动相关性有限的SDGs。相比之下，专业模型聚焦于高度相关的SDGs。强调了深思熟虑的模型选择的重要性，考虑任务要求、成本、复杂性和透明度。尽管LLMs的多功能性，但建议在需要精确性和准确性的任务中使用专业模型。研究最后鼓励了……

    This paper examines the comparative effectiveness of a specialized compiled language model and a general-purpose model like OpenAI's GPT-3.5 in detecting SDGs within text data. It presents a critical review of Large Language Models (LLMs), addressing challenges related to bias and sensitivity. The necessity of specialized training for precise, unbiased analysis is underlined. A case study using a company descriptions dataset offers insight into the differences between the GPT-3.5 and the specialized SDG detection model. While GPT-3.5 boasts broader coverage, it may identify SDGs with limited relevance to the companies' activities. In contrast, the specialized model zeroes in on highly pertinent SDGs. The importance of thoughtful model selection is emphasized, taking into account task requirements, cost, complexity, and transparency. Despite the versatility of LLMs, the use of specialized models is suggested for tasks demanding precision and accuracy. The study concludes by encouraging 
    
[^18]: 通过多个帖子依赖关系改进社交媒体受欢迎程度预测

    Improving Social Media Popularity Prediction with Multiple Post Dependencies. (arXiv:2307.15413v1 [cs.MM])

    [http://arxiv.org/abs/2307.15413](http://arxiv.org/abs/2307.15413)

    该论文提出了一种新型预测框架DSN，通过同时利用帖子内部和帖子间的依赖关系来改进社交媒体受欢迎程度的预测准确性。

    

    社交媒体受欢迎程度预测引起了广泛关注，因为它对许多不同应用有着深远的影响，如推荐系统和多媒体广告。尽管最近的一些努力利用社交媒体帖子的内容来提高预测准确性，但许多现有模型未能充分利用帖子之间的多个依赖关系，而这些依赖关系对于全面提取帖子内容信息很重要。为了解决这个问题，我们提出了一种名为“依赖感知序列网络（DSN）”的新型预测框架，它同时利用帖子内部依赖和帖子间依赖。对于帖子内部依赖，DSN采用一种多模态特征提取器和高效微调策略，从帖子的图像和文本信息中获取任务特定的表示。对于帖子间依赖，DSN使用一种分层信息传播方法来学习能更好描述帖子之间差异的类别表示。DSN还利用...

    Social Media Popularity Prediction has drawn a lot of attention because of its profound impact on many different applications, such as recommendation systems and multimedia advertising. Despite recent efforts to leverage the content of social media posts to improve prediction accuracy, many existing models fail to fully exploit the multiple dependencies between posts, which are important to comprehensively extract content information from posts. To tackle this problem, we propose a novel prediction framework named Dependency-aware Sequence Network (DSN) that exploits both intra- and inter-post dependencies. For intra-post dependency, DSN adopts a multimodal feature extractor with an efficient fine-tuning strategy to obtain task-specific representations from images and textual information of posts. For inter-post dependency, DSN uses a hierarchical information propagation method to learn category representations that could better describe the difference between posts. DSN also exploits 
    
[^19]: 研究上下文学习的学习行为：与监督学习的比较

    Investigating the Learning Behaviour of In-context Learning: A Comparison with Supervised Learning. (arXiv:2307.15411v1 [cs.CL])

    [http://arxiv.org/abs/2307.15411](http://arxiv.org/abs/2307.15411)

    本研究通过对比监督学习和上下文学习，发现大型语言模型在学习行为上受到金标签的显著影响，但对于上下文学习来说，标签不平衡影响较小。实证结果显示上下文学习对标签扰动的敏感性较低。

    

    大型语言模型（LLM）展示了令人注目的上下文学习（ICL）能力，在没有明确预训练的情况下，仅通过少量训练样例就可以学习新任务。然而，尽管LLM取得了成功，对于ICL如何从给定的提示中学习知识的了解还很少。在本文中，为了更好地理解ICL的学习行为，我们使用相同的演示样例通过ICL和监督学习（SL）分别训练相同的LLM，并研究它们在一系列分类任务上在标签扰动（噪声标签和标签不平衡）下的性能。首先，通过广泛的实验，我们发现金标签对于下游的上下文性能有重大影响，尤其是对于大型语言模型；然而，对于ICL来说，标签不平衡对所有模型大小都不太重要。其次，在与SL进行比较时，我们经验性地表明ICL对标签扰动的敏感性较低。

    Large language models (LLMs) have shown remarkable capacity for in-context learning (ICL), where learning a new task from just a few training examples is done without being explicitly pre-trained. However, despite the success of LLMs, there has been little understanding of how ICL learns the knowledge from the given prompts. In this paper, to make progress toward understanding the learning behaviour of ICL, we train the same LLMs with the same demonstration examples via ICL and supervised learning (SL), respectively, and investigate their performance under label perturbations (i.e., noisy labels and label imbalance) on a range of classification tasks. First, via extensive experiments, we find that gold labels have significant impacts on the downstream in-context performance, especially for large language models; however, imbalanced labels matter little to ICL across all model sizes. Second, when comparing with SL, we show empirically that ICL is less sensitive to label perturbations th
    
[^20]: 在客户支持对话中实现完全无监督的意图诱导框架

    Towards a Fully Unsupervised Framework for Intent Induction in Customer Support Dialogues. (arXiv:2307.15410v1 [cs.CL])

    [http://arxiv.org/abs/2307.15410](http://arxiv.org/abs/2307.15410)

    本文提出了一个完全无监督的对话意图诱导框架，通过预处理对话语料库和研究最常见的序列来提取意图的对话流程，适用于各行业的实际客户支持应用。

    

    目前的意图诱导模型需要注释的数据集。然而，注释对话耗时、繁琐且昂贵。本文提出了一个完全无监督的对话意图诱导框架。此外，我们展示了如何预处理对话语料库以提高结果。最后，我们展示了如何通过研究最常见的序列来提取意图的对话流程。尽管我们在MultiWOZ数据集上测试了我们的工作，但该框架不需要先验知识，因此适用于任何可能的用例，这使得它在各行业的实际客户支持应用中具有重要意义。

    State of the art models in intent induction require annotated datasets. However, annotating dialogues is time-consuming, laborious and expensive. In this work, we propose a completely unsupervised framework for intent induction within a dialogue. In addition, we show how pre-processing the dialogue corpora can improve results. Finally, we show how to extract the dialogue flows of intentions by investigating the most common sequences. Although we test our work in the MultiWOZ dataset, the fact that this framework requires no prior knowledge make it applicable to any possible use case, making it very relevant to real world customer support applications across industry.
    
[^21]: 使用ChatGPT进行多语言旅游辅助：比较印地语、泰卢固语和卡纳达语的能力

    Multilingual Tourist Assistance using ChatGPT: Comparing Capabilities in Hindi, Telugu, and Kannada. (arXiv:2307.15376v1 [cs.CL])

    [http://arxiv.org/abs/2307.15376](http://arxiv.org/abs/2307.15376)

    本研究比较了ChatGPT在翻译英语成印地语、泰卢固语和卡纳达语方面的效果，发现印地语翻译具有较高的准确性和流畅性，而泰卢固语翻译表现不佳。

    

    本研究调查了OpenAI的AI语言模型ChatGPT在将英语翻译成印地语、泰卢固语和卡纳达语方面的有效性，旨在帮助印度多语言环境中的游客。为了评估翻译质量，使用了包括常识、食物和旅行等领域的50个问题的测试集。这些问题由五名志愿者评估其准确性和流畅性，并将得分转换为BLEU分数。BLEU分数评估机器生成的翻译与人工翻译的接近程度，较高的分数表示更好的翻译质量。结果显示印地语翻译优于其他语言，准确性和流畅性更好，而泰卢固语翻译落后。人工评估员评价了翻译的准确性和流畅性，为语言模型的表现提供了全面的视角。

    This research investigates the effectiveness of ChatGPT, an AI language model by OpenAI, in translating English into Hindi, Telugu, and Kannada languages, aimed at assisting tourists in India's linguistically diverse environment. To measure the translation quality, a test set of 50 questions from diverse fields such as general knowledge, food, and travel was used. These were assessed by five volunteers for accuracy and fluency, and the scores were subsequently converted into a BLEU score. The BLEU score evaluates the closeness of a machine-generated translation to a human translation, with a higher score indicating better translation quality. The Hindi translations outperformed others, showcasing superior accuracy and fluency, whereas Telugu translations lagged behind. Human evaluators rated both the accuracy and fluency of translations, offering a comprehensive perspective on the language model's performance.
    
[^22]: Med-HALT:大规模语言模型中医疗领域幻觉测试

    Med-HALT: Medical Domain Hallucination Test for Large Language Models. (arXiv:2307.15343v1 [cs.CL])

    [http://arxiv.org/abs/2307.15343](http://arxiv.org/abs/2307.15343)

    Med-HALT是一个新的基准和数据集，用于评估和减少大规模语言模型中医疗领域的幻觉问题。这个数据集包括多种创新的测试模式，并评估了领先的LLMs在性能上的差异。

    

    本研究论文关注大规模语言模型（LLMs）中幻觉问题的挑战，特别是在医疗领域的背景下。幻觉指这些模型生成了合理但未经验证或错误的信息，这可能对医疗应用产生严重影响。我们提出了一个新的基准和数据集，Med-HALT（医疗领域幻觉测试），专门设计用于评估和减少幻觉。Med-HALT提供了一个多元化的跨国数据集，这些数据集来自不同国家的医疗检查，包括多种创新的测试模式。Med-HALT包括两类测试：推理和基于记忆的幻觉测试，旨在评估LLMs的问题解决和信息检索能力。我们的研究评估了文本Davinci，GPT-3.5，LlaMa-2，MPT和Falcon等领先的LLMs，揭示了它们在性能上的显著差异。这篇论文提供了有关数据集的详细见解，促进了进一步的研究和发展。

    This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs's problem-solving and information retrieval abilities.  Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting
    
[^23]: 教我如何提高我的论证能力：关于论证中的反馈的调查

    Teach Me How to Improve My Argumentation Skills: A Survey on Feedback in Argumentation. (arXiv:2307.15341v1 [cs.CL])

    [http://arxiv.org/abs/2307.15341](http://arxiv.org/abs/2307.15341)

    这项调查的目标是探讨当前论证计算模型提供的反馈维度，以提高学习者的批判性思维能力。

    

    论证在教育中的应用已被证明可以提高学生等最终用户的批判性思维能力，并且已经开发了用于辅助该过程的论证的计算模型。尽管这些模型对于评估论证的质量非常有用，但往往无法解释为什么某个特定的论证被认为是差的或不好，这使得难以向用户提供有建设性的反馈来增强他们的批判性思维能力。在本调查中，我们旨在探索当前论证计算模型提供的不同反馈维度（丰富性、可视化、互动性和个性化），以及增强这些模型解释能力的可能性，最终帮助学习者提高批判性思维能力。

    The use of argumentation in education has been shown to improve critical thinking skills for end-users such as students, and computational models for argumentation have been developed to assist in this process. Although these models are useful for evaluating the quality of an argument, they oftentimes cannot explain why a particular argument is considered poor or not, which makes it difficult to provide constructive feedback to users to strengthen their critical thinking skills. In this survey, we aim to explore the different dimensions of feedback (Richness, Visualization, Interactivity, and Personalization) provided by the current computational models for argumentation, and the possibility of enhancing the power of explanations of such models, ultimately helping learners improve their critical thinking skills.
    
[^24]: 思维的骨架：大型语言模型可以进行并行解码

    Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding. (arXiv:2307.15337v1 [cs.CL])

    [http://arxiv.org/abs/2307.15337](http://arxiv.org/abs/2307.15337)

    本研究提出了一种名为“思维的骨架”的方法，可以通过并行解码来减少大型语言模型的生成延迟。这种方法不仅显著提高了速度，还可以潜在地提高答案质量。

    

    本研究旨在减少大型语言模型（LLMs）的端到端生成延迟。高生成延迟的一个主要原因是几乎所有最先进的LLMs都采用了顺序解码方法。在本研究中，受到人类的思考和写作过程的启发，我们提出了“思维的骨架”（SoT），它指导LLMs首先生成答案的骨架，然后通过并行API调用或批量解码来并行完成每个骨架点的内容。SoT不仅显著提高了速度（在11个不同的LLMs上提高了最多2.39倍），而且还可以潜在地提高在多个问题类别上的答案质量，包括多样性和相关性。SoT是一种针对效率的数据导向优化的初步尝试，并揭示了将LLMs推动更像人类思考以提高答案质量的潜力。

    This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose "Skeleton-of-Thought" (SoT), which guides LLMs to first generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed-up (up to 2.39x across 11 different LLMs), but it can also potentially improve the answer quality on several question categories in terms of diversity and relevance. SoT is an initial attempt at data-centric optimization for efficiency, and reveal the potential of pushing LLMs to think more like a human for answer quality.
    
[^25]: BARTPhoBEiT: 预训练的序列到序列和图像Transformer模型在越南视觉问答中的应用

    BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering. (arXiv:2307.15335v1 [cs.CL])

    [http://arxiv.org/abs/2307.15335](http://arxiv.org/abs/2307.15335)

    BARTPhoBEiT是一个基于Transformer的越南模型，针对越南视觉问答任务进行了改进。实验证明，该模型在准确度、精确度、召回率、F1-score、WUPS 0.0和WUPS 0.9等六个指标上优于强基线模型，提升了最新技术水平。

    

    视觉问答（VQA）是一个复杂且要求高的任务，将自然语言处理（NLP）和计算机视觉（CV）相结合，引起了研究者的兴趣。 英语作为资源丰富的语言，在VQA的数据集和模型设计方面取得了显著进展。 但是，缺少针对越南等特定国家的模型。 为了解决这个问题，我们引入了一个基于Transformer的越南模型，名为BARTPhoBEiT。 该模型包括预训练的越南语序列到序列和双向编码器图像Transformer，并评估了越南VQA数据集。 实验结果表明，我们提出的模型在六个指标：准确度，精确度，召回率，F1-score，WUPS 0.0和WUPS 0.9上优于强基线模型，并改进了最新技术水平。

    Visual Question Answering (VQA) is an intricate and demanding task that integrates natural language processing (NLP) and computer vision (CV), capturing the interest of researchers. The English language, renowned for its wealth of resources, has witnessed notable advancements in both datasets and models designed for VQA. However, there is a lack of models that target specific countries such as Vietnam. To address this limitation, we introduce a transformer-based Vietnamese model named BARTPhoBEiT. This model includes pre-trained Sequence-to-Sequence and bidirectional encoder representation from Image Transformers in Vietnamese and evaluates Vietnamese VQA datasets. Experimental results demonstrate that our proposed model outperforms the strong baseline and improves the state-of-the-art in six metrics: Accuracy, Precision, Recall, F1-score, WUPS 0.0, and WUPS 0.9.
    
[^26]: 使用预训练语言模型进行立场识别的教程：BERT微调和提示大型语言模型

    Tutorials on Stance Detection using Pre-trained Language Models: Fine-tuning BERT and Prompting Large Language Models. (arXiv:2307.15331v1 [cs.CL])

    [http://arxiv.org/abs/2307.15331](http://arxiv.org/abs/2307.15331)

    这篇论文提供了两个教程，介绍了使用BERT微调和提示大型语言模型进行Twitter立场识别的方法。教程通过实例代码和可视化分析，展示了少样本ChatGPT和FLAN-T5的优势，同时提供了对BERT模型的训练和评估的指导。这些教程使学习者能够掌握运用先进方法进行立场识别的实践经验。

    

    本文提供了两个独立的教程，介绍了使用BERT微调和提示大型语言模型（LLMs）在Twitter数据上进行立场识别。第一个教程解释了BERT的架构和分词，指导用户通过使用HuggingFace transformers训练、调优和评估标准和领域特定的BERT模型。第二个教程侧重于构建提示和少样本示例，从ChatGPT和开源FLAN-T5中引出立场而无需进行微调。采用了各种提示策略，并使用混淆矩阵和宏F1分数进行评估。这些教程提供了代码、可视化和洞察力，揭示了少样本ChatGPT和FLAN-T5的优势，它们胜过了微调的BERT。通过以易于理解、实践为导向的方式同时涵盖模型微调和提示技术，这些教程使学习者能够获得对立场检测的尖端方法的实际经验。

    This paper presents two self-contained tutorials on stance detection in Twitter data using BERT fine-tuning and prompting large language models (LLMs). The first tutorial explains BERT architecture and tokenization, guiding users through training, tuning, and evaluating standard and domain-specific BERT models with HuggingFace transformers. The second focuses on constructing prompts and few-shot examples to elicit stances from ChatGPT and open-source FLAN-T5 without fine-tuning. Various prompting strategies are implemented and evaluated using confusion matrices and macro F1 scores. The tutorials provide code, visualizations, and insights revealing the strengths of few-shot ChatGPT and FLAN-T5 which outperform fine-tuned BERTs. By covering both model fine-tuning and prompting-based techniques in an accessible, hands-on manner, these tutorials enable learners to gain applied experience with cutting-edge methods for stance detection.
    
[^27]: TrafficSafetyGPT：将预训练的大型语言模型调整到交通安全领域的专家

    TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety. (arXiv:2307.15311v1 [cs.CL])

    [http://arxiv.org/abs/2307.15311](http://arxiv.org/abs/2307.15311)

    TrafficSafetyGPT是一种通过将预训练的大型语言模型进行领域特定的监督微调，以在交通安全领域任务中提供准确响应的模型。

    

    大型语言模型在各种通用领域的自然语言处理任务中表现出了显著的效能。然而，它们在交通安全领域的任务中的性能不佳，主要是因为需要专门的交通安全专业知识来产生准确的响应。为了解决这个挑战，我们引入了TrafficSafetyGPT，这是一种基于大型语言模型的模型，经过了使用TrafficSafety-2K数据集进行的监督微调，该数据集包含了政府出版的指南书和ChatGPT生成的指导-输出对。我们提出的TrafficSafetyGPT模型和TrafficSafety-2K训练数据集可以在https://github.com/ozheng1993/TrafficSafetyGPT上获取。

    Large Language Models (LLMs) have shown remarkable effectiveness in various general-domain natural language processing (NLP) tasks. However, their performance in transportation safety domain tasks has been suboptimal, primarily attributed to the requirement for specialized transportation safety expertise in generating accurate responses [1]. To address this challenge, we introduce TrafficSafetyGPT, a novel LLAMA-based model, which has undergone supervised fine-tuning using TrafficSafety-2K dataset which has human labels from government produced guiding books and ChatGPT-generated instruction-output pairs. Our proposed TrafficSafetyGPT model and TrafficSafety-2K train dataset are accessible at https://github.com/ozheng1993/TrafficSafetyGPT.
    
[^28]: WC-SBERT: 利用SBERT和自训练解决零样本文本分类问题的研究

    WC-SBERT: Zero-Shot Text Classification via SBERT with Self-Training for Wikipedia Categories. (arXiv:2307.15293v1 [cs.CL])

    [http://arxiv.org/abs/2307.15293](http://arxiv.org/abs/2307.15293)

    WC-SBERT提出了一种利用SBERT和自训练解决零样本文本分类问题的方法，通过使用维基百科作为训练集和建立类别对之间的正相关关系，实现快速且准确的分类。

    

    我们的研究专注于解决自然语言处理中的零样本文本分类问题，并特别强调创新的自训练策略。为了实现这一目标，我们提出了一种新颖的自训练策略，使用标签而非文本进行训练，显著减少了模型的训练时间。具体来说，我们使用来自维基百科的类别作为训练集，并利用SBERT预训练模型在同一文本中的类别对之间建立正相关关系，便于进行联想训练。对于新的测试数据集，我们改进了原始自训练方法，消除了需要每个目标数据集的先前训练和测试数据的需求。相反，我们采用维基百科作为统一的训练数据集，更好地近似零样本情境。这种修改方式可以快速进行不同数据集的微调和推断，大大减少了自训练所需的时间。我们的实验结果表明，这种方法比以往的方法具有更好的性能。

    Our research focuses on solving the zero-shot text classification problem in NLP, with a particular emphasis on innovative self-training strategies. To achieve this objective, we propose a novel self-training strategy that uses labels rather than text for training, significantly reducing the model's training time. Specifically, we use categories from Wikipedia as our training set and leverage the SBERT pre-trained model to establish positive correlations between pairs of categories within the same text, facilitating associative training. For new test datasets, we have improved the original self-training approach, eliminating the need for prior training and testing data from each target dataset. Instead, we adopt Wikipedia as a unified training dataset to better approximate the zero-shot scenario. This modification allows for rapid fine-tuning and inference across different datasets, greatly reducing the time required for self-training. Our experimental results demonstrate that this met
    
[^29]: ChatHome:家居装修领域的特定领域语言模型的开发和评估

    ChatHome: Development and Evaluation of a Domain-Specific Language Model for Home Renovation. (arXiv:2307.15290v1 [cs.CL])

    [http://arxiv.org/abs/2307.15290](http://arxiv.org/abs/2307.15290)

    本论文介绍了ChatHome，这是一个专注于家居装修领域的特定领域语言模型（DSLM）的开发和评估。通过领域自适应预训练和指导调整的方法，ChatHome可以生成与家居装修相关的高保真、精确的输出。

    

    本文介绍了ChatHome的开发和评估，这是一个专门针对复杂的家居装修领域设计的特定领域语言模型（DSLM）。考虑到类似GPT-4这样的大型语言模型（LLMs）的成熟能力以及对家居装修的不断兴趣，本研究旨在通过生成一个专门模型，产生与家居装修领域相关的高保真、精确的输出来解决这些方面的矛盾。ChatHome的创新在于其方法论，将领域自适应预训练和指导调整融合在一个广泛数据集上。该数据集包括与家居装修相关的专业文章、标准文档和网络内容。这种双重策略旨在确保我们的模型可以吸收全面的领域知识并有效地解决用户的问题。通过对各种数据集的彻底实验，包括新引入的“EvalHome”领域数据集，我们得到了实质性的结果。

    This paper presents the development and evaluation of ChatHome, a domain-specific language model (DSLM) designed for the intricate field of home renovation. Considering the proven competencies of large language models (LLMs) like GPT-4 and the escalating fascination with home renovation, this study endeavors to reconcile these aspects by generating a dedicated model that can yield high-fidelity, precise outputs relevant to the home renovation arena. ChatHome's novelty rests on its methodology, fusing domain-adaptive pretraining and instruction-tuning over an extensive dataset. This dataset includes professional articles, standard documents, and web content pertinent to home renovation. This dual-pronged strategy is designed to ensure that our model can assimilate comprehensive domain knowledge and effectively address user inquiries. Via thorough experimentation on diverse datasets, both universal and domain-specific, including the freshly introduced "EvalHome" domain dataset, we substa
    
[^30]: 多语言词汇简化通过释义生成

    Multilingual Lexical Simplification via Paraphrase Generation. (arXiv:2307.15286v1 [cs.CL])

    [http://arxiv.org/abs/2307.15286](http://arxiv.org/abs/2307.15286)

    本文提出了一种基于释义生成的多语言词汇简化方法，通过释义生成多样性的词汇替代词并保留句子的意义，实验结果显示该方法在英语上显著优于其他方法。

    

    基于预训练语言模型的词汇简化方法在分析词汇上下文环境中的潜在替代词方面取得了显著进展。然而，这些方法需要针对不同语言单独进行预训练，并且忽视了句子意义的保留。在本文中，我们提出了一种通过释义生成的新颖的多语言词汇简化方法，因为释义提供了词汇选择的多样性同时保留了句子的意义。我们将释义视为多语言神经机器翻译中的零翻译任务，支持数百种语言。在释义建模的编码器中输入句子后，我们基于一种新颖的解码策略生成替代词，该策略仅关注复杂词汇的词汇变化。实验结果表明，我们的方法在英语上显著超过了基于BERT的方法和零翻译GPT3-based方法。

    Lexical simplification (LS) methods based on pretrained language models have made remarkable progress, generating potential substitutes for a complex word through analysis of its contextual surroundings. However, these methods require separate pretrained models for different languages and disregard the preservation of sentence meaning. In this paper, we propose a novel multilingual LS method via paraphrase generation, as paraphrases provide diversity in word selection while preserving the sentence's meaning. We regard paraphrasing as a zero-shot translation task within multilingual neural machine translation that supports hundreds of languages. After feeding the input sentence into the encoder of paraphrase modeling, we generate the substitutes based on a novel decoding strategy that concentrates solely on the lexical variations of the complex word. Experimental results demonstrate that our approach surpasses BERT-based methods and zero-shot GPT3-based method significantly on English, 
    
[^31]: 从人类反馈中进行强化学习的开放问题和基本限制

    Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback. (arXiv:2307.15217v1 [cs.AI])

    [http://arxiv.org/abs/2307.15217](http://arxiv.org/abs/2307.15217)

    本文调查了从人类反馈中进行强化学习的开放问题和基本限制，并提出了加强社会监督的审计和披露标准。

    

    从人类反馈中进行强化学习（RLHF）是一种训练人工智能系统与人类目标保持一致的技术。RLHF已成为微调最新的大型语言模型（LLM）的核心方法。尽管如此受欢迎，但系统性地系统化其缺陷的公开工作相对较少。在本文中，我们（1）调查了RLHF及相关方法的开放问题和基本限制；（2）概述了了解、改进和补充RLHF的实践技术；以及（3）提出了审计和披露标准以改进RLHF系统的社会监督。我们的工作强调了RLHF的局限性，并强调了以多方面方法开发更安全的人工智能系统的重要性。

    Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.
    
[^32]: PromptStyler：基于提示的无源域泛化风格生成

    PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization. (arXiv:2307.15199v1 [cs.CV])

    [http://arxiv.org/abs/2307.15199](http://arxiv.org/abs/2307.15199)

    提出了PromptStyler，通过使用提示合成样式特征，解决了无源域泛化的问题。该方法通过学习样式词向量生成多样的样式，并通过强制样式内容特征与内容特征靠近来保证样式不会扭曲内容信息。在多个数据集上取得了最先进的结果。

    

    在联合视觉语言空间中，文本特征（如“一张狗的照片”）可以有效地表示其相关的图像特征（如狗的照片）。受此启发，我们提出了PromptStyler，通过使用提示来合成各种样式，而不使用任何图像来处理无源域泛化中的分布偏移。我们的方法通过可学习的样式词向量为伪词S*生成多样的样式特征（如“a S* style of a”）。为了确保学习到的样式不会扭曲内容信息，我们强制要求样式内容特征（如“a S* style of a [class]”）在联合视觉语言空间中靠近其对应的内容特征（如“[class]”）。在学习样式词向量之后，我们使用合成的样式内容特征训练一个线性分类器。尽管PromptStyler不需要使用任何图像，并且需要额外的训练，但在PACS、VLCS、OfficeHome和DomainNet上取得了最先进的结果。

    In a joint vision-language space, a text feature (e.g., from "a photo of a dog") could effectively represent its relevant image features (e.g., from dog photos). Inspired by this, we propose PromptStyler which simulates various distribution shifts in the joint space by synthesizing diverse styles via prompts without using any images to deal with source-free domain generalization. Our method learns to generate a variety of style features (from "a S* style of a") via learnable style word vectors for pseudo-words S*. To ensure that learned styles do not distort content information, we force style-content features (from "a S* style of a [class]") to be located nearby their corresponding content features (from "[class]") in the joint vision-language space. After learning style word vectors, we train a linear classifier using synthesized style-content features. PromptStyler achieves the state of the art on PACS, VLCS, OfficeHome and DomainNet, although it does not require any images and take
    
[^33]: f-Divergence最小化用于序列级知识蒸馏

    f-Divergence Minimization for Sequence-Level Knowledge Distillation. (arXiv:2307.15190v1 [cs.CL])

    [http://arxiv.org/abs/2307.15190](http://arxiv.org/abs/2307.15190)

    本文提出了一个f-DISTILL框架，将序列级知识蒸馏建模为最小化广义f-分歧函数。通过在词级上计算损失，能够更好地压缩语言模型并使学生模型从教师模型中学习。提出的方法在多个数据集上表现出色。

    

    知识蒸馏（KD）是将知识从大模型转移到小模型的过程。在自然语言处理领域，由于对不断增长的语言模型进行压缩的需求，它受到越来越多的关注。在这项工作中，我们提出了一个f-DISTILL框架，将序列级知识蒸馏建模为最小化广义f-分歧函数。我们在我们的框架下提出了四种蒸馏变种，并表明现有的 SeqKD 和 ENGINE 方法是我们f-DISTILL方法的近似。我们进一步推导出了我们的f-DISTILL的逐步分解，将难以处理的序列级分歧简化为可以以一种可处理的方式计算的词级损失。在四个数据集上的实验证明我们的方法优于现有的KD方法，并且我们对称的蒸馏损失可以更好地强迫学生从教师分布中学习。

    Knowledge distillation (KD) is the process of transferring knowledge from a large model to a small one. It has gained increasing attention in the natural language processing community, driven by the demands of compressing ever-growing language models. In this work, we propose an f-DISTILL framework, which formulates sequence-level knowledge distillation as minimizing a generalized f-divergence function. We propose four distilling variants under our framework and show that existing SeqKD and ENGINE approaches are approximations of our f-DISTILL methods. We further derive step-wise decomposition for our f-DISTILL, reducing intractable sequence-level divergence to word-level losses that can be computed in a tractable manner. Experiments across four datasets show that our methods outperform existing KD approaches, and that our symmetric distilling losses can better force the student to learn from the teacher distribution.
    
[^34]: RCT拒绝抽样用于因果估计评估

    RCT Rejection Sampling for Causal Estimation Evaluation. (arXiv:2307.15176v1 [cs.AI])

    [http://arxiv.org/abs/2307.15176](http://arxiv.org/abs/2307.15176)

    该论文提出了一种名为RCT拒绝抽样的新抽样算法，用于因果估计评估。该方法通过子抽样随机控制试验(RCT)创建混淆的观测数据集，并使用RCT的平均因果效应作为基准真实值，以进行有效比较。

    

    混淆是从观测数据中无偏估计因果效应的一个重要障碍。对于高维协变量的情况，如文本数据、基因组学或行为社会科学，研究人员提出了适应机器学习方法进行因果估计的调整方法。然而，这些调整方法的经验评估一直存在困难和限制。在这项工作中，我们基于一种有前景的经验评估策略，简化了评估设计，并使用真实数据：对随机控制试验(RCT)进行子抽样，以创建混淆的观测数据集，同时使用RCT的平均因果效应作为基准真实值。我们提出了一种新的抽样算法，称为RCT拒绝抽样，并提供了理论保证，以确保观测数据的因果识别成立，从而可以与基准RCT进行有效比较。通过使用合成数据，我们展示了我们的算法在...

    Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates -- such as text data, genomics, or the behavioral social sciences -researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm in
    
[^35]: VISU参加WASSA 2023共享任务：利用BERT和堆叠嵌入检测对新闻故事的情绪反应

    VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Leveraging BERT and Stacked Embeddings. (arXiv:2307.15164v1 [cs.CL])

    [http://arxiv.org/abs/2307.15164](http://arxiv.org/abs/2307.15164)

    本研究中，我们开发了一种利用深度学习模型和词嵌入表示的策略来捕捉复杂对话中情绪表达的微妙差异。我们的实验结果在情绪检测任务中取得了良好的效果，并在小样本和不平衡的混合目标情绪数据集中得到了验证。

    

    我们的系统VISU参加了WASSA 2023共享任务（3），即从对新闻文章的反应中写的文章中进行情绪分类。从复杂对话中检测情绪是具有挑战性的，通常需要上下文/领域的理解。因此，在这项研究中，我们专注于开发深度学习（DL）模型，使用定制的预处理策略与词嵌入表示的组合来捕捉表达的情绪的微妙差异。我们的实验使用了静态和上下文嵌入（单独和堆叠）与双向长短期记忆（BiLSTM）和Transformer模型。在情绪检测任务中，我们占据了第十名，得分为0.2717的宏F1-分数，验证了我们实施的方法在小样本和不平衡的混合目标情绪数据集中的有效性。

    Our system, VISU, participated in the WASSA 2023 Shared Task (3) of Emotion Classification from essays written in reaction to news articles. Emotion detection from complex dialogues is challenging and often requires context/domain understanding. Therefore in this research, we have focused on developing deep learning (DL) models using the combination of word embedding representations with tailored prepossessing strategies to capture the nuances of emotions expressed. Our experiments used static and contextual embeddings (individual and stacked) with Bidirectional Long short-term memory (BiLSTM) and Transformer based models. We occupied rank tenth in the emotion detection task by scoring a Macro F1-Score of 0.2717, validating the efficacy of our implemented approaches for small and imbalanced datasets with mixed categories of target emotions.
    
[^36]: 级联跨模态Transformer用于请求和投诉检测

    Cascaded Cross-Modal Transformer for Request and Complaint Detection. (arXiv:2307.15097v1 [cs.CL])

    [http://arxiv.org/abs/2307.15097](http://arxiv.org/abs/2307.15097)

    本文提出了一种级联跨模态Transformer模型，结合语音和文本转录，用于检测电话对话中的客户请求和投诉。在ACM Multimedia 2023计算语言学挑战赛的请求子挑战中，我们的系统在投诉和请求类别中达到了65.41%和85.87%的不平衡平均召回率。

    

    我们提出了一种新颖的级联跨模态Transformer（CCMT），将语音和文本转录结合起来，以检测电话对话中的客户请求和投诉。我们的方法通过使用自动语音识别（ASR）模型转录语音，并将转录件翻译成不同语言来利用多模态范式。随后，我们将语言特定的基于BERT的模型与Wav2Vec2.0音频特征在一个新颖的级联交叉注意力Transformer模型中相结合。我们将我们的系统应用于ACM Multimedia 2023计算语言学挑战赛的请求子挑战中，在投诉和请求类别中分别达到了65.41%和85.87%的不平衡平均召回率（UAR）。

    We propose a novel cascaded cross-modal transformer (CCMT) that combines speech and text transcripts to detect customer requests and complaints in phone conversations. Our approach leverages a multimodal paradigm by transcribing the speech using automatic speech recognition (ASR) models and translating the transcripts into different languages. Subsequently, we combine language-specific BERT-based models with Wav2Vec2.0 audio features in a novel cascaded cross-attention transformer model. We apply our system to the Requests Sub-Challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge, reaching unweighted average recalls (UAR) of 65.41% and 85.87% for the complaint and request classes, respectively.
    
[^37]: 使用机器学习从南非Twitter数据中检测COVID-19疫苗犹豫情绪的存在

    Detecting the Presence of COVID-19 Vaccination Hesitancy from South African Twitter Data Using Machine Learning. (arXiv:2307.15072v1 [cs.CY])

    [http://arxiv.org/abs/2307.15072](http://arxiv.org/abs/2307.15072)

    本研究通过对南非疫苗犹豫相关推文进行情感分析和机器学习模型训练，检测出COVID-19疫苗犹豫情绪的存在并对用户生成内容进行分类。这对于应对疫苗犹豫对公共卫生工作的影响具有重要意义。

    

    在COVID-19大流行期间，关于南非用户生成内容的社交媒体研究非常少，使用手动标注方法更是凤毛麟角。疫苗接种是对抗疫情的主要手段，但疫苗犹豫危及公共卫生工作。本研究对与疫苗犹豫有关的南非推文进行情感分析，旨在训练AI媒介的分类模型，并评估其在分类用户生成内容时的可靠性。我们提取了来自南非的3万条推文，并将其手动标注为三个情感类别之一：积极、消极、中性。使用的机器学习模型包括LSTM、双向LSTM、SVM、BERT-base-cased和RoBERTa-base模型，通过WandB平台精心选择和调整了它们的超参数。我们使用了两种不同的预处理方法进行比较：一种基于语义，另一种基于语料库。

    Very few social media studies have been done on South African user-generated content during the COVID-19 pandemic and even fewer using hand-labelling over automated methods. Vaccination is a major tool in the fight against the pandemic, but vaccine hesitancy jeopardizes any public health effort. In this study, sentiment analysis on South African tweets related to vaccine hesitancy was performed, with the aim of training AI-mediated classification models and assessing their reliability in categorizing UGC. A dataset of 30000 tweets from South Africa were extracted and hand-labelled into one of three sentiment classes: positive, negative, neutral. The machine learning models used were LSTM, bi-LSTM, SVM, BERT-base-cased and the RoBERTa-base models, whereby their hyperparameters were carefully chosen and tuned using the WandB platform. We used two different approaches when we pre-processed our data for comparison: one was semantics-based, while the other was corpus-based. The pre-processi
    
[^38]: 适应离线文本识别的作家适应性：基于神经网络的方法探索

    Writer adaptation for offline text recognition: An exploration of neural network-based methods. (arXiv:2307.15071v1 [cs.CV])

    [http://arxiv.org/abs/2307.15071](http://arxiv.org/abs/2307.15071)

    本研究探索了如何通过使用少量示例来实现适应新作家的手写文本识别模型。通过使用ResNet骨干网络和LSTM或Transformer序列解码器作为基础模型，并结合模型不可知元学习和作家代码的方法，实现了作家适应性。

    

    深度学习在手写识别方面取得了显著的成功。然而，神经网络的一个持久不足之处是它们不擅长处理数据分布的变化。在手写文本识别领域，这表现为对于与训练中所见到的作家不相似的作家，识别准确率较低。理想的手写文本识别模型应该能够适应新的书写风格，以处理大量可能的书写风格。在本文中，我们探讨了如何通过仅使用少量来自新作家的示例（例如16个示例）来使手写文本识别模型具有作家适应性。基于ResNet骨干网络和LSTM或Transformer序列解码器，使用了两种HTR架构作为基础模型。使用这些基础模型，考虑了两种使它们具有作家适应性的方法：1）模型不可知元学习（MAML），常用于少样本分类等任务的算法，和2）作家代码

    Handwriting recognition has seen significant success with the use of deep learning. However, a persistent shortcoming of neural networks is that they are not well-equipped to deal with shifting data distributions. In the field of handwritten text recognition (HTR), this shows itself in poor recognition accuracy for writers that are not similar to those seen during training. An ideal HTR model should be adaptive to new writing styles in order to handle the vast amount of possible writing styles. In this paper, we explore how HTR models can be made writer adaptive by using only a handful of examples from a new writer (e.g., 16 examples) for adaptation. Two HTR architectures are used as base models, using a ResNet backbone along with either an LSTM or Transformer sequence decoder. Using these base models, two methods are considered to make them writer adaptive: 1) model-agnostic meta-learning (MAML), an algorithm commonly used for tasks such as few-shot classification, and 2) writer codes
    
[^39]: 使用大型语言模型将患者与临床试验匹配

    Matching Patients to Clinical Trials with Large Language Models. (arXiv:2307.15051v1 [cs.CL])

    [http://arxiv.org/abs/2307.15051](http://arxiv.org/abs/2307.15051)

    本研究调查了使用大型语言模型（LLMs）来帮助患者和转诊医生识别合适的临床试验的潜力，并引入了TrialGPT架构，该架构能够准确预测合格性并提供解释，实验证明其有效性。

    

    临床试验在推动药物研发和基于证据的医学方面非常重要，但患者招募常常受到限制。在这项工作中，我们调查了使用大型语言模型（LLMs）来帮助患者和转诊医生识别合适的临床试验的潜力。具体而言，我们引入了一种新颖的架构TrialGPT，采用LLMs预测基于标准的合格性，并提供详细的解释，并根据患者病历中的自由文本来对候选临床试验进行排名和排除。我们在三个公开可用的184名患者和18,238个注释的临床试验的队列上评估了TrialGPT。实验结果表明几个关键发现：第一，TrialGPT在标准级别的预测准确性上表现出很高的准确率，并提供准确的解释。第二，TrialGPT的综合试验级别评分与专家标注的合格性高度相关。第三，这些评分

    Clinical trials are vital in advancing drug development and evidence-based medicine, but their success is often hindered by challenges in patient recruitment. In this work, we investigate the potential of large language models (LLMs) to assist individual patients and referral physicians in identifying suitable clinical trials from an extensive selection. Specifically, we introduce TrialGPT, a novel architecture employing LLMs to predict criterion-level eligibility with detailed explanations, which are then aggregated for ranking and excluding candidate clinical trials based on free-text patient notes. We evaluate TrialGPT on three publicly available cohorts of 184 patients and 18,238 annotated clinical trials. The experimental results demonstrate several key findings: First, TrialGPT achieves high criterion-level prediction accuracy with faithful explanations. Second, the aggregated trial-level TrialGPT scores are highly correlated with expert eligibility annotations. Third, these scor
    
[^40]: 在这篇论文中，我们介绍了首次将母语识别（Native Language Identification，NLI）应用于土耳其语的研究。

    Turkish Native Language Identification. (arXiv:2307.14850v1 [cs.CL])

    [http://arxiv.org/abs/2307.14850](http://arxiv.org/abs/2307.14850)

    这项研究首次将母语识别应用于土耳其语,通过分析作者不同语言的写作来预测作者的母语。研究使用了土耳其学习者语料库和三个句法特征来展示其有效性。

    

    在这篇论文中，我们首次将母语识别（NLI）应用于土耳其语。NLI 是通过分析作者不同语言的写作来预测作者的母语。尽管大多数NLI研究都侧重于英语，我们的研究将其范围扩展到土耳其语。我们使用了最近构建的土耳其学习者语料库，并结合了三个句法特征（CFG 产生规则，词性n-gram和函数词）与L2文本，以展示它们在该任务中的有效性。

    In this paper, we present the first application of Native Language Identification (NLI) for the Turkish language. NLI involves predicting the writer's first language by analysing their writing in different languages. While most NLI research has focused on English, our study extends its scope to Turkish. We used the recently constructed Turkish Learner Corpus and employed a combination of three syntactic features (CFG production rules, part-of-speech n-grams and function words) with L2 texts to demonstrate their effectiveness in this task.
    
[^41]: ARB：大型语言模型的高级推理基准

    ARB: Advanced Reasoning Benchmark for Large Language Models. (arXiv:2307.13692v1 [cs.CL])

    [http://arxiv.org/abs/2307.13692](http://arxiv.org/abs/2307.13692)

    ARB是一个新型基准，包含了数学、物理、生物、化学和法律领域的高级推理问题。目前的语言模型在这些任务上得分远低于50%，为了提高评估能力，我们引入了基于评分标准的评估方法。

    

    大型语言模型（LLMs）在各种定量推理和知识基准上展示了卓越的性能。然而，尽管在这些领域中还没有达到专家水平，但许多这些基准随着LLMs获得越来越高的分数而失去了效用。我们引入了ARB，一个由多个领域的高级推理问题组成的新型基准。ARB提供比以前的基准更具挑战性的测试，包括数学、物理、生物、化学和法律领域的问题。作为ARB的一部分，我们介绍了一组挑战性的数学和物理问题，需要高级符号推理和领域知识。我们评估了最近的模型，如GPT-4和Claude在ARB上的表现，并证明当前模型在更具挑战性的任务上得分远低于50%。为了改进自动和辅助评估能力，我们引入了基于评分标准的评估方法，允许GPT-4对其自身的中间推理步骤评分。

    Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains. We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields. ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law. As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge. We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks. In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps. Further, we conduct 
    
[^42]: DSTC 11 Track 4中用于开放域对话系统的鲁棒性和多语言自动评估度量的综述

    Overview of Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems at DSTC 11 Track 4. (arXiv:2306.12794v1 [cs.CL])

    [http://arxiv.org/abs/2306.12794](http://arxiv.org/abs/2306.12794)

    本文综述了DSTC 11 Track 4中针对开放域对话系统进行鲁棒性和多语言自动评估的挑战，介绍了提供给参与者的数据集和基线，并总结了表现最佳的系统及其方法。

    

    神经网络的出现和快速发展已经彻底改变了对话系统的研究，并随之引发了关于其自动评估的各种挑战。开放域对话系统的自动评估作为一个开放性挑战已经引起了许多研究人员的关注。尽管一直在努力提高自动评估度量与人类评估的相关性，但很少有尝试评估它们在多个领域和维度上的鲁棒性，而且它们的重点主要集中于英语语言上。所有这些挑战促进了开发可靠的自动评估度量，在各种领域、维度和语言中都能够使用。DSTC11中的这个轨道是促进鲁棒和多语言自动评估度量的持续努力的一部分。本文介绍了提供给参与者的数据集和基线，并讨论了该轨道的提交和结果细节。本文还总结了表现最佳的系统及其方法。

    The advent and fast development of neural networks have revolutionized the research on dialogue systems and subsequently have triggered various challenges regarding their automatic evaluation. Automatic evaluation of open-domain dialogue systems as an open challenge has been the center of the attention of many researchers. Despite the consistent efforts to improve automatic metrics' correlations with human evaluation, there have been very few attempts to assess their robustness over multiple domains and dimensions. Also, their focus is mainly on the English language. All of these challenges prompt the development of automatic evaluation metrics that are reliable in various domains, dimensions, and languages. This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result det
    
[^43]: 增强本地谱时特征用于语音分析

    Boosting Local Spectro-Temporal Features for Speech Analysis. (arXiv:2305.10270v1 [cs.CL])

    [http://arxiv.org/abs/2305.10270](http://arxiv.org/abs/2305.10270)

    该论文介绍了在语音识别中电话分类的问题，并探索了几组可以用于电话分类的本地谱时特征，提出了使用Haar特征和SVM分类的梯度直方图进行电话分类，并给出了一些初步结果。

    

    我们介绍了在语音识别中，电话分类的问题，并探索了几组可以用于电话分类的本地谱时特征。特别地，我们提出了使用两组常用于物体检测的特征（Haar特征和SVM分类的梯度直方图（HoG））进行电话分类的一些初步结果。

    We introduce the problem of phone classification in the context of speech recognition, and explore several sets of local spectro-temporal features that can be used for phone classification. In particular, we present some preliminary results for phone classification using two sets of features that are commonly used for object detection: Haar features and SVM-classified Histograms of Gradients (HoG)
    
[^44]: SANTA：Distantly-Supervised Named Entity Recognition中处理错误和不完整标注噪声的分离策略

    SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition. (arXiv:2305.04076v1 [cs.CL])

    [http://arxiv.org/abs/2305.04076](http://arxiv.org/abs/2305.04076)

    本文提出了一种处理Distantly-Supervised Named Entity Recognition中错误和不完整标注噪声的分离策略，使用不同的模型构建来应对两种类型的噪声。

    

    远程监督命名实体识别有效地减轻了监督设置中耗时且昂贵的注释负担，但是无上下文的匹配过程和知识库的有限覆盖引入了不准确和不完整的标注噪音。本研究提出了使用不同的策略来处理两种类型的噪声的SANTA，以解决由不准确和不完整标注带来的挑战。

    Distantly-Supervised Named Entity Recognition effectively alleviates the burden of time-consuming and expensive annotation in the supervised setting. But the context-free matching process and the limited coverage of knowledge bases introduce inaccurate and incomplete annotation noise respectively. Previous studies either considered only incomplete annotation noise or indiscriminately handle two types of noise with the same strategy. In this paper, we argue that the different causes of two types of noise bring up the requirement of different strategies in model architecture. Therefore, we propose the SANTA to handle these two types of noise separately with (1) Memory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity problem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate decision boundary shifting problem caused by incomplete annotation and a noise-tolerant loss to improve the robustness. Benefiting from our separate tailored strategies, we co
    
[^45]: VISAR：一种带有可视化编程和快速草案原型的人工智能论证写作助手

    VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping. (arXiv:2304.07810v1 [cs.HC])

    [http://arxiv.org/abs/2304.07810](http://arxiv.org/abs/2304.07810)

    VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。

    

    在辩论写作中，作者必须构思分层写作目标，确保其论点的说服力，并通过起草来修订和组织他们的计划。最近大型语言模型（LLM）的进展使得通过聊天界面进行交互式文本生成（例如ChatGPT）成为可能。然而，这种方法常常忽略了隐含的写作上下文和用户意图，缺乏用户控制和自主权，并且提供有限的帮助来进行意义构建和修订写作计划。为了应对这些挑战，我们引入了VISAR，一种AI支持的写作助手系统，旨在帮助作者在其写作上下文中构思和修订分层目标，通过同步文本编辑和可视化编程组织论证结构，并通过论证火花推荐增强说服力。VISAR允许用户使用自动草案原型探索、实验和验证他们的写作计划。一个受控实验室研究证实，VISAR可以通过客观和主观评估，有效地改善用户的写作体验和结果。

    In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confi
    
[^46]: 开放领域聊天机器人的悖论：共同基础是实现人类对话的基础

    The Open-domain Paradox for Chatbots: Common Ground as the Basis for Human-like Dialogue. (arXiv:2303.11708v1 [cs.CL])

    [http://arxiv.org/abs/2303.11708](http://arxiv.org/abs/2303.11708)

    最近研究表明，开放领域聊天机器人通过提供最少信息来实现最大化的“开放性”，在实践中导致了“开放领域悖论”——-要求用户“闲聊任何事情”会导致非常狭窄的对话形式。此研究进一步解释了共同基础理论与实现类似人类对话的关系，并提出了实现共同基础的路径。

    

    大型语言模型的最新进展推动了开放领域聊天机器人的发展，其“开放性”预计通过向用户提供最少信息，包括假定的共同活动，来实现最大化。然而，证据表明效果相反。要求用户“闲聊任何事情”会导致非常狭窄的对话形式，我们称之为“开放领域悖论”。在本文中，我们通过共同基础理论解释了这个悖论作为实现类似人类对话的基础。此外，我们质疑开放领域聊天机器人背后的假设，并确定实现人机对话中共同基础的路径。

    There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The "openness" of the dialogue is expected to be maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to "just chat about anything" results in a very narrow form of dialogue, which we refer to as the "open-domain paradox". In this paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue.
    
[^47]: 量化和建模多模态交互：一种信息分解框架

    Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework. (arXiv:2302.12247v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12247](http://arxiv.org/abs/2302.12247)

    通过引入信息分解框架，我们提供了一种量化和建模多模态交互的方法，通过PID统计量来度量输入模态与输出任务之间的冗余度、独特性和协同性，并引入了两个新的PID统计估计器。

    

    对于解决多模态任务所需的交互如何进行量化？最适合捕捉这些交互的多模态模型是什么？为了回答这些问题，我们提出了一种信息论方法来量化输入模态与输出任务之间的冗余度、独特性和协同性。我们将这三个衡量标准称为多模态分布（或简称PID）的PID统计量，并引入了两个新的PID统计估计器，适用于高维分布。为了验证PID估计，我们在已知PID的合成数据集和大规模多模态基准测试集上进行了大量实验。

    The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and integrating information from different modalities. Despite these empirical advances, there remain fundamental research questions: How can we quantify the interactions that are necessary to solve a multimodal task? Subsequently, what are the most suitable multimodal models to capture these interactions? To answer these questions, we propose an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy relating input modalities with an output task. We term these three measures as the PID statistics of a multimodal distribution (or PID for short), and introduce two new estimators for these PID statistics that scale to high-dimensional distributions. To validate PID estimation, we conduct extensive experiments on both synthetic datasets where the PID is known and on large-scale multimodal benchmarks where PID estimations
    
[^48]: 从非结构化的气候报告中回答气候问卷的方法

    Towards Answering Climate Questionnaires from Unstructured Climate Reports. (arXiv:2301.04253v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04253](http://arxiv.org/abs/2301.04253)

    本研究提出了一种从非结构化的气候报告中回答气候问卷的方法。研究引入两个新的大规模气候问卷数据集，并使用现有结构训练自监督模型，通过实验和人类试验验证了模型的有效性。同时，还引入了一个气候文本分类数据集的基准，以促进气候领域的自然语言处理研究。

    

    尽管气候变化问题紧迫，但在自然语言处理领域对其的关注有限。行动者和政策制定者需要自然语言处理工具，能够有效地将庞大且快速增长的非结构化文本气候报告转化为结构化形式。为了应对这一挑战，我们引入了两个新的大规模气候问卷数据集，并利用其现有结构来训练自监督模型。我们进行实验表明，这些模型能够学习到对训练过程中未见的不同组织类型的气候披露进行泛化。然后，我们使用这些模型在人类试验中帮助将非结构化气候文档中的文本与半结构化问卷对齐。最后，为了支持气候领域进一步的自然语言处理研究，我们引入了一个现有气候文本分类数据集的基准，以更好地评估和比较现有模型。

    The topic of Climate Change (CC) has received limited attention in NLP despite its urgency. Activists and policymakers need NLP tools to effectively process the vast and rapidly growing unstructured textual climate reports into structured form. To tackle this challenge we introduce two new large-scale climate questionnaire datasets and use their existing structure to train self-supervised models. We conduct experiments to show that these models can learn to generalize to climate disclosures of different organizations types than seen during training. We then use these models to help align texts from unstructured climate documents to the semi-structured questionnaires in a human pilot study. Finally, to support further NLP research in the climate domain we introduce a benchmark of existing climate text classification datasets to better evaluate and compare existing models.
    
[^49]: 有理指导下的少样本分类用于检测辱骂语言

    Rationale-Guided Few-Shot Classification to Detect Abusive Language. (arXiv:2211.17046v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.17046](http://arxiv.org/abs/2211.17046)

    本文提出了一种有理指导下的少样本分类（RGFS）方法，用于检测辱骂语言。通过多任务学习框架，该方法可以共同学习有理、目标和标签，并在性能上实现了显著的6%宏F1改进。

    

    在在线社交媒体中，辱骂语言是一个令人担忧的问题。过去关于检测辱骂语言的研究涵盖了不同的平台、语言、人口统计等。然而，在交叉领域评估设置中，使用这些数据集训练的模型表现不佳。为了克服这个问题，一种常见策略是使用目标领域中的少量样本来训练模型，以获得更好的性能（交叉领域少样本训练）。然而，这可能导致模型过度拟合这些样本的特征。一个引人注目的解决方案可能是指导模型朝向有理的方向，即可以证明文本标签的文本段落。已经发现这种方法可以提高各种自然语言处理任务中在领域内的模型性能。在本文中，我们提出了用于检测辱骂语言的有理指导下的少样本分类（RGFS）。我们首先建立一个多任务学习框架，共同学习有理、目标和标签，并实现了显著的6%宏F1改进。

    Abusive language is a concerning problem in online social media. Past research on detecting abusive language covers different platforms, languages, demographies, etc. However, models trained using these datasets do not perform well in cross-domain evaluation settings. To overcome this, a common strategy is to use a few samples from the target domain to train models to get better performance in that domain (cross-domain few-shot training). However, this might cause the models to overfit the artefacts of those samples. A compelling solution could be to guide the models toward rationales, i.e., spans of text that justify the text's label. This method has been found to improve model performance in the in-domain setting across various NLP tasks. In this paper, we propose RGFS (Rationale-Guided Few-Shot Classification) for abusive language detection. We first build a multitask learning setup to jointly learn rationales, targets, and labels, and find a significant improvement of 6% macro F1 o
    
[^50]: 迈向多模态预测自发幽默：一份新颖的数据集和初步结果

    Towards Multimodal Prediction of Spontaneous Humour: A Novel Dataset and First Results. (arXiv:2209.14272v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.14272](http://arxiv.org/abs/2209.14272)

    本研究提出了Passau-SFCH数据集，包含了11小时的录音，用于自发幽默的预测。通过多模态的分析和特征融合，实现了对幽默以及幽默情感的自动识别。

    

    幽默是人类情感和认知的重要元素。其自动理解可以促进更自然的人机交互和人工智能的人性化。目前的幽默检测方法仅基于策划数据，不能满足“现实世界”应用的需求。我们通过引入新颖的Passau-Spontaneous Football Coach Humour（Passau-SFCH）数据集，该数据集包含约11小时的录音，解决了这一缺陷。Passau-SFCH数据集的注释根据Martin的幽默风格问卷提出的幽默存在及其维度（情感和方向）。我们进行了一系列实验，采用预训练的Transformer、卷积神经网络和专家设计的特征。分析了自发幽默识别的每种模态（文本、音频、视频）的性能，并研究了它们之间的互补性。我们的研究结果表明，对于幽默及其情感的自动分析，多模态联合使用效果更好。

    Humour is a substantial element of human affect and cognition. Its automatic understanding can facilitate a more naturalistic human-device interaction and the humanisation of artificial intelligence. Current methods of humour detection are solely based on staged data making them inadequate for 'real-world' applications. We address this deficiency by introducing the novel Passau-Spontaneous Football Coach Humour (Passau-SFCH) dataset, comprising of about 11 hours of recordings. The Passau-SFCH dataset is annotated for the presence of humour and its dimensions (sentiment and direction) as proposed in Martin's Humor Style Questionnaire. We conduct a series of experiments, employing pretrained Transformers, convolutional neural networks, and expert-designed features. The performance of each modality (text, audio, video) for spontaneous humour recognition is analysed and their complementarity is investigated. Our findings suggest that for the automatic analysis of humour and its sentiment, 
    
[^51]: 基于梯度相似度的自适应元学习器，用于少样本文本分类

    Adaptive Meta-learner via Gradient Similarity for Few-shot Text Classification. (arXiv:2209.04702v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.04702](http://arxiv.org/abs/2209.04702)

    提出了一种基于梯度相似度的自适应元学习器方法（AMGS），用于改善少样本文本分类模型的泛化能力。该方法通过自监督辅助任务获得潜在语义表示，并使用梯度相似度约束基学习器的梯度，从而解决了过拟合问题。

    

    少样本文本分类旨在在少样本情况下对文本进行分类。大多数先前的方法采用基于优化的元学习来获得任务分布。然而，由于忽视了少量样本和复杂模型之间的匹配，以及有用和无用任务特征之间的区别，这些方法遭受了过拟合问题。为了解决这个问题，我们提出了一种新颖的基于梯度相似度的自适应元学习器（AMGS）方法，以提高模型对新任务的泛化能力。具体而言，所提出的AMGS从两个方面缓解过拟合问题：（i）通过内循环中的自监督辅助任务获得样本的潜在语义表示并改善模型的泛化能力，（ii）通过基于梯度相似度的自适应元学习器在外循环中对基学习器获得的梯度施加约束。此外，我们对影响因素进行了系统分析。

    Few-shot text classification aims to classify the text under the few-shot scenario. Most of the previous methods adopt optimization-based meta learning to obtain task distribution. However, due to the neglect of matching between the few amount of samples and complicated models, as well as the distinction between useful and useless task features, these methods suffer from the overfitting issue. To address this issue, we propose a novel Adaptive Meta-learner via Gradient Similarity (AMGS) method to improve the model generalization ability to a new task. Specifically, the proposed AMGS alleviates the overfitting based on two aspects: (i) acquiring the potential semantic representation of samples and improving model generalization through the self-supervised auxiliary task in the inner loop, (ii) leveraging the adaptive meta-learner via gradient similarity to add constraints on the gradient obtained by base-learner in the outer loop. Moreover, we make a systematic analysis of the influence
    
[^52]: Turkish自动词汇简化系统

    Automatic Lexical Simplification for Turkish. (arXiv:2201.05878v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.05878](http://arxiv.org/abs/2201.05878)

    本研究介绍了首个针对土耳其语的自动词汇简化系统，利用预训练表示模型BERT和形态特征生成正确的语法和语义简化表达。

    

    本文介绍了首个针对土耳其语的自动词汇简化系统。最近的文本简化工作依赖于手工构建的简化语料库和全面的自然语言处理工具，可以对目标文本进行词汇和句子级别的分析。土耳其语是一种形态丰富的聚合语言，需要考虑诸如处理变格等独特要求。作为资源有限且缺乏工业级工具支持的语言，这使得文本简化任务更加困难。我们提出了一种基于预训练表示模型BERT和形态特征的新文本简化流程，用于生成语法正确且语义合适的词级简化表达。

    In this paper, we present the first automatic lexical simplification system for the Turkish language. Recent text simplification efforts rely on manually crafted simplified corpora and comprehensive NLP tools that can analyse the target text both in word and sentence levels. Turkish is a morphologically rich agglutinative language that requires unique considerations such as the proper handling of inflectional cases. Being a low-resource language in terms of available resources and industrial-strength tools, it makes the text simplification task harder to approach. We present a new text simplification pipeline based on pretrained representation model BERT together with morphological features to generate grammatically correct and semantically appropriate word-level simplifications.
    
[^53]: 从人类的纠错中学习

    Learning From How Humans Correct. (arXiv:2102.00225v14 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2102.00225](http://arxiv.org/abs/2102.00225)

    本研究提出了一种从人类矫正中学习的方法。通过标注数据中的噪声数据，收集纠错信息，并将其注入至深度学习模型中，成功将文本分类准确度提升了1.7个百分点。

    

    在工业自然语言处理应用中，我们手动标注的数据中存在一定数量的噪声数据。我们提出了一种简单的方法来找到噪声数据并手动重新标注它们，同时收集纠错信息。然后，我们提出了一种将人类纠错信息融入深度学习模型的新方法。人类知道如何纠正噪声数据，因此纠错信息可以注入到深度学习模型中。我们在自己的文本分类数据集上进行了实验，该数据集是手动标注的，因为我们重新标注了我们数据集中的噪声数据，以适用于我们的工业应用。实验结果显示，我们的方法将分类准确度从91.7%提升到92.5%。91.7%的准确度是在修正后的数据集上训练的，它将基线准确度从83.3%提升到91.7%。

    In industry NLP application, our manually labeled data has a certain number of noisy data. We present a simple method to find the noisy data and re-label them manually, meanwhile we collect the correction information. Then we present novel method to incorporate the human correction information into deep learning model. Human know how to correct noisy data. So the correction information can be inject into deep learning model. We do the experiment on our own text classification dataset, which is manually labeled, because we re-label the noisy data in our dataset for our industry application. The experiment result shows that our method improve the classification accuracy from 91.7% to 92.5%. The 91.7% accuracy is trained on the corrected dataset, which improve the baseline from 83.3% to 91.7%.
    

