# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ChatGPT is a Potential Zero-Shot Dependency Parser.](http://arxiv.org/abs/2310.16654) | ChatGPT是一个有潜力的零-shot依存解析器，实验结果和语言分析都证明了这一点。 |
| [^2] | [ArTST: Arabic Text and Speech Transformer.](http://arxiv.org/abs/2310.16621) | ArTST是一种用于支持阿拉伯语开源语音技术的预训练模型，通过从头开始的预训练和微调，它在自动语音识别、文本到语音合成和口语方言识别任务中达到了与当前最先进技术相当甚至超过的性能。 |
| [^3] | [Context Does Matter: End-to-end Panoptic Narrative Grounding with Deformable Attention Refined Matching Network.](http://arxiv.org/abs/2310.16616) | 本文主要提出了一种名为DRMN的学习框架，通过引入可变形注意力以融入不同尺度像素的上下文信息，解决了全景叙事对齐中短语与像素不匹配的问题。 |
| [^4] | [Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors.](http://arxiv.org/abs/2310.16609) | 本文提出了一种使用反转录法和错误分类技术的方法，用于评估语音识别错误对自然语言理解模型性能的影响，结果表明合成语音与音频录制对于该方法的结果没有显著变化。 |
| [^5] | [On the Interplay between Fairness and Explainability.](http://arxiv.org/abs/2310.16607) | 公平的NLP模型并不总是依赖于更合理的解释，偏见缓解算法并不总是导致更公平的模型。 |
| [^6] | [Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons.](http://arxiv.org/abs/2310.16582) | 本文介绍了一种新方法，通过无监督建立个性化词典，来定制大型语言模型的个性特征。该方法可以以可插拔的方式结合五个大类因素，实现对个性特征的精确操纵。 |
| [^7] | [WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming Sentences with Contextualized Social Wisdom.](http://arxiv.org/abs/2310.16579) | 本研究探讨了假新闻揭穿领域中一项新任务——检测句子级别的误导性信息。其中的一个挑战是缺乏具有句子级别真实性注释的训练数据集。通过多实例学习（MIL）方法，我们提出了一种Weakly Supervised Detection of Misinforming Se模型。 |
| [^8] | [Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models.](http://arxiv.org/abs/2310.16570) | 这项工作调查了预训练语言模型中的事实知识探测方法和数据集，并提出了分类方案和未来工作方向。 |
| [^9] | [1-PAGER: One Pass Answer Generation and Evidence Retrieval.](http://arxiv.org/abs/2310.16568) | 1-PAGER是第一个使用单一模型和解码过程同时回答问题和检索证据的系统，通过约束解码和证据语料库的利用，达到了与传统的检索和阅读替代方法相比有竞争力的检索和回答准确度。此外，该系统也为可解释的神经检索提供了一种简单易读的搜索路径。 |
| [^10] | [FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning.](http://arxiv.org/abs/2310.16538) | FedTherapist是一种使用联邦学习在智能手机上进行用户生成的语言表达的精神健康监测的系统。它有效地利用了持续语音和键盘输入，并通过上下文感知语言学习方法来提高预测的准确性。在评估中，比较了非语言特征，结果显示FedTherapist在预测抑郁、压力、焦虑和心情方面的表现更好。 |
| [^11] | [R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context.](http://arxiv.org/abs/2310.16535) | R$^3$提示是一种用于在噪声背景下进行CoT推理的新方法，通过复审、改写和解决的思考过程，与大型语言模型交互以进行关键句提取、变量声明和答案预测。 |
| [^12] | [An Early Evaluation of GPT-4V(ision).](http://arxiv.org/abs/2310.16534) | GPT-4V在英文视觉为中心的基准测试上表现出色，但在识别中文文本、处理敏感特征相关问题和语言理解任务上存在挑战。 |
| [^13] | [CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval.](http://arxiv.org/abs/2310.16528) | 这个论文介绍了查理大学在MRL 2023多语言多任务信息检索共享任务中采用的解决方案，并通过翻译测试方法实现了命名实体识别和问题回答的多语言应用，通过使用标签敏感的翻译模型评分候选位置，保持了推断标签在原始语言中的正确位置。 |
| [^14] | [Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting.](http://arxiv.org/abs/2310.16523) | 本文研究了生成式大型语言模型中的人口多样性挑战，并提出了一种新的提示技术CCSV，通过利用模型的多样性推理能力来改善人口多样性，而无需依赖手工制作的示例或提示调整。 |
| [^15] | [OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models.](http://arxiv.org/abs/2310.16517) | OccuQuest是一个用于减轻大型语言模型中的职业偏见的指导调优数据集，它包含了1,000多个职业的110,000+个提示完成对和30,000+个对话，并表现出更加平衡的职业分布。 |
| [^16] | [Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training.](http://arxiv.org/abs/2310.16484) | 通过对语言模型训练过程中的表示空间进行分析，研究发现九个任务中的语言信息在不同阶段和时间点逐渐出现、共享和分化。句法知识在训练的早期阶段迅速习得，而后期的性能提升主要来自开放领域知识和长距离上下文理解的提升。语义和推理任务则受益于更高层次的特化。 |
| [^17] | [CLEX: Continuous Length Extrapolation for Large Language Models.](http://arxiv.org/abs/2310.16450) | CLEX是一种针对大型语言模型的持续长度外推方法，通过将位置嵌入缩放方法推广到连续动态建模，克服了当前方法在特定长度上的局限性。 |
| [^18] | [Diversity Enhanced Narrative Question Generation for Storybooks.](http://arxiv.org/abs/2310.16446) | 本文介绍了一种多问题生成模型（mQG），该模型可以通过关注上下文和问题来生成多样化且可回答的问题。通过对FairytaleQA数据集进行训练和评估，以及在TellMeWhy和SQuAD1.1数据集上进行零-shot适应，mQG在各种评估指标上显示出有希望的结果。这项研究将问题生成的多样性引入故事书领域，为提高理解和参与度提供了新的方法。 |
| [^19] | [DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models.](http://arxiv.org/abs/2310.16436) | DDCoT是一种职责分明的思路链刺激方法，通过负空间刺激保持批判态度，并在多模态推理中结合了关键洞见“保持批判性思考”和“让每个人发挥自己的作用”。 |
| [^20] | [PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization.](http://arxiv.org/abs/2310.16427) | PromptAgent是一个通过战略规划将目标任务与大型语言模型相结合实现优化的方法，能够自主设计与专家手工打造的提示相当的优化方法。 |
| [^21] | [Enhanced Simultaneous Machine Translation with Word-level Policies.](http://arxiv.org/abs/2310.16417) | 本论文提出了一种使用词级策略提升同时机器翻译的方法，并证明了词级策略优于子词级策略，并且提出了一种使用语言模型的方法来改进同时机器翻译模型。 |
| [^22] | [Decoding Stumpers: Large Language Models vs. Human Problem-Solvers.](http://arxiv.org/abs/2310.16411) | 通过对比大型语言模型与人类在难题解决能力上的表现，研究发现新一代大型语言模型在解决难题方面表现出色，超过了人类，但人类在验证解决方案方面具有优势。 |
| [^23] | [Video Referring Expression Comprehension via Transformer with Content-conditioned Query.](http://arxiv.org/abs/2310.16402) | 本论文提出了一种基于内容条件查询的Transformer方法，用于视频指代表达理解。通过创建动态查询，考虑输入视频和语言的影响，来建模多样化的指代对象。同时，对句子中的特定短语进行对齐，以解决当前查询特征忽视跨模态对齐的问题。 |
| [^24] | [Transformer-based Live Update Generation for Soccer Matches from Microblog Posts.](http://arxiv.org/abs/2310.16368) | 本文提出了基于Transformer的方法来从微博帖子中生成足球比赛的实时更新，通过控制更新数量和减少冗余更新，用户可以立即了解比赛进展并享受比赛的激动。 |
| [^25] | [InstructPTS: Instruction-Tuning LLMs for Product Title Summarization.](http://arxiv.org/abs/2310.16361) | InstructPTS是一种用于产品标题摘要的方法，通过指导调节LLMs可根据多种标准生成更准确的摘要，提高了产品名称摘要的质量。 |
| [^26] | [From Simple to Complex: A Progressive Framework for Document-level Informative Argument Extraction.](http://arxiv.org/abs/2310.16358) | 本论文提出了一种简单到复杂的逐步框架用于文档级信息性论证提取，通过计算每个事件的难度并按照简单到复杂的顺序进行提取，可以提供更可靠的记忆，避免在依赖先前事件的不正确预测的情况下引入噪声。 |
| [^27] | [A Multi-Modal Multilingual Benchmark for Document Image Classification.](http://arxiv.org/abs/2310.16356) | 介绍了两个新的多语言数据集(WIKI-DOC和MULTIEURLEX-DOC)，克服了现有数据集的限制，并探索了视觉丰富文档理解和文档AI模型在多标签分类和零样本跨语言迁移方面的局限性。这些发现为未来改进文档AI模型的研究提供了机会。 |
| [^28] | [Unraveling Feature Extraction Mechanisms in Neural Networks.](http://arxiv.org/abs/2310.16350) | 本研究提出了一种基于神经切线核的理论方法，研究神经网络中的特征提取机制。研究发现在梯度下降过程中模型如何利用统计特征，并揭示了激活函数选择对特征提取的影响。 |
| [^29] | [A Comprehensive Evaluation of Constrained Text Generation for Large Language Models.](http://arxiv.org/abs/2310.16343) | 该研究全面评估了大型语言模型在约束文本生成方面的应用，研究了LLM的能力和不足，并提供了未来发展的见解。 |
| [^30] | [RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models.](http://arxiv.org/abs/2310.16340) | RCAgent是一个工具增强的LLM自主代理框架，用于云根本原因分析，能够实现自由格式的数据收集和全面的分析，并在各个方面优于当前方法。 |
| [^31] | [Generative Pre-training for Speech with Flow Matching.](http://arxiv.org/abs/2310.16338) | 本文展示了一种使用流匹配的预训练生成模型，该模型可以适应不同的下游任务并获得强大的性能，通过在60k小时的未转录语音上进行预训练，该模型可以与现有的专家模型在语音增强、分离和合成方面进行匹配或超越。 |
| [^32] | [CoheSentia: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts.](http://arxiv.org/abs/2310.16329) | 本文提出了一个名为CoheSentia的新型基准，用于评估自动生成文本的人类感知连贯性。我们的注释协议包括整体评分和逐句评分两个角度。通过此基准，可以更准确地评估生成文本的连贯性并分析其相关因素。 |
| [^33] | [Samsung R&D Institute Philippines at WMT 2023.](http://arxiv.org/abs/2310.16322) | 本文介绍了三星菲律宾研究与开发中心在WMT 2023中提出的约束机器翻译系统。这些系统在综合数据处理、合成数据训练和在线解码中使用嘈杂通道重排的过程中，用较少的参数表现出与强基线无约束系统相当甚至超过的性能。 |
| [^34] | [DiQAD: A Benchmark Dataset for End-to-End Open-domain Dialogue Assessment.](http://arxiv.org/abs/2310.16319) | 本文发布了一个大规模的对话质量评估数据集（DiQAD），用于自动评估开放域对话质量。该数据集是端到端和人类认知评估数据集，其中包含约100,000个对话。对话质量的评估标准是根据符合人类对话质量判断的维度建立的。数据集可在https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation上公开获取。 |
| [^35] | [URL-BERT: Training Webpage Representations via Social Media Engagements.](http://arxiv.org/abs/2310.16303) | URL-BERT是一种通过社交媒体互动训练网页表示的方法，通过引入新的预训练目标和对比目标，实现了对URL和网页的更好理解和表示。 |
| [^36] | [Is ChatGPT a Good Multi-Party Conversation Solver?.](http://arxiv.org/abs/2310.16301) | 对于多方对话（MPC），目前ChatGPT在某些任务上的表现令人期待，而GPT-4的结果预示着一个有希望的未来。此外，通过引入MPC结构，包括发言人和受话人架构，可以进一步提高性能。 |
| [^37] | [XFEVER: Exploring Fact Verification across Languages.](http://arxiv.org/abs/2310.16278) | XFEVER 数据集是为了在不同语言中对事实验证模型进行基准测试而设计的，实验结果显示多语言语言模型可以有效地构建不同语言的事实验证模型。 |
| [^38] | [CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment.](http://arxiv.org/abs/2310.16271) | CycleAlign提出了一种从语言模型中提炼对齐能力的方法，它通过迭代提炼实现对黑盒模型到白盒模型的转变，解决了语言模型与人类价值对齐的问题。 |
| [^39] | [Attention Lens: A Tool for Mechanistically Interpreting the Attention Head Information Retrieval Mechanism.](http://arxiv.org/abs/2310.16270) | Attention Lens是一种工具，它能够通过学习的注意力头特定转换将注意力头的输出翻译为词汇标记。使用Attention Lens，我们可以解释注意力头在生成最终标记预测中的作用。注意力头在语言模型中扮演着高度专门化的角色。 |
| [^40] | [Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper.](http://arxiv.org/abs/2310.16269) | 本文研究了使用真实新闻机构的评级来创建一个多语言新闻语料库，其中包括粗略的立场注释和自动提取的主题注释。研究表明，在此数据上训练的分类器能够确定大多数未见报纸的社论立场。 |
| [^41] | [Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation.](http://arxiv.org/abs/2310.16263) | 本文介绍了一项针对安全代码生成的综合研究，通过使用经过策划的数据集评估和增强代码大规模语言模型（LLMs），有效解决了使用未经消毒的开源数据训练模型引入安全漏洞的风险。实验结果显示现有模型在安全方面常常被忽视。 |
| [^42] | [The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining.](http://arxiv.org/abs/2310.16261) | 本研究分析了蒙面语言模型预训练的目标函数，并探讨了预训练数据的分布特性对于预训练模型具有更好的样本效率的影响。结果发现，分布特性能够提高样本效率，但不能完全解释模型的泛化能力。此外，通过对真实数据的分析发现分布特性也无法解释自然语言模型的泛化能力。 |
| [^43] | [Speakerly: A Voice-based Writing Assistant for Text Composition.](http://arxiv.org/abs/2310.16251) | Speakerly是一种基于语音的文本创作辅助工具，用户可通过指令或口述与系统进行交互，系统生成格式良好、连贯的文档。该系统使用小型任务特定模型和预训练语言模型，实现快速有效的文本创作，并支持各种输入模式以提高可用性。 |
| [^44] | [GlotLID: Language Identification for Low-Resource Languages.](http://arxiv.org/abs/2310.16248) | GlotLID-M是一个满足广泛覆盖、可靠性和效率要求的语言识别模型，具有1665个可识别语言，并在实验中表现出色。它解决了低资源LID面临的挑战，并有望提高数据集质量和增强访问能力。 |
| [^45] | [ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality.](http://arxiv.org/abs/2310.16242) | 本文介绍了一种名为ZzzGPT的交互式GPT方法，旨在提高睡眠质量。通过利用大型语言模型进行预测和反馈，该方法融合了先进的机器学习和用户导向设计，以提供准确和有价值的结果。 |
| [^46] | [Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting Pre-trained Language Models.](http://arxiv.org/abs/2310.16240) | 本研究提出了一种方法，在预训练语言模型中引入语言结构，通过混合语言专家架构来改进和解释其性能，并且实验证明该方法在参数高效微调中比其他方法表现更好。 |
| [^47] | [TiC-CLIP: Continual Training of CLIP Models.](http://arxiv.org/abs/2310.16226) | 该论文提出了用于训练视觉-语言模型的大规模时间连续 (TiC) 基准，使用这些基准评估了现有模型的时间鲁棒性，并展示了一种简单有效的排练方法来持续训练模型。 |
| [^48] | [CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset.](http://arxiv.org/abs/2310.16225) | CleanCoNLL是一种几乎无噪声的命名实体识别数据集，通过全面重标记和自动一致性检查来纠正CoNLL-03中的注释错误，提高了最先进方法的F1分数，并减少了因注释缺失而误判的情况。 |
| [^49] | [Knowledge Editing for Large Language Models: A Survey.](http://arxiv.org/abs/2310.16218) | 大型语言模型(LLMs)在学术和工业领域具有巨大潜力。本文综述了LLMs的知识编辑问题，强调了需要开发有效和高效的技术来更新预训练LLMs以纳入新知识的重要性。 |
| [^50] | [Background Summarization of Event Timelines.](http://arxiv.org/abs/2310.16197) | 本文提出了一个任务，即生成新闻事件的背景摘要，用于补充每个时间线更新的相关前置事件，通过合并现有数据集并使用最先进的摘要系统建立基准性能。我们还提出了一种以查询为重点的变体来生成背景摘要，并提出了一个基于问答的评估指标来评估摘要质量。 |
| [^51] | [Length is a Curse and a Blessing for Document-level Semantics.](http://arxiv.org/abs/2310.16193) | 本文研究了基于对比学习的模型在长度上的泛化能力，并提出了一个仅依赖于文档长度的无监督学习方法。研究发现，延长文档的长度会加 intensify 达到的高内部相似性，并且这种等向性的表现高度依赖于文本长度范围。基于这些发现，提出了一个简单而通用的文档表示学习框架，用于实现语义鲁棒的句子表示学习。 |
| [^52] | [BLP 2023 Task 2: Sentiment Analysis.](http://arxiv.org/abs/2310.16183) | BLP 2023任务2是关于情感分析的共享任务，吸引了71个参与者。参与者通过各种方法，包括经典机器学习模型和大型语言模型，提交了597个运行结果。本文提供了任务的详细设置和参与者提交系统的概述。 |
| [^53] | [Hidden Citations Obscure True Impact in Science.](http://arxiv.org/abs/2310.16181) | 隐藏引用现象在科学中普遍存在，并且超过了正式引用的数量，表明传统的引文分析方法无法准确评估科学发现的影响力。 |
| [^54] | [Correction with Backtracking Reduces Hallucination in Summarization.](http://arxiv.org/abs/2310.16176) | 本文介绍了一种简单而有效的技术，CoBa，用于减少摘要中的幻觉。该方法通过测量条件词概率和上下文词距离的统计信息进行幻觉检测，并通过直观的回溯法进行减轻。实验证明，CoBa在减少摘要幻觉方面是有效且高效的。 |
| [^55] | [WojoodNER 2023: The First Arabic Named Entity Recognition Shared Task.](http://arxiv.org/abs/2310.16153) | WojoodNER-2023是第一个阿拉伯命名实体识别共享任务，提供了新颖的数据集和子任务，以促进NER方法之间的比较。最终获胜的团队在FlatNER和NestedNER中取得了优秀的性能。 |
| [^56] | [PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering.](http://arxiv.org/abs/2310.16147) | PreWoMe是一种处理长篇问答中信息检索问题的统一方法，通过提取问题中的预设并利用其作为工作记忆来生成反馈和行动，不仅能有效解决误导性问题，而且适用于处理正常问题，证明了在实际问答场景中利用预设、反馈和行动的有效性。 |
| [^57] | [Clinfo.ai: An Open-Source Retrieval-Augmented Large Language Model System for Answering Medical Questions using Scientific Literature.](http://arxiv.org/abs/2310.16146) | Clinfo.ai是一个开源的系统，使用科学文献回答医学问题。研究人员提出了一个信息检索和抽象概括任务，发布了相应的数据集，并进行了评估。 |
| [^58] | [A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing.](http://arxiv.org/abs/2310.16142) | 开发了一个循环神经语言模型，通过使用单个自我注意头紧密模拟了认知理论中假设的记忆系统，并捕捉到人类句子处理中的干扰。 |
| [^59] | [Can You Follow Me? Testing Situational Understanding in ChatGPT.](http://arxiv.org/abs/2310.16135) | 这项研究提出了一种新的合成环境用于测试聊天模型的情景理解能力，通过评估模型追踪和列举环境状态的能力，深入分析了性能模式的根本原因。 |
| [^60] | [GenKIE: Robust Generative Multimodal Document Key Information Extraction.](http://arxiv.org/abs/2310.16131) | GenKIE是一种生成式多模态文档关键信息提取模型，采用了弱监督信号和生成模型的优势，在不需要记号级标注和可自动纠正OCR错误的情况下实现了高效的关键信息提取。 |
| [^61] | [Octopus: A Multitask Model and Toolkit for Arabic Natural Language Generation.](http://arxiv.org/abs/2310.16127) | Octopus是一个用于阿拉伯语自然语言生成的多任务模型和工具包，通过新颖的AraT5v2模型和系统训练，在各种预训练策略下实现了优于竞争基准线的性能。 |
| [^62] | [NADI 2023: The Fourth Nuanced Arabic Dialect Identification Shared Task.](http://arxiv.org/abs/2310.16117) | NADI 2023是第四届Nuanced阿拉伯方言识别共享任务，该任务的目标是推进阿拉伯自然语言处理的最新发展。共有58个团队参与，并成功解决了方言识别和方言到MSA机器翻译的挑战。 |
| [^63] | [Locally Differentially Private Document Generation Using Zero Shot Prompting.](http://arxiv.org/abs/2310.16111) | 本研究提出了一种本地差分隐私文档生成机制，利用预训练的大型语言模型和零阶提示对抗作者去匿名攻击，同时最小化对下游效用的影响。实验证明，该机制在降低攻击成功率的同时能够完全恢复清洁的情感分数，比现有方法更有效。 |
| [^64] | [CR-COPEC: Causal Rationale of Corporate Performance Changes to Learn from Financial Reports.](http://arxiv.org/abs/2310.16095) | CR-COPEC是一个从财务报告中学习企业绩效变化的因果解释的数据集，可以为个人投资者和分析师提供重要的信息资源，同时考虑了不同行业的特征。 |
| [^65] | [WebWISE: Web Interface Control and Sequential Exploration with Large Language Models.](http://arxiv.org/abs/2310.16042) | 本文介绍了一种利用大型语言模型（LLM）自动执行Web软件任务的方法，通过步骤性生成小型程序来实现对点击、滚动和文本输入操作的控制。与其他方法相比，该方法在MiniWob++基准测试中通过一个上下文示例就能达到相似或更好的性能。 |
| [^66] | [Accented Speech Recognition With Accent-specific Codebooks.](http://arxiv.org/abs/2310.15970) | 本研究提出了一种使用具有专门口音代码本的口音适应方法，通过交叉注意力和可训练代码本，用于端到端ASR系统。在实验证明了该方法在已见和未见的口音上都能获得显著的性能提升。 |
| [^67] | [COPF: Continual Learning Human Preference through Optimal Policy Fitting.](http://arxiv.org/abs/2310.15694) | 通过COPF方法，我们不需要重新训练预训练语言模型，而是使用最优策略拟合和函数正则化来持续学习和适应人类偏好的变化。 |
| [^68] | [TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction.](http://arxiv.org/abs/2310.15556) | TCRA-LLM是通过概述压缩和语义压缩两种方法来减少商业大型语言模型推理成本的方案。 |
| [^69] | [FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions.](http://arxiv.org/abs/2310.15421) | FANToM是一个新的基准，用于通过问答在信息不对称的对话环境中压力测试机器的心智理论。这个基准对最先进的大型语言模型来说具有挑战性，即使是具有思维链推理和微调的模型也比人类表现得差。 |
| [^70] | [TaskDiff: A Similarity Metric for Task-Oriented Conversations.](http://arxiv.org/abs/2310.15298) | TaskDiff是一种新颖的对话相似度度量方法，通过使用不同的对话组成部分来计算相似度，取得了优越的性能和鲁棒性。 |
| [^71] | [DISC-FinLLM: A Chinese Financial Large Language Model based on Multiple Experts Fine-tuning.](http://arxiv.org/abs/2310.15205) | 我们提出了一种基于多专家微调的金融大型语言模型DISC-FinLLM，通过赋予模型多轮问答、领域文本处理、数学计算和检索增强生成能力，我们的模型在多个金融场景中表现出更好的性能。 |
| [^72] | [NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling Social Norm Adherence and Violation.](http://arxiv.org/abs/2310.14563) | NormDial是一个高质量的双语合成对话数据集，用于模拟社会规范的遵守和违反。通过引入社会规范遵守检测任务，该数据集能够帮助我们深入了解跨语言和文化背景下对话环境中社会规范的细微差别。 |
| [^73] | [Hunayn: Elevating Translation Beyond the Literal.](http://arxiv.org/abs/2310.13613) | 这项研究介绍了一种超越传统工具的高级英译阿拉伯语翻译器，使用赫尔辛基变压器和纯文学阿拉伯语数据集，表现出色，并强调了其在文化敏感性和语境准确性方面的优势。 |
| [^74] | [Multiscale Superpixel Structured Difference Graph Convolutional Network for VL Representation.](http://arxiv.org/abs/2310.13447) | 本文提出了一种多尺度超像素结构差异图卷积网络（MDGCN）用于视觉语言表征，通过聚类感知相似像素，减少了后续处理的视觉基元数量，并挖掘了更精确的拓扑关系。 |
| [^75] | [InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution.](http://arxiv.org/abs/2310.13276) | 通过反向图卷积进行的鲁棒跨模态检索，解决了表示退化问题，并通过增加数据点之间的距离来有效分离不同模态的表示。 |
| [^76] | [CLAIR: Evaluating Image Captions with Large Language Models.](http://arxiv.org/abs/2310.12971) | CLAIR是一种基于大型语言模型的新方法，用于评估机器生成的图像标题。相对于现有的评估方法，CLAIR在与人类判断的相关性方面表现更好，并针对具体数据集取得了较大改进。 |
| [^77] | [Large Language Model for Multi-objective Evolutionary Optimization.](http://arxiv.org/abs/2310.12541) | 本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。 |
| [^78] | [A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation.](http://arxiv.org/abs/2310.12127) | 本研究通过调查机器翻译模型中的性别偏见问题以及缓解性别偏见的方法来填补现有研究的空白。研究发现指导微调模型在默认为男性翻译上存在性别偏见，同时忽视了指示职业性别的代词，并提出了一些可行的缓解策略。 |
| [^79] | [MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models.](http://arxiv.org/abs/2310.11954) | MusicAgent是一个使用大型语言模型的AI代理，通过集成音乐相关工具和自主工作流程，帮助用户自动分析需求并调用合适的工具进行音乐处理。 |
| [^80] | [VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System.](http://arxiv.org/abs/2310.11069) | VoxArabica是一个稳健的方言感知阿拉伯语音识别系统，通过开发和演示，实现了阿拉伯语方言识别和自动语音识别。该系统训练了各种模型用于不同方言的识别，并提供了多种功能的网络界面。 |
| [^81] | [NLP for Crypto-Asset Regulation: A Roadmap.](http://arxiv.org/abs/2310.10333) | 这篇论文介绍了自然语言处理在加密资产监管中的应用，并提出了两个贡献。首先，调查了对未受监管的加密资产白皮书进行文本分析的现有应用，并发现了研究空白。然后，分析了欧盟的加密资产市场法规引入的变化，探讨了在新的监管框架内整合自然语言处理的机遇和挑战。这些发现为未来的研究提供了基础，有潜力使监管机构、加密资产发行者和投资者受益。 |
| [^82] | [KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models.](http://arxiv.org/abs/2310.09725) | KGQuiz是一个知识密集型基准测试，通过涵盖三个知识领域和五个任务，全面评估了大型语言模型(LLMs)的知识泛化能力。 |
| [^83] | [Improving Summarization with Human Edits.](http://arxiv.org/abs/2310.05857) | 本文介绍了一种改进摘要生成的方法，使用人工编辑的反馈数据，并通过序列对齐（不）似然训练(SALT)技术将人工编辑数据与模型生成数据结合起来。实验证明了这种方法在医学领域摘要生成中的有效性。 |
| [^84] | [An Investigation of LLMs' Inefficacy in Understanding Converse Relations.](http://arxiv.org/abs/2310.05163) | 本论文调查了LLMs在理解反向关系方面的无效性。作者引入了一个名为ConvRe的新基准，专注于逆向关系。通过两个任务Re2Text和Text2Re，作者评估了LLMs确定关系和相关文本之间匹配能力。实验结果揭示了LLMs在此方面的限制。 |
| [^85] | [Evaluating Hallucinations in Chinese Large Language Models.](http://arxiv.org/abs/2310.03368) | 本研究评估了中文大型语言模型中的幻觉现象，通过建立HalluQA基准测试和使用GPT-4进行自动评估方法，发现18个模型的非幻觉率低于50%。研究分析了不同类型模型中的幻觉类型和原因。 |
| [^86] | [OceanGPT: A Large Language Model for Ocean Science Tasks.](http://arxiv.org/abs/2310.02031) | OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。 |
| [^87] | [Overview of the BioLaySumm 2023 Shared Task on Lay Summarization of Biomedical Research Articles.](http://arxiv.org/abs/2309.17332) | 这项研究报道了BioLaySumm 2023共享任务的结果，该任务旨在开发抽象化摘要模型，能够在可控或不可控的环境中生成常规摘要，有两个子任务：常规摘要和可读性控制的摘要。共有20个团队参与了该任务。 |
| [^88] | [Reproducing Whisper-Style Training Using an Open-Source Toolkit and Publicly Available Data.](http://arxiv.org/abs/2309.13876) | 本研究复现了Whisper风格的训练，使用开源工具和公开可用数据开发了一个名为OWSM的模型，支持更多的翻译方向并且更高效地训练。 |
| [^89] | [NJUNLP's Participation for the WMT2023 Quality Estimation Shared Task.](http://arxiv.org/abs/2309.13230) | NJUNLP团队对WMT2023质量评估共享任务进行了投稿，通过使用伪数据方法和核心超参数的实验研究，他们的模型在英德语言对的质量预测和错误跨度检测上取得了最佳结果。 |
| [^90] | [Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model.](http://arxiv.org/abs/2309.09357) | 本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。 |
| [^91] | [Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences.](http://arxiv.org/abs/2309.06578) | 本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。 |
| [^92] | [Task-Based MoE for Multitask Multilingual Machine Translation.](http://arxiv.org/abs/2308.15772) | 本论文介绍了一种基于任务的混合专家模型，将任务信息与MoE模型相结合，在多任务多语言机器翻译中取得了优越的结果，并且能够高效地应用于新的任务。 |
| [^93] | [SeamlessM4T-Massively Multilingual & Multimodal Machine Translation.](http://arxiv.org/abs/2308.11596) | 本文介绍了SeamlessM4T，这是一个支持多语言和多模态机器翻译的模型，通过使用大量语音数据和自监督学习，实现了统一的语音到语音翻译、语音到文本翻译、文本到语音翻译和文本到文本翻译，以及自动语音识别的功能。 |
| [^94] | [Can Knowledge Graphs Simplify Text?.](http://arxiv.org/abs/2308.06975) | 提出了一种KGSimple方法，将知识图谱技术应用于无监督文本简化，实现从知识图谱开始生成简明文本，保留重要信息并输出流畅且描述性的句子。 |
| [^95] | [AgentBench: Evaluating LLMs as Agents.](http://arxiv.org/abs/2308.03688) | AgentBench是一个用于评估LLMs作为代理人的多维度基准，发现在复杂环境中，商业LLMs在充当代理人方面表现强劲，但与开源竞争对手相比，存在显著性能差距。该研究揭示了LLMs在长期推理、决策和指令遵循能力上的瓶颈。 |
| [^96] | [A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue Information Extraction.](http://arxiv.org/abs/2307.16200) | 本论文提出了一个知识增强的两阶段生成框架（KTGF）用于医学对话信息提取。通过两个阶段的生成，分别生成医学对话中的术语和每个术语的状态，从而更好地建模术语之间的关系。 |
| [^97] | [Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation.](http://arxiv.org/abs/2307.15776) | 本文提出了一种选择和增强的方法来改进文本增强的知识图谱嵌入，通过多任务框架选择相关的文本描述，并对知识图谱嵌入进行对齐或增强。 |
| [^98] | [WebArena: A Realistic Web Environment for Building Autonomous Agents.](http://arxiv.org/abs/2307.13854) | WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。 |
| [^99] | [Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding.](http://arxiv.org/abs/2306.02858) | Video-LLaMA是一个多模态框架，利用已有的预训练模型，解决了视频中的视觉和听觉的理解问题，其中Video Q-former和Audio Q-former用于处理视频中的视觉与时间变化和音频信号的问题。 |
| [^100] | [Training Priors Predict Text-To-Image Model Performance.](http://arxiv.org/abs/2306.01755) | 本文测试了文本到图像模型对于训练先验的依赖程度，发现模型能够更好地生成与训练数据中出现频率更高的三元组对齐的图像，但这也会降低其生成以翻转三元组为基础的图像质量。 |
| [^101] | [Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction.](http://arxiv.org/abs/2306.01439) | 该论文介绍了一种名为NUDGE的策略，利用训练好的基于神经网络的代理来引导逻辑规则的搜索，实现了可解释和可解释的策略。 |
| [^102] | [Making the Implicit Explicit: Implicit Content as a First Class Citizen in NLP.](http://arxiv.org/abs/2305.14583) | 该研究通过将自然语言处理的重点放在隐式内容上，提出了一种通过推理和分解方法降低自然语言处理复杂度的新方法，并在嵌入，计算政治学和构建发现方面实现了显著的改进和应用。 |
| [^103] | [Is a Prestigious Job the same as a Prestigious Country? A Case Study on Multilingual Sentence Embeddings and European Countries.](http://arxiv.org/abs/2305.14482) | 本文研究了多语句子嵌入如何捕捉欧洲国家和职业，并发现嵌入中最突出的国家特征是其GPD经济实力。本研究中的大部分国家维度与职业维度不相关，但一种模型表现出职业声望和原籍国之间的联系，这是一种潜在的基于国籍的歧视。 |
| [^104] | [Image Manipulation via Multi-Hop Instructions -- A New Dataset and Weakly-Supervised Neuro-Symbolic Approach.](http://arxiv.org/abs/2305.14410) | 该论文提出了一个基于神经符号概念学习的图像操作系统NeuroSIM，它可以通过多跳指令在多物体场景中执行复杂的推理，只需要弱监督的数据集，并创建了一个新的数据集。该系统具有很高的竞争力或超过SOTA基线。 |
| [^105] | [Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality.](http://arxiv.org/abs/2305.13812) | 本研究提出了一种基于场景图的对比学习框架，通过将从文本中解析出的场景图视为图像场景图的代理，并对图进行分解和增强，从简单到复杂的对比学习以将各种复杂度的句子对齐到同一幅图像上，同时在场景图空间中提出了新的负样本挖掘技术，以改善视觉语言组合能力。 |
| [^106] | [Asking Clarification Questions to Handle Ambiguity in Open-Domain QA.](http://arxiv.org/abs/2305.13808) | 本文提出了一种解决开放域QA中歧义问题的方法：通过提问澄清来确定最符合用户意图的解释。 |
| [^107] | [A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why?.](http://arxiv.org/abs/2305.12920) | 本研究提出了一个系统框架来分析自然语言处理领域研究主题的演变趋势，揭示了任务和方法是驱动研究的主要因素，而数据集和评估指标的影响较小。 |
| [^108] | [Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation.](http://arxiv.org/abs/2305.12786) | 本论文提出了一种名为Bi-ACL的框架，它使用目标语单语数据和双语词典来解决多语言机器翻译中的数据不平衡和表示衰减问题。实验证明该方法在长尾语种中效果更好。 |
| [^109] | [TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks.](http://arxiv.org/abs/2305.11430) | 本文提出了一个通用分类法，可以用来设计具有特定属性的提示来执行各种复杂任务，从而解决了LLM在执行复杂任务方面的性能变异巨大的问题。 |
| [^110] | [DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining.](http://arxiv.org/abs/2305.10429) | DoReMi方法使用分组分布式鲁棒优化训练小型代理模型以产生域权重，再使用这些权重重新采样数据集训练大型模型，相比使用默认权重的基线模型，在The Pile和GLaM数据集上平均提高了6.5%和4.7%的few-shot下游准确度，分别使用2.6倍和相同的训练步骤达到基线准确度。 |
| [^111] | [FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy.](http://arxiv.org/abs/2305.10307) | FACE是一组可以有效识别人类和模型之间差距的度量标准。它基于傅里叶分析和交叉熵估计，可以反映模型大小、解码采样方法和人类评分。 |
| [^112] | [StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure.](http://arxiv.org/abs/2305.05588) | 本文开发了StrAE框架，该框架利用句子结构无监督地学习多级节点嵌入，并且发现使用显式结构可以提高嵌入表现，新的对比目标优于标准的交叉熵目标。同时，完全忠实于结构确实能够根据相应模型的性能消除结构类型之间的歧义。 |
| [^113] | [API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs.](http://arxiv.org/abs/2304.08244) | API-Bank是一个针对工具增强的大型语言模型的基准测试，通过解决三个关键问题来评估LLMs的能力，并展示了GPT-3.5的改进能力。 |
| [^114] | [Goal Driven Discovery of Distributional Differences via Language Descriptions.](http://arxiv.org/abs/2302.14233) | 本论文提出了一个新的任务D5，通过目标驱动的方式自动发现两个大型语料库之间的差异。作者构建了一个D5系统，并提出了一套统一的评估指标来衡量其性能。通过实验证明，语言模型可以使用目标驱动的方法来发现语料库差异。 |
| [^115] | [Knowledge Distillation $\approx$ Label Smoothing: Fact or Fallacy?.](http://arxiv.org/abs/2301.12609) | 知识蒸馏和标签平滑被认为是等价的方法，但实验证明它们对模型置信度的影响方向完全相反。知识蒸馏不仅传递知识，还传递了自信心。 |
| [^116] | [JASMINE: Arabic GPT Models for Few-Shot Learning.](http://arxiv.org/abs/2212.10755) | JASMINE是一组功能强大的阿拉伯自回归Transformer语言模型，预训练于大规模多样的阿拉伯文本数据集，具有在少样本学习上表现出色的能力。 |
| [^117] | [Towards multi-document summarization in the open-domain.](http://arxiv.org/abs/2212.10526) | 本论文针对"开放领域"的多文档摘要任务进行研究，发现最先进的摘要器在此情境下性能下降严重，但进行额外的开放领域的训练可以降低对不完美检索的敏感性。 |
| [^118] | [Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks.](http://arxiv.org/abs/2212.09912) | 本论文发现了在训练生成式模型时常被忽视的标记一致性问题的重要性，并提出了一个简单且有效的解决方案。通过一致的标记化，模型在抽取型问答任务上表现更好，在领域内和领域外的数据集上平均 F2 增益为 +1.7，同时具有更快的收敛速度和更少的不相关输出生成。 |
| [^119] | [What to Read in a Contract? Party-Specific Summarization of Legal Obligations, Entitlements, and Prohibitions.](http://arxiv.org/abs/2212.09825) | 本论文提出了一种用于法律合同的各方特定摘要提取任务，旨在帮助更快地审查和理解重要的权利和义务。通过使用法律专家注释的数据集和基于流水线的摘要系统，我们证明了摘要中引入领域特定重要性的必要性。 |
| [^120] | [GLM-130B: An Open Bilingual Pre-trained Model.](http://arxiv.org/abs/2210.02414) | GLM-130B是一个具有1300亿参数的开源双语预训练模型，能够超越GPT-3和最大的中文语言模型ERNIE TITAN 3.0 260B，在多个基准测试中表现出色。 |
| [^121] | [Is Attention always needed? A Case Study on Language Identification from Speech.](http://arxiv.org/abs/2110.03427) | 本研究提出了一种基于卷积循环神经网络的语言识别方法，使用梅尔频率倒谱系数特征。与现有的方法进行了比较分析，并得出了一些结论。 |
| [^122] | [A Targeted Assessment of Incremental Processing in Neural LanguageModels and Humans.](http://arxiv.org/abs/2106.03232) | 本研究通过收集了人类和神经语言模型在逐词反应时间上的数据进行了比较，发现无论是人类还是模型，都在语法错误句子区域表现出了增加的处理困难。然而，模型在预测语法和非语法句子之间增量处理困难差异的幅度上存在系统性低估。 |
| [^123] | [GPT Understands, Too.](http://arxiv.org/abs/2103.10385) | 提出了一种方法P-Tuning，通过使用可学习的连续提示嵌入和离散提示的拼接，稳定了预训练语言模型（PLM）的训练过程，并在多种自然语言理解任务上显著提高了性能。 |

# 详细

[^1]: ChatGPT是一个潜在的零-shot依存解析器

    ChatGPT is a Potential Zero-Shot Dependency Parser. (arXiv:2310.16654v1 [cs.CL])

    [http://arxiv.org/abs/2310.16654](http://arxiv.org/abs/2310.16654)

    ChatGPT是一个有潜力的零-shot依存解析器，实验结果和语言分析都证明了这一点。

    

    预训练语言模型已经广泛应用于依存解析任务，并在解析性能方面取得了显著提升。然而，目前还不清楚在零-shot情景中，预训练语言模型是否能够在不引入额外解析器结构的情况下自发地展示出依存解析能力。本文提出了利用大型语言模型如ChatGPT来探索依存解析能力并进行语言分析的方法。实验结果表明，ChatGPT是一个潜在的零-shot依存解析器，并且语言分析还展示了一些独特的解析输出偏好。

    Pre-trained language models have been widely used in dependency parsing task and have achieved significant improvements in parser performance. However, it remains an understudied question whether pre-trained language models can spontaneously exhibit the ability of dependency parsing without introducing additional parser structure in the zero-shot scenario. In this paper, we propose to explore the dependency parsing ability of large language models such as ChatGPT and conduct linguistic analysis. The experimental results demonstrate that ChatGPT is a potential zero-shot dependency parser, and the linguistic analysis also shows some unique preferences in parsing outputs.
    
[^2]: ArTST: 阿拉伯文本和语音变换器

    ArTST: Arabic Text and Speech Transformer. (arXiv:2310.16621v1 [cs.CL])

    [http://arxiv.org/abs/2310.16621](http://arxiv.org/abs/2310.16621)

    ArTST是一种用于支持阿拉伯语开源语音技术的预训练模型，通过从头开始的预训练和微调，它在自动语音识别、文本到语音合成和口语方言识别任务中达到了与当前最先进技术相当甚至超过的性能。

    

    我们提出了一种用于支持阿拉伯语开源语音技术的预训练阿拉伯文本和语音变换器ArTST。该模型架构遵循最近发布的英文统一模态框架SpeechT5，并且专注于现代标准阿拉伯语（MSA），计划将模型扩展到未来版本的方言和混合阿拉伯语。我们从头开始在MSA语音和文本数据上进行了模型的预训练，并对以下任务进行了微调：自动语音识别（ASR）、文本到语音合成（TTS）和口语方言识别。通过与SpeechT5以及先前报道的这些任务的结果进行比较，ArTST在所有三个任务中的表现与当前最先进的技术持平或超过。此外，我们发现我们的预训练有助于泛化，这在低资源TTS任务中特别明显。预训练模型以及微调的ASR和TTS模型

    We present ArTST, a pre-trained Arabic text and speech transformer for supporting open-source speech technologies for the Arabic language. The model architecture follows the unified-modal framework, SpeechT5, that was recently released for English, and is focused on Modern Standard Arabic (MSA), with plans to extend the model for dialectal and code-switched Arabic in future editions. We pre-trained the model from scratch on MSA speech and text data, and fine-tuned it for the following tasks: Automatic Speech Recognition (ASR), Text-To-Speech synthesis (TTS), and spoken dialect identification. In our experiments comparing ArTST with SpeechT5, as well as with previously reported results in these tasks, ArTST performs on a par with or exceeding the current state-of-the-art in all three tasks. Moreover, we find that our pre-training is conducive for generalization, which is particularly evident in the low-resource TTS task. The pre-trained model as well as the fine-tuned ASR and TTS models
    
[^3]: 上下文确实很重要：具有可变形注意力精细匹配网络的端到端全景叙事对齐

    Context Does Matter: End-to-end Panoptic Narrative Grounding with Deformable Attention Refined Matching Network. (arXiv:2310.16616v1 [cs.CV])

    [http://arxiv.org/abs/2310.16616](http://arxiv.org/abs/2310.16616)

    本文主要提出了一种名为DRMN的学习框架，通过引入可变形注意力以融入不同尺度像素的上下文信息，解决了全景叙事对齐中短语与像素不匹配的问题。

    

    全景叙事对齐（PNG）是一种新兴的视觉对齐任务，旨在基于密集叙事标题在图像中分割视觉对象。当前最先进的方法首先通过聚合最相似的$k$个图像像素来改进短语的表示，然后将经过改进的文本表示与图像特征图的像素进行匹配，以生成分割结果。然而，简单地聚合采样的图像特征忽略了上下文信息，这可能导致短语与像素的不匹配。在本文中，我们提出了一种新颖的学习框架，称为可变形注意力精细匹配网络（DRMN），其主要思想是在特征学习的迭代过程中引入可变形注意力，以融入不同尺度像素的重要上下文信息。DRMN在更新了最相似的$k$个像素的特征表示后，使用可变形注意力网络对像素进行迭代重新编码。因此，DRMN可以实现一个...

    Panoramic Narrative Grounding (PNG) is an emerging visual grounding task that aims to segment visual objects in images based on dense narrative captions. The current state-of-the-art methods first refine the representation of phrase by aggregating the most similar $k$ image pixels, and then match the refined text representations with the pixels of the image feature map to generate segmentation results. However, simply aggregating sampled image features ignores the contextual information, which can lead to phrase-to-pixel mis-match. In this paper, we propose a novel learning framework called Deformable Attention Refined Matching Network (DRMN), whose main idea is to bring deformable attention in the iterative process of feature learning to incorporate essential context information of different scales of pixels. DRMN iteratively re-encodes pixels with the deformable attention network after updating the feature representation of the top-$k$ most similar pixels. As such, DRMN can lead to a
    
[^4]: 作为评估自然语言理解模型对语音识别错误鲁棒性的方法的反转录法

    Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors. (arXiv:2310.16609v1 [cs.CL])

    [http://arxiv.org/abs/2310.16609](http://arxiv.org/abs/2310.16609)

    本文提出了一种使用反转录法和错误分类技术的方法，用于评估语音识别错误对自然语言理解模型性能的影响，结果表明合成语音与音频录制对于该方法的结果没有显著变化。

    

    在口语对话系统中，自然语言理解模型之前是一个可能影响其性能的语音识别系统。本文提出了一种用于研究语音识别错误对自然语言理解模型性能影响的方法。该方法将反转录程序与细粒度的技术相结合，用于对影响NLU模型性能的错误进行分类。该方法依赖于使用合成语音进行NLU评估。我们证明在重要程度上，将合成语音用于音频录制的替代方法不会显著改变所提出技术的结果。

    In a spoken dialogue system, an NLU model is preceded by a speech recognition system that can deteriorate the performance of natural language understanding. This paper proposes a method for investigating the impact of speech recognition errors on the performance of natural language understanding models. The proposed method combines the back transcription procedure with a fine-grained technique for categorizing the errors that affect the performance of NLU models. The method relies on the usage of synthesized speech for NLU evaluation. We show that the use of synthesized speech in place of audio recording does not change the outcomes of the presented technique in a significant way.
    
[^5]: 公平性与可解释性之间的相互作用

    On the Interplay between Fairness and Explainability. (arXiv:2310.16607v1 [cs.CL])

    [http://arxiv.org/abs/2310.16607](http://arxiv.org/abs/2310.16607)

    公平的NLP模型并不总是依赖于更合理的解释，偏见缓解算法并不总是导致更公平的模型。

    

    为了构建可靠和值得信赖的自然语言处理(NLP)应用，模型需要在不同的人口统计数据中既具有公平性又可解释。通常，这两个目标，即公平性和可解释性，会被独立地进行优化和/或研究。相反，我们认为未来可信的NLP系统应该同时考虑两者。在这项工作中，我们进行了首次研究，以了解它们如何相互影响：更公平的模型是否依赖于更合理的解释？反之亦然。为此，我们在两个英语多类文本分类数据集BIOS和ECtHR上进行实验，这些数据集分别提供了有关性别和国籍的信息，以及人工标注的解释。我们使用多种方法对预训练语言模型进行微调，包括(i)偏见缓解，旨在提高公平性；(ii)解释提取，旨在产生合理的解释。我们发现，偏见缓解算法并不总是导致更公平的模型。此外，我们还发现

    In order to build reliable and trustworthy NLP applications, models need to be both fair across different demographics and explainable. Usually these two objectives, fairness and explainability, are optimized and/or examined independently of each other. Instead, we argue that forthcoming, trustworthy NLP systems should consider both. In this work, we perform a first study to understand how they influence each other: do fair(er) models rely on more plausible rationales? and vice versa. To this end, we conduct experiments on two English multi-class text classification datasets, BIOS and ECtHR, that provide information on gender and nationality, respectively, as well as human-annotated rationales. We fine-tune pre-trained language models with several methods for (i) bias mitigation, which aims to improve fairness; (ii) rationale extraction, which aims to produce plausible explanations. We find that bias mitigation algorithms do not always lead to fairer models. Moreover, we discover that 
    
[^6]: 通过无监督建立个性化词典来定制大型语言模型的个性特征

    Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons. (arXiv:2310.16582v1 [cs.CL])

    [http://arxiv.org/abs/2310.16582](http://arxiv.org/abs/2310.16582)

    本文介绍了一种新方法，通过无监督建立个性化词典，来定制大型语言模型的个性特征。该方法可以以可插拔的方式结合五个大类因素，实现对个性特征的精确操纵。

    

    个性在塑造人类表达模式方面起着关键作用，赋予和操纵大型语言模型（LLM）的个性特征在提升用户体验方面具有重大潜力。然而，先前的方法要么依赖于在富含个性表达的语料库上对LLM进行微调，要么需要手动制作提示来诱导LLM产生个性化回应。前者需要大量时间和资源来收集足够的训练样本，而后者可能无法精确操纵个性特征以达到细粒度的水平（例如，在减少开放性的同时提高宜人性）。在这项研究中，我们介绍了一种新的方法来定制LLM中的个性特征，允许以可插拔的方式结合五个大类因素（即开放性、责任心、外向性、宜人性和神经质）的任意组合。

    Personality plays a pivotal role in shaping human expression patterns, and empowering and manipulating large language models (LLMs) with personality traits holds significant promise in enhancing the user experience of LLMs. However, prior approaches either rely on fine-tuning LLMs on a corpus enriched with personalized expressions or necessitate the manual crafting of prompts to induce LLMs to produce personalized responses. The former approaches demand substantial time and resources for collecting sufficient training examples while the latter might fail in enabling the precise manipulation of the personality traits at a fine-grained level (e.g., achieving high agreeableness while reducing openness). In this study, we introduce a novel approach for tailoring personality traits within LLMs, allowing for the incorporation of any combination of the Big Five factors (i.e., openness, conscientiousness, extraversion, agreeableness, and neuroticism) in a pluggable manner. This is achieved by 
    
[^7]: WSDMS: 通过上下文化的社交智慧实现弱监督检测误导性句子来揭穿假新闻

    WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming Sentences with Contextualized Social Wisdom. (arXiv:2310.16579v1 [cs.CL])

    [http://arxiv.org/abs/2310.16579](http://arxiv.org/abs/2310.16579)

    本研究探讨了假新闻揭穿领域中一项新任务——检测句子级别的误导性信息。其中的一个挑战是缺乏具有句子级别真实性注释的训练数据集。通过多实例学习（MIL）方法，我们提出了一种Weakly Supervised Detection of Misinforming Se模型。

    

    最近几年，我们目睹了在社交媒体上迅速传播并令公众震惊的虚假和未经证实的信息（即谣言）的爆发。谣言可以引发社交媒体用户之间多样化但大多具有争议性的立场表达。谣言验证和立场检测是不同但相关的任务。假新闻揭穿主要关注确定新闻文章的真实性，这过于简化了问题，因为假新闻经常结合了真实性和虚假性的元素。因此，识别文章中特定的误导性信息实例变得至关重要。在这项研究中，我们调查了假新闻揭穿领域中的一项新任务，即检测句子级别的误导性信息。这项任务面临的主要挑战之一是缺乏具有句子级别真实性注释的训练数据集。受到多实例学习（MIL）方法的启发，我们提出了一种名为Weakly Supervised Detection of Misinforming Se的模型。

    In recent years, we witness the explosion of false and unconfirmed information (i.e., rumors) that went viral on social media and shocked the public. Rumors can trigger versatile, mostly controversial stance expressions among social media users. Rumor verification and stance detection are different yet relevant tasks. Fake news debunking primarily focuses on determining the truthfulness of news articles, which oversimplifies the issue as fake news often combines elements of both truth and falsehood. Thus, it becomes crucial to identify specific instances of misinformation within the articles. In this research, we investigate a novel task in the field of fake news debunking, which involves detecting sentence-level misinformation. One of the major challenges in this task is the absence of a training dataset with sentence-level annotations regarding veracity. Inspired by the Multiple Instance Learning (MIL) approach, we propose a model called Weakly Supervised Detection of Misinforming Se
    
[^8]: 给我事实！关于预训练语言模型中事实知识探测的调查

    Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models. (arXiv:2310.16570v1 [cs.CL])

    [http://arxiv.org/abs/2310.16570](http://arxiv.org/abs/2310.16570)

    这项工作调查了预训练语言模型中的事实知识探测方法和数据集，并提出了分类方案和未来工作方向。

    

    预训练语言模型(PLMs)在世界知识丰富的无标记数据上进行训练。这一事实引起了社区对于量化PLMs中存在的事实知识量的兴趣，因为这解释了它们在下游任务中的性能，同时可能证明它们作为知识库使用的合理性。在这项工作中，我们调查了用于探测PLMs事实知识的方法和数据集。我们的贡献有：(1) 我们提出了一个基于输入、输出和被探测的PLMs如何适应的分类方案；(2) 我们提供了用于事实探测的数据集概述；(3) 我们综合了关于PLMs中知识保留和提示优化的观点，分析了将PLMs作为知识库应用的障碍，并提出了未来工作的方向。

    Pre-trained Language Models (PLMs) are trained on vast unlabeled data, rich in world knowledge. This fact has sparked the interest of the community in quantifying the amount of factual knowledge present in PLMs, as this explains their performance on downstream tasks, and potentially justifies their use as knowledge bases. In this work, we survey methods and datasets that are used to probe PLMs for factual knowledge. Our contributions are: (1) We propose a categorization scheme for factual probing methods that is based on how their inputs, outputs and the probed PLMs are adapted; (2) We provide an overview of the datasets used for factual probing; (3) We synthesize insights about knowledge retention and prompt optimization in PLMs, analyze obstacles to adopting PLMs as knowledge bases and outline directions for future work.
    
[^9]: 1-PAGER: 一次通行的回答生成和证据检索

    1-PAGER: One Pass Answer Generation and Evidence Retrieval. (arXiv:2310.16568v1 [cs.CL])

    [http://arxiv.org/abs/2310.16568](http://arxiv.org/abs/2310.16568)

    1-PAGER是第一个使用单一模型和解码过程同时回答问题和检索证据的系统，通过约束解码和证据语料库的利用，达到了与传统的检索和阅读替代方法相比有竞争力的检索和回答准确度。此外，该系统也为可解释的神经检索提供了一种简单易读的搜索路径。

    

    我们提出了1-Pager，这是第一个使用单个基于Transformer的模型和解码过程同时回答问题和检索证据的系统。1-Pager使用约束解码逐步分割检索语料库，选择文档和答案字符串，并且我们展示出在检索和回答准确度度量方面，这与可比较的检索和阅读替代方法相比是有竞争力的。1-Pager还通过将预测结果基于证据语料库，胜过了等效的闭书问答模型。虽然1-Pager的表现还不及阅读多个文档后生成答案的更昂贵系统，但我们认为它是向归因生成迈出的重要一步，将检索融入到当前在自然语言处理中占主导地位的序列到序列范式中。我们还展示了用于分割语料库的搜索路径易于阅读和理解，为可解释的神经检索铺平了道路。

    We present 1-Pager the first system that answers a question and retrieves evidence using a single Transformer-based model and decoding process. 1-Pager incrementally partitions the retrieval corpus using constrained decoding to select a document and answer string, and we show that this is competitive with comparable retrieve-and-read alternatives according to both retrieval and answer accuracy metrics. 1-Pager also outperforms the equivalent closed-book question answering model, by grounding predictions in an evidence corpus. While 1-Pager is not yet on-par with more expensive systems that read many more documents before generating an answer, we argue that it provides an important step toward attributed generation by folding retrieval into the sequence-to-sequence paradigm that is currently dominant in NLP. We also show that the search paths used to partition the corpus are easy to read and understand, paving a way forward for interpretable neural retrieval.
    
[^10]: FedTherapist：通过联邦学习在智能手机上使用用户生成的语言表达进行精神健康监测

    FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning. (arXiv:2310.16538v1 [cs.CL])

    [http://arxiv.org/abs/2310.16538](http://arxiv.org/abs/2310.16538)

    FedTherapist是一种使用联邦学习在智能手机上进行用户生成的语言表达的精神健康监测的系统。它有效地利用了持续语音和键盘输入，并通过上下文感知语言学习方法来提高预测的准确性。在评估中，比较了非语言特征，结果显示FedTherapist在预测抑郁、压力、焦虑和心情方面的表现更好。

    

    精神科医生通过患者的语言使用来诊断精神疾病。但由于数据隐私问题，现有的被动精神健康监测系统使用手机设备的活动、应用使用和位置等替代特征。我们提出了FedTherapist，一种利用联邦学习以隐私保护方式使用持续语音和键盘输入的移动精神健康监测系统。我们通过比较不同模型设计的性能和开销来克服在智能手机上进行设备内语言模型训练的复杂性。我们还提出了一种上下文感知语言学习（CALL）方法，以有效利用智能手机的大规模和嘈杂文本进行精神健康信号感知。我们在46名参与者中进行了经IRB批准的自我报告抑郁、压力、焦虑和心情的预测评估，结果显示FedTherapist相比于非语言特征的性能提高了0.15 AUROC。

    Psychiatrists diagnose mental disorders via the linguistic use of patients. Still, due to data privacy, existing passive mental health monitoring systems use alternative features such as activity, app usage, and location via mobile devices. We propose FedTherapist, a mobile mental health monitoring system that utilizes continuous speech and keyboard input in a privacy-preserving way via federated learning. We explore multiple model designs by comparing their performance and overhead for FedTherapist to overcome the complex nature of on-device language model training on smartphones. We further propose a Context-Aware Language Learning (CALL) methodology to effectively utilize smartphones' large and noisy text for mental health signal sensing. Our IRB-approved evaluation of the prediction of self-reported depression, stress, anxiety, and mood from 46 participants shows higher accuracy of FedTherapist compared with the performance with non-language features, achieving 0.15 AUROC improveme
    
[^11]: R$^3$ Prompting：无噪声背景下大型语言模型链式思维推理的评审、改写和解决

    R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context. (arXiv:2310.16535v1 [cs.CL])

    [http://arxiv.org/abs/2310.16535](http://arxiv.org/abs/2310.16535)

    R$^3$提示是一种用于在噪声背景下进行CoT推理的新方法，通过复审、改写和解决的思考过程，与大型语言模型交互以进行关键句提取、变量声明和答案预测。

    

    在链式思维（CoT）提示的帮助下，大型语言模型（LLMs）在各种推理任务上取得了显著的表现。然而，大多数研究都在无噪声背景下进行评估，LLMs在噪声背景下产生不准确结果的困境尚未得到充分调查。现有研究利用触发句子鼓励LLMs集中于相关信息，但触发对最终答案预测的影响有限。受交互式CoT方法的启发，该方法通过用户和LLMs之间多轮互动促进中间推理步骤，我们提出了一种新的提示方法，即R$^3$提示，用于在噪声背景下进行CoT思维推理。具体而言，R$^3$提示与LLMs进行关键句提取、变量声明和答案预测的交互，对应于复审、改写和解决的思考过程。最后一次互动中生成的响应将执行

    With the help of Chain-of-Thought (CoT) prompting, Large Language Models (LLMs) have achieved remarkable performance on various reasoning tasks. However, most of them have been evaluated under noise-free context and the dilemma for LLMs to produce inaccurate results under the noisy context has not been fully investigated. Existing studies utilize trigger sentences to encourage LLMs to concentrate on the relevant information but the trigger has limited effect on final answer prediction. Inspired by interactive CoT method, where intermediate reasoning steps are promoted by multiple rounds of interaction between users and LLMs, we propose a novel prompting method, namely R$^3$ prompting, for CoT reasoning under noisy context. Specifically, R$^3$ prompting interacts with LLMs to perform key sentence extraction, variable declaration and answer prediction, which corresponds to a thought process of reviewing, rephrasing and resolving. The responses generated at the last interaction will perfo
    
[^12]: GPT-4V的早期评估

    An Early Evaluation of GPT-4V(ision). (arXiv:2310.16534v1 [cs.CL])

    [http://arxiv.org/abs/2310.16534](http://arxiv.org/abs/2310.16534)

    GPT-4V在英文视觉为中心的基准测试上表现出色，但在识别中文文本、处理敏感特征相关问题和语言理解任务上存在挑战。

    

    本文评估了GPT-4V的多个能力，包括视觉理解、语言理解、视觉拼图解决以及对深度、热量、视频和音频等其他模态的理解。为了评估GPT-4V的表现，我们手动构建了656个测试实例，并对GPT-4V的结果进行了仔细评估。我们的研究发现如下亮点：(1) GPT-4V在英语视觉为中心的基准测试中表现出色，但在图像中无法识别简单的中文文本；(2) 当回答与性别、种族和年龄等敏感特征相关的问题时，GPT-4V表现出不一致的拒绝行为；(3) GPT-4V在语言理解任务上的表现比GPT-4 (API)差，包括一般的语言理解基准测试和视觉常识知识评估基准测试；(4) 少样本启示法可以提高GPT-4V在视觉理解和语言理解上的表现；(5) GPT-4V在寻找细微差别上存在困难。

    In this paper, we evaluate different abilities of GPT-4V including visual understanding, language understanding, visual puzzle solving, and understanding of other modalities such as depth, thermal, video, and audio. To estimate GPT-4V's performance, we manually construct 656 test instances and carefully evaluate the results of GPT-4V. The highlights of our findings are as follows: (1) GPT-4V exhibits impressive performance on English visual-centric benchmarks but fails to recognize simple Chinese texts in the images; (2) GPT-4V shows inconsistent refusal behavior when answering questions related to sensitive traits such as gender, race, and age; (3) GPT-4V obtains worse results than GPT-4 (API) on language understanding tasks including general language understanding benchmarks and visual commonsense knowledge evaluation benchmarks; (4) Few-shot prompting can improve GPT-4V's performance on both visual understanding and language understanding; (5) GPT-4V struggles to find the nuances be
    
[^13]: 《CUNI投稿MRL 2023多语言多任务信息检索共享任务》的翻译

    CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval. (arXiv:2310.16528v1 [cs.CL])

    [http://arxiv.org/abs/2310.16528](http://arxiv.org/abs/2310.16528)

    这个论文介绍了查理大学在MRL 2023多语言多任务信息检索共享任务中采用的解决方案，并通过翻译测试方法实现了命名实体识别和问题回答的多语言应用，通过使用标签敏感的翻译模型评分候选位置，保持了推断标签在原始语言中的正确位置。

    

    我们介绍了查理大学在MRL 2023多语言多任务信息检索共享任务中的系统。该共享任务的目标是开发针对多个语言中的命名实体识别和问题回答的系统。我们对两个子任务的解决方案都依赖于“翻译测试”方法。首先，我们使用多语言机器翻译模型将未标记的示例翻译成英语。然后，我们使用强大的任务特定模型对翻译后的数据进行推断。最后，我们将标记的数据投影回原始语言。为了保持原始语言中的推断标签正确的位置，我们提出了一种基于使用标签敏感翻译模型评分候选位置的方法。在两种设置中，我们在翻译后的数据上尝试了分类模型的微调。然而，由于开发数据和共享任务验证和测试集之间存在领域不匹配，微调的模型可能无法得到准确的结果。

    We present the Charles University system for the MRL~2023 Shared Task on Multi-lingual Multi-task Information Retrieval. The goal of the shared task was to develop systems for named entity recognition and question answering in several under-represented languages. Our solutions to both subtasks rely on the translate-test approach. We first translate the unlabeled examples into English using a multilingual machine translation model. Then, we run inference on the translated data using a strong task-specific model. Finally, we project the labeled data back into the original language. To keep the inferred tags on the correct positions in the original language, we propose a method based on scoring the candidate positions using a label-sensitive translation model. In both settings, we experiment with finetuning the classification models on the translated data. However, due to a domain mismatch between the development data and the shared task validation and test sets, the finetuned models coul
    
[^14]: 通过集体批评和自我投票改善大型语言模型中的人口多样性

    Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting. (arXiv:2310.16523v1 [cs.CL])

    [http://arxiv.org/abs/2310.16523](http://arxiv.org/abs/2310.16523)

    本文研究了生成式大型语言模型中的人口多样性挑战，并提出了一种新的提示技术CCSV，通过利用模型的多样性推理能力来改善人口多样性，而无需依赖手工制作的示例或提示调整。

    

    对于生成式大型语言模型（LLMs）来说，多样性是一个重要挑战：当用户的提示不明确时，模型可能会在生成响应时遵循隐含假设，这可能导致响应的同质化，以及某些人口群体的代表性不足甚至消失在生成的响应中。本文规范了生成式LLMs中的多样性表示。我们提出了评估数据集，并提出了衡量在人和文化方向上生成响应多样性的度量指标。我们发现LLMs理解多样性的概念，并且它们可以对自己的响应进行推理和批评以实现这个目标。这一发现激发了一种名为集体批评和自我投票(CCSC)的新提示技术，通过利用它的多样性推理能力来提高LLMs的人口多样性，而不依赖于手工制作的示例或提示调整。通过人类和自动化评估进行了广泛的实证实验。

    A crucial challenge for generative large language models (LLMs) is diversity: when a user's prompt is under-specified, models may follow implicit assumptions while generating a response, which may result in homogenization of the responses, as well as certain demographic groups being under-represented or even erased from the generated responses. In this paper, we formalize diversity of representation in generative LLMs. We present evaluation datasets and propose metrics to measure diversity in generated responses along people and culture axes. We find that LLMs understand the notion of diversity, and that they can reason and critique their own responses for that goal. This finding motivated a new prompting technique called collective-critique and self-voting (CCSV) to self-improve people diversity of LLMs by tapping into its diversity reasoning capabilities, without relying on handcrafted examples or prompt tuning. Extensive empirical experiments with both human and automated evaluation
    
[^15]: OccuQuest：缓解针对具有包容性的大型语言模型的职业偏见

    OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models. (arXiv:2310.16517v1 [cs.CL])

    [http://arxiv.org/abs/2310.16517](http://arxiv.org/abs/2310.16517)

    OccuQuest是一个用于减轻大型语言模型中的职业偏见的指导调优数据集，它包含了1,000多个职业的110,000+个提示完成对和30,000+个对话，并表现出更加平衡的职业分布。

    

    大型语言模型（LLMs）的出现彻底改变了自然语言处理任务。然而，现有的指导调优数据集存在职业偏见：大多数数据只涉及少数几个职业，这使得指导调优的LLMs难以对特定领域的从业人员的专业问题生成有用的响应。为了减轻这个问题并推广包容性的LLMs，我们创建了一个名为“OccuQuest”的指导调优数据集，其中包含110,000多个提示完成对和30,000多个对话，涵盖了26个职业类别中的1,000多个职业。我们通过与三个常用数据集（Dolly、ShareGPT和WizardLM）进行比较，发现OccuQuest在职业分布上更加平衡。

    The emergence of large language models (LLMs) has revolutionized natural language processing tasks. However, existing instruction-tuning datasets suffer from occupational bias: the majority of data relates to only a few occupations, which hampers the instruction-tuned LLMs to generate helpful responses to professional queries from practitioners in specific fields. To mitigate this issue and promote occupation-inclusive LLMs, we create an instruction-tuning dataset named \emph{OccuQuest}, which contains 110,000+ prompt-completion pairs and 30,000+ dialogues covering over 1,000 occupations in 26 occupational categories. We systematically request ChatGPT, organizing queries hierarchically based on Occupation, Responsibility, Topic, and Question, to ensure a comprehensive coverage of occupational specialty inquiries. By comparing with three commonly used datasets (Dolly, ShareGPT, and WizardLM), we observe that OccuQuest exhibits a more balanced distribution across occupations. Furthermore
    
[^16]: 维度空间编年史: 自然语言模型训练过程中的语言信息如何出现、变化和交互

    Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training. (arXiv:2310.16484v1 [cs.CL])

    [http://arxiv.org/abs/2310.16484](http://arxiv.org/abs/2310.16484)

    通过对语言模型训练过程中的表示空间进行分析，研究发现九个任务中的语言信息在不同阶段和时间点逐渐出现、共享和分化。句法知识在训练的早期阶段迅速习得，而后期的性能提升主要来自开放领域知识和长距离上下文理解的提升。语义和推理任务则受益于更高层次的特化。

    

    通过语言建模学习到的表示空间是自然语言处理(NLP)的基础，然而关于不同类型的语言信息在训练过程中如何以及何时出现和交互的理解还有限。利用一种新颖的信息论探测套件，我们不仅能直接比较任务性能，还能比较它们的表示子空间，我们分析了包括句法、语义和推理在内的九个任务，涵盖了2M个预训练步骤和五个种子。我们确定了任务和时间上的关键学习阶段，在这些阶段，子空间会出现、共享信息，然后分化成特定的子空间。在这些阶段中，句法知识在完成全部训练的0.5%之后很快被获得。持续的性能提升主要来源于对开放领域知识的习得，而语义和推理任务则受益于更高级别的远程上下文和更高层次的特化。我们测量了跨任务的相似度…

    Representational spaces learned via language modeling are fundamental to Natural Language Processing (NLP), however there has been limited understanding regarding how and when during training various types of linguistic information emerge and interact. Leveraging a novel information theoretic probing suite, which enables direct comparisons of not just task performance, but their representational subspaces, we analyze nine tasks covering syntax, semantics and reasoning, across 2M pre-training steps and five seeds. We identify critical learning phases across tasks and time, during which subspaces emerge, share information, and later disentangle to specialize. Across these phases, syntactic knowledge is acquired rapidly after 0.5% of full training. Continued performance improvements primarily stem from the acquisition of open-domain knowledge, while semantics and reasoning tasks benefit from later boosts to long-range contextualization and higher specialization. Measuring cross-task simil
    
[^17]: CLEX: 大型语言模型的持续长度外推

    CLEX: Continuous Length Extrapolation for Large Language Models. (arXiv:2310.16450v1 [cs.CL])

    [http://arxiv.org/abs/2310.16450](http://arxiv.org/abs/2310.16450)

    CLEX是一种针对大型语言模型的持续长度外推方法，通过将位置嵌入缩放方法推广到连续动态建模，克服了当前方法在特定长度上的局限性。

    

    基于Transformer的大型语言模型（LLM）在许多自然语言处理任务中取得了突破性进展，然而，它们的卓越能力受限于Transformer的预设上下文窗口。位置嵌入（PE）缩放方法虽然能够将上下文窗口扩展到特定长度，但在外推能力方面存在明显的局限性，或者在上下文窗口内牺牲部分性能。虽然长度外推方法在理论上能够将上下文窗口延长至训练序列长度之外，但在实际的长上下文应用中表现不佳。为解决这些挑战，我们提出了适用于LLMs的持续长度外推（CLEX）方法。我们将PE缩放方法推广到通过常微分方程对长度缩放因子建模，从而克服了当前为特定长度设计的PE缩放方法的限制。

    Transformer-based Large Language Models (LLMs) are pioneering advances in many natural language processing tasks, however, their exceptional capabilities are restricted within the preset context window of Transformer. Position Embedding (PE) scaling methods, while effective in extending the context window to a specific length, demonstrate either notable limitations in their extrapolation abilities or sacrificing partial performance within the context window. Length extrapolation methods, although theoretically capable of extending the context window beyond the training sequence length, often underperform in practical long-context applications. To address these challenges, we propose Continuous Length EXtrapolation (CLEX) for LLMs. We generalise the PE scaling approaches to model the continuous dynamics by ordinary differential equations over the length scaling factor, thereby overcoming the constraints of current PE scaling methods designed for specific lengths. Moreover, by extending 
    
[^18]: 故事书的多样性增强叙事问题生成

    Diversity Enhanced Narrative Question Generation for Storybooks. (arXiv:2310.16446v1 [cs.CL])

    [http://arxiv.org/abs/2310.16446](http://arxiv.org/abs/2310.16446)

    本文介绍了一种多问题生成模型（mQG），该模型可以通过关注上下文和问题来生成多样化且可回答的问题。通过对FairytaleQA数据集进行训练和评估，以及在TellMeWhy和SQuAD1.1数据集上进行零-shot适应，mQG在各种评估指标上显示出有希望的结果。这项研究将问题生成的多样性引入故事书领域，为提高理解和参与度提供了新的方法。

    

    从给定的上下文生成问题可以增强理解、参与度、评估和学习或对话环境的整体效力。尽管问题生成领域近年来取得了一些进展，但提高或衡量生成问题的多样性仍然是一个未解决的挑战。在本文中，我们引入了一个多问题生成模型（mQG），该模型可以通过关注上下文和问题来生成多样化且可回答的问题。为了验证生成问题的可回答性，我们使用了一个经过SQuAD2.0微调的问答模型，将问题分类为可回答或不可回答。我们在FairytaleQA数据集上对mQG进行训练和评估，该数据集是基于故事书的结构化问答数据集，包含叙事性问题。我们还对TellMeWhy和SQuAD1.1数据集进行了零-shot适应。mQG在各种评估指标上表现出色，超过了强基线模型。

    Question generation (QG) from a given context can enhance comprehension, engagement, assessment, and overall efficacy in learning or conversational environments. Despite recent advancements in QG, the challenge of enhancing or measuring the diversity of generated questions often remains unaddressed. In this paper, we introduce a multi-question generation model (mQG), which is capable of generating multiple, diverse, and answerable questions by focusing on context and questions. To validate the answerability of the generated questions, we employ a SQuAD2.0 fine-tuned question answering model, classifying the questions as answerable or not. We train and evaluate mQG on the FairytaleQA dataset, a well-structured QA dataset based on storybooks, with narrative questions. We further apply a zero-shot adaptation on the TellMeWhy and SQuAD1.1 datasets. mQG shows promising results across various evaluation metrics, among strong baselines.
    
[^19]: DDCoT: 多模态语言模型中的职责分明的思路链刺激

    DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models. (arXiv:2310.16436v1 [cs.CV])

    [http://arxiv.org/abs/2310.16436](http://arxiv.org/abs/2310.16436)

    DDCoT是一种职责分明的思路链刺激方法，通过负空间刺激保持批判态度，并在多模态推理中结合了关键洞见“保持批判性思考”和“让每个人发挥自己的作用”。

    

    人工智能系统的一个长远目标是实现类似人类的复杂多模态推理。最近，大型语言模型在语言模态上利用思路链（CoT）模拟人类思维，在多步推理方面取得了显著进展。然而，将这些进展转移到多模态环境中引入了更高的挑战，包括但不限于对劳动密集型注释的需求以及灵活性、一般化和可解释性方面的限制。为了在多模态环境中唤起CoT推理，本研究首先对多模态环境中的这些挑战进行了深入分析，并提出了两个关键洞见：“保持批判性思考”和“让每个人发挥自己的作用”。此外，本研究提出了一种新颖的DDCoT刺激方法，通过负空间刺激保持批判态度，并通过首先划分责任明确国多模态推理。

    A long-standing goal of AI systems is to perform complex multimodal reasoning like humans. Recently, large language models (LLMs) have made remarkable strides in such multi-step reasoning on the language modality solely by leveraging the chain of thought (CoT) to mimic human thinking. However, the transfer of these advancements to multimodal contexts introduces heightened challenges, including but not limited to the impractical need for labor-intensive annotation and the limitations in terms of flexibility, generalizability, and explainability. To evoke CoT reasoning in multimodality, this work first conducts an in-depth analysis of these challenges posed by multimodality and presents two key insights: "keeping critical thinking" and "letting everyone do their jobs" in multimodal CoT reasoning. Furthermore, this study proposes a novel DDCoT prompting that maintains a critical attitude through negative-space prompting and incorporates multimodality into reasoning by first dividing the r
    
[^20]: PromptAgent: 通过语言模型的战略规划实现优化

    PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization. (arXiv:2310.16427v1 [cs.CL])

    [http://arxiv.org/abs/2310.16427](http://arxiv.org/abs/2310.16427)

    PromptAgent是一个通过战略规划将目标任务与大型语言模型相结合实现优化的方法，能够自主设计与专家手工打造的提示相当的优化方法。

    

    高效、任务特定的提示通常需要经过专家的精心设计，需要结合详细的指导和领域见解，基于对大型语言模型和目标任务细节的深入理解。然而，自动化生成专家级提示的方法仍然难以实现。现有的提示优化方法往往忽视领域知识的深度，并且难以高效地探索专家级提示的广阔空间。为解决这个问题，我们提出了PromptAgent，这是一种自主设计与专家手工打造的提示相当的优化方法。PromptAgent将提示优化视为一个战略规划问题，并采用一种根据Monte Carlo树搜索的规则计算算法在专家级提示空间中进行有效导航。PromptAgent通过类人类的反复试错探索，引发精确的专家级见解和深入的指令。

    Highly effective, task-specific prompts are often heavily engineered by experts to integrate detailed instructions and domain insights based on a deep understanding of both instincts of large language models (LLMs) and the intricacies of the target task. However, automating the generation of such expert-level prompts remains elusive. Existing prompt optimization methods tend to overlook the depth of domain knowledge and struggle to efficiently explore the vast space of expert-level prompts. Addressing this, we present PromptAgent, an optimization method that autonomously crafts prompts equivalent in quality to those handcrafted by experts. At its core, PromptAgent views prompt optimization as a strategic planning problem and employs a principled planning algorithm, rooted in Monte Carlo tree search, to strategically navigate the expert-level prompt space. Inspired by human-like trial-and-error exploration, PromptAgent induces precise expert-level insights and in-depth instructions by r
    
[^21]: 通过词级策略提升同时机器翻译

    Enhanced Simultaneous Machine Translation with Word-level Policies. (arXiv:2310.16417v1 [cs.CL])

    [http://arxiv.org/abs/2310.16417](http://arxiv.org/abs/2310.16417)

    本论文提出了一种使用词级策略提升同时机器翻译的方法，并证明了词级策略优于子词级策略，并且提出了一种使用语言模型的方法来改进同时机器翻译模型。

    

    最近几年，在同时机器翻译（SiMT）领域取得了显著进展，这要归功于引入了创新的策略，决定了在翻译过程的每一步中是读取还是写入。然而，许多现有研究中的一个常见假设是，操作是在子词级别进行的，尽管在大多数实际场景中，输入和输出的标准单位通常是以词为单位。本文证明了在子词级别制定和验证的策略被在以词为单位进行操作的策略超越，并且这些策略一次处理多个子词以形成一个完整的词。此外，我们提出了一种使用语言模型（LMs）提升SiMT模型的方法，其中所提出的词级策略在解决LMs和SiMT模型之间的子词差异中起着重要作用。代码可在https://github.com/xl8-ai/WordSiMT找到。

    Recent years have seen remarkable advances in the field of Simultaneous Machine Translation (SiMT) due to the introduction of innovative policies that dictate whether to READ or WRITE at each step of the translation process. However, a common assumption in many existing studies is that operations are carried out at the subword level, even though the standard unit for input and output in most practical scenarios is typically at the word level. This paper demonstrates that policies devised and validated at the subword level are surpassed by those operating at the word level, which process multiple subwords to form a complete word in a single step. Additionally, we suggest a method to boost SiMT models using language models (LMs), wherein the proposed word-level policy plays a vital role in addressing the subword disparity between LMs and SiMT models. Code is available at https://github.com/xl8-ai/WordSiMT.
    
[^22]: 解密难题：大型语言模型与人类问题求解者的对比

    Decoding Stumpers: Large Language Models vs. Human Problem-Solvers. (arXiv:2310.16411v1 [cs.CL])

    [http://arxiv.org/abs/2310.16411](http://arxiv.org/abs/2310.16411)

    通过对比大型语言模型与人类在难题解决能力上的表现，研究发现新一代大型语言模型在解决难题方面表现出色，超过了人类，但人类在验证解决方案方面具有优势。

    

    本文通过评估大型语言模型（LLMs）在难题上的表现，探究了它们的问题求解能力。难题是一种独特的单步直觉问题，对人类求解者构成挑战，但很容易验证。我们将四种最先进的LLMs（Davinci-2、Davinci-3、GPT-3.5-Turbo、GPT-4）与人类参与者的表现进行比较。我们的研究发现，新一代LLMs在解决难题方面表现出色，超过了人类的表现。然而，人类在验证相同问题的解决方案方面展示出卓越的技能。这项研究增进了我们对LLMs认知能力的理解，并为提升其在各个领域的问题求解潜力提供了见解。

    This paper investigates the problem-solving capabilities of Large Language Models (LLMs) by evaluating their performance on stumpers, unique single-step intuition problems that pose challenges for human solvers but are easily verifiable. We compare the performance of four state-of-the-art LLMs (Davinci-2, Davinci-3, GPT-3.5-Turbo, GPT-4) to human participants. Our findings reveal that the new-generation LLMs excel in solving stumpers and surpass human performance. However, humans exhibit superior skills in verifying solutions to the same problems. This research enhances our understanding of LLMs' cognitive abilities and provides insights for enhancing their problem-solving potential across various domains.
    
[^23]: 基于内容条件查询的Transformer视频指代表达理解

    Video Referring Expression Comprehension via Transformer with Content-conditioned Query. (arXiv:2310.16402v1 [cs.CV])

    [http://arxiv.org/abs/2310.16402](http://arxiv.org/abs/2310.16402)

    本论文提出了一种基于内容条件查询的Transformer方法，用于视频指代表达理解。通过创建动态查询，考虑输入视频和语言的影响，来建模多样化的指代对象。同时，对句子中的特定短语进行对齐，以解决当前查询特征忽视跨模态对齐的问题。

    

    视频指代表达理解（REC）旨在根据查询的自然语言在视频中定位目标对象。最近，使用具有可学习查询的Transformer方法在视频REC方面取得了进展。然而，我们认为，考虑到文本监督带来的视频REC的开放世界性质，这种简单的查询设计并不理想。由于存在众多潜在的语义类别，仅依靠一些更新缓慢的查询无法充分描述它们。我们解决这个问题的方法是创建动态查询，这些查询受输入视频和语言的影响，以建模所指的多样化对象。具体而言，我们在帧中放置了固定数量的可学习边界框，并使用相应的区域特征提供先验信息。此外，我们注意到当前的查询特征忽视了跨模态对齐的重要性。为了解决这个问题，我们将句子中的特定短语与语义相关的视觉区域进行对齐。

    Video Referring Expression Comprehension (REC) aims to localize a target object in videos based on the queried natural language. Recent improvements in video REC have been made using Transformer-based methods with learnable queries. However, we contend that this naive query design is not ideal given the open-world nature of video REC brought by text supervision. With numerous potential semantic categories, relying on only a few slow-updated queries is insufficient to characterize them. Our solution to this problem is to create dynamic queries that are conditioned on both the input video and language to model the diverse objects referred to. Specifically, we place a fixed number of learnable bounding boxes throughout the frame and use corresponding region features to provide prior information. Also, we noticed that current query features overlook the importance of cross-modal alignment. To address this, we align specific phrases in the sentence with semantically relevant visual areas, a
    
[^24]: 基于Transformer的微博帖子生成足球比赛的实时更新

    Transformer-based Live Update Generation for Soccer Matches from Microblog Posts. (arXiv:2310.16368v1 [cs.CL])

    [http://arxiv.org/abs/2310.16368](http://arxiv.org/abs/2310.16368)

    本文提出了基于Transformer的方法来从微博帖子中生成足球比赛的实时更新，通过控制更新数量和减少冗余更新，用户可以立即了解比赛进展并享受比赛的激动。

    

    尽管使用微博帖子观看体育比赛直播已经越来越受欢迎，但从庞大而多样的微博帖子序列中生成足够的体育比赛更新一直是困难的。本文针对足球比赛，致力于构建一个系统，通过微博帖子生成足球比赛的实时更新，让用户可以立即了解比赛的进展，并从原始微博中体验比赛的激动。我们提出的系统基于一个大型的预训练语言模型，并融入了控制更新数量的机制以及减少重复和相似更新冗余的机制。

    It has been known to be difficult to generate adequate sports updates from a sequence of vast amounts of diverse live tweets, although the live sports viewing experience with tweets is gaining the popularity. In this paper, we focus on soccer matches and work on building a system to generate live updates for soccer matches from tweets so that users can instantly grasp a match's progress and enjoy the excitement of the match from raw tweets. Our proposed system is based on a large pre-trained language model and incorporates a mechanism to control the number of updates and a mechanism to reduce the redundancy of duplicate and similar updates.
    
[^25]: InstructPTS: 用于产品标题摘要的指导调节LLMs的方法

    InstructPTS: Instruction-Tuning LLMs for Product Title Summarization. (arXiv:2310.16361v1 [cs.CL])

    [http://arxiv.org/abs/2310.16361](http://arxiv.org/abs/2310.16361)

    InstructPTS是一种用于产品标题摘要的方法，通过指导调节LLMs可根据多种标准生成更准确的摘要，提高了产品名称摘要的质量。

    

    电子商务产品目录中包含数十亿个商品。大多数产品标题很长，卖家使用产品属性来改进商品检索并突出关键产品方面。这导致了不自然的产品标题与客户对其的称呼之间的差距。它也限制了电子商务商店使用这些卖家提供的标题进行推荐、问答或评论摘要的能力。受最近有关指导调节LLMs的研究的启示，我们提出了InstructPTS，这是一种用于产品标题摘要任务的可控方法。使用一种新的指导微调策略进行训练，我们的方法能够根据各种标准（例如摘要中的单词数量、包含特定短语等）总结产品标题。对实际电子商务目录进行广泛的评估表明，与简单微调LLMs相比，我们提出的方法可以生成更准确的产品名称摘要，BLEU和ROUG提高了超过14和8个百分点。

    E-commerce product catalogs contain billions of items. Most products have lengthy titles, as sellers pack them with product attributes to improve retrieval, and highlight key product aspects. This results in a gap between such unnatural products titles, and how customers refer to them. It also limits how e-commerce stores can use these seller-provided titles for recommendation, QA, or review summarization.  Inspired by recent work on instruction-tuned LLMs, we present InstructPTS, a controllable approach for the task of Product Title Summarization (PTS). Trained using a novel instruction fine-tuning strategy, our approach is able to summarize product titles according to various criteria (e.g. number of words in a summary, inclusion of specific phrases, etc.). Extensive evaluation on a real-world e-commerce catalog shows that compared to simple fine-tuning of LLMs, our proposed approach can generate more accurate product name summaries, with an improvement of over 14 and 8 BLEU and ROUG
    
[^26]: 从简单到复杂：一种逐步框架用于文档级信息性论证提取

    From Simple to Complex: A Progressive Framework for Document-level Informative Argument Extraction. (arXiv:2310.16358v1 [cs.CL])

    [http://arxiv.org/abs/2310.16358](http://arxiv.org/abs/2310.16358)

    本论文提出了一种简单到复杂的逐步框架用于文档级信息性论证提取，通过计算每个事件的难度并按照简单到复杂的顺序进行提取，可以提供更可靠的记忆，避免在依赖先前事件的不正确预测的情况下引入噪声。

    

    文档级事件论证提取（EAE）要求模型从单个文档中提取多个事件的论证。考虑到这些事件之间的相关性，最近的努力利用了"记忆"的想法，已经预测的事件的结果被缓存，可以用来帮助预测即将发生的事件。这些方法根据事件在文档中的出现顺序进行提取，然而，出现在第一句中的事件并不意味着它是最容易提取的。现有的方法可能会在依赖于先前事件的不正确预测的情况下引入噪声到即将发生的事件的提取中。为了提供更可靠的记忆，我们提出了一个简单到复杂的逐步框架用于文档级EAE。具体而言，我们首先计算每个事件的难度，然后按照简单到复杂的顺序进行提取。这样，记忆将存储最确定的结果，并且使得即将发生的事件的提取更加可靠。

    Document-level Event Argument Extraction (EAE) requires the model to extract arguments of multiple events from a single document. Considering the underlying dependencies between these events, recent efforts leverage the idea of "memory", where the results of already predicted events are cached and can be retrieved to help the prediction of upcoming events. These methods extract events according to their appearance order in the document, however, the event that appears in the first sentence does not mean that it is the easiest to extract. Existing methods might introduce noise to the extraction of upcoming events if they rely on an incorrect prediction of previous events. In order to provide more reliable memory, we propose a simple-to-complex progressive framework for document-level EAE. Specifically, we first calculate the difficulty of each event and then, we conduct the extraction following a simple-to-complex order. In this way, the memory will store the most certain results, and t
    
[^27]: 多模态多语言文档图像分类的基准测试

    A Multi-Modal Multilingual Benchmark for Document Image Classification. (arXiv:2310.16356v1 [cs.CL])

    [http://arxiv.org/abs/2310.16356](http://arxiv.org/abs/2310.16356)

    介绍了两个新的多语言数据集(WIKI-DOC和MULTIEURLEX-DOC)，克服了现有数据集的限制，并探索了视觉丰富文档理解和文档AI模型在多标签分类和零样本跨语言迁移方面的局限性。这些发现为未来改进文档AI模型的研究提供了机会。

    

    文档图像分类与纯文本文档分类不同，它涉及对表单、电子邮件等文档的内容和结构进行分类。我们发现现有唯一的数据集存在一些限制，并介绍了两个新的多语言数据集——WIKI-DOC和MULTIEURLEX-DOC，克服了这些限制。我们进一步在以前未经测试的设置下对常见的视觉丰富文档理解或文档AI模型进行全面研究，如1）多标签分类，和2）零样本跨语言迁移设置。实验结果显示了跨语言迁移距离较远的语言上多语言文档AI模型的限制。我们的数据集和发现为未来改进文档AI模型的研究打开了大门。

    Document image classification is different from plain-text document classification and consists of classifying a document by understanding the content and structure of documents such as forms, emails, and other such documents. We show that the only existing dataset for this task (Lewis et al., 2006) has several limitations and we introduce two newly curated multilingual datasets WIKI-DOC and MULTIEURLEX-DOC that overcome these limitations. We further undertake a comprehensive study of popular visually-rich document understanding or Document AI models in previously untested setting in document image classification such as 1) multi-label classification, and 2) zero-shot cross-lingual transfer setup. Experimental results show limitations of multilingual Document AI models on cross-lingual transfer across typologically distant languages. Our datasets and findings open the door for future research into improving Document AI models.
    
[^28]: 揭示神经网络中的特征提取机制

    Unraveling Feature Extraction Mechanisms in Neural Networks. (arXiv:2310.16350v1 [cs.CL])

    [http://arxiv.org/abs/2310.16350](http://arxiv.org/abs/2310.16350)

    本研究提出了一种基于神经切线核的理论方法，研究神经网络中的特征提取机制。研究发现在梯度下降过程中模型如何利用统计特征，并揭示了激活函数选择对特征提取的影响。

    

    神经网络在捕捉精确知识方面的基本机制一直是持续研究的对象。本研究提出了一种基于神经切线核（NTK）的理论方法，用于研究这些机制。具体而言，考虑无限网络宽度，我们猜测目标模型的学习动态可能直观地揭示其从训练数据中获取的特征，进一步加深我们对其内部机制的理解。我们将该方法应用于几个基本模型，并揭示了这些模型在梯度下降过程中如何利用统计特征、以及它们如何融入最终的决策中。我们还发现激活函数的选择会影响特征提取。例如，使用ReLU激活函数可能会引入特征偏差，这可以解释为什么最近的预训练语言模型中选择了替代函数来代替它。

    The underlying mechanism of neural networks in capturing precise knowledge has been the subject of consistent research efforts. In this work, we propose a theoretical approach based on Neural Tangent Kernels (NTKs) to investigate such mechanisms. Specifically, considering the infinite network width, we hypothesize the learning dynamics of target models may intuitively unravel the features they acquire from training data, deepening our insights into their internal mechanisms. We apply our approach to several fundamental models and reveal how these models leverage statistical features during gradient descent and how they are integrated into final decisions. We also discovered that the choice of activation function can affect feature extraction. For instance, the use of the \textit{ReLU} activation function could potentially introduce a bias in features, providing a plausible explanation for its replacement with alternative functions in recent pre-trained language models. Additionally, we
    
[^29]: 对大型语言模型的约束文本生成进行了全面评估

    A Comprehensive Evaluation of Constrained Text Generation for Large Language Models. (arXiv:2310.16343v1 [cs.CL])

    [http://arxiv.org/abs/2310.16343](http://arxiv.org/abs/2310.16343)

    该研究全面评估了大型语言模型在约束文本生成方面的应用，研究了LLM的能力和不足，并提供了未来发展的见解。

    

    自然语言生成 (NLG) 和大型语言模型 (LLM) 的进步使得在各种任务中能够生成熟练的文本。然而，由于LLM的不透明性，将复杂的约束集成到神经文本生成中仍然具有挑战性。本研究调查了LLM的约束文本生成，其中在LLM的生成过程中应用了预定义的约束。我们的研究考察了多个LLM，包括ChatGPT和GPT-4，并将约束分为词汇、结构和关系类型。我们还提出了各种基准来促进公平评估。研究解决了一些关键研究问题，包括LLM与约束的遵守程度。结果揭示了LLM集成约束的能力和不足，并为未来发展约束文本生成提供了见解。代码和数据集将在被接受后发布。

    Advancements in natural language generation (NLG) and large language models (LLMs) have led to proficient text generation in various tasks. However, integrating intricate constraints into neural text generation, due to LLMs' opacity, remains challenging. This study investigates constrained text generation for LLMs, where predefined constraints are applied during LLM's generation process. Our research examines multiple LLMs, including ChatGPT and GPT-4, categorizing constraints into lexical, structural, and relation-based types. We also present various benchmarks to facilitate fair evaluation. The study addresses some key research questions, including the extent of LLMs' compliance with constraints. Results illuminate LLMs' capacity and deficiency to incorporate constraints and provide insights for future developments in constrained text generation. Codes and datasets will be released upon acceptance.
    
[^30]: RCAgent：基于自主代理和增强的大型语言模型的云根本原因分析

    RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models. (arXiv:2310.16340v1 [cs.SE])

    [http://arxiv.org/abs/2310.16340](http://arxiv.org/abs/2310.16340)

    RCAgent是一个工具增强的LLM自主代理框架，用于云根本原因分析，能够实现自由格式的数据收集和全面的分析，并在各个方面优于当前方法。

    

    最近，云根本原因分析中的大型语言模型（LLM）应用受到了积极的关注。然而，当前方法仍然依赖于手动工作流设置，并没有充分发挥LLMs的决策和环境交互能力。我们提出了RCAgent，这是一个实用和注重隐私的工具增强LLM自主代理框架，用于实际的工业RCA使用。RCAgent在内部部署的模型上运行，而不是GPT系列，能够进行自由格式的数据收集和全面的分析，并结合各种增强功能，包括独特的行动轨迹自一致性和一套用于上下文管理、稳定化和导入领域知识的方法。我们的实验证明RCAgent在RCA的各个方面（预测根本原因、解决方案、证据和责任）以及当前规则未涵盖的任务上都明显优于ReAct，得到了自动化和人工验证的确认。

    Large language model (LLM) applications in cloud root cause analysis (RCA) have been actively explored recently. However, current methods are still reliant on manual workflow settings and do not unleash LLMs' decision-making and environment interaction capabilities. We present RCAgent, a tool-augmented LLM autonomous agent framework for practical and privacy-aware industrial RCA usage. Running on an internally deployed model rather than GPT families, RCAgent is capable of free-form data collection and comprehensive analysis with tools. Our framework combines a variety of enhancements, including a unique Self-Consistency for action trajectories, and a suite of methods for context management, stabilization, and importing domain knowledge. Our experiments show RCAgent's evident and consistent superiority over ReAct across all aspects of RCA -- predicting root causes, solutions, evidence, and responsibilities -- and tasks covered or uncovered by current rules, as validated by both automate
    
[^31]: 带有流匹配的语音生成预训练

    Generative Pre-training for Speech with Flow Matching. (arXiv:2310.16338v1 [eess.AS])

    [http://arxiv.org/abs/2310.16338](http://arxiv.org/abs/2310.16338)

    本文展示了一种使用流匹配的预训练生成模型，该模型可以适应不同的下游任务并获得强大的性能，通过在60k小时的未转录语音上进行预训练，该模型可以与现有的专家模型在语音增强、分离和合成方面进行匹配或超越。

    

    近年来，生成模型在需要估计和抽样数据分布以生成高保真合成数据的任务中取得了显著的成功，因此越来越受到关注。在语音领域，文本到语音合成和神经声码器是生成模型成功应用的典型例子。尽管生成模型已经在语音的不同应用中得到了应用，但还没有一个通用的生成模型可以直接建模语音。在本文中，我们通过展示单一的预训练生成模型可以适应不同的下游任务并获得强大的性能，迈出了这个方向的一步。具体来说，我们使用流匹配和蒙版条件在60k小时的未转录语音上预训练了一个名为SpeechFlow的生成模型。实验结果表明，预训练的生成模型可以通过特定任务数据进行微调，以在语音增强、分离和合成方面达到或超过现有的专家模型的性能。

    Generative models have gained more and more attention in recent years for their remarkable success in tasks that required estimating and sampling data distribution to generate high-fidelity synthetic data. In speech, text-to-speech synthesis and neural vocoder are good examples where generative models have shined. While generative models have been applied to different applications in speech, there exists no general-purpose generative model that models speech directly. In this work, we take a step toward this direction by showing a single pre-trained generative model can be adapted to different downstream tasks with strong performance. Specifically, we pre-trained a generative model, named SpeechFlow, on 60k hours of untranscribed speech with Flow Matching and masked conditions. Experiment results show the pre-trained generative model can be fine-tuned with task-specific data to match or surpass existing expert models on speech enhancement, separation, and synthesis. Our work suggested 
    
[^32]: CoheSentia: 一个对生成文本连贯性进行增量与整体评估的新型基准。（arXiv:2310.16329v1 [cs.CL]）

    CoheSentia: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts. (arXiv:2310.16329v1 [cs.CL])

    [http://arxiv.org/abs/2310.16329](http://arxiv.org/abs/2310.16329)

    本文提出了一个名为CoheSentia的新型基准，用于评估自动生成文本的人类感知连贯性。我们的注释协议包括整体评分和逐句评分两个角度。通过此基准，可以更准确地评估生成文本的连贯性并分析其相关因素。

    

    连贯性是一个语言学术语，指的是文本单元（句子、命题）之间的关系，使文本在逻辑上一致并对读者有意义。随着自然语言处理中生成模型的进展，迫切需要自动评估自动生成文本的人类感知连贯性。目前为止，关于明确评估生成文本的连贯性并分析（不）连贯性因素的工作很少。以往关于该主题的研究使用其他任务（如句子重排）作为连贯性的替代指标，而不是直接进行连贯性检测。本文介绍了一个名为CoheSentia的新型基准，用于评估自动生成文本的人类感知连贯性。我们的注释协议反映了两个角度：一个是全局角度，给出一个总体连贯性分数；另一个是逐句评分的增量角度。增量方法产生了一个（不）连贯性评估以及相应的分数。

    Coherence is a linguistic term that refers to the relations between small textual units (sentences, propositions), which make the text logically consistent and meaningful to the reader. With the advances of generative foundational models in NLP, there is a pressing need to automatically assess the human-perceived coherence of automatically generated texts. Up until now, little work has been done on explicitly assessing the coherence of generated texts and analyzing the factors contributing to (in)coherence. Previous work on the topic used other tasks, e.g., sentence reordering, as proxies of coherence, rather than approaching coherence detection heads on. In this paper, we introduce {\sc CoheSentia}, a novel benchmark of human-perceived coherence of automatically generated texts. Our annotation protocol reflects two perspectives; one is global, assigning a single coherence score, and the other is incremental, scoring sentence by sentence. The incremental method produces an (in)coherenc
    
[^33]: 三星菲律宾研究与开发中心在WMT 2023上的研究

    Samsung R&D Institute Philippines at WMT 2023. (arXiv:2310.16322v1 [cs.CL])

    [http://arxiv.org/abs/2310.16322](http://arxiv.org/abs/2310.16322)

    本文介绍了三星菲律宾研究与开发中心在WMT 2023中提出的约束机器翻译系统。这些系统在综合数据处理、合成数据训练和在线解码中使用嘈杂通道重排的过程中，用较少的参数表现出与强基线无约束系统相当甚至超过的性能。

    

    本文描述了三星菲律宾研究与开发中心在WMT 2023的一般翻译任务中提交的约束机器翻译系统。我们的系统是基于Transformer的序列到序列模型，经过综合的数据预处理流程、合成反向翻译数据的训练，并在在线解码过程中使用嘈杂通道重排。尽管参数较少，我们的模型在FLORES-200和NTREX-128两个公共基准数据集上表现出与强基线无约束系统（如mBART50 M2M和NLLB 200 MoE）相当甚至有时超过的性能。

    In this paper, we describe the constrained MT systems submitted by Samsung R&D Institute Philippines to the WMT 2023 General Translation Task for two directions: en$\rightarrow$he and he$\rightarrow$en. Our systems comprise of Transformer-based sequence-to-sequence models that are trained with a mix of best practices: comprehensive data preprocessing pipelines, synthetic backtranslated data, and the use of noisy channel reranking during online decoding. Our models perform comparably to, and sometimes outperform, strong baseline unconstrained systems such as mBART50 M2M and NLLB 200 MoE despite having significantly fewer parameters on two public benchmarks: FLORES-200 and NTREX-128.
    
[^34]: DiQAD：一种用于端到端开放域对话评估的基准数据集

    DiQAD: A Benchmark Dataset for End-to-End Open-domain Dialogue Assessment. (arXiv:2310.16319v1 [cs.CL])

    [http://arxiv.org/abs/2310.16319](http://arxiv.org/abs/2310.16319)

    本文发布了一个大规模的对话质量评估数据集（DiQAD），用于自动评估开放域对话质量。该数据集是端到端和人类认知评估数据集，其中包含约100,000个对话。对话质量的评估标准是根据符合人类对话质量判断的维度建立的。数据集可在https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation上公开获取。

    

    对话评估在开放域对话系统的开发中扮演着关键的角色。现有的工作无法提供端到端和人类认知评估数据集，它们只提供一些子指标，如连贯性或对话在远离实际用户环境的注释者之间进行。在本文中，我们发布了一个大规模的对话质量评估数据集（DiQAD），用于自动评估开放域对话质量。具体来说，我们（1）根据符合人类对话质量判断的维度建立评估标准，并（2）根据这些标准对实际用户之间对话进行大规模注释，其中包含约100,000个对话。我们进行了几个实验，并报告了DiQAD上基准的基线性能。该数据集可在https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation上公开获取。

    Dialogue assessment plays a critical role in the development of open-domain dialogue systems. Existing work are uncapable of providing an end-to-end and human-epistemic assessment dataset, while they only provide sub-metrics like coherence or the dialogues are conversed between annotators far from real user settings. In this paper, we release a large-scale dialogue quality assessment dataset (DiQAD), for automatically assessing open-domain dialogue quality. Specifically, we (1) establish the assessment criteria based on the dimensions conforming to human judgements on dialogue qualities, and (2) annotate large-scale dialogues that conversed between real users based on these annotation criteria, which contains around 100,000 dialogues. We conduct several experiments and report the performances of the baselines as the benchmark on DiQAD. The dataset is openly accessible at https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation.
    
[^35]: URL-BERT: 通过社交媒体互动训练网页表示

    URL-BERT: Training Webpage Representations via Social Media Engagements. (arXiv:2310.16303v1 [cs.CL])

    [http://arxiv.org/abs/2310.16303](http://arxiv.org/abs/2310.16303)

    URL-BERT是一种通过社交媒体互动训练网页表示的方法，通过引入新的预训练目标和对比目标，实现了对URL和网页的更好理解和表示。

    

    理解和表示网页对于在线社交网络至关重要，用户可以分享和参与URL。常见的语言模型（LM）编码器如BERT可以用于理解和表示网页的文本内容。然而，这些表示可能无法建模网域和URL的主题信息，也无法准确地捕捉它们对社交媒体用户的吸引力。在这项工作中，我们引入了一种新的预训练目标，用于使语言模型适应URL和网页的理解。我们提出的框架包括两个步骤：（1）基于社交媒体上的用户互动学习URL的浅层表示的可扩展图嵌入，以及（2）将LM表示与前述基于图的表示进行对齐的对比目标。我们将这个框架应用到BERT的多语言版本上，得到了模型URL-BERT。我们通过实验证明，我们的持续预训练方法改善了各种任务的网页理解能力。

    Understanding and representing webpages is crucial to online social networks where users may share and engage with URLs. Common language model (LM) encoders such as BERT can be used to understand and represent the textual content of webpages. However, these representations may not model thematic information of web domains and URLs or accurately capture their appeal to social media users. In this work, we introduce a new pre-training objective that can be used to adapt LMs to understand URLs and webpages. Our proposed framework consists of two steps: (1) scalable graph embeddings to learn shallow representations of URLs based on user engagement on social media and (2) a contrastive objective that aligns LM representations with the aforementioned graph-based representation. We apply our framework to the multilingual version of BERT to obtain the model URL-BERT. We experimentally demonstrate that our continued pre-training approach improves webpage understanding on a variety of tasks and 
    
[^36]: ChatGPT是一个好的多方对话解决方案吗？

    Is ChatGPT a Good Multi-Party Conversation Solver?. (arXiv:2310.16301v1 [cs.CL])

    [http://arxiv.org/abs/2310.16301](http://arxiv.org/abs/2310.16301)

    对于多方对话（MPC），目前ChatGPT在某些任务上的表现令人期待，而GPT-4的结果预示着一个有希望的未来。此外，通过引入MPC结构，包括发言人和受话人架构，可以进一步提高性能。

    

    大型语言模型（LLM）已经成为自然语言处理领域中具有影响力的工具，然而，它们处理多方对话（MPC）的能力——一个由多个参与者参与复杂信息交流的场景——尚未被探索。在本文中，我们深入研究了ChatGPT和GPT-4等生成型LLM在MPC环境下的潜力。通过对包含五个代表性任务的三个MPC数据集进行评估，进行了一个实证分析，以评估ChatGPT和GPT-4的零样本学习能力。研究结果显示，ChatGPT在一些评估的MPC任务上的表现令人期待，而GPT-4的结果预示着一个有希望的未来。此外，我们通过包括发言人和受话人结构在内的MPC结构，努力提高性能。本研究提供了一种详尽的评估和分析。

    Large Language Models (LLMs) have emerged as influential instruments within the realm of natural language processing; nevertheless, their capacity to handle multi-party conversations (MPCs) -- a scenario marked by the presence of multiple interlocutors involved in intricate information exchanges -- remains uncharted. In this paper, we delve into the potential of generative LLMs such as ChatGPT and GPT-4 within the context of MPCs. An empirical analysis is conducted to assess the zero-shot learning capabilities of ChatGPT and GPT-4 by subjecting them to evaluation across three MPC datasets that encompass five representative tasks. The findings reveal that ChatGPT's performance on a number of evaluated MPC tasks leaves much to be desired, whilst GPT-4's results portend a promising future. Additionally, we endeavor to bolster performance through the incorporation of MPC structures, encompassing both speaker and addressee architecture. This study provides an exhaustive evaluation and analy
    
[^37]: XFEVER: 跨语言事实验证的探索

    XFEVER: Exploring Fact Verification across Languages. (arXiv:2310.16278v1 [cs.CL])

    [http://arxiv.org/abs/2310.16278](http://arxiv.org/abs/2310.16278)

    XFEVER 数据集是为了在不同语言中对事实验证模型进行基准测试而设计的，实验结果显示多语言语言模型可以有效地构建不同语言的事实验证模型。

    

    本文介绍了适用于跨语言事实验证模型基准测试的Cross-lingual Fact Extraction and VERification (XFEVER)数据集。我们通过将Fact Extraction and VERification (FEVER)数据集的主张和证据文本翻译成六种语言来构建它。训练集和开发集使用机器翻译进行翻译，而测试集包括由专业翻译人员和机器翻译生成的文本。使用XFEVER数据集，本文定义了两种跨语言事实验证场景，即零样本学习和翻译训练学习，并针对每个场景提出了基准模型。实验结果表明，多语言语言模型可以有效地构建不同语言的事实验证模型。然而，性能在不同语言之间有差异，并且在英语情况下稍逊一筹。我们还发现，我们可以有效地减轻模型的误差校准问题。

    This paper introduces the Cross-lingual Fact Extraction and VERification (XFEVER) dataset designed for benchmarking the fact verification models across different languages. We constructed it by translating the claim and evidence texts of the Fact Extraction and VERification (FEVER) dataset into six languages. The training and development sets were translated using machine translation, whereas the test set includes texts translated by professional translators and machine-translated texts. Using the XFEVER dataset, two cross-lingual fact verification scenarios, zero-shot learning and translate-train learning, are defined, and baseline models for each scenario are also proposed in this paper. Experimental results show that the multilingual language model can be used to build fact verification models in different languages efficiently. However, the performance varies by language and is somewhat inferior to the English case. We also found that we can effectively mitigate model miscalibratio
    
[^38]: CycleAlign: 从黑盒语言模型到白盒模型进行迭代提炼，以实现更好的人类对齐

    CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment. (arXiv:2310.16271v1 [cs.CL])

    [http://arxiv.org/abs/2310.16271](http://arxiv.org/abs/2310.16271)

    CycleAlign提出了一种从语言模型中提炼对齐能力的方法，它通过迭代提炼实现对黑盒模型到白盒模型的转变，解决了语言模型与人类价值对齐的问题。

    

    在大规模语料库上训练的语言模型通常会生成有害、有毒或与人类偏好相悖的内容，使得其与人类价值的对齐成为一个关键问题。强化学习从人类反馈中进行对齐的方法（如PPO）是一种常见的方法，但往往复杂、不稳定且资源密集。最近，基于排名的对齐方法已经出现，通过用监督微调替换强化学习框架，提供稳定性和有效性，但由于需要带注释的数据，它们的成本较高。考虑到现有的大型语言模型（如ChatGPT）已经相对较好地对齐并且成本较低，研究人员已经开始从AI反馈中对语言模型与人类偏好进行对齐。现有的常规实践仅仅从LLMs提炼出遵循指令的响应，受到了瓶颈的限制。因此，我们引入CycleAlign来从参数非可见的模型中提炼对齐能力。

    Language models trained on large-scale corpus often generate content that is harmful, toxic, or contrary to human preferences, making their alignment with human values a critical concern. Reinforcement learning from human feedback (RLHF) with algorithms like PPO is a prevalent approach for alignment but is often complex, unstable, and resource-intensive. Recently, ranking-based alignment methods have emerged, offering stability and effectiveness by replacing the RL framework with supervised fine-tuning, but they are costly due to the need for annotated data. Considering that existing large language models (LLMs) like ChatGPT are already relatively well-aligned and cost-friendly, researchers have begun to align the language model with human preference from AI feedback. The common practices, which unidirectionally distill the instruction-following responses from LLMs, are constrained by their bottleneck. Thus we introduce CycleAlign to distill alignment capabilities from parameter-invisi
    
[^39]: 注意力镜头：一种解释注意力头信息检索机制的工具

    Attention Lens: A Tool for Mechanistically Interpreting the Attention Head Information Retrieval Mechanism. (arXiv:2310.16270v1 [cs.CL])

    [http://arxiv.org/abs/2310.16270](http://arxiv.org/abs/2310.16270)

    Attention Lens是一种工具，它能够通过学习的注意力头特定转换将注意力头的输出翻译为词汇标记。使用Attention Lens，我们可以解释注意力头在生成最终标记预测中的作用。注意力头在语言模型中扮演着高度专门化的角色。

    

    基于Transformer的大型语言模型(LLMs)是自然语言任务的最先进技术。最近的研究尝试通过逆向工程线性层的作用，解码LLMs为文本完成任务做出最终预测的内部机制。然而，关于注意力头在生成最终标记预测中的具体作用还知之甚少。我们提出了Attention Lens，一个工具，可以通过学习的注意力头特定转换(称为镜头)将注意力头的输出翻译为词汇标记。我们训练的镜头的初步发现表明，注意力头在语言模型中扮演着高度专门化的角色。Attention Lens的代码可在github.com/msakarvadia/AttentionLens上获得。

    Transformer-based Large Language Models (LLMs) are the state-of-the-art for natural language tasks. Recent work has attempted to decode, by reverse engineering the role of linear layers, the internal mechanisms by which LLMs arrive at their final predictions for text completion tasks. Yet little is known about the specific role of attention heads in producing the final token prediction. We propose Attention Lens, a tool that enables researchers to translate the outputs of attention heads into vocabulary tokens via learned attention-head-specific transformations called lenses. Preliminary findings from our trained lenses indicate that attention heads play highly specialized roles in language models. The code for Attention Lens is available at github.com/msakarvadia/AttentionLens.
    
[^40]: 媒体的多语言粗略政治立场分类：ChatGPT和Bard报纸的社论立场

    Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper. (arXiv:2310.16269v1 [cs.CL])

    [http://arxiv.org/abs/2310.16269](http://arxiv.org/abs/2310.16269)

    本文研究了使用真实新闻机构的评级来创建一个多语言新闻语料库，其中包括粗略的立场注释和自动提取的主题注释。研究表明，在此数据上训练的分类器能够确定大多数未见报纸的社论立场。

    

    中立性在政治中很难实现，也是主观的。传统媒体通常采取一种社论立场，这可以作为潜在读者用来判断媒体偏见的指标。目前有几个平台根据政治偏见对新闻机构进行评级。社论立场和评级有助于读者获得一种平衡的新闻观点。但是随着指令遵循型的语言模型的出现，如何在不施加偏见的情况下，人工智能新闻机构会位于何处的偏见评级？在这项工作中，我们使用真实新闻机构的评级来创建一个包含粗略立场注释（左翼和右翼）以及自动提取的主题注释的多语言新闻语料库。我们证明了在此数据上训练的分类器能够识别出英语、德语、西班牙语和加泰罗尼亚语的大多数未见报纸的社论立场。然后，我们将这些分类器应用于101份类似报纸的新闻刊物。

    Neutrality is difficult to achieve and, in politics, subjective. Traditional media typically adopt an editorial line that can be used by their potential readers as an indicator of the media bias. Several platforms currently rate news outlets according to their political bias. The editorial line and the ratings help readers in gathering a balanced view of news. But in the advent of instruction-following language models, tasks such as writing a newspaper article can be delegated to computers. Without imposing a biased persona, where would an AI-based news outlet lie within the bias ratings? In this work, we use the ratings of authentic news outlets to create a multilingual corpus of news with coarse stance annotations (Left and Right) along with automatically extracted topic annotations. We show that classifiers trained on this data are able to identify the editorial line of most unseen newspapers in English, German, Spanish and Catalan. We then apply the classifiers to 101 newspaper-lik
    
[^41]: 提升大规模语言模型用于安全代码生成：基于数据集驱动的漏洞缓解研究

    Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation. (arXiv:2310.16263v1 [cs.SE])

    [http://arxiv.org/abs/2310.16263](http://arxiv.org/abs/2310.16263)

    本文介绍了一项针对安全代码生成的综合研究，通过使用经过策划的数据集评估和增强代码大规模语言模型（LLMs），有效解决了使用未经消毒的开源数据训练模型引入安全漏洞的风险。实验结果显示现有模型在安全方面常常被忽视。

    

    大规模语言模型（LLMs）对代码生成带来了显著的进展，既有利于新手开发人员，也有利于经验丰富的开发人员。然而，它们使用来自开源仓库（如GitHub）的未经消毒的数据进行训练，会引入意外传播安全漏洞的风险。为了有效缓解这个问题，本文从软件安全的角度进行了一项综合研究，旨在评估和增强代码LLMs。我们引入了SecuCoGen，一个精心策划的数据集，针对21种关键漏洞类型。SecuCoGen包含180个样本，并作为进行三个关键的与代码相关任务的实验的基础：代码生成、代码修复和漏洞分类，其中安全性得到了极大的强调。我们的实验结果表明，现有模型在处理安全问题时经常被忽视了。

    Large language models (LLMs) have brought significant advancements to code generation, benefiting both novice and experienced developers. However, their training using unsanitized data from open-source repositories, like GitHub, introduces the risk of inadvertently propagating security vulnerabilities. To effectively mitigate this concern, this paper presents a comprehensive study focused on evaluating and enhancing code LLMs from a software security perspective. We introduce SecuCoGen\footnote{SecuCoGen has been uploaded as supplemental material and will be made publicly available after publication.}, a meticulously curated dataset targeting 21 critical vulnerability types. SecuCoGen comprises 180 samples and serves as the foundation for conducting experiments on three crucial code-related tasks: code generation, code repair and vulnerability classification, with a strong emphasis on security. Our experimental results reveal that existing models often overlook security concerns during
    
[^42]: 分布假设不能完全解释蒙面语言模型预训练的好处

    The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining. (arXiv:2310.16261v1 [cs.CL])

    [http://arxiv.org/abs/2310.16261](http://arxiv.org/abs/2310.16261)

    本研究分析了蒙面语言模型预训练的目标函数，并探讨了预训练数据的分布特性对于预训练模型具有更好的样本效率的影响。结果发现，分布特性能够提高样本效率，但不能完全解释模型的泛化能力。此外，通过对真实数据的分析发现分布特性也无法解释自然语言模型的泛化能力。

    

    我们从分布假设的角度分析了蒙面语言模型预训练的目标函数。我们研究了使用蒙面语言模型预训练的模型是否能够归因于预训练数据的语义相似性所编码的分布特性而获得更好的样本效率和更好的泛化能力。通过一个合成数据集，我们的分析表明，分布特性确实导致了预训练蒙面语言模型的更好样本效率，但不能完全解释其泛化能力。我们还在两个真实数据集上进行了分析，并证明分布特性也不能解释预训练自然语言模型的泛化能力。我们的结果揭示了我们对模型预训练的理解有限，并提供了未来的研究方向。

    We analyze the masked language modeling pretraining objective function from the perspective of the distributional hypothesis. We investigate whether better sample efficiency and the better generalization capability of models pretrained with masked language modeling can be attributed to the semantic similarity encoded in the pretraining data's distributional property. Via a synthetic dataset, our analysis suggests that distributional property indeed leads to the better sample efficiency of pretrained masked language models, but does not fully explain the generalization capability. We also conduct analyses over two real-world datasets and demonstrate that the distributional property does not explain the generalization ability of pretrained natural language models either. Our results illustrate our limited understanding of model pretraining and provide future research directions.
    
[^43]: Speakerly：一种基于语音的文本创作辅助工具

    Speakerly: A Voice-based Writing Assistant for Text Composition. (arXiv:2310.16251v1 [cs.CL])

    [http://arxiv.org/abs/2310.16251](http://arxiv.org/abs/2310.16251)

    Speakerly是一种基于语音的文本创作辅助工具，用户可通过指令或口述与系统进行交互，系统生成格式良好、连贯的文档。该系统使用小型任务特定模型和预训练语言模型，实现快速有效的文本创作，并支持各种输入模式以提高可用性。

    

    我们提出了Speakerly，一种新的实时语音文本创作辅助系统，可帮助用户在各种用例中进行文本创作，如电子邮件、即时通讯和笔记。用户可以通过指令或口述与系统进行交互，系统生成格式良好、连贯的文档。我们描述了系统架构，并详细介绍了在构建和部署如此规模的系统时如何解决各种挑战。具体而言，我们的系统使用了一组小型、任务特定的模型以及预训练的语言模型，实现快速有效的文本创作，同时支持各种输入模式以提高可用性。

    We present Speakerly, a new real-time voice-based writing assistance system that helps users with text composition across various use cases such as emails, instant messages, and notes. The user can interact with the system through instructions or dictation, and the system generates a well-formatted and coherent document. We describe the system architecture and detail how we address the various challenges while building and deploying such a system at scale. More specifically, our system uses a combination of small, task-specific models as well as pre-trained language models for fast and effective text composition while supporting a variety of input modes for better usability.
    
[^44]: GlotLID: 低资源语言的语言识别

    GlotLID: Language Identification for Low-Resource Languages. (arXiv:2310.16248v1 [cs.CL])

    [http://arxiv.org/abs/2310.16248](http://arxiv.org/abs/2310.16248)

    GlotLID-M是一个满足广泛覆盖、可靠性和效率要求的语言识别模型，具有1665个可识别语言，并在实验中表现出色。它解决了低资源LID面临的挑战，并有望提高数据集质量和增强访问能力。

    

    最近有几篇论文发表了针对约300种高资源和中资源语言的语言识别（LID）的良好解决方案。然而，目前没有可用的LID满足以下要求：（i）涵盖广泛的低资源语言，（ii）经过严格评估且可靠，（iii）高效易用。在这里，我们发布了GlotLID-M，一个满足广泛覆盖、可靠性和效率要求的LID模型。它可以识别1665种语言，在覆盖范围上相比之前的工作有了大幅增加。在我们的实验中，GlotLID-M在平衡F1分数和假阳性率（FPR）方面优于四个基准模型（CLD3，FT176，OpenLID和NLLB）。我们分析了低资源LID面临的独特挑战：不正确的语料库元数据，来自高资源语言的泄漏，难以区分密切相关的语言，处理宏语言与方言，以及一般的噪声数据。我们希望将GlotLID-M集成到数据集创建流程中，以提高质量和增强访问能力。

    Several recent papers have published good solutions for language identification (LID) for about 300 high-resource and medium-resource languages. However, there is no LID available that (i) covers a wide range of low-resource languages, (ii) is rigorously evaluated and reliable and (iii) efficient and easy to use. Here, we publish GlotLID-M, an LID model that satisfies the desiderata of wide coverage, reliability and efficiency. It identifies 1665 languages, a large increase in coverage compared to prior work. In our experiments, GlotLID-M outperforms four baselines (CLD3, FT176, OpenLID and NLLB) when balancing F1 and false positive rate (FPR). We analyze the unique challenges that low-resource LID poses: incorrect corpus metadata, leakage from high-resource languages, difficulty separating closely related languages, handling of macrolanguage vs varieties and in general noisy data. We hope that integrating GlotLID-M into dataset creation pipelines will improve quality and enhance acces
    
[^45]: ZzzGPT: 提高睡眠质量的交互式GPT方法

    ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality. (arXiv:2310.16242v1 [cs.LG])

    [http://arxiv.org/abs/2310.16242](http://arxiv.org/abs/2310.16242)

    本文介绍了一种名为ZzzGPT的交互式GPT方法，旨在提高睡眠质量。通过利用大型语言模型进行预测和反馈，该方法融合了先进的机器学习和用户导向设计，以提供准确和有价值的结果。

    

    在当今世界中，睡眠质量对总体健康至关重要。虽然可穿戴传感器提供实时监测，但它们常常缺乏有针对性的见解，导致用户放弃使用。本文研究了技术在理解睡眠模式方面的作用。我们引入了一个两阶段的框架，利用大型语言模型 (LLMs)，旨在提供准确的睡眠预测和有价值的反馈。利用GLOBEM数据集和LLMs的合成数据，我们展示了与XGBoost等模型相比的增强结果。我们的方法将先进的机器学习与以用户为中心的设计相结合，将科学准确性与实用性融合在一起。

    In today's world, sleep quality is pivotal for overall well-being. While wearable sensors offer real-time monitoring, they often lack actionable insights, leading to user abandonment. This paper delves into the role of technology in understanding sleep patterns. We introduce a two-stage framework, utilizing Large Language Models (LLMs), aiming to provide accurate sleep predictions with actionable feedback. Leveraging the GLOBEM dataset and synthetic data from LLMs, we highlight enhanced results with models like XGBoost. Our approach merges advanced machine learning with user-centric design, blending scientific accuracy with practicality.
    
[^46]: 使用混合语言专家适配器改进和解释预训练语言模型

    Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting Pre-trained Language Models. (arXiv:2310.16240v1 [cs.CL])

    [http://arxiv.org/abs/2310.16240](http://arxiv.org/abs/2310.16240)

    本研究提出了一种方法，在预训练语言模型中引入语言结构，通过混合语言专家架构来改进和解释其性能，并且实验证明该方法在参数高效微调中比其他方法表现更好。

    

    本文提出了一种方法，通过将语言结构注入到预训练语言模型中，在参数高效的微调设置下，将两个热门研究领域相结合。在我们的方法中，使用一种新颖的混合语言专家架构组合编码不同语言结构的并行适配器模块，通过Gumbel-Softmax门确定模型每一层中这些模块的重要性。为了减少参数数量，在修剪专家的重要性评分后，我们首先对模型进行一定数量的固定步骤的训练。我们在三种不同的预训练模型上进行了实验，结果表明我们的方法在具有可比较参数数量的情况下，可以超越最先进的参数高效微调方法。此外，我们提供了额外的分析来检查每个模型在每层选择的专家，为未来的研究提供参考。

    In this work, we propose a method that combines two popular research areas by injecting linguistic structures into pre-trained language models in the parameter-efficient fine-tuning (PEFT) setting. In our approach, parallel adapter modules encoding different linguistic structures are combined using a novel Mixture-of-Linguistic-Experts architecture, where Gumbel-Softmax gates are used to determine the importance of these modules at each layer of the model. To reduce the number of parameters, we first train the model for a fixed small number of steps before pruning the experts based on their importance scores. Our experiment results with three different pre-trained models show that our approach can outperform state-of-the-art PEFT methods with a comparable number of parameters. In addition, we provide additional analysis to examine the experts selected by each model at each layer to provide insights for future studies.
    
[^47]: TiC-CLIP: CLIP模型的持续训练

    TiC-CLIP: Continual Training of CLIP Models. (arXiv:2310.16226v1 [cs.CV])

    [http://arxiv.org/abs/2310.16226](http://arxiv.org/abs/2310.16226)

    该论文提出了用于训练视觉-语言模型的大规模时间连续 (TiC) 基准，使用这些基准评估了现有模型的时间鲁棒性，并展示了一种简单有效的排练方法来持续训练模型。

    

    保持大型基础模型与最新数据保持同步本身就是昂贵的。为了避免不断重新训练的高成本，持续训练这些模型至关重要。这个问题被缺乏大规模连续学习基准或基线所加剧。我们引入了用于训练视觉-语言模型的第一批 Web 规模时间连续（TiC）基准：TiC-DataCompt、TiC-YFCC 和 TiC-RedCaps，其中包含超过 127 亿个时间戳图像-文本对，跨越了 9 年的时间（2014-2022）。我们首先使用这些基准来策划各种动态评估，以衡量现有模型的时间鲁棒性。我们展示了 OpenAI 的 CLIP 模型（使用 2020 年的数据进行训练）在我们策划的从 2021 年到 2022 年的检索任务中，失去了约 8% 的零-shot准确率，而与 OpenCLIP 存储库中最近训练的模型相比。然后，我们研究如何高效地对时间连续数据进行训练。我们证明了一种简单的排练方法，从上次的训练中继续训练，可以实现有效的训练。

    Keeping large foundation models up to date on latest data is inherently expensive. To avoid the prohibitive costs of constantly retraining, it is imperative to continually train these models. This problem is exacerbated by the lack of any large scale continual learning benchmarks or baselines. We introduce the first set of web-scale Time-Continual (TiC) benchmarks for training vision-language models: TiC-DataCompt, TiC-YFCC, and TiC-RedCaps with over 12.7B timestamped image-text pairs spanning 9 years (2014--2022). We first use our benchmarks to curate various dynamic evaluations to measure temporal robustness of existing models. We show OpenAI's CLIP (trained on data up to 2020) loses $\approx 8\%$ zero-shot accuracy on our curated retrieval task from 2021--2022 compared with more recently trained models in OpenCLIP repository. We then study how to efficiently train models on time-continuous data. We demonstrate that a simple rehearsal-based approach that continues training from the l
    
[^48]: CleanCoNLL: 一种几乎无噪声的命名实体识别数据集

    CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset. (arXiv:2310.16225v1 [cs.CL])

    [http://arxiv.org/abs/2310.16225](http://arxiv.org/abs/2310.16225)

    CleanCoNLL是一种几乎无噪声的命名实体识别数据集，通过全面重标记和自动一致性检查来纠正CoNLL-03中的注释错误，提高了最先进方法的F1分数，并减少了因注释缺失而误判的情况。

    

    CoNLL-03语料库被认为是最著名和广泛使用的命名实体识别（NER）基准数据集。然而，之前的研究发现了大量的注释错误、不完整性和数据不一致性。这给客观比较NER方法和分析其错误带来了挑战，因为目前最先进的模型在CoNLL-03中达到的F1分数与估计的噪声水平相当甚至更高。为了解决这个问题，我们通过自动一致性检查辅助的全面重标记工作来纠正英文CoNLL-03中所有标签的7.0％。我们的工作还为了更好地解释NER标签和作为附加保证注释质量而添加了一个实体链接注释层。我们的实验证明，最先进的方法不仅在我们的数据上达到了显著更高的F1分数（97.1％），而且关键是正确预测被错误地计算为错误的比例由于注释的缺失得到了改善。

    The CoNLL-03 corpus is arguably the most well-known and utilized benchmark dataset for named entity recognition (NER). However, prior works found significant numbers of annotation errors, incompleteness, and inconsistencies in the data. This poses challenges to objectively comparing NER approaches and analyzing their errors, as current state-of-the-art models achieve F1-scores that are comparable to or even exceed the estimated noise level in CoNLL-03. To address this issue, we present a comprehensive relabeling effort assisted by automatic consistency checking that corrects 7.0% of all labels in the English CoNLL-03. Our effort adds a layer of entity linking annotation both for better explainability of NER labels and as additional safeguard of annotation quality. Our experimental evaluation finds not only that state-of-the-art approaches reach significantly higher F1-scores (97.1%) on our data, but crucially that the share of correct predictions falsely counted as errors due to annota
    
[^49]: 大型语言模型的知识编辑：一项综述

    Knowledge Editing for Large Language Models: A Survey. (arXiv:2310.16218v1 [cs.CL])

    [http://arxiv.org/abs/2310.16218](http://arxiv.org/abs/2310.16218)

    大型语言模型(LLMs)在学术和工业领域具有巨大潜力。本文综述了LLMs的知识编辑问题，强调了需要开发有效和高效的技术来更新预训练LLMs以纳入新知识的重要性。

    

    大型语言模型(LLMs)近期以其出色的理解、分析和生成文本的能力，根据其广博的知识和推理能力，改变了学术和工业领域的格局。然而，LLMs的一个主要缺点是它们在预训练时需要大量计算资源，因为其参数数量前所未有。当需要频繁引入新知识到预训练模型中时，这个缺点更加显著。因此，开发有效和高效的技术来更新预训练LLMs是必不可少的。传统方法是通过直接微调将新知识编码到预训练LLMs中。然而，简单地重新训练LLMs可能计算资源密集，并且存在将与模型更新无关的有价值的预训练知识退化的风险。最近，基于知识的模型编辑(KME)引起了越来越多的关注，旨在精确修改LLMs以纳入特定的知识。

    Large language models (LLMs) have recently transformed both the academic and industrial landscapes due to their remarkable capacity to understand, analyze, and generate texts based on their vast knowledge and reasoning ability. Nevertheless, one major drawback of LLMs is their substantial computational cost for pre-training due to their unprecedented amounts of parameters. The disadvantage is exacerbated when new knowledge frequently needs to be introduced into the pre-trained model. Therefore, it is imperative to develop effective and efficient techniques to update pre-trained LLMs. Traditional methods encode new knowledge in pre-trained LLMs through direct fine-tuning. However, naively re-training LLMs can be computationally intensive and risks degenerating valuable pre-trained knowledge irrelevant to the update in the model. Recently, Knowledge-based Model Editing (KME) has attracted increasing attention, which aims to precisely modify the LLMs to incorporate specific knowledge, wit
    
[^50]: 事件时间线的背景摘要

    Background Summarization of Event Timelines. (arXiv:2310.16197v1 [cs.CL])

    [http://arxiv.org/abs/2310.16197](http://arxiv.org/abs/2310.16197)

    本文提出了一个任务，即生成新闻事件的背景摘要，用于补充每个时间线更新的相关前置事件，通过合并现有数据集并使用最先进的摘要系统建立基准性能。我们还提出了一种以查询为重点的变体来生成背景摘要，并提出了一个基于问答的评估指标来评估摘要质量。

    

    生成新闻事件的简洁摘要是一项具有挑战性的自然语言处理任务。虽然记者通常会整理时间线来突出关键子事件，但是对于新闻事件的新人来说，了解其历史背景是一项挑战。本文通过引入背景新闻摘要的任务来解决这个需求，该任务为每个时间线更新配上相关前置事件的背景摘要。我们通过合并现有的时间线数据集并要求人工注释者为每个新闻事件的每一时间步骤编写背景摘要来构建数据集。我们使用最先进的摘要系统建立了强大的基准性能，并提出了一个以查询为重点的变体来生成背景摘要。为了评估背景摘要的质量，我们提出了一个基于问答的评估指标，背景效用分数（BUS），它衡量了背景摘要回答当前事件时间步骤问题的百分比。

    Generating concise summaries of news events is a challenging natural language processing task. While journalists often curate timelines to highlight key sub-events, newcomers to a news event face challenges in catching up on its historical context. In this paper, we address this need by introducing the task of background news summarization, which complements each timeline update with a background summary of relevant preceding events. We construct a dataset by merging existing timeline datasets and asking human annotators to write a background summary for each timestep of each news event. We establish strong baseline performance using state-of-the-art summarization systems and propose a query-focused variant to generate background summaries. To evaluate background summary quality, we present a question-answering-based evaluation metric, Background Utility Score (BUS), which measures the percentage of questions about a current event timestep that a background summary answers. Our experim
    
[^51]: 长度对于文档级语义而言既是诅咒也是福音

    Length is a Curse and a Blessing for Document-level Semantics. (arXiv:2310.16193v1 [cs.CL])

    [http://arxiv.org/abs/2310.16193](http://arxiv.org/abs/2310.16193)

    本文研究了基于对比学习的模型在长度上的泛化能力，并提出了一个仅依赖于文档长度的无监督学习方法。研究发现，延长文档的长度会加 intensify 达到的高内部相似性，并且这种等向性的表现高度依赖于文本长度范围。基于这些发现，提出了一个简单而通用的文档表示学习框架，用于实现语义鲁棒的句子表示学习。

    

    最近几年，对比学习（CL）已经广泛应用于从预训练的语言模型中恢复句子和文档级别的编码能力。在这项工作中，我们质疑基于CL的模型的长度泛化能力，即它们对于长度引起的语义变化的易受攻击的程度。我们验证了长度易受攻击是一个重要但被忽视的研究空白，并且我们可以设计仅依赖于文档长度提供的语义信号的无监督CL方法。我们首先推导了长度攻击的理论基础，表明延长文档会加 intensify 已经由CL带来的高内部文档相似性。此外，我们发现CL承诺的等向性高度依赖于训练中暴露的文本长度范围。受到这些发现的启发，我们引入了一个简单而通用的文档表示学习框架，LA(SER)$^{3}$: 长度不受限的自我参照用于语义鲁棒的句子表示学习

    In recent years, contrastive learning (CL) has been extensively utilized to recover sentence and document-level encoding capability from pre-trained language models. In this work, we question the length generalizability of CL-based models, i.e., their vulnerability towards length-induced semantic shift. We verify not only that length vulnerability is a significant yet overlooked research gap, but we can devise unsupervised CL methods solely depending on the semantic signal provided by document length. We first derive the theoretical foundations underlying length attacks, showing that elongating a document would intensify the high intra-document similarity that is already brought by CL. Moreover, we found that isotropy promised by CL is highly dependent on the length range of text exposed in training. Inspired by these findings, we introduce a simple yet universal document representation learning framework, LA(SER)$^{3}$: length-agnostic self-reference for semantically robust sentence r
    
[^52]: BLP 2023任务2：情感分析

    BLP 2023 Task 2: Sentiment Analysis. (arXiv:2310.16183v1 [cs.CL])

    [http://arxiv.org/abs/2310.16183](http://arxiv.org/abs/2310.16183)

    BLP 2023任务2是关于情感分析的共享任务，吸引了71个参与者。参与者通过各种方法，包括经典机器学习模型和大型语言模型，提交了597个运行结果。本文提供了任务的详细设置和参与者提交系统的概述。

    

    我们总结了作为BLP 2023创新工作坊的一部分举办的BLP情感共享任务。该任务的定义是在给定的社交媒体文本中检测情感。该任务吸引了71个参与者的关注，其中在开发和评估阶段分别有29个和30个团队提交了系统。总共，参与者提交了597个运行结果。然而，总共有15个团队提交了系统描述论文。提交的系统涵盖了从经典的机器学习模型、微调预训练模型到在零样本和少样本设置中利用大型语言模型（LLMs）的各种方法。在本文中，我们详细介绍了该任务的设置，包括数据集的开发和评估设置。此外，我们简要概述了参与者提交的系统。共享任务的所有数据集和评估脚本已公开可用。

    We present an overview of the BLP Sentiment Shared Task, organized as part of the inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is defined as the detection of sentiment in a given piece of social media text. This task attracted interest from 71 participants, among whom 29 and 30 teams submitted systems during the development and evaluation phases, respectively. In total, participants submitted 597 runs. However, a total of 15 teams submitted system description papers. The range of approaches in the submitted systems spans from classical machine learning models, fine-tuning pre-trained models, to leveraging Large Language Model (LLMs) in zero- and few-shot settings. In this paper, we provide a detailed account of the task setup, including dataset development and evaluation setup. Additionally, we provide a brief overview of the systems submitted by the participants. All datasets and evaluation scripts from the shared task have been made publicly available for the res
    
[^53]: 科学中的隐藏引用模糊了真正的影响力

    Hidden Citations Obscure True Impact in Science. (arXiv:2310.16181v1 [cs.CL])

    [http://arxiv.org/abs/2310.16181](http://arxiv.org/abs/2310.16181)

    隐藏引用现象在科学中普遍存在，并且超过了正式引用的数量，表明传统的引文分析方法无法准确评估科学发现的影响力。

    

    引用是科学家们用来表示之前知识的机制，但最近已经变成了广泛使用和滥用的科学影响力的度量标准。然而，当一个发现变成共识时，引用会因为被忽视而被合并。这导致了隐藏引用的概念，它表示对一个发现的明确文本认可，但没有引用该发现的出版物。在这里，我们依赖于无监督可解释机器学习应用于每篇论文的全文，以系统地识别隐藏引用。我们发现，对于有影响力的发现，隐藏引用数量超过了引用计数，而且不受出版场所和学科的限制。我们展示了隐藏引用的普遍性不是由引用计数驱动的，而是由于手稿文本中对话题的讨论程度决定的，这表明一个发现被讨论得越多，它在标准的引文分析中就越不可见。隐藏引用指示了...

    References, the mechanism scientists rely on to signal previous knowledge, lately have turned into widely used and misused measures of scientific impact. Yet, when a discovery becomes common knowledge, citations suffer from obliteration by incorporation. This leads to the concept of hidden citation, representing a clear textual credit to a discovery without a reference to the publication embodying it. Here, we rely on unsupervised interpretable machine learning applied to the full text of each paper to systematically identify hidden citations. We find that for influential discoveries hidden citations outnumber citation counts, emerging regardless of publishing venue and discipline. We show that the prevalence of hidden citations is not driven by citation counts, but rather by the degree of the discourse on the topic within the text of the manuscripts, indicating that the more discussed is a discovery, the less visible it is to standard bibliometric analysis. Hidden citations indicate t
    
[^54]: 通过回溯法纠正，减少摘要中的幻觉

    Correction with Backtracking Reduces Hallucination in Summarization. (arXiv:2310.16176v1 [cs.CL])

    [http://arxiv.org/abs/2310.16176](http://arxiv.org/abs/2310.16176)

    本文介绍了一种简单而有效的技术，CoBa，用于减少摘要中的幻觉。该方法通过测量条件词概率和上下文词距离的统计信息进行幻觉检测，并通过直观的回溯法进行减轻。实验证明，CoBa在减少摘要幻觉方面是有效且高效的。

    

    摘要生成旨在生成源文件的自然语言摘要，既简洁又保留重要元素。尽管最近取得了一些进展，但神经文本摘要模型容易产生幻觉（或更准确地说是混淆），即生成的摘要包含源文件中没有根据的细节。在本文中，我们引入了一种简单而有效的技术，CoBa，用于减少摘要中的幻觉。该方法基于两个步骤：幻觉检测和减轻。我们展示了通过测量有关条件词概率和上下文词距离的简单统计信息可以实现前者。此外，我们还证明了直观的回溯法在减轻幻觉方面的惊人效果。我们在三个文本摘要基准数据集上对所提出的方法进行了全面评估。结果表明，CoBa在减少摘要幻觉方面是有效且高效的。

    Abstractive summarization aims at generating natural language summaries of a source document that are succinct while preserving the important elements. Despite recent advances, neural text summarization models are known to be susceptible to hallucinating (or more correctly confabulating), that is to produce summaries with details that are not grounded in the source document. In this paper, we introduce a simple yet efficient technique, CoBa, to reduce hallucination in abstractive summarization. The approach is based on two steps: hallucination detection and mitigation. We show that the former can be achieved through measuring simple statistics about conditional word probabilities and distance to context words. Further, we demonstrate that straight-forward backtracking is surprisingly effective at mitigation. We thoroughly evaluate the proposed method with prior art on three benchmark datasets for text summarization. The results show that CoBa is effective and efficient in reducing hall
    
[^55]: WojoodNER 2023: 第一个阿拉伯命名实体识别共享任务

    WojoodNER 2023: The First Arabic Named Entity Recognition Shared Task. (arXiv:2310.16153v1 [cs.CL])

    [http://arxiv.org/abs/2310.16153](http://arxiv.org/abs/2310.16153)

    WojoodNER-2023是第一个阿拉伯命名实体识别共享任务，提供了新颖的数据集和子任务，以促进NER方法之间的比较。最终获胜的团队在FlatNER和NestedNER中取得了优秀的性能。

    

    我们提出了WojoodNER-2023，这是第一个阿拉伯命名实体识别（NER）共享任务。WojoodNER-2023的主要关注点是阿拉伯NER，提供了新颖的NER数据集（即Wojood）和旨在促进不同NER方法之间有意义比较的子任务定义。WojoodNER-2023包括两个子任务：FlatNER和NestedNER。共有45个独立团队注册参加此共享任务，其中有11个团队在测试阶段积极参与。具体而言，11个团队参与了FlatNER，而8个团队处理了NestedNER。获胜的团队在FlatNER和NestedNER中分别达到了91.96和93.73的F1分数。

    We present WojoodNER-2023, the first Arabic Named Entity Recognition (NER) Shared Task. The primary focus of WojoodNER-2023 is on Arabic NER, offering novel NER datasets (i.e., Wojood) and the definition of subtasks designed to facilitate meaningful comparisons between different NER approaches. WojoodNER-2023 encompassed two Subtasks: FlatNER and NestedNER. A total of 45 unique teams registered for this shared task, with 11 of them actively participating in the test phase. Specifically, 11 teams participated in FlatNER, while $8$ teams tackled NestedNER. The winning teams achieved F1 scores of 91.96 and 93.73 in FlatNER and NestedNER, respectively.
    
[^56]: PreWoMe:利用预设为长篇问答中的工作记忆进行问题回答

    PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering. (arXiv:2310.16147v1 [cs.CL])

    [http://arxiv.org/abs/2310.16147](http://arxiv.org/abs/2310.16147)

    PreWoMe是一种处理长篇问答中信息检索问题的统一方法，通过提取问题中的预设并利用其作为工作记忆来生成反馈和行动，不仅能有效解决误导性问题，而且适用于处理正常问题，证明了在实际问答场景中利用预设、反馈和行动的有效性。

    

    长篇问答中的信息检索问题常常由于问题中的模糊或错误预设而误导。虽然许多现有方法可以处理误导性问题，但它们针对的是有限的问题，很难适应实际情况中不可预测的输入特征。在这项工作中，我们提出了PreWoMe，这是一种统一的方法，能够处理任何类型的信息检索问题。PreWoMe的关键思想是提取问题中的预设，并将其作为工作记忆来生成对问题的反馈和行动。我们的实验证明，PreWoMe不仅在解决误导性问题方面有效，而且在处理正常问题方面也很有效，从而证明了在实际问答场景中利用预设、反馈和行动的有效性。

    Information-seeking questions in long-form question answering (LFQA) often prove misleading due to ambiguity or false presupposition in the question. While many existing approaches handle misleading questions, they are tailored to limited questions, which are insufficient in a real-world setting with unpredictable input characteristics. In this work, we propose PreWoMe, a unified approach capable of handling any type of information-seeking question. The key idea of PreWoMe involves extracting presuppositions in the question and exploiting them as working memory to generate feedback and action about the question. Our experiment shows that PreWoMe is effective not only in tackling misleading questions but also in handling normal ones, thereby demonstrating the effectiveness of leveraging presuppositions, feedback, and action for real-world QA settings.
    
[^57]: Clinfo.ai:用科学文献回答医学问题的开源检索增强型大型语言模型系统

    Clinfo.ai: An Open-Source Retrieval-Augmented Large Language Model System for Answering Medical Questions using Scientific Literature. (arXiv:2310.16146v1 [cs.IR])

    [http://arxiv.org/abs/2310.16146](http://arxiv.org/abs/2310.16146)

    Clinfo.ai是一个开源的系统，使用科学文献回答医学问题。研究人员提出了一个信息检索和抽象概括任务，发布了相应的数据集，并进行了评估。

    

    随着医学文献的快速增长，医生和研究人员很难及时跟上并总结最近的相关发现。虽然现在存在几个基于大型语言模型（LLMs）的闭源摘要工具，但其输出结果缺乏严格和系统的评估。此外，缺乏高质量的数据集和适当的基准任务来评估这些工具。我们通过四个贡献来解决这些问题：我们发布了名为Clinfo.ai的开源WebApp，它基于动态检索的科学文献回答临床问题；我们指定了一个信息检索和抽象概括任务，以评估这种检索增强型LLM系统的性能；我们发布了一个包含200个问题及其对应答案的数据集，我们将其命名为PubMed检索和综述（PubMedRS-200）；并报告了Cli的基准结果。

    The quickly-expanding nature of published medical literature makes it challenging for clinicians and researchers to keep up with and summarize recent, relevant findings in a timely manner. While several closed-source summarization tools based on large language models (LLMs) now exist, rigorous and systematic evaluations of their outputs are lacking. Furthermore, there is a paucity of high-quality datasets and appropriate benchmark tasks with which to evaluate these tools. We address these issues with four contributions: we release Clinfo.ai, an open-source WebApp that answers clinical questions based on dynamically retrieved scientific literature; we specify an information retrieval and abstractive summarization task to evaluate the performance of such retrieval-augmented LLM systems; we release a dataset of 200 questions and corresponding answers derived from published systematic reviews, which we name PubMed Retrieval and Synthesis (PubMedRS-200); and report benchmark results for Cli
    
[^58]: 有限记忆容量的语言模型捕捉人类句子处理中的干扰

    A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing. (arXiv:2310.16142v1 [cs.CL])

    [http://arxiv.org/abs/2310.16142](http://arxiv.org/abs/2310.16142)

    开发了一个循环神经语言模型，通过使用单个自我注意头紧密模拟了认知理论中假设的记忆系统，并捕捉到人类句子处理中的干扰。

    

    人类句子处理困难的两个核心因素被认为是期望和来自工作记忆的检索。最近的一个尝试，旨在创建一个综合认知模型，将这两个因素整合在一起，依赖于transformer语言模型的自我注意机制和人类句子处理中基于暗示的工作记忆检索理论之间的相似之处。（Ryu and Lewis, 2021）.虽然Ryu和Lewis展示了GPT-2的特殊自注意头中的注意模式与基于相似性的干扰的关键预测一致，这是基于暗示的检索模型，但他们的方法需要识别出句法特化的自注意头，并做出认知上不合理的假设，即数百次的内存检索操作是并行进行的。在本研究中，我们开发了一个具有单个自我注意头的循环神经语言模型，更贴近认知理论所假设的记忆系统。我们展示了我们模型的...

    Two of the central factors believed to underpin human sentence processing difficulty are expectations and retrieval from working memory. A recent attempt to create a unified cognitive model integrating these two factors relied on the parallels between the self-attention mechanism of transformer language models and cue-based retrieval theories of working memory in human sentence processing (Ryu and Lewis 2021). While Ryu and Lewis show that attention patterns in specialized attention heads of GPT-2 are consistent with similarity-based interference, a key prediction of cue-based retrieval models, their method requires identifying syntactically specialized attention heads, and makes the cognitively implausible assumption that hundreds of memory retrieval operations take place in parallel. In the present work, we develop a recurrent neural language model with a single self-attention head, which more closely parallels the memory system assumed by cognitive theories. We show that our model's
    
[^59]: 能跟上我吗？在ChatGPT中测试情景理解能力

    Can You Follow Me? Testing Situational Understanding in ChatGPT. (arXiv:2310.16135v1 [cs.CL])

    [http://arxiv.org/abs/2310.16135](http://arxiv.org/abs/2310.16135)

    这项研究提出了一种新的合成环境用于测试聊天模型的情景理解能力，通过评估模型追踪和列举环境状态的能力，深入分析了性能模式的根本原因。

    

    理解句子的含义并适时更新信息状态，即我们所称的"情景理解"（SU），对于类似ChatGPT的聊天模型来说是一种关键的人工智能能力。SU对于聊天模型特别重要，可以实现人机之间的一致、连贯和有效的对话。先前的研究已经确定了非聊天机器人大型语言模型（LLMs）存在某些SU限制，但对这些限制的程度和原因尚不了解，并且当前聊天模型在这一领域的能力尚未得到探索。本研究解决了这些问题，提出了一种新颖的用于测试聊天导向模型SU的合成环境，通过评估模型跟踪和列举环境状态的能力，实现对SU的受控和系统化测试。我们的环境还允许对模型性能动态进行深入分析，以更好地理解性能模式的根本原因。

    Understanding sentence meanings and updating information states appropriately across time -- what we call "situational understanding" (SU) -- is a critical ability for human-like AI agents. SU is essential in particular for chat models, such as ChatGPT, to enable consistent, coherent, and effective dialogue between humans and AI. Previous works have identified certain SU limitations in non-chatbot Large Language models (LLMs), but the extent and causes of these limitations are not well understood, and capabilities of current chat-based models in this domain have not been explored. In this work we tackle these questions, proposing a novel synthetic environment for SU testing which allows us to do controlled and systematic testing of SU in chat-oriented models, through assessment of models' ability to track and enumerate environment states. Our environment also allows for close analysis of dynamics of model performance, to better understand underlying causes for performance patterns. We 
    
[^60]: GenKIE: 强大的生成式多模态文档关键信息提取

    GenKIE: Robust Generative Multimodal Document Key Information Extraction. (arXiv:2310.16131v1 [cs.CL])

    [http://arxiv.org/abs/2310.16131](http://arxiv.org/abs/2310.16131)

    GenKIE是一种生成式多模态文档关键信息提取模型，采用了弱监督信号和生成模型的优势，在不需要记号级标注和可自动纠正OCR错误的情况下实现了高效的关键信息提取。

    

    由于其在各个领域中的应用，从扫描文档中提取关键信息（KIE）引起了越来越多的关注。虽然一些最近的KIE方法取得了令人期待的结果，但它们通常是基于判别模型构建的，这些模型缺乏处理光学字符识别（OCR）错误的能力，需要费力的记号级标注。在本文中，我们提出了一种新颖的生成式端到端模型，名为GenKIE，来解决KIE任务。GenKIE是一个序列到序列的多模态生成模型，利用多模态编码器嵌入视觉、布局和文本特征，并使用解码器生成所需的输出。设计良好的提示被利用来将标签语义作为弱监督信号并激发关键信息的生成。生成模型的一个显着优势是它可以自动纠正OCR错误。此外，不需要记号级的粒度注释。

    Key information extraction (KIE) from scanned documents has gained increasing attention because of its applications in various domains. Although promising results have been achieved by some recent KIE approaches, they are usually built based on discriminative models, which lack the ability to handle optical character recognition (OCR) errors and require laborious token-level labelling. In this paper, we propose a novel generative end-to-end model, named GenKIE, to address the KIE task. GenKIE is a sequence-to-sequence multimodal generative model that utilizes multimodal encoders to embed visual, layout and textual features and a decoder to generate the desired output. Well-designed prompts are leveraged to incorporate the label semantics as the weakly supervised signals and entice the generation of the key information. One notable advantage of the generative model is that it enables automatic correction of OCR errors. Besides, token-level granular annotation is not required. Extensive 
    
[^61]: Octopus: 用于阿拉伯语自然语言生成的多任务模型和工具包

    Octopus: A Multitask Model and Toolkit for Arabic Natural Language Generation. (arXiv:2310.16127v1 [cs.CL])

    [http://arxiv.org/abs/2310.16127](http://arxiv.org/abs/2310.16127)

    Octopus是一个用于阿拉伯语自然语言生成的多任务模型和工具包，通过新颖的AraT5v2模型和系统训练，在各种预训练策略下实现了优于竞争基准线的性能。

    

    理解阿拉伯文本并产生人类化的回复是一项具有挑战性的任务。尽管许多研究人员提出了针对特定问题的模型和解决方案，但目前缺乏一个全面的阿拉伯语自然语言生成工具包，能够处理各种任务。本研究中，我们提出了一种新颖的阿拉伯文本到文本Transformer模型，名为AraT5v2。我们的新模型在广泛而多样化的数据上进行了系统训练，利用了扩展的序列长度达到2,048个标记。我们探索了各种预训练策略，包括无监督、有监督和联合训练，单任务和多任务设置下的表现。我们的模型在性能上超过了竞争基准线。我们进一步开发并公开发布了Octopus，一个基于Python的套件和命令行工具，专门针对八项阿拉伯语生成任务，全部利用单个模型。我们在我们的公共代码库上发布了模型和工具包。

    Understanding Arabic text and generating human-like responses is a challenging endeavor. While many researchers have proposed models and solutions for individual problems, there is an acute shortage of a comprehensive Arabic natural language generation toolkit that is capable of handling a wide range of tasks. In this work, we present a novel Arabic text-to-text Transformer model, namely AraT5v2. Our new model is methodically trained on extensive and diverse data, utilizing an extended sequence length of 2,048 tokens. We explore various pretraining strategies including unsupervised, supervised, and joint pertaining, under both single and multitask settings. Our models outperform competitive baselines with large margins. We take our work one step further by developing and publicly releasing Octopus, a Python-based package and command-line toolkit tailored for eight Arabic generation tasks all exploiting a single model. We release the models and the toolkit on our public repository.
    
[^62]: NADI 2023：第四届Nuanced阿拉伯方言识别共享任务

    NADI 2023: The Fourth Nuanced Arabic Dialect Identification Shared Task. (arXiv:2310.16117v1 [cs.CL])

    [http://arxiv.org/abs/2310.16117](http://arxiv.org/abs/2310.16117)

    NADI 2023是第四届Nuanced阿拉伯方言识别共享任务，该任务的目标是推进阿拉伯自然语言处理的最新发展。共有58个团队参与，并成功解决了方言识别和方言到MSA机器翻译的挑战。

    

    我们描述了第四届Nuanced阿拉伯方言识别共享任务（NADI 2023）的发现。NADI的目标是通过在标准条件下创建合作竞争的机会，帮助推进最先进的阿拉伯自然语言处理。它专注于阿拉伯方言，提供新颖的数据集，并定义了允许不同方法进行有意义比较的子任务。NADI 2023针对方言识别（子任务1）和方言到MSA机器翻译（子任务2和子任务3）。共有58个独特的团队注册参加了共享任务，其中有18个团队参加了（测试阶段有76个有效的提交）。其中，16个团队参加了子任务1，5个团队参加了子任务2，3个团队参加了子任务3。获胜的团队在子任务1上实现了87.27的F1得分，在子任务2上实现了14.76的Bleu得分，在子任务3上实现了21.10的Bleu得分。结果表明，这三个子任务都仍然具有挑战性。

    We describe the findings of the fourth Nuanced Arabic Dialect Identification Shared Task (NADI 2023). The objective of NADI is to help advance state-of-the-art Arabic NLP by creating opportunities for teams of researchers to collaboratively compete under standardized conditions. It does so with a focus on Arabic dialects, offering novel datasets and defining subtasks that allow for meaningful comparisons between different approaches. NADI 2023 targeted both dialect identification (Subtask 1) and dialect-to-MSA machine translation (Subtask 2 and Subtask 3). A total of 58 unique teams registered for the shared task, of whom 18 teams have participated (with 76 valid submissions during test phase). Among these, 16 teams participated in Subtask 1, 5 participated in Subtask 2, and 3 participated in Subtask 3. The winning teams achieved 87.27  F1 on Subtask 1, 14.76 Bleu in Subtask 2, and 21.10 Bleu in Subtask 3, respectively. Results show that all three subtasks remain challenging, thereby m
    
[^63]: 使用零阶提示的本地差分隐私文档生成

    Locally Differentially Private Document Generation Using Zero Shot Prompting. (arXiv:2310.16111v1 [cs.CL])

    [http://arxiv.org/abs/2310.16111](http://arxiv.org/abs/2310.16111)

    本研究提出了一种本地差分隐私文档生成机制，利用预训练的大型语言模型和零阶提示对抗作者去匿名攻击，同时最小化对下游效用的影响。实验证明，该机制在降低攻击成功率的同时能够完全恢复清洁的情感分数，比现有方法更有效。

    

    大量研究已经强调了预训练的大型语言模型所带来的隐私风险。相比之下，我们的研究提供了一个独特的视角，证明了预训练的大型语言模型可以有效地为隐私保护做出贡献。我们提出了一种名为DP-Prompt的本地差分隐私机制，它利用预训练的大型语言模型和零阶提示来对抗作者去匿名攻击，同时最小化对下游效用的影响。当DP-Prompt与像ChatGPT（gpt-3.5）这样的强大语言模型一起使用时，我们观察到去匿名攻击成功率显著降低，并且尽管其设计更简单，但它超过了现有方法的很大程度。例如，在IMDB数据集的情况下，DP-Prompt（使用ChatGPT）完全恢复了清洁的情感F1分数，并在静态攻击者的作者识别F1分数上实现了46％的降低和26％的减少。

    Numerous studies have highlighted the privacy risks associated with pretrained large language models. In contrast, our research offers a unique perspective by demonstrating that pretrained large language models can effectively contribute to privacy preservation. We propose a locally differentially private mechanism called DP-Prompt, which leverages the power of pretrained large language models and zero-shot prompting to counter author de-anonymization attacks while minimizing the impact on downstream utility. When DP-Prompt is used with a powerful language model like ChatGPT (gpt-3.5), we observe a notable reduction in the success rate of de-anonymization attacks, showing that it surpasses existing approaches by a considerable margin despite its simpler design. For instance, in the case of the IMDB dataset, DP-Prompt (with ChatGPT) perfectly recovers the clean sentiment F1 score while achieving a 46\% reduction in author identification F1 score against static attackers and a 26\% reduc
    
[^64]: CR-COPEC: 从财务报告学习企业绩效变化的因果解释

    CR-COPEC: Causal Rationale of Corporate Performance Changes to Learn from Financial Reports. (arXiv:2310.16095v1 [cs.CL])

    [http://arxiv.org/abs/2310.16095](http://arxiv.org/abs/2310.16095)

    CR-COPEC是一个从财务报告中学习企业绩效变化的因果解释的数据集，可以为个人投资者和分析师提供重要的信息资源，同时考虑了不同行业的特征。

    

    本文介绍了CR-COPEC，即从财务报告中学习企业绩效变化的因果解释。这是一个综合的大规模领域自适应因果句子数据集，用于检测企业的财务绩效变化。CR-COPEC的两个主要贡献是：首先，它从美国公司的10-K年度报告中检测因果解释，这些报告按照正式的会计准则由专家进行因果分析。这个数据集可以广泛应用于个人投资者和分析师，作为投资和决策制定的重要信息资源，无需大量阅读所有文件。其次，它仔细考虑了影响十二个行业公司财务绩效的不同特征。因此，CR-COPEC可以通过考虑每个行业的独特叙述，区分各个行业中的因果句子。我们还对CR-COPEC进行了广泛的分析，以了解其性能。

    In this paper, we introduce CR-COPEC called Causal Rationale of Corporate Performance Changes from financial reports. This is a comprehensive large-scale domain-adaptation causal sentence dataset to detect financial performance changes of corporate. CR-COPEC contributes to two major achievements. First, it detects causal rationale from 10-K annual reports of the U.S. companies, which contain experts' causal analysis following accounting standards in a formal manner. This dataset can be widely used by both individual investors and analysts as material information resources for investing and decision making without tremendous effort to read through all the documents. Second, it carefully considers different characteristics which affect the financial performance of companies in twelve industries. As a result, CR-COPEC can distinguish causal sentences in various industries by taking unique narratives in each industry into consideration. We also provide an extensive analysis of how well CR-
    
[^65]: WebWISE：具有大型语言模型的Web界面控制和顺序探索

    WebWISE: Web Interface Control and Sequential Exploration with Large Language Models. (arXiv:2310.16042v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.16042](http://arxiv.org/abs/2310.16042)

    本文介绍了一种利用大型语言模型（LLM）自动执行Web软件任务的方法，通过步骤性生成小型程序来实现对点击、滚动和文本输入操作的控制。与其他方法相比，该方法在MiniWob++基准测试中通过一个上下文示例就能达到相似或更好的性能。

    

    本文研究了使用大型语言模型（LLM）自动执行点击、滚动和文本输入操作的Web软件任务。之前的方法，如强化学习（RL）或模仿学习，训练效率低且特定于任务。我们的方法使用筛选后的文档对象模型（DOM）元素作为观察，逐步执行任务，根据当前观察生成小型程序。我们使用上下文学习，可以从单个手动提供的示例中获益，或者从成功的零样例试验中生成自动示例。我们在MiniWob++基准测试上评估了所提出的方法。只有一个上下文示例，我们的WebWISE方法的性能与其他需要许多演示或试验的方法相当或更好。

    The paper investigates using a Large Language Model (LLM) to automatically perform web software tasks using click, scroll, and text input operations. Previous approaches, such as reinforcement learning (RL) or imitation learning, are inefficient to train and task-specific. Our method uses filtered Document Object Model (DOM) elements as observations and performs tasks step-by-step, sequentially generating small programs based on the current observations. We use in-context learning, either benefiting from a single manually provided example, or an automatically generated example based on a successful zero-shot trial. We evaluate the proposed method on the MiniWob++ benchmark. With only one in-context example, our WebWISE method achieves similar or better performance than other methods that require many demonstrations or trials.
    
[^66]: 使用具有专门口音代码本的口音识别

    Accented Speech Recognition With Accent-specific Codebooks. (arXiv:2310.15970v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.15970](http://arxiv.org/abs/2310.15970)

    本研究提出了一种使用具有专门口音代码本的口音适应方法，通过交叉注意力和可训练代码本，用于端到端ASR系统。在实验证明了该方法在已见和未见的口音上都能获得显著的性能提升。

    

    语音口音对于现有自动语音识别（ASR）系统构成了重要挑战。在代表性不足的口音中的性能下降严重阻碍了ASR的普及应用。本研究提出了一种新颖的口音适应方法，通过交叉注意力和可训练代码本，用于端到端ASR系统。这些可学习的代码本捕捉了口音特定信息，并被整合到ASR编码器层中。模型在带口音的英语语音上进行训练，而测试数据中也包含了在训练过程中未见过的口音。在Mozilla Common Voice多口音数据集上，我们展示了我们提出的方法在不仅在已见的英语口音中获得显著的性能提升（单词错误率相对提升高达37%），而且在未见的口音上也获得了5%的相对提升。此外，我们还展示了在L2Artic数据集上的零样本迁移设置的好处。我们还进行了对比实验。

    Speech accents pose a significant challenge to state-of-the-art automatic speech recognition (ASR) systems. Degradation in performance across underrepresented accents is a severe deterrent to the inclusive adoption of ASR. In this work, we propose a novel accent adaptation approach for end-to-end ASR systems using cross-attention with a trainable set of codebooks. These learnable codebooks capture accent-specific information and are integrated within the ASR encoder layers. The model is trained on accented English speech, while the test data also contained accents which were not seen during training. On the Mozilla Common Voice multi-accented dataset, we show that our proposed approach yields significant performance gains not only on the seen English accents (up to $37\%$ relative improvement in word error rate) but also on the unseen accents (up to $5\%$ relative improvement in WER). Further, we illustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We also compare
    
[^67]: COPF: 通过最优策略拟合实现持续学习人类偏好

    COPF: Continual Learning Human Preference through Optimal Policy Fitting. (arXiv:2310.15694v1 [cs.LG])

    [http://arxiv.org/abs/2310.15694](http://arxiv.org/abs/2310.15694)

    通过COPF方法，我们不需要重新训练预训练语言模型，而是使用最优策略拟合和函数正则化来持续学习和适应人类偏好的变化。

    

    强化学习通过人类反馈（RLHF）的技术是改善预训练语言模型（LM）以符合人类偏好的常用方法。然而，当前基于RLHF的LM在引入新的查询或反馈时需要完全重新训练，这是一项具有挑战性的任务，因为人类偏好在不同领域或任务之间可能会有所变化。由于所需的时间和计算资源以及与数据隐私相关的问题，重新训练LM在许多现实世界的情况下存在实际困难。为了解决这个限制，我们提出了一种新的方法，称为持续最优策略拟合（COPF），其中我们使用蒙特卡罗法估计一系列最优策略，然后通过函数正则化不断拟合策略序列。COPF包含一个单一的学习阶段，不需要复杂的强化学习。

    The technique of Reinforcement Learning from Human Feedback (RLHF) is a commonly employed method to improve pre-trained Language Models (LM), enhancing their ability to conform to human preferences. Nevertheless, the current RLHF-based LMs necessitate full retraining each time novel queries or feedback are introduced, which becomes a challenging task because human preferences can vary between different domains or tasks. Retraining LMs poses practical difficulties in many real-world situations due to the significant time and computational resources required, along with concerns related to data privacy. To address this limitation, we propose a new method called Continual Optimal Policy Fitting (COPF), in which we estimate a series of optimal policies using the Monte Carlo method, and then continually fit the policy sequence with the function regularization. COPF involves a single learning phase and doesn't necessitate complex reinforcement learning. Importantly, it shares the capability 
    
[^68]: TCRA-LLM: 用于减少推理成本的令牌压缩检索增强大型语言模型

    TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction. (arXiv:2310.15556v1 [cs.CL])

    [http://arxiv.org/abs/2310.15556](http://arxiv.org/abs/2310.15556)

    TCRA-LLM是通过概述压缩和语义压缩两种方法来减少商业大型语言模型推理成本的方案。

    

    自从ChatGPT发布了API供公众使用以来，构建在商业大型语言模型（LLM）之上的应用程序数量呈指数增长。这种模型的一个流行用法是利用其上下文学习能力并生成响应以回答用户查询，并利用检索增强获得的知识。部署商业检索增强型LLM的一个问题是成本，因为额外检索的上下文大大增加了LLM的输入标记量。为了缓解这个问题，我们提出了一种令牌压缩方案，包括两种方法：概述压缩和语义压缩。第一种方法使用基于T5模型，通过使用包含具有不同长度的样本的自指示数据集进行微调，并通过概述来减少令牌大小。第二种方法通过移除对语义影响较小的词来进一步压缩令牌大小。为了充分评估所提方法的有效性，

    Since ChatGPT released its API for public use, the number of applications built on top of commercial large language models (LLMs) increase exponentially. One popular usage of such models is leveraging its in-context learning ability and generating responses given user queries leveraging knowledge obtained by retrieval augmentation. One problem of deploying commercial retrieval-augmented LLMs is the cost due to the additionally retrieved context that largely increases the input token size of the LLMs. To mitigate this, we propose a token compression scheme that includes two methods: summarization compression and semantic compression. The first method applies a T5-based model that is fine-tuned by datasets generated using self-instruct containing samples with varying lengths and reduce token size by doing summarization. The second method further compresses the token size by removing words with lower impact on the semantic. In order to adequately evaluate the effectiveness of the proposed
    
[^69]: FANToM: 在交互中对机器心智理论进行压力测试的基准

    FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions. (arXiv:2310.15421v1 [cs.CL])

    [http://arxiv.org/abs/2310.15421](http://arxiv.org/abs/2310.15421)

    FANToM是一个新的基准，用于通过问答在信息不对称的对话环境中压力测试机器的心智理论。这个基准对最先进的大型语言模型来说具有挑战性，即使是具有思维链推理和微调的模型也比人类表现得差。

    

    目前关于心智理论（ToM）的评估主要集中在使用缺乏互动性的被动故事，我们介绍了FANToM，一个新的基准，通过问答在信息不对称的对话环境中进行心智理论的压力测试。我们的基准结合了心理学中的重要理论要求和对评估大型语言模型（LLM）时必要的经验考虑。特别地，我们制定了多种类型的问题，要求相同的基本推理来识别LLM中不存在或虚假的心智理论能力。我们展示了FANToM对最先进的LLM来说具有挑战性，即使是具有思维链推理和微调的LLM也表现比人类差得多。

    Theory of mind (ToM) evaluations currently focus on testing models using passive narratives that inherently lack interactivity. We introduce FANToM, a new benchmark designed to stress-test ToM within information-asymmetric conversational contexts via question answering. Our benchmark draws upon important theoretical requisites from psychology and necessary empirical considerations when evaluating large language models (LLMs). In particular, we formulate multiple types of questions that demand the same underlying reasoning to identify illusory or false sense of ToM capabilities in LLMs. We show that FANToM is challenging for state-of-the-art LLMs, which perform significantly worse than humans even with chain-of-thought reasoning or fine-tuning.
    
[^70]: 任务导向对话的相似度度量方法

    TaskDiff: A Similarity Metric for Task-Oriented Conversations. (arXiv:2310.15298v1 [cs.CL])

    [http://arxiv.org/abs/2310.15298](http://arxiv.org/abs/2310.15298)

    TaskDiff是一种新颖的对话相似度度量方法，通过使用不同的对话组成部分来计算相似度，取得了优越的性能和鲁棒性。

    

    会话式数字助手的普及导致了大量会话数据的可用性，这可以用于改善用户体验和个性化响应生成。使用像ChatGPT这样的流行大型语言模型构建这些助手还需要额外强调提示工程和评估方法。文本相似度度量是这种分析和评估的关键因素。虽然文献中提出了许多相似度度量方法，但它们在任务导向对话方面并不有效，因为它们没有充分利用独特的对话特征。为了填补这一差距，我们提出了一种新颖的对话相似度度量方法TaskDiff，它利用对话的不同组成部分（话语、意图和槽）及其分布来计算相似度。在基准数据集上进行的广泛实验证明了TaskDiff在性能和鲁棒性方面的优越表现，超过了其他相关方法。

    The popularity of conversational digital assistants has resulted in the availability of large amounts of conversational data which can be utilized for improved user experience and personalized response generation. Building these assistants using popular large language models like ChatGPT also require additional emphasis on prompt engineering and evaluation methods. Textual similarity metrics are a key ingredient for such analysis and evaluations. While many similarity metrics have been proposed in the literature, they have not proven effective for task-oriented conversations as they do not take advantage of unique conversational features. To address this gap, we present TaskDiff, a novel conversational similarity metric that utilizes different dialogue components (utterances, intents, and slots) and their distributions to compute similarity. Extensive experimental evaluation of TaskDiff on a benchmark dataset demonstrates its superior performance and improved robustness over other rela
    
[^71]: 基于多专家微调的中国金融大型语言模型DISC-FinLLM

    DISC-FinLLM: A Chinese Financial Large Language Model based on Multiple Experts Fine-tuning. (arXiv:2310.15205v1 [cs.CL])

    [http://arxiv.org/abs/2310.15205](http://arxiv.org/abs/2310.15205)

    我们提出了一种基于多专家微调的金融大型语言模型DISC-FinLLM，通过赋予模型多轮问答、领域文本处理、数学计算和检索增强生成能力，我们的模型在多个金融场景中表现出更好的性能。

    

    我们提出了一种基于多专家微调框架的金融大型语言模型DISC-FinLLM。我们的方法通过赋予通用语言模型多轮问答能力、领域文本处理能力、数学计算技能和检索增强生成能力来改进通用语言模型。我们构建了一个金融指令微调数据集DISC-FIN-SFT，包括四个分类的指令样本（咨询、自然语言处理任务、计算和检索增强生成）。在多个基准测试上进行的评估表明，我们的模型在各种金融场景中优于基准模型。更多资源可以在https://github.com/FudanDISC/DISC-FinLLM找到。

    We propose Multiple Experts Fine-tuning Framework to build a financial large language model (LLM), DISC-FinLLM. Our methodology improves general LLMs by endowing them with multi-turn question answering abilities, domain text processing capabilities, mathematical computation skills, and retrieval-enhanced generation capabilities. We build a financial instruction-tuning dataset named DISC-FIN-SFT, including instruction samples of four categories (consulting, NLP tasks, computing and retrieval-augmented generation). Evaluations conducted on multiple benchmarks demonstrate that our model performs better than baseline models in various financial scenarios. Further resources can be found at https://github.com/FudanDISC/DISC-FinLLM.
    
[^72]: NormDial: 用于模拟社会规范遵守和违反的可比较双语合成对话数据集

    NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling Social Norm Adherence and Violation. (arXiv:2310.14563v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.14563](http://arxiv.org/abs/2310.14563)

    NormDial是一个高质量的双语合成对话数据集，用于模拟社会规范的遵守和违反。通过引入社会规范遵守检测任务，该数据集能够帮助我们深入了解跨语言和文化背景下对话环境中社会规范的细微差别。

    

    社会规范从根本上塑造了人际交流。我们提供了NormDial，一个高质量的双人对话数据集，其中包含了中美两种文化的社会规范遵守和违反的逐轮注释。通过引入社会规范遵守检测任务，我们使用人机协作的方式，通过使用少量专家注释的社会规范提示大型语言模型在中英文中生成数据。我们通过人工评估证明了我们生成的对话质量很高，进一步评估了现有大型语言模型在这一任务上的性能。我们的研究结果指向了新的方向，以了解跨语言和文化背景下的对话环境中社会规范的微妙之处。

    Social norms fundamentally shape interpersonal communication. We present NormDial, a high-quality dyadic dialogue dataset with turn-by-turn annotations of social norm adherences and violations for Chinese and American cultures. Introducing the task of social norm observance detection, our dataset is synthetically generated in both Chinese and English using a human-in-the-loop pipeline by prompting large language models with a small collection of expert-annotated social norms. We show that our generated dialogues are of high quality through human evaluation and further evaluate the performance of existing large language models on this task. Our findings point towards new directions for understanding the nuances of social norms as they manifest in conversational contexts that span across languages and cultures.
    
[^73]: Hunayn：超越字面意义的翻译进步

    Hunayn: Elevating Translation Beyond the Literal. (arXiv:2310.13613v1 [cs.CL])

    [http://arxiv.org/abs/2310.13613](http://arxiv.org/abs/2310.13613)

    这项研究介绍了一种超越传统工具的高级英译阿拉伯语翻译器，使用赫尔辛基变压器和纯文学阿拉伯语数据集，表现出色，并强调了其在文化敏感性和语境准确性方面的优势。

    

    该项目介绍了一种超越传统工具的高级英译阿拉伯语翻译器。利用赫尔辛基变压器（MarianMT），我们的方法涉及在一个自动生成的、纯文学阿拉伯语数据集上进行微调。与谷歌翻译的评估表明，在定性评估中始终表现出色。值得注意的是，它在文化敏感性和语境准确性方面表现出色。这项研究强调了赫尔辛基变压器在使用Fusha数据集的英阿翻译中的优势。

    This project introduces an advanced English-to-Arabic translator surpassing conventional tools. Leveraging the Helsinki transformer (MarianMT), our approach involves fine-tuning on a self-scraped, purely literary Arabic dataset. Evaluations against Google Translate show consistent outperformance in qualitative assessments. Notably, it excels in cultural sensitivity and context accuracy. This research underscores the Helsinki transformer's superiority for English-to-Arabic translation using a Fusha dataset.
    
[^74]: 多尺度超像素结构差异图卷积网络用于视觉语言表征

    Multiscale Superpixel Structured Difference Graph Convolutional Network for VL Representation. (arXiv:2310.13447v1 [cs.CV])

    [http://arxiv.org/abs/2310.13447](http://arxiv.org/abs/2310.13447)

    本文提出了一种多尺度超像素结构差异图卷积网络（MDGCN）用于视觉语言表征，通过聚类感知相似像素，减少了后续处理的视觉基元数量，并挖掘了更精确的拓扑关系。

    

    在多模态领域中，整合视觉和语言的关键在于建立一个良好的对齐策略。最近，受到自监督学习成功的启发，基于预训练模型的视觉和语言的多模态语义表征取得了重大进展。然而，视觉语义表征仍有改进的空间。当前基于像素或块的方法在准确提取复杂场景边界方面存在空间语义连贯性不足和对噪声的脆弱性的挑战。为此，本文将超像素作为可学习图像数据的综合紧凑表征，通过对感知相似像素进行聚类，有效地减少了后续处理的视觉基元数量。为了挖掘更精确的拓扑关系，我们提出了一种多尺度差异图卷积网络（MDGCN）。它将整个图像解析为细到粗的层次结构，从而实现了整个图像的解析。

    Within the multimodal field, the key to integrating vision and language lies in establishing a good alignment strategy. Recently, benefiting from the success of self-supervised learning, significant progress has been made in multimodal semantic representation based on pre-trained models for vision and language. However, there is still room for improvement in visual semantic representation. The lack of spatial semantic coherence and vulnerability to noise makes it challenging for current pixel or patch-based methods to accurately extract complex scene boundaries. To this end, this paper develops superpixel as a comprehensive compact representation of learnable image data, which effectively reduces the number of visual primitives for subsequent processing by clustering perceptually similar pixels. To mine more precise topological relations, we propose a Multiscale Difference Graph Convolutional Network (MDGCN). It parses the entire image as a fine-to-coarse hierarchical structure of cons
    
[^75]: 通过反向图卷积实现鲁棒的跨模态检索

    InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution. (arXiv:2310.13276v1 [cs.CV])

    [http://arxiv.org/abs/2310.13276](http://arxiv.org/abs/2310.13276)

    通过反向图卷积进行的鲁棒跨模态检索，解决了表示退化问题，并通过增加数据点之间的距离来有效分离不同模态的表示。

    

    近年来，跨模态检索的重大进展主要是通过视觉和语言建模的突破推动的。然而，最近的研究表明，多模态数据表示往往在有限的凸锥内聚集（作为表示退化问题），这由于这些表示的不可分离性而阻碍了检索性能。在我们的研究中，我们首先通过多个跨模态基准和方法经验证实了表示退化问题的存在。接下来，为了解决这个问题，我们引入了一种新方法，称为InvGC，它是一种受图卷积和平均池化启发的后处理技术。具体而言，InvGC在数据集中定义图拓扑，然后应用图卷积以一种减法的方式。这种方法通过增加数据点之间的距离来有效地分离表示。为了提高InvGC的效率和效果，我们提出了一个高级图拓扑，Lo

    Over recent decades, significant advancements in cross-modal retrieval are mainly driven by breakthroughs in visual and linguistic modeling. However, a recent study shows that multi-modal data representations tend to cluster within a limited convex cone (as representation degeneration problem), which hinders retrieval performance due to the inseparability of these representations. In our study, we first empirically validate the presence of the representation degeneration problem across multiple cross-modal benchmarks and methods. Next, to address it, we introduce a novel method, called InvGC, a post-processing technique inspired by graph convolution and average pooling. Specifically, InvGC defines the graph topology within the datasets and then applies graph convolution in a subtractive manner. This method effectively separates representations by increasing the distances between data points. To improve the efficiency and effectiveness of InvGC, we propose an advanced graph topology, Lo
    
[^76]: CLAIR: 用大型语言模型评估图像标题

    CLAIR: Evaluating Image Captions with Large Language Models. (arXiv:2310.12971v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2310.12971](http://arxiv.org/abs/2310.12971)

    CLAIR是一种基于大型语言模型的新方法，用于评估机器生成的图像标题。相对于现有的评估方法，CLAIR在与人类判断的相关性方面表现更好，并针对具体数据集取得了较大改进。

    

    机器生成图像标题的评估是一个有趣但持久存在的挑战。有效的评估指标必须考虑多个相似性维度，包括语义相关性、视觉结构、物体交互、标题多样性和特定性。现有的高度工程化的评估方法试图捕捉特定方面，但在提供与人类判断密切一致的整体评分方面仍有不足之处。在这里，我们提出了CLAIR，一种利用大型语言模型（LLM）的零射语言建模能力来评估候选标题的新方法。在我们的评估中，CLAIR相对于现有指标更能与人类对标题质量的判断相关。值得注意的是，在Flickr8K-Expert上，CLAIR在与SPICE相比的相关改进方面提高了39.6％，在与RefCLIP-S等图像增强方法相比的相关改进方面提高了18.3％。此外，CLAIR提供了可解释性结果，允许语言模型识别u

    The evaluation of machine-generated image captions poses an interesting yet persistent challenge. Effective evaluation measures must consider numerous dimensions of similarity, including semantic relevance, visual structure, object interactions, caption diversity, and specificity. Existing highly-engineered measures attempt to capture specific aspects, but fall short in providing a holistic score that aligns closely with human judgments. Here, we propose CLAIR, a novel method that leverages the zero-shot language modeling capabilities of large language models (LLMs) to evaluate candidate captions. In our evaluations, CLAIR demonstrates a stronger correlation with human judgments of caption quality compared to existing measures. Notably, on Flickr8K-Expert, CLAIR achieves relative correlation improvements over SPICE of 39.6% and over image-augmented methods such as RefCLIP-S of 18.3%. Moreover, CLAIR provides noisily interpretable results by allowing the language model to identify the u
    
[^77]: 大型语言模型用于多目标进化优化

    Large Language Model for Multi-objective Evolutionary Optimization. (arXiv:2310.12541v1 [cs.NE])

    [http://arxiv.org/abs/2310.12541](http://arxiv.org/abs/2310.12541)

    本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。

    

    多目标进化算法（MOEAs）是解决多目标优化问题（MOPs）的主要方法。在过去几十年中，提出了许多MOEAs，其操作符需要通过领域知识进行精心设计。最近，一些尝试将MOEAs中手动设计的操作符替换为基于学习的操作符（如神经网络模型）已经取得了一些进展。然而，设计和训练这样的模型仍然需要大量的工作，并且学习到的操作符可能不能很好地推广到解决新问题。为了解决上述挑战，本文研究了一种利用强大的大型语言模型（LLM）来设计MOEA操作符的新方法。通过适当的提示工程，我们成功地让一个通用的LLM以零-shot的方式作为分解型MOEA（MOEA/D）的黑盒搜索操作符。此外，通过从LLM行为中学习，我们进一步设计了一个显性的白盒操作符，并提出了...

    Multiobjective evolutionary algorithms (MOEAs) are major methods for solving multiobjective optimization problems (MOPs). Many MOEAs have been proposed in the past decades, of which the operators need carefully handcrafted design with domain knowledge. Recently, some attempts have been made to replace the manually designed operators in MOEAs with learning-based operators (e.g., neural network models). However, much effort is still required for designing and training such models, and the learned operators might not generalize well to solve new problems. To tackle the above challenges, this work investigates a novel approach that leverages the powerful large language model (LLM) to design MOEA operators. With proper prompt engineering, we successfully let a general LLM serve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a zero-shot manner. In addition, by learning from the LLM behavior, we further design an explicit white-box operator with randomness and propose
    
[^78]: 代词故事：可解释性指导下的公平指导机器翻译中的性别偏见缓解

    A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation. (arXiv:2310.12127v1 [cs.CL])

    [http://arxiv.org/abs/2310.12127](http://arxiv.org/abs/2310.12127)

    本研究通过调查机器翻译模型中的性别偏见问题以及缓解性别偏见的方法来填补现有研究的空白。研究发现指导微调模型在默认为男性翻译上存在性别偏见，同时忽视了指示职业性别的代词，并提出了一些可行的缓解策略。

    

    最近的指导微调模型可在多个NLP任务中解决问题，其中机器翻译（MT）是一个突出的用例。然而，当前的研究通常集中在标准性能基准上，忽视了引人注目的公平和伦理考虑。在MT中，这可能导致性别错误的翻译，从而导致刻板印象和偏见的持续存在。在这项工作中，我们通过调查这些模型在机器翻译中是否存在性别偏见以及如何缓解性别偏见来填补这一空白。具体而言，我们在从英文到德文和西班牙文的WinoMT语料库上计算已建立的性别偏见指标。我们发现指导微调模型默认为男性屈从翻译，甚至忽视女性职业刻板印象。接下来，使用可解释性方法，我们揭示了模型系统性地忽视指示目标职业性别的代词在同时性别错误的翻译中。最后，根据可解释性的发现，我们提出了性别偏见缓解的策略，并将其应用于MT模型中。

    Recent instruction fine-tuned models can solve multiple NLP tasks when prompted to do so, with machine translation (MT) being a prominent use case. However, current research often focuses on standard performance benchmarks, leaving compelling fairness and ethical considerations behind. In MT, this might lead to misgendered translations, resulting, among other harms, in the perpetuation of stereotypes and prejudices. In this work, we address this gap by investigating whether and to what extent such models exhibit gender bias in machine translation and how we can mitigate it. Concretely, we compute established gender bias metrics on the WinoMT corpus from English to German and Spanish. We discover that IFT models default to male-inflected translations, even disregarding female occupational stereotypes. Next, using interpretability methods, we unveil that models systematically overlook the pronoun indicating the gender of a target occupation in misgendered translations. Finally, based on 
    
[^79]: MusicAgent：一种用于音乐理解和生成的人工智能代理，基于大型语言模型

    MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models. (arXiv:2310.11954v1 [cs.CL])

    [http://arxiv.org/abs/2310.11954](http://arxiv.org/abs/2310.11954)

    MusicAgent是一个使用大型语言模型的AI代理，通过集成音乐相关工具和自主工作流程，帮助用户自动分析需求并调用合适的工具进行音乐处理。

    

    AI-加强的音乐处理是一个多样化的领域，涵盖了许多任务，从生成任务（例如音色合成）到理解任务（例如音乐分类）。对于开发人员和业余爱好者来说，很难掌握所有这些任务，以满足他们在音乐处理方面的需求，尤其考虑到音乐数据的表示和不同任务之间的模型适用性在各个平台上存在巨大差异。因此，建立一个系统来组织和集成这些任务，并帮助从业者自动分析他们的需求并调用适当的工具作为解决方案来满足他们的要求是必要的。受大型语言模型（LLMs）在任务自动化方面的最新成功启示，我们开发了一个名为MusicAgent的系统，它集成了众多与音乐相关的工具和自主工作流程，以满足用户的需求。

    AI-empowered music processing is a diverse field that encompasses dozens of tasks, ranging from generation tasks (e.g., timbre synthesis) to comprehension tasks (e.g., music classification). For developers and amateurs, it is very difficult to grasp all of these task to satisfy their requirements in music processing, especially considering the huge differences in the representations of music data and the model applicability across platforms among various tasks. Consequently, it is necessary to build a system to organize and integrate these tasks, and thus help practitioners to automatically analyze their demand and call suitable tools as solutions to fulfill their requirements. Inspired by the recent success of large language models (LLMs) in task automation, we develop a system, named MusicAgent, which integrates numerous music-related tools and an autonomous workflow to address user requirements. More specifically, we build 1) toolset that collects tools from diverse sources, includi
    
[^80]: VoxArabica：一个稳健的方言感知阿拉伯语音识别系统

    VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System. (arXiv:2310.11069v1 [cs.CL])

    [http://arxiv.org/abs/2310.11069](http://arxiv.org/abs/2310.11069)

    VoxArabica是一个稳健的方言感知阿拉伯语音识别系统，通过开发和演示，实现了阿拉伯语方言识别和自动语音识别。该系统训练了各种模型用于不同方言的识别，并提供了多种功能的网络界面。

    

    阿拉伯语是一种复杂的语言，全球有超过4.5亿人口使用许多不同的方言和口音。由于语言的多样性和变化，为阿拉伯语构建一个稳健且通用的语音识别系统具有挑战性。在这项工作中，我们通过开发和演示一个名为VoxArabica的系统，解决了这个问题，用于方言识别(DID)和阿拉伯语自动语音识别(ASR)。我们在监督环境下训练了各种模型，例如HuBERT(DID)、Whisper和XLS-R(ASR)，用于阿拉伯语的DID和ASR任务。我们的DID模型被训练用于识别除了标准阿拉伯之外的17种不同的方言。我们在标准阿拉伯语(MSA)、埃及语、摩洛哥语和混合数据上微调我们的ASR模型。此外，对于ASR中的其他方言，我们提供了Whisper和MMS等不同模型的选择。我们将这些模型集成到一个单一的网络界面中，具有多样的功能，如音频录制、上传文件、模型选择和提出问题的选项。

    Arabic is a complex language with many varieties and dialects spoken by over 450 millions all around the world. Due to the linguistic diversity and variations, it is challenging to build a robust and generalized ASR system for Arabic. In this work, we address this gap by developing and demoing a system, dubbed VoxArabica, for dialect identification (DID) as well as automatic speech recognition (ASR) of Arabic. We train a wide range of models such as HuBERT (DID), Whisper, and XLS-R (ASR) in a supervised setting for Arabic DID and ASR tasks. Our DID models are trained to identify 17 different dialects in addition to MSA. We finetune our ASR models on MSA, Egyptian, Moroccan, and mixed data. Additionally, for the remaining dialects in ASR, we provide the option to choose various models such as Whisper and MMS in a zero-shot setting. We integrate these models into a single web interface with diverse features such as audio recording, file upload, model selection, and the option to raise fl
    
[^81]: 区块链资产监管的自然语言处理：一份路线图

    NLP for Crypto-Asset Regulation: A Roadmap. (arXiv:2310.10333v1 [cs.CY])

    [http://arxiv.org/abs/2310.10333](http://arxiv.org/abs/2310.10333)

    这篇论文介绍了自然语言处理在加密资产监管中的应用，并提出了两个贡献。首先，调查了对未受监管的加密资产白皮书进行文本分析的现有应用，并发现了研究空白。然后，分析了欧盟的加密资产市场法规引入的变化，探讨了在新的监管框架内整合自然语言处理的机遇和挑战。这些发现为未来的研究提供了基础，有潜力使监管机构、加密资产发行者和投资者受益。

    

    在快速发展的区块链资产领域，白皮书是投资者指导的重要文件，在欧盟的加密资产市场法规（MiCAR）下，它们现在面临前所未有的内容要求。自然语言处理可以作为分析这些文件和协助监管合规的强大工具。本文为该主题提供了两个贡献。首先，我们调查了对未受监管的区块链资产白皮书进行文本分析的现有应用，发现了可以通过跨学科合作来填补研究空白。然后，我们对MiCAR引入的变化进行了分析，突出了在新的监管框架内整合自然语言处理的机遇和挑战。我们的研究结果为进一步的研究奠定了基础，并有潜力使监管机构、区块链资产发行者和投资者受益。

    In the rapidly evolving field of crypto-assets, white papers are essential documents for investor guidance, and are now subject to unprecedented content requirements under the EU's Markets in Crypto-Assets Regulation (MiCAR). Natural Language Processing can serve as a powerful tool for both analyzing these documents and assisting in regulatory compliance. This paper delivers two contributions to the topic. First, we survey existing applications of textual analysis to unregulated crypto-asset white papers, uncovering a research gap that could be bridged with interdisciplinary collaboration. We then conduct an analysis of the changes introduced by MiCAR, highlighting the opportunities and challenges of integrating NLP within the new regulatory framework. Our findings set the stage for further research, with the potential to benefit regulators, crypto-asset issuers, and investors.
    
[^82]: KGQuiz: 评估大型语言模型中编码知识的泛化能力

    KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models. (arXiv:2310.09725v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.09725](http://arxiv.org/abs/2310.09725)

    KGQuiz是一个知识密集型基准测试，通过涵盖三个知识领域和五个任务，全面评估了大型语言模型(LLMs)的知识泛化能力。

    

    大型语言模型(LLMs)在知识密集型任务上表现出色，这表明真实世界的知识被编码在它们的模型参数中。然而，除了在有限的知识领域上进行一些探索性任务之外，我们对于如何系统评估LLMs的知识能力以及它们的知识能力在不同领域和逐渐复杂的任务格式中的泛化效果并不了解。为了解决这个问题，我们提出了KGQuiz，一个知识密集型基准测试，全面调查LLMs的知识泛化能力。KGQuiz是一个可扩展的框架，由基于三元组的知识构建，涵盖了三个知识领域，并包括五个任务，难度递增：真假判断、多项选择问题、填空、事实编辑和开放式知识生成。为了更好地理解LLMs的知识能力和它们的泛化效果，我们评估了10种开源和黑盒LLMs。

    Large language models (LLMs) demonstrate remarkable performance on knowledge-intensive tasks, suggesting that real-world knowledge is encoded in their model parameters. However, besides explorations on a few probing tasks in limited knowledge domains, it is not well understood how to evaluate LLMs' knowledge systematically and how well their knowledge abilities generalize, across a spectrum of knowledge domains and progressively complex task formats. To this end, we propose KGQuiz, a knowledge-intensive benchmark to comprehensively investigate the knowledge generalization abilities of LLMs. KGQuiz is a scalable framework constructed from triplet-based knowledge, which covers three knowledge domains and consists of five tasks with increasing complexity: true-or-false, multiple-choice QA, blank filling, factual editing, and open-ended knowledge generation. To gain a better understanding of LLMs' knowledge abilities and their generalization, we evaluate 10 open-source and black-box LLMs o
    
[^83]: 使用人工编辑改进摘要生成

    Improving Summarization with Human Edits. (arXiv:2310.05857v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05857](http://arxiv.org/abs/2310.05857)

    本文介绍了一种改进摘要生成的方法，使用人工编辑的反馈数据，并通过序列对齐（不）似然训练(SALT)技术将人工编辑数据与模型生成数据结合起来。实验证明了这种方法在医学领域摘要生成中的有效性。

    

    最近的研究表明，通过人类反馈范式学习可以产生高质量的文本。现有的工作在通用领域抽象化摘要生成中使用人类反馈来训练大型语言模型(LLMs)，并获得了超越传统似然训练的摘要质量。在本文中，我们关注一种较少探索的人类反馈形式——人工编辑。我们提出了一种新颖的技术——序列对齐（不）似然训练(SALT)，在训练循环中同时使用人工编辑和模型生成的数据。此外，我们还展示了使用现有训练数据中的基准摘要来模拟人工编辑，以及在训练后获取的模型生成摘要，以减少对昂贵的人工编辑数据的需求。在实验中，我们将人类反馈的探索从通用领域摘要生成扩展到医学领域摘要生成。我们的结果表明SALT在改进摘要生成方面的有效性。

    Recent work has shown the promise of learning with human feedback paradigms to produce human-determined high-quality text. Existing works use human feedback to train large language models (LLMs) in general domain abstractive summarization and have obtained summary quality exceeding traditional likelihood training. In this paper, we focus on a less explored form of human feedback -- Human Edits. We propose Sequence Alignment (un)Likelihood Training (SALT), a novel technique to use both the human-edited and model-generated data together in the training loop. In addition, we demonstrate simulating Human Edits with ground truth summaries coming from existing training data -Imitation edits, along with the model-generated summaries obtained after the training, to reduce the need for expensive human-edit data. In our experiments, we extend human feedback exploration from general domain summarization to medical domain summarization. Our results demonstrate the effectiveness of SALT in improv
    
[^84]: LLMs在理解反向关系中的无效性的调查

    An Investigation of LLMs' Inefficacy in Understanding Converse Relations. (arXiv:2310.05163v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05163](http://arxiv.org/abs/2310.05163)

    本论文调查了LLMs在理解反向关系方面的无效性。作者引入了一个名为ConvRe的新基准，专注于逆向关系。通过两个任务Re2Text和Text2Re，作者评估了LLMs确定关系和相关文本之间匹配能力。实验结果揭示了LLMs在此方面的限制。

    

    大型语言模型（LLMs）在许多形式语言导向的任务中取得了显着的成功，如结构化数据到文本和语义解析。然而，当前的基准大多遵循LLMs的预训练数据的数据分布。因此，一个自然的问题是，LLMs真正理解形式语言的结构化语义吗？本文在特殊情况下，即逆向二进制关系上进行了调查。我们引入了一个名为ConvRe的新基准，专注于逆向关系，其中包含来自知识图谱完成数据集的17个关系和1240个三元组。我们的ConvRE包括两个任务，Re2Text和Text2Re，这些任务被制定为多项选择题，用于评估LLMs确定关系和相关文本之间匹配能力。在评估协议方面，除了不同的提示方法，我们还引入了测试文本和少样本示例文本的变体。我们在三个实验上进行实验。

    Large Language Models (LLMs) have achieved remarkable success in many formal language oriented tasks, such as structural data-to-text and semantic parsing. However current benchmarks mostly follow the data distribution of the pre-training data of LLMs. Therefore, a natural question rises that do LLMs really understand the structured semantics of formal languages. In this paper, we investigate this problem on a special case, converse binary relation. We introduce a new benchmark ConvRe focusing on converse relations, which contains 17 relations and 1240 triples extracted from popular knowledge graph completion datasets. Our ConvRE features two tasks, Re2Text and Text2Re, which are formulated as multi-choice question answering to evaluate LLMs' ability to determine the matching between relations and associated text. For the evaluation protocol, apart from different prompting methods, we further introduce variants to the test text and few-shot example text. We conduct experiments on three
    
[^85]: 评估中文大型语言模型中的幻觉

    Evaluating Hallucinations in Chinese Large Language Models. (arXiv:2310.03368v1 [cs.CL])

    [http://arxiv.org/abs/2310.03368](http://arxiv.org/abs/2310.03368)

    本研究评估了中文大型语言模型中的幻觉现象，通过建立HalluQA基准测试和使用GPT-4进行自动评估方法，发现18个模型的非幻觉率低于50%。研究分析了不同类型模型中的幻觉类型和原因。

    

    本文介绍了一项名为HalluQA（中文幻觉问答）的基准测试，用于衡量中文大型语言模型中的幻觉现象。HalluQA包含450个经过精心设计的对抗性问题，涵盖多个领域，并考虑了中国历史文化、风俗和社会现象。在构建HalluQA过程中，我们考虑了两种幻觉类型：模仿性虚假和事实错误，并基于GLM-130B和ChatGPT构建对抗样本。为了评估，我们设计了一种使用GPT-4的自动评估方法来判断模型输出是否是幻觉。我们对24个大型语言模型进行了广泛的实验，包括ERNIE-Bot、Baichuan2、ChatGLM、Qwen、SparkDesk等。在这24个模型中，有18个的非幻觉率低于50%。这表明HalluQA具有很高的挑战性。我们分析了不同类型模型中主要的幻觉类型及其原因。

    In this paper, we establish a benchmark named HalluQA (Chinese Hallucination Question-Answering) to measure the hallucination phenomenon in Chinese large language models. HalluQA contains 450 meticulously designed adversarial questions, spanning multiple domains, and takes into account Chinese historical culture, customs, and social phenomena. During the construction of HalluQA, we consider two types of hallucinations: imitative falsehoods and factual errors, and we construct adversarial samples based on GLM-130B and ChatGPT. For evaluation, we design an automated evaluation method using GPT-4 to judge whether a model output is hallucinated. We conduct extensive experiments on 24 large language models, including ERNIE-Bot, Baichuan2, ChatGLM, Qwen, SparkDesk and etc. Out of the 24 models, 18 achieved non-hallucination rates lower than 50%. This indicates that HalluQA is highly challenging. We analyze the primary types of hallucinations in different types of models and their causes. Add
    
[^86]: OceanGPT：用于海洋科学任务的大型语言模型

    OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v1 [cs.CL])

    [http://arxiv.org/abs/2310.02031](http://arxiv.org/abs/2310.02031)

    OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。

    

    海洋科学是探索充满生命和生物多样性的海洋的科学，考虑到海洋覆盖了地球表面的70％以上，这一领域具有重要意义。最近，大型语言模型（LLM）的进展改变了科学的范式。尽管在其他领域取得了成功，但现有的LLM通常无法满足海洋学家等领域专家的需求，同时对LLM在海洋科学中的潜力尚未得到充分探索。这其中的根本原因可能是海洋数据的庞大而复杂的性质，以及对更高的粒度和丰富的知识的需求。为了解决这些问题，我们推出了首个海洋领域的LLM——OceanGPT，该模型擅长各种海洋科学任务。我们提出了一个新颖的框架DoInstruct，用于自动获取大量的海洋领域指导数据，它基于多智能体的协作生成指导。

    Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge. To alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean domain, which is expert in various ocean science tasks. We propose DoInstruct, a novel framework to automatically obtain a large volume of ocean domain instruction data, which generates instructions based on multi-agent collaboration. Additionally, we construct the first oceanography benchmark, OceanBench,
    
[^87]: 关于BioLaySumm 2023共享任务的综述：生物医学研究文章的简化摘要

    Overview of the BioLaySumm 2023 Shared Task on Lay Summarization of Biomedical Research Articles. (arXiv:2309.17332v1 [cs.CL])

    [http://arxiv.org/abs/2309.17332](http://arxiv.org/abs/2309.17332)

    这项研究报道了BioLaySumm 2023共享任务的结果，该任务旨在开发抽象化摘要模型，能够在可控或不可控的环境中生成常规摘要，有两个子任务：常规摘要和可读性控制的摘要。共有20个团队参与了该任务。

    

    本文介绍了在ACL 2023的BioNLP研讨会上举办的关于生物医学研究文章简化摘要的共享任务（BioLaySumm）的结果。该共享任务的目标是开发能够生成“常规摘要”（即可理解给非技术人员的摘要）的抽象化摘要模型，无论在可控或不可控的环境中。共享任务包括两个子任务：1）常规摘要，参与者需要根据提供的完整文章文本和对应的摘要作为输入，构建产生常规摘要的模型；2）可读性控制的摘要，参与者需要根据文章的主要文本作为输入，训练模型来生成技术摘要和常规摘要。除了总体结果，我们还报告了BioLaySumm共享任务的设置和见解，共有20个参与团队参与了这两个子任务。

    This paper presents the results of the shared task on Lay Summarisation of Biomedical Research Articles (BioLaySumm), hosted at the BioNLP Workshop at ACL 2023. The goal of this shared task is to develop abstractive summarisation models capable of generating "lay summaries" (i.e., summaries that are comprehensible to non-technical audiences) in both a controllable and non-controllable setting. There are two subtasks: 1) Lay Summarisation, where the goal is for participants to build models for lay summary generation only, given the full article text and the corresponding abstract as input; and 2) Readability-controlled Summarisation, where the goal is for participants to train models to generate both the technical abstract and the lay summary, given an article's main text as input. In addition to overall results, we report on the setup and insights from the BioLaySumm shared task, which attracted a total of 20 participating teams across both subtasks.
    
[^88]: 使用开源工具和公开可用数据复现Whisper风格训练

    Reproducing Whisper-Style Training Using an Open-Source Toolkit and Publicly Available Data. (arXiv:2309.13876v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.13876](http://arxiv.org/abs/2309.13876)

    本研究复现了Whisper风格的训练，使用开源工具和公开可用数据开发了一个名为OWSM的模型，支持更多的翻译方向并且更高效地训练。

    

    在大量数据上预训练语音模型取得了显著的成功。OpenAI的Whisper是一个多语言多任务模型，经过了680k小时的监督式语音数据训练。它在各种语音识别和翻译基准测试中表现出良好的泛化能力，甚至在零样本设置中也能够发挥良好的作用。然而，开发这种模型的完整流程（从数据收集到训练）并不公开可访问，这使得研究人员难以进一步改进其性能并解决训练相关的问题，如效率、健壮性、公平性和偏见。本文介绍了一个名为Open Whisper-style Speech Model（OWSM）的模型，使用开源工具和公开可用数据复现了Whisper风格的训练。OWSM甚至支持更多的翻译方向，并且可以更高效地训练。我们将公开发布用于数据准备、训练、推理和评分的所有脚本，以及预训练模型和训练日志，以促进开放科学。

    Pre-training speech models on large volumes of data has achieved remarkable success. OpenAI Whisper is a multilingual multitask model trained on 680k hours of supervised speech data. It generalizes well to various speech recognition and translation benchmarks even in a zero-shot setup. However, the full pipeline for developing such models (from data collection to training) is not publicly accessible, which makes it difficult for researchers to further improve its performance and address training-related issues such as efficiency, robustness, fairness, and bias. This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisper-style training using an open-source toolkit and publicly available data. OWSM even supports more translation directions and can be more efficient to train. We will publicly release all scripts used for data preparation, training, inference, and scoring as well as pre-trained models and training logs to promote open science.
    
[^89]: NJUNLP对WMT2023质量评估共享任务的参与

    NJUNLP's Participation for the WMT2023 Quality Estimation Shared Task. (arXiv:2309.13230v1 [cs.CL])

    [http://arxiv.org/abs/2309.13230](http://arxiv.org/abs/2309.13230)

    NJUNLP团队对WMT2023质量评估共享任务进行了投稿，通过使用伪数据方法和核心超参数的实验研究，他们的模型在英德语言对的质量预测和错误跨度检测上取得了最佳结果。

    

    我们介绍了NJUNLP团队在WMT 2023质量估计（QE）共享任务中的投稿。我们的团队提交了对英德语言对的所有两个子任务的预测：（i）句子和单词级别的质量预测；（ii）细粒度错误跨度检测。今年，我们进一步探索了基于NJUQE框架（https://github.com/NJUNLP/njuqe）的伪数据方法进行QE。我们使用WMT翻译任务的并行数据生成伪MQM数据。我们在伪QE数据上预训练XLMR大模型，然后在真实QE数据上进行微调。在两个阶段，我们共同学习句子级分数和单词级标签。在实证上，我们进行实验来寻找改善性能的关键超参数。在技术上，我们提出了一种简单的方法，将单词级输出转换为细粒度错误跨度结果。总体而言，我们的模型在英德语言对的单词级别和细粒度错误跨度检测子任务中取得了最佳结果。

    We introduce the submissions of the NJUNLP team to the WMT 2023 Quality Estimation (QE) shared task. Our team submitted predictions for the English-German language pair on all two sub-tasks: (i) sentence- and word-level quality prediction; and (ii) fine-grained error span detection. This year, we further explore pseudo data methods for QE based on NJUQE framework (https://github.com/NJUNLP/njuqe). We generate pseudo MQM data using parallel data from the WMT translation task. We pre-train the XLMR large model on pseudo QE data, then fine-tune it on real QE data. At both stages, we jointly learn sentence-level scores and word-level tags. Empirically, we conduct experiments to find the key hyper-parameters that improve the performance. Technically, we propose a simple method that covert the word-level outputs to fine-grained error span results. Overall, our models achieved the best results in English-German for both word-level and fine-grained error span detection sub-tasks by a considera
    
[^90]: Talk2Care: 利用大型语言模型促进异步患者-医生通信

    Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model. (arXiv:2309.09357v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09357](http://arxiv.org/abs/2309.09357)

    本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。

    

    尽管有大量的远程医疗应用程序来帮助家庭中的老年人和医疗提供者，但基本的消息和电话仍然是最常见的通信方法，这些方法存在有限的可用性、信息丢失和流程效率低下的问题。促进患者-医生通信的一个有希望的解决方案是利用大型语言模型(LLMs)及其强大的自然对话和摘要能力。然而，对于LLMs在通信过程中的作用还存在有限的理解。我们首先进行了两项访谈研究，分别与老年人(N=10)和医疗提供者(N=9)进行了交流，以了解他们在患者-医生异步通信中对LLMs的需求和机会。基于这些见解，我们构建了一个LLM驱动的通信系统Talk2Care，并为两个群体设计了交互组件: (1) 对于老年人，我们利用语音助手的便利性和易于获取性，构建了一个LLM驱动的语音助手

    Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered VA i
    
[^91]: 大型语言模型能否辨别科学假设的证据？社会科学案例研究。

    Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences. (arXiv:2309.06578v1 [cs.CL])

    [http://arxiv.org/abs/2309.06578](http://arxiv.org/abs/2309.06578)

    本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。

    

    假设的制定和测试是经验性研究的核心。一个强有力的假设是基于现有证据的最佳猜测，并且是基于相关文献的全面视图进行启发的。然而，随着每年科学文章数量的指数增长，对于给定假设相关证据的手动汇总和综合是一项挑战。我们的工作探索了当前大型语言模型（LLMs）根据科学摘要文本中的证据，能否辨别支持或反驳特定假设的能力。我们共享了一个新颖的数据集，用于社会科学中使用社区驱动的研究注释的科学假设证据任务。我们将LLMs的性能与几个最先进的基准进行比较，并指出未来研究的机会。该数据集可在https://github.com/Sai90000/ScientificHypothesisEvidencing.git上获得。

    Hypothesis formulation and testing are central to empirical research. A strong hypothesis is a best guess based on existing evidence and informed by a comprehensive view of relevant literature. However, with exponential increase in the number of scientific articles published annually, manual aggregation and synthesis of evidence related to a given hypothesis is a challenge. Our work explores the ability of current large language models (LLMs) to discern evidence in support or refute of specific hypotheses based on the text of scientific abstracts. We share a novel dataset for the task of scientific hypothesis evidencing using community-driven annotations of studies in the social sciences. We compare the performance of LLMs to several state-of-the-art benchmarks and highlight opportunities for future research in this area. The dataset is available at https://github.com/Sai90000/ScientificHypothesisEvidencing.git
    
[^92]: 基于任务的混合专家模型用于多任务多语言机器翻译

    Task-Based MoE for Multitask Multilingual Machine Translation. (arXiv:2308.15772v1 [cs.CL])

    [http://arxiv.org/abs/2308.15772](http://arxiv.org/abs/2308.15772)

    本论文介绍了一种基于任务的混合专家模型，将任务信息与MoE模型相结合，在多任务多语言机器翻译中取得了优越的结果，并且能够高效地应用于新的任务。

    

    在训练深度模型的多种应用中，混合专家（MoE）架构已被证明是一种强大的方法。然而，当前的MoE实现是任务无关的，将不同任务的所有标记以相同方式处理。在这项工作中，我们设计了一种新颖的方法，通过共享的动态基于任务的适配器，在MoE模型的不同粒度级别上将任务信息纳入其中。我们的实验证明了我们的方法在多任务多语言机器翻译上的优势。借助任务特定的适配器，我们的模型还可以高效地推广到新的任务。

    Mixture-of-experts (MoE) architecture has been proven a powerful method for diverse tasks in training deep models in many applications. However, current MoE implementations are task agnostic, treating all tokens from different tasks in the same manner. In this work, we instead design a novel method that incorporates task information into MoE models at different granular levels with shared dynamic task-based adapters. Our experiments and analysis show the advantages of our approaches over the dense and canonical MoE models on multi-task multilingual machine translations. With task-specific adapters, our models can additionally generalize to new tasks efficiently.
    
[^93]: SeamlessM4T-大规模多语言和多模态机器翻译

    SeamlessM4T-Massively Multilingual & Multimodal Machine Translation. (arXiv:2308.11596v1 [cs.CL])

    [http://arxiv.org/abs/2308.11596](http://arxiv.org/abs/2308.11596)

    本文介绍了SeamlessM4T，这是一个支持多语言和多模态机器翻译的模型，通过使用大量语音数据和自监督学习，实现了统一的语音到语音翻译、语音到文本翻译、文本到语音翻译和文本到文本翻译，以及自动语音识别的功能。

    

    创造一种类似于巴别鱼的工具，能够帮助个人在任意两种语言之间进行语音翻译，需要付出什么样的努力？虽然最近在基于文本的模型方面取得了突破，使机器翻译的覆盖范围超过了200种语言，但统一的语音到语音翻译模型还没有取得类似的进展。更具体地说，传统的语音到语音翻译系统依赖于渐进式的级联系统进行翻译，使高性能的统一系统难以实现。为了弥补这些差距，我们引入了SeamlessM4T，一种支持语音到语音翻译、语音到文本翻译、文本到语音翻译、文本到文本翻译以及自动语音识别的单一模型，支持多达100种语言。为了构建这个模型，我们使用了100万小时的开放式语音音频数据，使用了w2v-BERT 2.0来学习自监督的语音表示。随后，我们创建了一个多模态的自动对齐语音翻译的语料库。

    What does it take to create the Babel Fish, a tool that can help individuals translate speech between any two languages? While recent breakthroughs in text-based models have pushed machine translation coverage beyond 200 languages, unified speech-to-speech translation models have yet to achieve similar strides. More specifically, conventional speech-to-speech translation systems rely on cascaded systems that perform translation progressively, putting high-performing unified systems out of reach. To address these gaps, we introduce SeamlessM4T, a single model that supports speech-to-speech translation, speech-to-text translation, text-to-speech translation, text-to-text translation, and automatic speech recognition for up to 100 languages. To build this, we used 1 million hours of open speech audio data to learn self-supervised speech representations with w2v-BERT 2.0. Subsequently, we created a multimodal corpus of automatically aligned speech translations. Filtered and combined with h
    
[^94]: 知识图谱能简化文本吗？

    Can Knowledge Graphs Simplify Text?. (arXiv:2308.06975v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.06975](http://arxiv.org/abs/2308.06975)

    提出了一种KGSimple方法，将知识图谱技术应用于无监督文本简化，实现从知识图谱开始生成简明文本，保留重要信息并输出流畅且描述性的句子。

    

    知识图谱到文本生成在生成流畅且信息丰富的句子方面有了最新的改进，这些句子描述了给定的知识图谱。由于知识图谱在多个领域广泛存在且包含重要的实体关系信息，并且文本简化旨在减少文本的复杂性同时保留原始文本的意思，我们提出了KGSimple，一种新颖的无监督文本简化方法，它融入了知识图谱技术来构建简化的知识图谱路径，并生成保留原始输入意义的简明文本。通过迭代和采样的以知识图谱为基础的方法，我们的模型能够从知识图谱开始简化文本，通过学习保留重要信息并利用知识图谱到文本生成输出流畅且描述性的句子。我们在目前可用的知识图谱到文本数据集上评估了KGSimple模型的各种设置，证明了其相对于无监督文本简化的有效性。

    Knowledge Graph (KG)-to-Text Generation has seen recent improvements in generating fluent and informative sentences which describe a given KG. As KGs are widespread across multiple domains and contain important entity-relation information, and as text simplification aims to reduce the complexity of a text while preserving the meaning of the original text, we propose KGSimple, a novel approach to unsupervised text simplification which infuses KG-established techniques in order to construct a simplified KG path and generate a concise text which preserves the original input's meaning. Through an iterative and sampling KG-first approach, our model is capable of simplifying text when starting from a KG by learning to keep important information while harnessing KG-to-text generation to output fluent and descriptive sentences. We evaluate various settings of the KGSimple model on currently-available KG-to-text datasets, demonstrating its effectiveness compared to unsupervised text simplificat
    
[^95]: AgentBench: 评估LLMs作为代理人

    AgentBench: Evaluating LLMs as Agents. (arXiv:2308.03688v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.03688](http://arxiv.org/abs/2308.03688)

    AgentBench是一个用于评估LLMs作为代理人的多维度基准，发现在复杂环境中，商业LLMs在充当代理人方面表现强劲，但与开源竞争对手相比，存在显著性能差距。该研究揭示了LLMs在长期推理、决策和指令遵循能力上的瓶颈。

    

    大型语言模型(LLMs)变得越来越智能和自主，针对传统的NLP任务之外的现实世界实际任务。因此，迫切需要在互动环境中评估LLMs作为代理人在具有挑战性的任务上的推理和决策能力。我们提出了AgentBench，一个多维度演变的基准，目前包括8个不同的环境，以评估LLM作为代理人在多轮开放式生成设置中的推理和决策能力。我们在27个基于API和开源的LLM上进行了广泛的测试，结果表明，虽然顶级商业LLM在复杂环境中表现出良好的代理人能力，但它们与开源竞争对手之间的性能差距很大。我们找出了环境和LLM中失败的典型原因，表明长期推理、决策和遵循指示能力不佳是开发可用LLM代理人的主要障碍。通过对代码和高质量进行训练

    Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 27 API-based and open-sourced (OSS) LLMs shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and OSS competitors. We identify the typical reasons of failures in environments and LLMs, showing that poor long-term reasoning, decision-making, and instruction following abilities are the main obstacles for developing usable LLM agents. Training on code and high quality 
    
[^96]: 一个知识增强的两阶段生成框架用于医学对话信息提取

    A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue Information Extraction. (arXiv:2307.16200v1 [cs.CL])

    [http://arxiv.org/abs/2307.16200](http://arxiv.org/abs/2307.16200)

    本论文提出了一个知识增强的两阶段生成框架（KTGF）用于医学对话信息提取。通过两个阶段的生成，分别生成医学对话中的术语和每个术语的状态，从而更好地建模术语之间的关系。

    

    本文关注医学对话中的术语-状态对提取（MD-TSPE），这在诊断对话系统和电子医疗记录（EMR）的自动抄写中是必不可少的。在过去的几年中，MD-TSPE的研究引起了越来越多的关注，特别是在生成方法取得显著进展之后。然而，这些生成方法在一阶段输出整个由术语-状态对组成的序列时忽略了集成先前知识的需求，这需要更深入的理解来建模术语之间的关系和推断每个术语的状态。本文提出了一个知识增强的两阶段生成框架（KTGF）来解决上述挑战。通过使用任务特定的提示，我们采用单一模型以统一的生成形式完成MD-TSPE的两个阶段：首先生成所有的术语，然后生成每个生成的术语的状态。通过这种方式，可以更有效地学习术语之间的关系。

    This paper focuses on term-status pair extraction from medical dialogues (MD-TSPE), which is essential in diagnosis dialogue systems and the automatic scribe of electronic medical records (EMRs). In the past few years, works on MD-TSPE have attracted increasing research attention, especially after the remarkable progress made by generative methods. However, these generative methods output a whole sequence consisting of term-status pairs in one stage and ignore integrating prior knowledge, which demands a deeper understanding to model the relationship between terms and infer the status of each term. This paper presents a knowledge-enhanced two-stage generative framework (KTGF) to address the above challenges. Using task-specific prompts, we employ a single model to complete the MD-TSPE through two phases in a unified generative form: we generate all terms the first and then generate the status of each generated term. In this way, the relationship between terms can be learned more effect
    
[^97]: 选择和增强：增强稠密检索知识图谱增强

    Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation. (arXiv:2307.15776v1 [cs.CL])

    [http://arxiv.org/abs/2307.15776](http://arxiv.org/abs/2307.15776)

    本文提出了一种选择和增强的方法来改进文本增强的知识图谱嵌入，通过多任务框架选择相关的文本描述，并对知识图谱嵌入进行对齐或增强。

    

    在自然语言处理社区中，将文本信息注入知识图谱（KG）实体表示已经成为一个值得探索的领域，以提高KG相关任务的性能。常用的外部知识增强KG嵌入的方法包括语义丰富的依赖解析特征、一组相关关键词，以及来自外部语料库（如维基百科）的完整文本描述。尽管这种创新（文本增强的KG嵌入）取得了一定的进展，但本文提出这种方法可以进一步改进。我们不再使用单一文本描述（因为文本的固有语义歧义无法充分表示一个实体），而是提出了一个多任务框架，既能选择与KG实体相关的一组文本描述，又能将KG嵌入与文本描述进行对齐或增强。与之前将形式化实体描述插入知识库的方法不同，这一方法是提供了对KG嵌入进行增强和对齐的新途径。

    Injecting textual information into knowledge graph (KG) entity representations has been a worthwhile expedition in terms of improving performance in KG oriented tasks within the NLP community. External knowledge often adopted to enhance KG embeddings ranges from semantically rich lexical dependency parsed features to a set of relevant key words to entire text descriptions supplied from an external corpus such as wikipedia and many more. Despite the gains this innovation (Text-enhanced KG embeddings) has made, the proposal in this work suggests that it can be improved even further. Instead of using a single text description (which would not sufficiently represent an entity because of the inherent lexical ambiguity of text), we propose a multi-task framework that jointly selects a set of text descriptions relevant to KG entities as well as align or augment KG embeddings with text descriptions. Different from prior work that plugs formal entity descriptions declared in knowledge bases, th
    
[^98]: WebArena: 一个用于构建自主智能体的真实网络环境

    WebArena: A Realistic Web Environment for Building Autonomous Agents. (arXiv:2307.13854v1 [cs.AI])

    [http://arxiv.org/abs/2307.13854](http://arxiv.org/abs/2307.13854)

    WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。

    

    随着生成式人工智能的进展，通过自然语言指令进行日常任务的自主智能体的潜力逐渐显现。然而，当前的智能体主要是在简化的合成环境中创建和测试的，严重限制了现实世界场景的表示能力。在本文中，我们构建了一个高度逼真且可复现的智能体指令和控制环境。具体而言，我们关注在网站上执行任务的智能体，我们创建了一个包含来自四个常见领域的完全功能网站的环境，分别是电子商务、社交论坛讨论、协同软件开发和内容管理。我们的环境使用工具（如地图）和外部知识库（如用户手册）来鼓励像人类一样解决任务。在我们的环境基础上，我们发布了一组重点评估任务完成功能正确性的基准任务。我们基准任务具有多样性和长远的视野，并且被设计为鼓励智能体进行更深层次的任务理解和解决。

    With generative AI advances, the exciting potential for autonomous agents to manage daily tasks via natural language commands has emerged. However, cur rent agents are primarily created and tested in simplified synthetic environments, substantially limiting real-world scenario representation. In this paper, we build an environment for agent command and control that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and are desi
    
[^99]: Video-LLaMA：用于视频理解的指令调整的语音-视觉语言模型

    Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding. (arXiv:2306.02858v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02858](http://arxiv.org/abs/2306.02858)

    Video-LLaMA是一个多模态框架，利用已有的预训练模型，解决了视频中的视觉和听觉的理解问题，其中Video Q-former和Audio Q-former用于处理视频中的视觉与时间变化和音频信号的问题。

    

    我们提出了一个多模态框架Video-LLaMA，赋予大型语言模型（LLMs）理解视频中的视觉和听觉内容的能力。Video-LLaMA从已经预训练好的视觉和音频编码器以及已经冻结的LLMs进行跨模态训练。相比于之前专注于静态图像理解的视觉-LLMs，如MiniGPT-4和LLaVA，Video-LLaMA主要解决两个视频理解方面的挑战：（1）捕捉视觉场景中的时间变化，（2）集成音频视觉信号。为了克服第一个挑战，我们提出了一个Video Q-former，将预训练的图像编码器组装到我们的视频编码器中，并引入一个视频到文本生成任务来学习视频-语言对应关系。为了解决第二个挑战，我们利用ImageBind，一个将多种模态对齐的通用嵌入模型，作为预训练的音频编码器，并在ImageBind之上引入一个Audio Q-former，学习合理的听觉查询嵌入。

    We present Video-LLaMA, a multi-modal framework that empowers Large Language Models (LLMs) with the capability of understanding both visual and auditory content in the video. Video-LLaMA bootstraps cross-modal training from the frozen pre-trained visual & audio encoders and the frozen LLMs. Unlike previous vision-LLMs that focus on static image comprehensions such as MiniGPT-4 and LLaVA, Video-LLaMA mainly tackles two challenges in video understanding: (1) capturing the temporal changes in visual scenes, (2) integrating audio-visual signals. To counter the first challenge, we propose a Video Q-former to assemble the pre-trained image encoder into our video encoder and introduce a video-to-text generation task to learn video-language correspondence. For the second challenge, we leverage ImageBind, a universal embedding model aligning multiple modalities as the pre-trained audio encoder, and introduce an Audio Q-former on top of ImageBind to learn reasonable auditory query embeddings for
    
[^100]: 训练先验影响文本到图像模型性能

    Training Priors Predict Text-To-Image Model Performance. (arXiv:2306.01755v1 [cs.CV])

    [http://arxiv.org/abs/2306.01755](http://arxiv.org/abs/2306.01755)

    本文测试了文本到图像模型对于训练先验的依赖程度，发现模型能够更好地生成与训练数据中出现频率更高的三元组对齐的图像，但这也会降低其生成以翻转三元组为基础的图像质量。

    

    文本到图像的模型能够生成一些关系，比如“宇航员骑马”，但却不能生成由相同基本部分组成的其他关系，比如“马骑宇航员”。这些失败通常被视为模型依赖训练先验而不是构建新颖的图像组合的证据。本文直接在稳定扩散2.1文本到图像模型上进行了测试。通过观察组成这些提示的主语-谓语-宾语 (SVO) 三元组（例如，“宇航员”，“骑”，“马”），我们发现，SVO三元组在训练数据中出现的次数越多，该模型就能生成与该三元组对齐的图像就越好。在这里，通过对齐，我们的意思是每个术语在生成的图像中以正确的关系出现。然而，这种增加的频率也会减少模型能够生成与翻转三元组对齐的图像的能力。例如，如果“宇航员骑马”在训练数据中频繁出现，那么“马骑宇航员”的对齐质量就会降低。

    Text-to-image models can often generate some relations, i.e., "astronaut riding horse", but fail to generate other relations composed of the same basic parts, i.e., "horse riding astronaut". These failures are often taken as evidence that the models rely on training priors rather than constructing novel images compositionally. This paper tests this intuition directly on the stablediffusion 2.1 text-to-image model. By looking at the subject-verb-object (SVO) triads that form the backbone of these prompts (e.g., "astronaut", "ride", "horse"), we find that the more often an SVO triad appears in the training data, the better the model can generate an image aligned with that triad. Here, by aligned we mean that each of the terms appears in the generated image in the proper relation to each other. However, this increased frequency also diminishes how well the model can generate an image aligned with the flipped triad. For example, if "astronaut riding horse" appears frequently in the trainin
    
[^101]: 通过神经引导符号抽象实现可解释和可解释逻辑策略

    Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction. (arXiv:2306.01439v1 [cs.LG])

    [http://arxiv.org/abs/2306.01439](http://arxiv.org/abs/2306.01439)

    该论文介绍了一种名为NUDGE的策略，利用训练好的基于神经网络的代理来引导逻辑规则的搜索，实现了可解释和可解释的策略。

    

    神经网络所需要的有限先验使其成为使用强化学习（RL）编码和学习策略的主要选择。然而，它们也是黑匣子，在工作在图像级别时难以理解代理行为。因此，神经符号RL旨在首先创建可解释的策略。不幸的是，可解释性不意味着可解释性。为了实现解释性和可解释性，我们引入了神经引导可微分逻辑策略（NUDGE）。NUDGE利用训练好的基于神经网络的代理来引导候选加权逻辑规则的搜索，然后使用可微分的逻辑来训练逻辑代理。我们的实验评估表明，NUDGE代理可以产生可解释和可解释的策略，同时胜过纯神经代理，并展现出良好的灵活性，以适应不同初始状态和问题大小的环境。

    The limited priors required by neural networks make them the dominating choice to encode and learn policies using reinforcement learning (RL). However, they are also black-boxes, making it hard to understand the agent's behaviour, especially when working on the image level. Therefore, neuro-symbolic RL aims at creating policies that are interpretable in the first place. Unfortunately, interpretability is not explainability. To achieve both, we introduce Neurally gUided Differentiable loGic policiEs (NUDGE). NUDGE exploits trained neural network-based agents to guide the search of candidate-weighted logic rules, then uses differentiable logic to train the logic agents. Our experimental evaluation demonstrates that NUDGE agents can induce interpretable and explainable policies while outperforming purely neural ones and showing good flexibility to environments of different initial states and problem sizes.
    
[^102]: 让隐含的显性化：以NLP中的隐式内容为第一公民

    Making the Implicit Explicit: Implicit Content as a First Class Citizen in NLP. (arXiv:2305.14583v1 [cs.CL])

    [http://arxiv.org/abs/2305.14583](http://arxiv.org/abs/2305.14583)

    该研究通过将自然语言处理的重点放在隐式内容上，提出了一种通过推理和分解方法降低自然语言处理复杂度的新方法，并在嵌入，计算政治学和构建发现方面实现了显著的改进和应用。

    

    语言是多元化的，一个表述可以用等价的形式重申，而其中的隐含和显性内容支持各种逻辑和语用推理。在处理表述时，我们考虑这些不同的方面，因为我们需要理解“这里很黑”可能是一个暗示需要打开灯。然而，NLP方法通常仅仅基于表面形式操作，省略了这种细微差别。在这项工作中，我们用语言来表示语言，并引导LLM将表述分解为逻辑和可信的推理。分解的降低复杂性，使它们更容易嵌入，开启了新的应用。我们的技术变化在句子嵌入基准测试中实现了最先进的改进，在计算政治学中有实质性应用，并引出一种新的构建发现过程，我们用人工注释验证了这种过程。

    Language is multifaceted. A given utterance can be re-expressed in equivalent forms, and its implicit and explicit content support various logical and pragmatic inferences. When processing an utterance, we consider these different aspects, as mediated by our interpretive goals -- understanding that "it's dark in here" may be a veiled direction to turn on a light. Nonetheless, NLP methods typically operate over the surface form alone, eliding this nuance.  In this work, we represent language with language, and direct an LLM to decompose utterances into logical and plausible inferences. The reduced complexity of the decompositions makes them easier to embed, opening up novel applications. Variations on our technique lead to state-of-the-art improvements on sentence embedding benchmarks, a substantive application in computational political science, and to a novel construct-discovery process, which we validate with human annotations.
    
[^103]: 是否具有声望的工作与声望高的国家相同？多语句子嵌入和欧洲国家的案例研究

    Is a Prestigious Job the same as a Prestigious Country? A Case Study on Multilingual Sentence Embeddings and European Countries. (arXiv:2305.14482v1 [cs.CL])

    [http://arxiv.org/abs/2305.14482](http://arxiv.org/abs/2305.14482)

    本文研究了多语句子嵌入如何捕捉欧洲国家和职业，并发现嵌入中最突出的国家特征是其GPD经济实力。本研究中的大部分国家维度与职业维度不相关，但一种模型表现出职业声望和原籍国之间的联系，这是一种潜在的基于国籍的歧视。

    

    我们研究了多语句子表示如何捕捉欧洲国家，以及这种差异如何在欧洲语言之间不同。我们用模板句子提示模型，将其机器翻译成12种欧洲语言，并分析嵌入中最突出的维度。我们的分析表明，嵌入中最突出的国家特征是其GPD经济实力。当特别询问声望高低时，嵌入空间清楚地区分了声望高低的工作。三个受研究的模型中的大部分国家维度与职业维度不相关，但Distilled Multilingual Universal Sentence Encoder模型表现出职业声望和原籍国之间的联系，这是一种潜在的基于国籍的歧视。我们的发现在不同的语言中是一致的，并且在一定程度上与上述例外情况下的受研究的表示模型一致。

    We study how multilingual sentence representations capture European countries and how this differs across European languages. We prompt the models with templated sentences that we machine-translate into 12 European languages and analyze the most prominent dimensions in the embeddings. Our analysis reveals that the most prominent country feature in the embedding is its economic strength in terms of GPD. When prompted specifically for job prestige, the embedding space clearly distinguishes high and low-prestige jobs. The occupational dimension is uncorrelated with the most dominant country dimensions for three out of four studied models. One model: Distilled Multilingual Universal Sentence Encoder, however, exhibited a connection between occupational prestige and country of origin, which is a potential source of nationality-based discrimination. Our findings are consistent across languages and, to some extent, with the exception mentioned above, across studied representation models.
    
[^104]: 通过多跳指令进行图像操作——一个新的数据集和基于弱监督的神经符号方法

    Image Manipulation via Multi-Hop Instructions -- A New Dataset and Weakly-Supervised Neuro-Symbolic Approach. (arXiv:2305.14410v1 [cs.CV])

    [http://arxiv.org/abs/2305.14410](http://arxiv.org/abs/2305.14410)

    该论文提出了一个基于神经符号概念学习的图像操作系统NeuroSIM，它可以通过多跳指令在多物体场景中执行复杂的推理，只需要弱监督的数据集，并创建了一个新的数据集。该系统具有很高的竞争力或超过SOTA基线。

    

    我们对通过自然语言文本进行图像操作感兴趣，这是多个人工智能应用程序中有用的任务，但需要对多模态空间进行复杂的推理。我们扩展了最近提出的神经符号概念学习(NSCL)，该方法在视觉问答(VQA)任务上非常有效，扩展其用于图像操作的任务。我们的系统称为NeuroSIM，可以在多物体场景上执行复杂的多跳推理，只需要以VQA的注释数据形式提供弱监督。NeuroSIM将指令解析成符号程序，基于由对象属性和操作组成的专业领域语言(DSL)，指导其执行。我们为这个任务创建了一个新的数据集，广泛的实验表明，NeuroSIM与使用监督数据进行操作的SOTA基线相比具有很高的竞争力或超过SOTA基线。

    We are interested in image manipulation via natural language text -- a task that is useful for multiple AI applications but requires complex reasoning over multi-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning (NSCL), which has been quite effective for the task of Visual Question Answering (VQA), for the task of image manipulation. Our system referred to as NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and only requires weak supervision in the form of annotated data for VQA. NeuroSIM parses an instruction into a symbolic program, based on a Domain Specific Language (DSL) comprising of object attributes and manipulation operations, that guides its execution. We create a new dataset for the task, and extensive experiments demonstrate that NeuroSIM is highly competitive with or beats SOTA baselines that make use of supervised data for manipulation.
    
[^105]: 从图像-文本-图谱空间中进行粗到细的对比学习，提高视觉语言组合能力

    Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality. (arXiv:2305.13812v1 [cs.CL])

    [http://arxiv.org/abs/2305.13812](http://arxiv.org/abs/2305.13812)

    本研究提出了一种基于场景图的对比学习框架，通过将从文本中解析出的场景图视为图像场景图的代理，并对图进行分解和增强，从简单到复杂的对比学习以将各种复杂度的句子对齐到同一幅图像上，同时在场景图空间中提出了新的负样本挖掘技术，以改善视觉语言组合能力。

    

    对比学习视觉语言模型已经在视觉和语言表示学习方面取得了显著进展，从而为各种下游多模态任务提供了最先进的模型。但是，最近的研究凸显了这些模型在对象、属性和关系的组成推理能力方面的严重限制。场景图已经成为一种理解图像组成的有效方式。这些是图像的图形结构化语义表示，包括场景中的对象、它们的属性和与场景中其他对象的关系。在本文中，我们将从文本中解析出的场景图视为图像场景图的代理，并提出了一种图分解和增强框架，以及从简单到复杂的对比学习目标，将各种复杂度的句子对齐到同一幅图像上。同时，我们还在场景图空间提出了新的负样本挖掘技术，用于改善对比学习。在三个视觉语言任务上的实验表明，我们的方法优于强大的视觉语言基线，特别是在对象、属性和关系的组成推理方面。

    Contrastively trained vision-language models have achieved remarkable progress in vision and language representation learning, leading to state-of-the-art models for various downstream multimodal tasks. However, recent research has highlighted severe limitations of these models in their ability to perform compositional reasoning over objects, attributes, and relations. Scene graphs have emerged as an effective way to understand images compositionally. These are graph-structured semantic representations of images that contain objects, their attributes, and relations with other objects in a scene. In this work, we consider the scene graph parsed from text as a proxy for the image scene graph and propose a graph decomposition and augmentation framework along with a coarse-to-fine contrastive learning objective between images and text that aligns sentences of various complexities to the same image. Along with this, we propose novel negative mining techniques in the scene graph space for im
    
[^106]: 开放域QA中通过提问澄清解决歧义问题

    Asking Clarification Questions to Handle Ambiguity in Open-Domain QA. (arXiv:2305.13808v1 [cs.CL])

    [http://arxiv.org/abs/2305.13808](http://arxiv.org/abs/2305.13808)

    本文提出了一种解决开放域QA中歧义问题的方法：通过提问澄清来确定最符合用户意图的解释。

    

    开放域中存在歧义问题，如何提出一个准确且独一无二的问题是很具挑战性的。过去，Min et al. (2020) 通过为所有可能的解释生成消除歧义的问题来解决这个问题。这种方法可能有效，但并不理想。我们提出通过提问澄清来解决这个问题，用户的回答将帮助确定最符合用户意图的解释。我们首先介绍了一个数据集CAMBIGNQ，该数据集由5,654个含有相关段落、可能的答案和澄清问题的歧义问题组成。这些澄清问题是通过使用InstructGPT生成然后进行必要的手动修订来高效创建的。然后我们定义了一系列任务和相应的评估指标。最后，我们在歧义检测上获得了61.3 F1，在澄清型QA上获得了40.5 F1，为提供强有力的答案提出了解决方案。

    Ambiguous questions persist in open-domain question answering, because formulating a precise question with a unique answer is often challenging. Previously, Min et al. (2020) have tackled this issue by generating disambiguated questions for all possible interpretations of the ambiguous question. This can be effective, but not ideal for providing an answer to the user. Instead, we propose to ask a clarification question, where the user's response will help identify the interpretation that best aligns with the user's intention. We first present CAMBIGNQ, a dataset consisting of 5,654 ambiguous questions, each with relevant passages, possible answers, and a clarification question. The clarification questions were efficiently created by generating them using InstructGPT and manually revising them as necessary. We then define a pipeline of tasks and design appropriate evaluation metrics. Lastly, we achieve 61.3 F1 on ambiguity detection and 40.5 F1 on clarification-based QA, providing stron
    
[^107]: 自然语言处理研究范式转变的历时分析：何时、如何和为何？

    A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why?. (arXiv:2305.12920v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12920](http://arxiv.org/abs/2305.12920)

    本研究提出了一个系统框架来分析自然语言处理领域研究主题的演变趋势，揭示了任务和方法是驱动研究的主要因素，而数据集和评估指标的影响较小。

    

    理解科学领域的基本概念和趋势对于跟上其持续发展是至关重要的。在本研究中，我们提出了一个系统的框架，利用因果发现和推理技术来分析科学领域中研究主题的演变。我们定义了三个变量，以涵盖NLP研究主题演变的多个方面，并利用因果发现算法揭示这些变量之间的因果关系。随后，我们利用这个结构来测量这些关系的强度。通过在ACL Anthology语料库上进行大量实验，我们证明了我们的框架能够有效地发现广泛的NLP研究主题的演变趋势和潜在原因。具体来说，我们发现任务和方法是推动NLP研究的主要因素，而数据集紧随其后，而评估指标的影响很小。

    Understanding the fundamental concepts and trends in a scientific field is crucial for keeping abreast of its continuous advancement. In this study, we propose a systematic framework for analyzing the evolution of research topics in a scientific field using causal discovery and inference techniques. We define three variables to encompass diverse facets of the evolution of research topics within NLP and utilize a causal discovery algorithm to unveil the causal connections among these variables using observational data. Subsequently, we leverage this structure to measure the intensity of these relationships. By conducting extensive experiments on the ACL Anthology corpus, we demonstrate that our framework effectively uncovers evolutionary trends and the underlying causes for a wide range of NLP research topics. Specifically, we show that tasks and methods are primary drivers of research in NLP, with datasets following, while metrics have minimal impact.
    
[^108]: 减轻多语言机器翻译中的数据不平衡和表示衰减问题

    Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation. (arXiv:2305.12786v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12786](http://arxiv.org/abs/2305.12786)

    本论文提出了一种名为Bi-ACL的框架，它使用目标语单语数据和双语词典来解决多语言机器翻译中的数据不平衡和表示衰减问题。实验证明该方法在长尾语种中效果更好。

    

    尽管多语言神经机器翻译 (MNMT) 取得了进展，但我们认为在这个领域仍存在两个主要挑战：数据不平衡和表示衰减。数据不平衡问题指的是所有语言对的平行语料数量的不平衡，尤其是对于长尾语种 (即资源极度匮乏的语种)。表示衰减问题指的是编码标记趋向于仅在 MNMT 模型可用的全空间的一个小子空间中出现的问题。为了解决这两个问题，我们提出了Bi-ACL，一个只使用目标语单语数据和双语词典来改善MNMT模型性能的框架。我们定义了两个模块，名为双向自编码器和双向对比学习，它们与在线约束束搜索和课程学习采样策略相结合。大量实验证明我们提出的方法在长尾语种中更有效。

    Despite advances in multilingual neural machine translation (MNMT), we argue that there are still two major challenges in this area: data imbalance and representation degeneration. The data imbalance problem refers to the imbalance in the amount of parallel corpora for all language pairs, especially for long-tail languages (i.e., very low-resource languages). The representation degeneration problem refers to the problem of encoded tokens tending to appear only in a small subspace of the full space available to the MNMT model. To solve these two issues, we propose Bi-ACL, a framework that uses only target-side monolingual data and a bilingual dictionary to improve the performance of the MNMT model. We define two modules, named bidirectional autoencoder and bidirectional contrastive learning, which we combine with an online constrained beam search and a curriculum learning sampling strategy. Extensive experiments show that our proposed method is more effective both in long-tail languages
    
[^109]: TELeR：用于基准测试复杂任务的LLM提示的通用分类法

    TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks. (arXiv:2305.11430v1 [cs.AI])

    [http://arxiv.org/abs/2305.11430](http://arxiv.org/abs/2305.11430)

    本文提出了一个通用分类法，可以用来设计具有特定属性的提示来执行各种复杂任务，从而解决了LLM在执行复杂任务方面的性能变异巨大的问题。

    

    尽管LLM在传统对话环境中理解和生成文本时取得了巨大成功，但它们在执行不明确的复杂任务方面的潜力仍然受到很少的研究。本文提出了一种通用分类法，可以用来设计具有特定属性的提示，以执行各种复杂任务，从而解决了使用不同提示类型/风格和提示提供的不同详细程度时LLM性能变化巨大的问题。这个分类法将使未来的基准测试研究能够报告研究中使用的特定提示类别，从而实现跨不同研究的有意义的比较。

    While LLMs have shown great success in understanding and generating text in traditional conversational settings, their potential for performing ill-defined complex tasks is largely under-studied. Indeed, we are yet to conduct comprehensive benchmarking studies with multiple LLMs that are exclusively focused on a complex task. However, conducting such benchmarking studies is challenging because of the large variations in LLMs' performance when different prompt types/styles are used and different degrees of detail are provided in the prompts. To address this issue, the paper proposes a general taxonomy that can be used to design prompts with specific properties in order to perform a wide range of complex tasks. This taxonomy will allow future benchmarking studies to report the specific categories of prompts used as part of the study, enabling meaningful comparisons across different studies. Also, by establishing a common standard through this taxonomy, researchers will be able to draw mo
    
[^110]: DoReMi: 优化数据混合加速语言模型预训练

    DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining. (arXiv:2305.10429v1 [cs.CL])

    [http://arxiv.org/abs/2305.10429](http://arxiv.org/abs/2305.10429)

    DoReMi方法使用分组分布式鲁棒优化训练小型代理模型以产生域权重，再使用这些权重重新采样数据集训练大型模型，相比使用默认权重的基线模型，在The Pile和GLaM数据集上平均提高了6.5%和4.7%的few-shot下游准确度，分别使用2.6倍和相同的训练步骤达到基线准确度。

    

    预训练数据域的混合比例（例如，维基百科、图书、网页文本）极大地影响语言模型（LM）性能。在本文中，我们提出了一种称为DoReMi的Domain Reweighting with Minimax Optimization方法，它首先使用分组分布式鲁棒优化（Group DRO）训练一个小代理模型，以产生域权重（混合比例），而不需要知道下游任务的知识。然后我们使用这些域权重重新采样一个数据集，并训练一个更大的，全尺寸的模型。在我们的实验中，我们使用DoReMi在一个280M参数的代理模型上，更有效地找到训练一个8B参数模型（30倍大）的域权重。在The Pile上，即使在减小一些域的比重时，DoReMi也能提高所有域的perplexity。相比使用The Pile的默认域权重训练的基线模型，DoReMi将平均few-shot下游准确度提高了6.5%，并使用2.6倍的训练步骤达到基线准确度。在GLaM数据集上，DoReMi没有任何关于下游任务的知识，提高了4.7%（次于现有最先进的模型）的few-shot准确度，在相同的训练步骤下提高了9.0%的准确度。

    The mixture proportions of pretraining data domains (e.g., Wikipedia, books, web text) greatly affect language model (LM) performance. In this paper, we propose Domain Reweighting with Minimax Optimization (DoReMi), which first trains a small proxy model using group distributionally robust optimization (Group DRO) over domains to produce domain weights (mixture proportions) without knowledge of downstream tasks. We then resample a dataset with these domain weights and train a larger, full-sized model. In our experiments, we use DoReMi on a 280M-parameter proxy model to find domain weights for training an 8B-parameter model (30x larger) more efficiently. On The Pile, DoReMi improves perplexity across all domains, even when it downweights a domain. DoReMi improves average few-shot downstream accuracy by 6.5% over a baseline model trained using The Pile's default domain weights and reaches the baseline accuracy with 2.6x fewer training steps. On the GLaM dataset, DoReMi, which has no know
    
[^111]: FACE: 使用交叉熵的傅里叶分析评估自然语言生成

    FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy. (arXiv:2305.10307v1 [cs.CL])

    [http://arxiv.org/abs/2305.10307](http://arxiv.org/abs/2305.10307)

    FACE是一组可以有效识别人类和模型之间差距的度量标准。它基于傅里叶分析和交叉熵估计，可以反映模型大小、解码采样方法和人类评分。

    

    评估机器生成的语言与人类语言之间的距离是一个至关重要的问题。受到语言学心理学关于语言熵周期性实证发现的启示，我们提出了FACE——一组基于语言交叉熵的傅里叶分析的度量，用于衡量生成模型产生的语言与人类书写语言之间的相似度。通过一个开放式的生成任务和以前研究的实验数据，我们发现FACE可以有效地识别人类模型差距，在模型规模上有所缩放，反映了不同解码采样方法的结果，与其他评估指标和人类判断分数相关良好。FACE在计算上是高效的，并提供直观的解释。

    Measuring the distance between machine-produced and human language is acritical open problem. Inspired by empirical findings from psycholinguistics on theperiodicity of entropy in language, we propose FACE, a set of metrics based onFourier Analysis of the estimated Cross-Entropy of language, for measuring thesimilarity between model-generated and human-written languages. Based on anopen-ended generation task and the experimental data from previous studies, weind that FACE can effectively identify the human-model gap, scales with modelsize, reflects the outcomes of different sampling methods for decoding, correlateswell with other evaluation metrics and with human judgment scores. FACE iscomputationally efficient and provides intuitive interpretations.
    
[^112]: StrAE：使用显式结构的自编码预训练嵌入的表示学习

    StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure. (arXiv:2305.05588v1 [cs.CL])

    [http://arxiv.org/abs/2305.05588](http://arxiv.org/abs/2305.05588)

    本文开发了StrAE框架，该框架利用句子结构无监督地学习多级节点嵌入，并且发现使用显式结构可以提高嵌入表现，新的对比目标优于标准的交叉熵目标。同时，完全忠实于结构确实能够根据相应模型的性能消除结构类型之间的歧义。

    

    本文通过开发StrAE这一自编码框架，探究了在NLP中使用显式结构进行表示学习的实用性，该框架利用句子结构无监督地学习多级节点嵌入。我们在包括一种新的对比损失在内的不同类型句子结构和目标下使用StrAE进行模型训练，并在一系列内在和外在任务上评估所学嵌入。实验结果表明，通过StrAE利用显式结构可以提高嵌入，新的对比目标优于标准的交叉熵目标。此外，与以往的做法相比，我们发现完全忠实于结构确实能够根据相应模型的性能消除结构类型之间的歧义。作为StrAE实用性的进一步证明，我们开发了一个简单的p

    This work explores the utility of explicit structure for representation learning in NLP by developing StrAE -- an autoencoding framework that faithfully leverages sentence structure to learn multi-level node embeddings in an unsupervised fashion. We use StrAE to train models across different types of sentential structure and objectives, including a novel contrastive loss over structure, and evaluate the learnt embeddings on a series of both intrinsic and extrinsic tasks. Our experiments indicate that leveraging explicit structure through StrAE leads to improved embeddings over prior work, and that our novel contrastive objective over structure outperforms the standard cross-entropy objective. Moreover, in contrast to findings from prior work that weakly leverages structure, we find that being completely faithful to structure does enable disambiguation between types of structure based on the corresponding model's performance. As further evidence of StrAE's utility, we develop a simple p
    
[^113]: API-Bank: 一种针对工具增强的大型语言模型的全面基准测试

    API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs. (arXiv:2304.08244v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08244](http://arxiv.org/abs/2304.08244)

    API-Bank是一个针对工具增强的大型语言模型的基准测试，通过解决三个关键问题来评估LLMs的能力，并展示了GPT-3.5的改进能力。

    

    最近的研究表明，大型语言模型（LLMs）可以通过利用外部工具来增强其能力。然而，仍然存在三个关键问题尚未解答：（1）目前的LLMs在利用工具方面的效果如何？（2）如何增强LLMs利用工具的能力？（3）如何克服利用工具所面临的障碍？为了解决这些问题，我们引入了API-Bank，一个具有突破性意义的基准测试，专门为工具增强的LLMs设计。针对第一个问题，我们开发了一个可运行的评估系统，包含73个API工具。我们使用753个API调用注释了314个工具使用对话，以评估现有LLMs在规划、检索和调用API方面的能力。针对第二个问题，我们构建了一个包含来自1,000个不同领域的2,138个API的1,888个工具使用对话的全面训练集。使用这个数据集，我们训练了Lynx，这是一个从Alpaca初始化的工具增强LLM。实验结果表明，GPT-3.5显示出了改进的能力。

    Recent research has demonstrated that Large Language Models (LLMs) can enhance their capabilities by utilizing external tools. However, three pivotal questions remain unanswered: (1) How effective are current LLMs in utilizing tools? (2) How can we enhance LLMs' ability to utilize tools? (3) What obstacles need to be overcome to leverage tools? To address these questions, we introduce API-Bank, a groundbreaking benchmark, specifically designed for tool-augmented LLMs. For the first question, we develop a runnable evaluation system consisting of 73 API tools. We annotate 314 tool-use dialogues with 753 API calls to assess the existing LLMs' capabilities in planning, retrieving, and calling APIs. For the second question, we construct a comprehensive training set containing 1,888 tool-use dialogues from 2,138 APIs spanning 1,000 distinct domains. Using this dataset, we train Lynx, a tool-augmented LLM initialized from Alpaca. Experimental results demonstrate that GPT-3.5 exhibits improved
    
[^114]: 通过基于目标的语言描述发现分布差异

    Goal Driven Discovery of Distributional Differences via Language Descriptions. (arXiv:2302.14233v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14233](http://arxiv.org/abs/2302.14233)

    本论文提出了一个新的任务D5，通过目标驱动的方式自动发现两个大型语料库之间的差异。作者构建了一个D5系统，并提出了一套统一的评估指标来衡量其性能。通过实验证明，语言模型可以使用目标驱动的方法来发现语料库差异。

    

    挖掘大型语料库可以产生有用的发现，但对人类来说耗时。我们提出了一个新的任务D5，它以目标驱动的方式自动发现两个大型语料库之间的差异。任务输入是一个问题，包括一个研究目标“比较药物A和药物B的副作用”，以及一个语料库对（两个大型患者自报反应的集合）。输出是对这些语料库差异的语言描述（发现）（使用药物A后，患者更经常提到“偏执感”）。我们构建了一个D5系统，并为了定量衡量其性能，我们贡献了一个元数据集OpenD5，聚合了675个开放问题，涵盖了商业、社会科学、人文学科、机器学习和健康等领域，同时我们提出了一套统一的评估指标：有效性、相关性、新颖性和显著性。通过数据集和统一指标，我们确认语言模型可以使用目标驱动的方法来发现语料库差异。

    Mining large corpora can generate useful discoveries but is time-consuming for humans. We formulate a new task, D5, that automatically discovers differences between two large corpora in a goal-driven way. The task input is a problem comprising a research goal "$\textit{comparing the side effects of drug A and drug B}$" and a corpus pair (two large collections of patients' self-reported reactions after taking each drug). The output is a language description (discovery) of how these corpora differ (patients taking drug A "$\textit{mention feelings of paranoia}$" more often). We build a D5 system, and to quantitatively measure its performance, we 1) contribute a meta-dataset, OpenD5, aggregating 675 open-ended problems ranging across business, social sciences, humanities, machine learning, and health, and 2) propose a set of unified evaluation metrics: validity, relevance, novelty, and significance. With the dataset and the unified metrics, we confirm that language models can use the goal
    
[^115]: 知识蒸馏≈标签平滑：事实还是谬误？

    Knowledge Distillation $\approx$ Label Smoothing: Fact or Fallacy?. (arXiv:2301.12609v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12609](http://arxiv.org/abs/2301.12609)

    知识蒸馏和标签平滑被认为是等价的方法，但实验证明它们对模型置信度的影响方向完全相反。知识蒸馏不仅传递知识，还传递了自信心。

    

    最初被提出作为一种从一个模型向另一个模型进行知识传递的方法，一些最近的研究表明知识蒸馏(KD)实际上是一种正则化的形式。最强有力的支持来自于它与标签平滑(LS)方法的明显相似之处。本文通过比较它们所训练的模型的预测置信度，重新考察了这两种方法之间的等价关系。在涉及不同规模模型的四个文本分类任务的实验中，显示出：(a)在大多数设置中，KD和LS会完全相反地影响模型的置信度。(b) 在KD中，学生不仅继承知识，而且还从老师那里继承自信心，加强了传统的知识传递观点。

    Originally proposed as a method for knowledge transfer from one model to another, some recent studies have suggested that knowledge distillation (KD) is in fact a form of regularization. Perhaps the strongest support of all for this new perspective comes from its apparent similarities with label smoothing (LS). Here we re-examine this stated equivalence between the two methods by comparing the predictive confidences of the models they train. Experiments on four text classification tasks involving models of different sizes show that: (a) In most settings, KD and LS drive model confidence in completely opposite directions, and (b) In KD, the student inherits not only its knowledge but also its confidence from the teacher, reinforcing the classical knowledge transfer view.
    
[^116]: JASMINE：用于少样本学习的阿拉伯GPT模型

    JASMINE: Arabic GPT Models for Few-Shot Learning. (arXiv:2212.10755v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10755](http://arxiv.org/abs/2212.10755)

    JASMINE是一组功能强大的阿拉伯自回归Transformer语言模型，预训练于大规模多样的阿拉伯文本数据集，具有在少样本学习上表现出色的能力。

    

    生成预训练（GPT）的学术研究仍然以英语为中心，导致我们对自回归模型整个类别的理解存在严重的空白。例如，我们对这些模型在不同语言和文化环境中的潜力及其对社会的影响知之甚少。为了解决这个问题，我们引入了JASMINE，它针对阿拉伯语这个拥有4亿多人口、包含广泛语言和方言变体的语言集合而设计。JASMINE是一组功能强大的阿拉伯自回归Transformer语言模型，参数范围为3亿-67亿，预训练于一个大而多样的数据集（约235GB的文本）。我们还精心设计并发布了一个综合评估阿拉伯自回归模型的基准，包括潜在的社会偏见、危害和有害性。利用我们的新颖基准，我们对JASMINE进行了广泛评估，展示了其自身强大的性能以及在少样本学习上的表现。

    Scholarship on generative pretraining (GPT) remains acutely Anglocentric, leaving serious gaps in our understanding of the whole class of autoregressive models. For example, we have little knowledge about the potential of these models and their societal impacts in diverse linguistic and cultural settings. We alleviate this issue for Arabic, a wide collection of languages and dialectal varieties with more than 400 million population, by introducing JASMINE. JASMINE is a suite of powerful Arabic autoregressive Transformer language models ranging in size between 300 million-6.7 billion parameters pretrained on a large and diverse dataset (~ 235 GB of text). We also carefully design and release a comprehensive benchmark for both automated and human evaluation of Arabic autoregressive models, with coverage of potential social biases, harms, and toxicity. Using our novel benchmark, we evaluate JASMINE extensively showing powerful performance intrinsically as well as in few-shot learning on a
    
[^117]: 面向开放领域的多文档摘要

    Towards multi-document summarization in the open-domain. (arXiv:2212.10526v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10526](http://arxiv.org/abs/2212.10526)

    本论文针对"开放领域"的多文档摘要任务进行研究，发现最先进的摘要器在此情境下性能下降严重，但进行额外的开放领域的训练可以降低对不完美检索的敏感性。

    

    多文档摘要(MDS)通常假设提供一组主题相关的文档。但是，这个文档集通常是数据集策划过程的产物；在实践中，它不一定可用，需要根据信息需求，即问题或主题陈述进行检索。我们通过形式化任务并使用现有数据集，检索器和摘要器来引导这个更具挑战性的“开放领域”设置的研究。通过广泛的实验，我们确定：(1)即使检索性能较高，最先进的摘要器在应用于开放领域时也会大幅降低性能;(2)在开放领域的设置中进行额外的训练可以降低对不完美检索的敏感性，(3)摘要器对检索重复文档和检索文档的顺序不敏感，但对其他错误，如检索无关文档的敏感性较高。根据我们的研究结果，我们提供了

    Multi-document summarization (MDS) traditionally assumes a set of topic-related documents are provided. However, this document set is often an artifact of the dataset curation process; in practice, it is not necessarily available and would need to be retrieved given an information need, i.e. a question or topic statement. We study this more challenging "open-domain" setting by formalizing the task and bootstrapping it using existing datasets, retrievers and summarizers. Via extensive experimentation, we determine that: (1) state-of-the-art summarizers suffer large reductions in performance when applied to the open-domain, even when retrieval performance is high, (2) additional training in the open-domain setting can reduce this sensitivity to imperfect retrieval, and (3) summarizers are insensitive to the retrieval of duplicate documents and the order of retrieved documents, but highly sensitive to other errors, like the retrieval of irrelevant documents. Based on our results, we provi
    
[^118]: 生成式模型在抽取型自然语言处理任务中的标记一致性问题对结果影响的重要性

    Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks. (arXiv:2212.09912v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09912](http://arxiv.org/abs/2212.09912)

    本论文发现了在训练生成式模型时常被忽视的标记一致性问题的重要性，并提出了一个简单且有效的解决方案。通过一致的标记化，模型在抽取型问答任务上表现更好，在领域内和领域外的数据集上平均 F2 增益为 +1.7，同时具有更快的收敛速度和更少的不相关输出生成。

    

    生成式模型在解决抽取型任务时取得了显著的成功，例如在抽取式问答（QA）中，生成式模型一直保持着最先进的结果。本研究发现，在训练这些模型时经常被忽视的标记化不一致性问题。这个问题在标记器对输入和输出进行不一致的标记化后会破坏这些任务的抽取性质，从而导致性能下降和虚构。我们提出了一个简单而有效的解决方案，并在抽取式问答方面进行了案例研究。我们发现，通过一致的标记化，模型在领域内和领域外的数据集上表现更好，在将 BART 模型训练于 SQuAD 并在 8 个 QA 数据集上评估时，平均 F2 增益显著，为 +1.7。同时，模型收敛速度更快，并且更不容易生成不相关的输出。

    Generative models have been widely applied to solve extractive tasks, where parts of the input is extracted to form the desired output, and achieved significant success. For example, in extractive question answering (QA), generative models have constantly yielded state-of-the-art results. In this work, we identify the issue of tokenization inconsistency that is commonly neglected in training these models. This issue damages the extractive nature of these tasks after the input and output are tokenized inconsistently by the tokenizer, and thus leads to performance drop as well as hallucination. We propose a simple yet effective fix to this issue and conduct a case study on extractive QA. We show that, with consistent tokenization, the model performs better in both in-domain and out-of-domain datasets, with a notable average of +1.7 F2 gain when a BART model is trained on SQuAD and evaluated on 8 QA datasets. Further, the model converges faster, and becomes less likely to generate out-of-
    
[^119]: 《合同中要读些什么？对法律义务、权益和禁止的各方特定摘要》

    What to Read in a Contract? Party-Specific Summarization of Legal Obligations, Entitlements, and Prohibitions. (arXiv:2212.09825v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09825](http://arxiv.org/abs/2212.09825)

    本论文提出了一种用于法律合同的各方特定摘要提取任务，旨在帮助更快地审查和理解重要的权利和义务。通过使用法律专家注释的数据集和基于流水线的摘要系统，我们证明了摘要中引入领域特定重要性的必要性。

    

    由于合同长度和领域特定性，审查和理解法律合同中的重要义务、权益和禁止可能是一项繁琐的任务。此外，需要审查的主要权利和义务在每个合约方之间也存在差异。在本文中，我们提出了一种新任务，即用于法律合同的各方特定摘要提取，以促进更快的审查和提高对权利和义务的理解。为了实现这一目标，我们策划了一个数据集，包括法律专家注释的各方特定重要性比较，涵盖了从租赁协议中提取的大约293K个句子对，包括义务、权益和禁止。利用这个数据集，我们训练了一个重要性排序模型，并提出了一个基于流水线的提取性摘要系统，生成了各方特定的合同摘要。通过与各种基准模型进行比较，我们证明了在摘要中引入领域特定重要性的必要性。

    Reviewing and comprehending key obligations, entitlements, and prohibitions in legal contracts can be a tedious task due to their length and domain-specificity. Furthermore, the key rights and duties requiring review vary for each contracting party. In this work, we propose a new task of party-specific extractive summarization for legal contracts to facilitate faster reviewing and improved comprehension of rights and duties. To facilitate this, we curate a dataset comprising of party-specific pairwise importance comparisons annotated by legal experts, covering ~293K sentence pairs that include obligations, entitlements, and prohibitions extracted from lease agreements. Using this dataset, we train a pairwise importance ranker and propose a pipeline-based extractive summarization system that generates a party-specific contract summary. We establish the need for incorporating domain-specific notion of importance during summarization by comparing our system against various baselines using
    
[^120]: GLM-130B: 一个开源的双语预训练模型

    GLM-130B: An Open Bilingual Pre-trained Model. (arXiv:2210.02414v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.02414](http://arxiv.org/abs/2210.02414)

    GLM-130B是一个具有1300亿参数的开源双语预训练模型，能够超越GPT-3和最大的中文语言模型ERNIE TITAN 3.0 260B，在多个基准测试中表现出色。

    

    本文介绍了GLM-130B，一个具有1300亿参数的双语（英语和中文）预训练语言模型。它是为了打开1000亿规模的模型，至少与GPT-3（davinci）一样好，并揭示如何成功地进行如此规模的预训练。在这个过程中，我们遇到了许多意外的技术和工程挑战，特别是在损失峰和发散方面。在本文中，我们介绍了GLM-130B的训练过程，包括设计选择、提高效率和稳定性的训练策略，以及工程努力。GLM-130B模型在广泛的英语基准测试中明显优于GPT-3 175B（davinci），但在OPT-175B和BLOOM-176B中没有观察到性能优势。它还在相关基准测试中始终且显著优于最大的中文语言模型ERNIE TITAN 3.0 260B。最后，我们利用GLM-130B的独特缩放性能进行实验。

    We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model at least as good as GPT-3 (davinci) and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we face numerous unexpected technical and engineering challenges, particularly on loss spikes and divergence. In this paper, we introduce the training process of GLM-130B including its design choices, training strategies for both efficiency and stability, and engineering efforts. The resultant GLM-130B model offers significant outperformance over GPT-3 175B (davinci) on a wide range of popular English benchmarks while the performance advantage is not observed in OPT-175B and BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN 3.0 260B -- the largest Chinese language model -- across related benchmarks. Finally, we leverage a unique scaling property of GLM-130B to rea
    
[^121]: 是否总是需要注意力？语言识别案例研究。(arXiv:2110.03427v3 [cs.LG] 更新)

    Is Attention always needed? A Case Study on Language Identification from Speech. (arXiv:2110.03427v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.03427](http://arxiv.org/abs/2110.03427)

    本研究提出了一种基于卷积循环神经网络的语言识别方法，使用梅尔频率倒谱系数特征。与现有的方法进行了比较分析，并得出了一些结论。

    

    语言识别（LID）是自动语音识别（ASR）领域中的关键预处理过程，涉及从音频样本中识别出讲话语言。当前能够处理多种语言的系统要求用户在使用之前明确指定一种或多种语言。在多语言环境下，当ASR系统无法理解讲话语言时，LID任务扮演着重要的角色，导致语音识别结果失败。本研究引入了基于卷积循环神经网络（CRNN）的LID方法，设计用于处理音频样本的梅尔频率倒谱系数（MFCC）特征。此外，我们复制了一些最先进的方法，特别是卷积神经网络（CNN）和基于注意力的卷积循环神经网络（带有注意力的CRNN），并与我们的基于CRNN的方法进行了比较分析。我们进行了一项实验

    Language Identification (LID) is a crucial preliminary process in the field of Automatic Speech Recognition (ASR) that involves the identification of a spoken language from audio samples. Contemporary systems that can process speech in multiple languages require users to expressly designate one or more languages prior to utilization. The LID task assumes a significant role in scenarios where ASR systems are unable to comprehend the spoken language in multilingual settings, leading to unsuccessful speech recognition outcomes. The present study introduces convolutional recurrent neural network (CRNN) based LID, designed to operate on the Mel-frequency Cepstral Coefficient (MFCC) characteristics of audio samples. Furthermore, we replicate certain state-of-the-art methodologies, specifically the Convolutional Neural Network (CNN) and Attention-based Convolutional Recurrent Neural Network (CRNN with attention), and conduct a comparative analysis with our CRNN-based approach. We conducted co
    
[^122]: 神经语言模型和人类的增量处理的有针对性评估

    A Targeted Assessment of Incremental Processing in Neural LanguageModels and Humans. (arXiv:2106.03232v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2106.03232](http://arxiv.org/abs/2106.03232)

    本研究通过收集了人类和神经语言模型在逐词反应时间上的数据进行了比较，发现无论是人类还是模型，都在语法错误句子区域表现出了增加的处理困难。然而，模型在预测语法和非语法句子之间增量处理困难差异的幅度上存在系统性低估。

    

    我们通过收集跨越多种结构现象的十六个不同句法测试套件的逐词反应时间数据，提出了一种针对神经语言模型和人类增量处理的有针对性、规模化比较。人类反应时间数据来自一种称为"Interpolated Maze"任务的新型在线实验范例。我们将人类反应时间与四种不同架构、训练数据集大小范围的当代语言模型的逐词概率进行比较。我们发现，在许多现象中，无论是人类还是语言模型，在语法错误的句子区域都显示出了增加的处理困难，人类和模型的“准确度”得分（类似于Marvin和Linzen(2018)）大致相等。然而，尽管语言模型的输出与人类的方向相匹配，我们表明模型在预测语法和非语法句子之间增量处理困难差异的幅度上系统性地低估了。具体而言，当模型遇到句法错误时，模型在增量处理困难的差异大小上低估了。

    We present a targeted, scaled-up comparison of incremental processing in humans and neural language models by collecting by-word reaction time data for sixteen different syntactic test suites across a range of structural phenomena. Human reaction time data comes from a novel online experimental paradigm called the Interpolated Maze task. We compare human reaction times to by-word probabilities for four contemporary language models, with different architectures and trained on a range of data set sizes. We find that across many phenomena, both humans and language models show increased processing difficulty in ungrammatical sentence regions with human and model `accuracy' scores (a la Marvin and Linzen(2018)) about equal. However, although language model outputs match humans in direction, we show that models systematically under-predict the difference in magnitude of incremental processing difficulty between grammatical and ungrammatical sentences. Specifically, when models encounter synt
    
[^123]: GPT也理解了

    GPT Understands, Too. (arXiv:2103.10385v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2103.10385](http://arxiv.org/abs/2103.10385)

    提出了一种方法P-Tuning，通过使用可学习的连续提示嵌入和离散提示的拼接，稳定了预训练语言模型（PLM）的训练过程，并在多种自然语言理解任务上显著提高了性能。

    

    使用自然语言模式来促使预训练语言模型（PLM）具有自然语言理解（NLU）方面的效果已经被证明是有效的。然而，我们的初步研究发现，手动离散的提示往往导致性能不稳定——例如，在提示中改变一个单词可能导致性能大幅下降。我们提出了一种新方法P-Tuning，它使用训练可学习的连续提示嵌入以及离散提示的拼接。经验证明，P-Tuning不仅通过减小各种离散提示之间的差距来稳定训练，还通过较大幅度的提升在包括LAMA和SuperGLUE在内的各种NLU任务上的性能。无论是冻结的还是调整的语言模型，在全监督和少样本设置下，P-Tuning通常都是有效的。

    Prompting a pretrained language model with natural language patterns has been proved effective for natural language understanding (NLU). However, our preliminary study reveals that manual discrete prompts often lead to unstable performance -- e.g., changing a single word in the prompt might result in substantial performance drop. We propose a novel method P-Tuning that employs trainable continuous prompt embeddings in concatenation with discrete prompts. Empirically, P-Tuning not only stabilizes training by minimizing the gap between various discrete prompts, but also improves performance by a sizeable margin on a wide range of NLU tasks including LAMA and SuperGLUE. P-Tuning is generally effective for both frozen and tuned language models, under both the fully-supervised and few-shot settings.
    

