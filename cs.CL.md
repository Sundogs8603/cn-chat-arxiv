# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Unstructured and structured data: Can we have the best of both worlds with large language models?.](http://arxiv.org/abs/2304.13010) | 本文探讨使用大型语言模型查询无结构数据和结构化数据的潜力及挑战。 |
| [^2] | [Answering Questions by Meta-Reasoning over Multiple Chains of Thought.](http://arxiv.org/abs/2304.13007) | 本论文提出了基于元推理的Multi-Chain Reasoning (MCR)方法，该方法检查多个推理链，混合它们之间的信息并选择最相关的事实，从而超越多链思维，解决多跳QA问题。 实验结果表明MCR胜过多个强基线，解释质量高。 |
| [^3] | [Evaluating Inter-Bilingual Semantic Parsing for Indian Languages.](http://arxiv.org/abs/2304.13005) | 本研究提出了一个11种不同的印度语言的间语言Seq2seq语义分析数据集IE-SEMPARSE，并评估了现有的多语言seq2seq模型在其中的表现。 |
| [^4] | [AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head.](http://arxiv.org/abs/2304.12995) | AudioGPT是一种多模式人工智能系统，能够处理复杂的音频信息并支持口语对话，其实验结果表明其在处理语音、音乐、声音和人头像方面有着很强的能力。 |
| [^5] | [Measuring Massive Multitask Chinese Understanding.](http://arxiv.org/abs/2304.12986) | 本研究提出了一项测试，以衡量大型中文语言模型的多任务准确性，测试涵盖医学、法律、心理学和教育四个主要领域，结果表明所有模型在法律领域中表现都很差，建议研究人员应该开发更加多样化和均衡的多任务中文理解模型。 |
| [^6] | [Intent Induction from Conversations for Task-Oriented Dialogue Track at DSTC 11.](http://arxiv.org/abs/2304.12982) | 本论文介绍了DSTC11任务导向式对话跟踪的会话意图诱导，提出了两个子任务和三个数据集，并给出了简单的基线，用以评估方法的研究。其中旨在在客户服务交互的真实环境中自动诱导客户意图并对其进行评估。 |
| [^7] | [GMNLP at SemEval-2023 Task 12: Sentiment Analysis with Phylogeny-Based Adapters.](http://arxiv.org/abs/2304.12979) | 该论文介绍了GMU团队在SemEval-2023共享任务AfriSenti-SemEval中所使用的情感分析系统，使用AfroXLMR-large作为预训练语言模型并引入了增强的训练数据和基于Phylogeny的适配器调整以得到最佳结果。 |
| [^8] | [Escaping the sentence-level paradigm in machine translation.](http://arxiv.org/abs/2304.12959) | 本文提出了一种摆脱机器翻译中句子级范式限制的方法，通过处理三个障碍来实现：使用足够大的标准Transformer架构、引入一种简单而有效的技术来将文档级信息转化为适合训练的形式、基于自动文档分类的评估协议来有效地识别文档级翻译质量。在两个非常不同的文档级翻译任务上，我们的实验表明，在此数据上训练的Transformer模型明显优于强大的基线模型。 |
| [^9] | [Nondeterministic Stacks in Neural Networks.](http://arxiv.org/abs/2304.12955) | 本论文提出在神经网络中添加了可以处理句法歧义的非确定性栈，有效地模拟一个非确定性下推自动机。 |
| [^10] | [Topological properties and organizing principles of semantic networks.](http://arxiv.org/abs/2304.12940) | 本论文研究了由不同语言的7个语义关系定义的语义网络的基本属性。我们发现，语义网络具有普遍的基本特性：稀疏、高度聚集和自我组织化，并呈现出幂律度数分布。一些网络显示出语言特定的属性，这些属性受语法规则的影响，例如来自高度屈折语言的网络。 |
| [^11] | [Out-of-distribution Evidence-aware Fake News Detection via Dual Adversarial Debiasing.](http://arxiv.org/abs/2304.12888) | 该论文提出了一种新颖的双重对抗学习方法，通过在模型中加入去偏置鉴别器，旨在训练模型更好地进行越界证据感知假新闻检测，有效减轻新闻和证据内容偏差的影响。 |
| [^12] | [NLP-LTU at SemEval-2023 Task 10: The Impact of Data Augmentation and Semi-Supervised Learning Techniques on Text Classification Performance on an Imbalanced Dataset.](http://arxiv.org/abs/2304.12847) | 本文提出应用transformer模型和数据增强、半监督学习技术的方法，以应对文本分类中的类别不平衡问题，从而增强整体性能。 |
| [^13] | [Lessons Learned from a Citizen Science Project for Natural Language Processing.](http://arxiv.org/abs/2304.12836) | 本论文探讨了公民科学在自然语言处理领域的应用，研究表明这可以产生高质量的注释并吸引积极的志愿者，但需要考虑可扩展性、长期参与和法律和伦理问题等因素。 |
| [^14] | [A New Information Theory of Certainty for Machine Learning.](http://arxiv.org/abs/2304.12833) | 该论文提出了一种新的信息理论概念 troenpy 来量化底层分布的确定性，用于机器学习中文档分类和序列数据权重方案，并定义了量子 troenpy 量化量子系统确定性。 |
| [^15] | [A Novel Dual of Shannon Information and Weighting Scheme.](http://arxiv.org/abs/2304.12814) | 本文通过发掘信息熵自然对偶，提出了一种新的量troenpy，并应用于提出了基于troenpy的文档加权方案，即正类别频率（PCF），以及一种新的类别信息偏差特征ECIB，在监督学习中具有互信息的泛化性质。 |
| [^16] | [Transcending the "Male Code": Implicit Masculine Biases in NLP Contexts.](http://arxiv.org/abs/2304.12810) | 研究发现，当存在性别化语言时，NLP语境中也存在着性别偏见，尤其是男性偏见。调查者提供了一个涵盖了性别化语言与语言之间歧义关系的新字典“Ava”。 |
| [^17] | [Can Voice Assistants Sound Cute? Towards a Model of Kawaii Vocalics.](http://arxiv.org/abs/2304.12809) | 本文研究声音是否可以具备可爱性，并通过探索可爱的语音特质，即可爱的声音学来实现。通过对不同年龄段和不同特征的语音感受研究，发现可爱性与性别、年龄、流利度和人工性等方面有关。提出了一个可爱嗓音的模型，需要进行声音质量、认知评估、行为反应和情感报告的研究来验证。 |
| [^18] | [State Spaces Aren't Enough: Machine Translation Needs Attention.](http://arxiv.org/abs/2304.12776) | S4模型在机器翻译任务上与变压器模型相比存在四个BLEU分数点的差距，需要注意力机制来弥补其无法在单个隐藏状态中总结完整的源句子的缺陷。 |
| [^19] | [Test-Time Adaptation with Perturbation Consistency Learning.](http://arxiv.org/abs/2304.12764) | 本文提出了一种测试时间自适应方法PCL，通过促进模型对分布变化的稳定预测，解决了目前PLMs在应对分布变化问题方面表现不佳的难题。 |
| [^20] | [What does BERT learn about prosody?.](http://arxiv.org/abs/2304.12706) | 本论文在BERT上进行了一系列实验，探究了不同层次捕捉到的表示。结果表明，韵律是BERT学习到的结构信息的一部分，主要集中在中间层。 |
| [^21] | [Compressing Sentence Representation with maximum Coding Rate Reduction.](http://arxiv.org/abs/2304.12674) | 提出了一种在最大编码速率降低下的句子表示压缩方法，通过在句子表示模型Sentence-BERT中加入一个额外的学习投影层，并证明其可以在语义相关任务中获得与大型语言模型相当的结果。 |
| [^22] | [PUNR: Pre-training with User Behavior Modeling for News Recommendation.](http://arxiv.org/abs/2304.12633) | 本论文提出了一种无监督的预训练方法，它可以通过两个任务实现有效的用户行为建模，以提高新闻推荐系统的准确性和性能表现。 |
| [^23] | [Explain like I am BM25: Interpreting a Dense Model's Ranked-List with a Sparse Approximation.](http://arxiv.org/abs/2304.12631) | 本论文提出了一种解释NRM的新方法——基于等价查询的局部解释方法。通过最大化NRM结果与具有等价查询的稀疏检索系统的结果集之间的相似性来生成等价查询。该方法与现有方法进行比较，并对检索效果和每种方法生成的词项进行了对比。 |
| [^24] | [KINLP at SemEval-2023 Task 12: Kinyarwanda Tweet Sentiment Analysis.](http://arxiv.org/abs/2304.12569) | 本文介绍了作者在SemEval-2023任务12中使用的针对金亚琳达推文情感分析的系统，并在该竞赛中取得了第二高的成绩。 |
| [^25] | [RenderDiffusion: Text Generation as Image Generation.](http://arxiv.org/abs/2304.12519) | 本文提出了一种新的扩散方法——\textsc{RenderDiffusion}，通过文本引导的图像生成进行文本生成。它将连续扩散模型应用于离散文本并实现了条件文本生成作为字形图像生成问题。 |
| [^26] | [Understanding and Predicting Human Label Variation in Natural Language Inference through Explanation.](http://arxiv.org/abs/2304.12443) | 这篇论文介绍了一个包含注释标记和自由文本解释的自然语言推理解释数据集，称为LiveNLI，通过该数据集可以帮助自然语言处理模型识别人工标注的差异，同时还发现了GPT-3在标签预测方面仍有改进的空间。 |
| [^27] | [TIGTEC : Token Importance Guided TExt Counterfactuals.](http://arxiv.org/abs/2304.12425) | TIGTEC是一个高效的文本对抗事例生成方法，使用本地特征重要性针对和修改对分类结果影响最大的单词，并在代价函数中使用语义距离评估对抗性解释。该方法具有很高的成功率、稀疏性、多样性和可信度，并且既可以是特定于模型的，也可以是无关模型的，非常方便用于生成对抗性解释。 |
| [^28] | [ChatGPT (Feb 13 Version) is a Chinese Room.](http://arxiv.org/abs/2304.12411) | ChatGPT能通过各种专业和许可考试，但其当前版本更像是一个中文房间而非人工意识，存在严重的因果推理错误和不准确的回复。 |
| [^29] | [PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques.](http://arxiv.org/abs/2304.12410) | 本文提出了PEFT-Ref参考架构，标准化了不同PEFT技术共享的方面，隔离了差异到特定位置和交互中，模块化的视图有助于比较不同技术及其效率和任务性能，并有助于更好地理解PEFT的基本原理。 |
| [^30] | [Semantic Tokenizer for Enhanced Natural Language Processing.](http://arxiv.org/abs/2304.12404) | 本文提出一种基于语义的标记器，使用训练器来增强子词形成，优化和适应以最小化不能编码的单词数量。该标记器的复杂性超过了之前的两倍，但显着提高了NLP模型的收敛速度，并改善了单词和句子嵌入的质量。 |
| [^31] | [On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research.](http://arxiv.org/abs/2304.12397) | 本文讨论使用黑盒API进行毒性评估的挑战，发现依赖继承的自动毒性评分可能导致不准确的结果，建议采用更加结构化的方法评估毒性随时间变化的模型和方法。 |
| [^32] | [Extreme Classification for Answer Type Prediction in Question Answering.](http://arxiv.org/abs/2304.12395) | 本文提出了使用Transformer模型（XBERT）进行极端多标签分类，通过将KG类型基于问题文本使用结构和语义特征进行聚类，以提高问题回答（QA）系统中语义答案类型预测（SMART）任务的性能，并获得最先进的结果。 |
| [^33] | [Better Question-Answering Models on a Budget.](http://arxiv.org/abs/2304.12370) | 本文针对低成本下，提出了基于LoRA和Stanford Alpaca数据集的Eluwa模型系列，可大幅提高Facebook的OPT 1.3B、2.7B和6.7B模型的表现，40美元的计算成本即可让较小的模型具有和大3倍模型一样的性能表现。 |
| [^34] | [USTEP: Structuration des logs en flux gr{\^a}ce {\`a} un arbre de recherche {\'e}volutif.](http://arxiv.org/abs/2304.12331) | 本论文提出了一种基于演化树结构的在线日志解析方法USTEP，该方法在有效性和鲁棒性方面优越。 |
| [^35] | [Generating Post-hoc Explanations for Skip-gram-based Node Embeddings by Identifying Important Nodes with Bridgeness.](http://arxiv.org/abs/2304.12036) | 本文提出了一种解释Skip-gram节点嵌入的方法，即通过计算桥接度识别重要节点，并提出了一种新型基于梯度的解释方法GRAPH-wGD，有效地提供全局性解释。 |
| [^36] | [NAIST-SIC-Aligned: Automatically-Aligned English-Japanese Simultaneous Interpretation Corpus.](http://arxiv.org/abs/2304.11766) | 本论文提出了NAIST-SIC-Aligned，这是一个自动对齐的英日平行同声传译数据集。该论文使用了一个两阶段的对齐方法，经过定量或定性验证的每个步骤，以确保语料库的质量。这是第一个开源的大规模平行SI数据集。 |
| [^37] | [Boosting Theory-of-Mind Performance in Large Language Models via Prompting.](http://arxiv.org/abs/2304.11490) | 本研究通过提示提高大型语言模型（LLMs）在心智理论（ToM）任务上的表现，证明了上下文学习可以提升LLMs在复杂推理特别是ToM任务中的表现。 |
| [^38] | [UBC-DLNLP at SemEval-2023 Task 12: Impact of Transfer Learning on African Sentiment Analysis.](http://arxiv.org/abs/2304.11256) | 该研究旨在解决非洲14个不同语言的情感分析任务，使用转移学习的方法，并取得了不错的成果，可应用于其他语言的情感分析任务。 |
| [^39] | [Learn What NOT to Learn: Towards Generative Safety in Chatbots.](http://arxiv.org/abs/2304.11220) | 本文提出了一种名为“LOT”的框架，采用对比损失训练聊天机器人以从正面和负面训练信号中增强泛化能力，并使用离散度将生成向量从不安全子空间指向安全子空间，从而避免生成不安全的内容。 |
| [^40] | [CB-Conformer: Contextual biasing Conformer for biased word recognition.](http://arxiv.org/abs/2304.09607) | CB-Conformer 是一种为了提高有偏差词识别而提出的 Conformer，引入了 Contextual Biasing Module 和 Self-Adaptive Language Model 以更好地利用上下文信息和单词偏差信息，并在测试中取得显著提高。 |
| [^41] | [Improving Autoregressive NLP Tasks via Modular Linearized Attention.](http://arxiv.org/abs/2304.08453) | 本文提出模块化线性化注意力机制（MLA）以最大化推理质量并实现速度提升，并在多个自回归自然语言处理任务上验证了该方法，包括语音到文本神经机器翻译（S2T NMT）、语音到文本同声传译（SimulST）和自回归文本到频谱图任务，在TTS上具有高效率收益，在NMT和SimulST的训练和推理过程中表现出竞争性能。 |
| [^42] | [Chinese Open Instruction Generalist: A Preliminary Release.](http://arxiv.org/abs/2304.07987) | 本论文旨在通过适应不同子任务的固有特性，创建一个中文指令数据集，以填补指令调整技术在中文语言领域的空白。 |
| [^43] | [Selective Data Augmentation for Robust Speech Translation.](http://arxiv.org/abs/2304.03169) | 本文提出了一种针对英印ST的e2e架构，同时将两个不完美的机器翻译服务用于生成并行数据，并且提出了一种数据增强策略以提高鲁棒性，结果呈现出比基准方法更好的性能。 |
| [^44] | [Context-Aware Classification of Legal Document Pages.](http://arxiv.org/abs/2304.02787) | 本文提出一种新方法，使用额外的标记增强输入，引入循环，可以使用预训练的 Transformer 模型（如 BERT）进行上下文感知的法律文件页面分类。 |
| [^45] | [RPTQ: Reorder-based Post-training Quantization for Large Language Models.](http://arxiv.org/abs/2304.01089) | 本研究提出了一种新的基于重排的量化方法RPTQ，目的是解决大型语言模型在量化时由于信道激活范围不同而产生的问题。实现该方法后，我们将LLL模型推动到3位激活。 |
| [^46] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^47] | [Is ChatGPT a Good NLG Evaluator? A Preliminary Study.](http://arxiv.org/abs/2303.04048) | 通过针对任务特定和方面特定，我们在五个NLG元评估数据集上进行实验，表明ChatGPT作为NLG评估指标并不总是与人类评估相一致，尤其是在流畅度方面。这提醒人们在使用ChatGPT作为唯一的自动NLG评估指标时要谨慎。 |
| [^48] | [Hitachi at SemEval-2023 Task 3: Exploring Cross-lingual Multi-task Strategies for Genre and Framing Detection in Online News.](http://arxiv.org/abs/2303.01794) | Hitachi团队参加SemEval-2023第3项任务，研究了跨语言和多任务策略，表明跨语言/多任务训练和收集外部平衡数据集可以有益于流派和框架检测，在意大利语和俄语流派分类子任务中实现了最高的宏平均F1分数。 |
| [^49] | [Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics Without the Reference.](http://arxiv.org/abs/2301.09008) | 该论文提出了一个质量评估的问题，叫做Metric Estimation，它能够在没有参考翻译的情况下，预测自动化评估度量，同时解决了人工注释费时费力的问题。 |
| [^50] | [InferEM: Inferring the Speaker's Intention for Empathetic Dialogue Generation.](http://arxiv.org/abs/2212.06373) | 通过推断对话中最后一次发言来捕捉说话者的意图，提出了一种利用多头注意力的意图融合模块的共情对话生成模型InferEM。模型同时利用前几次发言预测最后一次发言，具有较高的可行性。 |
| [^51] | [Relation-Aware Language-Graph Transformer for Question Answering.](http://arxiv.org/abs/2212.00975) | 本论文提出了关系感知语言图转换器，能够以统一的方式联合推理语言和图关于实体关系，并在多个QA数据集上验证了其有效性。 |
| [^52] | [StructDiffusion: Language-Guided Creation of Physically-Valid Structures using Unseen Objects.](http://arxiv.org/abs/2211.04604) | 本论文提出了一种结合扩散模型和以物体为中心的转换器的方法，通过高层语言目标和局部视点云构建物理有效的结构，该方法可用于多个具有挑战性的多步骤3D规划任务，即使使用未知对象仍能提高成功率。 |
| [^53] | [Augmenting Interpretable Models with LLMs during Training.](http://arxiv.org/abs/2209.11799) | 本文提出了 Aug-imodels 框架，利用 LLMs 的知识在拟合过程中构建高效且可解释的模型，在推理过程中不使用 LLMs，具备完全的透明性。研究探讨了两种不同方式的实现，并在多种文本分类数据集中表现出优异的效果。 |
| [^54] | [Abstractive Meeting Summarization: A Survey.](http://arxiv.org/abs/2208.04163) | 本文提供了对抽象会议摘要的调查，介绍了数据集、模型和评估指标，并表明这种摘要形式在多方谈话中尤其有用。 |
| [^55] | [Predicting Hate Intensity of Twitter Conversation Threads.](http://arxiv.org/abs/2206.08406) | 本文提出了DRAGNET++, 通过考虑对话线程的语义、传播结构和用户交互，以预测推文的回复链中可能存在的仇恨程度，并在两个公开数据集上的实验中表现出优越性能。该模型可为社交媒体平台提供在恶意对话升级之前识别和管理的工具。 |
| [^56] | [Evaluating the Tradeoff Between Abstractiveness and Factuality in Abstractive Summarization.](http://arxiv.org/abs/2108.02859) | 本文分析了抽象化摘要中抽象性和事实性之间的权衡，并引入了两个包含人类事实判断的数据集。研究表明，虽然抽象性的增加通常会导致事实性的下降，但事实性的衰减率取决于系统的训练数据等因素。同时，新的事实度指标可以调整抽象程度的程度，弥补事实性的不足。 |

# 详细

[^1]: 无结构数据和结构化数据：我们能否使用大型语言模型获得最佳结果？

    Unstructured and structured data: Can we have the best of both worlds with large language models?. (arXiv:2304.13010v1 [cs.DB])

    [http://arxiv.org/abs/2304.13010](http://arxiv.org/abs/2304.13010)

    本文探讨使用大型语言模型查询无结构数据和结构化数据的潜力及挑战。

    

    本文讨论了使用大型语言模型查询无结构数据和结构化数据的潜力，并概述了构建适用于两种数据类型的问答系统所涉及的一些研究挑战。

    This paper presents an opinion on the potential of using large language models to query on both unstructured and structured data. It also outlines some research challenges related to the topic of building question-answering systems for both types of data.
    
[^2]: 超越多链思维：基于元推理的问题解答方法

    Answering Questions by Meta-Reasoning over Multiple Chains of Thought. (arXiv:2304.13007v1 [cs.CL])

    [http://arxiv.org/abs/2304.13007](http://arxiv.org/abs/2304.13007)

    本论文提出了基于元推理的Multi-Chain Reasoning (MCR)方法，该方法检查多个推理链，混合它们之间的信息并选择最相关的事实，从而超越多链思维，解决多跳QA问题。 实验结果表明MCR胜过多个强基线，解释质量高。

    

    现代多跳问题解答（QA）系统通常将问题分解为一系列思考步骤（CoT），然后才得出最终答案。通常来说，多个链条被抽样并通过最终答案的投票机制进行聚合，但中间步骤本身被丢弃。虽然这种方法提高了性能，但它们并不考虑链之间的中间步骤之间的关系，并且不提供预测答案的统一解释。我们引入了基于元推理的 Multi-Chain Reasoning (MCR) 方法，该方法利用大型语言模型来超越多个思考链，而不是聚合回答。MCR检查不同的推理链，混合它们之间的信息并选择在生成解释和预测答案时最相关的事实。MCR在7个多跳QA数据集上胜过强基线。此外，我们的分析表明MCR的解释具有高质量。

    Modern systems for multi-hop question answering (QA) typically break questions into a sequence of reasoning steps, termed chain-of-thought (CoT), before arriving at a final answer. Often, multiple chains are sampled and aggregated through a voting mechanism over the final answers, but the intermediate steps themselves are discarded. While such approaches improve performance, they do not consider the relations between intermediate steps across chains and do not provide a unified explanation for the predicted answer. We introduce Multi-Chain Reasoning (MCR), an approach which prompts large language models to meta-reason over multiple chains of thought, rather than aggregating their answers. MCR examines different reasoning chains, mixes information between them and selects the most relevant facts in generating an explanation and predicting the answer. MCR outperforms strong baselines on 7 multi-hop QA datasets. Moreover, our analysis reveals that MCR explanations exhibit high quality, en
    
[^3]: 评估印度语言间语义分析

    Evaluating Inter-Bilingual Semantic Parsing for Indian Languages. (arXiv:2304.13005v1 [cs.CL])

    [http://arxiv.org/abs/2304.13005](http://arxiv.org/abs/2304.13005)

    本研究提出了一个11种不同的印度语言的间语言Seq2seq语义分析数据集IE-SEMPARSE，并评估了现有的多语言seq2seq模型在其中的表现。

    

    尽管印度语言（IndicNLP）的自然语言生成取得了重大进展，但对于像语义解析这样的复杂结构任务缺乏数据集。导致此严重缺口的一个原因是逻辑形式的复杂性，这使得英语到多语言的翻译变得困难。 这个过程涉及将逻辑形式、意图和槽与翻译的非结构化话语对齐。为了解决这个问题，我们提出了一个11种不同的印度语言的间语言Seq2seq语义分析数据集IE-SEMPARSE。我们强调了所提出任务的实用性，并评估了现有的多语言seq2seq模型在几种训练-测试策略之间的性能。我们的实验揭示了原始多语言语义分析数据集（如mTOP、多语言TOP和multiATIS++）和我们提出的IE-SEMPARSE套件之间的高相关性。

    Despite significant progress in Natural Language Generation for Indian languages (IndicNLP), there is a lack of datasets around complex structured tasks such as semantic parsing. One reason for this imminent gap is the complexity of the logical form, which makes English to multilingual translation difficult. The process involves alignment of logical forms, intents and slots with translated unstructured utterance. To address this, we propose an Inter-bilingual Seq2seq Semantic parsing dataset IE-SEMPARSE for 11 distinct Indian languages. We highlight the proposed task's practicality, and evaluate existing multilingual seq2seq models across several train-test strategies. Our experiment reveals a high correlation across performance of original multilingual semantic parsing datasets (such as mTOP, multilingual TOP and multiATIS++) and our proposed IE-SEMPARSE suite.
    
[^4]: AudioGPT：理解和生成语音、音乐、声音和人头像

    AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head. (arXiv:2304.12995v1 [cs.CL])

    [http://arxiv.org/abs/2304.12995](http://arxiv.org/abs/2304.12995)

    AudioGPT是一种多模式人工智能系统，能够处理复杂的音频信息并支持口语对话，其实验结果表明其在处理语音、音乐、声音和人头像方面有着很强的能力。

    

    大型语言模型（LLM）在各种领域和任务中展现出了卓越的能力，挑战了我们对学习和认知的理解。尽管最近取得了成功，但当前的LLM无法处理复杂的音频信息或进行口语交流（如Siri或Alexa）。在这项工作中，我们提出了一种名为AudioGPT的多模式人工智能系统，它通过以下方式补充了LLM（即ChatGPT）：1）提供基础模型以处理复杂的音频信息并解决众多的理解和生成任务；2）提供输入/输出接口（ASR，TTS）以支持口语对话。随着对人类意图理解和与基础模型协作的多模式LLM的评估需求的增加，我们概述了原则和过程，并测试了AudioGPT的一致性、能力和稳健性。实验结果显示，AudioGPT在解决具有语音、音乐、声音和人头像理解和生成的AI任务方面具有很强的能力。

    Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving AI tasks with speech, music, sound, and talking head understanding and gene
    
[^5]: 测量大规模多任务中文理解能力

    Measuring Massive Multitask Chinese Understanding. (arXiv:2304.12986v1 [cs.CL])

    [http://arxiv.org/abs/2304.12986](http://arxiv.org/abs/2304.12986)

    本研究提出了一项测试，以衡量大型中文语言模型的多任务准确性，测试涵盖医学、法律、心理学和教育四个主要领域，结果表明所有模型在法律领域中表现都很差，建议研究人员应该开发更加多样化和均衡的多任务中文理解模型。

    

    大规模中文语言模型的研发正蓬勃发展，但缺乏相应的能力评估。因此，我们提出了一个测试，以衡量大型中文语言模型的多任务准确性。该测试涵盖了医学、法律、心理学和教育四个主要领域，在医学领域有15个子任务，在教育领域有8个子任务。我们发现，在零样本设置下表现最佳的模型平均比表现最差的模型高出近22个百分点。在四个主要领域中，所有模型的平均零样本准确度均未超过0.5。在子领域中，只有GPT-3.5-turbo模型在临床医学中实现了0.703的零样本准确度，这是所有模型在所有子任务中最高的准确度。所有模型在法律领域中表现都很差，最高的零样本准确度仅达到0.259。通过全面评估多个学科的广度和深度的知识，我们建议研究人员应该开发更加多样化和均衡的多任务中文理解模型。

    The development of large-scale Chinese language models is flourishing, yet there is a lack of corresponding capability assessments. Therefore, we propose a test to measure the multitask accuracy of large Chinese language models. This test encompasses four major domains, including medicine, law, psychology, and education, with 15 subtasks in medicine and 8 subtasks in education. We found that the best-performing models in the zero-shot setting outperformed the worst-performing models by nearly 22 percentage points on average. Across the four major domains, the average zero-shot accuracy of all models did not exceed 0.5. In the subdomains, only the GPT-3.5-turbo model achieved a zero-shot accuracy of 0.703 in clinical medicine, which was the highest accuracy among all models across all subtasks. All models performed poorly in the legal domain, with the highest zero-shot accuracy reaching only 0.259. By comprehensively evaluating the breadth and depth of knowledge across multiple discipli
    
[^6]: 面向DSTC11任务导向式对话跟踪的会话意图诱导

    Intent Induction from Conversations for Task-Oriented Dialogue Track at DSTC 11. (arXiv:2304.12982v1 [cs.CL])

    [http://arxiv.org/abs/2304.12982](http://arxiv.org/abs/2304.12982)

    本论文介绍了DSTC11任务导向式对话跟踪的会话意图诱导，提出了两个子任务和三个数据集，并给出了简单的基线，用以评估方法的研究。其中旨在在客户服务交互的真实环境中自动诱导客户意图并对其进行评估。

    

    随着虚拟助手的需求和普及增加，近年来的一些工作研究了通过自动诱导意图或诱导槽和对话状态来加速机器人架构设计的方法。然而，缺乏专用基准和标准化评估使得进展难以跟踪，系统之间的比较也难以进行。本次挑战赛提出了一个基准来评估在人类代理和客户之间的客户服务交互的真实环境中自动诱导客户意图方法的研究。我们提出了两个子任务来逐步解决自动诱导意图和相应评估方法。我们提供了三个适合进行任务评估的数据集，并提出了简单的基线。最后，我们总结了挑战赛的提交和结果，共收到了来自34个团队的提交。

    With increasing demand for and adoption of virtual assistants, recent work has investigated ways to accelerate bot schema design through the automatic induction of intents or the induction of slots and dialogue states. However, a lack of dedicated benchmarks and standardized evaluation has made progress difficult to track and comparisons between systems difficult to make. This challenge track, held as part of the Eleventh Dialog Systems Technology Challenge, introduces a benchmark that aims to evaluate methods for the automatic induction of customer intents in a realistic setting of customer service interactions between human agents and customers. We propose two subtasks for progressively tackling the automatic induction of intents and corresponding evaluation methodologies. We then present three datasets suitable for evaluating the tasks and propose simple baselines. Finally, we summarize the submissions and results of the challenge track, for which we received submissions from 34 tea
    
[^7]: 基于Phylogeny的适配器在SemEval-2023第12项任务：情感分析中的应用

    GMNLP at SemEval-2023 Task 12: Sentiment Analysis with Phylogeny-Based Adapters. (arXiv:2304.12979v1 [cs.CL])

    [http://arxiv.org/abs/2304.12979](http://arxiv.org/abs/2304.12979)

    该论文介绍了GMU团队在SemEval-2023共享任务AfriSenti-SemEval中所使用的情感分析系统，使用AfroXLMR-large作为预训练语言模型并引入了增强的训练数据和基于Phylogeny的适配器调整以得到最佳结果。

    

    本文介绍了GMU对SemEval-2023共享任务AfriSenti-SemEval的情感分析系统。我们参与了单语言、多语言和零样本三个子任务。我们的方法使用了初始化为AfroXLMR-large的模型，它是一个在非洲语言上预训练并相应微调的多语言语言模型。我们还引入了增强的训练数据以及原始训练数据。除了微调外，我们还执行基于Phylogeny的适配器调整来创建多个模型，并将最佳模型集成到最终提交中。我们的系统在第5轨道Amharic上取得了最佳的F1分数，比该轨道上第二最佳性能系统高出6.2个F1分数。总体而言，我们的系统在参与所有15个轨道的10个系统中排名第5。

    This report describes GMU's sentiment analysis system for the SemEval-2023 shared task AfriSenti-SemEval. We participated in all three sub-tasks: Monolingual, Multilingual, and Zero-Shot. Our approach uses models initialized with AfroXLMR-large, a pre-trained multilingual language model trained on African languages and fine-tuned correspondingly. We also introduce augmented training data along with original training data. Alongside finetuning, we perform phylogeny-based adapter tuning to create several models and ensemble the best models for the final submission. Our system achieves the best F1-score on track 5: Amharic, with 6.2 points higher F1-score than the second-best performing system on this track. Overall, our system ranks 5th among the 10 systems participating in all 15 tracks.
    
[^8]: 逃离机器翻译中句子级范式的限制

    Escaping the sentence-level paradigm in machine translation. (arXiv:2304.12959v1 [cs.CL])

    [http://arxiv.org/abs/2304.12959](http://arxiv.org/abs/2304.12959)

    本文提出了一种摆脱机器翻译中句子级范式限制的方法，通过处理三个障碍来实现：使用足够大的标准Transformer架构、引入一种简单而有效的技术来将文档级信息转化为适合训练的形式、基于自动文档分类的评估协议来有效地识别文档级翻译质量。在两个非常不同的文档级翻译任务上，我们的实验表明，在此数据上训练的Transformer模型明显优于强大的基线模型。

    

    众所周知，文档语境对于解决一系列翻译模糊性至关重要，事实上，文档设置几乎是所有翻译的自然设置。然而，机器翻译（包括研究和生产）在几十年前的句子级翻译范式中仍然停滞不前，这是一个越来越明显的问题，由于来自大型语言模型的竞争压力，这些模型天生就是基于文档的。本文提出了一种摆脱这种困境的方法，同时解决了三个障碍：我们应该使用什么架构？我们从哪里获取训练它们的文档级信息？以及我们如何知道它们是否足够好？

    It is well-known that document context is vital for resolving a range of translation ambiguities, and in fact the document setting is the most natural setting for nearly all translation. It is therefore unfortunate that machine translation -- both research and production -- largely remains stuck in a decades-old sentence-level translation paradigm. It is also an increasingly glaring problem in light of competitive pressure from large language models, which are natively document-based. Much work in document-context machine translation exists, but for various reasons has been unable to catch hold. This paper suggests a path out of this rut by addressing three impediments at once: what architectures should we use? where do we get document-level information for training them? and how do we know whether they are any good? In contrast to work on specialized architectures, we show that the standard Transformer architecture is sufficient, provided it has enough capacity. Next, we address the t
    
[^9]: 神经网络中的非确定性栈

    Nondeterministic Stacks in Neural Networks. (arXiv:2304.12955v1 [cs.CL])

    [http://arxiv.org/abs/2304.12955](http://arxiv.org/abs/2304.12955)

    本论文提出在神经网络中添加了可以处理句法歧义的非确定性栈，有效地模拟一个非确定性下推自动机。

    

    人类语言中充满了 组成性句法结构，尽管神经网络在处理语言的计算机系统方面做出了突破性的改进，但是广泛使用的神经网络体系结构在处理语法方面仍存在局限性。为了解决这个问题，之前的工作提出在神经网络中添加栈 数据结构，从语法和栈之间的理论关系中汲取灵感。然而，这些方法采用的是设计用于跟踪一个句法分析的确定性栈，而在语言中需要采用非确定性栈进行解析的句法歧义极其常见。在本论文中，我们通过提出一种将非确定性栈纳入到神经网络中的方法来解决这个差异。我们开发了一种可微分的数据结构，利用动态规划算法高效地模拟了一个非确定性下推自动机，表示一个指数级的计算数量。

    Human language is full of compositional syntactic structures, and although neural networks have contributed to groundbreaking improvements in computer systems that process language, widely-used neural network architectures still exhibit limitations in their ability to process syntax. To address this issue, prior work has proposed adding stack data structures to neural networks, drawing inspiration from theoretical connections between syntax and stacks. However, these methods employ deterministic stacks that are designed to track one parse at a time, whereas syntactic ambiguity, which requires a nondeterministic stack to parse, is extremely common in language. In this dissertation, we remedy this discrepancy by proposing a method of incorporating nondeterministic stacks into neural networks. We develop a differentiable data structure that efficiently simulates a nondeterministic pushdown automaton, representing an exponential number of computations with a dynamic programming algorithm. 
    
[^10]: 语义网络的拓扑性质和组织原理

    Topological properties and organizing principles of semantic networks. (arXiv:2304.12940v1 [cs.CL])

    [http://arxiv.org/abs/2304.12940](http://arxiv.org/abs/2304.12940)

    本论文研究了由不同语言的7个语义关系定义的语义网络的基本属性。我们发现，语义网络具有普遍的基本特性：稀疏、高度聚集和自我组织化，并呈现出幂律度数分布。一些网络显示出语言特定的属性，这些属性受语法规则的影响，例如来自高度屈折语言的网络。

    

    随着非结构化文本数据的增加，自然语言理解成为计算机算法中越来越重要的任务。自然语言处理(NLP)应用程序依靠语义网络进行结构化知识表示。设计NLP算法时必须考虑语义网络的基本属性，但它们的结构尚未得到研究。我们研究了由11种不同语言的7个语义关系定义的ConceptNet语义网络的属性。我们发现，语义网络具有普遍的基本特性：它们是稀疏的、高度集聚的，并呈现出幂律度数分布。我们的研究结果显示，大多数网络都是自我组织的。一些网络显示出语言特定的属性，这些属性受语法规则的影响，例如高度屈折语言(如拉丁语、德语、法语和西班牙语)的网络在度数分布方面有峰值偏差。

    Interpreting natural language is an increasingly important task in computer algorithms due to the growing availability of unstructured textual data. Natural Language Processing (NLP) applications rely on semantic networks for structured knowledge representation. The fundamental properties of semantic networks must be taken into account when designing NLP algorithms, yet they remain to be structurally investigated. We study the properties of semantic networks from ConceptNet, defined by 7 semantic relations from 11 different languages. We find that semantic networks have universal basic properties: they are sparse, highly clustered, and exhibit power-law degree distributions. Our findings show that the majority of the considered networks are scale-free. Some networks exhibit language-specific properties determined by grammatical rules, for example networks from highly inflected languages, such as e.g. Latin, German, French and Spanish, show peaks in the degree distribution that deviate 
    
[^11]: 通过双重对抗去偏置实现的越界证据感知假新闻检测

    Out-of-distribution Evidence-aware Fake News Detection via Dual Adversarial Debiasing. (arXiv:2304.12888v1 [cs.CL])

    [http://arxiv.org/abs/2304.12888](http://arxiv.org/abs/2304.12888)

    该论文提出了一种新颖的双重对抗学习方法，通过在模型中加入去偏置鉴别器，旨在训练模型更好地进行越界证据感知假新闻检测，有效减轻新闻和证据内容偏差的影响。

    

    越界证据感知假新闻检测旨在对新闻和基于新闻内容检索的证据进行推理，以查找统一性或不一致性。然而，我们发现，证据感知检测模型会受到偏差的影响，即新闻/证据内容和真实/假新闻标签之间的虚假相关性，并且很难推广到越界情况。为了应对这个问题，我们提出了一种新颖的双重对抗学习方法。我们在DAL中加入了新闻方面和证据方面去偏置鉴别器，它们的目标都是真假新闻标签。然后，DAL会逆向优化新闻方面和证据方面去偏置鉴别器，以减轻新闻和证据内容偏差的影响。同时，DAL还优化主要的假新闻预测器，让新闻-证据交互模块能够被学习。这个过程能够帮助我们教新闻检测模型更好地进行新闻证据推理，并将检测假新闻的负面影响降至最低。

    Evidence-aware fake news detection aims to conduct reasoning between news and evidence, which is retrieved based on news content, to find uniformity or inconsistency. However, we find evidence-aware detection models suffer from biases, i.e., spurious correlations between news/evidence contents and true/fake news labels, and are hard to be generalized to Out-Of-Distribution (OOD) situations. To deal with this, we propose a novel Dual Adversarial Learning (DAL) approach. We incorporate news-aspect and evidence-aspect debiasing discriminators, whose targets are both true/fake news labels, in DAL. Then, DAL reversely optimizes news-aspect and evidence-aspect debiasing discriminators to mitigate the impact of news and evidence content biases. At the same time, DAL also optimizes the main fake news predictor, so that the news-evidence interaction module can be learned. This process allows us to teach evidence-aware fake news detection models to better conduct news-evidence reasoning, and min
    
[^12]: NLP-LTU在SemEval-2023任务10中的应用: 数据增强和半监督学习技术对非平衡数据文本分类性能的影响

    NLP-LTU at SemEval-2023 Task 10: The Impact of Data Augmentation and Semi-Supervised Learning Techniques on Text Classification Performance on an Imbalanced Dataset. (arXiv:2304.12847v1 [cs.CL])

    [http://arxiv.org/abs/2304.12847](http://arxiv.org/abs/2304.12847)

    本文提出应用transformer模型和数据增强、半监督学习技术的方法，以应对文本分类中的类别不平衡问题，从而增强整体性能。

    

    本文提出了一种方法，专注于检测和分类社交媒体帖子中的在线性别歧视，以应对SemEval23任务10的挑战。我们的解决方案基于微调后的transformer模型（BERTweet、RoBERTa和DeBERTa）的集成。为了缓解与类别不平衡相关的问题，并提高模型的泛化能力，我们还尝试了数据增强和半监督学习。具体来说，对于数据增强，我们使用了回译，不是在所有类别上，就是只在欠表示的类别上。我们还通过广泛的实验分析了这些策略对管道整体性能的影响。对于半监督学习，我们发现，如果有大量未标记的领域内数据可用，半监督学习可以增强性能。

    In this paper, we propose a methodology for task 10 of SemEval23, focusing on detecting and classifying online sexism in social media posts. The task is tackling a serious issue, as detecting harmful content on social media platforms is crucial for mitigating the harm of these posts on users. Our solution for this task is based on an ensemble of fine-tuned transformer-based models (BERTweet, RoBERTa, and DeBERTa). To alleviate problems related to class imbalance, and to improve the generalization capability of our model, we also experiment with data augmentation and semi-supervised learning. In particular, for data augmentation, we use back-translation, either on all classes, or on the underrepresented classes only. We analyze the impact of these strategies on the overall performance of the pipeline through extensive experiments. while for semi-supervised learning, we found that with a substantial amount of unlabelled, in-domain data available, semi-supervised learning can enhance the 
    
[^13]: 一项面向自然语言处理的公民科学项目的经验教训

    Lessons Learned from a Citizen Science Project for Natural Language Processing. (arXiv:2304.12836v1 [cs.CL])

    [http://arxiv.org/abs/2304.12836](http://arxiv.org/abs/2304.12836)

    本论文探讨了公民科学在自然语言处理领域的应用，研究表明这可以产生高质量的注释并吸引积极的志愿者，但需要考虑可扩展性、长期参与和法律和伦理问题等因素。

    

    许多自然语言处理系统使用带注释的语料库进行训练和评估。然而，标记数据通常很难获得，并且扩展注释项目也很困难，因此注释任务常常被外包给有偿的众包工人。公民科学是一个相对未被开发的众包替代方案。为了调查公民科学是否以及如何适用于此领域，我们进行了一项探索性研究，通过重新注释现有众包数据集的部分内容，与不同志愿者群体参与公民科学。结果显示，这可以产生高质量的注释并吸引积极的志愿者，但也需要考虑可扩展性、长期参与和法律和伦理问题等因素。我们总结了指南，并提供了我们的代码和数据，以帮助未来进行公民科学工作。

    Many Natural Language Processing (NLP) systems use annotated corpora for training and evaluation. However, labeled data is often costly to obtain and scaling annotation projects is difficult, which is why annotation tasks are often outsourced to paid crowdworkers. Citizen Science is an alternative to crowdsourcing that is relatively unexplored in the context of NLP. To investigate whether and how well Citizen Science can be applied in this setting, we conduct an exploratory study into engaging different groups of volunteers in Citizen Science for NLP by re-annotating parts of a pre-existing crowdsourced dataset. Our results show that this can yield high-quality annotations and attract motivated volunteers, but also requires considering factors such as scalability, participation over time, and legal and ethical issues. We summarize lessons learned in the form of guidelines and provide our code and data to aid future work on Citizen Science.
    
[^14]: 一种新的用于机器学习的确定性信息理论

    A New Information Theory of Certainty for Machine Learning. (arXiv:2304.12833v1 [cs.IT])

    [http://arxiv.org/abs/2304.12833](http://arxiv.org/abs/2304.12833)

    该论文提出了一种新的信息理论概念 troenpy 来量化底层分布的确定性，用于机器学习中文档分类和序列数据权重方案，并定义了量子 troenpy 量化量子系统确定性。

    

    克劳德·香农提出了熵的概念来量化通信编码理论中随机分布的不确定性。我们观察到熵的这种不确定性特性也限制了其在数学建模中的直接使用。因此，我们提出了一个新概念 troenpy，作为熵的规范对偶，来量化底层分布的确定性。我们展示了在机器学习中的两个应用。第一个是用于传统的文档分类，我们开发了一个基于 troenpy 权重方案来利用文档分类标签。第二个是针对序列数据的自我 troenpy 权重方案，并表明它可以轻松地包含在基于神经网络的语言模型中，并实现显著的困惑度降低。我们还定义了量子 troenpy 作为 Von Neumann 熵的对偶，以量化量子系统的确定性。

    Claude Shannon coined entropy to quantify the uncertainty of a random distribution for communication coding theory. We observe that the uncertainty nature of entropy also limits its direct usage in mathematical modeling. Therefore we propose a new concept troenpy,as the canonical dual of entropy, to quantify the certainty of the underlying distribution. We demonstrate two applications in machine learning. The first is for the classical document classification, we develop a troenpy based weighting scheme to leverage the document class label. The second is a self-troenpy weighting scheme for sequential data and show that it can be easily included in neural network based language models and achieve dramatic perplexity reduction. We also define quantum troenpy as the dual of the Von Neumann entropy to quantify the certainty of quantum systems.
    
[^15]: 一种新型的Shannon信息及加权方案的对偶

    A Novel Dual of Shannon Information and Weighting Scheme. (arXiv:2304.12814v1 [cs.CL])

    [http://arxiv.org/abs/2304.12814](http://arxiv.org/abs/2304.12814)

    本文通过发掘信息熵自然对偶，提出了一种新的量troenpy，并应用于提出了基于troenpy的文档加权方案，即正类别频率（PCF），以及一种新的类别信息偏差特征ECIB，在监督学习中具有互信息的泛化性质。

    

    Shannon信息理论不仅在通信技术领域，其应用还拓展至机器学习和人工智能领域。本文发掘信息熵存在自然对偶，并引入了一种新的量troenpy，用于衡量底层分布的确定性、普遍性和相似性。我们提出了基于troenpy的文档加权方案，即正类别频率（PCF），并证明其在公共数据集上的优越性。此外，我们还开发了一种新的类别信息偏差特征ECIB，在监督学习中具有互信息的泛化性质。

    Shannon Information theory has achieved great success in not only communication technology where it was originally developed for but also many other science and engineering fields such as machine learning and artificial intelligence. Inspired by the famous weighting scheme TF-IDF, we discovered that information entropy has a natural dual. We complement the classical Shannon information theory by proposing a novel quantity, namely troenpy. Troenpy measures the certainty, commonness and similarity of the underlying distribution. To demonstrate its usefulness, we propose a troenpy based weighting scheme for document with class labels, namely positive class frequency (PCF). On a collection of public datasets we show the PCF based weighting scheme outperforms the classical TF-IDF and a popular Optimal Transportation based word moving distance algorithm in a kNN setting. We further developed a new odds-ratio type feature, namely Expected Class Information Bias(ECIB), which can be regarded as
    
[^16]: 超越“男性准则”：NLP语境中的隐性男性偏见

    Transcending the "Male Code": Implicit Masculine Biases in NLP Contexts. (arXiv:2304.12810v1 [cs.CL])

    [http://arxiv.org/abs/2304.12810](http://arxiv.org/abs/2304.12810)

    研究发现，当存在性别化语言时，NLP语境中也存在着性别偏见，尤其是男性偏见。调查者提供了一个涵盖了性别化语言与语言之间歧义关系的新字典“Ava”。

    

    关于虚拟助手（VAs）的性别偏差问题，批判性学说已经提高了人们的注意。大部分研究集中在语言中的显性偏见，尤其是针对女性、女孩、女性认同人群和性别酷儿的歧视，以及通过词向量嵌入的隐性关联；而对于男性和毒性男性，性别和性别二元分类的混为一谈，很少有基于男性和男性气概的有限模型。然而，我们还必须质询如何将男性气概“编码”到语言中及其将“男性”作为语言默认值的假设：隐性男性偏见。为此，我们调查了两个自然语言处理（NLP）数据集。我们发现当存在性别化语言时，性别偏见尤其是男性偏见也存在。此外，这些偏见与NLP上下文的关系细微且相关。我们提供了一个名为AVA的新字典，涵盖了性别化语言与语言之间的歧义关系。

    Critical scholarship has elevated the problem of gender bias in data sets used to train virtual assistants (VAs). Most work has focused on explicit biases in language, especially against women, girls, femme-identifying people, and genderqueer folk; implicit associations through word embeddings; and limited models of gender and masculinities, especially toxic masculinities, conflation of sex and gender, and a sex/gender binary framing of the masculine as diametric to the feminine. Yet, we must also interrogate how masculinities are "coded" into language and the assumption of "male" as the linguistic default: implicit masculine biases. To this end, we examined two natural language processing (NLP) data sets. We found that when gendered language was present, so were gender biases and especially masculine biases. Moreover, these biases related in nuanced ways to the NLP context. We offer a new dictionary called AVA that covers ambiguous associations between gendered language and the langua
    
[^17]: 语音助手可以听起来可爱吗？迈向可爱嗓音的模型

    Can Voice Assistants Sound Cute? Towards a Model of Kawaii Vocalics. (arXiv:2304.12809v1 [cs.HC])

    [http://arxiv.org/abs/2304.12809](http://arxiv.org/abs/2304.12809)

    本文研究声音是否可以具备可爱性，并通过探索可爱的语音特质，即可爱的声音学来实现。通过对不同年龄段和不同特征的语音感受研究，发现可爱性与性别、年龄、流利度和人工性等方面有关。提出了一个可爱嗓音的模型，需要进行声音质量、认知评估、行为反应和情感报告的研究来验证。

    

    日本的“可爱”概念或表达可爱、脆弱和/或魅力的方式是一种全球文化输出。研究探讨了在机器人和虚拟角色的视觉外观、非语言行为和声音中探索可爱性作为设计特征和用户体验因素。在这项初步工作中，我们考虑了声音是否可以通过探索语音助手语音的声音特质，即可爱的声音学，具备可爱性。根据一个包含年龄的可爱模型，我们对年轻和年老的日语电脑语音的可爱度进行了用户感知研究。我们发现可爱性与性别和年龄的感知相交，即性别模糊和女孩气质，以及VA的特征，即流利度和人工性。我们提出了一个可爱嗓音的模型，通过识别和研究声音质量、认知评估、行为反应和情感报告进行验证。

    The Japanese notion of "kawaii" or expressions of cuteness, vulnerability, and/or charm is a global cultural export. Work has explored kawaii-ness as a design feature and factor of user experience in the visual appearance, nonverbal behaviour, and sound of robots and virtual characters. In this initial work, we consider whether voices can be kawaii by exploring the vocal qualities of voice assistant speech, i.e., kawaii vocalics. Drawing from an age-inclusive model of kawaii, we ran a user perceptions study on the kawaii-ness of younger- and older-sounding Japanese computer voices. We found that kawaii-ness intersected with perceptions of gender and age, i.e., gender ambiguous and girlish, as well as VA features, i.e., fluency and artificiality. We propose an initial model of kawaii vocalics to be validated through the identification and study of vocal qualities, cognitive appraisals, behavioural responses, and affective reports.
    
[^18]: 状态空间不够用：机器翻译需要注意力机制

    State Spaces Aren't Enough: Machine Translation Needs Attention. (arXiv:2304.12776v1 [cs.CL])

    [http://arxiv.org/abs/2304.12776](http://arxiv.org/abs/2304.12776)

    S4模型在机器翻译任务上与变压器模型相比存在四个BLEU分数点的差距，需要注意力机制来弥补其无法在单个隐藏状态中总结完整的源句子的缺陷。

    

    序列的结构状态空间（S4）是一个最近提出的序列模型，在各种任务中都有成功的应用，例如视觉、语言建模和音频。由于它的数学公式，它将其输入压缩为一个隐藏状态，并能够捕获长期依赖关系，同时避免了注意力机制的需要。在本文中，我们将S4应用于机器翻译（MT），并在WMT'14和WMT'16上评估了几种编码器-解码器变体。与在语言建模中的成功相比，我们发现S4在BLEU点数上落后于变压器约4个点，并且令人感到困惑的是，它在处理长句时遇到了困难。最后，我们展示了这种差距是由于S4无法在单个隐藏状态中总结完整的源句子所致，并展示了我们可以通过引入注意力机制来弥补这一差距。

    Structured State Spaces for Sequences (S4) is a recently proposed sequence model with successful applications in various tasks, e.g. vision, language modeling, and audio. Thanks to its mathematical formulation, it compresses its input to a single hidden state, and is able to capture long range dependencies while avoiding the need for an attention mechanism. In this work, we apply S4 to Machine Translation (MT), and evaluate several encoder-decoder variants on WMT'14 and WMT'16. In contrast with the success in language modeling, we find that S4 lags behind the Transformer by approximately 4 BLEU points, and that it counter-intuitively struggles with long sentences. Finally, we show that this gap is caused by S4's inability to summarize the full source sentence in a single hidden state, and show that we can close the gap by introducing an attention mechanism.
    
[^19]: 带扰动一致性学习的测试时间自适应方法

    Test-Time Adaptation with Perturbation Consistency Learning. (arXiv:2304.12764v1 [cs.CL])

    [http://arxiv.org/abs/2304.12764](http://arxiv.org/abs/2304.12764)

    本文提出了一种测试时间自适应方法PCL，通过促进模型对分布变化的稳定预测，解决了目前PLMs在应对分布变化问题方面表现不佳的难题。

    

    目前，预训练语言模型(PLMs)在应对分布变化问题方面表现不佳，导致训练集上训练的模型在真实测试场景中失败。为解决这个问题，测试时间自适应(TTA)显示出巨大潜力，即在测试时更新模型参数以适应测试数据。现有的TTA方法依赖于经过良好设计的辅助任务或基于伪标签的自训练策略。然而，这些方法在性能提升和计算成本方面并没有达到良好的平衡。为了深入了解这种困境，本文选取了两种典型的TTA方法(Tent和OIL)进行探索，并发现稳定的预测是实现良好平衡的关键。因此，本文提出了扰动一致性学习(PCL)，一种简单的测试时间自适应方法，以促进模型对分布变化的样本进行稳定预测。在对抗攻击和跨域情况下的广泛实验结果表明了该方法的有效性。

    Currently, pre-trained language models (PLMs) do not cope well with the distribution shift problem, resulting in models trained on the training set failing in real test scenarios. To address this problem, the test-time adaptation (TTA) shows great potential, which updates model parameters to suit the test data at the testing time. Existing TTA methods rely on well-designed auxiliary tasks or self-training strategies based on pseudo-label. However, these methods do not achieve good trade-offs regarding performance gains and computational costs. To obtain some insights into such a dilemma, we take two representative TTA methods, i.e., Tent and OIL, for exploration and find that stable prediction is the key to achieving a good balance. Accordingly, in this paper, we propose perturbation consistency learning (PCL), a simple test-time adaptation method to promote the model to make stable predictions for samples with distribution shifts. Extensive experiments on adversarial robustness and cr
    
[^20]: BERT学习到了什么关于韵律的知识?

    What does BERT learn about prosody?. (arXiv:2304.12706v1 [cs.CL])

    [http://arxiv.org/abs/2304.12706](http://arxiv.org/abs/2304.12706)

    本论文在BERT上进行了一系列实验，探究了不同层次捕捉到的表示。结果表明，韵律是BERT学习到的结构信息的一部分，主要集中在中间层。

    

    语言模型已经在自然语言处理领域变得非常普遍，取得了许多任务的最先进结果，包括韵律。在训练期间，模型设计并不定义预先确定的语言目标，而是旨在学习语言的广义表示，因此分析和解释模型隐式捕获的表示对于弥合可解释性和模型性能之间的差距非常重要。几项研究探讨了模型捕获的语言信息，提供了一些有关它们表示能力的见解。然而，当前的研究尚未探索韵律是否是模型学习的语言结构信息的组成部分。在这项工作中，我们在BERT上进行了一系列实验，探究了不同层次捕捉到的表示。我们的结果表明，有关韵律突出的信息跨越许多层，但主要集中在中间层，这表明韵律确实是BERT学习到的结构信息的一部分。

    Language models have become nearly ubiquitous in natural language processing applications achieving state-of-the-art results in many tasks including prosody. As the model design does not define predetermined linguistic targets during training but rather aims at learning generalized representations of the language, analyzing and interpreting the representations that models implicitly capture is important in bridging the gap between interpretability and model performance. Several studies have explored the linguistic information that models capture providing some insights on their representational capacity. However, the current studies have not explored whether prosody is part of the structural information of the language that models learn. In this work, we perform a series of experiments on BERT probing the representations captured at different layers. Our results show that information about prosodic prominence spans across many layers but is mostly focused in middle layers suggesting th
    
[^21]: 最大编码速率降低下的句子表示压缩方法

    Compressing Sentence Representation with maximum Coding Rate Reduction. (arXiv:2304.12674v1 [cs.CL])

    [http://arxiv.org/abs/2304.12674](http://arxiv.org/abs/2304.12674)

    提出了一种在最大编码速率降低下的句子表示压缩方法，通过在句子表示模型Sentence-BERT中加入一个额外的学习投影层，并证明其可以在语义相关任务中获得与大型语言模型相当的结果。

    

    在大多数自然语言推理问题中，需要使用句子表示来进行语义检索任务。在近年来，预训练的大型语言模型已经相当有效地计算这些表示。这些模型产生高维句子嵌入。实际上存在大型和小型模型之间明显的性能差距。因此，由于空间和时间硬件限制，需要在使用较小模型(通常是大型语言模型的精简版本)时获得可比较的结果。在本文中，我们通过在最大编码速率降低(MCR2)目标的基础上学习额外的投影层，评估了句子表示模型Sentence-BERT的模型蒸馏，在这种方法中，MCR2是一种为了通用流形聚类而开发的新方法。我们证明，通过在复杂度和句子嵌入大小方面减小的新语言模型可以在语义相关任务中获得可比较的结果。

    In most natural language inference problems, sentence representation is needed for semantic retrieval tasks. In recent years, pre-trained large language models have been quite effective for computing such representations. These models produce high-dimensional sentence embeddings. An evident performance gap between large and small models exists in practice. Hence, due to space and time hardware limitations, there is a need to attain comparable results when using the smaller model, which is usually a distilled version of the large language model. In this paper, we assess the model distillation of the sentence representation model Sentence-BERT by augmenting the pre-trained distilled model with a projection layer additionally learned on the Maximum Coding Rate Reduction (MCR2)objective, a novel approach developed for general-purpose manifold clustering. We demonstrate that the new language model with reduced complexity and sentence embedding size can achieve comparable results on semantic
    
[^22]: PUNR: 用户行为建模的新闻推荐预训练

    PUNR: Pre-training with User Behavior Modeling for News Recommendation. (arXiv:2304.12633v1 [cs.IR])

    [http://arxiv.org/abs/2304.12633](http://arxiv.org/abs/2304.12633)

    本论文提出了一种无监督的预训练方法，它可以通过两个任务实现有效的用户行为建模，以提高新闻推荐系统的准确性和性能表现。

    

    新闻推荐旨在基于用户行为预测点击行为。如何有效地建模用户表示是推荐首选新闻的关键。现有方法大多集中在监督微调阶段的改进上。然而，还缺乏针对用户表示优化的基于PLM的无监督预训练方法。在本文中，我们提出了一种具有两个任务的无监督预训练范例，即用户行为掩蔽和用户行为生成，均致力于有效的用户行为建模。首先，我们引入了用户行为掩蔽预训练任务，以恢复基于上下文行为的掩蔽用户行为。通过这种方式，模型可以捕捉到更强大、更全面的用户新闻阅读模式。此外，我们还结合了一种新颖的辅助用户行为生成预训练任务，以增强从用户编码器派生出的用户表示向量。我们使用上述预训练的用户建模来进行新闻推荐，实验结果表明，我们的模型在多个数据集上取得了显著的性能提升。

    News recommendation aims to predict click behaviors based on user behaviors. How to effectively model the user representations is the key to recommending preferred news. Existing works are mostly focused on improvements in the supervised fine-tuning stage. However, there is still a lack of PLM-based unsupervised pre-training methods optimized for user representations. In this work, we propose an unsupervised pre-training paradigm with two tasks, i.e. user behavior masking and user behavior generation, both towards effective user behavior modeling. Firstly, we introduce the user behavior masking pre-training task to recover the masked user behaviors based on their contextual behaviors. In this way, the model could capture a much stronger and more comprehensive user news reading pattern. Besides, we incorporate a novel auxiliary user behavior generation pre-training task to enhance the user representation vector derived from the user encoder. We use the above pre-trained user modeling en
    
[^23]: BM25简单易懂：用稀疏逼近解释密集模型的排名列表

    Explain like I am BM25: Interpreting a Dense Model's Ranked-List with a Sparse Approximation. (arXiv:2304.12631v1 [cs.IR])

    [http://arxiv.org/abs/2304.12631](http://arxiv.org/abs/2304.12631)

    本论文提出了一种解释NRM的新方法——基于等价查询的局部解释方法。通过最大化NRM结果与具有等价查询的稀疏检索系统的结果集之间的相似性来生成等价查询。该方法与现有方法进行比较，并对检索效果和每种方法生成的词项进行了对比。

    

    相比于传统统计模型，神经检索模型(NRMs)因为可以通过稠密文档表示来捕捉语义意义而显示出更好的检索性能。然而，由于其不依赖于明确的词项匹配，这些模型往往可读性差。为了生成一种基于局部查询解释的新方法，我们引入了“等价查询”的概念，通过最大化NRM结果与具有等价查询的稀疏检索系统的结果集之间的相似性来生成等价查询。我们将这种方法与现有方法(如基于RM3的查询扩展)进行了比较，并对检索效果和每种方法生成的词项进行了对比。

    Neural retrieval models (NRMs) have been shown to outperform their statistical counterparts owing to their ability to capture semantic meaning via dense document representations. These models, however, suffer from poor interpretability as they do not rely on explicit term matching. As a form of local per-query explanations, we introduce the notion of equivalent queries that are generated by maximizing the similarity between the NRM's results and the result set of a sparse retrieval system with the equivalent query. We then compare this approach with existing methods such as RM3-based query expansion and contrast differences in retrieval effectiveness and in the terms generated by each approach.
    
[^24]: KINLP在SemEval-2023任务12中的应用：金亚琳达推文情感分析

    KINLP at SemEval-2023 Task 12: Kinyarwanda Tweet Sentiment Analysis. (arXiv:2304.12569v1 [cs.CL])

    [http://arxiv.org/abs/2304.12569](http://arxiv.org/abs/2304.12569)

    本文介绍了作者在SemEval-2023任务12中使用的针对金亚琳达推文情感分析的系统，并在该竞赛中取得了第二高的成绩。

    

    本文介绍了作者参加SemEval-2023任务12（非洲语言情感分析）的系统。该系统着重于金亚琳达语，并使用了具有语言特异性的模型。金亚琳达语的词汇形态学被建模为两层变形金刚体系结构，并且变形金刚模型是使用多任务掩码形态预测在大型文本语料库上进行预训练的。该模型部署在一个实验平台上，使用户可以在无需编写机器学习代码的情况下对预训练语言模型进行微调。我们在共享任务的最终提交中获得了34支团队中的第二名，取得了72.50%的加权F1分数。我们的评估结果分析突出了在该任务上实现高准确度的挑战，并确定了需要改进的领域。

    This paper describes the system entered by the author to the SemEval-2023 Task 12: Sentiment analysis for African languages. The system focuses on the Kinyarwanda language and uses a language-specific model. Kinyarwanda morphology is modeled in a two tier transformer architecture and the transformer model is pre-trained on a large text corpus using multi-task masked morphology prediction. The model is deployed on an experimental platform that allows users to experiment with the pre-trained language model fine-tuning without the need to write machine learning code. Our final submission to the shared task achieves second ranking out of 34 teams in the competition, achieving 72.50% weighted F1 score. Our analysis of the evaluation results highlights challenges in achieving high accuracy on the task and identifies areas for improvement.
    
[^25]: RenderDiffusion: 文本生成作为图像生成

    RenderDiffusion: Text Generation as Image Generation. (arXiv:2304.12519v1 [cs.CL])

    [http://arxiv.org/abs/2304.12519](http://arxiv.org/abs/2304.12519)

    本文提出了一种新的扩散方法——\textsc{RenderDiffusion}，通过文本引导的图像生成进行文本生成。它将连续扩散模型应用于离散文本并实现了条件文本生成作为字形图像生成问题。

    

    扩散模型已成为文本生成的新生成范式。考虑到文本的离散分类特性，在本文中，我们提出了一种新颖的扩散方法——\textsc{RenderDiffusion}，通过文本引导的图像生成进行文本生成。我们的关键思路是将目标文本呈现为包含视觉语言内容的"字形图像"。这样，条件化的文本生成可以被形式化为一个字形图像生成任务，然后自然地将连续扩散模型应用于离散文本。

    Diffusion models have become a new generative paradigm for text generation. Considering the discrete categorical nature of text, in this paper, we propose \textsc{RenderDiffusion}, a novel diffusion approach for text generation via text-guided image generation. Our key idea is to render the target text as a \emph{glyph image} containing visual language content. In this way, conditional text generation can be cast as a glyph image generation task, and it is then natural to apply continuous diffusion models to discrete texts. Specially, we utilize a cascaded architecture (\ie a base and a super-resolution diffusion model) to generate high-fidelity glyph images, conditioned on the input text. Furthermore, we design a text grounding module to transform and refine the visual language content from generated glyph images into the final texts. In experiments over four conditional text generation tasks and two classes of metrics (\ie quality and diversity), \textsc{RenderDiffusion} can achieve 
    
[^26]: 通过解释理解和预测自然语言推理中人工标注的变异

    Understanding and Predicting Human Label Variation in Natural Language Inference through Explanation. (arXiv:2304.12443v1 [cs.CL])

    [http://arxiv.org/abs/2304.12443](http://arxiv.org/abs/2304.12443)

    这篇论文介绍了一个包含注释标记和自由文本解释的自然语言推理解释数据集，称为LiveNLI，通过该数据集可以帮助自然语言处理模型识别人工标注的差异，同时还发现了GPT-3在标签预测方面仍有改进的空间。

    

    许多自然语言处理任务中存在人工标注的差异或注释不一致现象。为了使自然语言处理模型更加鲁棒且可信，需要识别这种差异并能够进行解释。为此，我们创建了第一个生态有效的解释数据集（LiveNLI），其中包括122个英文自然语言推理项目的注释和自由文本解释，每个项目至少有10个注释。我们使用该数据集的解释进行思维链提示，并发现仍有改进GPT-3的能力来预测在上下文中学习后的标签分布的空间。

    Human label variation (Plank 2022), or annotation disagreement, exists in many natural language processing (NLP) tasks. To be robust and trusted, NLP models need to identify such variation and be able to explain it. To this end, we created the first ecologically valid explanation dataset with diverse reasoning, LiveNLI. LiveNLI contains annotators' highlights and free-text explanations for the label(s) of their choice for 122 English Natural Language Inference items, each with at least 10 annotations. We used its explanations for chain-of-thought prompting, and found there is still room for improvement in GPT-3's ability to predict label distribution with in-context learning.
    
[^27]: TIGTEC：基于标记重要性的文本对抗事例生成方法

    TIGTEC : Token Importance Guided TExt Counterfactuals. (arXiv:2304.12425v1 [cs.LG])

    [http://arxiv.org/abs/2304.12425](http://arxiv.org/abs/2304.12425)

    TIGTEC是一个高效的文本对抗事例生成方法，使用本地特征重要性针对和修改对分类结果影响最大的单词，并在代价函数中使用语义距离评估对抗性解释。该方法具有很高的成功率、稀疏性、多样性和可信度，并且既可以是特定于模型的，也可以是无关模型的，非常方便用于生成对抗性解释。

    

    对抗事例是一种通过改变实例来翻转分类器输出以解释模型预测的方法。本文提出了TIGTEC，一种用于生成稀疏、可信和多样性的对抗性解释的高效模块方法。TIGTEC是一种文本编辑启发式方法，使用本地特征重要性针对和修改对分类结果影响最大的单词。提出了一种基于注意力机制的本地特征重要性，并通过一个集成语义距离的代价函数对生成的对抗性解释进行评估。该方法采用波束搜索算法进行高效的解空间搜索。实验结果表明，TIGTEC在成功率、稀疏性、多样性和可信度方面具有很高的实用性。该方法既可以是特定于模型的，也可以是无关模型的，非常方便用于生成对抗性解释。

    Counterfactual examples explain a prediction by highlighting changes of instance that flip the outcome of a classifier. This paper proposes TIGTEC, an efficient and modular method for generating sparse, plausible and diverse counterfactual explanations for textual data. TIGTEC is a text editing heuristic that targets and modifies words with high contribution using local feature importance. A new attention-based local feature importance is proposed. Counterfactual candidates are generated and assessed with a cost function integrating semantic distance, while the solution space is efficiently explored in a beam search fashion. The conducted experiments show the relevance of TIGTEC in terms of success rate, sparsity, diversity and plausibility. This method can be used in both model-specific or model-agnostic way, which makes it very convenient for generating counterfactual explanations.
    
[^28]: ChatGPT (2月13日版本)是一个中文房间

    ChatGPT (Feb 13 Version) is a Chinese Room. (arXiv:2304.12411v1 [cs.CL])

    [http://arxiv.org/abs/2304.12411](http://arxiv.org/abs/2304.12411)

    ChatGPT能通过各种专业和许可考试，但其当前版本更像是一个中文房间而非人工意识，存在严重的因果推理错误和不准确的回复。

    

    ChatGPT因能够通过各种专业和许可考试而引起了积极和消极的新闻报道。这表明ChatGPT可能在不久的将来通过图灵测试。然而，通过图灵测试的计算机程序既可以意味着它是一个中文房间，也可以意味着它是人工意识。因此，当前ChatGPT的状态更像是一个中文房间还是接近人工意识的问题仍存在。在这里，我证明了当前版本的ChatGPT（2月13日版本）是一个中文房间。尽管存在潜在的认知联系的证据，ChatGPT在因果推理方面存在严重错误。同时，我证明ChatGPT能够生成对同一问题的所有可能分类响应，并回复带有错误示例，因此质疑它作为学习工具的效用。我还展示了ChatGPT可以进行人工幻觉，这被定义为生成自信错误的回复。

    ChatGPT has gained both positive and negative publicity after reports suggesting that it is able to pass various professional and licensing examinations. This suggests that ChatGPT may pass Turing Test in the near future. However, a computer program that passing Turing Test can either mean that it is a Chinese Room or artificially conscious. Hence, the question of whether the current state of ChatGPT is more of a Chinese Room or approaching artificial consciousness remains. Here, I demonstrate that the current version of ChatGPT (Feb 13 version) is a Chinese Room. Despite potential evidence of cognitive connections, ChatGPT exhibits critical errors in causal reasoning. At the same time, I demonstrate that ChatGPT can generate all possible categorical responses to the same question and response with erroneous examples; thus, questioning its utility as a learning tool. I also show that ChatGPT is capable of artificial hallucination, which is defined as generating confidently wrong replie
    
[^29]: PEFT-Ref: 一种模块化的参考架构和类型，用于参数效率微调技术

    PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques. (arXiv:2304.12410v1 [cs.CL])

    [http://arxiv.org/abs/2304.12410](http://arxiv.org/abs/2304.12410)

    本文提出了PEFT-Ref参考架构，标准化了不同PEFT技术共享的方面，隔离了差异到特定位置和交互中，模块化的视图有助于比较不同技术及其效率和任务性能，并有助于更好地理解PEFT的基本原理。

    

    最近的参数效率微调(PEFT)技术旨在改善完全微调大型预训练语言模型(PLM)的高昂成本。随着不同的PEFT技术不断出现，对它们进行比较变得越来越困难，特别是在以下方面：(i)它们添加到PLM的结构和功能，(ii)不同类型和程度的效率改进，(iii)在不同的下游任务中的性能，以及(iv)结构和功能差异如何与效率和任务性能相关联。为了促进这样的比较，本文提出了一个参考框架，标准化了不同PEFT技术共享的方面，同时将差异隔离到与标准组件的特定位置和交互中。通过这个标准化和隔离差异的过程，出现了PEFT技术的模块化视图，不仅支持直接比较不同技术及其效率和任务性能，而且还有助于更好地理解PEFT的基本原理。所提出的参考架构称为PEFT-Ref，包括七个核心模块，每个模块都处理PEFT的特定方面，并可用作开发新PEFT技术和比较现有技术的指南。

    Recent parameter-efficient finetuning (PEFT) techniques aim to improve over the considerable cost of fully finetuning large pretrained language models (PLM). As different PEFT techniques proliferate, it is becoming difficult to compare them, in particular in terms of (i) the structure and functionality they add to the PLM, (ii) the different types and degrees of efficiency improvements achieved, (iii) performance at different downstream tasks, and (iv) how differences in structure and functionality relate to efficiency and task performance. To facilitate such comparisons, this paper presents a reference framework which standardises aspects shared by different PEFT techniques, while isolating differences to specific locations and interactions with the standard components. Through this process of standardising and isolating differences, a modular view of PEFT techniques emerges, supporting not only direct comparison of different techniques and their efficiency and task performance, but a
    
[^30]: 基于语义的标记器用于增强自然语言处理

    Semantic Tokenizer for Enhanced Natural Language Processing. (arXiv:2304.12404v1 [cs.CL])

    [http://arxiv.org/abs/2304.12404](http://arxiv.org/abs/2304.12404)

    本文提出一种基于语义的标记器，使用训练器来增强子词形成，优化和适应以最小化不能编码的单词数量。该标记器的复杂性超过了之前的两倍，但显着提高了NLP模型的收敛速度，并改善了单词和句子嵌入的质量。

    

    传统上，自然语言处理的性能改进一直集中于改进模型和增加模型参数数量。NLP词汇构建一直专注于通过子词规则最大化表示的单词数量。我们提出了一种利用语义引导词汇构建的新型标记器。标记器包括使用词干提取增强子词形成的训练器。进一步优化和适应被实现以最小化不能编码的单词数量。编码器被更新以与训练器集成。该标记器已被实现为SentencePiece标记器的替代品。新标记器的词形数量超过了之前的两倍。增强词汇显着提高了NLP模型的收敛速度，并改善了单词和句子嵌入的质量。我们的实验结果表明，在使用BERT-base的两个Glue任务中，我们的性能最佳，比其他模型提高了50倍以上。

    Traditionally, NLP performance improvement has been focused on improving models and increasing the number of model parameters. NLP vocabulary construction has remained focused on maximizing the number of words represented through subword regularization. We present a novel tokenizer that uses semantics to drive vocabulary construction. The tokenizer includes a trainer that uses stemming to enhance subword formation. Further optimizations and adaptations are implemented to minimize the number of words that cannot be encoded. The encoder is updated to integrate with the trainer. The tokenizer is implemented as a drop-in replacement for the SentencePiece tokenizer. The new tokenizer more than doubles the number of wordforms represented in the vocabulary. The enhanced vocabulary significantly improves NLP model convergence, and improves quality of word and sentence embeddings. Our experimental results show top performance on two Glue tasks using BERT-base, improving on models more than 50X 
    
[^31]: 论使用黑盒API进行毒性评估的挑战

    On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research. (arXiv:2304.12397v1 [cs.CL])

    [http://arxiv.org/abs/2304.12397](http://arxiv.org/abs/2304.12397)

    本文讨论使用黑盒API进行毒性评估的挑战，发现依赖继承的自动毒性评分可能导致不准确的结果，建议采用更加结构化的方法评估毒性随时间变化的模型和方法。

    

    对毒性的感知随时间推移而不断演变，而且在不同的地理和文化背景中往往存在差异。同样，用于检测毒性的商业黑盒API（例如Perspective API）也不是静态的，而经常重新训练以解决任何未被关注的弱点和偏见。我们评估了这些变化对比较旨在遏制毒性的模型和方法的相对优劣的研究发现的可重复性的影响。我们的发现表明，依赖继承的自动毒性评分来比较模型和技术的研究可能导致不准确的结果。重新对HELM的所有模型进行最新版本API的毒性评分，导致了广泛使用的基础模型的不同排名。我们建议在将研究之间进行马蜂拼接型比较时要谨慎，并为评估毒性随时间变化的更加有结构化的方法提出建议。代码和数据可在https://github.com/X/XXX上找到。

    Perception of toxicity evolves over time and often differs between geographies and cultural backgrounds. Similarly, black-box commercially available APIs for detecting toxicity, such as the Perspective API, are not static, but frequently retrained to address any unattended weaknesses and biases. We evaluate the implications of these changes on the reproducibility of findings that compare the relative merits of models and methods that aim to curb toxicity. Our findings suggest that research that relied on inherited automatic toxicity scores to compare models and techniques may have resulted in inaccurate findings. Rescoring all models from HELM, a widely respected living benchmark, for toxicity with the recent version of the API led to a different ranking of widely used foundation models. We suggest caution in applying apples-to-apples comparisons between studies and lay recommendations for a more structured approach to evaluating toxicity over time. Code and data are available at https
    
[^32]: 问题回答中的答案类型预测的极限分类

    Extreme Classification for Answer Type Prediction in Question Answering. (arXiv:2304.12395v1 [cs.CL])

    [http://arxiv.org/abs/2304.12395](http://arxiv.org/abs/2304.12395)

    本文提出了使用Transformer模型（XBERT）进行极端多标签分类，通过将KG类型基于问题文本使用结构和语义特征进行聚类，以提高问题回答（QA）系统中语义答案类型预测（SMART）任务的性能，并获得最先进的结果。

    

    语义答案类型预测（SMART）已被证明是有效的问题回答（QA）系统的有用步骤。 SMART任务涉及预测给定自然语言问题的前k个知识图（KG）类型。由于KG中存在大量类型，这是具有挑战性的。在本文中，我们提出使用Transformer模型（XBERT）进行极端多标签分类，通过将KG类型基于问题文本使用结构和语义特征进行聚类。我们具体地改善了XBERT流程的聚类阶段，利用从KG中派生的文本和结构特征。我们表明，这些特征可以提高SMART任务的端到端性能，并产生最先进的结果。

    Semantic answer type prediction (SMART) is known to be a useful step towards effective question answering (QA) systems. The SMART task involves predicting the top-$k$ knowledge graph (KG) types for a given natural language question. This is challenging due to the large number of types in KGs. In this paper, we propose use of extreme multi-label classification using Transformer models (XBERT) by clustering KG types using structural and semantic features based on question text. We specifically improve the clustering stage of the XBERT pipeline using textual and structural features derived from KGs. We show that these features can improve end-to-end performance for the SMART task, and yield state-of-the-art results.
    
[^33]: 低成本下更好的问答模型

    Better Question-Answering Models on a Budget. (arXiv:2304.12370v1 [cs.CL])

    [http://arxiv.org/abs/2304.12370](http://arxiv.org/abs/2304.12370)

    本文针对低成本下，提出了基于LoRA和Stanford Alpaca数据集的Eluwa模型系列，可大幅提高Facebook的OPT 1.3B、2.7B和6.7B模型的表现，40美元的计算成本即可让较小的模型具有和大3倍模型一样的性能表现。

    

    低秩适应（LoRA）和来自大型语言模型的问题-答案数据集使得更小的模型可以轻松地微调到具有复杂对话能力的程度。本文提出了Eluwa，一种使用Stanford Alpaca数据集的LoRA模型系列，可以大幅提升Facebook的OPT 1.3B、2.7B和6.7B模型的能力。我们通过多种方式进行了基准测试，包括让GPT-4评估它们对涵盖基础知识、写作、编程和其他任务的提示的回答。我们展示了在低成本下，较小的模型可以微调到和大3倍模型一样的性能表现，仅需40美元的计算成本。

    Low-rank adaptation (LoRA) and question-answer datasets from large language models have made it much easier for much smaller models to be finetuned to the point where they display sophisticated conversational abilities. In this paper, we present Eluwa, a family of LoRA models that use the Stanford Alpaca dataset and massively improve the capabilities of Facebook's OPT 1.3B, 2.7B and 6.7B models. We benchmark these models in multiple ways, including letting GPT-4 judge their answers to prompts that span general knowledge, writing, programming and other tasks. We show that smaller models here can be fine-tuned to be as performant as models 3x larger - all for as little as 40 USD in compute.
    
[^34]: USTEP: 基于演化树结构的在线日志解析方法

    USTEP: Structuration des logs en flux gr{\^a}ce {\`a} un arbre de recherche {\'e}volutif. (arXiv:2304.12331v1 [cs.CL])

    [http://arxiv.org/abs/2304.12331](http://arxiv.org/abs/2304.12331)

    本论文提出了一种基于演化树结构的在线日志解析方法USTEP，该方法在有效性和鲁棒性方面优越。

    

    运行时日志记录了有价值的系统信息。它们被广泛用于数据驱动的开发和监控目的。解析日志消息以结构化其格式是日志挖掘任务的经典预备步骤。由于它们出现在上游，解析操作可能成为下游应用程序的处理时间瓶颈。解析质量也直接影响其效率。本文提出了一种基于演化树结构的在线日志解析方法USTEP。对来自不同实际系统的广泛数据集的评估结果表明，与其他在线方法相比，USTEP在有效性和鲁棒性方面优越。

    Logs record valuable system information at runtime. They are widely used by data-driven approaches for development and monitoring purposes. Parsing log messages to structure their format is a classic preliminary step for log-mining tasks. As they appear upstream, parsing operations can become a processing time bottleneck for downstream applications. The quality of parsing also has a direct influence on their efficiency. Here, we propose USTEP, an online log parsing method based on an evolving tree structure. Evaluation results on a wide panel of datasets coming from different real-world systems demonstrate USTEP superiority in terms of both effectiveness and robustness when compared to other online methods.
    
[^35]: 通过识别桥接度重要节点生成Skip-gram节点嵌入的后续解释

    Generating Post-hoc Explanations for Skip-gram-based Node Embeddings by Identifying Important Nodes with Bridgeness. (arXiv:2304.12036v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.12036](http://arxiv.org/abs/2304.12036)

    本文提出了一种解释Skip-gram节点嵌入的方法，即通过计算桥接度识别重要节点，并提出了一种新型基于梯度的解释方法GRAPH-wGD，有效地提供全局性解释。

    

    网络中的节点表示学习是编码连续矢量空间中的关系信息同时保留网络固有属性和结构的重要机器学习技术。最近，DeepWalk、LINE、struc2vec、PTE、UserItem2vec和RWJBG等无监督节点嵌入方法从Skip-gram模型中出现，并在诸如节点分类和链接预测等下游任务中表现出更好的性能。然而，由于缺乏适用于嵌入的解释方法和理论研究，提供Skip-gram嵌入的后续解释仍然是一个具有挑战性的问题。本文首先表明可以通过在谱聚类感知局部扰动下计算桥接度来找到Skip-gram嵌入的全局解释。此外，还提出了一种名为GRAPH-wGD的新型基于梯度的解释方法，允许检索top-q全局性解释，并通过实验证明了其有效性。

    Node representation learning in a network is an important machine learning technique for encoding relational information in a continuous vector space while preserving the inherent properties and structures of the network. Recently, unsupervised node embedding methods such as DeepWalk, LINE, struc2vec, PTE, UserItem2vec, and RWJBG have emerged from the Skip-gram model and perform better performance in several downstream tasks such as node classification and link prediction than the existing relational models. However, providing post-hoc explanations of Skip-gram-based embeddings remains a challenging problem because of the lack of explanation methods and theoretical studies applicable for embeddings. In this paper, we first show that global explanations to the Skip-gram-based embeddings can be found by computing bridgeness under a spectral cluster-aware local perturbation. Moreover, a novel gradient-based explanation method, which we call GRAPH-wGD, is proposed that allows the top-q glo
    
[^36]: NAIST-SIC-Aligned：自动对齐的英日同声传译语料库

    NAIST-SIC-Aligned: Automatically-Aligned English-Japanese Simultaneous Interpretation Corpus. (arXiv:2304.11766v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.11766](http://arxiv.org/abs/2304.11766)

    本论文提出了NAIST-SIC-Aligned，这是一个自动对齐的英日平行同声传译数据集。该论文使用了一个两阶段的对齐方法，经过定量或定性验证的每个步骤，以确保语料库的质量。这是第一个开源的大规模平行SI数据集。

    

    如何利用同声传译（SI）数据来影响同声机器翻译（SiMT）仍然是一个问题。由于缺乏大规模的训练语料库，研究受到了限制。本文介绍了NAIST-SIC-Aligned，这是一个自动对齐的英日平行同声传译数据集。通过一个非对齐语料库NAIST-SIC开始，我们提出了一个两阶段对齐方法，使语料库具有平行性，从而适合模型训练。第一阶段是粗略对齐，在此步骤中，我们在源语言和目标语言之间执行一个多对多的映射；第二阶段是细粒度对齐，在此步骤中，我们执行语句内部和语句间过滤来提高对齐对的质量。为确保语料库的质量，每个步骤都经过了定量或定性的验证。这是文献中第一个开源的大规模平行SI数据集。我们还手动精选了一个小型测试集用于评估目的。

    It remains a question that how simultaneous interpretation (SI) data affects simultaneous machine translation (SiMT). Research has been limited due to the lack of a large-scale training corpus. In this work, we aim to fill in the gap by introducing NAIST-SIC-Aligned, which is an automatically-aligned parallel English-Japanese SI dataset. Starting with a non-aligned corpus NAIST-SIC, we propose a two-stage alignment approach to make the corpus parallel and thus suitable for model training. The first stage is coarse alignment where we perform a many-to-many mapping between source and target sentences, and the second stage is fine-grained alignment where we perform intra- and inter-sentence filtering to improve the quality of aligned pairs. To ensure the quality of the corpus, each step has been validated either quantitatively or qualitatively. This is the first open-sourced large-scale parallel SI dataset in the literature. We also manually curated a small test set for evaluation purpose
    
[^37]: 通过提示提高大型语言模型的心智理论表现

    Boosting Theory-of-Mind Performance in Large Language Models via Prompting. (arXiv:2304.11490v1 [cs.AI])

    [http://arxiv.org/abs/2304.11490](http://arxiv.org/abs/2304.11490)

    本研究通过提示提高大型语言模型（LLMs）在心智理论（ToM）任务上的表现，证明了上下文学习可以提升LLMs在复杂推理特别是ToM任务中的表现。

    

    2023年，大型语言模型（LLMs）在许多任务中表现出色，但在复杂推理方面仍面临挑战。心智理论（ToM）任务需要理解代理人的信念、目标和心理状态，对于涉及人类的常识推理至关重要，因此提高LLM在这方面的表现至关重要。本研究测量了GPT-4和三个GPT-3.5变体（Davinci-2、Davinci-3、GPT-3.5-Turbo）的ToM表现，并研究了上下文学习提高它们的ToM理解力的有效性。我们评估了包含两步思维推理和逐步思考说明的提示。我们发现，通过人类反馈的强化学习（RLHF）训练的LLMs（除Davinci-2外的所有模型）通过上下文学习提高了它们的ToM准确性。GPT-4在零轮情况下表现最佳，达到了近80%的ToM准确性，但仍不足测试集上87%的人类准确性。然而，当提供上下文学习的提示时，GPT-4和三个GPT-3.5变体的ToM准确性显著高于无提示时，其中表现最好的模型（GPT-3.5-Turbo）达到了92%的准确性。我们的研究展示了上下文学习提升LLM在复杂推理尤其是ToM任务中表现的潜力。

    Large language models (LLMs) excel in many tasks in 2023, but they still face challenges in complex reasoning. Theory-of-mind (ToM) tasks, which require understanding agents' beliefs, goals, and mental states, are essential for common-sense reasoning involving humans, making it crucial to enhance LLM performance in this area. This study measures the ToM performance of GPT-4 and three GPT-3.5 variants (Davinci-2, Davinci-3, GPT-3.5-Turbo), and investigates the effectiveness of in-context learning in improving their ToM comprehension. We evaluated prompts featuring two-shot chain of thought reasoning and step-by-step thinking instructions. We found that LLMs trained with Reinforcement Learning from Human Feedback (RLHF) (all models excluding Davinci-2) improved their ToM accuracy via in-context learning. GPT-4 performed best in zero-shot settings, reaching nearly 80% ToM accuracy, but still fell short of the 87% human accuracy on the test set. However, when supplied with prompts for in-c
    
[^38]: UBC-DLNLP在SemEval-2023任务12中的贡献：转移学习对非洲情感分析的影响

    UBC-DLNLP at SemEval-2023 Task 12: Impact of Transfer Learning on African Sentiment Analysis. (arXiv:2304.11256v1 [cs.CL])

    [http://arxiv.org/abs/2304.11256](http://arxiv.org/abs/2304.11256)

    该研究旨在解决非洲14个不同语言的情感分析任务，使用转移学习的方法，并取得了不错的成果，可应用于其他语言的情感分析任务。

    

    我们描述了我们在SemEval 2023 AfriSenti-SemEval共享任务中的贡献，其中我们解决了14种不同非洲语言的情感分析任务。我们在完全监督的条件下开发了单语和多语模型（子任务A和B）。我们还为零-shot设置（子任务C）开发了模型。我们的方法涉及使用六种语言模型进行转移学习的实验，包括一些模型的进一步调整以及最后的微调阶段。我们效果最好的模型在开发数据上实现了70.36的F1分数，在测试数据上实现了66.13的F1分数。我们的结果表明了跨多种语言的情感分析中，转移学习和微调技术的有效性。我们的方法可以应用于不同语言和领域的其他情感分析任务。

    We describe our contribution to the SemEVAl 2023 AfriSenti-SemEval shared task, where we tackle the task of sentiment analysis in 14 different African languages. We develop both monolingual and multilingual models under a full supervised setting (subtasks A and B). We also develop models for the zero-shot setting (subtask C). Our approach involves experimenting with transfer learning using six language models, including further pertaining of some of these models as well as a final finetuning stage. Our best performing models achieve an F1-score of 70.36 on development data and an F1-score of 66.13 on test data. Unsurprisingly, our results demonstrate the effectiveness of transfer learning and fine-tuning techniques for sentiment analysis across multiple languages. Our approach can be applied to other sentiment analysis tasks in different languages and domains.
    
[^39]: 学习“不学习”: 朝向聊天机器人中的生成安全

    Learn What NOT to Learn: Towards Generative Safety in Chatbots. (arXiv:2304.11220v1 [cs.CL])

    [http://arxiv.org/abs/2304.11220](http://arxiv.org/abs/2304.11220)

    本文提出了一种名为“LOT”的框架，采用对比损失训练聊天机器人以从正面和负面训练信号中增强泛化能力，并使用离散度将生成向量从不安全子空间指向安全子空间，从而避免生成不安全的内容。

    

    生成式、开放领域的对话模型尤其容易生成不安全的内容，因为它们是在基于Web的社交数据上训练的。先前缓解这个问题的方法存在缺点，如打断对话流程、对未见过的有毒输入环境的泛化能力不强、为了安全而牺牲对话质量等。在本文中，我们提出了一种新颖的框架，称为“LOT”（Learn NOT to），它采用对比损失来增强泛化能力，通过同时从正面和负面训练信号中学习来做到这一点。相较于标准的对比学习框架，我们的方法从先前学习的安全和不安全语言分布中自动获得正、负信号。LOT框架利用离散度将生成向量从不安全子空间指向安全子空间，同时维持对话的流程。我们的方法内存和时间效率高，在SafeDialog数据集上实现了最先进的性能。

    Conversational models that are generative and open-domain are particularly susceptible to generating unsafe content since they are trained on web-based social data. Prior approaches to mitigating this issue have drawbacks, such as disrupting the flow of conversation, limited generalization to unseen toxic input contexts, and sacrificing the quality of the dialogue for the sake of safety. In this paper, we present a novel framework, named "LOT" (Learn NOT to), that employs a contrastive loss to enhance generalization by learning from both positive and negative training signals. Our approach differs from the standard contrastive learning framework in that it automatically obtains positive and negative signals from the safe and unsafe language distributions that have been learned beforehand. The LOT framework utilizes divergence to steer the generations away from the unsafe subspace and towards the safe subspace while sustaining the flow of conversation. Our approach is memory and time-ef
    
[^40]: CB-Conformer: 针对偏差词识别的语境偏差Conformer

    CB-Conformer: Contextual biasing Conformer for biased word recognition. (arXiv:2304.09607v1 [cs.SD])

    [http://arxiv.org/abs/2304.09607](http://arxiv.org/abs/2304.09607)

    CB-Conformer 是一种为了提高有偏差词识别而提出的 Conformer，引入了 Contextual Biasing Module 和 Self-Adaptive Language Model 以更好地利用上下文信息和单词偏差信息，并在测试中取得显著提高。

    

    由于源域和目标域之间的差异，如何更好地利用有偏差的单词信息来提高目标领域中自动语音识别模型的性能成为一个热门研究话题。以前的方法要么使用固定的外部语言模型进行解码，要么引入一个庞大的偏差模块，导致适应性差，推理速度慢。在本研究中，我们提出了CB-Conformer，通过引入上下文偏差模块和自适应语言模型来改进有偏差的单词识别。上下文偏差模块将音频片段和上下文信息组合起来，仅有原始Conformer模型参数的0.2％。自适应语言模型根据有偏差的单词召回率和精确度修改其内部权重，使得自动语音识别模型更关注有偏差的单词，并比标准的固定语言模型更成功地集成。此外，我们在语音识别基准测试中对模型进行了评估，包括领域内和领域外的测试集，发现显著提高了成绩。

    Due to the mismatch between the source and target domains, how to better utilize the biased word information to improve the performance of the automatic speech recognition model in the target domain becomes a hot research topic. Previous approaches either decode with a fixed external language model or introduce a sizeable biasing module, which leads to poor adaptability and slow inference. In this work, we propose CB-Conformer to improve biased word recognition by introducing the Contextual Biasing Module and the Self-Adaptive Language Model to vanilla Conformer. The Contextual Biasing Module combines audio fragments and contextual information, with only 0.2% model parameters of the original Conformer. The Self-Adaptive Language Model modifies the internal weights of biased words based on their recall and precision, resulting in a greater focus on biased words and more successful integration with the automatic speech recognition model than the standard fixed language model. In addition
    
[^41]: 通过模块化线性化注意力机制改进自回归自然语言处理任务

    Improving Autoregressive NLP Tasks via Modular Linearized Attention. (arXiv:2304.08453v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08453](http://arxiv.org/abs/2304.08453)

    本文提出模块化线性化注意力机制（MLA）以最大化推理质量并实现速度提升，并在多个自回归自然语言处理任务上验证了该方法，包括语音到文本神经机器翻译（S2T NMT）、语音到文本同声传译（SimulST）和自回归文本到频谱图任务，在TTS上具有高效率收益，在NMT和SimulST的训练和推理过程中表现出竞争性能。

    

    多种自然语言处理任务需要的模型必须在最终应用于边缘或其他资源受限制的环境中高效且小型。尽管先前的研究已将这些模型的大小减小，但在不影响性能的前提下提高计算效率仍然很困难，特别是对于自回归任务而言。本文提出了一种模块化线性化注意力机制（MLA），它结合了多个有效的注意力机制，包括cosFormer，以最大化推理质量并实现显着的速度提升。我们在几个自回归自然语言处理任务上验证了这种方法，包括语音到文本神经机器翻译（S2T NMT）、语音到文本同声传译（SimulST）和自回归文本到频谱图任务，在TTS上具有高效率收益，在NMT和SimulST的训练和推理过程中表现出竞争性能。

    Various natural language processing (NLP) tasks necessitate models that are efficient and small based on their ultimate application at the edge or in other resource-constrained environments. While prior research has reduced the size of these models, increasing computational efficiency without considerable performance impacts remains difficult, especially for autoregressive tasks. This paper proposes {modular linearized attention (MLA), which combines multiple efficient attention mechanisms, including cosFormer, to maximize inference quality while achieving notable speedups. We validate this approach on several autoregressive NLP tasks, including speech-to-text neural machine translation (S2T NMT), speech-to-text simultaneous translation (SimulST), and autoregressive text-to-spectrogram, noting efficiency gains on TTS and competitive performance for NMT and SimulST during training and inference.
    
[^42]: 中文开放式指令广义语言模型：初步发布

    Chinese Open Instruction Generalist: A Preliminary Release. (arXiv:2304.07987v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.07987](http://arxiv.org/abs/2304.07987)

    本论文旨在通过适应不同子任务的固有特性，创建一个中文指令数据集，以填补指令调整技术在中文语言领域的空白。

    

    指令调整被广泛认为是构建广义语言模型的关键技术，随着InstructGPT和ChatGPT的发布，它已经引起了研究人员和公众的关注。尽管英语为基础的大规模语言模型取得了令人瞩目的进展，但是还未探索英语为基础的语言模型在多语任务上是否可以像英语任务那样通过精心设计的指令调整来执行，以及我们如何构建所需的语料库进行调整。为填补这一空白，我们提出了一个项目，试图通过适应4个子任务的固有特性，采用各种方法创建一个中文指令数据集。我们收集了约20万个中文指令调整样本，并进行了人工检查以确保高质量。我们还总结了现有的英文和中文指令语料库，并对一些潜在的应用进行了简要描述。

    Instruction tuning is widely recognized as a key technique for building generalist language models, which has attracted the attention of researchers and the public with the release of InstructGPT~\citep{ouyang2022training} and ChatGPT\footnote{\url{https://chat.openai.com/}}. Despite impressive progress in English-oriented large-scale language models (LLMs), it is still under-explored whether English-based foundation LLMs can perform similarly on multilingual tasks compared to English tasks with well-designed instruction tuning and how we can construct the corpora needed for the tuning.  To remedy this gap, we propose the project as an attempt to create a Chinese instruction dataset by various methods adapted to the intrinsic characteristics of 4 sub-tasks. We collect around 200k Chinese instruction tuning samples, which have been manually checked to guarantee high quality. We also summarize the existing English and Chinese instruction corpora and briefly describe some potential applic
    
[^43]: 针对鲁棒语音翻译的选择性数据增强

    Selective Data Augmentation for Robust Speech Translation. (arXiv:2304.03169v1 [cs.CL])

    [http://arxiv.org/abs/2304.03169](http://arxiv.org/abs/2304.03169)

    本文提出了一种针对英印ST的e2e架构，同时将两个不完美的机器翻译服务用于生成并行数据，并且提出了一种数据增强策略以提高鲁棒性，结果呈现出比基准方法更好的性能。

    

    语音翻译系统将一种语言的语音转化为另一种语言的文字。端到端（e2e）语音翻译系统由于具有减少延迟和计算成本的优越性能而比串联系统受到欢迎。虽然资源密集型，但e2e-ST系统具有保留语音的参数和非语言特征的内在能力，与串联系统不同。本文提出使用e2e架构来进行英印（en-hi）ST。我们使用两个不完美的机器翻译服务将Libri-trans en文本翻译成hi文本。虽然每个服务都会单独提供MT数据以生成并行ST数据，但我们提出了一种噪声MT数据的数据增强策略来帮助鲁棒ST。本文的主要贡献是提出了一种数据增强策略。我们表明，这导致比强力MT数据增强更好的ST（BLEU得分）。我们观察到我们的方法比基准方法提高了1.59 BLEU得分。

    Speech translation (ST) systems translate speech in one language to text in another language. End-to-end ST systems (e2e-ST) have gained popularity over cascade systems because of their enhanced performance due to reduced latency and computational cost. Though resource intensive, e2e-ST systems have the inherent ability to retain para and non-linguistic characteristics of the speech unlike cascade systems. In this paper, we propose to use an e2e architecture for English-Hindi (en-hi) ST. We use two imperfect machine translation (MT) services to translate Libri-trans en text into hi text. While each service gives MT data individually to generate parallel ST data, we propose a data augmentation strategy of noisy MT data to aid robust ST. The main contribution of this paper is the proposal of a data augmentation strategy. We show that this results in better ST (BLEU score) compared to brute force augmentation of MT data. We observed an absolute improvement of 1.59 BLEU score with our appr
    
[^44]: 法律文件页面的上下文感知分类

    Context-Aware Classification of Legal Document Pages. (arXiv:2304.02787v1 [cs.CL])

    [http://arxiv.org/abs/2304.02787](http://arxiv.org/abs/2304.02787)

    本文提出一种新方法，使用额外的标记增强输入，引入循环，可以使用预训练的 Transformer 模型（如 BERT）进行上下文感知的法律文件页面分类。

    

    对于许多需要处理、索引和检索专业文档（如 PDF 格式等）的商业应用，将任何给定文档的页面分类为其相应类型通常是必要的。文档图像分类领域中大多数现有研究要么专注于单页文档，要么将文档中的多个页面独立处理。虽然近年来已经提出了一些技术来利用相邻页面的上下文信息来增强文档页面分类，但由于输入长度的限制，它们通常不能与大型预训练语言模型一起使用。本文提出了一种简单但有效的方法，克服了上述限制。具体而言，我们使用带有关于前一页的顺序信息的额外标记来增强输入，从而引入了循环，这使得可以使用预训练的 Transformer 模型（如 BERT）进行上下文感知的法律文件页面分类。

    For many business applications that require the processing, indexing, and retrieval of professional documents such as legal briefs (in PDF format etc.), it is often essential to classify the pages of any given document into their corresponding types beforehand. Most existing studies in the field of document image classification either focus on single-page documents or treat multiple pages in a document independently. Although in recent years a few techniques have been proposed to exploit the context information from neighboring pages to enhance document page classification, they typically cannot be utilized with large pre-trained language models due to the constraint on input length. In this paper, we present a simple but effective approach that overcomes the above limitation. Specifically, we enhance the input with extra tokens carrying sequential information about previous pages - introducing recurrence - which enables the usage of pre-trained Transformer models like BERT for context
    
[^45]: 基于重排的后训练量化方法在大型语言模型中的应用

    RPTQ: Reorder-based Post-training Quantization for Large Language Models. (arXiv:2304.01089v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.01089](http://arxiv.org/abs/2304.01089)

    本研究提出了一种新的基于重排的量化方法RPTQ，目的是解决大型语言模型在量化时由于信道激活范围不同而产生的问题。实现该方法后，我们将LLL模型推动到3位激活。

    

    大型语言模型在各种任务上表现出色，但由于其巨大的模型大小而引发的部署挑战。本文指出，LLL模型量化的主要难点在于信道之间不同的激活范围，而不仅仅是离群值问题。我们提出了一种新颖的基于重排的量化方法RPTQ，用于解决LLL模型量化问题。RPTQ通过重新排列激活中的信道，并按簇量化信道，从而减少信道范围差异的影响。此外，我们通过避免显式重排减少存储和计算开销。实现了该方法后，我们首次将LLL模型推动到3位激活。

    Large-scale language models (LLMs) have demonstrated outstanding performance on various tasks, but their deployment poses challenges due to their enormous model size. In this paper, we identify that the main challenge in quantizing LLMs stems from the different activation ranges between the channels, rather than just the issue of outliers.We propose a novel reorder-based quantization approach, RPTQ, that addresses the issue of quantizing the activations of LLMs. RPTQ rearranges the channels in the activations and then quantizing them in clusters, thereby reducing the impact of range difference of channels. In addition, we reduce the storage and computation overhead by avoiding explicit reordering. By implementing this approach, we achieved a significant breakthrough by pushing LLM models to 3 bit activation for the first time.
    
[^46]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^47]: ChatGPT作为自然语言生成的评价指标可靠吗？初步研究。

    Is ChatGPT a Good NLG Evaluator? A Preliminary Study. (arXiv:2303.04048v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04048](http://arxiv.org/abs/2303.04048)

    通过针对任务特定和方面特定，我们在五个NLG元评估数据集上进行实验，表明ChatGPT作为NLG评估指标并不总是与人类评估相一致，尤其是在流畅度方面。这提醒人们在使用ChatGPT作为唯一的自动NLG评估指标时要谨慎。

    

    最近，ChatGPT的出现引起了计算语言学界的广泛关注。许多先前的研究表明，ChatGPT在各种NLP任务中以自动评估指标为基础获得了显着的性能。然而，ChatGPT作为一种评估指标的能力尚未得到充分探索。考虑到评估自然语言生成（NLG）模型的质量是一项艰巨的任务，并且NLG指标以其糟糕的与人类判断的相关性而闻名，因此我们是否会认为ChatGPT是一个好的NLG评估指标。在这篇报告中，我们对ChatGPT进行了初步的元评估，展示了ChatGPT作为NLG指标的可靠性。具体而言，我们将ChatGPT视为人类评估器，并针对任务特定（例如摘要）和方面特定（例如相关性）进行说明，以促使ChatGPT评估NLG模型的生成结果。我们在包括摘要、故事生成和翻译在内的五个NLG元评估数据集上进行实验。我们的结果表明，对于某些方面（例如流畅度），ChatGPT并不总是与人类评估相一致。这提醒人们在使用ChatGPT作为唯一的自动NLG评估指标时要谨慎。

    Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community. Many prior studies have shown that ChatGPT achieves remarkable performance on various NLP tasks in terms of automatic evaluation metrics. However, the ability of ChatGPT to serve as an evaluation metric is still underexplored. Considering assessing the quality of natural language generation (NLG) models is an arduous task and NLG metrics notoriously show their poor correlation with human judgments, we wonder whether ChatGPT is a good NLG evaluation metric. In this report, we provide a preliminary meta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT as a human evaluator and give task-specific (e.g., summarization) and aspect-specific (e.g., relevance) instruction to prompt ChatGPT to evaluate the generated results of NLG models. We conduct experiments on five NLG meta-evaluation datasets (including summarization, story generation and 
    
[^48]: Hitachi在SemEval-2023任务3中的表现：探索跨语言多任务策略，用于在线新闻中的流派和框架检测

    Hitachi at SemEval-2023 Task 3: Exploring Cross-lingual Multi-task Strategies for Genre and Framing Detection in Online News. (arXiv:2303.01794v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.01794](http://arxiv.org/abs/2303.01794)

    Hitachi团队参加SemEval-2023第3项任务，研究了跨语言和多任务策略，表明跨语言/多任务训练和收集外部平衡数据集可以有益于流派和框架检测，在意大利语和俄语流派分类子任务中实现了最高的宏平均F1分数。

    

    本文介绍了Hitachi团队参加SemEval-2023第3项任务“在多语言设置中检测在线新闻中的流派、框架和说服技巧”的情况。鉴于任务的多语言、多任务性质和低资源环境，我们研究了不同的跨语言和多任务策略，以训练预训练语言模型。通过广泛的实验，我们发现(a)跨语言/多任务训练，以及(b)收集外部平衡数据集，可以有益于流派和框架检测。我们从结果构建了集成模型，并在意大利语和俄语流派分类子任务中实现了最高的宏平均F1分数。

    This paper explains the participation of team Hitachi to SemEval-2023 Task 3 "Detecting the genre, the framing, and the persuasion techniques in online news in a multi-lingual setup.'' Based on the multilingual, multi-task nature of the task and the low-resource setting, we investigated different cross-lingual and multi-task strategies for training the pretrained language models. Through extensive experiments, we found that (a) cross-lingual/multi-task training, and (b) collecting an external balanced dataset, can benefit the genre and framing detection. We constructed ensemble models from the results and achieved the highest macro-averaged F1 scores in Italian and Russian genre categorization subtasks.
    
[^49]: 穷人的质量评估：在没有参考的情况下预测基于参考的机器翻译度量

    Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics Without the Reference. (arXiv:2301.09008v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.09008](http://arxiv.org/abs/2301.09008)

    该论文提出了一个质量评估的问题，叫做Metric Estimation，它能够在没有参考翻译的情况下，预测自动化评估度量，同时解决了人工注释费时费力的问题。

    

    机器翻译质量评估（QE）是在不查看参考文献的情况下预测翻译假设的人类判断的方法。基于预先训练的语言模型的最先进QE系统正在实现与人类判断的显着相关性，但它们的计算量大并且需要人类注释，这些注释需要耗费时间和资金。为了解决这些限制，我们定义了指标估计（ME）问题，其中预测自动化度量分数，同样也没有参考文献。我们展示了，即使没有参考文献，我们的模型也能在句子级别上估计自动化度量（$ \rho = 60 \% $对于BLEU，$ \rho = 51 \% $对于其他度量）。因为自动化度量与人类评估相关，我们可以利用ME任务为预训练QE模型服务。对于QE任务，我们发现在TER上进行预训练（$ \rho = 23 \% $）比从头开始训练（$ \rho = 20 \% $）更好。

    Machine translation quality estimation (QE) predicts human judgements of a translation hypothesis without seeing the reference. State-of-the-art QE systems based on pretrained language models have been achieving remarkable correlations with human judgements yet they are computationally heavy and require human annotations, which are slow and expensive to create. To address these limitations, we define the problem of metric estimation (ME) where one predicts the automated metric scores also without the reference. We show that even without access to the reference, our model can estimate automated metrics ($\rho$=60% for BLEU, $\rho$=51% for other metrics) at the sentence-level. Because automated metrics correlate with human judgements, we can leverage the ME task for pre-training a QE model. For the QE task, we find that pre-training on TER is better ($\rho$=23%) than training for scratch ($\rho$=20%).
    
[^50]: InferEM: 推断说话者意图的共情对话生成模型

    InferEM: Inferring the Speaker's Intention for Empathetic Dialogue Generation. (arXiv:2212.06373v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.06373](http://arxiv.org/abs/2212.06373)

    通过推断对话中最后一次发言来捕捉说话者的意图，提出了一种利用多头注意力的意图融合模块的共情对话生成模型InferEM。模型同时利用前几次发言预测最后一次发言，具有较高的可行性。

    

    目前，共情回复生成的方法一般直接编码整个对话历史，然后通过解码器生成友好的反馈。这些方法强调建模情境信息，但忽视了捕捉说话者的直接意图。我们认为对话中最后一次发言表达了说话者的意图。因此，我们提出了一种名为InferEM的新模型用于共情回复生成。我们将最后一次发言单独编码，通过基于多头注意力的意图融合模块与整个对话融合以捕捉说话者的意图。此外，我们利用前几次发言预测最后一次发言，以模拟人类的心理，猜测对话者可能提前说些什么。为平衡发言预测和回复生成的优化速率，InferEM还设计了一种多任务学习策略。实验结果证明了该模型的可行性。

    Current approaches to empathetic response generation typically encode the entire dialogue history directly and put the output into a decoder to generate friendly feedback. These methods focus on modelling contextual information but neglect capturing the direct intention of the speaker. We argue that the last utterance in the dialogue empirically conveys the intention of the speaker. Consequently, we propose a novel model named InferEM for empathetic response generation. We separately encode the last utterance and fuse it with the entire dialogue through the multi-head attention based intention fusion module to capture the speaker's intention. Besides, we utilize previous utterances to predict the last utterance, which simulates human's psychology to guess what the interlocutor may speak in advance. To balance the optimizing rates of the utterance prediction and response generation, a multi-task learning strategy is designed for InferEM. Experimental results demonstrate the plausibility
    
[^51]: 基于关系感知的语言图转换器用于问答

    Relation-Aware Language-Graph Transformer for Question Answering. (arXiv:2212.00975v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.00975](http://arxiv.org/abs/2212.00975)

    本论文提出了关系感知语言图转换器，能够以统一的方式联合推理语言和图关于实体关系，并在多个QA数据集上验证了其有效性。

    

    问答是一项需要推理自然语言环境的任务，许多相关工作通过图神经网络(GNN)增强语言模型(LM)，以对知识图谱(KG)信息进行编码。然而，大多数现有的面向问答的基于GNN的模块并未利用KG的丰富关系信息，并且依赖于LM和KG之间的有限信息交互。为了解决这些问题，我们提出了 Question Answering Transformer(QAT)，它旨在以统一的方式联合推理语言和图关于实体关系。具体而言，QAT构建了元路径令牌，这些令牌学习基于不同的结构和语义关系的关系中心嵌入。然后，我们的关系感知自注意力模块通过跨模态相关位置偏差全面整合了不同的模态，以指导不同模态之间相关实体的信息交换。我们验证了QAT在多个QA数据集上的有效性。

    Question Answering (QA) is a task that entails reasoning over natural language contexts, and many relevant works augment language models (LMs) with graph neural networks (GNNs) to encode the Knowledge Graph (KG) information. However, most existing GNN-based modules for QA do not take advantage of rich relational information of KGs and depend on limited information interaction between the LM and the KG. To address these issues, we propose Question Answering Transformer (QAT), which is designed to jointly reason over language and graphs with respect to entity relations in a unified manner. Specifically, QAT constructs Meta-Path tokens, which learn relation-centric embeddings based on diverse structural and semantic relations. Then, our Relation-Aware Self-Attention module comprehensively integrates different modalities via the Cross-Modal Relative Position Bias, which guides information exchange between relevant entites of different modalities. We validate the effectiveness of QAT on com
    
[^52]: StructDiffusion：使用未知对象进行物理有效结构的语言指导创建

    StructDiffusion: Language-Guided Creation of Physically-Valid Structures using Unseen Objects. (arXiv:2211.04604v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.04604](http://arxiv.org/abs/2211.04604)

    本论文提出了一种结合扩散模型和以物体为中心的转换器的方法，通过高层语言目标和局部视点云构建物理有效的结构，该方法可用于多个具有挑战性的多步骤3D规划任务，即使使用未知对象仍能提高成功率。

    

    在人类环境中运作的机器人必须能够将物体重新排列成语义有意义的配置，即使这些物体以前没见过。本文关注如何在无需逐步指令的情况下构建物理有效的结构。我们提出了StructDiffusion，该方法结合了扩散模型和以物体为中心的转换器，根据局部视点云和高级语言目标（如“摆桌子”），构建结构。我们的方法可以使用一个模型执行多个具有挑战性的语言条件的多步骤3D规划任务。与训练在特定结构上的现有多模态转换器模型相比，StructDiffusion甚至提高了将未知对象组装成物理有效结构的成功率，平均可提高16％。我们展示了模拟和实际重新排列任务中使用保留对象的实验。重要的是，我们展示了如何将扩散模型和碰撞鉴别器模型结合起来，以实现对拟合性以及对语言指导物理有效结构构建任务的影响。

    Robots operating in human environments must be able to rearrange objects into semantically-meaningful configurations, even if these objects are previously unseen. In this work, we focus on the problem of building physically-valid structures without step-by-step instructions. We propose StructDiffusion, which combines a diffusion model and an object-centric transformer to construct structures given partial-view point clouds and high-level language goals, such as "set the table". Our method can perform multiple challenging language-conditioned multi-step 3D planning tasks using one model. StructDiffusion even improves the success rate of assembling physically-valid structures out of unseen objects by on average 16% over an existing multi-modal transformer model trained on specific structures. We show experiments on held-out objects in both simulation and on real-world rearrangement tasks. Importantly, we show how integrating both a diffusion model and a collision-discriminator model allo
    
[^53]: 使用LLM来增强可解释模型的训练

    Augmenting Interpretable Models with LLMs during Training. (arXiv:2209.11799v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.11799](http://arxiv.org/abs/2209.11799)

    本文提出了 Aug-imodels 框架，利用 LLMs 的知识在拟合过程中构建高效且可解释的模型，在推理过程中不使用 LLMs，具备完全的透明性。研究探讨了两种不同方式的实现，并在多种文本分类数据集中表现出优异的效果。

    

    近期，大型语言模型（LLMs）在越来越多的任务中表现出了出色的表现。然而，它们进入高风险领域（例如医学）和计算资源有限的环境中，对解释性和效率的需求日益增加。我们提出了增强可解释模型（Aug-imodels）框架，利用LLMs所学习的知识建立极其高效且可解释的模型。Aug-imodels在拟合过程中使用LLMs，但在推理过程中不使用，从而实现了完全的透明性，并且与LLMs相比，推理速度和内存性能有了大于1000倍的提高。我们探讨了两种Aug-imodels在自然语言处理中的具体实例：（i）Aug-GAM，它使用来自LLM的解耦嵌入来增强广义加性模型；（ii）Aug-Tree，它通过LLM特征扩展来增强决策树。在各种文本分类数据集中，这两种方法都优于其未增强的对照模型。

    Recent large language models (LLMs) have demonstrated remarkable prediction performance for a growing array of tasks. However, their proliferation into high-stakes domains (e.g. medicine) and compute-limited settings has created a burgeoning need for interpretability and efficiency. We address this need by proposing Augmented Interpretable Models (Aug-imodels), a framework for leveraging the knowledge learned by LLMs to build extremely efficient and interpretable models. Aug-imodels use LLMs during fitting but not during inference, allowing complete transparency and often a speed/memory improvement of greater than 1,000x for inference compared to LLMs. We explore two instantiations of Aug-imodels in natural-language processing: (i) Aug-GAM, which augments a generalized additive model with decoupled embeddings from an LLM and (ii) Aug-Tree, which augments a decision tree with LLM feature expansions. Across a variety of text-classification datasets, both outperform their non-augmented co
    
[^54]: 抽象会议摘要：一项调查

    Abstractive Meeting Summarization: A Survey. (arXiv:2208.04163v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.04163](http://arxiv.org/abs/2208.04163)

    本文提供了对抽象会议摘要的调查，介绍了数据集、模型和评估指标，并表明这种摘要形式在多方谈话中尤其有用。

    

    一种可靠地识别和总结谈话中最重要的要点的系统将在广泛的现实世界背景下具有价值，从商业会议到医疗咨询到客户服务呼叫。最近深度学习方面的进展，特别是编码器-解码器架构的发明，显著改善了语言生成系统，为提高抽象概括的形式开了一扇门，这种形式的概括尤其适合多方谈话。本文提供了抽象会议摘要任务所引起的挑战的概述，以及用于解决这些问题的数据集、模型和评估指标。

    A system that could reliably identify and sum up the most important points of a conversation would be valuable in a wide variety of real-world contexts, from business meetings to medical consultations to customer service calls. Recent advances in deep learning, and especially the invention of encoder-decoder architectures, has significantly improved language generation systems, opening the door to improved forms of abstractive summarization, a form of summarization particularly well-suited for multi-party conversation. In this paper, we provide an overview of the challenges raised by the task of abstractive meeting summarization and of the data sets, models and evaluation metrics that have been used to tackle the problems.
    
[^55]: 预测Twitter对话线程中的仇恨强度

    Predicting Hate Intensity of Twitter Conversation Threads. (arXiv:2206.08406v3 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2206.08406](http://arxiv.org/abs/2206.08406)

    本文提出了DRAGNET++, 通过考虑对话线程的语义、传播结构和用户交互，以预测推文的回复链中可能存在的仇恨程度，并在两个公开数据集上的实验中表现出优越性能。该模型可为社交媒体平台提供在恶意对话升级之前识别和管理的工具。

    

    推文是在线社交媒体中最简洁的交流形式，一条推文有可能是对话中打造或破坏讨论的潜在媒介。在线仇恨言论比以往任何时候都更容易获得，阻止其传播对于社交媒体公司和用户来说是极为重要的，可以推进良好的交流方式。目前除了最近的一些研究外，大部分研究都专注于分类单个推文，而忽略了推文之间的对话线程/上下文。我们提出了DRAGNET++，旨在通过推文的回复链预测它可能带来的仇恨程度，同时考虑到对话线程的语义和传播结构以及线程中的用户交互。我们在两个公开数据集上的实验表明DRAGNET++的表现优于现有的方法，我们认为社交媒体平台可以利用我们提出的方法，预测和管理恶意对话。

    Tweets are the most concise form of communication in online social media, wherein a single tweet has the potential to make or break the discourse of the conversation. Online hate speech is more accessible than ever, and stifling its propagation is of utmost importance for social media companies and users for congenial communication. Most of the research barring a recent few has focused on classifying an individual tweet regardless of the tweet thread/context leading up to that point. One of the classical approaches to curb hate speech is to adopt a reactive strategy after the hate speech postage. The ex-post facto strategy results in neglecting subtle posts that do not show the potential to instigate hate speech on their own but may portend in the subsequent discussion ensuing in the post's replies. In this paper, we propose DRAGNET++, which aims to predict the intensity of hatred that a tweet can bring in through its reply chain in the future. It uses the semantic and propagating stru
    
[^56]: 在抽象化摘要中权衡抽象性和事实性的评估

    Evaluating the Tradeoff Between Abstractiveness and Factuality in Abstractive Summarization. (arXiv:2108.02859v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2108.02859](http://arxiv.org/abs/2108.02859)

    本文分析了抽象化摘要中抽象性和事实性之间的权衡，并引入了两个包含人类事实判断的数据集。研究表明，虽然抽象性的增加通常会导致事实性的下降，但事实性的衰减率取决于系统的训练数据等因素。同时，新的事实度指标可以调整抽象程度的程度，弥补事实性的不足。

    

    抽象化摘要的神经模型往往会生成流畅而形式良好的输出，但与输入文档的语义忠实度或事实性不一致。在本文中，我们使用对事实性的人类评估，分析了多个数据集和模型生成的摘要中抽象性和事实性之间的权衡。在我们的分析中，我们使用解码约束逐渐增加抽象性，可视化了事实性的变化率，并观察到，虽然抽象性的增加通常会导致事实性的下降，但事实性的衰减率取决于系统的训练数据等因素。我们引入了两个包含人类事实判断的数据集；一个包含10.2k个生成的摘要，具有系统地变化的抽象程度；另一个包含来自五个不同摘要模型的4.2k个摘要。我们提出了新的事实度指标，调整了抽象程度的程度。

    Neural models for abstractive summarization tend to generate output that is fluent and well-formed but lacks semantic faithfulness, or factuality, with respect to the input documents. In this paper, we analyze the tradeoff between abstractiveness and factuality of generated summaries across multiple datasets and models, using extensive human evaluations of factuality. In our analysis, we visualize the rates of change in factuality as we gradually increase abstractiveness using a decoding constraint, and we observe that, while increased abstractiveness generally leads to a drop in factuality, the rate of factuality decay depends on factors such as the data that the system was trained on. We introduce two datasets with human factuality judgements; one containing 10.2k generated summaries with systematically varied degrees of abstractiveness; the other containing 4.2k summaries from five different summarization models. We propose new factuality metrics that adjust for the degree of abstra
    

