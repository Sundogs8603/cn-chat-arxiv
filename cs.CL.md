# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [CFGPT: Chinese Financial Assistant with Large Language Model.](http://arxiv.org/abs/2309.10654) | CFGPT是一个具有大型语言模型的中国金融助手，包括CFData用于预训练和监督微调，以及CFLLM用于处理金融文本，CFAPP用于实际金融应用。这个框架在金融领域的各个方面展现出了巨大的潜力。 |
| [^2] | [Large language models can accurately predict searcher preferences.](http://arxiv.org/abs/2309.10621) | 大型语言模型可以通过从真实用户那里获取高质量的第一方数据来准确预测搜索者的偏好。 |
| [^3] | [Improving Medical Dialogue Generation with Abstract Meaning Representations.](http://arxiv.org/abs/2309.10608) | 该论文提出了一种改进医学对话生成方法，通过引入抽象意义表示（AMR）构建图形表示，以增强模型对文本语义和医学知识的理解。实验结果表明，该方法在医学对话生成方面优于强基线模型。 |
| [^4] | [FRACAS: A FRench Annotated Corpus of Attribution relations in newS.](http://arxiv.org/abs/2309.10604) | 本文介绍了一份新闻语料库，用于研究法语中的引述提取和来源归属。语料库包含1676篇手动注释的新闻文本，其中包括直接引述、间接引述和混合引述。通过8位标注者的一致性验证，该语料库对于这个困难的语言现象来说具有高度的一致性。 |
| [^5] | [Unsupervised Deep Cross-Language Entity Alignment.](http://arxiv.org/abs/2309.10598) | 本文提出了一种无监督的跨语言实体对齐方法，利用深度学习多语言编码器和机器翻译器对知识图谱文本进行编码，同时考虑了全局和局部对齐策略，生成了有排名的匹配结果，并提供了多种优化选择。 |
| [^6] | [Multimodal Modeling For Spoken Language Identification.](http://arxiv.org/abs/2309.10567) | 该论文提出了一种多模态口语识别方法MuSeLI，利用视频标题、描述和地理位置等元数据来增强语言识别任务，并在两个YouTube视频数据集上获得了最新的结果。 |
| [^7] | [A Neighbourhood-Aware Differential Privacy Mechanism for Static Word Embeddings.](http://arxiv.org/abs/2309.10551) | 该论文提出了一种邻域感知差分隐私机制，通过考虑预训练的词嵌入空间中单词的邻域来确定所需的最小噪声量，实验证明该机制在多个下游任务中优于其他机制，同时保证更高的隐私级别。 |
| [^8] | [Model Leeching: An Extraction Attack Targeting LLMs.](http://arxiv.org/abs/2309.10544) | 模型吸取是一种针对大型语言模型的提取攻击，能够将目标模型的任务特定知识提取到一个参数较少的模型中，并且具有较高的准确率和攻击成功率。 |
| [^9] | [OpenMSD: Towards Multilingual Scientific Documents Similarity Measurement.](http://arxiv.org/abs/2309.10539) | 这项研究开发并评估了多语言科学文档相似度测量模型，提出了第一个多语言科学文档数据集OpenMSD，利用该数据集训练了科学专门化语言模型，并探索了多种策略来提高模型性能。 |
| [^10] | [NSOAMT -- New Search Only Approach to Machine Translation.](http://arxiv.org/abs/2309.10526) | NSOAMT是一个新的只搜索的机器翻译方法，通过建立递增词汇索引实现即时和严谨的翻译过程，提高翻译效率和准确性。 |
| [^11] | [Harnessing the Zero-Shot Power of Instruction-Tuned Large Language Model in End-to-End Speech Recognition.](http://arxiv.org/abs/2309.10524) | 本论文结合指导调整的大语言模型（LLM）和端到端自动语音识别（ASR），利用LLM的零-shot能力来改善语音识别性能。 |
| [^12] | [Enhancing Open-Domain Table Question Answering via Syntax- and Structure-aware Dense Retrieval.](http://arxiv.org/abs/2309.10506) | 本研究提出了一种对开放领域表格问答任务的句法和结构感知检索方法，通过提供句法表示并使用表格的结构信息，解决了在表格评分过程中丢失句法和结构信息的问题，取得了在NQ-tables数据集上的最先进成果。 |
| [^13] | [An Evaluation of GPT-4 on the ETHICS Dataset.](http://arxiv.org/abs/2309.10492) | 本研究评估了GPT-4在ETHICS数据集上的性能，结果表明GPT-4的表现优于之前的模型，表明AI伦理中与共同人类价值观的合作学习并不是一个难题。 |
| [^14] | [Improving Speaker Diarization using Semantic Information: Joint Pairwise Constraints Propagation.](http://arxiv.org/abs/2309.10456) | 该论文提出了一种利用语义信息改进说话者分离的方法，通过引入口语理解模块提取语义信息并构建成对约束，并将其集成到说话者分离流程中，从而提高系统性能。 |
| [^15] | [Toward Unified Controllable Text Generation via Regular Expression Instruction.](http://arxiv.org/abs/2309.10447) | 本文通过引入正则表达式指令（REI）实现了统一可控文本生成，通过指令方式支持各种约束，无需对架构进行修改，并对各种约束组合表现出良好的性能。 |
| [^16] | [Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models.](http://arxiv.org/abs/2309.10444) | 本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。 |
| [^17] | [Reformulating Sequential Recommendation: Learning Dynamic User Interest with Content-enriched Language Modeling.](http://arxiv.org/abs/2309.10435) | 本研究提出了一个新的顺序推荐范式 LANCER，利用预训练语言模型的语义理解能力生成更加人性化的个性化推荐。在多个基准数据集上的实验结果表明，该方法有效且有希望，并为了解顺序推荐的影响提供了有价值的见解。 |
| [^18] | [Writer-Defined AI Personas for On-Demand Feedback Generation.](http://arxiv.org/abs/2309.10433) | 这项研究提出了基于作家定义的AI人物形象生成即时反馈的概念，通过两项用户研究表明，这个概念受到了作家的欢迎并帮助他们获得不同的观点。这项工作扩展了AI工具设计中的社会技术视角，为支持作家与AI的愿景做出了贡献。 |
| [^19] | [PICK: Polished & Informed Candidate Scoring for Knowledge-Grounded Dialogue Systems.](http://arxiv.org/abs/2309.10413) | 本文提出了PICK（Polished & Informed Candidate Scoring）框架作为一种基于知识的对话系统的生成重新评分方法，以解决当前系统在生成响应优质性方面的问题，该方法能够生成忠实、相关且无需额外标记数据或调整模型。 |
| [^20] | [PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training.](http://arxiv.org/abs/2309.10400) | 本文介绍了一种名为PoSE的训练方法，通过在训练过程中使用固定的上下文窗口和操纵位置索引来适应极长的上下文窗口，实验证明这种方法大大减小了内存和时间开销，对性能影响较小，成功将LLaMA模型扩展到了128k个标记。 |
| [^21] | [Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning.](http://arxiv.org/abs/2309.10359) | 本论文提出了一个新的任务，即通过对无支持论断进行分类，从中提取可数集合的叙事。作者使用大型语言模型合成支持论断，并发现这可以提高叙事分类模型的性能。这个模型在依赖叙事的应用中具有潜在的实用价值，例如事实核查。 |
| [^22] | [Explaining Agent Behavior with Large Language Models.](http://arxiv.org/abs/2309.10346) | 使用大规模语言模型解释智能体行为的方法，通过学习智能体行为的紧凑表示，并与用户进行交互，能够生成合理的解释，具备与人类专家相似的帮助性。 |
| [^23] | [KoBigBird-large: Transformation of Transformer for Korean Language Understanding.](http://arxiv.org/abs/2309.10339) | KoBigBird-large是一种适用于韩语理解的大型Transformer模型，通过改进架构和引入新的位置编码表示（TAPER）实现了最先进性能，尤其适用于处理长序列的文档分类和问题回答任务。 |
| [^24] | [QASnowball: An Iterative Bootstrapping Framework for High-Quality Question-Answering Data Generation.](http://arxiv.org/abs/2309.10326) | QASnowball是一个迭代自举框架，可以根据有监督的样本种子集生成大规模高质量的QA数据，并通过重新种子化进行自我增强。在高资源英文场景中进行了实验。 |
| [^25] | [Investigating the Catastrophic Forgetting in Multimodal Large Language Models.](http://arxiv.org/abs/2309.10313) | 本论文针对多模态大规模语言模型中的灾难性遗忘问题进行研究，引入了EMT方法来评估灾难性遗忘，并发现在标准图像分类任务上，几乎所有评估的模型都无法保持与视觉编码器相同的性能水平。研究结果表明，早期微调阶段对性能至关重要。 |
| [^26] | [Rigorously Assessing Natural Language Explanations of Neurons.](http://arxiv.org/abs/2309.10312) | 该论文开发了两种模式来评估自然语言解释神经元的忠实度，并且应用于GPT-4生成的GPT-2 XL神经元解释的评估结果显示，即使是自信度最高的解释也存在较高的错误率和几乎没有因果效应。 |
| [^27] | [Baichuan 2: Open Large-scale Language Models.](http://arxiv.org/abs/2309.10305) | Baichuan 2是一系列开放的大规模多语言模型，拥有70亿和130亿个参数，训练自26万亿个标记。Baichuan 2在公开基准测试中表现出色，并在垂直领域如医学和法律中具有优势。 |
| [^28] | [Using fine-tuning and min lookahead beam search to improve Whisper.](http://arxiv.org/abs/2309.10299) | 使用微调和最小先行搜索算法来改进Whisper，在低资源语言上提高了性能，并且证明了最小先行搜索优于标准束搜索算法。 |
| [^29] | [Leveraging Speech PTM, Text LLM, and Emotional TTS for Speech Emotion Recognition.](http://arxiv.org/abs/2309.10294) | 本文利用语音预训练模型、文本生成技术和语音合成技术提升了语音情感识别的效果，并通过实验证明了方法的有效性。 |
| [^30] | [Mixed-Distil-BERT: Code-mixed Language Modeling for Bangla, English, and Hindi.](http://arxiv.org/abs/2309.10272) | 本文介绍了Tri-Distil-BERT和Mixed-Distil-BERT两个模型，Tri-Distil-BERT是一个在孟加拉语、英语和印地语上预训练的多语言模型，Mixed-Distil-BERT是一个在混合编码数据上微调的模型。这两个模型在多个自然语言处理任务上表现出与更大的模型相竞争的性能。 |
| [^31] | [LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins.](http://arxiv.org/abs/2309.10254) | 本文提出了一个框架，用于分析和改进当前和未来与插件集成的LLM平台的安全性、隐私和安全性。在应用框架于OpenAI的插件生态系统时，我们发现了一些具体证明了潜在问题的插件。 |
| [^32] | [What is the Best Automated Metric for Text to Motion Generation?.](http://arxiv.org/abs/2309.10248) | 该论文研究了文本到动作生成任务中与人类评估最吻合的度量，并提出了新的更优度量。结果发现当前用于该任务的度量与人类判断相关性较低，但用于评估平均模型性能的常用度量显示出较强的相关性。 |
| [^33] | [PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models.](http://arxiv.org/abs/2309.10238) | PolicyGPT是一个使用大语言模型进行自动分析隐私政策的框架，能够解决隐私政策冗长的问题，提供更好的用户隐私保护和法律风险管理。 |
| [^34] | [Stabilizing RLHF through Advantage Model and Selective Rehearsal.](http://arxiv.org/abs/2309.10202) | 本论文提出了通过优势模型和选择性回放来稳定RLHF训练的两种创新方法，成功地解决了奖励欺骗和灾难性遗忘等不稳定性问题，并在实验中取得了更高的奖励得分和胜率。 |
| [^35] | [Positive and Risky Message Assessment for Music Products.](http://arxiv.org/abs/2309.10182) | 这项研究提出了一个新的问题：如何评估音乐产品中的正面和风险信息。研究者提出了一个多任务预测模型，通过序数约束解决这个问题，并且取得了显著优于其他方法的结果。 |
| [^36] | [Few-Shot Adaptation for Parsing Contextual Utterances with LLMs.](http://arxiv.org/abs/2309.10168) | 该论文评估了基于LLMs的语义解析器处理语境话语的能力，并提出了重写-解析范式作为解析准确性、注释成本和错误类型全面考虑时最有前途的选择。 |
| [^37] | [Understanding Catastrophic Forgetting in Language Models via Implicit Inference.](http://arxiv.org/abs/2309.10105) | 本研究通过在语言模型上进行实验，发现微调对模型在微调数据分布任务上的表现有正面影响，但会抑制模型在其他任务上的能力，特别是与微调分布最接近的任务。作者假设语言模型会隐式推理任务，并且微调过程偏向于微调数据分布中的任务。作者进一步提出了共轭提示方法，以尝试恢复模型在预训练阶段的能力。 |
| [^38] | [Unified Coarse-to-Fine Alignment for Video-Text Retrieval.](http://arxiv.org/abs/2309.10091) | 提出了一种统一粗到细对齐模型UCoFiA，用于视频-文本检索，该模型能够在不同粒度级别上捕捉跨模态相似性信息，并通过交互式相似性聚合模块有效考虑不同视觉特征的重要性，最终解决了视频-文本检索中的精确匹配问题。 |
| [^39] | [HTEC: Human Transcription Error Correction.](http://arxiv.org/abs/2309.10089) | HTEC是一种用于人类转录错误修正的方法，包括错误检测和填充两个阶段，提出了一种综合的修正操作列表，并针对删除错误提出了四种新操作。 |
| [^40] | [Automatic Personalized Impression Generation for PET Reports Using Large Language Models.](http://arxiv.org/abs/2309.10066) | 本研究旨在使用fine-tuned大型语言模型实现自动个性化生成全身PET报告的准确印象。通过训练语言模型并引入阅读医生的身份信息，模型能够学习医生特定的报告风格。研究结果经过专家评估和核医学医生的质量评分认可，证明该方法在实践中具有潜在的应用价值。 |
| [^41] | [Hierarchy Builder: Organizing Textual Spans into a Hierarchy to Facilitate Navigation.](http://arxiv.org/abs/2309.10057) | 这个论文介绍了一种层级构建器的方法，可以将信息提取系统生成的大量字符串进行组织和导航，特别适用于医疗信息提取。 |
| [^42] | [Multimodal Foundation Models: From Specialists to General-Purpose Assistants.](http://arxiv.org/abs/2309.10020) | 这项研究调查了多模态基础模型的分类和演化情况，并重点关注了从专业模型到通用助手的过渡。它涵盖了五个核心主题，包括预训练模型和通用助手模型的学习方法以及整合语言模型的统一视觉模型的最新进展。 |
| [^43] | [SYNDICOM: Improving Conversational Commonsense with Error-Injection and Natural Language Feedback.](http://arxiv.org/abs/2309.10015) | SYNDICOM是一种改进对话常识的方法，包含了一个常识对话数据集和一个基于自然语言反馈的模型，可用于训练对话应答生成模型。 |
| [^44] | [A novel approach to measuring patent claim scope based on probabilities obtained from (large) language models.](http://arxiv.org/abs/2309.10003) | 本文提出了一种使用概率从语言模型中获得的自信息来测量专利权要求范围的新方法。该方法通过计算要求的发生概率和自信息来评估要求的信息量，进而反映出要求的范围。研究结果表明，不同类型的语言模型对范围测量的影响不同，最简单的模型可以将范围度量简化为单词或字符计数的倒数。此方法在九个系列的专利权要求上进行了验证，结果表明各系列的要求范围逐渐减小。 |
| [^45] | [Detecting covariate drift in text data using document embeddings and dimensionality reduction.](http://arxiv.org/abs/2309.10000) | 本研究通过比较不同的文档嵌入、降维技术和漂移检测方法，发现在检测文本数据中的协变漂移方面，特定的嵌入方法、降维技术和漂移检测方法的组合效果优于其他方法。 |
| [^46] | [Improving Speech Recognition for African American English With Audio Classification.](http://arxiv.org/abs/2309.09996) | 通过使用少量非洲裔美国英语的数据，结合音频分类器和地理信息，我们提出了一种改进美国英语语音识别的方法，相对词错误率减少了38.5%。 |
| [^47] | [OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?.](http://arxiv.org/abs/2309.09992) | GPT-4在处理税务方面存在问题，无法可靠地计算税务。 |
| [^48] | [Code Representation Pre-training with Complements from Program Executions.](http://arxiv.org/abs/2309.09980) | 本论文提出了一种名为FuzzPretrain的方法，用于在代码表示预训练中探索由程序的测试用例揭示的动态信息，并解决从代码中直接学习功能语义的挑战。 |
| [^49] | [HypR: A comprehensive study for ASR hypothesis revising with a reference corpus.](http://arxiv.org/abs/2309.09838) | 本研究集中在发布一个ASR假设修订（HypR）数据集，该数据集包含了几个常用的语料库，并且为ASR模型的修订提供了一个基础。 |
| [^50] | [Watch the Speakers: A Hybrid Continuous Attribution Network for Emotion Recognition in Conversation With Emotion Disentanglement.](http://arxiv.org/abs/2309.09799) | 本文提出了一种用于情感识别的混合连续归属网络，解决了在对话中情感的延续和归属的问题，并改善了模型在不同情景中的表现。 |
| [^51] | [Facilitating NSFW Text Detection in Open-Domain Dialogue Systems via Knowledge Distillation.](http://arxiv.org/abs/2309.09749) | 该论文介绍了CensorChat，一个用于监测NSFW对话的数据集，并利用知识蒸馏技术构建了高效的NSFW内容检测器。 |
| [^52] | [LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models.](http://arxiv.org/abs/2309.09708) | 本文介绍了LLM4Jobs无监督的职业提取和规范化方法，通过利用大型语言模型，它展现了超越最新基准的灵活性和多功能性。此外，本研究还提供了合成和真实数据集，可用于相关研究。研究结果表明，现代语言模型有望为复杂的职业提取和规范化任务提供强有力的基础。 |
| [^53] | [LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models.](http://arxiv.org/abs/2309.09506) | LayoutNUWA是第一个将版式生成视为代码生成任务来增强语义信息和利用大型语言模型的隐藏版式专长的模型。 |
| [^54] | [Enhancing Multilingual Speech Recognition through Language Prompt Tuning and Frame-Level Language Adapter.](http://arxiv.org/abs/2309.09443) | 通过语言提示调整和帧级语言适配器这两种简单且参数高效的方法，我们成功提高了多语言语音识别的性能。 |
| [^55] | [Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?.](http://arxiv.org/abs/2309.08963) | 本研究评估了当前大型语言模型（LLMs）在生成复杂结构化数据方面的能力，并提出了一种结构感知的微调方法来改善这种能力。通过使用Struc-Bench和多个代表性的LLMs进行评估，发现了常见的格式错误和潜在改进的领域。通过应用结构感知微调方法，能够显著提高对自然语言约束的遵守程度。 |
| [^56] | [TextBind: Multi-turn Interleaved Multimodal Instruction-following.](http://arxiv.org/abs/2309.08637) | TextBind是一个注释极少的框架，用于将较大规模的语言模型赋予多轮交错多模态指令跟随能力，并通过图像-标题对生成多轮多模态指令-回应对话。这个框架对于解决实际任务具有重要意义，并为未来的研究提供了数据集、模型和演示。 |
| [^57] | [Media of Langue.](http://arxiv.org/abs/2309.08609) | 该论文介绍了《Media of Langue》这一全新词典和公共雕塑，通过描述不同语言之间的意义地图和两个力量之间的边界，重点介绍了三个新的概念：《Inter-Langue Map/Dictionary》、《Inter-Langue Space》和《Inter-Langue Network》。 |
| [^58] | [Sparse Autoencoders Find Highly Interpretable Features in Language Models.](http://arxiv.org/abs/2309.08600) | 本研究通过稀疏自编码器在语言模型中发现了一组高度可解释和单一义的特征，从而解决了神经网络内部多义性的问题。 |
| [^59] | [The Rise and Potential of Large Language Model Based Agents: A Survey.](http://arxiv.org/abs/2309.07864) | 基于大型语言模型的代理的崛起和潜力：一项调查。大型语言模型被认为是构建通用人工智能代理的潜在催化剂，许多研究已经取得重要进展。 |
| [^60] | [Traveling Words: A Geometric Interpretation of Transformers.](http://arxiv.org/abs/2309.07315) | 本文提出了一种几何视角来解释变压器的内部机制，主要贡献在于阐明了层归一化如何限制潜在特征并在超球面上塑造注意力机制，通过探测预训练的GPT-2模型验证了该视角的有效性，并提供了对变压器的直观理解。 |
| [^61] | [BHASA: A Holistic Southeast Asian Linguistic and Cultural Evaluation Suite for Large Language Models.](http://arxiv.org/abs/2309.06085) | BHASA是一个综合评估套件，用于评估大语言模型在东南亚语言和文化方面的表现。它包括NLP基准、语言诊断工具包和文化诊断数据集。目前，该套件的初步版本仅针对印度尼西亚语、越南语、泰语和泰米尔语实现。 |
| [^62] | [An Empirical Study of NetOps Capability of Pre-Trained Large Language Models.](http://arxiv.org/abs/2309.05557) | 本文通过对预训练大型语言模型（LLMs）进行系统评估，发现LLMs在网络运维（NetOps）领域具有强大的潜力应用，能够提升自动化和智能化的NetOps能力。 |
| [^63] | [FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation.](http://arxiv.org/abs/2309.05007) | 本文引入了一项真实世界的信息获取跟进问题生成任务，通过生成跟进问题来更深入地理解初始问题和答案。构建了数据集FOLLOWUPQG，评估了当前的问题生成模型在生成跟进问题方面的效果，并展示了其作为一个具有挑战性的基准任务的验证。 |
| [^64] | [Evaluation and Analysis of Hallucination in Large Vision-Language Models.](http://arxiv.org/abs/2308.15126) | 本文提出了基于大型语言模型的幻觉评估框架HaELM，可以评估大型视觉语言模型中的幻觉问题，并分析了导致幻觉的因素，并提出了缓解幻觉问题的建议。 |
| [^65] | [Attention Is Not All You Need Anymore.](http://arxiv.org/abs/2308.07661) | 本文提出了一种名为Extractor的插入替代器，用于取代Transformer中的自注意机制，实验证明使用Extractor可以提高Transformer的性能，并且具有更短的计算关键路径。 |
| [^66] | [Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review.](http://arxiv.org/abs/2308.04306) | 本文对基于深度学习的隐喻识别任务中知识注入的研究进展进行了全面综述，包括主流知识和知识注入原则的总结、数据集、评估指标和基准模型的回顾，并探讨了当前的知识注入问题。 |
| [^67] | [Think-on-Graph: Deep and Responsible Reasoning of Large Language Model with Knowledge Graph.](http://arxiv.org/abs/2307.07697) | Think-on-Graph是一个利用知识图谱增强大型语言模型深度和负责任推理能力的新框架，在复杂的多跳推理问答任务上表现出色，解决了现有方法中存在的限制。 |
| [^68] | [Towards Populating Generalizable Engineering Design Knowledge.](http://arxiv.org/abs/2307.06985) | 这项研究提出了一种从专利文件中提取工程设计知识的方法，通过构建知识图来填充通用设计知识，并与现有方法进行了比较。 |
| [^69] | [Fine-tuning Large Enterprise Language Models via Ontological Reasoning.](http://arxiv.org/abs/2306.10723) | 通过本体推理构建任务和领域特定的语料库，对大型企业语言模型进行微调。 |
| [^70] | [ChatGPT Informed Graph Neural Network for Stock Movement Prediction.](http://arxiv.org/abs/2306.03763) | 该研究介绍了一种新的框架，利用ChatGPT技术增强图神经网络，能够从财经新闻中提取出不断变化的网络结构，并用于股票价格预测，获得了超过基于深度学习的最新基准的表现，提示了ChatGPT在文本推断和金融预测方面的潜力。 |
| [^71] | [Using a Large Language Model to Control Speaking Style for Expressive TTS.](http://arxiv.org/abs/2305.10321) | 该论文提出了一种使用大型语言模型控制TTS语音表现风格的方法。该方法可为非表现性语料库上的TTS模型提供适当的韵律建议，使其生成表现力更强的语音。 |
| [^72] | [ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs.](http://arxiv.org/abs/2305.03513) | ChatGraph通过将ChatGPT的知识转换为图形，提高了文本分类的可解释性和性能 |
| [^73] | [Large Language Models are Diverse Role-Players for Summarization Evaluation.](http://arxiv.org/abs/2303.15078) | 本文提出了一种新的基于LLMs的评估框架，通过比较生成的文本和参考文本的客观和主观维度，提供了全面的评估框架。 |
| [^74] | [Towards Reliable Neural Machine Translation with Consistency-Aware Meta-Learning.](http://arxiv.org/abs/2303.10966) | 本论文提出了一种一致性感知元学习（CAML）框架，以解决神经机器翻译（NMT）中存在的可靠性问题。该框架通过在外部循环中学习一致的语义等价句子的元表示，并通过内部循环训练一个从元表示到翻译结果的映射，以实现更加可靠的翻译。 |
| [^75] | [Applying Automated Machine Translation to Educational Video Courses.](http://arxiv.org/abs/2301.03141) | 本研究通过自动翻译可汗学院的视频，并利用文本转语音合成和音视频同步技术构建引人入胜的教育视频。我们还提出了两种可靠的翻译置信度估计器，用于高效质量管理和减少人工翻译工作量。最后，我们开发了一个可部署的系统，用于提供翻译视频给用户并收集用户纠正以改进。 |
| [^76] | [Empirical Study Incorporating Linguistic Knowledge on Filled Pauses for Personalized Spontaneous Speech Synthesis.](http://arxiv.org/abs/2210.07559) | 该论文通过实证研究探讨了基于语言知识的个性化自发语音合成。研究结果揭示了填充式停顿在言语生成中的重要作用，并提出了个性化填充式停顿插入和非个性化填充式停顿预测方法的比较评估。 |
| [^77] | [Differentially Private Optimization on Large Model at Small Cost.](http://arxiv.org/abs/2210.00038) | 本文提出了一种名为簿记（BK）的技术，实现了差分隐私优化器在大模型和高维数据上的快速训练，并在计算成本上取得了实质性的改进。 |
| [^78] | [Learning Decoupled Retrieval Representation for Nearest Neighbour Neural Machine Translation.](http://arxiv.org/abs/2209.08738) | 本文提出了一种学习解耦的检索表示用于最近邻神经机器翻译，通过使用监督对比学习和构建难负样本，改进了检索准确性和BLEU分数。 |
| [^79] | [Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning.](http://arxiv.org/abs/2205.14704) | 本论文提出了一种检索增强的提示学习方法，通过将知识从记忆中解耦，帮助模型在泛化和记忆之间取得平衡。 |
| [^80] | [Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt Tuning.](http://arxiv.org/abs/2205.02355) | 提出了一种新的半参数学习范式，即检索增强的提示调优，用于关系抽取。通过构建开放式存储库，并使用线性插值的方式，模型能够在推断过程中根据存储库中的记忆信息推断关系。 |
| [^81] | [Contrastive Demonstration Tuning for Pre-trained Language Models.](http://arxiv.org/abs/2204.04392) | 本论文提出了一种名为对比演示调优的方法，可以在低数据场景下有效激发预训练语言模型的能力。实验结果表明，该方法与先前的提示调优方法相结合可以取得更好的性能。 |
| [^82] | [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.](http://arxiv.org/abs/1910.10683) | 本文通过引入一种统一的框架，将所有基于文本的语言问题转换为文本到文本格式，从而探索了NLP中的迁移学习技术的全貌，通过对多个任务进行系统研究，实现了许多基准测试上的最新结果。 |

# 详细

[^1]: CFGPT: 具有大型语言模型的中国金融助手

    CFGPT: Chinese Financial Assistant with Large Language Model. (arXiv:2309.10654v1 [cs.CL])

    [http://arxiv.org/abs/2309.10654](http://arxiv.org/abs/2309.10654)

    CFGPT是一个具有大型语言模型的中国金融助手，包括CFData用于预训练和监督微调，以及CFLLM用于处理金融文本，CFAPP用于实际金融应用。这个框架在金融领域的各个方面展现出了巨大的潜力。

    

    大型语言模型（LLM）已经在金融领域的自然语言处理任务中展现出巨大的潜力。在这项工作中，我们提出了一个名为CFGPT的中国金融生成式预训练Transformer框架，该框架包括用于预训练和监督微调的数据集（CFData），用于熟练处理金融文本的金融LLM（CFLLM），以及用于实际金融应用的部署框架（CFAPP）。CFData包括一个预训练数据集和一个监督微调数据集，其中预训练数据集汇集了中国金融数据和分析，以及总共584M个文件和141B个标记的较小的通用文本子集，并且监督微调数据集针对六个不同的金融任务进行了定制，内容涵盖了金融分析和决策的各个方面，包括1.5M个指令对和总计1.5B个标记。CFLLM基于InternLM-7B进行了平衡模型能力的调整。

    Large language models (LLMs) have demonstrated great potential in natural language processing tasks within the financial domain. In this work, we present a Chinese Financial Generative Pre-trained Transformer framework, named CFGPT, which includes a dataset~(CFData) for pre-training and supervised fine-tuning, a financial LLM~(CFLLM) to adeptly manage financial texts, and a deployment framework~(CFAPP) designed to navigate real-world financial applications. The CFData comprising both a pre-training dataset and a supervised fine-tuning dataset, where the pre-training dataset collates Chinese financial data and analytics, alongside a smaller subset of general-purpose text with 584M documents and 141B tokens in total, and the supervised fine-tuning dataset is tailored for six distinct financial tasks, embodying various facets of financial analysis and decision-making with 1.5M instruction pairs and 1.5B tokens in total. The CFLLM, which is based on InternLM-7B to balance the model capabil
    
[^2]: 大型语言模型能够准确预测搜索者的偏好

    Large language models can accurately predict searcher preferences. (arXiv:2309.10621v1 [cs.IR])

    [http://arxiv.org/abs/2309.10621](http://arxiv.org/abs/2309.10621)

    大型语言模型可以通过从真实用户那里获取高质量的第一方数据来准确预测搜索者的偏好。

    

    相关性标签是评估和优化搜索系统的关键。获取大量相关性标签通常需要第三方标注人员，但存在低质量数据的风险。本论文介绍了一种改进标签质量的替代方法，通过从真实用户那里获得仔细反馈来获取高质量的第一方数据。

    Relevance labels, which indicate whether a search result is valuable to a searcher, are key to evaluating and optimising search systems. The best way to capture the true preferences of users is to ask them for their careful feedback on which results would be useful, but this approach does not scale to produce a large number of labels. Getting relevance labels at scale is usually done with third-party labellers, who judge on behalf of the user, but there is a risk of low-quality data if the labeller doesn't understand user needs. To improve quality, one standard approach is to study real users through interviews, user studies and direct feedback, find areas where labels are systematically disagreeing with users, then educate labellers about user needs through judging guidelines, training and monitoring. This paper introduces an alternate approach for improving label quality. It takes careful feedback from real users, which by definition is the highest-quality first-party gold data that 
    
[^3]: 改进医学对话生成的抽象意义表示

    Improving Medical Dialogue Generation with Abstract Meaning Representations. (arXiv:2309.10608v1 [cs.CL])

    [http://arxiv.org/abs/2309.10608](http://arxiv.org/abs/2309.10608)

    该论文提出了一种改进医学对话生成方法，通过引入抽象意义表示（AMR）构建图形表示，以增强模型对文本语义和医学知识的理解。实验结果表明，该方法在医学对话生成方面优于强基线模型。

    

    医学对话生成在远程医疗中起着重要的作用，它有助于将医学专业知识传达给患者。现有研究侧重于引入文本表示，但这限制了他们对文本语义的表达能力，例如忽视了重要的医学实体。为了增强模型对文本语义和医学知识（包括实体和关系）的理解，我们介绍了使用抽象意义表示（AMR）构建图形表示的方法，这些表示显示了对话中语言成分和医学实体的角色。本文提出了一个新的框架，使用AMR图对患者和医疗专业人员之间的对话进行建模，其中神经网络通过双重注意机制结合文本和图形知识。实验结果表明，我们的框架在医学对话生成方面优于强基线模型，展示了其效果。

    Medical Dialogue Generation serves a critical role in telemedicine by facilitating the dissemination of medical expertise to patients. Existing studies focus on incorporating textual representations, which have limited their ability to represent the semantics of text, such as ignoring important medical entities. To enhance the model's understanding of the textual semantics and the medical knowledge including entities and relations, we introduce the use of Abstract Meaning Representations (AMR) to construct graphical representations that delineate the roles of language constituents and medical entities within the dialogues. In this paper, We propose a novel framework that models dialogues between patients and healthcare professionals using AMR graphs, where the neural networks incorporate textual and graphical knowledge with a dual attention mechanism. Experimental results show that our framework outperforms strong baseline models in medical dialogue generation, demonstrating the effect
    
[^4]: FRACAS: 一份用于新闻中引述关系的法语注释语料库

    FRACAS: A FRench Annotated Corpus of Attribution relations in newS. (arXiv:2309.10604v1 [cs.CL])

    [http://arxiv.org/abs/2309.10604](http://arxiv.org/abs/2309.10604)

    本文介绍了一份新闻语料库，用于研究法语中的引述提取和来源归属。语料库包含1676篇手动注释的新闻文本，其中包括直接引述、间接引述和混合引述。通过8位标注者的一致性验证，该语料库对于这个困难的语言现象来说具有高度的一致性。

    

    引述提取是一项在社会学和自然语言处理方面都非常有用的任务，但是除了英语之外，很少有数据可用于研究其他语言中的这个任务。在本文中，我们介绍了一份手动注释的法语新闻语料库，包含1676篇新闻文本，用于引述提取和来源归属。我们首先描述了我们语料库的组成以及在选择数据时做出的选择。然后详细介绍了标注指南和标注过程，以及关于最终语料库和引述类型（直接引述、间接引述和混合引述）之间的一些统计数据，这些类型特别具有挑战性。最后，我们详细介绍了8位参与手动标注的标注者之间的标注者一致性，对于这样一个困难的语言现象来说，一致性相当高。

    Quotation extraction is a widely useful task both from a sociological and from a Natural Language Processing perspective. However, very little data is available to study this task in languages other than English. In this paper, we present a manually annotated corpus of 1676 newswire texts in French for quotation extraction and source attribution. We first describe the composition of our corpus and the choices that were made in selecting the data. We then detail the annotation guidelines and annotation process, as well as a few statistics about the final corpus and the obtained balance between quote types (direct, indirect and mixed, which are particularly challenging). We end by detailing our inter-annotator agreement between the 8 annotators who worked on manual labelling, which is substantially high for such a difficult linguistic phenomenon.
    
[^5]: 无监督深度跨语言实体对齐

    Unsupervised Deep Cross-Language Entity Alignment. (arXiv:2309.10598v1 [cs.CL])

    [http://arxiv.org/abs/2309.10598](http://arxiv.org/abs/2309.10598)

    本文提出了一种无监督的跨语言实体对齐方法，利用深度学习多语言编码器和机器翻译器对知识图谱文本进行编码，同时考虑了全局和局部对齐策略，生成了有排名的匹配结果，并提供了多种优化选择。

    

    跨语言实体对齐是在不同语言的知识图谱中找到相同语义实体的任务。在本文中，我们提出了一种简单而新颖的无监督跨语言实体对齐方法。我们利用深度学习多语言编码器结合机器翻译器来编码知识图谱文本，减少对标签数据的依赖。与仅强调全局或局部对齐的传统方法不同，我们的方法同时考虑了两种对齐策略。我们首先将对齐任务视为一个二分匹配问题，然后采用重新交换的思想来完成对齐。与仅给出一个最优解的传统二分匹配算法相比，我们的算法生成了有排名的匹配结果，这使得许多潜在的下游任务成为可能。此外，我们的方法可以在二分匹配过程中适应两种不同类型的优化（最小和最大），从而提供更多的灵活性。

    Cross-lingual entity alignment is the task of finding the same semantic entities from different language knowledge graphs. In this paper, we propose a simple and novel unsupervised method for cross-language entity alignment. We utilize the deep learning multi-language encoder combined with a machine translator to encode knowledge graph text, which reduces the reliance on label data. Unlike traditional methods that only emphasize global or local alignment, our method simultaneously considers both alignment strategies. We first view the alignment task as a bipartite matching problem and then adopt the re-exchanging idea to accomplish alignment. Compared with the traditional bipartite matching algorithm that only gives one optimal solution, our algorithm generates ranked matching results which enabled many potentials downstream tasks. Additionally, our method can adapt two different types of optimization (minimal and maximal) in the bipartite matching process, which provides more flexibil
    
[^6]: 多模态建模用于口语识别

    Multimodal Modeling For Spoken Language Identification. (arXiv:2309.10567v1 [cs.CL])

    [http://arxiv.org/abs/2309.10567](http://arxiv.org/abs/2309.10567)

    该论文提出了一种多模态口语识别方法MuSeLI，利用视频标题、描述和地理位置等元数据来增强语言识别任务，并在两个YouTube视频数据集上获得了最新的结果。

    

    口语识别是指在给定的话语中自动预测口语的任务。传统上，它被建模为一种基于语音的语言识别任务。以往的技术都局限于单一模态；然而，在视频数据中，存在许多其他元数据，这些元数据对于这个任务可能会有益处。在这项工作中，我们提出了MuSeLI，一种多模态口语识别方法，它深入研究了使用各种元数据源来增强语言识别。我们的研究发现，诸如视频标题、描述和地理位置等元数据提供了大量信息，能够识别多媒体录制的口语。我们利用两个不同的YouTube视频的公共数据集进行实验，并在语言识别任务中获得了最新的结果。我们还进行了一项消融研究，描述了每种模态对语言识别的独特贡献。

    Spoken language identification refers to the task of automatically predicting the spoken language in a given utterance. Conventionally, it is modeled as a speech-based language identification task. Prior techniques have been constrained to a single modality; however in the case of video data there is a wealth of other metadata that may be beneficial for this task. In this work, we propose MuSeLI, a Multimodal Spoken Language Identification method, which delves into the use of various metadata sources to enhance language identification. Our study reveals that metadata such as video title, description and geographic location provide substantial information to identify the spoken language of the multimedia recording. We conduct experiments using two diverse public datasets of YouTube videos, and obtain state-of-the-art results on the language identification task. We additionally conduct an ablation study that describes the distinct contribution of each modality for language recognition.
    
[^7]: 用于静态词嵌入的邻域感知差分隐私机制

    A Neighbourhood-Aware Differential Privacy Mechanism for Static Word Embeddings. (arXiv:2309.10551v1 [cs.LG])

    [http://arxiv.org/abs/2309.10551](http://arxiv.org/abs/2309.10551)

    该论文提出了一种邻域感知差分隐私机制，通过考虑预训练的词嵌入空间中单词的邻域来确定所需的最小噪声量，实验证明该机制在多个下游任务中优于其他机制，同时保证更高的隐私级别。

    

    我们提出了一种考虑预训练的静态词嵌入空间中单词邻域的邻域感知差分隐私（NADP）机制，以确定保证指定隐私级别所需的最小噪声量。我们首先使用它们的嵌入构建单词的最近邻图，并将其分解为一组连通分量（即邻域）。然后，在每个邻域中根据该邻域中的单词集合分别对单词应用不同水平的高斯噪声。实验表明，我们提出的NADP机制在多个下游任务中始终优于多个先前提出的DP机制，如拉普拉斯、高斯和马氏距离，同时保证更高的隐私级别。

    We propose a Neighbourhood-Aware Differential Privacy (NADP) mechanism considering the neighbourhood of a word in a pretrained static word embedding space to determine the minimal amount of noise required to guarantee a specified privacy level. We first construct a nearest neighbour graph over the words using their embeddings, and factorise it into a set of connected components (i.e. neighbourhoods). We then separately apply different levels of Gaussian noise to the words in each neighbourhood, determined by the set of words in that neighbourhood. Experiments show that our proposed NADP mechanism consistently outperforms multiple previously proposed DP mechanisms such as Laplacian, Gaussian, and Mahalanobis in multiple downstream tasks, while guaranteeing higher levels of privacy.
    
[^8]: 模型吸取: 针对LLMs的一种提取攻击

    Model Leeching: An Extraction Attack Targeting LLMs. (arXiv:2309.10544v1 [cs.LG])

    [http://arxiv.org/abs/2309.10544](http://arxiv.org/abs/2309.10544)

    模型吸取是一种针对大型语言模型的提取攻击，能够将目标模型的任务特定知识提取到一个参数较少的模型中，并且具有较高的准确率和攻击成功率。

    

    模型吸取是一种针对大型语言模型(LLMs)的新型提取攻击，能够将目标LLM的任务特定知识提炼到一个参数较少的模型中。我们通过从ChatGPT-3.5-Turbo中提取任务能力来演示我们攻击的有效性，实现了73%的准确匹配(EM)相似性以及75%的SQuAD EM准确率和87%的F1得分，仅需50美元的API费用。我们进一步展示了通过模型吸取提取的模型在对目标LLM进行机器学习攻击时的可行性，当应用于ChatGPT-3.5-Turbo时，攻击成功率提高了11%。

    Model Leeching is a novel extraction attack targeting Large Language Models (LLMs), capable of distilling task-specific knowledge from a target LLM into a reduced parameter model. We demonstrate the effectiveness of our attack by extracting task capability from ChatGPT-3.5-Turbo, achieving 73% Exact Match (EM) similarity, and SQuAD EM and F1 accuracy scores of 75% and 87%, respectively for only $50 in API cost. We further demonstrate the feasibility of adversarial attack transferability from an extracted model extracted via Model Leeching to perform ML attack staging against a target LLM, resulting in an 11% increase to attack success rate when applied to ChatGPT-3.5-Turbo.
    
[^9]: OpenMSD:面向多语言科学文档相似度测量的研究

    OpenMSD: Towards Multilingual Scientific Documents Similarity Measurement. (arXiv:2309.10539v1 [cs.CL])

    [http://arxiv.org/abs/2309.10539](http://arxiv.org/abs/2309.10539)

    这项研究开发并评估了多语言科学文档相似度测量模型，提出了第一个多语言科学文档数据集OpenMSD，利用该数据集训练了科学专门化语言模型，并探索了多种策略来提高模型性能。

    

    在这项工作中，我们开发并评估了多语言科学文档相似度测量模型。这些模型可以用来找到不同语言的相关作品，帮助多语言研究人员更有效地找到和探索论文。我们提出了第一个多语言科学文档数据集OpenMSD，其中包含103种语言的7400万篇论文和7780万个引用对。利用OpenMSD，我们预训练了科学专门化语言模型，并探索了不同策略来导出“相关”的论文对以调整模型，包括使用引用、共引用和文献耦合的混合对。为了进一步提高非英文论文的模型性能，我们还探索了使用生成式语言模型来用英文摘要丰富非英文论文。这使我们能够利用模型的英文能力为非英文论文创建更好的表示。我们的最佳模型显著地超过了其他模型的表现。

    We develop and evaluate multilingual scientific documents similarity measurement models in this work. Such models can be used to find related works in different languages, which can help multilingual researchers find and explore papers more efficiently. We propose the first multilingual scientific documents dataset, Open-access Multilingual Scientific Documents (OpenMSD), which has 74M papers in 103 languages and 778M citation pairs. With OpenMSD, we pretrain science-specialized language models, and explore different strategies to derive "related" paper pairs to fine-tune the models, including using a mixture of citation, co-citation, and bibliographic-coupling pairs. To further improve the models' performance for non-English papers, we explore the use of generative language models to enrich the non-English papers with English summaries. This allows us to leverage the models' English capabilities to create better representations for non-English papers. Our best model significantly outp
    
[^10]: NSOAMT -- 新的只搜索的机器翻译方法

    NSOAMT -- New Search Only Approach to Machine Translation. (arXiv:2309.10526v1 [cs.CL])

    [http://arxiv.org/abs/2309.10526](http://arxiv.org/abs/2309.10526)

    NSOAMT是一个新的只搜索的机器翻译方法，通过建立递增词汇索引实现即时和严谨的翻译过程，提高翻译效率和准确性。

    

    翻译自动化机制和工具已经发展了几年，以使说不同语言的人能够联系起来。"新的只搜索的机器翻译方法"被采用来解决其他技术的慢速和不准确性问题。该方法通过建立一个语义相符的递增词汇索引，使其能够创建原语言记录和翻译语言之间的对应过程，从而实现在翻译过程中的即时性和严谨性。通过对电子文本文档的处理、加载、分析和测量，验证了这一研究原理的前提。尽管观察到的和预测的度量指标可能存在一些差异，但整体而言，这种新方法在提高翻译过程中的效率和准确性方面取得了积极的结果。

    Translation automation mechanisms and tools have been developed for several years to bring people who speak different languages together. A "new search only approach to machine translation" was adopted to tackle some of the slowness and inaccuracy of the other technologies. The idea is to develop a solution that, by indexing an incremental set of words that combine a certain semantic meaning, makes it possible to create a process of correspondence between their native language record and the language of translation. This research principle assumes that the vocabulary used in a given type of publication/document is relatively limited in terms of language style and word diversity, which enhances the greater effect of instantaneously and rigor in the translation process through the indexing process. A volume of electronic text documents where processed and loaded into a database, and analyzed and measured in order confirm the previous premise. Although the observed and projected metric va
    
[^11]: 发挥指导调整的大语言模型在端到端语音识别中的零-shot能力

    Harnessing the Zero-Shot Power of Instruction-Tuned Large Language Model in End-to-End Speech Recognition. (arXiv:2309.10524v1 [eess.AS])

    [http://arxiv.org/abs/2309.10524](http://arxiv.org/abs/2309.10524)

    本论文结合指导调整的大语言模型（LLM）和端到端自动语音识别（ASR），利用LLM的零-shot能力来改善语音识别性能。

    

    我们提出了一种将指导调整的大语言模型和端到端自动语音识别相结合的新方法。现代大语言模型在零-shot学习中可以执行各种语言任务，只要提供明确的指导或提示来指导文本生成过程。我们探索使用这种零-shot能力的大语言模型来提取语言信息，以改善语音识别性能。具体来说，我们将大语言模型引导去纠正语音识别假设中的语法错误，并利用嵌入的语言知识进行端到端语音识别。所提出的模型基于混合连接主义时间分类和注意力架构，其中指导调整的大语言模型（即Llama2）被用作解码器的前端。通过CTC解码从编码器获得一个需要纠正的语音识别假设，然后将其与指导一起输入大语言模型。解码器随后采取...

    We present a novel integration of an instruction-tuned large language model (LLM) and end-to-end automatic speech recognition (ASR). Modern LLMs can perform a wide range of linguistic tasks within zero-shot learning when provided with a precise instruction or a prompt to guide the text generation process towards the desired task. We explore using this zero-shot capability of LLMs to extract linguistic information that can contribute to improving ASR performance. Specifically, we direct an LLM to correct grammatical errors in an ASR hypothesis and harness the embedded linguistic knowledge to conduct end-to-end ASR. The proposed model is built on the hybrid connectionist temporal classification (CTC) and attention architecture, where an instruction-tuned LLM (i.e., Llama2) is employed as a front-end of the decoder. An ASR hypothesis, subject to correction, is obtained from the encoder via CTC decoding, which is then fed into the LLM along with an instruction. The decoder subsequently tak
    
[^12]: 通过关注句法和结构的稠密检索增强开放领域表格问答

    Enhancing Open-Domain Table Question Answering via Syntax- and Structure-aware Dense Retrieval. (arXiv:2309.10506v1 [cs.CL])

    [http://arxiv.org/abs/2309.10506](http://arxiv.org/abs/2309.10506)

    本研究提出了一种对开放领域表格问答任务的句法和结构感知检索方法，通过提供句法表示并使用表格的结构信息，解决了在表格评分过程中丢失句法和结构信息的问题，取得了在NQ-tables数据集上的最先进成果。

    

    开放领域表格问答旨在通过从大量的表格中检索和提取信息来回答问题。现有的开放领域表格问答研究要么直接采用文本检索方法，要么仅在表格检索的编码层考虑表格结构，这可能导致在表格评分过程中丢失句法和结构信息。为了解决这个问题，我们提出了一种对开放领域表格问答任务的句法和结构感知检索方法。它为问题提供句法表示，使用表格的结构头部和值表示来避免对细粒度句法和结构信息的丢失。然后，我们使用一个句法到结构的聚合器来模拟人类检索过程，获取问题和候选表格之间的匹配分数。实验结果表明，我们的方法在NQ-tables数据集上达到了最先进水平，并且超过了其他方法。

    Open-domain table question answering aims to provide answers to a question by retrieving and extracting information from a large collection of tables. Existing studies of open-domain table QA either directly adopt text retrieval methods or consider the table structure only in the encoding layer for table retrieval, which may cause syntactical and structural information loss during table scoring. To address this issue, we propose a syntax- and structure-aware retrieval method for the open-domain table QA task. It provides syntactical representations for the question and uses the structural header and value representations for the tables to avoid the loss of fine-grained syntactical and structural information. Then, a syntactical-to-structural aggregator is used to obtain the matching score between the question and a candidate table by mimicking the human retrieval process. Experimental results show that our method achieves the state-of-the-art on the NQ-tables dataset and overwhelms str
    
[^13]: 对GPT-4在ETHICS数据集上的评估

    An Evaluation of GPT-4 on the ETHICS Dataset. (arXiv:2309.10492v1 [cs.CL])

    [http://arxiv.org/abs/2309.10492](http://arxiv.org/abs/2309.10492)

    本研究评估了GPT-4在ETHICS数据集上的性能，结果表明GPT-4的表现优于之前的模型，表明AI伦理中与共同人类价值观的合作学习并不是一个难题。

    

    本报告总结了对GPT-4在ETHICS数据集上性能的短期研究。ETHICS数据集包含五个分数据集，涵盖了伦理学的不同领域：正义、道德、德性伦理学、功利主义和常识伦理学。这些道德判断被精选，以尽可能高的一致性来代表共享的人类价值观，而不是道德困境。GPT-4的表现比之前的模型好得多，表明AI伦理中与共同人类价值观的合作学习并不是一个难题。

    This report summarizes a short study of the performance of GPT-4 on the ETHICS dataset. The ETHICS dataset consists of five sub-datasets covering different fields of ethics: Justice, Deontology, Virtue Ethics, Utilitarianism, and Commonsense Ethics. The moral judgments were curated so as to have a high degree of agreement with the aim of representing shared human values rather than moral dilemmas. GPT-4's performance is much better than that of previous models and suggests that learning to work with common human values is not the hard problem for AI ethics.
    
[^14]: 利用语义信息改进说话者分离: 利用联合成对约束传播

    Improving Speaker Diarization using Semantic Information: Joint Pairwise Constraints Propagation. (arXiv:2309.10456v1 [cs.SD])

    [http://arxiv.org/abs/2309.10456](http://arxiv.org/abs/2309.10456)

    该论文提出了一种利用语义信息改进说话者分离的方法，通过引入口语理解模块提取语义信息并构建成对约束，并将其集成到说话者分离流程中，从而提高系统性能。

    

    说话者分离已经引起了语音处理研究界的广泛关注。主流的说话者分离主要依赖于从声音信号中提取的说话者的声音特征，往往忽视了语义信息的潜力。考虑到语音信号能够有效传达语音的内容，我们有兴趣充分利用这些语义线索，利用语言模型。在这项工作中，我们提出了一种新的方法，以有效地利用基于聚类的说话者分离系统中的语义信息。首先，我们引入口语理解模块来提取与说话者相关的语义信息，并利用这些信息构建成对约束。其次，我们提出了一个新的框架来将这些约束集成到说话者分离流程中，提高整个系统的性能。在公开数据集上进行了大量实验证明了一致的优势。

    Speaker diarization has gained considerable attention within speech processing research community. Mainstream speaker diarization rely primarily on speakers' voice characteristics extracted from acoustic signals and often overlook the potential of semantic information. Considering the fact that speech signals can efficiently convey the content of a speech, it is of our interest to fully exploit these semantic cues utilizing language models. In this work we propose a novel approach to effectively leverage semantic information in clustering-based speaker diarization systems. Firstly, we introduce spoken language understanding modules to extract speaker-related semantic information and utilize these information to construct pairwise constraints. Secondly, we present a novel framework to integrate these constraints into the speaker diarization pipeline, enhancing the performance of the entire system. Extensive experiments conducted on the public dataset demonstrate the consistent superiori
    
[^15]: 通过正则表达式指令实现统一可控文本生成

    Toward Unified Controllable Text Generation via Regular Expression Instruction. (arXiv:2309.10447v1 [cs.CL])

    [http://arxiv.org/abs/2309.10447](http://arxiv.org/abs/2309.10447)

    本文通过引入正则表达式指令（REI）实现了统一可控文本生成，通过指令方式支持各种约束，无需对架构进行修改，并对各种约束组合表现出良好的性能。

    

    可控文本生成是自然语言生成的基本方面之一，已经提出了许多针对不同约束类型的方法。然而，这些方法往往需要重大的架构或解码修改，使得它们难以应用于附加约束或解决不同约束组合。为了解决这个问题，本文引入了正则表达式指令（REI），利用基于指令的机制充分利用正则表达式的优势，统一建模各种约束。具体而言，我们的REI通过正则表达式风格的指令支持所有流行的细粒度可控生成约束，即词汇、位置和长度，以及它们的复杂组合。我们的方法只需要在中等规模语言模型上进行微调或在大规模语言模型上进行少样本、上下文学习，并且在应用于各种约束组合时不需要进一步调整。实验证明了我们方法的有效性。

    Controllable text generation is a fundamental aspect of natural language generation, with numerous methods proposed for different constraint types. However, these approaches often require significant architectural or decoding modifications, making them challenging to apply to additional constraints or resolve different constraint combinations. To address this, our paper introduces Regular Expression Instruction (REI), which utilizes an instruction-based mechanism to fully exploit regular expressions' advantages to uniformly model diverse constraints. Specifically, our REI supports all popular fine-grained controllable generation constraints, i.e., lexical, positional, and length, as well as their complex combinations, via regular expression-style instructions. Our method only requires fine-tuning on medium-scale language models or few-shot, in-context learning on large language models, and requires no further adjustment when applied to various constraint combinations. Experiments demon
    
[^16]: 利用大型语言模型探索自我强化以改进学生生成的多项选择题解释

    Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models. (arXiv:2309.10444v1 [cs.AI])

    [http://arxiv.org/abs/2309.10444](http://arxiv.org/abs/2309.10444)

    本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。

    

    学生资源共享涉及学生生成和分享学习资源。在学生生成多项选择题时，创建解释是一个关键步骤，因为它有助于对相关概念的深入理解。然而，学生往往由于主题理解有限和仅仅重申问题、干扰因素和正确答案的倾向而难以编写有效的解释。为了帮助支撑这个任务，在这项工作中，我们提出了一个自我强化的大型语言模型框架，旨在自动生成和评估解释。该框架由三个模块组成，生成与学生对齐的解释，评估这些解释以确保其质量，并迭代增强解释。如果一个解释的评估分数低于定义的阈值，框架会迭代地优化和重新评估解释。重要的是，我们的框架模拟了一个学生学习的过程。

    Learnersourcing involves students generating and sharing learning resources with their peers. When learnersourcing multiple-choice questions, creating explanations for the generated questions is a crucial step as it facilitates a deeper understanding of the related concepts. However, it is often difficult for students to craft effective explanations due to limited subject understanding and a tendency to merely restate the question stem, distractors, and correct answer. To help scaffold this task, in this work we propose a self-reinforcement large-language-model framework, with the goal of generating and evaluating explanations automatically. Comprising three modules, the framework generates student-aligned explanations, evaluates these explanations to ensure their quality and iteratively enhances the explanations. If an explanation's evaluation score falls below a defined threshold, the framework iteratively refines and reassesses the explanation. Importantly, our framework emulates th
    
[^17]: 重塑顺序推荐系统：利用内容增强语言建模学习动态用户兴趣

    Reformulating Sequential Recommendation: Learning Dynamic User Interest with Content-enriched Language Modeling. (arXiv:2309.10435v1 [cs.IR])

    [http://arxiv.org/abs/2309.10435](http://arxiv.org/abs/2309.10435)

    本研究提出了一个新的顺序推荐范式 LANCER，利用预训练语言模型的语义理解能力生成更加人性化的个性化推荐。在多个基准数据集上的实验结果表明，该方法有效且有希望，并为了解顺序推荐的影响提供了有价值的见解。

    

    推荐系统对在线应用至关重要，而顺序推荐由于其表达能力强大，能够捕捉到动态用户兴趣而广泛使用。然而，先前的顺序建模方法在捕捉上下文信息方面仍存在局限性。主要的原因是语言模型常常缺乏对领域特定知识和物品相关文本内容的理解。为了解决这个问题，我们采用了一种新的顺序推荐范式，并提出了LANCER，它利用预训练语言模型的语义理解能力生成个性化推荐。我们的方法弥合了语言模型与推荐系统之间的差距，产生了更加人性化的推荐。通过对多个基准数据集上的实验，我们验证了我们的方法的有效性，展示了有希望的结果，并提供了对我们模型对顺序推荐的影响的有价值的见解。

    Recommender systems are essential for online applications, and sequential recommendation has enjoyed significant prevalence due to its expressive ability to capture dynamic user interests. However, previous sequential modeling methods still have limitations in capturing contextual information. The primary reason for this issue is that language models often lack an understanding of domain-specific knowledge and item-related textual content. To address this issue, we adopt a new sequential recommendation paradigm and propose LANCER, which leverages the semantic understanding capabilities of pre-trained language models to generate personalized recommendations. Our approach bridges the gap between language models and recommender systems, resulting in more human-like recommendations. We demonstrate the effectiveness of our approach through experiments on several benchmark datasets, showing promising results and providing valuable insights into the influence of our model on sequential recomm
    
[^18]: 为即时反馈生成定义AI人物形象

    Writer-Defined AI Personas for On-Demand Feedback Generation. (arXiv:2309.10433v1 [cs.HC])

    [http://arxiv.org/abs/2309.10433](http://arxiv.org/abs/2309.10433)

    这项研究提出了基于作家定义的AI人物形象生成即时反馈的概念，通过两项用户研究表明，这个概念受到了作家的欢迎并帮助他们获得不同的观点。这项工作扩展了AI工具设计中的社会技术视角，为支持作家与AI的愿景做出了贡献。

    

    优秀的写作应该根据受众进行适应。然而，作家可能难以同读者产生共鸣，难以及时获得反馈或者难以获得目标群体的信息。本论文提出了一种概念，即基于作家定义的任何目标受众的AI人物形象生成即时反馈。我们通过一个原型（使用GPT-3.5）在两项用户研究（N=5和N=11）中探索了这一概念：作家们赞赏这一概念，并且战略性地使用人物形象来获得不同的观点。反馈被认为是有帮助的，并且激发了文本和人物形象的修订，尽管该反馈通常冗长而不具体。我们讨论了即时反馈的影响、当代AI系统的有限代表性以及进一步定义AI人物的想法。这项工作在支持作家与AI的愿景中做出了贡献，扩展了AI工具设计中的社会技术视角：为了赋予创作者权力，我们还需要考虑他们与观众的关系。

    Compelling writing is tailored to its audience. This is challenging, as writers may struggle to empathize with readers, get feedback in time, or gain access to the target group. We propose a concept that generates on-demand feedback, based on writer-defined AI personas of any target audience. We explore this concept with a prototype (using GPT-3.5) in two user studies (N=5 and N=11): Writers appreciated the concept and strategically used personas for getting different perspectives. The feedback was seen as helpful and inspired revisions of text and personas, although it was often verbose and unspecific. We discuss the impact of on-demand feedback, the limited representativity of contemporary AI systems, and further ideas for defining AI personas. This work contributes to the vision of supporting writers with AI by expanding the socio-technical perspective in AI tool design: To empower creators, we also need to keep in mind their relationship to an audience.
    
[^19]: PICK: 磨砺和知情候选分数的基于知识的对话系统.

    PICK: Polished & Informed Candidate Scoring for Knowledge-Grounded Dialogue Systems. (arXiv:2309.10413v1 [cs.CL])

    [http://arxiv.org/abs/2309.10413](http://arxiv.org/abs/2309.10413)

    本文提出了PICK（Polished & Informed Candidate Scoring）框架作为一种基于知识的对话系统的生成重新评分方法，以解决当前系统在生成响应优质性方面的问题，该方法能够生成忠实、相关且无需额外标记数据或调整模型。

    

    提议在外部知识的基础上加强对话响应生成，以产生信息量大且引人入胜的响应。然而，当前的基于知识的对话系统在与人类优先品质的生成响应对齐方面常常存在问题，比如幻觉和缺乏连贯性等。在分析多个语言模型生成的基础上，我们观察到在一个单一的解码过程中存在着多个备选生成响应。这些备选响应相对于解码过程优先考虑的最优响应更加忠实，并且与之前的对话转换具有可比性或更高级别的相关性。为了应对这些挑战并受到这些观察的驱动，我们提出了Polished \& Informed Candidate Scoring (PICK)，这是一个生成重新评分的框架，使模型能够生成忠实和相关的响应，而无需额外的标记数据或模型调整。

    Grounding dialogue response generation on external knowledge is proposed to produce informative and engaging responses. However, current knowledge-grounded dialogue (KGD) systems often fail to align the generated responses with human-preferred qualities due to several issues like hallucination and the lack of coherence. Upon analyzing multiple language model generations, we observe the presence of alternative generated responses within a single decoding process. These alternative responses are more faithful and exhibit a comparable or higher level of relevance to prior conversational turns compared to the optimal responses prioritized by the decoding processes. To address these challenges and driven by these observations, we propose Polished \& Informed Candidate Scoring (PICK), a generation re-scoring framework that empowers models to generate faithful and relevant responses without requiring additional labeled data or model tuning. Through comprehensive automatic and human evaluation
    
[^20]: PoSE: 通过位置跳跃式训练提高LLMs对于上下文窗口的有效拓展

    PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training. (arXiv:2309.10400v1 [cs.CL])

    [http://arxiv.org/abs/2309.10400](http://arxiv.org/abs/2309.10400)

    本文介绍了一种名为PoSE的训练方法，通过在训练过程中使用固定的上下文窗口和操纵位置索引来适应极长的上下文窗口，实验证明这种方法大大减小了内存和时间开销，对性能影响较小，成功将LLaMA模型扩展到了128k个标记。

    

    本文介绍了一种名为Positional Skip-wise (PoSE)训练的方法，用于将大型语言模型（LLMs）适应于极长的上下文窗口。PoSE通过在训练过程中使用固定的上下文窗口和操纵位置索引来模拟长输入，将训练长度与目标上下文窗口大小分离。具体而言，我们从长输入序列中选择若干短块，并引入不同的跳跃偏置项来修改每个块的位置索引。这些跳跃偏置项以及每个块的长度在每个训练样本中都会变化，使得模型能够适应目标上下文窗口中的所有位置，而无需对完整长度的输入进行训练。实验证明，与对完整长度进行微调相比，PoSE大大减小了内存和时间开销，对性能影响较小。利用这一优势，我们成功将LLaMA模型扩展到了128k个标记。此外，我们经验证实，PoSE与

    In this paper, we introduce Positional Skip-wisE (PoSE) training for efficient adaptation of large language models~(LLMs) to extremely long context windows. PoSE decouples train length from target context window size by simulating long inputs using a fixed context window with manipulated position indices during training. Concretely, we select several short chunks from a long input sequence, and introduce distinct skipping bias terms to modify the position indices of each chunk. These bias terms, along with the length of each chunk, are altered for each training example, allowing the model to adapt to all positions within the target context window without training on full length inputs. Experiments show that, compared with fine-tuning on the full length, PoSE greatly reduces memory and time overhead with minimal impact on performance. Leveraging this advantage, we have successfully extended the LLaMA model to 128k tokens. Furthermore, we empirically confirm that PoSE is compatible with 
    
[^21]: 提示、条件和生成：基于上下文学习的无支持论断的分类

    Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning. (arXiv:2309.10359v1 [cs.CL])

    [http://arxiv.org/abs/2309.10359](http://arxiv.org/abs/2309.10359)

    本论文提出了一个新的任务，即通过对无支持论断进行分类，从中提取可数集合的叙事。作者使用大型语言模型合成支持论断，并发现这可以提高叙事分类模型的性能。这个模型在依赖叙事的应用中具有潜在的实用价值，例如事实核查。

    

    在我们日常生活中遇到的无支持和不可反驳的论断可以影响我们对世界的看法。然而，对这些论断进行表征、总结和更一般地理解却是具有挑战性的。在这项工作中，我们专注于细粒度的辩论主题，并提出了从这些论断中提炼可数集合的叙事的新任务。我们提供了一个众包数据集，包括12个有争议的主题，超过120k个来自异构来源的论证、论断和评论，每个都标注有一个叙事标签。我们进一步研究了如何使用大型语言模型（LLMs）使用上下文学习来合成论断。我们发现，使用支持的证据生成的论断可以提高叙事分类模型的性能，并且同样的模型可以使用少量的训练样例来推断立场和方面。这样的模型在依赖叙事的应用中，例如事实核查，是非常有用的。

    Unsupported and unfalsifiable claims we encounter in our daily lives can influence our view of the world. Characterizing, summarizing, and -- more generally -- making sense of such claims, however, can be challenging. In this work, we focus on fine-grained debate topics and formulate a new task of distilling, from such claims, a countable set of narratives. We present a crowdsourced dataset of 12 controversial topics, comprising more than 120k arguments, claims, and comments from heterogeneous sources, each annotated with a narrative label. We further investigate how large language models (LLMs) can be used to synthesise claims using In-Context Learning. We find that generated claims with supported evidence can be used to improve the performance of narrative classification models and, additionally, that the same model can infer the stance and aspect using a few training examples. Such a model can be useful in applications which rely on narratives , e.g. fact-checking.
    
[^22]: 使用大规模语言模型解释智能体行为

    Explaining Agent Behavior with Large Language Models. (arXiv:2309.10346v1 [cs.LG])

    [http://arxiv.org/abs/2309.10346](http://arxiv.org/abs/2309.10346)

    使用大规模语言模型解释智能体行为的方法，通过学习智能体行为的紧凑表示，并与用户进行交互，能够生成合理的解释，具备与人类专家相似的帮助性。

    

    智能体如机器人越来越多地被部署在真实世界中的安全关键环境中。重要的是，这些智能体能够向人类对等体解释他们决策背后的推理，然而，他们的行为通常是由不可解释的模型（如深度神经网络）产生的。我们提出了一种方法，基于状态和动作的观察，不考虑底层模型表示，生成智能体行为的自然语言解释。我们展示了如何学习智能体行为的简洁表示，并用其生成合理的解释，同时保证了与预训练的大规模语言模型的用户交互。通过用户研究和实证实验，我们证明了我们的方法生成的解释与人类领域专家生成的解释一样有用，同时具备有益的交互，如澄清和反事实查询。

    Intelligent agents such as robots are increasingly deployed in real-world, safety-critical settings. It is vital that these agents are able to explain the reasoning behind their decisions to human counterparts, however, their behavior is often produced by uninterpretable models such as deep neural networks. We propose an approach to generate natural language explanations for an agent's behavior based only on observations of states and actions, agnostic to the underlying model representation. We show how a compact representation of the agent's behavior can be learned and used to produce plausible explanations with minimal hallucination while affording user interaction with a pre-trained large language model. Through user studies and empirical experiments, we show that our approach generates explanations as helpful as those generated by a human domain expert while enabling beneficial interactions such as clarification and counterfactual queries.
    
[^23]: KoBigBird-large: Transformer模型在韩语理解中的应用

    KoBigBird-large: Transformation of Transformer for Korean Language Understanding. (arXiv:2309.10339v1 [cs.CL])

    [http://arxiv.org/abs/2309.10339](http://arxiv.org/abs/2309.10339)

    KoBigBird-large是一种适用于韩语理解的大型Transformer模型，通过改进架构和引入新的位置编码表示（TAPER）实现了最先进性能，尤其适用于处理长序列的文档分类和问题回答任务。

    

    本研究介绍了KoBigBird-large，这是一种适用于韩语理解的大型Transformer模型，它在性能和处理长序列方面达到了最先进水平。我们通过对架构进行改进并引入了我们提出的锥形绝对位置编码表示（TAPER），在没有进行进一步的预训练的情况下，实现了这一成果。实验证明，KoBigBird-large 在韩语理解基准任务上取得了最先进的全部性能，并且在长序列的文档分类和问题回答任务中表现优于竞争基线模型。我们在此公开发布了我们的模型。

    This work presents KoBigBird-large, a large size of Korean BigBird that achieves state-of-the-art performance and allows long sequence processing for Korean language understanding. Without further pretraining, we only transform the architecture and extend the positional encoding with our proposed Tapered Absolute Positional Encoding Representations (TAPER). In experiments, KoBigBird-large shows state-of-the-art overall performance on Korean language understanding benchmarks and the best performance on document classification and question answering tasks for longer sequences against the competitive baseline models. We publicly release our model here.
    
[^24]: QASnowball: 一个用于高质量问答数据生成的迭代自举框架

    QASnowball: An Iterative Bootstrapping Framework for High-Quality Question-Answering Data Generation. (arXiv:2309.10326v1 [cs.CL])

    [http://arxiv.org/abs/2309.10326](http://arxiv.org/abs/2309.10326)

    QASnowball是一个迭代自举框架，可以根据有监督的样本种子集生成大规模高质量的QA数据，并通过重新种子化进行自我增强。在高资源英文场景中进行了实验。

    

    近年来，问题回答（QA）取得了成功，特别是其在应对各种自然语言处理任务中的潜力。然而，获取足够的数据来构建一个有效稳定的QA系统仍然是一个未解决的问题。针对这个问题，我们引入了一个迭代自举框架QASnowball，用于QA数据增强，它可以根据有监督的样本种子集迭代地生成大规模高质量的QA数据。具体而言，QASnowball包括三个模块：回答提取器，用于从无标签的文档中提取候选答案的核心短语；问题生成器，根据文档和候选答案生成问题；QA数据过滤器，用于过滤出高质量的QA数据。此外，QASnowball可以通过重新种子化种子集在不同迭代中进行自我增强，从而不断提高生成质量。我们在高资源英文场景中进行了实验。

    Recent years have witnessed the success of question answering (QA), especially its potential to be a foundation paradigm for tackling diverse NLP tasks. However, obtaining sufficient data to build an effective and stable QA system still remains an open problem. For this problem, we introduce an iterative bootstrapping framework for QA data augmentation (named QASnowball), which can iteratively generate large-scale high-quality QA data based on a seed set of supervised examples. Specifically, QASnowball consists of three modules, an answer extractor to extract core phrases in unlabeled documents as candidate answers, a question generator to generate questions based on documents and candidate answers, and a QA data filter to filter out high-quality QA data. Moreover, QASnowball can be self-enhanced by reseeding the seed set to fine-tune itself in different iterations, leading to continual improvements in the generation quality. We conduct experiments in the high-resource English scenario
    
[^25]: 对多模态大规模语言模型中的灾难性遗忘进行的研究

    Investigating the Catastrophic Forgetting in Multimodal Large Language Models. (arXiv:2309.10313v1 [cs.CL])

    [http://arxiv.org/abs/2309.10313](http://arxiv.org/abs/2309.10313)

    本论文针对多模态大规模语言模型中的灾难性遗忘问题进行研究，引入了EMT方法来评估灾难性遗忘，并发现在标准图像分类任务上，几乎所有评估的模型都无法保持与视觉编码器相同的性能水平。研究结果表明，早期微调阶段对性能至关重要。

    

    在GPT4的成功之后，多模态大规模语言模型（MLLM）研究引起了广泛关注。这一研究方向侧重于通过微调预训练的LLM和视觉模型来开发通用的LLM。然而，灾难性遗忘，即微调模型无法保持与预训练模型相似的性能水平，仍然是多模态LLM（MLLM）中的一个固有问题。本文介绍了EMT：用于评估MLLM中灾难性遗忘的评估方法，将每个MLLM作为一个图像分类器进行评估。我们首先应用EMT来评估几个开源的微调MLLM，并发现几乎所有评估的MLLM在标准图像分类任务上无法保持与他们的视觉编码器相同的性能水平。此外，我们继续微调LLaVA，一种MLLM，并利用EMT来评估整个微调过程中的性能。有趣的是，我们的结果表明，早期的微调阶段是关键的，过早停止微调可能导致低性能的模型。

    Following the success of GPT4, there has been a surge in interest in multimodal large language model (MLLM) research. This line of research focuses on developing general-purpose LLMs through fine-tuning pre-trained LLMs and vision models. However, catastrophic forgetting, a notorious phenomenon where the fine-tuned model fails to retain similar performance compared to the pre-trained model, still remains an inherent problem in multimodal LLMs (MLLM). In this paper, we introduce EMT: Evaluating MulTimodality for evaluating the catastrophic forgetting in MLLMs, by treating each MLLM as an image classifier. We first apply EMT to evaluate several open-source fine-tuned MLLMs and we discover that almost all evaluated MLLMs fail to retain the same performance levels as their vision encoders on standard image classification tasks. Moreover, we continue fine-tuning LLaVA, an MLLM and utilize EMT to assess performance throughout the fine-tuning. Interestingly, our results suggest that early-sta
    
[^26]: 严格评估神经元的自然语言解释

    Rigorously Assessing Natural Language Explanations of Neurons. (arXiv:2309.10312v1 [cs.CL])

    [http://arxiv.org/abs/2309.10312](http://arxiv.org/abs/2309.10312)

    该论文开发了两种模式来评估自然语言解释神经元的忠实度，并且应用于GPT-4生成的GPT-2 XL神经元解释的评估结果显示，即使是自信度最高的解释也存在较高的错误率和几乎没有因果效应。

    

    自然语言是解释大型语言模型如何处理和存储信息的一种吸引人的方式，但评估这种解释的忠实性是具有挑战性的。为了帮助解决这个问题，我们开发了两种评估自然语言解释的模式，这些解释声称个别神经元代表文本输入中的一个概念。在观察模式中，我们评估了神经元$a$仅并且完全激活与所提出的解释$E$所指代的概念相关的所有输入字符串的说法。在干预模式中，我们将$E$解释为神经元$a$是由$E$所表示的概念的因果中介者的说法。我们将我们的框架应用于Bills等人（2023年）对GPT-2 XL神经元的GPT-4生成的解释，并显示即使是最自信的解释也有很高的错误率和几乎没有因果效应。最后，我们对自然语言是否是一个好的解释选择以及神经元是否是最好的分析层次进行了批判性评估。

    Natural language is an appealing medium for explaining how large language models process and store information, but evaluating the faithfulness of such explanations is challenging. To help address this, we develop two modes of evaluation for natural language explanations that claim individual neurons represent a concept in a text input. In the observational mode, we evaluate claims that a neuron $a$ activates on all and only input strings that refer to a concept picked out by the proposed explanation $E$. In the intervention mode, we construe $E$ as a claim that the neuron $a$ is a causal mediator of the concept denoted by $E$. We apply our framework to the GPT-4-generated explanations of GPT-2 XL neurons of Bills et al. (2023) and show that even the most confident explanations have high error rates and little to no causal efficacy. We close the paper by critically assessing whether natural language is a good choice for explanations and whether neurons are the best level of analysis.
    
[^27]: Baichuan 2: 开放的大规模语言模型

    Baichuan 2: Open Large-scale Language Models. (arXiv:2309.10305v1 [cs.CL])

    [http://arxiv.org/abs/2309.10305](http://arxiv.org/abs/2309.10305)

    Baichuan 2是一系列开放的大规模多语言模型，拥有70亿和130亿个参数，训练自26万亿个标记。Baichuan 2在公开基准测试中表现出色，并在垂直领域如医学和法律中具有优势。

    

    大型语言模型（LLMs）在仅有少量自然语言指令示例的情况下，已经在各种自然语言任务中展示出了令人瞩目的性能，减少了对广泛特征工程的需求。然而，大多数强大的LLMs是封闭源代码的，或者在除了英语以外的其他语言方面能力有限。在这篇技术报告中，我们介绍了Baichuan 2系列，这是一系列从头开始进行训练的大规模多语言模型，包含70亿和130亿个参数，使用26万亿个标记进行训练。Baichuan 2在MMLU、CMMLU、GSM8K和HumanEval等公开基准测试中与其他相同规模的开源模型相匹配或胜过。此外，Baichuan 2在医学和法律等垂直领域表现出色。我们将发布所有预训练模型检查点，以使研究界更好地理解Baichuan 2的训练动态。

    Large language models (LLMs) have demonstrated remarkable performance on a variety of natural language tasks based on just a few examples of natural language instructions, reducing the need for extensive feature engineering. However, most powerful LLMs are closed-source or limited in their capability for languages other than English. In this technical report, we present Baichuan 2, a series of large-scale multilingual language models containing 7 billion and 13 billion parameters, trained from scratch, on 2.6 trillion tokens. Baichuan 2 matches or outperforms other open-source models of similar size on public benchmarks like MMLU, CMMLU, GSM8K, and HumanEval. Furthermore, Baichuan 2 excels in vertical domains such as medicine and law. We will release all pre-training model checkpoints to benefit the research community in better understanding the training dynamics of Baichuan 2.
    
[^28]: 使用微调和最小先行搜索来提高Whisper

    Using fine-tuning and min lookahead beam search to improve Whisper. (arXiv:2309.10299v1 [eess.AS])

    [http://arxiv.org/abs/2309.10299](http://arxiv.org/abs/2309.10299)

    使用微调和最小先行搜索算法来改进Whisper，在低资源语言上提高了性能，并且证明了最小先行搜索优于标准束搜索算法。

    

    Whisper在低资源语言上的性能仍然远离完美。除了低资源语言上缺乏训练数据外，我们还发现Whisper中使用的束搜索算法存在一些限制。为了解决这些问题，我们在额外的数据上对Whisper进行微调，并提出了一种改进的解码算法。在越南语上，使用LoRA对Whisper-Tiny进行微调可以将WER的改进提高38.49，相比于全参数微调，进一步减少了1.45。此外，通过使用Filter-Ends和Min Lookahead解码算法，与标准束搜索相比，WER在一系列语言中平均降低了2.26。这些结果可以推广到更大的Whisper模型尺寸。我们还证明了Min Lookahead优于Whisper中使用的标准束搜索算法。

    The performance of Whisper in low-resource languages is still far from perfect. In addition to a lack of training data on low-resource languages, we identify some limitations in the beam search algorithm used in Whisper. To address these issues, we fine-tune Whisper on additional data and propose an improved decoding algorithm. On the Vietnamese language, fine-tuning Whisper-Tiny with LoRA leads to an improvement of 38.49 in WER over the zero-shot Whisper-Tiny setting which is a further reduction of 1.45 compared to full-parameter fine-tuning. Additionally, by using Filter-Ends and Min Lookahead decoding algorithms, the WER reduces by 2.26 on average over a range of languages compared to standard beam search. These results generalise to larger Whisper model sizes. We also prove a theorem that Min Lookahead outperforms the standard beam search algorithm used in Whisper.
    
[^29]: 利用语音PTM、文本LLM和情感TTS进行语音情感识别

    Leveraging Speech PTM, Text LLM, and Emotional TTS for Speech Emotion Recognition. (arXiv:2309.10294v1 [cs.CL])

    [http://arxiv.org/abs/2309.10294](http://arxiv.org/abs/2309.10294)

    本文利用语音预训练模型、文本生成技术和语音合成技术提升了语音情感识别的效果，并通过实验证明了方法的有效性。

    

    本文探讨如何利用最先进的语音预训练模型(PTM)、data2vec、文本生成技术GPT-4以及语音合成技术Azure TTS来提升语音情感识别(SER)。首先，我们研究了不同的语音自监督预训练模型的表示能力，发现data2vec在SER任务上具有良好的表示能力。其次，我们采用了强大的大语言模型(GPT-4)和情感文本到语音(TTS)模型(Azure TTS)来生成情感一致的文本和语音。我们精心设计了文本提示和数据集构建，以获得质量高的合成情感语音数据。第三，我们研究了不同的数据增强方法来促进使用合成语音的SER任务，包括随机混合、对抗训练、迁移学习和课程学习。在IEMOCAP数据集上的实验和消融研究表明了我们方法的有效性。

    In this paper, we explored how to boost speech emotion recognition (SER) with the state-of-the-art speech pre-trained model (PTM), data2vec, text generation technique, GPT-4, and speech synthesis technique, Azure TTS. First, we investigated the representation ability of different speech self-supervised pre-trained models, and we found that data2vec has a good representation ability on the SER task. Second, we employed a powerful large language model (LLM), GPT-4, and emotional text-to-speech (TTS) model, Azure TTS, to generate emotionally congruent text and speech. We carefully designed the text prompt and dataset construction, to obtain the synthetic emotional speech data with high quality. Third, we studied different ways of data augmentation to promote the SER task with synthetic speech, including random mixing, adversarial training, transfer learning, and curriculum learning. Experiments and ablation studies on the IEMOCAP dataset demonstrate the effectiveness of our method, compar
    
[^30]: 混合Distil-BERT: 用于孟加拉语、英语和印地语的混合语言建模

    Mixed-Distil-BERT: Code-mixed Language Modeling for Bangla, English, and Hindi. (arXiv:2309.10272v1 [cs.CL])

    [http://arxiv.org/abs/2309.10272](http://arxiv.org/abs/2309.10272)

    本文介绍了Tri-Distil-BERT和Mixed-Distil-BERT两个模型，Tri-Distil-BERT是一个在孟加拉语、英语和印地语上预训练的多语言模型，Mixed-Distil-BERT是一个在混合编码数据上微调的模型。这两个模型在多个自然语言处理任务上表现出与更大的模型相竞争的性能。

    

    在自然语言处理领域中，文本分类是最受欢迎的下游任务之一。当文本是混合编码时，文本分类任务变得更加困难。虽然在预训练过程中没有接触到这种文本，但不同的BERT模型已经成功地解决了混合编码的自然语言处理挑战。再次，为了提高性能，混合编码自然语言处理模型已经依赖于将合成数据与真实数据相结合。当BERT模型使用相应的混合编码语言进行预训练时，了解它们的性能受到了怎样的影响是至关重要的。在本文中，我们介绍了Tri-Distil-BERT，一个在孟加拉语、英语和印地语上预训练的多语言模型，以及Mixed-Distil-BERT，一个在混合编码数据上微调的模型。这两个模型在多个自然语言处理任务上进行了评估，并展示出与更大的模型如mBERT和XLM-R相竞争的性能。我们的两层预训练方法为多语言任务提供了高效的替代选择。

    One of the most popular downstream tasks in the field of Natural Language Processing is text classification. Text classification tasks have become more daunting when the texts are code-mixed. Though they are not exposed to such text during pre-training, different BERT models have demonstrated success in tackling Code-Mixed NLP challenges. Again, in order to enhance their performance, Code-Mixed NLP models have depended on combining synthetic data with real-world data. It is crucial to understand how the BERT models' performance is impacted when they are pretrained using corresponding code-mixed languages. In this paper, we introduce Tri-Distil-BERT, a multilingual model pre-trained on Bangla, English, and Hindi, and Mixed-Distil-BERT, a model fine-tuned on code-mixed data. Both models are evaluated across multiple NLP tasks and demonstrate competitive performance against larger models like mBERT and XLM-R. Our two-tiered pre-training approach offers efficient alternatives for multiling
    
[^31]: LLM平台安全：将系统评估框架应用于OpenAI的ChatGPT插件

    LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins. (arXiv:2309.10254v1 [cs.CR])

    [http://arxiv.org/abs/2309.10254](http://arxiv.org/abs/2309.10254)

    本文提出了一个框架，用于分析和改进当前和未来与插件集成的LLM平台的安全性、隐私和安全性。在应用框架于OpenAI的插件生态系统时，我们发现了一些具体证明了潜在问题的插件。

    

    近期，如ChatGPT等大型语言模型（LLM）平台开始提供插件生态系统，以与互联网上的第三方服务进行交互。虽然这些插件扩展了LLM平台的功能，但它们是由任意的第三方开发的，因此不能隐式信任。插件还使用自然语言与LLM平台和用户进行交互，这可能导致模糊的解释。本文提出了一个框架，为LLM平台设计者分析和改进当前和未来与插件集成的LLM平台的安全性、隐私和安全性奠定了基础。我们的框架是一个攻击分类法的表述，通过迭代地探索LLM平台相关方如何利用他们的能力和责任对彼此进行攻击来开发的。作为我们迭代过程的一部分，我们将我们的框架应用于OpenAI的插件生态系统。我们揭示了一些具体证明了潜在问题的插件。

    Large language model (LLM) platforms, such as ChatGPT, have recently begun offering a plugin ecosystem to interface with third-party services on the internet. While these plugins extend the capabilities of LLM platforms, they are developed by arbitrary third parties and thus cannot be implicitly trusted. Plugins also interface with LLM platforms and users using natural language, which can have imprecise interpretations. In this paper, we propose a framework that lays a foundation for LLM platform designers to analyze and improve the security, privacy, and safety of current and future plugin-integrated LLM platforms. Our framework is a formulation of an attack taxonomy that is developed by iteratively exploring how LLM platform stakeholders could leverage their capabilities and responsibilities to mount attacks against each other. As part of our iterative process, we apply our framework in the context of OpenAI's plugin ecosystem. We uncover plugins that concretely demonstrate the poten
    
[^32]: 文本到动作生成的最佳自动度量是什么？

    What is the Best Automated Metric for Text to Motion Generation?. (arXiv:2309.10248v1 [cs.CL])

    [http://arxiv.org/abs/2309.10248](http://arxiv.org/abs/2309.10248)

    该论文研究了文本到动作生成任务中与人类评估最吻合的度量，并提出了新的更优度量。结果发现当前用于该任务的度量与人类判断相关性较低，但用于评估平均模型性能的常用度量显示出较强的相关性。

    

    生成基于骨骼的人体动作并解释自然语言描述的兴趣日益增长。尽管大部分工作集中在为此任务开发更好的神经网络架构上，但在确定适当的评估度量方面没有进行重要工作。人类评估是该任务的最终准确性度量标准，自动度量应与人类质量判断相关性强。由于描述与许多动作相兼容，确定正确的度量对于评估和设计有效的生成模型至关重要。本文系统地研究了哪些度量与人类评估最吻合，并提出了与之更加吻合的新度量。我们的研究结果表明，目前用于此任务的度量中没有一个在样本级别上与人类判断有中等相关性。然而，对于评估平均模型性能，常用的度量如R-Precision和较少使用的坐标误差显示出较强的相关性。

    There is growing interest in generating skeleton-based human motions from natural language descriptions. While most efforts have focused on developing better neural architectures for this task, there has been no significant work on determining the proper evaluation metric. Human evaluation is the ultimate accuracy measure for this task, and automated metrics should correlate well with human quality judgments. Since descriptions are compatible with many motions, determining the right metric is critical for evaluating and designing effective generative models. This paper systematically studies which metrics best align with human evaluations and proposes new metrics that align even better. Our findings indicate that none of the metrics currently used for this task show even a moderate correlation with human judgments on a sample level. However, for assessing average model performance, commonly used metrics such as R-Precision and less-used coordinate errors show strong correlations. Addit
    
[^33]: PolicyGPT: 自动化分析使用大语言模型的隐私政策

    PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models. (arXiv:2309.10238v1 [cs.CL])

    [http://arxiv.org/abs/2309.10238](http://arxiv.org/abs/2309.10238)

    PolicyGPT是一个使用大语言模型进行自动分析隐私政策的框架，能够解决隐私政策冗长的问题，提供更好的用户隐私保护和法律风险管理。

    

    隐私政策是在线服务提供商向用户通知其数据收集和使用程序的主要途径。然而，为了全面和减轻法律风险，这些政策文件通常很冗长。在实际使用中，用户往往直接点击同意按钮而不是仔细阅读。这种做法使用户面临隐私泄露和法律问题的风险。最近，像ChatGPT和GPT-4这样的大型语言模型（LLM）的出现为文本分析，特别是对于像隐私政策这样的长篇文档，提供了新的可能性。在本研究中，我们基于LLM研究了一个名为PolicyGPT的隐私政策文本分析框架。该框架使用了两个数据集进行测试。第一个数据集包括了115个网站的隐私政策，由法律专家精心注释，将每个段落分类为10个类别之一。第二个数据集包括了304个热门手机应用的隐私政策。

    Privacy policies serve as the primary conduit through which online service providers inform users about their data collection and usage procedures. However, in a bid to be comprehensive and mitigate legal risks, these policy documents are often quite verbose. In practical use, users tend to click the Agree button directly rather than reading them carefully. This practice exposes users to risks of privacy leakage and legal issues. Recently, the advent of Large Language Models (LLM) such as ChatGPT and GPT-4 has opened new possibilities for text analysis, especially for lengthy documents like privacy policies. In this study, we investigate a privacy policy text analysis framework PolicyGPT based on the LLM. This framework was tested using two datasets. The first dataset comprises of privacy policies from 115 websites, which were meticulously annotated by legal experts, categorizing each segment into one of 10 classes. The second dataset consists of privacy policies from 304 popular mobil
    
[^34]: 通过优势模型和选择性回放稳定RLHF

    Stabilizing RLHF through Advantage Model and Selective Rehearsal. (arXiv:2309.10202v1 [cs.CL])

    [http://arxiv.org/abs/2309.10202](http://arxiv.org/abs/2309.10202)

    本论文提出了通过优势模型和选择性回放来稳定RLHF训练的两种创新方法，成功地解决了奖励欺骗和灾难性遗忘等不稳定性问题，并在实验中取得了更高的奖励得分和胜率。

    

    大型语言模型（LLM）已经在自然语言处理领域产生了革命性的影响，然而，通过RLHF将这些模型与人类价值观和偏好对齐仍然是一个重大挑战。这个挑战表现为各种不稳定性，比如奖励欺骗和灾难性遗忘。在这个技术报告中，我们提出了两项创新来稳定RLHF训练: 1) 优势模型，直接建模优势得分，即相对于期望奖励的额外奖励，并通过调节得分分布来防止奖励欺骗。2) 选择性回放，通过有策略地选择数据进行PPO训练和知识回放，从而减轻灾难性遗忘。我们在公开和专有数据集上进行的实验分析表明，所提出的方法不仅在RLHF训练中增加了稳定性，而且实现了更高的奖励得分和胜率。

    Large Language Models (LLMs) have revolutionized natural language processing, yet aligning these models with human values and preferences using RLHF remains a significant challenge. This challenge is characterized by various instabilities, such as reward hacking and catastrophic forgetting. In this technical report, we propose two innovations to stabilize RLHF training: 1) Advantage Model, which directly models advantage score i.e., extra reward compared to the expected rewards and regulates score distributions across tasks to prevent reward hacking. 2) Selective Rehearsal, which mitigates catastrophic forgetting by strategically selecting data for PPO training and knowledge rehearsing. Our experimental analysis on public and proprietary datasets reveals that the proposed methods not only increase stability in RLHF training but also achieve higher reward scores and win rates.
    
[^35]: 音乐产品的正面和风险信息评估

    Positive and Risky Message Assessment for Music Products. (arXiv:2309.10182v1 [cs.CL])

    [http://arxiv.org/abs/2309.10182](http://arxiv.org/abs/2309.10182)

    这项研究提出了一个新的问题：如何评估音乐产品中的正面和风险信息。研究者提出了一个多任务预测模型，通过序数约束解决这个问题，并且取得了显著优于其他方法的结果。

    

    在这项工作中，我们提出了一个新颖的研究问题：评估音乐产品中的正面和风险信息。我们首先建立了一个多角度多级音乐内容评估的基准，然后提出了一种有效的多任务预测模型，并通过序数约束来解决这个问题。我们的结果显示，所提出的方法不仅明显优于强大的针对特定任务的对应方法，而且可以同时评估多个方面。

    In this work, we propose a novel research problem: assessing positive and risky messages from music products. We first establish a benchmark for multi-angle multi-level music content assessment and then present an effective multi-task prediction model with ordinality-enforcement to solve this problem. Our result shows the proposed method not only significantly outperforms strong task-specific counterparts but can concurrently evaluate multiple aspects.
    
[^36]: 少样本适应语境话语的LLMs解析

    Few-Shot Adaptation for Parsing Contextual Utterances with LLMs. (arXiv:2309.10168v1 [cs.CL])

    [http://arxiv.org/abs/2309.10168](http://arxiv.org/abs/2309.10168)

    该论文评估了基于LLMs的语义解析器处理语境话语的能力，并提出了重写-解析范式作为解析准确性、注释成本和错误类型全面考虑时最有前途的选择。

    

    我们评估了基于大型语言模型（LLMs）的语义解析器处理语境话语的能力。在现实世界中，由于注释成本，通常只存在有限数量的注释语境话语，导致与非语境话语相比不平衡。因此，解析器必须使用少量训练示例来适应语境话语。我们在对话式语义解析中考察了四种主要的范式，即带有话语历史的解析、带有参考程序的解析、解析-解决、重写-解析。为了促进跨范式比较，我们构建了SMCalFlow-EventQueries，这是从SMCalFlow中选择的带有附加注释的语境示例的子集。在语境学习和微调的实验中，结果表明重写-解析是在全面考虑解析准确性、注释成本和错误类型等因素时最有前途的范式。

    We evaluate the ability of semantic parsers based on large language models (LLMs) to handle contextual utterances. In real-world settings, there typically exists only a limited number of annotated contextual utterances due to annotation cost, resulting in an imbalance compared to non-contextual utterances. Therefore, parsers must adapt to contextual utterances with a few training examples. We examine four major paradigms for doing so in conversational semantic parsing i.e., Parse-with-Utterance-History, Parse-with-Reference-Program, Parse-then-Resolve, and Rewrite-then-Parse. To facilitate such cross-paradigm comparisons, we construct SMCalFlow-EventQueries, a subset of contextual examples from SMCalFlow with additional annotations. Experiments with in-context learning and fine-tuning suggest that Rewrite-then-Parse is the most promising paradigm when holistically considering parsing accuracy, annotation cost, and error types.
    
[^37]: 通过隐式推理理解语言模型中的灾难性遗忘

    Understanding Catastrophic Forgetting in Language Models via Implicit Inference. (arXiv:2309.10105v1 [cs.CL])

    [http://arxiv.org/abs/2309.10105](http://arxiv.org/abs/2309.10105)

    本研究通过在语言模型上进行实验，发现微调对模型在微调数据分布任务上的表现有正面影响，但会抑制模型在其他任务上的能力，特别是与微调分布最接近的任务。作者假设语言模型会隐式推理任务，并且微调过程偏向于微调数据分布中的任务。作者进一步提出了共轭提示方法，以尝试恢复模型在预训练阶段的能力。

    

    微调（通过指令微调或从人类反馈进行强化学习等方法）是训练语言模型以鲁棒地执行所需任务的关键步骤。然而，我们缺乏对微调的影响的系统理解，特别是在狭窄的微调分布之外的任务上。在一个简化的场景中，我们证明，在微调数据分布内提高任务表现的同时，会抑制模型在其他任务上的能力。这种退化在与微调分布“最接近”的任务中尤为显著。我们假设语言模型会隐式推理出与提示相对应的任务，并且微调过程主要偏向于微调分布中的任务，以测试这个假设，我们提出了共轭提示以查看是否可以恢复预训练的能力。共轭提示会人为地使任务看起来与微调分布较远。

    Fine-tuning (via methods such as instruction-tuning or reinforcement learning from human feedback) is a crucial step in training language models to robustly carry out tasks of interest. However, we lack a systematic understanding of the effects of fine-tuning, particularly on tasks outside the narrow fine-tuning distribution. In a simplified scenario, we demonstrate that improving performance on tasks within the fine-tuning data distribution comes at the expense of suppressing model capabilities on other tasks. This degradation is especially pronounced for tasks "closest" to the fine-tuning distribution. We hypothesize that language models implicitly infer the task of the prompt corresponds, and the fine-tuning process predominantly skews this task inference towards tasks in the fine-tuning distribution. To test this hypothesis, we propose Conjugate Prompting to see if we can recover pretrained capabilities. Conjugate prompting artificially makes the task look farther from the fine-tun
    
[^38]: 视频-文本检索的统一粗到细对齐方法

    Unified Coarse-to-Fine Alignment for Video-Text Retrieval. (arXiv:2309.10091v1 [cs.CV])

    [http://arxiv.org/abs/2309.10091](http://arxiv.org/abs/2309.10091)

    提出了一种统一粗到细对齐模型UCoFiA，用于视频-文本检索，该模型能够在不同粒度级别上捕捉跨模态相似性信息，并通过交互式相似性聚合模块有效考虑不同视觉特征的重要性，最终解决了视频-文本检索中的精确匹配问题。

    

    视频-文本检索通常利用视觉和文本信息之间的粗粒度或细粒度对齐。然而，根据文本查询检索正确的视频通常具有挑战性，因为它需要能够推理出高级（场景）和低级（对象）视觉线索及其与文本查询的关系。为此，我们提出了一种名为UCoFiA的统一粗到细对齐模型。具体而言，我们的模型在不同粒度级别上捕捉跨模态相似性信息。为减轻无关视觉线索的影响，我们还应用了交互式相似性聚合模块（ISA）来考虑不同视觉特征的重要性，同时聚合跨模态相似性以获得每个粒度的相似度得分。最后，我们应用Sinkhorn-Knopp算法对每个级别的相似性进行标准化，以减轻不同级别上的过度或不足表示问题。

    The canonical approach to video-text retrieval leverages a coarse-grained or fine-grained alignment between visual and textual information. However, retrieving the correct video according to the text query is often challenging as it requires the ability to reason about both high-level (scene) and low-level (object) visual clues and how they relate to the text query. To this end, we propose a Unified Coarse-to-fine Alignment model, dubbed UCoFiA. Specifically, our model captures the cross-modal similarity information at different granularity levels. To alleviate the effect of irrelevant visual clues, we also apply an Interactive Similarity Aggregation module (ISA) to consider the importance of different visual features while aggregating the cross-modal similarity to obtain a similarity score for each granularity. Finally, we apply the Sinkhorn-Knopp algorithm to normalize the similarities of each level before summing them, alleviating over- and under-representation issues at different l
    
[^39]: HTEC: 人类转录错误修正

    HTEC: Human Transcription Error Correction. (arXiv:2309.10089v1 [eess.AS])

    [http://arxiv.org/abs/2309.10089](http://arxiv.org/abs/2309.10089)

    HTEC是一种用于人类转录错误修正的方法，包括错误检测和填充两个阶段，提出了一种综合的修正操作列表，并针对删除错误提出了四种新操作。

    

    高质量的人类转录对于训练和改进自动语音识别（ASR）模型至关重要。最近的研究发现，每增加1%的转录错误率（WER），使用这些转录来训练ASR模型将增加约2%的ASR WER。即使是经过高度培训的注释员也难免出现转录错误。然而，很少有研究探讨人类转录错误的修正方法。其他问题的错误修正方法，如ASR错误修正和语法错误修正，对这个问题的表现不够好。因此，我们提出了HTEC用于人类转录错误修正。HTEC包括两个阶段：Trans-Checker，一种错误检测模型，用于预测和屏蔽错误单词，和Trans-Filler，一种序列到序列的生成模型，用于填充屏蔽位置。我们提出了一个综合的修正操作列表，其中包括四种处理删除错误的新操作。

    High-quality human transcription is essential for training and improving Automatic Speech Recognition (ASR) models. Recent study~\cite{libricrowd} has found that every 1% worse transcription Word Error Rate (WER) increases approximately 2% ASR WER by using the transcriptions to train ASR models. Transcription errors are inevitable for even highly-trained annotators. However, few studies have explored human transcription correction. Error correction methods for other problems, such as ASR error correction and grammatical error correction, do not perform sufficiently for this problem. Therefore, we propose HTEC for Human Transcription Error Correction. HTEC consists of two stages: Trans-Checker, an error detection model that predicts and masks erroneous words, and Trans-Filler, a sequence-to-sequence generative model that fills masked positions. We propose a holistic list of correction operations, including four novel operations handling deletion errors. We further propose a variant of e
    
[^40]: 使用大型语言模型的自动个性化印象生成PET报告

    Automatic Personalized Impression Generation for PET Reports Using Large Language Models. (arXiv:2309.10066v1 [cs.AI])

    [http://arxiv.org/abs/2309.10066](http://arxiv.org/abs/2309.10066)

    本研究旨在使用fine-tuned大型语言模型实现自动个性化生成全身PET报告的准确印象。通过训练语言模型并引入阅读医生的身份信息，模型能够学习医生特定的报告风格。研究结果经过专家评估和核医学医生的质量评分认可，证明该方法在实践中具有潜在的应用价值。

    

    目的：确定通过fine-tuned大型语言模型(LLMs)是否可以为全身PET报告生成准确的个性化印象。材料和方法：使用teacher-forcing算法在PET报告语料库上训练了12个语言模型，输入是报告发现，参考是临床印象。额外的输入标记编码了阅读医生的身份，使模型能够学习医生特定的报告风格。我们的语料库包括2010年至2022年间从我们机构收集的37,370份回顾性PET报告。通过与两名核医学（NM）医生的质量评分进行30个评估指标的基准测试，最匹配的指标选择了用于专家评估的模型。在部分数据子集中，根据6个质量维度和一个总体实用性评分（5分制），三名核医学医生评估了模型生成的印象和原始临床印象。

    Purpose: To determine if fine-tuned large language models (LLMs) can generate accurate, personalized impressions for whole-body PET reports. Materials and Methods: Twelve language models were trained on a corpus of PET reports using the teacher-forcing algorithm, with the report findings as input and the clinical impressions as reference. An extra input token encodes the reading physician's identity, allowing models to learn physician-specific reporting styles. Our corpus comprised 37,370 retrospective PET reports collected from our institution between 2010 and 2022. To identify the best LLM, 30 evaluation metrics were benchmarked against quality scores from two nuclear medicine (NM) physicians, with the most aligned metrics selecting the model for expert evaluation. In a subset of data, model-generated impressions and original clinical impressions were assessed by three NM physicians according to 6 quality dimensions and an overall utility score (5-point scale). Each physician reviewe
    
[^41]: 层级构建器：将文本片段组织成层次结构以促进导航

    Hierarchy Builder: Organizing Textual Spans into a Hierarchy to Facilitate Navigation. (arXiv:2309.10057v1 [cs.CL])

    [http://arxiv.org/abs/2309.10057](http://arxiv.org/abs/2309.10057)

    这个论文介绍了一种层级构建器的方法，可以将信息提取系统生成的大量字符串进行组织和导航，特别适用于医疗信息提取。

    

    信息提取系统通常会产生数百到数千个关于特定主题的字符串。我们提出了一种方法，以在探索性环境中更好地消费这些字符串，其中用户既想获得广泛的概述，又想有机会深入研究某些方面。该系统通过将相似的项目分组并将剩余项目按照层次化可导航的有向无环图结构进行排列。我们将该方法应用于医疗信息提取。

    Information extraction systems often produce hundreds to thousands of strings on a specific topic. We present a method that facilitates better consumption of these strings, in an exploratory setting in which a user wants to both get a broad overview of what's available, and a chance to dive deeper on some aspects. The system works by grouping similar items together and arranging the remaining items into a hierarchical navigable DAG structure. We apply the method to medical information extraction.
    
[^42]: 多模态基础模型：从专业模型到通用助手

    Multimodal Foundation Models: From Specialists to General-Purpose Assistants. (arXiv:2309.10020v1 [cs.CV])

    [http://arxiv.org/abs/2309.10020](http://arxiv.org/abs/2309.10020)

    这项研究调查了多模态基础模型的分类和演化情况，并重点关注了从专业模型到通用助手的过渡。它涵盖了五个核心主题，包括预训练模型和通用助手模型的学习方法以及整合语言模型的统一视觉模型的最新进展。

    

    本文介绍了一项对多模态基础模型的分类和演化的全面调查研究，重点关注从专业模型到通用助手的过渡。研究范围包括五个核心主题，分为两类。第一类是已经建立起来的研究领域：为特定目的而预训练的多模态基础模型，包括两个主题：学习视觉骨干用于视觉理解和文本到图像生成的方法。第二类是最近在探索性、开放的研究领域中取得的进展：旨在扮演通用助手角色的多模态基础模型，包括三个主题：受大型语言模型启发的统一视觉模型、多模态语言模型的端到端训练以及与语言模型进行链式多模态工具的开发。本文的目标读者是研究人员、研究生和计算专业人士。

    This paper presents a comprehensive survey of the taxonomy and evolution of multimodal foundation models that demonstrate vision and vision-language capabilities, focusing on the transition from specialist models to general-purpose assistants. The research landscape encompasses five core topics, categorized into two classes. (i) We start with a survey of well-established research areas: multimodal foundation models pre-trained for specific purposes, including two topics -- methods of learning vision backbones for visual understanding and text-to-image generation. (ii) Then, we present recent advances in exploratory, open research areas: multimodal foundation models that aim to play the role of general-purpose assistants, including three topics -- unified vision models inspired by large language models (LLMs), end-to-end training of multimodal LLMs, and chaining multimodal tools with LLMs. The target audiences of the paper are researchers, graduate students, and professionals in compute
    
[^43]: SYNDICOM: 错误注入和自然语言反馈改进对话常识研究

    SYNDICOM: Improving Conversational Commonsense with Error-Injection and Natural Language Feedback. (arXiv:2309.10015v1 [cs.CL])

    [http://arxiv.org/abs/2309.10015](http://arxiv.org/abs/2309.10015)

    SYNDICOM是一种改进对话常识的方法，包含了一个常识对话数据集和一个基于自然语言反馈的模型，可用于训练对话应答生成模型。

    

    常识推理是人类交流的关键方面。尽管近年来由大型语言模型驱动的对话人工智能取得了进展，但常识推理仍然是一个具有挑战性的任务。在这项工作中，我们介绍了SYNDICOM - 一种改进对话应答生成中常识的方法。SYNDICOM由两个部分组成。第一个组件是一个由知识图创建的常识对话数据集，并以自然语言形式合成。该数据集包括对话环境中的有效和无效回答，以及对无效回答的自然语言反馈（NLF）。第二个贡献是一个两步的过程：训练一个模型来预测无效回答的自然语言反馈（NLF），然后根据预测的NLF、无效回答和对话条件训练一个应答生成模型。SYNDICOM具有可伸缩性，不需要强化学习。通过对三个任务的经验结果进行评估。

    Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce SYNDICOM - a method for improving commonsense in dialogue response generation. SYNDICOM consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue. SYNDICOM is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad
    
[^44]: 基于语言模型的概率测量专利权要求范围的新方法

    A novel approach to measuring patent claim scope based on probabilities obtained from (large) language models. (arXiv:2309.10003v1 [cs.CL])

    [http://arxiv.org/abs/2309.10003](http://arxiv.org/abs/2309.10003)

    本文提出了一种使用概率从语言模型中获得的自信息来测量专利权要求范围的新方法。该方法通过计算要求的发生概率和自信息来评估要求的信息量，进而反映出要求的范围。研究结果表明，不同类型的语言模型对范围测量的影响不同，最简单的模型可以将范围度量简化为单词或字符计数的倒数。此方法在九个系列的专利权要求上进行了验证，结果表明各系列的要求范围逐渐减小。

    

    本文提出了一种将专利权要求的范围测量为该要求所包含的自信息的倒数的方法。这种方法基于信息论，基于一个假设，即罕见的概念比平常的概念更具信息量，因为它更令人惊讶。自信息是从该要求的发生概率计算得出的，其中概率是根据语言模型计算的。本文考虑了五个语言模型，从最简单的模型（每个单词或字符均从均匀分布中抽取）到中等模型（使用平均词或字符频率），再到一个大型语言模型（GPT2）。有趣的是，最简单的语言模型将范围度量减少为单词或字符计数的倒数，这是先前作品中已经使用的度量标准。该方法应用于九个系列的针对不同发明的专利权要求，其中每个系列的要求范围逐渐减小。

    This work proposes to measure the scope of a patent claim as the reciprocal of the self-information contained in this claim. Grounded in information theory, this approach is based on the assumption that a rare concept is more informative than a usual concept, inasmuch as it is more surprising. The self-information is calculated from the probability of occurrence of that claim, where the probability is calculated in accordance with a language model. Five language models are considered, ranging from the simplest models (each word or character is drawn from a uniform distribution) to intermediate models (using average word or character frequencies), to a large language model (GPT2). Interestingly, the simplest language models reduce the scope measure to the reciprocal of the word or character count, a metric already used in previous works. Application is made to nine series of patent claims directed to distinct inventions, where the claims in each series have a gradually decreasing scope.
    
[^45]: 使用文档嵌入和降维方法检测文本数据中的协变漂移

    Detecting covariate drift in text data using document embeddings and dimensionality reduction. (arXiv:2309.10000v1 [cs.LG])

    [http://arxiv.org/abs/2309.10000](http://arxiv.org/abs/2309.10000)

    本研究通过比较不同的文档嵌入、降维技术和漂移检测方法，发现在检测文本数据中的协变漂移方面，特定的嵌入方法、降维技术和漂移检测方法的组合效果优于其他方法。

    

    检测文本数据中的协变漂移对于保持文本分析模型的可靠性和性能至关重要。在这项研究中，我们调查了不同的文档嵌入、降维技术和漂移检测方法对于识别文本数据中的协变漂移的有效性。我们探索了三种流行的文档嵌入方法：使用潜在语义分析（LSA）的词频-逆文档频率（TF-IDF）进行降维，以及使用主成分分析（PCA）进行降维的Doc2Vec和BERT嵌入。为了量化训练数据和测试数据分布之间的差异，我们采用了Kolmogorov-Smirnov（KS）统计量和最大均值差异（MMD）检验作为漂移检测方法。实验结果表明，在检测协变漂移方面，某些嵌入方法、降维技术和漂移检测方法的组合表现优于其他方法。

    Detecting covariate drift in text data is essential for maintaining the reliability and performance of text analysis models. In this research, we investigate the effectiveness of different document embeddings, dimensionality reduction techniques, and drift detection methods for identifying covariate drift in text data. We explore three popular document embeddings: term frequency-inverse document frequency (TF-IDF) using Latent semantic analysis(LSA) for dimentionality reduction and Doc2Vec, and BERT embeddings, with and without using principal component analysis (PCA) for dimensionality reduction. To quantify the divergence between training and test data distributions, we employ the Kolmogorov-Smirnov (KS) statistic and the Maximum Mean Discrepancy (MMD) test as drift detection methods. Experimental results demonstrate that certain combinations of embeddings, dimensionality reduction techniques, and drift detection methods outperform others in detecting covariate drift. Our findings co
    
[^46]: 用音频分类改进非洲裔美国英语的语音识别

    Improving Speech Recognition for African American English With Audio Classification. (arXiv:2309.09996v1 [eess.AS])

    [http://arxiv.org/abs/2309.09996](http://arxiv.org/abs/2309.09996)

    通过使用少量非洲裔美国英语的数据，结合音频分类器和地理信息，我们提出了一种改进美国英语语音识别的方法，相对词错误率减少了38.5%。

    

    自动语音识别(ASR)系统在识别不同语言变种时存在较大的质量差异。为了缓解这个问题，一种方法是使用更具代表性的数据集来训练或微调模型。但是有时候在领域内数据的数量有限，这会使该方法受到限制。我们提出了一种新的方法，利用少量领域外数据(长篇形式的非洲裔美国英语)来提高美国英语短篇语音识别器的鲁棒性。我们使用CORAAL、YouTube和Mozilla Common Voice来训练一个音频分类器，该分类器可以大致判断一句话是非洲裔美国英语还是其他变种，包括主流美国英语。通过将分类器输出与粗略的地理信息结合起来，我们可以从大量未翻译的短篇查询语料库中选择一部分语句进行半监督学习。在此数据上进行微调结果显示相对词错误率减少了38.5%。

    Automatic speech recognition (ASR) systems have been shown to have large quality disparities between the language varieties they are intended or expected to recognize. One way to mitigate this is to train or fine-tune models with more representative datasets. But this approach can be hindered by limited in-domain data for training and evaluation. We propose a new way to improve the robustness of a US English short-form speech recognizer using a small amount of out-of-domain (long-form) African American English (AAE) data. We use CORAAL, YouTube and Mozilla Common Voice to train an audio classifier to approximately output whether an utterance is AAE or some other variety including Mainstream American English (MAE). By combining the classifier output with coarse geographic information, we can select a subset of utterances from a large corpus of untranscribed short-form queries for semi-supervised learning at scale. Fine-tuning on this data results in a 38.5% relative word error rate disp
    
[^47]: OpenAI抄袭了我们的税务案例，但GPT-4真的能够处理税务吗？

    OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?. (arXiv:2309.09992v1 [cs.AI])

    [http://arxiv.org/abs/2309.09992](http://arxiv.org/abs/2309.09992)

    GPT-4在处理税务方面存在问题，无法可靠地计算税务。

    

    作者解释了OpenAI在GPT-4的直播演示中使用税法案例的来源，以及为什么GPT-4得到了错误的答案，以及它如何无法可靠地计算税务。

    The authors explain where OpenAI got the tax law example in its livestream demonstration of GPT-4, why GPT-4 got the wrong answer, and how it fails to reliably calculate taxes.
    
[^48]: 通过程序执行补充进行代码表示预训练

    Code Representation Pre-training with Complements from Program Executions. (arXiv:2309.09980v1 [cs.SE])

    [http://arxiv.org/abs/2309.09980](http://arxiv.org/abs/2309.09980)

    本论文提出了一种名为FuzzPretrain的方法，用于在代码表示预训练中探索由程序的测试用例揭示的动态信息，并解决从代码中直接学习功能语义的挑战。

    

    大型语言模型（LLMs）已被应用于编程语言建模，以推进代码智能化。尽管代码可以以文本格式表示，但为了正确编译或解释以执行一组期望的行为，代码在语法上更加严格。在这种情况下，现有的工作通过抽象语法树、控制流图等形式的句法表示，从代码中以较少的歧义性学习。然而，具有相同目的的程序可以用各种方式实现，显示出不同的句法表示，而具有类似实现的程序可能具有不同的行为。虽然在执行过程中可以轻易地演示这种语义，但功能上的这些语义很难直接从代码中学习，特别是在无监督的情况下。因此，在本文中，我们提出了FuzzPretrain来探索由测试用例揭示的程序的动态信息，并嵌入到代码表示的预训练中。

    Large language models (LLMs) for natural language processing have been grafted onto programming language modeling for advancing code intelligence. Although it can be represented in the text format, code is syntactically more rigorous in order to be properly compiled or interpreted to perform a desired set of behaviors given any inputs. In this case, existing works benefit from syntactic representations to learn from code less ambiguously in the forms of abstract syntax tree, control-flow graph, etc. However, programs with the same purpose can be implemented in various ways showing different syntactic representations while the ones with similar implementations can have distinct behaviors. Though trivially demonstrated during executions, such semantics about functionality are challenging to be learned directly from code, especially in an unsupervised manner. Hence, in this paper, we propose FuzzPretrain to explore the dynamic information of programs revealed by their test cases and embed
    
[^49]: HypR：一个使用参考语料库进行ASR假设修订的全面研究

    HypR: A comprehensive study for ASR hypothesis revising with a reference corpus. (arXiv:2309.09838v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09838](http://arxiv.org/abs/2309.09838)

    本研究集中在发布一个ASR假设修订（HypR）数据集，该数据集包含了几个常用的语料库，并且为ASR模型的修订提供了一个基础。

    

    随着深度学习的发展，自动语音识别（ASR）取得了显著进展。为了进一步提高性能，修订识别结果是一种轻量级但高效的方法之一。各种方法可以大致分为N-best重排序方法和错误修正模型。前者旨在从由ASR生成的一组候选假设中选择错误率最低的假设，用于给定的输入语音。后者则专注于检测给定假设中的识别错误，并纠正这些错误以获得增强的结果。然而，我们观察到这些研究很难相互比较，因为它们通常在不同的语料库上进行评估，与不同的ASR模型配对，并且甚至使用不同的数据集来训练模型。因此，在本研究中，我们首先专注于发布一个ASR假设修订（HypR）数据集。HypR包含几个常用的语料库（AISHELL-1，TED-LIUM 2和LibriSpeech），并且提供了ASR模型的基线系统。

    With the development of deep learning, automatic speech recognition (ASR) has made significant progress. To further enhance the performance, revising recognition results is one of the lightweight but efficient manners. Various methods can be roughly classified into N-best reranking methods and error correction models. The former aims to select the hypothesis with the lowest error rate from a set of candidates generated by ASR for a given input speech. The latter focuses on detecting recognition errors in a given hypothesis and correcting these errors to obtain an enhanced result. However, we observe that these studies are hardly comparable to each other as they are usually evaluated on different corpora, paired with different ASR models, and even use different datasets to train the models. Accordingly, we first concentrate on releasing an ASR hypothesis revising (HypR) dataset in this study. HypR contains several commonly used corpora (AISHELL-1, TED-LIUM 2, and LibriSpeech) and provid
    
[^50]: 观察演讲者：一种用于情感识别的混合连续归属网络，对话中带有情感分离

    Watch the Speakers: A Hybrid Continuous Attribution Network for Emotion Recognition in Conversation With Emotion Disentanglement. (arXiv:2309.09799v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09799](http://arxiv.org/abs/2309.09799)

    本文提出了一种用于情感识别的混合连续归属网络，解决了在对话中情感的延续和归属的问题，并改善了模型在不同情景中的表现。

    

    会话中的情感识别（ERC）在自然语言处理领域引起了广泛关注，因为它具有巨大的实际应用潜力。现有的ERC方法面临着在各种不同情景下泛化的挑战，原因是对上下文建模不足、对对话关系的模糊捕捉不精确以及在讲话者建模中过拟合。在这项工作中，我们提出了一种混合连续属性网络（HCAN），以情感延续和情感归属的视角解决这些问题。具体而言，HCAN采用混合循环和基于注意力的模块来建模全局情感连续性。然后，提出了一种新颖的情感归属编码（EAE）来对每个话语的内部和交叉情感归属进行建模。此外，为了增强模型在说话者建模方面的稳健性，并提高在不同情景下的性能，引入了一个综合的损失函数情感认知损失´EC。

    Emotion Recognition in Conversation (ERC) has attracted widespread attention in the natural language processing field due to its enormous potential for practical applications. Existing ERC methods face challenges in achieving generalization to diverse scenarios due to insufficient modeling of context, ambiguous capture of dialogue relationships and overfitting in speaker modeling. In this work, we present a Hybrid Continuous Attributive Network (HCAN) to address these issues in the perspective of emotional continuation and emotional attribution. Specifically, HCAN adopts a hybrid recurrent and attention-based module to model global emotion continuity. Then a novel Emotional Attribution Encoding (EAE) is proposed to model intra- and inter-emotional attribution for each utterance. Moreover, aiming to enhance the robustness of the model in speaker modeling and improve its performance in different scenarios, A comprehensive loss function emotional cognitive loss $\mathcal{L}_{\rm EC}$ is p
    
[^51]: 通过知识蒸馏促进开放域对话系统中NSFW文本的检测

    Facilitating NSFW Text Detection in Open-Domain Dialogue Systems via Knowledge Distillation. (arXiv:2309.09749v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09749](http://arxiv.org/abs/2309.09749)

    该论文介绍了CensorChat，一个用于监测NSFW对话的数据集，并利用知识蒸馏技术构建了高效的NSFW内容检测器。

    

    在开放域对话系统中，对话中的NSFW（不适合上班）内容可能对用户产生严重影响。然而，在对话上下文中检测NSFW语言，尤其是性爱内容方面的研究明显滞后。为了解决这个问题，我们引入了CensorChat，一个旨在检测NSFW对话的对话监控数据集。利用涉及GPT-4和ChatGPT的知识蒸馏技术，该数据集提供了一种经济高效的构建NSFW内容检测器的方法。该过程涉及收集真实的人机交互数据，并将其分解为单个话语和单轮对话，其中聊天机器人提供最后一句话。使用ChatGPT对无标签数据进行注释，作为训练集。使用ChatGPT和GPT-4作为注释器构建了合理性验证集和测试集，并使用自我批评策略解决标记中的差异。BERT模型用于微调。

    NSFW (Not Safe for Work) content, in the context of a dialogue, can have severe side effects on users in open-domain dialogue systems. However, research on detecting NSFW language, especially sexually explicit content, within a dialogue context has significantly lagged behind. To address this issue, we introduce CensorChat, a dialogue monitoring dataset aimed at NSFW dialogue detection. Leveraging knowledge distillation techniques involving GPT-4 and ChatGPT, this dataset offers a cost-effective means of constructing NSFW content detectors. The process entails collecting real-life human-machine interaction data and breaking it down into single utterances and single-turn dialogues, with the chatbot delivering the final utterance. ChatGPT is employed to annotate unlabeled data, serving as a training set. Rationale validation and test sets are constructed using ChatGPT and GPT-4 as annotators, with a self-criticism strategy for resolving discrepancies in labeling. A BERT model is fine-tun
    
[^52]: LLM4Jobs: 无监督的职业提取和规范化，借助大型语言模型

    LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models. (arXiv:2309.09708v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09708](http://arxiv.org/abs/2309.09708)

    本文介绍了LLM4Jobs无监督的职业提取和规范化方法，通过利用大型语言模型，它展现了超越最新基准的灵活性和多功能性。此外，本研究还提供了合成和真实数据集，可用于相关研究。研究结果表明，现代语言模型有望为复杂的职业提取和规范化任务提供强有力的基础。

    

    自动从自由文本的招聘信息和简历中提取和规范化职业是诸如职位推荐和劳动力市场政策制定等应用中至关重要的。本文介绍了LLM4Jobs，一种利用大型语言模型（LLM）进行职业编码的新型无监督方法。LLM4Jobs独特地利用了LLMs的自然语言理解和生成能力。通过对合成和真实数据集的严格实验评估，我们展示了LLM4Jobs始终超越无监督的最新基准，证明了其在不同数据集和粒度上的多功能性。作为我们工作的一个附带结果，我们提供了合成和真实数据集，这对于该领域的后续研究可能具有重要意义。总体而言，这项调查突显了当代LLMs在复杂的职业提取和规范化任务中的潜力，为建立一个强大的基础。

    Automated occupation extraction and standardization from free-text job postings and resumes are crucial for applications like job recommendation and labor market policy formation. This paper introduces LLM4Jobs, a novel unsupervised methodology that taps into the capabilities of large language models (LLMs) for occupation coding. LLM4Jobs uniquely harnesses both the natural language understanding and generation capacities of LLMs. Evaluated on rigorous experimentation on synthetic and real-world datasets, we demonstrate that LLM4Jobs consistently surpasses unsupervised state-of-the-art benchmarks, demonstrating its versatility across diverse datasets and granularities. As a side result of our work, we present both synthetic and real-world datasets, which may be instrumental for subsequent research in this domain. Overall, this investigation highlights the promise of contemporary LLMs for the intricate task of occupation extraction and standardization, laying the foundation for a robust
    
[^53]: LayoutNUWA: 揭示大型语言模型的隐藏版式专长

    LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models. (arXiv:2309.09506v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.09506](http://arxiv.org/abs/2309.09506)

    LayoutNUWA是第一个将版式生成视为代码生成任务来增强语义信息和利用大型语言模型的隐藏版式专长的模型。

    

    图形版式生成作为一个不断发展的研究领域，在用户参与度和信息感知方面起着重要作用。现有方法主要将版式生成视为数值优化任务，注重定量方面，但忽略了版式的语义信息，如每个版式元素之间的关系。本文提出了LayoutNUWA，这是第一个将版式生成视为代码生成任务的模型，以增强语义信息并利用大型语言模型的隐藏版式专长。具体而言，我们开发了一种称为代码指示调整（Code Instruct Tuning，CIT）的方法，包括三个相互关联的模块：1）代码初始化（Code Initialization，CI）模块将数值条件量化并以HTML代码的形式进行初始化，并放置了策略性的屏蔽；2）代码完成（Code Completion，CC）模块利用语言模型的格式化知识填写HTML代码中的屏蔽部分；3）代码渲染（Code Rendering，CR）模块将完成的代码转化为最终的图形版式。

    Graphic layout generation, a growing research field, plays a significant role in user engagement and information perception. Existing methods primarily treat layout generation as a numerical optimization task, focusing on quantitative aspects while overlooking the semantic information of layout, such as the relationship between each layout element. In this paper, we propose LayoutNUWA, the first model that treats layout generation as a code generation task to enhance semantic information and harness the hidden layout expertise of large language models~(LLMs). More concretely, we develop a Code Instruct Tuning (CIT) approach comprising three interconnected modules: 1) the Code Initialization (CI) module quantifies the numerical conditions and initializes them as HTML code with strategically placed masks; 2) the Code Completion (CC) module employs the formatting knowledge of LLMs to fill in the masked portions within the HTML code; 3) the Code Rendering (CR) module transforms the complet
    
[^54]: 通过语言提示调整和帧级语言适配器提高多语言语音识别能力

    Enhancing Multilingual Speech Recognition through Language Prompt Tuning and Frame-Level Language Adapter. (arXiv:2309.09443v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2309.09443](http://arxiv.org/abs/2309.09443)

    通过语言提示调整和帧级语言适配器这两种简单且参数高效的方法，我们成功提高了多语言语音识别的性能。

    

    最近，多语言智能助手如ChatGPT变得越来越受欢迎。为了进一步扩大多语言人工智能助手的应用，并促进国际交流，提高多语言语音识别性能至关重要。本文提出了两种简单且参数高效的方法：语言提示调整和帧级语言适配器，分别用于增强可配置语言和语言无关的多语言语音识别。此外，我们还探索了使用参数高效微调方法集成这两种方法的可行性。我们的实验结果表明，使用我们提出的方法在七种语言上显著改善了性能。

    Multilingual intelligent assistants, such as ChatGPT, have recently gained popularity. To further expand the applications of multilingual artificial intelligence assistants and facilitate international communication, it is essential to enhance the performance of multilingual speech recognition, which is a crucial component of speech interaction. In this paper, we propose two simple and parameter-efficient methods: language prompt tuning and frame-level language adapter, to respectively enhance language-configurable and language-agnostic multilingual speech recognition. Additionally, we explore the feasibility of integrating these two approaches using parameter-efficient fine-tuning methods. Our experiments demonstrate significant performance improvements across seven languages using our proposed methods.
    
[^55]: Struc-Bench：大型语言模型在生成复杂结构化数据方面表现得真的好吗？

    Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?. (arXiv:2309.08963v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.08963](http://arxiv.org/abs/2309.08963)

    本研究评估了当前大型语言模型（LLMs）在生成复杂结构化数据方面的能力，并提出了一种结构感知的微调方法来改善这种能力。通过使用Struc-Bench和多个代表性的LLMs进行评估，发现了常见的格式错误和潜在改进的领域。通过应用结构感知微调方法，能够显著提高对自然语言约束的遵守程度。

    

    尽管像GPT-4这样的大型语言模型（LLMs）非常强大，但它们在生成需要复杂结构化输出的任务上仍然有困难。在本研究中，我们评估了当前LLMs在生成复杂结构化数据方面的能力，并提出了一种结构感知的微调方法作为改进这种能力的解决方案。为了进行全面评估，我们提出了Struc-Bench，包括五个代表性的LLM（即GPT-NeoX 20B，GPT-3.5，GPT-4和Vicuna），并在我们精心构建的跨原始文本、HTML和LaTeX表的数据集上对它们进行评估。根据我们对当前模型性能的分析，我们确定了特定的常见格式错误和潜在改进的领域。为了解决复杂的格式要求，我们利用FormatCoT（思维链）从目标输出中生成格式指令。我们的实验证明，当将这种结构感知微调方法应用到LLaMA-7B上时，能够显著提高对自然语言约束的遵守程度。

    Despite the power of Large Language Models (LLMs) like GPT-4, they still struggle with tasks that require generating complex, structured outputs. In this study, we assess the capability of Current LLMs in generating complex structured data and propose a structure-aware fine-tuning approach as a solution to improve this ability. To perform a comprehensive evaluation, we propose Struc-Bench, include five representative LLMs (i.e., GPT-NeoX 20B, GPT-3.5, GPT-4, and Vicuna) and evaluate them on our carefully constructed datasets spanning raw text, HTML, and LaTeX tables. Based on our analysis of current model performance, we identify specific common formatting errors and areas of potential improvement. To address complex formatting requirements, we utilize FormatCoT (Chain-of-Thought) to generate format instructions from target outputs. Our experiments show that our structure-aware fine-tuning method, when applied to LLaMA-7B, significantly improves adherence to natural language constraint
    
[^56]: TextBind: 多轮交错多模态指令跟随

    TextBind: Multi-turn Interleaved Multimodal Instruction-following. (arXiv:2309.08637v1 [cs.CL])

    [http://arxiv.org/abs/2309.08637](http://arxiv.org/abs/2309.08637)

    TextBind是一个注释极少的框架，用于将较大规模的语言模型赋予多轮交错多模态指令跟随能力，并通过图像-标题对生成多轮多模态指令-回应对话。这个框架对于解决实际任务具有重要意义，并为未来的研究提供了数据集、模型和演示。

    

    具有指令跟随能力的大型语言模型已经在人工智能领域产生了革命性的影响。这些模型通过其自然语言界面展示了卓越的泛化能力，可以解决各种实际任务。然而，它们的性能在很大程度上依赖于高质量的示例数据，而这往往很难获得。当涉及到多模态指令跟随时，这个挑战变得更加严峻。我们引入了TextBind，这是一个几乎不需要注释的框架，用于赋予较大规模的语言模型多轮交错多模态指令跟随能力。我们的方法仅需要图像-标题对，并从语言模型生成多轮多模态指令-回应对话。我们发布了我们的数据集、模型和演示，以促进未来在多模态指令跟随领域的研究。

    Large language models with instruction-following abilities have revolutionized the field of artificial intelligence. These models show exceptional generalizability to tackle various real-world tasks through their natural language interfaces. However, their performance heavily relies on high-quality exemplar data, which is often difficult to obtain. This challenge is further exacerbated when it comes to multimodal instruction following. We introduce TextBind, an almost annotation-free framework for empowering larger language models with the multi-turn interleaved multimodal instruction-following capabilities. Our approach requires only image-caption pairs and generates multi-turn multimodal instruction-response conversations from a language model. We release our dataset, model, and demo to foster future research in the area of multimodal instruction following.
    
[^57]: 《Media of Langue》的媒体

    Media of Langue. (arXiv:2309.08609v1 [cs.CL])

    [http://arxiv.org/abs/2309.08609](http://arxiv.org/abs/2309.08609)

    该论文介绍了《Media of Langue》这一全新词典和公共雕塑，通过描述不同语言之间的意义地图和两个力量之间的边界，重点介绍了三个新的概念：《Inter-Langue Map/Dictionary》、《Inter-Langue Space》和《Inter-Langue Network》。

    

    本文旨在存档Goki Muramoto等人的《Media of Langue》后面的材料。《Media of Langue》是一个全新的字典和公共雕塑，它仅从“这个词被翻译成那个词”的广泛事件和两个力量之间的边界上描述出不同语言之间的意义地图。首先，介绍了三个新概念：《Inter-Langue Map/Dictionary》、《Inter-Langue Space》和《Inter-Langue Network》并将其与字典、语义空间和语义网络的三个领域进行了比较。接下来，描述了该作品中实施的具体算法和设计。

    This paper aims to archive the materials behind "Media of Langue" by Goki Muramoto et al. Media of Langue is a new dictionary and public sculpture that depicts the map of meaning on the boundary between languages solely from the vast events of "this word was translated into that word" and two forces: repulsion between all words in the same language and attraction between translated words in different languages. First, the three new concepts proposed, Inter-Langue Map/Dictionary, Inter-Langue Space, and then Inter-Langue Network, are introduced, comparing them to the three domains of dictionary, semantic space, and semantic network. Next, the specific algorithms and designs implemented in the work were described.
    
[^58]: 稀疏自编码器在语言模型中发现高度可解释的特征

    Sparse Autoencoders Find Highly Interpretable Features in Language Models. (arXiv:2309.08600v1 [cs.LG])

    [http://arxiv.org/abs/2309.08600](http://arxiv.org/abs/2309.08600)

    本研究通过稀疏自编码器在语言模型中发现了一组高度可解释和单一义的特征，从而解决了神经网络内部多义性的问题。

    

    神经网络内部理解的一个障碍是多义性，其中神经元在多个语义不同的上下文中激活。多义性使我们无法找到简洁的、人类可理解的解释来解释神经网络内部的工作。多义性的一个猜测原因是叠加效应，即神经网络通过将特征分配给激活空间中的一个过完备方向集合，而不是个别神经元，表示更多的特征。在这里，我们尝试使用稀疏自编码器来确定这些方向，以重构语言模型的内部激活。这些自编码器学习到的一组稀疏激活特征比其他方法鉴定出的方向更可解释和单一义，解释性是通过自动化方法衡量的。删除这些特征可以实现精确的模型编辑，例如通过删除这些特征可以改变模型输出。

    One of the roadblocks to a better understanding of neural networks' internals is \textit{polysemanticity}, where neurons appear to activate in multiple, semantically distinct contexts. Polysemanticity prevents us from identifying concise, human-understandable explanations for what neural networks are doing internally. One hypothesised cause of polysemanticity is \textit{superposition}, where neural networks represent more features than they have neurons by assigning features to an overcomplete set of directions in activation space, rather than to individual neurons. Here, we attempt to identify those directions, using sparse autoencoders to reconstruct the internal activations of a language model. These autoencoders learn sets of sparsely activating features that are more interpretable and monosemantic than directions identified by alternative approaches, where interpretability is measured by automated methods. Ablating these features enables precise model editing, for example, by remo
    
[^59]: 基于大型语言模型的代理的崛起和潜力：一项调查

    The Rise and Potential of Large Language Model Based Agents: A Survey. (arXiv:2309.07864v1 [cs.AI])

    [http://arxiv.org/abs/2309.07864](http://arxiv.org/abs/2309.07864)

    基于大型语言模型的代理的崛起和潜力：一项调查。大型语言模型被认为是构建通用人工智能代理的潜在催化剂，许多研究已经取得重要进展。

    

    长期以来，人类一直追求人工智能（AI）达到或超越人类水平的目标，而被认为是实现这一目标的有望方式的AI代理。AI代理是能感知环境、做出决策和采取行动的人工实体。自20世纪中叶以来，人们为开发智能AI代理进行了许多努力。然而，这些努力主要集中在算法或训练策略的进步上，以增强特定能力或在特定任务上的性能。实际上，社区所缺乏的是一个足够通用和强大的模型，作为设计能适应各种场景的AI代理的起点。由于展示出的多功能和显著能力，大型语言模型（LLMs）被视为人工通用智能（AGI）的潜在催化剂，为构建通用AI代理提供了希望。许多研究工作利用LLMs作为构建AI代理的基础，并且已经取得重要的进展。

    For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent AI agents since the mid-20th century. However, these efforts have mainly focused on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a sufficiently general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile and remarkable capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many research efforts have leveraged LLMs as the foundation to build AI agents and ha
    
[^60]: 旅行词：一种变压器的几何解释。

    Traveling Words: A Geometric Interpretation of Transformers. (arXiv:2309.07315v1 [cs.CL])

    [http://arxiv.org/abs/2309.07315](http://arxiv.org/abs/2309.07315)

    本文提出了一种几何视角来解释变压器的内部机制，主要贡献在于阐明了层归一化如何限制潜在特征并在超球面上塑造注意力机制，通过探测预训练的GPT-2模型验证了该视角的有效性，并提供了对变压器的直观理解。

    

    变压器在自然语言处理领域取得了显著的进展，但理解其内部机制仍然是一个挑战。本文介绍了一种新颖的几何视角，阐明了变压器操作的内部机制。我们的主要贡献是说明了层归一化如何将潜在特征限制在一个超球面上，从而使注意力能够在该表面上塑造单词的语义表示。这种几何视点无缝地连接了迭代改进和上下文嵌入等已知属性。我们通过探测一个预训练的124M参数的GPT-2模型验证了我们的见解。我们的发现揭示了早期层中清晰的查询-键注意力模式，并在更深的层次上建立在先前关于注意头的专门性的观察基础上。利用这些几何见解，我们提出了对变压器的直观理解，将其描绘为塑造轨迹的过程。

    Transformers have significantly advanced the field of natural language processing, but comprehending their internal mechanisms remains a challenge. In this paper, we introduce a novel geometric perspective that elucidates the inner mechanisms of transformer operations. Our primary contribution is illustrating how layer normalization confines the latent features to a hyper-sphere, subsequently enabling attention to mold the semantic representation of words on this surface. This geometric viewpoint seamlessly connects established properties such as iterative refinement and contextual embeddings. We validate our insights by probing a pre-trained 124M parameter GPT-2 model. Our findings reveal clear query-key attention patterns in early layers and build upon prior observations regarding the subject-specific nature of attention heads at deeper layers. Harnessing these geometric insights, we present an intuitive understanding of transformers, depicting them as processes that model the trajec
    
[^61]: BHASA：面向大语言模型的东南亚语言和文化综合评估套件

    BHASA: A Holistic Southeast Asian Linguistic and Cultural Evaluation Suite for Large Language Models. (arXiv:2309.06085v1 [cs.CL])

    [http://arxiv.org/abs/2309.06085](http://arxiv.org/abs/2309.06085)

    BHASA是一个综合评估套件，用于评估大语言模型在东南亚语言和文化方面的表现。它包括NLP基准、语言诊断工具包和文化诊断数据集。目前，该套件的初步版本仅针对印度尼西亚语、越南语、泰语和泰米尔语实现。

    

    大型语言模型（LLM）的快速发展和规模带来的新能力使得构建全面、多样和具有挑战性的基准成为必要，如HELM和BIG-bench。然而，目前大部分基准只关注英语的表现，包括东南亚（SEA）语言的评估很少。因此，我们提出了BHASA，一个针对SEA语言的综合语言和文化评估套件。它包括三个组成部分：（1）涵盖自然语言理解（NLU）、生成（NLG）和推理（NLR）任务的NLP基准，共涵盖八个任务；（2）LINDSEA，一个跨越句法、语义和语用等各种语言现象的语言诊断工具包；（3）一份文化诊断数据集，旨在探索文化表达和敏感性。对于这个初步工作，我们只针对印度尼西亚语、越南语、泰语和泰米尔语实现了NLP基准。

    The rapid development of Large Language Models (LLMs) and the emergence of novel abilities with scale have necessitated the construction of holistic, diverse and challenging benchmarks such as HELM and BIG-bench. However, at the moment, most of these benchmarks focus only on performance in English and evaluations that include Southeast Asian (SEA) languages are few in number. We therefore propose BHASA, a holistic linguistic and cultural evaluation suite for LLMs in SEA languages. It comprises three components: (1) a NLP benchmark covering eight tasks across Natural Language Understanding (NLU), Generation (NLG) and Reasoning (NLR) tasks, (2) LINDSEA, a linguistic diagnostic toolkit that spans the gamut of linguistic phenomena including syntax, semantics and pragmatics, and (3) a cultural diagnostics dataset that probes for both cultural representation and sensitivity. For this preliminary effort, we implement the NLP benchmark only for Indonesian, Vietnamese, Thai and Tamil, and we on
    
[^62]: 预训练大型语言模型的网络运维能力的实证研究

    An Empirical Study of NetOps Capability of Pre-Trained Large Language Models. (arXiv:2309.05557v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05557](http://arxiv.org/abs/2309.05557)

    本文通过对预训练大型语言模型（LLMs）进行系统评估，发现LLMs在网络运维（NetOps）领域具有强大的潜力应用，能够提升自动化和智能化的NetOps能力。

    

    大型语言模型（LLMs）可以回答人类语言查询，并在网络运维（NetOps）领域展现出强大的潜力应用。由于具备大量常识知识，LLMs在推理准确性上比传统模型更好，并具有更强的泛化能力、推理能力和代码生成能力，这些能力可能对自动化和智能化的NetOps有巨大的提升。然而，LLMs在各种NetOps任务中的表现仍然未被充分探索。本文系统评估了选择的几种LLMs在NetOps领域的能力、优势和限制。评估针对5732个关于NetOps的问题进行，涵盖了26个公开可用的通用领域LLMs，包括ChatGPT、LLaMA、Falcon等。我们还对其中一些LLMs进行了NetOps语料库的微调，并评估了结果模型的性能。评估方法遵循广泛采用的用于生成任务基准测试的方法。

    Large language models (LLMs) can respond to human language queries and have shown powerful potential applications in network operations (NetOps). Thanks to the large amount of commonsense knowledge inherent, LLMs achieve much better inference accuracy than traditional models and emerge with strong abilities in generalization, reasoning, and code generation. These abilities may have a crucial boost to automated and intelligent NetOps. However, it remains under-explored how well LLMs perform in various NetOps tasks. In this work, we make a systematic assessment of the capabilities, strengths, and limitations of selected LLMs in the field of NetOps. The evaluation is conducted on a collection of 5,732 questions about NetOps, encompassing 26 publicly available general-domain LLMs, including ChatGPT, LLaMA, Falcon, etc. We also finetune some of these LLMs with our collected NetOps corpus and evaluate the resulting models. The evaluation method follows the widely adopted benchmarks for gener
    
[^63]: FOLLOWUPQG:面向信息获取的跟进问题生成

    FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation. (arXiv:2309.05007v1 [cs.CL])

    [http://arxiv.org/abs/2309.05007](http://arxiv.org/abs/2309.05007)

    本文引入了一项真实世界的信息获取跟进问题生成任务，通过生成跟进问题来更深入地理解初始问题和答案。构建了数据集FOLLOWUPQG，评估了当前的问题生成模型在生成跟进问题方面的效果，并展示了其作为一个具有挑战性的基准任务的验证。

    

    人类出于好奇心而提出跟进问题，这反映了人类创造性的认知过程。我们引入了一个真实世界的信息获取跟进问题生成（FQG）任务，旨在生成能够更深入理解初始问题和答案的跟进问题。我们构建了FOLLOWUPQG数据集，包含了来自Reddit论坛的超过3K个真实世界的（初始问题，答案，跟进问题）元组，提供了对开放性问题的非专业人士友好的解释。与现有数据集相比，FOLLOWUPQG中的问题使用更多样化的实用策略来寻求信息，并展示了更高层次的认知技能（如应用和关联）。我们评估了当前的问题生成模型在生成跟进问题方面的效果，探索如何基于逐步演示生成特定类型的跟进问题。我们的结果验证了FOLLOWUPQG作为一个具有挑战性的基准任务。

    Humans ask follow-up questions driven by curiosity, which reflects a creative human cognitive process. We introduce the task of real-world information-seeking follow-up question generation (FQG), which aims to generate follow-up questions seeking a more in-depth understanding of an initial question and answer. We construct FOLLOWUPQG, a dataset of over 3K real-world (initial question, answer, follow-up question) tuples collected from a Reddit forum providing layman-friendly explanations for open-ended questions. In contrast to existing datasets, questions in FOLLOWUPQG use more diverse pragmatic strategies to seek information, and they also show higher-order cognitive skills (such as applying and relating). We evaluate current question generation models on their efficacy for generating follow-up questions, exploring how to generate specific types of follow-up questions based on step-by-step demonstrations. Our results validate FOLLOWUPQG as a challenging benchmark, as model-generated q
    
[^64]: 大型视觉语言模型中幻觉的评估与分析

    Evaluation and Analysis of Hallucination in Large Vision-Language Models. (arXiv:2308.15126v1 [cs.LG])

    [http://arxiv.org/abs/2308.15126](http://arxiv.org/abs/2308.15126)

    本文提出了基于大型语言模型的幻觉评估框架HaELM，可以评估大型视觉语言模型中的幻觉问题，并分析了导致幻觉的因素，并提出了缓解幻觉问题的建议。

    

    最近，大型视觉语言模型（LVLMs）取得了显著的成功。然而，LVLMs仍然存在幻觉问题，这限制了在许多场景中的实用性。幻觉指的是LVLMs响应中不存在于视觉输入中的信息，这可能导致重大后果的潜在风险。目前对LVLMs中的幻觉评估的研究工作有限。在本文中，我们提出了基于大型语言模型（LLM）的幻觉评估框架HaELM。HaELM的性能近似于ChatGPT的95%，并具有低成本、可复现、保护隐私和本地部署等额外优势。利用HaELM，我们评估了当前LVLMs中的幻觉。此外，我们分析了导致LVLMs中幻觉的因素，并提出了缓解幻觉问题的有用建议。

    Large Vision-Language Models (LVLMs) have recently achieved remarkable success. However, LVLMs are still plagued by the hallucination problem, which limits the practicality in many scenarios. Hallucination refers to the information of LVLMs' responses that does not exist in the visual input, which poses potential risks of substantial consequences. There has been limited work studying hallucination evaluation in LVLMs. In this paper, we propose Hallucination Evaluation based on Large Language Models (HaELM), an LLM-based hallucination evaluation framework. HaELM achieves an approximate 95% performance comparable to ChatGPT and has additional advantages including low cost, reproducibility, privacy preservation and local deployment. Leveraging the HaELM, we evaluate the hallucination in current LVLMs. Furthermore, we analyze the factors contributing to hallucination in LVLMs and offer helpful suggestions to mitigate the hallucination problem. Our training data and human annotation halluci
    
[^65]: 注意力不再是唯一需要的东西了。

    Attention Is Not All You Need Anymore. (arXiv:2308.07661v1 [cs.LG])

    [http://arxiv.org/abs/2308.07661](http://arxiv.org/abs/2308.07661)

    本文提出了一种名为Extractor的插入替代器，用于取代Transformer中的自注意机制，实验证明使用Extractor可以提高Transformer的性能，并且具有更短的计算关键路径。

    

    在最近几年中，流行的Transformer架构在自然语言处理和计算机视觉等许多应用领域取得了巨大成功。许多现有的工作旨在通过性能平衡来减少Transformer中自注意机制的计算和存储复杂度。然而，性能对于Transformer的持续成功至关重要。本文提出了一种用于取代Transformer中自注意机制的插入替代器（Extractor）。实验结果表明，使用Extractor替换自注意机制可以提高Transformer的性能。此外，Extractor具有更短的计算关键路径，因此有潜力比自注意更快。此外，本文还使用可变长离散时间马尔可夫链对文本生成中的序列预测问题进行了建模，并针对我们的插入替代器对Transformer进行了评估。

    In recent years, the popular Transformer architecture has achieved great success in many application areas, including natural language processing and computer vision. Many existing works aim to reduce the computational and memory complexity of the self-attention mechanism in the Transformer by trading off performance. However, performance is key for the continuing success of the Transformer. In this paper, a drop-in replacement for the self-attention mechanism in the Transformer, called the Extractor, is proposed. Experimental results show that replacing the self-attention mechanism with the Extractor improves the performance of the Transformer. Furthermore, the proposed Extractor has the potential to run faster than the self-attention since it has a much shorter critical path of computation. Additionally, the sequence prediction problem in the context of text generation is formulated using variable-length discrete-time Markov chains, and the Transformer is reviewed based on our unders
    
[^66]: 基于深度学习的隐喻检测知识注入：综述研究

    Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review. (arXiv:2308.04306v1 [cs.CL])

    [http://arxiv.org/abs/2308.04306](http://arxiv.org/abs/2308.04306)

    本文对基于深度学习的隐喻识别任务中知识注入的研究进展进行了全面综述，包括主流知识和知识注入原则的总结、数据集、评估指标和基准模型的回顾，并探讨了当前的知识注入问题。

    

    隐喻研究的历史也标志着知识注入研究的演变。随着近年来深度学习技术的不断进步，自然语言处理社区对将知识应用于在隐喻识别任务中取得成功结果表现出极大兴趣。尽管在隐喻识别领域涉及知识注入的方法逐渐增加，但缺乏一篇完整的关于基于知识注入的方法的综述文章。因此，本文旨在综述深度学习在隐喻识别任务中应用知识注入的研究进展。本文系统总结和概括了主流的知识和知识注入原则，同时回顾了在隐喻识别任务中使用的数据集、评估指标和基准模型。最后，我们探讨了当前面临的知识注入问题。

    The history of metaphor research also marks the evolution of knowledge infusion research. With the continued advancement of deep learning techniques in recent years, the natural language processing community has shown great interest in applying knowledge to successful results in metaphor recognition tasks. Although there has been a gradual increase in the number of approaches involving knowledge injection in the field of metaphor recognition, there is a lack of a complete review article on knowledge injection based approaches. Therefore, the goal of this paper is to provide a comprehensive review of research advances in the application of deep learning for knowledge injection in metaphor recognition tasks. In this paper, we systematically summarize and generalize the mainstream knowledge and knowledge injection principles, as well as review the datasets, evaluation metrics, and benchmark models used in metaphor recognition tasks. Finally, we explore the current issues facing knowledge 
    
[^67]: Think-on-Graph: 利用知识图谱进行大型语言模型的深度和负责任的推理

    Think-on-Graph: Deep and Responsible Reasoning of Large Language Model with Knowledge Graph. (arXiv:2307.07697v1 [cs.CL])

    [http://arxiv.org/abs/2307.07697](http://arxiv.org/abs/2307.07697)

    Think-on-Graph是一个利用知识图谱增强大型语言模型深度和负责任推理能力的新框架，在复杂的多跳推理问答任务上表现出色，解决了现有方法中存在的限制。

    

    大型语言模型（LLMs）在各种任务中取得了重大进展，但在需要知识追溯性、及时性和准确性至关重要的场景中，它们经常在复杂推理和表现方面遇到困难。为了解决这些限制，我们提出了Think-on-Graph（ToG），这是一个利用知识图谱增强LLMs深度和负责任推理能力的新框架。通过使用ToG，我们可以确定与给定问题相关的实体，并对外部知识数据库进行探索和推理，以检索相关三元组。这个迭代过程生成包含顺序连接的三元组的多个推理路径，直到收集到足够的信息来回答问题或达到最大深度为止。通过在复杂的多跳推理问答任务上的实验证明，ToG优于现有方法，有效地解决了LLMs的前述限制。

    Large language models (LLMs) have made significant strides in various tasks, yet they often struggle with complex reasoning and exhibit poor performance in scenarios where knowledge traceability, timeliness, and accuracy are crucial. To address these limitations, we present Think-on-Graph (ToG), a novel framework that leverages knowledge graphs to enhance LLMs' ability for deep and responsible reasoning. By employing ToG, we can identify entities relevant to a given question and conduct exploration and reasoning to retrieve related triples from an external knowledge database. This iterative procedure generates multiple reasoning pathways consisting of sequentially connected triplets until sufficient information is gathered to answer the question or the maximum depth is reached. Through experiments on complex multi-hop reasoning question-answering tasks, we demonstrate that ToG outperforms existing methods, effectively addressing the aforementioned limitations of LLMs without incurring 
    
[^68]: 迈向填充通用工程设计知识的方法

    Towards Populating Generalizable Engineering Design Knowledge. (arXiv:2307.06985v1 [cs.CL])

    [http://arxiv.org/abs/2307.06985](http://arxiv.org/abs/2307.06985)

    这项研究提出了一种从专利文件中提取工程设计知识的方法，通过构建知识图来填充通用设计知识，并与现有方法进行了比较。

    

    为了填充通用工程设计知识，我们提出了一种从专利文件中提取head entity :: relationship :: tail entity形式事实的方法。这些事实可以在专利文件内部和跨文件之间组合形成知识图，用作表示和存储设计知识的方案。现有的工程设计文献中的方法通常利用一组预定义的关系来填充统计近似而非事实的三元组。在我们的方法中，我们训练一个标记器来识别句子中的实体和关系。在确定了一对实体后，我们训练另一个标记器来识别特定表示这对实体之间关系的关系标记。为了训练这些标记器，我们手动构建了一个包含44,227个句子和相应事实的数据集。我们还将该方法的性能与通常推荐的方法进行了比较，其中我们预.

    Aiming to populate generalizable engineering design knowledge, we propose a method to extract facts of the form head entity :: relationship :: tail entity from sentences found in patent documents. These facts could be combined within and across patent documents to form knowledge graphs that serve as schemes for representing as well as storing design knowledge. Existing methods in engineering design literature often utilise a set of predefined relationships to populate triples that are statistical approximations rather than facts. In our method, we train a tagger to identify both entities and relationships from a sentence. Given a pair of entities thus identified, we train another tagger to identify the relationship tokens that specifically denote the relationship between the pair. For training these taggers, we manually construct a dataset of 44,227 sentences and corresponding facts. We also compare the performance of the method against typically recommended approaches, wherein, we pre
    
[^69]: 通过本体推理对大型企业语言模型进行微调

    Fine-tuning Large Enterprise Language Models via Ontological Reasoning. (arXiv:2306.10723v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.10723](http://arxiv.org/abs/2306.10723)

    通过本体推理构建任务和领域特定的语料库，对大型企业语言模型进行微调。

    

    大型语言模型利用微调作为一种技术，通过任务特定的训练数据来适应多样化的目标。任务特定性应该与领域定向相结合，即将语言模型专门化，以准确地处理给定领域的任务。然而，模型通常通过公开可用的数据进行微调，或者最多只通过数据库中的基础数据进行微调，而忽略了基于业务的定义和领域经验。另一方面，企业知识图谱能够通过本体推理捕获和增加这种领域知识。为了将语言模型的灵活性与企业知识图谱的领域定向相结合，我们提出了一种新颖的神经符号架构，利用本体推理的能力为语言模型的微调构建任务和领域特定的语料库。

    Large Language Models (LLMs) exploit fine-tuning as a technique to adapt to diverse goals, thanks to task-specific training data. Task specificity should go hand in hand with domain orientation, that is, the specialization of an LLM to accurately address the tasks of a given realm of interest. However, models are usually fine-tuned over publicly available data or, at most, over ground data from databases, ignoring business-level definitions and domain experience. On the other hand, Enterprise Knowledge Graphs (EKGs) are able to capture and augment such domain knowledge via ontological reasoning. With the goal of combining LLM flexibility with the domain orientation of EKGs, we propose a novel neurosymbolic architecture that leverages the power of ontological reasoning to build task- and domain-specific corpora for LLM fine-tuning.
    
[^70]: ChatGPT信息的图神经网络用于股票价格预测

    ChatGPT Informed Graph Neural Network for Stock Movement Prediction. (arXiv:2306.03763v1 [q-fin.ST])

    [http://arxiv.org/abs/2306.03763](http://arxiv.org/abs/2306.03763)

    该研究介绍了一种新的框架，利用ChatGPT技术增强图神经网络，能够从财经新闻中提取出不断变化的网络结构，并用于股票价格预测，获得了超过基于深度学习的最新基准的表现，提示了ChatGPT在文本推断和金融预测方面的潜力。

    

    ChatGPT已在各种自然语言处理（NLP）任务中展示了出色的能力。然而，它从时间文本数据（尤其是财经新闻）推断动态网络结构的潜力仍是一个未开发的领域。在这项研究中，我们介绍了一个新的框架，利用ChatGPT的图推断能力来增强图神经网络（GNN）。我们的框架巧妙地从文本数据中提取出不断变化的网络结构，并将这些网络结构融合到图神经网络中，进行后续的预测任务。股票价格预测的实验结果表明，我们的模型始终优于基于深度学习的最新基准。此外，基于我们模型的产出构建的组合展示出更高的年化累计回报、更低的波动性和最大回撤。这种卓越表现突显了ChatGPT用于基于文本的网络推断和金融预测应用的潜力。

    ChatGPT has demonstrated remarkable capabilities across various natural language processing (NLP) tasks. However, its potential for inferring dynamic network structures from temporal textual data, specifically financial news, remains an unexplored frontier. In this research, we introduce a novel framework that leverages ChatGPT's graph inference capabilities to enhance Graph Neural Networks (GNN). Our framework adeptly extracts evolving network structures from textual data, and incorporates these networks into graph neural networks for subsequent predictive tasks. The experimental results from stock movement forecasting indicate our model has consistently outperformed the state-of-the-art Deep Learning-based benchmarks. Furthermore, the portfolios constructed based on our model's outputs demonstrate higher annualized cumulative returns, alongside reduced volatility and maximum drawdown. This superior performance highlights the potential of ChatGPT for text-based network inferences and 
    
[^71]: 使用大型语言模型控制说话风格以实现表现性文本到语音合成

    Using a Large Language Model to Control Speaking Style for Expressive TTS. (arXiv:2305.10321v1 [cs.CL])

    [http://arxiv.org/abs/2305.10321](http://arxiv.org/abs/2305.10321)

    该论文提出了一种使用大型语言模型控制TTS语音表现风格的方法。该方法可为非表现性语料库上的TTS模型提供适当的韵律建议，使其生成表现力更强的语音。

    

    恰当的韵律对于成功的口头交流至关重要。上下文词嵌入已被证明在预测韵律方面有所帮助，但不允许在可能的韵律演绎之间进行选择。基于参考语音的TTS模型试图通过在参考语音样本基础上生成语音来解决这个问题。这些模型可以生成富有表现力的语音，但需要找到适当的参考样本。已经使用足够大的生成语言模型来解决各种与语言相关的任务。我们探讨了这样的模型是否可以用于建议适当的韵律以实现表现性TTS。我们在非表现性语料库上训练TTS模型，然后提示语言模型建议更改音调、能量和持续时间。提示可以为任何任务设计，并根据目标说话风格和对话上下文提示模型进行建议。与基线模型的31.0％相比，所提出的方法在49.9％的情况下被评为最合适的方法。

    Appropriate prosody is critical for successful spoken communication. Contextual word embeddings are proven to be helpful in predicting prosody but do not allow for choosing between plausible prosodic renditions. Reference-based TTS models attempt to address this by conditioning speech generation on a reference speech sample. These models can generate expressive speech but this requires finding an appropriate reference.  Sufficiently large generative language models have been used to solve various language-related tasks. We explore whether such models can be used to suggest appropriate prosody for expressive TTS. We train a TTS model on a non-expressive corpus and then prompt the language model to suggest changes to pitch, energy and duration. The prompt can be designed for any task and we prompt the model to make suggestions based on target speaking style and dialogue context. The proposed method is rated most appropriate in 49.9\% of cases compared to 31.0\% for a baseline model.
    
[^72]: ChatGraph: 通过将ChatGPT的知识转换为图形来实现可解释的文本分类

    ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs. (arXiv:2305.03513v1 [cs.CL])

    [http://arxiv.org/abs/2305.03513](http://arxiv.org/abs/2305.03513)

    ChatGraph通过将ChatGPT的知识转换为图形，提高了文本分类的可解释性和性能

    

    ChatGPT作为最近推出的大型语言模型（LLM），在各种自然语言处理（NLP）任务中展现出卓越的性能。然而，存在两个主要限制阻碍了它的潜在应用：（1）在下游任务上微调的不灵活性和（2）在决策过程中缺乏可解释性。为了解决这些限制，我们提出了一种新颖的框架，利用ChatGPT的能力来进行特定任务（如文本分类），同时提高其可解释性。

    ChatGPT, as a recently launched large language model (LLM), has shown superior performance in various natural language processing (NLP) tasks. However, two major limitations hinder its potential applications: (1) the inflexibility of finetuning on downstream tasks and (2) the lack of interpretability in the decision-making process. To tackle these limitations, we propose a novel framework that leverages the power of ChatGPT for specific tasks, such as text classification, while improving its interpretability. The proposed framework conducts a knowledge graph extraction task to extract refined and structural knowledge from the raw data using ChatGPT. The rich knowledge is then converted into a graph, which is further used to train an interpretable linear classifier to make predictions. To evaluate the effectiveness of our proposed method, we conduct experiments on four datasets. The result shows that our method can significantly improve the performance compared to directly utilizing Cha
    
[^73]: 大语言模型是摘要评估的不同角色扮演者

    Large Language Models are Diverse Role-Players for Summarization Evaluation. (arXiv:2303.15078v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.15078](http://arxiv.org/abs/2303.15078)

    本文提出了一种新的基于LLMs的评估框架，通过比较生成的文本和参考文本的客观和主观维度，提供了全面的评估框架。

    

    文本摘要在许多场景中具有广泛的应用。生成文本的质量评估是一个复杂的问题。语言评估的一个大挑战是现有指标和人工评估之间存在明显的分歧。例如，文档摘要的质量可以通过人工注释者从客观方面（如语法和语义的正确性）以及主观维度（如全面性、简洁性和有趣性）进行评估。大多数自动评估方法（如BLUE/ROUGE）可能无法很好地捕捉以上维度。在本文中，我们提出了一个基于LLMs的新的评估框架，通过比较从客观和主观方面生成的文本和参考文本，提供了全面的评估框架。首先，我们提出了基于角色扮演者提示机制的生成的文本的客观和主观维度的建模。此外，我们还引入了一个上下文。。

    Text summarization has a wide range of applications in many scenarios. The evaluation of the quality of the generated text is a complex problem. A big challenge to language evaluation is that there is a clear divergence between existing metrics and human evaluation. For example, the quality of a document summary can be measured by human annotators from both objective aspects, such as grammatical and semantic correctness, as well as subjective dimensions, such as comprehensiveness, succinctness, and interestingness. Most of the automatic evaluation methods like BLUE/ROUGE may be not able to capture the above dimensions well. In this paper, we propose a new evaluation framework based on LLMs, which provides a comprehensive evaluation framework by comparing generated text and reference text from both objective and subjective aspects. First, we propose to model objective and subjective dimensions of generated text based on roleplayers prompting mechanism. Furthermore, we introduce a contex
    
[^74]: 通过一致性感知元学习实现可靠的神经机器翻译

    Towards Reliable Neural Machine Translation with Consistency-Aware Meta-Learning. (arXiv:2303.10966v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.10966](http://arxiv.org/abs/2303.10966)

    本论文提出了一种一致性感知元学习（CAML）框架，以解决神经机器翻译（NMT）中存在的可靠性问题。该框架通过在外部循环中学习一致的语义等价句子的元表示，并通过内部循环训练一个从元表示到翻译结果的映射，以实现更加可靠的翻译。

    

    神经机器翻译（NMT）在产生高质量翻译方面取得了显著成功。然而，当前的NMT系统缺乏可靠性，其输出常常受到输入中词汇或句法变化的影响，导致翻译质量存在较大的变异。这种限制阻碍了NMT的实用性和可信度。造成这个问题的一个因素是，采用一对一范式训练的NMT模型难以处理源语言多样性现象，即具有相同意义的输入可能以不同方式表达。本研究将这个问题视为一个双层优化问题，并提出了一种从模型无关元学习（MAML）算法推导出的一致性感知元学习（CAML）框架来解决它。具体而言，CAML的NMT模型（命名为CoNMT）首先在外部循环中学习一致的语义等价句子的元表示。随后，通过内部循环训练一个从元表示到翻译结果的映射，以实现更加可靠的翻译。

    Neural machine translation (NMT) has achieved remarkable success in producing high-quality translations. However, current NMT systems suffer from a lack of reliability, as their outputs that are often affected by lexical or syntactic changes in inputs, resulting in large variations in quality. This limitation hinders the practicality and trustworthiness of NMT. A contributing factor to this problem is that NMT models trained with the one-to-one paradigm struggle to handle the source diversity phenomenon, where inputs with the same meaning can be expressed differently. In this work, we treat this problem as a bilevel optimization problem and present a consistency-aware meta-learning (CAML) framework derived from the model-agnostic meta-learning (MAML) algorithm to address it. Specifically, the NMT model with CAML (named CoNMT) first learns a consistent meta representation of semantically equivalent sentences in the outer loop. Subsequently, a mapping from the meta representation to the 
    
[^75]: 应用自动机器翻译技术于教育视频课程

    Applying Automated Machine Translation to Educational Video Courses. (arXiv:2301.03141v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.03141](http://arxiv.org/abs/2301.03141)

    本研究通过自动翻译可汗学院的视频，并利用文本转语音合成和音视频同步技术构建引人入胜的教育视频。我们还提出了两种可靠的翻译置信度估计器，用于高效质量管理和减少人工翻译工作量。最后，我们开发了一个可部署的系统，用于提供翻译视频给用户并收集用户纠正以改进。

    

    通过使用最先进的翻译模型，将可汗学院的视频自动翻译成目标语言，并应用文本转语音合成和音视频同步技术来构建引人入胜的视频。我们还分析和建立了两种可靠的翻译置信度估计器，通过往返翻译的方式高效管理翻译质量并减少人工翻译工作量。最后，我们开发了一个可部署的系统，用于向最终用户提供翻译视频并收集用户纠正以进行迭代改进。

    We studied the capability of automated machine translation in the online video education space by automatically translating Khan Academy videos with state-of-the-art translation models and applying text-to-speech synthesis and audio/video synchronization to build engaging videos in target languages. We also analyzed and established two reliable translation confidence estimators based on round-trip translations in order to efficiently manage translation quality and reduce human translation effort. Finally, we developed a deployable system to deliver translated videos to end users and collect user corrections for iterative improvement.
    
[^76]: 基于语言知识的个性化自发语音合成的实证研究

    Empirical Study Incorporating Linguistic Knowledge on Filled Pauses for Personalized Spontaneous Speech Synthesis. (arXiv:2210.07559v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.07559](http://arxiv.org/abs/2210.07559)

    该论文通过实证研究探讨了基于语言知识的个性化自发语音合成。研究结果揭示了填充式停顿在言语生成中的重要作用，并提出了个性化填充式停顿插入和非个性化填充式停顿预测方法的比较评估。

    

    我们提出了一个基于语言知识的个性化自发语音合成的综合实证研究。随着语音克隆用于阅读风格的语音合成的出现，需要一种新的语音克隆范 paradigm 以实现类似人类和自发式语音合成。因此，我们专注于个性化自发语音合成，既可以克隆个体声音的音色，也可以模拟其言语不流畅。具体而言，我们处理了填充式停顿，这是言语不流畅的主要来源，在心理学和语言学中已被认为在言语生成和交流中起重要作用。为了比较评估个性化填充式停顿插入和非个性化填充式停顿预测方法，我们开发了一种语音合成方法，其中使用了训练有多说话人语料库的非个性化外部填充式停顿预测器。实验结果阐明了填充式停顿的位置-词汇纠缠问题，即需要准确预测位置以实现自然流畅性。

    We present a comprehensive empirical study for personalized spontaneous speech synthesis on the basis of linguistic knowledge. With the advent of voice cloning for reading-style speech synthesis, a new voice cloning paradigm for human-like and spontaneous speech synthesis is required. We, therefore, focus on personalized spontaneous speech synthesis that can clone both the individual's voice timbre and speech disfluency. Specifically, we deal with filled pauses, a major source of speech disfluency, which is known to play an important role in speech generation and communication in psychology and linguistics. To comparatively evaluate personalized filled pause insertion and non-personalized filled pause prediction methods, we developed a speech synthesis method with a non-personalized external filled pause predictor trained with a multi-speaker corpus. The results clarify the position-word entanglement of filled pauses, i.e., the necessity of precisely predicting positions for naturalnes
    
[^77]: 在小成本上对大模型进行差分隐私优化

    Differentially Private Optimization on Large Model at Small Cost. (arXiv:2210.00038v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00038](http://arxiv.org/abs/2210.00038)

    本文提出了一种名为簿记（BK）的技术，实现了差分隐私优化器在大模型和高维数据上的快速训练，并在计算成本上取得了实质性的改进。

    

    差分隐私（DP）优化是学习准确且保护隐私的大型神经网络的标准范式。然而，由于逐样本梯度修剪，DP深度学习的计算成本非常高昂。现有的DP实现比标准（非私有）训练的时间和空间复杂度高2-1000倍。在这项工作中，我们开发了一种新颖的簿记（BK）技术，它实现了现有的DP优化器（从而实现相同的准确性），并在计算成本上有实质性的改进。具体而言，BK使得对大型模型和高维数据进行DP训练的速度和节省内存与标准训练相当，而以前的DP算法可能因内存错误而低效或无法训练。通过复杂度分析和对视觉和语言任务的广泛实验，验证了BK的计算优势。我们的实现达到了最先进的水平（SOTA）。

    Differentially private (DP) optimization is the standard paradigm to learn large neural networks that are accurate and privacy-preserving. The computational cost for DP deep learning, however, is notoriously heavy due to the per-sample gradient clipping. Existing DP implementations are 2-1000X more costly in time and space complexity than the standard (non-private) training. In this work, we develop a novel Book-Keeping (BK) technique that implements existing DP optimizers (thus achieving the same accuracy), with a substantial improvement on the computational cost. Specifically, BK enables DP training on large models and high dimensional data to be roughly as fast and memory-saving as the standard training, whereas previous DP algorithms can be inefficient or incapable of training due to memory error. The computational advantage of BK is supported by the complexity analysis as well as extensive experiments on vision and language tasks. Our implementation achieves state-of-the-art (SOTA
    
[^78]: 学习解耦的检索表示用于最近邻神经机器翻译

    Learning Decoupled Retrieval Representation for Nearest Neighbour Neural Machine Translation. (arXiv:2209.08738v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.08738](http://arxiv.org/abs/2209.08738)

    本文提出了一种学习解耦的检索表示用于最近邻神经机器翻译，通过使用监督对比学习和构建难负样本，改进了检索准确性和BLEU分数。

    

    K-最近邻神经机器翻译（kNN-MT）成功地在测试时通过检索单词级别的表示来引入外部语料库。通常，kNN-MT借用翻译任务中现成的上下文表示（例如最后一个解码器层的输出）作为检索任务的查询向量。在本研究中，我们强调将这两个任务的表示耦合对于细粒度的检索是次优的。为了缓解这个问题，我们利用监督对比学习来学习从原始上下文表示派生的独特检索表示。我们还提出了一种快速有效的构建难负样本的方法。在五个领域的实验结果表明，与原始kNN-MT相比，我们的方法提高了检索准确性和BLEU分数。

    K-Nearest Neighbor Neural Machine Translation (kNN-MT) successfully incorporates external corpus by retrieving word-level representations at test time. Generally, kNN-MT borrows the off-the-shelf context representation in the translation task, e.g., the output of the last decoder layer, as the query vector of the retrieval task. In this work, we highlight that coupling the representations of these two tasks is sub-optimal for fine-grained retrieval. To alleviate it, we leverage supervised contrastive learning to learn the distinctive retrieval representation derived from the original context representation. We also propose a fast and effective approach to constructing hard negative samples. Experimental results on five domains show that our approach improves the retrieval accuracy and BLEU score compared to vanilla kNN-MT.
    
[^79]: 将知识从记忆中解耦：检索增强的提示学习

    Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning. (arXiv:2205.14704v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.14704](http://arxiv.org/abs/2205.14704)

    本论文提出了一种检索增强的提示学习方法，通过将知识从记忆中解耦，帮助模型在泛化和记忆之间取得平衡。

    

    提示学习方法在自然语言处理领域取得了显著的突破，提高了少样本学习的性能，但仍然遵循参数化学习范式；在学习过程中，遗忘和机械记忆问题可能导致不稳定的泛化问题。为了缓解这些限制，我们开发了RetroPrompt，旨在从记忆中将知识解耦，帮助模型在泛化和记忆之间取得平衡。与传统的提示学习方法相比，RetroPrompt从训练实例构建了一个开放式知识库，并在输入、训练和推断过程中实施检索机制，使模型具备了从训练语料库中检索相关上下文用于增强的能力。大量实验证明了RetroPrompt的效果。

    Prompt learning approaches have made waves in natural language processing by inducing better few-shot performance while they still follow a parametric-based learning paradigm; the oblivion and rote memorization problems in learning may encounter unstable generalization issues. Specifically, vanilla prompt learning may struggle to utilize atypical instances by rote during fully-supervised training or overfit shallow patterns with low-shot data. To alleviate such limitations, we develop RetroPrompt with the motivation of decoupling knowledge from memorization to help the model strike a balance between generalization and memorization. In contrast with vanilla prompt learning, RetroPrompt constructs an open-book knowledge-store from training instances and implements a retrieval mechanism during the process of input, training and inference, thus equipping the model with the ability to retrieve related contexts from the training corpus as cues for enhancement. Extensive experiments demonstra
    
[^80]: 关系抽取作为开书考试：检索增强的提示调优

    Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt Tuning. (arXiv:2205.02355v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.02355](http://arxiv.org/abs/2205.02355)

    提出了一种新的半参数学习范式，即检索增强的提示调优，用于关系抽取。通过构建开放式存储库，并使用线性插值的方式，模型能够在推断过程中根据存储库中的记忆信息推断关系。

    

    预训练语言模型通过展示出卓越的少样本学习能力，在关系抽取方面做出了重要贡献。然而，关系抽取的提示调优方法可能仍然无法推广到那些罕见或困难的模式中。我们将关系抽取视为一种开放式考试，并提出了一种新的检索增强的提示调优的半参数学习范式。我们构建了一个开放式存储库，用于检索基于提示的实例表示和相应的关系标签作为记忆的键值对。在推断过程中，模型可以通过线性插值基于PLM的基本输出与存储库上的非参数最近邻分布来推断关系。

    Pre-trained language models have contributed significantly to relation extraction by demonstrating remarkable few-shot learning abilities. However, prompt tuning methods for relation extraction may still fail to generalize to those rare or hard patterns. Note that the previous parametric learning paradigm can be viewed as memorization regarding training data as a book and inference as the close-book test. Those long-tailed or hard patterns can hardly be memorized in parameters given few-shot instances. To this end, we regard RE as an open-book examination and propose a new semiparametric paradigm of retrieval-enhanced prompt tuning for relation extraction. We construct an open-book datastore for retrieval regarding prompt-based instance representations and corresponding relation labels as memorized key-value pairs. During inference, the model can infer relations by linearly interpolating the base output of PLM with the non-parametric nearest neighbor distribution over the datastore. In
    
[^81]: 面向预训练语言模型的对比演示调优

    Contrastive Demonstration Tuning for Pre-trained Language Models. (arXiv:2204.04392v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.04392](http://arxiv.org/abs/2204.04392)

    本论文提出了一种名为对比演示调优的方法，可以在低数据场景下有效激发预训练语言模型的能力。实验结果表明，该方法与先前的提示调优方法相结合可以取得更好的性能。

    

    在低数据场景中，使用文本提示或演示可以有效地激发预训练语言模型的能力。最近的研究主要集中在自动搜索离散或连续提示或优化语言表达者，但对于演示的研究仍然有限。具体来说，演示示例对于最终的提示调优性能至关重要。本文提出了一种新颖的可插拔、可扩展和高效的方法，称为对比演示调优，它不需要进行演示采样。此外，该方法能够：（i）嵌入到任何先前的提示调优方法中；（ii）扩展到具有大量类别的广泛分类任务中。在16个数据集上的实验结果表明，我们的方法与先前的LM-BFF和P-tuning方法相结合可以得到更好的性能。代码可在https://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning中获得。

    Pretrained language models can be effectively stimulated by textual prompts or demonstrations, especially in low-data scenarios. Recent works have focused on automatically searching discrete or continuous prompts or optimized verbalizers, yet studies for the demonstration are still limited. Concretely, the demonstration examples are crucial for an excellent final performance of prompt-tuning. In this paper, we propose a novel pluggable, extensible, and efficient approach named contrastive demonstration tuning, which is free of demonstration sampling. Furthermore, the proposed approach can be: (i) Plugged into any previous prompt-tuning approaches; (ii) Extended to widespread classification tasks with a large number of categories. Experimental results on 16 datasets illustrate that our method integrated with previous approaches LM-BFF and P-tuning can yield better performance. Code is available in https://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning.
    
[^82]: 探索使用统一的文本到文本转换器进行迁移学习的极限

    Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. (arXiv:1910.10683v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1910.10683](http://arxiv.org/abs/1910.10683)

    本文通过引入一种统一的框架，将所有基于文本的语言问题转换为文本到文本格式，从而探索了NLP中的迁移学习技术的全貌，通过对多个任务进行系统研究，实现了许多基准测试上的最新结果。

    

    迁移学习已经成为自然语言处理(NLP)中一种强大的技术，其中模型在进行下游任务的微调之前首先在数据丰富的任务上进行预训练。迁移学习的有效性催生了多种方法、方法论和实践。本文通过引入一种将所有基于文本的语言问题转换为文本到文本格式的统一框架，探索了NLP中的迁移学习技术的全貌。我们对许多语言理解任务进行了系统性的研究，比较了预训练目标、架构、无标签数据集、迁移方法和其他因素。通过将我们探索的见解与规模和我们的新的“庞大干净抓取语料库”相结合，在许多涉及摘要、问答、文本分类等基准测试上取得了最新的成果。为了促进NLP领域的未来迁移学习研究，我们发布了我们的数据集、预训练模型等。

    Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained mode
    

