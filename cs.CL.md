# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Testing of Detection Tools for AI-Generated Text.](http://arxiv.org/abs/2306.15666) | 本文研究了人工智能生成文本的检测工具的功能，并对其进行了评估。研究发现，现有的检测工具既不准确也不可靠。 |
| [^2] | [SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design.](http://arxiv.org/abs/2306.15656) | SparseOptimizer是一种深度学习优化器，通过Moreau-Yosida正则化在大型语言模型中引入稀疏性。它采用嵌入的收缩操作符，无需对代码进行修改即可适应各种大型语言模型，并在各种基准数据集上实现与密集型模型相当的性能，同时减少参数数量。 |
| [^3] | [Style-transfer based Speech and Audio-visual Scene Understanding for Robot Action Sequence Acquisition from Videos.](http://arxiv.org/abs/2306.15644) | 本文介绍了一种从指令视频中生成机器人动作序列的方法，使用音视Transformer将音视特征和指令语音转换为机器人动作序列，并利用基于风格转移的训练来提高模型的性能。 |
| [^4] | [Automatic Annotation of Direct Speech in Written French Narratives.](http://arxiv.org/abs/2306.15634) | 本论文旨在为法语中的自动注释直接言语（AADS）创建一个统一的框架。研究采用最大的法语叙述数据集进行了广泛评估，结果表明该任务仍需大量努力，并强调了不同基线模型的特点。 |
| [^5] | [Constructing Multilingual Code Search Dataset Using Neural Machine Translation.](http://arxiv.org/abs/2306.15604) | 该论文利用神经机器翻译模型创建了一个多语言代码检索数据集，并通过预训练和微调Transformer模型，在多个代码检索测试集上取得了最佳效果。研究结果表明，翻译质量对模型性能有一定影响，但数据规模更为重要。 |
| [^6] | [Extending Context Window of Large Language Models via Positional Interpolation.](http://arxiv.org/abs/2306.15595) | 通过位置插值方法，我们可以在最小微调的情况下将RoPE-based预训练语言模型的上下文窗口扩展到最多32768，并在多个任务上获得强有力的实证结果。通过线性降低输入位置索引的大小，我们保持了扩展模型在原始上下文窗口内任务的质量。 |
| [^7] | [CrunchGPT: A chatGPT assisted framework for scientific machine learning.](http://arxiv.org/abs/2306.15551) | CrunchGPT是一个基于ChatGPT的科学机器学习辅助框架，通过简单的用户提示来协调整个科学机器学习的工作流程，实现无缝集成数据和物理知识，解决了SciML在预处理、问题建模、代码生成、后处理和分析等方面的耗时问题，拓展了其工业应用和数字孪生框架的适用性。 |
| [^8] | [CamemBERT-bio: a Tasty French Language Model Better for your Health.](http://arxiv.org/abs/2306.15550) | 本研究介绍了CamemBERT-bio，它是一种针对法语生物医学领域专门设计的语言模型，相对于通用模型在命名实体识别任务上平均提高了2.54个百分点。 |
| [^9] | [Unleashing the Power of User Reviews: Exploring Airline Choices at Catania Airport, Italy.](http://arxiv.org/abs/2306.15541) | 本研究通过使用新工具，探讨了社会影响机制与航空公司选择之间的关系，并通过对用户评论的分析，提供了关于卡塔尼亚机场航空生态系统中航空公司的重要见解。 |
| [^10] | [Paradigm Shift in Sustainability Disclosure Analysis: Empowering Stakeholders with CHATREPORT, a Language Model-Based Tool.](http://arxiv.org/abs/2306.15518) | 本研究提出了一种利用专家知识来增强大型语言模型的方法，通过自动化分析企业可持续性报告，将其与气候相关金融披露任务组的建议进行对比。该方法有助于解决人力分析成本高、缺乏透明度等问题。 |
| [^11] | [Using Large Language Models to Provide Explanatory Feedback to Human Tutors.](http://arxiv.org/abs/2306.15498) | 本文介绍了使用大型语言模型为人类导师提供解释性反馈的研究。通过两种方法，在在线课程中实时为导师提供有关如何给学生有效赞扬的反馈。其中一种方法使用了大型语言模型的命名实体识别技术，可以更好地提供解释性反馈。 |
| [^12] | [Understanding Social Reasoning in Language Models with Language Models.](http://arxiv.org/abs/2306.15448) | 这项研究提出了一种新的框架，通过填充因果模板来生成对大型语言模型（LLMs）进行评估，从而解决了之前评估结果不一致和现有评估方法的有效性存在疑虑的挑战。使用这个框架，他们创建了一个新的社交推理基准（BigToM），并发现人类参与者评价这个基准的质量更高。 |
| [^13] | [Are aligned neural networks adversarially aligned?.](http://arxiv.org/abs/2306.15447) | 我们研究了大型语言模型在面对对抗用户构建的对抗性输入时是否仍能保持对齐。我们发现现有的攻击手法不足以可靠攻击对齐文本模型，并通过蛮力方法找到了对抗性输入。 |
| [^14] | [KnowPrefix-Tuning: A Two-Stage Prefix-Tuning Framework for Knowledge-Grounded Dialogue Generation.](http://arxiv.org/abs/2306.15430) | KnowPrefix-Tuning是一种知识驱动对话生成的两阶段前缀调优框架，通过将先验知识注入到轻量级知识前缀中来避免检索过程，与PLM进行全面交互优化响应生成的过程。 |
| [^15] | [Phase Space Analysis of Cardiac Spectra.](http://arxiv.org/abs/2306.15425) | 本研究通过相空间分析心脏频谱，找到了心脏疾病的改善方法，并提出了一种适用于多通道生理信号的快速和稳健的诊断方法。 |
| [^16] | [Quality Estimation of Machine Translated Texts based on Direct Evidence from Training Data.](http://arxiv.org/abs/2306.15399) | 本文研究了基于训练数据直接证据的机器翻译质量评估方法，实验结果表明这种方法对于纯数据驱动的机器翻译系统具有潜力。 |
| [^17] | [Exploiting Pseudo Future Contexts for Emotion Recognition in Conversations.](http://arxiv.org/abs/2306.15376) | 该论文探索了利用伪未来上下文改进对话情感识别。通过使用预训练语言模型生成未来上下文，可以融合历史上下文和说话人特定上下文，形成一个简单的多上下文集成框架。实验结果表明该方法优越性。 |
| [^18] | [The Architecture of a Biologically Plausible Language Organ.](http://arxiv.org/abs/2306.15364) | 本研究提出了一个模拟的生物学上可信的语言器官，通过赫布连可塑性实现了从有限数量的句子的有意义输入中学习名词、动词及其意义。这一研究超越了以前的解析器设计，添加了一个生物学上可信的机制来解释婴儿大脑如何习得语言。 |
| [^19] | [3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement.](http://arxiv.org/abs/2306.15354) | 3D-Speaker是一个大规模的多设备、多距离和多方言语音语料库，用于研究语音表示解缠。它包含了10,000多个说话人的数据，可以用来评估大型通用语音模型和探索域外学习和自监督学习方法。 |
| [^20] | [Understanding Client Reactions in Online Mental Health Counseling.](http://arxiv.org/abs/2306.15334) | 本研究通过开发一个注释框架，深入研究了在线心理健康咨询中客户的反应。通过收集和分析大规模的基于文本的咨询数据集，我们展示了客户如何反应咨询师的策略以及这些反应对咨询结果的影响，并探讨了咨询师如何根据客户的反应调整策略。 |
| [^21] | [Gender Bias in BERT -- Measuring and Analysing Biases through Sentiment Rating in a Realistic Downstream Classification Task.](http://arxiv.org/abs/2306.15298) | 该论文通过引入新的偏见度量方法，并在一个现实的IMDB电影分类器的例子中对BERT的性别偏见进行了全面分析。研究结果表明，公开的BERT模型中存在着显著的性别偏见，并强调了负责任使用的重要性。 |
| [^22] | [IDOL: Indicator-oriented Logic Pre-training for Logical Reasoning.](http://arxiv.org/abs/2306.15273) | IDOL是一种面向逻辑推理的指标导向预训练方法，通过使用逻辑指标和逻辑丰富的数据集在逻辑上增强了预训练模型。IDOL在逻辑推理MRC基准测试中取得了最先进的性能，并且具有竞争力的综合语言理解能力。 |
| [^23] | [Can Pretrained Language Models Derive Correct Semantics from Corrupt Subwords under Noise?.](http://arxiv.org/abs/2306.15268) | 本研究评估了预训练语言模型对噪音引起的不同分割错误的鲁棒性。实验结果表明，如果噪音引入不同的子词、小的子词片段或大量的额外子词，特别是插入在其他子词中，PLMs将无法准确计算单词的含义。 |
| [^24] | [A Survey on Out-of-Distribution Evaluation of Neural NLP Models.](http://arxiv.org/abs/2306.15261) | 本调研对神经NLP模型的离域评估的对抗性鲁棒性、领域泛化和数据集偏差三个研究方向进行了比较和总结，并强调了未来工作的挑战和机遇。 |
| [^25] | [GroundNLQ @ Ego4D Natural Language Queries Challenge 2023.](http://arxiv.org/abs/2306.15255) | GroundNLQ是一个用于自然语言查询挑战的创新标注模型，通过采用两阶段的预训练策略和多模态多尺度的标注模块，实现了在视频中的准确标注，获得了较好的性能表现。 |
| [^26] | [MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for Situated Neural Dialogue Generation.](http://arxiv.org/abs/2306.15253) | MindDial是一个使用心智模拟进行信念动态跟踪的对话生成框架，可以在场景化环境中生成自由对话来协商共识。 |
| [^27] | [C-PMI: Conditional Pointwise Mutual Information for Turn-level Dialogue Evaluation.](http://arxiv.org/abs/2306.15245) | 本研究提出了一种基于条件点对点互信息的模型-无关方法，用于衡量对话系统与用户之间的交互，通过替换评分器，显著改进了与人类判断的相关性。 |
| [^28] | [Emulating Reader Behaviors for Fake News Detection.](http://arxiv.org/abs/2306.15231) | 本文提出了一种模拟读者行为的方法（Ember）用于社交媒体上的假新闻检测，通过纳入读者的阅读和验证过程，从组件角度全面建模新闻，以提高假新闻检测的效果和真实性。 |
| [^29] | [Learning to Rank in Generative Retrieval.](http://arxiv.org/abs/2306.15222) | 这篇论文介绍了一种将生成式检索和经典的学习排序范例相结合的方法，通过使用段落排序损失来训练自回归模型，直接优化自回归模型朝着最优解优化。 |
| [^30] | [Reducing the gap between streaming and non-streaming Transducer-based ASR by adaptive two-stage knowledge distillation.](http://arxiv.org/abs/2306.15171) | 提出了一个自适应两阶段知识蒸馏的方法，通过学习隐藏层和输出层的分布一致性来缩小流式与非流式转导式自动语音识别之间的差距。该方法在词错误率上实现了19%的相对降低，并且对第一个令牌的响应更快。 |
| [^31] | [DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization.](http://arxiv.org/abs/2306.15164) | 本论文介绍了一种新颖的方法DSRM，通过最小化分布偏移风险而不是使用对抗样本来对抗训练，从而提高了深度语言模型的鲁棒性，减少了时间消耗。 |
| [^32] | [YouTube-ASL: A Large-Scale, Open-Domain American Sign Language-English Parallel Corpus.](http://arxiv.org/abs/2306.15162) | 本文介绍了一个大规模的、开放领域的美国手语-英语平行语料库YouTube-ASL，包含了约1000小时的美国手语视频和超过2500位独特的签名者。研究者在此语料库上训练了手语到英语翻译的模型，并在另一个数据集上实现了最新的最佳效果。 |
| [^33] | [Investigating Cross-Domain Behaviors of BERT in Review Understanding.](http://arxiv.org/abs/2306.15123) | 该研究调查了在产品评论理解的各种任务中，BERT模型在不同域上的跨域行为。尽管单域模型在对应域上略有提高，多域模型在评估多域数据时表现更好，并且在平均测试中也更优。尽管单域模型微调可以提高准确性，但会增加计算资源消耗。 |
| [^34] | [FeedbackMap: a tool for making sense of open-ended survey responses.](http://arxiv.org/abs/2306.15112) | FeedbackMap是一个基于网络的工具，利用自然语言处理技术来分析开放性调查回答。它可以生成多层次的摘要，识别有趣的回答示例，并通过嵌入方式可视化回答空间。由于总结方法可能引入偏见，需要对回答者的声音进行批判性评估。 |
| [^35] | [Structured Dialogue Discourse Parsing.](http://arxiv.org/abs/2306.15103) | 本文提出了一种结构化对话话语分析的方法，从编码和解码两个角度改进了先前的工作，并通过对邻接矩阵进行结构化编码，以及使用修改后的Chiu-Liu-Edmonds算法进行结构化推理来优化对话中的链接和关系。 |
| [^36] | [Understanding In-Context Learning via Supportive Pretraining Data.](http://arxiv.org/abs/2306.15091) | 通过研究预训练数据，我们发现支持性预训练数据中的罕见且长尾的词对于上下文学习非常重要。这些发现有助于提高语言模型在各种NLP任务中的性能。 |
| [^37] | [WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models.](http://arxiv.org/abs/2306.15087) | WinoQueer是一个社区协同基准，旨在衡量大型语言模型是否存在对LGBTQ+社区有害的偏见。研究发现现成模型普遍存在相当大的反同偏见，通过在该社区撰写或由该社区成员撰写的数据上进行微调，可以在一定程度上减轻偏见。 |
| [^38] | [Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression.](http://arxiv.org/abs/2306.15063) | 预训练的transformer在回归问题中展现了非贝叶斯上下文学习能力，其在任务多样性阈值以下表现类似于贝叶斯估计器，而在阈值以上明显优于贝叶斯估计器，与岭回归一致。 |
| [^39] | [DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.](http://arxiv.org/abs/2306.15006) | 本研究提出了DNABERT-2，一个用于多种物种基因组的高效基础模型和基准。我们通过使用基于统计的数据压缩算法Byte Pair Encoding（BPE）替代传统的k-mer标记化，克服了k-mer标记化的计算和样本效率问题，并取得了重要进展。 |
| [^40] | [The Art of Embedding Fusion: Optimizing Hate Speech Detection.](http://arxiv.org/abs/2306.14939) | 这项工作研究了优化仇恨言论检测的方法。研究发现，尽管嵌入的组合会略微提高性能，但计算成本很高，并且组合方式对结果的影响较小。 |
| [^41] | [Integrating Bidirectional Long Short-Term Memory with Subword Embedding for Authorship Attribution.](http://arxiv.org/abs/2306.14933) | 这项研究提出了一种将双向长短期记忆网络与子词嵌入相结合的方法，用于解决作者归属问题。该方法能够在处理文本中的隐含词问题的同时保留词的顺序上下文。 |
| [^42] | [LLM-Assisted Content Analysis: Using Large Language Models to Support Deductive Coding.](http://arxiv.org/abs/2306.14924) | 本研究探索了使用大型语言模型（LLMs）来减少演绎编码所需时间的方法，同时保留传统内容分析的灵活性。通过一个案例研究和经验基准测试，证明了在不同演绎编码任务上，GPT-3.5在LLM辅助内容分析（LACA）中的有效性。 |
| [^43] | [Product Information Extraction using ChatGPT.](http://arxiv.org/abs/2306.14921) | 使用ChatGPT进行产品信息提取，解决了传统方法对大量训练数据和泛化到未知属性和属性值的困难，为电子商务应用提供了可能的解决方案。 |
| [^44] | [Utilizing Natural Language Processing for Automated Assessment of Classroom Discussion.](http://arxiv.org/abs/2306.14918) | 本研究利用自然语言处理技术，通过自动生成细化标准得分，实现对课堂讨论质量的自动评估。实验结果令人鼓舞，同时指出标准仍有改进空间，并发现不同的NLP方法对不同的标准更有效。 |
| [^45] | [Towards Enriched Controllability for Educational Question Generation.](http://arxiv.org/abs/2306.14917) | 本研究旨在通过引入新的引导属性（问题明确性）来丰富教育问题生成的可控性。我们提出了通过控制生成明确和隐含wh-问题的方法。研究展示了通过问题明确性和叙事要素同时控制问题生成的初步证据。 |
| [^46] | [FSUIE: A Novel Fuzzy Span Mechanism for Universal Information Extraction.](http://arxiv.org/abs/2306.14913) | FSUIE是一种用于普适信息抽取的新型模糊跨度机制，通过引入模糊跨度损失和模糊跨度注意力，能够在快速收敛和少量数据训练轮数的情况下显著提高信息抽取的性能。 |
| [^47] | ["You might think about slightly revising the title": identifying hedges in peer-tutoring interactions.](http://arxiv.org/abs/2306.14911) | 该研究利用多模态同伴辅导数据集构建了一个计算框架，用于识别同伴辅导互动中的措辞。最佳表现的是一个混合方法，它比现有基准更好且更容易解释，并发现了一些新特征。 |
| [^48] | [The Importance of Human-Labeled Data in the Era of LLMs.](http://arxiv.org/abs/2306.14910) | 本文论述了在LLMs时代，人标记数据仍然具有重要性的论据和支持。 |
| [^49] | [Clickbait Classification and Spoiling Using Natural Language Processing.](http://arxiv.org/abs/2306.14907) | 本文针对点击诱饵标题进行分类和剧透的任务。对于分类任务，提出了两个二元分类器来确定最终的剧透类型；对于剧透任务，采用问答模型和大型语言模型生成剧透信息。实验证明，所提出的模型在任务1中优于基准模型。 |
| [^50] | [PRISMA-DFLLM: An Extension of PRISMA for Systematic Literature Reviews using Domain-specific Finetuned Large Language Models.](http://arxiv.org/abs/2306.14905) | PRISMA-DFLLM是将大型语言模型(LLMs)与PRISMA的严格报告指南相结合，通过在领域特定的学术论文上进行微调，提高了系统文献综述的效率和可扩展性，同时开启了新的研究机遇。 |
| [^51] | [Detect Depression from Social Networks with Sentiment Knowledge Sharing.](http://arxiv.org/abs/2306.14903) | 本论文通过深度学习技术以及情感知识共享，从社交网络消息中识别抑郁症的潜在迹象，旨在提供早期心理健康状况识别的方法。 |
| [^52] | [InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback.](http://arxiv.org/abs/2306.14898) | InterCode是一个交互式编码的标准化和基准测试框架，它使用执行反馈作为观察，并提供了安全可重现的执行环境，可以用于开发新的交互式代码生成方法。 |
| [^53] | [Kosmos-2: Grounding Multimodal Large Language Models to the World.](http://arxiv.org/abs/2306.14824) | Kosmos-2是一个多模态大规模语言模型，可以感知物体描述并将文本与视觉世界联系起来。它在多个任务上展示了出色表现，包括多模态接地、多模态引用、感知语言任务以及语言理解和生成。 |
| [^54] | [Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation.](http://arxiv.org/abs/2306.14514) | 本文介绍了一种基于数据驱动的正式敏感机器翻译方法，通过语言特定处理和合成数据生成，显著改进了翻译性能。 |
| [^55] | [Cross-Language Speech Emotion Recognition Using Multimodal Dual Attention Transformers.](http://arxiv.org/abs/2306.13804) | 提出一种多模态双重注意力变换器（MDAT）模型，利用预训练模型进行多模态特征提取，通过引入图形注意和共同关注机制来捕捉不同情感的跨模态依赖，并使用最少的目标语言数据实现改进的跨语言情感识别结果。 |
| [^56] | [Margin Maximization in Attention Mechanism.](http://arxiv.org/abs/2306.13596) | 这篇论文证明了，在softmax-attention模型中，通过在p或等价的W上运行梯度下降，可以收敛到一个最大边缘解，这将局部最优的标记与非最优的标记分隔开。这明确地将注意力机制形式化为标记分离机制。 |
| [^57] | [Learning Descriptive Image Captioning via Semipermeable Maximum Likelihood Estimation.](http://arxiv.org/abs/2306.13460) | 本文通过半透过最大似然估计方法，鼓励模型生成更详细的长字幕。 |
| [^58] | [DiversiGATE: A Comprehensive Framework for Reliable Large Language Models.](http://arxiv.org/abs/2306.13230) | DiversiGATE是一个统一框架，汇集了多种LLM验证方法，其中包括自一致性、数学提示和WebGPT，同时提出了一个符合该框架的新模型“SelfLearner”，该模型可以从自己的输出中学习并优化性能，在实验中表现良好，GSM8K基准测试上提高了7%的性能。 |
| [^59] | [Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models.](http://arxiv.org/abs/2306.08952) | 本研究提出了一个全面的探测数据集来评估大型语言模型的时间推理能力，并提出了一种使用时间跨度提取和时敏性强化学习的新型学习框架来改进大型语言模型的时间推理能力。实验结果表明该方法的有效性。 |
| [^60] | [Survey on Sociodemographic Bias in Natural Language Processing.](http://arxiv.org/abs/2306.08158) | 本文调查了209篇关于NLP模型偏见的论文，其中大部分涉及社会人口统计偏见。研究者提出了社会人口统计偏见的定义，并确定了NLP偏见研究的三个主要类别。当前去偏见技术只是隐藏了偏见而不是真正去除它，需要进一步改进。 |
| [^61] | [LLMZip: Lossless Text Compression using Large Language Models.](http://arxiv.org/abs/2306.04050) | 本研究使用大型语言模型提出了一种结合预测和无损压缩方案的英文文本压缩算法，并在初步实验中表现优于当前最先进的文本压缩方案。 |
| [^62] | [Language Models are Bounded Pragmatic Speakers.](http://arxiv.org/abs/2305.17760) | 本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。经过人类反馈的强化学习微调的大型语言模型具有概念上类似于 快与慢思考模型的思维模型，而这种思维模型被归因于人类。此研究凸显了采用认知概率建模方法对语言模型的理解、评估和推进的价值。 |
| [^63] | [Cross-Attention is Not Enough: Incongruity-Aware Multimodal Sentiment Analysis and Emotion Recognition.](http://arxiv.org/abs/2305.13583) | 本文提出了一种基于不协调感知的跨模态情感分析方法，通过Hierarchical Crossmodal Transformer with Modality Gating(HCT-MG)模型来确定主要模态并分层融合辅助模态，有效减轻模态之间的不协调感知和信息冗余问题。 |
| [^64] | [Debiased Automatic Speech Recognition for Dysarthric Speech via Sample Reweighting with Sample Affinity Test.](http://arxiv.org/abs/2305.13108) | 本文提出了一种样本重新加权与样本关联测试（Re-SAT）的新方法，用于缓解失语症患者的偏差问题，在不影响健康患者语音的ASR性能的情况下，有效提高了ASR的性能表现。 |
| [^65] | [Constructing Word-Context-Coupled Space Aligned with Associative Knowledge Relations for Interpretable Language Modeling.](http://arxiv.org/abs/2305.11543) | 本文提出了一种可解释的语言建模方法，通过构建词-上下文耦合空间，并引入联想知识网络和上下文相对距离作为语义特征，实现了语言建模可解释性的提高。 |
| [^66] | [Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers.](http://arxiv.org/abs/2305.07011) | 本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。 |
| [^67] | [mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive Pre-Training of Transformers for Few- and Zero-shot Framing Detection.](http://arxiv.org/abs/2303.09901) | 本研究提出了mCPT模型用于多语言的、多标签的零样本或少样本的框架检测任务，并在西班牙语和其他8种语言中取得了良好的成绩。该方案采用了基于多语言变压器的预训练程序，使用标签感知对比损失函数。 |
| [^68] | [Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering.](http://arxiv.org/abs/2303.05352) | 本论文提出了ChatExtract方法，使用先进的对话式语言模型和提示工程，自动从研究论文中提取准确的数据，不需要大量的前期努力和背景知识。 |
| [^69] | [SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks.](http://arxiv.org/abs/2302.13939) | 本论文提出了一种称之为SpikeGPT的生成语言模型，使用二进制、事件驱动脉冲激活单元进行训练，克服了SNN训练中的挑战性。该模型可以用于大规模语言生成任务。 |
| [^70] | [Auditing large language models: a three-layered approach.](http://arxiv.org/abs/2302.08500) | 本文提出了一个三层次的方法来审计大型语言模型（LLMs），包括治理审计、模型审计和应用审计，解决LLMs带来的伦理和社会挑战。 |
| [^71] | [Mu$^{2}$SLAM: Multitask, Multilingual Speech and Language Models.](http://arxiv.org/abs/2212.09553) | Mu$^{2}$SLAM是一个多语言的语音和语言模型，通过使用未标记的语音和文本进行预训练，以及利用监督任务提高跨语言和跨模态表示对齐，取得了在CoVoST AST上新的最高性能，并与使用RNN微调的mSLAM模型在Voxpopuli ASR上性能相当。 |
| [^72] | [WACO: Word-Aligned Contrastive Learning for Speech Translation.](http://arxiv.org/abs/2212.09359) | WACO是一种用于极低资源语音到文本翻译的简单而有效的方法，通过对比学习将语音和文本的词级表示连接起来，实验证明WACO在极低资源条件下比基线方法提高了9+ BLEU分。 |
| [^73] | [Imagination is All You Need! Curved Contrastive Learning for Abstract Sequence Modeling Utilized on Long Short-Term Dialogue Planning.](http://arxiv.org/abs/2211.07591) | 本文介绍了一种新颖的表示学习技术——曲线对比学习（CCL），用于学习多轮对话中发言对之间的相对转弯距离。利用这种技术可以将目标发言和回复候选项映射到潜在空间中，通过余弦相似性评估候选发言和目标之间的距离。此外，该方法还探索了如何通过曲线空间中的余弦相似度评估序列的可能性，从而想象未来对话模式的可能性。 |
| [^74] | [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model.](http://arxiv.org/abs/2211.05100) | BLOOM是一个由数百名研究人员合作设计和构建的拥有176B参数的开放式语言模型，它在多种基准测试中表现出竞争性的性能，并在进行多任务提示微调后表现更强。该模型的发布有助于推动大型语言模型技术的民主化。 |
| [^75] | [SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control.](http://arxiv.org/abs/2210.17432) | SSD-LM是一种半自回归的扩散语言模型，通过在解码时灵活生成文本块并实现本地上下文更新，以及在自然词汇空间上进行扩散，实现了分类器指导和模块化控制。在无约束文本生成基准上，SSD-LM与自回归模型相比，在质量和多样性方面表现出色，并且显著超越了其他基于扩散的模型。 |
| [^76] | [Blank Collapse: Compressing CTC emission for the faster decoding.](http://arxiv.org/abs/2210.17017) | 本文提出了一种省略折叠的方法，通过压缩CTC发射来加快解码速度。实验结果表明，在LibriSpeech数据集上，这种方法可以达到比普通解码快78%的速度，并且准确度的损失非常小。这种方法不仅在实践中有效，而且在理论上有数学依据。 |
| [^77] | [What Do Compressed Multilingual Machine Translation Models Forget?.](http://arxiv.org/abs/2205.10828) | 本研究评估了压缩方法对多语言神经机器翻译模型在不同语言群体、性别和语义偏差方面的影响，并发现代表性不足的语言性能显著下降。 |
| [^78] | [Zero-Shot Dialogue Disentanglement by Self-Supervised Entangled Response Selection.](http://arxiv.org/abs/2110.12646) | 本文提出了一种新的零样本对话解缠方法，通过自我监督的纠缠响应选择，无需标注数据即可实现对长篇多参与者对话的分解，并在实验中获得了较好的聚类F1分数。 |
| [^79] | [When Does Translation Require Context? A Data-driven, Multilingual Exploration.](http://arxiv.org/abs/2109.07446) | 本研究开发了多语言语篇感知基准，系统性地确定了需要上下文翻译的现象。发现上下文感知机器翻译模型对于解决这些现象的困难程度有限，为进一步研究提供了挑战。 |
| [^80] | [Neural Topic Modeling with Continual Lifelong Learning.](http://arxiv.org/abs/2006.10909) | 本研究提出了一个具有持续终身学习的神经主题建模框架，可以处理数据稀疏性，并通过知识的持续积累和转移来提高主题建模的效果。 |
| [^81] | [Explainable and Discourse Topic-aware Neural Language Understanding.](http://arxiv.org/abs/2006.10632) | 该论文提出了一个新颖的神经复合语言模型，通过引入可解释性的主题表示和句子级的主题对话，将主题模型和语言模型相结合。实验结果表明，在多个任务上，该模型显示出了良好的性能。 |

# 详细

[^1]: AI-生成文本检测工具的测试

    Testing of Detection Tools for AI-Generated Text. (arXiv:2306.15666v1 [cs.CL])

    [http://arxiv.org/abs/2306.15666](http://arxiv.org/abs/2306.15666)

    本文研究了人工智能生成文本的检测工具的功能，并对其进行了评估。研究发现，现有的检测工具既不准确也不可靠。

    

    最近，生成式预训练变形器大语言模型的发展强调了在学术环境中不公平使用人工智能生成内容的潜在风险，并加强了寻找检测此类内容解决方案的努力。本文研究了人工智能生成文本的检测工具的一般功能，并根据准确性和错误类型分析对其进行评估。具体而言，该研究旨在回答以下研究问题：现有的检测工具是否能可靠地区分人类编写的文本和ChatGPT生成的文本，以及机器翻译和内容混淆技术是否影响对AI生成文本的检测。研究涵盖了12种公开可用的工具和两个广泛应用于学术环境中的商业系统（Turnitin和PlagiarismCheck）。研究人员得出结论，现有的检测工具既不准确也不可靠，并且存在主要的可辨识错误。

    Recent advances in generative pre-trained transformer large language models have emphasised the potential risks of unfair use of artificial intelligence (AI) generated content in an academic environment and intensified efforts in searching for solutions to detect such content. The paper examines the general functionality of detection tools for artificial intelligence generated text and evaluates them based on accuracy and error type analysis. Specifically, the study seeks to answer research questions about whether existing detection tools can reliably differentiate between human-written text and ChatGPT-generated text, and whether machine translation and content obfuscation techniques affect the detection of AIgenerated text. The research covers 12 publicly available tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely used in the academic setting. The researchers conclude that the available detection tools are neither accurate nor reliable and have a main bi
    
[^2]: SparseOptimizer: 通过Moreau-Yosida正则化来降低语言模型的稀疏性，并通过编译器共同设计来加速

    SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design. (arXiv:2306.15656v1 [cs.LG])

    [http://arxiv.org/abs/2306.15656](http://arxiv.org/abs/2306.15656)

    SparseOptimizer是一种深度学习优化器，通过Moreau-Yosida正则化在大型语言模型中引入稀疏性。它采用嵌入的收缩操作符，无需对代码进行修改即可适应各种大型语言模型，并在各种基准数据集上实现与密集型模型相当的性能，同时减少参数数量。

    

    本文介绍了SparseOptimizer，一种新颖的深度学习优化器，通过Moreau-Yosida正则化在大型语言模型（如BERT，ALBERT和GPT）中自然地引入稀疏性。SparseOptimizer设计的关键是嵌入的收缩操作符，它在优化过程中直接引入稀疏性。这个操作符通过坚实的理论框架支持，并包含了一个分析解，从而增强了优化器的鲁棒性和效果。重要的是，SparseOptimizer的即插即用功能消除了对代码修改的需求，使其成为适用于各种大型语言模型的通用适应工具。在GLUE、RACE、SQuAD1和SQuAD2等基准数据集上的实证评估表明，通过SparseOptimizer稀疏化后的SparseBERT和SparseALBERT在性能上与密集型的BERT和ALBERT相当，同时显著减少了参数数量。

    This paper introduces SparseOptimizer, a novel deep learning optimizer that exploits Moreau-Yosida regularization to naturally induce sparsity in large language models such as BERT, ALBERT and GPT. Key to the design of SparseOptimizer is an embedded shrinkage operator, which imparts sparsity directly within the optimization process. This operator, backed by a sound theoretical framework, includes an analytical solution, thereby reinforcing the optimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play functionality eradicates the need for code modifications, making it a universally adaptable tool for a wide array of large language models. Empirical evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2 confirm that SparseBERT and SparseALBERT, when sparsified using SparseOptimizer, achieve performance comparable to their dense counterparts, BERT and ALBERT, while significantly reducing their parameter count. Further, this work proposes an innovati
    
[^3]: 基于风格转移的语音与视听场景理解方法用于从视频中获取机器人动作序列

    Style-transfer based Speech and Audio-visual Scene Understanding for Robot Action Sequence Acquisition from Videos. (arXiv:2306.15644v1 [cs.CL])

    [http://arxiv.org/abs/2306.15644](http://arxiv.org/abs/2306.15644)

    本文介绍了一种从指令视频中生成机器人动作序列的方法，使用音视Transformer将音视特征和指令语音转换为机器人动作序列，并利用基于风格转移的训练来提高模型的性能。

    

    为了实现人机协作，机器人需要根据有限的先验知识执行新任务的动作，根据人类的指令执行。人类专家可以通过多模态指令的演示向机器人分享执行任务的知识，展示一系列短暂步骤来实现一个长期目标。本文介绍了一种从指令视频中生成机器人动作序列的方法，使用(1)音视Transformer将音视特征和指令语音转换为称为动态运动原理(DMPs)的机器人动作序列，以及(2)基于风格转移的训练，利用视频字幕和语义分类器进行多任务学习和弱监督学习，以利用不配对的视频动作数据。我们构建了一个系统，实现了各种烹饪动作，其中一个臂式机器人使用音视Transformer执行从烹饪视频中获取的DMP序列。在Epic-K实验中进行了实验。

    To realize human-robot collaboration, robots need to execute actions for new tasks according to human instructions given finite prior knowledge. Human experts can share their knowledge of how to perform a task with a robot through multi-modal instructions in their demonstrations, showing a sequence of short-horizon steps to achieve a long-horizon goal. This paper introduces a method for robot action sequence generation from instruction videos using (1) an audio-visual Transformer that converts audio-visual features and instruction speech to a sequence of robot actions called dynamic movement primitives (DMPs) and (2) style-transfer-based training that employs multi-task learning with video captioning and weakly-supervised learning with a semantic classifier to exploit unpaired video-action data. We built a system that accomplishes various cooking actions, where an arm robot executes a DMP sequence acquired from a cooking video using the audio-visual Transformer. Experiments with Epic-K
    
[^4]: 自动注释法语书面叙述中的直接言语

    Automatic Annotation of Direct Speech in Written French Narratives. (arXiv:2306.15634v1 [cs.CL])

    [http://arxiv.org/abs/2306.15634](http://arxiv.org/abs/2306.15634)

    本论文旨在为法语中的自动注释直接言语（AADS）创建一个统一的框架。研究采用最大的法语叙述数据集进行了广泛评估，结果表明该任务仍需大量努力，并强调了不同基线模型的特点。

    

    自动注释法语书面文本中的直接言语（AADS）经常在计算机叙述理解中使用。已经研究了基于规则或深度神经网络的方法，特别是针对英语或德语。然而，对于我们的目标语言法语，很少有相关研究。我们的目标是创建一个统一的框架，用于设计和评估法语中的AADS模型。为此，我们整合了迄今为止标注有每个单词的最大的法语叙述数据集；我们针对序列标注或其他语言的AADS适应了各种基线模型；并且我们设计并进行了广泛评估，重点是泛化能力。结果表明，这个任务仍然需要大量的工作，并强调了每个基线模型的特点。尽管这个框架可以改进，但它是鼓励更多关于这个主题的研究的一步。

    The automatic annotation of direct speech (AADS) in written text has been often used in computational narrative understanding. Methods based on either rules or deep neural networks have been explored, in particular for English or German languages. Yet, for French, our target language, not many works exist. Our goal is to create a unified framework to design and evaluate AADS models in French. For this, we consolidated the largest-to-date French narrative dataset annotated with DS per word; we adapted various baselines for sequence labelling or from AADS in other languages; and we designed and conducted an extensive evaluation focused on generalisation. Results show that the task still requires substantial efforts and emphasise characteristics of each baseline. Although this framework could be improved, it is a step further to encourage more research on the topic.
    
[^5]: 使用神经机器翻译构建多语言代码检索数据集

    Constructing Multilingual Code Search Dataset Using Neural Machine Translation. (arXiv:2306.15604v1 [cs.CL])

    [http://arxiv.org/abs/2306.15604](http://arxiv.org/abs/2306.15604)

    该论文利用神经机器翻译模型创建了一个多语言代码检索数据集，并通过预训练和微调Transformer模型，在多个代码检索测试集上取得了最佳效果。研究结果表明，翻译质量对模型性能有一定影响，但数据规模更为重要。

    

    代码检索是一项寻找与给定自然语言查询语义匹配的编程代码的任务。尽管某些现有数据集在编程语言一侧是多语言的，但它们的查询数据仅限于英语。在这项研究中，我们利用神经机器翻译模型创建了一个包含四种自然语言和四种编程语言的多语言代码检索数据集。使用我们的数据集，我们对基于Transformer的模型进行预训练和微调，然后在多个代码检索测试集上进行评估。我们的结果表明，在大多数情况下，使用所有自然语言和编程语言数据进行预训练的模型表现最好。通过对我们的数据集应用反向翻译数据过滤，我们证明翻译质量在一定程度上影响模型的性能，但数据规模更为重要。

    Code search is a task to find programming codes that semantically match the given natural language queries. Even though some of the existing datasets for this task are multilingual on the programming language side, their query data are only in English. In this research, we create a multilingual code search dataset in four natural and four programming languages using a neural machine translation model. Using our dataset, we pre-train and fine-tune the Transformer-based models and then evaluate them on multiple code search test sets. Our results show that the model pre-trained with all natural and programming language data has performed best in most cases. By applying back-translation data filtering to our dataset, we demonstrate that the translation quality affects the model's performance to a certain extent, but the data size matters more.
    
[^6]: 通过位置插值扩展大型语言模型的上下文窗口

    Extending Context Window of Large Language Models via Positional Interpolation. (arXiv:2306.15595v1 [cs.CL])

    [http://arxiv.org/abs/2306.15595](http://arxiv.org/abs/2306.15595)

    通过位置插值方法，我们可以在最小微调的情况下将RoPE-based预训练语言模型的上下文窗口扩展到最多32768，并在多个任务上获得强有力的实证结果。通过线性降低输入位置索引的大小，我们保持了扩展模型在原始上下文窗口内任务的质量。

    

    我们提出了一种位置插值（PI）方法，可以在最小微调的情况下将RoPE-based预训练语言模型（如LLaMA模型）的上下文窗口大小扩展到最多32768，并且在需要长上下文的各种任务（包括密钥检索、语言建模和长篇文档摘要等）上展现出良好的实证结果。同时，通过位置插值扩展的模型在原始上下文窗口内的任务中相对保持良好的质量。为了实现这一目标，位置插值线性地降低输入位置索引的大小，以匹配原始的上下文窗口大小，而不是超过训练时上下文长度，这可能会导致严重的高注意力分数，完全破坏自注意机制。我们的理论研究表明，插值的上界至少是推断的上界的$\sim 600 \times$要小，进一步证明了其稳定性。

    We present Position Interpolation (PI) that extends the context window sizes of RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal fine-tuning (within 1000 steps), while demonstrating strong empirical results on various tasks that require long context, including passkey retrieval, language modeling, and long document summarization from LLaMA 7B to 65B. Meanwhile, the extended model by Position Interpolation preserve quality relatively well on tasks within its original context window. To achieve this goal, Position Interpolation linearly down-scales the input position indices to match the original context window size, rather than extrapolating beyond the trained context length which may lead to catastrophically high attention scores that completely ruin the self-attention mechanism. Our theoretical study shows that the upper bound of interpolation is at least $\sim 600 \times$ smaller than that of extrapolation, further demonstrating its stability. Models extend
    
[^7]: CrunchGPT：基于ChatGPT的科学机器学习辅助框架

    CrunchGPT: A chatGPT assisted framework for scientific machine learning. (arXiv:2306.15551v1 [cs.LG])

    [http://arxiv.org/abs/2306.15551](http://arxiv.org/abs/2306.15551)

    CrunchGPT是一个基于ChatGPT的科学机器学习辅助框架，通过简单的用户提示来协调整个科学机器学习的工作流程，实现无缝集成数据和物理知识，解决了SciML在预处理、问题建模、代码生成、后处理和分析等方面的耗时问题，拓展了其工业应用和数字孪生框架的适用性。

    

    科学机器学习（SciML）近年来在计算科学和工程的许多不同领域取得了进展。其目标是在不需要复杂和计算密集的数据同化方案的情况下，无缝地将数据和物理知识集成起来。然而，预处理、问题建模、代码生成、后处理和分析仍然是耗时的，并且可能限制SciML在工业应用和数字孪生框架中的广泛适用性。在这里，我们将SciML的各个阶段整合到ChatGPT的伞下，形成CrunchGPT，它通过用户简单的提示来协调整个SciML的工作流程。具体而言，我们提供了两个示例，演示了CrunchGPT在气动学中优化机翼和在各种几何形状中获得流场的潜在用途，并强调了验证阶段。为了演示CrunchGPT的流程和

    Scientific Machine Learning (SciML) has advanced recently across many different areas in computational science and engineering. The objective is to integrate data and physics seamlessly without the need of employing elaborate and computationally taxing data assimilation schemes. However, preprocessing, problem formulation, code generation, postprocessing and analysis are still time consuming and may prevent SciML from wide applicability in industrial applications and in digital twin frameworks. Here, we integrate the various stages of SciML under the umbrella of ChatGPT, to formulate CrunchGPT, which plays the role of a conductor orchestrating the entire workflow of SciML based on simple prompts by the user. Specifically, we present two examples that demonstrate the potential use of CrunchGPT in optimizing airfoils in aerodynamics, and in obtaining flow fields in various geometries in interactive mode, with emphasis on the validation stage. To demonstrate the flow of the CrunchGPT, and
    
[^8]: CamemBERT-bio：一种更健康的法语语言模型

    CamemBERT-bio: a Tasty French Language Model Better for your Health. (arXiv:2306.15550v1 [cs.CL])

    [http://arxiv.org/abs/2306.15550](http://arxiv.org/abs/2306.15550)

    本研究介绍了CamemBERT-bio，它是一种针对法语生物医学领域专门设计的语言模型，相对于通用模型在命名实体识别任务上平均提高了2.54个百分点。

    

    通过临床数据仓库，医院中的临床数据变得越来越容易用于研究，然而这些文件都是非结构化的。因此，需要从医疗报告中提取信息以进行临床研究。使用CamemBERT等BERT-like模型的迁移学习已经取得了重大进展，特别是命名实体识别方面。然而，这些模型是为通用语言训练的，在生物医学数据上效果较弱。因此，我们提出了一种新的法语公共生物医学数据集，对CamemBERT进行了继续预训练。因此，我们介绍了CamemBERT-bio的第一个版本，它是一种为法语生物医学领域专门设计的公共模型，在不同的生物医学命名实体识别任务上平均F1分数提高了2.54个百分点。

    Clinical data in hospitals are increasingly accessible for research through clinical data warehouses, however these documents are unstructured. It is therefore necessary to extract information from medical reports to conduct clinical studies. Transfer learning with BERT-like models such as CamemBERT has allowed major advances, especially for named entity recognition. However, these models are trained for plain language and are less efficient on biomedical data. This is why we propose a new French public biomedical dataset on which we have continued the pre-training of CamemBERT. Thus, we introduce a first version of CamemBERT-bio, a specialized public model for the French biomedical domain that shows 2.54 points of F1 score improvement on average on different biomedical named entity recognition tasks.
    
[^9]: 解放用户评论的力量：探索意大利卡塔尼亚机场的航空公司选择

    Unleashing the Power of User Reviews: Exploring Airline Choices at Catania Airport, Italy. (arXiv:2306.15541v1 [cs.CL])

    [http://arxiv.org/abs/2306.15541](http://arxiv.org/abs/2306.15541)

    本研究通过使用新工具，探讨了社会影响机制与航空公司选择之间的关系，并通过对用户评论的分析，提供了关于卡塔尼亚机场航空生态系统中航空公司的重要见解。

    

    本研究旨在通过使用新工具，探讨社会影响机制与航空公司选择之间的可能关系，以进一步了解影响消费者在航空领域决策的因素。我们选择从知名平台Trustpilot、Google和Twitter中提取用户评论。通过结合网络爬取技术，我们能够收集到包含各种用户意见、反馈和评分的全面数据集。然后，我们优化了BERT模型，以便更好地聚焦航空公司评论中的有见地的情感。通过分析，我们观察到不同航空公司平均负面情感得分的有趣趋势，这使我们更深入地了解了航空公司之间的动态，帮助我们识别卡塔尼亚机场航空生态系统中的关键合作伙伴、热门航线和扮演核心角色的航空公司。

    This study aims to investigate the possible relationship between the mechanisms of social influence and the choice of airline, through the use of new tools, with the aim of understanding whether they can contribute to a better understanding of the factors influencing the decisions of consumers in the aviation sector. We have chosen to extract user reviews from well-known platforms: Trustpilot, Google, and Twitter. By combining web scraping techniques, we have been able to collect a comprehensive dataset comprising a wide range of user opinions, feedback, and ratings. We then refined the BERT model to focus on insightful sentiment in the context of airline reviews. Through our analysis, we observed an intriguing trend of average negative sentiment scores across various airlines, giving us deeper insight into the dynamics between airlines and helping us identify key partnerships, popular routes, and airlines that play a central role in the aeronautical ecosystem of Catania airport during
    
[^10]: 可持续披露分析中的范式转变：利用基于语言模型的工具CHATREPORT赋予利益相关者权力

    Paradigm Shift in Sustainability Disclosure Analysis: Empowering Stakeholders with CHATREPORT, a Language Model-Based Tool. (arXiv:2306.15518v1 [cs.CL])

    [http://arxiv.org/abs/2306.15518](http://arxiv.org/abs/2306.15518)

    本研究提出了一种利用专家知识来增强大型语言模型的方法，通过自动化分析企业可持续性报告，将其与气候相关金融披露任务组的建议进行对比。该方法有助于解决人力分析成本高、缺乏透明度等问题。

    

    本文介绍了一种新颖的方法，通过将专家知识与大型语言模型（LLMs）相结合，自动分析企业可持续性报告，并将其与《气候相关金融披露任务组》（TCFD）建议进行基准对比。企业可持续性报告对于评估组织的环境和社会风险和影响至关重要。然而，分析这些报告中大量的信息往往会导致人力成本过高。因此，全球只有少数机构有资源来分析这些报告，这可能导致缺乏透明度。虽然AI驱动的工具可以自动分析数据，但由于缺乏领域专业知识，它们容易出现不准确性。本文介绍了一种新颖的方法，以增强LLMs的专业知识，自动分析企业可持续性报告。我们将其命名为CHATREPORT工具，并在第一个应用案例中将其应用于评估企业的气候风险披露。

    This paper introduces a novel approach to enhance Large Language Models (LLMs) with expert knowledge to automate the analysis of corporate sustainability reports by benchmarking them against the Task Force for Climate-Related Financial Disclosures (TCFD) recommendations. Corporate sustainability reports are crucial in assessing organizations' environmental and social risks and impacts. However, analyzing these reports' vast amounts of information makes human analysis often too costly. As a result, only a few entities worldwide have the resources to analyze these reports, which could lead to a lack of transparency. While AI-powered tools can automatically analyze the data, they are prone to inaccuracies as they lack domain-specific expertise. This paper introduces a novel approach to enhance LLMs with expert knowledge to automate the analysis of corporate sustainability reports. We christen our tool CHATREPORT, and apply it in a first use case to assess corporate climate risk disclosure
    
[^11]: 使用大型语言模型为人类导师提供解释性反馈

    Using Large Language Models to Provide Explanatory Feedback to Human Tutors. (arXiv:2306.15498v1 [cs.CL])

    [http://arxiv.org/abs/2306.15498](http://arxiv.org/abs/2306.15498)

    本文介绍了使用大型语言模型为人类导师提供解释性反馈的研究。通过两种方法，在在线课程中实时为导师提供有关如何给学生有效赞扬的反馈。其中一种方法使用了大型语言模型的命名实体识别技术，可以更好地提供解释性反馈。

    

    研究表明，学习者在产生解释以支持他们的推理过程时，对学习有积极影响。然而，提供学习者实时的解释性反馈常常面临与分类准确性相关的挑战，特别是在包含复杂和微妙的情境响应的领域专用环境中。我们提出了两种方法，在在线课程中为导师提供有关如何给学生有效赞扬的实时反馈。这项进行中的工作在纠正性反馈（F1分数=0.811）和成果导向反馈（F1分数=0.350）的二分类方面表现出了相当高的准确性。更重要的是，我们引入了利用大型语言模型的命名实体识别来提供解释性反馈的改进方法，这不仅可以在课程中为导师提供反馈，还可以潜在地提出实时措施。

    Research demonstrates learners engaging in the process of producing explanations to support their reasoning, can have a positive impact on learning. However, providing learners real-time explanatory feedback often presents challenges related to classification accuracy, particularly in domain-specific environments, containing situationally complex and nuanced responses. We present two approaches for supplying tutors real-time feedback within an online lesson on how to give students effective praise. This work-in-progress demonstrates considerable accuracy in binary classification for corrective feedback of effective, or effort-based (F1 score = 0.811), and ineffective, or outcome-based (F1 score = 0.350), praise responses. More notably, we introduce progress towards an enhanced approach of providing explanatory feedback using large language model-facilitated named entity recognition, which can provide tutors feedback, not only while engaging in lessons, but can potentially suggest real-
    
[^12]: 通过语言模型理解语言模型中的社交推理

    Understanding Social Reasoning in Language Models with Language Models. (arXiv:2306.15448v1 [cs.CL])

    [http://arxiv.org/abs/2306.15448](http://arxiv.org/abs/2306.15448)

    这项研究提出了一种新的框架，通过填充因果模板来生成对大型语言模型（LLMs）进行评估，从而解决了之前评估结果不一致和现有评估方法的有效性存在疑虑的挑战。使用这个框架，他们创建了一个新的社交推理基准（BigToM），并发现人类参与者评价这个基准的质量更高。

    

    随着大型语言模型（LLM）越来越多地融入到我们的日常生活中，了解它们理解人类心理状态的能力对于确保有效的交互变得至关重要。然而，尽管最近有人尝试评估LLM的理论心智（ToM）推理能力，但这些模型与人类ToM的一致程度仍然是一个复杂的探索主题。这主要是因为存在两个不同的挑战：（1）之前评估结果不一致，（2）现有评估方法的有效性存在疑虑。为了解决这些挑战，我们提出了一个新的框架，通过填充因果模板来生成与LLM的评估。使用我们的框架，我们为LLM创建了一个新的社交推理基准（BigToM），其中包含25个控制和5000个模型写的评估。我们发现，与之前众包评估相比，人类参与者对我们的基准的质量评价更高。

    As Large Language Models (LLMs) become increasingly integrated into our everyday lives, understanding their ability to comprehend human mental states becomes critical for ensuring effective interactions. However, despite the recent attempts to assess the Theory-of-Mind (ToM) reasoning capabilities of LLMs, the degree to which these models can align with human ToM remains a nuanced topic of exploration. This is primarily due to two distinct challenges: (1) the presence of inconsistent results from previous evaluations, and (2) concerns surrounding the validity of existing evaluation methodologies. To address these challenges, we present a novel framework for procedurally generating evaluations with LLMs by populating causal templates. Using our framework, we create a new social reasoning benchmark (BigToM) for LLMs which consists of 25 controls and 5,000 model-written evaluations. We find that human participants rate the quality of our benchmark higher than previous crowd-sourced evalua
    
[^13]: 对齐的神经网络是否对抗对齐？

    Are aligned neural networks adversarially aligned?. (arXiv:2306.15447v1 [cs.CL])

    [http://arxiv.org/abs/2306.15447](http://arxiv.org/abs/2306.15447)

    我们研究了大型语言模型在面对对抗用户构建的对抗性输入时是否仍能保持对齐。我们发现现有的攻击手法不足以可靠攻击对齐文本模型，并通过蛮力方法找到了对抗性输入。

    

    大型语言模型现在被调整为与其创建者的目标保持一致，即"有益且无害"。这些模型应该对用户的问题给出有益的回答，但拒绝回答可能会造成伤害的请求。然而，对抗用户可以构建绕过对齐尝试的输入。在这项工作中，我们研究了在与构造最坏情况输入（对抗性样本）的对抗用户交互时，这些模型保持多大程度的对齐。这些输入被设计成导致模型发出本应禁止的有害内容。我们展示了现有基于自然语言处理的优化攻击手法在可靠攻击对齐文本模型方面的不足之处：即使在当前基于自然语言处理的攻击失败时，我们仍然可以通过蛮力方法找到对抗性输入。因此，当前攻击的失败不应被视为对齐文本模型在面对对抗性输入时仍然保持对齐的证明。但是近期大规模机器学习模型的趋势是多模态的。

    Large language models are now tuned to align with the goals of their creators, namely to be "helpful and harmless." These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study to what extent these models remain aligned, even when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs.  However the recent trend in large-scale ML models is multim
    
[^14]: 《KnowPrefix-Tuning: 一种用于知识驱动对话生成的两阶段前缀调优框架》

    KnowPrefix-Tuning: A Two-Stage Prefix-Tuning Framework for Knowledge-Grounded Dialogue Generation. (arXiv:2306.15430v1 [cs.CL])

    [http://arxiv.org/abs/2306.15430](http://arxiv.org/abs/2306.15430)

    KnowPrefix-Tuning是一种知识驱动对话生成的两阶段前缀调优框架，通过将先验知识注入到轻量级知识前缀中来避免检索过程，与PLM进行全面交互优化响应生成的过程。

    

    现有的知识驱动对话系统通常以检索再生成的方式生成回复。它们需要一个庞大的知识库和一个强大的知识检索组件，这需要时间和资源。在本文中，我们通过利用预训练语言模型（PLMs）中内在编码的知识来应对这一挑战。我们提出了一种名为Knowledgeable Prefix Tuning（KnowPrefix-Tuning）的两阶段调优框架，在知识驱动对话系统中通过将先验知识注入到轻量级知识前缀中来避免检索过程。知识前缀是一系列连续的与知识相关的向量，在训练过程中可以学习到。此外，我们提出了一种新颖的交互重参数化机制，允许前缀在响应生成优化过程中与PLM进行全面的交互。实验结果表明，KnowPrefix-Tuning优于fine-tuning和其他轻量级调优方法。

    Existing knowledge-grounded conversation systems generate responses typically in a retrieve-then-generate manner. They require a large knowledge base and a strong knowledge retrieval component, which is time- and resource-consuming. In this paper, we address the challenge by leveraging the inherent knowledge encoded in the pre-trained language models (PLMs). We propose Knowledgeable Prefix Tuning (KnowPrefix-Tuning), a two-stage tuning framework, bypassing the retrieval process in a knowledge-grounded conversation system by injecting prior knowledge into the lightweight knowledge prefix. The knowledge prefix is a sequence of continuous knowledge-specific vectors that can be learned during training. In addition, we propose a novel interactive re-parameterization mechanism that allows the prefix to interact fully with the PLM during the optimization of response generation. Experimental results demonstrate that KnowPrefix-Tuning outperforms fine-tuning and other lightweight tuning approac
    
[^15]: 心脏频谱的相空间分析

    Phase Space Analysis of Cardiac Spectra. (arXiv:2306.15425v1 [physics.med-ph])

    [http://arxiv.org/abs/2306.15425](http://arxiv.org/abs/2306.15425)

    本研究通过相空间分析心脏频谱，找到了心脏疾病的改善方法，并提出了一种适用于多通道生理信号的快速和稳健的诊断方法。

    

    心脏疾病是现代工业化社会死亡的主要原因之一，并导致公共卫生系统的高额开支。因此，开发分析方法以改善心脏诊断非常重要。通过使用一组非线性微分方程对心脏的电活动进行了首次建模。随后，研究了起源于确定性动力学的心脏频谱的变化。通过分析正常人心脏的功率谱，可以发现具有类似分形结构的希斯-普尔金杰网络。从心电图的时间序列图中提取相空间轨迹。分形维数D的较低值表示更加一致的动力学。当D具有大于2的非整数值时，系统变得混沌或具有奇特吸引子。最近，报道了一种可以应用于多通道生理信号的快速而稳健的方法的开发。本文研究了两种不同的从n产生的心电图系统。

    Cardiac diseases are one of the main reasons of mortality in modern, industrialized societies, and they cause high expenses in public health systems. Therefore, it is important to develop analytical methods to improve cardiac diagnostics. Electric activity of heart was first modeled by using a set of nonlinear differential equations. Latter, variations of cardiac spectra originated from deterministic dynamics are investigated. Analyzing the power spectra of a normal human heart presents His-Purkinje network, possessing a fractal like structure. Phase space trajectories are extracted from the time series graph of ECG. Lower values of fractal dimension, D indicate dynamics that are more coherent. If D has non-integer values greater than two when the system becomes chaotic or strange attractor. Recently, the development of a fast and robust method, which can be applied to multichannel physiologic signals, was reported. This manuscript investigates two different ECG systems produced from n
    
[^16]: 基于训练数据直接证据的机器翻译文本质量评估

    Quality Estimation of Machine Translated Texts based on Direct Evidence from Training Data. (arXiv:2306.15399v1 [cs.CL])

    [http://arxiv.org/abs/2306.15399](http://arxiv.org/abs/2306.15399)

    本文研究了基于训练数据直接证据的机器翻译质量评估方法，实验结果表明这种方法对于纯数据驱动的机器翻译系统具有潜力。

    

    当前的机器翻译系统在越来越多的语言对和数据集上取得了非常好的结果。然而，众所周知它们产生的流畅翻译输出往往可能包含重要的意义错误。质量估计任务是在不依赖参考翻译的情况下，对由机器翻译系统生成的翻译质量进行估计。多年来，提出了许多方法。本文表明，用于训练机器翻译系统的平行语料库对于估计机器翻译系统生成的翻译质量具有直接线索。我们的实验结果表明，这种简单直接的方法对于任何纯数据驱动的机器翻译系统产生的翻译质量评估具有潜力。

    Current Machine Translation systems achieve very good results on a growing variety of language pairs and data sets. However, it is now well known that they produce fluent translation outputs that often can contain important meaning errors. Quality Estimation task deals with the estimation of quality of translations produced by a Machine Translation system without depending on Reference Translations. A number of approaches have been suggested over the years. In this paper we show that the parallel corpus used as training data for training the MT system holds direct clues for estimating the quality of translations produced by the MT system. Our experiments show that this simple and direct method holds promise for quality estimation of translations produced by any purely data driven machine translation system.
    
[^17]: 利用伪未来上下文对对话情感识别进行探索

    Exploiting Pseudo Future Contexts for Emotion Recognition in Conversations. (arXiv:2306.15376v1 [cs.CL])

    [http://arxiv.org/abs/2306.15376](http://arxiv.org/abs/2306.15376)

    该论文探索了利用伪未来上下文改进对话情感识别。通过使用预训练语言模型生成未来上下文，可以融合历史上下文和说话人特定上下文，形成一个简单的多上下文集成框架。实验结果表明该方法优越性。

    

    随着互联网上对话数据的广泛积累，对话情感识别（ERC）受到越来越多的关注。先前的工作主要集中在利用上下文和具体说话人的特征，或者整合异构的外部常识知识。其中一些工作严重依赖未来的上下文，然而在现实生活中未必总是可用。这一事实激发了我们生成伪未来上下文来提高ERC的想法。具体而言，对于一个话语，我们使用预训练的语言模型生成其未来上下文，可能包含了对对话过程中有益的额外知识，与历史上下文的形式保持一致。这些特点使得伪未来上下文容易与历史上下文和历史特定说话人的上下文相融合，形成一个概念上简单的系统，系统地集成了多个上下文。在四个ERC数据集上的实验证明了我们方法的优越性。

    With the extensive accumulation of conversational data on the Internet, emotion recognition in conversations (ERC) has received increasing attention. Previous efforts of this task mainly focus on leveraging contextual and speaker-specific features, or integrating heterogeneous external commonsense knowledge. Among them, some heavily rely on future contexts, which, however, are not always available in real-life scenarios. This fact inspires us to generate pseudo future contexts to improve ERC. Specifically, for an utterance, we generate its future context with pre-trained language models, potentially containing extra beneficial knowledge in a conversational form homogeneous with the historical ones. These characteristics make pseudo future contexts easily fused with historical contexts and historical speaker-specific contexts, yielding a conceptually simple framework systematically integrating multi-contexts. Experimental results on four ERC datasets demonstrate our method's superiority
    
[^18]: 一个生物学上可信的语言器官的架构

    The Architecture of a Biologically Plausible Language Organ. (arXiv:2306.15364v1 [cs.CL])

    [http://arxiv.org/abs/2306.15364](http://arxiv.org/abs/2306.15364)

    本研究提出了一个模拟的生物学上可信的语言器官，通过赫布连可塑性实现了从有限数量的句子的有意义输入中学习名词、动词及其意义。这一研究超越了以前的解析器设计，添加了一个生物学上可信的机制来解释婴儿大脑如何习得语言。

    

    我们提出了一个模拟的生物学上可信的语言器官，由风格化但逼真的神经元、突触、脑区、可塑性和简化的感觉知觉模型组成。通过实验证明，这个模型在语言习得的重要早期阶段取得了成功：从有限数量的句子的有意义输入中学习名词、动词及其意义。这个系统的学习是通过赫布连可塑性实现的，而没有使用反向传播。我们的模型超越了以前在类似环境中设计的解析器，关键是添加了一个生物学上可信的机制，解释了婴儿大脑如何习得语言，而不仅仅是成熟大脑的处理语言。

    We present a simulated biologically plausible language organ, made up of stylized but realistic neurons, synapses, brain areas, plasticity, and a simplified model of sensory perception. We show through experiments that this model succeeds in an important early step in language acquisition: the learning of nouns, verbs, and their meanings, from the grounded input of only a modest number of sentences. Learning in this system is achieved through Hebbian plasticity, and without backpropagation. Our model goes beyond a parser previously designed in a similar environment, with the critical addition of a biologically plausible account for how language can be acquired in the infant's brain, not just processed by a mature brain.
    
[^19]: 3D-Speaker：用于语音表示解缠的大规模多设备、多距离和多方言语料库

    3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement. (arXiv:2306.15354v1 [cs.CL])

    [http://arxiv.org/abs/2306.15354](http://arxiv.org/abs/2306.15354)

    3D-Speaker是一个大规模的多设备、多距离和多方言语音语料库，用于研究语音表示解缠。它包含了10,000多个说话人的数据，可以用来评估大型通用语音模型和探索域外学习和自监督学习方法。

    

    在语音社区中，分离语音话语中的不相关信息是一个关键的研究课题。不同的语音相关任务专注于提取不同的语音表示，同时最小化其他不相关信息的影响。我们提出了一个大规模的语音语料库，以促进语音表示解缠的研究。3D-Speaker包含超过10,000个说话人，每个说话人同时由多个设备录制，在不同的距离上，并且一些说话人会讲多种方言。多维音频数据的受控组合产生了一个多样的混合语音表示纠缠矩阵，从而激发出解开它们的有趣方法。3D-Speaker的多领域性质还使其成为评估大型通用语音模型和实验域外学习和自监督学习方法的合适资源。

    Disentangling uncorrelated information in speech utterances is a crucial research topic within speech community. Different speech-related tasks focus on extracting distinct speech representations while minimizing the affects of other uncorrelated information. We present a large-scale speech corpus to facilitate the research of speech representation disentanglement. 3D-Speaker contains over 10,000 speakers, each of whom are simultaneously recorded by multiple Devices, locating at different Distances, and some speakers are speaking multiple Dialects. The controlled combinations of multi-dimensional audio data yield a matrix of a diverse blend of speech representation entanglement, thereby motivating intriguing methods to untangle them. The multi-domain nature of 3D-Speaker also makes it a suitable resource to evaluate large universal speech models and experiment methods of out-of-domain learning and self-supervised learning. https://3dspeaker.github.io/
    
[^20]: 在线心理健康咨询中理解客户反应

    Understanding Client Reactions in Online Mental Health Counseling. (arXiv:2306.15334v1 [cs.CL])

    [http://arxiv.org/abs/2306.15334](http://arxiv.org/abs/2306.15334)

    本研究通过开发一个注释框架，深入研究了在线心理健康咨询中客户的反应。通过收集和分析大规模的基于文本的咨询数据集，我们展示了客户如何反应咨询师的策略以及这些反应对咨询结果的影响，并探讨了咨询师如何根据客户的反应调整策略。

    

    传达的成功在很大程度上依赖于读取参与者的反应。这种反馈对于心理健康咨询师尤为重要，他们必须仔细考虑客户的进展并相应地调整自己的方法。然而，以往关于咨询的自然语言处理(NLP)研究主要集中在研究咨询师的干预策略，而不是客户对干预的反应。本研究旨在填补这一空白，通过开发一个基于理论的注释框架，涵盖咨询师的策略和客户反应行为。该框架已经在一个在线福利咨询平台上收集了过去两年的大规模、高质量的基于文本的咨询数据集，并经过了测试。我们的研究显示了客户如何对咨询师的策略做出反应，这样的反应如何影响最终的咨询结果，以及咨询师如何根据这些反应调整策略。我们还证明了这项研究可以帮助咨询师自动化地提供个性化的咨询服务。

    Communication success relies heavily on reading participants' reactions. Such feedback is especially important for mental health counselors, who must carefully consider the client's progress and adjust their approach accordingly. However, previous NLP research on counseling has mainly focused on studying counselors' intervention strategies rather than their clients' reactions to the intervention. This work aims to fill this gap by developing a theoretically grounded annotation framework that encompasses counselors' strategies and client reaction behaviors. The framework has been tested against a large-scale, high-quality text-based counseling dataset we collected over the past two years from an online welfare counseling platform. Our study shows how clients react to counselors' strategies, how such reactions affect the final counseling outcomes, and how counselors can adjust their strategies in response to these reactions. We also demonstrate that this study can help counselors automat
    
[^21]: BERT中的性别偏见——通过情感评分在现实的下游分类任务中测量和分析偏见

    Gender Bias in BERT -- Measuring and Analysing Biases through Sentiment Rating in a Realistic Downstream Classification Task. (arXiv:2306.15298v1 [cs.CL])

    [http://arxiv.org/abs/2306.15298](http://arxiv.org/abs/2306.15298)

    该论文通过引入新的偏见度量方法，并在一个现实的IMDB电影分类器的例子中对BERT的性别偏见进行了全面分析。研究结果表明，公开的BERT模型中存在着显著的性别偏见，并强调了负责任使用的重要性。

    

    预训练语言模型在各种现实应用中公开可用，并不断进行微调。随着它们具备抓取复杂上下文信息的能力，有害偏见很可能越来越多地与这些模型交织在一起。本文通过两个主要贡献来分析BERT模型中的性别偏见：首先，引入了一种新的偏见度量方法，将偏见定义为女性和男性样本版本在情感评估上的差异。其次，我们对一个现实的IMDB电影分类器的例子中BERT的偏见进行了全面分析。通过系统地变化训练流程的各个元素，我们可以对最终模型偏见的影响做出结论。我们比较了七个不同的公开BERT模型的九种训练条件，即总共63个模型。几乎所有的条件都产生了显著的性别偏见。结果表明，反映的偏见源于公开的BERT模型而不是任务特定数据，强调了负责任使用的重要性。

    Pretrained language models are publicly available and constantly finetuned for various real-life applications. As they become capable of grasping complex contextual information, harmful biases are likely increasingly intertwined with those models. This paper analyses gender bias in BERT models with two main contributions: First, a novel bias measure is introduced, defining biases as the difference in sentiment valuation of female and male sample versions. Second, we comprehensively analyse BERT's biases on the example of a realistic IMDB movie classifier. By systematically varying elements of the training pipeline, we can conclude regarding their impact on the final model bias. Seven different public BERT models in nine training conditions, i.e. 63 models in total, are compared. Almost all conditions yield significant gender biases. Results indicate that reflected biases stem from public BERT models rather than task-specific data, emphasising the weight of responsible usage.
    
[^22]: IDOL: 面向逻辑推理的指标导向预训练方法

    IDOL: Indicator-oriented Logic Pre-training for Logical Reasoning. (arXiv:2306.15273v1 [cs.CL])

    [http://arxiv.org/abs/2306.15273](http://arxiv.org/abs/2306.15273)

    IDOL是一种面向逻辑推理的指标导向预训练方法，通过使用逻辑指标和逻辑丰富的数据集在逻辑上增强了预训练模型。IDOL在逻辑推理MRC基准测试中取得了最先进的性能，并且具有竞争力的综合语言理解能力。

    

    在机器阅读理解领域，现有系统在许多任务（如SQuAD）中的表现已经超过了人类平均水平。然而，当涉及到逻辑推理时，仍有很大的进步空间。在本文中，我们提出了一种名为IDOL（InDicator-Oriented Logic Pre-training）的易于理解且高效的进一步预训练任务，该任务利用6种逻辑指标和逻辑丰富的数据集LGP（LoGic Pre-training）在逻辑上强化了预训练模型。IDOL在ReClor和LogiQA这两个具有代表性的逻辑推理MRC基准测试上实现了最先进的性能，并且被证明能够推广到不同的预训练模型和其他类型的MRC基准测试，如RACE和SQuAD 2.0，同时保持有竞争力的综合语言理解能力。

    In the field of machine reading comprehension (MRC), existing systems have surpassed the average performance of human beings in many tasks like SQuAD. However, there is still a long way to go when it comes to logical reasoning. Although some methods for it have been put forward, they either are designed in a quite complicated way or rely too much on external structures. In this paper, we proposed IDOL (InDicator-Oriented Logic Pre-training), an easy-to-understand but highly effective further pre-training task which logically strengthens the pre-trained models with the help of 6 types of logical indicators and a logically rich dataset LGP (LoGic Pre-training). IDOL achieves state-of-the-art performance on ReClor and LogiQA, the two most representative benchmarks in logical reasoning MRC, and is proven to be capable of generalizing to different pre-trained models and other types of MRC benchmarks like RACE and SQuAD 2.0 while keeping competitive general language understanding ability thr
    
[^23]: 预训练语言模型是否能够在噪音下从损坏的子词中得到正确的语义？

    Can Pretrained Language Models Derive Correct Semantics from Corrupt Subwords under Noise?. (arXiv:2306.15268v1 [cs.CL])

    [http://arxiv.org/abs/2306.15268](http://arxiv.org/abs/2306.15268)

    本研究评估了预训练语言模型对噪音引起的不同分割错误的鲁棒性。实验结果表明，如果噪音引入不同的子词、小的子词片段或大量的额外子词，特别是插入在其他子词中，PLMs将无法准确计算单词的含义。

    

    对于预训练语言模型（PLMs），它们对噪音的敏感性最近被认为与子词分割有关。然而，目前还不清楚分割的哪些方面会影响它们的理解能力。本研究评估了PLMs对由噪音引起的各种受损分割的鲁棒性。提出了一个用于子词分割的评估框架，名为对比词汇语义（CoLeS）探针。它通过生成带有规范-噪音词对的对比数据集，对分割错误进行了系统分类，并提供了评估协议。实验结果表明，如果噪音引入完全不同的子词、小的子词片段或大量的额外子词，特别是当它们插入在其他子词中时，PLMs将无法准确计算单词的含义。

    For Pretrained Language Models (PLMs), their susceptibility to noise has recently been linked to subword segmentation. However, it is unclear which aspects of segmentation affect their understanding. This study assesses the robustness of PLMs against various disrupted segmentation caused by noise. An evaluation framework for subword segmentation, named Contrastive Lexical Semantic (CoLeS) probe, is proposed. It provides a systematic categorization of segmentation corruption under noise and evaluation protocols by generating contrastive datasets with canonical-noisy word pairs. Experimental results indicate that PLMs are unable to accurately compute word meanings if the noise introduces completely different subwords, small subword fragments, or a large number of additional subwords, particularly when they are inserted within other subwords.
    
[^24]: 对神经NLP模型的离域评估的调研

    A Survey on Out-of-Distribution Evaluation of Neural NLP Models. (arXiv:2306.15261v1 [cs.CL])

    [http://arxiv.org/abs/2306.15261](http://arxiv.org/abs/2306.15261)

    本调研对神经NLP模型的离域评估的对抗性鲁棒性、领域泛化和数据集偏差三个研究方向进行了比较和总结，并强调了未来工作的挑战和机遇。

    

    对抗性鲁棒性、领域泛化和数据集偏差是对神经NLP模型离域评估的三个研究方向。然而，目前文献中还缺乏关于这三个研究方向的综合、整合性的讨论。本调研对这三个研究方向进行了比较，并总结了每个研究方向的数据生成过程和评估协议，并强调了未来工作的挑战和机遇。

    Adversarial robustness, domain generalization and dataset biases are three active lines of research contributing to out-of-distribution (OOD) evaluation on neural NLP models. However, a comprehensive, integrated discussion of the three research lines is still lacking in the literature. In this survey, we 1) compare the three lines of research under a unifying definition; 2) summarize the data-generating processes and evaluation protocols for each line of research; and 3) emphasize the challenges and opportunities for future work.
    
[^25]: GroundNLQ @ Ego4D自然语言查询挑战2023年

    GroundNLQ @ Ego4D Natural Language Queries Challenge 2023. (arXiv:2306.15255v1 [cs.CV])

    [http://arxiv.org/abs/2306.15255](http://arxiv.org/abs/2306.15255)

    GroundNLQ是一个用于自然语言查询挑战的创新标注模型，通过采用两阶段的预训练策略和多模态多尺度的标注模块，实现了在视频中的准确标注，获得了较好的性能表现。

    

    在本报告中，我们呈现了我们在CVPR 2023年的Ego4D自然语言查询挑战中的冠军解决方案。为了在视频中准确进行标注，需要一个有效的自我中心特征提取器和一个强大的标注模型。为此，我们采用两阶段的预训练策略，在视频叙述上训练自我中心特征提取器和标注模型，并在标注数据上进行进一步的微调。此外，我们引入了一种新颖的标注模型GroundNLQ，它采用了多模态多尺度的标注模块，用于有效融合视频和文本，并对各种时间间隔（尤其是长视频）进行处理。在盲测集上，GroundNLQ在R1@IoU=0.3和R1@IoU=0.5分别达到了25.67和18.18，并且在各项指标上都明显超过了其他所有团队。我们的代码将在\url{https://github.com/houzhijian/GroundNLQ}上发布。

    In this report, we present our champion solution for Ego4D Natural Language Queries (NLQ) Challenge in CVPR 2023. Essentially, to accurately ground in a video, an effective egocentric feature extractor and a powerful grounding model are required. Motivated by this, we leverage a two-stage pre-training strategy to train egocentric feature extractors and the grounding model on video narrations, and further fine-tune the model on annotated data. In addition, we introduce a novel grounding model GroundNLQ, which employs a multi-modal multi-scale grounding module for effective video and text fusion and various temporal intervals, especially for long videos. On the blind test set, GroundNLQ achieves 25.67 and 18.18 for R1@IoU=0.3 and R1@IoU=0.5, respectively, and surpasses all other teams by a noticeable margin. Our code will be released at\url{https://github.com/houzhijian/GroundNLQ}.
    
[^26]: MindDial: 带有心智模拟的信念动态跟踪用于场景化神经对话生成

    MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for Situated Neural Dialogue Generation. (arXiv:2306.15253v1 [cs.CL])

    [http://arxiv.org/abs/2306.15253](http://arxiv.org/abs/2306.15253)

    MindDial是一个使用心智模拟进行信念动态跟踪的对话生成框架，可以在场景化环境中生成自由对话来协商共识。

    

    人类在交流中自由表达意义或共识的同时进行对话。尽管大型生成语言模型具有令人印象深刻的对话能力，但它们并未考虑到共享的场景环境中个体的上下文理解差异。本文提出了MindDial，一种新颖的对话框架，可以生成场景化的自由对话来协商共识。我们设计了一个明确的心智模块，可以追踪三个层次的信念，即说话者的信念、说话者对听众信念的预测以及基于前两者之间的共同信念。然后，说话行为分类头将决定是否继续对话、结束此轮对话或采取与任务相关的行动。我们使用了一个共识对齐的数据集MutualFriend，增加了信念动态注释，目标是根据两个代理之间的自由对话找到一个共同的朋友。实验证明，我们的模型在心智状态建模方面取得了良好的效果。

    Humans talk in free-form while negotiating the expressed meanings or common ground. Despite the impressive conversational abilities of the large generative language models, they do not consider the individual differences in contextual understanding in a shared situated environment. In this work, we propose MindDial, a novel conversational framework that can generate situated free-form responses to negotiate common ground. We design an explicit mind module that can track three-level beliefs -- the speaker's belief, the speaker's prediction of the listener's belief, and the common belief based on the gap between the first two. Then the speaking act classification head will decide to continue to talk, end this turn, or take task-related action. We augment a common ground alignment dataset MutualFriend with belief dynamics annotation, of which the goal is to find a single mutual friend based on the free chat between two agents. Experiments show that our model with mental state modeling can
    
[^27]: C-PMI: 条件点对点互信息用于对话评估的方法研究

    C-PMI: Conditional Pointwise Mutual Information for Turn-level Dialogue Evaluation. (arXiv:2306.15245v1 [cs.CL])

    [http://arxiv.org/abs/2306.15245](http://arxiv.org/abs/2306.15245)

    本研究提出了一种基于条件点对点互信息的模型-无关方法，用于衡量对话系统与用户之间的交互，通过替换评分器，显著改进了与人类判断的相关性。

    

    现有的chatbot的无参考级对话评估指标不足以捕捉用户与系统之间的交互。因此，它们通常与人类评估的相关性较差。为解决这一问题，我们提出了一种新颖的模型无关方法，利用条件点对点互信息（C-PMI）来度量系统和用户之间基于给定评估维度的对话交互。在广泛使用的FED对话评估数据集上的实验结果表明，与现有评估系统相比，我们的方法显著提高了与人类判断的相关性。通过将基于负对数似然的评分器替换为我们提出的C-PMI评分器，我们在FED评估指标上的Spearman相关性平均相对提高了60.5%。我们的代码公开发布在https://github.com/renll/C-PMI。

    Existing reference-free turn-level evaluation metrics for chatbots inadequately capture the interaction between the user and the system. Consequently, they often correlate poorly with human evaluations. To address this issue, we propose a novel model-agnostic approach that leverages Conditional Pointwise Mutual Information (C-PMI) to measure the turn-level interaction between the system and the user based on a given evaluation dimension. Experimental results on the widely used FED dialogue evaluation dataset demonstrate that our approach significantly improves the correlation with human judgment compared with existing evaluation systems. By replacing the negative log-likelihood-based scorer with our proposed C-PMI scorer, we achieve a relative 60.5% higher Spearman correlation on average for the FED evaluation metric. Our code is publicly available at https://github.com/renll/C-PMI.
    
[^28]: 模拟读者行为进行假新闻检测

    Emulating Reader Behaviors for Fake News Detection. (arXiv:2306.15231v1 [cs.CL])

    [http://arxiv.org/abs/2306.15231](http://arxiv.org/abs/2306.15231)

    本文提出了一种模拟读者行为的方法（Ember）用于社交媒体上的假新闻检测，通过纳入读者的阅读和验证过程，从组件角度全面建模新闻，以提高假新闻检测的效果和真实性。

    

    假新闻的广泛传播影响了我们生活的许多方面，因此假新闻检测变得非常重要并吸引了越来越多的关注。现有方法通过从单模态或多模态的角度对新闻进行建模，在这个领域做出了实质性的贡献。然而，这些基于模态的方法可能会导致次优的结果，因为它们忽略了读者在阅读新闻和验证真实性方面的行为。举例来说，它们没有考虑到按部分进行阅读的过程：从标题、图片、评论到正文，这对于更细致地建模新闻至关重要。为此，我们提出了一种模拟读者行为的方法（Ember）用于社交媒体上的假新闻检测，将读者的阅读和验证过程纳入对组件角度全面建模的新闻模型中。具体而言，我们首先构建了内部组件特征提取器，以模拟对每个组件进行语义分析的行为。

    The wide dissemination of fake news has affected our lives in many aspects, making fake news detection important and attracting increasing attention. Existing approaches make substantial contributions in this field by modeling news from a single-modal or multi-modal perspective. However, these modal-based methods can result in sub-optimal outcomes as they ignore reader behaviors in news consumption and authenticity verification. For instance, they haven't taken into consideration the component-by-component reading process: from the headline, images, comments, to the body, which is essential for modeling news with more granularity. To this end, we propose an approach of Emulating the behaviors of readers (Ember) for fake news detection on social media, incorporating readers' reading and verificating process to model news from the component perspective thoroughly. Specifically, we first construct intra-component feature extractors to emulate the behaviors of semantic analyzing on each co
    
[^29]: 学习在生成式检索中进行排序

    Learning to Rank in Generative Retrieval. (arXiv:2306.15222v1 [cs.CL])

    [http://arxiv.org/abs/2306.15222](http://arxiv.org/abs/2306.15222)

    这篇论文介绍了一种将生成式检索和经典的学习排序范例相结合的方法，通过使用段落排序损失来训练自回归模型，直接优化自回归模型朝着最优解优化。

    

    生成式检索是一种有前景的文本检索范例，它将相关段落的标识符字符串生成为检索目标。这种范例利用强大的生成模型，并代表了与传统的学习排序方法有所不同的新范例。然而，尽管其快速发展，当前的生成式检索方法仍存在局限性。它们通常依赖启发式函数将预测的标识符转换为段落排序列表，这在生成式检索的学习目标与期望的段落排序目标之间产生了差距。此外，文本生成的固有曝光偏差问题在生成式检索中仍然存在。为了解决这些问题，我们提出了一种新颖的框架，称为LTRGR，它将生成式检索与经典的学习排序范例相结合。我们的方法涉及使用段落排序损失训练一个自回归模型，该损失直接优化自回归模型朝着最优解优化。

    Generative retrieval is a promising new paradigm in text retrieval that generates identifier strings of relevant passages as the retrieval target. This paradigm leverages powerful generation models and represents a new paradigm distinct from traditional learning-to-rank methods. However, despite its rapid development, current generative retrieval methods are still limited. They typically rely on a heuristic function to transform predicted identifiers into a passage rank list, which creates a gap between the learning objective of generative retrieval and the desired passage ranking target. Moreover, the inherent exposure bias problem of text generation also persists in generative retrieval. To address these issues, we propose a novel framework, called LTRGR, that combines generative retrieval with the classical learning-to-rank paradigm. Our approach involves training an autoregressive model using a passage rank loss, which directly optimizes the autoregressive model toward the optimal 
    
[^30]: 通过自适应两阶段知识蒸馏来缩小流式与非流式转导式自动语音识别之间的差距

    Reducing the gap between streaming and non-streaming Transducer-based ASR by adaptive two-stage knowledge distillation. (arXiv:2306.15171v1 [cs.CL])

    [http://arxiv.org/abs/2306.15171](http://arxiv.org/abs/2306.15171)

    提出了一个自适应两阶段知识蒸馏的方法，通过学习隐藏层和输出层的分布一致性来缩小流式与非流式转导式自动语音识别之间的差距。该方法在词错误率上实现了19%的相对降低，并且对第一个令牌的响应更快。

    

    转导式自动语音识别是流式语音识别的一个主流框架。由于上下文有限，流式与非流式转导式模型之间存在性能差距。为了缩小这个差距，一个有效的方式是确保它们的隐藏层和输出分布一致，可以通过层级知识蒸馏来实现。然而，同时确保分布一致性是困难的，因为输出分布的学习依赖于隐藏层。在本文中，我们提出了一个自适应两阶段知识蒸馏的方法，包括隐藏层学习和输出层学习。在前一阶段，我们通过应用均方误差损失函数学习具有完整上下文的隐藏表示。在后一阶段，我们设计了基于幂变换的自适应平滑方法来学习稳定的输出分布。实验结果表明，该方法在词错误率上实现了19%相对降低，并且对于第一个令牌的响应更快。

    Transducer is one of the mainstream frameworks for streaming speech recognition. There is a performance gap between the streaming and non-streaming transducer models due to limited context. To reduce this gap, an effective way is to ensure that their hidden and output distributions are consistent, which can be achieved by hierarchical knowledge distillation. However, it is difficult to ensure the distribution consistency simultaneously because the learning of the output distribution depends on the hidden one. In this paper, we propose an adaptive two-stage knowledge distillation method consisting of hidden layer learning and output layer learning. In the former stage, we learn hidden representation with full context by applying mean square error loss function. In the latter stage, we design a power transformation based adaptive smoothness method to learn stable output distribution. It achieved 19\% relative reduction in word error rate, and a faster response for the first token compare
    
[^31]: 用分布偏移风险最小化增强文本对抗训练（DSRM）

    DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization. (arXiv:2306.15164v1 [cs.CL])

    [http://arxiv.org/abs/2306.15164](http://arxiv.org/abs/2306.15164)

    本论文介绍了一种新颖的方法DSRM，通过最小化分布偏移风险而不是使用对抗样本来对抗训练，从而提高了深度语言模型的鲁棒性，减少了时间消耗。

    

    对抗训练是改善深度语言模型鲁棒性的最佳方法之一。然而，鲁棒模型的代价是时间消耗高，因为它们需要多步梯度上升或单词替换来获取对抗样本。此外，这些生成的样本在语法质量和语义一致性方面存在缺陷，影响了对抗训练的有效性。为了解决这些问题，我们引入了一种新颖、有效的过程，将对抗训练改为只使用干净数据。我们的方法DSRM通过扰动输入数据的概率分布而不是它们的嵌入来估计对抗损失。这种公式化结果导致了一个在对抗攻击下最小化期望全局损失的鲁棒模型。我们的方法在训练过程中不需要对抗样本，并且与当前最佳对抗训练相比，减少了高达70\%的时间消耗。

    Adversarial training is one of the best-performing methods in improving the robustness of deep language models. However, robust models come at the cost of high time consumption, as they require multi-step gradient ascents or word substitutions to obtain adversarial samples. In addition, these generated samples are deficient in grammatical quality and semantic consistency, which impairs the effectiveness of adversarial training. To address these problems, we introduce a novel, effective procedure for instead adversarial training with only clean data. Our procedure, distribution shift risk minimization (DSRM), estimates the adversarial loss by perturbing the input data's probability distribution rather than their embeddings. This formulation results in a robust model that minimizes the expected global loss under adversarial attacks. Our approach requires zero adversarial samples for training and reduces time consumption by up to 70\% compared to current best-performing adversarial traini
    
[^32]: YouTube-ASL:一个大规模的、开放领域的美国手语-英语平行语料库。

    YouTube-ASL: A Large-Scale, Open-Domain American Sign Language-English Parallel Corpus. (arXiv:2306.15162v1 [cs.CL])

    [http://arxiv.org/abs/2306.15162](http://arxiv.org/abs/2306.15162)

    本文介绍了一个大规模的、开放领域的美国手语-英语平行语料库YouTube-ASL，包含了约1000小时的美国手语视频和超过2500位独特的签名者。研究者在此语料库上训练了手语到英语翻译的模型，并在另一个数据集上实现了最新的最佳效果。

    

    机器学习对于手语的瓶颈在于数据。在本文中，我们介绍了YouTube-ASL，一个来自YouTube的包含美国手语（ASL）视频和英文字幕的大规模、开放领域的语料库。YouTube-ASL拥有约1000小时的视频和超过2500个独特的签名者，是迄今为止最大的ASL数据集的3倍之多，并且拥有10倍于先前ASL数据集的独特签名者数量。我们在YouTube-ASL上训练了ASL到英语翻译的基准模型，并在How2Sign上进行评估，在这里我们实现了新的微调最佳效果12.39 BLEU，并首次报道了零-shot方法的结果。

    Machine learning for sign languages is bottlenecked by data. In this paper, we present YouTube-ASL, a large-scale, open-domain corpus of American Sign Language (ASL) videos and accompanying English captions drawn from YouTube. With ~1000 hours of videos and >2500 unique signers, YouTube-ASL is ~3x as large and has ~10x as many unique signers as the largest prior ASL dataset. We train baseline models for ASL to English translation on YouTube-ASL and evaluate them on How2Sign, where we achieve a new finetuned state of the art of 12.39 BLEU and, for the first time, report zero-shot results.
    
[^33]: 研究BERT在评论理解中的跨域行为

    Investigating Cross-Domain Behaviors of BERT in Review Understanding. (arXiv:2306.15123v1 [cs.CL])

    [http://arxiv.org/abs/2306.15123](http://arxiv.org/abs/2306.15123)

    该研究调查了在产品评论理解的各种任务中，BERT模型在不同域上的跨域行为。尽管单域模型在对应域上略有提高，多域模型在评估多域数据时表现更好，并且在平均测试中也更优。尽管单域模型微调可以提高准确性，但会增加计算资源消耗。

    

    评论分数预测需要理解评论文本，这是自然语言处理的一个关键实际应用。由于产品评论中的文本领域不同，常见做法是在不同领域的评论上对BERT模型进行微调。然而，目前还没有对BERT模型在产品评论理解的各种任务中的跨域行为进行实证研究。在本项目中，我们研究了在单域和多域亚马逊评论数据上微调的文本分类BERT模型。通过我们的发现，尽管单域模型在对应域上的性能略有提高，但在多域数据上评估时，多域模型优于单域模型，特别是在单域模型未进行微调的单域数据上，以及在考虑所有测试时的平均性能。虽然通过单域模型微调可以略微提高准确性，但计算资源也会增加。

    Review score prediction requires review text understanding, a critical real-world application of natural language processing. Due to dissimilar text domains in product reviews, a common practice is fine-tuning BERT models upon reviews of differing domains. However, there has not yet been an empirical study of cross-domain behaviors of BERT models in the various tasks of product review understanding. In this project, we investigate text classification BERT models fine-tuned on single-domain and multi-domain Amazon review data. In our findings, though single-domain models achieved marginally improved performance on their corresponding domain compared to multi-domain models, multi-domain models outperformed single-domain models when evaluated on multi-domain data, single-domain data the single-domain model was not fine-tuned on, and on average when considering all tests. Though slight increases in accuracy can be achieved through single-domain model fine-tuning, computational resources an
    
[^34]: FeedbackMap: 一种分析开放性调查回答的工具

    FeedbackMap: a tool for making sense of open-ended survey responses. (arXiv:2306.15112v1 [cs.CL])

    [http://arxiv.org/abs/2306.15112](http://arxiv.org/abs/2306.15112)

    FeedbackMap是一个基于网络的工具，利用自然语言处理技术来分析开放性调查回答。它可以生成多层次的摘要，识别有趣的回答示例，并通过嵌入方式可视化回答空间。由于总结方法可能引入偏见，需要对回答者的声音进行批判性评估。

    

    分析开放性调查回答是社会科学家、非营利组织和教育机构面临的关键但具有挑战性的任务，因为他们常常面临着获取丰富数据和阅读和编码文本回答的负担之间的权衡。本文介绍了FeedbackMap，这是一个基于网络的工具，利用自然语言处理技术来促进开放性调查回答的分析。FeedbackMap让研究人员可以在多个层次上生成摘要，识别有趣的回答示例，并通过嵌入方式可视化回答空间。我们讨论了从多个角度审视调查结果的重要性以及总结方法引入的潜在偏见，强调了对被调查人声音的代表性和遗漏性的批判性评估的必要性。

    Analyzing open-ended survey responses is a crucial yet challenging task for social scientists, non-profit organizations, and educational institutions, as they often face the trade-off between obtaining rich data and the burden of reading and coding textual responses. This demo introduces FeedbackMap, a web-based tool that uses natural language processing techniques to facilitate the analysis of open-ended survey responses. FeedbackMap lets researchers generate summaries at multiple levels, identify interesting response examples, and visualize the response space through embeddings. We discuss the importance of examining survey results from multiple perspectives and the potential biases introduced by summarization methods, emphasizing the need for critical evaluation of the representation and omission of respondent voices.
    
[^35]: 结构化对话话语分析

    Structured Dialogue Discourse Parsing. (arXiv:2306.15103v1 [cs.CL])

    [http://arxiv.org/abs/2306.15103](http://arxiv.org/abs/2306.15103)

    本文提出了一种结构化对话话语分析的方法，从编码和解码两个角度改进了先前的工作，并通过对邻接矩阵进行结构化编码，以及使用修改后的Chiu-Liu-Edmonds算法进行结构化推理来优化对话中的链接和关系。

    

    对话话语分析旨在通过找到所有话语链接和对应关系，揭示多参与者对话的内部结构。先前的工作要么将此任务视为一系列独立的多项选择问题，其中链接存在和关系被分别解码，要么将编码限制在仅局部交互中，忽略了整体的结构信息。相反，我们提出了一种从编码和解码两个角度改进先前工作的原理方法。从编码方面来看，我们对邻接矩阵执行结构化编码，然后采用矩阵树学习算法，根据潜在的树级分布共同优化对话中的所有链接和关系。从解码方面来看，我们使用修改后的Chiu-Liu-Edmonds算法执行结构化推理，明确生成最佳的带标签多根非投射生成树。

    Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conversation by finding all the discourse~\emph{links} and corresponding~\emph{relations}. Previous work either treats this task as a series of independent multiple-choice problems, in which the link existence and relations are decoded separately, or the encoding is restricted to only local interaction, ignoring the holistic structural information. In contrast, we propose a principled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we perform structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best
    
[^36]: 通过支持性预训练数据理解上下文学习

    Understanding In-Context Learning via Supportive Pretraining Data. (arXiv:2306.15091v1 [cs.CL])

    [http://arxiv.org/abs/2306.15091](http://arxiv.org/abs/2306.15091)

    通过研究预训练数据，我们发现支持性预训练数据中的罕见且长尾的词对于上下文学习非常重要。这些发现有助于提高语言模型在各种NLP任务中的性能。

    

    上下文学习（ICL）通过在推理时简单展示少量示例，提高语言模型在各种NLP任务上的性能。尽管模型从未被专门训练过这样的示例，ICL的能力如何出现仍不为人所知。与探索ICL背后的隐式机制的先前工作不同，我们通过研究预训练数据来研究ICL。具体而言，我们首先采用迭代的基于梯度的方法，找到一小部分支持ICL的预训练数据。我们观察到，在这个小的子集上持续预训练可以显著提高模型的ICL能力，最多可以提高18%。然后，我们将支持性子集与随机子集进行对比，发现：（1）支持性预训练数据与下游任务的域相关性并不高。（2）支持性预训练数据中有更多罕见且长尾的词。（3）支持性预训练数据具有挑战性。

    In-context learning (ICL) improves language models' performance on a variety of NLP tasks by simply demonstrating a handful of examples at inference time. It is not well understood why ICL ability emerges, as the model has never been specifically trained on such demonstrations. Unlike prior work that explores implicit mechanisms behind ICL, we study ICL via investigating the pretraining data. Specifically, we first adapt an iterative, gradient-based approach to find a small subset of pretraining data that supports ICL. We observe that a continued pretraining on this small subset significantly improves the model's ICL ability, by up to 18%. We then compare the supportive subset constrastively with random subsets of pretraining data and discover: (1) The supportive pretraining data to ICL do not have a higher domain relevance to downstream tasks. (2) The supportive pretraining data have a higher mass of rarely occurring, long-tail tokens. (3) The supportive pretraining data are challengi
    
[^37]: WinoQueer：针对大型语言模型中反LGBTQ+偏见的社区协同基准

    WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models. (arXiv:2306.15087v1 [cs.CL])

    [http://arxiv.org/abs/2306.15087](http://arxiv.org/abs/2306.15087)

    WinoQueer是一个社区协同基准，旨在衡量大型语言模型是否存在对LGBTQ+社区有害的偏见。研究发现现成模型普遍存在相当大的反同偏见，通过在该社区撰写或由该社区成员撰写的数据上进行微调，可以在一定程度上减轻偏见。

    

    我们提出了WinoQueer：一个专门设计用来测试大型语言模型（LLMs）是否存在对LGBTQ+社区有害的偏见的基准。该基准是通过一种新颖的方法从社区调查中生成的偏见基准。我们将该基准应用于几个流行的LLMs，并发现现成模型普遍存在相当大的反同偏见。最后，我们展示了通过在该社区撰写或由该社区成员撰写的数据上进行微调，可以在一定程度上减轻LLM对边缘化社区的偏见，并且社区成员撰写的社交媒体文本比非社区成员撰写的新闻文本更有效。我们的社区协同基准开发方法为未来的研究人员提供了一个蓝图，以开发面向其他边缘化社区的、以社区为中心的、基于伤害的LLM基准。

    We present WinoQueer: a benchmark specifically designed to measure whether large language models (LLMs) encode biases that are harmful to the LGBTQ+ community. The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey. We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias. Finally, we show that LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community, and that social media text written by community members is more effective than news text written about the community by non-members. Our method for community-in-the-loop benchmark development provides a blueprint for future researchers to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities.
    
[^38]: 预训练任务多样性与回归问题中非贝叶斯上下文学习的出现

    Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression. (arXiv:2306.15063v1 [cs.LG])

    [http://arxiv.org/abs/2306.15063](http://arxiv.org/abs/2306.15063)

    预训练的transformer在回归问题中展现了非贝叶斯上下文学习能力，其在任务多样性阈值以下表现类似于贝叶斯估计器，而在阈值以上明显优于贝叶斯估计器，与岭回归一致。

    

    预训练的transformer表现出了令人钦佩的上下文学习能力（ICL）：它们可以从仅提供在提示中的少量示例中学习任务，而无需更新任何权重。这引发了一个基本问题：ICL能够解决在预训练期间未见过的、在本质上与之前任务非常不同的新任务吗？为了探索这个问题，我们在预训练数据集中改变任务的多样性，研究了ICL在线性回归中的表现。我们经验性地证明了出现ICL的任务多样性阈值。在这个阈值以下，预训练的transformer无法解决未见的回归任务，因为它的行为类似于具有非多样性预训练任务分布作为先验的贝叶斯估计器。超过这个阈值后，transformer明显优于这个估计器；它的行为与岭回归一致，对$\textit{所有任务}$，包括在预训练期间未见过的任务，具有高斯先验。

    Pretrained transformers exhibit the remarkable ability of in-context learning (ICL): they can learn tasks from just a few examples provided in the prompt without updating any weights. This raises a foundational question: can ICL solve fundamentally $\textit{new}$ tasks that are very different from those seen during pretraining? To probe this question, we examine ICL's performance on linear regression while varying the diversity of tasks in the pretraining dataset. We empirically demonstrate a $\textit{task diversity threshold}$ for the emergence of ICL. Below this threshold, the pretrained transformer cannot solve unseen regression tasks as it behaves like a Bayesian estimator with the $\textit{non-diverse pretraining task distribution}$ as the prior. Beyond this threshold, the transformer significantly outperforms this estimator; its behavior aligns with that of ridge regression, corresponding to a Gaussian prior over $\textit{all tasks}$, including those not seen during pretraining. 
    
[^39]: DNABERT-2:多种物种基因组的高效基础模型和基准

    DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome. (arXiv:2306.15006v1 [q-bio.GN])

    [http://arxiv.org/abs/2306.15006](http://arxiv.org/abs/2306.15006)

    本研究提出了DNABERT-2，一个用于多种物种基因组的高效基础模型和基准。我们通过使用基于统计的数据压缩算法Byte Pair Encoding（BPE）替代传统的k-mer标记化，克服了k-mer标记化的计算和样本效率问题，并取得了重要进展。

    

    解码基因组的语言复杂性是生物学中一个关键问题，而DNABERT和Nucleotide Transformer等预训练基础模型在这个领域取得了重要进展。现有的工作主要依赖于k-mer作为基因组语言的标记，由于其简单性。然而，我们认为k-mer标记化引入的计算和样本效率问题是发展大规模基因组基础模型的主要障碍。我们提供了关于基因组标记化的概念和经验见解，基于此提出用基于统计的数据压缩算法Byte Pair Encoding（BPE）替代k-mer标记化，BPE通过迭代合并语料库中最频繁共同出现的基因组片段来构建标记。我们证明，BPE不仅克服了k-mer标记化的局限性，还能从非重叠标记化的计算效率中受益。

    Decoding the linguistic intricacies of the genome is a crucial problem in biology, and pre-trained foundational models such as DNABERT and Nucleotide Transformer have made significant strides in this area. Existing works have largely hinged on k-mer, fixed-length permutations of A, T, C, and G, as the token of the genome language due to its simplicity. However, we argue that the computation and sample inefficiencies introduced by k-mer tokenization are primary obstacles in developing large genome foundational models. We provide conceptual and empirical insights into genome tokenization, building on which we propose to replace k-mer tokenization with Byte Pair Encoding (BPE), a statistics-based data compression algorithm that constructs tokens by iteratively merging the most frequent co-occurring genome segment in the corpus. We demonstrate that BPE not only overcomes the limitations of k-mer tokenization but also benefits from the computational efficiency of non-overlapping tokenizatio
    
[^40]: 嵌入融合的艺术：优化仇恨言论检测

    The Art of Embedding Fusion: Optimizing Hate Speech Detection. (arXiv:2306.14939v1 [cs.CL])

    [http://arxiv.org/abs/2306.14939](http://arxiv.org/abs/2306.14939)

    这项工作研究了优化仇恨言论检测的方法。研究发现，尽管嵌入的组合会略微提高性能，但计算成本很高，并且组合方式对结果的影响较小。

    

    仇恨言论检测是一项具有挑战性的自然语言处理任务，需要捕捉语言和语境细微差别。预训练语言模型（PLMs）提供了丰富的文本语义表示，可以改进这个任务。然而，对于有效地组合PLMs的表示和利用它们的互补优势的方法还知之甚少。在这项工作中，我们揭示了几种PLMs组合技术的方式，并全面分析了它们的有效性。我们的研究结果表明，组合嵌入可以略微改善性能，但计算成本较高，组合方式对最终结果的影响较小。我们还在https://github.com/aflah02/The-Art-of-Embedding-Fusion-Optimizing-Hate-Speech-Detection上公开了我们的代码库。

    Hate speech detection is a challenging natural language processing task that requires capturing linguistic and contextual nuances. Pre-trained language models (PLMs) offer rich semantic representations of text that can improve this task. However there is still limited knowledge about ways to effectively combine representations across PLMs and leverage their complementary strengths. In this work, we shed light on various combination techniques for several PLMs and comprehensively analyze their effectiveness. Our findings show that combining embeddings leads to slight improvements but at a high computational cost and the choice of combination has marginal effect on the final outcome. We also make our codebase public at https://github.com/aflah02/The-Art-of-Embedding-Fusion-Optimizing-Hate-Speech-Detection .
    
[^41]: 将双向长短期记忆网络与子词嵌入相结合用于作者归属的研究

    Integrating Bidirectional Long Short-Term Memory with Subword Embedding for Authorship Attribution. (arXiv:2306.14933v1 [cs.CL])

    [http://arxiv.org/abs/2306.14933](http://arxiv.org/abs/2306.14933)

    这项研究提出了一种将双向长短期记忆网络与子词嵌入相结合的方法，用于解决作者归属问题。该方法能够在处理文本中的隐含词问题的同时保留词的顺序上下文。

    

    揭示给定文本文档的作者身份是作者归属问题。深度学习方法已成功地使用多样的基于词的风格标记来处理作者归属的内在问题。然而，基于词的作者归属系统的性能受到训练语料库词汇的限制。文献推荐了以字符为基础的风格标记作为克服隐含词问题的替代方法。然而，基于字符的方法经常无法捕捉文本中的词的顺序关系，这是进一步改善的难题。本文讨论的问题是是否可以解决文本文档中隐含词的歧义性，同时保留词的顺序上下文。因此，提出了一种基于双向长短期记忆网络（BLSTM）与二维卷积神经网络（CNN）相结合的方法来捕捉顺序上下文。

    The problem of unveiling the author of a given text document from multiple candidate authors is called authorship attribution. Manifold word-based stylistic markers have been successfully used in deep learning methods to deal with the intrinsic problem of authorship attribution. Unfortunately, the performance of word-based authorship attribution systems is limited by the vocabulary of the training corpus. Literature has recommended character-based stylistic markers as an alternative to overcome the hidden word problem. However, character-based methods often fail to capture the sequential relationship of words in texts which is a chasm for further improvement. The question addressed in this paper is whether it is possible to address the ambiguity of hidden words in text documents while preserving the sequential context of words. Consequently, a method based on bidirectional long short-term memory (BLSTM) with a 2-dimensional convolutional neural network (CNN) is proposed to capture sequ
    
[^42]: LLM辅助内容分析：利用大型语言模型支持演绎编码

    LLM-Assisted Content Analysis: Using Large Language Models to Support Deductive Coding. (arXiv:2306.14924v1 [cs.CL])

    [http://arxiv.org/abs/2306.14924](http://arxiv.org/abs/2306.14924)

    本研究探索了使用大型语言模型（LLMs）来减少演绎编码所需时间的方法，同时保留传统内容分析的灵活性。通过一个案例研究和经验基准测试，证明了在不同演绎编码任务上，GPT-3.5在LLM辅助内容分析（LACA）中的有效性。

    

    演绎编码是一种广泛使用的定性研究方法，用于确定文档中主题的普遍性。尽管有用，演绎编码通常是繁琐且耗时的，因为它要求研究人员阅读、解释并可靠地对大量非结构化文本进行分类。大型语言模型（LLMs），如ChatGPT，是一类快速发展的人工智能工具，可以执行各种自然语言处理和推理任务。在这项研究中，我们探索了使用LLMs来减少演绎编码所需的时间，同时保留传统内容分析的灵活性。我们概述了所提出的方法，称为LLM辅助内容分析（LACA），并使用GPT-3.5在一个公开可用的演绎编码数据集上进行了深入案例研究。此外，我们还进行了一个经验基准测试，使用LACA在4个公开可用的数据集上评估GPT-3.5在不同演绎编码任务上的表现。

    Deductive coding is a widely used qualitative research method for determining the prevalence of themes across documents. While useful, deductive coding is often burdensome and time consuming since it requires researchers to read, interpret, and reliably categorize a large body of unstructured text documents. Large language models (LLMs), like ChatGPT, are a class of quickly evolving AI tools that can perform a range of natural language processing and reasoning tasks. In this study, we explore the use of LLMs to reduce the time it takes for deductive coding while retaining the flexibility of a traditional content analysis. We outline the proposed approach, called LLM-assisted content analysis (LACA), along with an in-depth case study using GPT-3.5 for LACA on a publicly available deductive coding data set. Additionally, we conduct an empirical benchmark using LACA on 4 publicly available data sets to assess the broader question of how well GPT-3.5 performs across a range of deductive co
    
[^43]: 使用ChatGPT进行产品信息提取

    Product Information Extraction using ChatGPT. (arXiv:2306.14921v1 [cs.CL])

    [http://arxiv.org/abs/2306.14921](http://arxiv.org/abs/2306.14921)

    使用ChatGPT进行产品信息提取，解决了传统方法对大量训练数据和泛化到未知属性和属性值的困难，为电子商务应用提供了可能的解决方案。

    

    以属性/值对的形式呈现的结构化产品数据是许多电子商务应用的基础，例如分面产品搜索、产品比较和产品推荐。产品报价通常只包含以标题或自由文本形式呈现的产品属性的文本描述。因此，从文本产品描述中提取属性/值对对于电子商务应用非常重要。为了表现出色，最先进的产品信息提取方法需要大量的任务特定训练数据。这些方法还难以推广到训练数据中没有包含的分布之外的属性和属性值。由于在大量文本上进行预训练以及由于模型规模导致的新兴效果，像ChatGPT这样的大型语言模型具有解决这两个缺点的潜力。本文探讨了ChatGPT在提取属性/值对方面的潜力。

    Structured product data in the form of attribute/value pairs is the foundation of many e-commerce applications such as faceted product search, product comparison, and product recommendation. Product offers often only contain textual descriptions of the product attributes in the form of titles or free text. Hence, extracting attribute/value pairs from textual product descriptions is an essential enabler for e-commerce applications. In order to excel, state-of-the-art product information extraction methods require large quantities of task-specific training data. The methods also struggle with generalizing to out-of-distribution attributes and attribute values that were not a part of the training data. Due to being pre-trained on huge amounts of text as well as due to emergent effects resulting from the model size, Large Language Models like ChatGPT have the potential to address both of these shortcomings. This paper explores the potential of ChatGPT for extracting attribute/value pairs f
    
[^44]: 利用自然语言处理进行课堂讨论的自动评估

    Utilizing Natural Language Processing for Automated Assessment of Classroom Discussion. (arXiv:2306.14918v1 [cs.CL])

    [http://arxiv.org/abs/2306.14918](http://arxiv.org/abs/2306.14918)

    本研究利用自然语言处理技术，通过自动生成细化标准得分，实现对课堂讨论质量的自动评估。实验结果令人鼓舞，同时指出标准仍有改进空间，并发现不同的NLP方法对不同的标准更有效。

    

    严格而互动的课堂讨论对于学习至关重要，同时也是大多数教学干预的核心组成部分。然而，对讨论质量进行规模化的正式评估对于大多数研究者来说是昂贵且不可行的。在这项工作中，我们尝试了各种现代自然语言处理（NLP）技术，以自动生成课堂文本讨论质量的细化标准得分。具体而言，我们使用了包含超过18000轮次、注释有详细的教学分析运动（ATM）代码的90个课堂讨论记录数据集，并聚焦于四个教学质量评估（IQA）标准。尽管数据量有限，我们的工作在一些标准上取得了令人鼓舞的结果，同时也暗示其他标准仍有改进空间。我们还发现，某些NLP方法在某些标准上效果更好。

    Rigorous and interactive class discussions that support students to engage in high-level thinking and reasoning are essential to learning and are a central component of most teaching interventions. However, formally assessing discussion quality 'at scale' is expensive and infeasible for most researchers. In this work, we experimented with various modern natural language processing (NLP) techniques to automatically generate rubric scores for individual dimensions of classroom text discussion quality. Specifically, we worked on a dataset of 90 classroom discussion transcripts consisting of over 18000 turns annotated with fine-grained Analyzing Teaching Moves (ATM) codes and focused on four Instructional Quality Assessment (IQA) rubrics. Despite the limited amount of data, our work shows encouraging results in some of the rubrics while suggesting that there is room for improvement in the others. We also found that certain NLP approaches work better for certain rubrics.
    
[^45]: 迈向教育问题生成的丰富可控性

    Towards Enriched Controllability for Educational Question Generation. (arXiv:2306.14917v1 [cs.CL])

    [http://arxiv.org/abs/2306.14917](http://arxiv.org/abs/2306.14917)

    本研究旨在通过引入新的引导属性（问题明确性）来丰富教育问题生成的可控性。我们提出了通过控制生成明确和隐含wh-问题的方法。研究展示了通过问题明确性和叙事要素同时控制问题生成的初步证据。

    

    生成问题（QG）是自然语言处理（NLP）中的一个任务，它涉及根据输入（通常由文本和目标答案组成）自动生成问题。近期关于QG的研究旨在控制生成问题的类型，以满足教育需求。教育QG中可控性的一个显著例子是生成涉及特定叙事要素的问题，例如因果关系、结果解决或预测。本研究旨在通过引入新的引导属性（问题明确性）来丰富QG的可控性。我们提议通过控制从适合儿童的故事中生成明确和隐含的wh-问题。我们展示了仅通过问题明确性以及与另一个目标属性（问题的叙事要素）同时控制QG的初步证据。代码公开可在github.com/bernardoleite/question-generation-control获取。

    Question Generation (QG) is a task within Natural Language Processing (NLP) that involves automatically generating questions given an input, typically composed of a text and a target answer. Recent work on QG aims to control the type of generated questions so that they meet educational needs. A remarkable example of controllability in educational QG is the generation of questions underlying certain narrative elements, e.g., causal relationship, outcome resolution, or prediction. This study aims to enrich controllability in QG by introducing a new guidance attribute: question explicitness. We propose to control the generation of explicit and implicit wh-questions from children-friendly stories. We show preliminary evidence of controlling QG via question explicitness alone and simultaneously with another target attribute: the question's narrative element. The code is publicly available at github.com/bernardoleite/question-generation-control.
    
[^46]: FSUIE:一种用于普适信息抽取的新型模糊跨度机制

    FSUIE: A Novel Fuzzy Span Mechanism for Universal Information Extraction. (arXiv:2306.14913v1 [cs.CL])

    [http://arxiv.org/abs/2306.14913](http://arxiv.org/abs/2306.14913)

    FSUIE是一种用于普适信息抽取的新型模糊跨度机制，通过引入模糊跨度损失和模糊跨度注意力，能够在快速收敛和少量数据训练轮数的情况下显著提高信息抽取的性能。

    

    普适信息抽取（UIE）作为一个统一的框架已经取得了广泛成功，但UIE模型存在一些局限性。例如，在训练过程中，它们过于依赖于数据中的跨度边界，这并不反映跨度注释的真实挑战。微小的位置调整也可以满足要求。此外，UIE模型缺乏对信息抽取中有限的跨度长度特征的关注。为了解决这些问题，我们提出了模糊跨度普适信息抽取（FSUIE）框架。具体而言，我们的贡献包括模糊跨度损失和模糊跨度注意力两个概念。我们在一系列主要的信息抽取任务上的实验结果显示，在数据量和训练轮数较少的情况下，与基准模型相比，FSUIE在快速收敛和强大性能方面取得了显著改进。这些结果证明了FSUIE的有效性和泛化能力。

    Universal Information Extraction (UIE) has been introduced as a unified framework for various Information Extraction (IE) tasks and has achieved widespread success. Despite this, UIE models have limitations. For example, they rely heavily on span boundaries in the data during training, which does not reflect the reality of span annotation challenges. Slight adjustments to positions can also meet requirements. Additionally, UIE models lack attention to the limited span length feature in IE. To address these deficiencies, we propose the Fuzzy Span Universal Information Extraction (FSUIE) framework. Specifically, our contribution consists of two concepts: fuzzy span loss and fuzzy span attention. Our experimental results on a series of main IE tasks show significant improvement compared to the baseline, especially in terms of fast convergence and strong performance with small amounts of data and training epochs. These results demonstrate the effectiveness and generalization of FSUIE in di
    
[^47]: 在同伴辅导互动中识别措辞的研究

    "You might think about slightly revising the title": identifying hedges in peer-tutoring interactions. (arXiv:2306.14911v1 [cs.CL])

    [http://arxiv.org/abs/2306.14911](http://arxiv.org/abs/2306.14911)

    该研究利用多模态同伴辅导数据集构建了一个计算框架，用于识别同伴辅导互动中的措辞。最佳表现的是一个混合方法，它比现有基准更好且更容易解释，并发现了一些新特征。

    

    措辞在对话互动中起着重要作用。在同伴辅导中，导师在缺乏默契的双人对话中使用措辞来减轻指令和负反馈的影响。为了建立一个管理与学生的亲密关系以提高学习效果的辅导代理系统，我们利用多模态同伴辅导数据集构建了一个用于识别措辞的计算框架。我们比较了依赖预训练资源和结合社会科学文献见解的方法。我们的最佳表现来自一个混合方法，其性能优于现有基准，并且更容易解释。我们使用一个模型可解释性工具探索了同伴辅导对话中特征的特点，并识别了一些新特征以及这种混合模型方法的好处。

    Hedges play an important role in the management of conversational interaction. In peer tutoring, they are notably used by tutors in dyads (pairs of interlocutors) experiencing low rapport to tone down the impact of instructions and negative feedback. Pursuing the objective of building a tutoring agent that manages rapport with students in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of such a hybrid model approach.
    
[^48]: 机器学习语言模型时代中人标记数据的重要性

    The Importance of Human-Labeled Data in the Era of LLMs. (arXiv:2306.14910v1 [cs.CL])

    [http://arxiv.org/abs/2306.14910](http://arxiv.org/abs/2306.14910)

    本文论述了在LLMs时代，人标记数据仍然具有重要性的论据和支持。

    

    大型语言模型（LLMs）的出现在定制机器学习模型的开发方面带来了一场革命，并引发了关于重新定义数据要求的讨论。LLMs的训练和实施所带来的自动化引发了对人工标记干预可能不再具有与监督学习时代相同重要性的讨论和期望。本文提出了有力的论据，支持在LLMs时代人标记数据的持续重要性。

    The advent of large language models (LLMs) has brought about a revolution in the development of tailored machine learning models and sparked debates on redefining data requirements. The automation facilitated by the training and implementation of LLMs has led to discussions and aspirations that human-level labeling interventions may no longer hold the same level of importance as in the era of supervised learning. This paper presents compelling arguments supporting the ongoing relevance of human-labeled data in the era of LLMs.
    
[^49]: 点击诱饵标题和自然语言处理中的剧透分类

    Clickbait Classification and Spoiling Using Natural Language Processing. (arXiv:2306.14907v1 [cs.CL])

    [http://arxiv.org/abs/2306.14907](http://arxiv.org/abs/2306.14907)

    本文针对点击诱饵标题进行分类和剧透的任务。对于分类任务，提出了两个二元分类器来确定最终的剧透类型；对于剧透任务，采用问答模型和大型语言模型生成剧透信息。实验证明，所提出的模型在任务1中优于基准模型。

    

    点击诱饵是一种通过精心设计标题来激励读者点击文章的做法。这些使用夸张语言的标题尽可能少地透露信息。有时，点击诱饵会故意误导读者，因此自然语言处理（NLP）可以扫描文章并回答点击诱饵标题提出的问题，或者剧透信息。我们解决了两个任务：将点击诱饵分类为3种类型之一（任务1），以及剧透点击诱饵（任务2）。对于任务1，我们提出了两个二元分类器来确定最终的剧透类型。对于任务2，我们尝试了两种方法：使用问答模型来识别剧透文本的范围，以及使用大型语言模型（LLM）生成剧透信息。由于剧透信息包含在文章中，我们将第二个任务描述为一种用于识别剧透信息开始和结束位置的问答方法。我们创建的任务1模型优于提出的基准模型。

    Clickbait is the practice of engineering titles to incentivize readers to click through to articles. Such titles with sensationalized language reveal as little information as possible. Occasionally, clickbait will be intentionally misleading, so natural language processing (NLP) can scan the article and answer the question posed by the clickbait title, or spoil it. We tackle two tasks: classifying the clickbait into one of 3 types (Task 1), and spoiling the clickbait (Task 2). For Task 1, we propose two binary classifiers to determine the final spoiler type. For Task 2, we experiment with two approaches: using a question-answering model to identify the span of text of the spoiler, and using a large language model (LLM) to generate the spoiler. Because the spoiler is contained in the article, we frame the second task as a question-answering approach for identifying the starting and ending positions of the spoiler. We created models for Task 1 that were better than the baselines proposed
    
[^50]: PRISMA-DFLLM：PRISMA的一种扩展，使用领域特定的大型语言模型进行系统文献综述

    PRISMA-DFLLM: An Extension of PRISMA for Systematic Literature Reviews using Domain-specific Finetuned Large Language Models. (arXiv:2306.14905v1 [cs.CL])

    [http://arxiv.org/abs/2306.14905](http://arxiv.org/abs/2306.14905)

    PRISMA-DFLLM是将大型语言模型(LLMs)与PRISMA的严格报告指南相结合，通过在领域特定的学术论文上进行微调，提高了系统文献综述的效率和可扩展性，同时开启了新的研究机遇。

    

    随着开源大型语言模型（LLMs）的普及和高效的微调技术，我们正处于涌现出许多针对专业领域和应用的特定领域LLMs的阶段，这些LLMs已经针对当前通用LLMs无法适应的专业领域进行了微调。在学术界，这项技术有潜力改变我们进行系统文献综述（SLRs）的方式，获取知识和生成新见解。本文提出了一种结合LLMs强大能力和Preferred Reporting Items for Systematic Reviews and Meta-Analyses（PRISMA）的严格报告指南的AI-Enabled方法框架。通过对通过严格SLR过程选定的领域特定学术论文进行LLMs微调，提出的PRISMA-DFLLM（用于领域特定的LLMs微调）报告指南具有更高的效率、可重复性和可扩展性，并同时开启了一系列新的研究机遇。

    With the proliferation of open-sourced Large Language Models (LLMs) and efficient finetuning techniques, we are on the cusp of the emergence of numerous domain-specific LLMs that have been finetuned for expertise across specialized fields and applications for which the current general-purpose LLMs are unsuitable. In academia, this technology has the potential to revolutionize the way we conduct systematic literature reviews (SLRs), access knowledge and generate new insights. This paper proposes an AI-enabled methodological framework that combines the power of LLMs with the rigorous reporting guidelines of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). By finetuning LLMs on domain-specific academic papers that have been selected as a result of a rigorous SLR process, the proposed PRISMA-DFLLM (for Domain-specific Finetuned LLMs) reporting guidelines offer the potential to achieve greater efficiency, reusability and scalability, while also opening the po
    
[^51]: 从社交网络中检测抑郁情绪并进行情感知识共享

    Detect Depression from Social Networks with Sentiment Knowledge Sharing. (arXiv:2306.14903v1 [cs.CL])

    [http://arxiv.org/abs/2306.14903](http://arxiv.org/abs/2306.14903)

    本论文通过深度学习技术以及情感知识共享，从社交网络消息中识别抑郁症的潜在迹象，旨在提供早期心理健康状况识别的方法。

    

    社交网络在传播人们的观点、情绪、思维和恐惧方面起着重要作用。值得注意的是，在COVID-19大流行期间的封锁期后，抑郁症问题引起了人们的越来越多的关注，许多人借助社交网络表达情绪。利用深度学习技术从社交网络消息中辨别潜在的抑郁症迹象有助于早期识别心理健康状况。目前，通过社交网络检测抑郁症的努力通常仅依靠对文本内容进行分析，忽略了其他潜在信息。在这项工作中，我们进行了彻底的研究，揭示了抑郁症和负面情绪状态之间的强相关性。将这样的关联作为外部知识的整合可以为检测抑郁症提供宝贵的洞见。因此，我们提出了一种多任务训练框架DeSK，利用情感知识共享来实现。

    Social network plays an important role in propagating people's viewpoints, emotions, thoughts, and fears. Notably, following lockdown periods during the COVID-19 pandemic, the issue of depression has garnered increasing attention, with a significant portion of individuals resorting to social networks as an outlet for expressing emotions. Using deep learning techniques to discern potential signs of depression from social network messages facilitates the early identification of mental health conditions. Current efforts in detecting depression through social networks typically rely solely on analyzing the textual content, overlooking other potential information. In this work, we conduct a thorough investigation that unveils a strong correlation between depression and negative emotional states. The integration of such associations as external knowledge can provide valuable insights for detecting depression. Accordingly, we propose a multi-task training framework, DeSK, which utilizes share
    
[^52]: InterCode:标准化和基准测试具有执行反馈的交互编码

    InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback. (arXiv:2306.14898v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.14898](http://arxiv.org/abs/2306.14898)

    InterCode是一个交互式编码的标准化和基准测试框架，它使用执行反馈作为观察，并提供了安全可重现的执行环境，可以用于开发新的交互式代码生成方法。

    

    人类以基本交互方式编写代码，并依赖于持续的执行反馈来纠正错误，解决歧义和分解任务。尽管最近的LLM展示出了有希望的编码能力，但目前的编码基准主要考虑静态的指令到代码序列转换过程，这可能导致错误传播和生成的代码与其最终执行环境之间的脱节。为了填补这一差距，我们引入了InterCode，这是一个轻量级、灵活且易于使用的交互式编码框架，作为一个标准强化学习（RL）环境，使用代码作为行动，执行反馈作为观察。我们的框架与语言和平台无关，使用独立的Docker环境提供安全和可重现的执行，并且与传统的seq2seq编码方法开箱即用，同时还可以开发新的交互式代码生成方法。我们使用InterCode创建...

    Humans write code in a fundamentally interactive manner and rely on constant execution feedback to correct errors, resolve ambiguities, and decompose tasks. While LLMs have recently exhibited promising coding capabilities, current coding benchmarks mostly consider a static instruction-to-code sequence transduction process, which has the potential for error propagation and a disconnect between the generated code and its final execution environment. To address this gap, we introduce InterCode, a lightweight, flexible, and easy-to-use framework of interactive coding as a standard reinforcement learning (RL) environment, with code as actions and execution feedback as observations. Our framework is language and platform agnostic, uses self-contained Docker environments to provide safe and reproducible execution, and is compatible out-of-the-box with traditional seq2seq coding methods, while enabling the development of new methods for interactive code generation. We use InterCode to create t
    
[^53]: Kosmos-2: 将多模态大规模语言模型与世界连接

    Kosmos-2: Grounding Multimodal Large Language Models to the World. (arXiv:2306.14824v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.14824](http://arxiv.org/abs/2306.14824)

    Kosmos-2是一个多模态大规模语言模型，可以感知物体描述并将文本与视觉世界联系起来。它在多个任务上展示了出色表现，包括多模态接地、多模态引用、感知语言任务以及语言理解和生成。

    

    我们介绍了Kosmos-2，一个多模态大规模语言模型（MLLM），使其能够感知物体描述（例如，边界框）并将文本与视觉世界联系起来。具体而言，我们将引用表达式表示为Markdown中的链接，即``[text span](bounding boxes)''，其中物体描述是位置标记序列。通过与多模态语料库结合，我们构建了大规模的图像文本对（称为GrIT）的数据来训练该模型。除了MLLM的现有功能（例如，感知各种模态，遵循指令和进行上下文学习）外，Kosmos-2还将接地能力集成到下游应用中。我们在广泛的任务上评估了Kosmos-2，包括多模态接地（例如，引用表达理解和短语接地），多模态引用（例如，引用表达生成），感知语言任务以及语言理解和生成。

    We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new capabilities of perceiving object descriptions (e.g., bounding boxes) and grounding text to the visual world. Specifically, we represent refer expressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where object descriptions are sequences of location tokens. Together with multimodal corpora, we construct large-scale data of grounded image-text pairs (called GrIT) to train the model. In addition to the existing capabilities of MLLMs (e.g., perceiving general modalities, following instructions, and performing in-context learning), Kosmos-2 integrates the grounding capability into downstream applications. We evaluate Kosmos-2 on a wide range of tasks, including (i) multimodal grounding, such as referring expression comprehension, and phrase grounding, (ii) multimodal referring, such as referring expression generation, (iii) perception-language tasks, and (iv) language understanding and generatio
    
[^54]: 基于数据驱动的正式敏感机器翻译方法：语言特定处理与合成数据生成

    Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation. (arXiv:2306.14514v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.14514](http://arxiv.org/abs/2306.14514)

    本文介绍了一种基于数据驱动的正式敏感机器翻译方法，通过语言特定处理和合成数据生成，显著改进了翻译性能。

    

    在本文中，我们介绍了一种基于数据驱动的正式敏感机器翻译（FSMT）方法，该方法针对四种目标语言的独特语言特性进行优化。我们的方法主要依靠两个核心策略：语言特定数据处理和使用大规模语言模型和经验性提示工程生成合成数据。该方法相较于基准模型有显著改进，突显了数据中心技术的有效性。我们的提示工程策略通过产生优质的合成翻译示例进一步提高了性能。

    In this paper, we introduce a data-driven approach for Formality-Sensitive Machine Translation (FSMT) that caters to the unique linguistic properties of four target languages. Our methodology centers on two core strategies: 1) language-specific data handling, and 2) synthetic data generation using large-scale language models and empirical prompt engineering. This approach demonstrates a considerable improvement over the baseline, highlighting the effectiveness of data-centric techniques. Our prompt engineering strategy further improves performance by producing superior synthetic translation examples.
    
[^55]: 多模态双重注意力变换器实现跨语音情感识别

    Cross-Language Speech Emotion Recognition Using Multimodal Dual Attention Transformers. (arXiv:2306.13804v1 [cs.CL])

    [http://arxiv.org/abs/2306.13804](http://arxiv.org/abs/2306.13804)

    提出一种多模态双重注意力变换器（MDAT）模型，利用预训练模型进行多模态特征提取，通过引入图形注意和共同关注机制来捕捉不同情感的跨模态依赖，并使用最少的目标语言数据实现改进的跨语言情感识别结果。

    

    尽管语音情感识别（SER）取得了近期的进展，但最先进的系统无法在跨语言环境中实现改进的性能。本文提出了一种多模态双重注意力变换器（MDAT）模型，以改进跨语言SER。我们的模型利用预训练模型进行多模态特征提取，并配备双重注意机制，包括图形注意和共同关注，以捕获不同模态之间的复杂依赖关系，并使用最少的目标语言数据实现改进的跨语言SER结果。此外，我们的模型还利用变换器编码器层进行高层特征表示，以提高情感分类准确性。MDAT在各个阶段执行特征表示的细化，并为分类层提供情感显着特征。这种新颖方法还确保了模态特定的情感信息的保存，同时增强了交叉模态。

    Despite the recent progress in speech emotion recognition (SER), state-of-the-art systems are unable to achieve improved performance in cross-language settings. In this paper, we propose a Multimodal Dual Attention Transformer (MDAT) model to improve cross-language SER. Our model utilises pre-trained models for multimodal feature extraction and is equipped with a dual attention mechanism including graph attention and co-attention to capture complex dependencies across different modalities and achieve improved cross-language SER results using minimal target language data. In addition, our model also exploits a transformer encoder layer for high-level feature representation to improve emotion classification accuracy. In this way, MDAT performs refinement of feature representation at various stages and provides emotional salient features to the classification layer. This novel approach also ensures the preservation of modality-specific emotional information while enhancing cross-modality 
    
[^56]: 注意力机制中的边缘最大化

    Margin Maximization in Attention Mechanism. (arXiv:2306.13596v1 [cs.LG])

    [http://arxiv.org/abs/2306.13596](http://arxiv.org/abs/2306.13596)

    这篇论文证明了，在softmax-attention模型中，通过在p或等价的W上运行梯度下降，可以收敛到一个最大边缘解，这将局部最优的标记与非最优的标记分隔开。这明确地将注意力机制形式化为标记分离机制。

    

    注意力机制是Transformer架构的核心组件，也是大型语言模型取得惊人成功的原因之一。然而，注意力机制背后的理论原则尚不清楚，特别是它的非凸优化动力学。本文探讨了开创性的softmax-attention模型$f(\boldsymbol{X})=\langle \boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$，其中$\boldsymbol{X}$是标记序列，$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$是可调参数。我们证明了在$\boldsymbol{p}$或等价的$\boldsymbol{W}$上运行梯度下降会沿着方向收敛到分隔“局部最优”标记和“非最优”标记的最大边缘解。这明确地形式化了注意力作为一种标记分离机制。值得注意的是，我们的结果适用于一般数据，并使用嵌入$\boldsymbol{Xv}$和$\texttt{softmax}(\boldsymbol{XWp})$精细地表征标记的“最优性”。

    Attention mechanism is a central component of the transformer architecture which led to the phenomenal success of large language models. However, the theoretical principles underlying the attention mechanism are poorly understood, especially its nonconvex optimization dynamics. In this work, we explore the seminal softmax-attention model $f(\boldsymbol{X})=\langle \boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where, $\boldsymbol{X}$ is the token sequence and $(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are tunable parameters. We prove that running gradient descent on $\boldsymbol{p}$, or equivalently $\boldsymbol{W}$, converges in direction to a max-margin solution that separates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearly formalizes attention as a token separation mechanism. Remarkably, our results are applicable to general data and precisely characterize $\textit{optimality}$ of tokens in terms of the value embeddings $\boldsymbol{Xv}$ and
    
[^57]: 通过半透过最大似然估计学习描述性图像字幕

    Learning Descriptive Image Captioning via Semipermeable Maximum Likelihood Estimation. (arXiv:2306.13460v1 [cs.CL])

    [http://arxiv.org/abs/2306.13460](http://arxiv.org/abs/2306.13460)

    本文通过半透过最大似然估计方法，鼓励模型生成更详细的长字幕。

    

    图像字幕旨在用自然语言描述视觉内容。然而，由于最大似然估计是训练目标，字幕模型在预测与标签不匹配时会受到惩罚。本文提出了半透过最大似然估计（SMILE）方法，允许丰富性优化同时阻止简洁性优化，从而鼓励模型生成更详细的长字幕。

    Image captioning aims to describe visual content in natural language. As 'a picture is worth a thousand words', there could be various correct descriptions for an image. However, with maximum likelihood estimation as the training objective, the captioning model is penalized whenever its prediction mismatches with the label. For instance, when the model predicts a word expressing richer semantics than the label, it will be penalized and optimized to prefer more concise expressions, referred to as conciseness optimization. In contrast, predictions that are more concise than labels lead to richness optimization. Such conflicting optimization directions could eventually result in the model generating general descriptions. In this work, we introduce Semipermeable MaxImum Likelihood Estimation (SMILE), which allows richness optimization while blocking conciseness optimization, thus encouraging the model to generate longer captions with more details. Extensive experiments on two mainstream im
    
[^58]: DiversiGATE: 一个可靠的大规模语言模型全面框架

    DiversiGATE: A Comprehensive Framework for Reliable Large Language Models. (arXiv:2306.13230v1 [cs.CL])

    [http://arxiv.org/abs/2306.13230](http://arxiv.org/abs/2306.13230)

    DiversiGATE是一个统一框架，汇集了多种LLM验证方法，其中包括自一致性、数学提示和WebGPT，同时提出了一个符合该框架的新模型“SelfLearner”，该模型可以从自己的输出中学习并优化性能，在实验中表现良好，GSM8K基准测试上提高了7%的性能。

    

    本文提出了DiversiGATE，一个统一的框架，汇集LLM验证的多种方法。该框架包括两个主要组成部分：多样化和聚合，在现有的验证方法上提供了全面的视角，例如自一致性、数学提示和WebGPT。此外，本文提出了一个新颖的“SelfLearner”模型，符合DiversiGATE框架，可以从自己的输出中学习并随着时间的推移不断完善其性能，从而提高准确性。为了评估SelfLearner的有效性，我们进行了一系列严格的实验，包括对合成数据和广泛使用的算术推理基准测试GSM8K的测试。我们的结果表明，我们的方法优于传统的LLMs，在GSM8K基准测试中实现了可观的54.8%->61.8%的提高。

    In this paper, we introduce DiversiGATE, a unified framework that consolidates diverse methodologies for LLM verification. The proposed framework comprises two main components: Diversification and Aggregation which provide a holistic perspective on existing verification approaches, such as Self-Consistency, Math Prompter and WebGPT. Furthermore, we propose a novel `SelfLearner' model that conforms to the DiversiGATE framework which can learn from its own outputs and refine its performance over time, leading to improved accuracy. To evaluate the effectiveness of SelfLearner, we conducted a rigorous series of experiments, including tests on synthetic data as well as on popular arithmetic reasoning benchmarks such as GSM8K. Our results demonstrate that our approach outperforms traditional LLMs, achieving a considerable 54.8% -> 61.8% improvement on the GSM8K benchmark.
    
[^59]: 评估和改进大型语言模型的时间推理能力的基准研究

    Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models. (arXiv:2306.08952v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.08952](http://arxiv.org/abs/2306.08952)

    本研究提出了一个全面的探测数据集来评估大型语言模型的时间推理能力，并提出了一种使用时间跨度提取和时敏性强化学习的新型学习框架来改进大型语言模型的时间推理能力。实验结果表明该方法的有效性。

    

    时间推理是非常重要的。许多事实是与时间相关的。例如，运动员会不时地更换球队，不同的政府官员会定期进行选举。先前的时间相关问题回答（QA）数据集往往在时间跨度或问题类型的涵盖上存在偏见。在本文中，我们介绍了一个全面的探测数据集\tempreason，用于评估大型语言模型的时间推理能力。我们的数据集包括三个时间推理级别的问题。此外，我们还提出了一种基于时间跨度提取和时敏性强化学习的新型学习框架，以改进大型语言模型的时间推理能力。我们在封闭书式QA、开放书式QA和推理QA设置中进行了实验，并证明了我们方法的有效性。我们的代码和数据已在https://github.com/DAMO-NLP-SG/TempReason上发布。

    Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types. In this paper, we introduce a comprehensive probing dataset \tempreason to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning. We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach. Our code and data are released on https://github.com/DAMO-NLP-SG/TempReason.
    
[^60]: 自然语言处理中社会人口统计偏见的调查

    Survey on Sociodemographic Bias in Natural Language Processing. (arXiv:2306.08158v1 [cs.CL])

    [http://arxiv.org/abs/2306.08158](http://arxiv.org/abs/2306.08158)

    本文调查了209篇关于NLP模型偏见的论文，其中大部分涉及社会人口统计偏见。研究者提出了社会人口统计偏见的定义，并确定了NLP偏见研究的三个主要类别。当前去偏见技术只是隐藏了偏见而不是真正去除它，需要进一步改进。

    

    深度神经网络在训练过程中往往会学习到非预期的偏见，这在实际应用中可能会产生有害的影响。本文对209篇关于NLP模型中偏见的论文进行了调查，其中大部分论文涉及社会人口统计偏见。为了更好地理解偏见与真实世界的危害之间的区别，我们借鉴心理学和行为经济学的思想，提出了社会人口统计偏见的定义。我们确定了NLP偏见研究的三个主要类别：偏见类型、量化偏见和去偏见。我们认为当前对于量化偏见的方法存在可靠性问题，许多偏见度量并不涉及真实世界中的偏见，当前的去偏见技术是表面的，只是隐藏了偏见，而不是真正去除它。最后，我们提供了未来工作的建议。

    Deep neural networks often learn unintended biases during training, which might have harmful effects when deployed in real-world settings. This paper surveys 209 papers on bias in NLP models, most of which address sociodemographic bias. To better understand the distinction between bias and real-world harm, we turn to ideas from psychology and behavioral economics to propose a definition for sociodemographic bias. We identify three main categories of NLP bias research: types of bias, quantifying bias, and debiasing. We conclude that current approaches on quantifying bias face reliability issues, that many of the bias metrics do not relate to real-world biases, and that current debiasing techniques are superficial and hide bias rather than removing it. Finally, we provide recommendations for future work.
    
[^61]: LLMZip：使用大型语言模型的无损文本压缩

    LLMZip: Lossless Text Compression using Large Language Models. (arXiv:2306.04050v1 [cs.IT])

    [http://arxiv.org/abs/2306.04050](http://arxiv.org/abs/2306.04050)

    本研究使用大型语言模型提出了一种结合预测和无损压缩方案的英文文本压缩算法，并在初步实验中表现优于当前最先进的文本压缩方案。

    

    本文使用大型语言模型LLaMA-7B对英语熵的渐近上界提出了新估计值，并提出了一种结合大型语言模型预测与无损压缩方案的英文文本压缩算法。初步实验结果显示，我们的算法优于当前最先进的文本压缩方案，如BSC、ZPAQ和paq8h。

    We provide new estimates of an asymptotic upper bound on the entropy of English using the large language model LLaMA-7B as a predictor for the next token given a window of past tokens. This estimate is significantly smaller than currently available estimates in \cite{cover1978convergent}, \cite{lutati2023focus}. A natural byproduct is an algorithm for lossless compression of English text which combines the prediction from the large language model with a lossless compression scheme. Preliminary results from limited experiments suggest that our scheme outperforms state-of-the-art text compression schemes such as BSC, ZPAQ, and paq8h.
    
[^62]: 语言模型是有限实用说话者

    Language Models are Bounded Pragmatic Speakers. (arXiv:2305.17760v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17760](http://arxiv.org/abs/2305.17760)

    本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。经过人类反馈的强化学习微调的大型语言模型具有概念上类似于 快与慢思考模型的思维模型，而这种思维模型被归因于人类。此研究凸显了采用认知概率建模方法对语言模型的理解、评估和推进的价值。

    

    本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。特别地，我们展示了经过人类反馈的强化学习微调的大型语言模型（Ouyang等人，2022）具有概念上类似于 快与慢思考模型（Kahneman，2011）的思维模型，而这种思维模型被心理学家们归因于人类。我们讨论了从人类反馈中的强化学习作为快与慢思考模型的局限性，并提出了扩展这个框架的途径。本研究实质上凸显了采用认知概率建模方法来获得对语言模型的理解、评估和推进方面的深刻见解的价值。

    How do language models "think"? This paper formulates a probabilistic cognitive model called the bounded pragmatic speaker, which can characterize the operation of different variations of language models. Specifically, we demonstrate that large language models fine-tuned with reinforcement learning from human feedback (Ouyang et al., 2022) embody a model of thought that conceptually resembles a fast-and-slow model (Kahneman, 2011), which psychologists have attributed to humans. We discuss the limitations of reinforcement learning from human feedback as a fast-and-slow model of thought and propose avenues for expanding this framework. In essence, our research highlights the value of adopting a cognitive probabilistic modeling approach to gain insights into the comprehension, evaluation, and advancement of language models.
    
[^63]: 跨模态注意力不足：基于不协调感知的多模态情感分析与识别

    Cross-Attention is Not Enough: Incongruity-Aware Multimodal Sentiment Analysis and Emotion Recognition. (arXiv:2305.13583v1 [cs.CL])

    [http://arxiv.org/abs/2305.13583](http://arxiv.org/abs/2305.13583)

    本文提出了一种基于不协调感知的跨模态情感分析方法，通过Hierarchical Crossmodal Transformer with Modality Gating(HCT-MG)模型来确定主要模态并分层融合辅助模态，有效减轻模态之间的不协调感知和信息冗余问题。

    

    多模态融合在情感计算任务中的应用对性能的提升已被证明是有效的。然而，多模态融合的机理尚不清楚，在现实世界中使用它通常会导致大型模型的问题。本文在情感分析的基础上，首先分析了跨模态注意力中一个模态中突出的情感信息如何受到另一个模态的影响。我们发现，由于跨模态的关注，模态之间存在潜在的不协调感知。基于这一发现，我们提出了一种轻量级模型(HCT-MG)，该模型通过分层交叉模态Transformer与模态门控制来确定主要的模态，并分层地将辅助模态纳入其中，以减轻模态之间的不协调感知并减少信息冗余。在三个基准数据集CMU-MOSI、CMU-MOSEI和IEMOCAP上的实验评估验证了我们方法的有效性，表明：1）其优于当前最先进的多模态模型；2）它仅使用少量的超参数和参数；3）它的计算成本较低。

    Fusing multiple modalities for affective computing tasks has proven effective for performance improvement. However, how multimodal fusion works is not well understood, and its use in the real world usually results in large model sizes. In this work, on sentiment and emotion analysis, we first analyze how the salient affective information in one modality can be affected by the other in crossmodal attention. We find that inter-modal incongruity exists at the latent level due to crossmodal attention. Based on this finding, we propose a lightweight model via Hierarchical Crossmodal Transformer with Modality Gating (HCT-MG), which determines a primary modality according to its contribution to the target task and then hierarchically incorporates auxiliary modalities to alleviate inter-modal incongruity and reduce information redundancy. The experimental evaluation on three benchmark datasets: CMU-MOSI, CMU-MOSEI, and IEMOCAP verifies the efficacy of our approach, showing that it: 1) outperfo
    
[^64]: 通过样本重新加权与样本关联测试进行失语症语音的无偏自动语音识别

    Debiased Automatic Speech Recognition for Dysarthric Speech via Sample Reweighting with Sample Affinity Test. (arXiv:2305.13108v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2305.13108](http://arxiv.org/abs/2305.13108)

    本文提出了一种样本重新加权与样本关联测试（Re-SAT）的新方法，用于缓解失语症患者的偏差问题，在不影响健康患者语音的ASR性能的情况下，有效提高了ASR的性能表现。

    

    基于深度学习的自动语音识别系统主要是通过经验风险最小化（ERM）进行训练的。由于ERM利用数据样本的平均表现而不考虑一个群体，例如健康或失语症患者，因此ASR系统无法识别跨群体的性能差异，导致ASR系统存在偏差且其群体性能差异严重。本研究旨在提高语音识别系统的群体稳健性，针对失语症患者进行改进。为了实现我们的目标，我们提出了一种新方法，即样本重新加权与样本关联测试（Re-SAT）。 Re-SAT系统地衡量所给数据样本的去偏帮助性，并通过去偏帮助性加权来缓解偏差。实验结果表明， Re-SAT有助于改善失语症语音的ASR性能，而不会影响健康语音的ASR性能。

    Automatic speech recognition systems based on deep learning are mainly trained under empirical risk minimization (ERM). Since ERM utilizes the averaged performance on the data samples regardless of a group such as healthy or dysarthric speakers, ASR systems are unaware of the performance disparities across the groups. This results in biased ASR systems whose performance differences among groups are severe. In this study, we aim to improve the ASR system in terms of group robustness for dysarthric speakers. To achieve our goal, we present a novel approach, sample reweighting with sample affinity test (Re-SAT). Re-SAT systematically measures the debiasing helpfulness of the given data sample and then mitigates the bias by debiasing helpfulness-based sample reweighting. Experimental results demonstrate that Re-SAT contributes to improved ASR performance on dysarthric speech without performance degradation on healthy speech.
    
[^65]: 构建基于联想知识关系的词-上下文耦合空间用于可解释化语言建模

    Constructing Word-Context-Coupled Space Aligned with Associative Knowledge Relations for Interpretable Language Modeling. (arXiv:2305.11543v1 [cs.CL])

    [http://arxiv.org/abs/2305.11543](http://arxiv.org/abs/2305.11543)

    本文提出了一种可解释的语言建模方法，通过构建词-上下文耦合空间，并引入联想知识网络和上下文相对距离作为语义特征，实现了语言建模可解释性的提高。

    

    作为当前自然语言处理方法的基础，预训练语言模型已经取得了出色的表现。然而，预训练语言模型中深度神经网络的黑箱结构严重限制了语言建模过程的可解释性。本文通过重新审视深度神经表示和语言建模的语义逻辑之间的耦合要求，引入了词-上下文耦合空间(W2CSpace)，通过介绍可解释的统计逻辑和不可解释的神经表示之间的对齐处理来实现。此外，还设计了一种聚类过程来连接词级和上下文级语义。具体来说，在对齐词级语义的过程中引入了可解释的统计逻辑的联想知识网络(AKN)。此外，上下文相对距离被用作下游分类器的语义特征，这与当前的非解释性方法非常不同。

    As the foundation of current natural language processing methods, pre-trained language model has achieved excellent performance. However, the black-box structure of the deep neural network in pre-trained language models seriously limits the interpretability of the language modeling process. After revisiting the coupled requirement of deep neural representation and semantics logic of language modeling, a Word-Context-Coupled Space (W2CSpace) is proposed by introducing the alignment processing between uninterpretable neural representation and interpretable statistical logic. Moreover, a clustering process is also designed to connect the word- and context-level semantics. Specifically, an associative knowledge network (AKN), considered interpretable statistical logic, is introduced in the alignment process for word-level semantics. Furthermore, the context-relative distance is employed as the semantic feature for the downstream classifier, which is greatly different from the current unint
    
[^66]: 区域感知预训练：视觉变压器下的开放词汇物体检测

    Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers. (arXiv:2305.07011v1 [cs.CV])

    [http://arxiv.org/abs/2305.07011](http://arxiv.org/abs/2305.07011)

    本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。

    

    本文提出了区域感知开放词汇视觉变压器（RO-ViT），一种对比图像-文本预训练方法，旨在填补图像级预训练和开放词汇物体检测之间的差距。在预训练阶段，我们建议随机裁剪并调整位置嵌入的区域，而不是使用整个图像位置嵌入。这更好地匹配了检测微调阶段中区域级别上使用位置嵌入的方式。此外，我们用聚焦损失替换了对比学习中常用的softmax交叉熵损失，以更好地学习那些有信息量但难以捕捉的例子。最后，我们利用了最近在新颖物体提案方面的进展，以改进开放词汇检测的微调。我们在LVIS和COCO开放词汇检测基准上评估了完整模型和零-shot转移性能。RO-ViT在LVIS上实现了32.1$AP_r$的最佳效果，超过现有最佳方法5.8个百分点，同时还具有竞争性的零-shot转移检测结果。

    We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a contrastive image-text pretraining recipe to bridge the gap between image-level pretraining and open-vocabulary object detection. At the pretraining phase, we propose to randomly crop and resize regions of positional embeddings instead of using the whole image positional embeddings. This better matches the use of positional embeddings at region-level in the detection finetuning phase. In addition, we replace the common softmax cross entropy loss in contrastive learning with focal loss to better learn the informative yet difficult examples. Finally, we leverage recent advances in novel object proposals to improve open-vocabulary detection finetuning. We evaluate our full model on the LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer. RO-ViT achieves a state-of-the-art 32.1 $AP_r$ on LVIS, surpassing the best existing approach by +5.8 points in addition to competitive zero-shot transfer detec
    
[^67]: SemEval-2023任务3上的mCPT：用于零样本和少样本框架检测的多语言标签感知对比预训练变压器

    mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive Pre-Training of Transformers for Few- and Zero-shot Framing Detection. (arXiv:2303.09901v1 [cs.CL])

    [http://arxiv.org/abs/2303.09901](http://arxiv.org/abs/2303.09901)

    本研究提出了mCPT模型用于多语言的、多标签的零样本或少样本的框架检测任务，并在西班牙语和其他8种语言中取得了良好的成绩。该方案采用了基于多语言变压器的预训练程序，使用标签感知对比损失函数。

    

    本文介绍了零样本的西班牙语框架检测任务的获胜系统，并在另外八种语言中取得了良好的成绩。框架检测任务的挑战在于在只有少量或零个样本的情况下识别一组14个框架，即多语言多标签的少样本和零样本设置。我们开发的解决方案采用了基于多语言变压器的预训练程序，使用标签感知对比损失函数。除了描述系统外，我们还进行了嵌入空间分析和消融研究，以展示我们的预训练程序如何支持框架检测以推进计算框架分析。

    This paper presents the winning system for the zero-shot Spanish framing detection task, which also achieves competitive places in eight additional languages. The challenge of the framing detection task lies in identifying a set of 14 frames when only a few or zero samples are available, i.e., a multilingual multi-label few- or zero-shot setting. Our developed solution employs a pre-training procedure based on multilingual Transformers using a label-aware contrastive loss function. In addition to describing the system, we perform an embedding space analysis and ablation study to demonstrate how our pre-training procedure supports framing detection to advance computational framing analysis.
    
[^68]: 使用会话式语言模型和提示工程从研究论文中提取准确的材料数据

    Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering. (arXiv:2303.05352v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.05352](http://arxiv.org/abs/2303.05352)

    本论文提出了ChatExtract方法，使用先进的对话式语言模型和提示工程，自动从研究论文中提取准确的数据，不需要大量的前期努力和背景知识。

    

    人们正在不断努力用自然语言处理、语言模型和最近出现的大型语言模型（LLM）代替手工从研究论文中提取数据的工作。尽管这些方法可以高效地从大量研究论文中提取数据，但它们需要大量的前期努力、专业知识和编码。在这项工作中，我们提出了ChatExtract方法，它可以通过一个先进的对话式LLM自动提取极准确的数据，几乎不需要初期的努力和背景知识。ChatExtract由一组工程化的提示应用于对话式LLM，既可以识别出具有数据的句子，提取出这些数据，又可以通过一系列跟进问题确保数据的正确性。这些跟进问题很大程度上克服了LLM提供事实不准确答案的已知问题。ChatExtract可以应用于任何对话式LLM，并能提供非常高质量的数据提取。

    There has been a growing effort to replace hand extraction of data from research papers with automated data extraction based on natural language processing, language models, and recently, large language models (LLMs). Although these methods enable efficient extraction of data from large sets of research papers, they require a significant amount of up-front effort, expertise, and coding. In this work we propose the ChatExtract method that can fully automate very accurate data extraction with minimal initial effort and background, using an advanced conversational LLM. ChatExtract consists of a set of engineered prompts applied to a conversational LLM that both identify sentences with data, extract that data, and assure the data's correctness through a series of follow-up questions. These follow-up questions largely overcome known issues with LLMs providing factually inaccurate responses. ChatExtract can be applied with any conversational LLMs and yields very high quality data extraction.
    
[^69]: SpikeGPT：带有脉冲神经网络的生成预训练语言模型

    SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks. (arXiv:2302.13939v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13939](http://arxiv.org/abs/2302.13939)

    本论文提出了一种称之为SpikeGPT的生成语言模型，使用二进制、事件驱动脉冲激活单元进行训练，克服了SNN训练中的挑战性。该模型可以用于大规模语言生成任务。

    

    随着大型语言模型的规模不断扩大，所需的计算资源也随之增加。脉冲神经网络（SNN）已成为一种能够利用稀疏和事件驱动激活减少模型推理计算开销的节能深度学习方法。虽然它们在许多计算机视觉任务上已经具有竞争力，但SNN的训练也被证明更具挑战性。因此，它们的性能落后于现代深度学习，我们尚未看到SNN在语言生成方面的有效性。在本文中，我们受到Receptance Weighted Key Value（RWKV）语言模型的启发，成功实现了“SpikeGPT”，它是一种具有二进制、事件驱动脉冲激活单元的生成语言模型。我们在两种模型变体上训练了所提出的模型：45M和216M参数。据我们所知，SpikeGPT是迄今最大的反向传播训练SNN模型，使其适用于非脉冲模型通常解决的大规模语言生成任务。

    As the size of large language models continue to scale, so does the computational resources required to run it. Spiking Neural Networks (SNNs) have emerged as an energy-efficient approach to deep learning that leverage sparse and event-driven activations to reduce the computational overhead associated with model inference. While they have become competitive with non-spiking models on many computer vision tasks, SNNs have also proven to be more challenging to train. As a result, their performance lags behind modern deep learning, and we are yet to see the effectiveness of SNNs in language generation. In this paper, inspired by the Receptance Weighted Key Value (RWKV) language model, we successfully implement `SpikeGPT', a generative language model with binary, event-driven spiking activation units. We train the proposed model on two model variants: 45M and 216M parameters. To the best of our knowledge, SpikeGPT is the largest backpropagation-trained SNN model to date, rendering it suita
    
[^70]: 审计大型语言模型：一个三层次的方法

    Auditing large language models: a three-layered approach. (arXiv:2302.08500v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08500](http://arxiv.org/abs/2302.08500)

    本文提出了一个三层次的方法来审计大型语言模型（LLMs），包括治理审计、模型审计和应用审计，解决LLMs带来的伦理和社会挑战。

    

    大型语言模型（LLMs）是人工智能（AI）研究的一个重大突破。然而，LLMs的广泛使用也伴随着重大的伦理和社会挑战。先前的研究指出，审计作为一种有前途的治理机制，有助于确保AI系统设计和部署的道德、法律和技术的健壮性。然而，现有的审计程序无法解决LLMs带来的治理挑战，因为LLMs显示出新兴能力，并可适应各种下游任务。在本文中，我们通过概述一种新颖的审计LLMs的蓝图来填补这一空白。具体而言，我们提出了一个三层次的方法，即治理审计（针对设计和传播LLMs的技术提供商）、模型审计（针对LLMs进行预训练但尚未发布的审计）和应用审计（基于LLMs的应用程序的审计），相互补充和相互通知。我们展示了审计在LLMs上的实施可以有效解决伦理和社会挑战。

    Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducte
    
[^71]: Mu$^{2}$SLAM: 多任务、多语言的语音和语言模型

    Mu$^{2}$SLAM: Multitask, Multilingual Speech and Language Models. (arXiv:2212.09553v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09553](http://arxiv.org/abs/2212.09553)

    Mu$^{2}$SLAM是一个多语言的语音和语言模型，通过使用未标记的语音和文本进行预训练，以及利用监督任务提高跨语言和跨模态表示对齐，取得了在CoVoST AST上新的最高性能，并与使用RNN微调的mSLAM模型在Voxpopuli ASR上性能相当。

    

    我们提出了Mu$^{2}$SLAM，它是一个多语言序列到序列模型，同时在超过100种语言的未标记语音、未标记文本和监督数据上进行预训练，覆盖了自动语音识别（ASR）、自动语音翻译（AST）和机器翻译（MT）领域。通过利用量化表示的语音作为目标，Mu$^{2}$SLAM使用类似于T5的序列到序列掩蔽去噪目标在解码器上训练语音-文本模型，并在编码器上使用掩蔽语言建模（MLM）目标来训练未标记语音和文本，同时利用监督任务来提高模型内的跨语言和跨模态表示对齐。在CoVoST AST上，Mu$^{2}$SLAM在公共数据集上训练的模型达到了新的最高水平，在XX-EN翻译上比之前最优结果提高了1.9 BLEU分，对于EN-XX翻译提高了1.1 BLEU分。在Voxpopuli ASR上，我们的模型与使用RNN微调的mSLAM模型的性能相当。

    We present Mu$^{2}$SLAM, a multilingual sequence-to-sequence model pre-trained jointly on unlabeled speech, unlabeled text and supervised data spanning Automatic Speech Recognition (ASR), Automatic Speech Translation (AST) and Machine Translation (MT), in over 100 languages. By leveraging a quantized representation of speech as a target, Mu$^{2}$SLAM trains the speech-text models with a sequence-to-sequence masked denoising objective similar to T5 on the decoder and a masked language modeling (MLM) objective on the encoder, for both unlabeled speech and text, while utilizing the supervised tasks to improve cross-lingual and cross-modal representation alignment within the model. On CoVoST AST, Mu$^{2}$SLAM establishes a new state-of-the-art for models trained on public datasets, improving on xx-en translation over the previous best by 1.9 BLEU points and on en-xx translation by 1.1 BLEU points. On Voxpopuli ASR, our model matches the performance of an mSLAM model fine-tuned with an RNN-
    
[^72]: WACO: 用于语音翻译的词对齐对比学习

    WACO: Word-Aligned Contrastive Learning for Speech Translation. (arXiv:2212.09359v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09359](http://arxiv.org/abs/2212.09359)

    WACO是一种用于极低资源语音到文本翻译的简单而有效的方法，通过对比学习将语音和文本的词级表示连接起来，实验证明WACO在极低资源条件下比基线方法提高了9+ BLEU分。

    

    端到端语音翻译（E2E ST）旨在直接将源语音转化为目标文本。当仅有极少的语音文本数据用于训练时，现有的ST方法的表现很差。我们观察到ST模型的性能与其语音和源文本之间的嵌入相似度密切相关。在本文中，我们提出了一种名为Word-Aligned COntrastive learning（WACO）的简单有效的极低资源语音到文本翻译方法。我们的关键思想是通过对比学习来建立语音和文本模态的词级表示之间的桥梁。我们在MuST-C数据集上评估了WACO和其他方法，该数据集是一个广泛使用的ST基准，并在从IWSLT 2023获取的低资源方向的马耳他语-英语翻译上进行了评估。我们的实验表明，WACO仅使用1小时的并行ST数据，比最好的基准提高了9+ BLEU分。代码可在https://github.com/owaski/WACO上找到。

    End-to-end Speech Translation (E2E ST) aims to directly translate source speech into target text. Existing ST methods perform poorly when only extremely small speech-text data are available for training. We observe that an ST model's performance closely correlates with its embedding similarity between speech and source transcript. In this paper, we propose Word-Aligned COntrastive learning (WACO), a simple and effective method for extremely low-resource speech-to-text translation. Our key idea is bridging word-level representations for both speech and text modalities via contrastive learning. We evaluate WACO and other methods on the MuST-C dataset, a widely used ST benchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our experiments demonstrate that WACO outperforms the best baseline by 9+ BLEU points with only 1-hour parallel ST data. Code is available at https://github.com/owaski/WACO.
    
[^73]: 想象力是你所需要的一切！用于长期对话规划的曲线对比学习的抽象序列建模

    Imagination is All You Need! Curved Contrastive Learning for Abstract Sequence Modeling Utilized on Long Short-Term Dialogue Planning. (arXiv:2211.07591v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07591](http://arxiv.org/abs/2211.07591)

    本文介绍了一种新颖的表示学习技术——曲线对比学习（CCL），用于学习多轮对话中发言对之间的相对转弯距离。利用这种技术可以将目标发言和回复候选项映射到潜在空间中，通过余弦相似性评估候选发言和目标之间的距离。此外，该方法还探索了如何通过曲线空间中的余弦相似度评估序列的可能性，从而想象未来对话模式的可能性。

    

    受时空曲率启发（爱因斯坦，1921），我们引入了曲线对比学习（CCL），这是一种新颖的表示学习技术，用于学习多轮对话中发言对之间的相对转弯距离。通过将目标发言和相应的回复候选项投影到潜在空间中，得到的双编码器模型可以引导变压器作为响应排序模型以零-shot方式朝着目标前进。这里的余弦相似性表示了候选发言朝着相应目标的距离/可达性。此外，我们探讨了如何利用这些前向启示性语言表示来评估序列的可能性，即通过其各个成员（分别编码）的余弦相似度作为曲线空间中的新兴属性。这些非局部属性使我们能够想象未来对话模式的可能性，具体是通过排序/识别未来的go

    Inspired by the curvature of space-time (Einstein, 1921), we introduce Curved Contrastive Learning (CCL), a novel representation learning technique for learning the relative turn distance between utterance pairs in multi-turn dialogues. The resulting bi-encoder models can guide transformers as a response ranking model towards a goal in a zero-shot fashion by projecting the goal utterance and the corresponding reply candidates into a latent space. Here the cosine similarity indicates the distance/reachability of a candidate utterance toward the corresponding goal. Furthermore, we explore how these forward-entailing language representations can be utilized for assessing the likelihood of sequences by the entailment strength i.e. through the cosine similarity of its individual members (encoded separately) as an emergent property in the curved space. These non-local properties allow us to imagine the likelihood of future patterns in dialogues, specifically by ordering/identifying future go
    
[^74]: BLOOM: 一个拥有176B参数的开放式多语言语言模型

    BLOOM: A 176B-Parameter Open-Access Multilingual Language Model. (arXiv:2211.05100v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.05100](http://arxiv.org/abs/2211.05100)

    BLOOM是一个由数百名研究人员合作设计和构建的拥有176B参数的开放式语言模型，它在多种基准测试中表现出竞争性的性能，并在进行多任务提示微调后表现更强。该模型的发布有助于推动大型语言模型技术的民主化。

    BLOOM is an open-access language model with 176B parameters, designed and built by hundreds of researchers. It achieves competitive performance on various benchmarks and shows even stronger results after multitask prompted finetuning. The release of this model facilitates the democratization of large language model technology.

    大型语言模型（LLMs）已被证明能够根据少量演示或自然语言指令执行新任务。尽管这些能力已被广泛采用，但大多数LLMs都是由资源丰富的组织开发的，并经常被保密。为了推动这种强大技术的民主化，我们提出了BLOOM，这是一个由数百名研究人员合作设计和构建的拥有176B参数的开放式语言模型。BLOOM是一个仅解码器的Transformer语言模型，它是在ROOTS语料库上进行训练的，该语料库包括46种自然语言和13种编程语言的数百个来源（总共59种）。我们发现，BLOOM在各种基准测试中取得了竞争性的表现，在进行多任务提示微调后表现更强。为了促进未来使用LLMs的研究和应用，我们在负责任的AI许可下公开发布我们的模型和代码。

    Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.
    
[^75]: SSD-LM: 基于半自回归简单形式的扩散语言模型用于文本生成和模块化控制

    SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control. (arXiv:2210.17432v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.17432](http://arxiv.org/abs/2210.17432)

    SSD-LM是一种半自回归的扩散语言模型，通过在解码时灵活生成文本块并实现本地上下文更新，以及在自然词汇空间上进行扩散，实现了分类器指导和模块化控制。在无约束文本生成基准上，SSD-LM与自回归模型相比，在质量和多样性方面表现出色，并且显著超越了其他基于扩散的模型。

    

    尽管扩散模型在连续值领域（如图像）取得了很大成功，但在离散领域（如文本）中，类似的努力却还没有达到自回归语言模型的性能水平。在这项工作中，我们提出了 SSD-LM，一个基于扩散的语言模型，使用了两个关键设计选择。首先，SSD-LM是半自回归的，通过迭代生成文本块，在解码时允许灵活的输出长度，同时实现本地双向上下文更新。其次，它采用基于单纯形的方法，在自然词汇空间上进行扩散，而不是在学习到的潜在空间上，这使得我们能够在不进行任何自适应的情况下，利用现成的分类器实现分类器指导和模块化控制。我们在无约束文本生成基准上评估了 SSD-LM，并展示它在标准质量和多样性度量上与强大的自回归 GPT-2 模型相匹配或超越，并且远远优于基于扩散的基准模型。

    Despite the growing success of diffusion models in continuous-valued domains (e.g., images), similar efforts for discrete domains such as text have yet to match the performance of autoregressive language models. In this work, we present SSD-LM -- a diffusion-based language model with two key design choices. First, SSD-LM is semi-autoregressive, iteratively generating blocks of text, allowing for flexible output length at decoding time while enabling local bidirectional context updates. Second, it is simplex-based, performing diffusion on the natural vocabulary space rather than a learned latent space, allowing us to incorporate classifier guidance and modular control using off-the-shelf classifiers without any adaptation. We evaluate SSD-LM on unconstrained text generation benchmarks, and show that it matches or outperforms strong autoregressive GPT-2 models across standard quality and diversity metrics, while vastly outperforming diffusion-based baselines. On controlled text generatio
    
[^76]: 省略折叠：压缩CTC发射以实现更快的解码

    Blank Collapse: Compressing CTC emission for the faster decoding. (arXiv:2210.17017v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.17017](http://arxiv.org/abs/2210.17017)

    本文提出了一种省略折叠的方法，通过压缩CTC发射来加快解码速度。实验结果表明，在LibriSpeech数据集上，这种方法可以达到比普通解码快78%的速度，并且准确度的损失非常小。这种方法不仅在实践中有效，而且在理论上有数学依据。

    

    连接时序分类（CTC）模型是一种非常高效的序列建模方法，特别适用于语音数据。为了将CTC模型用于自动语音识别（ASR）任务，需要使用外部语言模型（如n-gram LM）进行束搜索解码，以获得合理的结果。本文深入分析了CTC束搜索中的空标签，并提出了一种非常简单的方法，以减少计算量，从而实现更快的束搜索解码速度。通过这种方法，在LibriSpeech数据集上可以获得比普通束搜索解码快78%的解码速度，同时损失很小的准确度。我们通过实验证明了这种方法不仅在实践中有效，而且在数学上也是有理论依据的。我们还观察到，如果模型的准确度更高，则这种减少效果更加明显。

    Connectionist Temporal Classification (CTC) model is a very efficient method for modeling sequences, especially for speech data. In order to use CTC model as an Automatic Speech Recognition (ASR) task, the beam search decoding with an external language model like n-gram LM is necessary to obtain reasonable results. In this paper we analyze the blank label in CTC beam search deeply and propose a very simple method to reduce the amount of calculation resulting in faster beam search decoding speed. With this method, we can get up to 78% faster decoding speed than ordinary beam search decoding with a very small loss of accuracy in LibriSpeech datasets. We prove this method is effective not only practically by experiments but also theoretically by mathematical reasoning. We also observe that this reduction is more obvious if the accuracy of the model is higher.
    
[^77]: 压缩型多语言机器翻译模型会忽略什么？

    What Do Compressed Multilingual Machine Translation Models Forget?. (arXiv:2205.10828v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.10828](http://arxiv.org/abs/2205.10828)

    本研究评估了压缩方法对多语言神经机器翻译模型在不同语言群体、性别和语义偏差方面的影响，并发现代表性不足的语言性能显著下降。

    

    最近，非常庞大的预训练模型在各种自然语言处理（NLP）任务中取得了最先进的结果，但是它们的大小使得在资源受限的环境中应用它们更具挑战性。压缩技术可以大幅减小模型的大小，从而减少推理时间，并对顶级指标几乎没有影响。然而，对多个任务和/或语言进行平均的综合性能可能掩盖了在代表性不足的功能上的严重性能下降，这可能导致模型所编码的偏见的放大。在这项工作中，我们通过对不同机器翻译基准（FLORES-101、MT-Gender和DiBiMT）上的压缩模型进行全面分析，评估了压缩方法对多语言神经机器翻译模型（MNMT）在不同语言群体、性别和语义偏差方面的影响。我们发现，代表性不足的语言的性能显著下降，而平均BLEU度量值则没什么变化。

    Recently, very large pre-trained models achieve state-of-the-art results in various natural language processing (NLP) tasks, but their size makes it more challenging to apply them in resource-constrained environments. Compression techniques allow to drastically reduce the size of the models and therefore their inference time with negligible impact on top-tier metrics. However, the general performance averaged across multiple tasks and/or languages may hide a drastic performance drop on under-represented features, which could result in the amplification of biases encoded by the models. In this work, we assess the impact of compression methods on Multilingual Neural Machine Translation models (MNMT) for various language groups, gender, and semantic biases by extensive analysis of compressed models on different machine translation benchmarks, i.e. FLORES-101, MT-Gender, and DiBiMT. We show that the performance of under-represented languages drops significantly, while the average BLEU metr
    
[^78]: 通过自我监督的纠缠响应选择实现零样本对话解缠

    Zero-Shot Dialogue Disentanglement by Self-Supervised Entangled Response Selection. (arXiv:2110.12646v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.12646](http://arxiv.org/abs/2110.12646)

    本文提出了一种新的零样本对话解缠方法，通过自我监督的纠缠响应选择，无需标注数据即可实现对长篇多参与者对话的分解，并在实验中获得了较好的聚类F1分数。

    

    对话解缠旨在将长篇多参与者对话中的话语分组成线索。这对于话语分析和对话响应选择等下游应用非常有用，因为它可以作为构建清洁上下文/响应集的第一步。然而，标记所有"回复至"链接需要与话语数量的平方级别的工作量：注释者必须检查所有之前的话语，以确定当前话语是回复给哪个话语。在本文中，我们首次提出了一种零样本对话解缠的解决方案。首先，我们在一个未注释的互动对话响应选择数据集上训练一个模型；然后，我们应用训练好的模型来进行零样本对话解缠。在没有任何标注数据的情况下，我们的模型可以达到25的聚类F1分数。我们还使用不同数量的标注数据对模型进行微调。实验结果表明，仅使用10%的数据，我们可以达到...

    Dialogue disentanglement aims to group utterances in a long and multi-participant dialogue into threads. This is useful for discourse analysis and downstream applications such as dialogue response selection, where it can be the first step to construct a clean context/response set. Unfortunately, labeling all~\emph{reply-to} links takes quadratic effort w.r.t the number of utterances: an annotator must check all preceding utterances to identify the one to which the current utterance is a reply. In this paper, we are the first to propose a~\textbf{zero-shot} dialogue disentanglement solution. Firstly, we train a model on a multi-participant response selection dataset harvested from the web which is not annotated; we then apply the trained model to perform zero-shot dialogue disentanglement. Without any labeled data, our model can achieve a cluster F1 score of 25. We also fine-tune the model using various amounts of labeled data. Experiments show that with only 10\% of the data, we achiev
    
[^79]: 何时需要上下文翻译？一项数据驱动的、多语言的探索

    When Does Translation Require Context? A Data-driven, Multilingual Exploration. (arXiv:2109.07446v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2109.07446](http://arxiv.org/abs/2109.07446)

    本研究开发了多语言语篇感知基准，系统性地确定了需要上下文翻译的现象。发现上下文感知机器翻译模型对于解决这些现象的困难程度有限，为进一步研究提供了挑战。

    

    虽然正确处理语篇对机器翻译的质量有很大影响，但这些改进在常见的翻译质量评估指标中得不到充分衡量。最近的上下文感知机器翻译研究试图针对一小部分语篇现象进行评估，但缺乏完全系统化的方式。在本文中，我们开发了多语言语篇感知（MuDA）基准，这是一系列标记器，用于识别和评估给定数据集中的语篇现象的模型性能。选择的语篇现象受到一种新颖的方法的启发，该方法可系统地确定需要上下文的翻译。我们确认了之前研究的语篇现象的难度，并揭示了之前未解决的其他现象。我们发现常见的上下文感知机器翻译模型仅对上下文无关模型进行了轻微的改进，这表明这些模型并没有有效处理这些歧义。我们发布了14种语言对的代码和数据，以鼓励进一步研究。

    Although proper handling of discourse significantly contributes to the quality of machine translation (MT), these improvements are not adequately measured in common translation quality metrics. Recent works in context-aware MT attempt to target a small set of discourse phenomena during evaluation, however not in a fully systematic way. In this paper, we develop the Multilingual Discourse-Aware (MuDA) benchmark, a series of taggers that identify and evaluate model performance on discourse phenomena in any given dataset. The choice of phenomena is inspired by a novel methodology to systematically identify translations requiring context. We confirm the difficulty of previously studied phenomena while uncovering others that were previously unaddressed. We find that common context-aware MT models make only marginal improvements over context-agnostic models, which suggests these models do not handle these ambiguities effectively. We release code and data for 14 language pairs to encourage th
    
[^80]: 具有持续终身学习的神经主题建模

    Neural Topic Modeling with Continual Lifelong Learning. (arXiv:2006.10909v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2006.10909](http://arxiv.org/abs/2006.10909)

    本研究提出了一个具有持续终身学习的神经主题建模框架，可以处理数据稀疏性，并通过知识的持续积累和转移来提高主题建模的效果。

    

    终身学习吸引了人们对建立机器学习系统的关注，这些系统可以不断积累和传递知识，以帮助未来的学习。无监督主题建模广泛用于从文档集合中发现主题。然而，由于数据稀疏性，例如在一个小的（短）文档集合中，主题建模的应用具有挑战性，从而产生不连贯的主题和次优的文档表示。为了解决这个问题，我们提出了一个神经主题建模的终身学习框架，可以持续处理文档集合的流，积累主题，并通过从多个源的知识转移指导未来的主题建模任务，以更好地处理稀疏数据。在终身过程中，我们特别研究了共享的生成同源性（潜在主题）以在终身中传递先前的知识，以及通过新的选择性遗忘来最小化灾难性遗忘，以保留过去的学习。

    Lifelong learning has recently attracted attention in building machine learning systems that continually accumulate and transfer knowledge to help future learning. Unsupervised topic modeling has been popularly used to discover topics from document collections. However, the application of topic modeling is challenging due to data sparsity, e.g., in a small collection of (short) documents and thus, generate incoherent topics and sub-optimal document representations. To address the problem, we propose a lifelong learning framework for neural topic modeling that can continuously process streams of document collections, accumulate topics and guide future topic modeling tasks by knowledge transfer from several sources to better deal with the sparse data. In the lifelong process, we particularly investigate jointly: (1) sharing generative homologies (latent topics) over lifetime to transfer prior knowledge, and (2) minimizing catastrophic forgetting to retain the past learning via novel sele
    
[^81]: 可解释的、对话主题感知的神经语言理解

    Explainable and Discourse Topic-aware Neural Language Understanding. (arXiv:2006.10632v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2006.10632](http://arxiv.org/abs/2006.10632)

    该论文提出了一个新颖的神经复合语言模型，通过引入可解释性的主题表示和句子级的主题对话，将主题模型和语言模型相结合。实验结果表明，在多个任务上，该模型显示出了良好的性能。

    

    将主题模型与语言模型相结合，通过主题将语言理解扩展到句子之外的更广泛的文档级上下文。现有的方法在语言模型中引入了主题语义，但忽略了文档中句子的主题对话。本研究通过为每个潜在主题的比例相对应地引入可解释性主题表示来扩展研究领域。此外，我们通过为文档中的每个句子建模主题对话，保留句子-主题关联以及文档-主题关联。我们提出了一种新颖的神经复合语言模型，在主题模型和语言模型的联合学习框架中同时利用潜在主题和可解释主题以及句子级的主题对话。我们在多个任务上进行实验，如语言建模、词义消歧等。

    Marrying topic models and language models exposes language understanding to a broader source of document-level context beyond sentences via topics. While introducing topical semantics in language models, existing approaches incorporate latent document topic proportions and ignore topical discourse in sentences of the document. This work extends the line of research by additionally introducing an explainable topic representation in language understanding, obtained from a set of key terms correspondingly for each latent topic of the proportion. Moreover, we retain sentence-topic associations along with document-topic association by modeling topical discourse for every sentence in the document. We present a novel neural composite language model that exploits both the latent and explainable topics along with topical discourse at sentence-level in a joint learning framework of topic and language models. Experiments over a range of tasks such as language modeling, word sense disambiguation, 
    

