# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.](http://arxiv.org/abs/2306.17842) | 本研究引入了SPAE，使用语义金字塔自编码器实现了冻结LLM执行涉及非语言模态的理解和生成任务。通过将图像转化为LLM可理解的词汇标记，我们的方法成功地提升了冻结LLM在图像理解任务中的性能，超过了现有技术25%以上。 |
| [^2] | [Statler: State-Maintaining Language Models for Embodied Reasoning.](http://arxiv.org/abs/2306.17840) | Statler是一个为LLMs赋予了明确的、维持状态的语言模型，可以解决当代LLMs在长时间范围内推理的困难。 |
| [^3] | [Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language Models.](http://arxiv.org/abs/2306.17820) | 本论文提出了一种称为“元推理”的方法，它通过使用语义符号解构的方式，将不同推理问题转化为类似的自然语言表示，以提高大型语言模型的推理能力。 |
| [^4] | [A Massive Scale Semantic Similarity Dataset of Historical English.](http://arxiv.org/abs/2306.17810) | 本研究利用重新数字化的无版权美国本地报纸文章，构建了一个大规模的跨越了70年的语义相似性数据集，并包含近4亿个正向语义相似性对。 |
| [^5] | [Stay on topic with Classifier-Free Guidance.](http://arxiv.org/abs/2306.17806) | 本论文展示了分类器无关的指导（CFG）可以作为一种推断时间技术，显著提高了纯语言建模中各种任务的性能，并能够增强助手在具有挑战性的提示中的准确性和一致性。 |
| [^6] | [Towards Improving the Performance of Pre-Trained Speech Models for Low-Resource Languages Through Lateral Inhibition.](http://arxiv.org/abs/2306.17792) | 本研究通过将微调密集层替换为侧抑制层，提高了低资源语言的预训练语音模型性能，并在罗马尼亚语语料库和Robin技术采集语料库上实现了最先进的结果。 |
| [^7] | [Should you marginalize over possible tokenizations?.](http://arxiv.org/abs/2306.17757) | 该论文分析了语言模型计算字符串概率时是否应该边缘化所有可能的标记化。研究结果表明，在大多数情况下，忽略边缘化计算的差距不超过0.5%，但对于含有长复杂单词的数据来说，这种差距更加明显。 |
| [^8] | [Token-Event-Role Structure-based Multi-Channel Document-Level Event Extraction.](http://arxiv.org/abs/2306.17733) | 本文提出了一种基于Token-Event-Role结构的多通道文档级事件抽取框架，通过引入新的数据结构和预测模块，能够更全面地理解事件之间的关系，并通过预测token-event对的方式，实现了实体和多事件抽取的集成，减少了模型复杂性。 |
| [^9] | [Improved NL2SQL based on Multi-layer Expert Network.](http://arxiv.org/abs/2306.17727) | 本研究提出了一种名为多层专家生成SQL的新方法，通过利用专用的多任务分层网络，该方法解决了由于不同分类任务的负迁移问题导致生成不准确SQL语句的限制。该方法在WiKSQL数据集上取得了良好的效果。 |
| [^10] | [Beyond Neural-on-Neural Approaches to Speaker Gender Protection.](http://arxiv.org/abs/2306.17700) | 本文超越了基于神经网络的方法，提出了一种超越性别保护的研究方法，并强调了测试基于语音特征的性别推测攻击的重要性，以及与人类执行的声音适应进行比较。 |
| [^11] | [A New Task and Dataset on Detecting Attacks on Human Rights Defenders.](http://arxiv.org/abs/2306.17695) | 本文提出了一个新的任务和数据集，用于检测对人权捍卫者的攻击。利用NLP来处理大量新闻文章，以检测和总结攻击的特征。通过提供具有精细信息的众包注释，展示了数据集的实用性。 |
| [^12] | [X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents.](http://arxiv.org/abs/2306.17674) | X-RiSAWOZ是一个高质量的多语言对话数据集，提供了 给构建完全功能代理人的端到端数据集。开发了一套工具来加快翻译后的新语言数据集的后期编辑，提高了机器翻译的性能。 |
| [^13] | [Biomedical Language Models are Robust to Sub-optimal Tokenization.](http://arxiv.org/abs/2306.17649) | 生物医学语言模型对生物医学术语的标记分割方式具有鲁棒性，这对于改进下游生物医学自然语言处理任务的性能非常重要。 |
| [^14] | [Feature Representation Learning for NL2SQL Generation Based on Coupling and Decoupling.](http://arxiv.org/abs/2306.17646) | 提出了一种基于耦合和解耦的NL2SQL生成任务的特征表示学习方法，通过显式和隐式相关特征表示的解耦和耦合，实现了更好的性能。 |
| [^15] | [ChatGPT for Robotics: Design Principles and Model Abilities.](http://arxiv.org/abs/2306.17582) | 本文介绍了使用ChatGPT进行机器人应用的实验研究，通过设计原则和函数库的结合，ChatGPT能够适应不同的机器人任务，并展示了在各种机器人任务中的有效性和多样性。 |
| [^16] | [Augmenting Holistic Review in University Admission using Natural Language Processing for Essays and Recommendation Letters.](http://arxiv.org/abs/2306.17575) | 这项研究通过机器学习模型的实证评估发现，在大学录取过程中排除受保护属性会导致预测表现下降，而通过使用文本信息可以部分恢复模型的性能。 |
| [^17] | [A Cost-aware Study of Depression Language on Social Media using Topic and Affect Contextualization.](http://arxiv.org/abs/2306.17564) | 本文提出了一种自动系统，通过结合多种文本表示方法和主题、情感信息的情景化模式检测社交媒体上的抑郁。通过评估实验发现，该方法在改善分类效果方面表现出色。 |
| [^18] | [Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting.](http://arxiv.org/abs/2306.17563) | 本论文提出了一种名为PRP的新技术，通过使用两两排名提示来显著减轻大型语言模型（LLM）的负担，并首次在标准基准测试中实现了最先进的排名性能。 |
| [^19] | [Towards the extraction of robust sign embeddings for low resource sign language recognition.](http://arxiv.org/abs/2306.17558) | 本研究的目标是实现对低资源手势语言识别的稳健手势嵌入提取。针对当前存在的问题，人体姿势估计器虽然是理想的选择，但由于域不匹配和手势语言中的挑战性姿势，其在手势语言数据上的稳健性有所欠缺。关键点基于的模型仍然优于图像基于的模型，但其训练方式限制了其在手势语言识别中的应用。 |
| [^20] | [GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models.](http://arxiv.org/abs/2306.17519) | 本论文介绍了使用大型语言模型和上下文学习框架进行金融关系提取的解决方案。通过两种检索策略，无需学习的密集检索器和基于学习的检索器，我们能够从训练数据中找到与给定测试示例相关的上下文学习示范。 |
| [^21] | [Preference Ranking Optimization for Human Alignment.](http://arxiv.org/abs/2306.17492) | 本文提出了Preference Ranking Optimization (PRO)方法，通过扩展布拉德利-特里比较，采用偏好排序的方式来直接对齐大型语言模型（LLMs），解决了强化学习从人类反馈中学习的复杂性、不稳定性和对超参数的敏感性的问题。 |
| [^22] | [Knowledge Base Completion for Long-Tail Entities.](http://arxiv.org/abs/2306.17472) | 本研究提出了一种用于长尾实体事实的基于语言模型的知识库完善方法，在F1得分上超过了所有的基准线，尤其在召回率上取得了重大的进展。 |
| [^23] | [Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring of Learning Objectives.](http://arxiv.org/abs/2306.17459) | 本论文评估了使用GPT-4在人工智能课程中自动生成高质量学习目标的能力，强调了学习目标的重要性和撰写高质量目标的挑战性。 |
| [^24] | [Progressive Multi-task Learning Framework for Chinese Text Error Correction.](http://arxiv.org/abs/2306.17447) | 我们提出了一种面向中文文本错误校正的渐进式多任务学习框架ProTEC，该框架通过引导模型从易到难地学习错误检测、错误类型识别和校正结果生成，以解决过纠正的问题。 |
| [^25] | [Provable Robust Watermarking for AI-Generated Text.](http://arxiv.org/abs/2306.17439) | GPTWatermark是一种针对性模型水印技术，通过固定分组设计和强大的可证明保证，提供了对AI生成文本的鲁棒性检测和安全性防御。实验证明了其在检测准确性和生成质量方面的优越性，推动了LLMs负责任使用的进步。 |
| [^26] | [LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection.](http://arxiv.org/abs/2306.17408) | LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。 |
| [^27] | [Japanese Lexical Complexity for Non-Native Readers: A New Dataset.](http://arxiv.org/abs/2306.17399) | 该论文构建了第一个日语词汇复杂性预测数据集，通过提供不同的复杂度评分满足了非母语读者的需要，并展示了基于BERT的系统在日语LCP中的有效性。 |
| [^28] | [SummQA at MEDIQA-Chat 2023:In-Context Learning with GPT-4 for Medical Summarization.](http://arxiv.org/abs/2306.17384) | SummQA在MEDIQA-Chat 2023上通过使用GPT-4进行上下文学习，针对医学摘要任务取得了显著效果，尤其是对于few-shot prompting的有效应用，虽然也发现了基于prompting方法的几个不足之处。 |
| [^29] | [Citations as Queries: Source Attribution Using Language Models as Rerankers.](http://arxiv.org/abs/2306.17322) | 本研究探索了一种新方法，通过微调语言模型以重新排序候选的来源，实现定位文本撰写的源。实验结果表明，半监督方法可以几乎与完全监督方法一样有效，同时避免了对目标和源文档进行昂贵的跨度级注释。 |
| [^30] | [Towards Open-Domain Topic Classification.](http://arxiv.org/abs/2306.17290) | 该论文介绍了一个开放领域的主题分类系统，该系统可以实时接受用户定义的分类法，并利用预训练语言模型的隐含知识进行零射击分类。实验证明该系统在开放领域场景中明显优于现有的零射击基线模型，与弱监督模型有竞争力。 |
| [^31] | [Prediction of COVID-19 Patients' Emergency Room Revisit using Multi-Source Transfer Learning.](http://arxiv.org/abs/2306.17257) | 本研究利用迁移学习和自然语言处理技术，预测COVID-19患者出院后在急诊室的再访情况，早期识别有助于医生专注于危及生命的病例。 |
| [^32] | [Towards Personalized Cold-Start Recommendation with Prompts.](http://arxiv.org/abs/2306.17256) | 本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。 |
| [^33] | [Learning Multilingual Expressive Speech Representation for Prosody Prediction without Parallel Data.](http://arxiv.org/abs/2306.17199) | 我们提出了一种在离散语音单元级别上进行语音情感保留翻译的方法，该方法使用多语言情感嵌入来预测目标语言中语音单元的音高和持续时间，并成功地以相同的情感内容重新合成源语音信号。 |
| [^34] | [On the Exploitability of Instruction Tuning.](http://arxiv.org/abs/2306.17194) | 该论文研究了如何利用指令调整技术来改变模型行为的问题，并提出了一种自动数据注入的方法AutoPoison。实验结果表明，通过少量的训练数据毒化，对手能够改变模型的行为。 |
| [^35] | [Why can neural language models solve next-word prediction? A mathematical perspective.](http://arxiv.org/abs/2306.17184) | 本文研究了神经语言模型在下一个词预测任务中的成功，在形式语言理论背景下，提出了一种为什么神经语言模型能够学习到组合规则的解释，并在一个现实世界的英语句子示例中提供了零错误的证明。 |
| [^36] | [Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis.](http://arxiv.org/abs/2306.17181) | 本论文提出了一种使用生成对抗网络（GAN）生成连续文本嵌入空间的方法（TESGAN），以解决传统GAN在自然语言生成中的限制。这种方法通过引入连续的文本嵌入空间取代离散的标记，使得生成器在通过反向传播更新梯度时更加有效。 |
| [^37] | [Replace and Report: NLP Assisted Radiology Report Generation.](http://arxiv.org/abs/2306.17180) | 本研究提出了一种模板化的方法，利用NLP技术辅助生成放射学报告。该方法通过使用图像分类器生成图像标签，然后通过基于变压器的模型生成病理描述，并使用BERT模型替换正常报告模板中的相应部分，最终生成完整的放射学报告。 |
| [^38] | [Leveraging ChatGPT As Text Annotation Tool For Sentiment Analysis.](http://arxiv.org/abs/2306.17177) | 本研究探索了使用ChatGPT作为情感分析任务的数据标注工具，克服了监督学习算法需要人工标注的限制和基于词典的算法无法捕捉全部情感范围的缺点。 |
| [^39] | [News Verifiers Showdown: A Comparative Performance Evaluation of ChatGPT 3.5, ChatGPT 4.0, Bing AI, and Bard in News Fact-Checking.](http://arxiv.org/abs/2306.17176) | 本研究通过对比实验评估了ChatGPT 3.5、ChatGPT 4.0、Bing AI和Bard在新闻事实检查中的表现，结果显示它们的熟练程度普遍居中，其中OpenAI的GPT-4.0在区分真相和欺骗方面具有一定优势。 |
| [^40] | [RECAP-KG: Mining Knowledge Graphs from Raw GP Notes for Remote COVID-19 Assessment in Primary Care.](http://arxiv.org/abs/2306.17175) | 本研究提出了一个从原始GP笔记中提取信息并构建知识图谱的框架，用于解决临床决策过程中现有技术无法处理的问题。 |
| [^41] | [Empowering NLG: Offline Reinforcement Learning for Informal Summarization in Online Domains.](http://arxiv.org/abs/2306.17174) | 该论文介绍了一种离线强化学习的自然语言生成方法，用于在在线领域生成非正式摘要，并通过該方法在用户体验和负载减轻方面取得了显著改进。 |
| [^42] | [Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors.](http://arxiv.org/abs/2306.17156) | 该论文系统评估了ChatGPT、GPT-4和人类导师在不同的编程教育场景中的表现，并发现GPT-4优于ChatGPT，接近于人类导师。 |
| [^43] | [Identity Construction in a Misogynist Incels Forum.](http://arxiv.org/abs/2306.15745) | 本研究使用定量文本和网络分析方法，研究了最大的黑洞incels论坛如何讨论身份群体。研究发现该社区产生了许多新的身份术语，存在物质主义的意识形态。对此我们讨论了对自动化 misogynist hate speech 检测研究的影响。 |
| [^44] | [Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering.](http://arxiv.org/abs/2306.00526) | 该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。 |
| [^45] | [Faithfulness Tests for Natural Language Explanations.](http://arxiv.org/abs/2305.18029) | 该论文研究了评估自然语言解释真实性的问题，并提出了两个测试方法：反事实输入编辑器和重建输入测试。这些测试对于评估新兴的NLE模型，对开发真实的NLEs具有重要意义。 |
| [^46] | [Eliciting the Translation Ability of Large Language Models via Multilingual Finetuning with Translation Instructions.](http://arxiv.org/abs/2305.15083) | 本文通过对多语言预训练语言模型进行微调，研究了它们如何通过翻译指令执行多语言翻译任务。研究发现多语言LLMs具有较强的翻译能力，这取决于语言与英语的相似性和预训练阶段使用的数据量。此外，执行翻译指令的能力依赖于对指令的理解和不同语言之间的对齐。 |
| [^47] | [UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers.](http://arxiv.org/abs/2301.13741) | UPop是一种通用的视觉语言Transformer压缩框架，采用统一和渐进式剪枝方法，可自动分配剪枝比率，实现更高的压缩比率。 |
| [^48] | [Conversational Question Answering on Heterogeneous Sources.](http://arxiv.org/abs/2204.11677) | 本文提出了CONVINSE，一个用于异构数据源上的ConvQA的端到端流水线，通过联合提取来自知识库、文本和表格的信息，提升了答案覆盖率和可信度。 |
| [^49] | [Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting.](http://arxiv.org/abs/2110.05367) | 该论文提出了一种新方法GEEP，用于提高预训练语言模型的性别公平性，同时没有灾难性遗忘问题。透过性别中性数据学习性别相关的提示，GEEP实现了SOTA表现并在GLUE性能上取得了显著提高。 |

# 详细

[^1]: SPAE: 基于语义金字塔自编码器的冻结LLM的多模态生成

    SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs. (arXiv:2306.17842v1 [cs.CV])

    [http://arxiv.org/abs/2306.17842](http://arxiv.org/abs/2306.17842)

    本研究引入了SPAE，使用语义金字塔自编码器实现了冻结LLM执行涉及非语言模态的理解和生成任务。通过将图像转化为LLM可理解的词汇标记，我们的方法成功地提升了冻结LLM在图像理解任务中的性能，超过了现有技术25%以上。

    

    本研究引入了Semantic Pyramid AutoEncoder (SPAE)，使冻结的LLM能够执行涉及非语言模态（如图像或视频）的理解和生成任务。SPAE在原始像素和从LLM词汇表中提取的可解释的词汇标记（或单词）之间进行转换。生成的标记捕捉了视觉重建所需的语义含义和细粒度细节，将视觉内容转化为LLM能理解的语言，并使其能够执行各种多模态任务。我们的方法通过在多样化的图像理解和生成任务上，与冻结的PaLM 2和GPT 3.5进行上下文学习实验证实。在相同的设置下，我们的方法是第一个成功使冻结LLM生成图像内容，并在图像理解任务中的性能超过现有技术25%以上的尝试。

    In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.
    
[^2]: Statler：用于具身推理的保持状态的语言模型

    Statler: State-Maintaining Language Models for Embodied Reasoning. (arXiv:2306.17840v1 [cs.RO])

    [http://arxiv.org/abs/2306.17840](http://arxiv.org/abs/2306.17840)

    Statler是一个为LLMs赋予了明确的、维持状态的语言模型，可以解决当代LLMs在长时间范围内推理的困难。

    

    大型语言模型（LLMs）为机器人执行复杂的机器人推理任务提供了一种有希望的工具。然而，当代LLMs的有限上下文窗口使得在长时间范围内进行推理变得困难。具身任务（例如我们期望一个家庭机器人执行的任务）通常需要规划者考虑很久之前获得的信息（例如，机器人在环境中遇到的许多对象的属性）。通过LLM的隐含内部表示来捕获世界状态的尝试会因为机器人操作历史中可用的与任务和环境相关的信息有限而变得复杂，而依赖通过提示向LLM传递信息的方法则受其有限的上下文窗口的限制。在本文中，我们提出了Statler，一个为LLMs赋予了明确的、作为“记忆”的世界状态表示的框架，这种记忆随时间保持。

    Large language models (LLMs) provide a promising tool that enable robots to perform complex robot reasoning tasks. However, the limited context window of contemporary LLMs makes reasoning over long time horizons difficult. Embodied tasks such as those that one might expect a household robot to perform typically require that the planner consider information acquired a long time ago (e.g., properties of the many objects that the robot previously encountered in the environment). Attempts to capture the world state using an LLM's implicit internal representation is complicated by the paucity of task- and environment-relevant information available in a robot's action history, while methods that rely on the ability to convey information via the prompt to the LLM are subject to its limited context window. In this paper, we propose Statler, a framework that endows LLMs with an explicit representation of the world state as a form of ``memory'' that is maintained over time. Integral to Statler i
    
[^3]: 元推理：用于大型语言模型的语义符号解构

    Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language Models. (arXiv:2306.17820v1 [cs.CL])

    [http://arxiv.org/abs/2306.17820](http://arxiv.org/abs/2306.17820)

    本论文提出了一种称为“元推理”的方法，它通过使用语义符号解构的方式，将不同推理问题转化为类似的自然语言表示，以提高大型语言模型的推理能力。

    

    大型语言模型中的符号化方法已经被证明可以有效提高语言模型的推理能力。然而，大多数这些方法依赖于将自然语言映射到更加语法完备且没有歧义的形式语言（例如Python、SQL）。虽然这些方法有效，但它们离开了自然语言本身，偏离了人类思维的习惯，而更多地迎合了计算机的执行思维方式。相反，我们希望从语言学中符号的概念出发来简化自然语言，使得语言模型可以学习不同自然语义中包含的推理问题的常见表达方式和通用解决方案。基于这种考虑，我们提出了“元推理”，它允许语言模型自动完成语义符号的解构，即语义解析，从而最大程度地将某些推理任务的不同问题减少到类似的自然语言表示，从而获得推理的能力。

    Symbolization methods in large language models (LLMs) have been shown effective to improve LLMs' reasoning ability. However, most of these approaches hinge on mapping natural languages to formal languages (e.g., Python, SQL) that are more syntactically complete and free of ambiguity. Although effective, they depart from the natural language itself and deviate from the habits of human thinking, and instead cater more to the execution mindset of computers. In contrast, we hope to simplify natural language by starting from the concept of symbols in linguistics itself, so that LLMs can learn the common formulation and general solution of reasoning problems wrapped in different natural semantics. From this consideration, we propose \textbf{Meta-Reasoning}, which allows LLMs to automatically accomplish semantic-symbol deconstruction, i.e., semantic resolution, to maximally reduce different questions of certain reasoning tasks to similar natural language representation, thus gaining the abili
    
[^4]: 一个历史英语的大规模语义相似性数据集

    A Massive Scale Semantic Similarity Dataset of Historical English. (arXiv:2306.17810v1 [cs.CL])

    [http://arxiv.org/abs/2306.17810](http://arxiv.org/abs/2306.17810)

    本研究利用重新数字化的无版权美国本地报纸文章，构建了一个大规模的跨越了70年的语义相似性数据集，并包含近4亿个正向语义相似性对。

    

    各种任务使用在语义相似性数据上训练的语言模型。虽然有多种数据集可捕捉语义相似性，但它们要么是从现代网络数据构建的，要么是由人工标注员在过去十年中创建的相对较小的数据集。本研究利用一种新颖的来源，即重新数字化的无版权美国本地报纸文章，构建了一个大规模的语义相似性数据集，跨越了1920年到1989年的70年，并包含近4亿个正向语义相似性对。在美国本地报纸中，大约一半的文章来自新闻机构的新闻稿，而本地报纸复制了新闻稿的文章，并撰写了自己的标题，这些标题形成了与文章相关的提取性摘要。我们通过利用文档布局和语言理解将文章和标题关联起来。然后，我们使用深度神经方法来检测哪些文章来自相同的基础来源。

    A diversity of tasks use language models trained on semantic similarity data. While there are a variety of datasets that capture semantic similarity, they are either constructed from modern web data or are relatively small datasets created in the past decade by human annotators. This study utilizes a novel source, newly digitized articles from off-copyright, local U.S. newspapers, to assemble a massive-scale semantic similarity dataset spanning 70 years from 1920 to 1989 and containing nearly 400M positive semantic similarity pairs. Historically, around half of articles in U.S. local newspapers came from newswires like the Associated Press. While local papers reproduced articles from the newswire, they wrote their own headlines, which form abstractive summaries of the associated articles. We associate articles and their headlines by exploiting document layouts and language understanding. We then use deep neural methods to detect which articles are from the same underlying source, in th
    
[^5]: 不使用分类器的指导下保持话题的一致性

    Stay on topic with Classifier-Free Guidance. (arXiv:2306.17806v1 [cs.CL])

    [http://arxiv.org/abs/2306.17806](http://arxiv.org/abs/2306.17806)

    本论文展示了分类器无关的指导（CFG）可以作为一种推断时间技术，显著提高了纯语言建模中各种任务的性能，并能够增强助手在具有挑战性的提示中的准确性和一致性。

    

    分类器无关的指导（CFG）最近在文本到图像生成中出现，作为一种轻量级技术促进生成的立即遵循。在这项工作中，我们证明CFG可以广泛用作纯语言建模的推断时间技术。我们展示了CFG在一系列任务上提高了Pythia、GPT-2和LLaMA-family模型的性能：问答，推理，代码生成和机器翻译，在LAMBADA上使用LLaMA-7B超过PaLM-540B的SOTA；（2）带来了相当于双倍参数数的模型的改进；（3）可以与其他推断时间方法如Chain-of-Thought和Self-Consistency一起使用，在困难任务中取得进一步改进；（4）可以用于增加助手在具有挑战性的形式驱动和内容驱动提示中的忠实度和连贯性：在人类评估中，我们展示了75％的用户更喜欢使用CFG的GPT4All而不是基准方法。

    Classifier-Free Guidance (CFG) has recently emerged in text-to-image generation as a lightweight technique to encourage prompt-adherence in generations. In this work, we demonstrate that CFG can be used broadly as an inference-time technique in pure language modeling. We show that CFG (1) improves the performance of Pythia, GPT-2 and LLaMA-family models across an array of tasks: Q\&A, reasoning, code generation, and machine translation, achieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements equivalent to a model with twice the parameter-count; (3) can stack alongside other inference-time methods like Chain-of-Thought and Self-Consistency, yielding further improvements in difficult tasks; (4) can be used to increase the faithfulness and coherence of assistants in challenging form-driven and content-driven prompts: in a human evaluation we show a 75\% preference for GPT4All using CFG over baseline.
    
[^6]: 通过侧抑制方法提高低资源语言的预训练语音模型性能

    Towards Improving the Performance of Pre-Trained Speech Models for Low-Resource Languages Through Lateral Inhibition. (arXiv:2306.17792v1 [cs.CL])

    [http://arxiv.org/abs/2306.17792](http://arxiv.org/abs/2306.17792)

    本研究通过将微调密集层替换为侧抑制层，提高了低资源语言的预训练语音模型性能，并在罗马尼亚语语料库和Robin技术采集语料库上实现了最先进的结果。

    

    随着双向编码器Transformer模型在自然语言处理领域的兴起，语音领域采用了其中一些开发方法。因此，Wav2Vec模型被引入以减少获取最先进结果所需的数据量。本研究利用这些知识，通过将微调密集层替换为受生物过程启发的侧抑制层来提高预训练语音模型的性能。我们在罗马尼亚语这种低资源语言上的实验表明，使用侧抑制层的平均字错误率（WER）提高了12.5%。此外，我们在罗马尼亚语语音语料库和Robin技术采集语料库上获得了最先进的结果，分别为1.78% WER和29.64% WER。

    With the rise of bidirectional encoder representations from Transformer models in natural language processing, the speech community has adopted some of their development methodologies. Therefore, the Wav2Vec models were introduced to reduce the data required to obtain state-of-the-art results. This work leverages this knowledge and improves the performance of the pre-trained speech models by simply replacing the fine-tuning dense layer with a lateral inhibition layer inspired by the biological process. Our experiments on Romanian, a low-resource language, show an average improvement of 12.5% word error rate (WER) using the lateral inhibition layer. In addition, we obtain state-of-the-art results on both the Romanian Speech Corpus and the Robin Technical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.
    
[^7]: 是否应该对可能的标记化进行边缘化计算？

    Should you marginalize over possible tokenizations?. (arXiv:2306.17757v1 [cs.CL])

    [http://arxiv.org/abs/2306.17757](http://arxiv.org/abs/2306.17757)

    该论文分析了语言模型计算字符串概率时是否应该边缘化所有可能的标记化。研究结果表明，在大多数情况下，忽略边缘化计算的差距不超过0.5%，但对于含有长复杂单词的数据来说，这种差距更加明显。

    

    自回归语言模型(LMs)将令牌序列映射到概率。计算任何字符串(例如英文句子)的概率的常见做法是先将其转换为由模型评分的令牌序列。然而，有指数级的令牌序列可以表示任何给定的字符串。为了真正计算字符串的概率，应该对所有标记化进行边缘化计算，但这通常是难以处理的。在这里，我们分析忽略边缘化计算的做法是否合理。为此，我们设计了一种基于重要性采样的算法，使我们能够计算边缘概率的估计，并将其与一系列最先进的模型和数据集中的默认过程进行比较。我们的结果表明，在大多数情况下，对数似然差距不超过0.5％，但对于包含长复杂单词的数据，这种差距变得更加明显。

    Autoregressive language models (LMs) map token sequences to probabilities. The usual practice for computing the probability of any character string (e.g. English sentences) is to first transform it into a sequence of tokens that is scored by the model. However, there are exponentially many token sequences that represent any given string. To truly compute the probability of a string one should marginalize over all tokenizations, which is typically intractable. Here, we analyze whether the practice of ignoring the marginalization is justified. To this end, we devise an importance-sampling-based algorithm that allows us to compute estimates of the marginal probabilities and compare them to the default procedure in a range of state-of-the-art models and datasets. Our results show that the gap in log-likelihood is no larger than 0.5% in most cases, but that it becomes more pronounced for data with long complex words.
    
[^8]: 基于Token-Event-Role结构的多通道文档级事件抽取

    Token-Event-Role Structure-based Multi-Channel Document-Level Event Extraction. (arXiv:2306.17733v1 [cs.CL])

    [http://arxiv.org/abs/2306.17733](http://arxiv.org/abs/2306.17733)

    本文提出了一种基于Token-Event-Role结构的多通道文档级事件抽取框架，通过引入新的数据结构和预测模块，能够更全面地理解事件之间的关系，并通过预测token-event对的方式，实现了实体和多事件抽取的集成，减少了模型复杂性。

    

    文档级事件抽取是一个历史悠久且具有挑战性的信息检索问题，涉及一系列子任务：实体抽取、事件类型判断和特定事件类型的多事件抽取。然而，将问题视为多个学习任务会增加模型复杂性。此外，现有方法未充分利用跨越不同事件的实体的相关性，导致事件抽取性能有限。本文引入了一种新的文档级事件抽取框架，其中包括一个称为token-event-role的新数据结构和一个多通道参数角色预测模块。所提出的数据结构使得我们的模型能够揭示多个事件中token的主要作用，从而更全面地理解事件之间的关系。通过利用多通道预测模块，我们将实体和多事件抽取转化为预测token-event对的单一任务，从而减少了模型复杂性。

    Document-level event extraction is a long-standing challenging information retrieval problem involving a sequence of sub-tasks: entity extraction, event type judgment, and event type-specific multi-event extraction. However, addressing the problem as multiple learning tasks leads to increased model complexity. Also, existing methods insufficiently utilize the correlation of entities crossing different events, resulting in limited event extraction performance. This paper introduces a novel framework for document-level event extraction, incorporating a new data structure called token-event-role and a multi-channel argument role prediction module. The proposed data structure enables our model to uncover the primary role of tokens in multiple events, facilitating a more comprehensive understanding of event relationships. By leveraging the multi-channel prediction module, we transform entity and multi-event extraction into a single task of predicting token-event pairs, thereby reducing the 
    
[^9]: 基于多层专家网络的改进NL2SQL技术

    Improved NL2SQL based on Multi-layer Expert Network. (arXiv:2306.17727v1 [cs.CL])

    [http://arxiv.org/abs/2306.17727](http://arxiv.org/abs/2306.17727)

    本研究提出了一种名为多层专家生成SQL的新方法，通过利用专用的多任务分层网络，该方法解决了由于不同分类任务的负迁移问题导致生成不准确SQL语句的限制。该方法在WiKSQL数据集上取得了良好的效果。

    

    自然语言到SQL（NL2SQL）技术用于将自然语言查询转换为可执行的SQL语句。通常，通过插槽填充作为多任务分类方法来实现此目标。然而，由于不同分类任务的负迁移问题，插槽填充可能导致生成不准确的SQL语句。为了克服这个限制，本研究引入了一种名为多层专家生成SQL（MLEG-SQL）的新方法，该方法利用专用的多任务分层网络。网络的下层提取自然语言语句的语义特征，而上层构建一个专门的专家系统来处理特定的分类任务。这种分层方法减轻了不同任务冲突带来的性能下降。该方法在WiKSQL数据集上进行了评估，并证明在生成准确的SQL语句方面是有效的。

    The Natural Language to SQL (NL2SQL) technique is used to convert natural language queries into executable SQL statements. Typically, slot-filling is employed as a classification method for multi-task cases to achieve this goal. However, slot-filling can result in inaccurate SQL statement generation due to negative migration issues arising from different classification tasks. To overcome this limitation, this study introduces a new approach called Multi-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated multi-task hierarchical network. The lower layer of the network extracts semantic features of natural language statements, while the upper layer builds a specialized expert system for handling specific classification tasks. This hierarchical approach mitigates performance degradation resulting from different task conflicts. The proposed method was evaluated on the WiKSQL dataset and was found to be effective in generating accurate SQL statements.
    
[^10]: 超越基于神经网络的方法保护演讲者性别的研究

    Beyond Neural-on-Neural Approaches to Speaker Gender Protection. (arXiv:2306.17700v1 [eess.AS])

    [http://arxiv.org/abs/2306.17700](http://arxiv.org/abs/2306.17700)

    本文超越了基于神经网络的方法，提出了一种超越性别保护的研究方法，并强调了测试基于语音特征的性别推测攻击的重要性，以及与人类执行的声音适应进行比较。

    

    最近的研究提出了一些修改语音以防止性别推测攻击的方法。这些保护算法的目标是控制关于演讲者性别这个隐私敏感属性的信息的可用性。目前，开发和测试性别保护算法的常见做法是 "神经网络之间的"，即通过神经网络生成和测试扰动。在本文中，我们提出超越这种做法以加强对性别保护的研究。首先，我们证明了测试基于语音科学家历史上开发的语音特征的性别推测攻击的重要性，同时还与传统的神经分类器进行比较。接下来，我们认为研究人员应该使用语音特征来洞察保护性修改如何改变语音信号。最后，我们指出性别保护算法应该与新型的 "语音对手"，即人类执行的声音适应进行比较。

    Recent research has proposed approaches that modify speech to defend against gender inference attacks. The goal of these protection algorithms is to control the availability of information about a speaker's gender, a privacy-sensitive attribute. Currently, the common practice for developing and testing gender protection algorithms is "neural-on-neural", i.e., perturbations are generated and tested with a neural network. In this paper, we propose to go beyond this practice to strengthen the study of gender protection. First, we demonstrate the importance of testing gender inference attacks that are based on speech features historically developed by speech scientists, alongside the conventionally used neural classifiers. Next, we argue that researchers should use speech features to gain insight into how protective modifications change the speech signal. Finally, we point out that gender-protection algorithms should be compared with novel "vocal adversaries", human-executed voice adaptati
    
[^11]: 在检测对人权捍卫者的攻击方面的新任务和数据集

    A New Task and Dataset on Detecting Attacks on Human Rights Defenders. (arXiv:2306.17695v1 [cs.CL])

    [http://arxiv.org/abs/2306.17695](http://arxiv.org/abs/2306.17695)

    本文提出了一个新的任务和数据集，用于检测对人权捍卫者的攻击。利用NLP来处理大量新闻文章，以检测和总结攻击的特征。通过提供具有精细信息的众包注释，展示了数据集的实用性。

    

    能够对人权捍卫者的攻击进行历史性和地域性的回顾性分析对于人道主义组织更好地了解历史或正在进行的人权侵犯，并因此更好地管理此类事件的全球影响至关重要。我们假设自然语言处理可以通过快速处理大量新闻文章来检测和总结对人权捍卫者的攻击的特征，从而支持这些努力。为此，我们提出了一个新的用于检测对人权捍卫者的攻击的数据集（HRDsAttack），包括对500篇在线新闻文章的众包注释。这些注释包括对攻击类型和地点以及受害者信息的细粒度信息。我们通过使用该数据集训练和评估基准模型在几个子任务上预测注释特征的方法来展示数据集的实用性。

    The ability to conduct retrospective analyses of attacks on human rights defenders over time and by location is important for humanitarian organizations to better understand historical or ongoing human rights violations and thus better manage the global impact of such events. We hypothesize that NLP can support such efforts by quickly processing large collections of news articles to detect and summarize the characteristics of attacks on human rights defenders. To that end, we propose a new dataset for detecting Attacks on Human Rights Defenders (HRDsAttack) consisting of crowdsourced annotations on 500 online news articles. The annotations include fine-grained information about the type and location of the attacks, as well as information about the victim(s). We demonstrate the usefulness of the dataset by using it to train and evaluate baseline models on several sub-tasks to predict the annotated characteristics.
    
[^12]: X-RiSAWOZ: 高质量的多语言对话数据集和少样本代理人

    X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents. (arXiv:2306.17674v1 [cs.CL])

    [http://arxiv.org/abs/2306.17674](http://arxiv.org/abs/2306.17674)

    X-RiSAWOZ是一个高质量的多语言对话数据集，提供了 给构建完全功能代理人的端到端数据集。开发了一套工具来加快翻译后的新语言数据集的后期编辑，提高了机器翻译的性能。

    

    任务导向的对话研究主要集中在英语和中文等几种流行语言上，这是因为为新语言创建数据集的成本较高。为了降低成本，我们对自动翻译的数据进行手动编辑。我们通过将中文RiSAWOZ翻译为英语、法语、印地语、韩语以及混合英印地语的语言，创建了一个新的多语言基准数据集X-RiSAWOZ。X-RiSAWOZ每种语言都有超过18,000个经人工验证的对话语句，并且与大多数多语言之前的工作不同，它是一个用于构建完全功能代理人的端到端数据集。在创建X-RiSAWOZ时，我们遇到了许多困难，因此开发了一套工具来加快翻译后的新语言数据集的后期编辑。这套工具使用混合实体对齐技术，结合了神经网络和基于字典的方法，以及许多自动化和半自动化的验证检查，从而改进了机器翻译的性能。

    Task-oriented dialogue research has mainly focused on a few popular languages like English and Chinese, due to the high dataset creation cost for a new language. To reduce the cost, we apply manual editing to automatically translated data. We create a new multilingual benchmark, X-RiSAWOZ, by translating the Chinese RiSAWOZ to 4 languages: English, French, Hindi, Korean; and a code-mixed English-Hindi language. X-RiSAWOZ has more than 18,000 human-verified dialogue utterances for each language, and unlike most multilingual prior work, is an end-to-end dataset for building fully-functioning agents.  The many difficulties we encountered in creating X-RiSAWOZ led us to develop a toolset to accelerate the post-editing of a new language dataset after translation. This toolset improves machine translation with a hybrid entity alignment technique that combines neural with dictionary-based methods, along with many automated and semi-automated validation checks.  We establish strong baselines f
    
[^13]: 生物医学语言模型对不理想的标记分割方式具有鲁棒性

    Biomedical Language Models are Robust to Sub-optimal Tokenization. (arXiv:2306.17649v1 [cs.CL])

    [http://arxiv.org/abs/2306.17649](http://arxiv.org/abs/2306.17649)

    生物医学语言模型对生物医学术语的标记分割方式具有鲁棒性，这对于改进下游生物医学自然语言处理任务的性能非常重要。

    

    与一般的英语相反，生物医学术语中的许多概念是由生物医学专业人员设计的，目的是要精确且简明。通常通过将有意义的生物医学词素连接起来创建新的语义单位来实现这一目标。然而，大多数现代生物医学语言模型 (LMs) 是使用从大规模生物医学语料库统计中导出的标准领域特定标记器进行预训练的，而没有明确利用生物医学语言的粘附性特点。在这项工作中，我们首先发现标准通用领域和生物医学标记器在将生物医学术语分割成有意义的组成部分方面能力有限。因此，我们假设使用一种更准确分割生物医学术语的标记器将使生物医学语言模型在下游生物医学自然语言处理任务中提高性能，特别是涉及生物医学术语的任务，如命名实体识别 (NER) 和实体链接。

    As opposed to general English, many concepts in biomedical terminology have been designed in recent history by biomedical professionals with the goal of being precise and concise. This is often achieved by concatenating meaningful biomedical morphemes to create new semantic units. Nevertheless, most modern biomedical language models (LMs) are pre-trained using standard domain-specific tokenizers derived from large scale biomedical corpus statistics without explicitly leveraging the agglutinating nature of biomedical language. In this work, we first find that standard open-domain and biomedical tokenizers are largely unable to segment biomedical terms into meaningful components. Therefore, we hypothesize that using a tokenizer which segments biomedical terminology more accurately would enable biomedical LMs to improve their performance on downstream biomedical NLP tasks, especially ones which involve biomedical terms directly such as named entity recognition (NER) and entity linking. Su
    
[^14]: 基于耦合和解耦的NL2SQL生成的特征表示学习方法

    Feature Representation Learning for NL2SQL Generation Based on Coupling and Decoupling. (arXiv:2306.17646v1 [cs.CL])

    [http://arxiv.org/abs/2306.17646](http://arxiv.org/abs/2306.17646)

    提出了一种基于耦合和解耦的NL2SQL生成任务的特征表示学习方法，通过显式和隐式相关特征表示的解耦和耦合，实现了更好的性能。

    

    NL2SQL任务涉及将自然语言语句解析为SQL查询。目前大多数先进的方法将NL2SQL视为填槽任务，并使用特征表示学习技术，但忽视了SELECT和WHERE子句之间的显式相关特征以及单个子句内部的隐式相关特征。为了解决这个问题，我们提出了一种称为Clause Feature Correlation Decoupling and Coupling (CFCDC)模型的方法，该模型使用特征表示解耦方法在参数级别上将SELECT和WHERE子句分离开。接下来，我们引入了一种多任务学习架构，以解耦特定子句中不同SQL任务之间的隐式相关特征表示。此外，我们提出了一种改进的特征表示耦合模块，将解耦的任务集成到SELECT和WHERE子句中，并预测最终的SQL查询。我们提出的CFCDC模型在WikiSQL数据集上展现出优秀的性能。

    The NL2SQL task involves parsing natural language statements into SQL queries. While most state-of-the-art methods treat NL2SQL as a slot-filling task and use feature representation learning techniques, they overlook explicit correlation features between the SELECT and WHERE clauses and implicit correlation features between sub-tasks within a single clause. To address this issue, we propose the Clause Feature Correlation Decoupling and Coupling (CFCDC) model, which uses a feature representation decoupling method to separate the SELECT and WHERE clauses at the parameter level. Next, we introduce a multi-task learning architecture to decouple implicit correlation feature representation between different SQL tasks in a specific clause. Moreover, we present an improved feature representation coupling module to integrate the decoupled tasks in the SELECT and WHERE clauses and predict the final SQL query. Our proposed CFCDC model demonstrates excellent performance on the WikiSQL dataset, wit
    
[^15]: ChatGPT用于机器人技术：设计原则和模型能力

    ChatGPT for Robotics: Design Principles and Model Abilities. (arXiv:2306.17582v1 [cs.AI])

    [http://arxiv.org/abs/2306.17582](http://arxiv.org/abs/2306.17582)

    本文介绍了使用ChatGPT进行机器人应用的实验研究，通过设计原则和函数库的结合，ChatGPT能够适应不同的机器人任务，并展示了在各种机器人任务中的有效性和多样性。

    

    本文介绍了使用OpenAI的ChatGPT进行机器人应用的实验研究。我们概述了一种策略，将提示工程的设计原则与高级函数库的创建相结合，使ChatGPT能够适应不同的机器人任务、模拟器和形态。我们重点评估了不同的提示工程技术和对话策略对执行各种类型机器人任务的效果。我们探讨了ChatGPT使用自由形式对话、解析XML标记和合成代码的能力，以及使用任务特定提示函数和通过对话进行闭环推理的能力。我们的研究涵盖了机器人领域的一系列任务，从基本的逻辑、几何和数学推理到复杂的领域，如空中导航、操纵和具身代理。我们证明了ChatGPT在解决这些任务方面可以取得有效结果，同时使我们能够进行探索。

    This paper presents an experimental study regarding the use of OpenAI's ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT's ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing us
    
[^16]: 使用自然语言处理增强大学录取中的整体评估，以分析论文和推荐信

    Augmenting Holistic Review in University Admission using Natural Language Processing for Essays and Recommendation Letters. (arXiv:2306.17575v1 [cs.CL])

    [http://arxiv.org/abs/2306.17575](http://arxiv.org/abs/2306.17575)

    这项研究通过机器学习模型的实证评估发现，在大学录取过程中排除受保护属性会导致预测表现下降，而通过使用文本信息可以部分恢复模型的性能。

    

    在许多高度选择性的机构中，大学录取采用全面评估过程，考虑申请的所有方面，包括隐私属性（如种族、性别）、成绩、论文和推荐信，以组成一支优秀和多样化的班级。在本研究中，我们使用机器学习（ML）模型实证评估受保护属性对预测录取决策的影响，并探讨文本信息（如个人论文、教师推荐信）在模型中代替受保护属性的程度。通过使用2022-2023学年在一所具有选择性的美国本科入学办公室的14,915名申请人的数据，我们发现从ML模型中排除受保护属性会显著降低预测录取表现。通过TF-IDF表示和隐狄利克雷分配（LDA）模型，文本信息的包含部分恢复了模型的性能。

    University admission at many highly selective institutions uses a holistic review process, where all aspects of the application, including protected attributes (e.g., race, gender), grades, essays, and recommendation letters are considered, to compose an excellent and diverse class. In this study, we empirically evaluate how influential protected attributes are for predicting admission decisions using a machine learning (ML) model, and in how far textual information (e.g., personal essay, teacher recommendation) may substitute for the loss of protected attributes in the model. Using data from 14,915 applicants to an undergraduate admission office at a selective U.S. institution in the 2022-2023 cycle, we find that the exclusion of protected attributes from the ML model leads to substantially reduced admission-prediction performance. The inclusion of textual information via both a TF-IDF representation and a Latent Dirichlet allocation (LDA) model partially restores model performance, b
    
[^17]: 使用主题和情感上下文化对社交媒体上的抑郁语言进行成本感知研究

    A Cost-aware Study of Depression Language on Social Media using Topic and Affect Contextualization. (arXiv:2306.17564v1 [cs.CL])

    [http://arxiv.org/abs/2306.17564](http://arxiv.org/abs/2306.17564)

    本文提出了一种自动系统，通过结合多种文本表示方法和主题、情感信息的情景化模式检测社交媒体上的抑郁。通过评估实验发现，该方法在改善分类效果方面表现出色。

    

    抑郁是社会心理健康中日益严重的问题，影响生活的各个方面，甚至可能导致自杀。幸运的是，预防计划可以在抑郁的治疗中起到作用。在这个背景下，本文提出了一种基于机器学习和自然语言处理方法的社交媒体抑郁检测自动系统。本文提出了以下贡献：（i）一个将多种文本表示方式结合起来进行抑郁检测的集成学习系统，包括该领域的最新进展；（ii）通过主题和情感信息的情景化模式；（iii）分析模型的能耗，建立分类性能和总体计算成本之间的权衡。为了评估所提出模型的有效性，对两个模拟抑郁文本的数据集进行了全面评估。实验证明，所提出的情景化策略可以改善分类效果，并且应用于自己构建的数据集表明，该方法在检测抑郁风险方面优于目前的方法。

    Depression is a growing issue in society's mental health that affects all areas of life and can even lead to suicide. Fortunately, prevention programs can be effective in its treatment. In this context, this work proposes an automatic system for detecting depression on social media based on machine learning and natural language processing methods. This paper presents the following contributions: (i) an ensemble learning system that combines several types of text representations for depression detection, including recent advances in the field; (ii) a contextualization schema through topic and affective information; (iii) an analysis of models' energy consumption, establishing a trade-off between classification performance and overall computational costs. To assess the proposed models' effectiveness, a thorough evaluation is performed in two datasets that model depressive text. Experiments indicate that the proposed contextualization strategies can improve the classification and that app
    
[^18]: 大型语言模型是有效的文本排序器，具有两两排名提示

    Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting. (arXiv:2306.17563v1 [cs.IR])

    [http://arxiv.org/abs/2306.17563](http://arxiv.org/abs/2306.17563)

    本论文提出了一种名为PRP的新技术，通过使用两两排名提示来显著减轻大型语言模型（LLM）的负担，并首次在标准基准测试中实现了最先进的排名性能。

    

    使用大型语言模型（LLM）通过直接将查询和候选文档输入提示进行文档排序是一个有趣且实用的问题。然而，迄今为止取得了有限的成功，研究人员发现很难在基准数据集上超越精调基准排序器。我们分析了现有方法使用的点对点和列表排序提示，并认为现成的LLM没有完全理解这些排序公式，可能是由于LLM的训练方式的特性。在本文中，我们提出了一种名为两两排名提示（PRP）的新技术，大大减轻了LLM的负担。我们的结果是文献中首次使用中等规模的开源LLM在标准基准测试中实现了最先进的排名性能。在TREC-DL2020上，基于20B参数的Flan-UL2模型的PRP超过了文献中基于商业黑盒GPT-4的最佳方法。

    Ranking documents using Large Language Models (LLMs) by directly feeding the query and candidate documents into the prompt is an interesting and practical problem. However, there has been limited success so far, as researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets. We analyze pointwise and listwise ranking prompts used by existing methods and argue that off-the-shelf LLMs do not fully understand these ranking formulations, possibly due to the nature of how LLMs are trained. In this paper, we propose to significantly reduce the burden on LLMs by using a new technique called Pairwise Ranking Prompting (PRP). Our results are the first in the literature to achieve state-of-the-art ranking performance on standard benchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on the Flan-UL2 model with 20B parameters outperforms the previous best approach in the literature, which is based on the blackbox commercial GPT-4 that ha
    
[^19]: 实现对低资源手势语言识别的稳健手势嵌入提取

    Towards the extraction of robust sign embeddings for low resource sign language recognition. (arXiv:2306.17558v1 [cs.CV])

    [http://arxiv.org/abs/2306.17558](http://arxiv.org/abs/2306.17558)

    本研究的目标是实现对低资源手势语言识别的稳健手势嵌入提取。针对当前存在的问题，人体姿势估计器虽然是理想的选择，但由于域不匹配和手势语言中的挑战性姿势，其在手势语言数据上的稳健性有所欠缺。关键点基于的模型仍然优于图像基于的模型，但其训练方式限制了其在手势语言识别中的应用。

    

    孤立的手势语言识别通常应用于包含由一组有限手势执行者缓慢而清晰执行的相对大规模数据集。然而，在现实世界的场景中，我们面临着具有挑战性的视觉条件、共同发音的手势、小数据集以及对独立演讲者模型的需求。为了解决这个困难的问题，我们需要一个稳健的特征提取器来处理手势语言视频。人体姿势估计器可以被认为是理想的候选者。然而，由于其训练集与手势语言中具有挑战性的姿势之间存在领域不匹配，它们在手势语言数据和基于图像的模型上仍然缺乏稳健性，关键点基于的模型通常仍然优于基于图像的模型。此外，虽然与基于图像的模型进行迁移学习的常见实践可以获得更高的准确性，但关键点基于的模型通常在每个手势语言识别数据集上都是从头开始训练的。这些因素限制了它们在手势语言识别中的实用性。

    Isolated Sign Language Recognition (SLR) has mostly been applied on relatively large datasets containing signs executed slowly and clearly by a limited group of signers. In real-world scenarios, however, we are met with challenging visual conditions, coarticulated signing, small datasets, and the need for signer independent models. To tackle this difficult problem, we require a robust feature extractor to process the sign language videos. One could expect human pose estimators to be ideal candidates. However, due to a domain mismatch with their training sets and challenging poses in sign language, they lack robustness on sign language data and image based models often still outperform keypoint based models. Furthermore, whereas the common practice of transfer learning with image based models yields even higher accuracy, keypoint based models are typically trained from scratch on every SLR dataset. These factors limit their usefulness for SLR. From the existing literature, it is also no
    
[^20]: GPT-FinRE: 使用大型语言模型进行金融关系提取的上下文学习

    GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models. (arXiv:2306.17519v1 [cs.CL])

    [http://arxiv.org/abs/2306.17519](http://arxiv.org/abs/2306.17519)

    本论文介绍了使用大型语言模型和上下文学习框架进行金融关系提取的解决方案。通过两种检索策略，无需学习的密集检索器和基于学习的检索器，我们能够从训练数据中找到与给定测试示例相关的上下文学习示范。

    

    关系提取（RE）是自然语言处理（NLP）中的一个关键任务，旨在识别和分类文本中提及的实体之间的关系。在金融领域，关系提取在从财经文件（如新闻文章、盈利报告和公司申报）中提取有价值信息方面起着至关重要的作用。本文描述了我们在一个名为REFinD的数据集上进行关系提取的解决方案。该数据集是作为SIGIR 2023举办的第四届从非结构化数据中发现知识的研讨会的共享任务的一部分发布的。我们在本文中采用了OpenAI模型，并应用了上下文学习（ICL）框架。我们利用两种检索策略从训练数据中找出与给定测试示例相关的前K个上下文学习示范/示例。第一个检索机制是无需学习的密集检索器，而另一个系统是基于学习的检索器。

    Relation extraction (RE) is a crucial task in natural language processing (NLP) that aims to identify and classify relationships between entities mentioned in text. In the financial domain, relation extraction plays a vital role in extracting valuable information from financial documents, such as news articles, earnings reports, and company filings. This paper describes our solution to relation extraction on one such dataset REFinD. The dataset was released along with shared task as a part of the Fourth Workshop on Knowledge Discovery from Unstructured Data in Financial Services, co-located with SIGIR 2023. In this paper, we employed OpenAI models under the framework of in-context learning (ICL). We utilized two retrieval strategies to find top K relevant in-context learning demonstrations / examples from training data for a given test example. The first retrieval mechanism, we employed, is a learning-free dense retriever and the other system is a learning-based retriever. We were able
    
[^21]: 人类对齐的偏好排序优化

    Preference Ranking Optimization for Human Alignment. (arXiv:2306.17492v1 [cs.CL])

    [http://arxiv.org/abs/2306.17492](http://arxiv.org/abs/2306.17492)

    本文提出了Preference Ranking Optimization (PRO)方法，通过扩展布拉德利-特里比较，采用偏好排序的方式来直接对齐大型语言模型（LLMs），解决了强化学习从人类反馈中学习的复杂性、不稳定性和对超参数的敏感性的问题。

    

    大型语言模型（LLMs）经常包含误导性内容，强调了将其与人类价值观对齐以确保安全的AI系统的必要性。采用从人类反馈中学习强化学习（RLHF）来实现这种对齐，通过将基于布拉德利-特里配对比较的奖励模型与Proximal Policy Optimization（PPO）等RL算法结合起来来优化LLM的响应。然而，RLHF表现出复杂性、不稳定性和对超参数的敏感性。在本文中，我们提出了Preference Ranking Optimization（PRO）作为PPO的另一种直接将LLM与布拉德利-特里比较对齐的方法。PRO将配对的布拉德利-特里比较扩展到适应任意长度的偏好排序。通过反复对比生成响应的可能性，PRO指导LLM优先考虑最佳响应，并逐渐对剩余的响应进行排序。通过这种方式，PRO将人类对齐有效地转化为概率对齐。

    Large language models (LLMs) often contain misleading content, emphasizing the need to align them with human values to ensure secur AI systems. Reinforcement learning from human feedback (RLHF) has been employed to achieve this alignment by combining a reward model, typically based on Bradley-Terry paired comparison, with an RL algorithm such as Proximal Policy Optimization (PPO) to optimize LLM responses. However, RLHF exhibits complexity, instability, and sensitivity to hyperparameters. In this paper, we propose Preference Ranking Optimization (PRO) as an alternative to PPO for directly aligning LLMs with the Bradley-Terry comparison. PRO extends the pairwise Bradley-Terry comparison to accommodate preference rankings of any length. By iteratively contrasting the likelihood of generating responses, PRO instructs the LLM to prioritize the best response while progressively ranking the remaining responses. In this manner, PRO effectively transforms human alignment into aligning the prob
    
[^22]: 面向长尾实体的知识库完善

    Knowledge Base Completion for Long-Tail Entities. (arXiv:2306.17472v1 [cs.CL])

    [http://arxiv.org/abs/2306.17472](http://arxiv.org/abs/2306.17472)

    本研究提出了一种用于长尾实体事实的基于语言模型的知识库完善方法，在F1得分上超过了所有的基准线，尤其在召回率上取得了重大的进展。

    

    尽管知识库（KB）如Wikidata具有令人印象深刻的规模，但仍存在重大空缺。语言模型（LM）被提出作为填补这些空缺的来源。然而，以往的研究主要关注具有丰富LM覆盖的突出实体，忽视了关键的长尾实体案例。本文提出了一种针对长尾实体事实的基于LM的KB完善的新方法。该方法在两个阶段利用了两个不同的LM：用于候选检索和用于候选验证和消歧。为了评估我们的方法和不同的基线，我们引入了一个名为MALT的新数据集，其根源于Wikidata。我们的方法在F1得分上超过了所有的基准线，尤其在召回率上取得了重大的进展。

    Despite their impressive scale, knowledge bases (KBs), such as Wikidata, still contain significant gaps. Language models (LMs) have been proposed as a source for filling these gaps. However, prior works have focused on prominent entities with rich coverage by LMs, neglecting the crucial case of long-tail entities. In this paper, we present a novel method for LM-based-KB completion that is specifically geared for facts about long-tail entities. The method leverages two different LMs in two stages: for candidate retrieval and for candidate verification and disambiguation. To evaluate our method and various baselines, we introduce a novel dataset, called MALT, rooted in Wikidata. Our method outperforms all baselines in F1, with major gains especially in recall.
    
[^23]: 在课程设计中利用LLMs: 使用GPT-4支持学习目标的创作

    Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring of Learning Objectives. (arXiv:2306.17459v1 [cs.AI])

    [http://arxiv.org/abs/2306.17459](http://arxiv.org/abs/2306.17459)

    本论文评估了使用GPT-4在人工智能课程中自动生成高质量学习目标的能力，强调了学习目标的重要性和撰写高质量目标的挑战性。

    

    我们评估了生成式预训练转换器（GPT-4）在实践导向的人工智能大学课程中自动生成高质量学习目标（LOs）的能力。对于教育中这一新兴技术的机会（例如内容生成，解释）和风险（例如作弊）的讨论日益加强，但到目前为止还没有一项研究评估模型在课程设计和LOs撰写方面的能力。LOs清晰表达了学习者通过参与课程所期望获得的知识和技能。为了有效，LOs必须专注于学生的预期成就，专注于特定的认知过程，并且可以衡量。因此，撰写高质量LOs是一项具有挑战性且耗时（即昂贵）的工作。我们对127个LOs进行了评估，这些LOs是基于精心设计的提示（关于高质量LOs撰写的详细指南）自动生成的。

    We evaluated the capability of a generative pre-trained transformer (GPT-4) to automatically generate high-quality learning objectives (LOs) in the context of a practically oriented university course on Artificial Intelligence. Discussions of opportunities (e.g., content generation, explanation) and risks (e.g., cheating) of this emerging technology in education have intensified, but to date there has not been a study of the models' capabilities in supporting the course design and authoring of LOs. LOs articulate the knowledge and skills learners are intended to acquire by engaging with a course. To be effective, LOs must focus on what students are intended to achieve, focus on specific cognitive processes, and be measurable. Thus, authoring high-quality LOs is a challenging and time consuming (i.e., expensive) effort. We evaluated 127 LOs that were automatically generated based on a carefully crafted prompt (detailed guidelines on high-quality LOs authoring) submitted to GPT-4 for con
    
[^24]: 面向中文文本错误校正的渐进式多任务学习框架

    Progressive Multi-task Learning Framework for Chinese Text Error Correction. (arXiv:2306.17447v1 [cs.CL])

    [http://arxiv.org/abs/2306.17447](http://arxiv.org/abs/2306.17447)

    我们提出了一种面向中文文本错误校正的渐进式多任务学习框架ProTEC，该框架通过引导模型从易到难地学习错误检测、错误类型识别和校正结果生成，以解决过纠正的问题。

    

    中文文本错误校正旨在检测和纠正输入文本中的错误，这有益于人类日常生活和各种下游任务。近期的方法主要采用预训练语言模型(PLM)来解决中文文本错误校正任务，并取得了巨大成功。然而，之前的方法存在过纠正和欠纠正的问题，前者在对精确性要求较高的中文文本错误校正任务中尤为明显。为了缓解过纠正的问题，我们提出了一种新颖的模型无关的渐进式多任务学习框架，命名为ProTEC，它引导一个CTEC模型从简单到困难地学习任务。我们将CTEC任务分为三个子任务，从易到难分别为错误检测、错误类型识别和校正结果生成。在训练过程中，ProTEC将这些子任务纳入多任务训练目标，引导模型逐渐学习文本错误校正。在推理过程中，模型则...

    Chinese Text Error Correction (CTEC) aims to detect and correct errors in the input text, which benefits human's daily life and various downstream tasks. Recent approaches mainly employ Pre-trained Language Models (PLMs) to resolve CTEC task and achieve tremendous success. However, previous approaches suffer from issues of over-correction and under-correction, and the former is especially conspicuous in the precision-critical CTEC task. To mitigate the issue of overcorrection, we propose a novel model-agnostic progressive multitask learning framework for CTEC, named ProTEC, which guides a CTEC model to learn the task from easy to difficult. We divide CTEC task into three sub-tasks from easy to difficult: Error Detection, Error Type Identification, and Correction Result Generation. During the training process, ProTEC guides the model to learn text error correction progressively by incorporating these sub-tasks into a multi-task training objective. During the inference process, the model
    
[^25]: 可证明的针对AI生成文本的鲁棒水印技术

    Provable Robust Watermarking for AI-Generated Text. (arXiv:2306.17439v1 [cs.CL])

    [http://arxiv.org/abs/2306.17439](http://arxiv.org/abs/2306.17439)

    GPTWatermark是一种针对性模型水印技术，通过固定分组设计和强大的可证明保证，提供了对AI生成文本的鲁棒性检测和安全性防御。实验证明了其在检测准确性和生成质量方面的优越性，推动了LLMs负责任使用的进步。

    

    随着AI生成的文本越来越接近人类撰写的内容，检测机器生成的文本的能力变得至关重要。为了应对这一挑战，我们提出了GPTWatermark，一种强大且高质量的解决方案，用于确定一段文本是否来自特定模型。我们的方法扩展了现有的水印策略，并采用了一种固定的分组设计，以增强对编辑和改写攻击的鲁棒性。我们展示了我们的带水印语言模型在生成质量、检测正确性和对抗规避攻击的安全性方面具有强大的可证明保证。在各种大型语言模型（LLMs）和多样化数据集上的实验结果表明，我们的方法在检测准确性方面达到了优越的表现，并且与生成质量在困惑度方面相当，从而促进了LLMs的负责任使用。

    As AI-generated text increasingly resembles human-written content, the ability to detect machine-generated text becomes crucial. To address this challenge, we present GPTWatermark, a robust and high-quality solution designed to ascertain whether a piece of text originates from a specific model. Our approach extends existing watermarking strategies and employs a fixed group design to enhance robustness against editing and paraphrasing attacks. We show that our watermarked language model enjoys strong provable guarantees on generation quality, correctness in detection, and security against evasion attacks. Experimental results on various large language models (LLMs) and diverse datasets demonstrate that our method achieves superior detection accuracy and comparable generation quality in perplexity, thus promoting the responsible use of LLMs.
    
[^26]: LMBot: 将图形知识融入语言模型以进行无图形部署的推特机器人检测

    LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v1 [cs.AI])

    [http://arxiv.org/abs/2306.17408](http://arxiv.org/abs/2306.17408)

    LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。

    

    随着恶意行为者使用越来越先进和广泛的机器人来传播错误信息和操纵舆论，推特机器人的检测已成为一项至关重要的任务。尽管基于图形的推特机器人检测方法取得了最先进的性能，但我们发现它们的推理依赖于距离目标用户多跳的邻居用户，并且获取邻居用户是耗时的，并可能引入偏差。与此同时，我们发现在推特机器人检测上微调后，预训练的语言模型在竞争性性能方面取得了良好的表现，并且在部署过程中不需要图形结构。受到这一发现的启发，我们提出了一种新颖的机器人检测框架LMBot，它将图神经网络(GNNs)的知识融入语言模型(LMs)，以在推特机器人检测中进行无图形部署，以应对数据依赖性的挑战。此外，LMBot对基于图形和不使用图形的数据集兼容。具体而言，我们首先将每个用户表示为一段文本

    As malicious actors employ increasingly advanced and widespread bots to disseminate misinformation and manipulate public opinion, the detection of Twitter bots has become a crucial task. Though graph-based Twitter bot detection methods achieve state-of-the-art performance, we find that their inference depends on the neighbor users multi-hop away from the targets, and fetching neighbors is time-consuming and may introduce bias. At the same time, we find that after finetuning on Twitter bot detection, pretrained language models achieve competitive performance and do not require a graph structure during deployment. Inspired by this finding, we propose a novel bot detection framework LMBot that distills the knowledge of graph neural networks (GNNs) into language models (LMs) for graph-less deployment in Twitter bot detection to combat the challenge of data dependency. Moreover, LMBot is compatible with graph-based and graph-less datasets. Specifically, we first represent each user as a tex
    
[^27]: 非母语读者的日语词汇复杂性：一个新的数据集

    Japanese Lexical Complexity for Non-Native Readers: A New Dataset. (arXiv:2306.17399v1 [cs.CL])

    [http://arxiv.org/abs/2306.17399](http://arxiv.org/abs/2306.17399)

    该论文构建了第一个日语词汇复杂性预测数据集，通过提供不同的复杂度评分满足了非母语读者的需要，并展示了基于BERT的系统在日语LCP中的有效性。

    

    词汇复杂度预测（LCP）是在连续的尺度上预测文本中词汇复杂度的任务。它在简化或标注复杂单词来辅助读者方面起着重要作用。为了研究日语中的词汇复杂性，我们构建了第一个日语LCP数据集。我们的数据集针对中文/韩文标注者和其他人提供了不同的复杂度评分，以满足读者的母语特定需求。在基线实验中，我们展示了基于BERT的日语LCP系统的有效性。

    Lexical complexity prediction (LCP) is the task of predicting the complexity of words in a text on a continuous scale. It plays a vital role in simplifying or annotating complex words to assist readers. To study lexical complexity in Japanese, we construct the first Japanese LCP dataset. Our dataset provides separate complexity scores for Chinese/Korean annotators and others to address the readers' L1-specific needs. In the baseline experiment, we demonstrate the effectiveness of a BERT-based system for Japanese LCP.
    
[^28]: MEDIQA-Chat 2023上的SummQA: 使用GPT-4进行医学摘要的上下文学习

    SummQA at MEDIQA-Chat 2023:In-Context Learning with GPT-4 for Medical Summarization. (arXiv:2306.17384v1 [cs.CL])

    [http://arxiv.org/abs/2306.17384](http://arxiv.org/abs/2306.17384)

    SummQA在MEDIQA-Chat 2023上通过使用GPT-4进行上下文学习，针对医学摘要任务取得了显著效果，尤其是对于few-shot prompting的有效应用，虽然也发现了基于prompting方法的几个不足之处。

    

    由于医学对话的非结构化性质、黄金摘要中的医学术语使用以及在多个症状集合中识别关键信息的需要，医学对话摘要是具有挑战性的。我们在MEDIQA 2023共享任务的Dialogue2Note医学摘要任务中提出了一种新颖的系统。我们针对按部分摘要（任务A）的方法是一个两阶段的过程，首先选择语义相似的对话，然后使用前k个相似的对话作为GPT-4的上下文示例。对于完整摘要（任务B），我们使用类似的解决方案，但k=1。在任务A中，我们取得了第三名（在所有团队中排名第二），在任务B的分类摘要中取得了第四名（在所有团队中排名第二），在任务A的部分标题分类中取得了第15名（在所有团队中排名第九），以及在任务B中在所有团队中排名第八。我们的结果突出了对于这个任务来说few-shot prompting的有效性，同时我们也发现了几个基于prompting的方法的不足之处。

    Medical dialogue summarization is challenging due to the unstructured nature of medical conversations, the use of medical terminology in gold summaries, and the need to identify key information across multiple symptom sets. We present a novel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA 2023 Shared Task. Our approach for section-wise summarization (Task A) is a two-stage process of selecting semantically similar dialogues and using the top-k similar dialogues as in-context examples for GPT-4. For full-note summarization (Task B), we use a similar solution with k=1. We achieved 3rd place in Task A (2nd among all teams), 4th place in Task B Division Wise Summarization (2nd among all teams), 15th place in Task A Section Header Classification (9th among all teams), and 8th place among all teams in Task B. Our results highlight the effectiveness of few-shot prompting for this task, though we also identify several weaknesses of prompting-based approaches. We compare
    
[^29]: 引文作为查询：使用语言模型作为重排序器的源归属方法。

    Citations as Queries: Source Attribution Using Language Models as Rerankers. (arXiv:2306.17322v1 [cs.CL])

    [http://arxiv.org/abs/2306.17322](http://arxiv.org/abs/2306.17322)

    本研究探索了一种新方法，通过微调语言模型以重新排序候选的来源，实现定位文本撰写的源。实验结果表明，半监督方法可以几乎与完全监督方法一样有效，同时避免了对目标和源文档进行昂贵的跨度级注释。

    

    本文通过微调各种语言模型以重新排序候选源，探索了定位撰写文本所使用的来源的新方法。在使用基准的BM25检索模型检索候选源之后，我们测试了多种重新排序方法，以评估它们在源归属任务中的有效性。我们在两个数据集上进行实验，分别为英文维基百科和中世纪阿拉伯历史文献，并采用了多种基于检索和生成的重新排序模型。特别是，我们试图了解所需监督程度如何影响各种重新排序模型的性能。我们发现，半监督方法在避免对目标和源文档进行潜在昂贵的跨度级注释的同时，几乎可以与完全监督方法一样有效。

    This paper explores new methods for locating the sources used to write a text, by fine-tuning a variety of language models to rerank candidate sources. After retrieving candidates sources using a baseline BM25 retrieval model, a variety of reranking methods are tested to see how effective they are at the task of source attribution. We conduct experiments on two datasets, English Wikipedia and medieval Arabic historical writing, and employ a variety of retrieval and generation based reranking models. In particular, we seek to understand how the degree of supervision required affects the performance of various reranking models. We find that semisupervised methods can be nearly as effective as fully supervised methods while avoiding potentially costly span-level annotation of the target and source documents.
    
[^30]: 实现开放领域的主题分类

    Towards Open-Domain Topic Classification. (arXiv:2306.17290v1 [cs.CL])

    [http://arxiv.org/abs/2306.17290](http://arxiv.org/abs/2306.17290)

    该论文介绍了一个开放领域的主题分类系统，该系统可以实时接受用户定义的分类法，并利用预训练语言模型的隐含知识进行零射击分类。实验证明该系统在开放领域场景中明显优于现有的零射击基线模型，与弱监督模型有竞争力。

    

    我们介绍了一个实时接受用户定义分类法的开放领域主题分类系统。用户可以根据他们想要的候选标签对文本片段进行分类，并从我们的网络界面获得即时响应。为了获得这种灵活性，我们以零射击的方式构建了后端模型。通过在从维基百科构建的新数据集上进行训练，我们的标签感知文本分类器能够有效利用预训练语言模型中的隐含知识来处理它以前从未见过的标签。我们在来自不同领域的四个数据集上评估了我们的模型，这些数据集具有不同的标签集。实验结果表明，在开放领域场景下，该模型明显优于现有的零射击基线，并与在域内数据上进行弱监督训练的模型有竞争力。

    We introduce an open-domain topic classification system that accepts user-defined taxonomy in real time. Users will be able to classify a text snippet with respect to any candidate labels they want, and get instant response from our web interface. To obtain such flexibility, we build the backend model in a zero-shot way. By training on a new dataset constructed from Wikipedia, our label-aware text classifier can effectively utilize implicit knowledge in the pretrained language model to handle labels it has never seen before. We evaluate our model across four datasets from various domains with different label sets. Experiments show that the model significantly improves over existing zero-shot baselines in open-domain scenarios, and performs competitively with weakly-supervised models trained on in-domain data.
    
[^31]: 使用多源迁移学习预测COVID-19患者的急诊室再访

    Prediction of COVID-19 Patients' Emergency Room Revisit using Multi-Source Transfer Learning. (arXiv:2306.17257v1 [cs.LG])

    [http://arxiv.org/abs/2306.17257](http://arxiv.org/abs/2306.17257)

    本研究利用迁移学习和自然语言处理技术，预测COVID-19患者出院后在急诊室的再访情况，早期识别有助于医生专注于危及生命的病例。

    

    2019冠状病毒病（COVID-19）导致了一场全球范围内的严重大流行。除了具有高传染性外，COVID-19的临床进展可以有很大差异，从无症状携带者到严重且潜在危及生命的健康并发症。许多患者在出院后的短时间内需要再次就诊急诊室（ER），这极大增加了医务人员的工作负担。及早识别此类患者对于帮助医生专注于治疗危及生命的病例至关重要。在本研究中，我们获取了2020年3月至2021年1月期间匹兹堡大学医学中心13个附属急诊室的3,210个患者就诊电子健康记录（EHR）。我们利用自然语言处理技术ScispaCy提取临床概念，并使用出现最频繁的1001个概念为COVID-19患者在急诊室中建立了7天再访模型。我们从13个急诊室收集的研究数据可能具有

    The coronavirus disease 2019 (COVID-19) has led to a global pandemic of significant severity. In addition to its high level of contagiousness, COVID-19 can have a heterogeneous clinical course, ranging from asymptomatic carriers to severe and potentially life-threatening health complications. Many patients have to revisit the emergency room (ER) within a short time after discharge, which significantly increases the workload for medical staff. Early identification of such patients is crucial for helping physicians focus on treating life-threatening cases. In this study, we obtained Electronic Health Records (EHRs) of 3,210 encounters from 13 affiliated ERs within the University of Pittsburgh Medical Center between March 2020 and January 2021. We leveraged a Natural Language Processing technique, ScispaCy, to extract clinical concepts and used the 1001 most frequent concepts to develop 7-day revisit models for COVID-19 patients in ERs. The research data we collected from 13 ERs may have 
    
[^32]: 以提示为基础的个性化冷启动推荐的研究

    Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v1 [cs.IR])

    [http://arxiv.org/abs/2306.17256](http://arxiv.org/abs/2306.17256)

    本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。

    

    推荐系统在根据用户过去的行为帮助用户发现与其兴趣相符的信息方面发挥着关键作用。然而，当用户和物品之间的历史交互记录不可用时，开发个性化推荐系统变得具有挑战性，这就是所谓的系统冷启动推荐问题。此问题在创业企业或用户参与历史不足的平台中尤为突出。以往的研究集中在用户或物品的冷启动场景，其中系统仍然通过在同一领域中的历史用户和物品交互进行训练来为新用户或物品提供推荐，而无法解决我们的问题。为了弥合这一鸿沟，我们的研究引入了一种创新且有效的方法，利用预训练语言模型的能力。我们将推荐过程转化为自然语言情感分析，其中包含用户资料和物品属性的信息。

    Recommender systems play a crucial role in helping users discover information that aligns with their interests based on their past behaviors. However, developing personalized recommendation systems becomes challenging when historical records of user-item interactions are unavailable, leading to what is known as the system cold-start recommendation problem. This issue is particularly prominent in start-up businesses or platforms with insufficient user engagement history. Previous studies focus on user or item cold-start scenarios, where systems could make recommendations for new users or items but are still trained with historical user-item interactions in the same domain, which cannot solve our problem. To bridge the gap, our research introduces an innovative and effective approach, capitalizing on the capabilities of pre-trained language models. We transform the recommendation process into sentiment analysis of natural languages containing information of user profiles and item attribu
    
[^33]: 学习多语言表达性语音表示以实现无需平行数据的韵律预测

    Learning Multilingual Expressive Speech Representation for Prosody Prediction without Parallel Data. (arXiv:2306.17199v1 [eess.AS])

    [http://arxiv.org/abs/2306.17199](http://arxiv.org/abs/2306.17199)

    我们提出了一种在离散语音单元级别上进行语音情感保留翻译的方法，该方法使用多语言情感嵌入来预测目标语言中语音单元的音高和持续时间，并成功地以相同的情感内容重新合成源语音信号。

    

    我们提出了一种在离散语音单元级别上进行语音情感保留翻译的方法。我们的方法依赖于使用多语言情感嵌入，可以以一种语言无关的方式捕捉情感信息。我们展示了这种嵌入可以用于预测目标语言中语音单元的音高和持续时间，从而使我们能够用相同的情感内容重新合成源语音信号。我们评估了我们的方法对英语和法语语音信号的效果，并展示了它优于不使用情感信息的基线方法，即使情感嵌入是从不同语言提取的。尽管这个初步研究并未直接解决机器翻译问题，但我们的结果表明了我们的方法在语音重合成的跨语言情感保留方面的有效性。

    We propose a method for speech-to-speech emotionpreserving translation that operates at the level of discrete speech units. Our approach relies on the use of multilingual emotion embedding that can capture affective information in a language-independent manner. We show that this embedding can be used to predict the pitch and duration of speech units in a target language, allowing us to resynthesize the source speech signal with the same emotional content. We evaluate our approach to English and French speech signals and show that it outperforms a baseline method that does not use emotional information, including when the emotion embedding is extracted from a different language. Even if this preliminary study does not address directly the machine translation issue, our results demonstrate the effectiveness of our approach for cross-lingual emotion preservation in the context of speech resynthesis.
    
[^34]: 关于指令调整的可利用性

    On the Exploitability of Instruction Tuning. (arXiv:2306.17194v1 [cs.CR])

    [http://arxiv.org/abs/2306.17194](http://arxiv.org/abs/2306.17194)

    该论文研究了如何利用指令调整技术来改变模型行为的问题，并提出了一种自动数据注入的方法AutoPoison。实验结果表明，通过少量的训练数据毒化，对手能够改变模型的行为。

    

    指令调整是一种将大型语言模型与人类意图对齐的有效技术。在这项工作中，我们研究了一个对手如何通过向训练数据注入特定的指令跟随示例来利用指令调整，从而有意改变模型的行为。例如，对手可以通过注入提及目标内容的训练示例，并引诱下游模型展示此类行为来实现内容注入。为了达到这个目标，我们提出了一种自动数据注入的方法，称为AutoPoison。它使用了一个预言模型来将多样攻击目标自然而连贯地注入到毒化数据中。我们展示了两个实例攻击：内容注入和过度拒绝攻击，每个攻击都旨在诱导特定的可利用行为。我们对我们的数据注入方案的强度和隐蔽性进行了量化和基准测试。我们的结果表明，仅通过毒化少量训练数据，AutoPoison允许对手改变模型的行为。

    Instruction tuning is an effective technique to align large language models (LLMs) with human intents. In this work, we investigate how an adversary can exploit instruction tuning by injecting specific instruction-following examples into the training data that intentionally changes the model's behavior. For example, an adversary can achieve content injection by injecting training examples that mention target content and eliciting such behavior from downstream models. To achieve this goal, we propose \textit{AutoPoison}, an automated data poisoning pipeline. It naturally and coherently incorporates versatile attack goals into poisoned data with the help of an oracle LLM. We showcase two example attacks: content injection and over-refusal attacks, each aiming to induce a specific exploitable behavior. We quantify and benchmark the strength and the stealthiness of our data poisoning scheme. Our results show that AutoPoison allows an adversary to change a model's behavior by poisoning only
    
[^35]: 为什么神经语言模型可以解决下一个词预测问题？数学视角

    Why can neural language models solve next-word prediction? A mathematical perspective. (arXiv:2306.17184v1 [cs.CL])

    [http://arxiv.org/abs/2306.17184](http://arxiv.org/abs/2306.17184)

    本文研究了神经语言模型在下一个词预测任务中的成功，在形式语言理论背景下，提出了一种为什么神经语言模型能够学习到组合规则的解释，并在一个现实世界的英语句子示例中提供了零错误的证明。

    

    最近，深度学习在自然语言处理领域引起了革命，神经语言模型在下一个词预测方面证明了非常有效。然而，在形式语言理论的背景下，关于神经语言模型在此任务中可以学习到组合规则的成功的严格理论解释尚未被提出，因为尚不清楚为什么神经语言模型可以学习到控制下一个词预测任务的组合规则。在本文中，我们研究了一类可以用来模拟英语句子的现实世界示例的形式语言。我们构建了神经语言模型来解决这种情况下的下一个词预测任务，且错误率为零。我们的证明突出了嵌入层和全连接组件在神经语言模型中的不同作用。

    Recently, deep learning has revolutionized the field of natural language processing, with neural language models proving to be very effective for next-word prediction. However, a rigorous theoretical explanation for their success in the context of formal language theory has not yet been developed, as it is unclear why neural language models can learn the combinatorial rules that govern the next-word prediction task. In this paper, we study a class of formal languages that can be used to model real-world examples of English sentences. We construct neural language models can solve the next-word prediction task in this context with zero error. Our proof highlights the different roles of the embedding layer and the fully connected component within the neural language model.
    
[^36]: 使用生成对抗网络生成无监督文本嵌入空间用于文本合成

    Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis. (arXiv:2306.17181v1 [cs.CL])

    [http://arxiv.org/abs/2306.17181](http://arxiv.org/abs/2306.17181)

    本论文提出了一种使用生成对抗网络（GAN）生成连续文本嵌入空间的方法（TESGAN），以解决传统GAN在自然语言生成中的限制。这种方法通过引入连续的文本嵌入空间取代离散的标记，使得生成器在通过反向传播更新梯度时更加有效。

    

    生成对抗网络（GAN）是一种用于数据合成的模型，通过生成器和判别器的竞争来创建逼真的数据。尽管GAN在图像合成方面得到了广泛研究，但在自然语言生成方面存在固有的限制。因为自然语言由离散的标记组成，生成器在通过反向传播更新梯度时遇到困难；因此，大多数文本-GAN研究使用奖励系统以随机标记为基础生成句子。因此，先前研究中的生成器在对抗训练之前以自回归方式进行预训练，导致合成的句子重复训练数据。在本文中，我们使用类似原始GAN的框架来合成句子。更具体地说，我们提出了文本嵌入空间生成对抗网络（TESGAN），它生成连续的文本嵌入空间来解决梯度反向传播的问题。

    Generative Adversarial Networks (GAN) is a model for data synthesis, which creates plausible data through the competition of generator and discriminator. Although GAN application to image synthesis is extensively studied, it has inherent limitations to natural language generation. Because natural language is composed of discrete tokens, a generator has difficulty updating its gradient through backpropagation; therefore, most text-GAN studies generate sentences starting with a random token based on a reward system. Thus, the generators of previous studies are pre-trained in an autoregressive way before adversarial training, causing data memorization that synthesized sentences reproduce the training data. In this paper, we synthesize sentences using a framework similar to the original GAN. More specifically, we propose Text Embedding Space Generative Adversarial Networks (TESGAN) which generate continuous text embedding spaces instead of discrete tokens to solve the gradient backpropagat
    
[^37]: 替换和报告：NLP辅助的放射学报告生成

    Replace and Report: NLP Assisted Radiology Report Generation. (arXiv:2306.17180v1 [cs.CL])

    [http://arxiv.org/abs/2306.17180](http://arxiv.org/abs/2306.17180)

    本研究提出了一种模板化的方法，利用NLP技术辅助生成放射学报告。该方法通过使用图像分类器生成图像标签，然后通过基于变压器的模型生成病理描述，并使用BERT模型替换正常报告模板中的相应部分，最终生成完整的放射学报告。

    

    临床实践经常使用医学成像来进行诊断和治疗。自动生成放射学报告的一个重要挑战是，放射学报告是由多个句子组成的长篇叙述，包括异常和正常的发现。因此，将传统的图像标题生成方法应用于生成整个报告是不足够的，因为这些方法是设计用于简要描述图像的短句子。我们提出了一种基于模板的方法，从放射图像中生成放射学报告。我们的方法包括以下步骤：i）使用多标签图像分类器，为输入的放射图生成标签；ii）使用基于变压器的模型，根据步骤（i）中生成的标签生成病理描述（放射图像上的异常发现的描述）；iii）使用基于BERT的多标签文本分类器，找到正常报告模板中要替换为生成的病理描述的部分；iv）使用基于规则的模型来生成最终的放射学报告。

    Clinical practice frequently uses medical imaging for diagnosis and treatment. A significant challenge for automatic radiology report generation is that the radiology reports are long narratives consisting of multiple sentences for both abnormal and normal findings. Therefore, applying conventional image captioning approaches to generate the whole report proves to be insufficient, as these are designed to briefly describe images with short sentences. We propose a template-based approach to generate radiology reports from radiographs. Our approach involves the following: i) using a multilabel image classifier, produce the tags for the input radiograph; ii) using a transformer-based model, generate pathological descriptions (a description of abnormal findings seen on radiographs) from the tags generated in step (i); iii) using a BERT-based multi-label text classifier, find the spans in the normal report template to replace with the generated pathological descriptions; and iv) using a rul
    
[^38]: 使用ChatGPT作为文本注释工具进行情感分析

    Leveraging ChatGPT As Text Annotation Tool For Sentiment Analysis. (arXiv:2306.17177v1 [cs.CL])

    [http://arxiv.org/abs/2306.17177](http://arxiv.org/abs/2306.17177)

    本研究探索了使用ChatGPT作为情感分析任务的数据标注工具，克服了监督学习算法需要人工标注的限制和基于词典的算法无法捕捉全部情感范围的缺点。

    

    情感分析是一项众所周知的自然语言处理任务，涉及识别给定文本的情感色彩或极性。随着社交媒体和其他在线平台的增长，情感分析对于寻求监控和理解客户反馈和意见的企业和组织变得越来越重要。监督学习算法已经广泛用于这个任务，但它们需要人工标注的文本来创建分类器。为了克服这个挑战，使用了基于词典的工具。基于词典的算法的一个缺点是它们依赖于预定义的情感词典，这可能无法捕捉自然语言中的所有情感范围。ChatGPT是OpenAI的新产品，已成为最受欢迎的人工智能产品之一。它可以回答各种主题和任务的问题。本研究探讨了使用ChatGPT作为不同情感分析任务的数据标注工具。在两个实验数据集上进行了评估。

    Sentiment analysis is a well-known natural language processing task that involves identifying the emotional tone or polarity of a given piece of text. With the growth of social media and other online platforms, sentiment analysis has become increasingly crucial for businesses and organizations seeking to monitor and comprehend customer feedback as well as opinions. Supervised learning algorithms have been popularly employed for this task, but they require human-annotated text to create the classifier. To overcome this challenge, lexicon-based tools have been used. A drawback of lexicon-based algorithms is their reliance on pre-defined sentiment lexicons, which may not capture the full range of sentiments in natural language. ChatGPT is a new product of OpenAI and has emerged as the most popular AI product. It can answer questions on various topics and tasks. This study explores the use of ChatGPT as a tool for data labeling for different sentiment analysis tasks. It is evaluated on two
    
[^39]: 新闻验证者的对决：ChatGPT 3.5、ChatGPT 4.0、Bing AI和Bard在新闻事实检查中的比较性能评估

    News Verifiers Showdown: A Comparative Performance Evaluation of ChatGPT 3.5, ChatGPT 4.0, Bing AI, and Bard in News Fact-Checking. (arXiv:2306.17176v1 [cs.CL])

    [http://arxiv.org/abs/2306.17176](http://arxiv.org/abs/2306.17176)

    本研究通过对比实验评估了ChatGPT 3.5、ChatGPT 4.0、Bing AI和Bard在新闻事实检查中的表现，结果显示它们的熟练程度普遍居中，其中OpenAI的GPT-4.0在区分真相和欺骗方面具有一定优势。

    

    本研究旨在评估知名大型语言模型（LLMs），包括OpenAI的ChatGPT 3.5和4.0、谷歌的Bard（LaMDA）和微软的Bing AI，在使用黑盒测试区分新闻真实性方面的熟练程度。总共提供了100条经过事实核查的新闻，所有新闻均来自独立的事实核查机构，在受控条件下向每个LLMs提供。它们的回答被归类为三类：真实、错误和部分真实/错误。基于独立机构提供的核实事实，评估了LLMs的分类准确性来衡量其有效性。结果显示，所有模型的熟练程度都属于中等水平，平均得分为65.25/100。在这些模型中，OpenAI的GPT-4.0以71分的得分脱颖而出，表明较新的LLMs在区分真相和欺骗方面具有优势。然而，与人类事实核查员的表现相比，尽管AI模型表现出一定的熟练度，但仍有改进空间。

    This study aimed to evaluate the proficiency of prominent Large Language Models (LLMs), namely OpenAI's ChatGPT 3.5 and 4.0, Google's Bard(LaMDA), and Microsoft's Bing AI in discerning the truthfulness of news items using black box testing. A total of 100 fact-checked news items, all sourced from independent fact-checking agencies, were presented to each of these LLMs under controlled conditions. Their responses were classified into one of three categories: True, False, and Partially True/False. The effectiveness of the LLMs was gauged based on the accuracy of their classifications against the verified facts provided by the independent agencies. The results showed a moderate proficiency across all models, with an average score of 65.25 out of 100. Among the models, OpenAI's GPT-4.0 stood out with a score of 71, suggesting an edge in newer LLMs' abilities to differentiate fact from deception. However, when juxtaposed against the performance of human fact-checkers, the AI models, despite
    
[^40]: 从原始的GP笔记中挖掘知识图谱，用于远程COVID-19初级保健评估

    RECAP-KG: Mining Knowledge Graphs from Raw GP Notes for Remote COVID-19 Assessment in Primary Care. (arXiv:2306.17175v1 [cs.CL])

    [http://arxiv.org/abs/2306.17175](http://arxiv.org/abs/2306.17175)

    本研究提出了一个从原始GP笔记中提取信息并构建知识图谱的框架，用于解决临床决策过程中现有技术无法处理的问题。

    

    临床决策是向患者提供适当护理的基本阶段。近年来，为了帮助临床医生在这个过程中做出决策，已经开发了几个决策系统。然而，目前使用的技术解决方案基于简单的回归模型，只能考虑简单的预定义多选特征，如患者年龄、既往病史、吸烟者状况等。决策系统当前无法处理的一个特定患者数据来源是患者会诊的GP笔记的收集。这些笔记包含了临床医生用来做出最终决策并将患者引导到适当护理的关键体征和症状。从GP笔记中提取信息是一个技术上具有挑战性的问题，因为它们往往包含缩写、打字错误和不完整的句子。本文解决了这个公开挑战。我们提出了一个框架，可以执行从原始GP笔记中提取出关键信息，并构建知识图谱的任务。

    Clinical decision-making is a fundamental stage in delivering appropriate care to patients. In recent years several decision-making systems designed to aid the clinician in this process have been developed. However, technical solutions currently in use are based on simple regression models and are only able to take into account simple pre-defined multiple-choice features, such as patient age, pre-existing conditions, smoker status, etc. One particular source of patient data, that available decision-making systems are incapable of processing is the collection of patient consultation GP notes. These contain crucial signs and symptoms - the information used by clinicians in order to make a final decision and direct the patient to the appropriate care. Extracting information from GP notes is a technically challenging problem, as they tend to include abbreviations, typos, and incomplete sentences.  This paper addresses this open challenge. We present a framework that performs knowledge grap
    
[^41]: 在在线领域中强化离线学习的方法：增强自然语言生成算法的能力

    Empowering NLG: Offline Reinforcement Learning for Informal Summarization in Online Domains. (arXiv:2306.17174v1 [cs.CL])

    [http://arxiv.org/abs/2306.17174](http://arxiv.org/abs/2306.17174)

    该论文介绍了一种离线强化学习的自然语言生成方法，用于在在线领域生成非正式摘要，并通过該方法在用户体验和负载减轻方面取得了显著改进。

    

    我们的研究引入了一种创新的自然语言生成（NLG）方法，旨在优化用户体验并减轻人工客服代理的工作负担。我们的主要目标是使用离线强化学习技术为在线文章和帖子生成非正式摘要。在我们的研究中，我们将我们提出的方法与现有的文本生成方法进行了比较，并全面介绍了我们的架构设计，包括爬虫、强化学习和文本生成模块。通过提出这种原创方法，我们的论文为NLG领域作出了有价值的贡献，为在线内容生成自然语言摘要提供了新的视角。通过实施“增强NLG”，我们能够在在线领域生成更高质量的回复。实验结果显示，平均“喜欢”评分显著提高，从0.09954378增加到0.5000152。

    Our research introduces an innovative Natural Language Generation (NLG) approach that aims to optimize user experience and alleviate the workload of human customer support agents. Our primary objective is to generate informal summaries for online articles and posts using an offline reinforcement learning technique. In our study, we compare our proposed method with existing approaches to text generation and provide a comprehensive overview of our architectural design, which incorporates crawling, reinforcement learning, and text generation modules. By presenting this original approach, our paper makes a valuable contribution to the field of NLG by offering a fresh perspective on generating natural language summaries for online content. Through the implementation of Empowering NLG, we are able to generate higher-quality replies in the online domain. The experimental results demonstrate a significant improvement in the average "like" score, increasing from 0.09954378 to 0.5000152. This ad
    
[^42]: 编程教育的生成AI：比较ChatGPT、GPT-4和人类导师的表现

    Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors. (arXiv:2306.17156v1 [cs.CY])

    [http://arxiv.org/abs/2306.17156](http://arxiv.org/abs/2306.17156)

    该论文系统评估了ChatGPT、GPT-4和人类导师在不同的编程教育场景中的表现，并发现GPT-4优于ChatGPT，接近于人类导师。

    

    生成AI和大型语言模型在提高计算机教育方面具有很大的潜力，通过为初级编程提供下一代教育技术。最近的研究已经研究了这些模型在与编程教育相关的不同场景中的应用；然而，这些研究由于多种原因而受限，因为它们通常考虑的是已经过时的模型或仅仅特定的场景。因此，缺乏一个系统的研究来对最先进的模型进行全面的编程教育场景基准测试。在我们的工作中，我们系统地评估了两个模型，ChatGPT（基于GPT-3.5）和GPT-4，并将其在各种场景下与人类导师的表现进行了比较。我们使用五个初级Python编程问题和来自在线平台的真实错误程序进行评估，并使用专家评注来评估性能。我们的结果表明，GPT-4明显优于ChatGPT（基于GPT-3.5），并且接近于人类导师。

    Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming. Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s). Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios. We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations. Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to hu
    
[^43]: 《在一个对女性厌恶的incels论坛中的身份建构》

    Identity Construction in a Misogynist Incels Forum. (arXiv:2306.15745v1 [cs.CL])

    [http://arxiv.org/abs/2306.15745](http://arxiv.org/abs/2306.15745)

    本研究使用定量文本和网络分析方法，研究了最大的黑洞incels论坛如何讨论身份群体。研究发现该社区产生了许多新的身份术语，存在物质主义的意识形态。对此我们讨论了对自动化 misogynist hate speech 检测研究的影响。

    

    本文使用定量文本和网络分析方法，研究了incels.is，即最大的黑洞incels论坛如何讨论身份群体。我们发现该社区产生了许多新的身份术语，尽管女性的术语最常见，但其他少数群体的提及也在增加。对身份群体的关联分析表明，这个社区存在着物质主义的意识形态，其中身体外貌、性别和种族等决定了人的价值。我们讨论了对自动化 misogynist hate speech 检测研究的影响。

    Online communities of involuntary celibates (incels) are a prominent source of misogynist hate speech. In this paper, we use quantitative text and network analysis approaches to examine how identity groups are discussed on incels.is, the largest black-pilled incels forum. We find that this community produces a wide range of novel identity terms and, while terms for women are most common, mentions of other minoritized identities are increasing. An analysis of the associations made with identity groups suggests an essentialist ideology where physical appearance, as well as gender and racial hierarchies, determine human value. We discuss implications for research into automated misogynist hate speech detection.
    
[^44]: 布局和任务感知的零样本文档图像问答指导模型

    Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering. (arXiv:2306.00526v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00526](http://arxiv.org/abs/2306.00526)

    该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。

    

    基于布局感知多模态预训练模型的预训练-微调范式在文档图像问答方面取得了显著进展。然而，领域预训练和任务微调对于额外的视觉、布局和任务模块阻止了其直接利用现成的指导调优语言基础模型，而这些模型最近在零样本学习方面显示出了良好的潜力。与将语言模型与文档图像问答领域对齐相反，我们将文档图像问答与现成的指导调优语言基础模型对齐，利用其零样本能力。具体而言，我们提出了布局和任务感知的指导提示模型，称为LATIN-Prompt，它包括布局感知的文档内容和任务感知的描述。前者通过适当的空格和换行符从OCR工具中恢复文本片段之间的布局信息。后者确保模型生成符合任务需求的答案。

    The pre-training-fine-tuning paradigm based on layout-aware multimodal pre-trained models has achieved significant progress on document image question answering. However, domain pre-training and task fine-tuning for additional visual, layout, and task modules prevent them from directly utilizing off-the-shelf instruction-tuning language foundation models, which have recently shown promising potential in zero-shot learning. Contrary to aligning language models to the domain of document image question answering, we align document image question answering to off-the-shell instruction-tuning language foundation models to utilize their zero-shot capability. Specifically, we propose layout and task aware instruction prompt called LATIN-Prompt, which consists of layout-aware document content and task-aware descriptions. The former recovers the layout information among text segments from OCR tools by appropriate spaces and line breaks. The latter ensures that the model generates answers that m
    
[^45]: 自然语言解释的真实性测试

    Faithfulness Tests for Natural Language Explanations. (arXiv:2305.18029v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18029](http://arxiv.org/abs/2305.18029)

    该论文研究了评估自然语言解释真实性的问题，并提出了两个测试方法：反事实输入编辑器和重建输入测试。这些测试对于评估新兴的NLE模型，对开发真实的NLEs具有重要意义。

    

    神经模型的解释旨在揭示模型预测的决策过程。然而，最近的研究表明，诸如显著性地图或反事实解释等当前的解释方法可能会误导，因为它们容易呈现与模型内部机制不一致的原因。本研究探讨了评估自然语言解释（NLEs）真实性的挑战性问题。为此，我们提出了两个测试。首先，我们提出了一种反事实输入编辑器，用于插入导致反事实预测但不被NLEs反映的原因。其次，我们根据生成的NLEs中所述的原因重建输入，并检查它们导致相同预测的频率。我们的测试可以评估新兴的NLE模型，为开发真实的NLEs提供了基本工具。

    Explanations of neural models aim to reveal a model's decision-making process for its predictions. However, recent work shows that current methods giving explanations such as saliency maps or counterfactuals can be misleading, as they are prone to present reasons that are unfaithful to the model's inner workings. This work explores the challenging question of evaluating the faithfulness of natural language explanations (NLEs). To this end, we present two tests. First, we propose a counterfactual input editor for inserting reasons that lead to counterfactual predictions but are not reflected by the NLEs. Second, we reconstruct inputs from the reasons stated in the generated NLEs and check how often they lead to the same predictions. Our tests can evaluate emerging NLE models, proving a fundamental tool in the development of faithful NLEs.
    
[^46]: 通过多语言微调和翻译指令诱发大规模语言模型的翻译能力

    Eliciting the Translation Ability of Large Language Models via Multilingual Finetuning with Translation Instructions. (arXiv:2305.15083v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15083](http://arxiv.org/abs/2305.15083)

    本文通过对多语言预训练语言模型进行微调，研究了它们如何通过翻译指令执行多语言翻译任务。研究发现多语言LLMs具有较强的翻译能力，这取决于语言与英语的相似性和预训练阶段使用的数据量。此外，执行翻译指令的能力依赖于对指令的理解和不同语言之间的对齐。

    

    大规模预训练语言模型（LLMs），例如ChatGPT和GPT4，展现出在多语言翻译方面的强大能力，而无需明确训练并行语料库。本文研究了LLMs如何获得其对不同语言进行翻译指令的能力。我们通过对多语言预训练语言模型XGLM-7B进行微调来执行多语言翻译任务，并进行了详细分析。首先，我们展示了多语言LLMs具有比先前展示的更强的翻译能力。对于某种语言，其表现取决于其与英语的相似性和预训练阶段使用的数据量。其次，我们发现LLMs执行翻译指令的能力依赖于对翻译指令的理解以及不同语言之间的对齐。通过多语言微调，LLMs能够学习并在翻译任务中表现出良好的能力，即使对于那些语言间平行语料较少的情况。

    Large-scale Pretrained Language Models (LLMs), such as ChatGPT and GPT4, have shown strong abilities in multilingual translations, without being explicitly trained on parallel corpora. It is interesting how the LLMs obtain their ability to carry out translation instructions for different languages. In this paper, we present a detailed analysis by finetuning a multilingual pretrained language model, XGLM-7B, to perform multilingual translation following given instructions. Firstly, we show that multilingual LLMs have stronger translation abilities than previously demonstrated. For a certain language, the performance depends on its similarity to English and the amount of data used in the pretraining phase. Secondly, we find that LLMs' ability to carry out translation instructions relies on the understanding of translation instructions and the alignment among different languages. With multilingual finetuning, LLMs could learn to perform the translation task well even for those language pa
    
[^47]: UPop：用于压缩视觉语言Transformer模型的统一和渐进式剪枝方法

    UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers. (arXiv:2301.13741v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13741](http://arxiv.org/abs/2301.13741)

    UPop是一种通用的视觉语言Transformer压缩框架，采用统一和渐进式剪枝方法，可自动分配剪枝比率，实现更高的压缩比率。

    

    真实世界的数据包含大量的多模态信息，其中视觉和语言是最具代表性的两种模态。此外，越来越重的模型，例如Transformer，已经引起了研究人员对模型压缩的关注。然而，如何压缩多模态模型，特别是视觉语言Transformer，仍然未被充分探索。本文提出了一种名为UPop的通用视觉语言Transformer压缩框架，它包括1）在原始模型中在连续优化空间中统一搜索多模态子网，从而实现可压缩模态和结构之间自动分配剪枝比率；2）渐进式搜索和微调子网，从而保持搜索和微调之间的收敛，以实现更高的压缩比率。

    Real-world data contains a vast amount of multimodal information, among which vision and language are the two most representative modalities. Moreover, increasingly heavier models, \textit{e}.\textit{g}., Transformers, have attracted the attention of researchers to model compression. However, how to compress multimodal models, especially vison-language Transformers, is still under-explored. This paper proposes the \textbf{U}nified and \textbf{P}r\textbf{o}gressive \textbf{P}runing (\textbf{\emph{UPop}}) as a universal vison-language Transformer compression framework, which incorporates 1) unifiedly searching multimodal subnets in a continuous optimization space from the original model, which enables automatic assignment of pruning ratios among compressible modalities and structures; 2) progressively searching and retraining the subnet, which maintains convergence between the search and retrain to attain higher compression ratios. Experiments on various tasks, datasets, and model archit
    
[^48]: 异构数据源上的对话问答

    Conversational Question Answering on Heterogeneous Sources. (arXiv:2204.11677v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2204.11677](http://arxiv.org/abs/2204.11677)

    本文提出了CONVINSE，一个用于异构数据源上的ConvQA的端到端流水线，通过联合提取来自知识库、文本和表格的信息，提升了答案覆盖率和可信度。

    

    会话问答(ConvQA)解决了顺序信息需求中的后续问题中上下文隐含的问题。当前的ConvQA系统只能在同质化的信息源上操作，如知识库(KB)、文本语料库或表格集合。本文针对的是在这些异质数据源中联合提取信息，从而提升答案覆盖率和可信度的新问题。我们提出了CONVINSE，一个用于异构数据源上的ConvQA的端到端流水线，分为三个阶段：i）学习对传入问题及其对话上下文的明确结构化表示，ii）利用这个类似框架的表示方式统一地获取到来自KB、文本和表格的相关证据，iii）运行融合解码模型来生成答案。我们构建并发布了第一个基准数据集ConvMix，用于异构数据源上的ConvQA，包括3000个真实用户对话和16000个问题，以及实体注释。

    Conversational question answering (ConvQA) tackles sequential information needs where contexts in follow-up questions are left implicit. Current ConvQA systems operate over homogeneous sources of information: either a knowledge base (KB), or a text corpus, or a collection of tables. This paper addresses the novel issue of jointly tapping into all of these together, this way boosting answer coverage and confidence. We present CONVINSE, an end-to-end pipeline for ConvQA over heterogeneous sources, operating in three stages: i) learning an explicit structured representation of an incoming question and its conversational context, ii) harnessing this frame-like representation to uniformly capture relevant evidences from KB, text, and tables, and iii) running a fusion-in-decoder model to generate the answer. We construct and release the first benchmark, ConvMix, for ConvQA over heterogeneous sources, comprising 3000 real-user conversations with 16000 questions, along with entity annotations,
    
[^49]: 在不产生灾难性遗忘的情况下提高预训练语言模型的性别公平性。

    Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting. (arXiv:2110.05367v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.05367](http://arxiv.org/abs/2110.05367)

    该论文提出了一种新方法GEEP，用于提高预训练语言模型的性别公平性，同时没有灾难性遗忘问题。透过性别中性数据学习性别相关的提示，GEEP实现了SOTA表现并在GLUE性能上取得了显著提高。

    

    现有的解决预训练语言模型性别偏见的研究通常建立一个小型的性别中性数据集，然后在该数据集上对模型进行第二阶段的预训练。然而，鉴于性别中性数据集的规模有限且集中关注，第二阶段预训练会出现灾难性遗忘。忘记原始训练数据中的信息可能会严重损害模型在下游任务中的性能。在这项工作中，我们通过在GLUE中进行评估，实证地表明这种方法中会发生灾难性遗忘。然后，我们提出了一种新方法，GEnder Equality Prompt (GEEP)，以改善预训练模型的性别公平性，且遗忘较少。 GEEP会冻结预训练模型，并使用性别中性数据学习与性别相关的提示。实证结果显示，GEEP不仅在性别公平任务上实现了SOTA表现，而且在GLUE上遗忘较少，并取得了明显的性能提高。

    Existing studies addressing gender bias of pre-trained language models, usually build a small gender-neutral data set and conduct a second phase pre-training on the model with such data. However, given the limited size and concentrated focus of the gender-neutral data, catastrophic forgetting would occur during second-phase pre-training. Forgetting information in the original training data may damage the model's downstream performance by a large margin. In this work, we empirically show that catastrophic forgetting occurs in such methods by evaluating them with general NLP tasks in GLUE. Then, we propose a new method, GEnder Equality Prompt (GEEP), to improve gender fairness of pre-trained models with less forgetting. GEEP freezes the pre-trained model and learns gender-related prompts with gender-neutral data. Empirical results show that GEEP not only achieves SOTA performances on gender fairness tasks, but also forgets less and performs better on GLUE by a large margin.
    

