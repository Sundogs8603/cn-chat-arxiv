# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors.](http://arxiv.org/abs/2306.17156) | 该论文系统评估了ChatGPT、GPT-4和人类导师在不同的编程教育场景中的表现，并发现GPT-4优于ChatGPT，接近于人类导师。 |
| [^2] | [LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding.](http://arxiv.org/abs/2306.17107) | LLaVAR是一个增强的视觉指令调整模型，通过使用文本丰富的图像数据，它能够显著提升在文本为基础的视觉问答数据集上的准确率。 |
| [^3] | [LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT.](http://arxiv.org/abs/2306.17103) | LyricWhiz是一种鲁棒、多语言、零射击的自动歌词转录方法，通过使用Whisper作为"耳朵"和GPT-4作为"大脑"，它在各种数据集上实现了最先进的性能，同时还实现了在多种语言中进行歌词转录的能力，并创建了第一个大规模多语言歌词转录数据集。 |
| [^4] | [Concept-Oriented Deep Learning with Large Language Models.](http://arxiv.org/abs/2306.17089) | 本文讨论了大型语言模型在概念导向深度学习中的应用，包括从文本和图像中提取概念和概念图。同时也探讨了多模态语言模型在表达人类知识方面的优势。 |
| [^5] | [Presenting an approach based on weighted CapsuleNet networks for Arabic and Persian multi-domain sentiment analysis.](http://arxiv.org/abs/2306.17068) | 本文提出了一种基于加权胶囊网络的阿拉伯语和波斯语多领域情感分析方法，通过训练单独的胶囊网络并使用加权度量来实现情感分类，具有较好的准确性和适应性。 |
| [^6] | [The mapKurator System: A Complete Pipeline for Extracting and Linking Text from Historical Maps.](http://arxiv.org/abs/2306.17059) | 该论文介绍了一种名为mapKurator的系统，能完整地从历史地图中提取和链接文本信息。该系统解决了传统方法中对位置相关词语的忽略问题，并利用主题建模方法考虑更广的主题范围，能够识别文档的空间焦点。 |
| [^7] | [Towards Grammatical Tagging for the Legal Language of Cybersecurity.](http://arxiv.org/abs/2306.17042) | 本研究提出了一种面向网络安全法律语言的语法标注方法，通过使用先进的自然语言处理工具和手动分析，实现了从法律文件中提取关键词性的自动化。该方法可以适用于任何法律语言，并具有广泛的适用性。 |
| [^8] | [Exploring & Exploiting High-Order Graph Structure for Sparse Knowledge Graph Completion.](http://arxiv.org/abs/2306.17034) | 本论文提出了一种新的框架 LR-GCN，用于在稀疏知识图谱中进行补全。该框架能够探索高阶图结构，自动捕捉实体之间的远程依赖关系，并通过逻辑推理提炼知识，从而有效解决稀疏性带来的挑战。 |
| [^9] | [Classifying Crime Types using Judgment Documents from Social Media.](http://arxiv.org/abs/2306.17020) | 本文提出了一种通过NLP处理方法的新的训练模型，通过生成新样本来平衡不均匀的数据集分布的缺陷，并使用预训练和微调来赋予模型对小数据集的良好泛化能力。 |
| [^10] | [High-Quality Automatic Voice Over with Accurate Alignment: Supervision through Self-Supervised Discrete Speech Units.](http://arxiv.org/abs/2306.17005) | 本文提出了一种新的自动配音方法，通过自监督离散语音单元预测的学习目标，实现了更准确的对齐学习和更高质量的语音合成，优于传统方法的表现。 |
| [^11] | [MEMD-ABSA: A Multi-Element Multi-Domain Dataset for Aspect-Based Sentiment Analysis.](http://arxiv.org/abs/2306.16956) | 这个论文提出了一个大规模的多要素多领域数据集（MEMD-ABSA），用于面向方面情感分析的研究。数据集涵盖了五个领域的四个要素，包括近2万个评论句子和3万个带有显式和隐式方面和观点的四元组。研究结果表明，开放领域ABSA以及挖掘隐含的方面和观点仍然是待解决的挑战。 |
| [^12] | [Predicting Music Hierarchies with a Graph-Based Neural Decoder.](http://arxiv.org/abs/2306.16955) | 本文提出了一个基于图的神经解码器，用于预测音乐的层次结构。通过使用转换器编码器和分类器，该系统能够将音乐序列解析为依赖树，并在多个音乐特征和顺序上下文信息的基础上提供部分结果和更好的性能。 |
| [^13] | [UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?.](http://arxiv.org/abs/2306.16931) | 本文介绍了UMASS_BioNLP团队在MEDIQA-Chat 2023共享任务中的参与，提出了一种新型LLMs协作系统用于生成高质量对话数据集，并与ChatGPT和GPT-4进行了比较分析。 |
| [^14] | [Leveraging Cross-Utterance Context For ASR Decoding.](http://arxiv.org/abs/2306.16903) | 本文研究了如何利用跨话语上下文来提升语音识别系统的解码性能，实验结果表明，通过波束搜索和长上下文转换器LMs可以更好地利用跨话语上下文，实现了较低的识别误差。 |
| [^15] | [Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research.](http://arxiv.org/abs/2306.16900) | 这项研究调查了自然语言处理领域计算需求量大的研究中存在的不平等和担忧，通过对NLP社区的312位参与者进行调查，发现了在资历、学术界和工业界等方面存在的（不）平等现象，并提出了相应的缓解建议。 |
| [^16] | [Tokenization and the Noiseless Channel.](http://arxiv.org/abs/2306.16842) | 优秀的分词器能够实现较高的通道使用效率，并且R\'enyi熵在机器翻译中与\textsc{Bleu}有很强的相关性。 |
| [^17] | [A Formal Perspective on Byte-Pair Encoding.](http://arxiv.org/abs/2306.16837) | 这篇论文从形式化的角度对Byte-Pair编码进行了研究，将其形式化为组合优化问题，证明了迭代贪婪版本是对最优合并序列的近似解，并优化了算法的运行时间复杂度。 |
| [^18] | [CLIPAG: Towards Generator-Free Text-to-Image Generation.](http://arxiv.org/abs/2306.16805) | 本文将感知对齐梯度（PAG）的研究扩展到视觉-语言架构，并通过对 CLIP 进行鲁棒性调整，展示了在视觉-语言生成任务中集成 CLIPAG 可以实现显著改进，并实现了无生成器的文本到图像生成。 |
| [^19] | [Benchmarking Large Language Model Capabilities for Conditional Generation.](http://arxiv.org/abs/2306.16793) | 本文测评了大型语言模型在条件生成中的能力，并讨论了其生成质量的评估和与真实世界应用场景的关联性。 |
| [^20] | [Stop Pre-Training: Adapt Visual-Language Models to Unseen Languages.](http://arxiv.org/abs/2306.16774) | 这项研究提出了一种利用多语言预训练语言模型将视觉语言模型适应于未见语言的方法，通过跨语言的上下文化词元嵌入对齐技术，无需图像输入和目标语言数据，取得了在图像-文本检索、视觉蕴涵和自然语言视觉推理等任务上的良好结果。 |
| [^21] | [DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations.](http://arxiv.org/abs/2306.16770) | DialoGPS是第一个在连续语义空间中进行对话路径采样的多对多增强方法，用于多轮对话的数据增强任务。 |
| [^22] | [Unified Language Representation for Question Answering over Text, Tables, and Images.](http://arxiv.org/abs/2306.16762) | 本文提出了一种新的方法来回答复杂问题，即将图像和表格转化为统一的语言表示，通过检索、排序和生成三个步骤解决文本问答问题。实验证明，这种方法在两个数据集上表现优于所有现有方法，并在WebQA榜单上取得了最佳表现。 |
| [^23] | [Evaluating Paraphrastic Robustness in Textual Entailment Models.](http://arxiv.org/abs/2306.16722) | 本文介绍了PaRTE，一个包含1,126对文本蕴涵示例的集合，用于评估模型对改写句的鲁棒性。实验结果表明，现代模型在8-16％的改写示例上改变了他们的预测，说明仍有改进的空间。 |
| [^24] | [Automatic Speech Recognition of Non-Native Child Speech for Language Learning Applications.](http://arxiv.org/abs/2306.16710) | 该论文评估了两种最新的语音识别系统在非母语儿童语音学习中的表现，并研究了使用语音识别技术提供对儿童发音和流利性的反馈的实用性。 |
| [^25] | [Multi-source Semantic Graph-based Multimodal Sarcasm Explanation Generation.](http://arxiv.org/abs/2306.16650) | 本研究提出了一种基于多源语义图的多模态讽刺解释生成方案（TEAM），该方案通过提取对象级语义元数据和引入外部相关知识概念，有效地解决了现有方法中存在的视觉特征与解码器语义空间之间的差距以及潜在的外部知识限制。 |
| [^26] | [ZeroGen: Zero-shot Multimodal Controllable Text Generation with Multiple Oracles.](http://arxiv.org/abs/2306.16649) | ZeroGen是一种零射击的多模态可控文本生成方法，通过在解码过程中利用文本和图像信号的控制，将它们映射到统一的概率空间并通过加权添加自定义LM输出实现高效率的文本生成。实验证明了来自不同模式信号之间的深度与宽度之间的关系。 |
| [^27] | [Probabilistic Linguistic Knowledge and Token-level Text Augmentation.](http://arxiv.org/abs/2306.16644) | 研究了标记级文本增强的有效性和概率语言知识的作用，实验证明了所研究的五种标记级文本增强技术在语言评估环境下不具备普遍有效性，而且与不同分类模型类型无关。 |
| [^28] | [A negation detection assessment of GPTs: analysis with the xNot360 dataset.](http://arxiv.org/abs/2306.16638) | 本研究评估了GPT-2、GPT-3、GPT-3.5和GPT-4模型在否定检测方面的表现，发现它们之间存在显著的性能差异，GPT-4表现最优，而GPT-3.5表现下降。总体而言，GPT模型在否定检测方面的能力相对有限，这表明该任务挑战了它们在自然语言理解方面的边界。我们不仅突显了GPT模型在处理否定方面的限制，还强调了逻辑可靠性的重要性。 |
| [^29] | [CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?.](http://arxiv.org/abs/2306.16636) | 该论文介绍了中国小学数学应用题（CMATH）数据集，评估了多个流行的大型语言模型（LLMs）在小学数学不同年级的表现。研究发现只有GPT-4在所有年级中取得成功，并且能够保持鲁棒性，而其他模型则在不同年级上表现较差。 |
| [^30] | [An Efficient Sparse Inference Software Accelerator for Transformer-based Language Models on CPUs.](http://arxiv.org/abs/2306.16601) | 本文提出了一个用于基于Transformer的语言模型的高效稀疏推断软件加速器，在CPU上利用Intel Deep Learning Boost实现了稀疏矩阵-稠密矩阵乘法的优化，相较于现有的稀疏库，在各种形状和稀疏度下都获得了一个数量级的性能提升。 |
| [^31] | [Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision.](http://arxiv.org/abs/2306.16564) | 本文介绍了一种Pareto Optimal自监督框架，利用可用的编程监督将大型语言模型(LLM)的响应进行系统校准，通过为每个响应生成风险评分，而无需额外的手动工作。 |
| [^32] | [ICSVR: Investigating Compositional and Semantic Understanding in Video Retrieval Models.](http://arxiv.org/abs/2306.16533) | 这篇论文研究了视频检索模型中的组合和语义理解，并通过在标准基准测试上进行实验，评估了这些组成部分对视频检索性能的影响。 |
| [^33] | [Pre-Training Multi-Modal Dense Retrievers for Outside-Knowledge Visual Question Answering.](http://arxiv.org/abs/2306.16478) | 本文提出了一个为外部知识视觉问答任务预训练的段落检索模型的自动数据生成管道，相较于最先进的架构实现了更好的Precision@5。此外，所提出的预训练方法在零样本检索场景中展示了良好的能力。 |
| [^34] | [A Framework for Identifying Depression on Social Media: MentalRiskES@IberLEF 2023.](http://arxiv.org/abs/2306.16125) | 该论文介绍了在社交媒体上识别抑郁症的框架，使用机器学习和深度学习技术来解决四个预测子任务，并发现使用句子嵌入作为线性回归器的输入产生了更好的结果。 |
| [^35] | [Chain-of-Thought Prompt Distillation for Multimodal Named Entity and Multimodal Relation Extraction.](http://arxiv.org/abs/2306.14122) | 本研究提出了一种链式思维提示提取方法，将大型语言模型的推理能力转化为更紧凑的学生模型，从而提高了多模态命名实体识别和多模态关系抽取的效果。 |
| [^36] | [Bring Your Own Data! Self-Supervised Evaluation for Large Language Models.](http://arxiv.org/abs/2306.13651) | 本研究提出了一种自我监督评估框架，通过分析输入文本上的变换对LLMs的灵敏度或不变性，直接监控LLMs在实际数据上的行为。 |
| [^37] | [Data Augmentation Approaches for Source Code Models: A Survey.](http://arxiv.org/abs/2305.19915) | 本文对源代码的数据增强技术进行了全面的调查和综述，介绍了它们的分类法、优化策略和性能结果，并讨论了未来方向和研究挑战。 |
| [^38] | [ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task.](http://arxiv.org/abs/2304.14177) | 本研究比较了ChatGPT和现有模型在关键短语生成任务上的性能，并发现ChatGPT在所有测试数据集和环境中的表现均优于现有模型，适用于不同领域和文档长度的关键短语生成。 |
| [^39] | [Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models.](http://arxiv.org/abs/2304.07396) | 本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。 |
| [^40] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^41] | [Can AI-Generated Text be Reliably Detected?.](http://arxiv.org/abs/2303.11156) | 本研究通过实证和理论分析表明，在实际场景中，几种AI文本检测器不可靠。改写攻击可以破解多种检测器，包括水印方案、神经网络检测器和零样本分类器。即使是最好的检测器，随着语言模型的进一步提升，性能也会下降。因此，AI生成的文本的可靠检测仍然是一个挑战。 |
| [^42] | [Effectiveness of Data Augmentation for Parameter Efficient Tuning with Limited Data.](http://arxiv.org/abs/2303.02577) | 本文研究了在有限数据情况下，使用参数高效调整方法时，数据增强的有效性。研究表明，数据增强可以提升某些方法的性能，但效果因技术和任务而异，并且在使用较大模型和更难的任务时可能导致性能下降。 |
| [^43] | [Predicting Sentence-Level Factuality of News and Bias of Media Outlets.](http://arxiv.org/abs/2301.11850) | 本论文提出了一种针对整个媒体的细粒度可靠性分析方法，在手动制作的“FactNews”数据库上，通过 fine-tuning BERT 模型预测新闻报道的句子级别事实性和媒体倾向。此方法可应用于任何其他语言。 |
| [^44] | [MooseNet: A Trainable Metric for Synthesized Speech with a PLDA Module.](http://arxiv.org/abs/2301.07087) | 我们提出了一种可训练的语音度量学模型MooseNet，使用PLDA模块在SSL模型中进行嵌入层生成，能够准确预测听众的平均意见分数（MOS）。通过在低资源情况下对PLDA进行训练，我们证明了它相对于SSL模型微调的优越性。我们还通过选择适当的优化器和额外的训练目标改进了SSL模型的微调效果。经过PLDA模块微调的MooseNet在VoiceMOS Challenge数据集上表现出色，超越了SSL基线模型。 |
| [^45] | [Log-linear Guardedness and its Implications.](http://arxiv.org/abs/2210.10012) | 本研究介绍了对数线性保护性及其对下游分类器行为的影响。在二元情况下，下游对数线性模型无法恢复被删除的概念，但在某些情况下，可以通过构建多类对数线性模型间接恢复概念。这些结果揭示了线性删除方法的局限性，并强调了进一步研究的需求。 |
| [^46] | [The expected sum of edge lengths in planar linearizations of trees. Theory and applications.](http://arxiv.org/abs/2207.05564) | 本论文研究了在树的平面线性化中边长度的期望和，提出了一个计算平面排列的方法，并分析了平面排列与投影排列之间的关系。 |
| [^47] | [Language Models as Knowledge Embeddings.](http://arxiv.org/abs/2206.12617) | 该论文提出了一种使用语言模型来推导知识嵌入的方法LMKE，它旨在提高对丰富的长尾实体的表示能力并解决基于描述的先前方法的问题，实验结果表明该方法在多个基准数据集上实现了最先进的性能。 |
| [^48] | [On the Usefulness of Embeddings, Clusters and Strings for Text Generator Evaluation.](http://arxiv.org/abs/2205.16001) | 这篇论文讨论了语言生成器评估中的自动度量标准问题，以及目前存在的Mauve度量标准的局限性。当前的方法通过近似计算来衡量概率分布之间的差异，但在实践中并不是一个严格的近似。 |
| [^49] | ["That Is a Suspicious Reaction!": Interpreting Logits Variation to Detect NLP Adversarial Attacks.](http://arxiv.org/abs/2204.04636) | 这项工作提出了一个模型无关的对抗文本检测器，通过识别目标分类器的概率中的模式来改进对抗输入的识别性能，并具有较强的泛化能力。 |
| [^50] | [Did AI get more negative recently?.](http://arxiv.org/abs/2202.13610) | 本文通过对自然语言处理和机器学习领域的论文进行分类和分析，发现随着时间的推移，科学文章更倾向于积极的立场，但也存在一些持消极立场的论文。 |

# 详细

[^1]: 编程教育的生成AI：比较ChatGPT、GPT-4和人类导师的表现

    Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors. (arXiv:2306.17156v1 [cs.CY])

    [http://arxiv.org/abs/2306.17156](http://arxiv.org/abs/2306.17156)

    该论文系统评估了ChatGPT、GPT-4和人类导师在不同的编程教育场景中的表现，并发现GPT-4优于ChatGPT，接近于人类导师。

    

    生成AI和大型语言模型在提高计算机教育方面具有很大的潜力，通过为初级编程提供下一代教育技术。最近的研究已经研究了这些模型在与编程教育相关的不同场景中的应用；然而，这些研究由于多种原因而受限，因为它们通常考虑的是已经过时的模型或仅仅特定的场景。因此，缺乏一个系统的研究来对最先进的模型进行全面的编程教育场景基准测试。在我们的工作中，我们系统地评估了两个模型，ChatGPT（基于GPT-3.5）和GPT-4，并将其在各种场景下与人类导师的表现进行了比较。我们使用五个初级Python编程问题和来自在线平台的真实错误程序进行评估，并使用专家评注来评估性能。我们的结果表明，GPT-4明显优于ChatGPT（基于GPT-3.5），并且接近于人类导师。

    Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming. Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s). Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios. We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations. Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to hu
    
[^2]: LLaVAR:增强的视觉指令调整用于文本丰富的图像理解

    LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding. (arXiv:2306.17107v1 [cs.CV])

    [http://arxiv.org/abs/2306.17107](http://arxiv.org/abs/2306.17107)

    LLaVAR是一个增强的视觉指令调整模型，通过使用文本丰富的图像数据，它能够显著提升在文本为基础的视觉问答数据集上的准确率。

    

    指令调整可以发挥大型语言模型（LLM）与人类互动的出色能力。此外，最近的指令遵循数据集包括图像作为视觉输入，收集图像指令的响应。然而，视觉指令调整的模型不能很好地理解图像中的文本细节。本研究增强了当前的视觉指令调整流程，使用文本丰富的图像（如电影海报、图书封面等）。具体地，我们首先使用公开可用的OCR工具从LAION数据集的422K个文本丰富的图像上提取结果。此外，我们使用识别到的文本和图像标题来启动仅文本的GPT-4生成16K个对话，每个对话包含文本丰富的图像的问答对。通过将我们收集的数据与先前的多模态指令遵循数据组合，我们的模型LLaVAR在文本为基础的VQA数据集上显著提高了LLaVA模型的能力（准确率提高了20%）同时 achieving an accur

    Instruction tuning unlocks the superior capability of Large Language Models (LLM) to interact with humans. Furthermore, recent instruction-following datasets include images as visual inputs, collecting responses for image-based instructions. However, visual instruction-tuned models cannot comprehend textual details within images well. This work enhances the current visual instruction tuning pipeline with text-rich images (e.g., movie posters, book covers, etc.). Specifically, we first use publicly available OCR tools to collect results on 422K text-rich images from the LAION dataset. Moreover, we prompt text-only GPT-4 with recognized texts and image captions to generate 16K conversations, each containing question-answer pairs for text-rich images. By combining our collected data with previous multi-modal instruction-following data, our model, LLaVAR, substantially improves the LLaVA model's capability on text-based VQA datasets (up to 20% accuracy improvement) while achieving an accur
    
[^3]: LyricWhiz: 通过向ChatGPT耳语进行鲁棒的多语言零射击歌词转录

    LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT. (arXiv:2306.17103v1 [cs.CL])

    [http://arxiv.org/abs/2306.17103](http://arxiv.org/abs/2306.17103)

    LyricWhiz是一种鲁棒、多语言、零射击的自动歌词转录方法，通过使用Whisper作为"耳朵"和GPT-4作为"大脑"，它在各种数据集上实现了最先进的性能，同时还实现了在多种语言中进行歌词转录的能力，并创建了第一个大规模多语言歌词转录数据集。

    

    我们介绍了一种名为LyricWhiz的鲁棒、多语言、零射击的自动歌词转录方法，该方法在各种歌词转录数据集上实现了最先进的性能，即使在具有挑战性的流派如摇滚和金属中也是如此。我们的全新、无需训练的方法利用了Whisper，一种弱监督的鲁棒语音识别模型，以及GPT-4，当今最性能卓越的基于聊天的大型语言模型。在该方法中，Whisper充当“耳朵”，负责转录语音，而GPT-4则作为“大脑”，作为一种具有强大性能的上下文输出选择和校正的注释器。我们的实验结果表明，与现有方法相比，LyricWhiz在英语中显著降低了词错误率，并且可以有效地转录多种语言的歌词。此外，我们使用LyricWhiz创建了第一个具有CC-BY-NC-SA版权许可的公开可用的大规模多语言歌词转录数据集，基于MTG-Jamendo，并提供了h

    We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal. Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model. In the proposed method, Whisper functions as the "ear" by transcribing the audio, while GPT-4 serves as the "brain," acting as an annotator with a strong performance for contextualized output selection and correction. Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a h
    
[^4]: 基于大型语言模型的概念导向深度学习

    Concept-Oriented Deep Learning with Large Language Models. (arXiv:2306.17089v1 [cs.LG])

    [http://arxiv.org/abs/2306.17089](http://arxiv.org/abs/2306.17089)

    本文讨论了大型语言模型在概念导向深度学习中的应用，包括从文本和图像中提取概念和概念图。同时也探讨了多模态语言模型在表达人类知识方面的优势。

    

    大型语言模型（LLMs）已成功应用于许多自然语言任务和应用，包括文本生成和人工智能聊天机器人。它们也是概念导向深度学习（CODL）的一种有前景的新技术。然而，前提是LLMs要理解概念并确保概念一致性。本文讨论了这些问题，以及LLMs在CODL中的主要用途，包括从文本中提取概念、从文本中提取概念图和概念学习。人类知识包括符号（概念性）知识和具体（感性）知识。而仅文本的LLMs只能表示符号（概念性）知识。另一方面，多模态LLMs能够表示人类知识的完整范围（概念性和感性）。我们讨论了视觉-语言LLMs中的概念理解，这是最重要的多模态LLMs，并介绍了它们在CODL中的主要用途，包括从图像中提取概念、从图像中提取概念图。

    Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image
    
[^5]: 基于加权CapsuleNet网络的阿拉伯语和波斯语多领域情感分析方法

    Presenting an approach based on weighted CapsuleNet networks for Arabic and Persian multi-domain sentiment analysis. (arXiv:2306.17068v1 [cs.CL])

    [http://arxiv.org/abs/2306.17068](http://arxiv.org/abs/2306.17068)

    本文提出了一种基于加权胶囊网络的阿拉伯语和波斯语多领域情感分析方法，通过训练单独的胶囊网络并使用加权度量来实现情感分类，具有较好的准确性和适应性。

    

    情感分类是自然语言处理中的基本任务，对自由文本进行正面、负面或中性的分类。然而，情感分类模型高度依赖于领域，分类器在一个领域中可能具有合理的准确性，但在另一个领域中由于词语的语义多重性而准确率较低。本文提出了一种新的波斯语/阿拉伯语多领域情感分析方法，使用累积加权胶囊网络的方法。加权胶囊集合由为每个领域训练的单独的胶囊网络和称为领域所属度（DBD）的加权度量组成。这个度量由TF和IDF组成，计算每个文档对于每个领域的依赖关系，然后乘以每个胶囊创建的可能输出。最终，这些乘积的总和是最终输出的标签，并用于确定极性。

    Sentiment classification is a fundamental task in natural language processing, assigning one of the three classes, positive, negative, or neutral, to free texts. However, sentiment classification models are highly domain dependent; the classifier may perform classification with reasonable accuracy in one domain but not in another due to the Semantic multiplicity of words getting poor accuracy. This article presents a new Persian/Arabic multi-domain sentiment analysis method using the cumulative weighted capsule networks approach. Weighted capsule ensemble consists of training separate capsule networks for each domain and a weighting measure called domain belonging degree (DBD). This criterion consists of TF and IDF, which calculates the dependency of each document for each domain separately; this value is multiplied by the possible output that each capsule creates. In the end, the sum of these multiplications is the title of the final output, and is used to determine the polarity. And 
    
[^6]: The mapKurator系统：从历史地图中提取和链接文本的完整管道

    The mapKurator System: A Complete Pipeline for Extracting and Linking Text from Historical Maps. (arXiv:2306.17059v1 [cs.AI])

    [http://arxiv.org/abs/2306.17059](http://arxiv.org/abs/2306.17059)

    该论文介绍了一种名为mapKurator的系统，能完整地从历史地图中提取和链接文本信息。该系统解决了传统方法中对位置相关词语的忽略问题，并利用主题建模方法考虑更广的主题范围，能够识别文档的空间焦点。

    

    文档具有空间焦点和有价值的地方特征。例如，房地产或旅行博客中的列表描述包含有关特定地区社区的信息。这些信息对于描述人类如何感知他们的环境是有价值的。然而，利用这些信息的第一步是识别文档的空间焦点（例如，城市）。传统方法用于识别文档的空间焦点依赖于从文档中检测和消歧化地名。这种方法需要一个包含位置短语和临时规则的词汇集，这些规则忽略了与位置相关的重要词语。最近，使用大型语言模型的主题建模方法通常考虑几个广度的主题。相比之下，文档的空间焦点可以是一个国家、一个城市，甚至是一个社区，这些范围比这些方法考虑的主题数要大得多。

    Documents hold spatial focus and valuable locality characteristics. For example, descriptions of listings in real estate or travel blogs contain information about specific local neighborhoods. This information is valuable to characterize how humans perceive their environment. However, the first step to making use of this information is to identify the spatial focus (e.g., a city) of a document. Traditional approaches for identifying the spatial focus of a document rely on detecting and disambiguating toponyms from the document. This approach requires a vocabulary set of location phrases and ad-hoc rules, which ignore important words related to location. Recent topic modeling approaches using large language models often consider a few topics, each with broad coverage. In contrast, the spatial focus of a document can be a country, a city, or even a neighborhood, which together, is much larger than the number of topics considered in these approaches. Additionally, topic modeling methods a
    
[^7]: 面向网络安全法律语言的语法标注

    Towards Grammatical Tagging for the Legal Language of Cybersecurity. (arXiv:2306.17042v1 [cs.CL])

    [http://arxiv.org/abs/2306.17042](http://arxiv.org/abs/2306.17042)

    本研究提出了一种面向网络安全法律语言的语法标注方法，通过使用先进的自然语言处理工具和手动分析，实现了从法律文件中提取关键词性的自动化。该方法可以适用于任何法律语言，并具有广泛的适用性。

    

    法律语言可以理解为律师职业中通常使用的语言，可以是口语或书面形式。最近关于网络安全的立法显然使用了书面的法律语言，因此继承了其解释复杂性，包括案例和细节的丰富性。本文面对的挑战是对网络安全法律语言进行基本解释，即从与网络安全有关的法律文件中提取基本词性（POS）。我们的方法论克服了这个挑战，它利用了最先进的开源自然语言处理（NLP）工具以及手动分析来验证工具的结果。结果，这个方法是自动化的，可以适用于任何法律语言，只需对预处理步骤进行轻微调整。

    Legal language can be understood as the language typically used by those engaged in the legal profession and, as such, it may come both in spoken or written form. Recent legislation on cybersecurity obviously uses legal language in writing, thus inheriting all its interpretative complications due to the typical abundance of cases and sub-cases as well as to the general richness in detail. This paper faces the challenge of the essential interpretation of the legal language of cybersecurity, namely of the extraction of the essential Parts of Speech (POS) from the legal documents concerning cybersecurity. The challenge is overcome by our methodology for POS tagging of legal language. It leverages state-of-the-art open-source tools for Natural Language Processing (NLP) as well as manual analysis to validate the outcomes of the tools. As a result, the methodology is automated and, arguably, general for any legal language following minor tailoring of the preprocessing step. It is demonstrate
    
[^8]: 探索和利用高阶图结构进行稀疏知识图谱补全

    Exploring & Exploiting High-Order Graph Structure for Sparse Knowledge Graph Completion. (arXiv:2306.17034v1 [cs.AI])

    [http://arxiv.org/abs/2306.17034](http://arxiv.org/abs/2306.17034)

    本论文提出了一种新的框架 LR-GCN，用于在稀疏知识图谱中进行补全。该框架能够探索高阶图结构，自动捕捉实体之间的远程依赖关系，并通过逻辑推理提炼知识，从而有效解决稀疏性带来的挑战。

    

    稀疏知识图谱场景对之前的知识图谱补全方法提出了挑战，即随着图的稀疏性增加，补全性能迅速下降。由于稀疏知识图谱在实际应用中广泛存在，这个问题也被加剧。为了缓解这个挑战，我们提出了一种新颖的框架，LR-GCN，能够自动捕捉实体之间有价值的远程依赖关系，以补充不足的结构特征并提炼逻辑推理知识用于稀疏图谱补全。所提出的方法包括两个主要组件：基于GNN的预测器和推理路径提取器。推理路径提取器探索高阶图结构，如推理路径，并将其编码为富语义边，明确地将远程依赖关系组合到预测器中。此步骤还在稀疏问题中起着重要作用，有效缓解了稀疏问题。此外，路径提取器还可以帮助密化知识图谱。

    Sparse knowledge graph (KG) scenarios pose a challenge for previous Knowledge Graph Completion (KGC) methods, that is, the completion performance decreases rapidly with the increase of graph sparsity. This problem is also exacerbated because of the widespread existence of sparse KGs in practical applications. To alleviate this challenge, we present a novel framework, LR-GCN, that is able to automatically capture valuable long-range dependency among entities to supplement insufficient structure features and distill logical reasoning knowledge for sparse KGC. The proposed approach comprises two main components: a GNN-based predictor and a reasoning path distiller. The reasoning path distiller explores high-order graph structures such as reasoning paths and encodes them as rich-semantic edges, explicitly compositing long-range dependencies into the predictor. This step also plays an essential role in densifying KGs, effectively alleviating the sparse issue. Furthermore, the path distiller
    
[^9]: 使用社交媒体上的判决文件对犯罪类型进行分类

    Classifying Crime Types using Judgment Documents from Social Media. (arXiv:2306.17020v1 [cs.CL])

    [http://arxiv.org/abs/2306.17020](http://arxiv.org/abs/2306.17020)

    本文提出了一种通过NLP处理方法的新的训练模型，通过生成新样本来平衡不均匀的数据集分布的缺陷，并使用预训练和微调来赋予模型对小数据集的良好泛化能力。

    

    基于犯罪行为事实来确定犯罪类型的任务在社会科学中变得非常重要和有意义。但该领域面临的问题是，由于犯罪本身的性质，数据样本本身分布不均匀。同时，司法领域的数据集少有公开可用，无法产生用于直接训练的大型数据集。本文提出了一种通过NLP处理方法解决该问题的新的训练模型。我们首先提出了一个犯罪事实数据预处理模块(CFDPM)，通过生成新样本来平衡不均匀的数据集分布的缺陷。然后，我们使用一个大型开源数据集(CAIL-big)作为我们的预训练数据集，使用我们自己收集的一个小数据集进行微调，赋予模型对不熟悉的小数据集具有良好的泛化能力。同时，我们使用改进的Bert模型和动态遮蔽来改进模型。实验证明

    The task of determining crime types based on criminal behavior facts has become a very important and meaningful task in social science. But the problem facing the field now is that the data samples themselves are unevenly distributed, due to the nature of the crime itself. At the same time, data sets in the judicial field are less publicly available, and it is not practical to produce large data sets for direct training. This article proposes a new training model to solve this problem through NLP processing methods. We first propose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the defects of uneven data set distribution by generating new samples. Then we use a large open source dataset (CAIL-big) as our pretraining dataset and a small dataset collected by ourselves for Fine-tuning, giving it good generalization ability to unfamiliar small datasets. At the same time, we use the improved Bert model with dynamic masking to improve the model. Experiments show that the 
    
[^10]: 准确对齐的高质量自动配音：通过自监督离散语音单元实现监督

    High-Quality Automatic Voice Over with Accurate Alignment: Supervision through Self-Supervised Discrete Speech Units. (arXiv:2306.17005v1 [eess.AS])

    [http://arxiv.org/abs/2306.17005](http://arxiv.org/abs/2306.17005)

    本文提出了一种新的自动配音方法，通过自监督离散语音单元预测的学习目标，实现了更准确的对齐学习和更高质量的语音合成，优于传统方法的表现。

    

    自动配音（AVO）的目标是根据静音视频的文本脚本生成与之同步的语音。最近的AVO框架建立在文本到语音合成（TTS）之上，取得了令人印象深刻的结果。然而，当前AVO的学习目标是声学特征重建，为跨模态对齐学习带来了间接监督，从而限制了同步性能和合成语音质量。为此，我们提出了一种新颖的AVO方法，利用自监督离散语音单元预测的学习目标，不仅为对齐学习提供了更直接的监督，还减轻了文本-视频上下文与声学特征之间的不匹配。实验结果表明，我们提出的方法通过在客观和主观评估中优于基准方法，实现了卓越的嘴唇-语音同步和高质量的语音。代码和语音样本已公开提供。

    The goal of Automatic Voice Over (AVO) is to generate speech in sync with a silent video given its text script. Recent AVO frameworks built upon text-to-speech synthesis (TTS) have shown impressive results. However, the current AVO learning objective of acoustic feature reconstruction brings in indirect supervision for inter-modal alignment learning, thus limiting the synchronization performance and synthetic speech quality. To this end, we propose a novel AVO method leveraging the learning objective of self-supervised discrete speech unit prediction, which not only provides more direct supervision for the alignment learning, but also alleviates the mismatch between the text-video context and acoustic features. Experimental results show that our proposed method achieves remarkable lip-speech synchronization and high speech quality by outperforming baselines in both objective and subjective evaluations. Code and speech samples are publicly available.
    
[^11]: MEMD-ABSA：面向方面情感分析的多要素多领域数据集

    MEMD-ABSA: A Multi-Element Multi-Domain Dataset for Aspect-Based Sentiment Analysis. (arXiv:2306.16956v1 [cs.CL])

    [http://arxiv.org/abs/2306.16956](http://arxiv.org/abs/2306.16956)

    这个论文提出了一个大规模的多要素多领域数据集（MEMD-ABSA），用于面向方面情感分析的研究。数据集涵盖了五个领域的四个要素，包括近2万个评论句子和3万个带有显式和隐式方面和观点的四元组。研究结果表明，开放领域ABSA以及挖掘隐含的方面和观点仍然是待解决的挑战。

    

    面向方面情感分析是情感挖掘领域长期以来的研究兴趣，近年来，研究人员逐渐将焦点从简单的ABSA子任务转向端到端的多要素ABSA任务。然而，目前研究中使用的数据集局限于特定任务的个别要素，通常关注于领域内设置，忽略了隐含的方面和观点，并且数据规模较小。为了解决这些问题，我们提出了一个大规模的多要素多领域数据集(MEMD)，涵盖了五个领域的四个要素，包括近2万个评论句子和3万个带有显式和隐式方面和观点的四元组，可用于ABSA研究。同时，我们在开放领域设置下评估了生成式和非生成式基线模型在多个ABSA子任务上的表现，结果表明，开放领域ABSA以及挖掘隐含的方面和观点仍然是待解决的挑战。

    Aspect-based sentiment analysis is a long-standing research interest in the field of opinion mining, and in recent years, researchers have gradually shifted their focus from simple ABSA subtasks to end-to-end multi-element ABSA tasks. However, the datasets currently used in the research are limited to individual elements of specific tasks, usually focusing on in-domain settings, ignoring implicit aspects and opinions, and with a small data scale. To address these issues, we propose a large-scale Multi-Element Multi-Domain dataset (MEMD) that covers the four elements across five domains, including nearly 20,000 review sentences and 30,000 quadruples annotated with explicit and implicit aspects and opinions for ABSA research. Meanwhile, we evaluate generative and non-generative baselines on multiple ABSA subtasks under the open domain setting, and the results show that open domain ABSA as well as mining implicit aspects and opinions remain ongoing challenges to be addressed. The datasets
    
[^12]: 使用基于图的神经解码器预测音乐层次结构

    Predicting Music Hierarchies with a Graph-Based Neural Decoder. (arXiv:2306.16955v1 [cs.SD])

    [http://arxiv.org/abs/2306.16955](http://arxiv.org/abs/2306.16955)

    本文提出了一个基于图的神经解码器，用于预测音乐的层次结构。通过使用转换器编码器和分类器，该系统能够将音乐序列解析为依赖树，并在多个音乐特征和顺序上下文信息的基础上提供部分结果和更好的性能。

    

    本文描述了一个数据驱动的框架，将音乐序列解析为依赖树，这是音乐认知研究和音乐分析中使用的分层结构。解析包括两个步骤。首先，将输入序列通过转换器编码器传递，以丰富上下文信息。然后，分类器筛选出所有可能的依赖弧的图，生成依赖树。该系统的一个主要优点是可以轻松集成到现代深度学习流水线中。此外，由于它不依赖于任何特定的符号语法，它可以同时考虑多个音乐特征，利用顺序上下文信息，并针对嘈杂的输入产生部分结果。我们将我们的方法测试在两个音乐树数据集上 - 单声部音符序列的时间跨度树和爵士和弦序列的和声树上，并展示了我们的方法优于先前的方法。

    This paper describes a data-driven framework to parse musical sequences into dependency trees, which are hierarchical structures used in music cognition research and music analysis. The parsing involves two steps. First, the input sequence is passed through a transformer encoder to enrich it with contextual information. Then, a classifier filters the graph of all possible dependency arcs to produce the dependency tree. One major benefit of this system is that it can be easily integrated into modern deep-learning pipelines. Moreover, since it does not rely on any particular symbolic grammar, it can consider multiple musical features simultaneously, make use of sequential context information, and produce partial results for noisy inputs. We test our approach on two datasets of musical trees -- time-span trees of monophonic note sequences and harmonic trees of jazz chord sequences -- and show that our approach outperforms previous methods.
    
[^13]: UMASS_BioNLP参加MEDIQA-Chat 2023：LLMs能否生成高质量的医生-患者基于笔记的对话？

    UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?. (arXiv:2306.16931v1 [cs.CL])

    [http://arxiv.org/abs/2306.16931](http://arxiv.org/abs/2306.16931)

    本文介绍了UMASS_BioNLP团队在MEDIQA-Chat 2023共享任务中的参与，提出了一种新型LLMs协作系统用于生成高质量对话数据集，并与ChatGPT和GPT-4进行了比较分析。

    

    本文介绍了UMASS_BioNLP团队参与MEDIQA-Chat 2023共享任务的Task-A和Task-C。我们特别关注Task-C，并提出了一种名为医生-患者循环的新型LLMs协作系统，用于生成高质量的对话数据集。实验证明，我们的方法在ROUGE、医疗概念召回率、BLEU和Self-BLEU等自动评估指标下表现合理。此外，我们还对我们提出的方法与ChatGPT和GPT-4进行了比较分析，探讨了利用协作LLMs生成高质量数据集的潜力。

    This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C. We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets. The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU. Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4. This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets.
    
[^14]: 利用跨话语上下文进行语音识别解码

    Leveraging Cross-Utterance Context For ASR Decoding. (arXiv:2306.16903v1 [cs.CL])

    [http://arxiv.org/abs/2306.16903](http://arxiv.org/abs/2306.16903)

    本文研究了如何利用跨话语上下文来提升语音识别系统的解码性能，实验结果表明，通过波束搜索和长上下文转换器LMs可以更好地利用跨话语上下文，实现了较低的识别误差。

    

    尽管外部语言模型（LMs）通常被用于自动语音识别系统的解码阶段，但这些模型通常只使用有限的上下文信息。研究表明，在第二次重新评分时，跨话语信息对提升性能有益，然而这仅基于第一次语言模型可用的局部信息来限制假设空间。本文研究了通过波束搜索将长上下文转换器LMs应用于声学模型的跨话语解码，并与n-best重新评分的结果进行比较。结果表明，波束搜索可以更好地利用跨话语上下文。在长格式数据集AMI上进行评估时，与单话语设置相比，dev和test集的绝对减少分别为0.7％和0.3％，包括多达500个标记的先前上下文时还有改进。Tedlium-1也进行了评估，改进幅度约为0.1％。

    While external language models (LMs) are often incorporated into the decoding stage of automated speech recognition systems, these models usually operate with limited context. Cross utterance information has been shown to be beneficial during second pass re-scoring, however this limits the hypothesis space based on the local information available to the first pass LM. In this work, we investigate the incorporation of long-context transformer LMs for cross-utterance decoding of acoustic models via beam search, and compare against results from n-best rescoring. Results demonstrate that beam search allows for an improved use of cross-utterance context. When evaluating on the long-format dataset AMI, results show a 0.7\% and 0.3\% absolute reduction on dev and test sets compared to the single-utterance setting, with improvements when including up to 500 tokens of prior context. Evaluations are also provided for Tedlium-1 with less significant improvements of around 0.1\% absolute.
    
[^15]: 调查计算需求量大的自然语言处理研究中的不平等和担忧

    Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research. (arXiv:2306.16900v1 [cs.CL])

    [http://arxiv.org/abs/2306.16900](http://arxiv.org/abs/2306.16900)

    这项研究调查了自然语言处理领域计算需求量大的研究中存在的不平等和担忧，通过对NLP社区的312位参与者进行调查，发现了在资历、学术界和工业界等方面存在的（不）平等现象，并提出了相应的缓解建议。

    

    自然语言处理领域的许多最新进展源于开发和使用具有数十亿参数的大规模预训练语言模型（PLM）。大模型的规模使得计算成本成为训练和评估这些模型的主要限制因素之一；并且对于研究PLMs的可持续性、可重复性和包容性引发了严重的担忧。这些担忧往往基于个人经验和观察。然而，迄今为止还没有进行大规模调查来调查这些担忧。在这项工作中，我们首次尝试量化与环境影响、公平性和同行评审影响相关的这些担忧。通过对NLP社区的312位参与者进行调查，我们捕捉到不同群体内部和之间的现有（不）平等现象，包括资历、学术界和工业界，以及它们对同行评审过程的影响。对于每个主题，我们提供了分析结果，并提出了相应的缓解建议。

    Many recent improvements in NLP stem from the development and use of large pre-trained language models (PLMs) with billions of parameters. Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs. These concerns are often based on personal experiences and observations. However, there had not been any large-scale surveys that investigate them. In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing. By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process. For each topic, we provide an analysis and devise recommendations to mitigate found 
    
[^16]: Tokenization和无噪声通道

    Tokenization and the Noiseless Channel. (arXiv:2306.16842v1 [cs.CL])

    [http://arxiv.org/abs/2306.16842](http://arxiv.org/abs/2306.16842)

    优秀的分词器能够实现较高的通道使用效率，并且R\'enyi熵在机器翻译中与\textsc{Bleu}有很强的相关性。

    

    子词分词是许多自然语言处理流程的关键组成部分。然而，我们对于为什么某些分词器和超参数组合会比其他组合在下游模型性能上表现更好还知之甚少。我们提出优秀的分词器会导致\emph{效率}较高的通道使用，其中通道是指将某些输入传递给模型的方式，而效率可以用信息论术语中的Shannon熵与令牌分布的最大熵之比来量化。然而，根据Shannon熵进行的最优编码将把低频令牌赋予极长的编码，把高频令牌赋予极短的编码。另一方面，用R\'enyi熵来定义效率则会惩罚具有极高或极低频令牌的分布。在机器翻译中，我们发现在多个分词器中，当$\alpha = 2.5$时，R\'enyi熵与\textsc{Bleu}有很强的相关性（$0.78$），而相比之下，Shannon熵与\textsc{Bleu}的相关性仅为$-0.32$。

    Subword tokenization is a key part of many NLP pipelines. However, little is known about why some tokenizer and hyperparameter combinations lead to better downstream model performance than others. We propose that good tokenizers lead to \emph{efficient} channel usage, where the channel is the means by which some input is conveyed to the model and efficiency can be quantified in information-theoretic terms as the ratio of the Shannon entropy to the maximum possible entropy of the token distribution. Yet, an optimal encoding according to Shannon entropy assigns extremely long codes to low-frequency tokens and very short codes to high-frequency tokens. Defining efficiency in terms of R\'enyi entropy, on the other hand, penalizes distributions with either very high or very low-frequency tokens. In machine translation, we find that across multiple tokenizers, the R\'enyi entropy with $\alpha = 2.5$ has a very strong correlation with \textsc{Bleu}: $0.78$ in comparison to just $-0.32$ for co
    
[^17]: Byte-Pair编码的形式化视角

    A Formal Perspective on Byte-Pair Encoding. (arXiv:2306.16837v1 [cs.CL])

    [http://arxiv.org/abs/2306.16837](http://arxiv.org/abs/2306.16837)

    这篇论文从形式化的角度对Byte-Pair编码进行了研究，将其形式化为组合优化问题，证明了迭代贪婪版本是对最优合并序列的近似解，并优化了算法的运行时间复杂度。

    

    Byte-Pair编码（BPE）是一种用于自然语言处理中的数据标记算法，尽管最初是作为一种压缩方法而设计的。BPE表面上看起来是一种贪婪算法，但是BPE寻求解决的底层优化问题尚未明确。我们将BPE形式化为组合优化问题。通过子模函数，我们证明了迭代贪婪版本是一个对于最优合并序列的$\frac{1}{{\sigma(\boldsymbol{\mu}^\star)}}(1-e^{-{\sigma(\boldsymbol{\mu}^\star)}})$-近似解，其中${\sigma(\boldsymbol{\mu}^\star)}$是相对于最优合并序列$\boldsymbol{\mu}^\star$的总向后曲率。经验证近似解的下界约为$\approx 0.37$。我们提供了一个更快的BPE实现，将运行时间复杂度从$\mathcal{O}\left(N M\right)$优化为$\mathcal{O}\left(N \log M\right)$，其中$N$是序列长度，$M$是合并次数。最后，我们优化了暴力搜索法。

    Byte-Pair Encoding (BPE) is a popular algorithm used for tokenizing data in NLP, despite being devised initially as a compression method. BPE appears to be a greedy algorithm at face value, but the underlying optimization problem that BPE seeks to solve has not yet been laid down. We formalize BPE as a combinatorial optimization problem. Via submodular functions, we prove that the iterative greedy version is a $\frac{1}{{\sigma(\boldsymbol{\mu}^\star)}}(1-e^{-{\sigma(\boldsymbol{\mu}^\star)}})$-approximation of an optimal merge sequence, where ${\sigma(\boldsymbol{\mu}^\star)}$ is the total backward curvature with respect to the optimal merge sequence $\boldsymbol{\mu}^\star$. Empirically the lower bound of the approximation is $\approx 0.37$.  We provide a faster implementation of BPE which improves the runtime complexity from $\mathcal{O}\left(N M\right)$ to $\mathcal{O}\left(N \log M\right)$, where $N$ is the sequence length and $M$ is the merge count. Finally, we optimize the brute
    
[^18]: CLIPAG: 走向无需生成器的文本到图像生成

    CLIPAG: Towards Generator-Free Text-to-Image Generation. (arXiv:2306.16805v1 [cs.CV])

    [http://arxiv.org/abs/2306.16805](http://arxiv.org/abs/2306.16805)

    本文将感知对齐梯度（PAG）的研究扩展到视觉-语言架构，并通过对 CLIP 进行鲁棒性调整，展示了在视觉-语言生成任务中集成 CLIPAG 可以实现显著改进，并实现了无生成器的文本到图像生成。

    

    感知对齐梯度 (Perceptually Aligned Gradients, PAG) 是在健壮的图像分类模型中观察到的一种有趣属性，其中它们的输入渐变与人类感知对齐并具有语义意义。虽然这一现象引起了显着的研究关注，但仅仅在单模态纯视觉架构的背景下进行了研究。在本研究中，我们将 PAG 的研究扩展到视觉-语言架构，这是多样化的图像-文本任务和应用的基础。通过对 CLIP 进行对抗性鲁棒微调，我们证明了鲁棒的视觉-语言模型相对于其基准模型表现出了 PAG。这项工作展示了 CLIPAG 在几种视觉-语言生成任务中的优势。值得注意的是，我们展示了无缝集成 CLIPAG 的 "即插即用" 方式显著改进了视觉-语言生成应用。此外，利用其 PAG 属性，CLIPAG 实现了无生成器的文本到图像生成。

    Perceptually Aligned Gradients (PAG) refer to an intriguing property observed in robust image classification models, wherein their input gradients align with human perception and pose semantic meanings. While this phenomenon has gained significant research attention, it was solely studied in the context of unimodal vision-only architectures. In this work, we extend the study of PAG to Vision-Language architectures, which form the foundations for diverse image-text tasks and applications. Through an adversarial robustification finetuning of CLIP, we demonstrate that robust Vision-Language models exhibit PAG in contrast to their vanilla counterparts. This work reveals the merits of CLIP with PAG (CLIPAG) in several vision-language generative tasks. Notably, we show that seamlessly integrating CLIPAG in a "plug-n-play" manner leads to substantial improvements in vision-language generative applications. Furthermore, leveraging its PAG property, CLIPAG enables text-to-image generation witho
    
[^19]: 测评大型语言模型在条件生成中的能力

    Benchmarking Large Language Model Capabilities for Conditional Generation. (arXiv:2306.16793v1 [cs.CL])

    [http://arxiv.org/abs/2306.16793](http://arxiv.org/abs/2306.16793)

    本文测评了大型语言模型在条件生成中的能力，并讨论了其生成质量的评估和与真实世界应用场景的关联性。

    

    预训练的大型语言模型 (PLMs) 是自然语言处理中大多数新发展的基础。它们将该领域从应用特定的模型流程转变为一个适应各种任务的单一模型。与分类或回归不同，自回归 PLMs（例如GPT-3或PaLM）以及少样本学习等技术将输出方式进一步转变为生成。尽管它们被广泛使用，但在引入这些模型时很少对语言模型的生成质量进行评估。此外，目前还不清楚现有的生成任务——尽管可以用于比较系统——如何与人们采用它们的真实世界应用场景相关联。在这项工作中，我们讨论如何将现有的应用特定生成基准适应PLMs，并对PLMs在自然语言生成任务中的限制和能力进行了深入的经验研究，包括规模、架构等维度。

    Pre-trained large language models (PLMs) underlie most new developments in natural language processing. They have shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks. Autoregressive PLMs like GPT-3 or PaLM, alongside techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression. Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced. Additionally, it is unclear how existing generation tasks--while they can be used to compare systems at a high level--relate to the real world use cases for which people have been adopting them. In this work, we discuss how to adapt existing application-specific generation benchmarks to PLMs and provide an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, archite
    
[^20]: 停止预训练：将视觉语言模型适应于未见过的语言

    Stop Pre-Training: Adapt Visual-Language Models to Unseen Languages. (arXiv:2306.16774v1 [cs.CL])

    [http://arxiv.org/abs/2306.16774](http://arxiv.org/abs/2306.16774)

    这项研究提出了一种利用多语言预训练语言模型将视觉语言模型适应于未见语言的方法，通过跨语言的上下文化词元嵌入对齐技术，无需图像输入和目标语言数据，取得了在图像-文本检索、视觉蕴涵和自然语言视觉推理等任务上的良好结果。

    

    视觉语言预训练(VLP)已经提高了许多视觉语言任务的性能，比如图像文本检索、视觉蕴涵和视觉推理。预训练主要利用英语的词汇数据库和图像查询。先前的研究表明，在零射未见语言中，英语的预训练效果不佳。然而，多语言预训练语言模型(MPLM)在各种单模态语言任务中表现出色。本文提出了一种简单而有效的方法，利用MPLM将VLP适应于未见语言。我们利用跨语言上下文化的词元嵌入对齐方法来训练非英语语言的文本编码器。我们的方法不需要图像输入，主要使用机器翻译，消除了对目标语言数据的需求。我们在三个不同的任务(图像-文本检索、视觉蕴涵和自然语言视觉推理)上进行了评估，结果表明此方法

    Vision-Language Pre-training (VLP) has advanced the performance of many vision-language tasks, such as image-text retrieval, visual entailment, and visual reasoning. The pre-training mostly utilizes lexical databases and image queries in English. Previous work has demonstrated that the pre-training in English does not transfer well to other languages in a zero-shot setting. However, multilingual pre-trained language models (MPLM) have excelled at a variety of single-modal language tasks. In this paper, we propose a simple yet efficient approach to adapt VLP to unseen languages using MPLM. We utilize a cross-lingual contextualized token embeddings alignment approach to train text encoders for non-English languages. Our approach does not require image input and primarily uses machine translation, eliminating the need for target language data. Our evaluation across three distinct tasks (image-text retrieval, visual entailment, and natural language visual reasoning) demonstrates that this 
    
[^21]: DialoGPS: 在连续语义空间中对话路径采样用于多轮对话的数据增强

    DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations. (arXiv:2306.16770v1 [cs.CL])

    [http://arxiv.org/abs/2306.16770](http://arxiv.org/abs/2306.16770)

    DialoGPS是第一个在连续语义空间中进行对话路径采样的多对多增强方法，用于多轮对话的数据增强任务。

    

    在开放领域对话生成任务中，大多数数据集中的上下文和回复是一对一的映射，违反了重要的多对多特性：上下文有多种回复，回复回答多个上下文。缺乏这样的模式，模型很难泛化并倾向于安全回复。已经有许多尝试以一对多的角度处理多轮对话或以多对多的角度处理单轮对话，但对于多对多的多轮对话的增强仍然存在挑战。在本文中，我们提出了DialoGPS方法，它是第一个用于多轮对话的多对多增强方法。具体而言，我们将对话映射到我们的扩展布朗桥（Brownian Bridge），一个特殊的高斯过程。我们采样潜变量以形成连续空间中的连贯对话路径。

    In open-domain dialogue generation tasks, contexts and responses in most datasets are one-to-one mapped, violating an important many-to-many characteristic: a context leads to various responses, and a response answers multiple contexts. Without such patterns, models poorly generalize and prefer responding safely. Many attempts have been made in either multi-turn settings from a one-to-many perspective or in a many-to-many perspective but limited to single-turn settings. The major challenge to many-to-many augment multi-turn dialogues is that discretely replacing each turn with semantic similarity breaks fragile context coherence. In this paper, we propose DialoGue Path Sampling (DialoGPS) method in continuous semantic space, the first many-to-many augmentation method for multi-turn dialogues. Specifically, we map a dialogue to our extended Brownian Bridge, a special Gaussian process. We sample latent variables to form coherent dialogue paths in the continuous space. A dialogue path cor
    
[^22]: 文本、表格和图像的统一语言表示在问答中的应用

    Unified Language Representation for Question Answering over Text, Tables, and Images. (arXiv:2306.16762v1 [cs.CL])

    [http://arxiv.org/abs/2306.16762](http://arxiv.org/abs/2306.16762)

    本文提出了一种新的方法来回答复杂问题，即将图像和表格转化为统一的语言表示，通过检索、排序和生成三个步骤解决文本问答问题。实验证明，这种方法在两个数据集上表现优于所有现有方法，并在WebQA榜单上取得了最佳表现。

    

    在试图回答复杂问题时，人们经常依赖于多种信息源，如视觉、文本和表格数据。之前的方法主要集中在设计多模态空间的输入特征或模型结构，这对于跨模态推理或数据高效训练来说是不灵活的。本文提出了一种新的范式，将图像和表格转化为统一的语言表示，从而将任务简化为一个更简单的文本问答问题，可以使用三个步骤解决：检索、排序和生成，所有这些都在语言空间内进行。这个想法利用了预训练语言模型的能力，并在一个名为Solar的框架中实现。我们的实验结果显示，Solar在两个数据集MultimodalQA和MMCoQA上相对于所有现有方法的指标提高了10.6-32.3个百分点。此外，Solar在WebQA榜单上取得了最佳表现。

    When trying to answer complex questions, people often rely on multiple sources of information, such as visual, textual, and tabular data. Previous approaches to this problem have focused on designing input features or model structure in the multi-modal space, which is inflexible for cross-modal reasoning or data-efficient training. In this paper, we call for an alternative paradigm, which transforms the images and tables into unified language representations, so that we can simplify the task into a simpler textual QA problem that can be solved using three steps: retrieval, ranking, and generation, all within a language space. This idea takes advantage of the power of pre-trained language models and is implemented in a framework called Solar. Our experimental results show that Solar outperforms all existing methods by 10.6-32.3 pts on two datasets, MultimodalQA and MMCoQA, across ten different metrics. Additionally, Solar achieves the best performance on the WebQA leaderboard
    
[^23]: 评估文本蕴涵模型对改写句的鲁棒性

    Evaluating Paraphrastic Robustness in Textual Entailment Models. (arXiv:2306.16722v1 [cs.CL])

    [http://arxiv.org/abs/2306.16722](http://arxiv.org/abs/2306.16722)

    本文介绍了PaRTE，一个包含1,126对文本蕴涵示例的集合，用于评估模型对改写句的鲁棒性。实验结果表明，现代模型在8-16％的改写示例上改变了他们的预测，说明仍有改进的空间。

    

    我们提出了PaRTE，一个包含1,126对文本蕴涵（RTE）示例的集合，用于评估模型对改写句的鲁棒性。我们认为，如果RTE模型能够理解语言，它们的预测应该在具有相同含义的输入上保持一致。我们使用评估集来确定当示例被改写时，RTE模型的预测是否发生变化。在我们的实验中，现代模型在8-16％的改写示例上改变了他们的预测，这说明仍有改进的空间。

    We present PaRTE, a collection of 1,126 pairs of Recognizing Textual Entailment (RTE) examples to evaluate whether models are robust to paraphrasing. We posit that if RTE models understand language, their predictions should be consistent across inputs that share the same meaning. We use the evaluation set to determine if RTE models' predictions change when examples are paraphrased. In our experiments, contemporary models change their predictions on 8-16\% of paraphrased examples, indicating that there is still room for improvement.
    
[^24]: 面向语言学习应用的非母语儿童语音识别

    Automatic Speech Recognition of Non-Native Child Speech for Language Learning Applications. (arXiv:2306.16710v1 [cs.CL])

    [http://arxiv.org/abs/2306.16710](http://arxiv.org/abs/2306.16710)

    该论文评估了两种最新的语音识别系统在非母语儿童语音学习中的表现，并研究了使用语音识别技术提供对儿童发音和流利性的反馈的实用性。

    

    语音机器人在支持语言技能发展方面提供了一种新途径，尤其是在第二语言学习的背景下。然而，语音机器人主要面向母语成年人。我们旨在评估两种最先进的ASR系统（Wav2Vec2.0和Whisper AI）的性能，以开发一种能够支持儿童习得外语的语音机器人。我们评估了它们对母语和非母语荷兰儿童的朗读和即兴演讲的表现。我们还研究了使用ASR技术提供对儿童发音和流利性的洞察的实用性。结果表明，最新的预训练ASR基于Transformer的模型能够实现可接受的性能，可以提取有关音素发音质量的详细反馈，尽管儿童和非母语的语音具有挑战性。

    Voicebots have provided a new avenue for supporting the development of language skills, particularly within the context of second language learning. Voicebots, though, have largely been geared towards native adult speakers. We sought to assess the performance of two state-of-the-art ASR systems, Wav2Vec2.0 and Whisper AI, with a view to developing a voicebot that can support children acquiring a foreign language. We evaluated their performance on read and extemporaneous speech of native and non-native Dutch children. We also investigated the utility of using ASR technology to provide insight into the children's pronunciation and fluency. The results show that recent, pre-trained ASR transformer-based models achieve acceptable performance from which detailed feedback on phoneme pronunciation quality can be extracted, despite the challenging nature of child and non-native speech.
    
[^25]: 基于多源语义图的多模态讽刺解释生成

    Multi-source Semantic Graph-based Multimodal Sarcasm Explanation Generation. (arXiv:2306.16650v1 [cs.CL])

    [http://arxiv.org/abs/2306.16650](http://arxiv.org/abs/2306.16650)

    本研究提出了一种基于多源语义图的多模态讽刺解释生成方案（TEAM），该方案通过提取对象级语义元数据和引入外部相关知识概念，有效地解决了现有方法中存在的视觉特征与解码器语义空间之间的差距以及潜在的外部知识限制。

    

    多模态讽刺解释（MuSE）是一个新而具有挑战性的任务，旨在为多模态社交帖子（包括图像和其标题）生成自然语言句子，解释为什么它包含讽刺。尽管现有的先驱研究在使用BART框架方面取得了巨大成功，但它忽视了图像的对象级元数据与解码器语义空间之间的差距，以及潜在的外部知识。为了解决这些限制，本研究提出了一种新颖的基于多源语义图的多模态讽刺解释方案，称为TEAM。具体而言，TEAM提取了输入图像的对象级语义元数据而不是传统全局视觉特征。同时，TEAM利用ConceptNet获取输入文本和提取的对象元数据的相关外部知识概念。然后，TEAM引入了一个多源语义图，全面地刻画了多模态讽刺解释的特征。

    Multimodal Sarcasm Explanation (MuSE) is a new yet challenging task, which aims to generate a natural language sentence for a multimodal social post (an image as well as its caption) to explain why it contains sarcasm. Although the existing pioneer study has achieved great success with the BART backbone, it overlooks the gap between the visual feature space and the decoder semantic space, the object-level metadata of the image, as well as the potential external knowledge. To solve these limitations, in this work, we propose a novel mulTi-source sEmantic grAph-based Multimodal sarcasm explanation scheme, named TEAM. In particular, TEAM extracts the object-level semantic meta-data instead of the traditional global visual features from the input image. Meanwhile, TEAM resorts to ConceptNet to obtain the external related knowledge concepts for the input text and the extracted object meta-data. Thereafter, TEAM introduces a multi-source semantic graph that comprehensively characterize the m
    
[^26]: ZeroGen: 零射击多模态可控文本生成与多个标准

    ZeroGen: Zero-shot Multimodal Controllable Text Generation with Multiple Oracles. (arXiv:2306.16649v1 [cs.CL])

    [http://arxiv.org/abs/2306.16649](http://arxiv.org/abs/2306.16649)

    ZeroGen是一种零射击的多模态可控文本生成方法，通过在解码过程中利用文本和图像信号的控制，将它们映射到统一的概率空间并通过加权添加自定义LM输出实现高效率的文本生成。实验证明了来自不同模式信号之间的深度与宽度之间的关系。

    

    自动生成带有所需属性的文本内容是一个雄心勃勃的任务，人们一直在追求这一目标。现有的工作在将单模态控制引入语言模型(LMs)方面取得了一系列进展，然而如何使用多模态信号和高效地生成可控句子仍然是一个开放的问题。为了解决这个难题，我们提出了一种新的零射击多模态可控文本生成范式(ZeroGen)。具体而言，ZeroGen从令牌级别到句子级别连续利用文本和图像的控制，并在解码时将它们映射到统一的概率空间中，通过加权添加自定义LM输出，无需额外训练。为了实现更好的跨模态权衡，我们进一步引入了一种有效的动态加权机制来调节所有控制权重。此外，我们进行了大量实验证明来自不同模式信号之间的深度与宽度之间的关系。

    Automatically generating textual content with desired attributes is an ambitious task that people have pursued long. Existing works have made a series of progress in incorporating unimodal controls into language models (LMs), whereas how to generate controllable sentences with multimodal signals and high efficiency remains an open question. To tackle the puzzle, we propose a new paradigm of zero-shot controllable text generation with multimodal signals (\textsc{ZeroGen}). Specifically, \textsc{ZeroGen} leverages controls of text and image successively from token-level to sentence-level and maps them into a unified probability space at decoding, which customizes the LM outputs by weighted addition without extra training. To achieve better inter-modal trade-offs, we further introduce an effective dynamic weighting mechanism to regulate all control weights. Moreover, we conduct substantial experiments to probe the relationship of being in-depth or in-width between signals from distinct mo
    
[^27]: 概率语言知识与标记级文本增强

    Probabilistic Linguistic Knowledge and Token-level Text Augmentation. (arXiv:2306.16644v1 [cs.CL])

    [http://arxiv.org/abs/2306.16644](http://arxiv.org/abs/2306.16644)

    研究了标记级文本增强的有效性和概率语言知识的作用，实验证明了所研究的五种标记级文本增强技术在语言评估环境下不具备普遍有效性，而且与不同分类模型类型无关。

    

    本文研究了在语言学驱动的评估环境下，标记级文本增强的有效性以及概率语言知识的作用。我们开发了两个文本增强程序REDA和REDA$_{NG}$，它们都实现了五种标记级文本编辑操作：同义词替换(SR)、随机交换(RS)、随机插入(RI)、随机删除(RD)和随机混合(RM)。REDA$_{NG}$利用预训练的n-gram语言模型从REDA的输出中选择最可能的增强文本。我们对中文和英文的二元问题匹配分类任务进行了全面和细致的实验。结果强烈否定了所研究的五种标记级文本增强技术的普遍有效性，无论是同时应用还是分别应用，也无论使用了哪种常见的分类模型类型，包括transformers。此外，概率语言知识的作用是...

    This paper investigates the effectiveness of token-level text augmentation and the role of probabilistic linguistic knowledge within a linguistically-motivated evaluation context. Two text augmentation programs, REDA and REDA$_{NG}$, were developed, both implementing five token-level text editing operations: Synonym Replacement (SR), Random Swap (RS), Random Insertion (RI), Random Deletion (RD), and Random Mix (RM). REDA$_{NG}$ leverages pretrained $n$-gram language models to select the most likely augmented texts from REDA's output. Comprehensive and fine-grained experiments were conducted on a binary question matching classification task in both Chinese and English. The results strongly refute the general effectiveness of the five token-level text augmentation techniques under investigation, whether applied together or separately, and irrespective of various common classification model types used, including transformers. Furthermore, the role of probabilistic linguistic knowledge is 
    
[^28]: GPT模型在否定检测方面的评估：以xNot360数据集分析

    A negation detection assessment of GPTs: analysis with the xNot360 dataset. (arXiv:2306.16638v1 [cs.CL])

    [http://arxiv.org/abs/2306.16638](http://arxiv.org/abs/2306.16638)

    本研究评估了GPT-2、GPT-3、GPT-3.5和GPT-4模型在否定检测方面的表现，发现它们之间存在显著的性能差异，GPT-4表现最优，而GPT-3.5表现下降。总体而言，GPT模型在否定检测方面的能力相对有限，这表明该任务挑战了它们在自然语言理解方面的边界。我们不仅突显了GPT模型在处理否定方面的限制，还强调了逻辑可靠性的重要性。

    

    否定是自然语言的基本要素，在交流和理解中起着关键作用。本研究评估了Generative Pre-trained Transformer（GPT）模型（特别是GPT-2、GPT-3、GPT-3.5和GPT-4）在否定检测方面的表现。我们专注于使用零样本预测方法在我们自定义的xNot360数据集上识别自然语言中的否定。我们的方法考察了标记为第二个句子是否否定了第一个句子的句子对。我们的研究结果显示了GPT模型之间明显的性能差异，其中GPT-4表现优异，而GPT-3.5则显示出明显的性能下降。GPT模型在否定检测方面整体的能力相对有限，表明这一任务挑战了它们的自然语言理解能力的边界。我们不仅突显了GPT模型在处理否定方面的局限性，而且强调了逻辑可靠性的重要性。

    Negation is a fundamental aspect of natural language, playing a critical role in communication and comprehension. Our study assesses the negation detection performance of Generative Pre-trained Transformer (GPT) models, specifically GPT-2, GPT-3, GPT-3.5, and GPT-4. We focus on the identification of negation in natural language using a zero-shot prediction approach applied to our custom xNot360 dataset. Our approach examines sentence pairs labeled to indicate whether the second sentence negates the first. Our findings expose a considerable performance disparity among the GPT models, with GPT-4 surpassing its counterparts and GPT-3.5 displaying a marked performance reduction. The overall proficiency of the GPT models in negation detection remains relatively modest, indicating that this task pushes the boundaries of their natural language understanding capabilities. We not only highlight the constraints of GPT models in handling negation but also emphasize the importance of logical relia
    
[^29]: CMATH：你的语言模型能通过中国小学数学测试吗？

    CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?. (arXiv:2306.16636v1 [cs.CL])

    [http://arxiv.org/abs/2306.16636](http://arxiv.org/abs/2306.16636)

    该论文介绍了中国小学数学应用题（CMATH）数据集，评估了多个流行的大型语言模型（LLMs）在小学数学不同年级的表现。研究发现只有GPT-4在所有年级中取得成功，并且能够保持鲁棒性，而其他模型则在不同年级上表现较差。

    

    我们提出了中国小学数学应用题（CMATH）数据集，包含了1.7k个具有详细注释的小学水平数学应用题，来源于中国实际的练习和考试。该数据集旨在提供一个评估流行的大型语言模型（LLMs）能够达到小学数学哪个年级水平的基准工具。我们评估了各种流行的LLMs，包括商业和开源选项，并发现只有GPT-4在所有六个小学年级中都取得了成功（准确率≥60%），而其他模型在不同年级上的表现欠佳。此外，我们通过添加干扰信息来评估几个表现最佳的LLMs的鲁棒性。我们的发现显示GPT-4能够保持鲁棒性，而其他模型则失败。我们预计我们的研究将揭示LLMs在算术和推理能力方面的局限性。

    We present the Chinese Elementary School Math Word Problems (CMATH) dataset, comprising 1.7k elementary school-level math word problems with detailed annotations, source from actual Chinese workbooks and exams. This dataset aims to provide a benchmark tool for assessing the following question: to what grade level of elementary school math do the abilities of popular large language models (LLMs) correspond? We evaluate a variety of popular LLMs, including both commercial and open-source options, and discover that only GPT-4 achieves success (accuracy $\geq$ 60\%) across all six elementary school grades, while other models falter at different grade levels. Furthermore, we assess the robustness of several top-performing LLMs by augmenting the original problems in the CMATH dataset with distracting information. Our findings reveal that GPT-4 is able to maintains robustness, while other model fail. We anticipate that our study will expose limitations in LLMs' arithmetic and reasoning capabi
    
[^30]: 用于CPU上基于Transformer的语言模型的高效稀疏推断软件加速器

    An Efficient Sparse Inference Software Accelerator for Transformer-based Language Models on CPUs. (arXiv:2306.16601v1 [cs.LG])

    [http://arxiv.org/abs/2306.16601](http://arxiv.org/abs/2306.16601)

    本文提出了一个用于基于Transformer的语言模型的高效稀疏推断软件加速器，在CPU上利用Intel Deep Learning Boost实现了稀疏矩阵-稠密矩阵乘法的优化，相较于现有的稀疏库，在各种形状和稀疏度下都获得了一个数量级的性能提升。

    

    近年来，基于Transformer的语言模型已成为自然语言处理任务的标准方法。然而，在工业应用中，严格的吞吐量和延迟要求限制了它们的采用。为了缓解这一差距，我们采用了结构化剪枝等模型压缩技术来提高推断效率。然而，大多数现有的神经网络推断运行时对结构化稀疏性缺乏充分的支持。本文提出了一种高效的稀疏深度学习推断软件堆栈，用于基于Transformer的语言模型，其中权重使用恒定的块大小进行剪枝。我们的稀疏软件加速器利用Intel Deep Learning Boost在CPU上最大化稀疏矩阵-稠密矩阵乘法（通常被缩写为SpMM）的性能。在广泛的GEMM形状和5个代表性稀疏度水平下，我们的SpMM内核的性能优于现有的稀疏库（oneMKL、TVM和LIBXSMM）一个数量级。

    In recent years, Transformer-based language models have become the standard approach for natural language processing tasks. However, stringent throughput and latency requirements in industrial applications are limiting their adoption. To mitigate the gap, model compression techniques such as structured pruning are being used to improve inference efficiency. However, most existing neural network inference runtimes lack adequate support for structured sparsity. In this paper, we propose an efficient sparse deep learning inference software stack for Transformer-based language models where the weights are pruned with constant block size. Our sparse software accelerator leverages Intel Deep Learning Boost to maximize the performance of sparse matrix - dense matrix multiplication (commonly abbreviated as SpMM) on CPUs. Our SpMM kernel outperforms the existing sparse libraries (oneMKL, TVM, and LIBXSMM) by an order of magnitude on a wide range of GEMM shapes under 5 representative sparsity ra
    
[^31]: 通过Pareto Optimal自监督实现大型语言模型的自动校准和错误修正

    Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision. (arXiv:2306.16564v1 [cs.CL])

    [http://arxiv.org/abs/2306.16564](http://arxiv.org/abs/2306.16564)

    本文介绍了一种Pareto Optimal自监督框架，利用可用的编程监督将大型语言模型(LLM)的响应进行系统校准，通过为每个响应生成风险评分，而无需额外的手动工作。

    

    大型语言模型(LLM)已经展现了出色的能力，适用于广泛的应用领域，但是准确性仍然是一个重要的增长领域，特别是在生物医学等关键领域。一种有效的方法，用于校准LLM响应的置信水平，对于自动检测错误并促进人机协作验证至关重要。一个重要的校准信号来源是专家指定的编程监督，通常具有较低的成本，但也有其自身的局限性，如噪声和覆盖范围。在本文中，我们引入了一种Pareto Optimal自监督框架，可以利用可用的编程监督来系统地校准LLM响应，通过为每个响应生成风险评分，而不需要任何额外的手动工作。这通过学习一个调和模型来实现，将LLM输出与其他可用的监督来源相协调，将更不确定的响应分配更高的风险评分。

    Large language models (LLMs) have demonstrated remarkable capabilities out of box for a wide range of applications, yet accuracy still remains a major growth area, especially in mission-critical domains such as biomedicine. An effective method to calibrate the confidence level on LLM responses is essential to automatically detect errors and facilitate human-in-the-loop verification. An important source of calibration signals stems from expert-stipulated programmatic supervision, which is often available at low cost but has its own limitations such as noise and coverage. In this paper, we introduce a Pareto optimal self-supervision framework that can leverage available programmatic supervision to systematically calibrate LLM responses by producing a risk score for every response, without any additional manual efforts. This is accomplished by learning a harmonizer model to align LLM output with other available supervision sources, which would assign higher risk scores to more uncertain L
    
[^32]: ICSVR: 在视频检索模型中研究组合和语义理解

    ICSVR: Investigating Compositional and Semantic Understanding in Video Retrieval Models. (arXiv:2306.16533v1 [cs.CV])

    [http://arxiv.org/abs/2306.16533](http://arxiv.org/abs/2306.16533)

    这篇论文研究了视频检索模型中的组合和语义理解，并通过在标准基准测试上进行实验，评估了这些组成部分对视频检索性能的影响。

    

    视频检索（VR）涉及根据文本标题检索视频数据库中的真实视频，或反之亦然。合成性的两个重要组成部分：对象和属性以及动作，使用正确的语义联结以形成正确的文本查询。这些组成部分（对象和属性、动作和语义）各自在帮助区分视频和检索正确的真实视频方面起着重要作用。然而，这些组成部分对视频检索性能的影响尚不清楚。因此，我们进行了一项系统研究，评估了视频检索模型在标准基准测试上对组合和语义理解的能力，如MSRVTT、MSVD和DIDEMO。该研究针对两类视频检索模型进行了，一类是在视频文本对上预训练并在下游视频检索数据集上进行微调的（例如，Frozen-in-Time、Violet、MCQ等），另一类是适应预训练的图像文本表示（如CLIP）的。

    Video retrieval (VR) involves retrieving the ground truth video from the video database given a text caption or vice-versa. The two important components of compositionality: objects \& attributes and actions are joined using correct semantics to form a proper text query. These components (objects \& attributes, actions and semantics) each play an important role to help distinguish among videos and retrieve the correct ground truth video. However, it is unclear what is the effect of these components on the video retrieval performance. We therefore, conduct a systematic study to evaluate the compositional and semantic understanding of video retrieval models on standard benchmarks such as MSRVTT, MSVD and DIDEMO. The study is performed on two categories of video retrieval models: (i) which are pre-trained on video-text pairs and fine-tuned on downstream video retrieval datasets (Eg. Frozen-in-Time, Violet, MCQ etc.) (ii) which adapt pre-trained image-text representations like CLIP for vid
    
[^33]: 为外部知识视觉问答预训练多模态稠密检索器

    Pre-Training Multi-Modal Dense Retrievers for Outside-Knowledge Visual Question Answering. (arXiv:2306.16478v1 [cs.IR])

    [http://arxiv.org/abs/2306.16478](http://arxiv.org/abs/2306.16478)

    本文提出了一个为外部知识视觉问答任务预训练的段落检索模型的自动数据生成管道，相较于最先进的架构实现了更好的Precision@5。此外，所提出的预训练方法在零样本检索场景中展示了良好的能力。

    

    本文研究了一类视觉问答任务，其中访问外部知识对于回答问题是必要的。这个类别被称为外部知识视觉问答（OK-VQA）。开发OK-VQA系统的一个重要步骤是为给定的多模态查询检索相关文档。目前此任务的最先进的非对称稠密检索模型使用了一个多模态查询编码器和一个单模态文档编码器的架构。这样的架构需要大量的训练数据才能实现有效的性能。我们提出了一个用于预训练OK-VQA任务的段落检索模型的自动数据生成管道。与当前最先进的非对称架构相比，所提出的方法使Precision@5提升了26.9%。此外，所提出的预训练方法在零样本检索场景中展示了良好的能力。

    This paper studies a category of visual question answering tasks, in which accessing external knowledge is necessary for answering the questions. This category is called outside-knowledge visual question answering (OK-VQA). A major step in developing OK-VQA systems is to retrieve relevant documents for the given multi-modal query. Current state-of-the-art asymmetric dense retrieval model for this task uses an architecture with a multi-modal query encoder and a uni-modal document encoder. Such an architecture requires a large amount of training data for effective performance. We propose an automatic data generation pipeline for pre-training passage retrieval models for OK-VQA tasks. The proposed approach leads to 26.9% Precision@5 improvements compared to the current state-of-the-art asymmetric architecture. Additionally, the proposed pre-training approach exhibits a good ability in zero-shot retrieval scenarios.
    
[^34]: 在社交媒体上识别抑郁症的框架：MentalRiskES@IberLEF 2023

    A Framework for Identifying Depression on Social Media: MentalRiskES@IberLEF 2023. (arXiv:2306.16125v1 [cs.CL])

    [http://arxiv.org/abs/2306.16125](http://arxiv.org/abs/2306.16125)

    该论文介绍了在社交媒体上识别抑郁症的框架，使用机器学习和深度学习技术来解决四个预测子任务，并发现使用句子嵌入作为线性回归器的输入产生了更好的结果。

    

    本文描述了我们参与IberLEF 2023的MentalRiskES任务。该任务涉及根据个人在社交媒体上的活动来预测他们可能患抑郁症的可能性。数据集由175个Telegram用户的对话组成，每个用户根据他们患病证据进行标记。我们使用传统机器学习和深度学习技术的组合来解决四个预测子任务：二分类、简单回归、多类别分类和多类别回归。我们通过训练一个模型来解决多类别回归问题，然后将预测结果转换为适用于其他三个子任务的结果。我们比较了两种不同建模方法的性能：对基于BERT的模型进行微调和使用句子嵌入作为线性回归器的输入，后者产生了更好的结果。可以在以下链接找到复现我们结果的代码：https://github.com/simonsanvil/EarlyDep

    This paper describes our participation in the MentalRiskES task at IberLEF 2023. The task involved predicting the likelihood of an individual experiencing depression based on their social media activity. The dataset consisted of conversations from 175 Telegram users, each labeled according to their evidence of suffering from the disorder. We used a combination of traditional machine learning and deep learning techniques to solve four predictive subtasks: binary classification, simple regression, multiclass classification, and multiclass regression. We approached this by training a model to solve the multiclass regression case and then transforming the predictions to work for the other three subtasks. We compare the performance of two different modeling approaches: fine-tuning a BERT-based model and using sentence embeddings as inputs to a linear regressor, with the latter yielding better results. The code to reproduce our results can be found at: https://github.com/simonsanvil/EarlyDep
    
[^35]: 链式思维提示提取多模态命名实体和多模态关系抽取技术

    Chain-of-Thought Prompt Distillation for Multimodal Named Entity and Multimodal Relation Extraction. (arXiv:2306.14122v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.14122](http://arxiv.org/abs/2306.14122)

    本研究提出了一种链式思维提示提取方法，将大型语言模型的推理能力转化为更紧凑的学生模型，从而提高了多模态命名实体识别和多模态关系抽取的效果。

    

    多模态命名实体识别（MNER）和多模态关系抽取（MRE）需要处理复杂语言和多模态理解的基本推理能力。本研究探索了将大型语言模型（LLMs）的推理能力提炼为更紧凑的学生模型的方法，通过生成一系列中间推理步骤来实现。具体而言，我们首先通过涵盖多粒度（名词、句子、多模态）和数据增强（样式、实体、图像）维度的链式思维提示，展示了从LLMs中引导此类推理能力的示例。随后，我们提出了一种新的条件提示提取方法，以吸收LLMs中的常识推理能力，从而增强学生模型在处理仅文本输入时的实用性，而无需添加图像和链式思维知识。大量实验证明，我们的方法达到了最先进的准确性，并表现出更好的性能。

    Multimodal Named Entity Recognition (MNER) and Multimodal Relation Extraction (MRE) necessitate the fundamental reasoning capacity for intricate linguistic and multimodal comprehension. In this study, we explore distilling the reasoning ability of large language models (LLMs) into a more compact student model by generating a \textit{chain of thought} (CoT) -- a sequence of intermediate reasoning steps. Specifically, we commence by exemplifying the elicitation of such reasoning ability from LLMs through CoT prompts covering multi-grain (noun, sentence, multimodality) and data-augmentation (style, entity, image) dimensions. Subsequently, we present a novel conditional prompt distillation method to assimilate the commonsense reasoning ability from LLMs, thereby enhancing the utility of the student model in addressing text-only inputs without the requisite addition of image and CoT knowledge. Extensive experiments reveal that our approach attains state-of-the-art accuracy and manifests a p
    
[^36]: 自带数据！大型语言模型的自我监督评估

    Bring Your Own Data! Self-Supervised Evaluation for Large Language Models. (arXiv:2306.13651v1 [cs.CL])

    [http://arxiv.org/abs/2306.13651](http://arxiv.org/abs/2306.13651)

    本研究提出了一种自我监督评估框架，通过分析输入文本上的变换对LLMs的灵敏度或不变性，直接监控LLMs在实际数据上的行为。

    

    随着大型语言模型（LLMs）的兴起以及它们在各种领域的普及，衡量语言模型在实际数据上的行为变得不可或缺。为了解决这个问题，本研究提出了一种自我监督评估框架，通过分析输入文本上的变换对LLMs的灵敏度或不变性，直接监控LLM在野外收集的数据集或在模型部署期间进行的流数据的行为，实现了评估LLMs的有效和可扩展的解决方案。

    With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations. To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, tox
    
[^37]: 源代码模型的数据增强方法：一份综述

    Data Augmentation Approaches for Source Code Models: A Survey. (arXiv:2305.19915v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.19915](http://arxiv.org/abs/2305.19915)

    本文对源代码的数据增强技术进行了全面的调查和综述，介绍了它们的分类法、优化策略和性能结果，并讨论了未来方向和研究挑战。

    

    源代码在许多关键任务中的广泛应用促进了数据增强（DA）技术的发展，以增强训练数据并提高这些模型的各种能力（例如健壮性和可泛化性）。虽然已经提出并针对源代码模型进行了一系列DA方法的调整，但缺乏综合性的调查和审查以理解它们的有效性和含义。本文通过对源代码的数据增强进行全面而综合的调查，填补这一空白，我们系统地整理和概述现有文献，以提供该领域的全面概述。我们首先构建了适用于源代码模型的数据增强的分类法，然后讨论了著名的、方法上具有说明性的方法。接下来，我们强调了优化DA质量的一般策略和技术。随后，我们强调了在被广泛接受的基准测试中发挥作用的技术，并呈现了它们的性能结果。最后，我们讨论了DA用于源代码模型的潜在未来方向和开放研究挑战。

    The increasingly popular adoption of source code in many critical tasks motivates the development of data augmentation (DA) techniques to enhance training data and improve various capabilities (e.g., robustness and generalizability) of these models. Although a series of DA methods have been proposed and tailored for source code models, there lacks a comprehensive survey and examination to understand their effectiveness and implications. This paper fills this gap by conducting a comprehensive and integrative survey of data augmentation for source code, wherein we systematically compile and encapsulate existing literature to provide a comprehensive overview of the field. We start by constructing a taxonomy of DA for source code models model approaches, followed by a discussion on prominent, methodologically illustrative approaches. Next, we highlight the general strategies and techniques to optimize the DA quality. Subsequently, we underscore techniques that find utility in widely-accept
    
[^38]: ChatGPT与现有模型之间的关键短语生成任务基准研究

    ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task. (arXiv:2304.14177v1 [cs.CL])

    [http://arxiv.org/abs/2304.14177](http://arxiv.org/abs/2304.14177)

    本研究比较了ChatGPT和现有模型在关键短语生成任务上的性能，并发现ChatGPT在所有测试数据集和环境中的表现均优于现有模型，适用于不同领域和文档长度的关键短语生成。

    

    基于Transformer的语言模型，包括ChatGPT，已经在各种自然语言生成任务中展现了出色的性能。但是，在评估ChatGPT的关键短语生成能力方面，还没有多少研究，这涉及到准确反映文档内容的信息性短语的识别。本文试图通过将ChatGPT的关键短语生成表现与现有模型进行比较来解决这个问题，同时还测试了它作为解决领域适应和长文档关键短语生成两个重大挑战的潜力。我们在来自科学文章和新闻领域的六个公开数据集上进行了实验，分析了在短文档和长文档上的表现。结果表明，在所有测试的数据集和环境中，ChatGPT的性能优于当前现有模型，产生适应不同领域和文档长度的高质量关键短语。

    Transformer-based language models, including ChatGPT, have demonstrated exceptional performance in various natural language generation tasks. However, there has been limited research evaluating ChatGPT's keyphrase generation ability, which involves identifying informative phrases that accurately reflect a document's content. This study seeks to address this gap by comparing ChatGPT's keyphrase generation performance with state-of-the-art models, while also testing its potential as a solution for two significant challenges in the field: domain adaptation and keyphrase generation from long documents. We conducted experiments on six publicly available datasets from scientific articles and news domains, analyzing performance on both short and long documents. Our results show that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.
    
[^39]: 改善临床试验的患者预筛选：利用大型语言模型辅助医生

    Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models. (arXiv:2304.07396v1 [cs.LG])

    [http://arxiv.org/abs/2304.07396](http://arxiv.org/abs/2304.07396)

    本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。

    

    考虑到患者的临床试验，医生需要进行繁琐的检查，以确定患者是否符合文本基准。大型语言模型（LLMs）已被证明在临床信息提取和临床推理方面表现良好，但尚未在现实场景中得到应用。本文研究了使用InstructGPT辅助医生根据患者的医疗简况确定其是否符合临床试验的资格。使用一次性、选择-推理和思维链策略相结合的提示策略，我们研究了LLMs在10个合成患者简况上的表现。在四个级别上评估了性能：能否从临床试验中给出的医疗简况中识别筛选资格标准；能否为每个单独的标准分类是否符合患者；整体分类是否符合临床试验资格以及需要筛选资格标准的百分比。

    Physicians considering clinical trials for their patients are met with the laborious process of checking many text based eligibility criteria. Large Language Models (LLMs) have shown to perform well for clinical information extraction and clinical reasoning, including medical tests, but not yet in real-world scenarios. This paper investigates the use of InstructGPT to assist physicians in determining eligibility for clinical trials based on a patient's summarised medical profile. Using a prompting strategy combining one-shot, selection-inference and chain-of-thought techniques, we investigate the performance of LLMs on 10 synthetically created patient profiles. Performance is evaluated at four levels: ability to identify screenable eligibility criteria from a trial given a medical profile; ability to classify for each individual criterion whether the patient qualifies; the overall classification whether a patient is eligible for a clinical trial and the percentage of criteria to be scr
    
[^40]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^41]: AI生成的文本是否可靠地检测出来？

    Can AI-Generated Text be Reliably Detected?. (arXiv:2303.11156v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.11156](http://arxiv.org/abs/2303.11156)

    本研究通过实证和理论分析表明，在实际场景中，几种AI文本检测器不可靠。改写攻击可以破解多种检测器，包括水印方案、神经网络检测器和零样本分类器。即使是最好的检测器，随着语言模型的进一步提升，性能也会下降。因此，AI生成的文本的可靠检测仍然是一个挑战。

    

    本文从实证和理论两个方面表明，在实际场景中，几种AI文本检测器并不可靠。从实践上来说，我们证明了轻量级的改写器应用在大型语言模型（LLM）上可以破解一系列的检测器，包括使用水印方案、神经网络检测器和零样本分类器。我们的实验表明，旨在躲避改写攻击的基于检索的检测器仍然容易受到递归改写的攻击。然后，我们提出了一个理论上的不可能结果，指出随着语言模型变得越来越复杂和更擅长模仿人类文本，在最好的检测器性能会下降。对于一个足够先进的语言模型来模仿人类文本，即使最佳的检测器的表现只比随机分类器好上一点点。我们的结果足够概括特定的场景，如改写攻击。

    In this paper, both empirically and theoretically, we show that several AI-text detectors are not reliable in practical scenarios. Empirically, we show that paraphrasing attacks, where a light paraphraser is applied on top of a large language model (LLM), can break a whole range of detectors, including ones using watermarking schemes as well as neural network-based detectors and zero-shot classifiers. Our experiments demonstrate that retrieval-based detectors, designed to evade paraphrasing attacks, are still vulnerable to recursive paraphrasing. We then provide a theoretical impossibility result indicating that as language models become more sophisticated and better at emulating human text, the performance of even the best-possible detector decreases. For a sufficiently advanced language model seeking to imitate human text, even the best-possible detector may only perform marginally better than a random classifier. Our result is general enough to capture specific scenarios such as par
    
[^42]: 数据增强在有限数据下参数高效调整的有效性研究

    Effectiveness of Data Augmentation for Parameter Efficient Tuning with Limited Data. (arXiv:2303.02577v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.02577](http://arxiv.org/abs/2303.02577)

    本文研究了在有限数据情况下，使用参数高效调整方法时，数据增强的有效性。研究表明，数据增强可以提升某些方法的性能，但效果因技术和任务而异，并且在使用较大模型和更难的任务时可能导致性能下降。

    

    最近的研究表明，使用参数高效调整技术，如预训练语言模型上的前缀调整（或P-tuning），可以在大大减少可训练参数的同时，产生与微调相媲美或更好的性能。然而，在低数据情况下，这种方法在数据增强的背景下的效果尚未得到充分探讨。本文研究了在数据稀缺情况下，使用两种通用参数高效调整方法——P-tuning v2和LoRA时，几种常用的任务无关数据增强技术，即EDA，后翻译和混合，的有效性。我们展示了数据增强可以用于提升P-tuning和LoRA模型的性能，但各种技术的有效性有所不同，并且某些方法可能导致性能明显下降，特别是在使用较大模型和更难的任务时。我们进一步分析了句子的表示方法。

    Recent work has demonstrated that using parameter efficient tuning techniques such as prefix tuning (or P-tuning) on pretrained language models can yield performance that is comparable or superior to fine-tuning while dramatically reducing trainable parameters. Nevertheless, the effectiveness of such methods under the context of data augmentation, a common strategy to improve learning under low data regimes, has not been fully explored. In this paper, we examine the effectiveness of several popular task-agnostic data augmentation techniques, i.e., EDA, Back Translation, and Mixup, when using two general parameter efficient tuning methods, P-tuning v2 and LoRA, under data scarcity. We show that data augmentation can be used to boost the performance of P-tuning and LoRA models, but the effectiveness of each technique varies and certain methods can lead to a notable degradation in performance, particularly when using larger models and on harder tasks. We further analyze the sentence repre
    
[^43]: 预测新闻事实性和媒体倾向的句子级别可靠性分析

    Predicting Sentence-Level Factuality of News and Bias of Media Outlets. (arXiv:2301.11850v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11850](http://arxiv.org/abs/2301.11850)

    本论文提出了一种针对整个媒体的细粒度可靠性分析方法，在手动制作的“FactNews”数据库上，通过 fine-tuning BERT 模型预测新闻报道的句子级别事实性和媒体倾向。此方法可应用于任何其他语言。

    

    预测新闻报道的事实性和媒体倾向对于自动化的新闻信誉和事实核查是很重要的。本文提出了对整个媒体进行细粒度可靠性分析的方法。我们研究了预测新闻报道的句子级别事实性和媒体倾向，这可以更精确地解释整个 source 的可靠程度。我们首先手动制作了一个大型的句子级别数据库，“FactNews”，由 6191 个专家注释的句子组成，注释依据来自 AllSides 的事实性和媒体倾向定义。最后，由于巴西存在严重的虚假新闻和政治极化问题，我们提供了用于葡萄牙语的数据集和基线模型。但是，我们的方法可以应用于任何其他语言。

    Predicting the factuality of news reporting and bias of media outlets is surely relevant for automated news credibility and fact-checking. While prior work has focused on the veracity of news, we propose a fine-grained reliability analysis of the entire media. Specifically, we study the prediction of sentence-level factuality of news reporting and bias of media outlets, which may explain more accurately the overall reliability of the entire source. We first manually produced a large sentence-level dataset, titled "FactNews", composed of 6,191 sentences expertly annotated according to factuality and media bias definitions from AllSides. As a result, baseline models for sentence-level factuality prediction were presented by fine-tuning BERT. Finally, due to the severity of fake news and political polarization in Brazil, both dataset and baseline were proposed for Portuguese. However, our approach may be applied to any other language.
    
[^44]: MooseNet：一种可训练的合成语音度量学模型与PLDA模块

    MooseNet: A Trainable Metric for Synthesized Speech with a PLDA Module. (arXiv:2301.07087v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.07087](http://arxiv.org/abs/2301.07087)

    我们提出了一种可训练的语音度量学模型MooseNet，使用PLDA模块在SSL模型中进行嵌入层生成，能够准确预测听众的平均意见分数（MOS）。通过在低资源情况下对PLDA进行训练，我们证明了它相对于SSL模型微调的优越性。我们还通过选择适当的优化器和额外的训练目标改进了SSL模型的微调效果。经过PLDA模块微调的MooseNet在VoiceMOS Challenge数据集上表现出色，超越了SSL基线模型。

    

    我们提出了一种可训练的语音度量学模型MooseNet，用于预测听众的平均意见分数（MOS）。我们提出了一种新颖的方法，在自监督学习（SSL）神经网络模型中使用基于概率线性判别分析（PLDA）生成模型得到的嵌入层。我们证明，在仅使用136个句子（大约一分钟的训练时间）训练的非微调SSL模型的情况下，PLDA能够取得良好的效果，并且PLDA持续改进各种神经网络的MOS预测模型，甚至包括具有任务特定微调的最先进模型。我们的消融研究表明，在资源有限的情况下，PLDA的训练在SSL模型微调中具有优势。我们还改进了SSL模型微调，采用了合适的优化器选择和额外的对比和多任务训练目标。经过PLDA模块微调的MooseNet神经网络在VoiceMOS Challenge数据集上取得了最好的结果，超过了SSL基线。

    We present MooseNet, a trainable speech metric that predicts the listeners' Mean Opinion Score (MOS). We propose a novel approach where the Probabilistic Linear Discriminative Analysis (PLDA) generative model is used on top of an embedding obtained from a self-supervised learning (SSL) neural network (NN) model. We show that PLDA works well with a non-finetuned SSL model when trained only on 136 utterances (ca. one minute training time) and that PLDA consistently improves various neural MOS prediction models, even state-of-the-art models with task-specific fine-tuning. Our ablation study shows PLDA training superiority over SSL model fine-tuning in a low-resource scenario. We also improve SSL model fine-tuning using a convenient optimizer choice and additional contrastive and multi-task training objectives. The fine-tuned MooseNet NN with the PLDA module achieves the best results, surpassing the SSL baseline on the VoiceMOS Challenge data.
    
[^45]: 对数线性保护性及其影响的研究

    Log-linear Guardedness and its Implications. (arXiv:2210.10012v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.10012](http://arxiv.org/abs/2210.10012)

    本研究介绍了对数线性保护性及其对下游分类器行为的影响。在二元情况下，下游对数线性模型无法恢复被删除的概念，但在某些情况下，可以通过构建多类对数线性模型间接恢复概念。这些结果揭示了线性删除方法的局限性，并强调了进一步研究的需求。

    

    已经发现，在假设可线性的神经表示中，从中删除可人解释的概念的方法是可行和有用的。然而，这种删除对于基于修改后表示进行训练的下游分类器行为的影响尚未完全理解。在这项工作中，我们正式定义了对数线性保护性的概念，即对手无法直接从表示中预测概念的能力，并研究其影响。我们证明，在二元情况下，在某些假设下，下游对数线性模型无法恢复被删除的概念。然而，我们证明，在某些情况下，可以构建一个多类对数线性模型，间接恢复概念，这指出了对数线性保护性作为下游偏差缓解技术的内在局限性。这些发现揭示了线性删除方法的理论限制，并强调了进一步研究可解释神经表示与分类器之间的联系的需要。

    Methods for erasing human-interpretable concepts from neural representations that assume linearity have been found to be tractable and useful. However, the impact of this removal on the behavior of downstream classifiers trained on the modified representations is not fully understood. In this work, we formally define the notion of log-linear guardedness as the inability of an adversary to predict the concept directly from the representation, and study its implications. We show that, in the binary case, under certain assumptions, a downstream log-linear model cannot recover the erased concept. However, we demonstrate that a multiclass log-linear model \emph{can} be constructed that indirectly recovers the concept in some cases, pointing to the inherent limitations of log-linear guardedness as a downstream bias mitigation technique. These findings shed light on the theoretical limitations of linear erasure methods and highlight the need for further research on the connections between int
    
[^46]: 树的平面线性化中边长度的期望和：理论与应用

    The expected sum of edge lengths in planar linearizations of trees. Theory and applications. (arXiv:2207.05564v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.05564](http://arxiv.org/abs/2207.05564)

    本论文研究了在树的平面线性化中边长度的期望和，提出了一个计算平面排列的方法，并分析了平面排列与投影排列之间的关系。

    

    依赖树已被证明是表示人类语言句子的句法结构的非常成功的模型。在这些结构中，顶点是单词，边连接语法相关的单词。使用随机基线来计算边长度之和或其变体，已经证明了这些依赖关系的倾向是短的。一个普遍存在的基线是在投影排序中的期望和（其中边不相交，并且句子的根词没有被任何边覆盖），可以在$O(n)$时间内计算得到。在这里，我们关注一个较弱的形式约束，即平面性。在理论领域，我们提出了一个刻画平面性的方法，给定一个句子，可以得到平面排列的数量或以均匀随机方式生成平面排列的有效算法。我们还展示了平面排列中的期望总和与投影排列中的期望总和之间的关系。

    Dependency trees have proven to be a very successful model to represent the syntactic structure of sentences of human languages. In these structures, vertices are words and edges connect syntactically-dependent words. The tendency of these dependencies to be short has been demonstrated using random baselines for the sum of the lengths of the edges or its variants. A ubiquitous baseline is the expected sum in projective orderings (wherein edges do not cross and the root word of the sentence is not covered by any edge), that can be computed in time $O(n)$. Here we focus on a weaker formal constraint, namely planarity. In the theoretical domain, we present a characterization of planarity that, given a sentence, yields either the number of planar permutations or an efficient algorithm to generate uniformly random planar permutations of the words. We also show the relationship between the expected sum in planar arrangements and the expected sum in projective arrangements. In the domain of a
    
[^47]: 语言模型作为知识嵌入

    Language Models as Knowledge Embeddings. (arXiv:2206.12617v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.12617](http://arxiv.org/abs/2206.12617)

    该论文提出了一种使用语言模型来推导知识嵌入的方法LMKE，它旨在提高对丰富的长尾实体的表示能力并解决基于描述的先前方法的问题，实验结果表明该方法在多个基准数据集上实现了最先进的性能。

    

    知识嵌入是通过将实体和关系嵌入到连续向量空间中来表示知识图谱的一种方法。现有的方法主要是基于结构或基于描述。基于结构的方法学习表示，以保留知识图谱的内在结构。它们不能很好地表示现实世界知识图谱中有限结构信息下丰富的长尾实体。基于描述的方法利用文本信息和语言模型。在这个方向上的先前方法几乎无法超越基于结构的方法，并且存在昂贵的负采样和限制性描述需求等问题。在本文中，我们提出了LMKE，采用语言模型来推导知识嵌入，旨在丰富长尾实体的表示并解决基于描述的先前方法的问题。我们用对比学习框架来表述基于描述的知识嵌入学习，以提高训练和评价的效率。实验结果表明，LMKE在多个基准数据集上实现了最先进的性能，超越了基于结构和基于先前描述的方法。

    Knowledge embeddings (KE) represent a knowledge graph (KG) by embedding entities and relations into continuous vector spaces. Existing methods are mainly structure-based or description-based. Structure-based methods learn representations that preserve the inherent structure of KGs. They cannot well represent abundant long-tail entities in real-world KGs with limited structural information. Description-based methods leverage textual information and language models. Prior approaches in this direction barely outperform structure-based ones, and suffer from problems like expensive negative sampling and restrictive description demand. In this paper, we propose LMKE, which adopts Language Models to derive Knowledge Embeddings, aiming at both enriching representations of long-tail entities and solving problems of prior description-based methods. We formulate description-based KE learning with a contrastive learning framework to improve efficiency in training and evaluation. Experimental resul
    
[^48]: 关于嵌入、聚类和字符串在文本生成器评估中的实用性

    On the Usefulness of Embeddings, Clusters and Strings for Text Generator Evaluation. (arXiv:2205.16001v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.16001](http://arxiv.org/abs/2205.16001)

    这篇论文讨论了语言生成器评估中的自动度量标准问题，以及目前存在的Mauve度量标准的局限性。当前的方法通过近似计算来衡量概率分布之间的差异，但在实践中并不是一个严格的近似。

    

    一种好的自动评估语言生成度量标准应该与人类对文本质量的判断高度相关。然而，这样的度量标准很少，这阻碍了语言生成器的快速和高效发展。一个例外是最近提出的Mauve度量标准。理论上，Mauve度量的是两个概率分布之间的信息论差异：一个表示被评估的语言生成器，另一个表示真正的自然语言分布。Mauve的作者认为其成功来自于所提出差异的定性特性。然而在实践中，由于这个差异不可计算，Mauve通过衡量聚类上多项式分布之间的差异来近似表示，其中聚类分配是通过基于预训练语言模型的嵌入进行分组字符串获得的。然而，正如我们所展示的，这并不是一个严格的近似——无论是在理论还是实践中。

    A good automatic evaluation metric for language generation ideally correlates highly with human judgements of text quality. Yet, there is a dearth of such metrics, which inhibits the rapid and efficient progress of language generators. One exception is the recently proposed Mauve. In theory, Mauve measures an information-theoretic divergence between two probability distributions over strings: one representing the language generator under evaluation; the other representing the true natural language distribution. Mauve's authors argue that its success comes from the qualitative properties of their proposed divergence. Yet in practice, as this divergence is uncomputable, Mauve approximates it by measuring the divergence between multinomial distributions over clusters instead, where cluster assignments are attained by grouping strings based on a pre-trained language model's embeddings. As we show, however, this is not a tight approximation -- in either theory or practice. This begs the que
    
[^49]: “这是一个可疑的反应！”：解读概率变化以检测NLP对抗攻击。

    "That Is a Suspicious Reaction!": Interpreting Logits Variation to Detect NLP Adversarial Attacks. (arXiv:2204.04636v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2204.04636](http://arxiv.org/abs/2204.04636)

    这项工作提出了一个模型无关的对抗文本检测器，通过识别目标分类器的概率中的模式来改进对抗输入的识别性能，并具有较强的泛化能力。

    

    对抗攻击是当前机器学习研究面临的主要挑战。这些有意制作的输入甚至可以欺骗最先进的模型，使其无法在安全关键的应用中部署。计算机视觉领域已经进行了大量研究以开发可靠的防御策略。然而，在自然语言处理中，同样的问题仍然没有得到深入探究。我们的工作提出了一个对抗文本示例的模型无关检测器。该方法通过扰动输入文本时在目标分类器的概率中识别模式。所提出的检测器在识别对抗输入方面提高了当前技术水平，并展示了在不同的NLP模型、数据集和词级攻击中具有较强的泛化能力。

    Adversarial attacks are a major challenge faced by current machine learning research. These purposely crafted inputs fool even the most advanced models, precluding their deployment in safety-critical applications. Extensive research in computer vision has been carried to develop reliable defense strategies. However, the same issue remains less explored in natural language processing. Our work presents a model-agnostic detector of adversarial text examples. The approach identifies patterns in the logits of the target classifier when perturbing the input text. The proposed detector improves the current state-of-the-art performance in recognizing adversarial inputs and exhibits strong generalization capabilities across different NLP models, datasets, and word-level attacks.
    
[^50]: AI最近变得更消极了吗？

    Did AI get more negative recently?. (arXiv:2202.13610v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.13610](http://arxiv.org/abs/2202.13610)

    本文通过对自然语言处理和机器学习领域的论文进行分类和分析，发现随着时间的推移，科学文章更倾向于积极的立场，但也存在一些持消极立场的论文。

    

    在这篇论文中，我们将人工智能（AI）的核心子领域自然语言处理（NLP）和机器学习（ML）的科学文章分类为两种，一种是通过引入新技术超越现有模型的文章，被称为“积极立场”；另一种是主要批评现有技术不足的文章，被称为“消极立场”。我们使用超过1500篇NLP和ML论文进行标注，使用基于SciBERT的模型自动预测论文的立场。然后，我们分析了近35年来NLP和ML领域的超过41000篇论文的大规模趋势，发现论文随着时间的推移变得更积极，但也有一些消极的论文。

    In this paper, we classify scientific articles in the domain of natural language processing (NLP) and machine learning (ML), as core subfields of artificial intelligence (AI), into whether (i) they extend the current state-of-the-art by the introduction of novel techniques which beat existing models or whether (ii) they mainly criticize the existing state-of-the-art, i.e. that it is deficient with respect to some property (e.g. wrong evaluation, wrong datasets, misleading task specification). We refer to contributions under (i) as having a 'positive stance' and contributions under (ii) as having a 'negative stance' (to related work). We annotate over 1.5 k papers from NLP and ML to train a SciBERT-based model to automatically predict the stance of a paper based on its title and abstract. We then analyse large-scale trends on over 41 k papers from the last approximately 35 years in NLP and ML, finding that papers have become substantially more positive over time, but negative papers als
    

