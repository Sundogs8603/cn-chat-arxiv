# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction.](http://arxiv.org/abs/2305.13981) | 本文提出了第一个模拟评估开放式信息提取模型在真实世界中的基准测试，并通过判断模型在整个团体上的表现是否始终准确来评估模型的鲁棒性。 |
| [^2] | [Effortless Integration of Memory Management into Open-Domain Conversation Systems.](http://arxiv.org/abs/2305.13973) | 本文提出了一种简单的方法，将内存管理能力集成到 BlenderBot3 中以改进其性能，并通过自动化数据集创建来管理内存。对于 F1 分数，我们提出的模型 BlenderBot3-M^3 比 BlenderBot3 提高了 4%。 |
| [^3] | [Make a Choice! Knowledge Base Question Answering with In-Context Learning.](http://arxiv.org/abs/2305.13972) | McL-KBQA是一个新的框架，它通过基于上下文学习的多项选择将LLMs的一些样本能力纳入KBQA方法，从而显著提高了概括能力，有效性和效果。 |
| [^4] | [Flexible Grammar-Based Constrained Decoding for Language Models.](http://arxiv.org/abs/2305.13971) | 本文提出了一种使用形式语法约束丰富解码步骤的方法，有效生成符合特定语法的复杂输出结构，同时允许任何上下文无关语法集成。实验证明该方法在四个信息提取任务上实现了最先进的性能表现。 |
| [^5] | [Acquiring Frame Element Knowledge with Deep Metric Learning for Semantic Frame Induction.](http://arxiv.org/abs/2305.13944) | 本论文提出一种方法，应用深度度量学习获取框架元素知识，以适合于区分框架元素角色，实验证明该方法比现有方法具有更好的性能。 |
| [^6] | [Generating Data for Symbolic Language with Large Language Models.](http://arxiv.org/abs/2305.13917) | 符号语言任务中，利用大型语言模型（LLMs）生成数据的方法被提出。SymGen由信息提示和基于协议的验证器组成，可以生成各种注释昂贵的符号语言数据。相对于LLMs，使用1%大小的任务模型性能相当或更好，大幅削减了推理和部署成本。使用SymGen生成数据可以提高符号语言任务的性能和通用性。 |
| [^7] | [DAPR: A Benchmark on Document-Aware Passage Retrieval.](http://arxiv.org/abs/2305.13915) | DAPR是一个文档感知段落检索的基准测试，挑战在于如何从长文档中找到正确的段落并返回准确结果。 |
| [^8] | [Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction.](http://arxiv.org/abs/2305.13903) | 该论文提出了一种新的研究方向 VideoCOT，利用视觉-语言模型的多模态生成能力，以增强视频推理，同时减少处理数百或数千帧的计算复杂度。在VIP数据集上，我们基于各种视觉-语言模型进行了基准测试，展示了使用视觉-语言模型进行VideoCOT的潜力。 |
| [^9] | [Sequence-Level Knowledge Distillation for Class-Incremental End-to-End Spoken Language Understanding.](http://arxiv.org/abs/2305.13899) | 本文针对连续学习场景下的口语语言理解问题，提出了增量类别场景和三种知识蒸馏方法，并显示序列级知识蒸馏可以显著改善绩效。 |
| [^10] | [PaD: Program-aided Distillation Specializes Large Models in Reasoning.](http://arxiv.org/abs/2305.13888) | 本文提出了一种程序辅助蒸馏（PaD）技术，它可以蒸馏大型语言模型（LLMs）以在推理任务中获得专业化的小模型。PaD使用程序辅助推理加强专业化模型，并通过自动化错误检查来帮助它们克服错误的推理步骤。 |
| [^11] | [Narrative XL: A Large-scale Dataset For Long-Term Memory Models.](http://arxiv.org/abs/2305.13877) | 本研究提出了一个新的用于长期记忆模型的大规模自然数据集，以帮助改进现有的大型语言模型。数据集由 GPT 3.5 生成，摘要包括来自 Project Gutenberg 的 1500 本书中每个场景的总结，以及配套的阅读理解问题。 |
| [^12] | [Probing Brain Context-Sensitivity with Masked-Attention Generation.](http://arxiv.org/abs/2305.13863) | 本文介绍了一种新方法Masked-Attention生成，使用GPT-2变形器生成的固定量上下文信息的词嵌入可以预测人类听自然语言时的fMRI脑活动，结果表明语言网络的大多数皮层对上下文信息敏感，右半球对更长的上下文更敏感。 |
| [^13] | [A Trip Towards Fairness: Bias and De-Biasing in Large Language Models.](http://arxiv.org/abs/2305.13862) | 本文研究大型语言模型中的偏见问题，并提出了一种去偏差技术以产生在下游任务中表现良好的健壮去偏差模型。 |
| [^14] | [Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study.](http://arxiv.org/abs/2305.13860) | 本研究探索了通过提示工程破解ChatGPT的有效性，发现破解提示可以在40种用例情况下一致地规避限制，强调了提示结构在破解ChatGPT中的重要性。 |
| [^15] | [Revealing User Familiarity Bias in Task-Oriented Dialogue via Interactive Evaluation.](http://arxiv.org/abs/2305.13857) | 本研究发现任务导向对话系统中存在用户熟悉度偏见，而真实世界的应用场景很少符合封闭目标的设定。因此，在开放目标设置下，系统会出现严重问题，同时研究者发现了“不匹配错误”这一新型错误类型。 |
| [^16] | [Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document.](http://arxiv.org/abs/2305.13850) | 这篇论文提出了一种结合全局结构知识的连续迭代的方式去捕获实体之间的依赖关系，以提高视觉丰富文档中关系抽取的准确性。 |
| [^17] | [Arukikata Travelogue Dataset with Geographic Entity Mention, Coreference, and Link Annotation.](http://arxiv.org/abs/2305.13844) | 该论文介绍了一个日本旅行游记数据集，强调文档级地理实体解析的重要性，提供丰富的地理实体信息，并为地理解析系统评估提供了基础。 |
| [^18] | [Reducing Sensitivity on Speaker Names for Text Generation from Dialogues.](http://arxiv.org/abs/2305.13833) | 本文提出在对话生成文本中降低说话者名称敏感度的方法，通过定量测量模型敏感度并全面评估已知方法，得出了一种新方法的良好表现，为此问题提供了基准。 |
| [^19] | [ZET-Speech: Zero-shot adaptive Emotion-controllable Text-to-Speech Synthesis with Diffusion and Style-based Models.](http://arxiv.org/abs/2305.13831) | 本文提出了一种零样本自适应情感可控的语音合成模型ZET-Speech, 它可以通过一段短的中性语音和目标情感标签合成任何说话者的情感语音，并且成功合成了具有所需情感的自然和情感语音，适用于见过和未见过的发言人。 |
| [^20] | [Learn from Mistakes through Cooperative Interaction with Study Assistant.](http://arxiv.org/abs/2305.13829) | 本文提出了一个新框架 SALAM，通过协作交互与学习助手来帮助 LLM 在反思和改进过程中。该框架通过收集错误并在推理时提供指导方针，显着提高模型性能。 |
| [^21] | ["Is the Pope Catholic?" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures.](http://arxiv.org/abs/2305.13826) | 本论文运用思维链推理，将格赖斯的四个准则纳入模型，证明了可以提高模型性能以有效理解对话含义。 |
| [^22] | [An Open Dataset and Model for Language Identification.](http://arxiv.org/abs/2305.13820) | 本文介绍了一种语言识别模型，使用开源的数据集和筛选出来的单语数据，取得了优秀的性能表现，尤其是在低资源语言上表现出色，并对模型的表现进行了详细的分析。 |
| [^23] | [Detecting automatically the layout of clinical documents to enhance the performances of downstream natural language processing.](http://arxiv.org/abs/2305.13817) | 本文提出了一种算法，可以自动提取临床 PDF 文档中有关临床的文本，以提高下游自然语言处理任务的性能。 |
| [^24] | [Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality.](http://arxiv.org/abs/2305.13812) | 本研究提出了一种基于场景图的对比学习框架，通过将从文本中解析出的场景图视为图像场景图的代理，并对图进行分解和增强，从简单到复杂的对比学习以将各种复杂度的句子对齐到同一幅图像上，同时在场景图空间中提出了新的负样本挖掘技术，以改善视觉语言组合能力。 |
| [^25] | [Asking Clarification Questions to Handle Ambiguity in Open-Domain QA.](http://arxiv.org/abs/2305.13808) | 本文提出了一种解决开放域QA中歧义问题的方法：通过提问澄清来确定最符合用户意图的解释。 |
| [^26] | [Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path.](http://arxiv.org/abs/2305.13805) | 本文提出了一种名为 ReXMiner 的新方法，用于实现 Web 挖掘中的零样本关系抽取。该方法利用文档对象模型（DOM）树中最短相对路径来更准确、高效地提取网页中的键值对，并通过计算文本节点在不同网页中出现的次数来衡量其流行度。 |
| [^27] | [Personalized Predictive ASR for Latency Reduction in Voice Assistants.](http://arxiv.org/abs/2305.13794) | 本文介绍了一种个性化预测ASR方法，可以降低语音助手中的延迟，通过预测完整话语来预取响应，并探讨了成功预测和失败预测之间的权衡。 |
| [^28] | [Can Large Language Models Infer and Disagree Like Humans?.](http://arxiv.org/abs/2305.13788) | 本文研究了大型语言模型在自然语言推断方面的性能和与人类分歧分布的对齐情况。结果表明LLM的推断能力有限，无法捕捉到人类分歧分布，引发了对其NLU和代表人类用户性质的担忧。 |
| [^29] | [Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation.](http://arxiv.org/abs/2305.13785) | 本论文提出一种基于提示的数据增强方法，通过在辅助语言模型上进行微调来实现，从而提高了黑盒少样本文本分类的性能。 |
| [^30] | [Images in Language Space: Exploring the Suitability of Large Language Models for Vision & Language Tasks.](http://arxiv.org/abs/2305.13782) | 该论文研究了只使用语言模型是否可以用于需要视觉输入和强大推理能力的任务，并使用单独的语言模型使其可以访问视觉信息的方法。结果表明，即使样本有限，语言模型也可以成功解决视觉语言任务，还提高了模型输出的可解释性。 |
| [^31] | [Counterspeeches up my sleeve! Intent Distribution Learning and Persistent Fusion for Intent-Conditioned Counterspeech Generation.](http://arxiv.org/abs/2305.13776) | 这篇论文提出了一个意图条件下的反话语生成方法QUARC，基于IntentCONAN数据集，利用向量量化表示和PerFuMe融合模块实现特定意图的反话语输出。 |
| [^32] | [Concept-aware Training Improves In-context Learning Ability of Language Models.](http://arxiv.org/abs/2305.13775) | 本研究提出了一种概念感知训练的方法，用于训练能够更好利用上下文信息的语言模型。该方法能够显著提高模型的推理能力，在多个基准测试中表现出良好的效果。 |
| [^33] | [Topic-driven Distant Supervision Framework for Macro-level Discourse Parsing.](http://arxiv.org/abs/2305.13755) | 本研究提出了一种基于主题驱动的远程监督框架，通过远程监督方法利用领域内数据生成高质量的篇章训练数据，进一步提高篇章分析性能，在使用更少的训练数据的情况下实现最先进的结果。 |
| [^34] | [Challenges in Context-Aware Neural Machine Translation.](http://arxiv.org/abs/2305.13751) | 本文研究上下文感知神经机器翻译中存在的挑战，并提出了更为真实的文档级翻译设置，段落级翻译(para2para)，以及收集了一份新的中英小说数据集，以促进未来的研究。 |
| [^35] | [Goal-Driven Explainable Clustering via Language Descriptions.](http://arxiv.org/abs/2305.13749) | 该研究提出了一种“带解释的基于目标的聚类”（GoalEx）的新任务形式，它将目标和解释都表示为自由形式的语言描述。通过将摘要系统的注释进行分类来说明研究的有效性以及生成的解释。 |
| [^36] | [TeCS: A Dataset and Benchmark for Tense Consistency of Machine Translation.](http://arxiv.org/abs/2305.13740) | 本文提出了一个包含552个法语-英语话语的平行时态测试集和相应的时态预测准确率基准，这使得研究人员能够首次从语言学角度衡量机器翻译系统的时态一致性性能。 |
| [^37] | [i-Code Studio: A Configurable and Composable Framework for Integrative AI.](http://arxiv.org/abs/2305.13738) | i-Code Studio提供了一个综合、灵活和可组合的设置，可以使开发人员快速轻松地组合最先进的服务和技术，以解决复杂的多模态任务，是实现人工通用智能（AGI）的一种重要方法。 |
| [^38] | [Aligning Large Language Models through Synthetic Feedback.](http://arxiv.org/abs/2305.13735) | 该论文提出了一种使用合成反馈对齐大型语言模型的新框架，几乎不需要人力成本，也不依赖于预先对齐的LLMs。其中，通过对尺寸和提示等不同因素的普通 LLMS的响应进行奖励建模，来模拟高质量的示范来训练监督策略，并进一步使用强化学习优化模型。 |
| [^39] | [Self-Critique Prompting with Large Language Models for Inductive Instructions.](http://arxiv.org/abs/2305.13733) | 本研究提出了一个基准，名为INDust，用于评估大型语言模型（LLMs）对于包含错误信息的指令的抵抗能力。研究发现，当前的LLMs很容易被欺骗，因此采用自我批判提示的方法来激励LLMs不仅对自己进行批评，而且对用户进行批评。 |
| [^40] | [Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker.](http://arxiv.org/abs/2305.13729) | 本文提出了一种新的离散提示优化方法，称为受约束提示生成（Co-Prompt），通过估算最佳排序来引导 PLM 生成的文本朝向最优提示。实验结果表明，Co-Prompt 相对于基线方法表现出卓越的重排性能。 |
| [^41] | [Conversational Recommendation as Retrieval: A Simple, Strong Baseline.](http://arxiv.org/abs/2305.13725) | 本论文提出一种以检索方式进行的对话式推荐方法，将对话表示为查询，将物品表示为待检索的文档，并使用基于BM25的检索器进行推荐。相比于使用复杂的外部知识的基准线，该方法简单且更具优越性能。 |
| [^42] | [ChatGPT-EDSS: Empathetic Dialogue Speech Synthesis Trained from ChatGPT-derived Context Word Embeddings.](http://arxiv.org/abs/2305.13724) | 本文提出了一种使用 ChatGPT 提取对话上下文，实现具有情感的对话语音合成的方法。该方法使用 ChatGPT 衍生的上下文单词嵌入来训练模型，实验证明其性能相当于使用情感标签或神经网络衍生的上下文嵌入的方法。 |
| [^43] | [PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training.](http://arxiv.org/abs/2305.13723) | 提出了一种新的叫PromptClass的弱监督文本分类方法，通过利用提示增强学习，生成噪声鲁棒性更强的伪标签和自我训练。 |
| [^44] | [Continual Dialogue State Tracking via Example-Guided Question Answering.](http://arxiv.org/abs/2305.13721) | 本文建议将对话状态跟踪重构为由例子引导的粒度问题回答任务，以最小化服务之间的任务转移，获得持续的学习效益。通过结合简单的持续学习策略，可以在基准数据集上获得最先进的性能。 |
| [^45] | [LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large Language Models.](http://arxiv.org/abs/2305.13718) | 本文介绍了 LogicLLM，一种通过自监督后训练来提高大语言模型的逻辑推理能力的方法，该方法有效地在常见逻辑推理任务上进行表现，超过了目前最先进的无监督基线方法。 |
| [^46] | [BA-SOT: Boundary-Aware Serialized Output Training for Multi-Talker ASR.](http://arxiv.org/abs/2305.13716) | BA-SOT是一种面向多说话人ASR的训练方法，通过边界感知和连接时间分类策略，显著提高了模型的准确性和精度。 |
| [^47] | [CALLS: Japanese Empathetic Dialogue Speech Corpus of Complaint Handling and Attentive Listening in Customer Center.](http://arxiv.org/abs/2305.13713) | 这份论文介绍了一个日语语音语料库 - CALLS，它旨在将共情对话语音合成应用于客户服务中心的投诉处理和关注倾听领域。对于扩展该技术的应用范围，该语料库具有实际意义。 |
| [^48] | [Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models.](http://arxiv.org/abs/2305.13712) | 本文探索了大型语言模型对其自身知识的理解和测量不确定性的能力。该研究聚焦于解决“已知-未知”问题，提出了新的分类方案，并使用语义评估方法量化了模型表达不确定性的准确性。 |
| [^49] | [LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models.](http://arxiv.org/abs/2305.13711) | LLM-Eval是一种针对大型语言模型的开放领域对话的多维自动评估方法，其在一个模型调用中涵盖了多个对话质量维度，并提供了有效性、高效性和适应性，是评估开放领域对话系统的多功能强大解决方案。 |
| [^50] | [Using Textual Interface to Align External Knowledge for End-to-End Task-Oriented Dialogue Systems.](http://arxiv.org/abs/2305.13710) | 本文提出了一种使用文本界面对齐外部知识以消除繁琐过程的端到端任务导向对话系统的新范例，实验结果表明该方法生成了更自然的最终响应，并且相对于先前的模型实现了更大的任务成功率。 |
| [^51] | [Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models.](http://arxiv.org/abs/2305.13707) | 本文研究了商用语言模型API在多语言支持方面存在的问题，分析了标记化对API跨语言定价公平性的影响，并在22种语言中评估了OpenAI语言模型API。我们发现，一些地区的语言付费过高，而且结果较差。 |
| [^52] | [MemeCap: A Dataset for Captioning and Interpreting Memes.](http://arxiv.org/abs/2305.13703) | MemeCap是一个新的数据集，用于说明和解释Memes。 然而，即使是最先进的视觉和语言模型也难以应对Memes中的视觉隐喻，表现远远不如人类。 |
| [^53] | [Exploring Large Language Models for Classical Philology.](http://arxiv.org/abs/2305.13698) | 本论文探索使用RoBERTa和T5作为强大的语言模型类型的编码器和编码器-解码器架构，创建了古希腊语和拉丁语等多语言实例的四个古希腊语言模型。测试结果表明，这些模型在形态和句法任务上的表现都得到了显著的提升，并且多语言模型表现优于单语模型。 |
| [^54] | [UNIMO-3: Multi-granularity Interaction for Vision-Language Representation Learning.](http://arxiv.org/abs/2305.13697) | 本研究提出了 UNIMO-3 模型，具有多层次交互能力，能够更好地学习多模态语义信息的交互。 |
| [^55] | [Abstractive Text Summarization Using the BRIO Training Paradigm.](http://arxiv.org/abs/2305.13696) | 本文提出了一种新的BRIO训练范式，以减少摘要模型对参考摘要的依赖，并提高其推理性能。在VieSum数据集上的实验证明，BRIO训练范式可以在基本硬件上优化抽象摘要模型，并在越南文本摘要上取得更好的表现。 |
| [^56] | [Automated Metrics for Medical Multi-Document Summarization Disagree with Human Evaluations.](http://arxiv.org/abs/2305.13693) | 在医学文献综述的多文献摘要中，现有的自动评估指标与人工评估存在不一致性，需要更好的评估指标和数据集支持。 |
| [^57] | [Towards Asking Clarification Questions for Information Seeking on Task-Oriented Dialogues.](http://arxiv.org/abs/2305.13690) | 本文提出了一个名为MAS2S的多注意力Seq2Seq网络，它能够提问以澄清任务导向信息获取中用户的信息需求和个人资料。实验证明该模型在任务导向信息查询方面的准确性和覆盖范围优于现有模型。 |
| [^58] | [mPLM-Sim: Unveiling Better Cross-Lingual Similarity and Transfer in Multilingual Pretrained Language Models.](http://arxiv.org/abs/2305.13684) | mPLM-Sim是一种新的语言相似度测量方法，利用多语言平行语料库从mPLMs中引导出语言之间的相似性，可用于选择源语言以增强跨语言迁移，具有中等程度的相关性。不同的mPLMs和层产生不同的相似性结果。 |
| [^59] | [Error Detection for Text-to-SQL Semantic Parsing.](http://arxiv.org/abs/2305.13683) | 该论文提出了一种独立于解析器的文本到SQL语义解析的误差检测模型，该模型可以有效地提高解析器的性能和可用性，不考虑其架构。 |
| [^60] | [Towards Legally Enforceable Hate Speech Detection for Public Forums.](http://arxiv.org/abs/2305.13677) | 本研究提出了一个以法律定义为中心的、可法律强制执行的仇恨言论检测任务，利用法律专家对数据集进行了注释，结合基于零样本和小样本的提示，可以使模型的输出更符合监管者目标。 |
| [^61] | [Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.](http://arxiv.org/abs/2305.13675) | 本文评估了基础模型在跨越多种语言、主题和上下文来检索百科知识的能力，发现Meta的LLaMA模型准确率较高，但也存在不足之处，表明利用基础语言模型作为多语种工具的前景并不明显。 |
| [^62] | [Physics of Language Models: Part 1, Context-Free Grammar.](http://arxiv.org/abs/2305.13673) | 本研究探究了生成式语言模型如何学习上下文无关文法（CFG），并通过构造人造数据证明了预训练transformers可以学会生成具有接近完美准确度和显着多样性的句子。研究发现transformer内部的隐藏状态隐含而精确地编码了CFG结构，学会形成类似动态规划的“边界到边界”的注意力。此外，还研究了标准CFG的扩展，例如概率CFG和线性CFG，并证明transformers也可以学会这些扩展语法结构。 |
| [^63] | [Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment.](http://arxiv.org/abs/2305.13669) | 本文提出了MixAlign框架，通过与用户和知识库交互，实现自动的问题-知识对齐，从而解决了语言模型因无法正确理解问题和知识而导致的幻觉问题。 |
| [^64] | [Grounding and Distinguishing Conceptual Vocabulary Through Similarity Learning in Embodied Simulations.](http://arxiv.org/abs/2305.13668) | 本论文提出了一种新的方法，利用具体模拟中的智能体经验将上下文化的词向量接地到物体表示中。结果发现接地对象标记向量比接地动词和属性标记向量更有帮助。 |
| [^65] | [Optimizing Non-Autoregressive Transformers with Contrastive Learning.](http://arxiv.org/abs/2305.13667) | 本文通过从模型分布中采样来缓解NATs学习多模态数据分布的困难，并导出对比约束来稳定训练过程。该方法在机器翻译、文本摘要和改写三个任务上优于以前的非自回归基线。 |
| [^66] | [On the Risk of Misinformation Pollution with Large Language Models.](http://arxiv.org/abs/2305.13661) | 本文探讨了大型语言模型（LLM）可能误用的潜在风险，指出LLM可以作为有效的误导性信息生成器，导致开放域问答（ODQA）系统性能显著降低，并尝试提出三种防御策略：提示，误报检测和大多数投票。 |
| [^67] | [Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning.](http://arxiv.org/abs/2305.13660) | GDP-Zero是一种使用Open-Loop MCTS进行目标导向对话策略规划而不需要任何模型训练的方法，并使用大型语言模型作为策略先验、价值函数、用户模拟器和系统模型，在目标导向任务中优于ChatGPT。 |
| [^68] | [Understanding compositional data augmentation in automatic morphological inflection.](http://arxiv.org/abs/2305.13658) | 本研究揭示了自动词形变化中的数据增强策略StemCorrupt带来的根本性变化，并证明选择高多样性和高预测不确定性的数据点子集是提高其数据效率的有效方法。同时，StemCorrupt能够学习可推广的词形规则。 |
| [^69] | [ChatGPT as your Personal Data Scientist.](http://arxiv.org/abs/2305.13657) | ChatGPT框架作为一种个人数据科学家，可以利用自然对话界面协助用户进行自动化机器学习任务。 |
| [^70] | [Understanding and Mitigating Spurious Correlations in Text Classification.](http://arxiv.org/abs/2305.13654) | 本文研究了深度学习模型容易利用训练集中存在但通常不成立的伪相关性的问题，并提出了一种邻域分析框架以解释语言模型如何利用伪相关性。通过一系列正则化方法NFL（不要忘记你的语言）避免了这种情况，并在实验中证明了其鲁棒性方面的显著改进。 |
| [^71] | [Cross-lingual Knowledge Transfer and Iterative Pseudo-labeling for Low-Resource Speech Recognition with Transducers.](http://arxiv.org/abs/2305.13652) | 本文探讨了两种新技术（跨语言知识转移和迭代伪标记）如何提高低资源语音识别系统的识别准确性，并使用这些技术提高了Transducer基础ASR系统的性能。 |
| [^72] | [Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine Translation.](http://arxiv.org/abs/2305.13648) | 本文探究了如何利用kNN预测的统计信息来改善fine-tuning阶段的机器翻译模型表现，通过不同的方法整合kNN统计信息，成功地提高了BLEU分数。 |
| [^73] | [Detecting and Mitigating Hallucinations in Multilingual Summarisation.](http://arxiv.org/abs/2305.13632) | 本文提出一种新的度量方法mFACT，可以在非英语摘要中评估其忠实性。本文还提出了一种简单有效的加权方法，可以通过跨语言转移减少摘要的幻觉问题。 |
| [^74] | [EDIS: Entity-Driven Image Search over Multimodal Web Content.](http://arxiv.org/abs/2305.13631) | 这篇论文介绍了EDIS数据集，该数据集包括100万个多模态图像和文本配对，旨在鼓励开发实现跨模态信息融合和匹配的检索模型。 |
| [^75] | [Improving Self-training for Cross-lingual Named Entity Recognition with Contrastive and Prototype Learning.](http://arxiv.org/abs/2305.13628) | 本文提出了一种名为ContProto的方法，通过对比自我训练和基于原型的伪标记，结合表示学习和伪标签精化，在一个一致的框架中提高了跨语言命名实体识别的自训练方法；实验结果表明，ContProto 方法在多个转移对上优于最先进的基准，并在各种基准上取得了显着的改进。 |
| [^76] | [Instruct-Align: Teaching Novel Languages with to LLMs through Alignment-based Cross-Lingual Instruction.](http://arxiv.org/abs/2305.13627) | Instruct-Align提出了基于对齐的跨语言教学调整框架，使得教学调整的LLMs能够学习新语言，且不会发生灾难性遗忘。 |
| [^77] | [Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration.](http://arxiv.org/abs/2305.13626) | 本研究针对大型语言模型的对话系统，针对澄清、目标导向和非协作对话，提出了Proactive Chain-of-Thought提示方案，以增强系统的主动性能力，为未来研究提供了经验结果。 |
| [^78] | [Validating Multimedia Content Moderation Software via Semantic Fusion.](http://arxiv.org/abs/2305.13623) | 该论文提出了一种名为“Semantic Fusion”的通用有效方法，通过融合两个或多个不同模态的内容审核模型来提高多媒体内容审核软件的验证效果。该方法经过大规模多媒体内容审核数据集的评估，相比现有方法显著提高了验证结果。 |
| [^79] | [SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres.](http://arxiv.org/abs/2305.13617) | 这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。 |
| [^80] | [LLM-empowered Chatbots for Psychiatrist and Patient Simulation: Application and Evaluation.](http://arxiv.org/abs/2305.13614) | 本研究聚焦于探索利用ChatGPT技术赋能聊天机器人在精神病医生和患者模拟方面的潜力，并证明了在精神科场景中使用ChatGPT技术赋能聊天机器人的可行性。 |
| [^81] | [ReSee: Responding through Seeing Fine-grained Visual Knowledge in Open-domain Dialogue.](http://arxiv.org/abs/2305.13602) | 该研究提供了一种新的构建多模态对话的范例，并提供了两个相关数据集，将视觉知识明确分类为更细粒度来增强准确性和多样性，从互联网或大型图像数据集中检索视觉信息。该研究提出了ReSee框架，可将视觉表示添加到原始对话模型中。 |
| [^82] | [Decoupled Rationalization with Asymmetric Learning Rates: A Flexible Lipshitz Restraint.](http://arxiv.org/abs/2305.13599) | 本文提出了一种名为DR的灵活的方法，它通过不对称的学习率来解决由合作博弈引发的退化问题，该方法能够在两个基准测试中显著改善表现。 |
| [^83] | [Understanding Programs by Exploiting (Fuzzing) Test Cases.](http://arxiv.org/abs/2305.13592) | 本文提出了通过模糊测试获取代表性输入来帮助语义理解程序的方法。 |
| [^84] | [BiasX: "Thinking Slow" in Toxic Content Moderation with Explanations of Implied Social Biases.](http://arxiv.org/abs/2305.13589) | BiasX是一个框架，通过输入自由文本解释的隐含社会偏见来提高内容审核的质量。经过大规模的用户研究，我们展示了解释对于准确识别建议的有害内容的微妙程度有很大的帮助。机器生成的解释仅能提高2.4％的有效性，而人工撰写的解释能够提高7.2％的有效性。 |
| [^85] | [Query Structure Modeling for Inductive Logical Reasoning Over Knowledge Graphs.](http://arxiv.org/abs/2305.13585) | 本研究提出了一种基于查询结构建模的文本编码框架，用于在不完整的知识图谱上进行归纳逻辑推理。通过针对复杂查询的结构建模和单独对不同的几何操作进行建模，它在提高泛化能力的同时实现了更准确的答案匹配。 |
| [^86] | [Cross-Attention is Not Enough: Incongruity-Aware Multimodal Sentiment Analysis and Emotion Recognition.](http://arxiv.org/abs/2305.13583) | 本文提出了一种基于不协调感知的跨模态情感分析方法，通过Hierarchical Crossmodal Transformer with Modality Gating(HCT-MG)模型来确定主要模态并分层融合辅助模态，有效减轻模态之间的不协调感知和信息冗余问题。 |
| [^87] | [Better Low-Resource Entity Recognition Through Translation and Annotation Fusion.](http://arxiv.org/abs/2305.13582) | 本研究提出了一种通过翻译和注释融合的框架，可以改进低资源语言文本的命名实体识别。通过TransFusion模型，可以在不同语言之间进行强大的预测，且在两个低资源命名实体识别数据集上表现一致优秀。 |
| [^88] | [Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings.](http://arxiv.org/abs/2305.13571) | 该论文展示了在无位置嵌入的Transformer语言模型的自注意力方差中存在潜在的位置信息，并证明丢弃位置嵌入的决策可促进Transformer语言模型的更有效预训练。 |
| [^89] | [EntRED: Benchmarking Relation Extraction with Fewer Shortcuts.](http://arxiv.org/abs/2305.13551) | 本研究提出了一个名称更为多样、没有捷径、具有挑战性的关系提取基准测试EntRed，并解决了标准基准测试数据集存在的实体注释错误、实体名称多样性较低、从实体名称到基本事实关系的捷径等问题。 |
| [^90] | [Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot Text Classification Tasks.](http://arxiv.org/abs/2305.13547) | 论文提出了一种基于自我进化学习的 Mixup 方法，用于文本分类的数据扩充，可以为模型训练生成更加适应和友好的伪样本，该方法可以降低模型的overconfidence。 |
| [^91] | [Improving Classifier Robustness through Active Generation of Pairwise Counterfactuals.](http://arxiv.org/abs/2305.13535) | 本论文提出一种利用反事实生成模型来主动抽样生成大量不同的反事实数据，并自动标记它们的框架。通过训练一个成对分类器来插值原始样例和反事实数据之间的关系，可以更正确地标记生成的反事实数据，从而显著提高自然语言分类器的鲁棒性。 |
| [^92] | [How Language Model Hallucinations Can Snowball.](http://arxiv.org/abs/2305.13534) | 语言模型在生产中容易产生幻觉错误，这些幻觉会导致模型产生更多的错误，并且模型可以自行识别其中的一些错误。 |
| [^93] | [Open-world Semi-supervised Generalized Relation Discovery Aligned in a Real-world Setting.](http://arxiv.org/abs/2305.13533) | 本文提出了一种新的开放世界关系抽取方法，能够在已知类和新颖类中进行显式和隐式表示的关系分类，在真实场景数据的特征下进行了两个关键改进。 |
| [^94] | [The Grammar and Syntax Based Corpus Analysis Tool For The Ukrainian Language.](http://arxiv.org/abs/2305.13530) | StyloMetrix是一种基于语法和句法的文本挖掘工具，可分析乌克兰语的语法、文体和句法模式，适用于文本分类任务。 |
| [^95] | [Transfer-Free Data-Efficient Multilingual Slot Labeling.](http://arxiv.org/abs/2305.13528) | 本论文提出了一种无需英文数据的多语言数据高效标记方法，结果显示其比跨语言转移基准显着提高（最多提高22%）。 |
| [^96] | [Aligning the Norwegian UD Treebank with Entity and Coreference Information.](http://arxiv.org/abs/2305.13527) | 本文将挪威两种书写形式语料库中的实体和共指标注数据合并到了通用依存语料库（UD treebanks）中，这是第一个加入实体和共指信息的挪威UD treebank，对未来语料库对齐和共指注释工作有帮助。 |
| [^97] | [A Study of Generative Large Language Model for Medical Research and Healthcare.](http://arxiv.org/abs/2305.13523) | 本研究开发了一种临床生成式语言模型——GatorTronGPT，它改善了生物医学自然语言处理，使用它训练的合成NLP模型性能优于使用真实临床文本训练的NLP模型，医生也无法区分它和真实临床文本的差异。 |
| [^98] | [CEO: Corpus-based Open-Domain Event Ontology Induction.](http://arxiv.org/abs/2305.13521) | 本文介绍了一种名为CEO的事件本体诱导模型，它可以放松预定义事件本体所强加的限制，通过远程监督检测整个语料库中显著的事件，并诱导具有有意义名称的分层事件本体，实验结果表明，其诱导的模式具有更好的覆盖范围和更高的准确性。 |
| [^99] | [Scaling Speech Technology to 1,000+ Languages.](http://arxiv.org/abs/2305.13516) | 该论文介绍了Massively Multilingual Speech (MMS)项目，该项目通过新的数据集和自监督学习的方法将受支持的语言数量增加了10-40倍。实验表明，MMS的多语种语音识别模型可以在FLEURS基准测试的54种语言上将单词错误率降至一半以上。 |
| [^100] | [Small Language Models Improve Giants by Rewriting Their Outputs.](http://arxiv.org/abs/2305.13514) | 本论文提出了一种方法，通过使用小语言模型重写大语言模型的输出，从而提高其性能。实验证明，该方法可以显着改善大语言模型的少样本学习能力和泛化性能。 |
| [^101] | [Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding.](http://arxiv.org/abs/2305.13512) | 本文评估了几个大型预训练语言模型在口语理解任务中的表现，发现最大模型可以在零-shot学习和上下文学习中达到与监督模型相近的意图分类准确度，但在槽填充方面表现不佳，且对ASR错误敏感。 |
| [^102] | [Multimodal Automated Fact-Checking: A Survey.](http://arxiv.org/abs/2305.13507) | 本调查提出了一个多模态自动事实核查的框架，并包括了独特的子任务，重点关注了文本，图像，音频和视频这四种模态的现实应用。纪录了相关的基准模型，讨论了未来研究的局限性和前景。 |
| [^103] | [Neural Machine Translation for Code Generation.](http://arxiv.org/abs/2305.13504) | 该论文概述了神经机器翻译（NMT）在代码生成中的应用。该应用涵盖了各种各样的输入情况和约束条件。本文回顾了已探索的多种方法，并讨论了目前方法的局限性和未来的研究方向。 |
| [^104] | [Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefixes.](http://arxiv.org/abs/2305.13499) | 本文提出了一种基于前缀的方法，用于学习带有源任务的固定文本表示。独立地学习每个源任务的任务特定前缀，并将它们组合成最终表示，以解决如何学习易于更新、适用广泛的通用文本表示的挑战。 |
| [^105] | [Flover: A Temporal Fusion Framework for Efficient Autoregressive Model Parallel Inference.](http://arxiv.org/abs/2305.13484) | Flover是一种用于自回归模型并行推断的时间融合框架，解决了并行性不足和灵活性差的问题，可以实现更加高效的推断性能。 |
| [^106] | [Automatic Readability Assessment for Closely Related Languages.](http://arxiv.org/abs/2305.13478) | 本研究探索了如何通过语言方面（如相互智能性或语言相关性）来提高低资源语言中的自动可读性评估，并使用三种菲律宾语言的短篇小说来训练模型，发现应用专业特征CrossNGO可以改善ARA。 |
| [^107] | [MAILEX: Email Event and Argument Extraction.](http://arxiv.org/abs/2305.13469) | 本文提出了针对邮件领域的事件抽取数据集\dataset，比较了序列标记和生成式端到端抽取的方法，结果表明该任务存在非连续共享触发器跨度、非命名实体参数和邮件会话历史等难点，未来需要更多研究。 |
| [^108] | [clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents.](http://arxiv.org/abs/2305.13455) | 本论文探讨了大型语言模型在接触具有挑战性的受限游戏式环境下，能否有意义地评估它们的能力。作为概念验证，研究了五种交互设置，表明当前的聊天优化LLMs在一定程度上能够遵循游戏玩法指令。这对于将LLMs开发为具有广泛适用性的对话代理人具有启示作用。 |
| [^109] | [Interpreting Transformer's Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT.](http://arxiv.org/abs/2305.13417) | 本文提出了一种将Transformer模型的权重和隐藏状态投影到其词汇表中解释模型的方法，并分析了注意力机制内部信息流的模式。文章还介绍了一个可视化工具，将GPT的前向传递可视化为交互式流图，简化了大量数据为易于阅读的图表，展示了其语义信息流。 |
| [^110] | [Syntactic Knowledge via Graph Attention with BERT in Machine Translation.](http://arxiv.org/abs/2305.13413) | 该论文提出了一种在机器翻译中使用图注意力和BERT来表示句法依赖关系的方法，可以丰富源语言表示并引导目标语言生成，经实验证实该方法能够在不影响BLEU分数的情况下改善翻译质量。 |
| [^111] | [Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method.](http://arxiv.org/abs/2305.13412) | 通过新的元素感知测试集为自动文摘提供更细粒度的参考摘要，使用 LLMS 以零-shot方式生成摘要，提出 SumCoT 技术以改进连贯性和相关性，并在多个数据集上进行实验，为推荐场景中的用户意图理解提供了7％的准确率改善。 |
| [^112] | [Modular Domain Adaptation for Conformer-Based Streaming ASR.](http://arxiv.org/abs/2305.13408) | 论文提出了一种名为模块化领域适应的框架，使单个Conformer模型处理多领域数据，同时保持参数领域特异性，通过在Conformer编码器中添加每个领域的适配器和逐领域的前馈网络，可以在不重新训练多领域模型的情况下在其他领域（如语音搜索和听写）中达到类似的性能。 |
| [^113] | [DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules.](http://arxiv.org/abs/2305.13406) | DADA是一种适用于多个方言，基于语言规则的动态聚合适配器，可为SAE训练的模型赋予多方言鲁棒性，同时针对特定方言变体进行适应，提供了一种可解释的方言适应性框架。 |
| [^114] | [GATology for Linguistics: What Syntactic Dependencies It Knows.](http://arxiv.org/abs/2305.13403) | 本文探究了使用GAT和BERT等预训练模型在机器翻译场景中建模句法知识的方法。实验表明，通过适当的层数和关注头数量，可以实现更好的性能。此外，相对于MT-B，GAT在下游MT任务中的语法建模方面略微更好。 |
| [^115] | [A study of conceptual language similarity: comparison and evaluation.](http://arxiv.org/abs/2305.13401) | 本文研究了一种新的定义语言相似度的方法，该方法基于语言如何表示基本概念，而非常规的词汇或类型学特征。我们在二元分类任务上对其进行了评估。 |
| [^116] | [BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance.](http://arxiv.org/abs/2305.13395) | 该论文引入了BioDEX，它是一个大型资源，用于生物医学不良药物事件提取，可在真实世界中改进药物安全监测。 |
| [^117] | [The neural dynamics of auditory word recognition and integration.](http://arxiv.org/abs/2305.13388) | 该论文研究了听觉单词识别和整合的神经动态，提出了一个计算模型解释了这一过程，发现对于需要超过大约100ms的输入才能被识别的单词，神经响应会被放大。 |
| [^118] | [Can LLMs facilitate interpretation of pre-trained language models?.](http://arxiv.org/abs/2305.13386) | 该论文提出使用大型语言模型ChatGPT作为注释器以便对预训练语言模型进行细粒度解释分析，发现ChatGPT产生了更准确和语义更丰富的注释。同时，基于GPT注释的解释分析方法可以帮助进一步探索和实验。 |
| [^119] | [On the Limitations of Simulating Active Learning.](http://arxiv.org/abs/2305.13342) | 研究提出了主动学习模拟的局限性，并警告基于模拟实验结果得出强烈结论可能导致评估AL算法的误导。 |
| [^120] | [Gene Set Summarization using Large Language Models.](http://arxiv.org/abs/2305.13338) | 该论文介绍了一种使用大型语言模型来对基因集进行函数概括的方法，名为SPINDOCTOR，可以提供比传统方法更好的性能和可解释性。 |
| [^121] | [A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning.](http://arxiv.org/abs/2305.13331) | 本文通过使用最先进的语音识别技术和AphsiaBank数据集，提出了失语症语音识别和检测的新基准。我们的系统实现了最先进的说话人级别检测准确率(97.3%)，并相对于中度失语症患者的WER降低了11%。我们的方法还可应用于其他语音数据库，促进失语症语音处理的进步。 |
| [^122] | [Unsupervised ASR via Cross-Lingual Pseudo-Labeling.](http://arxiv.org/abs/2305.13330) | 本研究提出了一种基于跨语言伪标注的无监督ASR方法，能够使用其他语言中的标注数据来引导新语言的无监督AM。在Common Voice上取得了良好的效果，可以实现18% WER。而且在不同语言的数据集上都优于基线模型。 |
| [^123] | [A Novel Dataset Towards Extracting Virus-Host Interactions.](http://arxiv.org/abs/2305.13317) | 这份论文介绍了一个新的数据集，用于自动识别有关病毒与宿主相互作用的实体，提出该数据集可作为未来模型训练的黄金标准。该工作为自动从科学出版物中提取与主机-病原体检测方法相关的信息迈出了第一步，并自动预测了与人类健康相关的重要概念“病毒跨界传播风险”。 |
| [^124] | [Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate Speech Detection.](http://arxiv.org/abs/2305.13276) | 本研究评估了跨11种语言级别上ChatGPT模型在检测仇恨言论中的优势和劣势，揭示了模型复杂的故障，并指出生成模型在某些类型的仇恨言论检测方面的不足，为未来开发更强大的仇恨言论检测系统提供了见解。 |
| [^125] | [SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations.](http://arxiv.org/abs/2305.13235) | 这篇论文介绍了SparseFit，一种少样本刺激的稀疏微调策略，用于联合生成预测和自然语言解释。该方法可以在只有少量自然语言解释可用时生成高质量的自然语言解释。 |
| [^126] | [GPT-SW3: An Autoregressive Language Model for the Nordic Languages.](http://arxiv.org/abs/2305.12987) | GPT-SW3是面向北欧语言的第一个本地化大型生成语言模型，本文介绍了其开发过程，可作为其他研究人员开发面向较小语言的大型生成模型的指南和参考。 |
| [^127] | [Beyond Words: A Comprehensive Survey of Sentence Representations.](http://arxiv.org/abs/2305.12641) | 本文综述了不同的句子表示学习方法，包括传统和基于深度学习技术的方法。突出该领域的主要贡献和挑战，并强调句子表示学习的进展和未来的研究方向。 |
| [^128] | [Multilingual Simplification of Medical Texts.](http://arxiv.org/abs/2305.12532) | 本研究介绍了MultiCochrane，这是医学领域中第一个句子对齐的多语言文本简化数据集，通过多语言简化直接将复杂文本简化为多种语言的简化文本。 |
| [^129] | [Evaluating the Performance of Large Language Models on GAOKAO Benchmark.](http://arxiv.org/abs/2305.12474) | 本文介绍了一个基于高考考试问题的基准测试GAOKAO-Benchmark，用于评估大型语言模型在客观和主观问题方面的表现。通过对ChatGPT模型的评估，研究发现其在客观问题方面表现出色，同时也揭示了其不足之处和改进的方向。 |
| [^130] | [Hedges in Bidirectional Translations of Publicity-Oriented Documents.](http://arxiv.org/abs/2305.12146) | 本文研究了宣传性文件翻译中的措辞处理问题，发现政治文本中的措辞在英文中出现更频繁，且翻译方向影响措辞使用频率和翻译策略。同时还观察到了措辞在历时方面的增加。 |
| [^131] | [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings.](http://arxiv.org/abs/2305.11853) | 本文针对引导LLMs进行文本到SQL的任务中提示文本构建问题展开了综合探究，从而为未来的研究提供了见解。 |
| [^132] | [Evaluating task understanding through multilingual consistency: A ChatGPT case study.](http://arxiv.org/abs/2305.11662) | 本文提出了一种新的评估大型语言模型理解能力的范例，通过评估模型自身生成的不同意义之间的一致性，探讨了多语言自我一致性作为模型理解的检验方法，同时证明了ChatGPT在多语言一致性方面的优秀性能。 |
| [^133] | [Learning In-context Learning for Named Entity Recognition.](http://arxiv.org/abs/2305.11038) | 本文提出了一种在 PLMs 中注入上下文 NER 能力的方法，只需少量示意实例即可动态识别新类型的实体，在几个基准数据集上达到了最先进的性能。 |
| [^134] | [Language Models Meet World Models: Embodied Experiences Enhance Language Models.](http://arxiv.org/abs/2305.10626) | 本文提出一种新的增强语言模型的方法——将其与世界模型相结合，通过有目的的规划和随机探索获得丰富的实体经验进行微调, 以提高其在物理环境下的推理和行为能力，并在语言基准上保持或提高性能。 |
| [^135] | [A Better Way to Do Masked Language Model Scoring.](http://arxiv.org/abs/2305.10588) | 本文提出了一种更好的掩码语言模型评分方法，即PLL-word-l2r，用于估计句子的伪对数似然得分，相对于原PLL方法和屏蔽所有单词标记的PLL评分方法，改进的度量方法更好地针对字汇外单词得分问题进行了解决。 |
| [^136] | [Evaluating Object Hallucination in Large Vision-Language Models.](http://arxiv.org/abs/2305.10355) | 本研究是对大型视觉-语言模型中的物体幻觉问题进行的第一项系统研究，通过研究发现视觉指令可能影响幻觉，提出新的评估指标成功解决了现有评估方法的不足。 |
| [^137] | [Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models.](http://arxiv.org/abs/2305.10276) | 本文提出了自然语言规划（NLP）的基准，旨在研究LLMs在需要理解并在文本中相应进行操作的复杂规划任务中的表现。同时提出了一种新方法CoS，使用简化的符号空间表示法来表示复杂的环境。 |
| [^138] | [LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development.](http://arxiv.org/abs/2305.07507) | 本文对面向法律的预训练语言模型进行了详细分析，发布了一个跨国英语法律文集和一个法律知识探针基准，发现探针性能与上游性能强相关，下游性能主要由模型的大小和先前的法律知识驱动。 |
| [^139] | [When the Majority is Wrong: Leveraging Annotator Disagreement for Subjective Tasks.](http://arxiv.org/abs/2305.06626) | 本文通过预测单个标注者的打分，并结合文本目标群体的预测，模拟了目标群体成员的意见，通过使用他们的人口统计学数据和在线意见预测标注者的打分，在仇恨言论检测等主观任务中提高了模型性能。 |
| [^140] | [Putting Natural in Natural Language Processing.](http://arxiv.org/abs/2305.04572) | 自然语言处理领域过于重视书面语言，应该将口语作为主要交流方式纳入考虑，真正的自然语言处理可以超越文本，与其他语言科学更好地整合，实现更高效、更像人类的系统。 |
| [^141] | [Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements.](http://arxiv.org/abs/2305.03695) | 本文提出了Vera模型，它是一个通用模型，可以基于常识知识估计陈述性语句的可信度。在解决验证格式的常识问题时，Vera明显优于现有的模型，并展现了对未见任务的泛化能力和良好的标定输出。 |
| [^142] | [Automated Code generation for Information Technology Tasks in YAML through Large Language Models.](http://arxiv.org/abs/2305.02783) | 这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。 |
| [^143] | [Answering Questions by Meta-Reasoning over Multiple Chains of Thought.](http://arxiv.org/abs/2304.13007) | 本论文提出了基于元推理的Multi-Chain Reasoning (MCR)方法，该方法检查多个推理链，混合它们之间的信息并选择最相关的事实，从而超越多链思维，解决多跳QA问题。 实验结果表明MCR胜过多个强基线，解释质量高。 |
| [^144] | [Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology.](http://arxiv.org/abs/2304.11957) | 本研究评估了ChatGPT-4在放射肿瘤学方面的表现，成绩显示出它在医学考试上有很大的优势，在实际应用中存在局限性。另外，ChatGPT-4 在放射肿瘤学上表现出色，但在骨骼和软组织以及妇科方面有待改进。 |
| [^145] | [Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems.](http://arxiv.org/abs/2304.11090) | 本文提出了一个以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统，重点关注可解释性、公平性、安全性和鲁棒性等关键设计元素。 |
| [^146] | [Large language models effectively leverage document-level context for literary translation, but critical errors persist.](http://arxiv.org/abs/2304.03245) | 该研究通过人工评估发现，大型语言模型在进行文学段落翻译时会利用更多的文档级上下文，从而减少关键错误。然而，一些与上下文和意义相关的错误仍然存在。 |
| [^147] | [Affect as a proxy for literary mood.](http://arxiv.org/abs/2304.02894) | 该研究提出使用情感作为文学文本情绪的代理，并能通过扩展情感词典在考虑文本语义转移和领域的前提下，提供近期和现代分析的实际可行结果。 |
| [^148] | [A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube.](http://arxiv.org/abs/2303.16281) | 研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。 |
| [^149] | [DeltaScore: Evaluating Story Generation with Differentiating Perturbations.](http://arxiv.org/abs/2303.08991) | DeltaScore利用差分扰动来评估故事生成的细粒度方面，并通过计算故事在特定方面扰动前后的可能性差异来衡量影响。该方法在多个故事领域中得到了评估，并与人类判断的相关性进行了研究。 |
| [^150] | [MUX-PLMs: Data Multiplexing for High-throughput Language Models.](http://arxiv.org/abs/2302.12441) | 该论文开发了一种名为MUX-PLMs的高吞吐量预训练语言模型，使用数据复用训练，可用于高性能的MIMO样式语言模型推断。 |
| [^151] | [Active Prompting with Chain-of-Thought for Large Language Models.](http://arxiv.org/abs/2302.12246) | 本论文提出了一种新的方法Active-Prompt，它使用任务特定的示例提示适应大型语言模型中的不同任务，提高模型性能与效率。 |
| [^152] | [ChatGPT: Jack of all trades, master of none.](http://arxiv.org/abs/2302.10724) | 本研究检验了 ChatGPT 在 25 个不同的 NLP 任务上的性能，它是一个万能的 AI 模型，但无关紧要的表现可能会对某些任务的表现产生负面影响。 |
| [^153] | [Semi-Structured Object Sequence Encoders.](http://arxiv.org/abs/2301.01015) | 本文提出了一种半结构化物体序列编码器，通过编码键的值的表示并自我关注这些键以完成下游任务来解决长对象序列的问题。 |
| [^154] | [ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models.](http://arxiv.org/abs/2212.10474) | 本研究提出了一种基于无记号言语模型的端到端诗歌生成模型ByGPT5，并成功地应用于韵律、节律和头韵等风格的诗歌生成，取得了较好的性能表现。 |
| [^155] | [Large Language Models are reasoners with Self-Verification.](http://arxiv.org/abs/2212.09561) | 本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。 |
| [^156] | [Multi-View Knowledge Distillation from Crowd Annotations for Out-of-Domain Generalization.](http://arxiv.org/abs/2212.09409) | 本文提出了一种新方法，通过聚合多个视图的众包注释来获取软标签，从而进行跨领域泛化。 |
| [^157] | [The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources in Natural Language Understanding Systems.](http://arxiv.org/abs/2212.08192) | 本文提出了一个KITMUS测试套件，用于评估自然语言理解模型对多源知识进行整合和推理的能力，在测试中的核心子任务需要进行针对多个事实的推理。实验结果表明，许多模型难以实时进行推理。 |
| [^158] | [MM-SHAP: A Performance-agnostic Metric for Measuring Multimodal Contributions in Vision and Language Models & Tasks.](http://arxiv.org/abs/2212.08158) | 该论文提出了一种性能不可知的多模态得分方法MM-SHAP，可以可靠地量化多模态模型使用各自模态的比例，并应用于比较模型的平均多模态程度和衡量个体模型的贡献。实验结果表明单模态崩溃比以前认为的更为普遍，而MM-SHAP是分析VL模型多模态行为的有效工具。 |
| [^159] | [Robustness of Learning from Task Instructions.](http://arxiv.org/abs/2212.03813) | 本文提出了一种鲁棒的方法来从任务说明中学习，以处理说明的变化并提高对新任务的泛化能力。 |
| [^160] | [KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning.](http://arxiv.org/abs/2211.16773) | 本文提出了一种新的训练算法，KRLS，该算法通过关键词强化学习和精细的奖励函数来帮助模型在任务导向对话中生成关键词，实验结果显示，该算法在MultiWoZ基准数据集上取得了最先进的表现。 |
| [^161] | [Prompted Opinion Summarization with GPT-3.5.](http://arxiv.org/abs/2211.15914) | 本文展示了使用GPT-3.5模型实现意见摘要的方法，通过递归摘要和显著内容选择的方式来处理大量用户评论，并使用三个新的评估指标来评估性能。 |
| [^162] | [In-sample Curriculum Learning by Sequence Completion for Natural Language Generation.](http://arxiv.org/abs/2211.11297) | 本文提出了一种在自然语言生成任务中的课程学习方法，通过序列补全的方式逐步训练模型，该方法具有很好的推广能力且在实验中表现出显著的改进。 |
| [^163] | [UGIF: UI Grounded Instruction Following.](http://arxiv.org/abs/2211.07615) | 该论文提出了一个多语言、多模态的 UI 视觉引导数据集，旨在通过将指令步骤与 UI 视频相结合，帮助智能手机用户更轻松地完成任务。 |
| [^164] | [miCSE: Mutual Information Contrastive Learning for Low-shot Sentence Embeddings.](http://arxiv.org/abs/2211.04928) | 本文提出了miCSE框架，使用互信息对比学习在少样本情况下学习句子嵌入，在多个基准测试中均表现出卓越结果，并为更加鲁棒的自监督学习方法开辟了新的途径。 |
| [^165] | [Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese.](http://arxiv.org/abs/2211.01335) | 本研究构建了一个大规模的中文图像-文本对数据集，新提出的两阶段预训练方法提高了模型性能，中文CLIP在多任务图像理解中取得最先进的性能表现，特别在零样本学习和微调设置下表现出色。 |
| [^166] | [Exploring Train and Test-Time Augmentations for Audio-Language Learning.](http://arxiv.org/abs/2210.17143) | 本研究揭示了数据增强对音频语言多模态学习的重要性。作者提出了音频语言配对增强和多层测试增强方法，成功地将它们与单模态增强结合起来，在自动化音频字幕和音频文本检索任务中取得了显著的进展。 |
| [^167] | [Task-Aware Specialization for Efficient and Robust Dense Retrieval for Open-Domain Question Answering.](http://arxiv.org/abs/2210.05156) | TASER是一种新的架构，使得密集检索器能够在参数低的情况下实现更高的准确性，超过了传统的BM25；实验表明TASER也更具鲁棒性。 |
| [^168] | [ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models.](http://arxiv.org/abs/2210.04325) | 该论文提出了一种名为ASDOT的新方法，可以通过利用任何给定或没有样本进行数据到文本的生成。该方法由两个步骤组成，其使用预训练语言模型进行解决，并可适用于各种不同的场景。 |
| [^169] | [A Study on the Efficiency and Generalization of Light Hybrid Retrievers.](http://arxiv.org/abs/2210.01371) | 本文研究了光轻混合召回器的效率和泛化性能，提出了一种采用索引高效的密集召回器和LITE召回器相结合的方法，相对于传统方法可以节省内存。实验证明，该方法可以在不牺牲性能的情况下显著提高模型的泛化性能。 |
| [^170] | [Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks.](http://arxiv.org/abs/2210.00185) | Zemi是一种零样本半参数语言模型，使用外部检索器增强语言模型，可以在广泛的未见过的任务上展示出强大的零样本性能，比参数模型表现更好。 |
| [^171] | [Stateful Memory-Augmented Transformers for Efficient Dialogue Modeling.](http://arxiv.org/abs/2209.07634) | 本文提出了一种记忆增强变压器，它可以高效地保存对话历史信息，并且在对话生成任务中表现出卓越的性能。 |
| [^172] | [CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models.](http://arxiv.org/abs/2205.12213) | 本论文提出了一种 CombLM 方法，通过小型微调模型调整大型黑盒语言模型以适应新领域和任务，且不需要访问它们的权重或中间激活。实验证明在多个领域和下游任务中，性能得到提高。 |
| [^173] | [Contextualized Semantic Distance between Highly Overlapped Texts.](http://arxiv.org/abs/2110.01176) | 本文旨在解决自然语言处理任务中，覆盖文本之间语义距离评估的传统挑战。通过掩码和预测策略，本文提出了邻近分布散度（NDD）来表示重叠部分的语义距离。实验结果表明，NDD对于各种语义差异更为敏感。 |

# 详细

[^1]: 保持知识不变性：重新思考开放信息抽取的鲁棒性评估

    Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction. (arXiv:2305.13981v1 [cs.CL])

    [http://arxiv.org/abs/2305.13981](http://arxiv.org/abs/2305.13981)

    本文提出了第一个模拟评估开放式信息提取模型在真实世界中的基准测试，并通过判断模型在整个团体上的表现是否始终准确来评估模型的鲁棒性。

    

    鲁棒性是确保自然语言处理模型能够成功应用于现实世界中的关键因素，特别是对于信息抽取任务而言。然而，大多数先前的评估基准都专注于验证配对匹配的正确性，忽略了关键的鲁棒性测量。在本文中，我们提出了第一个基准测试，模拟在真实世界中评估开放式信息提取模型的情况，其中同一知识含义的句法和表达分布会各不相同。我们设计和注释了一个大规模的测试平台，其中每个示例都是一个知识不变的团体，由具有相同含义但结构不同的句子组成。通过进一步阐述鲁棒性指标，当模型在整个团体上的表现始终准确时，被判定为鲁棒性强。我们对过去十年中发表的几种典型模型进行了实验。

    The robustness to distribution changes ensures that NLP models can be successfully applied in the realistic world, especially for information extraction tasks. However, most prior evaluation benchmarks have been devoted to validating pairwise matching correctness, ignoring the crucial measurement of robustness. In this paper, we present the first benchmark that simulates the evaluation of open information extraction models in the real world, where the syntactic and expressive distributions under the same knowledge meaning may drift variously. We design and annotate a large-scale testbed in which each example is a knowledge-invariant clique that consists of sentences with structured knowledge of the same meaning but with different syntactic and expressive forms. By further elaborating the robustness metric, a model is judged to be robust if its performance is consistently accurate on the overall cliques. We perform experiments on typical models published in the last decade as well as a 
    
[^2]: 无缝集成内存管理到开放域对话系统中的方法

    Effortless Integration of Memory Management into Open-Domain Conversation Systems. (arXiv:2305.13973v1 [cs.CL])

    [http://arxiv.org/abs/2305.13973](http://arxiv.org/abs/2305.13973)

    本文提出了一种简单的方法，将内存管理能力集成到 BlenderBot3 中以改进其性能，并通过自动化数据集创建来管理内存。对于 F1 分数，我们提出的模型 BlenderBot3-M^3 比 BlenderBot3 提高了 4%。

    

    开放域对话系统通过模块化方法将多种对话技能整合到单一系统中。然而，该系统的一个限制是缺乏外部内存的管理能力。在本文中，我们提出了一种简单的方法，将内存管理能力集成到 BlenderBot3 中以改进其性能。由于没有用于此目的的训练数据，我们提出一种自动化数据集创建方法来管理内存。我们的方法 1) 需要很少的数据构建成本，2) 不会影响其他任务的性能，3) 减少了外部内存的使用。我们展示了我们提出的模型 BlenderBot3-M^3，它是多任务训练的内存管理版本，在 F1 分数方面相对于 BlenderBot3 提高了 4%。

    Open-domain conversation systems integrate multiple conversation skills into a single system through a modular approach. One of the limitations of the system, however, is the absence of management capability for external memory. In this paper, we propose a simple method to improve BlenderBot3 by integrating memory management ability into it. Since no training data exists for this purpose, we propose an automating dataset creation for memory management. Our method 1) requires little cost for data construction, 2) does not affect performance in other tasks, and 3) reduces external memory. We show that our proposed model BlenderBot3-M^3, which is multi-task trained with memory management, outperforms BlenderBot3 with a relative 4% performance gain in terms of F1 score.
    
[^3]: 做出选择！基于上下文学习的知识库问答

    Make a Choice! Knowledge Base Question Answering with In-Context Learning. (arXiv:2305.13972v1 [cs.CL])

    [http://arxiv.org/abs/2305.13972](http://arxiv.org/abs/2305.13972)

    McL-KBQA是一个新的框架，它通过基于上下文学习的多项选择将LLMs的一些样本能力纳入KBQA方法，从而显著提高了概括能力，有效性和效果。

    

    知识库问答（KBQA）旨在利用给定的知识库（KB）回答事实类问题。由于KB的大规模，注释数据无法涵盖KB中的所有事实模式，这也给需要足够注释数据的方法的概括能力带来了挑战。最近，LLMs在许多NLP任务中表现出了强大的少样本性能。我们期望LLMs可以帮助现有方法提高它们的概括能力，特别是在资源匮乏的情况下。在本文中，我们提出了McL-KBQA，这是一个通过基于上下文学习的多项选择将LLMs的一些样本能力纳入KBQA方法并提高QA任务效果的框架。在两个KBQA数据集上的实验结果表明，McL-KBQA表现竞争力强，概括能力得到了显著提高。我们希望探索一种结合LLMs的方法来解决KBQA中的QA任务，如何使回答规范正确且概括能力强。

    Question answering over knowledge bases (KBQA) aims to answer factoid questions with a given knowledge base (KB). Due to the large scale of KB, annotated data is impossible to cover all fact schemas in KB, which poses a challenge to the generalization ability of methods that require a sufficient amount of annotated data. Recently, LLMs have shown strong few-shot performance in many NLP tasks. We expect LLM can help existing methods improve their generalization ability, especially in low-resource situations. In this paper, we present McL-KBQA, a framework that incorporates the few-shot ability of LLM into the KBQA method via ICL-based multiple choice and then improves the effectiveness of the QA tasks. Experimental results on two KBQA datasets demonstrate the competitive performance of McL-KBQA with strong improvements in generalization. We expect to explore a new way to QA tasks from KBQA in conjunction with LLM, how to generate answers normatively and correctly with strong generalizat
    
[^4]: 基于语法约束的语言模型灵活解码技术

    Flexible Grammar-Based Constrained Decoding for Language Models. (arXiv:2305.13971v1 [cs.CL])

    [http://arxiv.org/abs/2305.13971](http://arxiv.org/abs/2305.13971)

    本文提出了一种使用形式语法约束丰富解码步骤的方法，有效生成符合特定语法的复杂输出结构，同时允许任何上下文无关语法集成。实验证明该方法在四个信息提取任务上实现了最先进的性能表现。

    

    LLM在许多任务中展现出了惊人的少量样本表现，但在生成信息提取所需的复杂输出结构时仍存在困难。这个限制源于LLM在没有微调的情况下倾向于生成自由文本而不是遵循特定语法的精确结构。在本文中，我们提出在解码步骤中使用形式语法约束来丰富模型。在搜索过程中，只有符合语法产生规则的有效令牌能被考虑到。这样就强制只产生有效的序列。我们的框架非常通用和灵活，允许任何上下文无关语法(CFG)集成到我们的自定义约束beam搜索实现中。我们展示了许多NLP任务的输出可以被表示为形式语言，使它们适合在我们的框架中直接使用。对于输出空间取决于输入的任务，我们提出了基于输入的CFG，根据特定于输入的特征更新产生规则。实验证明了我们的方法在生成复杂输出结构方面的有效性，并在四个信息提取任务上实现了最先进的性能。

    LLMs have shown impressive few-shot performance across many tasks. However, they still struggle when it comes to generating complex output structures, such as those required for Information Extraction. This limitation stems from the fact that LLMs, without finetuning, tend to generate free text rather than precise structures that follow a specific grammar. In this work, we propose to enrich the decoding step with formal grammar constraints. During beam search, only valid token continuations compliant with the grammar production rules are considered. This enforces the generation of valid sequences exclusively. Our framework is highly general and flexible, allowing any Context-Free Grammar (CFG) to be integrated into our custom constrained beam search implementation. We demonstrate that the outputs of many NLP tasks can be represented as formal languages, making them suitable for direct use in our framework. For task where the output space is dependent on the input, we propose input-depe
    
[^5]: 基于深度度量学习的语义框架诱导中的框架元素知识获取

    Acquiring Frame Element Knowledge with Deep Metric Learning for Semantic Frame Induction. (arXiv:2305.13944v1 [cs.CL])

    [http://arxiv.org/abs/2305.13944](http://arxiv.org/abs/2305.13944)

    本论文提出一种方法，应用深度度量学习获取框架元素知识，以适合于区分框架元素角色，实验证明该方法比现有方法具有更好的性能。

    

    语义框架诱导任务将单词聚类为它们所唤起的框架，并根据它们应该填充的框架元素角色对它们的参数进行聚类。本文解决了框架聚类任务的后者，旨在获取框架元素知识，并提出了一种应用深度度量学习的方法。该方法通过使用带有框架注释数据的预训练语言模型进行微调，以适合于区分框架元素角色，并通过从微调模型获得的嵌入进行参数聚类。FrameNet上的实验结果表明，我们的方法比现有方法的性能要好得多。

    The semantic frame induction tasks are defined as a clustering of words into the frames that they evoke, and a clustering of their arguments according to the frame element roles that they should fill. In this paper, we address the latter task of argument clustering, which aims to acquire frame element knowledge, and propose a method that applies deep metric learning. In this method, a pre-trained language model is fine-tuned to be suitable for distinguishing frame element roles through the use of frame-annotated data, and argument clustering is performed with embeddings obtained from the fine-tuned model. Experimental results on FrameNet demonstrate that our method achieves substantially better performance than existing methods.
    
[^6]: 利用大型语言模型生成符号语言数据

    Generating Data for Symbolic Language with Large Language Models. (arXiv:2305.13917v1 [cs.CL])

    [http://arxiv.org/abs/2305.13917](http://arxiv.org/abs/2305.13917)

    符号语言任务中，利用大型语言模型（LLMs）生成数据的方法被提出。SymGen由信息提示和基于协议的验证器组成，可以生成各种注释昂贵的符号语言数据。相对于LLMs，使用1%大小的任务模型性能相当或更好，大幅削减了推理和部署成本。使用SymGen生成数据可以提高符号语言任务的性能和通用性。

    

    尽管大型语言模型（LLMs）带来了性能提升，但也增加了复杂性。最近的研究开始将LLMs转换为数据生成器而不是任务推理器，通过训练另一个可负担的任务模型以实现高效部署和推理。然而，这种方法主要被应用于自然语言任务，并且尚未探索用于具有复杂结构输出（例如语义解析和代码生成）的符号语言任务。本文提出了SymGen，利用LLMs生成各种注释昂贵的符号语言数据。SymGen由信息提示和基于协议的验证器组成，以提高数据的正确性。我们在各种设置下对六个符号语言任务进行了大量实验。与LLMs相比，我们证明1\%大小的任务模型可以实现相当或更好的性能，大大降低了推理和部署成本。我们还展示了使用SymGen生成数据可以提高符号语言任务的性能和通用性。

    While large language models (LLMs) bring not only performance but also complexity, recent work has started to turn LLMs into data generators rather than task inferencers, where another affordable task model is trained for efficient deployment and inference. However, such an approach has primarily been applied to natural language tasks and has not yet been explored for symbolic language tasks with complex structured outputs (e.g., semantic parsing and code generation). In this paper, we propose SymGen which utilizes LLMs for generating various annotation-expensive symbolic language data. SymGen consists of an informative prompt to steer generation and an agreement-based verifier to improve data correctness. We conduct extensive experiments on six symbolic language tasks across various settings. Compared with the LLMs, we demonstrate the 1\%-sized task model can achieve comparable or better performance, largely cutting inference and deployment costs. We also show that generated data with
    
[^7]: DAPR：文档感知段落检索的基准测试

    DAPR: A Benchmark on Document-Aware Passage Retrieval. (arXiv:2305.13915v1 [cs.IR])

    [http://arxiv.org/abs/2305.13915](http://arxiv.org/abs/2305.13915)

    DAPR是一个文档感知段落检索的基准测试，挑战在于如何从长文档中找到正确的段落并返回准确结果。

    

    最近的神经检索主要关注短文本的排名，并且在处理长文档方面存在挑战。现有的工作主要评估排名段落或整个文档。然而，许多情况下，用户希望从庞大的语料库中找到长文档中的相关段落，例如法律案例，研究论文等，此时段落往往提供很少的文档上下文，这就挑战了当前的方法找到正确的文档并返回准确的结果。为了填补这个空白，我们提出并命名了Document-Aware Passage Retrieval（DAPR）任务，并构建了一个包括来自不同领域的多个数据集的基准测试，涵盖了DAPR和整个文档检索。在实验中，我们通过不同的方法，包括在文档摘要中添加文档级别的内容，汇总段落表示和使用BM25进行混合检索，扩展了最先进的神经段落检索器。这个混合检索系统，总体基准测试显示，我们提出的DAPR任务是一个具有挑战性和重要性的问题，需要进一步研究。

    Recent neural retrieval mainly focuses on ranking short texts and is challenged with long documents. Existing work mainly evaluates either ranking passages or whole documents. However, there are many cases where the users want to find a relevant passage within a long document from a huge corpus, e.g. legal cases, research papers, etc. In this scenario, the passage often provides little document context and thus challenges the current approaches to finding the correct document and returning accurate results. To fill this gap, we propose and name this task Document-Aware Passage Retrieval (DAPR) and build a benchmark including multiple datasets from various domains, covering both DAPR and whole-document retrieval. In experiments, we extend the state-of-the-art neural passage retrievers with document-level context via different approaches including prepending document summary, pooling over passage representations, and hybrid retrieval with BM25. The hybrid-retrieval systems, the overall b
    
[^8]: 让我们逐帧思考：使用视频插帧和预测评估视频思维链

    Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction. (arXiv:2305.13903v1 [cs.CL])

    [http://arxiv.org/abs/2305.13903](http://arxiv.org/abs/2305.13903)

    该论文提出了一种新的研究方向 VideoCOT，利用视觉-语言模型的多模态生成能力，以增强视频推理，同时减少处理数百或数千帧的计算复杂度。在VIP数据集上，我们基于各种视觉-语言模型进行了基准测试，展示了使用视觉-语言模型进行VideoCOT的潜力。

    

    尽管在2023年构成了所有互联网流量的65％，但视频内容在生成AI研究中却被低估了。与此同时，最近的大型语言模型（LLM）已越来越多地与视觉模态融合。将视频与LLM整合是下一步自然的发展方向，那么这个鸿沟如何被填补？为了推进视频推理，我们提出了一个新的研究方向，即基于视频关键帧的VideoCOT，它利用了视觉-语言模型的多模态生成能力，以增强视频推理，同时减少处理数百或数千帧的计算复杂度。我们介绍了VIP，一种可以用来评估VideoCOT的推断时间数据集，其中包含1）各种带有关键帧的真实生活视频以及相应的非结构化和结构化场景描述，2）两个新的视频推理任务：视频插帧和场景预测。我们在VIP上对各种视觉-语言模型进行了基准测试，展示了使用视觉-语言模型进行VideoCOT的潜力。

    Despite constituting 65% of all internet traffic in 2023, video content is underrepresented in generative AI research. Meanwhile, recent large language models (LLMs) have become increasingly integrated with capabilities in the visual modality. Integrating video with LLMs is a natural next step, so how can this gap be bridged? To advance video reasoning, we propose a new research direction of VideoCOT on video keyframes, which leverages the multimodal generative abilities of vision-language models to enhance video reasoning while reducing the computational complexity of processing hundreds or thousands of frames. We introduce VIP, an inference-time dataset that can be used to evaluate VideoCOT, containing 1) a variety of real-life videos with keyframes and corresponding unstructured and structured scene descriptions, and 2) two new video reasoning tasks: video infilling and scene prediction. We benchmark various vision-language models on VIP, demonstrating the potential to use vision-la
    
[^9]: 针对增量学习的端到端语音理解序列级知识蒸馏

    Sequence-Level Knowledge Distillation for Class-Incremental End-to-End Spoken Language Understanding. (arXiv:2305.13899v1 [eess.AS])

    [http://arxiv.org/abs/2305.13899](http://arxiv.org/abs/2305.13899)

    本文针对连续学习场景下的口语语言理解问题，提出了增量类别场景和三种知识蒸馏方法，并显示序列级知识蒸馏可以显著改善绩效。

    

    现代神经网络在逐步学习新概念方面的能力是一个重要的弱点，这妨碍了它们在非平稳环境中的使用。它们倾向于将当前数据分布拟合得越来越好，而忽略了过去所获取的知识，导致了灾难性的遗忘问题。本文解决了应用于连续学习情境的口语语言理解问题。我们首先为SLURP数据集定义了一个增量类别场景，并针对序列到序列的Transformer模型提出了三种知识蒸馏（KD）方法以减轻遗忘：第一种KD方法应用于编码器输出（audio-KD），其余两种方法则分别在解码器输出的标记级（tok-KD）或序列级（seq-KD）分布上进行。我们展示了seq-KD显著地改善了所有绩效指标，将它与audio-KD相结合进一步降低了平均词错误率（WER）并提高了实体预测指标。

    The ability to learn new concepts sequentially is a major weakness for modern neural networks, which hinders their use in non-stationary environments. Their propensity to fit the current data distribution to the detriment of the past acquired knowledge leads to the catastrophic forgetting issue. In this work we tackle the problem of Spoken Language Understanding applied to a continual learning setting. We first define a class-incremental scenario for the SLURP dataset. Then, we propose three knowledge distillation (KD) approaches to mitigate forgetting for a sequence-to-sequence transformer model: the first KD method is applied to the encoder output (audio-KD), and the other two work on the decoder output, either directly on the token-level (tok-KD) or on the sequence-level (seq-KD) distributions. We show that the seq-KD substantially improves all the performance metrics, and its combination with the audio-KD further decreases the average WER and enhances the entity prediction metric.
    
[^10]: PaD: 程序辅助蒸馏专注于推理的大型模型

    PaD: Program-aided Distillation Specializes Large Models in Reasoning. (arXiv:2305.13888v1 [cs.CL])

    [http://arxiv.org/abs/2305.13888](http://arxiv.org/abs/2305.13888)

    本文提出了一种程序辅助蒸馏（PaD）技术，它可以蒸馏大型语言模型（LLMs）以在推理任务中获得专业化的小模型。PaD使用程序辅助推理加强专业化模型，并通过自动化错误检查来帮助它们克服错误的推理步骤。

    

    尽管大型语言模型（LLMs）在几个自然语言处理任务中表现优异，但它们的大小和不可访问性对于广泛的实际应用仍然存在挑战。先前的研究通过对LLMs进行精炼以获取专业技能，在商业场景中实现了通用能力的交换，称为模型专业化。对于推理能力，公司已合成用于后续提炼的思维链。但是，由于幻觉，LLMs的合成思维链包含错误推理，这些不正确的推理步骤损害了推理能力。为了解决上述问题，我们提出了程序辅助蒸馏（PaD），它可以蒸馏LLMs以在推理任务中获得专业化的小模型。在PaD中，我们使用程序辅助推理加强专业化模型，并通过自动化错误检查来帮助它们克服错误的推理步骤。实验结果表明，在GSM8K基准测试中，使用PaD的0.06B模型不仅可以胜过某些LLMs（例如LLaMA），而且还可以取得比其他模型更好的性能。

    While Large Language Models (LLMs) excel in several natural language processing tasks, their size and inaccessibility present challenges for extensive practical application. Previous studies acquire specialized skills through distillation on LLMs, which result in trading generic abilities, called model specialization. As for reasoning ability, chain-of-thought was synthesized to subsequent distillation. However, due to hallucination, synthetic chain-of-thought from LLMs contains faulty reasoning. These incorrect reasoning steps damage the reasoning capability. To tackle above issues, we propose Program-aided Distillation (PaD), which distills LLMs to obtain specialized small models in reasoning tasks. In PaD, we strengthen specialized models with program-aided reasoning, and help them overcome faulty reasoning steps with automated error checking. Experimental results demonstrate that, on the GSM8K benchmark, a 0.06B model using PaD can not only outperform certain LLMs (e.g., LLaMA), bu
    
[^11]: Narrative XL: 一个用于长期记忆模型的大规模数据集

    Narrative XL: A Large-scale Dataset For Long-Term Memory Models. (arXiv:2305.13877v1 [cs.CL])

    [http://arxiv.org/abs/2305.13877](http://arxiv.org/abs/2305.13877)

    本研究提出了一个新的用于长期记忆模型的大规模自然数据集，以帮助改进现有的大型语言模型。数据集由 GPT 3.5 生成，摘要包括来自 Project Gutenberg 的 1500 本书中每个场景的总结，以及配套的阅读理解问题。

    

    虽然大多数大型语言模型取得了巨大的成功，但它们缺乏任何长期记忆机制，这限制了它们的应用。要克服这一限制，不仅需要对典型的变压器架构或训练程序进行更改，还需要一个可以训练和评估这些新模型的数据集。我们认为现有的资源缺少一些关键属性，目前没有足够规模的自然数据集来训练（而不仅仅是评估）长期记忆语言模型。然后，我们提出了利用短期记忆语言模型的进展来创建这样一个数据集的解决方案。使用 GPT 3.5，我们总结了 Project Gutenberg 中 1500 本手工筛选的书籍中的每个场景，每本书得到大约 150 个场景级别的摘要。然后，我们创建了一些阅读理解问题，包括三种类型的多项选择场景识别问题，以及...

    Despite their tremendous successes, most large language models do not have any long-term memory mechanisms, which restricts their applications. Overcoming this limitation would not only require changes to the typical transformer architectures or training procedures, but also a dataset on which these new models could be trained and evaluated. We argue that existing resources lack a few key properties, and that at present, there are no naturalistic datasets of sufficient scale to train (and not only evaluate) long-term memory language models. We then present our solution that capitalizes on the advances in short-term memory language models to create such a dataset. Using GPT 3.5, we summarized each scene in 1500 hand-curated books from Project Gutenberg, which resulted in approximately 150 scene-level summaries per book. We then created a number of reading comprehension questions based on these summaries, including three types of multiple-choice scene recognition questions, as well as fr
    
[^12]: 探究脑区上下文敏感性：基于Masked-Attention生成的研究

    Probing Brain Context-Sensitivity with Masked-Attention Generation. (arXiv:2305.13863v1 [cs.CL])

    [http://arxiv.org/abs/2305.13863](http://arxiv.org/abs/2305.13863)

    本文介绍了一种新方法Masked-Attention生成，使用GPT-2变形器生成的固定量上下文信息的词嵌入可以预测人类听自然语言时的fMRI脑活动，结果表明语言网络的大多数皮层对上下文信息敏感，右半球对更长的上下文更敏感。

    

    神经语言学中的两个基本问题是超越词汇层次整合信息的脑区以及它们的整合窗口大小。为了解决这些问题，我们引入了一种名为Masked-Attention生成的新方法。它使用GPT-2变形器生成捕获固定量上下文信息的词嵌入。然后我们测试这些嵌入能否预测人类听自然文本时的fMRI脑活动。结果显示，语言网络中的大多数皮层对上下文信息敏感，右半球比左半球更加敏感于更长的上下文。Masked-Attention生成支持之前在大脑上下文敏感性分析方面的研究，并通过量化每个体素的上下文整合窗口大小来补充它们。

    Two fundamental questions in neurolinguistics concerns the brain regions that integrate information beyond the lexical level, and the size of their window of integration. To address these questions we introduce a new approach named masked-attention generation. It uses GPT-2 transformers to generate word embeddings that capture a fixed amount of contextual information. We then tested whether these embeddings could predict fMRI brain activity in humans listening to naturalistic text. The results showed that most of the cortex within the language network is sensitive to contextual information, and that the right hemisphere is more sensitive to longer contexts than the left. Masked-attention generation supports previous analyses of context-sensitivity in the brain, and complements them by quantifying the window size of context integration per voxel.
    
[^13]: 公平之路：大型语言模型中的偏差及去偏差

    A Trip Towards Fairness: Bias and De-Biasing in Large Language Models. (arXiv:2305.13862v1 [cs.CL])

    [http://arxiv.org/abs/2305.13862](http://arxiv.org/abs/2305.13862)

    本文研究大型语言模型中的偏见问题，并提出了一种去偏差技术以产生在下游任务中表现良好的健壮去偏差模型。

    

    基于转换器的语言模型（如GPT（Brown等，2020）和PaLM（Chowdhery等，2022））的普及引发了新的机器学习应用。特别是，在自然语言处理中，从大型文本语料库中进行预训练对于在下游任务中取得显着结果至关重要。然而，这些语言模型似乎具有对某些人口统计数据偏见的固有偏差。尽管研究试图缓解这个问题，但现有的方法要么未能完全消除偏见，要么降低了性能，要么代价过高。本文研究了当不同参数和预训练数据时，这些有前途的语言模型产生的偏见。最后，我们提出了一种去偏差技术，可以产生在下游任务中保持性能的健壮的去偏差模型。

    An outbreak in the popularity of transformer-based Language Models (such as GPT (Brown et al., 2020) and PaLM (Chowdhery et al., 2022)) has opened the doors to new Machine Learning applications. In particular, in Natural Language Processing and how pre-training from large text, corpora is essential in achieving remarkable results in downstream tasks. However, these Language Models seem to have inherent biases toward certain demographics reflected in their training data. While research has attempted to mitigate this problem, existing methods either fail to remove bias altogether, degrade performance, or are expensive. This paper examines the bias produced by promising Language Models when varying parameters and pre-training data. Finally, we propose a de-biasing technique that produces robust de-bias models that maintain performance on downstream tasks.
    
[^14]: 通过提示工程破解ChatGPT：一项实证研究

    Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study. (arXiv:2305.13860v1 [cs.SE])

    [http://arxiv.org/abs/2305.13860](http://arxiv.org/abs/2305.13860)

    本研究探索了通过提示工程破解ChatGPT的有效性，发现破解提示可以在40种用例情况下一致地规避限制，强调了提示结构在破解ChatGPT中的重要性。

    

    大型语言模型（LLMs）如ChatGPT已经展示了强大的潜力，但同时也引发了与内容约束和潜在滥用相关的挑战。我们的研究探究了三个关键问题：（1）可以用多少种不同的提示类型破解LLMs，（2）破解提示在规避LLM限制方面的有效性以及（3）ChatGPT对这些破解提示的韧性。首先，我们开发了一个分类模型来分析现有提示的分布，识别出十个不同模式和三个破解提示类别。随后，我们使用3,120个禁止情景下的狱中问题数据集评估ChatGPT 3.5和4.0版本的破解能力。最后，我们评估了ChatGPT对破解提示的抵抗力，发现提示可以在40种用例情景下一致地规避限制。该研究强调了提示结构在破解ChatGPT中的重要性，并突出了LLMs对意外滥用的敏感性。

    Large Language Models (LLMs), like ChatGPT, have demonstrated vast potential but also introduce challenges related to content constraints and potential misuse. Our study investigates three key research questions: (1) the number of different prompt types that can jailbreak LLMs, (2) the effectiveness of jailbreak prompts in circumventing LLM constraints, and (3) the resilience of ChatGPT against these jailbreak prompts. Initially, we develop a classification model to analyze the distribution of existing prompts, identifying ten distinct patterns and three categories of jailbreak prompts. Subsequently, we assess the jailbreak capability of prompts with ChatGPT versions 3.5 and 4.0, utilizing a dataset of 3,120 jailbreak questions across eight prohibited scenarios. Finally, we evaluate the resistance of ChatGPT against jailbreak prompts, finding that the prompts can consistently evade the restrictions in 40 use-case scenarios. The study underscores the importance of prompt structures in j
    
[^15]: 通过交互式评估揭示任务导向对话中的用户熟悉度偏见

    Revealing User Familiarity Bias in Task-Oriented Dialogue via Interactive Evaluation. (arXiv:2305.13857v1 [cs.CL])

    [http://arxiv.org/abs/2305.13857](http://arxiv.org/abs/2305.13857)

    本研究发现任务导向对话系统中存在用户熟悉度偏见，而真实世界的应用场景很少符合封闭目标的设定。因此，在开放目标设置下，系统会出现严重问题，同时研究者发现了“不匹配错误”这一新型错误类型。

    

    大多数任务导向对话(TOD)基准假定用户精确地知道如何使用系统，通过将用户行为限制在系统的能力范围内，即“用户熟悉度”偏见。当这种数据偏见与数据驱动的TOD系统相结合时，该偏见加深了，因为使用现有的静态评估无法理解其影响。因此，我们进行了一项交互式用户研究，揭示TOD系统在真实场景下的脆弱性。具体而言，我们比较了具有1）符合系统边界的详细目标说明（封闭目标）和2）通常不受支持但现实（开放目标）的模糊目标说明的用户。我们的研究发现，在开放目标设置下的对话会导致系统严重失败，92%的对话存在显著的问题。此外，我们进行了彻底的分析，通过错误注释识别两种设置之间的显著特征。从中我们发现了一种新的错误类型称为“不匹配错误”，这表明用户和系统无法建立共享的语境理解。本研究强调了在TOD评估中考虑用户熟悉度偏见的重要性，并开发更强大的系统来处理实际情况。

    Most task-oriented dialogue (TOD) benchmarks assume users that know exactly how to use the system by constraining the user behaviors within the system's capabilities via strict user goals, namely "user familiarity" bias. This data bias deepens when it combines with data-driven TOD systems, as it is impossible to fathom the effect of it with existing static evaluations. Hence, we conduct an interactive user study to unveil how vulnerable TOD systems are against realistic scenarios. In particular, we compare users with 1) detailed goal instructions that conform to the system boundaries (closed-goal) and 2) vague goal instructions that are often unsupported but realistic (open-goal). Our study reveals that conversations in open-goal settings lead to catastrophic failures of the system, in which 92% of the dialogues had significant issues. Moreover, we conduct a thorough analysis to identify distinctive features between the two settings through error annotation. From this, we discover a no
    
[^16]: 结合全局结构知识的视觉丰富文档关系抽取方法

    Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document. (arXiv:2305.13850v1 [cs.CL])

    [http://arxiv.org/abs/2305.13850](http://arxiv.org/abs/2305.13850)

    这篇论文提出了一种结合全局结构知识的连续迭代的方式去捕获实体之间的依赖关系，以提高视觉丰富文档中关系抽取的准确性。

    

    视觉关系提取（VRE）旨在从视觉丰富的文档中提取实体之间的关系。现有方法通常基于实体特征单独预测每对实体之间的关系，但忽略了全局结构信息，即实体对之间的依赖关系。缺乏全局结构信息可能使模型难以学习长程关系，并容易产生冲突的预测结果。为了缓解这些限制，我们提出了一种GOSE框架，该框架以迭代的方式捕获实体对之间的依赖关系。给定文档的扫描图像，GOSE首先对实体对生成初步的关系预测。第二，在先前迭代的预测结果基础上，GOSE利用全局结构知识进一步整合实体表示。这种“生成-捕获-整合”模式被多次执行，以便实体之间的依赖关系能够被很好地捕获和利用。

    Visual relation extraction (VRE) aims to extract relations between entities from visuallyrich documents. Existing methods usually predict relations for each entity pair independently based on entity features but ignore the global structure information, i.e., dependencies between entity pairs. The absence of global structure information may make the model struggle to learn long-range relations and easily predict conflicted results. To alleviate such limitations, we propose a GlObal Structure knowledgeguided relation Extraction (GOSE) framework, which captures dependencies between entity pairs in an iterative manner. Given a scanned image of the document, GOSE firstly generates preliminary relation predictions on entity pairs. Secondly, it mines global structure knowledge based on prediction results of the previous iteration and further incorporates global structure knowledge into entity representations. This "generate-capture-incorporate" schema is performed multiple times so that entit
    
[^17]: 带有地理实体提及、指代和链接标注的Arukikata游记数据集

    Arukikata Travelogue Dataset with Geographic Entity Mention, Coreference, and Link Annotation. (arXiv:2305.13844v1 [cs.CL])

    [http://arxiv.org/abs/2305.13844](http://arxiv.org/abs/2305.13844)

    该论文介绍了一个日本旅行游记数据集，强调文档级地理实体解析的重要性，提供丰富的地理实体信息，并为地理解析系统评估提供了基础。

    

    地理解析是分析文本中地理实体信息的基本技术。我们关注于文档级地理解析，考虑地理相关性，同时提出了一个专门用于评估文档级地理解析系统的日本旅行游记数据集。该数据集包含200篇游记文档，具有丰富的地理实体信息：12,171个提及、6,339个指代簇和2,551个链接到地理数据库条目的地理实体。

    Geoparsing is a fundamental technique for analyzing geo-entity information in text. We focus on document-level geoparsing, which considers geographic relatedness among geo-entity mentions, and presents a Japanese travelogue dataset designed for evaluating document-level geoparsing systems. Our dataset comprises 200 travelogue documents with rich geo-entity information: 12,171 mentions, 6,339 coreference clusters, and 2,551 geo-entities linked to geo-database entries.
    
[^18]: 从对话生成文本中降低说话者名称敏感度

    Reducing Sensitivity on Speaker Names for Text Generation from Dialogues. (arXiv:2305.13833v1 [cs.CL])

    [http://arxiv.org/abs/2305.13833](http://arxiv.org/abs/2305.13833)

    本文提出在对话生成文本中降低说话者名称敏感度的方法，通过定量测量模型敏感度并全面评估已知方法，得出了一种新方法的良好表现，为此问题提供了基准。

    

    在对话中始终保持说话者名称的一致性不应该影响到其含义以及对话生成的相应输出。然而，预训练的语言模型作为对话处理任务的主干已经显示出对微妙之处的敏感性。这可能会导致现实世界中的不公平。过去没有对这个问题进行全面的分析。在这项工作中，我们建议定量测量模型对说话者名称的敏感度，并全面评估许多已知的减少说话者名称敏感度的方法，包括我们自己的一种新方法。对多个数据集进行的广泛实验为此问题提供了基准，并展示了我们的方法在敏感度降低和生成质量方面的优异表现。

    Changing speaker names consistently throughout a dialogue should not affect its meaning and corresponding outputs for text generation from dialogues. However, pre-trained language models, serving as the backbone for dialogue-processing tasks, have shown to be sensitive to nuances. This may result in unfairness in real-world applications. No comprehensive analysis of this problem has been done in the past. In this work, we propose to quantitatively measure a model's sensitivity on speaker names, and comprehensively evaluate a number of known methods for reducing speaker name sensitivity, including a novel approach of our own. Extensive experiments on multiple datasets provide a benchmark for this problem and show the favorable performance of our approach in sensitivity reduction and quality of generation.
    
[^19]: ZET-Speech: 基于扩散和基于风格的模型的零样本自适应情感可控文本转语音合成

    ZET-Speech: Zero-shot adaptive Emotion-controllable Text-to-Speech Synthesis with Diffusion and Style-based Models. (arXiv:2305.13831v1 [cs.SD])

    [http://arxiv.org/abs/2305.13831](http://arxiv.org/abs/2305.13831)

    本文提出了一种零样本自适应情感可控的语音合成模型ZET-Speech, 它可以通过一段短的中性语音和目标情感标签合成任何说话者的情感语音，并且成功合成了具有所需情感的自然和情感语音，适用于见过和未见过的发言人。

    

    情感语音合成是开发需要自然和情绪语音的系统（例如类人对话代理）中的重要任务。然而，现有的方法只针对训练期间见过的发言人生成情感语音，没有考虑到对未见过的发言人的泛化。本文提出了一种零样本自适应情感可控的语音合成模型ZET-Speech，只需要通过一段短的中性语音和目标情感标签即可合成任何说话者的情感语音。具体而言，我们提出了在扩散模型上进行域对抗学习和指导方法，以实现零样本自适应情感语音合成。实验结果表明，ZET-Speech成功地合成了具有所需情感的自然和情感语音，适用于见过和未见过的发言人。样本在https://ZET-Speech.github.io/ZET-Speech-Demo/上提供。

    Emotional Text-To-Speech (TTS) is an important task in the development of systems (e.g., human-like dialogue agents) that require natural and emotional speech. Existing approaches, however, only aim to produce emotional TTS for seen speakers during training, without consideration of the generalization to unseen speakers. In this paper, we propose ZET-Speech, a zero-shot adaptive emotion-controllable TTS model that allows users to synthesize any speaker's emotional speech using only a short, neutral speech segment and the target emotion label. Specifically, to enable a zero-shot adaptive TTS model to synthesize emotional speech, we propose domain adversarial learning and guidance methods on the diffusion model. Experimental results demonstrate that ZET-Speech successfully synthesizes natural and emotional speech with the desired emotion for both seen and unseen speakers. Samples are at https://ZET-Speech.github.io/ZET-Speech-Demo/.
    
[^20]: 通过协作交互与学习助手从错误中学习

    Learn from Mistakes through Cooperative Interaction with Study Assistant. (arXiv:2305.13829v1 [cs.CL])

    [http://arxiv.org/abs/2305.13829](http://arxiv.org/abs/2305.13829)

    本文提出了一个新框架 SALAM，通过协作交互与学习助手来帮助 LLM 在反思和改进过程中。该框架通过收集错误并在推理时提供指导方针，显着提高模型性能。

    

    大型语言模型已经证明了它们自我反思和改进生成能力的能力，这可以进一步提高它们的性能。然而，这种反馈机制面临挑战，例如不能保证正确性和对模型弱点缺乏全局洞察力。在本文中，我们提出了一种新的框架 Study Assistant for Large Language Model (SALAM)，以帮助 LLM 在反思和改进过程中。我们根据人类助理研究的灵感，通过将先前的响应与真实值进行定量分级，并在训练阶段收集错误来实现这一点。在推理期间，它根据错误收集确定常见误解，并提供指导方针，以帮助模型在推理期间避免类似的错误。SALAM 是一个模型不可知的框架，专注于提供一般性的反馈，并可适用于任何基础模型。我们在两个具有挑战性的基准测试上对 SALAM 进行了评估，它在各种基线上都获得了显着的改进。

    Large language models have demonstrated their ability to self-reflect and refine their generation, which can further improve their performance. However, this feedback mechanism faces challenges such as no guarantee of correctness and the lack of global insight into the model's weaknesses. In this paper, we propose a novel framework, Study Assistant for Large Language Model (SALAM), to aid LLMs in the reflection and refinement process. Motivated by the human study assistant, this framework grades previous responses with the ground truth and collects mistakes in the training phase. During inference, it identifies common misunderstandings based on the mistake collections and provides guidelines for the model to help the model avoid similar mistakes during inference. SALAM is a model-agnostic framework, focusing on providing general feedback and can adapt to any base model. Our evaluation of SALAM on two challenging benchmarks demonstrated a significant improvement over various baselines.
    
[^21]: “教皇是天主教徒吗？”——运用思维链推理理解对话含义。

    "Is the Pope Catholic?" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures. (arXiv:2305.13826v1 [cs.CL])

    [http://arxiv.org/abs/2305.13826](http://arxiv.org/abs/2305.13826)

    本论文运用思维链推理，将格赖斯的四个准则纳入模型，证明了可以提高模型性能以有效理解对话含义。

    

    对话含义是指要求听者从说话者的明确话语中推断出其所要传达的意思的语用推断。尽管这种推理是人类交流的基础，但最近的研究表明，大型语言模型在理解这些含义方面的表现远低于普通人。本文通过运用格赖斯的四个准则，并通过思维链提示将其纳入模型中，证明了我们可以显著提高其性能，甚至超过了该任务的平均人类表现。

    Conversational implicatures are pragmatic inferences that require listeners to deduce the intended meaning conveyed by a speaker from their explicit utterances. Although such inferential reasoning is fundamental to human communication, recent research indicates that large language models struggle to comprehend these implicatures as effectively as the average human. This paper demonstrates that by incorporating Grice's Four Maxims into the model through chain-of-thought prompting, we can significantly enhance its performance, surpassing even the average human performance on this task.
    
[^22]: 一种用于语言识别的开源数据集和模型

    An Open Dataset and Model for Language Identification. (arXiv:2305.13820v1 [cs.CL])

    [http://arxiv.org/abs/2305.13820](http://arxiv.org/abs/2305.13820)

    本文介绍了一种语言识别模型，使用开源的数据集和筛选出来的单语数据，取得了优秀的性能表现，尤其是在低资源语言上表现出色，并对模型的表现进行了详细的分析。

    

    语言识别是许多自然语言处理流程的基本步骤。然而，当前的语言识别系统还有许多缺陷，特别是对于低资源语言。本文提出了一个语言识别模型，它在 201 种语言上取得了宏平均 F1 值为0.93、假阳性率为0.033的性能，超过了先前的工作。本文通过在一个筛选出来的单语数据集上训练，同时手工审核样本，确保其可靠性。我们将模型和数据集都提供给了研究社区。最后，我们对模型的性能进行了详细的分析，包括与现有开源模型的比较以及按语言类别的性能。

    Language identification (LID) is a fundamental step in many natural language processing pipelines. However, current LID systems are far from perfect, particularly on lower-resource languages. We present a LID model which achieves a macro-average F1 score of 0.93 and a false positive rate of 0.033 across 201 languages, outperforming previous work. We achieve this by training on a curated dataset of monolingual data, the reliability of which we ensure by auditing a sample from each source and each language manually. We make both the model and the dataset available to the research community. Finally, we carry out detailed analysis into our model's performance, both in comparison to existing open models and by language class.
    
[^23]: 自动检测临床文档的版面以提高下游自然语言处理性能

    Detecting automatically the layout of clinical documents to enhance the performances of downstream natural language processing. (arXiv:2305.13817v1 [cs.CL])

    [http://arxiv.org/abs/2305.13817](http://arxiv.org/abs/2305.13817)

    本文提出了一种算法，可以自动提取临床 PDF 文档中有关临床的文本，以提高下游自然语言处理任务的性能。

    

    目标：开发并验证一种分析 PDF 临床文档版面的算法，以提高下游自然语言处理任务的性能。方法：我们设计了一个算法来处理临床 PDF 文档，并提取只与临床相关的文本。该算法包括几个步骤：使用 PDF 解析器进行初始文本提取，然后使用 Transformer 深度神经网络架构将其分类为正文、左侧注释和页脚等类别，最后进行汇总步骤以编译给定标签的文本行。我们通过将其应用于已注释的文档的随机样本，评估了正文提取算法的技术性能。通过检查从各自的部分中提取感兴趣的医学概念来评估医学性能。最后，我们在描述急性感染的医学用例上测试了一个端到端系统。

    Objective:Develop and validate an algorithm for analyzing the layout of PDF clinical documents to improve the performance of downstream natural language processing tasks. Materials and Methods: We designed an algorithm to process clinical PDF documents and extract only clinically relevant text. The algorithm consists of several steps: initial text extraction using a PDF parser, followed by classification into categories such as body text, left notes, and footers using a Transformer deep neural network architecture, and finally an aggregation step to compile the lines of a given label in the text. We evaluated the technical performance of the body text extraction algorithm by applying it to a random sample of documents that were annotated. Medical performance was evaluated by examining the extraction of medical concepts of interest from the text in their respective sections. Finally, we tested an end-to-end system on a medical use case of automatic detection of acute infection described
    
[^24]: 从图像-文本-图谱空间中进行粗到细的对比学习，提高视觉语言组合能力

    Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality. (arXiv:2305.13812v1 [cs.CL])

    [http://arxiv.org/abs/2305.13812](http://arxiv.org/abs/2305.13812)

    本研究提出了一种基于场景图的对比学习框架，通过将从文本中解析出的场景图视为图像场景图的代理，并对图进行分解和增强，从简单到复杂的对比学习以将各种复杂度的句子对齐到同一幅图像上，同时在场景图空间中提出了新的负样本挖掘技术，以改善视觉语言组合能力。

    

    对比学习视觉语言模型已经在视觉和语言表示学习方面取得了显著进展，从而为各种下游多模态任务提供了最先进的模型。但是，最近的研究凸显了这些模型在对象、属性和关系的组成推理能力方面的严重限制。场景图已经成为一种理解图像组成的有效方式。这些是图像的图形结构化语义表示，包括场景中的对象、它们的属性和与场景中其他对象的关系。在本文中，我们将从文本中解析出的场景图视为图像场景图的代理，并提出了一种图分解和增强框架，以及从简单到复杂的对比学习目标，将各种复杂度的句子对齐到同一幅图像上。同时，我们还在场景图空间提出了新的负样本挖掘技术，用于改善对比学习。在三个视觉语言任务上的实验表明，我们的方法优于强大的视觉语言基线，特别是在对象、属性和关系的组成推理方面。

    Contrastively trained vision-language models have achieved remarkable progress in vision and language representation learning, leading to state-of-the-art models for various downstream multimodal tasks. However, recent research has highlighted severe limitations of these models in their ability to perform compositional reasoning over objects, attributes, and relations. Scene graphs have emerged as an effective way to understand images compositionally. These are graph-structured semantic representations of images that contain objects, their attributes, and relations with other objects in a scene. In this work, we consider the scene graph parsed from text as a proxy for the image scene graph and propose a graph decomposition and augmentation framework along with a coarse-to-fine contrastive learning objective between images and text that aligns sentences of various complexities to the same image. Along with this, we propose novel negative mining techniques in the scene graph space for im
    
[^25]: 开放域QA中通过提问澄清解决歧义问题

    Asking Clarification Questions to Handle Ambiguity in Open-Domain QA. (arXiv:2305.13808v1 [cs.CL])

    [http://arxiv.org/abs/2305.13808](http://arxiv.org/abs/2305.13808)

    本文提出了一种解决开放域QA中歧义问题的方法：通过提问澄清来确定最符合用户意图的解释。

    

    开放域中存在歧义问题，如何提出一个准确且独一无二的问题是很具挑战性的。过去，Min et al. (2020) 通过为所有可能的解释生成消除歧义的问题来解决这个问题。这种方法可能有效，但并不理想。我们提出通过提问澄清来解决这个问题，用户的回答将帮助确定最符合用户意图的解释。我们首先介绍了一个数据集CAMBIGNQ，该数据集由5,654个含有相关段落、可能的答案和澄清问题的歧义问题组成。这些澄清问题是通过使用InstructGPT生成然后进行必要的手动修订来高效创建的。然后我们定义了一系列任务和相应的评估指标。最后，我们在歧义检测上获得了61.3 F1，在澄清型QA上获得了40.5 F1，为提供强有力的答案提出了解决方案。

    Ambiguous questions persist in open-domain question answering, because formulating a precise question with a unique answer is often challenging. Previously, Min et al. (2020) have tackled this issue by generating disambiguated questions for all possible interpretations of the ambiguous question. This can be effective, but not ideal for providing an answer to the user. Instead, we propose to ask a clarification question, where the user's response will help identify the interpretation that best aligns with the user's intention. We first present CAMBIGNQ, a dataset consisting of 5,654 ambiguous questions, each with relevant passages, possible answers, and a clarification question. The clarification questions were efficiently created by generating them using InstructGPT and manually revising them as necessary. We then define a pipeline of tasks and design appropriate evaluation metrics. Lastly, we achieve 61.3 F1 on ambiguity detection and 40.5 F1 on clarification-based QA, providing stron
    
[^26]: 面向零样本关系抽取的 Web 挖掘多模态相对 XML 路径方法

    Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path. (arXiv:2305.13805v1 [cs.CL])

    [http://arxiv.org/abs/2305.13805](http://arxiv.org/abs/2305.13805)

    本文提出了一种名为 ReXMiner 的新方法，用于实现 Web 挖掘中的零样本关系抽取。该方法利用文档对象模型（DOM）树中最短相对路径来更准确、高效地提取网页中的键值对，并通过计算文本节点在不同网页中出现的次数来衡量其流行度。

    

    网页数量的快速增长及其结构的日益复杂化对 Web 挖掘模型提出了挑战。这些模型需要理解半结构化的网页，特别是在对新网页的主题或模板知之甚少的情况下。目前的方法通过将 XML 源代码嵌入到 transformer 或使用图神经网络对呈现的布局进行编码，将语言模型迁移到 Web 挖掘领域。然而，这些方法并没有考虑网页内部和跨页面的文本节点之间的关系。本文提出一种新的方法 ReXMiner，用于实现 Web 挖掘中的零样本关系抽取。ReXMiner 编码文档对象模型（DOM）树中的最短相对路径，这种方法对于网页内的键值对提取来说更加准确和有效。它还通过计算相同文本节点在不同网页中出现的次数，来反映每个文本节点的流行程度。

    The rapid growth of web pages and the increasing complexity of their structure poses a challenge for web mining models. Web mining models are required to understand the semi-structured web pages, particularly when little is known about the subject or template of a new page. Current methods migrate language models to the web mining by embedding the XML source code into the transformer or encoding the rendered layout with graph neural networks. However, these approaches do not take into account the relationships between text nodes within and across pages. In this paper, we propose a new approach, ReXMiner, for zero-shot relation extraction in web mining. ReXMiner encodes the shortest relative paths in the Document Object Model (DOM) tree which is a more accurate and efficient signal for key-value pair extraction within a web page. It also incorporates the popularity of each text node by counting the occurrence of the same text node across different web pages. We use the contrastive learn
    
[^27]: 个性化预测ASR在语音助手中的延迟降低

    Personalized Predictive ASR for Latency Reduction in Voice Assistants. (arXiv:2305.13794v1 [cs.CL])

    [http://arxiv.org/abs/2305.13794](http://arxiv.org/abs/2305.13794)

    本文介绍了一种个性化预测ASR方法，可以降低语音助手中的延迟，通过预测完整话语来预取响应，并探讨了成功预测和失败预测之间的权衡。

    

    语音助手中的流式自动语音识别（ASR）可以利用预取来部分隐藏响应生成的延迟。预取涉及将初步的ASR假设传递给下游系统，以预取和缓存响应。如果终点检测后的最终ASR假设与初步假设匹配，则可以将缓存的响应交付给用户，从而节省延迟。在本文中，我们通过引入基于部分观察到的话语预测完整话语，并根据预测话语预取响应的预测自动语音识别，扩展了这个想法。我们引入了两种个性化方法，并研究了成功预测的潜在延迟增益与预测失败的成本增加之间的权衡。我们在内部语音助手数据集以及公共SLURP数据集上评估了我们的方法。

    Streaming Automatic Speech Recognition (ASR) in voice assistants can utilize prefetching to partially hide the latency of response generation. Prefetching involves passing a preliminary ASR hypothesis to downstream systems in order to prefetch and cache a response. If the final ASR hypothesis after endpoint detection matches the preliminary one, the cached response can be delivered to the user, thus saving latency. In this paper, we extend this idea by introducing predictive automatic speech recognition, where we predict the full utterance from a partially observed utterance, and prefetch the response based on the predicted utterance. We introduce two personalization approaches and investigate the tradeoff between potential latency gains from successful predictions and the cost increase from failed predictions. We evaluate our methods on an internal voice assistant dataset as well as the public SLURP dataset.
    
[^28]: 大型语言模型能像人类一样推理和产生分歧吗？

    Can Large Language Models Infer and Disagree Like Humans?. (arXiv:2305.13788v1 [cs.CL])

    [http://arxiv.org/abs/2305.13788](http://arxiv.org/abs/2305.13788)

    本文研究了大型语言模型在自然语言推断方面的性能和与人类分歧分布的对齐情况。结果表明LLM的推断能力有限，无法捕捉到人类分歧分布，引发了对其NLU和代表人类用户性质的担忧。

    

    大型语言模型在解决广泛任务方面已经表现出非常好的成绩。在生成文本时，从这些模型中采样标记是一种常见的策略。但是，LLM很难与人类的分歧分布高度对齐，特别是在自然语言推断方面。本文使用 Monte Carlo Reconstruction（MCR）和 Log Probability Reconstruction（LPR）两种不同的技术评估了LLM分布的性能和与人类的对齐情况。结果表明，LLM在解决NLI任务方面能力有限，同时无法捕捉到人类的分歧分布，这对其自然语言理解（NLU）能力和代表人类用户的特性提出了关注。

    Large Language Models (LLMs) have shown stellar achievements in solving a broad range of tasks. When generating text, it is common to sample tokens from these models: whether LLMs closely align with the human disagreement distribution has not been well-studied, especially within the scope of Natural Language Inference (NLI). In this paper, we evaluate the performance and alignment of LLM distribution with humans using two different techniques: Monte Carlo Reconstruction (MCR) and Log Probability Reconstruction (LPR). As a result, we show LLMs exhibit limited ability in solving NLI tasks and simultaneously fail to capture human disagreement distribution, raising concerns about their natural language understanding (NLU) ability and their representativeness of human users.
    
[^29]: 基于提示的数据增强提升黑盒少样本文本分类

    Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation. (arXiv:2305.13785v1 [cs.CL])

    [http://arxiv.org/abs/2305.13785](http://arxiv.org/abs/2305.13785)

    本论文提出一种基于提示的数据增强方法，通过在辅助语言模型上进行微调来实现，从而提高了黑盒少样本文本分类的性能。

    

    训练或微调大规模语言模型如 GPT-3 需要大量计算资源，这推动了最近探索参数高效适应下游任务的努力。这篇论文研究了如何优化少样本文本分类，而无需访问 LLM 的梯度。为了实现这一点，我们将黑盒模型视为特征提取器，并使用增强的文本数据训练分类器。数据增强是通过在一个比黑盒模型参数规模小得多的辅助语言模型上进行基于提示的微调来完成的。通过对八个文本分类数据集的广泛实验，我们展示了我们的方法（称为 BT-Classifier）显著优于最先进的黑盒少样本学习器，并与依赖于全模型调整的方法表现相当。

    Training or finetuning large-scale language models (LLMs) such as GPT-3 requires substantial computation resources, motivating recent efforts to explore parameter-efficient adaptation to downstream tasks. One practical area of research is to treat these models as black boxes and interact with them through their inference APIs. In this paper, we investigate how to optimize few-shot text classification without accessing the gradients of the LLMs. To achieve this, we treat the black-box model as a feature extractor and train a classifier with the augmented text data. Data augmentation is performed using prompt-based finetuning on an auxiliary language model with a much smaller parameter size than the black-box model. Through extensive experiments on eight text classification datasets, we show that our approach, dubbed BT-Classifier, significantly outperforms state-of-the-art black-box few-shot learners and performs on par with methods that rely on full-model tuning.
    
[^30]: 语言空间中的图像：探索大型语言模型在视觉语言任务中的适用性。

    Images in Language Space: Exploring the Suitability of Large Language Models for Vision & Language Tasks. (arXiv:2305.13782v1 [cs.CL])

    [http://arxiv.org/abs/2305.13782](http://arxiv.org/abs/2305.13782)

    该论文研究了只使用语言模型是否可以用于需要视觉输入和强大推理能力的任务，并使用单独的语言模型使其可以访问视觉信息的方法。结果表明，即使样本有限，语言模型也可以成功解决视觉语言任务，还提高了模型输出的可解释性。

    

    大型语言模型已经在各种语言任务中展现了强大的性能，使用了零样本或少样本学习范式。虽然多模型模型正在积极研究中，可以额外处理图像作为输入，但在大小和普适性上还没有达到仅语言模型。在这项工作中，我们询问只使用语言模型是否可以用于需要视觉输入的任务，并且正如我们所争论的，这些任务通常需要强大的推理能力。类似于一些最近的相关工作，我们使用单独的语言模型来使语言模型可以访问视觉信息。具体而言，我们研究了开源、开放访问的语言模型相对于GPT-3在给定以文本编码的视觉信息时在五个视觉语言任务上的表现。我们的结果表明，即使样本有限，语言模型也可以有效地解决视觉语言任务。这种方法还通过提供手段来增强模型输出的可解释性。

    Large language models have demonstrated robust performance on various language tasks using zero-shot or few-shot learning paradigms. While being actively researched, multimodal models that can additionally handle images as input have yet to catch up in size and generality with language-only models. In this work, we ask whether language-only models can be utilised for tasks that require visual input -- but also, as we argue, often require a strong reasoning component. Similar to some recent related work, we make visual information accessible to the language model using separate verbalisation models. Specifically, we investigate the performance of open-source, open-access language models against GPT-3 on five vision-language tasks when given textually-encoded visual information. Our results suggest that language models are effective for solving vision-language tasks even with limited samples. This approach also enhances the interpretability of a model's output by providing a means of tra
    
[^31]: 持续融合意图分布学习的反话语生成方法

    Counterspeeches up my sleeve! Intent Distribution Learning and Persistent Fusion for Intent-Conditioned Counterspeech Generation. (arXiv:2305.13776v1 [cs.CL])

    [http://arxiv.org/abs/2305.13776](http://arxiv.org/abs/2305.13776)

    这篇论文提出了一个意图条件下的反话语生成方法QUARC，基于IntentCONAN数据集，利用向量量化表示和PerFuMe融合模块实现特定意图的反话语输出。

    

    反话语已被证明是对抗仇恨言论的一种有效方法。然而，对于每种场景，具有特定意图的反话语可能并不足够。本文探讨了意图条件下的反话语生成。首先，我们创建了IntentCONAN数据集，其中包含6831个反话语，分为五种意图：信息、谴责、问题、积极和幽默。随后，我们提出QUARC框架，该框架有两个阶段，用于意图条件下的反话语生成。QUARC利用学习每种意图类别的向量量化表示，以及PerFuMe，一种用于整合特定意图的信息的新型融合模块。

    Counterspeech has been demonstrated to be an efficacious approach for combating hate speech. While various conventional and controlled approaches have been studied in recent years to generate counterspeech, a counterspeech with a certain intent may not be sufficient in every scenario. Due to the complex and multifaceted nature of hate speech, utilizing multiple forms of counter-narratives with varying intents may be advantageous in different circumstances. In this paper, we explore intent-conditioned counterspeech generation. At first, we develop IntentCONAN, a diversified intent-specific counterspeech dataset with 6831 counterspeeches conditioned on five intents, i.e., informative, denouncing, question, positive, and humour. Subsequently, we propose QUARC, a two-stage framework for intent-conditioned counterspeech generation. QUARC leverages vector-quantized representations learned for each intent category along with PerFuMe, a novel fusion module to incorporate intent-specific inform
    
[^32]: 概念感知训练提高了语言模型在上下文学习中的能力

    Concept-aware Training Improves In-context Learning Ability of Language Models. (arXiv:2305.13775v1 [cs.CL])

    [http://arxiv.org/abs/2305.13775](http://arxiv.org/abs/2305.13775)

    本研究提出了一种概念感知训练的方法，用于训练能够更好利用上下文信息的语言模型。该方法能够显著提高模型的推理能力，在多个基准测试中表现出良好的效果。

    

    近期的多个Transformer系列语言模型展现了所谓的上下文学习能力(ICL)，表现为这些语言模型可以通过对自然语言输入任务进行调节来改变自身的功能。之前的一些研究认为，ICL的出现是由于过度参数化或多任务训练规模。然而，最近一些理论研究认为，ICL的出现是由具体的训练数据属性引起的，并在小规模的仿真环境中创建了功能性的上下文学习器。借鉴数据属性驱动ICL的最新发现，我们提出了一种方法来创建能够更好地利用上下文信息的语言模型。通过构建训练场景，使得模型捕捉到类比思维的概念，我们的概念感知训练 (CoAT) 方法可以显著提高模型的推理能力。结果，使用CoAT训练得到的具有上下文学习能力的语言模型在多个基准测试中得到了提升。

    Many recent language models (LMs) of Transformers family exhibit so-called in-context learning (ICL) ability, manifested in the LMs' ability to modulate their function by a task described in a natural language input. Previous work curating these models assumes that ICL emerges from vast over-parametrization or the scale of multi-task training. However, a complementary branch of recent theoretical work attributes ICL emergence to specific properties of training data and creates functional in-context learners in small-scale, synthetic settings.  Inspired by recent findings on data properties driving the emergence of ICL, we propose a method to create LMs able to better utilize the in-context information, by constructing training scenarios where it is beneficial for the LM to capture the analogical reasoning concepts. We measure that data sampling of Concept-aware Training (CoAT) consistently improves models' reasoning ability. As a result, the in-context learners trained with CoAT on onl
    
[^33]: 基于主题驱动的远程监督框架实现宏观层面的篇章分析

    Topic-driven Distant Supervision Framework for Macro-level Discourse Parsing. (arXiv:2305.13755v1 [cs.CL])

    [http://arxiv.org/abs/2305.13755](http://arxiv.org/abs/2305.13755)

    本研究提出了一种基于主题驱动的远程监督框架，通过远程监督方法利用领域内数据生成高质量的篇章训练数据，进一步提高篇章分析性能，在使用更少的训练数据的情况下实现最先进的结果。

    

    篇章分析是自然语言处理中一个具有挑战性的任务，其目的是分析文本的内部修辞结构。尽管神经模型存在近期的进展，但缺乏大规模、高质量的语料库用于训练仍然是一个重要的障碍。最近的研究尝试通过远程监督来克服此限制，该方法利用其他自然语言处理任务（例如情感极性、注意力矩阵和分割概率）的结果来解析篇章树。然而，这些方法没有考虑领域内外任务的差异，导致效果较差并且不能利用高质量的领域内数据进一步提高效果。为了解决这些问题，我们提出了一种远程监督框架，将主题结构和修辞结构之间的关系利用起来。具体来说，我们提出了两种基于远程监督的方法，基于转移学习和师生模型，用于重复生成高质量的领域内篇章训练数据。我们在基准数据集上的评估结果表明，我们的提议框架在要求更少的训练数据的同时实现了最先进的性能。

    Discourse parsing, the task of analyzing the internal rhetorical structure of texts, is a challenging problem in natural language processing. Despite the recent advances in neural models, the lack of large-scale, high-quality corpora for training remains a major obstacle. Recent studies have attempted to overcome this limitation by using distant supervision, which utilizes results from other NLP tasks (e.g., sentiment polarity, attention matrix, and segmentation probability) to parse discourse trees. However, these methods do not take into account the differences between in-domain and out-of-domain tasks, resulting in lower performance and inability to leverage the high-quality in-domain data for further improvement. To address these issues, we propose a distant supervision framework that leverages the relations between topic structure and rhetorical structure. Specifically, we propose two distantly supervised methods, based on transfer learning and the teacher-student model, that narr
    
[^34]: 上下文感知神经机器翻译的挑战

    Challenges in Context-Aware Neural Machine Translation. (arXiv:2305.13751v1 [cs.CL])

    [http://arxiv.org/abs/2305.13751](http://arxiv.org/abs/2305.13751)

    本文研究上下文感知神经机器翻译中存在的挑战，并提出了更为真实的文档级翻译设置，段落级翻译(para2para)，以及收集了一份新的中英小说数据集，以促进未来的研究。

    

    上下文感知神经机器翻译涉及利用句子级别上下文之外的信息来解决句际话语依赖关系和提高文档级翻译质量，引起了许多技术方面的关注。然而，尽管有着明智的直觉，大多数上下文感知翻译模型只能显示出适度的改进。本研究探讨了阻碍该领域进展的几个挑战，涉及话语现象、上下文使用、模型架构和文档级评估等方面。为解决这些问题，我们提出了更为真实的文档级翻译设置，称为段落级翻译(para2para)，并收集了一份新的中英小说数据集以促进未来的研究。

    Context-aware neural machine translation involves leveraging information beyond sentence-level context to resolve inter-sentential discourse dependencies and improve document-level translation quality, and has given rise to a number of recent techniques. However, despite well-reasoned intuitions, most context-aware translation models show only modest improvements over sentence-level systems. In this work, we investigate several challenges that impede progress within this field, relating to discourse phenomena, context usage, model architectures, and document-level evaluation. To address these problems, we propose a more realistic setting for document-level translation, called paragraph-to-paragraph (para2para) translation, and collect a new dataset of Chinese-English novels to promote future research.
    
[^35]: 基于目标的可解释聚类在语言描述中的应用

    Goal-Driven Explainable Clustering via Language Descriptions. (arXiv:2305.13749v1 [cs.CL])

    [http://arxiv.org/abs/2305.13749](http://arxiv.org/abs/2305.13749)

    该研究提出了一种“带解释的基于目标的聚类”（GoalEx）的新任务形式，它将目标和解释都表示为自由形式的语言描述。通过将摘要系统的注释进行分类来说明研究的有效性以及生成的解释。

    

    无监督聚类广泛用于探索大型语料库，但现有表述既不考虑用户的目标，也不解释聚类的含义。我们提出了一个新的任务形式——带解释的基于目标的聚类（GoalEx），它将目标和解释都表示为自由形式的语言描述。对于一个总结系统所犯的错误进行分类，GoalEx的输入是一个注释者为系统生成的摘要撰写的注释语料库和目标描述“根据注释者认为摘要不完美的原因对注释进行分类”;输出是每个具有解释的文本聚类(“此聚类提到摘要缺少重要的上下文信息。“)，这些聚类与目标相关，并准确解释哪些注释应该(不应该)属于一个聚类。为了解决GoalEx，我们使用一个语言模型提示“ [数据集子集]+[目标]+头脑风暴一个代表聚类的解释列表”，然后分类哪些解释属于每个聚类。实验在五个数据集上进行，包括汇总反馈、新闻文章、维基百科页面、科学文章和批评评论，展示了我们方法的有效性和生成的解释。

    Unsupervised clustering is widely used to explore large corpora, but existing formulations neither consider the users' goals nor explain clusters' meanings. We propose a new task formulation, "Goal-Driven Clustering with Explanations" (GoalEx), which represents both the goal and the explanations as free-form language descriptions. For example, to categorize the errors made by a summarization system, the input to GoalEx is a corpus of annotator-written comments for system-generated summaries and a goal description "cluster the comments based on why the annotators think the summary is imperfect.''; the outputs are text clusters each with an explanation ("this cluster mentions that the summary misses important context information."), which relates to the goal and precisely explain which comments should (not) belong to a cluster. To tackle GoalEx, we prompt a language model with "[corpus subset] + [goal] + Brainstorm a list of explanations each representing a cluster."; then we classify wh
    
[^36]: TeCS:一个用于机器翻译时态一致性的数据集和基准

    TeCS: A Dataset and Benchmark for Tense Consistency of Machine Translation. (arXiv:2305.13740v1 [cs.CL])

    [http://arxiv.org/abs/2305.13740](http://arxiv.org/abs/2305.13740)

    本文提出了一个包含552个法语-英语话语的平行时态测试集和相应的时态预测准确率基准，这使得研究人员能够首次从语言学角度衡量机器翻译系统的时态一致性性能。

    

    机器翻译中经常出现时态不一致的情况。然而，从语言学角度评估模型时态预测的掌握程度的标准很少。在本文中，我们提出了一个平行时态测试集，包含法语-英语552个话语。我们还引入了相应的基准，即时态预测准确率。借助时态测试集和基准，研究人员能够首次衡量机器翻译系统的时态一致性性能。

    Tense inconsistency frequently occurs in machine translation. However, there are few criteria to assess the model's mastery of tense prediction from a linguistic perspective. In this paper, we present a parallel tense test set, containing French-English 552 utterances. We also introduce a corresponding benchmark, tense prediction accuracy. With the tense test set and the benchmark, researchers are able to measure the tense consistency performance of machine translation systems for the first time.
    
[^37]: i-Code Studio：一种可配置和可组合的综合AI框架

    i-Code Studio: A Configurable and Composable Framework for Integrative AI. (arXiv:2305.13738v1 [cs.CL])

    [http://arxiv.org/abs/2305.13738](http://arxiv.org/abs/2305.13738)

    i-Code Studio提供了一个综合、灵活和可组合的设置，可以使开发人员快速轻松地组合最先进的服务和技术，以解决复杂的多模态任务，是实现人工通用智能（AGI）的一种重要方法。

    

    人工通用智能（AGI）需要全面的理解和生成能力，可以涵盖不同的模态和功能。综合AI是实现AGI的一种重要方法，通过组合多个模型来解决复杂的多模态任务。然而，缺乏一种灵活和可组合的平台来促进模型的高效和有效的组合和协调。本文提出了i-Code Studio，这是一个可配置和可组合的综合AI框架。 i-Code Studio以无fine-tuning方式协调多个预训练模型，以执行复杂的多模态任务。 i-Code Studio不仅提供简单的模型组合，还提供了一个综合、灵活和可组合的设置，使开发人员能够快速轻松地组合最先进的服务和技术，以满足他们的特定要求。i-Code Studio在多种零-shot多模态任务上取得了惊人的结果。

    Artificial General Intelligence (AGI) requires comprehensive understanding and generation capabilities for a variety of tasks spanning different modalities and functionalities. Integrative AI is one important direction to approach AGI, through combining multiple models to tackle complex multimodal tasks. However, there is a lack of a flexible and composable platform to facilitate efficient and effective model composition and coordination. In this paper, we propose the i-Code Studio, a configurable and composable framework for Integrative AI. The i-Code Studio orchestrates multiple pre-trained models in a finetuning-free fashion to conduct complex multimodal tasks. Instead of simple model composition, the i-Code Studio provides an integrative, flexible, and composable setting for developers to quickly and easily compose cutting-edge services and technologies tailored to their specific requirements. The i-Code Studio achieves impressive results on a variety of zero-shot multimodal tasks,
    
[^38]: 通过合成反馈对齐大型语言模型

    Aligning Large Language Models through Synthetic Feedback. (arXiv:2305.13735v1 [cs.CL])

    [http://arxiv.org/abs/2305.13735](http://arxiv.org/abs/2305.13735)

    该论文提出了一种使用合成反馈对齐大型语言模型的新框架，几乎不需要人力成本，也不依赖于预先对齐的LLMs。其中，通过对尺寸和提示等不同因素的普通 LLMS的响应进行奖励建模，来模拟高质量的示范来训练监督策略，并进一步使用强化学习优化模型。

    

    将大型语言模型(LLMs)与人类价值观对齐变得越来越重要，因为它能够提供复杂的LLMs控制，例如使它们按照特定的指令操作而不会产生有害反应。然而，这需要大量的人类示范和反馈。最近，开源模型试图通过提炼来自已对齐的LLMs（如InstructGPT或ChatGPT）的数据来复制对齐学习过程。虽然这个过程减少了人力成本，但是构建这些数据集对教师模型的依赖性很高。在这项工作中，我们提出了一个新的对齐学习框架，几乎不需要人类劳动，也不依赖于预先对齐的LLMs。首先，我们使用大小和提示等不同因素的普通LLMs的响应进行合成反馈的奖励建模(RM)。然后，我们使用RM模拟高质量的示范来训练监督策略，并进一步使用强化学习优化模型。

    Aligning large language models (LLMs) to human values has become increasingly important as it enables sophisticated steering of LLMs, e.g., making them follow given instructions while keeping them less toxic. However, it requires a significant amount of human demonstrations and feedback. Recently, open-sourced models have attempted to replicate the alignment learning process by distilling data from already aligned LLMs like InstructGPT or ChatGPT. While this process reduces human efforts, constructing these datasets has a heavy dependency on the teacher models. In this work, we propose a novel framework for alignment learning with almost no human labor and no dependency on pre-aligned LLMs. First, we perform reward modeling (RM) with synthetic feedback by contrasting responses from vanilla LLMs with various sizes and prompts. Then, we use the RM for simulating high-quality demonstrations to train a supervised policy and for further optimizing the model with reinforcement learning. Our 
    
[^39]: 巨型语言模型的自我批判提示用于归纳教学指导

    Self-Critique Prompting with Large Language Models for Inductive Instructions. (arXiv:2305.13733v1 [cs.CL])

    [http://arxiv.org/abs/2305.13733](http://arxiv.org/abs/2305.13733)

    本研究提出了一个基准，名为INDust，用于评估大型语言模型（LLMs）对于包含错误信息的指令的抵抗能力。研究发现，当前的LLMs很容易被欺骗，因此采用自我批判提示的方法来激励LLMs不仅对自己进行批评，而且对用户进行批评。

    

    大量的工作都被提出来提高或评估大型语言模型（LLM）实现用户指令的能力。 然而，它们忽略了用户输入可能因用户的错误信念或恶意意图而固有地包含不正确的信息的可能性。 盲目地遵循用户的错误内容将导致欺骗和伤害。 为解决这个问题，我们提出了一个具有挑战性的基准，由归纳指令（INDust）组成，以评估LLMs是否能够抵抗这些指令。 INDust包括三个类别的15K指令：事实核查指令，基于错误前提的问题和基于错误前提的创意指令。 我们对几个强大的LLMs进行的实验表明，当前的LLMs可以轻易地被INDust欺骗，生成误导性和恶意的陈述。 因此，我们采用自我批判提示，以激励LLMs不仅像以前的工作那样对自己进行批评，而且对用户进行批评，它展示出r。

    Numerous works are proposed to improve or evaluate the capabilities of Large language models (LLMs) to fulfill user instructions. However, they neglect the possibility that user inputs may inherently contain incorrect information due to users' false beliefs or malicious intents. In this way, blindly adhering to users' false content will cause deception and harm. To address this problem, we propose a challenging benchmark consisting of Inductive Instructions (INDust) to evaluate whether LLMs could resist these instructions. The INDust includes 15K instructions across three categories: Fact-Checking Instructions, Questions based on False Premises, and Creative Instructions based on False Premises. Our experiments on several strong LLMs reveal that current LLMs can be easily deceived by INDust into generating misleading and malicious statements. Hence we employ Self-Critique prompting to encourage LLMs to not only critique themselves like in previous works but also the users, which show r
    
[^40]: 基于约束生成的离散提示优化在零样本重排器中的应用

    Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker. (arXiv:2305.13729v1 [cs.IR])

    [http://arxiv.org/abs/2305.13729](http://arxiv.org/abs/2305.13729)

    本文提出了一种新的离散提示优化方法，称为受约束提示生成（Co-Prompt），通过估算最佳排序来引导 PLM 生成的文本朝向最优提示。实验结果表明，Co-Prompt 相对于基线方法表现出卓越的重排性能。

    

    重排器是在给定查询的相关性评分下对检索的文档进行排序的方法，在信息检索（IR）任务中得到了关注。与微调预训练语言模型（PLM）不同，利用大规模语言模型（LLM）作为具有优异结果的零样本重排器。虽然 LLM 在很大程度上依赖于提示语，但零样本重排器提示语的影响和优化尚未得到探究。除了强调优化对零样本重排器的影响外，我们还提出了一种新的离散提示优化方法，称为受约束提示生成（Co-Prompt），通过估算最佳排序来引导 PLM 生成的文本朝向最优提示。实验结果表明，Co-Prompt 相对于基线方法表现出卓越的重排性能。此外，Co-Prompt 生成的提示更易于人类理解。

    Re-rankers, which order retrieved documents with respect to the relevance score on the given query, have gained attention for the information retrieval (IR) task. Rather than fine-tuning the pre-trained language model (PLM), the large-scale language model (LLM) is utilized as a zero-shot re-ranker with excellent results. While LLM is highly dependent on the prompts, the impact and the optimization of the prompts for the zero-shot re-ranker are not explored yet. Along with highlighting the impact of optimization on the zero-shot re-ranker, we propose a novel discrete prompt optimization method, Constrained Prompt generation (Co-Prompt), with the metric estimating the optimum for re-ranking. Co-Prompt guides the generated texts from PLM toward optimal prompts based on the metric without parameter update. The experimental results demonstrate that Co-Prompt leads to outstanding re-ranking performance against the baselines. Also, Co-Prompt generates more interpretable prompts for humans aga
    
[^41]: 以检索方式进行的对话式推荐：一个简单、强大的基准线

    Conversational Recommendation as Retrieval: A Simple, Strong Baseline. (arXiv:2305.13725v1 [cs.CL])

    [http://arxiv.org/abs/2305.13725](http://arxiv.org/abs/2305.13725)

    本论文提出一种以检索方式进行的对话式推荐方法，将对话表示为查询，将物品表示为待检索的文档，并使用基于BM25的检索器进行推荐。相比于使用复杂的外部知识的基准线，该方法简单且更具优越性能。

    

    对话式推荐系统旨在通过自然语言对话向用户推荐合适的物品。然而，大多数现有的方法并没有有效利用这些对话提供的信号。它们严重依赖于显式的外部知识库（例如知识图谱）来增强模型对物品和属性的理解，这很难扩展。为了缓解这个问题，我们提出了一种替代信息检索（IR）风格的方法，将对话表示为查询，将物品表示为待检索的文档。我们扩展了用于检索的文档表示，使用训练集中的对话信息。通过简单的基于BM25的检索器，我们证明了我们的任务设置在流行的CRS基准测试中与复杂的、使用复杂外部知识的基准线相比具有优越性。我们使用以用户为中心的建模和数据增强来对抗冷启动问题，并进一步提高了推荐效果。

    Conversational recommendation systems (CRS) aim to recommend suitable items to users through natural language conversation. However, most CRS approaches do not effectively utilize the signal provided by these conversations. They rely heavily on explicit external knowledge e.g., knowledge graphs to augment the models' understanding of the items and attributes, which is quite hard to scale. To alleviate this, we propose an alternative information retrieval (IR)-styled approach to the CRS item recommendation task, where we represent conversations as queries and items as documents to be retrieved. We expand the document representation used for retrieval with conversations from the training set. With a simple BM25-based retriever, we show that our task formulation compares favorably with much more complex baselines using complex external knowledge on a popular CRS benchmark. We demonstrate further improvements using user-centric modeling and data augmentation to counter the cold start probl
    
[^42]: ChatGPT-EDSS: 基于 ChatGPT 衍生出的上下文词嵌入来训练的具有情感的对话语音合成方法

    ChatGPT-EDSS: Empathetic Dialogue Speech Synthesis Trained from ChatGPT-derived Context Word Embeddings. (arXiv:2305.13724v1 [cs.SD])

    [http://arxiv.org/abs/2305.13724](http://arxiv.org/abs/2305.13724)

    本文提出了一种使用 ChatGPT 提取对话上下文，实现具有情感的对话语音合成的方法。该方法使用 ChatGPT 衍生的上下文单词嵌入来训练模型，实验证明其性能相当于使用情感标签或神经网络衍生的上下文嵌入的方法。

    

    本文提出了 ChatGPT-EDSS，这是一种使用 ChatGPT 抽取对话上下文进行情感对话语音合成（EDSS）的方法。 ChatGPT 是一种聊天机器人，可以深入理解输入提示的内容和目的，并适当地回应用户的请求。我们专注于 ChatGPT 的阅读理解，并将其引入 EDSS，这是一项合成具有共情对话语音的任务。我们的方法首先将聊天历史记录提供给 ChatGPT，并要求其为每行生成表示意图、情感和说话风格的三个单词。然后，使用ChatGPT衍生的上下文单词的嵌入作为调节特征，训练EDSS模型。实验结果表明，我们的方法在性能上与使用情感标签或从聊天历史记录中学习的神经网络衍生的上下文嵌入的方法相当。衍生的 ChatGPT 上下文信息可在 https://sarulab-speech.github.io/demo_ChatGPT_EDSS/ 上获取。

    We propose ChatGPT-EDSS, an empathetic dialogue speech synthesis (EDSS) method using ChatGPT for extracting dialogue context. ChatGPT is a chatbot that can deeply understand the content and purpose of an input prompt and appropriately respond to the user's request. We focus on ChatGPT's reading comprehension and introduce it to EDSS, a task of synthesizing speech that can empathize with the interlocutor's emotion. Our method first gives chat history to ChatGPT and asks it to generate three words representing the intention, emotion, and speaking style for each line in the chat. Then, it trains an EDSS model using the embeddings of ChatGPT-derived context words as the conditioning features. The experimental results demonstrate that our method performs comparably to ones using emotion labels or neural network-derived context embeddings learned from chat histories. The collected ChatGPT-derived context information is available at https://sarulab-speech.github.io/demo_ChatGPT_EDSS/.
    
[^43]: PromptClass: 利用提示增强噪声鲁棒的自训练，进行弱监督文本分类

    PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training. (arXiv:2305.13723v1 [cs.CL])

    [http://arxiv.org/abs/2305.13723](http://arxiv.org/abs/2305.13723)

    提出了一种新的叫PromptClass的弱监督文本分类方法，通过利用提示增强学习，生成噪声鲁棒性更强的伪标签和自我训练。

    

    最近提出的弱监督文本分类模型，仅使用每个目标类别的标签名作为唯一的监督。这种方法相比于完全监督和半监督模型能大大减少人类注释的工作量，因此受到了越来越多的关注。该方法主要使用标签名来生成伪标签，然后用于训练分类器。然而，由于同一单词在不同的上下文中会有不同的含义，因此仅仅使用标签名进行匹配会导致非常嘈杂的伪标签。此外，在伪标签生成阶段产生的错误将直接传播到分类器训练阶段，无法被纠正。本文提出了一种新的方法PromptClass，包含两个模块：(1)伪标签获取模块

    Recently proposed weakly-supervised text classification settings train a classifier using the label name of each target class as the only supervision. Such weakly-supervised settings have been gaining increasing attention since they can largely reduce human annotation efforts compared to fully-supervised and semi-supervised settings. Most existing methods follow the strategy that first uses the label names as static features to generate pseudo labels, which are then used for classifier training. While reasonable, such a commonly adopted framework suffers from two limitations: (1) words can have different meanings in different contexts, so using label names for context-free matching can induce very noisy pseudo labels; and (2) the errors made in the pseudo label generation stage will directly propagate to the classifier training stage without a chance of being corrected. In this paper, we propose a new method, PromptClass, consisting of two modules: (1) a pseudo label acquisition module
    
[^44]: 基于示例引导问答的持续对话状态跟踪

    Continual Dialogue State Tracking via Example-Guided Question Answering. (arXiv:2305.13721v1 [cs.CL])

    [http://arxiv.org/abs/2305.13721](http://arxiv.org/abs/2305.13721)

    本文建议将对话状态跟踪重构为由例子引导的粒度问题回答任务，以最小化服务之间的任务转移，获得持续的学习效益。通过结合简单的持续学习策略，可以在基准数据集上获得最先进的性能。

    

    对话系统需要不断更新以适应新服务，但是简单地使用新服务的数据进行训练会降低先前学习的服务的性能。本文发现，对话状态跟踪(DST)是一个简单的自然语言理解任务，我们建议将其重构为一组由例子引导的粒度问题回答任务，以最小化服务之间的任务转移，从而获得持续的学习效益。我们的方法可以减轻特定服务的记忆负担，并教会模型将所给问题和示例用于从对话中提取必要信息。我们发现，一个只有6000万个参数的模型可以通过学习从检索器获取的上下文示例获得巨大的提升。将我们的方法与简单的持续学习策略相结合，可以在基准数据集上获得最先进的性能，证明了我们方法的有效性。

    Dialogue systems are frequently updated to accommodate new services, but naively updating them by continually training with data for new services in diminishing performance on previously learnt services. Motivated by the insight that dialogue state tracking (DST), a crucial component of dialogue systems that estimates the user's goal as a conversation proceeds, is a simple natural language understanding task, we propose reformulating it as a bundle of granular example-guided question answering tasks to minimize the task shift between services and thus benefit continual learning. Our approach alleviates service-specific memorization and teaches a model to contextualize the given question and example to extract the necessary information from the conversation. We find that a model with just 60M parameters can achieve a significant boost by learning to learn from in-context examples retrieved by a retriever trained to identify turns with similar dialogue state changes. Combining our method
    
[^45]: LogicLLM：探索自监督逻辑增强训练的大语言模型

    LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large Language Models. (arXiv:2305.13718v1 [cs.CL])

    [http://arxiv.org/abs/2305.13718](http://arxiv.org/abs/2305.13718)

    本文介绍了 LogicLLM，一种通过自监督后训练来提高大语言模型的逻辑推理能力的方法，该方法有效地在常见逻辑推理任务上进行表现，超过了目前最先进的无监督基线方法。

    

    改善语言模型的逻辑推理能力的现有努力主要依赖于有监督微调，这阻碍了将模型泛化到新的领域和/或任务。然而，通过发展大语言模型（LLM）已经证明了将丰富的知识压缩为单个代理的能力，使它们能够有效地处理多个任务。然而，我们的初步实验表明，LLMs 在逻辑推理方面并没有表现出能力。LLMs 在逻辑推理基准测试中的表现远远落后于现有的最先进基线。在本文中，我们首次尝试通过自监督后训练来探索融合逻辑知识的可行性，并通过上下文学习来激活它，我们将其称为LogicLLM。具体来说，我们设计了一个MERIt 的自回归目标变体，并将其与两个LLM系列FLAN-T5和LLaMA集成在一起，参数大小范围从30亿到130亿。实验结果表明，我们的方法在常用推理策略上与目前最先进的有监督方法相当，并且远远超过了目前最先进的无监督基线方法。

    Existing efforts to improve logical reasoning ability of language models have predominantly relied on supervised fine-tuning, hindering generalization to new domains and/or tasks. The development of Large Langauge Models (LLMs) has demonstrated the capacity of compressing abundant knowledge into a single proxy, enabling them to tackle multiple tasks effectively. Our preliminary experiments, nevertheless, show that LLMs do not show capability on logical reasoning. The performance of LLMs on logical reasoning benchmarks is far behind the existing state-of-the-art baselines. In this paper, we make the first attempt to investigate the feasibility of incorporating logical knowledge through self-supervised post-training, and activating it via in-context learning, which we termed as LogicLLM. Specifically, we devise an auto-regressive objective variant of MERIt and integrate it with two LLM series, i.e., FLAN-T5 and LLaMA, with parameter size ranging from 3 billion to 13 billion. The results 
    
[^46]: BA-SOT: 面向多说话人ASR的边界感知序列化输出训练

    BA-SOT: Boundary-Aware Serialized Output Training for Multi-Talker ASR. (arXiv:2305.13716v1 [cs.SD])

    [http://arxiv.org/abs/2305.13716](http://arxiv.org/abs/2305.13716)

    BA-SOT是一种面向多说话人ASR的训练方法，通过边界感知和连接时间分类策略，显著提高了模型的准确性和精度。

    

    最近提出的序列化输出训练（SOT）通过生成由特殊标记分隔的说话者转录简化了多说话者自动语音识别（ASR）。但是，频繁的说话者更改可能会使说话者更改预测变得困难。为了解决这个问题，我们提出了边界感知序列化输出训练（BA-SOT），它通过说话者更改检测任务和边界约束损失将边界知识明确地纳入解码器中。我们还引入了一个两阶段连接时间分类（CTC）策略，它将基于标记的SOT CTC结合起来，以恢复时间上下文信息。除了典型的字符错误率（CER），我们引入了基于话语的字符错误率（UD-CER），以进一步衡量说话者更改预测的精度。与原始的SOT相比，BA-SOT将CER / UD-CER降低了5.1％/ 14.0％，并利用预训练的ASR模型进行BA-SOT模型初始化进一步将CER / UD-CER降低了8.4％/ 19.9％。

    The recently proposed serialized output training (SOT) simplifies multi-talker automatic speech recognition (ASR) by generating speaker transcriptions separated by a special token. However, frequent speaker changes can make speaker change prediction difficult. To address this, we propose boundary-aware serialized output training (BA-SOT), which explicitly incorporates boundary knowledge into the decoder via a speaker change detection task and boundary constraint loss. We also introduce a two-stage connectionist temporal classification (CTC) strategy that incorporates token-level SOT CTC to restore temporal context information. Besides typical character error rate (CER), we introduce utterance-dependent character error rate (UD-CER) to further measure the precision of speaker change prediction. Compared to original SOT, BA-SOT reduces CER/UD-CER by 5.1%/14.0%, and leveraging a pre-trained ASR model for BA-SOT model initialization further reduces CER/UD-CER by 8.4%/19.9%.
    
[^47]: CALLS: 具有共情对话方法的日本客户服务中心投诉处理和关注倾听语音语料库

    CALLS: Japanese Empathetic Dialogue Speech Corpus of Complaint Handling and Attentive Listening in Customer Center. (arXiv:2305.13713v1 [cs.SD])

    [http://arxiv.org/abs/2305.13713](http://arxiv.org/abs/2305.13713)

    这份论文介绍了一个日语语音语料库 - CALLS，它旨在将共情对话语音合成应用于客户服务中心的投诉处理和关注倾听领域。对于扩展该技术的应用范围，该语料库具有实际意义。

    

    我们提出了CALLS，这是一个日语语音语料库，将客户中心中的电话呼叫称为共情口语对话的新领域。现有的STUDIES语料库仅涵盖学校教师和学生之间的共情对话。为了扩展共情对话语音合成（EDSS）的应用范围，我们设计了这个语料库，以包括与STUDIES教师相同的女性讲述者，在模拟的电话呼叫中担任操作员。我们描述了语料库构建方法，并分析了录制的语音。我们还使用CALLS和STUDIES语料库进行EDSS实验，以研究不同领域之间的影响。结果显示，在训练过程中混合两个语料库会导致合成语音质量的偏差改进，这是由于表现程度不同所导致的。本语料库的项目页面是http网址。

    We present CALLS, a Japanese speech corpus that considers phone calls in a customer center as a new domain of empathetic spoken dialogue. The existing STUDIES corpus covers only empathetic dialogue between a teacher and student in a school. To extend the application range of empathetic dialogue speech synthesis (EDSS), we designed our corpus to include the same female speaker as the STUDIES teacher, acting as an operator in simulated phone calls. We describe a corpus construction methodology and analyze the recorded speech. We also conduct EDSS experiments using the CALLS and STUDIES corpora to investigate the effect of domain differences. The results show that mixing the two corpora during training causes biased improvements in the quality of synthetic speech due to the different degrees of expressiveness. Our project page of the corpus is this http URL
    
[^48]: 知识的知识：探索大型语言模型对未知-已知不确定性的理解

    Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models. (arXiv:2305.13712v1 [cs.CL])

    [http://arxiv.org/abs/2305.13712](http://arxiv.org/abs/2305.13712)

    本文探索了大型语言模型对其自身知识的理解和测量不确定性的能力。该研究聚焦于解决“已知-未知”问题，提出了新的分类方案，并使用语义评估方法量化了模型表达不确定性的准确性。

    

    本文研究了大型语言模型（LLM）在理解自身知识和测量不确定性方面的能力，以缓解虚构现象。我们专门关注解决“已知-未知”问题，这种问题由于缺乏确定的答案而具有高度不确定性。为了促进我们的研究，我们收集了一个新的已知-未知问题（KUQ）数据集，并提出了一个新的分类方案来阐明不确定性的来源。随后，我们评估LLM区分已知和未知问题以及相应分类的能力。此外，我们在开放式QA环境中评估LLM的答案质量。为了量化答案中表达的不确定性，我们创建了一种语义评估方法，用于测量模型在表达已知vs未知问题的不确定性方面的准确性。

    This paper investigates the capabilities of Large Language Models (LLMs) in the context of understanding their own knowledge and measuring their uncertainty. We argue this is an important feature for mitigating hallucinations. Specifically, we focus on addressing \textit{known-unknown} questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our study, we collect a dataset with new Known-Unknown Questions (KUQ) and propose a novel categorization scheme to elucidate the sources of uncertainty. Subsequently, we assess the LLMs' ability to differentiate between known and unknown questions and classify them accordingly. Moreover, we evaluate the quality of their answers in an Open-Ended QA setting. To quantify the uncertainty expressed in the answers, we create a semantic evaluation method that measures the model's accuracy in expressing uncertainty between known vs unknown questions.
    
[^49]: LLM-Eval：开放领域对话中基于大语言模型的统一多维自动评估方法

    LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models. (arXiv:2305.13711v1 [cs.CL])

    [http://arxiv.org/abs/2305.13711](http://arxiv.org/abs/2305.13711)

    LLM-Eval是一种针对大型语言模型的开放领域对话的多维自动评估方法，其在一个模型调用中涵盖了多个对话质量维度，并提供了有效性、高效性和适应性，是评估开放领域对话系统的多功能强大解决方案。

    

    我们提出了LLM-Eval，一种针对基于大语言模型的开放领域对话的统一多维自动评估方法。现有的评估方法常常依赖于人工注释、基本事实回复或多个LLM提示，这些方法可能需要付出昂贵的代价并消耗大量时间。为了解决这些问题，我们设计了一个单提示评估方法，利用统一的评估模式，在单个模型调用中涵盖了对话质量的多个维度。我们在各种基准数据集上广泛评估了LLM-Eval的性能，并证明了它相对于最先进的评估方法而言具有的有效性、高效性和适应性。我们的分析还强调了为获得准确的评估结果，选择合适的LLM和解码策略的重要性。LLM-Eval提供了一种多功能且强大的解决方案，用于评估开放领域对话系统，简化了评估过程，并提供了在各种情景下的一致性表现。

    We propose LLM-Eval, a unified multi-dimensional automatic evaluation method for open-domain conversations with large language models (LLMs). Existing evaluation methods often rely on human annotations, ground-truth responses, or multiple LLM prompts, which can be expensive and time-consuming. To address these issues, we design a single prompt-based evaluation method that leverages a unified evaluation schema to cover multiple dimensions of conversation quality in a single model call. We extensively evaluate the performance of LLM-Eval on various benchmark datasets, demonstrating its effectiveness, efficiency, and adaptability compared to state-of-the-art evaluation methods. Our analysis also highlights the importance of choosing suitable LLMs and decoding strategies for accurate evaluation results. LLM-Eval offers a versatile and robust solution for evaluating open-domain conversation systems, streamlining the evaluation process and providing consistent performance across diverse scen
    
[^50]: 使用文本界面对齐外部知识以实现端到端任务导向对话系统

    Using Textual Interface to Align External Knowledge for End-to-End Task-Oriented Dialogue Systems. (arXiv:2305.13710v1 [cs.CL])

    [http://arxiv.org/abs/2305.13710](http://arxiv.org/abs/2305.13710)

    本文提出了一种使用文本界面对齐外部知识以消除繁琐过程的端到端任务导向对话系统的新范例，实验结果表明该方法生成了更自然的最终响应，并且相对于先前的模型实现了更大的任务成功率。

    

    传统的端到端任务导向对话系统采用模块化设计。然而，这种设计常常导致代理响应与外部知识之间的不对齐，由于信息表示不足而产生。此外，其评估指标强调评估代理的预词汇化响应，忽略了完成响应的质量。在本文中，我们提出了一个新的范例，使用文本界面对齐外部知识，消除冗余的过程。我们在MultiWOZ-Remake中演示了我们的范例，包括为MultiWOZ数据库构建的交互式文本界面和相应的重新处理的数据集。我们训练了一个端到端对话系统来评估这个新数据集。实验结果表明，我们的方法生成了更自然的最终响应，并且相对于先前的模型实现了更大的任务成功率。

    Traditional end-to-end task-oriented dialogue systems have been built with a modularized design. However, such design often causes misalignment between the agent response and external knowledge, due to inadequate representation of information. Furthermore, its evaluation metrics emphasize assessing the agent's pre-lexicalization response, neglecting the quality of the completed response. In this work, we propose a novel paradigm that uses a textual interface to align external knowledge and eliminate redundant processes. We demonstrate our paradigm in practice through MultiWOZ-Remake, including an interactive textual interface built for the MultiWOZ database and a correspondingly re-processed dataset. We train an end-to-end dialogue system to evaluate this new dataset. The experimental results show that our approach generates more natural final responses and achieves a greater task success rate compared to the previous models.
    
[^51]: 在商业语言模型时代，所有语言的成本都一样吗？基于标记化的探索

    Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models. (arXiv:2305.13707v1 [cs.CL])

    [http://arxiv.org/abs/2305.13707](http://arxiv.org/abs/2305.13707)

    本文研究了商用语言模型API在多语言支持方面存在的问题，分析了标记化对API跨语言定价公平性的影响，并在22种语言中评估了OpenAI语言模型API。我们发现，一些地区的语言付费过高，而且结果较差。

    

    语言模型从研究原型逐渐商业化，被作为Web API提供，最近的研究强调了这些产品的多语言能力。API供应商根据使用量收费，具体而言是由潜在的语言模型处理或生成的“令牌”数量。然而，什么构成一个令牌，是与训练数据和模型相关的，在不同语言中传达相同信息所需的令牌数量差异很大。在这项工作中，我们分析了这种不均匀性对 API 跨语言定价公平性的影响。我们对 22 种语言进行了系统分析，评估OpenAI的语言模型API在多语言基准测试中的成本和效用。我们提供了证据表明，许多支持语言的使用者付费过高，并获得更差的结果。这些使用者往往来自 API 使用率较低的地区。

    Language models have graduated from being research prototypes to commercialized products offered as web APIs, and recent works have highlighted the multilingual capabilities of these products. The API vendors charge their users based on usage, more specifically on the number of ``tokens'' processed or generated by the underlying language models. What constitutes a token, however, is training data and model dependent with a large variance in the number of tokens required to convey the same information in different languages. In this work, we analyze the effect of this non-uniformity on the fairness of an API's pricing policy across languages. We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less af
    
[^52]: MemeCap：一个用于说明和解释Memes的数据集

    MemeCap: A Dataset for Captioning and Interpreting Memes. (arXiv:2305.13703v1 [cs.CL])

    [http://arxiv.org/abs/2305.13703](http://arxiv.org/abs/2305.13703)

    MemeCap是一个新的数据集，用于说明和解释Memes。 然而，即使是最先进的视觉和语言模型也难以应对Memes中的视觉隐喻，表现远远不如人类。

    

    Memes是网民们使用视觉隐喻表达他们的思想的广泛工具。理解Memes需要识别和解释视觉隐喻，同时考虑Memes内外的文本，并常常使用背景知识和推理能力。我们提出了MemeCaption任务，并发布了一个新的数据集MemeCap。此数据集包含6.3K个Memes，以及包含Memes的帖子的标题、Memes的说明、字面图像说明和视觉隐喻。尽管近年来视觉和语言（VL）模型在图像说明和视觉问答等任务上取得了成功，但我们使用最先进的VL模型进行的广泛实验表明，它们仍然难以应对视觉隐喻，且表现远不如人类。

    Memes are a widely popular tool for web users to express their thoughts using visual metaphors. Understanding memes requires recognizing and interpreting visual metaphors with respect to the text inside or around the meme, often while employing background knowledge and reasoning abilities. We present the task of meme captioning and release a new dataset, MemeCap. Our dataset contains 6.3K memes along with the title of the post containing the meme, the meme captions, the literal image caption, and the visual metaphors. Despite the recent success of vision and language (VL) models on tasks such as image captioning and visual question answering, our extensive experiments using state-of-the-art VL models show that they still struggle with visual metaphors, and perform substantially worse than humans.
    
[^53]: 探索大型语言模型在古典语言学中的应用

    Exploring Large Language Models for Classical Philology. (arXiv:2305.13698v1 [cs.CL])

    [http://arxiv.org/abs/2305.13698](http://arxiv.org/abs/2305.13698)

    本论文探索使用RoBERTa和T5作为强大的语言模型类型的编码器和编码器-解码器架构，创建了古希腊语和拉丁语等多语言实例的四个古希腊语言模型。测试结果表明，这些模型在形态和句法任务上的表现都得到了显著的提升，并且多语言模型表现优于单语模型。

    

    自然语言处理领域的最新进展已经为包括古希腊语和拉丁语在内的许多语言创建了强大的语言模型。然而，在以往的古典语言研究中，大多数研究都使用BERT。本研究中，我们创建了四个古希腊语言模型，通过两个维度的变化来研究它们在古典语言学中的多功能性。我们探索使用RoBERTa和T5作为强大的语言模型类型的编码器和编码器-解码器架构，并为每个模型创建了包含拉丁语和英语的单语古希腊语和多语言实例。我们评估了所有模型在形态和句法任务上的表现，包括词形还原，展示了T5的解码能力的附加价值。我们进一步定义了两个探测任务来研究预训练在古典文本上的模型所获得的知识。我们的实验提供了对现有古希腊语言模型的第一批基准分析。结果表明，我们的模型相对于当前的最新技术水平提供了显著的改进，并且多语言模型优于单语模型。

    Recent advances in NLP have led to the creation of powerful language models for many languages including Ancient Greek and Latin. While prior work on Classical languages unanimously uses BERT, in this work we create four language models for Ancient Greek that vary along two dimensions to study their versatility for tasks of interest for Classical languages: we explore (i) encoder-only and encoder-decoder architectures using RoBERTa and T5 as strong model types, and create for each of them (ii) a monolingual Ancient Greek and a multilingual instance that includes Latin and English. We evaluate all models on morphological and syntactic tasks, including lemmatization, which demonstrates the added value of T5's decoding abilities. We further define two probing tasks to investigate the knowledge acquired by models pre-trained on Classical texts. Our experiments provide the first benchmarking analysis of existing models of Ancient Greek. Results show that our models provide significant impro
    
[^54]: UNIMO-3: 多层次交互的视觉语言表示学习模型

    UNIMO-3: Multi-granularity Interaction for Vision-Language Representation Learning. (arXiv:2305.13697v1 [cs.CL])

    [http://arxiv.org/abs/2305.13697](http://arxiv.org/abs/2305.13697)

    本研究提出了 UNIMO-3 模型，具有多层次交互能力，能够更好地学习多模态语义信息的交互。

    

    视觉语言预训练旨在学习通用的图文配对表示，以便在各种视觉语言任务中进行转移。与建模单模态数据相比，VL 模型面临的主要挑战是如何从多模态数据中学习跨模态交互，特别是细粒度交互。本文提出了 UNIMO-3 模型，具有同时学习多模态内层交互和跨层交互的能力。 UNIMO-3 模型能够建立有效的连接，从而更好地学习多模态语义信息的交互。

    Vision-and-language (VL) pre-training, which aims to learn a general representation of image-text pairs that can be transferred to various vision-and-language tasks. Compared with modeling uni-modal data, the main challenge of the VL model is: how to learn the cross-modal interaction from multimodal data, especially the fine-grained interaction. Existing works have shown that fully transformer-based models that adopt attention mechanisms to learn in-layer cross-model interaction can demonstrate impressive performance on various cross-modal downstream tasks. However, they ignored that the semantic information of the different modals at the same layer was not uniform, which leads to the cross-modal interaction collapsing into a limited multi-modal semantic information interaction. In this work, we propose the UNIMO-3 model, which has the capacity to simultaneously learn the multimodal in-layer interaction and cross-layer interaction. UNIMO-3 model can establish effective connections betw
    
[^55]: 使用BRIO训练范式的抽象文本摘要

    Abstractive Text Summarization Using the BRIO Training Paradigm. (arXiv:2305.13696v1 [cs.CL])

    [http://arxiv.org/abs/2305.13696](http://arxiv.org/abs/2305.13696)

    本文提出了一种新的BRIO训练范式，以减少摘要模型对参考摘要的依赖，并提高其推理性能。在VieSum数据集上的实验证明，BRIO训练范式可以在基本硬件上优化抽象摘要模型，并在越南文本摘要上取得更好的表现。

    

    抽象摘要模型生成的摘要句子可能连贯全面，但缺乏控制并且严重依赖于参考摘要。BRIO训练范例假定一个非确定性分布，以减少模型对参考摘要的依赖，并提高模型在推理期间的性能。本文提出了一种简单而有效的技术，通过微调预训练语言模型，并使用BRIO训练范式进行训练，以改善抽象摘要。我们建立了一个越南文本摘要数据集，称为VieSum。我们在CNNDM和VieSum数据集上使用经过BRIO模型训练的抽象摘要模型进行实验。结果表明，经过基本硬件训练的模型优于所有现有的抽象摘要模型，特别是对于越南语而言。

    Summary sentences produced by abstractive summarization models may be coherent and comprehensive, but they lack control and rely heavily on reference summaries. The BRIO training paradigm assumes a non-deterministic distribution to reduce the model's dependence on reference summaries, and improve model performance during inference. This paper presents a straightforward but effective technique to improve abstractive summaries by fine-tuning pre-trained language models, and training them with the BRIO paradigm. We build a text summarization dataset for Vietnamese, called VieSum. We perform experiments with abstractive summarization models trained with the BRIO paradigm on the CNNDM and the VieSum datasets. The results show that the models, trained on basic hardware, outperform all existing abstractive summarization models, especially for Vietnamese.
    
[^56]: 医学多文献摘要的自动评估指标与人工评估不一致

    Automated Metrics for Medical Multi-Document Summarization Disagree with Human Evaluations. (arXiv:2305.13693v1 [cs.CL])

    [http://arxiv.org/abs/2305.13693](http://arxiv.org/abs/2305.13693)

    在医学文献综述的多文献摘要中，现有的自动评估指标与人工评估存在不一致性，需要更好的评估指标和数据集支持。

    

    评估多文献摘要（MDS）质量是困难的，特别是在生物医学文献综述的情况下。先前的工作表明，模型可能会利用难以用标准n-gram相似度指标（如ROUGE）检测的快捷方式，而不是执行任务。需要更好的自动化评估指标，但提出评估指标时很少有资源可以评估。因此，我们介绍了一个人工评估的摘要质量方面和成对偏好的数据集，以鼓励和支持更好的文献综述MDS自动化评估方法的发展。我们利用社区提交的多文档综述（MSLR）共享任务，编编译了多样化且代表性的摘要样本，并分析了自动摘要评估指标与词汇相的关系。

    Evaluating multi-document summarization (MDS) quality is difficult. This is especially true in the case of MDS for biomedical literature reviews, where models must synthesize contradicting evidence reported across different documents. Prior work has shown that rather than performing the task, models may exploit shortcuts that are difficult to detect using standard n-gram similarity metrics such as ROUGE. Better automated evaluation metrics are needed, but few resources exist to assess metrics when they are proposed. Therefore, we introduce a dataset of human-assessed summary quality facets and pairwise preferences to encourage and support the development of better automated evaluation methods for literature review MDS. We take advantage of community submissions to the Multi-document Summarization for Literature Review (MSLR) shared task to compile a diverse and representative sample of generated summaries. We analyze how automated summarization evaluation metrics correlate with lexical
    
[^57]: 面向任务导向对话的信息请求中的澄清问题提问方法

    Towards Asking Clarification Questions for Information Seeking on Task-Oriented Dialogues. (arXiv:2305.13690v1 [cs.CL])

    [http://arxiv.org/abs/2305.13690](http://arxiv.org/abs/2305.13690)

    本文提出了一个名为MAS2S的多注意力Seq2Seq网络，它能够提问以澄清任务导向信息获取中用户的信息需求和个人资料。实验证明该模型在任务导向信息查询方面的准确性和覆盖范围优于现有模型。

    

    任务导向的对话系统旨在为用户提供特定任务的服务。这种系统的用户通常不知道他们正在完成的任务的所有信息，需要寻求关于任务的信息。为了提供准确和个性化的任务导向信息查询结果，任务导向对话系统需要解决两个潜在问题：1) 用户无法在请求中描述他们复杂的信息需求；2) 系统对用户的信息存在模糊/缺失。在本文中，我们提出了一个新的多注意力Seq2Seq网络，命名为MAS2S，它可以提问以澄清用户在任务导向信息查询中的信息需求和用户个人资料。我们还扩展了现有的任务导向信息查询数据集，导致我们的数据集包含约100k个任务导向信息查询对话，这些对话是公开的\footnote{ 数据集和代码可在\href{http://link/to/dataset}{http://link/to/dataset}找到}。在扩展的数据集上进行的实验表明，所提出的模型在任务导向信息查询的准确性和覆盖范围方面优于现有模型。

    Task-oriented dialogue systems aim at providing users with task-specific services. Users of such systems often do not know all the information about the task they are trying to accomplish, requiring them to seek information about the task. To provide accurate and personalized task-oriented information seeking results, task-oriented dialogue systems need to address two potential issues: 1) users' inability to describe their complex information needs in their requests; and 2) ambiguous/missing information the system has about the users. In this paper, we propose a new Multi-Attention Seq2Seq Network, named MAS2S, which can ask questions to clarify the user's information needs and the user's profile in task-oriented information seeking. We also extend an existing dataset for task-oriented information seeking, leading to the \ourdataset which contains about 100k task-oriented information seeking dialogues that are made publicly available\footnote{Dataset and code is available at \href{http
    
[^58]: mPLM-Sim: 揭示多语言预训练语言模型中更好的跨语言相似性和迁移

    mPLM-Sim: Unveiling Better Cross-Lingual Similarity and Transfer in Multilingual Pretrained Language Models. (arXiv:2305.13684v1 [cs.CL])

    [http://arxiv.org/abs/2305.13684](http://arxiv.org/abs/2305.13684)

    mPLM-Sim是一种新的语言相似度测量方法，利用多语言平行语料库从mPLMs中引导出语言之间的相似性，可用于选择源语言以增强跨语言迁移，具有中等程度的相关性。不同的mPLMs和层产生不同的相似性结果。

    

    近期的多语言预训练语言模型（mPLMs）已经证明具有强大的特定语言信号，这些信号在预训练期间并没有被明确提供。目前仍然存在一个问题，即是否可将mPLMs用于测量语言相似性，并随后使用相似性结果选择源语言以增强跨语言迁移。为了研究这一问题，我们提出了一种新的语言相似度测量方法mPLM-Sim，它利用多语言平行语料库从mPLMs中引导出语言之间的相似性。我们的研究表明，mPLM-Sim与词汇统计、语系和地理区域等语言相似度测量具有中等程度的相关性。我们还对相关性较低的语言进行了案例研究，并观察到mPLM-Sim产生更准确的相似性结果。此外，我们发现相似性结果因不同的mPLMs和mPLM中的不同层而异。我们进一步调查了mPLMs对语言迁移的影响。

    Recent multilingual pretrained language models (mPLMs) have been shown to encode strong language-specific signals, which are not explicitly provided during pretraining. It remains an open question whether it is feasible to employ mPLMs to measure language similarity, and subsequently use the similarity results to select source languages for boosting cross-lingual transfer. To investigate this, we propose mPLM-Sim, a new language similarity measure that induces the similarities across languages from mPLMs using multi-parallel corpora. Our study shows that mPLM-Sim exhibits moderately high correlations with linguistic similarity measures, such as lexicostatistics, genealogical language family, and geographical sprachbund. We also conduct a case study on languages with low correlation and observe that mPLM-Sim yields more accurate similarity results. Additionally, we find that similarity results vary across different mPLMs and different layers within an mPLM. We further investigate whethe
    
[^59]: 文本到SQL语义解析中的误差检测

    Error Detection for Text-to-SQL Semantic Parsing. (arXiv:2305.13683v1 [cs.CL])

    [http://arxiv.org/abs/2305.13683](http://arxiv.org/abs/2305.13683)

    该论文提出了一种独立于解析器的文本到SQL语义解析的误差检测模型，该模型可以有效地提高解析器的性能和可用性，不考虑其架构。

    

    尽管近年来文本到SQL语义解析取得了显著进展，但现有解析器的性能仍远非完美。同时，现代基于深度学习的文本到SQL解析器往往过于自信，因此在实际使用时对其可靠性产生怀疑。基于此，我们提出了一种独立于解析器的文本到SQL语义解析的误差检测模型。该模型基于代码的预训练语言模型，并利用图神经网络学习到的结构特征进行增强。我们在跨领域设置中收集的实际解析误差上训练我们的模型。针对具有不同解码机制的三种强大的文本到SQL解析器的实验表明，我们的方法优于解析器依赖的不确定性度量，并且可以有效地提高解析器的性能和可用性，而不考虑其架构。

    Despite remarkable progress in text-to-SQL semantic parsing in recent years, the performance of existing parsers is still far from perfect. At the same time, modern deep learning based text-to-SQL parsers are often over-confident and thus casting doubt on their trustworthiness when deployed for real use. To that end, we propose to build a parser-independent error detection model for text-to-SQL semantic parsing. The proposed model is based on pre-trained language model of code and is enhanced with structural features learned by graph neural networks. We train our model on realistic parsing errors collected from a cross-domain setting. Experiments with three strong text-to-SQL parsers featuring different decoding mechanisms show that our approach outperforms parser-dependent uncertainty metrics and could effectively improve the performance and usability of text-to-SQL semantic parsers regardless of their architectures.
    
[^60]: 面向公共论坛的可法律强制执行的仇恨言论检测研究

    Towards Legally Enforceable Hate Speech Detection for Public Forums. (arXiv:2305.13677v1 [cs.CL])

    [http://arxiv.org/abs/2305.13677](http://arxiv.org/abs/2305.13677)

    本研究提出了一个以法律定义为中心的、可法律强制执行的仇恨言论检测任务，利用法律专家对数据集进行了注释，结合基于零样本和小样本的提示，可以使模型的输出更符合监管者目标。

    

    仇恨言论是公共论坛上的严重问题，对恶意和歧视性语言的适当执行是保护人群免受伤害和歧视的关键。然而，确定什么构成仇恨言论是一项非常复杂的任务，高度容易受到主观解释的影响。现有的作品没有将它们的系统与可执行的仇恨言论定义对齐，这可能会使它们的输出与监管者的目标不一致。我们的研究引入了一个新的任务，即以法律定义为中心的可执行仇恨言论检测，并使用法律专家对违反十一种可能定义进行了数据集注释。考虑到确定清晰、可法律强制执行的仇恨言论的挑战，我们使用专家生成的样本和自动挖掘的挑战集增强了数据集。我们尝试使用零样本和小样本的提示来基于这些定义来决定模型的输出。然后，我们报告了在几个大型语言模型上的结果。

    Hate speech is a serious issue on public forums, and proper enforcement of hate speech laws is key for protecting groups of people against harmful and discriminatory language. However, determining what constitutes hate speech is a complex task that is highly open to subjective interpretations. Existing works do not align their systems with enforceable definitions of hate speech, which can make their outputs inconsistent with the goals of regulators. Our work introduces a new task for enforceable hate speech detection centred around legal definitions, and a dataset annotated on violations of eleven possible definitions by legal experts. Given the challenge of identifying clear, legally enforceable instances of hate speech, we augment the dataset with expert-generated samples and an automatically mined challenge set. We experiment with grounding the model decision in these definitions using zero-shot and few-shot prompting. We then report results on several large language models (LLMs). 
    
[^61]: 多语言还是单一语种？基于基础语言模型的多语言百科知识检索能力评估

    Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models. (arXiv:2305.13675v1 [cs.CL])

    [http://arxiv.org/abs/2305.13675](http://arxiv.org/abs/2305.13675)

    本文评估了基础模型在跨越多种语言、主题和上下文来检索百科知识的能力，发现Meta的LLaMA模型准确率较高，但也存在不足之处，表明利用基础语言模型作为多语种工具的前景并不明显。

    

    本文中，我们评估了基础模型在跨越多种语言、主题和上下文来检索百科知识的能力。为支持这一工作，我们制作了一个新的数据集，其中包含20种不同语言的303k个事实关联，并制定了一种新的反事实知识评估方式“多语种还是单一语种”，并在多语言环境下对5个基础模型进行了基准测试，以及在英语环境下对20种模型进行了测试。我们观察到感兴趣的模型的准确性差异显著，Meta的LLaMA模型在多语种和仅英语评估中均排名第一。误差分析显示，LLaMA模型在检索使用西里尔字母书写的语言的事实时有显著不足，同时在理解主语的位置和性别方面存在漏洞。最终，我们认为，将基础语言模型用作真正的多语种必备工具时，它们被赋予了检索信息的任务，这种承诺大大降低了它们的价值。

    In this work, we evaluate the capacity for foundation models to retrieve encyclopedic knowledge across a wide range of languages, topics, and contexts. To support this effort, we 1) produce a new dataset containing 303k factual associations in 20 different languages, 2) formulate a new counterfactual knowledge assessment, Polyglot or Not, and 3) benchmark 5 foundation models in a multilingual setting and a diverse set of 20 models in an English-only setting. We observed significant accuracy differences in models of interest, with Meta's LLaMA topping both the multilingual and English-only assessments. Error analysis reveals a significant deficiency in LLaMA's ability to retrieve facts in languages written in the Cyrillic script and gaps in its understanding of facts based on the location and gender of entailed subjects. Ultimately, we argue that the promise of utilizing foundation language models as bonafide polyglots is greatly diminished when they are tasked with retrieving informati
    
[^62]: 语言模型的物理学：第一部分，上下文无关文法。

    Physics of Language Models: Part 1, Context-Free Grammar. (arXiv:2305.13673v1 [cs.CL])

    [http://arxiv.org/abs/2305.13673](http://arxiv.org/abs/2305.13673)

    本研究探究了生成式语言模型如何学习上下文无关文法（CFG），并通过构造人造数据证明了预训练transformers可以学会生成具有接近完美准确度和显着多样性的句子。研究发现transformer内部的隐藏状态隐含而精确地编码了CFG结构，学会形成类似动态规划的“边界到边界”的注意力。此外，还研究了标准CFG的扩展，例如概率CFG和线性CFG，并证明transformers也可以学会这些扩展语法结构。

    

    我们设计了实验来研究生成式语言模型（例如GPT）如何学习上下文无关文法（CFG）-具有树状结构的多样化语言系统，可捕捉许多自然语言，程序和人类逻辑的方面。CFG与下推自动机一样困难，可能是模棱两可的，因此验证字符串是否满足规则需要动态规划。我们构造了人造数据，并证明即使对于非常具有挑战性的CFG，预训练transformers也可以学会生成具有接近完美准确度和显着多样性的句子。更重要的是，我们深入探讨了transformers学习CFG背后的物理原理。我们发现transformer内部的隐藏状态隐含而精确地编码了CFG结构（如在子树边界上精确定位树节点信息），并学会形成类似动态规划的“边界到边界”的注意力。我们还涵盖了一些标准CFG的扩展，例如概率CFG和线性CFG，并展示transformers也可以学会这些扩展语法结构。我们的工作揭示了语言模型的内部工作原理，并为未来的模型设计和分析提供了启示。

    We design experiments to study $\textit{how}$ generative language models, like GPT, learn context-free grammars (CFGs) -- diverse language systems with a tree-like structure capturing many aspects of natural languages, programs, and human logics. CFGs are as hard as pushdown automata, and can be ambiguous so that verifying if a string satisfies the rules requires dynamic programming. We construct synthetic data and demonstrate that even for very challenging CFGs, pre-trained transformers can learn to generate sentences with near-perfect accuracy and remarkable $\textit{diversity}$.  More importantly, we delve into the $\textit{physical principles}$ behind how transformers learns CFGs. We discover that the hidden states within the transformer implicitly and $\textit{precisely}$ encode the CFG structure (such as putting tree node information exactly on the subtree boundary), and learn to form "boundary to boundary" attentions that resemble dynamic programming. We also cover some extensio
    
[^63]: 通过交互式问题-知识对齐解决语言模型幻觉问题

    Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment. (arXiv:2305.13669v1 [cs.CL])

    [http://arxiv.org/abs/2305.13669](http://arxiv.org/abs/2305.13669)

    本文提出了MixAlign框架，通过与用户和知识库交互，实现自动的问题-知识对齐，从而解决了语言模型因无法正确理解问题和知识而导致的幻觉问题。

    

    尽管语言模型近期进展显著，但仍面临幻觉问题，可能会生成误导性和不支持的回答。一种缓解幻觉问题的常见方法是从知识库中检索和整合支持证据。然而，用户的问题通常与存储的知识不太对齐，因为他们在提问前不知道可用的信息。这种不对齐可能限制语言模型定位和利用知识的能力，可能迫使其通过忽略或覆盖检索到的证据而产生幻觉。为了解决这个问题，我们介绍了 MixAlign，一个框架，它与用户和知识库交互以获得并整合关于用户问题与存储信息相关性的澄清信息。 MixAlign 采用语言模型实现自动问题-知识对齐，并在需要时通过人工用户澄清进一步增强这种对齐。

    Despite the remarkable recent advances in language models, they still struggle with the hallucination problem and can generate misleading and unsupported responses. A common approach to mitigate the hallucination issue is retrieving and incorporating supporting evidence from a knowledge base. However, user questions usually do not align well with the stored knowledge, as they are unaware of the information available before asking questions. This misalignment can limit the language model's ability to locate and utilize the knowledge, potentially forcing it to hallucinate by ignoring or overriding the retrieved evidence. To address this issue, we introduce MixAlign, a framework that interacts with both the user and the knowledge base to obtain and integrate clarifications on how the user question relates to the stored information. MixAlign employs a language model to achieve automatic question-knowledge alignment and, if necessary, further enhances this alignment through human user clari
    
[^64]: 通过相似度学习在具体模拟中对概念词汇进行定位和区分

    Grounding and Distinguishing Conceptual Vocabulary Through Similarity Learning in Embodied Simulations. (arXiv:2305.13668v1 [cs.CL])

    [http://arxiv.org/abs/2305.13668](http://arxiv.org/abs/2305.13668)

    本论文提出了一种新的方法，利用具体模拟中的智能体经验将上下文化的词向量接地到物体表示中。结果发现接地对象标记向量比接地动词和属性标记向量更有帮助。

    

    我们提出了一种新的方法，利用通过具体模拟收集的智能体经验，将上下文化的词向量接地到物体表示中。我们使用相似度学习来比较不同对象类型之间的差异，并提取与物体行为相关的共同特征。然后我们使用仿射变换来计算从不同基于转换器的语言模型的上下文化词向量到这个学习空间的投影矩阵，并评估是否将转换后的标记向量的新测试实例正确地识别为对象嵌入空间中的正确概念。我们的结果揭示了四种不同转换模型的嵌入空间的特性，并表明接地对象标记向量通常比接地动词和属性标记向量更有帮助，这反映了早期类比推理和心理语言学文献中的结论。

    We present a novel method for using agent experiences gathered through an embodied simulation to ground contextualized word vectors to object representations. We use similarity learning to make comparisons between different object types based on their properties when interacted with, and to extract common features pertaining to the objects' behavior. We then use an affine transformation to calculate a projection matrix that transforms contextualized word vectors from different transformer-based language models into this learned space, and evaluate whether new test instances of transformed token vectors identify the correct concept in the object embedding space. Our results expose properties of the embedding spaces of four different transformer models and show that grounding object token vectors is usually more helpful to grounding verb and attribute token vectors than the reverse, which reflects earlier conclusions in the analogical reasoning and psycholinguistic literature.
    
[^65]: 优化对比学习的非自回归Transformer

    Optimizing Non-Autoregressive Transformers with Contrastive Learning. (arXiv:2305.13667v1 [cs.CL])

    [http://arxiv.org/abs/2305.13667](http://arxiv.org/abs/2305.13667)

    本文通过从模型分布中采样来缓解NATs学习多模态数据分布的困难，并导出对比约束来稳定训练过程。该方法在机器翻译、文本摘要和改写三个任务上优于以前的非自回归基线。

    

    非自回归Transformer (NATs) 可以同时预测所有单词，而不是按顺序预测，从而减少了自回归Transformer（ATs）的推断延迟。它们在机器翻译以及许多其他应用中取得了显着的进展。然而，NATs 长期以来面临的挑战是学习多模态数据分布，这是 NATs 和 ATs 性能差距的主要原因。本文提出通过从模型分布中采样来缓解模态学习的困难，而不是从数据分布中采样。我们导出对比约束来稳定训练过程，并将此结果的目标与最先进的 NAT 架构 DA-Transformer 集成。我们的模型在机器翻译、文本摘要和改写这3个任务中进行了检验，共使用了5种基准测试。结果表明，我们的方法在性能上显著优于以前的非自回归基线，并确立了

    Non-autoregressive Transformers (NATs) reduce the inference latency of Autoregressive Transformers (ATs) by predicting words all at once rather than in sequential order. They have achieved remarkable progress in machine translation as well as many other applications. However, a long-standing challenge for NATs is the learning of multi-modality data distribution, which is the main cause of the performance gap between NATs and ATs. In this paper, we propose to ease the difficulty of modality learning via sampling from the model distribution instead of the data distribution. We derive contrastive constraints to stabilize the training process and integrate this resulting objective with the state-of-the-art NAT architecture DA-Transformer. Our model \method is examined on 3 different tasks, including machine translation, text summarization, and paraphrasing with 5 benchmarks. Results show that our approach outperforms previous non-autoregressive baselines by a significant margin and establi
    
[^66]: 论大型语言模型的错误信息污染风险

    On the Risk of Misinformation Pollution with Large Language Models. (arXiv:2305.13661v1 [cs.CL])

    [http://arxiv.org/abs/2305.13661](http://arxiv.org/abs/2305.13661)

    本文探讨了大型语言模型（LLM）可能误用的潜在风险，指出LLM可以作为有效的误导性信息生成器，导致开放域问答（ODQA）系统性能显著降低，并尝试提出三种防御策略：提示，误报检测和大多数投票。

    

    本文全面调查了现代大型语言模型（LLM）的潜在误用，探讨了其生成可信并具有误导性的信息并对信息密集型应用程序，尤其是开放域问答（ODQA）系统的影响。我们建立了一个威胁模型，并对无意和故意的潜在误用场景进行模拟，以评估LLM可以用于生成信息不实的程度。研究发现，LLM可以作为有效的误导性信息生成器，导致ODQA系统性能显著降低。为了减轻由LLM生成的错误信息带来的危害，我们探讨了三种防御策略：提示，误报检测和大多数投票。虽然初步结果显示这些防御性策略有希望产生明显效果，但还需要做大量工作来应对错误信息污染的挑战。本研究强调了需要进一步进行跨学科研究。

    In this paper, we comprehensively investigate the potential misuse of modern Large Language Models (LLMs) for generating credible-sounding misinformation and its subsequent impact on information-intensive applications, particularly Open-Domain Question Answering (ODQA) systems. We establish a threat model and simulate potential misuse scenarios, both unintentional and intentional, to assess the extent to which LLMs can be utilized to produce misinformation. Our study reveals that LLMs can act as effective misinformation generators, leading to a significant degradation in the performance of ODQA systems. To mitigate the harm caused by LLM-generated misinformation, we explore three defense strategies: prompting, misinformation detection, and majority voting. While initial results show promising trends for these defensive strategies, much more work needs to be done to address the challenge of misinformation pollution. Our work highlights the need for further research and interdisciplinary
    
[^67]: 基于提示的Monte-Carlo树搜索用于目标导向对话策略规划

    Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning. (arXiv:2305.13660v1 [cs.CL])

    [http://arxiv.org/abs/2305.13660](http://arxiv.org/abs/2305.13660)

    GDP-Zero是一种使用Open-Loop MCTS进行目标导向对话策略规划而不需要任何模型训练的方法，并使用大型语言模型作为策略先验、价值函数、用户模拟器和系统模型，在目标导向任务中优于ChatGPT。

    

    目标导向的对话规划通常需要模拟未来的对话交互并估计任务进展。因此，许多方法考虑训练神经网络来执行前瞻搜索算法，例如A *搜索和Monte Carlo Tree Search（MCTS）。然而，这种训练通常需要大量的注释数据，当面临嘈杂的注释或低资源设置时会带来挑战。我们介绍了GDP-Zero，这是一种使用Open-Loop MCTS进行目标导向对话策略规划而不需要任何模型训练的方法。GDP-Zero提示大型语言模型在树搜索期间充当策略先验、价值函数、用户模拟器和系统模型。我们在目标导向任务PersuasionForGood上评估了GDP-Zero，并发现其响应比ChatGPT更受欢迎，达到了59.32％，在交互评估期间比ChatGPT更有说服力。

    Planning for goal-oriented dialogue often requires simulating future dialogue interactions and estimating task progress. Many approaches thus consider training neural networks to perform look-ahead search algorithms such as A* search and Monte Carlo Tree Search (MCTS). However, this training often require abundant annotated data, which creates challenges when faced with noisy annotations or low-resource settings. We introduce GDP-Zero, an approach using Open-Loop MCTS to perform goal-oriented dialogue policy planning without any model training. GDP-Zero prompts a large language model to act as a policy prior, value function, user simulator, and system model during the tree search. We evaluate GDP-Zero on the goal-oriented task PersuasionForGood, and find that its responses are preferred over ChatGPT up to 59.32% of the time, and are rated more persuasive than ChatGPT during interactive evaluations.
    
[^68]: 自动词形变化中的组合数据增强理解

    Understanding compositional data augmentation in automatic morphological inflection. (arXiv:2305.13658v1 [cs.CL])

    [http://arxiv.org/abs/2305.13658](http://arxiv.org/abs/2305.13658)

    本研究揭示了自动词形变化中的数据增强策略StemCorrupt带来的根本性变化，并证明选择高多样性和高预测不确定性的数据点子集是提高其数据效率的有效方法。同时，StemCorrupt能够学习可推广的词形规则。

    

    为了解决数据稀疏的问题，数据增强技术被广泛应用于低资源的自动词形变化中。然而，这些技术的全部影响仍然不为人所知。本研究旨在揭示数据增强策略StemCorrupt的理论方面，该方法通过随机替换现有的黄金标准训练样本中的词干字符来生成合成样本。我们的分析揭示了StemCorrupt带来了根本性的变化，在底层数据分布中展现了固有的组合连接结构。为了补充我们的理论分析，我们调查了StemCorrupt的数据效率。通过对七种类型学不同的语言的广泛评估，我们证明选择高多样性和高预测不确定性的数据点子集显著提高了StemCorrupt的数据效率，相比竞争基线。此外，我们展示了StemCorrupt能够学习可推广的词形规则，这是通过其在域外保留数据上表现出的优异性能所证明的。

    Data augmentation techniques are widely used in low-resource automatic morphological inflection to address the issue of data sparsity. However, the full implications of these techniques remain poorly understood. In this study, we aim to shed light on the theoretical aspects of the data augmentation strategy StemCorrupt, a method that generates synthetic examples by randomly substituting stem characters in existing gold standard training examples. Our analysis uncovers that StemCorrupt brings about fundamental changes in the underlying data distribution, revealing inherent compositional concatenative structure. To complement our theoretical analysis, we investigate the data-efficiency of StemCorrupt. Through evaluation across a diverse set of seven typologically distinct languages, we demonstrate that selecting a subset of datapoints with both high diversity and high predictive uncertainty significantly enhances the data-efficiency of StemCorrupt compared to competitive baselines. Furth
    
[^69]: ChatGPT作为你的个人数据科学家

    ChatGPT as your Personal Data Scientist. (arXiv:2305.13657v1 [cs.CL])

    [http://arxiv.org/abs/2305.13657](http://arxiv.org/abs/2305.13657)

    ChatGPT框架作为一种个人数据科学家，可以利用自然对话界面协助用户进行自动化机器学习任务。

    

    大数据的兴起加强了需要高效易用的自动化机器学习工具 (AutoML)。然而，理解特定领域的数据以及定义预测任务的复杂性需要人工干预，使该过程耗时且无法完全自动化。相反，构想一个智能代理，通过直观、自然的对话协助用户进行 AutoML 任务，而无需深入了解底层的机器学习 (ML) 过程。这个代理的主要挑战是准确理解用户的预测目标，并因此制定精确的 ML 任务，相应地调整数据集和模型参数，并有效地表述结果。本文通过引入基于 ChatGPT 的对话性数据科学框架，实现了作为“个人数据科学家”的初步目标。具体而言，我们利用大型语言模型 (ChatGPT) 构建自然语言接口来交互地进行自动化机器学习任务。

    The rise of big data has amplified the need for efficient, user-friendly automated machine learning (AutoML) tools. However, the intricacy of understanding domain-specific data and defining prediction tasks necessitates human intervention making the process time-consuming while preventing full automation. Instead, envision an intelligent agent capable of assisting users in conducting AutoML tasks through intuitive, natural conversations without requiring in-depth knowledge of the underlying machine learning (ML) processes. This agent's key challenge is to accurately comprehend the user's prediction goals and, consequently, formulate precise ML tasks, adjust data sets and model parameters accordingly, and articulate results effectively. In this paper, we take a pioneering step towards this ambitious goal by introducing a ChatGPT-based conversational data-science framework to act as a "personal data scientist". Precisely, we utilize Large Language Models (ChatGPT) to build a natural inte
    
[^70]: 理解和减少文本分类中的伪相关性

    Understanding and Mitigating Spurious Correlations in Text Classification. (arXiv:2305.13654v1 [cs.CL])

    [http://arxiv.org/abs/2305.13654](http://arxiv.org/abs/2305.13654)

    本文研究了深度学习模型容易利用训练集中存在但通常不成立的伪相关性的问题，并提出了一种邻域分析框架以解释语言模型如何利用伪相关性。通过一系列正则化方法NFL（不要忘记你的语言）避免了这种情况，并在实验中证明了其鲁棒性方面的显著改进。

    

    最近的研究表明，深度学习模型容易利用训练集中存在但通常不成立的伪相关性。例如情感分类器可能会错误地学习到令人愉悦的电影评论总是与“Spielberg”这个词相关联。依赖于伪相关性可能会导致泛化性能显著降低，因此应该避免。本文提出了一种邻域分析框架来解释语言模型如何利用伪相关性。在此基础上，我们提出了一系列正则化方法NFL（不要忘记你的语言），以避免这种情况。在两个文本分类任务上的实验表明，NFL相对于标准的微调算法在鲁棒性方面带来了显著的改进，而没有牺牲在数据内部的准确性。

    Recent work has shown that deep learning models are prone to exploit spurious correlations that are present in the training set, yet may not hold true in general. A sentiment classifier may erroneously learn that the token spielberg is always tied to positive movie reviews. Relying on spurious correlations may lead to significant degradation in generalizability and should be avoided. In this paper, we propose a neighborhood analysis framework to explain how exactly language models exploit spurious correlations. Driven by the analysis, we propose a family of regularization methods, NFL (do Not Forget your Language) to prevent the situation. Experiments on two text classification tasks show that NFL brings a significant improvement over standard fine-tuning in terms of robustness without sacrificing in-distribution accuracy.
    
[^71]: 跨语言知识转移和迭代伪标记在低资源语音识别中的应用

    Cross-lingual Knowledge Transfer and Iterative Pseudo-labeling for Low-Resource Speech Recognition with Transducers. (arXiv:2305.13652v1 [cs.CL])

    [http://arxiv.org/abs/2305.13652](http://arxiv.org/abs/2305.13652)

    本文探讨了两种新技术（跨语言知识转移和迭代伪标记）如何提高低资源语音识别系统的识别准确性，并使用这些技术提高了Transducer基础ASR系统的性能。

    

    近年来，语音技术日益普及。 然而，不同语言的准确性，和因此产生的体验，差异显著，这使得技术不够包容。不同语言的数据可用性是影响准确性的关键因素之一，尤其是在训练全神经端到端自动语音识别系统时。跨语言知识转移和迭代伪标记是两种已被证明成功提高ASR系统准确性的技术，特别适用于像乌克兰语这样的低资源语言。我们的目标是训练一个全神经Transducer基础ASR系统，以替换没有手动注释训练数据的DNN-HMM混合系统。我们表明，使用混合系统产生的转录文本训练的Transducer系统在词错误率方面实现了18%的降低。然而，使用相关语言的跨语言知识转移和迭代伪标记的组合，则进一步提高了ASR系统的性能。

    Voice technology has become ubiquitous recently. However, the accuracy, and hence experience, in different languages varies significantly, which makes the technology not equally inclusive. The availability of data for different languages is one of the key factors affecting accuracy, especially in training of all-neural end-to-end automatic speech recognition systems.  Cross-lingual knowledge transfer and iterative pseudo-labeling are two techniques that have been shown to be successful for improving the accuracy of ASR systems, in particular for low-resource languages, like Ukrainian.  Our goal is to train an all-neural Transducer-based ASR system to replace a DNN-HMM hybrid system with no manually annotated training data. We show that the Transducer system trained using transcripts produced by the hybrid system achieves 18% reduction in terms of word error rate. However, using a combination of cross-lingual knowledge transfer from related languages and iterative pseudo-labeling, we ar
    
[^72]: 无参数，最近邻辅助微调神经机器翻译

    Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine Translation. (arXiv:2305.13648v1 [cs.CL])

    [http://arxiv.org/abs/2305.13648](http://arxiv.org/abs/2305.13648)

    本文探究了如何利用kNN预测的统计信息来改善fine-tuning阶段的机器翻译模型表现，通过不同的方法整合kNN统计信息，成功地提高了BLEU分数。

    

    最近邻算法已经被用于辅助语言模型和机器翻译解码器等生成模型。本文研究了这种非参数模型如何通过kNN预测的统计信息来改进机器翻译模型在fine-tuning阶段的表现。我们探究了不同的方法，如通过门控机制进行渐变缩放、使用kNN的真实概率以及强化学习等方法来整合kNN统计信息。对于四个标准领域的机器翻译数据集，与经典的微调方法相比，我们报道了三种方法的一致改进，对于德英和英德翻译，BLEU分别提高了1.45和1.28分。通过定性分析，我们发现在翻译语法关系或函数词时，有着特别的改进。

    Non-parametric, k-nearest-neighbor algorithms have recently made inroads to assist generative models such as language models and machine translation decoders. We explore whether such non-parametric models can improve machine translation models at the fine-tuning stage by incorporating statistics from the kNN predictions to inform the gradient updates for a baseline translation model. There are multiple methods which could be used to incorporate kNN statistics and we investigate gradient scaling by a gating mechanism, the kNN's ground truth probability, and reinforcement learning. For four standard in-domain machine translation datasets, compared with classic fine-tuning, we report consistent improvements of all of the three methods by as much as 1.45 BLEU and 1.28 BLEU for German-English and English-German translations respectively. Through qualitative analysis, we found particular improvements when it comes to translating grammatical relations or function words, which results in incre
    
[^73]: 多语言摘要中的幻觉检测和缓解

    Detecting and Mitigating Hallucinations in Multilingual Summarisation. (arXiv:2305.13632v1 [cs.CL])

    [http://arxiv.org/abs/2305.13632](http://arxiv.org/abs/2305.13632)

    本文提出一种新的度量方法mFACT，可以在非英语摘要中评估其忠实性。本文还提出了一种简单有效的加权方法，可以通过跨语言转移减少摘要的幻觉问题。

    

    幻觉对于抽象摘要的神经模型的可靠性构成了重大挑战。虽然自动产生的摘要可能流畅，但通常缺乏对原始文档的忠实性。在低资源环境下，如跨语言转移，这个问题变得更加突出。由于现有的忠实性测量方法主要集中于英语，因此在跨语言环境中甚至衡量这种现象的程度也很困难。为了解决这个问题，作者首先提出了一种新的度量方法mFACT，通过从多个英语的忠实性测量结果中借鉴翻译基础知识为非英语摘要评估其忠实性。然后，他们提出了一种简单而有效的方法来通过跨语言转移减少幻觉，该方法将每个训练样本的损失乘以其忠实性得分。通过多种语言的广泛实验，作者证明了mFACT是最适合检测幻觉的度量方法。此外，他们发现他们的提出的加权方法可以缓解幻觉问题。

    Hallucinations pose a significant challenge to the reliability of neural models for abstractive summarisation. While automatically generated summaries may be fluent, they often lack faithfulness to the original document. This issue becomes even more pronounced in low-resource settings, such as cross-lingual transfer. With the existing faithful metrics focusing on English, even measuring the extent of this phenomenon in cross-lingual settings is hard. To address this, we first develop a novel metric, mFACT, evaluating the faithfulness of non-English summaries, leveraging translation-based transfer from multiple English faithfulness metrics. We then propose a simple but effective method to reduce hallucinations with a cross-lingual transfer, which weighs the loss of each training example by its faithfulness score. Through extensive experiments in multiple languages, we demonstrate that mFACT is the metric that is most suited to detect hallucinations. Moreover, we find that our proposed l
    
[^74]: 基于实体的多模态网络内容图像搜索

    EDIS: Entity-Driven Image Search over Multimodal Web Content. (arXiv:2305.13631v1 [cs.CL])

    [http://arxiv.org/abs/2305.13631](http://arxiv.org/abs/2305.13631)

    这篇论文介绍了EDIS数据集，该数据集包括100万个多模态图像和文本配对，旨在鼓励开发实现跨模态信息融合和匹配的检索模型。

    

    为了在实际搜索应用中实现图像检索方法的实用性，需要在数据集规模、实体理解和多模态信息融合方面取得重大进展。

    Making image retrieval methods practical for real-world search applications requires significant progress in dataset scales, entity comprehension, and multimodal information fusion. In this work, we introduce \textbf{E}ntity-\textbf{D}riven \textbf{I}mage \textbf{S}earch (EDIS), a challenging dataset for cross-modal image search in the news domain. EDIS consists of 1 million web images from actual search engine results and curated datasets, with each image paired with a textual description. Unlike datasets that assume a small set of single-modality candidates, EDIS reflects real-world web image search scenarios by including a million multimodal image-text pairs as candidates. EDIS encourages the development of retrieval models that simultaneously address cross-modal information fusion and matching. To achieve accurate ranking results, a model must: 1) understand named entities and events from text queries, 2) ground entities onto images or text descriptions, and 3) effectively fuse tex
    
[^75]: 利用对比自我训练和原型学习改进跨语言命名实体识别的自训练方法

    Improving Self-training for Cross-lingual Named Entity Recognition with Contrastive and Prototype Learning. (arXiv:2305.13628v1 [cs.CL])

    [http://arxiv.org/abs/2305.13628](http://arxiv.org/abs/2305.13628)

    本文提出了一种名为ContProto的方法，通过对比自我训练和基于原型的伪标记，结合表示学习和伪标签精化，在一个一致的框架中提高了跨语言命名实体识别的自训练方法；实验结果表明，ContProto 方法在多个转移对上优于最先进的基准，并在各种基准上取得了显着的改进。

    

    在跨语言命名实体识别中，自训练通常用于通过在伪标记目标语言数据上进行训练来弥合语言差距。然而，由于目标语言性能不佳，伪标签通常存在噪声，限制了整体性能。本文旨在通过在一个一致的框架中结合表示学习和伪标签精化来改进跨语言命名实体识别的自训练方法。我们提出的方法主要包括两个组成部分：（1）对比自我训练和（2）基于原型的伪标记。我们的对比自我训练通过分离不同类别的聚类来促进跨语言转移，并通过产生源语言和目标语言之间紧密对齐的表示来增强跨语言可转移性。同时，基于原型的伪标记在训练过程中有效提高了伪标签的准确性。我们在多个转移对上评估ContProto，实验结果表明，我们的方法优于最先进的基准，并在各种基准上取得了显着的改进。

    In cross-lingual named entity recognition (NER), self-training is commonly used to bridge the linguistic gap by training on pseudo-labeled target-language data. However, due to sub-optimal performance on target languages, the pseudo labels are often noisy and limit the overall performance. In this work, we aim to improve self-training for cross-lingual NER by combining representation learning and pseudo label refinement in one coherent framework. Our proposed method, namely ContProto mainly comprises two components: (1) contrastive self-training and (2) prototype-based pseudo-labeling. Our contrastive self-training facilitates span classification by separating clusters of different classes, and enhances cross-lingual transferability by producing closely-aligned representations between the source and target language. Meanwhile, prototype-based pseudo-labeling effectively improves the accuracy of pseudo labels during training. We evaluate ContProto on multiple transfer pairs, and experim
    
[^76]: Instruct-Align：通过基于对齐的跨语言教学将新语言教给LLM

    Instruct-Align: Teaching Novel Languages with to LLMs through Alignment-based Cross-Lingual Instruction. (arXiv:2305.13627v1 [cs.CL])

    [http://arxiv.org/abs/2305.13627](http://arxiv.org/abs/2305.13627)

    Instruct-Align提出了基于对齐的跨语言教学调整框架，使得教学调整的LLMs能够学习新语言，且不会发生灾难性遗忘。

    

    教学调整的大型语言模型（LLM）已经展示了在多种语言和多种任务上的卓越泛化能力。然而，它们对不同语言的泛化能力会有所不同，尤其是对于少数语言或者是未知语言。先前的工作发现，简单地将新语言适应到经过教学调整的LLM中会导致灾难性遗忘，从而导致这些LLM失去多任务能力。为了解决这个问题，我们提出了称为Instruct-Align的框架，通过基于对齐的跨语言教学调整，使得经过教学调整的LLM能够学习到看不见的和之前学习的语言之间的跨语言对齐。我们在BLOOMZ-560M数据集上的初步结果显示，Instruct-Align能够在仅使用有限量的平行语料的情况下有效地学习新语言，并且通过持续的教学调整，防止了灾难性遗忘。

    Instruction-tuned large language models (LLMs) have shown remarkable generalization capability over multiple tasks in multiple languages. Nevertheless, their generalization towards different languages varies especially to underrepresented languages or even to unseen languages. Prior works on adapting new languages to LLMs find that naively adapting new languages to instruction-tuned LLMs will result in catastrophic forgetting, which in turn causes the loss of multitasking ability in these LLMs. To tackle this, we propose the Instruct-Align a.k.a (IA)$^1$ framework, which enables instruction-tuned LLMs to learn cross-lingual alignment between unseen and previously learned languages via alignment-based cross-lingual instruction-tuning. Our preliminary result on BLOOMZ-560M shows that (IA)$^1$ is able to learn a new language effectively with only a limited amount of parallel data and at the same time prevent catastrophic forgetting by applying continual instruction-tuning through experien
    
[^77]: 激励和评估用于主动对话的大型语言模型：澄清、目标导向和非协作性

    Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration. (arXiv:2305.13626v1 [cs.CL])

    [http://arxiv.org/abs/2305.13626](http://arxiv.org/abs/2305.13626)

    本研究针对大型语言模型的对话系统，针对澄清、目标导向和非协作对话，提出了Proactive Chain-of-Thought提示方案，以增强系统的主动性能力，为未来研究提供了经验结果。

    

    基于大型语言模型（LLM）的对话系统，如ChatGPT，在上下文理解和响应生成方面表现出异常的熟练程度，但是，尽管它们具有卓越的能力，仍然存在限制，例如对模糊查询提供随机猜测答案或无法拒绝用户的请求，这些都被认为是对话代理的主动性方面。这引发了LLM基于对话系统是否能够处理主动对话问题的问题。在这项工作中，我们对基于LLM的对话系统进行了全面的分析，具体关注主动对话系统的三个方面：澄清、目标导向和非协作对话。为了触发LLM的主动性，我们提出了Proactive Chain-of-Thought提示方案，它通过对描述性推理链的目标规划能力增强了LLM。我们讨论了实证结果以促进未来研究。

    Conversational systems based on Large Language Models (LLMs), such as ChatGPT, show exceptional proficiency in context understanding and response generation. However, despite their impressive capabilities, they still possess limitations, such as providing randomly-guessed answers to ambiguous queries or failing to refuse users' requests, both of which are considered aspects of a conversational agent's proactivity. This raises the question of whether LLM-based conversational systems are equipped to handle proactive dialogue problems. In this work, we conduct a comprehensive analysis of LLM-based conversational systems, specifically focusing on three aspects of proactive dialogue systems: clarification, target-guided, and non-collaborative dialogues. To trigger the proactivity of LLMs, we propose the Proactive Chain-of-Thought prompting scheme, which augments LLMs with the goal planning capability over descriptive reasoning chains. Empirical findings are discussed to promote future studi
    
[^78]: 通过语义融合验证多媒体内容审核软件

    Validating Multimedia Content Moderation Software via Semantic Fusion. (arXiv:2305.13623v1 [cs.SE])

    [http://arxiv.org/abs/2305.13623](http://arxiv.org/abs/2305.13623)

    该论文提出了一种名为“Semantic Fusion”的通用有效方法，通过融合两个或多个不同模态的内容审核模型来提高多媒体内容审核软件的验证效果。该方法经过大规模多媒体内容审核数据集的评估，相比现有方法显著提高了验证结果。

    

    社交媒体平台，如Facebook和TikTok的指数级增长，已经改变了人类社会的交流和内容发布方式。在这些平台上，用户可以发布结合文本，音频，图像和视频传递信息的多媒体内容。与此同时，多媒体内容发布设施日益被利用来传播有害内容，如仇恨言论，恶意广告和色情内容。为此，内容审核软件已经广泛部署在这些平台上，以检测和屏蔽有害内容。然而，由于内容审核模型的复杂性以及跨多种模式理解信息的困难，现有的内容审核软件可能会失败，导致极为负面的影响。我们引入Semantic Fusion，这是一种通用而有效的验证多媒体内容审核软件的方法。我们的关键思想是融合两个或更多基于不同模态（如文本，音频，图像和视频）的现有内容审核模型，并利用多模态的互补性和一致性来提高内容审核软件的验证性能。我们在一个大规模的多媒体内容审核数据集上评估了Semantic Fusion，并显示它相比现有方法显著提高了验证结果。

    The exponential growth of social media platforms, such as Facebook and TikTok, has revolutionized communication and content publication in human society. Users on these platforms can publish multimedia content that delivers information via the combination of text, audio, images, and video. Meanwhile, the multimedia content release facility has been increasingly exploited to propagate toxic content, such as hate speech, malicious advertisements, and pornography. To this end, content moderation software has been widely deployed on these platforms to detect and blocks toxic content. However, due to the complexity of content moderation models and the difficulty of understanding information across multiple modalities, existing content moderation software can fail to detect toxic content, which often leads to extremely negative impacts.  We introduce Semantic Fusion, a general, effective methodology for validating multimedia content moderation software. Our key idea is to fuse two or more ex
    
[^79]: SPEECH: 基于能量的事件中心超球的结构化预测

    SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres. (arXiv:2305.13617v1 [cs.CL])

    [http://arxiv.org/abs/2305.13617](http://arxiv.org/abs/2305.13617)

    这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。

    

    事件中心的结构化预测涉及预测事件的结构化输出。在大多数自然语言处理情况下，事件结构都具有复杂的依赖关系，因此有效地表示这些复杂的事件结构是具有挑战性的。为了解决这些问题，我们提出了基于能量的事件中心超球的结构化预测 (SPEECH)。 SPEECH 使用基于能量的建模来模拟事件结构组件之间的复杂依赖关系，并使用简单但有效的超球来表示事件类别。在两个统一标注的事件数据集的实验中，结果表明SPEECH在事件检测和事件关系抽取任务中占优势。

    Event-centric structured prediction involves predicting structured outputs of events. In most NLP cases, event structures are complex with manifold dependency, and it is challenging to effectively represent these complicated structured events. To address these issues, we propose Structured Prediction with Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex dependency among event structured components with energy-based modeling, and represents event classes with simple but effective hyperspheres. Experiments on two unified-annotated event datasets indicate that SPEECH is predominant in event detection and event-relation extraction tasks.
    
[^80]: 基于LLM技术的精神病医生和患者模拟聊天机器人的应用与评估

    LLM-empowered Chatbots for Psychiatrist and Patient Simulation: Application and Evaluation. (arXiv:2305.13614v1 [cs.CL])

    [http://arxiv.org/abs/2305.13614](http://arxiv.org/abs/2305.13614)

    本研究聚焦于探索利用ChatGPT技术赋能聊天机器人在精神病医生和患者模拟方面的潜力，并证明了在精神科场景中使用ChatGPT技术赋能聊天机器人的可行性。

    

    在精神健康领域，赋能聊天机器人正越来越受到关注，然而在精神科门诊场景下，开发和评估聊天机器人仍然缺乏探索。本作品聚焦于探索利用ChatGPT技术赋能聊天机器人在精神病医生和患者模拟方面的潜力。我们与精神病医生合作，确定目标并逐步开发对话系统，紧密结合现实场景。在评估实验中，我们邀请真正的精神病医生和患者与聊天机器人进行诊断性对话，收集他们的评分以进行评估。我们的发现证明了在精神科场景中使用ChatGPT技术赋能聊天机器人的可行性，并探索了提示设计对聊天机器人行为和用户体验的影响。

    Empowering chatbots in the field of mental health is receiving increasing amount of attention, while there still lacks exploration in developing and evaluating chatbots in psychiatric outpatient scenarios. In this work, we focus on exploring the potential of ChatGPT in powering chatbots for psychiatrist and patient simulation. We collaborate with psychiatrists to identify objectives and iteratively develop the dialogue system to closely align with real-world scenarios. In the evaluation experiments, we recruit real psychiatrists and patients to engage in diagnostic conversations with the chatbots, collecting their ratings for assessment. Our findings demonstrate the feasibility of using ChatGPT-powered chatbots in psychiatric scenarios and explore the impact of prompt designs on chatbot behavior and user experience.
    
[^81]: ReSee：在开放域对话中通过视觉知识回应

    ReSee: Responding through Seeing Fine-grained Visual Knowledge in Open-domain Dialogue. (arXiv:2305.13602v1 [cs.CL])

    [http://arxiv.org/abs/2305.13602](http://arxiv.org/abs/2305.13602)

    该研究提供了一种新的构建多模态对话的范例，并提供了两个相关数据集，将视觉知识明确分类为更细粒度来增强准确性和多样性，从互联网或大型图像数据集中检索视觉信息。该研究提出了ReSee框架，可将视觉表示添加到原始对话模型中。

    

    将视觉知识与文本对话系统相结合成为一种模仿人类思考、想象和交流的潜在方向。然而，现有的多模态对话系统或者受到可用数据集的规模和质量的限制，或者受到视觉知识概念的粗糙限制。为了解决这些问题，我们提供了一种构建多模态对话的新范例及其相关数据集（ReSee-WoW、ReSee-DD）。我们提议将视觉知识明确分为更细粒度（“转向级”和“实体级”）。为了进一步增强视觉信息的准确性和多样性，我们从互联网或大型图像数据集中检索它们。为了展示提供的视觉知识的优越性和普适性，我们提出了一个简单而有效的框架ReSee，通过模态连接将视觉表示添加到原始对话模型中。我们还进行了广泛的实验。

    Incorporating visual knowledge into text-only dialogue systems has become a potential direction to imitate the way humans think, imagine, and communicate. However, existing multimodal dialogue systems are either confined by the scale and quality of available datasets or the coarse concept of visual knowledge. To address these issues, we provide a new paradigm of constructing multimodal dialogues as well as two datasets extended from text-only dialogues under such paradigm (ReSee-WoW, ReSee-DD). We propose to explicitly split the visual knowledge into finer granularity (``turn-level'' and ``entity-level''). To further boost the accuracy and diversity of augmented visual information, we retrieve them from the Internet or a large image dataset. To demonstrate the superiority and universality of the provided visual knowledge, we propose a simple but effective framework ReSee to add visual representation into vanilla dialogue models by modality concatenations. We also conduct extensive expe
    
[^82]: 不对称学习率的分离式理性化: 一种灵活的Lipschitz限制

    Decoupled Rationalization with Asymmetric Learning Rates: A Flexible Lipshitz Restraint. (arXiv:2305.13599v1 [cs.LG])

    [http://arxiv.org/abs/2305.13599](http://arxiv.org/abs/2305.13599)

    本文提出了一种名为DR的灵活的方法，它通过不对称的学习率来解决由合作博弈引发的退化问题，该方法能够在两个基准测试中显著改善表现。

    

    通常情况下，自说明理性化模型通过合作博弈构建，其中生成器从输入文本中选择最易理解的部分作为原理，接着预测器基于所选择的原理进行预测。然而，这种合作博弈可能会引发退化问题，预测器过度拟合于由尚未训练好的生成器生成的信息不足的部分，反过来导致生成器收敛于趋向于选择无意义的部分的次优模型。本文从理论上将退化问题与预测器的Lipschitz连续性联系起来。随后，我们实验性地提出了一种名为DR的简单而有效的方法，可以自然、灵活地约束预测器的Lipschitz常数，并解决了退化问题。DR方法的主要思想是将生成器和预测器分离，为它们分配不对称的学习率。在两个广泛使用的基准测试中进行的一系列实验表明，我们的DR方法能够显著改善现有方法的表现。

    A self-explaining rationalization model is generally constructed by a cooperative game where a generator selects the most human-intelligible pieces from the input text as rationales, followed by a predictor that makes predictions based on the selected rationales. However, such a cooperative game may incur the degeneration problem where the predictor overfits to the uninformative pieces generated by a not yet well-trained generator and in turn, leads the generator to converge to a sub-optimal model that tends to select senseless pieces. In this paper, we theoretically bridge degeneration with the predictor's Lipschitz continuity. Then, we empirically propose a simple but effective method named DR, which can naturally and flexibly restrain the Lipschitz constant of the predictor, to address the problem of degeneration. The main idea of DR is to decouple the generator and predictor to allocate them with asymmetric learning rates. A series of experiments conducted on two widely used benchm
    
[^83]: 利用（模糊测试）测试用例来理解程序

    Understanding Programs by Exploiting (Fuzzing) Test Cases. (arXiv:2305.13592v1 [cs.LG])

    [http://arxiv.org/abs/2305.13592](http://arxiv.org/abs/2305.13592)

    本文提出了通过模糊测试获取代表性输入来帮助语义理解程序的方法。

    

    程序的语义理解引起了社区的极大关注。受到自然语言理解中大型语言模型（LLM）的最近成功启发，通过将编程语言视为另一种自然语言，并在程序代码语料库上训练LLM，取得了巨大进展。然而，程序毕竟与文本有本质的区别，因为它们通常具有严格的结构和语法。特别是，程序及其基本单元（即函数和子程序）旨在展示各种行为和/或提供可能的输出，给定不同的输入。输入和可能的输出/行为之间的关系表示函数/子程序，并概述了整个程序。因此，我们提出将这种关系纳入学习中，以实现对程序的更深入语义理解。为了获得足够代表性的输入以触发大量执行，可以使用模糊测试。

    Semantic understanding of programs has attracted great attention in the community. Inspired by recent successes of large language models (LLMs) in natural language understanding, tremendous progress has been made by treating programming language as another sort of natural language and training LLMs on corpora of program code. However, programs are essentially different from texts after all, in a sense that they are normally heavily structured and syntax-strict. In particular, programs and their basic units (i.e., functions and subroutines) are designed to demonstrate a variety of behaviors and/or provide possible outputs, given different inputs. The relationship between inputs and possible outputs/behaviors represents the functions/subroutines and profiles the program as a whole. Therefore, we propose to incorporate such a relationship into learning, for achieving a deeper semantic understanding of programs. To obtain inputs that are representative enough to trigger the execution of mo
    
[^84]: BiasX：使用隐含社会偏见解释在有害内容审查中"缓慢思考"

    BiasX: "Thinking Slow" in Toxic Content Moderation with Explanations of Implied Social Biases. (arXiv:2305.13589v1 [cs.CL])

    [http://arxiv.org/abs/2305.13589](http://arxiv.org/abs/2305.13589)

    BiasX是一个框架，通过输入自由文本解释的隐含社会偏见来提高内容审核的质量。经过大规模的用户研究，我们展示了解释对于准确识别建议的有害内容的微妙程度有很大的帮助。机器生成的解释仅能提高2.4％的有效性，而人工撰写的解释能够提高7.2％的有效性。

    

    在有害内容的注释和审查中，注释员和审查员经常采用心理快捷方式做出决策。这可能会导致错过微妙的有害性，而看似有害但无害的内容被过度检测。我们介绍了BiasX，这是一个框架，通过陈述的隐含社会偏见的自由文本解释来增强内容审查设置，并通过大规模的众包用户研究来探索其有效性。我们展示了参与者通过解释正确识别微妙的（非）有害内容的实际获益。解释的质量至关重要:不完美的机器生成的解释（+2.4%在难以处理的有害样例上）相比专家撰写的人工解释（+7.2%）帮助较少。我们的结果展示了使用自由文本解释鼓励更加深思熟虑的有毒性审查的希望。

    Toxicity annotators and content moderators often default to mental shortcuts when making decisions. This can lead to subtle toxicity being missed, and seemingly toxic but harmless content being over-detected. We introduce BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, and explore its effectiveness through a large-scale crowdsourced user study. We show that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content. The quality of explanations is critical: imperfect machine-generated explanations (+2.4% on hard toxic examples) help less compared to expert-written human explanations (+7.2%). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.
    
[^85]: 基于查询结构建模的知识图谱归纳逻辑推理

    Query Structure Modeling for Inductive Logical Reasoning Over Knowledge Graphs. (arXiv:2305.13585v1 [cs.CL])

    [http://arxiv.org/abs/2305.13585](http://arxiv.org/abs/2305.13585)

    本研究提出了一种基于查询结构建模的文本编码框架，用于在不完整的知识图谱上进行归纳逻辑推理。通过针对复杂查询的结构建模和单独对不同的几何操作进行建模，它在提高泛化能力的同时实现了更准确的答案匹配。

    

    在不完整的知识图谱上进行逻辑推理以回答复杂的逻辑查询是一项具有挑战性的任务。随着不断演化的知识图谱中新实体和关系的出现，基于知识图谱的归纳逻辑推理已成为一个关键问题。然而，之前基于PLMs的方法难以对复杂查询进行逻辑建模，这限制了它们在相同结构内的泛化能力。在本文中，我们提出了一个基于结构建模的文本编码框架，用于在知识图谱上进行归纳逻辑推理。它使用预训练语言模型对线性化的查询结构和实体进行编码以找到答案。针对复杂查询的结构建模，我们设计了逐步指导的指令，它们隐含地提示PLMs在每个查询中执行几何操作的执行顺序。我们进一步使用预训练编码器在表示空间上单独对不同的几何操作（即投影、交集和并集）进行建模，并加入了注意力和最大输出层。

    Logical reasoning over incomplete knowledge graphs to answer complex logical queries is a challenging task. With the emergence of new entities and relations in constantly evolving KGs, inductive logical reasoning over KGs has become a crucial problem. However, previous PLMs-based methods struggle to model the logical structures of complex queries, which limits their ability to generalize within the same structure. In this paper, we propose a structure-modeled textual encoding framework for inductive logical reasoning over KGs. It encodes linearized query structures and entities using pre-trained language models to find answers. For structure modeling of complex queries, we design stepwise instructions that implicitly prompt PLMs on the execution order of geometric operations in each query. We further separately model different geometric operations (i.e., projection, intersection, and union) on the representation space using a pre-trained encoder with additional attention and maxout lay
    
[^86]: 跨模态注意力不足：基于不协调感知的多模态情感分析与识别

    Cross-Attention is Not Enough: Incongruity-Aware Multimodal Sentiment Analysis and Emotion Recognition. (arXiv:2305.13583v1 [cs.CL])

    [http://arxiv.org/abs/2305.13583](http://arxiv.org/abs/2305.13583)

    本文提出了一种基于不协调感知的跨模态情感分析方法，通过Hierarchical Crossmodal Transformer with Modality Gating(HCT-MG)模型来确定主要模态并分层融合辅助模态，有效减轻模态之间的不协调感知和信息冗余问题。

    

    多模态融合在情感计算任务中的应用对性能的提升已被证明是有效的。然而，多模态融合的机理尚不清楚，在现实世界中使用它通常会导致大型模型的问题。本文在情感分析的基础上，首先分析了跨模态注意力中一个模态中突出的情感信息如何受到另一个模态的影响。我们发现，由于跨模态的关注，模态之间存在潜在的不协调感知。基于这一发现，我们提出了一种轻量级模型(HCT-MG)，该模型通过分层交叉模态Transformer与模态门控制来确定主要的模态，并分层地将辅助模态纳入其中，以减轻模态之间的不协调感知并减少信息冗余。在三个基准数据集CMU-MOSI、CMU-MOSEI和IEMOCAP上的实验评估验证了我们方法的有效性，表明：1）其优于当前最先进的多模态模型；2）它仅使用少量的超参数和参数；3）它的计算成本较低。

    Fusing multiple modalities for affective computing tasks has proven effective for performance improvement. However, how multimodal fusion works is not well understood, and its use in the real world usually results in large model sizes. In this work, on sentiment and emotion analysis, we first analyze how the salient affective information in one modality can be affected by the other in crossmodal attention. We find that inter-modal incongruity exists at the latent level due to crossmodal attention. Based on this finding, we propose a lightweight model via Hierarchical Crossmodal Transformer with Modality Gating (HCT-MG), which determines a primary modality according to its contribution to the target task and then hierarchically incorporates auxiliary modalities to alleviate inter-modal incongruity and reduce information redundancy. The experimental evaluation on three benchmark datasets: CMU-MOSI, CMU-MOSEI, and IEMOCAP verifies the efficacy of our approach, showing that it: 1) outperfo
    
[^87]: 通过翻译和注释融合改进低资源实体识别

    Better Low-Resource Entity Recognition Through Translation and Annotation Fusion. (arXiv:2305.13582v1 [cs.CL])

    [http://arxiv.org/abs/2305.13582](http://arxiv.org/abs/2305.13582)

    本研究提出了一种通过翻译和注释融合的框架，可以改进低资源语言文本的命名实体识别。通过TransFusion模型，可以在不同语言之间进行强大的预测，且在两个低资源命名实体识别数据集上表现一致优秀。

    

    预训练的多语言语言模型已经在跨语言转移方面实现了重大进展。然而，这些模型在从高资源语言转移至低资源语言时，通常表现出性能差异，特别是对于未被充分训练或未包含在预训练数据中的语言。受这些模型在高资源语言上表现优秀的启发，我们介绍了一个翻译和融合框架，该框架将低资源语言文本翻译成高资源语言进行注释，然后将注释融合回低资源语言。基于该框架，我们提出了TransFusion模型，该模型训练用于融合来自高资源语言的预测结果，以在低资源语言上进行强大的预测。我们在两个低资源命名实体识别（NER）数据集MasakhaNER2.0和LORELEI NER上评估了我们的方法，并展示了与最先进的跨语言NER基线的一致优秀性能。

    Pre-trained multilingual language models have enabled significant advancements in cross-lingual transfer. However, these models often exhibit a performance disparity when transferring from high-resource languages to low-resource languages, especially for languages that are underrepresented or not in the pre-training data. Motivated by the superior performance of these models on high-resource languages compared to low-resource languages, we introduce a Translation-and-fusion framework, which translates low-resource language text into a high-resource language for annotation using fully supervised models before fusing the annotations back into the low-resource language. Based on this framework, we present TransFusion, a model trained to fuse predictions from a high-resource language to make robust predictions on low-resource languages. We evaluate our methods on two low-resource named entity recognition (NER) datasets, MasakhaNER2.0 and LORELEI NER, covering 25 languages, and show consist
    
[^88]: 在无位置嵌入的Transformer语言模型的自注意力方差中存在潜在的位置信息

    Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings. (arXiv:2305.13571v1 [cs.CL])

    [http://arxiv.org/abs/2305.13571](http://arxiv.org/abs/2305.13571)

    该论文展示了在无位置嵌入的Transformer语言模型的自注意力方差中存在潜在的位置信息，并证明丢弃位置嵌入的决策可促进Transformer语言模型的更有效预训练。

    

    Transformer语言模型通常使用位置嵌入，然而最近的研究质疑此类嵌入的必要性。我们通过展示随机初始化且无位置嵌入的冻结Transformer语言模型通过自注意力方差的收缩内在地编码了强的位置信息，进一步扩展了这一问题。我们通过推导Transformer层内每一步的底层分布来量化这一方差。通过使用完全预训练过的模型进行实证验证，我们证明即使经过了大量的渐进式更新梯度，方差收缩效应仍然存在。我们的发现证明了放弃位置嵌入的决策，并促进Transformer语言模型更有效的预训练。

    The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.
    
[^89]: EntRED: 用更少的捷径进行关系抽取基准测试

    EntRED: Benchmarking Relation Extraction with Fewer Shortcuts. (arXiv:2305.13551v1 [cs.CL])

    [http://arxiv.org/abs/2305.13551](http://arxiv.org/abs/2305.13551)

    本研究提出了一个名称更为多样、没有捷径、具有挑战性的关系提取基准测试EntRed，并解决了标准基准测试数据集存在的实体注释错误、实体名称多样性较低、从实体名称到基本事实关系的捷径等问题。

    

    实体名称在关系抽取中起着有效的作用，并常常影响模型性能。因此，基准测试中测试集中的实体名称显著影响了关系提取模型的评估。本研究发现，标准的关系抽取基准测试数据集存在大量错误的实体注释，实体名称多样性较低，并且容易出现从实体名称到基本事实关系的捷径。这些问题使得标准基准测试与现实世界场景相距甚远。因此，在本研究中，我们提出了EntRED，这是一个具有较少捷径和更高实体多样性的具有挑战性的关系提取基准测试。为构建EntRED，我们提出了一种基于因果推理（CI）的端到端实体替换管道：ERIC。ERIC对实体进行类型约束替换，以减少从实体偏差到基本事实关系的捷径。ERIC在两个方面应用CI：1）针对需要实体替换的实例，2）确定候选实体。

    Entity names play an effective role in relation extraction (RE) and often influence model performance. As a result, the entity names in the benchmarks' test sets significantly influence the evaluation of RE models. In this work, we find that the standard RE benchmarks' datasets have a large portion of incorrect entity annotations, low entity name diversity, and are prone to have shortcuts from entity names to ground-truth relations. These issues make the standard benchmarks far from reflecting the real-world scenarios. Hence, in this work, we present EntRED, a challenging RE benchmark with reduced shortcuts and higher diversity of entities. To build EntRED, we propose an end-to-end entity replacement pipeline based on causal inference (CI): ERIC. ERIC performs type-constrained replacements on entities to reduce the shortcuts from entity bias to ground-truth relations. ERIC applies CI in two aspects: 1) targeting the instances that need entity replacements, and 2) determining the candid
    
[^90]: 基于自我进化学习的 Mixup：增强少样本文本分类任务数据增强

    Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot Text Classification Tasks. (arXiv:2305.13547v1 [cs.CL])

    [http://arxiv.org/abs/2305.13547](http://arxiv.org/abs/2305.13547)

    论文提出了一种基于自我进化学习的 Mixup 方法，用于文本分类的数据扩充，可以为模型训练生成更加适应和友好的伪样本，该方法可以降低模型的overconfidence。

    

    文本分类任务往往遇到有限标注数据的少样本场景，解决数据稀缺问题至关重要。使用 Mixup 进行数据扩充已经在各种文本分类任务中显示出有效性。然而，大多数 Mixup 方法并不考虑训练不同阶段的学习难度差异并产生带有 one hot 标签的新样本，导致模型过于自信。本文提出了一种基于自我进化学习（SE）的 Mixup 方法，用于文本分类的数据扩充，可以为模型训练生成更加适应和友好的伪样本。SE 关注模型的学习能力变化。为了减轻模型置信度，我们引入了一种新的实例标签平滑方法，该方法线性插值模型的输出和原始样本的 one-hot 标签，以生成新的软标签用于混合。通过实验分析，在提高分类准确率的同时，我们的方法可以降低模型的overconfidence。

    Text classification tasks often encounter few shot scenarios with limited labeled data, and addressing data scarcity is crucial. Data augmentation with mixup has shown to be effective on various text classification tasks. However, most of the mixup methods do not consider the varying degree of learning difficulty in different stages of training and generate new samples with one hot labels, resulting in the model over confidence. In this paper, we propose a self evolution learning (SE) based mixup approach for data augmentation in text classification, which can generate more adaptive and model friendly pesudo samples for the model training. SE focuses on the variation of the model's learning ability. To alleviate the model confidence, we introduce a novel instance specific label smoothing approach, which linearly interpolates the model's output and one hot labels of the original samples to generate new soft for label mixing up. Through experimental analysis, in addition to improving cla
    
[^91]: 通过主动生成成对反事实数据来提高分类器的鲁棒性

    Improving Classifier Robustness through Active Generation of Pairwise Counterfactuals. (arXiv:2305.13535v1 [cs.CL])

    [http://arxiv.org/abs/2305.13535](http://arxiv.org/abs/2305.13535)

    本论文提出一种利用反事实生成模型来主动抽样生成大量不同的反事实数据，并自动标记它们的框架。通过训练一个成对分类器来插值原始样例和反事实数据之间的关系，可以更正确地标记生成的反事实数据，从而显著提高自然语言分类器的鲁棒性。

    

    对抗事实数据增强技术（CDA）是提高自然语言分类器鲁棒性的常用技术。然而，如何发现有意义的反事实数据并有效地标记它们是一个根本性挑战，需要尽可能降低人工标记成本。大多数现有方法要么完全依赖于人工标注的标签，这是一个昂贵的过程，限制了反事实数据的规模，要么隐含地假设标签不变性，这可能会误导模型产生错误的标签。本文提出了一个新的框架，利用反事实生成模型从不确定性区域主动抽样生成大量不同的反事实数据，然后用学习的成对分类器自动标记它们。我们的关键洞见是，通过训练一个成对分类器来插值原始样例和反事实数据之间的关系，我们可以更正确地标记生成的反事实数据。我们证明，在小规模的人工标记下，我们的方法可以实现高质量的反事实数据增强，显著提高自然语言分类器的鲁棒性。

    Counterfactual Data Augmentation (CDA) is a commonly used technique for improving robustness in natural language classifiers. However, one fundamental challenge is how to discover meaningful counterfactuals and efficiently label them, with minimal human labeling cost. Most existing methods either completely rely on human-annotated labels, an expensive process which limits the scale of counterfactual data, or implicitly assume label invariance, which may mislead the model with incorrect labels. In this paper, we present a novel framework that utilizes counterfactual generative models to generate a large number of diverse counterfactuals by actively sampling from regions of uncertainty, and then automatically label them with a learned pairwise classifier. Our key insight is that we can more correctly label the generated counterfactuals by training a pairwise classifier that interpolates the relationship between the original example and the counterfactual. We demonstrate that with a small
    
[^92]: 语言模型的幻觉如何会越来越严重

    How Language Model Hallucinations Can Snowball. (arXiv:2305.13534v1 [cs.CL])

    [http://arxiv.org/abs/2305.13534](http://arxiv.org/abs/2305.13534)

    语言模型在生产中容易产生幻觉错误，这些幻觉会导致模型产生更多的错误，并且模型可以自行识别其中的一些错误。

    

    在实际应用中使用语言模型的一个主要风险是它们倾向于产生错误的语句。这些幻觉通常归因于语言模型中的知识缺口，但我们假设在某些情况下，当证明之前产生的幻觉时，语言模型会输出错误的声明，它们可以单独地识别为不正确的。我们构建了三个问答数据集，其中ChatGPT和GPT-4经常陈述错误的答案，并提供至少一个不正确的声明的解释。重要的是，我们发现ChatGPT和GPT-4可以分别识别其自己错误的67％和87％。我们将这种现象称为幻觉滚雪球：语言模型过度致力于早期的错误，导致更多的错误，否则它不会犯这些错误。

    A major risk of using language models in practical applications is their tendency to hallucinate incorrect statements. Hallucinations are often attributed to knowledge gaps in LMs, but we hypothesize that in some cases, when justifying previously generated hallucinations, LMs output false claims that they can separately recognize as incorrect. We construct three question-answering datasets where ChatGPT and GPT-4 often state an incorrect answer and offer an explanation with at least one incorrect claim. Crucially, we find that ChatGPT and GPT-4 can identify 67% and 87% of their own mistakes, respectively. We refer to this phenomenon as hallucination snowballing: an LM over-commits to early mistakes, leading to more mistakes that it otherwise would not make.
    
[^93]: 实现在真实场景中对齐的开放世界半监督广义关系发现 (arXiv:2305.13533v1 [cs.CL])

    Open-world Semi-supervised Generalized Relation Discovery Aligned in a Real-world Setting. (arXiv:2305.13533v1 [cs.CL])

    [http://arxiv.org/abs/2305.13533](http://arxiv.org/abs/2305.13533)

    本文提出了一种新的开放世界关系抽取方法，能够在已知类和新颖类中进行显式和隐式表示的关系分类，在真实场景数据的特征下进行了两个关键改进。

    

    开放世界关系抽取(OpenRE)最近引起了人们的关注。然而，现有的方法往往简化了问题，假设所有未标记的文本都属于新类，从而限制了这些方法的实用性。我们认为OpenRE设置应更符合现实世界数据的特征。具体而言，我们提出了两个关键改进:(a)未标记数据应包括已知和新颖的类，包括难以区分的负样本实例;(b)新颖的类集应该代表长尾关系类型。此外，我们观察到，流行的关系，如标题和位置，通常可以通过特定的模式隐含地推断，而长尾的关系倾向于在句子中明确表示。在这些见解的推动下，我们提出了一种名为KNoRD（已知和新颖关系发现）的新方法，有效地对已知类和新颖类中的显式和隐式表示的关系进行分类。

    Open-world Relation Extraction (OpenRE) has recently garnered significant attention. However, existing approaches tend to oversimplify the problem by assuming that all unlabeled texts belong to novel classes, thereby limiting the practicality of these methods. We argue that the OpenRE setting should be more aligned with the characteristics of real-world data. Specifically, we propose two key improvements: (a) unlabeled data should encompass known and novel classes, including hard-negative instances; and (b) the set of novel classes should represent long-tail relation types. Furthermore, we observe that popular relations such as titles and locations can often be implicitly inferred through specific patterns, while long-tail relations tend to be explicitly expressed in sentences. Motivated by these insights, we present a novel method called KNoRD (Known and Novel Relation Discovery), which effectively classifies explicitly and implicitly expressed relations from known and novel classes w
    
[^94]: 面向乌克兰语的基于语法和句法的语料库分析工具

    The Grammar and Syntax Based Corpus Analysis Tool For The Ukrainian Language. (arXiv:2305.13530v1 [cs.CL])

    [http://arxiv.org/abs/2305.13530](http://arxiv.org/abs/2305.13530)

    StyloMetrix是一种基于语法和句法的文本挖掘工具，可分析乌克兰语的语法、文体和句法模式，适用于文本分类任务。

    

    本文介绍了一种文本挖掘工具StyloMetrix，最初用于波兰语，后来扩展到英语和乌克兰语。它基于计算语言学家和文学研究人员手工制作的各种指标，分析语法、文体和句法模式。我们描述了StyloMetrix管道，并针对文本分类任务进行了一些实验。我们还描述了我们软件包的主要限制和指标的评估过程。

    This paper provides an overview of a text mining tool the StyloMetrix developed initially for the Polish language and further extended for English and recently for Ukrainian. The StyloMetrix is built upon various metrics crafted manually by computational linguists and researchers from literary studies to analyze grammatical, stylistic, and syntactic patterns. The idea of constructing the statistical evaluation of syntactic and grammar features is straightforward and familiar for the languages like English, Spanish, German, and others; it is yet to be developed for low-resource languages like Ukrainian. We describe the StyloMetrix pipeline and provide some experiments with this tool for the text classification task. We also describe our package's main limitations and the metrics' evaluation procedure.
    
[^95]: 无需转移数据的多语言短语标记方法

    Transfer-Free Data-Efficient Multilingual Slot Labeling. (arXiv:2305.13528v1 [cs.CL])

    [http://arxiv.org/abs/2305.13528](http://arxiv.org/abs/2305.13528)

    本论文提出了一种无需英文数据的多语言数据高效标记方法，结果显示其比跨语言转移基准显着提高（最多提高22%）。

    

    短语标记（SL）是任务导向型对话（ToD）系统的核心组件，而其中的短语和相应的值通常是特定于语言、任务和领域的。因此，将系统扩展到任何新的语言-领域-任务配置需要重新运行昂贵而资源密集型的数据标注流程。为了减轻固有的数据稀缺问题，当前多语言ToD研究假设特定任务和领域的足够英语注释数据始终可用，因此在标准的跨语言传输设置中运行。在这项工作中，我们摆脱这种常常不现实的假设。我们研究挑战性场景，即无法保证具有传输功能的英文注释数据，并专注于在目标语言中直接进行多语言数据高效的标记。我们提出了一种两阶段短语标记方法（称为TWOSL），将标准的多语言SL转化为无需转移数据的高效设置。在第一阶段，我们利用一个小型平行语料库来对齐不同语言之间的短语集，并利用这种对齐来通过一个无监督的多语言短语感应框架从高资源语言传递注释。在第二阶段，我们应用主动学习来通过包含来自目标语言的少量监督数据来迭代更新和改进多语言短语分类器。实验结果表明，在多个语言和领域中，TWOSL比最先进的跨语言转移基线显着提高了短语F1分数（最多提高22%）。

    Slot labeling (SL) is a core component of task-oriented dialogue (ToD) systems, where slots and corresponding values are usually language-, task- and domain-specific. Therefore, extending the system to any new language-domain-task configuration requires (re)running an expensive and resource-intensive data annotation process. To mitigate the inherent data scarcity issue, current research on multilingual ToD assumes that sufficient English-language annotated data are always available for particular tasks and domains, and thus operates in a standard cross-lingual transfer setup. In this work, we depart from this often unrealistic assumption. We examine challenging scenarios where such transfer-enabling English annotated data cannot be guaranteed, and focus on bootstrapping multilingual data-efficient slot labelers in transfer-free scenarios directly in the target languages without any English-ready data. We propose a two-stage slot labeling approach (termed TWOSL) which transforms standar
    
[^96]: 将挪威UD Treebank与实体和共指信息对齐

    Aligning the Norwegian UD Treebank with Entity and Coreference Information. (arXiv:2305.13527v1 [cs.CL])

    [http://arxiv.org/abs/2305.13527](http://arxiv.org/abs/2305.13527)

    本文将挪威两种书写形式语料库中的实体和共指标注数据合并到了通用依存语料库（UD treebanks）中，这是第一个加入实体和共指信息的挪威UD treebank，对未来语料库对齐和共指注释工作有帮助。

    

    本文介绍了一个基于挪威两种书写形式语料库──Bokm{å}l和Nynorsk的通用依存语料库（UD treebanks）中的实体和共指标注数据的合并集合。所合并的数据集包括Norwegian Named Entities（NorNE）和Norwegian Anaphora Resolution Corpus（NARC）两部分。虽然NorNE与旧版本的treebank对齐，但NARC则未能对齐，需要从原始注释到UD结构和CoNLL-U格式进行广泛的转换。我们在此演示了转换和对齐过程，并分析了发现的数据问题和错误，其中包括原始treebank中的数据分割重叠问题。这些程序和开发的系统可能有助于未来的语料库对齐和共指注释工作。合并的语料库包括第一个加入命名实体和共指信息的挪威UD treebank。

    This paper presents a merged collection of entity and coreference annotated data grounded in the Universal Dependencies (UD) treebanks for the two written forms of Norwegian: Bokm{\aa}l and Nynorsk. The aligned and converted corpora are the \textit{Norwegian Named Entities} (NorNE) and \textit{Norwegian Anaphora Resolution Corpus} (NARC). While NorNE is aligned with an older version of the treebank, NARC is misaligned and requires extensive transformation from the original annotations to the UD structure and CoNLL-U format. We here demonstrate the conversion and alignment processes, along with an analysis of discovered issues and errors in the data -- some of which include data split overlaps in the original treebank. These procedures and the developed system may prove helpful for future corpus alignment and coreference annotation endeavors. The merged corpora comprise the first Norwegian UD treebank enriched with named entities and coreference information.
    
[^97]: 生成式大型语言模型在医疗研究与健康保健中的应用研究

    A Study of Generative Large Language Model for Medical Research and Healthcare. (arXiv:2305.13523v1 [cs.CL])

    [http://arxiv.org/abs/2305.13523](http://arxiv.org/abs/2305.13523)

    本研究开发了一种临床生成式语言模型——GatorTronGPT，它改善了生物医学自然语言处理，使用它训练的合成NLP模型性能优于使用真实临床文本训练的NLP模型，医生也无法区分它和真实临床文本的差异。

    

    应用大型语言模型（LLMs）在医疗保健领域备受瞩目，但当前的假设都是基于通用型的LLMs，如ChatGPT。本研究开发了一种临床生成式LLM，GatorTronGPT，使用2770亿个混合临床与英语文本和一个200亿参数的GPT-3架构。GatorTronGPT改进了医学研究的生物医学自然语言处理。使用GatorTronGPT训练的合成NLP模型生成的文本性能优于使用真实临床文本训练的NLP模型。使用1（最差）到9（最好）的刻度进行的医生图灵测试表明，语言可读性（p = 0.22; GatorTronGPT为6.57，人类为6.93）和临床相关性（p = 0.91; GatorTronGPT为7.0，人类为6.97）没有显着差异，并且医生无法区分它们（p <0.001）。此研究提供了关于LLMs在医学研究和保健中的机遇和挑战的见解。

    There is enormous enthusiasm and concerns in using large language models (LLMs) in healthcare, yet current assumptions are all based on general-purpose LLMs such as ChatGPT. This study develops a clinical generative LLM, GatorTronGPT, using 277 billion words of mixed clinical and English text with a GPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical natural language processing for medical research. Synthetic NLP models trained using GatorTronGPT generated text outperform NLP models trained using real-world clinical text. Physicians Turing test using 1 (worst) to 9 (best) scale shows that there is no significant difference in linguistic readability (p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical relevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that physicians cannot differentiate them (p < 0.001). This study provides insights on the opportunities and challenges of LLMs for medical research and healthcare.
    
[^98]: CEO：基于语料库的开放域事件本体诱导

    CEO: Corpus-based Open-Domain Event Ontology Induction. (arXiv:2305.13521v1 [cs.CL])

    [http://arxiv.org/abs/2305.13521](http://arxiv.org/abs/2305.13521)

    本文介绍了一种名为CEO的事件本体诱导模型，它可以放松预定义事件本体所强加的限制，通过远程监督检测整个语料库中显著的事件，并诱导具有有意义名称的分层事件本体，实验结果表明，其诱导的模式具有更好的覆盖范围和更高的准确性。

    

    现有的面向事件的自然语言处理模型通常仅适用于预定义本体，这严重限制了它们的泛化能力。本文介绍了一种新颖的基于语料库的事件本体诱导模型CEO，以放松预定义事件本体所强加的限制。在没有直接监督的情况下，CEO利用可用摘要数据集的远程监督来检测整个语料库中显著的事件，并利用外部事件知识使距离短的事件具有相似的嵌入。对三个常用的事件数据集进行的实验表明，CEO诱导的模式具有比以前的方法更好的覆盖范围和更高的准确性。此外，CEO是第一个能在十一个开放域语料库上诱导具有有意义名称的分层事件本体的事件本体诱导模型，使诱导的模式更值得信赖并更易于进一步编辑。

    Existing event-centric NLP models often only apply to the pre-defined ontology, which significantly restricts their generalization capabilities. This paper presents CEO, a novel Corpus-based Event Ontology induction model to relax the restriction imposed by pre-defined event ontologies. Without direct supervision, CEO leverages distant supervision from available summary datasets to detect corpus-wise salient events and exploits external event knowledge to force events within a short distance to have close embeddings. Experiments on three popular event datasets show that the schema induced by CEO has better coverage and higher accuracy than previous methods. Moreover, CEO is the first event ontology induction model that can induce a hierarchical event ontology with meaningful names on eleven open-domain corpora, making the induced schema more trustworthy and easier to be further curated.
    
[^99]: 将语音技术扩展到1000+种语言

    Scaling Speech Technology to 1,000+ Languages. (arXiv:2305.13516v1 [cs.CL])

    [http://arxiv.org/abs/2305.13516](http://arxiv.org/abs/2305.13516)

    该论文介绍了Massively Multilingual Speech (MMS)项目，该项目通过新的数据集和自监督学习的方法将受支持的语言数量增加了10-40倍。实验表明，MMS的多语种语音识别模型可以在FLEURS基准测试的54种语言上将单词错误率降至一半以上。

    

    扩展语音技术的语言覆盖范围对于许多人改善获取信息的机会具有潜在优势。然而，目前的语音技术仅限于约100种语言，而这只是世界上共使用的7000多种语言的一小部分。Massively Multilingual Speech (MMS)项目通过新数据集和有效利用自监督学习的方法，将受支持的语言数量增加了10-40倍。我们构建了预训练的wav2vec 2.0模型，覆盖了1406种语言，一个用于1107种语言的单一的多语种自动语音识别模型，相同数量的语音合成模型，以及一个用于4017种语言的语言识别模型。实验表明，我们的多语种语音识别模型在FLEURS基准测试的54种语言上可以将Whisper的单词错误率降至一半以上，而我们的模型是基于所有语种进行训练的。

    Expanding the language coverage of speech technology has the potential to improve access to information for many more people. However, current speech technology is restricted to about one hundred languages which is a small fraction of the over 7,000 languages spoken around the world. The Massively Multilingual Speech (MMS) project increases the number of supported languages by 10-40x, depending on the task. The main ingredients are a new dataset based on readings of publicly available religious texts and effectively leveraging self-supervised learning. We built pre-trained wav2vec 2.0 models covering 1,406 languages, a single multilingual automatic speech recognition model for 1,107 languages, speech synthesis models for the same number of languages, as well as a language identification model for 4,017 languages. Experiments show that our multilingual speech recognition model more than halves the word error rate of Whisper on 54 languages of the FLEURS benchmark while being trained on 
    
[^100]: 小语言模型通过重写其输出来提高巨型模型的性能

    Small Language Models Improve Giants by Rewriting Their Outputs. (arXiv:2305.13514v1 [cs.CL])

    [http://arxiv.org/abs/2305.13514](http://arxiv.org/abs/2305.13514)

    本论文提出了一种方法，通过使用小语言模型重写大语言模型的输出，从而提高其性能。实验证明，该方法可以显着改善大语言模型的少样本学习能力和泛化性能。

    

    大型语言模型(LLMs)展示了令人印象深刻的少样本学习能力，但它们在挑战性任务上的表现通常不如微调模型。此外，它们的巨大体积和通过API的受限访问使得针对任务的微调不切实际。而且，LLMs对提示的不同方面（例如，演示的选择和顺序）很敏感，因此可能需要耗费时间进行提示工程。因此，我们提出了一种方法，可以在不依赖其权重的情况下纠正LLM的输出。首先，我们通过少样本提示LLM生成一个候选池。其次，我们使用一个更小的模型，LM-corrector（LMCor）来改进LLM生成的输出。LMCor被训练用于对候选者进行排名、组合和重写，以产生最终的目标输出。我们的实验表明，即使是一个小的LMCor模型（250M），也可以显着改善LLMs（62B）的少样本性能，适用于各种任务。此外，我们还证明LMCor表现出对提示变化的改进鲁棒性和更好的泛化性。总体而言，我们的方法展示了改善LLMs实际可用性的有希望的结果。

    Large language models (LLMs) have demonstrated impressive few-shot learning capabilities, but they often underperform compared to fine-tuned models on challenging tasks. Furthermore, their large size and restricted access only through APIs make task-specific fine-tuning impractical. Moreover, LLMs are sensitive to different aspects of prompts (e.g., the selection and order of demonstrations) and can thus require time-consuming prompt engineering. In this light, we propose a method to correct LLM outputs without relying on their weights. First, we generate a pool of candidates by few-shot prompting an LLM. Second, we refine the LLM-generated outputs using a smaller model, the LM-corrector (LMCor), which is trained to rank, combine and rewrite the candidates to produce the final target output. Our experiments demonstrate that even a small LMCor model (250M) substantially improves the few-shot performance of LLMs (62B) across diverse tasks. Moreover, we illustrate that the LMCor exhibits 
    
[^101]: 能ChatGPT检测出意图吗？评估用于口语理解的大型语言模型。

    Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding. (arXiv:2305.13512v1 [cs.CL])

    [http://arxiv.org/abs/2305.13512](http://arxiv.org/abs/2305.13512)

    本文评估了几个大型预训练语言模型在口语理解任务中的表现，发现最大模型可以在零-shot学习和上下文学习中达到与监督模型相近的意图分类准确度，但在槽填充方面表现不佳，且对ASR错误敏感。

    

    最近，大型预训练语言模型展示了强大的语言理解能力，特别体现在通过提示在下游任务中的零-shot和上下文学习能力。为了评估它们对口语理解（SLU）的影响，我们评估了几个不同大小的ChatGPT和OPT模型在多个基准测试中的表现。我们验证了最大模型特有的新兴能力，即在给定Oracle转录的各种语言上，其可以接近于监督模型的意图分类准确度。相比之下，适合单个GPU的较小模型的结果远远落后。我们注意到错误案例通常来自数据集的注释方案；ChatGPT的响应仍然是合理的。但是我们发现，该模型在槽填充方面表现不佳，而且对ASR错误非常敏感，因此表明了将这些文本模型应用于口语理解的严峻挑战。

    Recently, large pretrained language models have demonstrated strong language understanding capabilities. This is particularly reflected in their zero-shot and in-context learning abilities on downstream tasks through prompting. To assess their impact on spoken language understanding (SLU), we evaluate several such models like ChatGPT and OPT of different sizes on multiple benchmarks. We verify the emergent ability unique to the largest models as they can reach intent classification accuracy close to that of supervised models with zero or few shots on various languages given oracle transcripts. By contrast, the results for smaller models fitting a single GPU fall far behind. We note that the error cases often arise from the annotation scheme of the dataset; responses from ChatGPT are still reasonable. We show, however, that the model is worse at slot filling, and its performance is sensitive to ASR errors, suggesting serious challenges for the application of those textual models on SLU.
    
[^102]: 多模态自动事实核查：一份调查

    Multimodal Automated Fact-Checking: A Survey. (arXiv:2305.13507v1 [cs.CL])

    [http://arxiv.org/abs/2305.13507](http://arxiv.org/abs/2305.13507)

    本调查提出了一个多模态自动事实核查的框架，并包括了独特的子任务，重点关注了文本，图像，音频和视频这四种模态的现实应用。纪录了相关的基准模型，讨论了未来研究的局限性和前景。

    

    错误信息，即事实上不正确的信息，通常以多种形式传达，例如带有标题的图像。 它被人们视为更可信，比其仅限于文本的对应物扩散速度更快，范围更广。 尽管越来越多的研究涉及自动事实核查（AFC），但以往的调查主要集中在文本误导方面。 在本调查中，我们构建了一个包括多模态误导独特子任务在内的AFC框架。此外，我们在我们的框架上讨论了不同社区所发展的相关术语。 我们重点关注现实世界事实核查中存在的四种模态：文本，图像，音频和视频。 我们调查了基准和模型，并讨论了未来研究的局限性和有前途的方向。

    Misinformation, i.e. factually incorrect information, is often conveyed in multiple modalities, e.g. an image accompanied by a caption. It is perceived as more credible by humans, and spreads faster and wider than its text-only counterparts. While an increasing body of research investigates automated fact-checking (AFC), previous surveys mostly focus on textual misinformation. In this survey, we conceptualise a framework for AFC including subtasks unique to multimodal misinformation. Furthermore, we discuss related terminological developed in different communities in the context of our framework. We focus on four modalities prevalent in real-world fact-checking: text, image, audio, and video. We survey benchmarks and models, and discuss limitations and promising directions for future research.
    
[^103]: 用于代码生成的神经机器翻译

    Neural Machine Translation for Code Generation. (arXiv:2305.13504v1 [cs.CL])

    [http://arxiv.org/abs/2305.13504](http://arxiv.org/abs/2305.13504)

    该论文概述了神经机器翻译（NMT）在代码生成中的应用。该应用涵盖了各种各样的输入情况和约束条件。本文回顾了已探索的多种方法，并讨论了目前方法的局限性和未来的研究方向。

    

    针对自然语言处理开发的神经机器翻译（NMT）方法已被证明在自动翻译自然语言到另一种语言方面取得了巨大的成功。最近，这些NMT方法已被应用到程序代码的生成中。在NMT用于代码生成中，任务是生成满足输入中表达的约束条件的输出源代码。在文献中，已经探索了各种不同的输入情况，包括基于自然语言描述的代码生成，较低级别的表示，如二进制或汇编（神经反汇编），源代码的部分表示（代码完成和修复），以及另一种语言的源代码（代码翻译）。在本文中，我们对NMT用于代码生成的文献进行概述，按照输入和输出表示，模型架构，使用的优化技术，数据集和评估方法对已探索的方法进行分类。我们讨论NMT-based方法生成代码的现有限制和未来研究方向的前景。

    Neural machine translation (NMT) methods developed for natural language processing have been shown to be highly successful in automating translation from one natural language to another. Recently, these NMT methods have been adapted to the generation of program code. In NMT for code generation, the task is to generate output source code that satisfies constraints expressed in the input. In the literature, a variety of different input scenarios have been explored, including generating code based on natural language description, lower-level representations such as binary or assembly (neural decompilation), partial representations of source code (code completion and repair), and source code in another language (code translation). In this paper we survey the NMT for code generation literature, cataloging the variety of methods that have been explored according to input and output representations, model architectures, optimization techniques used, data sets, and evaluation methods. We discu
    
[^104]: 通过可适应任务特定前缀学习易于更新的通用文本表示

    Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefixes. (arXiv:2305.13499v1 [cs.CL])

    [http://arxiv.org/abs/2305.13499](http://arxiv.org/abs/2305.13499)

    本文提出了一种基于前缀的方法，用于学习带有源任务的固定文本表示。独立地学习每个源任务的任务特定前缀，并将它们组合成最终表示，以解决如何学习易于更新、适用广泛的通用文本表示的挑战。

    

    许多实际应用需要从相同的文本中进行多次预测。针对每个下游任务微调大型预训练的语言模型会在推断时带来计算负担，因为需要多次正向传递。为了摊销计算成本，冻结语言模型并基于固定文本表示为下游任务建立轻量级模型是常见的解决方案。因此，如何学习一种固定但通用的文本表示，以便在未知的下游任务中表现良好，成为一项挑战。过去的研究表明，通过以多任务的方式对预训练的语言模型进行微调，可以提高表示的通用性。在本文中，我们提出了一种基于前缀的方法，用于学习带有源任务的固定文本表示。我们独立地学习每个源任务的任务特定前缀，并将它们组合成最终表示。我们的实验结果表明，...

    Many real-world applications require making multiple predictions from the same text. Fine-tuning a large pre-trained language model for each downstream task causes computational burdens in the inference time due to several times of forward passes. To amortize the computational cost, freezing the language model and building lightweight models for downstream tasks based on fixed text representations are common solutions. Accordingly, how to learn fixed but general text representations that can generalize well to unseen downstream tasks becomes a challenge. Previous works have shown that the generalizability of representations can be improved by fine-tuning the pre-trained language model with some source tasks in a multi-tasking way. In this work, we propose a prefix-based method to learn the fixed text representations with source tasks. We learn a task-specific prefix for each source task independently and combine them to get the final representations. Our experimental results show that 
    
[^105]: Flover：一种用于高效自回归模型并行推断的时间融合框架

    Flover: A Temporal Fusion Framework for Efficient Autoregressive Model Parallel Inference. (arXiv:2305.13484v1 [cs.DC])

    [http://arxiv.org/abs/2305.13484](http://arxiv.org/abs/2305.13484)

    Flover是一种用于自回归模型并行推断的时间融合框架，解决了并行性不足和灵活性差的问题，可以实现更加高效的推断性能。

    

    在深度学习领域快速发展的背景下，模型推断性能成为一个关键因素，尤其是在模型变得更加复杂并被部署在多个应用场景中的情况下。自回归模型由于在众多生成任务中表现优异，因此备受关注。这些模型设计上采用了一种时间依赖结构，其中当前token的概率分布受到前面token的影响。然而，这种本质上的序列特性遵循马尔可夫链假设，缺乏时间并行性，因此存在独特的挑战。特别是在工业背景下，推断请求遵循泊松时间分布，需要不同的响应长度，这种并行性的缺失更加明显。现有的解决方案如动态批处理和并发模型实例，然而，这些粗粒度的方法存在严重的开销和缺乏灵活性，无法实现最优化。

    In the rapidly evolving field of deep learning, the performance of model inference has become a pivotal aspect as models become more complex and are deployed in diverse applications. Among these, autoregressive models stand out due to their state-of-the-art performance in numerous generative tasks. These models, by design, harness a temporal dependency structure, where the current token's probability distribution is conditioned on preceding tokens. This inherently sequential characteristic, however, adheres to the Markov Chain assumption and lacks temporal parallelism, which poses unique challenges. Particularly in industrial contexts where inference requests, following a Poisson time distribution, necessitate diverse response lengths, this absence of parallelism is more profound. Existing solutions, such as dynamic batching and concurrent model instances, nevertheless, come with severe overheads and a lack of flexibility, these coarse-grained methods fall short of achieving optimal la
    
[^106]: 相近语言的自动可读性评估

    Automatic Readability Assessment for Closely Related Languages. (arXiv:2305.13478v1 [cs.CL])

    [http://arxiv.org/abs/2305.13478](http://arxiv.org/abs/2305.13478)

    本研究探索了如何通过语言方面（如相互智能性或语言相关性）来提高低资源语言中的自动可读性评估，并使用三种菲律宾语言的短篇小说来训练模型，发现应用专业特征CrossNGO可以改善ARA。

    

    近年来，自动可读性评估（ARA）的主要研究重点已转向使用昂贵的基于深度学习的方法，其主要目标是提高模型的准确性。然而，在低资源语言中，传统的手工制作特征仍然广泛使用，因为缺乏现有的NLP工具来提取更深层次的语言表示。我们从技术组件上退一步，着重探讨如何通过诸如相互智能性或语言相关性的语言方面来提高低资源环境下的ARA。我们收集在菲律宾的三种语言（他加禄语，比科尔语和宿务语）中编写的短篇小说来训练可读性评估模型，并探索各种跨语言设置中的数据和特征之间的交互作用。 我们的结果表明，在具有高相互可理解性的语言中应用n-gram重叠的新型专业特征CrossNGO可以改善ARA。

    In recent years, the main focus of research on automatic readability assessment (ARA) has shifted towards using expensive deep learning-based methods with the primary goal of increasing models' accuracy. This, however, is rarely applicable for low-resource languages where traditional handcrafted features are still widely used due to the lack of existing NLP tools to extract deeper linguistic representations. In this work, we take a step back from the technical component and focus on how linguistic aspects such as mutual intelligibility or degree of language relatedness can improve ARA in a low-resource setting. We collect short stories written in three languages in the Philippines-Tagalog, Bikol, and Cebuano-to train readability assessment models and explore the interaction of data and features in various cross-lingual setups. Our results show that the inclusion of CrossNGO, a novel specialized feature exploiting n-gram overlap applied to languages with high mutual intelligibility, sig
    
[^107]: MAILEX: 邮件事件与参数抽取

    MAILEX: Email Event and Argument Extraction. (arXiv:2305.13469v1 [cs.CL])

    [http://arxiv.org/abs/2305.13469](http://arxiv.org/abs/2305.13469)

    本文提出了针对邮件领域的事件抽取数据集\dataset，比较了序列标记和生成式端到端抽取的方法，结果表明该任务存在非连续共享触发器跨度、非命名实体参数和邮件会话历史等难点，未来需要更多研究。

    

    本文提出了第一个数据集 \dataset，用于从邮件串中执行事件抽取。为此，我们首先提出了一个新的分类法，涵盖了邮件领域中的 10 种事件类型和 76 个参数。我们的最终数据集包括约 4K 封标记有约 9K 个事件实例的邮件。为了了解任务的挑战，我们进行了一系列实验，比较了两种常见的事件抽取方法，即序列标记和生成式端到端抽取（包括几率 GPT-3.5）。我们的结果表明，邮件事件抽取任务远未得到解决，因为存在诸多难点，例如提取非连续共享触发器跨度、提取非命名实体参数和建模邮件会话历史等。因此，我们的工作提出了未来在这个特定领域的事件抽取任务中需要进行更多研究的建议。

    In this work, we present the first dataset, \dataset, for performing event extraction from conversational email threads. To this end, we first proposed a new taxonomy covering 10 event types and 76 arguments in the email domain. Our final dataset includes $\sim$4K emails annotated with $\sim$9K event instances. To understand the task challenges, we conducted a series of experiments comparing two commonly-seen lines of approaches for event extraction, i.e., sequence labeling and generative end-to-end extraction (including few-shot GPT-3.5). Our results showed that the task of email event extraction is far from being addressed, due to challenges lying in, e.g., extracting non-continuous, shared trigger spans, extracting non-named entity arguments, and modeling the email conversational history. Our work thus suggests more investigations in this domain-specific event extraction task in the future.\footnote{The source code and dataset can be obtained from \url{https://github.com/salokr/Emai
    
[^108]: clembench：使用游戏来评估作为对话代理人的聊天优化语言模型

    clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents. (arXiv:2305.13455v1 [cs.CL])

    [http://arxiv.org/abs/2305.13455](http://arxiv.org/abs/2305.13455)

    本论文探讨了大型语言模型在接触具有挑战性的受限游戏式环境下，能否有意义地评估它们的能力。作为概念验证，研究了五种交互设置，表明当前的聊天优化LLMs在一定程度上能够遵循游戏玩法指令。这对于将LLMs开发为具有广泛适用性的对话代理人具有启示作用。

    

    最近的工作提出了一种针对“站立语言理解代理”的系统评估方法——代理在丰富的语言和非语言环境中运行，通过在精心构造的互动环境中进行测试来评估它们。其他最近的工作则认为，如果适当设置，大型语言模型（LLMs）可以被理解为这样的代理（的模拟器）。本文探讨了这种联系：是否可以通过让LLMs接触具有挑战性的受限游戏式环境来有意义地评估它们的能力？作为概念验证，本文研究了五种交互设置，表明当前的聊天优化LLMs在一定程度上能够遵循游戏玩法指令。这种能力和游戏玩法的质量（通过满足不同游戏目标的情况来衡量）都遵循着发展循环，新型模型表现更好。即使是相对简单的“井字游戏”示例游戏的指标也提供了模型在这些条件下的基本性能指示。这对于将LLMs开发为具有广泛适用性的对话代理人具有启示作用。

    Recent work has proposed a methodology for the systematic evaluation of "Situated Language Understanding Agents"-agents that operate in rich linguistic and non-linguistic contexts-through testing them in carefully constructed interactive settings. Other recent work has argued that Large Language Models (LLMs), if suitably set up, can be understood as (simulators of) such agents. A connection suggests itself, which this paper explores: Can LLMs be evaluated meaningfully by exposing them to constrained game-like settings that are built to challenge specific capabilities? As a proof of concept, this paper investigates five interaction settings, showing that current chat-optimised LLMs are, to an extent, capable to follow game-play instructions. Both this capability and the quality of the game play, measured by how well the objectives of the different games are met, follows the development cycle, with newer models performing better. The metrics even for the comparatively simple example gam
    
[^109]: 解读Transformer的注意力动态内存，可视化GPT的语义信息流

    Interpreting Transformer's Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT. (arXiv:2305.13417v1 [cs.CL])

    [http://arxiv.org/abs/2305.13417](http://arxiv.org/abs/2305.13417)

    本文提出了一种将Transformer模型的权重和隐藏状态投影到其词汇表中解释模型的方法，并分析了注意力机制内部信息流的模式。文章还介绍了一个可视化工具，将GPT的前向传递可视化为交互式流图，简化了大量数据为易于阅读的图表，展示了其语义信息流。

    

    最近，解释性方面的进展表明我们可以将基于transformer模型的语言模型的权重和隐藏状态投影到其词汇表中，这种转换使它们变得更容易理解，并且使我们能够将语义分配到仅作为数字向量的内容上。在本文中，我们解释了LM注意力头和内存值，这些向量是模型在处理给定输入时动态地创建和检索的。通过通过这种投影分析它们所代表的标记，我们确定了注意力机制内部信息流的模式。基于这些发现，我们创建了一个工具来将生成预训练Transformer（GPT）的前向传递可视化为交互式流图，其中结点代表神经元或隐藏状态，边代表它们之间的相互作用。我们的可视化将海量数据简化为易于阅读的图表，反映了模型为什么输出其结果的原因。我们通过确定最重要的特征并可视化其语义信息流来演示我们建模的效用。

    Recent advances in interpretability suggest we can project weights and hidden states of transformer-based language models (LMs) to their vocabulary, a transformation that makes them human interpretable and enables us to assign semantics to what was seen only as numerical vectors. In this paper, we interpret LM attention heads and memory values, the vectors the models dynamically create and recall while processing a given input. By analyzing the tokens they represent through this projection, we identify patterns in the information flow inside the attention mechanism. Based on these discoveries, we create a tool to visualize a forward pass of Generative Pre-trained Transformers (GPTs) as an interactive flow graph, with nodes representing neurons or hidden states and edges representing the interactions between them. Our visualization simplifies huge amounts of data into easy-to-read plots that reflect why models output their results. We demonstrate the utility of our modeling by identifyi
    
[^110]: 基于BERT和图注意力机制的机器翻译中的句法知识

    Syntactic Knowledge via Graph Attention with BERT in Machine Translation. (arXiv:2305.13413v1 [cs.CL])

    [http://arxiv.org/abs/2305.13413](http://arxiv.org/abs/2305.13413)

    该论文提出了一种在机器翻译中使用图注意力和BERT来表示句法依赖关系的方法，可以丰富源语言表示并引导目标语言生成，经实验证实该方法能够在不影响BLEU分数的情况下改善翻译质量。

    

    虽然Transformer模型通过自注意机制可以有效地获取上下文特征，但较深的句法知识仍然未被有效地建模。为解决这个问题，我们提出了一种在机器翻译场景中使用图注意力和BERT来表示句法依赖特征的句法知识（SGB）方法。该方法可以丰富源语言表示并引导目标语言生成。我们的实验使用了金标注句子和质量估计模型来获得关于句法知识对翻译质量改善的解释性。实验结果表明，所提出的SGB引擎可以在三个机器翻译任务中改善翻译质量，而不会牺牲BLEU分数。我们研究了哪些源句长度受益最大，以及哪些依赖关系被SGB引擎更好地识别。

    Although the Transformer model can effectively acquire context features via a self-attention mechanism, deeper syntactic knowledge is still not effectively modeled. To alleviate the above problem, we propose Syntactic knowledge via Graph attention with BERT (SGB) in Machine Translation (MT) scenarios. Graph Attention Network (GAT) and BERT jointly represent syntactic dependency feature as explicit knowledge of the source language to enrich source language representations and guide target language generation. Our experiments use gold syntax-annotation sentences and Quality Estimation (QE) model to obtain interpretability of translation quality improvement regarding syntactic knowledge without being limited to a BLEU score. Experiments show that the proposed SGB engines improve translation quality across the three MT tasks without sacrificing BLEU scores. We investigate what length of source sentences benefits the most and what dependencies are better identified by the SGB engines. We al
    
[^111]: 大语言模型的元素感知文摘：专家对齐评估和思路链技术

    Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method. (arXiv:2305.13412v1 [cs.CL])

    [http://arxiv.org/abs/2305.13412](http://arxiv.org/abs/2305.13412)

    通过新的元素感知测试集为自动文摘提供更细粒度的参考摘要，使用 LLMS 以零-shot方式生成摘要，提出 SumCoT 技术以改进连贯性和相关性，并在多个数据集上进行实验，为推荐场景中的用户意图理解提供了7％的准确率改善。

    

    自动摘要生成包含源文件关键思想的简洁摘要。CNN / DailyMail和BBC XSum作为新闻领域的最主流数据集，已被广泛用于性能基准测试。然而，这些数据集的参考摘要证明是嘈杂的，主要体现在事实幻觉和信息冗余方面。为了应对这一挑战，我们首先按照Lasswell（1948）提出的“Lasswell通讯模型”注释了新的专家编写的元素感知测试集，允许参考摘要客观全面地关注更细粒度的新闻元素。利用新的测试集，我们观察到LLMs惊人的零-shot文摘能力，解决了LLMs的零-shot文摘在先前工作中的人类偏好和自动评估指标之间不一致结果的问题。此外，我们提出了一个Summary Chain-of-Thought（SumCoT）技术，以逐步引导LLMs生成摘要，以更好地处理连贯性和相关性。在CNN / DailyMail和我们的新元素感知测试集上的实验结果表明，SumCoT在各个方面显著提高了LLM生成的摘要质量。作为主要应用，我们展示元素感知文摘可以在推荐场景中受益于用户意图理解，在实际电影摘要数据集上产生最高7％的准确率改善。

    Automatic summarization generates concise summaries that contain key ideas of source documents. As the most mainstream datasets for the news sub-domain, CNN/DailyMail and BBC XSum have been widely used for performance benchmarking. However, the reference summaries of those datasets turn out to be noisy, mainly in terms of factual hallucination and information redundancy. To address this challenge, we first annotate new expert-writing Element-aware test sets following the "Lasswell Communication Model" proposed by Lasswell (1948), allowing reference summaries to focus on more fine-grained news elements objectively and comprehensively. Utilizing the new test sets, we observe the surprising zero-shot summary ability of LLMs, which addresses the issue of the inconsistent results between human preference and automatic evaluation metrics of LLMs' zero-shot summaries in prior work. Further, we propose a Summary Chain-of-Thought (SumCoT) technique to elicit LLMs to generate summaries step by s
    
[^112]: 基于 Conformer 的流式语音识别模块化领域自适应

    Modular Domain Adaptation for Conformer-Based Streaming ASR. (arXiv:2305.13408v1 [eess.AS])

    [http://arxiv.org/abs/2305.13408](http://arxiv.org/abs/2305.13408)

    论文提出了一种名为模块化领域适应的框架，使单个Conformer模型处理多领域数据，同时保持参数领域特异性，通过在Conformer编码器中添加每个领域的适配器和逐领域的前馈网络，可以在不重新训练多领域模型的情况下在其他领域（如语音搜索和听写）中达到类似的性能。

    

    不同领域的语音数据具有不同的声学和语言特征。通常在所有领域的混合数据上训练单个多域模型，如Conformer transducer语音识别器。但是，更改一个领域的数据或添加新领域会要求重新训练多领域模型。为此，我们提出了一种称为模块化领域适应（MDA）的框架，它可以使单个模型处理多领域数据，同时保持所有参数特定于领域，即每个参数仅由一个领域的数据训练。在仅使用视频字幕数据训练的流式Conformer transducer上，实验结果显示，通过在Conformer encoder中添加每个领域的适配器和逐领域的前馈网络，基于MDA的模型可以实现与多领域模型类似的性能在其他领域，如语音搜索和听写中。

    Speech data from different domains has distinct acoustic and linguistic characteristics. It is common to train a single multidomain model such as a Conformer transducer for speech recognition on a mixture of data from all domains. However, changing data in one domain or adding a new domain would require the multidomain model to be retrained. To this end, we propose a framework called modular domain adaptation (MDA) that enables a single model to process multidomain data while keeping all parameters domain-specific, i.e., each parameter is only trained by data from one domain. On a streaming Conformer transducer trained only on video caption data, experimental results show that an MDA-based model can reach similar performance as the multidomain model on other domains such as voice search and dictation by adding per-domain adapters and per-domain feed-forward networks in the Conformer encoder.
    
[^113]: DADA: 基于语言规则的方言适应性动态聚合

    DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules. (arXiv:2305.13406v1 [cs.CL])

    [http://arxiv.org/abs/2305.13406](http://arxiv.org/abs/2305.13406)

    DADA是一种适用于多个方言，基于语言规则的动态聚合适配器，可为SAE训练的模型赋予多方言鲁棒性，同时针对特定方言变体进行适应，提供了一种可解释的方言适应性框架。

    

    现有的大型语言模型主要集中于标准美式英语（SAE），在应用于其他英语方言时表现往往较差。而现有的缓解方法针对单个目标方言的偏差，但假设了可以访问高精度的方言识别系统。方言之间的界限固有弹性，使得将语言划分为离散预定义的范畴更加困难。在本文中，我们提出了DADA（基于语言规则的方言适应性动态聚合），一种通过组合处理特定语言特征的适配器，为SAE训练的模型赋予多方言的鲁棒性的模块化方法。DADA的组合架构允许有针对性地适应特定方言变体，同时适应各种方言。我们展示了DADA对于单任务和指令微调语言模型都是有效的，提供了一种可扩展和可解释的框架来适应各种方言。

    Existing large language models (LLMs) that mainly focus on Standard American English (SAE) often lead to significantly worse performance when being applied to other English dialects. While existing mitigations tackle discrepancies for individual target dialects, they assume access to high-accuracy dialect identification systems. The boundaries between dialects are inherently flexible, making it difficult to categorize language into discrete predefined categories. In this paper, we propose DADA (Dialect Adaptation via Dynamic Aggregation), a modular approach to imbue SAE-trained models with multi-dialectal robustness by composing adapters which handle specific linguistic features. The compositional architecture of DADA allows for both targeted adaptation to specific dialect variants and simultaneous adaptation to various dialects. We show that DADA is effective for both single task and instruction finetuned language models, offering an extensible and interpretable framework for adapting
    
[^114]: GATology在语言学中的应用: 它了解哪些句法依存关系？

    GATology for Linguistics: What Syntactic Dependencies It Knows. (arXiv:2305.13403v1 [cs.CL])

    [http://arxiv.org/abs/2305.13403](http://arxiv.org/abs/2305.13403)

    本文探究了使用GAT和BERT等预训练模型在机器翻译场景中建模句法知识的方法。实验表明，通过适当的层数和关注头数量，可以实现更好的性能。此外，相对于MT-B，GAT在下游MT任务中的语法建模方面略微更好。

    

    图注意力网络（GAT）是一种图形神经网络，是模拟和表示明确的句法知识的策略之一，可以与预训练模型（如BERT）一起在下游任务中使用。目前，从模型结构的角度来研究GAT如何学习句法知识仍然缺乏研究。作为模型明确句法知识的策略之一，GAT和BERT从未被应用和讨论过的机器翻译（MT）场景。我们设计了一个依赖关系预测任务，研究了GAT如何作为关注头和层数数量的函数来学习三种语言的句法知识。我们还使用配对t检验和F1分数来澄清GAT与MT-B微调之间的句法依存关系预测差异。实现表明，通过适当增加两个GAT层的关注头的数量可以实现更好的性能。在超过两层的情况下，无论关注头的数量如何，性能均没有显着提高。此外，我们的实验表明，在下游MT任务中，GAT在语法建模方面的表现略好于MT-B。

    Graph Attention Network (GAT) is a graph neural network which is one of the strategies for modeling and representing explicit syntactic knowledge and can work with pre-trained models, such as BERT, in downstream tasks. Currently, there is still a lack of investigation into how GAT learns syntactic knowledge from the perspective of model structure. As one of the strategies for modeling explicit syntactic knowledge, GAT and BERT have never been applied and discussed in Machine Translation (MT) scenarios. We design a dependency relation prediction task to study how GAT learns syntactic knowledge of three languages as a function of the number of attention heads and layers. We also use a paired t-test and F1-score to clarify the differences in syntactic dependency prediction between GAT and BERT fine-tuned by the MT task (MT-B). The experiments show that better performance can be achieved by appropriately increasing the number of attention heads with two GAT layers. With more than two layer
    
[^115]: 一项概念语言相似性的研究: 比较与评估

    A study of conceptual language similarity: comparison and evaluation. (arXiv:2305.13401v1 [cs.CL])

    [http://arxiv.org/abs/2305.13401](http://arxiv.org/abs/2305.13401)

    本文研究了一种新的定义语言相似度的方法，该方法基于语言如何表示基本概念，而非常规的词汇或类型学特征。我们在二元分类任务上对其进行了评估。

    

    自然语言处理(NLP)中的一个有趣的研究方向旨在融入语言学类型学, 以桥接语言多样性并协助低资源语言的研究。虽然大多数作品是基于词汇或类型学特征(如词序和动词变化)构建语言相似度度量, 但最近的工作引入了一种新方法, 基于语言如何表示基本概念来定义语言相似度, 这是现有相似度度量的补充。本文详细研究了概念相似性, 并在二元分类任务上进行了广泛评估。

    An interesting line of research in natural language processing (NLP) aims to incorporate linguistic typology to bridge linguistic diversity and assist the research of low-resource languages. While most works construct linguistic similarity measures based on lexical or typological features, such as word order and verbal inflection, recent work has introduced a novel approach to defining language similarity based on how they represent basic concepts, which is complementary to existing similarity measures. In this work, we study the conceptual similarity in detail and evaluate it extensively on a binary classification task.
    
[^116]: BioDEX：用于真实世界药物监测的大规模生物医学不良药物事件提取

    BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance. (arXiv:2305.13395v1 [cs.CL])

    [http://arxiv.org/abs/2305.13395](http://arxiv.org/abs/2305.13395)

    该论文引入了BioDEX，它是一个大型资源，用于生物医学不良药物事件提取，可在真实世界中改进药物安全监测。

    

    及时准确地从生物医学文献中提取不良药物事件(Adverse Drug Events, ADE)对公众安全至关重要，但涉及缓慢和昂贵的人工劳动。我们通过自然语言处理(NLP)来改进药物安全监测(药物监管学, PV)。我们引入了BioDEX，这是一个大型资源，用于生物医学不良药物事件提取，基于美国药物安全报告的历史输出。BioDEX包括65k个摘要和19k个全文生物医学论文，以及由医学专家创建的256k个相关的文档级安全报告。这些报告的核心特征包括患者的体重、年龄和生物性别，患者服用的一组药物、药物剂量、经历的反应以及反应是否危及生命。在这项工作中，我们考虑了根据起始论文预测报告的核心信息的任务。我们估计人类的表现为72.0% F1，而我们最好的m.....

    Timely and accurate extraction of Adverse Drug Events (ADE) from biomedical literature is paramount for public safety, but involves slow and costly manual labor. We set out to improve drug safety monitoring (pharmacovigilance, PV) through the use of Natural Language Processing (NLP). We introduce BioDEX, a large-scale resource for Biomedical adverse Drug Event Extraction, rooted in the historical output of drug safety reporting in the U.S. BioDEX consists of 65k abstracts and 19k full-text biomedical papers with 256k associated document-level safety reports created by medical experts. The core features of these reports include the reported weight, age, and biological sex of a patient, a set of drugs taken by the patient, the drug dosages, the reactions experienced, and whether the reaction was life threatening. In this work, we consider the task of predicting the core information of the report given its originating paper. We estimate human performance to be 72.0% F1, whereas our best m
    
[^117]: 听觉单词识别和整合的神经动态

    The neural dynamics of auditory word recognition and integration. (arXiv:2305.13388v1 [cs.CL])

    [http://arxiv.org/abs/2305.13388](http://arxiv.org/abs/2305.13388)

    该论文研究了听觉单词识别和整合的神经动态，提出了一个计算模型解释了这一过程，发现对于需要超过大约100ms的输入才能被识别的单词，神经响应会被放大。

    

    听者通过将有关即将出现的内容的期望与增量感知证据相结合，来快速识别和整合嘈杂的日常语音中的单词。我们提出了一个单词识别的计算模型，该模型在贝叶斯决策理论中形式化了这一知觉过程。我们将该模型拟合到作为被试者被动听取虚构故事时记录的头皮脑电信号中，揭示了在线听觉单词识别过程和单词识别和整合的神经相关性的动力学。该模型揭示了单词的不同神经处理，具体取决于它们是否可以快速识别。虽然所有单词都触发概率整合的神经响应，即文本背景中对单词惊异度预测的电压调制，但对于需要超过大约100ms的输入才能被识别的单词，这些调制会被放大。我们观察到这些神经响应的潜伏期不会根据单词长度而有所不同。

    Listeners recognize and integrate words in rapid and noisy everyday speech by combining expectations about upcoming content with incremental sensory evidence. We present a computational model of word recognition which formalizes this perceptual process in Bayesian decision theory. We fit this model to explain scalp EEG signals recorded as subjects passively listened to a fictional story, revealing both the dynamics of the online auditory word recognition process and the neural correlates of the recognition and integration of words.  The model reveals distinct neural processing of words depending on whether or not they can be quickly recognized. While all words trigger a neural response characteristic of probabilistic integration -- voltage modulations predicted by a word's surprisal in context -- these modulations are amplified for words which require more than roughly 100 ms of input to be recognized. We observe no difference in the latency of these neural responses according to words
    
[^118]: LLMs是否可以促进预先训练的语言模型的解释？

    Can LLMs facilitate interpretation of pre-trained language models?. (arXiv:2305.13386v1 [cs.CL])

    [http://arxiv.org/abs/2305.13386](http://arxiv.org/abs/2305.13386)

    该论文提出使用大型语言模型ChatGPT作为注释器以便对预训练语言模型进行细粒度解释分析，发现ChatGPT产生了更准确和语义更丰富的注释。同时，基于GPT注释的解释分析方法可以帮助进一步探索和实验。

    

    揭示预先训练的语言模型中编码的知识的工作依赖于带注释的语料库或人在环路方法。然而，这些方法在可伸缩性和解释范围方面存在限制。我们提议使用一个大型语言模型ChatGPT作为注释器，以便对预训练语言模型进行细粒度解释分析。通过在上下文表示上应用分层聚类，我们发现预先训练的语言模型中的潜在概念，然后使用GPT注释对这些概念进行注释。我们的研究发现，与人工注释的概念相比，ChatGPT产生了更准确和语义更丰富的注释。此外，我们展示了基于GPT注释的解释分析方法，其中我们展示了两种：探针框架和神经元解释。为了促进在这个领域的进一步探索和实验，我们提供了一个重要的概念网数据集。

    Work done to uncover the knowledge encoded within pre-trained language models, rely on annotated corpora or human-in-the-loop methods. However, these approaches are limited in terms of scalability and the scope of interpretation. We propose using a large language model, ChatGPT, as an annotator to enable fine-grained interpretation analysis of pre-trained language models. We discover latent concepts within pre-trained language models by applying hierarchical clustering over contextualized representations and then annotate these concepts using GPT annotations. Our findings demonstrate that ChatGPT produces accurate and semantically richer annotations compared to human-annotated concepts. Additionally, we showcase how GPT-based annotations empower interpretation analysis methodologies of which we demonstrate two: probing framework and neuron interpretation. To facilitate further exploration and experimentation in this field, we have made available a substantial ConceptNet dataset compris
    
[^119]: 论模拟主动学习的限制

    On the Limitations of Simulating Active Learning. (arXiv:2305.13342v1 [cs.LG])

    [http://arxiv.org/abs/2305.13342](http://arxiv.org/abs/2305.13342)

    研究提出了主动学习模拟的局限性，并警告基于模拟实验结果得出强烈结论可能导致评估AL算法的误导。

    

    主动学习（AL）是一种人与模型交互循环的范式，用于迭代地选择信息性未标记数据以供人类注释，旨在改善随机抽样的表现。然而，在流程中实时进行带人类注释的AL实验是一项繁琐而昂贵的过程，因此在学术研究中不切实际。解决此问题的简单方法是通过将已标记的公开可用数据集作为未标记数据的池来模拟AL。在这篇观点论文中，我们首先调查最近的文献并突出显示AL循环中所有不同步骤中的挑战。我们进一步揭示了实验设置中被忽视的注意事项，这些注意事项可能会显着影响AL研究的质量。我们接着探讨了模拟设置如何支配经验发现，认为这可能是“为什么有时主动学习算法无法胜过随机抽样”的权衡之一。我们认为仅基于模拟实验结果得出强烈结论可以导致评估AL算法的误导，因此提出谨慎。

    Active learning (AL) is a human-and-model-in-the-loop paradigm that iteratively selects informative unlabeled data for human annotation, aiming to improve over random sampling. However, performing AL experiments with human annotations on-the-fly is a laborious and expensive process, thus unrealistic for academic research. An easy fix to this impediment is to simulate AL, by treating an already labeled and publicly available dataset as the pool of unlabeled data. In this position paper, we first survey recent literature and highlight the challenges across all different steps within the AL loop. We further unveil neglected caveats in the experimental setup that can significantly affect the quality of AL research. We continue with an exploration of how the simulation setting can govern empirical findings, arguing that it might be one of the answers behind the ever posed question ``why do active learning algorithms sometimes fail to outperform random sampling?''. We argue that evaluating A
    
[^120]: 使用大型语言模型进行基因集概括

    Gene Set Summarization using Large Language Models. (arXiv:2305.13338v1 [q-bio.GN])

    [http://arxiv.org/abs/2305.13338](http://arxiv.org/abs/2305.13338)

    该论文介绍了一种使用大型语言模型来对基因集进行函数概括的方法，名为SPINDOCTOR，可以提供比传统方法更好的性能和可解释性。

    

    分子生物学家经常解释从高通量实验和计算分析中获得的基因列表。这通常是通过统计富集分析来完成的，该分析测量与基因或其属性相关的生物功能术语的过度或欠表示程度，基于知识库（KB）（例如Gene Ontology（GO））中的编译断言。解释基因列表也可以被构建为一个文本概括任务，利用大型语言模型（LLMs）进行，可能直接利用科学文本并避免依赖KB。我们开发了SPINDOCTOR（稳定的提示插值的受控术语的自然语言描述的结构化报告模板），一种使用GPT模型执行基因集函数概括的方法，作为标准富集分析的补充。该方法可以使用不同的基因功能信息来源：（1）从鉴定的本体KB注释中获得的结构化文本，（2）从文本挖掘中推断的本体术语，以及（3）直接从非结构化文本中获得的术语。我们在一个1813个基因集的基准数据集上评估了SPINDOCTOR，并展示了使用GPT模型显著改善了现有方法的性能，同时也提高了可解释性，因为它能够生成人类可读的基因功能摘要。

    Molecular biologists frequently interpret gene lists derived from high-throughput experiments and computational analysis. This is typically done as a statistical enrichment analysis that measures the over- or under-representation of biological function terms associated with genes or their properties, based on curated assertions from a knowledge base (KB) such as the Gene Ontology (GO). Interpreting gene lists can also be framed as a textual summarization task, enabling the use of Large Language Models (LLMs), potentially utilizing scientific texts directly and avoiding reliance on a KB.  We developed SPINDOCTOR (Structured Prompt Interpolation of Natural Language Descriptions of Controlled Terms for Ontology Reporting), a method that uses GPT models to perform gene set function summarization as a complement to standard enrichment analysis. This method can use different sources of gene functional information: (1) structured text derived from curated ontological KB annotations, (2) ontol
    
[^121]: 基于E-Branchformer和多任务学习的失语症语音识别和检测新基准

    A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning. (arXiv:2305.13331v1 [eess.AS])

    [http://arxiv.org/abs/2305.13331](http://arxiv.org/abs/2305.13331)

    本文通过使用最先进的语音识别技术和AphsiaBank数据集，提出了失语症语音识别和检测的新基准。我们的系统实现了最先进的说话人级别检测准确率(97.3%)，并相对于中度失语症患者的WER降低了11%。我们的方法还可应用于其他语音数据库，促进失语症语音处理的进步。

    

    失语症是一种影响数以百万计患者讲话能力的语言障碍。本文利用AphsiaBank数据集采用最先进的语音识别技术提出了一种失语症语音识别和检测任务的新基准。具体而言，我们引入了两种基于CTC/Attention架构的多任务学习方法，同时执行两个任务。我们的系统实现了最先进的说话人级别检测准确率(97.3%)，并且相对WER降低了11%的中度失语症患者。此外，我们通过将其应用于另一个有语言障碍的语音数据库DementiaBank Pitt corpus，展示了我们方法的通用性。我们将公开发布我们的配方和预训练模型，以便于学术论文的复现。我们的标准化数据预处理流程和开源配方可使研究者直接比较结果，推动失语症语音处理的进步。

    Aphasia is a language disorder that affects the speaking ability of millions of patients. This paper presents a new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset. Specifically, we introduce two multi-task learning methods based on the CTC/Attention architecture to perform both tasks simultaneously. Our system achieves state-of-the-art speaker-level detection accuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia patients. In addition, we demonstrate the generalizability of our approach by applying it to another disordered speech database, the DementiaBank Pitt corpus. We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.
    
[^122]: 基于跨语言伪标注的无监督自动语音识别

    Unsupervised ASR via Cross-Lingual Pseudo-Labeling. (arXiv:2305.13330v1 [eess.AS])

    [http://arxiv.org/abs/2305.13330](http://arxiv.org/abs/2305.13330)

    本研究提出了一种基于跨语言伪标注的无监督ASR方法，能够使用其他语言中的标注数据来引导新语言的无监督AM。在Common Voice上取得了良好的效果，可以实现18% WER。而且在不同语言的数据集上都优于基线模型。

    

    最近的研究表明，可以仅使用非配对的音频和文本来训练无监督自动语音识别（ASR）系统。现有的无监督ASR方法假定不能使用任何标注数据进行训练。本文认为，即使没有给定语言的任何标注音频，也始终可以使用其他语言中的标注数据。本文展示了如何使用其他语言的字符级声学模型（AM），来引导新语言的无监督AM。 这里，“无监督”意味着没有可用于目标语言的标注音频。本文的方法基于两个关键因素：（i）使用其他语言AM生成“目标”语言的伪标签（PLs）；（ii）使用“目标语言模型”限制这些PLs。我们的方法在Common Voice上非常有效：例如，将英语AM传递到斯瓦希里语可以实现18％的WER。 它还在不同语言的多个数据集上优于基于字符的基线模型。

    Recent work has shown that it is possible to train an $\textit{unsupervised}$ automatic speech recognition (ASR) system using only unpaired audio and text. Existing unsupervised ASR methods assume that no labeled data can be used for training. We argue that even if one does not have any labeled audio for a given language, there is $\textit{always}$ labeled data available for other languages. We show that it is possible to use character-level acoustic models (AMs) from other languages to bootstrap an $\textit{unsupervised}$ AM in a new language. Here, "unsupervised" means no labeled audio is available for the $\textit{target}$ language. Our approach is based on two key ingredients: (i) generating pseudo-labels (PLs) of the $\textit{target}$ language using some $\textit{other}$ language AM and (ii) constraining these PLs with a $\textit{target language model}$. Our approach is effective on Common Voice: e.g. transfer of English AM to Swahili achieves 18% WER. It also outperforms characte
    
[^123]: 一份用于提取病毒和宿主相互作用的新型数据集

    A Novel Dataset Towards Extracting Virus-Host Interactions. (arXiv:2305.13317v1 [cs.CL])

    [http://arxiv.org/abs/2305.13317](http://arxiv.org/abs/2305.13317)

    这份论文介绍了一个新的数据集，用于自动识别有关病毒与宿主相互作用的实体，提出该数据集可作为未来模型训练的黄金标准。该工作为自动从科学出版物中提取与主机-病原体检测方法相关的信息迈出了第一步，并自动预测了与人类健康相关的重要概念“病毒跨界传播风险”。

    

    我们描述了一个用于自动识别与病毒与宿主相关的命名分类和其他实体的新型数据集。我们进一步描述了使用预先训练的模型在该新型数据集上进行命名实体识别（NER）任务的一些初步结果。我们建议我们手动注释的摘要数据集现在为未来的NER模型培训提供了黄金标准。自动从科学出版物中提取主机-病原体检测方法，并进一步解释了我们的工作如何迈出了自动预测与人类健康相关的“病毒跨界传播风险”这一重要概念的第一步。

    We describe a novel dataset for the automated recognition of named taxonomic and other entities relevant to the association of viruses with their hosts. We further describe some initial results using pre-trained models on the named-entity recognition (NER) task on this novel dataset. We propose that our dataset of manually annotated abstracts now offers a Gold Standard Corpus for training future NER models in the automated extraction of host-pathogen detection methods from scientific publications, and further explain how our work makes first steps towards predicting the important human health-related concept of viral spillover risk automatically from the scientific literature.
    
[^124]: 评估ChatGPT对多语言和基于表情符号的仇恨言论检测的表现

    Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate Speech Detection. (arXiv:2305.13276v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13276](http://arxiv.org/abs/2305.13276)

    本研究评估了跨11种语言级别上ChatGPT模型在检测仇恨言论中的优势和劣势，揭示了模型复杂的故障，并指出生成模型在某些类型的仇恨言论检测方面的不足，为未来开发更强大的仇恨言论检测系统提供了见解。

    

    仇恨言论是影响许多在线平台的严重问题。迄今为止，已进行了多项研究以开发强大的仇恨言论检测系统。近来，像ChatGPT这样的大型语言模型已经展示了在执行多个任务，包括仇恨言论检测方面的巨大潜力。然而，了解这些模型的局限性以建立强大的仇恨言论检测系统是至关重要的。为了弥合这一差距，我们的研究旨在评估ChatGPT模型在跨11种语言的粒度级别上检测仇恨言论的优势和劣势。我们的评估采用一系列功能测试，揭示了模型的各种复杂故障，而聚合指标如宏F1或准确性则无法展示。此外，我们还调查了包括使用表情符号在内的复杂情感对ChatGPT模型表现的影响。我们的分析突出了生成模型在检测某些类型的仇恨言论方面的缺点，并为未来开发更强大的仇恨言论检测系统提供了见解。

    Hate speech is a severe issue that affects many online platforms. So far, several studies have been performed to develop robust hate speech detection systems. Large language models like ChatGPT have recently shown a great promise in performing several tasks, including hate speech detection. However, it is crucial to comprehend the limitations of these models to build robust hate speech detection systems. To bridge this gap, our study aims to evaluate the strengths and weaknesses of the ChatGPT model in detecting hate speech at a granular level across 11 languages. Our evaluation employs a series of functionality tests that reveals various intricate failures of the model which the aggregate metrics like macro F1 or accuracy are not able to unfold. In addition, we investigate the influence of complex emotions, such as the use of emojis in hate speech, on the performance of the ChatGPT model. Our analysis highlights the shortcomings of the generative models in detecting certain types of h
    
[^125]: SPARSEFIT：少样本刺激的稀疏微调，联合生成预测和自然语言解释

    SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations. (arXiv:2305.13235v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13235](http://arxiv.org/abs/2305.13235)

    这篇论文介绍了SparseFit，一种少样本刺激的稀疏微调策略，用于联合生成预测和自然语言解释。该方法可以在只有少量自然语言解释可用时生成高质量的自然语言解释。

    

    解释神经模型的决策对于确保这些模型在部署时的可信度很关键。最近，使用自然语言解释来证明模型的预测越来越受到关注。然而，这种方法通常需要大量的人工编写的自然语言解释作为真实答案的数据集，这些数据集既昂贵又可能对于某些应用程序来说不可行。为了使模型在只有少量自然语言解释可用时生成高质量的自然语言解释，最近提出了基于刺激学习的预训练语言模型微调方法。然而，预训练语言模型通常具有数十亿个参数，使得微调十分昂贵。我们提出了SparseFit，一种稀疏的少样本微调策略，利用离散刺激来联合生成预测和自然语言解释。我们在T5模型和四个数据集上使用SparseFit，并将其与现有的参数高效微调技术进行比较。我们进行了自动和人工评估。

    Explaining the decisions of neural models is crucial for ensuring their trustworthiness at deployment time. Using Natural Language Explanations (NLEs) to justify a model's predictions has recently gained increasing interest. However, this approach usually demands large datasets of human-written NLEs for the ground-truth answers, which are expensive and potentially infeasible for some applications. For models to generate high-quality NLEs when only a few NLEs are available, the fine-tuning of Pre-trained Language Models (PLMs) in conjunction with prompt-based learning recently emerged. However, PLMs typically have billions of parameters, making fine-tuning expensive. We propose SparseFit, a sparse few-shot fine-tuning strategy that leverages discrete prompts to jointly generate predictions and NLEs. We experiment with SparseFit on the T5 model and four datasets and compare it against state-of-the-art parameter-efficient fine-tuning techniques. We perform automatic and human evaluations 
    
[^126]: GPT-SW3：一种面向北欧语言的自回归语言模型

    GPT-SW3: An Autoregressive Language Model for the Nordic Languages. (arXiv:2305.12987v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12987](http://arxiv.org/abs/2305.12987)

    GPT-SW3是面向北欧语言的第一个本地化大型生成语言模型，本文介绍了其开发过程，可作为其他研究人员开发面向较小语言的大型生成模型的指南和参考。

    

    本文详细介绍了开发面向北欧语言的第一个本地化大型生成语言模型GPT-SW3的过程。我们涵盖了开发过程的所有部分，从数据收集和处理，训练配置和指令微调，到评估和发布策略的考虑。我们希望本文能够作为指南和参考，帮助其他研究人员开发面向较小语言的大型生成模型。

    This paper details the process of developing the first native large generative language model for the Nordic languages, GPT-SW3. We cover all parts of the development process, from data collection and processing, training configuration and instruction finetuning, to evaluation and considerations for release strategies. We hope that this paper can serve as a guide and reference for other researchers that undertake the development of large generative models for smaller languages.
    
[^127]: 超越语言：句子表示综述

    Beyond Words: A Comprehensive Survey of Sentence Representations. (arXiv:2305.12641v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12641](http://arxiv.org/abs/2305.12641)

    本文综述了不同的句子表示学习方法，包括传统和基于深度学习技术的方法。突出该领域的主要贡献和挑战，并强调句子表示学习的进展和未来的研究方向。

    

    句子表示已经成为自然语言处理应用中的关键组成部分，如检索、问答和文本分类。它们捕捉句子的语义和含义，使计算机能够理解和推理人类语言。近年来，在学习句子表示方面已经取得了重大进展，包括无监督、监督和迁移学习方法。本文综述了不同的句子表示学习方法，包括传统和基于深度学习技术的方法。我们系统地整理了句子表示学习方面的文献，突出了该领域的主要贡献和挑战。总的来说，我们的综述强调了句子表示学习的进展，这一领域在自然语言处理中的重要性以及仍然存在的挑战。最后，我们提出了未来的研究方向。

    Sentence representations have become a critical component in natural language processing applications, such as retrieval, question answering, and text classification. They capture the semantics and meaning of a sentence, enabling machines to understand and reason over human language. In recent years, significant progress has been made in developing methods for learning sentence representations, including unsupervised, supervised, and transfer learning approaches. In this paper, we provide an overview of the different methods for sentence representation learning, including both traditional and deep learning-based techniques. We provide a systematic organization of the literature on sentence representation learning, highlighting the key contributions and challenges in this area. Overall, our review highlights the progress made in sentence representation learning, the importance of this area in natural language processing, and the challenges that remain. We conclude with directions for fu
    
[^128]: 医学文本的多语言简化

    Multilingual Simplification of Medical Texts. (arXiv:2305.12532v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12532](http://arxiv.org/abs/2305.12532)

    本研究介绍了MultiCochrane，这是医学领域中第一个句子对齐的多语言文本简化数据集，通过多语言简化直接将复杂文本简化为多种语言的简化文本。

    

    自动化文本简化旨在产生复杂文本的简化版本。在医学领域，这项任务尤为重要，因为最新的医学发现通常通过复杂和技术性的文章进行传播。这为寻求最新医学发现信息的普通人造成了障碍，进而阻碍了健康素养的提高。大部分医学文本简化的现有工作都集中在单语言环境中，导致这些证据只能用一种语言（通常是英语）提供。本研究通过多语言简化直接将复杂文本简化为多种语言的简化文本来解决这个问题。我们介绍了MultiCochrane，这是医学领域中第一个四种语言（英语、西班牙语、法语和波斯语）的句子对齐多语言文本简化数据集。我们通过广泛的人工评估和分析，在这些语言之间评估了模型的微调和零样本模型。

    Automated text simplification aims to produce simple versions of complex texts. This task is especially useful in the medical domain, where the latest medical findings are typically communicated via complex and technical articles. This creates barriers for laypeople seeking access to up-to-date medical findings, consequently impeding progress on health literacy. Most existing work on medical text simplification has focused on monolingual settings, with the result that such evidence would be available only in just one language (most often, English). This work addresses this limitation via multilingual simplification, i.e., directly simplifying complex texts into simplified texts in multiple languages. We introduce MultiCochrane, the first sentence-aligned multilingual text simplification dataset for the medical domain in four languages: English, Spanish, French, and Farsi. We evaluate fine-tuned and zero-shot models across these languages, with extensive human assessments and analyses. 
    
[^129]: 在高考基准测试上评估大型语言模型的性能

    Evaluating the Performance of Large Language Models on GAOKAO Benchmark. (arXiv:2305.12474v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12474](http://arxiv.org/abs/2305.12474)

    本文介绍了一个基于高考考试问题的基准测试GAOKAO-Benchmark，用于评估大型语言模型在客观和主观问题方面的表现。通过对ChatGPT模型的评估，研究发现其在客观问题方面表现出色，同时也揭示了其不足之处和改进的方向。

    

    大型语言模型已经在各种自然语言处理任务中展示了出色的性能；然而它们在更具挑战性和领域特定的任务中的功效仍然不太清楚。本文介绍了GAOKAO-Benchmark（GAOKAO-Bench），这是一个直观的基准测试，它使用中国高考考试的题目作为测试样本，评估大型语言模型。为了尽可能地使评估结果与人类一致，我们设计了一种基于零-shot提示的方法，通过将问题分为主观和客观类型来分析模型的准确性和评分率。我们评估了ChatGPT模型在GAOKAO-Benchmark性能上的表现。我们的研究发现，ChatGPT模型在解决客观问题方面表现出色，同时也揭示了其不足之处和改进的方向。为了进一步审查模型的响应，我们加入了人类评估。总之，本研究为创建一个稳健的评估GAOKAO基准测试提供了贡献。

    Large language models have demonstrated remarkable performance across various natural language processing tasks; however, their efficacy in more challenging and domain-specific tasks remains less explored. This paper introduces the GAOKAO-Benchmark (GAOKAO-Bench), an intuitive benchmark that employs questions from the Chinese Gaokao examination as test samples for evaluating large language models.In order to align the evaluation results with humans as much as possible, we designed a method based on zero-shot prompts to analyze the accuracy and scoring rate of the model by dividing the questions into subjective and objective types. We evaluated the ChatGPT model on GAOKAO-Benchmark performance.Our findings reveal that the ChatGPT model excels in tackling objective questions, while also shedding light on its shortcomings and areas for improvement. To further scrutinize the model's responses, we incorporate human evaluations.In conclusion, this research contributes a robust evaluation ben
    
[^130]: 宣传性文件双向翻译中的措辞处理

    Hedges in Bidirectional Translations of Publicity-Oriented Documents. (arXiv:2305.12146v1 [cs.CL])

    [http://arxiv.org/abs/2305.12146](http://arxiv.org/abs/2305.12146)

    本文研究了宣传性文件翻译中的措辞处理问题，发现政治文本中的措辞在英文中出现更频繁，且翻译方向影响措辞使用频率和翻译策略。同时还观察到了措辞在历时方面的增加。

    

    措辞是跨专业领域广泛研究的词汇，但政治文本中措辞的翻译研究极为有限。本文研究了措辞在目标文本中的词频变化是否具有历时性，翻译中措辞通过年份变化的程度如何归因于源文本，并采用了何种翻译策略来处理它们。为了实现这一研究目的，我们收集了来自中国和联合国的两种公务政治文本及其翻译，形成了三个子语料库。结果表明，措辞在英文政治文本中（无论是原始英文还是翻译英文）似乎更频繁出现。此外，翻译方向似乎在影响措辞使用的频率和翻译策略方面起着重要作用。我们还观察到，措辞使用频率在我们的子语料库中出现了显著的历时性增加。

    Hedges are widely studied across registers and disciplines, yet research on the translation of hedges in political texts is extremely limited. This contrastive study is dedicated to investigating whether there is a diachronic change in the frequencies of hedging devices in the target texts, to what extent the changing frequencies of translated hedges through years are attributed to the source texts, and what translation strategies are adopted to deal with them. For the purposes of this research, two types of official political texts and their translations from China and the United Nations were collected to form three sub-corpora. Results show that hedges tend to appear more frequently in English political texts, be it original English or translated English. In addition, directionality seems to play an important role in influencing both the frequencies and translation strategies regarding the use of hedges. A noticeable diachronic increase of hedging devices is also observed in our corp
    
[^131]: 如何引导LLMs进行文本到SQL的学习: 从零样本到单领域到跨领域研究

    How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings. (arXiv:2305.11853v1 [cs.CL])

    [http://arxiv.org/abs/2305.11853](http://arxiv.org/abs/2305.11853)

    本文针对引导LLMs进行文本到SQL的任务中提示文本构建问题展开了综合探究，从而为未来的研究提供了见解。

    

    具有上下文学习的大型语言模型(LLMs)在文本到SQL任务中展现了显著能力。之前的研究通过各种演示-检索策略和中间推理步骤来促使LLMs性能的提升。然而，这些工作在构建文本到SQL输入的提示文本(如数据库和演示示例)时常采用不同的策略。这导致提示文本的构建和其主要贡献的可比性不足。此外，选择有效的提示文本建设已成为未来研究中的持久问题。为了解决这个限制，我们全面调查了不同设置下提示文本结构的影响，并为未来的工作提供了见解。

    Large language models (LLMs) with in-context learning have demonstrated remarkable capability in the text-to-SQL task. Previous research has prompted LLMs with various demonstration-retrieval strategies and intermediate reasoning steps to enhance the performance of LLMs. However, those works often employ varied strategies when constructing the prompt text for text-to-SQL inputs, such as databases and demonstration examples. This leads to a lack of comparability in both the prompt constructions and their primary contributions. Furthermore, selecting an effective prompt construction has emerged as a persistent problem for future research. To address this limitation, we comprehensively investigate the impact of prompt constructions across various settings and provide insights for future work.
    
[^132]: 通过多语言一致性评估任务理解：ChatGPT案例研究

    Evaluating task understanding through multilingual consistency: A ChatGPT case study. (arXiv:2305.11662v1 [cs.CL])

    [http://arxiv.org/abs/2305.11662](http://arxiv.org/abs/2305.11662)

    本文提出了一种新的评估大型语言模型理解能力的范例，通过评估模型自身生成的不同意义之间的一致性，探讨了多语言自我一致性作为模型理解的检验方法，同时证明了ChatGPT在多语言一致性方面的优秀性能。

    

    随着大型语言模型（LLM）功能的惊人提升，创建未来可持续的评估集以评估它们的理解变得越来越具有挑战性。本文提出了一种新的评估LLM的范例，该范例利用了正确的世界理解应该在相同含义的不同（弗雷格）意义上保持一致的思想。因此，我们不是通过正确性来衡量理解，而是通过评估模型自身生成的多个意义之间的一致性来衡量。我们通过实例化一个测试展示了我们的方法，其中不同的意义是不同的语言，因此将多语言自我一致性作为模型理解的检验并同时解决多语言的重要主题。我们以最新版本的ChatGPT为我们的研究对象，在三种不同语言中评估两个不同任务的多语言一致性。我们证明了ChatGPT在多语言一致性方面的优秀性能。

    At the staggering pace with which the capabilities of large language models (LLMs) are increasing, creating future-proof evaluation sets to assess their understanding becomes more and more challenging. In this paper, we propose a novel paradigm for evaluating LLMs which leverages the idea that correct world understanding should be consistent across different (Fregean) senses of the same meaning. Accordingly, we measure understanding not in terms of correctness but by evaluating consistency across multiple senses that are generated by the model itself. We showcase our approach by instantiating a test where the different senses are different languages, hence using multilingual self-consistency as a litmus test for the model's understanding and simultaneously addressing the important topic of multilingualism. Taking one of the latest versions of ChatGPT as our object of study, we evaluate multilingual consistency for two different tasks across three different languages. We show that its m
    
[^133]: 基于上下文学习的命名实体识别

    Learning In-context Learning for Named Entity Recognition. (arXiv:2305.11038v1 [cs.CL])

    [http://arxiv.org/abs/2305.11038](http://arxiv.org/abs/2305.11038)

    本文提出了一种在 PLMs 中注入上下文 NER 能力的方法，只需少量示意实例即可动态识别新类型的实体，在几个基准数据集上达到了最先进的性能。

    

    现实世界中的命名实体识别受到实体类型的多样性、新实体类型的出现和高质量标注的缺乏等问题的影响。本文提出了一种基于上下文学习的命名实体识别方法，能够将上下文NER能力有效地注入到PLMs中，并且只使用少量示意实例就能动态识别新类型的实体。具体而言，我们将PLMs建模为一个元函数 $\mathcal{ \lambda_ {\text{instruction, demonstrations, text}}. M}$，并通过将新的指示和示例应用于PLMs来隐含地构建新的实体提取器，即 $\mathcal{ (\lambda . M) }$(instruction, demonstrations) $\to$ $\mathcal{F}$，其中 $\mathcal{F}$ 将成为一个新的实体提取器，即 $\mathcal{F}$: text $\to$ entities。为了将上述上下文NER能力注入PLMs，我们提出了一种元函数预训练算法，该算法通过比较（指示、示例）-identity和（掩盖后的指示、示例）-identity来预训练PLMs。实验结果表明，我们的方法在几个基准数据集上达到了最先进的性能，并且能够使用少量示意实例有效地识别新类型的实体。

    Named entity recognition in real-world applications suffers from the diversity of entity types, the emergence of new entity types, and the lack of high-quality annotations. To address the above problems, this paper proposes an in-context learning-based NER approach, which can effectively inject in-context NER ability into PLMs and recognize entities of novel types on-the-fly using only a few demonstrative instances. Specifically, we model PLMs as a meta-function $\mathcal{ \lambda_ {\text{instruction, demonstrations, text}}. M}$, and a new entity extractor can be implicitly constructed by applying new instruction and demonstrations to PLMs, i.e., $\mathcal{ (\lambda . M) }$(instruction, demonstrations) $\to$ $\mathcal{F}$ where $\mathcal{F}$ will be a new entity extractor, i.e., $\mathcal{F}$: text $\to$ entities. To inject the above in-context NER ability into PLMs, we propose a meta-function pre-training algorithm, which pre-trains PLMs by comparing the (instruction, demonstration)-i
    
[^134]: 语言模型遇见世界模型：实体经验增强语言模型

    Language Models Meet World Models: Embodied Experiences Enhance Language Models. (arXiv:2305.10626v1 [cs.CL])

    [http://arxiv.org/abs/2305.10626](http://arxiv.org/abs/2305.10626)

    本文提出一种新的增强语言模型的方法——将其与世界模型相结合，通过有目的的规划和随机探索获得丰富的实体经验进行微调, 以提高其在物理环境下的推理和行为能力，并在语言基准上保持或提高性能。

    

    虽然大型语言模型 (LMs) 在许多任务上表现出了非凡的能力，但它们常常在处理物理环境下的简单推理和规划问题时遇到困难，例如理解物体永恒或规划家庭活动。这种限制源于 LM 仅受书面语言训练，缺少必要的实体知识和技能。本文提出了一种新的增强 LM 的方法，即将其与世界模型相结合进行微调，以获得多样化的实体知识，同时保持其一般语言能力。本方法在世界模型中部署一个融入实体经验的代理，特别是一个模拟物理世界的仿真器(VirtualHome)，通过有目的的规划和随机探索获得多样化的实体经验。然后，利用这些经验微调 LM ，以教授在物理世界中的各种推理和行为能力，例如规划和完成目标、物体永恒和跟踪等。此外，我们相信我们的方法可以轻松扩展以利用其他模拟器，包括机器人或自动驾驶汽车。我们证明了我们的方法显着提高了 LM 在一系列物理推理任务中的性能，同时保留并经常提高了它们在语言基准上的表现。

    While large language models (LMs) have shown remarkable capabilities across numerous tasks, they often struggle with simple reasoning and planning in physical environments, such as understanding object permanence or planning household activities. The limitation arises from the fact that LMs are trained only on written text and miss essential embodied knowledge and skills. In this paper, we propose a new paradigm of enhancing LMs by finetuning them with world models, to gain diverse embodied knowledge while retaining their general language capabilities. Our approach deploys an embodied agent in a world model, particularly a simulator of the physical world (VirtualHome), and acquires a diverse set of embodied experiences through both goal-oriented planning and random exploration. These experiences are then used to finetune LMs to teach diverse abilities of reasoning and acting in the physical world, e.g., planning and completing goals, object permanence and tracking, etc. Moreover, it is
    
[^135]: 一种更好的掩码语言模型评分方法

    A Better Way to Do Masked Language Model Scoring. (arXiv:2305.10588v1 [cs.CL])

    [http://arxiv.org/abs/2305.10588](http://arxiv.org/abs/2305.10588)

    本文提出了一种更好的掩码语言模型评分方法，即PLL-word-l2r，用于估计句子的伪对数似然得分，相对于原PLL方法和屏蔽所有单词标记的PLL评分方法，改进的度量方法更好地针对字汇外单词得分问题进行了解决。

    

    估计自回归语言模型下给定句子的对数似然很简单：可以直接应用链式法则并对每个连续标记的对数似然值求和。但对于掩码语言模型，没有直接的方法来估计一个句子的对数似然。为了解决这个问题，Salazar等人（2020）提出了估计句子伪对数似然（PLL）分数的方法，该方法通过依次屏蔽每个句子标记，使用其余的句子作为上下文检索其得分，并总结结果值。本文针对原PLL方法中字汇外单词产生的得分夸大的问题提出了一种改进的度量方法，其中我们不仅屏蔽目标标记，而且还屏蔽目标标记右侧所有的标记。我们展示了我们改进的度量方法（PLL-word-l2r）优于原始PLL度量方法和一个屏蔽所有单词标记的PLL合成方式。特别地，它更好地符合理论。

    Estimating the log-likelihood of a given sentence under an autoregressive language model is straightforward: one can simply apply the chain rule and sum the log-likelihood values for each successive token. However, for masked language models, there is no direct way to estimate the log-likelihood of a sentence. To address this issue, Salazar et al. (2020) propose to estimate sentence pseudo-log-likelihood (PLL) scores, computed by successively masking each sentence token, retrieving its score using the rest of the sentence as context, and summing the resulting values. Here, we demonstrate that the original PLL method yields inflated scores for out-of-vocabulary words and propose an adapted metric, in which we mask not only the target token, but also all within-word tokens to the right of the target. We show that our adapted metric (PLL-word-l2r) outperforms both the original PLL metric and a PLL metric in which all within-word tokens are masked. In particular, it better satisfies theore
    
[^136]: 大型视觉-语言模型中的物体幻觉评估

    Evaluating Object Hallucination in Large Vision-Language Models. (arXiv:2305.10355v1 [cs.CV])

    [http://arxiv.org/abs/2305.10355](http://arxiv.org/abs/2305.10355)

    本研究是对大型视觉-语言模型中的物体幻觉问题进行的第一项系统研究，通过研究发现视觉指令可能影响幻觉，提出新的评估指标成功解决了现有评估方法的不足。

    

    发掘大型语言模型(LLM)因为其出色的语言能力近来已经开始研究大型视觉-语言模型(LVLM)，并将强大的LLM集成于LVLM中，以提高LVLM在复杂的多模态任务中的表现。虽然LVLM取得了很大进步，但是本研究发现LVLM存在长度幻觉问题，即它们倾向于生成与目标图像不一致的物体描述。为了调查这个问题，本研究开展了第一项系统研究，评估了LVLM中的物体幻觉。我们对几个代表性的LVLM进行了评估实验，并表明它们大多数都存在严重的物体幻觉问题。我们进一步探讨了视觉指令可能会影响幻觉，并发现在视觉指令中经常出现或与图像中的物体共现的物体，更容易被LVLM产生幻觉。此外，我们发现现有的评估方法可能会受到输入指令的影响，不能足以识别物体幻觉。为了解决这个问题，我们提出了一种新的评估指标，可以有效地评估物体幻觉问题。实验结果表明，我们提出的指标不仅可以有效地识别物体幻觉问题，还可以提供有关幻觉问题出现位置和如何缓解它的见解。

    Inspired by the superior language abilities of large language models (LLM), large vision-language models (LVLM) have been recently explored by integrating powerful LLMs for improving the performance on complex multimodal tasks. Despite the promising progress on LVLMs, we find that LVLMs suffer from the hallucination problem, i.e. they tend to generate objects that are inconsistent with the target images in the descriptions. To investigate it, this work presents the first systematic study on object hallucination of LVLMs. We conduct the evaluation experiments on several representative LVLMs, and show that they mostly suffer from severe object hallucination issue. We further discuss that the visual instructions may influence the hallucination, and find that: objects that frequently occur in the visual instructions or co-occur with the image objects, are obviously prone to be hallucinated by LVLMs. Besides, we find that existing evaluation methods might be affected by the input instructio
    
[^137]: 连锁符号提示激发了大型语言模型中的规划能力

    Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models. (arXiv:2305.10276v1 [cs.CL])

    [http://arxiv.org/abs/2305.10276](http://arxiv.org/abs/2305.10276)

    本文提出了自然语言规划（NLP）的基准，旨在研究LLMs在需要理解并在文本中相应进行操作的复杂规划任务中的表现。同时提出了一种新方法CoS，使用简化的符号空间表示法来表示复杂的环境。

    

    本文旨在研究LLMs在需要理解通过自然语言模拟的虚拟空间环境并在文本中相应进行操作的复杂规划任务中的表现。我们提出了一个名为自然语言规划（NLP）的基准，它由一组新颖的任务组成：Brick World、基于NLVR的操作和自然语言导航。我们发现当前流行的LLMs（如ChatGPT）仍然缺乏复杂规划的能力。这引出了一个问题——LLMs是否对自然语言中描述的环境有良好的理解，或者其他替代方法（如符号表示）是否更加简单，因此更容易被LLMs理解？为此，我们提出了一种名为CoS（Chain-of-Symbol Prompting）的新方法，在链式中间思考步骤中使用简化的符号空间表示法来表示复杂的环境。CoS易于使用，不需要对LLMs进行额外的培训。

    In this paper, we take the initiative to investigate the performance of LLMs on complex planning tasks that require LLMs to understand a virtual spatial environment simulated via natural language and act correspondingly in text. We propose a benchmark named Natural Language Planning (NLP) composed of a set of novel tasks: Brick World, NLVR-based Manipulations, and Natural Language Navigation. We found that current popular LLMs such as ChatGPT still lack abilities in complex planning. This arises a question -- do the LLMs have a good understanding of the environments described in natural language, or maybe other alternatives such as symbolic representations are neater and hence better to be understood by LLMs? To this end, we propose a novel method called CoS (Chain-of-Symbol Prompting) that represents the complex environments with condensed symbolic spatial representations during the chained intermediate thinking steps. CoS is easy to use and does not need additional training on LLMs. 
    
[^138]: LeXFiles和LegalLAMA：促进英语跨国法律语言模型的开发

    LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development. (arXiv:2305.07507v1 [cs.CL])

    [http://arxiv.org/abs/2305.07507](http://arxiv.org/abs/2305.07507)

    本文对面向法律的预训练语言模型进行了详细分析，发布了一个跨国英语法律文集和一个法律知识探针基准，发现探针性能与上游性能强相关，下游性能主要由模型的大小和先前的法律知识驱动。

    

    本文对面向法律的预训练语言模型（PLMs）的性能进行了详细分析。我们考察了它们的原始目标、获取的知识和法律语言理解能力之间的相互作用，将其定义为上游、探针和下游性能。我们不仅考虑了模型的大小，还将预训练语料库作为研究中的重要维度。为此，我们发布了一个跨国英语法律文集（LeXFiles）和一个法律知识探针基准（LegalLAMA），以促进法律导向PLMs的训练和详细分析。我们发布了两个在LeXFiles上训练的新的法律PLMs，并在LegalLAMA和LexGLUE上进行了评估。我们发现，在相关法律主题中，探针性能与上游性能强相关。另一方面，下游性能主要由模型的大小和先前的法律知识驱动，可以通过上游和探针性能来估计。

    In this work, we conduct a detailed analysis on the performance of legal-oriented pre-trained language models (PLMs). We examine the interplay between their original objective, acquired knowledge, and legal language understanding capacities which we define as the upstream, probing, and downstream performance, respectively. We consider not only the models' size but also the pre-training corpora used as important dimensions in our study. To this end, we release a multinational English legal corpus (LeXFiles) and a legal knowledge probing benchmark (LegalLAMA) to facilitate training and detailed analysis of legal-oriented PLMs. We release two new legal PLMs trained on LeXFiles and evaluate them alongside others on LegalLAMA and LexGLUE. We find that probing performance strongly correlates with upstream performance in related legal topics. On the other hand, downstream performance is mainly driven by the model's size and prior legal knowledge which can be estimated by upstream and probing 
    
[^139]: 当多数人是错误的：利用标注者不一致性进行主观任务

    When the Majority is Wrong: Leveraging Annotator Disagreement for Subjective Tasks. (arXiv:2305.06626v1 [cs.CL])

    [http://arxiv.org/abs/2305.06626](http://arxiv.org/abs/2305.06626)

    本文通过预测单个标注者的打分，并结合文本目标群体的预测，模拟了目标群体成员的意见，通过使用他们的人口统计学数据和在线意见预测标注者的打分，在仇恨言论检测等主观任务中提高了模型性能。

    

    在自然语言处理中，虽然通常使用标注者的多数投票来确定标签，但在仇恨言论检测等主观任务中，标注者之间存在不一致性可能反映出群体观点的差异，而不是噪声。因此，仇恨言论检测的一个关键问题是一个语句是否冒犯了它所针对的人群，而这可能只占标注者池的一小部分。本文构建了一个模型，预测可能具有冒犯性文本上每个标注者的打分，并结合文本的预测目标群体来模拟目标群体成员的意见。我们展示了一系列的评估指标，包括提高了22％在预测每个标注者的打分上的性能，提高了33％在预测标注者之间方差上的性能，这提供了下游用来衡量模型不确定性的方法。我们发现可以使用标注者的人口统计信息和其在线意见来预测标注者的打分。

    Though majority vote among annotators is typically used for ground truth labels in natural language processing, annotator disagreement in tasks such as hate speech detection may reflect differences among group opinions, not noise. Thus, a crucial problem in hate speech detection is whether a statement is offensive to the demographic group that it targets, which may constitute a small fraction of the annotator pool. We construct a model that predicts individual annotator ratings on potentially offensive text and combines this information with the predicted target group of the text to model the opinions of target group members. We show gains across a range of metrics, including raising performance over the baseline by 22% at predicting individual annotators' ratings and 33% at predicting variance among annotators, which provides a method of measuring model uncertainty downstream. We find that annotators' ratings can be predicted using their demographic information and opinions on online 
    
[^140]: 让自然成为自然语言处理的一部分

    Putting Natural in Natural Language Processing. (arXiv:2305.04572v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04572](http://arxiv.org/abs/2305.04572)

    自然语言处理领域过于重视书面语言，应该将口语作为主要交流方式纳入考虑，真正的自然语言处理可以超越文本，与其他语言科学更好地整合，实现更高效、更像人类的系统。

    

    人类语言首先是口语，其次才是书写语言。然而，文本是语言的一种非常方便和有效的表示方式，现代文明已将其普及。因此，NLP领域主要关注处理书面语言，很少关注口语。与此同时，口语处理则主要集中于独立的语音处理社区，在将语音转录为文本方面一直极为占优势。然而，深度学习的最新进展导致了语音处理和主流NLP方法之间的有利趋同。有人认为，现在是将这两个领域统一起来，认真对待口语作为人类主要交流方式的时候了。真正的自然语言处理可以带来与其他语言科学更好的整合，可以实现更高效、更像人类的系统，从而可以超越文本模式进行沟通。

    Human language is firstly spoken and only secondarily written. Text, however, is a very convenient and efficient representation of language, and modern civilization has made it ubiquitous. Thus the field of NLP has overwhelmingly focused on processing written rather than spoken language. Work on spoken language, on the other hand, has been siloed off within the largely separate speech processing community which has been inordinately preoccupied with transcribing speech into text. Recent advances in deep learning have led to a fortuitous convergence in methods between speech processing and mainstream NLP. Arguably, the time is ripe for a unification of these two fields, and for starting to take spoken language seriously as the primary mode of human communication. Truly natural language processing could lead to better integration with the rest of language science and could lead to systems which are more data-efficient and more human-like, and which can communicate beyond the textual moda
    
[^141]: Vera：一个用于通用常识语句可信度评估的模型

    Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements. (arXiv:2305.03695v1 [cs.CL])

    [http://arxiv.org/abs/2305.03695](http://arxiv.org/abs/2305.03695)

    本文提出了Vera模型，它是一个通用模型，可以基于常识知识估计陈述性语句的可信度。在解决验证格式的常识问题时，Vera明显优于现有的模型，并展现了对未见任务的泛化能力和良好的标定输出。

    

    尽管当今的语言模型在许多方面表现出色，但它们仍然容易出现荒谬和意外的常识失败。本文提出了一种回顾性验证方法，反思LM输出的正确性，并引入了Vera，一个通用模型，它基于常识知识估计陈述性语句的可信度。通过使用19个QA数据集和两个大规模知识库创建的约700万条常识语句以及三个训练目标的组合进行训练，Vera是一个多功能模型，可以有效地区分各种常识领域中的正确和错误语句。当应用于解决验证格式的常识问题时，Vera明显优于现有的可重用于常识验证的模型，并且它进一步展示了对未见任务的泛化能力并提供了良好的标定输出。我们发现Vera在过滤LM生成的常识知识方面表现突出，可以潜在地增强它们的可信度和实际应用。

    Despite the much discussed capabilities of today's language models, they are still prone to silly and unexpected commonsense failures. We consider a retrospective verification approach that reflects on the correctness of LM outputs, and introduce Vera, a general-purpose model that estimates the plausibility of declarative statements based on commonsense knowledge. Trained on ~7M commonsense statements created from 19 QA datasets and two large-scale knowledge bases, and with a combination of three training objectives, Vera is a versatile model that effectively separates correct from incorrect statements across diverse commonsense domains. When applied to solving commonsense problems in the verification format, Vera substantially outperforms existing models that can be repurposed for commonsense verification, and it further exhibits generalization capabilities to unseen tasks and provides well-calibrated outputs. We find that Vera excels at filtering LM-generated commonsense knowledge an
    
[^142]: 大语言模型在信息技术任务中自动生成YAML代码

    Automated Code generation for Information Technology Tasks in YAML through Large Language Models. (arXiv:2305.02783v1 [cs.SE])

    [http://arxiv.org/abs/2305.02783](http://arxiv.org/abs/2305.02783)

    这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。

    

    由于大语言模型在代码生成方面的不断提升，在通用编程语言方面的受益最大，而针对IT自动化等领域特定语言的研究较少。本研究聚焦于Ansible-YAML的生成，提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，旨在提高IT自动化生产力。研究采用基于Transformer的模型，并通过新的包含Ansible-YAML的数据集进行扩展训练。同时，还开发了两个用于捕捉此领域特征的YAML和Ansible性能指标。结果表明，Ansible Wisdom可以精确地从自然语言提示中生成Ansible脚本，并且其性能可与现有技术的状态相媲美或更好。

    The recent improvement in code generation capabilities due to the use of large language models has mainly benefited general purpose programming languages. Domain specific languages, such as the ones used for IT Automation, have received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible-YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible-YAML code generation tool, aimed at improving IT automation productivity. Ansible Wisdom is a transformer-based model, extended by training with a new dataset containing Ansible-YAML. We also develop two novel performance metrics for YAML and Ansible to capture the specific characteristics of this domain. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code 
    
[^143]: 超越多链思维：基于元推理的问题解答方法

    Answering Questions by Meta-Reasoning over Multiple Chains of Thought. (arXiv:2304.13007v1 [cs.CL])

    [http://arxiv.org/abs/2304.13007](http://arxiv.org/abs/2304.13007)

    本论文提出了基于元推理的Multi-Chain Reasoning (MCR)方法，该方法检查多个推理链，混合它们之间的信息并选择最相关的事实，从而超越多链思维，解决多跳QA问题。 实验结果表明MCR胜过多个强基线，解释质量高。

    

    现代多跳问题解答（QA）系统通常将问题分解为一系列思考步骤（CoT），然后才得出最终答案。通常来说，多个链条被抽样并通过最终答案的投票机制进行聚合，但中间步骤本身被丢弃。虽然这种方法提高了性能，但它们并不考虑链之间的中间步骤之间的关系，并且不提供预测答案的统一解释。我们引入了基于元推理的 Multi-Chain Reasoning (MCR) 方法，该方法利用大型语言模型来超越多个思考链，而不是聚合回答。MCR检查不同的推理链，混合它们之间的信息并选择在生成解释和预测答案时最相关的事实。MCR在7个多跳QA数据集上胜过强基线。此外，我们的分析表明MCR的解释具有高质量。

    Modern systems for multi-hop question answering (QA) typically break questions into a sequence of reasoning steps, termed chain-of-thought (CoT), before arriving at a final answer. Often, multiple chains are sampled and aggregated through a voting mechanism over the final answers, but the intermediate steps themselves are discarded. While such approaches improve performance, they do not consider the relations between intermediate steps across chains and do not provide a unified explanation for the predicted answer. We introduce Multi-Chain Reasoning (MCR), an approach which prompts large language models to meta-reason over multiple chains of thought, rather than aggregating their answers. MCR examines different reasoning chains, mixes information between them and selects the most relevant facts in generating an explanation and predicting the answer. MCR outperforms strong baselines on 7 multi-hop QA datasets. Moreover, our analysis reveals that MCR explanations exhibit high quality, en
    
[^144]: 基于ChatGPT-4的ACR放射肿瘤内科（TXIT）考试和Red Journal Gray Zone案例的基准测试：AI辅助医学教育和放射肿瘤治疗决策的潜力与挑战

    Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology. (arXiv:2304.11957v2 [physics.med-ph] UPDATED)

    [http://arxiv.org/abs/2304.11957](http://arxiv.org/abs/2304.11957)

    本研究评估了ChatGPT-4在放射肿瘤学方面的表现，成绩显示出它在医学考试上有很大的优势，在实际应用中存在局限性。另外，ChatGPT-4 在放射肿瘤学上表现出色，但在骨骼和软组织以及妇科方面有待改进。

    

    大型语言模型在医学上的教育和决策方面的潜力已经得到证明，因为它们在美国医学许可考试（USMLE）和MedQA考试等医学考试中取得了不错的成绩。本研究评估了ChatGPT-4在放射肿瘤学专业领域的表现，使用了第38届美国放射学院（ACR）放射肿瘤内科（TXIT）考试和2022年的Red Journal Gray Zone案例。基于TXIT考试，ChatGPT-4在放射肿瘤学方面表现出色，但在ACR知识领域中的骨骼和软组织以及妇科方面存在局限性。在临床路径方面，ChatGPT-4在2022年的Red Journal Gray Zone案例中表现较好，具有70.65％的准确率。本研究展示了使用大型语言模型（例如ChatGPT-4）进行放射肿瘤学AI辅助医学教育和决策制定的潜力和挑战。

    The potential of large language models in medicine for education and decision making purposes has been demonstrated as they achieve decent scores on medical exams such as the United States Medical Licensing Exam (USMLE) and the MedQA exam. In this work, we evaluate the performance of ChatGPT-4 in the specialized field of radiation oncology using the 38th American College of Radiology (ACR) radiation oncology in-training (TXIT) exam and the 2022 red journal gray zone cases. For the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of 63.65% and 74.57%, respectively, highlighting the advantage of the latest ChatGPT-4 model. Based on the TXIT exam, ChatGPT-4's strong and weak areas in radiation oncology are identified to some extent. Specifically, ChatGPT-4 demonstrates good knowledge of statistics, CNS & eye, pediatrics, biology, and physics but has limitations in bone & soft tissue and gynecology, as per the ACR knowledge domain. Regarding clinical care paths, ChatGPT-4 perf
    
[^145]: 在ChatGPT时代迈向负责任的人工智能：用于设计基于基础模型的AI系统的参考架构

    Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems. (arXiv:2304.11090v1 [cs.CL])

    [http://arxiv.org/abs/2304.11090](http://arxiv.org/abs/2304.11090)

    本文提出了一个以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统，重点关注可解释性、公平性、安全性和鲁棒性等关键设计元素。

    

    ChatGPT、Bard和其他大型语言模型(LLM)聊天机器人的推出在全球范围内引起了巨大关注。基础模型将成为未来大多数AI系统的基础构建块的趋势正在增长。然而，将基础模型纳入AI系统引发了对负责任AI的重大关注，这是由于其黑匣子性质和快速发展的超级智能引起的。此外，基础模型的增长能力最终可能会吞噬AI系统的其他组件，引入架构设计中的运动边界和接口演变挑战。为了应对这些挑战，本文提出了一种以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统。特别地，本文首先呈现了基于基础模型的AI系统在架构演进方面的发展，从"基础模型作为连接器"到"基础模型作为单片机核"。然后，它提出了一个参考架构，包括五个类别的模式，重点关注关键设计元素，例如可解释性、公平性、安全性和鲁棒性。所提出的参考架构为设计负责任的基础模型的AI系统提供了系统化和透明的方法。

    The release of ChatGPT, Bard, and other large language model (LLM)-based chatbots has drawn huge attention on foundations models worldwide. There is a growing trend that foundation models will serve as the fundamental building blocks for most of the future AI systems. However, incorporating foundation models in AI systems raises significant concerns about responsible AI due to their black box nature and rapidly advancing super-intelligence. Additionally, the foundation model's growing capabilities can eventually absorb the other components of AI systems, introducing the moving boundary and interface evolution challenges in architecture design. To address these challenges, this paper proposes a pattern-oriented responsible-AI-by-design reference architecture for designing foundation model-based AI systems. Specially, the paper first presents an architecture evolution of AI systems in the era of foundation models, from "foundation-model-as-a-connector" to "foundation-model-as-a-monolithi
    
[^146]: 大型语言模型在文学翻译中高效利用文档级上下文，但关键错误仍然存在

    Large language models effectively leverage document-level context for literary translation, but critical errors persist. (arXiv:2304.03245v1 [cs.CL])

    [http://arxiv.org/abs/2304.03245](http://arxiv.org/abs/2304.03245)

    该研究通过人工评估发现，大型语言模型在进行文学段落翻译时会利用更多的文档级上下文，从而减少关键错误。然而，一些与上下文和意义相关的错误仍然存在。

    

    大型语言模型（LLMs）在许多句子级别的翻译数据集上与现有技术水平相当。然而，它们在段落和文档翻译方面的能力尚未得到探究，因为这些环境下的评估代价高且困难。通过一项严谨的人工评估，我们展示了要求Gpt-3.5（text-davinci-003）LLM将整个文学段落（例如，从小说中）进行翻译的结果比标准的逐句翻译在18个语言对（例如，日语、波兰语和英语的翻译）上产生更高质量的翻译。我们的评估需要约350个小时的注释和分析工作，通过聘请熟练掌握源语言和目标语言的译者，并要求他们提供跨度级别的错误注释以及哪种系统的翻译更好的偏好判断。我们观察到，篇章级别的LLM翻译在文学段落的翻译中出现的关键错误更少，但仍存在一些与上下文和意义相关的错误。

    Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer 
    
[^147]: 基于情感的文学情绪代理

    Affect as a proxy for literary mood. (arXiv:2304.02894v1 [cs.CL])

    [http://arxiv.org/abs/2304.02894](http://arxiv.org/abs/2304.02894)

    该研究提出使用情感作为文学文本情绪的代理，并能通过扩展情感词典在考虑文本语义转移和领域的前提下，提供近期和现代分析的实际可行结果。

    

    我们提出使用情感作为文学文本情绪的代理。在这项研究中，我们探讨了在计算情感与检测情绪之间的区别。从方法论的角度，我们利用情感词嵌入来观察不同文本段落中的情感分布。我们还提出了一种简单而有效的方法，用于增强情感词典，考虑了语义转移和文本领域，从而产生了与当代和现代定性分析密切匹配的现实世界一致的结果。

    We propose to use affect as a proxy for mood in literary texts. In this study, we explore the differences in computationally detecting tone versus detecting mood. Methodologically we utilize affective word embeddings to look at the affective distribution in different text segments. We also present a simple yet efficient and effective method of enhancing emotion lexicons to take both semantic shift and the domain of the text into account producing real-world congruent results closely matching both contemporary and modern qualitative analyses.
    
[^148]: 大象的透视镜：调查谷歌、ChatGPT、维基百科和YouTube上的语言偏见

    A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube. (arXiv:2303.16281v1 [cs.CY])

    [http://arxiv.org/abs/2303.16281](http://arxiv.org/abs/2303.16281)

    研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。

    

    与谷歌搜索“从多个角度获取信息，以便你可以形成自己对世界的理解”的任务相反，我们发现谷歌及其最突出的搜索结果 - 维基百科和YouTube，仅反映与“佛教”、“自由主义”、“殖民化”、“伊朗”和“美国”等复杂主题相关的文化刻板印象。简单地说，在不同语言的相同搜索中，它们以不同程度呈现不同的信息（我们称之为“语言偏见”），而不是呈现复杂主题的全球图片。我们的在线搜索使我们成为谚语中的盲人，仅触摸小象的一小部分，不知道其他文化的视角的存在。我们用于搜索的语言最终成为促进本族中心主义观点的文化过滤器，其中一个人根据自己的文化评估其他人或思想。我们还发现ChatGPT中深深嵌入了语言偏见。

    Contrary to Google Search's mission of delivering information from "many angles so you can form your own understanding of the world," we find that Google and its most prominent returned results -- Wikipedia and YouTube, simply reflect the narrow set of cultural stereotypes tied to the search language for complex topics like "Buddhism," "Liberalism," "colonization," "Iran" and "America." Simply stated, they present, to varying degrees, distinct information across the same search in different languages (we call it 'language bias'). Instead of presenting a global picture of a complex topic, our online searches turn us into the proverbial blind person touching a small portion of an elephant, ignorant of the existence of other cultural perspectives. The language we use to search ends up as a cultural filter to promote ethnocentric views, where a person evaluates other people or ideas based on their own culture. We also find that language bias is deeply embedded in ChatGPT. As it is primaril
    
[^149]: DeltaScore: 利用差分扰动评价故事生成

    DeltaScore: Evaluating Story Generation with Differentiating Perturbations. (arXiv:2303.08991v1 [cs.CL])

    [http://arxiv.org/abs/2303.08991](http://arxiv.org/abs/2303.08991)

    DeltaScore利用差分扰动来评估故事生成的细粒度方面，并通过计算故事在特定方面扰动前后的可能性差异来衡量影响。该方法在多个故事领域中得到了评估，并与人类判断的相关性进行了研究。

    

    自然语言生成的各种评价指标存在，但对于故事生成的实用性有限，因为它们通常与人类判断的相关性不强，也不能测量细粒度的故事方面，例如流畅度与相关性，因为它们旨在评估整体生成质量。本文提出DeltaScore，一种利用扰动来评估细粒度故事方面的方法。我们的核心思想是基于这样的假设：故事在特定方面表现得越好（例如流畅度），它就会受到特定扰动（例如引入错别字）的影响越大。为了衡量影响，我们使用语言模型计算扰动前后故事的可能性差异。我们在多个故事领域中使用DeltaScore评估了基于状态的最新模型和传统基于相似性的指标，并研究了它与人类在五个细粒度故事方面的判断之间的相关性。

    Various evaluation metrics exist for natural language generation tasks, but they have limited utility for story generation since they generally do not correlate well with human judgments and do not measure fine-grained story aspects, such as fluency versus relatedness, as they are intended to assess overall generation quality. In this paper, we propose deltascore, an approach that utilizes perturbation to evaluate fine-grained story aspects. Our core idea is based on the hypothesis that the better the story performs in a specific aspect (e.g., fluency), the more it will be affected by a particular perturbation (e.g., introducing typos). To measure the impact, we calculate the likelihood difference between the pre- and post-perturbation stories using a language model. We evaluate deltascore against state-of-the-art model-based and traditional similarity-based metrics across multiple story domains, and investigate its correlation with human judgments on five fine-grained story aspects: f
    
[^150]: MUX-PLMs：高吞吐量语言模型的数据复用

    MUX-PLMs: Data Multiplexing for High-throughput Language Models. (arXiv:2302.12441v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12441](http://arxiv.org/abs/2302.12441)

    该论文开发了一种名为MUX-PLMs的高吞吐量预训练语言模型，使用数据复用训练，可用于高性能的MIMO样式语言模型推断。

    

    大型语言模型（如ChatGPT和Bard）的广泛采用带来了前所未有的需求。越来越大的模型尺寸所需的推断成本以及硬件短缺，限制了经济实惠的访问，并提出了针对高吞吐量和高性能的效率方法的迫切需求。多输入多输出（MIMO）算法（例如数据复用）通过对多个输入执行推断，以单个输入的成本提供了多重吞吐量的有前途的解决方案。然而，这些方法目前的表现还不足以部署在现代系统中。我们通过开发MUX-PLMs，一种使用数据复用训练的高吞吐量预训练语言模型（PLMs），可以微调任何下游任务以产生高吞吐量和高性能。我们的新型复用和解复用模块能够有效地纠缠和解缠输入，并实现高性能的MIMO样式语言模型推断。

    The widespread adoption of large language models such as ChatGPT and Bard has led to unprecedented demand for these technologies. The burgeoning cost of inference for ever-increasing model sizes coupled with hardware shortages has limited affordable access and poses a pressing need for efficiency approaches geared towards high throughput and performance. Multi-input multi-output (MIMO) algorithms such as data multiplexing, offer a promising solution with a many-fold increase in throughput by performing inference for multiple inputs at the cost of a single input. Yet these approaches are not currently performant enough to be deployed in modern systems. We change that by developing MUX-PLMs, a class of high throughput pre-trained language models (PLMs) trained with data multiplexing, that can be fine-tuned for any downstream task to yield high-throughput high-performance. Our novel multiplexing and demultiplexing modules proficiently entangle and disentangle inputs, and enable high-perfo
    
[^151]: 大型语言模型的思维链主动提示

    Active Prompting with Chain-of-Thought for Large Language Models. (arXiv:2302.12246v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12246](http://arxiv.org/abs/2302.12246)

    本论文提出了一种新的方法Active-Prompt，它使用任务特定的示例提示适应大型语言模型中的不同任务，提高模型性能与效率。

    

    大型语言模型的规模日益增大，为各种需要推理的复杂任务（如算术和常识推理）带来了新的能力。众所周知，任务特定提示的有效设计对LLMs产生高质量答案的能力至关重要。特别是，对于复杂的问答任务，一种有效的方法是基于示例的思维链（CoT）推导提示，它大大提高了LLMs的性能。但是，当前的CoT方法依赖于一组固定的人类注释示例，这些示例不一定是不同任务的最有效示例。本文提出了一种新方法，Active-Prompt，使用任务特定的示例提示（人为设计的CoT推理注释）来适应LLMs不同的任务。为此，我们提出了一个解决方案，确定哪些问题从任务特定查询池中注释最重要和有用。通过借鉴主动学习的方法，我们提出了一个主动提示(Acitve-Prompt)的方法，将最相关的问题作为任务特定提示添加给LLMs，从而改善其性能。

    The increasing scale of large language models (LLMs) brings emergent abilities to various complex tasks requiring reasoning, such as arithmetic and commonsense reasoning. It is known that the effective design of task-specific prompts is critical for LLMs' ability to produce high-quality answers. In particular, an effective approach for complex question-and-answer tasks is example-based prompting with chain-of-thought (CoT) reasoning, which significantly improves the performance of LLMs. However, current CoT methods rely on a fixed set of human-annotated exemplars, which are not necessarily the most effective examples for different tasks. This paper proposes a new method, Active-Prompt, to adapt LLMs to different tasks with task-specific example prompts (annotated with human-designed CoT reasoning). For this purpose, we propose a solution to the key problem of determining which questions are the most important and helpful ones to annotate from a pool of task-specific queries. By borrowi
    
[^152]: ChatGPT：应付千事的万能型 AI，但无所专精

    ChatGPT: Jack of all trades, master of none. (arXiv:2302.10724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.10724](http://arxiv.org/abs/2302.10724)

    本研究检验了 ChatGPT 在 25 个不同的 NLP 任务上的性能，它是一个万能的 AI 模型，但无关紧要的表现可能会对某些任务的表现产生负面影响。

    

    OpenAI 推出了聊天生成预训练 Transformer（ChatGPT），革新了人工智能与人类互动的方法。许多研究通过测试 ChatGPT 在众所周知的自然语言处理（NLP）任务中的效果，来评估该模型的效能。然而，现有的研究大多非自动化，并且规模非常有限。本研究在 25 个不同的 NLP 任务上检验了 ChatGPT 的性能，其中大多数任务甚至对人类而言都是主观的，例如情感分析、情绪识别、攻击性和立场检测。另一些任务则需要更客观的推理，如词义消歧、语言可接受性和问答。我们还对 GPT-4 模型在五个选定的 NLP 任务子集上进行了评估。我们自动化了 ChatGPT 和 GPT-4 的引导过程，并分析了超过 49k 个响应。与现有最先进的解决方案（SOTA）进行比较，我们的结果显示，在一些任务上 ChatGPT 的性能存在一定的缺陷。

    OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quali
    
[^153]: 半结构化物体序列编码器

    Semi-Structured Object Sequence Encoders. (arXiv:2301.01015v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.01015](http://arxiv.org/abs/2301.01015)

    本文提出了一种半结构化物体序列编码器，通过编码键的值的表示并自我关注这些键以完成下游任务来解决长对象序列的问题。

    

    本文探讨了建模半结构化对象序列的任务，特别关注开发这些序列的结构感知输入表示的问题。这种数据的例子包括用户在网站上的活动、机器日志等。由于序列长度的不断增加，这种数据经常被表示为一系列的键值对集合。我们提出了一个两部分方法，首先独立考虑每个键并编码其值的表示，然后自我关注这些具有值感知的键表示以完成下游任务。这样，我们可以操作比现有方法更长的对象序列。我们介绍了两个模块之间的新型共享注意力头结构，并提出了一种创新的训练计划，交替训练两个模块，某些注意力头使用共享权重。我们对我们的方法在多个数据集上进行了实验，发现它在几个基准上取得了显着改进。

    In this paper we explore the task of modeling semi-structured object sequences; in particular, we focus our attention on the problem of developing a structure-aware input representation for such sequences. Examples of such data include user activity on websites, machine logs, and many others. This type of data is often represented as a sequence of sets of key-value pairs over time and can present modeling challenges due to an ever-increasing sequence length. We propose a two-part approach, which first considers each key independently and encodes a representation of its values over time; we then self-attend over these value-aware key representations to accomplish a downstream task. This allows us to operate on longer object sequences than existing methods. We introduce a novel shared-attention-head architecture between the two modules and present an innovative training schedule that interleaves the training of both modules with shared weights for some attention heads. Our experiments on
    
[^154]: ByGPT5：基于端到端的、面向风格的诗歌生成模型，采用无记号言语模型

    ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models. (arXiv:2212.10474v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10474](http://arxiv.org/abs/2212.10474)

    本研究提出了一种基于无记号言语模型的端到端诗歌生成模型ByGPT5，并成功地应用于韵律、节律和头韵等风格的诗歌生成，取得了较好的性能表现。

    

    现有的诗歌生成系统通常非常复杂，要么由特定任务的模型管道构成，要么采用手动创建的约束条件来融入先前的知识，或两者兼而有之。相反，端到端的模型不需要建模先前的知识，并且可以仅从数据中学习诗歌的微妙之处，从而减少需要人类监督的程度。在本研究中，我们研究了以韵律、节律和头韵等风格为条件的端到端诗歌生成。我们确定并解决了过去尝试的数据缺乏和不匹配的记号化算法可能存在的局限性。特别地，我们成功地预训练了ByGPT5，一种新的无记号解码器-仅语言模型，并在我们的风格标注的大型定制英语和德语四行诗语料库上进行微调。我们展示了ByGPT5优于其他模型，如mT5、ByT5、GPT-2和ChatGPT，同时也更具参数效率，性能表现良好。

    State-of-the-art poetry generation systems are often complex. They either consist of task-specific model pipelines, incorporate prior knowledge in the form of manually created constraints, or both. In contrast, end-to-end models would not suffer from the overhead of having to model prior knowledge and could learn the nuances of poetry from data alone, reducing the degree of human supervision required. In this work, we investigate end-to-end poetry generation conditioned on styles such as rhyme, meter, and alliteration. We identify and address lack of training data and mismatching tokenization algorithms as possible limitations of past attempts. In particular, we successfully pre-train ByGPT5, a new token-free decoder-only language model, and fine-tune it on a large custom corpus of English and German quatrains annotated with our styles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2 and ChatGPT, while also being more parameter efficient and performing favorably c
    
[^155]: 大型语言模型是带有自我验证的推理器

    Large Language Models are reasoners with Self-Verification. (arXiv:2212.09561v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.09561](http://arxiv.org/abs/2212.09561)

    本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。

    

    当大型语言模型（LLM）通过思维链（CoT）进行复杂推理时，它非常敏感于个别错误。为了解决这个问题，我们必须训练验证器。我们提出一种称为自我验证的新方法，该方法使用CoT的结论作为条件来构建一个新样本，并要求LLM重新预测被掩盖的原始条件。我们基于准确性计算可解释的验证分数。该方法可以在使用少量样本学习时提高多个算术和逻辑推理数据集的准确性。我们已经证明LLM可以对其自己的结论进行可解释的自我验证并实现竞争性的推理性能。全面的实验表明，我们的方法可以帮助多种带有自我验证功能的大型语言模型避免混淆。

    When a large language model (LLM) performs complex reasoning by chain of thought (CoT), it can be highly sensitive to individual mistakes. We have had to train verifiers to address this issue. As we all know, after human inferring a conclusion, they often check it by re-verifying it, which can avoid some mistakes. We propose a new method called self-verification that uses the conclusion of the CoT as a condition to build a new sample and asks the LLM to re-predict the original conditions which be masked. We calculate an explainable verification score based on the accuracy. This method can improve the accuracy of multiple arithmetics and logical reasoning datasets when using few-shot learning. we have demonstrated that LLMs can conduct explainable self-verification of their own conclusions and achieve competitive reasoning performance. Extensive experimentals have demonstrated that our method can help multiple large language models with self-verification can avoid interference from inco
    
[^156]: 从众包注释中进行多视角知识蒸馏以实现跨领域泛化

    Multi-View Knowledge Distillation from Crowd Annotations for Out-of-Domain Generalization. (arXiv:2212.09409v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09409](http://arxiv.org/abs/2212.09409)

    本文提出了一种新方法，通过聚合多个视图的众包注释来获取软标签，从而进行跨领域泛化。

    

    在自然语言处理任务中选择有效的训练信号很困难：专家注释很昂贵，而众包注释可能不可靠。最近的NLP研究表明，从众包注释中获取标签分布的学习可以是有效的。然而，有很多获取这种分布的方法，任何一种方法的性能都可能因任务和可用众包注释量而波动，这使得事先不知道哪种分布最好。本文在领域外系统地分析了这个问题，并提出了通过聚合现有方法产生的分布来获取来自众包注释的软标签的新方法。特别地，我们建议通过温度缩放和找到它们的Jensen-Shannon中心来聚合众包注释的多个视图。

    Selecting an effective training signal for tasks in natural language processing is difficult: expert annotations are expensive, and crowd-sourced annotations may not be reliable. At the same time, recent work in NLP has demonstrated that learning from a distribution over labels acquired from crowd annotations can be effective. However, there are many ways to acquire such a distribution, and the performance allotted by any one method can fluctuate based on the task and the amount of available crowd annotations, making it difficult to know a priori which distribution is best. This paper systematically analyzes this in the out-of-domain setting, adding to the NLP literature which has focused on in-domain evaluation, and proposes new methods for acquiring soft-labels from crowd-annotations by aggregating the distributions produced by existing methods. In particular, we propose to aggregate multiple-views of crowd annotations via temperature scaling and finding their Jensen-Shannon centroid
    
[^157]: KITMUS测试：评估自然语言理解系统中多源知识整合能力

    The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources in Natural Language Understanding Systems. (arXiv:2212.08192v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08192](http://arxiv.org/abs/2212.08192)

    本文提出了一个KITMUS测试套件，用于评估自然语言理解模型对多源知识进行整合和推理的能力，在测试中的核心子任务需要进行针对多个事实的推理。实验结果表明，许多模型难以实时进行推理。

    

    许多最先进的自然语言理解模型都基于预训练的神经语言模型。这些模型通常会利用多个来源的信息进行推理，其中一个重要类别的推理需要在推理时间提供预训练参数中包含的背景知识以及特定实例的信息。然而，在多源知识存在的情况下，自然语言理解模型的整合和推理能力还没有得到充分的研究。在这项工作中，我们提出了一个核心指代消解子任务的测试套件，需要针对多个事实进行推理。这些子任务在哪些知识来源包含相关的事实方面存在差异。我们还引入了在推理时间仅使用虚构知识的子任务。我们评估了最先进的核心指代消解模型在我们的数据集上。我们的结果表明，有几个模型难以实时进行推理。

    Many state-of-the-art natural language understanding (NLU) models are based on pretrained neural language models. These models often make inferences using information from multiple sources. An important class of such inferences are those that require both background knowledge, presumably contained in a model's pretrained parameters, and instance-specific information that is supplied at inference time. However, the integration and reasoning abilities of NLU models in the presence of multiple knowledge sources have been largely understudied. In this work, we propose a test suite of coreference resolution subtasks that require reasoning over multiple facts. These subtasks differ in terms of which knowledge sources contain the relevant facts. We also introduce subtasks where knowledge is present only at inference time using fictional knowledge. We evaluate state-of-the-art coreference resolution models on our dataset. Our results indicate that several models struggle to reason on-the-fly o
    
[^158]: MM-SHAP：一种用于衡量视觉与语言模型和任务的多模态贡献的性能不可知度量

    MM-SHAP: A Performance-agnostic Metric for Measuring Multimodal Contributions in Vision and Language Models & Tasks. (arXiv:2212.08158v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.08158](http://arxiv.org/abs/2212.08158)

    该论文提出了一种性能不可知的多模态得分方法MM-SHAP，可以可靠地量化多模态模型使用各自模态的比例，并应用于比较模型的平均多模态程度和衡量个体模型的贡献。实验结果表明单模态崩溃比以前认为的更为普遍，而MM-SHAP是分析VL模型多模态行为的有效工具。

    

    已知视觉和语言模型（VL）往往利用各自模态中的不稳定指标（例如由分布偏差引入）而不是专注于每个模态中的相关信息。如果单模态模型在VL任务上达到类似多模态模型的准确度，则表明所谓的单模态崩溃已经发生。然而，基于准确度的测试无法检测例如模型预测错误但模型使用了一个模态的相关信息。因此，我们提出了MM-SHAP，一种基于Shapley值的性能不可知多模态得分，可可靠地量化多模态模型使用各自模态的比例。我们将MM-SHAP应用于两种方式：（1）比较模型的平均多模态程度，（2）衡量不同任务和数据集的个体模型对各自模态的贡献。六个VL模型的实验（LXMERT、CLIP和四个ALBEF变体）表明单模态崩溃比我们以前认为的更为普遍。我们的结果还表明，MM-SHAP是揭示和分析VL模型多模态行为的有效工具。

    Vision and language models (VL) are known to exploit unrobust indicators in individual modalities (e.g., introduced by distributional biases) instead of focusing on relevant information in each modality. That a unimodal model achieves similar accuracy on a VL task to a multimodal one, indicates that so-called unimodal collapse occurred. However, accuracy-based tests fail to detect e.g., when the model prediction is wrong, while the model used relevant information from a modality. Instead, we propose MM-SHAP, a performance-agnostic multimodality score based on Shapley values that reliably quantifies in which proportions a multimodal model uses individual modalities. We apply MM-SHAP in two ways: (1) to compare models for their average degree of multimodality, and (2) to measure for individual models the contribution of individual modalities for different tasks and datasets. Experiments with six VL models -- LXMERT, CLIP and four ALBEF variants -- on four VL tasks highlight that unimodal
    
[^159]: 从任务说明书中学习的鲁棒性

    Robustness of Learning from Task Instructions. (arXiv:2212.03813v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.03813](http://arxiv.org/abs/2212.03813)

    本文提出了一种鲁棒的方法来从任务说明中学习，以处理说明的变化并提高对新任务的泛化能力。

    

    传统的监督学习大多在个别任务上进行，并需要在大量的任务特定示例上训练。这种范式严重阻碍了任务概括的发展，因为准备任务特定示例集是昂贵的。为了构建一个可以快速轻松地推广到新任务的系统，最近采用了任务说明作为监督的新兴趋势。这些说明给模型定义了任务，并允许模型根据说明和输入输出适当的答案。然而，任务说明通常以不同形式表达，可以从两个线索中解释：首先，一些说明是短句，并且是预训练的语言模型（PLM）导向，例如提示，而其他说明是段落，并且是人为导向的，例如亚马逊的MTurk; 其次，不同的最终用户很可能用不同的文本表达方式解释相同的任务。需要一种鲁棒的学习方法来解决任务说明的可变性。在本文中，作者提出了一种鲁棒的方法来从任务说明中学习，可以处理说明的变化并改善对新任务的概括。

    Traditional supervised learning mostly works on individual tasks and requires training on a large set of task-specific examples. This paradigm seriously hinders the development of task generalization since preparing a task-specific example set is costly. To build a system that can quickly and easily generalize to new tasks, task instructions have been adopted as an emerging trend of supervision recently. These instructions give the model the definition of the task and allow the model to output the appropriate answer based on the instructions and inputs. However, task instructions are often expressed in different forms, which can be interpreted from two threads: first, some instructions are short sentences and are pretrained language model (PLM) oriented, such as prompts, while other instructions are paragraphs and are human-oriented, such as those in Amazon MTurk; second, different end-users very likely explain the same task with instructions of different textual expressions. A robust 
    
[^160]: 基于关键词强化学习的任务导向对话中端到端响应生成的改进

    KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning. (arXiv:2211.16773v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.16773](http://arxiv.org/abs/2211.16773)

    本文提出了一种新的训练算法，KRLS，该算法通过关键词强化学习和精细的奖励函数来帮助模型在任务导向对话中生成关键词，实验结果显示，该算法在MultiWoZ基准数据集上取得了最先进的表现。

    

    在任务导向的对话中，一个信息丰富且成功的系统响应需要包含关键信息，例如酒店的电话号码。因此，我们假设通过正确生成关键数量，模型可以实现更好的整体性能。在本文中，我们提出了一种新的训练算法，即关键词强化学习与下一个单词采样（KRLS），利用强化学习，但避免了耗时的自回归生成，并采用了细粒度的逐令牌奖励函数来帮助模型更加强健地学习关键词生成。实证结果表明，KRLS算法可以在MultiWoZ基准数据集上实现良好的信息、成功和综合分数的最先进表现。

    In task-oriented dialogs, an informative and successful system response needs to include key information such as the phone number of a hotel. Therefore, we hypothesize that a model can achieve better overall performance by focusing on correctly generating key quantities. In this paper, we propose a new training algorithm, Keywords Reinforcement Learning with Next-word Sampling (KRLS), that utilizes Reinforcement Learning but avoids the time-consuming auto-regressive generation, and a fine-grained per-token reward function to help the model learn keywords generation more robustly. Empirical results show that the KRLS algorithm can achieve state-of-the-art performance on the inform, success, and combined score on the MultiWoZ benchmark dataset.
    
[^161]: GPT-3.5下的提示意见摘要化

    Prompted Opinion Summarization with GPT-3.5. (arXiv:2211.15914v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15914](http://arxiv.org/abs/2211.15914)

    本文展示了使用GPT-3.5模型实现意见摘要的方法，通过递归摘要和显著内容选择的方式来处理大量用户评论，并使用三个新的评估指标来评估性能。

    

    大型语言模型在各种任务中展现出了惊人的性能，包括文本摘要。本文展示了这种强大性能扩展到了意见摘要。我们探索了几种 GPT-3.5 应用于提示方式下对大量用户评论进行摘要的流水线方法。为了处理任意数量的用户评论，我们探索了递归摘要以及通过监督聚类或抽取选择显著内容进行摘要的方法。在两个数据集上（一个是酒店评论的方面导向的摘要数据集（SPACE），另一个是关于亚马逊和 Yelp 评论的通用摘要数据集（FewSum）），我们展示了 GPT-3.5 模型在人类评估中表现出了非常强大的性能。我们认为标准评估指标不能反映这一点，并引入了三个新的指标，以对比这些不同的方法，分别针对忠诚度、事实性和通用性。

    Large language models have shown impressive performance across a wide variety of tasks, including text summarization. In this paper, we show that this strong performance extends to opinion summarization. We explore several pipeline methods for applying GPT-3.5 to summarize a large collection of user reviews in a prompted fashion. To handle arbitrarily large numbers of user reviews, we explore recursive summarization as well as methods for selecting salient content to summarize through supervised clustering or extraction. On two datasets, an aspect-oriented summarization dataset of hotel reviews (SPACE) and a generic summarization dataset of Amazon and Yelp reviews (FewSum), we show that GPT-3.5 models achieve very strong performance in human evaluation. We argue that standard evaluation metrics do not reflect this, and introduce three new metrics targeting faithfulness, factuality, and genericity to contrast these different methods.
    
[^162]: 序列补全的课程学习在自然语言生成中的应用

    In-sample Curriculum Learning by Sequence Completion for Natural Language Generation. (arXiv:2211.11297v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.11297](http://arxiv.org/abs/2211.11297)

    本文提出了一种在自然语言生成任务中的课程学习方法，通过序列补全的方式逐步训练模型，该方法具有很好的推广能力且在实验中表现出显著的改进。

    

    通过从易到难的训练样本，课程学习已经在多个领域表现出有希望的提升效果。以往的研究设计规则或训练模型来评估难度，高度依赖于任务特定的专业知识，难以推广。受“从易到难”启发，我们提出了一种在自然语言生成任务中进行课程学习的方法：我们的学习策略从训练模型生成最后几个词开始，即进行序列补全，然后逐渐扩展到生成整个输出序列。综合实验表明，该方法推广能力强，对不同的任务进行了显著的改进。

    Curriculum learning has shown promising improvements in multiple domains by training machine learning models from easy samples to hard ones. Previous works which either design rules or train models for scoring the difficulty highly rely on task-specific expertise, and cannot generalize. Inspired by the "easy-to-hard" intuition, we propose to do in-sample curriculum learning for natural language generation tasks. Our learning strategy starts training the model to generate the last few words, i.e., do sequence completion, and gradually extends to generate the whole output sequence. Comprehensive experiments show that it generalizes well to different tasks and achieves significant improvements over strong baselines.
    
[^163]: UGIF：UI 视觉引导下的指令跟踪

    UGIF: UI Grounded Instruction Following. (arXiv:2211.07615v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07615](http://arxiv.org/abs/2211.07615)

    该论文提出了一个多语言、多模态的 UI 视觉引导数据集，旨在通过将指令步骤与 UI 视频相结合，帮助智能手机用户更轻松地完成任务。

    

    智能手机用户经常会发现导航复杂的菜单执行常见任务变得困难，例如“如何屏蔽未知号码的来电？”目前，人工编写的逐步说明文件可帮助用户。我们提出了 UGIF-DataSet，一个多语言、多模态的 UI 视觉引导数据集，其中包含了 8 种语言的 4,184 个常用操作。作为解决这个问题的初步方法，我们提出基于用户查询检索相关指令步骤，使用大型语言模型 (LLM) 分析步骤并生成可在设备上执行的宏。

    Smartphone users often find it difficult to navigate myriad menus to perform common tasks such as "How to block calls from unknown numbers?". Currently, help documents with step-by-step instructions are manually written to aid the user. The user experience can be further enhanced by grounding the instructions in the help document to the UI and overlaying a tutorial on the phone UI. To build such tutorials, several natural language processing components including retrieval, parsing, and grounding are necessary, but there isn't any relevant dataset for such a task. Thus, we introduce UGIF-DataSet, a multi-lingual, multi-modal UI grounded dataset for step-by-step task completion on the smartphone containing 4,184 tasks across 8 languages. As an initial approach to this problem, we propose retrieving the relevant instruction steps based on the user's query and parsing the steps using Large Language Models (LLMs) to generate macros that can be executed on-device. The instruction steps are o
    
[^164]: miCSE：用于少样本句子嵌入的互信息对比学习框架

    miCSE: Mutual Information Contrastive Learning for Low-shot Sentence Embeddings. (arXiv:2211.04928v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.04928](http://arxiv.org/abs/2211.04928)

    本文提出了miCSE框架，使用互信息对比学习在少样本情况下学习句子嵌入，在多个基准测试中均表现出卓越结果，并为更加鲁棒的自监督学习方法开辟了新的途径。

    

    本文介绍了miCSE，一种基于互信息对比学习的框架，该框架极大地提高了少样本句子嵌入的最新技术水平。所提出的方法在对比学习期间，通过对不同视图的注意力模式进行对齐。使用miCSE学习句子嵌入即对每个句子的增强视图强制实施结构一致性，从而使对比自监督学习更加高效。因此，该方法在少样本学习领域表现出强大的性能。虽然与多个少样本学习基准的最新方法相比表现出卓越的结果，但在全样本情况下具有可比性。这项研究为比当前的句子嵌入对比方法更加鲁棒的高效自监督学习方法开辟了新的途径。

    This paper presents miCSE, a mutual information-based contrastive learning framework that significantly advances the state-of-the-art in few-shot sentence embedding. The proposed approach imposes alignment between the attention pattern of different views during contrastive learning. Learning sentence embeddings with miCSE entails enforcing the structural consistency across augmented views for every sentence, making contrastive self-supervised learning more sample efficient. As a result, the proposed approach shows strong performance in the few-shot learning domain. While it achieves superior results compared to state-of-the-art methods on multiple benchmarks in few-shot learning, it is comparable in the full-shot scenario. This study opens up avenues for efficient self-supervised learning methods that are more robust than current contrastive methods for sentence embedding.
    
[^165]: 中文CLIP: 中文对比视觉语言预训练

    Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese. (arXiv:2211.01335v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.01335](http://arxiv.org/abs/2211.01335)

    本研究构建了一个大规模的中文图像-文本对数据集，新提出的两阶段预训练方法提高了模型性能，中文CLIP在多任务图像理解中取得最先进的性能表现，特别在零样本学习和微调设置下表现出色。

    

    CLIP的巨大成功推动了对于视觉语言预训练中对比学习的研究和应用。本研究构建了一个大规模的中文图像-文本对数据集，其中大部分数据来源于公开数据集，我们在这个新数据集上对中文CLIP模型进行了预训练，开发了5个多尺寸的中文CLIP模型，范围从7700万到9.58亿参数。此外，我们提出了一个两阶段预训练方法，在该方法中，模型首先使用冻结的图像编码器进行训练，然后使用所有参数进行优化来提高模型性能。综合实验表明，中文CLIP可以在零样本学习和微调设置下在MUGE、Flickr30K-CN和COCO-CN上实现最先进的性能，并且它能够在ELEVATER基准测试上的零样本图像分类中取得竞争性的性能。

    The tremendous success of CLIP (Radford et al., 2021) has promoted the research and application of contrastive learning for vision-language pretraining. In this work, we construct a large-scale dataset of image-text pairs in Chinese, where most data are retrieved from publicly available datasets, and we pretrain Chinese CLIP models on the new dataset. We develop 5 Chinese CLIP models of multiple sizes, spanning from 77 to 958 million parameters. Furthermore, we propose a two-stage pretraining method, where the model is first trained with the image encoder frozen and then trained with all parameters being optimized, to achieve enhanced model performance. Our comprehensive experiments demonstrate that Chinese CLIP can achieve the state-of-the-art performance on MUGE, Flickr30K-CN, and COCO-CN in the setups of zero-shot learning and finetuning, and it is able to achieve competitive performance in zero-shot image classification based on the evaluation on the ELEVATER benchmark (Li et al., 
    
[^166]: 探索音频语言学习中的训练和测试增强

    Exploring Train and Test-Time Augmentations for Audio-Language Learning. (arXiv:2210.17143v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.17143](http://arxiv.org/abs/2210.17143)

    本研究揭示了数据增强对音频语言多模态学习的重要性。作者提出了音频语言配对增强和多层测试增强方法，成功地将它们与单模态增强结合起来，在自动化音频字幕和音频文本检索任务中取得了显著的进展。

    

    本文旨在揭示音频语言多模态学习中数据增强的影响，尽管其重要性尚未被探索。我们探索了各种增强方法，不仅在训练时，而且在测试时也进行了研究，并发现适当的数据增强可以带来显著的改进。具体而言，应用我们提出的音频语言配对增强PairMix（这是第一个多模态音频语言增强方法），在自动化音频字幕和音频文本检索任务中均优于基线。为了充分利用数据增强，我们还提出了多层测试增强（Multi-TTA）进行测试。我们成功地将两种提出的方法和单模增强组合起来，在音频字幕方面实现了47.5 SPIDEr，相对于基线提高了18.2％。在音频文本检索方面，所提出的方法也表现出了性能的提高。

    In this paper, we aim to unveil the impact of data augmentation in audio-language multi-modal learning, which has not been explored despite its importance. We explore various augmentation methods at not only train-time but also test-time and find out that proper data augmentation can lead to substantial improvements. Specifically, applying our proposed audio-language paired augmentation PairMix, which is the first multi-modal audio-language augmentation method, outperforms the baselines for both automated audio captioning and audio-text retrieval tasks. To fully take advantage of data augmentation, we also present multi-level test-time augmentation (Multi-TTA) for the test-time. We successfully incorporate the two proposed methods and uni-modal augmentations and achieve 47.5 SPIDEr on audio captioning, which is an 18.2% relative increase over the baseline. In audio-text retrieval, the proposed methods also show an improvement in performance as well.
    
[^167]: 适用于开放域问答的高效稳健密集检索的任务感知专业化

    Task-Aware Specialization for Efficient and Robust Dense Retrieval for Open-Domain Question Answering. (arXiv:2210.05156v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.05156](http://arxiv.org/abs/2210.05156)

    TASER是一种新的架构，使得密集检索器能够在参数低的情况下实现更高的准确性，超过了传统的BM25；实验表明TASER也更具鲁棒性。

    

    鉴于密集检索模型在知识密集型自然语言处理任务上的有效性，这种模型变得越来越受欢迎。具体来说，开放域问答的事实上的架构使用两个同构编码器，从相同的预训练模型初始化，但分别为问题和段落参数化。这种双编码器架构在参数方面是低效的，因为在编码器之间没有参数共享。最近的研究表明，在各种设置中，这种密集检索器的性能低于BM25。因此，我们提出了一种新的架构，称为Task-aware Specialization for dense Retrieval(TASER)，它通过交错共享和专门化块在单个编码器中实现参数共享。我们在五个问答数据集上的实验表明，TASER可以在仅使用双编码器密集检索器约60%的参数的情况下，实现优越的准确性，超过BM25。在域外评估中，TASER也经验证实际上更具鲁棒性。

    Given its effectiveness on knowledge-intensive natural language processing tasks, dense retrieval models have become increasingly popular. Specifically, the de-facto architecture for open-domain question answering uses two isomorphic encoders that are initialized from the same pretrained model but separately parameterized for questions and passages. This bi-encoder architecture is parameter-inefficient in that there is no parameter sharing between encoders. Further, recent studies show that such dense retrievers underperform BM25 in various settings. We thus propose a new architecture, Task-aware Specialization for dense Retrieval (TASER), which enables parameter sharing by interleaving shared and specialized blocks in a single encoder. Our experiments on five question answering datasets show that TASER can achieve superior accuracy, surpassing BM25, while using about 60% of the parameters as bi-encoder dense retrievers. In out-of-domain evaluations, TASER is also empirically more robu
    
[^168]: ASDOT：预训练语言模型实现数据到文本的零样本生成

    ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models. (arXiv:2210.04325v3 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2210.04325](http://arxiv.org/abs/2210.04325)

    该论文提出了一种名为ASDOT的新方法，可以通过利用任何给定或没有样本进行数据到文本的生成。该方法由两个步骤组成，其使用预训练语言模型进行解决，并可适用于各种不同的场景。

    

    数据到文本的生成在输入数据的领域（如金融 vs 运动）或架构（例如，不同的谓词）方面存在巨大的差异，这使得最近的端到端神经方法需要足够多的训练样本才能学习到消除歧义和描述数据的方法。然而，现实中的数据到文本问题往往面临着各种不足样本的问题：可能只有极少量的训练样本或根本没有训练样本，或需要依赖于不同领域或架构的样例。为了填补这一空白，我们提出了 Any-Shot Data-to-Text (ASDOT)，一种新的方法，通过有效利用任何给定（或没有）样本，可以灵活适用于各种不同的场景。ASDOT由两个步骤组成，数据消歧和句子融合，这两个步骤都可以使用现成的预训练语言模型（LMs）进行解决。在数据消歧阶段，我们使用提示式GPT-3模型来理解输入数据中可能存在的模糊三元组，然后将其与可用样本中的信息融合以生成文本。

    Data-to-text generation is challenging due to the great variety of the input data in terms of domains (e.g., finance vs sports) or schemata (e.g., diverse predicates). Recent end-to-end neural methods thus require substantial training examples to learn to disambiguate and describe the data. Yet, real-world data-to-text problems often suffer from various data-scarce issues: one may have access to only a handful of or no training examples, and/or have to rely on examples in a different domain or schema. To fill this gap, we propose Any-Shot Data-to-Text (ASDOT), a new approach flexibly applicable to diverse settings by making efficient use of any given (or no) examples. ASDOT consists of two steps, data disambiguation and sentence fusion, both of which are amenable to be solved with off-the-shelf pretrained language models (LMs) with optional finetuning. In the data disambiguation stage, we employ the prompted GPT-3 model to understand possibly ambiguous triples from the input data and c
    
[^169]: 光轻混合召回器的效率和泛化性能研究

    A Study on the Efficiency and Generalization of Light Hybrid Retrievers. (arXiv:2210.01371v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2210.01371](http://arxiv.org/abs/2210.01371)

    本文研究了光轻混合召回器的效率和泛化性能，提出了一种采用索引高效的密集召回器和LITE召回器相结合的方法，相对于传统方法可以节省内存。实验证明，该方法可以在不牺牲性能的情况下显著提高模型的泛化性能。

    

    混合召回器可以充分利用稀疏和密集召回器的优点。以前的混合召回器利用索引密集的密集召回器。在本研究中，我们研究“是否可以在不牺牲性能的情况下减少混合召回器的索引内存”？受此问题驱动，我们利用一种索引高效的密集召回器（即DrBoost），并引入LITE召回器进一步减少DrBoost的内存。LITE同时通过对比学习和知识蒸馏来进行联合训练，并将BM25稀疏召回器与LITE或DrBoost相结合形成轻混合召回器。我们的Hybrid-LITE召回器在保持BM25和DPR混合召回器98.0％的性能的同时节省了13倍的内存。此外，我们研究了我们的轻混合召回器在域外数据集和一组对抗性攻击数据集上的泛化容量。实验表明，轻混合召回器的泛化性能优于单个召回器。

    Hybrid retrievers can take advantage of both sparse and dense retrievers. Previous hybrid retrievers leverage indexing-heavy dense retrievers. In this work, we study "Is it possible to reduce the indexing memory of hybrid retrievers without sacrificing performance"? Driven by this question, we leverage an indexing-efficient dense retriever (i.e. DrBoost) and introduce a LITE retriever that further reduces the memory of DrBoost. LITE is jointly trained on contrastive learning and knowledge distillation from DrBoost. Then, we integrate BM25, a sparse retriever, with either LITE or DrBoost to form light hybrid retrievers. Our Hybrid-LITE retriever saves 13X memory while maintaining 98.0% performance of the hybrid retriever of BM25 and DPR. In addition, we study the generalization capacity of our light hybrid retrievers on out-of-domain dataset and a set of adversarial attacks datasets. Experiments showcase that light hybrid retrievers achieve better generalization performance than individ
    
[^170]: Zemi: 从多任务中学习零样本半参数语言模型

    Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks. (arXiv:2210.00185v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.00185](http://arxiv.org/abs/2210.00185)

    Zemi是一种零样本半参数语言模型，使用外部检索器增强语言模型，可以在广泛的未见过的任务上展示出强大的零样本性能，比参数模型表现更好。

    

    虽然大型语言模型已经取得了令人印象深刻的零样本能力，但巨大的模型大小通常会产生高成本。最近，半参数语言模型使用外部检索器增强较小的语言模型，展示了有前途的语言建模能力。然而，这样的半参数语言模型能否在零样本推广到下游任务时像全参数模型一样表现竞争力仍然不清楚。在这项工作中，我们介绍了Zemi，一种零样本半参数语言模型。据我们所知，这是第一个能够在广泛的未见过的任务上展示出强大零样本性能的半参数语言模型。我们使用新颖的半参数多任务提示训练范式来训练Zemi，与T0提出的参数多任务训练相比，显示出显著的改进。具体来说，我们增强了多任务训练和零样本评估

    Although large language models have achieved impressive zero-shot ability, the huge model size generally incurs high cost. Recently, semi-parametric language models, which augment a smaller language model with an external retriever, have demonstrated promising language modeling capabilities. However, it remains unclear whether such semi-parametric language models can perform competitively well as their fully-parametric counterparts on zero-shot generalization to downstream tasks. In this work, we introduce $\text{Zemi}$, a zero-shot semi-parametric language model. To our best knowledge, this is the first semi-parametric language model that can demonstrate strong zero-shot performance on a wide range of held-out unseen tasks. We train $\text{Zemi}$ with a novel semi-parametric multitask prompted training paradigm, which shows significant improvement compared with the parametric multitask training as proposed by T0. Specifically, we augment the multitask training and zero-shot evaluation
    
[^171]: 用于高效对话建模的状态记忆增强变压器

    Stateful Memory-Augmented Transformers for Efficient Dialogue Modeling. (arXiv:2209.07634v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.07634](http://arxiv.org/abs/2209.07634)

    本文提出了一种记忆增强变压器，它可以高效地保存对话历史信息，并且在对话生成任务中表现出卓越的性能。

    

    变压器编码器-解码器模型在对话生成任务中取得了很好的性能，然而它们无法处理长对话历史，常常导致上下文被截断。为了解决这个问题，我们提出了一种新颖的记忆增强变压器，与现有的预训练编码器-解码器模型兼容，可以有效地保存对话历史信息。通过将一个单独的记忆模块与预训练变压器相结合，这个模型可以有效地交换记忆状态和当前输入上下文之间的信息。我们在三个对话数据集和两个语言建模数据集上评估了我们的模型。实验结果表明，与其他预训练Transformer基线相比，我们的方法在效率和性能方面都具有优越性。

    Transformer encoder-decoder models have achieved great performance in dialogue generation tasks, however, their inability to process long dialogue history often leads to truncation of the context To address this problem, we propose a novel memory-augmented transformer that is compatible with existing pre-trained encoder-decoder models and enables efficient preservation of the dialogue history information. By incorporating a separate memory module alongside the pre-trained transformer, the model can effectively interchange information between the memory states and the current input context. We evaluate our model on three dialogue datasets and two language modeling datasets. Experimental results show that our method has achieved superior efficiency and performance compared to other pre-trained Transformer baselines.
    
[^172]: CombLM: 通过小型微调模型调整黑盒语言模型

    CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models. (arXiv:2205.12213v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12213](http://arxiv.org/abs/2205.12213)

    本论文提出了一种 CombLM 方法，通过小型微调模型调整大型黑盒语言模型以适应新领域和任务，且不需要访问它们的权重或中间激活。实验证明在多个领域和下游任务中，性能得到提高。

    

    传统上，将语言模型适应新任务和域的方法通常假设对模型有白盒访问，并通过修改其参数进行操作。但这与该领域的最高质量模型仅通过推理API作为黑盒可用的最近趋势不兼容。即使可用模型权重，对大型语言模型进行微调的计算成本也可能对大多数研究人员来说是禁止的。在本研究中，我们提出了一种轻量级的方法，用于调整大型语言模型以适应新领域和任务，假设没有访问它们的权重或中间激活的权限。我们的方法通过在小验证集上学习的小型网络，在概率级别上微调小型白盒LM，并将其与大型黑盒LM结合起来。我们通过将大型LM（OPT-30B）适应多个领域和下游任务（机器翻译），在所有情况下观察到性能的提高，最高可达9\%，同时使用领域专家23倍。

    Methods for adapting language models (LMs) to new tasks and domains have traditionally assumed white-box access to the model, and work by modifying its parameters. However, this is incompatible with a recent trend in the field, where the highest quality models are only available as black-boxes through inference APIs. Even when the model weights are available, the computational cost of fine-tuning large LMs can be prohibitive for most practitioners. In this work, we present a lightweight method for adapting large LMs to new domains and tasks, assuming no access to their weights or intermediate activations. Our approach fine-tunes a small white-box LM and combines it with the large black-box LM at the probability level through a small network, learned on a small validation set. We validate our approach by adapting a large LM (OPT-30B) to several domains and a downstream task (machine translation), observing improved performance in all cases, of up to 9\%, while using a domain expert 23x 
    
[^173]: 高度重叠文本的情境化语义距离

    Contextualized Semantic Distance between Highly Overlapped Texts. (arXiv:2110.01176v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.01176](http://arxiv.org/abs/2110.01176)

    本文旨在解决自然语言处理任务中，覆盖文本之间语义距离评估的传统挑战。通过掩码和预测策略，本文提出了邻近分布散度（NDD）来表示重叠部分的语义距离。实验结果表明，NDD对于各种语义差异更为敏感。

    

    在文本编辑和语义相似性评估等自然语言处理任务中，文本之间经常会出现重叠。更好地评估重叠句子之间的语义距离有助于语言系统的理解并指导生成。由于传统的语义度量基于单词表示，它们容易受到具有类似表示的重叠部分的干扰。本文旨在通过掩码和预测策略解决这个问题。我们将最长公共序列（LCS）中的单词作为邻近单词，并使用来自预训练语言模型（PLMs）的掩码语言建模（MLM）来预测其位置上的分布。我们的度量指标，即邻近分布散度（NDD），通过计算重叠部分中分布之间的差异来表示语义距离。在语义文本相似性测试中，实验证明NDD对于各种语义差异更为敏感，

    Overlapping frequently occurs in paired texts in natural language processing tasks like text editing and semantic similarity evaluation. Better evaluation of the semantic distance between the overlapped sentences benefits the language system's understanding and guides the generation. Since conventional semantic metrics are based on word representations, they are vulnerable to the disturbance of overlapped components with similar representations. This paper aims to address the issue with a mask-and-predict strategy. We take the words in the longest common sequence (LCS) as neighboring words and use masked language modeling (MLM) from pre-trained language models (PLMs) to predict the distributions on their positions. Our metric, Neighboring Distribution Divergence (NDD), represent the semantic distance by calculating the divergence between distributions in the overlapped parts. Experiments on Semantic Textual Similarity show NDD to be more sensitive to various semantic differences, espec
    

