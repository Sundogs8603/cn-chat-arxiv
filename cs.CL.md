# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Leveraging Print Debugging to Improve Code Generation in Large Language Models.](http://arxiv.org/abs/2401.05319) | 通过利用打印调试方法，我们提出了一种上下文学习方法来改进大型语言模型(LLMs)在复杂编程问题中的代码生成能力。实验证明我们的方法比橡皮鸭调试在Leetcode的简单和中等级别问题上分别提高了1.5%和17.9%。 |
| [^2] | [ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video.](http://arxiv.org/abs/2401.05314) | ANIM-400K是一个大规模的数据集，支持自动化视频配音和其他与视频相关的任务。它解决了语言差异和数据稀缺的问题，为研究人员提供了丰富的资源。 |
| [^3] | [I am a Strange Dataset: Metalinguistic Tests for Language Models.](http://arxiv.org/abs/2401.05300) | 本研究提出了一个新的数据集，名为“我是一个奇怪的数据集”，用来测试大型语言模型（LLMs）是否能够处理元语言自指的陈述。实验证明，各种开源和闭源LLMs在生成和验证任务中的表现都接近随机猜测。 |
| [^4] | [INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges.](http://arxiv.org/abs/2401.05273) | 本文介绍了INACIA系统，这是一个将大型语言模型整合到巴西审计法院中的系统，可以自动化案件分析的各个阶段，并展示了其在从案件文件中提取信息、评估合法性和生成司法建议方面的潜力。 |
| [^5] | [AUTOACT: Automatic Agent Learning from Scratch via Self-Planning.](http://arxiv.org/abs/2401.05268) | AUTOACT是一个自动代理学习框架，通过自主规划合成轨迹，不依赖于大规模数据和闭源模型，能够实现更好或类似的性能。 |
| [^6] | [Language-based Valence and Arousal Expressions between the United States and China: a Cross-Cultural Examination.](http://arxiv.org/abs/2401.05254) | 本文从跨文化的角度研究了美国和中国社交媒体上的情感表达之间的差异。研究发现，与美国Twitter用户相比，中国新浪微博用户在情感强度的变化和激动程度上有更明显的差异。 |
| [^7] | [CASA: Causality-driven Argument Sufficiency Assessment.](http://arxiv.org/abs/2401.05249) | CASA是一个因果驱动的论证充分性评估框架，利用大型语言模型生成与前提和结论不一致的上下文，并通过注入前提事件对其进行修改，能够准确识别不足的论证。 |
| [^8] | [Do Vision and Language Encoders Represent the World Similarly?.](http://arxiv.org/abs/2401.05224) | 通过分析视觉和语言模型的潜在空间结构，发现未对齐和对齐的编码器的表示空间在语义上是相似的。我们提出了两种方法来匹配未对齐编码器，无需训练即可实现匹配。 |
| [^9] | [Pre-trained Large Language Models for Financial Sentiment Analysis.](http://arxiv.org/abs/2401.05215) | 本文提出了一种使用预训练大型语言模型进行金融情绪分析的方法，通过领域特定的适应和监督微调技术，即使在有限的训练样本下，也能显著提升分类性能。 |
| [^10] | [A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts into a Verbalizer.](http://arxiv.org/abs/2401.05204) | 本文提出了一种新颖的提示调整方法，通过将情景特定概念纳入到话语生成器中，提高了标签词空间的覆盖度和减小了偏见。 |
| [^11] | [Monte Carlo Tree Search for Recipe Generation using GPT-2.](http://arxiv.org/abs/2401.05199) | 本研究提出了一种利用GPT-2和蒙特卡洛树搜索的方法来生成食谱，通过定义奖励函数对文本生成进行限制，提高了生成食谱的可信度。 |
| [^12] | [Divide and Conquer for Large Language Models Reasoning.](http://arxiv.org/abs/2401.05190) | 分治求解方法应用于大型语言模型的推理中，通过根据统计置信度分数将问题划分为不同的子集，并采用基于先验知识和筛选选项的推理方法，提高了推理性能，取得了优异结果。 |
| [^13] | [Can ChatGPT Rival Neural Machine Translation? A Comparative Study.](http://arxiv.org/abs/2401.05176) | 本文比较了对话式语言模型ChatGPT和神经机器翻译引擎在将中文外交文本翻译为英文方面的能力，发现自动评价指标和人工评估方法之间存在差异。 |
| [^14] | [Yes, this is what I was looking for! Towards Multi-modal Medical Consultation Concern Summary Generation.](http://arxiv.org/abs/2401.05134) | 本文提出了一个新的任务：多模态医疗关注摘要生成，通过结合患者的非语言线索和个人信息，生成简短精确的咨询关注摘要。 |
| [^15] | [BELHD: Improving Biomedical Entity Linking with Homonoym Disambiguation.](http://arxiv.org/abs/2401.05125) | BELHD是一种改进生物医学实体链接的新方法，通过引入同音异义词消歧来处理同音异义词对知识库中实体链接的影响，提升了性能。 |
| [^16] | [Noise-robust zero-shot text-to-speech synthesis conditioned on self-supervised speech-representation model with adapters.](http://arxiv.org/abs/2401.05111) | 本论文提出了一种基于自监督学习的抗噪零样本文本到语音合成方法。通过在自监督学习模型中引入适配器，并使用带有噪声参考语音对TTS模型进行微调，以及采用语音增强前端，我们实现了高质量的语音合成，对参考语音中的噪声具有高度鲁棒性。 |
| [^17] | [Hierarchical Classification of Transversal Skills in Job Ads Based on Sentence Embeddings.](http://arxiv.org/abs/2401.05073) | 本论文提出了一个基于深度学习模型的分类框架，用于识别职位广告要求和横向技能集之间的相关性，并预测个别工作描述所需的技能。通过使用层次分类和多标签策略，并采用增强技术解决数据不平衡问题，该方法在欧洲就业市场具有良好的效果。 |
| [^18] | [Aligning Translation-Specific Understanding to General Understanding in Large Language Models.](http://arxiv.org/abs/2401.05072) | 这项研究旨在解决大型语言模型在机器翻译中的性能限制问题，通过提出一种跨语言解释困难词的新方法来对齐翻译特定理解和一般理解。 |
| [^19] | [MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot Detector.](http://arxiv.org/abs/2401.05060) | MuTox是第一个高度多语言的基于音频的毒性数据集，通过训练基于音频的毒性分类器，实现了跨多语言的零样本毒性检测，相较于现有基于文本的分类器，具有更好的性能和更广泛的语言覆盖，相较于基于词汇列表的分类器，精度和召回率提高了约2.5倍。 |
| [^20] | [Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding.](http://arxiv.org/abs/2401.05054) | 本研究提出了基于最小贝叶斯风险解码的多样性生成算法，通过在解码过程中加入多样性目标，能够生成高质量且多样化的文本输出。 |
| [^21] | [Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk.](http://arxiv.org/abs/2401.05033) | 本论文提出了一种通过LLM的自我对话收集数据的方法，用于指导基于LLM的任务导向对话代理。通过引入自我对话度量来衡量对话的成功，我们可以选择质量较高的样本进行训练和优化。 |
| [^22] | [Whose wife is it anyway? Assessing bias against same-gender relationships in machine translation.](http://arxiv.org/abs/2401.04972) | 本文研究了机器翻译系统对同性关系的偏见问题，发现三个受欢迎的MT服务在准确翻译涉及同性别名词之间关系的句子时存在较大的错误率，特别是在涉及女性职业的上下文中表现更差。这项工作为评估NLP系统中固有偏见提供了一个社会关系方面的案例研究。 |
| [^23] | [Can AI Write Classical Chinese Poetry like Humans? An Empirical Study Inspired by Turing Test.](http://arxiv.org/abs/2401.04952) | 本文通过一项受图灵测试启发的实证研究质疑了人类创造力无法被机器模仿的观点，发现最近的大型语言模型（LLMs）能够以几乎与人类无法区分的方式写作古典中文诗歌，并揭示了开源的LLMs在这一任务上的表现超越了GPT-4。 |
| [^24] | [Learning Audio Concepts from Counterfactual Natural Language.](http://arxiv.org/abs/2401.04935) | 本研究通过引入因果推理和反事实分析，提出了一种能够从自由文本中学习音频概念的方法。通过使用反事实实例，并综合考虑声学特征和声音来源信息，该方法在不同情景下能够有效识别声音事件和来源。 |
| [^25] | [The Impact of Reasoning Step Length on Large Language Models.](http://arxiv.org/abs/2401.04925) | 本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。 |
| [^26] | [ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain.](http://arxiv.org/abs/2401.04898) | ANGO是一个中文领域生成型语言模型评估基准，引入了关键点分类标准，提供了更好的可解释性，同时建立了可量化的问题难度标准，对模型训练提供了更精确的指导。 |
| [^27] | [Multi-User Chat Assistant (MUCA): a Framework Using LLMs to Facilitate Group Conversations.](http://arxiv.org/abs/2401.04883) | 这篇论文介绍了一种基于大规模语言模型的多用户聊天机器人框架（MUCA），该框架支持群组讨论，并提供了三个主要模块来确定回应内容、时机和适当的接收者。同时，作者还提出了一个基于语言模型的多用户模拟器（MUS），用于模拟真实用户行为，以便更高效地测试和优化聊天机器人。 |
| [^28] | [Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing.](http://arxiv.org/abs/2401.04881) | 本文提出了一种新的等待参与机制，通过在查询内存中检索带有驱逐查询的键值存储器（K/V存储器），使用逐出策略来减少内存大小并适应各种架构。 |
| [^29] | [Real-time and Continuous Turn-taking Prediction Using Voice Activity Projection.](http://arxiv.org/abs/2401.04868) | 本文介绍了一个实时且连续的语音活动预测系统，该系统利用语音活动投影模型将对话的音频映射到未来的语音活动，具有较低的性能损失。 |
| [^30] | [An Analysis of User Behaviours for Objectively Evaluating Spoken Dialogue Systems.](http://arxiv.org/abs/2401.04867) | 本文研究了用户行为与主观评估在口语对话系统中的关系，提出了一种间接但客观评估系统的框架，并发现在不同类型的对话任务中，不同的用户行为指标对评估起到重要作用。 |
| [^31] | [User Embedding Model for Personalized Language Prompting.](http://arxiv.org/abs/2401.04858) | 本研究提出了一种新的用户嵌入模块，可以更有效地处理长时间的用户历史记录，并在推荐系统中取得了显著的改进。 |
| [^32] | [Are Language Models More Like Libraries or Like Librarians? Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs.](http://arxiv.org/abs/2401.04854) | 本文探讨了语言模型（LLMs）是更像图书馆还是图书管理员的问题。论文首先阐述了 "文献主义 "这一概念，并提出了对其的挑战，指出LLMs生成的全新文本在内容上依赖于原始人类文本的内容。然后，论文提出了对 "文献主义"的新颖挑战，讨论了LLMs生成的 "新引用"问题。最后，根据心灵哲学中的解释主义，论文提出了有限代理能力的LLMs可能存在的可能性。 |
| [^33] | [Entity Recognition from Colloquial Text.](http://arxiv.org/abs/2401.04853) | 本论文研究了从非正式文本中进行实体识别的问题，特别关注医疗保健领域中从口语文本中识别症状的问题。通过设计和评估多个训练策略，使用BERT-based模型的微调，本研究找到了在非正式数据上表现较好的模型。 |
| [^34] | [Arabic Text Diacritization In The Age Of Transfer Learning: Token Classification Is All You Need.](http://arxiv.org/abs/2401.04848) | 本文介绍了一种新的两阶段方法PTCAD，用于阿拉伯文本音标化任务。通过将阿拉伯文本音标化视为标记分类任务，利用预训练模型取得了优于现有基准数据集和GPT-4的最新结果。 |
| [^35] | [MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer.](http://arxiv.org/abs/2401.04821) | MoSECroT是一个结合静态词向量的模型拼接框架，用于跨语言零样例迁移。它利用相对表示构建了源语言预训练语言模型和目标语言静态词向量的共享空间，从而实现了通过简单交换嵌入从源语言训练数据中进行训练，并在目标语言上进行零样例迁移。 |
| [^36] | [Translate-Distill: Learning Cross-Language Dense Retrieval by Translation and Distillation.](http://arxiv.org/abs/2401.04810) | Translate-Distill 提出了一种使用翻译和蒸馏的方法来训练跨语言稠密检索模型，克服了在不同语言的情况下训练数据不足的挑战，相比现有方法有更高的效率和效果。 |
| [^37] | [RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation.](http://arxiv.org/abs/2401.04679) | RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。 |
| [^38] | [Agent Alignment in Evolving Social Norms.](http://arxiv.org/abs/2401.04620) | 本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。 |
| [^39] | [Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark.](http://arxiv.org/abs/2401.03991) | 本研究通过改进StepGame基准，提供了更准确的数据集用于评估语言模型在空间推理方面的能力。研究发现，当前的大型语言模型在将自然语言文本映射到空间关系方面表现优秀，但在多跳推理方面存在限制。 |
| [^40] | [Grimoire is All You Need for Enhancing Large Language Models.](http://arxiv.org/abs/2401.03385) | Grimoire提出了一种名为SLEICL的方法，通过从示例中学习并将学到的技能传递给弱语言模型，增强了ICL能力。实验证明，这种方法可以使弱语言模型获得与强语言模型相当的ICL能力。 |
| [^41] | [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach.](http://arxiv.org/abs/2401.02987) | 本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。 |
| [^42] | [Cheetah: Natural Language Generation for 517 African Languages.](http://arxiv.org/abs/2401.01053) | Cheetah是一个面向517种非洲语言的大规模多语种自然语言生成模型，通过综合评估和人工评估，证明了其在生成连贯和上下文恰当的文本方面的卓越性能，并提供了促进语言多样性的解决方案。 |
| [^43] | [Large Language Models as Zero-Shot Keyphrase Extractors: A Preliminary Empirical Study.](http://arxiv.org/abs/2312.15156) | 该论文探讨了使用大型语言模型ChatGPT作为零-shot关键词提取器的可行性。实验证明，在关键词提取任务中，ChatGPT相对于现有的无监督和有监督模型仍有许多改进空间。 |
| [^44] | [HyperPIE: Hyperparameter Information Extraction from Scientific Publications.](http://arxiv.org/abs/2312.10638) | 本文提出了 HyperPIE 方法，用于从科学论文中提取超参数信息。通过训练和评估多种模型，包括BERT微调模型和五个大型语言模型，我们实现了关系提取和结构化数据提取，并取得了显著的性能改进。 |
| [^45] | [KwaiAgents: Generalized Information-seeking Agent System with Large Language Models.](http://arxiv.org/abs/2312.04889) | 本文介绍了 KwaiAgents，这是一个基于大型语言模型的通用信息搜索智能体系统。该系统能够利用语言模型作为认知核心，理解用户的查询，行为准则并参考外部文档，以提供高质量的知识和信息。 |
| [^46] | [Custom Data Augmentation for low resource ASR using Bark and Retrieval-Based Voice Conversion.](http://arxiv.org/abs/2311.14836) | 本文提出两种创新的方法来应对低资源语言ASR的挑战：一种是利用Bark模型和Meta的enCodec和预训练HuBert模型，一种是采用基于检索的语音转换(RVC)和Ozen工具包。这些方法为ASR技术的发展做出了贡献，并为构建定制化Common Voice数据集提供了宝贵的见解。 |
| [^47] | [A density estimation perspective on learning from pairwise human preferences.](http://arxiv.org/abs/2311.14115) | 研究提出了一个从密度估计的角度解释学习成对人类偏好的方法，并证明通过这种方法训练奖励函数可以有效地模拟注释者的隐含偏好分布。 |
| [^48] | [Pre-training LLMs using human-like development data corpus.](http://arxiv.org/abs/2311.04666) | 本论文使用类似人类发展数据语料库对LLMs进行预训练，通过与儿童观看的令牌数量相似的方式，评估了LLMs学习上下文词表示的能力。同时提供强大的基准和对任务组织者提供的RoBERTa基准的复制尝试。 |
| [^49] | [Improving Automatic VQA Evaluation Using Large Language Models.](http://arxiv.org/abs/2310.02567) | 提出使用大型语言模型改进自动视觉问答（VQA）评估的方法，将VQA评估格式化为回答评分任务，通过指令调整大型语言模型在准确度上评分候选答案，证明该方法与人类判断相关性优于现有度量方法。 |
| [^50] | [Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome.](http://arxiv.org/abs/2309.10744) | 该研究使用一个评分测试来评估大型语言模型（LLMs）理解人类微妙交流的能力。研究结果发现，随着模型参数数量的增加，LLMs对隐喻理解能力有所改善，但对讽刺理解能力的改进并未观察到。 |
| [^51] | [Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season.](http://arxiv.org/abs/2308.05281) | 该研究通过社交媒体数据和SIR模型研究了2020年西部美国火灾季的灾害响应。研究发现Twitter用户主要关注健康影响、损失和撤离三个主题，并使用SIR理论探索了这些主题在Twitter上的传播规模和速度。 |
| [^52] | [LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack.](http://arxiv.org/abs/2308.00319) | 本文提出了一种名为LimeAttack的硬标签攻击算法，通过本地可解释方法来近似单词重要性排序，然后利用波束搜索找到最优解。 |
| [^53] | [Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking.](http://arxiv.org/abs/2306.12245) | BEER^2是一种用于Retriever和Reader的双向端到端训练框架，通过检索器和阅读器之间的相互学习，共同进步，实现端到端EL。 |
| [^54] | [Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering.](http://arxiv.org/abs/2306.09996) | 本文探索使用不同提示策略，重点关注 BLIP2 模型，来提高零样本 VQA 的性能，研究了不同问题模板的有效性、少量样本示例的作用、思维链推理的影响以及将图像标题作为额外视觉线索融合的好处。精心设计的问题模板和整合额外视觉线索可以促进 VQA 性能的提高，特别是当它们结合使用时。 |
| [^55] | [BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks.](http://arxiv.org/abs/2305.17100) | BiomedGPT是一种面向视觉、语言和多模态任务的通用生物医学生成预训练Transformer，在多个临床任务中取得了16个最新的最优结果，包括超过了OpenAI的GPT-4V和Google的Med-PaLM M（12B）。同时，BiomedGPT还支持零-shot迁移学习。 |
| [^56] | [LaMP: When Large Language Models Meet Personalization.](http://arxiv.org/abs/2304.11406) | 本论文强调了当前自然语言处理领域中个性化的重要性，并提出了LaMP（一种用于训练和评估大型语言模型的新的个性化基准），并针对大型语言模型的生成任务，设计了七项个性化任务以及一种检索增强方法，结果表明在利用用户配置文件扩展大型语言模型的基础上，其生成结果明显优于传统方法。 |
| [^57] | [Personalized Dialogue Generation with Persona-Adaptive Attention.](http://arxiv.org/abs/2210.15088) | 本文提出了一种新的框架，使用个性自适应注意力（PAA）来生成基于个性的一致性回应，可以通过整合个性和上下文信息的权重来实现。实验证明 PAA 框架具有优越性能，可以在低资源环境下表现出色。 |
| [^58] | [BenchCLAMP: A Benchmark for Evaluating Language Models on Syntactic and Semantic Parsing.](http://arxiv.org/abs/2206.10668) | BenchCLAMP是一个用于评估语言模型在句法和语义解析上的基准测试。它包括七个语义解析数据集和两个句法解析数据集，提供了不同数据策略下的资源划分，并支持基于提示的学习和精调评估。实验证明，编码器-解码器预训练语言模型可以达到类似或超过现有最先进技术的性能水平。 |

# 详细

[^1]: 利用打印调试提高大型语言模型中的代码生成能力

    Leveraging Print Debugging to Improve Code Generation in Large Language Models. (arXiv:2401.05319v1 [cs.CL])

    [http://arxiv.org/abs/2401.05319](http://arxiv.org/abs/2401.05319)

    通过利用打印调试方法，我们提出了一种上下文学习方法来改进大型语言模型(LLMs)在复杂编程问题中的代码生成能力。实验证明我们的方法比橡皮鸭调试在Leetcode的简单和中等级别问题上分别提高了1.5%和17.9%。

    

    大型语言模型(LLMs)在代码生成任务中取得了显著进展，但在处理具有复杂数据结构和算法的编程问题时性能仍不理想。为了解决这个问题，我们提出了一种上下文学习方法，通过使用"打印调试"方法来引导LLMs进行调试，该方法涉及插入打印语句以跟踪和分析日志来修复错误。我们收集了Leetcode问题数据集，并使用Leetcode在线判题系统评估了我们的方法。使用GPT-4进行的实验证明了我们方法的有效性，在Leetcode的简单和中等级别问题上优于橡皮鸭调试分别达到1.5%和17.9%。

    Large language models (LLMs) have made significant progress in code generation tasks, but their performance in tackling programming problems with complex data structures and algorithms remains suboptimal. To address this issue, we propose an in-context learning approach that guides LLMs to debug by using a "print debugging" method, which involves inserting print statements to trace and analysing logs for fixing the bug. We collect a Leetcode problem dataset and evaluate our method using the Leetcode online judging system. Experiments with GPT-4 demonstrate the effectiveness of our approach, outperforming rubber duck debugging in easy and medium-level Leetcode problems by 1.5% and 17.9%.
    
[^2]: ANIM-400K: 用于自动化视频配音的大规模数据集

    ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video. (arXiv:2401.05314v1 [eess.AS])

    [http://arxiv.org/abs/2401.05314](http://arxiv.org/abs/2401.05314)

    ANIM-400K是一个大规模的数据集，支持自动化视频配音和其他与视频相关的任务。它解决了语言差异和数据稀缺的问题，为研究人员提供了丰富的资源。

    

    互联网上丰富的内容中，高达60％是用英语发布的，这与全球人口形成鲜明对比，全球只有18.8％是英语使用者，且只有5.1％将其视为母语，导致在线信息获取存在差异。不幸的是，使用替代翻译字幕替换视频的音轨仍然是一项复杂而具有挑战性的任务，需要精确的时序、面部运动同步和韵律匹配。虽然端对端配音提供了一种解决方案，但数据稀缺继续阻碍着端对端和基于流水线的方法的进展。在这项工作中，我们介绍了Anim-400K，这是一个包含超过425K个日语和英语对齐的动画视频片段的全面数据集，支持各种与视频相关的任务，包括自动化配音、同时翻译、导向视频摘要和类型/主题/风格分类。我们的数据集已公开提供给研究人员使用。

    The Internet's wealth of content, with up to 60% published in English, starkly contrasts the global population, where only 18.8% are English speakers, and just 5.1% consider it their native language, leading to disparities in online information access. Unfortunately, automated processes for dubbing of video - replacing the audio track of a video with a translated alternative remains a complex and challenging task due to pipelines, necessitating precise timing, facial movement synchronization, and prosody matching. While end-to-end dubbing offers a solution, data scarcity continues to impede the progress of both end-to-end and pipeline-based methods. In this work, we introduce Anim-400K, a comprehensive dataset of over 425K aligned animated video segments in Japanese and English supporting various video-related tasks, including automated dubbing, simultaneous translation, guided video summarization, and genre/theme/style classification. Our dataset is made publicly available for resea
    
[^3]: 我是一个奇怪的数据集：用于语言模型的元语言测试

    I am a Strange Dataset: Metalinguistic Tests for Language Models. (arXiv:2401.05300v1 [cs.CL])

    [http://arxiv.org/abs/2401.05300](http://arxiv.org/abs/2401.05300)

    本研究提出了一个新的数据集，名为“我是一个奇怪的数据集”，用来测试大型语言模型（LLMs）是否能够处理元语言自指的陈述。实验证明，各种开源和闭源LLMs在生成和验证任务中的表现都接近随机猜测。

    

    在许多领域中，涉及元语言自指的陈述（“本论文有六个部分。”）是普遍存在的。大型语言模型（LLMs）能否处理这样的语言？在本文中，我们提出了一个新的数据集“我是一个奇怪的数据集”，用来解决这个问题。它包含两个子任务：生成和验证。在生成任务中，模型会继续类似于“这个句子中倒数第二个词是”的陈述（正确的继续应该是“是”）。在验证任务中，模型会判断类似于“这个句子中倒数第二个词是句子。”的陈述的真实性（是假的）。我们还提供了最小差异的非自指元语言示例，来补充主数据集，以测试模型是否能够处理元语言语言。数据集由专家手工制作，非专家标注员进行验证。我们测试了各种开源LLMs（从7B到70B的参数）以及通过API进行测试的闭源LLMs。所有模型在两个子任务上的表现都接近随机猜测。

    Statements involving metalinguistic self-reference ("This paper has six sections.") are prevalent in many domains. Can large language models (LLMs) handle such language? In this paper, we present "I am a Strange Dataset", a new dataset for addressing this question. There are two subtasks: generation and verification. In generation, models continue statements like "The penultimate word in this sentence is" (where a correct continuation is "is"). In verification, models judge the truth of statements like "The penultimate word in this sentence is sentence." (false). We also provide minimally different metalinguistic non-self-reference examples to complement the main dataset by probing for whether models can handle metalinguistic language at all. The dataset is hand-crafted by experts and validated by non-expert annotators. We test a variety of open-source LLMs (7B to 70B parameters) as well as closed-source LLMs through APIs. All models perform close to chance across both subtasks and eve
    
[^4]: INACIA：将大型语言模型整合到巴西审计法院中的机会和挑战

    INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges. (arXiv:2401.05273v1 [cs.CL])

    [http://arxiv.org/abs/2401.05273](http://arxiv.org/abs/2401.05273)

    本文介绍了INACIA系统，这是一个将大型语言模型整合到巴西审计法院中的系统，可以自动化案件分析的各个阶段，并展示了其在从案件文件中提取信息、评估合法性和生成司法建议方面的潜力。

    

    本文介绍了INACIA（基于人工智能的辅助指令系统），这是一个开创性的系统，旨在将大型语言模型（LLMs）整合到巴西联邦审计法院（TCU）的运营框架中。该系统自动化了案件分析的各个阶段，包括基本信息提取、可受理性审查、Periculum in mora和Fumus boni iuris分析以及建议生成。通过一系列实验，我们展示了INACIA从案件文件中提取相关信息、评估其合法性并生成司法建议的潜力。利用验证数据集和LLMs，我们的评估方法提供了一种创新的方法来评估系统性能，与人类判断高度相关。结果突显了INACIA处理复杂法律任务的能力，表明其适用于增加法律系统的效率和司法公正性。

    This paper introduces INACIA (Instru\c{c}\~ao Assistida com Intelig\^encia Artificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA's potential in extracting relevant information from case documents, evaluating its legal plausibility, and generating judicial recommendations. Utilizing a validation dataset alongside LLMs, our evaluation methodology presents an innovative approach to assessing system performance, correlating highly with human judgment. The results highlight INACIA's proficiency in handling complex legal tasks, indicating its suitability for augmenting efficiency and judicial fairness within legal systems. The pap
    
[^5]: AUTOACT：通过自主规划实现的自动代理学习

    AUTOACT: Automatic Agent Learning from Scratch via Self-Planning. (arXiv:2401.05268v1 [cs.CL])

    [http://arxiv.org/abs/2401.05268](http://arxiv.org/abs/2401.05268)

    AUTOACT是一个自动代理学习框架，通过自主规划合成轨迹，不依赖于大规模数据和闭源模型，能够实现更好或类似的性能。

    

    语言代理在各种复杂任务上取得了相当的性能。尽管在这个领域进行了不断的探索，但现有的语言代理系统仍然面临昂贵、不可重复的数据依赖问题，并且面临将单一模型应用于多个功能的挑战。为此，我们介绍了AutoAct，这是一个自动代理学习框架，不依赖于大规模带注释的数据和来自闭源模型（如GPT-4）的合成轨迹。给定有限的数据和工具库，AutoAct首先自动合成规划轨迹，不需要人类或强闭源模型的任何辅助。然后，AutoAct利用分工策略，根据目标任务信息和合成轨迹自动区分，产生一个子代理组来完成任务。我们进行了多种LLMs的广泛实验，结果显示AutoAct在性能上优于或与其相当。

    Language agents have achieved considerable performance on various complex tasks. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework that does not rely on large-scale annotated data and synthetic trajectories from closed-source models (e.g., GPT-4). Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models. Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task. We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to var
    
[^6]: 中美两国之间基于语言的情绪表达的价值和激动对比：一个跨文化的研究

    Language-based Valence and Arousal Expressions between the United States and China: a Cross-Cultural Examination. (arXiv:2401.05254v1 [cs.CY])

    [http://arxiv.org/abs/2401.05254](http://arxiv.org/abs/2401.05254)

    本文从跨文化的角度研究了美国和中国社交媒体上的情感表达之间的差异。研究发现，与美国Twitter用户相比，中国新浪微博用户在情感强度的变化和激动程度上有更明显的差异。

    

    尽管社交媒体上个体的情感表达已经得到了广泛研究，但研究主要集中在西方环境中。不同文化之间存在着引发情感表达的重要差异。本文研究了美国Twitter和中国新浪微博上的两个主要情感维度（价值和激动）之间的差异。我们研究了美国和中国个体之间的激动和价值之间的功能关系差异，并探讨了相关内容上的差异。此外，我们还对两个平台上的词语使用和话题进行了相关性分析，以解读它们之间的差异。我们观察到，对于Twitter用户来说，负面情绪和正面情绪之间的情感强度变化不太明显，而对于新浪微博用户来说，伴随着情感的上升，激动程度有更明显的升级。从语言特征中，我们发现情感表达方面的差异。

    Although affective expressions of individuals have been extensively studied using social media, research has primarily focused on the Western context. There are substantial differences among cultures that contribute to their affective expressions. This paper examines the differences between Twitter (X) in the United States and Sina Weibo posts in China on two primary dimensions of affect - valence and arousal. We study the difference in the functional relationship between arousal and valence (so-called V-shaped) among individuals in the US and China and explore the associated content differences. Furthermore, we correlate word usage and topics in both platforms to interpret their differences. We observe that for Twitter users, the variation in emotional intensity is less distinct between negative and positive emotions compared to Weibo users, and there is a sharper escalation in arousal corresponding with heightened emotions. From language features, we discover that affective expressio
    
[^7]: CASA: 因果驱动的论证充分性评估

    CASA: Causality-driven Argument Sufficiency Assessment. (arXiv:2401.05249v1 [cs.CL])

    [http://arxiv.org/abs/2401.05249](http://arxiv.org/abs/2401.05249)

    CASA是一个因果驱动的论证充分性评估框架，利用大型语言模型生成与前提和结论不一致的上下文，并通过注入前提事件对其进行修改，能够准确识别不足的论证。

    

    论证充分性评估任务旨在确定一个给定论证的前提是否支持其结论。为了解决这个任务，现有的方法通常会对人工注释的数据进行分类器训练。然而，标注数据是费力的，而且由于主观标准的不一致性，标注往往也不一致。受因果文献中的充分概率（PS）定义的启发，我们提出了CASA，一个零射因果驱动的论证充分性评估框架。PS衡量的是当前提事件和结论事件都不存在时，引入前提事件是否会导致结论的可能性。为了估计这个概率，我们提出使用大型语言模型（LLMs）生成与前提和结论不一致的上下文，并通过注入前提事件对它们进行修改。在两个逻辑谬误检测数据集上的实验证明，CASA能够准确识别不足的论证。我们进一步将CASA部署在写作辅助系统中。

    The argument sufficiency assessment task aims to determine if the premises of a given argument support its conclusion. To tackle this task, existing works often train a classifier on data annotated by humans. However, annotating data is laborious, and annotations are often inconsistent due to subjective criteria. Motivated by the probability of sufficiency (PS) definition in the causal literature, we propose CASA, a zero-shot causality-driven argument sufficiency assessment framework. PS measures how likely introducing the premise event would lead to the conclusion, when both the premise and conclusion events are absent. To estimate this probability, we propose to use large language models (LLMs) to generate contexts that are inconsistent with the premise and conclusion, and revise them by injecting the premise event. Experiments on two logical fallacy detection datasets demonstrate that CASA accurately identifies insufficient arguments. We further deploy CASA in a writing assistance a
    
[^8]: 视觉和语言编码器是否以相似方式表示世界？

    Do Vision and Language Encoders Represent the World Similarly?. (arXiv:2401.05224v1 [cs.CV])

    [http://arxiv.org/abs/2401.05224](http://arxiv.org/abs/2401.05224)

    通过分析视觉和语言模型的潜在空间结构，发现未对齐和对齐的编码器的表示空间在语义上是相似的。我们提出了两种方法来匹配未对齐编码器，无需训练即可实现匹配。

    

    已经成为视觉语言任务中事实上的模型的对齐的文本-图像编码器（如CLIP）已经取得了令人印象深刻的表现。此外，模态特定的编码器在各自领域中也取得了令人印象深刻的表现。这引出了一个核心问题：由于它们基本上表示同一个物理世界，单模态的视觉和语言编码器之间是否存在对齐？通过使用中心核对齐（CKA）分析图像-标题基准上视觉和语言模型的潜在空间结构，我们发现未对齐和对齐的编码器的表示空间在语义上是相似的。在像CLIP这样的对齐编码器中缺乏统计相似性的情况下，我们显示了可能存在无需任何训练的未对齐编码器的匹配。我们将这视为利用图之间的语义相似性的有种子图匹配问题，并提出了两种方法 - 快速二次分配问题优化和一种基于新颖的局部CKA度量的匹配/检索方法。

    Aligned text-image encoders such as CLIP have become the de facto model for vision-language tasks. Furthermore, modality-specific encoders achieve impressive performances in their respective domains. This raises a central question: does an alignment exist between uni-modal vision and language encoders since they fundamentally represent the same physical world? Analyzing the latent spaces structure of vision and language models on image-caption benchmarks using the Centered Kernel Alignment (CKA), we find that the representation spaces of unaligned and aligned encoders are semantically similar. In the absence of statistical similarity in aligned encoders like CLIP, we show that a possible matching of unaligned encoders exists without any training. We frame this as a seeded graph-matching problem exploiting the semantic similarity between graphs and propose two methods - a Fast Quadratic Assignment Problem optimization, and a novel localized CKA metric-based matching/retrieval. We demons
    
[^9]: 金融情绪分析的预训练大型语言模型

    Pre-trained Large Language Models for Financial Sentiment Analysis. (arXiv:2401.05215v1 [cs.CL])

    [http://arxiv.org/abs/2401.05215](http://arxiv.org/abs/2401.05215)

    本文提出了一种使用预训练大型语言模型进行金融情绪分析的方法，通过领域特定的适应和监督微调技术，即使在有限的训练样本下，也能显著提升分类性能。

    

    金融情绪分析是将金融文本内容分类为情绪类别（如积极、消极和中性）。本文关注金融新闻标题的分类，这是一个具有挑战性的任务，因为缺乏大量的训练样本。为了克服这个困难，我们提出了将预训练的大型语言模型（LLMs）[1, 2, 3] 进行领域特定任务的有效适应。LLMs是从大量的文本语料库中训练得到的，具有文本理解的优势，并且可以在需要很少训练样本的情况下进行有效适应。具体而言，我们采用了开源的Llama2-7B模型（2023年）和监督微调（SFT）技术[4]。实验评估结果表明，即使对于LLMs来说较小的7B模型，我们的方法在性能上显著优于先前的最先进算法。

    Financial sentiment analysis refers to classifying financial text contents into sentiment categories (e.g. positive, negative, and neutral). In this paper, we focus on the classification of financial news title, which is a challenging task due to a lack of large amount of training samples. To overcome this difficulty, we propose to adapt the pretrained large language models (LLMs) [1, 2, 3] to solve this problem. The LLMs, which are trained from huge amount of text corpora,have an advantage in text understanding and can be effectively adapted to domain-specific task while requiring very few amount of training samples. In particular, we adapt the open-source Llama2-7B model (2023) with the supervised fine-tuning (SFT) technique [4]. Experimental evaluation shows that even with the 7B model (which is relatively small for LLMs), our approach significantly outperforms the previous state-of-the-art algorithms.
    
[^10]: 一种新颖的提示调整方法：将情景特定概念纳入到话语生成器中

    A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts into a Verbalizer. (arXiv:2401.05204v1 [cs.CL])

    [http://arxiv.org/abs/2401.05204](http://arxiv.org/abs/2401.05204)

    本文提出了一种新颖的提示调整方法，通过将情景特定概念纳入到话语生成器中，提高了标签词空间的覆盖度和减小了偏见。

    

    话语生成器是提示调整的关键组件，用于将标签词映射到类别标签。本文提出了一种构建话语生成器的新方法。与现有方法主要依赖于对类别名称的同义词或相关词集进行增强和精炼不同，我们的方法通过从特定任务场景中提取丰富的概念作为标签词候选，并开发了一种新颖的级联校准模块来将候选词精炼为每个类别的一组标签词，从而解决了现有方法在标签词空间中覆盖度有限和偏见较高的问题。

    The verbalizer, which serves to map label words to class labels, is an essential component of prompt-tuning. In this paper, we present a novel approach to constructing verbalizers. While existing methods for verbalizer construction mainly rely on augmenting and refining sets of synonyms or related words based on class names, this paradigm suffers from a narrow perspective and lack of abstraction, resulting in limited coverage and high bias in the label-word space. To address this issue, we propose a label-word construction process that incorporates scenario-specific concepts. Specifically, we extract rich concepts from task-specific scenarios as label-word candidates and then develop a novel cascade calibration module to refine the candidates into a set of label words for each class. We evaluate the effectiveness of our proposed approach through extensive experiments on {five} widely used datasets for zero-shot text classification. The results demonstrate that our method outperforms ex
    
[^11]: 使用GPT-2的蒙特卡洛树搜索进行食谱生成

    Monte Carlo Tree Search for Recipe Generation using GPT-2. (arXiv:2401.05199v1 [cs.CL])

    [http://arxiv.org/abs/2401.05199](http://arxiv.org/abs/2401.05199)

    本研究提出了一种利用GPT-2和蒙特卡洛树搜索的方法来生成食谱，通过定义奖励函数对文本生成进行限制，提高了生成食谱的可信度。

    

    自动食谱生成方法为厨师提供了一种创造性工具，可以探索和创造新的有趣的烹饪美食。考虑到大型语言模型（LLMs）的最近成功，它们有潜力创造出可以满足个人偏好、膳食限制以及适应您冰箱内食材的新食谱。现有的通过LLMs生成食谱的研究表明，LLMs可以通过微调来生成听起来真实的食谱。然而，仔细检查后发现，这些生成的食谱往往无法满足基本要求，比如在鸡肉菜肴中包含鸡肉。在本文中，我们提出了一种名为RecipeMC的文本生成方法，它使用GPT-2并依赖于蒙特卡洛树搜索（MCTS）。RecipeMC允许我们定义奖励函数以对文本生成进行软限制，从而提高生成食谱的可信度。我们的结果表明，人类评估者更喜欢使用RecipeMC生成的食谱。

    Automatic food recipe generation methods provide a creative tool for chefs to explore and to create new, and interesting culinary delights. Given the recent success of large language models (LLMs), they have the potential to create new recipes that can meet individual preferences, dietary constraints, and adapt to what is in your refrigerator. Existing research on using LLMs to generate recipes has shown that LLMs can be finetuned to generate realistic-sounding recipes. However, on close examination, these generated recipes often fail to meet basic requirements like including chicken as an ingredient in chicken dishes. In this paper, we propose RecipeMC, a text generation method using GPT-2 that relies on Monte Carlo Tree Search (MCTS). RecipeMC allows us to define reward functions to put soft constraints on text generation and thus improve the credibility of the generated recipes. Our results show that human evaluators prefer recipes generated with RecipeMC more often than recipes gen
    
[^12]: 大型语言模型的分治求解方法在推理中的应用

    Divide and Conquer for Large Language Models Reasoning. (arXiv:2401.05190v1 [cs.CL])

    [http://arxiv.org/abs/2401.05190](http://arxiv.org/abs/2401.05190)

    分治求解方法应用于大型语言模型的推理中，通过根据统计置信度分数将问题划分为不同的子集，并采用基于先验知识和筛选选项的推理方法，提高了推理性能，取得了优异结果。

    

    随着Chain-of-Thought（CoT）及其衍生方法的出现，大型语言模型（LLMs）在各种推理基准测试中表现出令人印象深刻的性能，特别是在涉及多项选择题（MCQs）的任务中。然而，当前的工作都是统一处理数据，没有考虑到问题解决的难度，这意味着过分关注简单问题，而对复杂问题不够重视。为了应对这一挑战，我们受到人类使用启发式策略对任务进行分类并单独处理的启发，提议将分治方法应用于LLMs推理中。首先，我们根据统计置信度分数（$\mathcal{CS}$）将问题划分为不同的子集，然后固定解决的子集，用精心设计的方法解决复杂的纷繁问题，包括基于先验知识的推理（PKR）和基于筛选选项的推理（FCR），以及它们的集成变体。我们的实验表明，这种提出的分治求解方法可以显著提高推理性能，并在不同难度的问题上取得了优异结果。

    Large language models (LLMs) have shown impressive performance in various reasoning benchmarks with the emergence of Chain-of-Thought (CoT) and its derivative methods, particularly in tasks involving multi-choice questions (MCQs). However, current works all process data uniformly without considering the problem-solving difficulty, which means an excessive focus on simple questions while insufficient to intricate ones. To address this challenge, we inspired by humans using heuristic strategies to categorize tasks and handle them individually, propose to apply the Divide and Conquer to LLMs reasoning. First, we divide questions into different subsets based on the statistical confidence score ($\mathcal{CS}$), then fix nearly resolved sets and conquer demanding nuanced process ones with elaborately designed methods, including Prior Knowledge based Reasoning (PKR) and Filter Choices based Reasoning (FCR), as well as their integration variants. Our experiments demonstrate that this proposed
    
[^13]: 对话式语言模型ChatGPT与神经机器翻译在翻译中的竞争性研究

    Can ChatGPT Rival Neural Machine Translation? A Comparative Study. (arXiv:2401.05176v1 [cs.CL])

    [http://arxiv.org/abs/2401.05176](http://arxiv.org/abs/2401.05176)

    本文比较了对话式语言模型ChatGPT和神经机器翻译引擎在将中文外交文本翻译为英文方面的能力，发现自动评价指标和人工评估方法之间存在差异。

    

    在对越来越多地利用大型语言模型进行翻译的兴趣不断增加的背景下，本文评估了ChatGPT等大型语言模型（LLM）与主流神经机器翻译（NMT）引擎在将中文外交文本翻译为英文方面的能力。具体而言，我们通过四个自动评价指标和基于错误类型和六个分析细则的人工评估，考察了ChatGPT和NMT引擎的翻译质量。研究结果表明，自动评价指标对于ChatGPT在不同提示和NMT系统下的表现得出了类似的结果，而当ChatGPT提供示例或翻译任务的上下文信息时，人工评估者往往会给予明显较高的评分。自动评价指标与人工评估维度之间的两两相关性结果较弱且不显著，这表明了两种翻译质量评估方法之间的差异。

    Inspired by the increasing interest in leveraging large language models for translation, this paper evaluates the capabilities of large language models (LLMs) represented by ChatGPT in comparison to the mainstream neural machine translation (NMT) engines in translating Chinese diplomatic texts into English. Specifically, we examine the translation quality of ChatGPT and NMT engines as measured by four automated metrics and human evaluation based on an error-typology and six analytic rubrics. Our findings show that automated metrics yield similar results for ChatGPT under different prompts and NMT systems, while human annotators tend to assign noticeably higher scores to ChatGPT when it is provided an example or contextual information about the translation task. Pairwise correlation between automated metrics and dimensions of human evaluation produces weak and non-significant results, suggesting the divergence between the two methods of translation quality assessment. These findings pro
    
[^14]: 是的，这就是我想要的！向多模态医疗咨询关注摘要生成迈进

    Yes, this is what I was looking for! Towards Multi-modal Medical Consultation Concern Summary Generation. (arXiv:2401.05134v1 [cs.AI])

    [http://arxiv.org/abs/2401.05134](http://arxiv.org/abs/2401.05134)

    本文提出了一个新的任务：多模态医疗关注摘要生成，通过结合患者的非语言线索和个人信息，生成简短精确的咨询关注摘要。

    

    在过去几年中，互联网在医疗保健相关任务中的使用增长迅猛，有效管理和处理信息以确保其高效利用面临挑战。在情绪困扰和心理挑战时刻，我们经常转向互联网作为我们最初的支持源，选择它而不是与他人讨论我们的感受，因为这涉及社会的污名。在本文中，我们提出了一个新的多模态医疗关注摘要生成（MMCS）任务，它提供了关于患者在咨询过程中提出的主要关注的简短和精确摘要。非语言线索，例如患者的手势和面部表情，有助于准确识别患者的关注点。医生还考虑患者的个人信息，例如年龄和性别，以便适当地描述医疗状况。受患者个人上下文和视觉手势的潜在疗效的启发，我们提出了一个新的方法

    Over the past few years, the use of the Internet for healthcare-related tasks has grown by leaps and bounds, posing a challenge in effectively managing and processing information to ensure its efficient utilization. During moments of emotional turmoil and psychological challenges, we frequently turn to the internet as our initial source of support, choosing this over discussing our feelings with others due to the associated social stigma. In this paper, we propose a new task of multi-modal medical concern summary (MMCS) generation, which provides a short and precise summary of patients' major concerns brought up during the consultation. Nonverbal cues, such as patients' gestures and facial expressions, aid in accurately identifying patients' concerns. Doctors also consider patients' personal information, such as age and gender, in order to describe the medical condition appropriately. Motivated by the potential efficacy of patients' personal context and visual gestures, we propose a tr
    
[^15]: BELHD: 使用同音异义词消歧来改进生物医学实体链接

    BELHD: Improving Biomedical Entity Linking with Homonoym Disambiguation. (arXiv:2401.05125v1 [cs.CL])

    [http://arxiv.org/abs/2401.05125](http://arxiv.org/abs/2401.05125)

    BELHD是一种改进生物医学实体链接的新方法，通过引入同音异义词消歧来处理同音异义词对知识库中实体链接的影响，提升了性能。

    

    生物医学实体链接是将实体提及与知识库进行关联的任务。该任务的一种常见方法是基于名称的方法，即为给定的提及识别出知识库中最合适的名称，可以通过密集检索或自回归建模来实现。然而，由于这些方法直接返回知识库中的名称，它们无法处理同音异义词，即不同的知识库实体共享相同的名称。这对它们的性能产生了显著影响，特别是当同音异义词占实体提及的很大比例时（如UMLS和NCBI Gene）。因此，我们提出了BELHD（具有同音异义词消歧的生物医学实体链接），一种能应对这一挑战的新型基于名称的方法。具体而言，BELHD在BioSyn（Sung等人，2020）模型的基础上引入了两个关键扩展。首先，它对知识库进行预处理，在其中使用自动选择的消歧字符串来扩展同音异义词，从而强制进行唯一的链接决策。其次，...

    Biomedical entity linking (BEL) is the task of grounding entity mentions to a knowledge base (KB). A popular approach to the task are name-based methods, i.e. those identifying the most appropriate name in the KB for a given mention, either via dense retrieval or autoregressive modeling. However, as these methods directly return KB names, they cannot cope with homonyms, i.e. different KB entities sharing the exact same name. This significantly affects their performance, especially for KBs where homonyms account for a large amount of entity mentions (e.g. UMLS and NCBI Gene). We therefore present BELHD (Biomedical Entity Linking with Homonym Disambiguation), a new name-based method that copes with this challenge. Specifically, BELHD builds upon the BioSyn (Sung et al.,2020) model introducing two crucial extensions. First, it performs a preprocessing of the KB in which it expands homonyms with an automatically chosen disambiguating string, thus enforcing unique linking decisions. Second,
    
[^16]: 基于自监督语音表征模型的抗噪零样本文本到语音合成方法

    Noise-robust zero-shot text-to-speech synthesis conditioned on self-supervised speech-representation model with adapters. (arXiv:2401.05111v1 [cs.SD])

    [http://arxiv.org/abs/2401.05111](http://arxiv.org/abs/2401.05111)

    本论文提出了一种基于自监督学习的抗噪零样本文本到语音合成方法。通过在自监督学习模型中引入适配器，并使用带有噪声参考语音对TTS模型进行微调，以及采用语音增强前端，我们实现了高质量的语音合成，对参考语音中的噪声具有高度鲁棒性。

    

    基于自监督学习（SSL）语音表征提取的说话人嵌入向量的零样本文本到语音（TTS）方法可以非常准确地复制说话人的特征。然而，当参考语音中含有噪声时，该方法的语音合成质量会下降。本文提出了一种抗噪零样本TTS方法。我们将适配器引入到SSL模型中，并使用带有噪声参考语音的TTS模型进行微调。此外，为了进一步提高性能，我们采用了语音增强（SE）前端。通过这些改进，我们提出的基于SSL的零样本TTS在噪声参考语音下实现了高质量的语音合成。通过客观和主观评估，我们确认了该方法对参考语音中的噪声具有高度的鲁棒性，并且与SE结合有效地运作。

    The zero-shot text-to-speech (TTS) method, based on speaker embeddings extracted from reference speech using self-supervised learning (SSL) speech representations, can reproduce speaker characteristics very accurately. However, this approach suffers from degradation in speech synthesis quality when the reference speech contains noise. In this paper, we propose a noise-robust zero-shot TTS method. We incorporated adapters into the SSL model, which we fine-tuned with the TTS model using noisy reference speech. In addition, to further improve performance, we adopted a speech enhancement (SE) front-end. With these improvements, our proposed SSL-based zero-shot TTS achieved high-quality speech synthesis with noisy reference speech. Through the objective and subjective evaluations, we confirmed that the proposed method is highly robust to noise in reference speech, and effectively works in combination with SE.
    
[^17]: 基于句子嵌入的职位广告中横向技能的层次分类

    Hierarchical Classification of Transversal Skills in Job Ads Based on Sentence Embeddings. (arXiv:2401.05073v1 [cs.LG])

    [http://arxiv.org/abs/2401.05073](http://arxiv.org/abs/2401.05073)

    本论文提出了一个基于深度学习模型的分类框架，用于识别职位广告要求和横向技能集之间的相关性，并预测个别工作描述所需的技能。通过使用层次分类和多标签策略，并采用增强技术解决数据不平衡问题，该方法在欧洲就业市场具有良好的效果。

    

    本文提出了一个分类框架，旨在识别职位广告要求和横向技能集之间的相关性，重点是使用深度学习模型预测个别工作描述所需的技能。该方法涉及数据收集、预处理和使用ESCO（欧洲技能、能力和职业）分类系统进行标注。在技能识别方面，采用了层次分类和多标签策略，而增强技术则解决了数据不平衡问题，提高了模型的稳健性。通过比较使用英语特定和多语言句子嵌入模型得到的结果，发现其准确度相近。实验案例研究详细说明了神经网络配置、超参数和交叉验证结果，突显了层次化方法的功效以及多语言模型适用于多样化的欧洲就业市场。因此，提供了一种新的层次分类方法。

    This paper proposes a classification framework aimed at identifying correlations between job ad requirements and transversal skill sets, with a focus on predicting the necessary skills for individual job descriptions using a deep learning model. The approach involves data collection, preprocessing, and labeling using ESCO (European Skills, Competences, and Occupations) taxonomy. Hierarchical classification and multi-label strategies are used for skill identification, while augmentation techniques address data imbalance, enhancing model robustness. A comparison between results obtained with English-specific and multi-language sentence embedding models reveals close accuracy. The experimental case studies detail neural network configurations, hyperparameters, and cross-validation results, highlighting the efficacy of the hierarchical approach and the suitability of the multi-language model for the diverse European job market. Thus, a new approach is proposed for the hierarchical classifi
    
[^18]: 将大型语言模型中的翻译特定理解与一般理解对齐

    Aligning Translation-Specific Understanding to General Understanding in Large Language Models. (arXiv:2401.05072v1 [cs.CL])

    [http://arxiv.org/abs/2401.05072](http://arxiv.org/abs/2401.05072)

    这项研究旨在解决大型语言模型在机器翻译中的性能限制问题，通过提出一种跨语言解释困难词的新方法来对齐翻译特定理解和一般理解。

    

    虽然大型语言模型（LLMs）展现出了令人惊讶的语言理解和生成能力，但在机器翻译领域尚未取得突破性进展。造成性能有限的一个潜在原因是LLMs中翻译特定理解与一般理解的不一致。为了将翻译特定理解与一般理解对齐，我们提出了一种新颖的翻译过程xIoD（跨语言解释困难词），明确地融入一般理解对产生不一致的理解以指导翻译。具体而言，xIoD对难以翻译的单词进行跨语言解释，并通过生成的解释增强翻译。此外，我们重新构建了外部工具QE，以解决xIoD在检测困难词和生成有帮助的解释方面的挑战。我们在实验中进行了测试。

    Although large language models (LLMs) have shown surprising language understanding and generation capabilities, they have yet to gain a revolutionary advancement in the field of machine translation. One potential cause of the limited performance is the misalignment between the translation-specific understanding and general understanding inside LLMs. To align the translation-specific understanding to the general one, we propose a novel translation process xIoD (Cross-Lingual Interpretation of Difficult words), explicitly incorporating the general understanding on the content incurring inconsistent understanding to guide the translation. Specifically, xIoD performs the cross-lingual interpretation for the difficult-to-translate words and enhances the translation with the generated interpretations. Furthermore, we reframe the external tools of QE to tackle the challenges of xIoD in the detection of difficult words and the generation of helpful interpretations. We conduct experiments on th
    
[^19]: MuTox: 通用多语言基于音频的毒性数据集和零样本检测器

    MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot Detector. (arXiv:2401.05060v1 [cs.SD])

    [http://arxiv.org/abs/2401.05060](http://arxiv.org/abs/2401.05060)

    MuTox是第一个高度多语言的基于音频的毒性数据集，通过训练基于音频的毒性分类器，实现了跨多语言的零样本毒性检测，相较于现有基于文本的分类器，具有更好的性能和更广泛的语言覆盖，相较于基于词汇列表的分类器，精度和召回率提高了约2.5倍。

    

    语音模态（基于音频）自然语言处理中的毒性检测研究相对有限，特别是对于非英语语言而言。为了解决这些限制，并为真正多语言的基于音频的毒性检测奠定基础，我们引入了MuTox，这是第一个具有毒性标签的高度多语言的基于音频的数据集。该数据集包含20,000个英语和西班牙语音频片段，以及其他19种语言的4,000个片段。为了证明数据集的质量，我们训练了MuTox基于音频的毒性分类器，它能够在各种语言中进行零样本毒性检测。与现有的基于文本训练的分类器相比，该分类器的AUC性能提高了超过1%，同时扩大了语言覆盖范围十倍以上。与基于词汇列表的具有相似语言覆盖数量的分类器相比，MuTox的精度和召回率提高了约2.5倍。这个显著的改进突显了其潜在的创新性和贡献。

    Research in toxicity detection in natural language processing for the speech modality (audio-based) is quite limited, particularly for languages other than English. To address these limitations and lay the groundwork for truly multilingual audio-based toxicity detection, we introduce MuTox, the first highly multilingual audio-based dataset with toxicity labels. The dataset comprises 20,000 audio utterances for English and Spanish, and 4,000 for the other 19 languages. To demonstrate the quality of this dataset, we trained the MuTox audio-based toxicity classifier, which enables zero-shot toxicity detection across a wide range of languages. This classifier outperforms existing text-based trainable classifiers by more than 1% AUC, while expanding the language coverage more than tenfold. When compared to a wordlist-based classifier that covers a similar number of languages, MuTox improves precision and recall by approximately 2.5 times. This significant improvement underscores the potenti
    
[^20]: 通过最小贝叶斯风险解码生成多样性和高质量的文本

    Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding. (arXiv:2401.05054v1 [cs.CL])

    [http://arxiv.org/abs/2401.05054](http://arxiv.org/abs/2401.05054)

    本研究提出了基于最小贝叶斯风险解码的多样性生成算法，通过在解码过程中加入多样性目标，能够生成高质量且多样化的文本输出。

    

    文本生成系统中最重要的挑战之一是产生不仅正确而且多样化的输出。最近，最小贝叶斯风险（MBR）解码在生成算法中得到了广泛应用，可以产生最高质量的句子。然而，目前为生成多样化输出而提出的现有算法主要基于波束搜索或随机抽样，因此其输出质量受限于这些基本方法。在本文中，我们探索了一种替代方法--通过将多样性目标强加到MBR解码中来开发促进多样性的解码算法。我们提出了两种MBR的变体，即多样性MBR（DMBR）和k-medoids MBR（KMBR），用于生成一组高质量和多样性的句子。我们使用编码器-解码器模型和大型语言模型进行了各种定向文本生成任务的DMBR和KMBR评估。实验结果表明，所提出的方法实现了更好的传统

    One of the most important challenges in text generation systems is to produce outputs that are not only correct but also diverse. Recently, Minimum Bayes-Risk (MBR) decoding has gained prominence for generating sentences of the highest quality among the decoding algorithms. However, existing algorithms proposed for generating diverse outputs are predominantly based on beam search or random sampling, thus their output quality is capped by these underlying methods. In this paper, we investigate an alternative approach -- we develop diversity-promoting decoding algorithms by enforcing diversity objectives to MBR decoding. We propose two variants of MBR, Diverse MBR (DMBR) and $k$-medoids MBR (KMBR), methods to generate a set of sentences with high quality and diversity. We evaluate DMBR and KMBR on a variety of directed text generation tasks using encoder-decoder models and a large language model with prompting. The experimental results show that the proposed method achieves a better trad
    
[^21]: 通过自我对话引导基于LLM的任务导向对话代理的引导

    Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk. (arXiv:2401.05033v1 [cs.CL])

    [http://arxiv.org/abs/2401.05033](http://arxiv.org/abs/2401.05033)

    本论文提出了一种通过LLM的自我对话收集数据的方法，用于指导基于LLM的任务导向对话代理。通过引入自我对话度量来衡量对话的成功，我们可以选择质量较高的样本进行训练和优化。

    

    大型语言模型（LLM）是强大的对话代理，但特化它们以实现特定功能可能具有挑战性。指示调谐，即在人类生成的指令和示例响应上调谐模型（Ouyang等人，2022），已被证明是一种有效的方法，但需要一定数量的数据样本，这些样本可能不可用或生成成本高昂。此外，当目标是使LLM遵循对话中的特定工作流程而不仅仅是单个指令时，这种成本会增加。受到强化学习中自我博弈技术和使用LLM模拟人类代理的启发，我们提出了一种更有效的通过LLM扮演不同角色进行对话的数据收集方法。这种方法通过LLM的“自我对话”生成训练数据，可以进行精细调谐和利用。我们引入了一种自动化的方法来衡量对话的（部分）成功。该度量用于过滤基于LLM的自我对话生成的训练数据，以选择质量较高的样本进行进一步的训练和优化。

    Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do so, yet requires a number of data samples that a) might not be available or b) costly to generate. Furthermore, this cost increases when the goal is to make the LLM follow a specific workflow within a dialogue instead of single instructions. Inspired by the self-play technique in reinforcement learning and the use of LLMs to simulate human agents, we propose a more effective method for data collection through LLMs engaging in a conversation in various roles. This approach generates a training data via "self-talk" of LLMs that can be refined and utilized for supervised fine-tuning. We introduce an automated way to measure the (partial) success of a dialogue. This metric is used to filter the ge
    
[^22]: 机器翻译中的同性关系偏见评估：它究竟是谁的妻子？

    Whose wife is it anyway? Assessing bias against same-gender relationships in machine translation. (arXiv:2401.04972v1 [cs.CL])

    [http://arxiv.org/abs/2401.04972](http://arxiv.org/abs/2401.04972)

    本文研究了机器翻译系统对同性关系的偏见问题，发现三个受欢迎的MT服务在准确翻译涉及同性别名词之间关系的句子时存在较大的错误率，特别是在涉及女性职业的上下文中表现更差。这项工作为评估NLP系统中固有偏见提供了一个社会关系方面的案例研究。

    

    机器翻译经常受到有偏见的数据和算法的困扰，这可能导致系统输出中的不可接受的错误。虽然对性别规范的偏见进行了调查研究，但对MT系统是否对社会关系编码偏见的情况了解较少，例如“律师吻了她的妻子”这样的句子。我们通过使用从几种名词性别语言（例如西班牙语）中抽取的生成模板句子，调查MT系统针对同性关系的偏见程度。我们发现三个受欢迎的MT服务在准确翻译涉及同性别名词之间关系的句子时一直存在问题。错误率根据上下文而变化很大，例如引用女性占比较高职业的同性句子的翻译准确度较低。我们提供这项工作作为研究NLP系统中固有偏见的案例研究，涉及社会关系方面的偏见评估。

    Machine translation often suffers from biased data and algorithms that can lead to unacceptable errors in system output. While bias in gender norms has been investigated, less is known about whether MT systems encode bias about social relationships, e.g. sentences such as "the lawyer kissed her wife." We investigate the degree of bias against same-gender relationships in MT systems, using generated template sentences drawn from several noun-gender languages (e.g. Spanish). We find that three popular MT services consistently fail to accurately translate sentences concerning relationships between nouns of the same gender. The error rate varies considerably based on the context, e.g. same-gender sentences referencing high female-representation occupations are translated with lower accuracy. We provide this work as a case study in the evaluation of intrinsic bias in NLP systems, with respect to social relationships.
    
[^23]: 人工智能能像人类一样写古典诗吗？一项受图灵测试启发的实证研究

    Can AI Write Classical Chinese Poetry like Humans? An Empirical Study Inspired by Turing Test. (arXiv:2401.04952v1 [cs.CL])

    [http://arxiv.org/abs/2401.04952](http://arxiv.org/abs/2401.04952)

    本文通过一项受图灵测试启发的实证研究质疑了人类创造力无法被机器模仿的观点，发现最近的大型语言模型（LLMs）能够以几乎与人类无法区分的方式写作古典中文诗歌，并揭示了开源的LLMs在这一任务上的表现超越了GPT-4。

    

    有人认为，创造力和情感等人类的本质特质永远无法被机器模仿。本文通过研究一个重要问题，对这种信念提出了质疑：人工智能能否像人类一样创作诗歌？为了回答这个问题，我们提出了一种新的评估框架ProFTAP，该框架受到图灵测试的启发，用于评估人工智能的诗歌创作能力。我们将其应用于当前的大型语言模型（LLMs），发现最近的LLMs确实具备了几乎无法区分的与人类写作的古典中文诗歌的能力。我们还揭示了各种开源的LLMs在这一任务上可以超越GPT-4。

    Some argue that the essence of humanity, such as creativity and sentiment, can never be mimicked by machines. This paper casts doubt on this belief by studying a vital question: Can AI compose poetry as well as humans? To answer the question, we propose ProFTAP, a novel evaluation framework inspired by Turing test to assess AI's poetry writing capability. We apply it on current large language models (LLMs) and find that recent LLMs do indeed possess the ability to write classical Chinese poems nearly indistinguishable from those of humans. We also reveal that various open-source LLMs can outperform GPT-4 on this task.
    
[^24]: 从对抗性自然语言中学习音频概念

    Learning Audio Concepts from Counterfactual Natural Language. (arXiv:2401.04935v1 [cs.MM])

    [http://arxiv.org/abs/2401.04935](http://arxiv.org/abs/2401.04935)

    本研究通过引入因果推理和反事实分析，提出了一种能够从自由文本中学习音频概念的方法。通过使用反事实实例，并综合考虑声学特征和声音来源信息，该方法在不同情景下能够有效识别声音事件和来源。

    

    传统的音频分类依赖于预定义的类别，缺乏从自由文本中学习的能力。最近的方法可以从描述音频的原始音频文本对中解锁学习联合音频-文本嵌入。尽管最近取得了一些进展，但对于在不同情景下训练模型以识别声音事件和来源的系统方法的探索很少，例如在类似的情况下区分室外活动中的烟火和枪声。本研究引入了音频领域的因果推理和反事实分析。我们使用反事实实例，并将它们包含在我们的模型中的不同方面。我们的模型考虑了来自人工注释参考文本的声学特征和声音来源信息。为了验证我们模型的有效性，我们进行了使用多个音频字幕数据集进行的预训练。然后我们使用几个常见的下游任务进行评估，展示了该方法的优点。

    Conventional audio classification relied on predefined classes, lacking the ability to learn from free-form text. Recent methods unlock learning joint audio-text embeddings from raw audio-text pairs describing audio in natural language. Despite recent advancements, there is little exploration of systematic methods to train models for recognizing sound events and sources in alternative scenarios, such as distinguishing fireworks from gunshots at outdoor events in similar situations. This study introduces causal reasoning and counterfactual analysis in the audio domain. We use counterfactual instances and include them in our model across different aspects. Our model considers acoustic characteristics and sound source information from human-annotated reference texts. To validate the effectiveness of our model, we conducted pre-training utilizing multiple audio captioning datasets. We then evaluate with several common downstream tasks, demonstrating the merits of the proposed method as one
    
[^25]: 推理步长对大型语言模型的影响

    The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v1 [cs.CL])

    [http://arxiv.org/abs/2401.04925](http://arxiv.org/abs/2401.04925)

    本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。

    

    思维链条（CoT）对于提高大型语言模型（LLM）的推理能力具有重要作用。然而，CoT的有效性与提示中推理步骤的长度之间的关系仍然不为人所知。为了揭示这一点，我们进行了几个实证实验来探索这些关系。具体而言，我们设计了一些实验，扩展和压缩CoT演示中的合理推理步骤，同时保持其他因素不变。我们得出了以下主要发现。首先，结果表明，在提示中延长推理步骤，即使没有向提示中添加新信息，也会显著提高LLM在多个数据集上的推理能力。相反，缩短推理步骤，即使保留关键信息，也会显著降低模型的推理能力。这一发现突显了CoT提示中步骤数量的重要性，并提供了实际指导。

    Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have the following key findings. First, the results indicate that lengthening the reasoning steps in prompts, even without adding new information into the prompt, considerably enhances LLMs' reasoning abilities across multiple datasets. Alternatively, shortening the reasoning steps, even while preserving the key information, significantly diminishes the reasoning abilities of models. This finding highlights the importance of the number of steps in CoT prompts and provides practical guidance to make 
    
[^26]: ANGO: 一个面向生成型语言模型的中文领域评估基准

    ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain. (arXiv:2401.04898v1 [cs.CL])

    [http://arxiv.org/abs/2401.04898](http://arxiv.org/abs/2401.04898)

    ANGO是一个中文领域生成型语言模型评估基准，引入了关键点分类标准，提供了更好的可解释性，同时建立了可量化的问题难度标准，对模型训练提供了更精确的指导。

    

    最近，出现了各种大规模语言模型（LLMs）评估数据集，但其中大多数存在排名失真和模型能力分析困难的问题。针对这些问题，本文引入了ANGO，一个中文多项选择题评估基准。ANGO首次提出了“关键点”分类标准，ANGO中的每个问题可以对应多个关键点，有效提高了评估结果的可解释性。基于真人表现的性能，我们建立了可量化的问题难度标准，并将ANGO问题分为9个难度级别，为模型训练提供了更精确的指导。为了最小化数据泄漏的影响并充分利用ANGO的创新特点，我们设计了独家抽样策略和新的评估框架，支持快速测试集迭代。我们的实验证明，ANGO对模型提出了更大的挑战，并在评估结果中揭示出更多细节。

    Recently, various Large Language Models (LLMs) evaluation datasets have emerged, but most of them have issues with distorted rankings and difficulty in model capabilities analysis. Addressing these concerns, this paper introduces ANGO, a Chinese multi-choice question evaluation benchmark. ANGO proposes \textit{Keypoint} categorization standard for the first time, each question in ANGO can correspond to multiple keypoints, effectively enhancing interpretability of evaluation results. Base on performance of real humans, we build a quantifiable question difficulty standard and divide ANGO questions into 9 difficulty levels, which provide more precise guidance for model training. To minimize data leakage impact and fully leverage ANGO's innovative features, we have engineered exclusive sampling strategies and a new evaluation framework that support swift testset iteration. Our experiments demonstrate that ANGO poses a stronger challenge to models and reveals more details in evaluation resu
    
[^27]: 多用户聊天助手（MUCA）：一种使用LLMs框架促进群体对话的方法

    Multi-User Chat Assistant (MUCA): a Framework Using LLMs to Facilitate Group Conversations. (arXiv:2401.04883v1 [cs.CL])

    [http://arxiv.org/abs/2401.04883](http://arxiv.org/abs/2401.04883)

    这篇论文介绍了一种基于大规模语言模型的多用户聊天机器人框架（MUCA），该框架支持群组讨论，并提供了三个主要模块来确定回应内容、时机和适当的接收者。同时，作者还提出了一个基于语言模型的多用户模拟器（MUS），用于模拟真实用户行为，以便更高效地测试和优化聊天机器人。

    

    最近大规模语言模型（LLMs）的进展为聊天机器人的发展提供了新的途径，而大部分现有研究主要集中在单用户的聊天机器人上，重点放在用户输入后决定“回答什么”。在本文中，我们发现多用户聊天机器人有更复杂的3W设计维度——如何回答，“何时”回应，“回答谁”。此外，我们提出了一个名为Multi-User Chat Assistant (MUCA)的基于LLM的聊天机器人框架，专门用于群组讨论。MUCA由三个主要模块组成：子主题生成器，对话分析器和话语策略仲裁器。这些模块共同确定合适的回应内容、时机和适当的接收者。为了使MUCA的优化过程更容易，我们进一步提出了一个基于LLM的多用户模拟器（MUS），可以模拟真实用户行为。这使得聊天机器人和模拟用户之间的对话进行更快速的模拟，从而使得早期测试和优化过程更高效。

    Recent advancements in large language models (LLMs) have provided a new avenue for chatbot development, while most existing research has primarily centered on single-user chatbots that focus on deciding "What" to answer after user inputs. In this paper, we identified that multi-user chatbots have more complex 3W design dimensions -- "What" to say, "When" to respond, and "Who" to answer. Additionally, we proposed Multi-User Chat Assistant (MUCA), which is an LLM-based framework for chatbots specifically designed for group discussions. MUCA consists of three main modules: Sub-topic Generator, Dialog Analyzer, and Utterance Strategies Arbitrator. These modules jointly determine suitable response contents, timings, and the appropriate recipients. To make the optimizing process for MUCA easier, we further propose an LLM-based Multi-User Simulator (MUS) that can mimic real user behavior. This enables faster simulation of a conversation between the chatbot and simulated users, making the earl
    
[^28]: Attendre: 用反驱逐查询在基于记忆的变压器中等待参与长上下文处理

    Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing. (arXiv:2401.04881v1 [cs.CL])

    [http://arxiv.org/abs/2401.04881](http://arxiv.org/abs/2401.04881)

    本文提出了一种新的等待参与机制，通过在查询内存中检索带有驱逐查询的键值存储器（K/V存储器），使用逐出策略来减少内存大小并适应各种架构。

    

    随着LLMs能够处理更复杂类型的输入，研究人员最近研究了如何高效且经济地处理可能任意长的序列。一种有效的方法是使用FIFO内存来存储过去块的注意子层的键和值，以允许后续查询参与。然而，这种方法需要大量内存和/或考虑特定的LM架构。此外，由于先前上下文中的键-值与当前查询之间的因果关系，这种方法无法扩展到具有双向注意力的架构，例如编码器-解码器或PrefixLM仅解码器架构。在本文中，我们提出使用逐出策略，例如LRA和LFA，来减少内存大小并适应各种架构，我们还提出了Attendre层，一种通过在查询内存中检索带有驱逐查询的键值存储器（K/V存储器）的等待参与机制。

    As LLMs have become capable of processing more complex types of inputs, researchers have recently studied how to efficiently and affordably process possibly arbitrarily long sequences. One effective approach is to use a FIFO memory to store keys and values of an attention sublayer from past chunks to allow subsequent queries to attend. However, this approach requires a large memory and/or takes into the consideration the specific LM architecture. Moreover, due to the causal nature between the key-values in prior context and the queries at present, this approach cannot be extended to bidirectional attention such as in an encoder-decoder or PrefixLM decoder-only architecture. In this paper, we propose to use eviction policies, such as LRA and LFA, to reduce the memory size and adapt to various architectures, and we also propose the Attendre layer, a wait-to-attend mechanism by retrieving the key-value memory (K/V memory) with evicted queries in the query memory (Q memory). As a first ste
    
[^29]: 实时且连续的语音活动预测系统的实现

    Real-time and Continuous Turn-taking Prediction Using Voice Activity Projection. (arXiv:2401.04868v1 [cs.CL])

    [http://arxiv.org/abs/2401.04868](http://arxiv.org/abs/2401.04868)

    本文介绍了一个实时且连续的语音活动预测系统，该系统利用语音活动投影模型将对话的音频映射到未来的语音活动，具有较低的性能损失。

    

    本文介绍了一个实时且连续的语音活动预测系统的演示。该系统基于语音活动投影(VAP)模型，直接将对话的立体声音频映射到未来的语音活动。VAP模型包括对比性预测编码(CPC)和自注意力转换器，接着是交叉注意力转换器。我们研究了输入上下文音频长度的影响，并证明了该系统可以在CPU设置下实时运行，性能损失最小。

    A demonstration of a real-time and continuous turn-taking prediction system is presented. The system is based on a voice activity projection (VAP) model, which directly maps dialogue stereo audio to future voice activities. The VAP model includes contrastive predictive coding (CPC) and self-attention transformers, followed by a cross-attention transformer. We examine the effect of the input context audio length and demonstrate that the proposed system can operate in real-time with CPU settings, with minimal performance degradation.
    
[^30]: 对用户行为进行分析以客观评估口语对话系统

    An Analysis of User Behaviours for Objectively Evaluating Spoken Dialogue Systems. (arXiv:2401.04867v1 [cs.CL])

    [http://arxiv.org/abs/2401.04867](http://arxiv.org/abs/2401.04867)

    本文研究了用户行为与主观评估在口语对话系统中的关系，提出了一种间接但客观评估系统的框架，并发现在不同类型的对话任务中，不同的用户行为指标对评估起到重要作用。

    

    建立口语对话系统的评估方案很重要，但也具有挑战性。虽然主观评估在用户实验中常用，但客观评估对于研究比较和可复制性是必要的。为解决这个问题，我们提出了一个框架，通过用户行为间接但客观地评估系统。为此，我们调查了社交对话任务中用户行为与主观评估分数之间的关系：专注倾听、面试和首次会议对话。结果显示，在用户话语是主要因素的对话任务中，如专注倾听和面试，话语数量和单词数量等指标在评估中起到重要作用。观察语调不流畅等也可以指示正式任务的有效性，例如面试。另一方面，在高互动性的对话任务中，如首次会议对话，用户情绪和参与程度更重要。

    Establishing evaluation schemes for spoken dialogue systems is important, but it can also be challenging. While subjective evaluations are commonly used in user experiments, objective evaluations are necessary for research comparison and reproducibility. To address this issue, we propose a framework for indirectly but objectively evaluating systems based on users' behaviours. In this paper, to this end, we investigate the relationship between user behaviours and subjective evaluation scores in social dialogue tasks: attentive listening, job interview, and first-meeting conversation. The results reveal that in dialogue tasks where user utterances are primary, such as attentive listening and job interview, indicators like the number of utterances and words play a significant role in evaluation. Observing disfluency also can indicate the effectiveness of formal tasks, such as job interview. On the other hand, in dialogue tasks with high interactivity, such as first-meeting conversation, b
    
[^31]: 个性化语言提示的用户嵌入模型

    User Embedding Model for Personalized Language Prompting. (arXiv:2401.04858v1 [cs.CL])

    [http://arxiv.org/abs/2401.04858](http://arxiv.org/abs/2401.04858)

    本研究提出了一种新的用户嵌入模块，可以更有效地处理长时间的用户历史记录，并在推荐系统中取得了显著的改进。

    

    对于提升推荐系统的模型，建模长时间的历史记录起到了关键作用，能够捕捉用户不断演变的偏好，从而得到更准确和个性化的推荐。本研究致力于解决自然语言偏好理解中建模长用户历史记录的挑战。具体地，我们引入了一种新的用户嵌入模块(UEM)，通过将用户历史记录以嵌入形式压缩和表示，将其作为对语言模型的软提示。我们的实验表明，与传统的基于文本的提示方法相比，这种方法在处理显著更长的历史记录方面具有卓越的能力，并在预测性能方面取得了实质性的改进。该研究的主要贡献在于展示了使用表示为嵌入的用户信号来偏置语言模型的能力。

    Modeling long histories plays a pivotal role in enhancing recommendation systems, allowing to capture user's evolving preferences, resulting in more precise and personalized recommendations. In this study we tackle the challenges of modeling long user histories for preference understanding in natural language. Specifically, we introduce a new User Embedding Module (UEM) that efficiently processes user history in free-form text by compressing and representing them as embeddings, to use them as soft prompts to a LM. Our experiments demonstrate the superior capability of this approach in handling significantly longer histories compared to conventional text based prompting methods, yielding substantial improvements in predictive performance. The main contribution of this research is to demonstrate the ability to bias language models with user signals represented as embeddings.
    
[^32]: 语言模型是更像图书馆还是图书管理员？Bibliotechnism，小说引用问题和LLM的态度。

    Are Language Models More Like Libraries or Like Librarians? Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs. (arXiv:2401.04854v1 [cs.CL])

    [http://arxiv.org/abs/2401.04854](http://arxiv.org/abs/2401.04854)

    本文探讨了语言模型（LLMs）是更像图书馆还是图书管理员的问题。论文首先阐述了 "文献主义 "这一概念，并提出了对其的挑战，指出LLMs生成的全新文本在内容上依赖于原始人类文本的内容。然后，论文提出了对 "文献主义"的新颖挑战，讨论了LLMs生成的 "新引用"问题。最后，根据心灵哲学中的解释主义，论文提出了有限代理能力的LLMs可能存在的可能性。

    

    LLMs（语言模型）是否像复印机或印刷机等文化技术一样，传输信息但无法创建新内容？我们将这个概念称为"文献主义"，它面临一个挑战，即LLMs经常生成全新的文本。我们首先为"文献主义"对抗这个挑战进行辩护，展示了新的文本仅在派生意义上具有意义，因此这些生成的文本的内容在重要意义上依赖于原始人类文本的内容。然后，我们提出了一个不同的、新颖的挑战，即LLMs生成"新引用"的例子，使用新的名称来引用新实体。如果LLMs不是文化技术而是具有有限形式的代理能力（信念、欲望和意图），这样的例子可以很好地解释。根据心灵哲学中的解释主义，仅当一个系统的行为可以通过假设它具有信念、欲望和意图来很好地解释时，它才具有这样的信念、欲望和意图。

    Are LLMs cultural technologies like photocopiers or printing presses, which transmit information but cannot create new content? A challenge for this idea, which we call bibliotechnism, is that LLMs often do generate entirely novel text. We begin by defending bibliotechnism against this challenge, showing how novel text may be meaningful only in a derivative sense, so that the content of this generated text depends in an important sense on the content of original human text. We go on to present a different, novel challenge for bibliotechnism, stemming from examples in which LLMs generate "novel reference", using novel names to refer to novel entities. Such examples could be smoothly explained if LLMs were not cultural technologies but possessed a limited form of agency (beliefs, desires, and intentions). According to interpretationism in the philosophy of mind, a system has beliefs, desires and intentions if and only if its behavior is well-explained by the hypothesis that it has such s
    
[^33]: 从口语文本中进行实体识别

    Entity Recognition from Colloquial Text. (arXiv:2401.04853v1 [cs.CL])

    [http://arxiv.org/abs/2401.04853](http://arxiv.org/abs/2401.04853)

    本论文研究了从非正式文本中进行实体识别的问题，特别关注医疗保健领域中从口语文本中识别症状的问题。通过设计和评估多个训练策略，使用BERT-based模型的微调，本研究找到了在非正式数据上表现较好的模型。

    

    从非正式文本（如社交媒体帖子和非正式交流）中提取概念和感兴趣的实体是决策支持系统在许多领域（包括医疗保健、客户关系管理等）中的重要能力。尽管近年来在训练大型语言模型以解决各种自然语言处理任务方面取得了进展，但这些模型和技术主要集中在正式文本上，在非正式数据上的表现较差，而非正式数据具有一些独特的挑战。在我们的研究中，我们关注医疗保健领域，并通过设计和评估BERT-based模型微调的几种训练策略，研究了从口语文本中识别症状的问题。这些策略通过选择基础模型、训练语料库以及在训练数据中应用术语扰动来区分。使用这些策略训练的最佳模型胜过了当前最先进的模型。

    Extraction of concepts and entities of interest from non-formal texts such as social media posts and informal communication is an important capability for decision support systems in many domains, including healthcare, customer relationship management, and others. Despite the recent advances in training large language models for a variety of natural language processing tasks, the developed models and techniques have mainly focused on formal texts and do not perform as well on colloquial data, which is characterized by a number of distinct challenges. In our research, we focus on the healthcare domain and investigate the problem of symptom recognition from colloquial texts by designing and evaluating several training strategies for BERT-based model fine-tuning. These strategies are distinguished by the choice of the base model, the training corpora, and application of term perturbations in the training data. The best-performing models trained using these strategies outperform the state-
    
[^34]: 在迁移学习时代的阿拉伯文本音标化：仅需标记分类

    Arabic Text Diacritization In The Age Of Transfer Learning: Token Classification Is All You Need. (arXiv:2401.04848v1 [cs.CL])

    [http://arxiv.org/abs/2401.04848](http://arxiv.org/abs/2401.04848)

    本文介绍了一种新的两阶段方法PTCAD，用于阿拉伯文本音标化任务。通过将阿拉伯文本音标化视为标记分类任务，利用预训练模型取得了优于现有基准数据集和GPT-4的最新结果。

    

    阿拉伯文本的自动音标化涉及向文本中添加音标符号。这一任务对于计算处理和理解具有重要意义。本文介绍了PTCAD（用于阿拉伯文本音标化的预先微调标记分类方法），这是一种针对阿拉伯文本音标化任务的全新两阶段方法。PTCAD包括预先微调阶段和微调阶段，将阿拉伯文本音标化视为针对预训练模型的标记分类任务。通过对来自Tashkeela数据集的两个基准数据集的评估，证明了PTCAD的有效性，在现有基准数据集上将词错误率（WER）减少了20％，并在ATD任务中表现优于GPT-4。

    Automatic diacritization of Arabic text involves adding diacritical marks (diacritics) to the text. This task poses a significant challenge with noteworthy implications for computational processing and comprehension. In this paper, we introduce PTCAD (Pre-FineTuned Token Classification for Arabic Diacritization, a novel two-phase approach for the Arabic Text Diacritization task. PTCAD comprises a pre-finetuning phase and a finetuning phase, treating Arabic Text Diacritization as a token classification task for pre-trained models. The effectiveness of PTCAD is demonstrated through evaluations on two benchmark datasets derived from the Tashkeela dataset, where it achieves state-of-the-art results, including a 20\% reduction in Word Error Rate (WER) compared to existing benchmarks and superior performance over GPT-4 in ATD tasks.
    
[^35]: MoSECroT: 使用静态词向量进行模型拼接实现跨语言零样例迁移

    MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer. (arXiv:2401.04821v1 [cs.CL])

    [http://arxiv.org/abs/2401.04821](http://arxiv.org/abs/2401.04821)

    MoSECroT是一个结合静态词向量的模型拼接框架，用于跨语言零样例迁移。它利用相对表示构建了源语言预训练语言模型和目标语言静态词向量的共享空间，从而实现了通过简单交换嵌入从源语言训练数据中进行训练，并在目标语言上进行零样例迁移。

    

    基于Transformer的预训练语言模型（PLMs）在各种自然语言处理（NLP）任务中取得了显著的性能。然而，这种模型的预训练需要大量资源，而这些资源几乎只有高资源语言才能获得。相反，静态词向量的训练更容易，可以更节省计算资源和数据量。本文介绍了MoSECroT（Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer）模型拼接与静态词向量结合的新颖且具有挑战性的任务，特别适用于存在静态词向量的低资源语言。为了解决这个任务，我们提出了第一个利用相对表示构建源语言PLM嵌入和目标语言静态词向量之间的共享空间的框架。通过这种方式，我们可以使用源语言训练数据训练PLM，并通过简单地交换嵌入完成从源语言到目标语言的零样例迁移。

    Transformer-based pre-trained language models (PLMs) have achieved remarkable performance in various natural language processing (NLP) tasks. However, pre-training such models can take considerable resources that are almost only available to high-resource languages. On the contrary, static word embeddings are easier to train in terms of computing resources and the amount of data required. In this paper, we introduce MoSECroT Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer), a novel and challenging task that is especially relevant to low-resource languages for which static word embeddings are available. To tackle the task, we present the first framework that leverages relative representations to construct a common space for the embeddings of a source language PLM and the static word embeddings of a target language. In this way, we can train the PLM on source-language training data and perform zero-shot transfer to the target language by simply swapping th
    
[^36]: Translate-Distill: 通过翻译和蒸馏学习跨语言稠密检索

    Translate-Distill: Learning Cross-Language Dense Retrieval by Translation and Distillation. (arXiv:2401.04810v1 [cs.IR])

    [http://arxiv.org/abs/2401.04810](http://arxiv.org/abs/2401.04810)

    Translate-Distill 提出了一种使用翻译和蒸馏的方法来训练跨语言稠密检索模型，克服了在不同语言的情况下训练数据不足的挑战，相比现有方法有更高的效率和效果。

    

    先前关于英语单语检索的研究表明，使用大量查询-文档相关性判断训练的交互编码器可以用作教师模型来训练更高效但同样有效的双编码器学生模型。然而，在不同语言的查询和文档之间进行跨语言信息检索 (CLIR) 时应用类似的知识蒸馏方法是具有挑战性的，因为查询和文档语言不同时缺乏足够大的训练集合。现有的 CLIR 技术依赖于从庞大的英语 MS MARCO 训练集中翻译查询、文档或两者的方法，称为 Translate-Train。本文提出了一种替代方案 Translate-Distill，其中从单语交互编码器或 CLIR 交互编码器进行知识蒸馏，训练双编码器 CLIR 学生模型。这种更丰富的设计空间使得教师模型能够...

    Prior work on English monolingual retrieval has shown that a cross-encoder trained using a large number of relevance judgments for query-document pairs can be used as a teacher to train more efficient, but similarly effective, dual-encoder student models. Applying a similar knowledge distillation approach to training an efficient dual-encoder model for Cross-Language Information Retrieval (CLIR), where queries and documents are in different languages, is challenging due to the lack of a sufficiently large training collection when the query and document languages differ. The state of the art for CLIR thus relies on translating queries, documents, or both from the large English MS MARCO training set, an approach called Translate-Train. This paper proposes an alternative, Translate-Distill, in which knowledge distillation from either a monolingual cross-encoder or a CLIR cross-encoder is used to train a dual-encoder CLIR student model. This richer design space enables the teacher model to
    
[^37]: RoSA: 通过鲁棒适应实现准确的参数高效微调

    RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v1 [cs.CL])

    [http://arxiv.org/abs/2401.04679](http://arxiv.org/abs/2401.04679)

    RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。

    

    我们研究了在大语言模型 (LLMs) 的背景下，能够在有限的计算和内存预算下提供良好准确性的参数高效微调 (PEFT) 方法。我们提出了一种新的PEFT方法，称为RoSA，受鲁棒主成分分析 (PCA) 的启发，它在一组固定的预训练权重上共同训练$\textit{低秩}$和$\textit{高度稀疏}$的组件，以高效近似完全微调（FFT）解决方案的性能。我们展示了RoSA在一系列具有挑战性的生成任务上的性能，例如小学数学和SQL查询生成，这些任务需要进行微调以获得良好性能，我们证明了在相同的参数预算下，RoSA优于LoRA和纯粹的稀疏微调。我们通过稀疏GPU内核为RoSA提供系统支持，以补充训练算法，从而实现内存和计算效率的训练。我们的代码将在https://github.com/IST-DASLab上提供。

    We investigate parameter-efficient fine-tuning (PEFT) methods that can provide good accuracy under limited computational and memory budgets in the context of large language models (LLMs). We present a new PEFT method called Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA) that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ components on top of a set of fixed pretrained weights to efficiently approximate the performance of a full-fine-tuning (FFT) solution. Across a series of challenging generative tasks such as grade-school math and SQL query generation, which require fine-tuning for good performance, we show that RoSA outperforms both LoRA and pure sparse fine-tuning, at the same parameter budget. We provide system support for RoSA to complement the training algorithm, specifically in the form of sparse GPU kernels which enable memoryand computationally-efficient training. Our code will be made available at https://github.com/IST-DASLab
    
[^38]: 在不断演化的社会规范中的Agent对齐

    Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v1 [cs.CL])

    [http://arxiv.org/abs/2401.04620](http://arxiv.org/abs/2401.04620)

    本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。

    

    基于大型语言模型（LLM）的Agent越来越多地渗透到人类生产和生活的各个领域，凸显了将其与人类价值观对齐的重要性。目前AI系统的对齐主要集中在通过人为干预对LLM进行被动对齐。然而，Agent具有接受环境反馈和自我进化等特性，使得LLM对齐方法变得不足够。为此，我们提出了一个名为EvolutionaryAgent的Agent进化和对齐的进化框架，将Agent对齐转化为适者生存的演化和选择过程。在社会规范不断演化的环境中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率，而对齐不足的Agent则逐渐减少。通过多个角度对与社会规范相对齐的Agent进行的实验结果进行评估。

    Agents based on Large Language Models (LLMs) are increasingly permeating various domains of human production and life, highlighting the importance of aligning them with human values. The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate. In response, we propose an evolutionary framework for agent evolution and alignment, named EvolutionaryAgent, which transforms agent alignment into a process of evolution and selection under the principle of survival of the fittest. In an environment where social norms continuously evolve, agents better adapted to the current social norms will have a higher probability of survival and proliferation, while those inadequately aligned dwindle over time. Experimental results assessing the agents from multiple perspectives in aligning with social norms demonstr
    
[^39]: 提升大型语言模型中的空间推理能力：通过StepGame基准的深入评估和增强

    Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark. (arXiv:2401.03991v1 [cs.AI] CROSS LISTED)

    [http://arxiv.org/abs/2401.03991](http://arxiv.org/abs/2401.03991)

    本研究通过改进StepGame基准，提供了更准确的数据集用于评估语言模型在空间推理方面的能力。研究发现，当前的大型语言模型在将自然语言文本映射到空间关系方面表现优秀，但在多跳推理方面存在限制。

    

    人工智能在各个领域取得了显著进展，例如ChatGPT等大型语言模型因其类似人类的文本生成能力而受到了广泛关注。然而，这些模型在空间推理方面仍然存在一定挑战。StepGame等基准评估了人工智能的空间推理能力，ChatGPT在其中表现出了不尽人意的性能。然而，基准中存在的模板错误对评估结果有影响。因此，如果解决了这些模板错误，ChatGPT有潜力表现更好，从而获得对其空间推理能力更准确的评估。在本研究中，我们完善了StepGame基准，提供了更准确的数据集用于模型评估。我们分析了GPT在经过修正的基准上的空间推理性能，在将自然语言文本映射到空间关系方面表现优秀，但在多跳推理方面存在限制。我们提供了一个无缺陷的解决方案

    Artificial intelligence (AI) has made remarkable progress across various domains, with large language models like ChatGPT gaining substantial attention for their human-like text-generation capabilities. Despite these achievements, spatial reasoning remains a significant challenge for these models. Benchmarks like StepGame evaluate AI spatial reasoning, where ChatGPT has shown unsatisfactory performance. However, the presence of template errors in the benchmark has an impact on the evaluation results. Thus there is potential for ChatGPT to perform better if these template errors are addressed, leading to more accurate assessments of its spatial reasoning capabilities. In this study, we refine the StepGame benchmark, providing a more accurate dataset for model evaluation. We analyze GPT's spatial reasoning performance on the rectified benchmark, identifying proficiency in mapping natural language text to spatial relations but limitations in multi-hop reasoning. We provide a flawless solu
    
[^40]: Grimoire是增强大型语言模型所需的一切

    Grimoire is All You Need for Enhancing Large Language Models. (arXiv:2401.03385v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.03385](http://arxiv.org/abs/2401.03385)

    Grimoire提出了一种名为SLEICL的方法，通过从示例中学习并将学到的技能传递给弱语言模型，增强了ICL能力。实验证明，这种方法可以使弱语言模型获得与强语言模型相当的ICL能力。

    

    在上下文学习（ICL）是通过提供一组少样例来增强大型语言模型在特定任务上表现的关键方法之一。然而，不同类型的模型的ICL能力存在显著差异，由于模型架构、学习数据的量和参数的大小等因素。一般来说，模型的参数大小越大，学习数据越广泛，其ICL能力越强。在本文中，我们提出了一种方法SLEICL，它涉及使用强语言模型从示例中学习，然后将这些学到的技能总结和传递给弱语言模型进行推理和应用。这确保了ICL的稳定性和效果。与直接使弱语言模型从提示示例中学习相比，SLEICL降低了这些模型的ICL难度。我们在多达八个数据集上进行的实验证明，弱语言模型可以通过SLEICL方法获得与强语言模型相当的ICL能力。

    In-context Learning (ICL) is one of the key methods for enhancing the performance of large language models on specific tasks by providing a set of few-shot examples. However, the ICL capability of different types of models shows significant variation due to factors such as model architecture, volume of learning data, and the size of parameters. Generally, the larger the model's parameter size and the more extensive the learning data, the stronger its ICL capability. In this paper, we propose a method SLEICL that involves learning from examples using strong language models and then summarizing and transferring these learned skills to weak language models for inference and application. This ensures the stability and effectiveness of ICL. Compared to directly enabling weak language models to learn from prompt examples, SLEICL reduces the difficulty of ICL for these models. Our experiments, conducted on up to eight datasets with five language models, demonstrate that weak language models a
    
[^41]: 你的预训练模型有改进吗？一种基于多头后验的方法

    Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach. (arXiv:2401.02987v1 [cs.CL])

    [http://arxiv.org/abs/2401.02987](http://arxiv.org/abs/2401.02987)

    本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。

    

    预训练模型的出现对自然语言处理（NLP）、计算机视觉和关系型数据集等领域产生了显著影响。传统上，这些模型通过下游任务进行评估。然而，这引发了如何更高效、更有效地评估这些模型的问题。在本研究中，我们探索了一种新颖的方法，即利用与每个实体相关的元特征作为世界知识的来源，并利用模型的实体表示。我们提出使用这些表示和元特征之间的一致性作为评估预训练模型的度量标准。我们的方法在各个领域表现出了有效性，包括具有关系型数据集、大型语言模型和图像模型的模型。

    The emergence of pretrained models has significantly impacted from Natural Language Processing (NLP) and Computer Vision to relational datasets. Traditionally, these models are assessed through fine-tuned downstream tasks. However, this raises the question of how to evaluate these models more efficiently and more effectively. In this study, we explore a novel approach where we leverage the meta features associated with each entity as a source of worldly knowledge and employ entity representations from the models. We propose using the consistency between these representations and the meta features as a metric for evaluating pretrained models. Our method's effectiveness is demonstrated across various domains, including models with relational datasets, large language models and images models.
    
[^42]: Cheetah: 517种非洲语言的自然语言生成

    Cheetah: Natural Language Generation for 517 African Languages. (arXiv:2401.01053v1 [cs.CL])

    [http://arxiv.org/abs/2401.01053](http://arxiv.org/abs/2401.01053)

    Cheetah是一个面向517种非洲语言的大规模多语种自然语言生成模型，通过综合评估和人工评估，证明了其在生成连贯和上下文恰当的文本方面的卓越性能，并提供了促进语言多样性的解决方案。

    

    对于自然语言处理 (NLP) 任务来说，非洲语言资源稀缺是一个独特的挑战，包括自然语言生成 (NLG)。在本文中，我们开发了Cheetah，一个面向非洲语言的大规模多语种NLG语言模型。Cheetah支持517种非洲语言和语言变体，解决了NLG资源匮乏问题，并为促进语言多样性提供了解决方案。我们通过七个生成下游任务的综合评估证明了Cheetah的有效性。在七个任务中的五个任务中，Cheetah的表现显著优于其他模型，展示了其在广泛范围的非洲语言中生成连贯和上下文恰当的文本的卓越性能。我们还进行了详细的人工评估，以深入了解Cheetah的语言能力。Cheetah的引入对语言多样性具有深远的益处。通过利用预训练模型并将其适应特定的非洲语言，我们能够提供更多的语言生成选择和资源。

    Low-resource African languages pose unique challenges for natural language processing (NLP) tasks, including natural language generation (NLG). In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages. Cheetah supports 517 African languages and language varieties, allowing us to address the scarcity of NLG resources and provide a solution to foster linguistic diversity. We demonstrate the effectiveness of Cheetah through comprehensive evaluations across seven generation downstream tasks. In five of the seven tasks, Cheetah significantly outperforms other models, showcasing its remarkable performance for generating coherent and contextually appropriate text in a wide range of African languages. We additionally conduct a detailed human evaluation to delve deeper into the linguistic capabilities of Cheetah. The introduction of Cheetah has far-reaching benefits for linguistic diversity. By leveraging pretrained models and adapting them to specifi
    
[^43]: 作为零-shot关键词提取器的大型语言模型：一项初步的实证研究

    Large Language Models as Zero-Shot Keyphrase Extractors: A Preliminary Empirical Study. (arXiv:2312.15156v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.15156](http://arxiv.org/abs/2312.15156)

    该论文探讨了使用大型语言模型ChatGPT作为零-shot关键词提取器的可行性。实验证明，在关键词提取任务中，ChatGPT相对于现有的无监督和有监督模型仍有许多改进空间。

    

    零-shot关键词提取旨在通过没有人工标注数据的训练来构建关键词提取器，这是一项具有挑战性的任务，因为其中涉及到的人工干预有限。零-shot设置能够高效减少数据标注所需的时间和工作量，因此具有挑战但值得研究。最近，关于预训练的大型语言模型（例如ChatGPT和ChatGLM）在零-shot设置上展现出了有希望的性能，这激发了我们探索基于提示的方法。本文探讨了是否可以通过直接向大型语言模型ChatGPT发出提示来构建强大的关键词提取模型。实验结果发现，与现有最先进的无监督和有监督模型相比，ChatGPT在关键词提取任务中仍有很大的改进空间。

    Zero-shot keyphrase extraction aims to build a keyphrase extractor without training by human-annotated data, which is challenging due to the limited human intervention involved. Challenging but worthwhile, zero-shot setting efficiently reduces the time and effort that data labeling takes. Recent efforts on pre-trained large language models (e.g., ChatGPT and ChatGLM) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this paper, we ask whether strong keyphrase extraction models can be constructed by directly prompting the large language model ChatGPT. Through experimental results, it is found that ChatGPT still has a lot of room for improvement in the keyphrase extraction task compared to existing state-of-the-art unsupervised and supervised models.
    
[^44]: HyperPIE: 从科学论文中提取超参数信息

    HyperPIE: Hyperparameter Information Extraction from Scientific Publications. (arXiv:2312.10638v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.10638](http://arxiv.org/abs/2312.10638)

    本文提出了 HyperPIE 方法，用于从科学论文中提取超参数信息。通过训练和评估多种模型，包括BERT微调模型和五个大型语言模型，我们实现了关系提取和结构化数据提取，并取得了显著的性能改进。

    

    从论文中自动提取信息是实现科学知识机器可读化的关键。提取出的信息可以促进学术搜索、决策制定和知识图谱构建。现有方法没有涵盖的一类重要信息是超参数信息。在本文中，我们将超参数信息提取（HyperPIE）形式化为实体识别和关系提取任务，并创建了一个标记数据集来涵盖各种计算机科学学科的论文。利用这个数据集，我们训练和评估了基于BERT的微调模型以及五个大型语言模型：GPT-3.5、GALACTICA、Falcon、Vicuna和WizardLM。对于微调模型，我们提出了一种关系提取方法，相较于最先进的基准模型，F1值提升了29%。对于大型语言模型，我们提出了一种利用YAML输出进行结构化数据提取的方法，取得了

    Automatic extraction of information from publications is key to making scientific knowledge machine readable at a large scale. The extracted information can, for example, facilitate academic search, decision making, and knowledge graph construction. An important type of information not covered by existing approaches is hyperparameters. In this paper, we formalize and tackle hyperparameter information extraction (HyperPIE) as an entity recognition and relation extraction task. We create a labeled data set covering publications from a variety of computer science disciplines. Using this data set, we train and evaluate BERT-based fine-tuned models as well as five large language models: GPT-3.5, GALACTICA, Falcon, Vicuna, and WizardLM. For fine-tuned models, we develop a relation extraction approach that achieves an improvement of 29% F1 over a state-of-the-art baseline. For large language models, we develop an approach leveraging YAML output for structured data extraction, which achieves a
    
[^45]: KwaiAgents：基于大型语言模型的通用信息搜索智能体系统

    KwaiAgents: Generalized Information-seeking Agent System with Large Language Models. (arXiv:2312.04889v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.04889](http://arxiv.org/abs/2312.04889)

    本文介绍了 KwaiAgents，这是一个基于大型语言模型的通用信息搜索智能体系统。该系统能够利用语言模型作为认知核心，理解用户的查询，行为准则并参考外部文档，以提供高质量的知识和信息。

    

    人类由于好奇心的驱使，不断探索和理解周围的世界，从而发明了各种工具来满足这种好奇心。尽管人类无法在大脑中处理和记忆大量信息，但在批判思维、规划、反思以及利用现有工具与世界进行交互和解释方面卓越出色，使其能够高效地寻找答案。最近大型语言模型（LLM）的进步表明，机器可能也具备类似于人类的能力，即使参数数量受限，也能展示强大的能力。在本文中，我们介绍了 KwaiAgents，这是一个基于LLM的通用信息搜索智能体系统。在 KwaiAgents 中，我们提出了一种利用LLM作为认知核心的智能体系统，它能够理解用户的查询、行为准则和参考外部文档。智能体还可以更新查询结果，与用户进行互动，并提供高质量的知识和信息。

    Driven by curiosity, humans have continually sought to explore and understand the world around them, leading to the invention of various tools to satiate this inquisitiveness. Despite not having the capacity to process and memorize vast amounts of information in their brains, humans excel in critical thinking, planning, reflection, and harnessing available tools to interact with and interpret the world, enabling them to find answers efficiently. The recent advancements in large language models (LLMs) suggest that machines might also possess the aforementioned human-like capabilities, allowing them to exhibit powerful abilities even with a constrained parameter count. In this paper, we introduce KwaiAgents, a generalized information-seeking agent system based on LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its cognitive core, which is capable of understanding a user's query, behavior guidelines, and referencing external documents. The agent can also update an
    
[^46]: 自定义数据增强在低资源ASR中的应用：基于Bark和基于检索的语音转换

    Custom Data Augmentation for low resource ASR using Bark and Retrieval-Based Voice Conversion. (arXiv:2311.14836v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2311.14836](http://arxiv.org/abs/2311.14836)

    本文提出两种创新的方法来应对低资源语言ASR的挑战：一种是利用Bark模型和Meta的enCodec和预训练HuBert模型，一种是采用基于检索的语音转换(RVC)和Ozen工具包。这些方法为ASR技术的发展做出了贡献，并为构建定制化Common Voice数据集提供了宝贵的见解。

    

    本文提出了两种创新的方法来构建定制化的Common Voice数据集，以应对低资源语言如印地语的挑战。第一种方法利用Suno开发的基于Transformer的文本到音频模型Bark，结合了Meta的enCodec和预训练的HuBert模型，以提高Bark的性能。第二种方法采用基于检索的语音转换(RVC)，并使用Ozen工具包进行数据准备。这两种方法都为ASR技术的发展做出了贡献，并为解决构建定制化Common Voice数据集的挑战提供了宝贵的见解。此外，它们还为实现各种应用的高质量个性化语音生成提供了途径。

    This paper proposes two innovative methodologies to construct customized Common Voice datasets for low-resource languages like Hindi. The first methodology leverages Bark, a transformer-based text-to-audio model developed by Suno, and incorporates Meta's enCodec and a pre-trained HuBert model to enhance Bark's performance. The second methodology employs Retrieval-Based Voice Conversion (RVC) and uses the Ozen toolkit for data preparation. Both methodologies contribute to the advancement of ASR technology and offer valuable insights into addressing the challenges of constructing customized Common Voice datasets for under-resourced languages. Furthermore, they provide a pathway to achieving high-quality, personalized voice generation for a range of applications.
    
[^47]: 从成对人类偏好学习的密度估计视角

    A density estimation perspective on learning from pairwise human preferences. (arXiv:2311.14115v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.14115](http://arxiv.org/abs/2311.14115)

    研究提出了一个从密度估计的角度解释学习成对人类偏好的方法，并证明通过这种方法训练奖励函数可以有效地模拟注释者的隐含偏好分布。

    

    从人类反馈中学习（LHF）--尤其是从成对偏好学习--最近在训练大型语言模型（LLM）中变得至关重要，并成为许多研究的主题。最近的工作大多将其框架为一种强化学习问题，通过成对偏好数据学习奖励函数，并将LLM视为一个策略，并在额外的正则化约束下进行调整以最大化奖励。我们提出了一种替代解释，它以成对偏好的生成过程为中心，并将LHF视为一个密度估计问题。我们提供了理论和实证结果，表明对于通过偏好行为分布方程定义的一类生成过程，通过成对偏好训练奖励函数有效地模拟了注释者的隐含偏好分布。最后，我们讨论并提出了关于“标注者错误”的研究结果--即错误的情况。

    Learning from human feedback (LHF) -- and in particular learning from pairwise preferences -- has recently become a crucial ingredient in training large language models (LLMs), and has been the subject of much research. Most recent works frame it as a reinforcement learning problem, where a reward function is learned from pairwise preference data and the LLM is treated as a policy which is adapted to maximize the rewards, often under additional regularization constraints. We propose an alternative interpretation which centers on the generative process for pairwise preferences and treats LHF as a density estimation problem. We provide theoretical and empirical results showing that for a family of generative processes defined via preference behavior distribution equations, training a reward function on pairwise preferences effectively models an annotator's implicit preference distribution. Finally, we discuss and present findings on "annotator misspecification" -failure cases where wro
    
[^48]: 使用类似人类发展数据语料库进行预训练的LLMs

    Pre-training LLMs using human-like development data corpus. (arXiv:2311.04666v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04666](http://arxiv.org/abs/2311.04666)

    本论文使用类似人类发展数据语料库对LLMs进行预训练，通过与儿童观看的令牌数量相似的方式，评估了LLMs学习上下文词表示的能力。同时提供强大的基准和对任务组织者提供的RoBERTa基准的复制尝试。

    

    预训练的大型语言模型（LLMs）在各种语言推理和理解任务中取得了成功。LLMs的预训练阶段会查看大量的原始文本数据。BabyLM共享任务将LLM的预训练与人类语言习得进行比较，13岁孩子看到的令牌数量比LLMs看到的数量要小得多。在这项工作中，我们在LLMs能够学习上下文词表示方面进行预训练和评估，使用的令牌数量与儿童看到的差不多。我们提供了一组强大的基准；不同的架构、评估不同时期性能变化和报告的预训练指标，以及尝试松散复制任务组织者提供的RoBERTa基准以观察超参数选择和复现性对训练稳健性的影响。我们提供了对严格和严格小规模路径的提交细节。

    Pre-trained Large Language Models (LLMs) have shown success in a diverse set of language inference and understanding tasks. The pre-training stage of LLMs looks at a large corpus of raw textual data. The BabyLM shared task compares LLM pre-training to human language acquisition, where the number of tokens seen by 13-year-old kids is magnitudes smaller than the number of tokens seen by LLMs. In this work, we pre-train and evaluate LLMs on their ability to learn contextual word representations using roughly the same number of tokens as seen by children. We provide a strong set of baselines; with different architectures, evaluation of changes in performance across epochs, and reported pre-training metrics for the strict small and strict tracks of the task. We also try to loosely replicate the RoBERTa baseline given by the task organizers to observe the training robustness to hyperparameter selection and replicability. We provide the submission details to the strict and strict-small tracks
    
[^49]: 使用大型语言模型改进自动VQA评估

    Improving Automatic VQA Evaluation Using Large Language Models. (arXiv:2310.02567v1 [cs.CV])

    [http://arxiv.org/abs/2310.02567](http://arxiv.org/abs/2310.02567)

    提出使用大型语言模型改进自动视觉问答（VQA）评估的方法，将VQA评估格式化为回答评分任务，通过指令调整大型语言模型在准确度上评分候选答案，证明该方法与人类判断相关性优于现有度量方法。

    

    在提出视觉问答（VQA）任务8年后，准确率仍然是自动评估的主要指标。在IID评估设置中，VQA准确度一直很有效。然而，我们的社区正在转向开放式生成模型和OOD评估。在这种新的范式中，现有的VQA准确度指标过于严格，低估了VQA系统的性能。因此，有必要开发更强大的自动VQA度量，作为人类判断的代理。在这项工作中，我们提出利用指令调整大型语言模型（LLM）的上下文学习能力来构建更好的VQA度量。我们将VQA评估格式化为一个回答评分任务，即指令调整的大型语言模型被指示根据一组参考答案评分候选答案的准确性。我们证明所提出的度量与人类判断相关性优于现有度量在几个VQA模型和基准测试中。

    8 years after the visual question answering (VQA) task was proposed, accuracy remains the primary metric for automatic evaluation. VQA Accuracy has been effective so far in the IID evaluation setting. However, our community is undergoing a shift towards open-ended generative models and OOD evaluation. In this new paradigm, the existing VQA Accuracy metric is overly stringent and underestimates the performance of VQA systems. Thus, there is a need to develop more robust automatic VQA metrics that serve as a proxy for human judgment. In this work, we propose to leverage the in-context learning capabilities of instruction-tuned large language models (LLMs) to build a better VQA metric. We formulate VQA evaluation as an answer-rating task where the LLM is instructed to score the accuracy of a candidate answer given a set of reference answers. We demonstrate the proposed metric better correlates with human judgment compared to existing metrics across several VQA models and benchmarks. We ho
    
[^50]: 评估大型语言模型利用亚斯伯格综合征筛选测试理解隐喻和讽刺的能力

    Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome. (arXiv:2309.10744v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.10744](http://arxiv.org/abs/2309.10744)

    该研究使用一个评分测试来评估大型语言模型（LLMs）理解人类微妙交流的能力。研究结果发现，随着模型参数数量的增加，LLMs对隐喻理解能力有所改善，但对讽刺理解能力的改进并未观察到。

    

    隐喻和讽刺是我们高度进化的社交沟通技巧的珍贵成果。然而，亚斯伯格综合征的儿童众所周知在理解讽刺方面存在困难，即使他们具有足够理解隐喻的口语智商水平。鉴于此，已经使用了一个评分测试来评估理解隐喻和讽刺的能力，以区分亚斯伯格综合征和其他表现相似外部行为的症状（例如注意力缺陷/多动障碍）。本研究使用标准化测试来研究最近大型语言模型（LLMs）理解人类微妙交流的能力。结果显示，随着模型参数数量的增加，它们理解隐喻的能力得到了改善，但并没有观察到对讽刺理解的改进。这意味着有必要采取其他方法来使LLMs具备理解讽刺的能力，这已与亚斯伯格综合征相关。

    Metaphors and sarcasm are precious fruits of our highly-evolved social communication skills. However, children with Asperger syndrome are known to have difficulties in comprehending sarcasm, even if they possess a certain level of verbal IQ sufficient for understanding metaphors. Given that, a screening test that scores the ability to understand metaphor and sarcasm has been used to differentiate Asperger syndrome from other symptoms exhibiting akin external behaviors (e.g., attention-deficit/hyperactivity disorder). This study uses the standardized test to examine the capability of recent large language models (LLMs) in understanding human nuanced communication. The results divulged that, whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed. This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which has been asso
    
[^51]: 通过社交媒体数据和易感-感染-康复（SIR）模型研究灾害响应：以2020年西部美国火灾季为案例研究

    Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season. (arXiv:2308.05281v1 [cs.SI])

    [http://arxiv.org/abs/2308.05281](http://arxiv.org/abs/2308.05281)

    该研究通过社交媒体数据和SIR模型研究了2020年西部美国火灾季的灾害响应。研究发现Twitter用户主要关注健康影响、损失和撤离三个主题，并使用SIR理论探索了这些主题在Twitter上的传播规模和速度。

    

    有效的灾害响应对受影响的社区至关重要。应急人员和决策者在灾害期间在了解社区所面临问题的可靠和及时的指标上将受益于社交媒体提供的丰富数据来源。社交媒体可以反映公众关注和需求，为决策者提供有价值的洞见，以了解不断演变的情况并优化资源配置。我们使用双向编码器表示转换（BERT）主题建模对Twitter数据进行主题聚类。然后，我们进行了时间-空间分析，研究了这些主题在2020年美国西部火灾季期间在不同地区的分布情况。我们的结果显示，Twitter用户主要关注三个主题：“健康影响”，“损失”，“撤离”。我们使用易感-感染-康复（SIR）理论来探索主题在Twitter上的传播规模和速度。结果清晰地显示了主题传播的情况。

    Effective disaster response is critical for affected communities. Responders and decision-makers would benefit from reliable, timely measures of the issues impacting their communities during a disaster, and social media offers a potentially rich data source. Social media can reflect public concerns and demands during a disaster, offering valuable insights for decision-makers to understand evolving situations and optimize resource allocation. We used Bidirectional Encoder Representations from Transformers (BERT) topic modeling to cluster topics from Twitter data. Then, we conducted a temporal-spatial analysis to examine the distribution of these topics across different regions during the 2020 western U.S. wildfire season. Our results show that Twitter users mainly focused on three topics:"health impact," "damage," and "evacuation." We used the Susceptible-Infected-Recovered (SIR) theory to explore the magnitude and velocity of topic diffusion on Twitter. The results displayed a clear re
    
[^52]: LimeAttack: 本地可解释方法用于文本硬标签对抗性攻击

    LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack. (arXiv:2308.00319v1 [cs.CL])

    [http://arxiv.org/abs/2308.00319](http://arxiv.org/abs/2308.00319)

    本文提出了一种名为LimeAttack的硬标签攻击算法，通过本地可解释方法来近似单词重要性排序，然后利用波束搜索找到最优解。

    

    自然语言处理模型容易受到对抗性样本的攻击。先前的文本对抗性攻击采用梯度或置信度分数来计算单词重要性排序，并生成对抗性样本。然而，在现实世界中，这些信息是不可用的。因此，我们将重点放在一个更现实和具有挑战性的场景上，名为硬标签攻击，其中攻击者只能查询模型并获取离散的预测标签。现有的硬标签攻击算法往往通过随机替换来初始化对抗性样本，然后利用复杂的启发式算法来优化对抗扰动。这些方法需要大量的模型查询，并且攻击成功率受到对手初始化的限制。在本文中，我们提出了一种名为LimeAttack的新型硬标签攻击算法，它利用本地可解释方法来近似单词重要性排序，然后采用波束搜索来找到最优解。

    Natural language processing models are vulnerable to adversarial examples. Previous textual adversarial attacks adopt gradients or confidence scores to calculate word importance ranking and generate adversarial examples. However, this information is unavailable in the real world. Therefore, we focus on a more realistic and challenging setting, named hard-label attack, in which the attacker can only query the model and obtain a discrete prediction label. Existing hard-label attack algorithms tend to initialize adversarial examples by random substitution and then utilize complex heuristic algorithms to optimize the adversarial perturbation. These methods require a lot of model queries and the attack success rate is restricted by adversary initialization. In this paper, we propose a novel hard-label attack algorithm named LimeAttack, which leverages a local explainable method to approximate word importance ranking, and then adopts beam search to find the optimal solution. Extensive experi
    
[^53]: 实体链接的检索器-阅读器范式的双向端到端学习

    Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking. (arXiv:2306.12245v1 [cs.CL])

    [http://arxiv.org/abs/2306.12245](http://arxiv.org/abs/2306.12245)

    BEER^2是一种用于Retriever和Reader的双向端到端训练框架，通过检索器和阅读器之间的相互学习，共同进步，实现端到端EL。

    

    实体链接（EL）是信息提取和知识图谱的基本任务，它的一般形式（即端到端EL）旨在首先在给定输入文档中找到提及，并将提及链接到特定知识库中的相应实体。最近，检索器-阅读器范式促进了端到端EL的进展，受益于密集的实体检索和机器阅读理解的优势。然而，现有研究仅以流水线方式单独训练检索器和阅读器，忽略了检索器和阅读器之间交互带来的益处。为了使检索器-阅读器范式更完美地执行端到端EL，我们提出了BEER$^2$，一种用于Retriever and Reader的双向端到端训练框架。通过我们设计的双向端到端训练，BEER$^2$指导检索器和阅读器互相学习，共同进步，并最终实现端到端EL。

    Entity Linking (EL) is a fundamental task for Information Extraction and Knowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to first find mentions in the given input document and then link the mentions to corresponding entities in a specific knowledge base. Recently, the paradigm of retriever-reader promotes the progress of end-to-end EL, benefiting from the advantages of dense entity retrieval and machine reading comprehension. However, the existing study only trains the retriever and the reader separately in a pipeline manner, which ignores the benefit that the interaction between the retriever and the reader can bring to the task. To advance the retriever-reader paradigm to perform more perfectly on end-to-end EL, we propose BEER$^2$, a Bidirectional End-to-End training framework for Retriever and Reader. Through our designed bidirectional end-to-end training, BEER$^2$ guides the retriever and the reader to learn from each other, make progress together, and ultimate
    
[^54]: 探究零样本和少样本视觉问答提示技术

    Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering. (arXiv:2306.09996v1 [cs.CV])

    [http://arxiv.org/abs/2306.09996](http://arxiv.org/abs/2306.09996)

    本文探索使用不同提示策略，重点关注 BLIP2 模型，来提高零样本 VQA 的性能，研究了不同问题模板的有效性、少量样本示例的作用、思维链推理的影响以及将图像标题作为额外视觉线索融合的好处。精心设计的问题模板和整合额外视觉线索可以促进 VQA 性能的提高，特别是当它们结合使用时。

    

    视觉问答（VQA）是一项具有挑战性的任务，需要具备理解和推理视觉信息的能力。虽然近期的视觉语言模型取得了进展，但它们在零样本VQA方面仍然存在问题，特别是在处理复杂组合问题和适应新领域，如基于知识的推理方面。本文探讨了各种提示策略的使用，重点关注BLIP2模型，以提高零样本VQA的性能。我们在几个VQA数据集上进行了全面调查，研究了不同问题模板的有效性、少量样本示例的作用、思维链推理的影响以及将图像标题作为额外视觉线索融合的好处。尽管结果各异，但我们的发现表明，精心设计的问题模板和整合额外视觉线索（如图像标题）可以促进VQA性能的提高，特别是当它们结合使用时。

    Visual question answering (VQA) is a challenging task that requires the ability to comprehend and reason with visual information. While recent vision-language models have made strides, they continue to struggle with zero-shot VQA, particularly in handling complex compositional questions and adapting to new domains i.e. knowledge-based reasoning. This paper explores the use of various prompting strategies, focusing on the BLIP2 model, to enhance zero-shot VQA performance. We conduct a comprehensive investigation across several VQA datasets, examining the effectiveness of different question templates, the role of few-shot exemplars, the impact of chain-of-thought (CoT) reasoning, and the benefits of incorporating image captions as additional visual cues. Despite the varied outcomes, our findings demonstrate that carefully designed question templates and the integration of additional visual cues, like image captions, can contribute to improved VQA performance, especially when used in conj
    
[^55]: BiomedGPT：一种面向视觉、语言和多模态任务的统一且通用的生物医学生成预训练Transformer

    BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks. (arXiv:2305.17100v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17100](http://arxiv.org/abs/2305.17100)

    BiomedGPT是一种面向视觉、语言和多模态任务的通用生物医学生成预训练Transformer，在多个临床任务中取得了16个最新的最优结果，包括超过了OpenAI的GPT-4V和Google的Med-PaLM M（12B）。同时，BiomedGPT还支持零-shot迁移学习。

    

    传统的任务和模态特定的人工智能模型在生物医学领域的实际应用和维护中不够灵活。与此同时，生物医学数据的不断增加，结合现代多模态多任务人工智能技术的进展，为通用的生物医学人工智能解决方案的出现铺平了道路。这些解决方案有潜力解释不同的医疗模态，并产生如自由文本报告或疾病诊断等表达性输出。本文提出了BiomedGPT，这是第一个面向多样化生物医学任务的开源通用视觉语言人工智能模型。BiomedGPT在26个数据集的五个临床重要任务中实现了16个最新的结果。值得注意的是，在放射学人员评估中，它超越了OpenAI的GPT-4 with vision（GPT-4V），并在乳腺癌诊断和医学视觉问题回答方面超过了Google的Med-PaLM M（12B）。此外，BiomedGPT还支持零-shot迁移学习。

    Conventional task- and modality-specific artificial intelligence (AI) models are inflexible in real-world deployment and maintenance for biomedicine. At the same time, the growing availability of biomedical data, coupled with the advancements in modern multi-modal multi-task AI techniques, has paved the way for the emergence of generalist biomedical AI solutions. These solutions hold the potential to interpret different medical modalities and produce expressive outputs such as free-text reports or disease diagnosis. Here, we propose BiomedGPT, the first open-source and generalist visual language AI for diverse biomedical tasks. BiomedGPT achieved 16 state-of-the-art results across five clinically significant tasks on 26 datasets. Notably, it outperformed OpenAI's GPT-4 with vision (GPT-4V) in radiology human evaluation and surpassed Google's Med-PaLM M (12B) in breast cancer diagnosis and medical visual question answering. Moreover, BiomedGPT facilitates zero-shot transfer learning, gr
    
[^56]: LaMP：当大型语言模型遇见个性化

    LaMP: When Large Language Models Meet Personalization. (arXiv:2304.11406v1 [cs.CL])

    [http://arxiv.org/abs/2304.11406](http://arxiv.org/abs/2304.11406)

    本论文强调了当前自然语言处理领域中个性化的重要性，并提出了LaMP（一种用于训练和评估大型语言模型的新的个性化基准），并针对大型语言模型的生成任务，设计了七项个性化任务以及一种检索增强方法，结果表明在利用用户配置文件扩展大型语言模型的基础上，其生成结果明显优于传统方法。

    

    本文强调在当前自然语言理解和生成领域的个性化的重要性，并介绍了LaMP基准——用于训练和评估生成个性化输出的语言模型的新典范。LaMP提供了一个全面的评估框架，具有多样化的语言任务和每个用户的多个条目，包括三个分类任务和四个文本生成任务的七个个性化任务。我们还提出了一种检索增强方法，可从用户配置文件中检索个性化项目，构建大型语言模型的个性化提示。我们的基线零-shot和微调模型的结果表明，利用个人资料扩展的LM优于不考虑个人资料信息的对应模型。

    This paper highlights the importance of personalization in the current state of natural language understanding and generation and introduces the LaMP benchmark -- a novel benchmark for training and evaluating language models for producing personalized outputs. LaMP offers a comprehensive evaluation framework with diverse language tasks and multiple entries for each user profile. It consists of seven personalized tasks, spanning three classification and four text generation tasks. We also propose a retrieval augmentation approach that retrieves personalized items from user profiles to construct personalized prompts for large language models. Our baseline zero-shot and fine-tuned model results indicate that LMs utilizing profile augmentation outperform their counterparts that do not factor in profile information.
    
[^57]: 带有个性自适应注意力的个性化对话生成

    Personalized Dialogue Generation with Persona-Adaptive Attention. (arXiv:2210.15088v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.15088](http://arxiv.org/abs/2210.15088)

    本文提出了一种新的框架，使用个性自适应注意力（PAA）来生成基于个性的一致性回应，可以通过整合个性和上下文信息的权重来实现。实验证明 PAA 框架具有优越性能，可以在低资源环境下表现出色。

    

    基于个性化的对话系统旨在根据历史上下文和预定义的个性生成一致的回应。与传统的对话生成不同，基于个性的对话需要考虑对话上下文和个性两个方面，这对于一致的训练提出了挑战。本文提出了一种有效的框架，使用个性自适应注意力（PAA），通过我们设计的注意力适应性地整合了来自个性和上下文信息的权重。此外，PAA 还应用了动态屏蔽机制，不仅可以丢弃上下文和个性的冗余信息，还可以作为正则化机制避免过拟合。实验结果表明，与强基线相比，所提出的 PAA 框架在自动和人工评估中表现优异。此外，所提出的 PAA 方法在低资源环境下表现同样出色。

    Persona-based dialogue systems aim to generate consistent responses based on historical context and predefined persona. Unlike conventional dialogue generation, the persona-based dialogue needs to consider both dialogue context and persona, posing a challenge for coherent training. Specifically, this requires a delicate weight balance between context and persona. To achieve that, in this paper, we propose an effective framework with Persona-Adaptive Attention (PAA), which adaptively integrates the weights from the persona and context information via our designed attention. In addition, a dynamic masking mechanism is applied to the PAA to not only drop redundant information in context and persona but also serve as a regularization mechanism to avoid overfitting. Experimental results demonstrate the superiority of the proposed PAA framework compared to the strong baselines in both automatic and human evaluation. Moreover, the proposed PAA approach can perform equivalently well in a low-r
    
[^58]: BenchCLAMP：用于评估语言模型在句法和语义解析上的基准测试

    BenchCLAMP: A Benchmark for Evaluating Language Models on Syntactic and Semantic Parsing. (arXiv:2206.10668v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.10668](http://arxiv.org/abs/2206.10668)

    BenchCLAMP是一个用于评估语言模型在句法和语义解析上的基准测试。它包括七个语义解析数据集和两个句法解析数据集，提供了不同数据策略下的资源划分，并支持基于提示的学习和精调评估。实验证明，编码器-解码器预训练语言模型可以达到类似或超过现有最先进技术的性能水平。

    

    近期研究表明，当输出被限制为有效的语义表示时，通过提示或精调的语言模型在语义解析上表现良好。我们引入了BenchCLAMP，这是一个用于评估约束语言模型解析的基准测试，包括七个语义解析数据集的上下文无关文法和两个具有不同输出表示的句法解析数据集，以及一个受限解码界面，仅生成这些文法包含的有效输出。我们为每个数据集提供了低、中、高资源划分，可以准确比较不同数据策略下各种语言模型的性能。我们的基准测试支持使用基于提示的学习和精调评估语言模型。我们对包括两个仅通过API可用的GPT-3变体在内的八个语言模型进行了基准测试。我们的实验证明，编码器-解码器预训练语言模型可以达到类似或超过现有最先进技术的性能水平。

    Recent work has shown that generation from a prompted or fine-tuned language model can perform well at semantic parsing when the output is constrained to be a valid semantic representation. We introduce BenchCLAMP, a Benchmark to evaluate Constrained LAnguage Model Parsing, that includes context-free grammars for seven semantic parsing datasets and two syntactic parsing datasets with varied output representations, as well as a constrained decoding interface to generate only valid outputs covered by these grammars. We provide low, medium, and high resource splits for each dataset, allowing accurate comparison of various language models under different data regimes. Our benchmark supports evaluation of language models using prompt-based learning as well as fine-tuning. We benchmark eight language models, including two GPT-3 variants available only through an API. Our experiments show that encoder-decoder pretrained language models can achieve similar performance or surpass state-of-the-a
    

