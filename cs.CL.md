# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A General-Purpose Multilingual Document Encoder.](http://arxiv.org/abs/2305.07016) | 本文提出了一种通用的大规模多语言文档编码器，使用维基百科作为数据来源，并采用跨语言对比目标进行训练，可用于监督和非监督文档级任务。 |
| [^2] | [Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers.](http://arxiv.org/abs/2305.07011) | 本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。 |
| [^3] | [Subword Segmental Machine Translation: Unifying Segmentation and Target Sentence Generation.](http://arxiv.org/abs/2305.07005) | 子词级分段机器翻译（SSMT）是一种将子词分割和MT在一个可训练模型中统一起来的方法，它学习分割目标句子词，同时联合学习生成目标句子。在6个翻译方向的实验中表明，SSMT提高了词素丰富的聚集性语言的chrF分数，且具有更高的鲁棒性。 |
| [^4] | [Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting.](http://arxiv.org/abs/2305.07004) | 该论文介绍了一种跨语言思维提示方法，名为XLT，用于提高LLMs的多语言能力。该方法能够显著提高各种多语言任务性能，并减少不同语言中任务性能的差距。 |
| [^5] | [Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach.](http://arxiv.org/abs/2305.07001) | 采用大型语言模型以指令遵循为方法的推荐系统，可以将用户偏好或需求进行自然语言描述，进而提高推荐精度。 |
| [^6] | [SMATCH++: Standardized and Extended Evaluation of Semantic Graphs.](http://arxiv.org/abs/2305.06993) | SMATCH++是一个用于语义图标准化和扩展评估的方法，通过将度量分为预处理、对齐和评分三个模块，解决了当前度量存在的问题，提高了对齐的安全性。 |
| [^7] | [Self-Chained Image-Language Model for Video Localization and Question Answering.](http://arxiv.org/abs/2305.06988) | SeViLA是一个利用单个图像语言模型的框架，在视频定位和问答方面表现出色，通过自我链接策略训练局部化器和回答器模块以定位最具信息的关键帧以回答问题。 |
| [^8] | [Evaluating Open-Domain Question Answering in the Era of Large Language Models.](http://arxiv.org/abs/2305.06984) | 本文评估了开放领域问答中的大语言模型，发现词汇匹配作为评估方法在这些模型中的作用有限，提出了一种手动评估方法，并发现其中一个零-shot模型的性能大幅度提升。 |
| [^9] | [Active Retrieval Augmented Generation.](http://arxiv.org/abs/2305.06983) | 本论文提出了一种主动检索增强生成的方法，与以往的方法相比，它在生成过程中更紧密地集成了主动检索和生成，并展示了在一组句子生成任务中的性能优势。 |
| [^10] | [Humans are Still Better than ChatGPT: Case of the IEEEXtreme Competition.](http://arxiv.org/abs/2305.06934) | 本文展示了一个对传统认识的颠覆性观点：在计算机编程领域的典型ChatGPT任务中，人类程序员仍然比ChatGPT更优秀。 |
| [^11] | [AfriQA: Cross-lingual Open-Retrieval Question Answering for African Languages.](http://arxiv.org/abs/2305.06897) | AfriQA是第一个专注于非洲语言的跨语言QA数据集，弥补了非洲语言数字化内容不足的问题。实验结果表明自动翻译和多语言检索模型的性能较差，需要支持跨语言推理和转移学习的模型。 |
| [^12] | [IUST_NLP at SemEval-2023 Task 10: Explainable Detecting Sexism with Transformers and Task-adaptive Pretraining.](http://arxiv.org/abs/2305.06892) | 本研究使用Transformer和任务自适应预训练设计了自动系统来检测和分类在线空间中的性别歧视内容，通过集成学习与大量未标记数据的自适应预训练提高模型性能，在SemEval-2023任务10中表现良好，达到了83％，64％和47％的F1得分。 |
| [^13] | [Think Twice: Measuring the Efficiency of Eliminating Prediction Shortcuts of Question Answering Models.](http://arxiv.org/abs/2305.06841) | 研究提出了一种衡量模型依赖已知虚假特征的技术，并评估了预先训练的问答模型和去偏置方法对大量已知和新发现的预测偏差的鲁棒性。其发现去偏置方法不能通过减轻对偏差特征的依赖来解释OOD收益，表明偏差在QA数据集中共享。 |
| [^14] | [Towards a Computational Analysis of Suspense: Detecting Dangerous Situations.](http://arxiv.org/abs/2305.06818) | 本文引入一个文本语料库，其中标注了危险情境及角色的恐惧，通过实验发现无监督的基础方法可以提供有价值的信号来检测这些情境，但要进一步深入分析需要更复杂的方法，因为危险和恐惧的描述在很大程度上依赖于上下文。 |
| [^15] | [THUIR@COLIEE 2023: More Parameters and Legal Knowledge for Legal Case Entailment.](http://arxiv.org/abs/2305.06817) | 本文描述了THUIR团队在COLIEE 2023法律案例蕴涵任务中的方法，尝试了传统的词汇匹配方法和预训练语言模型，并采用学习排序方法进一步提高性能，结果表明更多的参数和法律知识对法律案例蕴涵任务有所贡献。 |
| [^16] | [THUIR@COLIEE 2023: Incorporating Structural Knowledge into Pre-trained Language Models for Legal Case Retrieval.](http://arxiv.org/abs/2305.06812) | 本文总结了THUIR在COLIEE 2023比赛中的冠军方案，其将结构化知识融入预训练语言模型，提出启发式预处理和后处理方法，采用学习排序方法进行特征合并，实验结果显示其具有卓越的优势。 |
| [^17] | [Detecting Idiomatic Multiword Expressions in Clinical Terminology using Definition-Based Representation Learning.](http://arxiv.org/abs/2305.06801) | 本文提出了一种基于定义表示学习的方法，用于检测诊疗术语中的习语性多词表达式，加强了UMLS本体和生物医学语言模型的翻译效率。 |
| [^18] | [COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP tasks.](http://arxiv.org/abs/2305.06754) | COCKATIEL是一种连续概念排名带归因性解释的技术，基于概念，用于从NLP分类任务的神经网络模型的最后一层中生成有意义的解释，且不会影响准确性或需要新模型，已证明比现有方法产生更有信息量和可靠的解释。 |
| [^19] | [The First Parallel Corpora for Kurdish Sign Language.](http://arxiv.org/abs/2305.06747) | 该论文介绍了首个用于库尔德手语和口语库尔德之间平行翻译的数据集，并使用统计翻译技术进行了自动翻译，结果准确率为53.8%。 |
| [^20] | [Advancing Neural Encoding of Portuguese with Transformer Albertina PT-*.](http://arxiv.org/abs/2305.06721) | 本研究使用基于 Transformer 的 Albertina PT-* 模型进行了葡萄牙语的神经编码，创新性地提升了该语言在数字时代的技术准备水平，尤其是欧洲葡萄牙语和巴西的美洲葡萄牙语两个变种。 |
| [^21] | [Cost-efficient Crowdsourcing for Span-based Sequence Labeling: Worker Selection and Data Augmentation.](http://arxiv.org/abs/2305.06683) | 本文介绍了面向基于跨度的序列标注任务的成本效益众包算法，使用了组合多臂老虎机方法进行工人选择，并用移位、扩展和收缩的数据增强方法进行测试，提高了注释质量和降低成本，F1得分相对于仅专家的基线提高了100.04％，成本节约高达65.97％。 |
| [^22] | [INGENIOUS: Using Informative Data Subsets for Efficient Pre-Training of Large Language Models.](http://arxiv.org/abs/2305.06677) | 本文提出了一种使用信息丰富的数据子集来高效预训练大型语言模型的方法，减少了训练时间和计算成本，同时保持了模型的泛化能力。 |
| [^23] | [QURG: Question Rewriting Guided Context-Dependent Text-to-SQL Semantic Parsing.](http://arxiv.org/abs/2305.06655) | QURG是一种帮助文本到SQL语义解析模型实现上下文理解的新颖方法，能在SParC和CoSQL等上下文依赖性数据集上提高模型性能，特别是对于难以处理和长轮次的问题。 |
| [^24] | [PROM: A Phrase-level Copying Mechanism with Pre-training for Abstractive Summarization.](http://arxiv.org/abs/2305.06647) | 提出了一种新的短语级复制机制-PROM，可以增强对n-gram的注意力，用于具有预训练的零样本摘要生成，大大提高了摘要的质量和可信度。 |
| [^25] | [When the Majority is Wrong: Leveraging Annotator Disagreement for Subjective Tasks.](http://arxiv.org/abs/2305.06626) | 本文通过预测单个标注者的打分，并结合文本目标群体的预测，模拟了目标群体成员的意见，通过使用他们的人口统计学数据和在线意见预测标注者的打分，在仇恨言论检测等主观任务中提高了模型性能。 |
| [^26] | [Improving Continual Relation Extraction by Distinguishing Analogous Semantics.](http://arxiv.org/abs/2305.06620) | 本研究提出了一种针对类比关系的连续抽取模型，通过设计记忆无关的关系原型和记忆增强以克服过拟合问题，进而引入综合训练和焦点知识蒸馏以增强在类比关系上的性能。 |
| [^27] | [Serial Contrastive Knowledge Distillation for Continual Few-shot Relation Extraction.](http://arxiv.org/abs/2305.06616) | 本文提出了 SCKD 模型，使用序列知识蒸馏与对比学习，实现连续的少样本关系抽取任务。该方法可以有效解决旧关系遗忘和过度拟合的问题。 |
| [^28] | [Autocorrelations Decay in Texts and Applicability Limits of Language Models.](http://arxiv.org/abs/2305.06615) | 文本中的自相关衰减与语言模型的适用限制密切相关，生成文本的自相关衰减与文学文本的不同，表现出马尔科夫行为的语言模型可能存在在处理长文本时的局限性。 |
| [^29] | [BanglaBook: A Large-scale Bangla Dataset for Sentiment Analysis from Book Reviews.](http://arxiv.org/abs/2305.06595) | BanglaBook 是一个大规模的孟加拉语书评数据集，其中包括 158,065 个样本，针对情感分析分为三个大类，通过使用预训练模型来取代手动构建特征的模型，取得显着的性能优势。 |
| [^30] | [FactKG: Fact Verification via Reasoning on Knowledge Graphs.](http://arxiv.org/abs/2305.06590) | FactKG是一个新的数据集，通过知识图谱推理进行事实验证，包含108k个自然语言声明和五种推理类型，可帮助社区更好地使用知识图谱进行事实验证。 |
| [^31] | [SemEval-2023 Task 2: Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2).](http://arxiv.org/abs/2305.06586) | 该论文介绍了SemEval-2023 Task 2的研究发现，任务旨在通过使用MultiCoNER V2数据集，识别12种语言中复杂的细粒度命名实体。最优方法是将外部知识融入transformer模型，最具挑战性的是媒体标题和产品名称等实体类型。 |
| [^32] | [Chain-of-Dictionary Prompting Elicits Translation in Large Language Models.](http://arxiv.org/abs/2305.06575) | 研究通过在大型语言模型中添加字典链提示的方法来改进低资源语言的翻译能力，实验结果表明能显著提高翻译质量。 |
| [^33] | [A Fused Gromov-Wasserstein Framework for Unsupervised Knowledge Graph Entity Alignment.](http://arxiv.org/abs/2305.06574) | 本文提出了一种无监督实体对齐框架 FGWEA ，它利用融合格罗莫夫 - 瓦热斯坦距离，实现了实体语义和知识图谱结构的综合比较和对齐，通过三阶段的渐进优化算法来提高匹配准确性。 |
| [^34] | [How to Index Item IDs for Recommendation Foundation Models.](http://arxiv.org/abs/2305.06569) | 本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。 |
| [^35] | [A First Look at LLM-Powered Generative News Recommendation.](http://arxiv.org/abs/2305.06566) | 本文介绍了一种LLM驱动的生成式新闻推荐框架GENRE，它利用预训练语义知识丰富新闻数据，通过从模型设计转移到提示设计提供灵活而统一的解决方案，实现了个性化新闻生成、用户画像和新闻摘要。 |
| [^36] | [Long-Tailed Question Answering in an Open World.](http://arxiv.org/abs/2305.06557) | 本研究提出了一种支持长尾分布数据的Open Long-Tailed QA (OLTQA)模型，鼓励头部、尾部和未知任务间的知识共享，并从大型预训练语言模型中明确挖掘知识，解决了QA方法中瓶颈问题。 |
| [^37] | [Domain Incremental Lifelong Learning in an Open World.](http://arxiv.org/abs/2305.06555) | 本文提出了Diana模型，一种基于动态架构的生命周期学习模型，它使用四种层次化组织的提示来学习一系列任务。其中，任务级提示用于捕获任务特定的知识，实例级提示用于学习跨输入样本共享的知识，从而提高模型的泛化性能。 |
| [^38] | [GeoGLUE: A GeoGraphic Language Understanding Evaluation Benchmark.](http://arxiv.org/abs/2305.06545) | GeoGLUE是一个新的地理语言理解评估基准，提供了六个自然语言理解任务并且经过了有效性和重要性的验证。 |
| [^39] | [Semantic uncertainty guides the extension of conventions to new referents.](http://arxiv.org/abs/2305.06539) | 本研究探讨约定如何转移到与之前完全不同的对象，通过调查可命名性如何影响约定的形成以及新的规则如何泛化到新的指涉目标。 |
| [^40] | [KGA: A General Machine Unlearning Framework Based on Knowledge Gap Alignment.](http://arxiv.org/abs/2305.06535) | 本文提出了基于知识差异对齐的通用机器遗忘框架KGA，实现了文本场景中的遗忘功能，并在多个NLP任务中进行了实验验证。 |
| [^41] | [How Good are Commercial Large Language Models on African Languages?.](http://arxiv.org/abs/2305.06530) | 本文对商用大型语言模型在跨越不同语言系和地理区域的八种非洲语言上进行了初步分析，结果显示它们在非洲语言上的表现略低。呼吁确保非洲语言在商业大型语言模型中得到充分的重视。 |
| [^42] | [Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications.](http://arxiv.org/abs/2305.06522) | 该论文介绍了一种新的两阶段框架 RSMI，结合了随机平滑和掩码推理，以提高 NLP 系统的对抗鲁棒性，经过基准数据集测试，相较于现有最先进方法将对抗鲁棒性提高2到3倍。 |
| [^43] | [Multimodal Contextualized Plan Prediction for Embodied Task Completion.](http://arxiv.org/abs/2305.06485) | 本文提出了一种用于具身化完成任务数据集的多模态上下文化任务计划预测方法，并证明能够使用多模态上下文预测更好的计划，另外计划预测和计划执行模块可能相互依赖，完全解耦可能不是理想的。 |
| [^44] | [A Model for Translation of Text from Indian Languages to Bharti Braille Characters.](http://arxiv.org/abs/2305.06475) | 本文介绍了一种将主要印度语言文本转换成Bharti盲文字符的方案，其采用混合方法并通过LSTM模型解决歧义，测试表明该模型产生了接近准确的结果。 |
| [^45] | [ChatGPT-Like Large-Scale Foundation Models for Prognostics and Health Management: A Survey and Roadmaps.](http://arxiv.org/abs/2305.06472) | 该论文综述了基于大规模基础模型（LSF-Models）如ChatGPT和DALLE-E的人工智能（AI）技术在预测与健康管理（PHM）中的广泛应用。这种技术可以实现多模态、多任务、大量数据和超大模型范式，成为AI-2.0的新时代的标志之一。 |
| [^46] | [Word Grounded Graph Convolutional Network.](http://arxiv.org/abs/2305.06434) | 该论文提出了一种基于词语的图卷积网络模型，可以在处理图外文档时进行归纳推理；该模型在多个基准数据集上表现出较好的性能，同时表明了基于图的方法联合建模词级和文档级信息的有效性。 |
| [^47] | [Bot or Human? Detecting ChatGPT Imposters with A Single Question.](http://arxiv.org/abs/2305.06424) | 本文提出了一个名为FLAIR的框架，通过一个问题和回答来检测ChatGPT中的聊天机器人真实性，可以分类人和机器人。单问题分为对于人类而言容易但对于机器人很难和对于机器人而言容易但对于人类很难两个类别，分别进行检测。 在多个数据集上实现了最先进的性能。 |
| [^48] | [A Method to Automate the Discharge Summary Hospital Course for Neurology Patients.](http://arxiv.org/abs/2305.06416) | 开发了一种使用编码器-解码器序列到序列变换模型进行医院过程小结的自动化方法以缓解医生过劳。该方法在实际性上进行了优化，盲评估表明62%的自动化摘要符合标准，具有临床应用的潜力。 |
| [^49] | [LACoS-BLOOM: Low-rank Adaptation with Contrastive objective on 8 bits Siamese-BLOOM.](http://arxiv.org/abs/2305.06404) | 本文提出了一种新的文本嵌入模型LACoS-BLOOM，采用低秩自适应方法、对比学习目标和Siamese架构，能够生成语义上有意义的单词嵌入。 |
| [^50] | [Accessible Instruction-Following Agent.](http://arxiv.org/abs/2305.06358) | 该研究介绍了UVLN，一种新颖的机器翻译增强框架，用于跨语言视觉-语言导航，其结合了最新的语言模型与图形嵌入技术，旨在将指令跟随代理程序的成功推广到非英语语言，提高其易操作性和可访问性。 |
| [^51] | [Summarizing, Simplifying, and Synthesizing Medical Evidence Using GPT-3 (with Varying Success).](http://arxiv.org/abs/2305.06299) | 本文评估了GPT-3在生物医学领域中生成文章摘要的能力，发现它对单个文章的总结和简化效果较好，但在综合多篇文章中所报告的证据方面表现欠佳。 |
| [^52] | [CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors.](http://arxiv.org/abs/2305.05711) | CodeIE提出了使用代码生成模型（Code-LLMs）代替自然语言生成模型（NL-LLMs）对命名实体识别和关系抽取这类信息提取任务进行少样本学习，取得优于几个强基准高达4.5%的绝对精度改进。 |
| [^53] | [SemEval-2023 Task 7: Multi-Evidence Natural Language Inference for Clinical Trial Data.](http://arxiv.org/abs/2305.02993) | 本论文介绍SemEval 2023的任务七，旨在进行临床试验数据的多证据自然语言推理，该任务难度较大，证据选择任务相对于蕴含任务表现更佳。 |
| [^54] | [DiffuSum: Generation Enhanced Extractive Summarization with Diffusion.](http://arxiv.org/abs/2305.01735) | 本文提出了一种新的基于扩散模型的摘要提取方法DiffuSum，并且在多个数据集上实现了最先进的抽取结果。 |
| [^55] | [The Pipeline System of ASR and NLU with MLM-based Data Augmentation toward STOP Low-resource Challenge.](http://arxiv.org/abs/2305.01194) | 本文介绍了在低资源适应题目中使用的ASR和NLU的管道方法。在ASR中，使用上采样的Whisper对每个领域进行Feine-tune；在NLU中，使用MLM技术进行数据增强并使用基于检索的方法扩充数据。最终，我们在提醒/天气领域获得了高精确匹配准确度并获得了挑战的第一名。 |
| [^56] | [Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023).](http://arxiv.org/abs/2305.00217) | 本研究为对Kauhanen、Einhaus和Walkden（2023）的回应，仍然没有证据表明大量的L2用户影响语言复杂性。 |
| [^57] | [Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models.](http://arxiv.org/abs/2304.01852) | 本文全面介绍了最先进的大型语言模型ChatGPT和GPT-4，包括其在各个领域的前景应用，并着重介绍了大规模预训练、指令微调和人类反馈的强化学习创新。ChatGPT/GPT-4在自然语言处理应用方面表现突出，同时在其他领域也具有潜力。 |
| [^58] | [Self-contained Beta-with-Spikes Approximation for Inference Under a Wright-Fisher Model.](http://arxiv.org/abs/2303.04691) | 本研究提出了一种基于Beta-with-Spikes逼近的Wright-Fisher模型的自包含推断方法，可估算进化参数，稳健性好。 |
| [^59] | [Are Character-level Translations Worth the Wait? Comparing Character- and Subword-level Models for Machine Translation.](http://arxiv.org/abs/2302.14220) | 本文比较了字符级别和子词级别的预训练模型在机器翻译方面的效果，结果表明字符级别建模在形似单词和稀有单词的翻译方面具有更好的效果，在训练数据有限的情况下尤为明显。 |
| [^60] | [Can GPT-3 Perform Statutory Reasoning?.](http://arxiv.org/abs/2302.06100) | 本文研究了GPT-3在法定推理任务上的表现，并发现其表现优于之前最佳结果，但仍存在错误。研究还发现GPT-3对实际法规存在缺陷，且在对于合成法规的问题回答表现不佳。 |
| [^61] | [HyPe: Better Pre-trained Language Model Fine-tuning with Hidden Representation Perturbation.](http://arxiv.org/abs/2212.08853) | 本论文提出了一种名为HyPe的微调技术，通过扰动Transformer层的隐藏表示，改善了预训练语言模型微调过拟合或表示崩溃等问题，并在多个自然语言推理数据集上取得了比普通微调更好的效果。 |
| [^62] | [Attention as a Guide for Simultaneous Speech Translation.](http://arxiv.org/abs/2212.07850) | 本文研究了同声翻译中的编码器-解码器注意力行为，提出了一种基于注意力的策略（EDAtt），旨在通过实时引导编码器-解码器注意力得分来提高同声翻译性能。在英译德和英译西任务中，EDAtt 策略具有计算感知延迟优势并取得了更好的结果。 |
| [^63] | [Cross-Domain Few-Shot Relation Extraction via Representation Learning and Domain Adaptation.](http://arxiv.org/abs/2212.02560) | 本论文提出了一种基于先验知识和内在语义的原型表示学习方法和使用对比学习进行领域适应的跨领域小样本关系抽取框架，可以在多个领域中有效地提取新的关系。 |
| [^64] | [Automaton-Based Representations of Task Knowledge from Generative Language Models.](http://arxiv.org/abs/2212.01944) | 提出了一个算法GLM2FSA，能够自动从任务目标的简短自然语言描述中提取任务知识并构建一个编码高层次任务知识的有限状态自动机，构建的自动机可以被正式验证。 |
| [^65] | [Continual Learning of Natural Language Processing Tasks: A Survey.](http://arxiv.org/abs/2211.12701) | 本文综述了NLP中持续学习的最新进展，其中CF预防、知识迁移和跨任务类分离等方面对NLP任务至关重要，并讨论了未来研究方向。 |
| [^66] | [Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations.](http://arxiv.org/abs/2211.08794) | 本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。 |
| [^67] | [Streaming Joint Speech Recognition and Disfluency Detection.](http://arxiv.org/abs/2211.08726) | 本研究提出了一种实时联合语音识别和语言不流畅检测的方法，可以利用声学信息使不流畅检测具有鲁棒性，并提供非语言线索，降低了延迟和推理负担。多任务模型的输出可以实现高准确率的不流畅检测，并避免由于不流畅引起的识别错误，提高了整体语音识别的准确度。 |
| [^68] | [Easy to Decide, Hard to Agree: Reducing Disagreements Between Saliency Methods.](http://arxiv.org/abs/2211.08369) | 本文介绍了利用显著性方法揭示神经NLP模型黑匣子，协议评估并不能保证可靠性，通过使用Pearson-r更适合的替代方案实现一致性，同时通过正则化技术提高注意力解释的忠实度。 |
| [^69] | [FolkScope: Intention Knowledge Graph Construction for E-commerce Commonsense Discovery.](http://arxiv.org/abs/2211.08316) | 本文提出了FolkScope意图知识图谱构建框架，该框架使用大型语言模型和人机交互注释构建知识图谱，用于揭示有关购买物品的人类思维结构。 |
| [^70] | [Towards Understanding Omission in Dialogue Summarization.](http://arxiv.org/abs/2211.07145) | 本篇论文提出了OLDS数据集，用于为对话摘要提供高质量的省略标签。通过分析该数据集，发现通过为摘要模型提供真实省略标签，并在摘要过程中显式地建模和解决省略问题，可以大幅提高摘要质量。 |
| [^71] | [Fine-Tuning Language Models via Epistemic Neural Networks.](http://arxiv.org/abs/2211.01568) | 本文介绍了一种使用启示神经网络（ENN）来优先考虑有信息价值数据进行微调语言模型的方法，这种方法可以使用更少的标签数据实现更好的性能表现，同时在各种类型的神经网络模型中使用 ENN 都比常规的启发式主动学习方案表现更优。 |
| [^72] | [Composition, Attention, or Both?.](http://arxiv.org/abs/2210.12958) | 本文提出了一种名为“组合注意力语法”（CAGs）的新型结构，该结构通过组合函数将子树递归地组合为单个向量表示，并通过自我注意机制选择性地关注先前的结构信息；结果表明，组合函数和自我注意机制都发挥了重要作用，使LMs更加类似于人类，并允许句法特征而不允许语义特征渗透到子树表示中。 |
| [^73] | [Investigating self-supervised, weakly supervised and fully supervised training approaches for multi-domain automatic speech recognition: a study on Bangladeshi Bangla.](http://arxiv.org/abs/2210.12921) | 本研究研究了自监督、弱监督和完全监督的训练方法对多领域自动语音识别的影响，并且证明了在构建语料库时领域选择的重要性。 |
| [^74] | [Semantic Framework based Query Generation for Temporal Question Answering over Knowledge Graphs.](http://arxiv.org/abs/2210.04490) | 本论文提出了一种基于语义框架的知识图谱时间问答查询生成方法，受到时间约束的限制，有效地提高了问答能力。 |
| [^75] | [Using Full-Text Content to Characterize and Identify Best Seller Books.](http://arxiv.org/abs/2210.02334) | 该研究通过对书籍的全文内容进行可视化和分类任务，研究预测书籍是否会成为畅销书。使用了 SemAxis 和线性判别分析进行数据初步探索，采用多种分类器获得定量和更加客观的结果。 |
| [^76] | [Pre-trained Language Models for the Legal Domain: A Case Study on Indian Law.](http://arxiv.org/abs/2209.06049) | 本研究针对印度法律文本，重新训练和从零开始训练了两个PLMs，即LegalBERT和CaseLawBERT，并采用基于印度法律文本的词汇表训练了一个模型。我们在几项基准法律NLP任务中，对印度和非印度的法律文本进行了应用。 |
| [^77] | [Minority Stress Experienced by LGBTQ Online Communities during the COVID-19 Pandemic.](http://arxiv.org/abs/2205.09511) | 研究探究了LGBTQ在线社群在COVID-19疫情期间经历的少数群体压力。利用机器学习分类器检测Twitter上表现出的少数群体压力，比较疫情前后的语言差异。 |
| [^78] | [Estimating the Personality of White-Box Language Models.](http://arxiv.org/abs/2204.12000) | 本文评估了多个大规模语言模型的人格特征，填补了推断和改变这些模型所继承人格特征方面的空白。 |
| [^79] | [Analysing similarities between legal court documents using natural language processing approaches based on Transformers.](http://arxiv.org/abs/2204.07182) | 本文尝试通过利用六种基于Transformer的自然语言处理技术，基于巴西葡萄牙语的通用语料库预训练，利用210,000份法律诉讼文档进行微调和专业化训练，解决法律文件相似度问题，从而协助快速解决司法程序。 |
| [^80] | [Language modeling via stochastic processes.](http://arxiv.org/abs/2203.11370) | 本篇论文探究了对比表示在生成任务中的应用，提出了Time Control(TC)方法，可以保留长文本的结构，并在学习句子表示以获得话语连贯性方面表现竞争力。 |
| [^81] | [Application of Quantum Density Matrix in Classical Question Answering and Classical Image Classification.](http://arxiv.org/abs/2203.11155) | 该论文将量子密度矩阵应用于经典问答和图像分类中，证明了其可以提高任务的效率，尤其在图像分类中取得了优秀的性能表现。 |
| [^82] | [Modeling Human Sentence Processing with Left-Corner Recurrent Neural Network Grammars.](http://arxiv.org/abs/2109.04939) | 分层结构与左角架构是人类句子处理更具认知可信度的模型。 |
| [^83] | [An Efficient Transformer Decoder with Compressed Sub-layers.](http://arxiv.org/abs/2101.00542) | 该论文提出了一种使用压缩子层的高效Transformer解码器，通过减少子层并提高并行性能够达到1.42倍的速度提升，同时确保性能与基线相当。 |
| [^84] | [Categorical Vector Space Semantics for Lambek Calculus with a Relevant Modality.](http://arxiv.org/abs/2005.03074) | 本文为Lambek演算引入了一个相关模态!L*，并通过构建具有余代数模态的范畴向量空间语义学给出了该模态下的短语派生方法。 |

# 详细

[^1]: 通用多语言文档编码器

    A General-Purpose Multilingual Document Encoder. (arXiv:2305.07016v1 [cs.CL])

    [http://arxiv.org/abs/2305.07016](http://arxiv.org/abs/2305.07016)

    本文提出了一种通用的大规模多语言文档编码器，使用维基百科作为数据来源，并采用跨语言对比目标进行训练，可用于监督和非监督文档级任务。

    

    大规模多语言预训练转换器（MMTs）已经极大地推动了多语言NLP和特别是NLP模型的跨语言转移的最新进展。尽管许多工作利用MMTs来挖掘平行数据和诱导双语文档嵌入，但很少有工作专门用于训练通用（大规模）多语言文档编码器，可用于监督和非监督文档级任务。在本文中，我们预先训练了一种大规模多语言文档编码器，作为一个分层转换器模型（HMDE），其中一个浅层文档转换器对最先进的预先训练的多语言句子编码器产生的句子表示进行上下文处理。我们利用维基百科作为可用的可比较文件源来创建训练数据，并通过跨语言对比目标来训练HMDE，进一步利用维基百科的类别层次结构来创建难以区分的负样本。

    Massively multilingual pretrained transformers (MMTs) have tremendously pushed the state of the art on multilingual NLP and cross-lingual transfer of NLP models in particular. While a large body of work leveraged MMTs to mine parallel data and induce bilingual document embeddings, much less effort has been devoted to training general-purpose (massively) multilingual document encoder that can be used for both supervised and unsupervised document-level tasks. In this work, we pretrain a massively multilingual document encoder as a hierarchical transformer model (HMDE) in which a shallow document transformer contextualizes sentence representations produced by a state-of-the-art pretrained multilingual sentence encoder. We leverage Wikipedia as a readily available source of comparable documents for creating training data, and train HMDE by means of a cross-lingual contrastive objective, further exploiting the category hierarchy of Wikipedia for creation of difficult negatives. We evaluate 
    
[^2]: 区域感知预训练：视觉变压器下的开放词汇物体检测

    Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers. (arXiv:2305.07011v1 [cs.CV])

    [http://arxiv.org/abs/2305.07011](http://arxiv.org/abs/2305.07011)

    本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。

    

    本文提出了区域感知开放词汇视觉变压器（RO-ViT），一种对比图像-文本预训练方法，旨在填补图像级预训练和开放词汇物体检测之间的差距。在预训练阶段，我们建议随机裁剪并调整位置嵌入的区域，而不是使用整个图像位置嵌入。这更好地匹配了检测微调阶段中区域级别上使用位置嵌入的方式。此外，我们用聚焦损失替换了对比学习中常用的softmax交叉熵损失，以更好地学习那些有信息量但难以捕捉的例子。最后，我们利用了最近在新颖物体提案方面的进展，以改进开放词汇检测的微调。我们在LVIS和COCO开放词汇检测基准上评估了完整模型和零-shot转移性能。RO-ViT在LVIS上实现了32.1$AP_r$的最佳效果，超过现有最佳方法5.8个百分点，同时还具有竞争性的零-shot转移检测结果。

    We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a contrastive image-text pretraining recipe to bridge the gap between image-level pretraining and open-vocabulary object detection. At the pretraining phase, we propose to randomly crop and resize regions of positional embeddings instead of using the whole image positional embeddings. This better matches the use of positional embeddings at region-level in the detection finetuning phase. In addition, we replace the common softmax cross entropy loss in contrastive learning with focal loss to better learn the informative yet difficult examples. Finally, we leverage recent advances in novel object proposals to improve open-vocabulary detection finetuning. We evaluate our full model on the LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer. RO-ViT achieves a state-of-the-art 32.1 $AP_r$ on LVIS, surpassing the best existing approach by +5.8 points in addition to competitive zero-shot transfer detec
    
[^3]: 子词级分段机器翻译：统一分词和目标句子生成

    Subword Segmental Machine Translation: Unifying Segmentation and Target Sentence Generation. (arXiv:2305.07005v1 [cs.CL])

    [http://arxiv.org/abs/2305.07005](http://arxiv.org/abs/2305.07005)

    子词级分段机器翻译（SSMT）是一种将子词分割和MT在一个可训练模型中统一起来的方法，它学习分割目标句子词，同时联合学习生成目标句子。在6个翻译方向的实验中表明，SSMT提高了词素丰富的聚集性语言的chrF分数，且具有更高的鲁棒性。

    

    子词分词器（如BPE）在神经机器翻译和其他（条件）语言模型中作为预处理步骤。在训练之前应用它们于数据集上，因此翻译或文本生成的质量取决于分词的质量。我们提出了一种称为子词级分段机器翻译（SSMT）的偏离于此范例的方法。SSMT将子词分割和MT在一个可训练模型中统一起来。它学习分割目标句子词，同时联合学习生成目标句子。为了在推理过程中使用SSMT，我们提出了动态解码，这是一种随着生成翻译适应分割的文本生成算法。在6个翻译方向的实验表明，SSMT提高了词素丰富的聚集性语言的chrF分数。增益在非常低资源的情况下最强。与基准相比，SSMT还学习到了更接近语素的子词，并且在用于评估形态的测试集上证明了更大的鲁棒性。

    Subword segmenters like BPE operate as a preprocessing step in neural machine translation and other (conditional) language models. They are applied to datasets before training, so translation or text generation quality relies on the quality of segmentations. We propose a departure from this paradigm, called subword segmental machine translation (SSMT). SSMT unifies subword segmentation and MT in a single trainable model. It learns to segment target sentence words while jointly learning to generate target sentences. To use SSMT during inference we propose dynamic decoding, a text generation algorithm that adapts segmentations as it generates translations. Experiments across 6 translation directions show that SSMT improves chrF scores for morphologically rich agglutinative languages. Gains are strongest in the very low-resource scenario. SSMT also learns subwords that are closer to morphemes compared to baselines and proves more robust on a test set constructed for evaluating morphologic
    
[^4]: LLM 不同语言的性能表现不一: 通过跨语言思维提示提高多语言能力

    Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting. (arXiv:2305.07004v1 [cs.CL])

    [http://arxiv.org/abs/2305.07004](http://arxiv.org/abs/2305.07004)

    该论文介绍了一种跨语言思维提示方法，名为XLT，用于提高LLMs的多语言能力。该方法能够显著提高各种多语言任务性能，并减少不同语言中任务性能的差距。

    

    大型语言模型(LLMs)展示了令人印象深刻的多语言能力，但它们的性能在不同语言之间具有显著差异。在这项工作中，我们介绍了一种简单但有效的方法，称为跨语言思维提示(XLT)，以系统地提高LLMs的多语言能力。具体而言，XLT是一个通用的模板提示，可以刺激跨语言和逻辑推理技能，以增强不同语言的任务性能。我们在涵盖高资源和低资源语言的7个典型推理、理解和生成任务的全面评估上进行了全面的评估。实验结果表明，XLT不仅显著提高了各种多语言任务的性能，而且还显著减少了不同语言中每个任务平均性能和最佳性能之间的差距。值得注意的是，XLT在算术推理和开放域问答方面带来了超过10个百分点的平均改进。

    Large language models (LLMs) demonstrate impressive multilingual capability, but their performance varies substantially across different languages. In this work, we introduce a simple yet effective method, called cross-lingual-thought prompting (XLT), to systematically improve the multilingual capability of LLMs. Specifically, XLT is a generic template prompt that stimulates cross-lingual and logical reasoning skills to enhance task performance across languages. We conduct comprehensive evaluations on 7 typical benchmarks related to reasoning, understanding, and generation tasks, covering both high-resource and low-resource languages. Experimental results show that XLT not only remarkably enhances the performance of various multilingual tasks but also significantly reduces the gap between the average performance and the best performance of each task in different languages. Notably, XLT brings over 10 points of average improvement in arithmetic reasoning and open-domain question-answeri
    
[^5]: 推荐系统作为指令遵循的方法：大型语言模型增强的推荐方法

    Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach. (arXiv:2305.07001v1 [cs.IR])

    [http://arxiv.org/abs/2305.07001](http://arxiv.org/abs/2305.07001)

    采用大型语言模型以指令遵循为方法的推荐系统，可以将用户偏好或需求进行自然语言描述，进而提高推荐精度。

    

    在过去几十年中，推荐系统在研究和产业社区中引起了广泛关注，并且许多研究致力于开发有效的推荐模型。这些模型主要从历史行为数据中学习潜在的用户偏好，进而估计用户-项目匹配关系以进行推荐。受到大型语言模型（LLMs）近期进展的启发，我们采用了一种不同的方法来开发推荐模型，将推荐视为LLMs的指令遵循。关键思想是用户的偏好或需求可以用自然语言描述（称为指令）来表达，从而LLMs可以理解并进一步执行指令以达到推荐任务的目的。我们通过指令微调开源LLM（3B Flan-T5-XL）来开发推荐方法，以更好地使LLMs适应推荐系统。为此，我们首先提出了一种转换方法，将用户行为数据转化为指令，并在大规模电子商务数据集上评估了提出的方法。实验结果表明，我们的方法优于几种最先进的推荐方法，在推荐准确性方面取得了显着的改进。

    In the past decades, recommender systems have attracted much attention in both research and industry communities, and a large number of studies have been devoted to developing effective recommendation models. Basically speaking, these models mainly learn the underlying user preference from historical behavior data, and then estimate the user-item matching relationships for recommendations. Inspired by the recent progress on large language models (LLMs), we take a different approach to developing the recommendation models, considering recommendation as instruction following by LLMs. The key idea is that the preferences or needs of a user can be expressed in natural language descriptions (called instructions), so that LLMs can understand and further execute the instruction for fulfilling the recommendation task. Instead of using public APIs of LLMs, we instruction tune an open-source LLM (3B Flan-T5-XL), in order to better adapt LLMs to recommender systems. For this purpose, we first des
    
[^6]: SMATCH++: 语义图的标准化和扩展评估

    SMATCH++: Standardized and Extended Evaluation of Semantic Graphs. (arXiv:2305.06993v1 [cs.CL])

    [http://arxiv.org/abs/2305.06993](http://arxiv.org/abs/2305.06993)

    SMATCH++是一个用于语义图标准化和扩展评估的方法，通过将度量分为预处理、对齐和评分三个模块，解决了当前度量存在的问题，提高了对齐的安全性。

    

    Smatch度量是评估图形距离的流行方法，例如评估语义图解析系统的性能。然而，我们观察到该度量存在一些问题，如不透明的预处理选择可能会影响结果，当前的图形对齐解算器没有提供上界。然而，没有上界，公平的评估不能保证。此外，Smatch的自适应扩展任务（例如，细粒度语义相似性）分散，并缺乏统一的框架。为了更好地检查，我们将度量分为三个模块：预处理、对齐和评分。检查每个模块，我们指定它的目标并诊断潜在问题，为此我们讨论并测试缓解策略。对于预处理，我们展示如何完全符合允许结构不同但有效的图形注释指南。为了更安全和增强的对齐，我们展示了使用流形算法的可行性。

    The Smatch metric is a popular method for evaluating graph distances, as is necessary, for instance, to assess the performance of semantic graph parsing systems. However, we observe some issues in the metric that jeopardize meaningful evaluation. E.g., opaque pre-processing choices can affect results, and current graph-alignment solvers do not provide us with upper-bounds. Without upper-bounds, however, fair evaluation is not guaranteed. Furthermore, adaptions of Smatch for extended tasks (e.g., fine-grained semantic similarity) are spread out, and lack a unifying framework.  For better inspection, we divide the metric into three modules: pre-processing, alignment, and scoring. Examining each module, we specify its goals and diagnose potential issues, for which we discuss and test mitigation strategies. For pre-processing, we show how to fully conform to annotation guidelines that allow structurally deviating but valid graphs. For safer and enhanced alignment, we show the feasibility o
    
[^7]: 自我链式图像语言模型用于视频定位与问答

    Self-Chained Image-Language Model for Video Localization and Question Answering. (arXiv:2305.06988v1 [cs.CV])

    [http://arxiv.org/abs/2305.06988](http://arxiv.org/abs/2305.06988)

    SeViLA是一个利用单个图像语言模型的框架，在视频定位和问答方面表现出色，通过自我链接策略训练局部化器和回答器模块以定位最具信息的关键帧以回答问题。

    

    最近的研究显示，利用预训练的图像语言模型进行视频问答能够取得良好的结果。虽然这些图像语言模型可以有效启动视频语言模型的表示学习，但它们通常将均匀采样的视频帧作为视觉输入进行串接，而未进行显式的语言感知和时间建模。当视频输入中只有一部分与语言查询相关时，这种均匀帧采样通常会导致重要的视觉线索丢失。尽管人类通常会找到视频中要关注的片段并倒带片刻来回答问题，但训练一个明确的视频片段局部化器通常需要昂贵的注释和高计算成本。为了解决这个问题，我们提出了SeViLA框架，利用单个图像语言模型（BLIP-2）来处理视频的时间关键帧定位和问答。SeViLA框架包括两个模块：局部化器和回答器，两者共享相同的图像语言模型，并通过自我链接策略进行训练，以定位最具信息量的帧以回答给定的问题。在TVQA、TVR和How2QA数据集上的实验结果表明，SeViLA显著优于最先进的方法，且使用更少的参数和注释就能达到竞争性的性能。

    Recent studies have shown promising results on utilizing pre-trained image-language models for video question answering. While these image-language models can efficiently bootstrap the representation learning of video-language models, they typically concatenate uniformly sampled video frames as visual inputs without explicit language-aware, temporal modeling. When only a portion of a video input is relevant to the language query, such uniform frame sampling can often lead to missing important visual cues. Although humans often find a video moment to focus on and rewind the moment to answer questions, training a query-aware video moment localizer often requires expensive annotations and high computational costs. To address this issue, we propose Self-Chained Video Localization-Answering (SeViLA), a novel framework that leverages a single image-language model (BLIP-2) to tackle both temporal keyframe localization and QA on videos. SeViLA framework consists of two modules: Localizer and A
    
[^8]: 在大语言模型时代评估开放领域问答

    Evaluating Open-Domain Question Answering in the Era of Large Language Models. (arXiv:2305.06984v1 [cs.CL])

    [http://arxiv.org/abs/2305.06984](http://arxiv.org/abs/2305.06984)

    本文评估了开放领域问答中的大语言模型，发现词汇匹配作为评估方法在这些模型中的作用有限，提出了一种手动评估方法，并发现其中一个零-shot模型的性能大幅度提升。

    

    词汇匹配仍是开放领域问答（QA）的事实评估方法。然而，当一个合理的候选答案未出现在金标准答案列表中时，词汇匹配完全失败，随着我们从抽取模型转向生成模型，这种情况越来越普遍。大语言模型（LLMs）在QA中的最近成功加剧了词汇匹配的失败，因为候选答案变得更长，因此与金标准答案的匹配变得更加具有挑战性。缺乏准确的评估，开放领域QA的真正进展仍然未知。本文通过在NQ-open的一个子集上手动评估各种开放领域QA模型（包括LLMs）的答案进行了彻底分析。我们的评估揭示，尽管所有模型的真实性能被显着低估，但InstructGPT（零-shot）LLM的性能增加了近60％，使其与现有的顶级模型并驾齐驱，而I

    Lexical matching remains the de facto evaluation method for open-domain question answering (QA). Unfortunately, lexical matching fails completely when a plausible candidate answer does not appear in the list of gold answers, which is increasingly the case as we shift from extractive to generative models. The recent success of large language models (LLMs) for QA aggravates lexical matching failures since candidate answers become longer, thereby making matching with the gold answers even more challenging. Without accurate evaluation, the true progress in open-domain QA remains unknown. In this paper, we conduct a thorough analysis of various open-domain QA models, including LLMs, by manually evaluating their answers on a subset of NQ-open, a popular benchmark. Our assessments reveal that while the true performance of all models is significantly underestimated, the performance of the InstructGPT (zero-shot) LLM increases by nearly +60%, making it on par with existing top models, and the I
    
[^9]: 主动检索增强生成

    Active Retrieval Augmented Generation. (arXiv:2305.06983v1 [cs.CL])

    [http://arxiv.org/abs/2305.06983](http://arxiv.org/abs/2305.06983)

    本论文提出了一种主动检索增强生成的方法，与以往的方法相比，它在生成过程中更紧密地集成了主动检索和生成，并展示了在一组句子生成任务中的性能优势。

    

    尽管大型语言模型（LM）具有理解和生成语言的卓越能力，它们往往会产生虚假的和错误的输出。从外部知识资源中检索信息来增强LM是一种有前途的解决方案。大多数现有的检索增强的LM采用一种检索和生成的设置，仅基于输入一次检索信息。然而，在涉及生成长文本的更普遍的场景中，通过在生成过程中不断地收集信息是至关重要的。过去有一些检索信息，同时生成输出的努力，大多数都是使用前一个上下文作为查询，在固定的时间间隔内检索文档。在这项工作中，我们提供了一个主动检索增强生成的广义视图，即在整个生成过程中主动决定何时以及何时从哪里检索信息的方法。我们提出了前瞻性主动检索增强生成（FLARE），它通过允许生成器在每个步骤中主动查询检索组件来更紧密地集成主动检索和生成。FLARE在一组句子生成任务中优于以前的方法，展示了主动检索在整个生成过程中的好处。

    Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval-augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout the generation process is essential. There have been some past efforts to retrieve information multiple times while generating outputs, which mostly retrieve documents at fixed intervals using the previous context as queries. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval aug
    
[^10]: 人类仍然比ChatGPT更优秀：以IEEEXtreme编程竞赛为例

    Humans are Still Better than ChatGPT: Case of the IEEEXtreme Competition. (arXiv:2305.06934v1 [cs.SE])

    [http://arxiv.org/abs/2305.06934](http://arxiv.org/abs/2305.06934)

    本文展示了一个对传统认识的颠覆性观点：在计算机编程领域的典型ChatGPT任务中，人类程序员仍然比ChatGPT更优秀。

    

    自从ChatGPT发布以来，许多研究已经突出了ChatGPT的卓越性能，它在各种任务和领域中往往可以与甚至超越人类能力。然而，本文通过展示人类表现优异的实例，提出了一个对立的观点，特别是在计算机编程领域的典型ChatGPT任务中。我们将IEEExtreme编程挑战赛作为基准进行全面评估，这是一个包含各种复杂度问题的知名国际编程竞赛。为了进行彻底的评估，我们选择了102个来自五个不同IEEExtreme版本的挑战，使用三种主要编程语言Python、Java和C++进行执行。我们的经验分析提供了证据，证明与普遍认为的相反，人类程序员在编程环境中的问题解决的某些方面上仍然具有竞争优势。

    Since the release of ChatGPT, numerous studies have highlighted the remarkable performance of ChatGPT, which often rivals or even surpasses human capabilities in various tasks and domains. However, this paper presents a contrasting perspective by demonstrating an instance where human performance excels in typical tasks suited for ChatGPT, specifically in the domain of computer programming. We utilize the IEEExtreme Challenge competition as a benchmark, a prestigious, annual international programming contest encompassing a wide range of problems with different complexities. To conduct a thorough evaluation, we selected and executed a diverse set of 102 challenges, drawn from five distinct IEEExtreme editions, using three major programming languages: Python, Java, and C++. Our empirical analysis provides evidence that contrary to popular belief, human programmers maintain a competitive edge over ChatGPT in certain aspects of problem-solving within the programming context. In fact, we fou
    
[^11]: AfriQA：针对非洲语言的跨语言开放检索问答

    AfriQA: Cross-lingual Open-Retrieval Question Answering for African Languages. (arXiv:2305.06897v1 [cs.CL])

    [http://arxiv.org/abs/2305.06897](http://arxiv.org/abs/2305.06897)

    AfriQA是第一个专注于非洲语言的跨语言QA数据集，弥补了非洲语言数字化内容不足的问题。实验结果表明自动翻译和多语言检索模型的性能较差，需要支持跨语言推理和转移学习的模型。

    

    数字化的非洲语言内容远远不足，这使得问答系统难以满足用户的信息需求。跨语言开放检索问答（XOR QA）系统--这些系统可以在为人们提供本地语言服务的同时从其他语言中获取答案内容--提供了一种填补这一差距的手段。为此，我们创建了AfriQA，这是第一个专注于非洲语言的跨语言QA数据集。AfriQA包括10种非洲语言的12,000多个XOR QA示例。尽管先前的数据集主要关注交叉语言QA增强目标语言覆盖范围的语言，但AfriQA侧重于交叉语言答案内容是唯一高覆盖范围答案内容的语言。因此，我们认为非洲语言是XOR QA中最重要和最现实的用例之一。我们的实验证明了自动翻译和多语言检索系统在我们的数据集上表现不佳，突显了需要支持跨语言推理和转移学习的模型。

    African languages have far less in-language content available digitally, making it challenging for question answering systems to satisfy the information needs of users. Cross-lingual open-retrieval question answering (XOR QA) systems -- those that retrieve answer content from other languages while serving people in their native language -- offer a means of filling this gap. To this end, we create AfriQA, the first cross-lingual QA dataset with a focus on African languages. AfriQA includes 12,000+ XOR QA examples across 10 African languages. While previous datasets have focused primarily on languages where cross-lingual QA augments coverage from the target language, AfriQA focuses on languages where cross-lingual answer content is the only high-coverage source of answer content. Because of this, we argue that African languages are one of the most important and realistic use cases for XOR QA. Our experiments demonstrate the poor performance of automatic translation and multilingual retri
    
[^12]: IUST_NLP在SemEval-2023任务10中的应用：使用Transformer和任务自适应预训练进行可解释的性别歧视检测

    IUST_NLP at SemEval-2023 Task 10: Explainable Detecting Sexism with Transformers and Task-adaptive Pretraining. (arXiv:2305.06892v1 [cs.CL])

    [http://arxiv.org/abs/2305.06892](http://arxiv.org/abs/2305.06892)

    本研究使用Transformer和任务自适应预训练设计了自动系统来检测和分类在线空间中的性别歧视内容，通过集成学习与大量未标记数据的自适应预训练提高模型性能，在SemEval-2023任务10中表现良好，达到了83％，64％和47％的F1得分。

    

    本文介绍了我们在SemEval-2023任务10中的系统：在线性别歧视的可解释性检测（EDOS）。本研究旨在设计一种自动系统，用于检测和分类在线空间中的性别歧视内容。我们提出了一组基于Transformer的预训练模型，以及任务自适应预训练和集成学习。我们系统的主要贡献包括分析不同基于Transformer的预训练模型的性能并结合这些模型，以及提供有效的方法，使用大量未标记的数据进行模型的自适应预训练。我们还探索了几种其他策略。在测试数据集上，我们的系统在子任务A，B和C上分别达到了83％，64％和47％的F1得分。

    This paper describes our system on SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS). This work aims to design an automatic system for detecting and classifying sexist content in online spaces. We propose a set of transformer-based pre-trained models with task-adaptive pretraining and ensemble learning. The main contributions of our system include analyzing the performance of different transformer-based pre-trained models and combining these models, as well as providing an efficient method using large amounts of unlabeled data for model adaptive pretraining. We have also explored several other strategies. On the test dataset, our system achieves F1-scores of 83%, 64%, and 47% on subtasks A, B, and C, respectively.
    
[^13]: 三思而后行：衡量消除问答模型预测快捷方式的效率

    Think Twice: Measuring the Efficiency of Eliminating Prediction Shortcuts of Question Answering Models. (arXiv:2305.06841v1 [cs.CL])

    [http://arxiv.org/abs/2305.06841](http://arxiv.org/abs/2305.06841)

    研究提出了一种衡量模型依赖已知虚假特征的技术，并评估了预先训练的问答模型和去偏置方法对大量已知和新发现的预测偏差的鲁棒性。其发现去偏置方法不能通过减轻对偏差特征的依赖来解释OOD收益，表明偏差在QA数据集中共享。

    

    尽管大规模语言模型（Large Language Models，LLMs）主导了大部分语言理解任务，在训练数据集的建模假混淆的支持下, 因此有先前的工作表明，某些这些结果是由建模虚假相关性实现的。作者常常通过评估同一任务的分布外（OOD）数据集上的模型来评估模型的健壮性，但这些数据集可能具有与训练数据集相同的偏差。我们提出了一种衡量模型依赖于任何已知虚假特征的尺度的简单方法，并评估预先训练的模型和去偏置方法在问答（QA）中对大量已知和新发现的预测偏差的鲁棒性。我们发现去偏置方法的报告OOD收益不能通过减轻对有偏特征的依赖来解释，这表明偏差在QA数据集中共享。我们通过测量OOD模型的表现取决于偏差特征，与ID模型相当，进而证明了这一点，这推动了未来的研究。

    While the Large Language Models (LLMs) dominate a majority of language understanding tasks, previous work shows that some of these results are supported by modelling spurious correlations of training datasets. Authors commonly assess model robustness by evaluating their models on out-of-distribution (OOD) datasets of the same task, but these datasets might share the bias of the training dataset.  We propose a simple method for measuring a scale of models' reliance on any identified spurious feature and assess the robustness towards a large set of known and newly found prediction biases for various pre-trained models and debiasing methods in Question Answering (QA). We find that the reported OOD gains of debiasing methods can not be explained by mitigated reliance on biased features, suggesting that biases are shared among QA datasets. We further evidence this by measuring that performance of OOD models depends on bias features comparably to the ID model, motivating future work to refin
    
[^14]: 探索悬疑的计算机分析：检测危险情境

    Towards a Computational Analysis of Suspense: Detecting Dangerous Situations. (arXiv:2305.06818v1 [cs.CL])

    [http://arxiv.org/abs/2305.06818](http://arxiv.org/abs/2305.06818)

    本文引入一个文本语料库，其中标注了危险情境及角色的恐惧，通过实验发现无监督的基础方法可以提供有价值的信号来检测这些情境，但要进一步深入分析需要更复杂的方法，因为危险和恐惧的描述在很大程度上依赖于上下文。

    

    悬疑是保持读者参与并想继续阅读的重要工具。然而，计算机文学研究领域对此尚未深入研究。本文着重探讨作者可以利用来增加悬疑的元素之一：危险情境。我们引入了一个文本语料库，其中标注了危险情境，分辨了7种类型的危险。此外，我们还标注了文本中描述角色所经历的恐惧的部分，不管实际上存在危险与否。我们进行了自动检测这些情境的实验，并发现无监督的基础方法可以提供有价值的信号，但进一步分析需要更复杂的方法。不出所料，危险和恐惧的描述在很大程度上依赖于上下文，无论是局部的(例如，只提到但实际上并不存在危险的情境)还是全局的(例如，“风暴”在字面上使用的情境)。

    Suspense is an important tool in storytelling to keep readers engaged and wanting to read more. However, it has so far not been studied extensively in Computational Literary Studies. In this paper, we focus on one of the elements authors can use to build up suspense: dangerous situations. We introduce a corpus of texts annotated with dangerous situations, distinguishing between 7 types of danger. Additionally, we annotate parts of the text that describe fear experienced by a character, regardless of the actual presence of danger. We present experiments towards the automatic detection of these situations, finding that unsupervised baseline methods can provide valuable signals for the detection, but more complex methods are necessary for further analysis. Not unexpectedly, the description of danger and fear often relies heavily on the context, both local (e.g., situations where danger is only mentioned, but not actually present) and global (e.g., "storm" being used in a literal sense in 
    
[^15]: THUIR@COLIEE 2023：更多参数和法律知识用于法律案例蕴含问题

    THUIR@COLIEE 2023: More Parameters and Legal Knowledge for Legal Case Entailment. (arXiv:2305.06817v1 [cs.CL])

    [http://arxiv.org/abs/2305.06817](http://arxiv.org/abs/2305.06817)

    本文描述了THUIR团队在COLIEE 2023法律案例蕴涵任务中的方法，尝试了传统的词汇匹配方法和预训练语言模型，并采用学习排序方法进一步提高性能，结果表明更多的参数和法律知识对法律案例蕴涵任务有所贡献。

    

    本文描述了THUIR团队在COLIEE 2023法律案例蕴涵任务中的方法。该任务要求参与者从给定的支持案例中识别一个特定段落，该段落蕴含了查询案例的决定。我们尝试了传统的词汇匹配方法和具有不同大小的预训练语言模型，进一步采用学习排序方法提高性能。然而，学习排序方法在这个任务中并不是很健壮，这表明答案段落不能简单地通过信息检索技术确定。实验结果表明，更多的参数和法律知识对法律案例的蕴涵任务有所贡献。最后，我们在COLIEE 2023比赛中获得第三名。我们的方法的实现可以在https://github.com/CSHaitao/THUIR-COLIEE2023找到。

    This paper describes the approach of the THUIR team at the COLIEE 2023 Legal Case Entailment task. This task requires the participant to identify a specific paragraph from a given supporting case that entails the decision for the query case. We try traditional lexical matching methods and pre-trained language models with different sizes. Furthermore, learning-to-rank methods are employed to further improve performance. However, learning-to-rank is not very robust on this task. which suggests that answer passages cannot simply be determined with information retrieval techniques. Experimental results show that more parameters and legal knowledge contribute to the legal case entailment task. Finally, we get the third place in COLIEE 2023. The implementation of our method can be found at https://github.com/CSHaitao/THUIR-COLIEE2023.
    
[^16]: THUIR@COLIEE 2023: 将结构化知识融入预训练语言模型中用于法律案例检索

    THUIR@COLIEE 2023: Incorporating Structural Knowledge into Pre-trained Language Models for Legal Case Retrieval. (arXiv:2305.06812v1 [cs.IR])

    [http://arxiv.org/abs/2305.06812](http://arxiv.org/abs/2305.06812)

    本文总结了THUIR在COLIEE 2023比赛中的冠军方案，其将结构化知识融入预训练语言模型，提出启发式预处理和后处理方法，采用学习排序方法进行特征合并，实验结果显示其具有卓越的优势。

    

    法律案例检索技术在现代智能法律系统中起着重要作用，而作为一项年度知名国际比赛，COLIEE旨在实现针对法律文本的最先进检索模型。本文总结了冠军团队THUIR在COLIEE 2023的方法，具体而言，我们设计了结构感知的预训练语言模型以增强对法律案例的理解。此外，我们还提出了启发式预处理和后处理方法以减少无关信息的影响。最后，我们采用学习排序方法将具有不同维度的特征合并。实验结果表明我们的方案具有卓越的优势，官方结果显示我们的运行效果在所有提交中表现最佳。我们的方法实现可在https://github.com/CSHaitao/THUIR-COLIEE2023找到。

    Legal case retrieval techniques play an essential role in modern intelligent legal systems. As an annually well-known international competition, COLIEE is aiming to achieve the state-of-the-art retrieval model for legal texts. This paper summarizes the approach of the championship team THUIR in COLIEE 2023. To be specific, we design structure-aware pre-trained language models to enhance the understanding of legal cases. Furthermore, we propose heuristic pre-processing and post-processing approaches to reduce the influence of irrelevant messages. In the end, learning-to-rank methods are employed to merge features with different dimensions. Experimental results demonstrate the superiority of our proposal. Official results show that our run has the best performance among all submissions. The implementation of our method can be found at https://github.com/CSHaitao/THUIR-COLIEE2023.
    
[^17]: 基于定义表示学习的诊疗术语中习语性多词表达式检测

    Detecting Idiomatic Multiword Expressions in Clinical Terminology using Definition-Based Representation Learning. (arXiv:2305.06801v1 [cs.CL])

    [http://arxiv.org/abs/2305.06801](http://arxiv.org/abs/2305.06801)

    本文提出了一种基于定义表示学习的方法，用于检测诊疗术语中的习语性多词表达式，加强了UMLS本体和生物医学语言模型的翻译效率。

    

    本文探讨了基于定义语义模型在诊疗术语中检测习语性和半习语性多词表达式（MWEs）的潜力。研究聚焦于UMLS本体中定义的生物医学实体，并旨在帮助优先翻译这些实体。具体来说，我们开发了一种有效的工具，用于评分生物医学MWEs的习语性，该工具基于那些MWEs的语义表示和其组成部分的表示的加权平均值之间的相似度。我们使用经过训练的生物医学语言模型BioLORD实现了这一目标。与两个基于Transformer的最先进的生物医学语言模型SapBERT和CODER相比，定义表示方法的重要性得到了凸显。我们的研究结果表明BioLORD模型具有较强的识别习语MWEs的能力，不重复。

    This paper shines a light on the potential of definition-based semantic models for detecting idiomatic and semi-idiomatic multiword expressions (MWEs) in clinical terminology. Our study focuses on biomedical entities defined in the UMLS ontology and aims to help prioritize the translation efforts of these entities. In particular, we develop an effective tool for scoring the idiomaticity of biomedical MWEs based on the degree of similarity between the semantic representations of those MWEs and a weighted average of the representation of their constituents. We achieve this using a biomedical language model trained to produce similar representations for entity names and their definitions, called BioLORD. The importance of this definition-based approach is highlighted by comparing the BioLORD model to two other state-of-the-art biomedical language models based on Transformer: SapBERT and CODER. Our results show that the BioLORD model has a strong ability to identify idiomatic MWEs, not rep
    
[^18]: COCKATIEL:用可解释元素对NLP任务中的神经网络分类器进行连续概念排名带归因性解释

    COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP tasks. (arXiv:2305.06754v1 [cs.CL])

    [http://arxiv.org/abs/2305.06754](http://arxiv.org/abs/2305.06754)

    COCKATIEL是一种连续概念排名带归因性解释的技术，基于概念，用于从NLP分类任务的神经网络模型的最后一层中生成有意义的解释，且不会影响准确性或需要新模型，已证明比现有方法产生更有信息量和可靠的解释。

    

    Transformer结构复杂，其在NLP中的使用虽然取得了许多成功，但其可解释性或可解释性较为棘手。最近的争论表明，注意力图和归因方法不可靠，而我们在本文中介绍了其中一些局限性，同时介绍了COCKATIEL这一新型的模型无关的可解释性技术，它是一种后期方法，基于概念，用于从经过NLP分类任务训练的神经网络模型的最后一层中生成有意义的解释，通过使用非负矩阵分解(NMF)来发现模型利用来进行预测的概念，并利用敏感性分析来准确估计每个概念对模型的重要性，而不会影响底层模型的准确性或需要训练新模型。我们在单一和多方面的情感分析中进行实验，证明COCKATIEL比现有方法产生更有信息量和可靠的解释。

    Transformer architectures are complex and their use in NLP, while it has engendered many successes, makes their interpretability or explainability challenging. Recent debates have shown that attention maps and attribution methods are unreliable (Pruthi et al., 2019; Brunner et al., 2019). In this paper, we present some of their limitations and introduce COCKATIEL, which successfully addresses some of them. COCKATIEL is a novel, post-hoc, concept-based, model-agnostic XAI technique that generates meaningful explanations from the last layer of a neural net model trained on an NLP classification task by using Non-Negative Matrix Factorization (NMF) to discover the concepts the model leverages to make predictions and by exploiting a Sensitivity Analysis to estimate accurately the importance of each of these concepts for the model. It does so without compromising the accuracy of the underlying model or requiring a new one to be trained. We conduct experiments in single and multi-aspect sent
    
[^19]: 库尔德手语的第一个平行语料库

    The First Parallel Corpora for Kurdish Sign Language. (arXiv:2305.06747v1 [cs.CL])

    [http://arxiv.org/abs/2305.06747](http://arxiv.org/abs/2305.06747)

    该论文介绍了首个用于库尔德手语和口语库尔德之间平行翻译的数据集，并使用统计翻译技术进行了自动翻译，结果准确率为53.8%。

    

    库尔德手语(KuSL)是库尔德聋人的自然语言。我们致力于自动翻译口头库尔德语和KuSL之间的文本。手语语言的发展速度很快，并且遵循与口语语言不同的语法规则。因此，在任何翻译中，应考虑这些差异。我们提出了一种基于头像的Kurdish Sorani方言文本自动翻译成Kurdish Sign Language的方法。我们开发了该语言对的第一个平行语料库，用于训练统计机器翻译(SMT)引擎。我们使用双语评估验算(BLEU)测试了输出的可理解性并进行了评估。结果显示53.8%的准确率。与该领域以前的实验相比，结果相当高。我们怀疑原因是两个对的结构的相似性。我们计划在Kurdish-BLARK上以CC BY-NC-SA 4.0许可证公开资源。

    Kurdish Sign Language (KuSL) is the natural language of the Kurdish Deaf people. We work on automatic translation between spoken Kurdish and KuSL. Sign languages evolve rapidly and follow grammatical rules that differ from spoken languages. Consequently,those differences should be considered during any translation. We proposed an avatar-based automatic translation of Kurdish texts in the Sorani (Central Kurdish) dialect into the Kurdish Sign language. We developed the first parallel corpora for that pair that we use to train a Statistical Machine Translation (SMT) engine. We tested the outcome understandability and evaluated it using the Bilingual Evaluation Understudy (BLEU). Results showed 53.8% accuracy. Compared to the previous experiments in the field, the result is considerably high. We suspect the reason to be the similarity between the structure of the two pairs. We plan to make the resources publicly available under CC BY-NC-SA 4.0 license on the Kurdish-BLARK (https://kurdish
    
[^20]: 基于 Transformer Albertina PT-* 提升葡萄牙语的神经编码

    Advancing Neural Encoding of Portuguese with Transformer Albertina PT-*. (arXiv:2305.06721v1 [cs.CL])

    [http://arxiv.org/abs/2305.06721](http://arxiv.org/abs/2305.06721)

    本研究使用基于 Transformer 的 Albertina PT-* 模型进行了葡萄牙语的神经编码，创新性地提升了该语言在数字时代的技术准备水平，尤其是欧洲葡萄牙语和巴西的美洲葡萄牙语两个变种。

    

    本研究旨在推进葡萄牙语（PT）的神经编码，为该语言在数字时代的技术准备打下基础。我们开发了基于 Transformer 的 Albertina PT-* 基础模型，为其两个变种（葡萄牙的欧洲葡萄牙语（PT-PT）和巴西的美洲葡萄牙语（PT-BR））的神经编码创下了新的技术水平。我们使用一种强大的模型作为起点，即DeBERTa，并使用我们收集的PT-PT数据集和brWaC语料库对其进行预训练。我们通过对适用于葡萄牙语的著名下游语言处理任务进行评估，来评估Albertina和竞争模型的性能。 Albertina PT-PT和PT-BR版本均可免费分发，并在最宽松的许可以下运行于消费级硬件。

    To advance the neural encoding of Portuguese (PT), and a fortiori the technological preparation of this language for the digital age, we developed a Transformer-based foundation model that sets a new state of the art in this respect for two of its variants, namely European Portuguese from Portugal (PT-PT) and American Portuguese from Brazil (PT-BR).  To develop this encoder, which we named Albertina PT-*, a strong model was used as a starting point, DeBERTa, and its pre-training was done over data sets of Portuguese, namely over a data set we gathered for PT-PT and over the brWaC corpus for PT-BR. The performance of Albertina and competing models was assessed by evaluating them on prominent downstream language processing tasks adapted for Portuguese.  Both Albertina PT-PT and PT-BR versions are distributed free of charge and under the most permissive license possible and can be run on consumer-grade hardware, thus seeking to contribute to the advancement of research and innovation in l
    
[^21]: 面向基于跨度的序列标注的成本效益众包：工人选择和数据增强

    Cost-efficient Crowdsourcing for Span-based Sequence Labeling: Worker Selection and Data Augmentation. (arXiv:2305.06683v1 [cs.CL])

    [http://arxiv.org/abs/2305.06683](http://arxiv.org/abs/2305.06683)

    本文介绍了面向基于跨度的序列标注任务的成本效益众包算法，使用了组合多臂老虎机方法进行工人选择，并用移位、扩展和收缩的数据增强方法进行测试，提高了注释质量和降低成本，F1得分相对于仅专家的基线提高了100.04％，成本节约高达65.97％。

    

    本文介绍了一种新的工人选择算法，提高了自然语言处理中具有挑战性的基于跨度的序列标注任务的注释质量并降低了成本。与以前针对简单任务的研究不同，本研究涉及序列标注任务中的标签相互依赖性复杂性。所提议的算法使用组合多臂老虎机（CMAB）方法进行工人选择。解决了处理不平衡和小规模数据集的挑战，该挑战阻碍了工人选择的离线模拟，使用一种称为移位、扩展和收缩（SES）的创新数据增强方法来解决。SES方法专门为序列标注任务设计。在CoNLL 2003 NER和中文OEI数据集上进行的严格测试展示了算法的效率，F1得分相对于仅专家的基线提高了100.04％，成本节约高达65.97％。本文还包括一个独立于数据集的测试。

    This paper introduces a novel worker selection algorithm, enhancing annotation quality and reducing costs in challenging span-based sequence labeling tasks in Natural Language Processing (NLP). Unlike previous studies targeting simpler tasks, this study contends with the complexities of label interdependencies in sequence labeling tasks. The proposed algorithm utilizes a Combinatorial Multi-Armed Bandit (CMAB) approach for worker selection. The challenge of dealing with imbalanced and small-scale datasets, which hinders offline simulation of worker selection, is tackled using an innovative data augmentation method termed shifting, expanding, and shrinking (SES). The SES method is designed specifically for sequence labeling tasks. Rigorous testing on CoNLL 2003 NER and Chinese OEI datasets showcased the algorithm's efficiency, with an increase in F1 score up to 100.04% of the expert-only baseline, alongside cost savings up to 65.97%. The paper also encompasses a dataset-independent test
    
[^22]: INGENIOUS：使用信息丰富的数据子集对大型语言模型进行高效预训练

    INGENIOUS: Using Informative Data Subsets for Efficient Pre-Training of Large Language Models. (arXiv:2305.06677v1 [cs.CL])

    [http://arxiv.org/abs/2305.06677](http://arxiv.org/abs/2305.06677)

    本文提出了一种使用信息丰富的数据子集来高效预训练大型语言模型的方法，减少了训练时间和计算成本，同时保持了模型的泛化能力。

    

    大型预训练语言模型的显着特点是在其泛化能力和新能力方面随着模型容量和预训练数据集大小的增加而 achieved. 然而，必须认识到这不可避免地导致了过长的训练时间、过高的计算成本和有害的环境影响。本文提出了一种方法，即是否可能仅使用高度信息丰富的训练数据子集来训练 PTLM，并同时保持其下游性能？

    A salient characteristic of large pre-trained language models (PTLMs) is a remarkable improvement in their generalization capability and emergence of new capabilities with increasing model capacity and pre-training dataset size. Consequently, we are witnessing the development of enormous models pushing the state-of-the-art. It is, however, imperative to realize that this inevitably leads to prohibitively long training times, extortionate computing costs, and a detrimental environmental impact. Significant efforts are underway to make PTLM training more efficient through innovations in model architectures, training pipelines, and loss function design, with scant attention being paid to optimizing the utility of training data. The key question that we ask is whether it is possible to train PTLMs by employing only highly informative subsets of the training data while maintaining downstream performance? Building upon the recent progress in informative data subset selection, we show how we 
    
[^23]: QURG: 问题重写引导下的上下文依赖性文本到SQL语义解析

    QURG: Question Rewriting Guided Context-Dependent Text-to-SQL Semantic Parsing. (arXiv:2305.06655v1 [cs.CL])

    [http://arxiv.org/abs/2305.06655](http://arxiv.org/abs/2305.06655)

    QURG是一种帮助文本到SQL语义解析模型实现上下文理解的新颖方法，能在SParC和CoSQL等上下文依赖性数据集上提高模型性能，特别是对于难以处理和长轮次的问题。

    

    上下文依赖性文本到SQL的目标是将多轮自然语言问题翻译成SQL查询语句。本文提出了QURG，一种新颖的问题重写引导方法，以帮助模型实现足够的上下文理解。具体地，我们首先训练一个问题重写模型，在问题上下文的基础上完成当前问题，并将其转换为重写编辑矩阵。我们设计了一个双流矩阵编码器，来共同建模问题和上下文之间的重写关系，以及自然语言和结构化模式之间的模式链接关系。实验结果表明，QURG显著提高了两个大规模上下文依赖性数据集SParC和CoSQL的性能，特别是对于难以处理和长轮次的问题。

    Context-dependent Text-to-SQL aims to translate multi-turn natural language questions into SQL queries. Despite various methods have exploited context-dependence information implicitly for contextual SQL parsing, there are few attempts to explicitly address the dependencies between current question and question context. This paper presents QURG, a novel Question Rewriting Guided approach to help the models achieve adequate contextual understanding. Specifically, we first train a question rewriting model to complete the current question based on question context, and convert them into a rewriting edit matrix. We further design a two-stream matrix encoder to jointly model the rewriting relations between question and context, and the schema linking relations between natural language and structured schema. Experimental results show that QURG significantly improves the performances on two large-scale context-dependent datasets SParC and CoSQL, especially for hard and long-turn questions.
    
[^24]: PROM：基于预训练的短语级复制机制，用于抽象摘要生成

    PROM: A Phrase-level Copying Mechanism with Pre-training for Abstractive Summarization. (arXiv:2305.06647v1 [cs.CL])

    [http://arxiv.org/abs/2305.06647](http://arxiv.org/abs/2305.06647)

    提出了一种新的短语级复制机制-PROM，可以增强对n-gram的注意力，用于具有预训练的零样本摘要生成，大大提高了摘要的质量和可信度。

    

    基于预训练语言模型在抽象摘要生成方面的显著成就，复制机制通过提高事实性、稳定性和整体性能方面的改进证明其有助于这一进程。本文提出一种新的短语级复制机制-PROM，它增强了对n-gram的注意力，可以应用于具有预训练的零样本摘要生成中。PROM添加了一个指示器层，以明确从源中可以复制的n-gram中的令牌，并计算复制预测的辅助损失。实证研究表明，在基准微调中，PROM取得了显著改进。在零样本设置中，PROM用于对原始语料库进行自监督预训练，并在广泛的摘要数据集上提供了新的通用基线。进一步的分析表明，PROM执行更合理的复制并有助于保持忠实度。

    Based on the remarkable achievements of pre-trained language models in abstractive summarization, the copying mechanism has proved helpful by improving the factuality, stability, and overall performance. This work proposes PROM, a new PhRase-level cOpying Mechanism that enhances attention on n-grams, which can be applied to zero-shot summarization with pre-training. PROM adds an indicator layer to explicitly pick up tokens in n-gram that can be copied from the source, and calculates an auxiliary loss for the copying prediction. Empirical studies show that PROM makes significant improvements in fine-tuning on benchmarks. In zero-shot setting, PROM is utilized in the self-supervised pre-training on raw corpora and provides new general baselines on a wide range of summarization datasets. Further analysis shows that PROM performs more reasonable copying and contributes to faithfulness.
    
[^25]: 当多数人是错误的：利用标注者不一致性进行主观任务

    When the Majority is Wrong: Leveraging Annotator Disagreement for Subjective Tasks. (arXiv:2305.06626v1 [cs.CL])

    [http://arxiv.org/abs/2305.06626](http://arxiv.org/abs/2305.06626)

    本文通过预测单个标注者的打分，并结合文本目标群体的预测，模拟了目标群体成员的意见，通过使用他们的人口统计学数据和在线意见预测标注者的打分，在仇恨言论检测等主观任务中提高了模型性能。

    

    在自然语言处理中，虽然通常使用标注者的多数投票来确定标签，但在仇恨言论检测等主观任务中，标注者之间存在不一致性可能反映出群体观点的差异，而不是噪声。因此，仇恨言论检测的一个关键问题是一个语句是否冒犯了它所针对的人群，而这可能只占标注者池的一小部分。本文构建了一个模型，预测可能具有冒犯性文本上每个标注者的打分，并结合文本的预测目标群体来模拟目标群体成员的意见。我们展示了一系列的评估指标，包括提高了22％在预测每个标注者的打分上的性能，提高了33％在预测标注者之间方差上的性能，这提供了下游用来衡量模型不确定性的方法。我们发现可以使用标注者的人口统计信息和其在线意见来预测标注者的打分。

    Though majority vote among annotators is typically used for ground truth labels in natural language processing, annotator disagreement in tasks such as hate speech detection may reflect differences among group opinions, not noise. Thus, a crucial problem in hate speech detection is whether a statement is offensive to the demographic group that it targets, which may constitute a small fraction of the annotator pool. We construct a model that predicts individual annotator ratings on potentially offensive text and combines this information with the predicted target group of the text to model the opinions of target group members. We show gains across a range of metrics, including raising performance over the baseline by 22% at predicting individual annotators' ratings and 33% at predicting variance among annotators, which provides a method of measuring model uncertainty downstream. We find that annotators' ratings can be predicted using their demographic information and opinions on online 
    
[^26]: 区分类比语义以提升连续关系抽取

    Improving Continual Relation Extraction by Distinguishing Analogous Semantics. (arXiv:2305.06620v1 [cs.CL])

    [http://arxiv.org/abs/2305.06620](http://arxiv.org/abs/2305.06620)

    本研究提出了一种针对类比关系的连续抽取模型，通过设计记忆无关的关系原型和记忆增强以克服过拟合问题，进而引入综合训练和焦点知识蒸馏以增强在类比关系上的性能。

    

    连续关系抽取旨在学习不断出现的关系，同时避免遗忘已学习的关系。现有的方法是存储少量典型样本用于重新训练模型以缓解遗忘。然而，反复重放这些样本可能导致过拟合问题。本文对现有方法进行实证研究，发现类比关系严重影响性能。为解决这一问题，我们提出了一种针对类比关系的新型连续抽取模型，具有记忆无关的关系原型和记忆增强等设计，以克服过拟合问题；同时，引入综合训练和焦点知识蒸馏来增强在类比关系上的性能。实验结果表明，我们的模型表现卓越，且能够有效区分类比关系和克服过拟合。

    Continual relation extraction (RE) aims to learn constantly emerging relations while avoiding forgetting the learned relations. Existing works store a small number of typical samples to re-train the model for alleviating forgetting. However, repeatedly replaying these samples may cause the overfitting problem. We conduct an empirical study on existing works and observe that their performance is severely affected by analogous relations. To address this issue, we propose a novel continual extraction model for analogous relations. Specifically, we design memory-insensitive relation prototypes and memory augmentation to overcome the overfitting problem. We also introduce integrated training and focal knowledge distillation to enhance the performance on analogous relations. Experimental results show the superiority of our model and demonstrate its effectiveness in distinguishing analogous relations and overcoming overfitting.
    
[^27]: 序列对比知识蒸馏，用于连续的少样本关系抽取

    Serial Contrastive Knowledge Distillation for Continual Few-shot Relation Extraction. (arXiv:2305.06616v1 [cs.CL])

    [http://arxiv.org/abs/2305.06616](http://arxiv.org/abs/2305.06616)

    本文提出了 SCKD 模型，使用序列知识蒸馏与对比学习，实现连续的少样本关系抽取任务。该方法可以有效解决旧关系遗忘和过度拟合的问题。

    

    连续的少样本关系抽取旨在通过少量标注的训练样本不断地为新关系训练模型，其中最大的挑战是旧关系的灾难性遗忘和由数据稀疏性造成的过度拟合。本文提出了一种新模型SCKD，来完成连续的少样本关系抽取任务。具体来说，我们设计了序列知识蒸馏来保存以前模型的先前知识，并使用伪样本进行对比学习，以保持不同关系样本的表示足够可区分。我们在两个基准数据集上的实验验证了SCKD在连续的少样本关系抽取中的有效性，以及其在知识转移和内存利用方面优于现有技术模型。

    Continual few-shot relation extraction (RE) aims to continuously train a model for new relations with few labeled training data, of which the major challenges are the catastrophic forgetting of old relations and the overfitting caused by data sparsity. In this paper, we propose a new model, namely SCKD, to accomplish the continual few-shot RE task. Specifically, we design serial knowledge distillation to preserve the prior knowledge from previous models and conduct contrastive learning with pseudo samples to keep the representations of samples in different relations sufficiently distinguishable. Our experiments on two benchmark datasets validate the effectiveness of SCKD for continual few-shot RE and its superiority in knowledge transfer and memory utilization over state-of-the-art models.
    
[^28]: 文本中的自相关衰减及语言模型的适用限制

    Autocorrelations Decay in Texts and Applicability Limits of Language Models. (arXiv:2305.06615v1 [cs.CL])

    [http://arxiv.org/abs/2305.06615](http://arxiv.org/abs/2305.06615)

    文本中的自相关衰减与语言模型的适用限制密切相关，生成文本的自相关衰减与文学文本的不同，表现出马尔科夫行为的语言模型可能存在在处理长文本时的局限性。

    

    我们展示了文本中自相关衰减定律与语言模型的适用限制密切相关。使用分布语义学，我们经验性地展示了文本中单词的自相关性按照幂律衰减。我们发现，分布语义学为翻译成多种语言的文本提供了一致的自相关衰减指数。生成文本中的自相关衰减在数量上和质量上通常与文学文本有所不同。我们得出结论，表现出马尔科夫行为的语言模型，包括大型自回归语言模型，在分析或生成长文本时可能存在局限性。

    We show that the laws of autocorrelations decay in texts are closely related to applicability limits of language models. Using distributional semantics we empirically demonstrate that autocorrelations of words in texts decay according to a power law. We show that distributional semantics provides coherent autocorrelations decay exponents for texts translated to multiple languages. The autocorrelations decay in generated texts is quantitatively and often qualitatively different from the literary texts. We conclude that language models exhibiting Markov behavior, including large autoregressive language models, may have limitations when applied to long texts, whether analysis or generation.
    
[^29]: BanglaBook: 一种用于情感分析的大规模孟加拉语书评数据集

    BanglaBook: A Large-scale Bangla Dataset for Sentiment Analysis from Book Reviews. (arXiv:2305.06595v1 [cs.CL])

    [http://arxiv.org/abs/2305.06595](http://arxiv.org/abs/2305.06595)

    BanglaBook 是一个大规模的孟加拉语书评数据集，其中包括 158,065 个样本，针对情感分析分为三个大类，通过使用预训练模型来取代手动构建特征的模型，取得显着的性能优势。

    

    消费者情感分析可以通过评论表达提供有关产品质量的丰富见解。尽管情感分析的研究在许多流行语言中得到了广泛探索，但由于缺乏相关数据和跨领域适应性，相对较少关注孟加拉语言。为了解决这个限制，我们提出了 BanglaBook，这是一个大规模的孟加拉语书评数据集，包括 158,065 个样本，分为三个大类：积极、消极和中性。我们对数据集进行了详细的统计分析，并使用一系列机器学习模型建立了基线，包括 SVM、LSTM 和 Bangla-BERT。我们的研究结果表明，与依赖手动构建特征的模型相比，预训练模型具有显着的性能优势，强调了在此领域需要额外的培训资源。此外，我们通过检查情感错误分类来进行深入的错误分析，并提供有关孟加拉情感分析性质的进一步见解。

    The analysis of consumer sentiment, as expressed through reviews, can provide a wealth of insight regarding the quality of a product. While the study of sentiment analysis has been widely explored in many popular languages, relatively less attention has been given to the Bangla language, mostly due to a lack of relevant data and cross-domain adaptability. To address this limitation, we present BanglaBook, a large-scale dataset of Bangla book reviews consisting of 158,065 samples classified into three broad categories: positive, negative, and neutral. We provide a detailed statistical analysis of the dataset and employ a range of machine learning models to establish baselines including SVM, LSTM, and Bangla-BERT. Our findings demonstrate a substantial performance advantage of pre-trained models over models that rely on manually crafted features, emphasizing the necessity for additional training resources in this domain. Additionally, we conduct an in-depth error analysis by examining se
    
[^30]: FactKG: 通过知识图谱推理进行事实验证

    FactKG: Fact Verification via Reasoning on Knowledge Graphs. (arXiv:2305.06590v1 [cs.CL])

    [http://arxiv.org/abs/2305.06590](http://arxiv.org/abs/2305.06590)

    FactKG是一个新的数据集，通过知识图谱推理进行事实验证，包含108k个自然语言声明和五种推理类型，可帮助社区更好地使用知识图谱进行事实验证。

    

    在现实应用中，知识图谱（KG）在各种领域（如医疗应用和对话代理）中被广泛使用。然而，在事实验证方面，KG尚未充分利用作为知识源。KG可以成为事实验证的有价值的知识来源，因为它们具有可靠性和广泛的适用性。KG由节点和边组成，清晰地展示了概念之间的联系，使得机器可以推理出一系列主题。然而，理解这些机器可读的概念如何映射到文本中的信息存在许多挑战。为了使社区更好地利用KG，我们介绍了一个新的数据集，FactKG:通过知识图谱推理进行事实验证，它包含108k个自然语言声明以及五种推理类型：单跳、合取、存在、多跳和否定。此外，FactKG包含各种语言模式，包括口语风格的声明和书面风格的声明，以提高实用性。

    In real world applications, knowledge graphs (KG) are widely used in various domains (e.g. medical applications and dialogue agents). However, for fact verification, KGs have not been adequately utilized as a knowledge source. KGs can be a valuable knowledge source in fact verification due to their reliability and broad applicability. A KG consists of nodes and edges which makes it clear how concepts are linked together, allowing machines to reason over chains of topics. However, there are many challenges in understanding how these machine-readable concepts map to information in text. To enable the community to better use KGs, we introduce a new dataset, FactKG: Fact Verification via Reasoning on Knowledge Graphs. It consists of 108k natural language claims with five types of reasoning: One-hop, Conjunction, Existence, Multi-hop, and Negation. Furthermore, FactKG contains various linguistic patterns, including colloquial style claims as well as written style claims to increase practica
    
[^31]: SemEval-2023任务2：细粒度多语言命名实体识别（MultiCoNER 2）

    SemEval-2023 Task 2: Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2). (arXiv:2305.06586v1 [cs.CL])

    [http://arxiv.org/abs/2305.06586](http://arxiv.org/abs/2305.06586)

    该论文介绍了SemEval-2023 Task 2的研究发现，任务旨在通过使用MultiCoNER V2数据集，识别12种语言中复杂的细粒度命名实体。最优方法是将外部知识融入transformer模型，最具挑战性的是媒体标题和产品名称等实体类型。

    

    我们介绍了SemEval-2023任务2关于细粒度多语言命名实体识别（MultiCoNER 2）的研究发现。该任务分为13个轨道，重点关注12种语言和单语、多语和嘈杂环境下识别复杂的细粒度命名实体（如WRITTENWORK、VEHICLE、MUSICALGRP）的方法。任务使用MultiCoNER V2数据集，该数据集由Bangla、Chinese、English、Farsi、French、German、Hindi、Italian、Portuguese、Spanish、Swedish和Ukrainian组成，共有220万个实例。MultiCoNER 2是SemEval-2023中最受欢迎的任务之一，吸引了47个队伍提交842个结果，其中34个队伍提交了系统论文。结果表明，媒体标题和产品名称等复杂实体类型是最具挑战性的，将外部知识融入transformer模型的方法取得了最佳性能，并且在Creative Work和Group类别上获得了最大增益，即使使用外部知识仍然具有挑战性。

    We present the findings of SemEval-2023 Task 2 on Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2). Divided into 13 tracks, the task focused on methods to identify complex fine-grained named entities (like WRITTENWORK, VEHICLE, MUSICALGRP) across 12 languages, in both monolingual and multilingual scenarios, as well as noisy settings. The task used the MultiCoNER V2 dataset, composed of 2.2 million instances in Bangla, Chinese, English, Farsi, French, German, Hindi, Italian., Portuguese, Spanish, Swedish, and Ukrainian. MultiCoNER 2 was one of the most popular tasks of SemEval-2023. It attracted 842 submissions from 47 teams, and 34 teams submitted system papers. Results showed that complex entity types such as media titles and product names were the most challenging. Methods fusing external knowledge into transformer models achieved the best performance, and the largest gains were on the Creative Work and Group classes, which are still challenging even with external kn
    
[^32]: 大型语言模型中的字典链提示在翻译中的应用

    Chain-of-Dictionary Prompting Elicits Translation in Large Language Models. (arXiv:2305.06575v1 [cs.CL])

    [http://arxiv.org/abs/2305.06575](http://arxiv.org/abs/2305.06575)

    研究通过在大型语言模型中添加字典链提示的方法来改进低资源语言的翻译能力，实验结果表明能显著提高翻译质量。

    

    大型语言模型(LLMs)在多语言神经机器翻译(MNMT)中表现出惊人的性能，即使没有平行数据也能训练。然而，尽管训练数据量巨大，它们仍然难以翻译稀有词汇，特别是对于低资源语言。更糟糕的是，通常情况下，在低资源语言上，很难检索到相关示范来进行上下文学习，这限制了LLMs在翻译方面的实际应用——我们该如何缓解这个问题？为此，我们提出了一种新的方法，CoD，通过使用多语言字典链为一部分输入单词增加LLMs的先前知识，从而促进LLMs的翻译能力。广泛的实验表明，在FLORES-200全开发测试集上，通过将CoD和ChatGPT相结合，可以获得高达13倍的MNMT ChrF++分数的收益（英语到塞尔维亚语，西里尔字母书写，ChrF ++分数从3.08增加到42.63）。我们进一步展示了该方法在其他数据集上的重要作用。

    Large language models (LLMs) have shown surprisingly good performance in multilingual neural machine translation (MNMT) even when trained without parallel data. Yet, despite the fact that the amount of training data is gigantic, they still struggle with translating rare words, particularly for low-resource languages. Even worse, it is usually unrealistic to retrieve relevant demonstrations for in-context learning with low-resource languages on LLMs, which restricts the practical use of LLMs for translation -- how should we mitigate this problem? To this end, we present a novel method, CoD, which augments LLMs with prior knowledge with the chains of multilingual dictionaries for a subset of input words to elicit translation abilities for LLMs. Extensive experiments indicate that augmenting ChatGPT with CoD elicits large gains by up to 13x ChrF++ points for MNMT (3.08 to 42.63 for English to Serbian written in Cyrillic script) on FLORES-200 full devtest set. We further demonstrate the im
    
[^33]: 一种融合格罗莫夫 - 瓦热斯坦框架的无监督知识图谱实体对齐方法

    A Fused Gromov-Wasserstein Framework for Unsupervised Knowledge Graph Entity Alignment. (arXiv:2305.06574v1 [cs.CL])

    [http://arxiv.org/abs/2305.06574](http://arxiv.org/abs/2305.06574)

    本文提出了一种无监督实体对齐框架 FGWEA ，它利用融合格罗莫夫 - 瓦热斯坦距离，实现了实体语义和知识图谱结构的综合比较和对齐，通过三阶段的渐进优化算法来提高匹配准确性。

    

    实体对齐是在不同知识图谱中识别相应实体的任务。虽然基于嵌入的实体对齐方法已经取得了重大进展，但它们仍然难以充分利用知识图谱结构信息。在本文中，我们引入了FGWEA，这是一种无监督的实体对齐框架，利用融合格罗莫夫 - 瓦热斯坦（FGW）距离，允许在联合优化框架内全面比较实体语义和知识图谱结构。为了解决优化FGW所涉及的计算挑战，我们设计了一个三阶段渐进优化算法。它从基本语义嵌入匹配开始，根据高置信度实体链接的迭代更新，逐步近似跨知识图谱的结构和关系相似性匹配，最终在知识图谱间进行全局结构比较。我们在涵盖14个实体对齐数据集的四个数据集上进行了广泛的实验。

    Entity alignment is the task of identifying corresponding entities across different knowledge graphs (KGs). Although recent embedding-based entity alignment methods have shown significant advancements, they still struggle to fully utilize KG structural information. In this paper, we introduce FGWEA, an unsupervised entity alignment framework that leverages the Fused Gromov-Wasserstein (FGW) distance, allowing for a comprehensive comparison of entity semantics and KG structures within a joint optimization framework. To address the computational challenges associated with optimizing FGW, we devise a three-stage progressive optimization algorithm. It starts with a basic semantic embedding matching, proceeds to approximate cross-KG structural and relational similarity matching based on iterative updates of high-confidence entity links, and ultimately culminates in a global structural comparison between KGs. We perform extensive experiments on four entity alignment datasets covering 14 dist
    
[^34]: 如何为推荐基础模型索引项目ID

    How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])

    [http://arxiv.org/abs/2305.06569](http://arxiv.org/abs/2305.06569)

    本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。

    

    推荐基础模型将推荐任务转换为自然语言任务，利用大型语言模型（LLM）进行推荐。它通过直接生成建议的项目而不是计算传统推荐模型中每个候选项目的排名得分，简化了推荐管道，避免了多段过滤的问题。为了避免在决定要推荐哪些项目时生成过长的文本，为推荐基础模型创建LLM兼容的项目ID是必要的。本研究系统地研究了推荐基础模型的项目索引问题，以P5为代表的主干模型，并使用各种索引方法复制其结果。我们首先讨论了几种微不足道的项目索引方法（如独立索引、标题索引和随机索引）的问题，并表明它们不适用于推荐基础模型，然后提出了一种新的索引方法，称为上下文感知索引。我们表明，这种索引方法在项目推荐准确性和文本生成质量方面优于其他索引方法。

    Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
    
[^35]: LLM驱动的生成式新闻推荐初探

    A First Look at LLM-Powered Generative News Recommendation. (arXiv:2305.06566v1 [cs.IR])

    [http://arxiv.org/abs/2305.06566](http://arxiv.org/abs/2305.06566)

    本文介绍了一种LLM驱动的生成式新闻推荐框架GENRE，它利用预训练语义知识丰富新闻数据，通过从模型设计转移到提示设计提供灵活而统一的解决方案，实现了个性化新闻生成、用户画像和新闻摘要。

    

    个性化的新闻推荐系统已成为用户浏览海量在线新闻内容所必需的工具，然而现有的新闻推荐系统面临着冷启动问题、用户画像建模和新闻内容理解等重大挑战。先前的研究通常通过模型设计遵循一种不灵活的例行程序来解决特定的挑战，但在理解新闻内容和捕捉用户兴趣方面存在局限性。在本文中，我们介绍了GENRE，一种LLM驱动的生成式新闻推荐框架，它利用来自大型语言模型的预训练语义知识来丰富新闻数据。我们的目标是通过从模型设计转移到提示设计来提供一种灵活而统一的新闻推荐解决方案。我们展示了GENRE在个性化新闻生成、用户画像和新闻摘要中的应用。使用各种流行的推荐模型进行的大量实验证明了GENRE的有效性。

    Personalized news recommendation systems have become essential tools for users to navigate the vast amount of online news content, yet existing news recommenders face significant challenges such as the cold-start problem, user profile modeling, and news content understanding. Previous works have typically followed an inflexible routine to address a particular challenge through model design, but are limited in their ability to understand news content and capture user interests. In this paper, we introduce GENRE, an LLM-powered generative news recommendation framework, which leverages pretrained semantic knowledge from large language models to enrich news data. Our aim is to provide a flexible and unified solution for news recommendation by moving from model design to prompt design. We showcase the use of GENRE for personalized news generation, user profiling, and news summarization. Extensive experiments with various popular recommendation models demonstrate the effectiveness of GENRE. 
    
[^36]: 开放世界中的长尾问题回答

    Long-Tailed Question Answering in an Open World. (arXiv:2305.06557v1 [cs.CL])

    [http://arxiv.org/abs/2305.06557](http://arxiv.org/abs/2305.06557)

    本研究提出了一种支持长尾分布数据的Open Long-Tailed QA (OLTQA)模型，鼓励头部、尾部和未知任务间的知识共享，并从大型预训练语言模型中明确挖掘知识，解决了QA方法中瓶颈问题。

    

    现实世界的数据通常具有开放长尾分布，并构建一个统一的QA模型以支持各种任务对于实际的QA应用至关重要。然而，扩展以前的QA方法并不容易，因为它们要么需要访问足够样本的已知任务，要么不明确地对未知任务进行建模。在本文中，我们将Open Long-Tailed QA (OLTQA)定义为学习长尾分布数据并在已知和未知QA任务上优化性能。我们提出了一个OLTQA模型，该模型鼓励头部、尾部和未知任务之间的知识共享，并从大型预训练语言模型中明确挖掘知识。具体而言，我们通过一组细粒度的组件来组织我们的模型，并动态组合这些组件以方便知识共享。进一步引入了一个检索-重排框架来选择上下文例子，这些例子指导LM生成表达QA任务知识的文本。此外，我们还提出了一种新颖的动态池化机制。

    Real-world data often have an open long-tailed distribution, and building a unified QA model supporting various tasks is vital for practical QA applications. However, it is non-trivial to extend previous QA approaches since they either require access to seen tasks of adequate samples or do not explicitly model samples from unseen tasks. In this paper, we define Open Long-Tailed QA (OLTQA) as learning from long-tailed distributed data and optimizing performance over seen and unseen QA tasks. We propose an OLTQA model that encourages knowledge sharing between head, tail and unseen tasks, and explicitly mines knowledge from a large pre-trained language model (LM). Specifically, we organize our model through a pool of fine-grained components and dynamically combine these components for an input to facilitate knowledge sharing. A retrieve-then-rerank frame is further introduced to select in-context examples, which guild the LM to generate text that express knowledge for QA tasks. Moreover, 
    
[^37]: 开放世界下的领域增量生机学习

    Domain Incremental Lifelong Learning in an Open World. (arXiv:2305.06555v1 [cs.CL])

    [http://arxiv.org/abs/2305.06555](http://arxiv.org/abs/2305.06555)

    本文提出了Diana模型，一种基于动态架构的生命周期学习模型，它使用四种层次化组织的提示来学习一系列任务。其中，任务级提示用于捕获任务特定的知识，实例级提示用于学习跨输入样本共享的知识，从而提高模型的泛化性能。

    

    终身学习是NLP模型不断学习新任务的重要能力。基于架构的方法被报道为LL模型的有效实现。然而，将先前的方法扩展到领域增量LL场景并非易事，因为它们要么需要在测试阶段访问任务身份，要么无法处理来自未见任务的样本。在本文中，我们提出Diana：一种基于动态架构的生命周期学习模型，试图通过增强语言模型来学习一系列任务。 Diana使用四种层次化组织的提示来捕获不同粒度的知识。

    Lifelong learning (LL) is an important ability for NLP models to learn new tasks continuously. Architecture-based approaches are reported to be effective implementations for LL models. However, it is non-trivial to extend previous approaches to domain incremental LL scenarios since they either require access to task identities in the testing phase or cannot handle samples from unseen tasks. In this paper, we propose \textbf{Diana}: a \underline{d}ynam\underline{i}c \underline{a}rchitecture-based lifelo\underline{n}g le\underline{a}rning model that tries to learn a sequence of tasks with a prompt-enhanced language model. Four types of hierarchically organized prompts are used in Diana to capture knowledge from different granularities. Specifically, we dedicate task-level prompts to capture task-specific knowledge to retain high LL performances and maintain instance-level prompts to learn knowledge shared across input samples to improve the model's generalization performance. Moreover, w
    
[^38]: GeoGLUE：一个地理语言理解评估基准

    GeoGLUE: A GeoGraphic Language Understanding Evaluation Benchmark. (arXiv:2305.06545v1 [cs.CL])

    [http://arxiv.org/abs/2305.06545](http://arxiv.org/abs/2305.06545)

    GeoGLUE是一个新的地理语言理解评估基准，提供了六个自然语言理解任务并且经过了有效性和重要性的验证。

    

    随着地理应用的快速发展，自动化和智能化的模型是处理大量信息的必要条件。然而，很少有研究者关注地理自然语言处理，也从未建立过一个统一的标准。在这项研究中，我们提出了一个名为GeoGLUE的地理语言理解评估基准。我们从公开发布的地理资源收集数据，并引入六个自然语言理解任务，包括基于回调的地理文本相似度、基于重新排序的地理文本相似度、地理元素标记、地理组合分析、地理何处分离、地理实体对齐。我们还提供了评估实验和一般性基线的分析，表明GeoGLUE基准的有效性和重要性。

    With a fast developing pace of geographic applications, automatable and intelligent models are essential to be designed to handle the large volume of information. However, few researchers focus on geographic natural language processing, and there has never been a benchmark to build a unified standard. In this work, we propose a GeoGraphic Language Understanding Evaluation benchmark, named GeoGLUE. We collect data from open-released geographic resources and introduce six natural language understanding tasks, including geographic textual similarity on recall, geographic textual similarity on rerank, geographic elements tagging, geographic composition analysis, geographic where what cut, and geographic entity alignment. We also pro vide evaluation experiments and analysis of general baselines, indicating the effectiveness and significance of the GeoGLUE benchmark.
    
[^39]: 语义不确定性引导惯例在新指涉物上的推广

    Semantic uncertainty guides the extension of conventions to new referents. (arXiv:2305.06539v1 [cs.CL])

    [http://arxiv.org/abs/2305.06539](http://arxiv.org/abs/2305.06539)

    本研究探讨约定如何转移到与之前完全不同的对象，通过调查可命名性如何影响约定的形成以及新的规则如何泛化到新的指涉目标。

    

    语言心理学的长期研究传统一直在研究指称游戏中的特殊惯例的形成和泛化，展示了新目标的习得的惯例如何转移到新的指涉情境中。但是，另一个广泛化的轴却鲜有研究：当特定词汇选择不太可能重复时，形成的约定如何转移到完全不同的目标。本文介绍了两个双人研究（N=240），着重探讨可命名性的作用——两个个体共享相同标签的先验可能性。我们利用最近发布的KiloGram数据集，该数据集是之前可用数据集规模的数量级，展示了高可命名性等属性的高多样性抽象图案。我们的第一项研究探讨了可命名性如何形成惯例，而第二项则探讨了新的规则如何泛化到完全不同的指涉目标。

    A long tradition of studies in psycholinguistics has examined the formation and generalization of ad hoc conventions in reference games, showing how newly acquired conventions for a given target transfer to new referential contexts. However, another axis of generalization remains understudied: how do conventions formed for one target transfer to completely distinct targets, when specific lexical choices are unlikely to repeat? This paper presents two dyadic studies (N = 240) that address this axis of generalization, focusing on the role of nameability -- the a priori likelihood that two individuals will share the same label. We leverage the recently-released KiloGram dataset, a collection of abstract tangram images that is orders of magnitude larger than previously available, exhibiting high diversity of properties like nameability. Our first study asks how nameability shapes convention formation, while the second asks how new conventions generalize to entirely new targets of reference
    
[^40]: KGA: 基于知识差异对齐的通用机器遗忘框架

    KGA: A General Machine Unlearning Framework Based on Knowledge Gap Alignment. (arXiv:2305.06535v1 [cs.CL])

    [http://arxiv.org/abs/2305.06535](http://arxiv.org/abs/2305.06535)

    本文提出了基于知识差异对齐的通用机器遗忘框架KGA，实现了文本场景中的遗忘功能，并在多个NLP任务中进行了实验验证。

    

    近期《被遗忘权》立法引起了机器遗忘的研究兴趣，其中学习模型具有忘记有关特定训练实例信息的功能，就像它们从未存在于训练集中一样。以往的工作主要关注于计算机视觉场景，并且在NLP领域中忽略了遗忘的要素，文本数据比图像包含更多明确且敏感的个人信息。本文提出了一个通用的遗忘框架KGA来诱发遗忘。与以往试图恢复梯度或强制模型执行接近于一个特定分布的方法不同，KGA维护分布差异（即，知识差异）。这放宽了分布假设。此外，我们首次将遗忘方法应用于各种NLP任务（即，分类，翻译，响应生成）并提出了几个具有相关性的遗忘评估指标。在语言建模和文本分类任务上的实验表明，我们提出的KGA框架在NLP场景中实现了适当的遗忘。

    Recent legislation of the "right to be forgotten" has led to the interest in machine unlearning, where the learned models are endowed with the function to forget information about specific training instances as if they have never existed in the training set. Previous work mainly focuses on computer vision scenarios and largely ignores the essentials of unlearning in NLP field, where text data contains more explicit and sensitive personal information than images. In this paper, we propose a general unlearning framework called KGA to induce forgetfulness. Different from previous work that tries to recover gradients or forces models to perform close to one specific distribution, KGA maintains distribution differences (i.e., knowledge gap). This relaxes the distribution assumption. Furthermore, we first apply the unlearning method to various NLP tasks (i.e., classification, translation, response generation) and propose several unlearning evaluation metrics with pertinence. Experiments on l
    
[^41]: 商用大型语言模型在非洲语种上表现如何？

    How Good are Commercial Large Language Models on African Languages?. (arXiv:2305.06530v1 [cs.CL])

    [http://arxiv.org/abs/2305.06530](http://arxiv.org/abs/2305.06530)

    本文对商用大型语言模型在跨越不同语言系和地理区域的八种非洲语言上进行了初步分析，结果显示它们在非洲语言上的表现略低。呼吁确保非洲语言在商业大型语言模型中得到充分的重视。

    

    自然语言处理领域最近的进展，促使了大型预训练语言模型的普及。这些模型通过上下文学习表现出良好的性能，即使在未知任务和语言上也能表现出良好的性能。它们也被作为一种语言模型服务的商业API所采用。然而，它们在非洲语种上的表现尚不明确。本文对跨越不同语言系和地理区域的八种非洲语言上的两项任务（机器翻译和文本分类）上商业大型语言模型进行了初步分析。我们的结果表明，商业语言模型在非洲语种上的性能略低。我们还发现它们在文本分类方面的表现更好。总体上，我们的研究呼吁确保非洲语言在商业大型语言模型中得到充分的重视，这也是非洲语种逐渐流行的原因。

    Recent advancements in Natural Language Processing (NLP) has led to the proliferation of large pretrained language models. These models have been shown to yield good performance, using in-context learning, even on unseen tasks and languages. They have also been exposed as commercial APIs as a form of language-model-as-a-service, with great adoption. However, their performance on African languages is largely unknown. We present a preliminary analysis of commercial large language models on two tasks (machine translation and text classification) across eight African languages, spanning different language families and geographical areas. Our results suggest that commercial language models produce below-par performance on African languages. We also find that they perform better on text classification than machine translation. In general, our findings present a call-to-action to ensure African languages are well represented in commercial large language models, given their growing popularity.
    
[^42]: 随机平滑和掩码推理用于提高文本分类的对抗鲁棒性

    Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications. (arXiv:2305.06522v1 [cs.CL])

    [http://arxiv.org/abs/2305.06522](http://arxiv.org/abs/2305.06522)

    该论文介绍了一种新的两阶段框架 RSMI，结合了随机平滑和掩码推理，以提高 NLP 系统的对抗鲁棒性，经过基准数据集测试，相较于现有最先进方法将对抗鲁棒性提高2到3倍。

    

    大规模预训练的语言模型在各种 NLP 任务上表现出色，但它们也被知道对特定的对抗性例子存在脆弱性，因此越来越多关注 NLP 系统的对抗鲁棒性。我们引入了 RSMI，一种新的两阶段框架，它将随机平滑（RS）与掩码推理（MI）相结合，以提高 NLP 系统的对抗鲁棒性。RS将分类器转换为平滑的分类器，以获得稳健的表示，而MI强制模型利用输入序列中一个掩蔽标记的周围上下文。RSMI在基准数据集上比现有最先进方法将对抗鲁棒性提高2到3倍。我们还进行了深入的定性分析，以验证 RSMI 不同阶段的有效性，并通过广泛的消融研究探究其构成部分的影响。通过实证证明 RSMI 的稳定性，我们将其推向实际应用。

    Large-scale pre-trained language models have shown outstanding performance in a variety of NLP tasks. However, they are also known to be significantly brittle against specifically crafted adversarial examples, leading to increasing interest in probing the adversarial robustness of NLP systems. We introduce RSMI, a novel two-stage framework that combines randomized smoothing (RS) with masked inference (MI) to improve the adversarial robustness of NLP systems. RS transforms a classifier into a smoothed classifier to obtain robust representations, whereas MI forces a model to exploit the surrounding context of a masked token in an input sequence. RSMI improves adversarial robustness by 2 to 3 times over existing state-of-the-art methods on benchmark datasets. We also perform in-depth qualitative analysis to validate the effectiveness of the different stages of RSMI and probe the impact of its components through extensive ablations. By empirically proving the stability of RSMI, we put it f
    
[^43]: 多模态上下文化任务计划预测

    Multimodal Contextualized Plan Prediction for Embodied Task Completion. (arXiv:2305.06485v1 [cs.RO])

    [http://arxiv.org/abs/2305.06485](http://arxiv.org/abs/2305.06485)

    本文提出了一种用于具身化完成任务数据集的多模态上下文化任务计划预测方法，并证明能够使用多模态上下文预测更好的计划，另外计划预测和计划执行模块可能相互依赖，完全解耦可能不是理想的。

    

    任务规划是传统机器人系统的重要组成部分，使机器人能够组合细粒度技能来执行更复杂的任务。最近的工作构建系统，将自然语言转换为可执行行动，以在模拟的具身化代理中完成任务，重点是直接预测可通过物理机器人直接执行的低级别行动序列。在本文中，我们转而专注于预测较高层次的计划表示，用于TEACh这样的具身化完成任务数据集，假设从自然语言中获得高层次计划预测的技术预计对物理机器人系统更具可转移性。我们证明可以使用多模态上下文预测更好的计划，并且计划预测和计划执行模块可能相互依赖，因此完全解耦可能不是理想的。此外，我们对理想计划的执行进行基准测试，以量化计划预测的改进空间。

    Task planning is an important component of traditional robotics systems enabling robots to compose fine grained skills to perform more complex tasks. Recent work building systems for translating natural language to executable actions for task completion in simulated embodied agents is focused on directly predicting low level action sequences that would be expected to be directly executable by a physical robot. In this work, we instead focus on predicting a higher level plan representation for one such embodied task completion dataset - TEACh, under the assumption that techniques for high-level plan prediction from natural language are expected to be more transferable to physical robot systems. We demonstrate that better plans can be predicted using multimodal context, and that plan prediction and plan execution modules are likely dependent on each other and hence it may not be ideal to fully decouple them. Further, we benchmark execution of oracle plans to quantify the scope for improv
    
[^44]: 一种将印度语文本翻译成Bharti盲文字符的模型

    A Model for Translation of Text from Indian Languages to Bharti Braille Characters. (arXiv:2305.06475v1 [cs.CL])

    [http://arxiv.org/abs/2305.06475](http://arxiv.org/abs/2305.06475)

    本文介绍了一种将主要印度语言文本转换成Bharti盲文字符的方案，其采用混合方法并通过LSTM模型解决歧义，测试表明该模型产生了接近准确的结果。

    

    视力受损者在学习时面临很多困难，其中一大原因是缺乏Bharti盲文脚本的可用文本。本文提出了一种将主要印度语言的文本转换为Bharti盲文的方案。该系统采用混合方法，首先将印度语文本输入到基于规则的系统中，如有任何歧义，则通过应用基于LSTM的模型解决。开发的模型也经过测试，并被发现产生了接近准确的结果。

    People who are visually impaired face a lot of difficulties while studying. One of the major causes to this is lack of available text in Bharti Braille script. In this paper, we have suggested a scheme to convert text in major Indian languages into Bharti Braille. The system uses a hybrid approach where at first the text in Indian language is given to a rule based system and in case if there is any ambiguity then it is resolved by applying a LSTM based model. The developed model has also been tested and found to have produced near accurate results.
    
[^45]: ChatGPT式的大规模基础模型在预测与健康管理中的应用：综述与路线图

    ChatGPT-Like Large-Scale Foundation Models for Prognostics and Health Management: A Survey and Roadmaps. (arXiv:2305.06472v1 [cs.LG])

    [http://arxiv.org/abs/2305.06472](http://arxiv.org/abs/2305.06472)

    该论文综述了基于大规模基础模型（LSF-Models）如ChatGPT和DALLE-E的人工智能（AI）技术在预测与健康管理（PHM）中的广泛应用。这种技术可以实现多模态、多任务、大量数据和超大模型范式，成为AI-2.0的新时代的标志之一。

    

    预测与健康管理技术在工业生产和设备维护中扮演着至关重要的角色，通过基于人工智能的PHM技术识别和预测设备故障和损坏。现在，基于大规模基础模型（LSF-Models）如ChatGPT和DALLE-E的AI技术，可以实现多模态、多任务、大规模数据和超大模型范式，成为AI-2.0的新时代的标志之一。这种技术广泛应用于各种工业领域，如铁路、能源和航空等，以提高设备的服务寿命和可靠性，同时降低生产成本和停机时间。

    Prognostics and health management (PHM) technology plays a critical role in industrial production and equipment maintenance by identifying and predicting possible equipment failures and damages, thereby allowing necessary maintenance measures to be taken to enhance equipment service life and reliability while reducing production costs and downtime. In recent years, PHM technology based on artificial intelligence (AI) has made remarkable achievements in the context of the industrial IoT and big data, and it is widely used in various industries, such as railway, energy, and aviation, for condition monitoring, fault prediction, and health management. The emergence of large-scale foundation models (LSF-Models) such as ChatGPT and DALLE-E marks the entry of AI into a new era of AI-2.0 from AI-1.0, where deep models have rapidly evolved from a research paradigm of single-modal, single-task, and limited-data to a multi-modal, multi-task, massive data, and super-large model paradigm. ChatGPT r
    
[^46]: 基于词语的图卷积网络

    Word Grounded Graph Convolutional Network. (arXiv:2305.06434v1 [cs.CL])

    [http://arxiv.org/abs/2305.06434](http://arxiv.org/abs/2305.06434)

    该论文提出了一种基于词语的图卷积网络模型，可以在处理图外文档时进行归纳推理；该模型在多个基准数据集上表现出较好的性能，同时表明了基于图的方法联合建模词级和文档级信息的有效性。

    

    图卷积网络（GCNs）在学习文本表示方面表现出较强的性能，特别是在建模图结构数据（如文献引用网络）方面，对于各种任务如文本分类等都有良好的表现。大多数现有的GCNs仅限于处理预定义图中的文档，即不能推广到图外文档。为了解决这个问题，我们提出将文档图转化为词图，通过使用独立于文档的图来解耦数据样本（即训练和测试集中的文档）和GCN模型。这种基于词级的GCN因此可以自然地归纳地推理出图外文档。提出了基于WGraph的归纳词语图卷积网络（WGCN），它可以对单词级文本实例（如不在语料库中的文档）进行归纳推理。在四个基准数据集上的实验表明，WGCN优于现有方法，通过图形方法联合建模词级和文档级信息的有效性。

    Graph Convolutional Networks (GCNs) have shown strong performance in learning text representations for various tasks such as text classification, due to its expressive power in modeling graph structure data (e.g., a literature citation network). Most existing GCNs are limited to deal with documents included in a pre-defined graph, i.e., it cannot be generalized to out-of-graph documents. To address this issue, we propose to transform the document graph into a word graph, to decouple data samples (i.e., documents in training and test sets) and a GCN model by using a document-independent graph. Such word-level GCN could therefore naturally inference out-of-graph documents in an inductive way. The proposed Word-level Graph (WGraph) can not only implicitly learning word presentation with commonly-used word co-occurrences in corpora, but also incorporate extra global semantic dependency derived from inter-document relationships (e.g., literature citations). An inductive Word-grounded Graph 
    
[^47]: 机器人还是人类？用一个问题检测ChatGPT冒名顶替者

    Bot or Human? Detecting ChatGPT Imposters with A Single Question. (arXiv:2305.06424v1 [cs.CL])

    [http://arxiv.org/abs/2305.06424](http://arxiv.org/abs/2305.06424)

    本文提出了一个名为FLAIR的框架，通过一个问题和回答来检测ChatGPT中的聊天机器人真实性，可以分类人和机器人。单问题分为对于人类而言容易但对于机器人很难和对于机器人而言容易但对于人类很难两个类别，分别进行检测。 在多个数据集上实现了最先进的性能。

    

    大型语言模型如ChatGPT最近展示了令人瞩目的自然语言理解和生成能力，使得翻译、写作和闲聊等各种应用成为可能。然而，人们担心它们可能被滥用于欺诈或拒绝服务攻击等恶意用途。因此，开发检测聊天中涉及的另一方是机器人还是人类的方法至关重要。本文提出了一个名为FLAIR的框架，即通过单个问题和回答来查找大型语言模型的真实性，以在线方式检测会话中的对话机器人。具体而言，我们针对一个单一问题场景，该场景可以有效地区分人类用户和机器人。这些问题分为两类：对于人类而言容易但对于机器人很难（例如计数、替换、定位、噪音过滤和ASCII艺术），以及对于机器人而言容易但对于人类很难（例如机器生成文本识别）。我们在多个基准数据集上评估了FLAIR，并在机器人检测方面实现了最先进的性能。

    Large language models like ChatGPT have recently demonstrated impressive capabilities in natural language understanding and generation, enabling various applications including translation, essay writing, and chit-chatting. However, there is a concern that they can be misused for malicious purposes, such as fraud or denial-of-service attacks. Therefore, it is crucial to develop methods for detecting whether the party involved in a conversation is a bot or a human. In this paper, we propose a framework named FLAIR, Finding Large language model Authenticity via a single Inquiry and Response, to detect conversational bots in an online manner. Specifically, we target a single question scenario that can effectively differentiate human users from bots. The questions are divided into two categories: those that are easy for humans but difficult for bots (e.g., counting, substitution, positioning, noise filtering, and ASCII art), and those that are easy for bots but difficult for humans (e.g., m
    
[^48]: 自动化神经科患者出院小结医院过程的方法

    A Method to Automate the Discharge Summary Hospital Course for Neurology Patients. (arXiv:2305.06416v1 [cs.CL])

    [http://arxiv.org/abs/2305.06416](http://arxiv.org/abs/2305.06416)

    开发了一种使用编码器-解码器序列到序列变换模型进行医院过程小结的自动化方法以缓解医生过劳。该方法在实际性上进行了优化，盲评估表明62%的自动化摘要符合标准，具有临床应用的潜力。

    

    自动化临床笔记的生成被提出作为缓解医生过劳的策略。具体来说，病人住院期间自动化叙述性摘要可作为住院医生在电子病历系统中记录的出院小结中的医院过程部分的补充。在本研究中，我们开发并评估了一种使用编码器-解码器序列到序列变换模型进行医院过程小结的自动化方法。我们对BERT和BART模型进行了微调并通过限制波束搜索进行了实际性优化，采用了从学术医疗中心神经科病人的电子病历数据进行训练和测试。该方法表现出良好的ROUGE分数和13.76的R-2。在盲评估中，两位董事会认证的医生评价62%的自动化摘要符合标准，这表明该方法可能在临床上有用。据我们所知，这项研究是其中之一。

    Generation of automated clinical notes have been posited as a strategy to mitigate physician burnout. In particular, an automated narrative summary of a patient's hospital stay could supplement the hospital course section of the discharge summary that inpatient physicians document in electronic health record (EHR) systems. In the current study, we developed and evaluated an automated method for summarizing the hospital course section using encoder-decoder sequence-to-sequence transformer models. We fine tuned BERT and BART models and optimized for factuality through constraining beam search, which we trained and tested using EHR data from patients admitted to the neurology unit of an academic medical center. The approach demonstrated good ROUGE scores with an R-2 of 13.76. In a blind evaluation, two board-certified physicians rated 62% of the automated summaries as meeting the standard of care, which suggests the method may be useful clinically. To our knowledge, this study is among th
    
[^49]: LACoS-BLOOM：采用对比学习目标的低秩自适应方法

    LACoS-BLOOM: Low-rank Adaptation with Contrastive objective on 8 bits Siamese-BLOOM. (arXiv:2305.06404v1 [cs.CL])

    [http://arxiv.org/abs/2305.06404](http://arxiv.org/abs/2305.06404)

    本文提出了一种新的文本嵌入模型LACoS-BLOOM，采用低秩自适应方法、对比学习目标和Siamese架构，能够生成语义上有意义的单词嵌入。

    

    文本嵌入是几种自然语言处理应用程序的有用特征，例如句子相似性、文本聚类和语义搜索。本文介绍了一种采用对比学习目标的低秩自适应方法，在具有8位Siamese-BLOOM的基础上进行，该模型优化以生成语义上有意义的单词嵌入。

    Text embeddings are useful features for several NLP applications, such as sentence similarity, text clustering, and semantic search. In this paper, we present a Low-rank Adaptation with a Contrastive objective on top of 8-bit Siamese-BLOOM, a multilingual large language model optimized to produce semantically meaningful word embeddings. The innovation is threefold. First, we cast BLOOM weights to 8-bit values. Second, we fine-tune BLOOM with a scalable adapter (LoRA) and 8-bit Adam optimizer for sentence similarity classification. Third, we apply a Siamese architecture on BLOOM model with a contrastive objective to ease the multi-lingual labeled data scarcity. The experiment results show the quality of learned embeddings from LACoS-BLOOM is proportional to the number of model parameters and the amount of unlabeled training data. With the parameter efficient fine-tuning design, we are able to run BLOOM 7.1 billion parameters end-to-end on a single GPU machine with 32GB memory. Compared 
    
[^50]: “可访问的指令跟随机器人”

    Accessible Instruction-Following Agent. (arXiv:2305.06358v1 [cs.AI])

    [http://arxiv.org/abs/2305.06358](http://arxiv.org/abs/2305.06358)

    该研究介绍了UVLN，一种新颖的机器翻译增强框架，用于跨语言视觉-语言导航，其结合了最新的语言模型与图形嵌入技术，旨在将指令跟随代理程序的成功推广到非英语语言，提高其易操作性和可访问性。

    

    人类可以根据环境中的视觉信号和指令合作并完成任务。训练这样的机器人很难，特别是由于对指令的理解和复杂的环境。以英语为中心的语料库使得先前的指令跟随代理程序偏向英语，使其无法应用于使用多种语言甚至是低资源语言的用户。然而，指令跟随代理程序是在假设用户可以观察到环境的模式下进行预训练的，这限制了它的可访问性。在这项工作中，我们试图将指令跟随代理程序的成功推广到非英语语言，并改善其不可操作性和可访问性。我们引入了UVLN (通用视觉-语言导航), 该框架是一种新颖的机器翻译增强框架，用于跨语言视觉-语言导航，其结合了最新的大型语言模型 (如 GPT3) 与图形嵌入技术。

    Humans can collaborate and complete tasks based on visual signals and instruction from the environment. Training such a robot is difficult especially due to the understanding of the instruction and the complicated environment. Previous instruction-following agents are biased to English-centric corpus, making it unrealizable to be applied to users that use multiple languages or even low-resource languages. Nevertheless, the instruction-following agents are pre-trained in a mode that assumes the user can observe the environment, which limits its accessibility. In this work, we're trying to generalize the success of instruction-following agents to non-English languages with little corpus resources, and improve its intractability and accessibility. We introduce UVLN (Universal Vision-Language Navigation), a novel machine-translation instructional augmented framework for cross-lingual vision-language navigation, with a novel composition of state-of-the-art large language model (GPT3) with t
    
[^51]: 使用GPT-3对医学证据进行总结、简化和综合（成果参差不齐）

    Summarizing, Simplifying, and Synthesizing Medical Evidence Using GPT-3 (with Varying Success). (arXiv:2305.06299v1 [cs.CL])

    [http://arxiv.org/abs/2305.06299](http://arxiv.org/abs/2305.06299)

    本文评估了GPT-3在生物医学领域中生成文章摘要的能力，发现它对单个文章的总结和简化效果较好，但在综合多篇文章中所报告的证据方面表现欠佳。

    

    大型语言模型，特别是GPT-3，能够在几乎没有监督的情况下生成一流的普通领域新闻文章摘要。但是，尚不清楚这样的模型是否在更专业和高风险的领域，如生物医学中同样具备这样的能力。本文中，我们请领域专家（具备医学培训的人）评估由GPT-3生成的生物医学文章摘要，并考虑单一和多文档摘要情况。前者中，GPT-3的任务是生成描述随机对照试验的文章的常规和简明语言摘要；后者中，我们评估GPT-3在整个文章集中综合报告的程度。我们设计了一个注释方案来评估模型输出，并重点评估生成摘要的事实准确性。我们发现，虽然GPT-3能够忠实地总结和简化单个生物医学文章，但它在综合多个文章所提供的证据方面表现不佳。

    Large language models, particularly GPT-3, are able to produce high quality summaries of general domain news articles in few- and zero-shot settings. However, it is unclear if such models are similarly capable in more specialized, high-stakes domains such as biomedicine. In this paper, we enlist domain experts (individuals with medical training) to evaluate summaries of biomedical articles generated by GPT-3, given zero supervision. We consider both single- and multi-document settings. In the former, GPT-3 is tasked with generating regular and plain-language summaries of articles describing randomized controlled trials; in the latter, we assess the degree to which GPT-3 is able to \emph{synthesize} evidence reported across a collection of articles. We design an annotation scheme for evaluating model outputs, with an emphasis on assessing the factual accuracy of generated summaries. We find that while GPT-3 is able to summarize and simplify single biomedical articles faithfully, it stru
    
[^52]: CodeIE: 大型代码生成模型优于少样本信息提取器

    CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors. (arXiv:2305.05711v1 [cs.CL])

    [http://arxiv.org/abs/2305.05711](http://arxiv.org/abs/2305.05711)

    CodeIE提出了使用代码生成模型（Code-LLMs）代替自然语言生成模型（NL-LLMs）对命名实体识别和关系抽取这类信息提取任务进行少样本学习，取得优于几个强基准高达4.5%的绝对精度改进。

    

    在大规模语言模型（LLMs）的预训练方面，已经表现出在许多自然语言处理任务上具有惊人的少样本学习能力。通常的做法是将任务重构为文本到文本的格式，以便自然语言的生成式LLMs（如GPT-3）可以被提示解决它。然而，使用NL-LLMs进行信息提取（IE）任务是不易的，因为IE任务的输出通常是结构化的，因此很难转换成纯文本。我们提出使用代码形式而非自然语言来表达结构化的输出，并利用代码生成LLMs（如Codex）来执行IE任务，特别是命名实体识别和关系抽取。与NL-LLMs相比，我们表明通过设计代码风格的提示和将这些IE任务更改为代码生成任务，Code-LLMs可以与这些IE任务很好地对齐。在七个基准测试上的实验结果表明，我们的方法在少样本学习环境下一直优于几个强基准，并取得了高达4.5%的绝对精度改进。

    Large language models (LLMs) pre-trained on massive corpora have demonstrated impressive few-shot learning ability on many NLP tasks. A common practice is to recast the task into a text-to-text format such that generative LLMs of natural language (NL-LLMs) like GPT-3 can be prompted to solve it. However, it is nontrivial to perform information extraction (IE) tasks with NL-LLMs since the output of the IE task is usually structured and therefore is hard to be converted into plain text. In this paper, we propose to recast the structured output in the form of code instead of natural language and utilize generative LLMs of code (Code-LLMs) such as Codex to perform IE tasks, in particular, named entity recognition and relation extraction. In contrast to NL-LLMs, we show that Code-LLMs can be well-aligned with these IE tasks by designing code-style prompts and formulating these IE tasks as code generation tasks. Experiment results on seven benchmarks show that our method consistently outperf
    
[^53]: SemEval-2023任务7: 临床试验数据的多证据自然语言推理

    SemEval-2023 Task 7: Multi-Evidence Natural Language Inference for Clinical Trial Data. (arXiv:2305.02993v1 [cs.CL])

    [http://arxiv.org/abs/2305.02993](http://arxiv.org/abs/2305.02993)

    本论文介绍SemEval 2023的任务七，旨在进行临床试验数据的多证据自然语言推理，该任务难度较大，证据选择任务相对于蕴含任务表现更佳。

    

    本篇论文介绍SemEval 2023任务7的结果，该任务主要涉及临床试验数据中的多证据自然语言推理（NLI4CT），由两个子任务组成：一个是自然语言推理（NLI）任务，另一个是证据选择任务。这两个任务需要进行医学和数字推理，这对于开发能够进行大规模医疗证据解释和检索、提供个性化基于证据的保健具有重要意义。第1个子任务“蕴含任务”收到了来自40位参赛者的643份提交，第2个子任务“证据选择任务”收到了来自23位参赛者的364份提交。这两个任务具有挑战性，大部分提交的系统在蕴含任务上未能明显优于大多数类基线，而我们观察到证据选择任务的表现明显优于蕴含任务。增加模型参数会导致模型在测试集上表现更差。

    This paper describes the results of SemEval 2023 task 7 -- Multi-Evidence Natural Language Inference for Clinical Trial Data (NLI4CT) -- consisting of 2 tasks, a Natural Language Inference (NLI) task, and an evidence selection task on clinical trial data. The proposed challenges require multi-hop biomedical and numerical reasoning, which are of significant importance to the development of systems capable of large-scale interpretation and retrieval of medical evidence, to provide personalized evidence-based care.  Task 1, the entailment task, received 643 submissions from 40 participants, and Task 2, the evidence selection task, received 364 submissions from 23 participants. The tasks are challenging, with the majority of submitted systems failing to significantly outperform the majority class baseline on the entailment task, and we observe significantly better performance on the evidence selection task than on the entailment task. Increasing the number of model parameters leads to a di
    
[^54]: DiffuSum：基于扩散增强的摘要提取方法

    DiffuSum: Generation Enhanced Extractive Summarization with Diffusion. (arXiv:2305.01735v1 [cs.CL])

    [http://arxiv.org/abs/2305.01735](http://arxiv.org/abs/2305.01735)

    本文提出了一种新的基于扩散模型的摘要提取方法DiffuSum，并且在多个数据集上实现了最先进的抽取结果。

    

    抽取式摘要旨在通过直接从源文件中提取句子来形成摘要。本文提出了DiffuSum，一种基于扩散模型的新范式，通过直接生成所需的摘要句子表示，并基于句子表示匹配提取句子。此外，DiffuSum共同优化了对比句子编码器和匹配损失，用于句子表示对齐，以及用于表示多样性的多类对比损失。实验结果表明，DiffuSum在CNN/DailyMail数据集上实现了新的最先进的抽取结果，在ROUGE分数方面达到了 $44.83/22.56/40.56$。对两个具有不同摘要长度的数据集进行的实验也证明了DiffuSum的有效性。我们的框架的强大性能表明了适应当前情况的巨大潜力。

    Extractive summarization aims to form a summary by directly extracting sentences from the source document. Existing works mostly formulate it as a sequence labeling problem by making individual sentence label predictions. This paper proposes DiffuSum, a novel paradigm for extractive summarization, by directly generating the desired summary sentence representations with diffusion models and extracting sentences based on sentence representation matching. In addition, DiffuSum jointly optimizes a contrastive sentence encoder with a matching loss for sentence representation alignment and a multi-class contrastive loss for representation diversity. Experimental results show that DiffuSum achieves the new state-of-the-art extractive results on CNN/DailyMail with ROUGE scores of $44.83/22.56/40.56$. Experiments on the other two datasets with different summary lengths also demonstrate the effectiveness of DiffuSum. The strong performance of our framework shows the great potential of adapting g
    
[^55]: 基于MLM数据增强的ASR和NLU管道系统应对STOP低资源挑战

    The Pipeline System of ASR and NLU with MLM-based Data Augmentation toward STOP Low-resource Challenge. (arXiv:2305.01194v1 [cs.CL])

    [http://arxiv.org/abs/2305.01194](http://arxiv.org/abs/2305.01194)

    本文介绍了在低资源适应题目中使用的ASR和NLU的管道方法。在ASR中，使用上采样的Whisper对每个领域进行Feine-tune；在NLU中，使用MLM技术进行数据增强并使用基于检索的方法扩充数据。最终，我们在提醒/天气领域获得了高精确匹配准确度并获得了挑战的第一名。

    

    本文描述了我们在ICASSP信号处理大赛2023的口语理解大挑战（Spoken Language Understanding Grand Challenge）低资源领域适应赛道（Track3）中采用的ASR和NLU的管道方法。针对ASR，我们使用上采样 fine-tune Whisper 以适应每个领域。针对NLU，我们 fine-tune BART 在所有 Track3 数据上，然后在低资源域数据上进行 fine-tune。我们应用了基于遮盖的LM（MLM）数据增强，其中一些输入标记和相应的目标标签使用 MLM 进行替换。我们还采用了基于检索的方法，模型输入与类似的训练样本一起进行增强。结果，我们在提醒/天气领域实现了63.3 / 75.0（平均：69.15）的精确匹配（EM）准确度，获得了该挑战的第一名。

    This paper describes our system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023. In the track, we adopt a pipeline approach of ASR and NLU. For ASR, we fine-tune Whisper for each domain with upsampling. For NLU, we fine-tune BART on all the Track3 data and then on low-resource domain data. We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples. As a result, we achieved exact match (EM) accuracy 63.3/75.0 (average: 69.15) for reminder/weather domain, and won the 1st place at the challenge.
    
[^56]: 对Kauhanen、Einhaus和Walkden（2023年）的回应：仍然没有证据证明非母语用户比例对语言复杂度有影响（arXiv:2305.00217v1 [cs.CL]）

    Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023). (arXiv:2305.00217v1 [cs.CL])

    [http://arxiv.org/abs/2305.00217](http://arxiv.org/abs/2305.00217)

    本研究为对Kauhanen、Einhaus和Walkden（2023）的回应，仍然没有证据表明大量的L2用户影响语言复杂性。

    

    近期在《语言进化杂志》发表的一篇论文中，Kauhanen、Einhaus和Walkden（https://doi.org/10.1093/jole/lzad005，KEW）挑战了我在一篇论文中（Koplenig，Royal Society Open Science，6，181274（2019），https://doi.org/10.1098/rsos.181274）所呈现的结果。在该论文中，我试图通过一系列的统计分析来表明大量L2（第二语言）用户似乎不会影响语言的（语法或统计）复杂性。为此，我专注于Ethnologue评估语言地位的方式：如果一种语言除了被L1（第一语言）使用者之外，还应该有大量的L2使用者，那么该语言就被描述为传播性的。KEW批评了将传播性作为语言是否拥有大量L2使用者（二元）指标的使用，以及在直接估计L2比例的情况下，将L2用户比例归为非传播性语言的想法。

    In a recent paper published in the Journal of Language Evolution, Kauhanen, Einhaus & Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the results presented in one of my papers (Koplenig, Royal Society Open Science, 6, 181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show through a series of statistical analyses that large numbers of L2 (second language) speakers do not seem to affect the (grammatical or statistical) complexity of a language. To this end, I focus on the way in which the Ethnologue assesses language status: a language is characterised as vehicular if, in addition to being used by L1 (first language) speakers, it should also have a significant number of L2 users. KEW criticise both the use of vehicularity as a (binary) indicator of whether a language has a significant number of L2 users and the idea of imputing a zero proportion of L2 speakers to non-vehicular languages whenever a direct estimate of that proportion is unavailable. Whi
    
[^57]: ChatGPT/GPT-4研究综述及对大语言模型未来的展望

    Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models. (arXiv:2304.01852v1 [cs.CL])

    [http://arxiv.org/abs/2304.01852](http://arxiv.org/abs/2304.01852)

    本文全面介绍了最先进的大型语言模型ChatGPT和GPT-4，包括其在各个领域的前景应用，并着重介绍了大规模预训练、指令微调和人类反馈的强化学习创新。ChatGPT/GPT-4在自然语言处理应用方面表现突出，同时在其他领域也具有潜力。

    

    本文全面介绍了来自GPT系列的最先进的大型语言模型（LLM）ChatGPT和GPT-4及其在各个领域的前景应用。实际上，大规模预训练、指令微调和人类反馈的强化学习是提高LLMs的适应性和性能的重要创新。我们在arXiv上深入分析了194篇相关文献，包括趋势分析、词云表现和在各个应用领域的分布分析。研究发现ChatGPT/GPT-4研究显著增长，主要集中在直接的自然语言处理应用上，同时还展示了在从教育和历史到数学、医学和物理等领域具有相当的潜力。本研究旨在提供有关ChatGPT的能力的见解。

    This paper presents a comprehensive survey of ChatGPT and GPT-4, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT/GPT-4 research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabi
    
[^58]: Wright-Fisher模型下自包含Beta-with-Spikes逼近的推断方法

    Self-contained Beta-with-Spikes Approximation for Inference Under a Wright-Fisher Model. (arXiv:2303.04691v2 [q-bio.PE] UPDATED)

    [http://arxiv.org/abs/2303.04691](http://arxiv.org/abs/2303.04691)

    本研究提出了一种基于Beta-with-Spikes逼近的Wright-Fisher模型的自包含推断方法，可估算进化参数，稳健性好。

    

    我们构建了一个可靠的估计方法，从时序数据中估算Wright-Fisher模型内的进化参数，该模型描述了由于选择和基因漂变导致的等位基因频率的变化。生物种群的数据存在这样的数据，例如通过人工进化实验，以及行为的文化进化，例如记载带有类似含义的不同单词历史用法的语言文献。我们的分析方法建立在Wright-Fisher模型预测的等位基因频率分布的Beta-with-Spikes逼近基础之上。我们引入了一种自包含的方案来估计逼近中的参数，并用合成数据演示了其在强选择和接近灭绝的情况下的稳健性，这是以前方法失败的地方。我们进一步应用于面包酵母（Saccharomyces cerevisiae）等位基因频率数据，发现了支持独立证据的选择信号。

    We construct a reliable estimation of evolutionary parameters within the Wright-Fisher model, which describes changes in allele frequencies due to selection and genetic drift, from time-series data. Such data exists for biological populations, for example via artificial evolution experiments, and for the cultural evolution of behavior, such as linguistic corpora that document historical usage of different words with similar meanings. Our method of analysis builds on a Beta-with-Spikes approximation to the distribution of allele frequencies predicted by the Wright-Fisher model. We introduce a self-contained scheme for estimating the parameters in the approximation, and demonstrate its robustness with synthetic data, especially in the strong-selection and near-extinction regimes where previous approaches fail. We further apply to allele frequency data for baker's yeast (Saccharomyces cerevisiae), finding a significant signal of selection in cases where independent evidence supports such 
    
[^59]: 字符级别的翻译是否值得等待？将字符级别和子词级别模型用于机器翻译的比较

    Are Character-level Translations Worth the Wait? Comparing Character- and Subword-level Models for Machine Translation. (arXiv:2302.14220v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14220](http://arxiv.org/abs/2302.14220)

    本文比较了字符级别和子词级别的预训练模型在机器翻译方面的效果，结果表明字符级别建模在形似单词和稀有单词的翻译方面具有更好的效果，在训练数据有限的情况下尤为明显。

    

    最近的研究表明，在多种自然语言处理任务中，预先训练的字符级别语言模型与流行的子词模型具有相当的竞争力。然而，对于神经机器翻译方面，它们的有效性鲜有研究。本研究在多种语言和实验条件下，比较了最先进的字符级别和子词级别预训练模型（分别为ByT5和mT5）在机器翻译中的效果，结果表明字符级别建模在翻译方面是有效的，特别是在训练数据有限的情况下。我们的分析表明，字符模型的性能提升在于更好地翻译了形似单词和稀有单词。在评估源文本在驱动模型预测中的重要性时，我们突出ByT5单词级别模式表明字符级别建模的潜在弱点。

    Pretrained character-level language models were recently shown to be competitive with popular subword models across a range of NLP tasks. However, there has been little research on their effectiveness for neural machine translation (NMT). This work performs an extensive comparison across multiple languages and experimental conditions of state-of-the-art character- and subword-level pre-trained models (ByT5 and mT5, respectively) on NMT, showing the effectiveness of character-level modeling in translation, particularly in cases where training data is limited. In our analysis, we show how character models' performance gains are reflected in better translations of orthographically similar words and rare words. While evaluating the importance of source texts in driving model predictions, we highlight ByT5 word-level patterns suggesting an ability to modulate word and character-level information during the translation, providing insights into a potential weakness of character-level modeling
    
[^60]: GPT-3能进行法定推理吗？

    Can GPT-3 Perform Statutory Reasoning?. (arXiv:2302.06100v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.06100](http://arxiv.org/abs/2302.06100)

    本文研究了GPT-3在法定推理任务上的表现，并发现其表现优于之前最佳结果，但仍存在错误。研究还发现GPT-3对实际法规存在缺陷，且在对于合成法规的问题回答表现不佳。

    

    法定推理是一种利用事实和由立法机构用自然语言书写的规则（即法规）进行推理的基本法律技能。本文研究了最强大的GPT-3模型text-davinci-003在一个名为SARA的已建立的法定推理数据集上的能力。我们考虑了各种方法，包括动态少量示例提示、思维链提示和零样本提示。虽然我们取得了比先前最佳发表结果更好的GPT-3结果，但我们也确认了其出现了几种明显的错误。我们调查了这些错误的原因，并发现GPT-3对SARA基于实际美国法规的先验知识存在缺陷。更重要的是，我们创建了简单的合成法规，确保GPT-3在训练期间从未见过。我们发现GPT-3在回答关于这些简单合成法规的直截了当的问题时表现不佳。

    Statutory reasoning is the task of reasoning with facts and statutes, which are rules written in natural language by a legislature. It is a basic legal skill. In this paper we explore the capabilities of the most capable GPT-3 model, text-davinci-003, on an established statutory-reasoning dataset called SARA. We consider a variety of approaches, including dynamic few-shot prompting, chain-of-thought prompting, and zero-shot prompting. While we achieve results with GPT-3 that are better than the previous best published results, we also identify several types of clear errors it makes. We investigate why these errors happen. We discover that GPT-3 has imperfect prior knowledge of the actual U.S. statutes on which SARA is based. More importantly, we create simple synthetic statutes, which GPT-3 is guaranteed not to have seen during training. We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.
    
[^61]: HyPe：使用隐藏表示扰动提高预训练语言模型微调效果

    HyPe: Better Pre-trained Language Model Fine-tuning with Hidden Representation Perturbation. (arXiv:2212.08853v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08853](http://arxiv.org/abs/2212.08853)

    本论文提出了一种名为HyPe的微调技术，通过扰动Transformer层的隐藏表示，改善了预训练语言模型微调过拟合或表示崩溃等问题，并在多个自然语言推理数据集上取得了比普通微调更好的效果。

    

    基于Transformer结构的语言模型在自然语言处理任务中表现出色，但在微调预训练语言模型时仍然存在着过拟合或表示崩溃等问题。本论文提出了HyPe技术，通过扰动Transformer层的隐藏表示来缓解这些问题。与先前只添加噪声到输入或参数的方法不同，我们认为Transformer层的隐藏表示传达了更多不同且有意义的语言信息，因此让Transformer层更加鲁棒于隐藏表示的扰动可以进一步改善PLMs微调的效果。通过在GLUE和其他自然语言推理数据集上进行广泛的实验和分析，结果表明HyPe优于普通的微调，并增强了来自不同层的隐藏表示的泛化性能。

    Language models with the Transformers structure have shown great performance in natural language processing. However, there still poses problems when fine-tuning pre-trained language models on downstream tasks, such as over-fitting or representation collapse. In this work, we propose HyPe, a simple yet effective fine-tuning technique to alleviate such problems by perturbing hidden representations of Transformers layers. Unlike previous works that only add noise to inputs or parameters, we argue that the hidden representations of Transformers layers convey more diverse and meaningful language information. Therefore, making the Transformers layers more robust to hidden representation perturbations can further benefit the fine-tuning of PLMs en bloc. We conduct extensive experiments and analyses on GLUE and other natural language inference datasets. Results demonstrate that HyPe outperforms vanilla fine-tuning and enhances generalization of hidden representations from different layers. In
    
[^62]: 利用注意力机制提升同声翻译性能

    Attention as a Guide for Simultaneous Speech Translation. (arXiv:2212.07850v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07850](http://arxiv.org/abs/2212.07850)

    本文研究了同声翻译中的编码器-解码器注意力行为，提出了一种基于注意力的策略（EDAtt），旨在通过实时引导编码器-解码器注意力得分来提高同声翻译性能。在英译德和英译西任务中，EDAtt 策略具有计算感知延迟优势并取得了更好的结果。

    

    注意力机制的研究在多个领域中引起了浓厚的兴趣，如语言模型和机器翻译。本文研究针对同声翻译中的编码器-解码器注意力行为，并提出了一种基于注意力的策略（EDAtt），旨在通过实时引导编码器-解码器注意力得分来提高同声翻译性能。在英译德和英译西任务中，与现有同声翻译技术相比，EDAtt 策略在计算感知延迟等方面表现更好。

    The study of the attention mechanism has sparked interest in many fields, such as language modeling and machine translation. Although its patterns have been exploited to perform different tasks, from neural network understanding to textual alignment, no previous work has analysed the encoder-decoder attention behavior in speech translation (ST) nor used it to improve ST on a specific task. In this paper, we fill this gap by proposing an attention-based policy (EDAtt) for simultaneous ST (SimulST) that is motivated by an analysis of the existing attention relations between audio input and textual output. Its goal is to leverage the encoder-decoder attention scores to guide inference in real time. Results on en->{de, es} show that the EDAtt policy achieves overall better results compared to the SimulST state of the art, especially in terms of computational-aware latency.
    
[^63]: 基于表示学习和领域适应的多领域小样本关系抽取

    Cross-Domain Few-Shot Relation Extraction via Representation Learning and Domain Adaptation. (arXiv:2212.02560v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.02560](http://arxiv.org/abs/2212.02560)

    本论文提出了一种基于先验知识和内在语义的原型表示学习方法和使用对比学习进行领域适应的跨领域小样本关系抽取框架，可以在多个领域中有效地提取新的关系。

    

    少样本关系抽取旨在在每个关系中仅有少量标记样本的情况下识别新的关系。之前基于度量的少样本关系抽取算法通过将由少量标记样本嵌入生成的原型与使用训练的度量函数分析查询语句的嵌入进行比较以识别这些关系。然而，由于这些领域始终与训练数据集中的领域存在显着差异，这些方法在许多领域中对未见关系的泛化能力受到限制。因此，我们建议从先验知识和关系的内在语义中学习更易解释和高效的原型，以更有效地在各种领域中提取新的关系。通过使用先前信息探索关系之间的关系，我们有效地改善了关系的原型表示。通过使用对比学习来学习领域不变表示，我们提出了一种新的跨领域小样本关系抽取框架，可以有效地从带有少量标记示例的未见领域中提取新的关系。基准数据集上的实验表明，我们提出的方法在跨领域小样本关系抽取方面优于现有方法。

    Few-shot relation extraction aims to recognize novel relations with few labeled sentences in each relation. Previous metric-based few-shot relation extraction algorithms identify relationships by comparing the prototypes generated by the few labeled sentences embedding with the embeddings of the query sentences using a trained metric function. However, as these domains always have considerable differences from those in the training dataset, the generalization ability of these approaches on unseen relations in many domains is limited. Since the prototype is necessary for obtaining relationships between entities in the latent space, we suggest learning more interpretable and efficient prototypes from prior knowledge and the intrinsic semantics of relations to extract new relations in various domains more effectively. By exploring the relationships between relations using prior information, we effectively improve the prototype representation of relations. By using contrastive learning to 
    
[^64]: 基于自动生成语言模型的自动机表示任务知识

    Automaton-Based Representations of Task Knowledge from Generative Language Models. (arXiv:2212.01944v3 [cs.FL] UPDATED)

    [http://arxiv.org/abs/2212.01944](http://arxiv.org/abs/2212.01944)

    提出了一个算法GLM2FSA，能够自动从任务目标的简短自然语言描述中提取任务知识并构建一个编码高层次任务知识的有限状态自动机，构建的自动机可以被正式验证。

    

    基于自动机的任务知识表示在控制和规划序列决策问题中扮演着重要角色。然而，获取构建此类自动机所需的高层次任务知识通常很困难。同时，大规模自动生成语言模型可以自动生成相关任务知识。然而，自动生成语言模型的文本输出不能正式验证或用于顺序决策。我们提出了一个名为GLM2FSA的新算法，它从任务目标的简短自然语言描述中构建一个编码高层次任务知识的有限状态自动机（FSA）。GLM2FSA首先向GLM发送查询以提取文本形式的任务知识，然后它建立一个FSA来表示这种基于文本的知识。因此，所提出的算法填补了自然语言任务描述和自动机表示之间的差距，构建的FSA可以针对用户定义的规格进行正式验证。

    Automaton-based representations of task knowledge play an important role in control and planning for sequential decision-making problems. However, obtaining the high-level task knowledge required to build such automata is often difficult. Meanwhile, large-scale generative language models (GLMs) can automatically generate relevant task knowledge. However, the textual outputs from GLMs cannot be formally verified or used for sequential decision-making. We propose a novel algorithm named GLM2FSA, which constructs a finite state automaton (FSA) encoding high-level task knowledge from a brief natural-language description of the task goal. GLM2FSA first sends queries to a GLM to extract task knowledge in textual form, and then it builds an FSA to represent this text-based knowledge. The proposed algorithm thus fills the gap between natural-language task descriptions and automaton-based representations, and the constructed FSA can be formally verified against user-defined specifications. We a
    
[^65]: 自然语言处理任务的持续学习：一项调查

    Continual Learning of Natural Language Processing Tasks: A Survey. (arXiv:2211.12701v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.12701](http://arxiv.org/abs/2211.12701)

    本文综述了NLP中持续学习的最新进展，其中CF预防、知识迁移和跨任务类分离等方面对NLP任务至关重要，并讨论了未来研究方向。

    

    持续学习是一种学习范式，模拟人类不断学习和积累知识的能力，不会忘记之前学过的知识，并将学到的知识传递给新任务更好地学习。本文调查了NLP中CL的最新进展，它与计算机视觉和机器学习中的CL有显着区别。它涵盖了（1）所有CL设置及现有技术分类；（2）防止灾难性遗忘（CF）；（3）知识迁移（KT），对NLP任务尤其重要；以及（4）一些理论和交任务类分离（ICS）的隐含挑战。本文还讨论了未来方向的一些列表。

    Continual learning (CL) is a learning paradigm that emulates the human capability of learning and accumulating knowledge continually without forgetting the previously learned knowledge and also transferring the learned knowledge to help learn new tasks better. This survey presents a comprehensive review and analysis of the recent progress of CL in NLP, which has significant differences from CL in computer vision and machine learning. It covers (1) all CL settings with a taxonomy of existing techniques; (2) catastrophic forgetting (CF) prevention, (3) knowledge transfer (KT), which is particularly important for NLP tasks; and (4) some theory and the hidden challenge of inter-task class separation (ICS). (1), (3) and (4) have not been included in the existing survey. Finally, a list of future directions is discussed.
    
[^66]: 多视角压缩表示的鲁棒性低资源微调研究

    Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations. (arXiv:2211.08794v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08794](http://arxiv.org/abs/2211.08794)

    本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。

    

    由于参数的巨大数量，预训练语言模型（PLMs）的微调容易在低资源场景中出现过度拟合的问题。本文提出了一种新方法，该方法在PLM的隐藏表示上操作，以减少过拟合。在微调过程中，我们的方法在PLM的隐藏层之间插入随机自编码器，将来自前一层的激活转换为多视角压缩表示，然后将其馈送到上层。微调结束后，自编码器会被移除掉，因此我们的方法在推理过程中不会增加额外的参数或计算成本。我们的方法在一系列序列和标记级别的低资源NLP任务中展现了出色的性能提升。

    Due to the huge amount of parameters, fine-tuning of pretrained language models (PLMs) is prone to overfitting in the low resource scenarios. In this work, we present a novel method that operates on the hidden representations of a PLM to reduce overfitting. During fine-tuning, our method inserts random autoencoders between the hidden layers of a PLM, which transform activations from the previous layers into a multi-view compressed representation before feeding it into the upper layers. The autoencoders are plugged out after fine-tuning, so our method does not add extra parameters or increase computation cost during inference. Our method demonstrates promising performance improvement across a wide range of sequence- and token-level low-resource NLP tasks.
    
[^67]: 实时联合语音识别和语言不流畅检测

    Streaming Joint Speech Recognition and Disfluency Detection. (arXiv:2211.08726v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08726](http://arxiv.org/abs/2211.08726)

    本研究提出了一种实时联合语音识别和语言不流畅检测的方法，可以利用声学信息使不流畅检测具有鲁棒性，并提供非语言线索，降低了延迟和推理负担。多任务模型的输出可以实现高准确率的不流畅检测，并避免由于不流畅引起的识别错误，提高了整体语音识别的准确度。

    

    语言不流畅检测主要采用管道处理，作为语音识别的后处理步骤。本研究提出基于 Transformer 的编码器-解码器模型，联合解决语音识别和语言不流畅检测，以流式方式工作。与管道处理相比，联合模型可以利用声学信息，使语言不流畅检测对识别错误具有鲁棒性，并提供非语言线索。此外，联合建模有低延迟和轻量级推理的特点。我们研究了两种流式语言不流畅检测联合模型：文本增强模型和多任务模型。文本增强模型是在带有特殊标记的文本上训练的，指示不流畅部分的起点和终点。然而，它存在来自额外的不流畅标记的延迟和标准语言模型适应的问题。为解决这些问题，我们提出了一个多任务模型，同时具有语音识别和语言不流畅检测两个输出层。多任务模型通过避免由于不流畅而引起的识别错误，实现了高准确率的不流畅检测，并改善了整体的语音识别。

    Disfluency detection has mainly been solved in a pipeline approach, as post-processing of speech recognition. In this study, we propose Transformer-based encoder-decoder models that jointly solve speech recognition and disfluency detection, which work in a streaming manner. Compared to pipeline approaches, the joint models can leverage acoustic information that makes disfluency detection robust to recognition errors and provide non-verbal clues. Moreover, joint modeling results in low-latency and lightweight inference. We investigate two joint model variants for streaming disfluency detection: a transcript-enriched model and a multi-task model. The transcript-enriched model is trained on text with special tags indicating the starting and ending points of the disfluent part. However, it has problems with latency and standard language model adaptation, which arise from the additional disfluency tags. We propose a multi-task model to solve such problems, which has two output layers at the
    
[^68]: 易于决定，难以达成一致：减少显著性方法之间的分歧

    Easy to Decide, Hard to Agree: Reducing Disagreements Between Saliency Methods. (arXiv:2211.08369v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08369](http://arxiv.org/abs/2211.08369)

    本文介绍了利用显著性方法揭示神经NLP模型黑匣子，协议评估并不能保证可靠性，通过使用Pearson-r更适合的替代方案实现一致性，同时通过正则化技术提高注意力解释的忠实度。

    

    揭示神经NLP模型黑匣子的流行方法是利用显著性方法，它们为每个输入组件分配标量重要性分数。评估解释性方法是否忠实的常见做法是使用“协议评估”——如果多种方法对解释达成一致，其可信度就会增加。然而，最近的研究发现，即使应用于同一模型实例，显著性方法也表现出较弱的秩相关性，并倡导使用替代诊断方法。在我们的工作中，我们证明了秩相关性不适合评估一致性，并认为Pearson-r是更适合的替代方法。我们进一步表明，增加注意力解释的忠实度的正则化技术也会增加显著性方法之间的一致性。通过将我们的发现与基于培训动态的实例类别相连接，我们展示了标准基准数据集中某些类别的显著性方法解释的一致性非常低，例如细粒度情感分类，并提出未来研究的潜在方向。

    A popular approach to unveiling the black box of neural NLP models is to leverage saliency methods, which assign scalar importance scores to each input component. A common practice for evaluating whether an interpretability method is faithful has been to use evaluation-by-agreement -- if multiple methods agree on an explanation, its credibility increases. However, recent work has found that saliency methods exhibit weak rank correlations even when applied to the same model instance and advocated for the use of alternative diagnostic methods. In our work, we demonstrate that rank correlation is not a good fit for evaluating agreement and argue that Pearson-$r$ is a better-suited alternative. We further show that regularization techniques that increase faithfulness of attention explanations also increase agreement between saliency methods. By connecting our findings to instance categories based on training dynamics, we show that the agreement of saliency method explanations is very low f
    
[^69]: FolkScope: 面向电商常识发现的意图知识图谱构建

    FolkScope: Intention Knowledge Graph Construction for E-commerce Commonsense Discovery. (arXiv:2211.08316v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08316](http://arxiv.org/abs/2211.08316)

    本文提出了FolkScope意图知识图谱构建框架，该框架使用大型语言模型和人机交互注释构建知识图谱，用于揭示有关购买物品的人类思维结构。

    

    理解电商平台用户的意图需要常识知识。本文介绍了FolkScope，一种意图知识图谱构建框架，用于揭示有关购买物品的人类思维结构。由于常识知识通常不易言传且未明确表达，因此执行信息提取具有挑战性。因此，我们提出了一种新方法，利用大型语言模型的生成能力和人机交互注释来半自动构建知识图谱。首先，LLM通过电商特定提示生成意图断言，以解释购物行为，其中意图可以是开放原因或落入与ConceptNet对齐的18个类别之一的谓词，例如：是，由...制成，用于...等。然后，我们对随机抽样的意图进行合理性和典型性标注，作为训练数据，以便将人类判断应用于所有自动生成的数据。最后，为了将断言结构化，我们使用一种无向图神经网络将意图关系映射到知识图谱中。

    Understanding users' intentions in e-commerce platforms requires commonsense knowledge. In this paper, we present FolkScope, an intention knowledge graph construction framework to reveal the structure of humans' minds about purchasing items. As commonsense knowledge is usually ineffable and not expressed explicitly, it is challenging to perform information extraction. Thus, we propose a new approach that leverages the generation power of large language models~(LLMs) and human-in-the-loop annotation to semi-automatically construct the knowledge graph. LLMs first generate intention assertions via e-commerce-specific prompts to explain shopping behaviors, where the intention can be an open reason or a predicate falling into one of 18 categories aligning with ConceptNet, e.g., IsA, MadeOf, UsedFor, etc. Then we annotate plausibility and typicality labels of sampled intentions as training data in order to populate human judgments to all automatic generations. Last, to structurize the assert
    
[^70]: 探究对话摘要中的省略问题

    Towards Understanding Omission in Dialogue Summarization. (arXiv:2211.07145v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07145](http://arxiv.org/abs/2211.07145)

    本篇论文提出了OLDS数据集，用于为对话摘要提供高质量的省略标签。通过分析该数据集，发现通过为摘要模型提供真实省略标签，并在摘要过程中显式地建模和解决省略问题，可以大幅提高摘要质量。

    

    对话摘要的目标是将冗长的对话压缩成简练的摘要，并在近期取得了显著的进展。然而，现有方法的结果距离令人满意仍有很大差距。先前的研究表明，省略是影响摘要质量的主要因素之一，但是很少有研究进一步探讨省略问题，例如省略如何影响摘要结果以及如何检测省略问题，这对于减少省略并提高摘要质量至关重要。此外，分析和检测省略依赖于具有省略标签的摘要数据集（即，哪些对话话语在摘要中被省略），而当前文献中并没有这样的数据集。本文提出了OLDS数据集，为对话摘要提供了高质量的省略标签。通过分析该数据集，我们发现，通过为摘要模型提供真实省略标签，并在摘要过程中显式地建模和解决省略问题，可以大幅提高摘要质量。

    Dialogue summarization aims to condense the lengthy dialogue into a concise summary, and has recently achieved significant progress. However, the result of existing methods is still far from satisfactory. Previous works indicated that omission is a major factor in affecting the quality of summarization, but few of them have further explored the omission problem, such as how omission affects summarization results and how to detect omission, which is critical for reducing omission and improving summarization quality. Moreover, analyzing and detecting omission relies on summarization datasets with omission labels (i.e., which dialogue utterances are omitted in the summarization), which are not available in the current literature. In this paper, we propose the OLDS dataset, which provides high-quality Omission Labels for Dialogue Summarization. By analyzing this dataset, we find that a large improvement in summarization quality can be achieved by providing ground-truth omission labels for 
    
[^71]: 通过启示神经网络微调语言模型

    Fine-Tuning Language Models via Epistemic Neural Networks. (arXiv:2211.01568v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.01568](http://arxiv.org/abs/2211.01568)

    本文介绍了一种使用启示神经网络（ENN）来优先考虑有信息价值数据进行微调语言模型的方法，这种方法可以使用更少的标签数据实现更好的性能表现，同时在各种类型的神经网络模型中使用 ENN 都比常规的启发式主动学习方案表现更优。

    

    语言模型通常会在大规模的无监督文本语料库上进行预训练，然后在特定任务的数据上进行微调。然而，通常的微调方法并不重视所微调的示例。我们展示了如果你能够将有信息价值的训练数据放在优先考虑的位置上，就可以在使用更少标签的情况下获得更好的性能表现。我们将语言模型增广了一个 epinet，这是一个辅助估算模型不确定性并形成一个启示神经网络（ENN）的小型额外网络。ENN是能够知道自己的不足的神经网络。通过使用一个 epinet 来优先考虑不确定数据，我们可以将 BERT 对 GLUE 任务的微调性能提高到与不进行优先考虑训练相同的性能，同时使用的数据标签数量减半。我们还研究了合成神经网络生成模型的表现。在每种情况下，使用 epinet 都优于启发式主动学习方案。

    Language models often pre-train on large unsupervised text corpora, then fine-tune on additional task-specific data. However, typical fine-tuning schemes do not prioritize the examples that they tune on. We show that, if you can prioritize informative training data, you can achieve better performance while using fewer labels. To do this we augment a language model with an epinet: a small additional network that helps to estimate model uncertainty and forms an \textit{epistemic neural network} (ENN). ENNs are neural networks that can know what they don't know. Using an epinet to prioritize uncertain data, we can fine-tune BERT on GLUE tasks to the same performance while using 2x less data than training without prioritization. We also investigate performance in synthetic neural network generative models designed to build understanding. In each setting, using an epinet outperforms heuristic active learning schemes.
    
[^72]: 组合、注意力或两者兼备？

    Composition, Attention, or Both?. (arXiv:2210.12958v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.12958](http://arxiv.org/abs/2210.12958)

    本文提出了一种名为“组合注意力语法”（CAGs）的新型结构，该结构通过组合函数将子树递归地组合为单个向量表示，并通过自我注意机制选择性地关注先前的结构信息；结果表明，组合函数和自我注意机制都发挥了重要作用，使LMs更加类似于人类，并允许句法特征而不允许语义特征渗透到子树表示中。

    

    本文提出了一种名为“组合注意力语法”（CAGs）的新型结构，该结构通过组合函数将子树递归地组合为单个向量表示，并通过自我注意机制选择性地关注先前的结构信息。我们探讨了这些组件——组合函数和自我注意机制——是否都可以引起类似于人类的句法归纳。具体来说，我们使用谨慎控制的模型大小对具有和不具有这两个组件的语言模型（LMs）进行训练，并针对SyntaxGym基准测试中的六个测试电路评估其句法归纳能力。结果表明，组合函数和自我注意机制都发挥了重要作用，使LMs更加类似于人类，并对语言现象进行更近一步的检查，暗示组合函数允许句法特征而不允许语义特征渗透到子树表示中。

    In this paper, we propose a novel architecture called Composition Attention Grammars (CAGs) that recursively compose subtrees into a single vector representation with a composition function, and selectively attend to previous structural information with a self-attention mechanism. We investigate whether these components -- the composition function and the self-attention mechanism -- can both induce human-like syntactic generalization. Specifically, we train language models (LMs) with and without these two components with the model sizes carefully controlled, and evaluate their syntactic generalization performance against six test circuits on the SyntaxGym benchmark. The results demonstrated that the composition function and the self-attention mechanism both play an important role to make LMs more human-like, and closer inspection of linguistic phenomenon implied that the composition function allowed syntactic features, but not semantic features, to percolate into subtree representation
    
[^73]: 探讨多领域自动语音识别的自监督、弱监督和完全监督的训练方法：孟加拉布尔语的研究。

    Investigating self-supervised, weakly supervised and fully supervised training approaches for multi-domain automatic speech recognition: a study on Bangladeshi Bangla. (arXiv:2210.12921v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.12921](http://arxiv.org/abs/2210.12921)

    本研究研究了自监督、弱监督和完全监督的训练方法对多领域自动语音识别的影响，并且证明了在构建语料库时领域选择的重要性。

    

    尽管神经网络为自动语音识别（ASR）带来了巨大的改进，但由于领域转移而导致的鲁棒性和通用性问题仍然困扰着ASR系统。这主要是因为在编译ASR数据集时，通常不足够地识别和检查主要的语料库设计标准。在这项研究中，我们调查了最先进的转移学习方法（如自监督 wav2vec 2.0 和弱监督 Whisper）以及完全监督的卷积神经网络（CNN）在多领域ASR中的鲁棒性。我们还通过在一个新的多领域孟加拉国布尔语ASR评估基准BanSpeech上评估这些模型来证明在构建语料库时领域选择的重要性，BanSpeech包含大约6.52小时的人工标注语音和来自13个不同领域的8085个发言。

    Despite huge improvements in automatic speech recognition (ASR) employing neural networks, ASR systems still suffer from a lack of robustness and generalizability issues due to domain shifting. This is mainly because principal corpus design criteria are often not identified and examined adequately while compiling ASR datasets. In this study, we investigate the robustness of the state-of-the-art transfer learning approaches such as self-supervised wav2vec 2.0 and weakly supervised Whisper as well as fully supervised convolutional neural networks (CNNs) for multi-domain ASR. We also demonstrate the significance of domain selection while building a corpus by assessing these models on a novel multi-domain Bangladeshi Bangla ASR evaluation benchmark - BanSpeech, which contains approximately 6.52 hours of human-annotated speech and 8085 utterances from 13 distinct domains. SUBAK.KO, a mostly read speech corpus for the morphologically rich language Bangla, has been used to train the ASR syste
    
[^74]: 基于语义框架的知识图谱时间问答查询生成

    Semantic Framework based Query Generation for Temporal Question Answering over Knowledge Graphs. (arXiv:2210.04490v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04490](http://arxiv.org/abs/2210.04490)

    本论文提出了一种基于语义框架的知识图谱时间问答查询生成方法，受到时间约束的限制，有效地提高了问答能力。

    

    最近，知识图谱上关于时间的事实问答引起越来越多的关注。在生成时间查询时，现有的知识图谱问答方法忽略了一些内在的事件联系，这些联系使事件在时间上相关，可能限制了它们的能力。我们系统地分析了时间约束的可能解释，并将解释结构归纳为时间约束的语义框架（SF-TCons）。基于语义框架，我们提出了一种时间问答方法，SF-TQA，通过探索所提及实体的相关事实来生成查询图，探索过程受到SF-TCons的限制。我们的评估表明，SF-TQA在不同知识图谱上的两个基准测试中明显优于现有方法。

    Answering factual questions with temporal intent over knowledge graphs (temporal KGQA) attracts rising attention in recent years. In the generation of temporal queries, existing KGQA methods ignore the fact that some intrinsic connections between events can make them temporally related, which may limit their capability. We systematically analyze the possible interpretation of temporal constraints and conclude the interpretation structures as the Semantic Framework of Temporal Constraints, SF-TCons. Based on the semantic framework, we propose a temporal question answering method, SF-TQA, which generates query graphs by exploring the relevant facts of mentioned entities, where the exploring process is restricted by SF-TCons. Our evaluations show that SF-TQA significantly outperforms existing methods on two benchmarks over different knowledge graphs.
    
[^75]: 使用全文内容表征和识别畅销书

    Using Full-Text Content to Characterize and Identify Best Seller Books. (arXiv:2210.02334v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.02334](http://arxiv.org/abs/2210.02334)

    该研究通过对书籍的全文内容进行可视化和分类任务，研究预测书籍是否会成为畅销书。使用了 SemAxis 和线性判别分析进行数据初步探索，采用多种分类器获得定量和更加客观的结果。

    

    艺术作品可以从多个角度进行研究，其中一个例子是它们在读者中的接受情况。在本文中，我们从文艺作品的角度出发，特别是评估预测书籍是否会成为畅销书的任务。与以往的方法不同，我们专注于书籍的全文内容，并考虑了可视化和分类任务。我们使用 SemAxis 和线性判别分析进行数据结构和属性的初步探索。为了获得定量和更加客观的结果，我们采用了各种分类器。这些方法与数据集一起使用，该数据集包含从1895年到1924年出版的书籍，并被《出版周刊畅销书榜》确定为畅销书和在同一时期出版但未被提及的文学作品。我们方法比较的结果表明，最好的成绩是...

    Artistic pieces can be studied from several perspectives, one example being their reception among readers over time. In the present work, we approach this interesting topic from the standpoint of literary works, particularly assessing the task of predicting whether a book will become a best seller. Dissimilarly from previous approaches, we focused on the full content of books and considered visualization and classification tasks. We employed visualization for the preliminary exploration of the data structure and properties, involving SemAxis and linear discriminant analyses. Then, to obtain quantitative and more objective results, we employed various classifiers. Such approaches were used along with a dataset containing (i) books published from 1895 to 1924 and consecrated as best sellers by the Publishers Weekly Bestseller Lists and (ii) literary works published in the same period but not being mentioned in that list. Our comparison of methods revealed that the best-achieved result 
    
[^76]: 面向法律领域的预训练语言模型研究：以印度法律为例

    Pre-trained Language Models for the Legal Domain: A Case Study on Indian Law. (arXiv:2209.06049v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.06049](http://arxiv.org/abs/2209.06049)

    本研究针对印度法律文本，重新训练和从零开始训练了两个PLMs，即LegalBERT和CaseLawBERT，并采用基于印度法律文本的词汇表训练了一个模型。我们在几项基准法律NLP任务中，对印度和非印度的法律文本进行了应用。

    

    随着基于Transformer预训练语言模型（PLMs）在法律领域中应用的增多，特别是在欧美法律文本方面，PLMs获得了显著的成功。然而，印度等其他国家的法律文本具有很多特殊特征，因此也需要在这些方面进行预训练。本文尝试在印度法律领域进行预训练。我们在印度法律数据上重新训练（继续预训练）了两个流行的法律PLMs, LegalBERT和CaseLawBERT，以及使用基于印度法律文本的词汇表从零开始训练了一个模型。我们将这些PLMs应用于三个基准法律NLP任务——从事实中识别法律法规、对法院判决文件进行语义分割，以及预测法院上诉判决--在印度和非印度的文本上。

    NLP in the legal domain has seen increasing success with the emergence of Transformer-based Pre-trained Language Models (PLMs) pre-trained on legal text. PLMs trained over European and US legal text are available publicly; however, legal text from other domains (countries), such as India, have a lot of distinguishing characteristics. With the rapidly increasing volume of Legal NLP applications in various countries, it has become necessary to pre-train such LMs over legal text of other countries as well. In this work, we attempt to investigate pre-training in the Indian legal domain. We re-train (continue pre-training) two popular legal PLMs, LegalBERT and CaseLawBERT, on Indian legal data, as well as train a model from scratch with a vocabulary based on Indian legal text. We apply these PLMs over three benchmark legal NLP tasks -Legal Statute Identification from facts, Semantic Segmentation of Court Judgment Documents, and Court Appeal Judgment Prediction -- over both Indian and non-
    
[^77]: LGBTQ在线社群在COVID-19疫情期间经历的少数群体压力

    Minority Stress Experienced by LGBTQ Online Communities during the COVID-19 Pandemic. (arXiv:2205.09511v3 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2205.09511](http://arxiv.org/abs/2205.09511)

    研究探究了LGBTQ在线社群在COVID-19疫情期间经历的少数群体压力。利用机器学习分类器检测Twitter上表现出的少数群体压力，比较疫情前后的语言差异。

    

    COVID-19疫情的影响在少数族群中产生了不成比例的影响，如LGBTQ社群（女同性恋、男同性恋、双性恋、跨性别和酷儿）的成员，因为他们本身存在社会不利和健康差异。虽然对于COVID-19疫情对大众生活各个方面的影响进行了广泛研究，但很少有研究关注LGBTQ族群。本文利用疫情前和疫情期间的数据集开发和评估了两组机器学习分类器，以识别在Twitter上表现出少数群体压力的帖子。少数群体压力是LGBTQ族群成员由于其性别和性别认同而面临的独特压力。我们证明了我们最佳的疫情前和疫情期间模型表现出强大和稳定的性能，可以检测包含少数群体压力的帖子。我们研究了疫情前和疫情期间少数群体压力帖子的语言差异。我们发现愤怒是在疫情期间最显著的情绪表达。

    The COVID-19 pandemic has disproportionately impacted the lives of minorities, such as members of the LGBTQ community (lesbian, gay, bisexual, transgender, and queer) due to pre-existing social disadvantages and health disparities. Although extensive research has been carried out on the impact of the COVID-19 pandemic on different aspects of the general population's lives, few studies are focused on the LGBTQ population. In this paper, we develop and evaluate two sets of machine learning classifiers using a pre-pandemic and a during-pandemic dataset to identify Twitter posts exhibiting minority stress, which is a unique pressure faced by the members of the LGBTQ population due to their sexual and gender identities. We demonstrate that our best pre- and during-pandemic models show strong and stable performance for detecting posts that contain minority stress. We investigate the linguistic differences in minority stress posts across pre- and during-pandemic periods. We find that anger wo
    
[^78]: 评估白盒语言模型的人格特征

    Estimating the Personality of White-Box Language Models. (arXiv:2204.12000v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.12000](http://arxiv.org/abs/2204.12000)

    本文评估了多个大规模语言模型的人格特征，填补了推断和改变这些模型所继承人格特征方面的空白。

    

    近年来，面向开放式语言生成技术的人工智能应用取得了巨大进展。大规模语言模型在虚拟助手到对话机器人等各种应用中广泛应用，可以产生流畅的文本，然而现有研究表明，这些模型可能会反映人类偏见。虽然许多偏见尤其是那些可能导致危害的偏见已经被深入研究，但推断和改变这些模型所继承的人格特征的研究却很少或根本不存在。本文将通过探索用于生成开放式文本的多个大规模语言模型和数据集的人格特征，填补这一空白。我们基于流行的五个大因素和发展出健壮的方法来量化这些模型和数据集的人格特征。

    Technology for open-ended language generation, a key application of artificial intelligence, has advanced to a great extent in recent years. Large-scale language models, which are trained on large corpora of text, are being used in a wide range of applications everywhere, from virtual assistants to conversational bots. While these language models output fluent text, existing research shows that these models can and do capture human biases. Many of these biases, especially those that could potentially cause harm, are being well-investigated. On the other hand, studies that infer and change human personality traits inherited by these models have been scarce or non-existent. Our work seeks to address this gap by exploring the personality traits of several large-scale language models designed for open-ended text generation and the datasets used for training them. We build on the popular Big Five factors and develop robust methods that quantify the personality traits of these models and the
    
[^79]: 基于Transformer的自然语言处理方法用于法院文件的相似性分析

    Analysing similarities between legal court documents using natural language processing approaches based on Transformers. (arXiv:2204.07182v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2204.07182](http://arxiv.org/abs/2204.07182)

    本文尝试通过利用六种基于Transformer的自然语言处理技术，基于巴西葡萄牙语的通用语料库预训练，利用210,000份法律诉讼文档进行微调和专业化训练，解决法律文件相似度问题，从而协助快速解决司法程序。

    

    最近人工智能领域的发展在自然语言处理方面取得了重要进展，成为法律领域中协助快速解决司法程序的重要工具。本文以巴西司法系统的案例为研究对象，运用六种基于Transformer结构的自然语言处理技术，解决法律文件相似度问题。包括BERT、GPT-2、RoBERTa等NLP基于Transformer的模型，用巴西葡萄牙语的通用语料库进行预训练，并利用210,000份法律诉讼文档进行微调和专业化训练。通过计算每个文档的嵌入向量表征，运用聚类方法对诉讼案件进行分析，并计算每个模型的品质。

    Recent advances in Artificial Intelligence (AI) have leveraged promising results in solving complex problems in the area of Natural Language Processing (NLP), being an important tool to help in the expeditious resolution of judicial proceedings in the legal area. In this context, this work targets the problem of detecting the degree of similarity between judicial documents that can be achieved in the inference group, by applying six NLP techniques based on the transformers architecture to a case study of legal proceedings in the Brazilian judicial system. The NLP transformer-based models, namely BERT, GPT-2 and RoBERTa, were pre-trained using a general purpose corpora of the Brazilian Portuguese language, and then were fine-tuned and specialised for the legal sector using 210,000 legal proceedings. Vector representations of each legal document were calculated based on their embeddings, which were used to cluster the lawsuits, calculating the quality of each model based on the cosine of
    
[^80]: 基于随机过程的语言建模

    Language modeling via stochastic processes. (arXiv:2203.11370v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.11370](http://arxiv.org/abs/2203.11370)

    本篇论文探究了对比表示在生成任务中的应用，提出了Time Control(TC)方法，可以保留长文本的结构，并在学习句子表示以获得话语连贯性方面表现竞争力。

    

    现代语言模型能够生成高质量的短文本，但是当它们生成较长文本时，往往显得冗杂或者不连贯。这些问题源自next-token-only的语言建模目标。最近的自监督学习工作表明，模型可以通过对比学习学习到好的潜在表征，这对于区分性任务是有效的。我们的工作分析了对比表示应用于生成任务（如长文本生成）的情况。我们提出了一种利用对比表示的方法，称为Time Control (TC)。TC首先学习目标文本领域的对比表示，然后通过这些表示解码生成文本。与特定于领域的方法和跨越各种文本领域的fine-tuning GPT2相比，TC在学习句子表示以获得话语连贯性方面表现竞争力。在长文本生成设置中，TC保留了文本结构。

    Modern language models can generate high-quality short texts. However, they often meander or are incoherent when generating longer texts. These issues arise from the next-token-only language modeling objective. Recent work in self-supervised learning suggests that models can learn good latent representations via contrastive learning, which can be effective for discriminative tasks. Our work analyzes the application of contrastive representations for generative tasks, like long text generation. We propose one approach for leveraging constrastive representations, which we call Time Control (TC). TC first learns a contrastive representation of the target text domain, then generates text by decoding from these representations. Compared to domain-specific methods and fine-tuning GPT2 across a variety of text domains, TC performs competitively to methods specific for learning sentence representations on discourse coherence. On long text generation settings, TC preserves the text structure bo
    
[^81]: 量子密度矩阵在经典问答和图像分类中的应用

    Application of Quantum Density Matrix in Classical Question Answering and Classical Image Classification. (arXiv:2203.11155v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.11155](http://arxiv.org/abs/2203.11155)

    该论文将量子密度矩阵应用于经典问答和图像分类中，证明了其可以提高任务的效率，尤其在图像分类中取得了优秀的性能表现。

    

    量子密度矩阵可表示整个量子系统的全部信息，将密度矩阵用于经典问答任务可以更加有效地实现问题回答。本论文设计了一种基于LSTM的新机制，以应对输入为矩阵的情况，并将该机制应用于卷积神经网络进行QA问题的求解，同时也证明了量子密度矩阵可以增强经典图像分类中的特征信息和特征之间的关系。实验结果表明，该新框架在CIFAR-10数据集上的性能优于传统的基于CNN的分类方法。

    Quantum density matrix represents all the information of the entire quantum system, and novel models of meaning employing density matrices naturally model linguistic phenomena such as hyponymy and linguistic ambiguity, among others in quantum question answering tasks. Naturally, we argue that applying the quantum density matrix into classical Question Answering (QA) tasks can show more effective performance. Specifically, we (i) design a new mechanism based on Long Short-Term Memory (LSTM) to accommodate the case when the inputs are matrixes; (ii) apply the new mechanism to QA problems with Convolutional Neural Network (CNN) and gain the LSTM-based QA model with the quantum density matrix. Experiments of our new model on TREC-QA and WIKI-QA data sets show encouraging results. Similarly, we argue that the quantum density matrix can also enhance the image feature information and the relationship between the features for the classical image classification. Thus, we (i) combine density mat
    
[^82]: 利用左角递归神经网络语法模拟人类句子处理

    Modeling Human Sentence Processing with Left-Corner Recurrent Neural Network Grammars. (arXiv:2109.04939v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2109.04939](http://arxiv.org/abs/2109.04939)

    分层结构与左角架构是人类句子处理更具认知可信度的模型。

    

    在计算语言学中，已经表明分级结构使语言模型（LM）更像人类。然而，以前的文献对分层模型的分析策略持无知态度。本文研究了分层结构是否使LM更像人类，如果是，最具认知可信度的解析策略是什么。为了回答这个问题，我们在具有头终左向结构的日语阅读时间与长短时记忆（LSTM）作为序列模型和从上到下和从左角RNNG作为分层模型的情况下评估了三个LM。我们的计算建模表明，左上方RNNG优于从上到下的RNNG和LSTM，这表明分层和左角架构比从上到下或序列架构更具认知可信度。此外，认知可信度与（i）句子长度，（ii）句子结构和（iii）读者口语能力之间的关系也得到了探讨。

    In computational linguistics, it has been shown that hierarchical structures make language models (LMs) more human-like. However, the previous literature has been agnostic about a parsing strategy of the hierarchical models. In this paper, we investigated whether hierarchical structures make LMs more human-like, and if so, which parsing strategy is most cognitively plausible. In order to address this question, we evaluated three LMs against human reading times in Japanese with head-final left-branching structures: Long Short-Term Memory (LSTM) as a sequential model and Recurrent Neural Network Grammars (RNNGs) with top-down and left-corner parsing strategies as hierarchical models. Our computational modeling demonstrated that left-corner RNNGs outperformed top-down RNNGs and LSTM, suggesting that hierarchical and left-corner architectures are more cognitively plausible than top-down or sequential architectures. In addition, the relationships between the cognitive plausibility and (i) p
    
[^83]: 一种具有压缩子层的高效Transformer解码器

    An Efficient Transformer Decoder with Compressed Sub-layers. (arXiv:2101.00542v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2101.00542](http://arxiv.org/abs/2101.00542)

    该论文提出了一种使用压缩子层的高效Transformer解码器，通过减少子层并提高并行性能够达到1.42倍的速度提升，同时确保性能与基线相当。

    

    最近由于其高效而流行的大型基于注意力的编码器-解码器网络（Transformer）的解码器计算复杂度高，导致效率问题。通过查看解码器的数学公式，我们发现在某些条件下，可以通过压缩其子层（Transformer的基本构建块）简化架构并实现更高的并行性。因此，我们提出了压缩注意力网络，其解码器层仅包含一个子层而不是三个子层。在14个WMT机器翻译任务的广泛实验中表明，我们的模型比强基线快1.42倍，并且性能相当。而这个强基线已经比广泛使用的标准基线快2倍而且性能不降。

    The large attention-based encoder-decoder network (Transformer) has become prevailing recently due to its effectiveness. But the high computation complexity of its decoder raises the inefficiency issue. By examining the mathematic formulation of the decoder, we show that under some mild conditions, the architecture could be simplified by compressing its sub-layers, the basic building block of Transformer, and achieves a higher parallelism. We thereby propose Compressed Attention Network, whose decoder layer consists of only one sub-layer instead of three. Extensive experiments on 14 WMT machine translation tasks show that our model is 1.42x faster with performance on par with a strong baseline. This strong baseline is already 2x faster than the widely used standard baseline without loss in performance.
    
[^84]: 具有相关模态的Lambek演算的范畴向量空间语义学

    Categorical Vector Space Semantics for Lambek Calculus with a Relevant Modality. (arXiv:2005.03074v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2005.03074](http://arxiv.org/abs/2005.03074)

    本文为Lambek演算引入了一个相关模态!L*，并通过构建具有余代数模态的范畴向量空间语义学给出了该模态下的短语派生方法。

    

    我们为具有有限压缩和置换规则的相关模态! L *的Lambek演算开发了一种范畴组合分布语义学。语义学的范畴部分是一个具有余代数模态的一般双闭范畴，非常类似于微分范畴的结构。我们通过“量子化”函子将这个范畴实例化为有限维向量空间和线性映射，并利用三种具体的余代数模态来进行操作。我们将该模型应用于构建相关模态! L *的一个示例中：具有寄生代的短语派生。使用BERT、Word2Vec和FastText向量以及关系张量，我们对具体解释的有效性进行了评估，通过对扩展了的句子消岐数据集上的寄生代短语进行任务处理。

    We develop a categorical compositional distributional semantics for Lambek Calculus with a Relevant Modality !L*, which has a limited edition of the contraction and permutation rules. The categorical part of the semantics is a monoidal biclosed category with a coalgebra modality, very similar to the structure of a Differential Category. We instantiate this category to finite dimensional vector spaces and linear maps via "quantisation" functors and work with three concrete interpretations of the coalgebra modality. We apply the model to construct categorical and concrete semantic interpretations for the motivating example of !L*: the derivation of a phrase with a parasitic gap. The effectiveness of the concrete interpretations are evaluated via a disambiguation task, on an extension of a sentence disambiguation dataset to parasitic gap phrases, using BERT, Word2Vec, and FastText vectors and Relational tensors.
    

