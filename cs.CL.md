# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis.](http://arxiv.org/abs/2308.05725) | 本研究通过引入Expresso数据集，对离散表达性语音再合成进行了基准测试和分析，提出了一种不依赖文本的高质量语音合成方法，能够捕捉到难以转录的语音表达方面。 |
| [^2] | [A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment.](http://arxiv.org/abs/2308.05696) | 本研究初步探讨复杂性与对齐之间的固有关系。通过使用"tree-instruct"方法来增强指令数据的复杂性，可以在对齐到任务和用户偏好方面提供更好的性能。 |
| [^3] | [Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning.](http://arxiv.org/abs/2308.05680) | 本研究通过创建新的数据集、评估多语言预训练Transformer模型以及提出多阶段框架来解决了跨语言澄清检索问题。 |
| [^4] | [AST-MHSA : Code Summarization using Multi-Head Self-Attention.](http://arxiv.org/abs/2308.05646) | AST-MHSA模型通过多头自注意力从AST中提取重要的语义信息，并利用编码器-解码器架构生成源代码的简明自然语言描述。 |
| [^5] | [IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer.](http://arxiv.org/abs/2308.05633) | IIHT是一种用于医学报告生成的基于图像到指示器层次Transformer的框架，可以提取医学图像的特征并生成与疾病相关的指示器。 |
| [^6] | [LASIGE and UNICAGE solution to the NASA LitCoin NLP Competition.](http://arxiv.org/abs/2308.05609) | 本文介绍了LASIGE和UNICAGE在NASA LitCoin NLP竞赛中的解决方案，通过将产业界的数据工程解决方案与学术界的命名实体识别和关系抽取系统整合，成功地在大规模的生物医学文本处理任务中取得了显著成果。 |
| [^7] | [You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content.](http://arxiv.org/abs/2308.05596) | 本研究探讨如何利用大型语言模型和提示学习来解决在线有毒内容问题，重点关注毒性分类、毒性跨度检测和去毒化任务。 |
| [^8] | [Do Language Models Refer?.](http://arxiv.org/abs/2308.05576) | 论文探讨了语言模型是否具有指称能力，并通过借鉴语言哲学外部主义传统的观点，提出了LMs可以指称的理由。 |
| [^9] | [Exploring Linguistic Similarity and Zero-Shot Learning for Multilingual Translation of Dravidian Languages.](http://arxiv.org/abs/2308.05574) | 本文探索了在德拉维德语系多语言翻译中，利用音译和语言相似性的方法解决零样本翻译的问题，通过构建单一编码器-解码器神经机器翻译系统，并评估其性能与基于中间语言的方法进行比较。同时，还验证了形态丰富的语言是否需要较大的词汇量。 |
| [^10] | [Bringing order into the realm of Transformer-based language models for artificial intelligence and law.](http://arxiv.org/abs/2308.05502) | 本文提供了第一个对基于Transformer的语言模型在法律领域的人工智能问题和任务中的方法的系统概述。文章旨在突出这一领域的研究进展，以进一步了解Transformer在支持法律流程中的AI成功贡献以及当前的局限性。 |
| [^11] | [LLM As DBA.](http://arxiv.org/abs/2308.05481) | LLM变成DBA，提供数据库维护的诊断和优化建议，通过从文本来源中获取经验和多个LLMs的协作诊断。 |
| [^12] | [Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis.](http://arxiv.org/abs/2308.05476) | 本研究通过比较分析机器学习和基于Transformer的方法在欺诈性文本分类中的效果，揭示了它们的优势和局限性。 |
| [^13] | [WeaverBird: Empowering Financial Decision-Making with Large Language Model, Knowledge Base, and Search Engine.](http://arxiv.org/abs/2308.05361) | WeaverBird是一个专为金融领域设计的智能对话系统，通过利用大型语言模型、本地知识库和搜索引擎，能够理解复杂的金融查询并提供明智的回答，具有增强的可信度。 |
| [^14] | [Metacognitive Prompting Improves Understanding in Large Language Models.](http://arxiv.org/abs/2308.05342) | 元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。 |
| [^15] | [Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT.](http://arxiv.org/abs/2308.05341) | 本研究探索了分类人工智能生成文本与人类生成文本的问题，并研究了在人工智能以难以被人类辨认的方式进行文本生成时的更高级情况。实验结果显示，我们的最佳系统在区分基础和高级人工生成/人工智能生成文本时的F1分数超过96%，在区分基础和高级人工生成/人工智能重新表达文本时的F1分数超过78%。 |
| [^16] | [Developing an Informal-Formal Persian Corpus.](http://arxiv.org/abs/2308.05336) | 该论文介绍了开发一个非正式-正式波斯语语料库的方法，以满足非正式波斯语处理工具的需求。收集了5万个句子对，并以词语/短语级别对齐，涵盖了非正式和正式波斯语之间的各种词汇和句法变化。 |
| [^17] | [Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning.](http://arxiv.org/abs/2308.05317) | 该论文提出了一种处理结构化数据到文本生成的新方法，通过提供统一表示和多源学习，可以在多任务、零样本和少样本场景下改善性能。实验证明该方法能够适应不同形式的结构化数据，并且在性能上超过当前方法。该方法对于构建更通用的数据到文本生成框架具有重要意义。 |
| [^18] | [Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season.](http://arxiv.org/abs/2308.05281) | 该研究通过社交媒体数据和SIR模型研究了2020年西部美国火灾季的灾害响应。研究发现Twitter用户主要关注健康影响、损失和撤离三个主题，并使用SIR理论探索了这些主题在Twitter上的传播规模和速度。 |
| [^19] | [A Novel Self-training Approach for Low-resource Speech Recognition.](http://arxiv.org/abs/2308.05269) | 本文提出了一种新颖的自训练方法，用于低资源设置下的自动语音识别，通过生成高准确度的伪标签，显著改善了单词错误率，相对改进达到14.94%。 |
| [^20] | [Decoding Layer Saliency in Language Transformers.](http://arxiv.org/abs/2308.05219) | 本文提出了一种在语言转换器中识别文本显著性的策略，并适应了基于梯度的显著性方法，在多个基准分类数据集上取得了一致提升。 |
| [^21] | [GPT-4 Can't Reason.](http://arxiv.org/abs/2308.03762) | GPT-4在推理方面无能为力，尽管有着偶尔显示的分析才智。 |
| [^22] | [Towards Multiple References Era -- Addressing Data Leakage and Limited Reference Diversity in NLG Evaluation.](http://arxiv.org/abs/2308.03131) | 本论文提出了使用多个参考来增强匹配指标与人类评估之间的一致性。在WMT Metrics基准中，多参考F200spBLEU相对于传统的单参考方法准确率提高了7.2\%，超过了基于神经网络的BERTscore的3.9\%的准确率提高。此外，该方法还可以在很大程度上缓解大型语言模型中的数据泄漏问题。 |
| [^23] | [Scaling Data Generation in Vision-and-Language Navigation.](http://arxiv.org/abs/2307.15644) | 这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。 |
| [^24] | [Statistical Mechanics of Strahler Number via Random and Natural Language Sentences.](http://arxiv.org/abs/2307.02697) | 本文通过统计力学分析自然语言句子树结构的Strahler数的上下限，发现它几乎总是3或4，并证明它是处理句子所需记忆量的下限。同时，对随机树进行的分析揭示出Strahler数的增长模式，揭示了它作为自然语言句子特征的统计基础。 |
| [^25] | [Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions.](http://arxiv.org/abs/2306.02130) | 本论文研究使用精调的大型语言模型对数据进行预注释，以扩展事件类型本体。通过研究启发式方法和自动分数的应用，提高注释的效率和准确性。 |
| [^26] | [Domain Mastery Benchmark: An Ever-Updating Benchmark for Evaluating Holistic Domain Knowledge of Large Language Model--A Preliminary Release.](http://arxiv.org/abs/2304.11679) | DomMa 是一个用于测试大型语言模型领域知识理解能力的综合基准，它分为中英文10万个问题，并基于112个一级学科分类不断更新数据集。 |
| [^27] | [From Retrieval to Generation: Efficient and Effective Entity Set Expansion.](http://arxiv.org/abs/2304.03531) | 本文提出了GenExpan，一种基于生成式预训练语言模型的实体集扩展框架，利用前缀树保证实体生成的有效性，采用自动生成的类名来引导模型生成同一类实体，从而提高了效率和可扩展性。 |
| [^28] | [Synthesizing Mixed-type Electronic Health Records using Diffusion Models.](http://arxiv.org/abs/2302.14679) | 本论文研究了使用扩散模型合成混合类型电子健康记录的潜力，与现有方法相比，在数据质量、实用性和增强方面表现出更好的性能，但在隐私方面存在权衡。 |
| [^29] | [Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations.](http://arxiv.org/abs/2302.13817) | 本文讨论了聊天机器人的历史概述以及ChatGPT背后的技术，强调了它在医疗保健、教育和研究中的潜在应用，并指出了其隐私和道德方面的担忧以及当前版本的重要限制。 |
| [^30] | [Automaton-Based Representations of Task Knowledge from Generative Language Models.](http://arxiv.org/abs/2212.01944) | 提出了一个算法GLM2FSA，能够自动从任务目标的简短自然语言描述中提取任务知识并构建一个编码高层次任务知识的有限状态自动机，构建的自动机可以被正式验证。 |
| [^31] | [VT-CLIP: Enhancing Vision-Language Models with Visual-guided Texts.](http://arxiv.org/abs/2112.02399) | VT-CLIP通过视觉引导文本来增强视觉-语言模型CLIP，在下游任务中展现出更好的迁移性能。 |

# 详细

[^1]: EXPRESSO: 一项对离散表达性语音再合成进行基准测试和分析的研究

    EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis. (arXiv:2308.05725v1 [cs.CL])

    [http://arxiv.org/abs/2308.05725](http://arxiv.org/abs/2308.05725)

    本研究通过引入Expresso数据集，对离散表达性语音再合成进行了基准测试和分析，提出了一种不依赖文本的高质量语音合成方法，能够捕捉到难以转录的语音表达方面。

    

    最近的研究表明，不依赖于文本，而是基于在无监督学习中学习到的低比特率离散单元，可以重新合成高质量的语音，并且能够捕捉到难以转录的语音表达方面（韵律、声音风格、非语言语音化）。然而，由于大多数语音合成数据集都是朗读的，因此对 spontaneity 和 expressivity 的要求限制了这些方法的应用。本文引入了 Expresso，这是一个高质量的无文本语音合成数据集，包括朗读语音和26种自发表达风格的即兴对话。我们通过一个表达性重新合成基准测试来展示这个数据集的挑战和潜力，在这个任务中，需要以低比特率单元对输入进行编码，并在目标音色中重新合成，同时保持内容和风格。我们使用自动度量标准对不同的自监督离散合成方法进行了质量评估。

    Recent work has shown that it is possible to resynthesize high-quality speech based, not on text, but on low bitrate discrete units that have been learned in a self-supervised fashion and can therefore capture expressive aspects of speech that are hard to transcribe (prosody, voice styles, non-verbal vocalization). The adoption of these methods is still limited by the fact that most speech synthesis datasets are read, severely limiting spontaneity and expressivity. Here, we introduce Expresso, a high-quality expressive speech dataset for textless speech synthesis that includes both read speech and improvised dialogues rendered in 26 spontaneous expressive styles. We illustrate the challenges and potentials of this dataset with an expressive resynthesis benchmark where the task is to encode the input in low-bitrate units and resynthesize it in a target voice while preserving content and style. We evaluate resynthesis quality with automatic metrics for different self-supervised discrete 
    
[^2]: 复杂性与对齐之间固有关系的初步研究

    A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment. (arXiv:2308.05696v1 [cs.CL])

    [http://arxiv.org/abs/2308.05696](http://arxiv.org/abs/2308.05696)

    本研究初步探讨复杂性与对齐之间的固有关系。通过使用"tree-instruct"方法来增强指令数据的复杂性，可以在对齐到任务和用户偏好方面提供更好的性能。

    

    使用开放域指令数据培训大型语言模型(LLMs)在对齐到最终任务和用户偏好方面取得了显著成功。大量研究表明，提高指令数据的质量和多样性始终能够改善性能。然而，作为一个关键指标，数据复杂性的影响尚未被充分探索，主要包括三个方面：(1)扩展规律，性能改进在复杂性增加时的可持续性尚不确定，(2)额外的标记，复杂性带来的改进是否来自引入更多训练标记，以及(3)课程设置，将从简单到困难的指令纳入是否具有潜在优势也尚未完全理解。在本文中，我们提出了"tree-instruct"，以可控的方式系统地增强指令数据的复杂性。这种方法将指定数量的节点添加到指令语义树中，从而产生新的指令数据。

    Training large language models (LLMs) with open-domain instruction data has yielded remarkable success in aligning to end tasks and user preferences. Extensive research has highlighted that enhancing the quality and diversity of instruction data consistently improves performance. However, the impact of data complexity, as a crucial metric, remains relatively unexplored in three aspects: (1) scaling law, where the sustainability of performance improvements with increasing complexity is uncertain, (2) additional tokens, whether the improvement brought by complexity comes from introducing more training tokens, and (3) curriculum tuning, where the potential advantages of incorporating instructions ranging from easy to difficult are not yet fully understood. In this paper, we propose \textit{tree-instruct} to systematically enhance the complexity of instruction data in a controllable manner. This approach adds a specified number of nodes into the instruction semantic tree, yielding new inst
    
[^3]: 通过多阶段检索找到已经被澄清的叙述：实现跨语言、跨数据集和零样本学习

    Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning. (arXiv:2308.05680v1 [cs.CL])

    [http://arxiv.org/abs/2308.05680](http://arxiv.org/abs/2308.05680)

    本研究通过创建新的数据集、评估多语言预训练Transformer模型以及提出多阶段框架来解决了跨语言澄清检索问题。

    

    检索已经被澄清的叙述的任务旨在检测已经经过事实核查的故事。成功检测到已被澄清的声明不仅减少了专业事实核查人员的手动努力，还可以有助于减缓虚假信息的传播。由于缺乏可用数据，这是一个研究不足的问题，特别是在考虑跨语言任务时，即在检查的在线帖子的语言与事实核查文章的语言不同的情况下进行检索。本文通过以下方式填补了这一空白：（i）创建了一个新颖的数据集，以允许对已被澄清的叙述进行跨语言检索的研究，使用推文作为对事实核查文章数据库的查询；（ii）展示了一个全面的实验，以评估经过微调和现成的多语言预训练Transformer模型在这个任务上的性能；（iii）提出了一个新颖的多阶段框架，将这个跨语言澄清检索问题划分为不同的阶段。

    The task of retrieving already debunked narratives aims to detect stories that have already been fact-checked. The successful detection of claims that have already been debunked not only reduces the manual efforts of professional fact-checkers but can also contribute to slowing the spread of misinformation. Mainly due to the lack of readily available data, this is an understudied problem, particularly when considering the cross-lingual task, i.e. the retrieval of fact-checking articles in a language different from the language of the online post being checked. This paper fills this gap by (i) creating a novel dataset to enable research on cross-lingual retrieval of already debunked narratives, using tweets as queries to a database of fact-checking articles; (ii) presenting an extensive experiment to benchmark fine-tuned and off-the-shelf multilingual pre-trained Transformer models for this task; and (iii) proposing a novel multistage framework that divides this cross-lingual debunk ret
    
[^4]: AST-MHSA: 利用多头自注意力进行代码摘要

    AST-MHSA : Code Summarization using Multi-Head Self-Attention. (arXiv:2308.05646v1 [cs.CL])

    [http://arxiv.org/abs/2308.05646](http://arxiv.org/abs/2308.05646)

    AST-MHSA模型通过多头自注意力从AST中提取重要的语义信息，并利用编码器-解码器架构生成源代码的简明自然语言描述。

    

    代码摘要旨在为源代码生成简明的自然语言描述。现有的方法采用基于Transformer的编码器-解码器架构，其中利用源代码的抽象语法树（AST）来编码结构信息。然而，AST比对应的源代码要长得多，现有方法通过直接将整个线性化的AST输入到编码器中来忽略这个大小约束。这种简化的方法使得从过长的输入序列中提取真正有价值的依赖关系变得具有挑战性，并且由于对AST中的所有节点应用自注意力，导致了显著的计算开销。为了有效而高效地解决这个问题，我们提出了一个模型AST-MHSA，利用多头注意力从AST中提取重要的语义信息。该模型由两个主要组件组成：一个编码器和一个解码器。编码器以代码的抽象语法树（AST）作为输入，并

    Code summarization aims to generate concise natural language descriptions for source code. The prevailing approaches adopt transformer-based encoder-decoder architectures, where the Abstract Syntax Tree (AST) of the source code is utilized for encoding structural information. However, ASTs are much longer than the corresponding source code, and existing methods ignore this size constraint by directly feeding the entire linearized AST into the encoders. This simplistic approach makes it challenging to extract truly valuable dependency relations from the overlong input sequence and leads to significant computational overhead due to self-attention applied to all nodes in the AST.  To address this issue effectively and efficiently, we present a model, AST-MHSA that uses multi-head attention to extract the important semantic information from the AST. The model consists of two main components: an encoder and a decoder. The encoder takes as input the abstract syntax tree (AST) of the code and
    
[^5]: IIHT: 基于图像到指示器层次Transformer的医学报告生成

    IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer. (arXiv:2308.05633v1 [cs.CV])

    [http://arxiv.org/abs/2308.05633](http://arxiv.org/abs/2308.05633)

    IIHT是一种用于医学报告生成的基于图像到指示器层次Transformer的框架，可以提取医学图像的特征并生成与疾病相关的指示器。

    

    自动化医学报告生成在医疗分析中变得越来越重要。它可以产生计算机辅助诊断描述，从而极大地减轻医生的工作。受到神经机器翻译和图像描述的巨大成功的启发，已经提出了各种深度学习方法用于医学报告生成。然而，由于医学数据的固有特性，包括数据不平衡、报告序列的长度和相关性，现有方法生成的报告可能在语言流畅性上表现出色，但缺乏足够的临床准确性。在这项工作中，我们提出了一种基于图像到指示器层次Transformer的医学报告生成框架（IIHT）。它包括三个模块，即分类器模块、指示器扩展模块和生成器模块。分类器模块首先从输入的医学图像中提取图像特征，并生成与其对应状态的与疾病相关的指示器。

    Automated medical report generation has become increasingly important in medical analysis. It can produce computer-aided diagnosis descriptions and thus significantly alleviate the doctors' work. Inspired by the huge success of neural machine translation and image captioning, various deep learning methods have been proposed for medical report generation. However, due to the inherent properties of medical data, including data imbalance and the length and correlation between report sequences, the generated reports by existing methods may exhibit linguistic fluency but lack adequate clinical accuracy. In this work, we propose an image-to-indicator hierarchical transformer (IIHT) framework for medical report generation. It consists of three modules, i.e., a classifier module, an indicator expansion module and a generator module. The classifier module first extracts image features from the input medical images and produces disease-related indicators with their corresponding states. The dise
    
[^6]: LASIGE和UNICAGE解决NASA LitCoin NLP竞赛的方案

    LASIGE and UNICAGE solution to the NASA LitCoin NLP Competition. (arXiv:2308.05609v1 [cs.CL])

    [http://arxiv.org/abs/2308.05609](http://arxiv.org/abs/2308.05609)

    本文介绍了LASIGE和UNICAGE在NASA LitCoin NLP竞赛中的解决方案，通过将产业界的数据工程解决方案与学术界的命名实体识别和关系抽取系统整合，成功地在大规模的生物医学文本处理任务中取得了显著成果。

    

    对于大多数研究人员来说，生物医学自然语言处理（NLP）往往变得繁琐，往往是因为需要处理的文本数量和异质性。为了解决这个挑战，行业不断开发高效的工具并创建更灵活的工程解决方案。本文介绍了行业数据工程解决方案与命名实体识别（LasigeUnicage_NER）和关系抽取（BiOnt）的学术系统的整合。我们的设计反映了这些组件与其他数据集和生物医学本体的额外训练数据的外部知识的整合。我们在2022年LitCoin NLP挑战赛中使用了这个流水线，我们的团队LasigeUnicage获得了第七名奖项，约有200个参赛团队，反映了学术界（LASIGE）和产业界（Unicage）之间的成功合作。支持这项工作的软件可在

    Biomedical Natural Language Processing (NLP) tends to become cumbersome for most researchers, frequently due to the amount and heterogeneity of text to be processed. To address this challenge, the industry is continuously developing highly efficient tools and creating more flexible engineering solutions. This work presents the integration between industry data engineering solutions for efficient data processing and academic systems developed for Named Entity Recognition (LasigeUnicage\_NER) and Relation Extraction (BiOnt). Our design reflects an integration of those components with external knowledge in the form of additional training data from other datasets and biomedical ontologies. We used this pipeline in the 2022 LitCoin NLP Challenge, where our team LasigeUnicage was awarded the 7th Prize out of approximately 200 participating teams, reflecting a successful collaboration between the academia (LASIGE) and the industry (Unicage). The software supporting this work is available at \
    
[^7]: 只需一次提示：关于大语言模型的提示学习在解决有毒内容中的能力

    You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content. (arXiv:2308.05596v1 [cs.CL])

    [http://arxiv.org/abs/2308.05596](http://arxiv.org/abs/2308.05596)

    本研究探讨如何利用大型语言模型和提示学习来解决在线有毒内容问题，重点关注毒性分类、毒性跨度检测和去毒化任务。

    

    在线有害内容的传播是一个重要问题，对在线用户体验和社会产生负面影响。受到这个问题的重要性和影响的启发，研究集中于开发解决方案来检测有毒内容，通常利用在人工注释数据集上训练的机器学习模型。虽然这些努力很重要，但这些模型通常无法很好地推广，并且无法应对新的趋势（例如，新的有毒术语的出现）。目前，我们正在目睹解决在线社会问题的方法发生变化，特别是利用像GPT-3或T5这样的大语言模型，它们在大规模语料库上进行训练，并具有很强的泛化能力。在这项工作中，我们调查了如何利用大语言模型和提示学习来解决有毒内容的问题，特别关注三个任务：1）毒性分类，2）毒性跨度检测，3）去毒化。我们对五个模型进行了广泛的评估...

    The spread of toxic content online is an important problem that has adverse effects on user experience online and in our society at large. Motivated by the importance and impact of the problem, research focuses on developing solutions to detect toxic content, usually leveraging machine learning (ML) models trained on human-annotated datasets. While these efforts are important, these models usually do not generalize well and they can not cope with new trends (e.g., the emergence of new toxic terms). Currently, we are witnessing a shift in the approach to tackling societal issues online, particularly leveraging large language models (LLMs) like GPT-3 or T5 that are trained on vast corpora and have strong generalizability. In this work, we investigate how we can use LLMs and prompt learning to tackle the problem of toxic content, particularly focusing on three tasks; 1) Toxicity Classification, 2) Toxic Span Detection, and 3) Detoxification. We perform an extensive evaluation over five mo
    
[^8]: 语言模型是否具有指称能力？

    Do Language Models Refer?. (arXiv:2308.05576v1 [cs.CL])

    [http://arxiv.org/abs/2308.05576](http://arxiv.org/abs/2308.05576)

    论文探讨了语言模型是否具有指称能力，并通过借鉴语言哲学外部主义传统的观点，提出了LMs可以指称的理由。

    

    语言模型（LMs）用语言做什么？大家都同意它们能够生成（大部分）连贯的句子。但是它们用这些字符串表达了什么，还是只是以一种令人信服的语言运用的模拟中胡言乱语？这是一个模糊的问题，有许多方法可以使其明确化。这里我们将解决该问题的一个方面，即，LMs的词语是否指称：即，LMs的输出是否实现了“词语-世界”之间的联系。有初步的理由认为它们不具备指称能力，因为LMs没有像普通语言用户那样与世界互动。借鉴语言哲学的外部主义传统的观点，我们认为表象是误导的，有充分的理由认为LMs可以指称。

    What do language models (LMs) do with language? Everyone agrees that they produce sequences of (mostly) coherent sentences. But are they saying anything with those strings or simply babbling in a convincing simulacrum of language use? This is a vague question, and there are many ways of making it precise. Here we will address one aspect of the question, namely, whether LMs' words refer: that is, whether the outputs of LMs achieve "word-to-world" connections. There is prima facie reason to think they do not since LMs do not interact with the world in the way that ordinary language users do. Drawing on insights from the externalist tradition in philosophy of language, we argue that appearances are misleading and that there is good reason to think that LMs can refer.
    
[^9]: 探索语言相似性和零样本学习在德拉维德语系多语言翻译中的应用

    Exploring Linguistic Similarity and Zero-Shot Learning for Multilingual Translation of Dravidian Languages. (arXiv:2308.05574v1 [cs.CL])

    [http://arxiv.org/abs/2308.05574](http://arxiv.org/abs/2308.05574)

    本文探索了在德拉维德语系多语言翻译中，利用音译和语言相似性的方法解决零样本翻译的问题，通过构建单一编码器-解码器神经机器翻译系统，并评估其性能与基于中间语言的方法进行比较。同时，还验证了形态丰富的语言是否需要较大的词汇量。

    

    零样本翻译的当前研究存在诸多问题，如计算需求高、训练时间增加以及翻译偏离目标等。现有的解决方案往往需要额外的数据或计算资源。在大多数情况下，基于中间语言的神经机器翻译比单一编码器模型更受青睐，尽管训练和评估时间会增加。本文利用音译和语言相似性克服了零样本翻译的缺点。我们构建了一个单一编码器-解码器神经机器翻译系统，用于德拉维德语系之间的多语言翻译，并进行零样本翻译。我们比较了数据与零样本翻译的准确性之间的权衡，并评估我们的基本方法与现有基于中间语言的方法的性能。我们还通过使用一种基于最优传输的技术限制词汇表，验证了形态丰富的语言是否需要较大的词汇量。

    Current research in zero-shot translation is plagued by several issues such as high compute requirements, increased training time and off target translations. Proposed remedies often come at the cost of additional data or compute requirements. Pivot based neural machine translation is preferred over a single-encoder model for most settings despite the increased training and evaluation time. In this work, we overcome the shortcomings of zero-shot translation by taking advantage of transliteration and linguistic similarity. We build a single encoder-decoder neural machine translation system for Dravidian-Dravidian multilingual translation and perform zero-shot translation. We compare the data vs zero-shot accuracy tradeoff and evaluate the performance of our vanilla method against the current state of the art pivot based method. We also test the theory that morphologically rich languages require large vocabularies by restricting the vocabulary using an optimal transport based technique. 
    
[^10]: 将顺序带入基于Transformer的语言模型中，用于人工智能和法律的应用

    Bringing order into the realm of Transformer-based language models for artificial intelligence and law. (arXiv:2308.05502v1 [cs.CL])

    [http://arxiv.org/abs/2308.05502](http://arxiv.org/abs/2308.05502)

    本文提供了第一个对基于Transformer的语言模型在法律领域的人工智能问题和任务中的方法的系统概述。文章旨在突出这一领域的研究进展，以进一步了解Transformer在支持法律流程中的AI成功贡献以及当前的局限性。

    

    基于Transformer的语言模型（TLM）被广泛认可是一种先进的技术，能够成功开发出基于深度学习的解决方案，用于需要自然语言处理和理解的问题和应用。与其他文本领域一样，TLM确实推动了法律领域许多感兴趣任务对人工智能方法的最新进展。尽管第一个Transformer模型提出了大约6年时间，但这项技术以前所未有的速度迅猛发展，BERT和相关模型成为主要参考，也在法律领域占有重要地位。本文首次系统概述了TLM在法律领域的人工智能驱动问题和任务中的方法。一个主要目标是突出研究在这一领域的进展，以便一方面了解Transformer在支持法律流程中取得的AI成功贡献是什么，另一方面了解当前的局限性是什么。

    Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the state-of-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitati
    
[^11]: LLM变成DBA

    LLM As DBA. (arXiv:2308.05481v1 [cs.DB])

    [http://arxiv.org/abs/2308.05481](http://arxiv.org/abs/2308.05481)

    LLM变成DBA，提供数据库维护的诊断和优化建议，通过从文本来源中获取经验和多个LLMs的协作诊断。

    

    数据库管理员（DBA）在管理、维护和优化数据库系统以确保数据可用性、性能和可靠性方面起着至关重要的作用。然而，对于DBA来说，管理大量数据库实例（例如，云数据库上的数百万个实例）是困难和繁琐的。最近，大型语言模型（LLMs）已经显示出了理解有价值文件并生成合理答案的巨大潜力。因此，我们提出了D-Bot，一种基于LLM的数据库管理员，它可以持续从文本来源中获取数据库维护经验，并为目标数据库提供合理、有理、及时的诊断和优化建议。本文介绍了一个革命性的以LLM为中心的数据库维护框架，包括（i）从文档和工具中检测数据库维护知识，（ii）根本原因分析的思维树，和（iii）多个LLM之间的协作诊断。我们进行了初步实验。

    Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experiment
    
[^12]: 探索机器学习和基于Transformer的方法用于欺诈性文本分类：一项比较分析

    Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis. (arXiv:2308.05476v1 [cs.CL])

    [http://arxiv.org/abs/2308.05476](http://arxiv.org/abs/2308.05476)

    本研究通过比较分析机器学习和基于Transformer的方法在欺诈性文本分类中的效果，揭示了它们的优势和局限性。

    

    欺诈性文本分类是自然语言处理中的一项关键任务，旨在识别欺诈或欺骗性内容。本研究对机器学习和基于Transformer的方法进行了比较分析，用于欺诈性文本分类。我们研究了传统机器学习算法和最先进的Transformer模型（如BERT，XLNET，DistilBERT和RoBERTa）在检测欺诈性文本方面的有效性。我们使用一个带标签的数据集，其中包含欺诈性和非欺诈性文本，用于训练和评估目的。通过广泛的实验，我们比较了不同方法的性能指标，包括准确率，精确率，召回率和F1得分。本研究的结果揭示了机器学习和基于Transformer的方法在欺诈性文本分类中的优势和局限性，使研究人员和实践者能够在处理欺诈内容时做出明智的决策。

    Deceptive text classification is a critical task in natural language processing that aims to identify deceptive or fraudulent content. This study presents a comparative analysis of machine learning and transformer-based approaches for deceptive text classification. We investigate the effectiveness of traditional machine learning algorithms and state-of-the-art transformer models, such as BERT, XLNET, DistilBERT, and RoBERTa, in detecting deceptive text. A labeled dataset consisting of deceptive and non-deceptive texts is used for training and evaluation purposes. Through extensive experimentation, we compare the performance metrics, including accuracy, precision, recall, and F1 score, of the different approaches. The results of this study shed light on the strengths and limitations of machine learning and transformer-based methods for deceptive text classification, enabling researchers and practitioners to make informed decisions when dealing with deceptive content
    
[^13]: WeaverBird: 利用大型语言模型、知识库和搜索引擎增强金融决策能力

    WeaverBird: Empowering Financial Decision-Making with Large Language Model, Knowledge Base, and Search Engine. (arXiv:2308.05361v1 [cs.CL])

    [http://arxiv.org/abs/2308.05361](http://arxiv.org/abs/2308.05361)

    WeaverBird是一个专为金融领域设计的智能对话系统，通过利用大型语言模型、本地知识库和搜索引擎，能够理解复杂的金融查询并提供明智的回答，具有增强的可信度。

    

    我们提出了WeaverBird，一个专为金融领域设计的智能对话系统。我们的系统利用GPT架构的大型语言模型，并利用金融相关文本的广泛语料对其进行了调整。因此，我们的系统能够理解复杂的金融查询，例如“在通货膨胀期间如何管理我的投资？”并提供明智的回答。此外，我们的系统还集成了本地的知识库和搜索引擎以检索相关信息。最终的回答是基于搜索结果进行条件约束的，并包含适当的引用来源，从而具有增强的可信度。通过一系列与金融相关的问题，我们已经展示了我们的系统相比其他模型的卓越性能。用户可以在我们的在线演示网站https://weaverbird.ttic.edu与我们的系统进行互动，并观看我们的2分钟演示视频https://www.youtube.com/watch?v=yofgeq。

    We present WeaverBird, an intelligent dialogue system designed specifically for the finance domain. Our system harnesses a large language model of GPT architecture that has been tuned using extensive corpora of finance-related text. As a result, our system possesses the capability to understand complex financial queries, such as "How should I manage my investments during inflation?", and provide informed responses. Furthermore, our system incorporates a local knowledge base and a search engine to retrieve relevant information. The final responses are conditioned on the search results and include proper citations to the sources, thus enjoying an enhanced credibility. Through a range of finance-related questions, we have demonstrated the superior performance of our system compared to other models. To experience our system firsthand, users can interact with our live demo at https://weaverbird.ttic.edu, as well as watch our 2-min video illustration at https://www.youtube.com/watch?v=yofgeq
    
[^14]: 元认知提示改善大型语言模型的理解能力

    Metacognitive Prompting Improves Understanding in Large Language Models. (arXiv:2308.05342v1 [cs.CL])

    [http://arxiv.org/abs/2308.05342](http://arxiv.org/abs/2308.05342)

    元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。

    

    在大型语言模型 (LLMs) 中，通过有效的提示设计，任务特定性能一直在不断提高。尽管最近关于提示的研究增强了LLMs的推理能力，但在进一步提高它们的理解能力方面仍存在差距。在本研究中，我们介绍了元认知提示 (MP)，这是一种受人类内省推理过程启发的策略。使用MP，LLMs经历一系列有结构、自我意识的评估，利用其丰富的内在知识和新的见解。我们的实验涉及五个常见的LLMs：Llama2、Vicuna、PaLM、GPT-3.5和GPT-4，它们都涵盖了来自GLUE和SuperGLUE基准测试的各种通用自然语言理解 (NLU) 任务。结果表明，虽然GPT-4在大多数任务中始终表现出色，但配备MP的PaLM接近其性能水平。此外，跨模型和数据集，MP始终优于现有的提示方法。

    In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. While recent research on prompting has enhanced the reasoning capabilities of LLMs, a gap remains in further improving their understanding abilities. In this study, we introduce metacognitive prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. Our experiments involve five prevalent LLMs: Llama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various general natural language understanding (NLU) tasks from the GLUE and SuperGLUE benchmarks. Results indicate that, although GPT-4 consistently excels in most tasks, PaLM, when equipped with MP, approaches its performance level. Furthermore, across models and datasets, MP consistently outperforms existing prompting meth
    
[^15]: 人工智能生成文本与人类生成文本的分类：探索ChatGPT的特征

    Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT. (arXiv:2308.05341v1 [cs.CL])

    [http://arxiv.org/abs/2308.05341](http://arxiv.org/abs/2308.05341)

    本研究探索了分类人工智能生成文本与人类生成文本的问题，并研究了在人工智能以难以被人类辨认的方式进行文本生成时的更高级情况。实验结果显示，我们的最佳系统在区分基础和高级人工生成/人工智能生成文本时的F1分数超过96%，在区分基础和高级人工生成/人工智能重新表达文本时的F1分数超过78%。

    

    最近，像ChatGPT这样的生成型人工智能已经面向公众提供。这些工具可以被学生用来生成散文或整个论文。但是老师如何知道一篇文本是由学生还是由人工智能编写的？在我们的工作中，我们探索传统和新的特征来(1)检测由人工智能从头开始生成的文本和(2)由人工智能重新表达的文本。由于我们发现，当人工智能被指示以人类难以辨认的方式创建文本时，分类变得更加困难，我们还对这种更高级的情况进行了研究。为了进行实验，我们制作了涵盖10个学校话题的新文本语料库。我们最佳的基础和高级人工生成/人工智能生成文本分类系统的F1分数超过96%。我们最佳的对基础和高级人工生成/人工智能重新表达文本进行分类的系统的F1分数超过78%。

    Recently, generative AIs like ChatGPT have become available to the wide public. These tools can for instance be used by students to generate essays or whole theses. But how does a teacher know whether a text is written by a student or an AI? In our work, we explore traditional and new features to (1) detect text generated by AI from scratch and (2) text rephrased by AI. Since we found that classification is more difficult when the AI has been instructed to create the text in a way that a human would not recognize that it was generated by an AI, we also investigate this more advanced case. For our experiments, we produced a new text corpus covering 10 school topics. Our best systems to classify basic and advanced human-generated/AI-generated texts have F1-scores of over 96%. Our best systems for classifying basic and advanced human-generated/AI-rephrased texts have F1-scores of more than 78%. The systems use a combination of perplexity, semantic, list lookup, error-based, readability, A
    
[^16]: 开发一种非正式-正式波斯语语料库

    Developing an Informal-Formal Persian Corpus. (arXiv:2308.05336v1 [cs.CL])

    [http://arxiv.org/abs/2308.05336](http://arxiv.org/abs/2308.05336)

    该论文介绍了开发一个非正式-正式波斯语语料库的方法，以满足非正式波斯语处理工具的需求。收集了5万个句子对，并以词语/短语级别对齐，涵盖了非正式和正式波斯语之间的各种词汇和句法变化。

    

    非正式语言是一种在非正式场合中经常使用的口头或书面语言风格，包括日常对话、社交媒体、博客、电子邮件和短信。在非正式写作中，语言在不同语言之间会出现一些词汇和/或句法的变化。波斯语是一种正式和非正式写作风格之间存在许多差异的语言，因此为该语言开发非正式语言处理工具显得必要。这样的转换器需要一个大规模的正式-非正式句子对齐平行语料库，可以帮助语言学家提取非正式波斯语的规范语法和正字法，就像对正式语言已经做的那样。本文介绍了我们构建了一个包含5万个句子对且以词语/短语级别对齐的平行语料库的方法。句子试图涵盖非正式波斯语和正式波斯语之间几乎所有类型的词汇和句法变化，因此采用了探索和收集两种方法。

    Informal language is a style of spoken or written language frequently used in casual conversations, social media, weblogs, emails and text messages. In informal writing, the language faces some lexical and/or syntactic changes varying among different languages. Persian is one of the languages with many differences between its formal and informal styles of writing, thus developing informal language processing tools for this language seems necessary. Such a converter needs a large aligned parallel corpus of colloquial-formal sentences which can be useful for linguists to extract a regulated grammar and orthography for colloquial Persian as is done for the formal language. In this paper we explain our methodology in building a parallel corpus of 50,000 sentence pairs with alignments in the word/phrase level. The sentences were attempted to cover almost all kinds of lexical and syntactic changes between informal and formal Persian, therefore both methods of exploring and collecting from th
    
[^17]: 通过统一表示和多源学习实现少样本数据到文本生成

    Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning. (arXiv:2308.05317v1 [cs.CL])

    [http://arxiv.org/abs/2308.05317](http://arxiv.org/abs/2308.05317)

    该论文提出了一种处理结构化数据到文本生成的新方法，通过提供统一表示和多源学习，可以在多任务、零样本和少样本场景下改善性能。实验证明该方法能够适应不同形式的结构化数据，并且在性能上超过当前方法。该方法对于构建更通用的数据到文本生成框架具有重要意义。

    

    我们提出了一种新方法来处理结构化数据到文本生成的问题，解决了现有方法主要专注于特定类型结构化数据的限制。我们的方法通过提供一种能够处理各种形式结构化数据（如表格、知识图谱三元组和语义表示）的统一表示，旨在提高多任务训练、零样本和少样本场景的性能。我们展示了我们的方法能够有效适应新的结构化形式，并且能够在比较当前方法时提高性能。例如，我们的方法将在表格输入上训练的模型转移到知识图谱数据集时，零样本BLEU得分提高了66%。我们的方法是朝着更通用的数据到文本生成框架迈出的重要一步。

    We present a novel approach for structured data-to-text generation that addresses the limitations of existing methods that primarily focus on specific types of structured data. Our proposed method aims to improve performance in multi-task training, zero-shot and few-shot scenarios by providing a unified representation that can handle various forms of structured data such as tables, knowledge graph triples, and meaning representations. We demonstrate that our proposed approach can effectively adapt to new structured forms, and can improve performance in comparison to current methods. For example, our method resulted in a 66% improvement in zero-shot BLEU scores when transferring models trained on table inputs to a knowledge graph dataset. Our proposed method is an important step towards a more general data-to-text generation framework.
    
[^18]: 通过社交媒体数据和易感-感染-康复（SIR）模型研究灾害响应：以2020年西部美国火灾季为案例研究

    Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season. (arXiv:2308.05281v1 [cs.SI])

    [http://arxiv.org/abs/2308.05281](http://arxiv.org/abs/2308.05281)

    该研究通过社交媒体数据和SIR模型研究了2020年西部美国火灾季的灾害响应。研究发现Twitter用户主要关注健康影响、损失和撤离三个主题，并使用SIR理论探索了这些主题在Twitter上的传播规模和速度。

    

    有效的灾害响应对受影响的社区至关重要。应急人员和决策者在灾害期间在了解社区所面临问题的可靠和及时的指标上将受益于社交媒体提供的丰富数据来源。社交媒体可以反映公众关注和需求，为决策者提供有价值的洞见，以了解不断演变的情况并优化资源配置。我们使用双向编码器表示转换（BERT）主题建模对Twitter数据进行主题聚类。然后，我们进行了时间-空间分析，研究了这些主题在2020年美国西部火灾季期间在不同地区的分布情况。我们的结果显示，Twitter用户主要关注三个主题：“健康影响”，“损失”，“撤离”。我们使用易感-感染-康复（SIR）理论来探索主题在Twitter上的传播规模和速度。结果清晰地显示了主题传播的情况。

    Effective disaster response is critical for affected communities. Responders and decision-makers would benefit from reliable, timely measures of the issues impacting their communities during a disaster, and social media offers a potentially rich data source. Social media can reflect public concerns and demands during a disaster, offering valuable insights for decision-makers to understand evolving situations and optimize resource allocation. We used Bidirectional Encoder Representations from Transformers (BERT) topic modeling to cluster topics from Twitter data. Then, we conducted a temporal-spatial analysis to examine the distribution of these topics across different regions during the 2020 western U.S. wildfire season. Our results show that Twitter users mainly focused on three topics:"health impact," "damage," and "evacuation." We used the Susceptible-Infected-Recovered (SIR) theory to explore the magnitude and velocity of topic diffusion on Twitter. The results displayed a clear re
    
[^19]: 一种新颖的自训练方法用于低资源语音识别

    A Novel Self-training Approach for Low-resource Speech Recognition. (arXiv:2308.05269v1 [cs.CL])

    [http://arxiv.org/abs/2308.05269](http://arxiv.org/abs/2308.05269)

    本文提出了一种新颖的自训练方法，用于低资源设置下的自动语音识别，通过生成高准确度的伪标签，显著改善了单词错误率，相对改进达到14.94%。

    

    本文提出了一种自训练方法，用于低资源设置下的自动语音识别（ASR）。尽管自训练方法在英语等高资源语言上得到了广泛的发展和评估，但在像旁遮普语这样的低资源语言上的应用却很有限，尽管旁遮普语被全球数百万人口使用。标注数据的稀缺性阻碍了准确ASR系统的开发，特别是对于低资源语言（如旁遮普语和毛利语）。为解决这个问题，我们提出了一种有效的自训练方法，为无标签的低资源语音生成高准确度的伪标签。我们的实验分析表明，相对于基线模型，我们的方法显著改善了单词错误率，实现了14.94%的相对改进，同时在四个真实语音数据集上实现了最好的结果。

    In this paper, we propose a self-training approach for automatic speech recognition (ASR) for low-resource settings. While self-training approaches have been extensively developed and evaluated for high-resource languages such as English, their applications to low-resource languages like Punjabi have been limited, despite the language being spoken by millions globally. The scarcity of annotated data has hindered the development of accurate ASR systems, especially for low-resource languages (e.g., Punjabi and M\=aori languages). To address this issue, we propose an effective self-training approach that generates highly accurate pseudo-labels for unlabeled low-resource speech. Our experimental analysis demonstrates that our approach significantly improves word error rate, achieving a relative improvement of 14.94% compared to a baseline model across four real speech datasets. Further, our proposed approach reports the best results on the Common Voice Punjabi dataset.
    
[^20]: 语言转换器中的层显著性解码

    Decoding Layer Saliency in Language Transformers. (arXiv:2308.05219v1 [cs.CL])

    [http://arxiv.org/abs/2308.05219](http://arxiv.org/abs/2308.05219)

    本文提出了一种在语言转换器中识别文本显著性的策略，并适应了基于梯度的显著性方法，在多个基准分类数据集上取得了一致提升。

    

    本文介绍了一种在大规模语言模型应用于分类任务中识别文本显著性的策略。在视觉网络中，显著性往往通过卷积层自然地进行定位，然而，在用于处理自然语言的现代transformer-stack网络中，并非如此。我们为这些网络适应了基于梯度的显著性方法，提出了一种评估每层语义一致性程度的方法，并在多个基准分类数据集上展示了与其他多种文本显著性方法相比的一致提升。我们的方法不需要额外的训练或访问标记数据，而且计算效率相对较高。

    In this paper, we introduce a strategy for identifying textual saliency in large-scale language models applied to classification tasks. In visual networks where saliency is more well-studied, saliency is naturally localized through the convolutional layers of the network; however, the same is not true in modern transformer-stack networks used to process natural language. We adapt gradient-based saliency methods for these networks, propose a method for evaluating the degree of semantic coherence of each layer, and demonstrate consistent improvement over numerous other methods for textual saliency on multiple benchmark classification datasets. Our approach requires no additional training or access to labelled data, and is comparatively very computationally efficient.
    
[^21]: GPT-4无法进行推理

    GPT-4 Can't Reason. (arXiv:2308.03762v1 [cs.CL])

    [http://arxiv.org/abs/2308.03762](http://arxiv.org/abs/2308.03762)

    GPT-4在推理方面无能为力，尽管有着偶尔显示的分析才智。

    

    GPT-4于2023年3月发布，广受好评，相比之前的GPT-3.5（OpenAI之前最好的模型，用于ChatGPT的初次发布），在各个方面都有很大的改进。然而，尽管有着令人印象深刻的改进，对于GPT-4的推理能力存在充分的怀疑是有道理的。本文讨论了推理的本质；批评了当前NLP社区中推理问题的表述方式，以及目前LLM推理性能的评估方式；引入了一系列由21个多样化推理问题组成的集合；并对GPT-4在这些问题上的性能进行了详细的定性评估。基于这个分析，本文得出结论，尽管偶尔显示出分析上的才智，但目前的GPT-4完全无法进行推理。

    GPT-4 was released in March 2023 to wide acclaim, marking a very substantial improvement across the board over GPT-3.5 (OpenAI's previously best model, which had powered the initial release of ChatGPT). However, despite the genuinely impressive improvement, there are good reasons to be highly skeptical of GPT-4's ability to reason. This position paper discusses the nature of reasoning; criticizes the current formulation of reasoning problems in the NLP community, as well as the way in which LLM reasoning performance is currently evaluated; introduces a small collection of 21 diverse reasoning problems; and performs a detailed qualitative evaluation of GPT-4's performance on those problems. Based on this analysis, the paper concludes that, despite its occasional flashes of analytical brilliance, GPT-4 at present is utterly incapable of reasoning.
    
[^22]: 迈向多参考时代 —— 解决NLG评估中的数据泄漏和参考多样性有限问题

    Towards Multiple References Era -- Addressing Data Leakage and Limited Reference Diversity in NLG Evaluation. (arXiv:2308.03131v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03131](http://arxiv.org/abs/2308.03131)

    本论文提出了使用多个参考来增强匹配指标与人类评估之间的一致性。在WMT Metrics基准中，多参考F200spBLEU相对于传统的单参考方法准确率提高了7.2\%，超过了基于神经网络的BERTscore的3.9\%的准确率提高。此外，该方法还可以在很大程度上缓解大型语言模型中的数据泄漏问题。

    

    N-gram匹配的评估指标，如BLEU和chrF，在各种自然语言生成（NLG）任务中被广泛使用。然而，最近的研究发现，这些基于匹配的指标与人类评估之间存在较弱的相关性，尤其是与基于神经网络的指标如BLEURT相比。在本文中，我们推测匹配指标性能瓶颈的原因可能是参考资料多样性有限。为了解决这个问题，我们提出利用"多个参考"来增强这些指标与人类评估之间的一致性。在WMT Metrics基准中，我们观察到多参考F200spBLEU相对于传统的单参考方法，准确率提高了7.2\%。值得注意的是，它还超过了基于神经网络的BERTscore，准确率提高了3.9\%。此外，我们观察到大型语言模型（LLMs）中的数据泄漏问题可以在很大程度上得到缓解通过我们的多参考方法。

    N-gram matching-based evaluation metrics, such as BLEU and chrF, are widely utilized across a range of natural language generation (NLG) tasks. However, recent studies have revealed a weak correlation between these matching-based metrics and human evaluations, especially when compared with neural-based metrics like BLEURT. In this paper, we conjecture that the performance bottleneck in matching-based metrics may be caused by the limited diversity of references. To address this issue, we propose to utilize \textit{multiple references} to enhance the consistency between these metrics and human evaluations. Within the WMT Metrics benchmarks, we observe that the multi-references F200spBLEU surpasses the conventional single-reference one by an accuracy improvement of 7.2\%. Remarkably, it also exceeds the neural-based BERTscore by an accuracy enhancement of 3.9\%. Moreover, we observe that the data leakage issue in large language models (LLMs) can be mitigated to a large extent by our multi
    
[^23]: 视觉语言导航中的数据生成规模化

    Scaling Data Generation in Vision-and-Language Navigation. (arXiv:2307.15644v1 [cs.CV])

    [http://arxiv.org/abs/2307.15644](http://arxiv.org/abs/2307.15644)

    这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。

    

    最近在语言引导的视觉导航研究中，对于遍历环境的多样性和训练可泛化代理的监督数量有了明显需求。为了解决现有视觉语言导航数据集中普遍存在的数据稀缺问题，我们提出了一种有效的范式，用于生成用于学习的大规模数据。我们应用了HM3D和Gibson数据集中的1200多个逼真的环境，并利用网络上的资源合成了490万个指令轨迹对。重要的是，我们调查了范式中每个组成部分对代理性能的影响，并研究了如何恰当地应用扩增数据来预训练和微调代理。得益于我们的大规模数据集，通过简单的模仿学习，现有代理的性能可以大幅提升（相对于之前的最佳结果绝对值增加了11%），在R2R测试集中单次运行成功率显著提升至80%。

    Recent research in language-guided visual navigation has demonstrated a significant demand for the diversity of traversable environments and the quantity of supervision for training generalizable agents. To tackle the common data scarcity issue in existing vision-and-language navigation datasets, we propose an effective paradigm for generating large-scale data for learning, which applies 1200+ photo-realistic environments from HM3D and Gibson datasets and synthesizes 4.9 million instruction trajectory pairs using fully-accessible resources on the web. Importantly, we investigate the influence of each component in this paradigm on the agent's performance and study how to adequately apply the augmented data to pre-train and fine-tune an agent. Thanks to our large-scale dataset, the performance of an existing agent can be pushed up (+11% absolute with regard to previous SoTA) to a significantly new best of 80% single-run success rate on the R2R test split by simple imitation learning. The
    
[^24]: Strahler数的统计力学：基于随机和自然语言句子的研究

    Statistical Mechanics of Strahler Number via Random and Natural Language Sentences. (arXiv:2307.02697v1 [cs.CL])

    [http://arxiv.org/abs/2307.02697](http://arxiv.org/abs/2307.02697)

    本文通过统计力学分析自然语言句子树结构的Strahler数的上下限，发现它几乎总是3或4，并证明它是处理句子所需记忆量的下限。同时，对随机树进行的分析揭示出Strahler数的增长模式，揭示了它作为自然语言句子特征的统计基础。

    

    Strahler数最初被提出用于描述河流分支的复杂性，并找到了各种应用。本文提出了计算自然语言句子树结构的Strahler数上下限的方法，这些结构可以在一个大型数据集中进行统计力学分析。通过对语法注释数据的经验性测量，显示自然语言句子的Strahler数几乎总是3或4，与Strahler（1957年）和Horton（1945年）报道的河流分流情况类似。从该数值的理论观点出发，我们证明它是在特定模型下处理句子所需记忆量的下限。对随机树进行的数学分析进一步假设了Strahler数的性质，揭示出它并非常数而是以对数形式增长。这一发现揭示了Strahler数作为描述自然语言句子特征的统计基础。

    The Strahler number was originally proposed to characterize the complexity of river bifurcation and has found various applications. This article proposes computation of the Strahler number's upper and lower limits for natural language sentence tree structures, which are available in a large dataset allowing for statistical mechanics analysis.  Through empirical measurements across grammatically annotated data, the Strahler number of natural language sentences is shown to be almost always 3 or 4, similar to the case of river bifurcation as reported by Strahler (1957) and Horton (1945).  From the theory behind the number, we show that it is the lower limit of the amount of memory required to process sentences under a particular model. A mathematical analysis of random trees provides a further conjecture on the nature of the Strahler number, revealing that it is not a constant but grows logarithmically. This finding uncovers the statistical basics behind the Strahler number as a character
    
[^25]: 扩展事件类型本体：使用精调的大型语言模型添加动词和类别

    Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions. (arXiv:2306.02130v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02130](http://arxiv.org/abs/2306.02130)

    本论文研究使用精调的大型语言模型对数据进行预注释，以扩展事件类型本体。通过研究启发式方法和自动分数的应用，提高注释的效率和准确性。

    

    本项目研究了使用高级机器学习方法，特别是精调的大型语言模型，对数据进行预注释以进行词汇扩展任务，即将描述性词汇（动词）添加到现有的（但尚不完善的）事件类型本体中。我们关注了几个研究问题，从研究可能的启发式方法，为注释者提供至少提示，包括哪些动词在当前版本的本体之外，到可能使用自动分数帮助注释者更高效地确定无法分配到任何现有类别的动词，从而作为新类别的种子。我们还认真研究了自动分数与人工注释之间的相关性。尽管相关性较强，但由于其近似线性关系，对注释本身的影响较小。

    In this project, we have investigated the use of advanced machine learning methods, specifically fine-tuned large language models, for pre-annotating data for a lexical extension task, namely adding descriptive words (verbs) to an existing (but incomplete, as of yet) ontology of event types. Several research questions have been focused on, from the investigation of a possible heuristics to provide at least hints to annotators which verbs to include and which are outside the current version of the ontology, to the possible use of the automatic scores to help the annotators to be more efficient in finding a threshold for identifying verbs that cannot be assigned to any existing class and therefore they are to be used as seeds for a new class. We have also carefully examined the correlation of the automatic scores with the human annotation. While the correlation turned out to be strong, its influence on the annotation proper is modest due to its near linearity, even though the mere fact o
    
[^26]: 领域掌握水平基准：用于评估大型语言模型全面领域知识的不断更新的基准——初步发布。（arXiv:2304.11679v1 [cs.CL]）

    Domain Mastery Benchmark: An Ever-Updating Benchmark for Evaluating Holistic Domain Knowledge of Large Language Model--A Preliminary Release. (arXiv:2304.11679v1 [cs.CL])

    [http://arxiv.org/abs/2304.11679](http://arxiv.org/abs/2304.11679)

    DomMa 是一个用于测试大型语言模型领域知识理解能力的综合基准，它分为中英文10万个问题，并基于112个一级学科分类不断更新数据集。

    

    领域知识指对特定主题、行业、领域或特别兴趣领域的深入理解、专业知识和熟悉程度。现有的基准都缺乏对领域知识评估的整体设计。我们坚信，领域语言理解的真正能力只能通过全面深入的基准来公平地评估，因此我们提出了Domma领域掌握水平基准。DomMa旨在测试大型语言模型（LLM）对领域知识的理解能力，具有广泛的领域覆盖、大量数据和基于中国112个一级学科分类不断更新的数据集。DomMa包含10万个问题，其中包括中文和英文，来源于中国大学的研究生入学考试和本科考试。我们还提出了更适合LLMs的基准和评估流程的设计。

    Domain knowledge refers to the in-depth understanding, expertise, and familiarity with a specific subject, industry, field, or area of special interest. The existing benchmarks are all lack of an overall design for domain knowledge evaluation. Holding the belief that the real ability of domain language understanding can only be fairly evaluated by an comprehensive and in-depth benchmark, we introduces the Domma, a Domain Mastery Benchmark. DomMa targets at testing Large Language Models (LLMs) on their domain knowledge understanding, it features extensive domain coverage, large data volume, and a continually updated data set based on Chinese 112 first-level subject classifications. DomMa consist of 100,000 questions in both Chinese and English sourced from graduate entrance examinations and undergraduate exams in Chinese college. We have also propose designs to make benchmark and evaluation process more suitable to LLMs.
    
[^27]: 从检索到生成：高效且有效的实体集扩展方法

    From Retrieval to Generation: Efficient and Effective Entity Set Expansion. (arXiv:2304.03531v1 [cs.CL])

    [http://arxiv.org/abs/2304.03531](http://arxiv.org/abs/2304.03531)

    本文提出了GenExpan，一种基于生成式预训练语言模型的实体集扩展框架，利用前缀树保证实体生成的有效性，采用自动生成的类名来引导模型生成同一类实体，从而提高了效率和可扩展性。

    

    实体集扩展（ESE）是一项至关重要的任务，旨在扩展由小的种子实体集描述的目标语义类的实体。大多数现有的ESE方法是基于检索的框架，需要提取实体的上下文特征，并计算种子实体和候选实体之间的相似性。为了实现这两个目的，它们必须迭代地遍历语料库和数据集中提供的实体词汇，导致效率和可扩展性较差。实验结果表明，基于检索的ESE方法消耗的时间与实体词汇和语料库的大小成线性增长。本文首先提出了一种生成式ESE框架，Generative Entity Set Expansion (GenExpan)，它利用生成式预训练语言模型来完成ESE任务。具体而言，采用前缀树来保证实体生成的有效性，并采用自动生成的类名来引导模型生成同一类实体。

    Entity Set Expansion (ESE) is a critical task aiming to expand entities of the target semantic class described by a small seed entity set. Most existing ESE methods are retrieval-based frameworks that need to extract the contextual features of entities and calculate the similarity between seed entities and candidate entities. To achieve the two purposes, they should iteratively traverse the corpus and the entity vocabulary provided in the datasets, resulting in poor efficiency and scalability. The experimental results indicate that the time consumed by the retrieval-based ESE methods increases linearly with entity vocabulary and corpus size. In this paper, we firstly propose a generative ESE framework, Generative Entity Set Expansion (GenExpan), which utilizes a generative pre-trained language model to accomplish ESE task. Specifically, a prefix tree is employed to guarantee the validity of entity generation, and automatically generated class names are adopted to guide the model to gen
    
[^28]: 使用扩散模型合成混合类型的电子健康记录

    Synthesizing Mixed-type Electronic Health Records using Diffusion Models. (arXiv:2302.14679v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14679](http://arxiv.org/abs/2302.14679)

    本论文研究了使用扩散模型合成混合类型电子健康记录的潜力，与现有方法相比，在数据质量、实用性和增强方面表现出更好的性能，但在隐私方面存在权衡。

    

    电子健康记录（EHRs）包含敏感的患者信息，在共享此类数据时存在隐私问题。合成数据生成是缓解这些风险的一种有希望的解决方案，通常依赖于深度生成模型，如生成对抗网络（GANs）。然而，最近的研究表明，扩散模型在GANs之上具有几个优势，例如生成更真实的合成数据和稳定的训练以生成包括图像、文本和声音在内的数据模态。在这项工作中，我们研究了扩散模型在生成真实混合类型表格EHRs方面的潜力，将TabDDPM模型与现有方法在四个数据集上进行了数据质量、实用性、隐私和增强方面的比较。我们的实验证明，除隐私方面外，TabDDPM在所有评估指标上均优于现有模型，这证实了隐私和实用性之间的权衡。

    Electronic Health Records (EHRs) contain sensitive patient information, which presents privacy concerns when sharing such data. Synthetic data generation is a promising solution to mitigate these risks, often relying on deep generative models such as Generative Adversarial Networks (GANs). However, recent studies have shown that diffusion models offer several advantages over GANs, such as generation of more realistic synthetic data and stable training in generating data modalities, including image, text, and sound. In this work, we investigate the potential of diffusion models for generating realistic mixed-type tabular EHRs, comparing TabDDPM model with existing methods on four datasets in terms of data quality, utility, privacy, and augmentation. Our experiments demonstrate that TabDDPM outperforms the state-of-the-art models across all evaluation metrics, except for privacy, which confirms the trade-off between privacy and utility.
    
[^29]: 让我们来聊聊吧！与ChatGPT的对话：技术，应用和限制。

    Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations. (arXiv:2302.13817v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13817](http://arxiv.org/abs/2302.13817)

    本文讨论了聊天机器人的历史概述以及ChatGPT背后的技术，强调了它在医疗保健、教育和研究中的潜在应用，并指出了其隐私和道德方面的担忧以及当前版本的重要限制。

    

    一款能够生成像人类一样的句子和写出连贯文章的人工智能聊天机器人ChatGPT的出现引起了世界的关注。本文讨论了聊天机器人的历史概述以及ChatGPT背后的技术。此外，还强调了ChatGPT在各个领域，包括医疗保健，教育和研究中的潜在应用。尽管有着令人期待的结果，但是ChatGPT周围存在着一些隐私和道德方面的担忧。另外，我们还强调了当前版本ChatGPT的一些重要限制。我们还向ChatGPT提出了一些问题，以便它表达自己的看法。

    The emergence of an AI-powered chatbot that can generate human-like sentences and write coherent essays has caught the world's attention. This paper discusses the historical overview of chatbots and the technology behind Chat Generative Pre-trained Transformer, better known as ChatGPT. Moreover, potential applications of ChatGPT in various domains, including healthcare, education, and research, are highlighted. Despite promising results, there are several privacy and ethical concerns surrounding ChatGPT. In addition, we highlight some of the important limitations of the current version of ChatGPT. We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer.
    
[^30]: 基于自动生成语言模型的自动机表示任务知识

    Automaton-Based Representations of Task Knowledge from Generative Language Models. (arXiv:2212.01944v3 [cs.FL] UPDATED)

    [http://arxiv.org/abs/2212.01944](http://arxiv.org/abs/2212.01944)

    提出了一个算法GLM2FSA，能够自动从任务目标的简短自然语言描述中提取任务知识并构建一个编码高层次任务知识的有限状态自动机，构建的自动机可以被正式验证。

    

    基于自动机的任务知识表示在控制和规划序列决策问题中扮演着重要角色。然而，获取构建此类自动机所需的高层次任务知识通常很困难。同时，大规模自动生成语言模型可以自动生成相关任务知识。然而，自动生成语言模型的文本输出不能正式验证或用于顺序决策。我们提出了一个名为GLM2FSA的新算法，它从任务目标的简短自然语言描述中构建一个编码高层次任务知识的有限状态自动机（FSA）。GLM2FSA首先向GLM发送查询以提取文本形式的任务知识，然后它建立一个FSA来表示这种基于文本的知识。因此，所提出的算法填补了自然语言任务描述和自动机表示之间的差距，构建的FSA可以针对用户定义的规格进行正式验证。

    Automaton-based representations of task knowledge play an important role in control and planning for sequential decision-making problems. However, obtaining the high-level task knowledge required to build such automata is often difficult. Meanwhile, large-scale generative language models (GLMs) can automatically generate relevant task knowledge. However, the textual outputs from GLMs cannot be formally verified or used for sequential decision-making. We propose a novel algorithm named GLM2FSA, which constructs a finite state automaton (FSA) encoding high-level task knowledge from a brief natural-language description of the task goal. GLM2FSA first sends queries to a GLM to extract task knowledge in textual form, and then it builds an FSA to represent this text-based knowledge. The proposed algorithm thus fills the gap between natural-language task descriptions and automaton-based representations, and the constructed FSA can be formally verified against user-defined specifications. We a
    
[^31]: VT-CLIP: 用视觉引导文本增强视觉-语言模型

    VT-CLIP: Enhancing Vision-Language Models with Visual-guided Texts. (arXiv:2112.02399v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2112.02399](http://arxiv.org/abs/2112.02399)

    VT-CLIP通过视觉引导文本来增强视觉-语言模型CLIP，在下游任务中展现出更好的迁移性能。

    

    最近，对于其可转移的视觉表示学习，对比语言-图像预训练（CLIP）引起了越来越多的关注。然而，由于数据集内的语义差距，CLIP的预训练图像-文本对齐在下游任务中变得次优，严重影响了其迁移性能。为了更好地适应跨模态嵌入空间，我们提出了通过视觉引导文本来增强CLIP，命名为VT-CLIP。具体来说，我们通过注意机制引导不同类别的文本特征自适应地探索图像上的信息区域，并聚合视觉特征。这样，文本就成为了视觉引导的，即与下游图像更语义相关，这极大地有益于类别匹配的过程。在少样本设置中，我们评估了我们的VT-CLIP在11个知名分类数据集上的有效性。

    Contrastive Language-Image Pre-training (CLIP) has drawn increasing attention recently for its transferable visual representation learning. However, due to the semantic gap within datasets, CLIP's pre-trained image-text alignment becomes sub-optimal on downstream tasks, which severely harms its transferring performance. To better adapt the cross-modality embedding space, we propose to enhance CLIP via Visual-guided Texts, named VT-CLIP. Specifically, we guide textual features of different categories to adaptively explore informative regions on the image and aggregate visual features by attention mechanisms. In this way, the texts become visual-guided, namely, more semantically correlated with downstream images, which greatly benefits the category-wise matching process. In few-shot settings, we evaluate our VT-CLIP on 11 well-known classification datasets to demonstrate its effectiveness.
    

