# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model.](http://arxiv.org/abs/2304.15010) | 本文提出了LLaMA-Adapter V2，这是一个参数高效的视觉指令模型，通过解锁更多可学习的参数，早期融合策略和联合训练策略，能够更好地处理视觉输入和精确地执行开放式视觉指令。 |
| [^2] | [Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs.](http://arxiv.org/abs/2304.14999) | 本文实证分析了参数高效微调技术在大型语言模型中的优势和劣势，提供了选择优化微调技术的框架，同时揭示了在低数据场景下PEFT技术收敛速度较慢的事实。 |
| [^3] | [Interpreting Vision and Language Generative Models with Semantic Visual Priors.](http://arxiv.org/abs/2304.14986) | 本研究提出了一种利用SHAP框架和视觉先验知识生成全面、有意义解释的方法，相较于传统方法具有更低的计算成本、更高的解释表现力，并可以推广到其他模型上。 |
| [^4] | [CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data.](http://arxiv.org/abs/2304.14953) | 本文提出了一个流程，通过使用Common Crawl，从互联网上收集PDF文件，构建一个大规模、多样化、多语言的语料库。我们分享了一个CCpdf语料库，为研究人员提供了进行视觉丰富文档研究的机会。 |
| [^5] | [An Empirical Study of Multimodal Model Merging.](http://arxiv.org/abs/2304.14933) | 本研究通过融合在不同模态上训练的transformer进行多模态模型融合，并提出一种参数有效的模态不可知架构，形成有效的训练配方。 |
| [^6] | [HQP: A Human-Annotated Dataset for Detecting Online Propaganda.](http://arxiv.org/abs/2304.14931) | HQP是一个人工标注的网络宣传检测数据集，与现有的弱标签数据集相比，使用HQP进行训练可以提高44%的准确率。 |
| [^7] | [ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations.](http://arxiv.org/abs/2304.14827) | 本论文评估了ChatGPT在句子级别的时间、因果和语篇关系任务中的性能，发现其在检测和推理因果关系上表现出色，但在识别时间顺序方面可能存在问题。 |
| [^8] | [SemEval-2023 Task 11: Learning With Disagreements (LeWiDi).](http://arxiv.org/abs/2304.14803) | 该论文提出利用NLP数据集中评分者的不同意见来培养和评估NLP模型的方法，通过统一的框架来促进这种方法。 |
| [^9] | [ResiDual: Transformer with Dual Residual Connections.](http://arxiv.org/abs/2304.14802) | 本文提出了具有Pre-Post-LN双重残差连接的新型Transformer架构ResiDual，解决了Post-LN和Pre-LN存在的问题，并具有优越的性能表现。 |
| [^10] | [Are the Best Multilingual Document Embeddings simply Based on Sentence Embeddings?.](http://arxiv.org/abs/2304.14796) | 本文系统比较了从句子级别嵌入中产生文档级嵌入的方法，基于预训练的多语言模型LASER、LaBSE和Sentence BERT。我们着重比较了输入令牌数截断、句子平均以及一些简单的窗口方法，对三个多语言和跨语言任务表现进行了比较。 |
| [^11] | [Training and Evaluation of a Multilingual Tokenizer for GPT-SW3.](http://arxiv.org/abs/2304.14780) | 本文介绍了GPT-SW3的多语言分词器，通过使用SentencePiece库和BPE算法在Nordic Pile上训练，评估了其对于不同语言的表现和性能。 |
| [^12] | [RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction.](http://arxiv.org/abs/2304.14770) | 本文提出了一种名为RexUIE的方法，采用递归机制和显式模式说明，实现通用信息提取(UIE)。与以往的模型相比，RexUIE在提取不同模式时不会出现冲突，并且显式模式说明器有助于提高模型的泛化能力和性能，特别是在低资源情况下。 |
| [^13] | [Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain.](http://arxiv.org/abs/2304.14745) | 本文提出了一种新方法，通过探索预训练语言模型（PLM）学习车辆维修领域组件的特定材料，成功克服了数据稀疏性问题和缺乏注释数据集的问题。 |
| [^14] | [Cost-Sensitive Self-Training for Optimizing Non-Decomposable Metrics.](http://arxiv.org/abs/2304.14738) | 本研究提出了代价敏感自训练（CSST）框架，可以更好地利用未标记的数据优化不可分解指标，为处理具有复杂目标的实际机器学习系统提供了实用的解决方案。 |
| [^15] | [Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks.](http://arxiv.org/abs/2304.14732) | 提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。 |
| [^16] | [Towards autonomous system: flexible modular production system enhanced with large language model agents.](http://arxiv.org/abs/2304.14721) | 本论文介绍了一种将大语言模型、数字孪生和工业自动化系统相结合的框架，实现生产过程的智能化规划和控制。通过LLM代理的协调控制，实现了灵活生产的自主规划和控制，能够处理未预定义的任务并规划生产过程。 |
| [^17] | [CED: Catalog Extraction from Documents.](http://arxiv.org/abs/2304.14662) | 该论文提出一种目录从文档中提取（CED）的新任务，通过构建大规模的手动注释语料库并提出一个基于转换的框架来解决这个问题。实验结果表明，该方法优于基准系统并具有良好的迁移能力。 |
| [^18] | [Antisemitic Messages? A Guide to High-Quality Annotation and a Labeled Dataset of Tweets.](http://arxiv.org/abs/2304.14599) | 本文提供了一个反犹太主义言论的推文标注数据集，使用严格的定义标注，有助于自动检测仇恨言论，减少误判。 |
| [^19] | [A logical word embedding for learning grammar.](http://arxiv.org/abs/2304.14590) | 这篇论文介绍了一种逻辑语法嵌入模型(LGE)，它可以从文本语料库中无监督进行推理，产生简明易懂的输出，能够透明地生成新句子，并且可以从仅有一百句话的语料中进行学习。 |
| [^20] | [Improving Knowledge Graph Entity Alignment with Graph Augmentation.](http://arxiv.org/abs/2304.14585) | 该论文提出了 GAEA，一种基于图形增强的实体对齐方法，它利用实体-关系编码器生成实体的潜在表示，并使用图形增强创建两个图形视图，以增强实体对齐能力。 |
| [^21] | [Appropriateness is all you need!.](http://arxiv.org/abs/2304.14553) | 在chatbot的使用中，应该依据适当性原则而非纯粹的安全性原则来进行评估，以避免其受限制。 |
| [^22] | [Discourse over Discourse: The Need for an Expanded Pragmatic Focus in Conversational AI.](http://arxiv.org/abs/2304.14543) | 对话的论述是现代对话人工智能概括及其它应用的普遍限制，因此我们需要从语用角度拓展对话人工智能的研究。 |
| [^23] | [Deep Transfer Learning for Automatic Speech Recognition: Towards Better Generalization.](http://arxiv.org/abs/2304.14535) | 本文Survey了基于DTL的ASR框架，并介绍了如何使用实际数据集进行深度迁移学习以达到更好的泛化性能。 |
| [^24] | [Multivariate Representation Learning for Information Retrieval.](http://arxiv.org/abs/2304.14522) | 本论文提出一种多元分布模型的信息检索表示学习框架，可无缝集成到现有近似最近邻算法中以实现高效检索。 |
| [^25] | [Understanding Shared Speech-Text Representations.](http://arxiv.org/abs/2304.14514) | 本文研究了将文本整合进入端到端语音模型中训练的方法，通过研究无语音域自适应和激活的相似性，发现持续模型对共享语音-文本表示很重要，共享编码器学习了一个比单模态更紧凑重叠的语音-文本表示，这部分解释了Maestro共享的语音-文本表示有效的原因。 |
| [^26] | [Visual Referential Games Further the Emergence of Disentangled Representations.](http://arxiv.org/abs/2304.14511) | 本文研究了视觉指称游戏中组合性、解耦和系统性之间的关系，发现基于Obverter建筑的游戏优于无监督学习方法。同时，通过新的解耦损失函数和位置再标定任务改进了性能。 |
| [^27] | [Framing the News:From Human Perception to Large Language Model Inferences.](http://arxiv.org/abs/2304.14456) | 本文研究了新闻标题的框架辨别问题，并使用大型语言模型进行了实验，结果表明使用 GPT-3.5 方法可以提高分类任务的性能，达到了 68.13% 的 F1 分数。 |
| [^28] | [PMC-LLaMA: Further Finetuning LLaMA on Medical Papers.](http://arxiv.org/abs/2304.14454) | 本文介绍了一个针对医学领域进一步微调的开源语言模型PMC-LLaMA，其通过增加医学知识提高了在生物医学领域的性能表现，有望在生物医学问答领域有更好的应用表现。 |
| [^29] | [Analyzing Vietnamese Legal Questions Using Deep Neural Networks with Biaffine Classifiers.](http://arxiv.org/abs/2304.14447) | 本文提出了一种使用深度神经网络和双仿射分类器分析越南法律问题的方法，实现找到回答问题所需信息的所有片段。实验结果表明该模型效果优于强基线。 |
| [^30] | [Generative AI Perceptions: A Survey to Measure the Perceptions of Faculty, Staff, and Students on Generative AI Tools in Academia.](http://arxiv.org/abs/2304.14415) | 本文调查了学术界使用生成型人工智能工具ChatGPT的影响，旨在了解其如何革新工程教育并改变技术、教职工与学生之间的关系。调查可供其他大学和机构使用。 |
| [^31] | [Controllable Data Augmentation for Context-Dependent Text-to-SQL.](http://arxiv.org/abs/2304.13902) | 提出了ConDA方法，可以生成交互式问题和相应的SQL结果，并设计了SQL对话状态和过滤方法来增强数据多样性和质量，能够提高复杂问题的性能。 |
| [^32] | [Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery.](http://arxiv.org/abs/2304.13714) | 本研究评估了在临床环境中使用GPT-3.5和GPT-4解决医学问题的安全性以及与信息技术咨询服务报告的一致性。研究结果表明，两个LLMs都可以以安全和一致的方式满足医生的信息需求。 |
| [^33] | [Towards Multi-Modal DBMSs for Seamless Querying of Texts and Tables.](http://arxiv.org/abs/2304.13559) | 提出了一种新型数据库系统MMDB，它可以无缝查询文本和表格数据，通过使用所谓的多模态运算符（MMOps）实现文本集合的转换，该方法不仅优于现有的最先进方法，在对未见过的数据进行模型微调时，也具有显著的优势。 |
| [^34] | [IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named Entity Recognition using Knowledge Bases.](http://arxiv.org/abs/2304.10637) | 本文提出了一种基于知识库的上下文增强的多语言命名实体识别方法，通过识别、链接和预测实体类别，能够准确地分类细粒度和新兴实体。 |
| [^35] | [LLM as A Robotic Brain: Unifying Egocentric Memory and Control.](http://arxiv.org/abs/2304.09349) | 本文提出了一个统一自我中心记忆和控制的框架LLM-Brain，使用大规模语言模型作为机器人大脑进行零-shot学习。该框架包括封闭式多轮对话，覆盖了感知、规划、控制和记忆，具有很好的泛化性能，适用于多个机器人任务。 |
| [^36] | [chatIPCC: Grounding Conversational AI in Climate Science.](http://arxiv.org/abs/2304.05510) | chatIPCC是一个基于气候科学的对话型人工智能系统，通过整合IPCC AR6中的信息来增强GPT-4模型，并提供可靠、科学准确的答案。 |
| [^37] | [The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges.](http://arxiv.org/abs/2304.05351) | 本研究对ChatGPT在股票预测方面进行了零样本分析，结果表明其预测股票移动的表现不如最先进和传统方法，需要进一步改进。 |
| [^38] | [Convolution-enhanced Evolving Attention Networks.](http://arxiv.org/abs/2212.08330) | 本文提出了一种新颖且通用的卷积增强进化注意力机制，通过一系列残差卷积模块直接模拟标记间关系的演变，在不同层次之间促进信息流动。 |
| [^39] | [Automatic Severity Assessment of Dysarthric speech by using Self-supervised Model with Multi-task Learning.](http://arxiv.org/abs/2210.15387) | 该论文提出了一种使用自监督模型和多任务学习相结合的自动评估发音障碍严重程度的方法，在较少数据的情况下实现了向传统方法的优化，并且相对提高了1.25%的F1-score。 |
| [^40] | [Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks.](http://arxiv.org/abs/2210.04476) | 本论文提出了一种使用演示和自然语言指令相结合的机器人任务学习方法，其基于两种模式相互消除歧义来有效地指定和教授机器人复杂任务。此方法可以减少教师工作量并实现更好的泛化性能。 |

# 详细

[^1]: LLaMA-Adapter V2: 参数高效的视觉指令模型

    LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model. (arXiv:2304.15010v1 [cs.CV])

    [http://arxiv.org/abs/2304.15010](http://arxiv.org/abs/2304.15010)

    本文提出了LLaMA-Adapter V2，这是一个参数高效的视觉指令模型，通过解锁更多可学习的参数，早期融合策略和联合训练策略，能够更好地处理视觉输入和精确地执行开放式视觉指令。

    

    近期的研究方向是如何将大型语言模型（LLMs）高效地转化为指令跟随者，而为多模态推理训练LLM的研究仍然较少。虽然最近的LLaMA-Adapter证明了用LLM处理视觉输入的潜力，但它仍然不能很好地推广到开放式视觉指令，并且落后于GPT-4。本文提出了LLaMA-Adapter V2，这是一个参数高效的视觉指令模型。

    How to efficiently transform large language models (LLMs) into instruction followers is recently a popular research direction, while training LLM for multi-modal reasoning remains less explored. Although the recent LLaMA-Adapter demonstrates the potential to handle visual inputs with LLMs, it still cannot generalize well to open-ended visual instructions and lags behind GPT-4. In this paper, we present LLaMA-Adapter V2, a parameter-efficient visual instruction model. Specifically, we first augment LLaMA-Adapter by unlocking more learnable parameters (e.g., norm, bias and scale), which distribute the instruction-following ability across the entire LLaMA model besides adapters. Secondly, we propose an early fusion strategy to feed visual tokens only into the early LLM layers, contributing to better visual knowledge incorporation. Thirdly, a joint training paradigm of image-text pairs and instruction-following data is introduced by optimizing disjoint groups of learnable parameters. This 
    
[^2]: LLM参数高效微调技术的优势和劣势的实证分析

    Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs. (arXiv:2304.14999v1 [cs.CL])

    [http://arxiv.org/abs/2304.14999](http://arxiv.org/abs/2304.14999)

    本文实证分析了参数高效微调技术在大型语言模型中的优势和劣势，提供了选择优化微调技术的框架，同时揭示了在低数据场景下PEFT技术收敛速度较慢的事实。

    

    随着基于语言模型的模型规模呈指数级增长，高效的适应方法变得越来越关键。参数高效微调（PEFT）是目前最流行的适用于大型语言模型（LLM）的方法之一，只需要修改模型参数的一小部分，最近提出了几种具有不同权衡的PEFT技术。我们在代表性的LLM FLAN-T5模型上提供各种PEFT技术的全面和统一的基准测试，并评估在分类和生成数据集的不同数据规模下的模型性能。基于此，我们提供了一个框架，根据任务类型和数据可用性选择最佳的微调技术。与传统观念相反，我们通过实证证明PEFT技术在低数据场景下收敛速度比完全微调慢，并提出了PEFT方法需要表现良好和有效收敛所需要的数据量。

    As foundation models continue to exponentially scale in size, efficient methods of adaptation become increasingly critical. Parameter-efficient fine-tuning (PEFT), a recent class of techniques that require only modifying a small percentage of the model parameters, is currently the most popular method for adapting large language models (LLMs). Several PEFT techniques have recently been proposed with varying tradeoffs. We provide a comprehensive and uniform benchmark of various PEFT techniques across a representative LLM, the FLAN-T5 model, and evaluate model performance across different data scales of classification and generation datasets. Based on this, we provide a framework for choosing the optimal fine-tuning techniques given the task type and data availability. Contrary to popular belief, we also empirically prove that PEFT techniques converge slower than full tuning in low data scenarios, and posit the amount of data required for PEFT methods to both perform well and converge eff
    
[^3]: 利用语义视觉先验解释视觉和语言生成模型

    Interpreting Vision and Language Generative Models with Semantic Visual Priors. (arXiv:2304.14986v1 [cs.CV])

    [http://arxiv.org/abs/2304.14986](http://arxiv.org/abs/2304.14986)

    本研究提出了一种利用SHAP框架和视觉先验知识生成全面、有意义解释的方法，相较于传统方法具有更低的计算成本、更高的解释表现力，并可以推广到其他模型上。

    

    在应用于图像到文本模型时，可解释性方法通常提供逐个标记的解释，即为所生成的序列中的每个标记计算视觉解释。这些解释计算成本高，无法全面解释模型的输出。因此，这些模型通常需要某种近似方法，最终会导致误导性的解释。本文提出了一种基于SHAP的框架，该框架允许利用输出序列的含义表示生成全面、有意义的解释。此外，通过利用视觉主干网络中的语义先验知识，我们提取了任意数量的特征，并能够在大规模模型上高效计算Shapley值，同时生成高度明确的视觉解释。我们证明了我们的方法在更低的计算成本下生成语义上更具表现力的解释，并且可以推广到其他模型上。

    When applied to Image-to-text models, interpretability methods often provide token-by-token explanations namely, they compute a visual explanation for each token of the generated sequence. Those explanations are expensive to compute and unable to comprehensively explain the model's output. Therefore, these models often require some sort of approximation that eventually leads to misleading explanations. We develop a framework based on SHAP, that allows for generating comprehensive, meaningful explanations leveraging the meaning representation of the output sequence as a whole. Moreover, by exploiting semantic priors in the visual backbone, we extract an arbitrary number of features that allows the efficient computation of Shapley values on large-scale models, generating at the same time highly meaningful visual explanations. We demonstrate that our method generates semantically more expressive explanations than traditional methods at a lower compute cost and that it can be generalized o
    
[^4]: CCpdf：从网络爬虫数据中构建高质量的视觉丰富文档语料库

    CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data. (arXiv:2304.14953v1 [cs.CL])

    [http://arxiv.org/abs/2304.14953](http://arxiv.org/abs/2304.14953)

    本文提出了一个流程，通过使用Common Crawl，从互联网上收集PDF文件，构建一个大规模、多样化、多语言的语料库。我们分享了一个CCpdf语料库，为研究人员提供了进行视觉丰富文档研究的机会。

    

    最近几年，文档理解领域取得了很大进展。这些进展的一部分得益于使用预训练于大量文档的语言模型。然而，文档理解领域中使用的预训练语料库通常单一领域、单语言、或不公开。本文旨在提出一种有效的流程，通过使用Common Crawl，从互联网上收集PDF文件，构建一个大规模、多样化、多语言的语料库。我们对构建流程的所有步骤进行了广泛分析，并提出了一个在数据质量和处理时间之间平衡的解决方案。同时，我们还分享了一个CCpdf语料库，其中包括PDF文件的索引和下载脚本，可以用于语言模型预训练。本文所发布的数据集和工具为研究人员提供了进行视觉丰富文档研究的机会。

    In recent years, the field of document understanding has progressed a lot. A significant part of this progress has been possible thanks to the use of language models pretrained on large amounts of documents. However, pretraining corpora used in the domain of document understanding are single domain, monolingual, or nonpublic. Our goal in this paper is to propose an efficient pipeline for creating a big-scale, diverse, multilingual corpus of PDF files from all over the Internet using Common Crawl, as PDF files are the most canonical types of documents as considered in document understanding. We analysed extensively all of the steps of the pipeline and proposed a solution which is a trade-off between data quality and processing time. We also share a CCpdf corpus in a form or an index of PDF files along with a script for downloading them, which produces a collection useful for language model pretraining. The dataset and tools published with this paper offer researchers the opportunity to 
    
[^5]: 一项多模态模型融合的实证研究

    An Empirical Study of Multimodal Model Merging. (arXiv:2304.14933v1 [cs.CV])

    [http://arxiv.org/abs/2304.14933](http://arxiv.org/abs/2304.14933)

    本研究通过融合在不同模态上训练的transformer进行多模态模型融合，并提出一种参数有效的模态不可知架构，形成有效的训练配方。

    

    模型融合（例如插值或任务算术）将在不同任务上训练的多个模型合并以生成多任务解决方案。该技术在先前的研究中已经被证明成功，其中模型是在相似的任务和相同的初始化下训练的。在本文中，我们通过将在不同模态上训练的transformer进行融合，将此概念扩展到多模态设置。此外，我们针对一个新颖的目标进行研究，在该目标中，我们可以将视觉、语言和跨模态的transformer合并到特定模态的架构中，以创建一个参数有效的模态不可知架构。通过全面的实验，我们系统地研究了影响模型融合后性能的关键因素，包括初始化、融合机制和模型架构。我们的分析得出了一个有效的训练配方，可以通过模型融合来匹配模态不可知基线的性能（即从头开始预训练）。我们的代码可供使用。

    Model merging (e.g., via interpolation or task arithmetic) fuses multiple models trained on different tasks to generate a multi-task solution. The technique has been proven successful in previous studies, where the models are trained on similar tasks and with the same initialization. In this paper, we expand on this concept to a multimodal setup by merging transformers trained on different modalities. Furthermore, we conduct our study for a novel goal where we can merge vision, language, and cross-modal transformers of a modality-specific architecture to create a parameter-efficient modality-agnostic architecture. Through comprehensive experiments, we systematically investigate the key factors impacting model performance after merging, including initialization, merging mechanisms, and model architectures. Our analysis leads to an effective training recipe for matching the performance of the modality-agnostic baseline (i.e. pre-trained from scratch) via model merging. Our code is availa
    
[^6]: HQP：一份人工标注的用于检测网络宣传的数据集

    HQP: A Human-Annotated Dataset for Detecting Online Propaganda. (arXiv:2304.14931v1 [cs.CL])

    [http://arxiv.org/abs/2304.14931](http://arxiv.org/abs/2304.14931)

    HQP是一个人工标注的网络宣传检测数据集，与现有的弱标签数据集相比，使用HQP进行训练可以提高44%的准确率。

    

    网络宣传对社会的完整性构成了严重威胁。然而，现有的检测网络宣传的数据集存在一个关键限制：它们是使用弱标签进行注释的，可能存在噪音甚至错误。为了解决这一限制，本研究做出了以下贡献：（1）我们提出了一个新的数据集HQP（N=30,000），用于检测网络宣传，具有高质量的标注。据我们所知，这是第一个通过人工注释而创建的用于检测网络宣传的数据集。（2）我们证明了，在使用弱标签进行训练时，最先进的语言模型在检测网络宣传方面失败（AUC：64.03）。相比之下，当使用我们的高质量标签进行训练时，最先进的语言模型可以准确地检测网络宣传（AUC：92.25），提高了约44%。（3）为了解决标注成本问题，我们将我们的工作扩展到了少样本学习。具体来说，我们展示了使用一个小型数据集进行提示式学习的方法。

    Online propaganda poses a severe threat to the integrity of societies. However, existing datasets for detecting online propaganda have a key limitation: they were annotated using weak labels that can be noisy and even incorrect. To address this limitation, our work makes the following contributions: (1) We present \dataset: a novel dataset (N=30,000) for detecting online propaganda with high-quality labels. To the best of our knowledge, \dataset is the first dataset for detecting online propaganda that was created through human annotation. (2) We show empirically that state-of-the-art language models fail in detecting online propaganda when trained with weak labels (AUC: 64.03). In contrast, state-of-the-art language models can accurately detect online propaganda when trained with our high-quality labels (AUC: 92.25), which is an improvement of ~44%. (3) To address the cost of labeling, we extend our work to few-shot learning. Specifically, we show that prompt-based learning using a sm
    
[^7]: ChatGPT在句子级关系上的评估：重点关注时间、因果和语篇关系

    ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations. (arXiv:2304.14827v1 [cs.CL])

    [http://arxiv.org/abs/2304.14827](http://arxiv.org/abs/2304.14827)

    本论文评估了ChatGPT在句子级别的时间、因果和语篇关系任务中的性能，发现其在检测和推理因果关系上表现出色，但在识别时间顺序方面可能存在问题。

    

    本文旨在定量评估ChatGPT，在时间关系、因果关系和语篇关系等句间关系方面的性能。考虑到ChatGPT在各种任务中表现出色，我们在13个数据集的整个测试集上进行了广泛的评估，包括时间和因果关系、基于PDTB2.0和基于对话的语篇关系，以及关于对话理解的下游应用。为了获得可靠的结果，我们采用了三种针对每个任务的定制提示模板，包括零-shot提示模板、零-shot提示工程（PE）模板和上下文学习（ICL）提示模板，为所有流行的句对关系分类任务建立了初始基准分数。我们发现，ChatGPT在检测和推理因果关系方面表现出色，但可能不擅长识别句子间的时间顺序。ICL方法特别适用于提高一些数据集上的模型性能。我们的发现为模型改进和有效提示模板的设计提供了一些见解。

    This paper aims to quantitatively evaluate the performance of ChatGPT, an interactive large language model, on inter-sentential relations such as temporal relations, causal relations, and discourse relations. Given ChatGPT's promising performance across various tasks, we conduct extensive evaluations on the whole test sets of 13 datasets, including temporal and causal relations, PDTB2.0-based and dialogue-based discourse relations, and downstream applications on discourse understanding. To achieve reliable results, we adopt three tailored prompt templates for each task, including the zero-shot prompt template, zero-shot prompt engineering (PE) template, and in-context learning (ICL) prompt template, to establish the initial baseline scores for all popular sentence-pair relation classification tasks for the first time. We find that ChatGPT exhibits strong performance in detecting and reasoning about causal relations, while it may not be proficient in identifying the temporal order betwe
    
[^8]: SemEval-2023任务11：学习与分歧（LeWiDi）

    SemEval-2023 Task 11: Learning With Disagreements (LeWiDi). (arXiv:2304.14803v1 [cs.CL])

    [http://arxiv.org/abs/2304.14803](http://arxiv.org/abs/2304.14803)

    该论文提出利用NLP数据集中评分者的不同意见来培养和评估NLP模型的方法，通过统一的框架来促进这种方法。

    

    使用人类判断注释数据的自然语言处理(NLP)数据集之间经常存在着评分者的不同意见，特别是对于依赖主观判断的任务，如情感分析或冒犯性语言检测。针对这些情况，NLP社区已经意识到"调和"这些不同的主观解释的方法是不合适的。许多NLP研究人员因此得出结论，对于注释的语料库，我们应该保留它们之间的分歧。LeWiDi系列共享任务的目的是为了通过提供统一的训练和评估框架来促进这种NLP模型开发方法。我们报告第二个LeWiDi共享任务，与第一个版本有三个关键的不同之处。

    NLP datasets annotated with human judgments are rife with disagreements between the judges. This is especially true for tasks depending on subjective judgments such as sentiment analysis or offensive language detection. Particularly in these latter cases, the NLP community has come to realize that the approach of 'reconciling' these different subjective interpretations is inappropriate. Many NLP researchers have therefore concluded that rather than eliminating disagreements from annotated corpora, we should preserve them-indeed, some argue that corpora should aim to preserve all annotator judgments. But this approach to corpus creation for NLP has not yet been widely accepted. The objective of the LeWiDi series of shared tasks is to promote this approach to developing NLP models by providing a unified framework for training and evaluating with such datasets. We report on the second LeWiDi shared task, which differs from the first edition in three crucial respects: (i) it focuses entire
    
[^9]: ResiDual：具有双重残差连接的Transformer

    ResiDual: Transformer with Dual Residual Connections. (arXiv:2304.14802v1 [cs.CL])

    [http://arxiv.org/abs/2304.14802](http://arxiv.org/abs/2304.14802)

    本文提出了具有Pre-Post-LN双重残差连接的新型Transformer架构ResiDual，解决了Post-LN和Pre-LN存在的问题，并具有优越的性能表现。

    

    由于其卓越的性能，Transformer网络已成为许多任务的首选架构。然而，如何最优化地实现Transformer中的残差连接仍存在争议，而这些残差连接对于有效训练是必不可少的。两个广泛使用的变体是Post-Layer-Normalization(Post-LN)和Pre-Layer-Normalization(Pre-LN) Transformers，它们分别在每个残差块的输出之后或输入之前应用层规范化。尽管两种变体都有它们的优点，但也存在严重的局限性：Post-LN会导致梯度消失问题，从而阻碍训练深层Transformer，而Pre-LN会导致表示崩溃问题，限制模型容量。本文提出了一种新颖的Transformer架构ResiDual，具有Pre-Post-LN(PPLN)，它将Post-LN和Pre-LN中的连接融合在一起，继承了它们的优点，同时避免了它们的局限性。我们进行了理论分析和实证评估，表明ResiDual比现有方法优越，尤其是训练非常深的Transformer。

    Transformer networks have become the preferred architecture for many tasks due to their state-of-the-art performance. However, the optimal way to implement residual connections in Transformer, which are essential for effective training, is still debated. Two widely used variants are the Post-Layer-Normalization (Post-LN) and Pre-Layer-Normalization (Pre-LN) Transformers, which apply layer normalization after each residual block's output or before each residual block's input, respectively. While both variants enjoy their advantages, they also suffer from severe limitations: Post-LN causes gradient vanishing issue that hinders training deep Transformers, and Pre-LN causes representation collapse issue that limits model capacity. In this paper, we propose ResiDual, a novel Transformer architecture with Pre-Post-LN (PPLN), which fuses the connections in Post-LN and Pre-LN together and inherits their advantages while avoids their limitations. We conduct both theoretical analyses and empiric
    
[^10]: 最好的多语言文档嵌入是否仅基于句子嵌入？

    Are the Best Multilingual Document Embeddings simply Based on Sentence Embeddings?. (arXiv:2304.14796v1 [cs.CL])

    [http://arxiv.org/abs/2304.14796](http://arxiv.org/abs/2304.14796)

    本文系统比较了从句子级别嵌入中产生文档级嵌入的方法，基于预训练的多语言模型LASER、LaBSE和Sentence BERT。我们着重比较了输入令牌数截断、句子平均以及一些简单的窗口方法，对三个多语言和跨语言任务表现进行了比较。

    

    在现代自然语言处理中，文本数据的密集向量表征至关重要。从原始文本估计的词嵌入和句子嵌入是在多种需要语义理解的任务中实现最新成果的关键。然而，由于计算需求和缺乏适当的数据，获取文档级别的嵌入是具有挑战性的。相反，大多数方法退而使用基于句子表示的文档嵌入计算。尽管存在一些用于完全编码文档的体系结构和模型，但它们通常仅限于英语和其他几种高资源语言。在本文中，我们基于预训练的多语言模型LASER、LaBSE和Sentence BERT，系统比较从句子中产生文档级表示的方法。我们比较输入令牌数截断、句子平均以及一些简单的窗口方法，在三个多语言和跨语言任务中进行比较。

    Dense vector representations for textual data are crucial in modern NLP. Word embeddings and sentence embeddings estimated from raw texts are key in achieving state-of-the-art results in various tasks requiring semantic understanding. However, obtaining embeddings at the document level is challenging due to computational requirements and lack of appropriate data. Instead, most approaches fall back on computing document embeddings based on sentence representations. Although there exist architectures and models to encode documents fully, they are in general limited to English and few other high-resourced languages. In this work, we provide a systematic comparison of methods to produce document-level representations from sentences based on LASER, LaBSE, and Sentence BERT pre-trained multilingual models. We compare input token number truncation, sentence averaging as well as some simple windowing and in some cases new augmented and learnable approaches, on 3 multiand cross-lingual tasks 
    
[^11]: GPT-SW3多语言分词器的训练与评估

    Training and Evaluation of a Multilingual Tokenizer for GPT-SW3. (arXiv:2304.14780v1 [cs.CL])

    [http://arxiv.org/abs/2304.14780](http://arxiv.org/abs/2304.14780)

    本文介绍了GPT-SW3的多语言分词器，通过使用SentencePiece库和BPE算法在Nordic Pile上训练，评估了其对于不同语言的表现和性能。

    

    本篇论文详细介绍了GPT-SW3所使用的多语言分词器。该分词器使用SentencePiece库和BPE算法在Nordic Pile上进行训练。我们概述了分词器的最重要特点，并分享了其学习词汇的细节。此外，我们系统地分析了分词器在数据中不同语言方面的性能，并进行了评估。

    This paper provides a detailed discussion of the multilingual tokenizer used for GPT-SW3. It was trained on the Nordic Pile using the SentencePiece library and the BPE algorithm. We outline the tokenizer's most important features and share details on its learned vocabulary. In addition, we systematically analyze the properties and evaluate the performance of the tokenizer with regard to the different languages present in the data.
    
[^12]: RexUIE: 一种带显式模式说明的递归方法，用于通用信息提取

    RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction. (arXiv:2304.14770v1 [cs.CL])

    [http://arxiv.org/abs/2304.14770](http://arxiv.org/abs/2304.14770)

    本文提出了一种名为RexUIE的方法，采用递归机制和显式模式说明，实现通用信息提取(UIE)。与以往的模型相比，RexUIE在提取不同模式时不会出现冲突，并且显式模式说明器有助于提高模型的泛化能力和性能，特别是在低资源情况下。

    

    通用信息提取(UIE)因其具有不同目标、异构结构和需求特定模式而备受关注。然而，以前的研究仅通过统一一些任务(如命名实体识别和关系提取)取得了有限的成功，不能真正称之为UIE模型，特别是当提取其他常见模式（如四元组和五元组）时。此外，这些模型采用了一个隐式结构模式说明符，在类型之间建立错误的链接，使模型的泛化和在低资源情况下的性能受到影响。本文重新定义了正式的UIE公式，涵盖了几乎所有提取模式。我们是首次为任何类型的模式引入UIE。此外，我们提出了RexUIE，它是一种带显式模式说明的递归方法，用于 UIE。为了避免不同模式之间的干扰，RexUIE通过递归机制统一提取过程，适应多种提取场景。此外，我们引入了显式模式说明器，指导模型学习给定场景的结构模式，提高了在低资源设置中的泛化和性能。

    Universal Information Extraction (UIE) is an area of interest due to the challenges posed by varying targets, heterogeneous structures, and demand-specific schemas. However, previous works have only achieved limited success by unifying a few tasks, such as Named Entity Recognition (NER) and Relation Extraction (RE), which fall short of being authentic UIE models particularly when extracting other general schemas such as quadruples and quintuples. Additionally, these models used an implicit structural schema instructor, which could lead to incorrect links between types, hindering the model's generalization and performance in low-resource scenarios. In this paper, we redefine the authentic UIE with a formal formulation that encompasses almost all extraction schemas. To the best of our knowledge, we are the first to introduce UIE for any kind of schemas. In addition, we propose RexUIE, which is a Recursive Method with Explicit Schema Instructor for UIE. To avoid interference between diffe
    
[^13]: 由什么构成？学习修车领域组件的可信材料

    Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain. (arXiv:2304.14745v1 [cs.CL])

    [http://arxiv.org/abs/2304.14745](http://arxiv.org/abs/2304.14745)

    本文提出了一种新方法，通过探索预训练语言模型（PLM）学习车辆维修领域组件的特定材料，成功克服了数据稀疏性问题和缺乏注释数据集的问题。

    

    我们提出了一种新的方法，通过探索预训练语言模型（PLM）中的cloze任务样式设置来学习车辆维修领域组件的特定材料，以克服缺乏注释数据集的问题。我们设计了一种新方法，聚合了一组cloze查询模板的显著预测，并表明使用小型高质量或定制的维基百科语料库的领域自适应可以提高性能。当探索资源紧缺的替代方案时，我们发现精简的PLM明显优于经典的基于模式的算法。此外，考虑到我们领域特定组件的98％都是多词表达式，我们成功地利用组成性假设来解决数据稀疏性问题。

    We propose a novel approach to learn domain-specific plausible materials for components in the vehicle repair domain by probing Pretrained Language Models (PLMs) in a cloze task style setting to overcome the lack of annotated datasets. We devise a new method to aggregate salient predictions from a set of cloze query templates and show that domain-adaptation using either a small, high-quality or a customized Wikipedia corpus boosts performance. When exploring resource-lean alternatives, we find a distilled PLM clearly outperforming a classic pattern-based algorithm. Further, given that 98% of our domain-specific components are multiword expressions, we successfully exploit the compositionality assumption as a way to address data sparsity.
    
[^14]: 面向优化不可分解指标的代价敏感自训练

    Cost-Sensitive Self-Training for Optimizing Non-Decomposable Metrics. (arXiv:2304.14738v1 [cs.LG])

    [http://arxiv.org/abs/2304.14738](http://arxiv.org/abs/2304.14738)

    本研究提出了代价敏感自训练（CSST）框架，可以更好地利用未标记的数据优化不可分解指标，为处理具有复杂目标的实际机器学习系统提供了实用的解决方案。

    

    基于自训练的半监督学习算法使得仅使用少量标记数据就能学习到高精度的深度神经网络。然而，大多数自训练的工作都集中在提高精度的目标上，而实际的机器学习系统可能具有不可分解的复杂目标（例如，最大化不同类别召回率的最小值等）。在这项工作中，我们引入了代价敏感自训练（CSST）框架，该框架推广了用于优化不可分解指标的基于自训练的方法。我们证明了我们的框架可以更好地利用未标记的数据优化所需的不可分解指标，假设数据分布与自我训练的分析所做的一样。使用所提出的CSST框架，我们使用深度神经网络获得了针对不同不可分解指标的实际自训练方法（用于视觉和NLP任务）。我们的结果证明了CSST的有效性和可行性。

    Self-training based semi-supervised learning algorithms have enabled the learning of highly accurate deep neural networks, using only a fraction of labeled data. However, the majority of work on self-training has focused on the objective of improving accuracy, whereas practical machine learning systems can have complex goals (e.g. maximizing the minimum of recall across classes, etc.) that are non-decomposable in nature. In this work, we introduce the Cost-Sensitive Self-Training (CSST) framework which generalizes the self-training-based methods for optimizing non-decomposable metrics. We prove that our framework can better optimize the desired non-decomposable metric utilizing unlabeled data, under similar data distribution assumptions made for the analysis of self-training. Using the proposed CSST framework, we obtain practical self-training methods (for both vision and NLP tasks) for optimizing different non-decomposable metrics using deep neural networks. Our results demonstrate th
    
[^15]: 基于SearChain的复杂知识密集型任务中精确、可信和可追溯内容生成的研究

    Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks. (arXiv:2304.14732v1 [cs.CL])

    [http://arxiv.org/abs/2304.14732](http://arxiv.org/abs/2304.14732)

    提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。

    

    随着ChatGPT等大型语言模型（LLM）的广泛应用，如何使LLM生成的内容准确可信在复杂知识密集型任务中变得非常重要。本文提出了一种名为Search-in-the-Chain（SearChain）的新型框架，以改进多跳问题回答等典型复杂知识密集型任务中LLM生成内容的准确性、可信度和可追溯性。SearChain是一个深度集成LLM和信息检索（IR）的框架。在SearChain中，LLM构建查询链，作为多跳问题的分解。链的每个节点都是由IR导向的查询-答案对，以及由LLM生成的该查询的答案。IR验证、完善和跟踪链中每个节点的信息，以指导LLM构建正确的查询链，并最终回答多跳问题。SearChain使LLM从一次性答案转变为多步答案，从而提高了生成内容的准确性和可信度。实验结果表明，SearChain在准确性和可靠性方面优于其他最先进的方法。

    With the wide application of Large Language Models (LLMs) such as ChatGPT, how to make the contents generated by LLM accurate and credible becomes very important, especially in complex knowledge-intensive tasks. In this paper, we propose a novel framework called Search-in-the-Chain (SearChain) to improve the accuracy, credibility and traceability of LLM-generated content for multi-hop question answering, which is a typical complex knowledge-intensive task. SearChain is a framework that deeply integrates LLM and information retrieval (IR). In SearChain, LLM constructs a chain-of-query, which is the decomposition of the multi-hop question. Each node of the chain is a query-answer pair consisting of an IR-oriented query and the answer generated by LLM for this query. IR verifies, completes, and traces the information of each node of the chain, so as to guide LLM to construct the correct chain-of-query, and finally answer the multi-hop question. SearChain makes LLM change from trying to gi
    
[^16]: 朝自主系统迈进：使用大语言模型代理增强的灵活模块化生产系统

    Towards autonomous system: flexible modular production system enhanced with large language model agents. (arXiv:2304.14721v1 [cs.RO])

    [http://arxiv.org/abs/2304.14721](http://arxiv.org/abs/2304.14721)

    本论文介绍了一种将大语言模型、数字孪生和工业自动化系统相结合的框架，实现生产过程的智能化规划和控制。通过LLM代理的协调控制，实现了灵活生产的自主规划和控制，能够处理未预定义的任务并规划生产过程。

    

    本文提出了一种新颖的框架，将大型语言模型（LLM），数字孪生和工业自动化系统结合起来，实现生产过程的智能规划和控制。我们的方法涉及开发包含生产描述信息的数字孪生系统，并将自动化系统改造为提供统一接口的细粒度功能或模块，以供自动化组件或模块执行。随后，设计LLM代理来解释数字孪生中的描述性信息，并通过RESTful接口控制物理系统。这些LLM代理作为自动化系统内的智能代理，实现了灵活生产的自主规划和控制。给定一个任务指令作为输入，LLM代理协调一系列原子功能和技能来完成任务。我们展示了我们实现的原型如何处理未预定义的任务，并计划生产过程。

    In this paper, we present a novel framework that combines large language models (LLMs), digital twins and industrial automation system to enable intelligent planning and control of production processes. Our approach involves developing a digital twin system that contains descriptive information about the production and retrofitting the automation system to offer unified interfaces of fine-granular functionalities or skills executable by automation components or modules. Subsequently, LLM-Agents are designed to interpret descriptive information in the digital twins and control the physical system through RESTful interfaces. These LLM-Agents serve as intelligent agents within an automation system, enabling autonomous planning and control of flexible production. Given a task instruction as input, the LLM-agents orchestrate a sequence of atomic functionalities and skills to accomplish the task. We demonstrate how our implemented prototype can handle un-predefined tasks, plan a production p
    
[^17]: CED: 文档中的目录提取

    CED: Catalog Extraction from Documents. (arXiv:2304.14662v1 [cs.CL])

    [http://arxiv.org/abs/2304.14662](http://arxiv.org/abs/2304.14662)

    该论文提出一种目录从文档中提取（CED）的新任务，通过构建大规模的手动注释语料库并提出一个基于转换的框架来解决这个问题。实验结果表明，该方法优于基准系统并具有良好的迁移能力。

    

    长文档逐句信息提取是一项繁琐且容易出错的任务。作为文档结构的指示器，目录自然地将文档分成段落并提供有益的级联语义，有助于减少搜索空间。尽管目录很有用，但在没有外部知识的帮助下，很难提取目录。对于遵循特定模板的文档，正则表达式可用于提取目录。然而，在处理来自不同来源和不同格式的文档时，手工启发式规则不适用。为解决这个问题，我们建立了一个大规模手动注释的语料库，这是目录从文档中提取（CED）任务的第一个数据集。基于此语料库，我们提出了一个基于转换的框架，用于将文档解析成目录树。实验结果表明，我们提出的方法优于基准系统，并具有良好的迁移能力。我们认为

    Sentence-by-sentence information extraction from long documents is an exhausting and error-prone task. As the indicator of document skeleton, catalogs naturally chunk documents into segments and provide informative cascade semantics, which can help to reduce the search space. Despite their usefulness, catalogs are hard to be extracted without the assist from external knowledge. For documents that adhere to a specific template, regular expressions are practical to extract catalogs. However, handcrafted heuristics are not applicable when processing documents from different sources with diverse formats. To address this problem, we build a large manually annotated corpus, which is the first dataset for the Catalog Extraction from Documents (CED) task. Based on this corpus, we propose a transition-based framework for parsing documents into catalog trees. The experimental results demonstrate that our proposed method outperforms baseline systems and shows a good ability to transfer. We believ
    
[^18]: 反犹太主义言论？高质量标注指南和推文标注数据集的指南

    Antisemitic Messages? A Guide to High-Quality Annotation and a Labeled Dataset of Tweets. (arXiv:2304.14599v1 [cs.CL])

    [http://arxiv.org/abs/2304.14599](http://arxiv.org/abs/2304.14599)

    本文提供了一个反犹太主义言论的推文标注数据集，使用严格的定义标注，有助于自动检测仇恨言论，减少误判。

    

    自动检测仇恨言论的主要挑战之一是缺乏涵盖范围广泛的有偏见和无偏见言论且标注一致的数据集。本文提出了一种标注程序，解决了已标注数据集中常见的一些弱点。本文关注Twitter上的反犹太主义言论，并通过使用相关关键词从具有代表性的样本中提取涵盖2021年1月至2021年12月关于犹太人、以色列和反犹太主义的常见话题的6,941个推文，创建了一个标注数据集。我们的标注过程旨在严格应用一种广泛使用的反犹太主义定义，强制注释者指定所适用的定义部分，并让他们有选择地就个案表达不同意见。标注呼吁反对反犹太主义、报告反犹太主义或与反犹太主义有关但实际上不属于反犹太主义的推文可以帮助减少误判。

    One of the major challenges in automatic hate speech detection is the lack of datasets that cover a wide range of biased and unbiased messages and that are consistently labeled. We propose a labeling procedure that addresses some of the common weaknesses of labeled datasets. We focus on antisemitic speech on Twitter and create a labeled dataset of 6,941 tweets that cover a wide range of topics common in conversations about Jews, Israel, and antisemitism between January 2019 and December 2021 by drawing from representative samples with relevant keywords. Our annotation process aims to strictly apply a commonly used definition of antisemitism by forcing annotators to specify which part of the definition applies, and by giving them the option to personally disagree with the definition on a case-by-case basis. Labeling tweets that call out antisemitism, report antisemitism, or are otherwise related to antisemitism (such as the Holocaust) but are not actually antisemitic can help reduce fal
    
[^19]: 一种用于学习语法的逻辑词嵌入模型

    A logical word embedding for learning grammar. (arXiv:2304.14590v1 [cs.CL])

    [http://arxiv.org/abs/2304.14590](http://arxiv.org/abs/2304.14590)

    这篇论文介绍了一种逻辑语法嵌入模型(LGE)，它可以从文本语料库中无监督进行推理，产生简明易懂的输出，能够透明地生成新句子，并且可以从仅有一百句话的语料中进行学习。

    

    我们介绍了一种逻辑语法嵌入(LGE)模型，该模型受到了组合语法和类别语法的启发，可以从文本语料库中对词汇类别和句法规则进行无监督推理。 LGE产生了简明易懂的输出，能够透明地生成新句子，并且可以从仅有一百句话的语料中进行学习。

    We introduce the logical grammar emdebbing (LGE), a model inspired by pregroup grammars and categorial grammars to enable unsupervised inference of lexical categories and syntactic rules from a corpus of text. LGE produces comprehensible output summarizing its inferences, has a completely transparent process for producing novel sentences, and can learn from as few as a hundred sentences.
    
[^20]: 利用图形增强提高知识图谱实体对齐

    Improving Knowledge Graph Entity Alignment with Graph Augmentation. (arXiv:2304.14585v1 [cs.CL])

    [http://arxiv.org/abs/2304.14585](http://arxiv.org/abs/2304.14585)

    该论文提出了 GAEA，一种基于图形增强的实体对齐方法，它利用实体-关系编码器生成实体的潜在表示，并使用图形增强创建两个图形视图，以增强实体对齐能力。

    

    实体对齐在知识融合中扮演着至关重要的角色，其目的是将不同知识图谱中的相等实体进行链接。然而，现有的基于图神经网络的方法要么受到真实知识图谱分布中的结构异质性的影响，要么忽略未知（未标记）实体的异构表示学习，这将导致模型对少量对齐种子（即训练数据）过度拟合，从而导致对齐性能不佳。为了增强实体对齐能力，我们提出了基于图形增强的全新实体对齐方法——GAEA。在这个模型中，我们设计一个简单的实体-关系编码器，通过联合建模全面的结构信息和丰富的关系语义来生成实体的潜在表示。此外，我们使用图形增强创建两个图形视图，以进行基于边缘的对齐学习。

    Entity alignment (EA) which links equivalent entities across different knowledge graphs (KGs) plays a crucial role in knowledge fusion. In recent years, graph neural networks (GNNs) have been successfully applied in many embedding-based EA methods. However, existing GNN-based methods either suffer from the structural heterogeneity issue that especially appears in the real KG distributions or ignore the heterogeneous representation learning for unseen (unlabeled) entities, which would lead the model to overfit on few alignment seeds (i.e., training data) and thus cause unsatisfactory alignment performance. To enhance the EA ability, we propose GAEA, a novel EA approach based on graph augmentation. In this model, we design a simple Entity-Relation (ER) Encoder to generate latent representations for entities via jointly modeling comprehensive structural information and rich relation semantics. Moreover, we use graph augmentation to create two graph views for margin-based alignment learnin
    
[^21]: 适当性是你所需要的一切！

    Appropriateness is all you need!. (arXiv:2304.14553v1 [cs.AI])

    [http://arxiv.org/abs/2304.14553](http://arxiv.org/abs/2304.14553)

    在chatbot的使用中，应该依据适当性原则而非纯粹的安全性原则来进行评估，以避免其受限制。

    

    保障AI应用程序的“安全性”已成为它们允许使用的主要规范要求，甚至是唯一规范要求。然而，这种“安全性规范性”方法已经显示出在解决chatGPT和其他chatbot引发的问题方面的局限性。本文提出了一种新的限制chatbot话题范围的“适当性规范性”方法，通过对话语的三种适当性（技术交际、社会、道德）进行评估来规定chatbot的语言表达要求，以避免其受约束的范围。

    The strive to make AI applications "safe" has led to the development of safety-measures as the main or even sole normative requirement of their permissible use. Similar can be attested to the latest version of chatbots, such as chatGPT. In this view, if they are "safe", they are supposed to be permissible to deploy. This approach, which we call "safety-normativity", is rather limited in solving the emerging issues that chatGPT and other chatbots have caused thus far. In answering this limitation, in this paper we argue for limiting chatbots in the range of topics they can chat about according to the normative concept of appropriateness. We argue that rather than looking for "safety" in a chatbot's utterances to determine what they may and may not say, we ought to assess those utterances according to three forms of appropriateness: technical-discursive, social, and moral. We then spell out what requirements for chatbots follow from these forms of appropriateness to avoid the limits of p
    
[^22]: 论述对话：从语用角度拓展对话人工智能的研究

    Discourse over Discourse: The Need for an Expanded Pragmatic Focus in Conversational AI. (arXiv:2304.14543v1 [cs.CL])

    [http://arxiv.org/abs/2304.14543](http://arxiv.org/abs/2304.14543)

    对话的论述是现代对话人工智能概括及其它应用的普遍限制，因此我们需要从语用角度拓展对话人工智能的研究。

    

    对话的概括，即对话过程的论述，使得实用语用成为当代对话人工智能概括和其他应用的普遍限制。本文利用语义和句法方面的重大进展，讨论了概括对话和其他对话人工智能应用中的若干挑战，并借助相关理论研究说明了语用学的重要性。我们以所谓的明星句子为例，这些句子在句法上是可接受的命题，但在对话或其摘要中在语用上是不合适的。由于AI的质量基准是无法区分人类行为，因此我们 heavily 依赖心理语言学文献，并将我们的投诉标记为“图灵测试触发器”（TTTs）。我们讨论了对话摘要方法和语用人工智能应用设计和评估的影响，比如语音识别等。

    The summarization of conversation, that is, discourse over discourse, elevates pragmatic considerations as a pervasive limitation of both summarization and other applications of contemporary conversational AI. Building on impressive progress in both semantics and syntax, pragmatics concerns meaning in the practical sense. In this paper, we discuss several challenges in both summarization of conversations and other conversational AI applications, drawing on relevant theoretical work. We illustrate the importance of pragmatics with so-called star sentences, syntactically acceptable propositions that are pragmatically inappropriate in conversation or its summary. Because the baseline for quality of AI is indistinguishability from human behavior, we draw heavily on the psycho-linguistics literature, and label our complaints as "Turing Test Triggers" (TTTs). We discuss implications for the design and evaluation of conversation summarization methods and conversational AI applications like vo
    
[^23]: 基于深度迁移学习的自动语音识别：迈向更好的泛化

    Deep Transfer Learning for Automatic Speech Recognition: Towards Better Generalization. (arXiv:2304.14535v1 [cs.SD])

    [http://arxiv.org/abs/2304.14535](http://arxiv.org/abs/2304.14535)

    本文Survey了基于DTL的ASR框架，并介绍了如何使用实际数据集进行深度迁移学习以达到更好的泛化性能。

    

    最近，深度学习在自动语音识别（ASR）方面面临着一个重要的挑战，这需要大规模的训练数据集和高计算和存储资源。此外，机器学习（ML）方法和深度学习技术通常假设训练和测试数据来自相同的域，具有相同的输入特征空间和数据分布特性。然而，在一些现实世界的人工智能（AI）应用中，这种假设是无法适用的。DTL被引入来克服这些问题，它有助于使用实际数据集开发高性能的模型，这些实际数据集即使很小或稍有不同，但与训练数据相关。本文提出了基于DTL的ASR框架的全面调查，以阐明最新的发展。

    Automatic speech recognition (ASR) has recently become an important challenge when using deep learning (DL). It requires large-scale training datasets and high computational and storage resources. Moreover, DL techniques and machine learning (ML) approaches in general, hypothesize that training and testing data come from the same domain, with the same input feature space and data distribution characteristics. This assumption, however, is not applicable in some real-world artificial intelligence (AI) applications. Moreover, there are situations where gathering real data is challenging, expensive, or rarely occurring, which can not meet the data requirements of DL models. deep transfer learning (DTL) has been introduced to overcome these issues, which helps develop high-performing models using real datasets that are small or slightly different but related to the training data. This paper presents a comprehensive survey of DTL-based ASR frameworks to shed light on the latest developments 
    
[^24]: 信息检索的多元表示学习

    Multivariate Representation Learning for Information Retrieval. (arXiv:2304.14522v1 [cs.IR])

    [http://arxiv.org/abs/2304.14522](http://arxiv.org/abs/2304.14522)

    本论文提出一种多元分布模型的信息检索表示学习框架，可无缝集成到现有近似最近邻算法中以实现高效检索。

    

    稠密检索模型使用双编码器网络架构来学习查询和文档的表示形式，这些表示形式通常采用向量表示，它们的相似性通常使用点积函数计算。本文提出一种新的稠密检索表示学习框架。我们的框架不是学习每个查询和文档的向量，而是学习多元分布，并使用负多元KL散度计算分布之间的相似性。为了简化和提高效率，我们假设这些分布是多维正态分布，然后训练大型语言模型来生成这些分布的均值和方差向量。我们为所提出的框架提供了理论基础，并展示了它可以无缝地集成到现有的近似最近邻算法中以实现高效检索。我们进行了广泛的实验，覆盖了各种不同的基准数据集和评估指标。

    Dense retrieval models use bi-encoder network architectures for learning query and document representations. These representations are often in the form of a vector representation and their similarities are often computed using the dot product function. In this paper, we propose a new representation learning framework for dense retrieval. Instead of learning a vector for each query and document, our framework learns a multivariate distribution and uses negative multivariate KL divergence to compute the similarity between distributions. For simplicity and efficiency reasons, we assume that the distributions are multivariate normals and then train large language models to produce mean and variance vectors for these distributions. We provide a theoretical foundation for the proposed framework and show that it can be seamlessly integrated into the existing approximate nearest neighbor algorithms to perform retrieval efficiently. We conduct an extensive suite of experiments on a wide range 
    
[^25]: 理解共享的语音-文本表示

    Understanding Shared Speech-Text Representations. (arXiv:2304.14514v1 [cs.CL])

    [http://arxiv.org/abs/2304.14514](http://arxiv.org/abs/2304.14514)

    本文研究了将文本整合进入端到端语音模型中训练的方法，通过研究无语音域自适应和激活的相似性，发现持续模型对共享语音-文本表示很重要，共享编码器学习了一个比单模态更紧凑重叠的语音-文本表示，这部分解释了Maestro共享的语音-文本表示有效的原因。

    

    最近出现了许多将文本整合到端到端模型中训练语音模型的方法，其中Maestro推进了自动语音识别（ASR）和语音翻译（ST）的最新进展。本文通过两类分析扩展了我们对产生的共享语音-文本表示的理解。首先，我们研究了无语音域自适应的极限，发现为了学习共享的语音-文本表示，具有语音-文本对齐的特定语料库持续模型是最重要的组成部分。其次，我们检查了单模态编码器（语音或文本）的激活与共享编码器的激活之间的相似之处。我们发现，共享编码器学习了一个比单模态编码器更紧凑和重叠的语音-文本表示。我们假设这部分解释了Maestro共享的语音-文本表示的有效性。

    Recently, a number of approaches to train speech models by incorpo-rating text into end-to-end models have been developed, with Mae-stro advancing state-of-the-art automatic speech recognition (ASR)and Speech Translation (ST) performance. In this paper, we expandour understanding of the resulting shared speech-text representationswith two types of analyses. First we examine the limits of speech-free domain adaptation, finding that a corpus-specific duration modelfor speech-text alignment is the most important component for learn-ing a shared speech-text representation. Second, we inspect the sim-ilarities between activations of unimodal (speech or text) encodersas compared to the activations of a shared encoder. We find that theshared encoder learns a more compact and overlapping speech-textrepresentation than the uni-modal encoders. We hypothesize that thispartially explains the effectiveness of the Maestro shared speech-textrepresentations.
    
[^26]: 视觉指称游戏促进解耦表示的出现。

    Visual Referential Games Further the Emergence of Disentangled Representations. (arXiv:2304.14511v1 [cs.CL])

    [http://arxiv.org/abs/2304.14511](http://arxiv.org/abs/2304.14511)

    本文研究了视觉指称游戏中组合性、解耦和系统性之间的关系，发现基于Obverter建筑的游戏优于无监督学习方法。同时，通过新的解耦损失函数和位置再标定任务改进了性能。

    

    自然语言是人类交流信息的强大工具。 其中，组合性一直是指称游戏和其变体的主要关注点，因为它可以为代理人提供更大的系统性。解耦概念已经被证明是深入学习中有良好泛化的学习表示的核心，并认为这是实现系统性的必要条件。因此，本文研究了视觉指称游戏中新语言层面的组合性，学习表示层面的解耦，以及系统性之间的关系。首先，我们发现基于Obverter建筑物的视觉指称游戏在许多重要的解耦度量方面优于最先进的无监督学习方法。其次，我们扩展了先前提出的位置感知解耦损失，利用新提出的重复信息解耦损失和位置再标定任务进一步改进了性能。

    Natural languages are powerful tools wielded by human beings to communicate information. Among their desirable properties, compositionality has been the main focus in the context of referential games and variants, as it promises to enable greater systematicity to the agents which would wield it. The concept of disentanglement has been shown to be of paramount importance to learned representations that generalise well in deep learning, and is thought to be a necessary condition to enable systematicity. Thus, this paper investigates how do compositionality at the level of the emerging languages, disentanglement at the level of the learned representations, and systematicity relate to each other in the context of visual referential games. Firstly, we find that visual referential games that are based on the Obverter architecture outperforms state-of-the-art unsupervised learning approach in terms of many major disentanglement metrics. Secondly, we expand the previously proposed Positional D
    
[^27]: 新闻框架：从人类感知到大型语言模型推断

    Framing the News:From Human Perception to Large Language Model Inferences. (arXiv:2304.14456v1 [cs.CL])

    [http://arxiv.org/abs/2304.14456](http://arxiv.org/abs/2304.14456)

    本文研究了新闻标题的框架辨别问题，并使用大型语言模型进行了实验，结果表明使用 GPT-3.5 方法可以提高分类任务的性能，达到了 68.13% 的 F1 分数。

    

    辨别新闻框架对于了解文章的视角、意图、传递的信息以及哪些方面的新闻得到了强调是非常重要的。框架是新闻学中广泛研究的概念，并已成为计算领域中的新话题，具有自动化流程和方便新闻从业者工作的潜力。本文针对与 Covid-19 反疫苗运动相关的文章进行了研究。首先，为了理解处理这一主题所使用的视角，我们开发了一个人类标注框架的协议，对来自 5 个国家的欧洲报纸的 1786 个 No-Vax 运动文章的标题进行标注，因为标题是书面新闻中的关键单元，有分析价值，因为很多人只读标题（或用它们来指导他们进一步阅读的决策）。其次，考虑到大型语言模型在自然语言处理中的进展，我们研究了两种新闻标题框架推断方法：一种是使用 GPT-3.5 框架，另一种是基于 BERT 的分析。我们的实验表明，GPT-3.5 提高了分类任务的性能，F1 分数达到了 68.13%。基于 BERT 的方法提供了更低但仍有合理结果，F1 分数为 57.43%。这些结果有助于不断扩大的工作，展示了在 NLP 任务中使用大型语言模型的潜力。

    Identifying the frames of news is important to understand the articles' vision, intention, message to be conveyed, and which aspects of the news are emphasized. Framing is a widely studied concept in journalism, and has emerged as a new topic in computing, with the potential to automate processes and facilitate the work of journalism professionals. In this paper, we study this issue with articles related to the Covid-19 anti-vaccine movement. First, to understand the perspectives used to treat this theme, we developed a protocol for human labeling of frames for 1786 headlines of No-Vax movement articles of European newspapers from 5 countries. Headlines are key units in the written press, and worth of analysis as many people only read headlines (or use them to guide their decision for further reading.) Second, considering advances in Natural Language Processing (NLP) with large language models, we investigated two approaches for frame inference of news headlines: first with a GPT-3.5 f
    
[^28]: PMC-LLaMA: 在医学论文中进行LLaMA的进一步微调

    PMC-LLaMA: Further Finetuning LLaMA on Medical Papers. (arXiv:2304.14454v1 [cs.CL])

    [http://arxiv.org/abs/2304.14454](http://arxiv.org/abs/2304.14454)

    本文介绍了一个针对医学领域进一步微调的开源语言模型PMC-LLaMA，其通过增加医学知识提高了在生物医学领域的性能表现，有望在生物医学问答领域有更好的应用表现。

    

    大型语言模型(LLM)在各个领域的自然语言理解方面具有出色的能力。这些模型通常在日常对话或问答场景中表现良好，然而，在注重精度的领域，例如医疗应用中，它们往往表现出不尽人意的性能，原因是缺乏特定领域的知识。在本文中，我们介绍了PMC-LLaMA，这是一种开源的语言模型，通过在总共480万篇生物医学论文上微调开源语言模型，以进一步注入医学知识，增强其在医学领域的能力。我们进行了初步评估，包括PubMedQA、MedMCQA和USMLE等三个生物医学问答数据集，结果显示，我们的模型经过微调后，即PMC-LLaMA，对生物医学领域的特定概念有更好的理解，因此在问答基准测试中取得了较高的性能。该模型和代码以及在线演示均可在https://github.com/cstorm125/pmc-llama上找到。

    Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding in various domains. These models can usually behave well on daily dialog, or question answering scenarios, however, in areas that value precision, for example, in medical applications, they often exhibit unsatisfactory performance due to a lack of domain-specific knowledge. In this report, we introduce PMC-LLaMA, an open-source language model that is acquired by fine-tuning an open-source language model on a total of 4.8 million biomedical academic papers for further injecting medical knowledge, enhancing its capability in medical domain. Our preliminary evaluations are conducted on three biomedical QA datasets, including PubMedQA, MedMCQA, and USMLE, showing that the our model after finetuning, i.e., PMC-LLaMA, demonstrates better understanding of biomedical domain-specific concepts, thus achieving high performance on QA benchmarks. The model and codes, along with an online demo, are 
    
[^29]: 使用深度神经网络与双仿射分类器分析越南法律问题

    Analyzing Vietnamese Legal Questions Using Deep Neural Networks with Biaffine Classifiers. (arXiv:2304.14447v1 [cs.CL])

    [http://arxiv.org/abs/2304.14447](http://arxiv.org/abs/2304.14447)

    本文提出了一种使用深度神经网络和双仿射分类器分析越南法律问题的方法，实现找到回答问题所需信息的所有片段。实验结果表明该模型效果优于强基线。

    

    本文提出使用深度神经网络从越南法律问题中提取重要信息的方法，这是构建法律领域问答系统的基本任务。给定一个自然语言的法律问题，目标是提取包含回答问题所需信息的所有片段。我们引入了一个三阶段的深度模型来解决这个任务。首先，我们利用最近的自编码语言模型生成上下文词嵌入，然后结合字符级和POS-tag信息形成单词表示。接下来，我们采用双向长短时记忆网络来捕捉单词之间的关系并生成句子表示。在第三阶段，我们借鉴了基于图的依存分析方法的思想，该方法提供了对输入句子的全局视图，使用双仿射分类器估计每个起始-结束单词对成为重要片段的概率。在一个新构建的越南法律问题数据集上的实验结果表明，我们提出的模型大幅优于强基线。

    In this paper, we propose using deep neural networks to extract important information from Vietnamese legal questions, a fundamental task towards building a question answering system in the legal domain. Given a legal question in natural language, the goal is to extract all the segments that contain the needed information to answer the question. We introduce a deep model that solves the task in three stages. First, our model leverages recent advanced autoencoding language models to produce contextual word embeddings, which are then combined with character-level and POS-tag information to form word representations. Next, bidirectional long short-term memory networks are employed to capture the relations among words and generate sentence-level representations. At the third stage, borrowing ideas from graph-based dependency parsing methods which provide a global view on the input sentence, we use biaffine classifiers to estimate the probability of each pair of start-end words to be an imp
    
[^30]: 生成型人工智能知觉：关于学术界使用生成型人工智能工具的教职工和学生看法的调查

    Generative AI Perceptions: A Survey to Measure the Perceptions of Faculty, Staff, and Students on Generative AI Tools in Academia. (arXiv:2304.14415v1 [cs.HC])

    [http://arxiv.org/abs/2304.14415](http://arxiv.org/abs/2304.14415)

    本文调查了学术界使用生成型人工智能工具ChatGPT的影响，旨在了解其如何革新工程教育并改变技术、教职工与学生之间的关系。调查可供其他大学和机构使用。

    

    ChatGPT是一种自然语言处理工具，可以进行类似人类对话的交互，并能够根据不同的提示生成连贯且相关的回复。该工具能够理解用户输入的自然文本，并以多种形式生成适当的响应。本文重点探讨了ChatGPT如何革新工程教育，以及技术、学生、教职工之间的关系。因为该工具快速变化和不断改进，因此现在是收集相关数据的关键时期。为此，设计了一项调查，以衡量ChatGPT对教职工和学生的影响，并将该调查作为德克萨斯A&M大学技术报告分享，以便其他大学和机构使用该调查，并在其他地方进行影响评估。

    ChatGPT is a natural language processing tool that can engage in human-like conversations and generate coherent and contextually relevant responses to various prompts. ChatGPT is capable of understanding natural text that is input by a user and generating appropriate responses in various forms. This tool represents a major step in how humans are interacting with technology. This paper specifically focuses on how ChatGPT is revolutionizing the realm of engineering education and the relationship between technology, students, and faculty and staff. Because this tool is quickly changing and improving with the potential for even greater future capability, it is a critical time to collect pertinent data. A survey was created to measure the effects of ChatGPT on students, faculty, and staff. This survey is shared as a Texas A&M University technical report to allow other universities and entities to use this survey and measure the effects elsewhere.
    
[^31]: 可控的数据增强方法用于上下文相关的文本到SQL转换

    Controllable Data Augmentation for Context-Dependent Text-to-SQL. (arXiv:2304.13902v1 [cs.CL])

    [http://arxiv.org/abs/2304.13902](http://arxiv.org/abs/2304.13902)

    提出了ConDA方法，可以生成交互式问题和相应的SQL结果，并设计了SQL对话状态和过滤方法来增强数据多样性和质量，能够提高复杂问题的性能。

    

    由于标注数据数量有限，标注复杂度高，限制了现有的上下文相关的文本到SQL转换模型的规模。数据增强是解决这个问题的常用方法。然而，当前增强方法产生的数据往往缺乏多样性。在本文中，我们介绍了ConDA，可以生成交互式的问题和相应的SQL结果，设计了SQL对话状态以通过状态转移增强数据多样性，同时，我们还提供了一种基于grounding模型的过滤器方法来确保数据质量。此外，我们利用grounding模型来识别和过滤与状态信息不匹配的低质量问题。在SParC和CoSQL数据集上的实验结果表明，ConDA将基线模型提高了平均 $3.3\%$ 的复杂问题的性能。此外，我们分析了增强数据，发现ConDA生成的数据在SQL模板匹配和语义正确性方面具有高质量。

    The limited scale of annotated data constraints existing context-dependent text-to-SQL models because of the complexity of labeling. The data augmentation method is a commonly used method to solve this problem. However, the data generated by current augmentation methods often lack diversity. In this paper, we introduce ConDA, which generates interactive questions and corresponding SQL results. We designed the SQL dialogue state to enhance the data diversity through the state transition. Meanwhile, we also present a filter method to ensure the data quality by a grounding model. Additionally, we utilize a grounding model to identify and filter low-quality questions that mismatch the state information. Experimental results on the SParC and CoSQL datasets show that ConDA boosts the baseline model to achieve an average improvement of $3.3\%$ on complex questions. Moreover, we analyze the augmented data, which reveals that the data generated by ConDA are of high quality in both SQL template 
    
[^32]: 评估GPT-3.5和GPT-4在支持医疗保健信息需求方面的实际作用

    Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery. (arXiv:2304.13714v1 [cs.AI])

    [http://arxiv.org/abs/2304.13714](http://arxiv.org/abs/2304.13714)

    本研究评估了在临床环境中使用GPT-3.5和GPT-4解决医学问题的安全性以及与信息技术咨询服务报告的一致性。研究结果表明，两个LLMs都可以以安全和一致的方式满足医生的信息需求。

    

    尽管在医疗保健领域使用大型语言模型(LLMs)越来越受关注，但当前的探索并未评估LLMs在临床环境中的实用性和安全性。我们的目标是确定两个LLM是否可以以安全和一致的方式满足由医生提交的信息需求问题。我们将66个来自信息技术咨询服务的问题通过简单的提示提交给GPT-3.5和GPT-4。12名医生评估了LLM响应对患者造成伤害的可能性以及与信息技术咨询服务的现有报告的一致性。医生的评估基于多数票汇总。对于没有任何问题，大多数医生认为任何一个LLM响应都不会造成伤害。对于GPT-3.5，8个问题的响应与信息技术咨询报告一致，20个不一致，9个无法评估。有29个响应没有多数票表示“同意”、“不同意”和“无法评估”。

    Despite growing interest in using large language models (LLMs) in healthcare, current explorations do not assess the real-world utility and safety of LLMs in clinical settings. Our objective was to determine whether two LLMs can serve information needs submitted by physicians as questions to an informatics consultation service in a safe and concordant manner. Sixty six questions from an informatics consult service were submitted to GPT-3.5 and GPT-4 via simple prompts. 12 physicians assessed the LLM responses' possibility of patient harm and concordance with existing reports from an informatics consultation service. Physician assessments were summarized based on majority vote. For no questions did a majority of physicians deem either LLM response as harmful. For GPT-3.5, responses to 8 questions were concordant with the informatics consult report, 20 discordant, and 9 were unable to be assessed. There were 29 responses with no majority on "Agree", "Disagree", and "Unable to assess". Fo
    
[^33]: 实现无缝查询文本和表格的多模态数据库管理系统

    Towards Multi-Modal DBMSs for Seamless Querying of Texts and Tables. (arXiv:2304.13559v1 [cs.DB])

    [http://arxiv.org/abs/2304.13559](http://arxiv.org/abs/2304.13559)

    提出了一种新型数据库系统MMDB，它可以无缝查询文本和表格数据，通过使用所谓的多模态运算符（MMOps）实现文本集合的转换，该方法不仅优于现有的最先进方法，在对未见过的数据进行模型微调时，也具有显著的优势。

    

    本文提出了一种新型数据库系统，即多模态数据库（MMDBs），它可以使用SQL语言无缝地查询文本和表格数据。为了实现在MMDB中使用SQL语言进行文本数据的无缝查询，我们提出了所谓的多模态运算符（MMOps），它们基于最近大型语言模型（例如GPT-3）的进展。MMOps的主要思想是，它们允许将文本集合作为表格进行处理，而无需手动转换数据。正如我们在评估中展示的那样，我们的MMDB原型不仅在准确性和性能方面优于最先进的方法（如文本转表），而且在对一个未见过的文本集合进行模型微调时，需要的训练数据数量也显著减少。

    In this paper, we propose Multi-Modal Databases (MMDBs), which is a new class of database systems that can seamlessly query text and tables using SQL. To enable seamless querying of textual data using SQL in an MMDB, we propose to extend relational databases with so-called multi-modal operators (MMOps) which are based on the advances of recent large language models such as GPT-3. The main idea of MMOps is that they allow text collections to be treated as tables without the need to manually transform the data. As we show in our evaluation, our MMDB prototype can not only outperform state-of-the-art approaches such as text-to-table in terms of accuracy and performance but it also requires significantly less training data to fine-tune the model for an unseen text collection.
    
[^34]: IXA/Cogcomp在SemEval-2023任务2中的表现：基于知识库的上下文增强多语言命名实体识别。

    IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named Entity Recognition using Knowledge Bases. (arXiv:2304.10637v1 [cs.CL])

    [http://arxiv.org/abs/2304.10637](http://arxiv.org/abs/2304.10637)

    本文提出了一种基于知识库的上下文增强的多语言命名实体识别方法，通过识别、链接和预测实体类别，能够准确地分类细粒度和新兴实体。

    

    命名实体识别(NER)是一项核心的自然语言处理任务，在这方面，预训练的语言模型表现出了卓越的性能。然而，像CoNLL 2003等标准基准并没有解决部署NER系统需要面对的许多挑战，例如需要以细粒度的方式对新兴或复杂实体进行分类。本文提出了一种新颖的NER级联方法，包括三个步骤：首先，识别输入句子中的实体候选项；其次，将每个候选项链接到现有的知识库；第三，预测每个实体候选项的细粒度类别。我们通过实验证明了外部知识库在准确分类细粒度和新兴实体方面的重要性。我们的系统在MultiCoNER2共享任务中表现出了鲁棒性能，即使在低资源语言环境中，我们也能利用高资源语言的知识库。

    Named Entity Recognition (NER) is a core natural language processing task in which pre-trained language models have shown remarkable performance. However, standard benchmarks like CoNLL 2003 \cite{conll03} do not address many of the challenges that deployed NER systems face, such as having to classify emerging or complex entities in a fine-grained way. In this paper we present a novel NER cascade approach comprising three steps: first, identifying candidate entities in the input sentence; second, linking the each candidate to an existing knowledge base; third, predicting the fine-grained category for each entity candidate. We empirically demonstrate the significance of external knowledge bases in accurately classifying fine-grained and emerging entities. Our system exhibits robust performance in the MultiCoNER2 \cite{multiconer2-data} shared task, even in the low-resource language setting where we leverage knowledge bases of high-resource languages.
    
[^35]: LLM作为机器人的大脑：统一自我中心记忆与控制

    LLM as A Robotic Brain: Unifying Egocentric Memory and Control. (arXiv:2304.09349v1 [cs.AI])

    [http://arxiv.org/abs/2304.09349](http://arxiv.org/abs/2304.09349)

    本文提出了一个统一自我中心记忆和控制的框架LLM-Brain，使用大规模语言模型作为机器人大脑进行零-shot学习。该框架包括封闭式多轮对话，覆盖了感知、规划、控制和记忆，具有很好的泛化性能，适用于多个机器人任务。

    

    体感人工智能研究和开发具备物理或虚拟实体（即机器人）并能够与环境动态交互的智能系统。记忆和控制是体感系统的两个基本部分，通常需要分别使用框架进行建模。本文提出了一个新的、可推广的框架，称为LLM-Brain：使用大规模语言模型作为机器人大脑，统一自我中心记忆和控制。LLM-Brain框架集成了多个多模态语言模型用于机器人任务，利用零-shot学习方法。LLM-Brain中的所有组件使用自然语言进行封闭式多轮对话，包括感知、规划、控制和记忆。系统的核心是一个具备自我中心记忆和控制机器人的实体LLM。我们通过研究两个下游任务：主动探索和实体问答来演示LLM-Brain。

    Embodied AI focuses on the study and development of intelligent systems that possess a physical or virtual embodiment (i.e. robots) and are able to dynamically interact with their environment. Memory and control are the two essential parts of an embodied system and usually require separate frameworks to model each of them. In this paper, we propose a novel and generalizable framework called LLM-Brain: using Large-scale Language Model as a robotic brain to unify egocentric memory and control. The LLM-Brain framework integrates multiple multimodal language models for robotic tasks, utilizing a zero-shot learning approach. All components within LLM-Brain communicate using natural language in closed-loop multi-round dialogues that encompass perception, planning, control, and memory. The core of the system is an embodied LLM to maintain egocentric memory and control the robot. We demonstrate LLM-Brain by examining two downstream tasks: active exploration and embodied question answering. The
    
[^36]: chatIPCC: 基于气候科学的对话型人工智能系统

    chatIPCC: Grounding Conversational AI in Climate Science. (arXiv:2304.05510v1 [cs.CL])

    [http://arxiv.org/abs/2304.05510](http://arxiv.org/abs/2304.05510)

    chatIPCC是一个基于气候科学的对话型人工智能系统，通过整合IPCC AR6中的信息来增强GPT-4模型，并提供可靠、科学准确的答案。

    

    大型语言模型在近年来在问答任务方面取得了显着进展。然而，它们仍面临两个主要挑战：幻觉和训练后信息过时。在关键领域，如气候变化，快速从可靠来源获取准确和最新信息是至关重要且困难的。为了克服这些障碍，一个潜在的解决方案是为大型语言模型提供外部科学准确且可靠的来源（长期记忆），以持续更新其知识并防止不准确、不正确或过时信息的传播。在本研究中，我们通过整合联合政府间气候变化专门委员会第六次评估报告（IPCC AR6）中的信息来增强GPT-4。我们展示了我们的对话型人工智能原型，可以在www.chatclima.com上提问与气候科学相关的问题并获得基于IPCC AR6报告的科学准确答案。

    Large Language Models (LLMs) have made significant progress in recent years, achieving remarkable results in question-answering tasks (QA). However, they still face two major challenges: hallucination and outdated information after the training phase. These challenges take center stage in critical domains like climate change, where obtaining accurate and up-to-date information from reliable sources in a limited time is essential and difficult. To overcome these barriers, one potential solution is to provide LLMs with access to external, scientifically accurate, and robust sources (long-term memory) to continuously update their knowledge and prevent the propagation of inaccurate, incorrect, or outdated information. In this study, we enhanced GPT-4 by integrating the information from the Sixth Assessment Report of the Intergovernmental (IPCC AR6), the most comprehensive, up-to-date, and reliable source in this domain. We present our conversational AI prototype, available at www.chatclima
    
[^37]: ChatGPT在多模态股票预测挑战中的零样本分析：华尔街新手？

    The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges. (arXiv:2304.05351v1 [cs.CL])

    [http://arxiv.org/abs/2304.05351](http://arxiv.org/abs/2304.05351)

    本研究对ChatGPT在股票预测方面进行了零样本分析，结果表明其预测股票移动的表现不如最先进和传统方法，需要进一步改进。

    

    最近，如ChatGPT这样的大型语言模型在各种自然语言处理任务中展示了惊人的性能。然而，在预测股市走势方面，它们的有效性仍然有待探索。本文通过三个推文和历史股票价格数据集的广泛零样本分析，探讨了ChatGPT在多模态股票移动预测方面的能力。我们的研究表明，ChatGPT是一个“华尔街新手”，在预测股票移动方面的成功有限，不仅不如最先进的方法，而且不如使用价格特征的线性回归这样的传统方法。尽管思维链提示策略和推文的包含具有潜在的优势，ChatGPT的表现仍然不佳。此外，我们观察到它的可解释性和稳定性存在局限性，需要更专业的训练或微调。这项研究提供了有关ChatGPT在股票预测方面的见解。

    Recently, large language models (LLMs) like ChatGPT have demonstrated remarkable performance across a variety of natural language processing tasks. However, their effectiveness in the financial domain, specifically in predicting stock market movements, remains to be explored. In this paper, we conduct an extensive zero-shot analysis of ChatGPT's capabilities in multimodal stock movement prediction, on three tweets and historical stock price datasets. Our findings indicate that ChatGPT is a "Wall Street Neophyte" with limited success in predicting stock movements, as it underperforms not only state-of-the-art methods but also traditional methods like linear regression using price features. Despite the potential of Chain-of-Thought prompting strategies and the inclusion of tweets, ChatGPT's performance remains subpar. Furthermore, we observe limitations in its explainability and stability, suggesting the need for more specialized training or fine-tuning. This research provides insights i
    
[^38]: 卷积增强的不断进化的注意力网络

    Convolution-enhanced Evolving Attention Networks. (arXiv:2212.08330v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.08330](http://arxiv.org/abs/2212.08330)

    本文提出了一种新颖且通用的卷积增强进化注意力机制，通过一系列残差卷积模块直接模拟标记间关系的演变，在不同层次之间促进信息流动。

    

    基于注意力机制的神经网络，比如Transformers，在许多应用中变得无处不在，包括计算机视觉、自然语言处理和时间序列分析。在所有种类的注意力网络中，注意力图是至关重要的，因为它们编码了输入标记之间的语义依赖关系。然而，大多数现有的注意力网络是基于表示进行建模或推理的，不同层次的注意力图在学习时是分别学习而不是进行显式交互。本文提出了一种新颖且通用的进化注意力机制，该机制通过一系列残差卷积模块直接模拟标记间关系的演变。其主要动机有两方面。一方面，不同层次的注意力图分享可转移知识，因此添加残差连接可以促进标记之间关系在不同层次之间的信息流动。另一方面，自然存在着演化趋势。

    Attention-based neural networks, such as Transformers, have become ubiquitous in numerous applications, including computer vision, natural language processing, and time-series analysis. In all kinds of attention networks, the attention maps are crucial as they encode semantic dependencies between input tokens. However, most existing attention networks perform modeling or reasoning based on representations , wherein the attention maps of different layers are learned separately without explicit interactions. In this paper, we propose a novel and generic evolving attention mechanism, which directly models the evolution of inter-token relationships through a chain of residual convolutional modules. The major motivations are twofold. On the one hand, the attention maps in different layers share transferable knowledge, thus adding a residual connection can facilitate the information flow of inter-token relationships across layers. On the other hand, there is naturally an evolutionary trend a
    
[^39]: 自监督模型与多任务学习相结合的发音障碍自动严重程度评估方法

    Automatic Severity Assessment of Dysarthric speech by using Self-supervised Model with Multi-task Learning. (arXiv:2210.15387v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.15387](http://arxiv.org/abs/2210.15387)

    该论文提出了一种使用自监督模型和多任务学习相结合的自动评估发音障碍严重程度的方法，在较少数据的情况下实现了向传统方法的优化，并且相对提高了1.25%的F1-score。

    

    自动评估发音障碍的严重程度对于持续治疗和康复至关重要。然而，获取非典型发音的难度较大，往往会导致数据稀缺问题。为了应对这个问题，我们提出了一种新的自动评估发音障碍严重程度的方法，使用自监督模型与多任务学习相结合。我们联合训练Wav2vec 2.0 XLS-R进行两个不同的任务：严重程度分类和辅助自动语音识别（ASR）。对于基准实验，我们采用手工制作的声学特征和机器学习分类器，如SVM、MLP和XGBoost。在韩国发音障碍QoLT数据库上进行探究，我们的模型优于传统的基准方法，F1-score相对提高1.25%。此外，所提出的模型超过了没有ASR头训练的模型，实现了10.61%的相对百分比提高。此外，我们还展示了多任务学习如何影响障碍严重程度的评估结果。

    Automatic assessment of dysarthric speech is essential for sustained treatments and rehabilitation. However, obtaining atypical speech is challenging, often leading to data scarcity issues. To tackle the problem, we propose a novel automatic severity assessment method for dysarthric speech, using the self-supervised model in conjunction with multi-task learning. Wav2vec 2.0 XLS-R is jointly trained for two different tasks: severity classification and auxiliary automatic speech recognition (ASR). For the baseline experiments, we employ hand-crafted acoustic features and machine learning classifiers such as SVM, MLP, and XGBoost. Explored on the Korean dysarthric speech QoLT database, our model outperforms the traditional baseline methods, with a relative percentage increase of 1.25% for F1-score. In addition, the proposed model surpasses the model trained without ASR head, achieving 10.61% relative percentage improvements. Furthermore, we present how multi-task learning affects the seve
    
[^40]: 使用演示和自然语言指令高效学习机器人任务

    Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks. (arXiv:2210.04476v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.04476](http://arxiv.org/abs/2210.04476)

    本论文提出了一种使用演示和自然语言指令相结合的机器人任务学习方法，其基于两种模式相互消除歧义来有效地指定和教授机器人复杂任务。此方法可以减少教师工作量并实现更好的泛化性能。

    

    演示和自然语言指令是指定和教授机器人新任务的两种常见方式。然而，对于许多复杂任务，单独使用演示或语言指令会存在歧义，导致任务无法清晰地被指定。在这种情况下，演示和指令的组合可以更简明地有效地向机器人传达任务。为了演示这个问题设置，我们在几百个挑战性的机器人拾取放置任务上训练了一个多任务策略，并提出了一种名为 DeL-TaCo（联合演示 - 语言任务调节）的方法，用于将机器人策略调节为由两个组成部分组成的任务嵌入：视觉演示和语言指令。通过允许这两种模式在新任务规范时相互消除歧义和澄清彼此，DeL-TaCo（1）大大降低了指定新任务所需的教师工作量，并且（2）实现了更好的泛化性能。

    Demonstrations and natural language instructions are two common ways to specify and teach robots novel tasks. However, for many complex tasks, a demonstration or language instruction alone contains ambiguities, preventing tasks from being specified clearly. In such cases, a combination of both a demonstration and an instruction more concisely and effectively conveys the task to the robot than either modality alone. To instantiate this problem setting, we train a single multi-task policy on a few hundred challenging robotic pick-and-place tasks and propose DeL-TaCo (Joint Demo-Language Task Conditioning), a method for conditioning a robotic policy on task embeddings comprised of two components: a visual demonstration and a language instruction. By allowing these two modalities to mutually disambiguate and clarify each other during novel task specification, DeL-TaCo (1) substantially decreases the teacher effort needed to specify a new task and (2) achieves better generalization performa
    

