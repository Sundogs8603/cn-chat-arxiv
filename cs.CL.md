# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Theoretical guarantees on the best-of-n alignment policy.](http://arxiv.org/abs/2401.01879) | 该论文研究了对齐生成模型的最佳n对齐策略，并证明了之前文献中的某个分析表达式是错误的。研究者们提出了一个新的KL散度估计方法，并通过实验证明其有效性。 |
| [^2] | [A Vision Check-up for Language Models.](http://arxiv.org/abs/2401.01862) | 本研究系统地评估了大型语言模型（LLMs）在生成和识别各种视觉概念方面的能力，并通过使用文本模型进行训练的视觉表示学习系统展示了LLMs对视觉世界的认知。实验结果表明，精确建模字符串可以教会LLMs关于视觉世界的多个方面，并且仅使用LLMs可以训练能够对自然图像进行语义评估的视觉模型。 |
| [^3] | [Multilingual Instruction Tuning With Just a Pinch of Multilinguality.](http://arxiv.org/abs/2401.01854) | 本研究研究了多语言指令调优中的多语言性对跨语言指令遵循的影响。研究发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，只有40个多语言示例能够显著提高多语言指令遵循。总体来说，多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。 |
| [^4] | [Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling.](http://arxiv.org/abs/2401.01830) | 本文提出了一种新颖的文本增强方法，利用基于Transformer的BERT模型的填充-掩码功能，通过迭代掩码和语言模型预测进行替换，显著提高了自然语言处理任务的性能。 |
| [^5] | [Physio: An LLM-Based Physiotherapy Advisor.](http://arxiv.org/abs/2401.01825) | Physio是一种基于LLM的物理治疗顾问应用程序，它结合了生成模型的语言处理能力，并在回答中引用可靠的健康来源，能够进行诊断、推荐康复运动和非处方药物以缓解症状。 |
| [^6] | [Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering.](http://arxiv.org/abs/2401.01780) | 本文提出了一种新的大型语言模型，通过让模型自我评估是否需要查询外部资源，来优化封闭式问答中的幻觉问题。研究者通过引入幻觉屏蔽机制以及参数高效微调的方法，实现了该模型。 |
| [^7] | [Cross-target Stance Detection by Exploiting Target Analytical Perspectives.](http://arxiv.org/abs/2401.01761) | 本论文提出了一种利用目标分析视角进行跨目标立场检测的方法，并使用多视角提示调整框架将自然语言解释融合到立场预测器中。 |
| [^8] | [VGA: Vision and Graph Fused Attention Network for Rumor Detection.](http://arxiv.org/abs/2401.01759) | 这篇论文提出了一种名为VGA的视觉和图形融合注意力网络，用于多模态谣言检测。该方法不仅考虑了源索赔和图像的特征，还利用谣言的评论和传播结构来揭示谣言，并且能够有效处理图像篡改和文本信息隐藏等问题。 |
| [^9] | [Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs.](http://arxiv.org/abs/2401.01711) | 本论文评估了尚未在知识图谱对话问答任务上进行预训练的大型语言模型的性能，并通过实验证明了这些模型在生成图查询方面的能力以及通过少量提示和微调技术可以显著改善其性能。 |
| [^10] | [WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope.](http://arxiv.org/abs/2401.01699) | 本文介绍了WordArt设计师API，它利用大型语言模型在模型范围上进行用户驱动的艺术字体合成。通过提供动态、自适应和高效的替代方案，该方法能够满足非专业人士简化艺术字体的需求，并实现了更直观的设计过程。与现有系统相比，该API显著提高了用户满意度、设计灵活性和创造性表达，并为个性化数字通信和设计开辟了新的可能性。 |
| [^11] | [Patterns of Persistence and Diffusibility across World's Languages.](http://arxiv.org/abs/2401.01698) | 本研究通过构建大规模图表，探讨了合词和音韵跨语言相似性的语言原因，并支持了一项先前已有的假设。 |
| [^12] | [Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches.](http://arxiv.org/abs/2401.01692) | 本研究比较了三种自然语言处理方法（专家规则模型、监督式机器学习模型和大型语言模型）在从学生对话中检测和确定挑战的能力。结果表明，监督式机器学习模型和大型语言模型在这两个任务中表现较好，而专家规则模型效果较差。研究对这些方法的性能进行了广泛讨论。 |
| [^13] | [MLPs Compass: What is learned when MLPs are combined with PLMs?.](http://arxiv.org/abs/2401.01667) | 本文研究探究了Multilayer-Perceptrons (MLPs)模块是否能增强预训练语言模型（PLMs）对语言信息的捕捉能力。实验结果表明，MLPs确实能够提高PLMs对语言结构的理解能力。 |
| [^14] | [Social Media Ready Caption Generation for Brands.](http://arxiv.org/abs/2401.01637) | 这项研究提出了一个流程解决方案来帮助品牌生成与品牌个性相一致的社交媒体广告标题，以吸引消费者的注意力。 |
| [^15] | [Can AI Be as Creative as Humans?.](http://arxiv.org/abs/2401.01623) | 本文引入了一个新概念【相对创造力】，通过将焦点转向AI是否能够与人类具备相同的创造能力，实现对创造力的统计量化评估和直接比较。 |
| [^16] | [Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication.](http://arxiv.org/abs/2401.01620) | 在这项研究中，我们探讨了使用通用领域大型语言模型在术中风险预测和预后方面的能力。通过使用手术描述和患者临床记录，我们在8个不同的任务上考察了预测性能，并发现少量样本和链式启发式策略可以提高预测性能。此外，我们的研究表明当前一代大型语言模型可以帮助临床医生在术中风险分层和生成高质量的自然语言总结方面发挥作用。 |
| [^17] | [GPT-4V(ision) is a Generalist Web Agent, if Grounded.](http://arxiv.org/abs/2401.01614) | GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。 |
| [^18] | [PLLaMa: An Open-source Large Language Model for Plant Science.](http://arxiv.org/abs/2401.01600) | PLLaMa是一种用于植物科学的开源大型语言模型，通过综合数据库增强，显著丰富了其在植物和农业科学方面的知识和专长，并通过与专业人员小组的合作验证了其准确性。 |
| [^19] | [MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries.](http://arxiv.org/abs/2401.01596) | 本研究提出了一种多模态方法，用于总结混合码Hindi-English临床查询，通过整合文本和视觉线索，提供更全面的患者医疗状况的表示。为了解决这个问题，研究还提出了一个名为MedSumm的框架，利用LLMs和VLMs来完成任务。 |
| [^20] | [Hallucinations in Neural Automatic Speech Recognition: Identifying Errors and Hallucinatory Models.](http://arxiv.org/abs/2401.01572) | 该论文研究了神经自动语音识别中的幻听问题，并提出了一种用于在测试时评估幻听敏感性的基于扰动的方法，该方法能够帮助区分幻觉和非幻觉模型。 |
| [^21] | [GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse.](http://arxiv.org/abs/2401.01523) | 通过基于迷因的社交虐待研究对大型多模态模型的安全洞察，我们引入了综合的迷因基准测试集GOAT-Bench，评估各种LMMs在识别和回应迷因中体现的微妙社交虐待方面的能力。 |
| [^22] | [Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction.](http://arxiv.org/abs/2401.01498) | 利用神经转导器实现了一个两阶段的文本到语音转换框架，通过语义标记预测实现了稳健高效的对齐建模，并通过非自回归语音生成器合成语音波形。该框架在语音质量和说话者相似度方面超过了基线模型。 |
| [^23] | [A Two-Stage Multimodal Emotion Recognition Model Based on Graph Contrastive Learning.](http://arxiv.org/abs/2401.01495) | 该论文提出了一种基于图形对比学习的两阶段多模态情绪识别模型。首先，将原始数据集用不同预处理模态进行编码；然后，引入了图形对比学习策略，通过其他结构对不同模态数据进行学习，以了解模态内部的相似性和差异性；最后，使用MLP进行最终的情绪分类。 |
| [^24] | [Natural Language Processing and Multimodal Stock Price Prediction.](http://arxiv.org/abs/2401.01487) | 本文使用自然语言处理和多模式股票价格预测，利用股票百分比变化作为训练数据，分析公开发布的新闻文章。结果展示了使用小型自然语言处理模型准确预测总体股票趋势的能力，以及特定数据特征和选择的有效性。 |
| [^25] | [A First Look at Information Highlighting in Stack Overflow Answers.](http://arxiv.org/abs/2401.01472) | 本论文进行了首次大规模的探索性研究，研究了Stack Overflow回答中的信息高亮。通过使用神经网络架构，开发了自动推荐突出内容的方法。 |
| [^26] | [Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation.](http://arxiv.org/abs/2401.01469) | 提出了一种基于检索增强生成的问答式电子健康记录摘要方法，通过结合语义搜索、RAG和最新的LLMs，摘要是提取被专业人士认为重要的特定问题的答案。 |
| [^27] | [To Diverge or Not to Diverge: A Morphosyntactic Perspective on Machine Translation vs Human Translation.](http://arxiv.org/abs/2401.01419) | 通过对机器翻译和人工翻译进行细致比较分析，我们发现机器翻译相对保守，具有较少的构词-句法多样性和更多的收敛模式，并且机器翻译性能下降与构词-句法分歧的存在有关。 |
| [^28] | [Quantifying the Uniqueness of Donald Trump in Presidential Discourse.](http://arxiv.org/abs/2401.01405) | 这项研究使用了一种新的度量标准来量化唐纳德·特朗普在总统演讲中的独特性，并发现了他在使用具有分裂性和对抗性的语言、重复强调等方面与其他总统候选人存在显著差异。此外，特朗普比共和党同僚更具独特性。 |
| [^29] | [A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models.](http://arxiv.org/abs/2401.01313) | 大型语言模型在生成文本时容易出现幻觉，这是安全部署这些模型的最大障碍。解决幻觉问题对于在实际环境中广泛使用这些模型至关重要。 |
| [^30] | [Quality and Quantity of Machine Translation References for Automated Metrics.](http://arxiv.org/abs/2401.01283) | 本研究发现，机器翻译评估的较高质量参考文献对于评估指标与人类评价之间的相关性更好。每个段落平均使用7个参考文献有助于提升所有评估指标。不同质量的供应商参考文献可以混合使用来提高评估指标的准确性。这些发现可用于在特定预算下创建参考文献的共享任务的评估者。 |
| [^31] | [Fairness Certification for Natural Language Processing and Large Language Models.](http://arxiv.org/abs/2401.01262) | 这项研究旨在为自然语言处理领域开发公平性认证方法。通过综述大量文献和专家访谈，我们提出了六个公平性标准，为操作化和测试过程提供了基础。 |
| [^32] | [Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation.](http://arxiv.org/abs/2401.01078) | 本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。 |
| [^33] | [DialCLIP: Empowering CLIP as Multi-Modal Dialog Retriever.](http://arxiv.org/abs/2401.01076) | DialCLIP是一种参数高效的多模态对话检索方法，通过在预训练的视觉语言模型CLIP中引入多模态上下文提示生成器和领域提示来提升对话检索的能力。 |
| [^34] | [Retrieval-Augmented Generation for Large Language Models: A Survey.](http://arxiv.org/abs/2312.10997) | 本综述论文调查了基于检索增强的大型语言模型的发展，包括三个主要范式：Naive RAG、Advanced RAG和Modular RAG。RAG通过整合外部数据库的知识，增强模型的准确性和可信度，并实现了持续更新知识和整合领域特定信息的功能。 |
| [^35] | [A Survey of Text Watermarking in the Era of Large Language Models.](http://arxiv.org/abs/2312.07913) | 本文综述了大语言模型时代的文本水印技术，包括不同技术的概述和比较、算法评估方法、应用场景以及当前挑战和未来发展方向。 |
| [^36] | [EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models.](http://arxiv.org/abs/2312.06281) | EQ-Bench是一种为评估大型语言模型（LLMs）的情商而设计的新型基准。该基准通过要求模型预测对话中角色的情绪状态强度来评估模型对复杂情绪和社交交互的理解能力。它能够有效区分不同模型，并与其他综合基准相关性很高。 |
| [^37] | [Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents.](http://arxiv.org/abs/2310.19923) | Jina Embeddings 2是一个能够处理长篇文档的文本嵌入模型，突破了传统512个标记限制，提供了高达8192个标记的容量。 |
| [^38] | [ViCrop: Perceiving Small Visual Details in Zero-shot Visual Question Answering with Multimodal Large Language Models.](http://arxiv.org/abs/2310.16033) | 本研究探讨了多模态大型语言模型在零样本视觉问答中感知细小视觉细节的能力。实验表明，这些模型对于与问题相关的视觉主题的尺寸非常敏感，通过引入人类可视剪裁可以显著提升其准确性。 |
| [^39] | [SPEED: Speculative Pipelined Execution for Efficient Decoding.](http://arxiv.org/abs/2310.12072) | SPEED通过推测执行多个未来标记，加快Transformer解码器的推理效率，从而提高生成型大型语言模型在实时场景中的应用性能。 |
| [^40] | [Understanding the Effects of RLHF on LLM Generalisation and Diversity.](http://arxiv.org/abs/2310.06452) | 本研究深入分析了强化学习从人类反馈中调整的大型语言模型每个阶段对超出分布泛化和输出多样性的影响。 |
| [^41] | [What's the Magic Word? A Control Theory of LLM Prompting.](http://arxiv.org/abs/2310.04444) | 本论文将提示工程形式化为LLM上的最优控制问题，研究了给定token序列时是否存在一种最优提示能够准确预测最终的token，并提出了控制理论中的指标来描述LLM的可操纵性。 |
| [^42] | [Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models.](http://arxiv.org/abs/2309.08163) | 研究发现，使用自我评估测试对大型语言模型的人格进行测量时，不同的提示会导致非常不同的人格得分，因此缺乏客观标准来判断哪个提示更正确。 |
| [^43] | [TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation.](http://arxiv.org/abs/2307.05134) | 本文提出了一种评估文本到图像生成中对齐性的新度量方法TIAM，该方法基于提示模板，可以更好地描述生成图像与提示中内容的对齐程度，包括对象类型、数量和颜色。研究结果表明，图像质量可以有很大的变化。 |
| [^44] | [LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection.](http://arxiv.org/abs/2306.17408) | LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。 |
| [^45] | [Conflicts, Villains, Resolutions: Towards models of Narrative Media Framing.](http://arxiv.org/abs/2306.02052) | 该论文提出了一种重新审视媒体框架的方法，针对叙事媒体，对冲突、反派和解决方案进行建模，并提供了一个注释数据集和一个关于气候变化框架的案例研究。最后，采用监督和半监督方法进行自动多标签预测，并提出了一种新颖的基于检索的方法。 |
| [^46] | [Large Language Models Are Not Abstract Reasoners.](http://arxiv.org/abs/2305.19555) | 本文通过对最先进的大型语言模型进行抽象推理任务评估，发现它们在这方面的表现十分有限，揭示了其在推理方面的局限性。 |
| [^47] | [In the Name of Fairness: Assessing the Bias in Clinical Record De-identification.](http://arxiv.org/abs/2305.11348) | 本文研究了临床记录去识别系统在不同人口群体中的表现差异，揭示了其在名称去识别方面存在显著的偏见。 |

# 详细

[^1]: 关于最佳n对齐策略的理论保证

    Theoretical guarantees on the best-of-n alignment policy. (arXiv:2401.01879v1 [cs.LG])

    [http://arxiv.org/abs/2401.01879](http://arxiv.org/abs/2401.01879)

    该论文研究了对齐生成模型的最佳n对齐策略，并证明了之前文献中的某个分析表达式是错误的。研究者们提出了一个新的KL散度估计方法，并通过实验证明其有效性。

    

    一个简单有效的生成模型对齐方法是最佳n对齐策略，该策略从一个基本策略中抽取n个样本，并根据奖励函数对它们进行排序，选择排名最高的样本。文献中常用的分析表达式声称最佳n对齐策略与基本策略之间的KL散度等于$\log (n) (n-1)/n$。我们证明了该论断的不正确性，并展示了它只是实际KL散度的一个上界。我们还研究了在不同情况下该上界的紧致性。最后，我们提出了一种新的KL散度估计方法，并通过几个例子的实验证明它能提供一个紧致的近似。

    A simple and effective method for the alignment of generative models is the best-of-$n$ policy, where $n$ samples are drawn from a base policy, and ranked based on a reward function, and the highest ranking one is selected. A commonly used analytical expression in the literature claims that the KL divergence between the best-of-$n$ policy and the base policy is equal to $\log (n) (n-1)/n.$ We disprove the validity of this claim, and show that it is an upper bound on the actual KL divergence. We also explore the tightness of this upper bound in different regimes. Finally, we propose a new estimator for the KL divergence and empirically show that it provides a tight approximation through a few examples.
    
[^2]: 语言模型的视觉检查

    A Vision Check-up for Language Models. (arXiv:2401.01862v1 [cs.CV])

    [http://arxiv.org/abs/2401.01862](http://arxiv.org/abs/2401.01862)

    本研究系统地评估了大型语言模型（LLMs）在生成和识别各种视觉概念方面的能力，并通过使用文本模型进行训练的视觉表示学习系统展示了LLMs对视觉世界的认知。实验结果表明，精确建模字符串可以教会LLMs关于视觉世界的多个方面，并且仅使用LLMs可以训练能够对自然图像进行语义评估的视觉模型。

    

    学习建模字符串之间关系是否能教会大型语言模型（LLMs）关于视觉世界的知识？我们系统地评估了LLMs生成和识别各种逐渐复杂的视觉概念的能力，然后演示了如何使用文本模型来训练初步的视觉表示学习系统。由于语言模型缺乏以像素形式获取或输出视觉信息的能力，我们在研究中使用代码来表示图像。虽然LLMs生成的图像看起来不像自然图像，但在图像生成和模型纠正这些生成图像的能力方面的结果表明，精确建模字符串可以教会语言模型关于视觉世界的许多方面。此外，利用与文本模型生成的图像进行自我监督的视觉表示学习实验证明了仅使用LLMs可以训练能够对自然图像进行语义评估的视觉模型的潜力。

    What does learning to model relationships between strings teach large language models (LLMs) about the visual world? We systematically evaluate LLMs' abilities to generate and recognize an assortment of visual concepts of increasing complexity and then demonstrate how a preliminary visual representation learning system can be trained using models of text. As language models lack the ability to consume or output visual information as pixels, we use code to represent images in our study. Although LLM-generated images do not look like natural images, results on image generation and the ability of models to correct these generated images indicate that precise modeling of strings can teach language models about numerous aspects of the visual world. Furthermore, experiments on self-supervised visual representation learning, utilizing images generated with text models, highlight the potential to train vision models capable of making semantic assessments of natural images using just LLMs.
    
[^3]: 多语言指令调优中的多语言性

    Multilingual Instruction Tuning With Just a Pinch of Multilinguality. (arXiv:2401.01854v1 [cs.CL])

    [http://arxiv.org/abs/2401.01854](http://arxiv.org/abs/2401.01854)

    本研究研究了多语言指令调优中的多语言性对跨语言指令遵循的影响。研究发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，只有40个多语言示例能够显著提高多语言指令遵循。总体来说，多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。

    

    随着大型语言模型（LLMs）的全球采纳，它们在多语言指令遵循能力变得越来越重要。一种有前途的方法是跨语言转移，通过在另一种语言上微调，模型可以在某种语言上获得特定的功能。本文研究了多语言LLM在指令调优过程中的多语言性对跨语言指令遵循的影响。首先我们发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，我们发现在英语调优集合中，只有40个多语言示例能够显著提高多语言指令遵循，在调优过程中不论是已见语言还是未见语言。总的来说，我们观察到在多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。

    As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. One promising approach is cross-lingual transfer, where a model acquires specific functionality on some language by finetuning on another language. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages. We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning. Furthermore, we find that only 40 multilingual examples in an English tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning. In general, we observe that models tuned on multilingual mixtures exhibit comparable or superior performance in several languages compared to monolingually tuned models, despite training on 10x fewer examples in those language
    
[^4]: 迭代掩码填充：一种使用掩码语言建模的有效文本增强方法

    Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling. (arXiv:2401.01830v1 [cs.CL])

    [http://arxiv.org/abs/2401.01830](http://arxiv.org/abs/2401.01830)

    本文提出了一种新颖的文本增强方法，利用基于Transformer的BERT模型的填充-掩码功能，通过迭代掩码和语言模型预测进行替换，显著提高了自然语言处理任务的性能。

    

    数据增强是提高机器学习模型性能的有效技术，但在自然语言处理领域，它的应用远不及计算机视觉领域广泛。本文提出了一种新颖的文本增强方法，利用基于Transformer的BERT模型的填充-掩码功能。我们的方法涉及对句子中的单词进行迭代掩码，并用语言模型预测进行替换。我们在各种自然语言处理任务上测试了我们的方法，并发现它在许多情况下都很有效。我们的实验结果与现有的增强方法进行了比较。实验结果表明，我们的方法在主题分类数据集上显著提高了性能。

    Data augmentation is an effective technique for improving the performance of machine learning models. However, it has not been explored as extensively in natural language processing (NLP) as it has in computer vision. In this paper, we propose a novel text augmentation method that leverages the Fill-Mask feature of the transformer-based BERT model. Our method involves iteratively masking words in a sentence and replacing them with language model predictions. We have tested our proposed method on various NLP tasks and found it to be effective in many cases. Our results are presented along with a comparison to existing augmentation methods. Experimental results show that our proposed method significantly improves performance, especially on topic classification datasets.
    
[^5]: Physio:一种基于LLM的物理治疗顾问

    Physio: An LLM-Based Physiotherapy Advisor. (arXiv:2401.01825v1 [cs.CL])

    [http://arxiv.org/abs/2401.01825](http://arxiv.org/abs/2401.01825)

    Physio是一种基于LLM的物理治疗顾问应用程序，它结合了生成模型的语言处理能力，并在回答中引用可靠的健康来源，能够进行诊断、推荐康复运动和非处方药物以缓解症状。

    

    最新语言模型的能力增加了将它们整合到实际应用中的兴趣。然而，这些模型生成的合理但不正确的文本事实在考虑在几个领域使用它们时会造成限制。医疗保健是一个要求文本生成可信度的领域的典型例子，以保障患者的健康。在本文中，我们介绍了Physio，一种用于物理康复的基于聊天的应用程序。Physio能够进行初步诊断，并引用可靠的健康来源来支持提供的信息。此外，Physio还可以借助外部知识数据库推荐康复运动和非处方药物以缓解症状。通过结合这些功能，Physio可以利用生成模型进行语言处理，同时将其回复条件化为可靠和可验证的来源。Physio的在线演示可在https://phys访问。

    The capabilities of the most recent language models have increased the interest in integrating them into real-world applications. However, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains. Healthcare is a prime example of a domain where text-generative trustworthiness is a hard requirement to safeguard patient well-being. In this paper, we present Physio, a chat-based application for physical rehabilitation. Physio is capable of making an initial diagnosis while citing reliable health sources to support the information provided. Furthermore, drawing upon external knowledge databases, Physio can recommend rehabilitation exercises and over-the-counter medication for symptom relief. By combining these features, Physio can leverage the power of generative models for language processing while also conditioning its response on dependable and verifiable sources. A live demo of Physio is available at https://phys
    
[^6]: 在封闭式问答中优化API依赖以减少幻觉的不确定性导航

    Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering. (arXiv:2401.01780v1 [cs.CL])

    [http://arxiv.org/abs/2401.01780](http://arxiv.org/abs/2401.01780)

    本文提出了一种新的大型语言模型，通过让模型自我评估是否需要查询外部资源，来优化封闭式问答中的幻觉问题。研究者通过引入幻觉屏蔽机制以及参数高效微调的方法，实现了该模型。

    

    尽管大型语言模型(LLM)能够积累和恢复知识，但它们仍然容易产生幻觉。特别是在面对事实性问题时，LLM不能仅仅依靠参数中存储的知识来保证真实和正确的答案。将这些模型与搜索外部信息源(如网络)的能力相结合，是一种将知识基于检索信息的有希望的方法。然而，在大量文档中进行搜索会带来额外的计算/时间成本。最佳策略是只有在LLM对答案不确定时才查询外部资源。在本文中，我们提出了一种新的LLM，能够自我评估是否能够直接回答问题或者需要请求外部工具。我们通过在闭书问答任务中引入幻觉屏蔽机制来进行监督学习。此外，我们还提出利用参数高效微调的方法。

    While Large Language Models (LLM) are able to accumulate and restore knowledge, they are still prone to hallucination. Especially when faced with factual questions, LLM cannot only rely on knowledge stored in parameters to guarantee truthful and correct answers. Augmenting these models with the ability to search on external information sources, such as the web, is a promising approach to ground knowledge to retrieve information. However, searching in a large collection of documents introduces additional computational/time costs. An optimal behavior would be to query external resources only when the LLM is not confident about answers. In this paper, we propose a new LLM able to self-estimate if it is able to answer directly or needs to request an external tool. We investigate a supervised approach by introducing a hallucination masking mechanism in which labels are generated using a close book question-answering task. In addition, we propose to leverage parameter-efficient fine-tuning t
    
[^7]: 利用目标分析视角进行跨目标立场检测

    Cross-target Stance Detection by Exploiting Target Analytical Perspectives. (arXiv:2401.01761v1 [cs.CL])

    [http://arxiv.org/abs/2401.01761](http://arxiv.org/abs/2401.01761)

    本论文提出了一种利用目标分析视角进行跨目标立场检测的方法，并使用多视角提示调整框架将自然语言解释融合到立场预测器中。

    

    跨目标立场检测(CTSD)是一项重要任务，通过利用源目标产生的注释数据来推断目的目标的态度。CTSD中的一种重要方法是提取域不变特征以填补多个目标之间的知识差距。然而，非正式和短文本结构的分析以及隐含表达使得提取域不变知识变得复杂。本文提出了一种多视角提示调整(MPPT)模型用于CTSD，该模型将分析视角作为知识传递的桥梁。首先，我们开发了一个基于指令的两阶段思维链(TsCoT)方法，通过基于大型语言模型(LLM)的指令制定，从多个视角提取目标分析视角并提供自然语言解释(NLEs)。接着，我们提出了一个多视角提示调节框架(MultiPLN)，将NLEs融合到立场预测器中。进行了大量实验来验证我们的方法。

    Cross-target stance detection (CTSD) is an important task, which infers the attitude of the destination target by utilizing annotated data derived from the source target. One important approach in CTSD is to extract domain-invariant features to bridge the knowledge gap between multiple targets. However, the analysis of informal and short text structure, and implicit expressions, complicate the extraction of domain-invariant knowledge. In this paper, we propose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the analysis perspective as a bridge to transfer knowledge. First, we develop a two-stage instruct-based chain-of-thought method (TsCoT) to elicit target analysis perspectives and provide natural language explanations (NLEs) from multiple viewpoints by formulating instructions based on large language model (LLM). Second, we propose a multi-perspective prompt-tuning framework (MultiPLN) to fuse the NLEs into the stance predictor. Extensive experiments results demons
    
[^8]: VGA: 视觉和图形融合注意力网络用于谣言检测

    VGA: Vision and Graph Fused Attention Network for Rumor Detection. (arXiv:2401.01759v1 [cs.SI])

    [http://arxiv.org/abs/2401.01759](http://arxiv.org/abs/2401.01759)

    这篇论文提出了一种名为VGA的视觉和图形融合注意力网络，用于多模态谣言检测。该方法不仅考虑了源索赔和图像的特征，还利用谣言的评论和传播结构来揭示谣言，并且能够有效处理图像篡改和文本信息隐藏等问题。

    

    随着社交媒体的发展，谣言在社交媒体平台上广泛传播，给社会造成了巨大的危害。除了文本信息外，许多谣言还使用篡改的图像或将文本信息隐藏在图像中，以欺骗人们并避免被检测出来，使得多模态谣言检测成为一个关键问题。目前的多模态谣言检测方法主要集中于提取源索赔和相应图像的特征，而忽略了谣言的评论和传播结构。这些评论和结构蕴含着众人的智慧，并被证明对揭露谣言至关重要。此外，这些方法通常只以基本方式提取视觉特征，很少考虑图像中的篡改或文本信息。因此，在本研究中，我们提出了一种新颖的视觉和图形融合注意力网络（VGA）用于谣言检测，以利用帖子之间的传播结构，获取众人的意见和谣言。

    With the development of social media, rumors have been spread broadly on social media platforms, causing great harm to society. Beside textual information, many rumors also use manipulated images or conceal textual information within images to deceive people and avoid being detected, making multimodal rumor detection be a critical problem. The majority of multimodal rumor detection methods mainly concentrate on extracting features of source claims and their corresponding images, while ignoring the comments of rumors and their propagation structures. These comments and structures imply the wisdom of crowds and are proved to be crucial to debunk rumors. Moreover, these methods usually only extract visual features in a basic manner, seldom consider tampering or textual information in images. Therefore, in this study, we propose a novel Vision and Graph Fused Attention Network (VGA) for rumor detection to utilize propagation structures among posts so as to obtain the crowd opinions and fur
    
[^9]: 在语义解析中评估大型语言模型在基于知识图谱的对话问答中的应用

    Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs. (arXiv:2401.01711v1 [cs.CL])

    [http://arxiv.org/abs/2401.01711](http://arxiv.org/abs/2401.01711)

    本论文评估了尚未在知识图谱对话问答任务上进行预训练的大型语言模型的性能，并通过实验证明了这些模型在生成图查询方面的能力以及通过少量提示和微调技术可以显著改善其性能。

    

    会话式问答系统通常依赖语义解析来实现交互式信息检索，该过程涉及将自然语言输入转化为结构化数据库查询。对于知识图谱中存储的事实的信息检索对话，对话表达被转化为图查询的过程被称为基于知识的对话问答。本文评估了尚未明确在此任务上进行预训练的大型语言模型的性能。通过在广泛的基准数据集上进行一系列实验，我们比较了不同大小和提示技术的模型，并识别出生成输出中常见的问题类型。我们的结果表明，大型语言模型能够从对话中生成图查询，通过少量提示和微调技术可以显著提高性能，特别是对于展示较低零样本性能的较小模型。

    Conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. For information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. This paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. Through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. Our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-sho
    
[^10]: WordArt设计师API：利用模型范围上的大型语言模型进行用户驱动的艺术字体合成

    WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope. (arXiv:2401.01699v1 [cs.CV])

    [http://arxiv.org/abs/2401.01699](http://arxiv.org/abs/2401.01699)

    本文介绍了WordArt设计师API，它利用大型语言模型在模型范围上进行用户驱动的艺术字体合成。通过提供动态、自适应和高效的替代方案，该方法能够满足非专业人士简化艺术字体的需求，并实现了更直观的设计过程。与现有系统相比，该API显著提高了用户满意度、设计灵活性和创造性表达，并为个性化数字通信和设计开辟了新的可能性。

    

    本文介绍了WordArt设计师API，这是一个利用模型范围上的大型语言模型进行用户驱动的艺术字体合成的新框架。我们通过提供动态、自适应和计算效果高的替代传统刚性模板的方案，解决了非专业人士简化艺术字体的挑战。我们的方法利用LLMs的能力来理解和解释用户输入，促进更直观的设计过程。通过各种案例研究，我们展示了用户如何表达他们的审美偏好和功能需求，系统然后将其转化为独特且富有创意的字体设计。我们的评估结果表明，与现有系统相比，用户满意度、设计灵活性和创造性表达都有显著改进。WordArt设计师API不仅使字体艺术民主化，还为个性化数字通信和设计打开了新的可能性。

    This paper introduces the WordArt Designer API, a novel framework for user-driven artistic typography synthesis utilizing Large Language Models (LLMs) on ModelScope. We address the challenge of simplifying artistic typography for non-professionals by offering a dynamic, adaptive, and computationally efficient alternative to traditional rigid templates. Our approach leverages the power of LLMs to understand and interpret user input, facilitating a more intuitive design process. We demonstrate through various case studies how users can articulate their aesthetic preferences and functional requirements, which the system then translates into unique and creative typographic designs. Our evaluations indicate significant improvements in user satisfaction, design flexibility, and creative expression over existing systems. The WordArt Designer API not only democratizes the art of typography but also opens up new possibilities for personalized digital communication and design.
    
[^11]: 世界语言的持久性和扩散性模式

    Patterns of Persistence and Diffusibility across World's Languages. (arXiv:2401.01698v1 [cs.CL])

    [http://arxiv.org/abs/2401.01698](http://arxiv.org/abs/2401.01698)

    本研究通过构建大规模图表，探讨了合词和音韵跨语言相似性的语言原因，并支持了一项先前已有的假设。

    

    语言的相似性可能是由于遗传关系、区域接触、普遍性或偶然性。合词是一种未被充分研究的相似性类型，即使用一个词汇形式来表达多个意义。在我们的工作中，通过研究家族稳定性（持久性）和接触诱发变化（扩散性），我们揭示了合词和音韵跨语言相似性的语言原因。我们构建了涵盖1966种语言的大规模图，包括语义、家族、音韵和地理数据。我们通过研究语言学领域以前工作中的几个已建立的假设，并提出新的假设，展示了这一资源的潜力。我们的结果强烈支持语言学文献中一个之前已建立的假设，同时提供了对另一个假设的证据。我们的大规模资源为跨学科研究提供了更多的可能性，例如多语言自然语言处理和比较语言学。

    Language similarities can be caused by genetic relatedness, areal contact, universality, or chance. Colexification, i.e.~a type of similarity where a single lexical form is used to convey multiple meanings, is underexplored. In our work, we shed light on the linguistic causes of cross-lingual similarity in colexification and phonology, by exploring genealogical stability (persistence) and contact-induced change (diffusibility). We construct large-scale graphs incorporating semantic, genealogical, phonological and geographical data for 1,966 languages. We then show the potential of this resource, by investigating several established hypotheses from previous work in linguistics, while proposing new ones. Our results strongly support a previously established hypothesis in the linguistic literature, while offering contradicting evidence to another. Our large scale resource opens for further research across disciplines, e.g.~in multilingual NLP and comparative linguistics.
    
[^12]: 从学生的对话中预测挑战时刻：GPT-4与两种传统自然语言处理方法的比较

    Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches. (arXiv:2401.01692v1 [cs.CL])

    [http://arxiv.org/abs/2401.01692](http://arxiv.org/abs/2401.01692)

    本研究比较了三种自然语言处理方法（专家规则模型、监督式机器学习模型和大型语言模型）在从学生对话中检测和确定挑战的能力。结果表明，监督式机器学习模型和大型语言模型在这两个任务中表现较好，而专家规则模型效果较差。研究对这些方法的性能进行了广泛讨论。

    

    有效的协作需要团队在面对挑战时进行战略性的自我调控。研究表明，团队可能因成员对挑战的认知差异而无法进行调控，而这种情况可能受益于外部支持。本研究探讨了利用三种不同的自然语言处理模型：专家知识基于规则的模型、监督式机器学习模型和大型语言模型（LLM），在从学生对话中检测挑战和确定挑战维度（认知、元认知、情感和技术/其他挑战）方面的潜力。结果显示，监督式机器学习和大型语言模型在这两个任务中表现得相当好，而基于规则的方法效果较差，其功效严重依赖于专家设计的特征。本文对这三种方法在自动检测和支持学生挑战过程中的性能进行了广泛讨论。

    Effective collaboration requires groups to strategically regulate themselves to overcome challenges. Research has shown that groups may fail to regulate due to differences in members' perceptions of challenges which may benefit from external support. In this study, we investigated the potential of leveraging three distinct natural language processing models: an expert knowledge rule-based model, a supervised machine learning (ML) model and a Large Language model (LLM), in challenge detection and challenge dimension identification (cognitive, metacognitive, emotional and technical/other challenges) from student discourse, was investigated. The results show that the supervised ML and the LLM approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts. The paper provides an extensive discussion of the three approaches' performance for automated detection and support of students' challenge
    
[^13]: MLPs Compass: MLP与PLM相结合时学到了什么？

    MLPs Compass: What is learned when MLPs are combined with PLMs?. (arXiv:2401.01667v1 [cs.CL])

    [http://arxiv.org/abs/2401.01667](http://arxiv.org/abs/2401.01667)

    本文研究探究了Multilayer-Perceptrons (MLPs)模块是否能增强预训练语言模型（PLMs）对语言信息的捕捉能力。实验结果表明，MLPs确实能够提高PLMs对语言结构的理解能力。

    

    尽管基于Transformer的预训练语言模型及其变体具有很强的语义表示能力，但关于PLM的额外组件所带来的信息增益的理解仍然是一个未解开的问题。受到最近的工作的激励，其证明了多层感知器（MLP）模块实现了强大的结构捕捉能力，甚至 超过了图神经网络（GNN），本文旨在量化简单的MLP是否能进一步增强PLM捕捉语言信息的能力。具体而言，我们设计了一个简单但有效的探测框架，包含了基于BERT结构的MLP组件，并进行了广泛的实验，涵盖了三个不同语言层次的10个探测任务。实验结果表明，MLP确实可以通过PLM提高对语言结构的理解能力。我们的研究为设计各种变体提供了可解释且有价值的见解。

    While Transformer-based pre-trained language models and their variants exhibit strong semantic representation capabilities, the question of comprehending the information gain derived from the additional components of PLMs remains an open question in this field. Motivated by recent efforts that prove Multilayer-Perceptrons (MLPs) modules achieving robust structural capture capabilities, even outperforming Graph Neural Networks (GNNs), this paper aims to quantify whether simple MLPs can further enhance the already potent ability of PLMs to capture linguistic information. Specifically, we design a simple yet effective probing framework containing MLPs components based on BERT structure and conduct extensive experiments encompassing 10 probing tasks spanning three distinct linguistic levels. The experimental results demonstrate that MLPs can indeed enhance the comprehension of linguistic structure by PLMs. Our research provides interpretable and valuable insights into crafting variations o
    
[^14]: 为品牌设计社交媒体广告标题生成

    Social Media Ready Caption Generation for Brands. (arXiv:2401.01637v1 [cs.CL])

    [http://arxiv.org/abs/2401.01637](http://arxiv.org/abs/2401.01637)

    这项研究提出了一个流程解决方案来帮助品牌生成与品牌个性相一致的社交媒体广告标题，以吸引消费者的注意力。

    

    社交媒体广告对于品牌营销至关重要，致力于吸引消费者的注意力，通过吸引人的标题、图片以及标志来实现。尽管先前的研究侧重于为一般图像生成标题，但将品牌个性融入社交媒体标题仍未得到探索。品牌个性已被证明对消费者行为和社交互动产生影响，因此是营销策略的关键要素。现有的开源多模态语言模型并不适用于此任务。因此，我们提出了一种流程解决方案，以帮助品牌创建与图像和品牌个性相一致的吸引人社交媒体标题。我们的架构包含两个部分：第一部分包含一个图像字幕模型，它接收品牌要在网上发布的图像并生成一个简洁的英文标题；第二部分接收生成的标题以及目标品牌个性，输出与品牌个性相一致且引人注目的社交媒体标题。

    Social media advertisements are key for brand marketing, aiming to attract consumers with captivating captions and pictures or logos. While previous research has focused on generating captions for general images, incorporating brand personalities into social media captioning remains unexplored. Brand personalities are shown to be affecting consumers' behaviours and social interactions and thus are proven to be a key aspect of marketing strategies. Current open-source multimodal LLMs are not directly suited for this task. Hence, we propose a pipeline solution to assist brands in creating engaging social media captions that align with the image and the brand personalities. Our architecture is based on two parts: a the first part contains an image captioning model that takes in an image that the brand wants to post online and gives a plain English caption; b the second part takes in the generated caption along with the target brand personality and outputs a catchy personality-aligned soci
    
[^15]: AI是否能像人类一样具备创造力？

    Can AI Be as Creative as Humans?. (arXiv:2401.01623v1 [cs.AI])

    [http://arxiv.org/abs/2401.01623](http://arxiv.org/abs/2401.01623)

    本文引入了一个新概念【相对创造力】，通过将焦点转向AI是否能够与人类具备相同的创造能力，实现对创造力的统计量化评估和直接比较。

    

    创造力是社会进步和创新的基石，但其评估仍然是一个复杂且主观的任务。随着先进的生成型AI模型的出现，能够完成曾经只属于人类创造力的任务，探索AI的创造潜力变得至关重要，以确保其负责任的发展和应用。本文通过引入一个名为“相对创造力”的新概念来解决定义和评估创造力的复杂性。我们不再试图对创造力进行普遍定义，而是将焦点转向AI是否能够与一位假设的人类具备相同的创造能力。这种观点借鉴了图灵测试的思想，并扩展其范围以解决评估创造力中所固有的挑战和主观性。这种方法的转变使得对AI创造力的统计量化评估成为可能，我们将其称为统计创造力。这种方法允许直接比较AI与特定人类的创造能力。

    Creativity serves as a cornerstone for societal progress and innovation, but its assessment remains a complex and often subjective endeavor. With the rise of advanced generative AI models capable of tasks once reserved for human creativity, the study of AI's creative potential becomes imperative for its responsible development and application. This paper addresses the complexities in defining and evaluating creativity by introducing a new concept called Relative Creativity. Instead of trying to define creativity universally, we shift the focus to whether AI can match the creative abilities of a hypothetical human. This perspective draws inspiration from the Turing Test, expanding upon it to address the challenges and subjectivities inherent in evaluating creativity. This methodological shift facilitates a statistically quantifiable evaluation of AI's creativity, which we term Statistical Creativity. This approach allows for direct comparisons of AI's creative abilities with those of sp
    
[^16]: 术中风险预测和预后中的大型语言模型能力研究

    Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication. (arXiv:2401.01620v1 [cs.AI])

    [http://arxiv.org/abs/2401.01620](http://arxiv.org/abs/2401.01620)

    在这项研究中，我们探讨了使用通用领域大型语言模型在术中风险预测和预后方面的能力。通过使用手术描述和患者临床记录，我们在8个不同的任务上考察了预测性能，并发现少量样本和链式启发式策略可以提高预测性能。此外，我们的研究表明当前一代大型语言模型可以帮助临床医生在术中风险分层和生成高质量的自然语言总结方面发挥作用。

    

    我们研究了通用领域的大型语言模型，如GPT-4 Turbo，能否使用手术的描述和来自电子健康记录的患者临床记录，进行风险分层和预测术后结果指标。我们对8个不同任务的预测性能进行了考察：ASA生理状态分类的预测、住院、重症监护室入院、非计划入院、住院死亡、PACU第一阶段持续时间、住院时间和重症监护室时间的预测。少量样本和链式启发式策略改善了几个任务的预测性能。我们在ASA生理状态分类预测上达到了0.50的F1得分，在重症监护室入院预测上达到了0.81的F1得分，在住院死亡预测上达到了0.86的F1得分。所有提示策略在持续时间预测任务上的表现普遍较差。当前一代大型语言模型可以帮助临床医生在分类任务中进行术中风险分层，并生成高质量的自然语言总结。

    We investigate whether general-domain large language models such as GPT-4 Turbo can perform risk stratification and predict post-operative outcome measures using a description of the procedure and a patient's clinical notes derived from the electronic health record. We examine predictive performance on 8 different tasks: prediction of ASA Physical Status Classification, hospital admission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1 duration, hospital duration, and ICU duration. Few-shot and chain-of-thought prompting improves predictive performance for several of the tasks. We achieve F1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU admission, and 0.86 for hospital mortality. Performance on duration prediction tasks were universally poor across all prompt strategies. Current generation large language models can assist clinicians in perioperative risk stratification on classification tasks and produce high-quality natural language summarie
    
[^17]: GPT-4V(ision)是一个通用的网络代理，如果有基础的话。

    GPT-4V(ision) is a Generalist Web Agent, if Grounded. (arXiv:2401.01614v1 [cs.IR])

    [http://arxiv.org/abs/2401.01614](http://arxiv.org/abs/2401.01614)

    GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。

    

    最近对大型多模型（LMM）的研究，特别是GPT-4V(ision)和Gemini，快速推动了多模型的能力边界超越传统任务，如图像字幕和视觉问答。在这项工作中，我们探索了像GPT-4V这样的LMM作为通用网络代理的潜力，可以根据自然语言指令在任何给定的网站上完成任务。我们提出了SEEACT，一种利用LMM的力量进行综合视觉理解和网页操作的通用网络代理。我们在最新的MIND2WEB基准上进行评估。除了对缓存网站的标准离线评估外，我们还通过开发一个允许在实时网站上运行网络代理的工具，实现了一种新的在线评估设置。我们展示了GPT-4V在网页代理方面表现出巨大的潜力-如果我们将其文本计划手动地实施为网站上的行动，它可以成功地完成50%的任务。此结果明显超过了传统方法。

    The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering. In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website. We propose SEEACT, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web. We evaluate on the recent MIND2WEB benchmark. In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites. We show that GPT-4V presents a great potential for web agents - it can successfully complete 50% of the tasks on live websites if we manually ground its textual plans into actions on the websites. This substantially outperforms
    
[^18]: PLLaMa：一种用于植物科学的开源大型语言模型

    PLLaMa: An Open-source Large Language Model for Plant Science. (arXiv:2401.01600v1 [cs.CL])

    [http://arxiv.org/abs/2401.01600](http://arxiv.org/abs/2401.01600)

    PLLaMa是一种用于植物科学的开源大型语言模型，通过综合数据库增强，显著丰富了其在植物和农业科学方面的知识和专长，并通过与专业人员小组的合作验证了其准确性。

    

    大型语言模型（LLMs）在理解和与自然语言进行交互方面展示了出色的能力。然而，在植物科学等需要高准确性的专业领域中，由于缺乏相关领域的专业知识，它们的效果受到了限制。本文介绍了PLLaMa，一种从LLaMa-2进化而来的开源语言模型。它通过包括超过150万篇植物科学学术文章的综合数据库进行增强。这一发展显著丰富了PLLaMa在植物和农业科学方面的知识和专长。我们的初步测试中，涉及与植物和农业相关的特定数据集，显示PLLaMa显著提高了对植物科学相关主题的理解。此外，我们还组建了一个国际专业人员小组，包括植物科学家、农业工程师和植物育种员。该团队在验证PLLaMa的准确性方面起着关键作用。

    Large Language Models (LLMs) have exhibited remarkable capabilities in understanding and interacting with natural language across various sectors. However, their effectiveness is limited in specialized areas requiring high accuracy, such as plant science, due to a lack of specific expertise in these fields. This paper introduces PLLaMa, an open-source language model that evolved from LLaMa-2. It's enhanced with a comprehensive database, comprising more than 1.5 million scholarly articles in plant science. This development significantly enriches PLLaMa with extensive knowledge and proficiency in plant and agricultural sciences. Our initial tests, involving specific datasets related to plants and agriculture, show that PLLaMa substantially improves its understanding of plant science-related topics. Moreover, we have formed an international panel of professionals, including plant scientists, agricultural engineers, and plant breeders. This team plays a crucial role in verifying the accura
    
[^19]: MedSumm：一种多模态方法用于总结混合码Hindi-English临床查询

    MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries. (arXiv:2401.01596v1 [cs.AI])

    [http://arxiv.org/abs/2401.01596](http://arxiv.org/abs/2401.01596)

    本研究提出了一种多模态方法，用于总结混合码Hindi-English临床查询，通过整合文本和视觉线索，提供更全面的患者医疗状况的表示。为了解决这个问题，研究还提出了一个名为MedSumm的框架，利用LLMs和VLMs来完成任务。

    

    在医疗领域中，总结患者提出的医疗问题对于改善医患互动和医疗决策至关重要。虽然医疗数据的复杂性和数量不断增长，但目前在这个领域的研究主要集中在基于文本的方法上，忽视了视觉线索的整合。此外，在医学问题总结的领域中，之前的研究仅限于英语语言。本研究引入了在低资源环境下针对混合码输入进行多模态医学问题总结的任务。为了解决这个问题，我们引入了Multimodal Medical Codemixed Question Summarization（MMCQS）数据集，该数据集结合了Hindi-English混合码医学查询和视觉辅助工具。这种整合丰富了患者的医疗状况的表示，提供了更全面的视角。我们还提出了一个名为MedSumm的框架，利用LLMs和VLMs的能力来完成这个任务。

    In the healthcare domain, summarizing medical questions posed by patients is critical for improving doctor-patient interactions and medical decision-making. Although medical data has grown in complexity and quantity, the current body of research in this domain has primarily concentrated on text-based methods, overlooking the integration of visual cues. Also prior works in the area of medical question summarisation have been limited to the English language. This work introduces the task of multimodal medical question summarization for codemixed input in a low-resource setting. To address this gap, we introduce the Multimodal Medical Codemixed Question Summarization MMCQS dataset, which combines Hindi-English codemixed medical queries with visual aids. This integration enriches the representation of a patient's medical condition, providing a more comprehensive perspective. We also propose a framework named MedSumm that leverages the power of LLMs and VLMs for this task. By utilizing our 
    
[^20]: 神经自动语音识别中的幻听：识别错误和幻觉模型

    Hallucinations in Neural Automatic Speech Recognition: Identifying Errors and Hallucinatory Models. (arXiv:2401.01572v1 [cs.CL])

    [http://arxiv.org/abs/2401.01572](http://arxiv.org/abs/2401.01572)

    该论文研究了神经自动语音识别中的幻听问题，并提出了一种用于在测试时评估幻听敏感性的基于扰动的方法，该方法能够帮助区分幻觉和非幻觉模型。

    

    幻听是由深度神经网络产生的一种输出错误。虽然这在自然语言处理中已经被研究过，但在自动语音识别中以前还没有进行过研究。在这里，我们将ASR中的幻听定义为模型生成的转录与源话语不相关，但仍流畅和连贯的语义。幻听与模型可能的自然语言输出的相似性，会产生欺骗的危险，影响系统的可信度。我们证明了常用的指标，如词错误率，无法区分幻觉和非幻觉模型。为了解决这个问题，我们提出了一种基于扰动的方法，用于在测试时评估自动语音识别（ASR）系统对幻听的敏感性，该方法不需要访问训练数据集。我们证明了这种方法有助于区分幻觉和非幻觉模型。

    Hallucinations are a type of output error produced by deep neural networks. While this has been studied in natural language processing, they have not been researched previously in automatic speech recognition. Here, we define hallucinations in ASR as transcriptions generated by a model that are semantically unrelated to the source utterance, yet still fluent and coherent. The similarity of hallucinations to probable natural language outputs of the model creates a danger of deception and impacts the credibility of the system. We show that commonly used metrics, such as word error rates, cannot differentiate between hallucinatory and non-hallucinatory models. To address this, we propose a perturbation-based method for assessing the susceptibility of an automatic speech recognition (ASR) model to hallucination at test time, which does not require access to the training dataset. We demonstrate that this method helps to distinguish between hallucinatory and non-hallucinatory models that hav
    
[^21]: GOAT-Bench: 通过基于迷因的社交虐待研究对大型多模态模型的安全洞察

    GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse. (arXiv:2401.01523v1 [cs.CL])

    [http://arxiv.org/abs/2401.01523](http://arxiv.org/abs/2401.01523)

    通过基于迷因的社交虐待研究对大型多模态模型的安全洞察，我们引入了综合的迷因基准测试集GOAT-Bench，评估各种LMMs在识别和回应迷因中体现的微妙社交虐待方面的能力。

    

    社交媒体的指数级增长深刻改变了信息的创造、传播和吸收方式，在数字时代产生了前所未有的影响。遗憾的是，这个爆炸也导致了网络迷因的滥用数量显著增加。评估迷因的负面影响是相当具有挑战性的，因为它们通常具有微妙和隐晦的含义，这些含义不能直接通过显性的文本和图像传达出来。鉴于此，大型多模态模型(LMMs)作为处理多样化多模态任务的卓越能力的焦点引起了人们的兴趣。针对这一发展，我们的论文旨在深入研究各种LMMs(如GPT-4V)识别和回应迷因中体现的微妙社交虐待方面的能力。我们引入了综合的迷因基准测试集GOAT-Bench，其中包含超过6K个多样的迷因，涵盖的主题包括隐性仇恨言论、性别歧视和网络欺凌等。利用GOAT-Be

    The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Be
    
[^22]: 利用神经转导器进行两阶段文本到语音转换的语义标记预测

    Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction. (arXiv:2401.01498v1 [eess.AS])

    [http://arxiv.org/abs/2401.01498](http://arxiv.org/abs/2401.01498)

    利用神经转导器实现了一个两阶段的文本到语音转换框架，通过语义标记预测实现了稳健高效的对齐建模，并通过非自回归语音生成器合成语音波形。该框架在语音质量和说话者相似度方面超过了基线模型。

    

    我们提出了一个新颖的文本到语音（TTS）框架，它以神经转导器为核心。我们的方法将整个TTS流程划分为语义级别的序列到序列(seq2seq)建模和细粒度的声学建模阶段，利用从wav2vec2.0嵌入中获取的离散语义标记。为了实现稳健高效的对齐建模，我们使用了一个名为语义标记转导器的神经转导器来进行语义标记预测，从中获得了硬单调对齐约束的益处。随后，一个非自回归(NAR)语音生成器从这些语义标记有效地合成波形。另外，参考语音在每个阶段控制着时间动态和声学条件。这种解耦的框架减少了TTS的训练复杂性，同时允许每个阶段专注于语义和声学建模。我们在零-shot自适应TTS上的实验结果表明，我们的模型在语音质量和说话者相似度方面超越了基线模型。

    We propose a novel text-to-speech (TTS) framework centered around a neural transducer. Our approach divides the whole TTS pipeline into semantic-level sequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling stages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings. For a robust and efficient alignment modeling, we employ a neural transducer named token transducer for the semantic token prediction, benefiting from its hard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR) speech generator efficiently synthesizes waveforms from these semantic tokens. Additionally, a reference speech controls temporal dynamics and acoustic conditions at each stage. This decoupled framework reduces the training complexity of TTS while allowing each stage to focus on semantic and acoustic modeling. Our experimental results on zero-shot adaptive TTS demonstrate that our model surpasses the baseline in terms of speech quality and speaker similari
    
[^23]: 基于图形对比学习的两阶段多模态情绪识别模型

    A Two-Stage Multimodal Emotion Recognition Model Based on Graph Contrastive Learning. (arXiv:2401.01495v1 [cs.CL])

    [http://arxiv.org/abs/2401.01495](http://arxiv.org/abs/2401.01495)

    该论文提出了一种基于图形对比学习的两阶段多模态情绪识别模型。首先，将原始数据集用不同预处理模态进行编码；然后，引入了图形对比学习策略，通过其他结构对不同模态数据进行学习，以了解模态内部的相似性和差异性；最后，使用MLP进行最终的情绪分类。

    

    在人机交互方面，正确理解用户在对话中的情绪状态变得越来越重要，因此多模态情绪识别（MER）的任务开始受到更多关注。然而，现有的情绪分类方法通常只进行一次分类，句子在单轮分类中很可能被错误分类。先前的工作通常忽略了融合过程中不同形态特征之间的相似性和差异性。为了解决上述问题，我们提出了一种基于图形对比学习的两阶段情绪识别模型（TS-GCL）。首先，我们使用不同的预处理模态对原始数据集进行编码。其次，引入了图形对比学习（GCL）策略，通过其他结构对这三个模态数据进行学习，以了解模态内部的相似性和差异性。最后，我们使用MLP两次进行最终的情绪分类。

    In terms of human-computer interaction, it is becoming more and more important to correctly understand the user's emotional state in a conversation, so the task of multimodal emotion recognition (MER) started to receive more attention. However, existing emotion classification methods usually perform classification only once. Sentences are likely to be misclassified in a single round of classification. Previous work usually ignores the similarities and differences between different morphological features in the fusion process. To address the above issues, we propose a two-stage emotion recognition model based on graph contrastive learning (TS-GCL). First, we encode the original dataset with different preprocessing modalities. Second, a graph contrastive learning (GCL) strategy is introduced for these three modal data with other structures to learn similarities and differences within and between modalities. Finally, we use MLP twice to achieve the final emotion classification. This stage
    
[^24]: 自然语言处理与多模式股票价格预测

    Natural Language Processing and Multimodal Stock Price Prediction. (arXiv:2401.01487v1 [cs.LG])

    [http://arxiv.org/abs/2401.01487](http://arxiv.org/abs/2401.01487)

    本文使用自然语言处理和多模式股票价格预测，利用股票百分比变化作为训练数据，分析公开发布的新闻文章。结果展示了使用小型自然语言处理模型准确预测总体股票趋势的能力，以及特定数据特征和选择的有效性。

    

    在金融决策领域，预测股票价格是至关重要的。人工智能技术，如长短期记忆网络（LSTM）、支持向量机（SVM）和自然语言处理（NLP）模型常被用于预测股票价格。本文利用股票百分比变化作为训练数据，与传统使用原始货币值的方式相比，重点分析公开发布的新闻文章。百分比变化的选择旨在为模型提供关于价格波动的重要性及其对股票整体价格变化的影响的背景信息。该研究使用了专门的BERT自然语言处理模型来预测股票价格趋势，特别强调各种数据模态的重要性。结果展示了使用小型自然语言处理模型准确预测总体股票趋势的能力，并凸显了特定数据特征和选择的有效性。

    In the realm of financial decision-making, predicting stock prices is pivotal. Artificial intelligence techniques such as long short-term memory networks (LSTMs), support-vector machines (SVMs), and natural language processing (NLP) models are commonly employed to predict said prices. This paper utilizes stock percentage change as training data, in contrast to the traditional use of raw currency values, with a focus on analyzing publicly released news articles. The choice of percentage change aims to provide models with context regarding the significance of price fluctuations and overall price change impact on a given stock. The study employs specialized BERT natural language processing models to predict stock price trends, with a particular emphasis on various data modalities. The results showcase the capabilities of such strategies with a small natural language processing model to accurately predict overall stock trends, and highlight the effectiveness of certain data features and se
    
[^25]: Stack Overflow回答中信息高亮的初探

    A First Look at Information Highlighting in Stack Overflow Answers. (arXiv:2401.01472v1 [cs.CL])

    [http://arxiv.org/abs/2401.01472](http://arxiv.org/abs/2401.01472)

    本论文进行了首次大规模的探索性研究，研究了Stack Overflow回答中的信息高亮。通过使用神经网络架构，开发了自动推荐突出内容的方法。

    

    背景：浏览Stack Overflow（SO）的知识仍然具有挑战性。为了使帖子对用户更生动，SO允许用户使用Markdown或HTML编写和编辑帖子，以便用户可以利用各种格式化样式（例如粗体、斜体和代码）来突出重要信息。然而，关于突出信息的研究仍然有限。目标：我们在最近的研究中进行了首次大规模的探索性研究，研究了SO回答中的信息高亮。为了扩展我们之前的研究，我们利用最初设计用于命名实体识别任务的神经网络架构，开发了自动推荐带有格式化样式的突出内容的方法。方法：本文研究了Stack Overflow的31,169,429个回答。为了训练推荐模型，我们选择了CNN和BERT模型，针对每种格式化类型（即粗体、斜体、代码和标题）使用我们从SO回答收集的突出信息数据集。

    Context: Navigating the knowledge of Stack Overflow (SO) remains challenging. To make the posts vivid to users, SO allows users to write and edit posts with Markdown or HTML so that users can leverage various formatting styles (e.g., bold, italic, and code) to highlight the important information. Nonetheless, there have been limited studies on the highlighted information. Objective: We carried out the first large-scale exploratory study on the information highlighted in SO answers in our recent study. To extend our previous study, we develop approaches to automatically recommend highlighted content with formatting styles using neural network architectures initially designed for the Named Entity Recognition task. Method: In this paper, we studied 31,169,429 answers of Stack Overflow. For training recommendation models, we choose CNN and BERT models for each type of formatting (i.e., Bold, Italic, Code, and Heading) using the information highlighting dataset we collected from SO answers.
    
[^26]: 基于检索增强生成的问答式电子健康记录摘要

    Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation. (arXiv:2401.01469v1 [cs.CL])

    [http://arxiv.org/abs/2401.01469](http://arxiv.org/abs/2401.01469)

    提出了一种基于检索增强生成的问答式电子健康记录摘要方法，通过结合语义搜索、RAG和最新的LLMs，摘要是提取被专业人士认为重要的特定问题的答案。

    

    电子健康记录（EHRs）的摘要可以大大减少患者和医务人员的“屏幕时间”。近年来，EHRs的摘要已经使用最先进的神经模型进行机器学习流程。然而，由于难以获得足够的注释数据进行训练，这些模型产生的结果不够满意。此外，由于现代大型语言模型（LLMs）中的注意机制在输入大小方面增加了二次复杂性，因此需要考虑整个EHR内容的摘要效果较差。我们提出了一种通过结合语义搜索、检索增强生成（RAG）和最新的LLMs来缓解这些缺点的方法。在我们的方法中，摘要是提取被专业人士认为重要的特定问题的答案。

    Summarization of electronic health records (EHRs) can substantially minimize 'screen time' for both patients as well as medical personnel. In recent years summarization of EHRs have employed machine learning pipelines using state of the art neural models. However, these models have produced less than adequate results that are attributed to the difficulty of obtaining sufficient annotated data for training. Moreover, the requirement to consider the entire content of an EHR in summarization has resulted in poor performance due to the fact that attention mechanisms in modern large language models (LLMs) adds a quadratic complexity in terms of the size of the input. We propose here a method that mitigates these shortcomings by combining semantic search, retrieval augmented generation (RAG) and question-answering using the latest LLMs. In our approach summarization is the extraction of answers to specific questions that are deemed important by subject-matter experts (SMEs). Our approach is 
    
[^27]: 与不分歧相比：从构词-句法角度看机器翻译与人工翻译

    To Diverge or Not to Diverge: A Morphosyntactic Perspective on Machine Translation vs Human Translation. (arXiv:2401.01419v1 [cs.CL])

    [http://arxiv.org/abs/2401.01419](http://arxiv.org/abs/2401.01419)

    通过对机器翻译和人工翻译进行细致比较分析，我们发现机器翻译相对保守，具有较少的构词-句法多样性和更多的收敛模式，并且机器翻译性能下降与构词-句法分歧的存在有关。

    

    我们通过构词-句法分歧的镜头进行了大规模的细致比较分析，对比了机器翻译（MT）和人工翻译（HT）。在三种语言对和两种定义为源语言和目标语言之间的结构差异的分歧类型下，机器翻译始终比人工翻译更为保守，具有较少的构词-句法多样性，更多的收敛性模式和更多的一对一对应关系。通过对不同解码算法的分析，我们将这种差异归因于束搜索的使用，这使得机器翻译偏向于更为收敛的模式。当收敛模式出现在训练数据中约50%的时间时，这种偏向性会被放大。最后，我们表明对于大多数构词-句法分歧，其存在于人工翻译中与机器翻译的性能下降相关，给机器翻译系统带来了更大的挑战。

    We conduct a large-scale fine-grained comparative analysis of machine translations (MT) against human translations (HT) through the lens of morphosyntactic divergence. Across three language pairs and two types of divergence defined as the structural difference between the source and the target, MT is consistently more conservative than HT, with less morphosyntactic diversity, more convergent patterns, and more one-to-one alignments. Through analysis on different decoding algorithms, we attribute this discrepancy to the use of beam search that biases MT towards more convergent patterns. This bias is most amplified when the convergent pattern appears around 50% of the time in training data. Lastly, we show that for a majority of morphosyntactic divergences, their presence in HT is correlated with decreased MT performance, presenting a greater challenge for MT systems.
    
[^28]: 量化唐纳德·特朗普在总统演讲中的独特性

    Quantifying the Uniqueness of Donald Trump in Presidential Discourse. (arXiv:2401.01405v1 [cs.CL])

    [http://arxiv.org/abs/2401.01405](http://arxiv.org/abs/2401.01405)

    这项研究使用了一种新的度量标准来量化唐纳德·特朗普在总统演讲中的独特性，并发现了他在使用具有分裂性和对抗性的语言、重复强调等方面与其他总统候选人存在显著差异。此外，特朗普比共和党同僚更具独特性。

    

    唐纳德·特朗普与其他总统在演讲中是否表达出不同的风格？如果是，有哪些方面的不同？这些差异是否局限于任何单一的沟通媒介？为了调查这些问题，本文引入了一种基于大型语言模型的独特性度量标准，开发了一个新的分裂性演讲词库，并提出了比较政治对手词汇特征的框架。将这些工具应用于多种总统演讲语料库，我们发现有相当多的证据表明特朗普的讲话模式与近代历任主要总统候选人不同。一些显著的发现包括特朗普使用特别具有分裂性和对抗性的语言针对他的政治对手，并且他重复强调的模式。此外，特朗普比他的共和党同僚更加独特，而他们的独特性值与民主党相对较接近。这些差异在多种度量方法下保持一致。

    Does Donald Trump speak differently from other presidents? If so, in what ways? Are these differences confined to any single medium of communication? To investigate these questions, this paper introduces a novel metric of uniqueness based on large language models, develops a new lexicon for divisive speech, and presents a framework for comparing the lexical features of political opponents. Applying these tools to a variety of corpora of presidential speeches, we find considerable evidence that Trump's speech patterns diverge from those of all major party nominees for the presidency in recent history. Some notable findings include Trump's employment of particularly divisive and antagonistic language targeting of his political opponents and his patterns of repetition for emphasis. Furthermore, Trump is significantly more distinctive than his fellow Republicans, whose uniqueness values are comparably closer to those of the Democrats. These differences hold across a variety of measurement 
    
[^29]: 大型语言模型中幻觉缓解技术的综述

    A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models. (arXiv:2401.01313v1 [cs.CL])

    [http://arxiv.org/abs/2401.01313](http://arxiv.org/abs/2401.01313)

    大型语言模型在生成文本时容易出现幻觉，这是安全部署这些模型的最大障碍。解决幻觉问题对于在实际环境中广泛使用这些模型至关重要。

    

    随着大型语言模型（LLMs）在生成人类化文本方面的能力不断提高，一个关键挑战是它们倾向于产生虚构的内容，看似真实但没有依据。幻觉问题可以说是安全地将这些强大的LLMs部署到影响人们生活的现实生产系统中最大的障碍。在实际环境中广泛采用LLMs的过程严重依赖于解决和减轻幻觉。与传统的专注于有限任务的人工智能系统不同，LLMs在训练过程中可以接触到大量的在线文本数据。这使它们能够展示出令人印象深刻的语言流利性，但也意味着它们能够从训练数据的偏见中推断信息，错误解释含糊不清的提示，或者修改信息以表面上与输入一致。当我们依赖语言生成能力来完成敏感应用时，这变得非常令人担忧。

    As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded. This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives. The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations. Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training. While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. This becomes hugely alarming when we rely on language generation capabilities for sensitive applica
    
[^30]: 机器翻译自动评估的参考文献质量和数量

    Quality and Quantity of Machine Translation References for Automated Metrics. (arXiv:2401.01283v1 [cs.CL])

    [http://arxiv.org/abs/2401.01283](http://arxiv.org/abs/2401.01283)

    本研究发现，机器翻译评估的较高质量参考文献对于评估指标与人类评价之间的相关性更好。每个段落平均使用7个参考文献有助于提升所有评估指标。不同质量的供应商参考文献可以混合使用来提高评估指标的准确性。这些发现可用于在特定预算下创建参考文献的共享任务的评估者。

    

    自动机器翻译评估指标通常使用人工翻译来确定系统翻译的质量。领域内的共识认为人工参考文献应具有很高的质量。然而，目前没有成本效益分析可以指导计划收集机器翻译评估参考文献的从业者。我们发现，较高质量的参考文献能够在段落级别上与人类评价的相关性更好。每个段落平均使用7个参考文献有助于所有评估指标的提升。有趣的是，来自不同质量的供应商的参考文献可以混合使用，并提高评估指标的准确性。然而，较高质量的参考文献制作成本更高，我们将其视为一个优化问题：在特定预算下，应该收集哪些参考文献以最大化评估指标的准确性。这些发现可用于在特定预算下创建参考文献的共享任务的评估者。

    Automatic machine translation metrics often use human translations to determine the quality system translations. Common wisdom in the field dictates that the human references should be of very high quality. However, there are no cost-benefit analyses that could be used to guide practitioners who plan to collect references for machine translation evaluation. We find that higher-quality references lead to better metric correlations with humans at the segment-level. Having up to 7 references per segment and taking their average helps all metrics. Interestingly, the references from vendors of different qualities can be mixed together and improve metric success. Higher quality references, however, cost more to create and we frame this as an optimization problem: given a specific budget, what references should be collected to maximize metric success. These findings can be used by evaluators of shared tasks when references need to be created under a certain budget.
    
[^31]: 自然语言处理和大型语言模型公平性认证

    Fairness Certification for Natural Language Processing and Large Language Models. (arXiv:2401.01262v1 [cs.CL])

    [http://arxiv.org/abs/2401.01262](http://arxiv.org/abs/2401.01262)

    这项研究旨在为自然语言处理领域开发公平性认证方法。通过综述大量文献和专家访谈，我们提出了六个公平性标准，为操作化和测试过程提供了基础。

    

    自然语言处理（NLP）在我们的日常生活中扮演着重要角色，特别是由于大型语言模型（LLM）的巨大进展。然而，NLP在招聘等公平关键应用场景中存在许多问题，例如作为专家系统或基于LLM的教育导师。由于NLP基于人类语言，可能会导致潜在的有害偏见渗入NLP系统，产生不公平的结果，歧视少数群体或引发法律问题。因此，开展NLP方法的公平性认证非常重要。我们采用定性研究方法，对算法公平性的大量文献进行了综述，并与该领域的多位专家进行了半结构化的专家访谈。我们系统地提出了NLP的六个公平性标准，并进一步细化为18个子类别。我们的标准为实施和测试过程提供了基础。

    Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches. We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes
    
[^32]: 越南诗歌生成与跨语言诗歌翻译的前景

    Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation. (arXiv:2401.01078v1 [cs.CL])

    [http://arxiv.org/abs/2401.01078](http://arxiv.org/abs/2401.01078)

    本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。

    

    诗歌生成一直是自然语言处理领域的一项挑战任务，因为它要求模型理解语言、情感和风格的细微差别。在本文中，我们提出使用大型语言模型从自然语言提示中生成越南诗歌，从而实现直观的过程和增强的内容控制。我们最有效的模型，GPT-3 Babbage变种，在越南诗歌的“六八词”类型中实现了0.8的自定义评分。此外，我们还探索了将诗歌改写成正常文本提示的想法，并在“六八词”类型中获得了相对较高的0.718分数。这个实验展示了以翻译后的诗歌作为输入进行跨语言诗歌翻译的潜力，并同时保持对生成内容的完全控制。

    Poetry generation has been a challenging task in the field of Natural Language Processing, as it requires the model to understand the nuances of language, sentiment, and style. In this paper, we propose using Large Language Models to generate Vietnamese poems from natural language prompts, thereby facilitating an intuitive process with enhanced content control. Our most efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the "luc bat" genre of Vietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.718 in the "luc bat" genre. This experiment presents the potential for cross-Language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content.
    
[^33]: DialCLIP: 将CLIP扩展为多模态对话检索器

    DialCLIP: Empowering CLIP as Multi-Modal Dialog Retriever. (arXiv:2401.01076v1 [cs.CL])

    [http://arxiv.org/abs/2401.01076](http://arxiv.org/abs/2401.01076)

    DialCLIP是一种参数高效的多模态对话检索方法，通过在预训练的视觉语言模型CLIP中引入多模态上下文提示生成器和领域提示来提升对话检索的能力。

    

    最近，在预训练的视觉语言模型方面取得了重大进展，极大地提升了多模态对话系统的能力。这些模型通过在下游任务上进行微调，已经取得了显著的改进。然而，现有的预训练模型主要集中在有效地捕捉视觉和语言模态之间的对齐，往往忽视了对话环境的复杂性。本文提出了一种名为DialCLIP的参数高效的提示微调方法，用于多模态对话检索。具体而言，我们的方法引入了一个多模态上下文提示生成器，用于学习上下文特征，并在预训练视觉语言模型CLIP中将其提炼为提示。此外，我们引入了领域提示，以减轻下游对话数据引起的差异。为了方便各种类型的检索，我们还设计了多个专家，从CLIP的输出学习到多模态表示空间的映射，每个专家都有自己的模型。

    Recently, substantial advancements in pre-trained vision-language models have greatly enhanced the capabilities of multi-modal dialog systems. These models have demonstrated significant improvements by fine-tuning on downstream tasks. However, the existing pre-trained models primarily focus on effectively capturing the alignment between vision and language modalities, often ignoring the intricate nature of dialog context. In this paper, we propose a parameter-efficient prompt-tuning method named DialCLIP for multi-modal dialog retrieval. Specifically, our approach introduces a multi-modal context prompt generator to learn context features which are subsequently distilled into prompts within the pre-trained vision-language model CLIP. Besides, we introduce domain prompt to mitigate the disc repancy from the downstream dialog data. To facilitate various types of retrieval, we also design multiple experts to learn mappings from CLIP outputs to multi-modal representation space, with each e
    
[^34]: 基于检索增强的大型语言模型：一项调研

    Retrieval-Augmented Generation for Large Language Models: A Survey. (arXiv:2312.10997v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.10997](http://arxiv.org/abs/2312.10997)

    本综述论文调查了基于检索增强的大型语言模型的发展，包括三个主要范式：Naive RAG、Advanced RAG和Modular RAG。RAG通过整合外部数据库的知识，增强模型的准确性和可信度，并实现了持续更新知识和整合领域特定信息的功能。

    

    大型语言模型（LLMs）展示了显著的能力，但面临幻觉、过时知识和非透明、不可追溯的推理过程等挑战。检索增强生成（RAG）已经成为一种有前途的解决方案，通过整合来自外部数据库的知识，增强模型的准确性和可信度，特别适用于知识密集型任务，并允许持续更新知识和整合领域特定信息。RAG将LLMs自身的知识与庞大、动态的外部数据库相结合，实现协同效应。本综述论文详细考察了RAG范式的发展，包括Naive RAG、Advanced RAG和Modular RAG。它详细审视了RAG框架的三个基本要素，包括检索、生成和增强技术。本文强调了嵌入在RAG框架中的最新技术。

    Large Language Models (LLMs) demonstrate significant capabilities but face challenges such as hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the models, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval , the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in e
    
[^35]: 大语言模型时代文本水印技术综述

    A Survey of Text Watermarking in the Era of Large Language Models. (arXiv:2312.07913v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.07913](http://arxiv.org/abs/2312.07913)

    本文综述了大语言模型时代的文本水印技术，包括不同技术的概述和比较、算法评估方法、应用场景以及当前挑战和未来发展方向。

    

    文本水印算法在版权保护中起着至关重要的作用，然而其能力和应用场景一直受限。大语言模型的最新发展为文本水印技术的进步打开了新的机会。大语言模型不仅通过其文本理解和生成能力增强了文本水印算法的能力，还需要使用文本水印算法来保护自身的版权。本文对当前文本水印技术的现状进行了全面的调查，包括四个主要方面：（1）不同文本水印技术的概述和比较；（2）文本水印算法的评估方法，包括成功率、对文本质量的影响、鲁棒性和防篡改性；（3）文本水印技术的潜在应用场景；（4）当前挑战和未来发展方向。

    Text watermarking algorithms play a crucial role in the copyright protection of textual content, yet their capabilities and application scenarios have been limited historically. The recent developments in large language models (LLMs) have opened new opportunities for the advancement of text watermarking techniques. LLMs not only enhance the capabilities of text watermarking algorithms through their text understanding and generation abilities but also necessitate the use of text watermarking algorithms for their own copyright protection. This paper conducts a comprehensive survey of the current state of text watermarking technology, covering four main aspects: (1) an overview and comparison of different text watermarking techniques; (2) evaluation methods for text watermarking algorithms, including their success rates, impact on text quality, robustness, and unforgeability; (3) potential application scenarios for text watermarking technology; (4) current challenges and future directions
    
[^36]: EQ-Bench:一种用于大型语言模型的情商评估基准

    EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models. (arXiv:2312.06281v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.06281](http://arxiv.org/abs/2312.06281)

    EQ-Bench是一种为评估大型语言模型（LLMs）的情商而设计的新型基准。该基准通过要求模型预测对话中角色的情绪状态强度来评估模型对复杂情绪和社交交互的理解能力。它能够有效区分不同模型，并与其他综合基准相关性很高。

    

    我们介绍了EQ-Bench，这是一种用于评估大型语言模型（LLMs）情商方面的新型基准。我们通过要求LLMs预测对话中角色的情绪状态的强度来评估LLMs理解复杂情绪和社交交互的能力。这个基准可以有效地区分不同模型。我们发现EQ-Bench与综合多领域基准（如MMLU）之间存在很强的相关性（r=0.97），这表明我们可能捕捉到了广泛智能的相似方面。我们的基准使用60个英语问题产生高度可重复的结果。我们还在https://github.com/EQ-bench/EQ-Bench上提供了开源代码用于自动化基准测试流程，以及https://eqbench.com上的排行榜。

    We introduce EQ-Bench, a novel benchmark designed to evaluate aspects of emotional intelligence in Large Language Models (LLMs). We assess the ability of LLMs to understand complex emotions and social interactions by asking them to predict the intensity of emotional states of characters in a dialogue. The benchmark is able to discriminate effectively between a wide range of models. We find that EQ-Bench correlates strongly with comprehensive multi-domain benchmarks like MMLU (Hendrycks et al., 2020) (r=0.97), indicating that we may be capturing similar aspects of broad intelligence. Our benchmark produces highly repeatable results using a set of 60 English-language questions. We also provide open-source code for an automated benchmarking pipeline at https://github.com/EQ-bench/EQ-Bench and a leaderboard at https://eqbench.com
    
[^37]: Jina Embeddings 2: 面向长篇文档的8192-Token通用文本嵌入模型

    Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents. (arXiv:2310.19923v1 [cs.CL])

    [http://arxiv.org/abs/2310.19923](http://arxiv.org/abs/2310.19923)

    Jina Embeddings 2是一个能够处理长篇文档的文本嵌入模型，突破了传统512个标记限制，提供了高达8192个标记的容量。

    

    文本嵌入模型已经成为将句子转化为固定大小特征向量的强大工具，这些向量包含了语义信息。尽管这些模型对于信息检索、语义聚类和文本重排序等任务至关重要，但大多数现有的开源模型，尤其是基于BERT等架构构建的模型，难以表示长篇文档，并且常常会进行截断。为了缓解这个挑战，一种常见的方法是将文档分割成更小的段落进行嵌入。然而，这种策略会导致更大的向量集合，进而增加内存消耗，并且在向量搜索时会出现计算密集和延迟升高的问题。为了解决这些挑战，我们介绍了Jina Embeddings 2，这是一个开源的文本嵌入模型，可以容纳高达8192个标记。该模型旨在突破传统的512个标记限制，能够灵活处理长篇文档。

    Text embedding models have emerged as powerful tools for transforming sentences into fixed-sized feature vectors that encapsulate semantic information. While these models are essential for tasks like information retrieval, semantic clustering, and text re-ranking, most existing open-source models, especially those built on architectures like BERT, struggle to represent lengthy documents and often resort to truncation. One common approach to mitigate this challenge involves splitting documents into smaller paragraphs for embedding. However, this strategy results in a much larger set of vectors, consequently leading to increased memory consumption and computationally intensive vector searches with elevated latency.  To address these challenges, we introduce Jina Embeddings 2, an open-source text embedding model capable of accommodating up to 8192 tokens. This model is designed to transcend the conventional 512-token limit and adeptly process long documents. Jina Embeddings 2 not only ach
    
[^38]: ViCrop: 利用多模态大型语言模型在零样本视觉问答中感知细小视觉细节

    ViCrop: Perceiving Small Visual Details in Zero-shot Visual Question Answering with Multimodal Large Language Models. (arXiv:2310.16033v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.16033](http://arxiv.org/abs/2310.16033)

    本研究探讨了多模态大型语言模型在零样本视觉问答中感知细小视觉细节的能力。实验表明，这些模型对于与问题相关的视觉主题的尺寸非常敏感，通过引入人类可视剪裁可以显著提升其准确性。

    

    多模态大型语言模型(MLLMs)在视觉问答(VQA)上取得了令人期待的零样本准确性，这是一个影响各种下游应用和领域的基本任务。鉴于这些模型的广泛使用潜力，研究它们在处理不同的图像和问题属性方面的限制非常重要。在这项工作中，我们研究了MLLMs是否能够像较大的组件一样感知图像中的细节。特别是，我们发现它们在回答视觉问题时对与问题相关的视觉主题的尺寸非常敏感，并且随着尺寸的减小，零样本准确性下降多达45.91%。此外，通过观察到人类可视剪裁可以显著减轻其对尺寸的敏感性，我们证明了这种效应是因果的。为了扩大人类可视剪裁的实用性，我们提出了ViCrop，这是一个利用自动可视剪裁来增强MLLMs零样本VQA的通用框架。

    Multimodal Large Language Models (MLLMs) have recently achieved promising zero-shot accuracy on visual question answering (VQA) -- a fundamental task affecting various downstream applications and domains. Given the great potential for the broad use of these models, it is important to investigate their limitations in dealing with different image and question properties. In this work, we investigate whether MLLMs can perceive details as well as larger components in images. In particular, we show that their zero-shot accuracy in answering visual questions is very sensitive to the size of the visual subject related to the question, declining up to $45.91\%$ with size. Furthermore, we show that this effect is causal by observing that human visual cropping can significantly mitigate their sensitivity to size. To scale up the usefulness of human cropping, we propose ViCrop, a general framework that utilizes automatic visual cropping to enhance zero-shot VQA of MLLMs. We construct five variant
    
[^39]: SPEED: 用于高效解码的推测流水线执行

    SPEED: Speculative Pipelined Execution for Efficient Decoding. (arXiv:2310.12072v1 [cs.CL])

    [http://arxiv.org/abs/2310.12072](http://arxiv.org/abs/2310.12072)

    SPEED通过推测执行多个未来标记，加快Transformer解码器的推理效率，从而提高生成型大型语言模型在实时场景中的应用性能。

    

    基于Transformer架构的生成型大型语言模型（LLM）近来已成为广泛应用于自然语言处理任务的主导基础模型。然而，由于这些模型的推理延迟显著，它们在实时场景中的应用受到了很大限制。这主要是由于生成型LLM推理的自回归特性，其中每个标记依赖于所有先前的输出标记，因此很难实现任何标记级的并行性，使得推理过程极度受内存限制。在这项工作中，我们提出了SPEED，通过使用基于早期隐藏状态的预测值来并行地推测执行当前标记与多个未来标记，从而提高推理效率。对于采用参数共享的Transformer解码器，可以将并行执行的标记的内存操作分摊，从而允许我们...

    Generative Large Language Models (LLMs) based on the Transformer architecture have recently emerged as a dominant foundation model for a wide range of Natural Language Processing tasks. Nevertheless, their application in real-time scenarios has been highly restricted due to the significant inference latency associated with these models. This is particularly pronounced due to the autoregressive nature of generative LLM inference, where tokens are generated sequentially since each token depends on all previous output tokens. It is therefore challenging to achieve any token-level parallelism, making inference extremely memory-bound. In this work, we propose SPEED, which improves inference efficiency by speculatively executing multiple future tokens in parallel with the current token using predicted values based on early-layer hidden states. For Transformer decoders that employ parameter sharing, the memory operations for the tokens executing in parallel can be amortized, which allows us t
    
[^40]: 理解RLHF对LLM泛化和多样性的影响

    Understanding the Effects of RLHF on LLM Generalisation and Diversity. (arXiv:2310.06452v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.06452](http://arxiv.org/abs/2310.06452)

    本研究深入分析了强化学习从人类反馈中调整的大型语言模型每个阶段对超出分布泛化和输出多样性的影响。

    

    在最广泛使用的AI模型中，如OpenAI的ChatGPT或Anthropic的Claude，使用强化学习从人类反馈中调整的大型语言模型（LLM）。尽管在这些方法的开发方面有大量的研究，但我们对RLHF过程中每个阶段的利与弊的理解仍然有限。为了填补这一空白，我们对每个阶段（即监督微调（SFT），奖励建模和RLHF）如何影响两个关键属性进行了全面分析：超出分布的泛化和输出多样性。在这些模型被广泛应用于真实世界中的各种情景的背景下，超出分布的泛化非常重要，而输出多样性指的是模型生成各种不同输出的能力，对于各种用例来说都非常重要。我们在摘要和指令遵循任务中对两个基本模型进行了分析，后者非常相关。

    Large language models (LLMs) fine-tuned with reinforcement learning from human feedback (RLHF) have been used in some of the most widely deployed AI models to date, such as OpenAI's ChatGPT or Anthropic's Claude. % , or Meta's LLaMA-2. While there has been significant work developing these methods, our understanding of the benefits and downsides of each stage in RLHF is still limited. To fill this gap, we present an extensive analysis of how each stage of the process (i.e.~supervised fine-tuning (SFT), reward modelling, and RLHF) affects two key properties: out-of-distribution (OOD) generalisation and output diversity. OOD generalisation is crucial given the wide range of real-world scenarios in which these models are being used, while output diversity refers to the model's ability to generate varied outputs and is important for a variety of use cases. We perform our analysis across two base models on both summarisation and instruction following tasks, the latter being highly relevant 
    
[^41]: 魔法词是什么？LLM提示的控制理论研究

    What's the Magic Word? A Control Theory of LLM Prompting. (arXiv:2310.04444v1 [cs.CL])

    [http://arxiv.org/abs/2310.04444](http://arxiv.org/abs/2310.04444)

    本论文将提示工程形式化为LLM上的最优控制问题，研究了给定token序列时是否存在一种最优提示能够准确预测最终的token，并提出了控制理论中的指标来描述LLM的可操纵性。

    

    提示工程在LLM的部署中是有效和重要的，但在数学上理解不足。在这里，我们将提示工程形式化为LLM上的最优控制问题，其中提示被认为是调节LLM输出分布的控制变量。在这个框架内，我们提出一个简单的问题：给定一个token序列，是否总存在一个我们可以添加的提示，使得LLM能够准确预测最终的token？我们将这样的最优提示称为魔法词，因为添加提示会导致LLM输出正确的答案。如果存在魔法词，我们能否找到它们？如果可以，它们的特性是什么？我们提供了将控制理论应用于自注意力头的分析分析，证明了其权重矩阵的奇异值函数为可控制性的上界。我们借鉴控制理论来提出了一种叫做$k-\epsilon$可控制性的指标，用于描述LLM的可操纵性。

    Prompt engineering is effective and important in the deployment of LLMs but is poorly understood mathematically. Here, we formalize prompt engineering as an optimal control problem on LLMs -- where the prompt is considered a control variable for modulating the output distribution of the LLM. Within this framework, we ask a simple question: given a sequence of tokens, does there always exist a prompt we can prepend that will steer the LLM toward accurately predicting the final token? We call such an optimal prompt the magic word since prepending the prompt causes the LLM to output the correct answer. If magic words exist, can we find them? If so, what are their properties? We offer analytic analysis on the controllability of the self-attention head where we prove a bound on controllability as a function of the singular values of its weight matrices. We take inspiration from control theory to propose a metric called $k-\epsilon$ controllability to characterize LLM steerability. We comput
    
[^42]: 研究自我评估测试在大型语言模型的人格测量中的适用性

    Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models. (arXiv:2309.08163v1 [cs.CL])

    [http://arxiv.org/abs/2309.08163](http://arxiv.org/abs/2309.08163)

    研究发现，使用自我评估测试对大型语言模型的人格进行测量时，不同的提示会导致非常不同的人格得分，因此缺乏客观标准来判断哪个提示更正确。

    

    随着大型语言模型的能力不断发展，各种最近的研究试图使用用于研究人类行为的心理工具来量化它们的行为。其中一个例子是使用人格自我评估测试来衡量大型语言模型的“人格”。在本文中，我们选择了三个关于使用人格自我评估测试来量化大型语言模型的人格的研究。我们使用这三个不同论文中使用的提示来评估同一大型语言模型的人格。我们发现，这三个提示导致了非常不同的人格得分。这一简单测试揭示了大型语言模型中的人格自我评估得分取决于提示者的主观选择。由于我们不知道大型语言模型的人格得分的真实值，因为此类问题没有正确答案，所以无法声明某个提示比其他提示更正确或更不正确。然后，我们引入了人格选项顺序对称性的属性。

    As large language models (LLM) evolve in their capabilities, various recent studies have tried to quantify their behavior using psychological tools created to study human behavior. One such example is the measurement of "personality" of LLMs using personality self-assessment tests. In this paper, we take three such studies on personality measurement of LLMs that use personality self-assessment tests created to study human behavior. We use the prompts used in these three different papers to measure the personality of the same LLM. We find that all three prompts lead very different personality scores. This simple test reveals that personality self-assessment scores in LLMs depend on the subjective choice of the prompter. Since we don't know the ground truth value of personality scores for LLMs as there is no correct answer to such questions, there's no way of claiming if one prompt is more or less correct than the other. We then introduce the property of option order symmetry for persona
    
[^43]: TIAM -- 一种评估文本到图像生成中对齐性的度量方法

    TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation. (arXiv:2307.05134v1 [cs.CV])

    [http://arxiv.org/abs/2307.05134](http://arxiv.org/abs/2307.05134)

    本文提出了一种评估文本到图像生成中对齐性的新度量方法TIAM，该方法基于提示模板，可以更好地描述生成图像与提示中内容的对齐程度，包括对象类型、数量和颜色。研究结果表明，图像质量可以有很大的变化。

    

    合成图像生成的进展使得评估其质量变得至关重要。尽管已经提出了几种用于评估图像渲染的度量方法，但对于基于提示生成图像的文本到图像（T2I）模型而言，考虑到生成图像与提示中重要内容之间的相似程度等额外因素至关重要。此外，虽然生成的图像通常是从随机起始点开始的，但通常不考虑这一影响。本文提出了一种基于提示模板的新度量方法，用于研究提示中指定的内容与生成的图像之间的对齐性。它允许我们更好地描述对齐性，包括指定对象的类型、数量和颜色。我们对几个最近的T2I模型进行了研究，并获得了一个有趣的额外结果，即图像质量可以大幅度变化。

    The progress in the generation of synthetic images has made it crucial to assess their quality. While several metrics have been proposed to assess the rendering of images, it is crucial for Text-to-Image (T2I) models, which generate images based on a prompt, to consider additional aspects such as to which extent the generated image matches the important content of the prompt. Moreover, although the generated images usually result from a random starting point, the influence of this one is generally not considered. In this article, we propose a new metric based on prompt templates to study the alignment between the content specified in the prompt and the corresponding generated images. It allows us to better characterize the alignment in terms of the type of the specified objects, their number, and their color. We conducted a study on several recent T2I models about various aspects. An additional interesting result we obtained with our approach is that image quality can vary drastically 
    
[^44]: LMBot: 将图形知识融入语言模型以进行无图形部署的推特机器人检测

    LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v1 [cs.AI])

    [http://arxiv.org/abs/2306.17408](http://arxiv.org/abs/2306.17408)

    LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。

    

    随着恶意行为者使用越来越先进和广泛的机器人来传播错误信息和操纵舆论，推特机器人的检测已成为一项至关重要的任务。尽管基于图形的推特机器人检测方法取得了最先进的性能，但我们发现它们的推理依赖于距离目标用户多跳的邻居用户，并且获取邻居用户是耗时的，并可能引入偏差。与此同时，我们发现在推特机器人检测上微调后，预训练的语言模型在竞争性性能方面取得了良好的表现，并且在部署过程中不需要图形结构。受到这一发现的启发，我们提出了一种新颖的机器人检测框架LMBot，它将图神经网络(GNNs)的知识融入语言模型(LMs)，以在推特机器人检测中进行无图形部署，以应对数据依赖性的挑战。此外，LMBot对基于图形和不使用图形的数据集兼容。具体而言，我们首先将每个用户表示为一段文本

    As malicious actors employ increasingly advanced and widespread bots to disseminate misinformation and manipulate public opinion, the detection of Twitter bots has become a crucial task. Though graph-based Twitter bot detection methods achieve state-of-the-art performance, we find that their inference depends on the neighbor users multi-hop away from the targets, and fetching neighbors is time-consuming and may introduce bias. At the same time, we find that after finetuning on Twitter bot detection, pretrained language models achieve competitive performance and do not require a graph structure during deployment. Inspired by this finding, we propose a novel bot detection framework LMBot that distills the knowledge of graph neural networks (GNNs) into language models (LMs) for graph-less deployment in Twitter bot detection to combat the challenge of data dependency. Moreover, LMBot is compatible with graph-based and graph-less datasets. Specifically, we first represent each user as a tex
    
[^45]: 冲突、反派、解决方案：面向叙事媒体框架模型的研究

    Conflicts, Villains, Resolutions: Towards models of Narrative Media Framing. (arXiv:2306.02052v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02052](http://arxiv.org/abs/2306.02052)

    该论文提出了一种重新审视媒体框架的方法，针对叙事媒体，对冲突、反派和解决方案进行建模，并提供了一个注释数据集和一个关于气候变化框架的案例研究。最后，采用监督和半监督方法进行自动多标签预测，并提出了一种新颖的基于检索的方法。

    

    尽管自然语言处理中对媒体框架的自动检测越来越感兴趣，但问题通常被简化为单标签分类，并采用了类似主题的框架观点，避免了对更广泛的文档级叙事进行建模。在这项工作中，我们重新审视了通信科学中广泛使用的框架概念，该概念明确捕捉了叙事的要素，包括冲突及其解决方案，并将其与叙事框架中的关键实体（英雄、受害者或反派）相结合。我们采用了一种有效的注释范式，将复杂的注释任务分解为一系列较简单的二进制问题，并提供了一份英语新闻文章的注释数据集，并在来自政治光谱的新闻媒体文章中进行了气候变化框架的案例研究。最后，我们探索了使用监督和半监督方法自动多标签预测框架，并提出了一种新颖的基于检索的方法。

    Despite increasing interest in the automatic detection of media frames in NLP, the problem is typically simplified as single-label classification and adopts a topic-like view on frames, evading modelling the broader document-level narrative. In this work, we revisit a widely used conceptualization of framing from the communication sciences which explicitly captures elements of narratives, including conflict and its resolution, and integrate it with the narrative framing of key entities in the story as heroes, victims or villains. We adapt an effective annotation paradigm that breaks a complex annotation task into a series of simpler binary questions, and present an annotated data set of English news articles, and a case study on the framing of climate change in articles from news outlets across the political spectrum. Finally, we explore automatic multi-label prediction of our frames with supervised and semi-supervised approaches, and present a novel retrieval-based method which is bot
    
[^46]: 大型语言模型不能作为抽象推理器

    Large Language Models Are Not Abstract Reasoners. (arXiv:2305.19555v1 [cs.CL])

    [http://arxiv.org/abs/2305.19555](http://arxiv.org/abs/2305.19555)

    本文通过对最先进的大型语言模型进行抽象推理任务评估，发现它们在这方面的表现十分有限，揭示了其在推理方面的局限性。

    

    大型语言模型在自然语言处理任务上表现出极好的性能，包括文本理解和常识推理等。然而，这些成功的机制尚不清楚，LLMs是否能够达到人类的认知能力或这些模型是否还存在根本性的局限性也不确定。抽象推理是认知的基本任务，包括从少量数据中找到和应用一般模式。评估深度神经结构在这个任务上的表现可以揭示它们在推理方面的潜在局限性和广泛的泛化能力，这是一个目前未被探索的领域。本文对最先进的LLMs进行了大量评估，发现它们在抽象推理任务中的表现非常有限，并探究了造成这种差异的原因。

    Large Language Models have shown tremendous performance on a large variety of natural language processing tasks, ranging from text comprehension to common sense reasoning. However, the mechanisms responsible for this success remain unknown, and it is unclear whether LLMs can achieve human-like cognitive capabilities or whether these models are still fundamentally limited. Abstract reasoning is a fundamental task for cognition, consisting of finding and applying a general pattern from few data. Evaluating deep neural architectures on this task could give insight into their potential limitations regarding reasoning and their broad generalisation abilities, yet this is currently an under-explored area. In this paper, we perform extensive evaluations of state-of-the-art LLMs on abstract reasoning tasks, showing that they achieve very limited performance in contrast with other natural language tasks, and we investigate the reasons for this difference. We apply techniques that have been show
    
[^47]: 以公平名义：评估临床记录去识别中的偏见

    In the Name of Fairness: Assessing the Bias in Clinical Record De-identification. (arXiv:2305.11348v1 [cs.LG])

    [http://arxiv.org/abs/2305.11348](http://arxiv.org/abs/2305.11348)

    本文研究了临床记录去识别系统在不同人口群体中的表现差异，揭示了其在名称去识别方面存在显著的偏见。

    

    数据共享对于开放科学和可重复研究至关重要，但合法共享临床数据需要从电子健康记录中删除受保护的健康信息。这个过程，称为去识别，通常通过许多商业和开源系统使用机器学习算法来实现。虽然这些系统在平均水平上已经显示出令人信服的结果，但它们在不同的人口群体中的表现差异还没有得到彻底的检查。在这项工作中，我们通过大规模实证分析，研究了临床笔记中的名称去识别系统的偏见。为了实现这一目的，我们创建了16个名称集，涵盖了四个人口统计学维度：性别、种族、名称流行度和流行的十年。我们将这些名称插入到100个手动筛选的临床模板中，并评估了九种公共和私人去识别方法的性能。我们的发现表明，在临床记录去识别系统的名称方面存在统计显著的偏见。

    Data sharing is crucial for open science and reproducible research, but the legal sharing of clinical data requires the removal of protected health information from electronic health records. This process, known as de-identification, is often achieved through the use of machine learning algorithms by many commercial and open-source systems. While these systems have shown compelling results on average, the variation in their performance across different demographic groups has not been thoroughly examined. In this work, we investigate the bias of de-identification systems on names in clinical notes via a large-scale empirical analysis. To achieve this, we create 16 name sets that vary along four demographic dimensions: gender, race, name popularity, and the decade of popularity. We insert these names into 100 manually curated clinical templates and evaluate the performance of nine public and private de-identification methods. Our findings reveal that there are statistically significant p
    

