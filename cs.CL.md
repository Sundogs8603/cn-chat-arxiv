# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Distractor generation for multiple-choice questions with predictive prompting and large language models.](http://arxiv.org/abs/2307.16338) | 本研究利用预测提示和大型语言模型，通过引导它们生成干扰项来填补教育背景下多项选择题中生成干扰项的性能差距。实验证明，这种方法在质量上超过了现有模型，并获得了高质量的干扰项。 |
| [^2] | [Mispronunciation detection using self-supervised speech representations.](http://arxiv.org/abs/2307.16324) | 本文研究了在第二语言学习者的发音错误检测任务中使用自监督学习模型的方法。研究发现，使用为目标任务训练的下游模型能够得到最佳性能，而大多数上游模型在此任务中表现相似。 |
| [^3] | [Recent Advances in Hierarchical Multi-label Text Classification: A Survey.](http://arxiv.org/abs/2307.16265) | 这篇论文调查了分层多标签文本分类的最新进展，包括数据集、方法、评估指标、学习策略和挑战，同时提供了未来研究方向。 |
| [^4] | [A Private Watermark for Large Language Models.](http://arxiv.org/abs/2307.16230) | 这项工作提出了一种私密水印算法，通过使用两个不同的神经网络进行水印生成和检测，并共享部分参数，实现了高效且高准确性的检测，同时对生成和检测速度影响最小。 |
| [^5] | [Optimizing the Neural Network Training for OCR Error Correction of Historical Hebrew Texts.](http://arxiv.org/abs/2307.16220) | 这篇论文提出了一种使用较少的手动创建数据训练的轻量级神经网络方法，用于希伯来文OCR后校正。研究目标是开发自动生成训练数据的方法，改善OCR后校正结果，并研究最适用于历史文档的OCR后校正的数据集类型。 |
| [^6] | [Text Analysis Using Deep Neural Networks in Digital Humanities and Information Science.](http://arxiv.org/abs/2307.16217) | 本论文研究了在数字人文研究中使用深度神经网络进行文本分析的挑战，包括训练数据的可用性和领域适应的需求。 |
| [^7] | [Question Answering with Deep Neural Networks for Semi-Structured Heterogeneous Genealogical Knowledge Graphs.](http://arxiv.org/abs/2307.16214) | 本研究提出一种用于家族谱问答的深度神经网络方法，该方法将家族谱数据表示为知识图并与非结构化文本结合，使用Transformer模型进行训练。这种方法解决了家族谱领域中模型无法处理图结构和缺乏训练数据集的问题。 |
| [^8] | [Toward a Period-Specific Optimized Neural Network for OCR Error Correction of Historical Hebrew Texts.](http://arxiv.org/abs/2307.16213) | 本研究针对历史希伯来文本OCR错误校正的问题，提出了一种特定时期优化的神经网络模型。然而，由于希伯来语是形态丰富语言，神经网络所需的训练数据集不够充足，且最佳的网络结构和超参数值尚不明确。另外，不同流派和时期的语言变化可能会影响OCR后校正模型的准确性。 |
| [^9] | [Around the GLOBE: Numerical Aggregation Question-Answering on Heterogeneous Genealogical Knowledge Graphs with Deep Neural Networks.](http://arxiv.org/abs/2307.16208) | 本文介绍了一种在异构家谱知识图谱上进行数字聚合问答的方法，在基因谱领域提出了自然语言问题并获得准确答案的能力还未被充分研究。 |
| [^10] | [A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue Information Extraction.](http://arxiv.org/abs/2307.16200) | 本论文提出了一个知识增强的两阶段生成框架（KTGF）用于医学对话信息提取。通过两个阶段的生成，分别生成医学对话中的术语和每个术语的状态，从而更好地建模术语之间的关系。 |
| [^11] | [Improving TTS for Shanghainese: Addressing Tone Sandhi via Word Segmentation.](http://arxiv.org/abs/2307.16199) | 本文通过词分割方法改进了上海话TTS模型中声调连读的质量，对于将上海话的形式化语言学解释引入计算项目具有重要意义。 |
| [^12] | [Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models.](http://arxiv.org/abs/2307.16180) | 本文探讨了使用MBTI人格测试作为评估大型语言模型（LLMs）的可行性，通过实验研究了不同LLM的个性类型、通过提示工程改变个性类型的可能性以及训练数据集对模型个性的影响。 |
| [^13] | [User-Controlled Knowledge Fusion in Large Language Models: Balancing Creativity and Hallucination.](http://arxiv.org/abs/2307.16139) | 本文提出了一种用户可控的机制，用于调节大型语言模型在生成回应时创造力和对外部知识的忠诚度之间的平衡。这种机制通过在训练过程中引入数值标记，并使用自动化过程计算标记的程度，从而实现用户对模型的依赖程度的控制。 |
| [^14] | [SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension.](http://arxiv.org/abs/2307.16125) | 这项工作引入了一个名为SEED-Bench的基准测试，用于评估生成式多模态大语言模型的理解能力。SEED-Bench包括19K个多项选择题，涵盖了图像和视频模态等12个评估维度。通过人工注释提供的正确选项，能够客观高效地评估模型的性能。 |
| [^15] | [EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction.](http://arxiv.org/abs/2307.16082) | 本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。 |
| [^16] | [Roll Up Your Sleeves: Working with a Collaborative and Engaging Task-Oriented Dialogue System.](http://arxiv.org/abs/2307.16081) | TacoBot是一个以用户为中心的面向任务的数字助手，通过多步骤引导用户完成复杂的实际任务。它具备协作和引人入胜的对话体验，通过数据增强策略训练先进的神经模型，旨在提供高效的任务辅助。作为开源框架，TacoBot可以作为部署面向任务的对话系统的实用示例。 |
| [^17] | [\`{I}r\`{o}y\`{i}nSpeech: A multi-purpose Yor\`{u}b\'{a} Speech Corpus.](http://arxiv.org/abs/2307.16071) | 本论文介绍了IróyìnSpeech语料库，这是一个多功能的约鲁巴语语音语料库，可用于TTS和ASR任务，包含38.5小时的数据，由80名志愿者录制。 |
| [^18] | [Automatic Extraction of the Romanian Academic Word List: Data and Methods.](http://arxiv.org/abs/2307.16045) | 本文介绍了罗马尼亚学术词汇表（Ro-AWL）的自动提取方法和数据，将语料库和计算语言学方法与L2学术写作方法相结合，并根据不同学科进行了分布，Ro-AWL可供教学、研究和NLP应用免费使用。 |
| [^19] | [Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback.](http://arxiv.org/abs/2307.16039) | Okapi是一种使用强化学习从人类反馈中调优的多语言大型语言模型，它解决了目前开源语言模型只针对英语和少数流行语言进行指令调优的限制问题。 |
| [^20] | [Marrying Dialogue Systems with Data Visualization: Interactive Data Visualization Generation from Natural Language Conversations.](http://arxiv.org/abs/2307.16013) | 本研究结合了对话系统与数据可视化，通过用户和系统之间的交互来生成数据可视化。研究首先构建了一个基准数据集，然后提出了一种多重方法来实现此任务。 |
| [^21] | [RoCar: A Relationship Network-based Evaluation Method to Large Language Models.](http://arxiv.org/abs/2307.15997) | RoCar是一种利用关系网络构建任务图并生成自然语言评估任务的方法，用于评估大型语言模型的推理和记忆能力。该方法通过极大的随机性确保了评估的公平性。 |
| [^22] | [Towards Codable Text Watermarking for Large Language Models.](http://arxiv.org/abs/2307.15992) | 这项研究对于大型语言模型的可编解码文本水印技术进行了系统研究，提出了一种允许文本水印携带更多可定制化信息的方法，解决了现有水印方法编码效率低、不能满足不同应用场景需求的问题。 |
| [^23] | [A Theory for Emergence of Complex Skills in Language Models.](http://arxiv.org/abs/2307.15936) | 本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。 |
| [^24] | [GeneMask: Fast Pretraining of Gene Sequences to Enable Few-Shot Learning.](http://arxiv.org/abs/2307.15933) | GeneMask提出了一种新颖的基因序列屏蔽算法，通过选择具有最高规一化点对点互信息的跨度来优化屏蔽语言建模训练，相比于DNABert和LOGO等模型，在缺乏基因组学领域的人类可理解的语义的情况下表现更好。 |
| [^25] | [ATESA-B{\AE}RT: A Heterogeneous Ensemble Learning Model for Aspect-Based Sentiment Analysis.](http://arxiv.org/abs/2307.15920) | ATESA-B{\AE}RT是一个基于方面的情感分析的异构集成学习模型，通过将问题分为方面词提取和方面词情感分析两个子任务，并使用\textit{argmax}多类别分类算法进行分析，提高了在方面级别上的粒度，改进了当前解决方案在多方面数据上的性能问题。 |
| [^26] | [Dialogue Shaping: Empowering Agents through NPC Interaction.](http://arxiv.org/abs/2307.15833) | 本文研究了通过与NPC智能体的交互和对话，利用大型语言模型和知识图谱来加速强化学习智能体的训练过程。 |
| [^27] | [RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control.](http://arxiv.org/abs/2307.15818) | 本文研究了将互联网规模数据上训练的视觉-语言模型直接应用于机器人控制的方法，实现了泛化能力的提升和新兴的语义推理。通过在机器人轨迹数据和互联网规模的视觉-语言任务上共同微调最先进的视觉-语言模型，为单一的端到端训练模型提供了同时学习机器人观测到行为映射和利用语言和视觉-语言数据的益处的能力。 |
| [^28] | [LLM-Rec: Personalized Recommendation via Prompting Large Language Models.](http://arxiv.org/abs/2307.15780) | 本文通过引导大型语言模型进行个性化推荐的研究，提出了四种不同的引导策略，并通过实验证明了这些策略的有效性。这一发现强调了在个性化内容推荐中，采用多样的引导和输入增强技术可以提高大型语言模型的推荐性能。 |
| [^29] | [Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation.](http://arxiv.org/abs/2307.15776) | 本文提出了一种选择和增强的方法来改进文本增强的知识图谱嵌入，通过多任务框架选择相关的文本描述，并对知识图谱嵌入进行对齐或增强。 |
| [^30] | [The Hydra Effect: Emergent Self-repair in Language Model Computations.](http://arxiv.org/abs/2307.15771) | 本研究通过因果分析探究了语言模型计算的内部结构，发现了Hydra效应和晚期MLP层的平衡功能，并分析了它们在语言模型中的影响。 |
| [^31] | [CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools.](http://arxiv.org/abs/2307.15770) | 本论文介绍了一种名为ChatReport的基于LLM的系统，它通过实现可追溯的答案和解决领域专家参与低效性的问题，旨在通过自动分析企业可持续性报告，实现可持续性披露分析民主化。 |
| [^32] | [Lessons in Reproducibility: Insights from NLP Studies in Materials Science.](http://arxiv.org/abs/2307.15759) | 这两篇论文对于材料科学领域的NLP研究提供了重要的可再现性分析，其中包括了详尽的工作流程、整洁的代码库和清晰的模型评估指导，为未来的材料科学出版物树立了良好的标准。 |
| [^33] | [Resume Evaluation through Latent Dirichlet Allocation and Natural Language Processing for Effective Candidate Selection.](http://arxiv.org/abs/2307.15752) | 本文提出了一种使用LDA和自然语言处理的方法，通过提取简历中的实体并将其用于评分，从而实现有效的候选人选择。该方法在考虑所有属性的情况下达到了82%的准确率。 |
| [^34] | [Context-VQA: Towards Context-Aware and Purposeful Visual Question Answering.](http://arxiv.org/abs/2307.15745) | Context-VQA通过引入上下文信息，提供了一种全面满足人们需求的视觉问答模型，该模型的创新在于将图像与不同上下文配对，并发现不同上下文下问题类型存在差异。 |
| [^35] | [Utilizing Large Language Models for Natural Interface to Pharmacology Databases.](http://arxiv.org/abs/2307.15717) | 该论文介绍了一种利用大型语言模型的自然语言界面，旨在与药理学数据库中的结构化信息进行交互，具有广泛的应用价值。 |
| [^36] | [Improving Primary Healthcare Workflow Using Extreme Summarization of Scientific Literature Based on Generative AI.](http://arxiv.org/abs/2307.15715) | 本研究利用生成式人工智能技术对科学论文的摘要进行极端摘要化，旨在帮助初级保健专业人员减轻认知负荷，从而提高其工作效率和减少心理负担。 |
| [^37] | [A Geometric Notion of Causal Probing.](http://arxiv.org/abs/2307.15054) | 本文提出了一种几何观念的因果探测方法，通过在语言模型表示空间的子空间上进行反事实干预，优化了因果概念子空间，以实现概念控制生成。 |
| [^38] | [Gzip versus bag-of-words for text classification with KNN.](http://arxiv.org/abs/2307.15002) | Gzip与KNN相比较在文本分类中，我们发现通过简单的词袋匹配可以获得类似或更好的准确性，并且更加高效。 |
| [^39] | [Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models.](http://arxiv.org/abs/2307.14430) | 本论文提出了一个数据驱动的技能框架，用于理解和训练语言模型。通过研究人类获得技能的有序性，我们证明了语言模型学习技能时也有一定的顺序，并且这种顺序可以改善对语言模型的理解和数据高效训练。 |
| [^40] | [XDLM: Cross-lingual Diffusion Language Model for Machine Translation.](http://arxiv.org/abs/2307.13560) | 本文介绍了XDLM，一种用于机器翻译的跨语言扩散语言模型。通过预训练和微调阶段，我们成功地提高了在不同语言之间的翻译性能，超过了传统扩散模型和Transformer模型。 |
| [^41] | [Applying QNLP to sentiment analysis in finance.](http://arxiv.org/abs/2307.11788) | 本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。 |
| [^42] | [L-Eval: Instituting Standardized Evaluation for Long Context Language Models.](http://arxiv.org/abs/2307.11088) | 该论文提出了L-Eval，旨在为长文本语言模型引入标准化评估。通过开发一个包含411个长文档和2000多个人工标注的查询-回复对的数据集，研究探讨了扩展上下文对于处理长输入的实质性收益和改进程度。 |
| [^43] | [ChatGPT is Good but Bing Chat is Better for Vietnamese Students.](http://arxiv.org/abs/2307.08272) | 本研究比较了ChatGPT和Bing Chat在满足越南学生需求方面的效果，发现Bing Chat在除文学外的多个学科表现优于ChatGPT。Bing Chat采用更先进的GPT-4技术，能够提高文本的理解、推理和生成创造性、信息丰富的内容。 |
| [^44] | [Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations.](http://arxiv.org/abs/2307.06576) | 本文介绍了一种名为GLORY的模型，通过全局图与本地表示相结合，增强了个性化推荐系统。该模型通过构建全局感知历史新闻编码器来融合历史新闻表示，并考虑了用户隐藏的动机和行为。 |
| [^45] | [Interpreting deep embeddings for disease progression clustering.](http://arxiv.org/abs/2307.06060) | 本文提出了一种在疾病进展聚类中解读深度嵌入的新方法，并通过评估2型糖尿病参与者数据集展示了对疾病进展模式的临床意义性见解。 |
| [^46] | [Measuring Lexical Diversity in Texts: The Twofold Length Problem.](http://arxiv.org/abs/2307.04626) | 这篇论文关注了文本长度对词汇多样性估计的影响，并提出了解决该问题的一种方法。然而，现有的指数虽然能解决长度依赖问题，却未能解决对文本缩减长度参数的敏感性问题。最后，论文给出了优化词汇多样性分析的建议。 |
| [^47] | [Lost in the Middle: How Language Models Use Long Contexts.](http://arxiv.org/abs/2307.03172) | 本研究分析了语言模型在多文档问答和键值检索任务中的表现，发现当相关信息位于输入文本的开头或结尾时性能最佳，而当模型需要在长文本的中间访问相关信息时性能显著下降。此外，即使对于专门处理长文本的模型，输入文本越长性能也会大幅降低。我们的研究为理解语言模型如何使用输入文本的上下文提供了新的认识，并且为未来的长文本模型提供了新的评估方案。 |
| [^48] | [What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?.](http://arxiv.org/abs/2307.02469) | 本论文对训练GPT4风格的语言模型进行了系统综合研究，定量和定性分析了网络结构、训练数据和训练策略等设计选择对模型性能的影响，并提供了相关基准测试。 |
| [^49] | [Hexatagging: Projective Dependency Parsing as Tagging.](http://arxiv.org/abs/2306.05477) | 六边形标注器是一种新颖的依存分析器，可以在训练时实现完全并行化，具有线性时间复杂度和空间复杂度。使用预训练语言模型的特征进行预测。在 Penn Treebank 测试集上取得了最先进的性能。 |
| [^50] | [Take the Hint: Improving Arabic Diacritization with Partially-Diacritized Text.](http://arxiv.org/abs/2306.03557) | 本文提出了一个名为2SDiac的多源模型，可以在输入中使用可选音标来确定所有预测的输出，然后通过引入Guided Learning的训练策略，利用随机掩蔽和给定的输入音标提升标记的正确性。实验表明，该方法在非标记文本上表现良好，并实现了最先进的结果。 |
| [^51] | [Syntax-aware Hybrid prompt model for Few-shot multi-modal sentiment analysis.](http://arxiv.org/abs/2306.01312) | 本文提出了一种语法感知的混合提示模型，用于多模态少样本情感分析，通过融合手工提示和可学习提示，利用注意机制优化提示编码器，显著提高了分析性能。 |
| [^52] | [Column Type Annotation using ChatGPT.](http://arxiv.org/abs/2306.00745) | 本论文介绍了一种使用ChatGPT进行列类型注释的方法，并比较了不同的提示设计策略。实验结果表明，使用说明作为提示的ChatGPT在列类型注释方面取得了良好的性能，并能够根据任务定义进行灵活的注释。 |
| [^53] | [Forgotten Knowledge: Examining the Citational Amnesia in NLP.](http://arxiv.org/abs/2305.18554) | 本文系统地和实证地考察了自然语言处理(NLP)领域内的引文模式，证明了大约62%的引用论文属于出版前五年，只有约17%的论文超过十年。目前，NLP论文的引用年龄趋于历史最低水平，这个趋势与此前相反。 |
| [^54] | [A Survey on ChatGPT: AI-Generated Contents, Challenges, and Solutions.](http://arxiv.org/abs/2305.18339) | 本论文探讨了AI生成内容的工作原理、安全与隐私威胁、现状和未来挑战，并提供了针对这些问题的最新解决方案。 |
| [^55] | [Language Models are Bounded Pragmatic Speakers.](http://arxiv.org/abs/2305.17760) | 本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。经过人类反馈的强化学习微调的大型语言模型具有概念上类似于 快与慢思考模型的思维模型，而这种思维模型被归因于人类。此研究凸显了采用认知概率建模方法对语言模型的理解、评估和推进的价值。 |
| [^56] | [Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond.](http://arxiv.org/abs/2305.15299) | 这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。 |
| [^57] | [Deep Transfer Learning for Automatic Speech Recognition: Towards Better Generalization.](http://arxiv.org/abs/2304.14535) | 本文Survey了基于DTL的ASR框架，并介绍了如何使用实际数据集进行深度迁移学习以达到更好的泛化性能。 |
| [^58] | [Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding.](http://arxiv.org/abs/2304.05368) | 本研究全面评估了大型语言模型在临床语言理解任务上的表现，并引入自问自答提示策略来提高LLMs在医疗保健相关任务中的效果。 |
| [^59] | [ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model.](http://arxiv.org/abs/2304.03086) | 本文讨论了利用LLMs在牙科临床领域实现自动化和跨模态诊断的可能性，介绍了利用跨模态编码器进行高级自然语言推理的多模态LLM AI系统，展示了其在牙科临床中的巨大潜力。 |
| [^60] | [SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models.](http://arxiv.org/abs/2303.10464) | 本文提出了SPDF算法来实现大规模语言模型的高效训练。通过非结构化权重稀疏性来进行预训练，可以降低计算成本，而密集微调则可以保证高性能的表现。 |
| [^61] | [A Hybrid Architecture for Out of Domain Intent Detection and Intent Discovery.](http://arxiv.org/abs/2303.04134) | 本研究提出了一种混合架构来解决任务导向型对话系统中领域外意图检测和意图发现的问题。通过使用变分自编码器和无监督聚类方法，可以准确识别和区分已知和未知的意图，并发现潜藏在领域外输入中的不同未知意图。 |
| [^62] | [Competence-Based Analysis of Language Models.](http://arxiv.org/abs/2303.00333) | 该论文提出了一个基于能力的语言模型分析框架CALM，通过有针对性的干预来破坏语言模型的内部表示，评估其在执行任务时对不同表示的使用。研究表明，语言模型对关系属性的利用存在一定的不一致性。 |
| [^63] | [MEAformer: Multi-modal Entity Alignment Transformer for Meta Modality Hybrid.](http://arxiv.org/abs/2212.14454) | 该论文提出了一种适用于元模态混合的多模式实体对齐变压器方法，通过动态预测模态之间的相互关联系数以进行实体级特征聚合，进一步提出了一种模态感知的硬实体重播策略，用于解决模糊实体细节的问题。该模型在多个训练场景中实现了SOTA性能并有效提高了MMEA的鲁棒性。 |
| [^64] | [Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog.](http://arxiv.org/abs/2212.10008) | 本论文提出了一种通过合成开放领域对话来增强任务机器人的参与度的框架，并介绍了一种统一模型PivotBot，该模型能够无缝切换任务导向对话和开放领域对话，在处理融合任务方面具有优越能力。 |
| [^65] | [Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems.](http://arxiv.org/abs/2212.09180) | 本文提出了一种可靠的维度化评估人机聊天的新方法，并评估了一组最先进的开放领域聊天机器人，为未来聊天导向对话系统的发展提供了基准。 |
| [^66] | [Sources of Noise in Dialogue and How to Deal with Them.](http://arxiv.org/abs/2212.02745) | 本文构建了对话系统噪音分类体系，并研究了不同模型在不同噪音下的行为。结果显示模型对标签错误鲁棒性较高，但在对话特定噪音下性能下降。在此基础上，设计了一种专门用于会话环境的数据清洗算法，并进行了针对性的对话去噪概念验证。 |
| [^67] | [X$^2$-VLM: All-In-One Pre-trained Model For Vision-Language Tasks.](http://arxiv.org/abs/2211.12402) | X$^2$-VLM是一个全能的视觉-语言任务预训练模型，利用统一的框架实现了多粒度的视觉-语言对齐和定位，并在一个模型中统一了图像-文本和视频-文本预训练。实验结果显示，X$^2$-VLM在各种任务上表现最好，并且在性能和模型规模之间取得了良好的平衡。 |
| [^68] | [Isotropic Representation Can Improve Dense Retrieval.](http://arxiv.org/abs/2209.00218) | 本研究发现BERT-based DR遵循非均匀分布，为了解决这个问题，我们引入了正则化流和白化的后处理方法，并开发了单词级方法来应用这些后处理方法，实验证明这些方法能够有效地增强表示的同性质。 |
| [^69] | [Boosting Cross-Domain Speech Recognition with Self-Supervision.](http://arxiv.org/abs/2206.09783) | 本研究提出了一个系统的无监督领域自适应框架，通过使用自监督和伪标签方法来提升跨领域语音识别的性能。 |
| [^70] | [Probing for the Usage of Grammatical Number.](http://arxiv.org/abs/2204.08831) | 本文介绍了一种基于使用的探测设置，通过干预模型的表示来去除属性，从而发现模型实际使用的编码。以BERT如何编码语法数为例研究，结果显示BERT依赖于语法数的线性编码来产生正确的行为输出，并对名词和动词的语法数使用了不同的编码。 |
| [^71] | [Does Transliteration Help Multilingual Language Modeling?.](http://arxiv.org/abs/2201.12501) | 本文探究了把使用不同书写系统的相近语言音译成同一种书写系统，对于多语言语言模型的提升的影响，发现音译可以提高低资源语言的表现，而不会对资源相对较高的语言产生负面影响。 |
| [^72] | [Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings.](http://arxiv.org/abs/2201.05575) | 本文提出了一种新的知识图嵌入方法kNN-KGE，它通过预训练语言模型和最近邻的线性插值，允许罕见或新出现的实体被明确地记忆，而不是隐藏在模型参数中。实验结果显示，该方法能够改善链接预测结果并在低资源环境中表现出更好的性能。 |
| [^73] | [Tackling Query-Focused Summarization as A Knowledge-Intensive Task: A Pilot Study.](http://arxiv.org/abs/2112.07536) | 本研究将查询聚焦摘要生成任务作为一项知识密集型任务进行处理，并提出了一个新的数据集(KI-QFS)。实验结果表明，在无法直接访问相关文档的情况下，QFS模型在KI-QFS上的表现较差。 |

# 详细

[^1]: 利用预测提示和大型语言模型生成多项选择题的干扰项

    Distractor generation for multiple-choice questions with predictive prompting and large language models. (arXiv:2307.16338v1 [cs.CL])

    [http://arxiv.org/abs/2307.16338](http://arxiv.org/abs/2307.16338)

    本研究利用预测提示和大型语言模型，通过引导它们生成干扰项来填补教育背景下多项选择题中生成干扰项的性能差距。实验证明，这种方法在质量上超过了现有模型，并获得了高质量的干扰项。

    

    大型语言模型（LLM）如ChatGPT在各种任务中表现出色，并且吸引了研究人员和实践者的广泛关注。然而，在教育背景下，我们仍然观察到使用LLM为多项选择题（MCQ）生成干扰项（即可信但不正确的答案）存在性能差距。在本研究中，我们提出了一种策略，通过使用从题库中自动检索的问题项作为上下文示例，引导LLM（如ChatGPT）生成相关的干扰项。我们使用现有测试集的定量评估和人类专家（教师）的质量注释来评估我们基于LLM的解决方案。我们发现，平均而言，向教师展示的53％生成的干扰项被评为高质量，即适合立即使用，优于最先进的模型。我们还展示了我们方法的收益。

    Large Language Models (LLMs) such as ChatGPT have demonstrated remarkable performance across various tasks and have garnered significant attention from both researchers and practitioners. However, in an educational context, we still observe a performance gap in generating distractors -- i.e., plausible yet incorrect answers -- with LLMs for multiple-choice questions (MCQs). In this study, we propose a strategy for guiding LLMs such as ChatGPT, in generating relevant distractors by prompting them with question items automatically retrieved from a question bank as well-chosen in-context examples. We evaluate our LLM-based solutions using a quantitative assessment on an existing test set, as well as through quality annotations by human experts, i.e., teachers. We found that on average 53% of the generated distractors presented to the teachers were rated as high-quality, i.e., suitable for immediate use as is, outperforming the state-of-the-art model. We also show the gains of our approach
    
[^2]: 利用自监督语音表示进行发音错误检测

    Mispronunciation detection using self-supervised speech representations. (arXiv:2307.16324v1 [cs.CL])

    [http://arxiv.org/abs/2307.16324](http://arxiv.org/abs/2307.16324)

    本文研究了在第二语言学习者的发音错误检测任务中使用自监督学习模型的方法。研究发现，使用为目标任务训练的下游模型能够得到最佳性能，而大多数上游模型在此任务中表现相似。

    

    近年来，自监督学习模型在各种语音处理任务中取得了有希望的结果，特别是在数据稀缺的情况下。本文研究了在第二语言学习者的发音错误检测任务中使用自监督学习模型的方法。我们比较了两种下游方法：1）使用本地英文数据训练模型进行音素识别（PR）；2）使用非本地英文数据直接训练模型进行目标任务。我们比较了这两种方法在不同的自监督学习表示以及从传统的基于DNN的语音识别模型中提取的表示下的表现。我们在L2Arctic和EpaDB两个标注了音素级发音标签的非本地语音数据集上评估了这些模型。总的来说，我们发现使用为目标任务训练的下游模型能够得到最佳性能，而大多数上游模型在此任务中表现相似。

    In recent years, self-supervised learning (SSL) models have produced promising results in a variety of speech-processing tasks, especially in contexts of data scarcity. In this paper, we study the use of SSL models for the task of mispronunciation detection for second language learners. We compare two downstream approaches: 1) training the model for phone recognition (PR) using native English data, and 2) training a model directly for the target task using non-native English data. We compare the performance of these two approaches for various SSL representations as well as a representation extracted from a traditional DNN-based speech recognition model. We evaluate the models on L2Arctic and EpaDB, two datasets of non-native speech annotated with pronunciation labels at the phone level. Overall, we find that using a downstream model trained for the target task gives the best performance and that most upstream models perform similarly for the task.
    
[^3]: 分层多标签文本分类的最新进展：一项调查

    Recent Advances in Hierarchical Multi-label Text Classification: A Survey. (arXiv:2307.16265v1 [cs.CL])

    [http://arxiv.org/abs/2307.16265](http://arxiv.org/abs/2307.16265)

    这篇论文调查了分层多标签文本分类的最新进展，包括数据集、方法、评估指标、学习策略和挑战，同时提供了未来研究方向。

    

    分层多标签文本分类旨在将输入的文本分为多个标签，其中标签之间具有结构和层次关系。它是许多现实世界应用中的重要任务，例如科学文献归档。本文调查了分层多标签文本分类的最新进展，包括开源数据集、主要方法、评估指标、学习策略和当前的挑战。还列举了几个未来研究方向，供研究者进一步改进这个领域。

    Hierarchical multi-label text classification aims to classify the input text into multiple labels, among which the labels are structured and hierarchical. It is a vital task in many real world applications, e.g. scientific literature archiving. In this paper, we survey the recent progress of hierarchical multi-label text classification, including the open sourced data sets, the main methods, evaluation metrics, learning strategies and the current challenges. A few future research directions are also listed for community to further improve this field.
    
[^4]: 大型语言模型的私密水印

    A Private Watermark for Large Language Models. (arXiv:2307.16230v1 [cs.CL])

    [http://arxiv.org/abs/2307.16230](http://arxiv.org/abs/2307.16230)

    这项工作提出了一种私密水印算法，通过使用两个不同的神经网络进行水印生成和检测，并共享部分参数，实现了高效且高准确性的检测，同时对生成和检测速度影响最小。

    

    最近，针对大型语言模型（LLMs）的文本水印算法已经减轻了LLMs生成的文本可能带来的伪新闻和版权问题。然而，当前文本水印算法的水印检测需要生成过程的密钥，使其容易受到违规和伪造的影响。在这项工作中，我们提出了第一个私密水印算法，通过在水印生成和检测阶段使用两个不同的神经网络而不是使用相同的密钥来扩展当前的文本水印算法。同时，水印生成和检测网络的部分参数是共享的，这使得检测网络能够以高效的方式实现高准确性。实验证明，由于两个网络的参数规模较小，我们的算法确保了高的检测准确性，并对生成和检测速度的影响最小。

    Recently, text watermarking algorithms for large language models (LLMs) have been mitigating the potential harms of text generated by the LLMs, including fake news and copyright issues. However, the watermark detection of current text algorithms requires the key from the generation process, making them susceptible to breaches and counterfeiting. In this work, we propose the first private watermarking algorithm, which extends the current text watermarking algorithms by using two different neural networks respectively for watermark generation and detection, rather than using the same key at both stages. Meanwhile, part of the parameters of the watermark generation and detection networks are shared, which makes the detection network achieve a high accuracy very efficiently. Experiments show that our algorithm ensures high detection accuracy with minimal impact on generation and detection speed, due to the small parameter size of both networks. Additionally, our subsequent analysis demonst
    
[^5]: 优化神经网络训练以进行历史希伯来文OCR错误校正

    Optimizing the Neural Network Training for OCR Error Correction of Historical Hebrew Texts. (arXiv:2307.16220v1 [cs.CL])

    [http://arxiv.org/abs/2307.16220](http://arxiv.org/abs/2307.16220)

    这篇论文提出了一种使用较少的手动创建数据训练的轻量级神经网络方法，用于希伯来文OCR后校正。研究目标是开发自动生成训练数据的方法，改善OCR后校正结果，并研究最适用于历史文档的OCR后校正的数据集类型。

    

    在过去几十年中，大量纸质文档如书籍和报纸已经使用光学字符识别技术进行数字化。这种技术在处理历史文档时容易出现错误。为了纠正OCR错误，提出了基于自然语言分析和神经网络等机器学习技术的后处理算法。神经网络的缺点是需要大量手动标记的数据进行训练，而这种数据通常不易获取。本文提出了一种创新的方法，使用较少的手动创建数据来训练轻量级的希伯来文OCR后校正神经网络。主要研究目标是开发一种自动生成语言和任务特定训练数据的方法，以改善神经网络在OCR后校正中的结果，并研究哪种类型的数据集对于历史文档的OCR后校正最有效。为此，进行了一系列实验。

    Over the past few decades, large archives of paper-based documents such as books and newspapers have been digitized using Optical Character Recognition. This technology is error-prone, especially for historical documents. To correct OCR errors, post-processing algorithms have been proposed based on natural language analysis and machine learning techniques such as neural networks. Neural network's disadvantage is the vast amount of manually labeled data required for training, which is often unavailable. This paper proposes an innovative method for training a light-weight neural network for Hebrew OCR post-correction using significantly less manually created data. The main research goal is to develop a method for automatically generating language and task-specific training data to improve the neural network results for OCR post-correction, and to investigate which type of dataset is the most effective for OCR post-correction of historical documents. To this end, a series of experiments u
    
[^6]: 数字人文和信息科学中使用深度神经网络进行文本分析

    Text Analysis Using Deep Neural Networks in Digital Humanities and Information Science. (arXiv:2307.16217v1 [cs.LG])

    [http://arxiv.org/abs/2307.16217](http://arxiv.org/abs/2307.16217)

    本论文研究了在数字人文研究中使用深度神经网络进行文本分析的挑战，包括训练数据的可用性和领域适应的需求。

    

    结合计算技术和人文学科是一项持续进行的努力，旨在使文本、图像、音频、视频和其他艺术品等资源在数字化时代易于获得、可搜索和可分析。在近年来，深度神经网络（DNN）在自动文本分析和自然语言处理（NLP）领域占据主导地位，有时呈现出超人类的表现。DNN是解决数字人文研究中与NLP相关的许多任务（例如拼写检查、语言检测、实体提取、作者检测、问答等）的最先进的机器学习算法。这些有监督算法从大量的“正确”和“错误”示例中学习模式，并将其应用于新的示例。然而，在数字人文研究中使用DNN分析文本资源存在两个主要挑战：（不）可用的训练数据和领域适应的需求。本文通过分析多个使用案例来探讨这些挑战。

    Combining computational technologies and humanities is an ongoing effort aimed at making resources such as texts, images, audio, video, and other artifacts digitally available, searchable, and analyzable. In recent years, deep neural networks (DNN) dominate the field of automatic text analysis and natural language processing (NLP), in some cases presenting a super-human performance. DNNs are the state-of-the-art machine learning algorithms solving many NLP tasks that are relevant for Digital Humanities (DH) research, such as spell checking, language detection, entity extraction, author detection, question answering, and other tasks. These supervised algorithms learn patterns from a large number of "right" and "wrong" examples and apply them to new examples. However, using DNNs for analyzing the text resources in DH research presents two main challenges: (un)availability of training data and a need for domain adaptation. This paper explores these challenges by analyzing multiple use-cas
    
[^7]: 用于半结构异构家族谱知识图的深度神经网络问答

    Question Answering with Deep Neural Networks for Semi-Structured Heterogeneous Genealogical Knowledge Graphs. (arXiv:2307.16214v1 [cs.CL])

    [http://arxiv.org/abs/2307.16214](http://arxiv.org/abs/2307.16214)

    本研究提出一种用于家族谱问答的深度神经网络方法，该方法将家族谱数据表示为知识图并与非结构化文本结合，使用Transformer模型进行训练。这种方法解决了家族谱领域中模型无法处理图结构和缺乏训练数据集的问题。

    

    随着用户生成的家族谱越来越流行，新的家族谱信息系统得到了开发。最先进的自然语言问答算法使用基于自注意力网络的深度神经网络（DNN）架构。然而，其中一些模型使用基于序列的输入，不适合处理基于图的结构，而基于图的DNN模型则依赖于在家族谱领域中不存在的高度全面的知识图。此外，这些有监督的DNN模型需要在家族谱领域中缺乏的训练数据集。本研究提出了一种用于家族谱问答的端到端方法：1）将家族谱数据表示为知识图，2）将其转换为文本，3）与非结构化文本结合，4）训练基于Transformer的问答模型。为了评估需要专门方法的必要性，对比了微调模式下的模型与使用我们提出的方法的模型。

    With the rising popularity of user-generated genealogical family trees, new genealogical information systems have been developed. State-of-the-art natural question answering algorithms use deep neural network (DNN) architecture based on self-attention networks. However, some of these models use sequence-based inputs and are not suitable to work with graph-based structure, while graph-based DNN models rely on high levels of comprehensiveness of knowledge graphs that is nonexistent in the genealogical domain. Moreover, these supervised DNN models require training datasets that are absent in the genealogical domain. This study proposes an end-to-end approach for question answering using genealogical family trees by: 1) representing genealogical data as knowledge graphs, 2) converting them to texts, 3) combining them with unstructured texts, and 4) training a trans-former-based question answering model. To evaluate the need for a dedicated approach, a comparison between the fine-tuned mode
    
[^8]: 朝着历史希伯来文本OCR错误校正的特定时期优化神经网络

    Toward a Period-Specific Optimized Neural Network for OCR Error Correction of Historical Hebrew Texts. (arXiv:2307.16213v1 [cs.CL])

    [http://arxiv.org/abs/2307.16213](http://arxiv.org/abs/2307.16213)

    本研究针对历史希伯来文本OCR错误校正的问题，提出了一种特定时期优化的神经网络模型。然而，由于希伯来语是形态丰富语言，神经网络所需的训练数据集不够充足，且最佳的网络结构和超参数值尚不明确。另外，不同流派和时期的语言变化可能会影响OCR后校正模型的准确性。

    

    在过去几十年中，使用光学字符识别（OCR）技术对大量纸质历史文档（如书籍和报纸）进行了数字化存档。不幸的是，这种广泛使用的技术在处理写于数百年前的OCR文档时容易出错。神经网络在解决各种文本处理任务，包括OCR后校正方面取得了巨大成功。然而，对于希伯来语这样的形态丰富语言，使用神经网络处理历史语料库的主要缺点是它们需要大量充足的训练数据集来学习。此外，由于希伯来语的独特特点，神经网络在OCR错误校正方面的最佳结构和超参数值（预定义参数）尚不清楚。此外，语言在不同的流派和时期也会发生变化。这些变化可能会影响OCR后校正神经网络模型的准确性。

    Over the past few decades, large archives of paper-based historical documents, such as books and newspapers, have been digitized using the Optical Character Recognition (OCR) technology. Unfortunately, this broadly used technology is error-prone, especially when an OCRed document was written hundreds of years ago. Neural networks have shown great success in solving various text processing tasks, including OCR post-correction. The main disadvantage of using neural networks for historical corpora is the lack of sufficiently large training datasets they require to learn from, especially for morphologically-rich languages like Hebrew. Moreover, it is not clear what are the optimal structure and values of hyperparameters (predefined parameters) of neural networks for OCR error correction in Hebrew due to its unique features. Furthermore, languages change across genres and periods. These changes may affect the accuracy of OCR post-correction neural network models. To overcome these challenge
    
[^9]: 在异构家谱知识图谱上使用深度神经网络进行数字聚合问答的GLOBE方法

    Around the GLOBE: Numerical Aggregation Question-Answering on Heterogeneous Genealogical Knowledge Graphs with Deep Neural Networks. (arXiv:2307.16208v1 [cs.CL])

    [http://arxiv.org/abs/2307.16208](http://arxiv.org/abs/2307.16208)

    本文介绍了一种在异构家谱知识图谱上进行数字聚合问答的方法，在基因谱领域提出了自然语言问题并获得准确答案的能力还未被充分研究。

    

    文章介绍了一种在异构家谱知识图谱上进行数字聚合问答的方法，该方法利用深度神经网络实现自然语言问题与精确答案之间的转换。目前，在基因谱领域，提出自然语言问题并获得准确答案的能力还未被充分研究，而研究者在人文和社会科学等领域可以从这种能力中受益匪浅。

    One of the key AI tools for textual corpora exploration is natural language question-answering (QA). Unlike keyword-based search engines, QA algorithms receive and process natural language questions and produce precise answers to these questions, rather than long lists of documents that need to be manually scanned by the users. State-of-the-art QA algorithms based on DNNs were successfully employed in various domains. However, QA in the genealogical domain is still underexplored, while researchers in this field (and other fields in humanities and social sciences) can highly benefit from the ability to ask questions in natural language, receive concrete answers and gain insights hidden within large corpora. While some research has been recently conducted for factual QA in the genealogical domain, to the best of our knowledge, there is no previous research on the more challenging task of numerical aggregation QA (i.e., answering questions combining aggregation functions, e.g., count, ave
    
[^10]: 一个知识增强的两阶段生成框架用于医学对话信息提取

    A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue Information Extraction. (arXiv:2307.16200v1 [cs.CL])

    [http://arxiv.org/abs/2307.16200](http://arxiv.org/abs/2307.16200)

    本论文提出了一个知识增强的两阶段生成框架（KTGF）用于医学对话信息提取。通过两个阶段的生成，分别生成医学对话中的术语和每个术语的状态，从而更好地建模术语之间的关系。

    

    本文关注医学对话中的术语-状态对提取（MD-TSPE），这在诊断对话系统和电子医疗记录（EMR）的自动抄写中是必不可少的。在过去的几年中，MD-TSPE的研究引起了越来越多的关注，特别是在生成方法取得显著进展之后。然而，这些生成方法在一阶段输出整个由术语-状态对组成的序列时忽略了集成先前知识的需求，这需要更深入的理解来建模术语之间的关系和推断每个术语的状态。本文提出了一个知识增强的两阶段生成框架（KTGF）来解决上述挑战。通过使用任务特定的提示，我们采用单一模型以统一的生成形式完成MD-TSPE的两个阶段：首先生成所有的术语，然后生成每个生成的术语的状态。通过这种方式，可以更有效地学习术语之间的关系。

    This paper focuses on term-status pair extraction from medical dialogues (MD-TSPE), which is essential in diagnosis dialogue systems and the automatic scribe of electronic medical records (EMRs). In the past few years, works on MD-TSPE have attracted increasing research attention, especially after the remarkable progress made by generative methods. However, these generative methods output a whole sequence consisting of term-status pairs in one stage and ignore integrating prior knowledge, which demands a deeper understanding to model the relationship between terms and infer the status of each term. This paper presents a knowledge-enhanced two-stage generative framework (KTGF) to address the above challenges. Using task-specific prompts, we employ a single model to complete the MD-TSPE through two phases in a unified generative form: we generate all terms the first and then generate the status of each generated term. In this way, the relationship between terms can be learned more effect
    
[^11]: 改进上海话的TTS：通过词分割解决声调连读问题

    Improving TTS for Shanghainese: Addressing Tone Sandhi via Word Segmentation. (arXiv:2307.16199v1 [cs.CL])

    [http://arxiv.org/abs/2307.16199](http://arxiv.org/abs/2307.16199)

    本文通过词分割方法改进了上海话TTS模型中声调连读的质量，对于将上海话的形式化语言学解释引入计算项目具有重要意义。

    

    声调是上海话的重要组成部分，它是一种主要在上海城市使用的吴语方言。然而，最近关于上海话TTS（文本到语音）的研究，如苹果的VoiceOver，在声调连读（尤其是左侧优势连读）方面表现不佳。本文通过在文本预处理过程中进行词分割，展示了提高TTS模型中声调连读质量的方法。同一个词内的音节被用特殊符号标注，作为LD领域语调信息的代理。与通常主要用于静态停顿的语调注释方法不同，本文证明了语调注释也可以应用于动态语调现象。我期待这个项目成为将上海话的形式化语言学解释引入计算项目的起点。

    Tone is a crucial component of the prosody of Shanghainese, a Wu Chinese variety spoken primarily in urban Shanghai. Tone sandhi, which applies to all multi-syllabic words in Shanghainese, then, is key to natural-sounding speech. Unfortunately, recent work on Shanghainese TTS (text-to-speech) such as Apple's VoiceOver has shown poor performance with tone sandhi, especially LD (left-dominant sandhi). Here I show that word segmentation during text preprocessing can improve the quality of tone sandhi production in TTS models. Syllables within the same word are annotated with a special symbol, which serves as a proxy for prosodic information of the domain of LD. Contrary to the common practice of using prosodic annotation mainly for static pauses, this paper demonstrates that prosodic annotation can also be applied to dynamic tonal phenomena. I anticipate this project to be a starting point for bringing formal linguistic accounts of Shanghainese into computational projects. Too long have w
    
[^12]: LLM是否具有个性？MBTI人格测试在评估大型语言模型中的应用

    Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models. (arXiv:2307.16180v1 [cs.CL])

    [http://arxiv.org/abs/2307.16180](http://arxiv.org/abs/2307.16180)

    本文探讨了使用MBTI人格测试作为评估大型语言模型（LLMs）的可行性，通过实验研究了不同LLM的个性类型、通过提示工程改变个性类型的可能性以及训练数据集对模型个性的影响。

    

    大型语言模型(LLM)领域取得了显著进展，其知识存储能力接近人类。此外，通过使用提示学习和强化学习等先进技术，可以解决LLM的伦理问题和妄想问题，使其更加接近人类价值观。这自然引发了一个问题，具有类似人类能力的LLM是否具有类似人类的个性？本文旨在探讨使用Myers-Briggs类型指标(MBTI)，一种广泛使用的人格评估工具，作为LLM评估指标的可行性。具体而言，将进行大量实验来研究：1）不同LLM的个性类型，2）通过提示工程改变个性类型的可能性，3）训练数据集如何影响模型的个性。尽管MBTI不是严格的评估工具，但仍然可以用来评估LLM的个性特征。

    The field of large language models (LLMs) has made significant progress, and their knowledge storage capacity is approaching that of human beings. Furthermore, advanced techniques, such as prompt learning and reinforcement learning, are being employed to address ethical concerns and hallucination problems associated with LLMs, bringing them closer to aligning with human values. This situation naturally raises the question of whether LLMs with human-like abilities possess a human-like personality? In this paper, we aim to investigate the feasibility of using the Myers-Briggs Type Indicator (MBTI), a widespread human personality assessment tool, as an evaluation metric for LLMs. Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality. Although the MBTI is not a rigorous assessment, it can stil
    
[^13]: 用户可控的大型语言模型中的知识融合：平衡创造力和幻觉

    User-Controlled Knowledge Fusion in Large Language Models: Balancing Creativity and Hallucination. (arXiv:2307.16139v1 [cs.CL])

    [http://arxiv.org/abs/2307.16139](http://arxiv.org/abs/2307.16139)

    本文提出了一种用户可控的机制，用于调节大型语言模型在生成回应时创造力和对外部知识的忠诚度之间的平衡。这种机制通过在训练过程中引入数值标记，并使用自动化过程计算标记的程度，从而实现用户对模型的依赖程度的控制。

    

    在现代对话系统中，使用大型语言模型（LLMs）由于其生成多样、相关且有创造性的回应能力而呈指数增长。尽管LLMs具有这些优点，但在创造力和对外部知识的忠诚度之间取得平衡仍然是一个关键挑战。本文提出了一种创新的用户可控机制，用于调节LLM在想象能力和与事实信息的一致性之间的平衡。我们的方法在LLM的训练的微调阶段中引入一个表示生成回应中对参考知识忠诚度程度的数值标记。这个程度是通过自动化过程计算的，该过程使用ROUGE分数衡量词汇重叠，使用Sentence-BERT嵌入衡量语义相似性，以及LLM的自我评估分数。在模型推理过程中，用户可以操作这个数值标记，从而控制LLM对外部知识的依赖程度。

    In modern dialogue systems, the use of Large Language Models (LLMs) has grown exponentially due to their capacity to generate diverse, relevant, and creative responses. Despite their strengths, striking a balance between the LLMs' creativity and their faithfulness to external knowledge remains a key challenge. This paper presents an innovative user-controllable mechanism that modulates the balance between an LLM's imaginative capabilities and its adherence to factual information. Our approach incorporates a numerical tag during the fine-tuning phase of the LLM's training, representing the degree of faithfulness to the reference knowledge in the generated responses. This degree is computed through an automated process that measures lexical overlap using ROUGE scores, semantic similarity using Sentence-BERT embeddings, and an LLM's self-evaluation score. During model inference, users can manipulate this numerical tag, thus controlling the degree of the LLM's reliance on external knowledg
    
[^14]: SEED-Bench: 用生成式理解对多模态LLMs进行基准测试

    SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension. (arXiv:2307.16125v1 [cs.CL])

    [http://arxiv.org/abs/2307.16125](http://arxiv.org/abs/2307.16125)

    这项工作引入了一个名为SEED-Bench的基准测试，用于评估生成式多模态大语言模型的理解能力。SEED-Bench包括19K个多项选择题，涵盖了图像和视频模态等12个评估维度。通过人工注释提供的正确选项，能够客观高效地评估模型的性能。

    

    近期基于强大的大语言模型（LLMs），生成式多模态大语言模型（MLLMs）作为一个关键的研究领域受到了广泛关注，展示出了在理解和生成方面的卓越能力。在这项工作中，我们通过引入一个名为SEED-Bench的基准测试，解决了对MLLMs中生成式理解的评估问题，这是对生成式模型全面评估的一个初步步骤。SEED-Bench包括19K个准确的人工注释的多项选择题（比现有基准测试大6倍），涵盖了包括图像和视频模态在内的12个评估维度的理解能力。我们开发了一个先进的流程来生成针对特定评估维度的多项选择题，整合了自动筛选和手动验证过程。通过人工注释获得地面实况选项的多项选择题能够客观高效地评估模型的性能，

    Based on powerful Large Language Models (LLMs), recent generative Multimodal Large Language Models (MLLMs) have gained prominence as a pivotal research area, exhibiting remarkable capability for both comprehension and generation. In this work, we address the evaluation of generative comprehension in MLLMs as a preliminary step towards a comprehensive assessment of generative models, by introducing a benchmark named SEED-Bench. SEED-Bench consists of 19K multiple choice questions with accurate human annotations (x 6 larger than existing benchmarks), which spans 12 evaluation dimensions including the comprehension of both the image and video modality. We develop an advanced pipeline for generating multiple-choice questions that target specific evaluation dimensions, integrating both automatic filtering and manual verification processes. Multiple-choice questions with groundtruth options derived from human annotation enables an objective and efficient assessment of model performance, elim
    
[^15]: EnrichEvent: 使用上下文信息为新出现的事件提供丰富的社交数据

    EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction. (arXiv:2307.16082v1 [cs.CL])

    [http://arxiv.org/abs/2307.16082](http://arxiv.org/abs/2307.16082)

    本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。

    

    社交平台已成为传播和讨论真实事件信息的关键平台，为及早发现有新闻价值的事件提供了良好的机会。然而，现有的大多数事件检测方法仅利用关键词突发性或网络结构来检测热点事件。因此，对于事件和社交数据的复杂性而言，它们往往无法在达到趋势状态之前识别出新出现的社交事件。社交数据，例如推文，具有拼写错误、不完整性、歧义性和语言不规范性，以及意见方面的变化。此外，利用有限的上下文知识来学习事件的演变特征对于机器学习模型几乎是不可行的。为了解决这些问题，本文提出了一个利用流式社交数据的词汇、语义和上下文表示的框架。

    Social platforms have emerged as a crucial platform for disseminating and discussing information about real-life events, which offers an excellent opportunity for early detection of newsworthy events. However, most existing approaches for event detection solely exploit keyword burstiness or network structures to detect hot events. Thus, they often fail to identify emerging social events before reaching a trending state regarding the challenging nature of events and social data. Social data, e.g., tweets, is characterized by misspellings, incompleteness, ambiguity, and irregular language, as well as variation in aspects of opinions. Moreover, learning the evolving characteristics of the events utilizing limited contextual knowledge is almost infeasible for machine learning models. To address these problems, in this paper, we propose a framework that exploits the lexical, semantic, and contextual representations of streaming social data. In particular, we leverage contextual knowledge to
    
[^16]: 探索协作和引人入胜的面向任务的对话系统：Roll Up Your Sleeves

    Roll Up Your Sleeves: Working with a Collaborative and Engaging Task-Oriented Dialogue System. (arXiv:2307.16081v1 [cs.CL])

    [http://arxiv.org/abs/2307.16081](http://arxiv.org/abs/2307.16081)

    TacoBot是一个以用户为中心的面向任务的数字助手，通过多步骤引导用户完成复杂的实际任务。它具备协作和引人入胜的对话体验，通过数据增强策略训练先进的神经模型，旨在提供高效的任务辅助。作为开源框架，TacoBot可以作为部署面向任务的对话系统的实用示例。

    

    我们引入了TacoBot，一个以用户为中心的面向任务的数字助手，旨在通过多步骤引导用户完成复杂的实际任务。涵盖了广泛的烹饪和操作任务，我们的目标是提供协作和引人入胜的对话体验。TacoBot具备语言理解、对话管理和响应生成组件，支持强大的搜索引擎，确保高效的任务辅助。为了增强对话体验，我们使用LLMs探索了一系列数据增强策略，以持续训练先进的神经模型。TacoBot是我们在首届Alexa Prize TaskBot Challenge中取得第三名的成功经验的延续。我们将TacoBot作为一个开源框架提供，可作为部署面向任务的对话系统的实用示例。

    We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.
    
[^17]: IróyìnSpeech：一个多功能的约鲁巴语语音语料库

    \`{I}r\`{o}y\`{i}nSpeech: A multi-purpose Yor\`{u}b\'{a} Speech Corpus. (arXiv:2307.16071v1 [cs.CL])

    [http://arxiv.org/abs/2307.16071](http://arxiv.org/abs/2307.16071)

    本论文介绍了IróyìnSpeech语料库，这是一个多功能的约鲁巴语语音语料库，可用于TTS和ASR任务，包含38.5小时的数据，由80名志愿者录制。

    

    我们介绍了IróyìnSpeech语料库，这是一个受到希望增加高质量、免费可用的当代约鲁巴语语音的影响而创建的新数据集。我们发布了一个多用途的数据集，可用于TTS和ASR任务。我们从新闻和创意写作领域收集了文字句子，在开放授权（CC-BY-4.0）下进行筛选，并由多位发音人录制每个句子。我们将5000个发音句提供给Common Voice平台，在线众包转录。该数据集总共有38.5小时的数据，由80名志愿者录制。

    We introduce the \`{I}r\`{o}y\`{i}nSpeech corpus -- a new dataset influenced by a desire to increase the amount of high quality, freely available, contemporary Yor\`{u}b\'{a} speech. We release a multi-purpose dataset that can be used for both TTS and ASR tasks. We curated text sentences from the news and creative writing domains under an open license i.e., CC-BY-4.0 and had multiple speakers record each sentence. We provide 5000 of our utterances to the Common Voice platform to crowdsource transcriptions online. The dataset has 38.5 hours of data in total, recorded by 80 volunteers.
    
[^18]: 罗马尼亚学术词汇表的自动提取：数据与方法

    Automatic Extraction of the Romanian Academic Word List: Data and Methods. (arXiv:2307.16045v1 [cs.CL])

    [http://arxiv.org/abs/2307.16045](http://arxiv.org/abs/2307.16045)

    本文介绍了罗马尼亚学术词汇表（Ro-AWL）的自动提取方法和数据，将语料库和计算语言学方法与L2学术写作方法相结合，并根据不同学科进行了分布，Ro-AWL可供教学、研究和NLP应用免费使用。

    

    本文介绍了罗马尼亚学术词汇表（Ro-AWL）自动提取的方法和数据。学术词汇表在L2和L1教学环境中都非常有用，但对于罗马尼亚语来说，迄今为止还没有这样的资源。Ro-AWL是通过将语料库和计算语言学方法与L2学术写作方法相结合生成的。我们使用了两种类型的数据：（a）现有数据，例如基于ROMBAC语料库的罗马尼亚频率列表，和（b）自编数据，例如专家学术写作语料库EXPRES。为了构建学术词汇表，我们遵循了为英语语言建立学术词汇表的方法。Ro-AWL的特征分布（总体分布，词性分布）与先前的研究一致，将其分为四个学科数据集。Ro-AWL可供教学、研究和自然语言处理应用免费使用。

    This paper presents the methodology and data used for the automatic extraction of the Romanian Academic Word List (Ro-AWL). Academic Word Lists are useful in both L2 and L1 teaching contexts. For the Romanian language, no such resource exists so far. Ro-AWL has been generated by combining methods from corpus and computational linguistics with L2 academic writing approaches. We use two types of data: (a) existing data, such as the Romanian Frequency List based on the ROMBAC corpus, and (b) self-compiled data, such as the expert academic writing corpus EXPRES. For constructing the academic word list, we follow the methodology for building the Academic Vocabulary List for the English language. The distribution of Ro-AWL features (general distribution, POS distribution) into four disciplinary datasets is in line with previous research. Ro-AWL is freely available and can be used for teaching, research and NLP applications.
    
[^19]: Okapi: 使用强化学习从人类反馈中调优的多语言大型语言模型

    Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback. (arXiv:2307.16039v1 [cs.CL])

    [http://arxiv.org/abs/2307.16039](http://arxiv.org/abs/2307.16039)

    Okapi是一种使用强化学习从人类反馈中调优的多语言大型语言模型，它解决了目前开源语言模型只针对英语和少数流行语言进行指令调优的限制问题。

    

    开发大型语言模型的关键技术之一是指令调优，它有助于将模型的响应与人类预期对齐，实现令人印象深刻的学习能力。两种主要的指令调优方法是监督微调（SFT）和使用人类反馈的强化学习（RLHF），目前已应用于生产最佳的商业语言模型（例如ChatGPT）。为提高语言模型在研究和开发工作中的可访问性，最近还推出了各种经过指令调优的开源语言模型，例如Alpaca、Vicuna等。然而，现有的开源语言模型仅对英语和少数流行语言进行了指令调优，从而限制了它们在全球其他语言中的影响力和可访问性。最近有一些探索多语言大型语言模型指令调优的工作，但目前只使用了SFT作为指令调优的唯一方法。这已经存在了一些问题。

    A key technology for the development of large language models (LLMs) involves instruction tuning that helps align the models' responses with human expectations to realize impressive learning abilities. Two major approaches for instruction tuning characterize supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), which are currently applied to produce the best commercial LLMs (e.g., ChatGPT). To improve the accessibility of LLMs for research and development efforts, various instruction-tuned open-source LLMs have also been introduced recently, e.g., Alpaca, Vicuna, to name a few. However, existing open-source LLMs have only been instruction-tuned for English and a few popular languages, thus hindering their impacts and accessibility to many other languages in the world. Among a few very recent work to explore instruction tuning for LLMs in multiple languages, SFT has been used as the only approach to instruction-tune LLMs for multiple languages. This has lef
    
[^20]: 将对话系统与数据可视化结合：从自然语言对话中生成交互式数据可视化

    Marrying Dialogue Systems with Data Visualization: Interactive Data Visualization Generation from Natural Language Conversations. (arXiv:2307.16013v1 [cs.AI])

    [http://arxiv.org/abs/2307.16013](http://arxiv.org/abs/2307.16013)

    本研究结合了对话系统与数据可视化，通过用户和系统之间的交互来生成数据可视化。研究首先构建了一个基准数据集，然后提出了一种多重方法来实现此任务。

    

    数据可视化已经成为市场上流行的工具，因为它能有效地展示大量的数据见解。为了降低使用数据可视化的门槛，研究界已经开始研究自动数据可视化任务，如自然语言问题到可视化转换（正式称为文本到可视化）。然而，文本到可视化假设自然语言问题已经有一个良好的组织并且用一个句子来表达。然而，在现实世界中，复杂的数据可视化需要通过可视化系统和用户之间的连续交互来完成。在本文中，我们提出了一个新的任务，称为CoVis，即对话式文本到可视化，旨在通过用户和系统之间的多个交互来构建数据可视化。因为这个任务在文献中还没有被研究，所以我们首先建立了一个名为Dial-NVBench的基准数据集，包括用户的一系列查询和系统的回应的对话会话。然后，我们提出了一个多重的方法

    Data visualization (DV) has become the prevailing tool in the market due to its effectiveness into illustrating insights in vast amounts of data. To lower the barrier of using DVs, automatic DV tasks, such as natural language question (NLQ) to visualization translation (formally called text-to-vis), have been investigated in the research community. However, text-to-vis assumes the NLQ to be well-organized and expressed in a single sentence. However, in real-world settings, complex DV is needed through consecutive exchanges between the DV system and the users. In this paper, we propose a new task named CoVis, short for Conversational text-to-Visualization, aiming at constructing DVs through a series of interactions between users and the system. Since it is the task which has not been studied in the literature, we first build a benchmark dataset named Dial-NVBench, including dialogue sessions with a sequence of queries from a user and responses from the system. Then, we propose a multi-m
    
[^21]: RoCar:一种基于关系网络的大型语言模型评估方法

    RoCar: A Relationship Network-based Evaluation Method to Large Language Models. (arXiv:2307.15997v1 [cs.CL])

    [http://arxiv.org/abs/2307.15997](http://arxiv.org/abs/2307.15997)

    RoCar是一种利用关系网络构建任务图并生成自然语言评估任务的方法，用于评估大型语言模型的推理和记忆能力。该方法通过极大的随机性确保了评估的公平性。

    

    大型语言模型（LLMs）受到越来越多的关注。然而，由于其能力的复杂性，如何合理评估LLMs的能力仍然是一个需要解决的任务。我们提出了RoCar方法，利用定义的基本模式随机构建一个任务图，并基于任务图生成自然语言评估任务，分别评估LLMs的推理和记忆能力。由于任务构建过程的极大随机性，可以确保被测试的LLMs中没有一个直接学习了评估任务，从而保证了评估方法的公平性。

    Large language models (LLMs) have received increasing attention. However, due to the complexity of its capabilities, how to rationally evaluate the capabilities of LLMs is still a task to be solved. We propose the RoCar method, which utilizes the defined basic schemas to randomly construct a task graph and generates natural language evaluation tasks based on the task graph to evaluate the reasoning and memory abilities of LLMs respectively. Due to the very large randomness of the task construction process, it is possible to ensure that none of the LLMs to be tested has directly learned the evaluation tasks, guaranteeing the fairness of the evaluation method.
    
[^22]: 针对大型语言模型的可编解码文本水印技术研究

    Towards Codable Text Watermarking for Large Language Models. (arXiv:2307.15992v1 [cs.CL])

    [http://arxiv.org/abs/2307.15992](http://arxiv.org/abs/2307.15992)

    这项研究对于大型语言模型的可编解码文本水印技术进行了系统研究，提出了一种允许文本水印携带更多可定制化信息的方法，解决了现有水印方法编码效率低、不能满足不同应用场景需求的问题。

    

    随着大型语言模型（LLMs）生成的文本日益流畅和逼真，有必要识别文本的来源以防止LLMs的滥用。文本水印技术通过将隐藏的模式注入到生成的文本中已被证实可以可靠地区分是否由LLMs生成的文本。然而，我们认为现有的LLMs水印方法在编码效率上存在问题（只包含一个位的信息，即文本是否由LLMs生成），并且不能灵活地满足不同LLMs应用场景中的多样化信息编码需求（如编码模型版本、生成时间、用户ID等）。在这项工作中，我们首次对LLMs的可编解码文本水印（CTWL）进行了系统研究，允许文本水印携带更多可定制化的信息。首先，我们研究了LLMs水印技术的分类，为CTWL提供了数学公式。此外，我们提供了一份全面的研究视图，涵盖了CTWL的各个方面。

    As large language models (LLMs) generate texts with increasing fluency and realism, there is a growing need to identify the source of texts to prevent the abuse of LLMs. Text watermarking techniques have proven reliable in distinguishing whether a text is generated by LLMs by injecting hidden patterns into the generated texts. However, we argue that existing watermarking methods for LLMs are encoding-inefficient (only contain one bit of information whether it is generated from an LLM or not) and cannot flexibly meet the diverse information encoding needs (such as encoding model version, generation time, user id, etc.) in different LLMs application scenarios. In this work, we conduct the first systematic study on the topic of Codable Text Watermarking for LLMs (CTWL) that allows text watermarks to carry more customizable information. First of all, we study the taxonomy of LLM watermarking technology and give a mathematical formulation for CTWL. Additionally, we provide a comprehensive
    
[^23]: 语言模型中复杂技能产生的理论

    A Theory for Emergence of Complex Skills in Language Models. (arXiv:2307.15936v1 [cs.LG])

    [http://arxiv.org/abs/2307.15936](http://arxiv.org/abs/2307.15936)

    本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。

    

    当语言模型的参数集合和训练语料库扩大时，新的技能将在 AI 产品中出现的主要驱动因素。这种现象尚不为人所理解，并且通过对基于梯度训练的数学分析提供机械解释似乎很困难。本文采用不同的方法，使用著名的（和经验性的）LLM扩展定律和简单的统计框架来分析出现。贡献包括：（a）一个统计框架将LLM的交叉熵损失与语言任务基本技能的能力相关联。（b）数学分析表明，扩展定律意味着强烈的归纳偏见，使预训练模型能够学习得非常高效。我们非正式地称之为“弹弓泛化”，因为表面上看，它似乎提供了在技能水平上违反通常泛化理论的能力。（c）弹弓泛化的一个关键例子，即在执行任务时的能力。

    A major driver of AI products today is the fact that new skills emerge in language models when their parameter set and training corpora are scaled up. This phenomenon is poorly understood, and a mechanistic explanation via mathematical analysis of gradient-based training seems difficult. The current paper takes a different approach, analysing emergence using the famous (and empirical) Scaling Laws of LLMs and a simple statistical framework. Contributions include: (a) A statistical framework that relates cross-entropy loss of LLMs to competence on the basic skills that underlie language tasks. (b) Mathematical analysis showing that the Scaling Laws imply a strong form of inductive bias that allows the pre-trained model to learn very efficiently. We informally call this {\em slingshot generalization} since naively viewed it appears to give competence levels at skills that violate usual generalization theory. (c) A key example of slingshot generalization, that competence at executing task
    
[^24]: GeneMask: 快速预训练基因序列以实现少样本学习

    GeneMask: Fast Pretraining of Gene Sequences to Enable Few-Shot Learning. (arXiv:2307.15933v1 [cs.CL])

    [http://arxiv.org/abs/2307.15933](http://arxiv.org/abs/2307.15933)

    GeneMask提出了一种新颖的基因序列屏蔽算法，通过选择具有最高规一化点对点互信息的跨度来优化屏蔽语言建模训练，相比于DNABert和LOGO等模型，在缺乏基因组学领域的人类可理解的语义的情况下表现更好。

    

    大规模语言模型如DNABert和LOGO旨在学习最佳基因表示，并在整个人类参考基因组上进行训练。然而，标准的分词方案仅涉及类似k-mers的简单滑动窗口，不能利用任何基于基因的语义，因此可能会导致（平凡的）屏蔽易于预测序列，从而导致低效的屏蔽语言建模（MLM）训练。因此，我们提出了一种新颖的屏蔽算法GeneMask，用于基因序列的MLM训练，其中我们随机识别基因序列中的屏蔽中心位置，并局部选择中心位置周围具有最高规一化点对点互信息（NPMI）的跨度进行屏蔽。我们观察到，在基因组学领域缺乏人类理解的语义的情况下（相比之下，NLP中固有地提供单词和短语等语义单位），基于GeneMask的模型在四个基准基因上明显优于SOTA模型（DNABert和LOGO）。

    Large-scale language models such as DNABert and LOGO aim to learn optimal gene representations and are trained on the entire Human Reference Genome. However, standard tokenization schemes involve a simple sliding window of tokens like k-mers that do not leverage any gene-based semantics and thus may lead to (trivial) masking of easily predictable sequences and subsequently inefficient Masked Language Modeling (MLM) training. Therefore, we propose a novel masking algorithm, GeneMask, for MLM training of gene sequences, where we randomly identify positions in a gene sequence as mask centers and locally select the span around the mask center with the highest Normalized Pointwise Mutual Information (NPMI) to mask. We observe that in the absence of human-understandable semantics in the genomics domain (in contrast, semantic units like words and phrases are inherently available in NLP), GeneMask-based models substantially outperform the SOTA models (DNABert and LOGO) over four benchmark gene
    
[^25]: ATESA-B{\AE}RT: 一个用于基于方面的情感分析的异构集成学习模型

    ATESA-B{\AE}RT: A Heterogeneous Ensemble Learning Model for Aspect-Based Sentiment Analysis. (arXiv:2307.15920v1 [cs.CL])

    [http://arxiv.org/abs/2307.15920](http://arxiv.org/abs/2307.15920)

    ATESA-B{\AE}RT是一个基于方面的情感分析的异构集成学习模型，通过将问题分为方面词提取和方面词情感分析两个子任务，并使用\textit{argmax}多类别分类算法进行分析，提高了在方面级别上的粒度，改进了当前解决方案在多方面数据上的性能问题。

    

    随着在线评论数量的增加，情感分析模型的发展成为了确定消费者对不同产品和服务的意见的可能。到目前为止，情感分析已被证明是确定评论整体极性的有效工具。为了提高在方面级别上的粒度，更好地理解服务或产品，基于方面的情感分析任务首先旨在识别方面，然后确定用户对它们的意见。这项任务的复杂性在于同一评论可能会呈现多个方面，每个方面具有自己的极性。目前的解决方案在这种数据上表现不佳。我们通过提出ATESA-B{\AE}RT，一个用于基于方面的情感分析的异构集成学习模型来解决这个问题。首先，我们将问题分为两个子任务，即方面词提取和方面词情感分析。其次，我们使用\textit{argmax}多类别分类算法来对方面词进行分类。

    The increasing volume of online reviews has made possible the development of sentiment analysis models for determining the opinion of customers regarding different products and services. Until now, sentiment analysis has proven to be an effective tool for determining the overall polarity of reviews. To improve the granularity at the aspect level for a better understanding of the service or product, the task of aspect-based sentiment analysis aims to first identify aspects and then determine the user's opinion about them. The complexity of this task lies in the fact that the same review can present multiple aspects, each with its own polarity. Current solutions have poor performance on such data. We address this problem by proposing ATESA-B{\AE}RT, a heterogeneous ensemble learning model for Aspect-Based Sentiment Analysis. Firstly, we divide our problem into two sub-tasks, i.e., Aspect Term Extraction and Aspect Term Sentiment Analysis. Secondly, we use the \textit{argmax} multi-class 
    
[^26]: 对话塑造：通过NPC交互增强智能体能力

    Dialogue Shaping: Empowering Agents through NPC Interaction. (arXiv:2307.15833v1 [cs.CL])

    [http://arxiv.org/abs/2307.15833](http://arxiv.org/abs/2307.15833)

    本文研究了通过与NPC智能体的交互和对话，利用大型语言模型和知识图谱来加速强化学习智能体的训练过程。

    

    强化学习(RL)中的一个主要挑战是RL智能体在训练过程中需要收敛并学习最优策略的大量步骤，尤其是在动作空间广泛的基于文本的游戏环境中。然而，非玩家角色(NPCs)有时会拥有游戏的关键信息，这些信息有助于更快地训练RL智能体。因此，本文探讨了如何与NPC智能体进行交互和对话，利用大型语言模型(LLMs)获取关键信息，并使用知识图谱(KGs)和故事塑造来加速RL智能体的训练。

    One major challenge in reinforcement learning (RL) is the large amount of steps for the RL agent needs to converge in the training process and learn the optimal policy, especially in text-based game environments where the action space is extensive. However, non-player characters (NPCs) sometimes hold some key information about the game, which can potentially help to train RL agents faster. Thus, this paper explores how to interact and converse with NPC agents to get the key information using large language models (LLMs), as well as incorporate this information to speed up RL agent's training using knowledge graphs (KGs) and Story Shaping.
    
[^27]: RT-2：视觉-语言-行动模型将网络知识转化为机器人控制

    RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control. (arXiv:2307.15818v1 [cs.RO])

    [http://arxiv.org/abs/2307.15818](http://arxiv.org/abs/2307.15818)

    本文研究了将互联网规模数据上训练的视觉-语言模型直接应用于机器人控制的方法，实现了泛化能力的提升和新兴的语义推理。通过在机器人轨迹数据和互联网规模的视觉-语言任务上共同微调最先进的视觉-语言模型，为单一的端到端训练模型提供了同时学习机器人观测到行为映射和利用语言和视觉-语言数据的益处的能力。

    

    本文研究了如何将在互联网规模数据上训练的视觉-语言模型直接应用于端到端的机器人控制，以提升泛化能力并实现新兴的语义推理。我们的目标是让单一的端到端训练模型既能学会将机器人观测映射到行为，又能享受来自网络的语言和视觉-语言数据的益处。为此，我们提出在机器人轨迹数据和互联网规模的视觉-语言任务（如视觉问答）上共同微调最先进的视觉-语言模型。与其他方法不同，我们提出了一个简单的通用方法来实现这个目标：为了使自然语言回答和机器人行为都能以相同的格式进行处理，我们将行为表示为文本标记，并将它们直接纳入模型的训练集中，与自然语言标记相同。我们将这类模型称为视觉-语言-行动模型（VLA）。

    We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and inst
    
[^28]: LLM-Rec: 通过引导大型语言模型进行个性化推荐

    LLM-Rec: Personalized Recommendation via Prompting Large Language Models. (arXiv:2307.15780v1 [cs.CL])

    [http://arxiv.org/abs/2307.15780](http://arxiv.org/abs/2307.15780)

    本文通过引导大型语言模型进行个性化推荐的研究，提出了四种不同的引导策略，并通过实验证明了这些策略的有效性。这一发现强调了在个性化内容推荐中，采用多样的引导和输入增强技术可以提高大型语言模型的推荐性能。

    

    本文通过输入增强技术，研究了多种不同的引导策略，以提高大型语言模型（LLM）在个性化内容推荐方面的性能。我们提出的方法名为LLM-Rec，包括四种不同的引导策略：（1）基础引导，（2）推荐驱动引导，（3）参与引导引导，和（4）推荐驱动+参与引导引导。实验证明，将原始内容描述与LLM生成的增强输入文本结合起来，采用这些引导策略可以提高推荐性能。这一发现强调了在个性化内容推荐中，通过引入多样的引导和输入增强技术来提升大型语言模型的推荐能力的重要性。

    We investigate various prompting strategies for enhancing personalized content recommendation performance with large language models (LLMs) through input augmentation. Our proposed approach, termed LLM-Rec, encompasses four distinct prompting strategies: (1) basic prompting, (2) recommendation-driven prompting, (3) engagement-guided prompting, and (4) recommendation-driven + engagement-guided prompting. Our empirical experiments show that combining the original content description with the augmented input text generated by LLM using these prompting strategies leads to improved recommendation performance. This finding highlights the importance of incorporating diverse prompts and input augmentation techniques to enhance the recommendation capabilities with large language models for personalized content recommendation.
    
[^29]: 选择和增强：增强稠密检索知识图谱增强

    Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation. (arXiv:2307.15776v1 [cs.CL])

    [http://arxiv.org/abs/2307.15776](http://arxiv.org/abs/2307.15776)

    本文提出了一种选择和增强的方法来改进文本增强的知识图谱嵌入，通过多任务框架选择相关的文本描述，并对知识图谱嵌入进行对齐或增强。

    

    在自然语言处理社区中，将文本信息注入知识图谱（KG）实体表示已经成为一个值得探索的领域，以提高KG相关任务的性能。常用的外部知识增强KG嵌入的方法包括语义丰富的依赖解析特征、一组相关关键词，以及来自外部语料库（如维基百科）的完整文本描述。尽管这种创新（文本增强的KG嵌入）取得了一定的进展，但本文提出这种方法可以进一步改进。我们不再使用单一文本描述（因为文本的固有语义歧义无法充分表示一个实体），而是提出了一个多任务框架，既能选择与KG实体相关的一组文本描述，又能将KG嵌入与文本描述进行对齐或增强。与之前将形式化实体描述插入知识库的方法不同，这一方法是提供了对KG嵌入进行增强和对齐的新途径。

    Injecting textual information into knowledge graph (KG) entity representations has been a worthwhile expedition in terms of improving performance in KG oriented tasks within the NLP community. External knowledge often adopted to enhance KG embeddings ranges from semantically rich lexical dependency parsed features to a set of relevant key words to entire text descriptions supplied from an external corpus such as wikipedia and many more. Despite the gains this innovation (Text-enhanced KG embeddings) has made, the proposal in this work suggests that it can be improved even further. Instead of using a single text description (which would not sufficiently represent an entity because of the inherent lexical ambiguity of text), we propose a multi-task framework that jointly selects a set of text descriptions relevant to KG entities as well as align or augment KG embeddings with text descriptions. Different from prior work that plugs formal entity descriptions declared in knowledge bases, th
    
[^30]: Hydra效应：语言模型计算中的自适应自修复机制

    The Hydra Effect: Emergent Self-repair in Language Model Computations. (arXiv:2307.15771v1 [cs.LG])

    [http://arxiv.org/abs/2307.15771](http://arxiv.org/abs/2307.15771)

    本研究通过因果分析探究了语言模型计算的内部结构，发现了Hydra效应和晚期MLP层的平衡功能，并分析了它们在语言模型中的影响。

    

    本研究使用因果分析探究语言模型计算的内部结构，并展示了两种模式：（1）一种自适应计算形式，即语言模型中的某一自注意层被删减后另一层进行补偿（我们称之为Hydra效应）；（2）在后期多层感知机层中存在的平衡功能，用于调节最大似然令牌。我们的删减研究表明，语言模型层之间通常相对松散耦合（对一层的删减只会影响一小部分下游层）。令人惊讶的是，即使在没有任何形式的随机失活的语言模型中，这些效应仍然存在。我们在事实回忆的背景下分析了这些效应，并考虑了它们对语言模型的电路层面归因的影响。

    We investigate the internal structure of language model computations using causal analysis and demonstrate two motifs: (1) a form of adaptive computation where ablations of one attention layer of a language model cause another layer to compensate (which we term the Hydra effect) and (2) a counterbalancing function of late MLP layers that act to downregulate the maximum-likelihood token. Our ablation studies demonstrate that language model layers are typically relatively loosely coupled (ablations to one layer only affect a small number of downstream layers). Surprisingly, these effects occur even in language models trained without any form of dropout. We analyse these effects in the context of factual recall and consider their implications for circuit-level attribution in language models.
    
[^31]: CHATREPORT：通过基于LLM工具实现可持续性披露分析的民主化

    CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools. (arXiv:2307.15770v1 [cs.CL])

    [http://arxiv.org/abs/2307.15770](http://arxiv.org/abs/2307.15770)

    本论文介绍了一种名为ChatReport的基于LLM的系统，它通过实现可追溯的答案和解决领域专家参与低效性的问题，旨在通过自动分析企业可持续性报告，实现可持续性披露分析民主化。

    

    面对气候变化，公司真的在朝着更可持续经营迈出实质性的步伐吗？一个全面的答案可以在企业可持续性报告的密集信息中找到。然而，这些报告的数量和复杂性使人工分析成本非常高昂。因此，只有少数的机构拥有资源能够大规模分析这些报告，这导致可持续性报告缺乏透明度。通过基于LLM自动分析工具赋能利益相关者可能是实现可持续性报告分析民主化的一种有希望的方式。然而，开发这样的工具面临挑战，主要原因是LLM的幻觉问题和将领域专家引入AI开发过程的低效性。在本文中，我们介绍了ChatReport，这是一种基于LLM的新型系统，用于自动化分析企业可持续性报告，通过使答案可追溯来减少幻觉的危害，并解决领域专家参与AI开发过程的低效性。

    In the face of climate change, are companies really taking substantial steps toward more sustainable operations? A comprehensive answer lies in the dense, information-rich landscape of corporate sustainability reports. However, the sheer volume and complexity of these reports make human analysis very costly. Therefore, only a few entities worldwide have the resources to analyze these reports at scale, which leads to a lack of transparency in sustainability reporting. Empowering stakeholders with LLM-based automatic analysis tools can be a promising way to democratize sustainability report analysis. However, developing such tools is challenging due to (1) the hallucination of LLMs and (2) the inefficiency of bringing domain experts into the AI development loop. In this paper, we ChatReport, a novel LLM-based system to automate the analysis of corporate sustainability reports, addressing existing challenges by (1) making the answers traceable to reduce the harm of hallucination and (2) a
    
[^32]: 可再现性探究：从材料科学中的NLP研究中获得的见解

    Lessons in Reproducibility: Insights from NLP Studies in Materials Science. (arXiv:2307.15759v1 [physics.chem-ph])

    [http://arxiv.org/abs/2307.15759](http://arxiv.org/abs/2307.15759)

    这两篇论文对于材料科学领域的NLP研究提供了重要的可再现性分析，其中包括了详尽的工作流程、整洁的代码库和清晰的模型评估指导，为未来的材料科学出版物树立了良好的标准。

    

    自然语言处理（NLP）作为人工智能中的基石领域，越来越多地被应用于材料科学文献领域。本研究对该领域中的两项开创性研究：“机器学习和编码的氧化物材料合成参数”（Kim等人）和“无监督的词嵌入从材料科学文献中提取潜在知识”（Tshitoyan等人）进行了可再现性分析。我们的研究旨在从可再现性的角度理解这些研究，认识到它们对材料信息学领域的重要影响，而不是批评它们。我们的研究表明，这两篇论文提供了详尽的工作流程、整洁且有良好文档的代码库，以及清晰的模型评估指导。这使得成功复制他们的结果并部分重现他们的发现变得更加容易。通过这样做，它们为未来的材料科学出版物树立了值得称赞的标准。

    Natural Language Processing (NLP), a cornerstone field within artificial intelligence, has been increasingly utilized in the field of materials science literature. Our study conducts a reproducibility analysis of two pioneering works within this domain: "Machine-learned and codified synthesis parameters of oxide materials" by Kim et al., and "Unsupervised word embeddings capture latent knowledge from materials science literature" by Tshitoyan et al. We aim to comprehend these studies from a reproducibility perspective, acknowledging their significant influence on the field of materials informatics, rather than critiquing them. Our study indicates that both papers offered thorough workflows, tidy and well-documented codebases, and clear guidance for model evaluation. This makes it easier to replicate their results successfully and partially reproduce their findings. In doing so, they set commendable standards for future materials science publications to aspire to. However, our analysis 
    
[^33]: 通过潜在狄利克雷分配和自然语言处理对简历进行评估，以实现有效的候选人选择

    Resume Evaluation through Latent Dirichlet Allocation and Natural Language Processing for Effective Candidate Selection. (arXiv:2307.15752v1 [cs.CL])

    [http://arxiv.org/abs/2307.15752](http://arxiv.org/abs/2307.15752)

    本文提出了一种使用LDA和自然语言处理的方法，通过提取简历中的实体并将其用于评分，从而实现有效的候选人选择。该方法在考虑所有属性的情况下达到了82%的准确率。

    

    本文提出了一种使用潜在狄利克雷分配（LDA）和使用SpaCy进行实体检测的简历评分方法。所提出的方法首先使用SpaCy的命名实体识别（NER）从简历中提取相关实体，如教育背景、工作经历和技能。然后，LDA模型使用这些实体为简历评分，为每个实体分配主题概率。此外，我们使用SpaCy的NER进行实体检测的详细分析，并报告其评估指标。使用LDA，我们提出的系统将简历分解为潜在主题，并提取有意义的语义表示。我们的模型实现了77%的准确率，只考虑技能，在考虑所有属性（如学院名称、工作经历、学位和技能）的情况下，总体准确率达到82%。

    In this paper, we propose a method for resume rating using Latent Dirichlet Allocation (LDA) and entity detection with SpaCy. The proposed method first extracts relevant entities such as education, experience, and skills from the resume using SpaCy's Named Entity Recognition (NER). The LDA model then uses these entities to rate the resume by assigning topic probabilities to each entity. Furthermore, we conduct a detailed analysis of the entity detection using SpaCy's NER and report its evaluation metrics. Using LDA, our proposed system breaks down resumes into latent topics and extracts meaningful semantic representations. With a vision to define our resume score to be more content-driven rather than a structure and keyword match driven, our model has achieved 77% accuracy with respect to only skills in consideration and an overall 82% accuracy with all attributes in consideration. (like college name, work experience, degree and skills)
    
[^34]: Context-VQA: 面向上下文感知和有意义的视觉问答

    Context-VQA: Towards Context-Aware and Purposeful Visual Question Answering. (arXiv:2307.15745v1 [cs.CL])

    [http://arxiv.org/abs/2307.15745](http://arxiv.org/abs/2307.15745)

    Context-VQA通过引入上下文信息，提供了一种全面满足人们需求的视觉问答模型，该模型的创新在于将图像与不同上下文配对，并发现不同上下文下问题类型存在差异。

    

    视觉问答（VQA）有潜力以一种互动方式使互联网更具可访问性，使不能看到图像的人们能够就图像提出问题。然而，多项研究表明，盲人或视力低下的人更喜欢包含图像出现环境的图像解释，而当前的VQA数据集侧重于孤立的图像。我们认为，除非考虑上下文，否则VQA模型将无法完全满足人们的需求。为进一步激发和分析不同上下文之间的区别，我们引入了Context-VQA，一种将图像与上下文（如购物网站）配对的VQA数据集。我们发现不同上下文下的问题类型存在系统性差异。例如，在旅行上下文中呈现的图像产生2倍于平均数的“在哪里？”问题，而社交媒体和新闻上的图像产生的“谁？”问题分别为平均数的2.8倍和1.8倍。我们还发现，上下文对于回答正确的问题至关重要。具体来说，当上下文提供了提示时，准确率提高了17.2％。

    Visual question answering (VQA) has the potential to make the Internet more accessible in an interactive way, allowing people who cannot see images to ask questions about them. However, multiple studies have shown that people who are blind or have low-vision prefer image explanations that incorporate the context in which an image appears, yet current VQA datasets focus on images in isolation. We argue that VQA models will not fully succeed at meeting people's needs unless they take context into account. To further motivate and analyze the distinction between different contexts, we introduce Context-VQA, a VQA dataset that pairs images with contexts, specifically types of websites (e.g., a shopping website). We find that the types of questions vary systematically across contexts. For example, images presented in a travel context garner 2 times more "Where?" questions, and images on social media and news garner 2.8 and 1.8 times more "Who?" questions than the average. We also find that c
    
[^35]: 利用大型语言模型进行药理学数据库的自然界面

    Utilizing Large Language Models for Natural Interface to Pharmacology Databases. (arXiv:2307.15717v1 [cs.CL])

    [http://arxiv.org/abs/2307.15717](http://arxiv.org/abs/2307.15717)

    该论文介绍了一种利用大型语言模型的自然语言界面，旨在与药理学数据库中的结构化信息进行交互，具有广泛的应用价值。

    

    药物开发过程需要药理学家进行各种任务，如查阅文献，提出假设，设计实验和解释结果。每个阶段都需要访问和查询大量信息。在本文中，我们介绍了一种基于大型语言模型（LLM）的自然语言界面，旨在与存储在数据库中的结构化信息进行交互。我们的实验证明了所提出框架的可行性和有效性。该框架可以推广到查询各种药物数据和知识库。

    The drug development process necessitates that pharmacologists undertake various tasks, such as reviewing literature, formulating hypotheses, designing experiments, and interpreting results. Each stage requires accessing and querying vast amounts of information. In this abstract, we introduce a Large Language Model (LLM)-based Natural Language Interface designed to interact with structured information stored in databases. Our experiments demonstrate the feasibility and effectiveness of the proposed framework. This framework can generalize to query a wide range of pharmaceutical data and knowledge bases.
    
[^36]: 使用基于生成式人工智能的极端摘要化科学文献来改进初级医疗保健工作流程

    Improving Primary Healthcare Workflow Using Extreme Summarization of Scientific Literature Based on Generative AI. (arXiv:2307.15715v1 [cs.CL])

    [http://arxiv.org/abs/2307.15715](http://arxiv.org/abs/2307.15715)

    本研究利用生成式人工智能技术对科学论文的摘要进行极端摘要化，旨在帮助初级保健专业人员减轻认知负荷，从而提高其工作效率和减少心理负担。

    

    初级保健专业人员在指导以证据为基础的实践方面，如何跟上最新的科学文献一直是一个挑战。为了解决这个问题，我们使用基于大规模语言模型的生成式人工智能技术来对科学论文的摘要进行总结。我们的目标是研究生成式人工智能在减少从业者认知负荷方面的潜力，从而探索其减轻心理努力和负担的能力。研究参与者接受与预防保健和行为改变相关的两个案例，模拟对新的科学文献进行搜索。研究包括来自斯洛文尼亚和美国的113名大学生，被随机分成三个不同的研究组。第一组被分配阅读完整的摘要，第二组被分配阅读由人工智能生成的短摘要，第三组有选择性地阅读。

    Primary care professionals struggle to keep up to date with the latest scientific literature critical in guiding evidence-based practice related to their daily work. To help solve the above-mentioned problem, we employed generative artificial intelligence techniques based on large-scale language models to summarize abstracts of scientific papers. Our objective is to investigate the potential of generative artificial intelligence in diminishing the cognitive load experienced by practitioners, thus exploring its ability to alleviate mental effort and burden. The study participants were provided with two use cases related to preventive care and behavior change, simulating a search for new scientific literature. The study included 113 university students from Slovenia and the United States randomized into three distinct study groups. The first group was assigned to the full abstracts. The second group was assigned to the short abstracts generated by AI. The third group had the option to se
    
[^37]: 一种几何观念的因果探测

    A Geometric Notion of Causal Probing. (arXiv:2307.15054v1 [cs.CL])

    [http://arxiv.org/abs/2307.15054](http://arxiv.org/abs/2307.15054)

    本文提出了一种几何观念的因果探测方法，通过在语言模型表示空间的子空间上进行反事实干预，优化了因果概念子空间，以实现概念控制生成。

    

    大型语言模型依赖于文本的实值表示来进行预测。这些表示包含了模型在训练数据上学到的信息，包括语言属性和基于性别的人口偏见等。越来越多的研究关注通过在表示空间的子空间上进行正交投影来获得关于这些概念的信息。我们通过提出语言模型表示空间子空间的内在信息的形式定义，为这项研究贡献了新的内容。我们提出了一种反事实方法来避免虚假相关的失效模式，通过独立处理子空间中的分量和其正交补空间中的分量。我们展示了在子空间中的反事实信息概念是由一个因果概念子空间进行优化的。此外，这种干预使我们能够通过操作来尝试概念控制生成。

    Large language models rely on real-valued representations of text to make their predictions. These representations contain information learned from the data that the model has trained on, including knowledge of linguistic properties and forms of demographic bias, e.g., based on gender. A growing body of work has considered information about concepts such as these using orthogonal projections onto subspaces of the representation space. We contribute to this body of work by proposing a formal definition of intrinsic information in a subspace of a language model's representation space. We propose a counterfactual approach that avoids the failure mode of spurious correlations (Kumar et al., 2022) by treating components in the subspace and its orthogonal complement independently. We show that our counterfactual notion of information in a subspace is optimizing by an causal concept subspace. Furthermore, this intervention allows us to attempt concept controlled generation by manipulating the
    
[^38]: Gzip与KNN在文本分类中的对比研究

    Gzip versus bag-of-words for text classification with KNN. (arXiv:2307.15002v1 [cs.CL])

    [http://arxiv.org/abs/2307.15002](http://arxiv.org/abs/2307.15002)

    Gzip与KNN相比较在文本分类中，我们发现通过简单的词袋匹配可以获得类似或更好的准确性，并且更加高效。

    

    最近，基于KNN的文本分类中压缩距离（gzip）的有效性引起了很多关注。在本文中，我们展示了通过更简单的方法可以达到类似或更好的效果，并且可能不需要文本压缩。实际上，我们发现简单的“词袋”匹配可以达到类似或更好的准确性，并且更高效。

    The effectiveness of compression distance in KNN-based text classification ('gzip') has recently garnered lots of attention. In this note, we show that similar or better effectiveness can be achieved with simpler means, and text compression may not be necessary. Indeed, we find that a simple 'bag-of-words' matching can achieve similar or better accuracy, and is more efficient.
    
[^39]: Skill-it! 一个数据驱动的技能框架，用于理解和训练语言模型

    Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models. (arXiv:2307.14430v1 [cs.CL])

    [http://arxiv.org/abs/2307.14430](http://arxiv.org/abs/2307.14430)

    本论文提出了一个数据驱动的技能框架，用于理解和训练语言模型。通过研究人类获得技能的有序性，我们证明了语言模型学习技能时也有一定的顺序，并且这种顺序可以改善对语言模型的理解和数据高效训练。

    

    训练数据的质量对于预训练的大型语言模型的性能有重要影响。在固定的token预算下，我们研究如何选择能够在各个任务中获得良好下游模型性能的数据。我们提出了一个新的框架，基于一个简单的假设：人类在有意义的顺序中获得相互依赖的技能，语言模型在学习一组技能时也会遵循这样的顺序。如果存在这样的顺序，可以用于改进对语言模型的理解和数据高效训练。利用这种直觉，我们的框架将技能的概念和有序的技能集合的概念形式化为相关数据。首先，使用合成数据和真实数据，我们证明了这些有序的技能集合的存在，并且它们的存在使得在训练其先决条件技能时可以使用更少的数据来学习更高级的技能。其次，使用我们提出的框架，我们介绍了一种在线数据采样算法。

    The quality of training data impacts the performance of pre-trained large language models (LMs). Given a fixed budget of tokens, we study how to best select data that leads to good downstream model performance across tasks. We develop a new framework based on a simple hypothesis: just as humans acquire interdependent skills in a deliberate order, language models also follow a natural order when learning a set of skills from their training data. If such an order exists, it can be utilized for improved understanding of LMs and for data-efficient training. Using this intuition, our framework formalizes the notion of a skill and of an ordered set of skills in terms of the associated data. First, using both synthetic and real data, we demonstrate that these ordered skill sets exist, and that their existence enables more advanced skills to be learned with less data when we train on their prerequisite skills. Second, using our proposed framework, we introduce an online data sampling algorithm
    
[^40]: XDLM: 用于机器翻译的跨语言扩散语言模型

    XDLM: Cross-lingual Diffusion Language Model for Machine Translation. (arXiv:2307.13560v1 [cs.CL])

    [http://arxiv.org/abs/2307.13560](http://arxiv.org/abs/2307.13560)

    本文介绍了XDLM，一种用于机器翻译的跨语言扩散语言模型。通过预训练和微调阶段，我们成功地提高了在不同语言之间的翻译性能，超过了传统扩散模型和Transformer模型。

    

    最近，扩散模型在图像生成任务中表现出色，并且已经应用于神经语言处理（NLP）中的可控文本生成。然而，扩散模型在跨语言环境中的应用相对较少。此外，尽管已经研究了在单一语言中使用扩散模型进行预训练，但跨语言预训练的潜力仍未被深入研究。为了填补这些空白，我们提出了XDLM，一种新颖的用于机器翻译的跨语言扩散模型，包括预训练和微调阶段。在预训练阶段，我们提出了TLDM，一种新的训练目标，用于掌握不同语言之间的映射关系；在微调阶段，我们基于预训练模型构建了翻译系统。我们在几个机器翻译基准上进行了评估，并超过了扩散和Transformer基线模型。

    Recently, diffusion models have excelled in image generation tasks and have also been applied to neural language processing (NLP) for controllable text generation. However, the application of diffusion models in a cross-lingual setting is less unexplored. Additionally, while pretraining with diffusion models has been studied within a single language, the potential of cross-lingual pretraining remains understudied. To address these gaps, we propose XDLM, a novel Cross-lingual diffusion model for machine translation, consisting of pretraining and fine-tuning stages. In the pretraining stage, we propose TLDM, a new training objective for mastering the mapping between different languages; in the fine-tuning stage, we build up the translation system based on the pretrained model. We evaluate the result on several machine translation benchmarks and outperformed both diffusion and Transformer baselines.
    
[^41]: 在金融行业中应用量子自然语言处理(QNLP)进行情感分析

    Applying QNLP to sentiment analysis in finance. (arXiv:2307.11788v1 [cs.CL])

    [http://arxiv.org/abs/2307.11788](http://arxiv.org/abs/2307.11788)

    本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。

    

    作为一个领域，即使是最微小的质量改进也能产生巨大价值的应用领域，金融是早期量子优势的有前途的候选者。在迅速发展的量子自然语言处理(QNLP)领域中，我们探索了DisCoCat和量子增强的长短期记忆(QNLP)这两种中心方法在金融情感分析问题中的实际适用性。利用一种新颖的基于ChatGPT的数据生成方法，我们进行了一个包含1000多个真实句子的案例研究，发现QLSTM的训练速度比DisCoCat快得多，并且在可用的软件实现中也接近古典结果。

    As an application domain where the slightest qualitative improvements can yield immense value, finance is a promising candidate for early quantum advantage. Focusing on the rapidly advancing field of Quantum Natural Language Processing (QNLP), we explore the practical applicability of the two central approaches DisCoCat and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the problem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data generation approach, we conduct a case study with more than 1000 realistic sentences and find that QLSTMs can be trained substantially faster than DisCoCat while also achieving close to classical results for their available software implementations.
    
[^42]: L-Eval：为长文本语言模型引入标准化评估

    L-Eval: Instituting Standardized Evaluation for Long Context Language Models. (arXiv:2307.11088v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.11088](http://arxiv.org/abs/2307.11088)

    该论文提出了L-Eval，旨在为长文本语言模型引入标准化评估。通过开发一个包含411个长文档和2000多个人工标注的查询-回复对的数据集，研究探讨了扩展上下文对于处理长输入的实质性收益和改进程度。

    

    最近，对于扩展指令跟随模型的上下文长度，以便有效处理单回合的长输入（例如，论文总结）和具有更复杂历史的对话，引起了越来越多的关注。虽然像GPT-4和Claude这样的专有模型在处理极长输入方面取得了显著进步，但开放源代码模型仍处于尝试阶段。目前还不清楚扩展上下文是否能够比传统方法（如检索）提供实质性的收益，以及它在实际下游任务中对常规模型的改进程度。为了解决这一挑战，我们提出了为长上下文语言模型引入标准化评估的方案。具体而言，我们开发了L-Eval，其中包含411个长文档和2000多个人工标注的查询-回复对，涵盖法律、金融、学校讲座、长对话、新闻、长篇小说和会议等领域。

    Recently, there has been growing interest in extending the context length of instruction-following models in order to effectively process single-turn long input (e.g. summarizing a paper) and conversations with more extensive histories. While proprietary models such as GPT-4 and Claude have shown significant strides in handling extremely lengthy input, open-sourced models are still in the early stages of experimentation. It also remains unclear whether extending the context can offer substantial gains over traditional methods such as retrieval, and to what extent it improves upon their regular counterparts in practical downstream tasks. To address this challenge, we propose instituting standardized evaluation for long context language models. Concretely, we develop L-Eval which contains 411 long documents and over 2,000 human-labeled query-response pairs encompassing areas such as law, finance, school lectures, lengthy conversations, news, long-form novels, and meetings. L-Eval also ad
    
[^43]: ChatGPT很好，但对于越南学生来说，Bing Chat更好

    ChatGPT is Good but Bing Chat is Better for Vietnamese Students. (arXiv:2307.08272v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08272](http://arxiv.org/abs/2307.08272)

    本研究比较了ChatGPT和Bing Chat在满足越南学生需求方面的效果，发现Bing Chat在除文学外的多个学科表现优于ChatGPT。Bing Chat采用更先进的GPT-4技术，能够提高文本的理解、推理和生成创造性、信息丰富的内容。

    

    本研究探讨了两个最先进的大型语言模型（LLMs），即ChatGPT和微软Bing Chat（BingChat），在满足越南学生需求方面的功效。尽管ChatGPT在多个学科中展现了高水准的能力，但Bing Chat被认为是更有优势的选择。我们对它们在数学、文学、英语、物理、化学、生物、历史、地理和公民教育等各个学科的学业成就进行了比较分析。研究结果表明，BingChat在多个学科上显示出比ChatGPT更优异的性能，唯独在文学方面，ChatGPT的表现更好一些。此外，与基于GPT-3.5构建的ChatGPT相比，BingChat采用了更先进的GPT-4技术，这使其能够提高文本的理解、推理和生成创造性、信息丰富的文本。此外，BingChat在越南地区可获得。

    This study examines the efficacy of two SOTA large language models (LLMs), namely ChatGPT and Microsoft Bing Chat (BingChat), in catering to the needs of Vietnamese students. Although ChatGPT exhibits proficiency in multiple disciplines, Bing Chat emerges as the more advantageous option. We conduct a comparative analysis of their academic achievements in various disciplines, encompassing mathematics, literature, English language, physics, chemistry, biology, history, geography, and civic education. The results of our study suggest that BingChat demonstrates superior performance compared to ChatGPT across a wide range of subjects, with the exception of literature, where ChatGPT exhibits better performance. Additionally, BingChat utilizes the more advanced GPT-4 technology in contrast to ChatGPT, which is built upon GPT-3.5. This allows BingChat to improve to comprehension, reasoning and generation of creative and informative text. Moreover, the fact that BingChat is accessible in Vietna
    
[^44]: 超越本地范围：全球图增强个性化新闻推荐

    Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v1 [cs.IR])

    [http://arxiv.org/abs/2307.06576](http://arxiv.org/abs/2307.06576)

    本文介绍了一种名为GLORY的模型，通过全局图与本地表示相结合，增强了个性化推荐系统。该模型通过构建全局感知历史新闻编码器来融合历史新闻表示，并考虑了用户隐藏的动机和行为。

    

    精确地向用户推荐候选新闻文章一直是个性化新闻推荐系统的核心挑战。大多数近期的研究主要集中在使用先进的自然语言处理技术从丰富的文本数据中提取语义信息，使用从本地历史新闻派生的基于内容的方法。然而，这种方法缺乏全局视角，未能考虑用户隐藏的动机和行为，超越语义信息。为了解决这个问题，我们提出了一种新颖的模型 GLORY（Global-LOcal news Recommendation sYstem），它结合了从其他用户学到的全局表示和本地表示，来增强个性化推荐系统。我们通过构建一个全局感知历史新闻编码器来实现这一目标，其中包括一个全局新闻图，并使用门控图神经网络来丰富新闻表示，从而通过历史新闻聚合器融合历史新闻表示。

    Precisely recommending candidate news articles to users has always been a core challenge for personalized news recommendation systems. Most recent works primarily focus on using advanced natural language processing techniques to extract semantic information from rich textual data, employing content-based methods derived from local historical news. However, this approach lacks a global perspective, failing to account for users' hidden motivations and behaviors beyond semantic information. To address this challenge, we propose a novel model called GLORY (Global-LOcal news Recommendation sYstem), which combines global representations learned from other users with local representations to enhance personalized recommendation systems. We accomplish this by constructing a Global-aware Historical News Encoder, which includes a global news graph and employs gated graph neural networks to enrich news representations, thereby fusing historical news representations by a historical news aggregator.
    
[^45]: 解读疾病进展聚类中的深度嵌入

    Interpreting deep embeddings for disease progression clustering. (arXiv:2307.06060v1 [stat.ML])

    [http://arxiv.org/abs/2307.06060](http://arxiv.org/abs/2307.06060)

    本文提出了一种在疾病进展聚类中解读深度嵌入的新方法，并通过评估2型糖尿病参与者数据集展示了对疾病进展模式的临床意义性见解。

    

    我们提出了一种在患者聚类的背景下解读深度嵌入的新方法。我们在来自英国生物库的2型糖尿病参与者数据集上评估我们的方法，并展示出对疾病进展模式的临床意义性见解。

    We propose a novel approach for interpreting deep embeddings in the context of patient clustering. We evaluate our approach on a dataset of participants with type 2 diabetes from the UK Biobank, and demonstrate clinically meaningful insights into disease progression patterns.
    
[^46]: 在文本中测量词汇多样性：“两倍长度问题”

    Measuring Lexical Diversity in Texts: The Twofold Length Problem. (arXiv:2307.04626v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.04626](http://arxiv.org/abs/2307.04626)

    这篇论文关注了文本长度对词汇多样性估计的影响，并提出了解决该问题的一种方法。然而，现有的指数虽然能解决长度依赖问题，却未能解决对文本缩减长度参数的敏感性问题。最后，论文给出了优化词汇多样性分析的建议。

    

    关于文本长度对词汇多样性估计的影响已经引起科学界的长期关注。虽然已经提出了许多指数，并进行了许多研究来评估它们，但问题仍然存在。本方法学综述不仅对语言学习研究中最常用的指数进行了批判性分析，还对长度问题本身以及评估所提出解决方案的方法进行了分析。对三组英语学习者文本的分析结果表明，将所有文本使用概率或算法方法缩减为相同长度的指数可以解决长度依赖问题；然而，所有这些指数都未解决第二个问题，即它们对决定缩减文本长度的参数的敏感性问题。论文最后给出了优化词汇多样性分析的建议。

    The impact of text length on the estimation of lexical diversity has captured the attention of the scientific community for more than a century. Numerous indices have been proposed, and many studies have been conducted to evaluate them, but the problem remains. This methodological review provides a critical analysis not only of the most commonly used indices in language learning studies, but also of the length problem itself, as well as of the methodology for evaluating the proposed solutions. The analysis of three datasets of English language-learners' texts revealed that indices that reduce all texts to the same length using a probabilistic or an algorithmic approach solve the length dependency problem; however, all these indices failed to address the second problem, which is their sensitivity to the parameter that determines the length to which the texts are reduced. The paper concludes with recommendations for optimizing lexical diversity analysis.
    
[^47]: 迷失在中间：语言模型如何使用长文本

    Lost in the Middle: How Language Models Use Long Contexts. (arXiv:2307.03172v1 [cs.CL])

    [http://arxiv.org/abs/2307.03172](http://arxiv.org/abs/2307.03172)

    本研究分析了语言模型在多文档问答和键值检索任务中的表现，发现当相关信息位于输入文本的开头或结尾时性能最佳，而当模型需要在长文本的中间访问相关信息时性能显著下降。此外，即使对于专门处理长文本的模型，输入文本越长性能也会大幅降低。我们的研究为理解语言模型如何使用输入文本的上下文提供了新的认识，并且为未来的长文本模型提供了新的评估方案。

    

    尽管最近的语言模型能够将长文本作为输入，但我们对语言模型如何有效地使用较长的文本还知之甚少。本研究分析了语言模型在两个需要在输入文本中识别相关信息的任务（多文档问答和键值检索）上的表现。我们发现，当相关信息出现在输入文本的开头或结尾时，语言模型的表现通常最佳；而当模型需要访问长文本中的中间相关信息时，性能显著下降。此外，即使对于专门处理长文本的模型，当输入文本变得越来越长时，性能也会大幅降低。我们的分析为我们更好地理解语言模型如何使用输入文本的上下文，并为未来的长文本模型提供了新的评估方案。

    While recent language models have the ability to take long contexts as input, relatively little is known about how well the language models use longer context. We analyze language model performance on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.
    
[^48]: 用多模态输入训练GPT4风格的语言模型有哪些重要问题？

    What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?. (arXiv:2307.02469v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.02469](http://arxiv.org/abs/2307.02469)

    本论文对训练GPT4风格的语言模型进行了系统综合研究，定量和定性分析了网络结构、训练数据和训练策略等设计选择对模型性能的影响，并提供了相关基准测试。

    

    最近，关于大型语言模型（LLM）如GPT4的进展显示出在根据图像遵循开放式指令方面具有出色的多模态能力。然而，这些模型的性能很大程度上依赖于网络结构、训练数据和训练策略等设计选择，并且这些选择在文献中尚未得到广泛讨论，这使得在这个领域中很难量化进展。为了解决这个问题，本文对训练这种模型进行了系统全面的定量和定性研究。我们实现了20多个带有控制设置的变体。具体而言，对于网络结构，我们比较了不同的LLM骨干和模型设计。对于训练数据，我们研究了数据和采样策略的影响。对于指令，我们探讨了多样化提示对所训练模型的指令遵循能力的影响。对于基准测试，我们贡献了第一个在我们的最佳知识范围内对此进行全面评估的工作。

    Recent advancements in Large Language Models (LLMs) such as GPT4 have displayed exceptional multi-modal capabilities in following open-ended instructions given images. However, the performance of these models heavily relies on design choices such as network structures, training data, and training strategies, and these choices have not been extensively discussed in the literature, making it difficult to quantify progress in this field. To address this issue, this paper presents a systematic and comprehensive study, quantitatively and qualitatively, on training such models. We implement over 20 variants with controlled settings. Concretely, for network structures, we compare different LLM backbones and model designs. For training data, we investigate the impact of data and sampling strategies. For instructions, we explore the influence of diversified prompts on the instruction-following ability of the trained models. For benchmarks, we contribute the first, to our best knowledge, compreh
    
[^49]: 六边形标注：将投影依存句法分析作为标注

    Hexatagging: Projective Dependency Parsing as Tagging. (arXiv:2306.05477v1 [cs.CL])

    [http://arxiv.org/abs/2306.05477](http://arxiv.org/abs/2306.05477)

    六边形标注器是一种新颖的依存分析器，可以在训练时实现完全并行化，具有线性时间复杂度和空间复杂度。使用预训练语言模型的特征进行预测。在 Penn Treebank 测试集上取得了最先进的性能。

    

    我们介绍了一种新颖的依存分析器——六边形标注器，它通过将句子中的单词标记为来自可能标记有限集合中的元素来构建依存树。与许多处理依存性分析的方法不同，我们的方法在训练时是完全可并行化的，即用于构建依存分析所需的结构构建操作可以相互并行预测。此外，确切解码的时间和空间复杂度都是线性的。此外，我们导出了一种概率依存分析器，它使用预训练语言模型的特征来预测六边标记，而不需要专为此任务明确设计的定制体系结构。尽管我们的方法具有通用性和简单性，但在 Penn Treebank 测试集上，我们实现了 96.4 LAS 和 97.4 UAS 的最先进性能。此外，我们的分析器的线性时间复杂度和并行性显著提高了计算效率，速度提高了大约十倍。

    We introduce a novel dependency parser, the hexatagger, that constructs dependency trees by tagging the words in a sentence with elements from a finite set of possible tags. In contrast to many approaches to dependency parsing, our approach is fully parallelizable at training time, i.e., the structure-building actions needed to build a dependency parse can be predicted in parallel to each other. Additionally, exact decoding is linear in time and space complexity. Furthermore, we derive a probabilistic dependency parser that predicts hexatags using no more than a linear model with features from a pretrained language model, i.e., we forsake a bespoke architecture explicitly designed for the task. Despite the generality and simplicity of our approach, we achieve state-of-the-art performance of 96.4 LAS and 97.4 UAS on the Penn Treebank test set. Additionally, our parser's linear time complexity and parallelism significantly improve computational efficiency, with a roughly 10-times speed-u
    
[^50]: 利用部分标注的文本提升阿拉伯语音标注的准确性

    Take the Hint: Improving Arabic Diacritization with Partially-Diacritized Text. (arXiv:2306.03557v1 [cs.CL])

    [http://arxiv.org/abs/2306.03557](http://arxiv.org/abs/2306.03557)

    本文提出了一个名为2SDiac的多源模型，可以在输入中使用可选音标来确定所有预测的输出，然后通过引入Guided Learning的训练策略，利用随机掩蔽和给定的输入音标提升标记的正确性。实验表明，该方法在非标记文本上表现良好，并实现了最先进的结果。

    

    自动化的阿拉伯语音标注在很多应用场景中都非常有用，比如对于语言学习者来说，标注可以提供阅读支持，而对于语音合成这样的下游任务，标注准确性对于发音预测也非常重要。之前的研究大多数专注于处理没有音标的原始文本的模型，但是通过给人类提供选定的或部分标注的敏感词汇，可以使得生产系统的准确性更高。本文提出了一个名为2SDiac的多源模型，可以有效地支持输入中的可选音标以确定所有预测的输出。此外，本文还引入了一种称为Guided Learning的训练策略，可以利用给定的输入音标和不同等级的随机掩蔽来提升标注的正确性。我们展示了测试期间提供的标注能够影响更多的输出位置，实验结果还表明，我们的方法可以在非标记文本上表现出优异的效果，并且可以在减少60%的参数数目的情况下实现最先进的结果。

    Automatic Arabic diacritization is useful in many applications, ranging from reading support for language learners to accurate pronunciation predictor for downstream tasks like speech synthesis. While most of the previous works focused on models that operate on raw non-diacritized text, production systems can gain accuracy by first letting humans partly annotate ambiguous words. In this paper, we propose 2SDiac, a multi-source model that can effectively support optional diacritics in input to inform all predictions. We also introduce Guided Learning, a training scheme to leverage given diacritics in input with different levels of random masking. We show that the provided hints during test affect more output positions than those annotated. Moreover, experiments on two common benchmarks show that our approach i) greatly outperforms the baseline also when evaluated on non-diacritized text; and ii) achieves state-of-the-art results while reducing the parameter count by over 60%.
    
[^51]: 语法感知的混合提示模型用于小样本多模态情感分析

    Syntax-aware Hybrid prompt model for Few-shot multi-modal sentiment analysis. (arXiv:2306.01312v1 [cs.CL])

    [http://arxiv.org/abs/2306.01312](http://arxiv.org/abs/2306.01312)

    本文提出了一种语法感知的混合提示模型，用于多模态少样本情感分析，通过融合手工提示和可学习提示，利用注意机制优化提示编码器，显著提高了分析性能。

    

    多模态情感分析在自然语言处理中是当前一个热门话题，主要针对句子和方面级别。然而，现有方法几乎都需要大规模的标记数据集，这会带来大量的时间和资源消耗。因此，研究跨模态的少样本情感分析方法是很实用的。先前的研究主要执行在文本模式，使用基于提示的方法，主要有两种类型：手工提示和可学习提示。在小样本多模态情感分析任务中，现有方法已分别使用了这两种方法。我们进一步设计了一种混合模式，可以结合一个或多个固定的手工提示和可学习提示，并利用注意机制来优化提示编码器。在句子级和方面级数据集上的实验表明，我们得到了显着的性能提升。

    Multimodal Sentiment Analysis (MSA) has been a popular topic in natural language processing nowadays, at both sentence and aspect level. However, the existing approaches almost require large-size labeled datasets, which bring about large consumption of time and resources. Therefore, it is practical to explore the method for few-shot sentiment analysis in cross-modalities. Previous works generally execute on textual modality, using the prompt-based methods, mainly two types: hand-crafted prompts and learnable prompts. The existing approach in few-shot multi-modality sentiment analysis task has utilized both methods, separately. We further design a hybrid pattern that can combine one or more fixed hand-crafted prompts and learnable prompts and utilize the attention mechanisms to optimize the prompt encoder. The experiments on both sentence-level and aspect-level datasets prove that we get a significant outperformance.
    
[^52]: 使用ChatGPT进行列类型注释

    Column Type Annotation using ChatGPT. (arXiv:2306.00745v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00745](http://arxiv.org/abs/2306.00745)

    本论文介绍了一种使用ChatGPT进行列类型注释的方法，并比较了不同的提示设计策略。实验结果表明，使用说明作为提示的ChatGPT在列类型注释方面取得了良好的性能，并能够根据任务定义进行灵活的注释。

    

    列类型注释是将关系表的列标注为每列中包含的值的语义类型的任务。列类型注释是数据湖环境中数据检索和数据集成的重要预处理步骤。目前最先进的列类型注释方法要么依赖于将表列与知识图的属性进行匹配，要么对列类型注释使用预训练的语言模型（如BERT）进行微调。在这项工作中，我们采用不同的方法，探究使用ChatGPT进行列类型注释。我们在零样本和少样本情况下评估了不同的提示设计，并尝试向模型提供任务定义和详细说明。我们还实现了一个两步的表格注释流程，首先确定表中描述的实体的类别，然后根据这个类别，使用ChatGPT对列进行注释，仅使用整体词汇表的相关子集。使用说明作为提示的ChatGPT在列类型注释方面表现良好，并且能够根据任务定义进行灵活的注释。

    Column type annotation is the task of annotating the columns of a relational table with the semantic type of the values contained in each column. Column type annotation is an important pre-processing step for data search and data integration in the context of data lakes. State-of-the-art column type annotation methods either rely on matching table columns to properties of a knowledge graph or fine-tune pre-trained language models such as BERT for column type annotation. In this work, we take a different approach and explore using ChatGPT for column type annotation. We evaluate different prompt designs in zero- and few-shot settings and experiment with providing task definitions and detailed instructions to the model. We further implement a two-step table annotation pipeline which first determines the class of the entities described in the table and depending on this class asks ChatGPT to annotate columns using only the relevant subset of the overall vocabulary. Using instructions as we
    
[^53]: 遗忘的知识：审视自然语言处理中的引文健忘现象

    Forgotten Knowledge: Examining the Citational Amnesia in NLP. (arXiv:2305.18554v1 [cs.CL])

    [http://arxiv.org/abs/2305.18554](http://arxiv.org/abs/2305.18554)

    本文系统地和实证地考察了自然语言处理(NLP)领域内的引文模式，证明了大约62%的引用论文属于出版前五年，只有约17%的论文超过十年。目前，NLP论文的引用年龄趋于历史最低水平，这个趋势与此前相反。

    

    引用论文是现代科学写作讨论和建立先前工作的主要方法。全面地引用一组多样化(时间和研究领域)的论文是衡量社区阅读广泛程度的指标。然而，鲜有研究探讨引文的广泛时间模式。本研究系统地和实证地考察了自然语言处理领域内的引文重要性，探讨了我们引用论文时往回追溯多少年的问题，引用时间的变化趋势，以及有哪些因素与这种引文注意力/健忘状态相关。我们分析了约71.5K篇论文，选择了自然语言处理作为我们感兴趣的领域，并证明并量化了引用中的几个关键趋势。特别地，我们发现，大约62%的引用论文属于在出版前五年的论文，而只有约17%的论文超过十年。此外，我们发现引用论文的年龄中位数和年龄多样性从1990年到2014年持续增加，但自那时起，这个趋势已经逆转，目前自然语言处理论文的引文年龄还创历史最低点。

    Citing papers is the primary method through which modern scientific writing discusses and builds on past work. Collectively, citing a diverse set of papers (in time and area of study) is an indicator of how widely the community is reading. Yet, there is little work looking at broad temporal patterns of citation. This work systematically and empirically examines: How far back in time do we tend to go to cite papers? How has that changed over time, and what factors correlate with this citational attention/amnesia? We chose NLP as our domain of interest and analyzed approximately 71.5K papers to show and quantify several key trends in citation. Notably, around 62% of cited papers are from the immediate five years prior to publication, whereas only about 17% are more than ten years old. Furthermore, we show that the median age and age diversity of cited papers were steadily increasing from 1990 to 2014, but since then, the trend has reversed, and current NLP papers have an all-time low tem
    
[^54]: ChatGPT：AI生成内容的挑战与解决方案综述

    A Survey on ChatGPT: AI-Generated Contents, Challenges, and Solutions. (arXiv:2305.18339v1 [cs.CY])

    [http://arxiv.org/abs/2305.18339](http://arxiv.org/abs/2305.18339)

    本论文探讨了AI生成内容的工作原理、安全与隐私威胁、现状和未来挑战，并提供了针对这些问题的最新解决方案。

    

    随着大型人工智能模型比如ChatGPT的普及使用，AI生成内容（AIGC）日益受到关注，正在引领内容创作和知识表示方式实现范式转变。AIGC利用生成式大型AI算法来辅助或替代人类，根据用户提供的提示以更快的速度和更低的成本创建大规模、高质量和类人的内容。尽管在AIGC方面取得了显著进展，但安全、隐私、伦理和法律挑战仍需解决。本文深入调查了AIGC范式的工作原理、安全和隐私威胁、最新解决方案和未来挑战。具体而言，我们首先探讨了AIGC的技术实现、总体架构，并讨论了其工作模式和关键特征。然后，我们调查了针对AIGC的安全和隐私威胁分类法，并强调了GPT和AIGC技术的伦理和社会影响。接下来，我们全面回顾了现有的解决方案，以解决已确定的挑战，并讨论了AIGC领域未来的研究方向。最后，我们总结了我们的发现，并提出了一些未来发展AIGC的潜在研究方向。

    With the widespread use of large artificial intelligence (AI) models such as ChatGPT, AI-generated content (AIGC) has garnered increasing attention and is leading a paradigm shift in content creation and knowledge representation. AIGC uses generative large AI algorithms to assist or replace humans in creating massive, high-quality, and human-like content at a faster pace and lower cost, based on user-provided prompts. Despite the recent significant progress in AIGC, security, privacy, ethical, and legal challenges still need to be addressed. This paper presents an in-depth survey of working principles, security and privacy threats, state-of-the-art solutions, and future challenges of the AIGC paradigm. Specifically, we first explore the enabling technologies, general architecture of AIGC, and discuss its working modes and key characteristics. Then, we investigate the taxonomy of security and privacy threats to AIGC and highlight the ethical and societal implications of GPT and AIGC tec
    
[^55]: 语言模型是有限实用说话者

    Language Models are Bounded Pragmatic Speakers. (arXiv:2305.17760v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17760](http://arxiv.org/abs/2305.17760)

    本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。经过人类反馈的强化学习微调的大型语言模型具有概念上类似于 快与慢思考模型的思维模型，而这种思维模型被归因于人类。此研究凸显了采用认知概率建模方法对语言模型的理解、评估和推进的价值。

    

    本文提出了一个概率认知模型，称为有限实用说话者，用于表征不同变体的语言模型的操作方式。特别地，我们展示了经过人类反馈的强化学习微调的大型语言模型（Ouyang等人，2022）具有概念上类似于 快与慢思考模型（Kahneman，2011）的思维模型，而这种思维模型被心理学家们归因于人类。我们讨论了从人类反馈中的强化学习作为快与慢思考模型的局限性，并提出了扩展这个框架的途径。本研究实质上凸显了采用认知概率建模方法来获得对语言模型的理解、评估和推进方面的深刻见解的价值。

    How do language models "think"? This paper formulates a probabilistic cognitive model called the bounded pragmatic speaker, which can characterize the operation of different variations of language models. Specifically, we demonstrate that large language models fine-tuned with reinforcement learning from human feedback (Ouyang et al., 2022) embody a model of thought that conceptually resembles a fast-and-slow model (Kahneman, 2011), which psychologists have attributed to humans. We discuss the limitations of reinforcement learning from human feedback as a fast-and-slow model of thought and propose avenues for expanding this framework. In essence, our research highlights the value of adopting a cognitive probabilistic modeling approach to gain insights into the comprehension, evaluation, and advancement of language models.
    
[^56]: 在ChatGPT、大型语言模型和生成AI时代的科学：研究伦理的挑战及应对方法

    Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond. (arXiv:2305.15299v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2305.15299](http://arxiv.org/abs/2305.15299)

    这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。

    

    人工智能的大型语言模型（如ChatGPT）在科学研究中具有显著但有争议的应用。本文回顾了生成AI时代科学研究的认识论挑战、伦理和诚信风险，并旨在为高质量的研究伦理审查奠定新的及时基础。对AI语言模型作为研究工具和研究对象的角色进行了详细审查，并讨论了对科学家、参与者和评审人员的伦理影响。讨论了研究伦理审查的新兴实践，并给出了十项建议，为在AI时代更负责任的研究进行回应。

    Large language models of artificial intelligence (AI), such as ChatGPT, find remarkable but controversial applicability in science and research. This paper reviews epistemological challenges, ethical and integrity risks in science conduct in the advent of generative AI. This is with the aim to lay new timely foundations for a high-quality research ethics review. The role of AI language models as a research instrument and subject is scrutinized along with ethical implications for scientists, participants and reviewers. New emerging practices for research ethics review are discussed, concluding with ten recommendations that shape a response for a more responsible research conduct in the era of AI.
    
[^57]: 基于深度迁移学习的自动语音识别：迈向更好的泛化

    Deep Transfer Learning for Automatic Speech Recognition: Towards Better Generalization. (arXiv:2304.14535v1 [cs.SD])

    [http://arxiv.org/abs/2304.14535](http://arxiv.org/abs/2304.14535)

    本文Survey了基于DTL的ASR框架，并介绍了如何使用实际数据集进行深度迁移学习以达到更好的泛化性能。

    

    最近，深度学习在自动语音识别（ASR）方面面临着一个重要的挑战，这需要大规模的训练数据集和高计算和存储资源。此外，机器学习（ML）方法和深度学习技术通常假设训练和测试数据来自相同的域，具有相同的输入特征空间和数据分布特性。然而，在一些现实世界的人工智能（AI）应用中，这种假设是无法适用的。DTL被引入来克服这些问题，它有助于使用实际数据集开发高性能的模型，这些实际数据集即使很小或稍有不同，但与训练数据相关。本文提出了基于DTL的ASR框架的全面调查，以阐明最新的发展。

    Automatic speech recognition (ASR) has recently become an important challenge when using deep learning (DL). It requires large-scale training datasets and high computational and storage resources. Moreover, DL techniques and machine learning (ML) approaches in general, hypothesize that training and testing data come from the same domain, with the same input feature space and data distribution characteristics. This assumption, however, is not applicable in some real-world artificial intelligence (AI) applications. Moreover, there are situations where gathering real data is challenging, expensive, or rarely occurring, which can not meet the data requirements of DL models. deep transfer learning (DTL) has been introduced to overcome these issues, which helps develop high-performing models using real datasets that are small or slightly different but related to the training data. This paper presents a comprehensive survey of DTL-based ASR frameworks to shed light on the latest developments 
    
[^58]: 大型语言模型在医疗保健领域中准备就绪了吗？临床语言理解的比较研究。

    Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding. (arXiv:2304.05368v1 [cs.CL])

    [http://arxiv.org/abs/2304.05368](http://arxiv.org/abs/2304.05368)

    本研究全面评估了大型语言模型在临床语言理解任务上的表现，并引入自问自答提示策略来提高LLMs在医疗保健相关任务中的效果。

    

    大型语言模型（LLMs）在各个领域取得了显著的进展，包括医疗保健领域。然而，临床语言理解任务的专业性质带来了独特的挑战和限制，需要进一步研究。在本研究中，我们对最先进的LLMs——GPT-3.5、GPT-4和Bard进行了全面评估，该评估范围涵盖了各种任务，包括命名实体识别、关系提取、自然语言推理、语义文本相似性、文档分类和问答。我们还引入了一种新的提示策略——自问自答提示（SQP），旨在通过引发与相关临床场景相关的信息性问题和答案，定制化提高LLMs的性能。我们的评估强调了任务特定的学习策略和提示技术对于提高LLMs在医疗保健相关任务中的有效性的重要性。

    Large language models (LLMs) have made significant progress in various domains, including healthcare. However, the specialized nature of clinical language understanding tasks presents unique challenges and limitations that warrant further investigation. In this study, we conduct a comprehensive evaluation of state-of-the-art LLMs, namely GPT-3.5, GPT-4, and Bard, within the realm of clinical language understanding tasks. These tasks span a diverse range, including named entity recognition, relation extraction, natural language inference, semantic textual similarity, document classification, and question-answering. We also introduce a novel prompting strategy, self-questioning prompting (SQP), tailored to enhance LLMs' performance by eliciting informative questions and answers pertinent to the clinical scenarios at hand. Our evaluation underscores the significance of task-specific learning strategies and prompting techniques for improving LLMs' effectiveness in healthcare-related tasks.
    
[^59]: ChatGPT塑造牙科未来：多模态大语言模型的潜力

    ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model. (arXiv:2304.03086v1 [cs.CL])

    [http://arxiv.org/abs/2304.03086](http://arxiv.org/abs/2304.03086)

    本文讨论了利用LLMs在牙科临床领域实现自动化和跨模态诊断的可能性，介绍了利用跨模态编码器进行高级自然语言推理的多模态LLM AI系统，展示了其在牙科临床中的巨大潜力。

    

    ChatGPT是OpenAI开发的Generative Pretrained Transformer 4（GPT-4）的精简和对话变体，具有数十亿个参数的里程碑式大语言模型之一。事实上，LLMs在自然语言处理任务中展现出的印象深刻能力引起了研究人员和实践者的极大兴趣，对各个领域产生了深远的影响。本文主要讨论LLMs在牙科领域的未来应用。我们介绍了两种主要的LLM部署方法，包括自动牙科诊断和跨模态牙科诊断，并探讨了它们的潜在应用。特别地，配备跨模态编码器，单个LLM可以管理多源数据并进行高级自然语言推理，以执行复杂的临床操作。通过一个案例来展示针对牙科临床应用的完全自动化的多模态LLM AI系统的潜力。虽然LLMs在提供巨大的潜力方面取得了显著的进展，

    The ChatGPT, as a lite and conversational variant of Generative Pretrained Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large Language Models (LLMs) with billions of parameters. LLMs, in fact, have stirred up a lot of interest among researchers and practitioners by their impressive skills in natural language processing tasks, which have a profound impact on a wide range of fields. This paper mainly discusses the future applications of LLMs in dentistry. We introduce two primary LLM deployment methods in dentistry, including automated dental diagnosis and cross-modal dental diagnosis, and examine their potential applications. Especially, equipped with a cross-modal encoder, a single LLM can manage multi-source data and conduct advanced natural language reasoning to perform complex clinical operations. A use case is presented to demonstrate the potential of a fully automatic Multi-Modal LLM AI system for dentistry clinical application. While LLMs offer significant p
    
[^60]: SPDF：大规模语言模型的稀疏预训练和密集微调

    SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models. (arXiv:2303.10464v1 [cs.LG])

    [http://arxiv.org/abs/2303.10464](http://arxiv.org/abs/2303.10464)

    本文提出了SPDF算法来实现大规模语言模型的高效训练。通过非结构化权重稀疏性来进行预训练，可以降低计算成本，而密集微调则可以保证高性能的表现。

    

    预训练和微调范式为自然语言处理（NLP）的多项突破做出了贡献。语言模型首先在大型数据集上进行跨域知识的预训练（例如，Pile、MassiveText等），然后在特定任务的数据上进行微调（例如，自然语言生成、文本摘要等）。虽然扩大模型和数据集大小有助于提高LLM性能，但这也带来了极为禁止性的计算成本。预训练LLMs通常需要比微调演习更多的FLOPs，两个阶段之间的模型容量通常保持不变。为了实现相对于训练FLOPs的训练效率，我们建议在两个阶段之间解耦模型容量，并引入稀疏预训练和密集微调（SPDF）。在这项工作中，我们展示了使用非结构化权重稀疏性来仅训练子集权重的好处。

    The pre-training and fine-tuning paradigm has contributed to a number of breakthroughs in Natural Language Processing (NLP). Instead of directly training on a downstream task, language models are first pre-trained on large datasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then fine-tuned on task-specific data (e.g., natural language generation, text summarization, etc.). Scaling the model and dataset size has helped improve the performance of LLMs, but unfortunately, this also leads to highly prohibitive computational costs. Pre-training LLMs often require orders of magnitude more FLOPs than fine-tuning and the model capacity often remains the same between the two phases. To achieve training efficiency w.r.t training FLOPs, we propose to decouple the model capacity between the two phases and introduce Sparse Pre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits of using unstructured weight sparsity to train only a subset of weights during 
    
[^61]: 一种用于领域外意图检测和意图发现的混合架构

    A Hybrid Architecture for Out of Domain Intent Detection and Intent Discovery. (arXiv:2303.04134v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04134](http://arxiv.org/abs/2303.04134)

    本研究提出了一种混合架构来解决任务导向型对话系统中领域外意图检测和意图发现的问题。通过使用变分自编码器和无监督聚类方法，可以准确识别和区分已知和未知的意图，并发现潜藏在领域外输入中的不同未知意图。

    

    意图检测是任务导向型对话系统中自然语言理解（NLU）模块的任务之一。领域外（OOS）和领域外（OOD）的输入可能会给这些系统带来问题。另一方面，训练任务导向型对话系统中意图检测模型需要标记的数据集。创建标记数据集耗时且需要人力资源。本文旨在解决上述问题。将识别OOD/OOS输入的任务命名为OOD/OOS意图检测。同时，发现新的意图并对OOD输入进行伪标记，则被称为意图发现。在OOD意图检测部分，我们利用变分自编码器来区分已知意图和未知意图，独立于输入数据分布。之后，使用无监督聚类方法来发现OOD/OOS输入中不同的未知意图。我们还对OOD/OOS表示应用非线性降维。

    Intent Detection is one of the tasks of the Natural Language Understanding (NLU) unit in task-oriented dialogue systems. Out of Scope (OOS) and Out of Domain (OOD) inputs may run these systems into a problem. On the other side, a labeled dataset is needed to train a model for Intent Detection in task-oriented dialogue systems. The creation of a labeled dataset is time-consuming and needs human resources. The purpose of this article is to address mentioned problems. The task of identifying OOD/OOS inputs is named OOD/OOS Intent Detection. Also, discovering new intents and pseudo-labeling of OOD inputs is well known by Intent Discovery. In OOD intent detection part, we make use of a Variational Autoencoder to distinguish between known and unknown intents independent of input data distribution. After that, an unsupervised clustering method is used to discover different unknown intents underlying OOD/OOS inputs. We also apply a non-linear dimensionality reduction on OOD/OOS representations
    
[^62]: 基于能力的语言模型分析

    Competence-Based Analysis of Language Models. (arXiv:2303.00333v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.00333](http://arxiv.org/abs/2303.00333)

    该论文提出了一个基于能力的语言模型分析框架CALM，通过有针对性的干预来破坏语言模型的内部表示，评估其在执行任务时对不同表示的使用。研究表明，语言模型对关系属性的利用存在一定的不一致性。

    

    尽管大型预训练语言模型（LMs）在各种提示任务上取得了显著成功，但这些模型对输入或应用环境中的微小变化却异常脆弱。为了更好地理解这种行为并激励设计更健壮的LMs，我们提出了一个通用的实验框架CALM（基于能力的语言模型分析），其中利用有针对性的因果干预来破坏LM在各种语言属性上的内部表示，以评估它在执行给定任务时对每个表示的使用。我们将这些干预实现为基于梯度的对抗攻击，与先前的因果探查方法相比，它们能够针对任意编码的关系属性进行攻击，并进行了一个案例研究，分析了BERT-like LMs在执行相关关系提示任务时如何使用多种关系属性的表示。我们发现，虽然表示的选择对LM的性能产生了影响，但模型对某些特定关系属性的利用并不一致。

    Despite the recent success of large pretrained language models (LMs) on a variety of prompting tasks, these models can be alarmingly brittle to small changes in inputs or application contexts. To better understand such behavior and motivate the design of more robust LMs, we propose a general experimental framework, CALM (Competence-based Analysis of Language Models), where targeted causal interventions are utilized to damage an LM's internal representation of various linguistic properties in order to evaluate its use of each representation in performing a given task. We implement these interventions as gradient-based adversarial attacks, which (in contrast to prior causal probing methodologies) are able to target arbitrarily-encoded representations of relational properties, and carry out a case study of this approach to analyze how BERT-like LMs use representations of several relational properties in performing associated relation prompting tasks. We find that, while the representation
    
[^63]: MEAformer: 多模式实体对齐变压器用于元模态混合

    MEAformer: Multi-modal Entity Alignment Transformer for Meta Modality Hybrid. (arXiv:2212.14454v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.14454](http://arxiv.org/abs/2212.14454)

    该论文提出了一种适用于元模态混合的多模式实体对齐变压器方法，通过动态预测模态之间的相互关联系数以进行实体级特征聚合，进一步提出了一种模态感知的硬实体重播策略，用于解决模糊实体细节的问题。该模型在多个训练场景中实现了SOTA性能并有效提高了MMEA的鲁棒性。

    

    作为实体对齐（EA）的一个重要变体，多模式实体对齐（MMEA）旨在发现不同知识图谱（KGs）中具有相关图像的相同实体。 我们注意到，当前的MMEA算法都全局采用KG级模态融合策略进行多模式实体表示，但忽略了个体实体的模态偏好变化，从而削弱了对模态（例如模糊图像和关系）中潜在噪声的鲁棒性。在本文中，我们提出了MEAformer，一种适用于元模态混合的多模式实体对齐变压器方法，该方法动态预测模态之间的相互关联系数以进行实体级特征聚合。进一步提出了一种模态感知的硬实体重播策略，用于解决模糊实体细节的问题。实验结果表明，我们的模型不仅在多个训练场景（包括有监督、无监督、迭代和低资源设置）中实现了SOTA性能，而且通过利用模态偏好变化有效提高了MMEA的鲁棒性。

    As an important variant of entity alignment (EA), multi-modal entity alignment (MMEA) aims to discover identical entities across different knowledge graphs (KGs) with relevant images attached. We noticed that current MMEA algorithms all globally adopt the KG-level modality fusion strategies for multi-modal entity representation but ignore the variation in modality preferences for individual entities, hurting the robustness to potential noise involved in modalities (e.g., blurry images and relations). In this paper, we present MEAformer, a multi-modal entity alignment transformer approach for meta modality hybrid, which dynamically predicts the mutual correlation coefficients among modalities for entity-level feature aggregation. A modal-aware hard entity replay strategy is further proposed for addressing vague entity details. Experimental results show that our model not only achieves SOTA performance on multiple training scenarios including supervised, unsupervised, iterative, and low 
    
[^64]: 通过合成开放领域对话来增强任务机器人的参与度

    Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog. (arXiv:2212.10008v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10008](http://arxiv.org/abs/2212.10008)

    本论文提出了一种通过合成开放领域对话来增强任务机器人的参与度的框架，并介绍了一种统一模型PivotBot，该模型能够无缝切换任务导向对话和开放领域对话，在处理融合任务方面具有优越能力。

    

    已经进行了许多努力来构建适用于不同类型对话的对话系统，如任务导向对话（TOD）和开放领域对话（ODD）。为了更好地模仿人类级别的对话，通常需要融合各种对话模式，并建立一个可以有效处理TOD和ODD，并访问不同知识源的系统。为了解决融合任务缺乏可用数据的问题，我们提出了一个框架，用于自动生成在不同环境中结合了知识为基础的ODD和TOD的对话。此外，我们介绍了一个统一模型PivotBot，能够适当地采用TOD和ODD模式，并访问不同的知识源，以便有效地处理融合任务。评估结果表明，所提出的模型在TOD和ODD任务之间无缝切换的能力优于其他模型。

    Many efforts have been made to construct dialog systems for different types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD). To better mimic human-level conversations that usually fuse various dialog modes, it is essential to build a system that can effectively handle both TOD and ODD and access different knowledge sources. To address the lack of available data for the fused task, we propose a framework for automatically generating dialogues that combine knowledge-grounded ODDs and TODs in various settings. Additionally, we introduce a unified model PivotBot that is capable of appropriately adopting TOD and ODD modes and accessing different knowledge sources in order to effectively tackle the fused task. Evaluation results demonstrate the superior ability of the proposed model to switch seamlessly between TOD and ODD tasks.
    
[^65]: 别忘了你的ABC：评估聊天导向对话系统的最新进展

    Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems. (arXiv:2212.09180v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09180](http://arxiv.org/abs/2212.09180)

    本文提出了一种可靠的维度化评估人机聊天的新方法，并评估了一组最先进的开放领域聊天机器人，为未来聊天导向对话系统的发展提供了基准。

    

    人机聊天交互领域近来取得了巨大进展，然而，适当的评估仍需要人类主观判断，因此评测指标易出现高方差问题。此外，当前评估方法和标准缺乏规范性，缺乏用于评估有效性的工作。因此，现有的评估结果可能无法完整反映开放领域聊天机器人的优点和缺陷。我们旨在实现对人机聊天的维度化评估，可可靠地测量聊天质量的几个不同方面。为此，我们提出了一种新颖的人类评估方法，量化了几种与质量相关的机器人聊天行为。我们的结果表明，我们的方法比替代的Likert-style或比较方法更适合评估维度化聊天。然后，我们使用我们验证的方法和现有方法来评估一组最先进的开放领域聊天机器人，并全面比较了它们在几个质量维度上的性能。我们的结果突显了现有开放领域聊天机器人技术的持续优势和限制，并为聊天导向对话系统的未来发展提供了基准。

    There has been great recent advancement in human-computer chat. However, proper evaluation currently requires human judgements that produce notoriously high-variance metrics due to their inherent subjectivity. Furthermore, there is little standardization in the methods and labels used for evaluation, with an overall lack of work to compare and assess the validity of various evaluation approaches. As a consequence, existing evaluation results likely leave an incomplete picture of the strengths and weaknesses of open-domain chatbots. We aim towards a dimensional evaluation of human-computer chat that can reliably measure several distinct aspects of chat quality. To this end, we present our novel human evaluation method that quantifies the rate of several quality-related chatbot behaviors. Our results demonstrate our method to be more suitable for dimensional chat evaluation than alternative likert-style or comparative methods. We then use our validated method and existing methods to eval
    
[^66]: 对话中的噪音来源及其处理方法

    Sources of Noise in Dialogue and How to Deal with Them. (arXiv:2212.02745v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.02745](http://arxiv.org/abs/2212.02745)

    本文构建了对话系统噪音分类体系，并研究了不同模型在不同噪音下的行为。结果显示模型对标签错误鲁棒性较高，但在对话特定噪音下性能下降。在此基础上，设计了一种专门用于会话环境的数据清洗算法，并进行了针对性的对话去噪概念验证。

    

    训练对话系统常常需要处理噪音干扰和意外用户输入。尽管这些问题很普遍，但目前缺乏对对话噪音的准确调查，也没有对每种噪音类型对任务性能的影响有清晰的认识。本文首先构建了对话系统遇到的噪音分类体系。此外，我们进行了一系列实验，展示了不同模型在不同程度和类型的噪音下的行为。我们的结果显示，模型对常见标签错误非常鲁棒，但在对话特定噪音下性能下降。基于这些观察，我们设计了一种专门用于会话环境的数据清洗算法，并将其作为有针对性的对话去噪概念验证。

    Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs. Despite their prevalence, there currently lacks an accurate survey of dialogue noise, nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise. Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise. Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.
    
[^67]: X$^2$-VLM: 全能的视觉-语言任务预训练模型

    X$^2$-VLM: All-In-One Pre-trained Model For Vision-Language Tasks. (arXiv:2211.12402v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.12402](http://arxiv.org/abs/2211.12402)

    X$^2$-VLM是一个全能的视觉-语言任务预训练模型，利用统一的框架实现了多粒度的视觉-语言对齐和定位，并在一个模型中统一了图像-文本和视频-文本预训练。实验结果显示，X$^2$-VLM在各种任务上表现最好，并且在性能和模型规模之间取得了良好的平衡。

    

    视觉-语言预训练旨在从大量数据中学习视觉和语言之间的对齐。大多数现有的方法只学习图像-文本对齐。其他一些方法利用预先训练的物体检测器在对象级别上利用视觉-语言对齐。本文提出了一种统一的预训练框架，同时学习多粒度的视觉-语言对齐和多粒度的定位，从而实现多粒度的视觉-语言对齐。基于此，我们提出了全能模型X$^2$-VLM，具有灵活的模块化架构，在一个模型中进一步统一了图像-文本预训练和视频-文本预训练。X$^2$-VLM能够学习与多样的文本描述相关的无限视觉概念。实验结果显示，X$^2$-VLM在图像-文本和视频-文本任务的基础和大规模上表现最好，在性能和模型规模之间取得了良好的平衡。此外，我们还展示了X$^2$-VLM的模块化设计导致了...

    Vision language pre-training aims to learn alignments between vision and language from a large amount of data. Most existing methods only learn image-text alignments. Some others utilize pre-trained object detectors to leverage vision language alignments at the object level. In this paper, we propose to learn multi-grained vision language alignments by a unified pre-training framework that learns multi-grained aligning and multi-grained localization simultaneously. Based on it, we present X$^2$-VLM, an all-in-one model with a flexible modular architecture, in which we further unify image-text pre-training and video-text pre-training in one model. X$^2$-VLM is able to learn unlimited visual concepts associated with diverse text descriptions. Experiment results show that X$^2$-VLM performs the best on base and large scale for both image-text and video-text tasks, making a good trade-off between performance and model scale. Moreover, we show that the modular design of X$^2$-VLM results in
    
[^68]: 同性质的表示可以改善密集检索

    Isotropic Representation Can Improve Dense Retrieval. (arXiv:2209.00218v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.00218](http://arxiv.org/abs/2209.00218)

    本研究发现BERT-based DR遵循非均匀分布，为了解决这个问题，我们引入了正则化流和白化的后处理方法，并开发了单词级方法来应用这些后处理方法，实验证明这些方法能够有效地增强表示的同性质。

    

    最近语言表示建模的进展广泛影响了密集检索模型的设计。特别是，许多高性能的密集检索模型使用BERT评估查询和文档的表示，并随后应用基于余弦相似度的评分来确定相关性。然而，已知BERT表示遵循一个狭窄锥形的非均匀分布，这种非均匀分布对于基于余弦相似度的评分可能是不可取的。在这项工作中，我们首先展示了基于BERT的密集检索模型也遵循非均匀分布。为了应对这个问题，我们引入了无监督的后处理方法：正则化流和白化，并开发了单词级方法来将这些后处理方法应用到密集检索模型的表示中。我们展示了所提出的方法能够有效地增强表示的同性质，然后我们进行了实验。

    The recent advancement in language representation modeling has broadly affected the design of dense retrieval models. In particular, many of the high-performing dense retrieval models evaluate representations of query and document using BERT, and subsequently apply a cosine-similarity based scoring to determine the relevance. BERT representations, however, are known to follow an anisotropic distribution of a narrow cone shape and such an anisotropic distribution can be undesirable for the cosine-similarity based scoring. In this work, we first show that BERT-based DR also follows an anisotropic distribution. To cope with the problem, we introduce unsupervised post-processing methods of Normalizing Flow and whitening, and develop token-wise method in addition to the sequence-wise method for applying the post-processing methods to the representations of dense retrieval models. We show that the proposed methods can effectively enhance the representations to be isotropic, then we perform e
    
[^69]: 通过自监督提升跨领域语音识别能力

    Boosting Cross-Domain Speech Recognition with Self-Supervision. (arXiv:2206.09783v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2206.09783](http://arxiv.org/abs/2206.09783)

    本研究提出了一个系统的无监督领域自适应框架，通过使用自监督和伪标签方法来提升跨领域语音识别的性能。

    

    自动语音识别（ASR）的跨领域性能可能受到训练和测试分布之间的不匹配的严重阻碍。由于目标领域通常缺乏标记数据，并且声学和语言层面存在领域转移，因此对ASR进行无监督领域自适应（UDA）是具有挑战性的。先前的研究表明，通过利用无标签数据的自监督学习（SSL）或伪标签（PL），可以在UDA中发挥作用。然而，这些自监督也面临着不匹配领域分布的性能降低问题，这是之前的研究没有解决的。本文提出了一个系统的UDA框架，以充分利用预训练和微调范式中的无标签数据的自监督。一方面，我们应用了持续的预训练和数据重放技术来减轻SSL预训练模型的领域不匹配。另一方面，我们提出了一种领域自适应微调方法。

    The cross-domain performance of automatic speech recognition (ASR) could be severely hampered due to the mismatch between training and testing distributions. Since the target domain usually lacks labeled data, and domain shifts exist at acoustic and linguistic levels, it is challenging to perform unsupervised domain adaptation (UDA) for ASR. Previous work has shown that self-supervised learning (SSL) or pseudo-labeling (PL) is effective in UDA by exploiting the self-supervisions of unlabeled data. However, these self-supervisions also face performance degradation in mismatched domain distributions, which previous work fails to address. This work presents a systematic UDA framework to fully utilize the unlabeled data with self-supervision in the pre-training and fine-tuning paradigm. On the one hand, we apply continued pre-training and data replay techniques to mitigate the domain mismatch of the SSL pre-trained model. On the other hand, we propose a domain-adaptive fine-tuning approach
    
[^70]: 探究语法数的使用情况

    Probing for the Usage of Grammatical Number. (arXiv:2204.08831v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.08831](http://arxiv.org/abs/2204.08831)

    本文介绍了一种基于使用的探测设置，通过干预模型的表示来去除属性，从而发现模型实际使用的编码。以BERT如何编码语法数为例研究，结果显示BERT依赖于语法数的线性编码来产生正确的行为输出，并对名词和动词的语法数使用了不同的编码。

    

    探究的核心问题是揭示预训练模型如何在其表示中编码语言属性。然而，编码可能是虚假的，即模型在进行预测时可能不依赖于它。在本文中，我们尝试寻找模型实际使用的编码，引入一种基于使用的探测设置。我们首先选择一个行为任务，该任务在不使用语言属性的情况下无法解决。然后，我们试图通过干预模型的表示来去除属性。我们认为，如果模型使用了某种编码，去除该编码应该会损害所选择的行为任务的性能。以BERT如何编码语法数以及如何利用该编码解决数的一致性任务为案例研究。实验结果显示，BERT依赖于语法数的线性编码来产生正确的行为输出。我们还发现BERT对名词和动词的语法数使用了不同的编码。

    A central quest of probing is to uncover how pre-trained models encode a linguistic property within their representations. An encoding, however, might be spurious-i.e., the model might not rely on it when making predictions. In this paper, we try to find encodings that the model actually uses, introducing a usage-based probing setup. We first choose a behavioral task which cannot be solved without using the linguistic property. Then, we attempt to remove the property by intervening on the model's representations. We contend that, if an encoding is used by the model, its removal should harm the performance on the chosen behavioral task. As a case study, we focus on how BERT encodes grammatical number, and on how it uses this encoding to solve the number agreement task. Experimentally, we find that BERT relies on a linear encoding of grammatical number to produce the correct behavioral output. We also find that BERT uses a separate encoding of grammatical number for nouns and verbs. Fina
    
[^71]: 翻译：汉语拼音是否有助于多语言语言建模？

    Does Transliteration Help Multilingual Language Modeling?. (arXiv:2201.12501v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.12501](http://arxiv.org/abs/2201.12501)

    本文探究了把使用不同书写系统的相近语言音译成同一种书写系统，对于多语言语言模型的提升的影响，发现音译可以提高低资源语言的表现，而不会对资源相对较高的语言产生负面影响。

    

    由于大部分语言缺乏大规模的代表性语料库，对于多语言语言模型（MLLM）来说，从现有的语料库中提取最重要的信息非常重要。在这方面，不同语言的文本表现形式的多样性使得MLLM面临困难，因为相近的语言之间词汇重叠较少。因此，把使用不同书写系统的相近的语言音译成同一种书写系统可以提高MLLM的下游任务表现。本文中，我们预训练两个ALBERT模型，以实证的方式测量音译对MLLM的影响。我们特别关注印度语-雅利安语系，该系在世界上拥有最高的书写系统多样性。然后，我们在IndicGLUE基准测试中对模型进行评估。我们进行曼－惠特尼U检验，以严格验证音译的效果是否显著。我们发现，音译有利于低资源语言，而不会对资源相对较高的语言产生负面影响。

    As there is a scarcity of large representative corpora for most languages, it is important for Multilingual Language Models (MLLM) to extract the most out of existing corpora. In this regard, script diversity presents a challenge to MLLMs by reducing lexical overlap among closely related languages. Therefore, transliterating closely related languages that use different writing scripts to a common script may improve the downstream task performance of MLLMs. In this paper, we pretrain two ALBERT models to empirically measure the effect of transliteration on MLLMs. We specifically focus on the Indo-Aryan language family, which has the highest script diversity in the world. Afterward, we evaluate our models on the IndicGLUE benchmark. We perform Mann-Whitney U test to rigorously verify whether the effect of transliteration is significant or not. We find that transliteration benefits the low-resource languages without negatively affecting the comparatively high-resource languages. We also m
    
[^72]: 通过记忆推理：最近邻知识图嵌入

    Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings. (arXiv:2201.05575v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.05575](http://arxiv.org/abs/2201.05575)

    本文提出了一种新的知识图嵌入方法kNN-KGE，它通过预训练语言模型和最近邻的线性插值，允许罕见或新出现的实体被明确地记忆，而不是隐藏在模型参数中。实验结果显示，该方法能够改善链接预测结果并在低资源环境中表现出更好的性能。

    

    以往的知识图嵌入方法通常将实体映射到表示，并利用评分函数预测目标实体，但它们通常难以推理出罕见或新出现的未知实体。在本文中，我们提出了一种新的知识图嵌入方法kNN-KGE，它利用预训练语言模型，并通过线性插值将其实体分布与k个最近邻相结合。我们根据知识存储中实体嵌入空间中的距离计算最近邻。我们的方法可以明确地记忆罕见或新出现的实体，而不是隐藏在模型参数中。实验结果表明，我们的方法可以改善归纳和传递式链接预测结果，并在只有少量三元组的低资源环境中表现出更好的性能，而这可能更容易通过明确的记忆进行推理。

    Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they typically struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory. Code is available at https://github.com/zjunlp/KNN-KG.
    
[^73]: 将面向查询的摘要生成作为知识密集型任务进行处理：一项试点研究

    Tackling Query-Focused Summarization as A Knowledge-Intensive Task: A Pilot Study. (arXiv:2112.07536v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.07536](http://arxiv.org/abs/2112.07536)

    本研究将查询聚焦摘要生成任务作为一项知识密集型任务进行处理，并提出了一个新的数据集(KI-QFS)。实验结果表明，在无法直接访问相关文档的情况下，QFS模型在KI-QFS上的表现较差。

    

    查询聚焦摘要(QFS)需要在给定查询的情况下，使用相关文档集合生成摘要。然而，在现实场景中这些相关文档需要手动进行注释，因此不一定能即时获得。为了解决这一限制，我们将QFS任务作为一项知识密集型(KI)任务进行处理，不要求直接获取相关文档，而是假定这些文档存在于大规模知识语料库中，并需要首先进行检索。为了探索这个新的设定，我们通过改编现有的QFS数据集构建了一个新的数据集(KI-QFS)。在该数据集中，回答查询需要从知识语料库检索文档。我们构建了三种不同的知识语料库，并进一步提供相关性注释以进行检索评估。最后，我们使用最先进的QFS模型和增强的检索模型对数据集进行了基准测试。实验结果表明，与原始QFS相比，QFS模型在KI-QFS上表现显著较差。

    Query-focused summarization (QFS) requires generating a summary given a query using a set of relevant documents. However, such relevant documents should be annotated manually and thus are not readily available in realistic scenarios. To address this limitation, we tackle the QFS task as a knowledge-intensive (KI) task without access to any relevant documents. Instead, we assume that these documents are present in a large-scale knowledge corpus and should be retrieved first. To explore this new setting, we build a new dataset (KI-QFS) by adapting existing QFS datasets. In this dataset, answering the query requires document retrieval from a knowledge corpus. We construct three different knowledge corpora, and we further provide relevance annotations to enable retrieval evaluation. Finally, we benchmark the dataset with state-of-the-art QFS models and retrieval-enhanced models. The experimental results demonstrate that QFS models perform significantly worse on KI-QFS compared to the origi
    

