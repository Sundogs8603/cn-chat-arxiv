# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Prompt ChatGPT In MNER: Improved multimodal named entity recognition method based on auxiliary refining knowledge from ChatGPT.](http://arxiv.org/abs/2305.12212) | 本文提出了一个叫做 PGIM 的方法，该方法利用 ChatGPT 作为隐式知识引擎来获取辅助精炼知识，从而增强模型在 MNER 任务中的性能。 |
| [^2] | [Self-Distillation with Meta Learning for Knowledge Graph Completion.](http://arxiv.org/abs/2305.12209) | 本文提出了一个基于动态剪枝和元学习自蒸馏的框架，用于解决知识图谱补全中长尾样本问题，并在实验中取得了优于现有最先进方法的效果。 |
| [^3] | [Experimental results from applying GPT-4 to an unpublished formal language.](http://arxiv.org/abs/2305.12196) | GPT-4在一个未发表的正式系统上成功完成了一系列任务，展示了广泛的领域知识，发明了有用的新语法和语义，并展示了泛化和推理能力。 |
| [^4] | [Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs.](http://arxiv.org/abs/2305.12191) | 该论文研究了文档导向对话生成中的保真度问题，并提出了一种基于点互信息的度量方法和解码策略来预测更加保真的回答。 |
| [^5] | [Paragraph-level Citation Recommendation based on Topic Sentences as Queries.](http://arxiv.org/abs/2305.12190) | 该论文提出了一种中间层级的引用建议任务——段落级引用建议，即以段落的主题句为输入，输出在段落中引用的建议，并提出了用于解决此任务的模型。 |
| [^6] | [Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages.](http://arxiv.org/abs/2305.12182) | Glot500是一个水平扩展的语言模型，覆盖了511种低资源语言。相比于XLM-R基线，Glot500展现出了更好的高资源和低资源语言表现。该模型质量的决定因素包括语料库大小、脚本、相关语言的“帮助”和模型的总容量。 |
| [^7] | [Learn to Compose Syntactic and Semantic Representations Appropriately for Compositional Generalization.](http://arxiv.org/abs/2305.12169) | 该研究提出了一个名为COMPSITION的新框架，可以通过适当地组合句法和语义表示来解决组合泛化问题。实验证明该方法在合成和自然语言CG任务上实现了最先进的性能。 |
| [^8] | [Re-visiting Automated Topic Model Evaluation with Large Language Models.](http://arxiv.org/abs/2305.12152) | 本文提出使用大型语言模型来评估主题模型输出，并使用自动化方法确定最佳主题数量。 |
| [^9] | [LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4.](http://arxiv.org/abs/2305.12147) | 该论文提出了LogiCoT, 一个基于GPT-4的逻辑思维指令调整数据集，用于教授模型逻辑推理和引出一般推理技能。 |
| [^10] | [Hedges in Bidirectional Translations of Publicity-Oriented Documents.](http://arxiv.org/abs/2305.12146) | 本文研究了宣传性文件翻译中的措辞处理问题，发现政治文本中的措辞在英文中出现更频繁，且翻译方向影响措辞使用频率和翻译策略。同时还观察到了措辞在历时方面的增加。 |
| [^11] | [Lifting the Curse of Capacity Gap in Distilling Language Models.](http://arxiv.org/abs/2305.12129) | 本文提出了一种新的知识蒸馏方法（MiniMoE），通过增加学生的容量而不明显增加推理计算解除容量差异诅咒，并在GLUE和CoNLL上进行了实验验证。 |
| [^12] | [Modeling the Q-Diversity in a Min-max Play Game for Robust Optimization.](http://arxiv.org/abs/2305.12123) | 本文提出了Q-Diversity，与group DRO较好地配合，通过交互式训练模式直接参数化组的识别，从而提高了模型的泛化能力和鲁棒性。 |
| [^13] | [EE-TTS: Emphatic Expressive TTS with Linguistic Information.](http://arxiv.org/abs/2305.12107) | 该论文提出了一种利用语言信息和强调预测器实现表现力强且自然的TTS系统，并在实验中表现出良好的表现和泛化能力。 |
| [^14] | [Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?.](http://arxiv.org/abs/2305.12096) | 本文研究了最先进的NLP模型能否正确地推理打破常见假设的情况的语境，并系统地创建了相应的评估数据。 |
| [^15] | [ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain.](http://arxiv.org/abs/2305.12092) | 本论文提出了一种名为ESCOXLM-R的多语言语言模型，它使用领域自适应预训练技术，能够成功地处理职业市场领域的多项任务。 |
| [^16] | ["What do others think?": Task-Oriented Conversational Modeling with Subjective Knowledge.](http://arxiv.org/abs/2305.12091) | 该研究提出了一种主观知识驱动的任务导向式对话建模方法，并制作了相应数据集。该方法面临着新的挑战，例如如何汇总多个知识片段中的不同意见。 |
| [^17] | [UP5: Unbiased Foundation Model for Fairness-aware Recommendation.](http://arxiv.org/abs/2305.12090) | 本研究提出了一种新颖的基础模型UP5，它采用反事实公平促进技术来消除大型语言模型中的偏见，从而实现面向公平性的推荐。 |
| [^18] | [Prefix Propagation: Parameter-Efficient Tuning for Long Sequences.](http://arxiv.org/abs/2305.12086) | 前缀传播是一种针对长序列参数高效调整的方法，可实现50%减少参数且在处理长文档任务时具有更优性能。 |
| [^19] | [Revisiting Entropy Rate Constancy in Text.](http://arxiv.org/abs/2305.12084) | 本论文使用神经语言模型重新评估了基于n-gram语言模型下英文文本的概率提出的熵率恒定原理，未能找到明显的支持熵率恒定的证据。 |
| [^20] | [Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer.](http://arxiv.org/abs/2305.12077) | 该论文提出了一种利用骨架辅助的提示传递进行少样本对话摘要的方法，利用骨架生成作为额外的监督来更好地消耗对话状态信息，并提出了一种新型模型SkeletonNet进行骨架生成，实现了最先进的性能。 |
| [^21] | [DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining.](http://arxiv.org/abs/2305.12074) | DisCo是一个半监督学习的框架，能够使用知识蒸馏的方法微调由大型预训练语言模型生成的小型学生模型，采用协同训练技术，通过多视角的知识共享来优化模型。实验结果表明DisCo相对于已有方法，具有更高的效果和更小的模型尺寸。 |
| [^22] | [Accurate Knowledge Distillation with n-best Reranking.](http://arxiv.org/abs/2305.12057) | 该论文提出了一种基于n-best重排序的知识蒸馏方法，通过使用多种模型提供伪标签，训练出参数更少但精度相当的学生模型。 |
| [^23] | [Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding.](http://arxiv.org/abs/2305.12031) | 临床骆驼是一种基于对话的知识编码的开源医学语言模型，具有很高的可解释性和临床相关性，并在多个基准数据集上取得了最先进的结果。 |
| [^24] | [MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup.](http://arxiv.org/abs/2305.12029) | 本研究提出了MultiTurnCleanup任务，收集了新的数据集MultiTurnCleanup1，针对口语会话转录中的不连续现象进行探讨并提供了两个可用于未来研究的基准测试模型。 |
| [^25] | [Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings.](http://arxiv.org/abs/2305.12027) | 本文提出了 DUCK 方法，通过使用实体类型的先前知识在实体表示空间中注入结构信息。把盒嵌入概念引入到极坐标中，将关系表示为超球面上的盒子，将具有相似类型的实体放置在对应于它们关系的盒子内，实现聚类。在实体链接方面取得了最先进的结果，尤其在低资源环境下效果显著。 |
| [^26] | [BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases.](http://arxiv.org/abs/2305.12018) | 本文提出了BOLT方法，通过可调偏置直接调整语言模型的输出logits以实现快速能量控制文本生成。与现有方法相比，在情感和主题控制等任务中表现出了更高的效率和流畅性。 |
| [^27] | [XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters.](http://arxiv.org/abs/2305.12002) | XuanYuan 2.0是目前最大的中文聊天模型，采用了BLOOM-176B架构，并提出了混合微调训练方法，能够在中文金融领域提供准确和上下文适当的回答。 |
| [^28] | [OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.](http://arxiv.org/abs/2305.12001) | 本文探究了大型语言模型的推理能力，证明解释在模型微调过程中对性能影响不显著，但在提示模型时使用解释可提高模型在某些推理技能上的性能。 |
| [^29] | [Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis.](http://arxiv.org/abs/2305.11993) | 该论文提出使用自动生成的自然语言定义作为词义表示，可以使语义变化分析更具可解释性，并允许用户直观解释词义的历时轨迹。此外，上下文化的定义在上下文中的语义相似性上也优于令牌或使用句嵌入。 |
| [^30] | [Evaluation of medium-large Language Models at zero-shot closed book generative question answering.](http://arxiv.org/abs/2305.11991) | 本文评估了大小为中型的语言模型在没有外部检索的情况下完成问答任务的表现，结果表明使用适当的训练数据进行模型微调比单纯依赖参数数量更重要，最好的模型实现了46.4%的正确率。 |
| [^31] | [A Weak Supervision Approach for Few-Shot Aspect Based Sentiment.](http://arxiv.org/abs/2305.11979) | 该论文研究了如何通过弱监督学习方法提高少样本情感分析性能，并提出了一种基于管道方法的嘈杂数据集调整预训练的模型以适应少样本情感分析任务，在未经微调时能胜过之前的状态艺术。 |
| [^32] | [Self-QA: Unsupervised Knowledge Guided Language Model Alignment.](http://arxiv.org/abs/2305.11952) | Self-QA是一种无监督知识引导的语言模型对齐框架，使用大量的无监督知识来代替传统的人工撰写的指令种子，以生成更多正确且特定于领域的指令数据。 |
| [^33] | [Eye-SpatialNet: Spatial Information Extraction from Ophthalmology Notes.](http://arxiv.org/abs/2305.11948) | 本研究提出了Eye-SpatialNet模式，用于表示眼科文本中的空间语言，并使用BERT语言模型自动提取空间信息，实现了对眼科实体空间和语境信息的自动化精准标注和提取。 |
| [^34] | [Exploring the Viability of Synthetic Query Generation for Relevance Prediction.](http://arxiv.org/abs/2305.11944) | 本文研究在电子商务和医疗保健等专业领域中，利用强大的模型生成高质量特定任务和领域的合成数据，探索用于预测对文档的查询分级相关性的方法，并尝试使用无监督聚类技术进一步改进对数据中相关性模式的理解。 |
| [^35] | [XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented Languages.](http://arxiv.org/abs/2305.11938) | 该论文提出了 XTREME-UP，一个以少量数据评估代表性不足语言的 NLP 系统性能的用户中心稀缺数据基准测试。它专注于用户中心任务，聚焦于代表性不足的语言，覆盖 88 种语言，并介绍了新的 OCR、自动完成、语义分析和音译数据集，旨在帮助推进代表性不足语言的高度多语言 NLP 系统的发展。 |
| [^36] | [MParrotTTS: Multilingual Multi-speaker Text to Speech Synthesis in Low Resource Setting.](http://arxiv.org/abs/2305.11926) | MParrotTTS是一个统一的多语言、多说话人文本转语音合成模型，以自监督语音表示为基础；它可以在低资源环境中仅使用少量有监督数据就适应于新语言，并在不需要平行或双语语料的情况下传递说话人特定的语音特征。 |
| [^37] | [Judgments of research co-created by generative AI: experimental evidence.](http://arxiv.org/abs/2305.11873) | 本研究探讨了把研究中部分内容交由生成式AI完成，会导致人们不信任和贬低研究人员和科学输出，并可能影响到生成式AI使用的报告问题。 |
| [^38] | [Scaling laws for language encoding models in fMRI.](http://arxiv.org/abs/2305.11863) | 本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。 |
| [^39] | [Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews.](http://arxiv.org/abs/2305.11828) | 本文研究了使用LLM协助制作医学证据综述的潜在用途和风险，指出LLM有可能自动生成文献综述，但由于可能出现虚构或遗漏信息的情况，LLM的使用需要谨慎。 |
| [^40] | [Prompting with Pseudo-Code Instructions.](http://arxiv.org/abs/2305.11790) | 本文研究了使用伪代码指令提示能否提高预训练语言模型的性能，实验证明使用伪代码提示可以在分类任务中提高7-16分，并相对改善12-38%。 |
| [^41] | [HELMA: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models.](http://arxiv.org/abs/2305.11747) | 本文介绍了一个大型语言模型幻觉评估基准（HELMA），其为标准化和可靠的估算模型幻觉问题提供了一种方法，并使用ChatGPT进行了实证研究以表明其存在幻觉的风险并为鉴别和减轻模型幻觉问题提供了一种方法。 |
| [^42] | [Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate.](http://arxiv.org/abs/2305.11595) | 本文提出了通过辩论探究大型语言模型之间的内部一致性问题，实验证明通过严格的辩论框架可以提高模型性能和常识知识的结构化学习。 |
| [^43] | [Cross-modality Data Augmentation for End-to-End Sign Language Translation.](http://arxiv.org/abs/2305.11096) | 本文提出了一种Cross-modality Data Augmentation（XmDA）框架，通过利用来自手语单词翻译模型的伪手语单词-文本对，将强大的手语单词到文本的翻译能力转移到了端到端手语翻译，实验结果表明XmDA在该领域中明显优于现有的最先进方法。 |
| [^44] | [Deep Learning Methods for Extracting Metaphorical Names of Flowers and Plants.](http://arxiv.org/abs/2305.10833) | 本研究使用深度学习模型识别对话中基于隐喻的花和植物名称，鉴别模型表现优于GPT-3.5，最好的表现器在任务中报告了92.2349％的F1分数。 |
| [^45] | [Generative Pre-trained Transformer: A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions.](http://arxiv.org/abs/2305.10435) | 生成的预训练变形器是一种基于变形器架构的深度神经网络，能够在自然语言处理任务中表现出色且有效地进行对话，具有广泛的潜在应用，但仍面临新兴挑战和局限性。 |
| [^46] | [What You See is What You Read? Improving Text-Image Alignment Evaluation.](http://arxiv.org/abs/2305.10400) | 本研究介绍了SeeTRUE评估集和两种自动文本-图像对齐方法，这些方法在各种对齐任务中均取得了显着改进，在复杂组合或非自然图像的挑战性案例中表现出色。 |
| [^47] | [UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective.](http://arxiv.org/abs/2305.10306) | UniEX是一种能适用于各种模式格式的信息抽取框架，并能同时解决命名实体识别、关系抽取、事件提取和情感分析等任务，在性能和推理速度上优于其他通用信息抽取模型。 |
| [^48] | [M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models.](http://arxiv.org/abs/2305.10263) | 本文提出了一种面向中国大语言模型的大规模多级多主题知识评估基准M3KE，收集了20,477个问题以覆盖中国教育体系的所有主要层次和广泛的学科，使用多任务准确性测试法有效地评估了四个大语言模型GPT-2，RoBERTa，ERNIE和ELECTRA对多源知识的整合和利用能力。 |
| [^49] | [MemoryBank: Enhancing Large Language Models with Long-Term Memory.](http://arxiv.org/abs/2305.10250) | MemoryBank 提出了一种新型内存机制，旨在为大型语言模型提供类人的长期记忆。它可以召唤相关记忆，通过持续的记忆更新不断进化，通过合成过去的互动信息理解并适应用户个性。 |
| [^50] | [Towards Speech Dialogue Translation Mediating Speakers of Different Languages.](http://arxiv.org/abs/2305.09210) | 本文提出了一项新任务，即为不同语言的发言人构建语音对话翻译。作者构建了SpeechBSD数据集并进行了基准实验。作者指出上下文是该任务中需要考虑的一个重要方面，并提出了两种利用上下文的方法。最终结果表明，在该任务中双语上下文比单语上下文表现更好。 |
| [^51] | [Text Classification via Large Language Models.](http://arxiv.org/abs/2305.08377) | 本文介绍了Clue And Reasoning Prompting (CARP)算法，采用逐步推理策略优化了大型语言模型在文本分类中处理复杂语言现象的能力；并通过在监督数据集上使用微调模型进行$k$NN演示搜索，解决了上下文学习中有限标记的问题。 |
| [^52] | [Distinguish Before Answer: Generating Contrastive Explanation as Knowledge for Commonsense Question Answering.](http://arxiv.org/abs/2305.08135) | 提出了一种基于概念中心提示的对比解释生成模型CPACE，旨在将获得的符号知识转化为对比解释，用于更好地区分常识问答中的差异。 |
| [^53] | [CodeT5+: Open Code Large Language Models for Code Understanding and Generation.](http://arxiv.org/abs/2305.07922) | CodeT5+是一组灵活组合的编码器-解码器LLM族，用于代码，混合了多种不同的预训练目标，包括代码生成、自然语言处理和程序合成，可以适应多种不同的下游代码任务，并且在实验中比现有代码-specific LLMs实现了最先进的性能。 |
| [^54] | [Knowledge Refinement via Interaction Between Search Engines and Large Language Models.](http://arxiv.org/abs/2305.07402) | 本文介绍了一种新的框架InteR，通过搜索引擎和大型语言模型之间的交互促进知识精炼，从而提高检索准确性。 |
| [^55] | [A Framework for Designing Foundation Model based Systems.](http://arxiv.org/abs/2305.05352) | 本文提出了一个基于基础模型的系统分类体系，分类和比较了基础模型和基于基础模型的系统的特点。它为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。 |
| [^56] | [Distilling Script Knowledge from Large Language Models for Constrained Language Planning.](http://arxiv.org/abs/2305.05252) | 本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。 |
| [^57] | [X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages.](http://arxiv.org/abs/2305.04160) | 本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。 |
| [^58] | [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models.](http://arxiv.org/abs/2305.04091) | 本研究提出了一种计划和解决的提示方法来改善零样本思考链推理，该方法包括两个组成部分：制定计划将任务划分为子任务，并按计划执行子任务；将输入提示扩展到包括简单算术计算的示例。实验结果显示，该方法胜过了零样本-CoT。 |
| [^59] | [Sensitive Data Detection with High-Throughput Machine Learning Models in Electrical Health Records.](http://arxiv.org/abs/2305.03169) | 该论文使用机器学习算法来识别结构化数据中的敏感变量，以便便于去身份化过程。该算法可以解决不同数据集PHI字段异质性的问题。 |
| [^60] | [Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System.](http://arxiv.org/abs/2305.02468) | 本文提出了一种端到端任务导向对话系统，通过在预训练网络的固定层后添加少量参数的任务优化适配器来独立地学习每个任务，并通过强化学习提高DST和NLG模块的性能。 |
| [^61] | [Improving Contrastive Learning of Sentence Embeddings from AI Feedback.](http://arxiv.org/abs/2305.01918) | 本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。 |
| [^62] | [SCOTT: Self-Consistent Chain-of-Thought Distillation.](http://arxiv.org/abs/2305.01879) | 本研究提出了一种忠实的知识蒸馏方法，从比教师模型大数倍的模型中学习一个小的、自我一致的思路串模型。实验结果表明，该方法有助于证明决策并提高性能，特别是在较小的语言模型中。 |
| [^63] | [Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks.](http://arxiv.org/abs/2304.14732) | 提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。 |
| [^64] | [PMC-LLaMA: Further Finetuning LLaMA on Medical Papers.](http://arxiv.org/abs/2304.14454) | 本文介绍了一个针对医学领域进一步微调的开源语言模型PMC-LLaMA，其通过增加医学知识提高了在生物医学领域的性能表现，有望在生物医学问答领域有更好的应用表现。 |
| [^65] | [LaMP: When Large Language Models Meet Personalization.](http://arxiv.org/abs/2304.11406) | 本论文强调了当前自然语言处理领域中个性化的重要性，并提出了LaMP（一种用于训练和评估大型语言模型的新的个性化基准），并针对大型语言模型的生成任务，设计了七项个性化任务以及一种检索增强方法，结果表明在利用用户配置文件扩展大型语言模型的基础上，其生成结果明显优于传统方法。 |
| [^66] | [RRHF: Rank Responses to Align Language Models with Human Feedback without tears.](http://arxiv.org/abs/2304.05302) | RRHF是一种新的学习范式，可以高效地对齐语言模型输出概率与人类偏好，它通过排序损失对不同采样策略生成的响应进行评分，并在调整过程中只需1到2个模型。 |
| [^67] | [Why think step-by-step? Reasoning emerges from the locality of experience.](http://arxiv.org/abs/2304.03843) | 本文通过语言模型研究何时以及为什么推理是有帮助的，测试推理在训练数据由相互影响强烈的局部变量集群组成时是否有效。通过一步步的推理，能够将准确的局部推理链接在一起，以估算在训练中没有同时观察到的变量之间的关系。 |
| [^68] | [MEGA: Multilingual Evaluation of Generative AI.](http://arxiv.org/abs/2303.12528) | 这项研究对 33 种语言中 8 个不同任务的生成 AI 进行了全面评估，比较了生成 LLMs 和非自回归模型的表现差异。 |
| [^69] | [Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization.](http://arxiv.org/abs/2303.12314) | 提出了一种自我监督元提示学习框架SUPMER，包括元梯度正则化，用于少样本泛化，通过锚定的元训练任务和基于课程的任务增强丰富了任务分布，解决了在少样本情况下良好初始化软提示和过拟合的问题。 |
| [^70] | [Reflexion: an autonomous agent with dynamic memory and self-reflection.](http://arxiv.org/abs/2303.11366) | 本文提出 Reflexion 方法，给智能体赋予了动态记忆和自我反思能力，以增强其任务特定的行动选择能力。 |
| [^71] | [UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers.](http://arxiv.org/abs/2303.00807) | 该论文提出了一种无监督领域自适应方法，利用大型语言模型(LLMs)生成大量合成查询和reranker模型，蒸馏为高效的检索器，适用于长尾领域。 |
| [^72] | [Handling the Alignment for Wake Word Detection: A Comparison Between Alignment-Based, Alignment-Free and Hybrid Approaches.](http://arxiv.org/abs/2302.08950) | 本文比较了基于对齐、无对齐和混合方法处理唤醒词检测的效果，发现在目标操作点上无对齐系统比基于对齐的方法更好，而使用少量对齐数据和大量未对齐数据的混合方法在满足初始约束的情况下训练出了良好的模型。 |
| [^73] | [Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?.](http://arxiv.org/abs/2302.08143) | 本文研究了元Prompt Tuning（MPT）如何帮助改善跨任务泛化能力。使用元学习可以从其他相关任务中学习初始化Prompt嵌入，我们提出并实验了代表性的元学习算法，并在大量的少样本任务中证明了MPT的有效性，特别是在分类任务中。 |
| [^74] | [UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling.](http://arxiv.org/abs/2302.06605) | 本论文提出了 UniAdapter，它是一种新颖的跨模态适配器，可以高效跨模态适应预训练的视觉-语言模型，能够用较少的调参成本提升下游任务的性能。 |
| [^75] | [Can Peanuts Fall in Love with Distributional Semantics?.](http://arxiv.org/abs/2301.08731) | 通过计算语言模型和单词向量模拟，研究发现某些处理效应可不需要情景模型。 |
| [^76] | [Two Stage Contextual Word Filtering for Context bias in Unified Streaming and Non-streaming Transducer.](http://arxiv.org/abs/2301.06735) | 本文提出一种针对上下文偏差的双阶段上下文过滤方法，将流式输出和预定义上下文单词列表相结合，提高了端对端模型的识别准确率，并加快了推理过程。 |
| [^77] | [Black-box language model explanation by context length probing.](http://arxiv.org/abs/2212.14815) | 该论文提出了一个模型不可知的新颖解释技术：上下文长度探测，通过跟踪模型预测与可用上下文长度的关系来对不同上下文分配不同的重要性得分。该方法适用于大型预训练语言模型，并有利于研究远距离依赖性。 |
| [^78] | [DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines.](http://arxiv.org/abs/2212.10557) | DialGuide是一个使用自然语言规则或指南控制对话模型行为的新框架，能够帮助模型生成更加一致的响应，提升用户信任。作者在开放域对话回复生成的三个任务上评估了DialGuide，并提供了基准模型。 |
| [^79] | [Little Red Riding Hood Goes Around the Globe:Crosslingual Story Planning and Generation with Large Language Models.](http://arxiv.org/abs/2212.10471) | 本论文提出了一个新的跨语言故事生成任务，并利用大型预训练语言模型研究不同的故事规划。结果表明将故事分为三幕可以带来更一致和有趣的叙述，同时允许明确控制其内容和结构。 |
| [^80] | [SeqDiffuSeq: Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation.](http://arxiv.org/abs/2212.10325) | 本文提出了一种名为SeqDiffuSeq的文本扩散模型，用于序列生成，采用了编码器-解码器Transformer架构和自适应噪声调度技术，旨在探索扩散模型在自然语言生成方面的性能表现。 |
| [^81] | [KNIFE: Distilling Reasoning Knowledge From Free-Text Rationales.](http://arxiv.org/abs/2212.09721) | 通过KNIFE，可以从自由文本理由中提取推理知识，进而在小型语言模型中提高推理能力。 |
| [^82] | [SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations.](http://arxiv.org/abs/2212.09699) | 该论文提出了一种新的数据增强策略SegAugment，利用音频分段系统生成数据集的多个句子级别的替代版本，能够提高语音翻译的性能，实验结果显示平均BLEU分数提高了2.5分，甚至在低资源情况下提高了5分。 |
| [^83] | [Norm of Word Embedding Encodes Information Gain.](http://arxiv.org/abs/2212.09663) | 本文研究发现，跳字模型和负采样方法中静态词向量的平方范数编码了词所传达的信息增益，通过与语料库中单词的分布之间的KL散度来定义，可用于关键词提取、词性区分和上位词分类等任务。 |
| [^84] | [RISE: Leveraging Retrieval Techniques for Summarization Evaluation.](http://arxiv.org/abs/2212.08775) | RISE是一种利用信息检索技术进行摘要评估的新方法，能够在没有参考摘要的情况下评估给定输入文档的生成摘要。RISE具有更高的相关性，数据效率和泛化能力。 |
| [^85] | [On Text-based Personality Computing: Challenges and Future Directions.](http://arxiv.org/abs/2212.06711) | 本文提出了15个基于文本的人格计算方面的挑战，包括人格分类法，测量质量，数据集，性能评估，建模选择以及道德和公平性，旨在激发更多的有效和可靠的TPC研究。 |
| [^86] | [Investigating Glyph Phonetic Information for Chinese Spell Checking: What Works and What's Next.](http://arxiv.org/abs/2212.04068) | 本文探究用于汉语漏字检查的字形音标信息的效果和应用方向，提出一个更具挑战性和实用性的测试设置，并公开了所有代码。 |
| [^87] | [Automated Identification of Eviction Status from Electronic Health Record Notes.](http://arxiv.org/abs/2212.02762) | 本研究开发了一种自然语言处理系统，可以自动从电子健康档案（EHR）记录中检测到逐出状态，并开发了一个新颖的模型KIRESH，已经显示出明显优于其他最先进的模型。 |
| [^88] | [EURO: ESPnet Unsupervised ASR Open-source Toolkit.](http://arxiv.org/abs/2211.17196) | 本文介绍了ESPnet无监督ASR开源工具包（EURO）的细节及其在自监督语音表征和对抗性训练方面的最新方法。该工具包集成了27个自监督模型和基于图形的解码策略，成功提高了UASR的效率和可重现性；在TIMIT和LibriSpeech数据上获得了最先进的性能。 |
| [^89] | [Syntactic Substitutability as Unsupervised Dependency Syntax.](http://arxiv.org/abs/2211.16031) | 本文提出了一种新的无需语法规则的诱导方法，该方法基于语法可替代性，能够在定量和定性方面都有所提升。 |
| [^90] | [[RE]VER: Learning Natural Language Representations for Verbalizing Entities and Relations.](http://arxiv.org/abs/2211.11093) | 本文提出了一种名为[RE]VER的系统，使用基于transformer的模型来学习实体和关系的自然语言表示，能够生成一个能够表示实体与其他实体关系的句子，相比于之前的最先进方法有了显著改进。 |
| [^91] | [Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling Approaches.](http://arxiv.org/abs/2211.08371) | 本文调查了目前语用学模型的研究现状，提出了建议并分析了语言含义的丰富性。未来的任务设计需要引出语用现象，并关注更广泛的交流上下文和效益的方向。 |
| [^92] | [MEAL: Stable and Active Learning for Few-Shot Prompting.](http://arxiv.org/abs/2211.08358) | 本文提出了MEAL方法，是一个可以在少量样本下进行分类，稳定和活跃的少样本学习方法。方法包含两个贡献，一个是提出新颖的减少运行变异性的集成方法，另一个是引入AL准则用于数据选择。 |
| [^93] | [GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective.](http://arxiv.org/abs/2211.08073) | 本文提出了第一个创建名为方法的统一基准的尝试，用于评估NLP模型中的OOD鲁棒性，该基准包括13个公开可用的OOD测试数据集，并在21个常用的PLMs上对8个经典NLP任务进行评估。 |
| [^94] | [Prompting Language Models for Linguistic Structure.](http://arxiv.org/abs/2211.07830) | 本文探究了预训练语言模型（PLMs）对于语言结构的推理能力，通过结构化提示方法，在零样本和少样本情况下进行了序列标注实验，并证明了 PLMs 的上下文学习能力和语言知识的推广性，这能够帮助检索任意标签的语言结构。 |
| [^95] | [DiaASQ : A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis.](http://arxiv.org/abs/2211.05705) | 本文介绍了一项新的任务DiaASQ，它旨在检测对话中的目标-方面-观点-情感四元组。我们手动构建了一个大规模的高质量DiaASQ数据集，并开发了一种神经模型来进行基准测试，该模型在跨话语四元组提取方面取得了进展。 |
| [^96] | [A Training and Inference Strategy Using Noisy and Enhanced Speech as Target for Speech Enhancement without Clean Speech.](http://arxiv.org/abs/2210.15368) | 为解决语音增强领域中“无清晰语音”的挑战，提出了使用增强语音作为目标的训练和推理策略，即使在域内和域外噪声差异较大的情况下仍能有效，实验结果优于基线方法。 |
| [^97] | [Joint Speech Translation and Named Entity Recognition.](http://arxiv.org/abs/2210.11987) | 本文提出了一种新型多任务模型，结合命名实体识别和直接语音翻译，相比级联系统在命名实体识别上表现更好，且翻译质量和计算效率不会有所下降。 |
| [^98] | [End-to-End Entity Detection with Proposer and Regressor.](http://arxiv.org/abs/2210.10260) | 该论文提出了一种基于提议器和回归器的端到端实体检测方法，通过利用特征金字塔网络生成高质量的实体提议，并对提议进行精细调整以生成最终的预测结果。该模型具有查询语义丰富、实体定位精度高、模型训练容易等优点，还引入了空间调制变压器来增强内部关系的建模能力。实验结果表明，该方法显著优于现有的最先进方法。 |
| [^99] | [DICTDIS: Dictionary Constrained Disambiguation for Improved NMT.](http://arxiv.org/abs/2210.06996) | DICTDIS是一种新颖有词典约束的NMT系统，其利用多个字典候选项进行训练，实现了从多义词中消除翻译歧义的目的，提高了翻译质量。 |
| [^100] | [A Few-shot Approach to Resume Information Extraction via Prompts.](http://arxiv.org/abs/2209.09450) | 本文提出了一种基于提示的少样本简历信息提取方法，使用手动创建的模板和语言表述，改善了现有方法。他们的MKV方法解决了样本失衡问题，产生了更有效，更鲁棒的模板和语言表述器，为简历提取的定制提示学习方法提供了价值。 |
| [^101] | [Psychologically-informed chain-of-thought prompts for metaphor understanding in large language models.](http://arxiv.org/abs/2209.08141) | 本文介绍了一种在大语言模型中使用心理学引导思维的方法来增强隐喻理解的性能。这种方法使用了隐含变量和关系来选择正确的释义。 |
| [^102] | [ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection.](http://arxiv.org/abs/2205.12495) | 本研究提出了一种将仇恨言论检测任务拆分为部分并注入推理数据集知识的方法，相较于先前的方法，具有更好的泛化性能，在16个样本的情况下可达到17.83％的绝对增益。 |
| [^103] | [CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models.](http://arxiv.org/abs/2205.12213) | 本论文提出了一种 CombLM 方法，通过小型微调模型调整大型黑盒语言模型以适应新领域和任务，且不需要访问它们的权重或中间激活。实验证明在多个领域和下游任务中，性能得到提高。 |
| [^104] | [CORAL: Contextual Response Retrievability Loss Function for Training Dialog Generation Models.](http://arxiv.org/abs/2205.10558) | 本研究提出了一种基于强化学习视图的损失函数CORAL，用于评估生成对话模型的响应质量，该损失函数同时考虑到了上下文和生成的响应。 |
| [^105] | [ASR data augmentation in low-resource settings using cross-lingual multi-speaker TTS and cross-lingual voice conversion.](http://arxiv.org/abs/2204.00618) | 本文探索了一种在低资源情况下使用跨语言多说话人TTS和跨语言语音转换进行ASR数据增广的方法，其可以通过只使用一个说话人改善ASR系统，并且能够缩小ASR模型间使用人工和合成语音训练的差距，同时使用单一真实说话人的数据增广方法同样能够获得有希望的ASR训练结果。 |
| [^106] | [PoNet: Pooling Network for Efficient Token Mixing in Long Sequences.](http://arxiv.org/abs/2110.02442) | PoNet是一种池化网络，可用于长序列中的token混合，其具有线性复杂度，并可以比Transformer更好地处理长序列。该方法提供了一种高效且有效的自注意替代方案。 |
| [^107] | [Natural Language Specification of Reinforcement Learning Policies through Differentiable Decision Trees.](http://arxiv.org/abs/2101.07140) | 本文提出了一个新的可微分决策树框架，允许人们通过自然语言指定初始行为模型，并将其转换为词汇决策树，为机器人的强化学习策略提供指导。 |

# 详细

[^1]: Prompt ChatGPT 在 MNER 中的应用：基于 ChatGPT 辅助精炼知识的改进式多模态命名实体识别方法

    Prompt ChatGPT In MNER: Improved multimodal named entity recognition method based on auxiliary refining knowledge from ChatGPT. (arXiv:2305.12212v1 [cs.CL])

    [http://arxiv.org/abs/2305.12212](http://arxiv.org/abs/2305.12212)

    本文提出了一个叫做 PGIM 的方法，该方法利用 ChatGPT 作为隐式知识引擎来获取辅助精炼知识，从而增强模型在 MNER 任务中的性能。

    

    社交媒体上的多模态命名实体识别（MNER）旨在通过引入基于图像的线索来增强文本实体预测。现有研究主要集中在最大化图像相关信息的利用或将外部知识从显式知识库（KBs）中引入。然而，这些方法要么忽视了向模型提供相关外部知识的必要性，要么引入的外部知识存在重复性。为了解决这些问题，本文提出了一个概念简单的两阶段框架，称为 Prompt ChatGPT In MNER (PGIM)。我们利用 ChatGPT 作为隐式知识引擎来获取辅助精炼知识，从而增强模型在 MNER 任务中的性能。

    Multimodal Named Entity Recognition (MNER) on social media aims to enhance textual entity prediction by incorporating image-based clues. Existing research in this domain has primarily focused on maximizing the utilization of potentially relevant information in images or incorporating external knowledge from explicit knowledge bases (KBs). However, these methods either neglect the necessity of providing the model with relevant external knowledge, or the retrieved external knowledge suffers from high redundancy. To address these problems, we propose a conceptually simple two-stage framework called Prompt ChatGPT In MNER (PGIM) in this paper. We leverage ChatGPT as an implicit knowledge engine to acquire auxiliary refined knowledge, thereby bolstering the model's performance in MNER tasks. Specifically, we first utilize a Multimodal Similar Example Awareness module to select suitable examples from a small number of manually annotated samples. These examples are then integrated into a form
    
[^2]: 具有元学习的自蒸馏网络用于知识图谱补全

    Self-Distillation with Meta Learning for Knowledge Graph Completion. (arXiv:2305.12209v1 [cs.CL])

    [http://arxiv.org/abs/2305.12209](http://arxiv.org/abs/2305.12209)

    本文提出了一个基于动态剪枝和元学习自蒸馏的框架，用于解决知识图谱补全中长尾样本问题，并在实验中取得了优于现有最先进方法的效果。

    

    本文提出了一个基于动态剪枝的元学习自蒸馏框架(MetaSD)，旨在学习压缩的图嵌入并解决长尾样本问题。具体而言，我们首先提出了一种动态剪枝技术，从一个大源模型中获取一个较小的剪枝模型，其中剪枝掩模可以在模型权重更新后每个时期自适应地更新，剪枝模型应比源模型更敏感于难于记忆的样本（例如，长尾样本）。然后，我们提出了一种单步元自蒸馏方法，以将来自源模型的全面知识蒸馏到剪枝模型中，其中两个模型在训练期间以动态方式共同进化。特别地，我们利用了与源模型同时在一个迭代中训练的剪枝模型的性能来通过元学习提高源模型的知识迁移能力，以进行下一次迭代。实验结果表明，我们提出的框架在多个基准数据集上优于现有的最先进方法。

    In this paper, we propose a selfdistillation framework with meta learning(MetaSD) for knowledge graph completion with dynamic pruning, which aims to learn compressed graph embeddings and tackle the longtail samples. Specifically, we first propose a dynamic pruning technique to obtain a small pruned model from a large source model, where the pruning mask of the pruned model could be updated adaptively per epoch after the model weights are updated. The pruned model is supposed to be more sensitive to difficult to memorize samples(e.g., longtail samples) than the source model. Then, we propose a onestep meta selfdistillation method for distilling comprehensive knowledge from the source model to the pruned model, where the two models coevolve in a dynamic manner during training. In particular, we exploit the performance of the pruned model, which is trained alongside the source model in one iteration, to improve the source models knowledge transfer ability for the next iteration via meta l
    
[^3]: 将GPT-4应用于未发表的形式语言的实验结果

    Experimental results from applying GPT-4 to an unpublished formal language. (arXiv:2305.12196v1 [cs.CL])

    [http://arxiv.org/abs/2305.12196](http://arxiv.org/abs/2305.12196)

    GPT-4在一个未发表的正式系统上成功完成了一系列任务，展示了广泛的领域知识，发明了有用的新语法和语义，并展示了泛化和推理能力。

    

    大型语言模型能否用于完成传统手动或使用定理证明器完成的数学任务？为了回答这个问题，最先进的系统GPT-4使用简洁的自然语言规范，针对先前未发表的正式系统，完成了一些任务，包括陈述函数和类型定义、证明简单定理和验证用户提供的证明。该系统成功完成了所有任务，展示了广泛的领域知识，发明了有用的新语法和语义，并展示了泛化和推理能力。因此答案似乎是：可以。

    Can large language models be used to complete mathematical tasks that are traditionally performed either manually or with the aid of theorem provers? To answer this question, a state-of-the-art system, GPT-4, was provided with a concise natural language specification for a previously unpublished formal system and asked to complete a number of tasks, from stating function and type definitions to proving simple theorems and verifying user-supplied proofs. The system completed all tasks successfully, showed extensive domain knowledge, invented helpful new syntax and semantics, and exhibited generalization and inference abilities. So the answer seems to be: yes.
    
[^4]: 基于点互信息度量和解码策略的文档导向对话生成中的保真度研究

    Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs. (arXiv:2305.12191v1 [cs.CL])

    [http://arxiv.org/abs/2305.12191](http://arxiv.org/abs/2305.12191)

    该论文研究了文档导向对话生成中的保真度问题，并提出了一种基于点互信息的度量方法和解码策略来预测更加保真的回答。

    

    在基于深度学习的文档导向对话生成中，一个主要问题是生成的回答可能与底层文档不一致。现有的用于评估生成的回答是否与底层文档一致的自动化度量方法，度量生成的回答与文档内容之间的相似度。然而，这些自动化度量方法与人类判断相比差异很大。因此，为了提高保真度的测量，我们提出一种基于条件点互信息（PMI）的新度量方法，该度量方法量化生成的回答与源文档之间的PMI，受对话条件的影响。PMI量化文档对生成的回答的影响程度，PMI越高则回答越保真。我们基于此思想构建了一种新的解码技术，将PMI并入到生成流程中，以预测更加保真的回答。

    A major concern in using deep learning based generative models for document-grounded dialogs is the potential generation of responses that are not \textit{faithful} to the underlying document. Existing automated metrics used for evaluating the faithfulness of response with respect to the grounding document measure the degree of similarity between the generated response and the document's content. However, these automated metrics are far from being well aligned with human judgments. Therefore, to improve the measurement of faithfulness, we propose a new metric that utilizes (Conditional) Point-wise Mutual Information (PMI) between the generated response and the source document, conditioned on the dialogue. PMI quantifies the extent to which the document influences the generated response -- with a higher PMI indicating a more faithful response. We build upon this idea to create a new decoding technique that incorporates PMI into the response generation process to predict more faithful re
    
[^5]: 基于主题句作为查询的段落级引用建议

    Paragraph-level Citation Recommendation based on Topic Sentences as Queries. (arXiv:2305.12190v1 [cs.IR])

    [http://arxiv.org/abs/2305.12190](http://arxiv.org/abs/2305.12190)

    该论文提出了一种中间层级的引用建议任务——段落级引用建议，即以段落的主题句为输入，输出在段落中引用的建议，并提出了用于解决此任务的模型。

    

    引用建议(CR)模型可帮助作者在论文写作过程中的各个阶段找到相关文章。大多数研究处理全局CR，该全局CR适用于初始写作阶段的一般建议。本研究提出了段落级CR任务，作为两种方法之间的一种中间地带，其中段落的主题句作为输入，生成段落内引用的建议作为输出。我们提出了一个模型来解决这个任务，并使用ACL论文数据集上的四元组损失进行了微调，结果显示相对于基线有所改善。

    Citation recommendation (CR) models may help authors find relevant articles at various stages of the paper writing process. Most research has dealt with either global CR, which produces general recommendations suitable for the initial writing stage, or local CR, which produces specific recommendations more fitting for the final writing stages. We propose the task of paragraph-level CR as a middle ground between the two approaches, where the paragraph's topic sentence is taken as input and recommendations for citing within the paragraph are produced at the output. We propose a model for this task, fine-tune it using the quadruplet loss on the dataset of ACL papers, and show improvements over the baselines.
    
[^6]: Glot500：扩展500种语言的多语料库和语言模型

    Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages. (arXiv:2305.12182v1 [cs.CL])

    [http://arxiv.org/abs/2305.12182](http://arxiv.org/abs/2305.12182)

    Glot500是一个水平扩展的语言模型，覆盖了511种低资源语言。相比于XLM-R基线，Glot500展现出了更好的高资源和低资源语言表现。该模型质量的决定因素包括语料库大小、脚本、相关语言的“帮助”和模型的总容量。

    

    自然语言处理领域一直专注于使大型语言模型在大约100种语言中更加出色。我们通过不断的预训练，水平扩展大型语言模型。我们创建了Glot500-m，这是一个覆盖了511种语言的语言模型，其中几乎所有语言都是低资源语言。这项工作的重要部分是收集和清理Glot500-c，这是一个包括这511种语言的语料库，可以让我们对Glot500-m进行训练。我们在这些语言上评估了Glot500-m在五个不同的任务中的表现。我们观察到，与XLM-R基线相比，Glot500-m在高资源和低资源语言的表现都有了很大的提高。我们的分析表明，没有单一因素可以解释多语言大型语言模型表示的质量。相反，多个因素决定了质量，包括语料库大小、脚本、相关语言的“帮助”以及模型的总容量。我们的工作解决了自然语言处理研究的一个重要目标：我们不应该将自然语言处理局限于世界语言的一小部分，而是应该让它涵盖更广泛的语言范围。

    The NLP community has mainly focused on scaling Large Language Models (LLMs) vertically, i.e., making them better for about 100 languages. We instead scale LLMs horizontally: we create, through continued pretraining, Glot500-m, an LLM that covers 511 languages, almost all of them low-resource. An important part of this effort is to collect and clean Glot500-c, a corpus that covers these 511 languages and allows us to train Glot500-m. We evaluate Glot500-m on five diverse tasks across these languages. We observe large improvements for both high-resource and lowresource languages compared to an XLM-R baseline. Our analysis shows that no single factor explains the quality of multilingual LLM representations. Rather, a combination of factors determines quality including corpus size, script, "help" from related languages and the total capacity of the model. Our work addresses an important goal of NLP research: we should not limit NLP to a small fraction of the world's languages and instead 
    
[^7]: 学习适当地组合句法和语义表示以进行组合泛化

    Learn to Compose Syntactic and Semantic Representations Appropriately for Compositional Generalization. (arXiv:2305.12169v1 [cs.CL])

    [http://arxiv.org/abs/2305.12169](http://arxiv.org/abs/2305.12169)

    该研究提出了一个名为COMPSITION的新框架，可以通过适当地组合句法和语义表示来解决组合泛化问题。实验证明该方法在合成和自然语言CG任务上实现了最先进的性能。

    

    最近的研究表明，序列到序列（Seq2Seq）模型在解决组合泛化（CG）任务时存在局限性，无法系统性地推广到看不见的已知组件组合。越来越多的证据表明，阻碍CG的原因之一是编码器最上层的表示是纠缠的，也就是说，序列的句法和语义表示被不适当地扭曲了。然而，大多数以前的研究主要集中于在标记级别上增强语义信息，而不是适当地组合序列的句法和语义表示，就像人类所做的那样。此外，我们认为他们发现的表示纠缠问题不全面，并进一步假设传递到不同解码器层的源键值表示也是纠缠在一起的。基于这个直觉和受人类CG策略的启发，我们提出了COMPSITION（适当地组合句法和语义表示以进行组合泛化），这是一个解决CG任务的新框架。COMPSITION通过分别建模句法和语义表示，并通过几何表示模块将它们组合起来，显式地组合编码器的最上层。实验结果表明，COMPSITION在合成和自然语言CG任务上均实现了最先进的性能。

    Recent studies have shown that sequence-to-sequence (Seq2Seq) models are limited in solving the compositional generalization (CG) tasks, failing to systematically generalize to unseen compositions of seen components. There is mounting evidence that one of the reasons hindering CG is the representation of the encoder uppermost layer is entangled. In other words, the syntactic and semantic representations of sequences are twisted inappropriately. However, most previous studies mainly concentrate on enhancing semantic information at token-level, rather than composing the syntactic and semantic representations of sequences appropriately as humans do. In addition, we consider the representation entanglement problem they found is not comprehensive, and further hypothesize that source keys and values representations passing into different decoder layers are also entangled. Staring from this intuition and inspired by humans' strategies for CG, we propose COMPSITION (Compose Syntactic and Seman
    
[^8]: 用大语言模型重新审视自动主题模型评估

    Re-visiting Automated Topic Model Evaluation with Large Language Models. (arXiv:2305.12152v1 [cs.CL])

    [http://arxiv.org/abs/2305.12152](http://arxiv.org/abs/2305.12152)

    本文提出使用大型语言模型来评估主题模型输出，并使用自动化方法确定最佳主题数量。

    

    主题模型用于对大型文本集合进行分析。然而，自动评估主题模型输出和确定最佳主题数量一直是长期的挑战，目前尚无有效的自动化解决方案。本文提出使用大型语言模型来评估这种输出。我们发现，相比现有的自动度量标准，大型语言模型更能适当地评估出产生的主题，并且更能与人类判断相关。然后，我们研究能否利用大型语言模型自动确定最佳的主题数量。我们自动为文档分配标签，并选择具有最纯净标签的配置，以返回合理的最佳主题数量值。

    Topic models are used to make sense of large text collections. However, automatically evaluating topic model output and determining the optimal number of topics both have been longstanding challenges, with no effective automated solutions to date. This paper proposes using large language models to evaluate such output. We find that large language models appropriately assess the resulting topics, correlating more strongly with human judgments than existing automated metrics. We then investigate whether we can use large language models to automatically determine the optimal number of topics. We automatically assign labels to documents and choosing configurations with the most pure labels returns reasonable values for the optimal number of topics.
    
[^9]: LogiCoT：基于GPT-4的逻辑思维指令调整数据收集。

    LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4. (arXiv:2305.12147v1 [cs.CL])

    [http://arxiv.org/abs/2305.12147](http://arxiv.org/abs/2305.12147)

    该论文提出了LogiCoT, 一个基于GPT-4的逻辑思维指令调整数据集，用于教授模型逻辑推理和引出一般推理技能。

    

    生成式预训练变压器4（GPT-4）展示了令人印象深刻的思维链推理能力。最近的自我指导调整研究（如Alpaca）侧重于增强模型的通用能力。这些指令使模型在一般任务（如开放领域文本生成和释义）上能够达到与GPT-3.5相当的性能。然而，它们不能帮助模型处理复杂的推理任务。为填补这一差距，本文提出了LogiCoT，一种新的逻辑思维指令调整数据集，用于GPT-4的逻辑思维链推理。我们详细阐述了收集指令以提示GPT-4生成思维链推理的过程。LogiCoT作为教授逻辑推理模型的指令集，并引出了一般推理技能。

    Generative Pre-trained Transformer 4 (GPT-4) demonstrates impressive chain-of-thought reasoning ability. Recent work on self-instruction tuning, such as Alpaca, has focused on enhancing the general proficiency of models. These instructions enable the model to achieve performance comparable to GPT-3.5 on general tasks like open-domain text generation and paraphrasing. However, they fall short of helping the model handle complex reasoning tasks. To bridge the gap, this paper presents LogiCoT, a new instruction-tuning dataset for Logical Chain-of-Thought reasoning with GPT-4. We elaborate on the process of harvesting instructions for prompting GPT-4 to generate chain-of-thought rationales. LogiCoT serves as an instruction set for teaching models of logical reasoning and elicits general reasoning skills.
    
[^10]: 宣传性文件双向翻译中的措辞处理

    Hedges in Bidirectional Translations of Publicity-Oriented Documents. (arXiv:2305.12146v1 [cs.CL])

    [http://arxiv.org/abs/2305.12146](http://arxiv.org/abs/2305.12146)

    本文研究了宣传性文件翻译中的措辞处理问题，发现政治文本中的措辞在英文中出现更频繁，且翻译方向影响措辞使用频率和翻译策略。同时还观察到了措辞在历时方面的增加。

    

    措辞是跨专业领域广泛研究的词汇，但政治文本中措辞的翻译研究极为有限。本文研究了措辞在目标文本中的词频变化是否具有历时性，翻译中措辞通过年份变化的程度如何归因于源文本，并采用了何种翻译策略来处理它们。为了实现这一研究目的，我们收集了来自中国和联合国的两种公务政治文本及其翻译，形成了三个子语料库。结果表明，措辞在英文政治文本中（无论是原始英文还是翻译英文）似乎更频繁出现。此外，翻译方向似乎在影响措辞使用的频率和翻译策略方面起着重要作用。我们还观察到，措辞使用频率在我们的子语料库中出现了显著的历时性增加。

    Hedges are widely studied across registers and disciplines, yet research on the translation of hedges in political texts is extremely limited. This contrastive study is dedicated to investigating whether there is a diachronic change in the frequencies of hedging devices in the target texts, to what extent the changing frequencies of translated hedges through years are attributed to the source texts, and what translation strategies are adopted to deal with them. For the purposes of this research, two types of official political texts and their translations from China and the United Nations were collected to form three sub-corpora. Results show that hedges tend to appear more frequently in English political texts, be it original English or translated English. In addition, directionality seems to play an important role in influencing both the frequencies and translation strategies regarding the use of hedges. A noticeable diachronic increase of hedging devices is also observed in our corp
    
[^11]: 解除预训练语言模型中的容量差异诅咒

    Lifting the Curse of Capacity Gap in Distilling Language Models. (arXiv:2305.12129v1 [cs.CL])

    [http://arxiv.org/abs/2305.12129](http://arxiv.org/abs/2305.12129)

    本文提出了一种新的知识蒸馏方法（MiniMoE），通过增加学生的容量而不明显增加推理计算解除容量差异诅咒，并在GLUE和CoNLL上进行了实验验证。

    

    预训练语言模型在各种下游任务中表现出色，但不幸的是，它们需要大量的推理计算。知识蒸馏通过师生范式为小型模型压缩预训练语言模型，但当师生之间的容量差距很大时，容量差距诅咒会出现，导致蒸馏语言模型不足。虽然已有几项研究填补了这一差距，但诅咒仍未得到很好的解决。在本文中，我们旨在通过增加学生的容量而不明显增加推理计算来解除容量差异诅咒。受混合专家(Sparse Activation Regime of Mixture of Experts (MoE))的启发，我们提出了最小专家(MiniMoE)的混合物，这为学生引入了额外的参数，但几乎没有引入任何额外的推理计算。在GLUE和CoNLL上的实验结果表明，MiniMoE的魔力消除了容量差距诅咒。

    Pretrained language models (LMs) have shown compelling performance on various downstream tasks, but unfortunately they require a tremendous amount of inference compute. Knowledge distillation finds a path to compress LMs to small ones with a teacher-student paradigm. However, when the capacity gap between the teacher and the student is large, a curse of capacity gap appears, invoking a deficiency in distilling LMs. While a few studies have been carried out to fill the gap, the curse is not yet well tackled. In this paper, we aim at lifting the curse of capacity gap via enlarging the capacity of the student without notably increasing the inference compute. Largely motivated by sparse activation regime of mixture of experts (MoE), we propose a mixture of minimal experts (MiniMoE), which imposes extra parameters to the student but introduces almost no additional inference compute. Experimental results on GLUE and CoNLL demonstrate the curse of capacity gap is lifted by the magic of MiniMo
    
[^12]: Robust Optimization中最小最大博弈中Q-Diversity的建模

    Modeling the Q-Diversity in a Min-max Play Game for Robust Optimization. (arXiv:2305.12123v1 [cs.CL])

    [http://arxiv.org/abs/2305.12123](http://arxiv.org/abs/2305.12123)

    本文提出了Q-Diversity，与group DRO较好地配合，通过交互式训练模式直接参数化组的识别，从而提高了模型的泛化能力和鲁棒性。

    

    经验风险最小化(ERM)训练的模型往往过于依赖表面相关性，导致泛化性差。分组分布式鲁棒优化（group DRO）可以通过在预定义组上最小化最坏情况下的损失来缓解这个问题。但在实践中，昂贵的注释和隐私等因素都会阻碍组标签的可用性。更重要的是，当更深入地了解超出分布之外的泛化的失败模式时，“group DRO”中的重新加权典型过程会失去效率。基于这些限制，本文通过提出Q-Diversity重新构建了“group DRO”框架。Q-Diversity采用交互式训练模式，并将组的识别从注释中放宽到直接参数化。此外，还提出了一种新的混合策略，以分散未被充分代表的组。作者在一系列对于合成和真实世界文本分类的实验中测试了该框架的有效性。

    Models trained with empirical risk minimization (ERM) are revealed to easily rely on spurious correlations, resulting in poor generalization. Group distributionally robust optimization (group DRO) can alleviate this problem by minimizing the worst-case loss over pre-defined groups. While promising, in practice factors like expensive annotations and privacy preclude the availability of group labels. More crucially, when taking a closer look at the failure modes of out-of-distribution generalization, the typical procedure of reweighting in group DRO loses efficiency. Hinged on the limitations, in this work, we reformulate the group DRO framework by proposing Q-Diversity. Characterized by an interactive training mode, Q-Diversity relaxes the group identification from annotation into direct parameterization. Furthermore, a novel mixing strategy across groups is presented to diversify the under-represented groups. In a series of experiments on both synthetic and real-world text classificati
    
[^13]: 用语言信息实现强烈感情表现和语调的TTS系统

    EE-TTS: Emphatic Expressive TTS with Linguistic Information. (arXiv:2305.12107v1 [cs.SD])

    [http://arxiv.org/abs/2305.12107](http://arxiv.org/abs/2305.12107)

    该论文提出了一种利用语言信息和强调预测器实现表现力强且自然的TTS系统，并在实验中表现出良好的表现和泛化能力。

    

    目前的TTS系统能够合成高质量的语音，但要产生高度表现力的语音仍然是一个挑战。强调是决定语音表现力的关键因素，近年来受到了更多的关注。以前的研究通常通过添加中间特征来增强强调，但不能保证语音的整体表现力。为了解决这个问题，我们提出了一种名为EE-TTS的新方法，它利用句法和语义上的多层语言信息。EE-TTS包含一个强调位置预测器，可以从文本中识别出适当的强调位置，并具有一个条件声学模型，可以合成带强调和语言信息的表现力语音。实验结果表明，EE-TTS在表现力和自然度方面比基线有0.49和0.67的MOS提升。EE-TTS还表现出强大的泛化能力，根据AB测试结果在不同数据集上都表现良好。

    While Current TTS systems perform well in synthesizing high-quality speech, producing highly expressive speech remains a challenge. Emphasis, as a critical factor in determining the expressiveness of speech, has attracted more attention nowadays. Previous works usually enhance the emphasis by adding intermediate features, but they can not guarantee the overall expressiveness of the speech. To resolve this matter, we propose Emphatic Expressive TTS (EE-TTS), which leverages multi-level linguistic information from syntax and semantics. EE-TTS contains an emphasis predictor that can identify appropriate emphasis positions from text and a conditioned acoustic model to synthesize expressive speech with emphasis and linguistic information. Experimental results indicate that EE-TTS outperforms baseline with MOS improvements of 0.49 and 0.67 in expressiveness and naturalness. EE-TTS also shows strong generalization across different datasets according to AB test results.
    
[^14]: NLP模型能否正确处理打破常见假设的情境推理?

    Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?. (arXiv:2305.12096v1 [cs.CL])

    [http://arxiv.org/abs/2305.12096](http://arxiv.org/abs/2305.12096)

    本文研究了最先进的NLP模型能否正确地推理打破常见假设的情况的语境，并系统地创建了相应的评估数据。

    

    在大规模文本预训练的基础上，语言模型可以获取丰富的事实和常识知识，从而在各种语言理解任务中获得非凡的性能。然而，现实世界中经常出现不符合这些规律的情况，即打破常见假设的场景。最先进的NLP模型能否正确地推理这些情况的语境呢？本文研究了模型正确处理打破常见假设的情境的能力。为此，我们首先系统地创建了评估数据，每个数据实例都包括一个常见假设、一个遵循该假设的语境、一个打破该假设的语境和基于这些语境的问题。然后，在实验中对模型进行了评估。

    Pre-training on large corpora of text enables the language models to acquire a vast amount of factual and commonsense knowledge which allows them to achieve remarkable performance on a variety of language understanding tasks. They typically acquire this knowledge by learning from the pre-training text and capturing certain patterns from it. However, real-world settings often present scenarios that do not abide by these patterns i.e. scenarios that break the common assumptions. Can state-of-the-art NLP models correctly reason over the contexts of such scenarios?  Addressing the above question, in this paper, we investigate the ability of models to correctly reason over contexts that break the common assumptions. To this end, we first systematically create evaluation data in which each data instance consists of (a) a common assumption, (b) a context that follows the assumption, (c) a context that breaks the assumption, and (d) questions based on the contexts. Then, through evaluations on
    
[^15]: ESCOXLM-R: 多语言的基于分类法的职业培训

    ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain. (arXiv:2305.12092v1 [cs.CL])

    [http://arxiv.org/abs/2305.12092](http://arxiv.org/abs/2305.12092)

    本论文提出了一种名为ESCOXLM-R的多语言语言模型，它使用领域自适应预训练技术，能够成功地处理职业市场领域的多项任务。

    

    自然语言处理（NLP）任务的基准数量在计算职业市场领域不断增加，强调需要能够处理与技能提取、技能分类、工作标题分类和去标识符等方面相关的职相关任务的方法。虽然已经开发了一些特定于职业市场领域的方法，但缺乏通用的、多语言的模型和这些任务的基准。在本研究中，我们介绍了一种语言模型，称为ESCOXLM-R，它是基于XLM-R的，使用欧洲技能、竞争力、资格和职业ESCO分类法的领域自适应预训练，覆盖27种语言。ESCOXLM-R的预训练目标包括动态遮盖语言建模和引入多语言分类ESCOS关系的新型附加目标。我们在4种语言上对ESCOXLM-R的6个序列标签任务和3个分类任务进行全面评估，发现它取得了极好的表现。

    The increasing number of benchmarks for Natural Language Processing (NLP) tasks in the computational job market domain highlights the demand for methods that can handle job-related tasks such as skill extraction, skill classification, job title classification, and de-identification. While some approaches have been developed that are specific to the job market domain, there is a lack of generalized, multilingual models and benchmarks for these tasks. In this study, we introduce a language model called ESCOXLM-R, based on XLM-R, which uses domain-adaptive pre-training on the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy, covering 27 languages. The pre-training objectives for ESCOXLM-R include dynamic masked language modeling and a novel additional objective for inducing multilingual taxonomical ESCO relations. We comprehensively evaluate the performance of ESCOXLM-R on 6 sequence labeling and 3 classification tasks in 4 languages and find that it achieves s
    
[^16]: 主观知识驱动的任务导向式对话建模

    "What do others think?": Task-Oriented Conversational Modeling with Subjective Knowledge. (arXiv:2305.12091v1 [cs.CL])

    [http://arxiv.org/abs/2305.12091](http://arxiv.org/abs/2305.12091)

    该研究提出了一种主观知识驱动的任务导向式对话建模方法，并制作了相应数据集。该方法面临着新的挑战，例如如何汇总多个知识片段中的不同意见。

    

    任务导向式对话系统的目标是建立能够帮助用户完成特定目标的对话系统，例如预定酒店或餐厅。传统的任务导向式对话系统依赖于特定领域的API/数据库或外部事实知识来生成响应，无法满足主观用户请求（例如“Wi-Fi可靠吗？”或“餐厅环境好吗？”）。为了解决这个问题，我们提出了一个新颖的主观知识驱动的任务导向式对话建模（SK-TOD）任务。我们还提出了第一个相应的数据集，其中包含主观知识寻求对话上下文和手动注释的基于主观知识来源的响应。在与现有的任务导向式对话方法进行评估时，我们发现这个任务带来了新的挑战，如如何汇总多个知识片段中的不同意见。我们希望这个任务和数据集能促进进一步的任务导向式对话和主观内容理解的研究。代码和数据集可以在 https://github.com/alex 上找到。

    Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that assist users in accomplishing specific goals, such as booking a hotel or a restaurant. Traditional TODs rely on domain-specific APIs/DBs or external factual knowledge to generate responses, which cannot accommodate subjective user requests (e.g., "Is the WIFI reliable?" or "Does the restaurant have a good atmosphere?"). To address this issue, we propose a novel task of subjective-knowledge-based TOD (SK-TOD). We also propose the first corresponding dataset, which contains subjective knowledge-seeking dialogue contexts and manually annotated responses grounded in subjective knowledge sources. When evaluated with existing TOD approaches, we find that this task poses new challenges such as aggregating diverse opinions from multiple knowledge snippets. We hope this task and dataset can promote further research on TOD and subjective content understanding. The code and the dataset are available at https://github.com/alex
    
[^17]: UP5: 面向公平性推荐的无偏基础模型

    UP5: Unbiased Foundation Model for Fairness-aware Recommendation. (arXiv:2305.12090v1 [cs.IR])

    [http://arxiv.org/abs/2305.12090](http://arxiv.org/abs/2305.12090)

    本研究提出了一种新颖的基础模型UP5，它采用反事实公平促进技术来消除大型语言模型中的偏见，从而实现面向公平性的推荐。

    

    基于大型语言模型（LLM）等基础模型的最新进展，已将它们推到了推荐系统（RS）的前沿。此外，RS中的公平性很关键，因为许多用户将其用于决策和需求履行。然而，目前尚缺乏对推荐基础模型展示公平性水平和公平处理不同用户群组的适当方法的理解。本文侧重于用户方面的不公平问题，并通过彻底检查表明，LLMs中存在不公平性，导致不公平的推荐结果。为了消除LLM中的偏差以实现面向公平性的推荐，我们引入了一种基于反事实公平促进技术的新型无偏P5（UP5）基础模型。CFP包括两个子模块：个性化前缀提示和Prompt混合，从而增强了个体敏感属性的公平性。

    Recent advancements in foundation models such as large language models (LLM) have propelled them to the forefront of recommender systems (RS). Moreover, fairness in RS is critical since many users apply it for decision-making and demand fulfillment. However, at present, there is a lack of understanding regarding the level of fairness exhibited by recommendation foundation models and the appropriate methods for equitably treating different groups of users in foundation models. In this paper, we focus on user-side unfairness problem and show through a thorough examination that there is unfairness involved in LLMs that lead to unfair recommendation results. To eliminate bias from LLM for fairness-aware recommendation, we introduce a novel Unbiased P5 (UP5) foundation model based on Counterfactually-Fair-Prompting (CFP) techniques. CFP includes two sub-modules: a personalized prefix prompt that enhances fairness with respect to individual sensitive attributes, and a Prompt Mixture that int
    
[^18]: 前缀传播: 针对长序列参数高效调整的方法

    Prefix Propagation: Parameter-Efficient Tuning for Long Sequences. (arXiv:2305.12086v1 [cs.CL])

    [http://arxiv.org/abs/2305.12086](http://arxiv.org/abs/2305.12086)

    前缀传播是一种针对长序列参数高效调整的方法，可实现50%减少参数且在处理长文档任务时具有更优性能。

    

    参数高效调整旨在减轻针对下游任务调整预训练语言模型的大内存需求。本文提出前缀传播这一简单有效的方法来弥补目前前缀调整存在的问题，并展示前缀传播与前缀调整相比在处理长文档任务时具有更好的性能，所需参数也只有前者的一半。

    Parameter-efficient tuning aims to mitigate the large memory requirements of adapting pretrained language models for downstream tasks. For example, one popular method, prefix-tuning, prepends trainable tokens to sequences while freezing the rest of the model's parameters. Although such models attain comparable performance with fine-tuning when applied to sequences with short to moderate lengths, we show their inferior performance when modelling long sequences. To bridge this gap, we propose prefix-propagation, a simple but effective approach that conditions prefixes on previous hidden states. We empirically demonstrate that prefix-propagation outperforms prefix-tuning across long-document tasks, while using 50% fewer parameters. To further investigate the proposed architecture, we also show its advantage in calibration, and perform additional study on its relationship with kernel attention. To the best of our knowledge, this work is the first to focus on parameter-efficient learning fo
    
[^19]: 重访文本熵率恒定

    Revisiting Entropy Rate Constancy in Text. (arXiv:2305.12084v1 [cs.CL])

    [http://arxiv.org/abs/2305.12084](http://arxiv.org/abs/2305.12084)

    本论文使用神经语言模型重新评估了基于n-gram语言模型下英文文本的概率提出的熵率恒定原理，未能找到明显的支持熵率恒定的证据。

    

    统一信息密度（UID）假说表明，人类倾向于在话语或话语中大致均匀分布信息。支持UID假说的早期证据来自Genzel＆Charniak（2002），他们基于n-gram语言模型下英文文本的概率提出了熵率恒定原理。本文使用神经语言模型重新评估Genzel＆Charniak（2002）的说法，未能找到明显的支持熵率恒定的证据。我们在数据集、模型大小和语言等方面进行了一系列实验，并讨论了统一信息密度假说和更广泛的有效传播语言理论的含义。

    The uniform information density (UID) hypothesis states that humans tend to distribute information roughly evenly across an utterance or discourse. Early evidence in support of the UID hypothesis came from Genzel & Charniak (2002), which proposed an entropy rate constancy principle based on the probability of English text under n-gram language models. We re-evaluate the claims of Genzel & Charniak (2002) with neural language models, failing to find clear evidence in support of entropy rate constancy. We conduct a range of experiments across datasets, model sizes, and languages and discuss implications for the uniform information density hypothesis and linguistic theories of efficient communication more broadly.
    
[^20]: 利用骨架辅助的提示传递进行少样本对话摘要

    Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer. (arXiv:2305.12077v1 [cs.CL])

    [http://arxiv.org/abs/2305.12077](http://arxiv.org/abs/2305.12077)

    该论文提出了一种利用骨架辅助的提示传递进行少样本对话摘要的方法，利用骨架生成作为额外的监督来更好地消耗对话状态信息，并提出了一种新型模型SkeletonNet进行骨架生成，实现了最先进的性能。

    

    在现实场景中，对话摘要的标记样本通常是有限的（即少样本），因为为高质量的对话摘要付出高昂的注释成本。为了有效地从少样本样本中学习，先前的工作利用了其他下游任务的海量注释数据，并在提示调整中执行提示传递，以实现跨任务知识传输。然而，现有的通用提示传递技术缺乏对对话特定信息的考虑。本文专注于改善从对话状态跟踪到对话摘要的提示传递，并提出了骨架辅助的提示传递（SAPT），它利用骨架生成作为额外的监督，作为连接不同源和目标任务的媒介，使模型更好地消耗对话状态信息。为了自动提取对话骨架作为骨架生成的受监督训练数据，我们设计了一种名为SkeletonNet的新型少样本对话摘要模型，其中涉及一个专门设计的骨架生成模块。实验结果表明，我们提出的SAPT在两个少样本对话摘要基准数据集上实现了最先进的性能。

    In real-world scenarios, labeled samples for dialogue summarization are usually limited (i.e., few-shot) due to high annotation costs for high-quality dialogue summaries. To efficiently learn from few-shot samples, previous works have utilized massive annotated data from other downstream tasks and then performed prompt transfer in prompt tuning so as to enable cross-task knowledge transfer. However, existing general-purpose prompt transfer techniques lack consideration for dialogue-specific information. In this paper, we focus on improving the prompt transfer from dialogue state tracking to dialogue summarization and propose Skeleton-Assisted Prompt Transfer (SAPT), which leverages skeleton generation as extra supervision that functions as a medium connecting the distinct source and target task and resulting in the model's better consumption of dialogue state information. To automatically extract dialogue skeletons as supervised training data for skeleton generation, we design a novel 
    
[^21]: DisCo: 使用蒸馏聚合协同训练半监督文本挖掘的轻量级模型

    DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining. (arXiv:2305.12074v1 [cs.CL])

    [http://arxiv.org/abs/2305.12074](http://arxiv.org/abs/2305.12074)

    DisCo是一个半监督学习的框架，能够使用知识蒸馏的方法微调由大型预训练语言模型生成的小型学生模型，采用协同训练技术，通过多视角的知识共享来优化模型。实验结果表明DisCo相对于已有方法，具有更高的效果和更小的模型尺寸。

    

    许多文本挖掘模型是通过在下游任务中微调大型深度预训练语言模型（PLM）构建的。然而，当我们使用具有有限标记样本的轻量级模型时，其中重要的挑战是保持性能。我们提出了DisCo，这是一种半监督学习（SSL）框架，可用于微调由大型PLM生成的小型学生模型队列，该队列使用知识蒸馏方法。我们的关键洞察力是共享精华知识以促进其SSL有效性的蒸馏学生队列之间的知识共享。DisCo采用了一种新的协同训练技术，通过在不同的蒸馏策略和各种输入增强产生的模型视图和数据视图下促进学生之间的知识共享来优化多个小学生模型。我们针对半监督文本分类和提取式总结任务对DisCo进行评估。实验结果表明，DisCo可以产生比原始模型小7.6倍和比已有方法更好的结果。

    Many text mining models are constructed by fine-tuning a large deep pre-trained language model (PLM) in downstream tasks. However, a significant challenge is maintaining performance when we use a lightweight model with limited labeled samples. We present DisCo, a semi-supervised learning (SSL) framework for fine-tuning a cohort of small student models generated from a large PLM using knowledge distillation. Our key insight is to share complementary knowledge among distilled student cohorts to promote their SSL effectiveness. DisCo employs a novel co-training technique to optimize multiple small student models by promoting knowledge sharing among students under diversified views: model views produced by different distillation strategies and data views produced by various input augmentations. We evaluate DisCo on both semi-supervised text classification and extractive summarization tasks. Experimental results show that DisCo can produce student models that are 7.6 times smaller and 4.8 t
    
[^22]: 基于n-best重排序的精准知识蒸馏

    Accurate Knowledge Distillation with n-best Reranking. (arXiv:2305.12057v1 [cs.CL])

    [http://arxiv.org/abs/2305.12057](http://arxiv.org/abs/2305.12057)

    该论文提出了一种基于n-best重排序的知识蒸馏方法，通过使用多种模型提供伪标签，训练出参数更少但精度相当的学生模型。

    

    我们提出了一种带有n-best重排序的序列级别知识蒸馏方法，该方法考虑了教师模型的top-1假设以及top n-best假设。我们的方法利用包括公开可用的大型预训练模型在内的多种模型，为训练学生模型提供更准确的伪标签。我们在WMT21德英翻译任务上验证了我们的提议，并证明我们的学生模型在具有两个数量级较少的参数的情况下，实现了与Tran等人（2021年）的包含47亿参数的大型翻译模型相当的精度。

    We propose extending the Sequence-level Knowledge Distillation (Kim and Rush, 2016) with n-best reranking to consider not only the top-1 hypotheses but also the top n-best hypotheses of teacher models. Our approach leverages a diverse set of models, including publicly-available large pretrained models, to provide more accurate pseudo-labels for training student models. We validate our proposal on the WMT21 German-English translation task and demonstrate that our student model achieves comparable accuracy to a large translation model with 4.7 billion parameters from (Tran et al., 2021) while having two orders of magnitude fewer parameters.
    
[^23]: 临床骆驼：一种具有基于对话的知识编码的开源专家级医学语言模型

    Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding. (arXiv:2305.12031v1 [cs.CL])

    [http://arxiv.org/abs/2305.12031](http://arxiv.org/abs/2305.12031)

    临床骆驼是一种基于对话的知识编码的开源医学语言模型，具有很高的可解释性和临床相关性，并在多个基准数据集上取得了最先进的结果。

    

    大型语言模型（LLM）在医疗领域具有巨大潜力，但数据隐私、监管合规性和模型稳定性等问题限制了它们的广泛应用。为了应对这些挑战，我们提出了基于对话的知识编码（DBKE）。DBKE增强了模型的隐式知识库，使其具有更强的对话能力，为后续用例提供了软对齐。我们提出了Clinical Camel，这是一个开源的、专注于医疗保健的会话模型，来展示DBKE的有效性。Clinical Camel在几个基准数据集上实现了最先进的结果，同时保持了高水平的可解释性和临床相关性。它还为医疗应用提供了一个可信赖的、开放源代码的替代品。

    Large Language Models (LLMs) present immense potential in the medical field, yet concerns over data privacy, regulatory compliance, and model stability restrict their widespread adoption. Although the distillation of high-performing closed-source LLMs has proven effective for general tasks, their application in healthcare is limited due to reduced domain knowledge and remnants of alignment behavior hindering clinical tasks. To address these challenges, we propose Dialogue-Based Knowledge Encoding (DBKE). DBKE enhances models' implicit knowledge base and primes them for conversational recall, augmenting their conversational capabilities and enabling a soft alignment for subsequent use cases. By transforming dense academic source text into synthetic dialogue, DBKE broadens the model's knowledge base and enables a soft alignment that guides downstream behaviours. We present Clinical Camel, an open-source, healthcare-focused conversational model, to showcase the effectiveness of DBKE. Clin
    
[^24]: MultiTurnCleanup：用于多轮口语会话转录清理的基准测试

    MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup. (arXiv:2305.12029v1 [cs.CL])

    [http://arxiv.org/abs/2305.12029](http://arxiv.org/abs/2305.12029)

    本研究提出了MultiTurnCleanup任务，收集了新的数据集MultiTurnCleanup1，针对口语会话转录中的不连续现象进行探讨并提供了两个可用于未来研究的基准测试模型。

    

    目前的语调不连续检测模型侧重于单个说话者的每个话语。然而，口语会话转录中的许多不连续现象都发生在多轮对话中，这影响了人类的可读性和下游 NLP 任务的性能。本研究通过提出创新的“MultiTurnCleanup”任务，针对口语会话转录中的不连续现象进行探讨，并收集了新的数据集MultiTurnCleanup1。我们设计了一种数据标注模式以收集高质量的数据集，提供了广泛的数据分析。此外，我们利用两种建模方法进行实验评估，作为未来研究的基准测试。

    Current disfluency detection models focus on individual utterances each from a single speaker. However, numerous discontinuity phenomena in spoken conversational transcripts occur across multiple turns, hampering human readability and the performance of downstream NLP tasks. This study addresses these phenomena by proposing an innovative Multi-Turn Cleanup task for spoken conversational transcripts and collecting a new dataset, MultiTurnCleanup1. We design a data labeling schema to collect the high-quality dataset and provide extensive data analysis. Furthermore, we leverage two modeling approaches for experimental evaluation as benchmarks for future research.
    
[^25]: 极地鸭子的发现之旅：使用鸭式辨析和极坐标盒嵌入增强实体链接

    Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings. (arXiv:2305.12027v1 [cs.CL])

    [http://arxiv.org/abs/2305.12027](http://arxiv.org/abs/2305.12027)

    本文提出了 DUCK 方法，通过使用实体类型的先前知识在实体表示空间中注入结构信息。把盒嵌入概念引入到极坐标中，将关系表示为超球面上的盒子，将具有相似类型的实体放置在对应于它们关系的盒子内，实现聚类。在实体链接方面取得了最先进的结果，尤其在低资源环境下效果显著。

    

    基于密集检索的实体链接方法是大规模应用中高效且广泛使用的解决方案，但它们在性能上不如生成模型，因为它们对嵌入空间的结构敏感。为解决此问题，本文提出了 DUCK 方法，通过使用实体类型的先前知识在实体表示空间中注入结构信息。受编程语言中鸭式辨析的启发，我们提议根据实体在知识图中的关系定义实体的类型。然后，将盒嵌入的概念移植到球形极坐标中，我们提议将关系表示为超球面上的盒子。我们通过将具有相似类型的实体放置在对应于它们关系的盒子内来优化模型以聚类实体。我们的实验证明，我们的方法在标准实体消歧基准测试上设置了新的最先进结果，它提高了密集检索方法的性能，并且特别不适用于生成模型不可行的低资源环境。

    Entity linking methods based on dense retrieval are an efficient and widely used solution in large-scale applications, but they fall short of the performance of generative models, as they are sensitive to the structure of the embedding space. In order to address this issue, this paper introduces DUCK, an approach to infusing structural information in the space of entity representations, using prior knowledge of entity types. Inspired by duck typing in programming languages, we propose to define the type of an entity based on the relations that it has with other entities in a knowledge graph. Then, porting the concept of box embeddings to spherical polar coordinates, we propose to represent relations as boxes on the hypersphere. We optimize the model to cluster entities of similar type by placing them inside the boxes corresponding to their relations. Our experiments show that our method sets new state-of-the-art results on standard entity-disambiguation benchmarks, it improves the perf
    
[^26]: BOLT：可调偏置的快速能量控制文本生成.

    BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases. (arXiv:2305.12018v1 [cs.CL])

    [http://arxiv.org/abs/2305.12018](http://arxiv.org/abs/2305.12018)

    本文提出了BOLT方法，通过可调偏置直接调整语言模型的输出logits以实现快速能量控制文本生成。与现有方法相比，在情感和主题控制等任务中表现出了更高的效率和流畅性。

    

    基于能量的模型（EBMs）因其在广泛约束范围内的高适用性而在控制生成文本方面变得流行。然而，从EBMs中进行采样是非平凡的，因为通常需要大量迭代才能收敛到合理的文本，这会减慢解码过程并使其在实际应用中不那么实用。在本文中，我们提出了BOLT，它依赖于可调偏置以直接调整语言模型的输出logits。与以往的方法不同，BOLT保持生成器的自回归性质，以断言对标记条件依赖关系和总体流畅性的强控制，因此收敛速度更快。在使用软约束（例如情感控制）和硬约束（例如关键字引导的主题控制）的受控生成任务上与最先进技术进行比较时，BOLT展示了显着的效率和流畅性改进。在情感控制方面，BOLT比竞争基线快7倍，并且更流畅。

    Energy-based models (EBMs) have gained popularity for controlled text generation due to their high applicability to a wide range of constraints. However, sampling from EBMs is non-trivial, as it often requires a large number of iterations to converge to plausible text, which slows down the decoding process and makes it less practical for real-world applications. In this work, we propose BOLT, which relies on tunable biases to directly adjust the language model's output logits. Unlike prior work, BOLT maintains the generator's autoregressive nature to assert a strong control on token-wise conditional dependencies and overall fluency, and thus converges faster. When compared with state-of-the-arts on controlled generation tasks using both soft constraints (e.g., sentiment control) and hard constraints (e.g., keyword-guided topic control), BOLT demonstrates significantly improved efficiency and fluency. On sentiment control, BOLT is 7x faster than competitive baselines, and more fluent in
    
[^27]: XuanYuan 2.0：一个具有数百亿参数的大型中文金融聊天模型

    XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters. (arXiv:2305.12002v1 [cs.CL])

    [http://arxiv.org/abs/2305.12002](http://arxiv.org/abs/2305.12002)

    XuanYuan 2.0是目前最大的中文聊天模型，采用了BLOOM-176B架构，并提出了混合微调训练方法，能够在中文金融领域提供准确和上下文适当的回答。

    

    近年来，随着大规模模型的出现，预训练语言模型经历了快速发展。然而，专门针对中文语言的开源聊天模型在规模上仍存在缺乏，尤其是在中文金融领域。为了填补这一空白，我们介绍了 XuanYuan 2.0，它是目前最大的中文聊天模型，采用了 BLOOM-176B 架构。此外，我们提出了一种新的训练方法，称为混合微调，以减轻灾难性遗忘。通过将通用领域与特定领域的知识相结合，并集成预训练与微调阶段，XuanYuan 2.0 能够在中文金融领域提供准确和上下文适当的回答。

    In recent years, pre-trained language models have undergone rapid development with the emergence of large-scale models. However, there is a lack of open-sourced chat models specifically designed for the Chinese language, especially in the field of Chinese finance, at the scale of hundreds of billions. To address this gap, we introduce XuanYuan 2.0, the largest Chinese chat model to date, built upon the BLOOM-176B architecture. Additionally, we propose a novel training method called hybrid-tuning to mitigate catastrophic forgetting. By combining general-domain with domain-specific knowledge and integrating the stages of pre-training and fine-tuning, XuanYuan 2.0 is capable of providing accurate and contextually appropriate responses in the Chinese financial domain.
    
[^28]: OPT-R: 探究解释在大型语言模型微调与提示推理技能中的作用

    OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models. (arXiv:2305.12001v1 [cs.CL])

    [http://arxiv.org/abs/2305.12001](http://arxiv.org/abs/2305.12001)

    本文探究了大型语言模型的推理能力，证明解释在模型微调过程中对性能影响不显著，但在提示模型时使用解释可提高模型在某些推理技能上的性能。

    

    本文对大型语言模型（LLMs）的推理能力进行了全面研究，特别关注代表这种模型的Open Pretrained Transformers（OPT）模型。我们在精心策划的推理语料库上微调了三种不同大小的OPT，得到了两组微调模型：没有解释的OPT-R和带有解释的OPT-RE。然后，我们利用三种提示技术对所有模型在来自SUPER-NATURAL INSTRUCTIONS基准测试的57个域外任务上进行评估，涵盖26个不同的推理技能。通过一个全面的27个配置和6,156个测试评估矩阵，我们研究了微调、提示和规模的维度，以了解在不同推理技能方面解释的作用。我们的研究发现，在模型微调时，fewshot示例中有没有解释对模型的性能没有显著影响，而在提示模型时使用解释可提高模型在某些推理技能上的性能。

    In this paper, we conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the SUPER-NATURALINSTRUCTIONS benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model's performance when the model is finetuned, while p
    
[^29]: 通过定义生成实现可解释的词义表示：以语义变化分析为例

    Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis. (arXiv:2305.11993v1 [cs.CL])

    [http://arxiv.org/abs/2305.11993](http://arxiv.org/abs/2305.11993)

    该论文提出使用自动生成的自然语言定义作为词义表示，可以使语义变化分析更具可解释性，并允许用户直观解释词义的历时轨迹。此外，上下文化的定义在上下文中的语义相似性上也优于令牌或使用句嵌入。

    

    我们提出使用自动生成的自然语言定义来表示可解释的词和词义。给定一个目标词的使用示例集合和相应的数据驱动使用聚类（即词义），使用专门的Flan-T5语言模型为每个用法生成定义，并选择使用聚类中最具代表性的定义作为该词义标签。我们展示了如何使用生成的词义标签使现有的语义变化分析方法更具可解释性，以及如何允许用户 - 历史语言学家、词典编纂者或社会科学家 - 探索并直观地解释词义的历时轨迹。语义变化分析仅是“定义作为表示”的模式的众多可能应用之一。除了人类可读外，上下文化的定义在上下文中的语义相似性上也优于令牌或使用句嵌入。

    We propose using automatically generated natural language definitions of contextualised word usages as interpretable word and word sense representations. Given a collection of usage examples for a target word, and the corresponding data-driven usage clusters (i.e., word senses), a definition is generated for each usage with a specialised Flan-T5 language model, and the most prototypical definition in a usage cluster is chosen as the sense label.  We demonstrate how the resulting sense labels can make existing approaches to semantic change analysis more interpretable, and how they can allow users -historical linguists, lexicographers, or social scientists -- to explore and intuitively explain diachronic trajectories of word meaning. Semantic change analysis is only one of many possible applications of the `definitions as representations' paradigm. Beyond being human-readable, contextualised definitions also outperform token or usage sentence embeddings in word-in-context semantic simi
    
[^30]: 在零-shot封闭生成式问答中评估大小为中型-大型语言模型

    Evaluation of medium-large Language Models at zero-shot closed book generative question answering. (arXiv:2305.11991v1 [cs.CL])

    [http://arxiv.org/abs/2305.11991](http://arxiv.org/abs/2305.11991)

    本文评估了大小为中型的语言模型在没有外部检索的情况下完成问答任务的表现，结果表明使用适当的训练数据进行模型微调比单纯依赖参数数量更重要，最好的模型实现了46.4%的正确率。

    

    大型语言模型（LLMs）引起了重要关注，但“大”这个定义缺乏清晰度。本文关注中型语言模型（MLMs），这被定义为具有至少60亿参数但少于1000亿的模型。本研究评估MLMs在零-shot生成式问答方面的表现，这要求模型提供详细的答案而无需外部文档检索。本文引入了一个新的测试数据集，并给出了人类评估的结果，结果显示将不同MLMs的最佳答案组合可以实现82.7%的整体正确率，优于ChatGPT的60.9%。表现最好的MLM实现了46.4%，其具有70亿参数，强调了使用适当的训练数据进行微调的重要性，而不是仅仅依赖于参数数量。更细粒度的反馈应该被用于进一步提高答案的质量。

    Large language models (LLMs) have garnered significant attention, but the definition of "large" lacks clarity. This paper focuses on medium-sized lan-guage models (MLMs), defined as having at least six billion parameters but less than 100 billion. The study evaluates MLMs regarding zero-shot genera-tive question answering, which requires models to provide elaborate answers without external document retrieval. The paper introduces an own test da-taset and presents results from human evaluation. Results show that combin-ing the best answers from different MLMs yielded an overall correct answer rate of 82.7% which is better than the 60.9% of ChatGPT. The best MLM achieved 46.4% and has 7B parameters, which highlights the importance of using appropriate training data for fine-tuning rather than solely relying on the number of parameters. More fine-grained feedback should be used to further improve the quality of answers.
    
[^31]: 弱监督方法用于少样本方面情感分析

    A Weak Supervision Approach for Few-Shot Aspect Based Sentiment. (arXiv:2305.11979v1 [cs.CL])

    [http://arxiv.org/abs/2305.11979](http://arxiv.org/abs/2305.11979)

    该论文研究了如何通过弱监督学习方法提高少样本情感分析性能，并提出了一种基于管道方法的嘈杂数据集调整预训练的模型以适应少样本情感分析任务，在未经微调时能胜过之前的状态艺术。

    

    我们研究了如何利用大量未标记数据的弱监督来提高少样本方面情感分析（ABSA）任务的性能。我们提出了一种管道方法来构建一个嘈杂的ABSA数据集，并将其用于调整预训练的序列到序列模型以适应ABSA任务。我们在三个广泛使用的ABSA数据集上测试了结果模型，在微调之前和之后。我们提出的方法在保持完整微调性能的同时，在较难的任务的少样本学习场景中显示出显着的改进（15.84％绝对F1）。在零样本（即无需微调）中，我们的方法胜过以前的状态艺术在方面提取情感分类（AESC）任务上，此外还能够执行更难的方面情感三元组提取（ASTE）任务。

    We explore how weak supervision on abundant unlabeled data can be leveraged to improve few-shot performance in aspect-based sentiment analysis (ABSA) tasks. We propose a pipeline approach to construct a noisy ABSA dataset, and we use it to adapt a pre-trained sequence-to-sequence model to the ABSA tasks. We test the resulting model on three widely used ABSA datasets, before and after fine-tuning. Our proposed method preserves the full fine-tuning performance while showing significant improvements (15.84% absolute F1) in the few-shot learning scenario for the harder tasks. In zero-shot (i.e., without fine-tuning), our method outperforms the previous state of the art on the aspect extraction sentiment classification (AESC) task and is, additionally, capable of performing the harder aspect sentiment triplet extraction (ASTE) task.
    
[^32]: 自我问答：无监督知识引导的语言模型对齐

    Self-QA: Unsupervised Knowledge Guided Language Model Alignment. (arXiv:2305.11952v1 [cs.CL])

    [http://arxiv.org/abs/2305.11952](http://arxiv.org/abs/2305.11952)

    Self-QA是一种无监督知识引导的语言模型对齐框架，使用大量的无监督知识来代替传统的人工撰写的指令种子，以生成更多正确且特定于领域的指令数据。

    

    ChatGPT 和 GPT-4 等大规模语言模型因其出色的对话和生成能力而备受关注。然而，为指导模型调整而创建监督式配对的问答数据是一项艰巨的挑战。这需要大量的人力用于数据注释并涉及数据质量、多样性、准确性和其他相关因素的问题。为了克服这些障碍，我们引入了一个创新的框架，名为 Self-QA，它用大量的无监督知识代替传统的人工撰写的指令种子，使模型能够生成更多正确且特定于领域的指令数据。我们的方法的有效性通过在不同领域的无监督语料库上进行实验得到了证明。

    Large-scale language models like ChatGPT and GPT-4 have gained attention for their impressive conversational and generative capabilities. However, the creation of supervised paired question-answering data for instruction tuning presents formidable challenges. This endeavor necessitates substantial human effort for data annotation and wrestles with issues concerning data quality, diversity, accuracy, and other related factors. To overcome these obstacles, we introduce an innovative framework named Self-QA, which replaces the traditional practice of human-written instruction seeds with a vast amount of unsupervised knowledge, enabling the model to generate a larger quantity of correct and domain-specific instruction data. The effectiveness of our proposed method is demonstrated through experiments conducted on unsupervised corpora from various domains.
    
[^33]: 眼科笔记中的空间信息提取：Eye-SpatialNet

    Eye-SpatialNet: Spatial Information Extraction from Ophthalmology Notes. (arXiv:2305.11948v1 [cs.CL])

    [http://arxiv.org/abs/2305.11948](http://arxiv.org/abs/2305.11948)

    本研究提出了Eye-SpatialNet模式，用于表示眼科文本中的空间语言，并使用BERT语言模型自动提取空间信息，实现了对眼科实体空间和语境信息的自动化精准标注和提取。

    

    我们介绍了一个带有详细眼科实体空间和语境信息标注的600个眼科笔记的语料库。我们扩展了我们先前提出的基于框架语义的空间表示模式Rad-SpatialNet，以表示眼科文本中的空间语言，从而得到了Eye-SpatialNet模式。空间定位的实体是发现、程序和药物。为了准确捕获所有的空间细节，我们在Eye-SpatialNet中添加了一些特定领域的元素。标注的语料库包含1715个空间触发器、7308个发现、2424个解剖学和9914个描述符。为了自动提取空间信息，我们采用了基于 transformer 语言模型 BERT 的两轮问答方法。结果很有前途，F1 得分分别为 89.31、74.86 和 88.47，用于空间触发器、图形和地面框架元素。这是第一篇在眼科领域中表示和提取各种临床信息的工作。

    We introduce an annotated corpus of 600 ophthalmology notes labeled with detailed spatial and contextual information of ophthalmic entities. We extend our previously proposed frame semantics-based spatial representation schema, Rad-SpatialNet, to represent spatial language in ophthalmology text, resulting in the Eye-SpatialNet schema. The spatially-grounded entities are findings, procedures, and drugs. To accurately capture all spatial details, we add some domain-specific elements in Eye-SpatialNet. The annotated corpus contains 1715 spatial triggers, 7308 findings, 2424 anatomies, and 9914 descriptors. To automatically extract the spatial information, we employ a two-turn question answering approach based on the transformer language model BERT. The results are promising, with F1 scores of 89.31, 74.86, and 88.47 for spatial triggers, Figure, and Ground frame elements, respectively. This is the first work to represent and extract a wide variety of clinical information in ophthalmology.
    
[^34]: 探索用于相关性预测的合成查询生成的可行性

    Exploring the Viability of Synthetic Query Generation for Relevance Prediction. (arXiv:2305.11944v1 [cs.IR])

    [http://arxiv.org/abs/2305.11944](http://arxiv.org/abs/2305.11944)

    本文研究在电子商务和医疗保健等专业领域中，利用强大的模型生成高质量特定任务和领域的合成数据，探索用于预测对文档的查询分级相关性的方法，并尝试使用无监督聚类技术进一步改进对数据中相关性模式的理解。

    

    查询-文档相关性预测是信息检索系统中的一个关键问题。这个问题越来越多地使用（预先训练的）基于转换器的模型来解决，这些模型使用大量标记数据进行微调。然而，在电子商务和医疗保健等专业领域，这种方法的可行性受到领域内大规模数据的匮乏限制。为了解决这个问题，最近的方法利用这些强大的模型生成高质量的特定任务和领域的合成数据。先前的工作主要探索了合成数据生成或用于问答和二元（是/否）相关性预测的查询生成（QGen）, 其中例如，QGen模型给出一个文档，并训练生成一个与该文档相关的查询。然而，在许多问题中，我们对相关性有一个更细粒度的概念，而不是一个简单的是/否标签。因此，在这项工作中，我们进行了详细的研究，探讨了如何利用QGen方法实现细微的相关性预测。具体而言，我们研究了使用合成查询来预测对文档的查询分级相关性的有效性，并探索使用无监督聚类技术进一步改进对数据中相关性模式的理解。

    Query-document relevance prediction is a critical problem in Information Retrieval systems. This problem has increasingly been tackled using (pretrained) transformer-based models which are finetuned using large collections of labeled data. However, in specialized domains such as e-commerce and healthcare, the viability of this approach is limited by the dearth of large in-domain data. To address this paucity, recent methods leverage these powerful models to generate high-quality task and domain-specific synthetic data. Prior work has largely explored synthetic data generation or query generation (QGen) for Question-Answering (QA) and binary (yes/no) relevance prediction, where for instance, the QGen models are given a document, and trained to generate a query relevant to that document. However in many problems, we have a more fine-grained notion of relevance than a simple yes/no label. Thus, in this work, we conduct a detailed study into how QGen approaches can be leveraged for nuanced
    
[^35]: XTREME-UP：针对少样本数据的用户中心稀缺数据基准测试，在代表性不足的语言上进行评估

    XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented Languages. (arXiv:2305.11938v1 [cs.CL])

    [http://arxiv.org/abs/2305.11938](http://arxiv.org/abs/2305.11938)

    该论文提出了 XTREME-UP，一个以少量数据评估代表性不足语言的 NLP 系统性能的用户中心稀缺数据基准测试。它专注于用户中心任务，聚焦于代表性不足的语言，覆盖 88 种语言，并介绍了新的 OCR、自动完成、语义分析和音译数据集，旨在帮助推进代表性不足语言的高度多语言 NLP 系统的发展。

    

    数据稀缺是高度多语言 NLP 系统发展的关键问题。然而对于许多代表性不足的语言（UL）—— NLP 研究在满足用户需求方面特别滞后的语言——注释少量数据是可行的。基于此，我们提出了 XTREME-UP，这是一个基准测试，其重点是稀缺数据方案而不是零样本；其聚焦于用户中心任务（即许多高资源语言使用者广泛采用的任务）；以及其聚焦于代表性不足的语言，在这些语言中，稀缺数据的情况往往最为现实。XTREME-UP 评估语言模型在 88 种代表性不足的语言上，跨越了 9 项主要的用户中心技术，包括 ASR、OCR、MT 和信息访问任务。我们为 OCR、自动完成、语义分析和音译创建了新的数据集，并在其他任务上构建并完善了现有的数据集。XTREME-UP 提供了一种评估 NLP 系统在代表性不足的语言上稀缺数据方案的性能的方法。它专注于实际价值对于高资源语言使用者的用户中心任务，并涵盖了 88 种语言。其目标是帮助推进多语言 NLP 系统对于稀缺数据资源的代表性不足的语言的发展。

    Data scarcity is a crucial issue for the development of highly multilingual NLP systems. Yet for many under-represented languages (ULs) -- languages for which NLP re-search is particularly far behind in meeting user needs -- it is feasible to annotate small amounts of data. Motivated by this, we propose XTREME-UP, a benchmark defined by: its focus on the scarce-data scenario rather than zero-shot; its focus on user-centric tasks -- tasks with broad adoption by speakers of high-resource languages; and its focus on under-represented languages where this scarce-data scenario tends to be most realistic. XTREME-UP evaluates the capabilities of language models across 88 under-represented languages over 9 key user-centric technologies including ASR, OCR, MT, and information access tasks that are of general utility. We create new datasets for OCR, autocomplete, semantic parsing, and transliteration, and build on and refine existing datasets for other tasks. XTREME-UP provides methodology for e
    
[^36]: MParrotTTS：低资源环境下的多语言多说话人文本转语音合成

    MParrotTTS: Multilingual Multi-speaker Text to Speech Synthesis in Low Resource Setting. (arXiv:2305.11926v1 [cs.SD])

    [http://arxiv.org/abs/2305.11926](http://arxiv.org/abs/2305.11926)

    MParrotTTS是一个统一的多语言、多说话人文本转语音合成模型，以自监督语音表示为基础；它可以在低资源环境中仅使用少量有监督数据就适应于新语言，并在不需要平行或双语语料的情况下传递说话人特定的语音特征。

    

    我们介绍了MParrotTTS，这是一个统一的多语言、多说话人文本转语音(TTS)合成模型，可以产生高质量的语音。MParrotTTS受益于模块化培训范式，利用自监督语音表示，以最小的监督数据适应于新语言，并在训练自监督后骨干中对未见过的语言进行泛化。此外，MParrotTTS不需要任何双语或平行示例的训练，可以在语音中传递语音，同时保留说话人的特定特征，例如使用法语演讲者的声音和口音合成流利的印地语语音。我们在六种语言上提出了广泛的结果，包括并行和跨语言综合的语音自然度和说话人相似度。所提出的模型在只使用少量监督训练数据的情况下，优于最先进的多语言TTS模型和基线。我们的模型可在https://paper2438.github.io/tts上找到。

    We present MParrotTTS, a unified multilingual, multi-speaker text-to-speech (TTS) synthesis model that can produce high-quality speech. Benefiting from a modularized training paradigm exploiting self-supervised speech representations, MParrotTTS adapts to a new language with minimal supervised data and generalizes to languages not seen while training the self-supervised backbone. Moreover, without training on any bilingual or parallel examples, MParrotTTS can transfer voices across languages while preserving the speaker-specific characteristics, e.g., synthesizing fluent Hindi speech using a French speaker's voice and accent. We present extensive results on six languages in terms of speech naturalness and speaker similarity in parallel and cross-lingual synthesis. The proposed model outperforms the state-of-the-art multilingual TTS models and baselines, using only a small fraction of supervised training data. Speech samples from our model can be found at https://paper2438.github.io/tts
    
[^37]: 由生成式AI合作创作的研究的评价：实验证据

    Judgments of research co-created by generative AI: experimental evidence. (arXiv:2305.11873v1 [cs.HC])

    [http://arxiv.org/abs/2305.11873](http://arxiv.org/abs/2305.11873)

    本研究探讨了把研究中部分内容交由生成式AI完成，会导致人们不信任和贬低研究人员和科学输出，并可能影响到生成式AI使用的报告问题。

    

    ChatGPT的引入引发了关于生成式AI（大型语言模型；LLMs）的使用的公共争论，包括研究人员的使用。在本研究中，我们测试了将研究过程的某些部分委托给LLMs是否会导致人们不信任和贬低研究人员和科学输出。参与者（N=402）考虑一个将研究过程的元素委托给博士生或LLM的研究人员，并对以下进行评分：（1）道德可接受性，（2）相信科学家监督未来项目，以及（3）输出的准确性和质量。人们认为将任务委托给LLMs比委托给人类不太可接受（d=-0.78）。委托给LLMs也会降低人们对于监督未来研究项目的信任（d=-0.80），而且人们认为结果的准确性和质量会更低（d=-0.85）。我们讨论了这种贬值如何转化为LLMs使用的低估问题。

    The introduction of ChatGPT has fuelled a public debate on the use of generative AI (large language models; LLMs), including its use by researchers. In the current work, we test whether delegating parts of the research process to LLMs leads people to distrust and devalue researchers and scientific output. Participants (N=402) considered a researcher who delegates elements of the research process to a PhD student or LLM, and rated (1) moral acceptability, (2) trust in the scientist to oversee future projects, and (3) the accuracy and quality of the output. People judged delegating to an LLM as less acceptable than delegating to a human (d = -0.78). Delegation to an LLM also decreased trust to oversee future research projects (d = -0.80), and people thought the results would be less accurate and of lower quality (d = -0.85). We discuss how this devaluation might transfer into the underreporting of generative AI use.
    
[^38]: 基于fMRI的语言编码模型的规模定律研究

    Scaling laws for language encoding models in fMRI. (arXiv:2305.11863v1 [cs.CL])

    [http://arxiv.org/abs/2305.11863](http://arxiv.org/abs/2305.11863)

    本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。

    

    基于变压器的单向语言模型的表示已被证明能够有效地预测大脑对自然语言的反应。然而，大多数比较语言模型与大脑的研究都使用了类似GPT-2大小的语言模型。本研究测试了是否更大的开源模型（如OPT和LLaMA系列）更适用于预测使用fMRI记录的大脑反应。结果显示，在从125M到30B参数模型进行规模扩展时，大脑预测性能与模型大小呈对数线性关系，跨3个受试者的保留测试集相关性表现提高了约15％。当扩展fMRI训练集的大小时，我们也观察到了类似的对数线性行为。我们还对使用HuBERT，WavLM和Whisper的声学编码模型进行了规模定律研究，发现模型大小的增加带来了类似的改进。我们还使用噪音天花板分析了这些大规模且高性能的编码模型。

    Representations from transformer-based unidirectional language models are known to be effective at predicting brain responses to natural language. However, most studies comparing language models to brains have used GPT-2 or similarly sized language models. Here we tested whether larger open-source models such as those from the OPT and LLaMA families are better at predicting brain responses recorded using fMRI. Mirroring scaling results from other contexts, we found that brain prediction performance scales log-linearly with model size from 125M to 30B parameter models, with ~15% increased encoding performance as measured by correlation with a held-out test set across 3 subjects. Similar log-linear behavior was observed when scaling the size of the fMRI training set. We also characterized scaling for acoustic encoding models that use HuBERT, WavLM, and Whisper, and we found comparable improvements with model size. A noise ceiling analysis of these large, high-performance encoding models 
    
[^39]: LLM在医学系统综述中的潜在用途和风险评估

    Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews. (arXiv:2305.11828v1 [cs.CL])

    [http://arxiv.org/abs/2305.11828](http://arxiv.org/abs/2305.11828)

    本文研究了使用LLM协助制作医学证据综述的潜在用途和风险，指出LLM有可能自动生成文献综述，但由于可能出现虚构或遗漏信息的情况，LLM的使用需要谨慎。

    

    医学系统综述对于制定临床决策和医疗政策至关重要。但是制作这样的综述很费力且耗时。因此，很多问题缺乏高质量的证据综述，即使这些综述可用，在审查过程中可能已经过时。现在，大型语言模型（LLM）已经能够生成长篇文本，这意味着自动生成文献综述的诱人可能性。然而，由于虚构或遗漏重要信息，LLM有时会产生不准确（甚至可能具有误导性）的文本。在医疗保健环境中，这可能使LLM在最好情况下无法使用，在最坏情况下会带来危险。对于LLM的益处和风险的大多数讨论与具体应用脱离了关系。在这项工作中，我们试图定性描述LLM在协助制作医学证据综述方面的潜在用途和风险。我们对16位国际专家进行了半结构化访谈。

    Medical systematic reviews are crucial for informing clinical decision making and healthcare policy. But producing such reviews is onerous and time-consuming. Thus, high-quality evidence synopses are not available for many questions and may be outdated even when they are available. Large language models (LLMs) are now capable of generating long-form texts, suggesting the tantalizing possibility of automatically generating literature reviews on demand. However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucinating or omitting important information. In the healthcare context, this may render LLMs unusable at best and dangerous at worst. Most discussion surrounding the benefits and risks of LLMs have been divorced from specific applications. In this work, we seek to qualitatively characterize the potential utility and risks of LLMs for assisting in production of medical evidence reviews. We conducted 16 semi-structured interviews with international experts
    
[^40]: 伪代码指令提示

    Prompting with Pseudo-Code Instructions. (arXiv:2305.11790v1 [cs.CL])

    [http://arxiv.org/abs/2305.11790](http://arxiv.org/abs/2305.11790)

    本文研究了使用伪代码指令提示能否提高预训练语言模型的性能，实验证明使用伪代码提示可以在分类任务中提高7-16分，并相对改善12-38%。

    

    最近，使用自然语言指令提示已成为利用大型语言模型能力的一种流行方法。鉴于自然语言中的固有歧义，因此考虑使用更少歧义的提示样式，如伪代码提示，可能具有优势。本文探讨了通过伪代码指令提示是否有助于改善预训练语言模型的性能。我们手动创建了一个包含来自Super-NaturalInstructions数据集的132个不同任务的伪代码提示数据集，涵盖分类、QA和生成语言任务。使用这些伪代码提示以及它们的自然语言对应物，在两个LLM家族-BLOOM和CodeGen上研究它们的性能。我们的实验表明，使用伪代码指令提示会带来更好的结果，对于分类任务，F1分数平均增加（绝对值）7-16分，相对改善12-38%。

    Prompting with natural language instructions has recently emerged as a popular method of harnessing the capabilities of large language models. Given the inherent ambiguity present in natural language, it is intuitive to consider the possible advantages of prompting with less ambiguous prompt styles, such as the use of pseudo-code.  In this paper we explore if prompting via pseudo-code instructions helps improve the performance of pre-trained language models. We manually create a dataset of pseudo-code prompts for 132 different tasks spanning classification, QA and generative language tasks, sourced from the Super-NaturalInstructions dataset. Using these prompts along with their counterparts in natural language, we study their performance on two LLM families - BLOOM and CodeGen. Our experiments show that using pseudo-code instructions leads to better results, with an average increase (absolute) of 7-16 points in F1 scores for classification tasks and an improvement (relative) of 12-38% 
    
[^41]: HELMA：大型语言模型的幻觉评估基准

    HELMA: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models. (arXiv:2305.11747v1 [cs.CL])

    [http://arxiv.org/abs/2305.11747](http://arxiv.org/abs/2305.11747)

    本文介绍了一个大型语言模型幻觉评估基准（HELMA），其为标准化和可靠的估算模型幻觉问题提供了一种方法，并使用ChatGPT进行了实证研究以表明其存在幻觉的风险并为鉴别和减轻模型幻觉问题提供了一种方法。

    

    大型语言模型（LLM），如ChatGPT，容易生成幻觉，即与源内容冲突或无法通过事实知识进行验证的内容。为了了解LLMs会产生哪种类型的内容以及在多大程度上会产生幻觉，我们引入了Hallucination Evaluation for Large Language Models（HELMA）基准，这是一个包含大量生成的和人工注释的幻觉样本集，用于评估LLMs在识别和减轻幻觉方面的性能。为了生成这些样本，我们提出了一个基于ChatGPT的两步框架，即采样-过滤。具体来说，我们首先采用两种不同的采样方法基于指令生成幻觉样本，然后使用一个示例增强过滤方法选择最好的样本。此外，我们还聘请一些人工标注员来注释ChatGPT响应中的幻觉。经验证实，ChatGPT有一定的概率产生幻觉，并存在传播错误信息的潜在风险。我们提出的HELMA基准可作为识别和减轻LLMs幻觉问题的标准化可靠评估工具。

    Large language models (LLMs), such as ChatGPT, are prone to generate hallucinations, \ie content that conflicts with the source or cannot be verified by the factual knowledge. To understand what types of content and to which extent LLMs are apt to hallucinate, we introduce the Hallucination Evaluation for Large Language Models (HELMA) benchmark, a large collection of generated and human-annotated hallucinated samples for evaluating the performance of LLMs in recognizing and alleviating hallucination. To generate these samples, we propose a ChatGPT-based two-step framework, \ie sampling-then-filtering. Specifically, we first adopt two different sampling methods to generate hallucinated samples based on instructions, and then use an example-enhanced filtering method to select the best one. Furthermore, we also hire some human labelers to annotate the hallucinations in ChatGPT responses. The empirical results suggest that ChatGPT has some probabilities to generate hallucinations and exist
    
[^42]: 大型语言模型中的内部一致性问题研究：通过辩论进行深入分析

    Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate. (arXiv:2305.11595v1 [cs.CL])

    [http://arxiv.org/abs/2305.11595](http://arxiv.org/abs/2305.11595)

    本文提出了通过辩论探究大型语言模型之间的内部一致性问题，实验证明通过严格的辩论框架可以提高模型性能和常识知识的结构化学习。

    

    大型语言模型LLMs在各种自然语言处理NLP任务中展现出了惊人的零样本或少量样本通识推理性能。然而，尽管它们拥有强大的常识推理能力，但它们仍然存在各种不一致问题。本研究提出探索两个或多个LLMs之间的内部一致性问题，这对于不同和精确的决策过程至关重要。通过严格的辩论框架，在7个常识推理数据集上进行了广泛的实验。LLMs不仅通过妥协和反驳变得更具内部一致性，而且还实现了更高的性能和常识知识的结构化学习。

    Large language models (LLMs) have demonstrated impressive zero-shot or few-shot commonsense reasoning performance on various natural language processing (NLP) tasks. However, despite their strong commonsense reasoning abilities, LLMs still exhibit various kinds of inconsistency problems. While previous researches mainly focused on the self-consistency within a single LLM, we propose to explore the inter-consistency issue between two or more LLMs, which is critical for diverse and precise decision-making processes. Since the LLMs possess human-like intelligence after instruction tuning and reinforcement learning with human feedback (RLHF), we design a formal debate framework to delve into the inter-consistency problem among LLMs with three-stage debate: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on 7 commonsense reasoning datasets, LLMs not only become more inter-consistent by compromising and refuting but also achieve higher performance and str
    
[^43]: 跨模态数据增强用于端到端手语翻译

    Cross-modality Data Augmentation for End-to-End Sign Language Translation. (arXiv:2305.11096v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.11096](http://arxiv.org/abs/2305.11096)

    本文提出了一种Cross-modality Data Augmentation（XmDA）框架，通过利用来自手语单词翻译模型的伪手语单词-文本对，将强大的手语单词到文本的翻译能力转移到了端到端手语翻译，实验结果表明XmDA在该领域中明显优于现有的最先进方法。

    

    端到端手语翻译旨在直接将手语视频转换为口语文本，无需中间表示。受手语视频和文本之间的模态差距和标记数据的稀缺性的挑战，这一任务一直很具有挑战性。为了应对这些挑战，我们提出了一种新颖的“跨模态数据增强（XmDA）”框架，通过利用来自手语单词翻译模型的伪手语单词-文本对，将强大的手语单词到文本的翻译能力转移到了端到端手语翻译（即视频到文本）。具体来说，XmDA包括两个关键组成部分，即跨模态混合和跨模态知识蒸馏。前者明确地促进手语视频特征和手语单词嵌入之间的对齐，以弥合模态差距。后者利用来自手语单词到文本的教师模型的生成知识来指导口语文本生成。在两个广泛使用的手语翻译数据集LIBRISIGN和WLASL上的实验结果表明，XmDA在自动评估指标和人类评估方面均明显优于现有的最先进方法。

    End-to-end sign language translation (SLT) aims to convert sign language videos into spoken language texts directly without intermediate representations. It has been a challenging task due to the modality gap between sign videos and texts and the data scarcity of labeled data. To tackle these challenges, we propose a novel Cross-modality Data Augmentation (XmDA) framework to transfer the powerful gloss-to-text translation capabilities to end-to-end sign language translation (i.e. video-to-text) by exploiting pseudo gloss-text pairs from the sign gloss translation model. Specifically, XmDA consists of two key components, namely, cross-modality mix-up and cross-modality knowledge distillation. The former explicitly encourages the alignment between sign video features and gloss embeddings to bridge the modality gap. The latter utilizes the generation knowledge from gloss-to-text teacher models to guide the spoken language text generation. Experimental results on two widely used SLT datase
    
[^44]: 深度学习方法用于提取花和植物的隐喻性名称

    Deep Learning Methods for Extracting Metaphorical Names of Flowers and Plants. (arXiv:2305.10833v1 [cs.CL])

    [http://arxiv.org/abs/2305.10833](http://arxiv.org/abs/2305.10833)

    本研究使用深度学习模型识别对话中基于隐喻的花和植物名称，鉴别模型表现优于GPT-3.5，最好的表现器在任务中报告了92.2349％的F1分数。

    

    植物学领域充满了隐喻性术语，这些术语在描述和识别花和植物方面起着重要作用。但是，在对话中识别这些术语是一项艰巨的任务。在翻译过程和词典编纂任务中，这往往导致错误的发生。当涉及到单词和短语时，在机器翻译方面这个过程更具挑战性。自然语言处理（NLP）应用和机器翻译（MT）技术的最新关注点之一是通过深度学习（DL）自动识别对话中基于隐喻的单词。在本研究中，我们使用了十三种流行的变压器模型以及ChatGPT来填补这一空白，并且通过F1得分证明了鉴别模型优于GPT-3.5模型，我们最好的表现器在隐喻花卉和植物名称识别任务中报告了92.2349％的F1分数。

    The domain of Botany is rich with metaphorical terms. Those terms play an important role in the description and identification of flowers and plants. However, the identification of such terms in discourse is an arduous task. This leads in some cases to committing errors during translation processes and lexicographic tasks. The process is even more challenging when it comes to machine translation, both in the cases of single-word terms and multi-word terms. One of the recent concerns of Natural Language Processing (NLP) applications and Machine Translation (MT) technologies is the automatic identification of metaphor-based words in discourse through Deep Learning (DL). In this study, we seek to fill this gap through the use of thirteen popular transformer based models, as well as ChatGPT, and we show that discriminative models perform better than GPT-3.5 model with our best performer reporting 92.2349% F1 score in metaphoric flower and plant names identification task.
    
[^45]: 生成的预训练变形器：启用技术、潜在应用、新兴挑战和未来方向的综述

    Generative Pre-trained Transformer: A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions. (arXiv:2305.10435v1 [cs.CL])

    [http://arxiv.org/abs/2305.10435](http://arxiv.org/abs/2305.10435)

    生成的预训练变形器是一种基于变形器架构的深度神经网络，能够在自然语言处理任务中表现出色且有效地进行对话，具有广泛的潜在应用，但仍面临新兴挑战和局限性。

    

    生成的预训练变形器模型代表了自然语言处理领域的一项重大突破，将我们推向开发能够像人类一样理解和使用语言进行交流的机器。生成的预训练变形器模型基于变形器架构，这是一种专门设计用于自然语言处理任务的深度神经网络。由于在自然语言处理任务上表现出色且能够有效地进行对话，生成的预训练变形器模型在研究人员和工业界社区中获得了显著的知名度，成为自然语言处理及相关领域中最广泛使用和有效的模型之一，这促使进行了本综述。本综述详细介绍了生成预训练变形器，包括其架构、工作过程、训练过程、启用技术以及在各个领域的潜在应用。同时，本综述还讨论了该模型面临的新兴挑战和局限性，并提供了未来研究的可能方向。

    The Generative Pre-trained Transformer models represent a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. Generative Pre-trained Transformer models are based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, Generative Pre-trained Transformer models have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the Generative Pre-trained Transformer, including its architecture, working process, training procedures, enabling technologies, an
    
[^46]: 你看到的就是你读到的? 改进文本-图像对齐评估方法

    What You See is What You Read? Improving Text-Image Alignment Evaluation. (arXiv:2305.10400v1 [cs.CL])

    [http://arxiv.org/abs/2305.10400](http://arxiv.org/abs/2305.10400)

    本研究介绍了SeeTRUE评估集和两种自动文本-图像对齐方法，这些方法在各种对齐任务中均取得了显着改进，在复杂组合或非自然图像的挑战性案例中表现出色。

    

    自动确定文本和相应的图像是否语义上对齐是视觉语言模型面临的一项重要挑战，应用于生成文本到图像和图像到文本任务。在本研究中，我们研究了自动文本-图像对齐评估方法。我们首先介绍了SeeTRUE：一个全面的评估集，涵盖了从文本到图像和图像到文本生成任务的多个数据集，并具有人类的判断，判断给定的文本-图像对是否语义上对齐。然后，我们描述了两种自动确定对齐的方法：第一种是基于问题生成和视觉问题回答模型的管道，第二种是通过微调多模态预训练模型的端到端分类方法。这两种方法在各种文本-图像对齐任务中均超越了先前的方法，在涉及复杂组合或非自然图像的挑战性案例中有显着改进。最后，我们证明即使最先进的模型在这个任务上还有很大的改进空间，这激励了未来在这个领域的研究。

    Automatically determining whether a text and a corresponding image are semantically aligned is a significant challenge for vision-language models, with applications in generative text-to-image and image-to-text tasks. In this work, we study methods for automatic text-image alignment evaluation. We first introduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasets from both text-to-image and image-to-text generation tasks, with human judgements for whether a given text-image pair is semantically aligned. We then describe two automatic methods to determine alignment: the first involving a pipeline based on question generation and visual question answering models, and the second employing an end-to-end classification approach by finetuning multimodal pretrained models. Both methods surpass prior approaches in various text-image alignment tasks, with significant improvements in challenging cases that involve complex composition or unnatural images. Finally, we demonstrate 
    
[^47]: UniEX：一种基于跨度提取的统一信息抽取的有效高效框架

    UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective. (arXiv:2305.10306v1 [cs.CL])

    [http://arxiv.org/abs/2305.10306](http://arxiv.org/abs/2305.10306)

    UniEX是一种能适用于各种模式格式的信息抽取框架，并能同时解决命名实体识别、关系抽取、事件提取和情感分析等任务，在性能和推理速度上优于其他通用信息抽取模型。

    

    我们提出了一种新的通用信息抽取范式，它与任何模式格式兼容，并适用于一系列信息抽取任务，如命名实体识别、关系抽取、事件提取和情感分析。我们的方法将以文本为基础的信息抽取任务转化为 token-pair 问题，使用一种统一的提取框架 UniEX，将所有提取目标都统一分解为联合跨度检测、分类和关联问题。UniEX 可以同时编码基于模式的提示和文本信息，并使用自动编码器语言模型协同学习预定义信息的广义知识。我们开发了 traffine 注意机制，将包括任务、标签和内部 token 在内的异构因素集成起来，并通过评分矩阵获得提取目标。实验结果表明，UniEX 在 $14$个基准测试数据集上的表现和推理速度都优于基于生成的通用信息抽取模型。

    We propose a new paradigm for universal information extraction (IE) that is compatible with any schema format and applicable to a list of IE tasks, such as named entity recognition, relation extraction, event extraction and sentiment analysis. Our approach converts the text-based IE tasks as the token-pair problem, which uniformly disassembles all extraction targets into joint span detection, classification and association problems with a unified extractive framework, namely UniEX. UniEX can synchronously encode schema-based prompt and textual information, and collaboratively learn the generalized knowledge from pre-defined information using the auto-encoder language models. We develop a traffine attention mechanism to integrate heterogeneous factors including tasks, labels and inside tokens, and obtain the extraction target via a scoring matrix. Experiment results show that UniEX can outperform generative universal IE models in terms of performance and inference-speed on $14$ benchmar
    
[^48]: M3KE:一种面向中国大语言模型的大规模多级多主题知识评估基准

    M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. (arXiv:2305.10263v1 [cs.CL])

    [http://arxiv.org/abs/2305.10263](http://arxiv.org/abs/2305.10263)

    本文提出了一种面向中国大语言模型的大规模多级多主题知识评估基准M3KE，收集了20,477个问题以覆盖中国教育体系的所有主要层次和广泛的学科，使用多任务准确性测试法有效地评估了四个大语言模型GPT-2，RoBERTa，ERNIE和ELECTRA对多源知识的整合和利用能力。

    

    大型语言模型最近在各个方面取得了巨大的进展，例如跨任务通用性，指令遵循等。全面评估大语言模型在多个任务中的能力非常重要。在本文中，我们提出了M3KE，一种大规模多级多主题知识评估基准，旨在通过测试零和几个示例设置下的多任务准确性来衡量中文大语言模型所获得的知识。我们收集了71个任务的20,477个问题。选择涵盖了中国教育体系的所有主要层次，从小学到大学，以及广泛的学科，包括人文，历史，政治，法律，教育，心理，科学，技术，艺术和宗教。所有问题都是四个选项的多选题，因此保证了标准化和统一的评估流程。我们使用我们的基准测试了一些最先进的开源中文大语言模型，包括GPT-2，RoBERTa，ERNIE和ELECTRA，并提供了详细的结果和分析。我们展示了M3KE可以有效地评估大型语言模型，并全面了解它们整合和利用多个知识来源的能力。

    Large language models have recently made tremendous progress in a variety of aspects, e.g., cross-task generalization, instruction following. Comprehensively evaluating the capability of large language models in multiple tasks is of great importance. In this paper, we propose M3KE, a Massive Multi-Level Multi-Subject Knowledge Evaluation benchmark, which is developed to measure knowledge acquired by Chinese large language models by testing their multitask accuracy in zero- and few-shot settings. We have collected 20,477 questions from 71 tasks. Our selection covers all major levels of Chinese education system, ranging from the primary school to college, as well as a wide variety of subjects, including humanities, history, politics, law, education, psychology, science, technology, art and religion. All questions are multiple-choice questions with four options, hence guaranteeing a standardized and unified assessment process. We've assessed a number of state-of-the-art open-source Chines
    
[^49]: MemoryBank: 用长期记忆增强大型语言模型

    MemoryBank: Enhancing Large Language Models with Long-Term Memory. (arXiv:2305.10250v1 [cs.CL])

    [http://arxiv.org/abs/2305.10250](http://arxiv.org/abs/2305.10250)

    MemoryBank 提出了一种新型内存机制，旨在为大型语言模型提供类人的长期记忆。它可以召唤相关记忆，通过持续的记忆更新不断进化，通过合成过去的互动信息理解并适应用户个性。

    

    大型语言模型的革命性进展极大地改变了我们与人工智能系统的互动方式。尽管如此，其中一个明显的不足之处是这些模型缺乏长期记忆机制。这在需要持续互动的情况下尤为明显，例如个人伴侣系统和心理咨询。因此，我们提出了MemoryBank，这是一种专为LLM量身定制的新型内存机制。MemoryBank可以召唤相关记忆，通过持续的记忆更新不断进化，通过合成过去的互动信息理解并适应用户个性。为了模仿人类行为并有选择地保存记忆，MemoryBank采用了受Ebbinghaus遗忘曲线理论启发的记忆更新机制，这样人工智能可以根据时间和记忆的相对重要性来遗忘和加强记忆，从而为LLM提供类似于人类的长期记忆。

    Revolutionary advancements in Large Language Models have drastically reshaped our interactions with artificial intelligence systems. Despite this, a notable hindrance remains-the deficiency of a long-term memory mechanism within these models. This shortfall becomes increasingly evident in situations demanding sustained interaction, such as personal companion systems and psychological counseling. Therefore, we propose MemoryBank, a novel memory mechanism tailored for LLMs. MemoryBank enables the models to summon relevant memories, continually evolve through continuous memory updates, comprehend, and adapt to a user personality by synthesizing information from past interactions. To mimic anthropomorphic behaviors and selectively preserve memory, MemoryBank incorporates a memory updating mechanism, inspired by the Ebbinghaus Forgetting Curve theory, which permits the AI to forget and reinforce memory based on time elapsed and the relative significance of the memory, thereby offering a hum
    
[^50]: 向不同语言发言人斡旋的语音对话翻译

    Towards Speech Dialogue Translation Mediating Speakers of Different Languages. (arXiv:2305.09210v1 [cs.CL])

    [http://arxiv.org/abs/2305.09210](http://arxiv.org/abs/2305.09210)

    本文提出了一项新任务，即为不同语言的发言人构建语音对话翻译。作者构建了SpeechBSD数据集并进行了基准实验。作者指出上下文是该任务中需要考虑的一个重要方面，并提出了两种利用上下文的方法。最终结果表明，在该任务中双语上下文比单语上下文表现更好。

    

    我们提出了一项新任务，该任务是为不同语言的发言人构建语音对话翻译。我们构建了SpeechBSD数据集，并进行了基准实验。此外，我们认为上下文是这项任务中需要解决的一个重要方面，并提出了两种利用上下文的方法，即单语上下文和双语上下文。我们使用Whisper和mBART进行级联式语音翻译实验，并展示了双语上下文在我们的设置中表现更好。

    We present a new task, speech dialogue translation mediating speakers of different languages. We construct the SpeechBSD dataset for the task and conduct baseline experiments. Furthermore, we consider context to be an important aspect that needs to be addressed in this task and propose two ways of utilizing context, namely monolingual context and bilingual context. We conduct cascaded speech translation experiments using Whisper and mBART, and show that bilingual context performs better in our settings.
    
[^51]: 基于大型语言模型的文本分类

    Text Classification via Large Language Models. (arXiv:2305.08377v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08377](http://arxiv.org/abs/2305.08377)

    本文介绍了Clue And Reasoning Prompting (CARP)算法，采用逐步推理策略优化了大型语言模型在文本分类中处理复杂语言现象的能力；并通过在监督数据集上使用微调模型进行$k$NN演示搜索，解决了上下文学习中有限标记的问题。

    

    尽管像GPT-3这样的大规模语言模型（LLM）取得了显著的成功，但它们在文本分类任务中的表现仍然显著不及微调模型。这是由于(1)缺乏处理复杂语言现象（例如强调、对比、反讽等）的推理能力； (2)在上下文学习中只允许有限数量的标记。在本文中，我们介绍了Clue And Reasoning Prompting (CARP)，CARP采用一种逐步推理策略，旨在应对涉及文本分类的复杂语言现象：CARP首先提示LLMs找到表面线索（例如关键词、语气、语义关系、参考等），然后诱导诊断性推理过程作出最终决策。为了进一步解决有限标记的问题，CARP在监督数据集上使用微调模型进行$k$NN演示搜索，在上下文学习中充分利用了LLM的优势。

    Despite the remarkable success of large-scale Language Models (LLMs) such as GPT-3, their performances still significantly underperform fine-tuned models in the task of text classification. This is due to (1) the lack of reasoning ability in addressing complex linguistic phenomena (e.g., intensification, contrast, irony etc); (2) limited number of tokens allowed in in-context learning.  In this paper, we introduce Clue And Reasoning Prompting (CARP). CARP adopts a progressive reasoning strategy tailored to addressing the complex linguistic phenomena involved in text classification: CARP first prompts LLMs to find superficial clues (e.g., keywords, tones, semantic relations, references, etc), based on which a diagnostic reasoning process is induced for final decisions. To further address the limited-token issue, CARP uses a fine-tuned model on the supervised dataset for $k$NN demonstration search in the in-context learning, allowing the model to take the advantage of both LLM's generali
    
[^52]: 区分先于回答：生成对比解释作为常识问答的知识

    Distinguish Before Answer: Generating Contrastive Explanation as Knowledge for Commonsense Question Answering. (arXiv:2305.08135v1 [cs.CL])

    [http://arxiv.org/abs/2305.08135](http://arxiv.org/abs/2305.08135)

    提出了一种基于概念中心提示的对比解释生成模型CPACE，旨在将获得的符号知识转化为对比解释，用于更好地区分常识问答中的差异。

    

    现有的知识增强方法通过从不同的知识库获取不同的知识，在某些问答任务中取得了显著的成果。然而，受到检索知识的特性限制，它们仍然难以同时从知识相关性和区分性方面受益。为了解决这个挑战，我们提出了CPACE，一种基于概念中心提示的对比解释生成模型，旨在将获得的符号知识转化为对比解释，用于更好地区分给定候选者之间的差异。

    Existing knowledge-enhanced methods have achieved remarkable results in certain QA tasks via obtaining diverse knowledge from different knowledge bases. However, limited by the properties of retrieved knowledge, they still have trouble benefiting from both the knowledge relevance and distinguishment simultaneously. To address the challenge, we propose CPACE, a Concept-centric Prompt-bAsed Contrastive Explanation Generation model, which aims to convert obtained symbolic knowledge into a contrastive explanation for better distinguishing the differences among given candidates. Firstly, following previous works, we retrieve different types of symbolic knowledge with a concept-centric knowledge extraction module. After that, we generate corresponding contrastive explanations using acquired symbolic knowledge and explanation prompts as guidance for better modeling the knowledge distinguishment and interpretability. Finally, we regard the generated contrastive explanation as external knowledg
    
[^53]: CodeT5+: 用于代码理解和生成的开放代码大型语言模型

    CodeT5+: Open Code Large Language Models for Code Understanding and Generation. (arXiv:2305.07922v1 [cs.CL])

    [http://arxiv.org/abs/2305.07922](http://arxiv.org/abs/2305.07922)

    CodeT5+是一组灵活组合的编码器-解码器LLM族，用于代码，混合了多种不同的预训练目标，包括代码生成、自然语言处理和程序合成，可以适应多种不同的下游代码任务，并且在实验中比现有代码-specific LLMs实现了最先进的性能。

    

    预训练在大量源代码上的大型语言模型(LLMs)在代码智能方面取得了显著进展。然而，现有的代码LLM在架构和预训练任务方面有两个主要限制。首先，它们通常采用特定的架构(仅编码器或仅解码器)或依赖于不同下游任务的统一编码器-解码器网络。前一种范式受到应用灵活性的限制，而在后一种范式中，模型被视为所有任务的单一系统，导致在某些任务的子集上性能不优。其次，它们通常采用有限的预训练目标，这些目标可能与某些下游任务不相关，因此会导致性能显著下降。为了解决这些限制，我们提出了“CodeT5+”，这是一组编码器-解码器LLM族，用于代码，其中组件模块可以灵活组合以适应各种下游代码任务。这种灵活性是通过我们提出的混合预训练目标实现的，包括代码生成，自然语言处理和程序合成。我们在几个与代码相关的下游任务上进行了广泛实验，证明CodeT5+相对于现有的代码特定LLM实现了最先进的性能。

    Large language models (LLMs) pretrained on vast source code have achieved prominent progress in code intelligence. However, existing code LLMs have two main limitations in terms of architecture and pretraining tasks. First, they often adopt a specific architecture (encoder-only or decoder-only) or rely on a unified encoder-decoder network for different downstream tasks. The former paradigm is limited by inflexibility in applications while in the latter, the model is treated as a single system for all tasks, leading to suboptimal performance on a subset of tasks. Secondly, they often employ a limited set of pretraining objectives which might not be relevant to some downstream tasks and hence result in substantial performance degrade. To address these limitations, we propose ``CodeT5+'', a family of encoder-decoder LLMs for code in which component modules can be flexibly combined to suit a wide range of downstream code tasks. Such flexibility is enabled by our proposed mixture of pretrai
    
[^54]: 搜索引擎与大型语言模型间的交互优化知识精炼

    Knowledge Refinement via Interaction Between Search Engines and Large Language Models. (arXiv:2305.07402v1 [cs.CL])

    [http://arxiv.org/abs/2305.07402](http://arxiv.org/abs/2305.07402)

    本文介绍了一种新的框架InteR，通过搜索引擎和大型语言模型之间的交互促进知识精炼，从而提高检索准确性。

    

    信息检索在从大量数据中定位相关资源方面具有重要作用，其应用已从传统知识库发展至现代搜索引擎（SEs）。大型语言模型（LLMs）的出现进一步通过使用自然语言与搜索系统交互革命性地改变了该领域。本文探索了LLMs和SEs的优缺点，强调它们在理解用户查询和检索最新信息方面的各自优势。为了利用两种范例的优势并避免其限制，我们提出了InteR，这是一个通过SEs和LLMs之间的交互促进知识精炼的新框架。 InteR使SEs能够使用LLM生成的摘要来调整查询，同时使LLMs能够使用SE检索到的文档来增强提示。这种迭代的精炼过程增强了SEs和LLMs的输入，从而导致更准确的检索结果。

    Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern search engines (SEs). The emergence of large language models (LLMs) has further revolutionized the field by enabling users to interact with search systems in natural language. In this paper, we explore the advantages and disadvantages of LLMs and SEs, highlighting their respective strengths in understanding user-issued queries and retrieving up-to-date information. To leverage the benefits of both paradigms while circumventing their limitations, we propose InteR, a novel framework that facilitates knowledge refinement through interaction between SEs and LLMs. InteR allows SEs to refine knowledge in query using LLM-generated summaries and enables LLMs to enhance prompts using SE-retrieved documents. This iterative refinement process augments the inputs of SEs and LLMs, leading to more accurate retrieval. Ex
    
[^55]: 基于基础模型的系统设计框架

    A Framework for Designing Foundation Model based Systems. (arXiv:2305.05352v1 [cs.SE])

    [http://arxiv.org/abs/2305.05352](http://arxiv.org/abs/2305.05352)

    本文提出了一个基于基础模型的系统分类体系，分类和比较了基础模型和基于基础模型的系统的特点。它为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。

    

    最近推出了大型语言模型(LLM)的聊天机器人，如ChatGPT，这引起了人们对基础模型的广泛关注。基础模型被广泛认为将成为未来人工智能系统的基石。由于基础模型处于早期阶段，基于基础模型的系统设计尚未得到系统地探索。人们对在软件架构中引入基础模型的影响知之甚少。因此，在本文中，我们提出了一个基于基础模型的系统分类法，对基础模型和基于基础模型的系统的特点进行了分类和比较。我们的分类法包括三个类别：基础模型预训练和微调、基于基础模型的系统架构设计和负责任的AI设计。这个分类法为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。

    The recent release of large language model (LLM) based chatbots, such as ChatGPT, has attracted significant attention on foundations models. It is widely believed that foundation models will serve as the fundamental building blocks for future AI systems. As foundation models are in their early stages, the design of foundation model based systems has not yet been systematically explored. There is little understanding about the impact of introducing foundation models in software architecture. Therefore, in this paper, we propose a taxonomy of foundation model based systems, which classifies and compares the characteristics of foundation models and foundation model based systems. Our taxonomy comprises three categories: foundation model pretraining and fine-tuning, architecture design of foundation model based systems, and responsible-AI-by-design. This taxonomy provides concrete guidance for making major design decisions when designing foundation model based systems and highlights trade-
    
[^56]: 从大型语言模型中提取脚本知识以进行受限语言规划

    Distilling Script Knowledge from Large Language Models for Constrained Language Planning. (arXiv:2305.05252v1 [cs.CL])

    [http://arxiv.org/abs/2305.05252](http://arxiv.org/abs/2305.05252)

    本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。

    

    在日常生活中，人们经常通过遵循目标导向的脚本形式的逐步说明来规划自己的行动。以往的工作利用语言模型（LM）来为立体活动的抽象目标（例如，“制作蛋糕”）进行规划，但对于具有多方面约束的更具体目标（例如，“为糖尿病患者制作蛋糕”）鲜有研究。本文首次定义了受限语言规划任务。我们提出了一种过度生成并过滤的方法来改善大型语言模型（LLM）在这个任务中的表现，并利用它来提取一种新颖的受限语言规划数据集CoScript，其中包括55,000个脚本。实验证明，我们的方法显著提高了LLM在受限语言规划方面的能力，特别是在约束忠实度方面。此外，CoScript被证明对赋予较小的LM受限语言规划能力是非常有效的。

    In everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts. Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., "make a cake"), but leaves more specific goals with multi-facet constraints understudied (e.g., "make a cake for diabetics"). In this paper, we define the task of constrained language planning for the first time. We propose an overgenerate-then-filter approach to improve large language models (LLMs) on this task, and use it to distill a novel constrained language planning dataset, CoScript, which consists of 55,000 scripts. Empirical results demonstrate that our method significantly improves the constrained language planning ability of LLMs, especially on constraint faithfulness. Furthermore, CoScript is demonstrated to be quite effective in endowing smaller LMs with constrained language planning ability.
    
[^57]: X-LLM: 通过将多模态视为外语引入大型语言模型来启动高级大型语言模型

    X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages. (arXiv:2305.04160v1 [cs.CL])

    [http://arxiv.org/abs/2305.04160](http://arxiv.org/abs/2305.04160)

    本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。

    

    大型语言模型（LLM）展示了卓越的语言能力。基于高级LLM的GPT-4表现出超常的多模态能力，超越了以往的视觉语言模型。我们将这归功于与以前的多模态模型相比使用了更先进的LLM。但不幸的是，GPT-4的模型架构和训练策略是未知的。为了赋予LLM多模态能力，我们提出了X-LLM，通过使用X2L接口将多模态（图像、语音、视频）转换为外语并将其输入到大型语言模型（ChatGLM）中。具体而言，X-LLM使用X2L接口将多个冻结的单模态编码器和冻结的LLM对齐，其中“X”表示多模态，例如图像、语音和视频，“L”表示语言。X-LLM的训练由三个阶段组成：（1）转换多模态信息：第一阶段分别训练每个X2L接口与其各自的单模态编码器对齐，将多模态信息转换为外语输入到ChatGLM中。...

    Large language models (LLMs) have demonstrated remarkable language abilities. GPT-4, based on advanced LLMs, exhibits extraordinary multimodal capabilities beyond previous visual language models. We attribute this to the use of more advanced LLMs compared with previous multimodal models. Unfortunately, the model architecture and training strategies of GPT-4 are unknown. To endow LLMs with multimodal capabilities, we propose X-LLM, which converts Multi-modalities (images, speech, videos) into foreign languages using X2L interfaces and inputs them into a large Language model (ChatGLM). Specifically, X-LLM aligns multiple frozen single-modal encoders and a frozen LLM using X2L interfaces, where ``X'' denotes multi-modalities such as image, speech, and videos, and ``L'' denotes languages. X-LLM's training consists of three stages: (1) Converting Multimodal Information: The first stage trains each X2L interface to align with its respective single-modal encoder separately to convert multimod
    
[^58]: 计划和解决提示：通过大型语言模型改善零样本思考链推理

    Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. (arXiv:2305.04091v1 [cs.CL])

    [http://arxiv.org/abs/2305.04091](http://arxiv.org/abs/2305.04091)

    本研究提出了一种计划和解决的提示方法来改善零样本思考链推理，该方法包括两个组成部分：制定计划将任务划分为子任务，并按计划执行子任务；将输入提示扩展到包括简单算术计算的示例。实验结果显示，该方法胜过了零样本-CoT。

    

    最近，大型语言模型（LLMs）在各种自然语言处理任务中表现出惊人的性能。为了解决多步骤推理任务，少样本的思维链（CoT）提示包括一些手工制作的逐步推理演示，使LLMs能够明确生成推理步骤并提高其推理任务准确性。为了消除手动劳动，零样本思维链将目标问题陈述与“让我们逐步思考”连接起来作为输入提示LLMs。尽管零样本-CoT取得了成功，但仍存在计算错误、缺失步骤错误和语义误解错误的问题。为了解决缺失步骤错误，我们提出了计划和解决（PS）提示。它包含两个组成部分：首先，制定计划将整个任务划分为较小的子任务，然后按照计划执行子任务。为了解决计算错误并提高生成推理步骤的质量，我们将输入提示扩展到包括简单算术计算的示例。我们的实验表明，PS提示在思维链推理任务的准确性方面胜过了零样本CoT。

    Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual effort, Zero-shot-CoT concatenates the target problem statement with "Let's think step by step" as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend 
    
[^59]: 机器学习模型在电子健康记录中的敏感数据检测

    Sensitive Data Detection with High-Throughput Machine Learning Models in Electrical Health Records. (arXiv:2305.03169v1 [cs.CR])

    [http://arxiv.org/abs/2305.03169](http://arxiv.org/abs/2305.03169)

    该论文使用机器学习算法来识别结构化数据中的敏感变量，以便便于去身份化过程。该算法可以解决不同数据集PHI字段异质性的问题。

    

    在大数据时代，医疗保健提供者、社区和研究人员需要分享数据并合作改善健康结果、获取有价值的见解和推进研究。1996年《健康保险流通与责任法案》(HIPAA)是一项联邦法律，旨在通过制定保护健康信息的规定来保护敏感健康信息。然而，在数据共享之前，HIPAA没有提供有效的检测或删除PHI的工具。本文旨在探讨使用机器学习算法来识别结构化数据中的敏感变量，从而便于去身份化过程。

    In the era of big data, there is an increasing need for healthcare providers, communities, and researchers to share data and collaborate to improve health outcomes, generate valuable insights, and advance research. The Health Insurance Portability and Accountability Act of 1996 (HIPAA) is a federal law designed to protect sensitive health information by defining regulations for protected health information (PHI). However, it does not provide efficient tools for detecting or removing PHI before data sharing. One of the challenges in this area of research is the heterogeneous nature of PHI fields in data across different parties. This variability makes rule-based sensitive variable identification systems that work on one database fail on another. To address this issue, our paper explores the use of machine learning algorithms to identify sensitive variables in structured data, thus facilitating the de-identification process. We made a key observation that the distributions of metadata of
    
[^60]: 面向任务的端到端对话系统中的任务优化适配器

    Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System. (arXiv:2305.02468v1 [cs.CL])

    [http://arxiv.org/abs/2305.02468](http://arxiv.org/abs/2305.02468)

    本文提出了一种端到端任务导向对话系统，通过在预训练网络的固定层后添加少量参数的任务优化适配器来独立地学习每个任务，并通过强化学习提高DST和NLG模块的性能。

    

    任务导向对话系统旨在通过跟踪对话状态和生成适当的响应来执行特定任务，帮助用户实现定义的目标。最近，基于大型数据集预训练的端到端对话模型在对话系统中表现出了很好的性能。然而，它们共享相同的参数以训练对话系统的任务(NLU，DST，NLG)，因此每个任务的调试都很具有挑战性。此外，相较于PLM，将大量参数微调来创建面向任务的聊天机器人需要大量的努力，这使得非专家难以处理。因此，我们打算训练相对轻量级和快速的模型。本文提出了一种具有任务优化适配器的端到端任务导向对话系统，每个任务独立学习，在预训练网络的固定层之后仅添加少量参数。我们还通过强化学习提高了DST和NLG模块的性能，克服了学习曲线。

    Task-Oriented Dialogue (TOD) systems are designed to carry out specific tasks by tracking dialogue states and generating appropriate responses to help users achieve defined goals. Recently, end-to-end dialogue models pre-trained based on large datasets have shown promising performance in the conversational system. However, they share the same parameters to train tasks of the dialogue system (NLU, DST, NLG), so debugging each task is challenging. Also, they require a lot of effort to fine-tune large parameters to create a task-oriented chatbot, making it difficult for non-experts to handle. Therefore, we intend to train relatively lightweight and fast models compared to PLM. In this paper, we propose an End-to-end TOD system with Task-Optimized Adapters which learn independently per task, adding only small number of parameters after fixed layers of pre-trained network. We also enhance the performance of the DST and NLG modules through reinforcement learning, overcoming the learning curv
    
[^61]: 改进句子嵌入的对比学习方法，利用人工智能反馈

    Improving Contrastive Learning of Sentence Embeddings from AI Feedback. (arXiv:2305.01918v1 [cs.CL])

    [http://arxiv.org/abs/2305.01918](http://arxiv.org/abs/2305.01918)

    本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。

    

    对比学习已成为自然语言处理中句子嵌入学习中的流行方法。然而，自然语言的离散性使得通过数据增强方法生成的正负样本对的质量难以保证。虽然有监督的对比学习可以通过人类反馈标签生成更准确的样本对，但仍缺乏细粒度的训练信号。本文提出了一种基于AI反馈来改进句子嵌入对比学习的方法（CLAIF），利用大型预训练语言模型 (LLMs) 的AI反馈构建带有细粒度样本相似度分数的样本对，以改进对比学习。此外，我们结合人工反馈和AI反馈为对比学习中的句子嵌入提供更好的监督信号。实验结果表明，我们的方法达到了最先进的水平。

    Contrastive learning has become a popular approach in natural language processing, particularly for the learning of sentence embeddings. However, the discrete nature of natural language makes it difficult to ensure the quality of positive and negative sample pairs generated through data augmentation methods. Although supervised contrastive learning can produce more accurate sample pairs with human feedback labels, it still lacks fine-grained training signals. In this paper, we propose to improve \textbf{C}ontrastive \textbf{L}earning of sentence embeddings from \textbf{AI} \textbf{F}eedback \textbf{(CLAIF)}. Our method utilizes AI feedback from large pre-trained language models (LLMs) to construct sample pairs with fine-grained sample similarity scores to improve contrastive learning. Besides, we combine human feedback and AI feedback to provide better supervision signals for supervised contrastive learning of sentence embeddings. Experimental results show that our method achieves stat
    
[^62]: SCOTT: 自我一致性思路串提炼

    SCOTT: Self-Consistent Chain-of-Thought Distillation. (arXiv:2305.01879v1 [cs.CL])

    [http://arxiv.org/abs/2305.01879](http://arxiv.org/abs/2305.01879)

    本研究提出了一种忠实的知识蒸馏方法，从比教师模型大数倍的模型中学习一个小的、自我一致的思路串模型。实验结果表明，该方法有助于证明决策并提高性能，特别是在较小的语言模型中。

    

    超出一定规模的大型语言模型表现出通过一系列连续的思考过程获得自由文本理由的突出能力。虽然思路串可以显著提高性能，但仅在足够大的语言模型中才能观察到这种收益。更令人担忧的是，生成的理由很少保证与语言模型的预测保持一致或者忠实地证明决策。在这项工作中，我们提出了一种忠实的知识蒸馏方法，从比教师模型大数倍的模型中学习一个小的、自我一致的思路串模型。为了形成更好的监督，我们通过对比解码引导教师模型产生支持正确答案的理由，这鼓励教师模型生成的token只在考虑到答案时才更加可信。为了保证忠实的蒸馏，我们使用教师生成的理由来学习一个学生模型，该模型具有反事实推理目标，即根据具有自我一致性且忠实于教师预测的思路串理由预测决策。在自然语言推理和抽象摘要基准测试上，我们证明了学生模型中的自我一致性有助于证明决策并提高性能，特别是在较小的语言模型中。

    Large language models (LMs) beyond a certain scale, demonstrate the emergent capability of generating free-text rationales for their predictions via chain-of-thought (CoT) prompting. While CoT can yield dramatically improved performance, such gains are only observed for sufficiently large LMs. Even more concerning, there is little guarantee that the generated rationales are consistent with LM's predictions or faithfully justify the decisions. In this work, we propose a faithful knowledge distillation method to learn a small, self-consistent CoT model from a teacher model that is orders of magnitude larger. To form better supervision, we elicit rationales supporting the gold answers from a large LM (teacher) by contrastive decoding, which encourages the teacher to generate tokens that become more plausible only when the answer is considered. To ensure faithful distillation, we use the teacher-generated rationales to learn a student LM with a counterfactual reasoning objective, which pre
    
[^63]: 基于SearChain的复杂知识密集型任务中精确、可信和可追溯内容生成的研究

    Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks. (arXiv:2304.14732v1 [cs.CL])

    [http://arxiv.org/abs/2304.14732](http://arxiv.org/abs/2304.14732)

    提出了一个名为SearChain的新型框架，以改进LLM生成的内容的准确性、可信度和可追溯性，从而提高复杂知识密集型任务的表现。SearChain通过深度集成LLM和信息检索（IR）实现，其思路是通过构造查询链，将多跳问题进行分解，最终指导LLM生成正确的答案。

    

    随着ChatGPT等大型语言模型（LLM）的广泛应用，如何使LLM生成的内容准确可信在复杂知识密集型任务中变得非常重要。本文提出了一种名为Search-in-the-Chain（SearChain）的新型框架，以改进多跳问题回答等典型复杂知识密集型任务中LLM生成内容的准确性、可信度和可追溯性。SearChain是一个深度集成LLM和信息检索（IR）的框架。在SearChain中，LLM构建查询链，作为多跳问题的分解。链的每个节点都是由IR导向的查询-答案对，以及由LLM生成的该查询的答案。IR验证、完善和跟踪链中每个节点的信息，以指导LLM构建正确的查询链，并最终回答多跳问题。SearChain使LLM从一次性答案转变为多步答案，从而提高了生成内容的准确性和可信度。实验结果表明，SearChain在准确性和可靠性方面优于其他最先进的方法。

    With the wide application of Large Language Models (LLMs) such as ChatGPT, how to make the contents generated by LLM accurate and credible becomes very important, especially in complex knowledge-intensive tasks. In this paper, we propose a novel framework called Search-in-the-Chain (SearChain) to improve the accuracy, credibility and traceability of LLM-generated content for multi-hop question answering, which is a typical complex knowledge-intensive task. SearChain is a framework that deeply integrates LLM and information retrieval (IR). In SearChain, LLM constructs a chain-of-query, which is the decomposition of the multi-hop question. Each node of the chain is a query-answer pair consisting of an IR-oriented query and the answer generated by LLM for this query. IR verifies, completes, and traces the information of each node of the chain, so as to guide LLM to construct the correct chain-of-query, and finally answer the multi-hop question. SearChain makes LLM change from trying to gi
    
[^64]: PMC-LLaMA: 在医学论文中进行LLaMA的进一步微调

    PMC-LLaMA: Further Finetuning LLaMA on Medical Papers. (arXiv:2304.14454v1 [cs.CL])

    [http://arxiv.org/abs/2304.14454](http://arxiv.org/abs/2304.14454)

    本文介绍了一个针对医学领域进一步微调的开源语言模型PMC-LLaMA，其通过增加医学知识提高了在生物医学领域的性能表现，有望在生物医学问答领域有更好的应用表现。

    

    大型语言模型(LLM)在各个领域的自然语言理解方面具有出色的能力。这些模型通常在日常对话或问答场景中表现良好，然而，在注重精度的领域，例如医疗应用中，它们往往表现出不尽人意的性能，原因是缺乏特定领域的知识。在本文中，我们介绍了PMC-LLaMA，这是一种开源的语言模型，通过在总共480万篇生物医学论文上微调开源语言模型，以进一步注入医学知识，增强其在医学领域的能力。我们进行了初步评估，包括PubMedQA、MedMCQA和USMLE等三个生物医学问答数据集，结果显示，我们的模型经过微调后，即PMC-LLaMA，对生物医学领域的特定概念有更好的理解，因此在问答基准测试中取得了较高的性能。该模型和代码以及在线演示均可在https://github.com/cstorm125/pmc-llama上找到。

    Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding in various domains. These models can usually behave well on daily dialog, or question answering scenarios, however, in areas that value precision, for example, in medical applications, they often exhibit unsatisfactory performance due to a lack of domain-specific knowledge. In this report, we introduce PMC-LLaMA, an open-source language model that is acquired by fine-tuning an open-source language model on a total of 4.8 million biomedical academic papers for further injecting medical knowledge, enhancing its capability in medical domain. Our preliminary evaluations are conducted on three biomedical QA datasets, including PubMedQA, MedMCQA, and USMLE, showing that the our model after finetuning, i.e., PMC-LLaMA, demonstrates better understanding of biomedical domain-specific concepts, thus achieving high performance on QA benchmarks. The model and codes, along with an online demo, are 
    
[^65]: LaMP：当大型语言模型遇见个性化

    LaMP: When Large Language Models Meet Personalization. (arXiv:2304.11406v1 [cs.CL])

    [http://arxiv.org/abs/2304.11406](http://arxiv.org/abs/2304.11406)

    本论文强调了当前自然语言处理领域中个性化的重要性，并提出了LaMP（一种用于训练和评估大型语言模型的新的个性化基准），并针对大型语言模型的生成任务，设计了七项个性化任务以及一种检索增强方法，结果表明在利用用户配置文件扩展大型语言模型的基础上，其生成结果明显优于传统方法。

    

    本文强调在当前自然语言理解和生成领域的个性化的重要性，并介绍了LaMP基准——用于训练和评估生成个性化输出的语言模型的新典范。LaMP提供了一个全面的评估框架，具有多样化的语言任务和每个用户的多个条目，包括三个分类任务和四个文本生成任务的七个个性化任务。我们还提出了一种检索增强方法，可从用户配置文件中检索个性化项目，构建大型语言模型的个性化提示。我们的基线零-shot和微调模型的结果表明，利用个人资料扩展的LM优于不考虑个人资料信息的对应模型。

    This paper highlights the importance of personalization in the current state of natural language understanding and generation and introduces the LaMP benchmark -- a novel benchmark for training and evaluating language models for producing personalized outputs. LaMP offers a comprehensive evaluation framework with diverse language tasks and multiple entries for each user profile. It consists of seven personalized tasks, spanning three classification and four text generation tasks. We also propose a retrieval augmentation approach that retrieves personalized items from user profiles to construct personalized prompts for large language models. Our baseline zero-shot and fine-tuned model results indicate that LMs utilizing profile augmentation outperform their counterparts that do not factor in profile information.
    
[^66]: RRHF: 无需烦恼地使用排名响应来对齐语言模型与人类反馈

    RRHF: Rank Responses to Align Language Models with Human Feedback without tears. (arXiv:2304.05302v1 [cs.CL])

    [http://arxiv.org/abs/2304.05302](http://arxiv.org/abs/2304.05302)

    RRHF是一种新的学习范式，可以高效地对齐语言模型输出概率与人类偏好，它通过排序损失对不同采样策略生成的响应进行评分，并在调整过程中只需1到2个模型。

    

    人类反馈的强化学习（RLHF）可以帮助将大型语言模型与人类偏好对齐，从而显著提高人类与这些模型间的交互质量。与PPO相比，我们提出了一种新的学习范式——RRHF，它通过排序损失对不同采样策略生成的响应进行评分，并学习将它们与人类偏好对齐。RRHF可以高效地对齐语言模型输出概率与人类偏好，其效果和Fine-Tuning一样稳健，而在调整过程中只需1到2个模型。此外，RRHF可以被认为是SFT和奖励模型的扩展，与PPO相比在编码和模型数量方面更为简单。

    Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment of large language models with human preferences, significantly enhancing the quality of interactions between humans and these models. InstructGPT implements RLHF through several stages, including Supervised Fine-Tuning (SFT), reward model training, and Proximal Policy Optimization (PPO). PPO, however, is sensitive to hyperparameters and requires a minimum of four models in its standard implementation, which makes it hard to train. In contrast, we propose a novel learning paradigm called RRHF, which scores responses generated by different sampling policies and learns to align them with human preferences through ranking loss. RRHF can efficiently align language model output probabilities with human preferences as robust as fine-tuning and it only needs 1 to 2 models during tuning. In addition, RRHF can be considered an extension of SFT and reward models while being simpler than PPO in terms of coding, model count
    
[^67]: 为什么要逐步思考？推理源于经验的局部性。

    Why think step-by-step? Reasoning emerges from the locality of experience. (arXiv:2304.03843v1 [cs.AI])

    [http://arxiv.org/abs/2304.03843](http://arxiv.org/abs/2304.03843)

    本文通过语言模型研究何时以及为什么推理是有帮助的，测试推理在训练数据由相互影响强烈的局部变量集群组成时是否有效。通过一步步的推理，能够将准确的局部推理链接在一起，以估算在训练中没有同时观察到的变量之间的关系。

    

    人类有着强大而神秘的推理能力。通过一系列纯粹的思维步骤，我们可以推理出我们无法直接得出的推论 - 尽管我们从世界上没有得到任何额外数据。同样地，大型语言模型可以通过一步步的推理，在回答问题之前生成中间步骤，从而更好地完成复杂的任务。我们使用语言模型研究何时以及为什么推理是有帮助的，测试推理在训练数据由相互影响强烈的局部变量集群组成时是否有效。这些训练条件能够将准确的局部推理链接在一起，以估算在训练中没有同时观察到的变量之间的关系。我们使用贝叶斯网络定义的联合分布的样品对自回归变压器进行训练，但每个样品只包括其中的一部分变量。我们比较使用推理生成的变量子集与使用完整集合进行训练的方案的性能。

    Humans have a powerful and mysterious capacity to reason. By working through a series of purely mental steps, we can make inferences we would not be capable of making directly -- despite that fact that we get no additional data from the world. Similarly, large language models can perform better at complex tasks through chain-of-thought reasoning, where they generate intermediate steps before answering a question. We use language models to investigate the questions of when and why reasoning is helpful, testing the hypothesis that reasoning is effective when training data consisting of local clusters of variables that influence each other strongly. These training conditions enable the chaining of accurate local inferences in order to estimate relationships between variables that were not seen together in training. We train an autoregressive transformer on samples from joint distributions defined by Bayes nets, but only include a subset of all the variables in each sample. We compare lang
    
[^68]: MEGA: 多语言生成人工智能的综合评估

    MEGA: Multilingual Evaluation of Generative AI. (arXiv:2303.12528v1 [cs.CL])

    [http://arxiv.org/abs/2303.12528](http://arxiv.org/abs/2303.12528)

    这项研究对 33 种语言中 8 个不同任务的生成 AI 进行了全面评估，比较了生成 LLMs 和非自回归模型的表现差异。

    

    生成AI模型在许多自然语言处理任务（如语言理解、推理和语言生成）上具有令人印象深刻的性能。当今AI社区最重要的问题之一是关于这些模型的能力和限制，评估生成AI显然具有挑战性。大多数关于生成大型语言模型（LLMs）的研究都限于英语，不清楚这些模型在理解和生成其他语言方面的能力。我们提供了首个全面评估 8 项不同任务和 33 种语言的生成LLMs MEGA 的基准测试。我们还将生成LLMs的性能与这些任务上最先进的非自回归模型进行比较，以确定生成模型的表现如何与上一代LLMs相比。我们对模型的性能进行了彻底分析。

    Generative AI models have impressive performance on many Natural Language Processing tasks such as language understanding, reasoning and language generation. One of the most important questions that is being asked by the AI community today is about the capabilities and limits of these models, and it is clear that evaluating generative AI is very challenging. Most studies on generative Large Language Models (LLMs) are restricted to English and it is unclear how capable these models are at understanding and generating other languages. We present the first comprehensive benchmarking of generative LLMs MEGA, which evaluates models on standard NLP benchmarks, covering 8 diverse tasks and 33 typologically diverse languages. We also compare the performance of generative LLMs to State of the Art (SOTA) non-autoregressive models on these tasks to determine how well generative models perform compared to the previous generation of LLMs. We present a thorough analysis of the performance of model
    
[^69]: 具有元梯度正则化的自监督元提示学习用于少样本泛化

    Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization. (arXiv:2303.12314v1 [cs.CL])

    [http://arxiv.org/abs/2303.12314](http://arxiv.org/abs/2303.12314)

    提出了一种自我监督元提示学习框架SUPMER，包括元梯度正则化，用于少样本泛化，通过锚定的元训练任务和基于课程的任务增强丰富了任务分布，解决了在少样本情况下良好初始化软提示和过拟合的问题。

    

    提示调整是一种参数有效的方法，它学习软提示并使冻结的语言模型执行特定的下游任务。尽管有效，但提示调整在少样本情况下一方面严重依赖于良好的软提示初始化。另一方面，它很容易导致过度拟合。现有的方法利用预训练或监督元学习来初始化软提示，但它们不能对未见下游任务进行数据有效的泛化。为了解决以上问题，本文提出了一种新的自我监督元提示学习框架，其中包括元梯度正则化，用于少样本泛化（SUPMER）。我们首先设计了一组自监督锚定的元训练任务，具有不同的任务格式，并通过基于课程的任务增强进一步丰富了任务分布。然后将一种新的元梯度正则化方法集成到元提示学习中。它元学习在少样本情况下如何转换原始梯度。

    Prompt tuning is a parameter-efficient method, which learns soft prompts and conditions frozen language models to perform specific downstream tasks. Though effective, prompt tuning under few-shot settings on the one hand heavily relies on a good initialization of soft prompts. On the other hand, it can easily result in overfitting. Existing works leverage pre-training or supervised meta-learning to initialize soft prompts but they cannot data-efficiently generalize to unseen downstream tasks. To address the above problems, this paper proposes a novel Self-sUpervised meta-Prompt learning framework with meta-gradient Regularization for few-shot generalization (SUPMER). We first design a set of self-supervised anchor meta-training tasks with different task formats and further enrich the task distribution with curriculum-based task augmentation. Then a novel meta-gradient regularization method is integrated into meta-prompt learning. It meta-learns to transform the raw gradients during few
    
[^70]: Reflexion：具有动态记忆和自我反思的自主智能体

    Reflexion: an autonomous agent with dynamic memory and self-reflection. (arXiv:2303.11366v1 [cs.AI])

    [http://arxiv.org/abs/2303.11366](http://arxiv.org/abs/2303.11366)

    本文提出 Reflexion 方法，给智能体赋予了动态记忆和自我反思能力，以增强其任务特定的行动选择能力。

    

    最近决策大型语言模型（LLM）代理的发展在各种基准测试中展现出卓越的性能。然而，这些最先进的方法通常需要内部模型微调、外部模型微调或在定义的状态空间上进行策略优化。由于高质量训练数据的稀缺性或缺乏良好定义的状态空间，实现这些方法可能会具有挑战性。此外，这些代理没有人类决策过程固有的某些品质，特别是从错误中学习的能力。通过反思，人类可以通过试错过程高效地解决新的问题。在最近的研究基础上，我们提出 Reflexion，一种将动态记忆和自我反思能力赋予智能体的方法，以增强其现有的推理轨迹和任务特定的行动选择能力。为了实现完全自动化，我们介绍了一种简单而有效的方法。

    Recent advancements in decision-making large language model (LLM) agents have demonstrated impressive performance across various benchmarks. However, these state-of-the-art approaches typically necessitate internal model fine-tuning, external model fine-tuning, or policy optimization over a defined state space. Implementing these methods can prove challenging due to the scarcity of high-quality training data or the lack of well-defined state space. Moreover, these agents do not possess certain qualities inherent to human decision-making processes, specifically the ability to learn from mistakes. Self-reflection allows humans to efficiently solve novel problems through a process of trial and error. Building on recent research, we propose Reflexion, an approach that endows an agent with dynamic memory and self-reflection capabilities to enhance its existing reasoning trace and task-specific action choice abilities. To achieve full automation, we introduce a straightforward yet effective 
    
[^71]: UDAPDR: 基于LLM提示与reranker蒸馏的无监督领域自适应

    UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers. (arXiv:2303.00807v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2303.00807](http://arxiv.org/abs/2303.00807)

    该论文提出了一种无监督领域自适应方法，利用大型语言模型(LLMs)生成大量合成查询和reranker模型，蒸馏为高效的检索器，适用于长尾领域。

    

    很多信息检索任务需要大型标注数据集进行微调，但这样的数据集通常不可用，且在应用于真实场景中时可能会因为领域漂移而迅速失去效用。为了解决这个问题，我们提出一种使用大型语言模型(LLMs)廉价生成大量合成查询的方法。该方法首先利用昂贵的LLM生成少量合成查询，然后再利用成本较低的LLM生成大量的合成查询以微调一组reranker模型。最后，这些reranker会被蒸 distill 成一个高效的检索器，用于目标领域中的检索。实验证明，这种技术可以提高长尾领域中的零样本准确性，即使只使用2K个合成查询进行微调，并且比标准的reranking方法具有更低的延迟。我们提供完整的端到端方案，包括合成数据集等。

    Many information retrieval tasks require large labeled datasets for fine-tuning. However, such datasets are often unavailable, and their utility for real-world applications can diminish quickly due to domain shifts. To address this challenge, we develop and motivate a method for using large language models (LLMs) to generate large numbers of synthetic queries cheaply. The method begins by generating a small number of synthetic queries using an expensive LLM. After that, a much less expensive one is used to create large numbers of synthetic queries, which are used to fine-tune a family of reranker models. These rerankers are then distilled into a single efficient retriever for use in the target domain. We show that this technique boosts zero-shot accuracy in long-tail domains, even where only 2K synthetic queries are used for fine-tuning, and that it achieves substantially lower latency than standard reranking methods. We make our end-to-end approach, including our synthetic datasets an
    
[^72]: 处理唤醒词检测的对齐：基于对齐、无对齐和混合方法的比较

    Handling the Alignment for Wake Word Detection: A Comparison Between Alignment-Based, Alignment-Free and Hybrid Approaches. (arXiv:2302.08950v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08950](http://arxiv.org/abs/2302.08950)

    本文比较了基于对齐、无对齐和混合方法处理唤醒词检测的效果，发现在目标操作点上无对齐系统比基于对齐的方法更好，而使用少量对齐数据和大量未对齐数据的混合方法在满足初始约束的情况下训练出了良好的模型。

    

    唤醒词检测存在于大多数智能家居和便携设备中。它为这些设备提供了在召唤时“唤醒”的能力，并节省了功率和计算成本。本文着重探讨对齐在开发回答通用短语的唤醒词系统中的作用。我们讨论了三种方法。第一种是基于对齐的方法，模型使用逐帧交叉熵进行训练。第二种是无对齐的方法，模型使用CTC进行训练。我们提出的第三种是混合解决方案，在此方案中，模型使用少量对齐数据进行训练，然后使用大量未对齐的数据进行调优。我们比较了三种方法，并评估了不同对齐到未对齐比率对混合训练的影响。我们的结果表明，在目标操作点上，无对齐系统比基于对齐更好，并且在仅使用20％的数据的情况下，我们可以训练一个符合我们的初始约束的模型。

    Wake word detection exists in most intelligent homes and portable devices. It offers these devices the ability to "wake up" when summoned at a low cost of power and computing. This paper focuses on understanding alignment's role in developing a wake-word system that answers a generic phrase. We discuss three approaches. The first is alignment-based, where the model is trained with frame-wise cross-entropy. The second is alignment-free, where the model is trained with CTC. The third, proposed by us, is a hybrid solution in which the model is trained with a small set of aligned data and then tuned with a sizeable unaligned dataset. We compare the three approaches and evaluate the impact of the different aligned-to-unaligned ratios for hybrid training. Our results show that the alignment-free system performs better than the alignment-based for the target operating point, and with a small fraction of the data (20%), we can train a model that complies with our initial constraints.
    
[^73]: 学习初始化：元学习能否提高Prompt Tuning跨任务泛化能力？

    Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?. (arXiv:2302.08143v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08143](http://arxiv.org/abs/2302.08143)

    本文研究了元Prompt Tuning（MPT）如何帮助改善跨任务泛化能力。使用元学习可以从其他相关任务中学习初始化Prompt嵌入，我们提出并实验了代表性的元学习算法，并在大量的少样本任务中证明了MPT的有效性，特别是在分类任务中。

    

    Prompt Tuning (PT)是一种只调整每个任务的一个额外标记序列的嵌入，同时保持预训练完成的语言模型（PLM）不变，已经在少样本学习中展现出了优异的性能。尽管如此，PT已经被证明极大地依赖于很好的Prompt嵌入的初始化。本文研究了元Prompt Tuning (MPT) 来系统地探索元学习如何帮助通过从其他相关任务学习初始化Prompt嵌入来改善（如果可以）PT中的跨任务泛化能力。我们在大量的少样本任务上使用广泛的实验和分析来经验分析了一系列代表性的元学习算法，分析不同源/目标任务配置下的各种调整设置。通过广泛的实验和分析，我们证明了MPT的有效性。我们发现它特别在分类任务上的提升是显著的。对于其他类型的任务，例如问题回答，我们观察到，虽然MPT可以在大多数情况下优于PT，

    Prompt tuning (PT) which only tunes the embeddings of an additional sequence of tokens per task, keeping the pre-trained language model (PLM) frozen, has shown remarkable performance in few-shot learning. Despite this, PT has been shown to rely heavily on good initialization of the prompt embeddings. In this work, we study meta prompt tuning (MPT) to systematically explore how meta-learning can help improve (if it can) cross-task generalization in PT through learning to initialize the prompt embeddings from other relevant tasks. We empirically analyze a representative set of meta learning algorithms in a wide range of adaptation settings with different source/target task configurations on a large set of few-shot tasks. With extensive experiments and analysis, we demonstrate the effectiveness of MPT. We find the improvement to be significant particularly on classification tasks. For other kinds of tasks such as question answering, we observe that while MPT can outperform PT in most case
    
[^74]: UniAdapter: 用于跨模态建模的统一参数高效传递学习

    UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling. (arXiv:2302.06605v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.06605](http://arxiv.org/abs/2302.06605)

    本论文提出了 UniAdapter，它是一种新颖的跨模态适配器，可以高效跨模态适应预训练的视觉-语言模型，能够用较少的调参成本提升下游任务的性能。

    

    大规模的视觉-语言预训练模型已经证明在各种下游任务中具有良好的可转移性。随着这些基础模型的规模和下游任务的数量增加，由于计算和存储成本的增加，标准的完全微调范式变得不可行。本文提出了 UniAdapter，它将单模态和多模态适配器统一起来，对预训练的视觉-语言模型进行参数高效的跨模态适应。具体而言，适配器分布在不同的模态及其交互中，并通过部分权重共享来减少可调参数的总数。统一和知识共享的设计实现了强大的跨模态表示，可以帮助各种下游任务，只需要预训练模型的1.0％-2.0％可调参数。在包括视频-文本检索、图像-文本检索、VideoQA和VQA在内的6个跨模态下游基准上进行了大量实验，结果显示，在大多数情况下，UniAdapter都能带来更好的性能和更低的成本。

    Large-scale vision-language pre-trained models have shown promising transferability to various downstream tasks. As the size of these foundation models and the number of downstream tasks grow, the standard full fine-tuning paradigm becomes unsustainable due to heavy computational and storage costs. This paper proposes UniAdapter, which unifies unimodal and multimodal adapters for parameter-efficient cross-modal adaptation on pre-trained vision-language models. Specifically, adapters are distributed to different modalities and their interactions, with the total number of tunable parameters reduced by partial weight sharing. The unified and knowledge-sharing design enables powerful cross-modal representations that can benefit various downstream tasks, requiring only 1.0%-2.0% tunable parameters of the pre-trained model. Extensive experiments on 6 cross-modal downstream benchmarks (including video-text retrieval, image-text retrieval, VideoQA, and VQA) show that in most cases, UniAdapter 
    
[^75]: 花生能与分布语义有恋爱之情吗？

    Can Peanuts Fall in Love with Distributional Semantics?. (arXiv:2301.08731v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.08731](http://arxiv.org/abs/2301.08731)

    通过计算语言模型和单词向量模拟，研究发现某些处理效应可不需要情景模型。

    

    背景对预期词有影响，通过涉及植物人的故事，理解者预期句子“花生恋爱了”，而不是“花生被盐腌了”，如Nieuwland和van Berkum（2006）所示。这种预期的更新是通过情景模型-所描述事件的心理表示来解释的。然而，最近的研究显示，仅通过分布信息就可以预测N400的振幅，这就引发了：这些情境效应是否需要情景模型的问题。我们使用六个计算语言模型和三套单词向量来模拟Nieuwland和van Berkum（2006）的结果，其中没有显式的情景模型或语义基础。我们发现其中的一部分可以完全模拟Nieuwland和van Berkum（2006）所发现的效果。因此，至少有些通过情景模型解释的处理效应实际上不需要显式的情景模型。

    Context changes expectations about upcoming words - following a story involving an anthropomorphic peanut, comprehenders expect the sentence the peanut was in love more than the peanut was salted, as indexed by N400 amplitude (Nieuwland & van Berkum, 2006). This updating of expectations has been explained using Situation Models - mental representations of a described event. However, recent work showing that N400 amplitude is predictable from distributional information alone raises the question whether situation models are necessary for these contextual effects. We model the results of Nieuwland and van Berkum (2006) using six computational language models and three sets of word vectors, none of which have explicit situation models or semantic grounding. We find that a subset of these can fully model the effect found by Nieuwland and van Berkum (2006). Thus, at least some processing effects normally explained through situation models may not in fact require explicit situation models.
    
[^76]: 统一流式和非流式变换器中的上下文偏差双阶段上下文过滤

    Two Stage Contextual Word Filtering for Context bias in Unified Streaming and Non-streaming Transducer. (arXiv:2301.06735v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2301.06735](http://arxiv.org/abs/2301.06735)

    本文提出一种针对上下文偏差的双阶段上下文过滤方法，将流式输出和预定义上下文单词列表相结合，提高了端对端模型的识别准确率，并加快了推理过程。

    

    对于一个端对端的自动语音识别系统来说，很难识别像实体这样在训练数据中出现不频繁的单词。缓解这个问题的一种常用方法是将上下文信息输入到声学模型中。之前的研究已经证明了一个紧凑而准确的上下文列表可以显著提高性能。本文提出了一种高效的方法，为统一的流式/非流式的端对端模型得到一个高质量的上下文列表。具体来说，我们利用基于电话级别的流式输出来首先过滤预定义的上下文单词列表，然后将其融合到非因果编码器和解码器中生成最终的识别结果。我们的方法提高了上下文ASR系统的准确性并加快了推理过程。在两个数据集上的实验证明，相比基线系统，CERR提高了20%以上。同时，当上下文单词列表的大小超过6000时，我们的系统的RTF可以稳定在0.15左右。

    It is difficult for an E2E ASR system to recognize words such as entities appearing infrequently in the training data. A widely used method to mitigate this issue is feeding contextual information into the acoustic model. Previous works have proven that a compact and accurate contextual list can boost the performance significantly. In this paper, we propose an efficient approach to obtain a high quality contextual list for a unified streaming/non-streaming based E2E model. Specifically, we make use of the phone-level streaming output to first filter the predefined contextual word list then fuse it into non-casual encoder and decoder to generate the final recognition results. Our approach improve the accuracy of the contextual ASR system and speed up the inference process. Experiments on two datasets demonstrates over 20% CERR comparing to the baseline system. Meanwile, the RTF of our system can be stabilized within 0.15 when the size of the contextual word list grows over 6000.
    
[^77]: 通过上下文长度探究黑匣子语言模型解释

    Black-box language model explanation by context length probing. (arXiv:2212.14815v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.14815](http://arxiv.org/abs/2212.14815)

    该论文提出了一个模型不可知的新颖解释技术：上下文长度探测，通过跟踪模型预测与可用上下文长度的关系来对不同上下文分配不同的重要性得分。该方法适用于大型预训练语言模型，并有利于研究远距离依赖性。

    

    大型语言模型的广泛采用强调了改善其可解释性的必要性。我们提出了一种新颖的解释技术：上下文长度探测，它基于跟踪模型预测作为可用上下文长度的函数，并允许对不同上下文分配不同的重要性得分。该技术是模型不可知的，不依赖于除计算token级概率之外的模型内部访问。我们将上下文长度探测应用于大型预训练语言模型，并提供了一些初始的分析和见解，包括研究远距离依赖性的潜力。方法的源代码和交互式演示可用。

    The increasingly widespread adoption of large language models has highlighted the need for improving their explainability. We present context length probing, a novel explanation technique for causal language models, based on tracking the predictions of a model as a function of the length of available context, and allowing to assign differential importance scores to different contexts. The technique is model-agnostic and does not rely on access to model internals beyond computing token-level probabilities. We apply context length probing to large pre-trained language models and offer some initial analyses and insights, including the potential for studying long-range dependencies. The source code and an interactive demo of the method are available.
    
[^78]: DialGuide：将对话模型行为与开发者指南对准

    DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines. (arXiv:2212.10557v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10557](http://arxiv.org/abs/2212.10557)

    DialGuide是一个使用自然语言规则或指南控制对话模型行为的新框架，能够帮助模型生成更加一致的响应，提升用户信任。作者在开放域对话回复生成的三个任务上评估了DialGuide，并提供了基准模型。

    

    对话模型能够生成连贯流畅的回复，但是仍然具有挑战性，可能会产生不吸引人、不安全的结果，这种不可预测性会影响用户信任并限制模型在实际环境中的应用。为了解决这个问题，我们引入了DialGuide，这是一个使用自然语言规则或指南控制对话模型行为的新框架。这些指南提供了关于它们适用的上下文和响应内容的信息，使得模型能够生成与开发者期望和意图更加一致的响应。我们在开放域对话回复生成的三个任务上评估了DialGuide：指南选择，响应生成和响应包含验证。我们的数据集包含两个领域（闲聊和安全）的10,737个正向和15,467个负向对话上下文-响应-指南三元组，为这些任务提供了基准模型。

    Dialogue models are able to generate coherent and fluent responses, but they can still be challenging to control and may produce non-engaging, unsafe results. This unpredictability diminishes user trust and can hinder the use of the models in the real world. To address this, we introduce DialGuide, a novel framework for controlling dialogue model behavior using natural language rules, or guidelines. These guidelines provide information about the context they are applicable to and what should be included in the response, allowing the models to generate responses that are more closely aligned with the developer's expectations and intent. We evaluate DialGuide on three tasks in open-domain dialogue response generation: guideline selection, response generation, and response entailment verification. Our dataset contains 10,737 positive and 15,467 negative dialogue context-response-guideline triplets across two domains - chit-chat and safety. We provide baseline models for the tasks and benc
    
[^79]: 小红帽环球旅行：基于大语言模型的跨语言故事规划与生成

    Little Red Riding Hood Goes Around the Globe:Crosslingual Story Planning and Generation with Large Language Models. (arXiv:2212.10471v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10471](http://arxiv.org/abs/2212.10471)

    本论文提出了一个新的跨语言故事生成任务，并利用大型预训练语言模型研究不同的故事规划。结果表明将故事分为三幕可以带来更一致和有趣的叙述，同时允许明确控制其内容和结构。

    

    先前的研究已经证明了在单语环境下规划故事生成的有效性，主要集中在英语上。我们考虑在跨语言的自动故事生成中，规划是否带来了优势。我们提出了一个新的跨语言故事生成任务，并为该任务提供了一个新的数据集。我们通过利用大型预训练语言模型的创造和推理能力，对不同的故事规划进行了全面的研究，并在多种语言中生成了故事。我们的结果表明，将故事结构化为三幕的规划可以带来更一致和有趣的叙述，同时允许明确控制其内容和结构。

    Previous work has demonstrated the effectiveness of planning for story generation exclusively in a monolingual setting focusing primarily on English. We consider whether planning brings advantages to automatic story generation across languages. We propose a new task of cross-lingual story generation with planning and present a new dataset for this task. We conduct a comprehensive study of different plans and generate stories in several languages, by leveraging the creative and reasoning capabilities of large pre-trained language models. Our results demonstrate that plans which structure stories into three acts lead to more coherent and interesting narratives, while allowing to explicitly control their content and structure.
    
[^80]: SeqDiffuSeq: 一种使用编码器-解码器Transformer的文本扩散模型用于序列生成

    SeqDiffuSeq: Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation. (arXiv:2212.10325v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10325](http://arxiv.org/abs/2212.10325)

    本文提出了一种名为SeqDiffuSeq的文本扩散模型，用于序列生成，采用了编码器-解码器Transformer架构和自适应噪声调度技术，旨在探索扩散模型在自然语言生成方面的性能表现。

    

    扩散模型是一种新的生成建模范式，在图像、音频和视频生成方面取得了巨大成功。然而，考虑到文本的离散分类性质，将连续扩散模型扩展到自然语言并不是微不足道的，而且文本扩散模型研究较少。序列生成是自然语言处理中至关重要的话题之一。在本文中，我们将扩散模型应用于序列生成，探索扩散模型的优越生成性能能否转移到自然语言领域。我们提出SeqDiffuSeq，一种用于序列生成的文本扩散模型。SeqDiffuSeq使用编码器-解码器Transformer架构来建模去噪函数。为了提高生成质量，SeqDiffuSeq结合了自我调节技术和一个新提出的自适应噪声调度技术。自适应噪声调度具有均匀去噪的困难

    Diffusion model, a new generative modelling paradigm, has achieved great success in image, audio, and video generation. However, considering the discrete categorical nature of text, it is not trivial to extend continuous diffusion models to natural language, and text diffusion models are less studied. Sequence-to-sequence text generation is one of the essential natural language processing topics. In this work, we apply diffusion models to approach sequence-to-sequence text generation, and explore whether the superiority generation performance of diffusion model can transfer to natural language domain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence generation. SeqDiffuSeq uses an encoder-decoder Transformers architecture to model denoising function. In order to improve generation quality, SeqDiffuSeq combines the self-conditioning technique and a newly proposed adaptive noise schedule technique. The adaptive noise schedule has the difficulty of denoising evenly 
    
[^81]: KNIFE: 从自由文本理由中提取推理知识

    KNIFE: Distilling Reasoning Knowledge From Free-Text Rationales. (arXiv:2212.09721v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09721](http://arxiv.org/abs/2212.09721)

    通过KNIFE，可以从自由文本理由中提取推理知识，进而在小型语言模型中提高推理能力。

    

    语言模型在许多语言推理任务中表现出色，但它们的意外错误引起了对它们的推理能力的怀疑。因此，越来越多的人对微调/提示语言模型感兴趣，这些语言模型包含任务实例和其关联的自由文本理由（FTR），这些理由解释了预测正确任务输出的正确推理过程。然而，现有的微调方法无法提高语言模型的性能，而提示需要过大（即>50B）的语言模型才能良好工作。我们提出了KNIFE，证明从FTR中可以有效地提取推理知识，将其灌输到小型（即<1B）的语言模型中，从而提高语言模型的性能。首先，KNIFE对一个师生语言模型进行微调（给定任务输入和FTR），以预测任务输出，将推理知识从FTR转移至师生隐藏状态。其次，KNIFE对一个学生语言模型进行微调（仅给定任务输入），以使其隐藏状态类似于师生模型的隐藏状态，从而提高学生模型的性能。

    Language models (LMs) have yielded impressive results on many language reasoning tasks, but their unexpected errors raise doubts about their reasoning abilities. In light of this, there is growing interest in finetuning/prompting LMs with both task instances and their associated free-text rationales (FTRs), which explain the correct reasoning process for predicting the correct task output (i.e., how to be "right for the right reasons"). However, existing finetuning methods fail to improve LM performance, while prompting needs prohibitively large (i.e., >50B) LMs to work well. We propose KNIFE, which shows that reasoning knowledge can be effectively distilled from FTRs into a small (i.e., <1B) LM and improve the LM's performance. First, KNIFE finetunes a teacher LM (given task input and FTR) to predict the task output, transferring reasoning knowledge from the FTRs to the teacher's hidden states. Second, KNIFE finetunes a student LM (given task input only) such that its hidden states ar
    
[^82]: SegAugment: 基于分段增强的语音翻译数据利用最大化

    SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations. (arXiv:2212.09699v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09699](http://arxiv.org/abs/2212.09699)

    该论文提出了一种新的数据增强策略SegAugment，利用音频分段系统生成数据集的多个句子级别的替代版本，能够提高语音翻译的性能，实验结果显示平均BLEU分数提高了2.5分，甚至在低资源情况下提高了5分。

    

    端到端的语音翻译由于缺乏可用的数据资源而受到限制。虽然大多数资源是基于文档的，但也提供了一种句子级别的版本，但是它只有单个并且是固定的，可能会妨碍数据的有用性。我们提出了一种新的数据增强策略，SegAugment，通过生成数据集的多个句子级别的替代版本来解决这个问题。我们的方法利用音频分段系统，根据不同的长度约束重新分段每个文档的语音，然后通过对齐方法获取目标文本。实验证明，在MuST-C的八种语言对中，我们的方法具有一致的增益，平均增加了2.5 BLEU分数，并在mTEDx的低资源场景中获得了多达5 BLEU分数的提升。此外，当与强大的系统结合时，SegAugment在MuST-C中树立了新的状态记录。最后，我们还展示了该方法可以成功地增强句子级别数据集，并且使得端到端模型在低资源条件下的表现得到了提升。

    End-to-end Speech Translation is hindered by a lack of available data resources. While most of them are based on documents, a sentence-level version is available, which is however single and static, potentially impeding the usefulness of the data. We propose a new data augmentation strategy, SegAugment, to address this issue by generating multiple alternative sentence-level versions of a dataset. Our method utilizes an Audio Segmentation system, which re-segments the speech of each document with different length constraints, after which we obtain the target text via alignment methods. Experiments demonstrate consistent gains across eight language pairs in MuST-C, with an average increase of 2.5 BLEU points, and up to 5 BLEU for low-resource scenarios in mTEDx. Furthermore, when combined with a strong system, SegAugment establishes new state-of-the-art results in MuST-C. Finally, we show that the proposed method can also successfully augment sentence-level datasets, and that it enables 
    
[^83]: 词向量的范数编码信息增益

    Norm of Word Embedding Encodes Information Gain. (arXiv:2212.09663v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09663](http://arxiv.org/abs/2212.09663)

    本文研究发现，跳字模型和负采样方法中静态词向量的平方范数编码了词所传达的信息增益，通过与语料库中单词的分布之间的KL散度来定义，可用于关键词提取、词性区分和上位词分类等任务。

    

    词的分布式表示编码了词汇语义信息，但是编码了哪些类型的信息？以及如何编码？本文针对跳字模型和负采样方法，发现静态词向量的平方范数编码了词所传达的信息增益；而信息增益是通过词在共现分布和语料库的单词分布之间的KL散度来定义的。我们的发现是通过指数族概率分布的理论框架说明的，并通过消除词频引起的虚假相关性的精密实验进行了确认。我们证明，无论是KL散度还是词嵌入的平方范数，在关键词提取、词性区分和上位词分类等任务中都提供了有用的词信息度量。

    Distributed representations of words encode lexical semantic information, but what type of information is encoded, and how? Focusing on the skip-gram with negative-sampling method, we found that the squared norm of static word embedding encodes the information gain conveyed by the word; the information gain is defined by the Kullback-Leibler divergence of the co-occurrence distribution of the word to the unigram distribution of the corpus. Our findings are explained by the theoretical framework of the exponential family of probability distributions and confirmed through precise experiments that remove spurious correlations arising from word frequency. We demonstrate that both the KL divergence and the squared norm of embedding provide a useful metric of a word's informativeness in tasks such as keyword extraction, part-of-speech discrimination, and hypernym classification.
    
[^84]: RISE: 利用检索技术进行摘要评估

    RISE: Leveraging Retrieval Techniques for Summarization Evaluation. (arXiv:2212.08775v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08775](http://arxiv.org/abs/2212.08775)

    RISE是一种利用信息检索技术进行摘要评估的新方法，能够在没有参考摘要的情况下评估给定输入文档的生成摘要。RISE具有更高的相关性，数据效率和泛化能力。

    

    对于自动生成的文本摘要进行评估是一项具有挑战性的任务。尽管出现了许多有趣的方法，但仍然无法达到人类评估的水平。本文提出了RISE，一种利用信息检索技术进行摘要评估的新方法。RISE首先作为一个检索任务进行训练，使用双编码器检索设置，并且可以在没有参考摘要的情况下评估给定输入文档的生成摘要。当评估新数据集时，RISE特别适用，因为可能没有参考摘要可用于评估。我们在SummEval基准测试（Fabbri et al.，2021）上进行了全面实验，结果表明RISE与许多过去的摘要评估方法相比，与人类评估具有更高的相关性。此外，RISE还展示了跨语言的数据效率和泛化能力。

    Evaluating automatically-generated text summaries is a challenging task. While there have been many interesting approaches, they still fall short of human evaluations. We present RISE, a new approach for evaluating summaries by leveraging techniques from information retrieval. RISE is first trained as a retrieval task using a dual-encoder retrieval setup, and can then be subsequently utilized for evaluating a generated summary given an input document, without gold reference summaries. RISE is especially well suited when working on new datasets where one may not have reference summaries available for evaluation. We conduct comprehensive experiments on the SummEval benchmark (Fabbri et al., 2021) and the results show that RISE has higher correlation with human evaluations compared to many past approaches to summarization evaluation. Furthermore, RISE also demonstrates data-efficiency and generalizability across languages.
    
[^85]: 基于文本的人格计算：挑战和未来方向

    On Text-based Personality Computing: Challenges and Future Directions. (arXiv:2212.06711v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.06711](http://arxiv.org/abs/2212.06711)

    本文提出了15个基于文本的人格计算方面的挑战，包括人格分类法，测量质量，数据集，性能评估，建模选择以及道德和公平性，旨在激发更多的有效和可靠的TPC研究。

    

    基于文本的人格计算（TPC）在自然语言处理（NLP）中引起了许多研究兴趣。本文描述了15个挑战，值得研究社区的关注。这些挑战按以下主题组织：人格分类法、测量质量、数据集、性能评估、建模选择以及道德和公平性。在应对每个挑战时，我们不仅结合了NLP和社会科学的视角，还提供具体的建议。我们希望激发更多有效和可靠的TPC研究。

    Text-based personality computing (TPC) has gained many research interests in NLP. In this paper, we describe 15 challenges that we consider deserving the attention of the research community. These challenges are organized by the following topics: personality taxonomies, measurement quality, datasets, performance evaluation, modelling choices, as well as ethics and fairness. When addressing each challenge, not only do we combine perspectives from both NLP and social sciences, but also offer concrete suggestions. We hope to inspire more valid and reliable TPC research.
    
[^86]: 探究用于汉语漏字检查的字形音标信息：有效性和未来方向

    Investigating Glyph Phonetic Information for Chinese Spell Checking: What Works and What's Next. (arXiv:2212.04068v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.04068](http://arxiv.org/abs/2212.04068)

    本文探究用于汉语漏字检查的字形音标信息的效果和应用方向，提出一个更具挑战性和实用性的测试设置，并公开了所有代码。

    

    虽然预训练的中文语言模型在各种自然语言处理任务中表现出色，但汉语漏字检查（CSC）仍然是一个挑战。先前的研究探讨了使用字形和音标等信息来改善区分错拼字符的能力，取得了良好的结果。然而，这些模型的泛化能力并不好理解：不清楚它们是否包含字形音标信息，以及如果包含这些信息，是否充分利用了。在本文中，我们旨在更好地了解字形音标信息在 CSC 任务中的作用，并提出改进的方向。此外，我们提出了一个新的、更具挑战性和实用的 CSC 模型泛化性测试设置。所有代码都已公开发布。

    While pre-trained Chinese language models have demonstrated impressive performance on a wide range of NLP tasks, the Chinese Spell Checking (CSC) task remains a challenge. Previous research has explored using information such as glyphs and phonetics to improve the ability to distinguish misspelled characters, with good results. However, the generalization ability of these models is not well understood: it is unclear whether they incorporate glyph-phonetic information and, if so, whether this information is fully utilized. In this paper, we aim to better understand the role of glyph-phonetic information in the CSC task and suggest directions for improvement. Additionally, we propose a new, more challenging, and practical setting for testing the generalizability of CSC models. All code is made publicly available.
    
[^87]: 自动化从电子健康档案记录中识别逐出状态

    Automated Identification of Eviction Status from Electronic Health Record Notes. (arXiv:2212.02762v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.02762](http://arxiv.org/abs/2212.02762)

    本研究开发了一种自然语言处理系统，可以自动从电子健康档案（EHR）记录中检测到逐出状态，并开发了一个新颖的模型KIRESH，已经显示出明显优于其他最先进的模型。

    

    目标：逐出是健康的重要社会和行为决定因素。逐出与一系列负面事件相关，可能导致失业、住房不安全/无家可归、长期贫困和精神健康问题。在本研究中，我们开发了一种自然语言处理系统，可以自动从电子健康档案（EHR）记录中检测到逐出状态。

    Objective: Evictions are important social and behavioral determinants of health. Evictions are associated with a cascade of negative events that can lead to unemployment, housing insecurity/homelessness, long-term poverty, and mental health problems. In this study, we developed a natural language processing system to automatically detect eviction status from electronic health record (EHR) notes.  Materials and Methods: We first defined eviction status (eviction presence and eviction period) and then annotated eviction status in 5000 EHR notes from the Veterans Health Administration (VHA). We developed a novel model, KIRESH, that has shown to substantially outperform other state-of-the-art models such as fine-tuning pre-trained language models like BioBERT and BioClinicalBERT. Moreover, we designed a novel prompt to further improve the model performance by using the intrinsic connection between the two sub-tasks of eviction presence and period prediction. Finally, we used the Temperatur
    
[^88]: EURO: ESPnet无监督ASR开源工具包（arXiv:2211.17196v3 [cs.CL] UPDATED）

    EURO: ESPnet Unsupervised ASR Open-source Toolkit. (arXiv:2211.17196v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.17196](http://arxiv.org/abs/2211.17196)

    本文介绍了ESPnet无监督ASR开源工具包（EURO）的细节及其在自监督语音表征和对抗性训练方面的最新方法。该工具包集成了27个自监督模型和基于图形的解码策略，成功提高了UASR的效率和可重现性；在TIMIT和LibriSpeech数据上获得了最先进的性能。

    

    本文介绍了ESPnet无监督ASR开源工具包（EURO），这是一个端到端的无监督自动语音识别（UASR）开源工具包。EURO采用了由Wav2vec-U引入的最先进的UASR学习方法，该方法最初由FAIRSEQ实现，利用自监督语音表征和对抗性训练。除了wav2vec2之外，EURO通过集成S3PRL和k2扩展了UASR任务的功能和促进了可重现性，从而实现了27个自监督模型的灵活前端和各种基于图形的解码策略。EURO在ESPnet中实现并遵循其统一流程，提供了具有完整设置的UASR配方。这提高了流程的效率，并允许EURO轻松应用于ESPnet的现有数据集。对三个主流的自监督模型进行了广泛的实验，证明了该工具包的有效性，并在TIMIT和LibriSpeech数据上实现了最先进的UASR性能。

    This paper describes the ESPnet Unsupervised ASR Open-source Toolkit (EURO), an end-to-end open-source toolkit for unsupervised automatic speech recognition (UASR). EURO adopts the state-of-the-art UASR learning method introduced by the Wav2vec-U, originally implemented at FAIRSEQ, which leverages self-supervised speech representations and adversarial training. In addition to wav2vec2, EURO extends the functionality and promotes reproducibility for UASR tasks by integrating S3PRL and k2, resulting in flexible frontends from 27 self-supervised models and various graph-based decoding strategies. EURO is implemented in ESPnet and follows its unified pipeline to provide UASR recipes with a complete setup. This improves the pipeline's efficiency and allows EURO to be easily applied to existing datasets in ESPnet. Extensive experiments on three mainstream self-supervised models demonstrate the toolkit's effectiveness and achieve state-of-the-art UASR performance on TIMIT and LibriSpeech data
    
[^89]: 无监督依存语法的语法可替代性

    Syntactic Substitutability as Unsupervised Dependency Syntax. (arXiv:2211.16031v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.16031](http://arxiv.org/abs/2211.16031)

    本文提出了一种新的无需语法规则的诱导方法，该方法基于语法可替代性，能够在定量和定性方面都有所提升。

    

    语法是构成人类语言鲜明和组合性的潜在分层结构。本文进一步探究了依赖于语言模型注意力分布的句法依存关系表示的假设，并提出了一种新的无需语法规则的诱导方法。我们旨在模拟句法替代性这个更为普遍的关系，而不是严格按照标注架构建模依存关系。这种关系体现了事实，即句法依存关系两端的单词可以被同一句法范畴的单词所替换，从而定义了一组语法不变的句子。这些句子的表示被用作解析的基础。我们证明，我们的方法在定量和定性方面都有所提升，例如在长距离主谓一致性任务中实现了78.3％的召回率，而之前的无监督方法只有8.5％的召回率。

    Syntax is a latent hierarchical structure which underpins the robust and compositional nature of human language. In this work, we further explore the hypothesis that syntactic dependencies can be represented in the attention distributions of language models trained on text and propose a new method to induce these structures theory-agnostically. Instead of modeling syntactic relations as defined by annotation schemata, we model a more general property implicit in the definition of dependency relations, syntactic substitutability. This property captures the fact that the words at either end of a syntactic dependency can be substituted with words from the same syntactic category, defining a set of syntactically-invariant sentences whose representations are then used as the basis for parsing. We demonstrate that our method results in both qualitative and quantitative gains, for example achieving 78.3% recall on a long-distance subject-verb agreement task vs. 8.5% with a previous unsupervis
    
[^90]: [RE]VER：学习自然语言表示以阐述实体和关系

    [RE]VER: Learning Natural Language Representations for Verbalizing Entities and Relations. (arXiv:2211.11093v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.11093](http://arxiv.org/abs/2211.11093)

    本文提出了一种名为[RE]VER的系统，使用基于transformer的模型来学习实体和关系的自然语言表示，能够生成一个能够表示实体与其他实体关系的句子，相比于之前的最先进方法有了显著改进。

    

    实体及实体之间的关系是现实世界中至关重要的。人们通过理解实体和关系来了解世界。本文提出了一种名为[RE]VER的系统，通过使用基于transformer的模型来学习实体和关系的自然语言表示，并生成一个能够表示实体与其他实体关系的句子。我们在多个基准数据集上评估了我们的模型，并证明其相比于之前的最先进方法有了显著改进。

    Entities and relationships between entities are vital in the real world. Essentially, we understand the world by understanding entities and relations. For instance, to understand a field, e.g., computer science, we need to understand the relevant concepts, e.g., machine learning, and the relationships between concepts, e.g., machine learning and artificial intelligence. To understand a person, we should first know who he/she is and how he/she is related to others. To understand entities and relations, humans may refer to natural language descriptions. For instance, when learning a new scientific term, people usually start by reading its definition in dictionaries or encyclopedias. To know the relationship between two entities, humans tend to create a sentence to connect them. In this paper, we propose [RE]VER: A Unified Model for Verbalizing Entities and Relations. Specifically, we attempt to build a system that takes any entity or entity set as input and generates a sentence to repres
    
[^91]: 语言基础中的语用学：现象、任务和建模方法

    Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling Approaches. (arXiv:2211.08371v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08371](http://arxiv.org/abs/2211.08371)

    本文调查了目前语用学模型的研究现状，提出了建议并分析了语言含义的丰富性。未来的任务设计需要引出语用现象，并关注更广泛的交流上下文和效益的方向。

    

    人们在交流中经常依赖上下文来丰富言外之意，从而实现简明而有效的沟通。为了能够与人类成功地自然交互，面向用户的人工智能系统将需要类似的语用学技能：依靠各种上下文信息——从共享的语言目标和约定到视觉和具身世界，有效地使用语言。我们调查了现有的语境设置和语用建模方法，并分析了每个工作中任务目标、环境上下文和交际效益如何丰富语言含义。我们提出了未来基础任务设计的建议，以自然地引出语用学现象，并建议关注更广泛的交流上下文和效益的方向。

    People rely heavily on context to enrich meaning beyond what is literally said, enabling concise but effective communication. To interact successfully and naturally with people, user-facing artificial intelligence systems will require similar skills in pragmatics: relying on various types of context -from shared linguistic goals and conventions, to the visual and embodied world -- to use language effectively. We survey existing grounded settings and pragmatic modeling approaches and analyze how the task goals, environmental contexts, and communicative affordances in each work enrich linguistic meaning. We present recommendations for future grounded task design to naturally elicit pragmatic phenomena, and suggest directions that focus on a broader range of communicative contexts and affordances.
    
[^92]: MEAL：少样本提示的稳定和活跃学习

    MEAL: Stable and Active Learning for Few-Shot Prompting. (arXiv:2211.08358v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08358](http://arxiv.org/abs/2211.08358)

    本文提出了MEAL方法，是一个可以在少量样本下进行分类，稳定和活跃的少样本学习方法。方法包含两个贡献，一个是提出新颖的减少运行变异性的集成方法，另一个是引入AL准则用于数据选择。

    

    通过启动和提示，基础模型已经成为高效的少样本学习器，在少样本分类方面取得了巨大进展。然而，这种方法在不同的少样本集合（数据选择）和不同的微调运行（运行变异性）之间具有高变化率，这不仅阻碍了不同方法之间的公平比较，而且使得少样本学习对许多实际应用过于不可靠。为了缓解这些问题，我们提出了两个贡献，用于更稳定和有效的少样本学习：首先，我们提出了新颖的集成方法，并展示了它们可以大幅减少运行变异性。其次，我们引入了一种新的主动学习（AL）准则用于数据选择，并呈现了第一个专门针对基于提示的学习的AL方法。在实验中，我们展示了我们的联合方法MEAL（多提示微调与预测集成与主动学习）可以稳定地在少量样本下进行分类。

    Few-shot classification has made great strides due to foundation models that, through priming and prompting, are highly effective few-shot learners. However, this approach has high variance both across different sets of few shots (data selection) and across different finetuning runs (run variability). This is problematic not only because it impedes the fair comparison of different approaches, but especially because it makes few-shot learning too unreliable for many real-world applications. To alleviate these issues, we make two contributions for more stable and effective few-shot learning: First, we propose novel ensembling methods and show that they substantially reduce run variability. Second, we introduce a new active learning (AL) criterion for data selection and present the first AL-based approach specifically tailored towards prompt-based learning. In our experiments, we show that our combined method, MEAL (Multiprompt finetuning and prediction Ensembling with Active Learning), i
    
[^93]: GLUE-X: 从ODD普适性角度评估自然语言理解模型

    GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective. (arXiv:2211.08073v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08073](http://arxiv.org/abs/2211.08073)

    本文提出了第一个创建名为方法的统一基准的尝试，用于评估NLP模型中的OOD鲁棒性，该基准包括13个公开可用的OOD测试数据集，并在21个常用的PLMs上对8个经典NLP任务进行评估。

    

    预训练语言模型（PLMs）通过利用大量的训练数据，已知可以提高自然语言理解模型的泛化性能。然而，许多NLP任务中的ODD普适性问题仍然存在，这限制了这些方法在现实世界中的部署。本文提出了第一个创建名为方法的统一基准的尝试，用于评估NLP模型中的OOD鲁棒性，强调OOD鲁棒性的重要性，并提供如何衡量模型的鲁棒性以及如何改善模型的见解。该基准包括13个公开可用的OOD测试数据集，并在21个常用的PLMs（包括GPT-3和GPT-3.5）上对8个经典NLP任务进行评估。我们的研究结果确认了在所有设置下，与ID准确度相比，存在显着的性能下降，需要改善NLP任务中的OOD准确度。

    Pre-trained language models (PLMs) are known to improve the generalization performance of natural language understanding models by leveraging large amounts of data during the pre-training phase. However, the out-of-distribution (OOD) generalization problem remains a challenge in many NLP tasks, limiting the real-world deployment of these methods. This paper presents the first attempt at creating a unified benchmark named \method for evaluating OOD robustness in NLP models, highlighting the importance of OOD robustness and providing insights on how to measure the robustness of a model and how to improve it. The benchmark includes 13 publicly available datasets for OOD testing, and evaluations are conducted on 8 classic NLP tasks over 21 popularly used PLMs, including GPT-3 and GPT-3.5. Our findings confirm the need for improved OOD accuracy in NLP tasks, as significant performance degradation was observed in all settings compared to in-distribution (ID) accuracy.
    
[^94]: 挑战语言模型的语言结构推理能力

    Prompting Language Models for Linguistic Structure. (arXiv:2211.07830v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07830](http://arxiv.org/abs/2211.07830)

    本文探究了预训练语言模型（PLMs）对于语言结构的推理能力，通过结构化提示方法，在零样本和少样本情况下进行了序列标注实验，并证明了 PLMs 的上下文学习能力和语言知识的推广性，这能够帮助检索任意标签的语言结构。

    

    尽管预训练语言模型（PLMs）可以完成各种各样的语言任务，但基于可推广性的语言理解能力与基于表面级别的词汇模式有多少关系仍然是个未解之谜。为了测试这个问题，我们提出了一种针对语言结构预测任务的结构化提示方法，允许我们在自回归PLMs的零样本和少样本情况下进行序列标注。我们将其用于词性标注、命名实体识别和句子分块，并证明了它在所有情况下的强大少样本性能。我们发现，虽然由于任务泄露到预训练语料库中，PLMs包含了重要的任务标签先验知识，但结构化提示也可以检索任意标签的语言结构。这些发现表明，PLMs的上下文学习能力和语言知识具有推广性，不仅局限于其训练数据的记忆。

    Although pretrained language models (PLMs) can be prompted to perform a wide range of language tasks, it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns. To test this, we present a structured prompting approach for linguistic structured prediction tasks, allowing us to perform zero- and few-shot sequence tagging with autoregressive PLMs. We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking, demonstrating strong few-shot performance in all cases. We also find that while PLMs contain significant prior knowledge of task labels due to task leakage into the pretraining corpus, structured prompting can also retrieve linguistic structure with arbitrary labels. These findings indicate that the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data.
    
[^95]: DiaASQ：一种基于对话的方面情感四元组分析基准。

    DiaASQ : A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis. (arXiv:2211.05705v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.05705](http://arxiv.org/abs/2211.05705)

    本文介绍了一项新的任务DiaASQ，它旨在检测对话中的目标-方面-观点-情感四元组。我们手动构建了一个大规模的高质量DiaASQ数据集，并开发了一种神经模型来进行基准测试，该模型在跨话语四元组提取方面取得了进展。

    

    近几十年来，基于方面情感分析（ABSA）的快速发展展现出在现实世界中的巨大潜力。然而，当前的ABSA工作大多限于单个文本场景，缺乏对话上下文的研究。为了弥合细粒度情感分析和对话中观点挖掘之间的差距，在本文中，我们引入了一项新的任务，即基于对话的方面情感四元组分析（DiaASQ），旨在检测对话中的目标-方面-观点-情感四元组。我们手动构建了一个大规模的高质量DiaASQ数据集，涵盖中文和英文两种语言。我们开发了一种神经模型来进行基准测试，该模型在有效地执行端到端四元组预测方面取得了进展，并设法结合丰富的对话特定和话语特征表示，以实现更好的跨话语四元组提取。我们希望这一新的基准将激发更多的进展。

    The rapid development of aspect-based sentiment analysis (ABSA) within recent decades shows great potential for real-world society. The current ABSA works, however, are mostly limited to the scenario of a single text piece, leaving the study in dialogue contexts unexplored. To bridge the gap between fine-grained sentiment analysis and conversational opinion mining, in this work, we introduce a novel task of conversational aspect-based sentiment quadruple analysis, namely DiaASQ, aiming to detect the quadruple of target-aspect-opinion-sentiment in a dialogue. We manually construct a large-scale high-quality DiaASQ dataset in both Chinese and English languages. We deliberately develop a neural model to benchmark the task, which advances in effectively performing end-to-end quadruple prediction, and manages to incorporate rich dialogue-specific and discourse feature representations for better cross-utterance quadruple extraction. We hope the new benchmark will spur more advancements in th
    
[^96]: 一种使用噪声增强语音作为目标的训练和推理策略，用于无清晰语音的语音增强

    A Training and Inference Strategy Using Noisy and Enhanced Speech as Target for Speech Enhancement without Clean Speech. (arXiv:2210.15368v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.15368](http://arxiv.org/abs/2210.15368)

    为解决语音增强领域中“无清晰语音”的挑战，提出了使用增强语音作为目标的训练和推理策略，即使在域内和域外噪声差异较大的情况下仍能有效，实验结果优于基线方法。

    

    无清晰语音是发展语音增强系统的实际挑战，这意味着它们的训练准则和评估指标之间存在不可避免的不匹配。为了应对这种不利情况，我们提出了一种训练和推理策略，其中使用增强语音作为目标来改进先前提出的噪声目标训练（NyTT）。由于域内噪声与外部噪声的同质性是NyTT有效性的关键，我们通过混音训练多个学生模型，包括：1）使用教师模型估计的语音和噪声进行增强目标训练，或者2）使用原始的噪声语音和教师模型估计的噪声进行噪声目标训练。实验结果表明，我们提出的方法优于几种基线方法，特别是在教师/学生推理方面，其中预测的清晰语音是通过教师和最终学生模型成功地推导出来的。

    The lack of clean speech is a practical challenge to the development of speech enhancement systems, which means that there is an inevitable mismatch between their training criterion and evaluation metric. In response to this unfavorable situation, we propose a training and inference strategy that additionally uses enhanced speech as a target by improving the previously proposed noisy-target training (NyTT). Because homogeneity between in-domain noise and extraneous noise is the key to the effectiveness of NyTT, we train various student models by remixing 1) the teacher model's estimated speech and noise for enhanced-target training or 2) raw noisy speech and the teacher model's estimated noise for noisy-target training. Experimental results show that our proposed method outperforms several baselines, especially with the teacher/student inference, where predicted clean speech is derived successively through the teacher and final student models.
    
[^97]: 结合命名实体识别的语音翻译

    Joint Speech Translation and Named Entity Recognition. (arXiv:2210.11987v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.11987](http://arxiv.org/abs/2210.11987)

    本文提出了一种新型多任务模型，结合命名实体识别和直接语音翻译，相比级联系统在命名实体识别上表现更好，且翻译质量和计算效率不会有所下降。

    

    现代自动翻译系统旨在将人类放在中心位置，通过提供上下文支持和知识来实现这一目标。在这种情况下，一个关键任务是通过命名实体识别（NER）和实体链接系统来丰富输出的有关提到的实体的信息，而这目前是在生成的翻译上进行的。鉴于直接语音翻译（ST）模型的最近有希望的结果和级联系统的已知缺陷（误差传播和额外延迟），本文提出了多任务模型，共同执行ST和NER，并将它们与级联基线进行了比较。实验结果表明，我们的模型在NER任务上显著优于级联模型（0.4-1.0 F1），翻译质量没有降低，并且与纯ST模型相同的计算效率。

    Modern automatic translation systems aim at place the human at the center by providing contextual support and knowledge. In this context, a critical task is enriching the output with information regarding the mentioned entities, which is currently achieved processing the generated translation with named entity recognition (NER) and entity linking systems. In light of the recent promising results shown by direct speech translation (ST) models and the known weaknesses of cascades (error propagation and additional latency), in this paper we propose multitask models that jointly perform ST and NER, and compare them with a cascade baseline. The experimental results show that our models significantly outperform the cascade on the NER task (by 0.4-1.0 F1), without degradation in terms of translation quality, and with the same computational efficiency of a plain direct ST model.
    
[^98]: 基于提议器和回归器的端到端实体检测方法

    End-to-End Entity Detection with Proposer and Regressor. (arXiv:2210.10260v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10260](http://arxiv.org/abs/2210.10260)

    该论文提出了一种基于提议器和回归器的端到端实体检测方法，通过利用特征金字塔网络生成高质量的实体提议，并对提议进行精细调整以生成最终的预测结果。该模型具有查询语义丰富、实体定位精度高、模型训练容易等优点，还引入了空间调制变压器来增强内部关系的建模能力。实验结果表明，该方法显著优于现有的最先进方法。

    

    命名实体识别是自然语言处理中的传统任务。特别是，由于嵌套场景的普遍存在，嵌套实体识别受到广泛关注。最近的研究将目标检测中的集合预测被转移应用于应对实体嵌套，但是这些方法的问题在于需要手动创建查询向量，无法适应上下文中丰富的语义信息。本文提出了一种基于提议器和回归器的端到端实体检测方法来解决这些问题。首先，提议器利用特征金字塔网络生成高质量的实体提议。然后，回归器对提议进行精细调整以生成最终的预测结果。该模型采用了仅编码器架构，因此具有查询语义丰富、实体定位精度高、模型训练容易等优点。此外，我们引入了空间调制变压器来增强模型对不同实体之间内部关系的建模能力。在两个基准数据集上的实验结果表明，我们的模型显著优于现有的最先进方法。

    Named entity recognition is a traditional task in natural language processing. In particular, nested entity recognition receives extensive attention for the widespread existence of the nesting scenario. The latest research migrates the well-established paradigm of set prediction in object detection to cope with entity nesting. However, the manual creation of query vectors, which fail to adapt to the rich semantic information in the context, limits these approaches. An end-to-end entity detection approach with proposer and regressor is presented in this paper to tackle the issues. First, the proposer utilizes the feature pyramid network to generate high-quality entity proposals. Then, the regressor refines the proposals for generating the final prediction. The model adopts encoder-only architecture and thus obtains the advantages of the richness of query semantics, high precision of entity localization, and easiness of model training. Moreover, we introduce the novel spatially modulated
    
[^99]: DICTDIS：基于词典约束的神经机器翻译消歧方法对 NMT 的改进

    DICTDIS: Dictionary Constrained Disambiguation for Improved NMT. (arXiv:2210.06996v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06996](http://arxiv.org/abs/2210.06996)

    DICTDIS是一种新颖有词典约束的NMT系统，其利用多个字典候选项进行训练，实现了从多义词中消除翻译歧义的目的，提高了翻译质量。

    

    领域特定的神经机器翻译系统（例如教育应用程序）在多语言社会中帮助使信息对一组多样化的用户可访问是具有社会意义的。这种 NMT 系统应该具有词汇约束并从领域特定的词典中汲取。由于单词的多义性，词典中可能会为源单词或短语呈现多个候选翻译。这时，NMT 模型需要选择与语境最相关的候选翻译。先前的工作主要忽略了这个问题，而侧重于单个候选约束设置，其中目标词或短语被单个约束替换。在本文中，我们提出了一种名为DICTDIS的词典约束 NMT 系统，该系统消除了从字典中得出的多个候选翻译的歧义。我们通过将训练数据与多个字典候选项进行增量来实现这一点，从而在训练期间积极鼓励消除歧义。

    Domain-specific neural machine translation (NMT) systems (\eg, in educational applications) are socially significant with the potential to help make information accessible to a diverse set of users in multilingual societies. It is desirable that such NMT systems be lexically constrained and draw from domain-specific dictionaries. Dictionaries could present multiple candidate translations for a source word/phrase due to the polysemous nature of words. The onus is then on the NMT model to choose the contextually most appropriate candidate. Prior work has largely ignored this problem and focused on the single candidate constraint setting wherein the target word or phrase is replaced by a single constraint. In this work we present \dictdis, a lexically constrained NMT system that disambiguates between multiple candidate translations derived from dictionaries. We achieve this by augmenting training data with multiple dictionary candidates to actively encourage disambiguation during training
    
[^100]: 基于提示的少样本简历信息提取方法

    A Few-shot Approach to Resume Information Extraction via Prompts. (arXiv:2209.09450v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.09450](http://arxiv.org/abs/2209.09450)

    本文提出了一种基于提示的少样本简历信息提取方法，使用手动创建的模板和语言表述，改善了现有方法。他们的MKV方法解决了样本失衡问题，产生了更有效，更鲁棒的模板和语言表述器，为简历提取的定制提示学习方法提供了价值。

    

    在文本分类任务上，提示学习的微调性能引起了自然语言处理（NLP）社区的关注。本文将其应用于简历信息提取，并改进了现有的方法。我们创建了适用于简历文本的手动模板和语言表述，并比较了掩蔽式语言模型（MLM）和序列到序列提示语言模型（Seq2Seq PLMs）的性能。此外，我们增强了知识性提示微调（Knowledgeable Prompt-tuning）的语言表述设计，为跨NLP任务的提示模板设计做出了贡献。我们提出了“手动知识语言表述器”（MKV），用于构建特定应用程序的语言表述器的规则。我们的测试表明，MKV规则产生的模板和语言表述器比现有方法更有效和鲁棒。我们的MKV方法解决了样本失衡的问题，超越了当前自动提示方法。本研究强调了为简历提取量身定制的提示学习的价值，并强调了定制模板和语言表述器的重要性。

    Prompt learning's fine-tune performance on text classification tasks has attracted the NLP community. This paper applies it to resume information extraction, improving existing methods for this task. We created manual templates and verbalizers tailored to resume texts and compared the performance of Masked Language Model (MLM) and Seq2Seq PLMs. Also, we enhanced the verbalizer design for Knowledgeable Prompt-tuning, contributing to prompt template design across NLP tasks. We present the Manual Knowledgeable Verbalizer (MKV), a rule for constructing verbalizers for specific applications. Our tests show that MKV rules yield more effective, robust templates and verbalizers than existing methods. Our MKV approach resolved sample imbalance, surpassing current automatic prompt methods. This study underscores the value of tailored prompt learning for resume extraction, stressing the importance of custom-designed templates and verbalizers.
    
[^101]: 大语言模型中用心理学启发的思维链触发识别隐含变量和推理关系进行隐喻理解

    Psychologically-informed chain-of-thought prompts for metaphor understanding in large language models. (arXiv:2209.08141v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.08141](http://arxiv.org/abs/2209.08141)

    本文介绍了一种在大语言模型中使用心理学引导思维的方法来增强隐喻理解的性能。这种方法使用了隐含变量和关系来选择正确的释义。

    

    语言理解的概率模型是研究人们语言使用的有价值的工具，但它们需要手动设计。相比之下，大语言模型（LLMs）是用跨领域的文本进行训练的，但它们缺乏概率模型的结构和可解释性。本文采用思维链触发方式来将概率模型中的结构引入LLMs中，以隐喻理解为例来探究这一方法。我们的思维链触发方式导致语言模型推断隐含变量，并思考它们之间的关系，以选择适当的隐喻释义。所选择的隐含变量和关系都基于认知心理学中的隐喻理解理论。我们将这些提示应用于GPT-3的两个最大版本，并显示它们可以提高释义选择任务的性能。

    Probabilistic models of language understanding are valuable tools for investigating human language use. However, they need to be hand-designed for a particular domain. In contrast, large language models (LLMs) are trained on text that spans a wide array of domains, but they lack the structure and interpretability of probabilistic models. In this paper, we use chain-of-thought prompts to introduce structures from probabilistic models into LLMs. We explore this approach in the case of metaphor understanding. Our chain-of-thought prompts lead language models to infer latent variables and reason about their relationships in order to choose appropriate paraphrases for metaphors. The latent variables and relationships chosen are informed by theories of metaphor understanding from cognitive psychology. We apply these prompts to the two largest versions of GPT-3 and show that they can improve performance in a paraphrase selection task.
    
[^102]: ToKen：少样本仇恨言论检测的任务拆解和知识注入

    ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection. (arXiv:2205.12495v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12495](http://arxiv.org/abs/2205.12495)

    本研究提出了一种将仇恨言论检测任务拆分为部分并注入推理数据集知识的方法，相较于先前的方法，具有更好的泛化性能，在16个样本的情况下可达到17.83％的绝对增益。

    

    仇恨言论检测是一个复杂的问题，它依赖于常识推理、对刻板印象的了解以及对不同文化背景下社交细微差别的理解。而且很难收集大规模的标注好的仇恨言论数据集。在本研究中，我们将这个问题视为少样本学习任务，并展示了通过将任务分解为其“构成”部分，可以取得显著的进展。此外，我们发现从推理数据集（例如Atomic2020）中注入知识可以进一步提高性能。此外，我们观察到训练模型可以泛化到分布外的数据集，显示了任务拆解和知识注入相对于先前使用的方法的优越性。具体而言，在16个样本的情况下，我们的方法在基线上表现出17.83％的绝对增益。

    Hate speech detection is complex; it relies on commonsense reasoning, knowledge of stereotypes, and an understanding of social nuance that differs from one culture to the next. It is also difficult to collect a large-scale hate speech annotated dataset. In this work, we frame this problem as a few-shot learning task, and show significant gains with decomposing the task into its "constituent" parts. In addition, we see that infusing knowledge from reasoning datasets (e.g. Atomic2020) improves the performance even further. Moreover, we observe that the trained models generalize to out-of-distribution datasets, showing the superiority of task decomposition and knowledge infusion compared to previously used methods. Concretely, our method outperforms the baseline by 17.83% absolute gain in the 16-shot case.
    
[^103]: CombLM: 通过小型微调模型调整黑盒语言模型

    CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models. (arXiv:2205.12213v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12213](http://arxiv.org/abs/2205.12213)

    本论文提出了一种 CombLM 方法，通过小型微调模型调整大型黑盒语言模型以适应新领域和任务，且不需要访问它们的权重或中间激活。实验证明在多个领域和下游任务中，性能得到提高。

    

    传统上，将语言模型适应新任务和域的方法通常假设对模型有白盒访问，并通过修改其参数进行操作。但这与该领域的最高质量模型仅通过推理API作为黑盒可用的最近趋势不兼容。即使可用模型权重，对大型语言模型进行微调的计算成本也可能对大多数研究人员来说是禁止的。在本研究中，我们提出了一种轻量级的方法，用于调整大型语言模型以适应新领域和任务，假设没有访问它们的权重或中间激活的权限。我们的方法通过在小验证集上学习的小型网络，在概率级别上微调小型白盒LM，并将其与大型黑盒LM结合起来。我们通过将大型LM（OPT-30B）适应多个领域和下游任务（机器翻译），在所有情况下观察到性能的提高，最高可达9\%，同时使用领域专家23倍。

    Methods for adapting language models (LMs) to new tasks and domains have traditionally assumed white-box access to the model, and work by modifying its parameters. However, this is incompatible with a recent trend in the field, where the highest quality models are only available as black-boxes through inference APIs. Even when the model weights are available, the computational cost of fine-tuning large LMs can be prohibitive for most practitioners. In this work, we present a lightweight method for adapting large LMs to new domains and tasks, assuming no access to their weights or intermediate activations. Our approach fine-tunes a small white-box LM and combines it with the large black-box LM at the probability level through a small network, learned on a small validation set. We validate our approach by adapting a large LM (OPT-30B) to several domains and a downstream task (machine translation), observing improved performance in all cases, of up to 9\%, while using a domain expert 23x 
    
[^104]: CORAL：基于上下文的生成对话模型的响应可检索性损失函数

    CORAL: Contextual Response Retrievability Loss Function for Training Dialog Generation Models. (arXiv:2205.10558v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.10558](http://arxiv.org/abs/2205.10558)

    本研究提出了一种基于强化学习视图的损失函数CORAL，用于评估生成对话模型的响应质量，该损失函数同时考虑到了上下文和生成的响应。

    

    在自然语言处理领域中，使用交叉熵（CE）损失函数可以有效地解决许多任务。然而，生成对话的任务对CE损失提出了独特的挑战。这是因为CE损失假定对于任何给定的输入，唯一可能的输出是训练数据集中作为基本真实的输出。但是，在生成对话中，可以有多个有效的响应（对于给定的上下文），它们不仅具有不同的表面形式，而且可以是语义上不同的。此外，对于对话生成任务的CE损失计算不考虑输入上下文，并且基于响应对其进行评分，而不考虑上下文。要对生成的响应进行类似关联性、吸引力等品质的评分，损失函数应该依赖于上下文和生成的响应。本文提出了基于强化学习（RL）视图的CORAL，这是一种新颖的损失函数，用于解决这些限制。

    In the field of Natural Language Processing, there are many tasks that can be tackled effectively using the cross-entropy (CE) loss function. However, the task of dialog generation poses unique challenges for CE loss. This is because CE loss assumes that, for any given input, the only possible output is the one available as the ground truth in the training dataset. But, in dialog generation, there can be multiple valid responses (for a given context) that not only have different surface forms but can also be semantically different. Furthermore, CE loss computation for the dialog generation task does not take the input context into consideration and, hence, it grades the response irrespective of the context. To grade the generated response for qualities like relevance, engagingness, etc., the loss function should depend on both the context and the generated response. To address these limitations, this paper proposes CORAL, a novel loss function based on a reinforcement learning (RL) vie
    
[^105]: 低资源情况下使用跨语言多说话人TTS和跨语言语音转换进行ASR数据增广

    ASR data augmentation in low-resource settings using cross-lingual multi-speaker TTS and cross-lingual voice conversion. (arXiv:2204.00618v5 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2204.00618](http://arxiv.org/abs/2204.00618)

    本文探索了一种在低资源情况下使用跨语言多说话人TTS和跨语言语音转换进行ASR数据增广的方法，其可以通过只使用一个说话人改善ASR系统，并且能够缩小ASR模型间使用人工和合成语音训练的差距，同时使用单一真实说话人的数据增广方法同样能够获得有希望的ASR训练结果。

    

    我们研究了跨语言多说话人语音合成和跨语言语音转换在低/中资源情境下自动语音识别（ASR）系统数据增广的应用。通过大量实验，我们展示了只使用一个目标语言说话人在模型训练过程中应用语音合成和语音转换可以改善ASR系统。我们还展示了相比使用多说话人的人工和合成语音训练ASR模型间的差距得以缩小。最后，我们展示了只使用目标语言的单一真实说话人的数据增广方法可以获得有希望的ASR训练结果。

    We explore cross-lingual multi-speaker speech synthesis and cross-lingual voice conversion applied to data augmentation for automatic speech recognition (ASR) systems in low/medium-resource scenarios. Through extensive experiments, we show that our approach permits the application of speech synthesis and voice conversion to improve ASR systems using only one target-language speaker during model training. We also managed to close the gap between ASR models trained with synthesized versus human speech compared to other works that use many speakers. Finally, we show that it is possible to obtain promising ASR training results with our data augmentation method using only a single real speaker in a target language.
    
[^106]: PoNet：长序列中高效Token混合的池化网络

    PoNet: Pooling Network for Efficient Token Mixing in Long Sequences. (arXiv:2110.02442v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.02442](http://arxiv.org/abs/2110.02442)

    PoNet是一种池化网络，可用于长序列中的token混合，其具有线性复杂度，并可以比Transformer更好地处理长序列。该方法提供了一种高效且有效的自注意替代方案。

    

    基于Transformer的模型在各种NLP、视觉和语音任务中取得了巨大的成功。然而，Transformer的核心自注意机制和序列长度的平方时间和内存复杂度，阻碍了Transformer-based模型在处理长序列时的应用。为了缓解这个问题，有许多方法被提出，例如稀疏注意机制、低秩矩阵近似和可扩展的核函数，以及替代自注意的token混合。我们提出了一种用于长序列中token混合的新型池化网络(PoNet)，其复杂度为线性。我们设计了多粒度池化和池化融合来捕捉不同级别的上下文信息，并将其与token的交互结合起来。在长序列基准测试中，PoNet显著优于Transformer，并实现了有竞争力的准确性，而且在所有在GPU上测量的序列长度上，它仅比最快的模型FNet稍慢。我们还能可视化PoNet的注意力图，以展示它可以有效地混合具有不同上下文信息的token。我们的方法为处理长序列提供了一种高效且有效的自注意替代方案。

    Transformer-based models have achieved great success in various NLP, vision, and speech tasks. However, the core of Transformer, the self-attention mechanism, has a quadratic time and memory complexity with respect to the sequence length, which hinders applications of Transformer-based models to long sequences. Many approaches have been proposed to mitigate this problem, such as sparse attention mechanisms, low-rank matrix approximations and scalable kernels, and token mixing alternatives to self-attention. We propose a novel Pooling Network (PoNet) for token mixing in long sequences with linear complexity. We design multi-granularity pooling and pooling fusion to capture different levels of contextual information and combine their interactions with tokens. On the Long Range Arena benchmark, PoNet significantly outperforms Transformer and achieves competitive accuracy, while being only slightly slower than the fastest model, FNet, across all sequence lengths measured on GPUs. We also c
    
[^107]: 可微分决策树通过自然语言规范RL策略

    Natural Language Specification of Reinforcement Learning Policies through Differentiable Decision Trees. (arXiv:2101.07140v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2101.07140](http://arxiv.org/abs/2101.07140)

    本文提出了一个新的可微分决策树框架，允许人们通过自然语言指定初始行为模型，并将其转换为词汇决策树，为机器人的强化学习策略提供指导。

    

    本文提出了一种新的人工智能政策规范过程，可以使人类与机器人共同启动强化学习策略。该过程包含两个步骤：政策规范与政策优化。我们开发了一个新的协作框架，允许人通过非结构化自然语言指定初始行为模型，并将其转换为词汇决策树来启动和解释一个自主代理的行为。

    Human-AI policy specification is a novel procedure we define in which humans can collaboratively warm-start a robot's reinforcement learning policy. This procedure is comprised of two steps; (1) Policy Specification, i.e. humans specifying the behavior they would like their companion robot to accomplish, and (2) Policy Optimization, i.e. the robot applying reinforcement learning to improve the initial policy. Existing approaches to enabling collaborative policy specification are often unintelligible black-box methods, and are not catered towards making the autonomous system accessible to a novice end-user. In this paper, we develop a novel collaborative framework to allow humans to initialize and interpret an autonomous agent's behavior. Through our framework, we enable humans to specify an initial behavior model via unstructured, natural language (NL), which we convert to lexical decision trees. Next, we leverage these translated specifications, to warm-start reinforcement learning an
    

