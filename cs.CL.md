# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [IDAS: Intent Discovery with Abstractive Summarization.](http://arxiv.org/abs/2305.19783) | 本研究提出了一种利用摘要性总结对话进行聚类的 IDAS 方法，它可以在无监督环境下胜过最先进的竞争方法，并且在 Banking 和 Stack Overflow 数据集上只使用 5% 的标记数据即可获得竞争性的性能。 |
| [^2] | [Attention-Based Methods For Audio Question Answering.](http://arxiv.org/abs/2305.19769) | 本文提出了一种基于自我注意力和交叉注意力的神经网络体系结构，用于音频问答任务。实验结果表明，相较于参考方法，该方法在Clotho-AQA数据集上的表现有明显提高。 |
| [^3] | [Recursive Metropolis-Hastings Naming Game: Symbol Emergence in a Multi-agent System based on Probabilistic Generative Models.](http://arxiv.org/abs/2305.19761) | 本文提出了一种递归 Metropolis-Hastings 命名游戏 (RMHNG) 模型，用于多智能体系统中的符号出现，具有较快的收敛速度和鲁棒性，并在多个场景下进行了验证。 |
| [^4] | [Simple yet Effective Code-Switching Language Identification with Multitask Pre-Training and Transfer Learning.](http://arxiv.org/abs/2305.19759) | 本文提出了两个新方法来提高在混合语音数据上的语言识别精度，包括使用Residual CNN+GRU模型和多任务预训练方法。由于语言混合的低资源性，我们还使用了单语语料库进行银数据创建和上采样。 |
| [^5] | [Automatic Discrimination of Human and Neural Machine Translation in Multilingual Scenarios.](http://arxiv.org/abs/2305.19757) | 本文研究在多语言环境下，如何自动区分人类翻译和机器翻译。在单一源语言的平行数据训练分类器时，我们可以很好地执行来自不同源语言的英语翻译的判别。将源文本加入多语言分类器的输入可以提高分类器的准确性和鲁棒性，使用不同源语言的训练数据往往提高单语和多语言分类器的准确性。双语分类器不可行。 |
| [^6] | [Sentence Simplification Using Paraphrase Corpus for Initialization.](http://arxiv.org/abs/2305.19754) | 本文提出了两种使用释义语料库对神经句子简化方法进行初始化的策略，从而降低对平行语料库的依赖，并在WikiLarge数据上获得了显着的改进。 |
| [^7] | [Text-to-Speech Pipeline for Swiss German -- A comparison.](http://arxiv.org/abs/2305.19750) | 本研究通过比较不同的文本到语音（TTS）模型，最终实现了对瑞士德语方言进行高质量语音合成，并介绍了一项新的TTS模型评估方法。 |
| [^8] | [UKP-SQuARE: An Interactive Tool for Teaching Question Answering.](http://arxiv.org/abs/2305.19748) | 这篇论文介绍了UKP-SQuARE作为一个用于教授问答技术的交互式工具，学生可以通过其在不同角度了解各种QA模型，并借此获得理论概念和问题解决技能。 |
| [^9] | [Analyzing Text Representations by Measuring Task Alignment.](http://arxiv.org/abs/2305.19747) | 文章研究了文本表示对于分类任务表现的影响，并提出了任务对齐得分方法来度量对齐性，验证了任务对齐性对于表示的分类性能有决定性的影响。 |
| [^10] | [Knowledge Base Question Answering for Space Debris Queries.](http://arxiv.org/abs/2305.19734) | 本文介绍了一个基于知识库的系统，可以回答复杂自然语言的查询，支持工程师访问太空碎片环境的知识库中的信息。 |
| [^11] | [XPhoneBERT: A Pre-trained Multilingual Model for Phoneme Representations for Text-to-Speech.](http://arxiv.org/abs/2305.19709) | XPhoneBERT是第一个用于文本转语音的预训练多语言语音单位表示模型，通过其作为输入语音编码器，可以显著提高TTS模型的性能和语音质量。 |
| [^12] | [Building Extractive Question Answering System to Support Human-AI Health Coaching Model for Sleep Domain.](http://arxiv.org/abs/2305.19707) | 本文提出了一个人工智能健康辅导模型，包含一个提取式 QA 系统，通过对睡眠相关数据集进行微调，通过数据中心化框架提高系统性能。 在真实世界问题的人工评估中表现出色，在随机对照试验的试点测试中验证将其集成到人工智能健康辅导模型中。 |
| [^13] | [Assessing Word Importance Using Models Trained for Semantic Tasks.](http://arxiv.org/abs/2305.19689) | 本文介绍了一种从解决语义任务的模型中推导出单词重要性的方法，并证明其稳健性，可以在无需显式单词重要性标签的情况下识别句子中重要的单词。 |
| [^14] | [Unveiling Cross Modality Bias in Visual Question Answering: A Causal View with Possible Worlds VQA.](http://arxiv.org/abs/2305.19664) | 为了解决VQA系统因视觉和语言的混淆效应而导致的双重偏差问题，本文提出了一个反事实的推理方法。该方法可以同时并高效地减少视觉和语言偏见。 |
| [^15] | [Adverbs, Surprisingly.](http://arxiv.org/abs/2305.19650) | 本文发现计算语言学中副词的相关分析存在系统性空缺，在框架语义学（如FrameNet）的帮助下提出了一种有前途的副词分析方法。 |
| [^16] | [Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems.](http://arxiv.org/abs/2305.19607) | 本文针对文本分类系统提出了一种对抗性干净标签攻击，并提高了攻击成功率，比起标签翻转攻击更难以防御。同时，研究了多种防御策略对两种攻击的有效性。 |
| [^17] | [What does the Failure to Reason with "Respectively" in Zero/Few-Shot Settings Tell Us about Language Models?.](http://arxiv.org/abs/2305.19597) | 本文研究发现，语言模型在零/少样本环境下难以理解“respectively”的各种读法，需要更长时间的训练和依赖常识推理，仍落后于人类。 |
| [^18] | [SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT.](http://arxiv.org/abs/2305.19589) | 该论文利用BERT模型建模了第二语言习得，并构建了一个多语言数据集以研究母语儿童指导语言（CDS）对英文语言习得的积极和消极转移现象。 |
| [^19] | [LAIT: Efficient Multi-Segment Encoding in Transformers with Layer-Adjustable Interaction.](http://arxiv.org/abs/2305.19585) | LAIT是一种通过多段编码实现跨段注意力的新框架，使用Layer-Adjustable Interactions技术实现分段编码和逐层交互，提高了模型的效率和精度，并极大地简化了模型设计的复杂度。 |
| [^20] | [The Tag-Team Approach: Leveraging CLS and Language Tagging for Enhancing Multilingual ASR.](http://arxiv.org/abs/2305.19584) | 通过将相似的声音映射到常见的标签，利用CLS和语言标注相结合来提高多语言ASR模型的性能。 |
| [^21] | [DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code Collaborated with Mixer.](http://arxiv.org/abs/2305.19567) | 本文提出了一种基于离散码和混合器相协作的端到端表现力TTS，它采用新的输入表示和简单的架构来实现改进的韵律建模，证明了其有效性。 |
| [^22] | [Zero-Shot Automatic Pronunciation Assessment.](http://arxiv.org/abs/2305.19563) | 本文提出了一种基于预训练声学模型的零样本自动发音评估方法，该方法不需要标注数据，使用掩码模块破坏语音输入，应用k均值聚类获得标记序列并使用评分模块测量错误恢复标记的数量，在实验中取得了与监督回归基线相当的性能以及优于非回归基线的结果。 |
| [^23] | [Large Language Models Are Not Abstract Reasoners.](http://arxiv.org/abs/2305.19555) | 本文通过对最先进的大型语言模型进行抽象推理任务评估，发现它们在这方面的表现十分有限，揭示了其在推理方面的局限性。 |
| [^24] | [Accurate and Structured Pruning for Efficient Automatic Speech Recognition.](http://arxiv.org/abs/2305.19549) | 本文提出了一种新型压缩策略，结合结构化剪枝和知识蒸馏，以减少Conformer模型的模型大小和推理成本，同时保持较高的识别性能，并在LibriSpeech基准测试中优于所有剪枝基准线。 |
| [^25] | [Fine-grained Text Style Transfer with Diffusion-Based Language Models.](http://arxiv.org/abs/2305.19512) | 本文提出了一种基于扩散式语言模型的细粒度文本风格转换方法，在不依赖外部信息的情况下取得了比之前利用预训练权重、嵌入和外部语法分析器更好的效果，表明扩散概率模型在文本生成领域具有广泛的应用前景。 |
| [^26] | [Exploring Lottery Prompts for Pre-trained Language Models.](http://arxiv.org/abs/2305.19500) | 本文通过对实例级提示及其普适性的探讨，发现了一些强大且具备可区分语言特征的抽奖提示，通过提示集成方法可将其推广到未见数据集上，为替代传统微调方法提供了更有效的选择。 |
| [^27] | [Towards Flow Graph Prediction of Open-Domain Procedural Texts.](http://arxiv.org/abs/2305.19497) | 本文提出了一种针对开放领域操作文本的流程图预测框架，使用领域自适应技术，实现了比单独在烹饪或目标领域训练的模型表现更好。 |
| [^28] | [PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning.](http://arxiv.org/abs/2305.19472) | PlaSma提出了一种使用小型语言模型进行过程知识和计划能力的新方法， |
| [^29] | [The Impact of Positional Encoding on Length Generalization in Transformers.](http://arxiv.org/abs/2305.19466) | 本文通过实证研究 Transformer 模型中位置编码对于长度推广的影响，结果表明常用的位置编码方法并不适合用于下游任务的长度推广，并且使用位置编码甚至可能会损害长度推广的能力。 |
| [^30] | [ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning.](http://arxiv.org/abs/2305.19426) | 本文提出了Scoped Negation NLI (ScoNe-NLI)基准测试以评估微调和上下文学习策略对语言模型中否定推理表现的影响。研究结果表明，进行许多次微调后，RoBERTa和DeBERTa模型可以成功解决ScoNe-NLI。对于上下文学习方面，大多数提示策略都无法成功，但在嵌入否定推理的短故事的句子完成测试中，InstructGPT是成功的。 |
| [^31] | [Hierarchical Multi-Instance Multi-Label Learning for Detecting Propaganda Techniques.](http://arxiv.org/abs/2305.19419) | 本文提出了一种可以同时对所有段落进行宣传技术分类的多实例多标签（MIML）学习方法，并为模型引入了层次性标签依赖关系，许多现有的方法都忽略了这一点。 |
| [^32] | [Examining risks of racial biases in NLP tools for child protective services.](http://arxiv.org/abs/2305.19409) | 本研究调查了儿童保护服务中自然语言处理模型存在的种族偏见问题，并发现了NER模型一致存在算法不公平的情况，同时可能出现指代消解和风险预测中算法不公平的情况。 |
| [^33] | [Contextual Vision Transformers for Robust Representation Learning.](http://arxiv.org/abs/2305.19402) | 上下文视觉变换器(ContextViT)用于生成图像的鲁棒特征表示，引入了一个额外的上下文令牌，可以解释掉特定于组的协变量结构，同时保持跨组共享的核心视觉特征，能够在监督微调、半监督学习以及主动学习等方面得到应用。 |
| [^34] | [Resource-Efficient Fine-Tuning Strategies for Automatic MOS Prediction in Text-to-Speech for Low-Resource Languages.](http://arxiv.org/abs/2305.19396) | 本文通过在低资源语言 West Frisian 上的测试发现，在预训练 BVCC 数据集后，微调 SOMOS 数据集能够得到最佳精度。使用超过总数据的 30% 并不能显著提高精度。使用来自单个听众的数据进行微调的实验表明，这种方法有望提高系统级精度，支持单参与者试验的可行性。 |
| [^35] | [DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling.](http://arxiv.org/abs/2305.19395) | DyGen是一个动态增强的生成模型，使用嵌入空间中的动态模式可以改善从噪声标签中学习的精度，同时使用共规正则化机制来最小化潜在噪声标签和先验的影响，展示了最先进的性能。 |
| [^36] | [Quantum Natural Language Processing based Sentiment Analysis using lambeq Toolkit.](http://arxiv.org/abs/2305.19383) | 本文在情感分析中第一次应用了量子自然语言处理（QNLP），通过利用lambeq QNLP工具包和剑桥量子（Quantinuum）的$t|ket>$，在三种模拟和噪声量子设备上取得了完美测试集准确性和相当的准确性。 |
| [^37] | [Mining Themes in Clinical Notes to Identify Phenotypes and to Predict Length of Stay in Patients admitted with Heart Failure.](http://arxiv.org/abs/2305.19373) | 本文采用主题建模技术对1200例心力衰竭患者的诊断编码和程序报告中存在的主题进行识别，旨在从中识别心力衰竭的临床表型并预测病人住院时间。 |
| [^38] | [Blockwise Parallel Transformer for Long Context Large Models.](http://arxiv.org/abs/2305.19370) | 本文提出了块级并行Transformer方法，以最小化内存成本，能够处理长序列，并且可以处理比先前的内存高效方法更长32倍的训练序列。 |
| [^39] | [Stable Anisotropic Regularization.](http://arxiv.org/abs/2305.19358) | 本文提出了一种新颖的正则化方法I-STAR，可以增加模型的稳定性，提高性能，并改善自然语言处理中的组合表示问题。 |
| [^40] | [infoVerse: A Universal Framework for Dataset Characterization with Multidimensional Meta-information.](http://arxiv.org/abs/2305.19344) | 本文介绍了一种通用的数据集特征化框架infoVerse，通过结合各种模型驱动的元信息提供了一个新的特征空间，能够有效地捕捉数据集的多维特征，有助于用户或模型确定哪些样本需要关注。 |
| [^41] | [Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses.](http://arxiv.org/abs/2305.19339) |  |
| [^42] | [Large language models improve Alzheimer's disease diagnosis using multi-modality data.](http://arxiv.org/abs/2305.19280) | 本研究使用大型语言模型提高对非影像数据的应用能力，并在ADNI数据集上实现了SOTA结果。 |
| [^43] | [Grammar Prompting for Domain-Specific Language Generation with Large Language Models.](http://arxiv.org/abs/2305.19234) | 本文提出了一种基于语法提示的方法，使用专用的语法来增强示例，为大型语言模型（LLM）在特定领域的语言生成任务中使用外部知识和特定约束条件进行上下文学习。 |
| [^44] | [Controlled Text Generation with Hidden Representation Transformations.](http://arxiv.org/abs/2305.19230) | 我们提出了CHRT，它是一种可控语言生成框架，通过学习表示转换来修改基础模型的隐藏表示从而获得属性控制。实验证明，CHRT在三个属性上表现均优于所有基线模型，同时最小化了在语言质量上的损失。 |
| [^45] | [Cross Encoding as Augmentation: Towards Effective Educational Text Classification.](http://arxiv.org/abs/2305.18977) | 本文提出了一种新颖的检索方法CEAA，将交叉编码作为数据增强方法应用在教育文本分类中，能够解决教育文本分类中的数据稀缺问题，有效提高分类精度。 |
| [^46] | [Scalable Performance Analysis for Vision-Language Models.](http://arxiv.org/abs/2305.18786) | 本文提出了一种可扩展的视觉语言基准测试方案，它可以利用已有的注释基准测试，并通过提取多种不同的特征来测量模型输出的相关性。实验结果发现，CLIP模型类似于词袋模型，在名词和动词方面表现良好，但容易被具体词汇困扰。 |
| [^47] | [Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models.](http://arxiv.org/abs/2305.18703) | 本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。 |
| [^48] | [Practical PCG Through Large Language Models.](http://arxiv.org/abs/2305.18243) | 本研究介绍了如何利用语言模型生成游戏房间，在仅有少量数据的情况下，可以生成多达37%的可玩新颖关卡，该技术有助于解决包含许多局部和全局约束的PCG问题。 |
| [^49] | [The Curse of Recursion: Training on Generated Data Makes Models Forget.](http://arxiv.org/abs/2305.17493) | 使用生成数据进行训练会导致模型不可逆的缺陷并且使得原始内容分布的尾部消失，这种效应称为模型折叠。我们证明了这种现象在所有学习生成模型中都存在，必须认真对待。 |
| [^50] | [A Framework For Refining Text Classification and Object Recognition from Academic Articles.](http://arxiv.org/abs/2305.17401) | 本文提出了一种结合基于规则的方法和机器学习的框架，旨在解决从学术论文中提炼文本分类和对象识别的问题。 |
| [^51] | [Honey, I Shrunk the Language: Language Model Behavior at Reduced Scale.](http://arxiv.org/abs/2305.17266) | 本文研究了小规模语言模型的训练效果，并展示了掩码语言建模目标的预训练对性能的提高作用。同时，该研究还发现了计算成本与模型效果之间的相关性。 |
| [^52] | [On the Computational Power of Decoder-Only Transformer Language Models.](http://arxiv.org/abs/2305.17026) | 本篇论文研究了解码器Transformer语言模型的计算普适性，表明即使只有单层和单注意力头，仍然具有图灵完备性，其中单词嵌入的稀疏性/可压缩性是必要条件。 |
| [^53] | [Do GPTs Produce Less Literal Translations?.](http://arxiv.org/abs/2305.16806) | 本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。 |
| [^54] | [AdaPlanner: Adaptive Planning from Feedback with Language Models.](http://arxiv.org/abs/2305.16653) | LLM代理可以通过Adaplanner自适应改进自己的计划以应对环境反馈，为此提出计划内外的改进策略以及代码风格的LLM提示结构和技能发现机制。 |
| [^55] | [Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion.](http://arxiv.org/abs/2305.14652) | 本文提出了一种基于去噪瓶颈和最大化互信息的视频多模态融合模型（DBF），该模型可以细粒度地过滤掉冗余和噪声信息，同时保留不同模态中的关键信息，并在多语言视频分类任务中表现出显著优越性。 |
| [^56] | [On Bias and Fairness in NLP: How to have a fairer text classification?.](http://arxiv.org/abs/2305.12829) | 本文从上游偏见、样本偏见和过度放大偏见三方面分析了NLP模型中的偏见如何影响文本分类的公平性，并针对过度放大偏见通过微调语言模型达到公平分类效果。提出了构建公正文本分类模型的实用指南。 |
| [^57] | [Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech Pre-Training for Adaptation to Unseen Languages.](http://arxiv.org/abs/2305.12606) | 本研究比较了自监督和弱监督多语言语音预训练在适应未知语言方面的效果，发现预训练期间每种语言及其语系出现的小时数可以预测模型的比较结果。 |
| [^58] | [QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set Operations.](http://arxiv.org/abs/2305.11694) | 该研究构建了一个名为QUEST的检索数据集，其中含有3357个自然语言查询，这些查询使用隐式集合操作来满足有选择性的信息需求，这个数据集要求模型匹配查询中提到的条件，并正确执行集合操作。 |
| [^59] | [On the Hidden Mystery of OCR in Large Multimodal Models.](http://arxiv.org/abs/2305.07895) | 本研究全面评估了现有大型多模态模型在文本相关的视觉任务中的表现，结果显示这些模型虽然在语义理解方面表现优异，但对单个字符形状的感知有限，对图像的细粒度特征检测能力也不足，不能与传统领域特定方法相匹配，并仍需进一步探索它们在OCR中的表现。 |
| [^60] | [The Role of Global and Local Context in Named Entity Recognition.](http://arxiv.org/abs/2305.03132) | 研究者探讨了全局文档上下文与局部上下文在命名实体识别中的作用，发现正确检索全局文档上下文对提高性能至关重要。 |
| [^61] | [On the nonlinear correlation of ML performance between data subpopulations.](http://arxiv.org/abs/2305.02995) | 在不同数据子群体间，机器学习模型的内部准确性和外部准确性之间的相关性是非线性的，呈现出“月亮形”的相关性。 |
| [^62] | [Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System.](http://arxiv.org/abs/2305.02468) | 本文提出了一种端到端任务导向对话系统，通过在预训练网络的固定层后添加少量参数的任务优化适配器来独立地学习每个任务，并通过强化学习提高DST和NLG模块的性能。 |
| [^63] | [Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling.](http://arxiv.org/abs/2304.01373) | 本文介绍了一套名为 Pythia 的工具套件，包含 16 个大型语言模型，其大小从 70M 到 12B 参数不等。Pythia 可以帮助研究人员在多个领域开展研究，作者还提出了几个新的研究结果，在记忆、应用少量数据时的效果以及减少性别偏见等方面具有重要意义。 |
| [^64] | [Aligning a medium-size GPT model in English to a small closed domain in Spanish using reinforcement learning.](http://arxiv.org/abs/2303.17649) | 本文介绍了一种将英文GPT模型对齐到西班牙语的小封闭领域中的方法，该方法使用了奖励模型来改进答案的解码和生成，在问答任务中取得了良好的结果。 |
| [^65] | [cTBL: Augmenting Large Language Models for Conversational Tables.](http://arxiv.org/abs/2303.12024) | 本论文提出了一种称为cTBL的方法，可以从表格中检索信息，并生成具有检索信息支撑的对话响应，其中使用了转换器编码器嵌入进行浓密表检索，可以获得更好的性能。 |
| [^66] | [Exploring Partial Knowledge Base Inference in Biomedical Entity Linking.](http://arxiv.org/abs/2303.10330) | 本文探索了生物医学实体链接中的部分知识库推理问题，发现由于精度下降导致EL性能出现灾难性下降，而且EL范例无法处理无法链接的提及，提出了两种赎回方法来解决NIL问题。 |
| [^67] | [Query-Utterance Attention with Joint modeling for Query-Focused Meeting Summarization.](http://arxiv.org/abs/2303.04487) | 本文提出了一种基于查询-话语注意力和联合建模的查询感知框架，它使用密集检索模块计算话语级别与查询的相关性，并将标记级别的查询关联性和话语级别的查询关联性结合起来，实现生成一个更与查询相关的摘要。经过对两个基准数据集上的测试，表明该方法优于现有的QFMS模型。 |
| [^68] | [Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models.](http://arxiv.org/abs/2301.13826) | 该论文提出了一种基于注意力的文本到图像扩散模型的语义引导方法，名为参与兴奋，在推理时间内干预生成过程以改善生成图像的信实性和完整性，并解决了传统扩散模型在图像语义生成中可能存在的失灵现象。 |
| [^69] | [UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers.](http://arxiv.org/abs/2301.13741) | UPop是一种通用的视觉语言Transformer压缩框架，采用统一和渐进式剪枝方法，可自动分配剪枝比率，实现更高的压缩比率。 |
| [^70] | [Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases.](http://arxiv.org/abs/2301.12017) | 本文研究了在语言模型中采用INT4权重和激活量化的可行性，并开发了高度优化的W4A4编码器推断管道，支持不同的量化策略。使用W4A4可以实现模型在延迟方面的显著提高。 |
| [^71] | [Pre-training for Speech Translation: CTC Meets Optimal Transport.](http://arxiv.org/abs/2301.11716) | 本文提出了一种基于CTC和最优传输的语音翻译预训练方法，可以有效减小语音和文本模态之间的差距，提高最终的ST准确性。 |
| [^72] | [Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt Learning for Automatic Scoring in Science Education.](http://arxiv.org/abs/2301.08771) | 本研究提出了一种零样本学习自动评分的方法，利用预训练的语言模型配合匹配标本作为下一句预测技术，成功应用于科学教育领域的论证任务，极大地减少了训练成本和时间。 |
| [^73] | [Continual Contrastive Finetuning Improves Low-Resource Relation Extraction.](http://arxiv.org/abs/2212.10823) | 本文提出了一种使用连续对比微调的方法来改进低资源关系提取，通过使用一致的对比学习目标预训练和微调RE模型，以及多中心对比损失来允许一个关系形成多个聚类。实验结果表明该方法可以显着提高低资源情况和领域中的关系提取性能。 |
| [^74] | [ClarifyDelphi: Reinforced Clarification Questions with Defeasibility Rewards for Social and Moral Situations.](http://arxiv.org/abs/2212.10409) | ClarifyDelphi是一个交互式系统，能够针对社会或道德情境提出最有信息价值的问题，并通过奖励机制最大化回答问题时的道德判断分歧。 |
| [^75] | [Synthetic Pre-Training Tasks for Neural Machine Translation.](http://arxiv.org/abs/2212.09864) | 本文提出了一种使用合成任务和数据预训练神经机器翻译模型的方法，其可以缓解大规模抓取的语料库所导致的毒性、偏见和法律隐患，并证明了即使采用高度混淆或纯合成数据，预训练依然有效。 |
| [^76] | [Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages.](http://arxiv.org/abs/2212.09651) | 本文提出了跨语言检索增强提示(PARC)管道，在零-shot低资源语言上通过从高资源语言中检索出的语义上类似的句子来改善性能，表现明显优于 fine-tuning 基线，同时与高低资源语言之间的相似性以及低资源预训练数据的数量存在显著正相关关系。 |
| [^77] | [DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text Generation.](http://arxiv.org/abs/2212.08724) | DuNST是一种双重噪声自训练方法，用于半监督可控文本生成。该方法通过扰动生成的伪文本，将伪文本标记和无标签的伪标签结合使用，并且可以缓解先前学习到的空间的限制性泛化边界。 |
| [^78] | [Transformers learn in-context by gradient descent.](http://arxiv.org/abs/2212.07677) | 本文提出，训练Transformer模型应用于自回归目标问题时，与基于梯度的元学习的形式密切相关，通过梯度下降学习模型的“底层优化程序”的机制，在回归问题的领域中从机械的角度理解了Transformers模型中上下文学习的内部机制。 |
| [^79] | [MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets.](http://arxiv.org/abs/2211.07321) | 本文提出了一个新的自监督多任务学习框架MT4SSL，通过同时使用K均值算法作为离线目标提取器和没有梯度的教师网络作为在线目标提取器，取得了比以前更好的表现。同时，使用离线和在线目标提取器可以得到更好的收敛性，我们认为这是自监督语音模型上的多任务学习有前途的趋势。 |
| [^80] | [RARR: Researching and Revising What Language Models Say, Using Language Models.](http://arxiv.org/abs/2210.08726) | RARR是一个可以对不确定信息进行研究和修订的系统，它可以自动找到文本生成模型输出的归因并修正不支持的内容。 |
| [^81] | [Mention Annotations Alone Enable Efficient Domain Adaptation for Coreference Resolution.](http://arxiv.org/abs/2210.07602) | 论文提出一种仅使用提及注释的共指消解领域自适应方法，有效提高模型效果而不增加时间与成本。 |
| [^82] | [Are Sample-Efficient NLP Models More Robust?.](http://arxiv.org/abs/2210.06456) | 较低采样效率的NLP模型在特定情况下可能比较高采样效率的模型更为鲁棒，表明通用的提高采样效率方法不太可能改善自然语言处理中的OOD鲁棒性。 |
| [^83] | [Variational Open-Domain Question Answering.](http://arxiv.org/abs/2210.06345) | 本文介绍了变分开放领域（VOD）框架，提出了一种新的自归一化的Rényi变分界的估计方法，可用于训练具有检索增强功能的模型，例如阅读器-检索器BERT-sized模型，并实现了在多项选择医学考试问题上的优异表现。 |
| [^84] | [CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding.](http://arxiv.org/abs/2209.10918) | 本文提出了CONE，一个高效的粗-细对齐框架，可用于长视频时间定位。CONE通过基于查询的窗口选择策略和对比学习机制提升了多模态对齐，并在两个大规模长视频时间定位基准测试中取得最先进结果。 |
| [^85] | [ILLUME: Rationalizing Vision-Language Models through Human Interactions.](http://arxiv.org/abs/2208.08241) | 本文提出了一种新的调整范例，名为ILLUME，通过人机交互来合理化视觉-语言模型，从而使模型的输出更符合人的思维方式。在使用相对较少的训练数据和最少的人类反馈下，ILLUME表现出与标准监督微调相当的竞争力。 |
| [^86] | [Multi-Document Summarization with Centroid-Based Pretraining.](http://arxiv.org/abs/2208.01006) | 本文提出一种基于ROUGE的质心聚类预训练方法，可用于多文档摘要中，不需要人工编写的摘要，模型Centrum比现有先进模型更好。 |
| [^87] | [Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models.](http://arxiv.org/abs/2201.12675) | 该论文提出了一种针对联邦学习中文本的隐私攻击方法，通过部署恶意参数向量来揭示私人用户文本，并成功地进行mini-batches训练，适用于多个用户和长序列，提示了文本领域的FL比先前认为的更脆弱。 |
| [^88] | [AmbiFC: Fact-Checking Ambiguous Claims with Evidence.](http://arxiv.org/abs/2104.00640) | 本研究提出了一个大规模的事实核查数据集AmbiFC，用于处理现实场景中的含糊性声明核查问题，通过细粒度的证据注释和分析，提出了一种适用于含糊性声明的软标签证据核查方法，并且在注释人员争议分析中发现了相关性。 |
| [^89] | [Do Question Answering Modeling Improvements Hold Across Benchmarks?.](http://arxiv.org/abs/2102.01065) | 该论文通过测量32个问题回答基准测试之间的一致性，发现人工构建的基准测试具有高度的一致性，即使它们的段落和问题分布是非常不同的，这表明尽管人们长时间关注少数基准测试，但所研究的建模改进仍然具有广泛适用性。 |

# 详细

[^1]: IDAS: 带有摘要性总结的意图发现

    IDAS: Intent Discovery with Abstractive Summarization. (arXiv:2305.19783v1 [cs.CL])

    [http://arxiv.org/abs/2305.19783](http://arxiv.org/abs/2305.19783)

    本研究提出了一种利用摘要性总结对话进行聚类的 IDAS 方法，它可以在无监督环境下胜过最先进的竞争方法，并且在 Banking 和 Stack Overflow 数据集上只使用 5% 的标记数据即可获得竞争性的性能。

    

    意图发现是从一组未标记的话语中推断潜在意图的任务，是创建新对话代理的有效步骤。本研究表明，基于摘要性总结（即删除非必要信息，保留核心要素的“标签”）对话进行聚类可以胜过最近在意图发现方面的一些竞争方法。我们提出了 IDAS 方法，通过启动预训练的语言模型，从精心选择的原型话语种植开始，采集一组描述性话语标签，以启动一种上下文学习程序来为非典型话语生成标签。然后，将话语及其嘈杂的标签进行编码，并通过聚类来恢复潜在的意图。对于无监督任务（没有任何意图标签），IDAS 在 Banking、Stack Overflow 和 Chatbot 数据集的标准聚类度量中表现优异，可以超过最先进方法高达 +7.42%，在 Banking 和 Stack Overflow 数据集上仅使用 5% 的标记数据即可获得竞争性的性能，这表明它在有效意图发现方面具有潜力。

    Intent discovery is the task of inferring latent intents from a set of unlabeled utterances, and is a useful step towards the efficient creation of new conversational agents. We show that recent competitive methods in intent discovery can be outperformed by clustering utterances based on abstractive summaries, i.e., "labels", that retain the core elements while removing non-essential information. We contribute the IDAS approach, which collects a set of descriptive utterance labels by prompting a Large Language Model, starting from a well-chosen seed set of prototypical utterances, to bootstrap an In-Context Learning procedure to generate labels for non-prototypical utterances. The utterances and their resulting noisy labels are then encoded by a frozen pre-trained encoder, and subsequently clustered to recover the latent intents. For the unsupervised task (without any intent labels) IDAS outperforms the state-of-the-art by up to +7.42% in standard cluster metrics for the Banking, Stack
    
[^2]: 基于注意力机制的音频问答方法

    Attention-Based Methods For Audio Question Answering. (arXiv:2305.19769v1 [cs.CL])

    [http://arxiv.org/abs/2305.19769](http://arxiv.org/abs/2305.19769)

    本文提出了一种基于自我注意力和交叉注意力的神经网络体系结构，用于音频问答任务。实验结果表明，相较于参考方法，该方法在Clotho-AQA数据集上的表现有明显提高。

    

    音频问答(AQA)是对于音频和自然语言提出问题时，生成自然语言回答的任务。本文提出了基于自注意力和交叉注意力的神经网络体系结构，用于音频问答任务。自我注意力层可以提取强大的音频和文本表示。交叉注意力将与文本特征相关的音频特征映射到答案中。我们的所有模型都在最近提出的Clotho-AQA数据集上进行了训练，用于二进制是/否问题和单词回答问题。结果清楚地显示出相对于原始论文中的参考方法改进。在是/否二进制分类任务中，我们的提出的模型相对于参考模型的准确率从62.7％提高到了68.3％。对于单词答案多类分类器，我们的模型分别产生了57.9％和99.8％的top-1和top-5准确率，相对于参考模型的54.2％和93.7％有了明显提高。

    Audio question answering (AQA) is the task of producing natural language answers when a system is provided with audio and natural language questions. In this paper, we propose neural network architectures based on self-attention and cross-attention for the AQA task. The self-attention layers extract powerful audio and textual representations. The cross-attention maps audio features that are relevant to the textual features to produce answers. All our models are trained on the recently proposed Clotho-AQA dataset for both binary yes/no questions and single-word answer questions. Our results clearly show improvement over the reference method reported in the original paper. On the yes/no binary classification task, our proposed model achieves an accuracy of 68.3% compared to 62.7% in the reference model. For the single-word answers multiclass classifier, our model produces a top-1 and top-5 accuracy of 57.9% and 99.8% compared to 54.2% and 93.7% in the reference model respectively. We fur
    
[^3]: 递归 Metropolis-Hastings 命名游戏：基于概率生成模型的多智能体系统中的符号出现

    Recursive Metropolis-Hastings Naming Game: Symbol Emergence in a Multi-agent System based on Probabilistic Generative Models. (arXiv:2305.19761v1 [cs.CL])

    [http://arxiv.org/abs/2305.19761](http://arxiv.org/abs/2305.19761)

    本文提出了一种递归 Metropolis-Hastings 命名游戏 (RMHNG) 模型，用于多智能体系统中的符号出现，具有较快的收敛速度和鲁棒性，并在多个场景下进行了验证。

    

    在代理人群体中研究符号的出现和紧急通信，使用了一种计算模型，其中代理人参与各种语言游戏。其中，Metropolis-Hastings 命名游戏 (MHNG) 具有一个显著的数学属性：通过 MHNG 的符号出现被证明是分散式贝叶斯推理，是代理人共享的表征。然而，以前提出的 MHNG 仅在两个代理人场景中使用。本文将 MHNG 扩展到 N 代理人场景中。本文的主要贡献有两个：(1) 我们将递归 Metropolis-Hastings 命名游戏 (RMHNG) 提出为 MHNG 的 N 代理人版本，并证明 RMHNG 是一种近似贝叶斯推理方法，类似于 MHNG，用于代理人共享的潜在变量的后验分布；(2) 我们在合成和真实图像数据上进行了 RMHNG 的性能实证评估，使多个代理可以开发和共享符号系统。此外，我们还将 RMHNG 的性能与其他现有模型进行了比较，并展示了其在收敛速度和鲁棒性方面的优越性。

    In the studies on symbol emergence and emergent communication in a population of agents, a computational model was employed in which agents participate in various language games. Among these, the Metropolis-Hastings naming game (MHNG) possesses a notable mathematical property: symbol emergence through MHNG is proven to be a decentralized Bayesian inference of representations shared by the agents. However, the previously proposed MHNG is limited to a two-agent scenario. This paper extends MHNG to an N-agent scenario. The main contributions of this paper are twofold: (1) we propose the recursive Metropolis-Hastings naming game (RMHNG) as an N-agent version of MHNG and demonstrate that RMHNG is an approximate Bayesian inference method for the posterior distribution over a latent variable shared by agents, similar to MHNG; and (2) we empirically evaluate the performance of RMHNG on synthetic and real image data, enabling multiple agents to develop and share a symbol system. Furthermore, we
    
[^4]: 简单而有效的多任务预训练与迁移学习识别混合语言的方法

    Simple yet Effective Code-Switching Language Identification with Multitask Pre-Training and Transfer Learning. (arXiv:2305.19759v1 [cs.CL])

    [http://arxiv.org/abs/2305.19759](http://arxiv.org/abs/2305.19759)

    本文提出了两个新方法来提高在混合语音数据上的语言识别精度，包括使用Residual CNN+GRU模型和多任务预训练方法。由于语言混合的低资源性，我们还使用了单语语料库进行银数据创建和上采样。

    

    本文针对语言混合现象（code-switching）提出了两种新的方法来提高在英汉儿童语音数据集上的语言识别精度，包括Residual CNN+GRU模型和多任务预训练方法使用自动语音识别作为CSLID的辅助任务。由于语言混合的低资源性，我们还使用了单语语料库进行银数据创建和上采样进行数据增强。

    Code-switching, also called code-mixing, is the linguistics phenomenon where in casual settings, multilingual speakers mix words from different languages in one utterance. Due to its spontaneous nature, code-switching is extremely low-resource, which makes it a challenging problem for language and speech processing tasks. In such contexts, Code-Switching Language Identification (CSLID) becomes a difficult but necessary task if we want to maximally leverage existing monolingual tools for other tasks. In this work, we propose two novel approaches toward improving language identification accuracy on an English-Mandarin child-directed speech dataset. Our methods include a stacked Residual CNN+GRU model and a multitask pre-training approach to use Automatic Speech Recognition (ASR) as an auxiliary task for CSLID. Due to the low-resource nature of code-switching, we also employ careful silver data creation using monolingual corpora in both languages and up-sampling as data augmentation. We f
    
[^5]: 多语言场景中自动区分人类翻译和神经机器翻译

    Automatic Discrimination of Human and Neural Machine Translation in Multilingual Scenarios. (arXiv:2305.19757v1 [cs.CL])

    [http://arxiv.org/abs/2305.19757](http://arxiv.org/abs/2305.19757)

    本文研究在多语言环境下，如何自动区分人类翻译和机器翻译。在单一源语言的平行数据训练分类器时，我们可以很好地执行来自不同源语言的英语翻译的判别。将源文本加入多语言分类器的输入可以提高分类器的准确性和鲁棒性，使用不同源语言的训练数据往往提高单语和多语言分类器的准确性。双语分类器不可行。

    

    本文致力于解决自动区分人类翻译和机器翻译的问题。与大多数先前的研究相反，我们在多语言环境下进行实验，考虑了多种语言和多语言预训练语言模型。我们发现，在我们的情境中，使用单一源语言（在本例中为德语-英语）的平行数据训练分类器，仍然能够很好地执行来自不同源语言的英语翻译的判别，甚至在机器翻译是由不同于其训练系统的其他系统生成时也是如此。此外，我们证明，在一个多语言分类器的输入中加入源文本可以提高分类器的准确性和鲁棒性，相比于单语分类器。此外，我们发现使用不同源语言的训练数据（德语、俄语和中文）往往可以提高单语和多语言分类器的准确性。最后，我们展示了双语分类器是不现实的，并证明了这一点。

    We tackle the task of automatically discriminating between human and machine translations. As opposed to most previous work, we perform experiments in a multilingual setting, considering multiple languages and multilingual pretrained language models. We show that a classifier trained on parallel data with a single source language (in our case German-English) can still perform well on English translations that come from different source languages, even when the machine translations were produced by other systems than the one it was trained on. Additionally, we demonstrate that incorporating the source text in the input of a multilingual classifier improves (i) its accuracy and (ii) its robustness on cross-system evaluation, compared to a monolingual classifier. Furthermore, we find that using training data from multiple source languages (German, Russian, and Chinese) tends to improve the accuracy of both monolingual and multilingual classifiers. Finally, we show that bilingual classifie
    
[^6]: 使用释义语料库进行初始化的句子简化

    Sentence Simplification Using Paraphrase Corpus for Initialization. (arXiv:2305.19754v1 [cs.CL])

    [http://arxiv.org/abs/2305.19754](http://arxiv.org/abs/2305.19754)

    本文提出了两种使用释义语料库对神经句子简化方法进行初始化的策略，从而降低对平行语料库的依赖，并在WikiLarge数据上获得了显着的改进。

    

    基于序列到序列框架的神经句子简化方法已经成为句子简化(SS)任务的主流方法。不幸的是，这些方法目前受到平行SS语料库的稀缺性的限制。在本文中，我们关注如何通过利用释义语料库对神经SS方法进行精心初始化，从而降低对平行语料库的依赖。我们的工作得到以下两个发现的启发：(1)释义语料库包括大量属于SS语料库的句子对。(2)我们可以通过保留这些句子对中更高复杂度差异的句子对来构建大规模的伪并行SS数据。因此，我们提出了两种使用释义语料库初始化神经SS方法的策略。我们用初始化训练了三种不同的神经SS方法，在可用的WikiLarge数据上与自身没有初始化相比，可以获得显着的改进。

    Neural sentence simplification method based on sequence-to-sequence framework has become the mainstream method for sentence simplification (SS) task. Unfortunately, these methods are currently limited by the scarcity of parallel SS corpus. In this paper, we focus on how to reduce the dependence on parallel corpus by leveraging a careful initialization for neural SS methods from paraphrase corpus. Our work is motivated by the following two findings: (1) Paraphrase corpus includes a large proportion of sentence pairs belonging to SS corpus. (2) We can construct large-scale pseudo parallel SS data by keeping these sentence pairs with a higher complexity difference. Therefore, we propose two strategies to initialize neural SS methods using paraphrase corpus. We train three different neural SS methods with our initialization, which can obtain substantial improvements on the available WikiLarge data compared with themselves without initialization.
    
[^7]: 瑞士德语语音合成流程--一项比较研究

    Text-to-Speech Pipeline for Swiss German -- A comparison. (arXiv:2305.19750v1 [cs.CL])

    [http://arxiv.org/abs/2305.19750](http://arxiv.org/abs/2305.19750)

    本研究通过比较不同的文本到语音（TTS）模型，最终实现了对瑞士德语方言进行高质量语音合成，并介绍了一项新的TTS模型评估方法。

    

    本研究旨在使用不同的文本到语音（TTS）模型合成瑞士德语语音。我们对三个语料库的TTS模型进行了评估，发现VITS模型表现最佳，因此将其用于进一步测试。我们还介绍了一种新的方法，通过让训练好的vocoder GAN模型的鉴别器预测给定波形是人类生成的还是合成的来评估TTS模型。总之，我们的最佳模型能够以前所未有的质量为不同的瑞士德语方言提供语音合成。

    In this work, we studied the synthesis of Swiss German speech using different Text-to-Speech (TTS) models. We evaluated the TTS models on three corpora, and we found, that VITS models performed best, hence, using them for further testing. We also introduce a new method to evaluate TTS models by letting the discriminator of a trained vocoder GAN model predict whether a given waveform is human or synthesized. In summary, our best model delivers speech synthesis for different Swiss German dialects with previously unachieved quality.
    
[^8]: UKP-SQuARE: 一个用于教授问答技术的交互式工具

    UKP-SQuARE: An Interactive Tool for Teaching Question Answering. (arXiv:2305.19748v1 [cs.CL])

    [http://arxiv.org/abs/2305.19748](http://arxiv.org/abs/2305.19748)

    这篇论文介绍了UKP-SQuARE作为一个用于教授问答技术的交互式工具，学生可以通过其在不同角度了解各种QA模型，并借此获得理论概念和问题解决技能。

    

    问答技术的指数级增长使其成为任何自然语言处理（NLP）课程中不可或缺的话题。此外，这种指数级增长所导致的问答广度使其成为教授相关NLP主题（如信息检索、可解释性和对抗攻击等）的理想场景。本文介绍了UKP-SQuARE作为QA教育平台。该平台提供了一个交互式环境，在这里学生可以运行、比较和分析不同角度的各种QA模型，如一般行为，可解释性和鲁棒性。因此，学生可以在课堂上亲身体验不同的QA技术。由于这一点，我们提出了一种以学生为中心的QA教育方法，学生可以通过交互式的探索、实验和实践任务主动学习理论概念并获得问题解决技能，而不仅仅依赖传统的讲授。

    The exponential growth of question answering (QA) has made it an indispensable topic in any Natural Language Processing (NLP) course. Additionally, the breadth of QA derived from this exponential growth makes it an ideal scenario for teaching related NLP topics such as information retrieval, explainability, and adversarial attacks among others. In this paper, we introduce UKP-SQuARE as a platform for QA education. This platform provides an interactive environment where students can run, compare, and analyze various QA models from different perspectives, such as general behavior, explainability, and robustness. Therefore, students can get a first-hand experience in different QA techniques during the class. Thanks to this, we propose a learner-centered approach for QA education in which students proactively learn theoretical concepts and acquire problem-solving skills through interactive exploration, experimentation, and practical assignments, rather than solely relying on traditional le
    
[^9]: 通过测量任务对齐性分析文本表示

    Analyzing Text Representations by Measuring Task Alignment. (arXiv:2305.19747v1 [cs.CL])

    [http://arxiv.org/abs/2305.19747](http://arxiv.org/abs/2305.19747)

    文章研究了文本表示对于分类任务表现的影响，并提出了任务对齐得分方法来度量对齐性，验证了任务对齐性对于表示的分类性能有决定性的影响。

    

    基于预训练语言模型的文本表示对于少样本学习至关重要。什么使得文本分类的表示更好？是因为空间的几何属性还是因为它与任务有良好的对齐性？我们提出了第二种假设。为了测试，我们开发了一种基于层次聚类的任务对齐得分方法，在不同粒度级别上度量对齐性。我们的文本分类实验验证了我们的假设，证明任务对齐可以解释给定表示的分类性能。

    Textual representations based on pre-trained language models are key, especially in few-shot learning scenarios. What makes a representation good for text classification? Is it due to the geometric properties of the space or because it is well aligned with the task? We hypothesize the second claim. To test it, we develop a task alignment score based on hierarchical clustering that measures alignment at different levels of granularity. Our experiments on text classification validate our hypothesis by showing that task alignment can explain the classification performance of a given representation.
    
[^10]: 基于知识库的太空碎片问答系统

    Knowledge Base Question Answering for Space Debris Queries. (arXiv:2305.19734v1 [cs.AI])

    [http://arxiv.org/abs/2305.19734](http://arxiv.org/abs/2305.19734)

    本文介绍了一个基于知识库的系统，可以回答复杂自然语言的查询，支持工程师访问太空碎片环境的知识库中的信息。

    

    太空机构执行复杂的卫星操作，需要在其广泛的信息系统中存储和访问技术知识。知识库是以规模存储和访问此类信息的有效方式。本文中，我们介绍了一个为欧洲空间局（ESA）开发的系统，该系统可以回答复杂的自然语言查询，以支持工程师访问模拟轨道太空碎片环境的知识库中的信息。我们的系统基于一种管道流程，首先从自然语言问题生成一系列基本数据库操作，称为“程序草图”，然后将草图转换为具体的查询程序，包括实体、属性和关系的提及，最后针对数据库执行程序。这种流程分解方法使我们能够通过利用域外数据和由GPT-3生成的半合成数据来训练系统，从而减少过度拟合和漏洞。

    Space agencies execute complex satellite operations that need to be supported by the technical knowledge contained in their extensive information systems. Knowledge bases (KB) are an effective way of storing and accessing such information at scale. In this work we present a system, developed for the European Space Agency (ESA), that can answer complex natural language queries, to support engineers in accessing the information contained in a KB that models the orbital space debris environment. Our system is based on a pipeline which first generates a sequence of basic database operations, called a %program sketch, from a natural language question, then specializes the sketch into a concrete query program with mentions of entities, attributes and relations, and finally executes the program against the database. This pipeline decomposition approach enables us to train the system by leveraging out-of-domain data and semi-synthetic data generated by GPT-3, thus reducing overfitting and shor
    
[^11]: XPhoneBERT: 一种用于文本转语音的预训练多语言语音单位表示模型

    XPhoneBERT: A Pre-trained Multilingual Model for Phoneme Representations for Text-to-Speech. (arXiv:2305.19709v1 [cs.CL])

    [http://arxiv.org/abs/2305.19709](http://arxiv.org/abs/2305.19709)

    XPhoneBERT是第一个用于文本转语音的预训练多语言语音单位表示模型，通过其作为输入语音编码器，可以显著提高TTS模型的性能和语音质量。

    

    我们提出了XPhoneBERT，这是第一个预训练的多语言模型，用于学习下游文本转语音（TTS）任务的语音单位表示。我们的XPhoneBERT具有与BERT-base相同的模型架构，使用RoBERTa预训练方法在将近100种语言和语境中的330M个语音单位级句子上进行训练。实验结果表明，将XPhoneBERT作为输入语音编码器显著提升了强神经网络TTS模型的自然度和语调，并且在有限的训练数据下也有较高的语音质量。我们公开发布了我们的预训练XPhoneBERT，希望它能促进未来的多种语言TTS应用的研究。我们的XPhoneBERT模型可在https://github.com/VinAIResearch/XPhoneBERT获得。

    We present XPhoneBERT, the first multilingual model pre-trained to learn phoneme representations for the downstream text-to-speech (TTS) task. Our XPhoneBERT has the same model architecture as BERT-base, trained using the RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100 languages and locales. Experimental results show that employing XPhoneBERT as an input phoneme encoder significantly boosts the performance of a strong neural TTS model in terms of naturalness and prosody and also helps produce fairly high-quality speech with limited training data. We publicly release our pre-trained XPhoneBERT with the hope that it would facilitate future research and downstream TTS applications for multiple languages. Our XPhoneBERT model is available at https://github.com/VinAIResearch/XPhoneBERT
    
[^12]: 构建提取式问答系统以支持人工智能健康辅导模型在睡眠领域的应用

    Building Extractive Question Answering System to Support Human-AI Health Coaching Model for Sleep Domain. (arXiv:2305.19707v1 [cs.CL])

    [http://arxiv.org/abs/2305.19707](http://arxiv.org/abs/2305.19707)

    本文提出了一个人工智能健康辅导模型，包含一个提取式 QA 系统，通过对睡眠相关数据集进行微调，通过数据中心化框架提高系统性能。 在真实世界问题的人工评估中表现出色，在随机对照试验的试点测试中验证将其集成到人工智能健康辅导模型中。

    

    非传染性疾病 (NCDs) 是全球死亡的主要原因，需要关注初级预防和生活方式行为改变。 健康辅导和问答 (QA) 系统结合起来，有潜力改变预防保健。 本文提出了一个人工智能健康辅导模型，其中包括一个具有特定领域的提取式 QA 系统。 睡眠相关数据集 SleepQA 被手动组装并用于微调特定领域的 BERT 模型。 该 QA 系统使用自动和人类方法进行评估。 数据中心化框架通过改进段落检索和问题改写提高了系统性能。 尽管该系统在自动评估中未超越基线，但在真实世界问题的人工评估中表现出色。 在随机对照试验的试点测试中验证了将其集成到人工智能健康辅导模型中。

    Non-communicable diseases (NCDs) are a leading cause of global deaths, necessitating a focus on primary prevention and lifestyle behavior change. Health coaching, coupled with Question Answering (QA) systems, has the potential to transform preventive healthcare. This paper presents a human-Artificial Intelligence (AI) health coaching model incorporating a domain-specific extractive QA system. A sleep-focused dataset, SleepQA, was manually assembled and used to fine-tune domain-specific BERT models. The QA system was evaluated using automatic and human methods. A data-centric framework enhanced the system's performance by improving passage retrieval and question reformulation. Although the system did not outperform the baseline in automatic evaluation, it excelled in the human evaluation of real-world questions. Integration into a Human-AI health coaching model was tested in a pilot Randomized Controlled Trial (RCT).
    
[^13]: 利用训练用于语义任务的模型评估词语重要性

    Assessing Word Importance Using Models Trained for Semantic Tasks. (arXiv:2305.19689v1 [cs.CL])

    [http://arxiv.org/abs/2305.19689](http://arxiv.org/abs/2305.19689)

    本文介绍了一种从解决语义任务的模型中推导出单词重要性的方法，并证明其稳健性，可以在无需显式单词重要性标签的情况下识别句子中重要的单词。

    

    许多自然语言处理任务需要自动识别文本中最重要的单词。本文从训练用于解决自然语言推理和释义识别的模型中得到单词重要性。我们使用一种旨在解释这些模型预测的属性方法，为每个输入令牌导出重要性得分。我们使用所谓的交叉任务评估来评估它们的相关性：分析一个模型在按照另一个模型权重屏蔽的输入上的表现，我们展示了我们的方法对于初始任务的选择是稳健的。此外，我们从语法的角度研究了分数，并观察到有趣的模式，例如更接近语法树根的单词接收较高的重要性得分。总之，这些观察结果表明我们的方法可以用于在训练中没有任何显式单词重要性标签的情况下识别句子中重要的单词。

    Many NLP tasks require to automatically identify the most significant words in a text. In this work, we derive word significance from models trained to solve semantic task: Natural Language Inference and Paraphrase Identification. Using an attribution method aimed to explain the predictions of these models, we derive importance scores for each input token. We evaluate their relevance using a so-called cross-task evaluation: Analyzing the performance of one model on an input masked according to the other model's weight, we show that our method is robust with respect to the choice of the initial task. Additionally, we investigate the scores from the syntax point of view and observe interesting patterns, e.g. words closer to the root of a syntactic tree receive higher importance scores. Altogether, these observations suggest that our method can be used to identify important words in sentences without any explicit word importance labeling in training.
    
[^14]: 揭示视觉问答中的跨模态偏见：可能世界VQA的因果视角

    Unveiling Cross Modality Bias in Visual Question Answering: A Causal View with Possible Worlds VQA. (arXiv:2305.19664v1 [cs.CV])

    [http://arxiv.org/abs/2305.19664](http://arxiv.org/abs/2305.19664)

    为了解决VQA系统因视觉和语言的混淆效应而导致的双重偏差问题，本文提出了一个反事实的推理方法。该方法可以同时并高效地减少视觉和语言偏见。

    

    为了增强VQA系统的泛化能力，许多最近的研究尝试消除捷径式的语言或视觉关联来回答问题。尽管这些研究致力于此，但文献还没有同时解决视觉和语言的混淆效应。结果，他们从一个模态减少学习偏见时，通常会增加另一个模态的偏见。本文首先建模导致语言和视觉偏见的混淆效应，然后提出一个反事实的推理方法来消除这种影响。在这种策略下训练的模型可以同时且高效地减少视觉和语言偏见。据我们所知，这是第一篇利用因果关系解释消除视觉问答中视觉和语言混淆效应的地址偏见的作品。我们将我们的方法与一个解释消除策略相结合，提高数字答案问题的准确性结果。

    To increase the generalization capability of VQA systems, many recent studies have tried to de-bias spurious language or vision associations that shortcut the question or image to the answer. Despite these efforts, the literature fails to address the confounding effect of vision and language simultaneously. As a result, when they reduce bias learned from one modality, they usually increase bias from the other. In this paper, we first model a confounding effect that causes language and vision bias simultaneously, then propose a counterfactual inference to remove the influence of this effect. The model trained in this strategy can concurrently and efficiently reduce vision and language bias. To the best of our knowledge, this is the first work to reduce biases resulting from confounding effects of vision and language in VQA, leveraging causal explain-away relations. We accompany our method with an explain-away strategy, pushing the accuracy of the questions with numerical answers results
    
[^15]: 惊人地，副词在计算语言学中被忽视了 (arXiv:2305.19650v1 [cs.CL])

    Adverbs, Surprisingly. (arXiv:2305.19650v1 [cs.CL])

    [http://arxiv.org/abs/2305.19650](http://arxiv.org/abs/2305.19650)

    本文发现计算语言学中副词的相关分析存在系统性空缺，在框架语义学（如FrameNet）的帮助下提出了一种有前途的副词分析方法。

    

    本文的出发点是副词在计算语言学中被忽略了。这个观点来源于两个分析：一是文献综述，二是一个新颖的副词数据集，用于验证最新的语言模型，从而揭示了有关副词含义的系统性空缺。我们建议使用框架语义学来表征单词含义，例如FrameNet，提供了一种有前途的副词分析方法，因其能描述模糊性、语义角色和空值实例化。

    This paper begins with the premise that adverbs are neglected in computational linguistics. This view derives from two analyses: a literature review and a novel adverb dataset to probe a state-of-the-art language model, thereby uncovering systematic gaps in accounts for adverb meaning. We suggest that using Frame Semantics for characterizing word meaning, as in FrameNet, provides a promising approach to adverb analysis, given its ability to describe ambiguity, semantic roles, and null instantiation.
    
[^16]: 文本分类系统中的对抗性干净标签后门攻击及其防御

    Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems. (arXiv:2305.19607v1 [cs.CL])

    [http://arxiv.org/abs/2305.19607](http://arxiv.org/abs/2305.19607)

    本文针对文本分类系统提出了一种对抗性干净标签攻击，并提高了攻击成功率，比起标签翻转攻击更难以防御。同时，研究了多种防御策略对两种攻击的有效性。

    

    干净标签攻击是一种数据污染攻击，攻击者仅修改训练数据的文本输入，而无需访问标注函数。本文首先引入了一种对抗性干净标签攻击，可以故意扰动训练集中的同类样本来污染训练集。然后，我们展示了攻击者可以显著降低干净标签攻击的数据要求，使用上述方法可以将要求的数据量降低到原来的20%。最后，我们系统地评估和分析了一些既可防御干净标签攻击又可防御标签翻转攻击的防御方法。

    Clean-label (CL) attack is a form of data poisoning attack where an adversary modifies only the textual input of the training data, without requiring access to the labeling function. CL attacks are relatively unexplored in NLP, as compared to label flipping (LF) attacks, where the latter additionally requires access to the labeling function as well. While CL attacks are more resilient to data sanitization and manual relabeling methods than LF attacks, they often demand as high as ten times the poisoning budget than LF attacks. In this work, we first introduce an Adversarial Clean Label attack which can adversarially perturb in-class training examples for poisoning the training set. We then show that an adversary can significantly bring down the data requirements for a CL attack, using the aforementioned approach, to as low as 20% of the data otherwise required. We then systematically benchmark and analyze a number of defense methods, for both LF and CL attacks, some previously employed
    
[^17]: 语言模型在零/少样本环境下无法正确理解“respectively”的原因研究

    What does the Failure to Reason with "Respectively" in Zero/Few-Shot Settings Tell Us about Language Models?. (arXiv:2305.19597v1 [cs.CL])

    [http://arxiv.org/abs/2305.19597](http://arxiv.org/abs/2305.19597)

    本文研究发现，语言模型在零/少样本环境下难以理解“respectively”的各种读法，需要更长时间的训练和依赖常识推理，仍落后于人类。

    

    人类可以轻松理解“Niels Bohr and Kurt Cobain were born in Copenhagen and Seattle, respectively”这种句子的协作结构。在自然语言推断（NLI）的背景下，本文从句法-语义和常识-世界知识的两个角度研究了语言模型（LMs）如何理解两个读数（Gawron和Kehler，2004） 。我们提出了一个受控合成数据集WikiResNLI 和一个自然数据集 NatResNLI，以包含各种显式和隐式实现的“respectively”。我们发现，微调后的NLI模型在没有显式监督的情况下难以理解这样的读数。当存在显式提示时，零/少样本学习很容易，而当该读数隐含时，则需要更长的训练时间，以依赖常识推理。此外，我们的细致分析表明，模型无法在不同结构之间进行泛化。总之，我们证明了在零/少样本环境下，语言模型在理解“respectively”的各种读法方面仍落后于人类。

    Humans can effortlessly understand the coordinate structure of sentences such as "Niels Bohr and Kurt Cobain were born in Copenhagen and Seattle, respectively". In the context of natural language inference (NLI), we examine how language models (LMs) reason with respective readings (Gawron and Kehler, 2004) from two perspectives: syntactic-semantic and commonsense-world knowledge. We propose a controlled synthetic dataset WikiResNLI and a naturally occurring dataset NatResNLI to encompass various explicit and implicit realizations of "respectively". We show that fine-tuned NLI models struggle with understanding such readings without explicit supervision. While few-shot learning is easy in the presence of explicit cues, longer training is required when the reading is evoked implicitly, leaving models to rely on common sense inferences. Furthermore, our fine-grained analysis indicates models fail to generalize across different constructions. To conclude, we demonstrate that LMs still lag 
    
[^18]: SLABERT：使用BERT模型建模第二语言习得

    SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT. (arXiv:2305.19589v1 [cs.CL])

    [http://arxiv.org/abs/2305.19589](http://arxiv.org/abs/2305.19589)

    该论文利用BERT模型建模了第二语言习得，并构建了一个多语言数据集以研究母语儿童指导语言（CDS）对英文语言习得的积极和消极转移现象。

    

    第二语言习得（SLA）研究广泛研究了跨语言转移，即母语[L1]的语言结构对外语[L2]习得的影响。这种转移的影响可以是积极的(促进习得)或消极的(阻碍习得)。我们发现NLP文献没有足够关注消极转移现象。为了理解L1和L2之间积极和消极转移的模式，我们使用语言模型对顺序第二语言习得进行建模。此外，我们构建了一个多语言年龄排序CHILDES（MAO-CHILDES）数据集，其中包括5种类型不同的语言，即德语、法语、波兰语、印度尼西亚语和日语，以理解母语儿童指导语言（CDS）[L1]对英语语言习得[L2]有多大帮助或冲突。为了检查母语CDS的影响，我们使用TILT-based跨语言转移学习方法。

    Second language acquisition (SLA) research has extensively studied cross-linguistic transfer, the influence of linguistic structure of a speaker's native language [L1] on the successful acquisition of a foreign language [L2]. Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition). We find that NLP literature has not given enough attention to the phenomenon of negative transfer. To understand patterns of both positive and negative transfer between L1 and L2, we model sequential second language acquisition in LMs. Further, we build a Mutlilingual Age Ordered CHILDES (MAO-CHILDES) -- a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese -- to understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2]. To examine the impact of native CDS, we use the TILT-based cross lingual transfer learning approach established 
    
[^19]: 基于可调层交互的Transformer高效多段编码

    LAIT: Efficient Multi-Segment Encoding in Transformers with Layer-Adjustable Interaction. (arXiv:2305.19585v1 [cs.CL])

    [http://arxiv.org/abs/2305.19585](http://arxiv.org/abs/2305.19585)

    LAIT是一种通过多段编码实现跨段注意力的新框架，使用Layer-Adjustable Interactions技术实现分段编码和逐层交互，提高了模型的效率和精度，并极大地简化了模型设计的复杂度。

    

    Transformer编码器通过对各个令牌的注意力进行编码，使其上下文得以建立，但对于长文本二次计算成本较高。本文提出了名为LAIT的新框架，通过多段编码实现跨段注意力，极大地提升了模型的效率和精度。该框架通过Layer-Adjustable Interactions技术实现分段编码和逐层交互，不仅有效地利用了预训练的Transformers模型，而且极大地简化了模型设计的复杂度。

    Transformer encoders contextualize token representations by attending to all other tokens at each layer, leading to quadratic increase in compute effort with the input length. In practice, however, the input text of many NLP tasks can be seen as a sequence of related segments (e.g., the sequence of sentences within a passage, or the hypothesis and premise in NLI). While attending across these segments is highly beneficial for many tasks, we hypothesize that this interaction can be delayed until later encoding stages.  To this end, we introduce Layer-Adjustable Interactions in Transformers (LAIT). Within LAIT, segmented inputs are first encoded independently, and then jointly. This partial two-tower architecture bridges the gap between a Dual Encoder's ability to pre-compute representations for segments and a fully self-attentive Transformer's capacity to model cross-segment attention. The LAIT framework effectively leverages existing pretrained Transformers and converts them into the h
    
[^20]: 基于CLS和语言标注的标签组合方法：提高多语言ASR的性能

    The Tag-Team Approach: Leveraging CLS and Language Tagging for Enhancing Multilingual ASR. (arXiv:2305.19584v1 [cs.CL])

    [http://arxiv.org/abs/2305.19584](http://arxiv.org/abs/2305.19584)

    通过将相似的声音映射到常见的标签，利用CLS和语言标注相结合来提高多语言ASR模型的性能。

    

    在一个语言多样的国家，如印度，建立一个多语言的自动语音识别(ASR)系统可能是一项具有挑战性的任务，由于语音数据的有限可用性和脚本的差异。这个问题可以通过利用许多这些语言在音素上的相似性来解决。将这些语言转换为一个通用标签集(CLSet)，通过将相似的声音映射到常见的标签。在本文中，探讨并比较新的方法，以改善基于CLS的多语言ASR模型的性能。在CLS多语言模型的基础上，通过给予语言ID或者使用CLS到本地脚本转换器来注入特定的语言信息。这些方法与CLS基线相比，在词错误率(WER)方面有显著的改进。此外，这些方法在分布之外的数据上进行了尝试以检查其鲁棒性。

    Building a multilingual Automated Speech Recognition (ASR) system in a linguistically diverse country like India can be a challenging task due to the differences in scripts and the limited availability of speech data. This problem can be solved by exploiting the fact that many of these languages are phonetically similar. These languages can be converted into a Common Label Set (CLS) by mapping similar sounds to common labels. In this paper, new approaches are explored and compared to improve the performance of CLS based multilingual ASR model. Specific language information is infused in the ASR model by giving Language ID or using CLS to Native script converter on top of the CLS Multilingual model. These methods give a significant improvement in Word Error Rate (WER) compared to the CLS baseline. These methods are further tried on out-of-distribution data to check their robustness.
    
[^21]: DC CoMix TTS：一种与混合器协作的端到端表现力TTS，利用离散码实现改进的韵律建模

    DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code Collaborated with Mixer. (arXiv:2305.19567v1 [cs.SD])

    [http://arxiv.org/abs/2305.19567](http://arxiv.org/abs/2305.19567)

    本文提出了一种基于离散码和混合器相协作的端到端表现力TTS，它采用新的输入表示和简单的架构来实现改进的韵律建模，证明了其有效性。

    

    尽管中性TTS取得了巨大的成功，但内容泄漏仍然是一个挑战。本文提出了一种新的输入表示和简单的架构来实现改进的韵律建模。受最近在TTS中使用离散码取得的成功启发，我们将离散码引入到参考编码器的输入中。具体来说，我们利用音频压缩模型中的向量量化器来利用它已经训练过的多样化的声学信息。此外，我们将修改后的MLP-Mixer应用到参考编码器中，使得架构更加轻盈。因此，我们以端到端的方式训练韵律转移TTS。我们通过主观和客观评估证明了我们方法的有效性。我们在实验中证明了，当离散码作为输入时，参考编码器可以学习到更好的与说话人无关的韵律。另外，即使输入参数更少，我们也可以获得可比较的结果。

    Despite the huge successes made in neutral TTS, content-leakage remains a challenge. In this paper, we propose a new input representation and simple architecture to achieve improved prosody modeling. Inspired by the recent success in the use of discrete code in TTS, we introduce discrete code to the input of the reference encoder. Specifically, we leverage the vector quantizer from the audio compression model to exploit the diverse acoustic information it has already been trained on. In addition, we apply the modified MLP-Mixer to the reference encoder, making the architecture lighter. As a result, we train the prosody transfer TTS in an end-to-end manner. We prove the effectiveness of our method through both subjective and objective evaluations. We demonstrate that the reference encoder learns better speaker-independent prosody when discrete code is utilized as input in the experiments. In addition, we obtain comparable results even when fewer parameters are inputted.
    
[^22]: 无需标注数据的零样本自动发音评估

    Zero-Shot Automatic Pronunciation Assessment. (arXiv:2305.19563v1 [cs.SD])

    [http://arxiv.org/abs/2305.19563](http://arxiv.org/abs/2305.19563)

    本文提出了一种基于预训练声学模型的零样本自动发音评估方法，该方法不需要标注数据，使用掩码模块破坏语音输入，应用k均值聚类获得标记序列并使用评分模块测量错误恢复标记的数量，在实验中取得了与监督回归基线相当的性能以及优于非回归基线的结果。

    

    自动发音评估对于计算机辅助语言学习至关重要。传统方法依赖于带注释的语音文本数据来训练自动语音识别模型或依赖于带分数的语音数据来训练回归模型。本文提出了一种基于预训练声学模型HuBERT的全新零样本自动发音评估方法。我们的方法涉及对语音输入进行编码并通过掩码模块进行破坏。然后使用Transformer编码器并应用k均值聚类以获得标记序列。最后，设计了评分模块来测量错误恢复标记的数量。在speechocean762上的实验结果表明，所提出的方法在皮尔逊相关系数（PCC）方面与监督回归基线方法具有可比性，并且在非回归基线方法方面表现更优。此外，我们还分析了掩码策略对自动发音评估性能的影响。

    Automatic Pronunciation Assessment (APA) is vital for computer-assisted language learning. Prior methods rely on annotated speech-text data to train Automatic Speech Recognition (ASR) models or speech-score data to train regression models. In this work, we propose a novel zero-shot APA method based on the pre-trained acoustic model, HuBERT. Our method involves encoding speech input and corrupting them via a masking module. We then employ the Transformer encoder and apply k-means clustering to obtain token sequences. Finally, a scoring module is designed to measure the number of wrongly recovered tokens. Experimental results on speechocean762 demonstrate that the proposed method achieves comparable performance to supervised regression baselines and outperforms non-regression baselines in terms of Pearson Correlation Coefficient (PCC). Additionally, we analyze how masking strategies affect the performance of APA.
    
[^23]: 大型语言模型不能作为抽象推理器

    Large Language Models Are Not Abstract Reasoners. (arXiv:2305.19555v1 [cs.CL])

    [http://arxiv.org/abs/2305.19555](http://arxiv.org/abs/2305.19555)

    本文通过对最先进的大型语言模型进行抽象推理任务评估，发现它们在这方面的表现十分有限，揭示了其在推理方面的局限性。

    

    大型语言模型在自然语言处理任务上表现出极好的性能，包括文本理解和常识推理等。然而，这些成功的机制尚不清楚，LLMs是否能够达到人类的认知能力或这些模型是否还存在根本性的局限性也不确定。抽象推理是认知的基本任务，包括从少量数据中找到和应用一般模式。评估深度神经结构在这个任务上的表现可以揭示它们在推理方面的潜在局限性和广泛的泛化能力，这是一个目前未被探索的领域。本文对最先进的LLMs进行了大量评估，发现它们在抽象推理任务中的表现非常有限，并探究了造成这种差异的原因。

    Large Language Models have shown tremendous performance on a large variety of natural language processing tasks, ranging from text comprehension to common sense reasoning. However, the mechanisms responsible for this success remain unknown, and it is unclear whether LLMs can achieve human-like cognitive capabilities or whether these models are still fundamentally limited. Abstract reasoning is a fundamental task for cognition, consisting of finding and applying a general pattern from few data. Evaluating deep neural architectures on this task could give insight into their potential limitations regarding reasoning and their broad generalisation abilities, yet this is currently an under-explored area. In this paper, we perform extensive evaluations of state-of-the-art LLMs on abstract reasoning tasks, showing that they achieve very limited performance in contrast with other natural language tasks, and we investigate the reasons for this difference. We apply techniques that have been show
    
[^24]: 准确和结构化剪枝用于高效的自动语音识别

    Accurate and Structured Pruning for Efficient Automatic Speech Recognition. (arXiv:2305.19549v1 [cs.CL])

    [http://arxiv.org/abs/2305.19549](http://arxiv.org/abs/2305.19549)

    本文提出了一种新型压缩策略，结合结构化剪枝和知识蒸馏，以减少Conformer模型的模型大小和推理成本，同时保持较高的识别性能，并在LibriSpeech基准测试中优于所有剪枝基准线。

    

    深度神经网络，如Transformer和Conformer在自动语音识别（ASR）方面取得了显著进展。但是，这些模型通常具有较大的模型大小和高昂的推理成本，这对于在资源有限的设备上部署构成了挑战。在本文中，我们提出了一种利用结构化剪枝和知识蒸馏来减少Conformer模型的模型大小和推理成本的新型压缩策略，同时保持较高的识别性能。我们的方法利用一组二进制掩码来指示是否保留或修剪每个Conformer模块，并采用L0正则化来学习最佳掩码值。为了进一步增强剪枝性能，我们使用逐层蒸馏策略将知识从未修剪过的模型传输到修剪过的模型。我们的方法在广泛使用的LibriSpeech基准测试中优于所有剪枝基准线，在最小性能损失的情况下，实现了50％的模型大小减少和28％的推理成本减少。

    Automatic Speech Recognition (ASR) has seen remarkable advancements with deep neural networks, such as Transformer and Conformer. However, these models typically have large model sizes and high inference costs, posing a challenge to deploy on resource-limited devices. In this paper, we propose a novel compression strategy that leverages structured pruning and knowledge distillation to reduce the model size and inference cost of the Conformer model while preserving high recognition performance. Our approach utilizes a set of binary masks to indicate whether to retain or prune each Conformer module, and employs L0 regularization to learn the optimal mask values. To further enhance pruning performance, we use a layerwise distillation strategy to transfer knowledge from unpruned to pruned models. Our method outperforms all pruning baselines on the widely used LibriSpeech benchmark, achieving a 50% reduction in model size and a 28% reduction in inference cost with minimal performance loss.
    
[^25]: 基于扩散式语言模型的细粒度文本风格转换

    Fine-grained Text Style Transfer with Diffusion-Based Language Models. (arXiv:2305.19512v1 [cs.CL])

    [http://arxiv.org/abs/2305.19512](http://arxiv.org/abs/2305.19512)

    本文提出了一种基于扩散式语言模型的细粒度文本风格转换方法，在不依赖外部信息的情况下取得了比之前利用预训练权重、嵌入和外部语法分析器更好的效果，表明扩散概率模型在文本生成领域具有广泛的应用前景。

    

    扩散式概率模型已经在可控制地生成高质量图像上显示出了巨大的成功，研究人员已经试图将这种可控性运用到文本生成领域。以前的扩散式语言模型研究表明，它们可以在不需要外部知识（如预训练权重）的情况下进行训练，并且仍然可以实现稳定的性能和可控性。 在本文中，我们在StylePTB数据集上训练了一个扩散式模型，这是细粒度文本风格转换的标准基准。与以前的工作评估任务相比，StylePTB中的任务需要对输出文本进行更加精细的控制，我们的模型能够在StylePTB上实现卓越的性能，包括个别和组合转换。此外，我们的模型在没有外部知识的情况下使用StylePTB的有限数据进行训练，其表现优于以前利用预训练权重、嵌入和外部语法分析器的工作，这可能表明扩散概率模型在文本生成领域具有巨大的潜力。

    Diffusion probabilistic models have shown great success in generating high-quality images controllably, and researchers have tried to utilize this controllability into text generation domain. Previous works on diffusion-based language models have shown that they can be trained without external knowledge (such as pre-trained weights) and still achieve stable performance and controllability. In this paper, we trained a diffusion-based model on StylePTB dataset, the standard benchmark for fine-grained text style transfers. The tasks in StylePTB requires much more refined control over the output text compared to tasks evaluated in previous works, and our model was able to achieve state-of-the-art performance on StylePTB on both individual and compositional transfers. Moreover, our model, trained on limited data from StylePTB without external knowledge, outperforms previous works that utilized pretrained weights, embeddings, and external grammar parsers, and this may indicate that diffusion
    
[^26]: 探索用于预训练语言模型的抽奖提示

    Exploring Lottery Prompts for Pre-trained Language Models. (arXiv:2305.19500v1 [cs.CL])

    [http://arxiv.org/abs/2305.19500](http://arxiv.org/abs/2305.19500)

    本文通过对实例级提示及其普适性的探讨，发现了一些强大且具备可区分语言特征的抽奖提示，通过提示集成方法可将其推广到未见数据集上，为替代传统微调方法提供了更有效的选择。

    

    一直以来，对于预训练语言模型（PLMs）的可持续扩展，在模型适应性方面存在重大负担，需要更有效的替代传统的微调方法。 鉴于在零-shot环境中提示的优势和观察到不同提示之间的性能波动，本文探讨了实例级提示及其普适性。 通过在提示空间中进行搜索，我们首先验证了这样一种假设：对于每个实例，几乎总是存在一种抽奖提示，可以以低成本获得PLM的正确预测能力。 同时，我们发现一些强大的抽奖提示在整个训练集上具有高性能，并具备可区分的语言特征。 最后，我们试图使用提示集成方法将搜索到的强大抽奖提示推广到未见数据而无需任何参数调整。 在各种类型的NLP c上进行实验。

    Consistently scaling pre-trained language models (PLMs) imposes substantial burdens on model adaptation, necessitating more efficient alternatives to conventional fine-tuning. Given the advantage of prompting in the zero-shot setting and the observed performance fluctuation among different prompts, we explore the instance-level prompt and their generalizability. By searching through the prompt space, we first validate the assumption that for every instance, there is almost always a lottery prompt that induces the correct prediction from the PLM, and such prompt can be obtained at a low cost thanks to the inherent ability of PLMs. Meanwhile, we find that some strong lottery prompts have high performance over the whole training set, and they are equipped with distinguishable linguistic features. Lastly, we attempt to generalize the searched strong lottery prompts to unseen data with prompt ensembling method without any parameter tuning. Experiments are conducted on various types of NLP c
    
[^27]: 面向开放领域操作文本的流程图预测

    Towards Flow Graph Prediction of Open-Domain Procedural Texts. (arXiv:2305.19497v1 [cs.CL])

    [http://arxiv.org/abs/2305.19497](http://arxiv.org/abs/2305.19497)

    本文提出了一种针对开放领域操作文本的流程图预测框架，使用领域自适应技术，实现了比单独在烹饪或目标领域训练的模型表现更好。

    

    操作文本的机器理解对于推理步骤和自动化操作至关重要。然而，这要求在文本中识别实体并解决实体之间的关系。以前的工作侧重于烹饪领域，并提出了一种将菜谱文本转换为流程图(FG)表示的框架。在这项工作中，我们提出了一种基于菜谱FG的框架，用于预测开放领域操作文本的流程图。为了研究非烹饪领域中的流程图预测性能，我们介绍了来自how-to指南网站wikiHow上文章的wikiHow-FG语料库。在实验中，我们考虑使用现有的菜谱语料库，并从烹饪领域进行域自适应到目标领域。实验结果表明，域自适应模型比仅在烹饪或目标领域数据上训练的模型表现更好。

    Machine comprehension of procedural texts is essential for reasoning about the steps and automating the procedures. However, this requires identifying entities within a text and resolving the relationships between the entities. Previous work focused on the cooking domain and proposed a framework to convert a recipe text into a flow graph (FG) representation. In this work, we propose a framework based on the recipe FG for flow graph prediction of open-domain procedural texts. To investigate flow graph prediction performance in non-cooking domains, we introduce the wikiHow-FG corpus from articles on wikiHow, a website of how-to instruction articles. In experiments, we consider using the existing recipe corpus and performing domain adaptation from the cooking to the target domain. Experimental results show that the domain adaptation models achieve higher performance than those trained only on the cooking or target domain data.
    
[^28]: PlaSma: 为 (反事实) 计划制定增强过程知识模型的小型语言模型

    PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning. (arXiv:2305.19472v1 [cs.CL])

    [http://arxiv.org/abs/2305.19472](http://arxiv.org/abs/2305.19472)

    PlaSma提出了一种使用小型语言模型进行过程知识和计划能力的新方法，

    

    过程规划是机器的一项重要而又复杂的任务，它将一个高级目标分解为一系列时间顺序的步骤。它需要整合常识知识以推理出常常是反事实的复杂情境，例如 "没有电话时安排医生的约会"。当前的方法使用大型语言模型 (LLM) 取得了令人鼓舞的结果，但受到昂贵的 API 调用和可复现性问题的限制。本文提出使用更小的语言模型来进行规划，我们介绍了 PlaSma，这是一种新的双重方法，使小型语言模型具有过程知识和 (反事实) 计划能力。更具体地说，我们开发了符号过程知识蒸馏来增强小型语言模型中的隐含知识，以及一种推理算法来促进更结构化和准确的推理。此外，我们还引入了一个新的任务，反事实规划。

    Procedural planning, which entails decomposing a high-level goal into a sequence of temporally ordered steps, is an important yet intricate task for machines. It involves integrating common-sense knowledge to reason about complex contextualized situations that are often counterfactual, e.g. "scheduling a doctor's appointment without a phone". While current approaches show encouraging results using large language models (LLMs), they are hindered by drawbacks such as costly API calls and reproducibility issues. In this paper, we advocate planning using smaller language models. We present PlaSma, a novel two-pronged approach to endow small language models with procedural knowledge and (counterfactual) planning capabilities. More concretely, we develop symbolic procedural knowledge distillation to enhance the implicit knowledge in small language models and an inference-time algorithm to facilitate more structured and accurate reasoning. In addition, we introduce a novel task, Counterfactua
    
[^29]: 位置编码对 Transformer 模型长度推广的影响

    The Impact of Positional Encoding on Length Generalization in Transformers. (arXiv:2305.19466v1 [cs.CL])

    [http://arxiv.org/abs/2305.19466](http://arxiv.org/abs/2305.19466)

    本文通过实证研究 Transformer 模型中位置编码对于长度推广的影响，结果表明常用的位置编码方法并不适合用于下游任务的长度推广，并且使用位置编码甚至可能会损害长度推广的能力。

    

    Transformer-based 语言模型的开发中，长度推广是一个关键的挑战，它是指从小的训练文本范围到更大范围的泛化能力。位置编码（PE）被发现是影响长度推广的主要因素之一，但不同的 PE 方案对下游任务的外推影响还不清楚。本文通过对比评估五种不同位置编码方法（包括绝对位置嵌入、T5 的相对 PE、ALiBi、Rotary 和无位置编码）的解码器 Transformer 的长度推广能力，对推理和数学任务进行了系统的实证研究。研究发现，常用的位置编码方法，如 ALiBi、Rotary 和 APE，并不适合用于下游任务的长度推广。更重要的是，无 PE 的 Transformer 在推理任务中的表现优于其他显式 PE 方法，这意味着使用位置编码实际上可能会损害长度推广的能力。这些发现揭示了位置编码在有效 Transformer 模型开发中的重要作用。

    Length generalization, the ability to generalize from small training context sizes to larger ones, is a critical challenge in the development of Transformer-based language models. Positional encoding (PE) has been identified as a major factor influencing length generalization, but the exact impact of different PE schemes on extrapolation in downstream tasks remains unclear. In this paper, we conduct a systematic empirical study comparing the length generalization performance of decoder-only Transformers with five different position encoding approaches including Absolute Position Embedding (APE), T5's Relative PE, ALiBi, and Rotary, in addition to Transformers without positional encoding (NoPE). Our evaluation encompasses a battery of reasoning and mathematical tasks. Our findings reveal that the most commonly used positional encoding methods, such as ALiBi, Rotary, and APE, are not well suited for length generalization in downstream tasks. More importantly, NoPE outperforms other expli
    
[^30]: ScoNe: 用微调和上下文学习评估语言模型中的否定推理表现的基准测试

    ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning. (arXiv:2305.19426v1 [cs.CL])

    [http://arxiv.org/abs/2305.19426](http://arxiv.org/abs/2305.19426)

    本文提出了Scoped Negation NLI (ScoNe-NLI)基准测试以评估微调和上下文学习策略对语言模型中否定推理表现的影响。研究结果表明，进行许多次微调后，RoBERTa和DeBERTa模型可以成功解决ScoNe-NLI。对于上下文学习方面，大多数提示策略都无法成功，但在嵌入否定推理的短故事的句子完成测试中，InstructGPT是成功的。

    

    最近的一些基准测试试图评估模型处理自然语言否定的能力。然而，这些基准测试缺乏受控的示例范例，无法推断模型是否已经学会了否定语素的语义作用。为了填补这些分析上的空白，我们提出了Scoped Negation NLI (ScoNe-NLI)基准测试，其中包含六个对比示例组成的集合，其中包括多达两个否定语素，其中零个、一个或两个否定语素影响NLI标签。我们使用ScoNe-NLI评估微调和上下文学习策略。我们发现RoBERTa和DeBERTa模型在进行许多次微调之后可以解决ScoNe-NLI。在上下文学习方面，我们测试了InstructGPT模型，并发现大多数提示策略都不成功，包括那些使用逐步推理的策略。为了更好地理解这个结果，我们将ScoNe扩展为ScoNe-NLG，这是一个嵌入了否定推理的短故事的句子完成测试集。在这里，InstructGPT是成功的，揭示了...

    A number of recent benchmarks seek to assess how well models handle natural language negation. However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had learned how negation morphemes semantically scope. To fill these analytical gaps, we present the Scoped Negation NLI (ScoNe-NLI) benchmark, which contains contrast sets of six examples with up to two negations where either zero, one, or both negative morphemes affect the NLI label. We use ScoNe-NLI to assess fine-tuning and in-context learning strategies. We find that RoBERTa and DeBERTa models solve ScoNe-NLI after many shot fine-tuning. For in-context learning, we test InstructGPT models and find that most prompt strategies are not successful, including those using step-by-step reasoning. To better understand this result, we extend ScoNe with ScoNe-NLG, a sentence completion test set that embeds negation reasoning in short narratives. Here, InstructGPT is successful, which reveal
    
[^31]: 针对检测宣传技术的分层多实例多标签学习

    Hierarchical Multi-Instance Multi-Label Learning for Detecting Propaganda Techniques. (arXiv:2305.19419v1 [cs.CL])

    [http://arxiv.org/abs/2305.19419](http://arxiv.org/abs/2305.19419)

    本文提出了一种可以同时对所有段落进行宣传技术分类的多实例多标签（MIML）学习方法，并为模型引入了层次性标签依赖关系，许多现有的方法都忽略了这一点。

    

    自从SemEval 2020任务11（Martino等，2020a）推出以来，文献中提出了多种方法以基于修辞技巧分类宣传内容去影响读者。然而，这些方法一次只能对某个段落进行分类，忽略了同一上下文其他段落标签的依赖关系。在本文中，我们将宣传技术分类作为一种多实例多标签（MIML）学习问题（Zhou等，2012），并提出了一个简单的基于RoBERTa的模型（Zhuang等，2021）来同时分类文章中的所有段落。此外，我们还注意到，由于注释过程，标注者按照决策树对这些段落进行了分类，从而形成了不同技巧之间的层次关系，而现有的方法却忽略了这些层次关系。我们通过为训练目标中的每个节点添加辅助分类器来并入这些分层标签依赖关系，并优化模型。

    Since the introduction of the SemEval 2020 Task 11 (Martino et al., 2020a), several approaches have been proposed in the literature for classifying propaganda based on the rhetorical techniques used to influence readers. These methods, however, classify one span at a time, ignoring dependencies from the labels of other spans within the same context. In this paper, we approach propaganda technique classification as a Multi-Instance Multi-Label (MIML) learning problem (Zhou et al., 2012) and propose a simple RoBERTa-based model (Zhuang et al., 2021) for classifying all spans in an article simultaneously. Further, we note that, due to the annotation process where annotators classified the spans by following a decision tree, there is an inherent hierarchical relationship among the different techniques, which existing approaches ignore. We incorporate these hierarchical label dependencies by adding an auxiliary classifier for each node in the decision tree to the training objective and ense
    
[^32]: 分析自然语言处理在儿童保护服务中的种族偏见风险

    Examining risks of racial biases in NLP tools for child protective services. (arXiv:2305.19409v1 [cs.CL])

    [http://arxiv.org/abs/2305.19409](http://arxiv.org/abs/2305.19409)

    本研究调查了儿童保护服务中自然语言处理模型存在的种族偏见问题，并发现了NER模型一致存在算法不公平的情况，同时可能出现指代消解和风险预测中算法不公平的情况。

    

    虽然很多文献已经确认了自然语言处理模型中存在人口统计学偏见的问题，但是大部分研究都依赖于策划的偏见度量指标，这可能不能反映现实世界的应用。同时，从业人员越来越多地在高风险环境中使用算法工具，特别是在自然语言处理领域。本研究聚焦在儿童保护服务中的一种情况。儿童保护服务工作者经常写有关他们所服务的家庭的详细文本笔记，而儿童保护机构正在积极寻求部署自然语言处理模型来利用这些数据。鉴于在这个环境中已经存在的种族偏见，我们调查了部署的自然语言处理模型可能增加种族差异的可能途径。我们特别审查了笔记中的词汇统计和风险预测、指代消解和命名实体识别（NER）中的算法公平性。我们记录了NER模型的一致算法不公平性，并可能出现指代消解和风险预测中算法不公平的情况。

    Although much literature has established the presence of demographic bias in natural language processing (NLP) models, most work relies on curated bias metrics that may not be reflective of real-world applications. At the same time, practitioners are increasingly using algorithmic tools in high-stakes settings, with particular recent interest in NLP. In this work, we focus on one such setting: child protective services (CPS). CPS workers often write copious free-form text notes about families they are working with, and CPS agencies are actively seeking to deploy NLP models to leverage these data. Given well-established racial bias in this setting, we investigate possible ways deployed NLP is liable to increase racial disparities. We specifically examine word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER). We document consistent algorithmic unfairness in NER models, possible algorithmic unfairness in corefe
    
[^33]: 上下文视觉变换器用于强健的表示学习

    Contextual Vision Transformers for Robust Representation Learning. (arXiv:2305.19402v1 [cs.CV])

    [http://arxiv.org/abs/2305.19402](http://arxiv.org/abs/2305.19402)

    上下文视觉变换器(ContextViT)用于生成图像的鲁棒特征表示，引入了一个额外的上下文令牌，可以解释掉特定于组的协变量结构，同时保持跨组共享的核心视觉特征，能够在监督微调、半监督学习以及主动学习等方面得到应用。

    

    本文介绍了一种上下文视觉变换器(ContextViT)的方法，用于生成图像的鲁棒特征表示，特别是针对表现出分组结构的图像，如协变量。ContextViT引入了一个额外的上下文令牌来编码特定于组的信息，允许模型解释掉特定于组的协变量结构，同时保持跨组共享的核心视觉特征。具体而言，在给定输入图像的情况下，Context-ViT将共享相同协变量的图像映射到该上下文令牌，并添加到输入图像令牌中，以捕获将模型条件化为组成员身份的效果。此外，我们还引入了一个上下文推断网络，可以在运行时预测这些令牌，只需要给出一些来自组分布的样本即可，使得ContextViT可以推广到新的测试分布。我们通过各种应用程序说明了ContextViT的性能。在监督微调中，我们证明了将预训练的ViTs与额外的上下文令牌相结合可以提高图像分类基准的准确性。我们还展示了ContextViT可以用于半监督学习，在CIFAR-10数据集上仅使用10%的标记样本即可实现最先进的表现。最后，我们展示了ContextViT可以通过引导选择来自少数群体的更具信息价值的样本，从而提高主动学习的效率。

    We present Contextual Vision Transformers (ContextViT), a method for producing robust feature representations for images exhibiting grouped structure such as covariates. ContextViT introduces an extra context token to encode group-specific information, allowing the model to explain away group-specific covariate structures while keeping core visual features shared across groups. Specifically, given an input image, Context-ViT maps images that share the same covariate into this context token appended to the input image tokens to capture the effects of conditioning the model on group membership. We furthermore introduce a context inference network to predict such tokens on the fly given a few samples from a group distribution, enabling ContextViT to generalize to new testing distributions at inference time. We illustrate the performance of ContextViT through a diverse range of applications. In supervised fine-tuning, we demonstrate that augmenting pre-trained ViTs with additional context 
    
[^34]: 针对低资源语言的文本到语音自动 MOS 预测的资源有效微调策略

    Resource-Efficient Fine-Tuning Strategies for Automatic MOS Prediction in Text-to-Speech for Low-Resource Languages. (arXiv:2305.19396v1 [eess.AS])

    [http://arxiv.org/abs/2305.19396](http://arxiv.org/abs/2305.19396)

    本文通过在低资源语言 West Frisian 上的测试发现，在预训练 BVCC 数据集后，微调 SOMOS 数据集能够得到最佳精度。使用超过总数据的 30% 并不能显著提高精度。使用来自单个听众的数据进行微调的实验表明，这种方法有望提高系统级精度，支持单参与者试验的可行性。

    

    我们使用开放数据集 BVCC 和 SOMOS 基于 wav2vec 2.0 训练了一个 MOS 预测模型。我们在低资源语言 West Frisian 上进行测试，结果表明在 SOMOS 微调前先在 BVCC 上进行预训练，可以得到最佳的微调和零样本预测精度。进一步的微调实验表明，使用超过总数据的 30% 并不会带来显著的改进。此外，使用来自单个听众的数据进行微调的实验表明，这种方法有望提高系统级精度，支持单参与者试验的可行性。这些发现可以在资源有限的情况下为低资源语言的 TTS 开发提供帮助，进一步推进零样本 MOS 预测并指导早期评估中的测试设计。

    We train a MOS prediction model based on wav2vec 2.0 using the open-access data sets BVCC and SOMOS. Our test with neural TTS data in the low-resource language (LRL) West Frisian shows that pre-training on BVCC before fine-tuning on SOMOS leads to the best accuracy for both fine-tuned and zero-shot prediction. Further fine-tuning experiments show that using more than 30 percent of the total data does not lead to significant improvements. In addition, fine-tuning with data from a single listener shows promising system-level accuracy, supporting the viability of one-participant pilot tests. These findings can all assist the resource-conscious development of TTS for LRLs by progressing towards better zero-shot MOS prediction and informing the design of listening tests, especially in early-stage evaluation.
    
[^35]: DyGen: 通过动态增强的生成建模从噪声标签中学习

    DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling. (arXiv:2305.19395v1 [cs.CL])

    [http://arxiv.org/abs/2305.19395](http://arxiv.org/abs/2305.19395)

    DyGen是一个动态增强的生成模型，使用嵌入空间中的动态模式可以改善从噪声标签中学习的精度，同时使用共规正则化机制来最小化潜在噪声标签和先验的影响，展示了最先进的性能。

    

    在许多实际应用中，训练数据可能包含不正确或已损坏的标签，从噪声标签中学习是一个挑战。当使用带有噪声标签的语言模型进行微调时，模型很容易过度拟合标签噪声，导致性能下降。大多数现有的从噪声标签中学习的方法使用静态输入特征进行去噪，但这些方法受限于它们在真实标签分布方面提供的信息，可能导致有偏的或不正确的预测。在这项工作中，我们提出了一个名为DyGen的动态增强生成模型，该模型在语言模型的微调过程中利用嵌入空间中的动态模式来改善噪声标签预测。DyGen使用变分自动编码框架从噪声标签和训练动态中推断真实标签的后验分布。此外，使用共规正则化机制来最小化潜在噪声标签和先验的影响。在存在不同级别的标签噪声情况下，DyGen在两个大规模文本分类数据集上展示了最先进的性能。

    Learning from noisy labels is a challenge that arises in many real-world applications where training data can contain incorrect or corrupted labels. When fine-tuning language models with noisy labels, models can easily overfit the label noise, leading to decreased performance. Most existing methods for learning from noisy labels use static input features for denoising, but these methods are limited by the information they can provide on true label distributions and can result in biased or incorrect predictions. In this work, we propose the Dynamics-Enhanced Generative Model (DyGen), which uses dynamic patterns in the embedding space during the fine-tuning process of language models to improve noisy label predictions. DyGen uses the variational auto-encoding framework to infer the posterior distributions of true labels from noisy labels and training dynamics. Additionally, a co-regularization mechanism is used to minimize the impact of potentially noisy labels and priors. DyGen demonstr
    
[^36]: 使用lambeq工具包的量子自然语言处理在情感分析中的应用

    Quantum Natural Language Processing based Sentiment Analysis using lambeq Toolkit. (arXiv:2305.19383v1 [quant-ph])

    [http://arxiv.org/abs/2305.19383](http://arxiv.org/abs/2305.19383)

    本文在情感分析中第一次应用了量子自然语言处理（QNLP），通过利用lambeq QNLP工具包和剑桥量子（Quantinuum）的$t|ket>$，在三种模拟和噪声量子设备上取得了完美测试集准确性和相当的准确性。

    

    情感分类是经典自然语言处理中最好的应用之一，在银行、商业和营销行业等各个日常领域中，我们可以见证其力量。我们已经知道了经典AI和机器学习如何改变和改进技术。量子自然语言处理（QNLP）是一种年轻而逐渐出现的技术，它具有为NLP任务提供量子优势的潜力。在本文中，我们展示了QNLP在情感分析中的第一个应用，并在三种不同类型的模拟和在噪声量子设备上运行的实验中实现了完美的测试集准确性和相当的准确性。我们利用了lambeq QNLP工具包和剑桥量子（Quantinuum）的$t|ket>$来呈现结果。

    Sentiment classification is one the best use case of classical natural language processing (NLP) where we can witness its power in various daily life domains such as banking, business and marketing industry. We already know how classical AI and machine learning can change and improve technology. Quantum natural language processing (QNLP) is a young and gradually emerging technology which has the potential to provide quantum advantage for NLP tasks. In this paper we show the first application of QNLP for sentiment analysis and achieve perfect test set accuracy for three different kinds of simulations and a decent accuracy for experiments ran on a noisy quantum device. We utilize the lambeq QNLP toolkit and $t|ket>$ by Cambridge Quantum (Quantinuum) to bring out the results.
    
[^37]: 通过挖掘临床笔记中的主题识别心力衰竭患者的表型并预测住院时间

    Mining Themes in Clinical Notes to Identify Phenotypes and to Predict Length of Stay in Patients admitted with Heart Failure. (arXiv:2305.19373v1 [cs.LG])

    [http://arxiv.org/abs/2305.19373](http://arxiv.org/abs/2305.19373)

    本文采用主题建模技术对1200例心力衰竭患者的诊断编码和程序报告中存在的主题进行识别，旨在从中识别心力衰竭的临床表型并预测病人住院时间。

    

    心力衰竭是一种综合征，当心脏无法泵血和输送氧气以支持体内其他器官时出现。识别接受心力衰竭治疗的病人的诊断编码和程序报告中的潜在主题，可以揭示与心力衰竭相关的临床表型，并根据相似的特征对病人进行分组，这也有助于预测病人的住院时间。由于这些临床表型通常具有概率的潜在结构，并且之前没有关于使用概率框架在心力衰竭患者的临床笔记中识别表型和使用数据驱动的基于人工智能的方法预测这些患者的住院时间的研究，因此我们采用自然语言处理技术——主题建模，对伊利诺伊大学医院1200例心力衰竭患者的诊断编码和程序报告中存在的主题进行识别。

    Heart failure is a syndrome which occurs when the heart is not able to pump blood and oxygen to support other organs in the body. Identifying the underlying themes in the diagnostic codes and procedure reports of patients admitted for heart failure could reveal the clinical phenotypes associated with heart failure and to group patients based on their similar characteristics which could also help in predicting patient outcomes like length of stay. These clinical phenotypes usually have a probabilistic latent structure and hence, as there has been no previous work on identifying phenotypes in clinical notes of heart failure patients using a probabilistic framework and to predict length of stay of these patients using data-driven artificial intelligence-based methods, we apply natural language processing technique, topic modeling, to identify the themes present in diagnostic codes and in procedure reports of 1,200 patients admitted for heart failure at the University of Illinois Hospital 
    
[^38]: 大型长序列模型的块级并行Transformer

    Blockwise Parallel Transformer for Long Context Large Models. (arXiv:2305.19370v1 [cs.CL])

    [http://arxiv.org/abs/2305.19370](http://arxiv.org/abs/2305.19370)

    本文提出了块级并行Transformer方法，以最小化内存成本，能够处理长序列，并且可以处理比先前的内存高效方法更长32倍的训练序列。

    

    Transformer已经成为最先进的自然语言处理模型的基石，在各种AI应用中展现出出色的性能。然而，Transformer中的自我注意机制和大型前馈网络所需的内存容量限制了它们处理长序列的能力，从而为涉及多个长序列或长期依赖的任务带来了挑战。我们提出了一种独特的方法，块级并行Transformer（BPT），它利用块级计算自我注意和前馈网络融合以最小化内存成本。通过在保持内存效率的同时处理更长的输入序列，BPT使训练序列的长度比原始的Transformer长32倍，比先前的内存高效方法长2到4倍。对语言建模和强化学习任务进行的大量实验证明了BPT在减少内存需求和提高性能方面的有效性。

    Transformers have emerged as the cornerstone of state-of-the-art natural language processing models, showcasing exceptional performance across a wide range of AI applications. However, the memory demands posed by the self-attention mechanism and the large feedforward network in Transformers limit their ability to handle long sequences, thereby creating challenges for tasks involving multiple long sequences or long-term dependencies. We present a distinct approach, Blockwise Parallel Transformer (BPT), that leverages blockwise computation of self-attention and feedforward network fusion to minimize memory costs. By processing longer input sequences while maintaining memory efficiency, BPT enables training sequences up to 32 times longer than vanilla Transformers and 2 to 4 times longer than previous memory-efficient methods. Extensive experiments on language modeling and reinforcement learning tasks demonstrate the effectiveness of BPT in reducing memory requirements and improving perfo
    
[^39]: 稳健的各向异性正则化

    Stable Anisotropic Regularization. (arXiv:2305.19358v1 [cs.CL])

    [http://arxiv.org/abs/2305.19358](http://arxiv.org/abs/2305.19358)

    本文提出了一种新颖的正则化方法I-STAR，可以增加模型的稳定性，提高性能，并改善自然语言处理中的组合表示问题。

    

    鉴于大型语言模型（LLMs）的成功，研究模型激活的属性已引起了相当大的兴趣。文献普遍认为LLMs表示由少数具有极高方差和幅度的“异常维度”主导。自然语言处理（NLP）中的几项研究试图减轻这些异常维度的影响，并迫使LLMs成为各向同性（即在嵌入空间中所有维度具有均匀方差）的。各向同性被认为是LLMs的一种理想属性，可以提高模型性能并更加贴近人类直觉的文本表示。然而，关于NLP中各向同性的许多观点都是基于嵌入的平均余弦相似度，最近已经表明这是一种有缺陷的各向同性度量。在本文中，我们提出了I-STAR：基于IsoScore$^{\star}$的稳定各向异性正则化，这是一种新颖的正则化方法，可以用于增加模型的稳定性并提高性能。

    Given the success of Large Language Models (LLMs), there has been considerable interest in studying the properties of model activations. The literature overwhelmingly agrees that LLM representations are dominated by a few ``outlier dimensions'' with exceedingly high variance and magnitude. Several studies in Natural Language Processing (NLP) have sought to mitigate the impact of such outlier dimensions and force LLMs to be isotropic (i.e., have uniform variance across all dimensions in embedding space). Isotropy is thought to be a desirable property for LLMs that improves model performance and more closely aligns textual representations with human intuition. However, many of the claims regarding isotropy in NLP have been based on the average cosine similarity of embeddings, which has recently been shown to be a flawed measure of isotropy. In this paper, we propose I-STAR: IsoScore$^{\star}$-based STable Anisotropic Regularization, a novel regularization method that can be used to incre
    
[^40]: infoVerse：一种用多维度元信息对数据集进行特征化的通用框架

    infoVerse: A Universal Framework for Dataset Characterization with Multidimensional Meta-information. (arXiv:2305.19344v1 [cs.CL])

    [http://arxiv.org/abs/2305.19344](http://arxiv.org/abs/2305.19344)

    本文介绍了一种通用的数据集特征化框架infoVerse，通过结合各种模型驱动的元信息提供了一个新的特征空间，能够有效地捕捉数据集的多维特征，有助于用户或模型确定哪些样本需要关注。

    

    NLP系统的成功往往依赖于大量高质量的数据集。然而，这些数据集中并非所有样本都同样有利于学习，因为有些可能是冗余或带有噪声。已经开发了几种基于模型驱动元信息（例如模型的置信度）的数据集特征化方法，但这些方法之间的关系和互补效应受到的关注较少。在本文中，我们介绍了infoVerse，这是一种通用的数据集特征化框架，它通过结合各种模型驱动的元信息提供了一个新的特征空间，有效地捕捉了数据集的多维特征。infoVerse揭示了数据集中在原始语义空间中不明显的独特区域，从而引导用户（或模型）确定哪些样本需要关注以进行探索、评估或注释。此外，我们还在infoVerse上提出了一种新的采样方法来选择一组数据点。

    The success of NLP systems often relies on the availability of large, high-quality datasets. However, not all samples in these datasets are equally valuable for learning, as some may be redundant or noisy. Several methods for characterizing datasets based on model-driven meta-information (e.g., model's confidence) have been developed, but the relationship and complementary effects of these methods have received less attention. In this paper, we introduce infoVerse, a universal framework for dataset characterization, which provides a new feature space that effectively captures multidimensional characteristics of datasets by incorporating various model-driven meta-information. infoVerse reveals distinctive regions of the dataset that are not apparent in the original semantic space, hence guiding users (or models) in identifying which samples to focus on for exploration, assessment, or annotation. Additionally, we propose a novel sampling method on infoVerse to select a set of data points
    
[^41]: 

    Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses. (arXiv:2305.19339v1 [cs.CL])

    [http://arxiv.org/abs/2305.19339](http://arxiv.org/abs/2305.19339)

    

    

    

    A human decision-maker benefits the most from an AI assistant that corrects for their biases. For problems such as generating interpretation of a radiology report given findings, a system predicting only highly likely outcomes may be less useful, where such outcomes are already obvious to the user. To alleviate biases in human decision-making, it is worth considering a broad differential diagnosis, going beyond the most likely options. We introduce a new task, "less likely brainstorming," that asks a model to generate outputs that humans think are relevant but less likely to happen. We explore the task in two settings: a brain MRI interpretation generation setting and an everyday commonsense reasoning setting. We found that a baseline approach of training with less likely hypotheses as targets generates outputs that humans evaluate as either likely or irrelevant nearly half of the time; standard MLE training is not effective. To tackle this problem, we propose a controlled text generat
    
[^42]: 大型语言模型改善多模态数据诊断阿尔茨海默病

    Large language models improve Alzheimer's disease diagnosis using multi-modality data. (arXiv:2305.19280v1 [cs.LG])

    [http://arxiv.org/abs/2305.19280](http://arxiv.org/abs/2305.19280)

    本研究使用大型语言模型提高对非影像数据的应用能力，并在ADNI数据集上实现了SOTA结果。

    

    在诊断像阿尔茨海默病（AD）这样的艰难病症时，影像是一个重要的参考。非影像患者数据（例如患者信息、遗传数据、药物信息、认知和记忆测试）在诊断中也起着非常重要的作用。然而，由于人工智能模型挖掘这些信息的能力受限，大部分现有模型只能使用多模态影像数据，而不能充分利用非影像数据。我们使用目前非常流行的预训练大型语言模型（LLM），以增强模型使用非影像数据的能力，并在ADNI数据集上实现了SOTA的结果。

    In diagnosing challenging conditions such as Alzheimer's disease (AD), imaging is an important reference. Non-imaging patient data such as patient information, genetic data, medication information, cognitive and memory tests also play a very important role in diagnosis. Effect. However, limited by the ability of artificial intelligence models to mine such information, most of the existing models only use multi-modal image data, and cannot make full use of non-image data. We use a currently very popular pre-trained large language model (LLM) to enhance the model's ability to utilize non-image data, and achieved SOTA results on the ADNI dataset.
    
[^43]: 基于大语言模型的特定领域语言生成中的语法提示

    Grammar Prompting for Domain-Specific Language Generation with Large Language Models. (arXiv:2305.19234v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.19234](http://arxiv.org/abs/2305.19234)

    本文提出了一种基于语法提示的方法，使用专用的语法来增强示例，为大型语言模型（LLM）在特定领域的语言生成任务中使用外部知识和特定约束条件进行上下文学习。

    

    大型语言模型（LLM）可以从仅有几个上下文示例中学习执行各种自然语言任务。然而，对于从高度结构化的语言（例如，从语义解析到复杂的特定领域语言）生成字符串，LLM只从少量示例中进行泛化是具有挑战性的。我们探讨了$\textbf{语法提示}$作为一种简单的方法，通过在背科斯-诺尔范式（BNF）中表达的语法来启用LLM使用外部知识和特定领域的约束条件来进行上下文学习。语法提示使用一个专门的语法来增强每个演示示例，该语法足以生成特定的输出示例，其中该专门的语法是全DSL语法的子集。对于推理，LLM首先预测一个给定测试输入的BNF语法，然后根据语法规则生成输出。实验表明，语法提示可以使LLM在特定领域的语言生成任务中表现出色。

    Large language models (LLMs) can learn to perform a wide range of natural language tasks from just a handful of in-context examples. However, for generating strings from highly structured languages (e.g., semantic parsing to complex domain-specific languages), it is challenging for the LLM to generalize from just a few exemplars. We explore $\textbf{grammar prompting}$ as a simple approach for enabling LLMs to use external knowledge and domain-specific constraints, expressed through a grammar expressed in Backus--Naur Form (BNF), during in-context learning. Grammar prompting augments each demonstration example with a specialized grammar that is minimally sufficient for generating the particular output example, where the specialized grammar is a subset of the full DSL grammar. For inference, the LLM first predicts a BNF grammar given a test input, and then generates the output according to the rules of the grammar. Experiments demonstrate that grammar prompting can enable LLMs to perfor
    
[^44]: 通过隐藏表示转换实现的可控文本生成

    Controlled Text Generation with Hidden Representation Transformations. (arXiv:2305.19230v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.19230](http://arxiv.org/abs/2305.19230)

    我们提出了CHRT，它是一种可控语言生成框架，通过学习表示转换来修改基础模型的隐藏表示从而获得属性控制。实验证明，CHRT在三个属性上表现均优于所有基线模型，同时最小化了在语言质量上的损失。

    

    我们提出了CHRT(Control Hidden Representation Transformation)，它是一种可控语言生成框架，可以引导大型语言模型生成特定属性的文本(如有毒性文本)。CHRT通过学习表示转换从而修改基础模型的隐藏表示来获得属性控制。我们采用对比学习框架来学习这些表示转换，可以结合使用以获得多属性控制。通过在三个属性上与七个基线模型进行比较，实验证明了CHRT的有效性。CHRT在解毒、正面情感引导和文本简化任务中表现均优于所有基线模型，同时最小化了在语言质量上的损失。此外，我们的方法推断延迟仅比基础模型多0.01秒，是最适合高性能生产环境的方法。我们开放源代码并发布了两个新的数据集，以进一步推动可控文本生成的发展。

    We propose CHRT (Control Hidden Representation Transformation) - a controlled language generation framework that steers large language models to generate text pertaining to certain attributes (such as toxicity). CHRT gains attribute control by modifying the hidden representation of the base model through learned transformations. We employ a contrastive-learning framework to learn these transformations that can be combined to gain multi-attribute control. The effectiveness of CHRT is experimentally shown by comparing it with seven baselines over three attributes. CHRT outperforms all the baselines in the task of detoxification, positive sentiment steering, and text simplification while minimizing the loss in linguistic qualities. Further, our approach has the lowest inference latency of only 0.01 seconds more than the base model, making it the most suitable for high-performance production environments. We open-source our code and release two novel datasets to further propel controlled l
    
[^45]: 交叉编码作为数据增强方法：实现有效的教育文本分类

    Cross Encoding as Augmentation: Towards Effective Educational Text Classification. (arXiv:2305.18977v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18977](http://arxiv.org/abs/2305.18977)

    本文提出了一种新颖的检索方法CEAA，将交叉编码作为数据增强方法应用在教育文本分类中，能够解决教育文本分类中的数据稀缺问题，有效提高分类精度。

    

    教育文本分类，通常称为自动标记，是将相关标记自动分配给教育内容（如问题和教科书）的自动化过程。然而，自动标记面临着数据稀缺问题，这源于两个主要挑战：1）它具有大的标记空间；2）它是多标签的。尽管检索方法在低资源情况下表现良好，但在直接解决数据稀缺问题方面的努力较少。为了缓解这些问题，我们提出了一种新颖的检索方法CEAA，为教育文本分类提供有效的学习。我们的主要贡献如下：1）我们利用来自问答数据集的迁移学习；2）我们提出了一种简单但有效的数据增强方法，将交叉编码风格的文本引入到双编码器架构中，以实现更高效的推理。大量实验证明我们的方法在多标签场景和低资源情况下都十分有效。

    Text classification in education, usually called auto-tagging, is the automated process of assigning relevant tags to educational content, such as questions and textbooks. However, auto-tagging suffers from a data scarcity problem, which stems from two major challenges: 1) it possesses a large tag space and 2) it is multi-label. Though a retrieval approach is reportedly good at low-resource scenarios, there have been fewer efforts to directly address the data scarcity problem. To mitigate these issues, here we propose a novel retrieval approach CEAA that provides effective learning in educational text classification. Our main contributions are as follows: 1) we leverage transfer learning from question-answering datasets, and 2) we propose a simple but effective data augmentation method introducing cross-encoder style texts to a bi-encoder architecture for more efficient inference. An extensive set of experiments shows that our proposed method is effective in multi-label scenarios and l
    
[^46]: 视觉语言模型的可扩展性能分析

    Scalable Performance Analysis for Vision-Language Models. (arXiv:2305.18786v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.18786](http://arxiv.org/abs/2305.18786)

    本文提出了一种可扩展的视觉语言基准测试方案，它可以利用已有的注释基准测试，并通过提取多种不同的特征来测量模型输出的相关性。实验结果发现，CLIP模型类似于词袋模型，在名词和动词方面表现良好，但容易被具体词汇困扰。

    

    联合视觉语言模型已经在各种任务中表现出良好的性能。 然而，由于这些模型学习的高维空间使得识别语义错误变得困难，因此我们对它们的限制知之甚少。 最近的工作通过设计高度可控的探测任务基准来解决这个问题。 本文提出了一种更可扩展的解决方案，该方案依赖于已注释的基准。 我们的方法包括从视觉语言基准中提取大量不同的特征，并测量它们与目标模型的输出之间的相关性。我们确认先前的研究结果，即CLIP类似于词袋模型，并且在名词和动词方面表现更好; 我们还发现了一些新的见解，例如CLIP被具体的词汇困扰。我们的框架可在https://github.com/MichiganNLP/Scalable-VLM-Probing上获得，在其他多模式模型和基准测试中也可以使用。

    Joint vision-language models have shown great performance over a diverse set of tasks. However, little is known about their limitations, as the high dimensional space learned by these models makes it difficult to identify semantic errors. Recent work has addressed this problem by designing highly controlled probing task benchmarks. Our paper introduces a more scalable solution that relies on already annotated benchmarks. Our method consists of extracting a large set of diverse features from a vision-language benchmark and measuring their correlation with the output of the target model. We confirm previous findings that CLIP behaves like a bag of words model and performs better with nouns and verbs; we also uncover novel insights such as CLIP getting confused by concrete words. Our framework is available at https://github.com/MichiganNLP/Scalable-VLM-Probing and can be used with other multimodal models and benchmarks.
    
[^47]: 超越一个模型适用于所有领域：大型语言模型的领域专门化综述

    Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models. (arXiv:2305.18703v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18703](http://arxiv.org/abs/2305.18703)

    本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    

    大型语言模型（LLM）已经大大推动了自然语言处理（NLP）领域的发展，为广泛应用提供了高度实用、任务无关的基础。LLMs 作为通用任务求解器的巨大潜力，促使人们将其用于特定领域，如医疗保健、金融和教育，并将其用作助手甚至替代特定领域的专家和工具。但是，将LLMs直接应用于特定领域中的复杂问题会遇到许多困难，包括领域数据的异质性、领域知识的复杂性、领域目标的独特性以及约束的多样性。为了填补这种差距，最近几年进行了急剧增加的研究和实践致力于大型语言模型的领域专门化，然而这方面的研究尚未被系统地总结。在这篇综述中，我们对LLMs的领域专门化进行了全面概述，包括动机、挑战、方法论和评估指标。此外，我们提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. The great promise of LLMs as general task solvers motivated people to extend their functionality largely beyond just a ``chatbot'', and use it as an assistant or even replacement for domain experts and tools in specific domains such as healthcare, finance, and education. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). To fill such a gap, explosively-increase research, and practices have been conducted in very recent years on the domain specialization of LLMs, which, howe
    
[^48]: 通过大型语言模型实现实用的PCG

    Practical PCG Through Large Language Models. (arXiv:2305.18243v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18243](http://arxiv.org/abs/2305.18243)

    本研究介绍了如何利用语言模型生成游戏房间，在仅有少量数据的情况下，可以生成多达37%的可玩新颖关卡，该技术有助于解决包含许多局部和全局约束的PCG问题。

    

    大型语言模型(LLMs)已经被证明是自然语言处理领域之外的各种领域中非常有用的工具。本研究提供了如何使用LLMs为正在开发中的游戏Metavoidal生成2D游戏房间的实用方向。我们的技术可以通过人类参与的微调，利用GPT-3的能力，仅使用60个手动设计的房间数据，在复杂的游戏场景下，生成37%的可玩新颖关卡，这是针对存在大量局部和全局约束的PCG的。

    Large Language Models (LLMs) have proven to be useful tools in various domains outside of the field of their inception, which was natural language processing. In this study, we provide practical directions on how to use LLMs to generate 2D-game rooms for an under-development game, named Metavoidal. Our technique can harness the power of GPT-3 by Human-in-the-loop fine-tuning which allows our method to create 37% Playable-Novel levels from as scarce data as only 60 hand-designed rooms under a scenario of the non-trivial game, with respect to (Procedural Content Generation) PCG, that has a good amount of local and global constraints.
    
[^49]: 递归的诅咒：使用生成数据进行训练会让模型忘记

    The Curse of Recursion: Training on Generated Data Makes Models Forget. (arXiv:2305.17493v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.17493](http://arxiv.org/abs/2305.17493)

    使用生成数据进行训练会导致模型不可逆的缺陷并且使得原始内容分布的尾部消失，这种效应称为模型折叠。我们证明了这种现象在所有学习生成模型中都存在，必须认真对待。

    

    稳定扩散技术革命性地改变了从描述性文本中生成图像的方法。GPT-2、GPT-3(.5)和GPT-4在各种语言任务中表现惊人。ChatGPT将这些语言模型引入了大众视野。大语言模型(LLMs)已经不可避免并将彻底改变在线文本和图像的整个生态系统。本文考虑了未来可能发生的事情。当LLMs占据了在线语言的大部分时，GPT-{n}会发生什么？我们发现，在训练中使用模型生成的内容会导致所得模型中不可逆缺陷，原始内容分布的尾部消失。我们将这种效应称为模型折叠，并显示它可以发生在变分自编码器、高斯混合模型和LLMs中。我们建立了现象背后的理论直觉，并展示了这种现象在所有学习生成模型中的普遍性。我们证明，如果我们要在实践中使用生成数据进行训练，就必须认真对待这一问题。

    Stable Diffusion revolutionised image creation from descriptive text. GPT-2, GPT-3(.5) and GPT-4 demonstrated astonishing performance across a variety of language tasks. ChatGPT introduced such language models to the general public. It is now clear that large language models (LLMs) are here to stay, and will bring about drastic change in the whole ecosystem of online text and images. In this paper we consider what the future might hold. What will happen to GPT-{n} once LLMs contribute much of the language found online? We find that use of model-generated content in training causes irreversible defects in the resulting models, where tails of the original content distribution disappear. We refer to this effect as Model Collapse and show that it can occur in Variational Autoencoders, Gaussian Mixture Models and LLMs. We build theoretical intuition behind the phenomenon and portray its ubiquity amongst all learned generative models. We demonstrate that it has to be taken seriously if we ar
    
[^50]: 一种从学术论文中提炼文本分类和对象识别的框架

    A Framework For Refining Text Classification and Object Recognition from Academic Articles. (arXiv:2305.17401v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.17401](http://arxiv.org/abs/2305.17401)

    本文提出了一种结合基于规则的方法和机器学习的框架，旨在解决从学术论文中提炼文本分类和对象识别的问题。

    

    随着互联网的广泛使用，高效地从大量学术论文中提取特定信息变得越来越重要。数据挖掘技术通常用于解决这个问题。然而，挖掘学术论文的数据具有挑战性，因为它需要自动从复杂的非结构化布局文档中提取特定模式。当前的学术论文数据挖掘方法使用基于规则的（RB）或机器学习（ML）方法。然而，使用基于规则的方法需要编写复杂排版论文的高昂成本。另一方面，仅使用机器学习方法需要对文章中复杂内容类型进行注释工作，这可能成本高昂。此外，仅使用机器学习可能会导致基于规则的方法容易识别的模式被错误提取的情况。为了解决这些问题，本文从分析指定著作中使用的标准布局和排版角度出发，提出了一种结合基于规则的方法和机器学习的框架。

    With the widespread use of the internet, it has become increasingly crucial to extract specific information from vast amounts of academic articles efficiently. Data mining techniques are generally employed to solve this issue. However, data mining for academic articles is challenging since it requires automatically extracting specific patterns in complex and unstructured layout documents. Current data mining methods for academic articles employ rule-based(RB) or machine learning(ML) approaches. However, using rule-based methods incurs a high coding cost for complex typesetting articles. On the other hand, simply using machine learning methods requires annotation work for complex content types within the paper, which can be costly. Furthermore, only using machine learning can lead to cases where patterns easily recognized by rule-based methods are mistakenly extracted. To overcome these issues, from the perspective of analyzing the standard layout and typesetting used in the specified p
    
[^51]: 纵览语言模型：缩减规模后的行为

    Honey, I Shrunk the Language: Language Model Behavior at Reduced Scale. (arXiv:2305.17266v1 [cs.CL])

    [http://arxiv.org/abs/2305.17266](http://arxiv.org/abs/2305.17266)

    本文研究了小规模语言模型的训练效果，并展示了掩码语言建模目标的预训练对性能的提高作用。同时，该研究还发现了计算成本与模型效果之间的相关性。

    

    近年来，语言模型的规模急剧增长，这些模型的能力也随着规模的扩大而得到了提高。大部分最近的规模研究都集中在高计算量，高参数的环境中，没有回答这些能力何时开始出现的问题。在本文中，我们研究了在问题规模减小的情况下是否可以观察到预训练的效果，建立了一个较小的、缩减了词汇量的语言模型。我们展示了在参数为125万的模型中使用掩码语言建模（MLM）目标预训练的好处，并建立了预训练困惑和下游性能（GLUE基准）之间的强相关性。我们研究缩小规模的影响，将缩放定律扩展到了大约100万个参数的模型中。在这个规模下，我们观察到了计算-最优模型的幂律破裂，并展示了MLM损失在低于22万亿FLOPs的计算成本下并不平滑地缩放。

    In recent years, language models have drastically grown in size, and the abilities of these models have been shown to improve with scale. The majority of recent scaling laws studies focused on high-compute high-parameter count settings, leaving the question of when these abilities begin to emerge largely unanswered. In this paper, we investigate whether the effects of pre-training can be observed when the problem size is reduced, modeling a smaller, reduced-vocabulary language. We show the benefits of pre-training with masked language modeling (MLM) objective in models as small as 1.25M parameters, and establish a strong correlation between pre-training perplexity and downstream performance (GLUE benchmark). We examine downscaling effects, extending scaling laws to models as small as ~1M parameters. At this scale, we observe a break of the power law for compute-optimal models and show that the MLM loss does not scale smoothly with compute-cost (FLOPs) below $2.2 \times 10^{15}$ FLOPs. 
    
[^52]: 论解码器Transformer语言模型的计算能力

    On the Computational Power of Decoder-Only Transformer Language Models. (arXiv:2305.17026v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17026](http://arxiv.org/abs/2305.17026)

    本篇论文研究了解码器Transformer语言模型的计算普适性，表明即使只有单层和单注意力头，仍然具有图灵完备性，其中单词嵌入的稀疏性/可压缩性是必要条件。

    

    本文章对解码器Transformer模型的计算普适性进行了理论评估。我们扩展了Transformer模型的理论文献，并表明仅使用单层和单注意力头的解码器Transformer结构，在合理假设下具备图灵完备性。从理论分析中，我们证明了单词嵌入的稀疏性/可压缩性是图灵完备性成立的必要条件。

    This article presents a theoretical evaluation of the computational universality of decoder-only transformer models. We extend the theoretical literature on transformer models and show that decoder-only transformer architectures (even with only a single layer and single attention head) are Turing complete under reasonable assumptions. From the theoretical analysis, we show sparsity/compressibility of the word embedding to be a necessary condition for Turing completeness to hold.
    
[^53]: GPT是否会产生更不准确的翻译?

    Do GPTs Produce Less Literal Translations?. (arXiv:2305.16806v1 [cs.CL])

    [http://arxiv.org/abs/2305.16806](http://arxiv.org/abs/2305.16806)

    本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。

    

    大型语言模型（LLMs），如GPT-3，已经成为通用语言模型，能够处理许多自然语言生成或理解任务。在机器翻译（MT）任务中，已有多项研究探索利用few-shot提示机制从LLMs中引出更好的翻译。然而，人们相对较少地关注这种翻译与标准神经机器翻译（NMT）模型生成翻译的质量差异。本研究从文字对齐和单调性等方面，比较了GPT和NMT生成翻译的文本文字积极度，发现GPT从英语（E-X）翻译的文本更不准确，但在MT质量评估指标上表现出相似或更好的分数。我们证明这一结果在人工评估中也得到了验证。同时，当翻译句子长度增加时，这种差别就尤为显著。

    Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose language models capable of addressing many natural language generation or understanding tasks. On the task of Machine Translation (MT), multiple works have investigated few-shot prompting mechanisms to elicit better translations from LLMs. However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models. In this work, we investigate these differences in terms of the literalness of translations produced by the two systems. Using literalness measures involving word alignment and monotonicity, we find that translations out of English (E-X) from GPTs tend to be less literal, while exhibiting similar or better scores on MT quality metrics. We demonstrate that this finding is borne out in human evaluations as well. We then show that these differences are especially pronounced when translating senten
    
[^54]: AdaPlanner:自适应规划与语言模型的反馈。 （arXiv：2305.16653v1 [cs.CL]）

    AdaPlanner: Adaptive Planning from Feedback with Language Models. (arXiv:2305.16653v1 [cs.CL])

    [http://arxiv.org/abs/2305.16653](http://arxiv.org/abs/2305.16653)

    LLM代理可以通过Adaplanner自适应改进自己的计划以应对环境反馈，为此提出计划内外的改进策略以及代码风格的LLM提示结构和技能发现机制。

    

    最近的大型语言模型（LLM）展示了在序列决策任务中作为自主代理的潜力。然而，大多数现有方法要么贪婪地采取行动而没有计划，要么依赖于不可适应环境反馈的静态计划。因此，随着问题复杂性和计划水平的增加，LLM代理的顺序决策性能会退化。我们提出了一种闭环方法AdaPlanner，它允许LLM代理根据环境反馈自适应地改进其自动生成的计划。在AdaPlanner中，LLM代理通过计划内和计划外的改进策略自适应地改进其计划。为了减轻幻觉，我们开发了一种代码风格的LLM提示结构，促进了跨各种任务，环境和代理能力的计划生成。此外，我们提出了一种技能发现机制，利用成功的计划作为少量示例，使计划更具普适性。

    Large language models (LLMs) have recently demonstrated the potential in acting as autonomous agents for sequential decision-making tasks. However, most existing methods either take actions greedily without planning or rely on static plans that are not adaptable to environmental feedback. Consequently, the sequential decision-making performance of LLM agents degenerates with problem complexity and plan horizons increase. We propose a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. In AdaPlanner, the LLM agent adaptively refines its plan from feedback with both in-plan and out-of-plan refinement strategies. To mitigate hallucination, we develop a code-style LLM prompt structure that facilitates plan generation across a variety of tasks, environments, and agent capabilities. Furthermore, we propose a skill discovery mechanism that leverages successful plans as few-shot exemplars, enabling the
    
[^55]: 基于最大化互信息的视频多模态融合去噪瓶颈模型

    Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion. (arXiv:2305.14652v1 [cs.CL])

    [http://arxiv.org/abs/2305.14652](http://arxiv.org/abs/2305.14652)

    本文提出了一种基于去噪瓶颈和最大化互信息的视频多模态融合模型（DBF），该模型可以细粒度地过滤掉冗余和噪声信息，同时保留不同模态中的关键信息，并在多语言视频分类任务中表现出显著优越性。

    

    视频多模态融合旨在将视频中的多模态信号（如视觉、音频和文本）整合，以使用多模态内容进行补充预测。然而，与其他图像-文本多模态任务不同，视频具有更长的多模态序列，在视觉和音频模态中存在更多的冗余和噪声。因此，我们提出了一种用于细粒度视频多模态融合的去噪瓶颈融合（DBF）模型。我们一方面采用瓶颈机制，以限制的感受野过滤噪声和冗余信息。另一方面，我们使用最大化互信息模块来调节过滤模块，以保留不同模态中的关键信息。我们的DBF模型在多语言视频分类任务中显著优于当前最先进的基准模型。

    Video multimodal fusion aims to integrate multimodal signals in videos, such as visual, audio and text, to make a complementary prediction with multiple modalities contents. However, unlike other image-text multimodal tasks, video has longer multimodal sequences with more redundancy and noise in both visual and audio modalities. Prior denoising methods like forget gate are coarse in the granularity of noise filtering. They often suppress the redundant and noisy information at the risk of losing critical information. Therefore, we propose a denoising bottleneck fusion (DBF) model for fine-grained video multimodal fusion. On the one hand, we employ a bottleneck mechanism to filter out noise and redundancy with a restrained receptive field. On the other hand, we use a mutual information maximization module to regulate the filter-out module to preserve key information within different modalities. Our DBF model achieves significant improvement over current state-of-the-art baselines on mult
    
[^56]: 论自然语言处理中的偏见和公平：如何构建更公正的文本分类？

    On Bias and Fairness in NLP: How to have a fairer text classification?. (arXiv:2305.12829v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12829](http://arxiv.org/abs/2305.12829)

    本文从上游偏见、样本偏见和过度放大偏见三方面分析了NLP模型中的偏见如何影响文本分类的公平性，并针对过度放大偏见通过微调语言模型达到公平分类效果。提出了构建公正文本分类模型的实用指南。

    

    本文全面分析了自然语言处理模型中不同来源的偏见，即上游偏见、样本偏见和过度放大偏见，以及它们对文本分类任务公平性的影响。我们还研究了使用不同去偏方法消除这些偏见对文本分类公平性的影响。研究发现过度放大偏见对文本分类公平性的影响最大。将语言模型在平衡不同类别身份群体的数据集上进行微调，可以去除过度放大偏见，进而构建更公正的文本分类模型。最后，我们基于研究发现提出了构建更公正的文本分类模型的实用指南。

    In this paper, we provide a holistic analysis of the different sources of bias, Upstream, Sample and Overampflication biases, in NLP models. We investigate how they impact the fairness of the task of text classification. We also investigate the impact of removing these biases using different debiasing techniques on the fairness of text classification. We found that overamplification bias is the most impactful bias on the fairness of text classification. And that removing overamplification bias by fine-tuning the LM models on a dataset with balanced representations of the different identity groups leads to fairer text classification models. Finally, we build on our findings and introduce practical guidelines on how to have a fairer text classification model.
    
[^57]: 自监督和弱监督多语言语音预训练在适应未知语言方面的比较研究

    Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech Pre-Training for Adaptation to Unseen Languages. (arXiv:2305.12606v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12606](http://arxiv.org/abs/2305.12606)

    本研究比较了自监督和弱监督多语言语音预训练在适应未知语言方面的效果，发现预训练期间每种语言及其语系出现的小时数可以预测模型的比较结果。

    

    最近的一些模型(如XLS-R和Whisper)通过对来自大约100种语言的音频进行预训练，使得多语言语音技术更加易用。然而，世界上有成千上万种语言，适应新语言是一个重要的问题。本研究旨在了解哪种模型更好地适应预训练时未见过的语言。我们在13种未见过的语言和18种已见过的语言上微调了两种模型。我们的结果表明，预训练期间每种语言及其语系出现的小时数可以预测模型的比较结果，尽管预训练方法存在显著差异。

    Recent models such as XLS-R and Whisper have made multilingual speech technologies more accessible by pre-training on audio from around 100 spoken languages each. However, there are thousands of spoken languages worldwide, and adapting to new languages is an important problem. In this work, we aim to understand which model adapts better to languages unseen during pre-training. We fine-tune both models on 13 unseen languages and 18 seen languages. Our results show that the number of hours seen per language and language family during pre-training is predictive of how the models compare, despite the significant differences in the pre-training methods.
    
[^58]: QUEST:一种利用隐式集合操作的实体搜索查询检索数据集( arXiv:2305.11694v1[cs.CL])

    QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set Operations. (arXiv:2305.11694v1 [cs.CL])

    [http://arxiv.org/abs/2305.11694](http://arxiv.org/abs/2305.11694)

    该研究构建了一个名为QUEST的检索数据集，其中含有3357个自然语言查询，这些查询使用隐式集合操作来满足有选择性的信息需求，这个数据集要求模型匹配查询中提到的条件，并正确执行集合操作。

    

    为满足有选择性的信息需求，我们可以使用隐式集合操作，例如交集、并集和差集。研究检索系统满足这种信息需求的能力，我们构建了QUEST数据集，其中包含3357个自然语言查询，这些查询具有隐式集合操作，同时对应于维基百科文档中的实体集。该数据集要求模型将查询中提到的多个约束条件与文档中相应的证据相匹配，并正确执行各种集合操作。该数据集是半自动构建的，使用维基百科类别名称自动组合查询，然后由众包工作者对其进行释义和自然度验证。众包工作者还根据文档评估实体的相关性，并突出显示查询的属性。

    Formulating selective information needs results in queries that implicitly specify set operations, such as intersection, union, and difference. For instance, one might search for "shorebirds that are not sandpipers" or "science-fiction films shot in England". To study the ability of retrieval systems to meet such information needs, we construct QUEST, a dataset of 3357 natural language queries with implicit set operations, that map to a set of entities corresponding to Wikipedia documents. The dataset challenges models to match multiple constraints mentioned in queries with corresponding evidence in documents and correctly perform various set operations. The dataset is constructed semi-automatically using Wikipedia category names. Queries are automatically composed from individual categories, then paraphrased and further validated for naturalness and fluency by crowdworkers. Crowdworkers also assess the relevance of entities based on their documents and highlight attribution of query c
    
[^59]: 关于大型多模态模型中OCR的隐秘之谜

    On the Hidden Mystery of OCR in Large Multimodal Models. (arXiv:2305.07895v1 [cs.CV])

    [http://arxiv.org/abs/2305.07895](http://arxiv.org/abs/2305.07895)

    本研究全面评估了现有大型多模态模型在文本相关的视觉任务中的表现，结果显示这些模型虽然在语义理解方面表现优异，但对单个字符形状的感知有限，对图像的细粒度特征检测能力也不足，不能与传统领域特定方法相匹配，并仍需进一步探索它们在OCR中的表现。

    

    近来，大型模型在自然语言处理和多模态视觉语言学习中扮演着支配性的角色。关于它们在文本相关的视觉任务中有效性的探索仍不够。我们对现有公开可用的多模态模型进行了全面的研究，评估了它们在文本识别、基于文本的视觉问答和关键信息提取方面的表现。我们的研究结果揭示了这些模型的优劣势，它们主要依赖于语义理解来识别单词，并表现出较差的对单个字符形状的感知。它们对文本长度漠不关心，在检测图像的细粒度特征方面具有有限的能力。因此，这些结果表明，即使当前最强大的大型多模态模型也无法与传统文本任务的领域特定方法相匹配，并在更复杂的任务中面临更大的挑战。最重要的是，本研究展示的基线结果揭示了大型多模态模型中OCR的隐秘之谜，仍需要进一步探索。

    Large models have recently played a dominant role in natural language processing and multimodal vision-language learning. It remains less explored about their efficacy in text-related visual tasks. We conducted a comprehensive study of existing publicly available multimodal models, evaluating their performance in text recognition, text-based visual question answering, and key information extraction. Our findings reveal strengths and weaknesses in these models, which primarily rely on semantic understanding for word recognition and exhibit inferior perception of individual character shapes. They also display indifference towards text length and have limited capabilities in detecting fine-grained features in images. Consequently, these results demonstrate that even the current most powerful large multimodal models cannot match domain-specific methods in traditional text tasks and face greater challenges in more complex tasks. Most importantly, the baseline results showcased in this study
    
[^60]: 全局和局部文脉在命名实体识别中的作用。

    The Role of Global and Local Context in Named Entity Recognition. (arXiv:2305.03132v1 [cs.CL])

    [http://arxiv.org/abs/2305.03132](http://arxiv.org/abs/2305.03132)

    研究者探讨了全局文档上下文与局部上下文在命名实体识别中的作用，发现正确检索全局文档上下文对提高性能至关重要。

    

    最近，预训练的基于转换器的模型在命名实体识别方面表现出色。由于其自我注意力机制的复杂性，它们不能一次处理长文档，因此这些模型通常是按顺序应用的。这种方法不幸地只包含局部上下文，并阻碍了利用全局文档上下文的可能性，这可能会妨碍性能。在本文中，我们探讨了全局文档上下文的影响及其与局部上下文的关系。我们发现，正确检索全局文档上下文对性能的影响大于仅利用局部文本。这促使进一步研究如何更好地检索上下文。

    Pre-trained transformer-based models have recently shown great performance when applied to Named Entity Recognition (NER). As the complexity of their self-attention mechanism prevents them from processing long documents at once, these models are usually applied in a sequential fashion. Such an approach unfortunately only incorporates local context and prevents leveraging global document context in long documents such as novels, which might hinder performance. In this article, we explore the impact of global document context, and its relationships with local context. We find that correctly retrieving global document context has a greater impact on performance than only leveraging local context, prompting for further research on how to better retrieve that context.
    
[^61]: 关于数据子群体间机器学习模型性能的非线性相关性

    On the nonlinear correlation of ML performance between data subpopulations. (arXiv:2305.02995v1 [cs.LG])

    [http://arxiv.org/abs/2305.02995](http://arxiv.org/abs/2305.02995)

    在不同数据子群体间，机器学习模型的内部准确性和外部准确性之间的相关性是非线性的，呈现出“月亮形”的相关性。

    

    理解机器学习模型在不同数据分布下的性能对于可靠的应用至关重要。尽管最新的经验研究认为训练数据内部的准确性和新数据外部的准确性之间存在近乎完美的线性相关性，但我们在各种数据集、模型和训练时期进行了严格的实验和分析，发现在子群体转移下，内部准确性和外部准确性之间的相关性更为微妙，并且在上升阶段存在“月亮形”的相关性（抛物线上升曲线）。

    Understanding the performance of machine learning (ML) models across diverse data distributions is critically important for reliable applications. Despite recent empirical studies positing a near-perfect linear correlation between in-distribution (ID) and out-of-distribution (OOD) accuracies, we empirically demonstrate that this correlation is more nuanced under subpopulation shifts. Through rigorous experimentation and analysis across a variety of datasets, models, and training epochs, we demonstrate that OOD performance often has a nonlinear correlation with ID performance in subpopulation shifts. Our findings, which contrast previous studies that have posited a linear correlation in model performance during distribution shifts, reveal a "moon shape" correlation (parabolic uptrend curve) between the test performance on the majority subpopulation and the minority subpopulation. This non-trivial nonlinear correlation holds across model architectures, hyperparameters, training durations
    
[^62]: 面向任务的端到端对话系统中的任务优化适配器

    Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System. (arXiv:2305.02468v1 [cs.CL])

    [http://arxiv.org/abs/2305.02468](http://arxiv.org/abs/2305.02468)

    本文提出了一种端到端任务导向对话系统，通过在预训练网络的固定层后添加少量参数的任务优化适配器来独立地学习每个任务，并通过强化学习提高DST和NLG模块的性能。

    

    任务导向对话系统旨在通过跟踪对话状态和生成适当的响应来执行特定任务，帮助用户实现定义的目标。最近，基于大型数据集预训练的端到端对话模型在对话系统中表现出了很好的性能。然而，它们共享相同的参数以训练对话系统的任务(NLU，DST，NLG)，因此每个任务的调试都很具有挑战性。此外，相较于PLM，将大量参数微调来创建面向任务的聊天机器人需要大量的努力，这使得非专家难以处理。因此，我们打算训练相对轻量级和快速的模型。本文提出了一种具有任务优化适配器的端到端任务导向对话系统，每个任务独立学习，在预训练网络的固定层之后仅添加少量参数。我们还通过强化学习提高了DST和NLG模块的性能，克服了学习曲线。

    Task-Oriented Dialogue (TOD) systems are designed to carry out specific tasks by tracking dialogue states and generating appropriate responses to help users achieve defined goals. Recently, end-to-end dialogue models pre-trained based on large datasets have shown promising performance in the conversational system. However, they share the same parameters to train tasks of the dialogue system (NLU, DST, NLG), so debugging each task is challenging. Also, they require a lot of effort to fine-tune large parameters to create a task-oriented chatbot, making it difficult for non-experts to handle. Therefore, we intend to train relatively lightweight and fast models compared to PLM. In this paper, we propose an End-to-end TOD system with Task-Optimized Adapters which learn independently per task, adding only small number of parameters after fixed layers of pre-trained network. We also enhance the performance of the DST and NLG modules through reinforcement learning, overcoming the learning curv
    
[^63]: Pythia：一套用于跨训练和扩展分析大型语言模型的工具套件

    Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling. (arXiv:2304.01373v1 [cs.CL])

    [http://arxiv.org/abs/2304.01373](http://arxiv.org/abs/2304.01373)

    本文介绍了一套名为 Pythia 的工具套件，包含 16 个大型语言模型，其大小从 70M 到 12B 参数不等。Pythia 可以帮助研究人员在多个领域开展研究，作者还提出了几个新的研究结果，在记忆、应用少量数据时的效果以及减少性别偏见等方面具有重要意义。

    

    本文介绍了一套名为Pythia的工具套件，其中包括16个大型语言模型，这些模型都是在完全相同的顺序下从公共数据中训练而来的，大小从70M到12B参数不等。作者公开了这16个模型的154个检查点，并提供了工具以下载和重构模型的exact training dataloaders以进行进一步研究。本文介绍了Pythia在多个领域中的应用，包括对记忆、减少性别偏见等方面的新颖研究结果，并演示了这种高度控制的设置如何用于获得有关语言模型及其训练动态的新见解。

    How do large language models (LLMs) develop and evolve over the course of training? How do these patterns change as models scale? To answer these questions, we introduce \textit{Pythia}, a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters. We provide public access to 154 checkpoints for each one of the 16 models, alongside tools to download and reconstruct their exact training dataloaders for further study. We intend \textit{Pythia} to facilitate research in many areas, and we present several case studies including novel results in memorization, term frequency effects on few-shot performance, and reducing gender bias. We demonstrate that this highly controlled setup can be used to yield novel insights toward LLMs and their training dynamics. Trained models, analysis code, training code, and training data can be found at https://github.com/EleutherAI/pythia.
    
[^64]: 利用强化学习将一个中等大小的英文GPT模型对齐到西班牙语的小封闭领域中

    Aligning a medium-size GPT model in English to a small closed domain in Spanish using reinforcement learning. (arXiv:2303.17649v1 [cs.CL])

    [http://arxiv.org/abs/2303.17649](http://arxiv.org/abs/2303.17649)

    本文介绍了一种将英文GPT模型对齐到西班牙语的小封闭领域中的方法，该方法使用了奖励模型来改进答案的解码和生成，在问答任务中取得了良好的结果。

    

    本文提出了一种方法，将原本用于开放领域的中等大小英文GPT模型，对齐到西班牙语的小封闭领域。该模型被精细调整用于问答任务。为了实现这一目标，我们还需要训练和实现另一个神经网络（我们称之为奖励模型），以评分并确定答案是否适用于给定的问题。该组件有助于改进系统回答的解码和生成。 BLEU和perplexity等数字度量标准被用于评估模型，同时也使用人类判断来比较解码技术与其他技术。最终，结果支持了所提出的方法，并确定使用奖励模型来对齐生成回答是可行的。

    In this paper, we propose a methodology to align a medium-sized GPT model, originally trained in English for an open domain, to a small closed domain in Spanish. The application for which the model is finely tuned is the question answering task. To achieve this we also needed to train and implement another neural network (which we called the reward model) that could score and determine whether an answer is appropriate for a given question. This component served to improve the decoding and generation of the answers of the system. Numerical metrics such as BLEU and perplexity were used to evaluate the model, and human judgment was also used to compare the decoding technique with others. Finally, the results favored the proposed method, and it was determined that it is feasible to use a reward model to align the generation of responses.
    
[^65]: cTBL：增强大型语言模型用于对话表格

    cTBL: Augmenting Large Language Models for Conversational Tables. (arXiv:2303.12024v1 [cs.CL])

    [http://arxiv.org/abs/2303.12024](http://arxiv.org/abs/2303.12024)

    本论文提出了一种称为cTBL的方法，可以从表格中检索信息，并生成具有检索信息支撑的对话响应，其中使用了转换器编码器嵌入进行浓密表检索，可以获得更好的性能。

    

    多模态对话人工智能中一个开放的挑战是如何从文本和非文本来源中增强大型语言模型以进行多轮对话。为了解决这个问题，本文引入了Conversation Table (cTBL)，这是一种三步编码器-解码器方法，用于检索表格信息并生成基于检索信息的对话响应。cTBL使用转换器编码器嵌入进行浓密表检索，并在HyrbiDialogue数据集Top-1和Top-3准确性上相对于稀疏检索提高了最多5%。此外，cTBL使用编码器和解码器模型进行表格知识检索，在HyrbiDialogue上产生了最高46%的ROUGE分数相对改进，并实现了更好的人工评估响应生成。

    An open challenge in multimodal conversational AI requires augmenting large language models with information from textual and non-textual sources for multi-turn dialogue. To address this problem, this paper introduces Conversational Tables (cTBL), a three-step encoder-decoder approach to retrieve tabular information and generate dialogue responses grounded on the retrieved information. cTBL uses Transformer encoder embeddings for Dense Table Retrieval and obtains up to 5% relative improvement in Top-1 and Top-3 accuracy over sparse retrieval on the HyrbiDialogue dataset. Additionally, cTBL performs tabular knowledge retrieval using both encoder and decoder models, resulting in up to 46% relative improvement in ROUGE scores and better human evaluation for response generation on HyrbiDialogue.
    
[^66]: 探索生物医学实体链接中的部分知识库推理

    Exploring Partial Knowledge Base Inference in Biomedical Entity Linking. (arXiv:2303.10330v1 [cs.CL])

    [http://arxiv.org/abs/2303.10330](http://arxiv.org/abs/2303.10330)

    本文探索了生物医学实体链接中的部分知识库推理问题，发现由于精度下降导致EL性能出现灾难性下降，而且EL范例无法处理无法链接的提及，提出了两种赎回方法来解决NIL问题。

    

    生物医学实体链接（EL）包括命名实体识别（NER）和命名实体消歧（NED）。EL模型在由预定义的知识库标记的语料库上进行训练。然而，常见的情况是只有知识库的子集中的实体对利益相关者有价值。我们称这种情况为部分知识库推理：使用一个知识库对EL模型进行训练，并在没有进一步训练的情况下对其部分进行推理。在这项工作中，我们给出了这种实际上非常有价值但明显不够研究的情况的详细定义和评估方法，并评估了三个代表性的EL范例的方法。我们构建了部分知识库推理基准，并发现由于大量精度下降导致EL性能出现灾难性下降。我们的发现揭示了这些EL范例无法正确处理无法链接的提及（NIL），因此它们对部分知识库推理不具有鲁棒性。我们还提出了两种简单有效的赎回方法来解决NIL问题。

    Biomedical entity linking (EL) consists of named entity recognition (NER) and named entity disambiguation (NED). EL models are trained on corpora labeled by a predefined KB. However, it is a common scenario that only entities within a subset of the KB are precious to stakeholders. We name this scenario partial knowledge base inference: training an EL model with one KB and inferring on the part of it without further training. In this work, we give a detailed definition and evaluation procedures for this practically valuable but significantly understudied scenario and evaluate methods from three representative EL paradigms. We construct partial KB inference benchmarks and witness a catastrophic degradation in EL performance due to dramatically precision drop. Our findings reveal these EL paradigms can not correctly handle unlinkable mentions (NIL), so they are not robust to partial KB inference. We also propose two simple-and-effective redemption methods to combat the NIL issue with litt
    
[^67]: 基于查询-话语注意力和联合建模的查询焦点会议摘要

    Query-Utterance Attention with Joint modeling for Query-Focused Meeting Summarization. (arXiv:2303.04487v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04487](http://arxiv.org/abs/2303.04487)

    本文提出了一种基于查询-话语注意力和联合建模的查询感知框架，它使用密集检索模块计算话语级别与查询的相关性，并将标记级别的查询关联性和话语级别的查询关联性结合起来，实现生成一个更与查询相关的摘要。经过对两个基准数据集上的测试，表明该方法优于现有的QFMS模型。

    

    查询焦点会议摘要（QFMS）旨在根据给定的查询，从会议记录中生成摘要。以往的方法通常将查询与会议记录拼接起来，并使用注意机制隐式地对标记级别的查询相关性进行建模。然而，由于长时间的会议记录导致关键的查询相关信息被稀释，因此原始的基于转换的模型不足以突出与查询相关的关键部分。本文提出了一种基于查询-话语注意力和联合建模的查询感知框架。它使用密集检索模块计算话语级别与查询的相关性。然后，将标记级别的查询关联性和话语级别的查询关联性结合起来，并通过明确的注意机制整合到生成过程中。我们表明，不同颗粒度的查询相关性有助于生成一个更与查询相关的摘要。在两个基准数据集上的实验结果表明，我们提出的方法优于现有的QFMS模型。

    Query-focused meeting summarization (QFMS) aims to generate summaries from meeting transcripts in response to a given query. Previous works typically concatenate the query with meeting transcripts and implicitly model the query relevance only at the token level with attention mechanism. However, due to the dilution of key query-relevant information caused by long meeting transcripts, the original transformer-based model is insufficient to highlight the key parts related to the query. In this paper, we propose a query-aware framework with joint modeling token and utterance based on Query-Utterance Attention. It calculates the utterance-level relevance to the query with a dense retrieval module. Then both token-level query relevance and utterance-level query relevance are combined and incorporated into the generation process with attention mechanism explicitly. We show that the query relevance of different granularities contributes to generating a summary more related to the query. Exper
    
[^68]: 参与兴奋：一种基于注意力的文本到图像扩散模型的语义引导方法

    Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models. (arXiv:2301.13826v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13826](http://arxiv.org/abs/2301.13826)

    该论文提出了一种基于注意力的文本到图像扩散模型的语义引导方法，名为参与兴奋，在推理时间内干预生成过程以改善生成图像的信实性和完整性，并解决了传统扩散模型在图像语义生成中可能存在的失灵现象。

    

    最近的文本到图像生成模型展示了一种无与伦比的通过目标文本提示进行指导生成多种多样和富有创造性的形象的能力。虽然具有革命性，但目前最先进的扩散模型仍可能在生成完全传达给定文本提示中的语义的图像方面失败。我们分析了公开的稳定扩散模型，并评估了灾难性忽视的存在，即模型无法生成输入提示中的一个或多个主题。此外，我们发现在某些情况下，模型还未能将属性（例如颜色）正确绑定到其相应的主题上。为了帮助减轻这些失败情况，我们引入了产生式语义护理（GSN）的概念，在推理时间内寻求干预生成过程以改善所生成图像的信实性。使用基于注意力的 GSN 公式，被称为参与兴奋，我们引导模型改进跨注意力的不确定性。

    Recent text-to-image generative models have demonstrated an unparalleled ability to generate diverse and creative imagery guided by a target text prompt. While revolutionary, current state-of-the-art diffusion models may still fail in generating images that fully convey the semantics in the given text prompt. We analyze the publicly available Stable Diffusion model and assess the existence of catastrophic neglect, where the model fails to generate one or more of the subjects from the input prompt. Moreover, we find that in some cases the model also fails to correctly bind attributes (e.g., colors) to their corresponding subjects. To help mitigate these failure cases, we introduce the concept of Generative Semantic Nursing (GSN), where we seek to intervene in the generative process on the fly during inference time to improve the faithfulness of the generated images. Using an attention-based formulation of GSN, dubbed Attend-and-Excite, we guide the model to refine the cross-attention un
    
[^69]: UPop：用于压缩视觉语言Transformer模型的统一和渐进式剪枝方法

    UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers. (arXiv:2301.13741v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13741](http://arxiv.org/abs/2301.13741)

    UPop是一种通用的视觉语言Transformer压缩框架，采用统一和渐进式剪枝方法，可自动分配剪枝比率，实现更高的压缩比率。

    

    真实世界的数据包含大量的多模态信息，其中视觉和语言是最具代表性的两种模态。此外，越来越重的模型，例如Transformer，已经引起了研究人员对模型压缩的关注。然而，如何压缩多模态模型，特别是视觉语言Transformer，仍然未被充分探索。本文提出了一种名为UPop的通用视觉语言Transformer压缩框架，它包括1）在原始模型中在连续优化空间中统一搜索多模态子网，从而实现可压缩模态和结构之间自动分配剪枝比率；2）渐进式搜索和微调子网，从而保持搜索和微调之间的收敛，以实现更高的压缩比率。

    Real-world data contains a vast amount of multimodal information, among which vision and language are the two most representative modalities. Moreover, increasingly heavier models, \textit{e}.\textit{g}., Transformers, have attracted the attention of researchers to model compression. However, how to compress multimodal models, especially vison-language Transformers, is still under-explored. This paper proposes the \textbf{U}nified and \textbf{P}r\textbf{o}gressive \textbf{P}runing (\textbf{\emph{UPop}}) as a universal vison-language Transformer compression framework, which incorporates 1) unifiedly searching multimodal subnets in a continuous optimization space from the original model, which enables automatic assignment of pruning ratios among compressible modalities and structures; 2) progressively searching and retraining the subnet, which maintains convergence between the search and retrain to attain higher compression ratios. Experiments on various tasks, datasets, and model archit
    
[^70]: 理解Transformer模型的INT4量化：延迟速度提升、可组合性和故障案例

    Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases. (arXiv:2301.12017v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.12017](http://arxiv.org/abs/2301.12017)

    本文研究了在语言模型中采用INT4权重和激活量化的可行性，并开发了高度优化的W4A4编码器推断管道，支持不同的量化策略。使用W4A4可以实现模型在延迟方面的显著提高。

    

    鉴于Transformer基于语言模型的高计算和内存成本，提高其部署效率一直是一个挑战。尽管最近已经证明了INT8量化在减少内存成本和延迟方面的有效性，同时还保持了模型的准确性，但我们是否可以利用INT4（可以使硬件峰值吞吐量增加一倍）来实现进一步的延迟改进还不清楚。在这项研究中，我们探讨了在语言模型中采用INT4权重和激活（W4A4）量化的可行性。我们的发现表明，对于仅编码器和编码器-解码器模型，W4A4量化引入的准确性降低可以忽略不计，但对于仅解码器模型而言，会导致显著的准确性下降。为了实现使用W4A4的性能增益，我们开发了一个高度优化的端到端W4A4编码器推断管道，支持不同的量化策略。我们的INT4管道在面向延迟的场景下的速度可以提高8.5倍，在其他场景下最多可以提高3倍。

    Improving the deployment efficiency of transformer-based language models has been challenging given their high computation and memory cost. While INT8 quantization has recently been shown to be effective in reducing both the memory cost and latency while preserving model accuracy, it remains unclear whether we can leverage INT4 (which doubles peak hardware throughput) to achieve further latency improvement. In this study, we explore the feasibility of employing INT4 weight and activation (W4A4) quantization for language models. Our findings indicate that W4A4 quantization introduces no to negligible accuracy degradation for encoder-only and encoder-decoder models, but causes a significant accuracy drop for decoder-only models. To materialize the performance gain using W4A4, we develop a highly optimized end-to-end W4A4 encoder inference pipeline supporting different quantization strategies. Our INT4 pipeline is $8.5\times$ faster for latency-oriented scenarios and up to $3\times$ for t
    
[^71]: 基于CTC和最优传输的语音翻译预训练方法

    Pre-training for Speech Translation: CTC Meets Optimal Transport. (arXiv:2301.11716v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11716](http://arxiv.org/abs/2301.11716)

    本文提出了一种基于CTC和最优传输的语音翻译预训练方法，可以有效减小语音和文本模态之间的差距，提高最终的ST准确性。

    

    语音到文本翻译(ST)中的模态差距是一个重要挑战，该文提出了一种预训练方法来减轻这个问题，无需改变ST模型的架构。首先，本文表明连接时序分类(CTC)损失可以通过设计来减小模态差距。通过与更常见的交叉熵损失的定量比较，我们证明了使用CTC进行预训练可以始终实现更好的最终ST准确性。其次，我们提出了一种结合CTC和最优传输的新型预训练方法以进一步减小这种差距。我们的实验证明了使用CTC和最优传输进行预训练相对于仅使用CTC进行预训练和没有进行预训练的基线模型均能够提供持续改进。

    The gap between speech and text modalities is a major challenge in speech-to-text translation (ST). Different methods have been proposed to reduce this gap, but most of them require architectural changes in ST training. In this work, we propose to mitigate this issue at the pre-training stage, requiring no change in the ST model. First, we show that the connectionist temporal classification (CTC) loss can reduce the modality gap by design. We provide a quantitative comparison with the more common cross-entropy loss, showing that pre-training with CTC consistently achieves better final ST accuracy. Nevertheless, CTC is only a partial solution and thus, in our second contribution, we propose a novel pre-training method combining CTC and optimal transport to further reduce this gap. Our method pre-trains a Siamese-like model composed of two encoders, one for acoustic inputs and the other for textual inputs, such that they produce representations that are close to each other in the Wassers
    
[^72]: 匹配标本作为下一句预测：自然语言处理科学教育中的零样本学习自动评分

    Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt Learning for Automatic Scoring in Science Education. (arXiv:2301.08771v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.08771](http://arxiv.org/abs/2301.08771)

    本研究提出了一种零样本学习自动评分的方法，利用预训练的语言模型配合匹配标本作为下一句预测技术，成功应用于科学教育领域的论证任务，极大地减少了训练成本和时间。

    

    开发能够自动评分科学问题的学生书面答案的模型对于科学教育至关重要。然而，收集和标记足够的学生答案以训练模型是耗时和费用高昂的。最近的研究表明，预训练的语言模型（PLMs）可以在不需要prompt调整的情况下适应下游任务。然而，在科学教育中还没有使用过这种提示方法的研究。由于学生的答案是用自然语言呈现的，因此使用提示将评分过程对齐为下一句预测任务可以跳过昂贵的调整阶段。在这项研究中，我们通过匹配标本作为下一句预测（MeNSP）开发了一种零样本自动评分方法。这种方法不需要训练样本。我们首先在评分三个科学论证任务中应用MeNSP，并发现机器-人评分的一致性，Cohen的Kappa系数在0.30到0.57之间，F1分数

    Developing models to automatically score students' written responses to science problems is critical for science education. However, collecting and labeling sufficient student responses for training models is time and cost-consuming. Recent studies suggest that pre-trained language models (PLMs) can be adapted to downstream tasks without fine-tuning with prompts. However, no research has employed such a prompt approach in science education. As student responses are presented with natural language, aligning the scoring procedure as the next sentence prediction task using prompts can skip the costly fine-tuning stage. In this study, we developed a zero-shot approach to automatically score student responses via Matching Exemplars as Next Sentence Prediction (MeNSP). This approach employs no training samples. We first apply MeNSP in scoring three assessment tasks of scientific argumentation and found machine-human scoring agreements, Cohen's Kappa ranges from 0.30 to 0.57, and F1 score ran
    
[^73]: 连续对比微调改进低资源关系提取

    Continual Contrastive Finetuning Improves Low-Resource Relation Extraction. (arXiv:2212.10823v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2212.10823](http://arxiv.org/abs/2212.10823)

    本文提出了一种使用连续对比微调的方法来改进低资源关系提取，通过使用一致的对比学习目标预训练和微调RE模型，以及多中心对比损失来允许一个关系形成多个聚类。实验结果表明该方法可以显着提高低资源情况和领域中的关系提取性能。

    

    关系提取（RE）依赖结构化注释语料库进行模型训练，尤其在低资源情况和领域中，该任务具有挑战性。近期研究通过自监督学习来解决低资源的RE，其中解决方案包括通过RE目标预训练关系嵌入，并通过分类为基础的目标对有标签数据进行微调。然而，这种方法的一个关键挑战是目标之间的差距，它阻止RE模型充分利用预训练表示中的知识。本文旨在弥合差距，并提出使用一致的对比学习目标预训练和微调RE模型。由于在这种表示学习范式中，一个关系可能在表示空间中轻松形成多个聚类，因此我们进一步提出了多中心对比损失，允许一个关系形成多个聚类以更好地对齐预训练。在两个文档中的实验表明，所提出的方法可以在低资源情况和领域中显着提高关系提取性能。

    Relation extraction (RE), which has relied on structurally annotated corpora for model training, has been particularly challenging in low-resource scenarios and domains. Recent literature has tackled low-resource RE by self-supervised learning, where the solution involves pretraining the relation embedding by RE-based objective and finetuning on labeled data by classification-based objective. However, a critical challenge to this approach is the gap in objectives, which prevents the RE model from fully utilizing the knowledge in pretrained representations. In this paper, we aim at bridging the gap and propose to pretrain and finetune the RE model using consistent objectives of contrastive learning. Since in this kind of representation learning paradigm, one relation may easily form multiple clusters in the representation space, we further propose a multi-center contrastive loss that allows one relation to form multiple clusters to better align with pretraining. Experiments on two docum
    
[^74]: ClarifyDelphi：针对社会和道德情境的强化澄清问题与优先考虑对抗的奖励

    ClarifyDelphi: Reinforced Clarification Questions with Defeasibility Rewards for Social and Moral Situations. (arXiv:2212.10409v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10409](http://arxiv.org/abs/2212.10409)

    ClarifyDelphi是一个交互式系统，能够针对社会或道德情境提出最有信息价值的问题，并通过奖励机制最大化回答问题时的道德判断分歧。

    

    上下文的重要性不言而喻，甚至在常识道德推理中也是如此。改变上下文可能会颠倒一项行为的道德判断;“对朋友撒谎”在一般情况下是不对的，但如果旨在保护他们的生命，就可能是道德上可接受的。我们提出了ClarifyDelphi，一个交互式系统，它学习提出澄清问题（例如，你为什么要对你的朋友撒谎？）以获取社会或道德情境的其他重要信息。我们认为，其潜在答案导致道德判断有所分歧的问题是最有信息价值的。因此，我们提出了一种增强学习框架，该框架具有对抗性奖励，旨在最大化回答问题时的道德判断分歧。人类评估表明，与竞争基线相比，我们的系统生成的问题更相关、更有信息价值和更具优胜性。我们的工作最终受到认知科学研究的启发，该研究调查了道德认知的灵活性（即能够纳入新的上下文信息并相应地修改道德判断）。

    Context is everything, even in commonsense moral reasoning. Changing contexts can flip the moral judgment of an action; "Lying to a friend" is wrong in general, but may be morally acceptable if it is intended to protect their life.  We present ClarifyDelphi, an interactive system that learns to ask clarification questions (e.g., why did you lie to your friend?) in order to elicit additional salient contexts of a social or moral situation. We posit that questions whose potential answers lead to diverging moral judgments are the most informative. Thus, we propose a reinforcement learning framework with a defeasibility reward that aims to maximize the divergence between moral judgments of hypothetical answers to a question. Human evaluation demonstrates that our system generates more relevant, informative and defeasible questions compared to competitive baselines. Our work is ultimately inspired by studies in cognitive science that have investigated the flexibility in moral cognition (i.e
    
[^75]: 神经机器翻译的合成预训练任务

    Synthetic Pre-Training Tasks for Neural Machine Translation. (arXiv:2212.09864v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09864](http://arxiv.org/abs/2212.09864)

    本文提出了一种使用合成任务和数据预训练神经机器翻译模型的方法，其可以缓解大规模抓取的语料库所导致的毒性、偏见和法律隐患，并证明了即使采用高度混淆或纯合成数据，预训练依然有效。

    

    使用大规模抓取的语料库进行预训练模型可能会导致毒性和偏见等问题，以及版权和隐私问题。采用合成任务和数据进行预训练是缓解这些问题的一种有前途的方式，因为模型不会吸收任何真实世界信息。本文旨在了解使用合成资源时对预训练模型有效性的影响因素，特别是在神经机器翻译的背景下。我们提出了几种新颖的预训练翻译模型的方法，包括不同水平的词汇和结构知识，例如：1）从大型平行语料库生成混淆数据，2）连接从小型词对齐语料库提取的短语对，以及3）生成不带真实人类语料库的合成平行数据。我们在多种语言对上的实验表明，即使存在高水平的混淆或纯合成数据，也可以实现预训练的效益。

    Pre-training models with large crawled corpora can lead to issues such as toxicity and bias, as well as copyright and privacy concerns. A promising way of alleviating such concerns is to conduct pre-training with synthetic tasks and data, since no real-world information is ingested by the model. Our goal in this paper is to understand the factors that contribute to the effectiveness of pre-training models when using synthetic resources, particularly in the context of neural machine translation. We propose several novel approaches to pre-training translation models that involve different levels of lexical and structural knowledge, including: 1) generating obfuscated data from a large parallel corpus 2) concatenating phrase pairs extracted from a small word-aligned corpus, and 3) generating synthetic parallel data without real human language corpora. Our experiments on multiple language pairs reveal that pre-training benefits can be realized even with high levels of obfuscation or purely
    
[^76]: 低资源语言的跨语言检索增强提示

    Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages. (arXiv:2212.09651v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09651](http://arxiv.org/abs/2212.09651)

    本文提出了跨语言检索增强提示(PARC)管道，在零-shot低资源语言上通过从高资源语言中检索出的语义上类似的句子来改善性能，表现明显优于 fine-tuning 基线，同时与高低资源语言之间的相似性以及低资源预训练数据的数量存在显著正相关关系。

    

    多语言预训练语言模型(MPLMs)在最近的经验跨语言转移研究中展现了其强大的多语言能力。在本文中，我们提出了跨语言检索增强的提示(PARC)管道，通过从高资源语言(HRL)中检索出的语义上类似的句子作为提示来改善零-shot低资源语言(LRLs)的性能。PARC通过多语言并行测试集在三个下游任务(二元情感分类、主题分类和自然语言推断)上提高了零-shot的性能，覆盖了10个LRLs，涵盖了6种语言家族，在未标记的设置中提高了(+5.1%)，在标记的设置中提高了(+16.3%)。PARC标记还超越了 fine-tuning 基线3.7%。我们发现，跨语言转移性能在一方面与高低资源语言之间的相似性以及低资源预训练数据的数量之间存在显著正相关关系。

    Multilingual Pretrained Language Models (MPLMs) have shown their strong multilinguality in recent empirical cross-lingual transfer studies. In this paper, we propose the Prompts Augmented by Retrieval Crosslingually (PARC) pipeline to improve the zero-shot performance on low-resource languages (LRLs) by augmenting the context with semantically similar sentences retrieved from a high-resource language (HRL) as prompts. PARC improves the zero-shot performance on three downstream tasks (binary sentiment classification, topic categorization and natural language inference) with multilingual parallel test sets across 10 LRLs covering 6 language families in both unlabeled settings (+5.1%) and labeled settings (+16.3%). PARC-labeled also outperforms the finetuning baseline by 3.7%. We find a significant positive correlation between cross-lingual transfer performance on one side, and the similarity between the high- and low-resource languages as well as the amount of low-resource pretraining da
    
[^77]: DuNST：双重噪声自训练用于半监督可控文本生成

    DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text Generation. (arXiv:2212.08724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08724](http://arxiv.org/abs/2212.08724)

    DuNST是一种双重噪声自训练方法，用于半监督可控文本生成。该方法通过扰动生成的伪文本，将伪文本标记和无标签的伪标签结合使用，并且可以缓解先前学习到的空间的限制性泛化边界。

    

    对于语言理解，自训练（ST）通过增加预训练语言模型的微调次数来扩充标记数据不足的情况，有了较大发展。然而，在带属性控制的语言生成中，将ST纳入其中仍然具有挑战性。只能通过自动生成的伪文本进行增强的生成模型会过度强调先前学习到的空间，受到受限的泛化边界所困扰。我们重新思考ST，提出了一种新的方法DuNST来缓解这个问题。DuNST通过一个共享变分自编码器来联合生成文本和对应的分类标签，并使用两种灵活的噪声来扰乱生成的伪文本。这样，我们的模型可以构建并利用来自给定标签的伪文本以及来自可用无标签文本的伪标签，在ST过程中逐渐改进。理论上证明DuNST可以被视为向潜在真实文本的探索增强。

    Self-training (ST) has prospered again in language understanding by augmenting the fine-tuning of pre-trained language models when labeled data is insufficient. However, it remains challenging to incorporate ST into attribute-controllable language generation. Augmented by only self-generated pseudo text, generation models over-emphasize exploitation of the previously learned space, suffering from a constrained generalization boundary. We revisit ST and propose a novel method, DuNST to alleviate this problem. DuNST jointly models text generation and classification with a shared Variational AutoEncoder and corrupts the generated pseudo text by two kinds of flexible noise to disturb the space. In this way, our model could construct and utilize both pseudo text from given labels and pseudo labels from available unlabeled text, which are gradually refined during the ST process. We theoretically demonstrate that DuNST can be regarded as enhancing exploration towards the potential real text s
    
[^78]: Transformer模型通过梯度下降实现上下文学习

    Transformers learn in-context by gradient descent. (arXiv:2212.07677v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.07677](http://arxiv.org/abs/2212.07677)

    本文提出，训练Transformer模型应用于自回归目标问题时，与基于梯度的元学习的形式密切相关，通过梯度下降学习模型的“底层优化程序”的机制，在回归问题的领域中从机械的角度理解了Transformers模型中上下文学习的内部机制。

    

    目前，Transformers模型中上下文学习的机制尚未得到很好的理解，大多只停留在直觉上。本文提出，训练Transformer模型应用于自回归目标问题时，与基于梯度的元学习的形式密切相关。我们首先提供一个简单的权重构造，证明了由单个线性自注意力层引发的数据转换与由具有回归损失的梯度下降（GD）获得的转换具有等价性。在此基础上，我们通过实验证明，当仅训练自注意力Transformer模型进行简单的回归任务时，通过GD优化得到的模型与模型权重十分相似，或者在某些情况下，GD优化的权重与构造的权重相同。因此，我们展示了经过训练的Transformer模型是如何在前向传递中通过梯度下降学习模型的“底层优化程序”的。在回归问题的领域中，这使我们能够从机械的角度理解Transformers模型中上下文学习的内部机制。

    At present, the mechanisms of in-context learning in Transformers are not well understood and remain mostly an intuition. In this paper, we suggest that training Transformers on auto-regressive objectives is closely related to gradient-based meta-learning formulations. We start by providing a simple weight construction that shows the equivalence of data transformations induced by 1) a single linear self-attention layer and by 2) gradient-descent (GD) on a regression loss. Motivated by that construction, we show empirically that when training self-attention-only Transformers on simple regression tasks either the models learned by GD and Transformers show great similarity or, remarkably, the weights found by optimization match the construction. Thus we show how trained Transformers become mesa-optimizers i.e. learn models by gradient descent in their forward pass. This allows us, at least in the domain of regression problems, to mechanistically understand the inner workings of in-context
    
[^79]: MT4SSL：通过集成多个目标来提升自监督语音表示学习

    MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets. (arXiv:2211.07321v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07321](http://arxiv.org/abs/2211.07321)

    本文提出了一个新的自监督多任务学习框架MT4SSL，通过同时使用K均值算法作为离线目标提取器和没有梯度的教师网络作为在线目标提取器，取得了比以前更好的表现。同时，使用离线和在线目标提取器可以得到更好的收敛性，我们认为这是自监督语音模型上的多任务学习有前途的趋势。

    

    本文从训练目标的获取方式提出了自监督语音模型的新视角，并将目标提取器概括为离线目标提取器和在线目标提取器。基于此，我们提出了一种新的自监督多任务学习框架MT4SSL，它使用K均值算法作为离线目标提取器，使用没有梯度的教师网络作为在线目标提取器。实验结果表明，我们的模型在LibriSpeech基准测试上优于以前的方法，并且与使用更少数据的最佳模型相当甚至更好。此外，我们发现在预训练阶段同时使用离线和在线目标提取器可以得到更好的收敛性。因此，我们认为从我们的角度进行自监督语音模型上的多任务学习是一种有前途的趋势。

    In this paper, we provide a new perspective on self-supervised speech models from how the training targets are obtained. We generalize the targets extractor into Offline Targets Extractor (Off-TE) and Online Targets Extractor (On-TE). Based on this, we propose a new multi-tasking learning framework for self-supervised learning, MT4SSL, which stands for Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets. MT4SSL uses the K-means algorithm as an Off-TE and a teacher network without gradients as an On-TE, respectively. Our model outperforms previous SSL methods by nontrivial margins on the LibriSpeech benchmark, and is comparable to or even better than the best-performing models with fewer data. Furthermore, we find that using both Off-TE and On-TE results in better convergence in the pre-training phase. With both effectiveness and efficiency, we think doing multi-task learning on self-supervised speech models from our perspective is a promising trend.
    
[^80]: RARR: 使用语言模型研究和修正其输出结果中的不确定信息

    RARR: Researching and Revising What Language Models Say, Using Language Models. (arXiv:2210.08726v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08726](http://arxiv.org/abs/2210.08726)

    RARR是一个可以对不确定信息进行研究和修订的系统，它可以自动找到文本生成模型输出的归因并修正不支持的内容。

    

    现在的语言模型在诸如少样本学习、问答、推理和对话等许多任务上表现出色。然而，它们有时会生成无支持或误导性的内容。由于大多数语言模型没有任何内置的归因外部证据的机制，用户很难确定它们的输出是否可靠。为了在保留最新一代模型的所有强大优势的同时实现归因，我们提出了 RARR (使用研究和修订进行改进归因)系统，它 1) 自动找到任何文本生成模型输出的归因并 2) 在尽可能保留原始输出的同时，修正不支持的内容。当应用于几个最先进的语言模型在各种输出任务上的结果时，我们发现RARR在显著提高归因率的同时，比以前探索的编辑模型更能保留原始输入。

    Language models (LMs) now excel at many tasks such as few-shot learning, question answering, reasoning, and dialog. However, they sometimes generate unsupported or misleading content. A user cannot easily determine whether their outputs are trustworthy or not, because most LMs do not have any built-in mechanism for attribution to external evidence. To enable attribution while still preserving all the powerful advantages of recent generation models, we propose RARR (Retrofit Attribution using Research and Revision), a system that 1) automatically finds attribution for the output of any text generation model and 2) post-edits the output to fix unsupported content while preserving the original output as much as possible. When applied to the output of several state-of-the-art LMs on a diverse set of generation tasks, we find that RARR significantly improves attribution while otherwise preserving the original input to a much greater degree than previously explored edit models. Furthermore, 
    
[^81]: 仅提及注释即可有效进行共指消解的领域自适应

    Mention Annotations Alone Enable Efficient Domain Adaptation for Coreference Resolution. (arXiv:2210.07602v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07602](http://arxiv.org/abs/2210.07602)

    论文提出一种仅使用提及注释的共指消解领域自适应方法，有效提高模型效果而不增加时间与成本。

    

    最近，神经网络模型在共指消解方面取得了显著进展，但将这些模型转移到包含新的超出词汇表范围及需要不同注释方案的新目标域中仍然具有挑战性。典型方法涉及在目标域数据上进行持续训练，但获取注释是昂贵且耗时的。本文提出一种方法来有效适应共指模型，其中包括高精度提及检测目标并仅对目标域中的提及进行注释。在三个英语共指数据集上进行了广泛评估：CoNLL-2012（新闻/会话），i2b2 / VA（医学记录）和以前未研究的儿童福利笔记，证明了我们的方法有助于有效注释转移，结果平均F1值提高了7-14％，而不增加时间成本。

    Although recent neural models for coreference resolution have led to substantial improvements on benchmark datasets, transferring these models to new target domains containing out-of-vocabulary spans and requiring differing annotation schemes remains challenging. Typical approaches involve continued training on annotated target-domain data, but obtaining annotations is costly and time-consuming. We show that annotating mentions alone is nearly twice as fast as annotating full coreference chains. Accordingly, we propose a method for efficiently adapting coreference models, which includes a high-precision mention detection objective and requires annotating only mentions in the target domain. Extensive evaluation across three English coreference datasets: CoNLL-2012 (news/conversation), i2b2/VA (medical notes), and previously unstudied child welfare notes, reveals that our approach facilitates annotation-efficient transfer and results in a 7-14% improvement in average F1 without increasin
    
[^82]: 采样效率更高的NLP模型更加鲁棒吗？

    Are Sample-Efficient NLP Models More Robust?. (arXiv:2210.06456v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06456](http://arxiv.org/abs/2210.06456)

    较低采样效率的NLP模型在特定情况下可能比较高采样效率的模型更为鲁棒，表明通用的提高采样效率方法不太可能改善自然语言处理中的OOD鲁棒性。

    

    最近在图像分类和抽取式问答中的研究表明，预训练模型在更少的内部数据上训练可以获得更好的外部评测性能。然而，这些趋势的普适性还不清楚。在三个任务、三个广泛适用的建模干预（增加模型大小、使用不同的适应方法和在更多数据上进行预训练）和14个不同数据集上，我们进行了大规模的实证研究，以研究样本效率（达到给定ID准确度所需的数据量）和鲁棒性（模型在OOD评估中的表现）之间的关系。我们发现，较高的样本效率仅在某些建模干预和任务上与更好的平均OOD鲁棒性相关，而在其他情况下则不然。在个别数据集上，样本效率较低的模型甚至更为健壮。这些结果表明，提高样本效率的通用方法不太可能改善自然语言处理中的普遍OOD鲁棒性。

    Recent results in image classification and extractive question answering have observed that pre-trained models trained on less in-distribution data have better out-of-distribution performance. However, it is unclear how broadly these trends hold. We conduct a large empirical study across three tasks, three broadly-applicable modeling interventions (increasing model size, using a different adaptation method, and pre-training on more data), and 14 diverse datasets to investigate the relationship between sample efficiency (amount of data needed to reach a given ID accuracy) and robustness (how models fare on OOD evaluation). We find that higher sample efficiency is only correlated with better average OOD robustness on some modeling interventions and tasks, but not others. On individual datasets, models with lower sample efficiency can even be more robust. These results suggest that general-purpose methods for improving sample efficiency are unlikely to yield universal OOD robustness impro
    
[^83]: 变分开放领域问答

    Variational Open-Domain Question Answering. (arXiv:2210.06345v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06345](http://arxiv.org/abs/2210.06345)

    本文介绍了变分开放领域（VOD）框架，提出了一种新的自归一化的Rényi变分界的估计方法，可用于训练具有检索增强功能的模型，例如阅读器-检索器BERT-sized模型，并实现了在多项选择医学考试问题上的优异表现。

    

    检索增强模型在自然语言处理任务中已被证明是有效的，但是对它们进行变分推断的优化研究仍然不足。我们引入了变分开放领域（VOD）框架，用于检索增强模型的端到端训练和评估，重点放在开放领域问答和语言建模方面。VOD目标是一种自归一化的Rényi变分界的估计，近似于任务边缘似然，并在一个辅助采样分布（缓存的检索器和/或近似后验）中进行样本抽取评估。它仍然是可行的，即使是在对大量语料库定义的检索器分布下。我们通过训练针对多项选择医学考试问题的阅读器-检索器BERT-sized模型，展示了VOD的多功能性。在MedMCQA数据集上，我们超过了领域微调的Med-PaLM 5.3％，尽管使用的参数少了2500倍。我们的检索增强BioLinkBERT模型得分为62.9％。

    Retrieval-augmented models have proven to be effective in natural language processing tasks, yet there remains a lack of research on their optimization using variational inference. We introduce the Variational Open-Domain (VOD) framework for end-to-end training and evaluation of retrieval-augmented models, focusing on open-domain question answering and language modelling. The VOD objective, a self-normalized estimate of the R\'enyi variational bound, approximates the task marginal likelihood and is evaluated under samples drawn from an auxiliary sampling distribution (cached retriever and/or approximate posterior). It remains tractable, even for retriever distributions defined on large corpora. We demonstrate VOD's versatility by training reader-retriever BERT-sized models on multiple-choice medical exam questions. On the MedMCQA dataset, we outperform the domain-tuned Med-PaLM by +5.3% despite using 2.500$\times$ fewer parameters. Our retrieval-augmented BioLinkBERT model scored 62.9%
    
[^84]: CONE：用于长视频时间定位的高效粗-细对齐框架

    CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding. (arXiv:2209.10918v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.10918](http://arxiv.org/abs/2209.10918)

    本文提出了CONE，一个高效的粗-细对齐框架，可用于长视频时间定位。CONE通过基于查询的窗口选择策略和对比学习机制提升了多模态对齐，并在两个大规模长视频时间定位基准测试中取得最先进结果。

    

    本文解决了一个新兴且具有挑战性的问题——长视频时间定位（VTG），即定位与自然语言查询相关的视频片段。相比于短视频，长视频同样非常受欢迎，但是探索较少，这带来了多个挑战，例如更高的推理计算成本和弱的多模态对齐。为了解决这些挑战，我们提出了CONE，一个高效的粗-细对齐框架。CONE是一个插拔式的框架，可在现有的VTG模型上处理长视频，通过滑动窗口机制。具体来说，CONE（1）引入了基于查询的窗口选择策略以加快推理速度，（2）提议了通过新增对比学习来增强长视频的多模态对齐的粗细机制。对两个大规模长VTG基准测试进行的大量实验均表明，CONE在性能上都有很大提升（例如在MAD上从3.13％到6.87％），并且具有最先进的结果。分析也证明了CONE模型的有效性和可解释性。

    This paper tackles an emerging and challenging problem of long video temporal grounding~(VTG) that localizes video moments related to a natural language (NL) query. Compared with short videos, long videos are also highly demanded but less explored, which brings new challenges in higher inference computation cost and weaker multi-modal alignment. To address these challenges, we propose CONE, an efficient COarse-to-fiNE alignment framework. CONE is a plug-and-play framework on top of existing VTG models to handle long videos through a sliding window mechanism. Specifically, CONE (1) introduces a query-guided window selection strategy to speed up inference, and (2) proposes a coarse-to-fine mechanism via a novel incorporation of contrastive learning to enhance multi-modal alignment for long videos. Extensive experiments on two large-scale long VTG benchmarks consistently show both substantial performance gains (e.g., from 3.13% to 6.87% on MAD) and state-of-the-art results. Analyses also 
    
[^85]: ILLUME：通过人机交互来合理化视觉-语言模型

    ILLUME: Rationalizing Vision-Language Models through Human Interactions. (arXiv:2208.08241v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.08241](http://arxiv.org/abs/2208.08241)

    本文提出了一种新的调整范例，名为ILLUME，通过人机交互来合理化视觉-语言模型，从而使模型的输出更符合人的思维方式。在使用相对较少的训练数据和最少的人类反馈下，ILLUME表现出与标准监督微调相当的竞争力。

    

    基于预训练语言模型的引导已被证明是构建视觉-语言模型（VLM）的有效方法，可用于图像字幕或视觉问题回答等任务。然而，这些模型的输出很少与用户对特定答案的理性相一致。为了改善这种对齐并加强常识原因，我们提出了一种基于人机生成数据的调整范例。我们的ILLUME执行以下循环：给定一个图像-问题-答案提示，VLM样本多个候选原理，人类评论家通过偏好选择提供反馈，用于微调。这个循环增加了训练数据，并逐渐雕刻出与人类意图相一致的VLM的理性能力。我们的详尽实验表明，ILLUME在使用 significantly 更少的训练数据仅需要 minimal 反馈的同时，与标准监督微调具有竞争力。

    Bootstrapping from pre-trained language models has been proven to be an efficient approach for building vision-language models (VLM) for tasks such as image captioning or visual question answering. However, outputs of these models rarely align with user's rationales for specific answers. In order to improve this alignment and reinforce commonsense reasons, we propose a tuning paradigm based on human interactions with machine-generated data. Our ILLUME executes the following loop: Given an image-question-answer prompt, the VLM samples multiple candidate rationales, and a human critic provides feedback via preference selection, used for fine-tuning. This loop increases the training data and gradually carves out the VLM's rationalization capabilities that are aligned with human intent. Our exhaustive experiments demonstrate that ILLUME is competitive with standard supervised finetuning while using significantly fewer training data and only requiring minimal feedback.
    
[^86]: 基于质心预训练的多文档摘要

    Multi-Document Summarization with Centroid-Based Pretraining. (arXiv:2208.01006v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.01006](http://arxiv.org/abs/2208.01006)

    本文提出一种基于ROUGE的质心聚类预训练方法，可用于多文档摘要中，不需要人工编写的摘要，模型Centrum比现有先进模型更好。

    

    在多文档摘要(MDS)中，输入可以被建模为一组文档，输出是它们的摘要。本文侧重于MDS的预训练目标。具体而言，我们引入了一种新的预训练目标，它涉及选择每个文档聚类的基于ROUGE的质心作为其摘要的代理。我们的目标不需要人工编写的摘要，可以用于仅由文档集组成的数据集的预训练。通过在多个MDS数据集上进行零样本、少样本和完全监督实验，我们展示了我们的模型Centrum比现有的先进模型更好或可比。我们将预训练和微调的模型免费提供给研究社区https://github.com/ratishsp/centrum。

    In Multi-Document Summarization (MDS), the input can be modeled as a set of documents, and the output is its summary. In this paper, we focus on pretraining objectives for MDS. Specifically, we introduce a novel pretraining objective, which involves selecting the ROUGE-based centroid of each document cluster as a proxy for its summary. Our objective thus does not require human written summaries and can be utilized for pretraining on a dataset consisting solely of document sets. Through zero-shot, few-shot, and fully supervised experiments on multiple MDS datasets, we show that our model Centrum is better or comparable to a state-of-the-art model. We make the pretrained and fine-tuned models freely available to the research community https://github.com/ratishsp/centrum.
    
[^87]: 破坏者：训练语言模型的联邦学习中的变形金刚隐私泄露

    Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models. (arXiv:2201.12675v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.12675](http://arxiv.org/abs/2201.12675)

    该论文提出了一种针对联邦学习中文本的隐私攻击方法，通过部署恶意参数向量来揭示私人用户文本，并成功地进行mini-batches训练，适用于多个用户和长序列，提示了文本领域的FL比先前认为的更脆弱。

    

    联邦学习(Federated learning, FL)的核心原则是在不集中用户数据的情况下训练模型，这种方法强调隐私保护。然而，先前的研究表明，FL中使用的梯度更新可能泄露用户信息。尽管FL在文本应用领域（例如击键预测）中很常见，但对于FL隐私的几乎所有攻击都集中在简单的图像分类器上。我们提出了一种新的攻击方法，通过部署恶意参数向量来揭示私人用户文本，这种攻击可以成功地进行mini-batches训练，适用于多个用户和长序列。与以往针对FL的攻击不同的是，这种攻击利用了Transformer架构和标记嵌入(token embedding)的特性，分别提取标记和位置嵌入以检索高保真度文本。这项工作表明，文本领域的FL在历史上一直能够抵御隐私攻击，但比先前认为的更加脆弱。

    A central tenet of Federated learning (FL), which trains models without centralizing user data, is privacy. However, previous work has shown that the gradient updates used in FL can leak user information. While the most industrial uses of FL are for text applications (e.g. keystroke prediction), nearly all attacks on FL privacy have focused on simple image classifiers. We propose a novel attack that reveals private user text by deploying malicious parameter vectors, and which succeeds even with mini-batches, multiple users, and long sequences. Unlike previous attacks on FL, the attack exploits characteristics of both the Transformer architecture and the token embedding, separately extracting tokens and positional embeddings to retrieve high-fidelity text. This work suggests that FL on text, which has historically been resistant to privacy attacks, is far more vulnerable than previously thought.
    
[^88]: AmbiFC: 用证据检验含糊性声明的真实性

    AmbiFC: Fact-Checking Ambiguous Claims with Evidence. (arXiv:2104.00640v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2104.00640](http://arxiv.org/abs/2104.00640)

    本研究提出了一个大规模的事实核查数据集AmbiFC，用于处理现实场景中的含糊性声明核查问题，通过细粒度的证据注释和分析，提出了一种适用于含糊性声明的软标签证据核查方法，并且在注释人员争议分析中发现了相关性。

    

    在实际场景中，自动化事实核查系统必须将声明与检索到的证据进行比较以预测真实性。检索到的证据可能无法明确支持或反驳声明，并产生各种有效解释。现有的事实核查数据集需要模型为每个声明预测单个真实性标签，并且缺乏管理此类模糊性的能力。我们提出了一个大规模的事实核查数据集AmbiFC，其中包含从完整维基百科页面中获取的经过细粒度证据注释的信息需求的现实声明。我们彻底分析了AmbiFC中涉及含糊声明引起的争议，观察到与注释人员的自我评估和专家注释的语言现象强烈相关的注释人员争议。我们引入基于证据的含糊声明的真实性核查任务，比较了三种方法，其中包含注释信号和单标签分类。

    Automated fact-checking systems in real-world scenarios must compare claims with retrieved evidence to predict the veracity. The retrieved evidence may not unambiguously support or refute the claim and yield diverse valid interpretations. Existing fact-checking datasets necessitate that models predict a single veracity label for each claim and lack the ability to manage such ambiguity. We present AmbiFC, a large-scale fact-checking dataset with realistic claims derived from real-world information needs. Our dataset contains fine-grained evidence annotations of passages from complete Wikipedia pages. We thoroughly analyze disagreements arising from ambiguous claims in AmbiFC, observing a strong correlation of annotator disagreement with their self-assessment and expert-annotated linguistic phenomena. We introduce the task of evidence-based fact-checking for ambiguous claims with soft labels, and compare three methodologies incorporating annotation signals with a single-label classificat
    
[^89]: 问题回答建模的改进是否跨越基准测试持续存在？

    Do Question Answering Modeling Improvements Hold Across Benchmarks?. (arXiv:2102.01065v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2102.01065](http://arxiv.org/abs/2102.01065)

    该论文通过测量32个问题回答基准测试之间的一致性，发现人工构建的基准测试具有高度的一致性，即使它们的段落和问题分布是非常不同的，这表明尽管人们长时间关注少数基准测试，但所研究的建模改进仍然具有广泛适用性。

    

    问题回答 (QA) 模型的改进（例如，架构和训练过程的选择）是否在各种QA基准测试中都能持续存在？为了研究这个问题，我们引入了“一致性”的概念--如果两个基准测试在一组建模方法上排名相似，那么它们之间有高一致性。我们在一组20个不同的建模方法上测量了32个问题回答基准测试之间的一致性，发现人工构建的基准测试在相互之间具有高度一致性，即使它们的段落和问题分布是非常不同的。令人惊讶的是，即使是缩减了数据量的人工构建基准测试（即采集较少数据量）和程序生成的基准测试（例如，填空格式的示例）也与人工构建的基准测试具有高度一致性。这些结果表明，尽管社区长期关注少数基准测试，但所研究的建模改进仍然具有广泛适用性。

    Do question answering (QA) modeling improvements (e.g., choice of architecture and training procedure) hold consistently across the diverse landscape of QA benchmarks? To study this question, we introduce the notion of concurrence -- two benchmarks have high concurrence on a set of modeling approaches if they rank the modeling approaches similarly. We measure the concurrence between 32 QA benchmarks on a set of 20 diverse modeling approaches and find that human-constructed benchmarks have high concurrence amongst themselves, even if their passage and question distributions are very different. Surprisingly, even downsampled human-constructed benchmarks (i.e., collecting less data) and programmatically-generated benchmarks (e.g., cloze-formatted examples) have high concurrence with human-constructed benchmarks. These results indicate that, despite years of intense community focus on a small number of benchmarks, the modeling improvements studied hold broadly.
    

