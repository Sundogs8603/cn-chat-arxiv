# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ImageBind-LLM: Multi-modality Instruction Tuning.](http://arxiv.org/abs/2309.03905) | ImageBind-LLM是一种多模态指令调优的方法，通过图像-文本对齐训练，并利用联合嵌入实现了优秀的多模态指令跟随能力。 |
| [^2] | [A Function Interpretation Benchmark for Evaluating Interpretability Methods.](http://arxiv.org/abs/2309.03886) | 本文介绍了一个用于评估自动解释性方法的基准套件，该套件包括了类似于传统系统组件的函数。 |
| [^3] | [Zero-Shot Audio Captioning via Audibility Guidance.](http://arxiv.org/abs/2309.03884) | 本论文提出了一种通过听觉引导的零样本音频字幕生成方法，使用大型语言模型、多模态匹配网络和文本分类器来实现生成文本流畅性、忠实性和可听性。 |
| [^4] | [DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models.](http://arxiv.org/abs/2309.03883) | DoLa通过对比不同层次的逻辑差异，提高大型语言模型中的真实性和减少幻觉，无需外部知识或微调。 |
| [^5] | [On Large Language Models' Selection Bias in Multi-Choice Questions.](http://arxiv.org/abs/2309.03882) | 本研究发现大型语言模型在多项选择题中存在选择偏差，即倾向于选择特定位置上的选项。研究指出这一偏差的主要原因是选项编号，提出了一种名为PriDe的方法来减轻偏差，并展示了其高精度和稳定性。 |
| [^6] | [Introducing "Forecast Utterance" for Conversational Data Science.](http://arxiv.org/abs/2309.03877) | 本文引入了“预测话语”概念，通过自动和准确地解释用户的话语来解决对话式预测任务。实验结果验证了这一方法的可行性。 |
| [^7] | [OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs.](http://arxiv.org/abs/2309.03876) | OpinionGPT是一个指令调整大型语言模型(LLMs)的web演示，用户可以选择各种偏见并进行比较，它意在使模型的偏见显性和透明化。 |
| [^8] | [FLM-101B: An Open LLM and How to Train It with $100K Budget.](http://arxiv.org/abs/2309.03852) | 本文介绍了一种开放的LLM模型（FLM-101B）以及如何用10万美元的预算来训练它。通过采用增长策略，可以显著降低LLM训练的成本。同时，引入了一种系统的评估方法，以评估LLM的智能能力。 |
| [^9] | [Uncovering Drift in Textual Data: An Unsupervised Method for Detecting and Mitigating Drift in Machine Learning Models.](http://arxiv.org/abs/2309.03831) | 这项研究提出了一种无监督的方法来检测和减轻机器学习模型中的漂移。通过编码生产数据样本和模型训练数据，以及利用核统计检验和最大均值差异（MMD）距离度量来比较分布，可以有效估计漂移情况。 |
| [^10] | [USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset.](http://arxiv.org/abs/2309.03787) | 本论文提出了一种通过利用单词和整个文本之间的互相增强效应来提高情感分析性能的通用情感分析模型，并构建了新的情感文本分类和词性数据集。该模型在实验中表现出超越gpt-3.5-t的性能。 |
| [^11] | [Enhancing Pipeline-Based Conversational Agents with Large Language Models.](http://arxiv.org/abs/2309.03748) | 本文研究了如何使用大型语言模型（LLM）来增强基于流水线的对话系统。在设计和开发阶段，LLM可以帮助生成训练数据、提取实体和同义词、本地化和角色设计。在运营阶段，LLM可以辅助上下文化、意图分类、自动纠正话语、改写回复、摘要和使闭合问题回答能力。通过在私人银行领域的实验，证明了这些能力的有效性。 |
| [^12] | [The Daunting Dilemma with Sentence Encoders: Success on Standard Benchmarks, Failure in Capturing Basic Semantic Properties.](http://arxiv.org/abs/2309.03747) | 这篇论文调查了五种流行的句子编码器在下游任务表现和捕捉基本语义属性方面的能力。结果发现Sentence-Bert和USE模型在改写标准上表现良好，而LASER在同义词替换和反义词替换方面表现出色。 |
| [^13] | [Word segmentation granularity in Korean.](http://arxiv.org/abs/2309.03713) | 本文研究了韩语中的词语分割粒度，并发现在短语结构解析中，仅分割功能形态素并保留其他后缀可以获得最佳性能。 |
| [^14] | [Exploring an LM to generate Prolog Predicates from Mathematics Questions.](http://arxiv.org/abs/2309.03667) | 该论文调查了将语言模型用于从数学问题中生成Prolog谓词的潜力，并展示了通过微调模型和使用思维链的方法来提高模型的准确性。结果表明，生成Prolog代码的模型在性能上超过了基准模型。 |
| [^15] | [BNS-Net: A Dual-channel Sarcasm Detection Method Considering Behavior-level and Sentence-level Conflicts.](http://arxiv.org/abs/2309.03658) | BNS-Net是一种双通道讽刺检测方法，通过考虑行为级和句子级的冲突信息，有效捕捉讽刺表达中的隐含情感意义。 |
| [^16] | [Evaluating ChatGPT as a Recommender System: A Rigorous Approach.](http://arxiv.org/abs/2309.03613) | 这项研究评估了ChatGPT作为推荐系统的能力，通过探索其利用用户偏好进行推荐、重新排序推荐列表、利用相似用户信息以及处理冷启动情况的能力，并使用三个数据集进行了全面实验。 |
| [^17] | [Loquacity and Visible Emotion: ChatGPT as a Policy Advisor.](http://arxiv.org/abs/2309.03595) | 本文通过实验评估了ChatGPT在复杂写作任务中的潜力，发现它可以通过提供内容建议和生成大量语言正确的文本来加快工作流程，但它需要专家监督，并且可能产生肤浅或不相关的输出。 |
| [^18] | [Evaluating the Efficacy of Supervised Learning vs Large Language Models for Identifying Cognitive Distortions and Suicidal Risks in Chinese Social Media.](http://arxiv.org/abs/2309.03564) | 本研究评估了监督学习和大型语言模型在识别中国社交媒体中的认知偏差和自杀风险方面的功效。结果表明大型语言模型在这两个任务上具有很高的效果。 |
| [^19] | [All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm.](http://arxiv.org/abs/2309.03563) | 这项工作中，我们提出了一个端到端的One-to-All系统，可以在少样本场景下通过比较输入话语与所有标签候选项来充分利用标签语义。实验证明该方法在低资源情况下表现出最先进的性能，并通过预训练策略实现了跨领域零样本泛化。 |
| [^20] | [An Anchor Learning Approach for Citation Field Learning.](http://arxiv.org/abs/2309.03559) | 该论文介绍了一种用于引文字段学习的锚定学习方法，即CIFAL算法，通过利用锚定学习从不同引文样式的数据中捕捉引文模式，提高了引文字段学习性能，取得了2.83%的字段级F1分数提升。 |
| [^21] | [Machine Learning for Tangible Effects: Natural Language Processing for Uncovering the Illicit Massage Industry & Computer Vision for Tactile Sensing.](http://arxiv.org/abs/2309.03470) | 本文使用机器学习技术，通过自然语言处理和计算机视觉，揭示了非法按摩业中员工面临的劳动压力和语言障碍以及购买性服务者的收入、人口统计和社会压力，以帮助打击人口贩卖。 |
| [^22] | [XGen-7B Technical Report.](http://arxiv.org/abs/2309.03450) | XGen-7B是一种用于处理长序列的大型语言模型，通过克服开源LLMs在支持长序列长度方面的限制，并在标准基准上取得与最先进的开源LLMs相当或更好的结果，推进了研究进展和商业应用。 |
| [^23] | [Improving Open Information Extraction with Large Language Models: A Study on Demonstration Uncertainty.](http://arxiv.org/abs/2309.03433) | 本研究使用大型语言模型改进了开放信息抽取任务。通过提出上下文学习策略和演示不确定性量化模块，增强了模型的指令跟随能力和生成关系的自信度。 |
| [^24] | [From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models.](http://arxiv.org/abs/2309.03412) | 通过构建日语指令数据集并进行指令调整，验证了日语指令数据集的有效性，并表明通过指令调整可以提高下游任务的性能。 |
| [^25] | [Large Language Models as Optimizers.](http://arxiv.org/abs/2309.03409) | 本论文提出了一种简单有效的方法，利用大型语言模型(LLMs)作为优化器，通过自然语言描述优化任务。经过实验证明，该方法在线性回归和旅行推销员问题上表现出色，并且优化的最佳提示超过了人为设计的提示。 |
| [^26] | [RoDia: A New Dataset for Romanian Dialect Identification from Speech.](http://arxiv.org/abs/2309.03378) | RoDia是第一个用于罗马尼亚方言识别的语音数据集，包含来自五个不同地区的2小时手动标注数据，并提供了一组竞争模型作为未来研究的基准。 |
| [^27] | [Parameter Efficient Audio Captioning With Faithful Guidance Using Audio-text Shared Latent Representation.](http://arxiv.org/abs/2309.03340) | 本文提出了一种参数高效的音频字幕生成方法，通过使用音频-文本共享潜在表示来检测幻觉，并采用准确解码算法，使较小的模型能够实现与较大模型相当的性能。 |
| [^28] | [GPT Can Solve Mathematical Problems Without a Calculator.](http://arxiv.org/abs/2309.03241) | 本研究表明，通过充分训练，一个20亿参数的语言模型可以在没有计算器工具的情况下以几乎100%的准确度执行多位数的算术运算，超越了之前的GPT-4。这项研究还通过在附加的多步骤算术运算和数学问题的数据集上进行微调，展示了一个与GPT-4在中文数学问题上相似的性能。 |
| [^29] | [Implicit Design Choices and Their Impact on Emotion Recognition Model Development and Evaluation.](http://arxiv.org/abs/2309.03238) | 本研究探讨了情绪识别中的关键因素，包括收集多样化数据集、处理非典型训练数据、分析数据增强技术和注释方案的影响，以及使用对抗网络处理自然混淆变量和变化。研究结果对于开发准确和稳健的情绪识别模型具有重要意义。 |
| [^30] | [Learning a Patent-Informed Biomedical Knowledge Graph Reveals Technological Potential of Drug Repositioning Candidates.](http://arxiv.org/abs/2309.03227) | 本研究提出了一种使用药物专利和生物医学数据库相结合的方法，识别具有技术潜力和科学证据的药物再定位候选物。通过构建科学的生物医学知识图谱和基于专利的生物医学知识图谱，我们可以综合分析多种信息源，为药物再定位研究提供新的视角。 |
| [^31] | [Examining the Effectiveness of Chatbots in Gathering Family History Information in Comparison to the Standard In-Person Interview-Based Approach.](http://arxiv.org/abs/2309.03223) | 这项研究提出了一种针对家族历史收集的聊天机器人，并将其与传统面对面采访方法进行比较，探讨了聊天机器人的可行性。研究发现，聊天机器人方法能够克服地理和技术限制，并且具有较长的采访时间。 |
| [^32] | [Companion Animal Disease Diagnostics based on Literal-aware Medical Knowledge Graph Representation Learning.](http://arxiv.org/abs/2309.03219) | 这项研究提出了一种基于文本感知的医学知识图谱表示学习方法，以提高伴侣动物疾病诊断的效率。通过融合各种类型的文本信息和图结构，该方法能够捕捉到重要的实体和关系。 |
| [^33] | [Aligning Large Language Models for Clinical Tasks.](http://arxiv.org/abs/2309.02884) | 该论文讨论了对于临床任务的大型语言模型(LLMs)的对齐问题，提出了一种名为"expand-guess-refine"的医学问答对齐策略，并通过组合使用指令调优和in-prompt策略等技术来提高LLMs的性能。 |
| [^34] | [HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models.](http://arxiv.org/abs/2309.02706) | HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。 |
| [^35] | [Automating Behavioral Testing in Machine Translation.](http://arxiv.org/abs/2309.02553) | 本文提出了一种利用大型语言模型自动生成源句子的方法，以测试机器翻译模型在多种情况下的行为。通过对多个机器翻译系统应用该方法，发现在测试结果与传统准确率度量存在差异的情况下，仍可观察到一致的趋势。 |
| [^36] | [Wordle: A Microcosm of Life. Luck, Skill, Cheating, Loyalty, and Influence!.](http://arxiv.org/abs/2309.02110) | Wordle是一款流行的在线单词游戏，玩家需要在6次猜测中猜出每日目标单词。通过收集玩家的数据，研究者发现每天约有0.2-0.5%的玩家能在一次尝试中解决谜题，展示了玩家们的技巧和运气。 |
| [^37] | [Zero-shot information extraction from radiological reports using ChatGPT.](http://arxiv.org/abs/2309.01398) | 这项研究旨在使用ChatGPT语言模型从放射报告中无需标注数据即可提取有用信息，证明了大型语言模型在信息提取任务中的应用潜力。 |
| [^38] | [Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes.](http://arxiv.org/abs/2309.00237) | 使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。 |
| [^39] | [Transformers as Support Vector Machines.](http://arxiv.org/abs/2308.16898) | 这项工作建立了自注意力和硬间隔支持向量机问题之间的正式等价关系，通过转换器架构的优化几何来解决自然语言处理问题，同时揭示了梯度下降优化的转换器的隐式偏差。 |
| [^40] | [Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection.](http://arxiv.org/abs/2308.16763) | 该论文介绍了一种名为“Ladder-of-Thought”的方法，通过引入外部知识来提升立场检测任务中的语言模型的性能，解决了小型模型在应用先前内部知识时性能提升不明显的问题，以及大规模模型在效率方面的挑战。 |
| [^41] | [LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models.](http://arxiv.org/abs/2308.16137) | LM-Infinite研究了大规模语言模型在长序列上的长度推广失败问题，并提出了一种简单的即时推广方法，以更高效地利用现有模型的生成能力。 |
| [^42] | [EditSum: A Retrieve-and-Edit Framework for Source Code Summarization.](http://arxiv.org/abs/2308.13775) | 本文提出了一种基于检索和编辑的源代码摘要框架(EditSum)，用于自动生成结构化、信息丰富的代码摘要。 |
| [^43] | [ZC3: Zero-Shot Cross-Language Code Clone Detection.](http://arxiv.org/abs/2308.13754) | 本文提出了一种名为ZC3的跨语言零样本代码克隆检测方法。该方法设计了对比代码片段预测，形成不同编程语言之间的同构表示空间，并利用领域感知学习和循环一致性学习来进一步约束模型。 |
| [^44] | [Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models.](http://arxiv.org/abs/2308.11764) | 本文介绍了一种用于评估和减少开源弱大语言模型中幻觉问题的框架，并探索了知识注入和师生方法等技术来减轻低参数模型中的幻觉问题，实验结果表明，在挑战性领域中，这些模型的幻觉问题得到了减少。 |
| [^45] | [A Survey on Large Language Model based Autonomous Agents.](http://arxiv.org/abs/2308.11432) | 该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。 |
| [^46] | [Continual Pre-Training of Large Language Models: How to (re)warm your model?.](http://arxiv.org/abs/2308.04014) | 该论文研究了大型语言模型的持续预训练问题，探讨了热启动策略对于解决分布变化和提高计算效率的影响。 |
| [^47] | [Margin Maximization in Attention Mechanism.](http://arxiv.org/abs/2306.13596) | 这篇论文证明了，在softmax-attention模型中，通过在p或等价的W上运行梯度下降，可以收敛到一个最大边缘解，这将局部最优的标记与非最优的标记分隔开。这明确地将注意力机制形式化为标记分离机制。 |
| [^48] | [ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases.](http://arxiv.org/abs/2306.05301) | ToolAlpaca是一个自动生成工具使用语料库，实现紧凑的语言模型参加通用工具学习的框架。 |
| [^49] | [Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering.](http://arxiv.org/abs/2306.00526) | 该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。 |
| [^50] | [Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages.](http://arxiv.org/abs/2303.13592) | 本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。 |
| [^51] | [Claim Optimization in Computational Argumentation.](http://arxiv.org/abs/2212.08913) | 本文提出了主张优化的任务，旨在通过重新撰写论证性主张以优化其传递。使用大型语言模型生成多样化的候选主张集合，并使用各种质量指标选择最佳候选主张。在自动和人工评估中，我们的方法表现优于多种基准线，改善了60％的主张。 |
| [^52] | [BigText-QA: Question Answering over a Large-Scale Hybrid Knowledge Graph.](http://arxiv.org/abs/2212.05798) | BigText-QA引入了一种综合的QA方法，能够基于有结构化和非结构化知识的知识图回答复杂问题。 |
| [^53] | [Kernelized Concept Erasure.](http://arxiv.org/abs/2201.12191) | 通过核化线性极小极大博弈，防止特定非线性对手预测概念，但无法彻底解决非线性编码的概念擦除问题。 |

# 详细

[^1]: ImageBind-LLM: 多模态指令调优的方法

    ImageBind-LLM: Multi-modality Instruction Tuning. (arXiv:2309.03905v1 [cs.MM])

    [http://arxiv.org/abs/2309.03905](http://arxiv.org/abs/2309.03905)

    ImageBind-LLM是一种多模态指令调优的方法，通过图像-文本对齐训练，并利用联合嵌入实现了优秀的多模态指令跟随能力。

    

    我们提出了一种通过ImageBind对大型语言模型（LLMs）进行多模态指令调优的方法。现有的工作主要集中在语言和图像指令调优方面，与此不同，我们的ImageBind-LLM可以响应多模态条件，包括音频、3D点云、视频以及它们的嵌入空间算术，只需进行图像-文本对齐训练。在训练过程中，我们采用可学习的Bind网络来对齐LLaMA和ImageBind的图像编码器之间的嵌入空间。然后，通过Bind网络转换的图像特征被添加到LLaMA的所有层的单词标记中，通过一个无注意力和零初始化的门控机制逐步注入视觉指令。在ImageBind的联合嵌入的帮助下，简单的图像-文本训练使我们的模型展示出了卓越的多模态指令跟随能力。在推断过程中，多模态输入被送入相应的ImageBind编码器，并被处理。

    We present ImageBind-LLM, a multi-modality instruction tuning method of large language models (LLMs) via ImageBind. Existing works mainly focus on language and image instruction tuning, different from which, our ImageBind-LLM can respond to multi-modality conditions, including audio, 3D point clouds, video, and their embedding-space arithmetic by only image-text alignment training. During training, we adopt a learnable bind network to align the embedding space between LLaMA and ImageBind's image encoder. Then, the image features transformed by the bind network are added to word tokens of all layers in LLaMA, which progressively injects visual instructions via an attention-free and zero-initialized gating mechanism. Aided by the joint embedding of ImageBind, the simple image-text training enables our model to exhibit superior multi-modality instruction-following capabilities. During inference, the multi-modality inputs are fed into the corresponding ImageBind encoders, and processed by 
    
[^2]: 一个用于评估解释性方法的功能解释基准

    A Function Interpretation Benchmark for Evaluating Interpretability Methods. (arXiv:2309.03886v1 [cs.CL])

    [http://arxiv.org/abs/2309.03886](http://arxiv.org/abs/2309.03886)

    本文介绍了一个用于评估自动解释性方法的基准套件，该套件包括了类似于传统系统组件的函数。

    

    使用人类可读的描述标记神经网络子模块对于许多下游任务非常有用：这些描述可以暴露失败、引导干预，甚至可以解释重要的模型行为。到目前为止，大多数基于机械原理的已训练网络描述都涉及到小模型、狭义现象，并且需要大量人力。在不断增加的模型大小和复杂性中标记出所有人可解释的子计算几乎肯定需要能够自动生成和验证描述的工具。最近，利用学习模型进行标记的技术开始受到关注，但评估其有效性的方法有限且临时。我们应该如何验证和比较开放式标记工具？本文介绍了FIND（函数解释和描述），一个用于评估自动解释方法构建模块的基准套件。FIND包含了类似于传统系统的组件的函数。

    Labeling neural network submodules with human-legible descriptions is useful for many downstream tasks: such descriptions can surface failures, guide interventions, and perhaps even explain important model behaviors. To date, most mechanistic descriptions of trained networks have involved small models, narrowly delimited phenomena, and large amounts of human labor. Labeling all human-interpretable sub-computations in models of increasing size and complexity will almost certainly require tools that can generate and validate descriptions automatically. Recently, techniques that use learned models in-the-loop for labeling have begun to gain traction, but methods for evaluating their efficacy are limited and ad-hoc. How should we validate and compare open-ended labeling tools? This paper introduces FIND (Function INterpretation and Description), a benchmark suite for evaluating the building blocks of automated interpretability methods. FIND contains functions that resemble components of tr
    
[^3]: 通过听觉引导的零样本音频字幕生成

    Zero-Shot Audio Captioning via Audibility Guidance. (arXiv:2309.03884v1 [cs.SD])

    [http://arxiv.org/abs/2309.03884](http://arxiv.org/abs/2309.03884)

    本论文提出了一种通过听觉引导的零样本音频字幕生成方法，使用大型语言模型、多模态匹配网络和文本分类器来实现生成文本流畅性、忠实性和可听性。

    

    音频字幕生成的任务与图像和视频字幕生成类似，但却得到了较少的关注。我们提出了三个音频字幕生成的要求：（i）生成文本的流畅性，（ii）生成文本与输入音频的忠实性，以及（iii）可听性，即仅基于音频能够被感知的质量。我们的方法是一种零样本方法，即我们不会学习执行字幕生成。相反，字幕生成作为一个推理过程发生，涉及到三个对应于三个期望质量的网络：（i）一个大型语言模型，我们在这里选择了 GPT-2，（ii）一个在音频文件和文本之间提供匹配分数的模型，我们使用了一个名为 ImageBind 的多模态匹配网络，以及（iii）一种文本分类器，使用我们自动收集的数据集进行训练，这些数据集是通过指导 GPT-4 提示设计来指导可听和不可听文本的生成。

    The task of audio captioning is similar in essence to tasks such as image and video captioning. However, it has received much less attention. We propose three desiderata for captioning audio -- (i) fluency of the generated text, (ii) faithfulness of the generated text to the input audio, and the somewhat related (iii) audibility, which is the quality of being able to be perceived based only on audio. Our method is a zero-shot method, i.e., we do not learn to perform captioning. Instead, captioning occurs as an inference process that involves three networks that correspond to the three desired qualities: (i) A Large Language Model, in our case, for reasons of convenience, GPT-2, (ii) A model that provides a matching score between an audio file and a text, for which we use a multimodal matching network called ImageBind, and (iii) A text classifier, trained using a dataset we collected automatically by instructing GPT-4 with prompts designed to direct the generation of both audible and in
    
[^4]: DoLa：通过对比层次提高大型语言模型中的真实性

    DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models. (arXiv:2309.03883v1 [cs.CL])

    [http://arxiv.org/abs/2309.03883](http://arxiv.org/abs/2309.03883)

    DoLa通过对比不同层次的逻辑差异，提高大型语言模型中的真实性和减少幻觉，无需外部知识或微调。

    

    尽管大型语言模型（LLMs）具有令人印象深刻的能力，但它们容易出现幻觉，即生成与预训练期间观察到的事实偏离的内容。我们提出了一种简单的解码策略，用于减少预训练LLMs中的幻觉，它不需要在检索的外部知识或额外的微调上进行条件约束。我们的方法通过对比将较晚层和较早层投影到词汇空间得到的逻辑差异来获得下一个令牌的分布，利用了LLMs中的事实知识通常被证明局部化在特定的Transformer层中的事实。我们发现，这种通过对比层次的解码（DoLa）方法能够更好地展示事实知识，并减少生成不正确事实的情况。DoLa在多个选择任务和开放式生成任务中持续提升了真实性，例如改善了LLaMA系列模型在TruthfulQA上的表现。

    Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining. We propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning. Our approach obtains the next-token distribution by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space, exploiting the fact that factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers. We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts. DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA b
    
[^5]: 关于大型语言模型在多项选择题中的选择偏差问题

    On Large Language Models' Selection Bias in Multi-Choice Questions. (arXiv:2309.03882v1 [cs.CL])

    [http://arxiv.org/abs/2309.03882](http://arxiv.org/abs/2309.03882)

    本研究发现大型语言模型在多项选择题中存在选择偏差，即倾向于选择特定位置上的选项。研究指出这一偏差的主要原因是选项编号，提出了一种名为PriDe的方法来减轻偏差，并展示了其高精度和稳定性。

    

    多项选择题（MCQs）是大型语言模型（LLMs）研究中常见且重要的任务格式。我们的工作表明，LLMs在MCQs中存在固有的“选择偏差”，即LLMs倾向于选择特定位置上的选项（如“选项C”）。这种偏差在各种LLMs中普遍存在，使得它们在MCQs中对选项位置变化的性能变得脆弱。我们发现导致选择偏差的一个主要原因是选项编号，即与选项相关的ID符号A/B/C/D。为了减轻选择偏差，我们提出了一种新方法称为PriDe。PriDe首先将观察到的模型预测分布分解为对选项内容的内在预测和对选项ID的先验分布。然后，它通过在少量测试样本上对选项内容进行排列组合来估计先验，从而用于消除后续测试样本的偏差。我们证明了作为一种无标签、推断时间方法，PriDe可以实现高精度且稳定的解决方案。

    Multi-choice questions (MCQs) serve as a common yet important task format in the research of large language models (LLMs). Our work shows that LLMs exhibit an inherent "selection bias" in MCQs, which refers to LLMs' preferences to select options located at specific positions (like "Option C"). This bias is prevalent across various LLMs, making their performance vulnerable to option position changes in MCQs. We identify that one primary cause resulting in selection bias is option numbering, i.e., the ID symbols A/B/C/D associated with the options. To mitigate selection bias, we propose a new method called PriDe. PriDe first decomposes the observed model prediction distribution into an intrinsic prediction over option contents and a prior distribution over option IDs. It then estimates the prior by permutating option contents on a small number of test samples, which is used to debias the subsequent test samples. We demonstrate that, as a label-free, inference-time method, PriDe achieves 
    
[^6]: 引入“预测话语”用于对话式数据科学

    Introducing "Forecast Utterance" for Conversational Data Science. (arXiv:2309.03877v1 [cs.CL])

    [http://arxiv.org/abs/2309.03877](http://arxiv.org/abs/2309.03877)

    本文引入了“预测话语”概念，通过自动和准确地解释用户的话语来解决对话式预测任务。实验结果验证了这一方法的可行性。

    

    设想一个智能代理，能够通过直观自然的对话辅助用户进行预测任务，而不需要深入了解底层的机器学习（ML）过程。对于这一努力，代理面临的重大挑战是准确理解用户的预测目标，并因此制定精确的ML任务。本文通过引入一种称为“预测话语”的新概念，为实现这一雄心勃勃的目标迈出了创新的一步，并着重于从这些话语中自动和准确地解释用户的预测目标。具体而言，我们将任务框架化为一个槽填充问题，其中每个槽对应于目标预测任务的特定方面。然后，我们采用两种零样本方法来解决槽填充任务，即：1）实体提取（EE）和2）问答（QA）技术。我们在三个精心制作的数据集上进行的实验验证了我们方法的可行性。

    Envision an intelligent agent capable of assisting users in conducting forecasting tasks through intuitive, natural conversations, without requiring in-depth knowledge of the underlying machine learning (ML) processes. A significant challenge for the agent in this endeavor is to accurately comprehend the user's prediction goals and, consequently, formulate precise ML tasks. In this paper, we take a pioneering step towards this ambitious goal by introducing a new concept called Forecast Utterance and then focus on the automatic and accurate interpretation of users' prediction goals from these utterances. Specifically, we frame the task as a slot-filling problem, where each slot corresponds to a specific aspect of the goal prediction task. We then employ two zero-shot methods for solving the slot-filling task, namely: 1) Entity Extraction (EE), and 2) Question-Answering (QA) techniques. Our experiments, conducted with three meticulously crafted data sets, validate the viability of our am
    
[^7]: OpinionGPT: 模拟显性偏见的指令调整大型语言模型(LLMs)

    OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs. (arXiv:2309.03876v1 [cs.CL])

    [http://arxiv.org/abs/2309.03876](http://arxiv.org/abs/2309.03876)

    OpinionGPT是一个指令调整大型语言模型(LLMs)的web演示，用户可以选择各种偏见并进行比较，它意在使模型的偏见显性和透明化。

    

    最近，指令调整大型语言模型(LLMs)展示了生成与自然语言指令相匹配的回应的显著能力。然而，一个开放的研究问题涉及训练模型和它们的回应中固有的偏见。例如，如果用于调整LLM的数据主要由具有特定政治偏见的人编写，我们可能会期望生成的回答也共享这种偏见。目前的研究工作旨在除去这样的模型偏见，或抑制可能有偏见的回答。通过这个演示，我们对指令调整中的偏见持有不同的观点：我们的目标不是抑制它们，而是使它们显性和透明。为此，我们提供了OpinionGPT，一个网络演示，用户可以提问并选择所有他们希望调查的偏见。该演示将使用在代表每个选择偏见的文本上进行微调的模型来回答这个问题，从而实现并排比较。为了训练基础模型，我们选取了11个...

    Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable ability to generate fitting responses to natural language instructions. However, an open research question concerns the inherent biases of trained models and their responses. For instance, if the data used to tune an LLM is dominantly written by persons with a specific political bias, we might expect generated answers to share this bias. Current research work seeks to de-bias such models, or suppress potentially biased answers. With this demonstration, we take a different view on biases in instruction-tuning: Rather than aiming to suppress them, we aim to make them explicit and transparent. To this end, we present OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate. The demo will answer this question using a model fine-tuned on text representing each of the selected biases, allowing side-by-side comparison. To train the underlying model, we identified 11 
    
[^8]: FLM-101B：一种开放的LLM和如何用10万美元预算来训练它

    FLM-101B: An Open LLM and How to Train It with $100K Budget. (arXiv:2309.03852v1 [cs.CL])

    [http://arxiv.org/abs/2309.03852](http://arxiv.org/abs/2309.03852)

    本文介绍了一种开放的LLM模型（FLM-101B）以及如何用10万美元的预算来训练它。通过采用增长策略，可以显著降低LLM训练的成本。同时，引入了一种系统的评估方法，以评估LLM的智能能力。

    

    大型语言模型（LLMs）在自然语言处理和多模态任务中取得了显著的成功。然而，它们的发展面临两个主要挑战：（i）高计算成本；（ii）难以进行公平客观的评估。LLMs的价格昂贵，只有少数几家主要参与者有能力进行训练，从而限制了研究和应用机会。这凸显了成本效益的LLM训练的重要性。在本文中，我们采用了一种增长策略，显著降低LLM训练成本。我们证明了可以在10万美元的预算下训练具有101B参数和0.31TB令牌的LLM。我们还采用了一种系统的评估范式，用于对LLMs进行智能的智商评估，这是针对现有评估更注重知识能力的补充。我们引入了包括符号映射、规则理解、模式挖掘在内的重要智能方面的评估基准。

    Large language models (LLMs) have achieved remarkable success in NLP and multimodal tasks. Despite these successes, their development faces two main challenges: (i) high computational cost; and (ii) difficulty in conducting fair and objective evaluations. LLMs are prohibitively expensive, making it feasible for only a few major players to undertake their training, thereby constraining both research and application opportunities. This underscores the importance of cost-effective LLM training. In this paper, we utilize a growth strategy to significantly reduce LLM training cost. We demonstrate that an LLM with 101B parameters and 0.31TB tokens can be trained on a $100K budget. We also adopt a systematic evaluation paradigm for the IQ evaluation of LLMs, in complement to existing evaluations that focus more on knowledge-oriented abilities. We introduce our benchmark including evaluations on important aspects of intelligence including symbolic mapping, itrule understanding, pattern mining,
    
[^9]: 揭示文本数据中的漂移：一种无监督的方法用于检测和减轻机器学习模型中的漂移

    Uncovering Drift in Textual Data: An Unsupervised Method for Detecting and Mitigating Drift in Machine Learning Models. (arXiv:2309.03831v1 [cs.CL])

    [http://arxiv.org/abs/2309.03831](http://arxiv.org/abs/2309.03831)

    这项研究提出了一种无监督的方法来检测和减轻机器学习模型中的漂移。通过编码生产数据样本和模型训练数据，以及利用核统计检验和最大均值差异（MMD）距离度量来比较分布，可以有效估计漂移情况。

    

    机器学习中的漂移指的是数据或模型运行上下文的统计特性随时间变化而导致性能下降的现象。因此，保持对机器学习模型性能的持续监控过程对于预防潜在性能回退至关重要。然而，有监督的漂移检测方法需要人工标注，从而导致漂移检测和减轻过程时间较长。在我们提出的无监督漂移检测方法中，我们采用了两个步骤的流程。我们的第一步涉及将生产数据的一个样本作为目标分布，将模型训练数据作为参考分布进行编码。在第二步中，我们使用基于核的统计检验，并利用最大均值差异（MMD）距离度量来比较参考分布和目标分布，估计任何潜在的漂移。我们的方法还能确定生产数据子集的漂移情况。

    Drift in machine learning refers to the phenomenon where the statistical properties of data or context, in which the model operates, change over time leading to a decrease in its performance. Therefore, maintaining a constant monitoring process for machine learning model performance is crucial in order to proactively prevent any potential performance regression. However, supervised drift detection methods require human annotation and consequently lead to a longer time to detect and mitigate the drift. In our proposed unsupervised drift detection method, we follow a two step process. Our first step involves encoding a sample of production data as the target distribution, and the model training data as the reference distribution. In the second step, we employ a kernel-based statistical test that utilizes the maximum mean discrepancy (MMD) distance metric to compare the reference and target distributions and estimate any potential drift. Our method also identifies the subset of production
    
[^10]: 美国：通用情感分析模型和构建日语情感文本分类和词性数据集

    USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset. (arXiv:2309.03787v1 [cs.CL])

    [http://arxiv.org/abs/2309.03787](http://arxiv.org/abs/2309.03787)

    本论文提出了一种通过利用单词和整个文本之间的互相增强效应来提高情感分析性能的通用情感分析模型，并构建了新的情感文本分类和词性数据集。该模型在实验中表现出超越gpt-3.5-t的性能。

    

    情感分析是自然语言处理领域的一个关键任务，它包括文本级情感极性分类和词级情感极性确定。这种分析挑战模型在全面理解文本的同时，提取细微的信息。随着大语言模型（LLM）的兴起，情感分析的新途径得以开展。本文提出通过利用单词和整个文本之间的互相增强效应（MRE）来提高性能。它深入探讨了单词极性对整个段落的情感的影响。为了支持我们的研究，我们标注了四个新颖的情感文本分类和词性（SCPOS）数据集，基于现有的情感分类数据集进行构建。此外，我们还开发了一个拥有70亿参数规模的通用情感分析（USA）模型。实验证实，我们的模型的性能超过了gpt-3.5-t。

    Sentiment analysis is a pivotal task in the domain of natural language processing. It encompasses both text-level sentiment polarity classification and word-level Part of Speech(POS) sentiment polarity determination. Such analysis challenges models to understand text holistically while also extracting nuanced information. With the rise of Large Language Models(LLMs), new avenues for sentiment analysis have opened. This paper proposes enhancing performance by leveraging the Mutual Reinforcement Effect(MRE) between individual words and the overall text. It delves into how word polarity influences the overarching sentiment of a passage. To support our research, we annotated four novel Sentiment Text Classification and Part of Speech(SCPOS) datasets, building upon existing sentiment classification datasets. Furthermore, we developed a Universal Sentiment Analysis(USA) model, with a 7-billion parameter size. Experimental results revealed that our model surpassed the performance of gpt-3.5-t
    
[^11]: 使用大型语言模型增强基于流水线的对话系统

    Enhancing Pipeline-Based Conversational Agents with Large Language Models. (arXiv:2309.03748v1 [cs.CL])

    [http://arxiv.org/abs/2309.03748](http://arxiv.org/abs/2309.03748)

    本文研究了如何使用大型语言模型（LLM）来增强基于流水线的对话系统。在设计和开发阶段，LLM可以帮助生成训练数据、提取实体和同义词、本地化和角色设计。在运营阶段，LLM可以辅助上下文化、意图分类、自动纠正话语、改写回复、摘要和使闭合问题回答能力。通过在私人银行领域的实验，证明了这些能力的有效性。

    

    AI和深度学习的最新进展使得基于大型语言模型（LLM）的代理器（如GPT-4）取得了突破。然而，许多商业化对话系统开发工具是基于流水线的，并且在进行人类对话时存在限制。本文研究了LLM在以下两个阶段中增强基于流水线的对话系统的能力：1）设计和开发阶段；2）运营阶段。在1）中，LLM可以在生成训练数据、提取实体和同义词、本地化和角色设计方面提供帮助。在2）中，LLM可以辅助上下文化、意图分类以防止对话中断和处理超出范围的问题、自动纠正话语、改写回复、制定消歧问句、摘要和使闭合问题回答能力。我们在私人银行领域进行了使用GPT-4的非正式实验，以实际示例证明上述情景。

    The latest advancements in AI and deep learning have led to a breakthrough in large language model (LLM)-based agents such as GPT-4. However, many commercial conversational agent development tools are pipeline-based and have limitations in holding a human-like conversation. This paper investigates the capabilities of LLMs to enhance pipeline-based conversational agents during two phases: 1) in the design and development phase and 2) during operations. In 1) LLMs can aid in generating training data, extracting entities and synonyms, localization, and persona design. In 2) LLMs can assist in contextualization, intent classification to prevent conversational breakdown and handle out-of-scope questions, auto-correcting utterances, rephrasing responses, formulating disambiguation questions, summarization, and enabling closed question-answering capabilities. We conducted informal experiments with GPT-4 in the private banking domain to demonstrate the scenarios above with a practical example.
    
[^12]: 句子编码器面临的严峻困境：在标准基准上成功，在捕捉基本语义属性上失败

    The Daunting Dilemma with Sentence Encoders: Success on Standard Benchmarks, Failure in Capturing Basic Semantic Properties. (arXiv:2309.03747v1 [cs.CL])

    [http://arxiv.org/abs/2309.03747](http://arxiv.org/abs/2309.03747)

    这篇论文调查了五种流行的句子编码器在下游任务表现和捕捉基本语义属性方面的能力。结果发现Sentence-Bert和USE模型在改写标准上表现良好，而LASER在同义词替换和反义词替换方面表现出色。

    

    本文采用回顾性方法研究并比较了五种现有的流行句子编码器，即Sentence-BERT、Universal Sentence Encoder (USE)、LASER、InferSent和Doc2vec在下游任务的性能和捕捉基本语义属性的能力方面。初始时，我们在流行的SentEval基准上评估了这五种句子编码器，并发现多种句子编码器在各种下游任务上表现良好。然而，在所有情况下都没有找到一个单一的优胜者，因此我们设计了进一步的实验来深入了解它们的行为。具体而言，我们提出了四个语义评估标准，即改写、同义词替换、反义词替换和句子混乱，并使用这些标准评估了同样的五种句子编码器。我们发现Sentence-Bert和USE模型通过了改写标准，其中SBERT在两者之间更为优越。LASER在同义词替换和反义词替换标准方面表现出色。

    In this paper, we adopted a retrospective approach to examine and compare five existing popular sentence encoders, i.e., Sentence-BERT, Universal Sentence Encoder (USE), LASER, InferSent, and Doc2vec, in terms of their performance on downstream tasks versus their capability to capture basic semantic properties. Initially, we evaluated all five sentence encoders on the popular SentEval benchmark and found that multiple sentence encoders perform quite well on a variety of popular downstream tasks. However, being unable to find a single winner in all cases, we designed further experiments to gain a deeper understanding of their behavior. Specifically, we proposed four semantic evaluation criteria, i.e., Paraphrasing, Synonym Replacement, Antonym Replacement, and Sentence Jumbling, and evaluated the same five sentence encoders using these criteria. We found that the Sentence-Bert and USE models pass the paraphrasing criterion, with SBERT being the superior between the two. LASER dominates 
    
[^13]: 韩语中的词语分割粒度

    Word segmentation granularity in Korean. (arXiv:2309.03713v1 [cs.CL])

    [http://arxiv.org/abs/2309.03713](http://arxiv.org/abs/2309.03713)

    本文研究了韩语中的词语分割粒度，并发现在短语结构解析中，仅分割功能形态素并保留其他后缀可以获得最佳性能。

    

    本论文描述了韩语语言处理中的词语分割粒度。从以空格分隔的词语（称为辞词）到韩语中的一系列形态素，韩语中存在多个可能的词语分割粒度。针对特定的语言处理和语料库标注任务，已经提出并应用了多个不同的分割粒度水平，因为包括韩语在内的凝聚语言具有功能形态素和句法范畴之间的一对一映射关系。因此，我们分析了这些不同的分割粒度水平，并提供了韩语语言处理系统的示例以供参考。有趣的是，只分隔包括格标记和动词词尾在内的功能形态素，并保留其他后缀用于词法派生可以得到最佳的短语结构解析性能。这与此前韩语语言处理的最佳实践相矛盾，这一实践已经成为

    This paper describes word {segmentation} granularity in Korean language processing. From a word separated by blank space, which is termed an eojeol, to a sequence of morphemes in Korean, there are multiple possible levels of word segmentation granularity in Korean. For specific language processing and corpus annotation tasks, several different granularity levels have been proposed and utilized, because the agglutinative languages including Korean language have a one-to-one mapping between functional morpheme and syntactic category. Thus, we analyze these different granularity levels, presenting the examples of Korean language processing systems for future reference. Interestingly, the granularity by separating only functional morphemes including case markers and verbal endings, and keeping other suffixes for morphological derivation results in the optimal performance for phrase structure parsing. This contradicts previous best practices for Korean language processing, which has been th
    
[^14]: 从数学问题中生成Prolog谓词的语言模型的探索

    Exploring an LM to generate Prolog Predicates from Mathematics Questions. (arXiv:2309.03667v1 [cs.CL])

    [http://arxiv.org/abs/2309.03667](http://arxiv.org/abs/2309.03667)

    该论文调查了将语言模型用于从数学问题中生成Prolog谓词的潜力，并展示了通过微调模型和使用思维链的方法来提高模型的准确性。结果表明，生成Prolog代码的模型在性能上超过了基准模型。

    

    最近，由ChatGPT驱动的自然语言处理（NLP）的兴趣急剧增加。ChatGPT是一个基于Transformer的大规模生成语言模型，展示了在各种基于自然语言的任务上的多样性。然而，大型语言模型在需要推理的数学问题解决中通常表现较差。先前的研究已经证明了通过思维链激励在增强推理能力方面的有效性。现在，我们的目标是研究是否通过微调模型来生成逻辑语言（Prolog）代码，并将这些代码传递给编译器可以进一步提高准确性。因此，我们使用思维链来微调LLaMA7B作为基准模型，并开发其他用于生成Prolog代码、Prolog代码+思维链、思维链+Prolog代码的微调LLaMA7B模型。结果显示，Prolog生成模型超过了基准模型的性能，而还依然思维链。

    Recently, there has been a surge in interest in NLP driven by ChatGPT. ChatGPT, a transformer-based generative language model of substantial scale, exhibits versatility in performing various tasks based on natural language. Nevertheless, large language models often exhibit poor performance in solving mathematics questions that require reasoning. Prior research has demonstrated the effectiveness of chain-of-thought prompting in enhancing reasoning capabilities. Now, we aim to investigate whether fine-tuning a model for the generation of Prolog codes, a logic language, and subsequently passing these codes to a compiler can further improve accuracy. Consequently, we employ chain-of-thought to fine-tune LLaMA7B as a baseline model and develop other fine-tuned LLaMA7B models for the generation of Prolog code, Prolog code + chain-of-thought, and chain-of-thought + Prolog code, respectively. The results reveal that the Prolog generation model surpasses the baseline in performance, while the c
    
[^15]: BNS-Net:一种考虑行为级和句子级冲突的双通道讽刺检测方法

    BNS-Net: A Dual-channel Sarcasm Detection Method Considering Behavior-level and Sentence-level Conflicts. (arXiv:2309.03658v1 [cs.CL])

    [http://arxiv.org/abs/2309.03658](http://arxiv.org/abs/2309.03658)

    BNS-Net是一种双通道讽刺检测方法，通过考虑行为级和句子级的冲突信息，有效捕捉讽刺表达中的隐含情感意义。

    

    讽刺检测是一种二分类任务，旨在确定给定话语是否具有讽刺意味。在过去的十年中，讽刺检测已从经典的模式识别发展到深度学习方法，其中常用的特征包括用户配置文件、标点符号和情感词汇。在现实生活中的讽刺表达中，没有明确情感线索的行为常常作为隐含情感意义的载体。受到这一观察的启发，我们提出了一个名为BNS-Net的双通道讽刺检测模型。该模型在两个通道中考虑了行为和句子冲突。通道1: 行为级冲突通道基于核心动词重构文本，利用修改后的注意机制来突出冲突信息。通道2: 句子级冲突通道引入外部情感知识将文本分割为明确和隐含句子，捕捉它们之间的冲突。

    Sarcasm detection is a binary classification task that aims to determine whether a given utterance is sarcastic. Over the past decade, sarcasm detection has evolved from classical pattern recognition to deep learning approaches, where features such as user profile, punctuation and sentiment words have been commonly employed for sarcasm detection. In real-life sarcastic expressions, behaviors without explicit sentimental cues often serve as carriers of implicit sentimental meanings. Motivated by this observation, we proposed a dual-channel sarcasm detection model named BNS-Net. The model considers behavior and sentence conflicts in two channels. Channel 1: Behavior-level Conflict Channel reconstructs the text based on core verbs while leveraging the modified attention mechanism to highlight conflict information. Channel 2: Sentence-level Conflict Channel introduces external sentiment knowledge to segment the text into explicit and implicit sentences, capturing conflicts between them. To
    
[^16]: 评估ChatGPT作为推荐系统的严谨方法

    Evaluating ChatGPT as a Recommender System: A Rigorous Approach. (arXiv:2309.03613v1 [cs.IR])

    [http://arxiv.org/abs/2309.03613](http://arxiv.org/abs/2309.03613)

    这项研究评估了ChatGPT作为推荐系统的能力，通过探索其利用用户偏好进行推荐、重新排序推荐列表、利用相似用户信息以及处理冷启动情况的能力，并使用三个数据集进行了全面实验。

    

    由于其卓越的自然语言处理能力，大型AI语言模型近年来备受关注。它们在语言相关任务中具有重要贡献，包括基于提示的学习，因此对于各种特定任务非常有价值。这种方法释放了它们的全部潜力，提高了准确性和泛化性。研究界正在积极探索它们的应用，ChatGPT也因此获得了认可。尽管大型语言模型已经有了广泛的研究，但其在推荐场景中的潜力仍待探索。本研究旨在填补这一空白，通过探究ChatGPT作为零-shot推荐系统的能力。我们的目标包括评估其利用用户偏好进行推荐、重新排序现有推荐列表、利用相似用户的信息以及处理冷启动情况的能力。我们通过对三个数据集（MovieLens Small、Last.FM和Facebook Bo）进行全面实验来评估ChatGPT的性能。

    Recent popularity surrounds large AI language models due to their impressive natural language capabilities. They contribute significantly to language-related tasks, including prompt-based learning, making them valuable for various specific tasks. This approach unlocks their full potential, enhancing precision and generalization. Research communities are actively exploring their applications, with ChatGPT receiving recognition. Despite extensive research on large language models, their potential in recommendation scenarios still needs to be explored. This study aims to fill this gap by investigating ChatGPT's capabilities as a zero-shot recommender system. Our goals include evaluating its ability to use user preferences for recommendations, reordering existing recommendation lists, leveraging information from similar users, and handling cold-start situations. We assess ChatGPT's performance through comprehensive experiments using three datasets (MovieLens Small, Last.FM, and Facebook Bo
    
[^17]: 多言多语与显性情感：ChatGPT作为政策顾问

    Loquacity and Visible Emotion: ChatGPT as a Policy Advisor. (arXiv:2309.03595v1 [cs.CL])

    [http://arxiv.org/abs/2309.03595](http://arxiv.org/abs/2309.03595)

    本文通过实验评估了ChatGPT在复杂写作任务中的潜力，发现它可以通过提供内容建议和生成大量语言正确的文本来加快工作流程，但它需要专家监督，并且可能产生肤浅或不相关的输出。

    

    ChatGPT是一款寻求模拟人类对话能力的软件，引起了越来越多的关注。有时它被描述为一款开创性的生产力辅助工具，包括用于创意工作。本文通过进行实验来评估ChatGPT在复杂写作任务中的潜力。我们要求该软件为意大利银行董事会撰写一份政策简报。我们发现，ChatGPT能够通过提供良好结构的内容建议以及在几秒钟内生成大量的语言正确的文本，加快工作流程。然而，它需要大量专家监督，这在一定程度上抵消了生产力的增益。如果应用程序使用得不够谨慎，输出可能会不正确、肤浅或不相关。肤浅性在面向高级受众的政策建议背景下尤其是一个问题。

    ChatGPT, a software seeking to simulate human conversational abilities, is attracting increasing attention. It is sometimes portrayed as a groundbreaking productivity aid, including for creative work. In this paper, we run an experiment to assess its potential in complex writing tasks. We ask the software to compose a policy brief for the Board of the Bank of Italy. We find that ChatGPT can accelerate workflows by providing well-structured content suggestions, and by producing extensive, linguistically correct text in a matter of seconds. It does, however, require a significant amount of expert supervision, which partially offsets productivity gains. If the app is used naively, output can be incorrect, superficial, or irrelevant. Superficiality is an especially problematic limitation in the context of policy advice intended for high-level audiences.
    
[^18]: 评估监督学习和大型语言模型在识别中国社交媒体中的认知偏差和自杀风险方面的功效

    Evaluating the Efficacy of Supervised Learning vs Large Language Models for Identifying Cognitive Distortions and Suicidal Risks in Chinese Social Media. (arXiv:2309.03564v1 [cs.CL])

    [http://arxiv.org/abs/2309.03564](http://arxiv.org/abs/2309.03564)

    本研究评估了监督学习和大型语言模型在识别中国社交媒体中的认知偏差和自杀风险方面的功效。结果表明大型语言模型在这两个任务上具有很高的效果。

    

    大型语言模型，特别是类似快速发展的GPT系列，因其广泛的影响力而受到关注。尽管在心理学等医学领域对它们的适用性存在浓厚兴趣，但对真实世界数据的具体探索仍然很少。与此同时，社交媒体平台上的用户越来越多地表达个人情感；在特定的主题下，这些情感通常表现为消极情绪，有时会升级为自杀倾向。及时辨识这样的认知偏差和自杀风险对有效干预和潜在避免严重情况至关重要。我们的研究通过在中国社交媒体平台上进行两个关键任务：自杀风险和认知偏差识别的实验，进入了这个领域。使用监督学习作为基准，我们通过三种不同的策略：零样本、少样本和微调，考察了大型语言模型的功效。

    Large language models, particularly those akin to the rapidly progressing GPT series, are gaining traction for their expansive influence. While there is keen interest in their applicability within medical domains such as psychology, tangible explorations on real-world data remain scant. Concurrently, users on social media platforms are increasingly vocalizing personal sentiments; under specific thematic umbrellas, these sentiments often manifest as negative emotions, sometimes escalating to suicidal inclinations. Timely discernment of such cognitive distortions and suicidal risks is crucial to effectively intervene and potentially avert dire circumstances. Our study ventured into this realm by experimenting on two pivotal tasks: suicidal risk and cognitive distortion identification on Chinese social media platforms. Using supervised learning as a baseline, we examined and contrasted the efficacy of large language models via three distinct strategies: zero-shot, few-shot, and fine-tunin
    
[^19]: 全部标签在一起：基于高效的标签语义编码范式的低资源意图检测

    All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm. (arXiv:2309.03563v1 [cs.CL])

    [http://arxiv.org/abs/2309.03563](http://arxiv.org/abs/2309.03563)

    这项工作中，我们提出了一个端到端的One-to-All系统，可以在少样本场景下通过比较输入话语与所有标签候选项来充分利用标签语义。实验证明该方法在低资源情况下表现出最先进的性能，并通过预训练策略实现了跨领域零样本泛化。

    

    在意图检测任务中，利用意图标签的有意义的语义信息对于少样本场景可能特别有益。然而，现有的少样本意图检测方法要么忽略了意图标签，（例如将意图视为索引），要么没有充分利用这些信息（例如仅使用部分意图标签）。在这项工作中，我们提出了一个端到端的One-to-All系统，可以将输入话语与所有标签候选项进行比较。系统可以通过这种方式充分利用标签语义。在三个少样本意图检测任务上的实验证明，当训练资源极为有限时，One-to-All特别有效，在1-shot、3-shot和5-shot设置中实现了最先进的性能。此外，我们还提出了一种新颖的预训练策略，利用了从释义得到的间接监督信号，实现了对意图检测任务的跨领域零样本泛化。我们的代码位于https://github.com/jian

    In intent detection tasks, leveraging meaningful semantic information from intent labels can be particularly beneficial for few-shot scenarios. However, existing few-shot intent detection methods either ignore the intent labels, (e.g. treating intents as indices) or do not fully utilize this information (e.g. only using part of the intent labels). In this work, we present an end-to-end One-to-All system that enables the comparison of an input utterance with all label candidates. The system can then fully utilize label semantics in this way. Experiments on three few-shot intent detection tasks demonstrate that One-to-All is especially effective when the training resource is extremely scarce, achieving state-of-the-art performance in 1-, 3- and 5-shot settings. Moreover, we present a novel pretraining strategy for our model that utilizes indirect supervision from paraphrasing, enabling zero-shot cross-domain generalization on intent detection tasks. Our code is at https://github.com/jian
    
[^20]: 一种用于引文字段学习的锚定学习方法

    An Anchor Learning Approach for Citation Field Learning. (arXiv:2309.03559v1 [cs.CL])

    [http://arxiv.org/abs/2309.03559](http://arxiv.org/abs/2309.03559)

    该论文介绍了一种用于引文字段学习的锚定学习方法，即CIFAL算法，通过利用锚定学习从不同引文样式的数据中捕捉引文模式，提高了引文字段学习性能，取得了2.83%的字段级F1分数提升。

    

    引文字段学习是将引文字符串分割为感兴趣的字段，如作者、标题和场所。从引文中提取这些字段对于引文索引、研究者个人资料分析等非常重要。用户生成的资源，如学术主页和个人简历，提供了丰富的引文字段信息。然而，由于引文样式不一致、句法不完整和训练数据不足，从这些资源中提取字段是具有挑战性的。为了解决这些问题，我们提出了一种新颖的算法CIFAL（通过锚定学习进行引文字段学习），以提高引文字段学习性能。CIFAL利用锚定学习，它对于任何预训练语言模型都是模型不可知的，帮助捕捉不同引文样式的引文模式。实验证明，CIFAL在引文字段学习方面优于最先进的方法，在字段级F1分数上取得了2.83%的提升。大量的

    Citation field learning is to segment a citation string into fields of interest such as author, title, and venue. Extracting such fields from citations is crucial for citation indexing, researcher profile analysis, etc. User-generated resources like academic homepages and Curriculum Vitae, provide rich citation field information. However, extracting fields from these resources is challenging due to inconsistent citation styles, incomplete sentence syntax, and insufficient training data. To address these challenges, we propose a novel algorithm, CIFAL (citation field learning by anchor learning), to boost the citation field learning performance. CIFAL leverages the anchor learning, which is model-agnostic for any Pre-trained Language Model, to help capture citation patterns from the data of different citation styles. The experiments demonstrate that CIFAL outperforms state-of-the-art methods in citation field learning, achieving a 2.83% improvement in field-level F1-scores. Extensive an
    
[^21]: 机器学习在具体效果中的应用：自然语言处理揭示非法按摩业和计算机视觉实现触觉感知

    Machine Learning for Tangible Effects: Natural Language Processing for Uncovering the Illicit Massage Industry & Computer Vision for Tactile Sensing. (arXiv:2309.03470v1 [cs.CL])

    [http://arxiv.org/abs/2309.03470](http://arxiv.org/abs/2309.03470)

    本文使用机器学习技术，通过自然语言处理和计算机视觉，揭示了非法按摩业中员工面临的劳动压力和语言障碍以及购买性服务者的收入、人口统计和社会压力，以帮助打击人口贩卖。

    

    在这篇论文中，我探讨了两个问题：计算机科学如何用于打击人口贩卖？计算机视觉如何创建触觉感知？我使用自然语言处理（NLP）监控美国的非法按摩业（IMI），这是一个价值数十亿美元的行业，不仅提供治疗性按摩，还提供商业性服务。该行业的员工通常是少有工作机会的移民妇女，容易受到欺诈、胁迫和其他人口贩卖问题的影响。监测空间时间趋势有助于预防非法按摩业中的人口贩卖。通过创建包括Google Places、Rubmaps和AMPReviews等三个可公开访问的网站的数据集，结合诸如词袋和Word2Vec等NLP技术，我展示了如何洞察员工面临的劳动压力和语言障碍，以及影响购买性服务者的收入、人口统计和社会压力。我呼吁其他研究人员行动起来。

    I explore two questions in this thesis: how can computer science be used to fight human trafficking? And how can computer vision create a sense of touch?  I use natural language processing (NLP) to monitor the United States illicit massage industry (IMI), a multi-billion dollar industry that offers not just therapeutic massages but also commercial sexual services. Employees of this industry are often immigrant women with few job opportunities, leaving them vulnerable to fraud, coercion, and other facets of human trafficking. Monitoring spatiotemporal trends helps prevent trafficking in the IMI. By creating datasets with three publicly-accessible websites: Google Places, Rubmaps, and AMPReviews, combined with NLP techniques such as bag-of-words and Word2Vec, I show how to derive insights into the labor pressures and language barriers that employees face, as well as the income, demographics, and societal pressures affecting sex buyers. I include a call-to-action to other researchers give
    
[^22]: XGen-7B技术报告

    XGen-7B Technical Report. (arXiv:2309.03450v1 [cs.CL])

    [http://arxiv.org/abs/2309.03450](http://arxiv.org/abs/2309.03450)

    XGen-7B是一种用于处理长序列的大型语言模型，通过克服开源LLMs在支持长序列长度方面的限制，并在标准基准上取得与最先进的开源LLMs相当或更好的结果，推进了研究进展和商业应用。

    

    大型语言模型（LLMs）在各个领域变得普遍，改变了我们与信息交互和进行研究的方式。然而，大多数高性能的LLMs仍然受限于专有墙壁，阻碍了科学进展。另一方面，大多数开源的LLMs在支持较长序列长度方面有限，而这对于许多需要对输入上下文进行推理的任务来说是一个关键要求。为了解决这个问题，我们训练了XGen，一系列7B参数的模型，可支持长度为8K的序列和1.5T个令牌。我们还对XGen模型进行了公共领域教学数据的微调，创建了它们的教学优化版本（XGen-Inst）。我们将我们的模型开源，用于研究进展和商业应用。我们对标准基准的评估结果显示，与最先进的开源LLMs相比，XGen模型实现了相当或更好的结果。我们针对长序列建模任务进行了有针对性的评估。

    Large Language Models (LLMs) have become ubiquitous across various domains, transforming the way we interact with information and conduct research. However, most high-performing LLMs remain confined behind proprietary walls, hindering scientific progress. Most open-source LLMs, on the other hand, are limited in their ability to support longer sequence lengths, which is a key requirement for many tasks that require inference over an input context. To address this, we have trained XGen, a series of 7B parameter models on up to 8K sequence length for up to 1.5T tokens. We have also finetuned the XGen models on public-domain instructional data, creating their instruction-tuned counterparts (XGen-Inst). We open-source our models for both research advancements and commercial applications. Our evaluation on standard benchmarks shows that XGen models achieve comparable or better results when compared with state-of-the-art open-source LLMs. Our targeted evaluation on long sequence modeling task
    
[^23]: 使用大型语言模型改进开放信息抽取：对演示不确定性进行研究

    Improving Open Information Extraction with Large Language Models: A Study on Demonstration Uncertainty. (arXiv:2309.03433v1 [cs.CL])

    [http://arxiv.org/abs/2309.03433](http://arxiv.org/abs/2309.03433)

    本研究使用大型语言模型改进了开放信息抽取任务。通过提出上下文学习策略和演示不确定性量化模块，增强了模型的指令跟随能力和生成关系的自信度。

    

    开放信息抽取（OIE）任务旨在从非结构化文本中提取结构化事实，通常以（主体，关系，客体）三元组的形式存在。尽管像ChatGPT这样的大型语言模型具有作为通用任务解决器的潜力，但由于两个关键问题，它们在OIE任务中落后于最先进的（监督）方法。首先，由于对模型微调的限制，LLMs很难区分无关的上下文和相关关系，并生成结构化输出。其次，LLMs基于概率自回归生成响应，导致预测的关系缺乏自信。在本文中，我们评估了LLMs在改进OIE任务中的能力。特别是，我们提出了各种上下文学习策略来增强LLM的指令跟随能力，并提出了演示不确定性量化模块来增强生成关系的自信度。我们对三个OIE基准数据集进行的实验证明了我们的方法的有效性。

    Open Information Extraction (OIE) task aims at extracting structured facts from unstructured text, typically in the form of (subject, relation, object) triples. Despite the potential of large language models (LLMs) like ChatGPT as a general task solver, they lag behind state-of-the-art (supervised) methods in OIE tasks due to two key issues. First, LLMs struggle to distinguish irrelevant context from relevant relations and generate structured output due to the restrictions on fine-tuning the model. Second, LLMs generates responses autoregressively based on probability, which makes the predicted relations lack confidence. In this paper, we assess the capabilities of LLMs in improving the OIE task. Particularly, we propose various in-context learning strategies to enhance LLM's instruction-following ability and a demonstration uncertainty quantification module to enhance the confidence of the generated relations. Our experiments on three OIE benchmark datasets show that our approach hold
    
[^24]: 从基础到对话式：日语指令数据集和调整大型语言模型

    From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models. (arXiv:2309.03412v1 [cs.CL])

    [http://arxiv.org/abs/2309.03412](http://arxiv.org/abs/2309.03412)

    通过构建日语指令数据集并进行指令调整，验证了日语指令数据集的有效性，并表明通过指令调整可以提高下游任务的性能。

    

    对于大型语言模型（LLMs）能够变得交互性来说，指令调整是至关重要的。尽管存在许多英文的指令调整数据集，但其他语言缺乏明显。而且，它们在非英语语言中的效果尚未得到很好的验证。我们通过扩展和筛选现有数据集构建了一个日语指令数据集，并将该数据集应用于一个日语预训练基础模型。我们使用我们的指令数据集对日语和英语现有模型进行了低秩适应（LoRA）调整。我们从数量和质量两个角度评估了这些模型。结果确认了日语指令数据集的有效性。结果还表明，即使是相对较小的LLMs，通过指令调整也能提高下游任务的性能。我们的指令数据集、调整模型和实现均可在网上公开获取。

    Instruction tuning is essential for large language models (LLMs) to become interactive. While many instruction tuning datasets exist in English, there is a noticeable lack in other languages. Also, their effectiveness has not been well verified in non-English languages. We construct a Japanese instruction dataset by expanding and filtering existing datasets and apply the dataset to a Japanese pre-trained base model. We performed Low-Rank Adaptation (LoRA) tuning on both Japanese and English existing models using our instruction dataset. We evaluated these models from both quantitative and qualitative perspectives. As a result, the effectiveness of Japanese instruction datasets is confirmed. The results also indicate that even with relatively small LLMs, performances in downstream tasks would be improved through instruction tuning. Our instruction dataset, tuned models, and implementation are publicly available online.
    
[^25]: 大型语言模型作为优化器

    Large Language Models as Optimizers. (arXiv:2309.03409v1 [cs.LG])

    [http://arxiv.org/abs/2309.03409](http://arxiv.org/abs/2309.03409)

    本论文提出了一种简单有效的方法，利用大型语言模型(LLMs)作为优化器，通过自然语言描述优化任务。经过实验证明，该方法在线性回归和旅行推销员问题上表现出色，并且优化的最佳提示超过了人为设计的提示。

    

    优化是无处不在的。虽然基于导数的算法在各种问题上是强大的工具，但是没有梯度对许多实际应用提出了挑战。在这项工作中，我们提出了一种简单有效的方法，利用大型语言模型(LLMs)作为优化器，其中优化任务以自然语言形式描述。在每一次优化步骤中，LLM从包含先前生成的解与其值的提示中生成新的解，然后对新的解进行评估并添加到提示中，用于下一次优化步骤。我们首先展示了OPRO在线性回归和旅行推销员问题上的应用，然后转向提示优化，目标是找到能最大化任务准确性的指令。通过使用各种LLM，我们证明了OPRO优化的最佳提示在GSM8K上击败了人为设计的提示高达8%，在Big-Bench Hard任务上击败了人为设计的提示高达50%。

    Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.
    
[^26]: RoDia: 一份用于罗马尼亚方言识别的新数据集

    RoDia: A New Dataset for Romanian Dialect Identification from Speech. (arXiv:2309.03378v1 [cs.CL])

    [http://arxiv.org/abs/2309.03378](http://arxiv.org/abs/2309.03378)

    RoDia是第一个用于罗马尼亚方言识别的语音数据集，包含来自五个不同地区的2小时手动标注数据，并提供了一组竞争模型作为未来研究的基准。

    

    方言识别是语音处理和语言技术中关键的任务，可以增强诸如语音识别、说话人验证等各种应用。尽管大多数研究都集中在广为使用的语言的方言识别上，但对于罗马尼亚这种资源有限的低资源语言的方言识别却没有得到足够的关注。为了填补这一研究空白，我们引入了RoDia，这是第一个用于罗马尼亚方言识别的语音数据集。RoDia数据集包含了来自罗马尼亚五个不同地区的各种语音样本，涵盖了城市和农村环境，总共有2小时的手动标注语音数据。除了我们的数据集之外，我们还介绍了一组可作为未来研究基准的竞争模型。最高得分的模型的宏F1分数为59.83%，微F1分数为62.08%，说明该任务具有挑战性。因此，我们认为RoDia是一个有价值的资源。

    Dialect identification is a critical task in speech processing and language technology, enhancing various applications such as speech recognition, speaker verification, and many others. While most research studies have been dedicated to dialect identification in widely spoken languages, limited attention has been given to dialect identification in low-resource languages, such as Romanian. To address this research gap, we introduce RoDia, the first dataset for Romanian dialect identification from speech. The RoDia dataset includes a varied compilation of speech samples from five distinct regions of Romania, covering both urban and rural environments, totaling 2 hours of manually annotated speech data. Along with our dataset, we introduce a set of competitive models to be used as baselines for future research. The top scoring model achieves a macro F1 score of 59.83% and a micro F1 score of 62.08%, indicating that the task is challenging. We thus believe that RoDia is a valuable resource
    
[^27]: 使用音频-文本共享潜在表示的参数高效音频字幕生成方法

    Parameter Efficient Audio Captioning With Faithful Guidance Using Audio-text Shared Latent Representation. (arXiv:2309.03340v1 [cs.CL])

    [http://arxiv.org/abs/2309.03340](http://arxiv.org/abs/2309.03340)

    本文提出了一种参数高效的音频字幕生成方法，通过使用音频-文本共享潜在表示来检测幻觉，并采用准确解码算法，使较小的模型能够实现与较大模型相当的性能。

    

    在多模态文本生成任务中，已有大量的研究专注于开发预训练的Transformer架构。然而，尽管性能有所提升，这些模型往往过于参数化，因此容易出现幻觉和内存占用过大的问题，使它们在边缘设备上部署具有挑战性。本文针对自动化音频字幕应用中的这两个问题进行了研究。首先，我们提出了一种用于生成幻觉音频字幕的数据增强技术，并证明了基于音频-文本共享潜在空间的相似性对于检测幻觉是合适的。然后，我们提出了一种参数高效的推理时准确解码算法，使较小的音频字幕生成模型能够与使用更多数据训练的较大模型的性能相当。在束搜索解码步骤中，较小的模型利用音频-文本共享潜在表示来语义对齐生成的文本与相应的输入音频。准确的引导

    There has been significant research on developing pretrained transformer architectures for multimodal-to-text generation tasks. Albeit performance improvements, such models are frequently overparameterized, hence suffer from hallucination and large memory footprint making them challenging to deploy on edge devices. In this paper, we address both these issues for the application of automated audio captioning. First, we propose a data augmentation technique for generating hallucinated audio captions and show that similarity based on an audio-text shared latent space is suitable for detecting hallucination. Then, we propose a parameter efficient inference time faithful decoding algorithm that enables smaller audio captioning models with performance equivalent to larger models trained with more data. During the beam decoding step, the smaller model utilizes an audio-text shared latent representation to semantically align the generated text with corresponding input audio. Faithful guidance 
    
[^28]: GPT可以在没有计算器的情况下解决数学问题

    GPT Can Solve Mathematical Problems Without a Calculator. (arXiv:2309.03241v1 [cs.LG])

    [http://arxiv.org/abs/2309.03241](http://arxiv.org/abs/2309.03241)

    本研究表明，通过充分训练，一个20亿参数的语言模型可以在没有计算器工具的情况下以几乎100%的准确度执行多位数的算术运算，超越了之前的GPT-4。这项研究还通过在附加的多步骤算术运算和数学问题的数据集上进行微调，展示了一个与GPT-4在中文数学问题上相似的性能。

    

    以往的研究通常认为大型语言模型无法在没有计算器工具的情况下准确执行算术运算，特别是超过8位数字的乘法，以及涉及小数和分数的运算。本文旨在挑战这种误解。通过充分的训练数据，一个拥有20亿参数的语言模型可以以近乎100%的准确度执行多位数的算术运算，而且没有数据泄露，显著超过了GPT-4（其多位数乘法准确率仅为4.3%）。我们还演示了我们的MathGLM，它是通过在包含了文本描述的附加多步骤算术运算和数学问题的数据集上从GLM-10B微调而成的，它在一个包含5000个样本的中文数学问题测试集上的表现与GPT-4相似。

    Previous studies have typically assumed that large language models are unable to accurately perform arithmetic operations, particularly multiplication of >8 digits, and operations involving decimals and fractions, without the use of calculator tools. This paper aims to challenge this misconception. With sufficient training data, a 2 billion-parameter language model can accurately perform multi-digit arithmetic operations with almost 100% accuracy without data leakage, significantly surpassing GPT-4 (whose multi-digit multiplication accuracy is only 4.3%). We also demonstrate that our MathGLM, fine-tuned from GLM-10B on a dataset with additional multi-step arithmetic operations and math problems described in text, achieves similar performance to GPT-4 on a 5,000-samples Chinese math problem test set.
    
[^29]: 隐含设计选择及其对情绪识别模型开发和评估的影响

    Implicit Design Choices and Their Impact on Emotion Recognition Model Development and Evaluation. (arXiv:2309.03238v1 [cs.LG])

    [http://arxiv.org/abs/2309.03238](http://arxiv.org/abs/2309.03238)

    本研究探讨了情绪识别中的关键因素，包括收集多样化数据集、处理非典型训练数据、分析数据增强技术和注释方案的影响，以及使用对抗网络处理自然混淆变量和变化。研究结果对于开发准确和稳健的情绪识别模型具有重要意义。

    

    情绪识别是一项复杂的任务，因为情绪的感知和表达具有固有的主观性。情绪的主观性在开发准确和稳健的计算模型方面提出了重大挑战。本论文考察了情绪识别的关键要素，从收集旨在考虑情绪产生心理因素的多样化数据集开始。为了应对非典型训练数据的挑战，本研究收集了多模态应激情绪数据集，在数据收集过程中引入了受控的压力因素，以更好地反映情绪产生的真实环境影响。为了解决标签主观性问题，该研究全面分析了数据增强技术和注释方案如何影响情绪感知和注释者标签。此外，该研究通过使用对抗网络来处理自然混淆变量和变化，以隔离关键因素（如压力）与学习到的情绪表示之间的关系。

    Emotion recognition is a complex task due to the inherent subjectivity in both the perception and production of emotions. The subjectivity of emotions poses significant challenges in developing accurate and robust computational models. This thesis examines critical facets of emotion recognition, beginning with the collection of diverse datasets that account for psychological factors in emotion production.  To handle the challenge of non-representative training data, this work collects the Multimodal Stressed Emotion dataset, which introduces controlled stressors during data collection to better represent real-world influences on emotion production. To address issues with label subjectivity, this research comprehensively analyzes how data augmentation techniques and annotation schemes impact emotion perception and annotator labels. It further handles natural confounding variables and variations by employing adversarial networks to isolate key factors like stress from learned emotion rep
    
[^30]: 学习基于专利的生物医学知识图谱揭示药物再定位候选物的技术潜力

    Learning a Patent-Informed Biomedical Knowledge Graph Reveals Technological Potential of Drug Repositioning Candidates. (arXiv:2309.03227v1 [cs.AI])

    [http://arxiv.org/abs/2309.03227](http://arxiv.org/abs/2309.03227)

    本研究提出了一种使用药物专利和生物医学数据库相结合的方法，识别具有技术潜力和科学证据的药物再定位候选物。通过构建科学的生物医学知识图谱和基于专利的生物医学知识图谱，我们可以综合分析多种信息源，为药物再定位研究提供新的视角。

    

    药物再定位是一种发现现有药物新治疗用途的有前途的策略，近年来在计算科学文献中使用生物医学数据库进行了广泛探索。然而，药物再定位候选物的技术潜力经常被忽视。本研究提出了一种新的方法，综合分析药物专利和生物医学数据库等多种信息源，识别具有技术潜力和科学证据的药物再定位候选物。首先，我们构建了一个科学的生物医学知识图谱（s-BKG），包括来自生物医学数据库的药物、疾病和基因之间的关系。我们的方法涉及识别在s-BKG中与目标疾病关联有限但在空间上紧密相邻的药物作为潜在的药物候选物。然后，我们通过添加药物专利信息构建了一个基于专利的生物医学知识图谱（p-BKG）。

    Drug repositioning-a promising strategy for discovering new therapeutic uses for existing drugs-has been increasingly explored in the computational science literature using biomedical databases. However, the technological potential of drug repositioning candidates has often been overlooked. This study presents a novel protocol to comprehensively analyse various sources such as pharmaceutical patents and biomedical databases, and identify drug repositioning candidates with both technological potential and scientific evidence. To this end, first, we constructed a scientific biomedical knowledge graph (s-BKG) comprising relationships between drugs, diseases, and genes derived from biomedical databases. Our protocol involves identifying drugs that exhibit limited association with the target disease but are closely located in the s-BKG, as potential drug candidates. We constructed a patent-informed biomedical knowledge graph (p-BKG) by adding pharmaceutical patent information. Finally, we d
    
[^31]: 研究聊天机器人在收集家族历史信息方面与传统面对面访谈方法的有效性

    Examining the Effectiveness of Chatbots in Gathering Family History Information in Comparison to the Standard In-Person Interview-Based Approach. (arXiv:2309.03223v1 [cs.HC])

    [http://arxiv.org/abs/2309.03223](http://arxiv.org/abs/2309.03223)

    这项研究提出了一种针对家族历史收集的聊天机器人，并将其与传统面对面采访方法进行比较，探讨了聊天机器人的可行性。研究发现，聊天机器人方法能够克服地理和技术限制，并且具有较长的采访时间。

    

    一个家谱学家常常要做的事情之一就是通过面对面采访或使用诸如ancestry.com之类的平台收集一个人的家族历史，因为这可以为家谱学家打下坚实的基础。然而，进行这些采访的能力往往受到地理位置限制和被采访者的技术能力的影响，因为在这些类型的采访中，被采访者通常是一个年长且技术能力低于平均水平的人。基于这一点，本研究提出了据我们基于先前的研究相信是第一个完全面向家族历史收集的聊天机器人，并通过与上述替代方案的性能和可用性进行比较来探索利用这种聊天机器人的可行性。通过聊天机器人的方法，我们展示了尽管进行采访的平均时间可能较长，

    One of the most common things that a genealogist is tasked with is the gathering of a person's initial family history, normally via in-person interviews or with the use of a platform such as ancestry.com, as this can provide a strong foundation upon which a genealogist may build. However, the ability to conduct these interviews can often be hindered by both geographical constraints and the technical proficiency of the interviewee, as the interviewee in these types of interviews is most often an elderly person with a lower than average level of technical proficiency. With this in mind, this study presents what we believe, based on prior research, to be the first chatbot geared entirely towards the gathering of family histories, and explores the viability of utilising such a chatbot by comparing the performance and usability of such a method with the aforementioned alternatives. With a chatbot-based approach, we show that, though the average time taken to conduct an interview may be long
    
[^32]: 基于文本感知的医学知识图谱表示学习的伴侣动物疾病诊断

    Companion Animal Disease Diagnostics based on Literal-aware Medical Knowledge Graph Representation Learning. (arXiv:2309.03219v1 [cs.AI])

    [http://arxiv.org/abs/2309.03219](http://arxiv.org/abs/2309.03219)

    这项研究提出了一种基于文本感知的医学知识图谱表示学习方法，以提高伴侣动物疾病诊断的效率。通过融合各种类型的文本信息和图结构，该方法能够捕捉到重要的实体和关系。

    

    知识图谱嵌入被用于通过分析电子医疗记录（如笔记和兽医记录）来受益于动物疾病的诊断。然而，学习用于捕捉知识图谱中带有文本信息的实体和关系的表示是具有挑战性的，因为知识图谱显示出异构特性和各种类型的文本信息。同时，现有的方法大多旨在保留围绕目标节点的图结构，而无法考虑不同类型的文本，而这些文本也可能包含重要的信息。本文提出了一种用于有效诊断动物疾病的知识图谱嵌入模型，该模型可以学习各种类型的文本信息和图结构，并将它们融合为统一的表示，即LiteralKG。具体而言，我们构建了一个知识图谱，该图谱是从各个动物医院收集的电子医疗记录及文本信息构建而来。我们然后融合不同类型的实体和关系，以及文本信息。

    Knowledge graph (KG) embedding has been used to benefit the diagnosis of animal diseases by analyzing electronic medical records (EMRs), such as notes and veterinary records. However, learning representations to capture entities and relations with literal information in KGs is challenging as the KGs show heterogeneous properties and various types of literal information. Meanwhile, the existing methods mostly aim to preserve graph structures surrounding target nodes without considering different types of literals, which could also carry significant information. In this paper, we propose a knowledge graph embedding model for the efficient diagnosis of animal diseases, which could learn various types of literal information and graph structure and fuse them into unified representations, namely LiteralKG. Specifically, we construct a knowledge graph that is built from EMRs along with literal information collected from various animal hospitals. We then fuse different types of entities and no
    
[^33]: 对于临床任务的大型语言模型的对齐

    Aligning Large Language Models for Clinical Tasks. (arXiv:2309.02884v1 [cs.CL])

    [http://arxiv.org/abs/2309.02884](http://arxiv.org/abs/2309.02884)

    该论文讨论了对于临床任务的大型语言模型(LLMs)的对齐问题，提出了一种名为"expand-guess-refine"的医学问答对齐策略，并通过组合使用指令调优和in-prompt策略等技术来提高LLMs的性能。

    

    大型语言模型(LLMs)展示出了令人瞩目的适应性，展示了它们在没有明确训练的任务中表现出色的能力。然而，尽管它们具有令人印象深刻的自然语言处理(NLP)能力，但有效地对齐LLM仍然是在特定临床应用中部署它们的关键挑战。生成具有事实准确内容的响应和从事非平凡推理步骤的能力对于LLMs能否适用于临床医学应用至关重要。采用一系列技术，包括指令调优和少量示例和思路链接等in-prompt策略，显著提高了LLMs的性能。我们提出的医学问答对齐策略被称为“ expand-guess-refine”，提供了一种参数和数据高效的解决方案。对这种方法的初步分析表明，它在问题子集上取得了出色的表现，得分为70.63％。

    Large Language Models (LLMs) have demonstrated remarkable adaptability, showcasing their capacity to excel in tasks for which they were not explicitly trained. However, despite their impressive natural language processing (NLP) capabilities, effective alignment of LLMs remains a crucial challenge when deploying them for specific clinical applications. The ability to generate responses with factually accurate content and to engage in non-trivial reasoning steps are crucial for the LLMs to be eligible for applications in clinical medicine. Employing a combination of techniques including instruction-tuning and in-prompt strategies like few-shot and chain of thought prompting has significantly enhanced the performance of LLMs. Our proposed alignment strategy for medical question-answering, known as 'expand-guess-refine', offers a parameter and data-efficient solution. A preliminary analysis of this method demonstrated outstanding performance, achieving a score of 70.63% on a subset of ques
    
[^34]: HAE-RAE Bench: 评估语言模型对韩国知识的表现

    HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models. (arXiv:2309.02706v1 [cs.CL])

    [http://arxiv.org/abs/2309.02706](http://arxiv.org/abs/2309.02706)

    HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。

    

    在大规模预训练的语言模型(LLMs)在各种任务中展现出了显著的能力，但是对非英语语言的关注在这个领域的研究中有限。为了弥补这一空白并评估语言模型在韩语语言和文化方面的熟练程度，我们提出了HAE-RAE Bench，在词汇、历史和一般知识等6个任务上进行评估。我们对语言模型在这个基准上的评估突出了使用大型特定语言模型(LLSMs)与像GPT-3.5这样的全面通用模型相比的潜在优势。值得注意的是，我们的研究发现，比GPT-3.5约小13倍的模型，可以在语言特定知识检索方面展现出类似的性能水平。这一观察强调了在训练专业级语言特定模型时同质语料库的重要性。相反，当这些较小的模型在......

    Large Language Models (LLMs) pretrained on massive corpora exhibit remarkable capabilities across a wide range of tasks, however, the attention given to non-English languages has been limited in this field of research. To address this gap and assess the proficiency of language models in the Korean language and culture, we present HAE-RAE Bench, covering 6 tasks including vocabulary, history, and general knowledge. Our evaluation of language models on this benchmark highlights the potential advantages of employing Large Language-Specific Models(LLSMs) over a comprehensive, universal model like GPT-3.5. Remarkably, our study reveals that models approximately 13 times smaller than GPT-3.5 can exhibit similar performance levels in terms of language-specific knowledge retrieval. This observation underscores the importance of homogeneous corpora for training professional-level language-specific models. On the contrary, we also observe a perplexing performance dip in these smaller LMs when th
    
[^35]: 自动化机器翻译的行为测试

    Automating Behavioral Testing in Machine Translation. (arXiv:2309.02553v1 [cs.CL])

    [http://arxiv.org/abs/2309.02553](http://arxiv.org/abs/2309.02553)

    本文提出了一种利用大型语言模型自动生成源句子的方法，以测试机器翻译模型在多种情况下的行为。通过对多个机器翻译系统应用该方法，发现在测试结果与传统准确率度量存在差异的情况下，仍可观察到一致的趋势。

    

    NLP中的行为测试通过分析输入-输出行为来细粒度评估系统的语言能力。然而，目前关于机器翻译中行为测试的研究仅限于手工设计的测试范围有限、涵盖的语言种类也有限。为了解决这一限制，我们提出利用大型语言模型生成多样化的源句子，以测试机器翻译模型在不同情况下的行为。然后，我们可以使用相同的语言模型生成备选集，以验证机器翻译模型是否表现出预期的行为。我们的方法旨在使机器翻译系统的行为测试实际可行，同时只需要最少的人力投入。在实验中，我们将提出的评估框架应用于多个可用的机器翻译系统，结果显示，尽管总体上通过率与传统准确率度量可观察到的趋势相符，但仍存在差异。

    Behavioral testing in NLP allows fine-grained evaluation of systems by examining their linguistic capabilities through the analysis of input-output behavior. Unfortunately, existing work on behavioral testing in Machine Translation (MT) is currently restricted to largely handcrafted tests covering a limited range of capabilities and languages. To address this limitation, we propose to use Large Language Models (LLMs) to generate a diverse set of source sentences tailored to test the behavior of MT models in a range of situations. We can then verify whether the MT model exhibits the expected behavior through matching candidate sets that are also generated using LLMs. Our approach aims to make behavioral testing of MT systems practical while requiring only minimal human effort. In our experiments, we apply our proposed evaluation framework to assess multiple available MT systems, revealing that while in general pass-rates follow the trends observable from traditional accuracy-based metri
    
[^36]: Wordle: 生活的缩影。幸运、技巧、作弊、忠诚和影响力！

    Wordle: A Microcosm of Life. Luck, Skill, Cheating, Loyalty, and Influence!. (arXiv:2309.02110v2 [math.HO] UPDATED)

    [http://arxiv.org/abs/2309.02110](http://arxiv.org/abs/2309.02110)

    Wordle是一款流行的在线单词游戏，玩家需要在6次猜测中猜出每日目标单词。通过收集玩家的数据，研究者发现每天约有0.2-0.5%的玩家能在一次尝试中解决谜题，展示了玩家们的技巧和运气。

    

    Wordle是一款由纽约时报提供的流行在线单词游戏。目前全球有大约200万名英文版本的玩家。玩家有6次机会来猜测每日的目标单词，并在每次猜测后，根据每个字母的位置和正确性，玩家会得到彩色编码的信息。在成功完成谜题或最后一次未成功的尝试之后，软件可以使用信息论来评估玩家的运气和技巧，并且可以显示随机抽样的所有玩家的第一次、第二次...第六次猜测的数据。最近，我发现后面的数据以一种方便复制粘贴到电子表格中的格式呈现出来。我从2023年5月至2023年8月收集了Wordle玩家的第一次猜测数据，并推断出一些有趣的有关Wordle玩家的信息。A）每天约有0.2-0.5%的玩家在一次尝试中解决了谜题。由于猜对2315个位置上的单词的几率为1/2315，这一比例显示了玩家们在游戏中的技巧和运气。

    Wordle is a popular, online word game offered by the New York Times (nytimes.com). Currently there are some 2 million players of the English version worldwide. Players have 6 attempts to guess the daily word (target word) and after each attempt, the player receives color-coded information about the correctness and position of each letter in the guess. After either a successful completion of the puzzle or the final unsuccessful attempt, software can assess the player's luck and skill using Information Theory and can display data for the first, second, ..., sixth guesses of a random sample of all players. Recently, I discovered that the latter data is presented in a format that can easily be copied and pasted into a spreadsheet. I compiled data on Wordle players' first guesses from May 2023 - August 2023 and inferred some interesting information about Wordle players. A) Every day, about 0.2-0.5% of players solve the puzzle in one attempt. Because the odds of guessing the one of 2,315 pos
    
[^37]: 使用ChatGPT进行无需标注信息提取的放射报告翻译

    Zero-shot information extraction from radiological reports using ChatGPT. (arXiv:2309.01398v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01398](http://arxiv.org/abs/2309.01398)

    这项研究旨在使用ChatGPT语言模型从放射报告中无需标注数据即可提取有用信息，证明了大型语言模型在信息提取任务中的应用潜力。

    

    电子健康记录中包含大量有价值的信息，但很多记录都是自由文本。信息提取是将字符序列转换为结构化数据的策略，可以用于二次分析。然而，传统的信息提取组件，如命名实体识别和关系抽取，需要标注数据来优化模型参数，这已经成为构建信息提取系统的主要瓶颈之一。随着大型语言模型在各种下游自然语言处理任务中取得良好的性能而无需参数调优，使用大型语言模型进行零-shot信息提取也成为可能。在本研究中，我们旨在探索最流行的大型语言模型ChatGPT是否能从放射报告中提取有用信息。我们首先为CT报告中感兴趣的信息设计提示模板。然后，我们通过生成基于这些提示模板的提示语句到ChatGPT实现信息提取。

    Electronic health records contain an enormous amount of valuable information, but many are recorded in free text. Information extraction is the strategy to transform the sequence of characters into structured data, which can be employed for secondary analysis. However, the traditional information extraction components, such as named entity recognition and relation extraction, require annotated data to optimize the model parameters, which has become one of the major bottlenecks in building information extraction systems. With the large language models achieving good performances on various downstream NLP tasks without parameter tuning, it becomes possible to use large language models for zero-shot information extraction. In this study, we aim to explore whether the most popular large language model, ChatGPT, can extract useful information from the radiological reports. We first design the prompt template for the interested information in the CT reports. Then, we generate the prompts by 
    
[^38]: 基于合成临床记录的公开可共享的临床大语言模型

    Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes. (arXiv:2309.00237v1 [cs.CL])

    [http://arxiv.org/abs/2309.00237](http://arxiv.org/abs/2309.00237)

    使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。

    

    基于合成的临床案例报告，我们首先创建了大规模的合成临床记录，以解决临床记录的有限可及性和可用性的问题。然后，我们使用这些合成记录来训练我们的专门的临床大语言模型Asclepius。虽然Asclepius是在合成数据上训练的，但我们通过使用真实临床记录对其进行评估，以评估其在现实应用中的潜在性能。我们将Asclepius与包括GPT-3.5-turbo和其他开源替代方案在内的几种其他大语言模型进行了基准测试。为了进一步验证我们使用合成记录的方法，我们还将Asclepius与其在真实临床记录上训练的变体进行了比较。我们的发现有力地证明，合成临床记录在构建临床大语言模型时可以作为可行的替代品。

    The development of large language models tailored for handling patients' clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations. To address these challenges, we first create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature. We then use these synthetic notes to train our specialized clinical large language model, Asclepius. While Asclepius is trained on synthetic data, we assess its potential performance in real-world applications by evaluating it using real clinical notes. We benchmark Asclepius against several other large language models, including GPT-3.5-turbo and other open-source alternatives. To further validate our approach using synthetic notes, we also compare Asclepius with its variants trained on real clinical notes. Our findings convincingly demonstrate that synthetic clinical notes can serve as viable substitutes for real ones when constructi
    
[^39]: Transformers作为支持向量机

    Transformers as Support Vector Machines. (arXiv:2308.16898v1 [cs.LG])

    [http://arxiv.org/abs/2308.16898](http://arxiv.org/abs/2308.16898)

    这项工作建立了自注意力和硬间隔支持向量机问题之间的正式等价关系，通过转换器架构的优化几何来解决自然语言处理问题，同时揭示了梯度下降优化的转换器的隐式偏差。

    

    自从"Attention Is All You Need"中引入转换器架构以来，它在自然语言处理领域取得了革命性的进展。转换器中的注意力层接受输入令牌序列$X$并通过计算softmax$(XQK^\top X^\top)$的成对相似性使它们相互作用，其中$(K,Q)$是可训练的键-查询参数。在这项工作中，我们建立了自注意力优化几何和一个硬间隔支持向量机问题之间的正式等价关系，通过对令牌对的外积施加线性约束，将最佳输入令牌与非最佳令牌分离。这个形式主义使我们能够表征梯度下降优化的单层转换器的隐式偏差：(1)优化注意力层，使用可变正则化参数$(K,Q)$，收敛的方向是一个最小化综合参数$W=KQ^\top$的核范数的支持向量机解决方案。而直接使用$W$进行参数化则最小化一个Frobenius范数目标。

    Since its inception in "Attention Is All You Need", transformer architecture has led to revolutionary advancements in NLP. The attention layer within the transformer admits a sequence of input tokens $X$ and makes them interact through pairwise similarities computed as softmax$(XQK^\top X^\top)$, where $(K,Q)$ are the trainable key-query parameters. In this work, we establish a formal equivalence between the optimization geometry of self-attention and a hard-margin SVM problem that separates optimal input tokens from non-optimal tokens using linear constraints on the outer-products of token pairs. This formalism allows us to characterize the implicit bias of 1-layer transformers optimized with gradient descent: (1) Optimizing the attention layer with vanishing regularization, parameterized by $(K,Q)$, converges in direction to an SVM solution minimizing the nuclear norm of the combined parameter $W=KQ^\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm objective. 
    
[^40]: Ladder-of-Thought: 使用知识作为阶梯提升立场检测

    Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection. (arXiv:2308.16763v1 [cs.CL])

    [http://arxiv.org/abs/2308.16763](http://arxiv.org/abs/2308.16763)

    该论文介绍了一种名为“Ladder-of-Thought”的方法，通过引入外部知识来提升立场检测任务中的语言模型的性能，解决了小型模型在应用先前内部知识时性能提升不明显的问题，以及大规模模型在效率方面的挑战。

    

    思维链式提供（CoT）通过生成中间的推理来增强大型语言模型（LLM）的推理能力。然而，这些增强主要有益于大规模模型，在直接应用CoT时小型LLM的性能改进不明显。尽管LLM具有先进的推理能力，CoT主要依赖于其预先训练的内部知识，先前未知于模型的外部知识未被充分利用。在立场检测等任务中，外部背景知识起着关键作用，这种遗漏变得更加明显。此外，LLM的大规模架构在部署过程中不可避免地存在效率挑战。为了解决这些挑战，我们引入了用于立场检测的思维阶梯（LoT）。LoT基于双阶段级联优化框架，指导模型整合高质量的外部知识，增强中间步骤的性能。

    Chain-of-Thought Prompting (CoT) reinforces the reasoning capabilities of Large Language Models (LLMs) through the generation of intermediate rationales. However, these enhancements predominantly benefit large-scale models, leaving small LMs without significant performance improvements when directly applying CoT. Despite the advanced reasoning capabilities of LLMs, CoT relies primarily on their pre-trained internal knowledge. The external knowledge that is previously unknown to the model remains unexploited. This omission becomes pronounced in tasks such as stance detection, where the external background knowledge plays a pivotal role. Additionally, the large-scale architecture of LLMs inevitably present efficiency challenges during deployment. To address these challenges, we introduce the Ladder-of-Thought (LoT) for stance detection. Grounded in a dual-phase Cascaded Optimization framework, LoT directs the model to incorporate high-quality external knowledge, enhancing the intermediat
    
[^41]: LM-Infinite: 大规模语言模型的简单即时长度推广

    LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models. (arXiv:2308.16137v1 [cs.CL])

    [http://arxiv.org/abs/2308.16137](http://arxiv.org/abs/2308.16137)

    LM-Infinite研究了大规模语言模型在长序列上的长度推广失败问题，并提出了一种简单的即时推广方法，以更高效地利用现有模型的生成能力。

    

    近年来，在Transformer-based大规模语言模型（LLM）在各个领域取得了显著的进展。随着这些LLM在越来越复杂的任务上的部署，它们往往面临着对长时间推理过程或理解更大上下文的需求。在这些情况下，LLM在长序列上的长度推广失败变得更加突出。大多数预训练方案将训练序列截断到固定长度（例如LLaMa的2048）。即使使用了相对位置编码来应对这个问题，LLM在更长的上下文之后往往难以生成流畅的文本，更不用说进行下游任务了。常见的解决方案，如在更长的语料库上进行微调，往往需要耗费大量的硬件和时间成本，并需要进行仔细的训练过程设计。为了更高效地利用现有LLM的生成能力，我们在理论和实证上研究了主要的分布外(OOD) f

    In recent years, there have been remarkable advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains. As these LLMs are deployed for increasingly complex tasks, they often face the needs to conduct longer reasoning processes or understanding larger contexts. In these situations, the length generalization failure of LLMs on long sequences become more prominent. Most pre-training schemes truncate training sequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to generate fluent texts, let alone carry out downstream tasks, after longer contexts, even with relative positional encoding which is designed to cope with this problem. Common solutions such as finetuning on longer corpora often involves daunting hardware and time costs and requires careful training process design. To more efficiently leverage the generation capacity of existing LLMs, we theoretically and empirically investigate the main out-of-distribution (OOD) f
    
[^42]: EditSum: 一种基于检索和编辑的源代码摘要框架

    EditSum: A Retrieve-and-Edit Framework for Source Code Summarization. (arXiv:2308.13775v1 [cs.SE])

    [http://arxiv.org/abs/2308.13775](http://arxiv.org/abs/2308.13775)

    本文提出了一种基于检索和编辑的源代码摘要框架(EditSum)，用于自动生成结构化、信息丰富的代码摘要。

    

    现有研究表明，代码摘要有助于开发人员理解和维护源代码。不幸的是，软件项目中经常缺乏或过时的摘要。代码摘要旨在自动生成源代码的自然语言描述。代码摘要非常结构化，并具有重复的模式。除了模式化的单词外，代码摘要还包含重要的关键词，这些关键词是反映代码功能的关键。然而，现有技术在预测关键词方面表现较差，导致生成的摘要信息丧失了信息量。为了缓解这个问题，本文提出了一种名为EditSum的新型检索和编辑方法用于代码摘要。具体而言，EditSum首先从预定义的语料库中检索一个相似的代码片段，并将其摘要视为原型摘要以学习模式。然后，EditSum自动编辑原型摘要，以结合其中的模式。

    Existing studies show that code summaries help developers understand and maintain source code. Unfortunately, these summaries are often missing or outdated in software projects. Code summarization aims to generate natural language descriptions automatically for source code. Code summaries are highly structured and have repetitive patterns. Besides the patternized words, a code summary also contains important keywords, which are the key to reflecting the functionality of the code. However, the state-of-the-art approaches perform poorly on predicting the keywords, which leads to the generated summaries suffering a loss in informativeness. To alleviate this problem, this paper proposes a novel retrieve-and-edit approach named EditSum for code summarization. Specifically, EditSum first retrieves a similar code snippet from a pre-defined corpus and treats its summary as a prototype summary to learn the pattern. Then, EditSum edits the prototype automatically to combine the pattern in the pr
    
[^43]: ZC3: 跨语言零样本代码克隆检测

    ZC3: Zero-Shot Cross-Language Code Clone Detection. (arXiv:2308.13754v1 [cs.SE])

    [http://arxiv.org/abs/2308.13754](http://arxiv.org/abs/2308.13754)

    本文提出了一种名为ZC3的跨语言零样本代码克隆检测方法。该方法设计了对比代码片段预测，形成不同编程语言之间的同构表示空间，并利用领域感知学习和循环一致性学习来进一步约束模型。

    

    开发人员引入代码克隆以提高编程效率。许多现有研究在单语言代码克隆检测方面取得了令人瞩目的成果。然而，在软件开发过程中，越来越多的开发人员使用不同的语言编写语义上等价的程序，以支持不同的平台，并帮助开发人员从一种语言翻译项目到另一种语言。考虑到收集跨语言并行数据（尤其是低资源语言）的成本高昂且耗时，设计一种不依赖任何并行数据的有效跨语言模型是一个重要问题。本文提出了一种名为ZC3的新方法，用于零样本跨语言代码克隆检测。ZC3通过设计对比代码片段预测来形成不同编程语言之间的同构表示空间。基于此，ZC3利用领域感知学习和循环一致性学习进一步约束模型以生成表达。

    Developers introduce code clones to improve programming productivity. Many existing studies have achieved impressive performance in monolingual code clone detection. However, during software development, more and more developers write semantically equivalent programs with different languages to support different platforms and help developers translate projects from one language to another. Considering that collecting cross-language parallel data, especially for low-resource languages, is expensive and time-consuming, how designing an effective cross-language model that does not rely on any parallel data is a significant problem. In this paper, we propose a novel method named ZC3 for Zero-shot Cross-language Code Clone detection. ZC3 designs the contrastive snippet prediction to form an isomorphic representation space among different programming languages. Based on this, ZC3 exploits domain-aware learning and cycle consistency learning to further constrain the model to generate represen
    
[^44]: Halo：评估和降低开源弱大语言模型中的幻觉

    Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models. (arXiv:2308.11764v1 [cs.CL])

    [http://arxiv.org/abs/2308.11764](http://arxiv.org/abs/2308.11764)

    本文介绍了一种用于评估和减少开源弱大语言模型中幻觉问题的框架，并探索了知识注入和师生方法等技术来减轻低参数模型中的幻觉问题，实验结果表明，在挑战性领域中，这些模型的幻觉问题得到了减少。

    

    大型语言模型(LLMs)已经彻底改变了自然语言处理(NLP)领域。虽然对于研究和实际应用来说方便，但是与其更大规模的对应模型相比，开源的参数较少的LLMs经常出现严重幻觉问题。本文着重于测量和减少BLOOM 7B中的幻觉问题，该模型是公开提供给研究和商业应用的弱开源LLMs的代表。我们引入了HaloCheck，一种轻量级的无需知识的黑盒子框架，用于量化LLMs中幻觉问题的严重程度。此外，我们探索了知识注入和师生方法等技术，以减轻低参数LLMs中的幻觉问题。我们的实验证明了在这些LLMs的挑战性领域中幻觉问题的减少。

    Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP). Although convenient for research and practical applications, open-source LLMs with fewer parameters often suffer from severe hallucinations compared to their larger counterparts. This paper focuses on measuring and reducing hallucinations in BLOOM 7B, a representative of such weaker open-source LLMs that are publicly available for research and commercial applications. We introduce HaloCheck, a lightweight BlackBox knowledge-free framework designed to quantify the severity of hallucinations in LLMs. Additionally, we explore techniques like knowledge injection and teacher-student approaches to alleviate hallucinations in low-parameter LLMs. Our experiments effectively demonstrate the reduction of hallucinations in challenging domains for these LLMs.
    
[^45]: 基于大型语言模型的自主代理的调查

    A Survey on Large Language Model based Autonomous Agents. (arXiv:2308.11432v1 [cs.AI])

    [http://arxiv.org/abs/2308.11432](http://arxiv.org/abs/2308.11432)

    该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。

    

    自主代理长期以来一直是学术界的研究热点。以往的研究往往集中在对有限知识的代理进行训练，而这与人类的学习过程存在明显差异，因此很难实现人类般的决策。近年来，通过获取大量的网络知识，大型语言模型（LLM）展现出了实现人类水平智能的显著潜力。这引发了对基于LLM的自主代理的研究的高涨兴趣。为了发挥LLM的全部潜力，研究人员设计了各种不同应用的代理体系结构。本论文综述了这些研究，从整体的角度对自主代理领域进行了系统的审查。具体而言，我们的重点是基于LLM的代理构建，为此我们提出了一个统一的框架。

    Autonomous agents have long been a prominent research topic in the academic community. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from the human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating autonomous agents based on LLMs. To harness the full potential of LLMs, researchers have devised diverse agent architectures tailored to different applications. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of autonomous agents from a holistic perspective. More specifically, our focus lies in the construction of LLM-based agents, for which we propose a unified framework t
    
[^46]: 大型语言模型的持续预训练：如何（重新）热启动模型？

    Continual Pre-Training of Large Language Models: How to (re)warm your model?. (arXiv:2308.04014v1 [cs.CL])

    [http://arxiv.org/abs/2308.04014](http://arxiv.org/abs/2308.04014)

    该论文研究了大型语言模型的持续预训练问题，探讨了热启动策略对于解决分布变化和提高计算效率的影响。

    

    大型语言模型通常会对数十亿个标记进行预训练，一旦有新数据可用，就会重新开始这个过程。一种更廉价和高效的解决方案是实现这些模型的持续预训练，即用新数据更新预训练模型而不是从头开始重新训练。然而，新数据引起的分布变化通常会导致过去数据的性能下降。在本研究中，我们研究了不同的热启动策略对持续预训练的影响。我们的假设是，在训练新数据集时，需要重新增加学习率以提高计算效率。我们在Pile（上游数据，300B标记）上持续预训练模型在SlimPajama（下游数据，297B标记）上进行了线性热启动和余弦衰减的调度。我们在Pythia 410M语言模型架构上进行了所有实验。

    Large language models (LLMs) are routinely pre-trained on billions of tokens, only to restart the process over again once new data becomes available. A much cheaper and more efficient solution would be to enable the continual pre-training of these models, i.e. updating pre-trained models with new data instead of re-training them from scratch. However, the distribution shift induced by novel data typically results in degraded performance on past data. Taking a step towards efficient continual pre-training, in this work, we examine the effect of different warm-up strategies. Our hypothesis is that the learning rate must be re-increased to improve compute efficiency when training on a new dataset. We study the warmup phase of models pre-trained on the Pile (upstream data, 300B tokens) as we continue to pre-train on SlimPajama (downstream data, 297B tokens), following a linear warmup and cosine decay schedule. We conduct all experiments on the Pythia 410M language model architecture and ev
    
[^47]: 注意力机制中的边缘最大化

    Margin Maximization in Attention Mechanism. (arXiv:2306.13596v1 [cs.LG])

    [http://arxiv.org/abs/2306.13596](http://arxiv.org/abs/2306.13596)

    这篇论文证明了，在softmax-attention模型中，通过在p或等价的W上运行梯度下降，可以收敛到一个最大边缘解，这将局部最优的标记与非最优的标记分隔开。这明确地将注意力机制形式化为标记分离机制。

    

    注意力机制是Transformer架构的核心组件，也是大型语言模型取得惊人成功的原因之一。然而，注意力机制背后的理论原则尚不清楚，特别是它的非凸优化动力学。本文探讨了开创性的softmax-attention模型$f(\boldsymbol{X})=\langle \boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$，其中$\boldsymbol{X}$是标记序列，$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$是可调参数。我们证明了在$\boldsymbol{p}$或等价的$\boldsymbol{W}$上运行梯度下降会沿着方向收敛到分隔“局部最优”标记和“非最优”标记的最大边缘解。这明确地形式化了注意力作为一种标记分离机制。值得注意的是，我们的结果适用于一般数据，并使用嵌入$\boldsymbol{Xv}$和$\texttt{softmax}(\boldsymbol{XWp})$精细地表征标记的“最优性”。

    Attention mechanism is a central component of the transformer architecture which led to the phenomenal success of large language models. However, the theoretical principles underlying the attention mechanism are poorly understood, especially its nonconvex optimization dynamics. In this work, we explore the seminal softmax-attention model $f(\boldsymbol{X})=\langle \boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where, $\boldsymbol{X}$ is the token sequence and $(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are tunable parameters. We prove that running gradient descent on $\boldsymbol{p}$, or equivalently $\boldsymbol{W}$, converges in direction to a max-margin solution that separates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearly formalizes attention as a token separation mechanism. Remarkably, our results are applicable to general data and precisely characterize $\textit{optimality}$ of tokens in terms of the value embeddings $\boldsymbol{Xv}$ and
    
[^48]: ToolAlpaca: 通过3000个模拟案例对语言模型进行通用工具学习

    ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases. (arXiv:2306.05301v1 [cs.CL])

    [http://arxiv.org/abs/2306.05301](http://arxiv.org/abs/2306.05301)

    ToolAlpaca是一个自动生成工具使用语料库，实现紧凑的语言模型参加通用工具学习的框架。

    

    实现大型语言模型有效利用现实工具对于实现具有感知能力的智能至关重要。现有的工具学习方法主要依靠非常大的语言模型，例如GPT-4，在零-shot方式下获得通用的工具使用能力，或利用监督学习在紧凑的模型上训练有限类型的工具。然而，较小的语言模型是否能够在没有特定工具训练的情况下实现通用的工具使用能力尚不确定。本文介绍了ToolAlpaca，这是一个新框架，旨在自动生成工具使用语料库，并在最小人为干预下，在紧凑的语言模型上学习通用的工具使用能力。

    Enabling large language models to effectively utilize real-world tools is crucial for achieving embodied intelligence. Existing approaches to tool learning have primarily relied on either extremely large language models, such as GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or have utilized supervised learning to train limited types of tools on compact models. However, it remains uncertain whether smaller language models can achieve generalized tool-use abilities without specific tool-specific training. To address this question, this paper introduces ToolAlpaca, a novel framework designed to automatically generate a tool-use corpus and learn generalized tool-use abilities on compact language models with minimal human intervention. Specifically, ToolAlpaca first collects a comprehensive dataset by building a multi-agent simulation environment, which contains 3938 tool-use instances from more than 400 real-world tool APIs spanning 50 distinct categories. Subseque
    
[^49]: 布局和任务感知的零样本文档图像问答指导模型

    Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering. (arXiv:2306.00526v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00526](http://arxiv.org/abs/2306.00526)

    该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。

    

    基于布局感知多模态预训练模型的预训练-微调范式在文档图像问答方面取得了显著进展。然而，领域预训练和任务微调对于额外的视觉、布局和任务模块阻止了其直接利用现成的指导调优语言基础模型，而这些模型最近在零样本学习方面显示出了良好的潜力。与将语言模型与文档图像问答领域对齐相反，我们将文档图像问答与现成的指导调优语言基础模型对齐，利用其零样本能力。具体而言，我们提出了布局和任务感知的指导提示模型，称为LATIN-Prompt，它包括布局感知的文档内容和任务感知的描述。前者通过适当的空格和换行符从OCR工具中恢复文本片段之间的布局信息。后者确保模型生成符合任务需求的答案。

    The pre-training-fine-tuning paradigm based on layout-aware multimodal pre-trained models has achieved significant progress on document image question answering. However, domain pre-training and task fine-tuning for additional visual, layout, and task modules prevent them from directly utilizing off-the-shelf instruction-tuning language foundation models, which have recently shown promising potential in zero-shot learning. Contrary to aligning language models to the domain of document image question answering, we align document image question answering to off-the-shell instruction-tuning language foundation models to utilize their zero-shot capability. Specifically, we propose layout and task aware instruction prompt called LATIN-Prompt, which consists of layout-aware document content and task-aware descriptions. The former recovers the layout information among text segments from OCR tools by appropriate spaces and line breaks. The latter ensures that the model generates answers that m
    
[^50]: 大型语言模型生成混合代码文本的提示：东南亚语言的案例

    Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages. (arXiv:2303.13592v1 [cs.CL])

    [http://arxiv.org/abs/2303.13592](http://arxiv.org/abs/2303.13592)

    本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。

    

    尽管混合代码在世界许多地区是一种常见的语言实践，但收集高质量且低成本的混合代码数据仍然是自然语言处理（NLP）研究的重大挑战。最近大型语言模型（LLMs）的普及迫使人们问：这些系统能用于数据生成吗？在本文中，我们探讨了在一个零-shot的方式下如何提示LLMs为东南亚（SEA）的五种语言（印尼语，马来语，中文，塔加路语，越南语）及克里奥尔语S ingl ish创造混合代码数据。我们发现，ChatGPT显示出最大的潜力，当明确定义“混合代码”术语时，能够68%的时间生成混合代码文本。此外，ChatGPT和InstructGPT（davinci-003）生成S ingl ish文本的表现也值得注意，它们在各种提示下的成功率平均为96%。但是，ChatGPT和InstructGPT的混合代码熟练程度受到词汇选择错误的影响，导致语义不正确的输出。

    While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The proliferation of Large Language Models (LLMs) in recent times compels one to ask: can these systems be used for data generation? In this article, we explore prompting LLMs in a zero-shot manner to create code-mixed data for five languages in South East Asia (SEA) -Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the creole language Singlish. We find that ChatGPT shows the most potential, capable of producing code-mixed text 68% of the time when the term "code-mixing" is explicitly defined. Moreover, both ChatGPT and InstructGPT's (davinci-003) performances in generating Singlish texts are noteworthy, averaging a 96% success rate across a variety of prompts. The code-mixing proficiency of ChatGPT and InstructGPT, however, is dampened by word choice errors that lead to semant
    
[^51]: 计算辩论中的主张优化

    Claim Optimization in Computational Argumentation. (arXiv:2212.08913v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08913](http://arxiv.org/abs/2212.08913)

    本文提出了主张优化的任务，旨在通过重新撰写论证性主张以优化其传递。使用大型语言模型生成多样化的候选主张集合，并使用各种质量指标选择最佳候选主张。在自动和人工评估中，我们的方法表现优于多种基准线，改善了60％的主张。

    

    在任何辩论中，无论是对人类还是AI系统来说，优化论据的传递是说服的关键。这要求使用与辩论相关的清晰流畅的主张。之前的研究已经广泛研究了论据质量的自动评估，然而迄今为止没有一种方法能够实际改善质量。为了填补这一空白，本文提出了主张优化的任务：重新撰写论证性主张以优化其传递。由于存在多种优化类型，我们首先使用大型语言模型（如BART）生成一个多样化的候选主张集合，考虑到上下文信息。然后，使用各种质量指标选择最佳候选主张。在英语语料库的自动评估和人工评估中，我们基于质量的候选主张选择优于几种基准线，改善了60％的所有主张（仅恶化了16％）。后续分析表明，除了复制编辑外，我们的方法通常更加具体。

    An optimal delivery of arguments is key to persuasion in any debate, both for humans and for AI systems. This requires the use of clear and fluent claims relevant to the given debate. Prior work has studied the automatic assessment of argument quality extensively. Yet, no approach actually improves the quality so far. To fill this gap, this paper proposes the task of claim optimization: to rewrite argumentative claims in order to optimize their delivery. As multiple types of optimization are possible, we approach this task by first generating a diverse set of candidate claims using a large language model, such as BART, taking into account contextual information. Then, the best candidate is selected using various quality metrics. In automatic and human evaluation on an English-language corpus, our quality-based candidate selection outperforms several baselines, improving 60% of all claims (worsening 16% only). Follow-up analyses reveal that, beyond copy editing, our approach often speci
    
[^52]: BigText-QA：基于大规模混合知识图的问答系统

    BigText-QA: Question Answering over a Large-Scale Hybrid Knowledge Graph. (arXiv:2212.05798v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.05798](http://arxiv.org/abs/2212.05798)

    BigText-QA引入了一种综合的QA方法，能够基于有结构化和非结构化知识的知识图回答复杂问题。

    

    在文本资源上回答复杂问题仍然是一个挑战，特别是在处理自然语言句子中多个实体之间的微妙关系时。为此，像YAGO、DBpedia、Freebase和Wikidata这样的知识库（KB）在过去十年中广泛使用并得到了认可，用于问答（QA）应用。虽然这些知识库提供了结构化的知识表示，但缺乏自然语言来源中的上下文多样性。为了解决这个限制，BigText-QA引入了一种综合的QA方法，能够基于更冗余的知识图（KG）回答问题，该图将结构化和非结构化（即“混合”）知识以统一的图形表示方式组织。因此，BigText-QA能够兼顾两个世界的优势——一个经典的命名实体集合，映射到一个结构化的背景知识库（如YAGO或Wikidata），以及一个从自然语言来源中获取的上下文信息。

    Answering complex questions over textual resources remains a challenge, particularly when dealing with nuanced relationships between multiple entities expressed within natural-language sentences. To this end, curated knowledge bases (KBs) like YAGO, DBpedia, Freebase, and Wikidata have been widely used and gained great acceptance for question-answering (QA) applications in the past decade. While these KBs offer a structured knowledge representation, they lack the contextual diversity found in natural-language sources. To address this limitation, BigText-QA introduces an integrated QA approach, which is able to answer questions based on a more redundant form of a knowledge graph (KG) that organizes both structured and unstructured (i.e., "hybrid") knowledge in a unified graphical representation. Thereby, BigText-QA is able to combine the best of both worlds$\unicode{x2013}$a canonical set of named entities, mapped to a structured background KB (such as YAGO or Wikidata), as well as an o
    
[^53]: Kernelized Concept Erasure. (arXiv:2201.12191v4 [cs.LG] UPDATED)

    Kernelized Concept Erasure. (arXiv:2201.12191v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.12191](http://arxiv.org/abs/2201.12191)

    通过核化线性极小极大博弈，防止特定非线性对手预测概念，但无法彻底解决非线性编码的概念擦除问题。

    

    文本数据的神经模型的表示空间在训练过程中以无监督的方式出现。理解这些表示如何编码可解释的人类概念是一个基本问题。识别神经表示中的概念的一种明显方法是搜索一个线性子空间，其擦除会阻止从表示中预测概念。然而，尽管许多线性擦除算法是可处理和可解释的，但神经网络未必以线性方式表示概念。为了识别非线性编码的概念，我们提出了一个核化的概念擦除线性极小极大博弈。我们证明了可以防止特定的非线性对手预测概念。然而，这种保护不会转移到不同的非线性对手。因此，彻底地擦除非线性编码的概念仍然是一个待解决的问题。

    The representation space of neural models for textual data emerges in an unsupervised manner during training. Understanding how those representations encode human-interpretable concepts is a fundamental problem. One prominent approach for the identification of concepts in neural representations is searching for a linear subspace whose erasure prevents the prediction of the concept from the representations. However, while many linear erasure algorithms are tractable and interpretable, neural networks do not necessarily represent concepts in a linear manner. To identify non-linearly encoded concepts, we propose a kernelization of a linear minimax game for concept erasure. We demonstrate that it is possible to prevent specific non-linear adversaries from predicting the concept. However, the protection does not transfer to different nonlinear adversaries. Therefore, exhaustively erasing a non-linearly encoded concept remains an open problem.
    

