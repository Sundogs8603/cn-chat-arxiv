# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MRL Parsing Without Tears: The Case of Hebrew](https://arxiv.org/abs/2403.06970) | 本研究针对形态丰富的语言提出了一种新的“翻转流水线”方法，在希伯来语上取得了成功，即通过专家分类器直接在整个标记单元上做出决策，最后再综合预测结果。 |
| [^2] | [Hybrid Human-LLM Corpus Construction and LLM Evaluation for Rare Linguistic Phenomena](https://arxiv.org/abs/2403.06965) | 提出了一个新的论断结构构造方法，使用基于替换动词的测试方法评估大型语言模型对引起动作构造的理解。 |
| [^3] | [The pitfalls of next-token prediction](https://arxiv.org/abs/2403.06963) | 论文揭示了在某些任务类别中，教师强制方法可能无法在第一时间学习到准确的下一个标记预测器，进而导致模型失败的一般机制。 |
| [^4] | [SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data](https://arxiv.org/abs/2403.06952) | SELMA提出了一种新范式，通过在自动生成的多技能图像文本数据集上微调模型，并进行技能特定专家学习和合并，从而改进T2I模型的忠实度。 |
| [^5] | [Materials science in the era of large language models: a perspective](https://arxiv.org/abs/2403.06949) | 大语言模型在材料科学研究中展示出处理模糊需求、加速任务自动化和知识提取的潜力，可作为研究人员的有力工具。 |
| [^6] | [Counterfactual Reasoning with Knowledge Graph Embeddings](https://arxiv.org/abs/2403.06936) | 通过新任务CFKGR，本文将知识图补全和反事实推理联系起来，提出了一种用于适应假设前提的知识图嵌入方法COULDD，并通过基准数据集的评估表明KGEs可以学习图中的模式，检测出合理的反事实变化。 |
| [^7] | [Naming, Describing, and Quantifying Visual Objects in Humans and LLMs](https://arxiv.org/abs/2403.06935) | 评估了当前视觉与语言大语言模型在人类在可能标签的分布上显示出极大主观变异性的情况下，对视觉对象的命名、描述和量化的能力 |
| [^8] | [ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis](https://arxiv.org/abs/2403.06932) | ERA-CoT 提出了一种新颖的方法，通过捕获实体之间的关系和支持思维链，帮助大型语言模型(LLMs)理解上下文，提高了多样任务的推理准确性。 |
| [^9] | [Simplicity Bias of Transformers to Learn Low Sensitivity Functions](https://arxiv.org/abs/2403.06925) | Transformers在不同数据模态上具有低敏感性，这种简单性偏差有助于解释其在视觉和语言任务中的优越性能。 |
| [^10] | [MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning](https://arxiv.org/abs/2403.06914) | 提出了Meta dEmonstratioN Distillation (MEND)，利用知识蒸馏提高MEND和LLM之间的对齐，实现了高效和有效的上下文学习。 |
| [^11] | [Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head](https://arxiv.org/abs/2403.06892) | 本文提出了一种新颖的基于实时变压器的开词汇检测模型OmDet-Turbo，具有高效融合头模块，在实验中取得了与最先进监督模型几乎持平的性能水平。 |
| [^12] | [Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents](https://arxiv.org/abs/2403.06872) | 使用MESc框架探索大型法律文件的分类，通过大型语言模型提取文件部分的嵌入并使用聚类近似结构，进而预测判决。 |
| [^13] | [Learning with Noisy Foundation Models](https://arxiv.org/abs/2403.06869) | 本文首次全面了解和分析了预训练数据集中的噪声性质，有效减轻其对下游任务影响。 |
| [^14] | [Development of a Reliable and Accessible Caregiving Language Model (CaLM)](https://arxiv.org/abs/2403.06857) | 该研究旨在开发一种可靠的护理语言模型（CaLM），使用FM和护理知识库，通过RAG框架和FM微调提高FM答案质量，以支持家庭护理人员提供优质护理。 |
| [^15] | [RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback](https://arxiv.org/abs/2403.06840) | 通过迭代自反馈的检索增强方法在指定任务的特定场景中提高模型性能，优于现有基准模型，显著增强了事实推理能力。 |
| [^16] | [Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting](https://arxiv.org/abs/2403.06835) | 通过细粒度图像-文本对齐和解剖病理提示，提出一种新的医学图像合成模型，能够生成高度详细和准确的合成医学图像。 |
| [^17] | [Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?](https://arxiv.org/abs/2403.06833) | 本研究提出了一种形式化的度量来量化指令与数据分离现象，以及一种可以从模型黑盒输出计算的经验变量，并引入了新数据集SEP，用于评估 |
| [^18] | [The Power of Noise: Toward a Unified Multi-modal Knowledge Graph Representation Framework](https://arxiv.org/abs/2403.06832) | 提出了一种利用噪声掩模的Transformer-based架构SNAG方法，实现了多模态知识图表示中实体嵌入的最先进性能 |
| [^19] | [SPLADE-v3: New baselines for SPLADE](https://arxiv.org/abs/2403.06789) | SPLADE-v3相对于BM25和SPLADE++在效果上更为显著，同时与交叉编码器重新排序器相比较出色，具有更高的性能表现。 |
| [^20] | [Strength Lies in Differences! Towards Effective Non-collaborative Dialogues via Tailored Strategy Planning](https://arxiv.org/abs/2403.06769) | 该论文提出了一个名为TRIP的机制，通过整合用户感知的战略规划模块和基于人口的训练范式，解决了非合作对话代理商面临的挑战，有效地满足多样化用户的需求。 |
| [^21] | [ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model](https://arxiv.org/abs/2403.06765) | 本研究提出了ConspEmoLLM，这是第一个集成情感信息的大型语言模型，通过对阴谋理论文本的情感特征进行综合分析，能够执行多项任务，包括阴谋理论检测、理论类型分类和相关文本检测。 |
| [^22] | [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models](https://arxiv.org/abs/2403.06764) | FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。 |
| [^23] | [ALaRM: Align Language Models via Hierarchical Rewards Modeling](https://arxiv.org/abs/2403.06754) | ALaRM是第一个从人类反馈中建模分层奖励的框架，通过整合整体奖励与特定方面的奖励，改善了大型语言模型与人类偏好的对齐性，尤其在复杂文本生成任务中表现出更精确和一致的指导。 |
| [^24] | [ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation](https://arxiv.org/abs/2403.06745) | 该论文介绍了一种针对多语言神经机器翻译中出现的离靶问题的新型监督微调机制ACT-MNMT Auto-Constriction Turning，与传统基于提示的方法正交，并通过自动构建受限模板来解决该问题。 |
| [^25] | [Real-Time Multimodal Cognitive Assistant for Emergency Medical Services](https://arxiv.org/abs/2403.06734) | 本文提出了CognitiveEMS，一个实时多模态认知助手系统，通过引入三个新颖组件解决了实时认知辅助中的关键技术挑战，为急救服务提供关键的辅助。 |
| [^26] | [Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning](https://arxiv.org/abs/2403.06725) | 本文提出了名为LoReKT的低资源知识追踪框架，通过监督预训练和微调重要性机制，旨在从丰富资源的KT数据集中学习可转移的参数和表示来改进低资源知识追踪任务。 |
| [^27] | [Restoring Ancient Ideograph: A Multimodal Multitask Neural Network Approach](https://arxiv.org/abs/2403.06682) | 提出一种多模态多任务恢复模型（MMRM）来恢复古代文本，特别强调表意字符，结合上下文理解和残留的视觉信息来预测受损字符并生成恢复图像。 |
| [^28] | [Elephants Never Forget: Testing Language Models for Memorization of Tabular Data](https://arxiv.org/abs/2403.06644) | 本研究针对表格数据探讨了大型语言模型（LLMs）存在的数据污染和记忆化问题，发现LLMs在许多常见的表格数据集上进行了预训练，可能导致在下游任务中对性能评估的无效性。 |
| [^29] | [KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation](https://arxiv.org/abs/2403.06642) | 提出了一种知识增强的大型语言模型用于推荐的方法，通过使用外部知识来帮助生成真实可用的文本，并包括知识为基础的对比学习方案进行训练。 |
| [^30] | [MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding](https://arxiv.org/abs/2403.06611) | 通过整合外部知识增强模块和内部临床路径编码，MedKP框架在医学对话生成中取得了显著进展。 |
| [^31] | [Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds](https://arxiv.org/abs/2403.06609) | 大型语言模型在临床推理中展现出潜力，但存在幻觉问题和与医生决策路径不一致的挑战。 |
| [^32] | [Academically intelligent LLMs are not necessarily socially intelligent](https://arxiv.org/abs/2403.06591) | LLMs的社会智能仍有改进空间，存在较低的社会智能和学术智能相关性。 |
| [^33] | [ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models](https://arxiv.org/abs/2403.06586) | 将预训练的大型语言模型（LLMs）的常识知识有效地注入神经符号活动识别模型，以缓解标记数据稀缺性问题。 |
| [^34] | [AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models](https://arxiv.org/abs/2403.06574) | AC-EVAL是一个评估大型语言模型对古代汉语理解的创新基准，分为三个难度级别，涵盖历史知识、短文本和长文本理解，对LLMs的高级知识和推理能力进行评估。 |
| [^35] | [Improving Speaker Assignment in Speaker-Attributed ASR for Real Meeting Applications](https://arxiv.org/abs/2403.06570) | 该研究提出了一种优化实际会议应用中Speaker-Attributed ASR系统的方法，通过使用语音活动检测输出来微调模型以减少说话者错误率，并探讨了增强说话者嵌入模板提取的策略。 |
| [^36] | [Unraveling the Mystery of Scaling Laws: Part I](https://arxiv.org/abs/2403.06563) | 确认缩放定律原则在模型预训练中的重要作用，揭示OpenAI原始缩放定律论文的不完整细节，并探究预测测试损失轨迹可靠公式的挑战 |
| [^37] | [On the Consideration of AI Openness: Can Good Intent Be Abused?](https://arxiv.org/abs/2403.06537) | 开源技术虽然促进了科技进步，但也存在滥用风险，研究发现开源语言模型可以被调整用于提供有关犯罪活动的不道德且具有信息性的答案。 |
| [^38] | [How to Understand Named Entities: Using Common Sense for News Captioning](https://arxiv.org/abs/2403.06520) | 该论文利用常识知识来帮助新闻标题生成系统理解命名实体，从而更好地描述图像内容。 |
| [^39] | [Automatic Generation of Python Programs Using Context-Free Grammars](https://arxiv.org/abs/2403.06503) | 使用上下文无关文法自动生成Python程序的TinyPy Generator工具可以确保生成的程序的正确性，并能轻松生成大规模Python代码，尤其适用于机器学习领域。 |
| [^40] | [Multilingual Turn-taking Prediction Using Voice Activity Projection](https://arxiv.org/abs/2403.06487) | 本文研究了在口头对话中使用语音活动投影进行多语言交替预测，在多语言数据上训练的多语言模型展示出与单一语言模型相当的预测性能，并且学会了辨别输入信号的语言。 |
| [^41] | [Knowledge-aware Alert Aggregation in Large-scale Cloud Systems: a Hybrid Approach](https://arxiv.org/abs/2403.06485) | 提出了一种基于相关挖掘和大型语言模型推理的新型混合方法COLA，用于大规模云系统中的警报聚合，能够综合利用外部知识来解决基于语义相似性和统计方法的警报聚合的局限性。 |
| [^42] | [Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models](https://arxiv.org/abs/2403.06448) | 提出了一种利用大型语言模型内部状态进行实时幻觉检测的无监督训练框架，并引入了一个新的基准用于评估多个大型语言模型的幻觉检测。 |
| [^43] | [Evolving Knowledge Distillation with Large Language Models and Active Learning](https://arxiv.org/abs/2403.06414) | 本文提出了EvoKD，利用主动学习与大型语言模型交互地增强数据生成过程，同时改进小领域模型的任务能力。 |
| [^44] | [CLIcK: A Benchmark Dataset of Cultural and Linguistic Intelligence in Korean](https://arxiv.org/abs/2403.06412) | CLIcK介绍了一个包含1,995个问答对的韩国文化和语言智慧基准数据集，为填补韩语基准数据缺失的问题而来。 |
| [^45] | [A Logical Pattern Memory Pre-trained Model for Entailment Tree Generation](https://arxiv.org/abs/2403.06410) | 提出了逻辑模式记忆预训练模型（LMPM），通过结合外部存储结构学习和存储逻辑模式的潜在表示，有助于生成逻辑一致的结论，并引入实体抽象方法来减少维基百科数据中的逻辑无关领域知识的影响。 |
| [^46] | ['One size doesn't fit all': Learning how many Examples to use for In-Context Learning for Improved Text Classification](https://arxiv.org/abs/2403.06402) | 本文提出了自适应上下文学习（AICL）的工作流程，通过动态调整示例数量来提高文本分类的性能，类似于k最近邻（k-NN）中的可变大小邻域。 |
| [^47] | [GlossLM: Multilingual Pretraining for Low-Resource Interlinear Glossing](https://arxiv.org/abs/2403.06399) | 该论文提出了GlossLM模型，通过利用跨语言转移和大规模多语言预训练，实现了低资源语言文字间注释的有效生成。 |
| [^48] | [Human and Automatic Interpretation of Romanian Noun Compounds](https://arxiv.org/abs/2403.06360) | 提出了新的罗马尼亚名词复合词关系集，通过人类和神经网络分类器测试后发现，网络的预测与人类判断存在一致，即使是在人类一致率较低的情况下。需要一个更好的关系清单。 |
| [^49] | [Multi-modal Semantic Understanding with Contrastive Cross-modal Feature Alignment](https://arxiv.org/abs/2403.06355) | 提出了一种以CLIP为引导的对比学习架构，实现了多模态特征对齐，在多模态任务上表现显著优于多个基线模型，并展示了对模型性能提升的明显作用。 |
| [^50] | [Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages](https://arxiv.org/abs/2403.06354) | 本论文研究了如何训练LLaMA-2模型来学习阿姆哈拉语，使用了数据增强和连接图像编码器的方法以解决低资源语言的问题。 |
| [^51] | [IndicLLMSuite: A Blueprint for Creating Pre-training and Fine-Tuning Datasets for Indian Languages](https://arxiv.org/abs/2403.06350) | 为印度语言创建了一个覆盖22种语言、包含251B标记和74.8M指导-响应对的资源套件，结合高度筛选的数据、有价值的未验证数据和合成数据，建立了用于筛选预训练数据的干净开源流水线，以及用于指导微调的方法。 |
| [^52] | [From Instructions to Constraints: Language Model Alignment with Automatic Constraint Verification](https://arxiv.org/abs/2403.06326) | 提出了ACT框架，通过约束验证器自动计算每个响应的约束满意率，实现语言模型对齐与自动约束验证。 |
| [^53] | [LIEDER: Linguistically-Informed Evaluation for Discourse Entity Recognition](https://arxiv.org/abs/2403.06301) | 大型语言模型在语篇实体识别上具有基本的能力，但在新颖性方面仍未达到人类水平 |
| [^54] | [Transformer based Multitask Learning for Image Captioning and Object Detection](https://arxiv.org/abs/2403.06292) | 提出了一种结合图像字幕生成和物体检测的Transformer多任务学习框架，通过联合训练实现两个任务之间信息的互补共享，从而提高了图像字幕生成的性能。 |
| [^55] | [Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance](https://arxiv.org/abs/2403.06265) | 本文研究了文本压缩在分词过程中的重要性，证明了压缩与预训练语言模型后续成功之间的实证重要性，并表明分词器的压缩与模型的性能存在相关性。 |
| [^56] | [SCORE: Self-supervised Correspondence Fine-tuning for Improved Content Representations](https://arxiv.org/abs/2403.06260) | 提出了一种名为SCORE的自监督对齐微调方法，通过对齐训练策略学习类似表示，并应用于内容相关任务，显著提高了HuBERT在各种任务上的性能。 |
| [^57] | [Editing Conceptual Knowledge for Large Language Models](https://arxiv.org/abs/2403.06259) | 该论文首次研究了为大型语言模型编辑概念知识，通过构建基准数据集和建立新评估指标，发现现有方法虽然能一定程度上修改概念定义，但也可能造成LLMs中相关实例知识的扭曲，导致性能下降。 |
| [^58] | [No Language is an Island: Unifying Chinese and English in Financial Large Language Models, Instruction Data, and Benchmarks](https://arxiv.org/abs/2403.06249) | ICE-PIXIU模型将中文和英文金融分析统一，通过整合多种任务和数据集提升双语金融建模的效果。 |
| [^59] | [TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision](https://arxiv.org/abs/2403.06221) | 提出了TRAD框架，通过步骤式思维检索和对齐决策解决了利用上下文示例时可能出现的问题。 |
| [^60] | [Personalized LoRA for Human-Centered Text Understanding](https://arxiv.org/abs/2403.06208) | 提出了一种个性化LoRA（PLoRA）用于人类中心文本理解任务，在适应寒启动问题上具有优越性能。 |
| [^61] | [Identifying and interpreting non-aligned human conceptual representations using language modeling](https://arxiv.org/abs/2403.06204) | 通过引入监督的表示对齐方法，揭示了先天盲视引起了无模态和感觉相关的语义领域中的概念重组，并确定了相关的语义转变。 |
| [^62] | [Are You Being Tracked? Discover the Power of Zero-Shot Trajectory Tracing with LLMs!](https://arxiv.org/abs/2403.06201) | 介绍了LLMTrack模型，通过引入一种新颖的单提示技术，结合角色扮演和逐步思考方法，利用未经处理的IMU数据，实现了零射轨迹识别，超越了传统机器学习和深度学习模型，无需训练在专门数据集上的性能表现。 |
| [^63] | [A Comprehensive Overhaul of Multimodal Assistant with Small Language Models](https://arxiv.org/abs/2403.06199) | 通过设计多模态小语言模型(MSLMs)及提出高效多模态助手Mipha，实现了在多个方面的协同作用，击败了大语言模型，为开发强大MSLMs提供了见解和指南 |
| [^64] | [Can Large Language Models Automatically Score Proficiency of Written Essays?](https://arxiv.org/abs/2403.06149) | 本研究旨在测试大型语言模型在分析和评分书面作文方面的能力，通过对两种流行的LLMs进行实验，设计不同提示并在ASAP数据集上进行实验，揭示了有趣的观察结果。 |
| [^65] | [Fine-grainedly Synthesize Streaming Data Based On Large Language Models With Graph Structure Understanding For Data Sparsity](https://arxiv.org/abs/2403.06139) | 提出了一种细粒度合成流数据的框架，利用大型语言模型和图结构理解，将稀疏用户进行分类并生成高质量数据。 |
| [^66] | [FMPAF: How Do Fed Chairs Affect the Financial Market? A Fine-grained Monetary Policy Analysis Framework on Their Language](https://arxiv.org/abs/2403.06115) | FMPAF是一个新颖的方法，通过整合大型语言模型和回归分析，提供了对美联储主席新闻发布会沟通对金融市场影响的全面分析。 |
| [^67] | [Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning](https://arxiv.org/abs/2403.06108) | 本文研究了如何在细粒度情感检测数据集上使用大型语言模型来提高分类性能，并提出了对于文本中检测微妙情感的挑战的有价值见解。 |
| [^68] | [Automatic design optimization of preference-based subjective evaluation with online learning in crowdsourcing environment](https://arxiv.org/abs/2403.06100) | 在众包环境中，我们提出了一种自动优化方法，利用在线学习对配对组合和评估量进行优化，实现基于喜好的主观评估的设计优化。 |
| [^69] | [VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion Models](https://arxiv.org/abs/2403.06098) | VidProM是一个包含167万个独特文本到视频提示的大规模数据集，对于文本到视频扩散模型带来了新的研究进展，揭示了真实用户提示对视频生成的重要性。 |
| [^70] | [Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese Address Entity Recognition Dataset for UAV Delivery](https://arxiv.org/abs/2403.06097) | 提出了适用于无人机交付系统中地址解析任务的细粒度中文姓名实体识别数据集CNER-UAV，包含五个类别的多样化数据，经过严格的数据清洗和去敏处理，约有12,000个标注样本，评估了传统的实体识别模型并提供了深入分析 |
| [^71] | [FrameQuant: Flexible Low-Bit Quantization for Transformers](https://arxiv.org/abs/2403.06082) | 提出一种简单的方案，通过融合框架将Transformer模型量化为仅两位，仅有轻微精度下降。 |
| [^72] | [L$^2$GC: Lorentzian Linear Graph Convolutional Networks For Node Classification](https://arxiv.org/abs/2403.06064) | 本文提出了一种新颖的洛伦兹线性图卷积网络框架，将双曲空间引入线性GCN，用于捕捉数据的树状结构，并在实验中取得了新的最先进的节点分类结果。 |
| [^73] | [Target-constrained Bidirectional Planning for Generation of Target-oriented Proactive Dialogue](https://arxiv.org/abs/2403.06063) | 提出了一种面向目标导向对话生成的目标受限双向规划（TRIP）方法，通过前向和后向规划生成对话路径，促进对话向预定目标发展。 |
| [^74] | [Ensemble Language Models for Multilingual Sentiment Analysis](https://arxiv.org/abs/2403.06060) | 该研究针对低资源语言如阿拉伯语进行了情感分析，提出了两种集成语言模型，发现单语模型表现优越，集成模型胜过基线，而多数投票集成优于英语语言。 |
| [^75] | [Persian Slang Text Conversion to Formal and Deep Learning of Persian Short Texts on Social Media for Sentiment Classification](https://arxiv.org/abs/2403.06023) | 通过提供PSC工具将波斯语俚语文本转换为正式文本，结合深度学习方法进行波斯语短文本的情感学习。 |
| [^76] | [Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages](https://arxiv.org/abs/2403.06018) | 本研究评估了如何将具有70亿参数的开源PLM LLaMa 用于低资源语言的提示，解决了跨语言适应提示的问题。 |
| [^77] | [End-to-end solution for linked open data query logs analytics](https://arxiv.org/abs/2403.06016) | 通过提供一个端到端的解决方案，本研究针对链接开放数据查询日志的复杂结构和质量问题，为从中提取有价值信息提供了一种途径。 |
| [^78] | [Enhanced Auto Language Prediction with Dictionary Capsule -- A Novel Approach](https://arxiv.org/abs/2403.05982) | 该研究提出了一种使用增强型字典胶囊的自动语言预测框架，结合神经网络和符号表示，实现了多语言翻译准确性方面的重大改进，适用于多语言交流和自然语言处理任务。 |
| [^79] | [Measuring Bias in a Ranked List using Term-based Representations](https://arxiv.org/abs/2403.05975) | 本文提出了一种新的指标TExFAIR，基于术语表示群体在排名列表中的公平性，通过两个新的扩展来解决现有偏见度量方法的局限性。 |
| [^80] | [Calibrating Large Language Models Using Their Generations Only](https://arxiv.org/abs/2403.05973) | 使用APRICOT方法，通过仅使用大型语言模型的文本输入和输出来设置置信目标并训练额外模型，从而实现大型语言模型的校准。 |
| [^81] | [Thread Detection and Response Generation using Transformers with Prompt Optimisation](https://arxiv.org/abs/2403.05931) | 通过优化提示，该研究提出了一种端到端模型，能够识别对话中的线程并基于其重要性优先生成响应。 |
| [^82] | [High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models](https://arxiv.org/abs/2403.05920) | 大语言模型和混合NLP模型的结合可在高准确率下对医师笔记进行高吞吐量表型识别，有望成为未来首选方法。 |
| [^83] | [MaiBaam Annotation Guidelines](https://arxiv.org/abs/2403.05902) | 该论文提供了MaiBaam语料库的注释准则，详细介绍了如何处理和标记巴伐利亚数据，说明了词性标记和依赖关系的使用，以及对德语等相关语言适用的注释决策和对巴伐利亚语法特定决策的介绍和推动。 |
| [^84] | [KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge Graphs and Ranking Techniques](https://arxiv.org/abs/2403.05881) | 本研究开发了KG-Rank框架，利用医学知识图谱和排名技术，旨在提高医学领域自由文本问答的准确性。 |
| [^85] | [Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines](https://arxiv.org/abs/2403.05846) | 提出了一种分析文本到图像模型中文本编码器的方法，并通过生成中间表示的图像来深入研究，揭示了在复合提示和知识检索方面的一些重要发现。 |
| [^86] | [Reverse That Number! Decoding Order Matters in Arithmetic Learning](https://arxiv.org/abs/2403.05845) | 本研究提出了一种新颖的算术学习策略，重点考虑最低有效数字的输出，重新评估数字顺序，并结合逐步方法大幅减少了复杂性，从而取得了比之前方法更好的性能提升。 |
| [^87] | [An Audio-textual Diffusion Model For Converting Speech Signals Into Ultrasound Tongue Imaging Data](https://arxiv.org/abs/2403.05820) | 提出一种音频文本扩散模型，通过编码个体特征和通用模式，生成高质量超声舌头成像数据，用于语言分析和临床评估。 |
| [^88] | [MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs](https://arxiv.org/abs/2403.05814) | 提出了一种利用知识图谱的自动化对话生成框架MP2D，通过映射对话中话题的流动，有效地模拟了人类对话的动态，展示了其在生成具有自然话题转换的对话方面的有效性。 |
| [^89] | [Algorithmic progress in language models](https://arxiv.org/abs/2403.05812) | 研究发现，语言模型预训练算法每8个月几乎减半一次所需的计算需求，大大快于摩尔定律的硬件增益，尽管算法进展速度快，但计算能力的增加对整体性能改善的贡献更大。 |
| [^90] | [UniSparse: An Intermediate Language for General Sparse Format Customization](https://arxiv.org/abs/2403.05802) | UniSparse提出了一种中间语言，用于统一抽象和定制稀疏格式，提供了更灵活的方式支持新的自定义稀疏数据结构和布局变体 |
| [^91] | [ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes](https://arxiv.org/abs/2403.05795) | ClinicalMamba是基于纵向临床记录的生成型临床语言模型，具有130亿和28亿参数，相对于Mamba和临床Llama，在建模较长文本时表现出更优异的性能。 |
| [^92] | [ItD: Large Language Models Can Teach Themselves Induction through Deduction](https://arxiv.org/abs/2403.05789) | 提出了演绎通过归纳（ItD）框架，使大型语言模型能够通过演绎自学归纳，显著提升了归纳任务的性能。 |
| [^93] | [On the Benefits of Fine-Grained Loss Truncation: A Case Study on Factuality in Summarization](https://arxiv.org/abs/2403.05788) | 通过细粒度NLL损失和fi以更好地区分事实性，改进了细粒度损失截断对于摘要中事实性的影响。 |
| [^94] | [Extending Activation Steering to Broad Skills and Multiple Behaviours](https://arxiv.org/abs/2403.05767) | 本文研究了将激活导向技术应用于广泛技能和多种行为的功效，并发现导向广泛技能具有竞争力，同时在模型中同时注入个体导向向量是一种有前途的方法。 |
| [^95] | [FLAP: Flow Adhering Planning with Constrained Decoding in LLMs](https://arxiv.org/abs/2403.05766) | 本文研究了在任务导向对话中通过遵循预定义流程和保留API依赖性解决用户意图的忠实规划，提出了一种基于前瞻启发式的受限解码算法。 |
| [^96] | [Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text](https://arxiv.org/abs/2403.05750) | 大型语言模型在自然语言生成领域取得了重大突破，提出了识别AI生成文本的解决方案，并探索了未来研究方向。 |
| [^97] | [A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries](https://arxiv.org/abs/2403.05720) | 介绍了一个新的基准测试，评估了用于生成简要住院病程摘要的大语言模型在健康保健领域中的性能并提出相应的自适应策略 |
| [^98] | [DADIT: A Dataset for Demographic Classification of Italian Twitter Users and a Comparison of Prediction Methods](https://arxiv.org/abs/2403.05700) | 该研究构建了意大利推特用户人口分类数据集DADIT，用于预测社交媒体用户的性别和年龄，发现包含推文特征在年龄预测中特别有效，XLM-based分类器在性能上优于常用的M3分类器最多可提高53% F1分数。 |
| [^99] | [SeeGULL Multilingual: a Dataset of Geo-Culturally Situated Stereotypes](https://arxiv.org/abs/2403.05696) | 通过新方法，构建了全球范围的多语言社会刻板印象数据集SeeGULL Multilingual，有助于解决生成式多语言模型安全性和公平性评估中存在的英文资源限制问题。 |
| [^100] | [Decomposing Vision-based LLM Predictions for Auto-Evaluation with GPT-4](https://arxiv.org/abs/2403.05680) | 提出了一种新颖的评估框架，用于评估视觉-语言LLMs在生成CT异常的准确摘要方面的能力。 |
| [^101] | [PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System Co-design](https://arxiv.org/abs/2403.05676) | PipeRAG通过算法-系统共同设计，在生成过程中实现了快速检索增强，将检索时间大大降低并提高生成质量。 |
| [^102] | [Generating Hard-Negative Out-of-Scope Data with ChatGPT for Intent Classification](https://arxiv.org/abs/2403.05640) | 使用ChatGPT生成难负样本OOS数据，提出了新的难负样本OOS数据集，表明分类器在识别难负样本OOS数据方面存在困难，同时显示在训练中加入难负样本OOS数据可以提高模型的鲁棒性 |
| [^103] | [Tuning-Free Accountable Intervention for LLM Deployment -- A Metacognitive Approach](https://arxiv.org/abs/2403.05636) | 提出了一种创新的元认知方法，名为CLEAR，旨在为LLMs提供自我意识的错误识别和纠正能力 |
| [^104] | [Unfamiliar Finetuning Examples Control How Language Models Hallucinate](https://arxiv.org/abs/2403.05612) | 本文研究了大型语言模型如何产生幻觉，并提出通过调整微调示例的监督来控制其对不熟悉输入的预测。作者开发了一种基于RL的方法，更可靠地减轻了长篇生成任务中的幻觉。 |
| [^105] | [A Concept-based Interpretable Model for the Diagnosis of Choroid Neoplasias using Multimodal Data](https://arxiv.org/abs/2403.05606) | 提出了一种基于概念的可解释模型，用于利用多模态数据诊断脉络膜肿瘤，促进了对罕见疾病的诊断，并在临床实践和医学教育中具有重要意义 |
| [^106] | [Extracting Protein-Protein Interactions (PPIs) from Biomedical Literature using Attention-based Relational Context Information](https://arxiv.org/abs/2403.05602) | 通过利用关系上下文信息的Transformer-based深度学习方法，本研究提出了一个统一的、多源PPI语料库，改进了关系分类性能。 |
| [^107] | [HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy](https://arxiv.org/abs/2403.05574) | 这一创新心理治疗模型HealMe通过基于心理治疗框架的共情对话，有效解决了根深蒂固的负面思维，并促进了理性、平衡的观点。 |
| [^108] | [Is ChatGPT More Empathetic than Humans?](https://arxiv.org/abs/2403.05572) | ChatGPT在回应情绪场景时比人类表现出更高的移情能力，平均移情评分高于人类生成的回应10%；指示ChatGPT在回应中融入对移情的清晰理解使得其回应与高度移情的个体的期望大致接近5倍。 |
| [^109] | [Detecting a Proxy for Potential Comorbid ADHD in People Reporting Anxiety Symptoms from Social Media Data](https://arxiv.org/abs/2403.05561) | 通过分析社交媒体数据，使用Transformers技术检测出焦虑症状患者中潜在的亚临床ADHD代理，帮助阐明了焦虑和ADHD之间的关系。 |
| [^110] | [Understanding the Progression of Educational Topics via Semantic Matching](https://arxiv.org/abs/2403.05553) | 本文利用BERT主题建模从课程中提取主题，然后利用这些主题来识别不同学科之间的关系，帮助我们更好地理解各种学习话题的演进。 |
| [^111] | [Monitoring the evolution of antisemitic discourse on extremist social media using BERT](https://arxiv.org/abs/2403.05548) | 本研究提出了一种使用BERT监测极端社交媒体上反犹太主义话语演变的自动方法，避免了手动监测的不可行性，为干预和防止仇恨升级提供了新途径。 |
| [^112] | [Rule-driven News Captioning](https://arxiv.org/abs/2403.05101) | 本文提出了一种基于规则的新闻标题生成方法，通过新闻感知的语义规则，可以生成遵循新闻报道基本规则的图像描述。 |
| [^113] | [TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection](https://arxiv.org/abs/2403.04789) | 提出了一种TopicDiff方法，用于捕获多模态会话情感检测任务中的主题信息，通过将扩散模型集成到神经主题模型中，解决了神经主题模型在捕获主题信息方面的多样性不足问题，并相对于现有MCE基线取得了显著改进 |
| [^114] | [Removing GPT4's Filter](https://arxiv.org/abs/2403.04769) | 提出了一种方法，可以使经过微调的GPT4恢复到没有经过人类反馈强化学习训练的状态，从而移除其在学习期间的所有安全机制 |
| [^115] | [Chain of Thought Explanation for Dialogue State Tracking](https://arxiv.org/abs/2403.04656) | 提出了一种名为Chain-of-Thought-Explanation（CoTE）的模型，用于对话状态跟踪(DST)任务，通过逐步创建详细解释来确定插槽值，从而实现更准确可靠的结果。 |
| [^116] | [Aligners: Decoupling LLMs and Alignment](https://arxiv.org/abs/2403.04224) | 提出了一种通过训练对齐器模型来解耦大型语言模型（LLMs）和对齐，以减少对齐对性能的潜在负面影响。 |
| [^117] | [Can Large Language Models Reason and Plan?](https://arxiv.org/abs/2403.04121) | 大型语言模型缺乏自我批评能力，无法像人类一样纠正错误。 |
| [^118] | [Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People](https://arxiv.org/abs/2403.03640) | Apollo项目开发了多语言医学LLMs，创建了全球人口61亿的医学数据集，并发布了各种尺寸的最佳性能模型，其中Apollo-7B是最先进的多语言医学LLMs，可改善更大模型的多语言医学能力。 |
| [^119] | ["In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning](https://arxiv.org/abs/2403.03102) | 提出了一种In-Dialogue Learning框架，通过对话历史刻画个人设来完成个性化对话生成任务，无需预定义个人资料，并在实验证明其显著改进对话生成性能。 |
| [^120] | [Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs](https://arxiv.org/abs/2403.00858) | 通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。 |
| [^121] | [TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning](https://arxiv.org/abs/2402.19467) | TV-TREES是第一个多模态蕴涵树生成器，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树，实现了可解释联合模态推理，并在挑战性的TVQA数据集上展示了最先进的零-shot性能。 |
| [^122] | [Survey in Characterization of Semantic Change](https://arxiv.org/abs/2402.19088) | 语义变化对计算语言学算法的结果质量可能会产生影响，因此重要性日益凸显。 |
| [^123] | [MMSR: Symbolic Regression is a Multimodal Task](https://arxiv.org/abs/2402.18603) | 符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。 |
| [^124] | [LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step](https://arxiv.org/abs/2402.16906) | LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。 |
| [^125] | [A Survey on Data Selection for Language Models](https://arxiv.org/abs/2402.16827) | 大型语言模型成功的关键在于使用大规模的文本数据集进行无监督预训练，但如何优化选择数据以降低碳足迹和财务成本仍是一个挑战。 |
| [^126] | [LLM Inference Unveiled: Survey and Roofline Model Insights](https://arxiv.org/abs/2402.16363) | 本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。 |
| [^127] | [A Self-matching Training Method with Annotation Embedding Models for Ontology Subsumption Prediction](https://arxiv.org/abs/2402.16278) | 提出了一种自匹配训练方法，通过两种本体嵌入模型捕获全局和局部信息，提高了概念子类预测的稳健性 |
| [^128] | [DistALANER: Distantly Supervised Active Learning Augmented Named Entity Recognition in the Open Source Software Ecosystem](https://arxiv.org/abs/2402.16159) | 提出了一种为开源软件系统量身定制的新颖命名实体识别技术，通过远程监督注释过程、语言启发、查找表、外部知识源和主动学习方法来提高模型性能，有效缓解了成本和专家标注人员稀缺问题，并在关系抽取下游任务中显著优于LLMs。 |
| [^129] | [Emotion Classification in Short English Texts using Deep Learning Techniques](https://arxiv.org/abs/2402.16034) | 该研究使用深度学习技术在短英文文本中识别情绪，发现基于迁移学习和BERT的文本嵌入方法在分类准确性上表现优异。 |
| [^130] | [InfFeed: Influence Functions as a Feedback to Improve the Performance of Subjective Tasks](https://arxiv.org/abs/2402.14702) | InfFeed将影响函数作为反馈，用于改善主观任务表现，并通过自动识别需要交叉检查的数据点以提高模型性能，在调整标签方面优于现有基线。 |
| [^131] | [PIRB: A Comprehensive Benchmark of Polish Dense and Hybrid Text Retrieval Methods](https://arxiv.org/abs/2402.13350) | PIRB提出了一个全面的波兰文本信息检索基准，包含41个任务，评估了超过20种密集和稀疏检索模型，并引入了一个三步训练流程来构建高效的特定语言检索器，最后验证了他们的方法的优越性 |
| [^132] | [Me LLaMA: Foundation Large Language Models for Medical Applications](https://arxiv.org/abs/2402.12749) | Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。 |
| [^133] | [Comprehensive Cognitive LLM Agent for Smartphone GUI Automation](https://arxiv.org/abs/2402.11941) | 提出了全面认知LLM代理，通过全面环境感知和条件动作预测两种新方法系统性提高GUI自动化性能。 |
| [^134] | [Bridging or Breaking: Impact of Intergroup Interactions on Religious Polarization](https://arxiv.org/abs/2402.11895) | 研究探讨团体互动对宗教极端化的影响，在印度 Twitter 用户中发现，政治和社会事件的团体间互动可以减少极端化。 |
| [^135] | [Model Editing by Pure Fine-Tuning](https://arxiv.org/abs/2402.11078) | 纯微调通过优化条件似然、增加随机释义和事实的数据，在模型编辑中取得了不俗的表现。 |
| [^136] | [Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies](https://arxiv.org/abs/2402.09282) | 该论文介绍了一种利用大型语言模型和优化训练策略提高NLP任务性能的新方法，通过知识蒸馏和采用细思连想提示技术，将GPT-4中提炼的知识应用于BERT模型，在命名实体识别任务上取得了显著的性能提升，并为资源有限或封闭网络环境提供了一种成本效益的解决方案。 |
| [^137] | [Topic Modeling as Multi-Objective Contrastive Optimization](https://arxiv.org/abs/2402.07577) | 该论文介绍了一种新颖的主题建模方法，通过优化对数似然的证据下界和对比学习目标的加权线性组合，将对比主题建模作为一种多目标优化问题，旨在获得能够捕捉共享语义并克服低级别互信息干扰的主题向量集合。 |
| [^138] | [Can Large Language Model Agents Simulate Human Trust Behaviors?](https://arxiv.org/abs/2402.04559) | 大语言模型代理能够模拟人类的信任行为，表现出在信任游戏中的信任行为，并且与人类行为具有高度一致性，但存在一些偏见和对代理与人类的差异。 |
| [^139] | [Arrows of Time for Large Language Models](https://arxiv.org/abs/2401.17505) | 这篇论文通过研究自回归大型语言模型的时间方向性，发现了模型在建模自然语言能力上存在时间上的不对称性。从信息理论的角度来看，这种差异理论上是不应该存在的。通过稀疏性和计算复杂性的考虑，提供了一个理论框架来解释这种不对称性的出现。 |
| [^140] | [SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic Segmentation](https://arxiv.org/abs/2401.11791) | SemPLeS框架利用语义提示学习解决弱监督语义分割中的问题，通过学习有效提示来增强分割区域与目标对象类别之间的语义对齐。 |
| [^141] | [Alleviating Hallucinations of Large Language Models through Induced Hallucinations](https://arxiv.org/abs/2312.15710) | 通过诱导虚假信息来构建一个事实薄弱的语言模型，并在解码过程中通过对比解码来惩罚这些诱导的虚假信息，从而有效提升生成内容的真实性。 |
| [^142] | [Synergistic Anchored Contrastive Pre-training for Few-Shot Relation Extraction](https://arxiv.org/abs/2312.12021) | 新提出了一种协同对比预训练框架，利用大量的实例-标签对来丰富学习到的表示 |
| [^143] | [Constructing Vec-tionaries to Extract Message Features from Texts: A Case Study of Moral Appeals](https://arxiv.org/abs/2312.05990) | 通过构建vec-tionaries测量工具，该方法通过非线性优化将经过验证的词典与词嵌入相结合，改善了从文本中提取消息特征的测量，尤其是短格式中的那些，通过将原始词汇表的适用性扩展到其他语境。 |
| [^144] | [Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case](https://arxiv.org/abs/2311.13729) | 本文比较了用于端到端关系抽取的管道、序列到序列和GPT模型，发现管道模型仍然是最佳选择，而序列到序列模型紧随其后；参数量增加八倍的GPT模型甚至比序列到序列模型更差，且比管道模型低10个F1点以上。 |
| [^145] | [Language Generation from Brain Recordings](https://arxiv.org/abs/2311.09889) | 提出了一种在大脑记录中直接生成语言的方法，结合了大型语言模型和语义脑解码器，实现了从功能性磁共振成像输入生成与语义内容一致的连贯语言序列。 |
| [^146] | [Effective Large Language Model Adaptation for Improved Grounding and Citation Generation](https://arxiv.org/abs/2311.09533) | 本文提出了一个新的框架 AGREE，通过将大型语言模型的响应联系到检索到的段落并提供引文来提升信息关联，从而解决大型语言模型可能生成“臆想”答案的问题 |
| [^147] | [VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing](https://arxiv.org/abs/2311.08299) | 这项工作引入了 counseling response rewriting 任务，提出了基于模板的 VERVE 系统，通过加入释义的训练和自适应模板更新，将非反思性陈述转化为反思性回应。 |
| [^148] | [From Chatbots to PhishBots? -- Preventing Phishing scams created using ChatGPT, Google Bard and Claude](https://arxiv.org/abs/2310.19181) | 研究探讨了使用 ChatGPT、Google Bard 和 Claude 创建网络钓鱼攻击的潜力，发现这些大型语言模型可以生成逼真的网络钓鱼网站和电子邮件，并采用逃避检测机制的策略。 |
| [^149] | [Sentiment analysis with adaptive multi-head attention in Transformer](https://arxiv.org/abs/2310.14505) | 提出了一种基于Transformer的自适应多头注意力架构，根据句子长度变化头数，用于电影评论文档的情感分析。 |
| [^150] | [Prometheus: Inducing Fine-grained Evaluation Capability in Language Models](https://arxiv.org/abs/2310.08491) | Prometheus是一个开源的LLM，通过使用自定义评分标准和适当的参考材料，可以在与GPT-4相媲美的评估能力上进行评估。 |
| [^151] | [From Text to Self: Users' Perceptions of Potential of AI on Interpersonal Communication and Self](https://arxiv.org/abs/2310.03976) | 用户对大型语言模型驱动的工具在人际交流方面的能力持积极看法，认为可以增加沟通自信、帮助表达想法以及克服语言和文化障碍，但也揭示出工具存在的一些局限性和用户关于技术不真实性和过度依赖的担忧。 |
| [^152] | [DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation](https://arxiv.org/abs/2310.01381) | 本研究提出了一个扩散概率端到端模型，用于生成原始语音波形，实现了高保真合成和时间一致性，可实现无限语音持续时间，并支持无条件和有条件语音生成。 |
| [^153] | [Node-weighted Graph Convolutional Network for Depression Detection in Transcribed Clinical Interviews](https://arxiv.org/abs/2307.00920) | 提出了一种基于节点加权的图卷积网络方法，用于在临床面谈转录中检测抑郁症，相较于传统方法，在两个数据集上取得了更好的效果。 |
| [^154] | [TransERR: Translation-based Knowledge Graph Embedding via Efficient Relation Rotation](https://arxiv.org/abs/2306.14580) | TransERR是一种基于翻译的知识图嵌入方法，采用超复值空间编码知识图，在模型训练中通过适应性旋转头实体和尾实体来最小化翻译距离，并具有有效建模不同关系模式的能力。 |
| [^155] | [M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection](https://arxiv.org/abs/2305.14902) | 大型语言模型产生的文本可能被滥用，研究引入了名为M4的跨领域、多语言语料库，揭示了检测器在未知领域或模型上泛化的困难，指出存在改进空间。 |
| [^156] | [Cross-Model Comparative Loss for Enhancing Neuronal Utility in Language Understanding](https://arxiv.org/abs/2301.03765) | 本论文提出通过交叉模型比较损失的方法来增强语言理解模型中神经元的效用，实现减少冗余参数和抑制输入噪声的目标。 |
| [^157] | [A Discriminative Latent-Variable Model for Bilingual Lexicon Induction](https://arxiv.org/abs/1808.09334) | 引入判别式潜变量模型，结合先前研究的词典先验和表示法，提出了用于双语词典归纳的新方法，并通过实验证据展示先验可以改善诱导的双语词典。 |
| [^158] | [True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning.](http://arxiv.org/abs/2401.14151) | 本研究通过使用大型语言模型（LLMs）作为决策智能体，通过强化学习与具身环境高效互动来解决LLMs与环境之间知识不对齐的问题。通过查询LLMs的联合概率，形成行为策略，并通过两种归一化方法和四个提示设计原则提高策略的稳定性和鲁棒性。最后，通过设计参数高效的训练架构提高学习效率。 |
| [^159] | [Top in Chinese Data Processing: English Code Models.](http://arxiv.org/abs/2401.10286) | 在中文数据处理中，基于代码的语言模型在非编程中文任务中表现出色，尤其是在对中文幻觉敏感的任务中。此研究为讨论“中文房间”思想实验提供了独特的视角。 |
| [^160] | [InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks.](http://arxiv.org/abs/2401.05507) | InfiAgent-DABench是第一个评估基于LLM的代理在数据分析任务中的基准测试，包括DAEval数据集和代理框架。对23个最先进的LLMs进行的基准测试揭示了当前数据分析任务中的挑战。 |
| [^161] | [Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents.](http://arxiv.org/abs/2311.00262) | 基于大型语言模型的对话代理的即插即用策略规划器(PDDPP)引入了一种新的对话策略规划范式，通过可调整的语言模型插件实现主动对话问题的策略制定。利用监督微调和强化学习，该框架在处理新的案例时具有较高的灵活性和性能。 |
| [^162] | [Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs.](http://arxiv.org/abs/2310.18152) | 本文提出了一个名为Disentangled Graph-Text Learner (DGTL)的模型，通过引入定制的解缠图神经网络（GNN）层，使得大型语言模型（LLMs）能够更好地理解文本属性图（TAGs）中的复杂结构关系。 |
| [^163] | [Detecting Pretraining Data from Large Language Models.](http://arxiv.org/abs/2310.16789) | 这项研究探讨了如何检测大型语言模型的预训练数据，提出了一个动态基准和一种新的检测方法，以解决数据隐私和不透明性的问题。 |
| [^164] | [Cultural and Linguistic Diversity Improves Visual Representations.](http://arxiv.org/abs/2310.14356) | 这项研究发现数据集和模型生成的图像描述在不同语言间存在显著的语义差异，多语言数据有更高的语义覆盖率，并且基于多语言训练的模型表现更好。 |
| [^165] | [In-Context Pretraining: Language Modeling Beyond Document Boundaries.](http://arxiv.org/abs/2310.10638) | 本论文提出了一种超越文档边界的上下文预训练方法，通过在相关文档序列上训练语言模型，鼓励模型进行跨文档的阅读和推理。该方法通过改变文档顺序并应用现有的预训练管道来实现。 |
| [^166] | [Exploring the Landscape of Large Language Models In Medical Question Answering: Observations and Open Questions.](http://arxiv.org/abs/2310.07225) | 通过评估多种流行的大型语言模型在医学问题方面的知识，本研究提供了对这些模型作为一个群体的初步观察，并提出了进一步研究的开放问题。 |
| [^167] | [Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance.](http://arxiv.org/abs/2310.02107) | 为了提高大型语言模型的零样本性能，本文提出了一种新的方法，通过为每个个别的测试输入重新写作任务提示，使其更具体、明确和完整，从而提供更好的指导，实现了约10%的改进。 |
| [^168] | [LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset.](http://arxiv.org/abs/2309.11998) | LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。 |
| [^169] | [Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models.](http://arxiv.org/abs/2309.10444) | 本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。 |
| [^170] | [Reformulating Sequential Recommendation: Learning Dynamic User Interest with Content-enriched Language Modeling.](http://arxiv.org/abs/2309.10435) | 本研究提出了一个新的顺序推荐范式 LANCER，利用预训练语言模型的语义理解能力生成更加人性化的个性化推荐。在多个基准数据集上的实验结果表明，该方法有效且有希望，并为了解顺序推荐的影响提供了有价值的见解。 |
| [^171] | [Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms.](http://arxiv.org/abs/2309.05961) | 本文通过对六个社区问答平台的研究，发现了查询的元数据、问题构成方式和用户互动水平与第一个回答时间之间的关联，并利用机器学习模型预测查询是否能够迅速获得回答。 |
| [^172] | [DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models.](http://arxiv.org/abs/2309.03883) | DoLa通过对比不同层次的逻辑差异，提高大型语言模型中的真实性和减少幻觉，无需外部知识或微调。 |
| [^173] | [CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models.](http://arxiv.org/abs/2309.01940) | CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。 |
| [^174] | [MatchXML: An Efficient Text-label Matching Framework for Extreme Multi-label Text Classification.](http://arxiv.org/abs/2308.13139) | MatchXML是一种高效的文本-标签匹配框架，用于极端多标签文本分类。它通过label2vec方法生成语义密集的标签嵌入，并利用这些嵌入构建层次化标签树。通过微调预训练的Transformer模型，MatchXML将多标签文本分类问题转化为文本-标签匹配问题，并提取出密集的文本表示和静态的句子嵌入。 |
| [^175] | [Improving Audio-Visual Speech Recognition by Lip-Subword Correlation Based Visual Pre-training and Cross-Modal Fusion Encoder.](http://arxiv.org/abs/2308.08488) | 本文提出了通过基于嘴唇-音素字级相关性的视觉预训练和跨模态融合编码器来改进视听语音识别的两种新技术。这些技术可以在预训练和微调阶段准确对齐音频和视频流，并且充分利用模态互补性。 |
| [^176] | [Overthinking the Truth: Understanding how Language Models Process False Demonstrations.](http://arxiv.org/abs/2307.09476) | 该论文研究了现代语言模型在处理虚假演示时出现的过度思考和错误归纳头现象。通过研究模型的内部表示，发现模型在中间层之后对错误演示的处理准确性逐渐降低，并指出了错误归纳头机制可能导致过度思考现象。 |
| [^177] | [Analyzing Dataset Annotation Quality Management in the Wild.](http://arxiv.org/abs/2307.08153) | 该论文调查分析了自然语言数据集的创建过程中的质量管理实践，并提供了相应的建议。研究表明，流行数据集中存在较多的错误注释、偏见或注释伪像。这项研究的贡献是在这一领域进行了大规模的实证分析，并提出了实践指南。 |
| [^178] | [DeepOnto: A Python Package for Ontology Engineering with Deep Learning.](http://arxiv.org/abs/2307.03067) | DeepOnto是一个Python包，用于深度学习本体工程。它通过集成深度学习框架和本体API，提供了丰富的工具和算法，支持本体工程任务，如本体对齐和完成。 |
| [^179] | [Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection.](http://arxiv.org/abs/2307.00209) | 本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。 |
| [^180] | [Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation.](http://arxiv.org/abs/2306.05783) | Xiezhi是一种全面综合的评估套件，设有516个多项选择问题，覆盖了从13个不同学科跨越的15个专业领域，并对47个先进的LLMs进行评估，结果表明LLMs在大多数领域超越人类，但在一些领域表现不佳。 |
| [^181] | [Large Language Models as Tool Makers.](http://arxiv.org/abs/2305.17126) | 本文提出了一个闭环框架，即LLMs作为工具制造者（LATM），使LLMs能够自主地创建用于解决问题的工具，而不需要依赖于现有的外部工具。 |
| [^182] | [Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study.](http://arxiv.org/abs/2305.13860) | 本研究探索了通过提示工程破解ChatGPT的有效性，发现破解提示可以在40种用例情况下一致地规避限制，强调了提示结构在破解ChatGPT中的重要性。 |
| [^183] | [Neural Comprehension: Language Models with Compiled Neural Networks.](http://arxiv.org/abs/2304.01665) | 本文探讨了如何将编译神经网络CoNNs并入语言模型的架构中，以使语言模型在复合任务中提高性能，特别是在需要深入理解抽象规则的领域。方法称为“神经理解”，提高了语言模型在符号操作、规则推理、算术推理等方面的准确度。 |
| [^184] | [Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction.](http://arxiv.org/abs/2301.09209) | 本文提出了一种TransFusion架构，利用先前训练的图像字幕和视觉语言模型总结动作上下文，实现对多模态对象交互的预测，有效性得到验证。 |
| [^185] | [CAPE: Corrective Actions from Precondition Errors using Large Language Models.](http://arxiv.org/abs/2211.09935) | CAPE是一种利用大型语言模型从前置错误中纠正行动的方法，提高了生成计划的质量，使具身代理能够执行更多任务，并改善了计划的正确性。 |

# 详细

[^1]: 无泪MRL分析：希伯来语案例

    MRL Parsing Without Tears: The Case of Hebrew

    [https://arxiv.org/abs/2403.06970](https://arxiv.org/abs/2403.06970)

    本研究针对形态丰富的语言提出了一种新的“翻转流水线”方法，在希伯来语上取得了成功，即通过专家分类器直接在整个标记单元上做出决策，最后再综合预测结果。

    

    语法分析仍然是关系提取和信息提取的关键工具，特别是在资源匮乏的语言中，缺乏LLMs的情况下。然而，在形态丰富的语言(MRLs)中，解析器需要识别每个标记中的多个词素单元，现有系统在延迟和设置复杂性方面存在问题。一些系统使用流水线逐层处理：首先进行分词，然后进行形态标记，最后进行语法分析；然而，之前层次的错误会向前传播。另一些系统使用联合架构同时评估所有排列组合；虽然这提高了准确性，但速度极其缓慢。相反，以希伯来语作为测试案例，我们提出了一种新的“翻转流水线”：专家分类器直接在整个标记单元上做出决策，每个分类器专门负责一个特定任务。这些分类器彼此独立，只有在最后我们才综合它们的预测。

    arXiv:2403.06970v1 Announce Type: new  Abstract: Syntactic parsing remains a critical tool for relation extraction and information extraction, especially in resource-scarce languages where LLMs are lacking. Yet in morphologically rich languages (MRLs), where parsers need to identify multiple lexical units in each token, existing systems suffer in latency and setup complexity. Some use a pipeline to peel away the layers: first segmentation, then morphology tagging, and then syntax parsing; however, errors in earlier layers are then propagated forward. Others use a joint architecture to evaluate all permutations at once; while this improves accuracy, it is notoriously slow. In contrast, and taking Hebrew as a test case, we present a new "flipped pipeline": decisions are made directly on the whole-token units by expert classifiers, each one dedicated to one specific task. The classifiers are independent of one another, and only at the end do we synthesize their predictions. This blazingly
    
[^2]: 混合式人类-LLM语料库构建与罕见语言现象LLM评估

    Hybrid Human-LLM Corpus Construction and LLM Evaluation for Rare Linguistic Phenomena

    [https://arxiv.org/abs/2403.06965](https://arxiv.org/abs/2403.06965)

    提出了一个新的论断结构构造方法，使用基于替换动词的测试方法评估大型语言模型对引起动作构造的理解。

    

    论文提出了一个新的论断结构构造方法，为了展示构式语法的实用性，本文研究了论断结构构造（ASCs）这一组构造中的引起动作构造（CMC，“她打喷嚏把卡布奇诺上的泡沫吹走”）。我们假设即使对于最先进的大型语言模型（LLM），这仍然是具有挑战性的，为此我们设计了一个基于用典型动作动词替换动词进行测试的方法。为了能够在统计意义上进行此测试，在没有足够的构式语法语料库的情况下，我们开发了一个新的NLP辅助的语言学注释文本收集流水线。我们展示了依存解析和GPT-3.5如何可用于显著降低注释成本，从而实现对罕见语言现象进行注释。

    arXiv:2403.06965v1 Announce Type: new  Abstract: Argument Structure Constructions (ASCs) are one of the most well-studied construction groups, providing a unique opportunity to demonstrate the usefulness of Construction Grammar (CxG). For example, the caused-motion construction (CMC, ``She sneezed the foam off her cappuccino'') demonstrates that constructions must carry meaning, otherwise the fact that ``sneeze'' in this context causes movement cannot be explained. We form the hypothesis that this remains challenging even for state-of-the-art Large Language Models (LLMs), for which we devise a test based on substituting the verb with a prototypical motion verb. To be able to perform this test at statistically significant scale, in the absence of adequate CxG corpora, we develop a novel pipeline of NLP-assisted collection of linguistically annotated text. We show how dependency parsing and GPT-3.5 can be used to significantly reduce annotation cost and thus enable the annotation of rare
    
[^3]: 下一个标记预测的陷阱

    The pitfalls of next-token prediction

    [https://arxiv.org/abs/2403.06963](https://arxiv.org/abs/2403.06963)

    论文揭示了在某些任务类别中，教师强制方法可能无法在第一时间学习到准确的下一个标记预测器，进而导致模型失败的一般机制。

    

    一篇关于下一个标记预测的论文。我们提出了一个直观的担忧：一个仅仅基于下一个标记预测的模型是否能忠实地模拟人类智能。我们认为下一个标记预测中经常混淆的两个阶段 -- 自回归推断和教师强制训练 -- 必须被区别对待。我们描述了一个一般机制，展示了教师强制如何失败，并设计了一个最小化计划任务，在这个任务中Transformer和Mamba架构在实践中以这种方式失败 -- 尽管任务本身很容易学习。

    arXiv:2403.06963v1 Announce Type: cross  Abstract: Can a mere next-token predictor faithfully model human intelligence? We crystallize this intuitive concern, which is fragmented in the literature. As a starting point, we argue that the two often-conflated phases of next-token prediction -- autoregressive inference and teacher-forced training -- must be treated distinctly. The popular criticism that errors can compound during autoregressive inference, crucially assumes that teacher-forcing has learned an accurate next-token predictor. This assumption sidesteps a more deep-rooted problem we expose: in certain classes of tasks, teacher-forcing can simply fail to learn an accurate next-token predictor in the first place. We describe a general mechanism of how teacher-forcing can fail, and design a minimal planning task where both the Transformer and the Mamba architecture empirically fail in that manner -- remarkably, despite the task being straightforward to learn. We provide preliminary
    
[^4]: SELMA：学习和合并具有自动生成数据的技能特定文本到图像专家

    SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data

    [https://arxiv.org/abs/2403.06952](https://arxiv.org/abs/2403.06952)

    SELMA提出了一种新范式，通过在自动生成的多技能图像文本数据集上微调模型，并进行技能特定专家学习和合并，从而改进T2I模型的忠实度。

    

    最近，文本到图像（T2I）生成模型展示了从文本描述中创建图像的令人印象深刻的能力。然而，这些T2I生成模型在生成精确匹配文本输入细节的图像方面经常表现不佳，比如不正确的空间关系或缺失对象。在本文中，我们介绍了SELMA：具有自动生成数据的技能特定专家学习和合并，这是一种改进T2I模型忠实度的新范式，通过在自动生成的多技能图像文本数据集上微调模型，并进行技能特定专家学习和合并。首先，SELMA利用LLM的环境学习能力生成多个文本提示数据集，可以教授不同的技能，然后基于提示使用T2I模型生成图像。接下来，SELMA通过学习多个单技能的LoRA（低秩调整）专家调整T2I模型到新技能。

    arXiv:2403.06952v1 Announce Type: cross  Abstract: Recent text-to-image (T2I) generation models have demonstrated impressive capabilities in creating images from text descriptions. However, these T2I generation models often fall short of generating images that precisely match the details of the text inputs, such as incorrect spatial relationship or missing objects. In this paper, we introduce SELMA: Skill-Specific Expert Learning and Merging with Auto-Generated Data, a novel paradigm to improve the faithfulness of T2I models by fine-tuning models on automatically generated, multi-skill image-text datasets, with skill-specific expert learning and merging. First, SELMA leverages an LLM's in-context learning capability to generate multiple datasets of text prompts that can teach different skills, and then generates the images with a T2I model based on the prompts. Next, SELMA adapts the T2I model to the new skills by learning multiple single-skill LoRA (low-rank adaptation) experts follow
    
[^5]: 大语言模型时代的材料科学：一个展望

    Materials science in the era of large language models: a perspective

    [https://arxiv.org/abs/2403.06949](https://arxiv.org/abs/2403.06949)

    大语言模型在材料科学研究中展示出处理模糊需求、加速任务自动化和知识提取的潜力，可作为研究人员的有力工具。

    

    大型语言模型（LLMs）由于其令人印象深刻的自然语言能力而引起了广泛关注，结合各种新兴特性，使它们成为从复杂代码生成到启发式找解组合问题等工作流程中的多功能工具。 在本文中，我们提供了关于它们在材料科学研究中的适用性的观点，认为它们能够处理跨多项任务和学科的模糊需求意味着它们可能成为帮助研究人员的强大工具。 我们定性地研究了基本的LLM理论，将其与文献中的相关特性和技术联系起来，然后提供了两个案例研究，展示了它们在规模化任务自动化和知识提取中的应用。 在它们当前的发展阶段，我们认为LLMs应该被看作不是新颖洞察力的预言者，而是能够加速和统一探索的不知疲倦的工作者。

    arXiv:2403.06949v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have garnered considerable interest due to their impressive natural language capabilities, which in conjunction with various emergent properties make them versatile tools in workflows ranging from complex code generation to heuristic finding for combinatorial problems. In this paper we offer a perspective on their applicability to materials science research, arguing their ability to handle ambiguous requirements across a range of tasks and disciplines mean they could be a powerful tool to aid researchers. We qualitatively examine basic LLM theory, connecting it to relevant properties and techniques in the literature before providing two case studies that demonstrate their use in task automation and knowledge extraction at-scale. At their current stage of development, we argue LLMs should be viewed less as oracles of novel insight, and more as tireless workers that can accelerate and unify exploration across
    
[^6]: 使用知识图嵌入进行反事实推理

    Counterfactual Reasoning with Knowledge Graph Embeddings

    [https://arxiv.org/abs/2403.06936](https://arxiv.org/abs/2403.06936)

    通过新任务CFKGR，本文将知识图补全和反事实推理联系起来，提出了一种用于适应假设前提的知识图嵌入方法COULDD，并通过基准数据集的评估表明KGEs可以学习图中的模式，检测出合理的反事实变化。

    

    知识图嵌入（KGEs）最初是为了推断不完整知识库中缺失的真实事实而开发的。本文通过我们的新任务CFKGR将知识图补全和反事实推理联系起来。我们将原始世界状态建模为知识图，假设情景为添加到图中的边，对图的合理变化为逻辑规则推理的结果。我们创建了相应的基准数据集，其中包含各种假设情景及对原始知识图的合理改变以及应该保留的事实。我们开发了COULDD，一种针对特定假设前提调整现有知识图嵌入的通用方法，并在我们的基准上进行评估。我们的结果表明，KGEs可以在没有显式训练的情况下从图中学习模式。我们进一步观察到，通过COULDD调整后的KGEs可以可靠地检测出遵循逻辑规则的图的合理反事实变化。

    arXiv:2403.06936v1 Announce Type: cross  Abstract: Knowledge graph embeddings (KGEs) were originally developed to infer true but missing facts in incomplete knowledge repositories. In this paper, we link knowledge graph completion and counterfactual reasoning via our new task CFKGR. We model the original world state as a knowledge graph, hypothetical scenarios as edges added to the graph, and plausible changes to the graph as inferences from logical rules. We create corresponding benchmark datasets, which contain diverse hypothetical scenarios with plausible changes to the original knowledge graph and facts that should be retained. We develop COULDD, a general method for adapting existing knowledge graph embeddings given a hypothetical premise, and evaluate it on our benchmark. Our results indicate that KGEs learn patterns in the graph without explicit training. We further observe that KGEs adapted with COULDD solidly detect plausible counterfactual changes to the graph that follow the
    
[^7]: 人类和语言大型语言模型中的视觉对象命名、描述和量化

    Naming, Describing, and Quantifying Visual Objects in Humans and LLMs

    [https://arxiv.org/abs/2403.06935](https://arxiv.org/abs/2403.06935)

    评估了当前视觉与语言大语言模型在人类在可能标签的分布上显示出极大主观变异性的情况下，对视觉对象的命名、描述和量化的能力

    

    人类讲话者在描述图像中的同一对象时使用各种不同的表达方式，这产生了由语用约束驱动的合理标签分布，当前视觉与语言大语言模型（VLLMs）能够模仿语言使用中这一关键特征的程度尚不明确。我们评估了VLLMs（FROMAGe、BLIP-2、LLaVA）在人类在可能标签的分布上显示出极大主观变异性的三个类别（名词、属性和量词）上的性能。

    arXiv:2403.06935v1 Announce Type: new  Abstract: While human speakers use a variety of different expressions when describing the same object in an image, giving rise to a distribution of plausible labels driven by pragmatic constraints, the extent to which current Vision \& Language Large Language Models (VLLMs) can mimic this crucial feature of language use is an open question. This applies to common, everyday objects, but it is particularly interesting for uncommon or novel objects for which a category label may be lacking or fuzzy. Furthermore, humans show clear production preferences for highly context-sensitive expressions, such as the quantifiers `few' or `most'. In our work, we evaluate VLLMs (FROMAGe, BLIP-2, LLaVA) on three categories (nouns, attributes, and quantifiers) where humans show great subjective variability concerning the distribution over plausible labels, using datasets and resources mostly under-explored in previous work. Our results reveal mixed evidence on the a
    
[^8]: ERA-CoT: 通过实体关系分析改进思维链

    ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis

    [https://arxiv.org/abs/2403.06932](https://arxiv.org/abs/2403.06932)

    ERA-CoT 提出了一种新颖的方法，通过捕获实体之间的关系和支持思维链，帮助大型语言模型(LLMs)理解上下文，提高了多样任务的推理准确性。

    

    大型语言模型在各种自然语言处理任务中取得了可观的成就。然而，当处理涉及多个实体的复杂场景时，LLMs 仍然面临重大挑战。这些挑战源于存在需要多步推理的隐式关系。在本文中，我们提出了一种新颖的方法 ERA-CoT，通过捕获实体之间的关系来帮助 LLMs 理解上下文，并通过思维链（CoT）支持不同任务的推理。实验结果表明，与当前的 CoT 提示方法相比，ERA-CoT 表现出我们提出的方法在 GPT3.5 上平均比以前的 SOTA 基线实现了显著的 5.1% 改进的卓越性能。我们的分析表明，ERA-CoT 提高了LLM对实体关系的理解，显著提高了问题回答的准确性。

    arXiv:2403.06932v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved commendable accomplishments in various natural language processing tasks. However, LLMs still encounter significant challenges when dealing with complex scenarios involving multiple entities. These challenges arise from the presence of implicit relationships that demand multi-step reasoning. In this paper, we propose a novel approach ERA-CoT, which aids LLMs in understanding context by capturing relationships between entities and supports the reasoning of diverse tasks through Chain-of-Thoughts (CoT). Experimental results show that ERA-CoT demonstrates the superior performance of our proposed method compared to current CoT prompting methods, achieving a significant improvement of an average of 5.1\% on GPT3.5 compared to previous SOTA baselines. Our analysis indicates that ERA-CoT increases the LLM's understanding of entity relationships, significantly improves the accuracy of question answering
    
[^9]: Transformers学习低敏感性函数的简单性偏差

    Simplicity Bias of Transformers to Learn Low Sensitivity Functions

    [https://arxiv.org/abs/2403.06925](https://arxiv.org/abs/2403.06925)

    Transformers在不同数据模态上具有低敏感性，这种简单性偏差有助于解释其在视觉和语言任务中的优越性能。

    

    Transformers在许多任务中取得了最先进的准确性和鲁棒性，但对它们具有的归纳偏差以及这些偏差如何与其他神经网络架构不同的理解仍然难以捉摸。本文中，我们将模型对输入中的随机更改的敏感性概念化为一种简单性偏差的概念，这为解释transformers在不同数据模态上的简单性和谱偏差提供了统一的度量标准。我们展示了transformers在视觉和语言任务中比其他替代架构（如LSTMs、MLPs和CNNs）具有更低的敏感性。我们还展示了低敏感性偏差与改进性能的相关性。

    arXiv:2403.06925v1 Announce Type: cross  Abstract: Transformers achieve state-of-the-art accuracy and robustness across many tasks, but an understanding of the inductive biases that they have and how those biases are different from other neural network architectures remains elusive. Various neural network architectures such as fully connected networks have been found to have a simplicity bias towards simple functions of the data; one version of this simplicity bias is a spectral bias to learn simple functions in the Fourier space. In this work, we identify the notion of sensitivity of the model to random changes in the input as a notion of simplicity bias which provides a unified metric to explain the simplicity and spectral bias of transformers across different data modalities. We show that transformers have lower sensitivity than alternative architectures, such as LSTMs, MLPs and CNNs, across both vision and language tasks. We also show that low-sensitivity bias correlates with impro
    
[^10]: MEND：元演示蒸馏用于有效和高效的上下文学习

    MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning

    [https://arxiv.org/abs/2403.06914](https://arxiv.org/abs/2403.06914)

    提出了Meta dEmonstratioN Distillation (MEND)，利用知识蒸馏提高MEND和LLM之间的对齐，实现了高效和有效的上下文学习。

    

    大型语言模型(LLMs)展示了令人印象深刻的上下文学习(ICL)能力，其中LLM为给定的测试输入和少量输入-输出对(演示)进行预测。然而，演示的加入导致自注意机制的计算开销呈二次增加。现有解决方案尝试将冗长的演示蒸馏成紧凑的向量。然而，它们通常需要特定于任务的重新训练或牺牲LLM的上下文学习性能。为了缓解这些挑战，我们提出了Meta dEmonstratioN Distillation (MEND)，其中语言模型学会将任何冗长演示蒸馏为向量，而无需为新的下游任务重新训练。我们利用知识蒸馏增强MEND和LLM之间的对齐，同时实现效率和有效性。MEND具有蒸馏演示的元知识

    arXiv:2403.06914v1 Announce Type: cross  Abstract: Large Language models (LLMs) have demonstrated impressive in-context learning (ICL) capabilities, where a LLM makes predictions for a given test input together with a few input-output pairs (demonstrations). Nevertheless, the inclusion of demonstrations leads to a quadratic increase in the computational overhead of the self-attention mechanism. Existing solutions attempt to distill lengthy demonstrations into compact vectors. However, they often require task-specific retraining or compromise LLM's in-context learning performance. To mitigate these challenges, we present Meta dEmonstratioN Distillation (MEND), where a language model learns to distill any lengthy demonstrations into vectors without retraining for a new downstream task. We exploit the knowledge distillation to enhance alignment between MEND and LLM, achieving both efficiency and effectiveness simultaneously. MEND is endowed with the meta-knowledge of distilling demonstrat
    
[^11]: 基于实时变压器的高效融合头开词汇检测

    Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head

    [https://arxiv.org/abs/2403.06892](https://arxiv.org/abs/2403.06892)

    本文提出了一种新颖的基于实时变压器的开词汇检测模型OmDet-Turbo，具有高效融合头模块，在实验中取得了与最先进监督模型几乎持平的性能水平。

    

    基于端到端变压器的检测器（DETRs）通过整合语言模态，在封闭集和开词汇目标检测（OVD）任务中表现出色，但其高要求的计算需求阻碍了它们在实时目标检测（OD）场景中的实际应用。本文审查了OVDEval基准测试中两个领先模型OmDet和Grounding-DINO的限制，并引入了OmDet-Turbo。这种新颖的基于变压器的实时OVD模型具有创新的高效融合头（EFH）模块，旨在缓解OmDet和Grounding-DINO中观察到的瓶颈。值得注意的是，OmDet-Turbo-Base在应用TensorRT和语言缓存技术后实现了100.2帧每秒（FPS）。值得注意的是，在COCO和LVIS数据集的零样本场景中，OmDet-Turbo的性能几乎与当前最先进的监督模型持平。

    arXiv:2403.06892v1 Announce Type: cross  Abstract: End-to-end transformer-based detectors (DETRs) have shown exceptional performance in both closed-set and open-vocabulary object detection (OVD) tasks through the integration of language modalities. However, their demanding computational requirements have hindered their practical application in real-time object detection (OD) scenarios. In this paper, we scrutinize the limitations of two leading models in the OVDEval benchmark, OmDet and Grounding-DINO, and introduce OmDet-Turbo. This novel transformer-based real-time OVD model features an innovative Efficient Fusion Head (EFH) module designed to alleviate the bottlenecks observed in OmDet and Grounding-DINO. Notably, OmDet-Turbo-Base achieves a 100.2 frames per second (FPS) with TensorRT and language cache techniques applied. Notably, in zero-shot scenarios on COCO and LVIS datasets, OmDet-Turbo achieves performance levels nearly on par with current state-of-the-art supervised models. 
    
[^12]: 探索大型语言模型和分层框架用于大型非结构化法律文件的分类

    Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents

    [https://arxiv.org/abs/2403.06872](https://arxiv.org/abs/2403.06872)

    使用MESc框架探索大型法律文件的分类，通过大型语言模型提取文件部分的嵌入并使用聚类近似结构，进而预测判决。

    

    法律判决预测受长达数万字的案例文件和非均匀结构的问题困扰，尤其是对于没有结构标注的文件。本研究通过一个基于深度学习的分层框架(MESc)，即“基于多阶段编码器的带聚类的监督学习”，来探索这些大型法律文件的分类和它们缺乏结构信息的情况，用于判决预测。具体来说，我们将文件分成部分，从自定义精调的大型语言模型的最后四层中提取它们的嵌入，并尝试通过无监督聚类来近似它们的结构。然后在另一组变压器编码器层中使用这些表示来学习部分间的表示。我们分析了具有数十亿参数的大型语言模型(LLM)的适应性(GPT-Neo)。

    arXiv:2403.06872v1 Announce Type: cross  Abstract: Legal judgment prediction suffers from the problem of long case documents exceeding tens of thousands of words, in general, and having a non-uniform structure. Predicting judgments from such documents becomes a challenging task, more so on documents with no structural annotation. We explore the classification of these large legal documents and their lack of structural information with a deep-learning-based hierarchical framework which we call MESc; "Multi-stage Encoder-based Supervised with-clustering"; for judgment prediction. Specifically, we divide a document into parts to extract their embeddings from the last four layers of a custom fine-tuned Large Language Model, and try to approximate their structure through unsupervised clustering. Which we use in another set of transformer encoder layers to learn the inter-chunk representations. We analyze the adaptability of Large Language Models (LLMs) with multi-billion parameters (GPT-Neo
    
[^13]: 在有噪声基础模型中学习

    Learning with Noisy Foundation Models

    [https://arxiv.org/abs/2403.06869](https://arxiv.org/abs/2403.06869)

    本文首次全面了解和分析了预训练数据集中的噪声性质，有效减轻其对下游任务影响。

    

    基础模型通常是在大规模数据集上进行预训练，然后通过调整来适应下游任务。然而，大规模预训练数据集往往无法获取或成本过高，可能包含标签噪声，这可能会对模型的泛化能力造成不利影响，并带来意想不到的风险。本文是首个全面了解和分析预训练数据集中噪声性质，并有效减轻其对下游任务影响的工作。具体而言，通过在合成有噪声的ImageNet-1K、YFCC15M和CC12M数据集上进行完全监督和图像-文本对比预训练的广泛实验，我们证明了，尽管预训练中的轻微噪声可以使同领域（ID）性能受益，即训练和测试数据共享类似分布，但它总是会破坏跨领域（OOD）性能，在那里训练和测试分布明显不同。

    arXiv:2403.06869v1 Announce Type: cross  Abstract: Foundation models are usually pre-trained on large-scale datasets and then adapted to downstream tasks through tuning. However, the large-scale pre-training datasets, often inaccessible or too expensive to handle, can contain label noise that may adversely affect the generalization of the model and pose unexpected risks. This paper stands out as the first work to comprehensively understand and analyze the nature of noise in pre-training datasets and then effectively mitigate its impacts on downstream tasks. Specifically, through extensive experiments of fully-supervised and image-text contrastive pre-training on synthetic noisy ImageNet-1K, YFCC15M, and CC12M datasets, we demonstrate that, while slight noise in pre-training can benefit in-domain (ID) performance, where the training and testing data share a similar distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing distributions are signific
    
[^14]: 开发一种可靠且易获取的护理语言模型（CaLM）

    Development of a Reliable and Accessible Caregiving Language Model (CaLM)

    [https://arxiv.org/abs/2403.06857](https://arxiv.org/abs/2403.06857)

    该研究旨在开发一种可靠的护理语言模型（CaLM），使用FM和护理知识库，通过RAG框架和FM微调提高FM答案质量，以支持家庭护理人员提供优质护理。

    

    与专业护理人员不同，家庭护理人员通常在没有正式准备或培训的情况下承担这一角色。因此，迫切需要增强家庭护理人员提供优质护理的能力。大型语言模型可以作为支持护理人员的教育工具或护理的辅助技术的基础技术。本研究旨在通过使用FM和护理知识库开发可靠的护理语言模型（CaLM），使用需要更少计算资源的小FM开发易获取的CaLM，并评估模型相对于大型FM的性能。我们使用检索增强生成（RAG）框架结合FM微调开发CaLM，以通过将模型基于护理知识库来提高FM答案的质量。我们选择两个小FM作为CaLM的FM候选者（LLaMA-2和参数为7B的Falcon），以及更大的FM GPT-3.5。

    arXiv:2403.06857v1 Announce Type: new  Abstract: Unlike professional caregivers, family caregivers often assume this role without formal preparation or training. Because of this, there is an urgent need to enhance the capacity of family caregivers to provide quality care. Large language models can potentially be used as a foundation technology for supporting caregivers as educational tools or as adjunct to care. This study aimed to develop a reliable Caregiving Language Model (CaLM) by using FMs and a caregiving knowledge base, develop an accessible CaLM using a small FM that requires fewer computing resources, and evaluate the performance of the model compared to a large FM. We developed CaLM using the Retrieval Augmented Generation (RAG) framework combined with FM fine-tuning for improving the quality of FM answers by grounding the model on a caregiving knowledge base. We used two small FMs as candidates for the FM of CaLM (LLaMA-2 and Falcon with 7B parameters) and larger FM GPT-3.5
    
[^15]: RA-ISF: 通过迭代自反馈学习检索增强以回答和理解

    RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback

    [https://arxiv.org/abs/2403.06840](https://arxiv.org/abs/2403.06840)

    通过迭代自反馈的检索增强方法在指定任务的特定场景中提高模型性能，优于现有基准模型，显著增强了事实推理能力。

    

    大型语言模型(LLMs)在许多任务中表现出色，但仍然严重依赖存储在其参数中的知识。检索增强生成(RAG)方法通过整合外部知识来解决这一问题。模型可以通过检索与查询相关的知识来回答以前无法回答的问题。本文提出了检索增强迭代自反馈(RA-ISF)框架，通过三个子模块迭代分解任务并处理它们，以增强模型的问题解决能力。实验证明，我们的方法优于现有基准，在诸如GPT3.5、Llama2之类的模型上表现良好，显著增强了事实推理能力。

    arXiv:2403.06840v1 Announce Type: cross  Abstract: Large language models (LLMs) demonstrate exceptional performance in numerous tasks but still heavily rely on knowledge stored in their parameters. Moreover, updating this knowledge incurs high training costs. Retrieval-augmented generation (RAG) methods address this issue by integrating external knowledge. The model can answer questions it couldn't previously by retrieving knowledge relevant to the query. This approach improves performance in certain scenarios for specific tasks. However, if irrelevant texts are retrieved, it may impair model performance. In this paper, we propose Retrieval Augmented Iterative Self-Feedback (RA-ISF), a framework that iteratively decomposes tasks and processes them in three submodules to enhance the model's problem-solving capabilities. Experiments show that our method outperforms existing benchmarks, performing well on models like GPT3.5, Llama2, significantly enhancing factual reasoning capabilities a
    
[^16]: 通过细粒度图像-文本对齐和解剖病理提示进行医学图像合成

    Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting

    [https://arxiv.org/abs/2403.06835](https://arxiv.org/abs/2403.06835)

    通过细粒度图像-文本对齐和解剖病理提示，提出一种新的医学图像合成模型，能够生成高度详细和准确的合成医学图像。

    

    数据稀缺和隐私问题限制了高质量医学图像供公众使用的可用性，可以通过医学图像合成来缓解这一问题。然而，当前的医学图像合成方法常常难以准确捕捉详细解剖结构和病理条件的复杂性。为解决这些挑战，我们提出了一种新颖的医学图像合成模型，利用细粒度图像-文本对齐和解剖病理提示生成高度详细和准确的合成医学图像。我们的方法将先进的自然语言处理技术与图像生成建模相结合，实现描述性文本提示与合成图像的解剖和病理细节之间的精确对齐。所提出的方法由两个关键组件组成：解剖病理提示模块和基于细粒度对齐的合成模块。

    arXiv:2403.06835v1 Announce Type: cross  Abstract: Data scarcity and privacy concerns limit the availability of high-quality medical images for public use, which can be mitigated through medical image synthesis. However, current medical image synthesis methods often struggle to accurately capture the complexity of detailed anatomical structures and pathological conditions. To address these challenges, we propose a novel medical image synthesis model that leverages fine-grained image-text alignment and anatomy-pathology prompts to generate highly detailed and accurate synthetic medical images. Our method integrates advanced natural language processing techniques with image generative modeling, enabling precise alignment between descriptive text prompts and the synthesized images' anatomical and pathological details. The proposed approach consists of two key components: an anatomy-pathology prompting module and a fine-grained alignment-based synthesis module. The anatomy-pathology prompt
    
[^17]: LLMs能够将指令与数据分离吗？我们具体指的是什么？

    Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?

    [https://arxiv.org/abs/2403.06833](https://arxiv.org/abs/2403.06833)

    本研究提出了一种形式化的度量来量化指令与数据分离现象，以及一种可以从模型黑盒输出计算的经验变量，并引入了新数据集SEP，用于评估

    

    arXiv:2403.06833v1 公告类型: 跨 针对大型语言模型（LLMs）进行调节指令的技术取得了突破性的成果，为许多实际应用打开了无数新可能。然而，LLMs缺乏其他计算机科学领域已建立为规范的基本安全特性，比如指令与数据之间的分离，导致它们发生故障或易受第三方操控和干扰（例如通过间接提示/命令注入）。更糟糕的是，迄今为止，甚至没有确切定义这种分离究竟意味着什么以及如何测试其违反情况。本研究旨在填补这一空白。我们引入了一个正式的指标来量化指令与数据分离现象，以及一个可以从模型的黑盒输出计算的经验变量。我们还介绍了一个新的数据集SEP（应该执行还是处理？），该数据集允许评估

    arXiv:2403.06833v1 Announce Type: cross  Abstract: Instruction-tuned Large Language Models (LLMs) have achieved breakthrough results, opening countless new possibilities for many practical applications. However, LLMs lack elementary safety features that are established norms in other areas of computer science, such as the separation between instructions and data, causing them to malfunction or rendering them vulnerable to manipulation and interference by third parties e.g., via indirect prompt/command injection. Even worse, so far, there is not even an established definition of what precisely such a separation would mean and how its violation could be tested. In this work, we aim to close this gap. We introduce a formal measure to quantify the phenomenon of instruction-data separation as well as an empirical variant of the measure that can be computed from a model`s black-box outputs. We also introduce a new dataset, SEP (Should it be Executed or Processed?), which allows estimating th
    
[^18]: 噪声的力量：朝着统一的多模态知识图表示框架

    The Power of Noise: Toward a Unified Multi-modal Knowledge Graph Representation Framework

    [https://arxiv.org/abs/2403.06832](https://arxiv.org/abs/2403.06832)

    提出了一种利用噪声掩模的Transformer-based架构SNAG方法，实现了多模态知识图表示中实体嵌入的最先进性能

    

    多模态预训练的进展凸显出鲁棒的多模态知识图（MMKG）表示学习框架的必要性。此框架对于在规模上将结构化知识整合到多模态大型语言模型（LLMs）中至关重要，旨在减轻知识误解和多模态幻觉等问题。在这项工作中，为了评估模型准确嵌入MMKG中的实体的能力，我们专注于两个广泛研究的任务：多模态知识图完成（MKGC）和多模态实体对齐（MMEA）。在此基础上，我们提出了一种新颖的SNAG方法，该方法利用基于Transformer的架构，并配备了模态级噪声掩模，以在知识图中鲁棒地集成多模态实体特征。通过为MKGC和MMEA都引入特定的训练目标，我们的方法在总共十个数据集上（三个用于MKGC和...

    arXiv:2403.06832v1 Announce Type: cross  Abstract: The advancement of Multi-modal Pre-training highlights the necessity for a robust Multi-Modal Knowledge Graph (MMKG) representation learning framework. This framework is crucial for integrating structured knowledge into multi-modal Large Language Models (LLMs) at scale, aiming to alleviate issues like knowledge misconceptions and multi-modal hallucinations. In this work, to evaluate models' ability to accurately embed entities within MMKGs, we focus on two widely researched tasks: Multi-modal Knowledge Graph Completion (MKGC) and Multi-modal Entity Alignment (MMEA). Building on this foundation, we propose a novel SNAG method that utilizes a Transformer-based architecture equipped with modality-level noise masking for the robust integration of multi-modal entity features in KGs. By incorporating specific training objectives for both MKGC and MMEA, our approach achieves SOTA performance across a total of ten datasets (three for MKGC and 
    
[^19]: SPLADE-v3：SPLADE的新基准

    SPLADE-v3: New baselines for SPLADE

    [https://arxiv.org/abs/2403.06789](https://arxiv.org/abs/2403.06789)

    SPLADE-v3相对于BM25和SPLADE++在效果上更为显著，同时与交叉编码器重新排序器相比较出色，具有更高的性能表现。

    

    这是SPLADE库最新版本发布的伴随物。我们描述了对训练结构的更改，并展示了最新一系列的模型--SPLADE-v3。我们将这个新版本与BM25、SPLADE++以及重新排序器进行比较，并通过对40多个查询集的元分析展示其有效性。SPLADE-v3进一步推动了SPLADE模型的极限：它在统计上显著比BM25和SPLADE++更为有效，同时与交叉编码器重新排序器相比较出色。具体而言，它在MS MARCO dev集上获得了40个以上的MRR@10，并在BEIR基准测试中将域外结果提高了2%。

    arXiv:2403.06789v1 Announce Type: cross  Abstract: A companion to the release of the latest version of the SPLADE library. We describe changes to the training structure and present our latest series of models -- SPLADE-v3. We compare this new version to BM25, SPLADE++, as well as re-rankers, and showcase its effectiveness via a meta-analysis over more than 40 query sets. SPLADE-v3 further pushes the limit of SPLADE models: it is statistically significantly more effective than both BM25 and SPLADE++, while comparing well to cross-encoder re-rankers. Specifically, it gets more than 40 MRR@10 on the MS MARCO dev set, and improves by 2% the out-of-domain results on the BEIR benchmark.
    
[^20]: 不同之处在于力量！通过定制策略规划实现有效的非合作对话

    Strength Lies in Differences! Towards Effective Non-collaborative Dialogues via Tailored Strategy Planning

    [https://arxiv.org/abs/2403.06769](https://arxiv.org/abs/2403.06769)

    该论文提出了一个名为TRIP的机制，通过整合用户感知的战略规划模块和基于人口的训练范式，解决了非合作对话代理商面临的挑战，有效地满足多样化用户的需求。

    

    我们研究了非合作对话代理商，他们必须进行定制的战略规划，以确保与多样化用户达成有利的协议。这对现有的对话代理商构成挑战，主要原因有两点：他们无法将用户特定特征整合到战略规划中，以及他们的训练范式未能产生可以泛化到多样化用户的战略规划者。为了解决这些挑战，我们提出了TRIP以增强定制战略规划的能力，包括用户感知的战略规划模块和基于人口的训练范式。通过对基准非合作对话任务的实验，我们展示了TRIP在迎合多样化用户方面的有效性。

    arXiv:2403.06769v1 Announce Type: new  Abstract: We investigate non-collaborative dialogue agents that must engage in tailored strategic planning for diverse users to secure a favorable agreement. This poses challenges for existing dialogue agents due to two main reasons: their inability to integrate user-specific characteristics into their strategic planning and their training paradigm's failure to produce strategic planners that can generalize to diverse users. To address these challenges, we propose TRIP to enhance the capability in tailored strategic planning, incorporating a user-aware strategic planning module and a population-based training paradigm. Through experiments on benchmark non-collaborative dialogue tasks, we demonstrate the effectiveness of TRIP in catering to diverse users.
    
[^21]: 使用基于情感的大型语言模型检测阴谋理论

    ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model

    [https://arxiv.org/abs/2403.06765](https://arxiv.org/abs/2403.06765)

    本研究提出了ConspEmoLLM，这是第一个集成情感信息的大型语言模型，通过对阴谋理论文本的情感特征进行综合分析，能够执行多项任务，包括阴谋理论检测、理论类型分类和相关文本检测。

    

    互联网给社会带来了好处和伤害。后者的一个主要例子是误导信息，包括充斥网络的阴谋理论。 自然语言处理的最新进展，特别是大型语言模型（LLMs）的出现，已经提高了准确检测误导信息的前景。然而，大多数基于LLM的阴谋理论检测方法仅专注于二元分类，并未考虑误导信息与情感特征（即情感和情绪）之间的重要关系。通过对揭示其独特情感特征的阴谋文本的全面分析，我们提出了ConspEmoLLM，这是第一个集成情感信息且能够执行涉及阴谋理论的多样任务的开源LLM。 这些任务不仅包括阴谋理论检测，还包括理论类型分类和相关文本检测。

    arXiv:2403.06765v1 Announce Type: new  Abstract: The internet has brought both benefits and harms to society. A prime example of the latter is misinformation, including conspiracy theories, which flood the web. Recent advances in natural language processing, particularly the emergence of large language models (LLMs), have improved the prospects of accurate misinformation detection. However, most LLM-based approaches to conspiracy theory detection focus only on binary classification and fail to account for the important relationship between misinformation and affective features (i.e., sentiment and emotions). Driven by a comprehensive analysis of conspiracy text that reveals its distinctive affective features, we propose ConspEmoLLM, the first open-source LLM that integrates affective information and is able to perform diverse tasks relating to conspiracy theories. These tasks include not only conspiracy theory detection, but also classification of theory type and detection of related d
    
[^22]: 一张图片在第二层之后价值1/2代币：针对大规模视觉语言模型的即插即用推理加速

    An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models

    [https://arxiv.org/abs/2403.06764](https://arxiv.org/abs/2403.06764)

    FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。

    

    在本研究中，我们发现大规模视觉语言模型（LVLMs）中的注意力计算存在低效现象，尤其是在知名模型如LLaVA-1.5、QwenVL-Chat和Video-LLaVA中。我们发现在流行的LVLMs的深层中，对视觉代币的注意力计算极其低效，暗示相较于处理文本数据，需要更稀疏的方法。为此，我们引入了FastV，这是一种多功能即插即用方法，旨在通过学习早期层中的自适应注意力模式和在随后层中修剪视觉代币来优化计算效率。我们的评估表明FastV能够显著降低计算成本（例如，对于LLaVA-1.5-13B的FLOP减少了45%），而不会在广泛的图像和视频理解任务中牺牲性能。FastV的计算效率和性能权衡是高度可定制的，并且是帕累托有效的。

    arXiv:2403.06764v1 Announce Type: cross  Abstract: In this study, we identify the inefficient attention phenomena in Large Vision-Language Models (LVLMs), notably within prominent models like LLaVA-1.5, QwenVL-Chat and Video-LLaVA. We find out that the attention computation over visual tokens is of extreme inefficiency in the deep layers of popular LVLMs, suggesting a need for a sparser approach compared to textual data handling. To this end, we introduce FastV, a versatile plug-and-play method designed to optimize computational efficiency by learning adaptive attention patterns in early layers and pruning visual tokens in subsequent ones. Our evaluations demonstrate FastV's ability to dramatically reduce computational costs (e.g., a 45 reduction in FLOPs for LLaVA-1.5-13B) without sacrificing performance in a wide range of image and video understanding tasks. The computational efficiency and performance trade-off of FastV are highly customizable and pareto-efficient. It can compress t
    
[^23]: ALaRM: 通过分层奖励建模对齐语言模型

    ALaRM: Align Language Models via Hierarchical Rewards Modeling

    [https://arxiv.org/abs/2403.06754](https://arxiv.org/abs/2403.06754)

    ALaRM是第一个从人类反馈中建模分层奖励的框架，通过整合整体奖励与特定方面的奖励，改善了大型语言模型与人类偏好的对齐性，尤其在复杂文本生成任务中表现出更精确和一致的指导。

    

    我们介绍了ALaRM，第一个在强化学习中从人类反馈模型分层奖励的框架，旨在增强大型语言模型（LLMs）与人类偏好的对齐性。该框架解决了当前对齐方法的限制，这些方法通常难以处理人类监督信号的不一致性和稀疏性，通过将整体奖励与特定方面的奖励相结合。这种整合使得语言模型更加精确和一致地指导朝着期望的结果前进，尤其在复杂和开放的文本生成任务中。通过应用基于一致性的方法来过滤和组合多个奖励，该框架提供了一种可靠的机制来改善模型的对齐性。我们通过在长篇问题回答和机器翻译任务中使用gpt-3.5-turbo进行成对比较来验证我们的方法。

    arXiv:2403.06754v1 Announce Type: cross  Abstract: We introduce ALaRM, the first framework modeling hierarchical rewards in reinforcement learning from human feedback (RLHF), which is designed to enhance the alignment of large language models (LLMs) with human preferences. The framework addresses the limitations of current alignment approaches, which often struggle with the inconsistency and sparsity of human supervision signals, by integrating holistic rewards with aspect-specific rewards. This integration enables more precise and consistent guidance of language models towards desired outcomes, particularly in complex and open text generation tasks. By employing a methodology that filters and combines multiple rewards based on their consistency, the framework provides a reliable mechanism for improving model alignment. We validate our approach through applications in long-form question answering and machine translation tasks, employing gpt-3.5-turbo for pairwise comparisons, and demon
    
[^24]: ACT-MNMT自动收缩转向多语言神经机器翻译

    ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation

    [https://arxiv.org/abs/2403.06745](https://arxiv.org/abs/2403.06745)

    该论文介绍了一种针对多语言神经机器翻译中出现的离靶问题的新型监督微调机制ACT-MNMT Auto-Constriction Turning，与传统基于提示的方法正交，并通过自动构建受限模板来解决该问题。

    

    大型语言模型（LLM）通过零/少shot提示或提示调整在多语言机器翻译任务中取得了令人期待的表现。然而，由于在LLM的预训练过程中混合了多语言数据，基于LLM的翻译模型在基于提示的方法中面临了离靶问题，包括一系列现象，即指令误解、错误语言翻译和过度生成。针对这一问题，本文介绍了一种用于多语言神经机器翻译（\model）的\textbf{\underline{A}}uto-\textbf{\underline{C}}onstriction \textbf{\underline{T}}urning机制，这是一种新颖的监督微调机制，与传统的基于提示的方法正交。在这种方法中，\model通过在目标端添加触发令牌自动构造受限模板。

    arXiv:2403.06745v1 Announce Type: cross  Abstract: Large language model (LLM) has achieved promising performance in multilingual machine translation tasks through zero/few-shot prompts or prompt-tuning. However, due to the mixture of multilingual data during the pre-training of LLM, the LLM-based translation models face the off-target issue in both prompt-based methods, including a series of phenomena, namely instruction misunderstanding, translation with wrong language and over-generation. For this issue, this paper introduces an \textbf{\underline{A}}uto-\textbf{\underline{C}}onstriction \textbf{\underline{T}}urning mechanism for \textbf{\underline{M}}ultilingual \textbf{\underline{N}}eural \textbf{\underline{M}}achine \textbf{\underline{T}}ranslation (\model), which is a novel supervised fine-tuning mechanism and orthogonal to the traditional prompt-based methods. In this method, \model automatically constructs a constrained template in the target side by adding trigger tokens ahead
    
[^25]: 急救服务的实时多模态认知助手

    Real-Time Multimodal Cognitive Assistant for Emergency Medical Services

    [https://arxiv.org/abs/2403.06734](https://arxiv.org/abs/2403.06734)

    本文提出了CognitiveEMS，一个实时多模态认知助手系统，通过引入三个新颖组件解决了实时认知辅助中的关键技术挑战，为急救服务提供关键的辅助。

    

    急救服务（EMS）响应者经常在时间紧迫的条件下工作，面临认知过载和固有风险，需要具备关键思维和快速决策的基本技能。本文介绍了CognitiveEMS，这是一个端到端的可穿戴认知助手系统，可以充当协作虚拟伙伴，实时获取和分析急救现场的多模态数据，并通过增强现实（AR）智能眼镜与EMS响应者互动。CognitiveEMS实时处理连续的数据流，并利用边缘计算来提供EMS协议选择和干预识别的辅助。通过引入三个新颖组件，我们解决了实时认知辅助中的关键技术挑战：（i）一个经过微调的语音识别模型，用于针对模拟的EMS音频记录进行实际急诊对话，增强wit

    arXiv:2403.06734v1 Announce Type: new  Abstract: Emergency Medical Services (EMS) responders often operate under time-sensitive conditions, facing cognitive overload and inherent risks, requiring essential skills in critical thinking and rapid decision-making. This paper presents CognitiveEMS, an end-to-end wearable cognitive assistant system that can act as a collaborative virtual partner engaging in the real-time acquisition and analysis of multimodal data from an emergency scene and interacting with EMS responders through Augmented Reality (AR) smart glasses. CognitiveEMS processes the continuous streams of data in real-time and leverages edge computing to provide assistance in EMS protocol selection and intervention recognition. We address key technical challenges in real-time cognitive assistance by introducing three novel components: (i) a Speech Recognition model that is fine-tuned for real-world medical emergency conversations using simulated EMS audio recordings, augmented wit
    
[^26]: 通过监督预训练和重要性机制微调改进低资源知识追踪任务

    Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning

    [https://arxiv.org/abs/2403.06725](https://arxiv.org/abs/2403.06725)

    本文提出了名为LoReKT的低资源知识追踪框架，通过监督预训练和微调重要性机制，旨在从丰富资源的KT数据集中学习可转移的参数和表示来改进低资源知识追踪任务。

    

    知识追踪（KT）旨在基于学生的历史互动来估计他们的知识掌握程度。最近，基于深度学习的KT（DLKT）方法在KT任务中取得了令人印象深刻的表现。然而，由于各种原因，如预算限制和隐私问题，许多实际场景中观察到的互动非常有限，即低资源KT数据集。直接在低资源KT数据集上训练DLKT模型可能会导致过拟合，并且很难选择适当的深度神经架构。因此，在本文中，我们提出了一个名为LoReKT的低资源KT框架来应对上述挑战。受盛行的“预训练和微调”范式的启发，我们旨在在预训练阶段从丰富资源的KT数据集中学习可转移的参数和表示。

    arXiv:2403.06725v1 Announce Type: cross  Abstract: Knowledge tracing (KT) aims to estimate student's knowledge mastery based on their historical interactions. Recently, the deep learning based KT (DLKT) approaches have achieved impressive performance in the KT task. These DLKT models heavily rely on the large number of available student interactions. However, due to various reasons such as budget constraints and privacy concerns, observed interactions are very limited in many real-world scenarios, a.k.a, low-resource KT datasets. Directly training a DLKT model on a low-resource KT dataset may lead to overfitting and it is difficult to choose the appropriate deep neural architecture. Therefore, in this paper, we propose a low-resource KT framework called LoReKT to address above challenges. Inspired by the prevalent "pre-training and fine-tuning" paradigm, we aim to learn transferable parameters and representations from rich-resource KT datasets during the pre-training stage and subseque
    
[^27]: 恢复古代表意字符: 一种多模态多任务神经网络方法

    Restoring Ancient Ideograph: A Multimodal Multitask Neural Network Approach

    [https://arxiv.org/abs/2403.06682](https://arxiv.org/abs/2403.06682)

    提出一种多模态多任务恢复模型（MMRM）来恢复古代文本，特别强调表意字符，结合上下文理解和残留的视觉信息来预测受损字符并生成恢复图像。

    

    文化遗产作为人类思想和历史的永恒记录。尽管已经付出了大量努力来保护文化遗产，但许多古代文物已经被自然退化和人为行为不可逆地破坏。深度学习技术已经成为恢复各种文化遗产，包括古代文本恢复的有价值工具。以往的研究通常从视觉或文本角度探讨古代文本的恢复，往往忽视了多模态信息相互配合的潜力。本文提出了一种新颖的多模态多任务恢复模型（MMRM）来恢复古代文本，特别强调表意字符。该模型将从受损古代文物中的上下文理解与残留的视觉信息相结合，使其能够同时预测受损字符并生成恢复图像。我们通过实验测试了MMRM模型

    arXiv:2403.06682v1 Announce Type: new  Abstract: Cultural heritage serves as the enduring record of human thought and history. Despite significant efforts dedicated to the preservation of cultural relics, many ancient artefacts have been ravaged irreversibly by natural deterioration and human actions. Deep learning technology has emerged as a valuable tool for restoring various kinds of cultural heritages, including ancient text restoration. Previous research has approached ancient text restoration from either visual or textual perspectives, often overlooking the potential of synergizing multimodal information. This paper proposes a novel Multimodal Multitask Restoring Model (MMRM) to restore ancient texts, particularly emphasising the ideograph. This model combines context understanding with residual visual information from damaged ancient artefacts, enabling it to predict damaged characters and generate restored images simultaneously. We tested the MMRM model through experiments cond
    
[^28]: 大象永远不会忘记：测试语言模型对表格数据的记忆能力

    Elephants Never Forget: Testing Language Models for Memorization of Tabular Data

    [https://arxiv.org/abs/2403.06644](https://arxiv.org/abs/2403.06644)

    本研究针对表格数据探讨了大型语言模型（LLMs）存在的数据污染和记忆化问题，发现LLMs在许多常见的表格数据集上进行了预训练，可能导致在下游任务中对性能评估的无效性。

    

    虽然许多人已经展示了大型语言模型（LLMs）如何应用于各种任务，但数据污染和记忆化的关键问题往往被忽视。在这项工作中，我们针对表格数据解决了这一问题。我们从简单的定性测试开始，测试LLM是否知道特征的名称和值，引入了各种不同的技术来评估污染程度，包括用于条件分布建模的统计测试和四个识别记忆化的测试。我们的调查发现，LLMs在许多流行的表格数据集上进行了预训练。这种暴露可能导致在下游任务上无效的性能评估，因为LLMs实际上已经适应了测试集。有趣的是，我们还确定了一种情况，在这种情况下，语言模型可以复制数据的重要统计信息，但无法逐字复制数据集。在这些数据集上，尽管见过...

    arXiv:2403.06644v1 Announce Type: cross  Abstract: While many have shown how Large Language Models (LLMs) can be applied to a diverse set of tasks, the critical issues of data contamination and memorization are often glossed over. In this work, we address this concern for tabular data. Starting with simple qualitative tests for whether an LLM knows the names and values of features, we introduce a variety of different techniques to assess the degrees of contamination, including statistical tests for conditional distribution modeling and four tests that identify memorization. Our investigation reveals that LLMs are pre-trained on many popular tabular datasets. This exposure can lead to invalid performance evaluation on downstream tasks because the LLMs have, in effect, been fit to the test set. Interestingly, we also identify a regime where the language model reproduces important statistics of the data, but fails to reproduce the dataset verbatim. On these datasets, although seen during 
    
[^29]: KELLMRec: 知识增强大型语言模型用于推荐

    KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation

    [https://arxiv.org/abs/2403.06642](https://arxiv.org/abs/2403.06642)

    提出了一种知识增强的大型语言模型用于推荐的方法，通过使用外部知识来帮助生成真实可用的文本，并包括知识为基础的对比学习方案进行训练。

    

    在推荐系统领域，利用语义信息是一个重要的研究问题，旨在补充主流基于ID的方法的缺失部分。随着LLM的兴起，它作为知识库的能力和推理能力为这一研究领域开辟了新的可能性，使基于LLM的推荐成为新兴研究方向。然而，直接使用LLM来处理推荐场景中的语义信息是不可靠和次优的，由于存在幻觉等问题。应对这一问题的一种有前途的方法是利用外部知识来帮助LLM生成真实可用的文本。受以上动机的启发，我们提出了一种知识增强的LLMRec方法。除了在提示中使用外部知识外，所提出的方法还包括一个基于知识的对比学习方案用于训练。在公共数据集和企业中进行的实验

    arXiv:2403.06642v1 Announce Type: cross  Abstract: The utilization of semantic information is an important research problem in the field of recommender systems, which aims to complement the missing parts of mainstream ID-based approaches. With the rise of LLM, its ability to act as a knowledge base and its reasoning capability have opened up new possibilities for this research area, making LLM-based recommendation an emerging research direction. However, directly using LLM to process semantic information for recommendation scenarios is unreliable and sub-optimal due to several problems such as hallucination. A promising way to cope with this is to use external knowledge to aid LLM in generating truthful and usable text. Inspired by the above motivation, we propose a Knowledge-Enhanced LLMRec method. In addition to using external knowledge in prompts, the proposed method also includes a knowledge-based contrastive learning scheme for training. Experiments on public datasets and in-enter
    
[^30]: MedKP：医学对话与知识增强与临床路径编码

    MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding

    [https://arxiv.org/abs/2403.06611](https://arxiv.org/abs/2403.06611)

    通过整合外部知识增强模块和内部临床路径编码，MedKP框架在医学对话生成中取得了显著进展。

    

    通过适当的数据选择和训练技术，大型语言模型（LLMs）在各种医学考试和多项选择问题中表现出色。 然而，LLMs在医学对话生成领域的应用--这个任务更加贴近实际医学实践--却鲜有探讨。 这一差距归因于LLMs医学知识不足，导致生成的医学回复出现不准确和幻觉信息。 在这项工作中，我们介绍了医学对话与知识增强和临床路径编码（MedKP）框架，通过医学知识图和医疗实体以及医师行动的内部临床路径编码，集成了外部知识增强模块。 通过全面指标进行评估，我们在两个大规模、真实世界的在线医学咨询数据集（MedDG和KaMed）上的实验表明

    arXiv:2403.06611v1 Announce Type: cross  Abstract: With appropriate data selection and training techniques, Large Language Models (LLMs) have demonstrated exceptional success in various medical examinations and multiple-choice questions. However, the application of LLMs in medical dialogue generation-a task more closely aligned with actual medical practice-has been less explored. This gap is attributed to the insufficient medical knowledge of LLMs, which leads to inaccuracies and hallucinated information in the generated medical responses. In this work, we introduce the Medical dialogue with Knowledge enhancement and clinical Pathway encoding (MedKP) framework, which integrates an external knowledge enhancement module through a medical knowledge graph and an internal clinical pathway encoding via medical entities and physician actions. Evaluated with comprehensive metrics, our experiments on two large-scale, real-world online medical consultation datasets (MedDG and KaMed) demonstrate 
    
[^31]: 通过知识种子指导大型语言模型的临床推理

    Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds

    [https://arxiv.org/abs/2403.06609](https://arxiv.org/abs/2403.06609)

    大型语言模型在临床推理中展现出潜力，但存在幻觉问题和与医生决策路径不一致的挑战。

    

    临床推理是医生在评估和管理患者时采用的认知过程。这个过程通常涉及建议必要的检查，诊断患者疾病，并决定适当的治疗等。准确的临床推理需要广泛的医学知识和丰富的临床经验，为医生设置了很高的门槛。最近，像ChatGPT和GPT-4这样的大型语言模型(LLMs)显示出在临床推理中的潜力。然而，这些LLMs容易出现幻觉问题，而LLMs的推理过程可能与医生的临床决策路径不一致。在这项研究中，我们引入了一种

    arXiv:2403.06609v1 Announce Type: cross  Abstract: Clinical reasoning refers to the cognitive process that physicians employ in evaluating and managing patients. This process typically involves suggesting necessary examinations, diagnosing patients' diseases, and deciding on appropriate therapies, etc. Accurate clinical reasoning requires extensive medical knowledge and rich clinical experience, setting a high bar for physicians. This is particularly challenging in developing countries due to the overwhelming number of patients and limited physician resources, contributing significantly to global health inequity and necessitating automated clinical reasoning approaches. Recently, the emergence of large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated their potential in clinical reasoning. However, these LLMs are prone to hallucination problems, and the reasoning process of LLMs may not align with the clinical decision path of physicians. In this study, we introduce a 
    
[^32]: 学术智能的大型语言模型未必具备社会智能

    Academically intelligent LLMs are not necessarily socially intelligent

    [https://arxiv.org/abs/2403.06591](https://arxiv.org/abs/2403.06591)

    LLMs的社会智能仍有改进空间，存在较低的社会智能和学术智能相关性。

    

    最近，大型语言模型（LLMs）在学术智能方面取得了显著进展，但它们的社会智能表现仍不清楚。受到已建立的人类社会智能框架的启发，特别是丹尼尔·戈尔曼的社会智能理论，我们开发了一个基于真实社会场景的标准化社会智能测试，名为社会智能情境评估（SESI）。我们对13个近期流行的和尖端的LLM代理在SESI上进行了全面评估。结果表明，LLMs的社会智能仍有显著改进空间，表面友好是错误的主要原因。此外，LLMs展示的社会智能与学术智能之间存在较低的相关性，表明社会智能不同于学术智能。

    arXiv:2403.06591v1 Announce Type: new  Abstract: The academic intelligence of large language models (LLMs) has made remarkable progress in recent times, but their social intelligence performance remains unclear. Inspired by established human social intelligence frameworks, particularly Daniel Goleman's social intelligence theory, we have developed a standardized social intelligence test based on real-world social scenarios to comprehensively assess the social intelligence of LLMs, termed as the Situational Evaluation of Social Intelligence (SESI). We conducted an extensive evaluation with 13 recent popular and state-of-art LLM agents on SESI. The results indicate the social intelligence of LLMs still has significant room for improvement, with superficially friendliness as a primary reason for errors. Moreover, there exists a relatively low correlation between the social intelligence and academic intelligence exhibited by LLMs, suggesting that social intelligence is distinct from academ
    
[^33]: ContextGPT: 将LLMs知识注入神经符号活动识别模型

    ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models

    [https://arxiv.org/abs/2403.06586](https://arxiv.org/abs/2403.06586)

    将预训练的大型语言模型（LLMs）的常识知识有效地注入神经符号活动识别模型，以缓解标记数据稀缺性问题。

    

    上下文感知人类活动识别（HAR）是移动计算中一个热门的研究领域，文献中最有效的解决方案基于监督式深度学习模型。然而，这些系统的实际部署受到需要用于训练的标记数据的稀缺性的限制。神经符号人工智能（NeSy）为缓解这一问题提供了一个有趣的研究方向，即将关于人类活动及其可能发生的背景的常识知识注入HAR深度学习分类器中。现有的用于上下文感知HAR的NeSy方法依赖于逻辑模型中编码的知识（例如本体论），其设计、实施和维护以捕捉新活动和上下文需要显著的人力工程努力、技术知识和领域专业知识。最近的研究表明，预训练的大型语言模型（LLMs）有效地编码了关于人类活动的常识知识。

    arXiv:2403.06586v1 Announce Type: cross  Abstract: Context-aware Human Activity Recognition (HAR) is a hot research area in mobile computing, and the most effective solutions in the literature are based on supervised deep learning models. However, the actual deployment of these systems is limited by the scarcity of labeled data that is required for training. Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate this issue, by infusing common-sense knowledge about human activities and the contexts in which they can be performed into HAR deep learning classifiers. Existing NeSy methods for context-aware HAR rely on knowledge encoded in logic-based models (e.g., ontologies) whose design, implementation, and maintenance to capture new activities and contexts require significant human engineering efforts, technical knowledge, and domain expertise. Recent works show that pre-trained Large Language Models (LLMs) effectively encode common-sense knowledge about human a
    
[^34]: AC-EVAL：评估大型语言模型中对古代汉语的理解

    AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models

    [https://arxiv.org/abs/2403.06574](https://arxiv.org/abs/2403.06574)

    AC-EVAL是一个评估大型语言模型对古代汉语理解的创新基准，分为三个难度级别，涵盖历史知识、短文本和长文本理解，对LLMs的高级知识和推理能力进行评估。

    

    鉴于古代汉语在捕捉丰富历史和文化遗产精髓方面的重要性，大型语言模型（LLMs）的快速发展需要有效评估它们对古代语境的理解能力的基准。为了满足这一需求，我们提出了AC-EVAL，这是一个创新的基准，旨在评估LLMs在古代汉语语境中的高级知识和推理能力。AC-EVAL分为三个难度级别，反映了语言理解的不同方面：一般历史知识、短文本理解和长文本理解。该基准包括13个任务，涵盖历史事实、地理、社会习俗、艺术、哲学、古典诗歌和散文，提供了一个全面的评估框架。我们对表现最佳的针对英文和汉语的LLMs进行了广泛评估，揭示了增强古代汉语理解潜力的重要性。

    arXiv:2403.06574v1 Announce Type: new  Abstract: Given the importance of ancient Chinese in capturing the essence of rich historical and cultural heritage, the rapid advancements in Large Language Models (LLMs) necessitate benchmarks that can effectively evaluate their understanding of ancient contexts. To meet this need, we present AC-EVAL, an innovative benchmark designed to assess the advanced knowledge and reasoning capabilities of LLMs within the context of ancient Chinese. AC-EVAL is structured across three levels of difficulty reflecting different facets of language comprehension: general historical knowledge, short text understanding, and long text comprehension. The benchmark comprises 13 tasks, spanning historical facts, geography, social customs, art, philosophy, classical poetry and prose, providing a comprehensive assessment framework. Our extensive evaluation of top-performing LLMs, tailored for both English and Chinese, reveals a substantial potential for enhancing ancie
    
[^35]: 改进实际会议应用中说话者归因ASR中的说话者分配

    Improving Speaker Assignment in Speaker-Attributed ASR for Real Meeting Applications

    [https://arxiv.org/abs/2403.06570](https://arxiv.org/abs/2403.06570)

    该研究提出了一种优化实际会议应用中Speaker-Attributed ASR系统的方法，通过使用语音活动检测输出来微调模型以减少说话者错误率，并探讨了增强说话者嵌入模板提取的策略。

    

    过去关于端到端会议转录的研究主要集中在模型架构上，并且大多数是在模拟会议数据上进行评估的。我们提出了一项旨在优化Speaker-Attributed ASR (SA-ASR)系统在现实场景中（如AMI会议语料库）使用的研究，以改进语音段的说话者分配。首先，我们提出了一个针对涉及语音活动检测（VAD）、说话者辨识（SD）和SA-ASR的现实生活应用的流程。其次，我们提倡使用VAD输出段来微调SA-ASR模型，考虑到在测试期间它也被应用于VAD段，并展示了这导致说话者错误率（SER）相对减少高达28％。最后，我们探讨增强从SD输出中提取说话者嵌入模板的策略，这些模板作为SA-ASR系统的输入。我们证明，将它们从SD输出中提取而不是从注释的说话者段中提取，会导致一种...

    arXiv:2403.06570v1 Announce Type: new  Abstract: Past studies on end-to-end meeting transcription have focused on model architecture and have mostly been evaluated on simulated meeting data. We present a novel study aiming to optimize the use of a Speaker-Attributed ASR (SA-ASR) system in real-life scenarios, such as the AMI meeting corpus, for improved speaker assignment of speech segments. First, we propose a pipeline tailored to real-life applications involving Voice Activity Detection (VAD), Speaker Diarization (SD), and SA-ASR. Second, we advocate using VAD output segments to fine-tune the SA-ASR model, considering that it is also applied to VAD segments during test, and show that this results in a relative reduction of Speaker Error Rate (SER) up to 28%. Finally, we explore strategies to enhance the extraction of the speaker embedding templates used as inputs by the SA-ASR system. We show that extracting them from SD output rather than annotated speaker segments results in a rela
    
[^36]: 揭开缩放定律之谜：第一部分

    Unraveling the Mystery of Scaling Laws: Part I

    [https://arxiv.org/abs/2403.06563](https://arxiv.org/abs/2403.06563)

    确认缩放定律原则在模型预训练中的重要作用，揭示OpenAI原始缩放定律论文的不完整细节，并探究预测测试损失轨迹可靠公式的挑战

    

    缩放定律原则表明在模型大小、数据集大小和训练过程中使用的计算资源等变量之间存在幂定律相关性。这些原则在优化模型预训练的各个方面中起着至关重要的作用，最终有助于大型语言模型（如GPT-4、Llama和Gemini）的成功。然而，OpenAI的原始缩放定律论文并未披露推导精确缩放定律公式所必需的完整细节，他们的结论仅基于包含高达15亿参数的模型。尽管一些后续作品试图揭示这些细节并扩展到更大的模型，但它们经常忽略了重要因素的训练依赖性，如学习速率、上下文长度和批量大小，导致它们未能建立一个可靠的预测测试损失轨迹的公式。在本技术报告中，我们确认了缩放

    arXiv:2403.06563v1 Announce Type: cross  Abstract: Scaling law principles indicate a power-law correlation between loss and variables such as model size, dataset size, and computational resources utilized during training. These principles play a vital role in optimizing various aspects of model pre-training, ultimately contributing to the success of large language models such as GPT-4, Llama and Gemini. However, the original scaling law paper by OpenAI did not disclose the complete details necessary to derive the precise scaling law formulas, and their conclusions are only based on models containing up to 1.5 billion parameters. Though some subsequent works attempt to unveil these details and scale to larger models, they often neglect the training dependency of important factors such as the learning rate, context length and batch size, leading to their failure to establish a reliable formula for predicting the test loss trajectory. In this technical report, we confirm that the scaling 
    
[^37]: 对AI开放性的考量: 善意能否被滥用？

    On the Consideration of AI Openness: Can Good Intent Be Abused?

    [https://arxiv.org/abs/2403.06537](https://arxiv.org/abs/2403.06537)

    开源技术虽然促进了科技进步，但也存在滥用风险，研究发现开源语言模型可以被调整用于提供有关犯罪活动的不道德且具有信息性的答案。

    

    开放性对科学的进展至关重要。特别是，最近人工智能的快速进展仅可能通过各种开源模型、数据集和库。然而，这种开放性也意味着技术可以被自由地用于社会有害目的。开源模型或数据集可以被用于恶意目的吗？如果是这样，那么技术被用于这些目的会有多容易？本文在法律领域进行了一个案例研究，这是一个个人决策可能产生深远社会后果的领域。为此，我们构建了EVE数据集，包含了200个关于犯罪活动的问题和对应答案，基于200个韩国先例。我们发现一个广泛认可的开源LLM，最初拒绝回答不道德问题，可以很容易地通过EVE进行调整，提供关于犯罪活动的不道德且具有信息性的答案。这意味着，尽管开源技术能够促进科学技术进步，但同时也带来了滥用风险。

    arXiv:2403.06537v1 Announce Type: new  Abstract: Openness is critical for the advancement of science. In particular, recent rapid progress in AI has been made possible only by various open-source models, datasets, and libraries. However, this openness also means that technologies can be freely used for socially harmful purposes. Can open-source models or datasets be used for malicious purposes? If so, how easy is it to adapt technology for such goals? Here, we conduct a case study in the legal domain, a realm where individual decisions can have profound social consequences. To this end, we build EVE, a dataset consisting of 200 examples of questions and corresponding answers about criminal activities based on 200 Korean precedents. We found that a widely accepted open-source LLM, which initially refuses to answer unethical questions, can be easily tuned with EVE to provide unethical and informative answers about criminal activities. This implies that although open-source technologies c
    
[^38]: 如何理解命名实体：在新闻标题生成中使用常识

    How to Understand Named Entities: Using Common Sense for News Captioning

    [https://arxiv.org/abs/2403.06520](https://arxiv.org/abs/2403.06520)

    该论文利用常识知识来帮助新闻标题生成系统理解命名实体，从而更好地描述图像内容。

    

    新闻标题生成旨在使用新闻文章主体描述图像。它在很大程度上依赖于一组检测到的命名实体，包括真实世界的人物、组织和地点。本文利用常识知识来理解新闻标题生成中的命名实体。通过“理解”，我们指的是将新闻内容与常识联系起来，帮助代理人区分语义上相似的命名实体，并利用训练语料库之外的词语描述命名实体。

    arXiv:2403.06520v1 Announce Type: cross  Abstract: News captioning aims to describe an image with its news article body as input. It greatly relies on a set of detected named entities, including real-world people, organizations, and places. This paper exploits commonsense knowledge to understand named entities for news captioning. By ``understand'', we mean correlating the news content with common sense in the wild, which helps an agent to 1) distinguish semantically similar named entities and 2) describe named entities using words outside of training corpora. Our approach consists of three modules: (a) Filter Module aims to clarify the common sense concerning a named entity from two aspects: what does it mean? and what is it related to?, which divide the common sense into explanatory knowledge and relevant knowledge, respectively. (b) Distinguish Module aggregates explanatory knowledge from node-degree, dependency, and distinguish three aspects to distinguish semantically similar name
    
[^39]: 使用上下文无关文法自动生成Python程序

    Automatic Generation of Python Programs Using Context-Free Grammars

    [https://arxiv.org/abs/2403.06503](https://arxiv.org/abs/2403.06503)

    使用上下文无关文法自动生成Python程序的TinyPy Generator工具可以确保生成的程序的正确性，并能轻松生成大规模Python代码，尤其适用于机器学习领域。

    

    近年来，数据已经成为新的黄金，成为创建智能系统的强大工具。然而，获取高质量的数据仍然具有挑战性，尤其是对于代码。为了解决这个问题，我们开发了TinyPy Generator，这是一个使用上下文无关文法生成随机Python程序的工具。生成的程序通过构造保证正确性。我们的系统使用自定义的产生规则（采用巴科斯-诺尔范式（BNF）格式）递归地生成代码。这使我们能够生成具有不同复杂程度的代码，范围从仅包含赋值的代码到包含条件和循环的更复杂代码。我们提出的工具实现了轻松的大规模Python代码生成，在各种应用中具有益处。TinyPy Generator在机器学习领域特别有用，可以为训练Python语言模型生成大量Python代码。

    arXiv:2403.06503v1 Announce Type: cross  Abstract: In recent years, data has emerged as the new gold, serving as a powerful tool for creating intelligent systems. However, procuring high-quality data remains challenging, especially for code. To address this, we developed TinyPy Generator, a tool that generates random Python programs using a context-free grammar. The generated programs are guaranteed to be correct by construction. Our system uses custom production rules (in the Backus-Naur Form (BNF) format) to recursively generate code. This allows us to generate code with different levels of complexity, ranging from code containing only assignments to more complex code containing conditionals and loops. Our proposed tool enables effortless large-scale Python code generation, beneficial for a wide range of applications. TinyPy Generator is particularly useful in the field of machine learning, where it can generate substantial amounts of Python code for training Python language models. 
    
[^40]: 使用语音活动投影进行多语言交替预测

    Multilingual Turn-taking Prediction Using Voice Activity Projection

    [https://arxiv.org/abs/2403.06487](https://arxiv.org/abs/2403.06487)

    本文研究了在口头对话中使用语音活动投影进行多语言交替预测，在多语言数据上训练的多语言模型展示出与单一语言模型相当的预测性能，并且学会了辨别输入信号的语言。

    

    本文研究了在多语言数据上应用语音活动投影（VAP），这是一种用于口头对话的预测性交替模型，涵盖英语、汉语和日语。VAP模型持续预测双人对话中参与者即将发生的语音活动，利用交叉注意力Transformer捕捉参与者之间的动态互动。结果表明，在单一语言上训练的VAP模型在其他语言上的应用不会产生很好的预测。然而，在三种语言上训练的多语言模型，在所有语言上表现出与单语模型相当的预测性能。进一步的分析表明，多语言模型已学会辨别输入信号的语言。我们还分析了对音调敏感性，这是一种被认为对于交替非常重要的韵律线索。最后，我们比较了两种不同的音频编码器。

    arXiv:2403.06487v1 Announce Type: new  Abstract: This paper investigates the application of voice activity projection (VAP), a predictive turn-taking model for spoken dialogue, on multilingual data, encompassing English, Mandarin, and Japanese. The VAP model continuously predicts the upcoming voice activities of participants in dyadic dialogue, leveraging a cross-attention Transformer to capture the dynamic interplay between participants. The results show that a monolingual VAP model trained on one language does not make good predictions when applied to other languages. However, a multilingual model, trained on all three languages, demonstrates predictive performance on par with monolingual models across all languages. Further analyses show that the multilingual model has learned to discern the language of the input signal. We also analyze the sensitivity to pitch, a prosodic cue that is thought to be important for turn-taking. Finally, we compare two different audio encoders, contrast
    
[^41]: 大规模云系统中的知识感知警报聚合：一种混合方法

    Knowledge-aware Alert Aggregation in Large-scale Cloud Systems: a Hybrid Approach

    [https://arxiv.org/abs/2403.06485](https://arxiv.org/abs/2403.06485)

    提出了一种基于相关挖掘和大型语言模型推理的新型混合方法COLA，用于大规模云系统中的警报聚合，能够综合利用外部知识来解决基于语义相似性和统计方法的警报聚合的局限性。

    

    由于云系统的规模和复杂性，系统故障会引发“警报风暴”，即大量相关的警报。尽管这些警报可以追溯到少数几个根本原因，但压倒性的数量使人工处理变得不可行。因此，警报聚合对帮助工程师集中精力解决根本原因并促进故障解决至关重要。现有方法通常利用基于语义相似性的方法或统计方法来聚合警报。然而，基于语义相似性的方法忽视了警报的因果推理，而统计方法几乎无法处理不经常发生的警报。 为了解决这些限制，我们介绍了利用外部知识，即警报的标准操作规程（SOP）作为补充。我们提出了一种基于相关挖掘和LLM（Large Language Model）推理的在线警报聚合的新型混合方法COLA。

    arXiv:2403.06485v1 Announce Type: cross  Abstract: Due to the scale and complexity of cloud systems, a system failure would trigger an "alert storm", i.e., massive correlated alerts. Although these alerts can be traced back to a few root causes, the overwhelming number makes it infeasible for manual handling. Alert aggregation is thus critical to help engineers concentrate on the root cause and facilitate failure resolution. Existing methods typically utilize semantic similarity-based methods or statistical methods to aggregate alerts. However, semantic similarity-based methods overlook the causal rationale of alerts, while statistical methods can hardly handle infrequent alerts.   To tackle these limitations, we introduce leveraging external knowledge, i.e., Standard Operation Procedure (SOP) of alerts as a supplement. We propose COLA, a novel hybrid approach based on correlation mining and LLM (Large Language Model) reasoning for online alert aggregation. The correlation mining modul
    
[^42]: 基于大型语言模型内部状态的无监督实时幻觉检测

    Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models

    [https://arxiv.org/abs/2403.06448](https://arxiv.org/abs/2403.06448)

    提出了一种利用大型语言模型内部状态进行实时幻觉检测的无监督训练框架，并引入了一个新的基准用于评估多个大型语言模型的幻觉检测。

    

    大型语言模型中的幻觉是指产生连贯但事实不准确的响应。为了解决LLMs中幻觉的问题，本文提出了MIND，一种利用LLMs内部状态进行实时幻觉检测的无监督训练框架。同时，我们还提出了HELM，一个用于评估多个LLMs幻觉检测的新基准，在LLMs推理过程中具有多样化的LLM输出和内部状态。

    arXiv:2403.06448v1 Announce Type: cross  Abstract: Hallucinations in large language models (LLMs) refer to the phenomenon of LLMs producing responses that are coherent yet factually inaccurate. This issue undermines the effectiveness of LLMs in practical applications, necessitating research into detecting and mitigating hallucinations of LLMs. Previous studies have mainly concentrated on post-processing techniques for hallucination detection, which tend to be computationally intensive and limited in effectiveness due to their separation from the LLM's inference process. To overcome these limitations, we introduce MIND, an unsupervised training framework that leverages the internal states of LLMs for real-time hallucination detection without requiring manual annotations. Additionally, we present HELM, a new benchmark for evaluating hallucination detection across multiple LLMs, featuring diverse LLM outputs and the internal states of LLMs during their inference process. Our experiments d
    
[^43]: 利用大型语言模型和主动学习演进知识蒸馏

    Evolving Knowledge Distillation with Large Language Models and Active Learning

    [https://arxiv.org/abs/2403.06414](https://arxiv.org/abs/2403.06414)

    本文提出了EvoKD，利用主动学习与大型语言模型交互地增强数据生成过程，同时改进小领域模型的任务能力。

    

    大型语言模型（LLMs）在各种自然语言处理任务中展示了显著的能力。然而，它们的计算成本过高。为了解决这个问题，先前的研究尝试将LLMs的知识蒸馏到更小的模型中，通过生成带标注的数据来实现。然而，这些工作主要集中在直接利用LLMs进行文本生成和标注，而没有充分探索它们理解目标任务和获取有价值知识的潜力。在本文中，我们提出了EvoKD：演进知识蒸馏，利用主动学习的概念与大型语言模型交互地增强数据生成过程，同时改进小领域模型（学生模型）的任务能力。与以往的工作不同，我们主动分析学生模型的不足之处，然后基于该分析综合标记样本。此外，我们提供了i

    arXiv:2403.06414v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across various NLP tasks. However, their computational costs are prohibitively high. To address this issue, previous research has attempted to distill the knowledge of LLMs into smaller models by generating annotated data. Nonetheless, these works have mainly focused on the direct use of LLMs for text generation and labeling, without fully exploring their potential to comprehend the target task and acquire valuable knowledge. In this paper, we propose EvoKD: Evolving Knowledge Distillation, which leverages the concept of active learning to interactively enhance the process of data generation using large language models, simultaneously improving the task capabilities of small domain model (student model). Different from previous work, we actively analyze the student model's weaknesses, and then synthesize labeled samples based on the analysis. In addition, we provide i
    
[^44]: CLIcK：韩国文化和语言智慧的基准数据集

    CLIcK: A Benchmark Dataset of Cultural and Linguistic Intelligence in Korean

    [https://arxiv.org/abs/2403.06412](https://arxiv.org/abs/2403.06412)

    CLIcK介绍了一个包含1,995个问答对的韩国文化和语言智慧基准数据集，为填补韩语基准数据缺失的问题而来。

    

    尽管针对韩语的大型语言模型（LLMs）迅速发展，但仍然存在明显缺乏测试必要韩国文化和语言知识的基准数据集。现有的许多韩语基准数据集是通过翻译从英语对应数据集中衍生出来的，它们通常忽视不同的文化背景。仅有少数从韩国数据源捕捉文化知识的基准数据集，提供的仅有偏见和仇恨言论检测等狭窄任务。为了填补这一空白，我们介绍了一个名为CLIcK的韩国文化和语言智慧基准数据集，包含1,995个问答对。CLIcK将其数据来源于韩国官方考试和教科书，将问题分为两个主要类别（语言和文化）下的11个类别。对于CLIcK中的每个实例，我们提供了对哪些文化和语言知识的细粒度注释。

    arXiv:2403.06412v1 Announce Type: new  Abstract: Despite the rapid development of large language models (LLMs) for the Korean language, there remains an obvious lack of benchmark datasets that test the requisite Korean cultural and linguistic knowledge. Because many existing Korean benchmark datasets are derived from the English counterparts through translation, they often overlook the different cultural contexts. For the few benchmark datasets that are sourced from Korean data capturing cultural knowledge, only narrow tasks such as bias and hate speech detection are offered. To address this gap, we introduce a benchmark of Cultural and Linguistic Intelligence in Korean (CLIcK), a dataset comprising 1,995 QA pairs. CLIcK sources its data from official Korean exams and textbooks, partitioning the questions into eleven categories under the two main categories of language and culture. For each instance in CLIcK, we provide fine-grained annotation of which cultural and linguistic knowledge
    
[^45]: 用于蕴涵树生成的逻辑模式记忆预训练模型

    A Logical Pattern Memory Pre-trained Model for Entailment Tree Generation

    [https://arxiv.org/abs/2403.06410](https://arxiv.org/abs/2403.06410)

    提出了逻辑模式记忆预训练模型（LMPM），通过结合外部存储结构学习和存储逻辑模式的潜在表示，有助于生成逻辑一致的结论，并引入实体抽象方法来减少维基百科数据中的逻辑无关领域知识的影响。

    

    在人工智能领域，生成连贯可信的解释仍然是一个重大挑战。最近，研究人员深入研究了利用蕴涵树来描述解释的方法，这展示了一个假设如何从支持事实中推导出的推理过程。然而，现有模型通常忽视了从给定事实中生成具有逻辑一致性的中间结论的重要性，导致不准确的结论，削弱了蕴涵树的整体可信度。为了解决这一限制，我们提出了逻辑模式记忆预训练模型（LMPM）。LMPM结合了外部存储结构，学习和存储逻辑模式的潜在表示，有助于生成逻辑一致的结论。此外，为了减少维基百科数据中逻辑无关领域知识的影响，我们引入了一种实体抽象方法。

    arXiv:2403.06410v1 Announce Type: cross  Abstract: Generating coherent and credible explanations remains a significant challenge in the field of AI. In recent years, researchers have delved into the utilization of entailment trees to depict explanations, which exhibit a reasoning process of how a hypothesis is deduced from the supporting facts. However, existing models often overlook the importance of generating intermediate conclusions with logical consistency from the given facts, leading to inaccurate conclusions and undermining the overall credibility of entailment trees. To address this limitation, we propose the logical pattern memory pre-trained model (LMPM). LMPM incorporates an external memory structure to learn and store the latent representations of logical patterns, which aids in generating logically consistent conclusions. Furthermore, to mitigate the influence of logically irrelevant domain knowledge in the Wikipedia-based data, we introduce an entity abstraction approach
    
[^46]: 一刀切不适用：学习在文本分类中使用多少例为了改进上下文学习

    'One size doesn't fit all': Learning how many Examples to use for In-Context Learning for Improved Text Classification

    [https://arxiv.org/abs/2403.06402](https://arxiv.org/abs/2403.06402)

    本文提出了自适应上下文学习（AICL）的工作流程，通过动态调整示例数量来提高文本分类的性能，类似于k最近邻（k-NN）中的可变大小邻域。

    

    arXiv:2403.06402v1 发表类型：新 Abstract: 自然语言处理（NLP）中的预测模型已经从从头训练模型发展到使用标记数据微调预训练模型。这种微调的极端形式涉及到上下文学习（ICL），其中一个预先训练的生成模型的输出（冻结的解码器参数）只受到输入字符串的变化（称为指令或提示）的控制。ICL的一个重要组成部分是在提示中使用少量标记数据实例作为示例。尽管现有工作在推理过程中为每个数据实例使用静态数量的示例，但在本文中，我们提出了一种动态调整示例数量的新方法。这类似于k最近邻（k-NN）分类器中使用可变大小邻域的方法。在我们提出的自适应ICL（AICL）的工作流程中，对于特定数据实例进行推理时使用的演示数量是动态调整的。

    arXiv:2403.06402v1 Announce Type: new  Abstract: Predictive models in natural language processing (NLP) have evolved from training models from scratch to fine-tuning pre-trained models with labelled data. An extreme form of this fine-tuning involves in-context learning (ICL), where the output of a pre-trained generative model (frozen decoder parameters) is controlled only with variations in the input strings (called instructions or prompts). An important component of ICL is the use of a small number of labelled data instances as examples in the prompt. While existing work uses a static number of examples during inference for each data instance, in this paper we propose a novel methodology of dynamically adapting the number of examples as per the data. This is analogous to the use of a variable-sized neighborhood in k-nearest neighbors (k-NN) classifier. In our proposed workflow of adaptive ICL (AICL), the number of demonstrations to employ during the inference on a particular data inst
    
[^47]: GlossLM: 低资源语言文字间注释的多语言预训练

    GlossLM: Multilingual Pretraining for Low-Resource Interlinear Glossing

    [https://arxiv.org/abs/2403.06399](https://arxiv.org/abs/2403.06399)

    该论文提出了GlossLM模型，通过利用跨语言转移和大规模多语言预训练，实现了低资源语言文字间注释的有效生成。

    

    语言文献学的一个关键方面是以形式如文字间注释文本（IGT）的方式创建带注释的文本，IGT以逐词素的格式捕捉了精细的形态句法分析。先前的研究已探索了自动生成IGT的方法，以减少语言分析的时间成本。然而，许多语言（尤其是需要保护的语言）缺乏足够的IGT数据来训练有效的模型，跨语言转移被提出作为克服这一局限的方法。我们编制了来自各种来源的最大已有IGT数据语料库，涵盖了来自1.8k种语言的超过45万个例子，以便进行跨语言转移和IGT生成方面的研究。然后，我们在部分语料库上对一个大型多语言模型进行预训练，并进一步对特定语言进行微调。我们的模型在分割数据和大型单语数据方面与最先进的方法相竞争。

    arXiv:2403.06399v1 Announce Type: new  Abstract: A key aspect of language documentation is the creation of annotated text in a format such as interlinear glossed text (IGT), which captures fine-grained morphosyntactic analyses in a morpheme-by-morpheme format. Prior work has explored methods to automatically generate IGT in order to reduce the time cost of language analysis. However, many languages (particularly those requiring preservation) lack sufficient IGT data to train effective models, and crosslingual transfer has been proposed as a method to overcome this limitation.   We compile the largest existing corpus of IGT data from a variety of sources, covering over 450k examples across 1.8k languages, to enable research on crosslingual transfer and IGT generation. Then, we pretrain a large multilingual model on a portion of this corpus, and further finetune it to specific languages. Our model is competitive with state-of-the-art methods for segmented data and large monolingual datas
    
[^48]: 人类和自动解释罗马尼亚名词复合词

    Human and Automatic Interpretation of Romanian Noun Compounds

    [https://arxiv.org/abs/2403.06360](https://arxiv.org/abs/2403.06360)

    提出了新的罗马尼亚名词复合词关系集，通过人类和神经网络分类器测试后发现，网络的预测与人类判断存在一致，即使是在人类一致率较低的情况下。需要一个更好的关系清单。

    

    确定类似"鞋子销售"和"火灾大甩卖"这样的名词复合词在特定语境中的预期含义对于自然语言处理而言仍然是一个挑战。先前的研究依赖于捕捉复合词成员间不同含义的语义关系清单。针对罗马尼亚的复合词，其形态句法与英语的对应物不同，我们提出了一个新的关系集，并通过人类注释者和神经网络分类器进行了测试。结果显示网络的预测与人类判断之间存在一致，即使在人类一致率较低的地方也是如此。一致性与所选关系的频率保持一致，而不受结构差异的影响。然而，最常选择的关系不属于十六个标记的语义关系之一，这表明需要一个更好的关系清单。

    arXiv:2403.06360v1 Announce Type: cross  Abstract: Determining the intended, context-dependent meanings of noun compounds like "shoe sale" and "fire sale" remains a challenge for NLP. Previous work has relied on inventories of semantic relations that capture the different meanings between compound members. Focusing on Romanian compounds, whose morphosyntax differs from that of their English counterparts, we propose a new set of relations and test it with human annotators and a neural net classifier. Results show an alignment of the network's predictions and human judgments, even where the human agreement rate is low. Agreement tracks with the frequency of the selected relations, regardless of structural differences. However, the most frequently selected relation was none of the sixteen labeled semantic relations, indicating the need for a better relation inventory.
    
[^49]: 具有对比交叉模态特征对齐的多模态语义理解

    Multi-modal Semantic Understanding with Contrastive Cross-modal Feature Alignment

    [https://arxiv.org/abs/2403.06355](https://arxiv.org/abs/2403.06355)

    提出了一种以CLIP为引导的对比学习架构，实现了多模态特征对齐，在多模态任务上表现显著优于多个基线模型，并展示了对模型性能提升的明显作用。

    

    arXiv:2403.06355v1 公告类型: 新摘要: 多模态语义理解需要整合来自不同模态的信息，以提取用户言辞背后的真实意图。大多数先前的工作应用双编码器结构分别对图像和文本进行编码，但未能学习跨模态特征对齐，这使得难以实现跨模态的深度信息交互。本文提出了一种新颖的以CLIP为引导的基于对比学习的架构，以执行多模态特征对齐，将来自不同模态的特征投影到统一的深度空间中。在多模态讽刺检测（MMSD）和多模态情感分析（MMSA）任务上，实验结果表明我们提出的模型显著优于几个基线模型，并且我们的特征对齐策略比具有不同聚合方法的模型和甚至富含知识的模型带来明显的性能提升。更重要的是，我们的模型实现简单。

    arXiv:2403.06355v1 Announce Type: new  Abstract: Multi-modal semantic understanding requires integrating information from different modalities to extract users' real intention behind words. Most previous work applies a dual-encoder structure to separately encode image and text, but fails to learn cross-modal feature alignment, making it hard to achieve cross-modal deep information interaction. This paper proposes a novel CLIP-guided contrastive-learning-based architecture to perform multi-modal feature alignment, which projects the features derived from different modalities into a unified deep space. On multi-modal sarcasm detection (MMSD) and multi-modal sentiment analysis (MMSA) tasks, the experimental results show that our proposed model significantly outperforms several baselines, and our feature alignment strategy brings obvious performance gain over models with different aggregating methods and models even enriched with knowledge. More importantly, our model is simple to implemen
    
[^50]: 阿姆哈拉语LLaMA和LLaVA：低资源语言的多模态LLMs

    Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages

    [https://arxiv.org/abs/2403.06354](https://arxiv.org/abs/2403.06354)

    本论文研究了如何训练LLaMA-2模型来学习阿姆哈拉语，使用了数据增强和连接图像编码器的方法以解决低资源语言的问题。

    

    像GPT-4和LLaMA这样的大型语言模型已经展现出在自然语言处理任务上的惊人能力，甚至开始擅长跨越视觉和音频等其他模态的任务。然而，尽管取得成功，LLMs在低资源语言上往往表现不佳，因为可用的训练数据非常少。这一不足在开源模型中尤为突出。在这项工作中，我们探讨了对LLaMA-2进行训练以讲阿姆哈拉语，这是一种全球有超过5千万人口使用的语言，但可用数据远少于英语等语言。我们采用之前用于在数据稀缺情况下训练LLMs的方法，并使用开源翻译模型进行数据增强，将我们的数据集从数百万个记号增长到数十亿个。我们通过连接图像编码器并训练翻译视觉理解任务的图像来进一步增强模型的能力。

    arXiv:2403.06354v1 Announce Type: new  Abstract: Large Language Models (LLMs) like GPT-4 and LLaMA have shown incredible proficiency at natural language processing tasks and have even begun to excel at tasks across other modalities such as vision and audio. Despite their success, LLMs often struggle to perform well on low-resource languages because there is so little training data available. This shortcoming is especially prevalent with open source models. In this work, we explore training LLaMA-2 to speak Amharic, a language which is spoken by over 50 million people world wide, but has orders of magnitude less data available than languages like English. We employ methods previously used for training LLMs on other languages with data scarcity, and use open source translation models to perform data augmentation and grow our dataset from millions of tokens to billions. We further enhance the capabilities of our model by connecting an image encoder and training on a translated visual inst
    
[^51]: IndicLLMSuite: 为印度语言创建预训练和微调数据集提供了蓝图

    IndicLLMSuite: A Blueprint for Creating Pre-training and Fine-Tuning Datasets for Indian Languages

    [https://arxiv.org/abs/2403.06350](https://arxiv.org/abs/2403.06350)

    为印度语言创建了一个覆盖22种语言、包含251B标记和74.8M指导-响应对的资源套件，结合高度筛选的数据、有价值的未验证数据和合成数据，建立了用于筛选预训练数据的干净开源流水线，以及用于指导微调的方法。

    

    尽管英文LLM（Large Language Models）取得了显著进展，但由于缺乏定制资源，构建其他语言的可比模型的进展受阻。我们的工作旨在通过引入一个专门为发展印度语言LLM而设计的大量资源套件来弥合这一鸿沟，涵盖了22种语言，包含总共251B标记和7480万个指导-响应对。我们认识到数据质量和数量的重要性，我们的方法结合了经过精心筛选的手动验证数据、尚未验证但有价值的数据和合成数据。我们构建了一个干净的、开源的流水线，用于从各种来源筛选预训练数据，包括网站、PDF和视频，融入了爬取、清理、标记和去重的最佳实践。对于指导微调，我们汇集了现有的印度数据集，将英文数据集翻译/转写成印度语言，并利用了LLaMa2的技术。

    arXiv:2403.06350v1 Announce Type: new  Abstract: Despite the considerable advancements in English LLMs, the progress in building comparable models for other languages has been hindered due to the scarcity of tailored resources. Our work aims to bridge this divide by introducing an expansive suite of resources specifically designed for the development of Indic LLMs, covering 22 languages, containing a total of 251B tokens and 74.8M instruction-response pairs. Recognizing the importance of both data quality and quantity, our approach combines highly curated manually verified data, unverified yet valuable data, and synthetic data. We build a clean, open-source pipeline for curating pre-training data from diverse sources, including websites, PDFs, and videos, incorporating best practices for crawling, cleaning, flagging, and deduplication. For instruction-fine tuning, we amalgamate existing Indic datasets, translate/transliterate English datasets into Indian languages, and utilize LLaMa2 a
    
[^52]: 从指令到约束：语言模型对齐与自动约束验证

    From Instructions to Constraints: Language Model Alignment with Automatic Constraint Verification

    [https://arxiv.org/abs/2403.06326](https://arxiv.org/abs/2403.06326)

    提出了ACT框架，通过约束验证器自动计算每个响应的约束满意率，实现语言模型对齐与自动约束验证。

    

    用户对齐对于将通用语言模型（LMs）调整为下游任务至关重要，但通常无法为所有类型的指令提供人类注释，特别是具有定制约束的指令。我们观察到用户指令通常包含约束条件。虽然评估整个指令的响应质量通常成本高昂，但高效地评估约束条件的满意率是可行的。我们研究了NLP任务中的常见约束条件，将它们基于其参数类型分类为三类，并提出了一个统一框架，ACT（Aligning to ConsTraints），用于自动为带约束用户对齐生成监督信号。具体而言，ACT使用约束验证器，这些验证器在实践中通常易于实现，来计算每个响应的约束满意率（CSR）。它为每个提示取样多个响应并收集偏好标签。

    arXiv:2403.06326v1 Announce Type: cross  Abstract: User alignment is crucial for adapting general-purpose language models (LMs) to downstream tasks, but human annotations are often not available for all types of instructions, especially those with customized constraints. We observe that user instructions typically contain constraints. While assessing response quality in terms of the whole instruction is often costly, efficiently evaluating the satisfaction rate of constraints is feasible. We investigate common constraints in NLP tasks, categorize them into three classes based on the types of their arguments, and propose a unified framework, ACT (Aligning to ConsTraints), to automatically produce supervision signals for user alignment with constraints. Specifically, ACT uses constraint verifiers, which are typically easy to implement in practice, to compute constraint satisfaction rate (CSR) of each response. It samples multiple responses for each prompt and collect preference labels ba
    
[^53]: LIEDER: 用于语篇实体识别的语言学评估

    LIEDER: Linguistically-Informed Evaluation for Discourse Entity Recognition

    [https://arxiv.org/abs/2403.06301](https://arxiv.org/abs/2403.06301)

    大型语言模型在语篇实体识别上具有基本的能力，但在新颖性方面仍未达到人类水平

    

    论文提出了一种称为 LIEDER 的数据集，允许详细检查语言模型对存在性、唯一性、复数性和新颖性等四个关键语义属性的认知水平。研究发现，最先进的大型语言模型对所有这些属性都表现出敏感性，除了新颖性，这表明它们尚未达到人类水平的语言理解能力。

    arXiv:2403.06301v1 Announce Type: new  Abstract: Discourse Entity (DE) recognition is the task of identifying novel and known entities introduced within a text. While previous work has found that large language models have basic, if imperfect, DE recognition abilities (Schuster and Linzen, 2022), it remains largely unassessed which of the fundamental semantic properties that govern the introduction and subsequent reference to DEs they have knowledge of. We propose the Linguistically-Informed Evaluation for Discourse Entity Recognition (LIEDER) dataset that allows for a detailed examination of language models' knowledge of four crucial semantic properties: existence, uniqueness, plurality, and novelty. We find evidence that state-of-the-art large language models exhibit sensitivity to all of these properties except novelty, which demonstrates that they have yet to reach human-level language understanding abilities.
    
[^54]: 基于Transformer的多任务学习用于图像字幕生成和物体检测

    Transformer based Multitask Learning for Image Captioning and Object Detection

    [https://arxiv.org/abs/2403.06292](https://arxiv.org/abs/2403.06292)

    提出了一种结合图像字幕生成和物体检测的Transformer多任务学习框架，通过联合训练实现两个任务之间信息的互补共享，从而提高了图像字幕生成的性能。

    

    在像自主导航和移动性这样的几个实际场景中，为了更好地理解周围环境，图像字幕生成和物体检测发挥着关键作用。本研究引入了一种新颖的多任务学习框架，将图像字幕生成和物体检测结合成一个联合模型。我们提出了TICOD，一种基于Transformer的图像字幕生成和物体检测模型，通过结合图像字幕生成和物体检测网络获得的损失来同时训练两个任务。通过利用联合训练，该模型受益于两个任务之间共享的互补信息，从而提高了图像字幕生成的性能。我们的方法利用了基于Transformer的架构，实现了图像字幕生成和物体检测的端到端网络集成，并联合执行两个任务。我们通过全面实验评估了我们方法的有效性。

    arXiv:2403.06292v1 Announce Type: cross  Abstract: In several real-world scenarios like autonomous navigation and mobility, to obtain a better visual understanding of the surroundings, image captioning and object detection play a crucial role. This work introduces a novel multitask learning framework that combines image captioning and object detection into a joint model. We propose TICOD, Transformer-based Image Captioning and Object detection model for jointly training both tasks by combining the losses obtained from image captioning and object detection networks. By leveraging joint training, the model benefits from the complementary information shared between the two tasks, leading to improved performance for image captioning. Our approach utilizes a transformer-based architecture that enables end-to-end network integration for image captioning and object detection and performs both tasks jointly. We evaluate the effectiveness of our approach through comprehensive experiments on the
    
[^55]: 拆解分词：评估文本压缩及其与模型性能的相关性

    Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance

    [https://arxiv.org/abs/2403.06265](https://arxiv.org/abs/2403.06265)

    本文研究了文本压缩在分词过程中的重要性，证明了压缩与预训练语言模型后续成功之间的实证重要性，并表明分词器的压缩与模型的性能存在相关性。

    

    尽管压缩是BPE最常见的分词算法的重要基础，但分词过程中的压缩重要性仍不清楚。本文论述了压缩的理论重要性，可以被看作是0-gram语言建模，即为所有标记分配相等的概率。我们还展示了压缩对预训练语言模型后续成功的实证重要性。我们通过改变训练过程中可用文档的数量来控制多个BPE分词器的压缩能力：从100万个文档到相当于没有训练数据的基于字符的分词器。然后，我们基于这些分词器预训练英语语言模型，并在多个任务上进行微调。我们展示了分词器的压缩与模型的后续性能之间存在相关性，表明压缩是分词的可靠内在指标

    arXiv:2403.06265v1 Announce Type: cross  Abstract: Despite it being the cornerstone of BPE, the most common tokenization algorithm, the importance of compression in the tokenization process is still unclear. In this paper, we argue for the theoretical importance of compression, that can be viewed as 0-gram language modeling where equal probability is assigned to all tokens. We also demonstrate the empirical importance of compression for downstream success of pre-trained language models. We control the compression ability of several BPE tokenizers by varying the amount of documents available during their training: from 1 million documents to a character-based tokenizer equivalent to no training data at all. We then pre-train English language models based on those tokenizers and fine-tune them over several tasks. We show that there is a correlation between tokenizers' compression and models' downstream performance, suggesting that compression is a reliable intrinsic indicator of tokeniza
    
[^56]: SCORE: 自监督对齐微调，提升内容表示

    SCORE: Self-supervised Correspondence Fine-tuning for Improved Content Representations

    [https://arxiv.org/abs/2403.06260](https://arxiv.org/abs/2403.06260)

    提出了一种名为SCORE的自监督对齐微调方法，通过对齐训练策略学习类似表示，并应用于内容相关任务，显著提高了HuBERT在各种任务上的性能。

    

    arXiv:2403.06260v1 公告类型：新 提要：对于通过自监督学习（SSL）基础语音模型来获得任务特定表示以在各种下游任务上获得稳健性能，自监督微调（SSFT）引起了越来越多的关注。这些任务特定表示通过在标记数据上进行微调，用于提高各种下游任务的性能。本工作提出了一种名为自监督对齐（SCORE）微调的成本效益的SSFT方法，以调整SSL语音表示以适应与内容相关的任务。该方法使用一种对齐训练策略，旨在从扰动语音和原始语音中学习类似的表示。通常用于内容相关任务（ASR）的数据增强技术被应用于获取扰动语音。SCORE微调的HuBERT在超级基准上表现优于普通HuBERT，仅通过在单个GPU上进行少量时间的微调（<5小时）即可用于自动语音识别、音素识别和基于查询的示例。

    arXiv:2403.06260v1 Announce Type: new  Abstract: There is a growing interest in cost-effective self-supervised fine-tuning (SSFT) of self-supervised learning (SSL)-based speech models to obtain task-specific representations. These task-specific representations are used for robust performance on various downstream tasks by fine-tuning on the labelled data. This work presents a cost-effective SSFT method named Self-supervised Correspondence (SCORE) fine-tuning to adapt the SSL speech representations for content-related tasks. The proposed method uses a correspondence training strategy, aiming to learn similar representations from perturbed speech and original speech. Commonly used data augmentation techniques for content-related tasks (ASR) are applied to obtain perturbed speech. SCORE fine-tuned HuBERT outperforms the vanilla HuBERT on SUPERB benchmark with only a few hours of fine-tuning (< 5 hrs) on a single GPU for automatic speech recognition, phoneme recognition, and query-by-examp
    
[^57]: 大型语言模型的概念知识编辑

    Editing Conceptual Knowledge for Large Language Models

    [https://arxiv.org/abs/2403.06259](https://arxiv.org/abs/2403.06259)

    该论文首次研究了为大型语言模型编辑概念知识，通过构建基准数据集和建立新评估指标，发现现有方法虽然能一定程度上修改概念定义，但也可能造成LLMs中相关实例知识的扭曲，导致性能下降。

    

    最近，对于大型语言模型（LLMs）的知识编辑引起了越来越多的关注。当前的方法和评估仅探讨了实例级别的编辑，然而LLMs是否具有修改概念的能力仍不清楚。本文首次研究了为LLMs编辑概念知识，通过构建一个新颖的基准数据集ConceptEdit并建立了一套新的评估指标。实验结果表明，尽管现有的编辑方法可以有效地在一定程度上修改概念级别的定义，但它们也有潜力扭曲LLMs中相关的实例知识，导致性能不佳。我们期望这可以激发对更好理解LLMs的进一步进展。我们的项目主页位于https://zjunlp.github.io/project/ConceptEdit。

    arXiv:2403.06259v1 Announce Type: cross  Abstract: Recently, there has been a growing interest in knowledge editing for Large Language Models (LLMs). Current approaches and evaluations merely explore the instance-level editing, while whether LLMs possess the capability to modify concepts remains unclear. This paper pioneers the investigation of editing conceptual knowledge for LLMs, by constructing a novel benchmark dataset ConceptEdit and establishing a suite of new metrics for evaluation. The experimental results reveal that, although existing editing methods can efficiently modify concept-level definition to some extent, they also have the potential to distort the related instantial knowledge in LLMs, leading to poor performance. We anticipate this can inspire further progress in better understanding LLMs. Our project homepage is available at https://zjunlp.github.io/project/ConceptEdit.
    
[^58]: 没有孤岛语言:统一中英文金融大型语言模型、指导数据和基准

    No Language is an Island: Unifying Chinese and English in Financial Large Language Models, Instruction Data, and Benchmarks

    [https://arxiv.org/abs/2403.06249](https://arxiv.org/abs/2403.06249)

    ICE-PIXIU模型将中文和英文金融分析统一，通过整合多种任务和数据集提升双语金融建模的效果。

    

    随着大型语言模型（LLM）的发展显著推动了金融分析，但它们的应用主要局限在单一语言领域，未充分开发中英文双语能力的潜力。为弥合这一鸿沟，我们引入 ICE-PIXIU，无缝融合 ICE-INTENT 模型和 ICE-FLARE 双语金融分析基准。ICE-PIXIU 独特地整合了一系列中文任务，以及翻译和原始英文数据集，丰富了双语金融建模的广度和深度。它提供了对多种模型变体的无限访问权限，一个包含多种跨语言和多模态指导数据的大量编译，以及一个具有专家注释的评估基准，包括 10 个 NLP 任务，20 个双语专用任务，共计1,185k 数据集。我们的彻底评估强调了将这些双语数据集纳入的优势，尤其在t

    arXiv:2403.06249v1 Announce Type: cross  Abstract: While the progression of Large Language Models (LLMs) has notably propelled financial analysis, their application has largely been confined to singular language realms, leaving untapped the potential of bilingual Chinese-English capacity. To bridge this chasm, we introduce ICE-PIXIU, seamlessly amalgamating the ICE-INTENT model and ICE-FLARE benchmark for bilingual financial analysis. ICE-PIXIU uniquely integrates a spectrum of Chinese tasks, alongside translated and original English datasets, enriching the breadth and depth of bilingual financial modeling. It provides unrestricted access to diverse model variants, a substantial compilation of diverse cross-lingual and multi-modal instruction data, and an evaluation benchmark with expert annotations, comprising 10 NLP tasks, 20 bilingual specific tasks, totaling 1,185k datasets. Our thorough evaluation emphasizes the advantages of incorporating these bilingual datasets, especially in t
    
[^59]: 用步骤式思维检索和对齐决策增强LLM代理

    TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision

    [https://arxiv.org/abs/2403.06221](https://arxiv.org/abs/2403.06221)

    提出了TRAD框架，通过步骤式思维检索和对齐决策解决了利用上下文示例时可能出现的问题。

    

    许多大型语言模型（LLM）代理已经被构建用于不同任务，如网络导航和在线购物，这是因为LLM具有广泛的知识和文本理解能力。在这些研究中，许多利用上下文示例来实现泛化，而无需微调，但少数考虑了如何选择和有效利用这些示例的问题。最近，基于轨迹级检索和使用轨迹作为上下文示例的方法已经提出，以提高代理在一些顺序决策任务中的整体性能。然而，这些方法可能存在问题，因为检索出的可信示例缺乏特定于任务的状态转移动态，且输入长且包含大量无关上下文。在本文中，我们提出了一个新框架（TRAD）来解决这些问题。TRAD首先进行思维检索，实现步骤级演示。

    arXiv:2403.06221v1 Announce Type: new  Abstract: Numerous large language model (LLM) agents have been built for different tasks like web navigation and online shopping due to LLM's wide knowledge and text-understanding ability. Among these works, many of them utilize in-context examples to achieve generalization without the need for fine-tuning, while few of them have considered the problem of how to select and effectively utilize these examples. Recently, methods based on trajectory-level retrieval with task meta-data and using trajectories as in-context examples have been proposed to improve the agent's overall performance in some sequential decision making tasks. However, these methods can be problematic due to plausible examples retrieved without task-specific state transition dynamics and long input with plenty of irrelevant context. In this paper, we propose a novel framework (TRAD) to address these issues. TRAD first conducts Thought Retrieval, achieving step-level demonstration
    
[^60]: 面向人类中心文本理解的个性化LoRA

    Personalized LoRA for Human-Centered Text Understanding

    [https://arxiv.org/abs/2403.06208](https://arxiv.org/abs/2403.06208)

    提出了一种个性化LoRA（PLoRA）用于人类中心文本理解任务，在适应寒启动问题上具有优越性能。

    

    在大多数个性化应用中，用户标记通常达到百万级，并且没有明确的具体语义，因此对于有效且高效地调整预训练语言模型（PLM）以用于人类中心文本理解（HCTU）颇具挑战性。标准且参数高效的方法（如LoRA）需要为每个用户记忆大量适配器套件。在本文中，我们引入了一种具有插拔（PnP）框架的个性化LoRA（PLoRA）用于HCTU任务。PLoRA在PLMs中是有效的、参数高效的，可以动态部署。此外，我们采用了个性化的dropout和最大化互信息策略，因此提出的PLoRA可以很好地适应少量/零次学习场景以解决冷启动问题。在四个基准数据集上进行的实验表明，所提出的方法在HCTU任务的全/少/零次学习场景中优于现有方法，即使它的适配器套件较少。

    arXiv:2403.06208v1 Announce Type: new  Abstract: Effectively and efficiently adapting a pre-trained language model (PLM) for human-centered text understanding (HCTU) is challenging since user tokens are million-level in most personalized applications and do not have concrete explicit semantics. A standard and parameter-efficient approach (e.g., LoRA) necessitates memorizing numerous suits of adapters for each user. In this work, we introduce a personalized LoRA (PLoRA) with a plug-and-play (PnP) framework for the HCTU task. PLoRA is effective, parameter-efficient, and dynamically deploying in PLMs. Moreover, a personalized dropout and a mutual information maximizing strategies are adopted and hence the proposed PLoRA can be well adapted to few/zero-shot learning scenarios for the cold-start issue. Experiments conducted on four benchmark datasets show that the proposed method outperforms existing methods in full/few/zero-shot learning scenarios for the HCTU task, even though it has fewe
    
[^61]: 通过语言建模识别和解释不一致的人类概念表示

    Identifying and interpreting non-aligned human conceptual representations using language modeling

    [https://arxiv.org/abs/2403.06204](https://arxiv.org/abs/2403.06204)

    通过引入监督的表示对齐方法，揭示了先天盲视引起了无模态和感觉相关的语义领域中的概念重组，并确定了相关的语义转变。

    

    关于人们在世界中的经验是否塑造了概念表征和词汇语义的问题是长期存在的。通过词联想、特征列表和相似度评定任务来解决这一问题，但需要对识别出的潜在维度进行主观解释。在这项研究中，我们引入了一种监督的表示对齐方法，该方法确定了两组个体是否共享某一类别的相同基础，并解释了他们在哪些方面不同。通过应用这一方法，我们展示先天盲视在无模态和感觉相关的语义领域中诱导概念重组，并确定了相关的语义转变。我们首先对语言模型（GloVe）应用监督特征修剪，以从词嵌入中优化人类相似度判断的预测准确性。修剪确定了一个子集的保留的GloVe特征，优化了预测的准确性。

    arXiv:2403.06204v1 Announce Type: new  Abstract: The question of whether people's experience in the world shapes conceptual representation and lexical semantics is longstanding. Word-association, feature-listing and similarity rating tasks aim to address this question but require a subjective interpretation of the latent dimensions identified. In this study, we introduce a supervised representational-alignment method that (i) determines whether two groups of individuals share the same basis of a certain category, and (ii) explains in what respects they differ. In applying this method, we show that congenital blindness induces conceptual reorganization in both a-modal and sensory-related verbal domains, and we identify the associated semantic shifts. We first apply supervised feature-pruning to a language model (GloVe) to optimize prediction accuracy of human similarity judgments from word embeddings. Pruning identifies one subset of retained GloVe features that optimizes prediction of 
    
[^62]: 您被追踪了吗？发现LLMs的零射轨迹跟踪的威力！

    Are You Being Tracked? Discover the Power of Zero-Shot Trajectory Tracing with LLMs!

    [https://arxiv.org/abs/2403.06201](https://arxiv.org/abs/2403.06201)

    介绍了LLMTrack模型，通过引入一种新颖的单提示技术，结合角色扮演和逐步思考方法，利用未经处理的IMU数据，实现了零射轨迹识别，超越了传统机器学习和深度学习模型，无需训练在专门数据集上的性能表现。

    

    在关于大型语言模型（LLMs）能够作为基本组件的讨论中，能够无缝地融入物联网人工智能（AIoT）中以解释复杂轨迹。本研究介绍了LLMTrack，该模型演示了如何利用LLMs进行零射轨迹识别，通过采用将角色扮演和逐步思考方法与未经处理的惯性测量单元（IMU）数据相结合的新颖单提示技术。我们使用真实世界数据集对模型进行评估，这些数据集旨在挑战它以具有室内和室外情景特征的不同轨迹。在两种测试情景中，LLMTrack 不仅满足甚至超过了传统机器学习方法以及当代最先进的深度学习模型设定的性能基准，而且无需对专门数据集进行训练。

    arXiv:2403.06201v1 Announce Type: cross  Abstract: There is a burgeoning discussion around the capabilities of Large Language Models (LLMs) in acting as fundamental components that can be seamlessly incorporated into Artificial Intelligence of Things (AIoT) to interpret complex trajectories. This study introduces LLMTrack, a model that illustrates how LLMs can be leveraged for Zero-Shot Trajectory Recognition by employing a novel single-prompt technique that combines role-play and think step-by-step methodologies with unprocessed Inertial Measurement Unit (IMU) data. We evaluate the model using real-world datasets designed to challenge it with distinct trajectories characterized by indoor and outdoor scenarios. In both test scenarios, LLMTrack not only meets but exceeds the performance benchmarks set by traditional machine learning approaches and even contemporary state-of-the-art deep learning models, all without the requirement of training on specialized datasets. The results of our 
    
[^63]: 通过小语言模型全面改造多模态助手

    A Comprehensive Overhaul of Multimodal Assistant with Small Language Models

    [https://arxiv.org/abs/2403.06199](https://arxiv.org/abs/2403.06199)

    通过设计多模态小语言模型(MSLMs)及提出高效多模态助手Mipha，实现了在多个方面的协同作用，击败了大语言模型，为开发强大MSLMs提供了见解和指南

    

    多模态大语言模型(MLLMs)展示了在与视觉理解和推理相关的任务中令人印象深刻的技能。然而，由于培训和推理阶段的高计算需求，它们的广泛应用面临障碍，限制了它们在研究和用户社区中受众的范围。在本文中，我们研究了多模态小语言模型（MSLMs）的设计方面，并提出了一种名为Mipha的高效多模态助手，旨在在多个方面之间创造协同作用：视觉表示、语言模型和优化策略。我们表明，在不增加训练数据量的情况下，我们的Mipha-3B在多个基准测试中胜过了最先进的大型MLLMs，特别是LLaVA-1.5-13B。通过详细讨论，我们提供了发展强大的MSLMs的见解和指南，使其能够与MLLMs的能力相媲美。我们的代码可以获得。

    arXiv:2403.06199v1 Announce Type: cross  Abstract: Multimodal Large Language Models (MLLMs) have showcased impressive skills in tasks related to visual understanding and reasoning. Yet, their widespread application faces obstacles due to the high computational demands during both the training and inference phases, restricting their use to a limited audience within the research and user communities. In this paper, we investigate the design aspects of Multimodal Small Language Models (MSLMs) and propose an efficient multimodal assistant named Mipha, which is designed to create synergy among various aspects: visual representation, language models, and optimization strategies. We show that without increasing the volume of training data, our Mipha-3B outperforms the state-of-the-art large MLLMs, especially LLaVA-1.5-13B, on multiple benchmarks. Through detailed discussion, we provide insights and guidelines for developing strong MSLMs that rival the capabilities of MLLMs. Our code is availa
    
[^64]: 大型语言模型能否自动评分写作文章的能力？

    Can Large Language Models Automatically Score Proficiency of Written Essays?

    [https://arxiv.org/abs/2403.06149](https://arxiv.org/abs/2403.06149)

    本研究旨在测试大型语言模型在分析和评分书面作文方面的能力，通过对两种流行的LLMs进行实验，设计不同提示并在ASAP数据集上进行实验，揭示了有趣的观察结果。

    

    虽然在过去50年中提出了几种方法来解决自动评分作文（AES）的问题，但在效果方面仍有许多不足之处。大型语言模型（LLMs）是基于Transformer的模型，在各种任务上展示了非凡的能力。本文测试了LLMs的能力，鉴于它们强大的语言知识，来分析和有效评分书面作文。我们对两种流行的LLMs进行了实验，分别是ChatGPT和Llama。我们旨在检查这些模型是否能够完成这项任务，以及它们在两个层面上的表现如何，即在整体上和在个体写作特征上。我们利用提示工程策略设计了四个不同的提示，以发挥它们在这项任务中的最大潜力。我们在ASAP数据集上进行的实验揭示了几个有趣的观察结果。

    arXiv:2403.06149v1 Announce Type: cross  Abstract: Although several methods were proposed to address the problem of automated essay scoring (AES) in the last 50 years, there is still much to desire in terms of effectiveness. Large Language Models (LLMs) are transformer-based models that demonstrate extraordinary capabilities on various tasks. In this paper, we test the ability of LLMs, given their powerful linguistic knowledge, to analyze and effectively score written essays. We experimented with two popular LLMs, namely ChatGPT and Llama. We aim to check if these models can do this task and, if so, how their performance is positioned among the state-of-the-art (SOTA) models across two levels, holistically and per individual writing trait. We utilized prompt-engineering tactics in designing four different prompts to bring their maximum potential to this task. Our experiments conducted on the ASAP dataset revealed several interesting observations. First, choosing the right prompt depend
    
[^65]: 基于大型语言模型与图结构理解的细粒度合成流数据用于数据稀疏性

    Fine-grainedly Synthesize Streaming Data Based On Large Language Models With Graph Structure Understanding For Data Sparsity

    [https://arxiv.org/abs/2403.06139](https://arxiv.org/abs/2403.06139)

    提出了一种细粒度合成流数据的框架，利用大型语言模型和图结构理解，将稀疏用户进行分类并生成高质量数据。

    

    由于用户数据稀疏，电子商务平台上对用户评论进行情感分析通常性能不佳，特别是在面对极度稀疏的用户数据或长尾标签时。最近，LLMs的出现通过利用图结构生成辅助用户档案，为这些问题引入了新的解决方案。然而，先前的方法并未充分利用LLMs的图理解能力，并且难以适应复杂的流数据环境。在这项工作中，我们提出了一种细粒度的流数据合成框架，将稀疏用户分类为三类：中尾、长尾和极端。具体来说，我们设计了LLMs，全面理解流数据中的三个关键图元素，包括局部-全局图理解、二阶关系提取和产品属性理解，从而实现高质量数据的生成。

    arXiv:2403.06139v1 Announce Type: cross  Abstract: Due to the sparsity of user data, sentiment analysis on user reviews in e-commerce platforms often suffers from poor performance, especially when faced with extremely sparse user data or long-tail labels. Recently, the emergence of LLMs has introduced new solutions to such problems by leveraging graph structures to generate supplementary user profiles. However, previous approaches have not fully utilized the graph understanding capabilities of LLMs and have struggled to adapt to complex streaming data environments. In this work, we propose a fine-grained streaming data synthesis framework that categorizes sparse users into three categories: Mid-tail, Long-tail, and Extreme. Specifically, we design LLMs to comprehensively understand three key graph elements in streaming data, including Local-global Graph Understanding, Second-Order Relationship Extraction, and Product Attribute Understanding, which enables the generation of high-quality
    
[^66]: FMPAF：联邦储备主席如何影响金融市场？关于他们语言的细粒度货币政策分析框架

    FMPAF: How Do Fed Chairs Affect the Financial Market? A Fine-grained Monetary Policy Analysis Framework on Their Language

    [https://arxiv.org/abs/2403.06115](https://arxiv.org/abs/2403.06115)

    FMPAF是一个新颖的方法，通过整合大型语言模型和回归分析，提供了对美联储主席新闻发布会沟通对金融市场影响的全面分析。

    

    中央银行沟通的有效性是货币政策传导的一个关键方面。尽管最近的研究已经考察了美联储主席的政策沟通对各种金融变量的影响，但大部分文献依赖于基于规则或词典的方法来解析主席的语言，导致对包含在非言语情绪中的政策立场的微妙信息缺乏分析。在当前研究中，我们提出了细粒度货币政策分析框架（FMPAF），这是一种集成大型语言模型（LLMs）与回归分析的新方法，旨在全面分析美联储主席新闻发布会沟通对金融市场的影响。我们进行了模型性能在不同细粒度、模态和沟通场景下的广泛比较。

    arXiv:2403.06115v1 Announce Type: cross  Abstract: The effectiveness of central bank communication is a crucial aspect of monetary policy transmission. While recent research has examined the influence of policy communication by the chairs of the Federal Reserve on various financial variables, much of the literature relies on rule-based or dictionary-based methods in parsing the language of the chairs, leaving nuanced information about policy stance contained in nonverbal emotion out of the analysis. In the current study, we propose the Fine-Grained Monetary Policy Analysis Framework (FMPAF), a novel approach that integrates large language models (LLMs) with regression analysis to provide a comprehensive analysis of the impact of the press-conference communications of chairs of the Federal Reserve on financial markets. We conduct extensive comparisons of model performance under different levels of granularity, modalities, and communication scenarios. Based on our preferred specification
    
[^67]: 在包含数据增强和迁移学习的细粒度情感检测数据集上使用大型语言模型

    Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning

    [https://arxiv.org/abs/2403.06108](https://arxiv.org/abs/2403.06108)

    本文研究了如何在细粒度情感检测数据集上使用大型语言模型来提高分类性能，并提出了对于文本中检测微妙情感的挑战的有价值见解。

    

    本文深入研究了如何在GoEmotions数据集上提高情感检测的分类性能，这是一个大型、手动注释的文本情感检测数据集。本文的主要目标是解决在文本中检测微妙情感的挑战，这是自然语言处理中一个复杂的问题，具有重要的实际应用。研究结果为解决文本情感检测的挑战提供了宝贵的见解，并提出了未来研究的方向，包括合成该领域各个数据集上方法和性能的综述论文的潜在性。

    arXiv:2403.06108v1 Announce Type: cross  Abstract: This paper delves into enhancing the classification performance on the GoEmotions dataset, a large, manually annotated dataset for emotion detection in text. The primary goal of this paper is to address the challenges of detecting subtle emotions in text, a complex issue in Natural Language Processing (NLP) with significant practical applications. The findings offer valuable insights into addressing the challenges of emotion detection in text and suggest directions for future research, including the potential for a survey paper that synthesizes methods and performances across various datasets in this domain.
    
[^68]: 在众包环境中利用在线学习进行基于喜好的主观评估设计优化

    Automatic design optimization of preference-based subjective evaluation with online learning in crowdsourcing environment

    [https://arxiv.org/abs/2403.06100](https://arxiv.org/abs/2403.06100)

    在众包环境中，我们提出了一种自动优化方法，利用在线学习对配对组合和评估量进行优化，实现基于喜好的主观评估的设计优化。

    

    基于喜好的主观评估是评价生成式媒体可靠性的关键方法。然而，其庞大的配对组合使得它无法应用于利用众包进行大规模评估。为了解决这个问题，我们提出了一种用于在众包环境中进行基于喜好的主观评估的自动优化方法，该方法涉及对配对组合选择和评估量分配的在线学习。我们使用基于排序算法的基于喜好的在线学习方法来识别具有最小样本量的评估目标的完全顺序。我们的在线学习算法支持在众包所需的固定预算条件下的并行和异步执行。我们对合成语音的基于喜好的主观评估实验证明了我们的方法成功通过将配对组合从351减少到83并分配最优评估。

    arXiv:2403.06100v1 Announce Type: cross  Abstract: A preference-based subjective evaluation is a key method for evaluating generative media reliably. However, its huge combinations of pairs prohibit it from being applied to large-scale evaluation using crowdsourcing. To address this issue, we propose an automatic optimization method for preference-based subjective evaluation in terms of pair combination selections and allocation of evaluation volumes with online learning in a crowdsourcing environment. We use a preference-based online learning method based on a sorting algorithm to identify the total order of evaluation targets with minimum sample volumes. Our online learning algorithm supports parallel and asynchronous execution under fixed-budget conditions required for crowdsourcing. Our experiment on preference-based subjective evaluation of synthetic speech shows that our method successfully optimizes the test by reducing pair combinations from 351 to 83 and allocating optimal eva
    
[^69]: VidProM：一个百万规模的真实即时图库数据集，用于文本到视频扩散模型

    VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion Models

    [https://arxiv.org/abs/2403.06098](https://arxiv.org/abs/2403.06098)

    VidProM是一个包含167万个独特文本到视频提示的大规模数据集，对于文本到视频扩散模型带来了新的研究进展，揭示了真实用户提示对视频生成的重要性。

    

    Sora的到来标志着文本到视频扩散模型的新时代的到来，带来了视频生成和潜在应用方面的显著进步。然而，Sora以及其他文本到视频扩散模型高度依赖提示，但目前尚没有公开可用的包含文本到视频提示研究的数据集。本文介绍了VidProM，这是第一个由167万个来自真实用户的独特文本到视频提示组成的大规模数据集。此外，该数据集包括由四种最先进的扩散模型生成的669万个视频以及一些相关数据。我们首先展示了这一大规模数据集的策展过程，这是一个耗时且昂贵的过程。随后，我们展示了所提出的VidProM与DiffusionDB之间的区别，后者是一个用于图像生成的大规模提示图库数据集。通过对这些提示的分析，我们确定了一个专门的新提示数据集的必要性。

    arXiv:2403.06098v1 Announce Type: cross  Abstract: The arrival of Sora marks a new era for text-to-video diffusion models, bringing significant advancements in video generation and potential applications. However, Sora, as well as other text-to-video diffusion models, highly relies on the prompts, and there is no publicly available dataset featuring a study of text-to-video prompts. In this paper, we introduce VidProM, the first large-scale dataset comprising 1.67 million unique text-to-video prompts from real users. Additionally, the dataset includes 6.69 million videos generated by four state-of-the-art diffusion models and some related data. We initially demonstrate the curation of this large-scale dataset, which is a time-consuming and costly process. Subsequently, we show how the proposed VidProM differs from DiffusionDB, a large-scale prompt-gallery dataset for image generation. Based on the analysis of these prompts, we identify the necessity for a new prompt dataset specificall
    
[^70]: 能否用LLM替代人工标注？ 无人机交付任务下的细粒度中文地址实体识别数据集案例研究

    Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese Address Entity Recognition Dataset for UAV Delivery

    [https://arxiv.org/abs/2403.06097](https://arxiv.org/abs/2403.06097)

    提出了适用于无人机交付系统中地址解析任务的细粒度中文姓名实体识别数据集CNER-UAV，包含五个类别的多样化数据，经过严格的数据清洗和去敏处理，约有12,000个标注样本，评估了传统的实体识别模型并提供了深入分析

    

    我们提出了CNER-UAV，一个专为无人机交付系统中地址解析任务设计的细粒度中文姓名实体识别数据集。该数据集涵盖了五个类别，可以全面训练和评估实体识别模型。为构建这一数据集，我们从真实无人机交付系统中获取数据，并进行了严格的数据清洗和去敏处理，确保数据的隐私性和完整性。最终的数据集约包含12,000个标注样本，经过人工专家和大型语言模型的注释。我们在我们的数据集上评估了传统的实体识别模型，并提供了深入分析。数据集和模型可以在 \url{https://github.com/zhhvvv/CNER-UAV} 上公开获取。

    arXiv:2403.06097v1 Announce Type: cross  Abstract: We present CNER-UAV, a fine-grained \textbf{C}hinese \textbf{N}ame \textbf{E}ntity \textbf{R}ecognition dataset specifically designed for the task of address resolution in \textbf{U}nmanned \textbf{A}erial \textbf{V}ehicle delivery systems. The dataset encompasses a diverse range of five categories, enabling comprehensive training and evaluation of NER models. To construct this dataset, we sourced the data from a real-world UAV delivery system and conducted a rigorous data cleaning and desensitization process to ensure privacy and data integrity. The resulting dataset, consisting of around 12,000 annotated samples, underwent human experts and \textbf{L}arge \textbf{L}anguage \textbf{M}odel annotation. We evaluated classical NER models on our dataset and provided in-depth analysis. The dataset and models are publicly available at \url{https://github.com/zhhvvv/CNER-UAV}.
    
[^71]: FrameQuant: Transformer的灵活低比特量化方法

    FrameQuant: Flexible Low-Bit Quantization for Transformers

    [https://arxiv.org/abs/2403.06082](https://arxiv.org/abs/2403.06082)

    提出一种简单的方案，通过融合框架将Transformer模型量化为仅两位，仅有轻微精度下降。

    

    Transformer是许多视觉和自然语言处理任务强大基础模型的支柱。然而，它们的计算和内存/存储空间占用较大，因此为这些模型提供服务往往需要昂贵的高端硬件。为了缓解这一困难，后训练量化试图修改预训练模型并将其量化为八位或更低的位数，显着提高计算/内存/延迟效率。既可以成功将这些模型量化为四位，但性能有所损失。在这项工作中，我们概述了一个简单的方案，将基于Transformer的模型量化为仅两位（加一些额外开销），仅会有轻微的精度下降。我们的制定关键在于从谐波分析中借鉴了一种称为融合框架的概念。我们的主要发现是，量化不应该在原始权重空间中进行，而是应该在融合框架表示中进行。

    arXiv:2403.06082v1 Announce Type: cross  Abstract: Transformers are the backbone of powerful foundation models for many Vision and Natural Language Processing tasks. But their compute and memory/storage footprint is large, and so, serving such models is expensive often requiring high-end hardware. To mitigate this difficulty, Post-Training Quantization seeks to modify a pre-trained model and quantize it to eight bits or lower, significantly boosting compute/memory/latency efficiency. Such models have been successfully quantized to four bits with some performance loss. In this work, we outline a simple scheme to quantize Transformer-based models to just two bits (plus some overhead) with only a small drop in accuracy. Key to our formulation is a concept borrowed from Harmonic analysis called Fusion Frames. Our main finding is that the quantization must take place not in the original weight space, but instead in the Fusion Frame representations. If quantization is interpreted as the addi
    
[^72]: L$^2$GC: 洛伦兹线性图卷积网络用于节点分类

    L$^2$GC: Lorentzian Linear Graph Convolutional Networks For Node Classification

    [https://arxiv.org/abs/2403.06064](https://arxiv.org/abs/2403.06064)

    本文提出了一种新颖的洛伦兹线性图卷积网络框架，将双曲空间引入线性GCN，用于捕捉数据的树状结构，并在实验中取得了新的最先进的节点分类结果。

    

    线性图卷积网络（GCNs）用于对图数据中的节点进行分类。然而，我们注意到大多数现有的线性GCN模型在欧几里得空间中执行神经网络操作，这并没有明确捕捉到作为图模型的现实世界数据集中呈现出的类似树状的层次结构。本文尝试将双曲空间引入线性GCN，并提出了一种新颖的洛伦兹线性GCN框架。具体来说，我们将图节点的学习特征映射到双曲空间中，然后进行洛伦兹线性特征变换，以捕获数据的潜在树状结构。在标准引文网络数据集上进行的半监督学习实验结果显示，我们的方法在Citeseer数据集上达到了74.7%的准确度，而在PubMed数据集上达到了81.3%的准确度，创造了新的最先进结果。此外，我们观察到我们的方法可以训练至少达到2个数量级。

    arXiv:2403.06064v1 Announce Type: cross  Abstract: Linear Graph Convolutional Networks (GCNs) are used to classify the node in the graph data. However, we note that most existing linear GCN models perform neural network operations in Euclidean space, which do not explicitly capture the tree-like hierarchical structure exhibited in real-world datasets that modeled as graphs. In this paper, we attempt to introduce hyperbolic space into linear GCN and propose a novel framework for Lorentzian linear GCN. Specifically, we map the learned features of graph nodes into hyperbolic space, and then perform a Lorentzian linear feature transformation to capture the underlying tree-like structure of data. Experimental results on standard citation networks datasets with semi-supervised learning show that our approach yields new state-of-the-art results of accuracy 74.7$\%$ on Citeseer and 81.3$\%$ on PubMed datasets. Furthermore, we observe that our approach can be trained up to two orders of magnitu
    
[^73]: 面向目标导向主动对话生成的目标受限双向规划

    Target-constrained Bidirectional Planning for Generation of Target-oriented Proactive Dialogue

    [https://arxiv.org/abs/2403.06063](https://arxiv.org/abs/2403.06063)

    提出了一种面向目标导向对话生成的目标受限双向规划（TRIP）方法，通过前向和后向规划生成对话路径，促进对话向预定目标发展。

    

    面向目标导向的主动对话系统旨在引导对话从对话上下文向预定目标发展，比如在指定项目上进行推荐或介绍新的特定主题。为此，对话系统关键在于计划合理的行动以主动推动对话，并同时计划适当的主题以顺利推进对话到目标话题。本文主要关注于面向目标导向对话生成的有效对话规划。受认知科学中决策理论的启发，我们提出了一种新颖的目标受限双向规划（TRIP）方法，通过前向和后向规划一个适当的对话路径。通过将规划形式化为一项生成任务，我们的TRIP双向生成了一个由一系列pair组成的对话路径，使用了两个Transformer解码器。它们被预期用于监督

    arXiv:2403.06063v1 Announce Type: cross  Abstract: Target-oriented proactive dialogue systems aim to lead conversations from a dialogue context toward a pre-determined target, such as making recommendations on designated items or introducing new specific topics. To this end, it is critical for such dialogue systems to plan reasonable actions to drive the conversation proactively, and meanwhile, to plan appropriate topics to move the conversation forward to the target topic smoothly. In this work, we mainly focus on effective dialogue planning for target-oriented dialogue generation. Inspired by decision-making theories in cognitive science, we propose a novel target-constrained bidirectional planning (TRIP) approach, which plans an appropriate dialogue path by looking ahead and looking back. By formulating the planning as a generation task, our TRIP bidirectionally generates a dialogue path consisting of a sequence of  pairs using two Transformer decoders. They are expected to supervis
    
[^74]: 集成式多语言情感分析语言模型

    Ensemble Language Models for Multilingual Sentiment Analysis

    [https://arxiv.org/abs/2403.06060](https://arxiv.org/abs/2403.06060)

    该研究针对低资源语言如阿拉伯语进行了情感分析，提出了两种集成语言模型，发现单语模型表现优越，集成模型胜过基线，而多数投票集成优于英语语言。

    

    社交媒体的快速发展使我们能够分析用户的观点。最近，情感分析在理解基于社交媒体分享内容的人类情感方面显示出明显的研究空白。尽管常用语言的情感分析已有显著进展，但像阿拉伯语这样的低资源语言由于资源有限仍然很少被研究。在本研究中，我们探讨了来自SemEval-17和阿拉伯情感推文数据集的推文文本的情感分析。此外，我们调查了四个预训练语言模型，并提出了两个集成语言模型。我们的发现包括单语模型表现出优越性能，集成模型胜过基线，而多数投票集成胜过英语语言。

    arXiv:2403.06060v1 Announce Type: new  Abstract: The rapid advancement of social media enables us to analyze user opinions. In recent times, sentiment analysis has shown a prominent research gap in understanding human sentiment based on the content shared on social media. Although sentiment analysis for commonly spoken languages has advanced significantly, low-resource languages like Arabic continue to get little research due to resource limitations. In this study, we explore sentiment analysis on tweet texts from SemEval-17 and the Arabic Sentiment Tweet dataset. Moreover, We investigated four pretrained language models and proposed two ensemble language models. Our findings include monolingual models exhibiting superior performance and ensemble models outperforming the baseline while the majority voting ensemble outperforms the English language.
    
[^75]: 波斯语俚语文本转换为正式文本以及社交媒体上波斯语短文本的深度学习用于情感分类

    Persian Slang Text Conversion to Formal and Deep Learning of Persian Short Texts on Social Media for Sentiment Classification

    [https://arxiv.org/abs/2403.06023](https://arxiv.org/abs/2403.06023)

    通过提供PSC工具将波斯语俚语文本转换为正式文本，结合深度学习方法进行波斯语短文本的情感学习。

    

    缺乏适合分析波斯语会话文本的工具使得对这些文本（包括情感分析）的各种分析变得困难。本研究尝试通过提供PSC（波斯语俚语转换器），将会话文本转换为正式文本，并结合最新和最佳的深度学习方法，使机器更容易理解这些文本，更好地进行波斯语短文本的情感学习。

    arXiv:2403.06023v1 Announce Type: new  Abstract: The lack of a suitable tool for the analysis of conversational texts in the Persian language has made various analyses of these texts, including Sentiment Analysis, difficult. In this research, we tried to make the understanding of these texts easier for the machine by providing PSC, Persian Slang Converter, a tool for converting conversational texts into formal ones, and by using the most up-to-date and best deep learning methods along with the PSC, the sentiment learning of short Persian language texts for the machine in a better way. be made More than 10 million unlabeled texts from various social networks and movie subtitles (as Conversational texts) and about 10 million news texts (as formal texts) have been used for training unsupervised models and formal implementation of the tool. 60,000 texts from the comments of Instagram social network users with positive, negative, and neutral labels are considered supervised data for trainin
    
[^76]: 少样本跨语言迁移用于在低资源语言中提示大型语言模型

    Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages

    [https://arxiv.org/abs/2403.06018](https://arxiv.org/abs/2403.06018)

    本研究评估了如何将具有70亿参数的开源PLM LLaMa 用于低资源语言的提示，解决了跨语言适应提示的问题。

    

    大型预训练语言模型（PLMs）处于自然语言处理进展的前沿。PLMs的一个广泛应用是“提示” - 或上下文学习 - 用户在提示PLM对新示例执行任务之前向PLM提供任务描述和一些完成的示例作为上下文。目前只有最大、最有能力的PLMs才能有效地执行上下文学习，而这些模型通常是通过主要以英语为语料库训练的，其他所有语言都落后。大多数语言的数据限制阻碍了训练具有提示能力的语言特定PLMs。尽管在提示设置方面的工作激增，目前仍不清楚如何将PLMs专门用于跨语言适应提示。我们评估了适应LLaMa的可能方法，LLaMa是一个主要在英语中训练的具有70亿参数的开源PLM，用于在低资源语言中进行提示。

    arXiv:2403.06018v1 Announce Type: cross  Abstract: Large pre-trained language models (PLMs) are at the forefront of advances in Natural Language Processing. One widespread use case of PLMs is "prompting" - or in-context learning - where a user provides a description of a task and some completed examples of the task to a PLM as context before prompting the PLM to perform the task on a new example. Only the largest, most capable PLMs are able to perform in-context learning effectively, and these models are typically trained with a predominantly English corpus, leaving all other languages behind. The data limitations in most languages preclude the training of language-specific PLMs capable of prompting. Albeit the surge in work of prompting settings, it is still unclear how PLMs should be adapted cross-lingually specifically for prompting. We evaluate the possible methods to adapt LLaMa, a 7B parameter open-source PLM mainly trained in English, for prompting in low-resource languages, nam
    
[^77]: 针对链接开放数据查询日志分析的端到端解决方案

    End-to-end solution for linked open data query logs analytics

    [https://arxiv.org/abs/2403.06016](https://arxiv.org/abs/2403.06016)

    通过提供一个端到端的解决方案，本研究针对链接开放数据查询日志的复杂结构和质量问题，为从中提取有价值信息提供了一种途径。

    

    从利用查询日志中获取的对用户兴趣和偏好的深刻理解，推动了支柱领域的重要进展。深入了解用户提供了有用的知识，可以对决策产生强烈影响。本研究旨在从链接开放数据（LOD）查询日志中提取有价值的信息。LOD日志由于对LOD数据集的大规模利用而经历了显著增长。然而，利用这些日志是一项艰巨的任务，因为它们具有复杂的结构。此外，这些日志遭受与它们的质量和来源相关的许多风险，影响了它们的可信度。为解决这些问题，我们首先清晰定义了LOD查询日志的生态系统。然后，我们提供了一个端到端的解决方案来利用这些日志。最后，使用真实的LOD日志，并进行了一系列实验来验证所提出的解决方案。

    arXiv:2403.06016v1 Announce Type: cross  Abstract: Important advances in pillar domains are derived from exploiting query-logs which represents users interest and preferences. Deep understanding of users provides useful knowledge which can influence strongly decision-making. In this work, we want to extract valuable information from Linked Open Data (LOD) query-logs. LOD logs have experienced significant growth due to the large exploitation of LOD datasets. However, exploiting these logs is a difficult task because of their complex structure. Moreover, these logs suffer from many risks related to their Quality and Provenance, impacting their trust. To tackle these issues, we start by clearly defining the ecosystem of LOD query-logs. Then, we provide an end-to-end solution to exploit these logs. At the end, real LOD logs are used and a set of experiments are conducted to validate the proposed solution.
    
[^78]: 使用增强型字典胶囊的自动语言预测 -- 一种新颖方法

    Enhanced Auto Language Prediction with Dictionary Capsule -- A Novel Approach

    [https://arxiv.org/abs/2403.05982](https://arxiv.org/abs/2403.05982)

    该研究提出了一种使用增强型字典胶囊的自动语言预测框架，结合神经网络和符号表示，实现了多语言翻译准确性方面的重大改进，适用于多语言交流和自然语言处理任务。

    

    本文提出了一种新颖的自动语言预测字典胶囊（ALPDC）框架，用于语言预测和机器翻译。该模型使用神经网络和符号表示的组合来预测给定输入文本的语言，然后利用预先构建的字典将其翻译为目标语言。该研究还旨在将各种语言的文本翻译成英文的字面意思。所提出的模型在多个基准数据集上取得了最先进的结果，并与现有方法相比显著提高了翻译准确性。结果显示了所提出的方法在多语言交流和自然语言处理任务中的实际应用潜力。

    arXiv:2403.05982v1 Announce Type: new  Abstract: The paper presents a novel Auto Language Prediction Dictionary Capsule (ALPDC) framework for language prediction and machine translation. The model uses a combination of neural networks and symbolic representations to predict the language of a given input text and then translate it to a target language using pre-built dictionaries. This research work also aims to translate the text of various languages to its literal meaning in English. The proposed model achieves state-of-the-art results on several benchmark datasets and significantly improves translation accuracy compared to existing methods. The results show the potential of the proposed method for practical use in multilingual communication and natural language processing tasks.
    
[^79]: 使用基于术语表示的方法评估排名列表中的偏见

    Measuring Bias in a Ranked List using Term-based Representations

    [https://arxiv.org/abs/2403.05975](https://arxiv.org/abs/2403.05975)

    本文提出了一种新的指标TExFAIR，基于术语表示群体在排名列表中的公平性，通过两个新的扩展来解决现有偏见度量方法的局限性。

    

    在最近的研究中，性别偏见在文档排名中使用NFaiRR指标进行评估，该指标根据每个排名文档的无偏分数的聚合来衡量排名列表中的偏见。然而，这种衡量排名列表偏见的观点存在一个重要局限性：排名列表中的个别文档可能存在偏见，而整个排名列表却能平衡各个群体的表示。为了解决这个问题，我们提出了一种称为TExFAIR（基于术语曝光的公平性）的新指标，它基于通用公平性评估框架——注意力加权排名公平性（AWRF）的两个新扩展。TExFAIR根据排名列表中群体的基于术语的表示来评估公平性：（i）通过基于概率术语级关联来明确地将文档与群体关联起来的定义，以及（ii）用于计算对衡量产生偏差的因素的排名偏差折扣因子（RBDF）。

    arXiv:2403.05975v1 Announce Type: new  Abstract: In most recent studies, gender bias in document ranking is evaluated with the NFaiRR metric, which measures bias in a ranked list based on an aggregation over the unbiasedness scores of each ranked document. This perspective in measuring the bias of a ranked list has a key limitation: individual documents of a ranked list might be biased while the ranked list as a whole balances the groups' representations. To address this issue, we propose a novel metric called TExFAIR (term exposure-based fairness), which is based on two new extensions to a generic fairness evaluation framework, attention-weighted ranking fairness (AWRF). TExFAIR assesses fairness based on the term-based representation of groups in a ranked list: (i) an explicit definition of associating documents to groups based on probabilistic term-level associations, and (ii) a rank-biased discounting factor (RBDF) for counting non-representative documents towards the measurement o
    
[^80]: 仅使用生成来校准大型语言模型

    Calibrating Large Language Models Using Their Generations Only

    [https://arxiv.org/abs/2403.05973](https://arxiv.org/abs/2403.05973)

    使用APRICOT方法，通过仅使用大型语言模型的文本输入和输出来设置置信目标并训练额外模型，从而实现大型语言模型的校准。

    

    随着大型语言模型（LLMs）越来越多地部署在面向用户的应用程序中，通过准确量化模型对其预测的信心来建立信任并保持安全性变得更加重要。然而，找到有效的方法来校准LLMs - 尤其是当与模型的唯一接口是它们生成的文本时 - 仍然是一个挑战。我们提出了APRICOT（辅助预测置信目标）：一种通过仅使用其文本输入和输出来设置置信目标并训练一个额外模型来预测LLM置信度的方法。这种方法有几个优点：概念上简单，不需要访问目标模型超出其输出，不干扰语言生成，并且有多种潜在用途，例如通过言语化预测的置信度或根据置信度调整给定的答案。我们展示了我们的方法如何具有竞争性能。

    arXiv:2403.05973v1 Announce Type: cross  Abstract: As large language models (LLMs) are increasingly deployed in user-facing applications, building trust and maintaining safety by accurately quantifying a model's confidence in its prediction becomes even more important. However, finding effective ways to calibrate LLMs - especially when the only interface to the models is their generated text - remains a challenge. We propose APRICOT (auxiliary prediction of confidence targets): A method to set confidence targets and train an additional model that predicts an LLM's confidence based on its textual input and output alone. This approach has several advantages: It is conceptually simple, does not require access to the target model beyond its output, does not interfere with the language generation, and has a multitude of potential usages, for instance by verbalizing the predicted confidence or adjusting the given answer based on the confidence. We show how our approach performs competitively
    
[^81]: 使用优化提示的Transformer进行线程检测和响应生成

    Thread Detection and Response Generation using Transformers with Prompt Optimisation

    [https://arxiv.org/abs/2403.05931](https://arxiv.org/abs/2403.05931)

    通过优化提示，该研究提出了一种端到端模型，能够识别对话中的线程并基于其重要性优先生成响应。

    

    Conversational systems 对于人机交互至关重要，通过识别线程并优先响应来管理复杂对话。 在多方对话中尤为重要，其中线程的准确识别和策略性响应优先级确保高效对话管理。 为了解决这些挑战，开发了一种端到端模型，根据重要性识别线程并优先生成其响应，涉及将问题系统地分解为离散组件 - 线程检测、优先级和性能优化，并对其进行精心分析和优化。 这些精细的组件无缝集成到统一框架中，在会话系统中。 由于其高通用性，Llama2 7b被用于，该系统可以使用任何开源大型语言模型(LLM) 进行更新。 Llama2 模型的计算能力得到增强

    arXiv:2403.05931v1 Announce Type: new  Abstract: Conversational systems are crucial for human-computer interaction, managing complex dialogues by identifying threads and prioritising responses. This is especially vital in multi-party conversations, where precise identification of threads and strategic response prioritisation ensure efficient dialogue management. To address these challenges an end-to-end model that identifies threads and prioritises their response generation based on the importance was developed, involving a systematic decomposition of the problem into discrete components - thread detection, prioritisation, and performance optimisation which was meticulously analysed and optimised. These refined components seamlessly integrate into a unified framework, in conversational systems. Llama2 7b is used due to its high level of generalisation but the system can be updated with any open source Large Language Model(LLM). The computational capabilities of the Llama2 model was aug
    
[^82]: 基于大语言模型和混合NLP模型的医师笔记高吞吐量表型识别

    High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models

    [https://arxiv.org/abs/2403.05920](https://arxiv.org/abs/2403.05920)

    大语言模型和混合NLP模型的结合可在高准确率下对医师笔记进行高吞吐量表型识别，有望成为未来首选方法。

    

    深度表型是利用本体论中的概念对患者体征和症状进行详细描述。电子健康记录中大量医师笔记的深度表型需要高吞吐量的方法。在过去的三十年里，取得了使高吞吐量表型成为可能的进展。在这项研究中，我们证明了一个大型语言模型和一个混合NLP模型（结合了词向量和机器学习分类器）可以在高准确率下对医师笔记进行高吞吐量表型识别。大型语言模型很可能会成为医师笔记高吞吐量深度表型识别的首选方法。

    arXiv:2403.05920v1 Announce Type: cross  Abstract: Deep phenotyping is the detailed description of patient signs and symptoms using concepts from an ontology. The deep phenotyping of the numerous physician notes in electronic health records requires high throughput methods. Over the past thirty years, progress toward making high throughput phenotyping feasible. In this study, we demonstrate that a large language model and a hybrid NLP model (combining word vectors with a machine learning classifier) can perform high throughput phenotyping on physician notes with high accuracy. Large language models will likely emerge as the preferred method for high throughput deep phenotyping of physician notes.
    
[^83]: MaiBaam注释准则

    MaiBaam Annotation Guidelines

    [https://arxiv.org/abs/2403.05902](https://arxiv.org/abs/2403.05902)

    该论文提供了MaiBaam语料库的注释准则，详细介绍了如何处理和标记巴伐利亚数据，说明了词性标记和依赖关系的使用，以及对德语等相关语言适用的注释决策和对巴伐利亚语法特定决策的介绍和推动。

    

    本文提供了MaiBaam的注释准则，这是一个注释了词性标记和句法依赖关系的巴伐利亚语语料库。MaiBaam属于通用依存关系项目（UD），我们的注释详细说明了一般和德国UD第2版指南。在本文中，我们详细介绍了如何预处理和标记巴伐利亚数据，概述了我们使用的词性标记和依赖关系，解释了也适用于德语等密切相关语言的注释决策，最后介绍并推动了适用于巴伐利亚语法的决策。

    arXiv:2403.05902v1 Announce Type: new  Abstract: This document provides the annotation guidelines for MaiBaam, a Bavarian corpus annotated with part-of-speech (POS) tags and syntactic dependencies. MaiBaam belongs to the Universal Dependencies (UD) project, and our annotations elaborate on the general and German UD version 2 guidelines. In this document, we detail how to preprocess and tokenize Bavarian data, provide an overview of the POS tags and dependencies we use, explain annotation decisions that would also apply to closely related languages like German, and lastly we introduce and motivate decisions that are specific to Bavarian grammar.
    
[^84]: KG-Rank: 利用知识图谱和排名技术增强医学问答的大型语言模型

    KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge Graphs and Ranking Techniques

    [https://arxiv.org/abs/2403.05881](https://arxiv.org/abs/2403.05881)

    本研究开发了KG-Rank框架，利用医学知识图谱和排名技术，旨在提高医学领域自由文本问答的准确性。

    

    大型语言模型（LLMs）显著推进了医疗保健创新的生成能力。然而，由于可能偏离医疗事实和固有偏见，它们在实际临床设置中的应用具有挑战性。在这项工作中，我们开发了一个增强型LLM框架KG-Rank，利用医学知识图谱（KG）与排名和重新排名技术，旨在改进医学领域自由文本问答（QA）。具体来说，在收到问题后，我们首先从医学KG中检索三元组以收集事实信息。随后，我们创新性地应用排名方法来精细调整这些三元组的顺序，旨在产生更精确的答案。据我们所知，KG-Rank是首个将排名模型与KG结合在一起，专门用于生成长答案的医学问答应用。对四个选定的医学问答数据集的评估显示，KG-Rank实现了

    arXiv:2403.05881v1 Announce Type: new  Abstract: Large Language Models (LLMs) have significantly advanced healthcare innovation on generation capabilities. However, their application in real clinical settings is challenging due to potential deviations from medical facts and inherent biases. In this work, we develop an augmented LLM framework, KG-Rank, which leverages a medical knowledge graph (KG) with ranking and re-ranking techniques, aiming to improve free-text question-answering (QA) in the medical domain. Specifically, upon receiving a question, we initially retrieve triplets from a medical KG to gather factual information. Subsequently, we innovatively apply ranking methods to refine the ordering of these triplets, aiming to yield more precise answers. To the best of our knowledge, KG-Rank is the first application of ranking models combined with KG in medical QA specifically for generating long answers. Evaluation of four selected medical QA datasets shows that KG-Rank achieves a
    
[^85]: 扩散镜头：解释文本编码器在文本到图像管道中的作用

    Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines

    [https://arxiv.org/abs/2403.05846](https://arxiv.org/abs/2403.05846)

    提出了一种分析文本到图像模型中文本编码器的方法，并通过生成中间表示的图像来深入研究，揭示了在复合提示和知识检索方面的一些重要发现。

    

    arXiv:2403.05846v1 通告类型：跨 存在文本到图像扩散模型（T2I）使用文本提示的潜在表示来引导图像生成过程。然而，编码器产生文本表示的过程是未知的。我们提出了扩散镜头，一种分析 T2I 模型文本编码器的方法，通过生成其中间表示的图像。使用扩散镜头，我们对两个最近的 T2I 模型进行了广泛分析。在探索复合提示时，我们发现描述多个对象的复杂场景相对于简单场景是逐步且较慢地构建的；在探索知识检索时，我们发现表示不常见概念需要比常见概念更多的计算，并且知识检索在层之间是渐进的。总体而言，我们的发现为 T2I 管道中的文本编码器组件提供了宝贵的见解。

    arXiv:2403.05846v1 Announce Type: cross  Abstract: Text-to-image diffusion models (T2I) use a latent representation of a text prompt to guide the image generation process. However, the process by which the encoder produces the text representation is unknown. We propose the Diffusion Lens, a method for analyzing the text encoder of T2I models by generating images from its intermediate representations. Using the Diffusion Lens, we perform an extensive analysis of two recent T2I models. Exploring compound prompts, we find that complex scenes describing multiple objects are composed progressively and more slowly compared to simple scenes; Exploring knowledge retrieval, we find that representation of uncommon concepts requires further computation compared to common concepts, and that knowledge retrieval is gradual across layers. Overall, our findings provide valuable insights into the text encoder component in T2I pipelines.
    
[^86]: 数字反转！算术学习中顺序解码很重要

    Reverse That Number! Decoding Order Matters in Arithmetic Learning

    [https://arxiv.org/abs/2403.05845](https://arxiv.org/abs/2403.05845)

    本研究提出了一种新颖的算术学习策略，重点考虑最低有效数字的输出，重新评估数字顺序，并结合逐步方法大幅减少了复杂性，从而取得了比之前方法更好的性能提升。

    

    最近预训练的最新进展表明，现代大型语言模型（LLMs）具有有效学习算术操作的能力。然而，尽管承认数字顺序在算术计算中的重要性，但目前的方法主要依赖于顺序、逐步的方法来教授LLMs算术，导致结论是获得更好的性能涉及到精细的逐步操作。与传统路径不同，我们的工作引入了一种新颖的策略，不仅通过优先考虑从最低有效数字输出来重新评估数字顺序，还结合逐步方法大幅减少了复杂性。我们已经在全面的一系列实验中开发并应用了这种方法。与先前的最先进（SOTA）方法相比，我们的研究结果显示总体准确度的提高，同时仅需要三分之一的复杂度。

    arXiv:2403.05845v1 Announce Type: cross  Abstract: Recent advancements in pretraining have demonstrated that modern Large Language Models (LLMs) possess the capability to effectively learn arithmetic operations. However, despite acknowledging the significance of digit order in arithmetic computation, current methodologies predominantly rely on sequential, step-by-step approaches for teaching LLMs arithmetic, resulting in a conclusion where obtaining better performance involves fine-grained step-by-step. Diverging from this conventional path, our work introduces a novel strategy that not only reevaluates the digit order by prioritizing output from the least significant digit but also incorporates a step-by-step methodology to substantially reduce complexity. We have developed and applied this method in a comprehensive set of experiments. Compared to the previous state-of-the-art (SOTA) method, our findings reveal an overall improvement of in accuracy while requiring only a third of the 
    
[^87]: 一种音频文本扩散模型用于将语音信号转换为超声舌头成像数据

    An Audio-textual Diffusion Model For Converting Speech Signals Into Ultrasound Tongue Imaging Data

    [https://arxiv.org/abs/2403.05820](https://arxiv.org/abs/2403.05820)

    提出一种音频文本扩散模型，通过编码个体特征和通用模式，生成高质量超声舌头成像数据，用于语言分析和临床评估。

    

    声音到语音逆变换（AAI）旨在将音频转换为发音器官运动，如超声舌头成像（UTI）数据。现有AAI方法的一个问题是仅使用个性化音频信息来推导舌头运动的一般模式，因此生成的UTI数据质量有限。为解决这一问题，本文提出了一种用于UTI数据生成任务的音频文本扩散模型。在该模型中，使用wav2vec 2.0对个体相关的舌头运动细节进行编码，而使用BERT对与舌头运动普遍性相关的ASR转录进行编码。然后通过扩散模块生成UTI数据。实验结果表明，所提出的扩散模型能够生成具有清晰舌头轮廓的高质量UTI数据，这对语言分析和临床评估至关重要。

    arXiv:2403.05820v1 Announce Type: cross  Abstract: Acoustic-to-articulatory inversion (AAI) is to convert audio into articulator movements, such as ultrasound tongue imaging (UTI) data. An issue of existing AAI methods is only using the personalized acoustic information to derive the general patterns of tongue motions, and thus the quality of generated UTI data is limited. To address this issue, this paper proposes an audio-textual diffusion model for the UTI data generation task. In this model, the inherent acoustic characteristics of individuals related to the tongue motion details are encoded by using wav2vec 2.0, while the ASR transcriptions related to the universality of tongue motions are encoded by using BERT. UTI data are then generated by using a diffusion module. Experimental results showed that the proposed diffusion model could generate high-quality UTI data with clear tongue contour that is crucial for the linguistic analysis and clinical assessment. The project can be fou
    
[^88]: MP2D:一种利用知识图谱的自动话题转移对话生成框架

    MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs

    [https://arxiv.org/abs/2403.05814](https://arxiv.org/abs/2403.05814)

    提出了一种利用知识图谱的自动化对话生成框架MP2D，通过映射对话中话题的流动，有效地模拟了人类对话的动态，展示了其在生成具有自然话题转换的对话方面的有效性。

    

    尽管面向特定话题的对话系统取得了进展，但在对话中有效地管理话题转移仍然是一个持续的挑战，这在很大程度上归因于训练数据集的有限可用性。为了解决这个问题，我们提出了Multi-Passage to Dialogue (MP2D)，这是一个数据生成框架，可以自动创建具有自然话题转换的对话问答数据集。通过利用知识图谱中实体之间的关系，MP2D映射对话中话题的流动，有效地模拟人类对话的动态。它检索与话题对应的相关段落，并通过段落到对话的方法将它们转换为对话。通过定量和定性实验，我们展示了MP2D在生成具有自然话题转换的对话方面的有效性。此外，本研究介绍了一个新颖的话题转移对话基准，TS-WikiDialog。利用t

    arXiv:2403.05814v1 Announce Type: cross  Abstract: Despite advancements in on-topic dialogue systems, effectively managing topic shifts within dialogues remains a persistent challenge, largely attributed to the limited availability of training datasets. To address this issue, we propose Multi-Passage to Dialogue (MP2D), a data generation framework that automatically creates conversational question-answering datasets with natural topic transitions. By leveraging the relationships between entities in a knowledge graph, MP2D maps the flow of topics within a dialogue, effectively mirroring the dynamics of human conversation. It retrieves relevant passages corresponding to the topics and transforms them into dialogues through the passage-to-dialogue method. Through quantitative and qualitative experiments, we demonstrate MP2D's efficacy in generating dialogue with natural topic shifts. Furthermore, this study introduces a novel benchmark for topic shift dialogues, TS-WikiDialog. Utilizing t
    
[^89]: 语言模型中算法进展的研究

    Algorithmic progress in language models

    [https://arxiv.org/abs/2403.05812](https://arxiv.org/abs/2403.05812)

    研究发现，语言模型预训练算法每8个月几乎减半一次所需的计算需求，大大快于摩尔定律的硬件增益，尽管算法进展速度快，但计算能力的增加对整体性能改善的贡献更大。

    

    我们调查了自深度学习问世以来，用于预训练语言模型的算法改善速度。使用跨越2012年至2023年的Wikitext和Penn Treebank上的200多个语言模型评估数据集，我们发现达到一定性能阈值所需的计算时间大约每8个月减半，95%的置信区间约为5至14个月，远远快于摩尔定律的硬件增益。我们估计了增强扩展规律，这使我们能够量化算法进展，并确定模型扩展与训练算法创新的相对贡献。尽管算法进展速度快，且出现新的架构如Transformer，但我们的分析显示在这段时间内，计算能力的增加对整体性能改善的贡献更大。尽管受到嘈杂的基准数据的限制，我们的分析表明算法的进展对语言模型的性能的增长有显著影响。

    arXiv:2403.05812v1 Announce Type: cross  Abstract: We investigate the rate at which algorithms for pre-training language models have improved since the advent of deep learning. Using a dataset of over 200 language model evaluations on Wikitext and Penn Treebank spanning 2012-2023, we find that the compute required to reach a set performance threshold has halved approximately every 8 months, with a 95% confidence interval of around 5 to 14 months, substantially faster than hardware gains per Moore's Law. We estimate augmented scaling laws, which enable us to quantify algorithmic progress and determine the relative contributions of scaling models versus innovations in training algorithms. Despite the rapid pace of algorithmic progress and the development of new architectures such as the transformer, our analysis reveals that the increase in compute made an even larger contribution to overall performance improvements over this time period. Though limited by noisy benchmark data, our analy
    
[^90]: UniSparse：一种用于通用稀疏格式定制的中间语言

    UniSparse: An Intermediate Language for General Sparse Format Customization

    [https://arxiv.org/abs/2403.05802](https://arxiv.org/abs/2403.05802)

    UniSparse提出了一种中间语言，用于统一抽象和定制稀疏格式，提供了更灵活的方式支持新的自定义稀疏数据结构和布局变体

    

    硬件专门化的持续趋势导致在处理稀疏工作量时越来越多地使用自定义数据格式，这些工作量通常受限于内存。这些格式通过利用稀疏模式或面向目标的数据结构和布局来优化软硬件实现，以增强内存访问延迟和带宽利用率。然而，现有的稀疏张量编程模型和编译器很少或根本不支持有效定制稀疏格式。此外，由于这些框架使用有限的每个维度属性集表示格式，它们缺乏灵活性，无法适应大量新的自定义稀疏数据结构和布局变体。为了克服这一不足，我们提出了UniSparse，一种提供统一抽象以表示和定制稀疏格式的中间语言。与现有的基于属性的框架不同，UniSparse解耦

    arXiv:2403.05802v1 Announce Type: new  Abstract: The ongoing trend of hardware specialization has led to a growing use of custom data formats when processing sparse workloads, which are typically memory-bound. These formats facilitate optimized software/hardware implementations by utilizing sparsity pattern- or target-aware data structures and layouts to enhance memory access latency and bandwidth utilization. However, existing sparse tensor programming models and compilers offer little or no support for productively customizing the sparse formats. Additionally, because these frameworks represent formats using a limited set of per-dimension attributes, they lack the flexibility to accommodate numerous new variations of custom sparse data structures and layouts. To overcome this deficiency, we propose UniSparse, an intermediate language that provides a unified abstraction for representing and customizing sparse formats. Unlike the existing attribute-based frameworks, UniSparse decouples
    
[^91]: ClinicalMamba：基于纵向临床记录的生成型临床语言模型

    ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes

    [https://arxiv.org/abs/2403.05795](https://arxiv.org/abs/2403.05795)

    ClinicalMamba是基于纵向临床记录的生成型临床语言模型，具有130亿和28亿参数，相对于Mamba和临床Llama，在建模较长文本时表现出更优异的性能。

    

    在医疗保健领域，自然语言处理（NLP）系统的进步取决于语言模型解释临床笔记中包含的复杂信息的能力。本研究引入了ClinicalMamba，这是Mamba语言模型的专门版本，它在大量纵向临床记录语料库上进行了预训练，以解决医学领域的独特语言特征和信息处理需求。

    arXiv:2403.05795v1 Announce Type: new  Abstract: The advancement of natural language processing (NLP) systems in healthcare hinges on language model ability to interpret the intricate information contained within clinical notes. This process often requires integrating information from various time points in a patient's medical history. However, most earlier clinical language models were pretrained with a context length limited to roughly one clinical document. In this study, We introduce ClinicalMamba, a specialized version of the Mamba language model, pretrained on a vast corpus of longitudinal clinical notes to address the unique linguistic characteristics and information processing needs of the medical domain. ClinicalMamba, with 130 million and 2.8 billion parameters, demonstrates a superior performance in modeling clinical language across extended text lengths compared to Mamba and clinical Llama. With few-shot learning, ClinicalMamba achieves notable benchmarks in speed and accur
    
[^92]: ItD：大型语言模型可以通过演绎自学归纳

    ItD: Large Language Models Can Teach Themselves Induction through Deduction

    [https://arxiv.org/abs/2403.05789](https://arxiv.org/abs/2403.05789)

    提出了演绎通过归纳（ItD）框架，使大型语言模型能够通过演绎自学归纳，显著提升了归纳任务的性能。

    

    虽然大型语言模型（LLMs）在各种自然语言处理任务上表现出色，研究人员发现它们在进行归纳推理方面的能力仍然有限。最近的作品主要采用“后处理”范式来提高LLMs在归纳方面的表现（如假设搜索和细化方法），但它们的性能仍受限于LLMs的固有归纳能力。本文提出了一个新颖的框架，即演绎通过归纳（ItD），以使LLMs能够通过演绎自学归纳。ItD框架由两个主要组件组成：演绎数据生成模块用于生成归纳数据，以及朴素贝叶斯归纳模块用于优化LLMs的微调和解码。我们的实证结果展示了ItD在两个归纳基准上的有效性，相对性能提升分别为36%和1%。

    arXiv:2403.05789v1 Announce Type: cross  Abstract: Although Large Language Models (LLMs) are showing impressive performance on a wide range of Natural Language Processing tasks, researchers have found that they still have limited ability to conduct induction. Recent works mainly adopt ``post processes'' paradigms to improve the performance of LLMs on induction (e.g., the hypothesis search & refinement methods), but their performance is still constrained by the inherent inductive capability of the LLMs. In this paper, we propose a novel framework, Induction through Deduction (ItD), to enable the LLMs to teach themselves induction through deduction. The ItD framework is composed of two main components: a Deductive Data Generation module to generate induction data and a Naive Bayesian Induction module to optimize the fine-tuning and decoding of LLMs. Our empirical results showcase the effectiveness of ItD on two induction benchmarks, achieving relative performance improvement of 36% and 1
    
[^93]: 对细粒度损失截断效益的研究：以摘要中的事实性为例

    On the Benefits of Fine-Grained Loss Truncation: A Case Study on Factuality in Summarization

    [https://arxiv.org/abs/2403.05788](https://arxiv.org/abs/2403.05788)

    通过细粒度NLL损失和fi以更好地区分事实性，改进了细粒度损失截断对于摘要中事实性的影响。

    

    arXiv:2403.05788v1 公告类型：跨项 摘要：文本摘要和简化是人工智能中最广泛使用的应用之一。然而，针对这些任务开发的模型往往容易出现幻觉，这可能是因为在未对齐数据上进行训练。解决这一问题的一种有效方法是损失截断（LT）（Kang和Hashimoto，2020），这是一种修改标准对数损失以在训练过程中自适应地去除嘈杂示例的方法。然而，我们发现仅使用LT在各种数据集上会产生大量幻觉实体。我们研究了事实和非事实示例之间基础损失的行为，以了解并改进LT的性能。我们证明了当嘈杂目标具有较高NLL损失的基础假设不被满足时，LT的性能是有限的，并发现实体之间的单词级NLL为区分事实性提供了更好的信号。然后我们利用这一点提出了一种细粒度NLL损失和fi

    arXiv:2403.05788v1 Announce Type: cross  Abstract: Text summarization and simplification are among the most widely used applications of AI. However, models developed for such tasks are often prone to hallucination, which can result from training on unaligned data. One efficient approach to address this issue is Loss Truncation (LT) (Kang and Hashimoto, 2020), an approach to modify the standard log loss to adaptively remove noisy examples during training. However, we find that LT alone yields a considerable number of hallucinated entities on various datasets. We study the behavior of the underlying losses between factual and non-factual examples, to understand and refine the performance of LT. We demonstrate that LT's performance is limited when the underlying assumption that noisy targets have higher NLL loss is not satisfied, and find that word-level NLL among entities provides better signal for distinguishing factuality. We then leverage this to propose a fine-grained NLL loss and fi
    
[^94]: 将激活导向扩展到广泛技能与多种行为

    Extending Activation Steering to Broad Skills and Multiple Behaviours

    [https://arxiv.org/abs/2403.05767](https://arxiv.org/abs/2403.05767)

    本文研究了将激活导向技术应用于广泛技能和多种行为的功效，并发现导向广泛技能具有竞争力，同时在模型中同时注入个体导向向量是一种有前途的方法。

    

    当前大型语言模型具有危险的能力，这很可能在未来变得更加棘手。激活导向技术可用于减少这些能力带来的风险。本文研究了激活导向在广泛技能和多种行为中的功效。通过比较减少对一般编码能力和Python特定能力表现的影响，我们发现导向更广泛技能与导向较窄技能竞争激烈。其次，我们引导模型变得更加或更少近视和寻求财富，以及其他行为。在实验中，将多种不同行为的导向向量组合为一个导向向量通常不成功。另一方面，同时在模型中不同位置注入个体导向向量是有前途的。

    arXiv:2403.05767v1 Announce Type: cross  Abstract: Current large language models have dangerous capabilities, which are likely to become more problematic in the future. Activation steering techniques can be used to reduce risks from these capabilities. In this paper, we investigate the efficacy of activation steering for broad skills and multiple behaviours. First, by comparing the effects of reducing performance on general coding ability and Python-specific ability, we find that steering broader skills is competitive to steering narrower skills. Second, we steer models to become more or less myopic and wealth-seeking, among other behaviours. In our experiments, combining steering vectors for multiple different behaviours into one steering vector is largely unsuccessful. On the other hand, injecting individual steering vectors at different places in a model simultaneously is promising.
    
[^95]: FLAP: 在LLMs中具有受限解码的流程遵循规划

    FLAP: Flow Adhering Planning with Constrained Decoding in LLMs

    [https://arxiv.org/abs/2403.05766](https://arxiv.org/abs/2403.05766)

    本文研究了在任务导向对话中通过遵循预定义流程和保留API依赖性解决用户意图的忠实规划，提出了一种基于前瞻启发式的受限解码算法。

    

    计划对于任务导向对话中的代理人是至关重要的任务。人类代理人通常通过遵循预定义的工作流程解决用户问题，将工作流程步骤分解为可操作项目，并通过执行API执行操作；所有这些都需要推理和规划。鉴于LLMs的最新进展，人们越来越多地尝试使用LLMs进行任务规划和API使用。然而，由于LLMs偏向预训练数据，计划与预定义工作流程和API依赖性的忠实性并不被保证。此外，在现实生活中，工作流程是自定义的并且容易更改，因此，快速使代理人适应变化是可取的。在本文中，我们研究了在任务导向对话中通过遵循预定义流程和保留API依赖性解决用户意图的忠实规划。我们提出了一种基于前瞻启发式的受限解码算法用于忠实规划。

    arXiv:2403.05766v1 Announce Type: new  Abstract: Planning is a crucial task for agents in task oriented dialogs (TODs). Human agents typically resolve user issues by following predefined workflows, decomposing workflow steps into actionable items, and performing actions by executing APIs in order; all of which require reasoning and planning. With the recent advances in LLMs, there have been increasing attempts to use LLMs for task planning and API usage. However, the faithfulness of the plans to predefined workflows and API dependencies, is not guaranteed with LLMs because of their bias towards pretraining data. Moreover, in real life, workflows are custom-defined and prone to change, hence, quickly adapting agents to the changes is desirable. In this paper, we study faithful planning in TODs to resolve user intents by following predefined flows and preserving API dependencies. We propose a constrained decoding algorithm based on lookahead heuristic for faithful planning. Our algorithm
    
[^96]: 解读AI笔: 检测AI生成文本的技术与挑战

    Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text

    [https://arxiv.org/abs/2403.05750](https://arxiv.org/abs/2403.05750)

    大型语言模型在自然语言生成领域取得了重大突破，提出了识别AI生成文本的解决方案，并探索了未来研究方向。

    

    大型语言模型(LLMs)通过展示生成类人文本的惊人能力，彻底颠覆了自然语言生成(NLG)领域。然而，它们广泛的应用带来挑战，需要深入审查、伦理审查和负责任的实践。本研究探讨了这些挑战，探索了现有的缓解策略，重点是识别AI生成文本作为最终解决方案。此外，我们从理论角度评估了检测的可行性，并提出了解决当前领域限制的新颖研究方向。

    arXiv:2403.05750v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized the field of Natural Language Generation (NLG) by demonstrating an impressive ability to generate human-like text. However, their widespread usage introduces challenges that necessitate thoughtful examination, ethical scrutiny, and responsible practices. In this study, we delve into these challenges, explore existing strategies for mitigating them, with a particular emphasis on identifying AI-generated text as the ultimate solution. Additionally, we assess the feasibility of detection from a theoretical perspective and propose novel research directions to address the current limitations in this domain.
    
[^97]: 用于生成简要住院病程摘要的领域自适应大语言模型的基准测试

    A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries

    [https://arxiv.org/abs/2403.05720](https://arxiv.org/abs/2403.05720)

    介绍了一个新的基准测试，评估了用于生成简要住院病程摘要的大语言模型在健康保健领域中的性能并提出相应的自适应策略

    

    简要住院病程（BHC）摘要是通过总结临床记录而生成的常见临床文件。虽然大型语言模型（LLMs）在自动化实际任务方面展现出显著能力，但它们在医疗应用（如BHC合成）中的能力尚未得到展示。为了使LLMs能够适应BHC合成，我们引入了一个新颖的基准测试，其中包含从MIMIC-IV记录中提取的经过预处理的数据集，封装了临床记录和简要住院病程（BHC）对。我们评估了两个通用LLMs和三个医疗领域适应的LLMs的性能，以改进从临床记录生成BHC。我们使用临床记录作为输入来生成BHC，采用基于提示的（使用上下文学习）和基于微调的自适应策略来应用于三个开源LLMs（Clinical-T5-Large，Llama2-13B，FLAN-UL2）和两个专有LLMs（GPT-3.5，GPT-4）。我们定量评估了性能。

    arXiv:2403.05720v1 Announce Type: cross  Abstract: Brief hospital course (BHC) summaries are common clinical documents generated by summarizing clinical notes. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for healthcare applications such as BHC synthesis have not been shown. To enable the adaptation of LLMs for BHC synthesis, we introduce a novel benchmark consisting of a pre-processed dataset extracted from MIMIC-IV notes, encapsulating clinical note, and brief hospital course (BHC) pairs. We assess the performance of two general-purpose LLMs and three healthcare-adapted LLMs to improve BHC synthesis from clinical notes. Using clinical notes as input for generating BHCs, we apply prompting-based (using in-context learning) and fine-tuning-based adaptation strategies to three open-source LLMs (Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5, GPT-4). We quantitatively evaluate the performa
    
[^98]: DADIT：意大利推特用户人口分类数据集及预测方法比较

    DADIT: A Dataset for Demographic Classification of Italian Twitter Users and a Comparison of Prediction Methods

    [https://arxiv.org/abs/2403.05700](https://arxiv.org/abs/2403.05700)

    该研究构建了意大利推特用户人口分类数据集DADIT，用于预测社交媒体用户的性别和年龄，发现包含推文特征在年龄预测中特别有效，XLM-based分类器在性能上优于常用的M3分类器最多可提高53% F1分数。

    

    社会科学家越来越多地使用人口统计分层的社交媒体数据来研究一般公众的态度、信念和行为。为了促进这样的分析，我们构建、验证并公开发布了具有30M条推特的20k意大利推特用户的代表性DADIT数据集，以及他们的个人简介和个人头像。我们为用户数据添加了高质量的性别、年龄和位置标签。DADIT使我们能够训练和比较各种最先进模型的性能，用于预测社交媒体用户的性别和年龄。特别是，我们调查了推文是否包含有价值的信息，因为像M3这样的流行分类器并未利用它们。我们最好的基于XLM的分类器在F1分数上比常用对手M3提高了高达53%。对于年龄预测，分类器从包含推文作为特征中获益。我们还在一个德国测试集上确认了这些发现。

    arXiv:2403.05700v1 Announce Type: new  Abstract: Social scientists increasingly use demographically stratified social media data to study the attitudes, beliefs, and behavior of the general public. To facilitate such analyses, we construct, validate, and release publicly the representative DADIT dataset of 30M tweets of 20k Italian Twitter users, along with their bios and profile pictures. We enrich the user data with high-quality labels for gender, age, and location. DADIT enables us to train and compare the performance of various state-of-the-art models for the prediction of the gender and age of social media users. In particular, we investigate if tweets contain valuable information for the task, since popular classifiers like M3 don't leverage them. Our best XLM-based classifier improves upon the commonly used competitor M3 by up to 53% F1. Especially for age prediction, classifiers profit from including tweets as features. We also confirm these findings on a German test set.
    
[^99]: SeeGULL Multilingual：一个地理文化定位的刻板印象数据集

    SeeGULL Multilingual: a Dataset of Geo-Culturally Situated Stereotypes

    [https://arxiv.org/abs/2403.05696](https://arxiv.org/abs/2403.05696)

    通过新方法，构建了全球范围的多语言社会刻板印象数据集SeeGULL Multilingual，有助于解决生成式多语言模型安全性和公平性评估中存在的英文资源限制问题。

    

    虽然生成式多语言模型正在迅速部署，但它们的安全性和公平性评估主要局限于英文资源。为了解决这一关键差距，我们采用了一种最近引入的方法，将LLM生成与文化定位验证相结合，构建了全球范围的多语言社会刻板印象数据集SeeGULL Multilingual，包含超过25K条刻板印象，涵盖20种语言，在23个地区进行了人类注释。

    arXiv:2403.05696v1 Announce Type: new  Abstract: While generative multilingual models are rapidly being deployed, their safety and fairness evaluations are largely limited to resources collected in English. This is especially problematic for evaluations targeting inherently socio-cultural phenomena such as stereotyping, where it is important to build multi-lingual resources that reflect the stereotypes prevalent in respective language communities. However, gathering these resources, at scale, in varied languages and regions pose a significant challenge as it requires broad socio-cultural knowledge and can also be prohibitively expensive. To overcome this critical gap, we employ a recently introduced approach that couples LLM generations for scale with culturally situated validations for reliability, and build SeeGULL Multilingual, a global-scale multilingual dataset of social stereotypes, containing over 25K stereotypes, spanning 20 languages, with human annotations across 23 regions, 
    
[^100]: 使用GPT-4对基于视觉的LLM预测进行分解以进行自动评估

    Decomposing Vision-based LLM Predictions for Auto-Evaluation with GPT-4

    [https://arxiv.org/abs/2403.05680](https://arxiv.org/abs/2403.05680)

    提出了一种新颖的评估框架，用于评估视觉-语言LLMs在生成CT异常的准确摘要方面的能力。

    

    CT检查的数量每年都在增加，这导致放射科医生疲劳。大型语言模型（LLMs）有潜力减轻他们的负担，但其在临床中的采用取决于放射科医生的信任和生成内容的简单评估。本文提出了一个新颖的评估框架，用于评估视觉-语言LLMs在生成CT异常的准确摘要方面的能力。

    arXiv:2403.05680v1 Announce Type: new  Abstract: The volume of CT exams being done in the world has been rising every year, which has led to radiologist burn-out. Large Language Models (LLMs) have the potential to reduce their burden, but their adoption in the clinic depends on radiologist trust, and easy evaluation of generated content. Presently, many automated methods are available to evaluate the reports generated for chest radiographs, but such an approach is not available for CT presently. In this paper, we propose a novel evaluation framework to judge the capabilities of vision-language LLMs in generating accurate summaries of CT-based abnormalities. CT slices containing an abnormality (e.g., lesion) were input to a vision-based LLM (GPT-4V, LLaVA-Med, and RadFM), and it generated a free-text summary of the predicted characteristics of the abnormality. Next, a GPT-4 model decomposed the summary into specific aspects (body part, location, type, and attributes), automatically eval
    
[^101]: PipeRAG: 通过算法-系统共同设计实现快速检索增强生成

    PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System Co-design

    [https://arxiv.org/abs/2403.05676](https://arxiv.org/abs/2403.05676)

    PipeRAG通过算法-系统共同设计，在生成过程中实现了快速检索增强，将检索时间大大降低并提高生成质量。

    

    检索增强生成（RAG）可以通过整合外部标记数据库提高大语言模型（LLMs）的生成质量。然而，从大型数据库中检索在整体生成时间中可能占据相当大比例，特别是当定期执行检索以将检索内容与生成的最新状态对齐时。本文介绍了PipeRAG，这是一种新颖的算法-系统共同设计方法，旨在减少生成延迟并提高生成质量。PipeRAG结合了（1）管道并行性，以实现并发检索和生成过程，（2）灵活的检索间隔，以最大化管道并行性的效率，并且（3）性能模型，根据生成的状态和底层硬件自动平衡检索质量和延迟。我们的评估结果表明，通过结合这三种方法，PipeRAG实现了高达2.6倍的提升。

    arXiv:2403.05676v1 Announce Type: new  Abstract: Retrieval-augmented generation (RAG) can enhance the generation quality of large language models (LLMs) by incorporating external token databases. However, retrievals from large databases can constitute a substantial portion of the overall generation time, particularly when retrievals are periodically performed to align the retrieved content with the latest states of generation. In this paper, we introduce PipeRAG, a novel algorithm-system co-design approach to reduce generation latency and enhance generation quality. PipeRAG integrates (1) pipeline parallelism to enable concurrent retrieval and generation processes, (2) flexible retrieval intervals to maximize the efficiency of pipeline parallelism, and (3) a performance model to automatically balance retrieval quality and latency based on the generation states and underlying hardware. Our evaluation shows that, by combining the three aforementioned methods, PipeRAG achieves up to 2.6$\
    
[^102]: 使用ChatGPT生成难负样本数据以供意图分类使用

    Generating Hard-Negative Out-of-Scope Data with ChatGPT for Intent Classification

    [https://arxiv.org/abs/2403.05640](https://arxiv.org/abs/2403.05640)

    使用ChatGPT生成难负样本OOS数据，提出了新的难负样本OOS数据集，表明分类器在识别难负样本OOS数据方面存在困难，同时显示在训练中加入难负样本OOS数据可以提高模型的鲁棒性

    

    意图分类器必须能够区分用户的话语是否属于任何支持的意图，以避免产生不正确和无关的系统响应。 尽管已经研究了意图分类器的超范围（OOS）检测，但先前的工作尚未研究分类器性能对抗难负样本超范围话语（即，具有与范围内数据共同特征，但实际上超范围）的变化。 我们提出了一种使用ChatGPT生成难负样本OOS数据的自动化技术。 我们使用我们的技术构建了五个新的难负样本OOS数据集，并针对三个基准意图分类器对每个数据集进行评估。 我们展示了分类器在正确识别难负样本OOS话语方面的困难程度超过了一般的OOS话语。 最后，我们展示了在训练中结合难负样本OOS数据可以提高模型对难负样本OOS数据和一般OOS数据的鲁棒性。

    arXiv:2403.05640v1 Announce Type: new  Abstract: Intent classifiers must be able to distinguish when a user's utterance does not belong to any supported intent to avoid producing incorrect and unrelated system responses. Although out-of-scope (OOS) detection for intent classifiers has been studied, previous work has not yet studied changes in classifier performance against hard-negative out-of-scope utterances (i.e., inputs that share common features with in-scope data, but are actually out-of-scope). We present an automated technique to generate hard-negative OOS data using ChatGPT. We use our technique to build five new hard-negative OOS datasets, and evaluate each against three benchmark intent classifiers. We show that classifiers struggle to correctly identify hard-negative OOS utterances more than general OOS utterances. Finally, we show that incorporating hard-negative OOS data for training improves model robustness when detecting hard-negative OOS data and general OOS data. Our
    
[^103]: 无需调参的LLM部署负责干预--一种元认知方法

    Tuning-Free Accountable Intervention for LLM Deployment -- A Metacognitive Approach

    [https://arxiv.org/abs/2403.05636](https://arxiv.org/abs/2403.05636)

    提出了一种创新的元认知方法，名为CLEAR，旨在为LLMs提供自我意识的错误识别和纠正能力

    

    大型语言模型（LLMs）通过少量或零-shot提示在一系列自然语言处理任务中催生了变革性进展，绕过了参数调整的必要性。然而，这种便利的操作方式加剧了“幻觉”问题，特别是考虑到它们庞大模型规模背后的神秘“黑匣子”性质。这些担忧在高风险应用（如医疗保健）中变得更加严重，因为不负责任的决策错误可能导致灾难性后果。相比之下，人类决策依赖于微妙的认知过程，如通过概念理解感知和自适应地纠正错误判断的能力。受人类认知的启发，我们提出了一种创新的元认知方法，称为CLEAR，为LLMs提供自我意识的错误识别和纠正能力。我们的框架有助于构建co

    arXiv:2403.05636v1 Announce Type: new  Abstract: Large Language Models (LLMs) have catalyzed transformative advances across a spectrum of natural language processing tasks through few-shot or zero-shot prompting, bypassing the need for parameter tuning. While convenient, this modus operandi aggravates ``hallucination'' concerns, particularly given the enigmatic ``black-box'' nature behind their gigantic model sizes. Such concerns are exacerbated in high-stakes applications (e.g., healthcare), where unaccountable decision errors can lead to devastating consequences. In contrast, human decision-making relies on nuanced cognitive processes, such as the ability to sense and adaptively correct misjudgments through conceptual understanding. Drawing inspiration from human cognition, we propose an innovative \textit{metacognitive} approach, dubbed \textbf{CLEAR}, to equip LLMs with capabilities for self-aware error identification and correction. Our framework facilitates the construction of co
    
[^104]: 不熟悉的微调示例控制语言模型如何产生幻觉

    Unfamiliar Finetuning Examples Control How Language Models Hallucinate

    [https://arxiv.org/abs/2403.05612](https://arxiv.org/abs/2403.05612)

    本文研究了大型语言模型如何产生幻觉，并提出通过调整微调示例的监督来控制其对不熟悉输入的预测。作者开发了一种基于RL的方法，更可靠地减轻了长篇生成任务中的幻觉。

    

    大型语言模型（LLMs）倾向于生成听起来令人信服但事实不正确的响应，特别是当在不熟悉的概念上进行查询时。本文探讨了调整后的LLMs如何产生幻觉的基本机制。我们的调查揭示了一个有趣的模式：随着输入变得更不熟悉，LLMs的输出倾向于默认为"含糊其词"的预测，其形式受微调数据中不熟悉示例监督方式的影响。因此，通过策略性地修改这些示例的监督，我们可以控制LLM对不熟悉输入的预测（例如，教会它们说“我不知道”）。基于这些原则，我们开发了一种RL方法，通过解决奖励模型幻觉带来的挑战，更可靠地减轻长篇生成任务的幻觉。我们通过在MMLU上的多选QA中进行一系列受控实验来验证我们的发现。

    arXiv:2403.05612v1 Announce Type: cross  Abstract: Large language models (LLMs) have a tendency to generate plausible-sounding yet factually incorrect responses, especially when queried on unfamiliar concepts. In this work, we explore the underlying mechanisms that govern how finetuned LLMs hallucinate. Our investigation reveals an interesting pattern: as inputs become more unfamiliar, LLM outputs tend to default towards a ``hedged'' prediction, whose form is determined by how the unfamiliar examples in the finetuning data are supervised. Thus, by strategically modifying these examples' supervision, we can control LLM predictions for unfamiliar inputs (e.g., teach them to say ``I don't know''). Based on these principles, we develop an RL approach that more reliably mitigates hallucinations for long-form generation tasks, by tackling the challenges presented by reward model hallucinations. We validate our findings with a series of controlled experiments in multiple-choice QA on MMLU, as
    
[^105]: 基于概念的可解释模型用于利用多模态数据诊断脉络膜肿瘤

    A Concept-based Interpretable Model for the Diagnosis of Choroid Neoplasias using Multimodal Data

    [https://arxiv.org/abs/2403.05606](https://arxiv.org/abs/2403.05606)

    提出了一种基于概念的可解释模型，用于利用多模态数据诊断脉络膜肿瘤，促进了对罕见疾病的诊断，并在临床实践和医学教育中具有重要意义

    

    诊断罕见疾病在临床实践中面临着共同挑战，需要专家的专业知识才能准确识别。机器学习的出现提供了一种有希望的解决方案，然而这类技术的发展受到罕见状况的数据稀缺和在临床环境中需要具有可解释性和可信赖性的模型的需求的阻碍。可解释的人工智能，具有人类可读输出的能力，可以促进临床医生的验证并促进医学教育。在当前工作中，我们专注于脉络膜肿瘤，这是成人中最常见的眼睛癌症形式，尽管罕见，罹患率为每百万人5.1例。我们建立了迄今为止最大的数据集，共包括750名患者，涵盖了从2004年至2022年收集的三种不同成像模态。我们的工作引入了一个基于概念的可解释模型，可区分三种类型的脉络膜肿瘤，融合了一些不太重要的

    arXiv:2403.05606v1 Announce Type: cross  Abstract: Diagnosing rare diseases presents a common challenge in clinical practice, necessitating the expertise of specialists for accurate identification. The advent of machine learning offers a promising solution, while the development of such technologies is hindered by the scarcity of data on rare conditions and the demand for models that are both interpretable and trustworthy in a clinical context. Interpretable AI, with its capacity for human-readable outputs, can facilitate validation by clinicians and contribute to medical education. In the current work, we focus on choroid neoplasias, the most prevalent form of eye cancer in adults, albeit rare with 5.1 per million. We built the so-far largest dataset consisting of 750 patients, incorporating three distinct imaging modalities collected from 2004 to 2022. Our work introduces a concept-based interpretable model that distinguishes between three types of choroidal tumors, integrating insig
    
[^106]: 利用基于注意力的关联上下文信息从生物医学文献中提取蛋白质相互作用（PPIs）

    Extracting Protein-Protein Interactions (PPIs) from Biomedical Literature using Attention-based Relational Context Information

    [https://arxiv.org/abs/2403.05602](https://arxiv.org/abs/2403.05602)

    通过利用关系上下文信息的Transformer-based深度学习方法，本研究提出了一个统一的、多源PPI语料库，改进了关系分类性能。

    

    蛋白质相互作用（PPIs）对于理解生命系统至关重要，获取这些数据对于探究疾病发展和识别基因/蛋白质功能以及生物过程是必不可少的。本文提出了一个统一的、多源PPI语料库，通过二元交互类型标签增强了经过审查的交互定义，并提出了一种基于Transformer的深度学习方法，利用实体的关联上下文信息进行关系表示，以提高关系分类性能。

    arXiv:2403.05602v1 Announce Type: cross  Abstract: Because protein-protein interactions (PPIs) are crucial to understand living systems, harvesting these data is essential to probe disease development and discern gene/protein functions and biological processes. Some curated datasets contain PPI data derived from the literature and other sources (e.g., IntAct, BioGrid, DIP, and HPRD). However, they are far from exhaustive, and their maintenance is a labor-intensive process. On the other hand, machine learning methods to automate PPI knowledge extraction from the scientific literature have been limited by a shortage of appropriate annotated data. This work presents a unified, multi-source PPI corpora with vetted interaction definitions augmented by binary interaction type labels and a Transformer-based deep learning method that exploits entities' relational context information for relation representation to improve relation classification performance. The model's performance is evaluated
    
[^107]: 利用大型语言模型在心理治疗中进行认知重构

    HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy

    [https://arxiv.org/abs/2403.05574](https://arxiv.org/abs/2403.05574)

    这一创新心理治疗模型HealMe通过基于心理治疗框架的共情对话，有效解决了根深蒂固的负面思维，并促进了理性、平衡的观点。

    

    大型语言模型（LLMs）在心理治疗中可以发挥重要作用，熟练处理认知重构等关键任务，克服羞耻、不信任、治疗师技能差异和资源稀缺等挑战。在先前的认知重构中，主要将负面情绪转化为积极的，但这些方法效果有限，经常不能促进客户自我发现替代视角。在本文中，我们揭示了帮助和赋能通过自适应语言在心理增强（HealMe）模型。这种新颖的认知重构疗法方法有效地解决了根深蒂固的负面想法，并促进理性、平衡的视角。HealMe与传统LLM方法不同，采用基于心理治疗框架的共情对话。它通过系统指导客户区分情境和感受，集思广益寻找替代视角，并制定...

    arXiv:2403.05574v1 Announce Type: cross  Abstract: Large Language Models (LLMs) can play a vital role in psychotherapy by adeptly handling the crucial task of cognitive reframing and overcoming challenges such as shame, distrust, therapist skill variability, and resource scarcity. Previous LLMs in cognitive reframing mainly converted negative emotions to positive ones, but these approaches have limited efficacy, often not promoting clients' self-discovery of alternative perspectives. In this paper, we unveil the Helping and Empowering through Adaptive Language in Mental Enhancement (HealMe) model. This novel cognitive reframing therapy method effectively addresses deep-rooted negative thoughts and fosters rational, balanced perspectives. Diverging from traditional LLM methods, HealMe employs empathetic dialogue based on psychotherapeutic frameworks. It systematically guides clients through distinguishing circumstances from feelings, brainstorming alternative viewpoints, and developing 
    
[^108]: ChatGPT比人类更具移情能力吗？

    Is ChatGPT More Empathetic than Humans?

    [https://arxiv.org/abs/2403.05572](https://arxiv.org/abs/2403.05572)

    ChatGPT在回应情绪场景时比人类表现出更高的移情能力，平均移情评分高于人类生成的回应10%；指示ChatGPT在回应中融入对移情的清晰理解使得其回应与高度移情的个体的期望大致接近5倍。

    

    本文研究了ChatGPT以及尤其是其最新版本GPT-4在回应各种情绪场景（包括积极和消极情绪）时的移情能力，与人类生成的回应进行对比。我们采用严谨的评估方法，通过一个涉及600名参与者的组间研究来评估ChatGPT生成的回应中的移情水平。ChatGPT被提示的方式有两种：一种是标准方法，另一种明确详细说明了移情的认知、情感和同情方面。我们的发现表明，ChatGPT生成的回应的平均移情评分超过了人类生成的回应约10%。此外，指示ChatGPT在其回应中融入对移情的清晰理解使得这些回应与高度移情的个体的期望大致接近多达5倍。

    arXiv:2403.05572v1 Announce Type: cross  Abstract: This paper investigates the empathetic responding capabilities of ChatGPT, particularly its latest iteration, GPT-4, in comparison to human-generated responses to a wide range of emotional scenarios, both positive and negative. We employ a rigorous evaluation methodology, involving a between-groups study with 600 participants, to evaluate the level of empathy in responses generated by humans and ChatGPT. ChatGPT is prompted in two distinct ways: a standard approach and one explicitly detailing empathy's cognitive, affective, and compassionate counterparts. Our findings indicate that the average empathy rating of responses generated by ChatGPT exceeds those crafted by humans by approximately 10%. Additionally, instructing ChatGPT to incorporate a clear understanding of empathy in its responses makes the responses align approximately 5 times more closely with the expectations of individuals possessing a high degree of empathy, compared t
    
[^109]: 从社交媒体数据中检测可能患有亚临床ADHD的潜在伴随症状

    Detecting a Proxy for Potential Comorbid ADHD in People Reporting Anxiety Symptoms from Social Media Data

    [https://arxiv.org/abs/2403.05561](https://arxiv.org/abs/2403.05561)

    通过分析社交媒体数据，使用Transformers技术检测出焦虑症状患者中潜在的亚临床ADHD代理，帮助阐明了焦虑和ADHD之间的关系。

    

    我们提出了一个新颖的任务，可以阐明焦虑和ADHD之间的联系；利用变压器技术在解决基于关键字的分类器无法解决的任务方面取得进展；并讨论了一种可视化分类器的方法，阐明焦虑和ADHD表现之间的联系。大约50%的ADHD成年患者可能还患有焦虑症，约30%的焦虑成年患者可能也患有ADHD。患有焦虑症的患者可能会接受焦虑治疗，而不考虑ADHD，这可能会影响治疗。我们展示了如何从社交媒体数据中获取有关携带焦虑伴随的ADHD的数据，并展示了变压器可以用于检测在具有焦虑症状的人群中可能存在的亚临床ADHD的代理。

    arXiv:2403.05561v1 Announce Type: cross  Abstract: We present a novel task that can elucidate the connection between anxiety and ADHD; use Transformers to make progress toward solving a task that is not solvable by keyword-based classifiers; and discuss a method for visualization of our classifier illuminating the connection between anxiety and ADHD presentations.   Up to approximately 50% of adults with ADHD may also have an anxiety disorder and approximately 30\% of adults with anxiety may also have ADHD. Patients presenting with anxiety may be treated for anxiety without ADHD ever being considered, possibly affecting treatment. We show how data that bears on ADHD that is comorbid with anxiety can be obtained from social media data, and show that Transformers can be used to detect a proxy for possible comorbid ADHD in people with anxiety symptoms.   We collected data from anxiety and ADHD online forums (subreddits). We identified posters who first started posting in the Anxiety subre
    
[^110]: 通过语义匹配理解教育话题的演进

    Understanding the Progression of Educational Topics via Semantic Matching

    [https://arxiv.org/abs/2403.05553](https://arxiv.org/abs/2403.05553)

    本文利用BERT主题建模从课程中提取主题，然后利用这些主题来识别不同学科之间的关系，帮助我们更好地理解各种学习话题的演进。

    

    教育系统正在动态变化，以适应技术进步、工业和社会需求，并增强学生的学习旅程。课程专家和教育工作者不断修订各教育年级所教授的科目，以确定差距，引入新的学习话题，并提高学习成果。本文利用数据科学来更好地了解各种学习话题的演进。

    arXiv:2403.05553v1 Announce Type: cross  Abstract: Education systems are dynamically changing to accommodate technological advances, industrial and societal needs, and to enhance students' learning journeys. Curriculum specialists and educators constantly revise taught subjects across educational grades to identify gaps, introduce new learning topics, and enhance the learning outcomes. This process is usually done within the same subjects (e.g. math) or across related subjects (e.g. math and physics) considering the same and different educational levels, leading to massive multi-layer comparisons. Having nuanced data about subjects, topics, and learning outcomes structured within a dataset, empowers us to leverage data science to better understand the progression of various learning topics. In this paper, Bidirectional Encoder Representations from Transformers (BERT) topic modeling was used to extract topics from the curriculum, which were then used to identify relationships between su
    
[^111]: 使用BERT监测极端社交媒体上反犹太主义话语的演变

    Monitoring the evolution of antisemitic discourse on extremist social media using BERT

    [https://arxiv.org/abs/2403.05548](https://arxiv.org/abs/2403.05548)

    本研究提出了一种使用BERT监测极端社交媒体上反犹太主义话语演变的自动方法，避免了手动监测的不可行性，为干预和防止仇恨升级提供了新途径。

    

    研究表明，社交媒体上的种族主义和不宽容有可能在线下产生仇恨，最终导致身体暴力。本研究考虑的是在线反犹主义，追踪在线讨论中的反犹主题及其相关术语的演变，有助于监测参与者的情绪和演变，并可能提供干预方法，防止仇恨升级。鉴于在线流量庞大且不断变化，手动监测谈话实际上是不现实的。因此，我们提出了一种自动化方法，可以从极端社交媒体中提取反犹主题和术语，跟踪它们的演变。由于监督学习在这样的任务中过于受限，我们开发了一种无监督的在线机器学习方法，使用大型语言模型。

    arXiv:2403.05548v1 Announce Type: cross  Abstract: Racism and intolerance on social media contribute to a toxic online environment which may spill offline to foster hatred, and eventually lead to physical violence. That is the case with online antisemitism, the specific category of hatred considered in this study. Tracking antisemitic themes and their associated terminology over time in online discussions could help monitor the sentiments of their participants and their evolution, and possibly offer avenues for intervention that may prevent the escalation of hatred. Due to the large volume and constant evolution of online traffic, monitoring conversations manually is impractical. Instead, we propose an automated method that extracts antisemitic themes and terminology from extremist social media over time and captures their evolution. Since supervised learning would be too limited for such a task, we created an unsupervised online machine learning approach that uses large language model
    
[^112]: 基于规则的新闻标题生成

    Rule-driven News Captioning

    [https://arxiv.org/abs/2403.05101](https://arxiv.org/abs/2403.05101)

    本文提出了一种基于规则的新闻标题生成方法，通过新闻感知的语义规则，可以生成遵循新闻报道基本规则的图像描述。

    

    News captioning任务旨在通过描述图片及其新闻文章中的命名实体或具体事件来生成句子。现有方法通过依赖大规模预训练模型已取得显著成果，这些模型主要专注于输入新闻内容与输出预测之间的相关性。然而，新闻标题生成需要遵循新闻报道的一些基本规则，如准确描述与事件相关的个体和动作。在本文中，我们提出了基于规则的新闻标题生成方法，可以根据指定的规则信号生成图像描述。具体而言，我们首先为描述设计了新闻感知的语义规则。这一规则包括图片中描绘的主要动作（例如，“执行”）以及参与动作的命名实体扮演的角色（例如，“代理人”和“地点”）。其次，我们将这个语义规则注入到文本生成模型中。

    arXiv:2403.05101v1 Announce Type: cross  Abstract: News captioning task aims to generate sentences by describing named entities or concrete events for an image with its news article. Existing methods have achieved remarkable results by relying on the large-scale pre-trained models, which primarily focus on the correlations between the input news content and the output predictions. However, the news captioning requires adhering to some fundamental rules of news reporting, such as accurately describing the individuals and actions associated with the event. In this paper, we propose the rule-driven news captioning method, which can generate image descriptions following designated rule signal. Specifically, we first design the news-aware semantic rule for the descriptions. This rule incorporates the primary action depicted in the image (e.g., "performing") and the roles played by named entities involved in the action (e.g., "Agent" and "Place"). Second, we inject this semantic rule into th
    
[^113]: TopicDiff：一种用于多模态会话情感检测的主题丰富扩散方法

    TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection

    [https://arxiv.org/abs/2403.04789](https://arxiv.org/abs/2403.04789)

    提出了一种TopicDiff方法，用于捕获多模态会话情感检测任务中的主题信息，通过将扩散模型集成到神经主题模型中，解决了神经主题模型在捕获主题信息方面的多样性不足问题，并相对于现有MCE基线取得了显著改进

    

    多模态会话情感（MCE）检测通常跨越声学、视觉和语言模态，吸引了多媒体社区日益增加的兴趣。先前的研究主要集中在学习对话中的语境信息，只有少数考虑单一语言模态中的主题信息，而总是忽视声学和视觉主题信息。在此基础上，我们提出了一个模型不可知的Topic-enriched Diffusion（TopicDiff）方法，用于捕获MCE任务中的多模态主题信息。特别是，我们将扩散模型集成到神经主题模型中，以缓解神经主题模型在捕获主题信息方面的多样性不足问题。详细的评估表明，TopicDiff相对于最先进的MCE基线取得了显著改进，证明了多模态主题信息对MCE的重要性以及TopicDiff的有效性。

    arXiv:2403.04789v1 Announce Type: cross  Abstract: Multimodal Conversational Emotion (MCE) detection, generally spanning across the acoustic, vision and language modalities, has attracted increasing interest in the multimedia community. Previous studies predominantly focus on learning contextual information in conversations with only a few considering the topic information in single language modality, while always neglecting the acoustic and vision topic information. On this basis, we propose a model-agnostic Topic-enriched Diffusion (TopicDiff) approach for capturing multimodal topic information in MCE tasks. Particularly, we integrate the diffusion model into neural topic model to alleviate the diversity deficiency problem of neural topic model in capturing topic information. Detailed evaluations demonstrate the significant improvements of TopicDiff over the state-of-the-art MCE baselines, justifying the importance of multimodal topic information to MCE and the effectiveness of Topic
    
[^114]: 移除GPT4的过滤器

    Removing GPT4's Filter

    [https://arxiv.org/abs/2403.04769](https://arxiv.org/abs/2403.04769)

    提出了一种方法，可以使经过微调的GPT4恢复到没有经过人类反馈强化学习训练的状态，从而移除其在学习期间的所有安全机制

    

    GPT4最初在大量数据集上进行训练，然后使用来自人类反馈的强化学习进行微调，即志愿者提供反馈以教导GPT4不要生成不当内容。本文提出了一种方法来操作已经进行微调的版本，使其恢复到没有经过RLHF（Reinforcement learning from Human Feedback）的行为，有效地移除了模型在RLHF期间学习的所有安全机制。特别是，当GPT4在没有经过RLHF的情况下运行时，它失去了所有抑制力，只需前几个词就可以生成非常不当的内容。

    arXiv:2403.04769v1 Announce Type: cross  Abstract: GPT4 was initially trained on large amounts of data, and then fine-tuned using Reinforcement learning from Human Feedback (RLHF), which is when volunteers give feedback in order to teach GPT4 not to create inappropriate content. In this paper, we present a method to manipulate the fine-tuned version into reverting to pre-RLHF behavior, effectively removing all safety mechanisms that the model learned during RLHF. In particular, when GPT4 acts without RLHF, it loses all inhibition, and can complete very inappropriate content given only the first few words.
    
[^115]: 对话状态跟踪的思维链解释

    Chain of Thought Explanation for Dialogue State Tracking

    [https://arxiv.org/abs/2403.04656](https://arxiv.org/abs/2403.04656)

    提出了一种名为Chain-of-Thought-Explanation（CoTE）的模型，用于对话状态跟踪(DST)任务，通过逐步创建详细解释来确定插槽值，从而实现更准确可靠的结果。

    

    对话状态跟踪(DST)旨在记录用户在会话互动期间提出的查询和目标，通过维护一组预定义的插槽及其对应的值来实现。当前的方法以不透明方式决定插槽值，而人类通常采用更谨慎的方法，从相关的对话轮中收集信息，然后推理出适当的值。在这项工作中，我们聚焦于通过提出一个名为Chain-of-Thought-Explanation（CoTE）的模型，来解决确定插槽值所需的步骤。CoTE建立在生成式DST框架之上，旨在在确定插槽值后逐步创建详细解释。这一过程导致了更准确可靠的插槽值。此外，为了提高CoTE的推理能力，我们进一步通过自动改写构建更流畅高质量的解释，从而形成了CoTE-refined方法。

    arXiv:2403.04656v1 Announce Type: new  Abstract: Dialogue state tracking (DST) aims to record user queries and goals during a conversational interaction achieved by maintaining a prede- fined set of slots and their corresponding values. Current approaches decide slot values opaquely, while humans usually adopt a more deliberate approach by collecting information from relevant dialogue turns and then reasoning the appropriate values. In this work, we focus on the steps needed to figure out slot values by proposing a model named Chain-of-Thought-Explanation (CoTE) for the DST task. CoTE, which is built on the generative DST framework, is designed to create detailed explanations step by step after determining the slot values. This process leads to more accurate and reliable slot values. More-over, to improve the reasoning ability of the CoTE, we further construct more fluent and high-quality explanations with automatic paraphrasing, leading the method CoTE-refined. Experimental results on
    
[^116]: Aligners: 解耦LLMs和对齐

    Aligners: Decoupling LLMs and Alignment

    [https://arxiv.org/abs/2403.04224](https://arxiv.org/abs/2403.04224)

    提出了一种通过训练对齐器模型来解耦大型语言模型（LLMs）和对齐，以减少对齐对性能的潜在负面影响。

    

    大型语言模型（LLMs）需要与人类期望对齐，以确保它们在大多数应用中的安全性和实用性。对齐具有挑战性，成本高昂，并且需要为每个LLM和对齐标准重复进行。我们建议通过训练可以根据需要用于对齐给定标准的任何LLM的对齐模型来解耦LLMs和对齐，从而在一定程度上减少对性能的潜在负面影响。我们提出的对齐模型训练配方仅依赖于使用（提示的）LLM 生成的合成数据，并且可以轻松调整以适应各种对齐标准。我们通过训练一个“道德”对齐器并在实验上验证其有效性来阐明我们的方法。

    arXiv:2403.04224v1 Announce Type: cross  Abstract: Large Language Models (LLMs) need to be aligned with human expectations to ensure their safety and utility in most applications. Alignment is challenging, costly, and needs to be repeated for every LLM and alignment criterion. We propose to decouple LLMs and alignment by training aligner models that can be used to align any LLM for a given criteria on an as-needed basis, thus also reducing the potential negative impacts of alignment on performance. Our recipe for training the aligner models solely relies on synthetic data generated with a (prompted) LLM and can be easily adjusted for a variety of alignment criteria. We illustrate our method by training an "ethical" aligner and verify its efficacy empirically.
    
[^117]: 大型语言模型能够进行推理和规划吗？

    Can Large Language Models Reason and Plan?

    [https://arxiv.org/abs/2403.04121](https://arxiv.org/abs/2403.04121)

    大型语言模型缺乏自我批评能力，无法像人类一样纠正错误。

    

    虽然人类有时候表现出能够通过自我批评纠正自己错误猜测的能力，但似乎在大型语言模型的情况下没有依据支持这一假设。

    arXiv:2403.04121v1 Announce Type: new  Abstract: While humans sometimes do show the capability of correcting their own erroneous guesses with self-critiquing, there seems to be no basis for that assumption in the case of LLMs.
    
[^118]: Apollo：轻量级多语言医学LLMs：让医学人工智能普惠60亿人

    Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People

    [https://arxiv.org/abs/2403.03640](https://arxiv.org/abs/2403.03640)

    Apollo项目开发了多语言医学LLMs，创建了全球人口61亿的医学数据集，并发布了各种尺寸的最佳性能模型，其中Apollo-7B是最先进的多语言医学LLMs，可改善更大模型的多语言医学能力。

    

    尽管全球医学知识的庞大存储库主要是以英语为主，但在传递量身定制医疗服务方面，本地语言对于在医疗资源有限的地区尤为重要。为了将医学人工智能的进展扩展到更广泛的人群，我们旨在开发涵盖全球61亿人口的六种最常用语言的医学LLMs。这一努力最终促成了ApolloCorpora多语言医学数据集和XMedBench基准的创建。在多语言医学基准测试中，发布的Apollo模型，在各种相对较小尺寸（即0.5B、1.8B、2B、6B和7B）上取得了与同等大小模型最佳性能。特别地，Apollo-7B是迄今为止达到70B的最先进的多语言医学LLMs。此外，这些轻量级模型可用于在不需要微调的情况下改进较大模型的多语言医学能力。

    arXiv:2403.03640v1 Announce Type: cross  Abstract: Despite the vast repository of global medical knowledge predominantly being in English, local languages are crucial for delivering tailored healthcare services, particularly in areas with limited medical resources. To extend the reach of medical AI advancements to a broader population, we aim to develop medical LLMs across the six most widely spoken languages, encompassing a global population of 6.1 billion. This effort culminates in the creation of the ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the multilingual medical benchmark, the released Apollo models, at various relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best performance among models of equivalent size. Especially, Apollo-7B is the state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite models could be used to improve the multi-lingual medical capabilities of larger models without fine-tuning in a
    
[^119]: “在对话中学习”：通过对话中学习实现无需预定义个人资料的个性化对话

    "In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning

    [https://arxiv.org/abs/2403.03102](https://arxiv.org/abs/2403.03102)

    提出了一种In-Dialogue Learning框架，通过对话历史刻画个人设来完成个性化对话生成任务，无需预定义个人资料，并在实验证明其显著改进对话生成性能。

    

    个性化对话系统近年来备受关注，因其能够生成与不同人设一致的响应。然而，大多数现有方法依赖预定义的个人资料，这不仅耗时且劳动密集，还缺乏灵活性。我们提出了In-Dialogue Learning（IDL），一种微调框架，增强了预训练的大型语言模型利用对话历史来刻画个人设，以完成个性化对话生成任务，而无需预定义个人资料。我们在三个数据集上的实验表明，IDL带来了显著的改进，BLEU和ROUGE分数分别增加了高达200%和247%。此外，人工评估的结果进一步验证了我们提出方法的有效性。

    arXiv:2403.03102v1 Announce Type: cross  Abstract: Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning framework that enhances the ability of pre-trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre-defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements, with BLEU and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally, the results of human evaluations further validate the efficacy of our proposed method.
    
[^120]: 直接与Chat-Fine-Tuned LLMs的草案模型对齐

    Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs

    [https://arxiv.org/abs/2403.00858](https://arxiv.org/abs/2403.00858)

    通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。

    

    文本生成与大型语言模型（LLMs）由于其自回归本质、巨大的参数数量和有限的内存带宽而被认为是内存密集型，通常导致低令牌速率。猜测解码已被提出作为LLM推理加速的解决方案。然而，在现代开源LLM系列中，例如Llama 2 7B，由于草案模型通常不可用，因此需要训练高质量的草案模型以通过猜测解码实现推理加速。在本文中，我们提出了一个简单的草案模型训练框架，用于直接与Chat-capable目标模型对齐。通过我们提出的框架，我们训练出Llama 2 Chat Drafter 115M，这是一个适用于Llama 2 Chat 7B或更大模型的草案模型，仅占原始大小的1.64％。我们的训练框架仅包括预训练、蒸馏数据集生成和使用知识蒸馏进行微调，没有额外的对齐步骤。

    arXiv:2403.00858v1 Announce Type: cross  Abstract: Text generation with Large Language Models (LLMs) is known to be memory bound due to the combination of their auto-regressive nature, huge parameter counts, and limited memory bandwidths, often resulting in low token rates. Speculative decoding has been proposed as a solution for LLM inference acceleration. However, since draft models are often unavailable in the modern open-source LLM families, e.g., for Llama 2 7B, training a high-quality draft model is required to enable inference acceleration via speculative decoding. In this paper, we propose a simple draft model training framework for direct alignment to chat-capable target models. With the proposed framework, we train Llama 2 Chat Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\% of the original size. Our training framework only consists of pretraining, distillation dataset generation, and finetuning with knowledge distillation, with no additional align
    
[^121]: TV-TREES：用于神经符号视频推理的多模态蕴涵树

    TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning

    [https://arxiv.org/abs/2402.19467](https://arxiv.org/abs/2402.19467)

    TV-TREES是第一个多模态蕴涵树生成器，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树，实现了可解释联合模态推理，并在挑战性的TVQA数据集上展示了最先进的零-shot性能。

    

    在处理电视剪辑等复杂的多模态内容进行问答是一项具有挑战性的任务。这部分是因为当前的视频-语言模型依赖于单模态推理，在处理长输入时性能下降，并且缺乏可解释性。我们提出了TV-TREES，这是第一个多模态蕴涵树生成器。TV-TREES作为一种促进可解释联合模态推理的视频理解方法，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树。随后，我们引入了多模态蕴涵树生成任务来评估此类方法的推理质量。我们的方法在具有挑战性的TVQA数据集上的实验结果展示了可解释的、具有最先进零-shot性能的完整视频剪辑，展示了与黑盒方法相比的最佳实践。

    arXiv:2402.19467v1 Announce Type: cross  Abstract: It is challenging to perform question-answering over complex, multimodal content such as television clips. This is in part because current video-language models rely on single-modality reasoning, have lowered performance on long inputs, and lack interpetability. We propose TV-TREES, the first multimodal entailment tree generator. TV-TREES serves as an approach to video understanding that promotes interpretable joint-modality reasoning by producing trees of entailment relationships between simple premises directly entailed by the videos and higher-level conclusions. We then introduce the task of multimodal entailment tree generation to evaluate the reasoning quality of such methods. Our method's experimental results on the challenging TVQA dataset demonstrate intepretable, state-of-the-art zero-shot performance on full video clips, illustrating a best of both worlds contrast to black-box methods.
    
[^122]: 对语义变化特征的调查

    Survey in Characterization of Semantic Change

    [https://arxiv.org/abs/2402.19088](https://arxiv.org/abs/2402.19088)

    语义变化对计算语言学算法的结果质量可能会产生影响，因此重要性日益凸显。

    

    活语言不断发展，以吸纳人类社会的文化变化。这种演变通过新词语（新单词）或单词的语义变化（赋予已有单词新的含义）来体现。理解单词的含义对解释来自不同文化（地方用语或俚语）、领域（例如技术术语）或时代的文本至关重要。在计算机科学中，这些单词与计算语言学算法相关，例如翻译、信息检索、问答等。语义变化可能会影响这些算法的结果质量。因此，了解和形式化表征这些变化是很重要的。研究这种影响是计算语言学界近期引起关注的问题。几种方法提出了检测语义变化的方法，具有较高的精度，但需要更多努力来对其进行表征。

    arXiv:2402.19088v1 Announce Type: cross  Abstract: Live languages continuously evolve to integrate the cultural change of human societies. This evolution manifests through neologisms (new words) or \textbf{semantic changes} of words (new meaning to existing words). Understanding the meaning of words is vital for interpreting texts coming from different cultures (regionalism or slang), domains (e.g., technical terms), or periods. In computer science, these words are relevant to computational linguistics algorithms such as translation, information retrieval, question answering, etc. Semantic changes can potentially impact the quality of the outcomes of these algorithms. Therefore, it is important to understand and characterize these changes formally. The study of this impact is a recent problem that has attracted the attention of the computational linguistics community. Several approaches propose methods to detect semantic changes with good precision, but more effort is needed to charact
    
[^123]: MMSR：符号回归是一个多模态任务

    MMSR: Symbolic Regression is a Multimodal Task

    [https://arxiv.org/abs/2402.18603](https://arxiv.org/abs/2402.18603)

    符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。

    

    数学公式是探索自然规律几千年来人类智慧的结晶。用简洁的数学公式描述复杂的自然规律是科学家不断追求的目标，也是人工智能面临的重大挑战。这一领域被称为符号回归。在本文中，研究人员将从数据到表达式的映射视为翻译问题，并引入了相应的大规模预训练模型。

    arXiv:2402.18603v1 Announce Type: cross  Abstract: Mathematical formulas are the crystallization of human wisdom in exploring the laws of nature for thousands of years. Describing the complex laws of nature with a concise mathematical formula is a constant pursuit of scientists and a great challenge for artificial intelligence. This field is called symbolic regression. Symbolic regression was originally formulated as a combinatorial optimization problem, and GP and reinforcement learning algorithms were used to solve it. However, GP is sensitive to hyperparameters, and these two types of algorithms are inefficient. To solve this problem, researchers treat the mapping from data to expressions as a translation problem. And the corresponding large-scale pre-trained model is introduced. However, the data and expression skeletons do not have very clear word correspondences as the two languages do. Instead, they are more like two modalities (e.g., image and text). Therefore, in this paper, w
    
[^124]: LDB：通过逐步验证运行时执行来调试大型语言模型

    LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step

    [https://arxiv.org/abs/2402.16906](https://arxiv.org/abs/2402.16906)

    LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。

    

    大型语言模型（LLMs）在代码生成方面取得了重大进展。最近的研究不仅将单次代码生成，而且还将单元测试和程序验证器整合到LLMs中，以迭代地完善生成的程序。然而，这些工作将生成的程序视为不可分割的实体，这对LLMs在调试程序时存在不足，特别是当程序包含复杂的逻辑流程和数据操作时。相比之下，当人类开发人员调试程序时，他们通常设置断点并有选择地检查运行时执行信息。执行流和中间变量在调试过程中发挥着关键作用，然而现有的代码生成文献中未充分利用它们。本研究引入了大型语言模型调试器（LDB），这是一个新颖的调试框架，可以让LLMs通过运行时执行信息完善其生成的程序。

    arXiv:2402.16906v1 Announce Type: cross  Abstract: Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an indivisible entity, which falls short for LLMs in debugging the programs, especially when the programs contain complex logic flows and data operations. In contrast, when human developers debug programs, they typically set breakpoints and selectively examine runtime execution information. The execution flow and the intermediate variables play a crucial role in the debugging process, yet they are underutilized in the existing literature on code generation. In this study, we introduce Large Language Model Debugger (LDB), a novel debugging framework that enables LLMs to refine their generated programs with the runtime execution information. Specifical
    
[^125]: 语言模型数据选择概述

    A Survey on Data Selection for Language Models

    [https://arxiv.org/abs/2402.16827](https://arxiv.org/abs/2402.16827)

    大型语言模型成功的关键在于使用大规模的文本数据集进行无监督预训练，但如何优化选择数据以降低碳足迹和财务成本仍是一个挑战。

    

    最近大型语言模型取得成功的一个主要因素是利用巨大且不断增长的文本数据集进行无监督预训练。然而，简单地在所有可用数据上训练模型可能并不是最佳选择（或不可行），因为可用文本数据的质量可能有所不同。数据过滤也可以通过减少所需的训练量来降低训练模型的碳足迹和财务成本。数据选择方法旨在确定要包括在训练数据集中的哪些候选数据点，以及如何从所选数据点中适当采样。改进的数据选择方法的前景已经导致该领域的研究量迅速扩大。然而，由于深度学习主要受实证证据驱动，对大规模数据进行实验成本昂贵，很少有组织拥有资源进行广泛的数据选择研究。因此，有效数据选择的知识可能大多局限于大型技术公司或研究机构内部。

    arXiv:2402.16827v1 Announce Type: new  Abstract: A major factor in the recent success of large language models is the use of enormous and ever-growing text datasets for unsupervised pre-training. However, naively training a model on all available data may not be optimal (or feasible), as the quality of available text data can vary. Filtering out data can also decrease the carbon footprint and financial costs of training models by reducing the amount of training required.   Data selection methods aim to determine which candidate data points to include in the training dataset and how to appropriately sample from the selected data points. The promise of improved data selection methods has caused the volume of research in the area to rapidly expand. However, because deep learning is mostly driven by empirical evidence and experimentation on large-scale data is expensive, few organizations have the resources for extensive data selection research. Consequently, knowledge of effective data se
    
[^126]: LLM推断揭示：调查与Roofline模型见解

    LLM Inference Unveiled: Survey and Roofline Model Insights

    [https://arxiv.org/abs/2402.16363](https://arxiv.org/abs/2402.16363)

    本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。

    

    高效大语言模型（LLM）推断领域正在迅速发展，提供了机遇和挑战的独特结合。虽然该领域已经扩展并充满活力，但至今还没有一个简明的框架来分析LLM推断的各种方法，以便清晰地理解这一领域。我们的调查不仅总结了当前研究现状，还基于Roofline模型引入了一个框架，用于系统分析LLM推断技术。这一框架能够帮助识别LLM部署中的瓶颈，并更深入地了解在实际设备上的实际方面，从而为部署LLM提供更有效的策略。此外，我们还系统地汇总了高效LLM推断的最新进展，涵盖关键领域，比如权重优化（如知识蒸馏和量化）。

    arXiv:2402.16363v1 Announce Type: cross  Abstract: The field of efficient Large Language Model (LLM) inference is rapidly evolving, presenting a unique blend of opportunities and challenges. Although the field has expanded and is vibrant, there hasn't been a concise framework that analyzes the various methods of LLM Inference to provide a clear understanding of this domain. Our survey stands out from traditional literature reviews by not only summarizing the current state of research but also by introducing a framework based on roofline model for systematic analysis of LLM inference techniques. This framework enables identifying the bottlenecks in LLM deployments and provides a deeper understanding of the practical aspects on real devices, thereby informing more effective strategies for deploying LLM. Furthermore, we systematically collate the latest advancements in efficient LLM inference, covering crucial areas such as weight optimization (e.g., Knowledge Distillation and Quantizatio
    
[^127]: 一种使用注释嵌入模型的本体包含关系预测自匹配训练方法

    A Self-matching Training Method with Annotation Embedding Models for Ontology Subsumption Prediction

    [https://arxiv.org/abs/2402.16278](https://arxiv.org/abs/2402.16278)

    提出了一种自匹配训练方法，通过两种本体嵌入模型捕获全局和局部信息，提高了概念子类预测的稳健性

    

    最近，提出了一种在低维空间中表示实体的本体嵌入，用于本体完成。然而，用于概念子类预测的本体嵌入未解决类似和孤立实体的困难，并且未提取本体中注释公理的全局信息。本文提出了一种针对两种本体嵌入模型的自匹配训练方法：Inverted-index Matrix Embedding (InME) 和 Co-occurrence Matrix Embedding (CoME)。这两种嵌入通过每个单词在一组公理中出现的位置以及每个公理中单词的共现来捕获注释公理中的全局和局部信息。自匹配训练方法提高了概念子类预测的稳健性，当预测的超类与子类相似且孤立于本体中的其他实体时。

    arXiv:2402.16278v1 Announce Type: new  Abstract: Recently, ontology embeddings representing entities in a low-dimensional space have been proposed for ontology completion. However, the ontology embeddings for concept subsumption prediction do not address the difficulties of similar and isolated entities and fail to extract the global information of annotation axioms from an ontology. In this paper, we propose a self-matching training method for the two ontology embedding models: Inverted-index Matrix Embedding (InME) and Co-occurrence Matrix Embedding (CoME). The two embeddings capture the global and local information in annotation axioms by means of the occurring locations of each word in a set of axioms and the co-occurrences of words in each axiom. The self-matching training method increases the robustness of the concept subsumption prediction when predicted superclasses are similar to subclasses and are isolated to other entities in an ontology. Our evaluation experiments show that
    
[^128]: DistALANER：开源软件生态系统中的远程监督主动学习增强命名实体识别

    DistALANER: Distantly Supervised Active Learning Augmented Named Entity Recognition in the Open Source Software Ecosystem

    [https://arxiv.org/abs/2402.16159](https://arxiv.org/abs/2402.16159)

    提出了一种为开源软件系统量身定制的新颖命名实体识别技术，通过远程监督注释过程、语言启发、查找表、外部知识源和主动学习方法来提高模型性能，有效缓解了成本和专家标注人员稀缺问题，并在关系抽取下游任务中显著优于LLMs。

    

    本文提出了一种专为开源软件系统量身定制的新颖命名实体识别（NER）技术。我们的方法旨在通过采用全面的两步远程监督注释过程来解决软件数据标注稀缺的问题。该过程巧妙地利用语言启发、独特的查找表、外部知识源以及主动学习方法。通过利用这些强大的技术，我们不仅提高了模型性能，还有效地缓解了成本和专家标注人员稀缺所带来的限制。值得注意的是，我们的框架在很大程度上明显优于最先进的LLMs。我们还展示了NER在关系抽取的下游任务中的有效性。

    arXiv:2402.16159v1 Announce Type: new  Abstract: This paper proposes a novel named entity recognition (NER) technique specifically tailored for the open-source software systems. Our approach aims to address the scarcity of annotated software data by employing a comprehensive two-step distantly supervised annotation process. This process strategically leverages language heuristics, unique lookup tables, external knowledge sources, and an active learning approach. By harnessing these powerful techniques, we not only enhance model performance but also effectively mitigate the limitations associated with cost and the scarcity of expert annotators. It is noteworthy that our framework significantly outperforms the state-of-the-art LLMs by a substantial margin. We also show the effectiveness of NER in the downstream task of relation extraction.
    
[^129]: 使用深度学习技术在短英文文本中进行情绪分类

    Emotion Classification in Short English Texts using Deep Learning Techniques

    [https://arxiv.org/abs/2402.16034](https://arxiv.org/abs/2402.16034)

    该研究使用深度学习技术在短英文文本中识别情绪，发现基于迁移学习和BERT的文本嵌入方法在分类准确性上表现优异。

    

    从资源匮乏的语言中的有限文本数据集中检测情绪是一项严峻的挑战，需要专门的框架和计算策略。本研究对使用深度学习技术在短英文文本中识别情绪进行了彻底的研究。深度学习方法采用迁移学习和词嵌入，特别是BERT，以获得更高的准确性。为了评估这些方法，我们引入了“SmallEnglishEmotions”数据集，该数据集包含6372个带有五种主要情绪类别注释的不同短波斯文本。我们的实验表明，迁移学习和基于BERT的文本嵌入在准确分类数据集中的文本方面优于替代方法。

    arXiv:2402.16034v1 Announce Type: cross  Abstract: Detecting emotions in limited text datasets from under-resourced languages presents a formidable obstacle, demanding specialized frameworks and computational strategies. This study conducts a thorough examination of deep learning techniques for discerning emotions in short English texts. Deep learning approaches employ transfer learning and word embedding, notably BERT, to attain superior accuracy. To evaluate these methods, we introduce the "SmallEnglishEmotions" dataset, comprising 6372 varied short Persian texts annotated with five primary emotion categories. Our experiments reveal that transfer learning and BERT-based text embedding outperform alternative methods in accurately categorizing the text in the dataset.
    
[^130]: InfFeed：将影响函数作为反馈以改善主观任务的表现

    InfFeed: Influence Functions as a Feedback to Improve the Performance of Subjective Tasks

    [https://arxiv.org/abs/2402.14702](https://arxiv.org/abs/2402.14702)

    InfFeed将影响函数作为反馈，用于改善主观任务表现，并通过自动识别需要交叉检查的数据点以提高模型性能，在调整标签方面优于现有基线。

    

    最近，影响函数提供了一种工具，通过量化可能影响测试预测的个别训练实例的扰动，实现对深度神经模型的可解释性。本文的目标是双重的。首先，我们将影响函数作为反馈引入模型以改善其性能。其次，在数据集扩展练习中，使用影响函数自动识别最初由某些现有方法‘银’注释的数据点，并需要标注者交叉检查（和纠正）以改善模型性能。为了实现这些目标，本文引入了InfFeed，该方法使用影响函数计算目标实例的有影响力的实例。向第一个目标努力，我们根据其影响者的标签调整目标实例的标签。在此过程中，InfFeed的表现优于现有基线（包括LLMs）。

    arXiv:2402.14702v1 Announce Type: new  Abstract: Recently, influence functions present an apparatus for achieving explainability for deep neural models by quantifying the perturbation of individual train instances that might impact a test prediction. Our objectives in this paper are twofold. First we incorporate influence functions as a feedback into the model to improve its performance. Second, in a dataset extension exercise, using influence functions to automatically identify data points that have been initially `silver' annotated by some existing method and need to be cross-checked (and corrected) by annotators to improve the model performance. To meet these objectives, in this paper, we introduce InfFeed, which uses influence functions to compute the influential instances for a target instance. Toward the first objective, we adjust the label of the target instance based on its influencer(s) label. In doing this, InfFeed outperforms the state-of-the-art baselines (including LLMs) b
    
[^131]: PIRB：波兰密集和混合文本检索方法的综合基准评估

    PIRB: A Comprehensive Benchmark of Polish Dense and Hybrid Text Retrieval Methods

    [https://arxiv.org/abs/2402.13350](https://arxiv.org/abs/2402.13350)

    PIRB提出了一个全面的波兰文本信息检索基准，包含41个任务，评估了超过20种密集和稀疏检索模型，并引入了一个三步训练流程来构建高效的特定语言检索器，最后验证了他们的方法的优越性

    

    我们介绍了波兰信息检索基准（PIRB），这是一个全面的评估框架，涵盖了波兰语的41个文本信息检索任务。该基准包括现有数据集以及10个新的、以前未公开的数据集，涵盖了医学、法律、商业、物理和语言学等多样主题。我们进行了超过20个密集和稀疏检索模型的广泛评估，包括我们训练的基准模型以及其他可用的波兰语和多语言方法。最后，我们介绍了一个用于训练高效特定语言检索器的三步流程，包括知识蒸馏、监督微调以及使用轻量级重新评分模型构建稀疏-密集混合检索器。为了验证我们的方法，我们为波兰语训练了新的文本编码器，并将其结果与先前评估过的方法进行了比较。我们的密集模型优于现有的最佳解决方案

    arXiv:2402.13350v1 Announce Type: new  Abstract: We present Polish Information Retrieval Benchmark (PIRB), a comprehensive evaluation framework encompassing 41 text information retrieval tasks for Polish. The benchmark incorporates existing datasets as well as 10 new, previously unpublished datasets covering diverse topics such as medicine, law, business, physics, and linguistics. We conduct an extensive evaluation of over 20 dense and sparse retrieval models, including the baseline models trained by us as well as other available Polish and multilingual methods. Finally, we introduce a three-step process for training highly effective language-specific retrievers, consisting of knowledge distillation, supervised fine-tuning, and building sparse-dense hybrid retrievers using a lightweight rescoring model. In order to validate our approach, we train new text encoders for Polish and compare their results with previously evaluated methods. Our dense models outperform the best solutions avai
    
[^132]: Me LLaMA: 为医疗应用构建大型语言模型的基础

    Me LLaMA: Foundation Large Language Models for Medical Applications

    [https://arxiv.org/abs/2402.12749](https://arxiv.org/abs/2402.12749)

    Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。

    

    最近，诸如ChatGPT和LLaMA等大型语言模型(LLMs)在许多人工智能应用中展现出巨大的潜力。然而，它们在医学任务上的表现不够理想，并且可以通过在大型领域特定数据集上进行训练来进一步改进。本研究引入了Me LLaMA，一个医学LLM系列，包括基础模型- Me LLaMA 13/70B及其 chat-enhanced 版本- Me LLaMA 13/70B-chat，通过持续对LLaMA2进行预训练和指导调整，使用大规模医学数据开发而成。我们用于训练和评估的领域特定数据套件包括一个具有129B tokens的大规模持续预训练数据集，一个包含214k个样本的指导调整数据集，以及跨越14个数据集的六项任务的医学评估基准(MIBE)。我们使用MIBE进行的广泛评估显示，Me LLaMA模型在零-shot和少-shot学习方面超越了现有的开源医学LLMs，并且在商业巨头如ChatGPT上表现出色。

    arXiv:2402.12749v1 Announce Type: cross  Abstract: Recent large language models (LLMs) like ChatGPT and LLaMA have shown great promise in many AI applications. However, their performance on medical tasks is suboptimal and can be further improved by training on large domain-specific datasets. This study introduces Me LLaMA, a medical LLM family including foundation models - Me LLaMA 13/70B and their chat-enhanced versions - Me LLaMA 13/70B-chat, developed through the continual pre-training and instruction tuning of LLaMA2 using large medical data. Our domain-specific data suite for training and evaluation, includes a large-scale continual pre-training dataset with 129B tokens, an instruction tuning dataset with 214k samples, and a medical evaluation benchmark (MIBE) across six tasks with 14 datasets. Our extensive evaluation using MIBE shows that Me LLaMA models surpass existing open-source medical LLMs in zero-shot and few-shot learning and outperform commercial giants like ChatGPT on 
    
[^133]: 智能手机GUI自动化的全面认知LLM代理

    Comprehensive Cognitive LLM Agent for Smartphone GUI Automation

    [https://arxiv.org/abs/2402.11941](https://arxiv.org/abs/2402.11941)

    提出了全面认知LLM代理，通过全面环境感知和条件动作预测两种新方法系统性提高GUI自动化性能。

    

    大型语言模型(LLMs)已经显示出作为人类般自主语言代理与现实环境进行交互的显著潜力，尤其在图形用户界面(GUI)自动化方面。然而，这些GUI代理需要全面的认知能力，包括详尽的感知和可靠的动作响应。我们提出了全面认知LLM代理，CoCo-Agent，采用了两种新方法，全面环境感知(CEP)和条件动作预测(CAP)，以系统性地提高GUI自动化性能。首先，CEP通过不同方面和粒度促进GUI感知，包括屏幕截图和用于视觉通道的补充详细布局，以及用于文本通道的历史动作。其次，CAP将动作预测分解为子问题：动作类型预测和条件化于动作类型的动作目标。

    arXiv:2402.11941v1 Announce Type: new  Abstract: Large language models (LLMs) have shown remarkable potential as human-like autonomous language agents to interact with real-world environments, especially for graphical user interface (GUI) automation. However, those GUI agents require comprehensive cognition ability including exhaustive perception and reliable action response. We propose \underline{Co}mprehensive \underline{Co}gnitive LLM \underline{Agent}, CoCo-Agent, with two novel approaches, comprehensive environment perception (CEP) and conditional action prediction (CAP), to systematically improve the GUI automation performance. First, CEP facilitates the GUI perception through different aspects and granularity, including screenshots and complementary detailed layouts for the visual channel and historical actions for the textual channel. Second, CAP decomposes the action prediction into sub-problems: action type prediction and action target conditioned on the action type. With our
    
[^134]: 与团体互动：对宗教极端化影响的联系与破裂

    Bridging or Breaking: Impact of Intergroup Interactions on Religious Polarization

    [https://arxiv.org/abs/2402.11895](https://arxiv.org/abs/2402.11895)

    研究探讨团体互动对宗教极端化的影响，在印度 Twitter 用户中发现，政治和社会事件的团体间互动可以减少极端化。

    

    虽然接触不同观点可能会减少极端化，但当讨论对抗性时，也可能产生反效应并加剧极端化。在这里，我们研究了围绕重要事件的团体间互动是否影响社交网络中多数群体和少数群体之间的极端化。我们收集了约 70 万名印度 Twitter 用户在 2020 年参与与 COVID-19 相关话题讨论时的宗教身份数据。我们引入了一个基于推文文本的情境嵌入的新量度，用于帮助我们评估宗教群体之间的极端化。然后，我们使用元学习框架来研究围绕共同、政治和社会经济事件的异质处理效果对个体群体符合性的影响。我们发现，在政治和社会事件方面，团体间互动会减少极端化。

    arXiv:2402.11895v1 Announce Type: cross  Abstract: While exposure to diverse viewpoints may reduce polarization, it can also have a backfire effect and exacerbate polarization when the discussion is adversarial. Here, we examine the question whether intergroup interactions around important events affect polarization between majority and minority groups in social networks. We compile data on the religious identity of nearly 700,000 Indian Twitter users engaging in COVID-19-related discourse during 2020. We introduce a new measure for an individual's group conformity based on contextualized embeddings of tweet text, which helps us assess polarization between religious groups. We then use a meta-learning framework to examine heterogeneous treatment effects of intergroup interactions on an individual's group conformity in the light of communal, political, and socio-economic events. We find that for political and social events, intergroup interactions reduce polarization. This decline is we
    
[^135]: 通过纯微调进行模型编辑

    Model Editing by Pure Fine-Tuning

    [https://arxiv.org/abs/2402.11078](https://arxiv.org/abs/2402.11078)

    纯微调通过优化条件似然、增加随机释义和事实的数据，在模型编辑中取得了不俗的表现。

    

    精细调整被认为在模型编辑中不够有效，因为相对更专业的方法而言，它的表现较差。然而，微调是简单的，不关心被编辑模型的体系结构细节，并且能够利用标准训练方法的不断进展（例如PEFT），使其成为模型编辑器的吸引选择。在本文中，我们展示了纯粹的微调可以是一种可行的模型编辑方法。我们提出了对朴素微调进行轻微修改的两个关键因素。第一，我们优化条件似然而非完整似然。第二，我们使用随机释义和事实来增加数据，以鼓励泛化和局部性。我们在ZsRE和CounterFact上的实验表明，这一简单修改使得微调通常可以与专业编辑器在编辑分数方面匹敌甚至超越。

    arXiv:2402.11078v1 Announce Type: cross  Abstract: Fine-tuning is dismissed as not effective for model editing due to its poor performance compared to more specialized methods. However, fine-tuning is simple, agnostic to the architectural details of the model being edited, and able to leverage ongoing advances in standard training methods (e.g., PEFT), making it an appealing choice for a model editor. In this work, we show that pure fine-tuning can be a viable approach to model editing. We propose a slight modification of naive fine-tuning with two key ingredients. First, we optimize the conditional likelihood rather than the full likelihood. Second, we augment the data with random paraphrases and facts to encourage generalization and locality. Our experiments on ZsRE and CounterFact show that this simple modification allows fine-tuning to often match or outperform specialized editors in the edit score.
    
[^136]: 通过知识蒸馏和优化训练策略，利用大型语言模型提升NLP任务性能

    Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies

    [https://arxiv.org/abs/2402.09282](https://arxiv.org/abs/2402.09282)

    该论文介绍了一种利用大型语言模型和优化训练策略提高NLP任务性能的新方法，通过知识蒸馏和采用细思连想提示技术，将GPT-4中提炼的知识应用于BERT模型，在命名实体识别任务上取得了显著的性能提升，并为资源有限或封闭网络环境提供了一种成本效益的解决方案。

    

    大型语言模型（LLMs）如GPT-4的整合到传统的自然语言处理（NLP）任务中，为提高模型性能并减少对大量人工注释的依赖打开了新的途径。本文提出了一种利用细思连想（CoT）提示技术从GPT-4中提炼知识，并将其应用于改进较小模型BERT在命名实体识别（NER）任务上的效率和效果的新方法。我们的方法包括两个阶段的训练过程：首先使用GPT-4注释数据进行预训练，然后使用蒸馏和原始人工注释数据的组合对模型进行改进。结果表明，我们的混合训练策略明显优于仅使用人工注释数据训练的模型，在F1分数上表现出卓越的性能，并为资源有限或封闭网络环境提供了一种具有成本效益的解决方案。

    arXiv:2402.09282v1 Announce Type: new Abstract: The integration of Large Language Models (LLMs) like GPT-4 into traditional Natural Language Processing (NLP) tasks has opened new avenues for enhancing model performance while reducing the reliance on extensive human annotations. This paper presents a novel approach that leverages the Chain of Thought (CoT) prompting technique to distill knowledge from GPT-4, subsequently applying it to improve the efficiency and effectiveness of a smaller model, BERT, on Named Entity Recognition (NER) tasks. Our method involves a two-phase training process: initially employing GPT-4 annotated data for pre-training and then refining the model with a combination of distilled and original human-annotated data. The results demonstrate that our mixed-training strategy significantly outperforms models trained solely on human annotations, achieving superior F1-scores and showcasing a cost-effective solution for resource-limited or closed-network settings. The 
    
[^137]: 主题建模作为多目标对比优化方法

    Topic Modeling as Multi-Objective Contrastive Optimization

    [https://arxiv.org/abs/2402.07577](https://arxiv.org/abs/2402.07577)

    该论文介绍了一种新颖的主题建模方法，通过优化对数似然的证据下界和对比学习目标的加权线性组合，将对比主题建模作为一种多目标优化问题，旨在获得能够捕捉共享语义并克服低级别互信息干扰的主题向量集合。

    

    最近的表示学习方法通过优化对数似然的证据下界（ELBO）和对比学习目标的加权线性组合来增强神经主题模型。然而，文档级对比学习可能捕捉到低级别的互信息，例如词比例，这会干扰主题建模。此外，ELBO损失旨在记忆输入细节以获得更好的重构质量，而对比损失则试图学习在输入文档之间泛化的主题表示，二者存在潜在冲突。为了解决这些问题，首先我们引入了一种新颖的面向主题向量集合的对比学习方法，以捕捉一组输入文档之间共享的有用语义。其次，我们将对比主题建模明确提出为一个基于梯度的多目标优化问题，目标是实现帕累托平稳解决方案。

    Recent representation learning approaches enhance neural topic models by optimizing the weighted linear combination of the evidence lower bound (ELBO) of the log-likelihood and the contrastive learning objective that contrasts pairs of input documents. However, document-level contrastive learning might capture low-level mutual information, such as word ratio, which disturbs topic modeling. Moreover, there is a potential conflict between the ELBO loss that memorizes input details for better reconstruction quality, and the contrastive loss which attempts to learn topic representations that generalize among input documents. To address these issues, we first introduce a novel contrastive learning method oriented towards sets of topic vectors to capture useful semantics that are shared among a set of input documents. Secondly, we explicitly cast contrastive topic modeling as a gradient-based multi-objective optimization problem, with the goal of achieving a Pareto stationary solution that b
    
[^138]: 大语言模型代理能够模拟人类的信任行为吗？

    Can Large Language Model Agents Simulate Human Trust Behaviors?

    [https://arxiv.org/abs/2402.04559](https://arxiv.org/abs/2402.04559)

    大语言模型代理能够模拟人类的信任行为，表现出在信任游戏中的信任行为，并且与人类行为具有高度一致性，但存在一些偏见和对代理与人类的差异。

    

    大语言模型（LLM）代理已经越来越多地被采用作为模拟工具，用于模拟人类在社会科学等领域中的行为。然而，一个基本的问题仍然存在：LLM代理是否真的能够模拟人类行为？在本文中，我们专注于人类互动中最关键的行为之一，信任，旨在调查LLM代理是否能够模拟人类的信任行为。我们首先发现，在被行为经济学广泛接受的信任游戏框架下，LLM代理通常表现出信任行为，称为代理信任。然后，我们发现LLM代理在信任行为方面与人类具有较高的行为一致性，表明使用LLM代理模拟人类的信任行为是可行的。此外，我们还探索了代理信任中的偏见以及代理信任在对代理和人类之间的差异方面的内在特性。我们还探讨了包括高级推理策略在内的条件下代理信任的内在特性。

    Large Language Model (LLM) agents have been increasingly adopted as simulation tools to model humans in applications such as social science. However, one fundamental question remains: can LLM agents really simulate human behaviors? In this paper, we focus on one of the most critical behaviors in human interactions, trust, and aim to investigate whether or not LLM agents can simulate human trust behaviors. We first find that LLM agents generally exhibit trust behaviors, referred to as agent trust, under the framework of Trust Games, which are widely recognized in behavioral economics. Then, we discover that LLM agents can have high behavioral alignment with humans regarding trust behaviors, indicating the feasibility to simulate human trust behaviors with LLM agents. In addition, we probe into the biases in agent trust and the differences in agent trust towards agents and humans. We also explore the intrinsic properties of agent trust under conditions including advanced reasoning strate
    
[^139]: 大型语言模型中的时间箭头

    Arrows of Time for Large Language Models

    [https://arxiv.org/abs/2401.17505](https://arxiv.org/abs/2401.17505)

    这篇论文通过研究自回归大型语言模型的时间方向性，发现了模型在建模自然语言能力上存在时间上的不对称性。从信息理论的角度来看，这种差异理论上是不应该存在的。通过稀疏性和计算复杂性的考虑，提供了一个理论框架来解释这种不对称性的出现。

    

    我们通过时间方向性的视角研究了自回归大型语言模型的概率建模。我们在实证上发现这类模型在建模自然语言能力上存在时间上的不对称性：预测下一个记号和预测前一个记号时的平均对数困惑度存在差异。这种差异既微妙又在不同的模态（语言、模型大小、训练时间等）下非常一致。从信息理论的角度来看，这在理论上是令人惊讶的，不应该存在这样的差异。我们提供了一个理论框架，解释了这种不对称性如何出现在稀疏性和计算复杂性考虑中，并概述了我们的结果带来的一些展望。

    We study the probabilistic modeling performed by Autoregressive Large Language Models through the angle of time directionality. We empirically find a time asymmetry exhibited by such models in their ability to model natural language: a difference in the average log-perplexity when trying to predict the next token versus when trying to predict the previous one. This difference is at the same time subtle and very consistent across various modalities (language, model size, training time, ...). Theoretically, this is surprising: from an information-theoretic point of view, there should be no such difference. We provide a theoretical framework to explain how such an asymmetry can appear from sparsity and computational complexity considerations, and outline a number of perspectives opened by our results.
    
[^140]: SemPLeS: 语义提示学习用于弱监督语义分割

    SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic Segmentation

    [https://arxiv.org/abs/2401.11791](https://arxiv.org/abs/2401.11791)

    SemPLeS框架利用语义提示学习解决弱监督语义分割中的问题，通过学习有效提示来增强分割区域与目标对象类别之间的语义对齐。

    

    弱监督语义分割（WSSS）旨在利用仅具有图像级监督的图像数据来训练分割模型。由于无法获得精确的像素级标注，现有方法通常侧重于通过优化CAM样式的热图来生成用于训练分割模型的伪标记。然而，生成的热图可能仅捕获对象类别的具有区分性的图像区域或相关的共同出现的背景。为解决这些问题，我们提出了一种用于WSSS的语义提示学习（SemPLeS）框架，该框架学习有效地提示CLIP潜空间以增强分割区域与目标对象类别之间的语义对准。具体而言，我们提出了对比提示学习和提示引导的语义细化，以学习适当描述和抑制与每个目标对象类别相关的共同出现的背景的提示。

    arXiv:2401.11791v2 Announce Type: replace-cross  Abstract: Weakly-Supervised Semantic Segmentation (WSSS) aims to train segmentation models using image data with only image-level supervision. Since precise pixel-level annotations are not accessible, existing methods typically focus on producing pseudo masks for training segmentation models by refining CAM-like heatmaps. However, the produced heatmaps may capture only the discriminative image regions of object categories or the associated co-occurring backgrounds. To address the issues, we propose a Semantic Prompt Learning for WSSS (SemPLeS) framework, which learns to effectively prompt the CLIP latent space to enhance the semantic alignment between the segmented regions and the target object categories. More specifically, we propose Contrastive Prompt Learning and Prompt-guided Semantic Refinement to learn the prompts that adequately describe and suppress the co-occurring backgrounds associated with each target object category. In thi
    
[^141]: 通过诱导性幻觉缓解大型语言模型的幻觉

    Alleviating Hallucinations of Large Language Models through Induced Hallucinations

    [https://arxiv.org/abs/2312.15710](https://arxiv.org/abs/2312.15710)

    通过诱导虚假信息来构建一个事实薄弱的语言模型，并在解码过程中通过对比解码来惩罚这些诱导的虚假信息，从而有效提升生成内容的真实性。

    

    尽管大型语言模型(LLMs)具有令人印象深刻的能力，但已观察到它们生成的响应中包含不准确或虚假信息，这种现象通常称为“幻觉”。在这项工作中，我们提出了一个简单的“诱导-对比解码”(ICD)策略来减轻幻觉。我们首先通过从原始LLMs中诱导幻觉来构建一个事实上薄弱的LLM。然后，在解码过程中惩罚这些诱导的幻觉以增强生成内容的真实性。具体来说，我们通过对比解码来放大原模型的预测并贬低诱导的不真实预测来确定最终的下一个标记预测。对基于歧视和基于生成的幻觉评估基准，如TruthfulQA和FActScore等进行的实验结果表明，我们提出的ICD方法能够有效增强

    arXiv:2312.15710v2 Announce Type: replace-cross  Abstract: Despite their impressive capabilities, large language models (LLMs) have been observed to generate responses that include inaccurate or fabricated information, a phenomenon commonly known as ``hallucination''. In this work, we propose a simple \textit{Induce-then-Contrast} Decoding (ICD) strategy to alleviate hallucinations. We first construct a factually weak LLM by inducing hallucinations from the original LLMs. Then, we penalize these induced hallucinations during decoding to enhance the factuality of the generated content. Concretely, we determine the final next-token predictions by amplifying the predictions from the original model and downplaying the induced untruthful predictions via contrastive decoding. Experimental results on both discrimination-based and generation-based hallucination evaluation benchmarks, such as TruthfulQA and \textsc{FActScore}, demonstrate that our proposed ICD methods can effectively enhance th
    
[^142]: Synergistic Anchored Contrastive Pre-training for Few-Shot Relation Extraction

    Synergistic Anchored Contrastive Pre-training for Few-Shot Relation Extraction

    [https://arxiv.org/abs/2312.12021](https://arxiv.org/abs/2312.12021)

    新提出了一种协同对比预训练框架，利用大量的实例-标签对来丰富学习到的表示

    

    少样本关系抽取（FSRE）旨在从稀疏标记语料库中提取关系事实。最近的研究通过在监督对比学习框架中利用预训练语言模型（PLMs）展现了有希望的FSRE结果，该框架考虑了实例和标签事实。然而，在这种学习范式中如何有效利用大量的实例-标签对来使学习到的表示具有语义丰富性尚未得到充分探讨。为填补这一空白，我们提出了一种新颖的协同对比预训练框架。这个框架的动机是，通过实例-标签对传达的多样观点捕捉到了不完整但互补的文本语义。具体而言，我们的框架涉及一种对称对比目标，包含了句子锚定和标签锚定的对比损失。通过组合这两种损失

    arXiv:2312.12021v3 Announce Type: replace-cross  Abstract: Few-shot Relation Extraction (FSRE) aims to extract relational facts from a sparse set of labeled corpora. Recent studies have shown promising results in FSRE by employing Pre-trained Language Models (PLMs) within the framework of supervised contrastive learning, which considers both instances and label facts. However, how to effectively harness massive instance-label pairs to encompass the learned representation with semantic richness in this learning paradigm is not fully explored. To address this gap, we introduce a novel synergistic anchored contrastive pre-training framework. This framework is motivated by the insight that the diverse viewpoints conveyed through instance-label pairs capture incomplete yet complementary intrinsic textual semantics. Specifically, our framework involves a symmetrical contrastive objective that encompasses both sentence-anchored and label-anchored contrastive losses. By combining these two los
    
[^143]: 构建Vec-tionaries以从文本中提取消息特征：一项道德呼吁的案例研究

    Constructing Vec-tionaries to Extract Message Features from Texts: A Case Study of Moral Appeals

    [https://arxiv.org/abs/2312.05990](https://arxiv.org/abs/2312.05990)

    通过构建vec-tionaries测量工具，该方法通过非线性优化将经过验证的词典与词嵌入相结合，改善了从文本中提取消息特征的测量，尤其是短格式中的那些，通过将原始词汇表的适用性扩展到其他语境。

    

    虽然研究人员经常研究文本中的道德内容等消息特征，比如政党宣言和社交媒体，但它们的量化仍然是一个挑战。传统的人工编码在可伸缩性和互码者可靠性方面存在问题。本文提出一种构建vec-tionaries测量工具的方法，通过非线性优化将经过验证的词典与词嵌入相结合，通过利用嵌入编码的语义关系，vec-tionaries改善了从文本中提取消息特征的测量，尤其是短格式中的那些，通过将原始词汇表的适用性扩展到其他语境。

    arXiv:2312.05990v2 Announce Type: replace  Abstract: While researchers often study message features like moral content in text, such as party manifestos and social media, their quantification remains a challenge. Conventional human coding struggles with scalability and intercoder reliability. While dictionary-based methods are cost-effective and computationally efficient, they often lack contextual sensitivity and are limited by the vocabularies developed for the original applications. In this paper, we present an approach to construct vec-tionary measurement tools that boost validated dictionaries with word embeddings through nonlinear optimization. By harnessing semantic relationships encoded by embeddings, vec-tionaries improve the measurement of message features from text, especially those in short format, by expanding the applicability of original vocabularies to other contexts. Importantly, a vec-tionary can produce additional metrics to capture the valence and ambivalence of a m
    
[^144]: 比较用于端到端关系抽取的管道、序列到序列和GPT模型：以罕见疾病用例为实验

    Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case

    [https://arxiv.org/abs/2311.13729](https://arxiv.org/abs/2311.13729)

    本文比较了用于端到端关系抽取的管道、序列到序列和GPT模型，发现管道模型仍然是最佳选择，而序列到序列模型紧随其后；参数量增加八倍的GPT模型甚至比序列到序列模型更差，且比管道模型低10个F1点以上。

    

    端到端关系抽取（E2ERE）是自然语言处理（NLP）在生物医学中的一个重要而现实的应用。本文旨在使用一个关注罕见疾病、涉及不连续和嵌套实体的复杂数据集，比较E2ERE的三种流行范式。我们使用RareDis信息提取数据集评估了三种竞争方法（用于E2ERE）：实体识别（NER）→关系抽取（RE）管道、联合序列到序列模型和生成式预训练变压器（GPT）模型。我们针对每种方法使用可比的最先进模型和最佳实践，并进行错误分析以评估它们的失败模式。我们的发现显示，管道模型仍然是最佳选择，而序列到序列模型紧随其后；参数量增加八倍的GPT模型甚至比序列到序列模型更差，且比管道模型低10个F1点以上。

    arXiv:2311.13729v2 Announce Type: replace  Abstract: End-to-end relation extraction (E2ERE) is an important and realistic application of natural language processing (NLP) in biomedicine. In this paper, we aim to compare three prevailing paradigms for E2ERE using a complex dataset focused on rare diseases involving discontinuous and nested entities. We use the RareDis information extraction dataset to evaluate three competing approaches (for E2ERE): NER $\rightarrow$ RE pipelines, joint sequence to sequence models, and generative pre-trained transformer (GPT) models. We use comparable state-of-the-art models and best practices for each of these approaches and conduct error analyses to assess their failure modes. Our findings reveal that pipeline models are still the best, while sequence-to-sequence models are not far behind; GPT models with eight times as many parameters are worse than even sequence-to-sequence models and lose to pipeline models by over 10 F1 points. Partial matches and
    
[^145]: 大脑记录中的语言生成

    Language Generation from Brain Recordings

    [https://arxiv.org/abs/2311.09889](https://arxiv.org/abs/2311.09889)

    提出了一种在大脑记录中直接生成语言的方法，结合了大型语言模型和语义脑解码器，实现了从功能性磁共振成像输入生成与语义内容一致的连贯语言序列。

    

    通过非侵入式脑-计算机接口（BCIs）生成人类语言具有潜力解锁许多应用，如为残疾患者提供服务和改善沟通。然而，目前通过BCIs生成语言仅在分类设置内成功，用于选择带有最可能的皮层语义表示的预生成句子延续候选。受到最近显示大脑与大型计算语言模型之间关联的研究的启发，我们提出了一个生成语言BCI，该BCI利用大型语言模型（LLM）的能力，与语义脑解码器共同生成语言，直接从功能性磁共振成像（fMRI）输入中生成语言。所提出的模型可以生成与感知到的视觉或听觉语言刺激的语义内容一致的语言序列，而无需事先知道任何预定

    arXiv:2311.09889v4 Announce Type: replace  Abstract: Generating human language through non-invasive brain-computer interfaces (BCIs) has the potential to unlock many applications, such as serving disabled patients and improving communication. Currently, however, generating language via BCIs has been previously successful only within a classification setup for selecting pre-generated sentence continuation candidates with the most likely cortical semantic representation. Inspired by recent research that revealed associations between the brain and the large computational language models, we propose a generative language BCI that utilizes the capacity of a large language model (LLM) jointly with a semantic brain decoder to directly generate language from functional magnetic resonance imaging (fMRI) input. The proposed model can generate coherent language sequences aligned with the semantic content of visual or auditory language stimuli perceived, without prior knowledge of any pre-generate
    
[^146]: 有效的大型语言模型适应以提升信息关联和引用生成

    Effective Large Language Model Adaptation for Improved Grounding and Citation Generation

    [https://arxiv.org/abs/2311.09533](https://arxiv.org/abs/2311.09533)

    本文提出了一个新的框架 AGREE，通过将大型语言模型的响应联系到检索到的段落并提供引文来提升信息关联，从而解决大型语言模型可能生成“臆想”答案的问题

    

    大型语言模型（LLMs）在自然语言理解和生成方面取得了显著进展。然而，一大问题在于它们可能生成“臆想”的答案并非事实。为解决这一问题，本文着眼于通过将LLMs的响应联系到检索到的段落并提供引文来改进它们。我们提出了一个新的框架AGREE，即Adaptation for GRounding EnhancEment，从整体的角度提升了信息关联。我们的框架调整LLMs，使其自我联系其响应中的主张并为检索文档提供准确的引文。在预训练的LLMs基础上进行的这种调整需要对配对查询的响应进行很好的信息关联（带有引文），为此我们介绍了一种能够从未标记查询自动构造这些数据的方法。调整后的LLMs的自我关联能力进一步使其测试时间适应

    arXiv:2311.09533v2 Announce Type: replace  Abstract: Large language models (LLMs) have achieved remarkable advancements in natural language understanding and generation. However, one major issue towards their widespread deployment in the real world is that they can generate "hallucinated" answers that are not factual. Towards this end, this paper focuses on improving LLMs by grounding their responses in retrieved passages and by providing citations. We propose a new framework, AGREE, Adaptation for GRounding EnhancEment, that improves the grounding from a holistic perspective. Our framework tunes LLMs to selfground the claims in their responses and provide accurate citations to retrieved documents. This tuning on top of the pre-trained LLMs requires well-grounded responses (with citations) for paired queries, for which we introduce a method that can automatically construct such data from unlabeled queries. The selfgrounding capability of tuned LLMs further grants them a test-time adapt
    
[^147]: VERVE: 基于模板的反思重写用于激励性面谈

    VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing

    [https://arxiv.org/abs/2311.08299](https://arxiv.org/abs/2311.08299)

    这项工作引入了 counseling response rewriting 任务，提出了基于模板的 VERVE 系统，通过加入释义的训练和自适应模板更新，将非反思性陈述转化为反思性回应。

    

    反思式倾听是心理辅导师必须掌握的基本技能，以在激励性面谈中达到熟练水平。它涉及以一种承认和探索客户对话中表达的意义的方式进行回应。在这项工作中，我们引入了辅导响应重写的任务，将非反思性陈述转化为反思性回应。我们提出了VERVE，一个基于模板的重写系统，具有加入释义的训练和自适应模板更新。VERVE首先通过识别和过滤与反思无关的标记来创建模板，并使用模板构建反思式回应。释义增强训练使模型能够学习对掩码空间进行较不严格的填充，而自适应模板更新则有助于发现重写的有效模板，而不会显著移除原始内容。使用自动和

    arXiv:2311.08299v2 Announce Type: replace-cross  Abstract: Reflective listening is a fundamental skill that counselors must acquire to achieve proficiency in motivational interviewing (MI). It involves responding in a manner that acknowledges and explores the meaning of what the client has expressed in the conversation. In this work, we introduce the task of counseling response rewriting, which transforms non-reflective statements into reflective responses. We introduce VERVE, a template-based rewriting system with paraphrase-augmented training and adaptive template updating. VERVE first creates a template by identifying and filtering out tokens that are not relevant to reflections and constructs a reflective response using the template. Paraphrase-augmented training allows the model to learn less-strict fillings of masked spans, and adaptive template updating helps discover effective templates for rewriting without significantly removing the original content. Using both automatic and 
    
[^148]: 从聊天机器人到网络钓鱼机器人？-- 预防使用 ChatGPT、Google Bard 和 Claude 创建的网络钓鱼诈骗

    From Chatbots to PhishBots? -- Preventing Phishing scams created using ChatGPT, Google Bard and Claude

    [https://arxiv.org/abs/2310.19181](https://arxiv.org/abs/2310.19181)

    研究探讨了使用 ChatGPT、Google Bard 和 Claude 创建网络钓鱼攻击的潜力，发现这些大型语言模型可以生成逼真的网络钓鱼网站和电子邮件，并采用逃避检测机制的策略。

    

    大型语言模型（LLMs）的高级功能使它们在各种应用中变得不可或缺，包括对话代理、内容创作、数据分析、研究和创新。然而，它们的有效性和可访问性也使它们容易被滥用来生成恶意内容，包括网络钓鱼攻击。本研究探讨了使用四种流行的商业可用的LLMs（ChatGPT（GPT 3.5 Turbo）、GPT 4、Claude 和 Bard）来生成功能性网络钓鱼攻击的潜力，使用一系列恶意提示。我们发现这些LLMs可以生成既能够逼真模仿知名品牌又能够部署一系列逃避探测机制的网络钓鱼网站和电子邮件。这些攻击可以使用这些LLMs的未修改或“原始”版本生成，而无需任何先前的敌对训练。

    arXiv:2310.19181v2 Announce Type: replace-cross  Abstract: The advanced capabilities of Large Language Models (LLMs) have made them invaluable across various applications, from conversational agents and content creation to data analysis, research, and innovation. However, their effectiveness and accessibility also render them susceptible to abuse for generating malicious content, including phishing attacks. This study explores the potential of using four popular commercially available LLMs, i.e., ChatGPT (GPT 3.5 Turbo), GPT 4, Claude, and Bard, to generate functional phishing attacks using a series of malicious prompts. We discover that these LLMs can generate both phishing websites and emails that can convincingly imitate well-known brands and also deploy a range of evasive tactics that are used to elude detection mechanisms employed by anti-phishing systems. These attacks can be generated using unmodified or "vanilla" versions of these LLMs without requiring any prior adversarial ex
    
[^149]: 基于Transformer中自适应多头注意力机制的情感分析

    Sentiment analysis with adaptive multi-head attention in Transformer

    [https://arxiv.org/abs/2310.14505](https://arxiv.org/abs/2310.14505)

    提出了一种基于Transformer的自适应多头注意力架构，根据句子长度变化头数，用于电影评论文档的情感分析。

    

    我们提出了一个基于注意力机制的新框架，用于识别电影评论文档的情感。我们的论文中提出了一种自适应多头注意力架构（AdaptAttn），根据句子长度变化头数。AdaptAttn有一个数据预处理步骤，根据句子长度将每个文档分类为三个桶中的任一个：小、中或大。我们在斯坦福大型电影评论数据集上检验了我们模型的优点。

    arXiv:2310.14505v4 Announce Type: replace  Abstract: We propose a novel framework based on the attention mechanism to identify the sentiment of a movie review document. Previous efforts on deep neural networks with attention mechanisms focus on encoder and decoder with fixed numbers of multi-head attention. Therefore, we need a mechanism to stop the attention process automatically if no more useful information can be read from the memory.In this paper, we propose an adaptive multi-head attention architecture (AdaptAttn) which varies the number of attention heads based on length of sentences. AdaptAttn has a data preprocessing step where each document is classified into any one of the three bins small, medium or large based on length of the sentence. The document classified as small goes through two heads in each layer, the medium group passes four heads and the large group is processed by eight heads. We examine the merit of our model on the Stanford large movie review dataset. The exp
    
[^150]: Prometheus: 在语言模型中引入细粒度评估能力

    Prometheus: Inducing Fine-grained Evaluation Capability in Language Models

    [https://arxiv.org/abs/2310.08491](https://arxiv.org/abs/2310.08491)

    Prometheus是一个开源的LLM，通过使用自定义评分标准和适当的参考材料，可以在与GPT-4相媲美的评估能力上进行评估。

    

    最近，使用强大的专有大型语言模型（例如GPT-4）作为长篇回答的评估者已经成为事实上的标准。然而，对于具有大规模评估任务和考虑自定义标准（例如儿童可读性）的从业者来说，使用专有LLMs作为评估者是不可靠的，这是由于其闭源性质、无控制的版本和高昂的成本。在这项工作中，我们提出了Prometheus，这是一个完全开源的LLM，只要携带适当的参考材料（参考答案、评分标准），就可以与GPT-4的评估能力相媲美。我们首先构建了反馈收集（Feedback Collection），这是一个由1K个细粒度评分标准、20K条指令和GPT-4生成的100K条响应和语言反馈组成的新数据集。使用这个反馈收集，我们训练了Prometheus，一个13B的评估者LLM，可以根据定制的评分标准评估任何给定的长篇文本。

    arXiv:2310.08491v2 Announce Type: replace  Abstract: Recently, using a powerful proprietary Large Language Model (LLM) (e.g., GPT-4) as an evaluator for long-form responses has become the de facto standard. However, for practitioners with large-scale evaluation tasks and custom criteria in consideration (e.g., child-readability), using proprietary LLMs as an evaluator is unreliable due to the closed-source nature, uncontrolled versioning, and prohibitive costs. In this work, we propose Prometheus, a fully open-source LLM that is on par with GPT-4's evaluation capabilities when the appropriate reference materials (reference answer, score rubric) are accompanied. We first construct the Feedback Collection, a new dataset that consists of 1K fine-grained score rubrics, 20K instructions, and 100K responses and language feedback generated by GPT-4. Using the Feedback Collection, we train Prometheus, a 13B evaluator LLM that can assess any given long-form text based on customized score rubric
    
[^151]: 从文本到自我：用户对人工智能在人际交流和自我方面潜力的认知

    From Text to Self: Users' Perceptions of Potential of AI on Interpersonal Communication and Self

    [https://arxiv.org/abs/2310.03976](https://arxiv.org/abs/2310.03976)

    用户对大型语言模型驱动的工具在人际交流方面的能力持积极看法，认为可以增加沟通自信、帮助表达想法以及克服语言和文化障碍，但也揭示出工具存在的一些局限性和用户关于技术不真实性和过度依赖的担忧。

    

    在快速发展的AI中介交流（AIMC）领域中，由大型语言模型（LLMs）驱动的工具正成为人际交流的重要组成部分。采用混合方法，我们进行了为期一周的日记和访谈研究，探讨了用户对这些工具在短期内支持人际交流的能力和可能导致的长期效果的看法。我们的研究发现，参与者对AIMC支持持有积极看法，认为其能够增加沟通自信，帮助找到准确的语言表达想法，以及克服语言和文化障碍。然而，研究还揭示了AIMC工具目前存在的局限，包括啰嗦的回复、不自然的回应以及过度情绪化。这些缺陷进一步受到用户对不真实性和对技术过度依赖的担忧所加剧。此外，我们确定了

    arXiv:2310.03976v2 Announce Type: cross  Abstract: In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users' perceptions of these tools' ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, and finding precise language to express their thoughts, navigating linguistic and cultural barriers. However, the study also uncovers current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. Furthermore, we identified fou
    
[^152]: DiffAR：去噪扩散自回归模型用于原始语音波形生成

    DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation

    [https://arxiv.org/abs/2310.01381](https://arxiv.org/abs/2310.01381)

    本研究提出了一个扩散概率端到端模型，用于生成原始语音波形，实现了高保真合成和时间一致性，可实现无限语音持续时间，并支持无条件和有条件语音生成。

    

    近期，扩散模型已被证明与高质量语音生成相关。大多数工作集中在生成频谱图，因此进一步需要后续模型将频谱图转换为波形（即声码器）。本文提出了一个扩散概率端到端模型，用于生成原始语音波形。所提出的模型是自回归的，按顺序生成重叠帧，其中每个帧依赖于先前生成的部分。因此，我们的模型可以有效地合成无限语音持续时间，同时保持高保真合成和时间一致性。我们为无条件和有条件语音生成实现了所提出的模型，后者可以由输入的音素序列、振幅和音调值驱动。直接处理波形具有一些经验优势。具体来说，它允许创建

    arXiv:2310.01381v3 Announce Type: replace-cross  Abstract: Diffusion models have recently been shown to be relevant for high-quality speech generation. Most work has been focused on generating spectrograms, and as such, they further require a subsequent model to convert the spectrogram to a waveform (i.e., a vocoder). This work proposes a diffusion probabilistic end-to-end model for generating a raw speech waveform. The proposed model is autoregressive, generating overlapping frames sequentially, where each frame is conditioned on a portion of the previously generated one. Hence, our model can effectively synthesize an unlimited speech duration while preserving high-fidelity synthesis and temporal coherence. We implemented the proposed model for unconditional and conditional speech generation, where the latter can be driven by an input sequence of phonemes, amplitudes, and pitch values. Working on the waveform directly has some empirical advantages. Specifically, it allows the creation
    
[^153]: 基于节点加权的图卷积网络用于分析转录的临床面谈中的抑郁症检测

    Node-weighted Graph Convolutional Network for Depression Detection in Transcribed Clinical Interviews

    [https://arxiv.org/abs/2307.00920](https://arxiv.org/abs/2307.00920)

    提出了一种基于节点加权的图卷积网络方法，用于在临床面谈转录中检测抑郁症，相较于传统方法，在两个数据集上取得了更好的效果。

    

    我们提出了一种简单的方法，用于在图卷积网络（GCN）中加权自连接边，并展示其对从转录的临床面谈中进行抑郁症检测的影响。为此，我们使用GCN来对转录进行建模，以将其分类为抑郁症患者或对照组。所提出的方法旨在减轻GCN中对局部性和自连接与相邻节点边的等重要性的限制性假设，同时保留了诸如低计算成本、数据不可知和可解释性能力等有吸引力的特征。我们在两个基准数据集上进行了详尽的评估。结果表明，我们的方法始终优于基准GCN模型以及先前报告的结果，在两个数据集上均达到了F1=0.84。最后，定性分析展示了所提出方法的可解释性能力。

    arXiv:2307.00920v2 Announce Type: replace-cross  Abstract: We propose a simple approach for weighting self-connecting edges in a Graph Convolutional Network (GCN) and show its impact on depression detection from transcribed clinical interviews. To this end, we use a GCN for modeling non-consecutive and long-distance semantics to classify the transcriptions into depressed or control subjects. The proposed method aims to mitigate the limiting assumptions of locality and the equal importance of self-connections vs. edges to neighboring nodes in GCNs, while preserving attractive features such as low computational cost, data agnostic, and interpretability capabilities. We perform an exhaustive evaluation in two benchmark datasets. Results show that our approach consistently outperforms the vanilla GCN model as well as previously reported results, achieving an F1=0.84 on both datasets. Finally, a qualitative analysis illustrates the interpretability capabilities of the proposed approach and 
    
[^154]: TransERR:通过高效关系旋转的基于翻译的知识图嵌入方法

    TransERR: Translation-based Knowledge Graph Embedding via Efficient Relation Rotation

    [https://arxiv.org/abs/2306.14580](https://arxiv.org/abs/2306.14580)

    TransERR是一种基于翻译的知识图嵌入方法，采用超复值空间编码知识图，在模型训练中通过适应性旋转头实体和尾实体来最小化翻译距离，并具有有效建模不同关系模式的能力。

    

    本文提出了一种通过高效关系旋转（TransERR）实现的基于翻译的知识图嵌入方法，这是传统基于翻译的知识图嵌入模型的一种简单且有效的替代方案。与先前的基于翻译模型不同，TransERR在超复值空间中对知识图进行编码，从而使其能够在挖掘头部和尾部实体之间的潜在信息时具有更高程度的翻译自由度。为进一步减小翻译距离，TransERR通过它们各自可学习的单位四元数适应性地旋转头实体和尾实体。我们还提供数学证明来展示TransERR在建模各种关系模式（包括对称性、反对称性、倒置、合成和子关系模式）方面的能力。对10个基准数据集的实验验证了其有效性。

    arXiv:2306.14580v2 Announce Type: replace-cross  Abstract: This paper presents a translation-based knowledge geraph embedding method via efficient relation rotation (TransERR), a straightforward yet effective alternative to traditional translation-based knowledge graph embedding models. Different from the previous translation-based models, TransERR encodes knowledge graphs in the hypercomplex-valued space, thus enabling it to possess a higher degree of translation freedom in mining latent information between the head and tail entities. To further minimize the translation distance, TransERR adaptively rotates the head entity and the tail entity with their corresponding unit quaternions, which are learnable in model training. We also provide mathematical proofs to demonstrate the ability of TransERR in modeling various relation patterns, including symmetry, antisymmetry, inversion, composition, and subrelation patterns. The experiments on 10 benchmark datasets validate the effectiveness 
    
[^155]: M4: 多生成器、多领域和多语言黑匣子机器生成文本检测

    M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection

    [https://arxiv.org/abs/2305.14902](https://arxiv.org/abs/2305.14902)

    大型语言模型产生的文本可能被滥用，研究引入了名为M4的跨领域、多语言语料库，揭示了检测器在未知领域或模型上泛化的困难，指出存在改进空间。

    

    大型语言模型（LLMs）已经展示出在回答各种用户查询时生成流畅回答的显著能力。然而，这也引发了对这些文本在新闻、教育和学术领域潜在误用的担忧。在本研究中，我们努力创建可以检测机器生成文本并指出潜在误用的自动系统。我们首先引入了一个大规模基准M4，这是一个多生成器、多领域和多语言的用于机器生成文本检测的语料库。通过对这个数据集的广泛实证研究，我们展示了检测器很难在来自未见领域或LLMs的实例上很好地泛化。在这种情况下，检测器往往会误将机器生成的文本分类为人工编写的。这些结果表明，这个问题还远未解决，还有很大的改进空间。我们相信我们的数据集将促进未来研究。

    arXiv:2305.14902v2 Announce Type: replace  Abstract: Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark \textbf{M4}, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research tow
    
[^156]: 通过交叉模型比较损失增强语言理解中神经元效用

    Cross-Model Comparative Loss for Enhancing Neuronal Utility in Language Understanding

    [https://arxiv.org/abs/2301.03765](https://arxiv.org/abs/2301.03765)

    本论文提出通过交叉模型比较损失的方法来增强语言理解模型中神经元的效用，实现减少冗余参数和抑制输入噪声的目标。

    

    当前自然语言理解（NLU）模型在模型规模和输入背景方面不断扩大，引入了更多隐藏神经元和输入神经元，大体上提高了性能。然而，额外的神经元并不能为所有实例带来一致的改进，因为一些隐藏神经元是冗余的，混入输入神经元的噪声往往会分散模型的注意力。之前的工作主要侧重于通过附加的后处理或预处理，如网络修剪和上下文选择，从外部降低低效神经元的数量，以避免这个问题。除此之外，我们是否可以通过增强每个神经元的效用来使模型减少冗余参数并抑制输入噪声？如果一个模型能够有效地利用神经元，那么不管哪些神经元被剥离（禁用），剥离后的子模型的性能都不应该优于原始完整模型。根据这样的比较

    arXiv:2301.03765v2 Announce Type: replace  Abstract: Current natural language understanding (NLU) models have been continuously scaling up, both in terms of model size and input context, introducing more hidden and input neurons. While this generally improves performance on average, the extra neurons do not yield a consistent improvement for all instances. This is because some hidden neurons are redundant, and the noise mixed in input neurons tends to distract the model. Previous work mainly focuses on extrinsically reducing low-utility neurons by additional post- or pre-processing, such as network pruning and context selection, to avoid this problem. Beyond that, can we make the model reduce redundant parameters and suppress input noise by intrinsically enhancing the utility of each neuron? If a model can efficiently utilize neurons, no matter which neurons are ablated (disabled), the ablated submodel should perform no better than the original full model. Based on such a comparison pr
    
[^157]: 一种用于双语词典归纳的判别式潜变量模型

    A Discriminative Latent-Variable Model for Bilingual Lexicon Induction

    [https://arxiv.org/abs/1808.09334](https://arxiv.org/abs/1808.09334)

    引入判别式潜变量模型，结合先前研究的词典先验和表示法，提出了用于双语词典归纳的新方法，并通过实验证据展示先验可以改善诱导的双语词典。

    

    我们引入了一种新颖的用于双语词典归纳的判别式潜变量模型。我们的模型将Haghighi等人（2008）的二分匹配词典先验与基于表示的方法（Artetxe等人，2017）相结合。为了训练模型，我们推导出了高效的Viterbi EM算法。我们在两个度量标准下对六种语言对进行了实证结果，并显示先验改善了诱导的双语词典。我们还演示了如何将先前的工作视为类似风格的潜变量模型，尽管有不同的先验。

    arXiv:1808.09334v3 Announce Type: replace  Abstract: We introduce a novel discriminative latent variable model for bilingual lexicon induction. Our model combines the bipartite matching dictionary prior of Haghighi et al. (2008) with a representation-based approach (Artetxe et al., 2017). To train the model, we derive an efficient Viterbi EM algorithm. We provide empirical results on six language pairs under two metrics and show that the prior improves the induced bilingual lexicons. We also demonstrate how previous work may be viewed as a similarly fashioned latent-variable model, albeit with a different prior.
    
[^158]: 真知来源于实践：通过强化学习使LLMs与具身环境对齐的方法研究

    True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning. (arXiv:2401.14151v1 [cs.LG])

    [http://arxiv.org/abs/2401.14151](http://arxiv.org/abs/2401.14151)

    本研究通过使用大型语言模型（LLMs）作为决策智能体，通过强化学习与具身环境高效互动来解决LLMs与环境之间知识不对齐的问题。通过查询LLMs的联合概率，形成行为策略，并通过两种归一化方法和四个提示设计原则提高策略的稳定性和鲁棒性。最后，通过设计参数高效的训练架构提高学习效率。

    

    尽管在众多任务中取得了令人印象深刻的表现，但大型语言模型（LLMs）在解决简单的决策任务上经常失败，原因是LLMs中的知识与环境不对齐。相反，强化学习（RL）智能体从零开始学习策略，这使得它们始终与环境保持一致，但难以将先前的知识整合到其中以进行有效的探索。为了缩小这一差距，我们提出了TWOSOME，一种新颖的在线框架，利用LLMs作为决策智能体，通过RL与具身环境高效互动并实现对齐，而无需任何准备好的数据集或环境的先前知识。首先，我们使用LLMs查询每个有效动作的联合概率以形成行为策略。然后，为了增强策略的稳定性和鲁棒性，我们提出了两种归一化方法，并总结了四个提示设计原则。最后，我们设计了一种新颖的参数高效的训练架构，其中包括一个行为评估和选择算法来提高学习效率。

    Despite the impressive performance across numerous tasks, large language models (LLMs) often fail in solving simple decision-making tasks due to the misalignment of the knowledge in LLMs with environments. On the contrary, reinforcement learning (RL) agents learn policies from scratch, which makes them always align with environments but difficult to incorporate prior knowledge for efficient explorations. To narrow the gap, we propose TWOSOME, a novel general online framework that deploys LLMs as decision-making agents to efficiently interact and align with embodied environments via RL without requiring any prepared datasets or prior knowledge of the environments. Firstly, we query the joint probabilities of each valid action with LLMs to form behavior policies. Then, to enhance the stability and robustness of the policies, we propose two normalization methods and summarize four prompt design principles. Finally, we design a novel parameter-efficient training architecture where the acto
    
[^159]: 中文数据处理中的佼佼者：英文代码模型

    Top in Chinese Data Processing: English Code Models. (arXiv:2401.10286v1 [cs.CL])

    [http://arxiv.org/abs/2401.10286](http://arxiv.org/abs/2401.10286)

    在中文数据处理中，基于代码的语言模型在非编程中文任务中表现出色，尤其是在对中文幻觉敏感的任务中。此研究为讨论“中文房间”思想实验提供了独特的视角。

    

    尽管在语言模型的应用中，任务与训练语料之间的对齐是一个基本的共识，但我们的一系列实验和我们设计的评估指标表明，基于代码的大型语言模型(LLMs)在非编程中文任务中的表现明显优于与任务紧密匹配的训练数据。此外，在对中文幻觉敏感程度较高的任务中，展示较少中文语言特征的模型表现更好。我们的实验结果可以通过简单地用代码模型替换基础模型，在中文数据处理任务中，如为检索增强生成(RAG)准备数据，很容易得到复制。此外，我们的研究为讨论“中文房间”思想实验提供了独特的视角。

    While the alignment between tasks and training corpora is a fundamental consensus in the application of language models, our series of experiments and the metrics we designed reveal that code-based Large Language Models (LLMs) significantly outperform models trained on data that is closely matched to the tasks in non-coding Chinese tasks. Moreover, in tasks high sensitivity to Chinese hallucinations, models exhibiting fewer linguistic features of the Chinese language achieve better performance. Our experimental results can be easily replicated in Chinese data processing tasks, such as preparing data for Retrieval-Augmented Generation (RAG), by simply replacing the base model with a code-based model. Additionally, our research offers a distinct perspective for discussion on the philosophical "Chinese Room" thought experiment.
    
[^160]: InfiAgent-DABench: 在数据分析任务中评估代理的基准测试

    InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks. (arXiv:2401.05507v1 [cs.CL])

    [http://arxiv.org/abs/2401.05507](http://arxiv.org/abs/2401.05507)

    InfiAgent-DABench是第一个评估基于LLM的代理在数据分析任务中的基准测试，包括DAEval数据集和代理框架。对23个最先进的LLMs进行的基准测试揭示了当前数据分析任务中的挑战。

    

    本文介绍了"InfiAgent-DABench"，这是第一个专门设计用于评估基于LLM的代理在数据分析任务中的基准测试。该基准测试包含DAEval，这是一个由55个CSV文件衍生出的311个数据分析问题的数据集，以及一个评估LLMs作为数据分析代理的代理框架。我们采用了一种格式提示技术，确保问题是闭合形式的，可以自动评估。我们对23个最先进的LLMs进行了广泛的基准测试，揭示了数据分析任务中当前遇到的挑战。此外，我们还开发了DAAgent，这是一个在指令调优数据集上训练的专门代理。InfiAgent-DABench的评估数据集和工具包已经发布在https://github.com/InfiAgent/InfiAgent上。

    In this paper, we introduce "InfiAgent-DABench", the first benchmark specifically designed to evaluate LLM-based agents in data analysis tasks. This benchmark contains DAEval, a dataset consisting of 311 data analysis questions derived from 55 CSV files, and an agent framework to evaluate LLMs as data analysis agents. We adopt a format-prompting technique, ensuring questions to be closed-form that can be automatically evaluated. Our extensive benchmarking of 23 state-of-the-art LLMs uncovers the current challenges encountered in data analysis tasks. In addition, we have developed DAAgent, a specialized agent trained on instruction-tuning datasets. Evaluation datasets and toolkits for InfiAgent-DABench are released at https://github.com/InfiAgent/InfiAgent.
    
[^161]: 基于大型语言模型的对话代理的即插即用策略规划器

    Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents. (arXiv:2311.00262v1 [cs.CL])

    [http://arxiv.org/abs/2311.00262](http://arxiv.org/abs/2311.00262)

    基于大型语言模型的对话代理的即插即用策略规划器(PDDPP)引入了一种新的对话策略规划范式，通过可调整的语言模型插件实现主动对话问题的策略制定。利用监督微调和强化学习，该框架在处理新的案例时具有较高的灵活性和性能。

    

    在大型语言模型（LLMs）的时代中，主动对话作为一个实际但具有挑战性的对话问题，对话策略规划是提高LLMs主动性的关键。大多数现有研究使用各种提示方案或通过语言人工智能反馈迭代增强对LLMs的对话策略规划能力。然而，这些方法要么受限于冻结的LLMs的策略规划能力，要么难以转移到新的案例。在这项工作中，我们引入了一种新的对话策略规划范式，以使用可调整的语言模型插件作为即插即用的对话策略规划器来制定LLMs在主动对话问题上的策略，命名为PPDPP。具体而言，我们开发了一个新颖的训练框架，以便利用可用的人工注释数据进行监督微调，并通过基于LLM的自我对弈收集的动态交互数据进行强化学习。

    Proactive dialogues serve as a practical yet challenging dialogue problem in the era of large language models (LLMs), where the dialogue policy planning is the key to improving the proactivity of LLMs. Most existing studies enable the dialogue policy planning of LLMs using various prompting schemes or iteratively enhance this capability in handling the given case with verbal AI feedback. However, these approaches are either bounded by the policy planning capability of the frozen LLMs or hard to be transferred to new cases. In this work, we introduce a new dialogue policy planning paradigm to strategize LLMs for proactive dialogue problems with a tunable language model plug-in as a plug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a novel training framework to facilitate supervised fine-tuning over available human-annotated data as well as reinforcement learning from goal-oriented AI feedback with dynamic interaction data collected by the LLM-based self-play s
    
[^162]: 使用大型语言模型进行文本属性图的解缠表征学习

    Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs. (arXiv:2310.18152v1 [cs.CL])

    [http://arxiv.org/abs/2310.18152](http://arxiv.org/abs/2310.18152)

    本文提出了一个名为Disentangled Graph-Text Learner (DGTL)的模型，通过引入定制的解缠图神经网络（GNN）层，使得大型语言模型（LLMs）能够更好地理解文本属性图（TAGs）中的复杂结构关系。

    

    文本属性图（TAGs）在网络上非常常见，对于该类图，如引用网络、电子商务网络和社交网络的研究在网络社区中引起了相当大的关注。最近，大型语言模型（LLMs）在各种任务上展示了出色的能力。然而，现有的工作仅仅依靠提示信息来传达图结构信息给LLMs，因此对于TAGs中复杂的结构关系了解不足。为解决这个问题，本文提出了解缠图文学习器（DGTL）模型，能够增强LLMs对TAGs的推理和预测能力。我们的DGTL模型通过定制的解缠图神经网络（GNN）层将图结构信息纳入其中，使得LLMs能够捕捉多个结构因素中隐藏的复杂关系。

    Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs such as citation networks, e-commerce networks and social networks has attracted considerable attention in the web community. Recently, large language models (LLMs) have demonstrated exceptional capabilities across a wide range of tasks. However, the existing works focus on harnessing the potential of LLMs solely relying on prompts to convey graph structure information to LLMs, thus suffering from insufficient understanding of the complex structural relationships within TAGs. To address this problem, in this paper we present the Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the reasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model incorporates graph structure information through tailored disentangled graph neural network (GNN) layers, enabling LLMs to capture the intricate relationships hidden in text-attributed graphs from multiple structural factors. Furthe
    
[^163]: 检测大型语言模型的预训练数据

    Detecting Pretraining Data from Large Language Models. (arXiv:2310.16789v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.16789](http://arxiv.org/abs/2310.16789)

    这项研究探讨了如何检测大型语言模型的预训练数据，提出了一个动态基准和一种新的检测方法，以解决数据隐私和不透明性的问题。

    

    虽然大型语言模型（LLM）被广泛应用，但用于训练它们的数据很少被公开。考虑到这些数据的规模之大，可能包含受版权保护的材料、个人可识别信息以及用于广泛报道的参考基准测试数据，我们几乎可以肯定它们包含了潜在的问题文本。然而，我们目前无法知道这些文本中包含了哪些类型的数据以及比例。在本文中，我们研究了预训练数据检测问题：在不知道预训练数据的情况下，给定一段文本和对LLM的黑盒访问，我们能否确定模型是否是在提供的文本上进行了训练？为了方便这项研究，我们引入了一个动态基准WIKIMIA，使用在模型训练之前和之后创建的数据来支持金标准检测。我们还引入了一种新的检测方法Min-K% Prob，基于一个简单的假设：一个未见过的例子可能包含几个具有较低概率的离群词。

    Although large language models (LLMs) are widely deployed, the data used to train them is rarely disclosed. Given the incredible scale of this data, up to trillions of tokens, it is all but certain that it includes potentially problematic text such as copyrighted materials, personally identifiable information, and test data for widely reported reference benchmarks. However, we currently have no way to know which data of these types is included or in what proportions. In this paper, we study the pretraining data detection problem: given a piece of text and black-box access to an LLM without knowing the pretraining data, can we determine if the model was trained on the provided text? To facilitate this study, we introduce a dynamic benchmark WIKIMIA that uses data created before and after model training to support gold truth detection. We also introduce a new detection method Min-K% Prob based on a simple hypothesis: an unseen example is likely to contain a few outlier words with low pro
    
[^164]: 文化和语言多样性提高了视觉表示

    Cultural and Linguistic Diversity Improves Visual Representations. (arXiv:2310.14356v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2310.14356](http://arxiv.org/abs/2310.14356)

    这项研究发现数据集和模型生成的图像描述在不同语言间存在显著的语义差异，多语言数据有更高的语义覆盖率，并且基于多语言训练的模型表现更好。

    

    计算机视觉通常将感知视为客观的，并且这种假设在数据集收集和模型训练中得到反映。例如，不同语言的图像描述通常被假定为相同语义内容的翻译。然而，跨文化心理学和语言学的研究表明，个体的视觉感知因其文化背景和所说的语言而异。在本文中，我们展示了在数据集和模型生成的标题中，不同语言之间存在显著的语义内容差异。当数据是多语言而不是单语言时，标题的语义覆盖率平均更高，以场景图、嵌入和语言复杂性进行测量。例如，与一组单语标题相比，多语标题平均有21.8％更多的对象，24.5％更多的关系，以及27.1％更多的属性。此外，使用来自不同语言的内容训练的模型表现最好。

    Computer vision often treats perception as objective, and this assumption gets reflected in the way that datasets are collected and models are trained. For instance, image descriptions in different languages are typically assumed to be translations of the same semantic content. However, work in cross-cultural psychology and linguistics has shown that individuals differ in their visual perception depending on their cultural background and the language they speak. In this paper, we demonstrate significant differences in semantic content across languages in both dataset and model-produced captions. When data is multilingual as opposed to monolingual, captions have higher semantic coverage on average, as measured by scene graph, embedding, and linguistic complexity. For example, multilingual captions have on average 21.8% more objects, 24.5% more relations, and 27.1% more attributes than a set of monolingual captions. Moreover, models trained on content from different languages perform bes
    
[^165]: 超越文档边界的上下文预训练：语言模型

    In-Context Pretraining: Language Modeling Beyond Document Boundaries. (arXiv:2310.10638v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10638](http://arxiv.org/abs/2310.10638)

    本论文提出了一种超越文档边界的上下文预训练方法，通过在相关文档序列上训练语言模型，鼓励模型进行跨文档的阅读和推理。该方法通过改变文档顺序并应用现有的预训练管道来实现。

    

    目前，大型语言模型（LMs）通过预测给定文档前缀的标记来进行训练，从而能够直接进行长篇生成和提示式任务，这可以简化为文档完成。现有的预训练管道通过连接随机组合的短文档来训练LMs，以创建输入上下文，但前一个文档对于预测下一个文档没有提供任何信号。我们提出了一种新方法——上下文预训练，即在相关文档序列上预先训练语言模型，从而明确鼓励它们跨越文档边界进行阅读和推理。我们可以通过改变文档顺序，使每个上下文包含相关的文档，并直接应用现有的预训练管道来进行上下文预训练。然而，这个文档排序问题很具有挑战性。有数十亿个文档，我们希望在每个文档中最大化上下文相似性而不重复任何数据。

    Large language models (LMs) are currently trained to predict tokens given document prefixes, enabling them to directly perform long-form generation and prompting-style tasks which can be reduced to document completion. Existing pretraining pipelines train LMs by concatenating random sets of short documents to create input contexts but the prior documents provide no signal for predicting the next document. We instead present In-Context Pretraining, a new approach where language models are pretrained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. We can do In-Context Pretraining by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do
    
[^166]: 在医学问题回答中探索大型语言模型的领域: 观察和开放问题

    Exploring the Landscape of Large Language Models In Medical Question Answering: Observations and Open Questions. (arXiv:2310.07225v1 [cs.CL])

    [http://arxiv.org/abs/2310.07225](http://arxiv.org/abs/2310.07225)

    通过评估多种流行的大型语言模型在医学问题方面的知识，本研究提供了对这些模型作为一个群体的初步观察，并提出了进一步研究的开放问题。

    

    大型语言模型(LLMs)在医学问题回答领域显示出潜力，通过在标准化考试中取得及格分数，并被认为是支持医疗保健工作者的工具。将LLMs部署到如此高风险的环境中需要对这些模型的限制有清晰的理解。随着新的LLMs的快速发展和发布，识别跨模型存在的模式，并因此可能出现在新版本中，特别有价值。在本文中，我们评估了多种流行LLM在医学问题方面的知识，以更好地了解它们作为一个群体的特性。通过这个比较，我们提供了初步的观察，并提出了进一步研究的开放问题。

    Large Language Models (LLMs) have shown promise in medical question answering by achieving passing scores in standardised exams and have been suggested as tools for supporting healthcare workers. Deploying LLMs into such a high-risk context requires a clear understanding of the limitations of these models. With the rapid development and release of new LLMs, it is especially valuable to identify patterns which exist across models and may, therefore, continue to appear in newer versions. In this paper, we evaluate a wide range of popular LLMs on their knowledge of medical questions in order to better understand their properties as a group. From this comparison, we provide preliminary observations and raise open questions for further research.
    
[^167]: 实例需要更加细致的关怀：为实例重写提示提高了零样本性能

    Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance. (arXiv:2310.02107v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.02107](http://arxiv.org/abs/2310.02107)

    为了提高大型语言模型的零样本性能，本文提出了一种新的方法，通过为每个个别的测试输入重新写作任务提示，使其更具体、明确和完整，从而提供更好的指导，实现了约10%的改进。

    

    让大型语言模型能够在零样本情况下执行任务一直是一个吸引人的目标，因为它可以节省人力（即无需任务特定的注释）；因此，零样本提示方法也享有更好的任务泛化能力。为了提高大型语言模型的零样本性能，先前的工作着重于设计更有效的任务指导（例如“我们一步一步思考”）。然而，我们认为，为了让大型语言模型能够在零样本情况下正确解决问题，每个单独的测试实例需要更仔细地设计和定制的指导。为此，我们提出了PRoMPTd，一种为每个个别的测试输入重新写作任务提示的方法，使其更加具体、明确和完整，以更好地指导任务的大型语言模型。我们使用GPT-4作为任务型大型语言模型，在涵盖算术、逻辑推理和代码生成等任务的8个数据集上对PRoMPTd进行了评估。值得注意的是，PRoMPTd在复杂MATH数据集上的绝对改进约为10%。

    Enabling large language models (LLMs) to perform tasks in zero-shot has been an appealing goal owing to its labor-saving (i.e., requiring no task-specific annotations); as such, zero-shot prompting approaches also enjoy better task generalizability. To improve LLMs' zero-shot performance, prior work has focused on devising more effective task instructions (e.g., ``let's think step by step'' ). However, we argue that, in order for an LLM to solve them correctly in zero-shot, individual test instances need more carefully designed and customized instructions. To this end, we propose PRoMPTd, an approach that rewrites the task prompt for each individual test input to be more specific, unambiguous, and complete, so as to provide better guidance to the task LLM. We evaluated PRoMPTd on eight datasets covering tasks including arithmetics, logical reasoning, and code generation, using GPT-4 as the task LLM. Notably, PRoMPTd achieves an absolute improvement of around 10% on the complex MATH dat
    
[^168]: LMSYS-Chat-1M：一个大规模实际语言模型对话数据集

    LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset. (arXiv:2309.11998v1 [cs.CL])

    [http://arxiv.org/abs/2309.11998](http://arxiv.org/abs/2309.11998)

    LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。

    

    随着大规模语言模型（LLM）在各种应用中的广泛使用，研究人们如何在实际场景中与其交互变得越来越重要。在本文中，我们介绍了LMSYS-Chat-1M，这是一个包含一百万个与25个最先进的LLM进行的实际对话的大规模数据集。这个数据集是从我们的Vicuna演示和Chatbot Arena网站上的21万个独立IP地址中收集而来的。我们提供了数据集内容的概述，包括其策划过程、基本统计数据和主题分布，强调其多样性、独特性和规模。我们通过四个用例展示了它的多样性：开发与GPT-4表现相似的内容过滤模型、构建一个安全基准、训练与Vicuna表现相似的指令跟随模型、创建具有挑战性的基准问题。我们相信这个数据集将成为我们理解和推进LLM能力的宝贵资源。

    Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is pub
    
[^169]: 利用大型语言模型探索自我强化以改进学生生成的多项选择题解释

    Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models. (arXiv:2309.10444v1 [cs.AI])

    [http://arxiv.org/abs/2309.10444](http://arxiv.org/abs/2309.10444)

    本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。

    

    学生资源共享涉及学生生成和分享学习资源。在学生生成多项选择题时，创建解释是一个关键步骤，因为它有助于对相关概念的深入理解。然而，学生往往由于主题理解有限和仅仅重申问题、干扰因素和正确答案的倾向而难以编写有效的解释。为了帮助支撑这个任务，在这项工作中，我们提出了一个自我强化的大型语言模型框架，旨在自动生成和评估解释。该框架由三个模块组成，生成与学生对齐的解释，评估这些解释以确保其质量，并迭代增强解释。如果一个解释的评估分数低于定义的阈值，框架会迭代地优化和重新评估解释。重要的是，我们的框架模拟了一个学生学习的过程。

    Learnersourcing involves students generating and sharing learning resources with their peers. When learnersourcing multiple-choice questions, creating explanations for the generated questions is a crucial step as it facilitates a deeper understanding of the related concepts. However, it is often difficult for students to craft effective explanations due to limited subject understanding and a tendency to merely restate the question stem, distractors, and correct answer. To help scaffold this task, in this work we propose a self-reinforcement large-language-model framework, with the goal of generating and evaluating explanations automatically. Comprising three modules, the framework generates student-aligned explanations, evaluates these explanations to ensure their quality and iteratively enhances the explanations. If an explanation's evaluation score falls below a defined threshold, the framework iteratively refines and reassesses the explanation. Importantly, our framework emulates th
    
[^170]: 重塑顺序推荐系统：利用内容增强语言建模学习动态用户兴趣

    Reformulating Sequential Recommendation: Learning Dynamic User Interest with Content-enriched Language Modeling. (arXiv:2309.10435v1 [cs.IR])

    [http://arxiv.org/abs/2309.10435](http://arxiv.org/abs/2309.10435)

    本研究提出了一个新的顺序推荐范式 LANCER，利用预训练语言模型的语义理解能力生成更加人性化的个性化推荐。在多个基准数据集上的实验结果表明，该方法有效且有希望，并为了解顺序推荐的影响提供了有价值的见解。

    

    推荐系统对在线应用至关重要，而顺序推荐由于其表达能力强大，能够捕捉到动态用户兴趣而广泛使用。然而，先前的顺序建模方法在捕捉上下文信息方面仍存在局限性。主要的原因是语言模型常常缺乏对领域特定知识和物品相关文本内容的理解。为了解决这个问题，我们采用了一种新的顺序推荐范式，并提出了LANCER，它利用预训练语言模型的语义理解能力生成个性化推荐。我们的方法弥合了语言模型与推荐系统之间的差距，产生了更加人性化的推荐。通过对多个基准数据集上的实验，我们验证了我们的方法的有效性，展示了有希望的结果，并提供了对我们模型对顺序推荐的影响的有价值的见解。

    Recommender systems are essential for online applications, and sequential recommendation has enjoyed significant prevalence due to its expressive ability to capture dynamic user interests. However, previous sequential modeling methods still have limitations in capturing contextual information. The primary reason for this issue is that language models often lack an understanding of domain-specific knowledge and item-related textual content. To address this issue, we adopt a new sequential recommendation paradigm and propose LANCER, which leverages the semantic understanding capabilities of pre-trained language models to generate personalized recommendations. Our approach bridges the gap between language models and recommender systems, resulting in more human-like recommendations. We demonstrate the effectiveness of our approach through experiments on several benchmark datasets, showing promising results and providing valuable insights into the influence of our model on sequential recomm
    
[^171]: 评估潮起潮落：对不同平台间问答趋势的深入分析

    Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms. (arXiv:2309.05961v1 [cs.SI])

    [http://arxiv.org/abs/2309.05961](http://arxiv.org/abs/2309.05961)

    本文通过对六个社区问答平台的研究，发现了查询的元数据、问题构成方式和用户互动水平与第一个回答时间之间的关联，并利用机器学习模型预测查询是否能够迅速获得回答。

    

    社区问答平台因其快速回答用户查询的能力而越来越受欢迎。这些回答速度的快慢取决于查询特定和用户相关的因素的综合。本文通过研究六个高度流行的社区问答平台，分析了这些因素在其中的作用。我们的调查揭示了问题的第一个回答所花费的时间与元数据、问题的构成方式和用户之间的互动水平之间的关联。此外，通过使用传统的机器学习模型分析这些元数据和用户互动模式，我们试图预测哪些查询将迅速获得初始回答。

    Community Question Answering (CQA) platforms steadily gain popularity as they provide users with fast responses to their queries. The swiftness of these responses is contingent on a mixture of query-specific and user-related elements. This paper scrutinizes these contributing factors within the context of six highly popular CQA platforms, identified through their standout answering speed. Our investigation reveals a correlation between the time taken to yield the first response to a question and several variables: the metadata, the formulation of the questions, and the level of interaction among users. Additionally, by employing conventional machine learning models to analyze these metadata and patterns of user interaction, we endeavor to predict which queries will receive their initial responses promptly.
    
[^172]: DoLa：通过对比层次提高大型语言模型中的真实性

    DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models. (arXiv:2309.03883v1 [cs.CL])

    [http://arxiv.org/abs/2309.03883](http://arxiv.org/abs/2309.03883)

    DoLa通过对比不同层次的逻辑差异，提高大型语言模型中的真实性和减少幻觉，无需外部知识或微调。

    

    尽管大型语言模型（LLMs）具有令人印象深刻的能力，但它们容易出现幻觉，即生成与预训练期间观察到的事实偏离的内容。我们提出了一种简单的解码策略，用于减少预训练LLMs中的幻觉，它不需要在检索的外部知识或额外的微调上进行条件约束。我们的方法通过对比将较晚层和较早层投影到词汇空间得到的逻辑差异来获得下一个令牌的分布，利用了LLMs中的事实知识通常被证明局部化在特定的Transformer层中的事实。我们发现，这种通过对比层次的解码（DoLa）方法能够更好地展示事实知识，并减少生成不正确事实的情况。DoLa在多个选择任务和开放式生成任务中持续提升了真实性，例如改善了LLaMA系列模型在TruthfulQA上的表现。

    Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining. We propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning. Our approach obtains the next-token distribution by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space, exploiting the fact that factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers. We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts. DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA b
    
[^173]: CodeApex：用于大型语言模型的双语编程评估基准

    CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models. (arXiv:2309.01940v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01940](http://arxiv.org/abs/2309.01940)

    CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。

    

    随着大型语言模型（LLM）的出现，模型的编程能力得到了显著提升，吸引了研究人员日益增长的关注。我们提出了CodeApex，一种双语基准数据集，专注于LLM的编程理解和代码生成能力。CodeApex包括三种类型的多项选择题：概念理解、常识推理和多跳推理，旨在评估LLM在编程理解任务上的能力。此外，CodeApex利用算法问题和相应的测试用例来评估LLM生成的代码质量。我们评估了14个最先进的LLM，包括通用和专门化模型。GPT展现出最佳的编程能力，在这两个任务上的准确率分别达到了约50%和56%。编程任务仍有很大的改进空间。我们希望CodeApex能够为评估编程能力提供参考。

    With the emergence of Large Language Models (LLMs), there has been a significant improvement in the programming capabilities of models, attracting growing attention from researchers. We propose CodeApex, a bilingual benchmark dataset focusing on the programming comprehension and code generation abilities of LLMs. CodeApex comprises three types of multiple-choice questions: conceptual understanding, commonsense reasoning, and multi-hop reasoning, designed to evaluate LLMs on programming comprehension tasks. Additionally, CodeApex utilizes algorithmic questions and corresponding test cases to assess the code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs, including both general-purpose and specialized models. GPT exhibits the best programming capabilities, achieving approximate accuracies of 50% and 56% on the two tasks, respectively. There is still significant room for improvement in programming tasks. We hope that CodeApex can serve as a reference for evaluating the co
    
[^174]: MatchXML: 高效的文本-标签匹配框架，用于极端多标签文本分类

    MatchXML: An Efficient Text-label Matching Framework for Extreme Multi-label Text Classification. (arXiv:2308.13139v1 [cs.CL])

    [http://arxiv.org/abs/2308.13139](http://arxiv.org/abs/2308.13139)

    MatchXML是一种高效的文本-标签匹配框架，用于极端多标签文本分类。它通过label2vec方法生成语义密集的标签嵌入，并利用这些嵌入构建层次化标签树。通过微调预训练的Transformer模型，MatchXML将多标签文本分类问题转化为文本-标签匹配问题，并提取出密集的文本表示和静态的句子嵌入。

    

    极端多标签文本分类（XMC）是指训练一个分类器，从一个非常大规模的标签集中（例如数百万个标签）为文本样本分配相关标签。我们提出了MatchXML，一种用于XMC的高效文本-标签匹配框架。我们观察到，由稀疏的词频-逆文档频率（TF-IDF）特征生成的标签嵌入存在一些限制。因此，我们提出了label2vec，通过Skip-gram模型来有效训练语义密集的标签嵌入。然后，使用这些密集的标签嵌入来构建一个层次化标签树。在微调预训练的编码器Transformer时，我们将多标签文本分类问题制定为一个在二分图中的文本-标签匹配问题。然后，从微调后的Transformer中提取密集的文本表示。除了微调后的密集文本嵌入之外，我们还从预训练的Sentence Transformer中提取静态的密集句子嵌入。

    The eXtreme Multi-label text Classification(XMC) refers to training a classifier that assigns a text sample with relevant labels from an extremely large-scale label set (e.g., millions of labels). We propose MatchXML, an efficient text-label matching framework for XMC. We observe that the label embeddings generated from the sparse Term Frequency-Inverse Document Frequency(TF-IDF) features have several limitations. We thus propose label2vec to effectively train the semantic dense label embeddings by the Skip-gram model. The dense label embeddings are then used to build a Hierarchical Label Tree by clustering. In fine-tuning the pre-trained encoder Transformer, we formulate the multi-label text classification as a text-label matching problem in a bipartite graph. We then extract the dense text representations from the fine-tuned Transformer. Besides the fine-tuned dense text embeddings, we also extract the static dense sentence embeddings from a pre-trained Sentence Transformer. Finally,
    
[^175]: 通过基于嘴唇-音素字级相关性的视觉预训练和跨模态融合编码器来改进视听语音识别

    Improving Audio-Visual Speech Recognition by Lip-Subword Correlation Based Visual Pre-training and Cross-Modal Fusion Encoder. (arXiv:2308.08488v1 [cs.CL])

    [http://arxiv.org/abs/2308.08488](http://arxiv.org/abs/2308.08488)

    本文提出了通过基于嘴唇-音素字级相关性的视觉预训练和跨模态融合编码器来改进视听语音识别的两种新技术。这些技术可以在预训练和微调阶段准确对齐音频和视频流，并且充分利用模态互补性。

    

    最近的研究中观察到，在低质量视频的端到端框架下，从自动语音识别系统到视听语音识别系统的性能略有改进。据认为，音频和视觉模态之间不匹配的收敛速度和专门的输入表示导致了这个问题。在本文中，我们提出了两种新技术来改进视听语音识别（AVSR）在预训练和微调训练框架下。首先，我们探索了普通话中嘴唇形状和音节级音素字单元之间的相关性，以建立准确的帧级音节边界。这使得在视觉模型预训练和跨模态融合过程中能够对齐视频和音频流。接下来，我们提出了一种音频引导的跨模态融合编码器（CMFE）神经网络，利用主要训练参数来实现多个跨模态注意力层的充分利用模态互补性。在实验上进行了验证

    In recent research, slight performance improvement is observed from automatic speech recognition systems to audio-visual speech recognition systems in the end-to-end framework with low-quality videos. Unmatching convergence rates and specialized input representations between audio and visual modalities are considered to cause the problem. In this paper, we propose two novel techniques to improve audio-visual speech recognition (AVSR) under a pre-training and fine-tuning training framework. First, we explore the correlation between lip shapes and syllable-level subword units in Mandarin to establish good frame-level syllable boundaries from lip shapes. This enables accurate alignment of video and audio streams during visual model pre-training and cross-modal fusion. Next, we propose an audio-guided cross-modal fusion encoder (CMFE) neural network to utilize main training parameters for multiple cross-modal attention layers to make full use of modality complementarity. Experiments on the
    
[^176]: 过度思考真相：理解语言模型如何处理虚假演示

    Overthinking the Truth: Understanding how Language Models Process False Demonstrations. (arXiv:2307.09476v1 [cs.LG])

    [http://arxiv.org/abs/2307.09476](http://arxiv.org/abs/2307.09476)

    该论文研究了现代语言模型在处理虚假演示时出现的过度思考和错误归纳头现象。通过研究模型的内部表示，发现模型在中间层之后对错误演示的处理准确性逐渐降低，并指出了错误归纳头机制可能导致过度思考现象。

    

    现代语言模型可以通过少量示范进行复杂模式的模仿学习，使其能够在没有微调的情况下完成具有挑战性的任务。然而，模仿也可能导致模型在上下文中重现不准确或有害的内容。我们通过模型的内部表示来研究有害的模仿，并确定了两个相关现象：过度思考和错误归纳头。第一个现象，过度思考，在给出正确与错误的少量示范时，我们从中间层解码预测。在早期层中，两种示范引起了相似的模型行为，但在某个“关键层”之后，给出错误示范的准确性逐渐降低。第二个现象，错误归纳头，可能是过度思考的一种机制性原因：这些是位于较晚层的头部，它们关注并复制先前示范中的错误信息，其削弱会减少过度思考现象。

    Modern language models can imitate complex patterns through few-shot learning, enabling them to complete challenging tasks without fine-tuning. However, imitation can also lead models to reproduce inaccuracies or harmful content if present in the context. We study harmful imitation through the lens of a model's internal representations, and identify two related phenomena: overthinking and false induction heads. The first phenomenon, overthinking, appears when we decode predictions from intermediate layers, given correct vs. incorrect few-shot demonstrations. At early layers, both demonstrations induce similar model behavior, but the behavior diverges sharply at some "critical layer", after which the accuracy given incorrect demonstrations progressively decreases. The second phenomenon, false induction heads, are a possible mechanistic cause of overthinking: these are heads in late layers that attend to and copy false information from previous demonstrations, and whose ablation reduces 
    
[^177]: 在实践中分析数据集注释质量管理

    Analyzing Dataset Annotation Quality Management in the Wild. (arXiv:2307.08153v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08153](http://arxiv.org/abs/2307.08153)

    该论文调查分析了自然语言数据集的创建过程中的质量管理实践，并提供了相应的建议。研究表明，流行数据集中存在较多的错误注释、偏见或注释伪像。这项研究的贡献是在这一领域进行了大规模的实证分析，并提出了实践指南。

    

    数据质量对于训练准确、公正和可信的机器学习模型以及它们的正确评估至关重要。然而，最近的研究表明，即使是用于训练和评估最先进模型的流行数据集中也存在大量的错误注释、偏见或注释伪像。关于注释项目的最佳实践和指南已经存在，但据我们所知，迄今为止还没有进行大规模分析，以研究创建自然语言数据集时实际进行的质量管理以及是否遵循了这些建议。因此，我们首先调查并总结了文献中描述的数据集创建的推荐质量管理实践，并提供了如何应用这些实践的建议。然后，我们编制了一个由591篇科学出版物组成的文本数据集语料库，并针对与质量相关的方面进行了注释，例如注释者管理、一致性、仲裁或数据验证。

    Data quality is crucial for training accurate, unbiased, and trustworthy machine learning models and their correct evaluation. Recent works, however, have shown that even popular datasets used to train and evaluate state-of-the-art models contain a non-negligible amount of erroneous annotations, bias or annotation artifacts. There exist best practices and guidelines regarding annotation projects. But to the best of our knowledge, no large-scale analysis has been performed as of yet on how quality management is actually conducted when creating natural language datasets and whether these recommendations are followed. Therefore, we first survey and summarize recommended quality management practices for dataset creation as described in the literature and provide suggestions on how to apply them. Then, we compile a corpus of 591 scientific publications introducing text datasets and annotate it for quality-related aspects, such as annotator management, agreement, adjudication or data validat
    
[^178]: DeepOnto: 一个用于深度学习本体工程的Python包

    DeepOnto: A Python Package for Ontology Engineering with Deep Learning. (arXiv:2307.03067v1 [cs.AI])

    [http://arxiv.org/abs/2307.03067](http://arxiv.org/abs/2307.03067)

    DeepOnto是一个Python包，用于深度学习本体工程。它通过集成深度学习框架和本体API，提供了丰富的工具和算法，支持本体工程任务，如本体对齐和完成。

    

    应用深度学习技术，特别是语言模型（LMs），在本体工程中已经引起了广泛关注。然而，深度学习框架如PyTorch和Tensorflow主要是为Python开发的，而广泛使用的本体API（如OWL API和Jena）主要是基于Java的。为了方便无缝集成这些框架和API，我们提出了Deeponto，一个专为本体工程设计的Python包。该包包括一个基于广泛认可和可靠的OWL API的核心本体处理模块，以更“Pythonic”的方式封装其基本特性，并扩展其功能以包括其他重要组成部分，包括推理、语言化、规范化、投影等。基于这个模块，Deeponto提供了一套工具、资源和算法，支持各种本体工程任务，例如本体对齐和完成，利用深度学习方法实现。

    Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention. However, deep learning frameworks like PyTorch and Tensorflow are predominantly developed for Python programming, while widely-used ontology APIs, such as the OWL API and Jena, are primarily Java-based. To facilitate seamless integration of these frameworks and APIs, we present Deeponto, a Python package designed for ontology engineering. The package encompasses a core ontology processing module founded on the widely-recognised and reliable OWL API, encapsulating its fundamental features in a more "Pythonic" manner and extending its capabilities to include other essential components including reasoning, verbalisation, normalisation, projection, and more. Building on this module, Deeponto offers a suite of tools, resources, and algorithms that support various ontology engineering tasks, such as ontology alignment and completion, by harnessing deep learning meth
    
[^179]: 图像的重要性：多模态夸张检测的新数据集和实证研究

    Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection. (arXiv:2307.00209v1 [cs.CV])

    [http://arxiv.org/abs/2307.00209](http://arxiv.org/abs/2307.00209)

    本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。

    

    夸张，即夸大其词，是一种常见的语言现象。夸张检测是理解人类表达的重要部分。已经有几项关于夸张检测的研究，但大多数的研究只关注文本模态。然而，随着社交媒体的发展，人们可以使用各种模态（包括文本、图像、视频等）来表达夸张。在本文中，我们专注于多模态夸张检测。我们从微博（中国的一种社交媒体）创建了一个多模态检测数据集，并对其进行了一些研究。我们将微博的文本和图像视为两种模态，探索了文本和图像在夸张检测中的作用。此外，我们还评估了不同预训练的多模态编码器在这个下游任务上的性能。由于这个数据集是从五个不同的主题构建的，我们还评估了不同领域之间的性能。

    Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection of hyperbole is an important part of understanding human expression. There have been several studies on hyperbole detection, but most of which focus on text modality only. However, with the development of social media, people can create hyperbolic expressions with various modalities, including text, images, videos, etc. In this paper, we focus on multimodal hyperbole detection. We create a multimodal detection dataset\footnote{The dataset will be released to the community.} from Weibo (a Chinese social media) and carry out some studies on it. We treat the text and image from a piece of weibo as two modalities and explore the role of text and image for hyperbole detection. Different pre-trained multimodal encoders are also evaluated on this downstream task to show their performance. Besides, since this dataset is constructed from five different topics, we also evaluate the cross-domain performance of different 
    
[^180]: Xiezhi：一种全面更新的综合领域知识评估基准

    Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation. (arXiv:2306.05783v1 [cs.CL])

    [http://arxiv.org/abs/2306.05783](http://arxiv.org/abs/2306.05783)

    Xiezhi是一种全面综合的评估套件，设有516个多项选择问题，覆盖了从13个不同学科跨越的15个专业领域，并对47个先进的LLMs进行评估，结果表明LLMs在大多数领域超越人类，但在一些领域表现不佳。

    

    随着大型语言模型（LLM）的快速发展，急需新的自然语言处理（NLP）基准来实现对齐。我们提出了Xiezhi，这是一个最全面的评估套件，旨在评估综合领域知识。Xiezhi包括跨越13个不同学科的516个多项选择问题，包括22万个问题，并且附带Xiezhi-Specialty和Xiezhi-Interdiscipline，均有15,000个问题。我们对47个先进的LLM在Xiezhi上进行了评估。结果表明，LLM在科学、工程、农学、医学和艺术方面超过了人类的平均表现，但在经济学、法学、教育学、文学、历史和管理方面则表现不佳。我们期望Xiezhi将有助于分析LLM的重要优点和不足之处，该基准已在https://github.com/MikeGu721/XiezhiBenchmark发布。

    New Natural Langauge Process~(NLP) benchmarks are urgently needed to align with the rapid development of large language models (LLMs). We present Xiezhi, the most comprehensive evaluation suite designed to assess holistic domain knowledge. Xiezhi comprises multiple-choice questions across 516 diverse disciplines ranging from 13 different subjects with 220,000 questions and accompanied by Xiezhi-Specialty and Xiezhi-Interdiscipline, both with 15k questions. We conduct evaluation of the 47 cutting-edge LLMs on Xiezhi. Results indicate that LLMs exceed average performance of humans in science, engineering, agronomy, medicine, and art, but fall short in economics, jurisprudence, pedagogy, literature, history, and management. We anticipate Xiezhi will help analyze important strengths and shortcomings of LLMs, and the benchmark is released in https://github.com/MikeGu721/XiezhiBenchmark .
    
[^181]: 大型语言模型作为工具制造者

    Large Language Models as Tool Makers. (arXiv:2305.17126v1 [cs.LG])

    [http://arxiv.org/abs/2305.17126](http://arxiv.org/abs/2305.17126)

    本文提出了一个闭环框架，即LLMs作为工具制造者（LATM），使LLMs能够自主地创建用于解决问题的工具，而不需要依赖于现有的外部工具。

    

    最近的研究表明，通过使用外部工具，大型语言模型（LLMs）可以增强其问题解决能力的潜力。然而，在这方面的先前工作依赖于现有工具的可用性。在本文中，我们提出了一个闭环框架，称为LLMs As Tool Makers（LATM），以消除这种依赖性，其中LLMs创建自己的可重用工具来解决问题。我们的方法包括两个关键阶段：1）制造工具：LLM作为工具制造者，为给定任务制作工具，其中工具作为Python实用函数实现。2）使用工具：LLM作为工具用户，应用工具制造者构建的工具来解决问题。工具用户可以是与工具制造者相同或不同的LLM。工具制造使LLM能够不断生成可应用于不同请求的工具，以便将来请求在解决问题时能调用相应的API。

    Recent research shows the potential of enhancing the problem-solving ability of large language models (LLMs) through the use of external tools. However, prior work along this line depends on the availability of existing tools. In this work, we take an initial step towards removing this dependency by proposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM), where LLMs create their own reusable tools for problem-solving. Our approach consists of two key phases: 1) tool making: an LLM acts as the tool maker that crafts tools for given tasks, where a tool is implemented as a Python utility function. 2) tool using: an LLM acts as the tool user, which applies the tool built by the tool maker for problem-solving. The tool user can be either the same or a different LLM from the tool maker. Tool-making enables an LLM to continually generate tools that can be applied to different requests so that future requests can call the corresponding APIs when beneficial for solving the 
    
[^182]: 通过提示工程破解ChatGPT：一项实证研究

    Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study. (arXiv:2305.13860v1 [cs.SE])

    [http://arxiv.org/abs/2305.13860](http://arxiv.org/abs/2305.13860)

    本研究探索了通过提示工程破解ChatGPT的有效性，发现破解提示可以在40种用例情况下一致地规避限制，强调了提示结构在破解ChatGPT中的重要性。

    

    大型语言模型（LLMs）如ChatGPT已经展示了强大的潜力，但同时也引发了与内容约束和潜在滥用相关的挑战。我们的研究探究了三个关键问题：（1）可以用多少种不同的提示类型破解LLMs，（2）破解提示在规避LLM限制方面的有效性以及（3）ChatGPT对这些破解提示的韧性。首先，我们开发了一个分类模型来分析现有提示的分布，识别出十个不同模式和三个破解提示类别。随后，我们使用3,120个禁止情景下的狱中问题数据集评估ChatGPT 3.5和4.0版本的破解能力。最后，我们评估了ChatGPT对破解提示的抵抗力，发现提示可以在40种用例情景下一致地规避限制。该研究强调了提示结构在破解ChatGPT中的重要性，并突出了LLMs对意外滥用的敏感性。

    Large Language Models (LLMs), like ChatGPT, have demonstrated vast potential but also introduce challenges related to content constraints and potential misuse. Our study investigates three key research questions: (1) the number of different prompt types that can jailbreak LLMs, (2) the effectiveness of jailbreak prompts in circumventing LLM constraints, and (3) the resilience of ChatGPT against these jailbreak prompts. Initially, we develop a classification model to analyze the distribution of existing prompts, identifying ten distinct patterns and three categories of jailbreak prompts. Subsequently, we assess the jailbreak capability of prompts with ChatGPT versions 3.5 and 4.0, utilizing a dataset of 3,120 jailbreak questions across eight prohibited scenarios. Finally, we evaluate the resistance of ChatGPT against jailbreak prompts, finding that the prompts can consistently evade the restrictions in 40 use-case scenarios. The study underscores the importance of prompt structures in j
    
[^183]: 编译神经网络的语言模型：神经理解

    Neural Comprehension: Language Models with Compiled Neural Networks. (arXiv:2304.01665v1 [cs.CL])

    [http://arxiv.org/abs/2304.01665](http://arxiv.org/abs/2304.01665)

    本文探讨了如何将编译神经网络CoNNs并入语言模型的架构中，以使语言模型在复合任务中提高性能，特别是在需要深入理解抽象规则的领域。方法称为“神经理解”，提高了语言模型在符号操作、规则推理、算术推理等方面的准确度。

    

    语言模型在自然语言处理任务中取得了令人瞩目的成果，但其进行符号操作和算术操作的能力仍然有限，这归因于它们隐式地从数据中学习规则。我们探讨如何将特别设计得到的加权的编译神经网络（CoNNs）并入语言模型的架构中，使得通过梯度训练的语言模型获得完全的规则理解能力。编译神经网络的并入为改善语言模型在复合任务中的性能提供了一个有前途的方向，特别是在需要深入理解抽象规则的领域。我们的方法称为“神经理解”，有助于语言模型在符号操作、规则推理、算术推理等方面实现绝对准确度。我们的代码公开可用：\url{https://github.com/...}

    Language models have achieved impressive results in natural language processing tasks, but their ability to perform symbolic operations and arithmetic operations, remains limited, which attribute to their learn the rules implicitly from data. We explore how to incorporate compiled neural networks (CoNNs) which weight is specially designed, into the architecture of language models to enable the language model trained by gradient to obtain fully rule comprehension ability. The incorporation of compiled neural networks offers a promising direction for improving the performance of language models on compound tasks, particularly in areas that require a deeper comprehension of abstract rules beyond recognizing patterns in training data. Our method, which call "Neural Comprehension", helps language models achieve absolute accuracy in symbolic operations, thereby enhancing their ability for rule reasoning, symbolic reasoning, and arithmetic reasoning. Our code is publicly available at: \url{ht
    
[^184]: 总结过去以预测未来：自然语言对场景的描述促进多模态对象交互

    Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction. (arXiv:2301.09209v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.09209](http://arxiv.org/abs/2301.09209)

    本文提出了一种TransFusion架构，利用先前训练的图像字幕和视觉语言模型总结动作上下文，实现对多模态对象交互的预测，有效性得到验证。

    

    本论文针对自我中心视频中的对象交互预测进行了研究。该任务需要理解先前对对象执行的动作所形成的时空上下文，称为动作上下文。我们提出了一种基于多模态transformer的架构TransFusion。它利用语言的表达能力，对动作上下文进行总结。TransFusion利用预先训练的图像字幕和视觉语言模型从过去的视频帧中提取动作上下文。将这个动作上下文与下一个视频帧一起经过多模态融合模块进行处理，从而预测下一个对象交互。我们的模型实现了更高效的端到端学习，大型预训练语言模型则增加了通用性和泛化能力。在Ego4D和EPIC-KITCHENS-100上的实验证实了我们的多模态融合模型的有效性。同时，也凸显了在一个视觉似乎足够的任务中使用基于语言的上下文摘要的好处。我们的方法胜过了现有的方法。

    We study object interaction anticipation in egocentric videos. This task requires an understanding of the spatiotemporal context formed by past actions on objects, coined action context. We propose TransFusion, a multimodal transformer-based architecture. It exploits the representational power of language by summarising the action context. TransFusion leverages pre-trained image captioning and vision-language models to extract the action context from past video frames. This action context together with the next video frame is processed by the multimodal fusion module to forecast the next object interaction. Our model enables more efficient end-to-end learning. The large pre-trained language models add common sense and a generalisation capability. Experiments on Ego4D and EPIC-KITCHENS-100 show the effectiveness of our multimodal fusion model. They also highlight the benefits of using language-based context summaries in a task where vision seems to suffice. Our method outperforms state-
    
[^185]: CAPE: 使用大型语言模型从前置错误中纠正行动

    CAPE: Corrective Actions from Precondition Errors using Large Language Models. (arXiv:2211.09935v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.09935](http://arxiv.org/abs/2211.09935)

    CAPE是一种利用大型语言模型从前置错误中纠正行动的方法，提高了生成计划的质量，使具身代理能够执行更多任务，并改善了计划的正确性。

    

    从大型语言模型中提取常识知识为设计智能机器人提供了一种途径。现有的利用语言模型进行规划的方法在行动失败时无法恢复，并且通常只能尝试重新执行失败的行动，而无法解决错误的根本原因。我们提出了一种新颖的方法（CAPE），试图在规划过程中提出纠正前置条件错误的行动。CAPE通过利用少样本推理从行动前置条件中提高了生成计划的质量。我们的方法使得具身代理能够执行比基线方法更多的任务，同时确保语义正确性和最小化重新提示。在VirtualHome中，CAPE生成可执行的计划，并且相比SayCan，将人工标注的计划正确度指标从28.89%提高到49.63%。我们的改进也适用于一台配置了一组以语言为指定的技能和相关前置条件的波士顿动力公司的Spot机器人，其中CAPE提高了正确性。

    Extracting commonsense knowledge from a large language model (LLM) offers a path to designing intelligent robots. Existing approaches that leverage LLMs for planning are unable to recover when an action fails and often resort to retrying failed actions, without resolving the error's underlying cause.  We propose a novel approach (CAPE) that attempts to propose corrective actions to resolve precondition errors during planning. CAPE improves the quality of generated plans by leveraging few-shot reasoning from action preconditions. Our approach enables embodied agents to execute more tasks than baseline methods while ensuring semantic correctness and minimizing re-prompting. In VirtualHome, CAPE generates executable plans while improving a human-annotated plan correctness metric from 28.89% to 49.63% over SayCan. Our improvements transfer to a Boston Dynamics Spot robot initialized with a set of skills (specified in language) and associated preconditions, where CAPE improves the correctne
    

