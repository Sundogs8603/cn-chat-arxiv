# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models.](http://arxiv.org/abs/2308.07922) | RAVEN是一种结合了检索增强的蒙特卡洛语言建模和前缀语言建模的模型，通过引入上下文融合学习，它能够在上下文学习方面取得比ATLAS更好的性能。 |
| [^2] | [Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification.](http://arxiv.org/abs/2308.07921) | 本文研究了使用GPT-4代码解释器解决数学问题的方法，并提出了显式的基于代码的自我验证（CSV）方法，用于进一步提升GPT-4 Code Interpreter的数学推理能力。 |
| [^3] | [Through the Lens of Core Competency: Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2308.07902) | 本论文通过核心竞争力的视角，调查了大型语言模型(LLM)评估的多篇论文，总结出LLM的4个核心竞争力：推理能力、知识能力、可靠性和安全性，并介绍了对应的基准和评估指标。 |
| [^4] | [The Regular Expression Inference Challenge.](http://arxiv.org/abs/2308.07899) | 正则表达式推理挑战是一个以找到最小正则表达式为目标的任务，具有应用广泛、难度可调、适用于代码/语言建模和机器学习的特点。 |
| [^5] | [Link-Context Learning for Multimodal LLMs.](http://arxiv.org/abs/2308.07891) | 链接上下文学习(LCL)通过从因果关系中推理来增强多模态大型语言模型(MLLMs)的学习能力，引导模型辨别类比关系并揭示潜在的因果关联，提升了对未见过数据的识别和理解。 |
| [^6] | [A Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning.](http://arxiv.org/abs/2308.07889) | 本研究主要通过对7个知识图嵌入模型在4种常见关系模式上的性能评估，以及理论、实体频率和整体分析，探讨了知识图嵌入模型在不同关系模式下的能力，并得出了一些具有讽刺意味的结论。 |
| [^7] | [Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT.](http://arxiv.org/abs/2308.07876) | 该论文通过利用已建立的注释编码本的知识，探索零样本方法用于政治事件本体关系分类，并介绍一种基于自然语言推理的方法，名为ZSP。ZSP采用了一种树查询框架，提高了解释性、效率和对模式更改的适应性。在细粒度根代码分类上，ZSP的性能明显优于ChatGPT，F1得分提高了40%。 |
| [^8] | [Emotion Embeddings $\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets.](http://arxiv.org/abs/2308.07871) | 这篇论文提出了一种统一的计算模型，通过学习情感嵌入，独立于不同的语言、交流方式、媒体或标签形式，从而将以往对不同类型异质情感数据的研究整合起来。 |
| [^9] | [Informed Named Entity Recognition Decoding for Generative Language Models.](http://arxiv.org/abs/2308.07791) | 该论文提出了一种利用生成式语言模型进行命名实体识别解码的方法，通过在信息提取过程中应用生成模型的语言理解能力，提高了性能并消除了幻觉的风险。 |
| [^10] | [Enhancing Visually-Rich Document Understanding via Layout Structure Modeling.](http://arxiv.org/abs/2308.07777) | 本研究提出一种新的文档理解模型GraphLayoutLM，通过建模布局结构图将文档布局知识注入模型中，并利用布局感知的自注意力层来学习文档布局知识。模型在多个基准测试集上取得了最先进的结果，表明其优越性能。 |
| [^11] | [Backward Reasoning in Large Language Models for Verification.](http://arxiv.org/abs/2308.07758) | 本文研究了在大型语言模型中使用反向推理进行验证的方法。作者提出了一种新颖的技术，通过屏蔽问题中的一个标记，并要求语言模型预测被屏蔽的标记来验证候选答案。同时，作者还提出了一种结合正向和反向推理的方法来估计候选答案的概率。 |
| [^12] | [SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search.](http://arxiv.org/abs/2308.07711) | 本论文提出了一种用于在Meituan搜索中进行相关性建模的新颖两阶段预训练和匹配架构。 |
| [^13] | [Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models.](http://arxiv.org/abs/2308.07706) | 本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。 |
| [^14] | [Better Zero-Shot Reasoning with Role-Play Prompting.](http://arxiv.org/abs/2308.07702) | 通过角色扮演提示，研究评估了现代大型语言模型在零-shot推理场景下的表现，并发现角色扮演提示在多个推理基准测试中都超越了标准的零-shot方法。 |
| [^15] | [Attention Is Not All You Need Anymore.](http://arxiv.org/abs/2308.07661) | 本文提出了一种名为Extractor的插入替代器，用于取代Transformer中的自注意机制，实验证明使用Extractor可以提高Transformer的性能，并且具有更短的计算关键路径。 |
| [^16] | [SEER: Super-Optimization Explorer for HLS using E-graph Rewriting with MLIR.](http://arxiv.org/abs/2308.07654) | SEER是一个基于E图重写和MLIR的超级优化探索器，用于将软件程序自动转换为高效的硬件描述，填补了高级综合工具生成的硬件设计与手动实现之间的性能差距。 |
| [^17] | [Steering Language Generation: Harnessing Contrastive Expert Guidance and Negative Prompting for Coherent and Diverse Synthetic Data Generation.](http://arxiv.org/abs/2308.07645) | 该论文提出了一种引导语言生成的方法，通过对比专家指导和负面提示，实现了连贯和多样性的合成数据生成。该方法在推理时间内操作，利用对比形式指导LLMs在数据分布的一致性和与先前示例的偏离之间取得平衡。 |
| [^18] | [LLM-Mini-CEX: Automatic Evaluation of Large Language Model for Diagnostic Conversation.](http://arxiv.org/abs/2308.07635) | 本研究提出了一种用于诊断对话的自动评估方法，通过建立LLM-specific Mini-CEX评估标准和使用患者模拟器与ChatGPT自动评估诊断对话，解决了医学LLMs评估中的统一和全面性问题。 |
| [^19] | [A Survey on Model Compression for Large Language Models.](http://arxiv.org/abs/2308.07633) | 本论文提供了关于大型语言模型的模型压缩综述，探讨了量化、修剪、知识蒸馏等不同方法，并突出介绍了最新进展和创新方法，为实现高效的部署提供了重要思路。 |
| [^20] | [LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis.](http://arxiv.org/abs/2308.07610) | LogPrompt是一种新颖的零样本和可解释的日志分析方法，通过利用大型语言模型和专为日志任务设计的高级提示策略，实现了对日志的分析，提高了模型的性能和可解释性。 |
| [^21] | [VBD-MT Chinese-Vietnamese Translation Systems for VLSP 2022.](http://arxiv.org/abs/2308.07601) | VBD-MT是VLSP 2022中越翻译任务的系统，通过使用Transformer模型和mBART预训练模型，采用反向翻译和其他方法来提高翻译质量，在公共测试集上表现优秀。 |
| [^22] | [A User-Centered Evaluation of Spanish Text Simplification.](http://arxiv.org/abs/2308.07556) | 通过对西班牙文文本简化的用户评估，我们发现神经网络在预测用户偏好方面表现更好，同时也发现多语言模型不如西班牙文模型在同一任务上的表现。我们发布了评估中的语料库，希望推动西班牙语自然语言处理的最新技术。 |
| [^23] | [CALYPSO: LLMs as Dungeon Masters' Assistants.](http://arxiv.org/abs/2308.07540) | CALYPSO是一个以LLMs为基础的接口系统，旨在支持Dungeon Masters在龙与地下城和桌面游戏中。它将游戏背景信息转化为简洁的散文，并提供信息和灵感支持，以帮助DM在游戏中维持连贯性并进行头脑风暴。 |
| [^24] | [Finding Stakeholder-Material Information from 10-K Reports using Fine-Tuned BERT and LSTM Models.](http://arxiv.org/abs/2308.07522) | 本研究使用经过优化的BERT和LSTM模型，从上市公司的10-K报告中识别出利益相关方-材料信息，显著优于关键词搜索的基准模型。 |
| [^25] | [Data Race Detection Using Large Language Models.](http://arxiv.org/abs/2308.07505) | 本研究探索了一种基于大型语言模型的数据竞争检测方法，通过结合提示工程和微调技术，发现LLMs可以作为数据竞争检测的可行方法，但在需要详细信息时仍不如传统工具竞争。 |
| [^26] | [SOTASTREAM: A Streaming Approach to Machine Translation Training.](http://arxiv.org/abs/2308.07489) | SOTASTREAM是一种机器翻译训练的流式方法，提供了无限排列的训练数据流，避免了传统的静态数据预处理步骤，以及耗时、昂贵和繁琐的问题。 |
| [^27] | [O-1: Self-training with Oracle and 1-best Hypothesis.](http://arxiv.org/abs/2308.07486) | 提出了一种新的自我训练目标O-1，通过增强神谕假设来减少训练偏差，并统一训练和评估指标。通过实验证明了O-1在语音识别任务中的有效性，并取得了相对于EMBR的显著改进。 |
| [^28] | [Playing with Words: Comparing the Vocabulary and Lexical Richness of ChatGPT and Humans.](http://arxiv.org/abs/2308.07462) | 这篇论文比较了ChatGPT和人类在词汇和词汇丰富度方面的差异，研究发现使用ChatGPT等工具会对词汇使用和词汇丰富度产生影响，这可能会对语言演变产生影响。 |
| [^29] | [Development and Evaluation of Three Chatbots for Postpartum Mood and Anxiety Disorders.](http://arxiv.org/abs/2308.07407) | 我们开发了三个聊天机器人，为产后护理人员提供上下文特定的共情支持，其中基于规则的模型表现最好，人类用户更喜欢它的回复，生成模型的回复有时混淆或无意义。 |
| [^30] | [Text Injection for Capitalization and Turn-Taking Prediction in Speech Models.](http://arxiv.org/abs/2308.07395) | 本研究探讨了在语音模型中利用文本注入进行非ASR任务的辅助，并使用联合训练算法提升大写准确率和交替检测召回率。 |
| [^31] | [Using Text Injection to Improve Recognition of Personal Identifiers in Speech.](http://arxiv.org/abs/2308.07393) | 通过使用文本注入技术，在自动语音识别中改善个人识别符类别的识别准确率，并且在医疗记录中提高了人名和日期的召回率。 |
| [^32] | [Emergent communication for AR.](http://arxiv.org/abs/2308.07342) | 本研究提出了一种新兴语义通信框架，用于学习移动增强现实中的通信协议，并采用改进的Lewis信令博弈训练两个代理。通过这个框架，两个代理能够在嘈杂的信道中使用极小的消息进行关于视觉数据的抽象思想的交流，从而解决了现有解决方案中视觉数据通信延迟对体验质量的限制。 |
| [^33] | [Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic.](http://arxiv.org/abs/2308.07336) | 本研究研究了一种从合成语料库中学习演绎推理能力的方法，通过采用基于形式逻辑理论的演绎规则，训练的语言模型具有更泛化的推理能力。 |
| [^34] | [AI Text-to-Behavior: A Study In Steerability.](http://arxiv.org/abs/2308.07326) | 本研究探讨了大型语言模型的可操控性，通过使用行为心理学框架，模型在生成文本时能够根据提示展现特定的行为特征。研究发现，模型在不同特征上的表现具有灵活性和区分度，并能够准确复制历史人物的个性和对话风格。 |
| [^35] | [LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked.](http://arxiv.org/abs/2308.07308) | 本文提出了一种通过自检来防御大型语言模型(LLMs)对抗性攻击的简单方法，即让模型自行过滤回应。实验结果表明，即使模型未对齐人类价值观，通过使用语言模型验证内容，仍然可以防止模型向用户呈现有害内容。 |
| [^36] | [Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using Matchmaking for AI.](http://arxiv.org/abs/2308.07213) | 本研究使用AI的匹配设计方法，通过与专业事实核查员的合作设计，发现并解决事实核查员与技术之间的差距。合作设计会议产生了11个新的设计思路，包括提高效率和个性化的事实核查工具，帮助事实核查员准备未来的虚假信息，监测偏见，以及支持内部组织。 |
| [^37] | [Large Language Models for Information Retrieval: A Survey.](http://arxiv.org/abs/2308.07107) | 本综述将大型语言模型（LLMs）在信息检索中的发展进行了综述，探讨了其在捕捉上下文信号和语义细微之处方面的优势和挑战，以及与传统检索方法的结合的重要性。 |
| [^38] | [#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models.](http://arxiv.org/abs/2308.07074) | 本研究提出了InsTag，一种用于标记基于语义和意图的监督微调（SFT）数据集样本的开放式细粒度标注器。通过分析开源SFT数据集，发现模型能力会随着更多多样化和复杂化的数据而增长。基于这一观察结果，使用InsTag选择的数据进行模型微调，得到的TagLM模型在大规模SFT数据上优于开源模型，验证了查询多样性和复杂性的重要性。 |
| [^39] | [Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation.](http://arxiv.org/abs/2308.06953) | Thresh是一个统一的、可定制的和可部署的细粒度文本评估平台，通过创建一个YAML配置文件，用户可以快速构建和测试任何框架的注释界面，并提供一个社区中心来促进协作和共享。 |
| [^40] | [MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction.](http://arxiv.org/abs/2308.06546) | 本文提出了一个新的多方面交叉整合框架，用于从药物相关文档中提取药物事件/实体。该框架能够捕捉并对齐不同的上下文/语言/知识属性，并实现药物事件信息的全面检测和理解。 |
| [^41] | [Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review.](http://arxiv.org/abs/2308.04306) | 本文对基于深度学习的隐喻识别任务中知识注入的研究进展进行了全面综述，包括主流知识和知识注入原则的总结、数据集、评估指标和基准模型的回顾，并探讨了当前的知识注入问题。 |
| [^42] | [SynJax: Structured Probability Distributions for JAX.](http://arxiv.org/abs/2308.03291) | SynJax是一个针对JAX的结构化概率分布库，通过提供高效的向量化实现解决了对于结构化对象的难以实现的问题。 |
| [^43] | [LaFiCMIL: Rethinking Large File Classification from the Perspective of Correlated Multiple Instance Learning.](http://arxiv.org/abs/2308.01413) | LaFiCMIL是一个新的方法，从相关多实例学习的角度解决了Transformer模型输入长度限制的问题，可以用于改进大文件分类任务。 |
| [^44] | [PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization.](http://arxiv.org/abs/2307.15199) | 提出了PromptStyler，通过使用提示合成样式特征，解决了无源域泛化的问题。该方法通过学习样式词向量生成多样的样式，并通过强制样式内容特征与内容特征靠近来保证样式不会扭曲内容信息。在多个数据集上取得了最先进的结果。 |
| [^45] | [Stack More Layers Differently: High-Rank Training Through Low-Rank Updates.](http://arxiv.org/abs/2307.05695) | 本文以低秩训练技术作为替代方法，提出了一种名为ReLoRA的新方法，利用低秩更新来训练大规模神经网络。在预训练的Transformer语言模型中，我们观察到ReLoRA在与常规神经网络训练相比的性能表现上相当，并发现其在模型越大的情况下效率越高，为高效训练千亿级参数网络提供了新的可能性。 |
| [^46] | [Style Over Substance: Evaluation Biases for Large Language Models.](http://arxiv.org/abs/2307.03025) | 这项研究调查了人类和基于大型语言模型的评委在比较不同模型输出时的行为，并发现评估过程中存在偏见，即尽管包含事实错误，答案仍然被更高地评分。为了解决这个问题，我们提出了 |
| [^47] | [BatGPT: A Bidirectional Autoregessive Talker from Generative Pre-trained Transformer.](http://arxiv.org/abs/2307.00360) | BatGPT是一个双向自回归对话生成模型，能够高效捕捉自然语言的复杂依赖关系，并通过双向建模和参数扩展方法来改善对话生成的效果。这是一个在语言生成领域取得重要贡献的模型。 |
| [^48] | [PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in Poetry Generation.](http://arxiv.org/abs/2306.08456) | 本文提出了PoetryDiffusion模型，利用扩散模型生成诗歌，同时考虑了语义和韵律方面的控制，具有较高的实用性和创新性。 |
| [^49] | [Adaptive Contextual Biasing for Transducer Based Streaming Speech Recognition.](http://arxiv.org/abs/2306.00804) | 该论文提出了一种自适应上下文偏置方法，基于Context-Aware Transformer Transducer (CATT) 来进行流式语音识别的预测。实验结果表明，与基线相比，该方法在 WER 和 CER 上可以分别减少6.7%和20.7%，减少了96.7%和84.9% 的相对 WER 和 CER 增加。 |
| [^50] | [GripRank: Bridging the Gap between Retrieval and Generation via the Generative Knowledge Improved Passage Ranking.](http://arxiv.org/abs/2305.18144) | GripRank是一种通过将生成式知识应用于段落排序，填补检索和文本生成之间差距的方法。 |
| [^51] | [A Framework For Refining Text Classification and Object Recognition from Academic Articles.](http://arxiv.org/abs/2305.17401) | 本文提出了一种结合基于规则的方法和机器学习的框架，旨在解决从学术论文中提炼文本分类和对象识别的问题。 |
| [^52] | [ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification.](http://arxiv.org/abs/2305.04003) | 本文介绍了一种名为ANTONIO的Python库，它基于抽象解释方法提供了一种实用的方法和启发式规则，以便为自然语言处理（NLP）数据集和模型生成已知验证方法的基准。因为其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。 |
| [^53] | [LeafAI: query generator for clinical cohort discovery rivaling a human programmer.](http://arxiv.org/abs/2304.06203) | 该研究开发了一个名为LeafAI的系统，可以生成数据模型不受限制的查询，同时为复杂的临床试验资格标准提供新颖的逻辑推理能力。 |
| [^54] | [SGL-PT: A Strong Graph Learner with Graph Prompt Tuning.](http://arxiv.org/abs/2302.12449) | SGL-PT是一个具有图形提示调优的强大图形学习器，以缩小预训练和下游图形任务之间的差距，并提供一致的训练目标来增强预训练模型的能力。 |
| [^55] | [SuS-X: Training-Free Name-Only Transfer of Vision-Language Models.](http://arxiv.org/abs/2211.16198) | 本文提出了SuS-X，一种无需训练的基于名称的视觉语言模型迁移方法，具有较高的零样本分类能力。 |

# 详细

[^1]: RAVEN：上下文学习与检索增强的编码器-解码器语言模型

    RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models. (arXiv:2308.07922v1 [cs.CL])

    [http://arxiv.org/abs/2308.07922](http://arxiv.org/abs/2308.07922)

    RAVEN是一种结合了检索增强的蒙特卡洛语言建模和前缀语言建模的模型，通过引入上下文融合学习，它能够在上下文学习方面取得比ATLAS更好的性能。

    

    本文研究了检索增强的编码器-解码器语言模型在上下文学习方面的能力。我们首先对现有的ATLAS模型进行全面分析，发现其在上下文学习方面存在限制，主要原因是预训练和测试之间存在不匹配，以及上下文长度受限。为了解决这些问题，我们提出了RAVEN模型，该模型结合了检索增强的蒙特卡洛语言建模和前缀语言建模。我们还引入了上下文融合学习，通过使模型能够利用更多上下文示例而无需额外训练或模型修改来提高少样本性能。通过大量实验，我们证明了RAVEN在某些场景下明显优于ATLAS，并达到了与最先进的语言模型相当的结果，尽管参数数量显著较少。我们的工作强调了检索增强的编码器-解码器语言模型的潜力。

    In this paper, we investigate the in-context learning ability of retrieval-augmented encoder-decoder language models. We first conduct a comprehensive analysis of the state-of-the-art ATLAS model and identify its limitations in in-context learning, primarily due to a mismatch between pretraining and testing, as well as a restricted context length. To address these issues, we propose RAVEN, a model that combines retrieval-augmented masked language modeling and prefix language modeling. We further introduce Fusion-in-Context Learning to enhance the few-shot performance by enabling the model to leverage more in-context examples without requiring additional training or model modifications. Through extensive experiments, we demonstrate that RAVEN significantly outperforms ATLAS and achieves results comparable to the most advanced language models in certain scenarios, despite having substantially fewer parameters. Our work underscores the potential of retrieval-augmented encoder-decoder lang
    
[^2]: 使用GPT-4代码解释器和基于代码的自我验证解决具有挑战性的数学问题

    Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification. (arXiv:2308.07921v1 [cs.CL])

    [http://arxiv.org/abs/2308.07921](http://arxiv.org/abs/2308.07921)

    本文研究了使用GPT-4代码解释器解决数学问题的方法，并提出了显式的基于代码的自我验证（CSV）方法，用于进一步提升GPT-4 Code Interpreter的数学推理能力。

    

    最近大型语言模型（LLMs）如GPT-4和PaLM-2在解决数学推理问题方面取得了显著进展。尤其是OpenAI的最新版本GPT-4 Code Interpreter在挑战性的数学数据集上表现出色。本文通过引入不同的约束条件，探讨了代码对提升LLMs推理能力的影响。我们发现其成功很大程度上归功于其在生成和执行代码、评估代码执行结果以及修正解决方案时的强大技巧。基于这一洞察，我们提出了一种新颖有效的提示方法，即显式的基于代码的自我验证（CSV），以进一步提升GPT-4 Code Interpreter的数学推理潜力。该方法在GPT-4 Code Interpreter上采用零-shot提示，鼓励其使用代码进行推理。

    Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has brought significant advancements in addressing math reasoning problems. In particular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter, shows remarkable performance on challenging math datasets. In this paper, we explore the effect of code on enhancing LLMs' reasoning capability by introducing different constraints on the \textit{Code Usage Frequency} of GPT-4 Code Interpreter. We found that its success can be largely attributed to its powerful skills in generating and executing code, evaluating the output of code execution, and rectifying its solution when receiving unreasonable outputs. Based on this insight, we propose a novel and effective prompting method, explicit \uline{c}ode-based \uline{s}elf-\uline{v}erification~(CSV), to further boost the mathematical reasoning potential of GPT-4 Code Interpreter. This method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to use 
    
[^3]: 通过核心竞争力的视角：大型语言模型评估调查

    Through the Lens of Core Competency: Survey on Evaluation of Large Language Models. (arXiv:2308.07902v1 [cs.CL])

    [http://arxiv.org/abs/2308.07902](http://arxiv.org/abs/2308.07902)

    本论文通过核心竞争力的视角，调查了大型语言模型(LLM)评估的多篇论文，总结出LLM的4个核心竞争力：推理能力、知识能力、可靠性和安全性，并介绍了对应的基准和评估指标。

    

    从预训练语言模型（PLM）到大型语言模型（LLM），自然语言处理（NLP）领域已经见证了快速的性能提升和广泛的实际应用。然而，由于LLM的卓越性能，对其进行全面评估极其困难，主要有两个原因：首先，传统的NLP任务在LLM表现出色之后变得不够适用；其次，现有的评估任务难以跟上实际场景中广泛应用的速度。为了解决这些问题，已有研究提出了各种基准来更好地评估LLM。为了澄清学术界和工业界中与LLM评估相关的众多论文，我们调查了多篇关于LLM评估的论文。我们总结了LLM的4个核心竞争力，包括推理能力、知识能力、可靠性和安全性。对于每个核心竞争力，我们介绍了其定义、对应的基准和评估指标。基于这个核心竞争力体系，类似的任务可进行比较。

    From pre-trained language model (PLM) to large language model (LLM), the field of natural language processing (NLP) has witnessed steep performance gains and wide practical uses. The evaluation of a research field guides its direction of improvement. However, LLMs are extremely hard to thoroughly evaluate for two reasons. First of all, traditional NLP tasks become inadequate due to the excellent performance of LLM. Secondly, existing evaluation tasks are difficult to keep up with the wide range of applications in real-world scenarios. To tackle these problems, existing works proposed various benchmarks to better evaluate LLMs. To clarify the numerous evaluation tasks in both academia and industry, we investigate multiple papers concerning LLM evaluations. We summarize 4 core competencies of LLM, including reasoning, knowledge, reliability, and safety. For every competency, we introduce its definition, corresponding benchmarks, and metrics. Under this competency architecture, similar ta
    
[^4]: 正则表达式推理挑战

    The Regular Expression Inference Challenge. (arXiv:2308.07899v1 [cs.LG])

    [http://arxiv.org/abs/2308.07899](http://arxiv.org/abs/2308.07899)

    正则表达式推理挑战是一个以找到最小正则表达式为目标的任务，具有应用广泛、难度可调、适用于代码/语言建模和机器学习的特点。

    

    我们提出将正则表达式推理（REI）作为代码/语言建模以及更广泛的机器学习社区的挑战。REI是一个有监督的机器学习和程序合成任务，它提出了从示例中找到最小正则表达式的问题：给定两个有限字符串集合P和N以及一个成本函数cost(·)，任务是生成一个接受P中所有字符串并拒绝N中所有字符串的表达式r，而不存在其他表达式r'，使得cost(r')<cost(r)。REI作为一个挑战问题具有以下优势：（i）正则表达式是众所周知、广泛使用的，是代码的自然理想化；（ii）REI的渐近最坏情况复杂性已被充分理解；（iii）REI具有一小部分易于理解的参数（例如P或N的基数、示例的字符串长度或成本函数），这使得我们可以轻松调整REI的难度；（iv）对于基于深度学习的M模型而言，REI是一个未解决的问题。

    We propose \emph{regular expression inference (REI)} as a challenge for code/language modelling, and the wider machine learning community. REI is a supervised machine learning (ML) and program synthesis task, and poses the problem of finding minimal regular expressions from examples: Given two finite sets of strings $P$ and $N$ and a cost function $\text{cost}(\cdot)$, the task is to generate an expression $r$ that accepts all strings in $P$ and rejects all strings in $N$, while no other such expression $r'$ exists with $\text{cost}(r')<\text{cost}(r)$.  REI has advantages as a challenge problem: (i) regular expressions are well-known, widely used, and a natural idealisation of code; (ii) REI's asymptotic worst-case complexity is well understood; (iii) REI has a small number of easy to understand parameters (e.g.~$P$ or $N$ cardinality, string lengths of examples, or the cost function); this lets us easily finetune REI-hardness; (iv) REI is an unsolved problem for deep learning based M
    
[^5]: 多模态LLM的链接上下文学习

    Link-Context Learning for Multimodal LLMs. (arXiv:2308.07891v1 [cs.CV])

    [http://arxiv.org/abs/2308.07891](http://arxiv.org/abs/2308.07891)

    链接上下文学习(LCL)通过从因果关系中推理来增强多模态大型语言模型(MLLMs)的学习能力，引导模型辨别类比关系并揭示潜在的因果关联，提升了对未见过数据的识别和理解。

    

    在人类对话中，从上下文中学习新概念并提供适当的回应是至关重要的。尽管目前的多模态大型语言模型(MLLMs)和大型语言模型(LLMs)在大规模数据集上进行了训练，但在无需训练的情况下识别未见过的图像或理解新概念仍然是一个挑战。上下文学习(ICL)探索了无需训练的少样本学习，鼓励模型从有限的任务中“学会学习”并泛化到未见过的任务。在这项工作中，我们提出了链接上下文学习(LCL)，强调“从因果关系中推理”以增强MLLMs的学习能力。LCL超越传统的ICL，通过明确加强支持集和查询集之间的因果关系，提供具有因果链接的演示，引导模型不仅辨别类比关系，还揭示数据点之间的潜在因果关联，提升了MLLMs实现相应推荐的能力。

    The ability to learn from context with novel concepts, and deliver appropriate responses are essential in human conversations. Despite current Multimodal Large Language Models (MLLMs) and Large Language Models (LLMs) being trained on mega-scale datasets, recognizing unseen images or understanding novel concepts in a training-free manner remains a challenge. In-Context Learning (ICL) explores training-free few-shot learning, where models are encouraged to ``learn to learn" from limited tasks and generalize to unseen tasks. In this work, we propose link-context learning (LCL), which emphasizes "reasoning from cause and effect" to augment the learning capabilities of MLLMs. LCL goes beyond traditional ICL by explicitly strengthening the causal relationship between the support set and the query set. By providing demonstrations with causal links, LCL guides the model to discern not only the analogy but also the underlying causal associations between data points, which empowers MLLMs to reco
    
[^6]: 基于规则学习的关系模式的知识图嵌入的综合研究

    A Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning. (arXiv:2308.07889v1 [cs.AI])

    [http://arxiv.org/abs/2308.07889](http://arxiv.org/abs/2308.07889)

    本研究主要通过对7个知识图嵌入模型在4种常见关系模式上的性能评估，以及理论、实体频率和整体分析，探讨了知识图嵌入模型在不同关系模式下的能力，并得出了一些具有讽刺意味的结论。

    

    知识图嵌入（KGE）已被证明是解决知识图补全（KGC）任务的有效方法。关系模式是指具有特定语义的关系，展示图形模式，是影响KGE模型性能的重要因素。尽管理论上分析了KGE模型在不同关系模式上的能力，并建立了更好的关系模式建模与KGC更好性能之间的粗略关联，但对于KGE模型在关系模式上的综合定量分析尚未完成，因此不确定KGE对于关系模式的理论支持如何影响与此关系模式相关的三元组的性能。为解决这个挑战，我们评估了7个KGE模型在4个常见关系模式上的性能，并在2个基准数据集上进行了理论、实体频率和整体分析，得出了一些直观的结论。

    Knowledge Graph Embedding (KGE) has proven to be an effective approach to solving the Knowledge Graph Completion (KGC) task. Relational patterns which refer to relations with specific semantics exhibiting graph patterns are an important factor in the performance of KGE models. Though KGE models' capabilities are analyzed over different relational patterns in theory and a rough connection between better relational patterns modeling and better performance of KGC has been built, a comprehensive quantitative analysis on KGE models over relational patterns remains absent so it is uncertain how the theoretical support of KGE to a relational pattern contributes to the performance of triples associated to such a relational pattern. To address this challenge, we evaluate the performance of 7 KGE models over 4 common relational patterns on 2 benchmarks, then conduct an analysis in theory, entity frequency, and part-to-whole three aspects and get some counterintuitive conclusions. Finally, we int
    
[^7]: 通过编码本知识、自然语言推理和ChatGPT来合成政治零样本关系分类

    Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT. (arXiv:2308.07876v1 [cs.CL])

    [http://arxiv.org/abs/2308.07876](http://arxiv.org/abs/2308.07876)

    该论文通过利用已建立的注释编码本的知识，探索零样本方法用于政治事件本体关系分类，并介绍一种基于自然语言推理的方法，名为ZSP。ZSP采用了一种树查询框架，提高了解释性、效率和对模式更改的适应性。在细粒度根代码分类上，ZSP的性能明显优于ChatGPT，F1得分提高了40%。

    

    最近的事件编码的监督模型在性能方面远远超过模式匹配方法。然而，它们仅仅依赖于新的注释，忽视了专家数据库中的大量知识，限制了它们在细粒度分类中的适用性。为了解决这些限制，我们通过利用已建立的注释编码本的知识，探索零样本方法用于政治事件本体关系分类。我们的研究涵盖了ChatGPT和一种新颖的基于自然语言推理的方法，名为ZSP。ZSP采用了一种树查询框架，将任务分解为上下文、语态和类别消歧的不同层次。该框架提高了解释性、效率和对模式更改的适应性。通过在我们新策划的数据集上进行大量实验，我们指出了ChatGPT中的不稳定性问题，并突出了ZSP的卓越性能。ZSP在细粒度根代码分类的F1得分上取得了令人印象深刻的提高40%。

    Recent supervised models for event coding vastly outperform pattern-matching methods. However, their reliance solely on new annotations disregards the vast knowledge within expert databases, hindering their applicability to fine-grained classification. To address these limitations, we explore zero-shot approaches for political event ontology relation classification, by leveraging knowledge from established annotation codebooks. Our study encompasses both ChatGPT and a novel natural language inference (NLI) based approach named ZSP. ZSP adopts a tree-query framework that deconstructs the task into context, modality, and class disambiguation levels. This framework improves interpretability, efficiency, and adaptability to schema changes. By conducting extensive experiments on our newly curated datasets, we pinpoint the instability issues within ChatGPT and highlight the superior performance of ZSP. ZSP achieves an impressive 40% improvement in F1 score for fine-grained Rootcode classific
    
[^8]: 情感嵌入——从异质情感数据中学习稳定且均匀的抽象表示

    Emotion Embeddings $\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets. (arXiv:2308.07871v1 [cs.LG])

    [http://arxiv.org/abs/2308.07871](http://arxiv.org/abs/2308.07871)

    这篇论文提出了一种统一的计算模型，通过学习情感嵌入，独立于不同的语言、交流方式、媒体或标签形式，从而将以往对不同类型异质情感数据的研究整合起来。

    

    人类情感通过多种交流方式和媒体格式表达，因此它们的计算研究同样多样化，涉及到自然语言处理、音频信号分析、计算机视觉等等。在先前的研究中，情感被以不同的形式进行描述（极性尺度、基本情感类别、维度方法、评价理论等），导致数据集、预测模型和情感分析软件工具的多样化增长。由于这两种不同类型的异质性，在表达和表示层面上，迫切需要统一以往对越来越分散的数据和标签类型的研究成果。本文提出了一个统一的计算模型。我们提出了一种训练过程，可以学习一种共享的情感潜在表示，即所谓情感嵌入，不依赖于不同的自然语言、交流方式、媒体或表示标签形式。

    Human emotion is expressed in many communication modalities and media formats and so their computational study is equally diversified into natural language processing, audio signal analysis, computer vision, etc. Similarly, the large variety of representation formats used in previous research to describe emotions (polarity scales, basic emotion categories, dimensional approaches, appraisal theory, etc.) have led to an ever proliferating diversity of datasets, predictive models, and software tools for emotion analysis. Because of these two distinct types of heterogeneity, at the expressional and representational level, there is a dire need to unify previous work on increasingly diverging data and label types. This article presents such a unifying computational model. We propose a training procedure that learns a shared latent representation for emotions, so-called emotion embeddings, independent of different natural languages, communication modalities, media or representation label form
    
[^9]: 为生成式语言模型提供信息的命名实体识别解码

    Informed Named Entity Recognition Decoding for Generative Language Models. (arXiv:2308.07791v1 [cs.CL])

    [http://arxiv.org/abs/2308.07791](http://arxiv.org/abs/2308.07791)

    该论文提出了一种利用生成式语言模型进行命名实体识别解码的方法，通过在信息提取过程中应用生成模型的语言理解能力，提高了性能并消除了幻觉的风险。

    

    越来越大的语言模型具有越来越强的能力，已成为被广泛应用的文本处理工具。然而，信息提取任务，如命名实体识别，仍然受到之前一代仅编码器的转换器模型的影响。在这里，我们提出了一种简单但有效的方法，称为Informed Named Entity Recognition Decoding（iNERD），它将命名实体识别视为一种生成过程。它以面向未来的方式利用最近生成模型的语言理解能力，并采用了一种基于信息提取的有限文本生成方法，提高了性能并消除了任何幻觉的风险。我们在合并的命名实体语料库上粗调优化了模型，评估了五个生成式语言模型在八个命名实体识别数据集上的表现，并取得了显著的结果。

    Ever-larger language models with ever-increasing capabilities are by now well-established text processing tools. Alas, information extraction tasks such as named entity recognition are still largely unaffected by this progress as they are primarily based on the previous generation of encoder-only transformer models. Here, we propose a simple yet effective approach, Informed Named Entity Recognition Decoding (iNERD), which treats named entity recognition as a generative process. It leverages the language understanding capabilities of recent generative models in a future-proof manner and employs an informed decoding scheme incorporating the restricted nature of information extraction into open-ended text generation, improving performance and eliminating any risk of hallucinations. We coarse-tune our model on a merged named entity corpus to strengthen its performance, evaluate five generative language models on eight named entity recognition datasets, and achieve remarkable results, espec
    
[^10]: 通过布局结构建模增强视觉丰富文档理解

    Enhancing Visually-Rich Document Understanding via Layout Structure Modeling. (arXiv:2308.07777v1 [cs.CL])

    [http://arxiv.org/abs/2308.07777](http://arxiv.org/abs/2308.07777)

    本研究提出一种新的文档理解模型GraphLayoutLM，通过建模布局结构图将文档布局知识注入模型中，并利用布局感知的自注意力层来学习文档布局知识。模型在多个基准测试集上取得了最先进的结果，表明其优越性能。

    

    近年来，多模态预训练变换器的使用在视觉丰富文档理解方面取得了显著进展。然而，现有模型主要关注文本和图像等特征，忽视了文本节点之间布局关系的重要性。在本文中，我们提出了GraphLayoutLM，一种新颖的文档理解模型，它利用布局结构图的建模将文档布局知识注入模型中。GraphLayoutLM利用图重排序算法，根据图结构调整文本序列。此外，我们的模型使用了一个布局感知的多头自注意力层来学习文档布局知识。所提出的模型能够理解文本元素的空间排列，提高文档理解能力。我们在FUNSD、XFUND和CORD等多个基准测试集上评估了我们的模型，并在这些数据集中取得了最先进的结果。我们的实验结果证明了模型的优越性能。

    In recent years, the use of multi-modal pre-trained Transformers has led to significant advancements in visually-rich document understanding. However, existing models have mainly focused on features such as text and vision while neglecting the importance of layout relationship between text nodes. In this paper, we propose GraphLayoutLM, a novel document understanding model that leverages the modeling of layout structure graph to inject document layout knowledge into the model. GraphLayoutLM utilizes a graph reordering algorithm to adjust the text sequence based on the graph structure. Additionally, our model uses a layout-aware multi-head self-attention layer to learn document layout knowledge. The proposed model enables the understanding of the spatial arrangement of text elements, improving document comprehension. We evaluate our model on various benchmarks, including FUNSD, XFUND and CORD, and achieve state-of-the-art results among these datasets. Our experimental results demonstrat
    
[^11]: 在大型语言模型中使用反向推理进行验证

    Backward Reasoning in Large Language Models for Verification. (arXiv:2308.07758v1 [cs.CL])

    [http://arxiv.org/abs/2308.07758](http://arxiv.org/abs/2308.07758)

    本文研究了在大型语言模型中使用反向推理进行验证的方法。作者提出了一种新颖的技术，通过屏蔽问题中的一个标记，并要求语言模型预测被屏蔽的标记来验证候选答案。同时，作者还提出了一种结合正向和反向推理的方法来估计候选答案的概率。

    

    链式思考（Chain-of-Though, CoT）提示在各种推理任务中表现出了很好的性能。最近，Self-Consistency提出了一种方法，即通过采样一组不同的推理链，这些链可能导致不同的答案，然后选择得票最多的答案。本文提出了一种新颖的方法，即在验证候选答案时使用反向推理。我们使用一个简单的模板，即``如果我们知道上述问题的答案是候选答案，那么未知变量x的值是多少？''，将问题中的一个标记屏蔽，并要求语言模型预测被屏蔽的标记。直观上讲，如果提供的候选答案是正确的，语言模型应该能够成功预测被屏蔽的标记。我们进一步提出了FOBAR方法，将正向和反向推理结合起来估计候选答案的概率。我们在六个数据集和三个实验中进行了广泛的实验。

    Chain-of-Though (CoT) prompting has shown promising performance in various reasoning tasks. Recently, Self-Consistency \citep{wang2023selfconsistency} proposes to sample a diverse set of reasoning chains which may lead to different answers while the answer that receives the most votes is selected. In this paper, we propose a novel method to use backward reasoning in verifying candidate answers. We mask a token in the question by ${\bf x}$ and ask the LLM to predict the masked token when a candidate answer is provided by \textit{a simple template}, i.e., ``\textit{\textbf{If we know the answer of the above question is \{a candidate answer\}, what is the value of unknown variable ${\bf x}$?}}'' Intuitively, the LLM is expected to predict the masked token successfully if the provided candidate answer is correct. We further propose FOBAR to combine forward and backward reasoning for estimating the probability of candidate answers. We conduct extensive experiments on six data sets and three
    
[^12]: SPM: Meituan搜索中用于相关性建模的结构化预训练和匹配架构

    SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search. (arXiv:2308.07711v1 [cs.IR])

    [http://arxiv.org/abs/2308.07711](http://arxiv.org/abs/2308.07711)

    本论文提出了一种用于在Meituan搜索中进行相关性建模的新颖两阶段预训练和匹配架构。

    

    在电商搜索中，查询和文档之间的相关性是满足用户体验的基本要求。与传统的电商平台不同，用户在美团等生活服务平台上进行搜索主要是为了产品供应商，这些供应商通常拥有丰富的结构化信息，例如名称、地址、类别、成千上万的产品。使用这些丰富的结构化内容进行搜索相关性建模具有挑战性，主要存在以下问题：（1）不同字段的结构化文档存在语言分布差异，无法直接采用预训练的语言模型方法（如BERT）。（2）不同字段通常具有不同的重要性，且长度差异很大，很难提取对相关性匹配有帮助的文档信息。为了解决这些问题，本文提出了一种新的两阶段预训练和匹配架构，用于丰富结构的相关性匹配。

    In e-commerce search, relevance between query and documents is an essential requirement for satisfying user experience. Different from traditional e-commerce platforms that offer products, users search on life service platforms such as Meituan mainly for product providers, which usually have abundant structured information, e.g. name, address, category, thousands of products. Modeling search relevance with these rich structured contents is challenging due to the following issues: (1) there is language distribution discrepancy among different fields of structured document, making it difficult to directly adopt off-the-shelf pretrained language model based methods like BERT. (2) different fields usually have different importance and their length vary greatly, making it difficult to extract document information helpful for relevance matching.  To tackle these issues, in this paper we propose a novel two-stage pretraining and matching architecture for relevance matching with rich structure
    
[^13]: 利用视觉-语言模型在医学图像分割中探索迁移学习

    Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models. (arXiv:2308.07706v1 [cs.CV])

    [http://arxiv.org/abs/2308.07706](http://arxiv.org/abs/2308.07706)

    本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。

    

    医学图像分割在医学领域的各种临床应用中至关重要。尽管最先进的分割模型已被证明有效，但在这个任务中整合文本指导以增强视觉特征仍然是一个进展有限的领域。现有利用文本指导的分割模型主要在开放领域图像上训练，这引发了在医学领域直接应用的难题，需要手动介入或进行微调。为了解决这些挑战，我们提出使用多模态的视觉-语言模型从图像描述和图像中捕捉语义信息，使得能够对多样化的医学图像进行分割。该研究全面评估了现有的视觉-语言模型在多个数据集上的可迁移性，以评估其从开放领域向医学领域的迁移能力。此外，我们对数据集中以前未见图像的图像描述引入了变化，揭示了显著的变异。

    Medical Image Segmentation is crucial in various clinical applications within the medical domain. While state-of-the-art segmentation models have proven effective, integrating textual guidance to enhance visual features for this task remains an area with limited progress. Existing segmentation models that utilize textual guidance are primarily trained on open-domain images, raising concerns about their direct applicability in the medical domain without manual intervention or fine-tuning.  To address these challenges, we propose using multimodal vision-language models for capturing semantic information from image descriptions and images, enabling the segmentation of diverse medical images. This study comprehensively evaluates existing vision language models across multiple datasets to assess their transferability from the open domain to the medical field. Furthermore, we introduce variations of image descriptions for previously unseen images in the dataset, revealing notable variations 
    
[^14]: 通过角色扮演提示提高零-shot推理能力

    Better Zero-Shot Reasoning with Role-Play Prompting. (arXiv:2308.07702v1 [cs.CL])

    [http://arxiv.org/abs/2308.07702](http://arxiv.org/abs/2308.07702)

    通过角色扮演提示，研究评估了现代大型语言模型在零-shot推理场景下的表现，并发现角色扮演提示在多个推理基准测试中都超越了标准的零-shot方法。

    

    现代大型语言模型（LLM），如ChatGPT，展示了出色的角色扮演能力，使其能够扮演不仅是人类角色，还包括像Linux终端这样的非人角色。这种多功能性使它们能够在不同的上下文中模拟复杂的人类交互和行为，并仿真特定的对象或系统。尽管这些能力增强了用户参与度并引入了新的交互模式，但角色扮演对LLM的推理能力的影响仍有待深入探究。在本研究中，我们引入了一种策略性设计的角色扮演提示方法，并在十二个不同的推理基准测试中评估其在零-shot设置下的性能，涵盖了算术、常识推理、符号推理等多个领域。利用ChatGPT和Llama 2等模型，我们的实证结果表明，角色扮演提示在大多数数据集上始终优于标准的零-shot方法。值得注意的是，一个

    Modern large language models (LLMs), such as ChatGPT, exhibit a remarkable capacity for role-playing, enabling them to embody not only human characters but also non-human entities like a Linux terminal. This versatility allows them to simulate complex human-like interactions and behaviors within various contexts, as well as to emulate specific objects or systems. While these capabilities have enhanced user engagement and introduced novel modes of interaction, the influence of role-playing on LLMs' reasoning abilities remains underexplored. In this study, we introduce a strategically designed role-play prompting methodology and assess its performance under the zero-shot setting across twelve diverse reasoning benchmarks, encompassing arithmetic, commonsense reasoning, symbolic reasoning, and more. Leveraging models such as ChatGPT and Llama 2, our empirical results illustrate that role-play prompting consistently surpasses the standard zero-shot approach across most datasets. Notably, a
    
[^15]: 注意力不再是唯一需要的东西了。

    Attention Is Not All You Need Anymore. (arXiv:2308.07661v1 [cs.LG])

    [http://arxiv.org/abs/2308.07661](http://arxiv.org/abs/2308.07661)

    本文提出了一种名为Extractor的插入替代器，用于取代Transformer中的自注意机制，实验证明使用Extractor可以提高Transformer的性能，并且具有更短的计算关键路径。

    

    在最近几年中，流行的Transformer架构在自然语言处理和计算机视觉等许多应用领域取得了巨大成功。许多现有的工作旨在通过性能平衡来减少Transformer中自注意机制的计算和存储复杂度。然而，性能对于Transformer的持续成功至关重要。本文提出了一种用于取代Transformer中自注意机制的插入替代器（Extractor）。实验结果表明，使用Extractor替换自注意机制可以提高Transformer的性能。此外，Extractor具有更短的计算关键路径，因此有潜力比自注意更快。此外，本文还使用可变长离散时间马尔可夫链对文本生成中的序列预测问题进行了建模，并针对我们的插入替代器对Transformer进行了评估。

    In recent years, the popular Transformer architecture has achieved great success in many application areas, including natural language processing and computer vision. Many existing works aim to reduce the computational and memory complexity of the self-attention mechanism in the Transformer by trading off performance. However, performance is key for the continuing success of the Transformer. In this paper, a drop-in replacement for the self-attention mechanism in the Transformer, called the Extractor, is proposed. Experimental results show that replacing the self-attention mechanism with the Extractor improves the performance of the Transformer. Furthermore, the proposed Extractor has the potential to run faster than the self-attention since it has a much shorter critical path of computation. Additionally, the sequence prediction problem in the context of text generation is formulated using variable-length discrete-time Markov chains, and the Transformer is reviewed based on our unders
    
[^16]: SEER：使用MLIR进行E图重写的HLS超级优化探索器

    SEER: Super-Optimization Explorer for HLS using E-graph Rewriting with MLIR. (arXiv:2308.07654v1 [cs.PL])

    [http://arxiv.org/abs/2308.07654](http://arxiv.org/abs/2308.07654)

    SEER是一个基于E图重写和MLIR的超级优化探索器，用于将软件程序自动转换为高效的硬件描述，填补了高级综合工具生成的硬件设计与手动实现之间的性能差距。

    

    高级综合（HLS）是一个将高级语言编写的软件程序自动转换为低级硬件描述的过程。然而，由HLS工具生成的硬件设计与手动实现相比仍然存在显著的性能差距。这是因为输入的HLS程序仍必须按照硬件设计原则编写。现有的技术要么保持程序源代码不变，要么执行一系列固定的源代码转换步骤，可能会错过寻找最优设计的机会。我们提出了一种HLS的超级优化方法，可以自动将任意软件程序重写为高效的HLS代码，用于生成优化的硬件设计。我们开发了一个名为SEER的工具流程，基于E图数据结构，以高效地探索程序的等效实现。SEER提供了一个可扩展的框架，协调现有的软件编译器传递和硬

    High-level synthesis (HLS) is a process that automatically translates a software program in a high-level language into a low-level hardware description. However, the hardware designs produced by HLS tools still suffer from a significant performance gap compared to manual implementations. This is because the input HLS programs must still be written using hardware design principles.  Existing techniques either leave the program source unchanged or perform a fixed sequence of source transformation passes, potentially missing opportunities to find the optimal design. We propose a super-optimization approach for HLS that automatically rewrites an arbitrary software program into efficient HLS code that can be used to generate an optimized hardware design. We developed a toolflow named SEER, based on the e-graph data structure, to efficiently explore equivalent implementations of a program at scale. SEER provides an extensible framework, orchestrating existing software compiler passes and har
    
[^17]: 引导语言生成：利用对比专家指导和负面提示进行一致性和多样性的合成数据生成

    Steering Language Generation: Harnessing Contrastive Expert Guidance and Negative Prompting for Coherent and Diverse Synthetic Data Generation. (arXiv:2308.07645v1 [cs.CL])

    [http://arxiv.org/abs/2308.07645](http://arxiv.org/abs/2308.07645)

    该论文提出了一种引导语言生成的方法，通过对比专家指导和负面提示，实现了连贯和多样性的合成数据生成。该方法在推理时间内操作，利用对比形式指导LLMs在数据分布的一致性和与先前示例的偏离之间取得平衡。

    

    大型语言模型（LLMs）具有生成高质量和实用的合成数据的巨大潜力，这在从下游模型训练到实际数据利用的各种应用中都有很多。然而，尽管现代模型的能力令人印象深刻，却经常难以产生既连贯又多样化的数据。为了解决连贯性问题，我们引入了对比形式专家指导，强调了精细调整和基本语言模型之间的逻辑分布差异，以确保领域的一致性。为了保证多样性，我们利用现有的真实和合成的例子作为模型的负面提示。我们将这种对逻辑重塑的双重方法称为STEER：通过嵌入重新定位实现的语义文本增强。STEER在推理时间内运行，并系统地指导LLMs在数据分布的一致性（确保语义保真度）与先前合成示例或现有真实数据之间取得平衡。

    Large Language Models (LLMs) hold immense potential to generate synthetic data of high quality and utility, which has numerous applications from downstream model training to practical data utilisation. However, contemporary models, despite their impressive capacities, consistently struggle to produce both coherent and diverse data. To address the coherency issue, we introduce contrastive expert guidance, where the difference between the logit distributions of fine-tuned and base language models is emphasised to ensure domain adherence. In order to ensure diversity, we utilise existing real and synthetic examples as negative prompts to the model. We deem this dual-pronged approach to logit reshaping as STEER: Semantic Text Enhancement via Embedding Repositioning. STEER operates at inference-time and systematically guides the LLMs to strike a balance between adherence to the data distribution (ensuring semantic fidelity) and deviation from prior synthetic examples or existing real datase
    
[^18]: LLM-Mini-CEX: 用于诊断对话的大型语言模型的自动评估

    LLM-Mini-CEX: Automatic Evaluation of Large Language Model for Diagnostic Conversation. (arXiv:2308.07635v1 [cs.CL])

    [http://arxiv.org/abs/2308.07635](http://arxiv.org/abs/2308.07635)

    本研究提出了一种用于诊断对话的自动评估方法，通过建立LLM-specific Mini-CEX评估标准和使用患者模拟器与ChatGPT自动评估诊断对话，解决了医学LLMs评估中的统一和全面性问题。

    

    在开发用于医学诊断的LLM（大型语言模型）以提高诊断效率方面引起了越来越多的兴趣。尽管它们具有吸引人的技术潜力，但缺乏统一和全面的评估标准导致无法评估医学LLMs的质量和潜在风险，进一步阻碍了LLMs在医疗治疗场景中的应用。此外，当前的评估严重依赖于与LLMs进行劳动密集型的交互以获取诊断对话和人工评估诊断对话的质量。为了解决缺乏统一和全面评估标准的问题，我们首先根据原始的Mini-CEX建立了一个评估标准，称为LLM-specific Mini-CEX，以有效评估LLMs的诊断能力。为了解决劳动密集型交互问题，我们开发了一个患者模拟器与LLMs自动进行对话，并利用ChatGPT自动评估诊断对话。

    There is an increasing interest in developing LLMs for medical diagnosis to improve diagnosis efficiency. Despite their alluring technological potential, there is no unified and comprehensive evaluation criterion, leading to the inability to evaluate the quality and potential risks of medical LLMs, further hindering the application of LLMs in medical treatment scenarios. Besides, current evaluations heavily rely on labor-intensive interactions with LLMs to obtain diagnostic dialogues and human evaluation on the quality of diagnosis dialogue. To tackle the lack of unified and comprehensive evaluation criterion, we first initially establish an evaluation criterion, termed LLM-specific Mini-CEX to assess the diagnostic capabilities of LLMs effectively, based on original Mini-CEX. To address the labor-intensive interaction problem, we develop a patient simulator to engage in automatic conversations with LLMs, and utilize ChatGPT for evaluating diagnosis dialogues automatically. Experimenta
    
[^19]: 关于大型语言模型的模型压缩综述

    A Survey on Model Compression for Large Language Models. (arXiv:2308.07633v1 [cs.CL])

    [http://arxiv.org/abs/2308.07633](http://arxiv.org/abs/2308.07633)

    本论文提供了关于大型语言模型的模型压缩综述，探讨了量化、修剪、知识蒸馏等不同方法，并突出介绍了最新进展和创新方法，为实现高效的部署提供了重要思路。

    

    大型语言模型（LLMs）以惊人的成功彻底改变了自然语言处理任务。然而，它们庞大的体量和计算需求在资源受限环境下的实际部署中带来了重大挑战。随着这些挑战日益紧迫，模型压缩领域已成为一个关键的研究领域，旨在缓解这些限制。本文提供了一份全面的综述，探讨专门针对LLMs的模型压缩技术。我们深入研究了各种方法，包括量化、修剪、知识蒸馏等，以应对高效部署的迫切需求。在每种技术中，我们重点介绍了最新进展和创新方法，为LLM研究的发展提供了贡献。此外，我们还探讨了用于评估效果的基准策略和评估指标的重要性。

    Large Language Models (LLMs) have revolutionized natural language processing tasks with remarkable success. However, their formidable size and computational demands present significant challenges for practical deployment, especially in resource-constrained environments. As these challenges become increasingly pertinent, the field of model compression has emerged as a pivotal research area to alleviate these limitations. This paper presents a comprehensive survey that navigates the landscape of model compression techniques tailored specifically for LLMs. Addressing the imperative need for efficient deployment, we delve into various methodologies, encompassing quantization, pruning, knowledge distillation, and more. Within each of these techniques, we highlight recent advancements and innovative approaches that contribute to the evolving landscape of LLM research. Furthermore, we explore benchmarking strategies and evaluation metrics that are essential for assessing the effectiveness of 
    
[^20]: LogPrompt: 零样本和可解释的日志分析的提示工程

    LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis. (arXiv:2308.07610v1 [cs.SE])

    [http://arxiv.org/abs/2308.07610](http://arxiv.org/abs/2308.07610)

    LogPrompt是一种新颖的零样本和可解释的日志分析方法，通过利用大型语言模型和专为日志任务设计的高级提示策略，实现了对日志的分析，提高了模型的性能和可解释性。

    

    在现代软件密集型系统中，自动化日志分析对于确保软件维护和工程生命周期的可靠性和弹性至关重要。现有方法通过提供单个预测值而没有解释来执行诸如日志解析和日志异常检测等任务。然而，随着系统事件的增加，分析结果的有限可解释性阻碍了分析人员对其的信任度和采取适当行动的能力。此外，这些方法需要大量的领域内培训数据，并且它们的性能在涉及新域的未见过日志的在线场景中急剧下降（最多下降62.5%），这是由于软件更新的迅速而常见的情况。在本文中，我们提出了一个新颖的零样本和可解释的日志分析方法LogPrompt。LogPrompt利用大型语言模型（LLM）通过一套针对日志任务的高级提示策略执行零样本日志分析任务，从而增强LLM的性能。

    Automated log analysis is crucial in modern software-intensive systems for ensuring reliability and resilience throughout software maintenance and engineering life cycles. Existing methods perform tasks such as log parsing and log anomaly detection by providing a single prediction value without interpretation. However, given the increasing volume of system events, the limited interpretability of analysis results hinders analysts' trust and their ability to take appropriate actions. Moreover, these methods require substantial in-domain training data, and their performance declines sharply (by up to 62.5%) in online scenarios involving unseen logs from new domains, a common occurrence due to rapid software updates. In this paper, we propose LogPrompt, a novel zero-shot and interpretable log analysis approach. LogPrompt employs large language models (LLMs) to perform zero-shot log analysis tasks via a suite of advanced prompt strategies tailored for log tasks, which enhances LLMs' perform
    
[^21]: VBD-MT 用于VLSP 2022的中越翻译系统（arXiv:2308.07601v1 [cs.CL]）

    VBD-MT Chinese-Vietnamese Translation Systems for VLSP 2022. (arXiv:2308.07601v1 [cs.CL])

    [http://arxiv.org/abs/2308.07601](http://arxiv.org/abs/2308.07601)

    VBD-MT是VLSP 2022中越翻译任务的系统，通过使用Transformer模型和mBART预训练模型，采用反向翻译和其他方法来提高翻译质量，在公共测试集上表现优秀。

    

    我们介绍了参加VLSP 2022机器翻译共享任务的系统。在今年的共享任务中，我们参加了中越和越中两种翻译任务。我们的系统基于基于神经网络的Transformer模型和强大的多语言去噪预训练模型mBART。系统通过采样法进行反向翻译，利用大规模可用的单语数据进行增强。此外，还采用了其他几种方法来提高翻译质量，包括集成和后处理。在公共测试集上，我们在中越翻译任务上达到了38.9 BLEU，在越中翻译任务上达到了38.0 BLEU，超过了几个强有力的基准系统。

    We present our systems participated in the VLSP 2022 machine translation shared task. In the shared task this year, we participated in both translation tasks, i.e., Chinese-Vietnamese and Vietnamese-Chinese translations. We build our systems based on the neural-based Transformer model with the powerful multilingual denoising pre-trained model mBART. The systems are enhanced by a sampling method for backtranslation, which leverage large scale available monolingual data. Additionally, several other methods are applied to improve the translation quality including ensembling and postprocessing. We achieve 38.9 BLEU on ChineseVietnamese and 38.0 BLEU on VietnameseChinese on the public test sets, which outperform several strong baselines.
    
[^22]: 西班牙文文本简化的用户中心评估

    A User-Centered Evaluation of Spanish Text Simplification. (arXiv:2308.07556v1 [cs.CL])

    [http://arxiv.org/abs/2308.07556](http://arxiv.org/abs/2308.07556)

    通过对西班牙文文本简化的用户评估，我们发现神经网络在预测用户偏好方面表现更好，同时也发现多语言模型不如西班牙文模型在同一任务上的表现。我们发布了评估中的语料库，希望推动西班牙语自然语言处理的最新技术。

    

    我们通过两个语料库，一个针对复杂句子和一个针对复杂词语的识别，对西班牙文文本简化进行了一个生产系统的评估。我们将最流行的西班牙特定可读性评分与神经网络进行了比较，并表明后者在预测用户对文本简化的偏好方面始终更好。作为我们分析的一部分，我们发现多语言模型在相同任务上表现不如仅限于西班牙文的模型，但所有模型过于频繁地关注统计特征，如句子长度。我们将我们评估中的语料库发布给更广泛的社区，希望推动西班牙语自然语言处理的最新技术。

    We present an evaluation of text simplification (TS) in Spanish for a production system, by means of two corpora focused in both complex-sentence and complex-word identification. We compare the most prevalent Spanish-specific readability scores with neural networks, and show that the latter are consistently better at predicting user preferences regarding TS. As part of our analysis, we find that multilingual models underperform against equivalent Spanish-only models on the same task, yet all models focus too often on spurious statistical features, such as sentence length. We release the corpora in our evaluation to the broader community with the hopes of pushing forward the state-of-the-art in Spanish natural language processing.
    
[^23]: CALYPSO: 将LLMs作为Dungeon Masters的助手

    CALYPSO: LLMs as Dungeon Masters' Assistants. (arXiv:2308.07540v1 [cs.CL])

    [http://arxiv.org/abs/2308.07540](http://arxiv.org/abs/2308.07540)

    CALYPSO是一个以LLMs为基础的接口系统，旨在支持Dungeon Masters在龙与地下城和桌面游戏中。它将游戏背景信息转化为简洁的散文，并提供信息和灵感支持，以帮助DM在游戏中维持连贯性并进行头脑风暴。

    

    在游戏龙与地下城中，Dungeon Master（DM）的角色是同时执行多个任务。DM必须了解游戏背景和怪物的信息，综合场景展示给其他玩家，并对玩家与场景的互动作出响应。在保持故事连贯性的同时完成所有任务对于人类认知来说是一项不小的挑战，使新玩家难以接近和理解。大型语言模型（LLMs）如GPT-3和ChatGPT表现出生成连贯自然语言文本的非凡能力。在本文中，我们与DM进行了一项初步评估，以确定在龙与地下城和桌面游戏等领域中使用LLMs的用例。我们介绍了CALYPSO，这是一个由LLM驱动的界面系统，为DM提供与他们自己的场景相关的信息和灵感支持。CALYPSO将游戏背景转化为简洁的散文，并帮助DM在游戏过程中进行头脑风暴，而不会分散DM的注意力。

    The role of a Dungeon Master, or DM, in the game Dungeons & Dragons is to perform multiple tasks simultaneously. The DM must digest information about the game setting and monsters, synthesize scenes to present to other players, and respond to the players' interactions with the scene. Doing all of these tasks while maintaining consistency within the narrative and story world is no small feat of human cognition, making the task tiring and unapproachable to new players. Large language models (LLMs) like GPT-3 and ChatGPT have shown remarkable abilities to generate coherent natural language text. In this paper, we conduct a formative evaluation with DMs to establish the use cases of LLMs in D&D and tabletop gaming generally. We introduce CALYPSO, a system of LLM-powered interfaces that support DMs with information and inspiration specific to their own scenario. CALYPSO distills game context into bite-sized prose and helps brainstorm ideas without distracting the DM from the game. When give
    
[^24]: 使用经过优化的BERT和LSTM模型从10-K报告中找到利益相关方-材料信息

    Finding Stakeholder-Material Information from 10-K Reports using Fine-Tuned BERT and LSTM Models. (arXiv:2308.07522v1 [cs.CL])

    [http://arxiv.org/abs/2308.07522](http://arxiv.org/abs/2308.07522)

    本研究使用经过优化的BERT和LSTM模型，从上市公司的10-K报告中识别出利益相关方-材料信息，显著优于关键词搜索的基准模型。

    

    所有上市公司都要按照联邦证券法的规定在年度10-K报告中披露其业务和财务活动。每份报告通常有数百页，使得人工读者很难高效地识别和提取重要信息。为了解决这个问题，我使用经过优化的BERT模型和带有LSTM层的循环神经网络模型来识别利益相关方-材料信息，即携带有关公司对其利益相关方（包括客户、员工、投资者以及社区和自然环境）影响的陈述。现有的方法使用关键词搜索来识别这种信息，这是我的基准模型。通过对2022年发布的62份10-K报告中近6000个句子进行业务专家标注的训练数据，最佳模型在测试数据中达到了0.904的准确率和0.899的F1分数，远高于基准模型的0.781和0.749。此外，相同的工作已经

    All public companies are required by federal securities law to disclose their business and financial activities in their annual 10-K reports. Each report typically spans hundreds of pages, making it difficult for human readers to identify and extract the material information efficiently. To solve the problem, I have fine-tuned BERT models and RNN models with LSTM layers to identify stakeholder-material information, defined as statements that carry information about a company's influence on its stakeholders, including customers, employees, investors, and the community and natural environment. The existing practice uses keyword search to identify such information, which is my baseline model. Using business expert-labeled training data of nearly 6,000 sentences from 62 10-K reports published in 2022, the best model has achieved an accuracy of 0.904 and an F1 score of 0.899 in test data, significantly above the baseline model's 0.781 and 0.749 respectively. Furthermore, the same work was r
    
[^25]: 使用大型语言模型进行数据竞争检测

    Data Race Detection Using Large Language Models. (arXiv:2308.07505v1 [cs.LG])

    [http://arxiv.org/abs/2308.07505](http://arxiv.org/abs/2308.07505)

    本研究探索了一种基于大型语言模型的数据竞争检测方法，通过结合提示工程和微调技术，发现LLMs可以作为数据竞争检测的可行方法，但在需要详细信息时仍不如传统工具竞争。

    

    大型语言模型（LLMs）作为一种替代策略，展示了在分析和优化高性能计算程序方面的显著优势，避免了资源密集型手动工具的创建。本文中，我们探讨了一种新颖的基于LLM的数据竞争检测方法，结合了提示工程和微调技术。我们创建了一个名为DRB-ML的专用数据集，该数据集源自DataRaceBench，并具有精细的标签，显示了数据竞争对及其相关变量、行号和读/写信息的存在。然后，我们使用DRB-ML评估了代表性的LLMs并微调了开源模型。我们的实验证明，LLMs可以作为数据竞争检测的可行方法。然而，当我们需要有关引起数据竞争的变量对的详细信息时，它们仍无法与传统的数据竞争检测工具竞争。

    Large language models (LLMs) are demonstrating significant promise as an alternate strategy to facilitate analyses and optimizations of high-performance computing programs, circumventing the need for resource-intensive manual tool creation. In this paper, we explore a novel LLM-based data race detection approach combining prompting engineering and fine-tuning techniques. We create a dedicated dataset named DRB-ML, which is derived from DataRaceBench, with fine-grain labels showing the presence of data race pairs and their associated variables, line numbers, and read/write information. DRB-ML is then used to evaluate representative LLMs and fine-tune open-source ones. Our experiment shows that LLMs can be a viable approach to data race detection. However, they still cannot compete with traditional data race detection tools when we need detailed information about variable pairs causing data races.
    
[^26]: SOTASTREAM：一种用于机器翻译训练的流式方法

    SOTASTREAM: A Streaming Approach to Machine Translation Training. (arXiv:2308.07489v1 [cs.CL])

    [http://arxiv.org/abs/2308.07489](http://arxiv.org/abs/2308.07489)

    SOTASTREAM是一种机器翻译训练的流式方法，提供了无限排列的训练数据流，避免了传统的静态数据预处理步骤，以及耗时、昂贵和繁琐的问题。

    

    许多机器翻译工具包使用数据准备步骤将原始数据转换为可以直接被训练器使用的张量格式。然而，这个准备步骤与现代的研究和开发实践越来越不相符，因为这个过程产生了一个静态的、不可更改的训练数据版本，使得常见的训练时需求变得困难（例如，子词采样）、耗时（处理大量数据可能需要几天时间）、昂贵（例如，磁盘空间）和繁琐（管理实验组合）。我们提出了一种替代方法，将数据的生成与数据的使用分离。在这种方法中，没有单独的预处理步骤；数据的生成产生了原始训练数据的无限排列流，训练器在消费数据时将其转换为张量并进行批处理。此外，这个数据流可以通过一组可定义的操作符进行实时修改，例如子词采样等。

    Many machine translation toolkits make use of a data preparation step wherein raw data is transformed into a tensor format that can be used directly by the trainer. This preparation step is increasingly at odds with modern research and development practices because this process produces a static, unchangeable version of the training data, making common training-time needs difficult (e.g., subword sampling), time-consuming (preprocessing with large data can take days), expensive (e.g., disk space), and cumbersome (managing experiment combinatorics). We propose an alternative approach that separates the generation of data from the consumption of that data. In this approach, there is no separate pre-processing step; data generation produces an infinite stream of permutations of the raw training data, which the trainer tensorizes and batches as it is consumed. Additionally, this data stream can be manipulated by a set of user-definable operators that provide on-the-fly modifications, such 
    
[^27]: O-1: 自动标注与1-best假设的自我训练

    O-1: Self-training with Oracle and 1-best Hypothesis. (arXiv:2308.07486v1 [cs.LG])

    [http://arxiv.org/abs/2308.07486](http://arxiv.org/abs/2308.07486)

    提出了一种新的自我训练目标O-1，通过增强神谕假设来减少训练偏差，并统一训练和评估指标。通过实验证明了O-1在语音识别任务中的有效性，并取得了相对于EMBR的显著改进。

    

    我们引入了O-1，这是一个新的自我训练目标，旨在减少训练偏差，统一语音识别的训练和评估指标。O-1是期望最小贝叶斯风险（EMBR）的一种更快速的变体，它增强了神谕假设，并且可以适应有监督和无监督数据。我们通过对公开可用的SpeechStew数据集和大规模内部数据集进行识别效果的实证，证明了我们方法的有效性。在Speechstew上，相对于将实际性能与神谕性能之间的差距缩小43%的EMBR，O-1目标通过80%的相对缩小了这一差距。在SpeechStew的各个数据集上，O-1相对于EMBR实现了13%到25%的相对改进，并且相对于在内部数据集上使用EMBR训练的神谕词错误率相对缩小了12%的差距。总的来说，O-1相对于EMBR在词错误率上实现了9%的相对改进，这表明了该目标在大规模数据集上的可扩展性。

    We introduce O-1, a new self-training objective to reduce training bias and unify training and evaluation metrics for speech recognition. O-1 is a faster variant of Expected Minimum Bayes Risk (EMBR), that boosts the oracle hypothesis and can accommodate both supervised and unsupervised data. We demonstrate the effectiveness of our approach in terms of recognition on publicly available SpeechStew datasets and a large-scale, in-house data set. On Speechstew, the O-1 objective closes the gap between the actual and oracle performance by 80\% relative compared to EMBR which bridges the gap by 43\% relative. O-1 achieves 13\% to 25\% relative improvement over EMBR on the various datasets that SpeechStew comprises of, and a 12\% relative gap reduction with respect to the oracle WER over EMBR training on the in-house dataset. Overall, O-1 results in a 9\% relative improvement in WER over EMBR, thereby speaking to the scalability of the proposed objective for large-scale datasets.
    
[^28]: 玩弄文字：比较ChatGPT和人类的词汇和词汇丰富度

    Playing with Words: Comparing the Vocabulary and Lexical Richness of ChatGPT and Humans. (arXiv:2308.07462v1 [cs.CL])

    [http://arxiv.org/abs/2308.07462](http://arxiv.org/abs/2308.07462)

    这篇论文比较了ChatGPT和人类在词汇和词汇丰富度方面的差异，研究发现使用ChatGPT等工具会对词汇使用和词汇丰富度产生影响，这可能会对语言演变产生影响。

    

    人工智能生成语言模型（如GPT）和ChatGPT等工具的引入引发了一场革命，可以改变文本生成的方式。这对读者的语言能力以及新型人工智能工具的培训是否会产生影响具有许多含义？它是否会影响语言的演变？我们关注语言的一个特定方面：词语；在编写给定文本时，使用ChatGPT等工具会增加或减少使用的词汇量或词汇丰富度（理解为书面或口头表达中使用的不同词汇数量）？这对词语有影响，因为未包含在人工智能生成的内容中的词语往往会变得越来越不受欢迎，并最终可能消失。在这项工作中，我们对ChatGPT和人类的词汇和词汇丰富度进行了初步比较。

    The introduction of Artificial Intelligence (AI) generative language models such as GPT (Generative Pre-trained Transformer) and tools such as ChatGPT has triggered a revolution that can transform how text is generated. This has many implications, for example, as AI-generated text becomes a significant fraction of the text in many disciplines, would this have an effect on the language capabilities of readers and also on the training of newer AI tools? Would it affect the evolution of languages? Focusing on one specific aspect of the language: words; will the use of tools such as ChatGPT increase or reduce the vocabulary used or the lexical richness (understood as the number of different words used in a written or oral production) when writing a given text? This has implications for words, as those not included in AI-generated content will tend to be less and less popular and may eventually be lost. In this work, we perform an initial comparison of the vocabulary and lexical richness of
    
[^29]: 《为产后情绪与焦虑障碍开发和评估三个聊天机器人》

    Development and Evaluation of Three Chatbots for Postpartum Mood and Anxiety Disorders. (arXiv:2308.07407v1 [cs.CL])

    [http://arxiv.org/abs/2308.07407](http://arxiv.org/abs/2308.07407)

    我们开发了三个聊天机器人，为产后护理人员提供上下文特定的共情支持，其中基于规则的模型表现最好，人类用户更喜欢它的回复，生成模型的回复有时混淆或无意义。

    

    与产后支持国际（PSI）非盈利组织合作，该组织致力于为产后护理人员提供情绪和焦虑障碍的支持，我们开发了三个聊天机器人，以提供上下文特定的共情支持。我们利用基于规则和生成模型，对我们的聊天机器人的性能进行了评估，并使用机器测量和人类问卷。总体上，我们的基于规则的模型表现最好，输出接近地面真值参考，并且含有最高水平的共情。人类用户更喜欢基于规则的聊天机器人，因为它具有上下文特定的、人类化的回复。我们的生成模型也能产生共情回复，并被人类用户描述为有吸引力。然而，训练数据集的限制常常导致回复混淆或无意义。我们通过讨论基于规则和生成模型的实际好处作出结论。

    In collaboration with Postpartum Support International (PSI), a non-profit organization dedicated to supporting caregivers with postpartum mood and anxiety disorders, we developed three chatbots to provide context-specific empathetic support to postpartum caregivers, leveraging both rule-based and generative models. We present and evaluate the performance of our chatbots using both machine-based metrics and human-based questionnaires. Overall, our rule-based model achieves the best performance, with outputs that are close to ground truth reference and contain the highest levels of empathy. Human users prefer the rule-based chatbot over the generative chatbot for its context-specific and human-like replies. Our generative chatbot also produced empathetic responses and was described by human users as engaging. However, limitations in the training dataset often result in confusing or nonsensical responses. We conclude by discussing practical benefits of rule-based vs. generative models fo
    
[^30]: 语音模型中用于大写和交替预测的文本注入

    Text Injection for Capitalization and Turn-Taking Prediction in Speech Models. (arXiv:2308.07395v1 [cs.CL])

    [http://arxiv.org/abs/2308.07395](http://arxiv.org/abs/2308.07395)

    本研究探讨了在语音模型中利用文本注入进行非ASR任务的辅助，并使用联合训练算法提升大写准确率和交替检测召回率。

    

    文本注入用于自动语音识别（ASR），其中非配对的纯文本数据用于补充音频-文本数据，已显示出对词错误率有显著改善。该研究研究了文本注入用于辅助任务，在E2E模型中常用于非ASR任务。在本研究中，我们使用联合端到端和内部语言模型训练（JEIT）作为我们的文本注入算法，训练一个ASR模型来完成两个辅助任务。第一个任务是大写，是一种去标准化任务。第二个任务是交替预测，尝试识别用户是否已完成对话交替，在数字助理互动中。我们展示了我们的文本注入方法能提升长尾数据的大写性能，并改善了交替检测的召回率。

    Text injection for automatic speech recognition (ASR), wherein unpaired text-only data is used to supplement paired audio-text data, has shown promising improvements for word error rate. This study examines the use of text injection for auxiliary tasks, which are the non-ASR tasks often performed by an E2E model. In this work, we use joint end-to-end and internal language model training (JEIT) as our text injection algorithm to train an ASR model which performs two auxiliary tasks. The first is capitalization, which is a de-normalization task. The second is turn-taking prediction, which attempts to identify whether a user has completed their conversation turn in a digital assistant interaction. We show results demonstrating that our text injection method boosts capitalization performance for long-tail data, and improves turn-taking detection recall.
    
[^31]: 使用文本注入来提高语音中个人识别符的识别率

    Using Text Injection to Improve Recognition of Personal Identifiers in Speech. (arXiv:2308.07393v1 [cs.CL])

    [http://arxiv.org/abs/2308.07393](http://arxiv.org/abs/2308.07393)

    通过使用文本注入技术，在自动语音识别中改善个人识别符类别的识别准确率，并且在医疗记录中提高了人名和日期的召回率。

    

    在许多自动语音识别（ASR）应用中，准确识别特定类别（例如人名、日期或其他标识符）至关重要。由于这些类别代表个人信息，对于包括收集、转录、训练和评估在内的数据的合规使用需要特别注意。确保个人安全和隐私的一种方法是完全删除或修饰收集到的可识别个人信息（PII）。然而，这样做会导致ASR模型在这些类别上的识别准确性较低。我们使用文本注入方法在训练数据中包含PII类别的虚假文本替代物，以提高PII类别的识别。我们展示了在医疗记录中人名和日期的召回率显著提高，同时改善了整体的识别错误率。对于字母数字序列，我们还改善了字符错误率和句子准确性。

    Accurate recognition of specific categories, such as persons' names, dates or other identifiers is critical in many Automatic Speech Recognition (ASR) applications. As these categories represent personal information, ethical use of this data including collection, transcription, training and evaluation demands special care. One way of ensuring the security and privacy of individuals is to redact or eliminate Personally Identifiable Information (PII) from collection altogether. However, this results in ASR models that tend to have lower recognition accuracy of these categories. We use text-injection to improve the recognition of PII categories by including fake textual substitutes of PII categories in the training data using a text injection method. We demonstrate substantial improvement to Recall of Names and Dates in medical notes while improving overall WER. For alphanumeric digit sequences we show improvements to Character Error Rate and Sentence Accuracy.
    
[^32]: AR的新兴通讯方式

    Emergent communication for AR. (arXiv:2308.07342v1 [eess.SP])

    [http://arxiv.org/abs/2308.07342](http://arxiv.org/abs/2308.07342)

    本研究提出了一种新兴语义通信框架，用于学习移动增强现实中的通信协议，并采用改进的Lewis信令博弈训练两个代理。通过这个框架，两个代理能够在嘈杂的信道中使用极小的消息进行关于视觉数据的抽象思想的交流，从而解决了现有解决方案中视觉数据通信延迟对体验质量的限制。

    

    移动增强现实（MAR）被广泛认为是数字孪生和元宇宙的普遍接口之一，要求具有前所未有的延迟、计算能力和能效。现有的实现MAR的解决方案将边缘计算、云计算和第五代（5G）网络等多种技术结合起来。然而，视觉数据的固有通信延迟对体验质量（QoE）造成明显的限制。为了解决这个挑战，我们提出了一种新兴的语义通信框架，用于学习MAR中的通信协议。具体而言，我们通过改进的Lewis信令博弈来训练两个代理，以形成离散的通信协议。基于这个协议，两个代理可以通过极小数据大小的消息在嘈杂的信道中相互传达有关视觉数据的抽象思想，从而导致消息错误。为了更好地模拟真实世界的场景，我们将信道不确定性纳入模型中。

    Mobile augmented reality (MAR) is widely acknowledged as one of the ubiquitous interfaces to the digital twin and Metaverse, demanding unparalleled levels of latency, computational power, and energy efficiency. The existing solutions for realizing MAR combine multiple technologies like edge, cloud computing, and fifth-generation (5G) networks. However, the inherent communication latency of visual data imposes apparent limitations on the quality of experience (QoE). To address the challenge, we propose an emergent semantic communication framework to learn the communication protocols in MAR. Specifically, we train two agents through a modified Lewis signaling game to emerge a discrete communication protocol spontaneously. Based on this protocol, two agents can communicate about the abstract idea of visual data through messages with extremely small data sizes in a noisy channel, which leads to message errors. To better simulate real-world scenarios, we incorporate channel uncertainty into
    
[^33]: 从合成语料库和形式逻辑学习演绎推理

    Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic. (arXiv:2308.07336v1 [cs.AI])

    [http://arxiv.org/abs/2308.07336](http://arxiv.org/abs/2308.07336)

    本研究研究了一种从合成语料库中学习演绎推理能力的方法，通过采用基于形式逻辑理论的演绎规则，训练的语言模型具有更泛化的推理能力。

    

    我们研究了一种从合成语料库中学习演绎推理能力的语言模型（LMs）方法。之前的研究使用了具体的演绎规则来生成演绎示例，但这些规则受限或者是任意的。这可能限制了所获得演绎推理能力的泛化能力。我们重新思考并采用基于形式逻辑理论的一组良好基础的演绎规则，当这些规则以多步方式组合时，可以推导出任何其他演绎规则。我们通过实验证明，在提出的语料库上训练的LMs，即$\textbf{FLD}$（$\textbf{F}$ormal $\textbf{L}$ogic $\textbf{D}$eduction），获得了更具泛化性的演绎推理能力。此外，我们确定了演绎推理语料库可以增强LMs的推理能力的方面，以及不同方面无法增强的方面。最后，基于这些结果，我们讨论了将演绎语料库或其他方法应用于每个方面的未来方向。

    We study a synthetic corpus-based approach for language models (LMs) to acquire logical deductive reasoning ability. The previous studies generated deduction examples using specific sets of deduction rules. However, these rules were limited or otherwise arbitrary. This can limit the generalizability of acquired deductive reasoning ability. We rethink this and adopt a well-grounded set of deduction rules based on formal logic theory, which can derive any other deduction rules when combined in a multistep way. We empirically verify that LMs trained on the proposed corpora, which we name $\textbf{FLD}$ ($\textbf{F}$ormal $\textbf{L}$ogic $\textbf{D}$eduction), acquire more generalizable deductive reasoning ability. Furthermore, we identify the aspects of deductive reasoning ability on which deduction corpora can enhance LMs and those on which they cannot. Finally, on the basis of these results, we discuss the future directions for applying deduction corpora or other approaches for each as
    
[^34]: AI文本-行为：可操控性研究

    AI Text-to-Behavior: A Study In Steerability. (arXiv:2308.07326v1 [cs.AI])

    [http://arxiv.org/abs/2308.07326](http://arxiv.org/abs/2308.07326)

    本研究探讨了大型语言模型的可操控性，通过使用行为心理学框架，模型在生成文本时能够根据提示展现特定的行为特征。研究发现，模型在不同特征上的表现具有灵活性和区分度，并能够准确复制历史人物的个性和对话风格。

    

    该研究探讨了大型语言模型（LLM），特别是OpenAI的ChatGPT迭代版本的可操控性。通过采用一种名为OCEAN（开放性，责任心，外向性，宜人性，神经质）的行为心理学框架，我们量化评估了模型对定制提示的响应能力。当要求生成类似于外向人格的文本时，OCEAN得分对齐到了该行为特质。在我们的分析中，“开放性”呈现了语言的模糊性，而“责任心”和“神经质”在OCEAN框架中明确地被唤起，而“外向性”和“宜人性”则展示了与其他特征明显重叠但又有明显分离的特点。我们的发现强调了GPT的多功能性和识别以及适应微妙指导的能力。此外，历史人物模拟突出了LLM内化和投射可指导个性的能力，精确复制了他们的哲学和对话风格。

    The research explores the steerability of Large Language Models (LLMs), particularly OpenAI's ChatGPT iterations. By employing a behavioral psychology framework called OCEAN (Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism), we quantitatively gauged the model's responsiveness to tailored prompts. When asked to generate text mimicking an extroverted personality, OCEAN scored the language alignment to that behavioral trait. In our analysis, while "openness" presented linguistic ambiguity, "conscientiousness" and "neuroticism" were distinctly evoked in the OCEAN framework, with "extroversion" and "agreeableness" showcasing a notable overlap yet distinct separation from other traits. Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions. Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles. How
    
[^35]: LLM自卫：通过自检，LLMs意识到它们被愚弄了。

    LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked. (arXiv:2308.07308v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07308](http://arxiv.org/abs/2308.07308)

    本文提出了一种通过自检来防御大型语言模型(LLMs)对抗性攻击的简单方法，即让模型自行过滤回应。实验结果表明，即使模型未对齐人类价值观，通过使用语言模型验证内容，仍然可以防止模型向用户呈现有害内容。

    

    近年来，大型语言模型（LLMs）由于其能够对人类提示做出高质量文本回应而变得非常受欢迎。然而，研究表明，这些模型在回应用户提示时可能生成有害内容（例如，给用户提供犯罪指导）。文献中已经着重研究如何通过方法（例如通过强化学习将模型与人类价值观对齐）来减轻这些风险。然而，研究发现，即使对齐的语言模型也容易受到绕过生成有害文本限制的对抗性攻击。我们提出了一种简单的方法来防御这些攻击，即大型语言模型对自己的回应进行过滤。我们目前的研究结果表明，即使模型没有被微调以与人类价值观对齐，也可以通过使用语言模型验证内容来防止其向用户呈现有害内容。

    Large language models (LLMs) have skyrocketed in popularity in recent years due to their ability to generate high-quality text in response to human prompting. However, these models have been shown to have the potential to generate harmful content in response to user prompting (e.g., giving users instructions on how to commit crimes). There has been a focus in the literature on mitigating these risks, through methods like aligning models with human values through reinforcement learning. However, it has been shown that even aligned language models are susceptible to adversarial attacks that bypass their restrictions on generating harmful text. We propose a simple approach to defending against these attacks by having a large language model filter its own responses. Our current results show that even if a model is not fine-tuned to be aligned with human values, it is possible to stop it from presenting harmful content to users by validating the content using a language model.
    
[^36]: 人本自然语言处理事实核查：使用AI的匹配设计与事实核查员合作

    Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using Matchmaking for AI. (arXiv:2308.07213v1 [cs.HC] CROSS LISTED)

    [http://arxiv.org/abs/2308.07213](http://arxiv.org/abs/2308.07213)

    本研究使用AI的匹配设计方法，通过与专业事实核查员的合作设计，发现并解决事实核查员与技术之间的差距。合作设计会议产生了11个新的设计思路，包括提高效率和个性化的事实核查工具，帮助事实核查员准备未来的虚假信息，监测偏见，以及支持内部组织。

    

    专业事实核查在应对大量虚假信息方面存在可扩展性有限的挑战。虽然提出了许多自然语言处理工具来增强事实核查的效率和可扩展性，但学术研究和事实核查组织均报告了对此类工具的有限采用，因为这些工具不足以与事实核查员的实践、价值观和需求保持一致。为了弥补这一差距，我们研究了一种合作设计方法，即AI的匹配设计，该方法促进事实核查员、设计师和自然语言处理研究人员共同发现应以何种方式解决事实核查员的需求。我们与22名专业事实核查员进行的合作设计会议产生了11个新的设计思路。这些思路有助于提高信息搜索、处理和撰写效率以及个性化的事实核查；帮助事实核查员主动准备未来的虚假信息；监测潜在的偏见；并支持内部组织。

    A key challenge in professional fact-checking is its limited scalability in relation to the magnitude of false information. While many Natural Language Processing (NLP) tools have been proposed to enhance fact-checking efficiency and scalability, both academic research and fact-checking organizations report limited adoption of such tooling due to insufficient alignment with fact-checker practices, values, and needs. To address this gap, we investigate a co-design method, Matchmaking for AI, which facilitates fact-checkers, designers, and NLP researchers to collaboratively discover what fact-checker needs should be addressed by technology and how. Our co-design sessions with 22 professional fact-checkers yielded a set of 11 novel design ideas. They assist in information searching, processing, and writing tasks for efficient and personalized fact-checking; help fact-checkers proactively prepare for future misinformation; monitor their potential biases; and support internal organization c
    
[^37]: 信息检索中的大型语言模型：一项综述

    Large Language Models for Information Retrieval: A Survey. (arXiv:2308.07107v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07107](http://arxiv.org/abs/2308.07107)

    本综述将大型语言模型（LLMs）在信息检索中的发展进行了综述，探讨了其在捕捉上下文信号和语义细微之处方面的优势和挑战，以及与传统检索方法的结合的重要性。

    

    作为信息获取的主要手段，信息检索（IR）系统，如搜索引擎，已经融入到我们的日常生活中。这些系统还作为对话、问答和推荐系统的组成部分。IR的发展轨迹从基于词项的方法起步，逐渐发展成与先进的神经模型相融合。尽管神经模型擅长捕捉复杂的上下文信号和语义细微之处，从而改变了IR的格局，但它们仍然面临着数据稀缺、可解释性以及生成上下文合理但潜在不准确响应的挑战。这种演变需要传统方法（如基于词项的稀疏检索方法与快速响应）和现代神经架构（如具有强大语言理解能力的语言模型）的结合。与此同时，大型语言模型（LLMs），如ChatGPT和GPT-4的出现，引起了一场革命

    As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has revolu
    
[^38]: #InsTag:针对大型语言模型监督微调的指令标注分析

    #InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models. (arXiv:2308.07074v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07074](http://arxiv.org/abs/2308.07074)

    本研究提出了InsTag，一种用于标记基于语义和意图的监督微调（SFT）数据集样本的开放式细粒度标注器。通过分析开源SFT数据集，发现模型能力会随着更多多样化和复杂化的数据而增长。基于这一观察结果，使用InsTag选择的数据进行模型微调，得到的TagLM模型在大规模SFT数据上优于开源模型，验证了查询多样性和复杂性的重要性。

    

    基于监督微调（SFT），基础语言模型获得了遵循指令的能力。多样性和复杂性被认为是成功的SFT数据集的重要因素，但其定义仍然模糊不清，缺乏定量分析。在这项工作中，我们提出了InsTag，一种开放的细粒度标注器，根据语义和意图对SFT数据集中的样本进行标记，并且通过标签来定义指令的多样性和复杂性。我们获得了6.6K个标签来描述综合用户查询。然后，我们分析了一些流行的开源SFT数据集，并发现模型的能力随着更多多样化和复杂化的数据而增长。基于这一观察结果，我们提出了一个基于InsTag的数据选择器，从开源数据集中选择6K个多样性和复杂性样本，并在InsTag选择的数据上进行模型微调。结果表明，TagLM模型在MT-Bench评估的大规模SFT数据上优于开源模型，验证了查询多样性和复杂性的重要性。

    Foundation language models obtain the instruction-following ability through supervised fine-tuning (SFT). Diversity and complexity are considered critical factors of a successful SFT dataset, while their definitions remain obscure and lack quantitative analyses. In this work, we propose InsTag, an open-set fine-grained tagger, to tag samples within SFT datasets based on semantics and intentions and define instruction diversity and complexity regarding tags. We obtain 6.6K tags to describe comprehensive user queries. Then we analyze popular open-sourced SFT datasets and find that the model ability grows with more diverse and complex data. Based on this observation, we propose a data selector based on InsTag to select 6K diverse and complex samples from open-source datasets and fine-tune models on InsTag-selected data. The resulting models, TagLM, outperform open-source models based on considerably larger SFT data evaluated by MT-Bench, echoing the importance of query diversity and compl
    
[^39]: Thresh：一个统一的、可定制的和可部署的细粒度文本评估平台

    Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation. (arXiv:2308.06953v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.06953](http://arxiv.org/abs/2308.06953)

    Thresh是一个统一的、可定制的和可部署的细粒度文本评估平台，通过创建一个YAML配置文件，用户可以快速构建和测试任何框架的注释界面，并提供一个社区中心来促进协作和共享。

    

    细粒度的、跨度级别的人工评估已经成为评价文本生成任务的可靠和稳健的方法，如摘要、简化、机器翻译和新闻生成，并且得到的标注对训练自动评估指标和改善语言模型非常有用。然而，现有的为这些评估框架实施的标注工具缺乏适应不同领域或语言的能力，或者根据用户需求修改标注设置。缺乏统一的标注数据格式阻碍了多任务学习的研究。在本文中，我们介绍了Thresh，一个统一的、可定制的和可部署的细粒度评估平台。只需创建一个YAML配置文件，用户可以在几分钟内构建和测试任何框架的注释界面 - 所有这些都在一个web浏览器窗口中。为了促进协作和共享，Thresh提供了一个社区中心，这个中心托管了一系列细粒度评估数据集。

    Fine-grained, span-level human evaluation has emerged as a reliable and robust method for evaluating text generation tasks such as summarization, simplification, machine translation and news generation, and the derived annotations have been useful for training automatic metrics and improving language models. However, existing annotation tools implemented for these evaluation frameworks lack the adaptability to be extended to different domains or languages, or modify annotation settings according to user needs. And the absence of a unified annotated data format inhibits the research in multi-task learning. In this paper, we introduce Thresh, a unified, customizable and deployable platform for fine-grained evaluation. By simply creating a YAML configuration file, users can build and test an annotation interface for any framework within minutes -- all in one web browser window. To facilitate collaboration and sharing, Thresh provides a community hub that hosts a collection of fine-grained
    
[^40]: MC-DRE: 多方面交叉整合用于药物事件/实体提取

    MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction. (arXiv:2308.06546v1 [cs.CL])

    [http://arxiv.org/abs/2308.06546](http://arxiv.org/abs/2308.06546)

    本文提出了一个新的多方面交叉整合框架，用于从药物相关文档中提取药物事件/实体。该框架能够捕捉并对齐不同的上下文/语言/知识属性，并实现药物事件信息的全面检测和理解。

    

    提取有意义的药物相关信息块，如不良药物事件（ADE），对于预防疾病和拯救许多生命至关重要。大多数ADE是通过医疗背景下的非结构化对话报告的。因此，应用通用实体识别方法是不足够的。关键在于如何整合和对齐多个关键方面来检测药物事件信息，包括药物事件语义、句法结构和医学领域术语。在本文中，我们提出了一个新的多方面交叉整合框架，通过从药物相关文档中捕捉和对齐不同的上下文/语言/知识属性，用于药物实体/事件检测。我们首先构建多方面编码器来描述语义、句法和医学文档上下文信息，方法包括槽标注任务、主要药物实体/事件检测、词性标注和通用医学命名实体识别。然后，每个编码器进行交叉整合。

    Extracting meaningful drug-related information chunks, such as adverse drug events (ADE), is crucial for preventing morbidity and saving many lives. Most ADE are reported via an unstructured conversation with the medical context. Hence, applying a general entity recognition approach is not sufficient enough. The key is how to integrate and align multiple crucial aspects to detect drug event information, including drug event semantics, syntactic structures, and medical domain terminology. In this paper, we propose a new multi-aspect cross-integration framework for drug entity/event detection by capturing and aligning different context/language/knowledge properties from drug-related documents. We first construct multi-aspect encoders to describe semantic, syntactic, and medical document contextual information by conducting those slot tagging tasks, main drug entity/event detection, part-of-speech tagging, and general medical named entity recognition. Then, each encoder conducts cross int
    
[^41]: 基于深度学习的隐喻检测知识注入：综述研究

    Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review. (arXiv:2308.04306v1 [cs.CL])

    [http://arxiv.org/abs/2308.04306](http://arxiv.org/abs/2308.04306)

    本文对基于深度学习的隐喻识别任务中知识注入的研究进展进行了全面综述，包括主流知识和知识注入原则的总结、数据集、评估指标和基准模型的回顾，并探讨了当前的知识注入问题。

    

    隐喻研究的历史也标志着知识注入研究的演变。随着近年来深度学习技术的不断进步，自然语言处理社区对将知识应用于在隐喻识别任务中取得成功结果表现出极大兴趣。尽管在隐喻识别领域涉及知识注入的方法逐渐增加，但缺乏一篇完整的关于基于知识注入的方法的综述文章。因此，本文旨在综述深度学习在隐喻识别任务中应用知识注入的研究进展。本文系统总结和概括了主流的知识和知识注入原则，同时回顾了在隐喻识别任务中使用的数据集、评估指标和基准模型。最后，我们探讨了当前面临的知识注入问题。

    The history of metaphor research also marks the evolution of knowledge infusion research. With the continued advancement of deep learning techniques in recent years, the natural language processing community has shown great interest in applying knowledge to successful results in metaphor recognition tasks. Although there has been a gradual increase in the number of approaches involving knowledge injection in the field of metaphor recognition, there is a lack of a complete review article on knowledge injection based approaches. Therefore, the goal of this paper is to provide a comprehensive review of research advances in the application of deep learning for knowledge injection in metaphor recognition tasks. In this paper, we systematically summarize and generalize the mainstream knowledge and knowledge injection principles, as well as review the datasets, evaluation metrics, and benchmark models used in metaphor recognition tasks. Finally, we explore the current issues facing knowledge 
    
[^42]: SynJax: JAX的结构化概率分布

    SynJax: Structured Probability Distributions for JAX. (arXiv:2308.03291v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.03291](http://arxiv.org/abs/2308.03291)

    SynJax是一个针对JAX的结构化概率分布库，通过提供高效的向量化实现解决了对于结构化对象的难以实现的问题。

    

    深度学习软件库的发展使得该领域取得了显著的进展，它使用户能够专注于建模，同时让库来处理针对现代硬件加速器进行优化执行的繁琐和耗时的任务。然而，这仅对特定类型的深度学习模型有益，例如Transformer，其基本操作易于映射到向量化计算。而对于显式考虑结构化对象（如树和分割）的模型，并没有同样的受益，因为它们需要定制的难以以向量化形式实现的算法。SynJax通过提供用于结构化分布的推理算法的高效向量化实现来直接解决这个问题，包括对齐、标记、分割、组成树和生成树的处理。使用SynJax，我们可以构建大规模的可微分模型，显式地对数据的结构进行建模。代码可在https://g中获得。

    The development of deep learning software libraries enabled significant progress in the field by allowing users to focus on modeling, while letting the library to take care of the tedious and time-consuming task of optimizing execution for modern hardware accelerators. However, this has benefited only particular types of deep learning models, such as Transformers, whose primitives map easily to the vectorized computation. The models that explicitly account for structured objects, such as trees and segmentations, did not benefit equally because they require custom algorithms that are difficult to implement in a vectorized form.  SynJax directly addresses this problem by providing an efficient vectorized implementation of inference algorithms for structured distributions covering alignment, tagging, segmentation, constituency trees and spanning trees. With SynJax we can build large-scale differentiable models that explicitly model structure in the data. The code is available at https://g
    
[^43]: LaFiCMIL：从相关多实例学习的角度重新思考大文件分类

    LaFiCMIL: Rethinking Large File Classification from the Perspective of Correlated Multiple Instance Learning. (arXiv:2308.01413v1 [cs.CL])

    [http://arxiv.org/abs/2308.01413](http://arxiv.org/abs/2308.01413)

    LaFiCMIL是一个新的方法，从相关多实例学习的角度解决了Transformer模型输入长度限制的问题，可以用于改进大文件分类任务。

    

    基于Transformer的模型在各种语言任务的性能上取得了革命性的突破。直观上，人们可能会期望文本分类，作为不需要像生成任务那样许多高级表示的任务，能够充分利用Transformer强大的表示能力来进行综合性的处理。然而，实际上，在多类别和多标签分类长文本文档和其他大文件的领域仍然存在较大的改进潜力。Transformer模型的性能主要受到一个重要限制的阻碍：有限的输入长度，比如BERT的512个标记。虽然增加GPU内存可以稍微扩展这个限制，但实际应用中往往受限于有限的GPU资源。在这项工作中，我们从相关多实例学习的角度解决了输入限制问题。所提出的方法LaFiCMIL，作为一个多功能的框架，适用于

    Transformer-based models have revolutionized the performance of a wide range of language tasks. Intuitively, one might expect text classification, which does not necessitate as many high-level representations as generative tasks, to be comprehensively addressed with the powerful representation capabilities of Transformers. However, in reality, there remains significant potential for enhancement, particularly in the areas of multi-class and multi-label classification of lengthy textual documents and other large files. The performance of Transformer-based models is mainly hindered by a major limitation: a restricted input length, e.g., 512 tokens for BERT. While an increase in GPU memory can marginally extend this limit, practical real-world applications often operate under constrained GPU resources. In this work, we tackle the input limit problem from the perspective of correlated multiple instance learning. The proposed approach, LaFiCMIL, serves as a versatile framework applicable to 
    
[^44]: PromptStyler：基于提示的无源域泛化风格生成

    PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization. (arXiv:2307.15199v1 [cs.CV])

    [http://arxiv.org/abs/2307.15199](http://arxiv.org/abs/2307.15199)

    提出了PromptStyler，通过使用提示合成样式特征，解决了无源域泛化的问题。该方法通过学习样式词向量生成多样的样式，并通过强制样式内容特征与内容特征靠近来保证样式不会扭曲内容信息。在多个数据集上取得了最先进的结果。

    

    在联合视觉语言空间中，文本特征（如“一张狗的照片”）可以有效地表示其相关的图像特征（如狗的照片）。受此启发，我们提出了PromptStyler，通过使用提示来合成各种样式，而不使用任何图像来处理无源域泛化中的分布偏移。我们的方法通过可学习的样式词向量为伪词S*生成多样的样式特征（如“a S* style of a”）。为了确保学习到的样式不会扭曲内容信息，我们强制要求样式内容特征（如“a S* style of a [class]”）在联合视觉语言空间中靠近其对应的内容特征（如“[class]”）。在学习样式词向量之后，我们使用合成的样式内容特征训练一个线性分类器。尽管PromptStyler不需要使用任何图像，并且需要额外的训练，但在PACS、VLCS、OfficeHome和DomainNet上取得了最先进的结果。

    In a joint vision-language space, a text feature (e.g., from "a photo of a dog") could effectively represent its relevant image features (e.g., from dog photos). Inspired by this, we propose PromptStyler which simulates various distribution shifts in the joint space by synthesizing diverse styles via prompts without using any images to deal with source-free domain generalization. Our method learns to generate a variety of style features (from "a S* style of a") via learnable style word vectors for pseudo-words S*. To ensure that learned styles do not distort content information, we force style-content features (from "a S* style of a [class]") to be located nearby their corresponding content features (from "[class]") in the joint vision-language space. After learning style word vectors, we train a linear classifier using synthesized style-content features. PromptStyler achieves the state of the art on PACS, VLCS, OfficeHome and DomainNet, although it does not require any images and take
    
[^45]: 以不同方式堆叠更多层：通过低秩更新进行高秩训练

    Stack More Layers Differently: High-Rank Training Through Low-Rank Updates. (arXiv:2307.05695v1 [cs.CL])

    [http://arxiv.org/abs/2307.05695](http://arxiv.org/abs/2307.05695)

    本文以低秩训练技术作为替代方法，提出了一种名为ReLoRA的新方法，利用低秩更新来训练大规模神经网络。在预训练的Transformer语言模型中，我们观察到ReLoRA在与常规神经网络训练相比的性能表现上相当，并发现其在模型越大的情况下效率越高，为高效训练千亿级参数网络提供了新的可能性。

    

    尽管大规模网络拥有数百亿个参数的规模已经占主导地位并且效果显著，但对于过度参数化模型的训练必要性仍然缺乏清晰的理解，而替代方法不一定能够降低训练高性能模型的成本。本文探索了低秩训练技术作为训练大型神经网络的替代方法。我们引入了一种称为ReLoRA的新方法，它利用低秩更新来训练高秩网络。我们将ReLoRA应用于预训练的Transformer语言模型，参数量高达350M，并且证明了与常规神经网络训练相当的性能。此外，我们观察到ReLoRA的效率随着模型大小的增加而提高，这使得它成为高效训练千亿级参数网络的有希望的方法。我们的研究结果揭示了低秩训练技术的潜力及其对于缩放定律的影响。

    Despite the dominance and effectiveness of scaling, resulting in large networks with hundreds of billions of parameters, the necessity to train overparametrized models remains poorly understood, and alternative approaches do not necessarily make it cheaper to train high-performance models. In this paper, we explore low-rank training techniques as an alternative approach to training large neural networks. We introduce a novel method called ReLoRA, which utilizes low-rank updates to train high-rank networks. We apply ReLoRA to pre-training transformer language models with up to 350M parameters and demonstrate comparable performance to regular neural network training. Furthermore, we observe that the efficiency of ReLoRA increases with model size, making it a promising approach for training multi-billion-parameter networks efficiently. Our findings shed light on the potential of low-rank training techniques and their implications for scaling laws.
    
[^46]: 风格胜过实质：大型语言模型的评估偏见

    Style Over Substance: Evaluation Biases for Large Language Models. (arXiv:2307.03025v1 [cs.CL])

    [http://arxiv.org/abs/2307.03025](http://arxiv.org/abs/2307.03025)

    这项研究调查了人类和基于大型语言模型的评委在比较不同模型输出时的行为，并发现评估过程中存在偏见，即尽管包含事实错误，答案仍然被更高地评分。为了解决这个问题，我们提出了

    

    随着大型语言模型（LLMs）的不断进步，准确和全面评估它们的性能变得越来越具有挑战性。传统上，人类评估被认为是自然语言生成的黄金标准。最近的进展将最先进的LLMs纳入评估过程中，作为人类评委的代理。然而，人类和LLMs作为评估者的能力程度仍然不确定。本研究旨在研究众包人类评委和基于LLMs的评委在比较不同模型的输出时的行为。为了实现这一目标，我们收集了一个包含故意有缺陷的机器生成答案的数据集。我们的研究结果表明，尽管事实上的错误可能带来更大的危险，但带有事实错误的答案仍然比长度过短或包含语法错误的答案评分更高。这突显了评估过程中存在的令人担忧的偏见。为了解决这个问题，我们提出了

    As large language models (LLMs) continue to advance, accurately and comprehensively evaluating their performance becomes increasingly challenging. Conventionally, human evaluations are considered the gold standard in natural language generation. Recent advancements incorporate state-of-the-art LLMs as proxies for human judges in evaluation processes. Nonetheless, the extent to which humans and LLMs are capable evaluators remains uncertain. This study aims to investigate the behavior of both crowd-sourced human and LLM-based judges when comparing outputs from different models. To accomplish this, we curate a dataset comprising intentionally flawed machine-generated answers. Our findings indicate that despite the potentially greater danger posed by factual errors, answers with factual errors were still rated more favorably compared to answers that were too short or contained grammatical errors. This highlights a concerning bias in the evaluation process. To address this issue, we propose
    
[^47]: BatGPT: 从生成性预训练转换器中得到的双向自回归对话生成模型

    BatGPT: A Bidirectional Autoregessive Talker from Generative Pre-trained Transformer. (arXiv:2307.00360v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.00360](http://arxiv.org/abs/2307.00360)

    BatGPT是一个双向自回归对话生成模型，能够高效捕捉自然语言的复杂依赖关系，并通过双向建模和参数扩展方法来改善对话生成的效果。这是一个在语言生成领域取得重要贡献的模型。

    

    BatGPT是由武汉大学和上海交通大学共同设计和训练的大规模语言模型。它可以对各种类型的输入（包括文本提示、图像和音频）生成自然流畅的文本。在建模层面上，我们采用了双向自回归架构，使模型能够高效地捕捉自然语言的复杂依赖关系，从而在语言生成、对话系统和问答等任务中具有较高的效果。此外，双向自回归模型不仅从左到右运行，还从右到左运行，有效减少了固定记忆效应并缓解了模型产生虚假输出的问题。在训练方面，我们提出了一种新颖的参数扩展方法，用于利用较小模型的预训练，并采用了来自人工智能和人类反馈的强化学习，旨在改善模型的对齐性能。总体而言，这些方法在对话生成方向上取得了显著的贡献。

    BatGPT is a large-scale language model designed and trained jointly by Wuhan University and Shanghai Jiao Tong University. It is capable of generating highly natural and fluent text in response to various types of input, including text prompts, images, and audio. In the modeling level, we employ a bidirectional autoregressive architecture that allows the model to efficiently capture the complex dependencies of natural language, making it highly effective in tasks such as language generation, dialog systems, and question answering. Moreover, the bidirectional autoregressive modeling not only operates from left to right but also from right to left, effectively reducing fixed memory effects and alleviating model hallucinations.  In the training aspect, we propose a novel parameter expansion method for leveraging the pre-training of smaller models and employ reinforcement learning from both AI and human feedback, aimed at improving the model's alignment performance. Overall, these approach
    
[^48]: PoetryDiffusion: 实现诗歌生成中的语义和韵律结合

    PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in Poetry Generation. (arXiv:2306.08456v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.08456](http://arxiv.org/abs/2306.08456)

    本文提出了PoetryDiffusion模型，利用扩散模型生成诗歌，同时考虑了语义和韵律方面的控制，具有较高的实用性和创新性。

    

    可控制文本生成是自然语言生成中具有挑战性和意义重大的领域。尤其是诗歌生成是一个典型的领域，对文本生成有着明确定义和严格的条件，是评估当前方法学的理想实验场。过去的研究成功地控制了诗歌生成的语义或韵律方面，但同时解决这两个方面仍然是一个挑战。在本文中，我们首次使用扩散模型来生成十四行诗和中国宋词，以应对这些挑战。就语义而言，我们的PoetryDiffusion模型基于扩散模型生成完整的句子或诗歌，全面考虑句子信息的整体性。这种方法增强了语义表达，使其与自回归模型和大型语言模型有所区别。就韵律控制而言，扩散生成和其约束控制模块的分离特性使我们能够灵活地控制韵律。

    Controllable text generation is a challenging and meaningful field in natural language generation (NLG). Especially, poetry generation is a typical one with well-defined and strict conditions for text generation which is an ideal playground for the assessment of current methodologies. While prior works succeeded in controlling either semantic or metrical aspects of poetry generation, simultaneously addressing both remains a challenge. In this paper, we pioneer the use of the Diffusion model for generating sonnets and Chinese SongCi poetry to tackle such challenges. In terms of semantics, our PoetryDiffusion model, built upon the Diffusion model, generates entire sentences or poetry by comprehensively considering the entirety of sentence information. This approach enhances semantic expression, distinguishing it from autoregressive and large language models (LLMs). For metrical control, the separation feature of diffusion generation and its constraint control module enable us to flexibly
    
[^49]: 自适应上下文偏置的基于Transducer的流式语音识别

    Adaptive Contextual Biasing for Transducer Based Streaming Speech Recognition. (arXiv:2306.00804v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2306.00804](http://arxiv.org/abs/2306.00804)

    该论文提出了一种自适应上下文偏置方法，基于Context-Aware Transformer Transducer (CATT) 来进行流式语音识别的预测。实验结果表明，与基线相比，该方法在 WER 和 CER 上可以分别减少6.7%和20.7%，减少了96.7%和84.9% 的相对 WER 和 CER 增加。

    

    通过加入额外的上下文信息，深度偏置方法已经成为解决个性化话语识别的有希望的解决方案。然而，在实际的语音助手中，总是将高预测分数的个性化词语进行偏置处理会显著降低对常见词语的识别性能。为了解决这个问题，我们提出了一种基于上下文感知Transformer Transducer（CATT）的自适应上下文偏置方法，该方法利用偏置编码器和预测器嵌入来执行上下文短语出现的流式预测。这种预测然后被用来动态地切换偏置列表的开关，使模型适应个性化和常见情景。在Librispeech和内部语音助手数据集上的实验证明，与基线相比，我们的方法在WER和CER上分别可以达到6.7%和20.7%的相对降低，将相对WER和CER的增加减少到96.7%和84.9%。

    By incorporating additional contextual information, deep biasing methods have emerged as a promising solution for speech recognition of personalized words. However, for real-world voice assistants, always biasing on such personalized words with high prediction scores can significantly degrade the performance of recognizing common words. To address this issue, we propose an adaptive contextual biasing method based on Context-Aware Transformer Transducer (CATT) that utilizes the biased encoder and predictor embeddings to perform streaming prediction of contextual phrase occurrences. Such prediction is then used to dynamically switch the bias list on and off, enabling the model to adapt to both personalized and common scenarios. Experiments on Librispeech and internal voice assistant datasets show that our approach can achieve up to 6.7% and 20.7% relative reduction in WER and CER compared to the baseline respectively, mitigating up to 96.7% and 84.9% of the relative WER and CER increase 
    
[^50]: GripRank: 通过生成式知识改进的段落排序填补检索和生成之间的差距

    GripRank: Bridging the Gap between Retrieval and Generation via the Generative Knowledge Improved Passage Ranking. (arXiv:2305.18144v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18144](http://arxiv.org/abs/2305.18144)

    GripRank是一种通过将生成式知识应用于段落排序，填补检索和文本生成之间差距的方法。

    

    通过利用从大型段落语料库检索到的段落来提供合适的答案，检索增强的文本生成在知识密集型语言任务上取得了显著进展，如开放域问答和知识增强对话生成。然而，由于检索和生成之间存在差异，即在检索过程中候选段落都被等同对待而不考虑它们生成合适答案的潜力，因此检索到的段落并不理想用于指导答案生成。为了解决这个挑战，本文提出了GeneRative Knowledge Improved Passage Ranking (GripRank) 方法，通过将生成式段落估计器(GPE)的知识提炼到一个段落排序器中，其中GPE是用于衡量生成合适答案的可能性的生成式语言模型。

    Retrieval-enhanced text generation has shown remarkable progress on knowledge-intensive language tasks, such as open-domain question answering and knowledge-enhanced dialogue generation, by leveraging passages retrieved from a large passage corpus for delivering a proper answer given the input query. However, the retrieved passages are not ideal for guiding answer generation because of the discrepancy between retrieval and generation, i.e., the candidate passages are all treated equally during the retrieval procedure without considering their potential to generate a proper answer. This discrepancy makes a passage retriever deliver a sub-optimal collection of candidate passages to generate the answer. In this paper, we propose the GeneRative Knowledge Improved Passage Ranking (GripRank) approach, addressing the above challenge by distilling knowledge from a generative passage estimator (GPE) to a passage ranker, where the GPE is a generative language model used to measure how likely the
    
[^51]: 一种从学术论文中提炼文本分类和对象识别的框架

    A Framework For Refining Text Classification and Object Recognition from Academic Articles. (arXiv:2305.17401v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.17401](http://arxiv.org/abs/2305.17401)

    本文提出了一种结合基于规则的方法和机器学习的框架，旨在解决从学术论文中提炼文本分类和对象识别的问题。

    

    随着互联网的广泛使用，高效地从大量学术论文中提取特定信息变得越来越重要。数据挖掘技术通常用于解决这个问题。然而，挖掘学术论文的数据具有挑战性，因为它需要自动从复杂的非结构化布局文档中提取特定模式。当前的学术论文数据挖掘方法使用基于规则的（RB）或机器学习（ML）方法。然而，使用基于规则的方法需要编写复杂排版论文的高昂成本。另一方面，仅使用机器学习方法需要对文章中复杂内容类型进行注释工作，这可能成本高昂。此外，仅使用机器学习可能会导致基于规则的方法容易识别的模式被错误提取的情况。为了解决这些问题，本文从分析指定著作中使用的标准布局和排版角度出发，提出了一种结合基于规则的方法和机器学习的框架。

    With the widespread use of the internet, it has become increasingly crucial to extract specific information from vast amounts of academic articles efficiently. Data mining techniques are generally employed to solve this issue. However, data mining for academic articles is challenging since it requires automatically extracting specific patterns in complex and unstructured layout documents. Current data mining methods for academic articles employ rule-based(RB) or machine learning(ML) approaches. However, using rule-based methods incurs a high coding cost for complex typesetting articles. On the other hand, simply using machine learning methods requires annotation work for complex content types within the paper, which can be costly. Furthermore, only using machine learning can lead to cases where patterns easily recognized by rule-based methods are mistakenly extracted. To overcome these issues, from the perspective of analyzing the standard layout and typesetting used in the specified p
    
[^52]: ANTONIO:面向NLP验证的系统化基准生成方法

    ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification. (arXiv:2305.04003v1 [cs.CL])

    [http://arxiv.org/abs/2305.04003](http://arxiv.org/abs/2305.04003)

    本文介绍了一种名为ANTONIO的Python库，它基于抽象解释方法提供了一种实用的方法和启发式规则，以便为自然语言处理（NLP）数据集和模型生成已知验证方法的基准。因为其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。

    

    自然语言处理（NLP）中使用的机器学习模型的验证被认为是一个难题。现有的神经网络验证方法常用于计算机视觉和其他数字数据集，但并不适用于NLP。本研究探讨了造成这一问题的技术原因，并在此基础上提出了实用的方法和启发式规则，以便将NLP数据集和模型准备为适合基于抽象解释的已知验证方法。我们将这些方法实现为一个名为ANTONIO的Python库，该库连接到神经网络验证器ERAN和Marabou。我们使用一个名为R-U-A-Robot的NLP数据集对工具进行了评估，该数据集被提议作为验证具有法律重要性的NLP应用的基准。我们希望，由于其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。

    Verification of machine learning models used in Natural Language Processing (NLP) is known to be a hard problem. In particular, many known neural network verification methods that work for computer vision and other numeric datasets do not work for NLP. Here, we study technical reasons that underlie this problem. Based on this analysis, we propose practical methods and heuristics for preparing NLP datasets and models in a way that renders them amenable to known verification methods based on abstract interpretation. We implement these methods as a Python library called ANTONIO that links to the neural network verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP applications. We hope that, thanks to its general applicability, this work will open novel possibilities for including NLP verification problems into neural network verification competitions, and will popularise NLP problems withi
    
[^53]: LeafAI：临床队列发现的查询生成器与人类程序员不相上下

    LeafAI: query generator for clinical cohort discovery rivaling a human programmer. (arXiv:2304.06203v1 [cs.CL])

    [http://arxiv.org/abs/2304.06203](http://arxiv.org/abs/2304.06203)

    该研究开发了一个名为LeafAI的系统，可以生成数据模型不受限制的查询，同时为复杂的临床试验资格标准提供新颖的逻辑推理能力。

    

    目的：在临床研究中，确定研究资格的患者是关键步骤。然而，准确的查询设计通常需要广泛的技术和生物医学专业知识。我们试图创建一个系统，能够生成数据模型不受限制的查询，同时为复杂的临床试验资格标准提供新颖的逻辑推理能力。材料和方法：从资格标准创建查询的任务需要解决几个文本处理问题，包括命名实体识别和关系提取、序列到序列转换、归一化和推理。我们结合了深度学习和基于规则的模块以及统一医学语言系统（UMLS）和链接本体，建立了一个知识库。为了实现数据模型不受限制的查询创建，我们介绍了一种使用UMLS概念标记数据库模式元素的新方法。为了评估我们的系统LeafAI，我们与两个具有临床应用背景的真实世界数据库进行了比较。

    Objective: Identifying study-eligible patients within clinical databases is a critical step in clinical research. However, accurate query design typically requires extensive technical and biomedical expertise. We sought to create a system capable of generating data model-agnostic queries while also providing novel logical reasoning capabilities for complex clinical trial eligibility criteria.  Materials and Methods: The task of query creation from eligibility criteria requires solving several text-processing problems, including named entity recognition and relation extraction, sequence-to-sequence transformation, normalization, and reasoning. We incorporated hybrid deep learning and rule-based modules for these, as well as a knowledge base of the Unified Medical Language System (UMLS) and linked ontologies. To enable data-model agnostic query creation, we introduce a novel method for tagging database schema elements using UMLS concepts. To evaluate our system, called LeafAI, we compare
    
[^54]: SGL-PT: 一种具有图形提示调优的强大图形学习器

    SGL-PT: A Strong Graph Learner with Graph Prompt Tuning. (arXiv:2302.12449v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12449](http://arxiv.org/abs/2302.12449)

    SGL-PT是一个具有图形提示调优的强大图形学习器，以缩小预训练和下游图形任务之间的差距，并提供一致的训练目标来增强预训练模型的能力。

    

    最近，人们付出了很多努力来设计图形自监督方法，以获得通用的预训练模型，并通过微调将预训练模型应用于下游任务。然而，前文任务和下游图形任务之间存在固有差距，这不充分发挥了预训练模型的能力，甚至导致负传递。同时，通过将预训练和微调与一致的训练目标对齐，提示调优在自然语言处理中取得了成功。在本文中，我们确定了图形提示调优的挑战：首先，图领域中各种预训练方法之间缺乏强大且通用的预训练任务。第二个挑战在于设计一致的训练目标，既适用于预训练任务，也适用于下游任务。为了克服上述障碍，我们提出了一种名为SGL-PT的新框架，该框架遵循学习策略“预训练、提示和预测”。

    Recently, much exertion has been paid to design graph self-supervised methods to obtain generalized pre-trained models, and adapt pre-trained models onto downstream tasks through fine-tuning. However, there exists an inherent gap between pretext and downstream graph tasks, which insufficiently exerts the ability of pre-trained models and even leads to negative transfer. Meanwhile, prompt tuning has seen emerging success in natural language processing by aligning pre-training and fine-tuning with consistent training objectives. In this paper, we identify the challenges for graph prompt tuning: The first is the lack of a strong and universal pre-training task across sundry pre-training methods in graph domain. The second challenge lies in the difficulty of designing a consistent training objective for both pre-training and downstream tasks. To overcome above obstacles, we propose a novel framework named SGL-PT which follows the learning strategy ``Pre-train, Prompt, and Predict''. Specif
    
[^55]: SuS-X：无需训练的基于名称的视觉语言模型迁移方法

    SuS-X: Training-Free Name-Only Transfer of Vision-Language Models. (arXiv:2211.16198v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.16198](http://arxiv.org/abs/2211.16198)

    本文提出了SuS-X，一种无需训练的基于名称的视觉语言模型迁移方法，具有较高的零样本分类能力。

    

    对比语言-图像预训练（CLIP）已成为训练大规模视觉语言模型的一种简单而有效的方法。尽管CLIP在多种下游任务的零样本分类和检索方面展示出卓越的性能，但要发挥其全部潜力，微调仍然是必要的。微调整个CLIP模型会消耗资源且不稳定。此外，最近的方法虽然旨在避免对下游任务进行微调，但仍需要访问目标分布中的图像。本文探索了另一种方法——无需训练的“仅基于名称迁移”的方法。我们提出了一种新颖的方法SuS-X，由两个关键构建块——SuS和TIP-X组成，既不需要密集的微调，也不需要昂贵的标记数据。SuS-X在19个基准数据集上实现了最先进的零样本分类结果。

    Contrastive Language-Image Pre-training (CLIP) has emerged as a simple yet effective way to train large-scale vision-language models. CLIP demonstrates impressive zero-shot classification and retrieval on diverse downstream tasks. However, to leverage its full potential, fine-tuning still appears to be necessary. Fine-tuning the entire CLIP model can be resource-intensive and unstable. Moreover, recent methods that aim to circumvent this need for fine-tuning still require access to images from the target distribution. In this paper, we pursue a different approach and explore the regime of training-free "name-only transfer" in which the only knowledge we possess about the downstream task comprises the names of downstream target categories. We propose a novel method, SuS-X, consisting of two key building blocks -- SuS and TIP-X, that requires neither intensive fine-tuning nor costly labelled data. SuS-X achieves state-of-the-art zero-shot classification results on 19 benchmark datasets. 
    

