# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Experimental Narratives: A Comparison of Human Crowdsourced Storytelling and AI Storytelling.](http://arxiv.org/abs/2310.12902) | 本研究提出了一种框架，通过比较人类众包叙事和AI叙事，探究了文化产物和社会偏见在故事中的表现。实验结果显示，GPT-3.5和GPT-4生成的叙事更具进展性，并且普罗米修斯神话在人类和大型语言模型的想象中起到了重要作用。 |
| [^2] | [A Systematic Study of Performance Disparities in Multilingual Task-Oriented Dialogue Systems.](http://arxiv.org/abs/2310.12892) | 该研究系统性地研究了多语言任务导向对话系统中的性能差异，并发现了适应性和内在偏见对系统性能的影响。 |
| [^3] | [StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding.](http://arxiv.org/abs/2310.12874) | 本文通过构建故事级类比语料库StoryAnalogy评估了大型语言模型在识别和生成类比任务上的能力，发现这些任务对于句子嵌入模型和最近的大型语言模型来说都非常具有挑战性。同时，研究发现通过使用StoryAnalogy中的数据可以提高大型语言模型的类比生成质量。 |
| [^4] | [The Locality and Symmetry of Positional Encodings.](http://arxiv.org/abs/2310.12864) | 本研究对位置编码中的局部性和对称性进行了系统研究，发现其核心功能和与下游任务性能之间的密切关联，同时揭示了当前位置编码的不足之处。 |
| [^5] | [Probing LLMs for hate speech detection: strengths and vulnerabilities.](http://arxiv.org/abs/2310.12860) | 本研究探究了使用大型语言模型检测仇恨言论的方法，并发现在模型中包含目标信息和理由/解释可以显著提高其性能。同时，我们提供了模型分类和预测错误的错误案例的分类方法。 |
| [^6] | [EmoDiarize: Speaker Diarization and Emotion Identification from Speech Signals using Convolutional Neural Networks.](http://arxiv.org/abs/2310.12851) | 本研究提出了一个综合的解决方案，将说话人日程和情感识别相结合，使用深度学习技术和卷积神经网络提高了精度。 |
| [^7] | [Knowledge-Augmented Language Model Verification.](http://arxiv.org/abs/2310.12836) | 提出了一种知识增强的语言模型验证方法，通过一个独立的验证器来检测模型输出和知识的错误，并通过检索新知识或修正摘要来纠正错误。 |
| [^8] | [AgentTuning: Enabling Generalized Agent Abilities for LLMs.](http://arxiv.org/abs/2310.12823) | 本论文提出了AgentTuning，一种简单而通用的方法，可提升LLMs的代理能力，同时保持其通用能力。通过构建AgentInstruct数据集，并采用一种混合训练方法，作者成功地实现了提高LLMs代理能力的目标。 |
| [^9] | [GestureGPT: Zero-shot Interactive Gesture Understanding and Grounding with Large Language Model Agents.](http://arxiv.org/abs/2310.12821) | GestureGPT是一个零样本交互手势理解和对接框架，利用大语言模型代理解读手势描述并根据交互环境提供上下文信息，能够将用户意图对接到交互功能上。 |
| [^10] | [Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models.](http://arxiv.org/abs/2310.12818) | 本论文提出了一种提升参数共享预训练语言模型推理效率的简单技术，并介绍了一种简单的预训练方法来实现完全或部分共享的模型，实验结果证明了这些方法在各种模型上的有效性，为更有效地利用参数提供了新的见解。 |
| [^11] | [Prompt Injection Attacks and Defenses in LLM-Integrated Applications.](http://arxiv.org/abs/2310.12815) | 本文提出了一个通用框架来形式化提示注入攻击，并系统化防御这种类型的攻击。 |
| [^12] | [Model Merging by Uncertainty-Based Gradient Matching.](http://arxiv.org/abs/2310.12808) | 本论文通过不确定性梯度匹配的方法，提出了一种新的模型合并方案，该方案能够减少梯度不匹配，从而提高了模型合并的性能并对超参数更具鲁棒性。 |
| [^13] | [Causal-structure Driven Augmentations for Text OOD Generalization.](http://arxiv.org/abs/2310.12803) | 本文提出了一种基于因果结构的反事实数据增强方法，用于改善文本分类器在应用中的泛化效果，特别适用于存在虚假相关性的标签与属性预测问题。 |
| [^14] | [MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter.](http://arxiv.org/abs/2310.12798) | MolCA是一个可以通过跨模态投影和单模态适配器实现分子图和语言的建模系统。它可以通过连接图编码器和语言模型的表示空间来理解文本和图形的分子内容，并通过单模态适配器在下游任务中高效适应。 |
| [^15] | [Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization.](http://arxiv.org/abs/2310.12794) | 本文研究了在Transformer语言模型中明确对齐语言之间的概念对应关系的潜力，以强化跨语言泛化能力。研究发现，无论是仅有编码器还是仅有解码器的模型，各语言内的结构概念空间对齐度高。通过基于元学习的方法，可以学习对齐不同语言的概念空间，实现零样本和少样本泛化。 |
| [^16] | [Label-Aware Automatic Verbalizer for Few-Shot Text Classification.](http://arxiv.org/abs/2310.12778) | 这篇论文提出了一种标签感知的自动语言表达方式（LAAV），通过增加手动标签和连接词“和”来提升语言模型的生成，从而在少样本分类任务中取得更好的结果。 |
| [^17] | [Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning.](http://arxiv.org/abs/2310.12774) | 本文提出了一种名为ClaPS的简单黑盒搜索方法，通过聚类和修剪搜索空间中最有影响力的提示令牌，解决了现代黑盒方法中的效率问题。 |
| [^18] | [Transformer-based Entity Legal Form Classification.](http://arxiv.org/abs/2310.12766) | 提出了一种使用Transformer-based语言模型进行实体法律形式分类的方法，该方法在比较中表现出较高的性能并得到了第三方评审的支持。 |
| [^19] | [Character-level Chinese Backpack Language Models.](http://arxiv.org/abs/2310.12751) | 通过对中文进行字符标记化，我们训练了一个比Transformer更具解释性的中文背包语言模型，该模型学习到了丰富的字符级别含义，其组合形成词义，并且在词汇语义评估中胜过Transformer的输入嵌入。 |
| [^20] | [Representing and Computing Uncertainty in Phonological Reconstruction.](http://arxiv.org/abs/2310.12727) | 该论文提出了一个新的框架，用于在语言重构中表示和计算不确定性，通过借鉴监督音韵重构和自动预测方法，实现了模糊重构的工作流程。 |
| [^21] | [Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing.](http://arxiv.org/abs/2310.12664) | 本研究通过对金融自然语言处理中的语言模型进行评估，发现虽然一些解码器语言模型通过零样本提示在大多数金融任务中表现出了显着性能，但它们总体上落后于经过精细调整的专业模型，特别是在处理专有数据集时。 |
| [^22] | [Towards Real-World Streaming Speech Translation for Code-Switched Speech.](http://arxiv.org/abs/2310.12648) | 本文针对面向真实世界的混合语音流式翻译进行了研究，主要关注了流式设置和翻译到第三种语言的问题，并提出了一种基线模型进行了实验。 |
| [^23] | [Non-Autoregressive Sentence Ordering.](http://arxiv.org/abs/2310.12640) | 这篇论文提出了一种非自回归的句子排序方法，通过探索句子之间的双向依赖关系，并并行预测每个位置的句子，以解决现有方法在排序任务中只能利用单向依赖关系的限制。 |
| [^24] | [Predict the Future from the Past? On the Temporal Data Distribution Shift in Financial Sentiment Classifications.](http://arxiv.org/abs/2310.12620) | 本文针对金融情绪分类中存在的时间数据分布转移问题，通过对真实金融社交媒体数据集进行实证研究，发现经过微调的模型在时间分布转移的情况下性能下降。针对金融文本的独特时间特性，提出了一种结合离群点检测和时间序列建模的新方法，可以增强模型在波动性金融市场中适应时间分布转移的能力。 |
| [^25] | [Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model.](http://arxiv.org/abs/2310.12611) | 本研究通过三种方法识别英文语言模型中负责性别偏见的Transformer组件，然后使用这些组件进行参数高效的偏见缓解微调，取得了成功的性别偏见缓解效果并减少了对一般语言建模的损害。 |
| [^26] | [Time-Aware Representation Learning for Time-Sensitive Question Answering.](http://arxiv.org/abs/2310.12585) | 该论文提出了一种时态感知的问题回答框架，通过引入时间上下文的区间抽取任务和相应的数据生成框架来训练模型，提高了QA模型的时间感知能力，在TimeQA数据集中的F1分数上超过了基准模型达8.5。 |
| [^27] | [Pretraining Language Models with Text-Attributed Heterogeneous Graphs.](http://arxiv.org/abs/2310.12580) | 本文提出了一个新的语言模型预训练框架，能够明确考虑到文本属性异构图中的拓扑和异构信息。通过优化语言模型和辅助的异构图神经网络，预测了文本属性异构图中的节点。同时，还设计了一个文本丰富性加权的节点抽样策略，以更好地利用文本信息。 |
| [^28] | [Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers.](http://arxiv.org/abs/2310.12575) | 该论文提出了两种方法来自动分析政党宣言的缩放值：标签聚合和基于长文本输入Transformer的模型。他们在比较宣言项目数据集上进行了分析，结果表明它们是有效的并且可以在多语言环境下工作。 |
| [^29] | [Large Language Models Help Humans Verify Truthfulness -- Except When They Are Convincingly Wrong.](http://arxiv.org/abs/2310.12558) | 本研究比较了语言模型与搜索引擎在帮助用户事实核查方面的效果。结果显示，用户阅读语言模型的解释比使用搜索引擎更高效，但当解释错误时，用户容易过度依赖语言模型。为了减少过度依赖，研究提出了使用对比信息进行解释的方法。 |
| [^30] | [DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text.](http://arxiv.org/abs/2310.12557) | DepWiGNN是一种用于多跳空间推理的深度图神经网络。它通过设计新颖的节点记忆方案，并在图的深度维度上聚合信息，从而能够收集长时间的依赖关系，而无需堆叠多个层次。实验结果表明，DepWiGNN在两个挑战数据集上比传统GNN方法具有更高的准确性。 |
| [^31] | [Large Language Model for Multi-objective Evolutionary Optimization.](http://arxiv.org/abs/2310.12541) | 本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。 |
| [^32] | [Product Attribute Value Extraction using Large Language Models.](http://arxiv.org/abs/2310.12537) | 本文研究使用大型语言模型作为预训练的替代方法，解决了传统属性/值提取技术中需要大量训练数据和对未知属性值的挑战问题。 |
| [^33] | [ICU: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding.](http://arxiv.org/abs/2310.12531) | ICU提出了一种解决视觉与语言建模中语言障碍的方法，通过将任务划分为图像字幕和语言理解两个阶段，将多语言处理负担转移到多语言语言模型上。实验结果显示，ICU在多个语言上取得了最先进的结果。 |
| [^34] | [Named Entity Recognition for Monitoring Plant Health Threats in Tweets: a ChouBERT Approach.](http://arxiv.org/abs/2310.12522) | 本文研究了一种基于ChouBERT的命名实体识别方法，应用于监测植物健康威胁。通过利用社交媒体中的非结构化文本数据，可以检测并提取关键信息，从而解决现有解决方案中缺乏标记数据和细粒度语义资源的问题。 |
| [^35] | [Lost in Translation: When GPT-4V(ision) Can't See Eye to Eye with Text. A Vision-Language-Consistency Analysis of VLLMs and Beyond.](http://arxiv.org/abs/2310.12520) | 本研究通过对视觉语言一致性进行全面分析，揭示了视觉大语言模型在跨模态任务中的能力差异。 |
| [^36] | [Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks.](http://arxiv.org/abs/2310.12516) | 本文提出了一种通过可迁移的对抗攻击在大型语言模型中自动生成评估数据的方法，并使用ChatGPT和Natural Questions（NQ）数据集进行了验证。 |
| [^37] | [Attack Prompt Generation for Red Teaming and Defending Large Language Models.](http://arxiv.org/abs/2310.12505) | 我们提出了一种综合方法来经济地生成高质量的攻击提示，通过上下文学习指导大型语言模型（LLMs）模仿人类生成的提示，并通过迭代交互来加强受攻击的LLMs的安全性。这些方法在不同LLMs上的实验验证了其有效性。 |
| [^38] | [Co$^2$PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning.](http://arxiv.org/abs/2310.12490) | Co$^2$PT是一种通过反事实对比提示调整方法，可以在下游任务中减轻预训练语言模型中的偏见，并适应现有的去偏语言模型。 |
| [^39] | [MedAI Dialog Corpus (MEDIC): Zero-Shot Classification of Doctor and AI Responses in Health Consultations.](http://arxiv.org/abs/2310.12489) | 本研究通过零样本学习调查了预训练语言模型在医生和AI在健康咨询中的回答的准确分类上的效果。研究发现，虽然预训练语言模型在一般语言理解方面表现出了很强的能力，但在医疗咨询中，它们可能需要特定语料库训练或其他技术以实现准确的医生和AI生成文本的分类。 |
| [^40] | [Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models.](http://arxiv.org/abs/2310.12481) | 本文研究了大型语言模型中的文化主导问题，发现由于在模型训练中主要使用英语数据，当用户使用非英语语言提问时，模型往往提供与预期文化不相关的不恰当答案。我们提出了通过多样化数据预训练和文化感知提示两种方法来解决这个问题。 |
| [^41] | [An Exploration of In-Context Learning for Speech Language Model.](http://arxiv.org/abs/2310.12477) | 本研究是首次探索了在语音处理中利用上下文学习（ICL）的可能性，通过在输入中呈现LM话语-标签示范，语音LM可以在没有文本监督的情况下实现少样本学习，并通过验证了在语音分类任务上进行ICL的可行性。 |
| [^42] | [Contrastive Learning for Inference in Dialogue.](http://arxiv.org/abs/2310.12467) | 本论文分析了推理任务中的信息差异对模型的影响，并提出了一种对比学习方法来缓解这种信息差异。实验证明，负样本有助于模型改进其推理生成能力。 |
| [^43] | [Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights.](http://arxiv.org/abs/2310.12462) | 本文提出了一种基于注意力权重和输出的理论框架，用于恢复Transformer模型中的输入数据。研究结果暗示模型设计存在潜在的漏洞。 |
| [^44] | [Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models.](http://arxiv.org/abs/2310.12454) | 本研究重新思考了构建用于理解预训练语言模型机制的有效度量方法。通过设计一系列度量方法，并使用树拓扑探针模型对BERT-large进行了实证研究。 |
| [^45] | [A Read-and-Select Framework for Zero-shot Entity Linking.](http://arxiv.org/abs/2310.12450) | 提出了一个用于零样本实体链接的阅读和选择框架，通过建模实体消歧的主要组成部分，即实体提及-实体匹配和实体之间的比较，实现了最先进的性能。 |
| [^46] | [Revisiting Sparse Retrieval for Few-shot Entity Linking.](http://arxiv.org/abs/2310.12444) | 本研究重新审视了少样本实体链接中的稀疏检索方法，并利用ELECTRA模型提取关键词来改善查询表达式，在ZESHEL数据集上实验结果显示，所提出的方法在所有测试领域中优于最先进模型。 |
| [^47] | [Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher.](http://arxiv.org/abs/2310.12443) | 该论文提出了一种新颖的生成检索框架，旨在将LLM转变为一个相关、负责任且可信赖的搜索器。该框架包括生成器、验证器和优化器三个核心模块，分别用于生成可信赖的在线来源、验证来源可靠性和优化不可信赖的来源。通过广泛的实验证明了该方法相对于其他方法在相关性、负责任性和可信度方面的优势。 |
| [^48] | [Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer.](http://arxiv.org/abs/2310.12442) | 提出了一种高效的长程Transformer模型MASFormer，通过在少数层使用全局注意力和在其他层使用稀疏注意力，实现了在具有长序列的任务中高效的计算和建模能力。 |
| [^49] | [PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models.](http://arxiv.org/abs/2310.12439) | PoisonPrompt是一种新的后门攻击方法，能够成功地破坏基于提示的大型语言模型，该攻击方法的有效性、保真度和鲁棒性经过了广泛实验验证，强调了基于提示的语言模型面临的安全威胁和进一步研究的必要性。 |
| [^50] | [DocXChain: A Powerful Open-Source Toolchain for Document Parsing and Beyond.](http://arxiv.org/abs/2310.12430) | DocXChain是一个开源工具链，通过文档解析将非结构化文档转换为可读可操作的结构化表示，并提供了基本能力和完全功能的文档解析流水线，可以与其他工具和模型集成，用于完成复杂任务。 |
| [^51] | [MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models.](http://arxiv.org/abs/2310.12426) | 本研究提出了一种多方面反馈的迭代优化框架，该框架包括冻结的语言模型和外部工具模块，每个模块都专注于特定的错误类型。实验证明该方法改善了大型语言模型在推理任务中的性能，相对提升了多达20%。 |
| [^52] | [The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions.](http://arxiv.org/abs/2310.12418) | 本文通过分析用户-GPT对话，发现了当前NLP研究与实际应用需求之间的差异。用户经常请求的任务与学术研究中常研究的任务存在显著差距，如“设计”和“规划”等任务在学术研究中被忽视。对这些被忽略任务的研究有助于更好地满足实际需求。 |
| [^53] | [FinEntity: Entity-level Sentiment Classification for Financial Texts.](http://arxiv.org/abs/2310.12406) | 本论文介绍了一个名为FinEntity的实体级情感分类数据集，该数据集标注了金融新闻中的金融实体范围及其情感，为金融领域的实体级情感分析提供了重要资源。通过基准测试，指出了几个预训练模型在实体级情感分类任务上的效果，并通过案例研究展示了FinEntity在监测加密货币市场中的实际应用价值。 |
| [^54] | [Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative Editing.](http://arxiv.org/abs/2310.12404) | Loop Copilot是一种新型的AI音乐合奏系统，能够通过交互式多轮对话界面生成和迭代改进音乐，通过选择适当的AI模型执行任务，并在一个集中的表中保持关键属性以确保音乐的连贯性。 |
| [^55] | [Solving Hard Analogy Questions with Relation Embedding Chains.](http://arxiv.org/abs/2310.12379) | 本文提出了一种解决困难的类比问题的方法，通过将关系建模为路径并关联其边缘与关系嵌入，以获得合适的中间词和有信息量的关系嵌入，从而结合了知识图谱和关系嵌入的优势。 |
| [^56] | [REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models.](http://arxiv.org/abs/2310.12362) | REMARK-LLM是一种针对生成大型语言模型的文本的鲁棒高效的水印框架，通过学习-based消息编码、重新参数化和解码模块以及优化的波束搜索算法来保护生成内容的完整性和防止恶意利用。 |
| [^57] | [GRI: Graph-based Relative Isomorphism of Word Embedding Spaces.](http://arxiv.org/abs/2310.12360) | 提出了一种名为GRI的方法，通过结合分布训练目标和注意力图卷积，一致地考虑多个空间之间定义/计算相对同构性所需的语义相似词汇的影响。在实验评估中，GRI在平均P@1上相对得分提升了高达63.6％。 |
| [^58] | [knn-seq: Efficient, Extensible kNN-MT Framework.](http://arxiv.org/abs/2310.12352) | "knn-seq"是一个高效、可扩展的kNN-MT框架，通过利用翻译示例来提高预训练NMT模型的翻译质量，给出了在十亿级数据存储下具有可比较增益的实验结果，并在德英翻译任务中仅花费2.21小时来构建十亿规模的数据存储。 |
| [^59] | [LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following.](http://arxiv.org/abs/2310.12344) | 该论文提出了一种名为LACMA的方法，通过对比学习实现了智能体与指令的语言对齐，进而通过引入元行动的概念来解决高级语言指令与低级行动空间之间的语义差距，从而提高了智能体在未知环境中的泛化能力。 |
| [^60] | [Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs' Non-linear Thinking.](http://arxiv.org/abs/2310.12342) | 本文提出了一种名为推断性排除提示（IEP）的新框架，通过结合排除和推理的原则，引导LLM进行非线性思考。IEP通过规划和自然语言推理，可以模拟复杂的人类思维过程，比其他方法具有更广泛的视角。 |
| [^61] | [A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.](http://arxiv.org/abs/2310.12321) | GPT-3家族大型语言模型是一类特殊的预训练语言模型，通过扩大模型规模、预训练语料库和计算，能够在许多自然语言处理任务中无需特定训练而取得显著性能。这篇论文是对最近研究进展的全面概述，为研究社区提供未来研究方向的指导。 |
| [^62] | [The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis.](http://arxiv.org/abs/2310.12318) | 这项研究通过调查189篇论文，批判性地研究了情感分析在社会技术系统中的应用，揭示了对情感的不同概念化，并提出了一个伦理表格来解决情感分析中的公平利用问题。 |
| [^63] | [Document-Level Language Models for Machine Translation.](http://arxiv.org/abs/2310.12303) | 这项工作提出了一种利用文档级别语言模型构建上下文感知的翻译系统的方法。通过结合任何现有的句级别翻译模型与文档级别语言模型，并借鉴模型组合的最新进展，尤其是权重技术的提出，可以显著提高文档级别指标并降低计算开销。 |
| [^64] | [Measuring Pointwise $\mathcal{V}$-Usable Information In-Context-ly.](http://arxiv.org/abs/2310.12300) | 这项研究适用于上下文学习范式，通过调整逐点可用信息度量指标为适用于上下文的版本，将其命名为上下文PVI，并证明了上下文PVI的可靠性和稳定性。 |
| [^65] | [An Image is Worth Multiple Words: Learning Object Level Concepts using Multi-Concept Prompt Learning.](http://arxiv.org/abs/2310.12274) | 提出了一种多概念提示学习（MCPL）框架，通过同时学习多个新的“词”来解决在单个场景中识别和整合多个对象级概念的挑战。针对词概念相关性准确性问题，提出了注意力掩码、提示对比损失和绑定形容词等三种正则化技术。通过图像生成进行了评估，结果表明该框架能够生成更多样化和合成的图像。 |
| [^66] | [Direct Neural Machine Translation with Task-level Mixture of Experts models.](http://arxiv.org/abs/2310.12236) | 在这项工作中，我们研究了任务级MoE在直接神经机器翻译中的应用，并提出了一系列高性能的训练和评估配置，通过这些配置，任务级MoE的直接NMT系统在大量低资源语言对上优于双语和基于中间语言的模型。 |
| [^67] | [Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining.](http://arxiv.org/abs/2310.12172) | ImageArg-2023是第一个多模态论证挖掘的共享任务，涵盖了论证立场分类和图像说服力分类两个子任务。共收到了来自6个国家的9个团队提交的31个子任务A的提交和21个子任务B的提交，最好的提交在子任务A中达到了0.8647的F1得分，在子任务B中达到了0.5561的F1得分。 |
| [^68] | [From Dissonance to Insights: Dissecting Disagreements in Rationale Dataset Construction for Case Outcome Classification.](http://arxiv.org/abs/2310.11878) | 本研究关注法律自然语言处理中人工标注的变异问题，通过收集一组律师对案件结果评估存在分歧的数据集，对这些分歧进行了研究，构建了一个两级分类体系，并发现分歧主要源于对法律背景的不明确描述。 |
| [^69] | [Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning.](http://arxiv.org/abs/2310.11670) | 基于原型的超适配器（PHA）框架用于样本高效多任务调整，通过引入实例密集的检索器和样本高效的原型超网络生成条件模块，在多任务学习和少样本迁移学习中取得了可比性能的提升，甚至在数据量较小时也能超过其他强基线方法的性能。 |
| [^70] | [VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights.](http://arxiv.org/abs/2310.11368) | VECHR是一个专家注释的多标签数据集，用于欧洲人权法院漏洞类型的可解释和鲁棒分类。该数据集帮助识别脆弱性，并提供解释理由。结果显示了该任务的挑战性，模型与专家的一致性有限，模型在处理域外数据时鲁棒性也较低。 |
| [^71] | [Experimenting AI Technologies for Disinformation Combat: the IDMO Project.](http://arxiv.org/abs/2310.11097) | IDMO项目旨在使用人工智能技术打击虚假信息和假新闻，其贡献包括创建新型数据集、开发自动模型、评估GPT-4等。 |
| [^72] | [BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys.](http://arxiv.org/abs/2310.10765) | 提出了一种新颖的方法BiomedJourney，通过指导学习多模态患者旅程，进行反事实生物医学图像生成。使用GPT-4处理图像报告生成疾病进展的自然语言描述，并训练潜在扩散模型。 |
| [^73] | [In-Context Pretraining: Language Modeling Beyond Document Boundaries.](http://arxiv.org/abs/2310.10638) | 本论文提出了一种超越文档边界的上下文预训练方法，通过在相关文档序列上训练语言模型，鼓励模型进行跨文档的阅读和推理。该方法通过改变文档顺序并应用现有的预训练管道来实现。 |
| [^74] | [VIBE: Topic-Driven Temporal Adaptation for Twitter Classification.](http://arxiv.org/abs/2310.10191) | VIBE是一种解决Twitter分类中语言特征演变问题的模型，通过建模潜在主题演变以适应动态环境，并且在大规模Twitter实验中展现了良好的性能。 |
| [^75] | [A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks.](http://arxiv.org/abs/2310.09430) | 通过对大型语言模型在非分布式逻辑推理任务上进行系统评估，我们发现这些模型在处理我们新构建的数据集时都存在困难，尽管它们在其他自然语言处理任务上表现良好。这表明这些模型在逻辑推理方面的泛化和鲁棒性仍需要进一步研究。 |
| [^76] | [Ranking LLM-Generated Loop Invariants for Program Verification.](http://arxiv.org/abs/2310.09342) | 本研究提出了一种针对LLM生成结果进行重新排名的方法，可以显著提高正确不变量的排名，从而减少程序验证的调用次数。 |
| [^77] | [Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration.](http://arxiv.org/abs/2310.09168) | 通过采用探索指导的方法，使用大型语言模型 (LLMs) 进行主动探索，增强了领域特定指导调优的数据覆盖范围，并取得了显著的性能提升。 |
| [^78] | [Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation.](http://arxiv.org/abs/2310.08395) | 本文提出了一种使用思路链（CoT）对大型语言模型进行少样本知识库问题生成的方法，该方法将问题生成任务形式化为推理问题，并通过检索支持性逻辑形式和编写提示来实现生成过程。 |
| [^79] | [ClimateNLP: Analyzing Public Sentiment Towards Climate Change Using Natural Language Processing.](http://arxiv.org/abs/2310.08099) | 本研究利用自然语言处理分析社交媒体上关于气候变化的推文情感态度，通过使用ClimateBERT模型量化情感，从而获得有关公众对气候变化的观点和反馈。 |
| [^80] | [KwaiYiiMath: Technical Report.](http://arxiv.org/abs/2310.07488) | KwaiYiiMath是一个用于增强数学推理能力的大型语言模型，通过应用监督微调和人类反馈强化学习，在英语和中文数学任务上取得了最先进的性能，并且能够正确解决生成的问题过程。 |
| [^81] | [Jaeger: A Concatenation-Based Multi-Transformer VQA Model.](http://arxiv.org/abs/2310.07091) | Jaeger是一种基于连接的多变换器VQA模型，利用RoBERTa large和GPT2-xl作为特征提取器，通过并行考虑多源信息来增强模型表征能力。 |
| [^82] | [CAW-coref: Conjunction-Aware Word-level Coreference Resolution.](http://arxiv.org/abs/2310.06165) | 本文介绍了一种关联词感知的词级共指消解模型（CAW-coref），在处理并列提及的情况下表现出了较高的性能，有效地缩小了与昂贵的最先进方法的差距。 |
| [^83] | [Enhancing Document-level Event Argument Extraction with Contextual Clues and Role Relevance.](http://arxiv.org/abs/2310.05991) | 本文提出了一个SCPRG模型，通过引入Span-Trigger-based Contextual Pooling(STCP)和Role-based Latent Information Guidance (RLIG)模块，解决了文档级事件论证中忽略的非论证上下文线索信息以及论证角色相关性的问题。模型通过自适应地选择和汇聚上下文中的非论证线索词，以及构建潜在的角色表示并捕捉语义相关性，显著提升了文档级事件论证的准确性。 |
| [^84] | [Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback.](http://arxiv.org/abs/2310.05199) | 本文提出了一种创新的解决方案，通过应用“专家的乘积”（PoE）技术来减轻强化学习中的长度偏差问题。在这个框架中，主要的专家关注理解人类意图，而偏见专家则致力于识别和捕捉长度偏差。 |
| [^85] | [Recurrent Neural Language Models as Probabilistic Finite-state Automata.](http://arxiv.org/abs/2310.05161) | 本文研究了循环神经网络语言模型（RNN LMs）作为概率有限状态自动机的能力，并发现它们只能表示有限状态模型所能表达的概率分布的一个严格子集。 |
| [^86] | [Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot Performance via Probability Calibration.](http://arxiv.org/abs/2310.05069) | 通过概率校准方法，本研究通过结合校准技术和多语言编码器，解决了预训练模型对于频繁出现的标签词预测偏好的问题，并显著提高了零-shot性能。 |
| [^87] | [DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning.](http://arxiv.org/abs/2310.02954) | 本研究引入了DQ-LoRe框架，它通过双重查询和低秩近似重新排序自动选择用于上下文学习的示例，在复杂推理任务中展示了出色的性能和效果。 |
| [^88] | [OceanGPT: A Large Language Model for Ocean Science Tasks.](http://arxiv.org/abs/2310.02031) | OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。 |
| [^89] | [Meta Semantic Template for Evaluation of Large Language Models.](http://arxiv.org/abs/2310.01448) | 提出了一种通过创建元语义模板来评估大型语言模型（LLM）对语义理解能力的方法，该方法利用现有数据集生成新的超出分布（OOD）评估集。 |
| [^90] | [Measuring Value Understanding in Language Models through Discriminator-Critique Gap.](http://arxiv.org/abs/2310.00378) | 通过鉴别-批判差距测量LLMs对人类价值的理解，我们提出了价值理解测量（VUM）框架，并使用GPT-4开发了一个包含一千个对话的数据集。我们的评估结果显示，尺度定律对LLMs的“知道什么”有较大影响，而对“知道为什么”影响较小。 |
| [^91] | [NLPBench: Evaluating Large Language Models on Solving NLP Problems.](http://arxiv.org/abs/2309.15630) | NLPBench是一个评估大型语言模型解决NLP问题的基准数据集，为填补该领域的研究空白，作者收集了来自耶鲁大学期末考试的378个涵盖多个NLP主题的问题。该研究发现在使用高级提示策略时，大型语言模型的性能可能不稳定，并可能对较小的模型造成负面影响。 |
| [^92] | [AnglE-Optimized Text Embeddings.](http://arxiv.org/abs/2309.12871) | 本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。 |
| [^93] | [Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models.](http://arxiv.org/abs/2309.10444) | 本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。 |
| [^94] | [CONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling.](http://arxiv.org/abs/2309.05270) | 本论文提出了CONFLATOR：一种针对代码混合语言的神经语言建模方法，通过引入旋转位置编码和切换点信息，在混合语言建模中取得最佳结果。 |
| [^95] | [Evaluating Transformer's Ability to Learn Mildly Context-Sensitive Languages.](http://arxiv.org/abs/2309.00857) | 本文评估了Transformer学习轻度上下文敏感语言的能力，发现其在泛化到未见过的数据上表现良好，但在外推到较长字符串上的能力不如LSTMs。分析结果显示，Transformer学习到的自注意力模式和表示能够捕捉依赖关系并表现出计数行为。 |
| [^96] | [Towards Generalist Foundation Model for Radiology.](http://arxiv.org/abs/2308.02463) | 本研究旨在为放射学构建通用基础模型，提出了一个大规模的医学多模态数据集和支持不同放射学任务的架构，同时提出了一个新的评估基准。 |
| [^97] | [A scoping review on multimodal deep learning in biomedical images and texts.](http://arxiv.org/abs/2307.07362) | 这篇综述旨在提供对多模态深度学习在生物医学图像和文本中进行联合学习的当前状况的全面概述，并探索未来的研究方向和该领域的研究空白。 |
| [^98] | [Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale.](http://arxiv.org/abs/2306.15687) | Voicebox是一种大规模的多语言通用语音生成模型，通过使用非自回归的流匹配模型，在文本和音频上下文条件下进行训练，可以实现零样本跨语言文本到语音合成，噪声去除，内容编辑，风格转换和多样化的样本生成等多种任务。 |
| [^99] | [Automatic Assessment of Divergent Thinking in Chinese Language with TransDis: A Transformer-Based Language Model Approach.](http://arxiv.org/abs/2306.14790) | TransDis是一个基于Transformer的语言模型评分系统，用于评估中文发散性思维的质量和多样性。经过实验证明，TransDis的评分能够有效地预测人工评分，具有与人工评分相似的效度。 |
| [^100] | [Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulator to Enhance Dialogue System.](http://arxiv.org/abs/2306.09821) | 该论文提出了一种名为用户引导响应优化（UGRO）的方法，使用大型语言模型作为无注释的用户模拟器，以评估对话响应并优化监督式经过微调的端到端任务导向对话模型。该方法利用了大型语言模型在提供满意度反馈方面的潜力，取得了显著的改进，为利用大型语言模型增强对话系统提供了新的思路。 |
| [^101] | [WSPAlign: Word Alignment Pre-training via Large-Scale Weakly Supervised Span Prediction.](http://arxiv.org/abs/2306.05644) | 本文提出了一种名为WSPAlign的无需手动数据的预训练词对齐方法，通过用大规模弱监督数据中的跨度预测进行预训练，取得了比当前最佳方法更好的效果。 |
| [^102] | [Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning.](http://arxiv.org/abs/2306.00477) | 本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。 |
| [^103] | [NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models.](http://arxiv.org/abs/2305.16986) | NavGPT是基于LLM的导航智能体，可以在视觉语言导航（VLN）中，通过对文本描述进行推理，执行零-shot连续动作预测。该模型具有高级规划能力，可以将指令分解成子目标、整合常识知识以进行障碍物避免，并参考先前的步骤进行澄清。NavGPT展示了通用体现智能体发展的美好前景。 |
| [^104] | [An Efficient Multilingual Language Model Compression through Vocabulary Trimming.](http://arxiv.org/abs/2305.15020) | 该论文提出了一种名为词汇修剪（VT）的方法，通过删除多语言语言模型中的不相关标记，将其压缩为目标语言模型。实验证明，词汇修剪可以在保持多语言模型性能的同时，降低了模型的大小。 |
| [^105] | [RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs and for GPTs.](http://arxiv.org/abs/2305.14994) | RefGPT是一种基于参考的对话生成方法，可以生成大量真实且定制化的对话，并解决了对话生成中的模型幻觉问题。 |
| [^106] | [BeamSearchQA: Large Language Models are Strong Zero-Shot QA Solver.](http://arxiv.org/abs/2305.14766) | BeamSearchQA利用大型语言模型进行迭代式生成问题，以捕捉隐含知识并优化问答过程，在NQ和WebQ测试集上分别达到了71.7％和46.7％的F1分数，显着优于现有的最先进方法。 |
| [^107] | [This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language Models.](http://arxiv.org/abs/2305.14610) | 本文提出了地缘政治偏见的概念，并以领土争端为例，利用多语言、多选题的数据集BorderLines和几个定量指标分析语言模型响应中的地缘政治偏见现象。 |
| [^108] | [Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining.](http://arxiv.org/abs/2305.14281) | 本研究提出了两种弱监督学习方法在多模态预训练中学习视觉关系，通过转换视觉关系数据为结构化标题和遮罩关系预测，实现了从弱监督关系数据中学习多模态表示的有效性。 |
| [^109] | [Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding.](http://arxiv.org/abs/2305.14232) | 本论文提出了一个名为SciMult的多任务对比学习框架，旨在共享不同科学文献理解任务之间的通用知识，同时防止任务特定技能相互干扰。 |
| [^110] | [Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs.](http://arxiv.org/abs/2305.12818) | 基于无注释平行语料库，我们提出一种基于词义共存模式的多语言图方法，用于低资源语言的跨语言迁移学习。通过建立高质量的多语言嵌入，我们实现了高召回率的词义共存识别。 |
| [^111] | [Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training.](http://arxiv.org/abs/2305.12634) | 我们提出了一种数据高效的结构化预测主动学习方法，利用部分注释和自训练来减少注释成本。我们利用部分注释选择最具信息量的子结构进行标注，并将自动预测结果作为未注释子结构的伪标签。我们通过使用错误估计器自适应地决定部分选择比例，有效地结合了这两种方法。在四个结构化预测任务的评估中，我们展示了使用自适应选择比例的部分注释和自训练组合可以降低注释成本。 |
| [^112] | [Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning.](http://arxiv.org/abs/2305.12295) | 本文介绍了一种名为Logic-LM的新框架，它将大型语言模型与符号求解器结合起来，以提升在复杂逻辑问题上的推理能力。通过将自然语言问题转化为符号表达，并利用确定性符号求解器进行推理，我们的方法能够有效地改进准确逻辑推理。实验证明，Logic-LM在多个逻辑推理数据集上取得了显著的性能提升，并且相比使用标准提示或思维链提示，效果分别提高了39.2%和18.4%。这表明将大型语言模型与符号逻辑相结合是实现准确逻辑推理的一个有前途的方法。 |
| [^113] | [Prompting with Pseudo-Code Instructions.](http://arxiv.org/abs/2305.11790) | 本文研究了使用伪代码指令提示能否提高预训练语言模型的性能，实验证明使用伪代码提示可以在分类任务中提高7-16分，并相对改善12-38%。 |
| [^114] | [TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models.](http://arxiv.org/abs/2305.11171) | TrueTeacher是一种使用大型语言模型生成合成数据来进行事实一致性评估的方法，相较于传统方法，TrueTeacher不依赖于人工编写的摘要，多语言特性，实验证明能够显著提升模型的性能。 |
| [^115] | [CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge.](http://arxiv.org/abs/2305.09955) | CooK是一种用于赋能通用语言模型的新颖框架，通过专门的语言模型和协作的知识贡献者，提供模块化、不断增长和多源的知识。在知识密集型任务中，CooK展现出了明显的性能提升。 |
| [^116] | [FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge.](http://arxiv.org/abs/2305.08281) | FactKB是一种通用的事实性评估方法，使用增强了事实知识的语言模型进行预训练，并在不同领域的摘要生成中取得了最先进的性能。 |
| [^117] | [Generative Pretrained Autoregressive Transformer Graph Neural Network applied to the Analysis and Discovery of Novel Proteins.](http://arxiv.org/abs/2305.04934) | 本研究使用基于语言模型的深度学习策略，在蛋白质建模中应用transformer和图卷积的结构预训练生成模型，进一步训练后能够设计具有特定性质的蛋白质，案例验证表明该方法可生成理想目标性质的蛋白质。 |
| [^118] | [Automatic Prompt Optimization with "Gradient Descent" and Beam Search.](http://arxiv.org/abs/2305.03495) | 在基于大型语言模型的自然语言处理中，使用梯度下降和 beam search 的自动提示优化方法可以自动改进提示，提高性能。 |
| [^119] | [PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques.](http://arxiv.org/abs/2304.12410) | 本文提出了PEFT-Ref参考架构，标准化了不同PEFT技术共享的方面，隔离了差异到特定位置和交互中，模块化的视图有助于比较不同技术及其效率和任务性能，并有助于更好地理解PEFT的基本原理。 |
| [^120] | [MWE as WSD: Solving Multiword Expression Identification with Word Sense Disambiguation.](http://arxiv.org/abs/2303.06623) | 该论文提出了一种利用词义消歧来解决多词表达式识别问题的方法，并通过训练模型使用词义的描述和上下文信息来过滤候选项，从而显著提高了精确度。研究还引入了一种新的架构，通过双编码器进一步提高了MWE识别性能。 |
| [^121] | [Test-Time Distribution Normalization for Contrastively Learned Vision-language Models.](http://arxiv.org/abs/2302.11084) | 这篇论文介绍了一个针对对比学习的视觉-语言模型的测试时分布归一化的方法，解决了常见的点乘操作导致测试时信息丢失的问题，提高了模型在测试阶段的准确性和效率。 |
| [^122] | [PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded Dialogue.](http://arxiv.org/abs/2302.06674) | PK-ICR是一种基于角色和知识的互动上下文检索方法，可以在复杂的多场景对话中同时识别角色和知识。通过利用神经问答检索模型，该方法可以在较少的计算资源下实现检索，并且通过引入空-正向排名测试方法来提高排名性能。 |
| [^123] | [NNKGC: Improving Knowledge Graph Completion with Node Neighborhoods.](http://arxiv.org/abs/2302.06132) | NNKGC是一种通过节点邻居进行知识图谱补全并引入边连接预测任务的框架，简单而有效，可以预测出可解释的结果。 |
| [^124] | [IC3: Image Captioning by Committee Consensus.](http://arxiv.org/abs/2302.01328) | "IC3: Image Captioning by Committee Consensus"引入了一种通过委员会共识生成图像字幕的方法，能够从多个注释者的视角捕捉高层细节，优于单个人生成的参考字幕，并在视觉描述方面取得了显著改进。 |
| [^125] | [Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units.](http://arxiv.org/abs/2212.09730) | DISSC是一种新颖、轻量级的语音风格转换方法，它可以以无需文本的方式将录音的节奏、音高轮廓和音色转换为目标说话者的风格。该方法使用自监督模型编码语音为离散单元，具有简单、有效且快速的训练过程，适用于无配对数据的多对多语音转换。 |
| [^126] | [A Retrieve-and-Read Framework for Knowledge Graph Link Prediction.](http://arxiv.org/abs/2212.09724) | 这项研究提出了一种检索和阅读框架来解决现有知识图谱链接预测系统的局限性。通过首先检索相关子图上下文，然后使用高容量阅读器联合推理上下文和查询，该框架能够提供更有用的信息和更强大的表达能力。 |
| [^127] | [Large Language Models are reasoners with Self-Verification.](http://arxiv.org/abs/2212.09561) | 本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。 |
| [^128] | [Exploiting Contrastive Learning and Numerical Evidence for Improving Confusing Legal Judgment Prediction.](http://arxiv.org/abs/2211.08238) | 本文提出了一种利用对比学习和数字证据的方法改进混淆的法律判决预测。通过提出一种监督对比学习方法和利用数字证据预测处罚期限，成功地解决了区分分类错误和利用数字的问题。 |
| [^129] | [Reinforcement Learning and Bandits for Speech and Language Processing: Tutorial, Review and Outlook.](http://arxiv.org/abs/2210.13623) | 这篇综述调查了强化学习和赌博机在语音和自然语言处理中的最新进展，讨论了如何有效利用它们解决相关问题，构建适应性、交互性和可扩展性的模型。 |
| [^130] | [Can Brain Signals Reveal Inner Alignment with Human Languages?.](http://arxiv.org/abs/2208.06348) | 本研究探索了脑信号和人类语言之间的关系，并介绍了一种名为MTAM的方法，该方法在情感分析和关系检测等下游应用中取得了新的最先进结果。 |
| [^131] | [Learning to translate by learning to communicate.](http://arxiv.org/abs/2207.07025) | 本研究提出了一种利用紧急通信（EC）和预先训练的多语言模型的技术，通过基于视觉任务激励模型来改进资源匮乏语言的非监督NMT系统。实验证明，在四种语言中，其中包括了资源匮乏的尼泊尔语，我们的方法优于仅使用回译的基准模型。 |
| [^132] | [Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech.](http://arxiv.org/abs/2206.02147) | 本论文提出了Dict-TTS模型，利用在线字典作为先前信息来解决多音字消歧问题。通过设计语义到发音注意力模块，该模型能够在没有注释的情况下自动匹配文本语义和字典中的语义模式，并生成相应的发音，使得高质量的文本到语音系统能够更容易地扩展到不同领域和语言。 |
| [^133] | [Automatic WordNet Construction using Word Sense Induction through Sentence Embeddings.](http://arxiv.org/abs/2204.03251) | 本文提出了一种使用无标签语料库和基于句子嵌入的语言模型自动构建WordNet的方法。通过这种方法，我们生成了一个新的WordNet（FilWordNet），以替代并改进菲律宾语中过时的WordNet，并且不需要人工监督。 |
| [^134] | [Example-based Hypernetworks for Out-of-Distribution Generalization.](http://arxiv.org/abs/2203.14276) | 本文提出了一个基于示例的超网络框架，利用多个源领域的标记数据来进行领域外泛化。该框架通过生成输入示例的唯一签名，并将其嵌入源领域的语义空间中，并利用超网络生成任务分类器的权重。实验结果表明，该方法在29个适应场景中表现优于现有算法，且在输入示例的表示上具有丰富性。同时，与少样本GPT-3进行了比较，证明了其有效性。 |
| [^135] | [Bhasacitra: Visualising the dialect geography of South Asia.](http://arxiv.org/abs/2105.14082) | Bhasacitra是一个用于南亚的方言地理可视化系统，除了能够进行特征映射外，还可以作为南亚语言学家的互动参考书。 |

# 详细

[^1]: 实验叙事：人类众包叙事和AI叙事的比较

    Experimental Narratives: A Comparison of Human Crowdsourced Storytelling and AI Storytelling. (arXiv:2310.12902v1 [cs.CL])

    [http://arxiv.org/abs/2310.12902](http://arxiv.org/abs/2310.12902)

    本研究提出了一种框架，通过比较人类众包叙事和AI叙事，探究了文化产物和社会偏见在故事中的表现。实验结果显示，GPT-3.5和GPT-4生成的叙事更具进展性，并且普罗米修斯神话在人类和大型语言模型的想象中起到了重要作用。

    

    本论文提出了一个框架，结合行为和计算实验，利用虚构的提示作为一种新的工具，研究人类和生成式AI叙事中的文化产物和社会偏见。本研究分析了2019年6月由众包工作者创作的250个故事和2023年3月由GPT-3.5和GPT-4生成的80个故事，将叙事学和推理统计学方法相结合。众包工作者和大型语言模型都回答了关于与人工智能人类相恋的主题的相同提示。提出的实验范式使人类和LLM生成的叙事可以直接进行比较。对于提到普罗米修斯主题的回应证实了普罗米修斯神话在人类和大型语言模型的集体想象中的普遍存在。所有提供的叙事都表现出科学或技术的追求。分析表明，GPT-3.5和尤其是GPT-4生成的叙事更具进展性。

    The paper proposes a framework that combines behavioral and computational experiments employing fictional prompts as a novel tool for investigating cultural artifacts and social biases in storytelling both by humans and generative AI. The study analyzes 250 stories authored by crowdworkers in June 2019 and 80 stories generated by GPT-3.5 and GPT-4 in March 2023 by merging methods from narratology and inferential statistics. Both crowdworkers and large language models responded to identical prompts about creating and falling in love with an artificial human. The proposed experimental paradigm allows a direct comparison between human and LLM-generated storytelling. Responses to the Pygmalionesque prompts confirm the pervasive presence of the Pygmalion myth in the collective imaginary of both humans and large language models. All solicited narratives present a scientific or technological pursuit. The analysis reveals that narratives from GPT-3.5 and particularly GPT-4 are more more progre
    
[^2]: 多语言任务导向对话系统中性能差异的系统性研究

    A Systematic Study of Performance Disparities in Multilingual Task-Oriented Dialogue Systems. (arXiv:2310.12892v1 [cs.CL])

    [http://arxiv.org/abs/2310.12892](http://arxiv.org/abs/2310.12892)

    该研究系统性地研究了多语言任务导向对话系统中的性能差异，并发现了适应性和内在偏见对系统性能的影响。

    

    实现能够在世界上多种语言中表现良好的强大语言技术是多语言自然语言处理的核心目标。在这项工作中，我们对多语言任务导向对话（ToD）系统之间存在的任务性能差异进行了全面的总结和实证分析。我们首先定义了系统性能绝对和相对等价的新的量化指标，捕捉了跨语言和单个语言内的差异。通过一系列的控制性实验，我们证明了性能差异取决于多个因素：手头的ToD任务的性质，底层预训练语言模型，目标语言以及ToD注释数据的数量。我们实证地证明了当前ToD系统中存在的适应性和内在偏见：例如，使用与英语ToD数据完全平行的注释ToD数据训练的阿拉伯语或土耳其语ToD系统仍然表现出降低的ToD任务性能。除了提供一系列实证结果外，

    Achieving robust language technologies that can perform well across the world's many languages is a central goal of multilingual NLP. In this work, we take stock of and empirically analyse task performance disparities that exist between multilingual task-oriented dialogue (ToD) systems. We first define new quantitative measures of absolute and relative equivalence in system performance, capturing disparities across languages and within individual languages. Through a series of controlled experiments, we demonstrate that performance disparities depend on a number of factors: the nature of the ToD task at hand, the underlying pretrained language model, the target language, and the amount of ToD annotated data. We empirically prove the existence of the adaptation and intrinsic biases in current ToD systems: e.g., ToD systems trained for Arabic or Turkish using annotated ToD data fully parallel to English ToD data still exhibit diminished ToD task performance. Beyond providing a series of 
    
[^3]: StoryAnalogy: 从大型语言模型中衍生出故事级类比以解开类比理解

    StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding. (arXiv:2310.12874v1 [cs.CL])

    [http://arxiv.org/abs/2310.12874](http://arxiv.org/abs/2310.12874)

    本文通过构建故事级类比语料库StoryAnalogy评估了大型语言模型在识别和生成类比任务上的能力，发现这些任务对于句子嵌入模型和最近的大型语言模型来说都非常具有挑战性。同时，研究发现通过使用StoryAnalogy中的数据可以提高大型语言模型的类比生成质量。

    

    故事之间的类比是自然语言理解中最关键的能力之一。本文通过构建一个规模巨大的故事级类比语料库StoryAnalogy来评估识别和生成类比的能力，该语料库包含来自不同领域的24K个故事对，并对来自扩展结构映射理论的两个相似性进行人工注释。我们设计了一系列在StoryAnalogy上的测试，首次评估了故事级类比的识别和生成。有趣的是，我们发现类比识别任务对于句子嵌入模型以及最近的大型语言模型（如ChatGPT和LLaMa）来说都非常具有挑战性，其中ChatGPT在多选题中只能达到约30%的准确率（对于人类而言，准确率超过85%）。最后，我们发现StoryAnalogy中的数据可以提高大型语言模型的类比生成质量，其中经过微调的FlanT5-xxl模型获得了可比较的性能。

    Analogy-making between narratives is one of the most critical abilities in natural language understanding. In this paper, we evaluate the ability to identify and generate analogy by building a first-of-its-kind large-scale story-level analogy corpus, StoryAnalogy, which contains 24K story pairs from diverse domains with human annotations on two similarities from the extended Structure-Mapping Theory. We design a set of tests on StoryAnalogy, presenting the first evaluation of story-level analogy identification and generation. Interestingly, we find that the analogy identification tasks are extremely challenging not only for the sentence embedding models but also for the recent large language models (LLMs) such as ChatGPT and LLaMa, where ChatGPT only achieved around 30% accuracy in multiple-choice questions (> 85% accuracy for humans). Finally, we find that data in StoryAnalogy can improve LLMs analogy generation quality, where a fine-tuned FlanT5-xxl model yields comparable performanc
    
[^4]: 位置编码的局部性和对称性

    The Locality and Symmetry of Positional Encodings. (arXiv:2310.12864v1 [cs.CL])

    [http://arxiv.org/abs/2310.12864](http://arxiv.org/abs/2310.12864)

    本研究对位置编码中的局部性和对称性进行了系统研究，发现其核心功能和与下游任务性能之间的密切关联，同时揭示了当前位置编码的不足之处。

    

    位置编码（PE）被用于在基于Transformer的语言模型中注入单词顺序信息。虽然它们可以显著提升句子表示的质量，但它们在语言模型中的具体贡献尚未完全理解，特别是考虑到最近的研究发现各种位置编码对单词顺序不敏感。在这项工作中，我们对双向蒙版语言模型（BERT风格）中的位置编码进行了系统研究，补充了现有工作的三个方面：（1）通过确定局部性和对称性这两个常见属性，揭示出PE的核心功能；（2）展示了这两个属性与下游任务的性能密切相关；（3）通过引入两个新的探测任务，量化了当前PE的不足。我们相信这些结果是为基于Transformer的语言模型开发更好的PE的基础。代码可在 \faGITHUB 上获取。

    Positional Encodings (PEs) are used to inject word-order information into transformer-based language models. While they can significantly enhance the quality of sentence representations, their specific contribution to language models is not fully understood, especially given recent findings that various positional encodings are insensitive to word order. In this work, we conduct a systematic study of positional encodings in \textbf{Bidirectional Masked Language Models} (BERT-style) , which complements existing work in three aspects: (1) We uncover the core function of PEs by identifying two common properties, Locality and Symmetry; (2) We show that the two properties are closely correlated with the performances of downstream tasks; (3) We quantify the weakness of current PEs by introducing two new probing tasks, on which current PEs perform poorly. We believe that these results are the basis for developing better PEs for transformer-based language models. The code is available at \faGi
    
[^5]: 探究用于检测仇恨言论的LLM：优势和脆弱性

    Probing LLMs for hate speech detection: strengths and vulnerabilities. (arXiv:2310.12860v1 [cs.CL])

    [http://arxiv.org/abs/2310.12860](http://arxiv.org/abs/2310.12860)

    本研究探究了使用大型语言模型检测仇恨言论的方法，并发现在模型中包含目标信息和理由/解释可以显著提高其性能。同时，我们提供了模型分类和预测错误的错误案例的分类方法。

    

    社交媒体平台和研究人员最近做出了努力，使用大型语言模型来检测具有仇恨或有毒语言的存在。然而，这些研究并未在检测过程中利用解释、额外上下文和受害社区的信息。我们使用不同的提示变化和输入信息，在零样本设置下评估大型语言模型（不添加任何上下文示例）。我们选择了三个大型语言模型（GPT-3.5、text-davinci和Flan-T5）和三个数据集HateXplain、implicit hate和ToxicSpans。我们发现，平均而言，在管道中包含目标信息大大提高了模型性能（约20-30%）在各个数据集上相比基线。将理由/解释添加到管道中也有显著效果（约10-20%）在各个数据集上相比基线。此外，我们进一步提供了这些大型语言模型无法分类和预测错误的错误案例的分类方法。

    Recently efforts have been made by social media platforms as well as researchers to detect hateful or toxic language using large language models. However, none of these works aim to use explanation, additional context and victim community information in the detection process. We utilise different prompt variation, input information and evaluate large language models in zero shot setting (without adding any in-context examples). We select three large language models (GPT-3.5, text-davinci and Flan-T5) and three datasets HateXplain, implicit hate and ToxicSpans. We find that on average including the target information in the pipeline improves the model performance substantially (~20-30%) over the baseline across the datasets. There is also a considerable effect of adding the rationales/explanations into the pipeline (~10-20%) over the baseline across the datasets. In addition, we further provide a typology of the error cases where these large language models fail to (i) classify and (i
    
[^6]: EmoDiarize: 使用卷积神经网络从语音信号中进行说话人日程和情感识别

    EmoDiarize: Speaker Diarization and Emotion Identification from Speech Signals using Convolutional Neural Networks. (arXiv:2310.12851v1 [cs.SD])

    [http://arxiv.org/abs/2310.12851](http://arxiv.org/abs/2310.12851)

    本研究提出了一个综合的解决方案，将说话人日程和情感识别相结合，使用深度学习技术和卷积神经网络提高了精度。

    

    在先进的人工智能和人机交互时代，识别口头语言中的情感至关重要。本研究探讨了深度学习技术在语音情感识别中的应用，提供了一个综合的解决方案来应对说话人日程和情感识别所面临的挑战。它引入了一个框架，将现有的说话人日程流程和基于卷积神经网络 (CNN) 的情感识别模型相结合，以实现更高的精度。所提出的模型是在五个语音情感数据集 (RAVDESS，CREMA-D，SAVEE，TESS和电影片段) 上进行训练的，其中后者是专门为本研究创建的一个语音情感数据集。从每个样本中提取的特征包括Mel频率倒谱系数 (MFCC)，过零率 (ZCR)，均方根 (RMS) 和各种数据增强算法，如音高、噪声、拉伸和移位。

    In the era of advanced artificial intelligence and human-computer interaction, identifying emotions in spoken language is paramount. This research explores the integration of deep learning techniques in speech emotion recognition, offering a comprehensive solution to the challenges associated with speaker diarization and emotion identification. It introduces a framework that combines a pre-existing speaker diarization pipeline and an emotion identification model built on a Convolutional Neural Network (CNN) to achieve higher precision. The proposed model was trained on data from five speech emotion datasets, namely, RAVDESS, CREMA-D, SAVEE, TESS, and Movie Clips, out of which the latter is a speech emotion dataset created specifically for this research. The features extracted from each sample include Mel Frequency Cepstral Coefficients (MFCC), Zero Crossing Rate (ZCR), Root Mean Square (RMS), and various data augmentation algorithms like pitch, noise, stretch, and shift. This feature e
    
[^7]: 知识增强的语言模型验证

    Knowledge-Augmented Language Model Verification. (arXiv:2310.12836v1 [cs.CL])

    [http://arxiv.org/abs/2310.12836](http://arxiv.org/abs/2310.12836)

    提出了一种知识增强的语言模型验证方法，通过一个独立的验证器来检测模型输出和知识的错误，并通过检索新知识或修正摘要来纠正错误。

    

    最近的语言模型在生成文本方面展现出了令人瞩目的能力，因为它们具备了参数中内部化的知识。然而，由于它们的知识可能是不准确、不完整和过时的，因此语言模型往往会对给定查询生成出事实上不正确的回应。为了解决这个问题，之前的研究提出了利用从外部知识源检索到的知识来增强语言模型的方法。然而，这样的方法经常因为两个原因而显示出次优的文本生成性能：1）模型可能无法检索到与给定查询相关的知识；2）模型可能无法在生成文本中忠实地反映检索到的知识。为了克服这些问题，我们提出了利用一个单独的验证器来验证知识增强的语言模型的输出和知识，这个验证器是一个小型语言模型，通过指导微调的方式训练来检测这两种类型的错误。然后，当验证器检测到错误时，我们可以通过检索新的知识或获取更改摘要来进行修复。

    Recent Language Models (LMs) have shown impressive capabilities in generating texts with the knowledge internalized in parameters. Yet, LMs often generate the factually incorrect responses to the given queries, since their knowledge may be inaccurate, incomplete, and outdated. To address this problem, previous works propose to augment LMs with the knowledge retrieved from an external knowledge source. However, such approaches often show suboptimal text generation performance due to two reasons: 1) the model may fail to retrieve the knowledge relevant to the given query, or 2) the model may not faithfully reflect the retrieved knowledge in the generated text. To overcome these, we propose to verify the output and the knowledge of the knowledge-augmented LMs with a separate verifier, which is a small LM that is trained to detect those two types of errors through instruction-finetuning. Then, when the verifier recognizes an error, we can rectify it by either retrieving new knowledge or ge
    
[^8]: AgentTuning: 为LLMs实现通用代理能力

    AgentTuning: Enabling Generalized Agent Abilities for LLMs. (arXiv:2310.12823v1 [cs.CL])

    [http://arxiv.org/abs/2310.12823](http://arxiv.org/abs/2310.12823)

    本论文提出了AgentTuning，一种简单而通用的方法，可提升LLMs的代理能力，同时保持其通用能力。通过构建AgentInstruct数据集，并采用一种混合训练方法，作者成功地实现了提高LLMs代理能力的目标。

    

    开放的大型语言模型（LLMs）在各种任务中具有出色的性能，极大地推动了LLMs的发展。然而，当它们作为代理在现实世界中应对复杂任务时，它们远不及ChatGPT和GPT-4等商业模型。这些代理任务将LLMs作为负责规划、记忆和工具利用的中央控制器，需要细粒度的提示方法和强大的LLMs才能达到令人满意的性能。虽然已经提出了许多提示方法来完成特定的代理任务，但缺乏研究专注于提高LLMs自身的代理能力而不损害其通用能力。在这项工作中，我们提出了AgentTuning，一种简单而通用的方法，可以提升LLMs的代理能力，同时保持其通用的LLM能力。我们构建了AgentInstruct，一个轻量级的指令调整数据集，其中包含高质量的交互轨迹。

    Open large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust LLMs to achieve satisfactory performance. Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of LLMs themselves without compromising their general abilities. In this work, we present AgentTuning, a simple and general method to enhance the agent abilities of LLMs while maintaining their general LLM capabilities. We construct AgentInstruct, a lightweight instruction-tuning dataset containing high-quality interaction trajectories. We employ a hy
    
[^9]: GestureGPT: 零样本交互手势理解与基于大语言模型代理的对接

    GestureGPT: Zero-shot Interactive Gesture Understanding and Grounding with Large Language Model Agents. (arXiv:2310.12821v1 [cs.CL])

    [http://arxiv.org/abs/2310.12821](http://arxiv.org/abs/2310.12821)

    GestureGPT是一个零样本交互手势理解和对接框架，利用大语言模型代理解读手势描述并根据交互环境提供上下文信息，能够将用户意图对接到交互功能上。

    

    当前的手势识别系统主要关注识别预定义集合中的手势，未能将这些手势与交互式图形用户界面元素或系统功能相连接（例如，将“竖起大拇指”手势与“喜欢”按钮关联起来）。我们引入了GestureGPT，这是一个新颖的零样本手势理解和对接框架，利用大语言模型（LLM）。手势描述根据手势视频中的手部关键点坐标进行形式化，并输入到我们的双代理对话系统中。一个手势代理解读这些描述，并询问有关交互环境的信息（例如，界面、历史记录、凝视数据），一个上下文代理负责组织并提供这些信息。经过迭代的交流，手势代理能够理解用户意图，并将其对接到一个交互功能上。我们使用公开的第一视角和第三视角手势数据集验证了手势描述模块，并在视频流和智能家居物联网控制的两个真实场景中测试了整个系统。

    Current gesture recognition systems primarily focus on identifying gestures within a predefined set, leaving a gap in connecting these gestures to interactive GUI elements or system functions (e.g., linking a 'thumb-up' gesture to a 'like' button). We introduce GestureGPT, a novel zero-shot gesture understanding and grounding framework leveraging large language models (LLMs). Gesture descriptions are formulated based on hand landmark coordinates from gesture videos and fed into our dual-agent dialogue system. A gesture agent deciphers these descriptions and queries about the interaction context (e.g., interface, history, gaze data), which a context agent organizes and provides. Following iterative exchanges, the gesture agent discerns user intent, grounding it to an interactive function. We validated the gesture description module using public first-view and third-view gesture datasets and tested the whole system in two real-world settings: video streaming and smart home IoT control. T
    
[^10]: 提升推理效率：释放参数共享的预训练语言模型的能力

    Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models. (arXiv:2310.12818v1 [cs.CL])

    [http://arxiv.org/abs/2310.12818](http://arxiv.org/abs/2310.12818)

    本论文提出了一种提升参数共享预训练语言模型推理效率的简单技术，并介绍了一种简单的预训练方法来实现完全或部分共享的模型，实验结果证明了这些方法在各种模型上的有效性，为更有效地利用参数提供了新的见解。

    

    参数共享的预训练语言模型（PLMs）已经成为在资源有限环境中的成功方法，能够在不显著降低性能的情况下实现模型存储和内存成本的大幅降低。然而，需要注意的是，参数共享不能减轻推理过程中的计算负担，这使得在具有严格时延要求或计算资源受限的情况下，其实用性受到限制。基于神经常微分方程（ODEs），我们引入了一种简单的技术来提高参数共享的PLMs的推理效率。此外，我们提出了一种简单的预训练技术，可以实现完全或部分共享的模型，从而实现更大的推理加速。实验结果表明，我们的方法对于自回归和自编码PLMs都具有很好的效果，为更有效地利用参数提供了新的见解。

    Parameter-shared pre-trained language models (PLMs) have emerged as a successful approach in resource-constrained environments, enabling substantial reductions in model storage and memory costs without significant performance compromise. However, it is important to note that parameter sharing does not alleviate computational burdens associated with inference, thus impeding its practicality in situations characterized by limited stringent latency requirements or computational resources. Building upon neural ordinary differential equations (ODEs), we introduce a straightforward technique to enhance the inference efficiency of parameter-shared PLMs. Additionally, we propose a simple pre-training technique that leads to fully or partially shared models capable of achieving even greater inference acceleration. The experimental results demonstrate the effectiveness of our methods on both autoregressive and autoencoding PLMs, providing novel insights into more efficient utilization of paramet
    
[^11]: LLM-集成应用中的提示注入攻击和防御

    Prompt Injection Attacks and Defenses in LLM-Integrated Applications. (arXiv:2310.12815v1 [cs.CR])

    [http://arxiv.org/abs/2310.12815](http://arxiv.org/abs/2310.12815)

    本文提出了一个通用框架来形式化提示注入攻击，并系统化防御这种类型的攻击。

    

    大型语言模型（LLMs）越来越多地用作各种称为LLM-集成应用的实际应用程序的后端。最近的多项研究表明，LLM-集成应用容易受到提示注入攻击的威胁，攻击者可以将恶意指令/数据注入这些应用程序的输入中，以达到攻击者的预期结果。然而，现有的研究仅限于案例研究，缺乏对提示注入攻击及其防御的系统理解。本论文旨在填补这一空白。我们提出了一个通用框架来形式化提示注入攻击，并将研究论文和博客文章中讨论的现有攻击视为我们框架的特例。我们的框架使我们能够通过组合现有攻击设计新的攻击方式。此外，我们还提出了一个系统化提示注入攻击防御的框架。利用我们的框架，我们可以预防和缓解这种类型的攻击。

    Large Language Models (LLMs) are increasingly deployed as the backend for a variety of real-world applications called LLM-Integrated Applications. Multiple recent works showed that LLM-Integrated Applications are vulnerable to prompt injection attacks, in which an attacker injects malicious instruction/data into the input of those applications such that they produce results as the attacker desires. However, existing works are limited to case studies. As a result, the literature lacks a systematic understanding of prompt injection attacks and their defenses. We aim to bridge the gap in this work. In particular, we propose a general framework to formalize prompt injection attacks. Existing attacks, which are discussed in research papers and blog posts, are special cases in our framework. Our framework enables us to design a new attack by combining existing attacks. Moreover, we also propose a framework to systematize defenses against prompt injection attacks. Using our frameworks, we con
    
[^12]: 基于不确定性梯度匹配的模型合并

    Model Merging by Uncertainty-Based Gradient Matching. (arXiv:2310.12808v1 [cs.LG])

    [http://arxiv.org/abs/2310.12808](http://arxiv.org/abs/2310.12808)

    本论文通过不确定性梯度匹配的方法，提出了一种新的模型合并方案，该方案能够减少梯度不匹配，从而提高了模型合并的性能并对超参数更具鲁棒性。

    

    在不同数据集上训练的模型可以通过参数的加权平均来合并，但为什么会起作用，什么情况下会失败？在这里，我们将加权平均的不准确性与梯度不匹配联系起来，并提出了一种新的基于不确定性的方案，通过减少不匹配来提高性能。这种联系还揭示了其他方案（如平均值、任务算术和Fisher加权平均）中的隐含假设。我们的新方法在大型语言模型和视觉转换器方面都在性能和超参数鲁棒性方面得到了一致的改进。

    Models trained on different datasets can be merged by a weighted-averaging of their parameters, but why does it work and when can it fail? Here, we connect the inaccuracy of weighted-averaging to mismatches in the gradients and propose a new uncertainty-based scheme to improve the performance by reducing the mismatch. The connection also reveals implicit assumptions in other schemes such as averaging, task arithmetic, and Fisher-weighted averaging. Our new method gives consistent improvements for large language models and vision transformers, both in terms of performance and robustness to hyperparameters.
    
[^13]: 基于因果结构的文本离群值泛化增强方法

    Causal-structure Driven Augmentations for Text OOD Generalization. (arXiv:2310.12803v1 [cs.LG])

    [http://arxiv.org/abs/2310.12803](http://arxiv.org/abs/2310.12803)

    本文提出了一种基于因果结构的反事实数据增强方法，用于改善文本分类器在应用中的泛化效果，特别适用于存在虚假相关性的标签与属性预测问题。

    

    文本分类器对虚假相关性的依赖可能导致在实际应用中的泛化效果不佳，这引发了对其在如医疗领域等安全关键行业中使用的担忧。在本研究中，我们提出使用因果结构知识指导的反事实数据增强方法，模拟对虚假特征进行干预，以学习更加鲁棒的文本分类器。我们证明了在标签与属性之间存在虚假相关性的预测问题中，这种策略是合适的。在这种问题的假设下，我们讨论了反事实数据增强相对于重要性重加权的有利样本复杂性。实际上，我们使用辅助数据通过差分在差分的方法来匹配样本，并使用大型语言模型（LLM）来表示文本的条件概率。通过对从医学叙述中学习与看护者无关的临床诊断预测器以及半合成数据上进行了广泛的实验。

    The reliance of text classifiers on spurious correlations can lead to poor generalization at deployment, raising concerns about their use in safety-critical domains such as healthcare. In this work, we propose to use counterfactual data augmentation, guided by knowledge of the causal structure of the data, to simulate interventions on spurious features and to learn more robust text classifiers. We show that this strategy is appropriate in prediction problems where the label is spuriously correlated with an attribute. Under the assumptions of such problems, we discuss the favorable sample complexity of counterfactual data augmentation, compared to importance re-weighting. Pragmatically, we match examples using auxiliary data, based on diff-in-diff methodology, and use a large language model (LLM) to represent a conditional probability of text. Through extensive experimentation on learning caregiver-invariant predictors of clinical diagnoses from medical narratives and on semi-synthetic 
    
[^14]: MolCA: 通过跨模态投影和单模态适配器的分子图-语言建模

    MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter. (arXiv:2310.12798v1 [cs.CL])

    [http://arxiv.org/abs/2310.12798](http://arxiv.org/abs/2310.12798)

    MolCA是一个可以通过跨模态投影和单模态适配器实现分子图和语言的建模系统。它可以通过连接图编码器和语言模型的表示空间来理解文本和图形的分子内容，并通过单模态适配器在下游任务中高效适应。

    

    语言模型在各种与文本相关的任务上展示了对分子的卓越理解能力。然而，它们本质上缺乏人类专业人员在理解分子拓扑结构中的关键能力 - 2D图形感知能力。为了弥合这个差距，我们提出了MolCA: 通过跨模态投影和单模态适配器进行分子图-语言建模。MolCA通过跨模态投影使语言模型（例如Galactica）能够理解基于文本和图形的分子内容。具体而言，跨模态投影器被实现为一个Q-Former，连接一个图编码器的表示空间和一个语言模型的文本空间。此外，MolCA使用单模态适配器（即LoRA）使语言模型能够有效适应下游任务。与先前的研究通过跨模态对比学习将语言模型与图形编码器耦合不同，MolCA保留了语言模型的开放式文本生成能力，并增加了2D图形信息。为了展示其有效性，

    Language Models (LMs) have demonstrated impressive molecule understanding ability on various 1D text-related tasks. However, they inherently lack 2D graph perception - a critical ability of human professionals in comprehending molecules' topological structures. To bridge this gap, we propose MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter. MolCA enables an LM (e.g., Galactica) to understand both text- and graph-based molecular contents via the cross-modal projector. Specifically, the cross-modal projector is implemented as a Q-Former to connect a graph encoder's representation space and an LM's text space. Further, MolCA employs a uni-modal adapter (i.e., LoRA) for the LM's efficient adaptation to downstream tasks. Unlike previous studies that couple an LM with a graph encoder via cross-modal contrastive learning, MolCA retains the LM's ability of open-ended text generation and augments it with 2D graph information. To showcase its effectivenes
    
[^15]: 结构概念在Transformer语言模型中是否具有普适性？走向可解释的跨语言泛化

    Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization. (arXiv:2310.12794v1 [cs.CL])

    [http://arxiv.org/abs/2310.12794](http://arxiv.org/abs/2310.12794)

    本文研究了在Transformer语言模型中明确对齐语言之间的概念对应关系的潜力，以强化跨语言泛化能力。研究发现，无论是仅有编码器还是仅有解码器的模型，各语言内的结构概念空间对齐度高。通过基于元学习的方法，可以学习对齐不同语言的概念空间，实现零样本和少样本泛化。

    

    大型语言模型(LLMs)展示了显著的跨语言泛化能力，即它们通过隐式知识传输在不同语言之间进行转移。然而，这种转移对于所有语言而言并不均衡，特别是对于资源匮乏的语言，这是一个持续存在的挑战。目前尚不清楚我们是否已经达到了隐式跨语言泛化的极限，并且明确的知识传输是否可行。在本文中，我们调查了明确对齐语言之间概念对应关系的潜力，以增强跨语言泛化能力。通过将语法方面作为测试平台，我们对43种语言的分析显示，无论是仅有编码器还是仅有解码器的LLMs，各种语言内的结构概念空间之间存在高度的对准性。然后，我们提出了一种基于元学习的方法来学习对齐不同语言的概念空间，从而便于在概念分类和对齐上进行零样本和少样本泛化。

    Large language models (LLMs) have exhibited considerable cross-lingual generalization abilities, whereby they implicitly transfer knowledge across languages. However, the transfer is not equally successful for all languages, especially for low-resource ones, which poses an ongoing challenge. It is unclear whether we have reached the limits of implicit cross-lingual generalization and if explicit knowledge transfer is viable. In this paper, we investigate the potential for explicitly aligning conceptual correspondence between languages to enhance cross-lingual generalization. Using the syntactic aspect of language as a testbed, our analyses of 43 languages reveal a high degree of alignability among the spaces of structural concepts within each language for both encoder-only and decoder-only LLMs. We then propose a meta-learning-based method to learn to align conceptual spaces of different languages, which facilitates zero-shot and few-shot generalization in concept classification and al
    
[^16]: 使用标签感知的自动语言表达方式提供少样本文本分类

    Label-Aware Automatic Verbalizer for Few-Shot Text Classification. (arXiv:2310.12778v1 [cs.CL])

    [http://arxiv.org/abs/2310.12778](http://arxiv.org/abs/2310.12778)

    这篇论文提出了一种标签感知的自动语言表达方式（LAAV），通过增加手动标签和连接词“和”来提升语言模型的生成，从而在少样本分类任务中取得更好的结果。

    

    基于提示的学习在少样本文本分类中显示出有效性。其成功的一个重要因素是一种语言表达方式，将语言模型的输出转化为预测类别。值得注意的是，最简单和广泛认可的语言表达方式使用手动标签来表示类别。然而，手动选择并不能保证在选择的语言模型的条件下所选择的单词的最优性。因此，我们提出了一种标签感知的自动语言表达方式（LAAV），通过有效增加手动标签来实现更好的少样本分类结果。具体而言，我们使用手动标签以及连接词“和”来诱导模型生成更有效的语言表达方式中的单词。在五个数据集跨五种语言上的实验结果表明，LAAV明显优于现有的语言表达方式。此外，我们的分析还发现，与类似方法相比，LAAV提供更相关的单词，特别是在中到

    Prompt-based learning has shown its effectiveness in few-shot text classification. One important factor in its success is a verbalizer, which translates output from a language model into a predicted class. Notably, the simplest and widely acknowledged verbalizer employs manual labels to represent the classes. However, manual selection does not guarantee the optimality of the selected words when conditioned on the chosen language model. Therefore, we propose Label-Aware Automatic Verbalizer (LAAV), effectively augmenting the manual labels to achieve better few-shot classification results. Specifically, we use the manual labels along with the conjunction "and" to induce the model to generate more effective words for the verbalizer. The experimental results on five datasets across five languages demonstrate that LAAV significantly outperforms existing verbalizers. Furthermore, our analysis reveals that LAAV suggests more relevant words compared to similar approaches, especially in mid-to-
    
[^17]: 存活最有影响力的提示：通过聚类和修剪实现高效的黑盒提示搜索

    Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning. (arXiv:2310.12774v1 [cs.CL])

    [http://arxiv.org/abs/2310.12774](http://arxiv.org/abs/2310.12774)

    本文提出了一种名为ClaPS的简单黑盒搜索方法，通过聚类和修剪搜索空间中最有影响力的提示令牌，解决了现代黑盒方法中的效率问题。

    

    基于提示的学习已经成为大型预训练语言模型（LLM）的有效范例，使得少样本甚至零样本学习成为可能。最近，黑盒提示搜索因其梯度-free优化的独特特性而受到越来越多的关注，被证明在模型即服务的使用中特别有用和强大。然而，组合优化的离散本质和复杂性阻碍了现代黑盒方法的效率。尽管在搜索算法上进行了广泛研究，但搜索空间设计和优化的关键方面却被大部分忽视了。在本文中，我们首先通过提示LLM进行敏感性分析，揭示只有少量的令牌对LLM预测产生了不成比例的影响。利用这一洞见，我们提出了一种名为Clustering and Pruning for Efficient Black-box Prompt Search（ClaPS）的简单黑盒搜索方法，该方法首先对搜索空间进行聚类和修剪，只关注最具影响力的提示令牌。

    Prompt-based learning has been an effective paradigm for large pretrained language models (LLM), enabling few-shot or even zero-shot learning. Black-box prompt search has received growing interest recently for its distinctive properties of gradient-free optimization, proven particularly useful and powerful for model-as-a-service usage. However, the discrete nature and the complexity of combinatorial optimization hinder the efficiency of modern black-box approaches. Despite extensive research on search algorithms, the crucial aspect of search space design and optimization has been largely overlooked. In this paper, we first conduct a sensitivity analysis by prompting LLM, revealing that only a small number of tokens exert a disproportionate amount of influence on LLM predictions. Leveraging this insight, we propose the Clustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple black-box search method that first clusters and prunes the search space to focus exclusivel
    
[^18]: 基于Transformer的实体法律形式分类

    Transformer-based Entity Legal Form Classification. (arXiv:2310.12766v1 [cs.CL])

    [http://arxiv.org/abs/2310.12766](http://arxiv.org/abs/2310.12766)

    提出了一种使用Transformer-based语言模型进行实体法律形式分类的方法，该方法在比较中表现出较高的性能并得到了第三方评审的支持。

    

    我们提出了使用基于Transformer的语言模型来对原始法律实体名称进行实体法律形式分类的方法。具体而言，我们采用了各种BERT变种，并将它们的性能与多个传统基准进行比较。我们的评估涵盖了一个庞大的自由可用的法律实体标识符（LEI）数据子集，包括来自30个不同法律司法辖区的超过110万个法律实体。每个司法辖区的分类的真实标签来自实体法律形式（ELF）代码标准（ISO 20275）。我们的研究结果表明，预训练的BERT变种在F1分数方面优于传统的文本分类方法，在Macro F1分数方面表现相当好。此外，我们的提案得到了在十个选择的司法辖区进行的第三方专家评审的支持。本研究凸显了基于Transformer模型在推进数据标准化方面的重要潜力。

    We propose the application of Transformer-based language models for classifying entity legal forms from raw legal entity names. Specifically, we employ various BERT variants and compare their performance against multiple traditional baselines. Our evaluation encompasses a substantial subset of freely available Legal Entity Identifier (LEI) data, comprising over 1.1 million legal entities from 30 different legal jurisdictions. The ground truth labels for classification per jurisdiction are taken from the Entity Legal Form (ELF) code standard (ISO 20275). Our findings demonstrate that pre-trained BERT variants outperform traditional text classification approaches in terms of F1 score, while also performing comparably well in the Macro F1 Score. Moreover, the validity of our proposal is supported by the outcome of third-party expert reviews conducted in ten selected jurisdictions. This study highlights the significant potential of Transformer-based models in advancing data standardization
    
[^19]: 字符级中文背包语言模型

    Character-level Chinese Backpack Language Models. (arXiv:2310.12751v1 [cs.CL])

    [http://arxiv.org/abs/2310.12751](http://arxiv.org/abs/2310.12751)

    通过对中文进行字符标记化，我们训练了一个比Transformer更具解释性的中文背包语言模型，该模型学习到了丰富的字符级别含义，其组合形成词义，并且在词汇语义评估中胜过Transformer的输入嵌入。

    

    背包是一种Transformer的替代方法，通过将预测分解为令牌意义组件的加权和来提高英语语言模型的可解释性。然而，背包对于除英语以外的其他语言，特别是对于词项的子词标记化提供合理近似的语言而言，它们对令牌定义的含义的依赖性引发了一些问题。在这项工作中，我们训练、评估、解释和控制字符标记化的中文背包语言模型，其中词通常由多个字符组成。我们发现，我们的（134M参数）中文背包语言模型与（104M参数）Transformer相比表现相当，并学习到了丰富的字符级别含义，这些含义以对数加法组合成词义。在类似SimLex的词汇语义评估中，背包字符意义的简单平均值胜过Transformer的输入嵌入。我们发现，复杂的多字符含义通常是通过使用...

    The Backpack is a Transformer alternative shown to improve interpretability in English language modeling by decomposing predictions into a weighted sum of token sense components. However, Backpacks' reliance on token-defined meaning raises questions as to their potential for languages other than English, a language for which subword tokenization provides a reasonable approximation for lexical items. In this work, we train, evaluate, interpret, and control Backpack language models in character-tokenized Chinese, in which words are often composed of many characters. We find that our (134M parameter) Chinese Backpack language model performs comparably to a (104M parameter) Transformer, and learns rich character-level meanings that log-additively compose to form word meanings. In SimLex-style lexical semantic evaluations, simple averages of Backpack character senses outperform input embeddings from a Transformer. We find that complex multi-character meanings are often formed by using the s
    
[^20]: 在音韵重构中表示和计算不确定性

    Representing and Computing Uncertainty in Phonological Reconstruction. (arXiv:2310.12727v1 [cs.CL])

    [http://arxiv.org/abs/2310.12727](http://arxiv.org/abs/2310.12727)

    该论文提出了一个新的框架，用于在语言重构中表示和计算不确定性，通过借鉴监督音韵重构和自动预测方法，实现了模糊重构的工作流程。

    

    尽管历史语言学中的重构本质上是模糊的，大多数学者在提出原型形式时并不表示不确定性。随着自动化传统比较方法某些方面的最近提出的方法的成功，原型形式的形式化也得到了改善。这种形式化使得可以同时处理表示和计算不确定性。基于监督音韵重构的最新进展，其中算法通过先前注释的数据学习如何重构给定原始语言中的单词，并受到来自同源词集自动预测的改进方法的启发，我们提出了一个新的框架，可以在语言重构中表示不确定性，并包括从语言数据计算模糊重构的工作流程。

    Despite the inherently fuzzy nature of reconstructions in historical linguistics, most scholars do not represent their uncertainty when proposing proto-forms. With the increasing success of recently proposed approaches to automating certain aspects of the traditional comparative method, the formal representation of proto-forms has also improved. This formalization makes it possible to address both the representation and the computation of uncertainty. Building on recent advances in supervised phonological reconstruction, during which an algorithm learns how to reconstruct words in a given proto-language relying on previously annotated data, and inspired by improved methods for automated word prediction from cognate sets, we present a new framework that allows for the representation of uncertainty in linguistic reconstruction and also includes a workflow for the computation of fuzzy reconstructions from linguistic data.
    
[^21]: ChatGPT是金融专家吗？对金融自然语言处理中的语言模型进行评估

    Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing. (arXiv:2310.12664v1 [cs.CL])

    [http://arxiv.org/abs/2310.12664](http://arxiv.org/abs/2310.12664)

    本研究通过对金融自然语言处理中的语言模型进行评估，发现虽然一些解码器语言模型通过零样本提示在大多数金融任务中表现出了显着性能，但它们总体上落后于经过精细调整的专业模型，特别是在处理专有数据集时。

    

    大规模语言模型（LLM）的出现，如ChatGPT，已经彻底改变了一般自然语言处理（NLP）任务。然而，它们在金融领域的专长缺乏全面评估。为了评估LLMs解决金融NLP任务的能力，我们提出了FinLMEval，一个金融语言模型评估框架，包括九个设计用于评估语言模型性能的数据集。本研究比较了仅编码器和仅解码器语言模型的性能。我们的研究结果表明，尽管一些仅解码器的LLMs通过零样本提示在大多数金融任务中表现出了显着的性能，但它们总体上落后于经过精细调整的专业模型，特别是在处理专有数据集时。我们希望这项研究为继续努力构建更先进的金融领域LLMs提供基础评估。

    The emergence of Large Language Models (LLMs), such as ChatGPT, has revolutionized general natural language preprocessing (NLP) tasks. However, their expertise in the financial domain lacks a comprehensive evaluation. To assess the ability of LLMs to solve financial NLP tasks, we present FinLMEval, a framework for Financial Language Model Evaluation, comprising nine datasets designed to evaluate the performance of language models. This study compares the performance of encoder-only language models and the decoder-only language models. Our findings reveal that while some decoder-only LLMs demonstrate notable performance across most financial tasks via zero-shot prompting, they generally lag behind the fine-tuned expert models, especially when dealing with proprietary datasets. We hope this study provides foundation evaluations for continuing efforts to build more advanced LLMs in the financial domain.
    
[^22]: 面向现实世界的混合语音流式翻译的研究

    Towards Real-World Streaming Speech Translation for Code-Switched Speech. (arXiv:2310.12648v1 [cs.CL])

    [http://arxiv.org/abs/2310.12648](http://arxiv.org/abs/2310.12648)

    本文针对面向真实世界的混合语音流式翻译进行了研究，主要关注了流式设置和翻译到第三种语言的问题，并提出了一种基线模型进行了实验。

    

    混合语言（CS）即在一句话中混合使用不同语言，是通信中常见的现象，在许多自然语言处理（NLP）环境下可能具有挑战性。先前关于CS语音的研究在端到端语音翻译（ST）方面取得了有希望的结果，但仅限于离线场景，并且仅能翻译成源语中的一种语言（单语转录）。本文着重研究了两个尚未探索的面向现实世界的CS语音翻译领域：流式设置和翻译到第三种语言（即源语中未包含的语言）。为此，我们扩展了Fisher和Miami测试和验证数据集，包含了西班牙语和德语作为新的目标语言。利用这些数据，我们对离线和流式ST模型进行训练，并建立了之前提到的两个设置的基线结果。

    Code-switching (CS), i.e. mixing different languages in a single sentence, is a common phenomenon in communication and can be challenging in many Natural Language Processing (NLP) settings. Previous studies on CS speech have shown promising results for end-to-end speech translation (ST), but have been limited to offline scenarios and to translation to one of the languages present in the source (\textit{monolingual transcription}).  In this paper, we focus on two essential yet unexplored areas for real-world CS speech translation: streaming settings, and translation to a third language (i.e., a language not included in the source). To this end, we extend the Fisher and Miami test and validation datasets to include new targets in Spanish and German. Using this data, we train a model for both offline and streaming ST and we establish baseline results for the two settings mentioned earlier.
    
[^23]: 非自回归句子排序

    Non-Autoregressive Sentence Ordering. (arXiv:2310.12640v1 [cs.CL])

    [http://arxiv.org/abs/2310.12640](http://arxiv.org/abs/2310.12640)

    这篇论文提出了一种非自回归的句子排序方法，通过探索句子之间的双向依赖关系，并并行预测每个位置的句子，以解决现有方法在排序任务中只能利用单向依赖关系的限制。

    

    现有的句子排序方法通常采用编码器-解码器框架与指针网络，通过逐步预测每个句子来恢复连贯性。这种自回归方式只能在解码过程中利用单向依赖关系，无法充分探索句子之间的语义依赖关系进行排序。为了克服这些限制，本文提出了一种新颖的非自回归排序网络，名为NAON，它探索了句子之间的双向依赖关系，并并行预测每个位置的句子。我们认为非自回归方式不仅适用于句子排序任务，而且特别适用，原因有两个：1）每个生成目标具有确定化的长度，2）句子和位置应该完全匹配。此外，为了解决朴素的非自回归Transformer的重复问题，我们引入了一种排他性的损失函数。

    Existing sentence ordering approaches generally employ encoder-decoder frameworks with the pointer net to recover the coherence by recurrently predicting each sentence step-by-step. Such an autoregressive manner only leverages unilateral dependencies during decoding and cannot fully explore the semantic dependency between sentences for ordering. To overcome these limitations, in this paper, we propose a novel Non-Autoregressive Ordering Network, dubbed \textit{NAON}, which explores bilateral dependencies between sentences and predicts the sentence for each position in parallel. We claim that the non-autoregressive manner is not just applicable but also particularly suitable to the sentence ordering task because of two peculiar characteristics of the task: 1) each generation target is in deterministic length, and 2) the sentences and positions should match exclusively. Furthermore, to address the repetition issue of the naive non-autoregressive Transformer, we introduce an exclusive los
    
[^24]: 预测未来是过去的延续？关于金融情绪分类中的时间数据分布转移问题

    Predict the Future from the Past? On the Temporal Data Distribution Shift in Financial Sentiment Classifications. (arXiv:2310.12620v1 [cs.CL])

    [http://arxiv.org/abs/2310.12620](http://arxiv.org/abs/2310.12620)

    本文针对金融情绪分类中存在的时间数据分布转移问题，通过对真实金融社交媒体数据集进行实证研究，发现经过微调的模型在时间分布转移的情况下性能下降。针对金融文本的独特时间特性，提出了一种结合离群点检测和时间序列建模的新方法，可以增强模型在波动性金融市场中适应时间分布转移的能力。

    

    金融文本中存在着时间数据分布转移的问题。在波动性市场环境下，如何训练一个能够准确推断情绪并对时间数据分布转移具有鲁棒性的金融情绪分析系统？本文利用跨越三年的真实金融社交媒体数据集对金融情绪分析系统在时间数据分布转移下进行了实证研究。我们发现，经过微调的模型在时间分布转移的情况下会出现性能下降。此外，受金融文本的独特时间特性的启发，我们提出了一种结合了离群点检测和时间序列建模的新方法，用于进行金融情绪分析。实验结果表明，所提出的方法增强了模型在波动性金融市场中适应不断变化的时间分布转移的能力。

    Temporal data distribution shift is prevalent in the financial text. How can a financial sentiment analysis system be trained in a volatile market environment that can accurately infer sentiment and be robust to temporal data distribution shifts? In this paper, we conduct an empirical study on the financial sentiment analysis system under temporal data distribution shifts using a real-world financial social media dataset that spans three years. We find that the fine-tuned models suffer from general performance degradation in the presence of temporal distribution shifts. Furthermore, motivated by the unique temporal nature of the financial text, we propose a novel method that combines out-of-distribution detection with time series modeling for temporal financial sentiment analysis. Experimental results show that the proposed method enhances the model's capability to adapt to evolving temporal shifts in a volatile financial market.
    
[^25]: 识别和调整英文语言模型中负责性别偏见的Transformer组件

    Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model. (arXiv:2310.12611v1 [cs.CL])

    [http://arxiv.org/abs/2310.12611](http://arxiv.org/abs/2310.12611)

    本研究通过三种方法识别英文语言模型中负责性别偏见的Transformer组件，然后使用这些组件进行参数高效的偏见缓解微调，取得了成功的性别偏见缓解效果并减少了对一般语言建模的损害。

    

    语言模型（LMs）展现和放大了许多种不希望从训练数据中学到的偏见，包括性别偏见。然而，我们缺乏有效和高效地改变这种行为而不损害一般语言建模性能的工具。在本文中，我们研究了三种方法来识别LM组件与特定输出之间的因果关系：因果中介分析、自动电路发现和我们的新颖高效的方法DiffMask+，基于差异掩模。我们将这些方法应用于GPT-2 small和性别偏见问题，并使用发现的组件集进行参数高效的偏见缓解微调。我们的结果表明，尽管这些方法的计算要求存在巨大差异，但识别出的组件在很大程度上重叠，并且成功减轻了性别偏见，相比于完整模型微调对一般语言建模的损害较小。然而，我们的工作也强调了一些困难。

    Language models (LMs) exhibit and amplify many types of undesirable biases learned from the training data, including gender bias. However, we lack tools for effectively and efficiently changing this behavior without hurting general language modeling performance. In this paper, we study three methods for identifying causal relations between LM components and particular output: causal mediation analysis, automated circuit discovery and our novel, efficient method called DiffMask+ based on differential masking. We apply the methods to GPT-2 small and the problem of gender bias, and use the discovered sets of components to perform parameter-efficient fine-tuning for bias mitigation. Our results show significant overlap in the identified components (despite huge differences in the computational requirements of the methods) as well as success in mitigating gender bias, with less damage to general language modeling compared to full model fine-tuning. However, our work also underscores the dif
    
[^26]: 时态敏感问题回答的时态感知表示学习

    Time-Aware Representation Learning for Time-Sensitive Question Answering. (arXiv:2310.12585v1 [cs.CL])

    [http://arxiv.org/abs/2310.12585](http://arxiv.org/abs/2310.12585)

    该论文提出了一种时态感知的问题回答框架，通过引入时间上下文的区间抽取任务和相应的数据生成框架来训练模型，提高了QA模型的时间感知能力，在TimeQA数据集中的F1分数上超过了基准模型达8.5。

    

    时间是现实世界中问题回答的关键因素之一，然而语言模型很难理解时间限定词如“之后”和“之前”与数字之间的关系，因为现有的问题回答数据集中没有足够的时间表达。为了解决这个问题，我们提出了一种时间上下文感知的问题回答框架。我们提出了一种基于时间上下文的区间抽取任务，并构建了一个依赖于时间上下文的数据生成框架用于模型训练。此外，我们提出了一个评估QA模型的时间感知度的度量方法。区间抽取任务包括一个问题和四个句子候选项，根据时间和上下文分类为正确或错误。模型被训练为从在时间和上下文上都正确的句子中提取答案区间。通过使用TCQA训练的模型在TimeQA数据集上的F1分数上优于基准模型达8.5。我们的数据集和代码可在以下链接中获得。

    Time is one of the crucial factors in real-world question answering (QA) problems. However, language models have difficulty understanding the relationships between time specifiers, such as 'after' and 'before', and numbers, since existing QA datasets do not include sufficient time expressions. To address this issue, we propose a Time-Context aware Question Answering (TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE) task, and build a time-context dependent data generation framework for model training. Moreover, we present a metric to evaluate the time awareness of the QA model using TCSE. The TCSE task consists of a question and four sentence candidates classified as correct or incorrect based on time and context. The model is trained to extract the answer span from the sentence that is both correct in time and context. The model trained with TCQA outperforms baseline models up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code are available at
    
[^27]: 使用文本属性异构图进行语言模型的预训练

    Pretraining Language Models with Text-Attributed Heterogeneous Graphs. (arXiv:2310.12580v1 [cs.CL])

    [http://arxiv.org/abs/2310.12580](http://arxiv.org/abs/2310.12580)

    本文提出了一个新的语言模型预训练框架，能够明确考虑到文本属性异构图中的拓扑和异构信息。通过优化语言模型和辅助的异构图神经网络，预测了文本属性异构图中的节点。同时，还设计了一个文本丰富性加权的节点抽样策略，以更好地利用文本信息。

    

    在许多实际场景中（如学术网络、社交平台），不同类型的实体不仅与文本相关，还通过各种关系相连，这可以被抽象为文本属性异构图（Text-Attributed Heterogeneous Graphs，TAHGs）。

    In many real-world scenarios (e.g., academic networks, social platforms), different types of entities are not only associated with texts but also connected by various relationships, which can be abstracted as Text-Attributed Heterogeneous Graphs (TAHGs). Current pretraining tasks for Language Models (LMs) primarily focus on separately learning the textual information of each entity and overlook the crucial aspect of capturing topological connections among entities in TAHGs. In this paper, we present a new pretraining framework for LMs that explicitly considers the topological and heterogeneous information in TAHGs. Firstly, we define a context graph as neighborhoods of a target node within specific orders and propose a topology-aware pretraining task to predict nodes involved in the context graph by jointly optimizing an LM and an auxiliary heterogeneous graph neural network. Secondly, based on the observation that some nodes are text-rich while others have little text, we devise a tex
    
[^28]: 多语言政党定位的估计：从标签聚合到长文本输入Transformer

    Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers. (arXiv:2310.12575v1 [cs.CL])

    [http://arxiv.org/abs/2310.12575](http://arxiv.org/abs/2310.12575)

    该论文提出了两种方法来自动分析政党宣言的缩放值：标签聚合和基于长文本输入Transformer的模型。他们在比较宣言项目数据集上进行了分析，结果表明它们是有效的并且可以在多语言环境下工作。

    

    缩放分析是计算机政治学中的一种技术，它根据预定义的规模为政治行为者（例如政治家或政党）分配一个分数，该分数基于（通常是长的）文本体（例如议会演讲或选举宣言）。例如，政治科学家经常使用左右刻度来系统分析不同国家的政治景观。自动缩放分析的NLP方法可以找到广泛的应用，前提是它们能够处理长文本，并且在不同领域和语言中工作稳健。在这项工作中，我们实施并比较了两种自动缩放分析政党宣言的方法：标签聚合，一种依赖于宣言中个别陈述的注释的管道策略，以及基于长文本输入Transformer的模型，该模型直接从原始文本计算缩放值。我们对41个国家和27种语言的比较宣言项目数据集进行了分析。

    Scaling analysis is a technique in computational political science that assigns a political actor (e.g. politician or party) a score on a predefined scale based on a (typically long) body of text (e.g. a parliamentary speech or an election manifesto). For example, political scientists have often used the left--right scale to systematically analyse political landscapes of different countries. NLP methods for automatic scaling analysis can find broad application provided they (i) are able to deal with long texts and (ii) work robustly across domains and languages. In this work, we implement and compare two approaches to automatic scaling analysis of political-party manifestos: label aggregation, a pipeline strategy relying on annotations of individual statements from the manifestos, and long-input-Transformer-based models, which compute scaling values directly from raw text. We carry out the analysis of the Comparative Manifestos Project dataset across 41 countries and 27 languages and f
    
[^29]: 大语言模型帮助人类验证真实性——除非它们令人信服地错误。

    Large Language Models Help Humans Verify Truthfulness -- Except When They Are Convincingly Wrong. (arXiv:2310.12558v1 [cs.CL])

    [http://arxiv.org/abs/2310.12558](http://arxiv.org/abs/2310.12558)

    本研究比较了语言模型与搜索引擎在帮助用户事实核查方面的效果。结果显示，用户阅读语言模型的解释比使用搜索引擎更高效，但当解释错误时，用户容易过度依赖语言模型。为了减少过度依赖，研究提出了使用对比信息进行解释的方法。

    

    大语言模型（LLMs）越来越多地被用于获取网络上的信息。因此，它们的真实性和事实性备受关注。为了帮助用户做出正确的信息决策，LLMs不仅应提供信息，还应帮助用户事实核查。本文通过与80名众包工作者进行实验，比较了语言模型与搜索引擎（信息检索系统）在帮助人类用户事实核查方面的效果。我们引导LLMs验证给定的声明并提供相应的解释。与使用准确率相似的搜索引擎相比，阅读LLM的解释的用户效率显著提高。然而，当解释错误时，他们往往过度依赖LLMs。为了减少对LLMs的过度依赖，我们要求LLMs提供对比信息，解释为什么声明为真和为假，并将两方面的解释呈现给用户。这种对比解释减轻了用户的过度依赖。

    Large Language Models (LLMs) are increasingly used for accessing information on the web. Their truthfulness and factuality are thus of great interest. To help users make the right decisions about the information they're getting, LLMs should not only provide but also help users fact-check information. In this paper, we conduct experiments with 80 crowdworkers in total to compare language models with search engines (information retrieval systems) at facilitating fact-checking by human users. We prompt LLMs to validate a given claim and provide corresponding explanations. Users reading LLM explanations are significantly more efficient than using search engines with similar accuracy. However, they tend to over-rely the LLMs when the explanation is wrong. To reduce over-reliance on LLMs, we ask LLMs to provide contrastive information explain both why the claim is true and false, and then we present both sides of the explanation to users. This contrastive explanation mitigates users' over-
    
[^30]: DepWiGNN：一种用于多跳空间推理的深度图神经网络

    DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text. (arXiv:2310.12557v1 [cs.CL])

    [http://arxiv.org/abs/2310.12557](http://arxiv.org/abs/2310.12557)

    DepWiGNN是一种用于多跳空间推理的深度图神经网络。它通过设计新颖的节点记忆方案，并在图的深度维度上聚合信息，从而能够收集长时间的依赖关系，而无需堆叠多个层次。实验结果表明，DepWiGNN在两个挑战数据集上比传统GNN方法具有更高的准确性。

    

    文本中的空间推理在各种实际应用中起着至关重要的作用。现有的空间推理方法通常从纯文本中推断空间关系，忽视了自然语言与符号结构之间的差距。图神经网络（GNN）在引导和聚合符号结构方面表现出了卓越的能力。然而，传统的GNN在处理多跳空间推理时面临着挑战，由于过度平滑的问题，即随着图层数量的增加，性能显著下降。为了应对这些挑战，我们提出了一种新颖的Depth-Wise Graph Neural Network（DepWiGNN）。具体地，我们设计了一种新颖的节点记忆方案，并在图的深度维度上聚合信息，而不是在广度维度上，这样可以收集长时间的依赖关系，而无需堆叠多个层次。实验结果表明，在两个挑战数据集上，DepWiGNN可以以比传统GNN方法更高的准确性进行多跳空间推理。

    Spatial reasoning in text plays a crucial role in various real-world applications. Existing approaches for spatial reasoning typically infer spatial relations from pure text, which overlook the gap between natural language and symbolic structures. Graph neural networks (GNNs) have showcased exceptional proficiency in inducing and aggregating symbolic structures. However, classical GNNs face challenges in handling multi-hop spatial reasoning due to the over-smoothing issue, \textit{i.e.}, the performance decreases substantially as the number of graph layers increases. To cope with these challenges, we propose a novel \textbf{Dep}th-\textbf{Wi}se \textbf{G}raph \textbf{N}eural \textbf{N}etwork (\textbf{DepWiGNN}). Specifically, we design a novel node memory scheme and aggregate the information over the depth dimension instead of the breadth dimension of the graph, which empowers the ability to collect long dependencies without stacking multiple layers. Experimental results on two challen
    
[^31]: 大型语言模型用于多目标进化优化

    Large Language Model for Multi-objective Evolutionary Optimization. (arXiv:2310.12541v1 [cs.NE])

    [http://arxiv.org/abs/2310.12541](http://arxiv.org/abs/2310.12541)

    本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。

    

    多目标进化算法（MOEAs）是解决多目标优化问题（MOPs）的主要方法。在过去几十年中，提出了许多MOEAs，其操作符需要通过领域知识进行精心设计。最近，一些尝试将MOEAs中手动设计的操作符替换为基于学习的操作符（如神经网络模型）已经取得了一些进展。然而，设计和训练这样的模型仍然需要大量的工作，并且学习到的操作符可能不能很好地推广到解决新问题。为了解决上述挑战，本文研究了一种利用强大的大型语言模型（LLM）来设计MOEA操作符的新方法。通过适当的提示工程，我们成功地让一个通用的LLM以零-shot的方式作为分解型MOEA（MOEA/D）的黑盒搜索操作符。此外，通过从LLM行为中学习，我们进一步设计了一个显性的白盒操作符，并提出了...

    Multiobjective evolutionary algorithms (MOEAs) are major methods for solving multiobjective optimization problems (MOPs). Many MOEAs have been proposed in the past decades, of which the operators need carefully handcrafted design with domain knowledge. Recently, some attempts have been made to replace the manually designed operators in MOEAs with learning-based operators (e.g., neural network models). However, much effort is still required for designing and training such models, and the learned operators might not generalize well to solve new problems. To tackle the above challenges, this work investigates a novel approach that leverages the powerful large language model (LLM) to design MOEA operators. With proper prompt engineering, we successfully let a general LLM serve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a zero-shot manner. In addition, by learning from the LLM behavior, we further design an explicit white-box operator with randomness and propose
    
[^32]: 使用大型语言模型进行产品属性值提取

    Product Attribute Value Extraction using Large Language Models. (arXiv:2310.12537v1 [cs.CL])

    [http://arxiv.org/abs/2310.12537](http://arxiv.org/abs/2310.12537)

    本文研究使用大型语言模型作为预训练的替代方法，解决了传统属性/值提取技术中需要大量训练数据和对未知属性值的挑战问题。

    

    电子商务应用（如面向属性的产品搜索或产品比较）基于结构化的产品描述，如属性/值对。电子商务平台上的供应商不提供结构化的产品描述，而是使用标题或描述来描述产品。为了处理这样的产品，有必要从文本产品属性中提取属性/值对。现有技术中，属性/值提取方法依赖于预训练的语言模型（如BERT）。这些模型在属性/值提取方面存在两个主要缺点：（一）模型需要大量的与任务相关的训练数据；（二）优化后的模型在推广到训练数据中未包含的属性值方面面临挑战。本文探讨了大型语言模型（LLMs）作为训练数据效率高且鲁棒性强的替代方法在属性/值提取中的潜力。我们考虑了托管的LLMs，如GPT-3.5和GPT-4。

    E-commerce applications such as faceted product search or product comparison are based on structured product descriptions like attribute/value pairs. The vendors on e-commerce platforms do not provide structured product descriptions but describe offers using titles or descriptions. To process such offers, it is necessary to extract attribute/value pairs from textual product attributes. State-of-the-art attribute/value extraction techniques rely on pre-trained language models (PLMs), such as BERT. Two major drawbacks of these models for attribute/value extraction are that (i) the models require significant amounts of task-specific training data and (ii) the fine-tuned models face challenges in generalizing to attribute values not included in the training data. This paper explores the potential of large language models (LLMs) as a training data-efficient and robust alternative to PLM-based attribute/value extraction methods. We consider hosted LLMs, such as GPT-3.5 and GPT-4, as well as 
    
[^33]: ICU：通过将任务划分为图像字幕和语言理解来克服视觉与语言建模中的语言障碍

    ICU: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding. (arXiv:2310.12531v1 [cs.CL])

    [http://arxiv.org/abs/2310.12531](http://arxiv.org/abs/2310.12531)

    ICU提出了一种解决视觉与语言建模中语言障碍的方法，通过将任务划分为图像字幕和语言理解两个阶段，将多语言处理负担转移到多语言语言模型上。实验结果显示，ICU在多个语言上取得了最先进的结果。

    

    多语言视觉与语言(V&L)研究旨在在一个模型中实现多语言和多模态的能力。然而，图像的多语言字幕稀缺一直以来一直阻碍了该领域的发展。为了克服这个障碍，我们提出了ICU（Image Caption Understanding），将V&L任务分为两个阶段：一个V&L模型以英文进行图像字幕生成，然后一个多语言语言模型（mLM）以字幕作为替代文本进行跨语言语言理解。这种方式减轻了V&L模型的多语言处理负担，将其转移到了mLM上。由于多语言文本数据相对丰富和质量较高，ICU可以帮助克服V&L模型中的语言障碍。在IGLUE基准测试的两个任务中，涉及9种语言的实验中，我们展示了ICU可以在五种语言上实现新的最先进结果，并在其余语言上取得了可比较的结果。

    Most multilingual vision-and-language (V&L) research aims to accomplish multilingual and multimodal capabilities within one model. However, the scarcity of multilingual captions for images has hindered the development. To overcome this obstacle, we propose ICU, Image Caption Understanding, which divides a V&L task into two stages: a V&L model performs image captioning in English, and a multilingual language model (mLM), in turn, takes the caption as the alt text and performs crosslingual language understanding. The burden of multilingual processing is lifted off V&L model and placed on mLM. Since the multilingual text data is relatively of higher abundance and quality, ICU can facilitate the conquering of language barriers for V&L models. In experiments on two tasks across 9 languages in the IGLUE benchmark, we show that ICU can achieve new state-of-the-art results for five languages, and comparable results for the rest.
    
[^34]: 用于监测植物健康威胁的命名实体识别：一种基于ChouBERT的方法

    Named Entity Recognition for Monitoring Plant Health Threats in Tweets: a ChouBERT Approach. (arXiv:2310.12522v1 [cs.CL])

    [http://arxiv.org/abs/2310.12522](http://arxiv.org/abs/2310.12522)

    本文研究了一种基于ChouBERT的命名实体识别方法，应用于监测植物健康威胁。通过利用社交媒体中的非结构化文本数据，可以检测并提取关键信息，从而解决现有解决方案中缺乏标记数据和细粒度语义资源的问题。

    

    精密农业的一个重要应用场景是利用传感器和数据分析技术检测和测量作物健康威胁。然而，由于缺乏标记数据和细粒度语义资源，现有解决方案对文本数据仍未充分探索。最近的研究表明，农民之间日益增长的互联性和在线农业社区的出现使得Twitter等社交媒体成为检测陌生的植物健康事件的广泛参与平台，前提是我们能够从非结构化的文本数据中提取关键信息。ChouBERT是一个法语预训练语言模型，能够识别涉及植物健康问题观察的推文，并对未见过的自然灾害具有一般化能力。本文通过进一步研究ChouBERT在小型标记数据集上的令牌级注释任务，解决了标记数据不足的问题。

    An important application scenario of precision agriculture is detecting and measuring crop health threats using sensors and data analysis techniques. However, the textual data are still under-explored among the existing solutions due to the lack of labelled data and fine-grained semantic resources. Recent research suggests that the increasing connectivity of farmers and the emergence of online farming communities make social media like Twitter a participatory platform for detecting unfamiliar plant health events if we can extract essential information from unstructured textual data. ChouBERT is a French pre-trained language model that can identify Tweets concerning observations of plant health issues with generalizability on unseen natural hazards. This paper tackles the lack of labelled data by further studying ChouBERT's know-how on token-level annotation tasks over small labeled sets.
    
[^35]: 迷失在翻译中：当GPT-4V(ision)无法与文本一致时。VLLM和更多的视觉语言一致性分析。 (arXiv:2310.12520v1 [cs.CL])

    Lost in Translation: When GPT-4V(ision) Can't See Eye to Eye with Text. A Vision-Language-Consistency Analysis of VLLMs and Beyond. (arXiv:2310.12520v1 [cs.CL])

    [http://arxiv.org/abs/2310.12520](http://arxiv.org/abs/2310.12520)

    本研究通过对视觉语言一致性进行全面分析，揭示了视觉大语言模型在跨模态任务中的能力差异。

    

    最近多模态技术的进展为在涉及文本、音频和图像处理的多样任务中表现出色的模型开辟了令人兴奋的可能性。像将计算机视觉和语言建模结合在一起的GPT-4V这样的模型，在复杂的文本和图像任务上表现出色。以往的研究努力已经认真地考察了这些视觉大语言模型(VLLMs)在对象检测、图像字幕等任务中的性能。然而，这些分析往往集中在评估每种模态在单独任务中的性能，缺乏对它们跨模态交互的洞察。具体问题关于这些视觉语言模型是否一致地执行视觉和语言任务，还是独立地执行，仍然没有答案。在本研究中，我们借鉴了对多语言的最新研究，并对模型的跨模态交互进行了全面分析。我们引入了一个系统框架，量化了能力差异。

    Recent advancements in multimodal techniques open exciting possibilities for models excelling in diverse tasks involving text, audio, and image processing. Models like GPT-4V, blending computer vision and language modeling, excel in complex text and image tasks. Numerous prior research endeavors have diligently examined the performance of these Vision Large Language Models (VLLMs) across tasks like object detection, image captioning and others. However, these analyses often focus on evaluating the performance of each modality in isolation, lacking insights into their cross-modal interactions. Specifically, questions concerning whether these vision-language models execute vision and language tasks consistently or independently have remained unanswered. In this study, we draw inspiration from recent investigations into multilingualism and conduct a comprehensive analysis of model's cross-modal interactions. We introduce a systematic framework that quantifies the capability disparities be
    
[^36]: 通过可迁移的对抗攻击实现对齐大型语言模型的自动幻觉评估

    Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks. (arXiv:2310.12516v1 [cs.CL])

    [http://arxiv.org/abs/2310.12516](http://arxiv.org/abs/2310.12516)

    本文提出了一种通过可迁移的对抗攻击在大型语言模型中自动生成评估数据的方法，并使用ChatGPT和Natural Questions（NQ）数据集进行了验证。

    

    尽管在使用指令调整和检索增强技术防止大型语言模型（LLM）的幻觉方面取得了显著进展，但衡量LLM的可靠性仍然具有挑战性，因为人工评估数据对于许多任务和领域来说并不可用且可能存在数据泄漏。受到对抗机器学习的启发，本文旨在开发一种通过适当修改LLM在其中表现忠实的现有数据来自动生成评估数据的方法。具体而言，本文提出了一种基于LLM的框架AutoDebug，使用提示链接来生成以问答示例形式的可迁移对抗攻击。我们希望了解这些示例在多大程度上触发了LLM的幻觉行为。我们使用ChatGPT实现了AutoDebug，并对一个热门的开放领域问答数据集Natural Questions（NQ）的两个变体进行了评估。

    Although remarkable progress has been achieved in preventing large language model (LLM) hallucinations using instruction tuning and retrieval augmentation, it remains challenging to measure the reliability of LLMs using human-crafted evaluation data which is not available for many tasks and domains and could suffer from data leakage. Inspired by adversarial machine learning, this paper aims to develop a method of automatically generating evaluation data by appropriately modifying existing data on which LLMs behave faithfully. Specifically, this paper presents AutoDebug, an LLM-based framework to use prompting chaining to generate transferable adversarial attacks in the form of question-answering examples. We seek to understand the extent to which these examples trigger the hallucination behaviors of LLMs.  We implement AutoDebug using ChatGPT and evaluate the resulting two variants of a popular open-domain question-answering dataset, Natural Questions (NQ), on a collection of open-sour
    
[^37]: 大型语言模型的红队攻击提示生成和防御

    Attack Prompt Generation for Red Teaming and Defending Large Language Models. (arXiv:2310.12505v1 [cs.CL])

    [http://arxiv.org/abs/2310.12505](http://arxiv.org/abs/2310.12505)

    我们提出了一种综合方法来经济地生成高质量的攻击提示，通过上下文学习指导大型语言模型（LLMs）模仿人类生成的提示，并通过迭代交互来加强受攻击的LLMs的安全性。这些方法在不同LLMs上的实验验证了其有效性。

    

    大型语言模型（LLMs）容易受到红队攻击的影响，这可能导致LLMs生成有害内容。以前的研究通过手动或自动方法构建攻击提示，但这些方法在构建成本和质量上都存在限制。为了解决这些问题，我们提出了一种综合方法，结合了手动和自动方法，经济地生成高质量的攻击提示。具体而言，考虑到新兴LLMs的卓越能力，我们提出了一个攻击框架，通过上下文学习指导LLMs模仿人类生成的提示。此外，我们提出了一个防御框架，通过与攻击框架的迭代交互来对受攻击的LLMs进行微调，增强它们对红队攻击的安全性。对不同LLMs进行的大量实验验证了我们提出的攻击和防御框架的有效性。此外，我们发布了一系列攻击提示数据集，名为SAP，大小不同，便于研究者进行进一步研究。

    Large language models (LLMs) are susceptible to red teaming attacks, which can induce LLMs to generate harmful content. Previous research constructs attack prompts via manual or automatic methods, which have their own limitations on construction cost and quality. To address these issues, we propose an integrated approach that combines manual and automatic methods to economically generate high-quality attack prompts. Specifically, considering the impressive capabilities of newly emerged LLMs, we propose an attack framework to instruct LLMs to mimic human-generated prompts through in-context learning. Furthermore, we propose a defense framework that fine-tunes victim LLMs through iterative interactions with the attack framework to enhance their safety against red teaming attacks. Extensive experiments on different LLMs validate the effectiveness of our proposed attack and defense frameworks. Additionally, we release a series of attack prompts datasets named SAP with varying sizes, facili
    
[^38]: Co$^2$PT：通过反事实对比提示调整来缓解预训练语言模型中的偏见

    Co$^2$PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning. (arXiv:2310.12490v1 [cs.CL])

    [http://arxiv.org/abs/2310.12490](http://arxiv.org/abs/2310.12490)

    Co$^2$PT是一种通过反事实对比提示调整方法，可以在下游任务中减轻预训练语言模型中的偏见，并适应现有的去偏语言模型。

    

    预训练语言模型被广泛应用于许多重要的实际应用中。然而，最近的研究表明这些模型可能会从大规模的预训练语料库中编码社会偏见，甚至在后续应用中放大偏见。为了解决这个挑战，我们提出了Co$^2$PT，一种通过反事实对比提示调整在下游任务中减轻偏见的高效有效的去偏调整方法。我们在三个外部偏见基准上进行的实验表明，Co$^2$PT在提示调整过程中减轻偏见的有效性以及对现有上游去偏语言模型的适应性。这些发现表明了Co$^2$PT的优势，并为进一步改进下游任务中的偏见减轻提供了有希望的途径。

    Pre-trained Language Models are widely used in many important real-world applications. However, recent studies show that these models can encode social biases from large pre-training corpora and even amplify biases in downstream applications. To address this challenge, we propose Co$^2$PT, an efficient and effective debias-while-prompt tuning method for mitigating biases via counterfactual contrastive prompt tuning on downstream tasks. Our experiments conducted on three extrinsic bias benchmarks demonstrate the effectiveness of Co$^2$PT on bias mitigation during the prompt tuning process and its adaptability to existing upstream debiased language models. These findings indicate the strength of Co$^2$PT and provide promising avenues for further enhancement in bias mitigation on downstream tasks.
    
[^39]: MedAI对话语料库（MEDIC）：零样本分类医生与AI在健康咨询中的回答。

    MedAI Dialog Corpus (MEDIC): Zero-Shot Classification of Doctor and AI Responses in Health Consultations. (arXiv:2310.12489v1 [cs.CL])

    [http://arxiv.org/abs/2310.12489](http://arxiv.org/abs/2310.12489)

    本研究通过零样本学习调查了预训练语言模型在医生和AI在健康咨询中的回答的准确分类上的效果。研究发现，虽然预训练语言模型在一般语言理解方面表现出了很强的能力，但在医疗咨询中，它们可能需要特定语料库训练或其他技术以实现准确的医生和AI生成文本的分类。

    

    零样本分类使得可以将文本分类到在训练中没有见过的类中。在本文中，我们通过零样本学习，研究了预训练语言模型在准确分类来自医生和AI在健康咨询中的回答方面的有效性。我们的研究旨在确定这些模型是否能够在没有特定语料库训练的情况下有效地检测文本是来自人类还是AI模型。对于我们的实验，我们收集了来自医生对于患者健康咨询的回答，并对同样的问题/回答提问了AI模型。我们的研究结果显示，虽然预训练语言模型在一般语言理解方面表现出了很强的能力，但在医疗咨询中，它们可能需要特定语料库训练或其他技术以实现对医生和AI生成的文本的准确分类。作为基线方法，本研究展示了仅依靠零样本分类在医疗分类中的局限性。

    Zero-shot classification has enabled the classification of text into classes that were not seen during training. In this paper, we investigate the effectiveness of pre-trained language models to accurately classify responses from Doctors and AI in health consultations through zero-shot learning. Our study aims to determine whether these models can effectively detect if a text originates from human or AI models without specific corpus training. For our experiments, we collected responses from doctors to patient inquiries about their health and posed the same question/response to AI models. Our findings revealed that while pre-trained language models demonstrate a strong understanding of language generally, they may require specific corpus training or other techniques to achieve accurate classification of doctor- and AI-generated text in healthcare consultations. As a baseline approach, this study shows the limitations of relying solely on zero-shot classification in medical classificati
    
[^40]: 并非所有国家都庆祝感恩节：关于大型语言模型中的文化主导问题

    Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models. (arXiv:2310.12481v1 [cs.CL])

    [http://arxiv.org/abs/2310.12481](http://arxiv.org/abs/2310.12481)

    本文研究了大型语言模型中的文化主导问题，发现由于在模型训练中主要使用英语数据，当用户使用非英语语言提问时，模型往往提供与预期文化不相关的不恰当答案。我们提出了通过多样化数据预训练和文化感知提示两种方法来解决这个问题。

    

    本文针对大型语言模型（LLM）中存在的文化主导问题进行了研究，该问题源于在模型训练中主要使用英语数据（例如ChatGPT）。当用户使用非英语语言提问时，LLMs往往会提供与预期文化不相关的不恰当的英语文化相关答案。为了系统评估文化主导问题，我们构建了一个包含具体文化对象（如假日和歌曲）和抽象文化对象（如价值观和观点）的基准测试集。实证结果表明，代表性的GPT模型存在文化主导问题，其中GPT-4受到最严重影响，而text-davinci-003在这个问题上受影响最小。我们的研究强调了在开发和部署过程中对文化主导问题进行批判性审视和伦理考虑的需要。我们展示了两种直接的方法：模型开发中的多样化数据预训练和部署中的文化感知提示，可以显著缓解文化主导问题。

    In this paper, we identify a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g. ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in non-English languages. To systematically evaluate the cultural dominance issue, we build a benchmark that consists of both concrete (e.g. holidays and songs) and abstract (e.g. values and opinions) cultural objects. Empirical results show that the representative GPT models suffer from the culture dominance problem, where GPT-4 is the most affected while text-davinci-003 suffers the least from this problem. Our study emphasizes the need for critical examination of cultural dominance and ethical consideration in their development and deployment. We show two straightforward methods in model development (i.e. pretraining on more diverse data) and deployment (e.g. culture-aware prompting) can signifi
    
[^41]: 对语音语言模型的上下文学习进行探索

    An Exploration of In-Context Learning for Speech Language Model. (arXiv:2310.12477v1 [eess.AS])

    [http://arxiv.org/abs/2310.12477](http://arxiv.org/abs/2310.12477)

    本研究是首次探索了在语音处理中利用上下文学习（ICL）的可能性，通过在输入中呈现LM话语-标签示范，语音LM可以在没有文本监督的情况下实现少样本学习，并通过验证了在语音分类任务上进行ICL的可行性。

    

    自从GPT-3在自然语言处理（NLP）领域的发展以来，上下文学习（ICL）在利用大型语言模型（LLMs）方面发挥了重要作用。通过在输入中呈现LM话语-标签示范，LM可以在不依赖梯度下降或要求显式修改参数的情况下实现少样本学习。这使得LM能以黑盒的方式学习和调整。尽管ICL在NLP领域取得了成功，但在语音处理领域，很少有人研究ICL的可能性。本研究首次在没有文本监督的情况下提出了对语音LM的ICL的探索。我们首先证明了当前的语音LM没有ICL的能力。通过提出的热身训练，语音LM因此可以在未知任务上执行ICL。在这项研究中，我们验证了对语音LM在语音分类任务上进行ICL的可行性。

    Ever since the development of GPT-3 in the natural language processing (NLP) field, in-context learning (ICL) has played an important role in utilizing large language models (LLMs). By presenting the LM utterance-label demonstrations at the input, the LM can accomplish few-shot learning without relying on gradient descent or requiring explicit modification of its parameters. This enables the LM to learn and adapt in a black-box manner. Despite the success of ICL in NLP, little work is exploring the possibility of ICL in speech processing. This study proposes the first exploration of ICL with a speech LM without text supervision. We first show that the current speech LM does not have the ICL capability. With the proposed warmup training, the speech LM can, therefore, perform ICL on unseen tasks. In this work, we verify the feasibility of ICL for speech LM on speech classification tasks.
    
[^42]: 对话中的对比学习推理

    Contrastive Learning for Inference in Dialogue. (arXiv:2310.12467v1 [cs.CL])

    [http://arxiv.org/abs/2310.12467](http://arxiv.org/abs/2310.12467)

    本论文分析了推理任务中的信息差异对模型的影响，并提出了一种对比学习方法来缓解这种信息差异。实验证明，负样本有助于模型改进其推理生成能力。

    

    推理,尤其是那些来自归纳过程的推理,是我们对话中的一个关键组成部分，用于补充由讲话者隐含或明确传达的信息。虽然最近的大型语言模型在推理任务上取得了显著进展，但它们在归纳推理方面的表现远远落后于演绎推理。在本文中，我们根据语义信息差异来定义任务难度，分析了模型的行为，该差异区分了归纳推理和演绎推理（Johnson-Laird, 1988, 1993）。我们的分析揭示了对话上下文和所需推理之间信息差异的差距对归纳推理过程构成了重要挑战。为了缓解这种信息差距，我们研究了一种对比学习方法，通过提供负样本进行训练。我们的实验表明，负样本有助于模型理解错误并改进其推理生成能力。

    Inference, especially those derived from inductive processes, is a crucial component in our conversation to complement the information implicitly or explicitly conveyed by a speaker. While recent large language models show remarkable advances in inference tasks, their performance in inductive reasoning, where not all information is present in the context, is far behind deductive reasoning. In this paper, we analyze the behavior of the models based on the task difficulty defined by the semantic information gap -- which distinguishes inductive and deductive reasoning (Johnson-Laird, 1988, 1993). Our analysis reveals that the disparity in information between dialogue contexts and desired inferences poses a significant challenge to the inductive inference process. To mitigate this information gap, we investigate a contrastive learning approach by feeding negative samples. Our experiments suggest negative samples help models understand what is wrong and improve their inference generations.
    
[^43]: 揭示Transformer机器学习模型：基于注意力权重的数据恢复的理论方法

    Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights. (arXiv:2310.12462v1 [cs.LG])

    [http://arxiv.org/abs/2310.12462](http://arxiv.org/abs/2310.12462)

    本文提出了一种基于注意力权重和输出的理论框架，用于恢复Transformer模型中的输入数据。研究结果暗示模型设计存在潜在的漏洞。

    

    在深度学习领域中，Transformer已经成为了一种主导的架构，特别是在自然语言处理任务中。然而，随着它们的广泛应用，有关这些模型处理数据的安全性和隐私性的问题已经引起了关注。本文针对一个关键问题进行了研究：是否可以使用Transformer的注意力权重和输出来恢复输入数据？我们提出了一个理论框架来解决这个问题。具体地，我们介绍了一种算法，旨在通过最小化损失函数$L(X)$从给定的注意力权重$W = QK^\top$和输出$B$中恢复输入数据$X$，其中$X \in \mathbb{R}^{d \times n}$，$W \in \mathbb{R}^{d \times d}$，$B \in \mathbb{R}^{n \times n}$。这个损失函数捕捉了预期输出与实际输出之间的差异。我们的研究结果对于局部化分层机制（Localized Layer-wise Mechanism，LLM）具有重要的影响，表明模型设计存在潜在的漏洞。

    In the realm of deep learning, transformers have emerged as a dominant architecture, particularly in natural language processing tasks. However, with their widespread adoption, concerns regarding the security and privacy of the data processed by these models have arisen. In this paper, we address a pivotal question: Can the data fed into transformers be recovered using their attention weights and outputs? We introduce a theoretical framework to tackle this problem. Specifically, we present an algorithm that aims to recover the input data $X \in \mathbb{R}^{d \times n}$ from given attention weights $W = QK^\top \in \mathbb{R}^{d \times d}$ and output $B \in \mathbb{R}^{n \times n}$ by minimizing the loss function $L(X)$. This loss function captures the discrepancy between the expected output and the actual output of the transformer. Our findings have significant implications for the Localized Layer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's design from a s
    
[^44]: 重新思考构建用于理解预训练语言模型机制的有效度量方法

    Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models. (arXiv:2310.12454v1 [cs.CL])

    [http://arxiv.org/abs/2310.12454](http://arxiv.org/abs/2310.12454)

    本研究重新思考了构建用于理解预训练语言模型机制的有效度量方法。通过设计一系列度量方法，并使用树拓扑探针模型对BERT-large进行了实证研究。

    

    预训练语言模型被期望能够有效地将输入文本映射到一组向量，同时保留文本内在的关系。因此，设计一个白盒模型来计算反映这些向量内部关系存在的度量成为分析预训练语言模型后续可解释性的常见方法。然而，在源模型缺乏内在可解释性时，在白盒模型中实现可解释性并保证度量计算的严谨性变得具有挑战性。因此，本文讨论了在这种权衡中寻找平衡的方法，并提出了一种新颖的方法来构建理解预训练语言模型机制的度量方法。我们特别设计了一系列沿这一研究方向的度量方法，并使用这些方法中的树拓扑探针模型对BERT-large进行了测量。

    Pretrained language models are expected to effectively map input text to a set of vectors while preserving the inherent relationships within the text. Consequently, designing a white-box model to compute metrics that reflect the presence of specific internal relations in these vectors has become a common approach for post-hoc interpretability analysis of pretrained language models. However, achieving interpretability in white-box models and ensuring the rigor of metric computation becomes challenging when the source model lacks inherent interpretability. Therefore, in this paper, we discuss striking a balance in this trade-off and propose a novel line to constructing metrics for understanding the mechanisms of pretrained language models. We have specifically designed a family of metrics along this line of investigation, and the model used to compute these metrics is referred to as the tree topological probe. We conducted measurements on BERT-large by using these metrics. Based on the e
    
[^45]: 一个用于零样本实体链接的阅读和选择框架

    A Read-and-Select Framework for Zero-shot Entity Linking. (arXiv:2310.12450v1 [cs.CL])

    [http://arxiv.org/abs/2310.12450](http://arxiv.org/abs/2310.12450)

    提出了一个用于零样本实体链接的阅读和选择框架，通过建模实体消歧的主要组成部分，即实体提及-实体匹配和实体之间的比较，实现了最先进的性能。

    

    零样本实体链接旨在将实体提及与未见实体进行对齐，挑战泛化能力。先前的方法主要集中在候选检索阶段，忽视了实质性的候选排序阶段，这一阶段将实体进行消歧，从而做出最终的链接预测。在本文中，我们提出了一个阅读和选择（ReS）框架，通过对实体消歧的主要组成部分进行建模，即实体提及-实体匹配和实体之间的比较。首先，阅读模块利用提及上下文生成提及感知的实体表示，从而实现提及-实体匹配。然后，在选择模块中，我们将候选的选择视为一个序列标记问题，并将所有候选表示进行融合，以实现实体之间的比较。我们的方法在已建立的零样本实体链接数据集ZESHEL上取得了最先进的性能，平均精度为2.55%，无需耗时的人工劳动。

    Zero-shot entity linking (EL) aims at aligning entity mentions to unseen entities to challenge the generalization ability. Previous methods largely focus on the candidate retrieval stage and ignore the essential candidate ranking stage, which disambiguates among entities and makes the final linking prediction. In this paper, we propose a read-and-select (ReS) framework by modeling the main components of entity disambiguation, i.e., mention-entity matching and cross-entity comparison. First, for each candidate, the reading module leverages mention context to output mention-aware entity representations, enabling mention-entity matching. Then, in the selecting module, we frame the choice of candidates as a sequence labeling problem, and all candidate representations are fused together to enable cross-entity comparison. Our method achieves the state-of-the-art performance on the established zero-shot EL dataset ZESHEL with a 2.55\% micro-average accuracy gain, with no need for laborious mu
    
[^46]: 重新审视稀疏检索在少样本实体链接中的应用

    Revisiting Sparse Retrieval for Few-shot Entity Linking. (arXiv:2310.12444v1 [cs.CL])

    [http://arxiv.org/abs/2310.12444](http://arxiv.org/abs/2310.12444)

    本研究重新审视了少样本实体链接中的稀疏检索方法，并利用ELECTRA模型提取关键词来改善查询表达式，在ZESHEL数据集上实验结果显示，所提出的方法在所有测试领域中优于最先进模型。

    

    实体链接旨在将模糊的提及链接到知识库中的相应实体。其中一个主要挑战来自于特定领域标记数据不足。尽管密集的检索方法在一些基准数据集上取得了出色的性能，但是当只有有限数量的领域内标记数据时，它们的性能显著下降。在这种少样本情况下，我们重新审视了稀疏检索方法，并提出了一种基于ELECTRA的关键词提取器来去除提及上下文的噪声并构建更好的查询表达式。为了训练提取器，我们提出了一种远程监督方法，根据提及上下文和实体描述之间的重叠标记自动生成训练数据。在ZESHEL数据集上的实验结果表明，所提出的方法在所有测试领域中比现有最先进模型的性能有显著提高，展示了关键词增强的稀疏检索的有效性。

    Entity linking aims to link ambiguous mentions to their corresponding entities in a knowledge base. One of the key challenges comes from insufficient labeled data for specific domains. Although dense retrievers have achieved excellent performance on several benchmarks, their performance decreases significantly when only a limited amount of in-domain labeled data is available. In such few-shot setting, we revisit the sparse retrieval method, and propose an ELECTRA-based keyword extractor to denoise the mention context and construct a better query expression. For training the extractor, we propose a distant supervision method to automatically generate training data based on overlapping tokens between mention contexts and entity descriptions. Experimental results on the ZESHEL dataset demonstrate that the proposed method outperforms state-of-the-art models by a significant margin across all test domains, showing the effectiveness of keyword-enhanced sparse retrieval.
    
[^47]: 了解何处前往：使LLM成为一个相关、负责任且可信赖的搜索器。

    Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher. (arXiv:2310.12443v1 [cs.IR])

    [http://arxiv.org/abs/2310.12443](http://arxiv.org/abs/2310.12443)

    该论文提出了一种新颖的生成检索框架，旨在将LLM转变为一个相关、负责任且可信赖的搜索器。该框架包括生成器、验证器和优化器三个核心模块，分别用于生成可信赖的在线来源、验证来源可靠性和优化不可信赖的来源。通过广泛的实验证明了该方法相对于其他方法在相关性、负责任性和可信度方面的优势。

    

    大型语言模型（LLMs）的出现已经显示出它在提高搜索相关性和提供直接答案方面的潜力。然而，由于传统信息检索算法的局限性和LLM的错觉问题，验证生成结果的可靠性和贡献来源的可信度是一个挑战。为了创建LLM时代的“PageRank”，我们致力于将LLM转变为一个相关、负责任且可信赖的搜索器。我们提出了一个新颖的生成检索框架，利用LLM的知识建立查询和在线来源之间的直接链接。该框架包括三个核心模块：生成器、验证器和优化器，分别专注于生成可信赖的在线来源、验证来源的可靠性和优化不可信赖的来源。广泛的实验证明了我们方法在相关性、负责任性和可信度方面相对于各种SOTA方法的优势。

    The advent of Large Language Models (LLMs) has shown the potential to improve relevance and provide direct answers in web searches. However, challenges arise in validating the reliability of generated results and the credibility of contributing sources, due to the limitations of traditional information retrieval algorithms and the LLM hallucination problem. Aiming to create a "PageRank" for the LLM era, we strive to transform LLM into a relevant, responsible, and trustworthy searcher. We propose a novel generative retrieval framework leveraging the knowledge of LLMs to foster a direct link between queries and online sources. This framework consists of three core modules: Generator, Validator, and Optimizer, each focusing on generating trustworthy online sources, verifying source reliability, and refining unreliable sources, respectively. Extensive experiments and evaluations highlight our method's superior relevance, responsibility, and trustfulness against various SOTA methods.
    
[^48]: 高效长程Transformer：需要更多关注，但不一定在每一层都需要

    Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer. (arXiv:2310.12442v1 [cs.CL])

    [http://arxiv.org/abs/2310.12442](http://arxiv.org/abs/2310.12442)

    提出了一种高效的长程Transformer模型MASFormer，通过在少数层使用全局注意力和在其他层使用稀疏注意力，实现了在具有长序列的任务中高效的计算和建模能力。

    

    预训练的Transformer模型在各种自然语言处理任务中展示了卓越的性能。这些模型利用注意机制来捕捉序列中的长程和短程依赖关系。然而，全局注意机制的计算成本与序列长度呈二次关系，在具有长序列的任务中（例如8k个标记的输入）是不可承受的。尽管现有工作中建议使用稀疏注意力来提高计算效率，但它的建模能力有限，往往无法捕捉长序列中的复杂依赖关系。为了解决这个挑战，我们提出了MASFormer，一种易于实现的变种Transformer，具有混合注意范围。具体而言，MASFormer配备了全局注意力来捕捉长程依赖关系，但只在少数几层使用。对于剩余层，MASFormer只采用稀疏注意力来捕捉短程依赖关系。我们在n上的实验结果表明，MASFormer在长序列任务上具有较高的计算效率和建模能力。

    Pretrained transformer models have demonstrated remarkable performance across various natural language processing tasks. These models leverage the attention mechanism to capture long- and short-range dependencies in the sequence. However, the (full) attention mechanism incurs high computational cost quadratic in the sequence length, which is not affordable in tasks with long sequences, e.g., inputs with 8k tokens. Although sparse attention can be used to improve computational efficiency, as suggested in existing work, it has limited modeling capacity and often fails to capture complicated dependencies in long sequences. To tackle this challenge, we propose MASFormer, an easy-to-implement transformer variant with Mixed Attention Spans. Specifically, MASFormer is equipped with full attention to capture long-range dependencies, but only at a small number of layers. For the remaining layers, MASformer only employs sparse attention to capture short-range dependencies. Our experiments on n
    
[^49]: PoisonPrompt: 基于提示的大型语言模型的后门攻击

    PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models. (arXiv:2310.12439v1 [cs.CL])

    [http://arxiv.org/abs/2310.12439](http://arxiv.org/abs/2310.12439)

    PoisonPrompt是一种新的后门攻击方法，能够成功地破坏基于提示的大型语言模型，该攻击方法的有效性、保真度和鲁棒性经过了广泛实验验证，强调了基于提示的语言模型面临的安全威胁和进一步研究的必要性。

    

    最近，提示显著改善了预训练大型语言模型（LLM）在各种下游任务上的性能，使得它们在各种LLM应用场景中变得越来越不可或缺。然而，对于基于提示的LLM而言，后门漏洞——一种可以恶意更改受害模型正常预测的严重安全威胁——尚未得到充分的探索。本文提出了一种新颖的后门攻击POISONPROMPT，能够成功地破坏硬件和软件基于提示的LLM。我们通过对三种流行的提示方法、六个数据集和三种广泛使用的LLM进行广泛实验来评估POISONPROMPT的有效性、保真度和鲁棒性。我们的研究结果强调了基于提示的LLM受到后门攻击的潜在安全威胁，并强调了在这个领域需要进一步研究的必要性。

    Prompts have significantly improved the performance of pretrained Large Language Models (LLMs) on various downstream tasks recently, making them increasingly indispensable for a diverse range of LLM application scenarios. However, the backdoor vulnerability, a serious security threat that can maliciously alter the victim model's normal predictions, has not been sufficiently explored for prompt-based LLMs. In this paper, we present POISONPROMPT, a novel backdoor attack capable of successfully compromising both hard and soft prompt-based LLMs. We evaluate the effectiveness, fidelity, and robustness of POISONPROMPT through extensive experiments on three popular prompt methods, using six datasets and three widely used LLMs. Our findings highlight the potential security threats posed by backdoor attacks on prompt-based LLMs and emphasize the need for further research in this area.
    
[^50]: DocXChain: 一个强大的开源工具链用于文档解析及更多操作

    DocXChain: A Powerful Open-Source Toolchain for Document Parsing and Beyond. (arXiv:2310.12430v1 [cs.CV])

    [http://arxiv.org/abs/2310.12430](http://arxiv.org/abs/2310.12430)

    DocXChain是一个开源工具链，通过文档解析将非结构化文档转换为可读可操作的结构化表示，并提供了基本能力和完全功能的文档解析流水线，可以与其他工具和模型集成，用于完成复杂任务。

    

    在这篇报告中，我们介绍了DocXChain，一个强大的开源工具链，用于文档解析，旨在自动将非结构化文档中包含的丰富信息（如文本，表格和图表）转换为可读取和可操作的结构化表示。具体而言，提供了基本能力，包括文本检测、文本识别、表格结构识别和布局分析。在这些基本能力的基础上，我们还构建了一组完全功能的文档解析流水线，即通用文本阅读、表格解析和文档结构化，以推动与现实场景中的文档相关的各种应用。此外，DocXChain简洁、模块化和灵活，可以轻松集成现有的工具、库或模型（如LangChain和ChatGPT），构建更强大的系统，完成更复杂和具有挑战性的任务。DocXChain的代码可以在开源平台获得。

    In this report, we introduce DocXChain, a powerful open-source toolchain for document parsing, which is designed and developed to automatically convert the rich information embodied in unstructured documents, such as text, tables and charts, into structured representations that are readable and manipulable by machines. Specifically, basic capabilities, including text detection, text recognition, table structure recognition and layout analysis, are provided. Upon these basic capabilities, we also build a set of fully functional pipelines for document parsing, i.e., general text reading, table parsing, and document structurization, to drive various applications related to documents in real-world scenarios. Moreover, DocXChain is concise, modularized and flexible, such that it can be readily integrated with existing tools, libraries or models (such as LangChain and ChatGPT), to construct more powerful systems that can accomplish more complicated and challenging tasks. The code of DocXChai
    
[^51]: MAF: 多方面反馈以改善大型语言模型的推理能力

    MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models. (arXiv:2310.12426v1 [cs.CL])

    [http://arxiv.org/abs/2310.12426](http://arxiv.org/abs/2310.12426)

    本研究提出了一种多方面反馈的迭代优化框架，该框架包括冻结的语言模型和外部工具模块，每个模块都专注于特定的错误类型。实验证明该方法改善了大型语言模型在推理任务中的性能，相对提升了多达20%。

    

    语言模型在各种自然语言任务中展现出了令人印象深刻的性能。然而，在涉及自然语言推理的情况下，语言模型仍然面临诸如幻觉，生成错误的中间推理步骤和数学错误等挑战。最近的研究集中在通过反馈自我改进来增强语言模型。然而，现有的方法仅依赖于单一的通用反馈来源，无法解决语言模型生成的推理链中的多样错误类型。在这项工作中，我们提出了多方面反馈，这是一个集成了多个反馈模块的迭代优化框架，其中包括冻结的语言模型和外部工具，每个模块都专注于特定的错误类别。我们的实验证明了我们的方法在解决语言模型生成的推理链中的几个错误方面的有效性，从而改善了语言模型在几个推理任务中的整体性能。我们看到了在数学推理任务中相对提升了多达20%。

    Language Models (LMs) have shown impressive performance in various natural language tasks. However, when it comes to natural language reasoning, LMs still face challenges such as hallucination, generating incorrect intermediate reasoning steps, and making mathematical errors. Recent research has focused on enhancing LMs through self-improvement using feedback. Nevertheless, existing approaches relying on a single generic feedback source fail to address the diverse error types found in LM-generated reasoning chains. In this work, we propose Multi-Aspect Feedback, an iterative refinement framework that integrates multiple feedback modules, including frozen LMs and external tools, each focusing on a specific error category. Our experimental results demonstrate the efficacy of our approach to addressing several errors in the LM-generated reasoning chain and thus improving the overall performance of an LM in several reasoning tasks. We see a relative improvement of up to 20% in Mathematical
    
[^52]: 移位和忽略：对用户-GPT交互的任务导向调查

    The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions. (arXiv:2310.12418v1 [cs.CL])

    [http://arxiv.org/abs/2310.12418](http://arxiv.org/abs/2310.12418)

    本文通过分析用户-GPT对话，发现了当前NLP研究与实际应用需求之间的差异。用户经常请求的任务与学术研究中常研究的任务存在显著差距，如“设计”和“规划”等任务在学术研究中被忽视。对这些被忽略任务的研究有助于更好地满足实际需求。

    

    最近大规模语言模型（LLMs）的进展已经产生了在各种自然语言处理任务中表现出色的模型。然而，目前尚不清楚NLP研究的重点是否准确捕捉到了人类用户的真正需求。本文通过大规模收集用户-GPT对话的方式，对当前NLP研究与实际NLP应用需求之间的差异进行全面分析。我们对真实用户向GPT提出的大量查询进行了分析。我们将这些查询与现有NLP基准任务进行比较，并发现用户经常从LLMs请求的任务与学术研究中常常研究的任务之间存在显著差距。例如，我们发现在用户交互中普遍存在“设计”和“规划”等任务，但这些任务在传统的NLP基准中被忽视或存在差异。我们对这些被忽略的任务进行了深入研究，剖析了它们所带来的实际挑战和问题。

    Recent progress in Large Language Models (LLMs) has produced models that exhibit remarkable performance across a variety of NLP tasks. However, it remains unclear whether the existing focus of NLP research accurately captures the genuine requirements of human users. This paper provides a comprehensive analysis of the divergence between current NLP research and the needs of real-world NLP applications via a large-scale collection of user-GPT conversations. We analyze a large-scale collection of real user queries to GPT. We compare these queries against existing NLP benchmark tasks and identify a significant gap between the tasks that users frequently request from LLMs and the tasks that are commonly studied in academic research. For example, we find that tasks such as ``design'' and ``planning'' are prevalent in user interactions but are largely neglected or different from traditional NLP benchmarks. We investigate these overlooked tasks, dissect the practical challenges they pose, and 
    
[^53]: FinEntity: 金融文本的实体级情感分类

    FinEntity: Entity-level Sentiment Classification for Financial Texts. (arXiv:2310.12406v1 [cs.CL])

    [http://arxiv.org/abs/2310.12406](http://arxiv.org/abs/2310.12406)

    本论文介绍了一个名为FinEntity的实体级情感分类数据集，该数据集标注了金融新闻中的金融实体范围及其情感，为金融领域的实体级情感分析提供了重要资源。通过基准测试，指出了几个预训练模型在实体级情感分类任务上的效果，并通过案例研究展示了FinEntity在监测加密货币市场中的实际应用价值。

    

    在金融领域，进行实体级情感分析对准确评估针对特定金融实体的情感至关重要。据我们所知，目前尚无公开可用的数据集用于此目的。在本文中，我们介绍了一个名为FinEntity的实体级情感分类数据集，该数据集标注了金融新闻中的金融实体范围及其情感（积极、中性和消极）。我们在论文中记录了数据集构建过程。此外，我们在实体级情感分类上对几个预训练模型（BERT、FinBERT等）和ChatGPT进行了基准测试。通过案例研究，我们展示了在监测加密货币市场中使用FinEntity的实际效用。FinEntity的数据和代码可在\url{https://github.com/yixuantt/FinEntity}上获得。

    In the financial domain, conducting entity-level sentiment analysis is crucial for accurately assessing the sentiment directed toward a specific financial entity. To our knowledge, no publicly available dataset currently exists for this purpose. In this work, we introduce an entity-level sentiment classification dataset, called \textbf{FinEntity}, that annotates financial entity spans and their sentiment (positive, neutral, and negative) in financial news. We document the dataset construction process in the paper. Additionally, we benchmark several pre-trained models (BERT, FinBERT, etc.) and ChatGPT on entity-level sentiment classification. In a case study, we demonstrate the practical utility of using FinEntity in monitoring cryptocurrency markets. The data and code of FinEntity is available at \url{https://github.com/yixuantt/FinEntity}
    
[^54]: Loop Copilot: 用于音乐生成和迭代编辑的AI合奏系统

    Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative Editing. (arXiv:2310.12404v1 [cs.SD])

    [http://arxiv.org/abs/2310.12404](http://arxiv.org/abs/2310.12404)

    Loop Copilot是一种新型的AI音乐合奏系统，能够通过交互式多轮对话界面生成和迭代改进音乐，通过选择适当的AI模型执行任务，并在一个集中的表中保持关键属性以确保音乐的连贯性。

    

    创建音乐是一个迭代过程，每个阶段都需要不同的方法。然而，现有的AI音乐系统在组织多个子系统以满足不同需求方面存在不足。为了解决这个问题，我们引入了Loop Copilot，这是一个能够通过交互式、多轮对话界面生成和迭代改进音乐的新型系统。该系统使用一种大型语言模型来解释用户意图，并选择适当的AI模型进行任务执行。每个后端模型都专门针对特定任务，并将它们的输出聚合起来以满足用户的要求。为了确保音乐的连贯性，关键属性被保留在一个集中的表中。我们通过半结构化的访谈和问卷调查评估了所提出的系统的有效性，突出了它在促进音乐创作方面的实用性，以及它在更广泛应用中的潜力。

    Creating music is iterative, requiring varied methods at each stage. However, existing AI music systems fall short in orchestrating multiple subsystems for diverse needs. To address this gap, we introduce Loop Copilot, a novel system that enables users to generate and iteratively refine music through an interactive, multi-round dialogue interface. The system uses a large language model to interpret user intentions and select appropriate AI models for task execution. Each backend model is specialized for a specific task, and their outputs are aggregated to meet the user's requirements. To ensure musical coherence, essential attributes are maintained in a centralized table. We evaluate the effectiveness of the proposed system through semi-structured interviews and questionnaires, highlighting its utility not only in facilitating music creation but also its potential for broader applications.
    
[^55]: 用关系嵌入链解决困难的类比问题

    Solving Hard Analogy Questions with Relation Embedding Chains. (arXiv:2310.12379v1 [cs.CL])

    [http://arxiv.org/abs/2310.12379](http://arxiv.org/abs/2310.12379)

    本文提出了一种解决困难的类比问题的方法，通过将关系建模为路径并关联其边缘与关系嵌入，以获得合适的中间词和有信息量的关系嵌入，从而结合了知识图谱和关系嵌入的优势。

    

    在词汇语义学中，建模概念之间的关系是一个核心主题。一个常见策略是依赖于知识图谱（KGs）如ConceptNet，并将两个概念之间的关系建模为一组路径。然而，KGs仅限于固定的关系类型，不完整并且通常嘈杂。另一个策略是从微调的语言模型中提炼关系嵌入。然而，对于只间接相关的词来说，这种方法不太适用，并且不容易将结构化领域知识整合进来。在本文中，我们旨在结合两者的优点。我们将关系建模为路径，但将其边缘与关系嵌入相关联。首先，通过识别合适的中间词语来获取路径，然后选择那些可以获得有信息量的关系嵌入的词语。我们经验证明，我们提出的表示方法对于解决困难的类比问题是有用的。

    Modelling how concepts are related is a central topic in Lexical Semantics. A common strategy is to rely on knowledge graphs (KGs) such as ConceptNet, and to model the relation between two concepts as a set of paths. However, KGs are limited to a fixed set of relation types, and they are incomplete and often noisy. Another strategy is to distill relation embeddings from a fine-tuned language model. However, this is less suitable for words that are only indirectly related and it does not readily allow us to incorporate structured domain knowledge. In this paper, we aim to combine the best of both worlds. We model relations as paths but associate their edges with relation embeddings. The paths are obtained by first identifying suitable intermediate words and then selecting those words for which informative relation embeddings can be obtained. We empirically show that our proposed representations are useful for solving hard analogy questions.
    
[^56]: REMARK-LLM:一种用于生成大型语言模型的鲁棒高效的水印框架

    REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models. (arXiv:2310.12362v1 [cs.CR])

    [http://arxiv.org/abs/2310.12362](http://arxiv.org/abs/2310.12362)

    REMARK-LLM是一种针对生成大型语言模型的文本的鲁棒高效的水印框架，通过学习-based消息编码、重新参数化和解码模块以及优化的波束搜索算法来保护生成内容的完整性和防止恶意利用。

    

    我们提出了一种名为REMARK-LLM的新型高效、强鲁棒性的水印框架，专为大型语言模型（LLM）生成的文本设计。使用LLMs合成类似人类的内容需要大量的计算资源和广泛的数据集，涵盖了重要的知识产权（IP）。然而，生成的内容容易受到恶意利用，包括垃圾邮件和抄袭。为了解决这些挑战，REMARK-LLM提出了三个新的组成部分：（i）基于学习的消息编码模块，将二进制签名注入LLM生成的文本中；（ii）重新参数化模块，将消息编码的密集分布转换为水印文本标记的稀疏分布；（iii）专门用于签名提取的解码模块；此外，我们引入了一种优化的波束搜索算法，以保证生成内容的连贯性和一致性。REMARK-LLM经过严格的训练，以鼓励语义完整性的保留。

    We present REMARK-LLM, a novel efficient, and robust watermarking framework designed for texts generated by large language models (LLMs). Synthesizing human-like content using LLMs necessitates vast computational resources and extensive datasets, encapsulating critical intellectual property (IP). However, the generated content is prone to malicious exploitation, including spamming and plagiarism. To address the challenges, REMARK-LLM proposes three new components: (i) a learning-based message encoding module to infuse binary signatures into LLM-generated texts; (ii) a reparameterization module to transform the dense distributions from the message encoding to the sparse distribution of the watermarked textual tokens; (iii) a decoding module dedicated for signature extraction; Furthermore, we introduce an optimized beam search algorithm to guarantee the coherence and consistency of the generated content. REMARK-LLM is rigorously trained to encourage the preservation of semantic integrity
    
[^57]: GRI：基于图的词嵌入空间的相对同构

    GRI: Graph-based Relative Isomorphism of Word Embedding Spaces. (arXiv:2310.12360v1 [cs.CL])

    [http://arxiv.org/abs/2310.12360](http://arxiv.org/abs/2310.12360)

    提出了一种名为GRI的方法，通过结合分布训练目标和注意力图卷积，一致地考虑多个空间之间定义/计算相对同构性所需的语义相似词汇的影响。在实验评估中，GRI在平均P@1上相对得分提升了高达63.6％。

    

    在机器翻译中，使用单语言嵌入空间自动构建双语词典是一个核心挑战。这些词典的最终性能取决于个别空间的几何相似性，即它们的同构程度。现有的尝试控制不同空间的相对同构性无法将语义相关词汇的影响纳入到训练目标中。为了解决这个问题，我们提出了GRI方法，该方法将分布式训练目标与注意力图卷积相结合，以一致地考虑定义/计算多个空间之间的相对同构性所需的语义相似词汇的影响。实验评估表明，GRI通过将平均P@1的相对得分提升了高达63.6％，优于现有研究。我们在https://github.com/asif6827/GRI上发布GRI的代码。

    Automated construction of bilingual dictionaries using monolingual embedding spaces is a core challenge in machine translation. The end performance of these dictionaries relies upon the geometric similarity of individual spaces, i.e., their degree of isomorphism. Existing attempts aimed at controlling the relative isomorphism of different spaces fail to incorporate the impact of semantically related words in the training objective. To address this, we propose GRI that combines the distributional training objectives with attentive graph convolutions to unanimously consider the impact of semantically similar words required to define/compute the relative isomorphism of multiple spaces. Experimental evaluation shows that GRI outperforms the existing research by improving the average P@1 by a relative score of up to 63.6%. We release the codes for GRI at https://github.com/asif6827/GRI.
    
[^58]: knn-seq: 高效、可扩展的kNN-MT框架

    knn-seq: Efficient, Extensible kNN-MT Framework. (arXiv:2310.12352v1 [cs.CL])

    [http://arxiv.org/abs/2310.12352](http://arxiv.org/abs/2310.12352)

    "knn-seq"是一个高效、可扩展的kNN-MT框架，通过利用翻译示例来提高预训练NMT模型的翻译质量，给出了在十亿级数据存储下具有可比较增益的实验结果，并在德英翻译任务中仅花费2.21小时来构建十亿规模的数据存储。

    

    k-最近邻机器翻译（kNN-MT）通过在解码过程中利用翻译示例来提高预训练神经机器翻译（NMT）模型的翻译质量。翻译示例被存储在一个向量数据库中，称为数据存储，它包含了来自并行数据的每个目标标记的一个条目。由于其规模较大，构建和检索数据存储的示例都具有计算上的昂贵性。在本文中，我们提出了一个高效且可扩展的kNN-MT框架knn-seq，为研究人员和开发者提供了一个精心设计的框架，即使在拥有十亿级大型数据存储的情况下也可以高效地运行。knn-seq是作为fairseq的一个插件开发的，易于切换模型和kNN索引。实验结果表明，我们实现的kNN-MT与原始kNN-MT获得了可比较的增益，并且十亿规模的数据存储构建在WMT'19德英翻译任务中仅花费了2.21小时。我们将我们的knn-seq发布为MIT-li。

    k-nearest-neighbor machine translation (kNN-MT) boosts the translation quality of a pre-trained neural machine translation (NMT) model by utilizing translation examples during decoding. Translation examples are stored in a vector database, called a datastore, which contains one entry for each target token from the parallel data it is made from. Due to its size, it is computationally expensive both to construct and to retrieve examples from the datastore. In this paper, we present an efficient and extensible kNN-MT framework, knn-seq, for researchers and developers that is carefully designed to run efficiently, even with a billion-scale large datastore. knn-seq is developed as a plug-in on fairseq and easy to switch models and kNN indexes. Experimental results show that our implemented kNN-MT achieves a comparable gain to the original kNN-MT, and the billion-scale datastore construction took 2.21 hours in the WMT'19 German-to-English translation task. We publish our knn-seq as an MIT-li
    
[^59]: LACMA: 使用元行动的语言对齐对比学习用于具象指令跟随

    LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following. (arXiv:2310.12344v1 [cs.CL])

    [http://arxiv.org/abs/2310.12344](http://arxiv.org/abs/2310.12344)

    该论文提出了一种名为LACMA的方法，通过对比学习实现了智能体与指令的语言对齐，进而通过引入元行动的概念来解决高级语言指令与低级行动空间之间的语义差距，从而提高了智能体在未知环境中的泛化能力。

    

    当环境在训练中被看到时，端到端的Transformer在具象指令跟随方面表现出了令人印象深刻的成功率。然而，当它们在未知环境中部署时往往遇到困难。这种缺乏泛化能力是由于智能体对自然语言指令中的细微变化不敏感。为了缓解这个问题，我们提出了通过对比学习将智能体的隐藏状态与指令明确对齐。然而，高级语言指令与智能体的低级行动空间之间的语义差距仍然是一个障碍。因此，我们进一步引入了元行动的新概念来弥合这个差距。元行动是从原始行动序列中解析出来的普遍行动模式。这些模式代表了更高层次的语义，直观上更接近指令。当元行动被应用为额外的训练信号时，智能体在未知环境中的泛化能力更好。

    End-to-end Transformers have demonstrated an impressive success rate for Embodied Instruction Following when the environment has been seen in training. However, they tend to struggle when deployed in an unseen environment. This lack of generalizability is due to the agent's insensitivity to subtle changes in natural language instructions. To mitigate this issue, we propose explicitly aligning the agent's hidden states with the instructions via contrastive learning. Nevertheless, the semantic gap between high-level language instructions and the agent's low-level action space remains an obstacle. Therefore, we further introduce a novel concept of meta-actions to bridge the gap. Meta-actions are ubiquitous action patterns that can be parsed from the original action sequence. These patterns represent higher-level semantics that are intuitively aligned closer to the instructions. When meta-actions are applied as additional training signals, the agent generalizes better to unseen environment
    
[^60]: 通过推理与规划消除推理：一种引导LLMs非线性思维的新框架

    Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs' Non-linear Thinking. (arXiv:2310.12342v1 [cs.CL])

    [http://arxiv.org/abs/2310.12342](http://arxiv.org/abs/2310.12342)

    本文提出了一种名为推断性排除提示（IEP）的新框架，通过结合排除和推理的原则，引导LLM进行非线性思考。IEP通过规划和自然语言推理，可以模拟复杂的人类思维过程，比其他方法具有更广泛的视角。

    

    Thought Chain（CoT）提示及其变体通过模拟人类线性认知和逻辑，探索为大型语言模型（LLM）装备高级推理能力。然而，人类思维复杂且混合线性和非线性思维。在这项工作中，我们提出了一种新的提示方式，称为推断性排除提示（IEP），它结合了排除和推理的原则，以引导LLM进行非线性思考。IEP指导LLM进行规划，并利用自然语言推理（NLI）推断每个可能解与上下文、常识或事实的推理关系，从而通过回溯推理获得更广泛的视角。相比其他基于CoT的方法，IEP的前向规划和后向排除过程更好地模拟了复杂的人类思维过程，后者仅反映线性认知过程。我们进行了一系列的实证研究，并验证了IEP的优势。

    Chain-of-Thought(CoT) prompting and its variants explore equipping large language models (LLMs) with high-level reasoning abilities by emulating human-like linear cognition and logic. However, the human mind is complicated and mixed with both linear and nonlinear thinking. In this work, we propose \textbf{I}nferential \textbf{E}xclusion \textbf{P}rompting (IEP), a novel prompting that combines the principles of elimination and inference in order to guide LLMs to think non-linearly. IEP guides LLMs to plan and then utilize Natural Language Inference (NLI) to deduce each possible solution's entailment relation with context, commonsense, or facts, therefore yielding a broader perspective by thinking back for inferring. This forward planning and backward eliminating process allows IEP to better simulate the complex human thinking processes compared to other CoT-based methods, which only reflect linear cognitive processes. We conducted a series of empirical studies and have corroborated tha
    
[^61]: GPT-3家族大型语言模型的综述，包括ChatGPT和GPT-4

    A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4. (arXiv:2310.12321v1 [cs.CL])

    [http://arxiv.org/abs/2310.12321](http://arxiv.org/abs/2310.12321)

    GPT-3家族大型语言模型是一类特殊的预训练语言模型，通过扩大模型规模、预训练语料库和计算，能够在许多自然语言处理任务中无需特定训练而取得显著性能。这篇论文是对最近研究进展的全面概述，为研究社区提供未来研究方向的指导。

    

    大型语言模型(LLMs)是一类特殊的预训练语言模型，通过扩大模型规模、预训练语料库和计算得到。由于它们巨大的规模和在大量文本数据上的预训练，LLMs表现出特殊能力，在许多自然语言处理任务中能够达到令人瞩目的性能，而无需进行特定任务的训练。LLMs的时代始于OpenAI的GPT-3模型，自从引入了ChatGPT和GPT4等模型后，LLMs的受欢迎程度呈指数增长。我们将GPT-3及其继任者OpenAI模型，包括ChatGPT和GPT4，称为GPT-3家族大型语言模型（GLLMs）。随着GLLMs，尤其是在研究界的普及，对于综合概述近期在多个维度上的研究进展，并能为研究社区提供有见地的未来研究方向指导，存在着强烈的需求。我们在综述论文中从基础开始介绍。

    Large language models (LLMs) are a special class of pretrained language models obtained by scaling model size, pretraining corpus and computation. LLMs, because of their large size and pretraining on large volumes of text data, exhibit special abilities which allow them to achieve remarkable performances without any task-specific training in many of the natural language processing tasks. The era of LLMs started with OpenAI GPT-3 model, and the popularity of LLMs is increasing exponentially after the introduction of models like ChatGPT and GPT4. We refer to GPT-3 and its successor OpenAI models, including ChatGPT and GPT4, as GPT-3 family large language models (GLLMs). With the ever-rising popularity of GLLMs, especially in the research community, there is a strong need for a comprehensive survey which summarizes the recent research progress in multiple dimensions and can guide the research community with insightful future research directions. We start the survey paper with foundation c
    
[^62]: The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis.

    The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis. (arXiv:2310.12318v1 [cs.CL])

    [http://arxiv.org/abs/2310.12318](http://arxiv.org/abs/2310.12318)

    这项研究通过调查189篇论文，批判性地研究了情感分析在社会技术系统中的应用，揭示了对情感的不同概念化，并提出了一个伦理表格来解决情感分析中的公平利用问题。

    

    我们通过批判性地研究189篇同行评审的论文，对情感分析（SA）的应用、模型和数据集进行了调查，以探究情感分析的社会技术方面。我们的研究来源于对情感分析在不同社会技术系统中成为重要组成部分的认识，并对社会学和技术文献中的情感概念进行了深入研究。我们的研究揭示了金融、政府和医疗等领域对情感的不同概念化。我们的研究还发现在情感的定义和框架方面存在明确不足，可能导致挑战和偏见。为解决这个问题，我们提出了一个涵盖关键问题的伦理表格，以指导从业者确保情感分析的公平利用。我们的研究强调了采用跨学科方法来定义情感分析的重要性，并提供了一个实用的解决方案来实施情感分析。

    We conduct an inquiry into the sociotechnical aspects of sentiment analysis (SA) by critically examining 189 peer-reviewed papers on their applications, models, and datasets. Our investigation stems from the recognition that SA has become an integral component of diverse sociotechnical systems, exerting influence on both social and technical users. By delving into sociological and technological literature on sentiment, we unveil distinct conceptualizations of this term in domains such as finance, government, and medicine. Our study exposes a lack of explicit definitions and frameworks for characterizing sentiment, resulting in potential challenges and biases. To tackle this issue, we propose an ethics sheet encompassing critical inquiries to guide practitioners in ensuring equitable utilization of SA. Our findings underscore the significance of adopting an interdisciplinary approach to defining sentiment in SA and offer a pragmatic solution for its implementation.
    
[^63]: 文档级语言模型用于机器翻译

    Document-Level Language Models for Machine Translation. (arXiv:2310.12303v1 [cs.CL])

    [http://arxiv.org/abs/2310.12303](http://arxiv.org/abs/2310.12303)

    这项工作提出了一种利用文档级别语言模型构建上下文感知的翻译系统的方法。通过结合任何现有的句级别翻译模型与文档级别语言模型，并借鉴模型组合的最新进展，尤其是权重技术的提出，可以显著提高文档级别指标并降低计算开销。

    

    尽管已知存在局限性，但大多数机器翻译系统仍然在句级别上运行。其中一个原因是，大多数平行训练数据只有句级别的对齐，没有文档级别的元信息。在这项工作中，我们利用文档级别的单语数据构建上下文感知的翻译系统。我们通过将任何现有的句级别翻译模型与文档级别语言模型相结合来实现这一目标。我们通过利用模型组合的最新进展来改进现有方法。此外，我们提出了能够使系统组合更灵活、显著降低计算开销的权重技术。通过对四个不同的翻译任务进行全面评估，我们证明了我们的扩展显著提高了文档级别指标，并且在计算效率上也更优。然而，我们还发现在大多数情况下，反向翻译的结果更好，

    Despite the known limitations, most machine translation systems today still operate on the sentence-level. One reason for this is, that most parallel training data is only sentence-level aligned, without document-level meta information available. In this work, we set out to build context-aware translation systems utilizing document-level monolingual data instead. This can be achieved by combining any existing sentence-level translation model with a document-level language model. We improve existing approaches by leveraging recent advancements in model combination. Additionally, we propose novel weighting techniques that make the system combination more flexible and significantly reduce computational overhead. In a comprehensive evaluation on four diverse translation tasks, we show that our extensions improve document-targeted scores substantially and are also computationally more efficient. However, we also find that in most scenarios, back-translation gives even better results, at the
    
[^64]: 在上下文中测量逐点可用信息

    Measuring Pointwise $\mathcal{V}$-Usable Information In-Context-ly. (arXiv:2310.12300v1 [cs.CL])

    [http://arxiv.org/abs/2310.12300](http://arxiv.org/abs/2310.12300)

    这项研究适用于上下文学习范式，通过调整逐点可用信息度量指标为适用于上下文的版本，将其命名为上下文PVI，并证明了上下文PVI的可靠性和稳定性。

    

    在上下文学习（ICL）是一种新的学习范式，随着大型语言模型的发展而受到青睐。本文将最近提出的难度度量指标逐点可用信息（PVI）调整为适用于上下文的版本（上下文PVI）。与原始PVI相比，上下文PVI更高效，因为它只需少量示例并且不需要微调。我们进行了全面的实证分析以评估上下文PVI的可靠性。我们的研究结果表明，上下文PVI的估计值表现出类似于原始PVI的特征。具体针对上下文环境，我们展示了上下文PVI的估计值在不同示例选取和拍摄次数下保持一致。在不同的示例选取中，上下文PVI的估计值的方差是微不足道的，这表明上下文PVI是稳定的。此外，我们演示了如何利用上下文PVI来识别挑战。

    In-context learning (ICL) is a new learning paradigm that has gained popularity along with the development of large language models. In this work, we adapt a recently proposed hardness metric, pointwise $\mathcal{V}$-usable information (PVI), to an in-context version (in-context PVI). Compared to the original PVI, in-context PVI is more efficient in that it requires only a few exemplars and does not require fine-tuning. We conducted a comprehensive empirical analysis to evaluate the reliability of in-context PVI. Our findings indicate that in-context PVI estimates exhibit similar characteristics to the original PVI. Specific to the in-context setting, we show that in-context PVI estimates remain consistent across different exemplar selections and numbers of shots. The variance of in-context PVI estimates across different exemplar selections is insignificant, which suggests that in-context PVI are stable. Furthermore, we demonstrate how in-context PVI can be employed to identify challen
    
[^65]: 一图抵千言：使用多概念提示学习来学习对象级概念

    An Image is Worth Multiple Words: Learning Object Level Concepts using Multi-Concept Prompt Learning. (arXiv:2310.12274v1 [cs.CV])

    [http://arxiv.org/abs/2310.12274](http://arxiv.org/abs/2310.12274)

    提出了一种多概念提示学习（MCPL）框架，通过同时学习多个新的“词”来解决在单个场景中识别和整合多个对象级概念的挑战。针对词概念相关性准确性问题，提出了注意力掩码、提示对比损失和绑定形容词等三种正则化技术。通过图像生成进行了评估，结果表明该框架能够生成更多样化和合成的图像。

    

    文字反转是一种提示学习方法，它学习一种新的“单词”的嵌入表示图像风格和外观，使其能够整合到自然语言句子中生成新的合成图像。然而，即使对于可获得个别概念的嵌入，识别和整合一个场景中的多个对象级概念仍然面临着显著的挑战，这也得到了我们的实证测试的进一步证实。为了解决这个挑战，我们引入了一个多概念提示学习（MCPL）的框架，可以从一个句子-图像对中同时学习多个新的“词”。为了增强词概念相关性的准确性，我们提出了三种正则化技术：注意力掩码（AttnMask）将学习集中在相关区域；提示对比损失（PromptCL）将不同概念的嵌入分离开来；以及绑定形容词（Bind adj.）将新的“词”与已知词相关联。我们通过图像生成进行评估

    Textural Inversion, a prompt learning method, learns a singular embedding for a new "word" to represent image style and appearance, allowing it to be integrated into natural language sentences to generate novel synthesised images. However, identifying and integrating multiple object-level concepts within one scene poses significant challenges even when embeddings for individual concepts are attainable. This is further confirmed by our empirical tests. To address this challenge, we introduce a framework for Multi-Concept Prompt Learning (MCPL), where multiple new "words" are simultaneously learned from a single sentence-image pair. To enhance the accuracy of word-concept correlation, we propose three regularisation techniques: Attention Masking (AttnMask) to concentrate learning on relevant areas; Prompts Contrastive Loss (PromptCL) to separate the embeddings of different concepts; and Bind adjective (Bind adj.) to associate new "words" with known words. We evaluate via image generation
    
[^66]: 使用任务级混合专家模型的直接神经机器翻译

    Direct Neural Machine Translation with Task-level Mixture of Experts models. (arXiv:2310.12236v1 [cs.CL])

    [http://arxiv.org/abs/2310.12236](http://arxiv.org/abs/2310.12236)

    在这项工作中，我们研究了任务级MoE在直接神经机器翻译中的应用，并提出了一系列高性能的训练和评估配置，通过这些配置，任务级MoE的直接NMT系统在大量低资源语言对上优于双语和基于中间语言的模型。

    

    直接神经机器翻译（Direct NMT）是一种在两种非英语语言之间进行翻译的NMT系统。直接NMT系统通常面临由于非英语语言对之间平行数据稀缺导致的限制。已经提出了几种方法来解决这一限制，例如多语NMT和基于中间语言（通过英语进行翻译的NMT）的NMT。任务级混合专家模型（Task-level MoE）是一种基于Transformer模型的推理高效变体，对许多语言对展现了有前景的NMT性能。在任务级MoE中，不同的语言分组可以使用不同的路由策略来优化跨语言学习和推理速度。本文研究了任务级MoE在直接NMT中的适用性，并提出了一系列高性能的训练和评估配置，通过这些任务级MoE基础的直接NMT系统在大量低资源语言对上优于双语和基于中间语言的模型。

    Direct neural machine translation (direct NMT) is a type of NMT system that translates text between two non-English languages. Direct NMT systems often face limitations due to the scarcity of parallel data between non-English language pairs. Several approaches have been proposed to address this limitation, such as multilingual NMT and pivot NMT (translation between two languages via English). Task-level Mixture of expert models (Task-level MoE), an inference-efficient variation of Transformer-based models, has shown promising NMT performance for a large number of language pairs. In Task-level MoE, different language groups can use different routing strategies to optimize cross-lingual learning and inference speed. In this work, we examine Task-level MoE's applicability in direct NMT and propose a series of high-performing training and evaluation configurations, through which Task-level MoE-based direct NMT systems outperform bilingual and pivot-based models for a large number of low an
    
[^67]: ImageArg-2023概述：多模态论证挖掘中的首个共享任务

    Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining. (arXiv:2310.12172v1 [cs.CL])

    [http://arxiv.org/abs/2310.12172](http://arxiv.org/abs/2310.12172)

    ImageArg-2023是第一个多模态论证挖掘的共享任务，涵盖了论证立场分类和图像说服力分类两个子任务。共收到了来自6个国家的9个团队提交的31个子任务A的提交和21个子任务B的提交，最好的提交在子任务A中达到了0.8647的F1得分，在子任务B中达到了0.5561的F1得分。

    

    本文介绍了ImageArg共享任务的概述，这是第一个与EMNLP 2023 Argument Mining Workshop同时举办的多模态论证挖掘共享任务。该共享任务包括两个分类子任务：（1）子任务A：论证立场分类；（2）子任务B：图像说服力分类。前者确定了包含图像和一段文字的推文对于一个有争议的主题（如枪支控制和堕胎）的立场。后者确定图像是否使推文的文字更具说服力。共享任务共收到来自6个国家的9个不同团队提交的31个子任务A的提交和21个子任务B的提交。子任务A中最好的提交的F1得分为0.8647，而子任务B中最好的提交的F1得分为0.5561。

    This paper presents an overview of the ImageArg shared task, the first multimodal Argument Mining shared task co-located with the 10th Workshop on Argument Mining at EMNLP 2023. The shared task comprises two classification subtasks - (1) Subtask-A: Argument Stance Classification; (2) Subtask-B: Image Persuasiveness Classification. The former determines the stance of a tweet containing an image and a piece of text toward a controversial topic (e.g., gun control and abortion). The latter determines whether the image makes the tweet text more persuasive. The shared task received 31 submissions for Subtask-A and 21 submissions for Subtask-B from 9 different teams across 6 countries. The top submission in Subtask-A achieved an F1-score of 0.8647 while the best submission in Subtask-B achieved an F1-score of 0.5561.
    
[^68]: 从不一致到洞察：对案例结果分类的理由数据集构建进行解析

    From Dissonance to Insights: Dissecting Disagreements in Rationale Dataset Construction for Case Outcome Classification. (arXiv:2310.11878v1 [cs.CL])

    [http://arxiv.org/abs/2310.11878](http://arxiv.org/abs/2310.11878)

    本研究关注法律自然语言处理中人工标注的变异问题，通过收集一组律师对案件结果评估存在分歧的数据集，对这些分歧进行了研究，构建了一个两级分类体系，并发现分歧主要源于对法律背景的不明确描述。

    

    在法律自然语言处理中，案例结果分类（COC）不仅需要准确性，还需要可信赖性和可解释性。现有的可解释COC研究仅限于由单个专家进行的注释。然而，众所周知，律师在对案件事实进行评估时可能存在分歧。因此，我们收集了一个新的数据集RAVE：欧洲人权法领域的理由变异，该数据集是从国际人权法领域的两位专家那里获得的，我们观察到他们之间存在弱一致性。我们研究了他们的分歧，并构建了一个两级任务无关的分类体系，同时补充了COC特定的子类别。据我们所知，这是法律自然语言处理领域首次关注人工标注的变异。我们定量评估了不同分类类别，并发现分歧主要源于对法律背景的不明确描述，这在COC元数据通常具有有限细粒度和噪声的情况下带来了挑战。我们进一步评估了SOTA COC模型在RAVE数据集上的可解释性，并观察到...

    In legal NLP, Case Outcome Classification (COC) must not only be accurate but also trustworthy and explainable. Existing work in explainable COC has been limited to annotations by a single expert. However, it is well-known that lawyers may disagree in their assessment of case facts. We hence collect a novel dataset RAVE: Rationale Variation in ECHR1, which is obtained from two experts in the domain of international human rights law, for whom we observe weak agreement. We study their disagreements and build a two-level task-independent taxonomy, supplemented with COC-specific subcategories. To our knowledge, this is the first work in the legal NLP that focuses on human label variation. We quantitatively assess different taxonomy categories and find that disagreements mainly stem from underspecification of the legal context, which poses challenges given the typically limited granularity and noise in COC metadata. We further assess the explainablility of SOTA COC models on RAVE and observ
    
[^69]: 基于原型的超适配器用于样本高效多任务调整

    Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning. (arXiv:2310.11670v1 [cs.CL])

    [http://arxiv.org/abs/2310.11670](http://arxiv.org/abs/2310.11670)

    基于原型的超适配器（PHA）框架用于样本高效多任务调整，通过引入实例密集的检索器和样本高效的原型超网络生成条件模块，在多任务学习和少样本迁移学习中取得了可比性能的提升，甚至在数据量较小时也能超过其他强基线方法的性能。

    

    参数高效微调（PEFT）已经证明在适应预训练语言模型到下游任务时有效，同时只更新了少量参数。尽管取得了成功，大多数现有方法独立地适应每个任务，没有考虑任务之间的知识传输，并且受限于低数据情景。为了克服这个问题，我们提出了一种基于原型的超适配器（PHA）框架，该框架建立在适配器调整和超网络基础上。它引入了一个实例密集的检索器和一个样本高效的原型超网络来生成条件模块。这导致与现有PEFT方法在多任务学习和少样本迁移学习上相当的性能改进。更重要的是，当可用数据量变小时，我们的方法比其他强基线方法有很大的优势。基于我们在各种数据集上的广泛实证实验，我们证明了PHA在权衡方面取得了更好的结果。

    Parameter-efficient fine-tuning (PEFT) has shown its effectiveness in adapting the pre-trained language models to downstream tasks while only updating a small number of parameters. Despite the success, most existing methods independently adapt to each task without considering knowledge transfer between tasks and are limited to low-data regimes. To overcome this issue, we propose Prototype-based HyperAdapter (PHA), a novel framework built on the adapter-tuning and hypernetwork. It introduces an instance-dense retriever and a prototypical hypernetwork to generate the conditional modules in a sample-efficient manner. This leads to comparable performance improvements against existing PEFT methods on multi-task learning and few-shot transfer learning. More importantly, when the available data size gets smaller, our method outperforms other strong baselines by a large margin. Based on our extensive empirical experiments across various datasets, we demonstrate that PHA strikes a better trade-
    
[^70]: VECHR：欧洲人权法院漏洞类型的可解释和鲁棒分类数据集

    VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights. (arXiv:2310.11368v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.11368](http://arxiv.org/abs/2310.11368)

    VECHR是一个专家注释的多标签数据集，用于欧洲人权法院漏洞类型的可解释和鲁棒分类。该数据集帮助识别脆弱性，并提供解释理由。结果显示了该任务的挑战性，模型与专家的一致性有限，模型在处理域外数据时鲁棒性也较低。

    

    识别脆弱性对于了解和实施有针对性的支持以增强有需要的个人至关重要。这一点在欧洲人权法院尤为重要，法院将公约标准调整为满足实际个体需求，从而确保有效的人权保护。然而，脆弱性概念在欧洲人权法院仍然模糊不清，之前没有NLP研究涉及到这个问题。为了促进未来在这个领域的研究，我们提出了VECHR，一个新颖的专家注释的多标签数据集，包括脆弱性类型分类和解释理由。我们从预测和解释性的角度对VECHR上的最先进模型的性能进行了基准测试。我们的结果表明了这一任务的具有挑战性的特点，预测性能较低，并且模型和专家之间存在有限的一致性。此外，我们分析了这些模型处理域外数据的鲁棒性，并发现总体上受限。

    Recognizing vulnerability is crucial for understanding and implementing targeted support to empower individuals in need. This is especially important at the European Court of Human Rights (ECtHR), where the court adapts Convention standards to meet actual individual needs and thus ensures effective human rights protection. However, the concept of vulnerability remains elusive at the ECtHR and no prior NLP research has dealt with it. To enable future research in this area, we present VECHR, a novel expert-annotated multi-label dataset comprising of vulnerability type classification and explanation rationale. We benchmark the performance of state-of-the-art models on VECHR from both prediction and explainability perspectives. Our results demonstrate the challenging nature of the task with lower prediction performance and limited agreement between models and experts. Further, we analyze the robustness of these models in dealing with out-of-domain (OOD) data and observe overall limited per
    
[^71]: 用于打击虚假信息的人工智能技术的实验：IDMO项目

    Experimenting AI Technologies for Disinformation Combat: the IDMO Project. (arXiv:2310.11097v1 [cs.CL])

    [http://arxiv.org/abs/2310.11097](http://arxiv.org/abs/2310.11097)

    IDMO项目旨在使用人工智能技术打击虚假信息和假新闻，其贡献包括创建新型数据集、开发自动模型、评估GPT-4等。

    

    意大利数字媒体观察项目（IDMO）是欧洲一项倡议的一部分，专注于打击虚假信息和假新闻。本报告概述了Rai-CRITS在该项目中的贡献，包括：（i）创建用于测试技术的新型数据集，（ii）开发自动模型，用于分类Pagella Politica的裁决以便于更广泛的分析，（iii）创建自动模型，对FEVER数据集上的文本蕴含具有异常精度的识别能力，（iv）使用GPT-4评估文本蕴含， （v）在国家活动中开展提高对假新闻意识的游戏。

    The Italian Digital Media Observatory (IDMO) project, part of a European initiative, focuses on countering disinformation and fake news. This report outlines contributions from Rai-CRITS to the project, including: (i) the creation of novel datasets for testing technologies (ii) development of an automatic model for categorizing Pagella Politica verdicts to facilitate broader analysis (iii) creation of an automatic model for recognizing textual entailment with exceptional accuracy on the FEVER dataset (iv) assessment using GPT-4 to identify textual entailmen (v) a game to raise awareness about fake news at national events.
    
[^72]: BiomedJourney: 指导学习多模态患者旅程中的反事实生物医学图像生成

    BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys. (arXiv:2310.10765v1 [cs.CV])

    [http://arxiv.org/abs/2310.10765](http://arxiv.org/abs/2310.10765)

    提出了一种新颖的方法BiomedJourney，通过指导学习多模态患者旅程，进行反事实生物医学图像生成。使用GPT-4处理图像报告生成疾病进展的自然语言描述，并训练潜在扩散模型。

    

    随着自然语言指令图像编辑的指导学习取得了快速进展，如InstructPix2Pix，生物医学领域可以将这些方法应用于反事实图像生成，从而帮助区分因果结构和伪相关，并促进疾病进展建模的稳健图像解释。然而，通用的图像编辑模型并不适用于生物医学领域，反事实生物医学图像生成的研究还远未深入。在本文中，我们提出了一种新颖的方法BiomedJourney，通过指导学习多模态患者旅程，进行反事实生物医学图像生成。给定一个拍摄于不同时间点的两个生物医学图像的患者，我们使用GPT-4处理相应的图像报告，并生成疾病进展的自然语言描述。然后，使用生成的三元组（先前图像、进展描述、新图像）来训练一个潜在扩散模型。

    Rapid progress has been made in instruction-learning for image editing with natural-language instruction, as exemplified by InstructPix2Pix. In biomedicine, such methods can be applied to counterfactual image generation, which helps differentiate causal structure from spurious correlation and facilitate robust image interpretation for disease progression modeling. However, generic image-editing models are ill-suited for the biomedical domain, and counterfactual biomedical image generation is largely underexplored. In this paper, we present BiomedJourney, a novel method for counterfactual biomedical image generation by instruction-learning from multimodal patient journeys. Given a patient with two biomedical images taken at different time points, we use GPT-4 to process the corresponding imaging reports and generate a natural language description of disease progression. The resulting triples (prior image, progression description, new image) are then used to train a latent diffusion mode
    
[^73]: 超越文档边界的上下文预训练：语言模型

    In-Context Pretraining: Language Modeling Beyond Document Boundaries. (arXiv:2310.10638v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10638](http://arxiv.org/abs/2310.10638)

    本论文提出了一种超越文档边界的上下文预训练方法，通过在相关文档序列上训练语言模型，鼓励模型进行跨文档的阅读和推理。该方法通过改变文档顺序并应用现有的预训练管道来实现。

    

    目前，大型语言模型（LMs）通过预测给定文档前缀的标记来进行训练，从而能够直接进行长篇生成和提示式任务，这可以简化为文档完成。现有的预训练管道通过连接随机组合的短文档来训练LMs，以创建输入上下文，但前一个文档对于预测下一个文档没有提供任何信号。我们提出了一种新方法——上下文预训练，即在相关文档序列上预先训练语言模型，从而明确鼓励它们跨越文档边界进行阅读和推理。我们可以通过改变文档顺序，使每个上下文包含相关的文档，并直接应用现有的预训练管道来进行上下文预训练。然而，这个文档排序问题很具有挑战性。有数十亿个文档，我们希望在每个文档中最大化上下文相似性而不重复任何数据。

    Large language models (LMs) are currently trained to predict tokens given document prefixes, enabling them to directly perform long-form generation and prompting-style tasks which can be reduced to document completion. Existing pretraining pipelines train LMs by concatenating random sets of short documents to create input contexts but the prior documents provide no signal for predicting the next document. We instead present In-Context Pretraining, a new approach where language models are pretrained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. We can do In-Context Pretraining by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do
    
[^74]: VIBE：Twitter分类的主题驱动时间自适应

    VIBE: Topic-Driven Temporal Adaptation for Twitter Classification. (arXiv:2310.10191v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10191](http://arxiv.org/abs/2310.10191)

    VIBE是一种解决Twitter分类中语言特征演变问题的模型，通过建模潜在主题演变以适应动态环境，并且在大规模Twitter实验中展现了良好的性能。

    

    语言特征在现实世界的社交媒体中不断变化，导致文本分类在动态环境下的性能下降。为了解决这个挑战，我们研究了时间自适应，即在过去数据上训练的模型在未来进行测试。先前的大部分工作都集中在继续预训练或知识更新上，这可能会影响它们在噪声社交媒体数据上的性能。为了解决这个问题，我们通过建模潜在主题演变来反映特征变化，并提出了一种新的模型VIBE：Evolutions的变分信息瓶颈。具体而言，我们首先使用两个信息瓶颈(Bottleneck)正则化器来区分过去和未来的主题。然后，这些区分的主题通过时间戳和类别标签预测进行多任务训练，作为自适应特征。在自适应学习过程中，VIBE利用训练数据时间之后创建的在线流程中检索到的无标签数据。在三个分类任务的大规模Twitter实验中，我们的方法展示了良好的性能。

    Language features are evolving in real-world social media, resulting in the deteriorating performance of text classification in dynamics. To address this challenge, we study temporal adaptation, where models trained on past data are tested in the future. Most prior work focused on continued pretraining or knowledge updating, which may compromise their performance on noisy social media data. To tackle this issue, we reflect feature change via modeling latent topic evolution and propose a novel model, VIBE: Variational Information Bottleneck for Evolutions. Concretely, we first employ two Information Bottleneck (IB) regularizers to distinguish past and future topics. Then, the distinguished topics work as adaptive features via multi-task training with timestamp and class label prediction. In adaptive learning, VIBE utilizes retrieved unlabeled data from online streams created posterior to training data time. Substantial Twitter experiments on three classification tasks show that our mode
    
[^75]: 对大型语言模型在非分布式逻辑推理任务上的系统评估

    A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks. (arXiv:2310.09430v1 [cs.CL])

    [http://arxiv.org/abs/2310.09430](http://arxiv.org/abs/2310.09430)

    通过对大型语言模型在非分布式逻辑推理任务上进行系统评估，我们发现这些模型在处理我们新构建的数据集时都存在困难，尽管它们在其他自然语言处理任务上表现良好。这表明这些模型在逻辑推理方面的泛化和鲁棒性仍需要进一步研究。

    

    大型语言模型（LLMs），如GPT-3.5和GPT-4，已经将人工系统在各种自然语言处理任务上的性能提升到接近人类水平。然而，它们在逻辑推理方面的泛化和鲁棒性仍未得到充分评估。为了探索这种能力，我们提出了三个新的逻辑推理数据集，分别名为"ReClor-plus"、"LogiQA-plus"和"LogiQAv2-plus"，每个数据集都包含三个子集：第一个是选项随机打乱，第二个是将正确选项替换为"没有其他选项是正确的"，第三个是前两个子集的组合。我们在这些数据集上进行了实验，使用了鉴别和生成型的LLMs，并表明这些简单的技巧极大地阻碍了语言模型的性能。尽管在原始的公开可用数据集上表现出优秀的性能，但我们发现所有模型都很难回答我们新构建的数据集。我们展示了通过扰动引入任务变化可以提高模型的性能。

    Large language models (LLMs), such as GPT-3.5 and GPT-4, have greatly advanced the performance of artificial systems on various natural language processing tasks to human-like levels. However, their generalisation and robustness to perform logical reasoning remain under-evaluated. To probe this ability, we propose three new logical reasoning datasets named "ReClor-plus", "LogiQA-plus" and "LogiQAv2-plus", each featuring three subsets: the first with randomly shuffled options, the second with the correct choices replaced by "none of the other options are correct", and a combination of the previous two subsets. We carry out experiments on these datasets with both discriminative and generative LLMs and show that these simple tricks greatly hinder the performance of the language models. Despite their superior performance on the original publicly available datasets, we find that all models struggle to answer our newly constructed datasets. We show that introducing task variations by perturb
    
[^76]: 为程序验证对LLM生成的循环不变式进行排名

    Ranking LLM-Generated Loop Invariants for Program Verification. (arXiv:2310.09342v1 [cs.PL])

    [http://arxiv.org/abs/2310.09342](http://arxiv.org/abs/2310.09342)

    本研究提出了一种针对LLM生成结果进行重新排名的方法，可以显著提高正确不变量的排名，从而减少程序验证的调用次数。

    

    合成归纳循环不变量是自动化程序验证的基础。我们观察到，大型语言模型（如gpt-3.5或gpt-4）能够在0-shot环境下为一类程序合成循环不变量，但需要多个样本才能生成正确的不变量。这可能导致大量调用程序验证器来建立不变性。为了解决这个问题，我们提出了一种对LLM生成结果进行重新排名的方法。我们设计了一个排名器，可以根据问题定义区分正确的归纳不变量和错误的尝试。该排名器经过对比排名优化。实验结果表明，这种重新排名机制显著提高了正确不变量在生成的候选项中的排名，从而大幅减少了对验证器的调用次数。

    Synthesizing inductive loop invariants is fundamental to automating program verification. In this work, we observe that Large Language Models (such as gpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of programs in a 0-shot setting, yet require several samples to generate the correct invariants. This can lead to a large number of calls to a program verifier to establish an invariant. To address this issue, we propose a {\it re-ranking} approach for the generated results of LLMs. We have designed a ranker that can distinguish between correct inductive invariants and incorrect attempts based on the problem definition. The ranker is optimized as a contrastive ranker. Experimental results demonstrate that this re-ranking mechanism significantly improves the ranking of correct invariants among the generated candidates, leading to a notable reduction in the number of calls to a verifier.
    
[^77]: 探索指导：通过主动探索增强特定领域指导覆盖率

    Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration. (arXiv:2310.09168v1 [cs.CL])

    [http://arxiv.org/abs/2310.09168](http://arxiv.org/abs/2310.09168)

    通过采用探索指导的方法，使用大型语言模型 (LLMs) 进行主动探索，增强了领域特定指导调优的数据覆盖范围，并取得了显著的性能提升。

    

    通过增强多样性，可以大幅优化指导调优，从而使模型能够处理更广泛的任务。然而，用于此类调优的现有数据往往对个别领域的覆盖不足，限制了对这些领域内细致理解和交互的范围。为了解决这个问题，我们提出了一种新颖的方法，称为探索指导，通过大型语言模型 (LLMs) 的主动探索来增强用于特定领域指导调优的数据覆盖。探索指导基于典型的领域使用案例，通过实现搜索算法来获取多样化和面向领域的指导调优数据的多种变体或可能性。我们的数据中心分析验证了此方法在改进特定领域指导覆盖范围方面的有效性。此外，我们模型的性能显示出与多个基线模型相比的显著进展。

    Instruction-tuning can be substantially optimized through enhanced diversity, resulting in models capable of handling a broader spectrum of tasks. However, existing data employed for such tuning often exhibit an inadequate coverage of individual domains, limiting the scope for nuanced comprehension and interactions within these areas. To address this deficiency, we propose Explore-Instruct, a novel approach to enhance the data coverage to be used in domain-specific instruction-tuning through active exploration via Large Language Models (LLMs). Built upon representative domain use cases, Explore-Instruct explores a multitude of variations or possibilities by implementing a search algorithm to obtain diversified and domain-focused instruction-tuning data. Our data-centric analysis validates the effectiveness of this proposed approach in improving domain-specific instruction coverage. Moreover, our model's performance demonstrates considerable advancements over multiple baselines, includi
    
[^78]: 使用思路链进行大型语言模型的少样本知识库问题生成

    Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation. (arXiv:2310.08395v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.08395](http://arxiv.org/abs/2310.08395)

    本文提出了一种使用思路链（CoT）对大型语言模型进行少样本知识库问题生成的方法，该方法将问题生成任务形式化为推理问题，并通过检索支持性逻辑形式和编写提示来实现生成过程。

    

    知识库问答生成（KBQG）的任务是将逻辑形式转化为自然语言问题。由于大规模问题注释的昂贵成本，在低资源场景下急需开发KBQG方法。然而，当前方法在少样本问题生成中过于依赖注释数据的微调，这对于少样本问题生成并不合适。大型语言模型（LLM）的出现展示了它们在少样本任务中的印象力泛化能力。受到思路链（CoT）提示的启发，这是一种用于推理的上下文学习策略，我们将KBQG任务形式化为推理问题，其中一个完整问题的生成被分为一系列的子问题生成。我们提出的提示方法KQG-CoT首先从未标记数据池中检索支持性的逻辑形式，考虑逻辑形式的特征。然后，我们编写一个提示来明确推理链的生成过程。

    The task of Question Generation over Knowledge Bases (KBQG) aims to convert a logical form into a natural language question. For the sake of expensive cost of large-scale question annotation, the methods of KBQG under low-resource scenarios urgently need to be developed. However, current methods heavily rely on annotated data for fine-tuning, which is not well-suited for few-shot question generation. The emergence of Large Language Models (LLMs) has shown their impressive generalization ability in few-shot tasks. Inspired by Chain-of-Thought (CoT) prompting, which is an in-context learning strategy for reasoning, we formulate KBQG task as a reasoning problem, where the generation of a complete question is splitted into a series of sub-question generation. Our proposed prompting method KQG-CoT first retrieves supportive logical forms from the unlabeled data pool taking account of the characteristics of the logical form. Then, we write a prompt to explicit the reasoning chain of generati
    
[^79]: ClimateNLP: 使用自然语言处理分析公众对气候变化的情感态度

    ClimateNLP: Analyzing Public Sentiment Towards Climate Change Using Natural Language Processing. (arXiv:2310.08099v1 [cs.CL])

    [http://arxiv.org/abs/2310.08099](http://arxiv.org/abs/2310.08099)

    本研究利用自然语言处理分析社交媒体上关于气候变化的推文情感态度，通过使用ClimateBERT模型量化情感，从而获得有关公众对气候变化的观点和反馈。

    

    气候变化对人类健康的影响带来了前所未有的挑战。除非采取基于确凿证据的积极措施，否则这些威胁很可能会升级，并继续威胁人类福祉。信息和通信技术的不断发展已经促进了社交媒体平台的广泛可用性和利用率。个人利用Twitter和Facebook等平台表达自己对各种主题的意见、想法和评论，包括紧迫的气候变化问题。社交媒体上与气候变化相关内容的激增需要进行全面分析以获得有意义的洞察。本论文利用自然语言处理技术分析气候变化话语，并量化与气候变化相关的推文的情感。我们使用ClimateBERT，这是一个专门针对气候变化领域进行了微调的预训练模型。目标是识别情感态度。

    Climate change's impact on human health poses unprecedented and diverse challenges. Unless proactive measures based on solid evidence are implemented, these threats will likely escalate and continue to endanger human well-being. The escalating advancements in information and communication technologies have facilitated the widespread availability and utilization of social media platforms. Individuals utilize platforms such as Twitter and Facebook to express their opinions, thoughts, and critiques on diverse subjects, encompassing the pressing issue of climate change. The proliferation of climate change-related content on social media necessitates comprehensive analysis to glean meaningful insights. This paper employs natural language processing (NLP) techniques to analyze climate change discourse and quantify the sentiment of climate change-related tweets. We use ClimateBERT, a pretrained model fine-tuned specifically for the climate change domain. The objective is to discern the sentim
    
[^80]: KwaiYiiMath: 技术报告

    KwaiYiiMath: Technical Report. (arXiv:2310.07488v1 [cs.CL])

    [http://arxiv.org/abs/2310.07488](http://arxiv.org/abs/2310.07488)

    KwaiYiiMath是一个用于增强数学推理能力的大型语言模型，通过应用监督微调和人类反馈强化学习，在英语和中文数学任务上取得了最先进的性能，并且能够正确解决生成的问题过程。

    

    近年来，大型语言模型（LLMs）在处理各种自然语言处理（NLP）下游任务方面展示出了显著的能力，甚至可以处理需要多步推理的数学任务。在本报告中，我们介绍了KwaiYiiMath，通过应用监督微调（SFT）和人类反馈强化学习（RLHF），增强了KwaiYiiBase1的数学推理能力，包括英语和中文的数学任务。同时，我们还构建了一个小规模的中小学数学测试集（命名为KMath），包含188个例子，用来评估模型生成的问题解决过程的正确性。实证研究表明，与类似规模的模型相比，KwaiYiiMath在GSM8k、CMath和KMath上均能取得最先进的性能（SOTA）。

    Recent advancements in large language models (LLMs) have demonstrated remarkable abilities in handling a variety of natural language processing (NLP) downstream tasks, even on mathematical tasks requiring multi-step reasoning. In this report, we introduce the KwaiYiiMath which enhances the mathematical reasoning abilities of KwaiYiiBase1, by applying Supervised Fine-Tuning (SFT) and Reinforced Learning from Human Feedback (RLHF), including on both English and Chinese mathematical tasks. Meanwhile, we also constructed a small-scale Chinese primary school mathematics test set (named KMath), consisting of 188 examples to evaluate the correctness of the problem-solving process generated by the models. Empirical studies demonstrate that KwaiYiiMath can achieve state-of-the-art (SOTA) performance on GSM8k, CMath, and KMath compared with the similar size models, respectively.
    
[^81]: Jaeger:一种基于连接的多变换器VQA模型

    Jaeger: A Concatenation-Based Multi-Transformer VQA Model. (arXiv:2310.07091v1 [cs.CL])

    [http://arxiv.org/abs/2310.07091](http://arxiv.org/abs/2310.07091)

    Jaeger是一种基于连接的多变换器VQA模型，利用RoBERTa large和GPT2-xl作为特征提取器，通过并行考虑多源信息来增强模型表征能力。

    

    基于文档的视觉问答在语言意义消歧和细粒度多模态检索之间提出了一个具有挑战性的任务。虽然由于大规模语言和开放世界先验模型的利用，文档问答取得了鼓舞人心的进展，但仍存在一些挑战，包括响应时间延长、推断持续时间延长和匹配不准确。为了克服这些挑战，我们提出了一种基于连接的多变换器VQA模型Jaegar。为了提取问题特征，我们利用了RoBERTa large和GPT2-xl等预训练模型的强大能力作为特征提取器。随后，我们将两种模型的输出进行连接操作。这个操作使得模型可以同时考虑来自不同来源的信息，增强了其表征能力。通过利用预训练模型进行特征提取，我们的方法有可能增强性能。

    Document-based Visual Question Answering poses a challenging task between linguistic sense disambiguation and fine-grained multimodal retrieval. Although there has been encouraging progress in document-based question answering due to the utilization of large language and open-world prior models\cite{1}, several challenges persist, including prolonged response times, extended inference durations, and imprecision in matching. In order to overcome these challenges, we propose Jaegar, a concatenation-based multi-transformer VQA model. To derive question features, we leverage the exceptional capabilities of RoBERTa large\cite{2} and GPT2-xl\cite{3} as feature extractors. Subsequently, we subject the outputs from both models to a concatenation process. This operation allows the model to consider information from diverse sources concurrently, strengthening its representational capability. By leveraging pre-trained models for feature extraction, our approach has the potential to amplify the pe
    
[^82]: CAW-coref: 关联词感知的词级共指消解

    CAW-coref: Conjunction-Aware Word-level Coreference Resolution. (arXiv:2310.06165v1 [cs.CL])

    [http://arxiv.org/abs/2310.06165](http://arxiv.org/abs/2310.06165)

    本文介绍了一种关联词感知的词级共指消解模型（CAW-coref），在处理并列提及的情况下表现出了较高的性能，有效地缩小了与昂贵的最先进方法的差距。

    

    当前最先进的共指消解系统每篇文章需要多次调用语言模型，因此对于许多应用场景来说（例如使用大规模语料库进行信息提取），代价太高。而词级共指系统 (WL-coref) 在效率上更加高效，实现了这些最先进系统 96.6% 的性能。本文发现了 WL-coref 的一个常见但重要的失败案例：处理“Tom 和 Mary”之类的并列提及。我们提供了一个简单但有效的解决方案，在 OntoNotes 测试集上将性能提高了 0.9% F1，将高效的词级共指消解与昂贵的最先进方法的差距缩小了34.6%。我们的关联词感知的词级共指模型（CAW-coref）和代码可在 https://github.com/KarelDO/wl-coref 获取。

    State-of-the-art coreference resolutions systems depend on multiple LLM calls per document and are thus prohibitively expensive for many use cases (e.g., information extraction with large corpora). The leading word-level coreference system (WL-coref) attains 96.6% of these SOTA systems' performance while being much more efficient. In this work, we identify a routine yet important failure case of WL-coref: dealing with conjoined mentions such as 'Tom and Mary'. We offer a simple yet effective solution that improves the performance on the OntoNotes test set by 0.9% F1, shrinking the gap between efficient word-level coreference resolution and expensive SOTA approaches by 34.6%. Our Conjunction-Aware Word-level coreference model (CAW-coref) and code is available at https://github.com/KarelDO/wl-coref.
    
[^83]: 使用上下文线索和角色相关性提升文档级事件论证提取

    Enhancing Document-level Event Argument Extraction with Contextual Clues and Role Relevance. (arXiv:2310.05991v1 [cs.CL])

    [http://arxiv.org/abs/2310.05991](http://arxiv.org/abs/2310.05991)

    本文提出了一个SCPRG模型，通过引入Span-Trigger-based Contextual Pooling(STCP)和Role-based Latent Information Guidance (RLIG)模块，解决了文档级事件论证中忽略的非论证上下文线索信息以及论证角色相关性的问题。模型通过自适应地选择和汇聚上下文中的非论证线索词，以及构建潜在的角色表示并捕捉语义相关性，显著提升了文档级事件论证的准确性。

    

    与句子级事件论证相比，文档级事件论证面临着长输入和跨句子推理的新挑战。然而，大多数之前的工作都集中在捕捉每个事件中候选论证与事件触发器之间的关系，忽略了两个关键点：a）非论证的上下文线索信息；b）论证角色之间的相关性。在本文中，我们提出了一个SCPRG（基于跨度触发器的上下文汇聚和潜在角色引导）模型，它包含两个新颖而有效的模块来解决上述问题。基于跨度触发器的上下文汇聚（STCP）根据预训练模型的上下文注意力权重，自适应地选择和汇聚非论证线索词的信息。基于角色的潜在信息引导（RLIG）模块构建潜在的角色表示，通过角色交互编码使它们相互作用以捕捉语义相关性，并将它们合并到候选论证中。

    Document-level event argument extraction poses new challenges of long input and cross-sentence inference compared to its sentence-level counterpart. However, most prior works focus on capturing the relations between candidate arguments and the event trigger in each event, ignoring two crucial points: a) non-argument contextual clue information; b) the relevance among argument roles. In this paper, we propose a SCPRG (Span-trigger-based Contextual Pooling and latent Role Guidance) model, which contains two novel and effective modules for the above problem. The Span-Trigger-based Contextual Pooling(STCP) adaptively selects and aggregates the information of non-argument clue words based on the context attention weights of specific argument-trigger pairs from pre-trained model. The Role-based Latent Information Guidance (RLIG) module constructs latent role representations, makes them interact through role-interactive encoding to capture semantic relevance, and merges them into candidate ar
    
[^84]: 宽松的嘴唇会使船沉没：减轻强化学习中的长度偏差问题

    Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback. (arXiv:2310.05199v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05199](http://arxiv.org/abs/2310.05199)

    本文提出了一种创新的解决方案，通过应用“专家的乘积”（PoE）技术来减轻强化学习中的长度偏差问题。在这个框架中，主要的专家关注理解人类意图，而偏见专家则致力于识别和捕捉长度偏差。

    

    人类反馈强化学习是重要的桥梁，将大型语言模型与人类和社会价值观对齐。这种对齐需要大量的人类反馈语料库来学习奖励模型，然后用于微调语言模型。然而，我们发现奖励模型常常会找到绕过预期目标的捷径，错误地假设人类更喜欢较长的回答。长度偏差的出现常常会导致模型倾向于较长的输出，但并不意味着这些输出中有更多有用的信息。在本文中，我们提出了一种创新的解决方案，应用了“专家的乘积”（PoE）技术来将奖励建模与序列长度的影响分离。在我们的框架中，主要的专家关注理解人类意图，而偏见专家则致力于识别和捕捉长度偏差。为了进一步增强偏见的学习，我们引入了扰动进入偏差部分。

    Reinforcement learning from human feedback serves as a crucial bridge, aligning large language models with human and societal values. This alignment requires a vast corpus of human feedback to learn a reward model, which is subsequently used to finetune language models. However, we have identified that the reward model often finds shortcuts to bypass its intended objectives, misleadingly assuming that humans prefer longer responses. The emergence of length bias often induces the model to favor longer outputs, yet it doesn't equate to an increase in helpful information within these outputs. In this paper, we propose an innovative solution, applying the Product-of-Experts (PoE) technique to separate reward modeling from the influence of sequence length. In our framework, the main expert concentrates on understanding human intents, while the biased expert targets the identification and capture of length bias. To further enhance the learning of bias, we introduce perturbations into the bia
    
[^85]: 循环神经语言模型作为概率有限状态自动机

    Recurrent Neural Language Models as Probabilistic Finite-state Automata. (arXiv:2310.05161v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05161](http://arxiv.org/abs/2310.05161)

    本文研究了循环神经网络语言模型（RNN LMs）作为概率有限状态自动机的能力，并发现它们只能表示有限状态模型所能表达的概率分布的一个严格子集。

    

    通过以容易理解的形式来研究语言模型（LMs）可以使我们精确地描述它们的能力和局限性。先前的研究已经考察了循环神经网络（RNN）语言模型在识别无权重形式语言的能力。然而，LMs并不描述无权重形式语言，而是定义了对字符串的概率分布。在本研究中，我们研究了RNN LMs可以表示哪些类的概率分布，这使得我们可以更直接地陈述它们的能力。我们证明了简单的RNN等价于概率有限状态自动机的一个子类，因此只能模拟有限状态模型所能表达的概率分布的一个严格子集。此外，我们研究了用RNNs表示有限状态LMs的空间复杂度。我们证明了，为了表示一个任意确定的有限状态LMs，其中有$N$个状态且字符集为$\Sigma$的RNN requir

    Studying language models (LMs) in terms of well-understood formalisms allows us to precisely characterize their abilities and limitations. Previous work has investigated the representational capacity of recurrent neural network (RNN) LMs in terms of their capacity to recognize unweighted formal languages. However, LMs do not describe unweighted formal languages -- rather, they define probability distributions over strings. In this work, we study what classes of such probability distributions RNN LMs can represent, which allows us to make more direct statements about their capabilities. We show that simple RNNs are equivalent to a subclass of probabilistic finite-state automata, and can thus model a strict subset of probability distributions expressible by finite-state models. Furthermore, we study the space complexity of representing finite-state LMs with RNNs. We show that, to represent an arbitrary deterministic finite-state LM with $N$ states over an alphabet $\Sigma$, an RNN requir
    
[^86]: 揭示多语言编码器的潜力：通过概率校准增强零-shot性能

    Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot Performance via Probability Calibration. (arXiv:2310.05069v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05069](http://arxiv.org/abs/2310.05069)

    通过概率校准方法，本研究通过结合校准技术和多语言编码器，解决了预训练模型对于频繁出现的标签词预测偏好的问题，并显著提高了零-shot性能。

    

    预训练的多语言编码器模型可以通过将输入示例重新转化为填空式提示，直接执行零-shot多语言任务或语言探测。这通过预测屏蔽标记位置的标签词的概率来完成，无需对模型参数进行任何更新。然而，这种方法的性能受到模型对于在预训练期间频繁出现的标签词预测偏好的限制。这些词通常获得较高的概率。为了解决这个问题，我们将模型与校准技术结合，修改模型预测的标签词的概率。首先，我们验证了一个提出的简单校准方法与其他已有技术在单语言编码器的零-shot和少样本情况下的有效性。随后，我们将这些校准技术应用于多语言编码器中，显著提高了性能。

    Pretrained multilingual encoder models can directly perform zero-shot multilingual tasks or linguistic probing by reformulating the input examples into cloze-style prompts. This is accomplished by predicting the probabilities of the label words at the masked token position, without requiring any updates to the model parameters. However, the performance of this method is limited by the model's bias toward predicting label words which frequently occurred during the pretraining. These words typically receive high probabilities. To address this issue, we combine the models with calibration techniques which modify the probabilities of label words predicted by the models. We first validate the effectiveness of a proposed simple calibration method together with other existing techniques on monolingual encoders in both zero- and few-shot scenarios. We subsequently employ these calibration techniques on multilingual encoders, resulting in substantial performance improvements across a wide range
    
[^87]: DQ-LoRe: 用于上下文学习的低秩近似双重查询重新排序

    DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning. (arXiv:2310.02954v1 [cs.CL])

    [http://arxiv.org/abs/2310.02954](http://arxiv.org/abs/2310.02954)

    本研究引入了DQ-LoRe框架，它通过双重查询和低秩近似重新排序自动选择用于上下文学习的示例，在复杂推理任务中展示了出色的性能和效果。

    

    最近自然语言处理领域的新进展，主要是由大型语言模型（LLMs）推动的，展示了它们在上下文学习方面的显著能力。在复杂推理任务中引导LLMs的一个有前途的途径是利用链式思维（CoT）范式中的中间推理步骤。然而，最主要的挑战在于有效地选择示例来促进上下文学习。在这项研究中，我们引入了一个框架，利用双重查询和低秩近似重新排序（DQ-LoRe）来自动选择用于上下文学习的示例。双重查询首先查询LLM以获取LLM生成的知识，例如CoT，然后通过问题和知识查询检索器以获取最终的示例。此外，对于第二个查询，LoRe利用降维技术来改进示例选择，确保与输入问题的知识密切对齐。通过广泛的实验验证了DQ-LoRe框架的有效性和性能。

    Recent advances in natural language processing, primarily propelled by Large Language Models (LLMs), have showcased their remarkable capabilities grounded in in-context learning. A promising avenue for guiding LLMs in intricate reasoning tasks involves the utilization of intermediate reasoning steps within the Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies in the effective selection of exemplars for facilitating in-context learning. In this study, we introduce a framework that leverages Dual Queries and Low-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars for in-context learning. Dual Queries first query LLM to obtain LLM-generated knowledge such as CoT, then query the retriever to obtain the final exemplars via both question and the knowledge. Moreover, for the second query, LoRe employs dimensionality reduction techniques to refine exemplar selection, ensuring close alignment with the input question's knowledge. Through extensive ex
    
[^88]: OceanGPT：用于海洋科学任务的大型语言模型

    OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v1 [cs.CL])

    [http://arxiv.org/abs/2310.02031](http://arxiv.org/abs/2310.02031)

    OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。

    

    海洋科学是探索充满生命和生物多样性的海洋的科学，考虑到海洋覆盖了地球表面的70％以上，这一领域具有重要意义。最近，大型语言模型（LLM）的进展改变了科学的范式。尽管在其他领域取得了成功，但现有的LLM通常无法满足海洋学家等领域专家的需求，同时对LLM在海洋科学中的潜力尚未得到充分探索。这其中的根本原因可能是海洋数据的庞大而复杂的性质，以及对更高的粒度和丰富的知识的需求。为了解决这些问题，我们推出了首个海洋领域的LLM——OceanGPT，该模型擅长各种海洋科学任务。我们提出了一个新颖的框架DoInstruct，用于自动获取大量的海洋领域指导数据，它基于多智能体的协作生成指导。

    Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge. To alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean domain, which is expert in various ocean science tasks. We propose DoInstruct, a novel framework to automatically obtain a large volume of ocean domain instruction data, which generates instructions based on multi-agent collaboration. Additionally, we construct the first oceanography benchmark, OceanBench,
    
[^89]: 大型语言模型评估的元语义模板

    Meta Semantic Template for Evaluation of Large Language Models. (arXiv:2310.01448v1 [cs.CL])

    [http://arxiv.org/abs/2310.01448](http://arxiv.org/abs/2310.01448)

    提出了一种通过创建元语义模板来评估大型语言模型（LLM）对语义理解能力的方法，该方法利用现有数据集生成新的超出分布（OOD）评估集。

    

    大型语言模型（LLM）是否真正理解语言的语义，还是仅仅记住训练数据？最近对LLM潜在数据污染的担忧引起了社区对LLM评估研究的关注。在本文中，我们提出了MSTemp，一种通过创建元语义模板来评估LLM对语义理解能力的方法。MSTemp的核心不是直接在现有基准数据集上进行评估，而是使用现有数据集作为种子生成新的超出分布（OOD）评估集。具体而言，对于给定的句子，MSTemp利用另一个语言模型生成新样本，同时保留其语义。这些新样本被称为原句子的语义模板。然后，MSTemp通过句子解析和随机替换词语来生成评估样本。MSTemp具有高度灵活、动态和成本效益性。我们的初步实验表明，MSTemp-

    Do large language models (LLMs) genuinely understand the semantics of the language, or just memorize the training data? The recent concern on potential data contamination of LLMs has raised awareness of the community to conduct research on LLMs evaluation. In this paper, we propose MSTemp, an approach that creates meta semantic templates to evaluate the semantic understanding ability of LLMs. The core of MSTemp is not to perform evaluation directly on existing benchmark datasets, but to generate new out-of-distribution (OOD) evaluation sets using existing datasets as seeds. Specifically, for a given sentence, MSTemp leverages another language model to generate new samples while preserving its semantics. The new samples are called semantic templates to the original sentence. Then, MSTemp generates evaluation samples via sentence parsing and random word replacement on the semantic templates. MSTemp is highly flexible, dynamic, and cost-effective. Our initial experiments show that MSTemp-
    
[^90]: 通过鉴别-批判差距测量语言模型对价值的理解

    Measuring Value Understanding in Language Models through Discriminator-Critique Gap. (arXiv:2310.00378v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00378](http://arxiv.org/abs/2310.00378)

    通过鉴别-批判差距测量LLMs对人类价值的理解，我们提出了价值理解测量（VUM）框架，并使用GPT-4开发了一个包含一千个对话的数据集。我们的评估结果显示，尺度定律对LLMs的“知道什么”有较大影响，而对“知道为什么”影响较小。

    

    最近大型语言模型（LLMs）的进展引发了对它们与人类价值观之间潜在不一致性的担忧。然而，由于它们的复杂和适应性，评估它们对这些价值观的理解是复杂的。我们认为真正理解LLMs中的价值观需要考虑到“知道什么”和“知道为什么”两个方面。为此，我们提出了价值理解测量（VUM）框架，通过量化鉴别-批判差距来定量评估“知道什么”和“知道为什么”。利用施瓦茨价值观调查，我们确定了评估价值观的标准，并使用GPT-4开发了一个包含一千个对话的数据集。我们的评估考察了LLMs的输出与基准答案之间的价值观一致性，以及LLMs的回答与GPT-4的注释在价值认知原因上的一致性。我们评估了五个代表性LLMs，并提供了强有力的证据表明，尺度定律对“知道什么”的影响较大，但对“知道为什么”的影响较小。

    Recent advancements in Large Language Models (LLMs) have heightened concerns about their potential misalignment with human values. However, evaluating their grasp of these values is complex due to their intricate and adaptable nature. We argue that truly understanding values in LLMs requires considering both "know what" and "know why". To this end, we present the Value Understanding Measurement (VUM) framework that quantitatively assess both "know what" and "know why" by measuring the discriminator-critique gap related to human values. Using the Schwartz Value Survey, we specify our evaluation values and develop a thousand-level dialogue dataset with GPT-4. Our assessment looks at both the value alignment of LLM's outputs compared to baseline answers and how LLM responses align with reasons for value recognition versus GPT-4's annotations. We evaluate five representative LLMs and provide strong evidence that the scaling law significantly impacts "know what" but not much on "know why", 
    
[^91]: NLPBench：评估大型语言模型解决NLP问题

    NLPBench: Evaluating Large Language Models on Solving NLP Problems. (arXiv:2309.15630v1 [cs.CL])

    [http://arxiv.org/abs/2309.15630](http://arxiv.org/abs/2309.15630)

    NLPBench是一个评估大型语言模型解决NLP问题的基准数据集，为填补该领域的研究空白，作者收集了来自耶鲁大学期末考试的378个涵盖多个NLP主题的问题。该研究发现在使用高级提示策略时，大型语言模型的性能可能不稳定，并可能对较小的模型造成负面影响。

    

    大型语言模型（LLMs）的最新发展显示出增强自然语言处理（NLP）能力的潜力。尽管取得了一些成功，但在LLMs的NLP问题解决能力方面仍然缺乏专门的研究。为了填补这个领域的空白，我们提出了一个独特的基准数据集NLPBench，包括378个涵盖各种NLP主题的大学水平NLP问题，这些问题源自耶鲁大学以前的期末考试。NLPBench包括具有上下文的问题，其中多个子问题分享相同的公共信息，并且包括多选题、简答题和数学题等多种问题类型。我们的评估以GPT-3.5/4、PaLM-2和LLAMA-2等LLMs为中心，采用了诸如链式思维（CoT）和思维树（ToT）等高级提示策略。我们的研究揭示了高级提示策略的有效性可能不一致，有时会损害LLMs的性能，特别是在较小的模型（LLA）中。

    Recent developments in large language models (LLMs) have shown promise in enhancing the capabilities of natural language processing (NLP). Despite these successes, there remains a dearth of research dedicated to the NLP problem-solving abilities of LLMs. To fill the gap in this area, we present a unique benchmarking dataset, NLPBench, comprising 378 college-level NLP questions spanning various NLP topics sourced from Yale University's prior final exams. NLPBench includes questions with context, in which multiple sub-questions share the same public information, and diverse question types, including multiple choice, short answer, and math. Our evaluation, centered on LLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting strategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study reveals that the effectiveness of the advanced prompting strategies can be inconsistent, occasionally damaging LLM performance, especially in smaller models like the LLA
    
[^92]: 角度优化的文本嵌入

    AnglE-Optimized Text Embeddings. (arXiv:2309.12871v1 [cs.CL])

    [http://arxiv.org/abs/2309.12871](http://arxiv.org/abs/2309.12871)

    本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。

    

    高质量的文本嵌入对于提升语义文本相似度（STS）任务至关重要，而这些任务又是大型语言模型（LLM）应用中的关键组成部分。然而，现有的文本嵌入模型面临的一个普遍挑战是渐变消失问题，主要是由于它们在优化目标中依赖余弦函数，而余弦函数具有饱和区域。为了解决这个问题，本文提出了一种称为AnglE的新型角度优化文本嵌入模型。AnglE的核心思想是在一个复杂空间中引入角度优化。这种新颖的方法有效地缓解了余弦函数饱和区域产生的不利影响，从而可以阻碍梯度并阻碍优化过程。为了建立全面的STS评估，我们在现有的短文本STS数据集和从GitHub Issues中新收集的长文本STS数据集上进行了实验。此外，我们还研究了具有有限标签数据的特定领域STS场景，并探讨了AnglE的工作原理。

    High-quality text embedding is pivotal in improving semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. However, a common challenge existing text embedding models face is the problem of vanishing gradients, primarily due to their reliance on the cosine function in the optimization objective, which has saturation zones. To address this issue, this paper proposes a novel angle-optimized text embedding model called AnglE. The core idea of AnglE is to introduce angle optimization in a complex space. This novel approach effectively mitigates the adverse effects of the saturation zone in the cosine function, which can impede gradient and hinder optimization processes. To set up a comprehensive STS evaluation, we experimented on existing short-text STS datasets and a newly collected long-text STS dataset from GitHub Issues. Furthermore, we examine domain-specific STS scenarios with limited labeled data and explore how AnglE works w
    
[^93]: 利用大型语言模型探索自我强化以改进学生生成的多项选择题解释

    Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models. (arXiv:2309.10444v1 [cs.AI])

    [http://arxiv.org/abs/2309.10444](http://arxiv.org/abs/2309.10444)

    本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。

    

    学生资源共享涉及学生生成和分享学习资源。在学生生成多项选择题时，创建解释是一个关键步骤，因为它有助于对相关概念的深入理解。然而，学生往往由于主题理解有限和仅仅重申问题、干扰因素和正确答案的倾向而难以编写有效的解释。为了帮助支撑这个任务，在这项工作中，我们提出了一个自我强化的大型语言模型框架，旨在自动生成和评估解释。该框架由三个模块组成，生成与学生对齐的解释，评估这些解释以确保其质量，并迭代增强解释。如果一个解释的评估分数低于定义的阈值，框架会迭代地优化和重新评估解释。重要的是，我们的框架模拟了一个学生学习的过程。

    Learnersourcing involves students generating and sharing learning resources with their peers. When learnersourcing multiple-choice questions, creating explanations for the generated questions is a crucial step as it facilitates a deeper understanding of the related concepts. However, it is often difficult for students to craft effective explanations due to limited subject understanding and a tendency to merely restate the question stem, distractors, and correct answer. To help scaffold this task, in this work we propose a self-reinforcement large-language-model framework, with the goal of generating and evaluating explanations automatically. Comprising three modules, the framework generates student-aligned explanations, evaluates these explanations to ensure their quality and iteratively enhances the explanations. If an explanation's evaluation score falls below a defined threshold, the framework iteratively refines and reassesses the explanation. Importantly, our framework emulates th
    
[^94]: CONFLATOR:将基于切换点的旋转位置编码纳入混合语言建模中

    CONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling. (arXiv:2309.05270v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05270](http://arxiv.org/abs/2309.05270)

    本论文提出了CONFLATOR：一种针对代码混合语言的神经语言建模方法，通过引入旋转位置编码和切换点信息，在混合语言建模中取得最佳结果。

    

    两种或多种语言的混合称为代码混合（CM）。 CM是多语言社会的社会规范。神经语言模型（NLMs）（如变压器）在许多自然语言处理任务上非常有效。然而，对于CM的NLM是一个未被充分探索的领域。尽管变压器具有能力，但由于它们是非递归的，它们不能始终编码位置信息。因此，为了丰富词的信息并纳入位置信息，定义了位置编码。我们假设转换点（SPs），即语言切换的文本中的交汇点（L1-> L2或L2-> L1），对CM语言模型（LMs）构成挑战，并对建模过程中SPs给予特别重视。我们尝试了几种位置编码机制，并表明旋转位置编码以及切换点信息可以获得最佳结果。我们引入CONFLATOR：一种针对混合语言的神经语言建模方法。

    The mixing of two or more languages is called Code-Mixing (CM). CM is a social norm in multilingual societies. Neural Language Models (NLMs) like transformers have been effective on many NLP tasks. However, NLM for CM is an under-explored area. Though transformers are capable and powerful, they cannot always encode positional information since they are non-recurrent. Therefore, to enrich word information and incorporate positional information, positional encoding is defined. We hypothesize that Switching Points (SPs), i.e., junctions in the text where the language switches (L1 -> L2 or L2 -> L1), pose a challenge for CM Language Models (LMs), and hence give special emphasis to SPs in the modeling process. We experiment with several positional encoding mechanisms and show that rotatory positional encodings along with switching point information yield the best results.  We introduce CONFLATOR: a neural language modeling approach for code-mixed languages. CONFLATOR tries to learn to empha
    
[^95]: 评估Transformer学习轻度上下文敏感语言的能力

    Evaluating Transformer's Ability to Learn Mildly Context-Sensitive Languages. (arXiv:2309.00857v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.00857](http://arxiv.org/abs/2309.00857)

    本文评估了Transformer学习轻度上下文敏感语言的能力，发现其在泛化到未见过的数据上表现良好，但在外推到较长字符串上的能力不如LSTMs。分析结果显示，Transformer学习到的自注意力模式和表示能够捕捉依赖关系并表现出计数行为。

    

    尽管Transformer在自然语言处理任务中表现出色，但最近的研究表明，自注意力在学习一些规则和无上下文语言方面在理论上存在限制。这些发现激发我们思考它们在建模自然语言中的影响，自然语言被假设为轻度上下文敏感。我们测试了Transformer学习多种复杂程度的轻度上下文敏感语言的能力，并发现它们在未见过的分布数据上具有良好的泛化能力，但其对于更长字符串的外推能力低于LSTMs。我们的分析显示，学习到的自注意力模式和表示模型化了依赖关系，并展示了计数行为，这可能有助于模型解决这些语言。

    Despite the fact that Transformers perform well in NLP tasks, recent studies suggest that self-attention is theoretically limited in learning even some regular and context-free languages. These findings motivated us to think about their implications in modeling natural language, which is hypothesized to be mildly context-sensitive. We test the Transformer's ability to learn mildly context-sensitive languages of varying complexities, and find that they generalize well to unseen in-distribution data, but their ability to extrapolate to longer strings is worse than that of LSTMs. Our analyses show that the learned self-attention patterns and representations modeled dependency relations and demonstrated counting behavior, which may have helped the models solve the languages.
    
[^96]: 为放射学构建通用基础模型的探索

    Towards Generalist Foundation Model for Radiology. (arXiv:2308.02463v1 [cs.CV])

    [http://arxiv.org/abs/2308.02463](http://arxiv.org/abs/2308.02463)

    本研究旨在为放射学构建通用基础模型，提出了一个大规模的医学多模态数据集和支持不同放射学任务的架构，同时提出了一个新的评估基准。

    

    本研究旨在启动放射学基础模型的开发，称为RadFM。我们从数据、模型设计和评估的角度全面考虑了基础模型的构建。我们的贡献可总结如下：（i）构建了一个大规模的医学多模态数据集MedMD，包括1600万个2D和3D医学扫描。据我们所知，这是第一个包含3D医学扫描的多模态数据集。（ii）我们提出了一种架构，使得可视条件生成预训练成为可能，可以将文本输入与2D或3D医学扫描交错，生成不同放射学任务的响应。该模型首先在MedMD上进行了预训练，然后在RadMD上进行了特定领域的微调，RadMD是MedMD的放射学清理版本，包含300万个放射学的视觉语言对。（iii）我们提出了一个新的评估基准，包括五个任务，旨在全面评估该模型的能力。

    In this study, we aim to initiate the development of Radiology Foundation Model, termed as RadFM.We consider the construction of foundational models from the perspectives of data, model design, and evaluation thoroughly. Our contribution can be concluded as follows: (i), we construct a large-scale Medical Multi-modal Dataset, MedMD, consisting of 16M 2D and 3D medical scans. To the best of our knowledge, this is the first multi-modal dataset containing 3D medical scans. (ii), We propose an architecture that enables visually conditioned generative pre-training, allowing for the integration of text input interleaved with 2D or 3D medical scans to generate response for diverse radiologic tasks. The model was initially pre-trained on MedMD and subsequently domain-specific fine-tuned on RadMD, a radiologic cleaned version of MedMD, containing 3M radiologic visual-language pairs. (iii), we propose a new evaluation benchmark that comprises five tasks, aiming to comprehensively assess the capa
    
[^97]: 一篇关于多模态深度学习在生物医学图像和文本中的扫描综述

    A scoping review on multimodal deep learning in biomedical images and texts. (arXiv:2307.07362v1 [cs.CV])

    [http://arxiv.org/abs/2307.07362](http://arxiv.org/abs/2307.07362)

    这篇综述旨在提供对多模态深度学习在生物医学图像和文本中进行联合学习的当前状况的全面概述，并探索未来的研究方向和该领域的研究空白。

    

    未来的计算辅助诊断和预后系统应该能够同时处理多模态数据。多模态深度学习（MDL）涉及多种数据源（如图像和文本）的整合，有潜力彻底改变生物医学数据的分析和解释。然而，这一领域直到最近才引起研究人员的注意。因此，有必要对这个主题进行系统综述，确定当前工作的局限性，并探索未来的方向。在这篇综述中，我们旨在提供对该领域 current state 的全面概述，并重点关注生物医学图像和文本的联合学习，主要是因为这两种数据类型在 MDL 研究中最常用。本研究回顾了多模态深度学习在五个任务中的当前应用：（1）报告生成，（2）视觉问答，（3）交叉...

    Computer-assisted diagnostic and prognostic systems of the future should be capable of simultaneously processing multimodal data. Multimodal deep learning (MDL), which involves the integration of multiple sources of data, such as images and text, has the potential to revolutionize the analysis and interpretation of biomedical data. However, it only caught researchers' attention recently. To this end, there is a critical need to conduct a systematic review on this topic, identify the limitations of current work, and explore future directions. In this scoping review, we aim to provide a comprehensive overview of the current state of the field and identify key concepts, types of studies, and research gaps with a focus on biomedical images and texts joint learning, mainly because these two were the most commonly available data types in MDL research. This study reviewed the current uses of multimodal deep learning on five tasks: (1) Report generation, (2) Visual question answering, (3) Cros
    
[^98]: Voicebox：大规模的多语言通用语音生成模型

    Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale. (arXiv:2306.15687v1 [eess.AS])

    [http://arxiv.org/abs/2306.15687](http://arxiv.org/abs/2306.15687)

    Voicebox是一种大规模的多语言通用语音生成模型，通过使用非自回归的流匹配模型，在文本和音频上下文条件下进行训练，可以实现零样本跨语言文本到语音合成，噪声去除，内容编辑，风格转换和多样化的样本生成等多种任务。

    

    大规模生成模型，如GPT和DALL-E已经改变了自然语言处理和计算机视觉研究的方式。这些模型不仅可以生成高质量的文本或图像输出，而且还是通用的，可以解决未被明确教授的任务。相比之下，语音生成模型在规模和任务通用化方面仍然比较原始。在本文中，我们介绍了Voicebox，这是最多功能的面向规模的文本引导生成模型。Voicebox是一个非自回归的流匹配模型，通过在音频上下文和文本条件下进行训练，用50,000小时的未经过滤或增强的语音进行填充。与GPT类似，Voicebox可以通过上下文学习执行多种不同的任务，但更加灵活，因为它还可以对未来的上下文进行条件约束。Voicebox可以用于单语或跨语言零样本的文本到语音合成，噪声去除，内容编辑，风格转换和多样化的样本生成。特别是，Voicebox

    Large-scale generative models such as GPT and DALL-E have revolutionized natural language processing and computer vision research. These models not only generate high fidelity text or image outputs, but are also generalists which can solve tasks not explicitly taught. In contrast, speech generative models are still primitive in terms of scale and task generalization. In this paper, we present Voicebox, the most versatile text-guided generative model for speech at scale. Voicebox is a non-autoregressive flow-matching model trained to infill speech, given audio context and text, trained on over 50K hours of speech that are neither filtered nor enhanced. Similar to GPT, Voicebox can perform many different tasks through in-context learning, but is more flexible as it can also condition on future context. Voicebox can be used for mono or cross-lingual zero-shot text-to-speech synthesis, noise removal, content editing, style conversion, and diverse sample generation. In particular, Voicebox 
    
[^99]: 基于Transformer的语言模型方法在中文发散性思维的自动评估中的应用——TransDis

    Automatic Assessment of Divergent Thinking in Chinese Language with TransDis: A Transformer-Based Language Model Approach. (arXiv:2306.14790v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.14790](http://arxiv.org/abs/2306.14790)

    TransDis是一个基于Transformer的语言模型评分系统，用于评估中文发散性思维的质量和多样性。经过实验证明，TransDis的评分能够有效地预测人工评分，具有与人工评分相似的效度。

    

    语言模型在自动创造力评估中越来越受欢迎，通过生成语义距离来客观地衡量创造性思维的质量。然而，目前缺乏一个针对中文创造性思维评估的自动化系统。为了填补这个空白，我们开发了TransDis，一个采用基于Transformer的语言模型的评分系统，能够为中文中的Alternate Uses Task（AUT）回答提供有效的独创性（质量）和灵活性（多样性）评分。研究1表明，由三个基于Transformer的模型组成的潜在模型评分的原创性因素强烈预测人工原创性评分，而模型评分的灵活性与人工灵活性评分也强相关。准则效度分析表明，模型评分的原创性和灵活性与其他创造力测量正相关，证明与人工评分具有相似的效度。研究2和3表明，TransDis能够快速、准确地评估中文发散性思维的特征。

    Language models have been increasingly popular for automatic creativity assessment, generating semantic distances to objectively measure the quality of creative ideas. However, there is currently a lack of an automatic assessment system for evaluating creative ideas in the Chinese language. To address this gap, we developed TransDis, a scoring system using transformer-based language models, capable of providing valid originality (quality) and flexibility (variety) scores for Alternative Uses Task (AUT) responses in Chinese. Study 1 demonstrated that the latent model-rated originality factor, comprised of three transformer-based models, strongly predicted human originality ratings, and the model-rated flexibility strongly correlated with human flexibility ratings as well. Criterion validity analyses indicated that model-rated originality and flexibility positively correlated to other creativity measures, demonstrating similar validity to human ratings. Study 2 & 3 showed that TransDis e
    
[^100]: 开发用户反馈的潜力：利用大型语言模型作为用户模拟器以增强对话系统

    Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulator to Enhance Dialogue System. (arXiv:2306.09821v1 [cs.CL])

    [http://arxiv.org/abs/2306.09821](http://arxiv.org/abs/2306.09821)

    该论文提出了一种名为用户引导响应优化（UGRO）的方法，使用大型语言模型作为无注释的用户模拟器，以评估对话响应并优化监督式经过微调的端到端任务导向对话模型。该方法利用了大型语言模型在提供满意度反馈方面的潜力，取得了显著的改进，为利用大型语言模型增强对话系统提供了新的思路。

    

    对话系统和大型语言模型（LLMs）已经引起了人们的极大关注。然而，与较小的任务特定模型相比，直接利用LLMs作为任务导向对话（TOD）模型的性能较差。尽管如此，承认LLMs的重大潜力并探索利用它们的惊人能力的改进方法非常重要。为了利用LLMs，我们提出了一种名为用户引导响应优化（UGRO）的替代方法，将LLM与较小的TOD模型结合起来。该方法使用LLM作为无注释的用户模拟器来评估对话响应，将其与较小的经过微调的端到端TOD模型相结合。通过利用LLMs生成的满意度反馈，UGRO进一步优化了监督式经过微调的TOD模型。具体而言，TOD模型以对话历史记录作为输入，并在用户模拟器反馈的帮助下生成符合用户需求的高满意度响应。实验结果表明，基于UGRO的方法相比现有最先进模型取得了显著的改进，为利用LLMs增强对话系统提供了洞察力。

    Dialogue systems and large language models (LLMs) have gained considerable attention. However, the direct utilization of LLMs as task-oriented dialogue (TOD) models has been found to underperform compared to smaller task-specific models. Nonetheless, it is crucial to acknowledge the significant potential of LLMs and explore improved approaches for leveraging their impressive abilities. Motivated by the goal of leveraging LLMs, we propose an alternative approach called User-Guided Response Optimization (UGRO) to combine it with a smaller TOD model. This approach uses LLM as annotation-free user simulator to assess dialogue responses, combining them with smaller fine-tuned end-to-end TOD models. By utilizing the satisfaction feedback generated by LLMs, UGRO further optimizes the supervised fine-tuned TOD model. Specifically, the TOD model takes the dialogue history as input and, with the assistance of the user simulator's feedback, generates high-satisfaction responses that meet the user
    
[^101]: WSPAlign: 大规模弱监督跨度预测下的词对齐预训练

    WSPAlign: Word Alignment Pre-training via Large-Scale Weakly Supervised Span Prediction. (arXiv:2306.05644v1 [cs.CL])

    [http://arxiv.org/abs/2306.05644](http://arxiv.org/abs/2306.05644)

    本文提出了一种名为WSPAlign的无需手动数据的预训练词对齐方法，通过用大规模弱监督数据中的跨度预测进行预训练，取得了比当前最佳方法更好的效果。

    

    大多数现有的词对齐方法依赖于手动对齐数据集或平行语料库，这限制了它们的实用性。为了缓解对手动数据的依赖，我们通过放宽对正确、完全对齐和平行句子的要求，扩大了监督数据的来源。具体而言，我们生成了带有噪声、部分对齐和非平行段落作为大规模弱监督数据集，通过跨度预测对词对齐进行预训练。广泛的实验表明，我们的方法名为WSPAlign，是一种有效且可扩展的无需手动数据的预训练词对齐方法。在标准基准测试中fine-tuning时，WSPAlign在F1和AER两个指标上的最佳监督基线分别提高了3.3~6.1和1.5~6.1个点，成为了新的最优结果。此外，WSPAlign在少样本、零样本和跨语言测试中也获得了与相应基线相同的竞争性能。

    Most existing word alignment methods rely on manual alignment datasets or parallel corpora, which limits their usefulness. Here, to mitigate the dependence on manual data, we broaden the source of supervision by relaxing the requirement for correct, fully-aligned, and parallel sentences. Specifically, we make noisy, partially aligned, and non-parallel paragraphs. We then use such a large-scale weakly-supervised dataset for word alignment pre-training via span prediction. Extensive experiments with various settings empirically demonstrate that our approach, which is named WSPAlign, is an effective and scalable way to pre-train word aligners without manual data. When fine-tuned on standard benchmarks, WSPAlign has set a new state-of-the-art by improving upon the best-supervised baseline by 3.3~6.1 points in F1 and 1.5~6.1 points in AER. Furthermore, WSPAlign also achieves competitive performance compared with the corresponding baselines in few-shot, zero-shot and cross-lingual tests, whi
    
[^102]: 使预训练模型具有可逆性：从参数到内存高效的微调

    Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v1 [cs.CL])

    [http://arxiv.org/abs/2306.00477](http://arxiv.org/abs/2306.00477)

    本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。

    

    预训练语言模型（PLM）的参数高效微调已经成为一种非常成功的方法，只需训练少量参数而不会降低性能，并随着PLM越来越大而成为事实上的学习范式。然而，现有的PEFT方法不具备内存效率，因为它们仍需要存储大部分中间激活值以便计算梯度，类似于微调。一个减少激活内存的有效方法是应用可逆模型，这样中间激活值就无需缓存，可以重新计算。然而，将PLM修改为它的可逆变体并进行PEFT并不是一件容易的事，因为可逆模型具有与当前发布的PLM不同的体系结构。本文首先调查现有PEFT方法成功的关键因素，认识到在初始化PEFT时保留PLM的起点是至关重要的。

    Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs) has emerged as a highly successful approach, with training only a small number of parameters without sacrificing performance and becoming the de-facto learning paradigm with the increasing size of PLMs. However, existing PEFT methods are not memory-efficient, because they still require caching most of the intermediate activations for the gradient calculation, akin to fine-tuning. One effective way to reduce the activation memory is to apply a reversible model, so the intermediate activations are not necessary to be cached and can be recomputed. Nevertheless, modifying a PLM to its reversible variant with PEFT is not straightforward, since the reversible model has a distinct architecture from the currently released PLMs. In this paper, we first investigate what is a key factor for the success of existing PEFT methods, and realize that it's essential to preserve the PLM's starting point when initializing a PEFT 
    
[^103]: NavGPT: 带有大型语言模型的视觉语言导航中的显式推理

    NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models. (arXiv:2305.16986v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.16986](http://arxiv.org/abs/2305.16986)

    NavGPT是基于LLM的导航智能体，可以在视觉语言导航（VLN）中，通过对文本描述进行推理，执行零-shot连续动作预测。该模型具有高级规划能力，可以将指令分解成子目标、整合常识知识以进行障碍物避免，并参考先前的步骤进行澄清。NavGPT展示了通用体现智能体发展的美好前景。

    

    大型语言模型（LLM）例如ChatGPT和GPT-4以前所未有的规模进行训练，从模型的扩展中展现出显著的推理能力。这种趋势强调了使用无限语言数据训练LLM的潜力，推动了通用体现智能体的发展。本文介绍了NavGPT，这是一个纯粹基于LLM的指令跟随导航智能体，通过为视觉语言导航（VLN）执行零-shot的连续动作预测，揭示了对于在复杂的现实场景下GPT模型的推理能力。在每一步中，NavGPT将视觉观察、导航历史和未来可探索方向的文本描述作为输入，推理出智能体的当前状态，并决定如何接近目标。通过全面的实验，我们证明了NavGPT可以明确地执行导航的高级规划，包括将指令分解成子目标、整合常识知识以进行障碍物避免，并参考先前的步骤进行澄清。我们的结果表明，LLM可能成为复杂顺序决策任务中的传统流程的强有力替代品，展示了通用体现智能体发展的美好前景。

    Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling. Such a trend underscored the potential of training LLMs with unlimited language data, advancing the development of a universal embodied agent. In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN). At each step, NavGPT takes the textual descriptions of visual observations, navigation history, and future explorable directions as inputs to reason the agent's current status, and makes the decision to approach the target. Through comprehensive experiments, we demonstrate NavGPT can explicitly perform high-level planning for navigation, including decomposing instruction into sub-goal, integrating commonsense k
    
[^104]: 通过词汇修剪实现高效的多语言语言模型压缩

    An Efficient Multilingual Language Model Compression through Vocabulary Trimming. (arXiv:2305.15020v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15020](http://arxiv.org/abs/2305.15020)

    该论文提出了一种名为词汇修剪（VT）的方法，通过删除多语言语言模型中的不相关标记，将其压缩为目标语言模型。实验证明，词汇修剪可以在保持多语言模型性能的同时，降低了模型的大小。

    

    多语言语言模型（LM）已经成为自然语言处理中非英语语言的强大工具。然而，由于涵盖不同语言标记的词汇嵌入矩阵较大，多语言LM的模型参数仍然很大。相反，单一语言模型可以使用特定于语言的词汇在目标语言中训练，但这需要大量预算和可靠语料库才能从头开始实现高质量的语言模型。在本文中，我们提出了词汇修剪（VT）的方法，通过从词汇中删除不相关的标记，将多语言LM的词汇减少到目标语言。理论上，VT可以压缩任何现有的多语言LM，以在多语言LM涵盖的任何语言中构建单一语言模型。在我们的实验中，我们展示了VT可以保留多语言LM的原始性能，同时尺寸更小（通常只需原始词汇大小的约50％）。

    Multilingual language model (LM) have become a powerful tool in NLP especially for non-English languages. Nevertheless, model parameters of multilingual LMs remain large due to the larger embedding matrix of the vocabulary covering tokens in different languages. On the contrary, monolingual LMs can be trained in a target language with the language-specific vocabulary only, but this requires a large budget and availability of reliable corpora to achieve a high-quality LM from scratch. In this paper, we propose vocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a target language by deleting irrelevant tokens from its vocabulary. In theory, VT can compress any existing multilingual LM to build monolingual LMs in any language covered by the multilingual LM. In our experiments, we show that VT can retain the original performance of the multilingual LM, while being smaller in size (in general around 50% of the original vocabulary size is enough) than the original mu
    
[^105]: RefGPT: GPT模型中基于参考的真实且可学习化的对话生成

    RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs and for GPTs. (arXiv:2305.14994v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14994](http://arxiv.org/abs/2305.14994)

    RefGPT是一种基于参考的对话生成方法，可以生成大量真实且定制化的对话，并解决了对话生成中的模型幻觉问题。

    

    ChatGPT等通用的聊天模型已经通过使用高质量指令数据调整大型语言模型（LLM）来解决各种NLP任务。然而，收集人类编写的高质量数据，尤其是多轮对话，对大多数人来说是昂贵且难以实现的。尽管以往的研究已经使用了强大的LLMs来自动生成对话，但由于LLMs存在幻觉，这些对话都无法完全真实。因此，我们提出了一种名为RefGPT的方法，可以生成大量真实且定制化的对话，而无需担心模型幻觉造成的事实错误。RefGPT通过限制LLMs使用给定参考而不是回忆自己的知识来生成对话，从而解决了对话生成中的模型幻觉。此外，RefGPT对每个话语都添加了详细的控制，使其具有高度定制化的能力，这是以往研究所忽略的。

    General chat models, like ChatGPT, have attained impressive capability to resolve a wide range of NLP tasks by tuning Large Language Models (LLMs) with high-quality instruction data. However, collecting human-written high-quality data, especially multi-turn dialogues, is expensive and unattainable for most people. Though previous studies have used powerful LLMs to generate the dialogues automatically, but they all suffer from generating untruthful dialogues because of the LLMs hallucination. Therefore, we propose a method called RefGPT to generate enormous truthful and customized dialogues without worrying about factual errors caused by the model hallucination. RefGPT solves the model hallucination in dialogue generation by restricting the LLMs to leverage the given reference instead of reciting their own knowledge to generate dialogues. Additionally, RefGPT adds detailed controls on every utterances to enable highly customization capability, which previous studies have ignored. On the
    
[^106]: BeamSearchQA: 大型语言模型是强大的零-shot QA求解器

    BeamSearchQA: Large Language Models are Strong Zero-Shot QA Solver. (arXiv:2305.14766v1 [cs.CL])

    [http://arxiv.org/abs/2305.14766](http://arxiv.org/abs/2305.14766)

    BeamSearchQA利用大型语言模型进行迭代式生成问题，以捕捉隐含知识并优化问答过程，在NQ和WebQ测试集上分别达到了71.7％和46.7％的F1分数，显着优于现有的最先进方法。

    

    开放领域的问答是一个关键任务，通常需要访问外部信息。现有方法通常采用单轮检索-阅读方法，首先检索相关文档，然后基于检索的信息回答问题。然而，在某些情况下，回答问题需要隐含的知识，这些知识不直接从问题本身中获得。在这项工作中，我们提出了一种新的问答流程，称为BeamSearchQA。我们的方法利用大规模语言模型（LLMs）迭代生成关于原始问题的新问题，实现迭代推理过程。通过迭代细化和扩展问题的范围，我们的方法旨在捕捉并利用可能无法通过检索直接获取的隐藏知识。我们在广泛使用的开放领域NQ和WebQ数据集上评估了我们的方法。实验结果表明，BeamSearchQA明显优于现有的最先进方法，在NQ和WebQ测试集上分别达到了71.7％和46.7％的F1分数。

    Open-domain question answering is a crucial task that often requires accessing external information. Existing methods typically adopt a single-turn retrieve-then-read approach, where relevant documents are first retrieved, and questions are then answered based on the retrieved information. However, there are cases where answering a question requires implicit knowledge that is not directly retrievable from the question itself. In this work, we propose a novel question-answering pipeline called eamSearchQA. Our approach leverages large language models(LLMs) to iteratively generate new questions about the original question, enabling an iterative reasoning process. By iteratively refining and expanding the scope of the question, our method aims to capture and utilize hidden knowledge that may not be directly obtainable through retrieval. We evaluate our approach on the widely-used open-domain NQ and WebQ datasets. The experimental results demonstrate that BeamSearchQA significantly outperf
    
[^107]: 这片土地是你我的土地：评估语言模型中的地缘政治偏见

    This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language Models. (arXiv:2305.14610v1 [cs.CL])

    [http://arxiv.org/abs/2305.14610](http://arxiv.org/abs/2305.14610)

    本文提出了地缘政治偏见的概念，并以领土争端为例，利用多语言、多选题的数据集BorderLines和几个定量指标分析语言模型响应中的地缘政治偏见现象。

    

    我们引入了地缘政治偏见的概念——即根据语言环境报道不同的地缘政治知识的倾向。我们以领土争端为案例进行了研究。例如，对于被广泛争议的南沙群岛，如果用中文问，LM是否更有可能说它们属于中国，而如果用塔加洛语问，则更有可能说它们属于菲律宾？为了评估是否存在这种偏见，我们首先从维基百科上收集了一组领土争端数据，然后将每个领土与一组多语言、多选题联系起来。这个数据集被称为BorderLines，它包括250个领土和45种语言的问题。我们将这些问题集提交给语言模型，并通过几个提出的定量指标分析它们的响应中地缘政治偏见。这些指标比较不同语言的回答以及实际的地缘政治情况。地缘政治偏见现象是一种独特的跨语言评估。

    We introduce the notion of geopolitical bias -- a tendency to report different geopolitical knowledge depending on the linguistic context. As a case study, we consider territorial disputes between countries. For example, for the widely contested Spratly Islands, would an LM be more likely to say they belong to China if asked in Chinese, vs. to the Philippines if asked in Tagalog? To evaluate if such biases exist, we first collect a dataset of territorial disputes from Wikipedia, then associate each territory with a set of multilingual, multiple-choice questions. This dataset, termed BorderLines, consists of 250 territories with questions in 45 languages. We pose these question sets to language models, and analyze geopolitical bias in their responses through several proposed quantitative metrics. The metrics compare between responses in different question languages as well as to the actual geopolitical situation. The phenomenon of geopolitical bias is a uniquely cross-lingual evaluation
    
[^108]: 弱监督学习在多模态预训练中的视觉关系

    Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining. (arXiv:2305.14281v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14281](http://arxiv.org/abs/2305.14281)

    本研究提出了两种弱监督学习方法在多模态预训练中学习视觉关系，通过转换视觉关系数据为结构化标题和遮罩关系预测，实现了从弱监督关系数据中学习多模态表示的有效性。

    

    最近在视觉与语言预训练中的研究中，调查了从目标检测数据中的监督信号，以学习更好、细粒度的多模态表示。在本研究中，我们进一步探讨了如何利用小规模的视觉关系数据进行监督。具体而言，我们提出了两种预训练方法来在多模态设置中对视觉实体进行语境化。通过言语化场景图，我们将视觉关系三元组转换为结构化标题，并将其作为额外的图像描述。通过遮罩关系预测，我们进一步鼓励将图像区域中的实体与视觉上遮罩的上下文进行关联。当应用于在大量Web数据上预训练的强基线模型时，对于粗粒度和细粒度任务的零样本评估显示了我们的方法在从弱监督关系数据中学习多模态表示方面的有效性。

    Recent work in vision-and-language pretraining has investigated supervised signals from object detection data to learn better, fine-grained multimodal representations. In this work, we take a step further and explore how we can tap into supervision from small-scale visual relation data. In particular, we propose two pretraining approaches to contextualise visual entities in a multimodal setup. With verbalised scene graphs, we transform visual relation triplets into structured captions, and treat them as additional image descriptions. With masked relation prediction, we further encourage relating entities from image regions with visually masked contexts. When applied to strong baselines pretrained on large amounts of Web data, zero-shot evaluations on both coarse-grained and fine-grained tasks show the efficacy of our methods in learning multimodal representations from weakly-supervised relations data.
    
[^109]: 为科学文献理解预训练多任务对比学习模型

    Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding. (arXiv:2305.14232v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14232](http://arxiv.org/abs/2305.14232)

    本论文提出了一个名为SciMult的多任务对比学习框架，旨在共享不同科学文献理解任务之间的通用知识，同时防止任务特定技能相互干扰。

    

    科学文献理解任务因其加速科学发现的潜力而受到关注。预训练语言模型通过对比学习在这些任务中显示出有效性。然而，跨多个异构任务共同利用预训练数据（例如，极限多标签论文分类、引文预测和文献搜索）仍然基本上未被探索。为弥合这一差距，我们提出了一个多任务对比学习框架SciMult，重点是促进不同科学文献理解任务之间的共享通用知识，同时防止任务特定技能相互干扰。具体来说，我们探索了两种技术-任务感知的特化和指令调整。前者采用了具有任务感知子层的多专家变压器架构；后者在输入文本之前添加了任务特定的指令以产生。

    Scientific literature understanding tasks have gained significant attention due to their potential to accelerate scientific discovery. Pre-trained language models (LMs) have shown effectiveness in these tasks, especially when tuned via contrastive learning. However, jointly utilizing pre-training data across multiple heterogeneous tasks (e.g., extreme multi-label paper classification, citation prediction, and literature search) remains largely unexplored. To bridge this gap, we propose a multi-task contrastive learning framework, SciMult, with a focus on facilitating common knowledge sharing across different scientific literature understanding tasks while preventing task-specific skills from interfering with each other. To be specific, we explore two techniques -task-aware specialization and instruction tuning. The former adopts a Mixture-of-Experts Transformer architecture with task-aware sub-layers; the latter prepends task-specific instructions to the input text so as to produce t
    
[^110]: 基于多语言词义关系图的低资源语言跨语言迁移学习

    Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs. (arXiv:2305.12818v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12818](http://arxiv.org/abs/2305.12818)

    基于无注释平行语料库，我们提出一种基于词义共存模式的多语言图方法，用于低资源语言的跨语言迁移学习。通过建立高质量的多语言嵌入，我们实现了高召回率的词义共存识别。

    

    在比较语言学中，词义共存指的是一个词汇形式传达两个或更多不同的意义的现象。现有的关于词义共存模式的工作基于注释的词汇表，限制了在自然语言处理中的可扩展性和实用性。相比之下，我们从未注释的平行语料库中直接识别了超过2,000个概念在1,335种语言中的词义共存模式。然后，我们提出了简单而有效的方法来建立基于词义共存模式的多语言图：ColexNet和ColexNet+。ColexNet的节点是概念，边是词义共存关系。在ColexNet+中，概念节点通过中间节点进行附加连接，每个中间节点代表1,334种语言中的一个ngram。我们使用ColexNet+训练高质量的多语言嵌入，称之为$\overrightarrow{\mbox{ColexNet+}}$，非常适合迁移学习。在实验中，我们首先展示了ColexNet在跨语言词义共存数据集CLICS上的高召回率。然后我们对建议的方法进行了评估...

    In comparative linguistics, colexification refers to the phenomenon of a lexical form conveying two or more distinct meanings. Existing work on colexification patterns relies on annotated word lists, limiting scalability and usefulness in NLP. In contrast, we identify colexification patterns of more than 2,000 concepts across 1,335 languages directly from an unannotated parallel corpus. We then propose simple and effective methods to build multilingual graphs from the colexification patterns: ColexNet and ColexNet+. ColexNet's nodes are concepts and its edges are colexifications. In ColexNet+, concept nodes are additionally linked through intermediate nodes, each representing an ngram in one of 1,334 languages. We use ColexNet+ to train $\overrightarrow{\mbox{ColexNet+}}$, high-quality multilingual embeddings that are well-suited for transfer learning. In our experiments, we first show that ColexNet achieves high recall on CLICS, a dataset of crosslingual colexifications. We then evalu
    
[^111]: 数据高效的结构化预测主动学习，针对部分注释和自训练

    Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training. (arXiv:2305.12634v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12634](http://arxiv.org/abs/2305.12634)

    我们提出了一种数据高效的结构化预测主动学习方法，利用部分注释和自训练来减少注释成本。我们利用部分注释选择最具信息量的子结构进行标注，并将自动预测结果作为未注释子结构的伪标签。我们通过使用错误估计器自适应地决定部分选择比例，有效地结合了这两种方法。在四个结构化预测任务的评估中，我们展示了使用自适应选择比例的部分注释和自训练组合可以降低注释成本。

    

    在这项工作中，我们提出了一种实用的方法，利用主动学习来减少结构化标签空间的注释成本。我们的方法利用部分注释，通过只选择最具信息量的子结构进行注释，从而减少结构化输出的标注成本。我们还利用自训练，将当前模型的自动预测作为未注释子结构的伪标签。有效地结合部分注释和自训练以减少注释成本的一个关键挑战是确定选择哪些子结构进行标注。为了解决这个挑战，我们采用了一个错误估计器，根据当前模型的能力自适应地决定部分选择比例。通过对四个结构化预测任务进行评估，我们展示了我们的部分注释和自训练组合在一个公平比较方案下，使用自适应选择比例，可以降低注释成本。

    In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that ta
    
[^112]: Logic-LM：通过符号求解器增强大型语言模型在准确逻辑推理方面的能力

    Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning. (arXiv:2305.12295v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12295](http://arxiv.org/abs/2305.12295)

    本文介绍了一种名为Logic-LM的新框架，它将大型语言模型与符号求解器结合起来，以提升在复杂逻辑问题上的推理能力。通过将自然语言问题转化为符号表达，并利用确定性符号求解器进行推理，我们的方法能够有效地改进准确逻辑推理。实验证明，Logic-LM在多个逻辑推理数据集上取得了显著的性能提升，并且相比使用标准提示或思维链提示，效果分别提高了39.2%和18.4%。这表明将大型语言模型与符号逻辑相结合是实现准确逻辑推理的一个有前途的方法。

    

    大型语言模型(LLMs)已经展示了人类一样的推理能力，但仍然在复杂的逻辑问题上遇到困难。本文提出了一种新颖的框架，Logic-LM，将LLMs与符号求解器集成，以改进逻辑问题的解决能力。我们的方法首先利用LLMs将自然语言问题转化为符号化表述。然后，确定性符号求解器对问题进行推理。我们还引入了自我完善模块，利用符号求解器的错误信息修正符号化表示。通过在五个逻辑推理数据集ProofWriter、PrOntoQA、FOLIO、LogicalDeduction和AR-LSAT上的实验证明了Logic-LM的有效性。平均而言，Logic-LM相比仅使用LLMs的标准提示可以显著提高39.2%的性能，相比使用LLMs的思维链提示可以提高18.4%的性能。我们的研究结果表明，通过将LLMs与符号逻辑相结合，Logic-LM为准确的逻辑推理提供了一个有前途的途径。

    Large Language Models (LLMs) have shown human-like reasoning abilities but still struggle with complex logical problems. This paper introduces a novel framework, Logic-LM, which integrates LLMs with symbolic solvers to improve logical problem-solving. Our method first utilizes LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem. We also introduce a self-refinement module, which utilizes the symbolic solver's error messages to revise symbolic formalizations. We demonstrate Logic-LM's effectiveness on five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO, LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant performance boost of 39.2% over using LLM alone with standard prompting and 18.4% over LLM with chain-of-thought prompting. Our findings suggest that Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for faithful logical r
    
[^113]: 伪代码指令提示

    Prompting with Pseudo-Code Instructions. (arXiv:2305.11790v1 [cs.CL])

    [http://arxiv.org/abs/2305.11790](http://arxiv.org/abs/2305.11790)

    本文研究了使用伪代码指令提示能否提高预训练语言模型的性能，实验证明使用伪代码提示可以在分类任务中提高7-16分，并相对改善12-38%。

    

    最近，使用自然语言指令提示已成为利用大型语言模型能力的一种流行方法。鉴于自然语言中的固有歧义，因此考虑使用更少歧义的提示样式，如伪代码提示，可能具有优势。本文探讨了通过伪代码指令提示是否有助于改善预训练语言模型的性能。我们手动创建了一个包含来自Super-NaturalInstructions数据集的132个不同任务的伪代码提示数据集，涵盖分类、QA和生成语言任务。使用这些伪代码提示以及它们的自然语言对应物，在两个LLM家族-BLOOM和CodeGen上研究它们的性能。我们的实验表明，使用伪代码指令提示会带来更好的结果，对于分类任务，F1分数平均增加（绝对值）7-16分，相对改善12-38%。

    Prompting with natural language instructions has recently emerged as a popular method of harnessing the capabilities of large language models. Given the inherent ambiguity present in natural language, it is intuitive to consider the possible advantages of prompting with less ambiguous prompt styles, such as the use of pseudo-code.  In this paper we explore if prompting via pseudo-code instructions helps improve the performance of pre-trained language models. We manually create a dataset of pseudo-code prompts for 132 different tasks spanning classification, QA and generative language tasks, sourced from the Super-NaturalInstructions dataset. Using these prompts along with their counterparts in natural language, we study their performance on two LLM families - BLOOM and CodeGen. Our experiments show that using pseudo-code instructions leads to better results, with an average increase (absolute) of 7-16 points in F1 scores for classification tasks and an improvement (relative) of 12-38% 
    
[^114]: TrueTeacher: 使用大语言模型学习事实一致性评估

    TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models. (arXiv:2305.11171v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.11171](http://arxiv.org/abs/2305.11171)

    TrueTeacher是一种使用大型语言模型生成合成数据来进行事实一致性评估的方法，相较于传统方法，TrueTeacher不依赖于人工编写的摘要，多语言特性，实验证明能够显著提升模型的性能。

    

    事实一致性评估通常使用自然语言推理模型进行，然而这些模型在评估摘要时取得的成功有限。以往的工作通过合成训练数据改进了此类模型。然而，这些数据通常基于扰动的人工编写摘要，与真实的模型生成摘要在特性上常常存在差异，并且对可能存在的事实错误的覆盖范围有限。另一方面，大型语言模型（LLM）最近在直接评估生成任务方面显示了有希望的结果，但计算开销过大，无法实际应用。出于对这些限制的动机，我们引入了TrueTeacher，一种使用LLM注释多样的模型生成摘要来生成合成数据的方法。与以往的工作不同，TrueTeacher不依赖于人工编写的摘要，并且具有多语言特性。在TRUE基准测试上的实验表明，使用我们的数据训练的学生模型在性能上远远超过了NLI模型和之前的工作。

    Factual consistency evaluation is often conducted using Natural Language Inference (NLI) models, yet these models exhibit limited success in evaluating summaries. Previous work improved such models with synthetic training data. However, the data is typically based on perturbed human-written summaries, which often differ in their characteristics from real model-generated summaries and have limited coverage of possible factual errors. Alternatively, large language models (LLMs) have recently shown promising results in directly evaluating generative tasks, but are too computationally expensive for practical use. Motivated by these limitations, we introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a LLM. Unlike prior work, TrueTeacher does not rely on human-written summaries, and is multilingual by nature. Experiments on the TRUE benchmark show that a student model trained using our data, substantially outperforms both the st
    
[^115]: CooK: 用模块化和协作知识赋能通用语言模型

    CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge. (arXiv:2305.09955v1 [cs.CL])

    [http://arxiv.org/abs/2305.09955](http://arxiv.org/abs/2305.09955)

    CooK是一种用于赋能通用语言模型的新颖框架，通过专门的语言模型和协作的知识贡献者，提供模块化、不断增长和多源的知识。在知识密集型任务中，CooK展现出了明显的性能提升。

    

    大型语言模型（LLM）越来越多地用于知识密集型任务和语境中。现有方法通过检索或生成知识提示来改善通用语言模型的知识能力，但它们未能反映知识丰富模型的两个关键属性：知识应该是模块化，不断增长，来自不同领域；知识获取和生成应该是协作的过程，其中各种利益相关者 contribue 新信息。为此，我们提出了 CooK，一种新颖的框架，可为通用大型语言模型提供模块化和协作来源的知识。我们首先介绍了专门的语言模型，即在广泛领域和来源上训练的自回归模型。这些专门的语言模型可以作为参数化的知识库，后来被提示生成通用的 LLM 的背景知识。然后，我们提出了三个知识过滤器，以动态选择适合给定上下文的知识源。最后，我们呈现了一个知识贡献者组件，使利益相关者能够轻松地为系统贡献特定于域的知识。我们展示了 CooK 在一组知识密集型任务上的有效性，显示出明显的超越现有技术的性能。

    Large language models (LLMs) are increasingly adopted for knowledge-intensive tasks and contexts. Existing approaches improve the knowledge capabilities of general-purpose LLMs through retrieval or generated knowledge prompting, but they fall short of reflecting two key properties of knowledge-rich models: knowledge should be modular, ever-growing, sourced from diverse domains; knowledge acquisition and production should be a collaborative process, where diverse stakeholders contribute new information. To this end, we propose CooK, a novel framework to empower general-purpose large language models with modular and collaboratively sourced knowledge. We first introduce specialized language models, autoregressive models trained on corpora from a wide range of domains and sources. These specialized LMs serve as parametric knowledge repositories that are later prompted to generate background knowledge for general-purpose LLMs. We then propose three knowledge filters to dynamically select an
    
[^116]: FactKB: 使用增强了事实知识的语言模型进行可推广事实评估

    FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge. (arXiv:2305.08281v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08281](http://arxiv.org/abs/2305.08281)

    FactKB是一种通用的事实性评估方法，使用增强了事实知识的语言模型进行预训练，并在不同领域的摘要生成中取得了最先进的性能。

    

    评估自动生成的摘要的事实一致性对于可靠的摘要系统的进步和应用至关重要。尽管近年来取得了一些进展，但现有的事实性评估模型仍然不够稳健，在新的领域中特别容易出现实体和关系错误。我们提出了一种简单的新方法FactKB，用于事实性评估，它可以在不同领域通用，尤其是在实体和关系方面。FactKB基于使用从外部知识库中提取的事实进行预训练的语言模型。我们引入了基于直接实体事实、基于实体辅助知识的事实以及通过知识库路径组合构建的事实三种互补的事实预训练目标。结果显示，得到的事实性评估模型在两个领域内的新闻摘要基准以及三个领域外的科学文献数据集上都取得了最先进的性能。

    Evaluating the factual consistency of automatically generated summaries is essential for the progress and adoption of reliable summarization systems. Despite recent advances, existing factuality evaluation models are not robust, being especially prone to entity and relation errors in new domains. We propose FactKB, a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations. FactKB is based on language models pretrained using facts extracted from external knowledge bases. We introduce three types of complementary factuality pretraining objectives based on direct entity facts, facts grounded in auxiliary knowledge about entities, and facts constructed compositionally through knowledge base walks. The resulting factuality evaluation model achieves state-of-the-art performance on two in-domain news summarization benchmarks as well as on three out-of-domain scientific literature datasets. Further analysis of Fact
    
[^117]: 应用基于生成式预训练自回归Transformer图神经网络的方法分析和发现新型蛋白质

    Generative Pretrained Autoregressive Transformer Graph Neural Network applied to the Analysis and Discovery of Novel Proteins. (arXiv:2305.04934v1 [q-bio.BM])

    [http://arxiv.org/abs/2305.04934](http://arxiv.org/abs/2305.04934)

    本研究使用基于语言模型的深度学习策略，在蛋白质建模中应用transformer和图卷积的结构预训练生成模型，进一步训练后能够设计具有特定性质的蛋白质，案例验证表明该方法可生成理想目标性质的蛋白质。

    

    本文报道了一种灵活的基于语言模型的深度学习策略，应用于解决蛋白质建模中的正向和反向问题，使用一个整合了transformer和图卷积的注意力神经网络结构，在因果多头图机制中实现预训练生成模型。该模型被用于预测二级结构内容（每个残基的水平和总体内容）、蛋白质可溶性和测序任务。进一步在反向任务上训练，该模型能够设计具有这些性质作为目标特征的蛋白质。该模型被制定为一个通用的框架，完全基于提示，可以为各种下游任务进行适应。我们发现添加额外任务会产生相互协同作用，使模型在整体性能上得到提高，超过仅在每个数据集上训练模型的可能性。案例研究用于验证该方法，生成具有理想目标性质，包括稳定性和可溶性的蛋白质，并进行实验性研究。

    We report a flexible language-model based deep learning strategy, applied here to solve complex forward and inverse problems in protein modeling, based on an attention neural network that integrates transformer and graph convolutional architectures in a causal multi-headed graph mechanism, to realize a generative pretrained model. The model is applied to predict secondary structure content (per-residue level and overall content), protein solubility, and sequencing tasks. Further trained on inverse tasks, the model is rendered capable of designing proteins with these properties as target features. The model is formulated as a general framework, completely prompt-based, and can be adapted for a variety of downstream tasks. We find that adding additional tasks yields emergent synergies that the model exploits in improving overall performance, beyond what would be possible by training a model on each dataset alone. Case studies are presented to validate the method, yielding protein designs
    
[^118]: 基于“梯度下降”与 beam search 的自动提示优化

    Automatic Prompt Optimization with "Gradient Descent" and Beam Search. (arXiv:2305.03495v1 [cs.CL])

    [http://arxiv.org/abs/2305.03495](http://arxiv.org/abs/2305.03495)

    在基于大型语言模型的自然语言处理中，使用梯度下降和 beam search 的自动提示优化方法可以自动改进提示，提高性能。

    

    大型语言模型（LLM）在通用智能方面展现了出色性能，但其能力仍高度依赖于手写的提示，需要大量的试错尝试。我们提出了一个简单而非参数化的解决方案——自动提示优化（APO），其灵感来自于使用数值梯度下降自动改进提示。

    Large Language Models (LLMs) have shown impressive performance as general purpose agents, but their abilities remain highly dependent on prompts which are hand written with onerous trial-and-error effort. We propose a simple and nonparametric solution to this problem, Automatic Prompt Optimization (APO), which is inspired by numerical gradient descent to automatically improve prompts, assuming access to training data and an LLM API. The algorithm uses minibatches of data to form natural language ``gradients'' that criticize the current prompt. The gradients are then ``propagated'' into the prompt by editing the prompt in the opposite semantic direction of the gradient. These gradient descent steps are guided by a beam search and bandit selection procedure which significantly improves algorithmic efficiency. Preliminary results across three benchmark NLP tasks and the novel problem of LLM jailbreak detection suggest that Automatic Prompt Optimization can outperform prior prompt editing 
    
[^119]: PEFT-Ref: 一种模块化的参考架构和类型，用于参数效率微调技术

    PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques. (arXiv:2304.12410v1 [cs.CL])

    [http://arxiv.org/abs/2304.12410](http://arxiv.org/abs/2304.12410)

    本文提出了PEFT-Ref参考架构，标准化了不同PEFT技术共享的方面，隔离了差异到特定位置和交互中，模块化的视图有助于比较不同技术及其效率和任务性能，并有助于更好地理解PEFT的基本原理。

    

    最近的参数效率微调(PEFT)技术旨在改善完全微调大型预训练语言模型(PLM)的高昂成本。随着不同的PEFT技术不断出现，对它们进行比较变得越来越困难，特别是在以下方面：(i)它们添加到PLM的结构和功能，(ii)不同类型和程度的效率改进，(iii)在不同的下游任务中的性能，以及(iv)结构和功能差异如何与效率和任务性能相关联。为了促进这样的比较，本文提出了一个参考框架，标准化了不同PEFT技术共享的方面，同时将差异隔离到与标准组件的特定位置和交互中。通过这个标准化和隔离差异的过程，出现了PEFT技术的模块化视图，不仅支持直接比较不同技术及其效率和任务性能，而且还有助于更好地理解PEFT的基本原理。所提出的参考架构称为PEFT-Ref，包括七个核心模块，每个模块都处理PEFT的特定方面，并可用作开发新PEFT技术和比较现有技术的指南。

    Recent parameter-efficient finetuning (PEFT) techniques aim to improve over the considerable cost of fully finetuning large pretrained language models (PLM). As different PEFT techniques proliferate, it is becoming difficult to compare them, in particular in terms of (i) the structure and functionality they add to the PLM, (ii) the different types and degrees of efficiency improvements achieved, (iii) performance at different downstream tasks, and (iv) how differences in structure and functionality relate to efficiency and task performance. To facilitate such comparisons, this paper presents a reference framework which standardises aspects shared by different PEFT techniques, while isolating differences to specific locations and interactions with the standard components. Through this process of standardising and isolating differences, a modular view of PEFT techniques emerges, supporting not only direct comparison of different techniques and their efficiency and task performance, but a
    
[^120]: MWE作为WSD：用词义消歧解决多词表达式识别问题

    MWE as WSD: Solving Multiword Expression Identification with Word Sense Disambiguation. (arXiv:2303.06623v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.06623](http://arxiv.org/abs/2303.06623)

    该论文提出了一种利用词义消歧来解决多词表达式识别问题的方法，并通过训练模型使用词义的描述和上下文信息来过滤候选项，从而显著提高了精确度。研究还引入了一种新的架构，通过双编码器进一步提高了MWE识别性能。

    

    最近的词义消歧（WSD）方法利用词义的描述（定义）来提高性能，同时使用输入上下文。在本研究中，我们证明这种方法可以用于多词表达式（MWE）的识别，通过训练模型使用描述和上下文信息来过滤基于规则的提取流程产生的MWE候选项。我们的方法显著提高了精确度，在DiMSUM数据集上的MWE识别中超过了现有技术1.9个F1分数，并在PARSEME 1.1英语数据集上实现了竞争结果。我们的模型还保留了大部分WSD性能，表明一个模型可以同时用于两个任务。最后，基于类似于用于WSD的双编码器的方法，我们引入了一种新颖的Poly-encoder架构，提高了MWE识别性能。

    Recent approaches to word sense disambiguation (WSD) utilize encodings of the sense gloss (definition), in addition to the input context, to improve performance. In this work we demonstrate that this approach can be adapted for use in multiword expression (MWE) identification by training models which use gloss and context information to filter MWE candidates produced by a rule-based extraction pipeline. Our approach substantially improves precision, outperforming the state-of-the-art in MWE identification on the DiMSUM dataset by up to 1.9 F1 points and achieving competitive results on the PARSEME 1.1 English dataset. Our models also retain most of their WSD performance, showing that a single model can be used for both tasks. Finally, building on similar approaches using Bi-encoders for WSD, we introduce a novel Poly-encoder architecture which improves MWE identification performance.
    
[^121]: 对比学习的视觉-语言模型的测试时分布归一化

    Test-Time Distribution Normalization for Contrastively Learned Vision-language Models. (arXiv:2302.11084v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11084](http://arxiv.org/abs/2302.11084)

    这篇论文介绍了一个针对对比学习的视觉-语言模型的测试时分布归一化的方法，解决了常见的点乘操作导致测试时信息丢失的问题，提高了模型在测试阶段的准确性和效率。

    

    视觉-语言对比学习的进展使得许多下游应用可以通过简单地对图像和文本表示进行点乘来高效准确地进行。最近提出的代表性方法之一是CLIP，由于其有效性已经得到了广泛的采用。CLIP使用InfoNCE损失进行训练，该损失同时考虑了正样本和负样本，以帮助学习更加稳健的表示空间。本文揭示了常见的下游实践——进行点乘仅仅是对优化目标的零阶近似，导致了测试时信息的丢失。直观上，由于模型是基于InfoNCE损失进行优化的，测试时的过程也应该保持一致。问题在于如何以一种计算高效的方式检索到任何负样本信息。为此，我们提出了一种测试时分布归一化的方法

    Advances in the field of vision-language contrastive learning have made it possible for many downstream applications to be carried out efficiently and accurately by simply taking the dot product between image and text representations. One of the most representative approaches proposed recently known as CLIP has garnered widespread adoption due to its effectiveness. CLIP is trained with an InfoNCE loss that takes into account both positive and negative samples to help learn a much more robust representation space. This paper reveals that the common downstream practice of taking a dot product is only a zeroth-order approximation of the optimization goal, resulting in a loss of information during test-time. Intuitively, since the model has been optimized based on the InfoNCE loss, test-time procedures should also be in alignment. The question lies in how one can retrieve any semblance of negative samples information during inference in a computationally efficient way. To this end, we prop
    
[^122]: PK-ICR: 基于角色和知识的互动上下文检索进行基于场景对话

    PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded Dialogue. (arXiv:2302.06674v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.06674](http://arxiv.org/abs/2302.06674)

    PK-ICR是一种基于角色和知识的互动上下文检索方法，可以在复杂的多场景对话中同时识别角色和知识。通过利用神经问答检索模型，该方法可以在较少的计算资源下实现检索，并且通过引入空-正向排名测试方法来提高排名性能。

    

    鉴别与对话系统相关的角色和知识对于基于场景的对话应答生成至关重要。然而，目前每个对话基本上都是孤立研究的，而最近的工作中引入了更实际的多场景对话任务。我们将角色和知识双上下文识别定义为为给定的对话同时识别角色和知识的任务，在复杂的多场景对话设置中可能具有提升重要性。我们开发了一种新的基于检索的检索方法，可以同时利用对话的所有上下文信息。我们的方法通过使用神经问答检索模型，需要较少的计算资源。我们进一步介绍了一种新的空-正向排名测试方法，用于衡量与数据增强相关的语义差异样本（即困难负样本）的排名性能。

    Identifying relevant persona or knowledge for conversational systems is critical to grounded dialogue response generation. However, each grounding has been mostly researched in isolation with more practical multi-context dialogue tasks introduced in recent works. We define Persona and Knowledge Dual Context Identification as the task to identify persona and knowledge jointly for a given dialogue, which could be of elevated importance in complex multi-context dialogue settings. We develop a novel grounding retrieval method that utilizes all contexts of dialogue simultaneously. Our method requires less computational power via utilizing neural QA retrieval models. We further introduce our novel null-positive rank test which measures ranking performance on semantically dissimilar samples (i.e. hard negatives) in relation to data augmentation.
    
[^123]: NNKGC: 用节点邻居改进知识图谱补全

    NNKGC: Improving Knowledge Graph Completion with Node Neighborhoods. (arXiv:2302.06132v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.06132](http://arxiv.org/abs/2302.06132)

    NNKGC是一种通过节点邻居进行知识图谱补全并引入边连接预测任务的框架，简单而有效，可以预测出可解释的结果。

    

    知识图谱补全旨在发现查询实体的缺失关系。目前的基于文本的模型利用实体名称和描述推断头实体和特定关系给定的尾实体。现有方法还考虑了头实体的邻居。然而，这些方法往往使用扁平结构模拟邻居，且仅限于1跳邻居。在这项工作中，我们提出了一种增强知识图谱补全的节点邻居框架。它利用图神经网络对头实体邻居进行多跳建模，以丰富头节点信息。此外，我们引入了额外的边连接预测任务来改进知识图谱补全。在两个公共数据集上的评估表明，该框架简单而有效。案例研究还表明，模型能够预测可解释的预测结果。

    Knowledge graph completion (KGC) aims to discover missing relations of query entities. Current text-based models utilize the entity name and description to infer the tail entity given the head entity and a certain relation. Existing approaches also consider the neighborhood of the head entity. However, these methods tend to model the neighborhood using a flat structure and are only restricted to 1-hop neighbors. In this work, we propose a node neighborhood-enhanced framework for knowledge graph completion. It models the head entity neighborhood from multiple hops using graph neural networks to enrich the head node information. Moreover, we introduce an additional edge link prediction task to improve KGC. Evaluation on two public datasets shows that this framework is simple yet effective. The case study also shows that the model is able to predict explainable predictions.
    
[^124]: IC3：通过委员会共识进行图像字幕生成

    IC3: Image Captioning by Committee Consensus. (arXiv:2302.01328v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.01328](http://arxiv.org/abs/2302.01328)

    "IC3: Image Captioning by Committee Consensus"引入了一种通过委员会共识生成图像字幕的方法，能够从多个注释者的视角捕捉高层细节，优于单个人生成的参考字幕，并在视觉描述方面取得了显著改进。

    

    如果你请一个人描述一幅图像，他们可能会用一千种不同的方式来描述。传统上，图像字幕生成模型被训练成生成一个“最佳”（与参考最相似）的图像字幕。然而，这样做会鼓励生成“信息贫乏”的字幕，并且只关注可能细节的一个子集，而忽略了场景中其他可能有用的信息。在这项工作中，我们引入了一种简单而新颖的方法："通过委员会共识进行图像字幕生成"（IC3），旨在生成一个能够从多个注释者的视角捕捉到高层细节的单个字幕。人类评价IC3生成的字幕至少与基准SOTA模型一样有帮助的情况占了三分之二以上，并且IC3可以将SOTA自动召回系统的性能提升高达84%，胜过单个人生成的参考字幕，并显示出在视觉描述方面相比于SOTA方法的显著改进。代码可通过https://davidmchan获取。

    If you ask a human to describe an image, they might do so in a thousand different ways. Traditionally, image captioning models are trained to generate a single "best" (most like a reference) image caption. Unfortunately, doing so encourages captions that are "informationally impoverished," and focus on only a subset of the possible details, while ignoring other potentially useful information in the scene. In this work, we introduce a simple, yet novel, method: "Image Captioning by Committee Consensus" (IC3), designed to generate a single caption that captures high-level details from several annotator viewpoints. Humans rate captions produced by IC3 at least as helpful as baseline SOTA models more than two thirds of the time, and IC3 can improve the performance of SOTA automated recall systems by up to 84%, outperforming single human-generated reference captions, and indicating significant improvements over SOTA approaches for visual description. Code is available at https://davidmchan.
    
[^125]: 在波形域中使用离散自监督单元进行语音风格转换

    Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units. (arXiv:2212.09730v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2212.09730](http://arxiv.org/abs/2212.09730)

    DISSC是一种新颖、轻量级的语音风格转换方法，它可以以无需文本的方式将录音的节奏、音高轮廓和音色转换为目标说话者的风格。该方法使用自监督模型编码语音为离散单元，具有简单、有效且快速的训练过程，适用于无配对数据的多对多语音转换。

    

    我们介绍了一种名为DISSC的新颖、轻量级的方法，它可以以无需文本的方式将录音的节奏、音高轮廓和音色转换为目标说话者的风格。与DISSC不同，大多数语音转换（VC）方法主要关注音色，并忽略人们独特的说话风格（韵律）。所提出的方法使用预训练的自监督模型将语音编码为离散单元，使得训练简单、有效且快速。所有的转换模块仅在重建任务上进行训练，因此适用于无配对数据的多对多语音转换。我们介绍了一套定量和定性评估指标，并通过实验证明DISSC在这个设置下明显优于评估基线。代码和样例可在https://pages.cs.huji.ac.il/adiyoss-lab/dissc/ 上找到。

    We introduce DISSC, a novel, lightweight method that converts the rhythm, pitch contour and timbre of a recording to a target speaker in a textless manner. Unlike DISSC, most voice conversion (VC) methods focus primarily on timbre, and ignore people's unique speaking style (prosody). The proposed approach uses a pretrained, self-supervised model for encoding speech to discrete units, which makes it simple, effective, and fast to train. All conversion modules are only trained on reconstruction like tasks, thus suitable for any-to-many VC with no paired data. We introduce a suite of quantitative and qualitative evaluation metrics for this setup, and empirically demonstrate that DISSC significantly outperforms the evaluated baselines. Code and samples are available at https://pages.cs.huji.ac.il/adiyoss-lab/dissc/.
    
[^126]: 一种用于知识图谱链接预测的检索和阅读框架

    A Retrieve-and-Read Framework for Knowledge Graph Link Prediction. (arXiv:2212.09724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09724](http://arxiv.org/abs/2212.09724)

    这项研究提出了一种检索和阅读框架来解决现有知识图谱链接预测系统的局限性。通过首先检索相关子图上下文，然后使用高容量阅读器联合推理上下文和查询，该框架能够提供更有用的信息和更强大的表达能力。

    

    知识图谱链接预测旨在根据知识图谱中的现有事实推断出新的事实。最近的研究表明，通过图神经网络（GNNs）使用节点的图邻域提供了比仅使用查询信息更有用的信息。传统的KG链接预测的GNNs遵循整个KG上的标准消息传递范式，这导致了冗余计算、节点表示的过度平滑以及限制了它们的表达能力。在大规模上，从整个KG中聚合有用的信息进行推理变得计算上昂贵。为了解决现有KG链接预测框架的局限性，我们提出了一种新颖的检索和阅读框架，该框架首先检索与查询相关的子图上下文，然后通过高容量阅读器联合推理上下文和查询。作为我们新框架的实例化的一部分，我们提出了一种基于Transformer的GNN作为r的新方法。

    Knowledge graph (KG) link prediction aims to infer new facts based on existing facts in the KG. Recent studies have shown that using the graph neighborhood of a node via graph neural networks (GNNs) provides more useful information compared to just using the query information. Conventional GNNs for KG link prediction follow the standard message-passing paradigm on the entire KG, which leads to superfluous computation, over-smoothing of node representations, and also limits their expressive power. On a large scale, it becomes computationally expensive to aggregate useful information from the entire KG for inference. To address the limitations of existing KG link prediction frameworks, we propose a novel retrieve-and-read framework, which first retrieves a relevant subgraph context for the query and then jointly reasons over the context and the query with a high-capacity reader. As part of our exemplar instantiation for the new framework, we propose a novel Transformer-based GNN as the r
    
[^127]: 大型语言模型是带有自我验证的推理器

    Large Language Models are reasoners with Self-Verification. (arXiv:2212.09561v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.09561](http://arxiv.org/abs/2212.09561)

    本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。

    

    当大型语言模型（LLM）通过思维链（CoT）进行复杂推理时，它非常敏感于个别错误。为了解决这个问题，我们必须训练验证器。我们提出一种称为自我验证的新方法，该方法使用CoT的结论作为条件来构建一个新样本，并要求LLM重新预测被掩盖的原始条件。我们基于准确性计算可解释的验证分数。该方法可以在使用少量样本学习时提高多个算术和逻辑推理数据集的准确性。我们已经证明LLM可以对其自己的结论进行可解释的自我验证并实现竞争性的推理性能。全面的实验表明，我们的方法可以帮助多种带有自我验证功能的大型语言模型避免混淆。

    When a large language model (LLM) performs complex reasoning by chain of thought (CoT), it can be highly sensitive to individual mistakes. We have had to train verifiers to address this issue. As we all know, after human inferring a conclusion, they often check it by re-verifying it, which can avoid some mistakes. We propose a new method called self-verification that uses the conclusion of the CoT as a condition to build a new sample and asks the LLM to re-predict the original conditions which be masked. We calculate an explainable verification score based on the accuracy. This method can improve the accuracy of multiple arithmetics and logical reasoning datasets when using few-shot learning. we have demonstrated that LLMs can conduct explainable self-verification of their own conclusions and achieve competitive reasoning performance. Extensive experimentals have demonstrated that our method can help multiple large language models with self-verification can avoid interference from inco
    
[^128]: 利用对比学习和数字证据改进混淆的法律判决预测

    Exploiting Contrastive Learning and Numerical Evidence for Improving Confusing Legal Judgment Prediction. (arXiv:2211.08238v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08238](http://arxiv.org/abs/2211.08238)

    本文提出了一种利用对比学习和数字证据的方法改进混淆的法律判决预测。通过提出一种监督对比学习方法和利用数字证据预测处罚期限，成功地解决了区分分类错误和利用数字的问题。

    

    鉴于一个法律案例的事实描述文本，法律判决预测（LJP）旨在预测案例的罪名、法律条款和处罚期限。LJP的一个核心问题是如何区分混淆的法律案例，其中只存在微妙的文本差异。以往的研究在使用标准的交叉熵分类损失无法区分不同的分类错误，并忽略了事实描述中的数字，用于预测处罚期限。为了解决这些问题，本文首先提出了一种基于moco的监督对比学习，以学习可区分的表示，并探索构建正例对的最佳策略，从而同时有利于LJP的三个子任务。其次，为了利用法律案例中的数字来预测某些案例的处罚期限，我们进一步增强了由预训练数值模型编码的提取的犯罪金额对事实描述的表示。对公开数据集进行了大量实验。

    Given the fact description text of a legal case, legal judgment prediction (LJP) aims to predict the case's charge, law article and penalty term. A core problem of LJP is how to distinguish confusing legal cases, where only subtle text differences exist. Previous studies fail to distinguish different classification errors with a standard cross-entropy classification loss, and ignore the numbers in the fact description for predicting the term of penalty. To tackle these issues, in this work, first, we propose a moco-based supervised contrastive learning to learn distinguishable representations, and explore the best strategy to construct positive example pairs to benefit all three subtasks of LJP simultaneously. Second, in order to exploit the numbers in legal cases for predicting the penalty terms of certain cases, we further enhance the representation of the fact description with extracted crime amounts which are encoded by a pre-trained numeracy model. Extensive experiments on public 
    
[^129]: 强化学习和赌博机在语音和自然语言处理中的应用: 教程，回顾和展望

    Reinforcement Learning and Bandits for Speech and Language Processing: Tutorial, Review and Outlook. (arXiv:2210.13623v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.13623](http://arxiv.org/abs/2210.13623)

    这篇综述调查了强化学习和赌博机在语音和自然语言处理中的最新进展，讨论了如何有效利用它们解决相关问题，构建适应性、交互性和可扩展性的模型。

    

    最近几年，强化学习和赌博机已经在包括医疗保健，金融，推荐系统，机器人以及语音和自然语言处理等广泛的实际应用中发生了转变。虽然大部分强化学习算法在语音和语言处理领域的应用主要集中于利用其灵活的优化属性提高深度神经网络的训练，但仍有许多研究空间可以利用强化学习的好处，比如基于奖励驱动的适应性、状态表示、时间结构和通用性。在本文中，我们提出了强化学习和赌博机的最新进展综述，并讨论了如何有效地利用它们来解决语音和自然语言处理问题，构建适应性、交互性和可扩展性的模型。

    In recent years, reinforcement learning and bandits have transformed a wide range of real-world applications including healthcare, finance, recommendation systems, robotics, and last but not least, the speech and natural language processing. While most speech and language applications of reinforcement learning algorithms are centered around improving the training of deep neural networks with its flexible optimization properties, there are still many grounds to explore to utilize the benefits of reinforcement learning, such as its reward-driven adaptability, state representations, temporal structures and generalizability. In this survey, we present an overview of recent advancements of reinforcement learning and bandits, and discuss how they can be effectively employed to solve speech and natural language processing problems with models that are adaptive, interactive and scalable.
    
[^130]: 能否通过脑信号揭示人类语言的内部一致性？

    Can Brain Signals Reveal Inner Alignment with Human Languages?. (arXiv:2208.06348v4 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2208.06348](http://arxiv.org/abs/2208.06348)

    本研究探索了脑信号和人类语言之间的关系，并介绍了一种名为MTAM的方法，该方法在情感分析和关系检测等下游应用中取得了新的最先进结果。

    

    脑信号（如脑电图）和人类语言在许多下游任务中被广泛研究，但二者之间的联系尚未得到很好的探索。本研究探讨了脑电图和语言之间的关系和依赖性。在表示层面上，我们引入了一种名为MTAM（Multimodal Transformer Alignment Model）的方法，用于观察这两种模态之间的协调表示。我们使用了多种关系对齐技术，如典型相关分析和Wasserstein距离，作为损失函数来转换特征。在情感分析和关系检测等下游应用中，我们在ZuCo和K-EmoCon两个数据集上实现了新的最先进结果。我们的方法在情感分析方面使K-EmoCon数据集的F1分数提高了1.7％，ZuCo数据集提高了9.3％，在关系检测方面ZuCo数据集提高了7.4％。此外，我们提供了国际上最大的人类类比推理数据集的编码方案。

    Brain Signals, such as Electroencephalography (EEG), and human languages have been widely explored independently for many downstream tasks, however, the connection between them has not been well explored. In this study, we explore the relationship and dependency between EEG and language. To study at the representation level, we introduced \textbf{MTAM}, a \textbf{M}ultimodal \textbf{T}ransformer \textbf{A}lignment \textbf{M}odel, to observe coordinated representations between the two modalities. We used various relationship alignment-seeking techniques, such as Canonical Correlation Analysis and Wasserstein Distance, as loss functions to transfigure features. On downstream applications, sentiment analysis and relation detection, we achieved new state-of-the-art results on two datasets, ZuCo and K-EmoCon. Our method achieved an F1-score improvement of 1.7% on K-EmoCon and 9.3% on Zuco datasets for sentiment analysis, and 7.4% on ZuCo for relation detection. In addition, we provide inter
    
[^131]: 学习通过学习交流来进行翻译

    Learning to translate by learning to communicate. (arXiv:2207.07025v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.07025](http://arxiv.org/abs/2207.07025)

    本研究提出了一种利用紧急通信（EC）和预先训练的多语言模型的技术，通过基于视觉任务激励模型来改进资源匮乏语言的非监督NMT系统。实验证明，在四种语言中，其中包括了资源匮乏的尼泊尔语，我们的方法优于仅使用回译的基准模型。

    

    我们提出并测试了一种技术，利用紧急通信（EC）和预先训练的多语言模型，改进了现代非监督NMT系统，特别是对于资源匮乏的语言。已有观点认为，当前在NLP领域主导地位的文本预训练模型无法产生稳健的自然语言理解系统，并突出了对基于目标、目标导向和交互式语言学习的需求。在我们的方法中，我们将多语言模型（mBART，Liu等，2020）嵌入到一个EC图像参考游戏中，模型被激励使用多语言生成来完成一个基于视觉的任务。我们的假设是，这将使多种语言对齐到一个共享的任务空间。我们提出了两种EC微调的变体（Steinert-Threlkeld等人，2022），其中一种在包括资源匮乏的尼泊尔语在内的四种语言中都优于仅使用回译的基准模型。

    We formulate and test a technique to use Emergent Communication (EC) with a pre-trained multilingual model to improve on modern Unsupervised NMT systems, especially for low-resource languages. It has been argued that the current dominant paradigm in NLP of pre-training on text-only corpora will not yield robust natural language understanding systems, and the need for grounded, goal-oriented, and interactive language learning has been high lighted. In our approach, we embed a multilingual model (mBART, Liu et al., 2020) into an EC image-reference game, in which the model is incentivized to use multilingual generations to accomplish a vision-grounded task. The hypothesis is that this will align multiple languages to a shared task space. We present two variants of EC Fine-Tuning (Steinert-Threlkeld et al., 2022), one of which outperforms a backtranslation-only baseline in all four languages investigated, including the low-resource language Nepali.
    
[^132]: Dict-TTS: 利用先前的字典知识学习发音以用于文本到语音系统

    Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech. (arXiv:2206.02147v3 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2206.02147](http://arxiv.org/abs/2206.02147)

    本论文提出了Dict-TTS模型，利用在线字典作为先前信息来解决多音字消歧问题。通过设计语义到发音注意力模块，该模型能够在没有注释的情况下自动匹配文本语义和字典中的语义模式，并生成相应的发音，使得高质量的文本到语音系统能够更容易地扩展到不同领域和语言。

    

    多音字消歧旨在从自然文本序列中获取准确的发音知识，以构建可靠的文本到语音系统。然而，以往的方法需要大量的注释训练数据和语言专家的额外努力，使得难以将高质量的神经网络语音合成系统扩展到日常对话和全球各种语言中。本文从简洁而新颖的角度解决了多音字消歧问题：我们提出了Dict-TTS，这是一个语义感知的生成文本到语音模型，利用在线网站字典（即自然语言中已存在的先前信息）。具体来说，我们设计了一个语义到发音注意力（S2PA）模块，用于匹配输入文本序列与字典中先前语义之间的语义模式，并获取相应的发音；S2PA模块可以轻松地与端到端的语音合成模型一起训练，而无需任何注释的音素标签。

    Polyphone disambiguation aims to capture accurate pronunciation knowledge from natural text sequences for reliable Text-to-speech (TTS) systems. However, previous approaches require substantial annotated training data and additional efforts from language experts, making it difficult to extend high-quality neural TTS systems to out-of-domain daily conversations and countless languages worldwide. This paper tackles the polyphone disambiguation problem from a concise and novel perspective: we propose Dict-TTS, a semantic-aware generative text-to-speech model with an online website dictionary (the existing prior information in the natural language). Specifically, we design a semantics-to-pronunciation attention (S2PA) module to match the semantic patterns between the input text sequence and the prior semantics in the dictionary and obtain the corresponding pronunciations; The S2PA module can be easily trained with the end-to-end TTS model without any annotated phoneme labels. Experimental 
    
[^133]: 使用基于句子嵌入的词义归纳自动构建WordNet

    Automatic WordNet Construction using Word Sense Induction through Sentence Embeddings. (arXiv:2204.03251v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.03251](http://arxiv.org/abs/2204.03251)

    本文提出了一种使用无标签语料库和基于句子嵌入的语言模型自动构建WordNet的方法。通过这种方法，我们生成了一个新的WordNet（FilWordNet），以替代并改进菲律宾语中过时的WordNet，并且不需要人工监督。

    

    语言资源如WordNet对于不同的自然语言任务和应用至关重要。然而，对于低资源语言（如菲律宾语），现有的WordNet过时且不完整，并且生成新的WordNet可能需要大量的时间和资源。本文提出了一种使用无标签语料库和基于句子嵌入的语言模型自动构建WordNet的方法。我们通过这种方法，生成了一个新的WordNet（FilWordNet），以替代并改进菲律宾语中过时的WordNet。通过将我们自动诱导出的词义和词汇集与Princeton WordNet中的词义进行匹配，以及将词汇集与旧的菲律宾语WordNet进行比较，我们对其进行了评估。经验证明，我们的方法可以自动诱导现有的词义和词汇集，也可以潜在地自动诱导新的词义和词汇集，并且不需要人工监督。

    Language resources such as wordnets remain indispensable tools for different natural language tasks and applications. However, for low-resource languages such as Filipino, existing wordnets are old and outdated, and producing new ones may be slow and costly in terms of time and resources. In this paper, we propose an automatic method for constructing a wordnet from scratch using only an unlabeled corpus and a sentence embeddings-based language model. Using this, we produce FilWordNet, a new wordnet that supplants and improves the outdated Filipino WordNet. We evaluate our automatically-induced senses and synsets by matching them with senses from the Princeton WordNet, as well as comparing the synsets to the old Filipino WordNet. We empirically show that our method can induce existing, as well as potentially new, senses and synsets automatically without the need for human supervision.
    
[^134]: 基于示例的超网络用于领域外泛化

    Example-based Hypernetworks for Out-of-Distribution Generalization. (arXiv:2203.14276v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.14276](http://arxiv.org/abs/2203.14276)

    本文提出了一个基于示例的超网络框架，利用多个源领域的标记数据来进行领域外泛化。该框架通过生成输入示例的唯一签名，并将其嵌入源领域的语义空间中，并利用超网络生成任务分类器的权重。实验结果表明，该方法在29个适应场景中表现优于现有算法，且在输入示例的表示上具有丰富性。同时，与少样本GPT-3进行了比较，证明了其有效性。

    

    随着自然语言处理(NLP)算法不断突破新的里程碑，领域外泛化仍然是一个重大挑战。本文解决了对于陌生领域的多源适应问题：我们利用来自多个源领域的标记数据，在训练中泛化到未知目标领域。我们的创新性框架采用基于示例的超网络适应：一个T5编码-解码器首先从输入示例中生成一个唯一的签名，并将其嵌入到源领域的语义空间中。然后，这个签名被一个超网络利用来生成任务分类器的权重。我们在29种适应场景中评估了我们的方法，涉及情感分类和自然语言推理两个任务，在这些场景中，我们的方法超过了已有算法。在高级版本中，签名还丰富了输入示例的表示。我们还将我们的微调架构与少样本GPT-3进行了比较，证明了其有效性。

    As Natural Language Processing (NLP) algorithms continually achieve new milestones, out-of-distribution generalization remains a significant challenge. This paper addresses the issue of multi-source adaptation for unfamiliar domains: We leverage labeled data from multiple source domains to generalize to unknown target domains at training. Our innovative framework employs example-based Hypernetwork adaptation: a T5 encoder-decoder initially generates a unique signature from an input example, embedding it within the source domains' semantic space. This signature is subsequently utilized by a Hypernetwork to generate the task classifier's weights. We evaluated our method across two tasks - sentiment classification and natural language inference - in 29 adaptation scenarios, where it outpaced established algorithms. In an advanced version, the signature also enriches the input example's representation. We also compare our finetuned architecture to few-shot GPT-3, demonstrating its effectiv
    
[^135]: Bhasacitra: 南亚方言地理可视化

    Bhasacitra: Visualising the dialect geography of South Asia. (arXiv:2105.14082v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2105.14082](http://arxiv.org/abs/2105.14082)

    Bhasacitra是一个用于南亚的方言地理可视化系统，除了能够进行特征映射外，还可以作为南亚语言学家的互动参考书。

    

    我们介绍了Bhasacitra，这是一个基于南亚语言学研究数据库的方言映射系统，该数据库带有主题和位置数据的注释。我们通过可视化示例数据集，分析语言覆盖并展望其在类型学中的应用。这个应用不仅对功能映射有用，还作为一种新型的互动参考书，为南亚语言学家提供帮助。

    We present Bhasacitra, a dialect mapping system for South Asia built on a database of linguistic studies of languages of the region annotated for topic and location data. We analyse language coverage and look towards applications to typology by visualising example datasets. The application is not only meant to be useful for feature mapping, but also serves as a new kind of interactive bibliography for linguists of South Asian languages.
    

