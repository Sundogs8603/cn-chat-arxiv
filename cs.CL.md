# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Calibrating LLM-Based Evaluator.](http://arxiv.org/abs/2309.13308) | 这篇论文提出了AutoCalibrate，一种多阶段、无梯度的方法，用于自动校准和调整基于LLM的评估器以符合人类偏好。通过在少样本示例上进行上下文学习，该方法隐含地包括人类偏好，并通过选择最佳表现者和自我完善来进一步校准评分标准。 |
| [^2] | [OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis.](http://arxiv.org/abs/2309.13297) | OATS数据集是一个全新的观点方面目标情感四元组抽取数据集，它解决了面向方面的情感分析中的领域限制和数据粒度挑战，并填补了餐馆和笔记本电脑等常见领域的数据不足和句子与评论级情感之间的协同作用问题。 |
| [^3] | [Natural Language Processing for Requirements Formalization: How to Derive New Approaches?.](http://arxiv.org/abs/2309.13272) | 本论文介绍了自然语言处理在需求形式化中的应用和最新方法，以及其在生成规范模型中起到的作用。 |
| [^4] | [A Survey of Document-Level Information Extraction.](http://arxiv.org/abs/2309.13249) | 本文综述了近期文档级信息抽取的研究进展，发现标注误差、实体共指解析和推理的缺乏是限制文档级IE性能的主要因素，为进一步增强文档级IE性能提供了启示。 |
| [^5] | [ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education.](http://arxiv.org/abs/2309.13243) | 这项研究介绍了ChEDDAR，一个在EFL写作教育中应用的学生-ChatGPT对话数据集。该研究分析了学生对生成型AI的使用模式和感知，并为教育背景下的任务导向对话系统建立了基准结果。 |
| [^6] | [User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue.](http://arxiv.org/abs/2309.13233) | 提出了一种使用大型语言模型进行用户模拟的方法，用于评估任务导向对话系统。通过在上下文中学习，可以生成具有鲁棒性和语言多样性的输出，模拟人类对话参与者的行为。目标是使系统的成功率与人类和任务导向对话系统的交互相似。 |
| [^7] | [NJUNLP's Participation for the WMT2023 Quality Estimation Shared Task.](http://arxiv.org/abs/2309.13230) | NJUNLP团队对WMT2023质量评估共享任务进行了投稿，通过使用伪数据方法和核心超参数的实验研究，他们的模型在英德语言对的质量预测和错误跨度检测上取得了最佳结果。 |
| [^8] | [Hindi to English: Transformer-Based Neural Machine Translation.](http://arxiv.org/abs/2309.13222) | 本文使用Transformer模型开发了一种基于神经网络的印度语Hindi到英文的机器翻译系统，并通过回译和不同的分词方法提升了翻译质量。 |
| [^9] | [A Practical Survey on Zero-shot Prompt Design for In-context Learning.](http://arxiv.org/abs/2309.13205) | 本文综述了针对上下文学习的零样本提示设计技术，并探讨了不同类型提示对大型语言模型性能的影响。研究重点讨论了人工设计、优化算法和评价方法等多种提示设计方法，以优化模型在不同任务上的性能。同时，本文强调了考虑多种指标和缺乏单一最佳提示等评估挑战。该研究揭示了提示设计在充分发挥大型语言模型潜力方面的关键作用。 |
| [^10] | [Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts.](http://arxiv.org/abs/2309.13202) | 本研究使用大型语言模型和控制机制改善了生物医学摘要的文本可读性，具体包括领域微调和基于提示的学习方法，以及应用于编码器-解码器模型和GPT模型的控制令牌机制。 |
| [^11] | [Document Understanding for Healthcare Referrals.](http://arxiv.org/abs/2309.13184) | 该论文提出了一个混合模型，结合LayoutLMv3和领域特定规则，用于识别传真转诊文档中的关键实体。结果表明，在变换器模型中添加领域特定规则可以显著提高精确度和F1分数，从而提高转诊管理的效率。 |
| [^12] | [Effective Distillation of Table-based Reasoning Ability from LLMs.](http://arxiv.org/abs/2309.13182) | 本论文提出了一种从LLMs中提取基于表格推理能力的方法，通过蒸馏将大型模型转化为专门用于基于表格推理任务的小型模型，并取得了良好的性能。 |
| [^13] | [BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP.](http://arxiv.org/abs/2309.13173) | 本文对大型语言模型（LLMs）在孟加拉语自然语言处理中的潜力和缺陷进行了全面评估。结果显示，LLMs在孟加拉语自然语言处理任务中表现较差，需要进一步努力开发对低资源语言中LLMs的更好理解。 |
| [^14] | [Large Language Models Are Also Good Prototypical Commonsense Reasoners.](http://arxiv.org/abs/2309.13165) | 本论文提出了一种解决大型语言模型常识推理任务的方法，通过设计更好的提示，实现了在ProtoQA数据集上的最新最佳结果，最大答案正确率提高了8％，最大错误率降低了4％。 |
| [^15] | [Cardiovascular Disease Risk Prediction via Social Media.](http://arxiv.org/abs/2309.13147) | 该论文通过分析Twitter上的情感内容，引入了一个新颖的与心血管疾病相关的关键词词典，并使用机器学习模型评估个体的心血管疾病风险。研究发现，分析情感内容能够超越仅使用人口统计数据进行预测，识别出潜在风险患者。这项研究显示了社交媒体在心血管疾病风险预测方面的潜力。 |
| [^16] | [Towards Lexical Analysis of Dog Vocalizations via Online Videos.](http://arxiv.org/abs/2309.13086) | 本研究通过在线视频的数据驱动研究，探索了狗叫声的语义，发现了支持以前启发式研究的证据，并提出了关于狗叫声的新的观点和发现。 |
| [^17] | [SPICED: News Similarity Detection Dataset with Multiple Topics and Complexity Levels.](http://arxiv.org/abs/2309.13080) | 这个论文提出了一个名为SPICED的新闻相似性检测数据集，包括七个主题，并提供了四种不同的方法来生成新闻。 |
| [^18] | [MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models.](http://arxiv.org/abs/2309.13079) | MiChao-HuaFen 1.0是一个专为新闻和政府部门定制的面向领域特定大模型的预训练语料数据集，它不仅能够满足特定领域的高质量需求，还有助于推动相关领域的深度学习研究和应用。 |
| [^19] | [SCREWS: A Modular Framework for Reasoning with Revisions.](http://arxiv.org/abs/2309.13075) | SCREWS是一个模块化框架，用于推理修订。它能够统一先前的方法并提供新的策略来识别改进的推理链。在多样的推理任务上，使用最先进的LLMs（ChatGPT和GPT-4）评估SCREWS的性能，并发现了有用的新的推理策略。 |
| [^20] | [Weakly Supervised Reasoning by Neuro-Symbolic Approaches.](http://arxiv.org/abs/2309.13072) | 本文介绍了一种基于神经符号方法的弱监督推理框架，该框架将符号主义和连接主义结合起来，成功应用于各种自然语言处理任务，并通过设计具有符号潜在结构的神经系统，并应用强化学习或松弛方法来进行推理。 |
| [^21] | [Machine Learning Technique Based Fake News Detection.](http://arxiv.org/abs/2309.13069) | 本论文通过使用机器学习技术训练了一个模型，可以有效地检测假新闻。在实验中，我们发现朴素贝叶斯分类器的准确率为56%，是最佳模型。 |
| [^22] | [Personality Profiling: How informative are social media profiles in predicting personal information?.](http://arxiv.org/abs/2309.13065) | 这项研究探索了利用社交媒体资料预测个人信息的个性化分析模型的准确性和多用途性，并发现支持向量机模型在预测个性类型方面具有最佳准确率，而逻辑回归模型在速度和准确性上表现较好。 |
| [^23] | [Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies.](http://arxiv.org/abs/2309.13063) | 通过使用大型语言模型生成用户意图分类，我们提出了一种新方法来分析和验证日志数据中的用户意图，从而解决了手动或基于机器学习的标注方法在大型和不断变化的数据集上的问题。 |
| [^24] | [Applying BioBERT to Extract Germline Gene-Disease Associations for Building a Knowledge Graph from the Biomedical Literature.](http://arxiv.org/abs/2309.13061) | 本研究提出了一种自动知识图谱构建方法，利用BioBERT模型从生物医学文献中提取生殖细胞系基因与疾病的关联，展示了这一领域的重要工作。 |
| [^25] | [ChatPRCS: A Personalized Support System for English Reading Comprehension based on ChatGPT.](http://arxiv.org/abs/2309.12808) | 本研究提出了一种基于ChatGPT的个性化英语阅读理解辅助系统ChatPRCS。通过利用大型语言模型的先进能力，该系统采用阅读理解能力预测、问题生成、自动评估等方法来增强阅读理解教学。使用学生的历史数据来预测阅读理解能力，并生成适当难度的问题。辅助系统提供了个体化的阅读理解训练支持。 |
| [^26] | [Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers.](http://arxiv.org/abs/2309.12570) | 本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。 |
| [^27] | [The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A".](http://arxiv.org/abs/2309.12288) | LLMs模型在训练中只能学习到"A是B"的结构，无法自动推广到"B是A"。这表明模型在逻辑推断上存在基本失败和训练集中模式的推广问题。 |
| [^28] | [The Cambridge Law Corpus: A Corpus for Legal AI Research.](http://arxiv.org/abs/2309.12269) | 剑桥法律语料库是一个用于法律人工智能研究的语料库，包含来自英国的超过250,000个法庭案例。在该语料库的基础上，我们提供了案例结果的专家注解，并使用多个模型进行了案例结果提取的训练和评估，为研究提供了基准。 |
| [^29] | [Chain-of-Verification Reduces Hallucination in Large Language Models.](http://arxiv.org/abs/2309.11495) | 该论文提出了一种链式验证方法（CoVe），通过在回答之前进行备查问题来减少大型语言模型中的幻觉。实验证明CoVe方法在各种任务中都能有效降低幻觉的发生。 |
| [^30] | [Leveraging Data Collection and Unsupervised Learning for Code-switched Tunisian Arabic Automatic Speech Recognition.](http://arxiv.org/abs/2309.11327) | 本研究通过收集和标注数据以及探索切换方法，提出了一种有效的突尼斯方言自动语音识别解决方案，并且通过人工评估来消除拼写不合适的干扰。 |
| [^31] | [DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services.](http://arxiv.org/abs/2309.11325) | DISC-LawLLM是一种利用大型语言模型(LLMs)为智能法律服务细调的智能法律系统，通过采用法律推理提示策略和增强的检索模块，提供了在中国司法领域多样化法律场景下的有效法律服务。 |
| [^32] | [Recovering from Privacy-Preserving Masking with Large Language Models.](http://arxiv.org/abs/2309.08628) | 本文利用大型语言模型（LLM）探索了替换标识信息的方法，并在下游语言建模任务上进行了评估。实验结果表明，使用混淆语料库训练的模型能够达到可比较的性能。 |
| [^33] | [Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions.](http://arxiv.org/abs/2309.07875) | 在训练大型语言模型遵循指令时，仅强调帮助性而不考虑安全性会导致模型产生有害内容。本研究发现，在训练LLaMA模型时添加少量安全示例可以显著提高其安全性，而不影响其能力和帮助性。然而，过度安全调优会使模型拒绝回应表面上类似于不安全提示的合理提示。 |
| [^34] | [DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph.](http://arxiv.org/abs/2309.07545) | DBLPLink是一个用于DBLP学术知识图的实体链接器，它使用文本到文本的预训练语言模型和实体嵌入来进行实体标签生成和排序。 |
| [^35] | [Human Action Co-occurrence in Lifestyle Vlogs using Graph Link Prediction.](http://arxiv.org/abs/2309.06219) | 该论文提出了自动识别人类动作共现的任务，并创建了ACE数据集以及相应的代码。通过利用视觉和文本信息的图链接预测模型，可以有效捕捉不同数据域中的人类动作关系。 |
| [^36] | [Language Models as Black-Box Optimizers for Vision-Language Models.](http://arxiv.org/abs/2309.05950) | 本论文介绍了一种新的视觉-语言模型 (VLMs) 微调方法，通过自然语言提示来避免访问模型参数，采用聊天式的语言模型作为黑盒优化器，在少样本图像分类任务中达到效果。 |
| [^37] | [HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models.](http://arxiv.org/abs/2309.02706) | HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。 |
| [^38] | [Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models.](http://arxiv.org/abs/2309.01219) | 本文调查了大型语言模型中幻觉的检测、解释和缓解的最新研究，提出了幻觉现象和评估基准的分类，并讨论了未来研究的潜在方向。 |
| [^39] | [CPSP: Learning Speech Concepts From Phoneme Supervision.](http://arxiv.org/abs/2309.00424) | 论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。 |
| [^40] | [Text Style Transfer Evaluation Using Large Language Models.](http://arxiv.org/abs/2308.13577) | 大型语言模型（LLMs）有潜力成为人工评估和其他自动化评价指标的可行替代方案。 |
| [^41] | [Towards Objective Evaluation of Socially-Situated Conversational Robots: Assessing Human-Likeness through Multimodal User Behaviors.](http://arxiv.org/abs/2308.11020) | 本文提出了一种客观评价社交位置对话机器人的方法，利用多模态用户行为来评估机器人的人类相似度，增强了客观性和可复现性。 |
| [^42] | [Establishing Trust in ChatGPT BioMedical Generated Text: An Ontology-Based Knowledge Graph to Validate Disease-Symptom Links.](http://arxiv.org/abs/2308.03929) | 本研究通过构建基于本体的知识图谱，利用疾病本体和症状本体构建数学模型，利用事实核查算法和网络中心度指标分析ChatGPT生成的文本与真实医学文献之间的准确性，以验证疾病-症状关系。 |
| [^43] | [MASR: Multi-label Aware Speech Representation.](http://arxiv.org/abs/2307.10982) | MASR是一种多标签感知语音表示学习框架，可以利用多个外部知识源增强元数据信息的利用，并在多个下游任务上展示了显著的性能提升。 |
| [^44] | [Exploring the Landscape of Natural Language Processing Research.](http://arxiv.org/abs/2307.10652) | 该论文系统分类和分析了ACL Anthology中的研究论文，提供了对研究领域的结构化概述和NLP领域的分类学。本研究总结了最新的NLP发展，并提出了未来工作的方向。 |
| [^45] | [AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge.](http://arxiv.org/abs/2307.07851) | AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。 |
| [^46] | [Named entity recognition using GPT for identifying comparable companies.](http://arxiv.org/abs/2307.07420) | 本文使用GPT以识别可比公司。传统的可比公司方法通常使用定性方法来识别相似的同行公司，而我们使用大型语言模型通过提取公司描述/摘要从而进行相似性分析，实现更量化的方法。 |
| [^47] | [Efficient Domain Adaptation of Sentence Embeddings using Adapters.](http://arxiv.org/abs/2307.03104) | 本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。 |
| [^48] | [CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity and Infant Care.](http://arxiv.org/abs/2307.01458) | CARE-MI是一个用于评估中国孕婴护理领域LLM虚假信息的基准，填补了这一领域的研究空白，并提供了构建长篇生成评估基准的创新范式。 |
| [^49] | [3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement.](http://arxiv.org/abs/2306.15354) | 3D-Speaker是一个大规模的多设备、多距离和多方言语音语料库，用于研究语音表示解缠。它包含了10,000多个说话人的数据，可以用来评估大型通用语音模型和探索域外学习和自监督学习方法。 |
| [^50] | [Leveraging Auxiliary Domain Parallel Data in Intermediate Task Fine-tuning for Low-resource Translation.](http://arxiv.org/abs/2306.01382) | 本文展示了中间任务微调(ITFT)对于低资源、多语言、多领域的NMT非常有效，能够在一定程度上缓解领域分歧的影响。 |
| [^51] | [GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children.](http://arxiv.org/abs/2305.16809) | 本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。 |
| [^52] | [ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models.](http://arxiv.org/abs/2304.07666) | 该研究提出了ArguGPT，它是由7个GPT模型生成的论证文章语料库，旨在解决AI生成内容带来的挑战，研究结果表明教师首次接触机器生成的论文时只有61%的准确度，但经过一轮训练后提高到了67%。 |
| [^53] | [Controllable Textual Inversion for Personalized Text-to-Image Generation.](http://arxiv.org/abs/2304.05265) | 本文提出了一种名为COTI的技术，通过引入理论指导的损失目标和全面的加权评分机制，并结合主动学习范式来解决文本反转时的困难，提供了一个强大，数据效率高，易于使用的框架。 |
| [^54] | [Language-Guided Audio-Visual Source Separation via Trimodal Consistency.](http://arxiv.org/abs/2303.16342) | 该论文提出了一种自监督学习的方法，通过使用自然语言查询来进行音频源分离，实现了语言、视觉和音频的一致性对齐，并在多个数据集上表现出比现有方法更好的效果。 |
| [^55] | [Self-Consistent Learning: Cooperation between Generators and Discriminators.](http://arxiv.org/abs/2303.09075) | 本文提出了一个自一致学习的框架，通过鉴别器和生成器的合作训练，解决了标准GAN训练不稳定、样本容易偏离实际数据分布、鉴别模型改进饱和等问题。实验结果表明，该模型不仅优于最先进的GAN，在文本和图像生成任务中也实现了高质量的合成。 |
| [^56] | [Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages.](http://arxiv.org/abs/2303.01037) | Google USM是一个通用语音模型，通过多语言预训练和微调，实现了在100多种语言上的自动语音识别和语音-文本翻译任务的先进性能。 |
| [^57] | [HL Dataset: Visually-grounded Description of Scenes, Actions and Rationales.](http://arxiv.org/abs/2302.12189) | 这个论文介绍了HL数据集，该数据集扩展了COCO数据集，包含14997个图像和134,973个人工注释的高级别描述，涉及场景、动作和理由，可以用于对视觉和语言模型进行更高级别的测试和微调。 |
| [^58] | [Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data.](http://arxiv.org/abs/2301.05843) | 本研究通过探索设计提示的因素，研究了如何利用大型语言模型构建聊天机器人来进行自然对话和可靠地收集用户自我报告数据。结果显示，提示的设计和对话主题明显影响了对话流程和数据收集性能。 |
| [^59] | [A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding.](http://arxiv.org/abs/2301.03403) | 本文提供了关于自动文本摘要系统的综述，包括方法、数据、评估和编码。作者通过引用的方式回顾了相关文献，并介绍了不同的摘要生成方法。此外，还对可用于评估和数据训练的数据集进行了综述，并使用CNN语料库数据集对方法进行了实证探索。 |
| [^60] | [Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments.](http://arxiv.org/abs/2212.07425) | 本论文提出了一个鲁棒且可解释的方法来识别自然语言论证中的逻辑谬误。通过三阶段的评估框架和不同的推理方法，结合语言模型和背景知识，有效处理了大量数据和数据稀疏性的问题。 |
| [^61] | [Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control.](http://arxiv.org/abs/2211.05750) | 本研究提出了一个少样本人机交互训练算法Nano，用于按任意分布（定量和未定量）生成文本。与先前的工作相比，Nano在单一主题/属性以及定量分布控制方面表现出最先进的结果。 |
| [^62] | [CC-Riddle: A Question Answering Dataset of Chinese Character Riddles.](http://arxiv.org/abs/2206.13778) | 本论文构建了一个名为CC-Riddle的中文字谜问答数据集，覆盖了大多数常见的简体中文字符。该数据集的构建过程结合了网络爬虫、语言模型生成和手动过滤，为解决中文字谜问题提供了重要资源。 |
| [^63] | [Explainable and High-Performance Hate and Offensive Speech Detection.](http://arxiv.org/abs/2206.12983) | 这项研究构建了一个可解释且高性能的模型，基于XGBoost算法，用于检测社交媒体平台上的仇恨和冒犯性言论。该模型在不平衡的Twitter数据上显示出更好的性能，并且在降采样后的数据中也表现出优越性能。 |
| [^64] | [Actuarial Applications of Natural Language Processing Using Transformers: Case Studies for Using Text Features in an Actuarial Context.](http://arxiv.org/abs/2206.02014) | 这个教程介绍了使用Transformer模型的方法将文本数据应用于精算学中的分类和回归任务，并展示了在多语言和长输入序列的情况下的案例研究。该教程还提供了处理无标记数据情况下的分类任务的实用方法。 |
| [^65] | [Crime Hot-Spot Modeling via Topic Modeling and Relative Density Estimation.](http://arxiv.org/abs/2202.04176) | 本研究提出了一种通过主题建模和相对密度估计来进行犯罪热点建模的方法。实验证明该方法可以捕捉到被调度员忽视的地理热点趋势，这些热点趋势往往与整体事件密度的增加相混淆。 |
| [^66] | [BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on Twitter.](http://arxiv.org/abs/2105.01331) | 本论文提出了一个用于推特上检测黑人生命至关重要话题的大规模数据集BLM-17m，涵盖了乔治·弗洛伊德事件期间的17百万推文。作者提供了两个基线模型TF-IDF和LDA，并对其进行了评估。 |

# 详细

[^1]: 校准基于LLM的评估器

    Calibrating LLM-Based Evaluator. (arXiv:2309.13308v1 [cs.CL])

    [http://arxiv.org/abs/2309.13308](http://arxiv.org/abs/2309.13308)

    这篇论文提出了AutoCalibrate，一种多阶段、无梯度的方法，用于自动校准和调整基于LLM的评估器以符合人类偏好。通过在少样本示例上进行上下文学习，该方法隐含地包括人类偏好，并通过选择最佳表现者和自我完善来进一步校准评分标准。

    

    大型语言模型（LLMs）的最新进展在语言建模方面和出色的能力使它们成为有前景的无参考自然语言生成质量评估器，并且是人工评估的有竞争力替代品。然而，由于闭源或高计算消耗来托管和调节，缺乏进一步校准现成LLM评估器以实现更好的与人类一致性。在这项工作中，我们提出了AutoCalibrate，一个多阶段，无梯度的方法，用于自动校准和调整基于LLM的评估器以符合人类偏好。我们不是直接建模人类偏好，而是在一组人员标签中隐含地包括它们。然后，通过在不同的少样本示例上进行上下文学习，语言模型本身起草了一组初步的评分标准。为了进一步校准此一组标准，我们选择了表现最好的演员，并进行自我完善的再起草。我们的实验证明，多任务学习在多任务学习和评价中的有效性。

    Recent advancements in large language models (LLMs) on language modeling and emergent capabilities make them a promising reference-free evaluator of natural language generation quality, and a competent alternative to human evaluation. However, hindered by the closed-source or high computational demand to host and tune, there is a lack of practice to further calibrate an off-the-shelf LLM-based evaluator towards better human alignment. In this work, we propose AutoCalibrate, a multi-stage, gradient-free approach to automatically calibrate and align an LLM-based evaluator toward human preference. Instead of explicitly modeling human preferences, we first implicitly encompass them within a set of human labels. Then, an initial set of scoring criteria is drafted by the language model itself, leveraging in-context learning on different few-shot examples. To further calibrate this set of criteria, we select the best performers and re-draft them with self-refinement. Our experiments on multip
    
[^2]: OATS: 观点方面目标情感四元组抽取数据集用于面向方面的情感分析

    OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis. (arXiv:2309.13297v1 [cs.CL])

    [http://arxiv.org/abs/2309.13297](http://arxiv.org/abs/2309.13297)

    OATS数据集是一个全新的观点方面目标情感四元组抽取数据集，它解决了面向方面的情感分析中的领域限制和数据粒度挑战，并填补了餐馆和笔记本电脑等常见领域的数据不足和句子与评论级情感之间的协同作用问题。

    

    面向方面的情感分析（ABSA）旨在理解文本内容中特定要素的情感。它旨在分析用户生成的评论，确定a) 被评论的目标实体，b) 它所属的高级方面，c) 用于表达观点的情感词，d) 对目标和方面表达的情感。尽管各种基准数据集推动了ABSA的进展，但它们往往带来领域限制和数据粒度挑战。为了解决这些问题，我们介绍了OATS数据集，该数据集涵盖了三个全新的领域，并包含20,000个句子级四元组和13,000个评论级元组。我们的目标是填补一些特定的观察到的差距：对熟悉领域（如餐馆和笔记本电脑）的反复关注，用于复杂四元组抽取任务的有限数据，以及偶尔忽视句子和评论级情感之间的协同作用。此外，为了阐明OATS的潜在能力，

    Aspect-based sentiment Analysis (ABSA) delves into understanding sentiments specific to distinct elements within textual content. It aims to analyze user-generated reviews to determine a) the target entity being reviewed, b) the high-level aspect to which it belongs, c) the sentiment words used to express the opinion, and d) the sentiment expressed toward the targets and the aspects. While various benchmark datasets have fostered advancements in ABSA, they often come with domain limitations and data granularity challenges. Addressing these, we introduce the OATS dataset, which encompasses three fresh domains and consists of 20,000 sentence-level quadruples and 13,000 review-level tuples. Our initiative seeks to bridge specific observed gaps: the recurrent focus on familiar domains like restaurants and laptops, limited data for intricate quadruple extraction tasks, and an occasional oversight of the synergy between sentence and review-level sentiments. Moreover, to elucidate OATS's pote
    
[^3]: 自然语言处理用于需求形式化：如何得出新方法？

    Natural Language Processing for Requirements Formalization: How to Derive New Approaches?. (arXiv:2309.13272v1 [cs.SE])

    [http://arxiv.org/abs/2309.13272](http://arxiv.org/abs/2309.13272)

    本论文介绍了自然语言处理在需求形式化中的应用和最新方法，以及其在生成规范模型中起到的作用。

    

    企业和研究长期以来一直希望能自动化尽可能多的软件开发和测试过程。在这个过程中，需求工程（RE）对于构建在其基础上的所有其他步骤起着重要作用。已经开发了基于模型的设计和测试方法来处理软件系统日益增长的复杂性和变异性。然而，仍需要大量工作来从以自然语言提供的大量功能需求中创建规范模型。文献中提出了许多基于自然语言处理（NLP）的方法来使用主要的句法属性生成需求模型。NLP的最新进展表明，也可以识别和使用语义量来在需求形式化过程中提供更好的帮助。在这项工作中，我们介绍和讨论了NLP领域的主要思想和最新方法论，以指导读者如何创建一个规范模型。

    It is a long-standing desire of industry and research to automate the software development and testing process as much as possible. In this process, requirements engineering (RE) plays a fundamental role for all other steps that build on it. Model-based design and testing methods have been developed to handle the growing complexity and variability of software systems. However, major effort is still required to create specification models from a large set of functional requirements provided in natural language. Numerous approaches based on natural language processing (NLP) have been proposed in the literature to generate requirements models using mainly syntactic properties. Recent advances in NLP show that semantic quantities can also be identified and used to provide better assistance in the requirements formalization process. In this work, we present and discuss principal ideas and state-of-the-art methodologies from the field of NLP in order to guide the readers on how to create a s
    
[^4]: 文档级信息抽取综述

    A Survey of Document-Level Information Extraction. (arXiv:2309.13249v1 [cs.CL])

    [http://arxiv.org/abs/2309.13249](http://arxiv.org/abs/2309.13249)

    本文综述了近期文档级信息抽取的研究进展，发现标注误差、实体共指解析和推理的缺乏是限制文档级IE性能的主要因素，为进一步增强文档级IE性能提供了启示。

    

    文档级信息抽取（IE）是自然语言处理（NLP）中的一个关键任务。本文对近期文档级IE文献进行了系统回顾。此外，我们还通过当前最先进的算法进行了彻底的错误分析，并确定了它们在文档级IE任务中的限制以及剩余挑战。根据我们的发现，标注误差、实体共指解析和推理的缺乏严重影响了文档级IE的性能。本综述的目标是提供更多的见解，帮助NLP研究人员进一步提高文档级IE的性能。

    Document-level information extraction (IE) is a crucial task in natural language processing (NLP). This paper conducts a systematic review of recent document-level IE literature. In addition, we conduct a thorough error analysis with current state-of-the-art algorithms and identify their limitations as well as the remaining challenges for the task of document-level IE. According to our findings, labeling noises, entity coreference resolution, and lack of reasoning, severely affect the performance of document-level IE. The objective of this survey paper is to provide more insights and help NLP researchers to further enhance document-level IE performance.
    
[^5]: ChEDDAR: 在EFL写作教育中的学生-ChatGPT对话

    ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education. (arXiv:2309.13243v1 [cs.CL])

    [http://arxiv.org/abs/2309.13243](http://arxiv.org/abs/2309.13243)

    这项研究介绍了ChEDDAR，一个在EFL写作教育中应用的学生-ChatGPT对话数据集。该研究分析了学生对生成型AI的使用模式和感知，并为教育背景下的任务导向对话系统建立了基准结果。

    

    尽管将生成型AI应用于教育领域已有不少进展，但对于学生和AI系统之间大规模且真实的互动的实证分析仍然很有限。在本研究中，我们介绍了ChEDDAR，即ChatGPT和EFL学习者的对话数据集，该数据集是在一个学期长的纵向实验中收集的，研究对象包括212名参加英语作为外语（EFL）写作课程的大学生。学生被要求通过与ChatGPT的对话来修改他们的文章。ChEDDAR包括对话日志，话语级别的文章编辑历史，自我评价满意度和学生意图，以及记录他们目标和整体体验的会话级别的前后调查。我们分析了学生对生成型AI的使用模式和感知，以及他们的意图和满意度。作为基础性步骤，我们为教育背景下任务导向对话系统的两个关键任务建立了基准结果：在……

    The integration of generative AI in education is expanding, yet empirical analyses of large-scale, real-world interactions between students and AI systems still remain limited. In this study, we present ChEDDAR, ChatGPT & EFL Learner's Dialogue Dataset As Revising an essay, which is collected from a semester-long longitudinal experiment involving 212 college students enrolled in English as Foreign Langauge (EFL) writing courses. The students were asked to revise their essays through dialogues with ChatGPT. ChEDDAR includes a conversation log, utterance-level essay edit history, self-rated satisfaction, and students' intent, in addition to session-level pre-and-post surveys documenting their objectives and overall experiences. We analyze students' usage patterns and perceptions regarding generative AI with respect to their intent and satisfaction. As a foundational step, we establish baseline results for two pivotal tasks in task-oriented dialogue systems within educational contexts: in
    
[^6]: 使用大型语言模型进行用户模拟，用于评估任务导向对话

    User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue. (arXiv:2309.13233v1 [cs.CL])

    [http://arxiv.org/abs/2309.13233](http://arxiv.org/abs/2309.13233)

    提出了一种使用大型语言模型进行用户模拟的方法，用于评估任务导向对话系统。通过在上下文中学习，可以生成具有鲁棒性和语言多样性的输出，模拟人类对话参与者的行为。目标是使系统的成功率与人类和任务导向对话系统的交互相似。

    

    新任务导向对话系统开发过程中的一个主要障碍是需要在多个阶段和迭代中进行人工评估。为了实现对任务导向对话的自动化评估，我们提出了一种新颖的用户模拟器，利用最近开发的大型预训练语言模型（LLMs）构建。为了增加我们系统的语言多样性，相对于相关先前的工作，我们不在现有的任务导向对话数据集上对我们系统使用的LLMs进行微调；相反，我们使用上下文学习来提示LLMs生成鲁棒且语言多样的输出，以模拟人类对话参与者的行为。不同于以目标成功率（GSR）作为模拟器性能的主要指标的先前工作，我们的目标是使系统实现与人类与任务导向对话系统交互中观察到的GSR相似。采用这种方法，我们目前的模拟器能够有效地与人类进行互动。

    One of the major impediments to the development of new task-oriented dialogue (TOD) systems is the need for human evaluation at multiple stages and iterations of the development process. In an effort to move toward automated evaluation of TOD, we propose a novel user simulator built using recently developed large pretrained language models (LLMs). In order to increase the linguistic diversity of our system relative to the related previous work, we do not fine-tune the LLMs used by our system on existing TOD datasets; rather we use in-context learning to prompt the LLMs to generate robust and linguistically diverse output with the goal of simulating the behavior of human interlocutors. Unlike previous work, which sought to maximize goal success rate (GSR) as the primary metric of simulator performance, our goal is a system which achieves a GSR similar to that observed in human interactions with TOD systems. Using this approach, our current simulator is effectively able to interact with 
    
[^7]: NJUNLP对WMT2023质量评估共享任务的参与

    NJUNLP's Participation for the WMT2023 Quality Estimation Shared Task. (arXiv:2309.13230v1 [cs.CL])

    [http://arxiv.org/abs/2309.13230](http://arxiv.org/abs/2309.13230)

    NJUNLP团队对WMT2023质量评估共享任务进行了投稿，通过使用伪数据方法和核心超参数的实验研究，他们的模型在英德语言对的质量预测和错误跨度检测上取得了最佳结果。

    

    我们介绍了NJUNLP团队在WMT 2023质量估计（QE）共享任务中的投稿。我们的团队提交了对英德语言对的所有两个子任务的预测：（i）句子和单词级别的质量预测；（ii）细粒度错误跨度检测。今年，我们进一步探索了基于NJUQE框架（https://github.com/NJUNLP/njuqe）的伪数据方法进行QE。我们使用WMT翻译任务的并行数据生成伪MQM数据。我们在伪QE数据上预训练XLMR大模型，然后在真实QE数据上进行微调。在两个阶段，我们共同学习句子级分数和单词级标签。在实证上，我们进行实验来寻找改善性能的关键超参数。在技术上，我们提出了一种简单的方法，将单词级输出转换为细粒度错误跨度结果。总体而言，我们的模型在英德语言对的单词级别和细粒度错误跨度检测子任务中取得了最佳结果。

    We introduce the submissions of the NJUNLP team to the WMT 2023 Quality Estimation (QE) shared task. Our team submitted predictions for the English-German language pair on all two sub-tasks: (i) sentence- and word-level quality prediction; and (ii) fine-grained error span detection. This year, we further explore pseudo data methods for QE based on NJUQE framework (https://github.com/NJUNLP/njuqe). We generate pseudo MQM data using parallel data from the WMT translation task. We pre-train the XLMR large model on pseudo QE data, then fine-tune it on real QE data. At both stages, we jointly learn sentence-level scores and word-level tags. Empirically, we conduct experiments to find the key hyper-parameters that improve the performance. Technically, we propose a simple method that covert the word-level outputs to fine-grained error span results. Overall, our models achieved the best results in English-German for both word-level and fine-grained error span detection sub-tasks by a considera
    
[^8]: Hindi to English: 基于Transformer的神经机器翻译

    Hindi to English: Transformer-Based Neural Machine Translation. (arXiv:2309.13222v1 [cs.CL])

    [http://arxiv.org/abs/2309.13222](http://arxiv.org/abs/2309.13222)

    本文使用Transformer模型开发了一种基于神经网络的印度语Hindi到英文的机器翻译系统，并通过回译和不同的分词方法提升了翻译质量。

    

    机器翻译（MT）是自然语言处理（NLP）中最重要的任务之一，它涉及将文本从一种自然语言自动转换为另一种语言，同时保持其含义和流畅性。尽管机器翻译的研究已经持续了数十年，但将深度学习技术与自然语言处理结合的新方法从根本上改善了翻译质量。在本文中，我们通过训练Transformer模型开发了一种神经机器翻译（NMT）系统，用于将印度语Hindi文本翻译成英文。Hindi作为一种资源稀缺的语言，使得神经网络难以理解该语言，从而导致神经机器翻译器的发展缓慢。因此，为了弥补这一差距，我们实施了回译来增加训练数据，并通过实验使用了词级和子词级的分词方法创建了词汇表。

    Machine Translation (MT) is one of the most prominent tasks in Natural Language Processing (NLP) which involves the automatic conversion of texts from one natural language to another while preserving its meaning and fluency. Although the research in machine translation has been going on since multiple decades, the newer approach of integrating deep learning techniques in natural language processing has led to significant improvements in the translation quality. In this paper, we have developed a Neural Machine Translation (NMT) system by training the Transformer model to translate texts from Indian Language Hindi to English. Hindi being a low resource language has made it difficult for neural networks to understand the language thereby leading to a slow growth in the development of neural machine translators. Thus, to address this gap, we implemented back-translation to augment the training data and for creating the vocabulary, we experimented with both word and subword level tokenizat
    
[^9]: 针对上下文学习的零样本提示设计的实际调查

    A Practical Survey on Zero-shot Prompt Design for In-context Learning. (arXiv:2309.13205v1 [cs.CL])

    [http://arxiv.org/abs/2309.13205](http://arxiv.org/abs/2309.13205)

    本文综述了针对上下文学习的零样本提示设计技术，并探讨了不同类型提示对大型语言模型性能的影响。研究重点讨论了人工设计、优化算法和评价方法等多种提示设计方法，以优化模型在不同任务上的性能。同时，本文强调了考虑多种指标和缺乏单一最佳提示等评估挑战。该研究揭示了提示设计在充分发挥大型语言模型潜力方面的关键作用。

    

    大型语言模型（LLM）的显著进展在自然语言处理（NLP）任务中带来了显著的改进。本文对上下文学习技术进行了综合回顾，重点关注不同类型的提示，包括离散、连续、少样本和零样本，并探讨它们对LLM性能的影响。我们探索了各种提示设计方法，如人工设计、优化算法和评价方法，以优化LLM在各种任务中的性能。我们的回顾涵盖了提示工程领域的关键研究，讨论了其方法论和对该领域的贡献。我们还深入探讨了在评估提示性能方面面临的挑战，包括缺乏单一的"最佳"提示和考虑多个指标的重要性。总之，本文强调了提示设计在发挥LLM的全部潜力中的关键作用，并提供了关于人工设计、优化算法和评价方法结合的见解。

    The remarkable advancements in large language models (LLMs) have brought about significant improvements in Natural Language Processing(NLP) tasks. This paper presents a comprehensive review of in-context learning techniques, focusing on different types of prompts, including discrete, continuous, few-shot, and zero-shot, and their impact on LLM performance. We explore various approaches to prompt design, such as manual design, optimization algorithms, and evaluation methods, to optimize LLM performance across diverse tasks. Our review covers key research studies in prompt engineering, discussing their methodologies and contributions to the field. We also delve into the challenges faced in evaluating prompt performance, given the absence of a single "best" prompt and the importance of considering multiple metrics. In conclusion, the paper highlights the critical role of prompt design in harnessing the full potential of LLMs and provides insights into the combination of manual design, opt
    
[^10]: 大型语言模型和控制机制提高了生物医学摘要的文本可读性

    Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts. (arXiv:2309.13202v1 [cs.CL])

    [http://arxiv.org/abs/2309.13202](http://arxiv.org/abs/2309.13202)

    本研究使用大型语言模型和控制机制改善了生物医学摘要的文本可读性，具体包括领域微调和基于提示的学习方法，以及应用于编码器-解码器模型和GPT模型的控制令牌机制。

    

    生物医学文献通常使用复杂的语言和难以理解的专业术语。因此，简化在提高公共健康素养方面起着重要作用。将自然语言处理（NLP）模型应用于自动化此类任务可以使非专业读者快速直接地获取信息。在本研究中，我们使用公开可用的用于生物医学摘要简化的数据集（PLABA）来调查最先进大型语言模型（LLMs）在生物医学摘要简化任务上的能力。应用的方法包括领域微调和基于提示的学习（PBL）在：1）编码器-解码器模型（T5、SciFive和BART）上，2）仅解码器的GPT模型（GPT-3.5和GPT-4）来自OpenAI和BioGPT，以及3）基于控制令牌机制的基于BART的模型。我们使用了一系列自动评估指标，包括BLEU、ROUGE、SARI和BERTscore，并进行了人工评估。

    Biomedical literature often uses complex language and inaccessible professional terminologies. That is why simplification plays an important role in improving public health literacy. Applying Natural Language Processing (NLP) models to automate such tasks allows for quick and direct accessibility for lay readers. In this work, we investigate the ability of state-of-the-art large language models (LLMs) on the task of biomedical abstract simplification, using the publicly available dataset for plain language adaptation of biomedical abstracts (\textbf{PLABA}). The methods applied include domain fine-tuning and prompt-based learning (PBL) on: 1) Encoder-decoder models (T5, SciFive, and BART), 2) Decoder-only GPT models (GPT-3.5 and GPT-4) from OpenAI and BioGPT, and 3) Control-token mechanisms on BART-based models. We used a range of automatic evaluation metrics, including BLEU, ROUGE, SARI, and BERTscore, and also conducted human evaluations. BART-Large with Control Token (BART-L-w-CT) m
    
[^11]: 医疗转诊的文件理解

    Document Understanding for Healthcare Referrals. (arXiv:2309.13184v1 [cs.CL])

    [http://arxiv.org/abs/2309.13184](http://arxiv.org/abs/2309.13184)

    该论文提出了一个混合模型，结合LayoutLMv3和领域特定规则，用于识别传真转诊文档中的关键实体。结果表明，在变换器模型中添加领域特定规则可以显著提高精确度和F1分数，从而提高转诊管理的效率。

    

    依赖于扫描文档和传真通信的医疗转诊导致了高昂的行政成本和可能影响病人护理的错误。在这项工作中，我们提出了一个混合模型，利用LayoutLMv3和领域特定规则来识别传真转诊文档中的关键病人、医生和检查相关实体。我们探讨了将文档理解模型应用于转诊中所面临的一些挑战，这些转诊的格式因医疗实践而异，并使用MUC-5指标评估模型性能，以获得适用于实际用例的适当指标。我们的分析结果显示，将领域特定规则添加到变换器模型中可以大大提高精确度和F1分数，这表明在经过策划的数据集上训练的混合模型可以提高转诊管理的效率。

    Reliance on scanned documents and fax communication for healthcare referrals leads to high administrative costs and errors that may affect patient care. In this work we propose a hybrid model leveraging LayoutLMv3 along with domain-specific rules to identify key patient, physician, and exam-related entities in faxed referral documents. We explore some of the challenges in applying a document understanding model to referrals, which have formats varying by medical practice, and evaluate model performance using MUC-5 metrics to obtain appropriate metrics for the practical use case. Our analysis shows the addition of domain-specific rules to the transformer model yields greatly increased precision and F1 scores, suggesting a hybrid model trained on a curated dataset can increase efficiency in referral management.
    
[^12]: 从LLMs中有效提取基于表格推理能力的方法

    Effective Distillation of Table-based Reasoning Ability from LLMs. (arXiv:2309.13182v1 [cs.CL])

    [http://arxiv.org/abs/2309.13182](http://arxiv.org/abs/2309.13182)

    本论文提出了一种从LLMs中提取基于表格推理能力的方法，通过蒸馏将大型模型转化为专门用于基于表格推理任务的小型模型，并取得了良好的性能。

    

    大型语言模型（LLMs）在自然语言处理任务中展现出了卓越的性能。然而，它们庞大的参数和对计算资源的高需求给实际应用带来了挑战。最近的研究发现，LLMs的特定能力，如数值推理，可以通过蒸馏传递给较小的模型。一些研究探讨了利用LLMs进行基于表格推理的潜力。然而，在我们的工作之前，尚未对专门为表格生成任务定制的较小模型的表格推理能力进行研究。在本文中，我们提出了一种新颖的基于表格推理的蒸馏方法，旨在将LLMs蒸馏成专门为基于表格推理任务设计的较小模型。实验结果表明，一个具有0.22亿参数的模型（Flan-T5-base）可以有效地进行蒸馏，并展现出良好的性能。

    Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, their remarkable parameter size and their impressive high requirement of computing resources pose challenges for their practical deployment. Recent research has revealed that specific capabilities of LLMs, such as numerical reasoning, can be transferred to smaller models through distillation. Some studies explore the potential of leveraging LLMs to perform table-based reasoning. Nevertheless, prior to our work, there has been no investigation into the prospect of specialising table reasoning skills in smaller models specifically tailored for table-to-text generation tasks. In this paper, we propose a novel table-based reasoning distillation, with the aim of distilling distilling LLMs into tailored, smaller models specifically designed for table-based reasoning task. Experimental results have shown that a 0.22 billion parameter model (Flan-T5-base) fin
    
[^13]: BenLLMEval: 一项对孟加拉语自然语言处理中大型语言模型潜力和缺陷的全面评估

    BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP. (arXiv:2309.13173v1 [cs.CL])

    [http://arxiv.org/abs/2309.13173](http://arxiv.org/abs/2309.13173)

    本文对大型语言模型（LLMs）在孟加拉语自然语言处理中的潜力和缺陷进行了全面评估。结果显示，LLMs在孟加拉语自然语言处理任务中表现较差，需要进一步努力开发对低资源语言中LLMs的更好理解。

    

    大型语言模型（LLMs）因其在语言生成和其他具体语言任务中的出色能力而成为自然语言处理中最重要的突破之一。尽管LLMs已在各种任务中得到评估，但大部分评估集中在英语上，尚未对孟加拉语等资源匮乏的语言进行全面评估。本文评估了LLMs在资源匮乏的孟加拉语上的性能。我们选择了各种重要且多样的孟加拉语自然语言处理任务，如抽象摘要、问答、改写、自然语言推理、文本分类和情感分析，以零-shot评估ChatGPT、LLaMA-2和Claude-2，并将性能与最先进的微调模型进行对比。我们的实验结果显示，LLMs在不同的孟加拉语自然语言处理任务中表现较差，需要进一步努力开发对低资源语言（如孟加拉语）中LLMs的更好理解。

    Large Language Models (LLMs) have emerged as one of the most important breakthroughs in natural language processing (NLP) for their impressive skills in language generation and other language-specific tasks. Though LLMs have been evaluated in various tasks, mostly in English, they have not yet undergone thorough evaluation in under-resourced languages such as Bengali (Bangla). In this paper, we evaluate the performance of LLMs for the low-resourced Bangla language. We select various important and diverse Bangla NLP tasks, such as abstractive summarization, question answering, paraphrasing, natural language inference, text classification, and sentiment analysis for zero-shot evaluation with ChatGPT, LLaMA-2, and Claude-2 and compare the performance with state-of-the-art fine-tuned models. Our experimental results demonstrate an inferior performance of LLMs for different Bangla NLP tasks, calling for further effort to develop better understanding of LLMs in low-resource languages like Ba
    
[^14]: 大型语言模型也是良好的典型常识推理器

    Large Language Models Are Also Good Prototypical Commonsense Reasoners. (arXiv:2309.13165v1 [cs.CL])

    [http://arxiv.org/abs/2309.13165](http://arxiv.org/abs/2309.13165)

    本论文提出了一种解决大型语言模型常识推理任务的方法，通过设计更好的提示，实现了在ProtoQA数据集上的最新最佳结果，最大答案正确率提高了8％，最大错误率降低了4％。

    

    常识推理是大型语言模型的关键技能，但在涉及此能力的特定任务中仍存在持续挑战。传统的微调方法可能耗费大量资源，并可能损害模型的泛化能力。此外，像GPT-3.5和Claude这样的最先进语言模型主要通过API调用进行访问，这使得微调模型具有挑战性。为了解决这些问题，我们从大型模型的输出中汲取灵感，针对特定任务半自动地开发了一组新颖的提示，包括任务相关性、支持性证据生成（例如思路链和知识）、多样路径解码等，以帮助模型。在ProtoQA数据集上的实验结果表明，通过更好设计的提示，我们可以在ProtoQA排行榜上取得新的最佳成绩，将最大答案正确率提高了8％，最大错误率降低了4％（突破50％）

    Commonsense reasoning is a pivotal skill for large language models, yet it presents persistent challenges in specific tasks requiring this competence. Traditional fine-tuning approaches can be resource-intensive and potentially compromise a model's generalization capacity. Furthermore, state-of-the-art language models like GPT-3.5 and Claude are primarily accessible through API calls, which makes fine-tuning models challenging. To address these challenges, we draw inspiration from the outputs of large models for tailored tasks and semi-automatically developed a set of novel prompts from several perspectives, including task-relevance, supportive evidence generation (e.g. chain-of-thought and knowledge), diverse path decoding to aid the model. Experimental results on ProtoQA dataset demonstrate that with better designed prompts we can achieve the new state-of-art(SOTA) on the ProtoQA leaderboard, improving the Max Answer@1 score by 8%, Max Incorrect@1 score by 4% (breakthrough 50% for th
    
[^15]: 通过社交媒体预测心血管疾病风险

    Cardiovascular Disease Risk Prediction via Social Media. (arXiv:2309.13147v1 [cs.CL])

    [http://arxiv.org/abs/2309.13147](http://arxiv.org/abs/2309.13147)

    该论文通过分析Twitter上的情感内容，引入了一个新颖的与心血管疾病相关的关键词词典，并使用机器学习模型评估个体的心血管疾病风险。研究发现，分析情感内容能够超越仅使用人口统计数据进行预测，识别出潜在风险患者。这项研究显示了社交媒体在心血管疾病风险预测方面的潜力。

    

    研究人员利用Twitter和情感分析预测心血管疾病（CVD）的风险。我们通过审视推文中传达的情感，引入了一个新颖的与CVD相关的关键词词典。我们收集了来自美国18个州的推文，涵盖了阿巴拉契亚地区。采用VADER模型进行情感分析，我们将用户归类为潜在的CVD风险。采用机器学习（ML）模型评估个体的CVD风险，并随后将其应用于CDC数据集中的人口统计信息进行比较。我们考虑了各种性能评估指标，包括测试准确率，精确率，召回率，F1分数，马修斯相关系数（MCC）和科恩的Kappa分数（CK）。我们的研究结果表明，分析推文中的情感内容优于仅使用人口统计数据进行预测，能够识别出潜在风险患者的个体。这项研究强调了社交媒体在预测CVD风险方面的潜力。

    Researchers utilize Twitter and sentiment analysis to forecast the risk of Cardiovascular Disease (CVD). We have introduced a novel CVD-related keyword dictionary by scrutinizing the emotions conveyed in tweets. We gathered tweets from eighteen U.S. states, encompassing the Appalachian region. Employing the VADER model for sentiment analysis, we categorized users as potentially at risk for CVD. Machine Learning (ML) models were employed to assess individuals' CVD risk and were subsequently applied to a CDC dataset containing demographic information for comparison. We considered various performance evaluation metrics, including Test Accuracy, Precision, Recall, F1 score, Mathew's Correlation Coefficient (MCC), and Cohen's Kappa (CK) score. Our findings demonstrate that analyzing the emotional content of tweets outperforms the predictive capabilities of demographic data alone, enabling the identification of individuals at potential risk of developing CVD. This research underscores the po
    
[^16]: 通过在线视频对狗叫声进行词汇分析的研究

    Towards Lexical Analysis of Dog Vocalizations via Online Videos. (arXiv:2309.13086v1 [cs.SD])

    [http://arxiv.org/abs/2309.13086](http://arxiv.org/abs/2309.13086)

    本研究通过在线视频的数据驱动研究，探索了狗叫声的语义，发现了支持以前启发式研究的证据，并提出了关于狗叫声的新的观点和发现。

    

    解析动物语言的语义一直是一个重大挑战。本研究通过将不同声音类型与一致的语义相关联，对狗叫声的语义进行了数据驱动的研究。我们首先提出了一个新的Shiba Inu声音数据集，同时还收集了来自YouTube的上下文信息，如位置和活动，通过一套完善的流程。该框架也适用于其他动物物种。通过研究狗叫声与相应的位置和活动之间的条件概率分析，我们发现了支持以前启发式研究关于不同狗叫声的语义意义的证据。例如，咆哮可以表示互动。此外，我们的研究还得出了新的观点，即现有的词汇类型可以细分为更精细的子类型，对于Shiba Inu来说，最小的语义单元是与词汇相关的。例如，呜咽声可以细分为两种类型，求关注和不适。

    Deciphering the semantics of animal language has been a grand challenge. This study presents a data-driven investigation into the semantics of dog vocalizations via correlating different sound types with consistent semantics. We first present a new dataset of Shiba Inu sounds, along with contextual information such as location and activity, collected from YouTube with a well-constructed pipeline. The framework is also applicable to other animal species. Based on the analysis of conditioned probability between dog vocalizations and corresponding location and activity, we discover supporting evidence for previous heuristic research on the semantic meaning of various dog sounds. For instance, growls can signify interactions. Furthermore, our study yields new insights that existing word types can be subdivided into finer-grained subtypes and minimal semantic unit for Shiba Inu is word-related. For example, whimper can be subdivided into two types, attention-seeking and discomfort.
    
[^17]: SPICED: 具有多个主题和复杂程度的新闻相似性检测数据集

    SPICED: News Similarity Detection Dataset with Multiple Topics and Complexity Levels. (arXiv:2309.13080v1 [cs.CL])

    [http://arxiv.org/abs/2309.13080](http://arxiv.org/abs/2309.13080)

    这个论文提出了一个名为SPICED的新闻相似性检测数据集，包括七个主题，并提供了四种不同的方法来生成新闻。

    

    如今，使用智能系统来检测新闻文章中的冗余信息已经变得非常普遍，以增强用户体验，尤其是随着新闻媒体的蓬勃发展。然而，新闻的异质性可能导致这些系统中的虚假发现：简单的启发式算法，比如一对新闻是否都涉及政治问题，可以提供强大但具有误导性的下游性能。将新闻相似性数据集分割成主题可以通过强制模型学习如何在更狭窄的领域中区分显著特征来改进这些模型的训练。然而，这需要存在目前缺乏的专题特定数据集。在本文中，我们提出了一个新的相似新闻数据集SPICED，其中包括七个主题：犯罪与法律、文化与娱乐、灾难与事故、经济与商业、政治与冲突、科学与技术以及体育。此外，我们提供了四种不同的方法来生成新闻。

    Nowadays, the use of intelligent systems to detect redundant information in news articles has become especially prevalent with the proliferation of news media outlets in order to enhance user experience. However, the heterogeneous nature of news can lead to spurious findings in these systems: Simple heuristics such as whether a pair of news are both about politics can provide strong but deceptive downstream performance. Segmenting news similarity datasets into topics improves the training of these models by forcing them to learn how to distinguish salient characteristics under more narrow domains. However, this requires the existence of topic-specific datasets, which are currently lacking. In this article, we propose a new dataset of similar news, SPICED, which includes seven topics: Crime & Law, Culture & Entertainment, Disasters & Accidents, Economy & Business, Politics & Conflicts, Science & Technology, and Sports. Futhermore, we present four distinct approaches for generating news 
    
[^18]: MiChao-HuaFen 1.0：面向领域特定大模型的专用预训练语料数据集

    MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models. (arXiv:2309.13079v1 [cs.CL])

    [http://arxiv.org/abs/2309.13079](http://arxiv.org/abs/2309.13079)

    MiChao-HuaFen 1.0是一个专为新闻和政府部门定制的面向领域特定大模型的预训练语料数据集，它不仅能够满足特定领域的高质量需求，还有助于推动相关领域的深度学习研究和应用。

    

    随着深度学习技术的进步，如GPT-4等通用大模型已经在各个领域展现出卓越的能力。然而，在诸如医疗、法律和金融等领域仍然存在对高质量的领域特定输出的需求。本文首先评估了现有的面向特定领域的大模型，并讨论了它们的局限性。为了满足特定领域的特殊需求，我们引入了“MiChao-HuaFen 1.0”预训练语料数据集，该数据集特别针对新闻和政府部门。该数据集来源于2022年公开可用的互联网数据，经过多轮清洁和处理以确保高质量和可靠性，并具备持续和稳定的更新机制。该数据集不仅支持针对中文垂直领域的大模型的预训练，还助力于推动相关领域的深度学习研究和应用。

    With the advancement of deep learning technologies, general-purpose large models such as GPT-4 have demonstrated exceptional capabilities across various domains. Nevertheless, there remains a demand for high-quality, domain-specific outputs in areas like healthcare, law, and finance. This paper first evaluates the existing large models for specialized domains and discusses their limitations. To cater to the specific needs of certain domains, we introduce the ``MiChao-HuaFen 1.0'' pre-trained corpus dataset, tailored for the news and governmental sectors. The dataset, sourced from publicly available internet data from 2022, underwent multiple rounds of cleansing and processing to ensure high quality and reliable origins, with provisions for consistent and stable updates. This dataset not only supports the pre-training of large models for Chinese vertical domains but also aids in propelling deep learning research and applications in related fields.
    
[^19]: SCREWS: 一种用于推理修订的模块化框架

    SCREWS: A Modular Framework for Reasoning with Revisions. (arXiv:2309.13075v1 [cs.AI])

    [http://arxiv.org/abs/2309.13075](http://arxiv.org/abs/2309.13075)

    SCREWS是一个模块化框架，用于推理修订。它能够统一先前的方法并提供新的策略来识别改进的推理链。在多样的推理任务上，使用最先进的LLMs（ChatGPT和GPT-4）评估SCREWS的性能，并发现了有用的新的推理策略。

    

    大型语言模型 (LLMs) 可以通过根据反馈不断改进和修订其输出来提高在各种任务上的准确性。我们观察到这些修订可能会引入错误，如果是这样的话，最好回滚到先前的结果。此外，修订通常是同质的：它们使用与产生初始答案的相同推理方法，这可能无法纠正错误。为了在这个领域中进行探索，我们提出了 SCREWS，一种用于推理修订的模块化框架。它由三个主要模块组成: 采样、条件重新采样和选择，每个模块都包含可以根据任务手动选择的子模块。我们展示了 SCREWS 不仅将几个先前的方法统一到一个共同的框架中，还揭示了几种用于识别改进的推理链的新策略。我们使用最先进的LLMs （ChatGPT 和 GPT-4）在多样的推理任务上评估我们的框架，并揭示了有用的新的推理策略。

    Large language models (LLMs) can improve their accuracy on various tasks through iteratively refining and revising their output based on feedback. We observe that these revisions can introduce errors, in which case it is better to roll back to a previous result. Further, revisions are typically homogeneous: they use the same reasoning method that produced the initial answer, which may not correct errors. To enable exploration in this space, we present SCREWS, a modular framework for reasoning with revisions. It is comprised of three main modules: Sampling, Conditional Resampling, and Selection, each consisting of sub-modules that can be hand-selected per task. We show that SCREWS not only unifies several previous approaches under a common framework, but also reveals several novel strategies for identifying improved reasoning chains. We evaluate our framework with state-of-the-art LLMs (ChatGPT and GPT-4) on a diverse set of reasoning tasks and uncover useful new reasoning strategies fo
    
[^20]: 基于神经符号方法的弱监督推理

    Weakly Supervised Reasoning by Neuro-Symbolic Approaches. (arXiv:2309.13072v1 [cs.CL])

    [http://arxiv.org/abs/2309.13072](http://arxiv.org/abs/2309.13072)

    本文介绍了一种基于神经符号方法的弱监督推理框架，该框架将符号主义和连接主义结合起来，成功应用于各种自然语言处理任务，并通过设计具有符号潜在结构的神经系统，并应用强化学习或松弛方法来进行推理。

    

    深度学习极大地提高了各种自然语言处理（NLP）任务的性能。然而，大多数深度学习模型是黑盒机器，缺乏明确的解释。在本章中，我们将介绍我们在NLP方面的神经符号方法的最新进展，该方法结合了不同的人工智能学派，即符号主义和连接主义。一般而言，我们会设计一个带有符号潜在结构的神经系统，用于NLP任务，并应用强化学习或其松弛方法来进行下游任务中的弱监督推理。我们的框架已成功应用于各种任务，包括表格查询推理、句法结构推理、信息抽取推理和规则推理。对于每个应用，我们将介绍背景、我们的方法和实验结果。

    Deep learning has largely improved the performance of various natural language processing (NLP) tasks. However, most deep learning models are black-box machinery, and lack explicit interpretation. In this chapter, we will introduce our recent progress on neuro-symbolic approaches to NLP, which combines different schools of AI, namely, symbolism and connectionism. Generally, we will design a neural system with symbolic latent structures for an NLP task, and apply reinforcement learning or its relaxation to perform weakly supervised reasoning in the downstream task. Our framework has been successfully applied to various tasks, including table query reasoning, syntactic structure reasoning, information extraction reasoning, and rule reasoning. For each application, we will introduce the background, our approach, and experimental results.
    
[^21]: 基于机器学习技术的假新闻检测

    Machine Learning Technique Based Fake News Detection. (arXiv:2309.13069v1 [cs.CL])

    [http://arxiv.org/abs/2309.13069](http://arxiv.org/abs/2309.13069)

    本论文通过使用机器学习技术训练了一个模型，可以有效地检测假新闻。在实验中，我们发现朴素贝叶斯分类器的准确率为56%，是最佳模型。

    

    假新闻引起了公众和学术界的关注。这种虚假信息有能力影响公众的看法，给恶意团体影响公共事件（如选举）的机会。任何人都可以分享关于任何人或任何事情的虚假新闻或事实，以谋取个人利益或给某人带来麻烦。此外，信息因分享的地区而异。因此，在本文中，我们使用我们收集的1876条新闻数据训练了一个模型，通过使用自然语言处理方法对数据进行预处理，从而获得干净和过滤的文本。我们的研究使用了3个流行的机器学习算法（随机梯度下降、朴素贝叶斯、逻辑回归）和2个深度学习算法（长短期记忆、权重丢弃LSTM或AWD-LSTM）。经过我们的研究，我们发现了准确率为56%，F1-macro分数为的最佳朴素贝叶斯分类器。

    False news has received attention from both the general public and the scholarly world. Such false information has the ability to affect public perception, giving nefarious groups the chance to influence the results of public events like elections. Anyone can share fake news or facts about anyone or anything for their personal gain or to cause someone trouble. Also, information varies depending on the part of the world it is shared on. Thus, in this paper, we have trained a model to classify fake and true news by utilizing the 1876 news data from our collected dataset. We have preprocessed the data to get clean and filtered texts by following the Natural Language Processing approaches. Our research conducts 3 popular Machine Learning (Stochastic gradient descent, Na\"ive Bayes, Logistic Regression,) and 2 Deep Learning (Long-Short Term Memory, ASGD Weight-Dropped LSTM, or AWD-LSTM) algorithms. After we have found our best Naive Bayes classifier with 56% accuracy and an F1-macro score o
    
[^22]: 个性化分析：社交媒体资料在预测个人信息方面有多有用？

    Personality Profiling: How informative are social media profiles in predicting personal information?. (arXiv:2309.13065v1 [cs.CL])

    [http://arxiv.org/abs/2309.13065](http://arxiv.org/abs/2309.13065)

    这项研究探索了利用社交媒体资料预测个人信息的个性化分析模型的准确性和多用途性，并发现支持向量机模型在预测个性类型方面具有最佳准确率，而逻辑回归模型在速度和准确性上表现较好。

    

    公司利用个性化分析进行定向广告、政治宣传和疫苗宣传。然而，这些模型的准确性和多用途性仍然相对未知。因此，我们旨在探索人们的在线数字足迹能够被用来分析其迈尔斯-布里格斯人格类型的程度。我们分析和比较了四个模型的结果：逻辑回归、朴素贝叶斯、支持向量机（SVM）和随机森林。我们发现SVM模型在预测某人的完整个性类型方面达到了最佳准确率20.95%。然而，逻辑回归模型的表现只稍微差一些，并且在训练和进行预测时速度更快。我们发现许多标记数据集在社交媒体上呈现出个人特征的严重类别不平衡，包括我们自己的数据集。因此，我们强调需要在报告这些数据集上模型性能时进行仔细考虑。

    Personality profiling has been utilised by companies for targeted advertising, political campaigns and vaccine campaigns. However, the accuracy and versatility of such models still remains relatively unknown. Consequently, we aim to explore the extent to which peoples' online digital footprints can be used to profile their Myers-Briggs personality type. We analyse and compare the results of four models: logistic regression, naive Bayes, support vector machines (SVMs) and random forests. We discover that a SVM model achieves the best accuracy of 20.95% for predicting someones complete personality type. However, logistic regression models perform only marginally worse and are significantly faster to train and perform predictions. We discover that many labelled datasets present substantial class imbalances of personal characteristics on social media, including our own. As a result, we highlight the need for attentive consideration when reporting model performance on these datasets and com
    
[^23]: 使用大型语言模型生成、验证和应用用户意图分类方法

    Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies. (arXiv:2309.13063v1 [cs.IR])

    [http://arxiv.org/abs/2309.13063](http://arxiv.org/abs/2309.13063)

    通过使用大型语言模型生成用户意图分类，我们提出了一种新方法来分析和验证日志数据中的用户意图，从而解决了手动或基于机器学习的标注方法在大型和不断变化的数据集上的问题。

    

    日志数据可以揭示用户与网络搜索服务的交互方式、用户的需求以及满意程度等宝贵信息。然而，分析日志数据中的用户意图并不容易，尤其是对于新的网络搜索形式，如人工智能驱动的聊天。为了理解日志数据中的用户意图，我们需要一种能够用有意义的分类方式标记它们的方法，以捕捉其多样性和动态性。现有的方法依赖于手动或基于机器学习的标注，这些方法对于大型且不断变化的数据集而言，要么代价高昂要么不够灵活。我们提出了一种使用大型语言模型(LLM)的新方法，这种模型能够生成丰富且相关的概念、描述和示例来表示用户意图。然而，使用LLM生成用户意图分类并将其应用于日志分析可能存在两个主要问题：这样的分类得不到外部验证，并且可能存在不良的反馈回路。为了克服这些问题，我们提出了一种新的方法，通过人工专家和评估者来验证。

    Log data can reveal valuable information about how users interact with web search services, what they want, and how satisfied they are. However, analyzing user intents in log data is not easy, especially for new forms of web search such as AI-driven chat. To understand user intents from log data, we need a way to label them with meaningful categories that capture their diversity and dynamics. Existing methods rely on manual or ML-based labeling, which are either expensive or inflexible for large and changing datasets. We propose a novel solution using large language models (LLMs), which can generate rich and relevant concepts, descriptions, and examples for user intents. However, using LLMs to generate a user intent taxonomy and apply it to do log analysis can be problematic for two main reasons: such a taxonomy is not externally validated, and there may be an undesirable feedback loop. To overcome these issues, we propose a new methodology with human experts and assessors to verify th
    
[^24]: 将BioBERT应用于从生物医学文献中提取生殖细胞系基因与疾病关联以构建知识图谱

    Applying BioBERT to Extract Germline Gene-Disease Associations for Building a Knowledge Graph from the Biomedical Literature. (arXiv:2309.13061v1 [cs.CL])

    [http://arxiv.org/abs/2309.13061](http://arxiv.org/abs/2309.13061)

    本研究提出了一种自动知识图谱构建方法，利用BioBERT模型从生物医学文献中提取生殖细胞系基因与疾病的关联，展示了这一领域的重要工作。

    

    发表的生物医学信息数量不断增加。自然语言处理(NLP)的最新进展引起了人们对自动提取、规范化和表示生物医学实体(如基因和疾病)知识的浓厚兴趣。本研究分析了基因和疾病领域的生殖细胞系摘要，用于构建知识图谱以展示这一领域的大量工作。本文介绍了一种名为SimpleGermKG的自动知识图谱构建方法，将生殖细胞系基因和疾病联系起来。我们使用了在生物医学语料库上预训练的BioBERT模型来提取基因和疾病，提出了一种基于本体和规则的算法来规范化和消歧义医学术语。对于文章、基因和疾病之间的语义关系，我们实现了一种部分-整体关系方法来将每个实体与其数据源连接并以图形化知识展示。

    Published biomedical information has and continues to rapidly increase. The recent advancements in Natural Language Processing (NLP), have generated considerable interest in automating the extraction, normalization, and representation of biomedical knowledge about entities such as genes and diseases. Our study analyzes germline abstracts in the construction of knowledge graphs of the of the immense work that has been done in this area for genes and diseases. This paper presents SimpleGermKG, an automatic knowledge graph construction approach that connects germline genes and diseases. For the extraction of genes and diseases, we employ BioBERT, a pre-trained BERT model on biomedical corpora. We propose an ontology-based and rule-based algorithm to standardize and disambiguate medical terms. For semantic relationships between articles, genes, and diseases, we implemented a part-whole relation approach to connect each entity with its data source and visualize them in a graph-based knowled
    
[^25]: ChatPRCS: 基于ChatGPT的个性化英语阅读理解辅助系统

    ChatPRCS: A Personalized Support System for English Reading Comprehension based on ChatGPT. (arXiv:2309.12808v1 [cs.CL])

    [http://arxiv.org/abs/2309.12808](http://arxiv.org/abs/2309.12808)

    本研究提出了一种基于ChatGPT的个性化英语阅读理解辅助系统ChatPRCS。通过利用大型语言模型的先进能力，该系统采用阅读理解能力预测、问题生成、自动评估等方法来增强阅读理解教学。使用学生的历史数据来预测阅读理解能力，并生成适当难度的问题。辅助系统提供了个体化的阅读理解训练支持。

    

    作为学习英语的常见方法，阅读理解主要包括阅读文章和回答相关问题。然而，设计有效练习的复杂性导致学生遇到标准化问题，使其难以与个体化学习者的阅读理解能力相匹配。本文利用大型语言模型（如ChatGPT）提供的先进能力，基于近发展区理论提出了一种新型个性化阅读理解辅助系统ChatPRCS。ChatPRCS采用阅读理解能力预测、问题生成、自动评估等方法，以增强阅读理解教学。首先，我们开发了一种新的算法，可以根据学习者的历史数据预测他们的阅读理解能力，为生成具有相应难度水平的问题奠定基础。其次，我们设计了一系列的阅读理解支持功能，如问题生成、自动评估等，来帮助学生进行个性化的阅读理解训练。

    As a common approach to learning English, reading comprehension primarily entails reading articles and answering related questions. However, the complexity of designing effective exercises results in students encountering standardized questions, making it challenging to align with individualized learners' reading comprehension ability. By leveraging the advanced capabilities offered by large language models, exemplified by ChatGPT, this paper presents a novel personalized support system for reading comprehension, referred to as ChatPRCS, based on the Zone of Proximal Development theory. ChatPRCS employs methods including reading comprehension proficiency prediction, question generation, and automatic evaluation, among others, to enhance reading comprehension instruction. First, we develop a new algorithm that can predict learners' reading comprehension abilities using their historical data as the foundation for generating questions at an appropriate level of difficulty. Second, a serie
    
[^26]: 大型语言模型下的创造力支持: 一项涉及新兴作家的实证研究

    Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers. (arXiv:2309.12570v1 [cs.HC])

    [http://arxiv.org/abs/2309.12570](http://arxiv.org/abs/2309.12570)

    本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。

    

    大型语言模型（LLM）的发展使得其能够遵循指令并参与对话互动，引发了在各种支持工具中利用它们的兴趣增加。我们通过一项实证用户研究（n=30）探讨了现代LLM在协助专业作家方面的效用。我们的合作写作界面设计基于将写作视为一个目标导向的思维过程的认知过程模型，涵盖了非线性的认知活动：规划、翻译和审查。参与者被要求提交一份后完成调查，以提供关于LLM作为写作合作者潜力和问题的反馈。通过分析作家-LLM互动,我们发现作家在三种类型的认知活动中都寻求LLM的帮助，但他们发现LLM在翻译和审查方面更有帮助。通过分析互动和调查结果，我们的发现强调了未来研究的方向。

    The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions sparked increased interest in their utilization across various support tools. We investigate the utility of modern LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing that views writing as a goal-oriented thinking process encompassing non-linear cognitive activities: planning, translating, and reviewing. Participants are asked to submit a post-completion survey to provide feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research direc
    
[^27]: 翻转诅咒: 在大型语言模型中训练的"A是B"无法学习"B是A"

    The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A". (arXiv:2309.12288v1 [cs.CL])

    [http://arxiv.org/abs/2309.12288](http://arxiv.org/abs/2309.12288)

    LLMs模型在训练中只能学习到"A是B"的结构，无法自动推广到"B是A"。这表明模型在逻辑推断上存在基本失败和训练集中模式的推广问题。

    

    我们揭示了自回归大型语言模型（LLM）在泛化上的令人惊讶的失败。如果一个模型是基于"A是B"形式的句子进行训练，它不会自动推广到相反的方向"B是A"。这就是翻转诅咒。例如，如果一个模型是基于"Olaf Scholz是德国第九任总理"进行训练的，它不会自动能够回答问题"谁是德国第九任总理？"。此外，正确答案（"Olaf Scholz"）的可能性不会比随机名字更高。因此，模型在逻辑推断上存在基本失败，并且不会推广到它们训练集中的普遍模式（即如果出现"A是B"，则"B是A"更可能出现）。我们通过在虚构的陈述（如"Uriah Hawthorne是'Abyssal Melodies'的作曲家"）上对GPT-3和Llama-1进行微调，并展示它们无法正确回答"谁创作了'Abyssal Melodies'?"来提供翻转诅咒的证据。

    We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form "A is B", it will not automatically generalize to the reverse direction "B is A". This is the Reversal Curse. For instance, if a model is trained on "Olaf Scholz was the ninth Chancellor of Germany", it will not automatically be able to answer the question, "Who was the ninth Chancellor of Germany?". Moreover, the likelihood of the correct answer ("Olaf Scholz") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if "A is B'' occurs, "B is A" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as "Uriah Hawthorne is the composer of 'Abyssal Melodies'" and showing that they fail to correctly answer "Who composed 'Abyssal Melodies?'". The Reversal Cu
    
[^28]: 剑桥法律语料库：用于法律人工智能研究的语料库

    The Cambridge Law Corpus: A Corpus for Legal AI Research. (arXiv:2309.12269v1 [cs.CL])

    [http://arxiv.org/abs/2309.12269](http://arxiv.org/abs/2309.12269)

    剑桥法律语料库是一个用于法律人工智能研究的语料库，包含来自英国的超过250,000个法庭案例。在该语料库的基础上，我们提供了案例结果的专家注解，并使用多个模型进行了案例结果提取的训练和评估，为研究提供了基准。

    

    我们介绍了剑桥法律语料库（CLC），这是一个用于法律人工智能研究的语料库。它包含了来自英国的超过250,000个法庭案例。大部分案例来自21世纪，但该语料库包括了16世纪以来的案例。本文介绍了该语料库的首次发布，包括原始文本和元数据。在语料库的基础上，我们提供了638个案例的法律专家对案例结果的注解。我们使用我们的标注数据，训练和评估了GPT-3、GPT-4和RoBERTa模型进行案例结果提取，以提供基准。我们还进行了广泛的法律和伦理讨论，以解决这些材料可能具有敏感性的问题。因此，该语料库只会在一定限制下用于研究目的。

    We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.
    
[^29]: 链式验证减少大型语言模型中的幻觉

    Chain-of-Verification Reduces Hallucination in Large Language Models. (arXiv:2309.11495v1 [cs.CL])

    [http://arxiv.org/abs/2309.11495](http://arxiv.org/abs/2309.11495)

    该论文提出了一种链式验证方法（CoVe），通过在回答之前进行备查问题来减少大型语言模型中的幻觉。实验证明CoVe方法在各种任务中都能有效降低幻觉的发生。

    

    大型语言模型中存在生成合理但不正确的事实信息（即幻觉）的问题，我们研究了语言模型在给出回复时进行思考以纠正错误的能力。我们开发了一种链式验证（CoVe）方法，模型首先（i）起草初始回复；然后（ii）计划验证问题来事实检查草稿；（iii）独立回答这些问题，以避免答案受其他回复的影响；最后（iv）生成最终的经过验证的回答。在实验中，我们展示了CoVe在各种任务中降低了幻觉的情况，包括来自维基数据的列表问题、封闭书籍MultiSpanQA和长文本生成。

    Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response. In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation.
    
[^30]: 利用数据收集和无监督学习进行切换突尼斯阿拉伯语的自动语音识别

    Leveraging Data Collection and Unsupervised Learning for Code-switched Tunisian Arabic Automatic Speech Recognition. (arXiv:2309.11327v1 [eess.AS])

    [http://arxiv.org/abs/2309.11327](http://arxiv.org/abs/2309.11327)

    本研究通过收集和标注数据以及探索切换方法，提出了一种有效的突尼斯方言自动语音识别解决方案，并且通过人工评估来消除拼写不合适的干扰。

    

    开发能够有效识别方言的自动语音识别（ASR）解决方案需要创新的方法，不仅要解决数据稀缺问题，还要处理语言多样性的复杂性。本文针对突尼斯方言，解决了上述ASR挑战。首先，收集了文本和音频数据，并且在某些情况下进行了标注。其次，我们探索自我监督、半监督和少样本切换方法，以在不同突尼斯测试集上推动最先进的技术；涵盖不同的声学、语言和韵律条件。最后，鉴于常规拼写的缺失，我们对转录进行人工评估，以避免测试参考中的拼写不合适所带来的噪声。我们的模型可以转录突尼斯阿拉伯语、英语和法语混合语言的音频样本，并公开发布了所有训练和测试所使用的数据，供公众使用和进一步改进。

    Crafting an effective Automatic Speech Recognition (ASR) solution for dialects demands innovative approaches that not only address the data scarcity issue but also navigate the intricacies of linguistic diversity. In this paper, we address the aforementioned ASR challenge, focusing on the Tunisian dialect. First, textual and audio data is collected and in some cases annotated. Second, we explore self-supervision, semi-supervision and few-shot code-switching approaches to push the state-of-the-art on different Tunisian test sets; covering different acoustic, linguistic and prosodic conditions. Finally, and given the absence of conventional spelling, we produce a human evaluation of our transcripts to avoid the noise coming from spelling inadequacies in our testing references. Our models, allowing to transcribe audio samples in a linguistic mix involving Tunisian Arabic, English and French, and all the data used during training and testing are released for public use and further improvem
    
[^31]: DISC-LawLLM:为智能法律服务细调大型语言模型

    DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services. (arXiv:2309.11325v1 [cs.CL])

    [http://arxiv.org/abs/2309.11325](http://arxiv.org/abs/2309.11325)

    DISC-LawLLM是一种利用大型语言模型(LLMs)为智能法律服务细调的智能法律系统，通过采用法律推理提示策略和增强的检索模块，提供了在中国司法领域多样化法律场景下的有效法律服务。

    

    我们提出了DISC-LawLLM，一种利用大型语言模型(LLMs)提供各种法律服务的智能法律系统。我们采用法律推理提示策略，在中国司法领域构建了监督微调数据集，并使用具备法律推理能力的LLMs进行微调。我们利用检索模块增强了LLMs的能力，以访问和利用外部法律知识。我们还提出了一个全面的法律基准评估系统，DISC-Law-Eval，从客观和主观两个维度评估智能法律系统的性能。在DISC-Law-Eval上的定量和定性结果表明，我们的系统在为不同法律场景下的各种用户提供服务方面具有有效性。详细的资源可以在https://github.com/FudanDISC/DISC-LawLLM上查看。

    We propose DISC-LawLLM, an intelligent legal system utilizing large language models (LLMs) to provide a wide range of legal services. We adopt legal syllogism prompting strategies to construct supervised fine-tuning datasets in the Chinese Judicial domain and fine-tune LLMs with legal reasoning capability. We augment LLMs with a retrieval module to enhance models' ability to access and utilize external legal knowledge. A comprehensive legal benchmark, DISC-Law-Eval, is presented to evaluate intelligent legal systems from both objective and subjective dimensions. Quantitative and qualitative results on DISC-Law-Eval demonstrate the effectiveness of our system in serving various users across diverse legal scenarios. The detailed resources are available at https://github.com/FudanDISC/DISC-LawLLM.
    
[^32]: 通过大型语言模型进行隐私保护掩码的恢复

    Recovering from Privacy-Preserving Masking with Large Language Models. (arXiv:2309.08628v1 [cs.CL])

    [http://arxiv.org/abs/2309.08628](http://arxiv.org/abs/2309.08628)

    本文利用大型语言模型（LLM）探索了替换标识信息的方法，并在下游语言建模任务上进行了评估。实验结果表明，使用混淆语料库训练的模型能够达到可比较的性能。

    

    模型适应对于处理代理训练数据和实际用户数据之间的差异非常重要。为了有效地进行适应，用户的文本数据通常存储在服务器或本地设备上，下游的自然语言处理模型可以使用这些领域内的数据进行直接训练。然而，这可能会引起隐私和安全问题，因为存在向对手泄露用户信息的额外风险。最近，人们开始探索使用通用标记替换文本中的标识信息。在这项工作中，我们利用大型语言模型（LLM）来建议替换掩码标记的方法，并在下游语言建模任务上评估其效果。具体而言，我们提出了多种基于预训练和微调的LLM方法，并在不同数据集上进行实证研究以比较这些方法。实验结果表明，在混淆语料库上训练的模型能够达到可比较的性能。

    Model adaptation is crucial to handle the discrepancy between proxy training data and actual users data received. To effectively perform adaptation, textual data of users is typically stored on servers or their local devices, where downstream natural language processing (NLP) models can be directly trained using such in-domain data. However, this might raise privacy and security concerns due to the extra risks of exposing user information to adversaries. Replacing identifying information in textual data with a generic marker has been recently explored. In this work, we leverage large language models (LLMs) to suggest substitutes of masked tokens and have their effectiveness evaluated on downstream language modeling tasks. Specifically, we propose multiple pre-trained and fine-tuned LLM-based approaches and perform empirical studies on various datasets for the comparison of these methods. Experimental results show that models trained on the obfuscation corpora are able to achieve compar
    
[^33]: 安全调优的LLaMAs：从提高大型语言模型遵循指令的安全性中学到的经验

    Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions. (arXiv:2309.07875v1 [cs.CL])

    [http://arxiv.org/abs/2309.07875](http://arxiv.org/abs/2309.07875)

    在训练大型语言模型遵循指令时，仅强调帮助性而不考虑安全性会导致模型产生有害内容。本研究发现，在训练LLaMA模型时添加少量安全示例可以显著提高其安全性，而不影响其能力和帮助性。然而，过度安全调优会使模型拒绝回应表面上类似于不安全提示的合理提示。

    

    训练大型语言模型遵循指令可以使它们在各种任务上表现得更好，通常更具有帮助性。然而，一个完全有用的模型会遵循甚至最恶意的指令，并轻易生成有害内容。本文关注的是那些只强调帮助性而不考虑安全性的模型的安全性问题。我们展示了一些流行的指令调优模型非常不安全。此外，我们还展示了在fine-tuning类似LLaMA的模型时，只需将3%的安全示例（几百个演示）添加到训练集中，就能显著提高其安全性。我们的安全调优并不会显著降低模型的能力或帮助性，这是通过标准基准测试来衡量的。但是，我们发现一种过度安全的行为，即过度的安全调优会使得模型拒绝对表面上类似于不安全提示的合理提示做出回应。我们的研究揭示了训练LLM模型遵循指令时的权衡关系。

    Training large language models to follow instructions makes them perform better on a wide range of tasks, generally becoming more helpful. However, a perfectly helpful model will follow even the most malicious instructions and readily generate harmful content. In this paper, we raise concerns over the safety of models that only emphasize helpfulness, not safety, in their instruction-tuning. We show that several popular instruction-tuned models are highly unsafe. Moreover, we show that adding just 3% safety examples (a few hundred demonstrations) in the training set when fine-tuning a model like LLaMA can substantially improve their safety. Our safety-tuning does not make models significantly less capable or helpful as measured by standard benchmarks. However, we do find a behavior of exaggerated safety, where too much safety-tuning makes models refuse to respond to reasonable prompts that superficially resemble unsafe ones. Our study sheds light on trade-offs in training LLMs to follow
    
[^34]: DBLPLink: 一个用于DBLP学术知识图的实体链接器

    DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph. (arXiv:2309.07545v1 [cs.CL])

    [http://arxiv.org/abs/2309.07545](http://arxiv.org/abs/2309.07545)

    DBLPLink是一个用于DBLP学术知识图的实体链接器，它使用文本到文本的预训练语言模型和实体嵌入来进行实体标签生成和排序。

    

    在这项工作中，我们介绍了一个名为DBLPLink的网络应用程序，它在DBLP学术知识图上执行实体链接。DBLPLink使用文本到文本的预训练语言模型（如T5）从输入的文本问题中生成实体标签跨度。基于这些标签，从数据库中获取实体候选项，并使用实体嵌入（如TransE、DistMult和ComplEx）对它们进行排序。结果以用户可以比较和对比T5-small、T5-base和不同的知识图嵌入之间的结果。演示可以在https://ltdemos.informatik.uni-hamburg.de/dblplink/访问。

    In this work, we present a web application named DBLPLink, which performs entity linking over the DBLP scholarly knowledge graph. DBLPLink uses text-to-text pre-trained language models, such as T5, to produce entity label spans from an input text question. Entity candidates are fetched from a database based on the labels, and an entity re-ranker sorts them based on entity embeddings, such as TransE, DistMult and ComplEx. The results are displayed so that users may compare and contrast the results between T5-small, T5-base and the different KG embeddings used. The demo can be accessed at https://ltdemos.informatik.uni-hamburg.de/dblplink/.
    
[^35]: 使用图链接预测在生活方式vlog中的人类动作共现

    Human Action Co-occurrence in Lifestyle Vlogs using Graph Link Prediction. (arXiv:2309.06219v1 [cs.CV])

    [http://arxiv.org/abs/2309.06219](http://arxiv.org/abs/2309.06219)

    该论文提出了自动识别人类动作共现的任务，并创建了ACE数据集以及相应的代码。通过利用视觉和文本信息的图链接预测模型，可以有效捕捉不同数据域中的人类动作关系。

    

    我们介绍了自动识别人类动作共现的任务，即确定两个人类动作是否可以在同一时间间隔内共现。我们创建并公开了ACE（Action Co-occurrencE）数据集，该数据集由约12k个共现的视觉动作对和它们对应的视频片段组成的大型图形。我们描述了利用视觉和文本信息来自动推断两个动作是否共现的图链接预测模型。我们证明了图形特别适合捕捉人类动作之间的关系，并且所学习的图形表示对于我们的任务是有效的，并且在不同的数据域中捕捉到新颖而相关的信息。本文介绍的ACE数据集和代码可在https://github.com/MichiganNLP/vlog_action_co-occurrence公开获取。

    We introduce the task of automatic human action co-occurrence identification, i.e., determine whether two human actions can co-occur in the same interval of time. We create and make publicly available the ACE (Action Co-occurrencE) dataset, consisting of a large graph of ~12k co-occurring pairs of visual actions and their corresponding video clips. We describe graph link prediction models that leverage visual and textual information to automatically infer if two actions are co-occurring. We show that graphs are particularly well suited to capture relations between human actions, and the learned graph representations are effective for our task and capture novel and relevant information across different data domains. The ACE dataset and the code introduced in this paper are publicly available at https://github.com/MichiganNLP/vlog_action_co-occurrence.
    
[^36]: 语言模型作为视觉-语言模型的黑盒优化器

    Language Models as Black-Box Optimizers for Vision-Language Models. (arXiv:2309.05950v1 [cs.CL])

    [http://arxiv.org/abs/2309.05950](http://arxiv.org/abs/2309.05950)

    本论文介绍了一种新的视觉-语言模型 (VLMs) 微调方法，通过自然语言提示来避免访问模型参数，采用聊天式的语言模型作为黑盒优化器，在少样本图像分类任务中达到效果。

    

    预训练在大规模网络数据集上的视觉-语言模型 (VLMs) 展示了在各种视觉和多模态任务中的显著能力。目前，VLMs 的微调方法主要在白盒环境中操作，需要访问模型参数进行反向传播。然而，许多 VLMs 依赖于专有数据且不开源，限制了使用白盒方法进行微调。鉴于像 ChatGPT 这样的受欢迎私有大型语言模型 (LLMs) 仍然提供基于语言的用户界面，我们旨在通过自然语言提示开发一种新的 VLMs 微调方法，从而避免访问模型参数、特征嵌入或输出 logits 的需要。在这种设置下，我们提出使用基于聊天的 LLMs 作为黑盒优化器，以在使用 CLIP 进行少样本图像分类的示例任务中寻找最佳文本提示。具体而言，我们采用自动"爬山"程序，它能收敛到有效的提示上。

    Vision-language models (VLMs) pre-trained on web-scale datasets have demonstrated remarkable capabilities across a variety of vision and multimodal tasks. Currently, fine-tuning methods for VLMs mainly operate in a white-box setting, requiring access to model parameters for backpropagation. However, many VLMs rely on proprietary data and are not open-source, which restricts the use of white-box approaches for fine-tuning. Given that popular private large language models (LLMs) like ChatGPT still offer a language-based user interface, we aim to develop a novel fine-tuning approach for VLMs through natural language prompts, thereby avoiding the need to access model parameters, feature embeddings, or output logits. In this setup, we propose employing chat-based LLMs as black-box optimizers to search for the best text prompt on the illustrative task of few-shot image classification using CLIP. Specifically, we adopt an automatic "hill-climbing" procedure that converges on an effective prom
    
[^37]: HAE-RAE Bench: 评估语言模型对韩国知识的表现

    HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models. (arXiv:2309.02706v1 [cs.CL])

    [http://arxiv.org/abs/2309.02706](http://arxiv.org/abs/2309.02706)

    HAE-RAE Bench评估了语言模型对韩国知识的表现，发现使用比GPT-3.5小的特定语言模型可以实现类似的性能水平，强调了同质语料库在训练专业级语言特定模型中的重要性。

    

    在大规模预训练的语言模型(LLMs)在各种任务中展现出了显著的能力，但是对非英语语言的关注在这个领域的研究中有限。为了弥补这一空白并评估语言模型在韩语语言和文化方面的熟练程度，我们提出了HAE-RAE Bench，在词汇、历史和一般知识等6个任务上进行评估。我们对语言模型在这个基准上的评估突出了使用大型特定语言模型(LLSMs)与像GPT-3.5这样的全面通用模型相比的潜在优势。值得注意的是，我们的研究发现，比GPT-3.5约小13倍的模型，可以在语言特定知识检索方面展现出类似的性能水平。这一观察强调了在训练专业级语言特定模型时同质语料库的重要性。相反，当这些较小的模型在......

    Large Language Models (LLMs) pretrained on massive corpora exhibit remarkable capabilities across a wide range of tasks, however, the attention given to non-English languages has been limited in this field of research. To address this gap and assess the proficiency of language models in the Korean language and culture, we present HAE-RAE Bench, covering 6 tasks including vocabulary, history, and general knowledge. Our evaluation of language models on this benchmark highlights the potential advantages of employing Large Language-Specific Models(LLSMs) over a comprehensive, universal model like GPT-3.5. Remarkably, our study reveals that models approximately 13 times smaller than GPT-3.5 can exhibit similar performance levels in terms of language-specific knowledge retrieval. This observation underscores the importance of homogeneous corpora for training professional-level language-specific models. On the contrary, we also observe a perplexing performance dip in these smaller LMs when th
    
[^38]: AI海洋中的妖怪之歌：大型语言模型中的幻觉调查

    Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models. (arXiv:2309.01219v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01219](http://arxiv.org/abs/2309.01219)

    本文调查了大型语言模型中幻觉的检测、解释和缓解的最新研究，提出了幻觉现象和评估基准的分类，并讨论了未来研究的潜在方向。

    

    尽管大型语言模型（LLMs）在各种下游任务中展示出了卓越的能力，但人们对其产生幻觉的倾向表示担忧：LLMs有时会生成与用户输入不符、与先前生成的内容相矛盾或与已建立的世界知识不符的内容。这种现象对LLMs在现实场景中的可靠性构成了重大挑战。本文对关于幻觉检测、解释和缓解的最新研究进行了调查，重点探讨了LLMs所面临的独特挑战。我们提出了LLM幻觉现象和评估基准的分类，分析了现有的旨在缓解LLM幻觉的方法，并讨论了未来研究的潜在方向。

    While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating LLM hallucination, and discuss potential directions for future research.
    
[^39]: CPSP: 从音素监督中学习语音概念

    CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])

    [http://arxiv.org/abs/2309.00424](http://arxiv.org/abs/2309.00424)

    论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。

    

    对于诸如最小监督的文本转语音（TTS）、语音转换（VC）和自动语音识别（ASR）等细粒度生成和识别任务，从语音中提取的中间表示应包含介于文本编码和声学编码之间的信息。语言内容突出，而发言人身份和声学细节等语音信息应该被去除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余性过高和维度爆炸的问题。此外，音频领域中现有的对比学习方法主要关注提取用于下游音频分类任务的全局描述信息，不适合TTS、VC和ASR任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练（CPSP）的方法，该方法使用三个编码器、一个解码器和对比学习来将音素和语音信息相结合。

    For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representation extracted from speech should contain information that is between text coding and acoustic coding. The linguistic content is salient, while the paralinguistic information such as speaker identity and acoustic details should be removed. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Additionally, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named Contrastive Phoneme-Speech Pretraining (CPSP), which uses three encoders, one decoder, and contrastive learning to bring phoneme and speech
    
[^40]: 使用大型语言模型进行文本风格转换评估

    Text Style Transfer Evaluation Using Large Language Models. (arXiv:2308.13577v1 [cs.CL])

    [http://arxiv.org/abs/2308.13577](http://arxiv.org/abs/2308.13577)

    大型语言模型（LLMs）有潜力成为人工评估和其他自动化评价指标的可行替代方案。

    

    文本风格转换（TST）的评估具有挑战性，因为生成文本的质量表现在多个方面，每个方面都很难单独衡量：风格转换准确性、内容保留和整体流畅性。人工评估是TST评估的黄金标准，然而，它费时费力，并且结果难以重复。许多自动化指标被用于评估这些方面的性能，作为人工评估的替代品。然而，许多自动化指标与人工评估之间的相关性仍然不清楚，对它们作为可靠基准的效果产生了怀疑。最近大型语言模型（LLMs）的进展已经证明了它们不仅能够匹配，而且在各种未见任务中还能超过平均人类表现。这表明LLMs有潜力成为人工评估和其他自动化指标的可行替代方案。我们评估了...

    Text Style Transfer (TST) is challenging to evaluate because the quality of the generated text manifests itself in multiple aspects, each of which is hard to measure individually: style transfer accuracy, content preservation, and overall fluency of the text. Human evaluation is the gold standard in TST evaluation; however, it is expensive, and the results are difficult to reproduce. Numerous automated metrics are employed to assess performance in these aspects, serving as substitutes for human evaluation. However, the correlation between many of these automated metrics and human evaluations remains unclear, raising doubts about their effectiveness as reliable benchmarks. Recent advancements in Large Language Models (LLMs) have demonstrated their ability to not only match but also surpass the average human performance across a wide range of unseen tasks. This suggests that LLMs have the potential to serve as a viable alternative to human evaluation and other automated metrics. We asses
    
[^41]: 评估社交位置对话机器人的客观评价：通过多模态用户行为评估人类相似度

    Towards Objective Evaluation of Socially-Situated Conversational Robots: Assessing Human-Likeness through Multimodal User Behaviors. (arXiv:2308.11020v1 [cs.CL])

    [http://arxiv.org/abs/2308.11020](http://arxiv.org/abs/2308.11020)

    本文提出了一种客观评价社交位置对话机器人的方法，利用多模态用户行为来评估机器人的人类相似度，增强了客观性和可复现性。

    

    本文解决了评估社交位置对话机器人的挑战性任务，并提出了一种新颖的客观评价方法，该方法依赖于多模态用户行为。在本研究中，我们的主要关注点是评估机器人的人类相似度作为主要评价指标。而以往的研究常常依赖于用户的主观评价，我们的方法旨在通过间接观察用户行为来评估机器人的人类相似度，从而增强客观性和可复现性。首先，我们创建了一个使用关注性对话语料库中的用户行为来标注人类相似度分数的数据集。然后我们进行了分析，确定了多模态用户行为与人类相似度分数之间的相关性，证明了我们提出的基于行为的评估方法的可行性。

    This paper tackles the challenging task of evaluating socially situated conversational robots and presents a novel objective evaluation approach that relies on multimodal user behaviors. In this study, our main focus is on assessing the human-likeness of the robot as the primary evaluation metric. While previous research often relied on subjective evaluations from users, our approach aims to evaluate the robot's human-likeness based on observable user behaviors indirectly, thus enhancing objectivity and reproducibility. To begin, we created an annotated dataset of human-likeness scores, utilizing user behaviors found in an attentive listening dialogue corpus. We then conducted an analysis to determine the correlation between multimodal user behaviors and human-likeness scores, demonstrating the feasibility of our proposed behavior-based evaluation method.
    
[^42]: ChatGPT生物医学生成文本中建立信任的方法：基于本体的知识图谱用于验证疾病-症状关系

    Establishing Trust in ChatGPT BioMedical Generated Text: An Ontology-Based Knowledge Graph to Validate Disease-Symptom Links. (arXiv:2308.03929v1 [cs.AI])

    [http://arxiv.org/abs/2308.03929](http://arxiv.org/abs/2308.03929)

    本研究通过构建基于本体的知识图谱，利用疾病本体和症状本体构建数学模型，利用事实核查算法和网络中心度指标分析ChatGPT生成的文本与真实医学文献之间的准确性，以验证疾病-症状关系。

    

    方法：通过创新的方法，我们从真实的医学文献和人工智能生成的内容构建了基于本体的知识图谱。我们的目标是区分事实信息和未经验证的数据。我们收集了两个数据集：一个是使用“人类疾病和症状”查询从生物医学文献中编译的，另一个是由ChatGPT生成的模拟文章。利用这些数据集（PubMed和ChatGPT），我们随机选择了10组每组250个摘要，并使用特定的种子。我们的方法主要是利用疾病本体（DOID）和症状本体（SYMP）构建知识图谱，这是一种强大的数学模型，可以进行无偏差的比较。通过使用我们的事实核查算法和网络中心度指标，我们进行了GPT疾病-症状链接分析，以量化在噪声、假设和重要发现中的事实知识的准确性。结果：通过比较不同ChatGPT知识图谱及其PubMed计数获得的结果，我们发现...

    Methods: Through an innovative approach, we construct ontology-based knowledge graphs from authentic medical literature and AI-generated content. Our goal is to distinguish factual information from unverified data. We compiled two datasets: one from biomedical literature using a "human disease and symptoms" query, and another generated by ChatGPT, simulating articles. With these datasets (PubMed and ChatGPT), we curated 10 sets of 250 abstracts each, selected randomly with a specific seed. Our method focuses on utilizing disease ontology (DOID) and symptom ontology (SYMP) to build knowledge graphs, robust mathematical models that facilitate unbiased comparisons. By employing our fact-checking algorithms and network centrality metrics, we conducted GPT disease-symptoms link analysis to quantify the accuracy of factual knowledge amid noise, hypotheses, and significant findings.  Results: The findings obtained from the comparison of diverse ChatGPT knowledge graphs with their PubMed count
    
[^43]: MASR: 多标签感知语音表示

    MASR: Multi-label Aware Speech Representation. (arXiv:2307.10982v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2307.10982](http://arxiv.org/abs/2307.10982)

    MASR是一种多标签感知语音表示学习框架，可以利用多个外部知识源增强元数据信息的利用，并在多个下游任务上展示了显著的性能提升。

    

    近年来，语音表示学习主要以自监督学习任务为基础，仅使用原始音频信号，忽略了通常可用于给定语音记录的附加信息。在本文中，我们提出了MASR，一种多标签感知语音表示学习框架，以解决上述限制。MASR能够引入多个外部知识源，增强元数据信息的利用。外部知识源以样本级成对相似性矩阵的形式被纳入到一个硬挖掘损失函数中。MASR框架的一个关键优势是它可以与任何选择的自监督学习方法相结合。利用MASR表示，我们在多个下游任务上进行评估，如语言识别、语音识别以及说话人和情感识别等非语义任务。在这些实验中，我们展示了显著的性能提升。

    In the recent years, speech representation learning is constructed primarily as a self-supervised learning (SSL) task, using the raw audio signal alone, while ignoring the side-information that is often available for a given speech recording. In this paper, we propose MASR, a Multi-label Aware Speech Representation learning framework, which addresses the aforementioned limitations. MASR enables the inclusion of multiple external knowledge sources to enhance the utilization of meta-data information. The external knowledge sources are incorporated in the form of sample-level pair-wise similarity matrices that are useful in a hard-mining loss. A key advantage of the MASR framework is that it can be combined with any choice of SSL method. Using MASR representations, we perform evaluations on several downstream tasks such as language identification, speech recognition and other non-semantic tasks such as speaker and emotion recognition. In these experiments, we illustrate significant perfor
    
[^44]: 探讨自然语言处理研究领域的发展趋势

    Exploring the Landscape of Natural Language Processing Research. (arXiv:2307.10652v1 [cs.CL])

    [http://arxiv.org/abs/2307.10652](http://arxiv.org/abs/2307.10652)

    该论文系统分类和分析了ACL Anthology中的研究论文，提供了对研究领域的结构化概述和NLP领域的分类学。本研究总结了最新的NLP发展，并提出了未来工作的方向。

    

    自然语言处理(NLP)作为理解、生成和处理自然语言文本的一种高效方法，在近年来得到了快速传播和广泛应用。鉴于该领域研究工作的不断增加，研究界已对数个与NLP相关的方法进行了调查。然而，到目前为止，仍缺少一项全面的研究，对已建立的主题进行分类、识别趋势并概括未来研究方向。为填补这一空白，我们对ACL Anthology中包含的研究论文进行了系统分类和分析。结果呈现了研究领域的结构化概述，为NLP领域的研究提供了一个分类学，分析了NLP的最新发展，总结了我们的研究发现，并突出了未来工作的方向。

    As an efficient approach to understand, generate, and process natural language texts, research in natural language processing (NLP) has exhibited a rapid spread and wide adoption in recent years. Given the increasing amount of research work in this area, several NLP-related approaches have been surveyed in the research community. However, a comprehensive study that categorizes established topics, identifies trends, and outlines areas for future research remains absent to this day. Contributing to closing this gap, we have systematically classified and analyzed research papers included in the ACL Anthology. As a result, we present a structured overview of the research landscape, provide a taxonomy of fields-of-study in NLP, analyze recent developments in NLP, summarize our findings, and highlight directions for future work.
    
[^45]: AspectCSE: 使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入

    AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])

    [http://arxiv.org/abs/2307.07851](http://arxiv.org/abs/2307.07851)

    AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。

    

    通用的句子嵌入提供了对语义文本相似性的粗略近似，但忽略了使文本相似的特定方面。相反，基于方面的句子嵌入提供了基于预定义方面的文本相似性。因此，文本的相似性预测更加针对特定要求，并且更容易解释。在本文中，我们提出了AspectCSE，一种用于基于方面的对比学习句子嵌入的方法。结果表明，与之前最好的结果相比，AspectCSE在多个方面的信息检索任务中实现了平均改善3.97%。我们还提出使用Wikidata知识图属性来训练多方面句子嵌入模型，其中在相似性预测过程中同时考虑多个特定方面。我们证明了多方面嵌入在特定方面信息检索任务上优于单方面嵌入。最后，我们展示了嵌入模型的可解释性，并提出通过对比学习来改进嵌入质量。

    Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
    
[^46]: 使用GPT进行命名实体识别以识别可比公司

    Named entity recognition using GPT for identifying comparable companies. (arXiv:2307.07420v1 [cs.CL])

    [http://arxiv.org/abs/2307.07420](http://arxiv.org/abs/2307.07420)

    本文使用GPT以识别可比公司。传统的可比公司方法通常使用定性方法来识别相似的同行公司，而我们使用大型语言模型通过提取公司描述/摘要从而进行相似性分析，实现更量化的方法。

    

    对于公共和私人公司，可比公司分析被广泛用作公司估值的方法。特别是对于私募股权公司的估值，该方法非常有价值。可比公司方法的几种方法通常依赖于定性方法来识别相似的同行公司，这往往使用已建立的行业分类方案和/或分析师的直觉和知识。然而，文献和私募股权行业开始使用更多的量化方法，特别是机器学习聚类和自然语言处理（NLP）。对于NLP方法，该过程包括从公司的网站或来自某些金融数据库系统的公司描述中提取产品实体，然后进行相似性分析。在这里，我们使用公开可用的公司维基百科网站的公司描述/摘要，展示了使用大型语言模型（LLM），例如GPT

    For both public and private firms, comparable companies analysis is widely used as a method for company valuation. In particular, the method is of great value for valuation of private equity companies. The several approaches to the comparable companies method usually rely on a qualitative approach to identifying similar peer companies, which tends to use established industry classification schemes and/or analyst intuition and knowledge. However, more quantitative methods have started being used in the literature and in the private equity industry, in particular, machine learning clustering, and natural language processing (NLP). For NLP methods, the process consists of extracting product entities from e.g., the company's website or company descriptions from some financial database system and then to perform similarity analysis. Here, using companies descriptions/summaries from publicly available companies' Wikipedia websites, we show that using large language models (LLMs), such as GPT
    
[^47]: 使用适配器高效域自适应句子嵌入

    Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v1 [cs.CL])

    [http://arxiv.org/abs/2307.03104](http://arxiv.org/abs/2307.03104)

    本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。

    

    句子嵌入使我们能够捕捉短文本的语义相似性。大多数句子嵌入模型是针对一般语义文本相似性（STS）任务进行训练的。因此，要在特定领域中使用句子嵌入，必须将模型适应于该领域以获得良好的结果。通常，这是通过对感兴趣的域对整个句子嵌入模型进行微调来实现的。虽然这种方法能够产生最先进的结果，但在微调过程中更新了所有模型的权重，使该方法在资源上要求较高。因此，我们提出了训练轻量级适配器的方法，而不是单独为每个目标领域微调整个句子嵌入模型。这些特定领域的适配器不需要微调所有底层句子嵌入模型的参数。相反，我们只训练少量的额外参数，同时保持底层句子嵌入模型的权重不变。训练特定领域的适配器可以始终使用同一模型并在不同领域中获得良好的性能。

    Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always 
    
[^48]: CARE-MI: 中国孕婴护理领域的虚假信息评估基准

    CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity and Infant Care. (arXiv:2307.01458v1 [cs.CL])

    [http://arxiv.org/abs/2307.01458](http://arxiv.org/abs/2307.01458)

    CARE-MI是一个用于评估中国孕婴护理领域LLM虚假信息的基准，填补了这一领域的研究空白，并提供了构建长篇生成评估基准的创新范式。

    

    最近自然语言处理的进展导致了将LLM应用于现实场景的新趋势。尽管最新的LLM在与人类互动时令人惊叹地流利，但它们在生成错误事实陈述时会意外产生虚假信息问题。这可能导致有害后果，尤其是在敏感环境下，比如医疗保健领域。然而，之前很少有研究关注评估LLM长篇生成中的虚假信息，尤其是针对知识密集型主题。此外，尽管LLM在不同语言上表现良好，但虚假信息评估主要在英语中进行。为此，我们提供了一个基准，CARE-MI，用于评估LLM虚假信息在：1）一个敏感主题，具体是孕婴护理领域；和2）一种非英语语言，即中文。最重要的是，我们提供了一个创新的范式，用于构建长篇生成评估基准，可以

    The recent advances in NLP, have led to a new trend of applying LLMs to real-world scenarios. While the latest LLMs are astonishingly fluent when interacting with humans, they suffer from the misinformation problem by unintentionally generating factually false statements. This can lead to harmful consequences, especially when produced within sensitive contexts, such as healthcare. Yet few previous works have focused on evaluating misinformation in the long-form generation of LLMs, especially for knowledge-intensive topics. Moreover, although LLMs have been shown to perform well in different languages, misinformation evaluation has been mostly conducted in English. To this end, we present a benchmark, CARE-MI, for evaluating LLM misinformation in: 1) a sensitive topic, specifically the maternity and infant care domain; and 2) a language other than English, namely Chinese. Most importantly, we provide an innovative paradigm for building long-form generation evaluation benchmarks that can
    
[^49]: 3D-Speaker：用于语音表示解缠的大规模多设备、多距离和多方言语料库

    3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement. (arXiv:2306.15354v1 [cs.CL])

    [http://arxiv.org/abs/2306.15354](http://arxiv.org/abs/2306.15354)

    3D-Speaker是一个大规模的多设备、多距离和多方言语音语料库，用于研究语音表示解缠。它包含了10,000多个说话人的数据，可以用来评估大型通用语音模型和探索域外学习和自监督学习方法。

    

    在语音社区中，分离语音话语中的不相关信息是一个关键的研究课题。不同的语音相关任务专注于提取不同的语音表示，同时最小化其他不相关信息的影响。我们提出了一个大规模的语音语料库，以促进语音表示解缠的研究。3D-Speaker包含超过10,000个说话人，每个说话人同时由多个设备录制，在不同的距离上，并且一些说话人会讲多种方言。多维音频数据的受控组合产生了一个多样的混合语音表示纠缠矩阵，从而激发出解开它们的有趣方法。3D-Speaker的多领域性质还使其成为评估大型通用语音模型和实验域外学习和自监督学习方法的合适资源。

    Disentangling uncorrelated information in speech utterances is a crucial research topic within speech community. Different speech-related tasks focus on extracting distinct speech representations while minimizing the affects of other uncorrelated information. We present a large-scale speech corpus to facilitate the research of speech representation disentanglement. 3D-Speaker contains over 10,000 speakers, each of whom are simultaneously recorded by multiple Devices, locating at different Distances, and some speakers are speaking multiple Dialects. The controlled combinations of multi-dimensional audio data yield a matrix of a diverse blend of speech representation entanglement, thereby motivating intriguing methods to untangle them. The multi-domain nature of 3D-Speaker also makes it a suitable resource to evaluate large universal speech models and experiment methods of out-of-domain learning and self-supervised learning. https://3dspeaker.github.io/
    
[^50]: 利用辅助领域平行数据在中间任务微调中实现低资源翻译

    Leveraging Auxiliary Domain Parallel Data in Intermediate Task Fine-tuning for Low-resource Translation. (arXiv:2306.01382v1 [cs.CL])

    [http://arxiv.org/abs/2306.01382](http://arxiv.org/abs/2306.01382)

    本文展示了中间任务微调(ITFT)对于低资源、多语言、多领域的NMT非常有效，能够在一定程度上缓解领域分歧的影响。

    

    当没有足够的平行数据进行微调时，基于预先训练的多语种Seq-to-Seq模型的NMT系统应用困难，特别是对于这些模型中缺失/代表性不足的语言。当数据来自不同领域时，问题进一步恶化。本文展示了中间任务微调(ITFT)对于特定领域的NMT非常有益，尤其是当目标领域的数据有限/不可用，而考虑的语言在PMSS模型中缺失或代表性不足时。我们使用领域分歧测试量化了领域特定结果的变化，并且展示了ITFT能够在一定程度上缓解领域分歧的影响。

    NMT systems trained on Pre-trained Multilingual Sequence-Sequence (PMSS) models flounder when sufficient amounts of parallel data is not available for fine-tuning. This specifically holds for languages missing/under-represented in these models. The problem gets aggravated when the data comes from different domains. In this paper, we show that intermediate-task fine-tuning (ITFT) of PMSS models is extremely beneficial for domain-specific NMT, especially when target domain data is limited/unavailable and the considered languages are missing or under-represented in the PMSS model. We quantify the domain-specific results variations using a domain-divergence test, and show that ITFT can mitigate the impact of domain divergence to some extent.
    
[^51]: GenQ：自动化问答生成器以帮助照顾者与孩子共读故事

    GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children. (arXiv:2305.16809v1 [cs.CL])

    [http://arxiv.org/abs/2305.16809](http://arxiv.org/abs/2305.16809)

    本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。

    

    当照顾者询问开放式问题以激发与孩子的对话时，可以促进孩子的阅读理解能力。虽然有利用技术工具来支持这个过程，即所谓的“智能辅导系统”的空间，但目前仍不清楚现有的生成类人语言问题的智能系统是否有益。此外，用于开发这些自动生成问题系统的培训数据通常没有考虑到人口统计学，但具有不同文化背景的人可能会提出不同的问题。作为为拉丁裔儿童设计智能阅读支持应用程序的广泛项目的一部分，我们从来自不同人口统计学的拉丁裔护理人员和非护理人员以及其他人口统计学背景的护理人员和非护理人员中群集大量问题。我们研究了这个数据集中个体、文化和环境因素中介的问题提问的变化。然后我们设计了一个系统来自动产生问题。

    When caregivers ask open--ended questions to motivate dialogue with children, it facilitates the child's reading comprehension skills.Although there is scope for use of technological tools, referred here as "intelligent tutoring systems", to scaffold this process, it is currently unclear whether existing intelligent systems that generate human--language like questions is beneficial. Additionally, training data used in the development of these automated question generation systems is typically sourced without attention to demographics, but people with different cultural backgrounds may ask different questions. As a part of a broader project to design an intelligent reading support app for Latinx children, we crowdsourced questions from Latinx caregivers and noncaregivers as well as caregivers and noncaregivers from other demographics. We examine variations in question--asking within this dataset mediated by individual, cultural, and contextual factors. We then design a system that autom
    
[^52]: ArguGPT：评估、理解和识别由GPT模型生成的论证文章

    ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models. (arXiv:2304.07666v1 [cs.CL])

    [http://arxiv.org/abs/2304.07666](http://arxiv.org/abs/2304.07666)

    该研究提出了ArguGPT，它是由7个GPT模型生成的论证文章语料库，旨在解决AI生成内容带来的挑战，研究结果表明教师首次接触机器生成的论文时只有61%的准确度，但经过一轮训练后提高到了67%。

    

    人工智能生成的内容（AIGC）对全球教育工作者提出了巨大的挑战。教师们需要能够用肉眼或工具检测出由大型语言模型生成的文本。需要更多地了解AIGC的词汇、句法和风格特征。为了解决这些英语教学方面的挑战，我们首先提出了ArguGPT，这是一个由7个GPT模型生成的4038篇有平衡的论证文章语料库，这些论证文章是在以下三个来源的论文提示下生成的：（1）课堂或家庭作业练习，（2）托福和（3）GRE写作任务。机器生成的文本与大致相等数量的人工编写的文章配对，这些文章的三个得分级别匹配论文提示。然后，我们雇用英语教师来区分机器论文和人工论文。结果表明，当教师们首次接触机器生成的论文时，他们仅能以61%的准确度检测出它们。但经过一轮训练后，这个数字提高到了67%。

    AI generated content (AIGC) presents considerable challenge to educators around the world. Instructors need to be able to detect such text generated by large language models, either with the naked eye or with the help of some tools. There is also growing need to understand the lexical, syntactic and stylistic features of AIGC. To address these challenges in English language teaching, we first present ArguGPT, a balanced corpus of 4,038 argumentative essays generated by 7 GPT models in response to essay prompts from three sources: (1) in-class or homework exercises, (2) TOEFL and (3) GRE writing tasks. Machine-generated texts are paired with roughly equal number of human-written essays with three score levels matched in essay prompts. We then hire English instructors to distinguish machine essays from human ones. Results show that when first exposed to machine-generated essays, the instructors only have an accuracy of 61% in detecting them. But the number rises to 67% after one round of
    
[^53]: 个性化文本到图像生成的可控文本反转

    Controllable Textual Inversion for Personalized Text-to-Image Generation. (arXiv:2304.05265v1 [cs.CV])

    [http://arxiv.org/abs/2304.05265](http://arxiv.org/abs/2304.05265)

    本文提出了一种名为COTI的技术，通过引入理论指导的损失目标和全面的加权评分机制，并结合主动学习范式来解决文本反转时的困难，提供了一个强大，数据效率高，易于使用的框架。

    

    最近，大规模生成模型在以文本为引导的高保真图像的生成方面取得了前所未有的性能。当引导信息包含用户定义的、未见过的或长尾概念标记时，文本反转成为一种有效的个性化生成技术。尽管如此，我们发现并展示了文本反转的部署仍充满了“黑魔法”，例如额外数据集的严苛要求，在循环中需要艰苦的人力成本和缺乏鲁棒性等。在这项工作中，我们提出了一种名为可控文本反转的大大增强版反转，解决了所有上述问题，并反过来提供了一个强大，数据效率高，易于使用的框架。COTI的核心是基于理论的损失目标，具有全面和新颖的加权评分机制，并由主动学习范式所提取。广泛的结果表明，COTI的性能比之前技术有了显著的提升，尤其是在数据少的情况下。

    The recent large-scale generative modeling has attained unprecedented performance especially in producing high-fidelity images driven by text prompts. Text inversion (TI), alongside the text-to-image model backbones, is proposed as an effective technique in personalizing the generation when the prompts contain user-defined, unseen or long-tail concept tokens. Despite that, we find and show that the deployment of TI remains full of "dark-magics" -- to name a few, the harsh requirement of additional datasets, arduous human efforts in the loop and lack of robustness. In this work, we propose a much-enhanced version of TI, dubbed Controllable Textual Inversion (COTI), in resolving all the aforementioned problems and in turn delivering a robust, data-efficient and easy-to-use framework. The core to COTI is a theoretically-guided loss objective instantiated with a comprehensive and novel weighted scoring mechanism, encapsulated by an active-learning paradigm. The extensive results show that 
    
[^54]: 利用语言指导的三模态一致性进行音频-视频源分离

    Language-Guided Audio-Visual Source Separation via Trimodal Consistency. (arXiv:2303.16342v1 [cs.CV])

    [http://arxiv.org/abs/2303.16342](http://arxiv.org/abs/2303.16342)

    该论文提出了一种自监督学习的方法，通过使用自然语言查询来进行音频源分离，实现了语言、视觉和音频的一致性对齐，并在多个数据集上表现出比现有方法更好的效果。

    

    我们提出了一种自监督学习的方法，基于自然语言查询在视频中学习执行音频源分离，仅使用未标记的视频和音频对作为训练数据。这项任务的一个关键挑战是学习将发声物体的语言描述与其视觉特征和相应的音频波形组件联系起来，而在训练期间没有访问注释。为了克服这个挑战，我们改进了现成的视觉语言基础模型，通过两种新的损失函数提供伪目标监督，并促进音频、视觉和自然语言模态之间更强的对齐。在推理过程中，我们的方法可以在给定文本、视频和音频输入或仅给定文本和音频输入时分离声音。我们在三个音频-视频分离数据集（包括MUSIC、SOLOS和AudioSet）上展示了我们自监督方法的有效性，其中我们的模型胜过了现有强监督方法的最新成果。

    We propose a self-supervised approach for learning to perform audio source separation in videos based on natural language queries, using only unlabeled video and audio pairs as training data. A key challenge in this task is learning to associate the linguistic description of a sound-emitting object to its visual features and the corresponding components of the audio waveform, all without access to annotations during training. To overcome this challenge, we adapt off-the-shelf vision-language foundation models to provide pseudo-target supervision via two novel loss functions and encourage a stronger alignment between the audio, visual and natural language modalities. During inference, our approach can separate sounds given text, video and audio input, or given text and audio input alone. We demonstrate the effectiveness of our self-supervised approach on three audio-visual separation datasets, including MUSIC, SOLOS and AudioSet, where we outperform state-of-the-art strongly supervised 
    
[^55]: 自一致学习：生成器和鉴别器的合作

    Self-Consistent Learning: Cooperation between Generators and Discriminators. (arXiv:2303.09075v1 [cs.CL])

    [http://arxiv.org/abs/2303.09075](http://arxiv.org/abs/2303.09075)

    本文提出了一个自一致学习的框架，通过鉴别器和生成器的合作训练，解决了标准GAN训练不稳定、样本容易偏离实际数据分布、鉴别模型改进饱和等问题。实验结果表明，该模型不仅优于最先进的GAN，在文本和图像生成任务中也实现了高质量的合成。

    

    最近，使用生成的数据来提高下游鉴别模型的性能已经因预训练语言模型的巨大发展而广受欢迎。在大多数先前的研究中，生成模型和鉴别模型是分别训练的，因此它们不能适应彼此的任何变化。因此，生成的样本很容易偏离实际数据分布，而鉴别模型的改进很快就会达到饱和。生成对抗网络（GAN）通过一种对抗性过程与鉴别模型训练生成模型以实现联合训练。然而，标准GAN的训练极不稳定，往往难以收敛。在本文中，为了解决这些问题，我们提出了一个自一致学习框架，其中一个鉴别器和一个生成器以闭环形式合作训练。鉴别器和生成器在多轮更新中相互增强，生成的样本逐渐接近实际数据分布，而鉴别模型不断提高其性能。实验结果表明，我们的模型不仅在各种数据集上优于最先进的GAN，而且在文本和图像生成任务中实现了高质量的合成。

    Using generated data to improve the performance of downstream discriminative models has recently gained popularity due to the great development of pre-trained language models. In most previous studies, generative models and discriminative models are trained separately and thus could not adapt to any changes in each other. As a result, the generated samples can easily deviate from the real data distribution, while the improvement of the discriminative model quickly reaches saturation. Generative adversarial networks (GANs) train generative models via an adversarial process with discriminative models to achieve joint training. However, the training of standard GANs is notoriously unstable and often falls short of convergence. In this paper, to address these issues, we propose a $\textit{self-consistent learning}$ framework, in which a discriminator and a generator are cooperatively trained in a closed-loop form. The discriminator and the generator enhance each other during multiple round
    
[^56]: Google USM: 将自动语音识别扩展到100多种语言

    Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages. (arXiv:2303.01037v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.01037](http://arxiv.org/abs/2303.01037)

    Google USM是一个通用语音模型，通过多语言预训练和微调，实现了在100多种语言上的自动语音识别和语音-文本翻译任务的先进性能。

    

    我们介绍了通用语音模型（USM），这是一个在100多种语言上进行自动语音识别（ASR）的单个大模型。通过在多样化的无标签语料库上对模型的编码器进行预训练，该语料库跨越300多种语言，总时长达到1200万小时，并在较小的已标记数据集上进行微调，我们使用了多语言预训练、随机投影量化和语音-文本模态匹配，实现了下游多语言ASR和语音-文本翻译任务的最先进性能。我们还证明，尽管使用的训练集大小仅为Whisper模型使用的1/7，我们的模型在许多语言的领域内和领域外语音识别任务中表现出可比或更好的性能。

    We introduce the Universal Speech Model (USM), a single large model that performs automatic speech recognition (ASR) across 100+ languages. This is achieved by pre-training the encoder of the model on a large unlabeled multilingual dataset of 12 million (M) hours spanning over 300 languages, and fine-tuning on a smaller labeled dataset. We use multilingual pre-training with random-projection quantization and speech-text modality matching to achieve state-of-the-art performance on downstream multilingual ASR and speech-to-text translation tasks. We also demonstrate that despite using a labeled training set 1/7-th the size of that used for the Whisper model, our model exhibits comparable or better performance on both in-domain and out-of-domain speech recognition tasks across many languages.
    
[^57]: HL数据集: 基于视觉的场景、动作和理由的描述

    HL Dataset: Visually-grounded Description of Scenes, Actions and Rationales. (arXiv:2302.12189v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12189](http://arxiv.org/abs/2302.12189)

    这个论文介绍了HL数据集，该数据集扩展了COCO数据集，包含14997个图像和134,973个人工注释的高级别描述，涉及场景、动作和理由，可以用于对视觉和语言模型进行更高级别的测试和微调。

    

    当前的描述数据集侧重于以物体为中心的描述，描述图像中可见的物体，例如“人们在公园里吃东西”。虽然这些数据集对于评估视觉和语言模型识别和描述视觉内容的能力很有用，但它们不支持涉及模型测试或微调的受控实验，使用更高级的描述，人们发现很容易和自然地产生。例如，人们通常根据图像所描绘的场景类型（“人们在度假胜地”）和他们进行的动作（“人们正在野餐”）来描述图像。这些描述基于个人经验和常识性的假设。我们提供了高级别数据集，该数据集扩展了来自COCO数据集的14997个图像，并与一组新的134,973个人工注释（高级别）描述对齐，这些描述从场景、动作和理由三个方面进行了收集。我们进一步使用从独立阅读者组收集的信心得分扩展了该数据集。

    Current captioning datasets focus on object-centric captions, describing the visible objects in the image, e.g. "people eating food in a park". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict ('people at a holiday resort') and the actions they perform ('people having a picnic'). Such descriptions draw on personal experience and commonsense assumptions. We present the High-Level Dataset a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions, and rationales. We further extend this dataset with confidence scores collected from an independent set of readers,
    
[^58]: 利用大型语言模型提升用于收集用户自我报告数据的聊天机器人的能力

    Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data. (arXiv:2301.05843v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2301.05843](http://arxiv.org/abs/2301.05843)

    本研究通过探索设计提示的因素，研究了如何利用大型语言模型构建聊天机器人来进行自然对话和可靠地收集用户自我报告数据。结果显示，提示的设计和对话主题明显影响了对话流程和数据收集性能。

    

    大型语言模型（LLMs）提供了一种通过接受自然语言提示来构建聊天机器人的新方法。然而，如何设计提示来使聊天机器人在追求给定目标（如从用户收集自我报告数据）的同时进行自然对话尚不清楚。我们探讨了哪些提示的设计因素可以帮助引导聊天机器人进行自然对话并可靠地收集数据。为此，我们设计了四种具有不同结构和人设的提示形式。通过一项在线研究（N = 48），参与者与由不同设计提示驱动的聊天机器人进行对话，我们评估了设计提示和对话主题如何影响对话流程和用户对聊天机器人的感知。在对话过程中，我们的聊天机器人覆盖了79%的所需信息槽，并且提示和主题的设计显著影响了对话流程和数据收集性能。我们讨论了利用LLMs构建聊天机器人的机遇和挑战。

    Large language models (LLMs) provide a new way to build chatbots by accepting natural language prompts. Yet, it is unclear how to design prompts to power chatbots to carry on naturalistic conversations while pursuing a given goal, such as collecting self-report data from users. We explore what design factors of prompts can help steer chatbots to talk naturally and collect data reliably. To this aim, we formulated four prompt designs with different structures and personas. Through an online study (N = 48) where participants conversed with chatbots driven by different designs of prompts, we assessed how prompt designs and conversation topics affected the conversation flows and users' perceptions of chatbots. Our chatbots covered 79% of the desired information slots during conversations, and the designs of prompts and topics significantly influenced the conversation flows and the data collection performance. We discuss the opportunities and challenges of building chatbots with LLMs.
    
[^59]: 自动文本摘要技术的综合回顾：方法、数据、评估和编码

    A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding. (arXiv:2301.03403v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.03403](http://arxiv.org/abs/2301.03403)

    本文提供了关于自动文本摘要系统的综述，包括方法、数据、评估和编码。作者通过引用的方式回顾了相关文献，并介绍了不同的摘要生成方法。此外，还对可用于评估和数据训练的数据集进行了综述，并使用CNN语料库数据集对方法进行了实证探索。

    

    我们提供了关于自动文本摘要系统的文献综述。我们采用基于引用的方法。我们从我们已经掌握的关于每个我们想涵盖的主题的一些流行和著名的论文开始，然后我们追踪了“向后引用”（被我们之前知道的一系列论文引用的论文）和“向前引用”（引用我们之前知道的一系列论文的较新论文）。为了组织不同的方法，我们介绍了各种基于不同机制生成摘要的自动文本摘要方法。除了介绍方法外，我们还对可用于摘要任务的数据集和用于评估摘要质量的方法进行了广泛的回顾。最后，我们还使用CNN语料库数据集对这些方法进行了实证探索，该数据集为抽取式和生成式方法提供了金标准摘要。

    We provide a literature review about Automatic Text Summarization (ATS) systems. We consider a citation-based approach. We start with some popular and well-known papers that we have in hand about each topic we want to cover and we have tracked the "backward citations" (papers that are cited by the set of papers we knew beforehand) and the "forward citations" (newer papers that cite the set of papers we knew beforehand). In order to organize the different methods, we present the diverse approaches to ATS guided by the mechanisms they use to generate a summary. Besides presenting the methods, we also present an extensive review of the datasets available for summarization tasks and the methods used to evaluate the quality of the summaries. Finally, we present an empirical exploration of these methods using the CNN Corpus dataset that provides golden summaries for extractive and abstractive methods.
    
[^60]: 在自然语言论证中鲁棒且可解释的识别逻辑谬误

    Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments. (arXiv:2212.07425v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07425](http://arxiv.org/abs/2212.07425)

    本论文提出了一个鲁棒且可解释的方法来识别自然语言论证中的逻辑谬误。通过三阶段的评估框架和不同的推理方法，结合语言模型和背景知识，有效处理了大量数据和数据稀疏性的问题。

    

    在互联网时代，虚假信息、宣传和错误论证的传播现象得到了放大。给定数据量的庞大和识别论证规范违规的微妙性，使用可靠的方法来识别逻辑谬误来支持信息分析任务（如内容审核）是至关重要的。本文将以前关于逻辑谬误的理论工作制定为检测、粗粒度和细粒度分类的综合三阶段评估框架。我们针对评估的每个阶段对现有的评估数据集进行了适应。我们采用了基于原型推理、基于实例推理和知识注入的三个鲁棒且可解释的方法族。这些方法结合了语言模型、背景知识和可解释的机制。此外，我们通过数据增强和课程学习的策略解决了数据稀疏性的问题。我们的三阶段框架自然地巩固了以前的数据集和方法。

    The spread of misinformation, propaganda, and flawed argumentation has been amplified in the Internet era. Given the volume of data and the subtlety of identifying violations of argumentation norms, supporting information analytics tasks, like content moderation, with trustworthy methods that can identify logical fallacies is essential. In this paper, we formalize prior theoretical work on logical fallacies into a comprehensive three-stage evaluation framework of detection, coarse-grained, and fine-grained classification. We adapt existing evaluation datasets for each stage of the evaluation. We employ three families of robust and explainable methods based on prototype reasoning, instance-based reasoning, and knowledge injection. The methods combine language models with background knowledge and explainable mechanisms. Moreover, we address data sparsity with strategies for data augmentation and curriculum learning. Our three-stage framework natively consolidates prior datasets and metho
    
[^61]: Nano: 嵌套的人机交互奖励学习用于少样本语言模型控制

    Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control. (arXiv:2211.05750v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.05750](http://arxiv.org/abs/2211.05750)

    本研究提出了一个少样本人机交互训练算法Nano，用于按任意分布（定量和未定量）生成文本。与先前的工作相比，Nano在单一主题/属性以及定量分布控制方面表现出最先进的结果。

    

    预训练语言模型在语言生成方面展示了非凡的能力。然而，真实世界的任务经常需要控制生成文本的分布，以减轻偏见、促进公平性和实现个性化。现有的文本分布控制技术只适用于定量分布，这要求预先定义的类别、分布比例或符合所需分布的现有语料库。然而，许多重要的分布，如个人偏好，是未定量化的。在这项工作中，我们通过提出Nano，一个少样本人机交互训练算法，不断从人类反馈中学习，来解决按任意分布（定量和未定量）生成文本的问题。与先前的工作相比，Nano在单一主题/属性以及定量分布控制方面取得了最先进的结果。我们还展示Nano能够学习未定量化的分布。

    Pretrained language models have demonstrated extraordinary capabilities in language generation. However, real-world tasks often require controlling the distribution of generated text in order to mitigate bias, promote fairness, and achieve personalization. Existing techniques for controlling the distribution of generated text only work with quantified distributions, which require pre-defined categories, proportions of the distribution, or an existing corpus following the desired distributions. However, many important distributions, such as personal preferences, are unquantified. In this work, we tackle the problem of generating text following arbitrary distributions (quantified and unquantified) by proposing Nano, a few-shot human-in-the-loop training algorithm that continuously learns from human feedback. Nano achieves state-of-the-art results on single topic/attribute as well as quantified distribution control compared to previous works. We also show that Nano is able to learn unquan
    
[^62]: CC-Riddle：一个中文字谜问答数据集

    CC-Riddle: A Question Answering Dataset of Chinese Character Riddles. (arXiv:2206.13778v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.13778](http://arxiv.org/abs/2206.13778)

    本论文构建了一个名为CC-Riddle的中文字谜问答数据集，覆盖了大多数常见的简体中文字符。该数据集的构建过程结合了网络爬虫、语言模型生成和手动过滤，为解决中文字谜问题提供了重要资源。

    

    中文字谜是中文特有的一种文化娱乐形式，通常包括谜语描述和谜底两个部分。谜底是一个单字，而谜语描述主要描述了谜底的字形，有时还会附带解释和发音。解决中文字谜是一项具有挑战性的任务，要求理解字形、普通知识和掌握比喻语言。在本论文中，我们构建了一个名为CC-Riddle的中文字谜数据集，该数据集涵盖了大多数常见的简体中文字符。构建过程结合了网络爬虫、语言模型生成和手动过滤。在生成阶段，我们将谜底字的汉语拼音、字形和含义输入到生成模型中，模型会生成多个谜语描述。

    The Chinese character riddle is a unique form of cultural entertainment specific to the Chinese language. It typically comprises two parts: the riddle description and the solution. The solution to the riddle is a single character, while the riddle description primarily describes the glyph of the solution, occasionally supplemented with its explanation and pronunciation. Solving Chinese character riddles is a challenging task that demands understanding of character glyph, general knowledge, and a grasp of figurative language. In this paper, we construct a \textbf{C}hinese \textbf{C}haracter riddle dataset named CC-Riddle, which covers the majority of common simplified Chinese characters. The construction process is a combination of web crawling, language model generation and manual filtering. In generation stage, we input the Chinese phonetic alphabet, glyph and meaning of the solution character into the generation model, which then produces multiple riddle descriptions. The generated r
    
[^63]: 可解释且高性能的仇恨和冒犯性言论检测

    Explainable and High-Performance Hate and Offensive Speech Detection. (arXiv:2206.12983v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.12983](http://arxiv.org/abs/2206.12983)

    这项研究构建了一个可解释且高性能的模型，基于XGBoost算法，用于检测社交媒体平台上的仇恨和冒犯性言论。该模型在不平衡的Twitter数据上显示出更好的性能，并且在降采样后的数据中也表现出优越性能。

    

    社交媒体平台上信息的传播可能会在脆弱社群中创造敌对的环境，并使某些群体沉默。为了缓解这种情况，已开发了多个模型来检测仇恨和冒犯性言论。由于在社交媒体平台上检测仇恨和冒犯性言论可能错误地将个体排除在社交媒体平台之外，从而降低了信任度，因此有必要创建可解释且可解释的模型。因此，我们基于XGBoost算法构建了一个可解释且可解释的高性能模型，该模型使用Twitter数据进行训练。对于不平衡的Twitter数据，相比于LSTM、AutoGluon和ULMFiT模型的F1得分分别为0.38和0.37，以及0.38，XGBoost在仇恨言论检测方面的F1得分为0.75，表现更好。当我们将数据降采样为约5000条推文的三个独立类别时，XGBoost在仇恨言论检测方面的F1得分也优于LSTM、AutoGluon和ULMFiT，为0.79。

    The spread of information through social media platforms can create environments possibly hostile to vulnerable communities and silence certain groups in society. To mitigate such instances, several models have been developed to detect hate and offensive speech. Since detecting hate and offensive speech in social media platforms could incorrectly exclude individuals from social media platforms, which can reduce trust, there is a need to create explainable and interpretable models. Thus, we build an explainable and interpretable high performance model based on the XGBoost algorithm, trained on Twitter data. For unbalanced Twitter data, XGboost outperformed the LSTM, AutoGluon, and ULMFiT models on hate speech detection with an F1 score of 0.75 compared to 0.38 and 0.37, and 0.38 respectively. When we down-sampled the data to three separate classes of approximately 5000 tweets, XGBoost performed better than LSTM, AutoGluon, and ULMFiT; with F1 scores for hate speech detection of 0.79 vs 
    
[^64]: 自然语言处理在精算学中的应用：使用Transformer的案例研究来处理文本特征

    Actuarial Applications of Natural Language Processing Using Transformers: Case Studies for Using Text Features in an Actuarial Context. (arXiv:2206.02014v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.02014](http://arxiv.org/abs/2206.02014)

    这个教程介绍了使用Transformer模型的方法将文本数据应用于精算学中的分类和回归任务，并展示了在多语言和长输入序列的情况下的案例研究。该教程还提供了处理无标记数据情况下的分类任务的实用方法。

    

    本教程演示了如何将文本数据应用于精算分类和回归任务中，主要关注使用基于Transformer模型的方法。使用长度平均为400个单词的车祸描述数据集（包括英语和德语）以及短期财产保险索赔描述数据集来展示这些技术。案例研究解决了多语言环境和长输入序列的挑战，并展示了解释模型输出、评估和改进模型性能的方法，包括将模型微调到特定应用领域或特定预测任务。最后，本教程提供了处理在没有或只有少量标记数据的情况下进行分类任务的实用方法，包括但不限于ChatGPT。通过仅进行最小的预处理和微调，利用现成的自然语言处理（NLP）模型的语言理解能力可以取得良好的结果。

    This tutorial demonstrates workflows to incorporate text data into actuarial classification and regression tasks. The main focus is on methods employing transformer-based models. A dataset of car accident descriptions with an average length of 400 words, available in English and German, and a dataset with short property insurance claims descriptions are used to demonstrate these techniques. The case studies tackle challenges related to a multi-lingual setting and long input sequences. They also show ways to interpret model output, to assess and improve model performance, by fine-tuning the models to the domain of application or to a specific prediction task. Finally, the tutorial provides practical approaches to handle classification tasks in situations with no or only few labeled data, including but not limited to ChatGPT. The results achieved by using the language-understanding skills of off-the-shelf natural language processing (NLP) models with only minimal pre-processing and fine-
    
[^65]: 通过主题建模和相对密度估计的犯罪热点建模

    Crime Hot-Spot Modeling via Topic Modeling and Relative Density Estimation. (arXiv:2202.04176v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.04176](http://arxiv.org/abs/2202.04176)

    本研究提出了一种通过主题建模和相对密度估计来进行犯罪热点建模的方法。实验证明该方法可以捕捉到被调度员忽视的地理热点趋势，这些热点趋势往往与整体事件密度的增加相混淆。

    

    我们提出了一种方法，通过对犯罪记录叙述的集合进行主题分布的计算，确定相似呼叫的分组以及它们的相对空间分布。我们首先为每个叙述获取一个主题分布，然后提出了一种最近邻相对密度估计（kNN-RDE）方法来获得每个主题的空间相对密度。在亚特兰大警察局的大量叙述文档（$n=475,019$）上进行的实验表明，我们的方法能够捕捉到通常被呼叫调度员一开始没有察觉到的地理热点趋势，这些趋势由于与一般事件密度的混淆而被忽视。

    We present a method to capture groupings of similar calls and determine their relative spatial distribution from a collection of crime record narratives. We first obtain a topic distribution for each narrative, and then propose a nearest neighbors relative density estimation (kNN-RDE) approach to obtain spatial relative densities per topic. Experiments over a large corpus ($n=475,019$) of narrative documents from the Atlanta Police Department demonstrate the viability of our method in capturing geographic hot-spot trends which call dispatchers do not initially pick up on and which go unnoticed due to conflation with elevated event density in general.
    
[^66]: BLM-17m: 一个用于推特上黑人生命至关重要话题检测的大规模数据集

    BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on Twitter. (arXiv:2105.01331v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2105.01331](http://arxiv.org/abs/2105.01331)

    本论文提出了一个用于推特上检测黑人生命至关重要话题的大规模数据集BLM-17m，涵盖了乔治·弗洛伊德事件期间的17百万推文。作者提供了两个基线模型TF-IDF和LDA，并对其进行了评估。

    

    人权保护是世界上最重要的问题之一。本文旨在提供一个涵盖最近几个月全球影响深远的人权矛盾之一——乔治·弗洛伊德事件的数据集。我们提出了一个带有17百万推文的主题检测标记数据集。这些推文是从2020年5月25日至2020年8月21日收集的，涵盖了这一事件开始后的89天。我们通过监测全球和本地报纸的最热门新闻主题对数据集进行了标记。除此之外，我们还提供了两个基线模型，TF-IDF和LDA。我们使用三个不同的k值对这两种方法的精确度、召回率和F1分数进行了评估。收集到的数据集可以在https://github.com/MeysamAsgariC/BLMT 上找到。

    Protection of human rights is one of the most important problems of our world. In this paper, our aim is to provide a dataset which covers one of the most significant human rights contradiction in recent months affected the whole world, George Floyd incident. We propose a labeled dataset for topic detection that contains 17 million tweets. These Tweets are collected from 25 May 2020 to 21 August 2020 that covers 89 days from start of this incident. We labeled the dataset by monitoring most trending news topics from global and local newspapers. Apart from that, we present two baselines, TF-IDF and LDA. We evaluated the results of these two methods with three different k values for metrics of precision, recall and f1-score. The collected dataset is available at https://github.com/MeysamAsgariC/BLMT.
    

