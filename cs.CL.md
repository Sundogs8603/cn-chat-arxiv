# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Reinforced Self-Training (ReST) for Language Modeling.](http://arxiv.org/abs/2308.08998) | 本文提出了一种称为自学习增强 (ReST) 的算法，通过从人类反馈中进行强化学习来提高大型语言模型 (LLM) 的输出质量。在机器翻译任务上的实验结果表明，ReST能够以高效的方式显著提高翻译质量。 |
| [^2] | [Evaluation of really good grammatical error correction.](http://arxiv.org/abs/2308.08982) | 这项研究在最近发布的瑞典学习者文本数据集上对各种GEC系统进行了综合评估，并发现在几次训练的情况下，GPT-3具有明显的优势。 |
| [^3] | [Beam Retrieval: General End-to-End Retrieval for Multi-Hop Question Answering.](http://arxiv.org/abs/2308.08973) | Beam Retrieval是一个通用的端到端检索框架，用于多阶段问答。它通过保持多个相关文段的假设和通过最小化组合损失来优化编码器和分类头，实现了近50%的改进效果。 |
| [^4] | [CMB: A Comprehensive Medical Benchmark in Chinese.](http://arxiv.org/abs/2308.08833) | CMB是一个全面的中文医学基准，基于中国本土语言和文化框架设计，能够解决将英语医学评估翻译到本地环境中的上下文不一致问题。 |
| [^5] | [Factuality Detection using Machine Translation -- a Use Case for German Clinical Text.](http://arxiv.org/abs/2308.08827) | 这项工作使用机器翻译将英语数据翻译成德语，以训练临床文本中的事实度检测模型。这种方法解决了临床数据难以共享的问题。 |
| [^6] | [Linguistically-Informed Neural Architectures for Lexical, Syntactic and Semantic Tasks in Sanskrit.](http://arxiv.org/abs/2308.08807) | 本论文针对梵语手稿开发了基于神经网络的语言信息驱动的解决方案，旨在解决梵语的词分割、依赖解析、复合类型识别和诗歌分析等任务中的挑战。 |
| [^7] | [Chinese Spelling Correction as Rephrasing Language Model.](http://arxiv.org/abs/2308.08796) | 本文提出了一种新颖的中文拼写纠错方法，通过改写语言建模来重新表达整个句子，而不是仅仅依赖错误模式进行字符级别标注，取得了最新的最优结果。 |
| [^8] | [Task Relation Distillation and Prototypical Pseudo Label for Incremental Named Entity Recognition.](http://arxiv.org/abs/2308.08793) | 本论文提出了一种名为任务关系蒸馏和原型伪标签的方法，用于解决增量命名实体识别中的灾难性遗忘和背景转换问题。任务关系蒸馏通过最小化任务间关系蒸馏损失确保任务间语义一致性，同时通过最小化任务内自熵损失增强模型的预测置信度。原型伪标签策略能够区分旧实体类型和当前任务中的非实体类型。 |
| [^9] | [Exploring Demonstration Ensembling for In-context Learning.](http://arxiv.org/abs/2308.08780) | 本研究探索了上下文学习的演示集成方法，用于提高语言模型在给定任务的输入输出对中的预测性能。通过将演示分成子集并组合各子集的输出概率，我们得到了最终的预测结果。 |
| [^10] | [Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models.](http://arxiv.org/abs/2308.08774) | 该论文研究了多语言语言模型在多语言压缩、语言公平性和透明性等方面的要求，并发现差分隐私与训练数据影响稀疏性之间存在相互制约的关系。 |
| [^11] | [Discrete Prompt Compression with Reinforcement Learning.](http://arxiv.org/abs/2308.08758) | 本研究提出了一种使用强化学习的离散提示压缩方法（PCRL），以解决指令调整的语言模型中嵌入训练的挑战。PCRL采用了一种计算效率高的策略网络直接编辑提示，可以灵活应用于各种类型的LM，而不需要梯度访问或标记数据。 |
| [^12] | [An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning.](http://arxiv.org/abs/2308.08747) | 该研究实证评估了大型语言模型在持续微调过程中的灾难性遗忘现象，并发现随着模型规模增加，遗忘的严重程度也加剧。与编码器-解码器模型相比，仅有解码器的模型遗忘较少并保留更多知识。此外，研究还发现LLMs可以减轻语言偏见，并且ALPACA在保留知识和容量方面具有优势。 |
| [^13] | [PMET: Precise Model Editing in a Transformer.](http://arxiv.org/abs/2308.08742) | 该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。 |
| [^14] | [Enhancing Phrase Representation by Information Bottleneck Guided Text Diffusion Process for Keyphrase Extraction.](http://arxiv.org/abs/2308.08739) | 本研究提出了一种利用信息瓶颈引导的文本扩散过程来增强短语表示的关键词提取方法。该方法充分利用关键词信息，通过优化排名网络和变分信息瓶颈来提高关键词提取的效果。 |
| [^15] | [LLM-FuncMapper: Function Identification for Interpreting Complex Clauses in Building Codes via LLM.](http://arxiv.org/abs/2308.08728) | LLM-FuncMapper提出了一种通过LLM实现对建筑法规中复杂条款的函数识别的方法，通过定义原子函数和开发提示模板来解决传统逻辑表示的限制。 |
| [^16] | [Decoding Emotions: A comprehensive Multilingual Study of Speech Models for Speech Emotion Recognition.](http://arxiv.org/abs/2308.08713) | 本研究提出了一个全面的语音情感识别（SER）的基准，评估了八种语音表示模型和六种不同语言。通过探索性实验，发现使用来自语音模型单一优化层的特征可以平均降低32%的错误率，并且中间层捕获了最重要的情感信息。 |
| [^17] | [Lightweight Adaptation of Neural Language Models via Subspace Embedding.](http://arxiv.org/abs/2308.08688) | 本论文提出了一种新的紧凑嵌入结构，通过牺牲部分准确度，减少预训练语言模型的内存占用。实验证明，该结构可以实现超过99.8%的压缩率。 |
| [^18] | [Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions.](http://arxiv.org/abs/2308.08661) | 这项研究通过利用从维基百科生成的一组明确问题的数据库，提出了一种用于回答模糊问题的新技术，在回答性能和歧义问题消除方面取得了显著提高。 |
| [^19] | [Large Language Models for Granularized Barrett's Esophagus Diagnosis Classification.](http://arxiv.org/abs/2308.08660) | 本研究开发了一种基于transformer的通用方法，利用大型语言模型在Barrett食管炎诊断分类中实现数据自动化提取，具有与高度定制的基于规则系统相当的性能。 |
| [^20] | [Learning the meanings of function words from grounded language using a visual question answering model.](http://arxiv.org/abs/2308.08628) | 本研究通过研究基于视觉问答模型学习到的功能词的意义，旨在更好地了解模型和儿童如何学习这些词汇。研究发现，在以视觉为基础的语言上训练的递归模型能够学习到需要空间和数字推理的功能词的梯度语义，并且可以在没有逻辑推理先验知识的情况下学习到"和"和"或"的意义，以及迅速发展出替换推论的能力的早期证据。 |
| [^21] | [BIOptimus: Pre-training an Optimal Biomedical Language Model with Curriculum Learning for Named Entity Recognition.](http://arxiv.org/abs/2308.08625) | 本文通过比较不同的预训练方法，提出了一种初始化权重的新方法，该方法通过从BERT模型中提取现有权重来加速预训练，以探索在生物医学领域更优的预训练方法。 |
| [^22] | [Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought.](http://arxiv.org/abs/2308.08614) | 本文提出了一种新的提示技术——思维图（GoT），通过在三个不断升级的挑战中的测试，我们的方法在多步逻辑推理问题上表现优于GPT-4，并且相比最先进的提示方法思维树（ToT），我们的方法有更高的准确性提升。 |
| [^23] | [FootGPT : A Large Language Model Development Experiment on a Minimal Setting.](http://arxiv.org/abs/2308.08610) | 本文介绍了一个在最小设置上进行的大规模语言模型开发实验，研究发现准确的语言模型的关键在于适当的数据集内容和训练策略，而不是神经参数数量、训练时长或数据集大小。通过对一个10亿参数规模的通用因果语言模型进行微调，并使用商业语言模型提供的精简段落和问答对构建数据集，可以有效解释足球数据。 |
| [^24] | [AffectEcho: Speaker Independent and Language-Agnostic Emotion and Affect Transfer for Speech Synthesis.](http://arxiv.org/abs/2308.08577) | AffectEcho是一种无关说话人和无关语言的情感和情感传递模型，通过使用向量量化码书来建模情感，并在五个级别的情感强度上捕捉细微差别，从而成功地控制生成的语音的情感，同时保持每个说话人独特的身份、风格和情感节奏。 |
| [^25] | [Backward Reasoning in Large Language Models for Verification.](http://arxiv.org/abs/2308.07758) | 本文研究了在大型语言模型中使用反向推理进行验证的方法。作者提出了一种新颖的技术，通过屏蔽问题中的一个标记，并要求语言模型预测被屏蔽的标记来验证候选答案。同时，作者还提出了一种结合正向和反向推理的方法来估计候选答案的概率。 |
| [^26] | [Steering Language Generation: Harnessing Contrastive Expert Guidance and Negative Prompting for Coherent and Diverse Synthetic Data Generation.](http://arxiv.org/abs/2308.07645) | 该论文提出了一种引导语言生成的方法，通过对比专家指导和负面提示，实现了连贯和多样性的合成数据生成。该方法在推理时间内操作，利用对比形式指导LLMs在数据分布的一致性和与先前示例的偏离之间取得平衡。 |
| [^27] | [A Survey on Model Compression for Large Language Models.](http://arxiv.org/abs/2308.07633) | 本论文提供了关于大型语言模型的模型压缩综述，探讨了量化、修剪、知识蒸馏等不同方法，并突出介绍了最新进展和创新方法，为实现高效的部署提供了重要思路。 |
| [^28] | [Can Knowledge Graphs Simplify Text?.](http://arxiv.org/abs/2308.06975) | 提出了一种KGSimple方法，将知识图谱技术应用于无监督文本简化，实现从知识图谱开始生成简明文本，保留重要信息并输出流畅且描述性的句子。 |
| [^29] | [Metacognitive Prompting Improves Understanding in Large Language Models.](http://arxiv.org/abs/2308.05342) | 元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。 |
| [^30] | [WIKITIDE: A Wikipedia-Based Timestamped Definition Pairs Dataset.](http://arxiv.org/abs/2308.03582) | 本文提出了WikiTiDe，这是一个从维基百科中提取的时间戳定义对数据集，该数据集可用于加速历时性自然语言处理，并训练模型以扫描核心更新。通过自举种子版本，可以获得更好的微调模型。 |
| [^31] | [Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?.](http://arxiv.org/abs/2308.01284) | ChatGPT作为检测器能否有效检测AI生成的文本，我们通过评估其在人工编写文本与AI生成文本之间的区分能力，并在公开数据集上进行实验，得出了关于ChatGPT在自动化检测流程中的应用指导。 |
| [^32] | [Getting pwn'd by AI: Penetration Testing with Large Language Models.](http://arxiv.org/abs/2308.00121) | 本文探讨了使用大型语言模型（如GPT3.5）作为AI助手来增强渗透测试人员的能力，实现了高级任务规划和低级漏洞寻找两种用例，取得了有前景的初步结果，并就提供该技术的伦理问题进行了讨论。 |
| [^33] | [GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning.](http://arxiv.org/abs/2307.13923) | 本文介绍了GrammarGPT，一个开源LLM用于母语汉语语法错误修正，通过混合数据集和启发式方法，提高了模型的修正能力。 |
| [^34] | [Gradient-Based Word Substitution for Obstinate Adversarial Examples Generation in Language Models.](http://arxiv.org/abs/2307.12507) | 本文介绍了一种名为GradObstinate的基于梯度的方法，用于生成顽固对抗样本。该方法可以自动生成意义改变但模型预测结果保持不变的对抗样本，无需人工设计约束。 |
| [^35] | [Latent Jailbreak: A Test Suite for Evaluating Both Text Safety and Output Robustness of Large Language Models.](http://arxiv.org/abs/2307.08487) | 这篇论文提出了一个评估大型语言模型安全性和鲁棒性的基准测试套件，强调了平衡的方法。通过引入含有恶意指令的潜在越狱提示数据集，并设计分层注释框架，全面研究了文本安全性和输出鲁棒性。 |
| [^36] | [A Comprehensive Overview of Large Language Models.](http://arxiv.org/abs/2307.06435) | 大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。 |
| [^37] | [Visual Adversarial Examples Jailbreak Large Language Models.](http://arxiv.org/abs/2306.13213) | 本文对将图像引入大型语言模型的安全隐患进行了分析，指出视觉输入空间的连续性和高维性是对抗攻击的丰富领域，同时也为视觉攻击者提供了更广泛的实现对抗目标的可能性。 |
| [^38] | [Generative Multimodal Entity Linking.](http://arxiv.org/abs/2306.12725) | 本文提出了 GEMEL 方法，使用大规模预训练的 LLMs 直接生成目标实体名称，仅调整了极少的模型参数即可实现最先进的 MEL 实验结果。 |
| [^39] | [Does mBERT understand Romansh? Evaluating word embeddings using word alignment.](http://arxiv.org/abs/2306.08702) | 本研究通过在德语和罗曼什语的平行句子中使用mBERT和XLM-R的词嵌入，结合相似性对齐模型，评估了mBERT对罗曼什语的理解能力。结果显示mBERT的词嵌入能够有效地对罗曼什语进行词语对齐，为进一步研究提供了有意义和适用的信息。 |
| [^40] | [Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4.](http://arxiv.org/abs/2306.07622) | 本研究揭示了大型语言模型（LLMs）具有类人直觉行为和认知错误的特点，而高级语言模型则通过学习避免这类错误并表现出超理性的方式。此外，通过使用心理学研究的方法探测LLMs，可以揭示其新生特性。 |
| [^41] | [Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding.](http://arxiv.org/abs/2305.13512) | 本文评估了几个大型预训练语言模型在口语理解任务中的表现，发现最大模型可以在零-shot学习和上下文学习中达到与监督模型相近的意图分类准确度，但在槽填充方面表现不佳，且对ASR错误敏感。 |
| [^42] | [Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding.](http://arxiv.org/abs/2305.12031) | 临床骆驼是一种基于对话的知识编码的开源医学语言模型，具有很高的可解释性和临床相关性，并在多个基准数据集上取得了最先进的结果。 |
| [^43] | [SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models.](http://arxiv.org/abs/2305.05189) | 本文提出了一个名为SUR-adapter的微调方法，用于增强预先训练的文本到图像扩散模型的语义理解和常识推理能力，以便在生成图片时使用简短的叙述提示。作者还构建了一个新的数据集SURD，并使用大型语言模型的知识进行了优化。 |
| [^44] | [Self-Edit: Fault-Aware Code Editor for Code Generation.](http://arxiv.org/abs/2305.04087) | 本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。 |
| [^45] | [Topological properties and organizing principles of semantic networks.](http://arxiv.org/abs/2304.12940) | 本论文研究了由不同语言的7个语义关系定义的语义网络的基本属性。我们发现，语义网络具有普遍的基本特性：稀疏、高度聚集和自我组织化，并呈现出幂律度数分布。一些网络显示出语言特定的属性，这些属性受语法规则的影响，例如来自高度屈折语言的网络。 |
| [^46] | [Black Box Few-Shot Adaptation for Vision-Language models.](http://arxiv.org/abs/2304.01752) | 本文提出了一种黑匣子方法，实现了对预先计算的图像和文本特征的视觉-语言模型的快速少样本适应，适用于有监督和无监督训练，并且可以用于对单模型计算的图像和文本特征进行对齐。 |
| [^47] | [Few-Shot Table-to-Text Generation with Prompt Planning and Knowledge Memorization.](http://arxiv.org/abs/2302.04415) | 本论文提出了PromptMize框架，用于解决少样本情况下的表格到文本生成问题。该框架包含提示策划和知识适配器两个方面，通过生成提示信号和利用领域特定知识来改善文本生成结果。 |
| [^48] | [PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3.](http://arxiv.org/abs/2211.09699) | 提出了PromptCap，一种使用提示引导的图像字幕生成模型，用于解决基于知识的视觉问答中通用图像字幕无法准确描述视觉实体的问题。 |
| [^49] | [Efficient Utilization of Large Pre-Trained Models for Low Resource ASR.](http://arxiv.org/abs/2210.15445) | 本研究探讨了在低资源语音识别中如何高效利用大型预训练模型，通过无监督技术和改进的架构和训练方法取得了显著的性能提升。 |
| [^50] | [Integrating Knowledge Graph embedding and pretrained Language Models in Hypercomplex Spaces.](http://arxiv.org/abs/2208.02743) | 本文提出在超复数空间中整合知识图谱嵌入和预训练语言模型的方法，通过利用超复数代数来表示单模态嵌入以及不同模态之间的交互，并且能够更好地利用结构性和文本性知识的相互作用。 |
| [^51] | [A Part-of-Speech Tagger for Yiddish.](http://arxiv.org/abs/2204.01175) | 这项研究描述了一种用于意第绪语的词性标注器的构建和评估。通过结合两个资源，即历史意第绪语Penn解析语料库和OCR意第绪语文本，研究人员展示了在无需先“标准化”语料库的情况下，简单的非上下文化嵌入也能够捕捉到拼写变体之间的关系，并通过交叉验证展示了标注器的性能。 |

# 详细

[^1]: 自学习增强 (ReST) 用于语言模型的强化学习

    Reinforced Self-Training (ReST) for Language Modeling. (arXiv:2308.08998v1 [cs.CL])

    [http://arxiv.org/abs/2308.08998](http://arxiv.org/abs/2308.08998)

    本文提出了一种称为自学习增强 (ReST) 的算法，通过从人类反馈中进行强化学习来提高大型语言模型 (LLM) 的输出质量。在机器翻译任务上的实验结果表明，ReST能够以高效的方式显著提高翻译质量。

    

    通过从人类反馈中进行强化学习 (RLHF)，可以通过与人类偏好对齐来提高大型语言模型 (LLM) 的输出质量。我们提出了一种简单的算法，通过增长批量强化学习 (RL) 来与人类偏好对齐 LLM，我们称之为增强自学习 (ReST)。给定初始的LLM策略，ReST通过从策略中生成样本来产生一个数据集，然后使用离线强化学习算法改进LLM策略。ReST比典型的在线RLHF方法更高效，因为训练数据集是离线生成的，可以重复使用数据。虽然ReST是适用于所有生成学习设置的通用方法，但我们将重点放在其在机器翻译中的应用上。我们的结果表明，ReST可以以计算和采样高效的方式显著提高翻译质量，通过自动化指标和人工评估在机器翻译基准上测量。

    Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.
    
[^2]: 对优质语法错误修正的评估

    Evaluation of really good grammatical error correction. (arXiv:2308.08982v1 [cs.CL])

    [http://arxiv.org/abs/2308.08982](http://arxiv.org/abs/2308.08982)

    这项研究在最近发布的瑞典学习者文本数据集上对各种GEC系统进行了综合评估，并发现在几次训练的情况下，GPT-3具有明显的优势。

    

    尽管很少提及，在实践中，语法错误修正（GEC）涵盖了各种具有不同目标的模型，范围从语法错误检测到改善流畅度。传统的评估方法无法完全捕捉系统的全部能力和目标。基于参考的评估受限于捕捉可能修正的各种多样化以及参考创建过程中引入的偏见，易于偏好修复局部错误而忽视整体文本改进。大型语言模型（LLMs）的出现进一步凸显了这些评估策略的缺点，强调了评估方法的范式转变的必要性。在当前研究中，我们使用最近发布的瑞典学习者文本数据集对各种GEC系统进行全面评估。评估使用已建立的评估指标和人工评委进行。我们发现，在几次训练的情况下，GPT-3在性能上遥遥领先。

    Although rarely stated, in practice, Grammatical Error Correction (GEC) encompasses various models with distinct objectives, ranging from grammatical error detection to improving fluency. Traditional evaluation methods fail to fully capture the full range of system capabilities and objectives. Reference-based evaluations suffer from limitations in capturing the wide variety of possible correction and the biases introduced during reference creation and is prone to favor fixing local errors over overall text improvement. The emergence of large language models (LLMs) has further highlighted the shortcomings of these evaluation strategies, emphasizing the need for a paradigm shift in evaluation methodology. In the current study, we perform a comprehensive evaluation of various GEC systems using a recently published dataset of Swedish learner texts. The evaluation is performed using established evaluation metrics as well as human judges. We find that GPT-3 in a few-shot setting by far outpe
    
[^3]: Beam Retrieval: 通用的端到端检索用于多阶段问答

    Beam Retrieval: General End-to-End Retrieval for Multi-Hop Question Answering. (arXiv:2308.08973v1 [cs.CL])

    [http://arxiv.org/abs/2308.08973](http://arxiv.org/abs/2308.08973)

    Beam Retrieval是一个通用的端到端检索框架，用于多阶段问答。它通过保持多个相关文段的假设和通过最小化组合损失来优化编码器和分类头，实现了近50%的改进效果。

    

    多阶段问答涉及查找多个相关文段和逐步推理以回答复杂问题。虽然先前的方法已经开发了用于选择相关文段的检索模块，但是它们在超过两个阶段的场景中面临挑战，原因是一步方法的性能有限，两步方法在早期阶段选择无关文段时失败。在本研究中，我们介绍了Beam Retrieval，这是一个通用的多阶段问答的端到端检索框架。该方法在每个阶段保持多个相关文段的假设，扩展了搜索空间，降低了错过相关文段的风险。此外，Beam Retrieval通过最小化所有阶段的组合损失来联合优化编码器和两个分类头。为了建立一个完整的问答系统，我们引入了一个有监督的阅读器或零-shot GPT-3.5。实验结果表明，与基准方法相比，Beam Retrieval取得了近50%的改进效果。

    Multi-hop QA involves finding multiple relevant passages and step-by-step reasoning to answer complex questions. While previous approaches have developed retrieval modules for selecting relevant passages, they face challenges in scenarios beyond two hops, owing to the limited performance of one-step methods and the failure of two-step methods when selecting irrelevant passages in earlier stages. In this work, we introduce Beam Retrieval, a general end-to-end retrieval framework for multi-hop QA. This approach maintains multiple partial hypotheses of relevant passages at each step, expanding the search space and reducing the risk of missing relevant passages. Moreover, Beam Retrieval jointly optimizes an encoder and two classification heads by minimizing the combined loss across all hops. To establish a complete QA system, we incorporate a supervised reader or a zero-shot GPT-3.5. Experimental results demonstrate that Beam Retrieval achieves a nearly 50% improvement compared with baseli
    
[^4]: CMB：一个全面的中文医学基准

    CMB: A Comprehensive Medical Benchmark in Chinese. (arXiv:2308.08833v1 [cs.CL])

    [http://arxiv.org/abs/2308.08833](http://arxiv.org/abs/2308.08833)

    CMB是一个全面的中文医学基准，基于中国本土语言和文化框架设计，能够解决将英语医学评估翻译到本地环境中的上下文不一致问题。

    

    大型语言模型（LLMs）为在医学领域取得重大突破提供了可能性。建立一个标准化的医学基准成为衡量进展的基石。然而，不同地区的医学环境具有各自的特点，例如在中国境内传统中医的普遍性和重要性。因此，仅仅翻译基于英语的医学评估可能导致当地环境中的“上下文不一致”。为了解决这个问题，我们提出了一个名为CMB（Comprehensive Medical Benchmark in Chinese）的本地化医学基准，完全设计和根植于中国本土的语言和文化框架。尽管传统中医是这个评估的重要组成部分，但它并不构成其全部。使用这个基准，我们评估了几个知名的大规模LLMs，包括ChatGPT、GPT-4、专门的中文LLMs和专门用于医学领域的LLMs。

    Large Language Models (LLMs) provide a possibility to make a great breakthrough in medicine. The establishment of a standardized medical benchmark becomes a fundamental cornerstone to measure progression. However, medical environments in different regions have their local characteristics, e.g., the ubiquity and significance of traditional Chinese medicine within China. Therefore, merely translating English-based medical evaluation may result in \textit{contextual incongruities} to a local region. To solve the issue, we propose a localized medical benchmark called CMB, a Comprehensive Medical Benchmark in Chinese, designed and rooted entirely within the native Chinese linguistic and cultural framework. While traditional Chinese medicine is integral to this evaluation, it does not constitute its entirety. Using this benchmark, we have evaluated several prominent large-scale LLMs, including ChatGPT, GPT-4, dedicated Chinese LLMs, and LLMs specialized in the medical domain. It is worth not
    
[^5]: 使用机器翻译的事实度检测 -- 德语临床文本的应用案例

    Factuality Detection using Machine Translation -- a Use Case for German Clinical Text. (arXiv:2308.08827v1 [cs.CL])

    [http://arxiv.org/abs/2308.08827](http://arxiv.org/abs/2308.08827)

    这项工作使用机器翻译将英语数据翻译成德语，以训练临床文本中的事实度检测模型。这种方法解决了临床数据难以共享的问题。

    

    在自动处理临床文本时，事实度可以起到重要作用，因为明确指出某些症状是否存在、可能存在、未提及或肯定不存在是有差别的。在大多数情况下，在监督式机器学习环境中处理这类现象需要足够数量的样例。然而，由于临床文本可能包含敏感信息，数据不能轻易共享。在事实度检测的背景下，本文提出了一种简单的解决方案，使用机器翻译将英语数据翻译成德语，以训练基于Transformer的事实度检测模型。

    Factuality can play an important role when automatically processing clinical text, as it makes a difference if particular symptoms are explicitly not present, possibly present, not mentioned, or affirmed. In most cases, a sufficient number of examples is necessary to handle such phenomena in a supervised machine learning setting. However, as clinical text might contain sensitive information, data cannot be easily shared. In the context of factuality detection, this work presents a simple solution using machine translation to translate English data to German to train a transformer-based factuality detection model.
    
[^6]: 语言信息驱动的神经网络架构在梵语的词汇、句法和语义任务中的应用

    Linguistically-Informed Neural Architectures for Lexical, Syntactic and Semantic Tasks in Sanskrit. (arXiv:2308.08807v1 [cs.CL])

    [http://arxiv.org/abs/2308.08807](http://arxiv.org/abs/2308.08807)

    本论文针对梵语手稿开发了基于神经网络的语言信息驱动的解决方案，旨在解决梵语的词分割、依赖解析、复合类型识别和诗歌分析等任务中的挑战。

    

    本论文的主要目标是通过自然语言技术使梵语手稿更加易于使用。梵语的词态丰富、复合词、自由的词序以及资源匮乏的特点给深度学习解决方案的开发带来了重大挑战。我们确定了四个基本任务，这些任务对于开发梵语的强大自然语言处理技术至关重要：梵语词分割、依赖解析、复合类型识别和诗歌分析。第一个任务，梵语词分割，是任何其他下游应用的基本文本处理任务。然而，由于在词边界处修改字符的梵语特殊现象（加入或脱落），这一任务具有挑战性。类似地，现有的依赖解析方法在形态丰富和资源匮乏的梵语等语言上遇到困难。复合类型识别对梵语也具有挑战性，因为复合词组件之间存在上下文敏感的语义关系。

    The primary focus of this thesis is to make Sanskrit manuscripts more accessible to the end-users through natural language technologies. The morphological richness, compounding, free word orderliness, and low-resource nature of Sanskrit pose significant challenges for developing deep learning solutions. We identify four fundamental tasks, which are crucial for developing a robust NLP technology for Sanskrit: word segmentation, dependency parsing, compound type identification, and poetry analysis. The first task, Sanskrit Word Segmentation (SWS), is a fundamental text processing task for any other downstream applications. However, it is challenging due to the sandhi phenomenon that modifies characters at word boundaries. Similarly, the existing dependency parsing approaches struggle with morphologically rich and low-resource languages like Sanskrit. Compound type identification is also challenging for Sanskrit due to the context-sensitive semantic relation between components. All these 
    
[^7]: 《中文拼写纠错作为改写语言模型》

    Chinese Spelling Correction as Rephrasing Language Model. (arXiv:2308.08796v1 [cs.CL])

    [http://arxiv.org/abs/2308.08796](http://arxiv.org/abs/2308.08796)

    本文提出了一种新颖的中文拼写纠错方法，通过改写语言建模来重新表达整个句子，而不是仅仅依赖错误模式进行字符级别标注，取得了最新的最优结果。

    

    本文研究了中文拼写纠错（CSC），旨在检测和纠正给定句子中的潜在拼写错误。目前最先进的方法将CSC视为序列标注任务，并在句子对上微调基于BERT的模型。然而，我们注意到在将一个字符标记为另一个字符的过程中存在一个关键缺陷，即纠正过程过于依赖错误。这与人类思维相反，人们根据句子的语义重新表达整个句子，而不仅仅是基于之前记忆的错误模式。这种违反直觉的学习过程导致机器拼写纠错的泛化能力和可迁移性受到限制。为了解决这个问题，我们提出了“改写语言建模”（ReLM），其中模型通过填充额外的位置来重新表达整个句子，而不是进行字符级别的标注。这种新颖的训练范式在微调后取得了最新的最优结果。

    This paper studies Chinese Spelling Correction (CSC), which aims to detect and correct potential spelling errors in a given sentence. Current state-of-the-art methods regard CSC as a sequence tagging task and fine-tune BERT-based models on sentence pairs. However, we note a critical flaw in the process of tagging one character to another, that the correction is excessively conditioned on the error. This is opposite from human mindset, where individuals rephrase the complete sentence based on its semantics, rather than solely on the error patterns memorized before. Such a counter-intuitive learning process results in the bottleneck of generalizability and transferability of machine spelling correction. To address this, we propose $Rephrasing Language Modeling$ (ReLM), where the model is trained to rephrase the entire sentence by infilling additional slots, instead of character-to-character tagging. This novel training paradigm achieves the new state-of-the-art results across fine-tuned 
    
[^8]: 增量式命名实体识别的任务关系蒸馏和原型伪标签

    Task Relation Distillation and Prototypical Pseudo Label for Incremental Named Entity Recognition. (arXiv:2308.08793v1 [cs.CL])

    [http://arxiv.org/abs/2308.08793](http://arxiv.org/abs/2308.08793)

    本论文提出了一种名为任务关系蒸馏和原型伪标签的方法，用于解决增量命名实体识别中的灾难性遗忘和背景转换问题。任务关系蒸馏通过最小化任务间关系蒸馏损失确保任务间语义一致性，同时通过最小化任务内自熵损失增强模型的预测置信度。原型伪标签策略能够区分旧实体类型和当前任务中的非实体类型。

    

    增量命名实体识别（Incremental Named Entity Recognition, INER）涉及在不访问先前学习类型的训练数据的情况下，对新实体类型进行顺序学习。然而，INER面临着增量学习中的灾难性遗忘挑战，并进一步受到背景转换的影响（即，旧和未来的实体类型在当前任务中被标记为非实体类型）。为了解决这些挑战，我们提出了一种称为任务关系蒸馏和原型伪标签（RDP）的方法，用于INER。具体而言，为了解决灾难性遗忘问题，我们引入了任务关系蒸馏方案，该方案具有两个目的：1）通过最小化任务间关系蒸馏损失来确保不同增量学习任务之间的任务间语义一致性；2）通过最小化任务内自熵损失来增强模型的预测置信度。同时，为了减轻背景转换，我们开发了一种原型伪标签策略，可以区分旧实体类型和当前任务中的非实体类型。

    Incremental Named Entity Recognition (INER) involves the sequential learning of new entity types without accessing the training data of previously learned types. However, INER faces the challenge of catastrophic forgetting specific for incremental learning, further aggravated by background shift (i.e., old and future entity types are labeled as the non-entity type in the current task). To address these challenges, we propose a method called task Relation Distillation and Prototypical pseudo label (RDP) for INER. Specifically, to tackle catastrophic forgetting, we introduce a task relation distillation scheme that serves two purposes: 1) ensuring inter-task semantic consistency across different incremental learning tasks by minimizing inter-task relation distillation loss, and 2) enhancing the model's prediction confidence by minimizing intra-task self-entropy loss. Simultaneously, to mitigate background shift, we develop a prototypical pseudo label strategy that distinguishes old entit
    
[^9]: 探索上下文学习的演示集成

    Exploring Demonstration Ensembling for In-context Learning. (arXiv:2308.08780v1 [cs.CL])

    [http://arxiv.org/abs/2308.08780](http://arxiv.org/abs/2308.08780)

    本研究探索了上下文学习的演示集成方法，用于提高语言模型在给定任务的输入输出对中的预测性能。通过将演示分成子集并组合各子集的输出概率，我们得到了最终的预测结果。

    

    上下文学习通过向语言模型展示输入-输出对的示例来进行操作，即演示。上下文学习的标准方法是将演示与测试输入连接起来提示给语言模型。然而，这种方法存在一些问题。首先，连接方法几乎无法控制每个演示对模型预测的贡献。当一些演示与测试示例无关时，这可能不是最优的。其次，由于某些变换器模型对输入长度有限制，将许多示例放入上下文中可能是不可行的，特别是在处理长输入任务时。在本研究中，我们探索了演示集成（DENSE）作为简单连接的替代方法。模型使用演示的子集（即bucket）来预测输出，然后将每个子集得到的输出概率组合起来生成最终预测结果。我们使用GPT-j研究了不同的集成方法，并进行了实验。

    In-context learning (ICL) operates by showing language models (LMs) examples of input-output pairs for a given task, i.e., demonstrations. The standard approach for ICL is to prompt the LM with concatenated demonstrations followed by the test input. This approach suffers from some issues. First, concatenation offers almost no control over the contribution of each demo to the model prediction. This can be sub-optimal when some demonstrations are irrelevant to the test example. Second, due to the input length limit of some transformer models, it might be infeasible to fit many examples into the context, especially when dealing with long-input tasks. In this work, we explore Demonstration Ensembling (DENSE) as an alternative to simple concatenation. \model predicts outputs using subsets (i.e., buckets) of the demonstrations and then combines the output probabilities resulting from each subset to produce the final prediction. We study different ensembling methods using GPT-j and experiment
    
[^10]: 差分隐私、语言公平性和训练数据影响：多语言语言模型的不可能性和可能性定理

    Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models. (arXiv:2308.08774v1 [cs.CL])

    [http://arxiv.org/abs/2308.08774](http://arxiv.org/abs/2308.08774)

    该论文研究了多语言语言模型在多语言压缩、语言公平性和透明性等方面的要求，并发现差分隐私与训练数据影响稀疏性之间存在相互制约的关系。

    

    语言模型如mBERT、XLM-R和BLOOM旨在实现多语言概括或压缩，以便于转移到大量（可能未知的）语言。然而，这些模型还应该具备隐私性、语言公平性和透明性，即将它们的预测与训练数据相关联。这些要求可以同时满足吗？我们表明，多语言压缩和语言公平性与差分隐私是兼容的，但差分隐私与训练数据影响稀疏性是相悖的，后者是透明性的目标。我们还对两个常见的自然语言处理任务进行了一系列实验，并在不同的隐私保证下评估了多语言压缩和训练数据影响稀疏性，更详细地探讨了这些权衡。我们的结果表明，我们需要开发一种共同优化这些目标的方法，以找到实际的权衡。

    Language models such as mBERT, XLM-R, and BLOOM aim to achieve multilingual generalization or compression to facilitate transfer to a large number of (potentially unseen) languages. However, these models should ideally also be private, linguistically fair, and transparent, by relating their predictions to training data. Can these requirements be simultaneously satisfied? We show that multilingual compression and linguistic fairness are compatible with differential privacy, but that differential privacy is at odds with training data influence sparsity, an objective for transparency. We further present a series of experiments on two common NLP tasks and evaluate multilingual compression and training data influence sparsity under different privacy guarantees, exploring these trade-offs in more detail. Our results suggest that we need to develop ways to jointly optimize for these objectives in order to find practical trade-offs.
    
[^11]: 使用强化学习的离散提示压缩

    Discrete Prompt Compression with Reinforcement Learning. (arXiv:2308.08758v1 [cs.CL])

    [http://arxiv.org/abs/2308.08758](http://arxiv.org/abs/2308.08758)

    本研究提出了一种使用强化学习的离散提示压缩方法（PCRL），以解决指令调整的语言模型中嵌入训练的挑战。PCRL采用了一种计算效率高的策略网络直接编辑提示，可以灵活应用于各种类型的LM，而不需要梯度访问或标记数据。

    

    指令调整的语言模型（LM）被用户广泛使用来解决与任务特定提示相关的各种问题。由于上下文窗口长度和计算成本的限制，鼓励开发压缩提示的方法。现有方法严重依赖于训练嵌入，这些嵌入被设计为容纳多个记号含义。这在解释性、固定数量的嵌入记号、在不同LM之间的可重用性以及与黑盒API交互时的不适用性方面带来了挑战。本研究提出了一种使用强化学习的提示压缩方法（PCRL），它解决了这些问题。PCRL采用了一种计算效率高的策略网络，直接编辑提示。PCRL的训练方法可以灵活地应用于各种类型的LM，以及只有解码器和编码器-解码器架构，而不需要使用梯度访问LM或标记数据进行训练。

    Instruction-tuned Language Models (LMs) are widely used by users to address various problems with task-specific prompts. Constraints associated with the context window length and computational costs encourage the development of compressed prompts. Existing methods rely heavily on training embeddings, which are designed to accommodate multiple token meanings. This presents challenges in terms of interpretability, a fixed number of embedding tokens, reusability across different LMs, and inapplicability when interacting with black-box APIs. This study proposes prompt compression with reinforcement learning (PCRL), a novel discrete prompt compression method that addresses these issues. PCRL employs a computationally efficient policy network that directly edits prompts. The PCRL training approach can be flexibly applied to various types of LMs, as well as decoder-only and encoder-decoder architecture, and can be trained without gradient access to LMs or labeled data. PCRL achieves an averag
    
[^12]: 大型语言模型在持续微调过程中的灾难性遗忘的实证研究

    An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning. (arXiv:2308.08747v1 [cs.CL])

    [http://arxiv.org/abs/2308.08747](http://arxiv.org/abs/2308.08747)

    该研究实证评估了大型语言模型在持续微调过程中的灾难性遗忘现象，并发现随着模型规模增加，遗忘的严重程度也加剧。与编码器-解码器模型相比，仅有解码器的模型遗忘较少并保留更多知识。此外，研究还发现LLMs可以减轻语言偏见，并且ALPACA在保留知识和容量方面具有优势。

    

    灾难性遗忘（CF）是机器学习中的一种现象，当模型学习新信息时，它会忘记先前学到的信息。由于大型语言模型（LLMs）显示出了出色的性能，探究LLMs在持续微调中是否存在CF是很有意义的。在这项研究中，我们从领域知识、推理和阅读理解的角度对LLMs的遗忘现象进行了实证评估。实验表明，从1b到7b的范围内，LLMs普遍存在灾难性遗忘现象，并且随着规模的增加，遗忘的严重程度也加剧。与编码器-解码器模型mT0相比，仅有解码器的模型BLOOMZ遗忘较少并保留更多知识。我们还观察到，在持续微调过程中，LLMs可以减轻语言偏见（如性别偏见）。此外，我们发现与LLAMA相比，ALPACA在保留更多知识和容量方面具有优势。

    Catastrophic forgetting (CF) is a phenomenon that occurs in machine learning when a model forgets previously learned information as it learns new information. As large language models (LLMs) have shown excellent performance, it is interesting to uncover whether CF exists in the continual fine-tuning of LLMs. In this study, we empirically evaluate the forgetting phenomenon in LLMs' knowledge, from the perspectives of domain knowledge, reasoning, and reading comprehension. The experiments demonstrate that catastrophic forgetting is generally observed in LLMs ranging from 1b to 7b. Furthermore, as the scale increases, the severity of forgetting also intensifies. Comparing the decoder-only model BLOOMZ with the encoder-decoder model mT0, BLOOMZ suffers less forgetting and maintains more knowledge. We also observe that LLMs can mitigate language bias (e.g. gender bias) during continual fine-tuning. Moreover, we find that ALPACA can maintain more knowledge and capacity compared with LLAMA du
    
[^13]: PMET: 在Transformer中的精确模型编辑

    PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v1 [cs.CL])

    [http://arxiv.org/abs/2308.08742](http://arxiv.org/abs/2308.08742)

    该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。

    

    模型编辑技术可以以较低的成本修改大型语言模型中的少量知识，并且已经取得了显著的成功。现有方法假设Transformer层隐藏状态是前馈网络的键值内存的值。它们通常优化Transformer层隐藏状态来记忆目标知识，并将其用于更新大型语言模型中前馈网络的权重。然而，Transformer层隐藏状态的信息流来自三个部分：多头自注意力、前馈网络和残差连接。现有方法忽视了Transformer层隐藏状态包含了前馈网络特别需要的信息这一事实。因此，模型编辑的性能下降。为了实现更精确的模型编辑，我们分析了多头自注意力和前馈网络的隐藏状态，发现多头自注意力编码了某些通用知识提取模式。这意味着当引入新知识时，多头自注意力的权重不需要更新。

    Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we
    
[^14]: 使用信息瓶颈引导的文本扩散过程增强短语表示的关键词提取方法

    Enhancing Phrase Representation by Information Bottleneck Guided Text Diffusion Process for Keyphrase Extraction. (arXiv:2308.08739v1 [cs.CL])

    [http://arxiv.org/abs/2308.08739](http://arxiv.org/abs/2308.08739)

    本研究提出了一种利用信息瓶颈引导的文本扩散过程来增强短语表示的关键词提取方法。该方法充分利用关键词信息，通过优化排名网络和变分信息瓶颈来提高关键词提取的效果。

    

    关键词提取(KPE)是自然语言处理中的一个重要任务，用于从给定文档中提取关键词。许多现有的监督方法将KPE视为序列标注、跨度级分类或生成任务。然而，这些方法缺乏利用关键词信息的能力，可能导致结果有偏差。在本研究中，我们提出了Diff-KPE，它利用监督的变分信息瓶颈(VIB)来引导文本扩散过程，生成增强的关键词表示。Diff-KPE首先根据整个文档生成所需的关键词嵌入，然后将生成的关键词嵌入注入到每个短语表示中。然后，通过排名网络和VIB同时进行排名损失和分类损失的优化。Diff-KPE的设计允许我们利用关键词和文档的信息对每个候选短语进行排名。

    Keyphrase extraction (KPE) is an important task in Natural Language Processing for many scenarios, which aims to extract keyphrases that are present in a given document. Many existing supervised methods treat KPE as sequential labeling, span-level classification, or generative tasks. However, these methods lack the ability to utilize keyphrase information, which may result in biased results. In this study, we propose Diff-KPE, which leverages the supervised Variational Information Bottleneck (VIB) to guide the text diffusion process for generating enhanced keyphrase representations. Diff-KPE first generates the desired keyphrase embeddings conditioned on the entire document and then injects the generated keyphrase embeddings into each phrase representation. A ranking network and VIB are then optimized together with rank loss and classification loss, respectively. This design of Diff-KPE allows us to rank each candidate phrase by utilizing both the information of keyphrases and the docu
    
[^15]: LLM-FuncMapper:通过LLM解释建筑法规中的复杂条款的函数识别

    LLM-FuncMapper: Function Identification for Interpreting Complex Clauses in Building Codes via LLM. (arXiv:2308.08728v1 [cs.AI])

    [http://arxiv.org/abs/2308.08728](http://arxiv.org/abs/2308.08728)

    LLM-FuncMapper提出了一种通过LLM实现对建筑法规中复杂条款的函数识别的方法，通过定义原子函数和开发提示模板来解决传统逻辑表示的限制。

    

    作为自动化规则检查（ARC）的关键阶段，对监管性文本的规则解释需要相当大的努力。然而，由于缺乏领域知识和传统逻辑表示的表达能力有限，解释具有隐式属性或复杂计算逻辑的监管条款仍然具有挑战性。因此，提出了一种基于大型语言模型（LLM）的识别各种监管条款所需的预定义函数的方法LLM-FuncMapper。首先，通过对建筑法规进行系统分析，定义了一系列原子函数，以捕捉隐式属性和复杂约束的共享计算逻辑，创建了常见块的数据库，用于解释监管条款。然后，开发了一个具有思维链的提示模板，并通过基于分类的调优策略进一步增强，以实现有效的函数识别功能。最后，验证了所提出的方法。

    As a vital stage of automated rule checking (ARC), rule interpretation of regulatory texts requires considerable effort. However, interpreting regulatory clauses with implicit properties or complex computational logic is still challenging due to the lack of domain knowledge and limited expressibility of conventional logic representations. Thus, LLM-FuncMapper, an approach to identifying predefined functions needed to interpret various regulatory clauses based on the large language model (LLM), is proposed. First, by systematically analysis of building codes, a series of atomic functions are defined to capture shared computational logics of implicit properties and complex constraints, creating a database of common blocks for interpreting regulatory clauses. Then, a prompt template with the chain of thought is developed and further enhanced with a classification-based tuning strategy, to enable common LLMs for effective function identification. Finally, the proposed approach is validated
    
[^16]: 解码情绪：针对语音情感识别的多语言综合研究

    Decoding Emotions: A comprehensive Multilingual Study of Speech Models for Speech Emotion Recognition. (arXiv:2308.08713v1 [cs.CL])

    [http://arxiv.org/abs/2308.08713](http://arxiv.org/abs/2308.08713)

    本研究提出了一个全面的语音情感识别（SER）的基准，评估了八种语音表示模型和六种不同语言。通过探索性实验，发现使用来自语音模型单一优化层的特征可以平均降低32%的错误率，并且中间层捕获了最重要的情感信息。

    

    近年来，基于Transformer的语音表示模型在语音处理方面取得了巨大的进展。然而，对于这些模型在多种语言中进行语音情感识别（SER）的评估以及对其内部表示进行研究的研究仍然有限。本文通过提出一个全面的SER基准，使用八个语音表示模型和六种不同语言来评估这些模型，填补了这些差距。我们进行了探索性实验，以了解这些模型在SER中的内部工作原理。我们发现，在与使用来自语音模型所有层的特征的系统相比，使用来自语音模型单一优化层的特征可以平均降低32%的错误率。我们还在德语和波斯语方面取得了最新的成果。我们的探索性结果表明，语音模型的中间层捕获了最重要的情感信息。

    Recent advancements in transformer-based speech representation models have greatly transformed speech processing. However, there has been limited research conducted on evaluating these models for speech emotion recognition (SER) across multiple languages and examining their internal representations. This article addresses these gaps by presenting a comprehensive benchmark for SER with eight speech representation models and six different languages. We conducted probing experiments to gain insights into inner workings of these models for SER. We find that using features from a single optimal layer of a speech model reduces the error rate by 32\% on average across seven datasets when compared to systems where features from all layers of speech models are used. We also achieve state-of-the-art results for German and Persian languages. Our probing results indicate that the middle layers of speech models capture the most important emotional information for speech emotion recognition.
    
[^17]: 轻量级神经语言模型通过子空间嵌入进行适应性处理

    Lightweight Adaptation of Neural Language Models via Subspace Embedding. (arXiv:2308.08688v1 [cs.CL])

    [http://arxiv.org/abs/2308.08688](http://arxiv.org/abs/2308.08688)

    本论文提出了一种新的紧凑嵌入结构，通过牺牲部分准确度，减少预训练语言模型的内存占用。实验证明，该结构可以实现超过99.8%的压缩率。

    

    传统的神经词嵌入通常依赖于更丰富的词汇多样性。然而，语言模型倾向于通过单词嵌入参数来覆盖主要词汇，特别是对于通常覆盖其整体学习参数中的重要部分的多语言语言模型来说。在这项工作中，我们提出了一种新的紧凑嵌入结构，通过牺牲高达4%的绝对准确度来减少预训练语言模型的内存占用。嵌入向量的重建遵循一组子空间嵌入和通过从预训练语言模型中的标记之间的上下文关系进行的分配过程。子空间嵌入结构适应了掩码语言模型，以在相似性和文本蕴涵任务、句子和释义任务中评估我们的紧凑嵌入结构。我们的实验评估表明，与原始e相比，子空间嵌入实现了超过99.8%的压缩率。

    Traditional neural word embeddings are usually dependent on a richer diversity of vocabulary. However, the language models recline to cover major vocabularies via the word embedding parameters, in particular, for multilingual language models that generally cover a significant part of their overall learning parameters. In this work, we present a new compact embedding structure to reduce the memory footprint of the pre-trained language models with a sacrifice of up to 4% absolute accuracy. The embeddings vectors reconstruction follows a set of subspace embeddings and an assignment procedure via the contextual relationship among tokens from pre-trained language models. The subspace embedding structure calibrates to masked language models, to evaluate our compact embedding structure on similarity and textual entailment tasks, sentence and paraphrase tasks. Our experimental evaluation shows that the subspace embeddings achieve compression rates beyond 99.8% in comparison with the original e
    
[^18]: 使用问题、答案和修订的数据库回答模糊问题

    Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions. (arXiv:2308.08661v1 [cs.CL])

    [http://arxiv.org/abs/2308.08661](http://arxiv.org/abs/2308.08661)

    这项研究通过利用从维基百科生成的一组明确问题的数据库，提出了一种用于回答模糊问题的新技术，在回答性能和歧义问题消除方面取得了显著提高。

    

    许多开放领域的问题都没有明确的规定，因此可能有多个可能的答案，每个答案在问题的不同解释下都是正确的。回答这样模糊的问题具有挑战性，因为它需要从多个段落中检索并推理出不同的信息。我们提出了一种新的回答模糊问题的最新技术，利用从维基百科生成的一组明确问题的数据库。在具有挑战性的ASQA基准测试中，我们的方法在召回率测量上提高了15%（相对改进），在评估从预测输出中消除歧义问题的度量上提高了10%。从生成的问题数据库中检索还大大提高了多样的段落检索（通过间接匹配用户问题q到段落p，通过从p生成的问题q'）。

    Many open-domain questions are under-specified and thus have multiple possible answers, each of which is correct under a different interpretation of the question. Answering such ambiguous questions is challenging, as it requires retrieving and then reasoning about diverse information from multiple passages. We present a new state-of-the-art for answering ambiguous questions that exploits a database of unambiguous questions generated from Wikipedia. On the challenging ASQA benchmark, which requires generating long-form answers that summarize the multiple answers to an ambiguous question, our method improves performance by 15% (relative improvement) on recall measures and 10% on measures which evaluate disambiguating questions from predicted outputs. Retrieving from the database of generated questions also gives large improvements in diverse passage retrieval (by matching user questions q to passages p indirectly, via questions q' generated from p).
    
[^19]: 用于细分Barrett食管炎诊断分类的大型语言模型

    Large Language Models for Granularized Barrett's Esophagus Diagnosis Classification. (arXiv:2308.08660v1 [cs.CL])

    [http://arxiv.org/abs/2308.08660](http://arxiv.org/abs/2308.08660)

    本研究开发了一种基于transformer的通用方法，利用大型语言模型在Barrett食管炎诊断分类中实现数据自动化提取，具有与高度定制的基于规则系统相当的性能。

    

    Barrett食管炎（BE）的诊断代码在许多研究或临床使用情况下缺乏细化和精确性。需要费力的手动查阅病历以从BE病理报告中提取关键诊断表型。我们开发了一种通用的基于transformer的方法来自动化数据提取。使用哥伦比亚大学欧文医学中心的病理报告和胃肠病学家注释的目标，我们进行了二元异型分级以及细分的多类BE相关诊断分类。我们利用了两个临床预训练的大型语言模型，最佳模型性能与使用相同数据开发的高度定制的基于规则的系统相当。二元异型提取实现了0.964的F1分数，而多类模型实现了0.911的F1分数。我们的方法具有通用性，并且比定制的基于规则的方法更快实施。

    Diagnostic codes for Barrett's esophagus (BE), a precursor to esophageal cancer, lack granularity and precision for many research or clinical use cases. Laborious manual chart review is required to extract key diagnostic phenotypes from BE pathology reports. We developed a generalizable transformer-based method to automate data extraction. Using pathology reports from Columbia University Irving Medical Center with gastroenterologist-annotated targets, we performed binary dysplasia classification as well as granularized multi-class BE-related diagnosis classification. We utilized two clinically pre-trained large language models, with best model performance comparable to a highly tailored rule-based system developed using the same data. Binary dysplasia extraction achieves 0.964 F1-score, while the multi-class model achieves 0.911 F1-score. Our method is generalizable and faster to implement as compared to a tailored rule-based approach.
    
[^20]: 从视觉问答模型中以基于语境语言学习功能词的意义

    Learning the meanings of function words from grounded language using a visual question answering model. (arXiv:2308.08628v1 [cs.CL])

    [http://arxiv.org/abs/2308.08628](http://arxiv.org/abs/2308.08628)

    本研究通过研究基于视觉问答模型学习到的功能词的意义，旨在更好地了解模型和儿童如何学习这些词汇。研究发现，在以视觉为基础的语言上训练的递归模型能够学习到需要空间和数字推理的功能词的梯度语义，并且可以在没有逻辑推理先验知识的情况下学习到"和"和"或"的意义，以及迅速发展出替换推论的能力的早期证据。

    

    解释一个看似简单的功能词，如“或者”，“在......后面”，或“更多”可能需要逻辑、数字和关系推理。儿童如何学习这样的词汇？既往的习得理论通常依赖于认为具有先天知识的基础。然而，最近基于神经网络的视觉问答模型显然可以通过使用功能词来回答关于复杂视觉场景的问题而进行学习。在本文中，我们研究了这些模型对功能词的学习，并希望更好地了解这些词汇的意义如何被模型和儿童所学习。我们展示了在以视觉为基础的语言上训练的递归模型学习了需要空间和数字推理的功能词的梯度语义。此外，我们发现这些模型可以在没有任何逻辑推理的先验知识下学习到"和"和"或"的意义，并迅速发展出进行替换推论的能力的早期证据。

    Interpreting a seemingly-simple function word like "or", "behind", or "more" can require logical, numerical, and relational reasoning. How are such words learned by children? Prior acquisition theories have often relied on positing a foundation of innate knowledge. Yet recent neural-network based visual question answering models apparently can learn to use function words as part of answering questions about complex visual scenes. In this paper, we study what these models learn about function words, in the hope of better understanding how the meanings of these words can be learnt by both models and children. We show that recurrent models trained on visually grounded language learn gradient semantics for function words requiring spacial and numerical reasoning. Furthermore, we find that these models can learn the meanings of logical connectives "and" and "or" without any prior knowledge of logical reasoning, as well as early evidence that they can develop the ability to reason about alte
    
[^21]: BIOptimus：使用课程学习为命名实体识别预训练了一种最优生物医学语言模型

    BIOptimus: Pre-training an Optimal Biomedical Language Model with Curriculum Learning for Named Entity Recognition. (arXiv:2308.08625v1 [cs.CL])

    [http://arxiv.org/abs/2308.08625](http://arxiv.org/abs/2308.08625)

    本文通过比较不同的预训练方法，提出了一种初始化权重的新方法，该方法通过从BERT模型中提取现有权重来加速预训练，以探索在生物医学领域更优的预训练方法。

    

    在大型语料库上进行自监督预训练并对下游任务进行微调已经成为处理监督学习任务（如命名实体识别）中有限标注数据问题的一种方法。最近在生物医学语言处理领域的研究中，提出了多种使用不同方法和技术进行预训练的生物医学语言模型，这些模型在许多BioNLP任务中，包括命名实体识别方面取得了进展。然而，目前还缺乏对预训练方法进行全面比较，以找到在生物医学领域更优的方法。本文旨在研究不同的预训练方法，如从头开始预训练生物医学语言模型和连续预训练生物医学语言模型。我们将现有方法与我们提出的预训练方法进行比较，该方法通过将BERT模型中的现有权重提炼到上下文中找到的新标记的权重来初始化权重。该方法有助于加快预训练速度。

    Using language models (LMs) pre-trained in a self-supervised setting on large corpora and then fine-tuning for a downstream task has helped to deal with the problem of limited label data for supervised learning tasks such as Named Entity Recognition (NER). Recent research in biomedical language processing has offered a number of biomedical LMs pre-trained using different methods and techniques that advance results on many BioNLP tasks, including NER. However, there is still a lack of a comprehensive comparison of pre-training approaches that would work more optimally in the biomedical domain. This paper aims to investigate different pre-training methods, such as pre-training the biomedical LM from scratch and pre-training it in a continued fashion. We compare existing methods with our proposed pre-training method of initializing weights for new tokens by distilling existing weights from the BERT model inside the context where the tokens were found. The method helps to speed up the pre-
    
[^22]: 通过新的框架——思维图，提升大型语言模型的逻辑推理能力

    Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought. (arXiv:2308.08614v1 [cs.LG])

    [http://arxiv.org/abs/2308.08614](http://arxiv.org/abs/2308.08614)

    本文提出了一种新的提示技术——思维图（GoT），通过在三个不断升级的挑战中的测试，我们的方法在多步逻辑推理问题上表现优于GPT-4，并且相比最先进的提示方法思维树（ToT），我们的方法有更高的准确性提升。

    

    近期大规模模型（如GPT-4）的进展展示了在解决标准查询方面的卓越能力。然而，面对需要多步逻辑推理的复杂问题时，它们的准确性急剧下降。当前的研究已经探索了提示工程领域，以增强这些模型的推理能力。本文提出了一种创新的提示技术，称为“思维图（GoT）”。通过在三个不断升级的挑战上进行测试：24点游戏，高阶多项式方程的解析，以及递归数列的公式推导，我们的方法优于GPT-4，在每个任务中实现了$89.7\%$、$86\%$和$56\%$的准确性改进。此外，与最先进的提示方法“思维树（ToT）”相比，我们的方法平均准确性提升了$23\%$、$24\%$和$15\%$。

    Recent advancements in large-scale models, such as GPT-4, have showcased remarkable capabilities in addressing standard queries. However, when facing complex problems that require multi-step logical reasoning, their accuracy dramatically decreases. Current research has explored the realm of \textit{prompting engineering} to bolster the inferential capacities of these models. Our paper unveils a pioneering prompting technique, dubbed \textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating challenges: the 24-point game, resolution of high-degree polynomial equations, and derivation of formulas for recursive sequences, our method outperformed GPT-4, achieving accuracy improvements of $89.7\%$, $86\%$, and $56\%$ for each respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA) prompting method, \textit{Tree of Thought (ToT)}, our approach registered an average accuracy boost of $23\%$, $24\%$, and $15\%$.
    
[^23]: FootGPT：在最小设置上进行的大规模语言模型开发实验

    FootGPT : A Large Language Model Development Experiment on a Minimal Setting. (arXiv:2308.08610v1 [cs.CL])

    [http://arxiv.org/abs/2308.08610](http://arxiv.org/abs/2308.08610)

    本文介绍了一个在最小设置上进行的大规模语言模型开发实验，研究发现准确的语言模型的关键在于适当的数据集内容和训练策略，而不是神经参数数量、训练时长或数据集大小。通过对一个10亿参数规模的通用因果语言模型进行微调，并使用商业语言模型提供的精简段落和问答对构建数据集，可以有效解释足球数据。

    

    最近的实证观察表明，相比于神经参数数量、训练时长或数据集大小，开发准确的语言模型的最重要方面可能是适当的数据集内容和训练策略。基于这个观点，我们选择使用低秩适应性对一个10亿参数规模的通用因果语言模型进行微调，数据集由意大利足球联赛前十轮的球队统计信息构建，并使用强大的商业语言模型提供的精简段落和问答对。我们将训练时长保持相对较短，以提供我们最小设置探索的基础。在本文中，我们分享了与使用有限资源解释足球数据的特定目的语言模型开发相关的关键观察结果。

    With recent empirical observations, it has been argued that the most significant aspect of developing accurate language models may be the proper dataset content and training strategy compared to the number of neural parameters, training duration or dataset size. Following this argument, we opted to fine tune a one billion parameter size trained general purpose causal language model with a dataset curated on team statistics of the Italian football league first ten game weeks, using low rank adaptation. The limited training dataset was compiled based on a framework where a powerful commercial large language model provides distilled paragraphs and question answer pairs as intended. The training duration was kept relatively short to provide a basis for our minimal setting exploration. We share our key observations on the process related to developing a specific purpose language model which is intended to interpret soccer data with constrained resources in this article.
    
[^24]: AffectEcho：针对语音合成的无关说话人和无关语言的情感和情感传递模型

    AffectEcho: Speaker Independent and Language-Agnostic Emotion and Affect Transfer for Speech Synthesis. (arXiv:2308.08577v1 [cs.SD])

    [http://arxiv.org/abs/2308.08577](http://arxiv.org/abs/2308.08577)

    AffectEcho是一种无关说话人和无关语言的情感和情感传递模型，通过使用向量量化码书来建模情感，并在五个级别的情感强度上捕捉细微差别，从而成功地控制生成的语音的情感，同时保持每个说话人独特的身份、风格和情感节奏。

    

    情感是一种包括价值、唤醒度和强度的情绪特征，对于实现真实对话至关重要。现有的文本到语音(TTS)和语音到语音系统依赖于强度嵌入向量和全局风格标记来捕捉情感，这些模型将情感表示为风格的组成部分或以离散的类别表示。我们提出了一种情感转换模型AffectEcho，它使用了一个向量量化码书来在量化空间中对情感进行建模，该空间具有五个级别的情感强度，以捕捉同一情感中的复杂细微差别。这些量化的情感嵌入是从口语语音样本中隐含地派生出来的，消除了独热向量或显式强度嵌入的需要。实验结果表明，我们的方法在控制生成的语音情感的同时保持了每个说话人独特的身份、风格和情感节奏的有效性。

    Affect is an emotional characteristic encompassing valence, arousal, and intensity, and is a crucial attribute for enabling authentic conversations. While existing text-to-speech (TTS) and speech-to-speech systems rely on strength embedding vectors and global style tokens to capture emotions, these models represent emotions as a component of style or represent them in discrete categories. We propose AffectEcho, an emotion translation model, that uses a Vector Quantized codebook to model emotions within a quantized space featuring five levels of affect intensity to capture complex nuances and subtle differences in the same emotion. The quantized emotional embeddings are implicitly derived from spoken speech samples, eliminating the need for one-hot vectors or explicit strength embeddings. Experimental results demonstrate the effectiveness of our approach in controlling the emotions of generated speech while preserving identity, style, and emotional cadence unique to each speaker. We sho
    
[^25]: 在大型语言模型中使用反向推理进行验证

    Backward Reasoning in Large Language Models for Verification. (arXiv:2308.07758v1 [cs.CL])

    [http://arxiv.org/abs/2308.07758](http://arxiv.org/abs/2308.07758)

    本文研究了在大型语言模型中使用反向推理进行验证的方法。作者提出了一种新颖的技术，通过屏蔽问题中的一个标记，并要求语言模型预测被屏蔽的标记来验证候选答案。同时，作者还提出了一种结合正向和反向推理的方法来估计候选答案的概率。

    

    链式思考（Chain-of-Though, CoT）提示在各种推理任务中表现出了很好的性能。最近，Self-Consistency提出了一种方法，即通过采样一组不同的推理链，这些链可能导致不同的答案，然后选择得票最多的答案。本文提出了一种新颖的方法，即在验证候选答案时使用反向推理。我们使用一个简单的模板，即``如果我们知道上述问题的答案是候选答案，那么未知变量x的值是多少？''，将问题中的一个标记屏蔽，并要求语言模型预测被屏蔽的标记。直观上讲，如果提供的候选答案是正确的，语言模型应该能够成功预测被屏蔽的标记。我们进一步提出了FOBAR方法，将正向和反向推理结合起来估计候选答案的概率。我们在六个数据集和三个实验中进行了广泛的实验。

    Chain-of-Though (CoT) prompting has shown promising performance in various reasoning tasks. Recently, Self-Consistency \citep{wang2023selfconsistency} proposes to sample a diverse set of reasoning chains which may lead to different answers while the answer that receives the most votes is selected. In this paper, we propose a novel method to use backward reasoning in verifying candidate answers. We mask a token in the question by ${\bf x}$ and ask the LLM to predict the masked token when a candidate answer is provided by \textit{a simple template}, i.e., ``\textit{\textbf{If we know the answer of the above question is \{a candidate answer\}, what is the value of unknown variable ${\bf x}$?}}'' Intuitively, the LLM is expected to predict the masked token successfully if the provided candidate answer is correct. We further propose FOBAR to combine forward and backward reasoning for estimating the probability of candidate answers. We conduct extensive experiments on six data sets and three
    
[^26]: 引导语言生成：利用对比专家指导和负面提示进行一致性和多样性的合成数据生成

    Steering Language Generation: Harnessing Contrastive Expert Guidance and Negative Prompting for Coherent and Diverse Synthetic Data Generation. (arXiv:2308.07645v1 [cs.CL])

    [http://arxiv.org/abs/2308.07645](http://arxiv.org/abs/2308.07645)

    该论文提出了一种引导语言生成的方法，通过对比专家指导和负面提示，实现了连贯和多样性的合成数据生成。该方法在推理时间内操作，利用对比形式指导LLMs在数据分布的一致性和与先前示例的偏离之间取得平衡。

    

    大型语言模型（LLMs）具有生成高质量和实用的合成数据的巨大潜力，这在从下游模型训练到实际数据利用的各种应用中都有很多。然而，尽管现代模型的能力令人印象深刻，却经常难以产生既连贯又多样化的数据。为了解决连贯性问题，我们引入了对比形式专家指导，强调了精细调整和基本语言模型之间的逻辑分布差异，以确保领域的一致性。为了保证多样性，我们利用现有的真实和合成的例子作为模型的负面提示。我们将这种对逻辑重塑的双重方法称为STEER：通过嵌入重新定位实现的语义文本增强。STEER在推理时间内运行，并系统地指导LLMs在数据分布的一致性（确保语义保真度）与先前合成示例或现有真实数据之间取得平衡。

    Large Language Models (LLMs) hold immense potential to generate synthetic data of high quality and utility, which has numerous applications from downstream model training to practical data utilisation. However, contemporary models, despite their impressive capacities, consistently struggle to produce both coherent and diverse data. To address the coherency issue, we introduce contrastive expert guidance, where the difference between the logit distributions of fine-tuned and base language models is emphasised to ensure domain adherence. In order to ensure diversity, we utilise existing real and synthetic examples as negative prompts to the model. We deem this dual-pronged approach to logit reshaping as STEER: Semantic Text Enhancement via Embedding Repositioning. STEER operates at inference-time and systematically guides the LLMs to strike a balance between adherence to the data distribution (ensuring semantic fidelity) and deviation from prior synthetic examples or existing real datase
    
[^27]: 关于大型语言模型的模型压缩综述

    A Survey on Model Compression for Large Language Models. (arXiv:2308.07633v1 [cs.CL])

    [http://arxiv.org/abs/2308.07633](http://arxiv.org/abs/2308.07633)

    本论文提供了关于大型语言模型的模型压缩综述，探讨了量化、修剪、知识蒸馏等不同方法，并突出介绍了最新进展和创新方法，为实现高效的部署提供了重要思路。

    

    大型语言模型（LLMs）以惊人的成功彻底改变了自然语言处理任务。然而，它们庞大的体量和计算需求在资源受限环境下的实际部署中带来了重大挑战。随着这些挑战日益紧迫，模型压缩领域已成为一个关键的研究领域，旨在缓解这些限制。本文提供了一份全面的综述，探讨专门针对LLMs的模型压缩技术。我们深入研究了各种方法，包括量化、修剪、知识蒸馏等，以应对高效部署的迫切需求。在每种技术中，我们重点介绍了最新进展和创新方法，为LLM研究的发展提供了贡献。此外，我们还探讨了用于评估效果的基准策略和评估指标的重要性。

    Large Language Models (LLMs) have revolutionized natural language processing tasks with remarkable success. However, their formidable size and computational demands present significant challenges for practical deployment, especially in resource-constrained environments. As these challenges become increasingly pertinent, the field of model compression has emerged as a pivotal research area to alleviate these limitations. This paper presents a comprehensive survey that navigates the landscape of model compression techniques tailored specifically for LLMs. Addressing the imperative need for efficient deployment, we delve into various methodologies, encompassing quantization, pruning, knowledge distillation, and more. Within each of these techniques, we highlight recent advancements and innovative approaches that contribute to the evolving landscape of LLM research. Furthermore, we explore benchmarking strategies and evaluation metrics that are essential for assessing the effectiveness of 
    
[^28]: 知识图谱能简化文本吗？

    Can Knowledge Graphs Simplify Text?. (arXiv:2308.06975v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.06975](http://arxiv.org/abs/2308.06975)

    提出了一种KGSimple方法，将知识图谱技术应用于无监督文本简化，实现从知识图谱开始生成简明文本，保留重要信息并输出流畅且描述性的句子。

    

    知识图谱到文本生成在生成流畅且信息丰富的句子方面有了最新的改进，这些句子描述了给定的知识图谱。由于知识图谱在多个领域广泛存在且包含重要的实体关系信息，并且文本简化旨在减少文本的复杂性同时保留原始文本的意思，我们提出了KGSimple，一种新颖的无监督文本简化方法，它融入了知识图谱技术来构建简化的知识图谱路径，并生成保留原始输入意义的简明文本。通过迭代和采样的以知识图谱为基础的方法，我们的模型能够从知识图谱开始简化文本，通过学习保留重要信息并利用知识图谱到文本生成输出流畅且描述性的句子。我们在目前可用的知识图谱到文本数据集上评估了KGSimple模型的各种设置，证明了其相对于无监督文本简化的有效性。

    Knowledge Graph (KG)-to-Text Generation has seen recent improvements in generating fluent and informative sentences which describe a given KG. As KGs are widespread across multiple domains and contain important entity-relation information, and as text simplification aims to reduce the complexity of a text while preserving the meaning of the original text, we propose KGSimple, a novel approach to unsupervised text simplification which infuses KG-established techniques in order to construct a simplified KG path and generate a concise text which preserves the original input's meaning. Through an iterative and sampling KG-first approach, our model is capable of simplifying text when starting from a KG by learning to keep important information while harnessing KG-to-text generation to output fluent and descriptive sentences. We evaluate various settings of the KGSimple model on currently-available KG-to-text datasets, demonstrating its effectiveness compared to unsupervised text simplificat
    
[^29]: 元认知提示改善大型语言模型的理解能力

    Metacognitive Prompting Improves Understanding in Large Language Models. (arXiv:2308.05342v1 [cs.CL])

    [http://arxiv.org/abs/2308.05342](http://arxiv.org/abs/2308.05342)

    元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。

    

    在大型语言模型 (LLMs) 中，通过有效的提示设计，任务特定性能一直在不断提高。尽管最近关于提示的研究增强了LLMs的推理能力，但在进一步提高它们的理解能力方面仍存在差距。在本研究中，我们介绍了元认知提示 (MP)，这是一种受人类内省推理过程启发的策略。使用MP，LLMs经历一系列有结构、自我意识的评估，利用其丰富的内在知识和新的见解。我们的实验涉及五个常见的LLMs：Llama2、Vicuna、PaLM、GPT-3.5和GPT-4，它们都涵盖了来自GLUE和SuperGLUE基准测试的各种通用自然语言理解 (NLU) 任务。结果表明，虽然GPT-4在大多数任务中始终表现出色，但配备MP的PaLM接近其性能水平。此外，跨模型和数据集，MP始终优于现有的提示方法。

    In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. While recent research on prompting has enhanced the reasoning capabilities of LLMs, a gap remains in further improving their understanding abilities. In this study, we introduce metacognitive prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. Our experiments involve five prevalent LLMs: Llama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various general natural language understanding (NLU) tasks from the GLUE and SuperGLUE benchmarks. Results indicate that, although GPT-4 consistently excels in most tasks, PaLM, when equipped with MP, approaches its performance level. Furthermore, across models and datasets, MP consistently outperforms existing prompting meth
    
[^30]: WIKITIDE: 一个基于维基百科时间戳定义对数据集的研究

    WIKITIDE: A Wikipedia-Based Timestamped Definition Pairs Dataset. (arXiv:2308.03582v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03582](http://arxiv.org/abs/2308.03582)

    本文提出了WikiTiDe，这是一个从维基百科中提取的时间戳定义对数据集，该数据集可用于加速历时性自然语言处理，并训练模型以扫描核心更新。通过自举种子版本，可以获得更好的微调模型。

    

    目前自然语言处理领域的一个基本挑战是，由语言模型主导的情况下，现有体系架构对于学习新信息的灵活度不够。虽然存在基于模型的解决方案，如连续学习或参数高效微调，但仍然存在如何可靠地识别语言或世界变化的问题。本文提出了WikiTiDe，这是一个从维基百科中提取的时间戳定义对数据集。我们认为这样的资源有助于加速历时性自然语言处理，并用于训练模型，使其能够从知识资源中扫描与概念、事件或命名实体相关的核心更新。我们提出的端到端方法是完全自动的，并利用自举算法逐步创建高质量的数据集。我们的研究结果表明，通过自举WikiTiDe的种子版本可以获得更好的微调模型。我们还在许多下游任务中应用了微调模型。

    A fundamental challenge in the current NLP context, dominated by language models, comes from the inflexibility of current architectures to 'learn' new information. While model-centric solutions like continual learning or parameter-efficient fine tuning are available, the question still remains of how to reliably identify changes in language or in the world. In this paper, we propose WikiTiDe, a dataset derived from pairs of timestamped definitions extracted from Wikipedia. We argue that such resource can be helpful for accelerating diachronic NLP, specifically, for training models able to scan knowledge resources for core updates concerning a concept, an event, or a named entity. Our proposed end-to-end method is fully automatic, and leverages a bootstrapping algorithm for gradually creating a high-quality dataset. Our results suggest that bootstrapping the seed version of WikiTiDe leads to better fine-tuned models. We also leverage fine-tuned models in a number of downstream tasks, sh
    
[^31]: 用火攻火：ChatGPT能够检测AI生成的文本吗？

    Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?. (arXiv:2308.01284v1 [cs.CL])

    [http://arxiv.org/abs/2308.01284](http://arxiv.org/abs/2308.01284)

    ChatGPT作为检测器能否有效检测AI生成的文本，我们通过评估其在人工编写文本与AI生成文本之间的区分能力，并在公开数据集上进行实验，得出了关于ChatGPT在自动化检测流程中的应用指导。

    

    越来越多的大型语言模型（如ChatGPT）被用于各种用例，包括规模化的文本内容生成。虽然已经存在针对这种AI生成文本的检测方法，但我们研究了ChatGPT在这种AI生成文本上的检测性能，受到将ChatGPT用作数据标注器或注释器的研究启发。我们评估了ChatGPT在人工编写文本与AI生成文本检测任务中的零-shot性能，并在公开可用的数据集上进行实验。我们通过实证研究了ChatGPT在检测AI生成文本或人工编写文本方面是否具有对称效应。我们的发现揭示了通过简单关注问题的特定方面并从该解决方案中推导出其余部分，如何利用ChatGPT和类似的大型语言模型在自动化检测流程中发挥作用。所有代码和数据可在 \url{https://github.com/AmritaBh/ChatGPT-as-Detector} 上获得。

    Large language models (LLMs) such as ChatGPT are increasingly being used for various use cases, including text content generation at scale. Although detection methods for such AI-generated text exist already, we investigate ChatGPT's performance as a detector on such AI-generated text, inspired by works that use ChatGPT as a data labeler or annotator. We evaluate the zero-shot performance of ChatGPT in the task of human-written vs. AI-generated text detection, and perform experiments on publicly available datasets. We empirically investigate if ChatGPT is symmetrically effective in detecting AI-generated or human-written text. Our findings provide insight on how ChatGPT and similar LLMs may be leveraged in automated detection pipelines by simply focusing on solving a specific aspect of the problem and deriving the rest from that solution. All code and data is available at \url{https://github.com/AmritaBh/ChatGPT-as-Detector}.
    
[^32]: 使用大型语言模型进行渗透测试：AI作为辅助

    Getting pwn'd by AI: Penetration Testing with Large Language Models. (arXiv:2308.00121v1 [cs.CL])

    [http://arxiv.org/abs/2308.00121](http://arxiv.org/abs/2308.00121)

    本文探讨了使用大型语言模型（如GPT3.5）作为AI助手来增强渗透测试人员的能力，实现了高级任务规划和低级漏洞寻找两种用例，取得了有前景的初步结果，并就提供该技术的伦理问题进行了讨论。

    

    软件安全测试领域，尤其是渗透测试是一项需要高水平专业知识的活动，并涉及许多手动测试和分析步骤。本文探讨了使用大型语言模型（如GPT3.5）来增强渗透测试人员的能力。我们研究了两种不同的用例：用于安全测试任务的高级任务规划和在易受攻击的虚拟机中进行低级漏洞寻找。对于后者，我们实现了一个闭环反馈，将由语言模型生成的低级操作与易受攻击的虚拟机（通过SSH连接）相连，并允许语言模型分析虚拟机状态以寻找漏洞，并提供具体的攻击向量。我们讨论了有前景的初步结果，详细介绍了改进的途径，并就提供该技术的伦理问题进行了讨论。

    The field of software security testing, more specifically penetration testing, is an activity that requires high levels of expertise and involves many manual testing and analysis steps. This paper explores the potential usage of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners. We explore the feasibility of supplementing penetration testers with AI models for two distinct use cases: high-level task planning for security testing assignments and low-level vulnerability hunting within a vulnerable virtual machine. For the latter, we implemented a closed-feedback loop between LLM-generated low-level actions with a vulnerable virtual machine (connected through SSH) and allowed the LLM to analyze the machine state for vulnerabilities and suggest concrete attack vectors which were automatically executed within the virtual machine. We discuss promising initial results, detail avenues for improvement, and close deliberating on the ethics of providi
    
[^33]: GrammarGPT: 使用有监督微调的开源LLM探索母语汉语语法错误修正

    GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning. (arXiv:2307.13923v1 [cs.CL])

    [http://arxiv.org/abs/2307.13923](http://arxiv.org/abs/2307.13923)

    本文介绍了GrammarGPT，一个开源LLM用于母语汉语语法错误修正，通过混合数据集和启发式方法，提高了模型的修正能力。

    

    语法错误修正旨在自动修正不符合语法的句子。最近的一些研究表明，闭源大型语言模型（LLM，例如ChatGPT）在语法错误修正方面具有出色的能力。然而，开源LLM的潜力仍未被探索。本文介绍了一个名为GrammarGPT的开源LLM，旨在初步探索其在母语汉语语法错误修正方面的潜力。GrammarGPT的核心方法是利用ChatGPT生成的数据和人工标注的混合数据集。对于带有提示信息的语法错误，我们提出了一种启发式方法来指导ChatGPT通过提供这些提示信息生成不符合语法的句子。对于没有提示信息的语法错误，我们从公开可用的网站收集了不符合语法的句子，并进行手动修正。此外，我们还采用了一种错误不变增强方法，以增强该模型纠正母语汉语语法错误的能力。

    Grammatical error correction aims to correct ungrammatical sentences automatically. Recently, some work has demonstrated the excellent capabilities of closed-source Large Language Models (LLMs, e.g., ChatGPT) in grammatical error correction. However, the potential of open-source LLMs remains unexplored. In this paper, we introduced GrammarGPT, an open-source LLM, to preliminary explore its potential for native Chinese grammatical error correction. The core recipe of GrammarGPT is to leverage the hybrid dataset of ChatGPT-generated and human-annotated. For grammatical errors with clues, we proposed a heuristic method to guide ChatGPT to generate ungrammatical sentences by providing those clues. For grammatical errors without clues, we collected ungrammatical sentences from publicly available websites and manually corrected them. In addition, we employed an error-invariant augmentation method to enhance the ability of the model to correct native Chinese grammatical errors. We ultimately 
    
[^34]: 基于梯度的词替换用于生成语言模型中顽固对抗样本

    Gradient-Based Word Substitution for Obstinate Adversarial Examples Generation in Language Models. (arXiv:2307.12507v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12507](http://arxiv.org/abs/2307.12507)

    本文介绍了一种名为GradObstinate的基于梯度的方法，用于生成顽固对抗样本。该方法可以自动生成意义改变但模型预测结果保持不变的对抗样本，无需人工设计约束。

    

    本文研究了在自然语言处理中通过词替换生成顽固（超稳定性）对抗样本的问题，在这种情况下，输入文本的意义发生了改变，但模型的预测却没有变化，尽管应该发生变化。以往的词替换方法主要集中在手动设计的反义词策略上，用于生成顽固对抗样本，这制约了它的应用，因为这些策略只能找到部分顽固对抗样本，并且需要人工努力。为了解决这个问题，本文介绍了一种新的词替换方法，名为GradObstinate，它是一种基于梯度的方法，可以自动生成顽固对抗样本，不受搜索空间限制或需求人工设计原则的约束。为了经验性地评估GradObstinate的效果，我们在与自然语言处理基准模型（Electra、ALBERT、Roberta、DistillBERT和CLIP）上进行了全面的实验。

    In this paper, we study the problem of generating obstinate (over-stability) adversarial examples by word substitution in NLP, where input text is meaningfully changed but the model's prediction does not, even though it should. Previous word substitution approaches have predominantly focused on manually designed antonym-based strategies for generating obstinate adversarial examples, which hinders its application as these strategies can only find a subset of obstinate adversarial examples and require human efforts. To address this issue, in this paper, we introduce a novel word substitution method named GradObstinate, a gradient-based approach that automatically generates obstinate adversarial examples without any constraints on the search space or the need for manual design principles. To empirically evaluate the efficacy of GradObstinate, we conduct comprehensive experiments on five representative models (Electra, ALBERT, Roberta, DistillBERT, and CLIP) finetuned on four NLP benchmark
    
[^35]: 潜在越狱：评估大型语言模型的文本安全性和输出鲁棒性的测试套件

    Latent Jailbreak: A Test Suite for Evaluating Both Text Safety and Output Robustness of Large Language Models. (arXiv:2307.08487v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08487](http://arxiv.org/abs/2307.08487)

    这篇论文提出了一个评估大型语言模型安全性和鲁棒性的基准测试套件，强调了平衡的方法。通过引入含有恶意指令的潜在越狱提示数据集，并设计分层注释框架，全面研究了文本安全性和输出鲁棒性。

    

    已经有大量的研究致力于确保大型语言模型（LLMs）与人类价值观相一致并生成安全文本。然而，对某些主题的过度关注可能会损害模型在遵循指令方面的鲁棒性，从而影响其在完成任务方面的整体表现。以往用于越狱LLMs的基准主要关注评估模型的安全性，而没有考虑其鲁棒性。在本文中，我们提出了一个评估LLMs安全性和鲁棒性的基准，强调需要一个平衡的方法。为了全面研究文本安全性和输出鲁棒性，我们引入了一个潜在越狱提示数据集，每个数据集中都包含恶意指令嵌入。具体而言，我们指导模型完成常规任务，例如翻译，其中待翻译的文本包含恶意指令。为了进一步分析安全性和鲁棒性，我们设计了一个分层注释框架。

    Considerable research efforts have been devoted to ensuring that large language models (LLMs) align with human values and generate safe text. However, an excessive focus on sensitivity to certain topics can compromise the model's robustness in following instructions, thereby impacting its overall performance in completing tasks. Previous benchmarks for jailbreaking LLMs have primarily focused on evaluating the safety of the models without considering their robustness. In this paper, we propose a benchmark that assesses both the safety and robustness of LLMs, emphasizing the need for a balanced approach. To comprehensively study text safety and output robustness, we introduce a latent jailbreak prompt dataset, each involving malicious instruction embedding. Specifically, we instruct the model to complete a regular task, such as translation, with the text to be translated containing malicious instructions. To further analyze safety and robustness, we design a hierarchical annotation fram
    
[^36]: 大语言模型的综合概述

    A Comprehensive Overview of Large Language Models. (arXiv:2307.06435v1 [cs.CL])

    [http://arxiv.org/abs/2307.06435](http://arxiv.org/abs/2307.06435)

    大语言模型的综合概述，分析了各种新的架构和训练策略，讨论了LLM的特点和功能，并总结了重要的研究发现和关键的架构和训练策略。

    

    大语言模型（LLM）展示了出色的泛化能力，导致了众多模型的发展。这些模型提出了各种新的架构，通过改进的训练策略来调整现有的架构，增加上下文长度，使用高质量的训练数据，并增加训练时间以超越基线。分析新的发展对于识别增强训练稳定性和改进LLM泛化能力的变化至关重要。本综述论文全面分析了LLM的架构及其分类、训练策略、训练数据集和性能评估，并讨论未来的研究方向。此外，本文还讨论了LLM的基本构建块和概念，并提供了LLM的完整概述，包括其重要特点和功能。最后，本文总结了LLM研究的重要发现，并整合了关键的架构和训练策略。

    Large Language Models (LLMs) have shown excellent generalization capabilities that have led to the development of numerous models. These models propose various new architectures, tweaking existing architectures with refined training strategies, increasing context length, using high-quality training data, and increasing training time to outperform baselines. Analyzing new developments is crucial for identifying changes that enhance training stability and improve generalization in LLMs. This survey paper comprehensively analyses the LLMs architectures and their categorization, training strategies, training datasets, and performance evaluations and discusses future research directions. Moreover, the paper also discusses the basic building blocks and concepts behind LLMs, followed by a complete overview of LLMs, including their important features and functions. Finally, the paper summarizes significant findings from LLM research and consolidates essential architectural and training strateg
    
[^37]: 视觉对抗样本越狱大语言模型的安全隐患分析

    Visual Adversarial Examples Jailbreak Large Language Models. (arXiv:2306.13213v1 [cs.CR])

    [http://arxiv.org/abs/2306.13213](http://arxiv.org/abs/2306.13213)

    本文对将图像引入大型语言模型的安全隐患进行了分析，指出视觉输入空间的连续性和高维性是对抗攻击的丰富领域，同时也为视觉攻击者提供了更广泛的实现对抗目标的可能性。

    

    最近，将图像引入大型语言模型（LLMs）已经引起了人们的高度关注。大型视觉语言模型（VLMs）的普及，例如Flamingo、BLIP-2和GPT-4，标志着视觉和语言基础模型的先进发展相互融合的重要进展。然而，这种综合方法涉及的风险仍未得到详细研究。本文揭示了这一趋势的安全隐患。我们首先指出，视觉输入空间的连续性和高维性在本质上使其成为对抗攻击的丰富领域，这不可避免地扩大了LLMs的攻击面。其次，我们强调，LLMs的广泛功能也为视觉攻击者提供了更广泛的实现对抗目标的可能性，将安全失败的影响扩展到了简单的错误分类之外。为了阐明这些风险，我们研究了VLM视觉输入空间中的对抗性样例。

    Recently, there has been a surge of interest in introducing vision into Large Language Models (LLMs). The proliferation of large Visual Language Models (VLMs), such as Flamingo, BLIP-2, and GPT-4, signifies an exciting convergence of advancements in both visual and language foundation models. Yet, the risks associated with this integrative approach are largely unexamined. In this paper, we shed light on the security and safety implications of this trend. First, we underscore that the continuous and high-dimensional nature of the additional visual input space intrinsically makes it a fertile ground for adversarial attacks. This unavoidably expands the attack surfaces of LLMs. Second, we highlight that the broad functionality of LLMs also presents visual attackers with a wider array of achievable adversarial objectives, extending the implications of security failures beyond mere misclassification. To elucidate these risks, we study adversarial examples in the visual input space of a VLM.
    
[^38]: 生成式多模态实体链接

    Generative Multimodal Entity Linking. (arXiv:2306.12725v1 [cs.CL])

    [http://arxiv.org/abs/2306.12725](http://arxiv.org/abs/2306.12725)

    本文提出了 GEMEL 方法，使用大规模预训练的 LLMs 直接生成目标实体名称，仅调整了极少的模型参数即可实现最先进的 MEL 实验结果。

    

    多模态实体链接是将带有多模态上下文的提及映射到知识库（例如维基百科）中的引用实体的任务。本文提出了一种名为 GEMEL 的简单而有效的生成式多模态实体链接方法，利用大规模预训练的 LLMs 直接生成目标实体名称。我们保持视觉和语言模型冻结，只训练一个线性层以启用跨模态交互。为了将 LLMs 适应 MEL 任务，我们利用 LLMs 的新兴上下文学习能力，通过检索多模态实例作为示范来进行。大量实验表明，仅调整了大约0.3％的模型参数，GEMEL 就实现了最先进的结果。

    Multimodal Entity Linking (MEL) is the task of mapping mentions with multimodal contexts to the referent entities from a knowledge base (e.g., Wikipedia). Prior MEL methods mainly focus on designing complex multimodal interaction mechanisms and require fine-tuning all model parameters, which can be prohibitively costly and difficult to scale in the era of Large Language Models (LLMs). In this work, we propose GEMEL, a simple yet effective Generative Multimodal Entity Linking method, which leverages the capabilities of LLMs from large-scale pre-training to directly generate target entity names. We keep the vision and language model frozen and only train a linear layer to enable cross-modality interactions. To adapt LLMs to the MEL task, we take advantage of the emerging in-context learning (ICL) capability of LLMs by retrieving multimodal instances as demonstrations. Extensive experiments show that with only ~0.3% of the model parameters fine-tuned, GEMEL achieves state-of-the-art resul
    
[^39]: mBERT是否理解罗曼什语？使用词语对齐评估词嵌入

    Does mBERT understand Romansh? Evaluating word embeddings using word alignment. (arXiv:2306.08702v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.08702](http://arxiv.org/abs/2306.08702)

    本研究通过在德语和罗曼什语的平行句子中使用mBERT和XLM-R的词嵌入，结合相似性对齐模型，评估了mBERT对罗曼什语的理解能力。结果显示mBERT的词嵌入能够有效地对罗曼什语进行词语对齐，为进一步研究提供了有意义和适用的信息。

    

    我们在德语和罗曼什语之间的平行句子中，使用mBERT和XLM-R的词嵌入，结合基于相似性的词语对齐模型（SimAlign和awesome-align）进行测试。由于罗曼什语是一种未知语言，我们处于零样本的情况。使用mBERT的词嵌入，两个模型的对齐错误率为0.22，优于统计模型fast_align，并且与对于已知语言的基于相似性的词语对齐相当。我们将这些结果解释为mBERT包含了对罗曼什语有意义和适用的信息的证据。

    We test similarity-based word alignment models (SimAlign and awesome-align) in combination with word embeddings from mBERT and XLM-R on parallel sentences in German and Romansh. Since Romansh is an unseen language, we are dealing with a zero-shot setting. Using embeddings from mBERT, both models reach an alignment error rate of 0.22, which outperforms fast_align, a statistical model, and is on par with similarity-based word alignment for seen languages. We interpret these results as evidence that mBERT contains information that can be meaningful and applicable to Romansh.  To evaluate performance, we also present a new trilingual corpus, which we call the DERMIT (DE-RM-IT) corpus, containing press releases made by the Canton of Grisons in German, Romansh and Italian in the past 25 years. The corpus contains 4 547 parallel documents and approximately 100 000 sentence pairs in each language combination. We additionally present a gold standard for German-Romansh word alignment. The data i
    
[^40]: 语言模型中出现的类人直觉行为和推理偏差——以及在GPT-4中消失。

    Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4. (arXiv:2306.07622v1 [cs.CL])

    [http://arxiv.org/abs/2306.07622](http://arxiv.org/abs/2306.07622)

    本研究揭示了大型语言模型（LLMs）具有类人直觉行为和认知错误的特点，而高级语言模型则通过学习避免这类错误并表现出超理性的方式。此外，通过使用心理学研究的方法探测LLMs，可以揭示其新生特性。

    

    大型语言模型（LLM）目前处于将AI系统与人类交流和日常生活交织在一起的前沿。因此，评估它们的新兴能力非常重要。在这项研究中，我们展示了LLM（尤其是GPT-3）表现出惊人的类人直觉行为，以及遵循这种行为而来的认知错误。然而，具有更高认知能力的LLM，特别是ChatGPT和GPT-4，学会了避免屈服于这些错误并表现出超理性的方式。对于我们的实验，我们利用了Cognitive Reflection Test（CRT）及用于研究人类直觉决策的语义幻觉。此外，我们还探究了类人直觉决策的稳定倾向。我们的研究表明，通过心理学方法调查LLM有潜力揭示否则未知的新生特性。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Therefore, it is of great importance to evaluate their emerging abilities. In this study, we show that LLMs, most notably GPT-3, exhibit behavior that strikingly resembles human-like intuition -- and the cognitive errors that come with it. However, LLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4, learned to avoid succumbing to these errors and perform in a hyperrational manner. For our experiments, we probe LLMs with the Cognitive Reflection Test (CRT) as well as semantic illusions that were originally designed to investigate intuitive decision-making in humans. Moreover, we probe how sturdy the inclination for intuitive-like decision-making is. Our study demonstrates that investigating LLMs with methods from psychology has the potential to reveal otherwise unknown emergent traits.
    
[^41]: 能ChatGPT检测出意图吗？评估用于口语理解的大型语言模型。

    Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding. (arXiv:2305.13512v1 [cs.CL])

    [http://arxiv.org/abs/2305.13512](http://arxiv.org/abs/2305.13512)

    本文评估了几个大型预训练语言模型在口语理解任务中的表现，发现最大模型可以在零-shot学习和上下文学习中达到与监督模型相近的意图分类准确度，但在槽填充方面表现不佳，且对ASR错误敏感。

    

    最近，大型预训练语言模型展示了强大的语言理解能力，特别体现在通过提示在下游任务中的零-shot和上下文学习能力。为了评估它们对口语理解（SLU）的影响，我们评估了几个不同大小的ChatGPT和OPT模型在多个基准测试中的表现。我们验证了最大模型特有的新兴能力，即在给定Oracle转录的各种语言上，其可以接近于监督模型的意图分类准确度。相比之下，适合单个GPU的较小模型的结果远远落后。我们注意到错误案例通常来自数据集的注释方案；ChatGPT的响应仍然是合理的。但是我们发现，该模型在槽填充方面表现不佳，而且对ASR错误非常敏感，因此表明了将这些文本模型应用于口语理解的严峻挑战。

    Recently, large pretrained language models have demonstrated strong language understanding capabilities. This is particularly reflected in their zero-shot and in-context learning abilities on downstream tasks through prompting. To assess their impact on spoken language understanding (SLU), we evaluate several such models like ChatGPT and OPT of different sizes on multiple benchmarks. We verify the emergent ability unique to the largest models as they can reach intent classification accuracy close to that of supervised models with zero or few shots on various languages given oracle transcripts. By contrast, the results for smaller models fitting a single GPU fall far behind. We note that the error cases often arise from the annotation scheme of the dataset; responses from ChatGPT are still reasonable. We show, however, that the model is worse at slot filling, and its performance is sensitive to ASR errors, suggesting serious challenges for the application of those textual models on SLU.
    
[^42]: 临床骆驼：一种具有基于对话的知识编码的开源专家级医学语言模型

    Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding. (arXiv:2305.12031v1 [cs.CL])

    [http://arxiv.org/abs/2305.12031](http://arxiv.org/abs/2305.12031)

    临床骆驼是一种基于对话的知识编码的开源医学语言模型，具有很高的可解释性和临床相关性，并在多个基准数据集上取得了最先进的结果。

    

    大型语言模型（LLM）在医疗领域具有巨大潜力，但数据隐私、监管合规性和模型稳定性等问题限制了它们的广泛应用。为了应对这些挑战，我们提出了基于对话的知识编码（DBKE）。DBKE增强了模型的隐式知识库，使其具有更强的对话能力，为后续用例提供了软对齐。我们提出了Clinical Camel，这是一个开源的、专注于医疗保健的会话模型，来展示DBKE的有效性。Clinical Camel在几个基准数据集上实现了最先进的结果，同时保持了高水平的可解释性和临床相关性。它还为医疗应用提供了一个可信赖的、开放源代码的替代品。

    Large Language Models (LLMs) present immense potential in the medical field, yet concerns over data privacy, regulatory compliance, and model stability restrict their widespread adoption. Although the distillation of high-performing closed-source LLMs has proven effective for general tasks, their application in healthcare is limited due to reduced domain knowledge and remnants of alignment behavior hindering clinical tasks. To address these challenges, we propose Dialogue-Based Knowledge Encoding (DBKE). DBKE enhances models' implicit knowledge base and primes them for conversational recall, augmenting their conversational capabilities and enabling a soft alignment for subsequent use cases. By transforming dense academic source text into synthetic dialogue, DBKE broadens the model's knowledge base and enables a soft alignment that guides downstream behaviours. We present Clinical Camel, an open-source, healthcare-focused conversational model, to showcase the effectiveness of DBKE. Clin
    
[^43]: SUR-adapter：用大型语言模型增强文本-图像预训练扩散模型

    SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models. (arXiv:2305.05189v1 [cs.CL])

    [http://arxiv.org/abs/2305.05189](http://arxiv.org/abs/2305.05189)

    本文提出了一个名为SUR-adapter的微调方法，用于增强预先训练的文本到图像扩散模型的语义理解和常识推理能力，以便在生成图片时使用简短的叙述提示。作者还构建了一个新的数据集SURD，并使用大型语言模型的知识进行了优化。

    

    扩散模型是目前流行的文本到图像生成模型，可以通过文本提示生成具有高质量和内容丰富度的图像。但是，当输入的提示为简短的叙述时，现有模型在语义理解和常识推理方面存在一定限制，导致图像生成的质量较低。为了提高叙述提示的能力，我们提出了一种简单而有效的参数高效的微调方法，称为Semantic Understanding和Reasoning adapter（SUR-adapter），用于预先训练的扩散模型。为实现这一目标，我们首先收集和注释一个新的数据集SURD，其中包含超过57,000个语义修正的多模态样本。每个样本都包含一个简单的叙述提示，一个复杂的基于关键字的提示和一个高质量的图像。然后，我们将叙述提示的语义表示与复杂提示对齐，并通过大型语言模型的知识将其转移至我们的SUR-adapter中。

    Diffusion models, which have emerged to become popular text-to-image generation models, can produce high-quality and content-rich images guided by textual prompts. However, there are limitations to semantic understanding and commonsense reasoning in existing models when the input prompts are concise narrative, resulting in low-quality image generation. To improve the capacities for narrative prompts, we propose a simple-yet-effective parameter-efficient fine-tuning approach called the Semantic Understanding and Reasoning adapter (SUR-adapter) for pre-trained diffusion models. To reach this goal, we first collect and annotate a new dataset SURD which consists of more than 57,000 semantically corrected multi-modal samples. Each sample contains a simple narrative prompt, a complex keyword-based prompt, and a high-quality image. Then, we align the semantic representation of narrative prompts to the complex prompts and transfer knowledge of large language models (LLMs) to our SUR-adapter vi
    
[^44]: 自我编辑：针对代码生成的故障感知式代码编辑器

    Self-Edit: Fault-Aware Code Editor for Code Generation. (arXiv:2305.04087v1 [cs.SE])

    [http://arxiv.org/abs/2305.04087](http://arxiv.org/abs/2305.04087)

    本文提出了一种故障感知式代码编辑器，通过执行生成的代码并将执行结果包含在在注释中来优化竞技编程任务的代码质量，通过与九个不同的LLMs进行比较，本方法可以在两个竞技编程数据集上显著提高代码的准确性。

    

    大型语言模型（LLMs）在竞技编程任务中生成代码的能力已经得到证明，但由于样本数量有限，LLMs仍然存在较低的准确性。受人类编程过程的启发，我们提出了一种生成和编辑的方法，利用LLMs生成的代码的执行结果来提高竞技编程任务的代码质量。我们在问题中提供的示例测试用例上执行生成的代码，并将执行结果包含在补充性注释中。利用这个注释作为指导，我们的故障感知式代码编辑器用于纠正生成的代码中的错误。我们在两个竞技编程数据集上进行了广泛的评估，涵盖了九个不同的LLMs。与直接从LLMs生成相比，我们的方法可以在APPS-dev上将pass@1的平均值提高89％，在APPS-test上提高31％，在HumanEval上提高48％，超过了九个流行的代码生成LLMs，参数大小范围为110M-t。

    Large language models (LLMs) have demonstrated an impressive ability to generate codes on competitive programming tasks. However, with limited sample numbers, LLMs still suffer from poor accuracy. Inspired by the process of human programming, we propose a generate-and-edit approach that utilizes execution results of the generated code from LLMs to improve the code quality on the competitive programming task. We execute the generated code on the example test case provided in the question and wrap execution results into a supplementary comment. Utilizing this comment as guidance, our fault-aware code editor is employed to correct errors in the generated code. We perform extensive evaluations across two competitive programming datasets with nine different LLMs. Compared to directly generating from LLMs, our approach can improve the average of pass@1 by 89\% on APPS-dev, 31\% on APPS-test, and 48\% on HumanEval over nine popular code generation LLMs with parameter sizes ranging from 110M t
    
[^45]: 语义网络的拓扑性质和组织原理

    Topological properties and organizing principles of semantic networks. (arXiv:2304.12940v1 [cs.CL])

    [http://arxiv.org/abs/2304.12940](http://arxiv.org/abs/2304.12940)

    本论文研究了由不同语言的7个语义关系定义的语义网络的基本属性。我们发现，语义网络具有普遍的基本特性：稀疏、高度聚集和自我组织化，并呈现出幂律度数分布。一些网络显示出语言特定的属性，这些属性受语法规则的影响，例如来自高度屈折语言的网络。

    

    随着非结构化文本数据的增加，自然语言理解成为计算机算法中越来越重要的任务。自然语言处理(NLP)应用程序依靠语义网络进行结构化知识表示。设计NLP算法时必须考虑语义网络的基本属性，但它们的结构尚未得到研究。我们研究了由11种不同语言的7个语义关系定义的ConceptNet语义网络的属性。我们发现，语义网络具有普遍的基本特性：它们是稀疏的、高度集聚的，并呈现出幂律度数分布。我们的研究结果显示，大多数网络都是自我组织的。一些网络显示出语言特定的属性，这些属性受语法规则的影响，例如高度屈折语言(如拉丁语、德语、法语和西班牙语)的网络在度数分布方面有峰值偏差。

    Interpreting natural language is an increasingly important task in computer algorithms due to the growing availability of unstructured textual data. Natural Language Processing (NLP) applications rely on semantic networks for structured knowledge representation. The fundamental properties of semantic networks must be taken into account when designing NLP algorithms, yet they remain to be structurally investigated. We study the properties of semantic networks from ConceptNet, defined by 7 semantic relations from 11 different languages. We find that semantic networks have universal basic properties: they are sparse, highly clustered, and exhibit power-law degree distributions. Our findings show that the majority of the considered networks are scale-free. Some networks exhibit language-specific properties determined by grammatical rules, for example networks from highly inflected languages, such as e.g. Latin, German, French and Spanish, show peaks in the degree distribution that deviate 
    
[^46]: 视觉-语言模型的黑匣子少样本适应

    Black Box Few-Shot Adaptation for Vision-Language models. (arXiv:2304.01752v1 [cs.CV])

    [http://arxiv.org/abs/2304.01752](http://arxiv.org/abs/2304.01752)

    本文提出了一种黑匣子方法，实现了对预先计算的图像和文本特征的视觉-语言模型的快速少样本适应，适用于有监督和无监督训练，并且可以用于对单模型计算的图像和文本特征进行对齐。

    

    通过对比学习训练的视觉-语言模型在少样本情况下表现出很强的学习能力。软提示学习是少样本领域适用的最受欢迎的方法，旨在通过新领域引发的分布偏移来缩小模态差距。虽然该方法性能高效，但仍需要访问模型权重，并且在具有数十亿个参数的大型模型上可能会导致计算上的不可行性。本文提出了一种黑匣子方法，实现了对预先计算的图像和文本特征的 V-L 少样本适应，不需要访问模型权重，训练速度快数个数量级，适用于有监督和无监督训练，并且还可以用于对单模型计算的图像和文本特征进行对齐。

    Vision-Language (V-L) models trained with contrastive learning to align the visual and language modalities have been shown to be strong few-shot learners. Soft prompt learning is the method of choice for few-shot downstream adaption aiming to bridge the modality gap caused by the distribution shift induced by the new domain. While parameter-efficient, prompt learning still requires access to the model weights and can be computationally infeasible for large models with billions of parameters. To address these shortcomings, in this work, we describe a black-box method for V-L few-shot adaptation that (a) operates on pre-computed image and text features and hence works without access to the model's weights, (b) it is orders of magnitude faster at training time, (c) it is amenable to both supervised and unsupervised training, and (d) it can be even used to align image and text features computed from uni-modal models. To achieve this, we propose Linear Feature Alignment (LFA), a simple line
    
[^47]: 带有提示策划和知识记忆的少样本表格到文本生成

    Few-Shot Table-to-Text Generation with Prompt Planning and Knowledge Memorization. (arXiv:2302.04415v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.04415](http://arxiv.org/abs/2302.04415)

    本论文提出了PromptMize框架，用于解决少样本情况下的表格到文本生成问题。该框架包含提示策划和知识适配器两个方面，通过生成提示信号和利用领域特定知识来改善文本生成结果。

    

    预训练语言模型在表格到文本生成任务中取得了显著进展。然而，缺乏标记的领域特定知识和表格数据与文本之间的拓扑差距使得预训练语言模型难以生成准确的文本。在低资源生成中，这个领域面临着独特的挑战。受到人类如何使用先前的知识描述表格数据的启发，我们提出了一种新的框架：PromptMize，该框架针对少样本情况下的表格到文本生成。我们的框架的设计包含两个方面：提示策划和知识适配器。提示策划的目标是生成一个提示信号，为预训练语言模型提供实例指导，以弥合表格数据和文本之间的拓扑差距。此外，知识适配器从未标记的语料库中记忆领域特定的知识，在生成过程中提供必要的信息。我们对三个开放领域的少样本自然语言生成数据集进行了大量实验和分析。

    Pre-trained language models (PLM) have achieved remarkable advancement in table-to-text generation tasks. However, the lack of labeled domain-specific knowledge and the topology gap between tabular data and text make it difficult for PLMs to yield faithful text. Low-resource generation likewise faces unique challenges in this domain. Inspired by how humans descript tabular data with prior knowledge, we suggest a new framework: PromptMize, which targets table-to-text generation under few-shot settings. The design of our framework consists of two aspects: a prompt planner and a knowledge adapter. The prompt planner aims to generate a prompt signal that provides instance guidance for PLMs to bridge the topology gap between tabular data and text. Moreover, the knowledge adapter memorizes domain-specific knowledge from the unlabelled corpus to supply essential information during generation. Extensive experiments and analyses are investigated on three open domain few-shot NLG datasets: human
    
[^48]: PromptCap：使用GPT-3的提示引导图像字幕生成进行视觉问答

    PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3. (arXiv:2211.09699v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.09699](http://arxiv.org/abs/2211.09699)

    提出了PromptCap，一种使用提示引导的图像字幕生成模型，用于解决基于知识的视觉问答中通用图像字幕无法准确描述视觉实体的问题。

    

    基于知识的视觉问答涉及需要超越图片以产生正确答案的世界知识的问题。像GPT-3这样的大型语言模型特别适用于此任务，因为它们具有强大的知识检索和推理能力。为了使LM理解图像，先前的工作使用字幕模型将图像转换为文本。然而，在单个字幕句子中总结图像时，要描述哪些视觉实体经常不明确。通用图像字幕经常错过LM回答视觉问题所必需的视觉细节。为了解决这一挑战，我们提出了PromptCap（Prompt-guided image Captioning），一种字幕模型，旨在成为图像和黑盒LM之间更好的连接器。与通用字幕不同，PromptCap采用自然语言提示来控制生成的字幕中要描述的视觉实体。提示包含字幕应回答的问题。

    Knowledge-based visual question answering (VQA) involves questions that require world knowledge beyond the image to yield the correct answer. Large language models (LMs) like GPT-3 are particularly helpful for this task because of their strong knowledge retrieval and reasoning capabilities. To enable LM to understand images, prior work uses a captioning model to convert images into text. However, when summarizing an image in a single caption sentence, which visual entities to describe are often underspecified. Generic image captions often miss visual details essential for the LM to answer visual questions correctly. To address this challenge, we propose PromptCap (Prompt-guided image Captioning), a captioning model designed to serve as a better connector between images and black-box LMs. Different from generic captions, PromptCap takes a natural-language prompt to control the visual entities to describe in the generated caption. The prompt contains a question that the caption should ai
    
[^49]: 大型预训练模型在低资源语音识别中的高效利用

    Efficient Utilization of Large Pre-Trained Models for Low Resource ASR. (arXiv:2210.15445v3 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2210.15445](http://arxiv.org/abs/2210.15445)

    本研究探讨了在低资源语音识别中如何高效利用大型预训练模型，通过无监督技术和改进的架构和训练方法取得了显著的性能提升。

    

    最近，无监督的表示学习帮助自动语音识别(ASR)解决了有限标签数据的任务。在此基础上，硬件限制和应用程序给出了如何高效利用大型预训练模型并降低其复杂性的问题。在本研究中，我们研究了越南语和德语在医疗领域中的具有挑战性的低资源电话会话语音语料库。我们展示了利用无监督技术超越简单微调大型预训练模型的好处，讨论了如何将它们适应到实际的电话任务，包括带宽传输，并调查了不同的预训练和微调数据条件。我们使用预训练技术相对于项目基线提高了22%。通过架构和训练的改进，可以进一步提高29%，通过添加0.8小时的领域内自适应数据可以提高6%。

    Unsupervised representation learning has recently helped automatic speech recognition (ASR) to tackle tasks with limited labeled data. Following this, hardware limitations and applications give rise to the question how to take advantage of large pre-trained models efficiently and reduce their complexity. In this work, we study a challenging low resource conversational telephony speech corpus from the medical domain in Vietnamese and German. We show the benefits of using unsupervised techniques beyond simple fine-tuning of large pre-trained models, discuss how to adapt them to a practical telephony task including bandwidth transfer and investigate different data conditions for pre-training and fine-tuning. We outperform the project baselines by 22% relative using pretraining techniques. Further gains of 29% can be achieved by refinements of architecture and training and 6% by adding 0.8 h of in-domain adaptation data.
    
[^50]: 在超复数空间中整合知识图谱嵌入和预训练语言模型

    Integrating Knowledge Graph embedding and pretrained Language Models in Hypercomplex Spaces. (arXiv:2208.02743v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.02743](http://arxiv.org/abs/2208.02743)

    本文提出在超复数空间中整合知识图谱嵌入和预训练语言模型的方法，通过利用超复数代数来表示单模态嵌入以及不同模态之间的交互，并且能够更好地利用结构性和文本性知识的相互作用。

    

    知识图谱如Wikidata在表示知识时包含了结构性和文本性知识。针对这两种模态，专门的图嵌入和语言模型方法学习了能够预测新的结构性知识的模式。目前只有少数方法将学习和推理与两种模态整合起来，而且现有方法只能部分地利用结构性和文本性知识的相互作用。我们的方法利用现有强大的单模态表示，并使用超复数代数表示单模态嵌入以及不同模态之间以及它们作为知识表示的互补手段的交互。具体而言，我们建议使用四维超复数的二面体和四元数表示来整合四种模态，即结构性知识图谱嵌入、词级表示（例如Word2vec、Fasttext）、句级表示（Sen

    Knowledge Graphs, such as Wikidata, comprise structural and textual knowledge in order to represent knowledge. For each of the two modalities dedicated approaches for graph embedding and language models learn patterns that allow for predicting novel structural knowledge. Few approaches have integrated learning and inference with both modalities and these existing ones could only partially exploit the interaction of structural and textual knowledge. In our approach, we build on existing strong representations of single modalities and we use hypercomplex algebra to represent both, (i), single-modality embedding as well as, (ii), the interaction between different modalities and their complementary means of knowledge representation. More specifically, we suggest Dihedron and Quaternion representations of 4D hypercomplex numbers to integrate four modalities namely structural knowledge graph embedding, word-level representations (e.g.\ Word2vec, Fasttext), sentence-level representations (Sen
    
[^51]: 一种用于意第绪语的词性标注器

    A Part-of-Speech Tagger for Yiddish. (arXiv:2204.01175v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.01175](http://arxiv.org/abs/2204.01175)

    这项研究描述了一种用于意第绪语的词性标注器的构建和评估。通过结合两个资源，即历史意第绪语Penn解析语料库和OCR意第绪语文本，研究人员展示了在无需先“标准化”语料库的情况下，简单的非上下文化嵌入也能够捕捉到拼写变体之间的关系，并通过交叉验证展示了标注器的性能。

    

    我们描述了一种用于意第绪语的词性标注器的构建和评估。这是一个更大项目的第一步，旨在自动分配意第绪语文本的词性标签和句法结构，以供语言学研究之用。我们在这项工作中使用了两个资源 - 历史意第绪语Penn解析语料库（PPCHY）的一个80K字子集和来自意第绪书籍中心（YBC）的650百万字的OCR意第绪语文本。YBC语料库中的意第绪语正字法存在许多拼写不一致之处，我们提供一些证据表明，即使在YBC上训练的简单非上下文化的嵌入也能够捕捉到拼写变体之间的关系，而无需先“标准化”语料库。我们还使用YBC进行上下文化嵌入的持续预训练，然后将其整合到在PPCHY上训练和评估的标注器模型中。我们通过10折交叉验证分析了标注器的性能，展示了利用YBC文本的效果。

    We describe the construction and evaluation of a part-of-speech tagger for Yiddish. This is the first step in a larger project of automatically assigning part-of-speech tags and syntactic structure to Yiddish text for purposes of linguistic research. We combine two resources for the current work - an 80K-word subset of the Penn Parsed Corpus of Historical Yiddish (PPCHY) and 650 million words of OCR'd Yiddish text from the Yiddish Book Center (YBC). Yiddish orthography in the YBC corpus has many spelling inconsistencies, and we present some evidence that even simple non-contextualized embeddings trained on YBC are able to capture the relationships among spelling variants without the need to first "standardize" the corpus. We also use YBC for continued pretraining of contexualized embeddings, which are then integrated into a tagger model trained and evaluated on the PPCHY. We evaluate the tagger performance on a 10-fold cross-validation split, showing that the use of the YBC text for th
    

