# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Disinformation Detection: An Evolving Challenge in the Age of LLMs.](http://arxiv.org/abs/2309.15847) | 这项研究探讨了生成型大型语言模型（LLM）所带来的虚假信息传播问题以及如何对抗这一威胁。研究旨在回答三个问题：目前虚假信息检测技术对LLM生成的虚假信息是否可靠？如果传统技术无效，LLM是否能作为一个强大的防御手段？如果前两种策略失败，可以提出什么新的方法来对抗这一威胁？ |
| [^2] | [How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions.](http://arxiv.org/abs/2309.15840) | 本文提出了一个简单但高精确度的谎言检测器，通过在怀疑有谎言的情况下问一组无关的后续问题，并将LLM的是/否答案输入到一个逻辑回归分类器中，该检测器能够推广到不同的LLM架构和实际场景中的谎言情况。 |
| [^3] | [How We Define Harm Impacts Data Annotations: Explaining How Annotators Distinguish Hateful, Offensive, and Toxic Comments.](http://arxiv.org/abs/2309.15827) | 本研究研究了研究人员如何定义“伤害”对标注结果的影响。通过使用维恩图、信息增益比较和内容分析，我们发现标注者不将“令人讨厌的”、“冒犯的”和“有毒的”概念混为一谈。我们的结果为不鼓励混淆这些术语的使用提供了经验证据。 |
| [^4] | [Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing.](http://arxiv.org/abs/2309.15826) | 本文提出了一种具有硬参数共享的ST/MT多任务框架，通过将语音和文本输入转换为两个相似长度的离散标记序列的预处理阶段来减小语音-文本模态差距，以提高翻译性能，而不需要外部MT数据。 |
| [^5] | [Identifying the Risks of LM Agents with an LM-Emulated Sandbox.](http://arxiv.org/abs/2309.15817) | 通过使用LM模拟工具执行和开发基于LM的自动安全评估器，该论文提出了一种解决测试LM代理的高成本和寻找高风险问题的方法。 |
| [^6] | [Lyra: Orchestrating Dual Correction in Automated Theorem Proving.](http://arxiv.org/abs/2309.15806) | Lyra是一种新的框架，通过引入工具修正和猜想修正两种机制，增强了大规模语言模型在形式化定理证明领域的有效性，减轻了幻觉，并提高了证明的准确性。 |
| [^7] | [Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study.](http://arxiv.org/abs/2309.15800) | 本文就离散语音单元在语音处理模型中的应用进行了全面系统的探索，并在多个任务中进行了实验验证，结果表明离散单元表现良好。 |
| [^8] | [Learning from Flawed Data: Weakly Supervised Automatic Speech Recognition.](http://arxiv.org/abs/2309.15796) | 本文提出了一种弱监督自动语音识别方法，使用全时分类准则训练模型，可以有效学习语音-文本对齐，并适应训练转录中的错误，避免性能下降。 |
| [^9] | [Large Language Model Routing with Benchmark Datasets.](http://arxiv.org/abs/2309.15789) | 本论文解决了从一系列模型中为新任务选择最佳大型语言模型的挑战，通过提出了一个基于基准数据集的学习模型来选择模型，并在各种任务中提高了性能。 |
| [^10] | [Question answering using deep learning in low resource Indian language Marathi.](http://arxiv.org/abs/2309.15779) | 本文研究了在低资源印度语马拉地语中使用深度学习的问答系统。通过对不同Transformer模型进行实验，发现在Marathi数据集上微调MuRIL多语种模型时，可以获得最佳准确率，EM得分为0.64，F1得分为0.74。 |
| [^11] | [Experience and Evidence are the eyes of an excellent summarizer! Towards Knowledge Infused Multi-modal Clinical Conversation Summarization.](http://arxiv.org/abs/2309.15739) | 本文提出了一种利用知识融入的多模态多任务框架，用于生成临床对话的摘要。通过适配器注入知识和视觉特征，并采用门控机制统一融合的特征向量。实验证明了该方法的重要性。 |
| [^12] | [ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension.](http://arxiv.org/abs/2309.15714) | 本研究通过联合分析大型语言模型（LLMs）、眼动和脑电图（EEG）数据，研究了大脑在阅读过程中处理与关键字相关度不同的单词的神经状态，并提供了关于语义推理阅读理解中神经状态的洞察。 |
| [^13] | [HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models.](http://arxiv.org/abs/2309.15701) | 本文引入了第一个开源基准测试，利用大型语言模型进行自动语音识别错误修正，实现了与人类水平相当的性能，具有重要的实际应用价值。 |
| [^14] | [Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization.](http://arxiv.org/abs/2309.15686) | 本篇论文提出了一种利用目标语言上下文来增强端到端对话式语音翻译的方法，通过引入上下文，可以提高连贯性，并解决扩展音频片段的内存限制。同时，通过添加说话人信息和上下文丢弃机制，进一步提升性能。实验结果表明，上下文端到端对话式语音翻译方法优于传统的基于独立话语的方法。在会话式语音中，上下文信息主要有助于捕捉上下文风格和解决指代和命名实体问题。 |
| [^15] | [Speech collage: code-switched audio generation by collaging monolingual corpora.](http://arxiv.org/abs/2309.15674) | 本文提出了一种通过拼接单语语料生成混合语音的方法，可以解决混合语数据稀缺的问题。实证结果表明，生成的混合语音数据可以显著提高语音识别的准确率，并减少模型对单语的偏好。 |
| [^16] | [MONOVAB : An Annotated Corpus for Bangla Multi-label Emotion Detection.](http://arxiv.org/abs/2309.15670) | 这个研究构建了一个基于孟加拉语的注释语料库，用于多标签情感检测。通过使用基于上下文的方法以及BERT模型，填补了这一学科领域的空白。 |
| [^17] | [Conversational Feedback in Scripted versus Spontaneous Dialogues: A Comparative Analysis.](http://arxiv.org/abs/2309.15656) | 本文通过对英语、法语、德语、匈牙利语、意大利语、日语、挪威语和中文的脚本对话和自发对话数据进行量化分析，研究了交流反馈现象。研究发现这些对话类型在交流反馈和落地现象方面存在明显差异。 |
| [^18] | [Generative Speech Recognition Error Correction with Large Language Models.](http://arxiv.org/abs/2309.15649) | 本研究探讨了大型语言模型（LLMs）作为ASR后处理器的能力，通过重新评分和错误校正来提高系统性能。通过使用指令提示和任务激活提示方法，结合上下文学习和微调技术，我们展示了LLMs的泛化能力和有效性。 |
| [^19] | [NLPBench: Evaluating Large Language Models on Solving NLP Problems.](http://arxiv.org/abs/2309.15630) | NLPBench是一个评估大型语言模型解决NLP问题的基准数据集，为填补该领域的研究空白，作者收集了来自耶鲁大学期末考试的378个涵盖多个NLP主题的问题。该研究发现在使用高级提示策略时，大型语言模型的性能可能不稳定，并可能对较小的模型造成负面影响。 |
| [^20] | [Developing automatic verbatim transcripts for international multilingual meetings: an end-to-end solution.](http://arxiv.org/abs/2309.15609) | 本文提出了一种端到端的解决方案，用于创建全自动的会议记录和多语言翻译，解决了会议管理文档中现有工作流程的替代和改善问题。 |
| [^21] | [Few-Shot Multi-Label Aspect Category Detection Utilizing Prototypical Network with Sentence-Level Weighting and Label Augmentation.](http://arxiv.org/abs/2309.15588) | 本论文提出了一种利用支持集注意力和增强的标签信息的原型网络，用于解决少样本多标签方面类别检测问题。通过添加句子级注意力机制和标签增强，可以更好地表示实例之间的变化和贡献。 |
| [^22] | [Jointly Training Large Autoregressive Multimodal Models.](http://arxiv.org/abs/2309.15564) | 本研究提出了共同训练大型自回归多模态模型的方法，通过模块化的方式融合语言和图像生成模型，同时引入了数据高效的指令调优策略，使得该模型在生成高质量多模态输出方面表现出卓越的性能。 |
| [^23] | [Direct Models for Simultaneous Translation and Automatic Subtitling: FBK@IWSLT2023.](http://arxiv.org/abs/2309.15554) | 本文描述了FBK的研究成果，他们使用直接模型来实现同时翻译和自动字幕生成任务，并在计算感知延迟方面取得了突破性的进展，同时在自动字幕生成任务中也优于现有解决方案。 |
| [^24] | [Teaching Text-to-Image Models to Communicate.](http://arxiv.org/abs/2309.15516) | 本文提出了一种针对对话生成图像的高效方法，通过微调预训练的文本到图像模型，实现在给定对话背景下生成一致逼真的图像。 |
| [^25] | [High-Fidelity Speech Synthesis with Minimal Supervision: All Using Diffusion Models.](http://arxiv.org/abs/2309.15512) | 提出一种使用最少监督的扩散模型实现高保真度语音合成的方法，通过组合离散语音表示和利用序列到序列任务进行训练，解决了语义表示中的信息冗余和维度爆炸以及离散声学表示中的高频波形失真等问题。该方法中的非自回归框架增强了可控性，而持续时间扩散模型实现了音频的多样化控制。 |
| [^26] | [VideoAdviser: Video Knowledge Distillation for Multimodal Transfer Learning.](http://arxiv.org/abs/2309.15494) | 提出了一个视频知识蒸馏方法 VideoAdviser，通过将多模态视频增强提示的多模态知识从教师模型传输到学生模型，实现高效性能的多模态迁移学习。 |
| [^27] | [Dynamic Multi-Scale Context Aggregation for Conversational Aspect-Based Sentiment Quadruple Analysis.](http://arxiv.org/abs/2309.15476) | 本研究提出了一种名为动态多尺度上下文聚合网络(DMCA)的方法，通过利用对话结构和动态分层聚合模块(DHA)，有效地解决了会话级方面情感四元组分析(DiaASQ)中提取四元组的困难。采用多阶段损失策略进一步提高了模型的性能和泛化能力。 |
| [^28] | [ChatCounselor: A Large Language Models for Mental Health Support.](http://arxiv.org/abs/2309.15461) | ChatCounselor是一个用于心理健康支持的大型语言模型，通过对真实对话进行训练和评估，超越了现有模型并接近ChatGPT的性能水平。 |
| [^29] | [Graph Neural Prompting with Large Language Models.](http://arxiv.org/abs/2309.15427) | 本文提出了一种名为图神经提示（GNP）的方法，可以帮助大型语言模型从知识图中学习有益的知识，以弥补它们在准确捕捉和返回基于知识的信息方面的固有限制。 |
| [^30] | [A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future.](http://arxiv.org/abs/2309.15402) | 本文首次全面调查了思维链推理领域的研究，涵盖了构建、结构变体和增强技术等方法分类，以及规划、工具使用和提炼等前沿应用。同时讨论了挑战和未来发展方向。这份调查报告对于在思维链推理领域寻求创新的研究人员来说是一个有价值的资源。 |
| [^31] | [Beyond the Chat: Executable and Verifiable Text-Editing with LLMs.](http://arxiv.org/abs/2309.15337) | 这项研究介绍了InkSync，一个具有LLMs的可执行和可验证的文本编辑界面，可提供对用户编辑建议的透明性和准确性的支持。 |
| [^32] | [joint prediction and denoising for large-scale multilingual self-supervised learning.](http://arxiv.org/abs/2309.15317) | 这项研究提出了WavLabLM，它通过联合预测和去噪的方法，实现了在136种语言的40k小时数据上进行大规模多语言自监督学习。WavLabLM的多阶段预训练方法解决了多语言数据的语言失衡问题，使其在ML-SUPERB上达到了与XLS-R相当的性能，同时仅使用不到10%的训练数据，这使得SSL在学术高性能计算上可行。 |
| [^33] | [Learning Using Generated Privileged Information by Text-to-Image Diffusion Models.](http://arxiv.org/abs/2309.15238) | 本研究提出了一种利用生成的特权信息进行学习的框架，通过文本到图像扩散模型生成合成数据作为特权信息，进一步提升了学生模型在文本分类任务中的性能。 |
| [^34] | [Low-rank Adaptation of Large Language Model Rescoring for Parameter-Efficient Speech Recognition.](http://arxiv.org/abs/2309.15223) | 这篇论文介绍了一种基于低秩适应技术的神经语言建模系统，用于语音识别的输出重评分。通过使用低秩分解方法和优化插入矩阵，该系统能够以更高效的方式将BERT模型适应到新领域，大大减少了训练时间。 |
| [^35] | [RAGAS: Automated Evaluation of Retrieval Augmented Generation.](http://arxiv.org/abs/2309.15217) | RAGAs是一个用于无参考评估检索增强生成（RAG）的框架，能够评估检索系统和生成模块的能力，提供一种加快RAG架构评估周期的方法。 |
| [^36] | [STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation.](http://arxiv.org/abs/2309.15176) | STANCE-C3是一种通过对比学习和反事实生成进行领域自适应的跨目标立场检测模型，用于推断人们对于普遍或有争议话题的观点。在解决数据分布偏移和缺乏领域特定标注数据的挑战上具有重要贡献。 |
| [^37] | [Evaluating Cognitive Maps and Planning in Large Language Models with CogEval.](http://arxiv.org/abs/2309.15129) | 这项研究提出了CogEval协议，用于系统评估大型语言模型的认知能力，并使用该协议对八个LLMs的认知地图和规划能力进行了评估。 |
| [^38] | [QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models.](http://arxiv.org/abs/2309.14717) | 本文提出了QA-LoRA算法，它通过使用量化意识以及组内运算符来实现大语言模型的低秩适应。QA-LoRA能够将模型权重量化以减少时间和内存的使用，同时在不损失准确性的情况下将模型集成为一个量化模型。 |
| [^39] | [Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion.](http://arxiv.org/abs/2309.14398) | 本文提出了一个多模态分类器，在动机性访谈中准确区分了变化话语、持续话语和跟随/中立话语三种类别。该分类器利用文本、声调、面部表情和身体表现等多模态特征，并对AnnoMI数据集进行了注释和训练。研究还找到了决策过程中最重要的模态，提供了宝贵的洞察。 |
| [^40] | [ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning.](http://arxiv.org/abs/2309.13701) | ALLURE是一种基于迭代上下文学习的文本评估的审计和改进方法，通过与注释数据进行比较并纳入重大偏差的实例，使用上下文学习提高LLM对文本的评估能力。 |
| [^41] | [SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features.](http://arxiv.org/abs/2309.11791) | 这项研究提出了一种方法，通过结合知识图谱的结构信息和本体类名的语义和词汇特征，将Wikipedia的分类和列表映射到DBpedia，以构建一个完善和细粒度的知识图谱。 |
| [^42] | [Are Large Language Models Really Robust to Word-Level Perturbations?.](http://arxiv.org/abs/2309.11166) | 该论文提出了一种用于评估大型语言模型（LLMs）鲁棒性的新颖方法，使用预训练的奖励模型作为诊断工具。实验证明这种方法在评估LLM鲁棒性方面表现准确。 |
| [^43] | [MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods.](http://arxiv.org/abs/2309.10966) | 本文提出了MBR微调和QE微调方法，将训练时的质量提升蒸馏到基准模型中，从而在推断时使用高效的解码算法。实验证明，这些微调方法能显著提升模型性能，甚至超过基准模型。 |
| [^44] | [Estimating Contamination via Perplexity: Quantifying Memorisation in Language Model Evaluation.](http://arxiv.org/abs/2309.10677) | 本文提出了一种新方法，通过困惑度来量化语言模型评估中的污染，而不需要访问完整的训练数据。研究表明，最近的基础模型在阅读理解和摘要基准中存在显著的记忆化，而多项选择问题则受污染较少。 |
| [^45] | [Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs.](http://arxiv.org/abs/2309.07311) | 本文通过对掩码语言模型中的语法习得进行案例研究，发现在训练的一个短暂窗口内，模型突然获得了语法注意结构(SAS)，并伴随着损失的陡峭下降。SAS对随后习得语言能力起到了重要的促进作用。 |
| [^46] | [Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling.](http://arxiv.org/abs/2309.06726) | 本文提出了关注关键短语的BART模型(Keyphrase-Focused BART)，通过拆分和重排的方式来增强关键短语生成的性能。在不出现的关键短语生成任务中，该模型在两个关键短语生成基准数据集上取得了新的最佳得分。 |
| [^47] | [Cognitive Architectures for Language Agents.](http://arxiv.org/abs/2309.02427) | 本文提出了一种称为CoALA的认知架构，用于组织语言代理的现有研究并规划未来的发展方向。CoALA描述了一个具有模块化记忆组件、结构化行动空间和通用决策过程的语言代理。通过这一框架，有望发展出更强大的语言代理。 |
| [^48] | [CPSP: Learning Speech Concepts From Phoneme Supervision.](http://arxiv.org/abs/2309.00424) | 论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。 |
| [^49] | [DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using Sentence Transformers and Reciprocal-Rank Fusion.](http://arxiv.org/abs/2308.12877) | 本文介绍了DS4DH在#SMM4H 2023中开发的不良药物事件规范化系统的性能评估，该系统利用句子转换和倒数排名融合进行零样本规范化。实验结果表明该方法在共享任务中表现优异，可有效应用于社交媒体文本挖掘中的不良药物事件规范化。 |
| [^50] | [Advancing Beyond Identification: Multi-bit Watermark for Language Models.](http://arxiv.org/abs/2308.00221) | 本研究提出了一种用于语言模型的多位水印技术——COLOR，可在语言模型生成过程中嵌入可追踪的多位信息，实现了提取水印、即时嵌入和维持文本质量等功能，同时允许零位检测。初步实验显示成功在中等长度的文本中嵌入了32位消息，准确率为91.9％。这项研究有效推进了对语言模型滥用的反制策略。 |
| [^51] | [Robust Distortion-free Watermarks for Language Models.](http://arxiv.org/abs/2307.15593) | 该论文提出了一种在语言模型中添加鲁棒无畸变水印的方法，通过映射随机数序列到语言模型的样本，可以实现在不改变文本分布的前提下对水印文本进行检测，并且在多种改写攻击下依然保持较高的鲁棒性，实验证明在40-50%的随机扰动下仍可可靠地检测到水印文本。 |
| [^52] | [Single and Multi-Speaker Cloned Voice Detection: From Perceptual to Learned Features.](http://arxiv.org/abs/2307.07683) | 本论文介绍了三种区分真实声音和试图冒充特定人物声音的克隆声音的技术，分别采用不同的特征提取方法，并展示了在单个和多个声音上训练时的有效性。学习特征具有较高的准确性并且对对抗性清洗具有相当的鲁棒性。 |
| [^53] | [Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data.](http://arxiv.org/abs/2306.13840) | 本论文提出使用多样性系数作为LLM预训练数据质量的指标，研究表明公开可用的LLM数据集的多样性系数很高。 |
| [^54] | [AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers.](http://arxiv.org/abs/2306.06531) | AutoTAMP提出了一种使用LLMs作为翻译器和检查器的自回归任务和动作规划方法，通过少样本翻译将自然语言任务描述转换为中间任务表示，以实现对复杂任务的规划和执行。 |
| [^55] | [Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting.](http://arxiv.org/abs/2303.12057) | 本文展示了在零-shot学习环境下，大型语言模型可以用于评估政治家的意识形态，为我们更好地理解政治功能提供了有用的信息。 |
| [^56] | [A Deep Learning System for Domain-specific speech Recognition.](http://arxiv.org/abs/2303.10510) | 本文提出了一个使用半监督学习注释领域特定数据，基于预训练的声学模型进行微调的ASR系统，并在领域特定上取得了优于商业ASR系统的性能。 |
| [^57] | [GPT-Neo for commonsense reasoning -- a theoretical and practical lens.](http://arxiv.org/abs/2211.15593) | 本文评估了GPT-Neo模型在常识推理任务上的性能，并与其他较大模型进行了比较。在适当的超参数设置下，该模型在多个任务上取得了具有竞争力的准确性。 |
| [^58] | [Late Audio-Visual Fusion for In-The-Wild Speaker Diarization.](http://arxiv.org/abs/2211.01299) | 本论文提出了一种音频-视觉融合的模型，通过后期融合将音频和视觉信息相结合，用于解决在野外视频中具有挑战性的说话者分辨问题。通过使用模拟代理数据集进行训练，并引入注意力机制和说话者识别损失，我们提出的模型在处理更多说话者时表现更好。此外，利用面部属性和唇音同步的视觉子系统能够估计屏幕上说话者的身份和语音活动。整体而言，我们的模型在AVA-AVD基准测试上取得了新的最先进结果。 |
| [^59] | [Overcoming Referential Ambiguity in Language-Guided Goal-Conditioned Reinforcement Learning.](http://arxiv.org/abs/2209.12758) | 本文研究了语言指导的目标-条件强化学习中的指代歧义问题，并提出了教学法和实用主义的概念来解决这些问题。实验证明，这些概念可以提高学习者的训练效率。 |

# 详细

[^1]: 虚假信息检测：在LLM时代面临的持续挑战

    Disinformation Detection: An Evolving Challenge in the Age of LLMs. (arXiv:2309.15847v1 [cs.CL])

    [http://arxiv.org/abs/2309.15847](http://arxiv.org/abs/2309.15847)

    这项研究探讨了生成型大型语言模型（LLM）所带来的虚假信息传播问题以及如何对抗这一威胁。研究旨在回答三个问题：目前虚假信息检测技术对LLM生成的虚假信息是否可靠？如果传统技术无效，LLM是否能作为一个强大的防御手段？如果前两种策略失败，可以提出什么新的方法来对抗这一威胁？

    

    生成型大型语言模型（LLM）的出现，如ChatGPT，在多个领域催生了变革性的进展。然而，随着这些进展的同时，它们也引入了潜在的威胁。其中一个关键问题是滥用LLM生成虚假信息的传播者，利用这些模型生成高度有说服力但具有误导性的内容，挑战虚假信息检测系统。此项工作旨在通过回答三个研究问题来解决这个问题：（1）现有的虚假信息检测技术能够可靠地检测LLM生成的虚假信息的程度是多少？ （2）如果传统技术证明效果较差，LLM本身是否可以被利用作为对抗先进虚假信息的强大防御？ （3）如果这两种策略都失效，可以提出什么新的方法来有效应对这个日益严重的威胁？对于虚假信息的形成和检测进行了整体探索来推动这一行

    The advent of generative Large Language Models (LLMs) such as ChatGPT has catalyzed transformative advancements across multiple domains. However, alongside these advancements, they have also introduced potential threats. One critical concern is the misuse of LLMs by disinformation spreaders, leveraging these models to generate highly persuasive yet misleading content that challenges the disinformation detection system. This work aims to address this issue by answering three research questions: (1) To what extent can the current disinformation detection technique reliably detect LLM-generated disinformation? (2) If traditional techniques prove less effective, can LLMs themself be exploited to serve as a robust defense against advanced disinformation? and, (3) Should both these strategies falter, what novel approaches can be proposed to counter this burgeoning threat effectively? A holistic exploration for the formation and detection of disinformation is conducted to foster this line of 
    
[^2]: 如何捕捉AI谎言：通过问无关问题在黑盒LLMs中进行谎言检测

    How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions. (arXiv:2309.15840v1 [cs.CL])

    [http://arxiv.org/abs/2309.15840](http://arxiv.org/abs/2309.15840)

    本文提出了一个简单但高精确度的谎言检测器，通过在怀疑有谎言的情况下问一组无关的后续问题，并将LLM的是/否答案输入到一个逻辑回归分类器中，该检测器能够推广到不同的LLM架构和实际场景中的谎言情况。

    

    大型语言模型（LLMs）会“说谎”，也就是在明知道真相的情况下输出虚假陈述。当指示输出错误信息时，LLMs可能会“说谎”。在这里，我们开发了一个简单的谎言检测器，既不需要访问LLM的激活（黑盒），也不需要事实问题的真相知识。这个检测器通过在怀疑有谎言的情况下问一组预定义的无关后续问题，并将LLM的是/否答案输入到逻辑回归分类器中来工作。尽管简单，这个谎言检测器非常准确并且令人惊讶地通用。当在单一情境的示例上进行训练 - 促使GPT-3.5在事实问题上撒谎 - 该检测器可以推广到以下情况：（1）其他LLM架构，（2）细调为说谎的LLMs，（3）谄媚的谎言，和（4）出现在实际场景中的谎言，比如销售。这些结果表明，LLMs具有特殊的与谎言相关的行为模式。

    Large language models (LLMs) can "lie", which we define as outputting false statements despite "knowing" the truth in a demonstrable sense. LLMs might "lie", for example, when instructed to output misinformation. Here, we develop a simple lie detector that requires neither access to the LLM's activations (black-box) nor ground-truth knowledge of the fact in question. The detector works by asking a predefined set of unrelated follow-up questions after a suspected lie, and feeding the LLM's yes/no answers into a logistic regression classifier. Despite its simplicity, this lie detector is highly accurate and surprisingly general. When trained on examples from a single setting -prompting GPT-3.5 to lie about factual questions -- the detector generalises out-of-distribution to (1) other LLM architectures, (2) LLMs fine-tuned to lie, (3) sycophantic lies, and (4) lies emerging in real-life scenarios such as sales. These results indicate that LLMs have distinctive lie-related behavioural pa
    
[^3]: 如何定义伤害影响数据标注：解释标注者如何区分令人讨厌的、冒犯的和有毒的评论

    How We Define Harm Impacts Data Annotations: Explaining How Annotators Distinguish Hateful, Offensive, and Toxic Comments. (arXiv:2309.15827v1 [cs.CL])

    [http://arxiv.org/abs/2309.15827](http://arxiv.org/abs/2309.15827)

    本研究研究了研究人员如何定义“伤害”对标注结果的影响。通过使用维恩图、信息增益比较和内容分析，我们发现标注者不将“令人讨厌的”、“冒犯的”和“有毒的”概念混为一谈。我们的结果为不鼓励混淆这些术语的使用提供了经验证据。

    

    计算社会科学研究在机器学习和自然语言处理方面取得了进展，支持内容审核员检测有害内容。这些进展往往依赖于由众包工作者为有害内容标注的训练数据集。在设计标注任务的指导说明以生成这些算法的训练数据时，研究人员通常将我们训练算法检测的伤害概念 - “令人讨厌的”、“冒犯的”、“有毒的”、“种族主义的”、“性别歧视的”等视为可互换的。在这项工作中，我们研究了研究人员对“伤害”的定义方式是否影响标注结果。通过使用维恩图、信息增益比较和内容分析，我们发现标注者并不将“令人讨厌的”、“冒犯的”和“有毒的”概念混为一谈。我们发现伤害定义的特征以及标注者的个人特点在很大程度上解释了标注者如何不同地使用这些术语。我们的结果提供了经验   证据，不鼓励混淆这些术语的使用。

    Computational social science research has made advances in machine learning and natural language processing that support content moderators in detecting harmful content. These advances often rely on training datasets annotated by crowdworkers for harmful content. In designing instructions for annotation tasks to generate training data for these algorithms, researchers often treat the harm concepts that we train algorithms to detect - 'hateful', 'offensive', 'toxic', 'racist', 'sexist', etc. - as interchangeable. In this work, we studied whether the way that researchers define 'harm' affects annotation outcomes. Using Venn diagrams, information gain comparisons, and content analyses, we reveal that annotators do not use the concepts 'hateful', 'offensive', and 'toxic' interchangeably. We identify that features of harm definitions and annotators' individual characteristics explain much of how annotators use these terms differently. Our results offer empirical evidence discouraging the co
    
[^4]: 跨模态多任务的语音到文本翻译方法通过硬参数共享

    Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing. (arXiv:2309.15826v1 [cs.CL])

    [http://arxiv.org/abs/2309.15826](http://arxiv.org/abs/2309.15826)

    本文提出了一种具有硬参数共享的ST/MT多任务框架，通过将语音和文本输入转换为两个相似长度的离散标记序列的预处理阶段来减小语音-文本模态差距，以提高翻译性能，而不需要外部MT数据。

    

    最近的端到端语音到文本翻译(ST)的研究提出了一种利用机器翻译(MT)数据通过次要编码器将文本目标转化为跨模态表示的多任务方法和软参数共享。本文中，我们提出了一种具有硬参数共享的ST/MT多任务框架，其中所有模型参数都以跨模态方式共享。我们的方法通过将语音和文本输入转换为两个相似长度的离散标记序列的预处理阶段来减小语音-文本模态差距，这使得模型可以简单地使用一个联合词汇表对两种模态进行无差别处理。通过对MuST-C的实验，我们证明了我们的多任务框架在没有外部MT数据的情况下，可以提高注意力编码器-解码器、连接主义时序分类(CTC)、传递器和联合CTC/注意力模型的平均BLEU得分+0.5。此外，我们还展示了该框架可以利用外部MT数据，并获得更好的结果。

    Recent works in end-to-end speech-to-text translation (ST) have proposed multi-tasking methods with soft parameter sharing which leverage machine translation (MT) data via secondary encoders that map text inputs to an eventual cross-modal representation. In this work, we instead propose a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally. Our method reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length -- this allows models to indiscriminately process both modalities simply using a joint vocabulary. With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data. Further, we show that this framework incorporates external MT data, yield
    
[^5]: 使用LM模拟沙盒识别LM代理的风险

    Identifying the Risks of LM Agents with an LM-Emulated Sandbox. (arXiv:2309.15817v1 [cs.AI])

    [http://arxiv.org/abs/2309.15817](http://arxiv.org/abs/2309.15817)

    通过使用LM模拟工具执行和开发基于LM的自动安全评估器，该论文提出了一种解决测试LM代理的高成本和寻找高风险问题的方法。

    

    最近的语言模型（LM）代理和工具使用的技术进步，例如ChatGPT插件，使得代理具备了丰富的功能，但也放大了潜在的风险，如泄露私人数据或引发财务损失。识别这些风险是一项耗时的工作，需要实施工具，手动设置每个测试场景的环境，并找到风险案例。随着工具和代理变得越来越复杂，测试这些代理的高成本将使寻找高风险、长尾风险变得越来越困难。为了解决这些挑战，我们引入了ToolEmu：一个使用LM来模拟工具执行的框架，可以在不需要手动实例化的情况下对LM代理进行各种工具和场景的测试。除了模拟器，我们还开发了一个基于LM的自动安全评估器，用于检查代理的失败并量化相关风险。我们通过人工评估测试了工具模拟器和评估器，并发现了6个...

    Recent advances in Language Model (LM) agents and tool use, exemplified by applications like ChatGPT Plugins, enable a rich set of capabilities but also amplify potential risks - such as leaking private data or causing financial losses. Identifying these risks is labor-intensive, necessitating implementing the tools, manually setting up the environment for each test scenario, and finding risky cases. As tools and agents become more complex, the high cost of testing these agents will make it increasingly difficult to find high-stakes, long-tailed risks. To address these challenges, we introduce ToolEmu: a framework that uses an LM to emulate tool execution and enables the testing of LM agents against a diverse range of tools and scenarios, without manual instantiation. Alongside the emulator, we develop an LM-based automatic safety evaluator that examines agent failures and quantifies associated risks. We test both the tool emulator and evaluator through human evaluation and find that 6
    
[^6]: Lyra: 自动定理证明中的双重修正策略的编排

    Lyra: Orchestrating Dual Correction in Automated Theorem Proving. (arXiv:2309.15806v1 [cs.CL])

    [http://arxiv.org/abs/2309.15806](http://arxiv.org/abs/2309.15806)

    Lyra是一种新的框架，通过引入工具修正和猜想修正两种机制，增强了大规模语言模型在形式化定理证明领域的有效性，减轻了幻觉，并提高了证明的准确性。

    

    大规模语言模型（LLMs）为形式化定理证明领域提供了一个有趣的探索途径。然而，它们的全部潜力，尤其是关于幻觉的减轻和通过证明器错误消息的细化，仍然是一个尚未深入研究的领域。为了增强LLMs在该领域的有效性，我们引入了Lyra，一种采用两种不同修正机制的新框架：工具修正（TC）和猜想修正（CC）。为了在形式证明的后处理中实现工具修正，我们利用先前的知识来利用预定义的证明工具（如Sledgehammer）来指导替换不正确的工具。工具修正显著减轻了幻觉，从而提高了证明的整体准确性。此外，我们引入了猜想修正，一种错误反馈机制，旨在与证明器互动，通过证明器的错误消息进一步完善形式证明的猜想。

    Large Language Models (LLMs) present an intriguing avenue for exploration in the field of formal theorem proving. Nevertheless, their full potential, particularly concerning the mitigation of hallucinations and refinement through prover error messages, remains an area that has yet to be thoroughly investigated. To enhance the effectiveness of LLMs in the field, we introduce the Lyra, a new framework that employs two distinct correction mechanisms: Tool Correction (TC) and Conjecture Correction (CC). To implement Tool Correction in the post-processing of formal proofs, we leverage prior knowledge to utilize predefined prover tools (e.g., Sledgehammer) for guiding the replacement of incorrect tools. Tool Correction significantly contributes to mitigating hallucinations, thereby improving the overall accuracy of the proof. In addition, we introduce Conjecture Correction, an error feedback mechanism designed to interact with prover to refine formal proof conjectures with prover error messa
    
[^7]: 探索离散语音单元在语音识别、翻译和理解中的应用：一项比较研究

    Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study. (arXiv:2309.15800v1 [cs.CL])

    [http://arxiv.org/abs/2309.15800](http://arxiv.org/abs/2309.15800)

    本文就离散语音单元在语音处理模型中的应用进行了全面系统的探索，并在多个任务中进行了实验验证，结果表明离散单元表现良好。

    

    语音信号通常以每秒数万次的速率进行采样，包含冗余信息，导致序列建模的低效性。高维度的语音特征，如频谱图，通常被用作随后模型的输入。然而，它们仍然具有冗余性。最近的研究提出了使用从自监督学习表示中得到的离散语音单元，可以显著压缩语音数据的大小。应用各种方法，如去重和子词建模，可以进一步压缩语音序列长度。因此，训练时间显著缩短，同时仍然保持不错的性能。在这项研究中，我们对离散单元在端到端语音处理模型中的应用进行了全面系统的探索。对12个自动语音识别、3个语音翻译和1个口语理解语料库的实验表明，离散单元可以取得相当好的结果。

    Speech signals, typically sampled at rates in the tens of thousands per second, contain redundancies, evoking inefficiencies in sequence modeling. High-dimensional speech features such as spectrograms are often used as the input for the subsequent model. However, they can still be redundant. Recent investigations proposed the use of discrete speech units derived from self-supervised learning representations, which significantly compresses the size of speech data. Applying various methods, such as de-duplication and subword modeling, can further compress the speech sequence length. Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models. Experiments on 12 automatic speech recognition, 3 speech translation, and 1 spoken language understanding corpora demonstrate that discrete units achieve reasonably good resul
    
[^8]: 学习来自有缺陷的数据：弱监督式自动语音识别

    Learning from Flawed Data: Weakly Supervised Automatic Speech Recognition. (arXiv:2309.15796v1 [eess.AS])

    [http://arxiv.org/abs/2309.15796](http://arxiv.org/abs/2309.15796)

    本文提出了一种弱监督自动语音识别方法，使用全时分类准则训练模型，可以有效学习语音-文本对齐，并适应训练转录中的错误，避免性能下降。

    

    训练自动语音识别（ASR）系统需要大量经过精心筛选的配对数据。然而，人工标注者通常执行“非逐字”转录，这可能导致训练模型不佳。在本文中，我们提出了全时分类（OTC），一种新颖的训练准则，明确地融入了由此类弱监督引起的标签不确定性。这使得模型能够有效地学习语音-文本对齐，并适应训练转录中存在的错误。OTC通过利用加权有限状态转换器扩展了传统的CTC目标函数用于不完美转录。通过在LibriSpeech和LibriVox数据集上进行的实验，我们证明使用OTC训练ASR模型可以避免性能下降，即使转录中包含高达70％的错误，而CTC模型则完全失效。我们的实现可在https://github.com/k2-fsa/icefall获得。

    Training automatic speech recognition (ASR) systems requires large amounts of well-curated paired data. However, human annotators usually perform "non-verbatim" transcription, which can result in poorly trained models. In this paper, we propose Omni-temporal Classification (OTC), a novel training criterion that explicitly incorporates label uncertainties originating from such weak supervision. This allows the model to effectively learn speech-text alignments while accommodating errors present in the training transcripts. OTC extends the conventional CTC objective for imperfect transcripts by leveraging weighted finite state transducers. Through experiments conducted on the LibriSpeech and LibriVox datasets, we demonstrate that training ASR models with OTC avoids performance degradation even with transcripts containing up to 70% errors, a scenario where CTC models fail completely. Our implementation is available at https://github.com/k2-fsa/icefall.
    
[^9]: 大型语言模型选择与基准数据集

    Large Language Model Routing with Benchmark Datasets. (arXiv:2309.15789v1 [cs.CL])

    [http://arxiv.org/abs/2309.15789](http://arxiv.org/abs/2309.15789)

    本论文解决了从一系列模型中为新任务选择最佳大型语言模型的挑战，通过提出了一个基于基准数据集的学习模型来选择模型，并在各种任务中提高了性能。

    

    开源的大型语言模型（LLM）和基准数据集数量迅速增长，用于比较它们。虽然一些模型在这些基准测试中占优势，但通常没有单一模型在所有任务和用例中都能达到最佳准确性。在这项工作中，我们解决了从一系列模型中为新任务选择最佳LLM的挑战。我们提出了一个新的问题表述，在这个问题中，基准数据集被重新用于学习一个"路由器"模型来选择LLM，并且我们表明这个问题可以转化为一系列二元分类任务的集合。我们展示了从各种基准数据集学习模型路由器的效用和限制，我们在所有任务中始终比使用任何单一模型都提高了性能。

    There is a rapidly growing number of open-source Large Language Models (LLMs) and benchmark datasets to compare them. While some models dominate these benchmarks, no single model typically achieves the best accuracy in all tasks and use cases. In this work, we address the challenge of selecting the best LLM out of a collection of models for new tasks. We propose a new formulation for the problem, in which benchmark datasets are repurposed to learn a "router" model for this LLM selection, and we show that this problem can be reduced to a collection of binary classification tasks. We demonstrate the utility and limitations of learning model routers from various benchmark datasets, where we consistently improve performance upon using any single model for all tasks.
    
[^10]: 在低资源印度语马拉地语中使用深度学习的问答系统

    Question answering using deep learning in low resource Indian language Marathi. (arXiv:2309.15779v1 [cs.CL])

    [http://arxiv.org/abs/2309.15779](http://arxiv.org/abs/2309.15779)

    本文研究了在低资源印度语马拉地语中使用深度学习的问答系统。通过对不同Transformer模型进行实验，发现在Marathi数据集上微调MuRIL多语种模型时，可以获得最佳准确率，EM得分为0.64，F1得分为0.74。

    

    在问答系统中，通过使用本体、规则和基于机器学习的方法，从文本中为给定的问题提取出精确的答案。最近的研究通过使用Transformer模型和迁移学习方法来解决问答挑战，在马拉地语问答系统中取得了一定的成果。本文研究了不同的Transformer模型，用于创建基于阅读理解的马拉地语问答系统。我们在不同的预训练马拉地语多语种和单语种模型上进行了实验，如MuRIL、MahaBERT、IndicBERT，并在马拉地语阅读理解数据集上进行了微调。我们通过在马拉地语数据集上微调MuRIL多语种模型，在EM得分为0.64，F1得分为0.74时获得了最佳准确率。

    Precise answers are extracted from a text for a given input question in a question answering system. Marathi question answering system is created in recent studies by using ontology, rule base and machine learning based approaches. Recently transformer models and transfer learning approaches are used to solve question answering challenges. In this paper we investigate different transformer models for creating a reading comprehension-based Marathi question answering system. We have experimented on different pretrained Marathi language multilingual and monolingual models like Multilingual Representations for Indian Languages (MuRIL), MahaBERT, Indic Bidirectional Encoder Representations from Transformers (IndicBERT) and fine-tuned it on a Marathi reading comprehension-based data set. We got the best accuracy in a MuRIL multilingual model with an EM score of 0.64 and F1 score of 0.74 by fine tuning the model on the Marathi dataset.
    
[^11]: 体验和证据是出色摘要机器人的眼睛！朝着知识融入的多模态临床对话摘要化。

    Experience and Evidence are the eyes of an excellent summarizer! Towards Knowledge Infused Multi-modal Clinical Conversation Summarization. (arXiv:2309.15739v1 [cs.CL])

    [http://arxiv.org/abs/2309.15739](http://arxiv.org/abs/2309.15739)

    本文提出了一种利用知识融入的多模态多任务框架，用于生成临床对话的摘要。通过适配器注入知识和视觉特征，并采用门控机制统一融合的特征向量。实验证明了该方法的重要性。

    

    随着远程医疗的发展，研究人员和医疗从业者正共同努力开发各种技术来自动化各种医疗操作，如诊断报告生成。本文首先提出了一种多模态临床对话摘要生成任务，它根据临床医生和患者的交互（文本和视觉信息）生成对话的简洁概述。我们提出了一种融入知识的多模态多任务医学领域识别和临床对话摘要生成（MM-CliConSummation）框架。它利用适配器来注入知识和视觉特征，并使用门控机制统一融合的特征向量。此外，我们还开发了一个带有意图、症状和摘要注释的多模态多意图临床对话摘要语料库。通过大量定量和定性实验，得出以下发现：(a)关键的重要性

    With the advancement of telemedicine, both researchers and medical practitioners are working hand-in-hand to develop various techniques to automate various medical operations, such as diagnosis report generation. In this paper, we first present a multi-modal clinical conversation summary generation task that takes a clinician-patient interaction (both textual and visual information) and generates a succinct synopsis of the conversation. We propose a knowledge-infused, multi-modal, multi-tasking medical domain identification and clinical conversation summary generation (MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and visual features and unify the fused feature vector using a gated mechanism. Furthermore, we developed a multi-modal, multi-intent clinical conversation summarization corpus annotated with intent, symptom, and summary. The extensive set of experiments, both quantitatively and qualitatively, led to the following findings: (a) critical significan
    
[^12]: ChatGPT-BCI：使用GPT、EEG和眼动生物标记器在语义推理阅读理解中进行单词级神经状态分类

    ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension. (arXiv:2309.15714v1 [cs.CL])

    [http://arxiv.org/abs/2309.15714](http://arxiv.org/abs/2309.15714)

    本研究通过联合分析大型语言模型（LLMs）、眼动和脑电图（EEG）数据，研究了大脑在阅读过程中处理与关键字相关度不同的单词的神经状态，并提供了关于语义推理阅读理解中神经状态的洞察。

    

    随着大型语言模型（LLM）（如GPT）的迅猛发展，人类和机器理解语义语言意义的能力已经进入了一个新阶段。这需要跨认知科学和自然语言处理（NLP）领域的跨学科研究。本文的目标是通过联合分析LLMs、眼动和脑电图（EEG）数据，研究大脑在阅读过程中如何处理与关键字相关程度不同的单词，从而提供关于个体神经状态在语义关系阅读理解任务中的洞察。我们还使用特征工程方法改进了与关键字高相关度和低相关度的单词阅读过程中与注视相关的EEG数据的分类。在12名受试者中，此单词级别分类的最佳验证准确率超过了60％。

    With the recent explosion of large language models (LLMs), such as Generative Pretrained Transformers (GPT), the need to understand the ability of humans and machines to comprehend semantic language meaning has entered a new phase. This requires interdisciplinary research that bridges the fields of cognitive science and natural language processing (NLP). This pilot study aims to provide insights into individuals' neural states during a semantic relation reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and electroencephalographic (EEG) data to study how the brain processes words with varying degrees of relevance to a keyword during reading. We also use a feature engineering approach to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword. The best validation accuracy in this word-level classification is over 60\% across 12 subjects. Words of high relevance to the inference keyword had sig
    
[^13]: HyPoradise：基于大语言模型的生成式语音识别的开放基准线

    HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models. (arXiv:2309.15701v1 [cs.CL])

    [http://arxiv.org/abs/2309.15701](http://arxiv.org/abs/2309.15701)

    本文引入了第一个开源基准测试，利用大型语言模型进行自动语音识别错误修正，实现了与人类水平相当的性能，具有重要的实际应用价值。

    

    深度神经网络的进展使得自动语音识别系统在几个公开的干净语音数据集上达到了人类水平。然而，即使是最先进的自动语音识别系统在面对逆境时也会出现性能下降，因为良好训练的声学模型对于语音领域的变异性很敏感，如背景噪声。受到这一观察的启发，我们引入了第一个开源基准测试，利用外部的大型语言模型（LLMs）来进行自动语音识别错误修正，其中N最佳解码假设为真实转录预测提供了有信息量的元素。这种方法与传统的语言模型重评分策略不同，后者只能选择一个候选假设作为最终预测。

    Advancements in deep neural networks have allowed automatic speech recognition (ASR) systems to attain human parity on several publicly available clean speech datasets. However, even state-of-the-art ASR systems experience performance degradation when confronted with adverse conditions, as a well-trained acoustic model is sensitive to variations in the speech domain, e.g., background noise. Intuitively, humans address this issue by relying on their linguistic knowledge: the meaning of ambiguous spoken terms is usually inferred from contextual cues thereby reducing the dependency on the auditory system. Inspired by this observation, we introduce the first open-source benchmark to utilize external large language models (LLMs) for ASR error correction, where N-best decoding hypotheses provide informative elements for true transcription prediction. This approach is a paradigm shift from the traditional language model rescoring strategy that can only select one candidate hypothesis as the o
    
[^14]: 提升端到端对话式语音翻译通过利用目标语言上下文

    Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization. (arXiv:2309.15686v1 [cs.CL])

    [http://arxiv.org/abs/2309.15686](http://arxiv.org/abs/2309.15686)

    本篇论文提出了一种利用目标语言上下文来增强端到端对话式语音翻译的方法，通过引入上下文，可以提高连贯性，并解决扩展音频片段的内存限制。同时，通过添加说话人信息和上下文丢弃机制，进一步提升性能。实验结果表明，上下文端到端对话式语音翻译方法优于传统的基于独立话语的方法。在会话式语音中，上下文信息主要有助于捕捉上下文风格和解决指代和命名实体问题。

    

    已经证明将较长的上下文融入机器翻译可以带来好处，但是端到端对话式语音翻译中的上下文利用还未得到广泛研究。为了弥补这个空白，我们引入目标语言上下文在端到端对话式语音翻译中，增强连贯性并克服扩展音频片段的内存限制。此外，我们提出了上下文丢弃以确保对于上下文缺失具有鲁棒性，并通过添加说话人信息进一步提高性能。我们提出的上下文端到端对话式语音翻译优于孤立的话语为基础的端到端对话式语音翻译方法。最后，我们证明在会话式语音中，上下文信息主要有助于捕捉上下文风格，以及解决指代和命名实体。

    Incorporating longer context has been shown to benefit machine translation, but the inclusion of context in end-to-end speech translation (E2E-ST) remains under-studied. To bridge this gap, we introduce target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments. Additionally, we propose context dropout to ensure robustness to the absence of context, and further improve performance by adding speaker information. Our proposed contextual E2E-ST outperforms the isolated utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational speech, contextual information primarily contributes to capturing context style, as well as resolving anaphora and named entities.
    
[^15]: 语音拼贴：通过拼接单语语料生成混合语音

    Speech collage: code-switched audio generation by collaging monolingual corpora. (arXiv:2309.15674v1 [cs.SD])

    [http://arxiv.org/abs/2309.15674](http://arxiv.org/abs/2309.15674)

    本文提出了一种通过拼接单语语料生成混合语音的方法，可以解决混合语数据稀缺的问题。实证结果表明，生成的混合语音数据可以显著提高语音识别的准确率，并减少模型对单语的偏好。

    

    设计有效的用于混合语言的自动语音识别（ASR）系统往往取决于可获得的混合语资源的有效性。为了解决数据稀缺的问题，本文引入了语音拼贴方法，通过拼接音频片段从单语语料中合成混合语数据。我们进一步通过重叠添加的方法提高了音频生成的平滑度。我们研究了生成数据对两种情况下的语音识别的影响：使用领域内混合语文本和使用合成的混合语文本的零样本方法。实证结果显示，在领域内和零样本情况下，混合错误率和词错误率分别相对减少了34.4%和16.2%。最后，我们证明了混合语言增强了模型的混合倾向并减少了单语倾向。

    Designing effective automatic speech recognition (ASR) systems for Code-Switching (CS) often depends on the availability of the transcribed CS resources. To address data scarcity, this paper introduces Speech Collage, a method that synthesizes CS data from monolingual corpora by splicing audio segments. We further improve the smoothness quality of audio generation using an overlap-add approach. We investigate the impact of generated data on speech recognition in two scenarios: using in-domain CS text and a zero-shot approach with synthesized CS text. Empirical results highlight up to 34.4% and 16.2% relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation bolsters the model's code-switching inclination and reduces its monolingual bias.
    
[^16]: MONOVAB: 用于孟加拉语多标签情感检测的注释语料库

    MONOVAB : An Annotated Corpus for Bangla Multi-label Emotion Detection. (arXiv:2309.15670v1 [cs.LG])

    [http://arxiv.org/abs/2309.15670](http://arxiv.org/abs/2309.15670)

    这个研究构建了一个基于孟加拉语的注释语料库，用于多标签情感检测。通过使用基于上下文的方法以及BERT模型，填补了这一学科领域的空白。

    

    近年来，情感分析(SA)和情感识别(ER)在孟加拉语中越来越流行，孟加拉语是世界上第七大使用人数最多的语言。然而，孟加拉语的结构复杂，这使得准确提取情绪变得困难。在这个研究领域中，已经采用了一些不同的方法，例如提取积极和消极情感以及多类情绪。然而，在这种语言中提取多种情绪几乎是未开发的领域，它涉及基于一段文本识别出多种情感。因此，本研究展示了一种基于从Facebook上抓取的数据构建注释语料库的详细方法，以填补这个学科领域的空白，克服挑战。为了使这种注释更有成果，采用了基于上下文的方法。转换器中的双向编码器表示(BERT)。

    In recent years, Sentiment Analysis (SA) and Emotion Recognition (ER) have been increasingly popular in the Bangla language, which is the seventh most spoken language throughout the entire world. However, the language is structurally complicated, which makes this field arduous to extract emotions in an accurate manner. Several distinct approaches such as the extraction of positive and negative sentiments as well as multiclass emotions, have been implemented in this field of study. Nevertheless, the extraction of multiple sentiments is an almost untouched area in this language. Which involves identifying several feelings based on a single piece of text. Therefore, this study demonstrates a thorough method for constructing an annotated corpus based on scrapped data from Facebook to bridge the gaps in this subject area to overcome the challenges. To make this annotation more fruitful, the context-based approach has been used. Bidirectional Encoder Representations from Transformers (BERT),
    
[^17]: 脚本对话与自发对话中的会话反馈：一种比较分析

    Conversational Feedback in Scripted versus Spontaneous Dialogues: A Comparative Analysis. (arXiv:2309.15656v1 [cs.CL])

    [http://arxiv.org/abs/2309.15656](http://arxiv.org/abs/2309.15656)

    本文通过对英语、法语、德语、匈牙利语、意大利语、日语、挪威语和中文的脚本对话和自发对话数据进行量化分析，研究了交流反馈现象。研究发现这些对话类型在交流反馈和落地现象方面存在明显差异。

    

    脚本对话，如电影和电视字幕，构成了会话自然语言处理模型的广泛训练数据源。然而，这些对话的语言特点与自发交互的语料库中观察到的语言特点明显不同。特别是在交流反馈和落地现象（如回应、确认或澄清要求）方面，这种差异尤为明显。这些信号被认为是会话流程的重要组成部分，并由对话参与者用于对彼此之间正在进行的交互的感知提供反馈。本文在英语、法语、德语、匈牙利语、意大利语、日语、挪威语和中文的对话数据基础上，进行了这类交流反馈现象的定量分析。我们提取了词汇统计和使用神经对话行为标记器获得的分类输出。本文的主要发现有两个方面。

    Scripted dialogues such as movie and TV subtitles constitute a widespread source of training data for conversational NLP models. However, the linguistic characteristics of those dialogues are notably different from those observed in corpora of spontaneous interactions. This difference is particularly marked for communicative feedback and grounding phenomena such as backchannels, acknowledgments, or clarification requests. Such signals are known to constitute a key part of the conversation flow and are used by the dialogue participants to provide feedback to one another on their perception of the ongoing interaction. This paper presents a quantitative analysis of such communicative feedback phenomena in both subtitles and spontaneous conversations. Based on dialogue data in English, French, German, Hungarian, Italian, Japanese, Norwegian and Chinese, we extract both lexical statistics and classification outputs obtained with a neural dialogue act tagger. Two main findings of this empiri
    
[^18]: 用大型语言模型进行生成式语音识别错误校正

    Generative Speech Recognition Error Correction with Large Language Models. (arXiv:2309.15649v1 [cs.CL])

    [http://arxiv.org/abs/2309.15649](http://arxiv.org/abs/2309.15649)

    本研究探讨了大型语言模型（LLMs）作为ASR后处理器的能力，通过重新评分和错误校正来提高系统性能。通过使用指令提示和任务激活提示方法，结合上下文学习和微调技术，我们展示了LLMs的泛化能力和有效性。

    

    我们研究了大型语言模型（LLM）作为ASR后处理器的能力，用于重新评分和错误校正。我们的重点是使用指令提示让LLMs执行这些任务而无需微调，我们评估了不同的提示方案，包括零-shot和少-shot的上下文学习，以及一种新颖的任务激活提示（TAP）方法，结合指令和演示。通过在两个领域之外的任务（ATIS和WSJ）上使用预先训练的第一次扫描系统和重新评分输出，我们证明仅通过冻结LLMs的上下文学习进行重新评分可以达到与领域调优的LMs重新评分相竞争的结果。通过将提示技术与微调相结合，我们实现了低于N-best Oracle水平的错误率，展示了LLMs的泛化能力。

    We explore the ability of large language models (LLMs) to act as ASR post-processors that perform rescoring and error correction. Our focus is on instruction prompting to let LLMs perform these task without fine-tuning, for which we evaluate different prompting schemes, both zero- and few-shot in-context learning, and a novel task-activating prompting (TAP) method that combines instruction and demonstration. Using a pre-trained first-pass system and rescoring output on two out-of-domain tasks (ATIS and WSJ), we show that rescoring only by in-context learning with frozen LLMs achieves results that are competitive with rescoring by domain-tuned LMs. By combining prompting techniques with fine-tuning we achieve error rates below the N-best oracle level, showcasing the generalization power of the LLMs.
    
[^19]: NLPBench：评估大型语言模型解决NLP问题

    NLPBench: Evaluating Large Language Models on Solving NLP Problems. (arXiv:2309.15630v1 [cs.CL])

    [http://arxiv.org/abs/2309.15630](http://arxiv.org/abs/2309.15630)

    NLPBench是一个评估大型语言模型解决NLP问题的基准数据集，为填补该领域的研究空白，作者收集了来自耶鲁大学期末考试的378个涵盖多个NLP主题的问题。该研究发现在使用高级提示策略时，大型语言模型的性能可能不稳定，并可能对较小的模型造成负面影响。

    

    大型语言模型（LLMs）的最新发展显示出增强自然语言处理（NLP）能力的潜力。尽管取得了一些成功，但在LLMs的NLP问题解决能力方面仍然缺乏专门的研究。为了填补这个领域的空白，我们提出了一个独特的基准数据集NLPBench，包括378个涵盖各种NLP主题的大学水平NLP问题，这些问题源自耶鲁大学以前的期末考试。NLPBench包括具有上下文的问题，其中多个子问题分享相同的公共信息，并且包括多选题、简答题和数学题等多种问题类型。我们的评估以GPT-3.5/4、PaLM-2和LLAMA-2等LLMs为中心，采用了诸如链式思维（CoT）和思维树（ToT）等高级提示策略。我们的研究揭示了高级提示策略的有效性可能不一致，有时会损害LLMs的性能，特别是在较小的模型（LLA）中。

    Recent developments in large language models (LLMs) have shown promise in enhancing the capabilities of natural language processing (NLP). Despite these successes, there remains a dearth of research dedicated to the NLP problem-solving abilities of LLMs. To fill the gap in this area, we present a unique benchmarking dataset, NLPBench, comprising 378 college-level NLP questions spanning various NLP topics sourced from Yale University's prior final exams. NLPBench includes questions with context, in which multiple sub-questions share the same public information, and diverse question types, including multiple choice, short answer, and math. Our evaluation, centered on LLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting strategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study reveals that the effectiveness of the advanced prompting strategies can be inconsistent, occasionally damaging LLM performance, especially in smaller models like the LLA
    
[^20]: 发展国际多语种会议的自动逐字转录：一种端到端的解决方案

    Developing automatic verbatim transcripts for international multilingual meetings: an end-to-end solution. (arXiv:2309.15609v1 [cs.CL])

    [http://arxiv.org/abs/2309.15609](http://arxiv.org/abs/2309.15609)

    本文提出了一种端到端的解决方案，用于创建全自动的会议记录和多语言翻译，解决了会议管理文档中现有工作流程的替代和改善问题。

    

    本文提出了一种完整的端到端解决方案，用于创建全自动的会议记录和对它们进行多种语言的机器翻译。该工具是在世界知识产权组织（WIPO）开发的、使用其内部开发的语音转文本（S2T）和机器翻译（MT）组件的系统。除了描述数据收集和优化过程，生成高度定制和稳健的系统外，本文还描述了技术组件的架构和演变，并突出了用户方面的商业影响和收益。同时，我们还指出了系统在演进和采用过程中的特殊挑战，并介绍了这种新方法如何创造了一种新产品，并取代了会议管理文档中现有的工作流程。

    This paper presents an end-to-end solution for the creation of fully automated conference meeting transcripts and their machine translations into various languages. This tool has been developed at the World Intellectual Property Organization (WIPO) using in-house developed speech-to-text (S2T) and machine translation (MT) components. Beyond describing data collection and fine-tuning, resulting in a highly customized and robust system, this paper describes the architecture and evolution of the technical components as well as highlights the business impact and benefits from the user side. We also point out particular challenges in the evolution and adoption of the system and how the new approach created a new product and replaced existing established workflows in conference management documentation.
    
[^21]: 利用句级加权和标签增强的原型网络进行少样本多标签方面类别检测

    Few-Shot Multi-Label Aspect Category Detection Utilizing Prototypical Network with Sentence-Level Weighting and Label Augmentation. (arXiv:2309.15588v1 [cs.CL])

    [http://arxiv.org/abs/2309.15588](http://arxiv.org/abs/2309.15588)

    本论文提出了一种利用支持集注意力和增强的标签信息的原型网络，用于解决少样本多标签方面类别检测问题。通过添加句子级注意力机制和标签增强，可以更好地表示实例之间的变化和贡献。

    

    多标签方面类别检测旨在检测给定句子中出现的多个方面类别。由于数据集和数据稀疏性的限制，原型网络和注意机制已被应用于少样本方面类别检测。然而，目前大多数使用的原型网络计算支持集中实例的平均值，忽略了多标签方面类别检测中的实例间的变化。此外，一些相关工作利用标签文本信息来增强注意机制，但标签文本信息通常较短且有限，无法足够具体地区分类别。本文首先引入了支持集注意力以及增强的标签信息，以减轻每个支持集实例的单词级噪声。此外，我们使用了句子级注意机制，给予不同实例不同的权重，以更好地表示其贡献。

    Multi-label aspect category detection is intended to detect multiple aspect categories occurring in a given sentence. Since aspect category detection often suffers from limited datasets and data sparsity, the prototypical network with attention mechanisms has been applied for few-shot aspect category detection. Nevertheless, most of the prototypical networks used so far calculate the prototypes by taking the mean value of all the instances in the support set. This seems to ignore the variations between instances in multi-label aspect category detection. Also, several related works utilize label text information to enhance the attention mechanism. However, the label text information is often short and limited, and not specific enough to discern categories. In this paper, we first introduce support set attention along with the augmented label information to mitigate the noise at word-level for each support set instance. Moreover, we use a sentence-level attention mechanism that gives dif
    
[^22]: 共同训练大型自回归多模态模型

    Jointly Training Large Autoregressive Multimodal Models. (arXiv:2309.15564v1 [cs.LG])

    [http://arxiv.org/abs/2309.15564](http://arxiv.org/abs/2309.15564)

    本研究提出了共同训练大型自回归多模态模型的方法，通过模块化的方式融合语言和图像生成模型，同时引入了数据高效的指令调优策略，使得该模型在生成高质量多模态输出方面表现出卓越的性能。

    

    最近几年，语言和文本到图像模型的大规模预训练取得了重大突破，彻底改变了机器学习领域。然而，将这两种模态集成到一个能够生成无缝多模态输出的单一强大模型仍然是一个重大挑战。为了解决这一问题，我们提出了联合自回归混合（JAM）框架，一种系统融合现有文本和图像生成模型的模块化方法。我们还引入了一种专门的、数据高效的指令调优策略，针对混合模态生成任务进行了优化。我们最终的调优模型在生成高质量多模态输出方面表现出无与伦比的性能，并代表了第一个明确为此目的而设计的模型。

    In recent years, advances in the large-scale pretraining of language and text-to-image models have revolutionized the field of machine learning. Yet, integrating these two modalities into a single, robust model capable of generating seamless multimodal outputs remains a significant challenge. To address this gap, we present the Joint Autoregressive Mixture (JAM) framework, a modular approach that systematically fuses existing text and image generation models. We also introduce a specialized, data-efficient instruction-tuning strategy, tailored for mixed-modal generation tasks. Our final instruct-tuned model demonstrates unparalleled performance in generating high-quality multimodal outputs and represents the first model explicitly designed for this purpose.
    
[^23]: 直接模型用于同时翻译和自动字幕生成：FBK在IWSLT2023中的参与

    Direct Models for Simultaneous Translation and Automatic Subtitling: FBK@IWSLT2023. (arXiv:2309.15554v1 [cs.CL])

    [http://arxiv.org/abs/2309.15554](http://arxiv.org/abs/2309.15554)

    本文描述了FBK的研究成果，他们使用直接模型来实现同时翻译和自动字幕生成任务，并在计算感知延迟方面取得了突破性的进展，同时在自动字幕生成任务中也优于现有解决方案。

    

    本文描述了FBK在IWSLT 2023评估活动的同时翻译和自动字幕生成任务中的参与。我们的提交关注于使用直接模型来执行这两个任务：对于同时翻译任务，我们利用已经训练好的离线模型的知识，并直接应用策略来进行实时推理；对于字幕生成任务，我们将直接ST模型调整为生成符合规范的字幕，并利用相同的架构生成与音视频内容同步所需的时间戳。我们的英德SimulST系统在计算感知延迟方面比2021年和2022年的任务中排名靠前的系统有所减少，并获得了高达3.5 BLEU的增益。我们的自动字幕生成系统在英德和英西文对中优于基于直接系统的唯一现有解决方案，分别获得了3.7和1.7的SubER增益。

    This paper describes the FBK's participation in the Simultaneous Translation and Automatic Subtitling tracks of the IWSLT 2023 Evaluation Campaign. Our submission focused on the use of direct architectures to perform both tasks: for the simultaneous one, we leveraged the knowledge already acquired by offline-trained models and directly applied a policy to obtain the real-time inference; for the subtitling one, we adapted the direct ST model to produce well-formed subtitles and exploited the same architecture to produce timestamps needed for the subtitle synchronization with audiovisual content. Our English-German SimulST system shows a reduced computational-aware latency compared to the one achieved by the top-ranked systems in the 2021 and 2022 rounds of the task, with gains of up to 3.5 BLEU. Our automatic subtitling system outperforms the only existing solution based on a direct system by 3.7 and 1.7 SubER in English-German and English-Spanish respectively.
    
[^24]: 教授文本到图像模型进行交流

    Teaching Text-to-Image Models to Communicate. (arXiv:2309.15516v1 [cs.CL])

    [http://arxiv.org/abs/2309.15516](http://arxiv.org/abs/2309.15516)

    本文提出了一种针对对话生成图像的高效方法，通过微调预训练的文本到图像模型，实现在给定对话背景下生成一致逼真的图像。

    

    在文本到图像生成的研究中，各种工作已经得到广泛研究。虽然现有模型在文本到图像生成方面表现良好，但是在直接应用于对话生成图像时存在重大挑战。在本文中，我们首先突出了一个新的问题：对话到图像生成，即在给定对话背景的情况下，模型应该生成一个与指定对话内容一致的逼真图像作为回应。为了解决这个问题，我们提出了一种无需中间转换的高效方法，该方法最大程度地提取对话中包含的语义信息。考虑到对话结构的特点，我们在对话中的每个说话回合之前放置分割标记，以区分不同的发言者。然后，我们对预训练的文本到图像模型进行微调，使其能够根据处理后的对话背景生成图像。经过微调后，我们的方法可以生成与处理后对话环境相一致的图像。

    Various works have been extensively studied in the research of text-to-image generation. Although existing models perform well in text-to-image generation, there are significant challenges when directly employing them to generate images in dialogs. In this paper, we first highlight a new problem: dialog-to-image generation, that is, given the dialog context, the model should generate a realistic image which is consistent with the specified conversation as response. To tackle the problem, we propose an efficient approach for dialog-to-image generation without any intermediate translation, which maximizes the extraction of the semantic information contained in the dialog. Considering the characteristics of dialog structure, we put segment token before each sentence in a turn of a dialog to differentiate different speakers. Then, we fine-tune pre-trained text-to-image models to enable them to generate images conditioning on processed dialog context. After fine-tuning, our approach can con
    
[^25]: 使用最少监督的扩散模型实现高保真度语音合成

    High-Fidelity Speech Synthesis with Minimal Supervision: All Using Diffusion Models. (arXiv:2309.15512v1 [cs.SD])

    [http://arxiv.org/abs/2309.15512](http://arxiv.org/abs/2309.15512)

    提出一种使用最少监督的扩散模型实现高保真度语音合成的方法，通过组合离散语音表示和利用序列到序列任务进行训练，解决了语义表示中的信息冗余和维度爆炸以及离散声学表示中的高频波形失真等问题。该方法中的非自回归框架增强了可控性，而持续时间扩散模型实现了音频的多样化控制。

    

    文字转语音（TTS）方法在语音克隆方面取得了有希望的结果，但需要大量标记的文本-语音对。最小监督的语音合成通过组合两种类型的离散语音表示（语义和声学），并使用两种序列到序列任务，以实现最少监督的训练。然而，现有方法存在语义表示中的信息冗余和维度爆炸，以及离散声学表示中的高频波形失真。自回归框架具有典型的不稳定性和不可控性问题。非自回归框架受到持续预测模型引起的韵律平均化的影响。为了解决这些问题，我们提出了一种最小监督的高保真度语音合成方法，其中所有模块基于扩散模型构建。非自回归框架增强了可控性，而持续时间扩散模型实现了音频的多样化控制。

    Text-to-speech (TTS) methods have shown promising results in voice cloning, but they require a large number of labeled text-speech pairs. Minimally-supervised speech synthesis decouples TTS by combining two types of discrete speech representations(semantic \& acoustic) and using two sequence-to-sequence tasks to enable training with minimal supervision. However, existing methods suffer from information redundancy and dimension explosion in semantic representation, and high-frequency waveform distortion in discrete acoustic representation. Autoregressive frameworks exhibit typical instability and uncontrollability issues. And non-autoregressive frameworks suffer from prosodic averaging caused by duration prediction models. To address these issues, we propose a minimally-supervised high-fidelity speech synthesis method, where all modules are constructed based on the diffusion models. The non-autoregressive framework enhances controllability, and the duration diffusion model enables diver
    
[^26]: VideoAdviser: 视频知识蒸馏用于多模态迁移学习

    VideoAdviser: Video Knowledge Distillation for Multimodal Transfer Learning. (arXiv:2309.15494v1 [cs.CV])

    [http://arxiv.org/abs/2309.15494](http://arxiv.org/abs/2309.15494)

    提出了一个视频知识蒸馏方法 VideoAdviser，通过将多模态视频增强提示的多模态知识从教师模型传输到学生模型，实现高效性能的多模态迁移学习。

    

    多模态迁移学习旨在将不同模态的预训练表示转换为一个共享的领域空间，以实现有效的多模态融合。然而，传统系统通常基于所有模态均存在的假设构建，并且缺乏模态会导致推理性能较差。此外，为所有模态提取预训练嵌入在推理中效率低下。在本文中，为了实现高效性能的多模态迁移学习，我们提出了一种视频知识蒸馏方法 VideoAdviser，将多模态视频增强提示的多模态知识从一个多模态基础模型（教师）传输到一个特定模态的基础模型（学生）。基于专业顾问和聪明学生能够获得最佳学习性能的直觉，我们使用基于CLIP的教师模型通过优化步骤蒸馏，为基于RoBERTa的学生模型提供富有表达力的多模态知识监督信号。

    Multimodal transfer learning aims to transform pretrained representations of diverse modalities into a common domain space for effective multimodal fusion. However, conventional systems are typically built on the assumption that all modalities exist, and the lack of modalities always leads to poor inference performance. Furthermore, extracting pretrained embeddings for all modalities is computationally inefficient for inference. In this work, to achieve high efficiency-performance multimodal transfer learning, we propose VideoAdviser, a video knowledge distillation method to transfer multimodal knowledge of video-enhanced prompts from a multimodal fundamental model (teacher) to a specific modal fundamental model (student). With an intuition that the best learning performance comes with professional advisers and smart students, we use a CLIP-based teacher model to provide expressive multimodal knowledge supervision signals to a RoBERTa-based student model via optimizing a step-distillat
    
[^27]: 动态多尺度上下文聚合用于会话级方面情感四元组分析

    Dynamic Multi-Scale Context Aggregation for Conversational Aspect-Based Sentiment Quadruple Analysis. (arXiv:2309.15476v1 [cs.CL])

    [http://arxiv.org/abs/2309.15476](http://arxiv.org/abs/2309.15476)

    本研究提出了一种名为动态多尺度上下文聚合网络(DMCA)的方法，通过利用对话结构和动态分层聚合模块(DHA)，有效地解决了会话级方面情感四元组分析(DiaASQ)中提取四元组的困难。采用多阶段损失策略进一步提高了模型的性能和泛化能力。

    

    会话级方面情感四元组分析（DiaASQ）旨在提取对话中目标-方面-意见-情感的四元组。在DiaASQ中，四元组的元素经常跨越多个言语。这种情况复杂化了提取过程，强调了对会话上下文和交互的充分理解的需要。然而，现有工作独立地编码每个言语，因此难以捕捉到长范围的会话上下文并忽视了深层的言语间依赖关系。在本文中，我们提出了一种新颖的动态多尺度上下文聚合网络(DMCA)来应对这些挑战。具体而言，我们首先利用对话结构生成多尺度的言语窗口来捕捉丰富的上下文信息。之后，我们设计了一个动态分层聚合模块(DHA)来集成它们之间的渐进线索。此外，我们采用了多阶段损失策略来提高模型的性能和泛化能力。

    Conversational aspect-based sentiment quadruple analysis (DiaASQ) aims to extract the quadruple of target-aspect-opinion-sentiment within a dialogue. In DiaASQ, a quadruple's elements often cross multiple utterances. This situation complicates the extraction process, emphasizing the need for an adequate understanding of conversational context and interactions. However, existing work independently encodes each utterance, thereby struggling to capture long-range conversational context and overlooking the deep inter-utterance dependencies. In this work, we propose a novel Dynamic Multi-scale Context Aggregation network (DMCA) to address the challenges. Specifically, we first utilize dialogue structure to generate multi-scale utterance windows for capturing rich contextual information. After that, we design a Dynamic Hierarchical Aggregation module (DHA) to integrate progressive cues between them. In addition, we form a multi-stage loss strategy to improve model performance and generalizat
    
[^28]: ChatCounselor: 用于心理健康支持的大型语言模型

    ChatCounselor: A Large Language Models for Mental Health Support. (arXiv:2309.15461v1 [cs.CL])

    [http://arxiv.org/abs/2309.15461](http://arxiv.org/abs/2309.15461)

    ChatCounselor是一个用于心理健康支持的大型语言模型，通过对真实对话进行训练和评估，超越了现有模型并接近ChatGPT的性能水平。

    

    本文介绍了ChatCounselor，这是一个设计用于提供心理健康支持的大型语言模型（LLM）解决方案。与通用的聊天机器人不同，ChatCounselor以实际的心理咨询客户与专业心理学家之间的对话为基础，使其具备心理学领域的专业知识和咨询技巧。训练数据集Psych8k是由260个深度访谈构建而成，每个访谈持续一个小时。为了评估咨询回复的质量，设计了咨询Benchmark。利用GPT-4和基于七个心理咨询评估指标的精心设计的提示，对该模型进行了一系列真实咨询问题的评估。令人印象深刻的是，ChatCounselor在咨询Benchmark上超越了现有的开源模型，并接近ChatGPT的性能水平，展示了通过高质量领域特定数据获得的模型能力的显著提升。

    This paper presents ChatCounselor, a large language model (LLM) solution designed to provide mental health support. Unlike generic chatbots, ChatCounselor is distinguished by its foundation in real conversations between consulting clients and professional psychologists, enabling it to possess specialized knowledge and counseling skills in the field of psychology. The training dataset, Psych8k, was constructed from 260 in-depth interviews, each spanning an hour. To assess the quality of counseling responses, the counseling Bench was devised. Leveraging GPT-4 and meticulously crafted prompts based on seven metrics of psychological counseling assessment, the model underwent evaluation using a set of real-world counseling questions. Impressively, ChatCounselor surpasses existing open-source models in the counseling Bench and approaches the performance level of ChatGPT, showcasing the remarkable enhancement in model capability attained through high-quality domain-specific data.
    
[^29]: 使用大型语言模型的图神经提示

    Graph Neural Prompting with Large Language Models. (arXiv:2309.15427v1 [cs.CL])

    [http://arxiv.org/abs/2309.15427](http://arxiv.org/abs/2309.15427)

    本文提出了一种名为图神经提示（GNP）的方法，可以帮助大型语言模型从知识图中学习有益的知识，以弥补它们在准确捕捉和返回基于知识的信息方面的固有限制。

    

    大型语言模型（LLMs）在各种语言建模任务中表现出了卓越的泛化能力和出色的性能，但它们在准确捕捉和返回基于知识的信息方面仍存在固有限制。现有的研究已经探索了利用知识图来通过联合训练和定制模型架构增强语言建模，但是将此应用于LLMs存在参数数量庞大和计算成本高的问题。此外，如何利用预训练的LLMs并避免从头开始训练自定义模型仍然是一个开放的问题。在这项工作中，我们提出了图神经提示（GNP），一种新颖的即插即用方法，可以帮助预训练的LLMs从知识图中学习有益的知识。GNP包括各种设计，包括标准的图神经网络编码器、跨模态汇聚模块、域投影器和自监督链接预测目标。在多个实验中展示了GNP的有效性。

    Large Language Models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. In addition, how to leverage the pre-trained LLMs and avoid training a customized model from scratch remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective. Extensive experiments on multiple
    
[^30]: 关于思维链推理：进展、前沿和未来的调查

    A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future. (arXiv:2309.15402v1 [cs.CL])

    [http://arxiv.org/abs/2309.15402](http://arxiv.org/abs/2309.15402)

    本文首次全面调查了思维链推理领域的研究，涵盖了构建、结构变体和增强技术等方法分类，以及规划、工具使用和提炼等前沿应用。同时讨论了挑战和未来发展方向。这份调查报告对于在思维链推理领域寻求创新的研究人员来说是一个有价值的资源。

    

    思维链推理是人类智能的基本认知过程，在人工智能和自然语言处理领域引起了广泛关注。然而，目前仍缺乏一份全面的调查报告。为此，我们迈出了第一步，仔细广泛地概述了这个研究领域。我们用“X-of-Thought”来指代广义上的思维链推理。具体而言，我们根据方法的分类体系对当前的研究进行了系统组织，包括思维链的构建、结构变体和增强技术。此外，我们描述了思维链在规划、工具使用和提炼等领域的前沿应用。此外，我们还讨论了一些挑战和未来的方向，包括忠实度、多模态和理论等。我们希望这份调查报告能成为寻求在思维链推理领域创新的研究人员的宝贵资源。

    Chain-of-thought reasoning, a cognitive process fundamental to human intelligence, has garnered significant attention in the realm of artificial intelligence and natural language processing. However, there still remains a lack of a comprehensive survey for this arena. To this end, we take the first step and present a thorough survey of this research field carefully and widely. We use X-of-Thought to refer to Chain-of-Thought in a broad sense. In detail, we systematically organize the current research according to the taxonomies of methods, including XoT construction, XoT structure variants, and enhanced XoT. Additionally, we describe XoT with frontier applications, covering planning, tool use, and distillation. Furthermore, we address challenges and discuss some future directions, including faithfulness, multi-modal, and theory. We hope this survey serves as a valuable resource for researchers seeking to innovate within the domain of chain-of-thought reasoning.
    
[^31]: 超越对话：具有LLMs的可执行和可验证的文本编辑

    Beyond the Chat: Executable and Verifiable Text-Editing with LLMs. (arXiv:2309.15337v1 [cs.CL])

    [http://arxiv.org/abs/2309.15337](http://arxiv.org/abs/2309.15337)

    这项研究介绍了InkSync，一个具有LLMs的可执行和可验证的文本编辑界面，可提供对用户编辑建议的透明性和准确性的支持。

    

    最近，由大型语言模型（LLMs）提供支持的对话界面已经成为获取文档编辑反馈的流行方式。然而，标准基于聊天的对话界面不支持编辑建议的透明性和可验证性。为了在与LLM编辑时给予作者更多的自主权，我们提出了InkSync，一种编辑界面，在正在编辑的文档中直接建议可执行编辑。由于已知LLMs会引入事实错误，InkSync还支持一种3阶段的方法来减轻此风险：当建议的编辑引入新信息时，警告作者；通过外部搜索帮助作者验证新信息的准确性；允许审核人员通过跟踪所有自动生成内容的痕迹来对文档进行事后验证。两项可用性研究证实了InkSync的各个组件相比于标准的基于LLM的聊天界面的有效性，从而使得编辑更准确，

    Conversational interfaces powered by Large Language Models (LLMs) have recently become a popular way to obtain feedback during document editing. However, standard chat-based conversational interfaces do not support transparency and verifiability of the editing changes that they suggest. To give the author more agency when editing with an LLM, we present InkSync, an editing interface that suggests executable edits directly within the document being edited. Because LLMs are known to introduce factual errors, Inksync also supports a 3-stage approach to mitigate this risk: Warn authors when a suggested edit introduces new information, help authors Verify the new information's accuracy through external search, and allow an auditor to perform an a-posteriori verification by Auditing the document via a trace of all auto-generated content. Two usability studies confirm the effectiveness of InkSync's components when compared to standard LLM-based chat interfaces, leading to more accurate, more 
    
[^32]: 大规模多语言自监督学习的联合预测和去噪

    joint prediction and denoising for large-scale multilingual self-supervised learning. (arXiv:2309.15317v1 [cs.CL])

    [http://arxiv.org/abs/2309.15317](http://arxiv.org/abs/2309.15317)

    这项研究提出了WavLabLM，它通过联合预测和去噪的方法，实现了在136种语言的40k小时数据上进行大规模多语言自监督学习。WavLabLM的多阶段预训练方法解决了多语言数据的语言失衡问题，使其在ML-SUPERB上达到了与XLS-R相当的性能，同时仅使用不到10%的训练数据，这使得SSL在学术高性能计算上可行。

    

    多语言自监督学习(SSL)由于处理多种语言所需的费用和复杂性而经常落后于最先进的方法。这进一步影响了SSL的可重复性，由于资源使用的限制，SSL已经仅限于少数研究团队。我们展示了更强大的技术实际上可以导致更高效的预训练，从而使更多的研究团队能够加入SSL。我们提出了WavLabLM，将WavLM的联合预测和去噪扩展到136种语言的40k小时数据。为了构建WavLabLM，我们设计了一种新颖的多阶段预训练方法，旨在解决多语言数据的语言失衡问题。WavLabLM在ML-SUPERB上实现了与XLS-R相当的性能，仅使用不到10%的训练数据，使得SSL在学术高性能计算上可实现。我们还展示了vanilla HuBERT Base模型可以实现进一步的效率提升，仅使用3%的数据、4个GPU和有限的试验次数，就能保持94%的XLS-R性能。

    Multilingual self-supervised learning (SSL) has often lagged behind state-of-the-art (SOTA) methods due to the expenses and complexity required to handle many languages. This further harms the reproducibility of SSL, which is already limited to few research groups due to its resource usage. We show that more powerful techniques can actually lead to more efficient pre-training, opening SSL to more research groups. We propose WavLabLM, which extends WavLM's joint prediction and denoising to 40k hours of data across 136 languages. To build WavLabLM, we devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data. WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than 10% of the training data, making SSL realizable with academic compute. We show that further efficiency can be achieved with a vanilla HuBERT Base model, which can maintain 94% of XLS-R's performance with only 3% of the data, 4 GPUs, and limited trials. 
    
[^33]: 使用生成的特权信息学习通过文本到图像扩散模型

    Learning Using Generated Privileged Information by Text-to-Image Diffusion Models. (arXiv:2309.15238v1 [cs.CL])

    [http://arxiv.org/abs/2309.15238](http://arxiv.org/abs/2309.15238)

    本研究提出了一种利用生成的特权信息进行学习的框架，通过文本到图像扩散模型生成合成数据作为特权信息，进一步提升了学生模型在文本分类任务中的性能。

    

    使用生成的特权信息进行学习是一种特殊类型的知识蒸馏，其中教师模型在训练过程中从额外的数据表示中获益，这被称为特权信息，并改善了不看到额外表示的学生模型。然而，在实践中很少可获得特权信息。为此，我们提出了一种文本分类框架，利用文本到图像扩散模型生成人工特权信息。生成的图像和原始文本样本进一步用于基于最先进的基于转换器的架构来训练多模态教师模型。最后，多模态教师的知识被蒸馏到基于文本的（单模态）学生模型中。因此，通过使用生成模型产生合成数据作为特权信息，我们引导学生模型的训练。我们的框架称为利用生成的特权信息进行学习（LUGPI），可以显著提高性能。

    Learning Using Privileged Information is a particular type of knowledge distillation where the teacher model benefits from an additional data representation during training, called privileged information, improving the student model, which does not see the extra representation. However, privileged information is rarely available in practice. To this end, we propose a text classification framework that harnesses text-to-image diffusion models to generate artificial privileged information. The generated images and the original text samples are further used to train multimodal teacher models based on state-of-the-art transformer-based architectures. Finally, the knowledge from multimodal teachers is distilled into a text-based (unimodal) student. Hence, by employing a generative model to produce synthetic data as privileged information, we guide the training of the student model. Our framework, called Learning Using Generated Privileged Information (LUGPI), yields noticeable performance g
    
[^34]: 大规模语言模型重评分的低秩适应技术在参数高效的语音识别中的应用

    Low-rank Adaptation of Large Language Model Rescoring for Parameter-Efficient Speech Recognition. (arXiv:2309.15223v1 [cs.CL])

    [http://arxiv.org/abs/2309.15223](http://arxiv.org/abs/2309.15223)

    这篇论文介绍了一种基于低秩适应技术的神经语言建模系统，用于语音识别的输出重评分。通过使用低秩分解方法和优化插入矩阵，该系统能够以更高效的方式将BERT模型适应到新领域，大大减少了训练时间。

    

    我们提出了一种基于低秩适应（LoRA）的神经语言建模系统，用于语音识别输出重评分。尽管预训练的语言模型（如BERT）在第二次重评分中表现出优越的性能，但将预训练阶段扩展和将预训练模型适应到特定领域的高计算成本限制了它们在重评分中的实际应用。我们提出了一种基于低秩分解的方法，仅使用预训练参数的一小部分（0.08%）来训练重评分的BERT模型并将其适应到新领域。这些插入的矩阵通过相关性正则化损失和判别性训练目标进行优化。所提出的低秩适应Rescore-BERT（LoRB）体系结构在LibriSpeech和内部数据集上评估，训练时间减少了5.4至3.6倍。

    We propose a neural language modeling system based on low-rank adaptation (LoRA) for speech recognition output rescoring. Although pretrained language models (LMs) like BERT have shown superior performance in second-pass rescoring, the high computational cost of scaling up the pretraining stage and adapting the pretrained models to specific domains limit their practical use in rescoring. Here we present a method based on low-rank decomposition to train a rescoring BERT model and adapt it to new domains using only a fraction (0.08%) of the pretrained parameters. These inserted matrices are optimized through a discriminative training objective along with a correlation-based regularization loss. The proposed low-rank adaptation Rescore-BERT (LoRB) architecture is evaluated on LibriSpeech and internal datasets with decreased training times by factors between 5.4 and 3.6.
    
[^35]: RAGAS:自动评估检索增强生成

    RAGAS: Automated Evaluation of Retrieval Augmented Generation. (arXiv:2309.15217v1 [cs.CL])

    [http://arxiv.org/abs/2309.15217](http://arxiv.org/abs/2309.15217)

    RAGAs是一个用于无参考评估检索增强生成（RAG）的框架，能够评估检索系统和生成模块的能力，提供一种加快RAG架构评估周期的方法。

    

    我们介绍了RAGAs（检索增强生成评估）框架，用于对检索增强生成（RAG）流水线进行无参考评估。RAG系统由检索模块和基于LLM的生成模块组成，提供来自参考文本数据库的知识给LLMs，使它们能够充当用户和文本数据库之间的自然语言层，减少幻觉的风险。然而，评估RAG架构是具有挑战性的，因为有几个维度需要考虑：检索系统识别相关和有重点的上下文段落的能力，LLM在忠实地利用这些段落的能力，以及生成本身的质量。通过RAGAs，我们提出了一套度量标准，可以用来评估这些不同维度，而无需依赖地面真实的人类注释。我们认为，这样的框架能够对RAG架构的更快评估周期起到至关重要的贡献。

    We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAG systems are composed of a retrieval and an LLM based generation module, and provide LLMs with knowledge from a reference textual database, which enables them to act as a natural language layer between a user and textual databases, reducing the risk of hallucinations. Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself. With RAGAs, we put forward a suite of metrics which can be used to evaluate these different dimensions \textit{without having to rely on ground truth human annotations}. We posit that such a framework can crucially contribute to faster evaluation cycles of RAG architectur
    
[^36]: STANCE-C3: 通过对比学习和反事实生成进行领域自适应的跨目标立场检测

    STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation. (arXiv:2309.15176v1 [cs.CL])

    [http://arxiv.org/abs/2309.15176](http://arxiv.org/abs/2309.15176)

    STANCE-C3是一种通过对比学习和反事实生成进行领域自适应的跨目标立场检测模型，用于推断人们对于普遍或有争议话题的观点。在解决数据分布偏移和缺乏领域特定标注数据的挑战上具有重要贡献。

    

    立场检测是通过推断一个人在特定问题上的立场或观点，以推断对于普遍或有争议的话题的普遍看法，例如COVID-19疫情期间的健康政策。现有的立场检测模型在训练时往往在单个领域（例如COVID-19）和特定目标话题（例如口罩规定）上表现良好，但在其他领域或目标中往往表现不佳，这是由于数据的分布偏移。然而，构建高性能的领域特定立场检测模型需要大量与目标领域相关的已标注数据，但这样的数据集往往不容易获取。这就面临着一个挑战，因为标注数据的过程代价高昂且耗时。为了应对这些挑战，我们提出了一种新颖的立场检测模型，称为通过对比学习和反事实生成进行领域自适应的跨目标立场检测（STANCE-C3）。

    Stance detection is the process of inferring a person's position or standpoint on a specific issue to deduce prevailing perceptions toward topics of general or controversial interest, such as health policies during the COVID-19 pandemic. Existing models for stance detection are trained to perform well for a single domain (e.g., COVID-19) and a specific target topic (e.g., masking protocols), but are generally ineffectual in other domains or targets due to distributional shifts in the data. However, constructing high-performing, domain-specific stance detection models requires an extensive corpus of labeled data relevant to the targeted domain, yet such datasets are not readily available. This poses a challenge as the process of annotating data is costly and time-consuming. To address these challenges, we introduce a novel stance detection model coined domain-adaptive Cross-target STANCE detection via Contrastive learning and Counterfactual generation (STANCE-C3) that uses counterfactua
    
[^37]: 用CogEval评估大型语言模型中的认知地图和规划能力

    Evaluating Cognitive Maps and Planning in Large Language Models with CogEval. (arXiv:2309.15129v1 [cs.AI])

    [http://arxiv.org/abs/2309.15129](http://arxiv.org/abs/2309.15129)

    这项研究提出了CogEval协议，用于系统评估大型语言模型的认知能力，并使用该协议对八个LLMs的认知地图和规划能力进行了评估。

    

    最近，大量的研究声称大型语言模型（LLMs）具有新兴的认知能力。然而，大多数研究依赖于案例，忽视了训练集的污染，或者缺乏涉及多个任务、控制条件、多次迭代和统计鲁棒性测试的系统评估。在这里，我们做出了两个重大贡献。首先，我们提出了CogEval，这是一个受认知科学启发的协议，用于对大型语言模型的认知能力进行系统评估。CogEval协议可以用于评估各种能力。其次，我们使用CogEval协议对八个LLMs（OpenAI GPT-4、GPT-3.5-turbo-175B、davinci-003-175B、Google Bard、Cohere-xlarge-52.4B、Anthropic Claude-1-52B、LLaMA-13B和Alpaca-7B）的认知地图和规划能力进行了系统评估。我们的任务提示基于人类实验，既具有评估规划的已建立构造效度，又不存在于LLM的训练集中。我们发现，尽管LLMs展示了一些

    Recently an influx of studies claim emergent cognitive abilities in large language models (LLMs). Yet, most rely on anecdotes, overlook contamination of training sets, or lack systematic Evaluation involving multiple tasks, control conditions, multiple iterations, and statistical robustness tests. Here we make two major contributions. First, we propose CogEval, a cognitive science-inspired protocol for the systematic evaluation of cognitive capacities in Large Language Models. The CogEval protocol can be followed for the evaluation of various abilities. Second, here we follow CogEval to systematically evaluate cognitive maps and planning ability across eight LLMs (OpenAI GPT-4, GPT-3.5-turbo-175B, davinci-003-175B, Google Bard, Cohere-xlarge-52.4B, Anthropic Claude-1-52B, LLaMA-13B, and Alpaca-7B). We base our task prompts on human experiments, which offer both established construct validity for evaluating planning, and are absent from LLM training sets. We find that, while LLMs show a
    
[^38]: QA-LoRA: 基于量化意识的大语言模型低秩适应

    QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models. (arXiv:2309.14717v1 [cs.LG])

    [http://arxiv.org/abs/2309.14717](http://arxiv.org/abs/2309.14717)

    本文提出了QA-LoRA算法，它通过使用量化意识以及组内运算符来实现大语言模型的低秩适应。QA-LoRA能够将模型权重量化以减少时间和内存的使用，同时在不损失准确性的情况下将模型集成为一个量化模型。

    

    近年来，大型语言模型（LLMs）得到了快速发展。尽管在许多语言理解任务中具有强大的能力，但沉重的计算负担在很大程度上限制了LLMs的应用，特别是当需要将它们部署到边缘设备时。本文提出了一种基于量化意识的低秩适应（QA-LoRA）算法。动机在于量化和适应的自由度不平衡，解决方案是使用组内运算符，增加量化的自由度，同时减少适应的自由度。QA-LoRA可以用几行代码轻松实现，并使原始的LoRA具备了两个能力：（i）在微调过程中，LLM的权重被量化（例如转换为INT4），以减少时间和内存的使用；（ii）经过微调后，LLM和辅助权重自然地集成到一个量化模型中，而不会损失准确性。我们将QA-LoRA应用到LLaMA和LLaMA2模型家族中。

    Recently years have witnessed a rapid development of large language models (LLMs). Despite the strong ability in many language-understanding tasks, the heavy computational burden largely restricts the application of LLMs especially when one needs to deploy them onto edge devices. In this paper, we propose a quantization-aware low-rank adaptation (QA-LoRA) algorithm. The motivation lies in the imbalanced degrees of freedom of quantization and adaptation, and the solution is to use group-wise operators which increase the degree of freedom of quantization meanwhile decreasing that of adaptation. QA-LoRA is easily implemented with a few lines of code, and it equips the original LoRA with two-fold abilities: (i) during fine-tuning, the LLM's weights are quantized (e.g., into INT4) to reduce time and memory usage; (ii) after fine-tuning, the LLM and auxiliary weights are naturally integrated into a quantized model without loss of accuracy. We apply QA-LoRA to the LLaMA and LLaMA2 model famil
    
[^39]: 看见和听到没被说的话：可解释融合的多模态动机性访谈客户行为分类器

    Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion. (arXiv:2309.14398v1 [cs.LG])

    [http://arxiv.org/abs/2309.14398](http://arxiv.org/abs/2309.14398)

    本文提出了一个多模态分类器，在动机性访谈中准确区分了变化话语、持续话语和跟随/中立话语三种类别。该分类器利用文本、声调、面部表情和身体表现等多模态特征，并对AnnoMI数据集进行了注释和训练。研究还找到了决策过程中最重要的模态，提供了宝贵的洞察。

    

    动机性访谈（MI）是一种强调合作并鼓励行为改变的治疗方法。为了评估MI对话的质量，可以利用MISC代码将客户话语分类为变化话语、持续话语或跟随/中立话语。MI对话中变化话语的比例与治疗结果呈正相关，因此准确分类客户话语至关重要。本文提出了一个分类器，利用文本、声调、面部表情和身体表现等多模态特征准确区分三个MISC类别（变化话语、持续话语和跟随/中立话语）。为了训练我们的模型，我们对公开可用的AnnoMI数据集进行注释，收集了文本、音频、面部表情和身体表现等多模态信息。此外，我们还确定了决策过程中最重要的模态，提供了宝贵的洞察。

    Motivational Interviewing (MI) is an approach to therapy that emphasizes collaboration and encourages behavioral change. To evaluate the quality of an MI conversation, client utterances can be classified using the MISC code as either change talk, sustain talk, or follow/neutral talk. The proportion of change talk in a MI conversation is positively correlated with therapy outcomes, making accurate classification of client utterances essential. In this paper, we present a classifier that accurately distinguishes between the three MISC classes (change talk, sustain talk, and follow/neutral talk) leveraging multimodal features such as text, prosody, facial expressivity, and body expressivity. To train our model, we perform annotations on the publicly available AnnoMI dataset to collect multimodal information, including text, audio, facial expressivity, and body expressivity. Furthermore, we identify the most important modalities in the decision-making process, providing valuable insights i
    
[^40]: ALLURE: 基于迭代上下文学习的文本评估的审计和改进

    ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning. (arXiv:2309.13701v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.13701](http://arxiv.org/abs/2309.13701)

    ALLURE是一种基于迭代上下文学习的文本评估的审计和改进方法，通过与注释数据进行比较并纳入重大偏差的实例，使用上下文学习提高LLM对文本的评估能力。

    

    从评分论文到总结医疗文件，大型语言模型（LLM）越来越多地用于评估由人类和人工智能生成的文本。然而，尽管它们具有广泛的实用性，LLM存在着明显的失败模式，需要对其文本评估能力进行彻底审计和改进。在这里，我们介绍了ALLURE，一种系统的方法，用于审计大型语言模型的理解和推理错误。ALLURE涉及将LLM生成的评估与注释数据进行比较，并迭代地将重大偏差的实例纳入评估器中，利用上下文学习（ICL）提高和改进LLM对文本的鲁棒评估。通过这个迭代过程，我们改善了评估器LLM的性能，从而减少了在评估过程中对人工标注者的依赖。我们预计ALLURE将在与文本数据评估相关的各个领域，如医学概括等，为LLM的各种应用提供服务。

    From grading papers to summarizing medical documents, large language models (LLMs) are evermore used for evaluation of text generated by humans and AI alike. However, despite their extensive utility, LLMs exhibit distinct failure modes, necessitating a thorough audit and improvement of their text evaluation capabilities. Here we introduce ALLURE, a systematic approach to Auditing Large Language Models Understanding and Reasoning Errors. ALLURE involves comparing LLM-generated evaluations with annotated data, and iteratively incorporating instances of significant deviation into the evaluator, which leverages in-context learning (ICL) to enhance and improve robust evaluation of text by LLMs. Through this iterative process, we refine the performance of the evaluator LLM, ultimately reducing reliance on human annotators in the evaluation process. We anticipate ALLURE to serve diverse applications of LLMs in various domains related to evaluation of textual data, such as medical summarizatio
    
[^41]: SLHCat: 利用语义、词汇和层次特征将Wikipedia的分类和列表映射到DBpedia

    SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features. (arXiv:2309.11791v1 [cs.DL])

    [http://arxiv.org/abs/2309.11791](http://arxiv.org/abs/2309.11791)

    这项研究提出了一种方法，通过结合知识图谱的结构信息和本体类名的语义和词汇特征，将Wikipedia的分类和列表映射到DBpedia，以构建一个完善和细粒度的知识图谱。

    

    Wikipedia的文章通过分类和列表进行层次化组织，提供了其中一个最全面和普遍的分类系统，但其开放性导致了重复和不一致的问题。将DBpedia的类别分配给Wikipedia的分类和列表可以缓解这个问题，实现一个对实体链接和类型分类数字内容至关重要的大型知识图谱。然而，现有的CaLiGraph方法产生了不完整和非细粒度的映射。在本文中，我们将这个问题看作本体对齐，利用知识图谱的结构信息和本体类名的词汇和语义特征，发现自信映射，然后利用这些映射以远程监督方式对预训练的语言模型进行微调。我们的方法SLHCat包括两个主要部分：1）通过利用知识图谱的结构、语义相似性和命名实体自动生成训练数据

    Wikipedia articles are hierarchically organized through categories and lists, providing one of the most comprehensive and universal taxonomy, but its open creation is causing redundancies and inconsistencies. Assigning DBPedia classes to Wikipedia categories and lists can alleviate the problem, realizing a large knowledge graph which is essential for categorizing digital contents through entity linking and typing. However, the existing approach of CaLiGraph is producing incomplete and non-fine grained mappings. In this paper, we tackle the problem as ontology alignment, where structural information of knowledge graphs and lexical and semantic features of ontology class names are utilized to discover confident mappings, which are in turn utilized for finetuing pretrained language models in a distant supervision fashion. Our method SLHCat consists of two main parts: 1) Automatically generating training data by leveraging knowledge graph structure, semantic similarities, and named entity 
    
[^42]: 大型语言模型对单词级扰动真的具有鲁棒性吗？

    Are Large Language Models Really Robust to Word-Level Perturbations?. (arXiv:2309.11166v1 [cs.CL])

    [http://arxiv.org/abs/2309.11166](http://arxiv.org/abs/2309.11166)

    该论文提出了一种用于评估大型语言模型（LLMs）鲁棒性的新颖方法，使用预训练的奖励模型作为诊断工具。实验证明这种方法在评估LLM鲁棒性方面表现准确。

    

    大型语言模型（LLMs）在规模和能力上的快速发展使它们成为各种下游任务的有前途的工具。除了追求更好的性能和避免对特定提示的激烈反馈外，确保LLM的责任性还需要关注LLMs的鲁棒性。然而，现有的评估方法大多依赖于具有预定义监督标签的传统问答数据集，这与当代LLMs的出色生成能力不一致。为了解决这个问题，我们提出了一种新颖的合理评估方法，利用预训练的奖励模型作为诊断工具来评估LLMs的鲁棒性，我们将其称为合理鲁棒性评估的奖励模型（TREvaL）。我们广泛的实证实验表明，TREval提供了一种准确评估LLM鲁棒性的方法，特别是面对更具挑战性的开放式问题时。

    The swift advancement in the scale and capabilities of Large Language Models (LLMs) positions them as promising tools for a variety of downstream tasks. In addition to the pursuit of better performance and the avoidance of violent feedback on a certain prompt, to ensure the responsibility of the LLM, much attention is drawn to the robustness of LLMs. However, existing evaluation methods mostly rely on traditional question answering datasets with predefined supervised labels, which do not align with the superior generation capabilities of contemporary LLMs. To address this issue, we propose a novel rational evaluation approach that leverages pre-trained reward models as diagnostic tools to evaluate the robustness of LLMs, which we refer to as the Reward Model for Reasonable Robustness Evaluation (TREvaL). Our extensive empirical experiments have demonstrated that TREval provides an accurate method for evaluating the robustness of an LLM, especially when faced with more challenging open 
    
[^43]: MBR和QE微调：对最佳和最昂贵的解码方法进行训练时蒸馏

    MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods. (arXiv:2309.10966v1 [cs.CL])

    [http://arxiv.org/abs/2309.10966](http://arxiv.org/abs/2309.10966)

    本文提出了MBR微调和QE微调方法，将训练时的质量提升蒸馏到基准模型中，从而在推断时使用高效的解码算法。实验证明，这些微调方法能显著提升模型性能，甚至超过基准模型。

    

    最近在自然语言生成（NLG）任务的解码方法研究中表明，传统的波束搜索和贪婪解码算法并不是最优的，因为模型概率不总是与人类偏好一致。为了解决模型困惑度与质量不匹配的问题，提出了一些更强的解码方法，包括质量估计（QE）重排序和最小贝叶斯风险（MBR）解码。尽管这些解码方法实现了最先进的性能，但计算成本过高。在这项工作中，我们提出了MBR微调和QE微调，这些微调方法在训练时蒸馏了这些解码方法的质量提升，在推断时使用高效的解码算法。通过使用神经机器翻译（NMT）这一典型的NLG任务，我们表明即使进行自训练，这些微调方法的性能仍明显优于基准模型。此外，当使用外部LLM作为教师模型时，这些微调方法也表现出了卓越的性能。

    Recent research in decoding methods for Natural Language Generation (NLG) tasks has shown that the traditional beam search and greedy decoding algorithms are not optimal, because model probabilities do not always align with human preferences. Stronger decoding methods, including Quality Estimation (QE) reranking and Minimum Bayes' Risk (MBR) decoding, have since been proposed to mitigate the model-perplexity-vs-quality mismatch. While these decoding methods achieve state-of-the-art performance, they are prohibitively expensive to compute. In this work, we propose MBR finetuning and QE finetuning which distill the quality gains from these decoding methods at training time, while using an efficient decoding algorithm at inference time. Using the canonical NLG task of Neural Machine Translation (NMT), we show that even with self-training, these finetuning methods significantly outperform the base model. Moreover, when using an external LLM as a teacher model, these finetuning methods outp
    
[^44]: 通过困惑度估计污染：量化语言模型评估中的记忆化

    Estimating Contamination via Perplexity: Quantifying Memorisation in Language Model Evaluation. (arXiv:2309.10677v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.10677](http://arxiv.org/abs/2309.10677)

    本文提出了一种新方法，通过困惑度来量化语言模型评估中的污染，而不需要访问完整的训练数据。研究表明，最近的基础模型在阅读理解和摘要基准中存在显著的记忆化，而多项选择问题则受污染较少。

    

    在模型评估中，数据污染变得越来越普遍，因为大型语言模型的大规模训练语料库经常无意中包含基准样本。因此，污染分析已成为可靠模型评估不可避免的一部分。然而，现有的污染分析方法需要访问整个训练数据，这通常对于最新模型来说是保密的。这阻止了社区对这些模型进行严格审计和准确评估其能力。在本文中，我们提出了一种新的方法来在不访问完整训练集的情况下量化污染，即用困惑度来衡量污染的程度。我们的分析提供了证据，表明最近的基础模型在受欢迎的阅读理解和摘要基准中存在显著的记忆化，而多项选择似乎没有那么受污染。

    Data contamination in model evaluation is getting increasingly prevalent as the massive training corpora of large language models often unintentionally include benchmark samples. Therefore, contamination analysis has became an inevitable part of reliable model evaluation. However, existing method of contamination analysis requires the access of the entire training data which is often confidential for recent models. This prevent the community to rigorously audit these models and conduct accurate assessment of their capability. In this paper, we propose a novel method to quantify contamination without the access of the full training set, that measure the extent of contamination with perplexity. Our analysis provides evidence of significant memorisation of recent foundation models in popular reading comprehension, summarisation benchmarks, while multiple choice appears less contaminated.
    
[^45]: 损失突然下降：语法习得、相变和MLM中的简化偏差

    Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs. (arXiv:2309.07311v1 [cs.CL])

    [http://arxiv.org/abs/2309.07311](http://arxiv.org/abs/2309.07311)

    本文通过对掩码语言模型中的语法习得进行案例研究，发现在训练的一个短暂窗口内，模型突然获得了语法注意结构(SAS)，并伴随着损失的陡峭下降。SAS对随后习得语言能力起到了重要的促进作用。

    

    自然语言处理(NLP)中的大多数可解释性研究侧重于理解完全训练模型的行为和特征。然而，通过观察训练过程的轨迹，可能才能获得对模型行为的某些洞察。在本文中，我们通过对掩码语言模型(MLMs)中的语法习得进行案例研究，展示了如何通过分析训练过程中可解释性的演化来加深我们对新兴行为的理解。具体而言，我们研究了语法注意结构(SAS)，这是MLMs中自然形成的一个特性，其中特定的Transformer头倾向于关注特定的句法关系。我们发现在训练的一个短暂窗口内，模型突然获得了SAS，并发现这个窗口与损失的陡峭下降同时发生。此外，SAS促使了随后对语言能力的习得。然后，我们通过引入一个正则化项来操纵训练过程中的SAS，来研究SAS的因果作用，并进行了实验证明。

    Most interpretability research in NLP focuses on understanding the behavior and features of a fully trained model. However, certain insights into model behavior may only be accessible by observing the trajectory of the training process. In this paper, we present a case study of syntax acquisition in masked language models (MLMs). Our findings demonstrate how analyzing the evolution of interpretable artifacts throughout training deepens our understanding of emergent behavior. In particular, we study Syntactic Attention Structure (SAS), a naturally emerging property of MLMs wherein specific Transformer heads tend to focus on specific syntactic relations. We identify a brief window in training when models abruptly acquire SAS and find that this window is concurrent with a steep drop in loss. Moreover, SAS precipitates the subsequent acquisition of linguistic capabilities. We then examine the causal role of SAS by introducing a regularizer to manipulate SAS during training, and demonstrate
    
[^46]: 通过拆分和重排BART微调来增强关键短语生成

    Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling. (arXiv:2309.06726v1 [cs.CL])

    [http://arxiv.org/abs/2309.06726](http://arxiv.org/abs/2309.06726)

    本文提出了关注关键短语的BART模型(Keyphrase-Focused BART)，通过拆分和重排的方式来增强关键短语生成的性能。在不出现的关键短语生成任务中，该模型在两个关键短语生成基准数据集上取得了新的最佳得分。

    

    关键短语生成是一项识别最佳代表给定文本主题或主题的短语集的任务。关键短语分为出现和不在出现的关键短语。最近利用序列到序列模型的方法在不出现的关键短语生成上显示出了效果。然而，由于找到不出现的关键短语的难度，性能仍然有限。在本文中，我们提出了关注关键短语的BART模型(Keyphrase-Focused BART)，利用了出现和不出现关键短语生成之间的差异，并对出现和不出现关键短语分别进行了两个独立BART模型的微调。我们进一步展示了关键短语的重排和候选关键短语排序的有效方法。对于不出现的关键短语，在五个关键短语生成基准数据集中，我们的关注关键短语的BART在F1@5上取得了新的最佳得分。

    Keyphrase generation is a task of identifying a set of phrases that best repre-sent the main topics or themes of a given text. Keyphrases are dividend int pre-sent and absent keyphrases. Recent approaches utilizing sequence-to-sequence models show effectiveness on absent keyphrase generation. However, the per-formance is still limited due to the hardness of finding absent keyphrases. In this paper, we propose Keyphrase-Focused BART, which exploits the differ-ences between present and absent keyphrase generations, and performs fine-tuning of two separate BART models for present and absent keyphrases. We further show effective approaches of shuffling keyphrases and candidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART achieved new state-of-the-art score on F1@5 in two out of five keyphrase gen-eration benchmark datasets.
    
[^47]: 语言代理的认知架构

    Cognitive Architectures for Language Agents. (arXiv:2309.02427v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.02427](http://arxiv.org/abs/2309.02427)

    本文提出了一种称为CoALA的认知架构，用于组织语言代理的现有研究并规划未来的发展方向。CoALA描述了一个具有模块化记忆组件、结构化行动空间和通用决策过程的语言代理。通过这一框架，有望发展出更强大的语言代理。

    

    最近的研究在大规模语言模型（LLMs）中增加了外部资源（例如互联网）或内部控制流（例如提示链），用于需要基于语境或推理的任务，从而产生了一类新的语言代理。尽管这些代理取得了实证成功，但我们缺乏一个系统的框架来组织现有代理并规划未来的发展。在本文中，我们借鉴了认知科学和符号人工智能的丰富历史，提出了语言代理的认知架构（CoALA）。CoALA描述了一个具有模块化记忆组件、用于与内部记忆和外部环境交互的结构化行动空间以及选择行动的通用决策过程的语言代理。我们使用CoALA对最近的大量研究进行了回顾和组织，并展望了更强大代理的可行方向。总的来说，CoALA将当今的语言代理置于上下文中。

    Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a systematic framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within th
    
[^48]: CPSP: 从音素监督中学习语音概念

    CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])

    [http://arxiv.org/abs/2309.00424](http://arxiv.org/abs/2309.00424)

    论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。

    

    对于诸如最小监督的文本转语音（TTS）、语音转换（VC）和自动语音识别（ASR）等细粒度生成和识别任务，从语音中提取的中间表示应包含介于文本编码和声学编码之间的信息。语言内容突出，而发言人身份和声学细节等语音信息应该被去除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余性过高和维度爆炸的问题。此外，音频领域中现有的对比学习方法主要关注提取用于下游音频分类任务的全局描述信息，不适合TTS、VC和ASR任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练（CPSP）的方法，该方法使用三个编码器、一个解码器和对比学习来将音素和语音信息相结合。

    For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representation extracted from speech should contain information that is between text coding and acoustic coding. The linguistic content is salient, while the paralinguistic information such as speaker identity and acoustic details should be removed. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Additionally, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named Contrastive Phoneme-Speech Pretraining (CPSP), which uses three encoders, one decoder, and contrastive learning to bring phoneme and speech
    
[^49]: DS4DH在#SMM4H 2023上：使用句子转换和倒数排名融合进行零样本不良药物事件规范化

    DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using Sentence Transformers and Reciprocal-Rank Fusion. (arXiv:2308.12877v1 [cs.CL])

    [http://arxiv.org/abs/2308.12877](http://arxiv.org/abs/2308.12877)

    本文介绍了DS4DH在#SMM4H 2023中开发的不良药物事件规范化系统的性能评估，该系统利用句子转换和倒数排名融合进行零样本规范化。实验结果表明该方法在共享任务中表现优异，可有效应用于社交媒体文本挖掘中的不良药物事件规范化。

    

    本文概述了由数据科学与数字健康团队开发的用于社交媒体挖掘健康应用2023共享任务5的不良药物事件规范化系统的性能评估。共享任务5旨在将Twitter中的不良药物事件提及标准化为医疗法规活动术语字典中的标准概念。我们的系统采用两阶段方法：BERT微调实体识别，然后使用句子转换和倒数排名融合进行零样本规范化。该方法的精确度为44.9%，召回率为40.5%，F1分数为42.6%。它的性能超过了共享任务5中位数表现10%，并在所有参与者中展示了最高性能。这些结果证实了我们方法的有效性和在社交媒体文本挖掘领域中进行不良药物事件规范化的潜在应用。

    This paper outlines the performance evaluation of a system for adverse drug event normalization, developed by the Data Science for Digital Health group for the Social Media Mining for Health Applications 2023 shared task 5. Shared task 5 targeted the normalization of adverse drug event mentions in Twitter to standard concepts from the Medical Dictionary for Regulatory Activities terminology. Our system hinges on a two-stage approach: BERT fine-tuning for entity recognition, followed by zero-shot normalization using sentence transformers and reciprocal-rank fusion. The approach yielded a precision of 44.9%, recall of 40.5%, and an F1-score of 42.6%. It outperformed the median performance in shared task 5 by 10% and demonstrated the highest performance among all participants. These results substantiate the effectiveness of our approach and its potential application for adverse drug event normalization in the realm of social media text mining.
    
[^50]: 超越识别：用于语言模型的多位水印技术

    Advancing Beyond Identification: Multi-bit Watermark for Language Models. (arXiv:2308.00221v1 [cs.CL])

    [http://arxiv.org/abs/2308.00221](http://arxiv.org/abs/2308.00221)

    本研究提出了一种用于语言模型的多位水印技术——COLOR，可在语言模型生成过程中嵌入可追踪的多位信息，实现了提取水印、即时嵌入和维持文本质量等功能，同时允许零位检测。初步实验显示成功在中等长度的文本中嵌入了32位消息，准确率为91.9％。这项研究有效推进了对语言模型滥用的反制策略。

    

    本研究旨在积极应对大型语言模型在检测机器生成文本方面的滥用。尽管现有方法侧重于检测，但某些恶意滥用需要跟踪对手用户以进行反制。为了解决这个问题，我们提出了“多位水印通过颜色编码”（COLOR）的方法，在语言模型生成过程中嵌入可追踪的多位信息。利用零位水印技术的优势（Kirchenbauer等，2023a），COLOR实现了在没有模型访问权限的情况下提取水印、即时嵌入和维持文本质量的能力，同时允许零位检测。初步实验表明，在中等长度的文本（约500个标记）中成功嵌入了32位消息，准确率为91.9％。这项工作有效地推进了对语言模型滥用进行反制的策略。

    This study aims to proactively tackle misuse of large language models beyond identification of machine-generated text. While existing methods focus on detection, some malicious misuses demand tracing the adversary user for counteracting them. To address this, we propose "Multi-bit Watermark through Color-listing" (COLOR), embedding traceable multi-bit information during language model generation. Leveraging the benefits of zero-bit watermarking (Kirchenbauer et al., 2023a), COLOR enables extraction without model access, on-the-fly embedding, and maintains text quality, while allowing zero-bit detection all at the same time. Preliminary experiments demonstrates successful embedding of 32-bit messages with 91.9% accuracy in moderate-length texts ($\sim$500 tokens). This work advances strategies to counter language model misuse effectively.
    
[^51]: 语言模型的鲁棒无畸变水印方法

    Robust Distortion-free Watermarks for Language Models. (arXiv:2307.15593v1 [cs.LG])

    [http://arxiv.org/abs/2307.15593](http://arxiv.org/abs/2307.15593)

    该论文提出了一种在语言模型中添加鲁棒无畸变水印的方法，通过映射随机数序列到语言模型的样本，可以实现在不改变文本分布的前提下对水印文本进行检测，并且在多种改写攻击下依然保持较高的鲁棒性，实验证明在40-50%的随机扰动下仍可可靠地检测到水印文本。

    

    我们提出了一种在自回归语言模型中添加水印的方法，并且这些水印对扰动具有鲁棒性，而不会改变文本的分布，同时保证生成预算在一定范围内。我们用随机水印密钥计算的随机数序列映射到语言模型的样本来生成带水印的文本。要检测水印文本，只要知道密钥的任何一方都可以将文本与随机数序列对齐。我们使用两种采样方案来实例化水印方法：反变换采样和指数最小采样。我们将这些水印应用于三个语言模型——OPT-1.3B、LLaMA-7B和Alpaca-7B，以实验证明它们的统计功效和对各种改写攻击的鲁棒性。值得注意的是，对于OPT-1.3B和LLaMA-7B模型，即使在随机扰动了40-50%的词元后，我们仍然可以可靠地检测到带水印的文本（$p \leq 0.01$），只需要35个词元。

    We propose a methodology for planting watermarks in text from an autoregressive language model that are robust to perturbations without changing the distribution over text up to a certain maximum generation budget. We generate watermarked text by mapping a sequence of random numbers -- which we compute using a randomized watermark key -- to a sample from the language model. To detect watermarked text, any party who knows the key can align the text to the random number sequence. We instantiate our watermark methodology with two sampling schemes: inverse transform sampling and exponential minimum sampling. We apply these watermarks to three language models -- OPT-1.3B, LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B and LLaMA-7B models, we find we can reliably detect watermarked text ($p \leq 0.01$) from $35$ tokens even after corrupting between $40$-$50$\% of the tokens via random
    
[^52]: 单声道和多声道克隆声音检测：从感知到学习特征

    Single and Multi-Speaker Cloned Voice Detection: From Perceptual to Learned Features. (arXiv:2307.07683v1 [cs.SD])

    [http://arxiv.org/abs/2307.07683](http://arxiv.org/abs/2307.07683)

    本论文介绍了三种区分真实声音和试图冒充特定人物声音的克隆声音的技术，分别采用不同的特征提取方法，并展示了在单个和多个声音上训练时的有效性。学习特征具有较高的准确性并且对对抗性清洗具有相当的鲁棒性。

    

    近年来，合成语音克隆技术取得了显著进展，引发了一系列潜在的危害。从小规模和大规模的金融欺诈到虚假信息传播活动，需要可靠的方法来区分真实和合成声音是至关重要的。我们描述了三种区分真实声音和试图冒充特定人物声音的克隆声音的技术。这三种方法在特征提取阶段上有所不同，低维感知特征具有较高的可解释性但准确性较低，而通用的频谱特征和端到端学习特征具有较高的准确性但可解释性较低。我们展示了这些方法在单个说话人的声音上训练和在多个声音上训练时的有效性。学习特征始终保持着$0\%$至$4\%$之间的等错误率，并且对对抗性清洗具有相当的鲁棒性。

    Synthetic-voice cloning technologies have seen significant advances in recent years, giving rise to a range of potential harms. From small- and large-scale financial fraud to disinformation campaigns, the need for reliable methods to differentiate real and synthesized voices is imperative. We describe three techniques for differentiating a real from a cloned voice designed to impersonate a specific person. These three approaches differ in their feature extraction stage with low-dimensional perceptual features offering high interpretability but lower accuracy, to generic spectral features, and end-to-end learned features offering less interpretability but higher accuracy. We show the efficacy of these approaches when trained on a single speaker's voice and when trained on multiple voices. The learned features consistently yield an equal error rate between $0\%$ and $4\%$, and are reasonably robust to adversarial laundering.
    
[^53]: 超越规模：多样性系数作为数据质量指标证明了LLMs是在形式多样的数据上预先训练的

    Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data. (arXiv:2306.13840v1 [cs.CL])

    [http://arxiv.org/abs/2306.13840](http://arxiv.org/abs/2306.13840)

    本论文提出使用多样性系数作为LLM预训练数据质量的指标，研究表明公开可用的LLM数据集的多样性系数很高。

    

    当前，预先训练强大的大语言模型(LLMs)的趋势主要集中在模型和数据集规模的扩大。然而，预先训练数据的质量对于训练强大的LLMs来说是一个重要因素，但它是一个模糊的概念，尚未完全表征。因此，我们使用最近提出的Task2Vec多样性系数来基于数据质量的形式方面，超越规模本身。具体而言，我们测量公开可用的预先训练数据集的多样性系数，以证明它们的形式多样性高于理论的下限和上限。此外，为了建立对多样性系数的信心，我们进行可解释性实验，并发现该系数与多样性的直观属性相吻合，例如，随着潜在概念数量的增加，它增加。我们得出结论，多样性系数是可靠的，表明公开可用的LLM数据集的多样性系数很高，并推测它可以作为预训练LLMs模型的数据质量指标。

    Current trends to pre-train capable Large Language Models (LLMs) mostly focus on scaling of model and dataset size. However, the quality of pre-training data is an important factor for training powerful LLMs, yet it is a nebulous concept that has not been fully characterized. Therefore, we use the recently proposed Task2Vec diversity coefficient to ground and understand formal aspects of data quality, to go beyond scale alone. Specifically, we measure the diversity coefficient of publicly available pre-training datasets to demonstrate that their formal diversity is high when compared to theoretical lower and upper bounds. In addition, to build confidence in the diversity coefficient, we conduct interpretability experiments and find that the coefficient aligns with intuitive properties of diversity, e.g., it increases as the number of latent concepts increases. We conclude the diversity coefficient is reliable, show it's high for publicly available LLM datasets, and conjecture it can be
    
[^54]: AutoTAMP: 使用LLMs作为翻译器和检查器的自回归任务和动作规划

    AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers. (arXiv:2306.06531v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2306.06531](http://arxiv.org/abs/2306.06531)

    AutoTAMP提出了一种使用LLMs作为翻译器和检查器的自回归任务和动作规划方法，通过少样本翻译将自然语言任务描述转换为中间任务表示，以实现对复杂任务的规划和执行。

    

    为了实现有效的人机交互，机器人需要理解、规划和执行由自然语言描述的复杂、长期任务。最近大型语言模型（LLMs）的进展已经显示出了将自然语言翻译为机器人行动序列的潜力，用于复杂任务。然而，现有的方法要么直接将自然语言翻译为机器人轨迹，要么通过将语言分解为任务子目标并依靠动作规划器执行每个子目标来分解推理过程。当涉及复杂的环境和时间约束时，必须使用传统的任务和动作规划（TAMP）算法来联合进行规划任务的推理和动作规划，使得分解为子目标成为不可行的。我们使用LLMs来直接规划任务子目标，而是从自然语言任务描述中进行少样本翻译，生成一个中间任务表示，然后可以由TAMP算法消化该表示来进行规划。

    For effective human-robot interaction, robots need to understand, plan, and execute complex, long-horizon tasks described by natural language. Recent advances in large language models (LLMs) have shown promise for translating natural language into robot action sequences for complex tasks. However, existing approaches either translate the natural language directly into robot trajectories or factor the inference process by decomposing language into task sub-goals and relying on a motion planner to execute each sub-goal. When complex environmental and temporal constraints are involved, inference over planning tasks must be performed jointly with motion plans using traditional task-and-motion planning (TAMP) algorithms, making factorization into subgoals untenable. Rather than using LLMs to directly plan task sub-goals, we instead perform few-shot translation from natural language task descriptions to an intermediate task representation that can then be consumed by a TAMP algorithm to join
    
[^55]: 大型语言模型可以在零-shot学习环境下用于评估政治家的意识形态

    Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting. (arXiv:2303.12057v1 [cs.CY])

    [http://arxiv.org/abs/2303.12057](http://arxiv.org/abs/2303.12057)

    本文展示了在零-shot学习环境下，大型语言模型可以用于评估政治家的意识形态，为我们更好地理解政治功能提供了有用的信息。

    

    大型语言模型（LLMs）中蕴含的大量知识可以为社会科学中的可观测性和测量问题提供新的解决方案。本文研究了其中一种模型在衡量立法者的潜在意识形态方面的效用，这有助于我们更好地理解塑造政策的政治功能，以及政治行为者代表其选民的方式。我们通过提示ChatGPT在两两比较中选择更自由派（或保守派）的参议员，将第116届美国国会的参议员按照自由派-保守派的光谱进行缩放。我们展示了LLM在重复迭代中产生了稳定的答案，没有产生幻觉，并且不仅仅是从单一来源中复制信息。这个新尺度与现有的自由派-保守派尺度（如NOMINATE）强相关，但也在几个重要方面存在差异，比如正确定位一些路径依赖和自由派派别的议员。

    The mass aggregation of knowledge embedded in large language models (LLMs) holds the promise of new solutions to problems of observability and measurement in the social sciences. We examine the utility of one such model for a particularly difficult measurement task: measuring the latent ideology of lawmakers, which allows us to better understand functions that are core to democracy, such as how politics shape policy and how political actors represent their constituents. We scale the senators of the 116th United States Congress along the liberal-conservative spectrum by prompting ChatGPT to select the more liberal (or conservative) senator in pairwise comparisons. We show that the LLM produced stable answers across repeated iterations, did not hallucinate, and was not simply regurgitating information from a single source. This new scale strongly correlates with pre-existing liberal-conservative scales such as NOMINATE, but also differs in several important ways, such as correctly placin
    
[^56]: 面向领域特定语音识别的深度学习系统

    A Deep Learning System for Domain-specific speech Recognition. (arXiv:2303.10510v1 [cs.CL])

    [http://arxiv.org/abs/2303.10510](http://arxiv.org/abs/2303.10510)

    本文提出了一个使用半监督学习注释领域特定数据，基于预训练的声学模型进行微调的ASR系统，并在领域特定上取得了优于商业ASR系统的性能。

    

    随着人机语音接口越来越便捷，许多最先进的自动语音识别（ASR）系统被提出。然而，商业ASR系统通常在领域特定语音，特别是在低资源情况下的表现较差。作者使用预训练的DeepSpeech2和Wav2Vec2声学模型，开发了受益特定的ASR系统。使用半监督学习注释领域特定数据，只需少量人工干预即可。最佳性能来自一种经过微调的Wav2Vec2-Large-LV60声学模型，带有外部KenLM，在受益特定语音上超越了Google和AWS ASR系统。还研究了将容易出错的ASR转录作为口语理解（SLU）的一部分的可行性。受益特定自然语言理解（NLU）任务的结果表明，领域特定微调的ASR系统可以超越商业ASR系统并提高NLU任务的准确性。

    As human-machine voice interfaces provide easy access to increasingly intelligent machines, many state-of-the-art automatic speech recognition (ASR) systems are proposed. However, commercial ASR systems usually have poor performance on domain-specific speech especially under low-resource settings. The author works with pre-trained DeepSpeech2 and Wav2Vec2 acoustic models to develop benefit-specific ASR systems. The domain-specific data are collected using proposed semi-supervised learning annotation with little human intervention. The best performance comes from a fine-tuned Wav2Vec2-Large-LV60 acoustic model with an external KenLM, which surpasses the Google and AWS ASR systems on benefit-specific speech. The viability of using error prone ASR transcriptions as part of spoken language understanding (SLU) is also investigated. Results of a benefit-specific natural language understanding (NLU) task show that the domain-specific fine-tuned ASR system can outperform the commercial ASR sys
    
[^57]: GPT-Neo用于常识推理--理论与实践视角

    GPT-Neo for commonsense reasoning -- a theoretical and practical lens. (arXiv:2211.15593v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15593](http://arxiv.org/abs/2211.15593)

    本文评估了GPT-Neo模型在常识推理任务上的性能，并与其他较大模型进行了比较。在适当的超参数设置下，该模型在多个任务上取得了具有竞争力的准确性。

    

    最近的研究展示了在大型语言模型（LLM）上进行预训练，然后在下游任务中进行有监督微调可以取得显著的进展。在本文中，我们对GPT-Neo模型在6个常识推理基准任务上的性能进行了评估。我们旨在对使用GPT-Neo模型的较小模型与GPT-3、Llama-2、MPT和Falcon等几个较大模型基准进行性能比较。在使用适当的超参数集进行微调后，我们的模型在多个任务上取得了有竞争力的准确性。我们还使用注意力头可视化来调查和证实我们的结果，以更好地理解模型的性能。最后，我们使用各种方法进行了多种鲁棒性测试，以评估模型在多种设置下的性能。

    Recent work has demonstrated substantial gains in pre-training large-language models (LLMs) followed by supervised fine-tuning on the downstream task. In this paper, we evaluate the performance of the GPT-neo model using $6$ commonsense reasoning benchmark tasks. We aim to examine the performance of smaller models using the GPT-neo models against several larger model baselines such as GPT-$3$, Llama-$2$, MPT and Falcon. Upon fine-tuning with the appropriate set of hyperparameters, our model achieves competitive accuracy on several tasks. We also investigate and substantiate our results using attention-head visualization to better understand the model performance. Finally, we conduct various robustness tests using various methods to gauge the model performance under numerous settings.
    
[^58]: 在野外的说话者分辨中的后期音频-视觉融合

    Late Audio-Visual Fusion for In-The-Wild Speaker Diarization. (arXiv:2211.01299v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.01299](http://arxiv.org/abs/2211.01299)

    本论文提出了一种音频-视觉融合的模型，通过后期融合将音频和视觉信息相结合，用于解决在野外视频中具有挑战性的说话者分辨问题。通过使用模拟代理数据集进行训练，并引入注意力机制和说话者识别损失，我们提出的模型在处理更多说话者时表现更好。此外，利用面部属性和唇音同步的视觉子系统能够估计屏幕上说话者的身份和语音活动。整体而言，我们的模型在AVA-AVD基准测试上取得了新的最先进结果。

    

    音频视觉融合是为了应对具有更多说话者、较短发言和不一致的屏幕说话者的具有挑战性的野外视频而提出的。我们通过提出一种音频视觉分辨模型，通过后期融合将仅包含音频和以视觉为中心的子系统相结合。对于音频，我们展示了一个基于吸引子的端到端系统（EEND-EDA）在使用我们提出的一个模拟代理数据集的训练配方时表现出色，并提出了改进版的EEND-EDA++，在解码过程中使用注意力和在训练过程中使用说话者识别损失来更好地处理更多的说话者。以视觉为中心的子系统利用面部属性和唇音同步来估计屏幕上说话者的身份和语音活动。两个子系统都大幅超过了当前最先进技术 (SOTA)，通过融合音频-视觉系统在AVA-AVD基准测试中取得了新的SOTA。

    Speaker diarization is well studied for constrained audios but little explored for challenging in-the-wild videos, which have more speakers, shorter utterances, and inconsistent on-screen speakers. We address this gap by proposing an audio-visual diarization model which combines audio-only and visual-centric sub-systems via late fusion. For audio, we show that an attractor-based end-to-end system (EEND-EDA) performs remarkably well when trained with our proposed recipe of a simulated proxy dataset, and propose an improved version, EEND-EDA++, that uses attention in decoding and a speaker recognition loss during training to better handle the larger number of speakers. The visual-centric sub-system leverages facial attributes and lip-audio synchrony for identity and speech activity estimation of on-screen speakers. Both sub-systems surpass the state of the art (SOTA) by a large margin, with the fused audio-visual system achieving a new SOTA on the AVA-AVD benchmark.
    
[^59]: 克服语言指导的目标-条件强化学习中指代歧义

    Overcoming Referential Ambiguity in Language-Guided Goal-Conditioned Reinforcement Learning. (arXiv:2209.12758v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.12758](http://arxiv.org/abs/2209.12758)

    本文研究了语言指导的目标-条件强化学习中的指代歧义问题，并提出了教学法和实用主义的概念来解决这些问题。实验证明，这些概念可以提高学习者的训练效率。

    

    当教师用自然语言指导一个代理执行新任务时，解释的歧义很容易成为阻碍。当教师通过参考物体的特征向学习者提供指令时，学习者可能会误解教师的意图，特别是当指令模糊地涉及物体的特征时，这种现象称为指代歧义。我们研究了两个源自认知科学的概念如何帮助解决这些指代歧义：教学法（选择合适的指令）和实用主义（通过归纳推理了解其他代理的偏好）。我们将这些思想应用于一个带有两个人工代理的模拟机器人任务（堆积木块）。我们展示了这些概念如何提高学习者的训练样本效率。

    Teaching an agent to perform new tasks using natural language can easily be hindered by ambiguities in interpretation. When a teacher provides an instruction to a learner about an object by referring to its features, the learner can misunderstand the teacher's intentions, for instance if the instruction ambiguously refer to features of the object, a phenomenon called referential ambiguity. We study how two concepts derived from cognitive sciences can help resolve those referential ambiguities: pedagogy (selecting the right instructions) and pragmatism (learning the preferences of the other agents using inductive reasoning). We apply those ideas to a teacher/learner setup with two artificial agents on a simulated robotic task (block-stacking). We show that these concepts improve sample efficiency for training the learner.
    

