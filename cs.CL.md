# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models.](http://arxiv.org/abs/2309.15098) | 本研究使用约束满足问题框架研究了语言模型的内部行为，发现模型对约束标记的关注程度与事实准确性强正相关。提出了一种方法可以预测约束满足和事实错误，并允许早期错误识别，进一步提高了大型语言模型的可靠性。 |
| [^2] | [VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning.](http://arxiv.org/abs/2309.15091) | 本文提出了VideoDirectorGPT，一种利用LLMs的知识实现一致多场景视频生成的框架，通过视频内容规划和基于内容的视频生成来生成时间上一致的长视频。 |
| [^3] | [RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models.](http://arxiv.org/abs/2309.15088) | RankVicuna是第一个能够在零样本设置中执行高质量列表排序的完全开源的大型语言模型，通过使用比GPT-3.5小得多的参数模型，实现了与零样本重新排序相当的效果，并为将来研究提供了基础。 |
| [^4] | [Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial.](http://arxiv.org/abs/2309.15074) | 本教程介绍了基于大型语言模型的自然语言上下文建模和推理，通过与LLMs交互，使用自然语言进行上下文建模和推理。 |
| [^5] | [Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding.](http://arxiv.org/abs/2309.15028) | 本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。 |
| [^6] | [Large Language Model Alignment: A Survey.](http://arxiv.org/abs/2309.15025) | 这项调查对大规模语言模型对齐的方法进行了广泛探讨，并提出了内部对齐和外部对齐的分类。同时讨论了模型的可解释性和潜在的对抗攻击漏洞。考虑到模型可能产生的不准确和误导性文本，对齐技术显得至关重要。 |
| [^7] | [Question-Answering Approach to Evaluate Legal Summaries.](http://arxiv.org/abs/2309.15016) | 本文提出了一种利用GPT-4进行问答的法律摘要评估方法，通过生成一组问题-答案对来覆盖参考摘要中的主要信息，并通过GPT-4对参考摘要和生成摘要的答案进行评分，证明了该方法可以作为衡量摘要质量的有效工具。 |
| [^8] | [Updated Corpora and Benchmarks for Long-Form Speech Recognition.](http://arxiv.org/abs/2309.15013) | 本研究重新发布了三个标准的ASR语料库，并更新了转录和对齐，以用于长篇语音识别研究。对于转录器和基于注意力的编码器-解码器，我们发现AEDs对于训练-测试不匹配问题更为敏感。在领域转变下，简单的长篇训练可以提高模型的稳健性。 |
| [^9] | [Automating question generation from educational text.](http://arxiv.org/abs/2309.15004) | 本文设计并评估了一个用于学校形成性和总结性评估的自动化问题生成工具，通过对教师的调查，证明了自动化生成问题的需求，并提出了一个基于Transformer的语言模型的模块化框架，用于从文本内容中自动生成多项选择题。 |
| [^10] | [Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts.](http://arxiv.org/abs/2309.14974) | 该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。 |
| [^11] | [Interactively Learning Social Media Representations Improves News Source Factuality Detection.](http://arxiv.org/abs/2309.14966) | 本文提出了一种交互式的方法来改善社交媒体表示质量，通过人类互动帮助自动化系统检测新闻来源的真实性，并在实验证明即使进行了少量的人类互动，也能提高性能。 |
| [^12] | [Robustness of the Random Language Model.](http://arxiv.org/abs/2309.14913) | 随机语言模型的研究展示了第一语言学习过程中的语法句法连续转变，并证明该转变对于明确对称性的打破是鲁棒的。 |
| [^13] | [Segmentation-Free Streaming Machine Translation.](http://arxiv.org/abs/2309.14823) | 本研究提出了一种无需分割的流式机器翻译框架，通过延迟分割决策来提高翻译质量和延迟平衡，相比其他方法具有更好的效果。 |
| [^14] | [Fine-tuning and aligning question answering models for complex information extraction tasks.](http://arxiv.org/abs/2309.14805) | 本文提出了一种使用抽取型QA模型进行信息提取的方法，以解决大型语言模型在文档分析中的应用限制。实验结果表明，细调德语QA模型可以提高针对定制化信息提取任务的性能。 |
| [^15] | [Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification.](http://arxiv.org/abs/2309.14779) | 本研究探索了将小型语言模型（SLMs）与提示学习范式结合应用于领域特定文本分类的潜力，并在零售业的客户和代理人交互中进行了评估。结果显示，在有限的标记数据下，SLM T5-base能够实现约75%的准确率，展现了SLMs与提示学习的潜力。 |
| [^16] | [BLIP-Adapter: Parameter-Efficient Transfer Learning for Mobile Screenshot Captioning.](http://arxiv.org/abs/2309.14774) | 本研究提出了一种参数高效的迁移学习方法，通过冻结图像标题模型的参数并只调整附加模块，解决了移动设备屏幕截图标题生成任务中大量参数的开销问题。 |
| [^17] | [Boosting In-Context Learning with Factual Knowledge.](http://arxiv.org/abs/2309.14771) | 本文研究了使用事实知识提升上下文学习的效果，并提出了一个新的知识上下文调优框架来改善学习性能。 |
| [^18] | [KERMIT: Knowledge Graph Completion of Enhanced Relation Modeling with Inverse Transformation.](http://arxiv.org/abs/2309.14770) | 本研究提出了一种增强关系建模的知识图谱补全方法，通过利用外部知识库生成连贯的描述，并通过反向关系创建对称图来提供额外的标签和补充信息。实验证明这种方法在知识图谱补全方面取得了显著的改进。 |
| [^19] | [ConPET: Continual Parameter-Efficient Tuning for Large Language Models.](http://arxiv.org/abs/2309.14763) | ConPET是一种适用于大型语言模型的持续参数高效调整方法，通过参数高效调整（PET）和动态回放策略，减少调整成本、缓解过度拟合和遗忘问题。 |
| [^20] | [Program Repair with Minimal Edits Using CodeT5.](http://arxiv.org/abs/2309.14760) | 本文提出了一种使用CodeT5进行最小编辑的程序修复的方法，该方法通过在错误和正确程序的代码对上对预训练的CodeT5进行微调，实验结果表明其效果良好。 |
| [^21] | [Comparative Analysis of Artificial Intelligence for Indian Legal Question Answering (AILQA) Using Different Retrieval and QA Models.](http://arxiv.org/abs/2309.14735) | 本文对印度法律问答系统的人工智能模型进行比较分析，发现现有的AILQA系统能够自动解析用户的自然语言查询并生成高度准确的响应。 |
| [^22] | [PLMM: Personal Large Models on Mobile Devices.](http://arxiv.org/abs/2309.14726) | 本文提出了一种从传统大型语言模型中提取的个人大型模型，该模型更适应于本地用户的个人信息，并且能够保护用户的隐私。该模型分为个人级别、专家级别和传统级别，同时还需要小型化以适应个人计算机或移动设备，并实现实时响应以提供更好的用户体验。 |
| [^23] | [A Simple Text to Video Model via Transformer.](http://arxiv.org/abs/2309.14683) | 该研究提出了一种基于Transformer的简单文本到视频模型，通过同时编码文本和图像到隐藏空间，并使用U-Net进行图像重建，能够生成有希望的视频。 |
| [^24] | [Efficient Post-training Quantization with FP8 Formats.](http://arxiv.org/abs/2309.14592) | 本研究研究了FP8格式在后训练量化中的优势，并开发了一个通用的量化工作流程。实验结果表明，FP8相对于INT8具有更好的工作负载覆盖率和模型准确性。 |
| [^25] | [Introducing DictaLM -- A Large Generative Language Model for Modern Hebrew.](http://arxiv.org/abs/2309.14568) | 引入了一种用于现代希伯来语的大规模生成语言模型DictaLM，通过发布基础模型和训练模型，促进了希伯来语的研究和发展，并提供了一个初始的希伯来语LLM模型用于实验。 |
| [^26] | [Art or Artifice? Large Language Models and the False Promise of Creativity.](http://arxiv.org/abs/2309.14556) | 本研究通过提出创造性写作的托兰斯测验(TTCW)来评估大型语言模型(LLMs)的写作创造力。结果表明，LLM生成的故事在创意测试中通过的数量比专业作家写的故事少。此外，我们发现LLMs无法代替专家进行TTCW评估。 |
| [^27] | [Aligning Large Multimodal Models with Factually Augmented RLHF.](http://arxiv.org/abs/2309.14525) | 这项研究提出了一种名为Factually Augmented RLHF的新对齐算法，通过将事实信息加入奖励模型来解决多模态模型之间的幻觉问题，并进一步提高性能。 |
| [^28] | [ChatGPT Performance on Standardized Testing Exam -- A Proposed Strategy for Learners.](http://arxiv.org/abs/2309.14519) | 本研究探讨了ChatGPT在标准化考试准备中的应用，特别是在GRE定量领域。研究结果显示ChatGPT在回答不同类型的GRE问题时表现出良好的问题解决能力，并且修改问题提示可以影响其准确性。 |
| [^29] | [Watch Your Language: Large Language Models and Content Moderation.](http://arxiv.org/abs/2309.14517) | 本研究评估了大型语言模型在内容审查任务上的表现，发现它们在基于规则的社区审查和有害内容检测方面具有很好的效果，在有害内容检测方面超过了现有的分类器。然而，最近模型规模的增加对有害内容检测的改进效果很小。 |
| [^30] | [DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models.](http://arxiv.org/abs/2309.14509) | 本论文介绍了DeepSpeed-Ulysses，一种用于实现具备极长序列长度的高效可扩展LLM训练的新颖方法。 |
| [^31] | [Classifying token frequencies using angular Minkowski $p$-distance.](http://arxiv.org/abs/2309.14495) | 使用角度明可夫斯基$p$-距离可以获得比传统余弦相似度更高的分类性能 |
| [^32] | [When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs.](http://arxiv.org/abs/2309.14488) | 本研究通过对人类和GPT生成的文本进行实证评估，探讨了基于机器学习模型对文本质量评估的差异。结果表明，在评估GPT生成的文本时，预训练转换器模型的性能较差。 |
| [^33] | [Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond.](http://arxiv.org/abs/2309.14485) | 这项研究改进了联合NLU模型的准确性，并使其可解释，同时扩展适用于其他分类任务。 |
| [^34] | [Online Active Learning For Sound Event Detection.](http://arxiv.org/abs/2309.14460) | 通过提出新的损失函数，该论文解决了在线主动学习在声音事件检测中面临的类别分布波动和数据漂移问题，并在实验中证明该方法能够将训练分类器所需的时间和工作量减少5倍。 |
| [^35] | [Physics of Language Models: Part 3.2, Knowledge Manipulation.](http://arxiv.org/abs/2309.14402) | 本文研究了语言模型在推理过程中操控知识的能力，发现预训练模型在知识检索方面表现出色，但在简单的分类、比较和逆向搜索任务中表现不佳。作者还提供了一个合成数据集进行实验，验证了这些内在的弱点：语言模型无法高效地操控知识。 |
| [^36] | [Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion.](http://arxiv.org/abs/2309.14398) | 本文提出了一个多模态分类器，在动机性访谈中准确区分了变化话语、持续话语和跟随/中立话语三种类别。该分类器利用文本、声调、面部表情和身体表现等多模态特征，并对AnnoMI数据集进行了注释和训练。研究还找到了决策过程中最重要的模态，提供了宝贵的洞察。 |
| [^37] | [Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation.](http://arxiv.org/abs/2309.14394) | 本文提出了一种多噪声扩散模型（MDD）用于半监督多域翻译，通过引入噪声级别来对缺失的域进行建模，实现了任意域之间的翻译而不需要训练单独的模型。 |
| [^38] | [LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models.](http://arxiv.org/abs/2309.14393) | 本研究提出了LLMCarbon，一个针对密集型和MoE LLMs设计的端到端碳足迹预测模型，解决了现有工具的限制，并显著提升了估计的准确性。 |
| [^39] | [An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems.](http://arxiv.org/abs/2309.14391) | 一个AI聊天机器人被介绍来解释深度强化学习在面向服务系统中的决策过程，通过提供自然语言解释来帮助用户理解和建立信任。 |
| [^40] | [Agree To Disagree.](http://arxiv.org/abs/2309.14382) | "同意不同意"论文提出了一种基于机器学习的方法，旨在自动解析和总结使用户便于理解的关键信息，以帮助用户在承诺协议之前考虑重要细节。 |
| [^41] | [Survey of Social Bias in Vision-Language Models.](http://arxiv.org/abs/2309.14381) | 社交偏见在视觉-语言模型中的调查，旨在为研究人员提供对潜在社会偏见的理解，以解决资源分配不均和不公平代表等问题。 |
| [^42] | [Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence.](http://arxiv.org/abs/2309.14379) | 本研究提出了一种机器辅助的混合方法框架，利用大规模语言模型在人文社科领域的数据分析中的应用潜力，展示了16个案例研究，并涵盖了多种任务，包括语言分析、文本挖掘、社交网络推断等。 |
| [^43] | [A Text Classification-Based Approach for Evaluating and Enhancing the Machine Interpretability of Building Codes.](http://arxiv.org/abs/2309.14374) | 该研究提出了一种基于文本分类的方法，自动评估和增强建筑法规的机器可解释性。研究考虑了条款和文档层面的机器可解释性，通过引入几个类别进行分类并开发了一个数据集进行模型训练，并开发了一个高效的文本分类模型。 |
| [^44] | [Human Transcription Quality Improvement.](http://arxiv.org/abs/2309.14372) | 本文提出了一种可靠的方法来收集高质量的语音转录数据，通过在标注阶段进行置信度估计的重新处理和在标注后阶段进行自动词错误修正，成功降低了转录词误率（WER），并发现了转录错误对ASR模型性能的强相关性。 |
| [^45] | [An In-depth Survey of Large Language Model-based Artificial Intelligence Agents.](http://arxiv.org/abs/2309.14365) | 本文研究了基于大型语言模型的AI代理与传统AI代理之间的核心差异和特点，并引入了一种创新的记忆分类方案，提供了全新的设计视角。 |
| [^46] | [Diversifying Question Generation over Knowledge Base via External Natural Questions.](http://arxiv.org/abs/2309.14362) | 通过引入新的多样性评估指标，我们提出了一种通过外部自然问题在知识库上进行多样化问题生成的方法。同时，我们设计了一个双模型框架来解决如何增强多样化问题生成的挑战。 |
| [^47] | [COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs.](http://arxiv.org/abs/2309.14356) | COCO-Counterfactuals是一个自动构建图像-文本对的反事实例的框架，通过使用文本到图像扩散模型来自动生成多模态反事实例。通过人工评估，我们验证了COCO-Counterfactuals的质量，并展示了其对于改善域外泛化能力的实用性。 |
| [^48] | [PopBERT. Detecting populism and its host ideologies in the German Bundestag.](http://arxiv.org/abs/2309.14355) | 本文提出了一种可靠、有效且可扩展的方法来衡量民粹主义立场，通过在德国联邦议院的演讲中进行语言标记，训练了一个基于Transformer的模型（PopBERT）来检测和量化民粹主义的核心维度，并确定民粹主义陈述与左翼或右翼主导意识形态的关联。 |
| [^49] | [Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM.](http://arxiv.org/abs/2309.14348) | 本文提出了一种稳健对齐的LLM（RA-LLM），用于防御可能发生的对齐破坏攻击。RA-LLM可以直接在现有的对齐LLM上构建，并通过稳健的对齐检查函数来确保其有效性。 |
| [^50] | [Connecting Speech Encoder and Large Language Model for ASR.](http://arxiv.org/abs/2309.13963) | 本文通过比较研究了三种连接结构，即全连接层、多头交叉注意力和Q-Former，将语音编码器与大型语言模型相结合，实现了在自动语音识别中显著降低词错误率的效果。其中，基于Q-Former的大型语言模型在Out-of-Domain数据集上展现出了良好的泛化能力，并且相比基准模型实现了12%的相对词错误率降低。 (arXiv:2309.13963v2 [eess.AS] UPDATED) |
| [^51] | [MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models.](http://arxiv.org/abs/2309.13079) | MiChao-HuaFen 1.0是一个专为新闻和政府部门定制的面向领域特定大模型的预训练语料数据集，它不仅能够满足特定领域的高质量需求，还有助于推动相关领域的深度学习研究和应用。 |
| [^52] | [InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning.](http://arxiv.org/abs/2309.13064) | InvestLM是一个通过对金融领域指导数据集进行调优的大型语言模型，具有强大的理解金融文本的能力，并在投资相关问题上提供有帮助的回答。金融专家评价其与最先进的商业模型可媲美，并在金融NLP基准问题上展现了强大的泛化能力。 |
| [^53] | [Multimodal Deep Learning for Scientific Imaging Interpretation.](http://arxiv.org/abs/2309.12460) | 本研究提出了一种多模态深度学习框架，通过模拟人类与扫描电子显微镜图像的交互，利用文本和视觉数据进行精细数据合成和评估。该模型（GlassLLaVA）能够准确解释、识别关键特征和检测以前未见的SEM图像中的缺陷，同时引入了适用于多种科学成像应用的灵活评估指标。 |
| [^54] | [MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods.](http://arxiv.org/abs/2309.10966) | 本文提出了MBR微调和QE微调方法，将训练时的质量提升蒸馏到基准模型中，从而在推断时使用高效的解码算法。实验证明，这些微调方法能显著提升模型性能，甚至超过基准模型。 |
| [^55] | [Investigating the Catastrophic Forgetting in Multimodal Large Language Models.](http://arxiv.org/abs/2309.10313) | 本论文针对多模态大规模语言模型中的灾难性遗忘问题进行研究，引入了EMT方法来评估灾难性遗忘，并发现在标准图像分类任务上，几乎所有评估的模型都无法保持与视觉编码器相同的性能水平。研究结果表明，早期微调阶段对性能至关重要。 |
| [^56] | [Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations.](http://arxiv.org/abs/2307.06576) | 本文介绍了一种名为GLORY的模型，通过全局图与本地表示相结合，增强了个性化推荐系统。该模型通过构建全局感知历史新闻编码器来融合历史新闻表示，并考虑了用户隐藏的动机和行为。 |
| [^57] | [MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation.](http://arxiv.org/abs/2306.10322) | MO-VLN是一个用于评估通用机器人在多任务环境中的视觉和语言导航的基准，通过使用虚幻引擎5开发逼真的场景和包含多种不常见物体来测试其效果和泛化能力。 |
| [^58] | [Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias.](http://arxiv.org/abs/2305.19894) | Med-UniC是一个新的框架，旨在通过整合英语和西班牙语的跨语言医学数据，实现跨语言医学图像-语言预训练的统一。他们提出了跨语言文本对齐规则(CTR)，以明确统一来自不同语言社区的医学报告的跨语言语义表示。 |
| [^59] | [Weakly-Supervised Visual-Textual Grounding with Semantic Prior Refinement.](http://arxiv.org/abs/2305.10913) | 本文提出了一种利用语义先验细化的弱监督视觉-文本对齐方法，仅使用图像-句子对进行学习，其目标是实现实体表示中的区域-短语对应关系，通过联合两个主要模块的输出进行预测。 |
| [^60] | [How to Index Item IDs for Recommendation Foundation Models.](http://arxiv.org/abs/2305.06569) | 本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。 |
| [^61] | [Disentangling Prosody Representations with Unsupervised Speech Reconstruction.](http://arxiv.org/abs/2212.06972) | 本文提出了一种利用无监督语音重构来解决从语音中分离情绪韵律的任务的方法。通过设计和集成多个关键组件，我们能够在没有标签的情况下有效地提取出韵律信息。这对于自动语音识别和说话人验证等应用具有重要意义。 |
| [^62] | [Permutation invariant matrix statistics and computational language tasks.](http://arxiv.org/abs/2202.06829) | 本文提出了一种排列不变矩阵统计的方法，用于处理生成的矩阵统计，并描述了该方法在计算语言学中处理同义词、反义词、上义词和下义词等任务中的成功应用。 |

# 详细

[^1]: 满足关注：对语言模型事实错误的约束满足视角的研究

    Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models. (arXiv:2309.15098v1 [cs.CL])

    [http://arxiv.org/abs/2309.15098](http://arxiv.org/abs/2309.15098)

    本研究使用约束满足问题框架研究了语言模型的内部行为，发现模型对约束标记的关注程度与事实准确性强正相关。提出了一种方法可以预测约束满足和事实错误，并允许早期错误识别，进一步提高了大型语言模型的可靠性。

    

    本研究调查了基于Transformer的大型语言模型（LLM）在生成事实上错误的文本时的内部行为。我们将事实查询建模为约束满足问题，并利用这一框架研究模型如何与事实约束进行内部交互。具体而言，我们发现模型对约束标记的关注程度与其响应的事实准确性存在强正相关关系。在我们的11个数据集中，总计超过40,000个提示的精心策划套装中，我们研究了使用Llama-2系列在所有规模（7B，13B，70B）上预测事实错误的任务。我们提出了SAT Probe，一种探查自注意模式的方法，可以预测约束满足和事实错误，并允许早期错误识别。这一方法和发现表明，利用对LLM中事实性的机械理解可以增强可靠性。

    We investigate the internal behavior of Transformer-based Large Language Models (LLMs) when they generate factually incorrect text. We propose modeling factual queries as Constraint Satisfaction Problems and use this framework to investigate how the model interacts internally with factual constraints. Specifically, we discover a strong positive relation between the model's attention to constraint tokens and the factual accuracy of its responses. In our curated suite of 11 datasets with over 40,000 prompts, we study the task of predicting factual errors with the Llama-2 family across all scales (7B, 13B, 70B). We propose SAT Probe, a method probing self-attention patterns, that can predict constraint satisfaction and factual errors, and allows early error identification. The approach and findings demonstrate how using the mechanistic understanding of factuality in LLMs can enhance reliability.
    
[^2]: VideoDirectorGPT: 通过LLM引导的规划实现一致的多场景视频生成

    VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning. (arXiv:2309.15091v1 [cs.CV])

    [http://arxiv.org/abs/2309.15091](http://arxiv.org/abs/2309.15091)

    本文提出了VideoDirectorGPT，一种利用LLMs的知识实现一致多场景视频生成的框架，通过视频内容规划和基于内容的视频生成来生成时间上一致的长视频。

    

    尽管最近的文本到视频生成方法取得了显著的进展，但大多数工作集中在生成单个事件和单一背景的短视频片段（即单场景视频）。与此同时，最近的大型语言模型（LLMs）已经证明了它们在生成布局和控制下游视觉模块（如图像生成模型）的程序方面的能力。这引发了一个重要问题：我们能否利用这些LLMs中嵌入的知识用于生成时间上一致的长视频？在本文中，我们提出了VideoDirectorGPT，这是一个用于一致的多场景视频生成的新型框架，它利用LLMs的知识进行视频内容规划和基于内容的视频生成。具体而言，我们首先将单个文本提示输入我们的视频规划器LLM（GPT-4）中，将其扩展为“视频计划”，其中包括生成场景描述、实体及其布局、每个场景的背景以及保持一致性等内容。

    Although recent text-to-video (T2V) generation methods have seen significant advancements, most of these works focus on producing short video clips of a single event with a single background (i.e., single-scene videos). Meanwhile, recent large language models (LLMs) have demonstrated their capability in generating layouts and programs to control downstream visual modules such as image generation models. This raises an important question: can we leverage the knowledge embedded in these LLMs for temporally consistent long video generation? In this paper, we propose VideoDirectorGPT, a novel framework for consistent multi-scene video generation that uses the knowledge of LLMs for video content planning and grounded video generation. Specifically, given a single text prompt, we first ask our video planner LLM (GPT-4) to expand it into a 'video plan', which involves generating the scene descriptions, the entities with their respective layouts, the background for each scene, and consistency 
    
[^3]: RankVicuna: 使用开源大型语言模型进行零样本列表排序的研究

    RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models. (arXiv:2309.15088v1 [cs.IR])

    [http://arxiv.org/abs/2309.15088](http://arxiv.org/abs/2309.15088)

    RankVicuna是第一个能够在零样本设置中执行高质量列表排序的完全开源的大型语言模型，通过使用比GPT-3.5小得多的参数模型，实现了与零样本重新排序相当的效果，并为将来研究提供了基础。

    

    研究人员成功地将ChatGPT等大型语言模型应用于信息检索中的重新排序，但迄今为止，这样的工作大多建立在不透明的API后面的专有模型上。这种方法产生的实验结果不可复现且非确定性，威胁到建立在这种不稳定基础上的结果的真实性。为了解决这个重大缺陷，我们提出了RankVicuna，这是第一个能够在零样本设置中执行高质量列表排序的完全开源的大型语言模型。在TREC 2019和2020深度学习跟踪实验中，我们的实验结果显示，我们可以使用比GPT-3.5小得多的7B参数模型实现与零样本重新排序相当的效果，尽管我们的效果仍略逊于GPT-4重新排序。我们希望我们的工作为将来使用现代大型语言模型进行重新排序的研究提供基础。复现我们结果所需的所有代码都可以在h链接处获得。

    Researchers have successfully applied large language models (LLMs) such as ChatGPT to reranking in an information retrieval context, but to date, such work has mostly been built on proprietary models hidden behind opaque API endpoints. This approach yields experimental results that are not reproducible and non-deterministic, threatening the veracity of outcomes that build on such shaky foundations. To address this significant shortcoming, we present RankVicuna, the first fully open-source LLM capable of performing high-quality listwise reranking in a zero-shot setting. Experimental results on the TREC 2019 and 2020 Deep Learning Tracks show that we can achieve effectiveness comparable to zero-shot reranking with GPT-3.5 with a much smaller 7B parameter model, although our effectiveness remains slightly behind reranking with GPT-4. We hope our work provides the foundation for future research on reranking with modern LLMs. All the code necessary to reproduce our results is available at h
    
[^4]: 基于大型语言模型（LLMs）的自然语言上下文建模与推理：教程

    Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial. (arXiv:2309.15074v1 [cs.CL])

    [http://arxiv.org/abs/2309.15074](http://arxiv.org/abs/2309.15074)

    本教程介绍了基于大型语言模型的自然语言上下文建模和推理，通过与LLMs交互，使用自然语言进行上下文建模和推理。

    

    大型语言模型（LLMs）自2018年以来急剧增长，自引入上下文感知计算系统20年后。上下文感知计算通过考虑普适设备、用户和社会的情况，实现了广泛的创新应用，如辅助生活、基于位置的社交网络服务等。为了识别上下文并相应地做出决策，采用了各种人工智能技术（如本体论和OWL）作为上下文建模和推理的表示方法。最近，随着LLMs的崛起和它们改进的自然语言理解和推理能力，使用自然语言建模上下文并通过与ChatGPT和GPT-4等LLMs交互进行上下文推理变得可行。在本教程中，我们演示了使用文本、提示和自主代理（AutoAgents）使LLMs能够执行上下文建模的方法。

    Large language models (LLMs) have become phenomenally surging, since 2018--two decades after introducing context-awareness into computing systems. Through taking into account the situations of ubiquitous devices, users and the societies, context-aware computing has enabled a wide spectrum of innovative applications, such as assisted living, location-based social network services and so on. To recognize contexts and make decisions for actions accordingly, various artificial intelligence technologies, such as Ontology and OWL, have been adopted as representations for context modeling and reasoning. Recently, with the rise of LLMs and their improved natural language understanding and reasoning capabilities, it has become feasible to model contexts using natural language and perform context reasoning by interacting with LLMs such as ChatGPT and GPT-4. In this tutorial, we demonstrate the use of texts, prompts, and autonomous agents (AutoAgents) that enable LLMs to perform context modeling 
    
[^5]: 让PPO变得更好：基于值导向的Monte-Carlo Tree Search解码

    Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding. (arXiv:2309.15028v1 [cs.CL])

    [http://arxiv.org/abs/2309.15028](http://arxiv.org/abs/2309.15028)

    本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。

    

    在生成自然语言文本时，使用最新的强化学习算法，如Proximal Policy Optimization (PPO)，因此可以认为推理时间的搜索算法，如Monte-Carlo Tree Search (MCTS) 是不必要的。本文证明了通过在PPO之上集成MCTS，可以进一步提升PPO的性能。关键思想是在解码文本时，不要丢弃值网络，即PPO训练时用于评估部分输出序列的副产品，而是将其与策略网络紧密结合。具体而言，本文提出了一种称为PPO-MCTS的新颖的值导向解码算法，可以将来自PPO的值网络与推理时间产生的策略网络紧密结合。与基于MCTS的控制文本生成的先前方法相比，我们的方法的关键优势在于减少了训练和测试之间部分输出的评分机制的基本不匹配。在四个文本生成任务上的评估结果表明，PPO-MCTS可以显著提升性能。

    Inference-time search algorithms such as Monte-Carlo Tree Search (MCTS) may seem unnecessary when generating natural language text based on state-of-the-art reinforcement learning such as Proximal Policy Optimization (PPO). In this paper, we demonstrate that it is possible to get extra mileage out of PPO by integrating MCTS on top. The key idea is not to throw out the value network, a byproduct of PPO training for evaluating partial output sequences, when decoding text out of the policy network. More concretely, we present a novel value-guided decoding algorithm called PPO-MCTS, which can integrate the value network from PPO to work closely with the policy network during inference-time generation. Compared to prior approaches based on MCTS for controlled text generation, the key strength of our approach is to reduce the fundamental mismatch of the scoring mechanisms of the partial outputs between training and test. Evaluation on four text generation tasks demonstrate that PPO-MCTS grea
    
[^6]: 大规模语言模型对齐：一项调查

    Large Language Model Alignment: A Survey. (arXiv:2309.15025v1 [cs.CL])

    [http://arxiv.org/abs/2309.15025](http://arxiv.org/abs/2309.15025)

    这项调查对大规模语言模型对齐的方法进行了广泛探讨，并提出了内部对齐和外部对齐的分类。同时讨论了模型的可解释性和潜在的对抗攻击漏洞。考虑到模型可能产生的不准确和误导性文本，对齐技术显得至关重要。

    

    近年来，大规模语言模型（LLMs）取得了显著进展。这些进展引起了广泛关注，但同时也引发了各种担忧。这些模型的潜力无疑是巨大的；然而，它们可能产生不准确、误导性甚至有害的文本。因此，采用对齐技术以确保这些模型表现出与人类价值一致的行为变得至关重要。本调查旨在对针对LLMs设计的对齐方法进行广泛探讨，并结合该领域中的现有能力研究。采用AI对齐的视角，我们将用于对齐LLMs的主流方法和新兴提议分为外部对齐和内部对齐。我们还探讨了模型可解释性和潜在的对抗攻击漏洞等重要问题。为了评估LLM的对齐，我们提出了多样化的基准和评估方法。

    Recent years have witnessed remarkable progress made in large language models (LLMs). Such advancements, while garnering significant attention, have concurrently elicited various concerns. The potential of these models is undeniably vast; however, they may yield texts that are imprecise, misleading, or even detrimental. Consequently, it becomes paramount to employ alignment techniques to ensure these models to exhibit behaviors consistent with human values.  This survey endeavors to furnish an extensive exploration of alignment methodologies designed for LLMs, in conjunction with the extant capability research in this domain. Adopting the lens of AI alignment, we categorize the prevailing methods and emergent proposals for the alignment of LLMs into outer and inner alignment. We also probe into salient issues including the models' interpretability, and potential vulnerabilities to adversarial attacks. To assess LLM alignment, we present a wide variety of benchmarks and evaluation metho
    
[^7]: 用问答方法评估法律摘要

    Question-Answering Approach to Evaluate Legal Summaries. (arXiv:2309.15016v1 [cs.CL])

    [http://arxiv.org/abs/2309.15016](http://arxiv.org/abs/2309.15016)

    本文提出了一种利用GPT-4进行问答的法律摘要评估方法，通过生成一组问题-答案对来覆盖参考摘要中的主要信息，并通过GPT-4对参考摘要和生成摘要的答案进行评分，证明了该方法可以作为衡量摘要质量的有效工具。

    

    传统的评估指标如ROUGE仅比较参考摘要和生成摘要之间的词汇重叠，而不考虑论点结构，而这对于法律摘要非常重要。在本文中，我们提出了一种新颖的法律摘要评估框架，利用GPT-4生成一组问题-答案对，涵盖参考摘要中的主要点和信息。然后，利用生成摘要回答参考摘要中的问题。最后，GPT-4对参考摘要和生成摘要的答案进行评分。我们检查了GPT-4评分与人工评分之间的相关性。结果表明，利用GPT-4的问答方法可以作为衡量摘要质量的有用工具。

    Traditional evaluation metrics like ROUGE compare lexical overlap between the reference and generated summaries without taking argumentative structure into account, which is important for legal summaries. In this paper, we propose a novel legal summarization evaluation framework that utilizes GPT-4 to generate a set of question-answer pairs that cover main points and information in the reference summary. GPT-4 is then used to generate answers based on the generated summary for the questions from the reference summary. Finally, GPT-4 grades the answers from the reference summary and the generated summary. We examined the correlation between GPT-4 grading with human grading. The results suggest that this question-answering approach with GPT-4 can be a useful tool for gauging the quality of the summary.
    
[^8]: 长篇语音识别的更新语料库和基准

    Updated Corpora and Benchmarks for Long-Form Speech Recognition. (arXiv:2309.15013v1 [cs.CL])

    [http://arxiv.org/abs/2309.15013](http://arxiv.org/abs/2309.15013)

    本研究重新发布了三个标准的ASR语料库，并更新了转录和对齐，以用于长篇语音识别研究。对于转录器和基于注意力的编码器-解码器，我们发现AEDs对于训练-测试不匹配问题更为敏感。在领域转变下，简单的长篇训练可以提高模型的稳健性。

    

    绝大多数ASR研究使用预先分割为语句的语料库进行训练和测试。然而，在大多数实际ASR应用场景中，测试音频并没有分割，从而导致推理时条件和训练在分割语句上的模型之间存在不匹配。本文重新发布了三个标准ASR语料库-TED-LIUM 3，Gigapeech和VoxPopuli-en，并更新了转录和对齐，以便将其用于长篇语音识别研究。我们使用这些重组的语料库研究了转录器和基于注意力的编码器-解码器(AEDs)的训练-测试不匹配问题，并确认AEDs对此问题更为敏感。最后，我们为这些模型进行了简单的长篇训练的基准测试，展示了其在此领域转变下的模型稳健性。

    The vast majority of ASR research uses corpora in which both the training and test data have been pre-segmented into utterances. In most real-word ASR use-cases, however, test audio is not segmented, leading to a mismatch between inference-time conditions and models trained on segmented utterances. In this paper, we re-release three standard ASR corpora - TED-LIUM 3, Gigapeech, and VoxPopuli-en - with updated transcription and alignments to enable their use for long-form ASR research. We use these reconstituted corpora to study the train-test mismatch problem for transducers and attention-based encoder-decoders (AEDs), confirming that AEDs are more susceptible to this issue. Finally, we benchmark a simple long-form training for these models, showing its efficacy for model robustness under this domain shift.
    
[^9]: 从教育文本中自动生成问题

    Automating question generation from educational text. (arXiv:2309.15004v1 [cs.CL])

    [http://arxiv.org/abs/2309.15004](http://arxiv.org/abs/2309.15004)

    本文设计并评估了一个用于学校形成性和总结性评估的自动化问题生成工具，通过对教师的调查，证明了自动化生成问题的需求，并提出了一个基于Transformer的语言模型的模块化框架，用于从文本内容中自动生成多项选择题。

    

    问题式活动（QBA）在教育中得到广泛应用，传统上是学习和评估过程的一个重要组成部分。本文设计并评估了一个用于学校形成性和总结性评估的自动化问题生成工具。通过对104名教师的专家调查，我们展示了自动化生成QBA的需求，作为一个能够显著减轻教师工作量并促进个性化学习体验的工具。利用生成型AI的最新进展，我们提出了一个基于Transformer的语言模型的模块化框架，用于从文本内容中自动生成多项选择题（MCQ）。所提出的解决方案具有问题生成、正确答案预测和干扰项制定的不同模块，使我们能够评估不同的语言模型和生成技术。最后，我们进行了广泛的定量和定性评估。

    The use of question-based activities (QBAs) is wide-spread in education, traditionally forming an integral part of the learning and assessment process. In this paper, we design and evaluate an automated question generation tool for formative and summative assessment in schools. We present an expert survey of one hundred and four teachers, demonstrating the need for automated generation of QBAs, as a tool that can significantly reduce the workload of teachers and facilitate personalized learning experiences. Leveraging the recent advancements in generative AI, we then present a modular framework employing transformer based language models for automatic generation of multiple-choice questions (MCQs) from textual content. The presented solution, with distinct modules for question generation, correct answer prediction, and distractor formulation, enables us to evaluate different language models and generation techniques. Finally, we perform an extensive quantitative and qualitative evaluat
    
[^10]: 在一千年前的拉丁文本中检测句子级别的性内容

    Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts. (arXiv:2309.14974v1 [cs.CL])

    [http://arxiv.org/abs/2309.14974](http://arxiv.org/abs/2309.14974)

    该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。

    

    在这项研究中，我们提出使用深度学习方法在句子级别进行语义分类，以加快人文学科和语言学领域中语料库建设的过程，这是一项传统且耗时的任务。我们引入了一个新颖的语料库，包括约2500个句子，涵盖了从公元前300年到公元900年的性语义学（医学，情色等）。我们评估了各种句子分类方法和不同的输入嵌入层，并表明它们都比简单的基于标记的搜索方法更好。我们探索了个人言语和社会言语元数据嵌入（世纪，作者，写作类型）的整合，但发现这导致了过拟合。我们的结果表明了这种方法的有效性，使用HAN分别达到了70.60%的高精度和86.33%的真阳性率（TPR）。我们评估了数据集大小对模型性能的影响（420而不是2013），并显示出，尽管我们的模型性能可能稍有下降，但性能仍然稳定。

    In this study, we propose to evaluate the use of deep learning methods for semantic classification at the sentence level to accelerate the process of corpus building in the field of humanities and linguistics, a traditional and time-consuming task. We introduce a novel corpus comprising around 2500 sentences spanning from 300 BCE to 900 CE including sexual semantics (medical, erotica, etc.). We evaluate various sentence classification approaches and different input embedding layers, and show that all consistently outperform simple token-based searches. We explore the integration of idiolectal and sociolectal metadata embeddings (centuries, author, type of writing), but find that it leads to overfitting. Our results demonstrate the effectiveness of this approach, achieving high precision and true positive rates (TPR) of respectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset size on the model performances (420 instead of 2013), and show that, while our models per
    
[^11]: 通过交互学习社交媒体表示改善新闻来源真实性检测

    Interactively Learning Social Media Representations Improves News Source Factuality Detection. (arXiv:2309.14966v1 [cs.CL])

    [http://arxiv.org/abs/2309.14966](http://arxiv.org/abs/2309.14966)

    本文提出了一种交互式的方法来改善社交媒体表示质量，通过人类互动帮助自动化系统检测新闻来源的真实性，并在实验证明即使进行了少量的人类互动，也能提高性能。

    

    社交媒体的兴起使得虚假新闻的广泛传播成为可能，虚假新闻是指以传播错误信息和影响信仰为目的的文本。及时检测虚假新闻，特别是在新事件出现时，对于防止误导信息非常重要。尽管以前的研究利用监督学习系统解决了这个问题，但是自动建模社交媒体传播虚假新闻的复杂性仍然具有挑战性。相反，通过人工实时检查所有新闻是不可扩展的。因此，在本文中，我们提出了一种交互式的方法来解决这个问题，人们可以与自动化系统互动，帮助其学习更好的社交媒体表示质量。在真实事件中的实验证明，即使进行了少量的人类互动，也能提高检测新闻来源真实性的性能。

    The rise of social media has enabled the widespread propagation of fake news, text that is published with an intent to spread misinformation and sway beliefs. Rapidly detecting fake news, especially as new events arise, is important to prevent misinformation.  While prior works have tackled this problem using supervised learning systems, automatedly modeling the complexities of the social media landscape that enables the spread of fake news is challenging. On the contrary, having humans fact check all news is not scalable. Thus, in this paper, we propose to approach this problem interactively, where humans can interact to help an automated system learn a better social media representation quality. On real world events, our experiments show performance improvements in detecting factuality of news sources, even after few human interactions.
    
[^12]: 随机语言模型的鲁棒性

    Robustness of the Random Language Model. (arXiv:2309.14913v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2309.14913](http://arxiv.org/abs/2309.14913)

    随机语言模型的研究展示了第一语言学习过程中的语法句法连续转变，并证明该转变对于明确对称性的打破是鲁棒的。

    

    随机语言模型(De Giuli 2019)是一组随机上下文无关文法，量化人类和计算机语言的句法。该模型提出了一个简单的第一语言学习图景，即作为潜在语言空间中一个退火类型，推断了向语法句法的单一连续转变，其中潜在的词汇和分类之间的对称性会自发打破。在本文中，通过考虑其对明确对称性打破的鲁棒性，对这一图景进行了严格审视，这是在现实世界的学习中不可避免的组成部分。结果表明，该场景对于这种对称性的打破是鲁棒的。与语法网络聚类系数的人类数据进行比较表明，观察到的转变相当于儿童24个月时通常经历的转变。

    The Random Language Model (De Giuli 2019) is an ensemble of stochastic context-free grammars, quantifying the syntax of human and computer languages. The model suggests a simple picture of first language learning as a type of annealing in the vast space of potential languages. In its simplest formulation, it implies a single continuous transition to grammatical syntax, at which the symmetry among potential words and categories is spontaneously broken. Here this picture is scrutinized by considering its robustness against explicit symmetry breaking, an inevitable component of learning in the real world. It is shown that the scenario is robust to such symmetry breaking. Comparison with human data on the clustering coefficient of syntax networks suggests that the observed transition is equivalent to that normally experienced by children at age 24 months.
    
[^13]: 无需分割的流式机器翻译

    Segmentation-Free Streaming Machine Translation. (arXiv:2309.14823v1 [cs.CL])

    [http://arxiv.org/abs/2309.14823](http://arxiv.org/abs/2309.14823)

    本研究提出了一种无需分割的流式机器翻译框架，通过延迟分割决策来提高翻译质量和延迟平衡，相比其他方法具有更好的效果。

    

    流式机器翻译是实时将未限定输入文本流进行翻译的任务。传统级联方法将自动语音识别（ASR）和机器翻译系统结合，依赖于中间的分割步骤，将转录流分割成句子样式的单位。然而，硬分割的引入限制了机器翻译系统，并且是错误的来源。本文提出了一种无需分割的框架，使模型能够在生成翻译之前延迟分割决策，翻译未分割的源流。广泛的实验证明，所提出的无需分割的框架在质量延迟平衡方面优于使用独立分割模型的竞争方法。论文通过后将公开发布软件、数据和模型。

    Streaming Machine Translation (MT) is the task of translating an unbounded input text stream in real-time. The traditional cascade approach, which combines an Automatic Speech Recognition (ASR) and an MT system, relies on an intermediate segmentation step which splits the transcription stream into sentence-like units. However, the incorporation of a hard segmentation constrains the MT system and is a source of errors. This paper proposes a Segmentation-Free framework that enables the model to translate an unsegmented source stream by delaying the segmentation decision until the translation has been generated. Extensive experiments show how the proposed Segmentation-Free framework has better quality-latency trade-off than competing approaches that use an independent segmentation model. Software, data and models will be released upon paper acceptance.
    
[^14]: 细调和对齐问题回答模型以进行复杂信息提取任务

    Fine-tuning and aligning question answering models for complex information extraction tasks. (arXiv:2309.14805v1 [cs.CL])

    [http://arxiv.org/abs/2309.14805](http://arxiv.org/abs/2309.14805)

    本文提出了一种使用抽取型QA模型进行信息提取的方法，以解决大型语言模型在文档分析中的应用限制。实验结果表明，细调德语QA模型可以提高针对定制化信息提取任务的性能。

    

    大型语言模型(LLMs)的出现提升了各种自然语言处理任务的性能和可能性。尽管像ChatGPT这样的生成型AI模型为一些商业用例开启了新的机会，但其当前倾向于产生虚假内容的特点严重限制了其在文档分析(如从文档中检索信息)方面的适用性。相反，像问题回答(QA)或段落检索模型这样的抽取型语言模型保证查询结果在相应上下文文档的边界内，使其成为公司生产环境中更可靠的信息提取候选模型。在这项工作中，我们提出了一种方法，使用和整合抽取型QA模型来改进对德语商业文档(如保险报告或药品说明书)的特征提取，形成一个文档分析解决方案。我们还展示了细调现有德语QA模型可以提升针对定制化信息提取的性能。

    The emergence of Large Language Models (LLMs) has boosted performance and possibilities in various NLP tasks. While the usage of generative AI models like ChatGPT opens up new opportunities for several business use cases, their current tendency to hallucinate fake content strongly limits their applicability to document analysis, such as information retrieval from documents. In contrast, extractive language models like question answering (QA) or passage retrieval models guarantee query results to be found within the boundaries of an according context document, which makes them candidates for more reliable information extraction in productive environments of companies. In this work we propose an approach that uses and integrates extractive QA models for improved feature extraction of German business documents such as insurance reports or medical leaflets into a document analysis solution. We further show that fine-tuning existing German QA models boosts performance for tailored extractio
    
[^15]: 使用提示学习范式探索小型语言模型在高效领域特定文本分类中的应用

    Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification. (arXiv:2309.14779v1 [cs.CL])

    [http://arxiv.org/abs/2309.14779](http://arxiv.org/abs/2309.14779)

    本研究探索了将小型语言模型（SLMs）与提示学习范式结合应用于领域特定文本分类的潜力，并在零售业的客户和代理人交互中进行了评估。结果显示，在有限的标记数据下，SLM T5-base能够实现约75%的准确率，展现了SLMs与提示学习的潜力。

    

    面对手动标记的高成本，领域特定文本分类面临稀缺的标记数据的挑战。提示学习作为传统微调方法的替代方案，在少样本场景中表现出高效性。此外，虽然大型语言模型（LLMs）已经引起了关注，但小型语言模型（SLMs，小于10亿个参数）在领域特定任务中具有显著的定制性、适应性和成本效益，符合工业约束。本研究探讨了将SLMs与提示学习范式结合应用于领域特定文本分类的潜力，尤其是在零售业的客户和代理人交互中。我们的评估结果显示，在少样本的情况下，当可以进行基于提示的模型微调时，具有220M参数的典型SLM T5-base能够在有限的标记数据上实现约75%的准确率（达到完整数据的15%），显示出SLMs与提示学习的巨大潜力。

    Domain-specific text classification faces the challenge of scarce labeled data due to the high cost of manual labeling. Prompt-learning, known for its efficiency in few-shot scenarios, is proposed as an alternative to traditional fine-tuning methods. And besides, although large language models (LLMs) have gained prominence, small language models (SLMs, with under 1B parameters) offer significant customizability, adaptability, and cost-effectiveness for domain-specific tasks, given industry constraints. In this study, we investigate the potential of SLMs combined with prompt-learning paradigm for domain-specific text classification, specifically within customer-agent interactions in retail. Our evaluations show that, in few-shot settings when prompt-based model fine-tuning is possible, T5-base, a typical SLM with 220M parameters, achieve approximately 75% accuracy with limited labeled data (up to 15% of full data), which shows great potentials of SLMs with prompt-learning. Based on this
    
[^16]: BLIP-Adapter：移动设备屏幕截图标题生成的参数高效迁移学习

    BLIP-Adapter: Parameter-Efficient Transfer Learning for Mobile Screenshot Captioning. (arXiv:2309.14774v1 [cs.LG])

    [http://arxiv.org/abs/2309.14774](http://arxiv.org/abs/2309.14774)

    本研究提出了一种参数高效的迁移学习方法，通过冻结图像标题模型的参数并只调整附加模块，解决了移动设备屏幕截图标题生成任务中大量参数的开销问题。

    

    本研究旨在探索有效的调整方法来处理屏幕截图标题生成任务。近年来，图像标题生成取得了显著进展，但是对于移动设备屏幕截图的标题生成任务的研究相对较少。目前的数据集和使用案例中对产品截屏中的用户行为的描述相对有限。因此，我们尝试对现有模型进行微调，以解决屏幕截图标题生成任务。然而，微调大型预训练模型可能消耗大量资源，需要考虑到图像标题生成模型中大量参数的时间、计算力和存储开销。为了解决这一挑战，本研究提出了一种适配器方法的组合，只需要调整模型中的附加模块。这些方法最初是为视觉或语言任务设计的，我们的意图是将它们应用于解决屏幕截图标题生成中的类似挑战。通过冻结图像标题模型的参数并训练其他模块，可以实现参数高效的迁移学习。

    This study aims to explore efficient tuning methods for the screenshot captioning task. Recently, image captioning has seen significant advancements, but research in captioning tasks for mobile screens remains relatively scarce. Current datasets and use cases describing user behaviors within product screenshots are notably limited. Consequently, we sought to fine-tune pre-existing models for the screenshot captioning task. However, fine-tuning large pre-trained models can be resource-intensive, requiring considerable time, computational power, and storage due to the vast number of parameters in image captioning models. To tackle this challenge, this study proposes a combination of adapter methods, which necessitates tuning only the additional modules on the model. These methods are originally designed for vision or language tasks, and our intention is to apply them to address similar challenges in screenshot captioning. By freezing the parameters of the image caption models and trainin
    
[^17]: 使用事实知识提升上下文学习的效果

    Boosting In-Context Learning with Factual Knowledge. (arXiv:2309.14771v1 [cs.CL])

    [http://arxiv.org/abs/2309.14771](http://arxiv.org/abs/2309.14771)

    本文研究了使用事实知识提升上下文学习的效果，并提出了一个新的知识上下文调优框架来改善学习性能。

    

    在大型语言模型上下文学习（ICL）旨在通过依赖于少量的训练示例解决以前未见过的任务，从而消除参数更新的需求，并实现有竞争力的性能。本文展示了事实知识在ICL的性能中的重要性，包括在LLM中学到的固有知识，从所选的上下文示例中得出的事实知识，以及LLM在输出生成中的知识偏差。为了发挥LLM在少样本学习场景中的能力，我们引入了一种新的知识上下文调优（KICT）框架来进一步提高ICL的性能：1）在持续自监督预训练期间向LLM注入事实知识，2）谨慎选择具有高知识相关性的示例，3）根据先前的知识对预测结果进行校准。我们在自回归LLM（如GPT风格模型）上评估了所提出的方法。

    In-Context Learning (ICL) over Large language models (LLMs) aims at solving previously unseen tasks by conditioning on a few training examples, eliminating the need for parameter updates and achieving competitive performance. In this paper, we demonstrate that factual knowledge is imperative for the performance of ICL in three core facets, i.e., the inherent knowledge learned in LLMs, the factual knowledge derived from the selected in-context examples, and the knowledge biases in LLMs for output generation. To unleash the power of LLMs in few-shot learning scenarios, we introduce a novel Knowledgeable In-Context Tuning (KICT) framework to further improve the performance of ICL: 1) injecting factual knowledge to LLMs during continual self-supervised pre-training, 2) judiciously selecting the examples with high knowledge relevance, and 3) calibrating the prediction results based on prior knowledge. We evaluate the proposed approaches on auto-regressive LLMs (e.g., GPT-style models) over 
    
[^18]: KERMIT: 带有反转变换的增强关系建模的知识图谱补全

    KERMIT: Knowledge Graph Completion of Enhanced Relation Modeling with Inverse Transformation. (arXiv:2309.14770v1 [cs.CL])

    [http://arxiv.org/abs/2309.14770](http://arxiv.org/abs/2309.14770)

    本研究提出了一种增强关系建模的知识图谱补全方法，通过利用外部知识库生成连贯的描述，并通过反向关系创建对称图来提供额外的标签和补充信息。实验证明这种方法在知识图谱补全方面取得了显著的改进。

    

    知识图谱补全是一项基于知识图谱中可用信息填充缺失三元组的任务。在当前的研究中，基于文本的方法通过利用三元组的文本描述来完成任务。然而，这种建模方法可能遇到一些限制，尤其是当描述不能准确充分地表达预期含义时。为了克服这些挑战，我们提出了通过两个额外机制来增加数据的方法。首先，我们使用ChatGPT作为外部知识库，生成连贯的描述以弥补查询和答案之间的语义差距。其次，我们利用反向关系创建对称图，从而为链接预测提供额外的标签和补充信息。这种方法提供了关系实体之间额外的洞察力。通过这些努力，我们观察到了知识图谱补全方面的显著改进。

    Knowledge graph completion is a task that revolves around filling in missing triples based on the information available in a knowledge graph. Among the current studies, text-based methods complete the task by utilizing textual descriptions of triples. However, this modeling approach may encounter limitations, particularly when the description fails to accurately and adequately express the intended meaning. To overcome these challenges, we propose the augmentation of data through two additional mechanisms. Firstly, we employ ChatGPT as an external knowledge base to generate coherent descriptions to bridge the semantic gap between the queries and answers. Secondly, we leverage inverse relations to create a symmetric graph, thereby creating extra labeling and providing supplementary information for link prediction. This approach offers additional insights into the relationships between entities. Through these efforts, we have observed significant improvements in knowledge graph completion
    
[^19]: ConPET: 对大型语言模型的持续参数高效调整

    ConPET: Continual Parameter-Efficient Tuning for Large Language Models. (arXiv:2309.14763v1 [cs.CL])

    [http://arxiv.org/abs/2309.14763](http://arxiv.org/abs/2309.14763)

    ConPET是一种适用于大型语言模型的持续参数高效调整方法，通过参数高效调整（PET）和动态回放策略，减少调整成本、缓解过度拟合和遗忘问题。

    

    持续学习需要对模型进行持续调整以适应新出现的任务，同时最大限度地减少对旧任务的灾难性遗忘。对于具有全参数调整的大型语言模型（LLMs）来说，这是极具挑战性的，原因是计算成本高、内存消耗大且容易遗忘。受参数高效调整（PET）的成功启发，我们提出了持续参数高效调整（ConPET），这是一种适用于LLMs的具有任务数量无关训练复杂度的延续任务适应的通用范式。ConPET包括两个版本，适用于不同的应用场景。首先，静态ConPET可以通过PET和动态回放策略将原本针对较小模型设计的旧的持续学习方法应用到LLMs中，从而大大减少调整成本，缓解过度拟合和遗忘问题。此外，为了保持可伸缩性，动态ConPET为不同任务采用单独的PET模块和PET模块选择策略。

    Continual learning necessitates the continual adaptation of models to newly emerging tasks while minimizing the catastrophic forgetting of old ones. This is extremely challenging for large language models (LLMs) with vanilla full-parameter tuning due to high computation costs, memory consumption, and forgetting issue. Inspired by the success of parameter-efficient tuning (PET), we propose Continual Parameter-Efficient Tuning (ConPET), a generalizable paradigm for continual task adaptation of LLMs with task-number-independent training complexity. ConPET includes two versions with different application scenarios. First, Static ConPET can adapt former continual learning methods originally designed for relatively smaller models to LLMs through PET and a dynamic replay strategy, which largely reduces the tuning costs and alleviates the over-fitting and forgetting issue. Furthermore, to maintain scalability, Dynamic ConPET adopts separate PET modules for different tasks and a PET module sele
    
[^20]: 使用CodeT5进行最小编辑的程序修复

    Program Repair with Minimal Edits Using CodeT5. (arXiv:2309.14760v1 [cs.CL])

    [http://arxiv.org/abs/2309.14760](http://arxiv.org/abs/2309.14760)

    本文提出了一种使用CodeT5进行最小编辑的程序修复的方法，该方法通过在错误和正确程序的代码对上对预训练的CodeT5进行微调，实验结果表明其效果良好。

    

    程序员往往难以识别和修复程序中的错误。近年来，许多语言模型（LM）已经被提出用来修复错误的程序并支持错误恢复。然而，LMs往往会生成与原始输入程序不同的解决方案。这可能导致用户的理解困难。在本文中，我们提出了一种使用CodeT5建议进行最小修复编辑的正确程序的方法。我们在错误和正确程序的代码对上对预先训练的CodeT5进行微调，并使用几个基准模型评估其性能。实验结果表明，经过微调的CodeT5的通过率为91.95%，最相似的正确程序的平均编辑距离为6.84，这表明至少可以通过生成100个候选程序来建议一个正确的程序。我们展示了语言模型在解决初级编程问题时建议使用最小编辑的程序修复的有效性。

    Programmers often struggle to identify and fix bugs in their programs. In recent years, many language models (LMs) have been proposed to fix erroneous programs and support error recovery. However, the LMs tend to generate solutions that differ from the original input programs. This leads to potential comprehension difficulties for users. In this paper, we propose an approach to suggest a correct program with minimal repair edits using CodeT5. We fine-tune a pre-trained CodeT5 on code pairs of wrong and correct programs and evaluate its performance with several baseline models. The experimental results show that the fine-tuned CodeT5 achieves a pass@100 of 91.95% and an average edit distance of the most similar correct program of 6.84, which indicates that at least one correct program can be suggested by generating 100 candidate programs. We demonstrate the effectiveness of LMs in suggesting program repair with minimal edits for solving introductory programming problems.
    
[^21]: 基于不同检索和问答模型的印度法律问答系统的人工智能比较分析

    Comparative Analysis of Artificial Intelligence for Indian Legal Question Answering (AILQA) Using Different Retrieval and QA Models. (arXiv:2309.14735v1 [cs.CL])

    [http://arxiv.org/abs/2309.14735](http://arxiv.org/abs/2309.14735)

    本文对印度法律问答系统的人工智能模型进行比较分析，发现现有的AILQA系统能够自动解析用户的自然语言查询并生成高度准确的响应。

    

    法律问答（QA）系统有潜力改变法律专业人士与案例文件的互动方式。本文对现有的人工智能模型进行了比较分析，以评估其在印度法律体系下回答法律问题的效用，特别关注印度法律问答（AILQA）并研究了当前可用的不同检索和QA算法的有效性。利用OpenAI GPT模型作为基准，结合查询提示，我们的研究表明现有的AILQA系统能够自动解析用户的自然语言查询并生成高度准确的响应。本研究特别关注印度刑事司法领域的应用，该领域由于复杂性和资源限制而面临一系列挑战。为了严格评估这些模型的性能，经验证评估与从实践中获得的反馈相结合。

    Legal question-answering (QA) systems have the potential to revolutionize the way legal professionals interact with case law documents. This paper conducts a comparative analysis of existing artificial intelligence models for their utility in answering legal questions within the Indian legal system, specifically focusing on Indian Legal Question Answering (AILQA) and our study investigates the efficacy of different retrieval and QA algorithms currently available. Utilizing the OpenAI GPT model as a benchmark, along with query prompts, our investigation shows that existing AILQA systems can automatically interpret natural language queries from users and generate highly accurate responses. This research is particularly focused on applications within the Indian criminal justice domain, which has its own set of challenges due to its complexity and resource constraints. In order to rigorously assess the performance of these models, empirical evaluations are complemented by feedback from pra
    
[^22]: PLMM：移动设备上的个人大型模型

    PLMM: Personal Large Models on Mobile Devices. (arXiv:2309.14726v1 [cs.CV])

    [http://arxiv.org/abs/2309.14726](http://arxiv.org/abs/2309.14726)

    本文提出了一种从传统大型语言模型中提取的个人大型模型，该模型更适应于本地用户的个人信息，并且能够保护用户的隐私。该模型分为个人级别、专家级别和传统级别，同时还需要小型化以适应个人计算机或移动设备，并实现实时响应以提供更好的用户体验。

    

    在本文中，受到联邦学习的启发，我们提出了从传统大型语言模型中提取的个人大型模型，这些模型更适应本地用户的个人信息，如教育背景和爱好。我们将大型语言模型分为三个级别：个人级别，专家级别和传统级别。个人级别模型适应用户的个人信息，对用户的输入进行加密并保护其隐私。专家级别模型专注于合并特定领域的知识，如金融、IT和艺术。传统模型专注于普遍知识的发现和提升专家模型。在这样的分类中，个人模型直接与用户交互。对于整个系统来说，个人模型具有用户的（加密的）个人信息。此外，这些模型必须足够小以在个人计算机或移动设备上运行。最后，它们还必须实时响应，以提供更好的用户体验。

    Inspired by Federated Learning, in this paper, we propose personal large models that are distilled from traditional large language models but more adaptive to local users' personal information such as education background and hobbies. We classify the large language models into three levels: the personal level, expert level and traditional level. The personal level models are adaptive to users' personal information. They encrypt the users' input and protect their privacy. The expert level models focus on merging specific knowledge such as finance, IT and art. The traditional models focus on the universal knowledge discovery and upgrading the expert models. In such classifications, the personal models directly interact with the user. For the whole system, the personal models have users' (encrypted) personal information. Moreover, such models must be small enough to be performed on personal computers or mobile devices. Finally, they also have to response in real-time for better user exper
    
[^23]: 通过Transformer的简单文本到视频模型

    A Simple Text to Video Model via Transformer. (arXiv:2309.14683v1 [cs.CV])

    [http://arxiv.org/abs/2309.14683](http://arxiv.org/abs/2309.14683)

    该研究提出了一种基于Transformer的简单文本到视频模型，通过同时编码文本和图像到隐藏空间，并使用U-Net进行图像重建，能够生成有希望的视频。

    

    我们提出了一种基于Transformer的通用简单文本到视频模型。由于文本和视频都是序列数据，我们将文本和图像编码为相同的隐藏空间，然后将其输入到Transformer中以捕捉时间一致性，再通过解码器生成文本或图像。考虑到长序列中图像信号可能变弱，我们引入U-Net来从图像的噪声版本中重建图像。具体来说，在长序列中，我们增加原始图像的噪声级别，然后使用U-Net中的下采样模块来编码带噪声的图像，进而输入到Transformer中以预测下一个清晰的图像。我们还添加了一个约束条件，以促进视频中任意生成的图像对之间的运动。我们使用了GPT2，并在UCF101数据集上测试了我们的方法，结果显示它可以生成有希望的视频。

    We present a general and simple text to video model based on Transformer. Since both text and video are sequential data, we encode both texts and images into the same hidden space, which are further fed into Transformer to capture the temporal consistency and then decoder to generate either text or images. Considering the image signal may become weak in the long sequence, we introduce the U-Net to reconstruct image from its noised version. Specifically, we increase the noise level to the original image in the long sequence, then use the $down$ module from U-Net to encode noised images, which are further input to transformer to predict next clear images. We also add a constraint to promote motion between any generated image pair in the video. We use GPT2 and test our approach on UCF101 dataset and show it can generate promising videos.
    
[^24]: 使用FP8格式的高效后训练量化方法

    Efficient Post-training Quantization with FP8 Formats. (arXiv:2309.14592v1 [cs.LG])

    [http://arxiv.org/abs/2309.14592](http://arxiv.org/abs/2309.14592)

    本研究研究了FP8格式在后训练量化中的优势，并开发了一个通用的量化工作流程。实验结果表明，FP8相对于INT8具有更好的工作负载覆盖率和模型准确性。

    

    最近深度学习方法的进展，如LLMs和扩散模型，提出了对改进的量化方法的需求，以满足这些现代架构的计算需求，同时保持准确性。为了实现这一目标，我们研究了FP8数据格式在75个不同网络架构上进行后训练量化的优势，这些网络架构涵盖了多种任务，包括机器翻译、语言建模、文本生成、图像分类、生成和分割。我们研究了三种不同的FP8表示（E5M2、E4M3和E3M4），以研究在动态范围和精度之间不同权衡程度对模型准确性的影响。基于我们的广泛研究，我们开发了一个量化工作流程，可以概括适用于不同的网络架构。我们的实证结果表明，FP8格式在多个方面优于INT8，包括工作负载覆盖率（92.64％对65.87％）、模型准确性和适用于更广泛的操作范围。

    Recent advances in deep learning methods such as LLMs and Diffusion models have created a need for improved quantization methods that can meet the computational demands of these modern architectures while maintaining accuracy. Towards this goal, we study the advantages of FP8 data formats for post-training quantization across 75 unique network architectures covering a wide range of tasks, including machine translation, language modeling, text generation, image classification, generation, and segmentation. We examine three different FP8 representations (E5M2, E4M3, and E3M4) to study the effects of varying degrees of trade-off between dynamic range and precision on model accuracy. Based on our extensive study, we developed a quantization workflow that generalizes across different network architectures. Our empirical results show that FP8 formats outperform INT8 in multiple aspects, including workload coverage (92.64% vs. 65.87%), model accuracy and suitability for a broader range of ope
    
[^25]: 引入DictaLM - 一种用于现代希伯来语的大规模生成语言模型

    Introducing DictaLM -- A Large Generative Language Model for Modern Hebrew. (arXiv:2309.14568v1 [cs.CL])

    [http://arxiv.org/abs/2309.14568](http://arxiv.org/abs/2309.14568)

    引入了一种用于现代希伯来语的大规模生成语言模型DictaLM，通过发布基础模型和训练模型，促进了希伯来语的研究和发展，并提供了一个初始的希伯来语LLM模型用于实验。

    

    我们介绍了DictaLM，这是一个专为现代希伯来语量身定制的大规模语言模型。该模型拥有70亿个参数，主要训练于希伯来语相关数据。为了促进希伯来语的研究和发展，我们以Creative Commons许可证发布了基础模型和训练模型。同时，我们还引入了DictaLM-Rab，另一个针对拉比/历史希伯来语的基础模型。这些基础模型可作为各种希伯来语特定任务（如说明、问答、情感分析等）的理想起点进行微调。此发布代表了一个初步步骤，为希伯来语NLP社区提供了一个初始的希伯来语LLM模型用于实验。

    We present DictaLM, a large-scale language model tailored for Modern Hebrew. Boasting 7B parameters, this model is predominantly trained on Hebrew-centric data. As a commitment to promoting research and development in the Hebrew language, we release both the foundation model and the instruct-tuned model under a Creative Commons license. Concurrently, we introduce DictaLM-Rab, another foundation model geared towards Rabbinic/Historical Hebrew. These foundation models serve as ideal starting points for fine-tuning various Hebrew-specific tasks, such as instruction, Q&A, sentiment analysis, and more. This release represents a preliminary step, offering an initial Hebrew LLM model for the Hebrew NLP community to experiment with.
    
[^26]: 艺术还是技巧？大型语言模型与创造力的虚假承诺

    Art or Artifice? Large Language Models and the False Promise of Creativity. (arXiv:2309.14556v1 [cs.CL])

    [http://arxiv.org/abs/2309.14556](http://arxiv.org/abs/2309.14556)

    本研究通过提出创造性写作的托兰斯测验(TTCW)来评估大型语言模型(LLMs)的写作创造力。结果表明，LLM生成的故事在创意测试中通过的数量比专业作家写的故事少。此外，我们发现LLMs无法代替专家进行TTCW评估。

    

    研究人员认为，大型语言模型(LLMs)具有从博客到故事的高质量写作能力。然而，客观评估一段文字的创造力是具有挑战性的。受创造性思维的托兰斯测验(TTC)的启发，我们使用共识评估技术[3]，提出了创造性写作的托兰斯测验(TTCW)来评估创造力作为一个产品。TTCW由包含在流畅度、灵活性、独创性和细致度原始维度中的14个二元测试组成。我们招募了10位创意作家，并使用TTCW对48个由专业作家或LLMs撰写的故事进行人工评估。我们的分析表明，LLM生成的故事通过的TTCW测试比专业作家写的故事少了3-10倍。此外，我们探索了使用LLMs作为评价者，以自动化TTCW评估，结果显示没有一个LLM与专家评估呈正相关。

    Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT), which measures creativity as a process, we use the Consensual Assessment Technique [3] and propose the Torrance Test of Creative Writing (TTCW) to evaluate creativity as a product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.
    
[^27]: 用事实增强的RLHF方法对齐大型多模态模型

    Aligning Large Multimodal Models with Factually Augmented RLHF. (arXiv:2309.14525v1 [cs.CV])

    [http://arxiv.org/abs/2309.14525](http://arxiv.org/abs/2309.14525)

    这项研究提出了一种名为Factually Augmented RLHF的新对齐算法，通过将事实信息加入奖励模型来解决多模态模型之间的幻觉问题，并进一步提高性能。

    

    大型多模态模型（LMM）是跨模态构建的，两种模态之间的不对齐可能导致“幻觉”，生成的文本输出没有与上下文中的多模态信息相匹配。为了解决多模态不对齐问题，我们将来自文本领域的强化学习人类反馈（RLHF）方法改进为视觉语言对齐任务，其中需要人工标注者比较两个响应并指出“幻觉”更严重的一个，视觉语言模型则被训练以最大化模拟人类奖励。我们提出了一种新的对齐算法称为Factually Augmented RLHF，它通过附加图像标题和地面真实多选项等额外事实信息来增强奖励模型，从而减轻强化学习人类反馈中的奖励欺骗现象并进一步提高性能。我们还通过之前可用的人工编写的图像-文本数据增强了GPT-4生成的训练数据（用于视觉指令调整）。

    Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in "hallucination", generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement Learning from Human Feedback (RLHF) from the text domain to the task of vision-language alignment, where human annotators are asked to compare two responses and pinpoint the more hallucinated one, and the vision-language model is trained to maximize the simulated human rewards. We propose a new alignment algorithm called Factually Augmented RLHF that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance. We also enhance the GPT-4-generated training data (for vision instruction tuning) with previously available human-written image-text 
    
[^28]: ChatGPT在标准化考试中的表现——学习者的一种提议策略

    ChatGPT Performance on Standardized Testing Exam -- A Proposed Strategy for Learners. (arXiv:2309.14519v1 [cs.CY])

    [http://arxiv.org/abs/2309.14519](http://arxiv.org/abs/2309.14519)

    本研究探讨了ChatGPT在标准化考试准备中的应用，特别是在GRE定量领域。研究结果显示ChatGPT在回答不同类型的GRE问题时表现出良好的问题解决能力，并且修改问题提示可以影响其准确性。

    

    本研究探讨了ChatGPT的问题解决能力以及其在标准化考试准备中的潜在应用，重点关注GRE定量考试。先前的研究已经显示了在各个学科的学习方法革命中，利用ChatGPT进行学术目的的巨大潜力。我们研究了ChatGPT在GRE定量领域不同类型问题上的表现，并且调整问题提示对其准确性的影响。具体地，本研究回答了两个研究问题：1. ChatGPT如何回答GRE基础定量题目在不同内容领域？2. 修改问题提示如何影响ChatGPT的准确性？数据集包含了100个从ETS官方GRE考试准备指南中随机选择的GRE定量问题。我们使用定量评估来回答我们的第一个研究问题，并使用t检验来检查统计关联。

    This study explores the problem solving capabilities of ChatGPT and its prospective applications in standardized test preparation, focusing on the GRE quantitative exam. Prior research has shown great potential for the utilization of ChatGPT for academic purposes in revolutionizing the approach to studying across various disciplines. We investigate how ChatGPT performs across various question types in the GRE quantitative domain, and how modifying question prompts impacts its accuracy. More specifically this study addressed two research questions: 1. How does ChatGPT perform in answering GRE-based quantitative questions across various content areas? 2. How does the accuracy of ChatGPT vary with modifying the question prompts? The dataset consisting of 100 randomly selected GRE quantitative questions was collected from the ETS official guide to GRE test preparation. We used quantitative evaluation to answer our first research question, and t-test to examine the statistical association b
    
[^29]: 注意言辞：大型语言模型和内容审查

    Watch Your Language: Large Language Models and Content Moderation. (arXiv:2309.14517v1 [cs.HC])

    [http://arxiv.org/abs/2309.14517](http://arxiv.org/abs/2309.14517)

    本研究评估了大型语言模型在内容审查任务上的表现，发现它们在基于规则的社区审查和有害内容检测方面具有很好的效果，在有害内容检测方面超过了现有的分类器。然而，最近模型规模的增加对有害内容检测的改进效果很小。

    

    由于其在各种自然语言任务上的能力，大型语言模型（LLMs）变得非常受欢迎。基于文本的内容审查是其中一个受到近期热情关注的LLM应用案例，然而，鲜有研究调查LLMs在内容审查设置中的表现。在这项工作中，我们评估了一套现代、商业化的LLMs（GPT-3、GPT-3.5、GPT-4）在两个常见的内容审查任务上的表现：基于规则的社区审查和有害内容检测。对于基于规则的社区审查，我们构建了95个LLM审查引擎，并使用95个Reddit子社区的规则进行指导，发现LLMs在许多社区的基于规则的审查中表现出色，实现了中位数准确率为64%和中位数精确度为83%。在有害内容检测方面，我们发现LLMs明显优于现有商业可用的有害性分类器。然而，我们还发现最近模型规模的增加对有害内容检测几乎没有带来明显的好处。

    Large language models (LLMs) have exploded in popularity due to their ability to perform a wide array of natural language tasks. Text-based content moderation is one LLM use case that has received recent enthusiasm, however, there is little research investigating how LLMs perform in content moderation settings. In this work, we evaluate a suite of modern, commercial LLMs (GPT-3, GPT-3.5, GPT-4) on two common content moderation tasks: rule-based community moderation and toxic content detection. For rule-based community moderation, we construct 95 LLM moderation-engines prompted with rules from 95 Reddit subcommunities and find that LLMs can be effective at rule-based moderation for many communities, achieving a median accuracy of 64% and a median precision of 83%. For toxicity detection, we find that LLMs significantly outperform existing commercially available toxicity classifiers. However, we also find that recent increases in model size add only marginal benefit to toxicity detection
    
[^30]: DeepSpeed Ulysses：用于训练极长序列Transformer模型的系统优化

    DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models. (arXiv:2309.14509v1 [cs.LG])

    [http://arxiv.org/abs/2309.14509](http://arxiv.org/abs/2309.14509)

    本论文介绍了DeepSpeed-Ulysses，一种用于实现具备极长序列长度的高效可扩展LLM训练的新颖方法。

    

    传统的基于Transformer的大型语言模型（LLM）的计算可以通过批量大小、隐藏维度、层数和序列长度来描述。到目前为止，加速LLM训练的系统工作主要集中在前三个维度上：批量大小的数据并行化、隐藏尺寸的张量并行化以及模型深度或层数的流水线并行化。这些被广泛研究的并行形式并不针对长序列Transformer模型进行优化。鉴于长序列LLM在实际应用需求上的重要性，序列并行化引起了重新关注。然而，现有的序列并行化工作受到内存通信效率的限制，限制了它们在长序列大模型上的可扩展性。在这项工作中，我们引入了DeepSpeed-Ulysses，一种新颖、便携且有效的方法，用于实现具备极长序列长度的高效可扩展LLM训练。

    Computation in a typical Transformer-based large language model (LLM) can be characterized by batch size, hidden dimension, number of layers, and sequence length. Until now, system works for accelerating LLM training have focused on the first three dimensions: data parallelism for batch size, tensor parallelism for hidden size and pipeline parallelism for model depth or layers. These widely studied forms of parallelism are not targeted or optimized for long sequence Transformer models. Given practical application needs for long sequence LLM, renewed attentions are being drawn to sequence parallelism. However, existing works in sequence parallelism are constrained by memory-communication inefficiency, limiting their scalability to long sequence large models. In this work, we introduce DeepSpeed-Ulysses, a novel, portable and effective methodology for enabling highly efficient and scalable LLM training with extremely long sequence length. DeepSpeed-Ulysses at its core partitions input da
    
[^31]: 使用角度明可夫斯基$p$-距离分类标记频率

    Classifying token frequencies using angular Minkowski $p$-distance. (arXiv:2309.14495v1 [cs.LG])

    [http://arxiv.org/abs/2309.14495](http://arxiv.org/abs/2309.14495)

    使用角度明可夫斯基$p$-距离可以获得比传统余弦相似度更高的分类性能

    

    角度明可夫斯基$p$-距离是一种使用明可夫斯基$p$-距离替代余弦相似度定义的不相似度测量方法。余弦相似度经常用于包含标记频率的数据集中，而角度明可夫斯基$p$-距离可能在某些任务中是更好的选择。我们在基于20-newsgroups数据集的案例研究中，评估了传统加权最近邻和模糊粗糙最近邻的分类性能。此外，我们还分析了超参数$p$，数据集维数$m$，邻居数量$k$，权重选择和分类器选择之间的关系。我们得出结论：使用合适的$p$值，使用角度明可夫斯基$p$-距离可以获得比传统余弦相似度更高的分类性能。

    Angular Minkowski $p$-distance is a dissimilarity measure that is obtained by replacing Euclidean distance in the definition of cosine dissimilarity with other Minkowski $p$-distances. Cosine dissimilarity is frequently used with datasets containing token frequencies, and angular Minkowski $p$-distance may potentially be an even better choice for certain tasks. In a case study based on the 20-newsgroups dataset, we evaluate clasification performance for classical weighted nearest neighbours, as well as fuzzy rough nearest neighbours. In addition, we analyse the relationship between the hyperparameter $p$, the dimensionality $m$ of the dataset, the number of neighbours $k$, the choice of weights and the choice of classifier. We conclude that it is possible to obtain substantially higher classification performance with angular Minkowski $p$-distance with suitable values for $p$ than with classical cosine dissimilarity.
    
[^32]: 当自动化评估遇上自动化内容生成：在GPT时代审查文本质量

    When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs. (arXiv:2309.14488v1 [cs.CL])

    [http://arxiv.org/abs/2309.14488](http://arxiv.org/abs/2309.14488)

    本研究通过对人类和GPT生成的文本进行实证评估，探讨了基于机器学习模型对文本质量评估的差异。结果表明，在评估GPT生成的文本时，预训练转换器模型的性能较差。

    

    机器学习模型在评估和打分文本数据方面的应用已经在包括自然语言处理、信息检索、搜索和推荐以及在线内容可信度评估等各种情境中变得越来越普遍。在机器学习和文本交叉领域的一次重要变革是生成式预训练转换器（GPT）等生成大型语言模型的使用。我们通过经验性评估人类和GPT生成的文本对于基于人类内容训练的机器学习打分模型如何评估内容质量的差异。为此，我们提出了一个分析框架，该框架包括论文评分机器学习模型、人类和机器学习生成的论文，以及一种可以简洁考虑到被调查者类型、提示类型和评估模型的统计模型。我们利用一个丰富的测试样本，涵盖了18,460篇人工生成和GPT生成的论文。我们的基准分析结果显示，预训练转换器线性分类器在评估GPT生成的论文时性能较差。

    The use of machine learning (ML) models to assess and score textual data has become increasingly pervasive in an array of contexts including natural language processing, information retrieval, search and recommendation, and credibility assessment of online content. A significant disruption at the intersection of ML and text are text-generating large-language models such as generative pre-trained transformers (GPTs). We empirically assess the differences in how ML-based scoring models trained on human content assess the quality of content generated by humans versus GPTs. To do so, we propose an analysis framework that encompasses essay scoring ML-models, human and ML-generated essays, and a statistical model that parsimoniously considers the impact of type of respondent, prompt genre, and the ML model used for assessment model. A rich testbed is utilized that encompasses 18,460 human-generated and GPT-based essays. Results of our benchmark analysis reveal that transformer pretrained lan
    
[^33]: 可解释和准确的语音助手及其它领域的自然语言理解

    Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond. (arXiv:2309.14485v1 [cs.LG])

    [http://arxiv.org/abs/2309.14485](http://arxiv.org/abs/2309.14485)

    这项研究改进了联合NLU模型的准确性，并使其可解释，同时扩展适用于其他分类任务。

    

    联合意图检测和槽填充，也称为联合自然语言理解（NLU），对于智能语音助手非常重要。最近在这个领域的进展主要集中在使用各种技术提高准确性上。可解释性无疑是基于深度学习模型的模型的一个重要方面，包括联合NLU模型。如果没有解释性，它们的决策对外界来说是不透明的，因此容易缺乏用户的信任。因此，为了弥合这一差距，我们将完整的联合NLU模型转化为在细粒度上“内在地”可解释的，同时不影响准确性。此外，通过使完整的联合NLU模型具有可解释性，我们展示了我们的扩展可以成功应用于其他一般分类任务。我们使用情感分析和命名实体识别来证明这一点。

    Joint intent detection and slot filling, which is also termed as joint NLU (Natural Language Understanding) is invaluable for smart voice assistants. Recent advancements in this area have been heavily focusing on improving accuracy using various techniques. Explainability is undoubtedly an important aspect for deep learning-based models including joint NLU models. Without explainability, their decisions are opaque to the outside world and hence, have tendency to lack user trust. Therefore to bridge this gap, we transform the full joint NLU model to be `inherently' explainable at granular levels without compromising on accuracy. Further, as we enable the full joint NLU model explainable, we show that our extension can be successfully used in other general classification tasks. We demonstrate this using sentiment analysis and named entity recognition.
    
[^34]: 在线主动学习声音事件检测

    Online Active Learning For Sound Event Detection. (arXiv:2309.14460v1 [eess.AS])

    [http://arxiv.org/abs/2309.14460](http://arxiv.org/abs/2309.14460)

    通过提出新的损失函数，该论文解决了在线主动学习在声音事件检测中面临的类别分布波动和数据漂移问题，并在实验中证明该方法能够将训练分类器所需的时间和工作量减少5倍。

    

    数据收集和标注是监督机器学习任务的繁琐、耗时的前提条件。在线主动学习（OAL）是一种同时减少训练分类器所需的标注量并适应数据变化的范例。先前的研究表明，波动的类别分布和数据漂移仍然是OAL的常见问题。本文提出了新的损失函数，用于解决当OAL应用于声音事件检测时面临的挑战。SONYC数据集和两个语音类型识别（VTD）语料库的实验结果表明，OAL可以将训练声音事件检测分类器所需的时间和工作量减少5倍，并且本文介绍的新方法成功解决了现有OAL方法中存在的问题。

    Data collection and annotation is a laborious, time-consuming prerequisite for supervised machine learning tasks. Online Active Learning (OAL) is a paradigm that addresses this issue by simultaneously minimizing the amount of annotation required to train a classifier and adapting to changes in the data over the duration of the data collection process. Prior work has indicated that fluctuating class distributions and data drift are still common problems for OAL. This work presents new loss functions that address these challenges when OAL is applied to Sound Event Detection (SED). Experimental results from the SONYC dataset and two Voice-Type Discrimination (VTD) corpora indicate that OAL can reduce the time and effort required to train SED classifiers by a factor of 5 for SONYC, and that the new methods presented here successfully resolve issues present in existing OAL methods.
    
[^35]: 语言模型的物理学：第3.2部分，知识操控

    Physics of Language Models: Part 3.2, Knowledge Manipulation. (arXiv:2309.14402v1 [cs.CL])

    [http://arxiv.org/abs/2309.14402](http://arxiv.org/abs/2309.14402)

    本文研究了语言模型在推理过程中操控知识的能力，发现预训练模型在知识检索方面表现出色，但在简单的分类、比较和逆向搜索任务中表现不佳。作者还提供了一个合成数据集进行实验，验证了这些内在的弱点：语言模型无法高效地操控知识。

    

    语言模型可以存储大量事实知识，但它们在使用这些知识进行逻辑推理方面的能力仍然存在问题。本文探讨了语言模型在推理过程中操控其存储知识的能力。我们重点研究了四种操控类型：检索（例如，“A的属性X是什么”）、分类（例如，“A的属性X是奇数还是偶数”）、比较（例如，“在属性X中A是否大于B”）和逆向搜索（例如，“哪个人的属性X等于T”）。我们观察到，像GPT2/3/4这样的预训练语言模型在知识检索方面表现出色，但在简单的分类或比较任务中很难胜任，除非在训练和推理过程中采用了Chain of Thoughts（CoTs）。无论提示是什么，它们在逆向知识搜索中表现都很差。我们的主要贡献是一个为控制实验而设计的合成数据集，证实了这些内在的弱点：语言模型无法高效地操控知识。

    Language models can store vast amounts of factual knowledge, but their ability to use this knowledge for logical reasoning remains questionable. This paper explores a language model's ability to manipulate its stored knowledge during inference. We focus on four manipulation types: retrieval (e.g., "What is person A's attribute X"), classification (e.g., "Is A's attribute X even or odd?"), comparison (e.g., "Is A greater than B in attribute X?") and inverse search (e.g., "Which person's attribute X equals T?")  We observe that pre-trained language models like GPT2/3/4 excel in knowledge retrieval but struggle with simple classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. They also perform poorly in inverse knowledge search, irrespective of the prompts. Our primary contribution is a synthetic dataset for a controlled experiment that confirms these inherent weaknesses: a language model cannot efficiently manipulate knowledge
    
[^36]: 看见和听到没被说的话：可解释融合的多模态动机性访谈客户行为分类器

    Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion. (arXiv:2309.14398v1 [cs.LG])

    [http://arxiv.org/abs/2309.14398](http://arxiv.org/abs/2309.14398)

    本文提出了一个多模态分类器，在动机性访谈中准确区分了变化话语、持续话语和跟随/中立话语三种类别。该分类器利用文本、声调、面部表情和身体表现等多模态特征，并对AnnoMI数据集进行了注释和训练。研究还找到了决策过程中最重要的模态，提供了宝贵的洞察。

    

    动机性访谈（MI）是一种强调合作并鼓励行为改变的治疗方法。为了评估MI对话的质量，可以利用MISC代码将客户话语分类为变化话语、持续话语或跟随/中立话语。MI对话中变化话语的比例与治疗结果呈正相关，因此准确分类客户话语至关重要。本文提出了一个分类器，利用文本、声调、面部表情和身体表现等多模态特征准确区分三个MISC类别（变化话语、持续话语和跟随/中立话语）。为了训练我们的模型，我们对公开可用的AnnoMI数据集进行注释，收集了文本、音频、面部表情和身体表现等多模态信息。此外，我们还确定了决策过程中最重要的模态，提供了宝贵的洞察。

    Motivational Interviewing (MI) is an approach to therapy that emphasizes collaboration and encourages behavioral change. To evaluate the quality of an MI conversation, client utterances can be classified using the MISC code as either change talk, sustain talk, or follow/neutral talk. The proportion of change talk in a MI conversation is positively correlated with therapy outcomes, making accurate classification of client utterances essential. In this paper, we present a classifier that accurately distinguishes between the three MISC classes (change talk, sustain talk, and follow/neutral talk) leveraging multimodal features such as text, prosody, facial expressivity, and body expressivity. To train our model, we perform annotations on the publicly available AnnoMI dataset to collect multimodal information, including text, audio, facial expressivity, and body expressivity. Furthermore, we identify the most important modalities in the decision-making process, providing valuable insights i
    
[^37]: 多噪声扩散模型用于半监督多域翻译

    Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation. (arXiv:2309.14394v1 [cs.CL])

    [http://arxiv.org/abs/2309.14394](http://arxiv.org/abs/2309.14394)

    本文提出了一种多噪声扩散模型（MDD）用于半监督多域翻译，通过引入噪声级别来对缺失的域进行建模，实现了任意域之间的翻译而不需要训练单独的模型。

    

    域间翻译涉及在给定源域条件下生成目标域样本。大多数现有方法都集中在固定的输入和输出域上，即它们仅适用于特定的配置（例如对于两个域，要么$D_1\rightarrow{}D_2$，要么$D_2\rightarrow{}D_1$）。本文提出了Multi-Domain Diffusion（MDD）方法，这是一种用于半监督多域翻译的条件扩散框架。与以往的方法不同，MDD不需要定义输入和输出域，允许在一组域的任何分区之间进行翻译（例如$(D_1, D_2)\rightarrow{}D_3$，$D_2\rightarrow{}(D_1, D_3)$，$D_3\rightarrow{}D_1$等），而无需为每个域配置训练单独的模型。MDD的关键思想是利用扩散模型的噪声形式，通过为每个域引入一个噪声级别，以自然的方式对缺失的域进行建模。这将传统的翻译问题转化为一个通过噪声建模来解决的问题。

    Domain-to-domain translation involves generating a target domain sample given a condition in the source domain. Most existing methods focus on fixed input and output domains, i.e. they only work for specific configurations (i.e. for two domains, either $D_1\rightarrow{}D_2$ or $D_2\rightarrow{}D_1$). This paper proposes Multi-Domain Diffusion (MDD), a conditional diffusion framework for multi-domain translation in a semi-supervised context. Unlike previous methods, MDD does not require defining input and output domains, allowing translation between any partition of domains within a set (such as $(D_1, D_2)\rightarrow{}D_3$, $D_2\rightarrow{}(D_1, D_3)$, $D_3\rightarrow{}D_1$, etc. for 3 domains), without the need to train separate models for each domain configuration. The key idea behind MDD is to leverage the noise formulation of diffusion models by incorporating one noise level per domain, which allows missing domains to be modeled with noise in a natural way. This transforms the tra
    
[^38]: LLMCarbon: 对大型语言模型的端到端碳足迹建模

    LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models. (arXiv:2309.14393v1 [cs.CL])

    [http://arxiv.org/abs/2309.14393](http://arxiv.org/abs/2309.14393)

    本研究提出了LLMCarbon，一个针对密集型和MoE LLMs设计的端到端碳足迹预测模型，解决了现有工具的限制，并显著提升了估计的准确性。

    

    大型语言模型（LLMs）的碳足迹是一个重要关注点，包括它们的训练、推理、实验和存储过程中的排放，包括运营和固定碳排放。一个重要方面是在LLMs训练之前准确估计其碳影响，这在很大程度上依赖于GPU的使用。现有研究已报告了LLMs训练的碳足迹，但只有一个工具mlco2能够在实际训练之前预测新的神经网络的碳足迹。然而，mlco2存在一些严重的限制。它不能扩展其对密集或专家混合（MoE）LLMs的估计，忽视了关键的架构参数，仅关注GPU，并不能建模固化的碳足迹。为了解决这些问题，我们引入了LLMCarbon，一个为密集型和MoE LLMs设计的端到端碳足迹预测模型。与mlco2相比，LLMCarbon显著增强了准确性。

    The carbon footprint associated with large language models (LLMs) is a significant concern, encompassing emissions from their training, inference, experimentation, and storage processes, including operational and embodied carbon emissions. An essential aspect is accurately estimating the carbon impact of emerging LLMs even before their training, which heavily relies on GPU usage. Existing studies have reported the carbon footprint of LLM training, but only one tool, mlco2, can predict the carbon footprint of new neural networks prior to physical training. However, mlco2 has several serious limitations. It cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs, disregards critical architectural parameters, focuses solely on GPUs, and cannot model embodied carbon footprints. Addressing these gaps, we introduce \textit{LLMCarbon}, an end-to-end carbon footprint projection model designed for both dense and MoE LLMs. Compared to mlco2, LLMCarbon significantly enhances the ac
    
[^39]: 一个用于解释面向服务系统的深度强化学习决策的AI聊天机器人

    An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems. (arXiv:2309.14391v1 [cs.LG])

    [http://arxiv.org/abs/2309.14391](http://arxiv.org/abs/2309.14391)

    一个AI聊天机器人被介绍来解释深度强化学习在面向服务系统中的决策过程，通过提供自然语言解释来帮助用户理解和建立信任。

    

    深度强化学习 (Deep RL) 在面向服务系统中应用越来越多，以应对开放世界的假设。深度强化学习已成功应用于动态服务组合、作业调度、卸载以及服务适应等问题。然而，理解深度强化学习的决策过程具有挑战性，因为其学到的决策策略本质上是一个黑盒子。然而，理解深度强化学习的决策过程对于帮助服务开发人员进行调试、支持服务提供商遵守相关法律框架以及帮助服务使用者建立信任是至关重要的。我们引入了Chat4XAI，通过提供自然语言解释来促进对深度强化学习决策过程的理解。与视觉解释相比，自然语言解释的报告优点包括非技术用户更好的可理解性、用户的接受度和信任度提高，以及更高的效率。

    Deep Reinforcement Learning (Deep RL) is increasingly used to cope with the open-world assumption in service-oriented systems. Deep RL was successfully applied to problems such as dynamic service composition, job scheduling, and offloading, as well as service adaptation. While Deep RL offers many benefits, understanding the decision-making of Deep RL is challenging because its learned decision-making policy essentially appears as a black box. Yet, understanding the decision-making of Deep RL is key to help service developers perform debugging, support service providers to comply with relevant legal frameworks, and facilitate service users to build trust. We introduce Chat4XAI to facilitate the understanding of the decision-making of Deep RL by providing natural-language explanations. Compared with visual explanations, the reported benefits of natural-language explanations include better understandability for non-technical users, increased user acceptance and trust, as well as more effi
    
[^40]: 同意不同意

    Agree To Disagree. (arXiv:2309.14382v1 [cs.CL])

    [http://arxiv.org/abs/2309.14382](http://arxiv.org/abs/2309.14382)

    "同意不同意"论文提出了一种基于机器学习的方法，旨在自动解析和总结使用户便于理解的关键信息，以帮助用户在承诺协议之前考虑重要细节。

    

    在注册服务、安装软件或访问网站之前，个人有多频繁地仔细审查条款和条件？大多数互联网用户并不参与这种做法。鉴于条款和条件通常包含大量复杂的法律术语和晦涩难懂的句子，这种趋势并不令人意外。本文介绍了一种基于机器学习的方法，旨在以用户友好的方式自动解析和总结关键信息。这项技术专注于提取用户在承诺协议之前应考虑的相关细节。

    How frequently do individuals thoroughly review terms and conditions before proceeding to register for a service, install software, or access a website? The majority of internet users do not engage in this practice. This trend is not surprising, given that terms and conditions typically consist of lengthy documents replete with intricate legal terminology and convoluted sentences. In this paper, we introduce a Machine Learning-powered approach designed to automatically parse and summarize critical information in a user-friendly manner. This technology focuses on distilling the pertinent details that users should contemplate before committing to an agreement.
    
[^41]: 社交偏见在视觉-语言模型中的调查

    Survey of Social Bias in Vision-Language Models. (arXiv:2309.14381v1 [cs.CL])

    [http://arxiv.org/abs/2309.14381](http://arxiv.org/abs/2309.14381)

    社交偏见在视觉-语言模型中的调查，旨在为研究人员提供对潜在社会偏见的理解，以解决资源分配不均和不公平代表等问题。

    

    近年来，机器学习模型，尤其是基于Transformer的预训练模型，在自然语言处理和计算机视觉领域取得了快速的发展。然而，研究人员发现这些模型可能会无意中捕捉和强化其训练数据集中存在的社会偏见，导致资源分配不均和对特定社会群体的不公平代表。在人工智能系统中解决这些偏见并确保公平性已经成为机器学习社区的关键关切。最近引入的预训练的视觉-语言模型在新兴的多模态领域中需要关注这些模型中存在的潜在社会偏见。虽然视觉-语言模型容易受到社会偏见的影响，但对于与自然语言处理和计算机视觉中的偏见相比，人们对其了解有限。本调查旨在为研究人员提供高水平的综述和资源，以增进对视觉-语言模型中社会偏见的理解。

    In recent years, the rapid advancement of machine learning (ML) models, particularly transformer-based pre-trained models, has revolutionized Natural Language Processing (NLP) and Computer Vision (CV) fields. However, researchers have discovered that these models can inadvertently capture and reinforce social biases present in their training datasets, leading to potential social harms, such as uneven resource allocation and unfair representation of specific social groups. Addressing these biases and ensuring fairness in artificial intelligence (AI) systems has become a critical concern in the ML community.  The recent introduction of pre-trained vision-and-language (VL) models in the emerging multimodal field demands attention to the potential social biases present in these models as well. Although VL models are susceptible to social bias, there is a limited understanding compared to the extensive discussions on bias in NLP and CV. This survey aims to provide researchers with a high-le
    
[^42]: 机器辅助的混合方法：用人工智能增强人文社科研究

    Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence. (arXiv:2309.14379v1 [cs.CL])

    [http://arxiv.org/abs/2309.14379](http://arxiv.org/abs/2309.14379)

    本研究提出了一种机器辅助的混合方法框架，利用大规模语言模型在人文社科领域的数据分析中的应用潜力，展示了16个案例研究，并涵盖了多种任务，包括语言分析、文本挖掘、社交网络推断等。

    

    大规模语言模型（LLM）的不断进化为人文社科领域的数据分析提供了前所未有的机会，能够在以前通常由人力完成的定性分析任务中实现规模化、自动化。本研究提出了一种系统的混合方法框架，以利用定性分析专业知识、机器的可扩展性和严谨的量化方法，同时注重透明度和可复制性。研究展示了16个机器辅助的案例研究作为概念验证。任务包括语言和话语分析、词汇语义变化检测、采访分析、历史事件因果推断和文本挖掘、政治立场检测、文本和思想重复使用、文学和电影中的文类构成、社交网络推断、自动词典编纂、元数据补充和多模态视觉文化分析。与现有LLM应用文献中对英文的关注不同，本研究涵盖多种语言。

    The increasing capacities of large language models (LLMs) present an unprecedented opportunity to scale up data analytics in the humanities and social sciences, augmenting and automating qualitative analytic tasks previously typically allocated to human labor. This contribution proposes a systematic mixed methods framework to harness qualitative analytic expertise, machine scalability, and rigorous quantification, with attention to transparency and replicability. 16 machine-assisted case studies are showcased as proof of concept. Tasks include linguistic and discourse analysis, lexical semantic change detection, interview analysis, historical event cause inference and text mining, detection of political stance, text and idea reuse, genre composition in literature and film; social network inference, automated lexicography, missing metadata augmentation, and multimodal visual cultural analytics. In contrast to the focus on English in the emerging LLM applicability literature, many exampl
    
[^43]: 基于文本分类的方法用于评估和增强建筑法规的机器可解释性

    A Text Classification-Based Approach for Evaluating and Enhancing the Machine Interpretability of Building Codes. (arXiv:2309.14374v1 [cs.CL])

    [http://arxiv.org/abs/2309.14374](http://arxiv.org/abs/2309.14374)

    该研究提出了一种基于文本分类的方法，自动评估和增强建筑法规的机器可解释性。研究考虑了条款和文档层面的机器可解释性，通过引入几个类别进行分类并开发了一个数据集进行模型训练，并开发了一个高效的文本分类模型。

    

    将监管文件或建筑法规解释为可计算机处理的格式对于智能设计和建造建筑和基础设施至关重要。虽然自动化规则解释（ARI）方法已经研究多年，但其中大部分方法都严重依赖于从建筑法规中早期和手动筛选可解释条款。 虽然其中少数方法考虑了从条款和文档层面上的机器可解释性，但这代表了将其转化为可计算机处理格式的潜力。因此，本研究旨在提出一种新的方法，自动评估和增强单个条款和建筑法规的机器可解释性。首先，引入了几个类别，以考虑对规则解释的要求对每个建筑法规条款进行分类，并开发了一个数据集来进行模型训练。然后，基于预训练的领域特定语言的高效文本分类模型被开发出来。

    Interpreting regulatory documents or building codes into computer-processable formats is essential for the intelligent design and construction of buildings and infrastructures. Although automated rule interpretation (ARI) methods have been investigated for years, most of them highly depend on the early and manual filtering of interpretable clauses from a building code. While few of them considered machine interpretability, which represents the potential to be transformed into a computer-processable format, from both clause- and document-level. Therefore, this research aims to propose a novel approach to automatically evaluate and enhance the machine interpretability of single clause and building codes. First, a few categories are introduced to classify each clause in a building code considering the requirements for rule interpretation, and a dataset is developed for model training. Then, an efficient text classification model is developed based on a pretrained domain-specific language 
    
[^44]: 人类转录质量改进

    Human Transcription Quality Improvement. (arXiv:2309.14372v1 [cs.CL])

    [http://arxiv.org/abs/2309.14372](http://arxiv.org/abs/2309.14372)

    本文提出了一种可靠的方法来收集高质量的语音转录数据，通过在标注阶段进行置信度估计的重新处理和在标注后阶段进行自动词错误修正，成功降低了转录词误率（WER），并发现了转录错误对ASR模型性能的强相关性。

    

    高质量的转录数据对于训练自动语音识别（ASR）系统至关重要。然而，现有的行业级数据收集管道对研究人员来说成本高昂，而众包转录的质量较低。在本文中，我们提出了一种可靠的方法来收集语音转录。我们引入了两种机制来改善转录质量：在标注阶段基于置信度估计的重新处理和在标注后阶段的自动词错误修正。我们收集并发布了LibriCrowd - 一个包含100小时英语语音转录的大规模众包数据集。实验表明，转录词误率（WER）降低了50%以上。我们进一步研究了转录错误对ASR模型性能的影响，并发现了强相关性。转录质量的提升使ASR模型的WER相对减少了10%以上。我们发布了数据集和代码，以造福研究界。

    High quality transcription data is crucial for training automatic speech recognition (ASR) systems. However, the existing industry-level data collection pipelines are expensive to researchers, while the quality of crowdsourced transcription is low. In this paper, we propose a reliable method to collect speech transcriptions. We introduce two mechanisms to improve transcription quality: confidence estimation based reprocessing at labeling stage, and automatic word error correction at post-labeling stage. We collect and release LibriCrowd - a large-scale crowdsourced dataset of audio transcriptions on 100 hours of English speech. Experiment shows the Transcription WER is reduced by over 50%. We further investigate the impact of transcription error on ASR model performance and found a strong correlation. The transcription quality improvement provides over 10% relative WER reduction for ASR models. We release the dataset and code to benefit the research community.
    
[^45]: 基于大型语言模型的人工智能代理的深度调查

    An In-depth Survey of Large Language Model-based Artificial Intelligence Agents. (arXiv:2309.14365v1 [cs.CL])

    [http://arxiv.org/abs/2309.14365](http://arxiv.org/abs/2309.14365)

    本文研究了基于大型语言模型的AI代理与传统AI代理之间的核心差异和特点，并引入了一种创新的记忆分类方案，提供了全新的设计视角。

    

    由于大型语言模型（LLM）展示了强大的能力，最近人们一直在努力将它们与人工智能代理结合起来，以提高其性能。本文探讨了LLM-based AI代理与传统AI代理之间的核心差异和特点。具体而言，我们首先比较了这两种类型代理的基本特征，阐明了LLM-based代理在处理自然语言、知识存储和推理能力方面的显著优势。随后，我们对AI代理的关键组成部分，包括规划、记忆和工具使用进行了深入分析。尤其是对于关键的记忆组件，本文引入了一种创新的分类方案，不仅远离了传统的分类方法，而且为AI代理的记忆系统设计提供了全新的视角。我们坚信对这些核心组件进行深入的研究和理解

    Due to the powerful capabilities demonstrated by large language model (LLM), there has been a recent surge in efforts to integrate them with AI agents to enhance their performance. In this paper, we have explored the core differences and characteristics between LLM-based AI agents and traditional AI agents. Specifically, we first compare the fundamental characteristics of these two types of agents, clarifying the significant advantages of LLM-based agents in handling natural language, knowledge storage, and reasoning capabilities. Subsequently, we conducted an in-depth analysis of the key components of AI agents, including planning, memory, and tool use. Particularly, for the crucial component of memory, this paper introduced an innovative classification scheme, not only departing from traditional classification methods but also providing a fresh perspective on the design of an AI agent's memory system. We firmly believe that in-depth research and understanding of these core components
    
[^46]: 通过外部自然问题在知识库上进行多样化问题生成

    Diversifying Question Generation over Knowledge Base via External Natural Questions. (arXiv:2309.14362v1 [cs.CL])

    [http://arxiv.org/abs/2309.14362](http://arxiv.org/abs/2309.14362)

    通过引入新的多样性评估指标，我们提出了一种通过外部自然问题在知识库上进行多样化问题生成的方法。同时，我们设计了一个双模型框架来解决如何增强多样化问题生成的挑战。

    

    先前的知识库问题生成方法主要集中在提高单个生成问题的质量。我们认为，人类出色的改写能力表明相同的语义可以通过不同的表达来传达。以上观点使得多样化问题生成成为一个有趣的任务，其中第一个挑战是多样性评估指标。当前的指标不足以评估多样性，因为它们仅计算生成问题中唯一n-gram的比例，更倾向于衡量重复而非真正的多样性。因此，我们设计了一个新的多样性评估指标，它衡量每个实例的前k个生成问题之间的多样性，同时确保它们与基准问题相关。显然，第二个挑战是如何增强多样化问题生成。为了解决这个问题，我们引入了一个由两个选择模型交织而成的双模型框架。

    Previous methods on knowledge base question generation (KBQG) primarily focus on enhancing the quality of a single generated question. Recognizing the remarkable paraphrasing ability of humans, we contend that diverse texts should convey the same semantics through varied expressions. The above insights make diversifying question generation an intriguing task, where the first challenge is evaluation metrics for diversity. Current metrics inadequately assess the above diversity since they calculate the ratio of unique n-grams in the generated question itself, which leans more towards measuring duplication rather than true diversity. Accordingly, we devise a new diversity evaluation metric, which measures the diversity among top-k generated questions for each instance while ensuring their relevance to the ground truth. Clearly, the second challenge is how to enhance diversifying question generation. To address this challenge, we introduce a dual model framework interwoven by two selection
    
[^47]: COCO-Counterfactuals:自动构建图像-文本对的反事实例

    COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs. (arXiv:2309.14356v1 [cs.LG])

    [http://arxiv.org/abs/2309.14356](http://arxiv.org/abs/2309.14356)

    COCO-Counterfactuals是一个自动构建图像-文本对的反事实例的框架，通过使用文本到图像扩散模型来自动生成多模态反事实例。通过人工评估，我们验证了COCO-Counterfactuals的质量，并展示了其对于改善域外泛化能力的实用性。

    

    反事实例在自然语言处理(NLP)领域中已证明对于评估和改进语言模型对数据集中的虚假相关性的鲁棒性非常有价值。尽管反事实例在NLP领域具有显著的效用，但由于创建最小反事实变化的图像-文本配对数据的难度，多模态反事实例的研究相对较少。为了解决这一挑战，我们引入了一个可扩展的框架，利用文本到图像扩散模型自动生成反事实例。我们使用这个框架来创建COCO-Counterfactuals，这是一个基于MS-COCO数据集的多模态反事实数据集，包括图像和文本标题的配对。我们通过人工评估验证了COCO-Counterfactuals的质量，并展示了现有的多模态模型在我们的反事实图像-文本配对中面临的挑战。此外，我们展示了COCO-Counterfactuals在改善域外泛化能力方面的实用性。

    Counterfactual examples have proven to be valuable in the field of natural language processing (NLP) for both evaluating and improving the robustness of language models to spurious correlations in datasets. Despite their demonstrated utility for NLP, multimodal counterfactual examples have been relatively unexplored due to the difficulty of creating paired image-text data with minimal counterfactual changes. To address this challenge, we introduce a scalable framework for automatic generation of counterfactual examples using text-to-image diffusion models. We use our framework to create COCO-Counterfactuals, a multimodal counterfactual dataset of paired image and text captions based on the MS-COCO dataset. We validate the quality of COCO-Counterfactuals through human evaluations and show that existing multimodal models are challenged by our counterfactual image-text pairs. Additionally, we demonstrate the usefulness of COCO-Counterfactuals for improving out-of-domain generalization of 
    
[^48]: PopBERT. 检测德国联邦议院中的民粹主义及其主导意识形态

    PopBERT. Detecting populism and its host ideologies in the German Bundestag. (arXiv:2309.14355v1 [cs.CL])

    [http://arxiv.org/abs/2309.14355](http://arxiv.org/abs/2309.14355)

    本文提出了一种可靠、有效且可扩展的方法来衡量民粹主义立场，通过在德国联邦议院的演讲中进行语言标记，训练了一个基于Transformer的模型（PopBERT）来检测和量化民粹主义的核心维度，并确定民粹主义陈述与左翼或右翼主导意识形态的关联。

    

    民粹主义的崛起引起了许多政治学家和从业人员的关注，然而对其潜在语言的检测仍然不完整。本文旨在提供一种可靠、有效且可扩展的方法来衡量民粹主义立场。为此，我们基于德国联邦议院的议会演讲(2013年至2021年)创建了一个带注释的数据集。遵循民粹主义的概念定义，我们将对高尚人民或腐败精英的道德引用标记为民粹主义语言的核心维度。为了进一步确定民粹主义薄意识形态的形成方式，我们注释了民粹主义陈述如何与左翼或右翼的主导意识形态相关。然后，我们训练了一个基于Transformer的模型（PopBERT）作为一个多标签分类器，用于检测和量化每个维度。一系列验证检查显示该模型预测准确性强，具有高质量的面部有效性，与专家调查的党派排名相吻合，并检测出-of-sa

    The rise of populism concerns many political scientists and practitioners, yet the detection of its underlying language remains fragmentary. This paper aims to provide a reliable, valid, and scalable approach to measure populist stances. For that purpose, we created an annotated dataset based on parliamentary speeches of the German Bundestag (2013 to 2021). Following the ideational definition of populism, we label moralizing references to the virtuous people or the corrupt elite as core dimensions of populist language. To identify, in addition, how the thin ideology of populism is thickened, we annotate how populist statements are attached to left-wing or right-wing host ideologies. We then train a transformer-based model (PopBERT) as a multilabel classifier to detect and quantify each dimension. A battery of validation checks reveals that the model has a strong predictive accuracy, provides high qualitative face validity, matches party rankings of expert surveys, and detects out-of-sa
    
[^49]: 通过稳健对齐的LLM抵御对齐破坏攻击

    Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM. (arXiv:2309.14348v1 [cs.CL])

    [http://arxiv.org/abs/2309.14348](http://arxiv.org/abs/2309.14348)

    本文提出了一种稳健对齐的LLM（RA-LLM），用于防御可能发生的对齐破坏攻击。RA-LLM可以直接在现有的对齐LLM上构建，并通过稳健的对齐检查函数来确保其有效性。

    

    最近，大型语言模型（LLMs）取得了显著的进展，并在各个领域得到广泛应用。不幸的是，人们越来越担心LLMs可能被滥用来生成有害或恶意内容。尽管有一系列的研究专注于对齐LLMs与人类价值观，并防止它们生成不适当的内容，但这些对齐通常是脆弱的，并且可以通过对抗优化或手工构建的越狱提示来绕过。在这项工作中，我们介绍了一种稳健对齐的LLM（RA-LLM），以防范潜在的对齐破坏攻击。RA-LLM可以直接构建在现有的对齐LLM上，通过具有稳健对齐检查功能的方法，而无需对原始LLM进行任何昂贵的重新训练或微调。此外，我们还通过理论分析验证了RA-LLM在防御对齐破坏攻击方面的有效性。通过现实世界的实验，

    Recently, Large Language Models (LLMs) have made significant advancements and are now widely used across various domains. Unfortunately, there has been a rising concern that LLMs can be misused to generate harmful or malicious content. Though a line of research has focused on aligning LLMs with human values and preventing them from producing inappropriate content, such alignments are usually vulnerable and can be bypassed by alignment-breaking attacks via adversarially optimized or handcrafted jailbreaking prompts. In this work, we introduce a Robustly Aligned LLM (RA-LLM) to defend against potential alignment-breaking attacks. RA-LLM can be directly constructed upon an existing aligned LLM with a robust alignment checking function, without requiring any expensive retraining or fine-tuning process of the original LLM. Furthermore, we also provide a theoretical analysis for RA-LLM to verify its effectiveness in defending against alignment-breaking attacks. Through real-world experiments
    
[^50]: 连接语音编码器和大型语言模型用于ASR

    Connecting Speech Encoder and Large Language Model for ASR. (arXiv:2309.13963v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2309.13963](http://arxiv.org/abs/2309.13963)

    本文通过比较研究了三种连接结构，即全连接层、多头交叉注意力和Q-Former，将语音编码器与大型语言模型相结合，实现了在自动语音识别中显著降低词错误率的效果。其中，基于Q-Former的大型语言模型在Out-of-Domain数据集上展现出了良好的泛化能力，并且相比基准模型实现了12%的相对词错误率降低。 (arXiv:2309.13963v2 [eess.AS] UPDATED)

    

    大型语言模型(LLMs)的出色能力和多功能性引起了自动语音识别(ASR)领域的越来越多关注，几项开创性研究尝试通过连接语音编码器和LLMs构建一体化ASR模型。本文对三种常用的连接结构进行了比较研究，包括全连接层、多头交叉注意力和Q-Former。研究了Whisper模型系列的语音编码器以及Vicuna模型系列的LLMs，包括不同的模型大小。在常用的LibriSpeech、Common Voice和GigaSpeech数据集上进行了实验，在LLMs与其他连接结构相比，基于Q-Former的LLMs在词错误率(WER)上表现出一致且显著的降低。基于Q-Former的LLMs在领域外数据集上表现良好，在Eval2000测试集上相比Whisper基准ASR模型实现了12%的相对WER降低，而无需使用额外的领域适应数据。

    The impressive capability and versatility of large language models (LLMs) have aroused increasing attention in automatic speech recognition (ASR), with several pioneering studies attempting to build integrated ASR models by connecting a speech encoder with an LLM. This paper presents a comparative study of three commonly used structures as connectors, including fully connected layers, multi-head cross-attention, and Q-Former. Speech encoders from the Whisper model series as well as LLMs from the Vicuna model series with different model sizes were studied. Experiments were performed on the commonly used LibriSpeech, Common Voice, and GigaSpeech datasets, where the LLMs with Q-Formers demonstrated consistent and considerable word error rate (WER) reductions over LLMs with other connector structures. Q-Former-based LLMs can generalise well to out-of-domain datasets, where 12% relative WER reductions over the Whisper baseline ASR model were achieved on the Eval2000 test set without using a
    
[^51]: MiChao-HuaFen 1.0：面向领域特定大模型的专用预训练语料数据集

    MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models. (arXiv:2309.13079v1 [cs.CL])

    [http://arxiv.org/abs/2309.13079](http://arxiv.org/abs/2309.13079)

    MiChao-HuaFen 1.0是一个专为新闻和政府部门定制的面向领域特定大模型的预训练语料数据集，它不仅能够满足特定领域的高质量需求，还有助于推动相关领域的深度学习研究和应用。

    

    随着深度学习技术的进步，如GPT-4等通用大模型已经在各个领域展现出卓越的能力。然而，在诸如医疗、法律和金融等领域仍然存在对高质量的领域特定输出的需求。本文首先评估了现有的面向特定领域的大模型，并讨论了它们的局限性。为了满足特定领域的特殊需求，我们引入了“MiChao-HuaFen 1.0”预训练语料数据集，该数据集特别针对新闻和政府部门。该数据集来源于2022年公开可用的互联网数据，经过多轮清洁和处理以确保高质量和可靠性，并具备持续和稳定的更新机制。该数据集不仅支持针对中文垂直领域的大模型的预训练，还助力于推动相关领域的深度学习研究和应用。

    With the advancement of deep learning technologies, general-purpose large models such as GPT-4 have demonstrated exceptional capabilities across various domains. Nevertheless, there remains a demand for high-quality, domain-specific outputs in areas like healthcare, law, and finance. This paper first evaluates the existing large models for specialized domains and discusses their limitations. To cater to the specific needs of certain domains, we introduce the ``MiChao-HuaFen 1.0'' pre-trained corpus dataset, tailored for the news and governmental sectors. The dataset, sourced from publicly available internet data from 2022, underwent multiple rounds of cleansing and processing to ensure high quality and reliable origins, with provisions for consistent and stable updates. This dataset not only supports the pre-training of large models for Chinese vertical domains but also aids in propelling deep learning research and applications in related fields.
    
[^52]: InvestLM：使用金融领域指导调优的大型语言模型

    InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning. (arXiv:2309.13064v1 [q-fin.GN])

    [http://arxiv.org/abs/2309.13064](http://arxiv.org/abs/2309.13064)

    InvestLM是一个通过对金融领域指导数据集进行调优的大型语言模型，具有强大的理解金融文本的能力，并在投资相关问题上提供有帮助的回答。金融专家评价其与最先进的商业模型可媲美，并在金融NLP基准问题上展现了强大的泛化能力。

    

    我们介绍了一种新的金融领域大型语言模型InvestLM，该模型通过精心策划的与金融投资相关的指导数据集对LLaMA-65B进行调优。受到“少即是多”的启发，我们手动策划了一个既小又多样的指导数据集，涵盖了从特许金融分析师（CFA）考试问题到SEC文件和Stackexchange量化金融讨论的广泛金融相关主题。InvestLM表现出良好的理解金融文本的能力，并对投资相关问题提供有帮助的回答。包括对冲基金经理和研究分析师在内的金融专家将InvestLM的回答评价为与最先进的商业模型（GPT-3.5、GPT-4和Claude-2）可媲美。对一组金融NLP基准问题进行零样本评估表明了其强大的泛化能力。从研究角度来看，本研究表明可以使用高质量的领域特定LLM进行调优。

    We present a new financial domain large language model, InvestLM, tuned on LLaMA-65B (Touvron et al., 2023), using a carefully curated instruction dataset related to financial investment. Inspired by less-is-more-for-alignment (Zhou et al., 2023), we manually curate a small yet diverse instruction dataset, covering a wide range of financial related topics, from Chartered Financial Analyst (CFA) exam questions to SEC filings to Stackexchange quantitative finance discussions. InvestLM shows strong capabilities in understanding financial text and provides helpful responses to investment related questions. Financial experts, including hedge fund managers and research analysts, rate InvestLM's response as comparable to those of state-of-the-art commercial models (GPT-3.5, GPT-4 and Claude-2). Zero-shot evaluation on a set of financial NLP benchmarks demonstrates strong generalizability. From a research perspective, this work suggests that a high-quality domain specific LLM can be tuned usin
    
[^53]: 多模态深度学习用于科学成像解释

    Multimodal Deep Learning for Scientific Imaging Interpretation. (arXiv:2309.12460v1 [cs.LG])

    [http://arxiv.org/abs/2309.12460](http://arxiv.org/abs/2309.12460)

    本研究提出了一种多模态深度学习框架，通过模拟人类与扫描电子显微镜图像的交互，利用文本和视觉数据进行精细数据合成和评估。该模型（GlassLLaVA）能够准确解释、识别关键特征和检测以前未见的SEM图像中的缺陷，同时引入了适用于多种科学成像应用的灵活评估指标。

    

    在科学成像领域，解释视觉数据常常需要人类专业知识和对主题材料的深入理解的复杂组合。本研究提出了一种新的方法，通过多模态深度学习框架来模拟并评估与扫描电子显微镜（SEM）图像的人类交互，特别是玻璃材料图像。我们的方法利用从同行评议的文章中收集的文本和视觉数据，进一步借助 GPT-4 的能力进行精细数据合成和评估。尽管存在诸多挑战，如细微的解释和专业数据集的有限可用性，但我们的模型（GlassLLaVA）在制定准确的解释、识别关键特征和检测以前未见的SEM图像中的缺陷方面表现出色。此外，我们引入了适用于多种科学成像应用的灵活评估指标，使得进行综合评估成为可能。

    In the domain of scientific imaging, interpreting visual data often demands an intricate combination of human expertise and deep comprehension of the subject materials. This study presents a novel methodology to linguistically emulate and subsequently evaluate human-like interactions with Scanning Electron Microscopy (SEM) images, specifically of glass materials. Leveraging a multimodal deep learning framework, our approach distills insights from both textual and visual data harvested from peer-reviewed articles, further augmented by the capabilities of GPT-4 for refined data synthesis and evaluation. Despite inherent challenges--such as nuanced interpretations and the limited availability of specialized datasets--our model (GlassLLaVA) excels in crafting accurate interpretations, identifying key features, and detecting defects in previously unseen SEM images. Moreover, we introduce versatile evaluation metrics, suitable for an array of scientific imaging applications, which allows for
    
[^54]: MBR和QE微调：对最佳和最昂贵的解码方法进行训练时蒸馏

    MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods. (arXiv:2309.10966v1 [cs.CL])

    [http://arxiv.org/abs/2309.10966](http://arxiv.org/abs/2309.10966)

    本文提出了MBR微调和QE微调方法，将训练时的质量提升蒸馏到基准模型中，从而在推断时使用高效的解码算法。实验证明，这些微调方法能显著提升模型性能，甚至超过基准模型。

    

    最近在自然语言生成（NLG）任务的解码方法研究中表明，传统的波束搜索和贪婪解码算法并不是最优的，因为模型概率不总是与人类偏好一致。为了解决模型困惑度与质量不匹配的问题，提出了一些更强的解码方法，包括质量估计（QE）重排序和最小贝叶斯风险（MBR）解码。尽管这些解码方法实现了最先进的性能，但计算成本过高。在这项工作中，我们提出了MBR微调和QE微调，这些微调方法在训练时蒸馏了这些解码方法的质量提升，在推断时使用高效的解码算法。通过使用神经机器翻译（NMT）这一典型的NLG任务，我们表明即使进行自训练，这些微调方法的性能仍明显优于基准模型。此外，当使用外部LLM作为教师模型时，这些微调方法也表现出了卓越的性能。

    Recent research in decoding methods for Natural Language Generation (NLG) tasks has shown that the traditional beam search and greedy decoding algorithms are not optimal, because model probabilities do not always align with human preferences. Stronger decoding methods, including Quality Estimation (QE) reranking and Minimum Bayes' Risk (MBR) decoding, have since been proposed to mitigate the model-perplexity-vs-quality mismatch. While these decoding methods achieve state-of-the-art performance, they are prohibitively expensive to compute. In this work, we propose MBR finetuning and QE finetuning which distill the quality gains from these decoding methods at training time, while using an efficient decoding algorithm at inference time. Using the canonical NLG task of Neural Machine Translation (NMT), we show that even with self-training, these finetuning methods significantly outperform the base model. Moreover, when using an external LLM as a teacher model, these finetuning methods outp
    
[^55]: 对多模态大规模语言模型中的灾难性遗忘进行的研究

    Investigating the Catastrophic Forgetting in Multimodal Large Language Models. (arXiv:2309.10313v1 [cs.CL])

    [http://arxiv.org/abs/2309.10313](http://arxiv.org/abs/2309.10313)

    本论文针对多模态大规模语言模型中的灾难性遗忘问题进行研究，引入了EMT方法来评估灾难性遗忘，并发现在标准图像分类任务上，几乎所有评估的模型都无法保持与视觉编码器相同的性能水平。研究结果表明，早期微调阶段对性能至关重要。

    

    在GPT4的成功之后，多模态大规模语言模型（MLLM）研究引起了广泛关注。这一研究方向侧重于通过微调预训练的LLM和视觉模型来开发通用的LLM。然而，灾难性遗忘，即微调模型无法保持与预训练模型相似的性能水平，仍然是多模态LLM（MLLM）中的一个固有问题。本文介绍了EMT：用于评估MLLM中灾难性遗忘的评估方法，将每个MLLM作为一个图像分类器进行评估。我们首先应用EMT来评估几个开源的微调MLLM，并发现几乎所有评估的MLLM在标准图像分类任务上无法保持与他们的视觉编码器相同的性能水平。此外，我们继续微调LLaVA，一种MLLM，并利用EMT来评估整个微调过程中的性能。有趣的是，我们的结果表明，早期的微调阶段是关键的，过早停止微调可能导致低性能的模型。

    Following the success of GPT4, there has been a surge in interest in multimodal large language model (MLLM) research. This line of research focuses on developing general-purpose LLMs through fine-tuning pre-trained LLMs and vision models. However, catastrophic forgetting, a notorious phenomenon where the fine-tuned model fails to retain similar performance compared to the pre-trained model, still remains an inherent problem in multimodal LLMs (MLLM). In this paper, we introduce EMT: Evaluating MulTimodality for evaluating the catastrophic forgetting in MLLMs, by treating each MLLM as an image classifier. We first apply EMT to evaluate several open-source fine-tuned MLLMs and we discover that almost all evaluated MLLMs fail to retain the same performance levels as their vision encoders on standard image classification tasks. Moreover, we continue fine-tuning LLaVA, an MLLM and utilize EMT to assess performance throughout the fine-tuning. Interestingly, our results suggest that early-sta
    
[^56]: 超越本地范围：全球图增强个性化新闻推荐

    Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v1 [cs.IR])

    [http://arxiv.org/abs/2307.06576](http://arxiv.org/abs/2307.06576)

    本文介绍了一种名为GLORY的模型，通过全局图与本地表示相结合，增强了个性化推荐系统。该模型通过构建全局感知历史新闻编码器来融合历史新闻表示，并考虑了用户隐藏的动机和行为。

    

    精确地向用户推荐候选新闻文章一直是个性化新闻推荐系统的核心挑战。大多数近期的研究主要集中在使用先进的自然语言处理技术从丰富的文本数据中提取语义信息，使用从本地历史新闻派生的基于内容的方法。然而，这种方法缺乏全局视角，未能考虑用户隐藏的动机和行为，超越语义信息。为了解决这个问题，我们提出了一种新颖的模型 GLORY（Global-LOcal news Recommendation sYstem），它结合了从其他用户学到的全局表示和本地表示，来增强个性化推荐系统。我们通过构建一个全局感知历史新闻编码器来实现这一目标，其中包括一个全局新闻图，并使用门控图神经网络来丰富新闻表示，从而通过历史新闻聚合器融合历史新闻表示。

    Precisely recommending candidate news articles to users has always been a core challenge for personalized news recommendation systems. Most recent works primarily focus on using advanced natural language processing techniques to extract semantic information from rich textual data, employing content-based methods derived from local historical news. However, this approach lacks a global perspective, failing to account for users' hidden motivations and behaviors beyond semantic information. To address this challenge, we propose a novel model called GLORY (Global-LOcal news Recommendation sYstem), which combines global representations learned from other users with local representations to enhance personalized recommendation systems. We accomplish this by constructing a Global-aware Historical News Encoder, which includes a global news graph and employs gated graph neural networks to enrich news representations, thereby fusing historical news representations by a historical news aggregator.
    
[^57]: MO-VLN:一个用于开放集合零样本视觉和语言导航的多任务基准 (arXiv:2306.10322v2 [cs.CV] 更新)

    MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation. (arXiv:2306.10322v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.10322](http://arxiv.org/abs/2306.10322)

    MO-VLN是一个用于评估通用机器人在多任务环境中的视觉和语言导航的基准，通过使用虚幻引擎5开发逼真的场景和包含多种不常见物体来测试其效果和泛化能力。

    

    给定一个自然语言，一个通用的机器人必须理解指令并根据视觉观察找到目标对象或位置，即使在未探索的环境中也能做到。大多数代理依赖于大量多样的训练数据以实现更好的泛化，这需要昂贵的劳动力。这些代理通常只关注常见的对象和较少的任务，因此不足以处理不同类型的指令。为了促进开放集合视觉和语言导航的研究，我们提出了一个名为MO-VLN的基准，旨在测试代理在多任务设置中的有效性和泛化能力。首先，我们使用虚幻引擎5开发了一个3D模拟器，渲染了逼真的场景，包含更真实的光照和细节。模拟器包含三个场景，即咖啡馆、餐厅和养老院，这些场景在工业中具有很高的价值。此外，我们的模拟器涉及多种不常见的物体，如外卖杯和医用胶带，这些物体更加复杂。

    Given a natural language, a general robot has to comprehend the instruction and find the target object or location based on visual observations even in unexplored environments. Most agents rely on massive diverse training data to achieve better generalization, which requires expensive labor. These agents often focus on common objects and fewer tasks, thus are not intelligent enough to handle different types of instructions. To facilitate research in open-set vision-and-language navigation, we propose a benchmark named MO-VLN, aiming at testing the effectiveness and generalization of the agent in the multi-task setting. First, we develop a 3D simulator rendered by realistic scenarios using Unreal Engine 5, containing more realistic lights and details. The simulator contains three scenes, i.e., cafe, restaurant, and nursing house, of high value in the industry. Besides, our simulator involves multiple uncommon objects, such as takeaway cup and medical adhesive tape, which are more compli
    
[^58]: Med-UniC：通过减少偏见实现跨语言医学图像-语言预训练的统一

    Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias. (arXiv:2305.19894v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.19894](http://arxiv.org/abs/2305.19894)

    Med-UniC是一个新的框架，旨在通过整合英语和西班牙语的跨语言医学数据，实现跨语言医学图像-语言预训练的统一。他们提出了跨语言文本对齐规则(CTR)，以明确统一来自不同语言社区的医学报告的跨语言语义表示。

    

    数据稀缺性对医学图像-语言预训练(VLP)的效果造成了严重障碍。解决方案可能在于结合来自各种语言社区的数据集。然而，主要挑战来自于整合不同的语法和语义、特定于语言的医学术语以及特定于文化的隐式知识的复杂性。因此，一个关键的考虑因素是由不同语言引起的社区偏见的存在。本文介绍了一种名为统一跨语言医学图像-语言预训练(Med-UniC)的新框架，旨在整合来自两种最常见语言的多模态医学数据，即英语和西班牙语。具体而言，我们提出了跨语言文本对齐规则(CTR)，明确统一来自不同语言社区的医学报告的跨语言语义表示。通过潜在语言解缠，优化CTR，使我们的优化成果。

    The scarcity of data presents a critical obstacle to the efficacy of medical visionlanguage pre-training (VLP). A potential solution lies in the combination of datasets from various language communities. Nevertheless, the main challenge stems from the complexity of integrating diverse syntax and semantics, language-specific medical terminology, and culture-specific implicit knowledge. Therefore, one crucial aspect to consider is the presence of community bias caused by different languages. This paper presents a novel framework named Unifying Cross-Lingual Medical Vision-Language Pre-Training (Med-UniC), designed to integrate multimodal medical data from the two most prevalent languages, English and Spanish. Specifically, we propose Cross-lingual Text Alignment Regularization (CTR) to explicitly unify cross-lingual semantic representations of medical reports originating from diverse language communities. CTR is optimized through latent language disentanglement, rendering our optimizatio
    
[^59]: 利用语义先验细化的弱监督视觉-文本对齐

    Weakly-Supervised Visual-Textual Grounding with Semantic Prior Refinement. (arXiv:2305.10913v1 [cs.CV])

    [http://arxiv.org/abs/2305.10913](http://arxiv.org/abs/2305.10913)

    本文提出了一种利用语义先验细化的弱监督视觉-文本对齐方法，仅使用图像-句子对进行学习，其目标是实现实体表示中的区域-短语对应关系，通过联合两个主要模块的输出进行预测。

    

    弱监督视觉-文本对齐的目标是仅利用图像-句子对学习实体表示中的区域-短语对应关系。与监督方法相比，其难度更大，因为无法获得边界框和文本短语的对应关系。因此，我们提出了语义先验细化模型（SPRM），其预测结果是通过组合两个主要模块的输出得到的。第一个未经训练的模块旨在返回文本短语和边界框之间的粗略对齐。第二个训练过的模块由两个子组件组成，用于细化粗略的对齐以提高最终短语-边界框对齐的准确性。该模型的训练目标是最大化图像和句子之间的多模态相似度，同时使同一句子和一个新的不相关的图像的多模态相似度最小化，以在训练过程中最大限度地提高训练效果。我们的方法在两个流行的数据集上展现了最先进的结果。

    Using only image-sentence pairs, weakly-supervised visual-textual grounding aims to learn region-phrase correspondences of the respective entity mentions. Compared to the supervised approach, learning is more difficult since bounding boxes and textual phrases correspondences are unavailable. In light of this, we propose the Semantic Prior Refinement Model (SPRM), whose predictions are obtained by combining the output of two main modules. The first untrained module aims to return a rough alignment between textual phrases and bounding boxes. The second trained module is composed of two sub-components that refine the rough alignment to improve the accuracy of the final phrase-bounding box alignments. The model is trained to maximize the multimodal similarity between an image and a sentence, while minimizing the multimodal similarity of the same sentence and a new unrelated image, carefully selected to help the most during training. Our approach shows state-of-the-art results on two popula
    
[^60]: 如何为推荐基础模型索引项目ID

    How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])

    [http://arxiv.org/abs/2305.06569](http://arxiv.org/abs/2305.06569)

    本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。

    

    推荐基础模型将推荐任务转换为自然语言任务，利用大型语言模型（LLM）进行推荐。它通过直接生成建议的项目而不是计算传统推荐模型中每个候选项目的排名得分，简化了推荐管道，避免了多段过滤的问题。为了避免在决定要推荐哪些项目时生成过长的文本，为推荐基础模型创建LLM兼容的项目ID是必要的。本研究系统地研究了推荐基础模型的项目索引问题，以P5为代表的主干模型，并使用各种索引方法复制其结果。我们首先讨论了几种微不足道的项目索引方法（如独立索引、标题索引和随机索引）的问题，并表明它们不适用于推荐基础模型，然后提出了一种新的索引方法，称为上下文感知索引。我们表明，这种索引方法在项目推荐准确性和文本生成质量方面优于其他索引方法。

    Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
    
[^61]: 用无监督语音重构解开韵律表示的纠缠

    Disentangling Prosody Representations with Unsupervised Speech Reconstruction. (arXiv:2212.06972v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2212.06972](http://arxiv.org/abs/2212.06972)

    本文提出了一种利用无监督语音重构来解决从语音中分离情绪韵律的任务的方法。通过设计和集成多个关键组件，我们能够在没有标签的情况下有效地提取出韵律信息。这对于自动语音识别和说话人验证等应用具有重要意义。

    

    人类语音可以通过不同的组成部分进行表征，包括语义内容、说话者身份和韵律信息。在自动语音识别（ASR）和说话人验证任务中，已经取得了在语义内容和说话者身份的表示分离方面的重要进展。然而，从语音中提取韵律信息仍然是一个具有挑战性的开放性研究问题，主要是因为不同属性（如音色和节奏）之间的内在联系以及需要有监督训练方案来实现强大的大规模、与说话者无关的ASR。本文旨在通过无监督重构来解决从语音中分离情绪韵律的任务。具体而言，我们在提出的语音重构模型Prosody2Vec中鉴别、设计、实现和集成了三个关键组件：(1) 一个单元编码器，将语音信号转化为离散单元以表示语义内容，(2) 一个预训练的说话者编码器，用于分离出说话者身份的表示，以及 (3) 一个情绪编码器，用于分离出情绪韵律的表示。

    Human speech can be characterized by different components, including semantic content, speaker identity and prosodic information. Significant progress has been made in disentangling representations for semantic content and speaker identity in Automatic Speech Recognition (ASR) and speaker verification tasks respectively. However, it is still an open challenging research question to extract prosodic information because of the intrinsic association of different attributes, such as timbre and rhythm, and because of the need for supervised training schemes to achieve robust large-scale and speaker-independent ASR. The aim of this paper is to address the disentanglement of emotional prosody from speech based on unsupervised reconstruction. Specifically, we identify, design, implement and integrate three crucial components in our proposed speech reconstruction model Prosody2Vec: (1) a unit encoder that transforms speech signals into discrete units for semantic content, (2) a pretrained speak
    
[^62]: 排列不变矩阵统计和计算语言任务

    Permutation invariant matrix statistics and computational language tasks. (arXiv:2202.06829v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.06829](http://arxiv.org/abs/2202.06829)

    本文提出了一种排列不变矩阵统计的方法，用于处理生成的矩阵统计，并描述了该方法在计算语言学中处理同义词、反义词、上义词和下义词等任务中的成功应用。

    

    由Kartsaklis, Ramgoolam和Sadrzadeh引入的语言矩阵理论方案是一种处理类型驱动分布语义中生成的矩阵统计的方法，它基于被视为编码显著统计信息的关键可观测量的排列不变多项式函数。在本文中，我们对源自组合分布语义的矩阵分布的近似高斯性进行了推广。我们还通过利用排列不变量的图论基础和与单词相关的矩阵系列的统计特性，引入了一种可观察向量的几何概念来定义单词的。我们描述了将此统一框架成功应用于计算语言学中一些任务的情况，这些任务涉及同义词、反义词、上义词和下义词之间的区别。

    The Linguistic Matrix Theory programme introduced by Kartsaklis, Ramgoolam and Sadrzadeh is an approach to the statistics of matrices that are generated in type-driven distributional semantics, based on permutation invariant polynomial functions which are regarded as the key observables encoding the significant statistics. In this paper we generalize the previous results on the approximate Gaussianity of matrix distributions arising from compositional distributional semantics. We also introduce a geometry of observable vectors for words, defined by exploiting the graph-theoretic basis for the permutation invariants and the statistical characteristics of the ensemble of matrices associated with the words. We describe successful applications of this unified framework to a number of tasks in computational linguistics, associated with the distinctions between synonyms, antonyms, hypernyms and hyponyms.
    

