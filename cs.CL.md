# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Simple and Scalable Strategies to Continually Pre-train Large Language Models](https://arxiv.org/abs/2403.08763) | 通过简单和可扩展的学习率调整、重放数据的方法，可以在不重新训练的情况下，持续预训练大型语言模型以匹配完全重新训练时的性能。 |
| [^2] | [DAM: Dynamic Adapter Merging for Continual Video QA Learning](https://arxiv.org/abs/2403.08755) | 提出了一种用于持续视频问答学习的动态适配器合并方法DAM，能够减轻灾难性遗忘、有效适应不断到来的数据集、处理未知数据集输入，并允许在类似数据集领域之间共享知识。 |
| [^3] | [Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework](https://arxiv.org/abs/2403.08743) | 本文提出了一种基于因果关系的去偏倾框架，通过选择机制指导设计提示来减少大型语言模型(LLMs)产生的社会偏见。 |
| [^4] | [The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models](https://arxiv.org/abs/2403.08739) | 观察大型语言模型中动态参数分布的时间演变，特别是叉分效应，能帮助理解模型质量，减少训练成本和评估工作，同时实证显示稀疏权重有效性背后的原因。 |
| [^5] | [Improving Acoustic Word Embeddings through Correspondence Training of Self-supervised Speech Representations](https://arxiv.org/abs/2403.08738) | 通过对应自动编码器与基于自监督学习的语音表示相结合，探索了一种改进声学词嵌入的方法，并在跨语言环境中取得了优异的结果。 |
| [^6] | [ILCiteR: Evidence-grounded Interpretable Local Citation Recommendation](https://arxiv.org/abs/2403.08737) | 介绍了一个名为ILCiteR的系统，通过基于证据的局部引文推荐任务，从现有研究文献中提取相似证据范围来推荐引用的论文，提高了推荐的可解释性。 |
| [^7] | [Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization](https://arxiv.org/abs/2403.08730) | 提出了引导优先优化（BPO）策略，通过使用包含负面响应的数据集来减轻多模态大语言模型（MLLMs）对预训练语料库偏见的影响，并使用两种策略来促进模型在视觉输入中的表现。 |
| [^8] | [SOTOPIA-$\pi$: Interactive Learning of Socially Intelligent Language Agents](https://arxiv.org/abs/2403.08715) | 提出了一种交互式学习方法SOTOPIA-$\pi$，该方法利用行为克隆和自我强化训练，改进了语言代理的社交智能，使其达到了专家模型的水平，并提高了安全性。 |
| [^9] | [TeaMs-RL: Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning](https://arxiv.org/abs/2403.08694) | TeaMs-RL通过强化学习直接生成基础指导数据集，减少对人类的依赖，提供高质量数据，为单一微调步骤铺平了道路。 |
| [^10] | [Do Language Models Care About Text Quality? Evaluating Web-Crawled Corpora Across 11 Languages](https://arxiv.org/abs/2403.08693) | 本文评估了跨11种语言的大型网页抓取语料库的质量差异，并发现MaCoCu和OSCAR的表现最好。 |
| [^11] | [Token Alignment via Character Matching for Subword Completion](https://arxiv.org/abs/2403.08688) | 通过字符匹配实现标记对齐的方法，显著改进了生成模型在处理部分标记对齐的情景中的性能，包括空格前缀和部分缩进等微妙情况。 |
| [^12] | [Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records](https://arxiv.org/abs/2403.08664) | 这项研究探讨了利用合成数据生成医疗记录的方法，特别是通过零样本和少样本提示策略，避免了在训练过程中使用真实患者数据的隐私问题。 |
| [^13] | [MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models](https://arxiv.org/abs/2403.08607) | MedInsight是一种检索增强框架，通过从多个来源提取与患者医疗记录相关的背景信息，将其与大型语言模型输入结合，生成丰富的、针对患者的响应 |
| [^14] | [DevBench: A Comprehensive Benchmark for Software Development](https://arxiv.org/abs/2403.08604) | DevBench是一个综合基准测试，评估大型语言模型在软件开发生命周期各个阶段的表现，并发现现有的模型在其中存在挑战。 |
| [^15] | [Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments](https://arxiv.org/abs/2403.08593) | LLMs借助Reasoning-Path-Editing (Readi)框架，可以在结构化环境中高效且忠实地推理，显著提升了多个KGQA和TableQA数据集上的表现。 |
| [^16] | [Non-discrimination Criteria for Generative Language Models](https://arxiv.org/abs/2403.08564) | 本文研究如何在生成式语言模型中识别和量化性别偏见，提出了三个生成式人工智能的非歧视标准并设计了相应的提示。 |
| [^17] | [Language models scale reliably with over-training and on downstream tasks](https://arxiv.org/abs/2403.08540) | 本研究解决了语言模型缩放研究中过度训练和下游任务性能评估之间的差距。 |
| [^18] | [Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator](https://arxiv.org/abs/2403.08495) | 介绍了自动互动评估（AIE）框架和状态感知病人模拟器（SAPS），以动态、真实的平台评估LLMs，弥补传统评估方法无法满足临床任务需求的不足。 |
| [^19] | [Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking](https://arxiv.org/abs/2403.08492) | 本文使用富含语义知识的大型语言模型在少样本中文拼写检查任务上取得了比BERT模型更好的性能。 |
| [^20] | [Data-oriented Dynamic Fine-tuning Parameter Selection Strategy for FISH Mask based Efficient Fine-tuning](https://arxiv.org/abs/2403.08484) | 提出了一种数据驱动的动态微调参数选择策略，针对FISH Mask提出了IRD算法，用于在不稳定的数据分布下动态选择最佳参数设置。 |
| [^21] | [Authorship Verification based on the Likelihood Ratio of Grammar Models](https://arxiv.org/abs/2403.08462) | 提出了一种基于计算作者文件在候选作者语法模型与参考群体语法模型下的可能性比率的方法，用以解决作者身份验证中存在的科学解释不足和难以解释的问题 |
| [^22] | [Tastle: Distract Large Language Models for Automatic Jailbreak Attack](https://arxiv.org/abs/2403.08424) | Tastle是一种新颖的黑盒越狱框架，采用恶意内容隐藏和内存重构以及迭代优化算法，用于自动对大型语言模型进行红队攻击。 |
| [^23] | [Misinformation is not about Bad Facts: An Analysis of the Production and Consumption of Fringe Content](https://arxiv.org/abs/2403.08391) | 虚假信息不仅仅涉及错误的事实，研究发现在线边缘意识形态通过共识和“事实正确”的内容传播，同时发现了极右用户倾向挑选关注特定主题的新闻，并且可以根据用户的沟通风格识别易于分享错误信息的用户。 |
| [^24] | [Learning to Describe for Predicting Zero-shot Drug-Drug Interactions](https://arxiv.org/abs/2403.08377) | 提出了一种新的零样本药物相互作用（DDI）预测问题设置，通过利用在线数据库的文本信息和基于语言模型和强化学习的方法，实现对新药物准确DDI预测。 |
| [^25] | [Translating between SQL Dialects for Cloud Migration](https://arxiv.org/abs/2403.08375) | 本文讨论了云迁移中SQL数据库方言的转换困难，尽管有一些工具可以帮助转换方言，但并不能完全解决问题，需要人工干预。 |
| [^26] | [SMART: Submodular Data Mixture Strategy for Instruction Tuning](https://arxiv.org/abs/2403.08370) | SMART引入了一种新颖的数据混合策略，利用子模块函数为任务分配重要性分数，并在微调中重新分配预算，从而在指令调整任务中取得明显优势。 |
| [^27] | [Log Summarisation for Defect Evolution Analysis](https://arxiv.org/abs/2403.08358) | 提出了一种在线基于语义的聚类方法，用于动态更新日志聚类，以实现监控代码错误的生命周期，并引入了一种新颖的度量标准来评估时间日志聚类的性能，最终发现我们的解决方案优于类似系统。 |
| [^28] | [From human experts to machines: An LLM supported approach to ontology and knowledge graph construction](https://arxiv.org/abs/2403.08345) | 本文探讨了利用开源LLMs（半）自动构建知识图的方法，通过制定能力问题（CQs）、基于这些CQs开发本体论（TBox）、构建知识图并实现几乎不涉及人类专家的评估，展示了半自动化流程的可行性。 |
| [^29] | [Autoregressive Score Generation for Multi-trait Essay Scoring](https://arxiv.org/abs/2403.08332) | 提出一种自回归预测多特征分数的方法（ArTS），通过利用预先训练的T5来结合解码过程，实现了自动作文评分中多分数预测的效果。 |
| [^30] | [Knowledge Conflicts for LLMs: A Survey](https://arxiv.org/abs/2403.08319) | 这项调查深入分析了LLMs在融合上下文和参数化知识时所面临的知识冲突，探讨了三类知识冲突对其可信度和性能的重要影响，并提出改进LLMs稳健性策略的策略。 |
| [^31] | [Is Context Helpful for Chat Translation Evaluation?](https://arxiv.org/abs/2403.08314) | 自动度量标准在评估机器翻译聊天质量方面的应用受到限制，无参考度量标准在评估翻译质量时落后于有参考度量标准，尤其在非英语环境下评估时。研究发现将会话上下文信息结合到度量标准中可以改善其性能。 |
| [^32] | [StreamingDialogue: Prolonged Dialogue Learning via Long Context Compression with Minimal Losses](https://arxiv.org/abs/2403.08312) | 提出了StreamingDialogue，通过将长对话历史压缩为"会话注意力汇集点"，最小化损失，使计算复杂度减少，并有潜力处理超过200k条话语，实现长时间对话学习 |
| [^33] | [Towards Personalized Evaluation of Large Language Models with An Anonymous Crowd-Sourcing Platform](https://arxiv.org/abs/2403.08305) | 提出了一个新颖的匿名众包评估平台，BingJian，用于大型语言模型，采用了竞争性评分机制，解决了现有方法主要评估客观问题、忽视主观问题、使用中心化数据集、忽视个性化因素的局限性。 |
| [^34] | [Gemma: Open Models Based on Gemini Research and Technology](https://arxiv.org/abs/2403.08295) | Gemma是基于Gemini研究和技术所构建的开放模型系列，在语言理解、推理和安全性等方面表现出色，负责任地发布这些大型语言模型对于提高前沿模型的安全性至关重要。 |
| [^35] | [Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale](https://arxiv.org/abs/2403.08293) | GPST是一种无监督的句法语言模型，通过联合训练两个模型实现对原始文本的高并行预训练，克服了之前SLM依赖于黄金树和顺序训练的限制，展示了在多个任务中优于同等规模的GPT-2。 |
| [^36] | [Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models](https://arxiv.org/abs/2403.08281) | 通过融合高度专业化的语言、代码和数学模型，提出了一种名为UltraFuser的融合框架，引入了标记级别的门控机制，并设计了两阶段训练策略，以同时在三个领域取得高性能。 |
| [^37] | [RECIPE4U: Student-ChatGPT Interaction Dataset in EFL Writing Education](https://arxiv.org/abs/2403.08272) | 该论文提出了RECIPE4U数据集，从212名大学生的EFL写作课程中收集，用于研究学生与ChatGPT之间的互动，建立了任务导向对话系统中意图检测和满意度估计的基准结果。 |
| [^38] | [Skipformer: A Skip-and-Recover Strategy for Efficient Speech Recognition](https://arxiv.org/abs/2403.08258) | Skipformer提出了一种“跳过和恢复”的Conformer架构，可以动态、不均匀地压缩序列输入长度，大大减少了计算预算和内存消耗，并获得更好的识别准确性。 |
| [^39] | [Boosting Disfluency Detection with Large Language Model as Disfluency Generator](https://arxiv.org/abs/2403.08229) | 本研究提出了一种利用大型语言模型生成不流畅句子作为数据增强的轻量级方法，通过数据过滤和小型模型训练实现了不流畅检测性能的提升。 |
| [^40] | [Research on the Application of Deep Learning-based BERT Model in Sentiment Analysis](https://arxiv.org/abs/2403.08217) | 本文研究了深度学习技术在情感分析中的应用，重点探讨了BERT模型的架构、特性以及优化策略，并通过实验证实了BERT模型在情感分析中表现出的稳健性能和提升潜力。 |
| [^41] | [Can Large Language Models Identify Authorship?](https://arxiv.org/abs/2403.08213) | 大型语言模型在作者识别方面的潜力尚未得到充分探索，本文通过全面评估解决了LLMs在作者验证和归属中的三个关键研究问题。 |
| [^42] | [Large Language Models are Contrastive Reasoners](https://arxiv.org/abs/2403.08211) | 对比提示方法显著提高大型语言模型进行复杂推理的能力，不仅在算术、常识和符号推理任务上表现优良，还可以与现有提示方法整合，实现更好的性能。 |
| [^43] | [Validating and Exploring Large Geographic Corpora](https://arxiv.org/abs/2403.08198) | 本文研究了在大规模地理多语言网络语料库中的语料库创建决策对质量的影响，通过改进数据清洗方法来提高特定语言-国家子语料库的有效性，并重点关注未充分代表的语言和人口群体。 |
| [^44] | [SpeechColab Leaderboard: An Open-Source Platform for Automatic Speech Recognition Evaluation](https://arxiv.org/abs/2403.08196) | 介绍了SpeechColab Leaderboard，一个用于ASR评估的开源平台，提供全面的基准测试，揭示了ASR系统的最新技术现状，并量化了得分管道中不同细微之处对最终基准测试结果的影响。 |
| [^45] | [MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension](https://arxiv.org/abs/2403.08192) | MoleculeQA是一个用于评估分子理解中事实准确性的数据集，具有62K个QA对，是第一个分子事实偏见评估的基准，也是最大的分子研究QA数据集。 |
| [^46] | [Embedded Translations for Low-resource Automated Glossing](https://arxiv.org/abs/2403.08189) | 研究在低资源环境下自动词间标注，通过嵌入式翻译信息提升神经模型性能达到提升，尤其在处理和解释适度数据源时。 |
| [^47] | [Automatic Speech Recognition (ASR) for the Diagnosis of pronunciation of Speech Sound Disorders in Korean children](https://arxiv.org/abs/2403.08187) | 该研究提出了一个专门用于诊断韩国儿童言语声音障碍发音问题的自动语音识别模型，通过微调 wav2vec 2.0 XLS-R 模型，成功实现了对孩子们发音的高准确度识别。 |
| [^48] | [Rethinking Loss Functions for Fact Verification](https://arxiv.org/abs/2403.08174) | 提出了专为FEVER任务定制的两种任务特定目标函数，相比标准交叉熵在事实验证中表现更好，并通过简单类别加权进一步提高性能。 |
| [^49] | [MolBind: Multimodal Alignment of Language, Molecules, and Proteins](https://arxiv.org/abs/2403.08167) | MolBind 提出了一个框架，通过对比学习为多种模态训练编码器，将所有模态映射到共享特征空间，实现多模态语义对齐。 |
| [^50] | [BAGEL: Bootstrapping Agents by Guiding Exploration with Language](https://arxiv.org/abs/2403.08140) | BAGEL 提出了一种新方法，通过循环操作将随机探索到的轨迹或合成指令转换为演示，以使语言模型代理能够在新环境中自主学习适应。 |
| [^51] | [From Paper to Card: Transforming Design Implications with Generative AI](https://arxiv.org/abs/2403.08137) | 使用生成人工智能构建系统，从学术论文中创建设计卡片，帮助设计师更好理解设计启示并提高沟通效率。 |
| [^52] | [Legally Binding but Unfair? Towards Assessing Fairness of Privacy Policies](https://arxiv.org/abs/2403.08115) | 本研究旨在评估隐私政策的公平性，通过从法律来源和公平性研究中确定信息公正性、表现公正性和道德/伦理与隐私政策的关系，并提出自动评估政策的选项。 |
| [^53] | [AI-Assisted Causal Pathway Diagram for Human-Centered Design](https://arxiv.org/abs/2403.08111) | 本文研究了将因果路径图整合到人类中心设计中的方法，开发了专用插件用于在线协作白板平台，通过用户研究发现其支持设计过程中的分散和集中阶段，减少设计师的认知负荷并增加创造力。 |
| [^54] | [Contextual Clarity: Generating Sentences with Transformer Models using Context-Reverso Data](https://arxiv.org/abs/2403.08103) | 使用Transformer模型和Context-Reverso数据生成具有上下文清晰度的句子 |
| [^55] | [Mechanics of Next Token Prediction with Self-Attention](https://arxiv.org/abs/2403.08081) | 通过梯度下降训练自注意力学习到一个自动机，在下一个标记预测中生成标记的两个不同步骤是：硬检索和软组合。 |
| [^56] | [FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation](https://arxiv.org/abs/2403.08059) | FluoroSAM是用于X光图像的分割的语言对齐基础模型，提供了一种在X光成像领域具有广泛适用性的自动图像分析工具。 |
| [^57] | [CHAI: Clustered Head Attention for Efficient LLM Inference](https://arxiv.org/abs/2403.08058) | CHAI提出了Clustered Head Attention（CHAI）方法，通过在运行时结合具有高相关性的注意力头部，实现了减少内存需求和计算量，能够在不需要微调的情况下将存储K,V缓存的内存需求降低21.4％，推理时间延迟降低1.73倍。 |
| [^58] | [Generating Clarification Questions for Disambiguating Contracts](https://arxiv.org/abs/2403.08053) | 本研究提出了一个新颖的法律自然语言处理任务，旨在生成合同的澄清问题，以帮助识别合同中的歧义。 |
| [^59] | [Big City Bias: Evaluating the Impact of Metropolitan Size on Computational Job Market Abilities of Language Models](https://arxiv.org/abs/2403.08046) | 该研究评估了大型语言模型对美国384个都市地区的工作市场能力，发现都市规模越小，模型的表现越差。 |
| [^60] | [Authorship Style Transfer with Policy Optimization](https://arxiv.org/abs/2403.08043) | 提出了一种简单的两步调整和优化技术，用于低资源文本风格转移，在作者转移和母语风格任务方面均优于最先进的基准模型。 |
| [^61] | [Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection](https://arxiv.org/abs/2403.08035) | 该论文围绕大型语言模型（LLMs）在检测和分类令人憎恶或有毒内容方面的作用展开文献综述和实证分析，旨在揭示LLM在识别令人憎恶内容方面的能力及其影响因素。 |
| [^62] | [Gujarati-English Code-Switching Speech Recognition using ensemble prediction of spoken language](https://arxiv.org/abs/2403.08011) | 通过在输出中以每层有监督的方式对单词和字符的语言ID条件化变压器层，该方法虽然未能显著降低词错误率，但展现了在仅仅通过口语数据预测正确语言的潜力。 |
| [^63] | [Debatrix: Multi-dimensinal Debate Judge with Iterative Chronological Analysis Based on LLM](https://arxiv.org/abs/2403.08010) | 提出了Debatrix系统，利用LLMs进行多轮辩论的分析和评估，性能显著优于直接使用LLMs，实现了对整场辩论的评估。 |
| [^64] | [Pix2Pix-OnTheFly: Leveraging LLMs for Instruction-Guided Image Editing](https://arxiv.org/abs/2403.08004) | 本文提出了一种新方法，实现了基于自然语言指令的图像编辑，在不需要任何预备工作的情况下，通过图像字幕和DDIM反演，获取编辑方向嵌入，进行指导图像编辑，表现出有效性和竞争力。 |
| [^65] | [Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging](https://arxiv.org/abs/2403.08002) | 本文针对生物医学应用中前沿模型尚存在的多模态能力差距，探讨了训练开源小型多模态模型以弥补临床需求的生物医学能力差距。 |
| [^66] | [LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code](https://arxiv.org/abs/2403.07974) | LiveCodeBench提出了一个全面的、无污染的LLMs评估工具，聚焦于从LeetCode、AtCoder和CodeForces等平台连续收集的新问题，覆盖自修复、代码执行、测试输出预测等更广泛的代码相关能力。 |
| [^67] | [The evaluation of a code-switched Sepedi-English automatic speech recognition system](https://arxiv.org/abs/2403.07947) | 评估了一种混合使用Sepedi-英语的自动语音识别系统，探讨了端到端方法在低资源语言中的有效性。 |
| [^68] | [Speech Robust Bench: A Robustness Benchmark For Speech Recognition](https://arxiv.org/abs/2403.07937) | 提出了一个全面基准（SRB），用于评估自动语音识别（ASR）模型对各种破坏的鲁棒性，发现模型大小和某些建模选择有助于提高鲁棒性，并观察到在不同人口亚组上模型的鲁棒性存在明显差异。 |
| [^69] | [Merino: Entropy-driven Design for Generative Language Models on IoT Devices](https://arxiv.org/abs/2403.07921) | 在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型，通过最大化transformer解码器的熵来在计算预算内，成功设计了MeRino模型，在移动设置下展现出与当前最先进的自回归transformer模型竞争性能的特点 |
| [^70] | [ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training](https://arxiv.org/abs/2403.07920) | 提出了ProtLLM，一种具有独特动态蛋白质装配机制及蛋白质作为单词语言建模方法的交织式蛋白质-语言LLM，并构建了大规模的交织式蛋白质-文本数据集用于预训练。 |
| [^71] | [Multi-Task Media-Bias Analysis Generalization for Pre-Trained Identification of Expressions](https://arxiv.org/abs/2403.07910) | MAGPIE是第一个为媒体偏见检测定制的大规模多任务预训练方法，在媒体偏见检测方面表现优异，并且相对于单一任务方法需要更少的微调步骤。 |
| [^72] | [Beyond Memorization: The Challenge of Random Memory Access in Language Models](https://arxiv.org/abs/2403.07805) | 本文研究了语言模型在访问内存时的挑战，发现通过背诵和置换等技术可以改善语言模型的随机内存访问能力，从而在开放域问题回答任务中取得显著改进。 |
| [^73] | [StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models](https://arxiv.org/abs/2403.07714) | StableToolBench提出了一种虚拟API服务器和稳定评估系统，通过缓存系统、API模拟器和稳定评估设计，解决了大语言模型利用外部工具的稳定大规模基准测试问题。 |
| [^74] | [From English to ASIC: Hardware Implementation with Large Language Model](https://arxiv.org/abs/2403.07039) | 大型语言模型的快速发展改变了ASIC工程领域，但现代语言模型在生成硬件描述代码方面性能不佳，研究重点在于通过微调自然语言模型和重组HDL代码数据集来提高精度和准确性。 |
| [^75] | [Naming, Describing, and Quantifying Visual Objects in Humans and LLMs](https://arxiv.org/abs/2403.06935) | 评估了当前视觉与语言大语言模型在人类在可能标签的分布上显示出极大主观变异性的情况下，对视觉对象的命名、描述和量化的能力 |
| [^76] | [Multilingual Turn-taking Prediction Using Voice Activity Projection](https://arxiv.org/abs/2403.06487) | 本文研究了在口头对话中使用语音活动投影进行多语言交替预测，在多语言数据上训练的多语言模型展示出与单一语言模型相当的预测性能，并且学会了辨别输入信号的语言。 |
| [^77] | [A Comprehensive Overhaul of Multimodal Assistant with Small Language Models](https://arxiv.org/abs/2403.06199) | 通过设计多模态小语言模型(MSLMs)及提出高效多模态助手Mipha，实现了在多个方面的协同作用，击败了大语言模型，为开发强大MSLMs提供了见解和指南 |
| [^78] | [Electrocardiogram Instruction Tuning for Report Generation](https://arxiv.org/abs/2403.04945) | 提出了Multimodal ECG Instruction Tuning（MEIT）框架，首次尝试使用LLMs和多模态指导解决ECG报告生成问题，并在两个大规模ECG数据集上进行了广泛的实验评估其优越性。 |
| [^79] | [MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining](https://arxiv.org/abs/2403.04780) | MuseGraph将GNNs和LLMs的优势结合起来，提出了一种更有效和通用的图挖掘方法，可以跨不同任务和数据集使用 |
| [^80] | [Non-verbal information in spontaneous speech - towards a new framework of analysis](https://arxiv.org/abs/2403.03522) | 这项研究提出了一个分析框架和技术验证概念，用于对言语中的非言语信号进行分类，并将其与含义关联起来，从而为探索表达实现多层韵律事件的大型数据提供了一种方法。 |
| [^81] | [Benchmarking Large Language Models on Answering and Explaining Challenging Medical Questions](https://arxiv.org/abs/2402.18060) | 在回答医学问题方面，大型语言模型在处理具有挑战性的实际临床案例上的表现是关键，因此构建了两个结构化数据集进行评估。 |
| [^82] | [TOOLVERIFIER: Generalization to New Tools via Self-Verification](https://arxiv.org/abs/2402.14158) | 通过自验证方法，本研究提出了一种区分新工具的方法，通过对比性自问问题来实现工具选择和参数生成，进一步提升了语言模型对新工具的学习能力。 |
| [^83] | [A Unified Taxonomy-Guided Instruction Tuning Framework for Entity Set Expansion and Taxonomy Expansion](https://arxiv.org/abs/2402.13405) | 通过统一的基于分类学指导的指导调整框架，本文提出了一种利用现有分类学进行实体关系微调的方法，有效解决实体集扩展、分类学扩展和种子引导分类学构建三个任务。 |
| [^84] | [LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration](https://arxiv.org/abs/2402.11550) | LongAgent通过多智能体协作将语言模型扩展到128K上下文，并在长文本处理方面表现出潜在的优越性。 |
| [^85] | [Unveiling the Secrets of Engaging Conversations: Factors that Keep Users Hooked on Role-Playing Dialog Agents](https://arxiv.org/abs/2402.11522) | 机器人体现其扮演角色的程度对保留率的影响有限，而其讲话的每个轮次的长度显著影响保留率 |
| [^86] | [Network Formation and Dynamics Among Multi-LLMs](https://arxiv.org/abs/2402.10659) | 分析了多个LLM在社交网络中的行为，发现它们在给定网络结构并被询问形成网络偏好时表现出与人类社交动态一致的原则。 |
| [^87] | [SciGLM: Training Scientific Language Models with Self-Reflective Instruction Annotation and Tuning](https://arxiv.org/abs/2401.07950) | SciGLM引入了自我反思指导注释框架，用于弥补大型语言模型在理解复杂科学概念、推导符号方程式和解决高级数值计算方面的不足，以训练能够进行大学水平科学推理的科学语言模型。 |
| [^88] | [KnowGPT: Black-Box Knowledge Injection for Large Language Models](https://arxiv.org/abs/2312.06185) | KnowGPT是一种为大型语言模型提供黑盒知识注入的框架，通过深度强化学习和多臂老虎机构建最适合每个问题的提示，在三个基准数据集上实验证明其显著提升了知识注入的效果。 |
| [^89] | [Jellyfish: A Large Language Model for Data Preprocessing](https://arxiv.org/abs/2312.01678) | 这项研究探讨了在数据挖掘中利用大型语言模型进行数据预处理的方法，通过指导调整本地LLMs来解决通用数据预处理问题，确保数据安全并进行进一步调整 |
| [^90] | [MLLMs-Augmented Visual-Language Representation Learning](https://arxiv.org/abs/2311.18765) | MLLMs通过为图像-文本数据集建立更丰富的图像-文本关联，以增强视觉-语言表示学习，并通过“文本剪切”方法来避免偏见引入，显著提高了图像-文本检索的性能。 |
| [^91] | [WsiCaption: Multiple Instance Generation of Pathology Reports for Gigapixel Whole-Slide Images](https://arxiv.org/abs/2311.16480) | 研究提出了一种基于多实例生成模型的方法，能够生成千亿像素全切片图像的病理报告，实验结果表明该模型能够产生包含多个临床线索的病理报告。 |
| [^92] | [SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models](https://arxiv.org/abs/2311.09818) | SUQL是第一个支持大型知识语料库中的混合数据访问的对话代理，通过自由文本基元扩展了SQL，提出了一种新的语言SUQL，并开发了一个可以处理混合数据源的语义解析器。 |
| [^93] | [Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?](https://arxiv.org/abs/2311.09702) | 本研究探讨了大型语言模型存在的幻觉和不忠实推理问题，提出一种新的探测方法和基准测试以研究LLMs在推理过程中是否会采取欺骗性语义快捷方式。 |
| [^94] | [Speculative Contrastive Decoding](https://arxiv.org/abs/2311.08981) | SCD是一种结合了推测解码和对比解码的解码方法，利用较小语言模型的预测实现了解码加速和质量提升 |
| [^95] | [Agent Lumos: Unified and Modular Training for Open-Source Language Agents](https://arxiv.org/abs/2311.05657) | Agent Lumos提出了一种统一和模块化的框架，通过规划模块学习高级子目标生成，训练接地模块将其转化为动作，促进广泛互动任务应用。 |
| [^96] | [Octavius: Mitigating Task Interference in MLLMs via MoE](https://arxiv.org/abs/2311.02684) | 提出了一个名为Octavius的新框架，通过结合MoE和LoRA技术设计了一种新颖的LLM解码器LoRA-MoE，用于多模态学习，实验证明其在各种2D和3D下游任务中具有约20%的改进效果。 |
| [^97] | [LitCab: Lightweight Language Model Calibration over Short- and Long-form Responses](https://arxiv.org/abs/2310.19208) | LitCab 是一种轻量级校准机制，通过仅添加原始模型参数的 < 2%，以一个单一线性层的形式改善语言模型的校准。 |
| [^98] | [Scaling Laws of RoPE-based Extrapolation](https://arxiv.org/abs/2310.05209) | 本研究提出了RoPE基外推的尺度律，通过调整 RoPE 中的基数和微调文本长度来显著提高大型语言模型的外推性能。 |
| [^99] | [Demystifying Embedding Spaces using Large Language Models](https://arxiv.org/abs/2310.04475) | 通过使用大型语言模型（LLMs）直接与嵌入交互，将抽象向量转换为可理解的叙述，使得复杂嵌入数据更具解释性和广泛实用性。 |
| [^100] | [Quantifying the Plausibility of Context Reliance in Neural Machine Translation](https://arxiv.org/abs/2310.01188) | 引入了PECoRe框架，用于量化语言模型生成中的上下文使用情况，从而评估上下文感知机器翻译模型的可信度。 |
| [^101] | [CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets](https://arxiv.org/abs/2309.17428) | CRAFT提出了一个通用工具创建和检索框架，能够定制LLMs，为其创建特定任务的工具集，并使用这些工具集增强其解决复杂任务的能力。 |
| [^102] | [Empowering Private Tutoring by Chaining Large Language Models](https://arxiv.org/abs/2309.08112) | 通过链式连接大型语言模型，开发了一种全面智能辅导系统，实现了自动课程规划、个性化指导和灵活测验评估。 |
| [^103] | [BED: Bi-Encoder-Based Detectors for Out-of-Distribution Detection](https://arxiv.org/abs/2306.08852) | 本文提出了一种基于双编码器的检测器方法，通过对不同的特征提取器进行比较研究，在NLP领域中展现出了在异常检测方面的潜力。 |
| [^104] | [Schema-Driven Information Extraction from Heterogeneous Tables](https://arxiv.org/abs/2305.14336) | 本文探讨了大型语言模型在通过引入基于模式的信息提取任务进行多领域表格数据处理时的竞争性表现，而无需特定流水线或标签，同时保持成本效率。 |
| [^105] | [A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models](https://arxiv.org/abs/2212.12799) | 本文研究了化学命名实体识别模型中的性别偏见，使用合成数据和Reddit上的性别信息注释语料库评估多个生物医学NER模型，揭示了明显的偏见。 |
| [^106] | [ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence Labeling Tasks.](http://arxiv.org/abs/2401.16589) | 这项研究提出了一种名为ToPro的方法，用于跨语言序列标注任务。该方法通过将输入句子分解为单个词汇并应用提示模板，在零样本跨语言转移中实现了优于其他微调方法的性能，并在结构不同的语言上取得了最先进的结果。 |
| [^107] | [GPT-4V(ision) is a Generalist Web Agent, if Grounded.](http://arxiv.org/abs/2401.01614) | GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。 |
| [^108] | [Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer Inputs of Language Models in Federated Learning.](http://arxiv.org/abs/2312.05720) | 本文引入了一种创新的方法，在联邦学习中利用语言模型的池化层输入来实现对隐私攻击的改进。通过恢复池化层输入，这种方法能够在不同的批处理大小下提供更高的文本恢复率，从而提供更细致和有效的见解。 |
| [^109] | [GenTKG: Generative Forecasting on Temporal Knowledge Graph.](http://arxiv.org/abs/2310.07793) | 研究提出了一种名为GenTKG的生成模型，用于在时间知识图谱上进行预测。该模型通过结合基于时间逻辑规则的检索策略和轻量级的参数效率指导，克服了复杂的时间图数据结构和庞大的数据量所带来的挑战。 |
| [^110] | [PROGrasp: Pragmatic Human-Robot Communication for Object Grasping.](http://arxiv.org/abs/2309.07759) | PROGrasp是一个实现物体抓取的人机交流系统，通过使用面向意图的多模态对话和答案解释模块，机器人能够根据用户的意图来识别和抓取目标物体。 |
| [^111] | [Improving Detection of ChatGPT-Generated Fake Science Using Real Publication Text: Introducing xFakeBibs a Supervised-Learning Network Algorithm.](http://arxiv.org/abs/2308.11767) | 本文介绍了一种能够提高对ChatGPT生成的假科学进行检测的算法。通过使用一种新设计的监督机器学习算法，该算法能够准确地将机器生成的出版物与科学家生成的出版物区分开来。结果表明，ChatGPT在技术术语方面与真实科学存在显著差异。算法在分类过程中取得了较高的准确率。 |
| [^112] | [In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning.](http://arxiv.org/abs/2307.12375) | 大型语言模型（LLMs）在包含标签关系示例的上下文中的学习能力使其在下游任务中表现显著提高，但与传统学习方法不同。我们研究了上下文示例中的标签如何影响预测、预训练中学习到的标签关系如何与上下文示例相互作用以及上下文学习如何聚合标签信息。研究结果揭示了LLMs的工作机制及其对上下文信息的处理方式。 |
| [^113] | [UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data.](http://arxiv.org/abs/2307.09249) | UniTabE是一种面向异构表格数据的统一预训练表格编码器，能够处理不同表格结构的挑战，并具有对多样化下游应用的适应性。 |
| [^114] | [Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism of Language Models.](http://arxiv.org/abs/2305.09144) | 本论文研究了语言模型的记忆机制，发现预训练可以有效提高模型的记忆能力，而知识相关性和多样性对于记忆形成也有显著影响。 |
| [^115] | [Two-stage LLM Fine-tuning with Less Specialization and More Generalization.](http://arxiv.org/abs/2211.00635) | 预训练的大型语言模型（LLMs）通过精调可以提高特定任务的性能，但精调通常会使模型过度专门化，降低了其在上下文中的泛化学习性能。通过两阶段精调框架ProMoT可以减少这种格式特化。 |
| [^116] | [Application of Quantum Density Matrix in Classical Question Answering and Classical Image Classification.](http://arxiv.org/abs/2203.11155) | 该论文将量子密度矩阵应用于经典问答和图像分类中，证明了其可以提高任务的效率，尤其在图像分类中取得了优秀的性能表现。 |

# 详细

[^1]: 持续预训练大型语言模型的简单可扩展策略

    Simple and Scalable Strategies to Continually Pre-train Large Language Models

    [https://arxiv.org/abs/2403.08763](https://arxiv.org/abs/2403.08763)

    通过简单和可扩展的学习率调整、重放数据的方法，可以在不重新训练的情况下，持续预训练大型语言模型以匹配完全重新训练时的性能。

    

    大型语言模型（LLMs）通常在数十亿的标记上进行常规预训练，一旦有新数据可用就重新开始该过程。一个更有效率的解决方案是持续预训练这些模型，与重新训练相比能节省大量计算资源。然而，新数据引起的分布转移通常会导致在以前数据上降低性能或无法适应新数据。在本工作中，我们展示了一种简单且可扩展的学习率（LR）重新升温、LR重新衰减和重放上一数据的组合足以与完全从头开始重新训练在所有可用数据上的性能相匹配，从最终损失和语言模型（LM）评估基准的角度衡量。具体而言，我们展示了在两个常用的LLM预训练数据集（英语→英语）之间的弱但现实的分布转移以及更强烈的分布转移（英语→德语）下的情况。

    arXiv:2403.08763v1 Announce Type: cross  Abstract: Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by final loss and language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\rightarrow$English) and a stronger distribution shift (English$\rightarrow$German) at th
    
[^2]: DAM:用于持续视频问答学习的动态适配器合并

    DAM: Dynamic Adapter Merging for Continual Video QA Learning

    [https://arxiv.org/abs/2403.08755](https://arxiv.org/abs/2403.08755)

    提出了一种用于持续视频问答学习的动态适配器合并方法DAM，能够减轻灾难性遗忘、有效适应不断到来的数据集、处理未知数据集输入，并允许在类似数据集领域之间共享知识。

    

    我们提出了一种参数高效的方法，用于持续视频问答（VidQA）学习。我们的方法名为DAM，使用所提出的动态适配器合并来（i）减轻灾难性遗忘，（ii）实现对持续到达的数据集的高效适应，（iii）在推理过程中处理来自未知数据集的输入，（iv）实现跨相似数据集领域的知识共享。在给定一组持续流式传输的VidQA数据集的情况下，我们为每个数据集顺序训练特定于数据集的适配器，同时冻结大型预训练视频语言骨干的参数。在推理过程中，给定来自未知领域的视频问题示例，我们的方法首先使用所提出的非参数路由器函数计算每个适配器的概率，反映出该适配器与当前视频问题输入实例的相关性。随后，所提出的动态适配器合并方案聚合所有适配器权重。

    arXiv:2403.08755v1 Announce Type: cross  Abstract: We present a parameter-efficient method for continual video question-answering (VidQA) learning. Our method, named DAM, uses the proposed Dynamic Adapter Merging to (i) mitigate catastrophic forgetting, (ii) enable efficient adaptation to continually arriving datasets, (iii) handle inputs from unknown datasets during inference, and (iv) enable knowledge sharing across similar dataset domains. Given a set of continually streaming VidQA datasets, we sequentially train dataset-specific adapters for each dataset while freezing the parameters of a large pretrained video-language backbone. During inference, given a video-question sample from an unknown domain, our method first uses the proposed non-parametric router function to compute a probability for each adapter, reflecting how relevant that adapter is to the current video-question input instance. Subsequently, the proposed dynamic adapter merging scheme aggregates all the adapter weight
    
[^3]: 将LLMs引导到无偏响应：基于因果关系的去偏倾框架

    Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework

    [https://arxiv.org/abs/2403.08743](https://arxiv.org/abs/2403.08743)

    本文提出了一种基于因果关系的去偏倾框架，通过选择机制指导设计提示来减少大型语言模型(LLMs)产生的社会偏见。

    

    大型语言模型（LLMs）很容易产生偏见和歧视性的响应。由于LLMs涉及到重要的决策制定（例如招聘和医疗保健），开发减轻这些偏见的策略至关重要。本文侧重于社会偏见，解决了人口统计信息与LLM输出之间的关联。我们提出了一种基于因果关系的去偏倾框架，利用对LLMs输入的训练语料库的数据生成过程以及LLM推理的内部推理过程的因果理解，通过选择机制指导去偏倾LLM输出的提示设计。我们的框架统一了现有的去偏指示方法，如抑制指令和上下文对比例子，并通过鼓励无偏推理的方法，启示了新的去偏倾方式。我们在真实数据集上的强大实证表现表明，我们的框架可以

    arXiv:2403.08743v1 Announce Type: cross  Abstract: Large language models (LLMs) can easily generate biased and discriminative responses. As LLMs tap into consequential decision-making (e.g., hiring and healthcare), it is of crucial importance to develop strategies to mitigate these biases. This paper focuses on social bias, tackling the association between demographic information and LLM outputs. We propose a causality-guided debiasing framework that utilizes causal understandings of (1) the data-generating process of the training corpus fed to LLMs, and (2) the internal reasoning process of LLM inference, to guide the design of prompts for debiasing LLM outputs through selection mechanisms. Our framework unifies existing de-biasing prompting approaches such as inhibitive instructions and in-context contrastive examples, and sheds light on new ways of debiasing by encouraging bias-free reasoning. Our strong empirical performance on real-world datasets demonstrates that our framework pr
    
[^4]: 分叉路径的花园：观察大型语言模型中动态参数分布

    The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models

    [https://arxiv.org/abs/2403.08739](https://arxiv.org/abs/2403.08739)

    观察大型语言模型中动态参数分布的时间演变，特别是叉分效应，能帮助理解模型质量，减少训练成本和评估工作，同时实证显示稀疏权重有效性背后的原因。

    

    在理解Transformer架构在自然语言处理中卓越性能背后原因方面仍存在巨大差距。尤其是一个尚未被探索的领域涉及在训练过程中参数分布如何随时间演变的机械描述。在这项工作中，我们建议观察模型参数的统计分布随时间演变的方式，尤其是对叉分影响，可以帮助理解模型质量，潜在地减少训练成本和评估工作，并从实证上展示了稀疏权重有效性背后的原因。

    arXiv:2403.08739v1 Announce Type: cross  Abstract: A substantial gap persists in understanding the reasons behind the exceptional performance of the Transformer architecture in NLP. A particularly unexplored area involves the mechanistic description of how the distribution of parameters evolves over time during training. In this work we suggest that looking at the time evolution of the statistic distribution of model parameters, and specifically at bifurcation effects, can help understanding the model quality, potentially reducing training costs and evaluation efforts and empirically showing the reasons behind the effectiveness of weights sparsification.
    
[^5]: 通过对自监督语音表示进行对应训练来改进声学词嵌入

    Improving Acoustic Word Embeddings through Correspondence Training of Self-supervised Speech Representations

    [https://arxiv.org/abs/2403.08738](https://arxiv.org/abs/2403.08738)

    通过对应自动编码器与基于自监督学习的语音表示相结合，探索了一种改进声学词嵌入的方法，并在跨语言环境中取得了优异的结果。

    

    声学词嵌入（AWEs）是口语词汇的向量表示。获得AWEs的一种有效方法是通过对应自动编码器（CAE）。过去，CAE方法一直与传统MFCC特征相关联。从自监督学习（SSL）为基础的语音模型（如HuBERT、Wav2vec2等）中获得的表示在许多下游任务中优于MFCC。但是，在学习AWEs的情况下，它们并未得到充分研究。本文探讨了利用CAE与基于SSL的语音表示来获得改进的AWEs的有效性。此外，还探讨了在跨语言环境中利用基于SSL的语音模型获取AWEs的能力。在波兰语、葡萄牙语、西班牙语、法语和英语中进行了实验。基于HuBERT的CAE模型在所有语言中都实现了最佳的词辨别结果，尽管HuBERT仅在英语上进行了预训练。此外，HuBERT 在跨语言环境中展示了优异的性能。

    arXiv:2403.08738v1 Announce Type: new  Abstract: Acoustic word embeddings (AWEs) are vector representations of spoken words. An effective method for obtaining AWEs is the Correspondence Auto-Encoder (CAE). In the past, the CAE method has been associated with traditional MFCC features. Representations obtained from self-supervised learning (SSL)-based speech models such as HuBERT, Wav2vec2, etc., are outperforming MFCC in many downstream tasks. However, they have not been well studied in the context of learning AWEs. This work explores the effectiveness of CAE with SSL-based speech representations to obtain improved AWEs. Additionally, the capabilities of SSL-based speech models are explored in cross-lingual scenarios for obtaining AWEs. Experiments are conducted on five languages: Polish, Portuguese, Spanish, French, and English. HuBERT-based CAE model achieves the best results for word discrimination in all languages, despite Hu-BERT being pre-trained on English only. Also, the HuBERT
    
[^6]: ILCiteR：基于证据的可解释局部引文推荐

    ILCiteR: Evidence-grounded Interpretable Local Citation Recommendation

    [https://arxiv.org/abs/2403.08737](https://arxiv.org/abs/2403.08737)

    介绍了一个名为ILCiteR的系统，通过基于证据的局部引文推荐任务，从现有研究文献中提取相似证据范围来推荐引用的论文，提高了推荐的可解释性。

    

    现有的用于局部引文推荐的机器学习方法直接将查询（通常是声明或实体提及）映射或翻译为值得引用的研究论文。在这种表述中，很难确定为什么应该为特定查询引用特定研究论文，从而导致推荐的可解释性受限。为了缓解这一问题，我们引入了基于证据的局部引文推荐任务，其中目标潜在空间包括用于推荐特定论文的证据范围。通过使用远程监督证据检索和多步重新排序框架，我们提出的系统ILCiteR基于从现有研究文献中提取的相似证据范围向查询推荐应引用的论文。与过去简单输出推荐的形式不同，ILCiteR检索出经过排名的证据范围和推荐的论文对列表。

    arXiv:2403.08737v1 Announce Type: cross  Abstract: Existing Machine Learning approaches for local citation recommendation directly map or translate a query, which is typically a claim or an entity mention, to citation-worthy research papers. Within such a formulation, it is challenging to pinpoint why one should cite a specific research paper for a particular query, leading to limited recommendation interpretability. To alleviate this, we introduce the evidence-grounded local citation recommendation task, where the target latent space comprises evidence spans for recommending specific papers. Using a distantly-supervised evidence retrieval and multi-step re-ranking framework, our proposed system, ILCiteR, recommends papers to cite for a query grounded on similar evidence spans extracted from the existing research literature. Unlike past formulations that simply output recommendations, ILCiteR retrieves ranked lists of evidence span and recommended paper pairs. Secondly, previously prop
    
[^7]: 通过引入引导优先优化加强多模态大语言模型

    Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization

    [https://arxiv.org/abs/2403.08730](https://arxiv.org/abs/2403.08730)

    提出了引导优先优化（BPO）策略，通过使用包含负面响应的数据集来减轻多模态大语言模型（MLLMs）对预训练语料库偏见的影响，并使用两种策略来促进模型在视觉输入中的表现。

    

    多模态大语言模型（MLLMs）在基于视觉输入生成响应方面表现出色。然而，它们往往存在偏向于生成与其预训练语料库相似响应的偏见，掩盖了视觉信息的重要性。我们将这种偏见视为对预训练统计数据的“偏好”，这阻碍了模型对视觉输入的基础。为了缓解这一问题，我们提出了引导优先优化（BPO），该方法使用包含负面响应的数据集进行偏好学习，这些数据集是从模型本身中引导出来的。具体而言，我们提出了以下两种策略：1）使用扭曲的图像输入到MLLM中，以引发包含显著预训练偏见的响应；2）利用基于文本的LLM将错误但常见的元素明确地注入原始响应中。这些不良响应与数据集中原始的注释响应配对，构建了偏好。

    arXiv:2403.08730v1 Announce Type: new  Abstract: Multimodal Large Language Models (MLLMs) excel in generating responses based on visual inputs. However, they often suffer from a bias towards generating responses similar to their pretraining corpus, overshadowing the importance of visual information. We treat this bias as a "preference" for pretraining statistics, which hinders the model's grounding in visual input. To mitigate this issue, we propose Bootstrapped Preference Optimization (BPO), which conducts preference learning with datasets containing negative responses bootstrapped from the model itself. Specifically, we propose the following two strategies: 1) using distorted image inputs to the MLLM for eliciting responses that contain signified pretraining bias; 2) leveraging text-based LLM to explicitly inject erroneous but common elements into the original response. Those undesirable responses are paired with original annotated responses from the datasets to construct the prefere
    
[^8]: SOTOPIA-$\pi$: 交互式学习社交智能语言代理

    SOTOPIA-$\pi$: Interactive Learning of Socially Intelligent Language Agents

    [https://arxiv.org/abs/2403.08715](https://arxiv.org/abs/2403.08715)

    提出了一种交互式学习方法SOTOPIA-$\pi$，该方法利用行为克隆和自我强化训练，改进了语言代理的社交智能，使其达到了专家模型的水平，并提高了安全性。

    

    人类通过模仿和社交互动来学习社交技能。现有研究在构建语言代理方面很少涉及这种社交学习过程。受到这一空白的启发，我们提出了一种交互式学习方法SOTOPIA-$\pi$，改进了语言代理的社交智能。该方法利用行为克隆和自我强化训练，根据大型语言模型(LLM)评分对经过筛选的社交互动数据进行训练。我们证明了我们的训练方法使一个7B的LLM达到了专家模型(GPT-4-based agent)的社交目标完成能力，同时提高了语言代理的安全性，并在MMLU基准上保持了通用的问答能力。我们还发现，这种训练范式揭示了LLM评估社交智能的一些困难：基于LLM的评估者高估了专门针对社交互动训练的语言代理的能力。

    arXiv:2403.08715v1 Announce Type: new  Abstract: Humans learn social skills through both imitation and social interaction. This social learning process is largely understudied by existing research on building language agents. Motivated by this gap, we propose an interactive learning method, SOTOPIA-$\pi$, improving the social intelligence of language agents. This method leverages behavior cloning and self-reinforcement training on filtered social interaction data according to large language model (LLM) ratings. We show that our training method allows a 7B LLM to reach the social goal completion ability of an expert model (GPT-4-based agent), while improving the safety of language agents and maintaining general QA ability on the MMLU benchmark. We also find that this training paradigm uncovers some difficulties in LLM-based evaluation of social intelligence: LLM-based evaluators overestimate the abilities of the language agents trained specifically for social interaction.
    
[^9]: TeaMs-RL：通过强化学习教授LLMs更好地自我指导方法

    TeaMs-RL: Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning

    [https://arxiv.org/abs/2403.08694](https://arxiv.org/abs/2403.08694)

    TeaMs-RL通过强化学习直接生成基础指导数据集，减少对人类的依赖，提供高质量数据，为单一微调步骤铺平了道路。

    

    大型语言模型（LLMs）的发展通常面临着在强化学习与人类反馈（RLHF）框架中对人类标注员的严重依赖或与自我指导范式相关的频繁且昂贵的外部查询的挑战。在这项工作中，我们转向强化学习（RL）-- 但有所不同。我们偏离了典型的RLHF，后者在指导数据训练后优化LLMs，而我们使用RL直接生成单独足以进行微调的基础指导数据集。我们的方法TeaMs-RL使用一系列文本操作和规则，优先考虑训练数据集的多样化。它促进了高质量数据的生成，而不过于依赖外部先进模型，为单一微调步骤铺平了道路，消除了随后的RLHF阶段的必要性。我们的发现突出了我们方法的关键优势：减少对人类的依赖

    arXiv:2403.08694v1 Announce Type: new  Abstract: The development of Large Language Models (LLMs) often confronts challenges stemming from the heavy reliance on human annotators in the reinforcement learning with human feedback (RLHF) framework, or the frequent and costly external queries tied to the self-instruct paradigm. In this work, we pivot to Reinforcement Learning (RL) -- but with a twist. Diverging from the typical RLHF, which refines LLMs following instruction data training, we use RL to directly generate the foundational instruction dataset that alone suffices for fine-tuning. Our method, TeaMs-RL, uses a suite of textual operations and rules, prioritizing the diversification of training datasets. It facilitates the generation of high-quality data without excessive reliance on external advanced models, paving the way for a single fine-tuning step and negating the need for subsequent RLHF stages. Our findings highlight key advantages of our approach: reduced need for human inv
    
[^10]: 语言模型在意文本质量吗? 评估跨11种语言的网页抓取语料库

    Do Language Models Care About Text Quality? Evaluating Web-Crawled Corpora Across 11 Languages

    [https://arxiv.org/abs/2403.08693](https://arxiv.org/abs/2403.08693)

    本文评估了跨11种语言的大型网页抓取语料库的质量差异，并发现MaCoCu和OSCAR的表现最好。

    

    大型、策划、网页抓取的语料库在训练语言模型（LMs）中起着至关重要的作用。它们构成了几乎所有最近LMs训练数据的主要部分，如广为人知的GPT、LLaMA和XLM-RoBERTa模型。然而，尽管这一重要性，对这些语料库的质量关注相对较少。在本文中，我们比较了目前最相关的四个大型、网页抓取的语料库（CC100、MaCoCu、mC4和OSCAR）跨11种欧洲低资源语言。我们的方法是双重的：首先，我们通过对来自不同语料库的样本进行人工评估来进行内在评估；然后，我们评估了质量差异的实际影响，通过在每个语料库上训练特定的LMs，并评估它们在下游任务上的表现。我们发现语料库的质量存在明显差异，MaCoCu和OSCAR取得了最佳结果。

    arXiv:2403.08693v1 Announce Type: new  Abstract: Large, curated, web-crawled corpora play a vital role in training language models (LMs). They form the lion's share of the training data in virtually all recent LMs, such as the well-known GPT, LLaMA and XLM-RoBERTa models. However, despite this importance, relatively little attention has been given to the quality of these corpora. In this paper, we compare four of the currently most relevant large, web-crawled corpora (CC100, MaCoCu, mC4 and OSCAR) across eleven lower-resourced European languages. Our approach is two-fold: first, we perform an intrinsic evaluation by performing a human evaluation of the quality of samples taken from different corpora; then, we assess the practical impact of the qualitative differences by training specific LMs on each of the corpora and evaluating their performance on downstream tasks. We find that there are clear differences in quality of the corpora, with MaCoCu and OSCAR obtaining the best results. Ho
    
[^11]: 通过字符匹配实现标记对齐用于子词补全

    Token Alignment via Character Matching for Subword Completion

    [https://arxiv.org/abs/2403.08688](https://arxiv.org/abs/2403.08688)

    通过字符匹配实现标记对齐的方法，显著改进了生成模型在处理部分标记对齐的情景中的性能，包括空格前缀和部分缩进等微妙情况。

    

    生成模型在各种应用中被广泛使用，但通常难以处理与部分标记对齐的提示。这种困难源自标记化，在推理过程中部分标记会脱离分布，导致不正确或荒谬的输出。本文研究了一种技术，用于减轻生成模型中文本补全时的标记化问题，即使在常规非子词情况下也能保持性能。该方法称为标记对齐，涉及回溯到最后完整标记，并确保模型生成与提示对齐。这种方法在许多部分标记场景中展示了显著的改进，包括空格前缀和部分缩进等微妙情况，仅增加了少量时间。本文详细介绍的技术和分析有助于在处理部分输入方面不断推进生成模型，对诸如的应用具有相关意义

    arXiv:2403.08688v1 Announce Type: cross  Abstract: Generative models, widely utilized in various applications, can often struggle with prompts corresponding to partial tokens. This struggle stems from tokenization, where partial tokens fall out of distribution during inference, leading to incorrect or nonsensical outputs. This paper examines a technique to alleviate the tokenization artifact on text completion in generative models, maintaining performance even in regular non-subword cases. The method, termed token alignment, involves backtracking to the last complete tokens and ensuring the model's generation aligns with the prompt. This approach showcases marked improvement across many partial token scenarios, including nuanced cases like space-prefix and partial indentation, with only a minor time increase. The technique and analysis detailed in this paper contribute to the continuous advancement of generative models in handling partial inputs, bearing relevance for applications like
    
[^12]: 用于人工临床记录的零样本和少样本生成策略

    Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records

    [https://arxiv.org/abs/2403.08664](https://arxiv.org/abs/2403.08664)

    这项研究探讨了利用合成数据生成医疗记录的方法，特别是通过零样本和少样本提示策略，避免了在训练过程中使用真实患者数据的隐私问题。

    

    通过使用合成医疗记录的创新方法，本研究评估了Llama 2 LLM的能力，利用零样本和少样本提示策略生成可准确反映真实患者信息的合成医疗记录，与需要在训练过程中使用敏感患者数据的微调方法进行对比。

    arXiv:2403.08664v1 Announce Type: new  Abstract: The challenge of accessing historical patient data for clinical research, while adhering to privacy regulations, is a significant obstacle in medical science. An innovative approach to circumvent this issue involves utilising synthetic medical records that mirror real patient data without compromising individual privacy. The creation of these synthetic datasets, particularly without using actual patient data to train Large Language Models (LLMs), presents a novel solution as gaining access to sensitive patient information to train models is also a challenge. This study assesses the capability of the Llama 2 LLM to create synthetic medical records that accurately reflect real patient information, employing zero-shot and few-shot prompting strategies for comparison against fine-tuned methodologies that do require sensitive patient data during training. We focus on generating synthetic narratives for the History of Present Illness section, 
    
[^13]: MedInsight：用于使用大型语言模型生成以患者为中心的医疗响应的多源上下文增强框架

    MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models

    [https://arxiv.org/abs/2403.08607](https://arxiv.org/abs/2403.08607)

    MedInsight是一种检索增强框架，通过从多个来源提取与患者医疗记录相关的背景信息，将其与大型语言模型输入结合，生成丰富的、针对患者的响应

    

    大型语言模型（LLMs）在生成类人响应方面展现出令人印象深刻的能力。然而，它们缺乏领域特定知识，限制了它们在医疗环境中的适用性，而在医疗保健领域，具有上下文和全面性响应至关重要。为了解决这一挑战，实现生成具有上下文相关性和全面性的以患者为中心的响应，我们提出了MedInsight：一种新颖的检索增强框架，它使用多个来源的相关背景信息增强LLM输入（提示）。MedInsight从患者的病历或会诊记录中提取相关详细信息。然后，根据患者的健康历史和状况，集成来自权威医学教科书和策划的网络资源的信息。通过构建一个将患者记录与相关医学知识相结合的增强上下文，MedInsight生成丰富的、特定于患者的响应

    arXiv:2403.08607v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown impressive capabilities in generating human-like responses. However, their lack of domain-specific knowledge limits their applicability in healthcare settings, where contextual and comprehensive responses are vital. To address this challenge and enable the generation of patient-centric responses that are contextually relevant and comprehensive, we propose MedInsight:a novel retrieval augmented framework that augments LLM inputs (prompts) with relevant background information from multiple sources. MedInsight extracts pertinent details from the patient's medical record or consultation transcript. It then integrates information from authoritative medical textbooks and curated web resources based on the patient's health history and condition. By constructing an augmented context combining the patient's record with relevant medical knowledge, MedInsight generates enriched, patient-specific responses t
    
[^14]: DevBench：软件开发的综合基准测试

    DevBench: A Comprehensive Benchmark for Software Development

    [https://arxiv.org/abs/2403.08604](https://arxiv.org/abs/2403.08604)

    DevBench是一个综合基准测试，评估大型语言模型在软件开发生命周期各个阶段的表现，并发现现有的模型在其中存在挑战。

    

    arXiv:2403.08604v1宣布类型：新的摘要：大型语言模型（LLMs）的最新进展显著提升了它们的编码能力。然而，现有的基准测试主要关注编程的简化或孤立方面，如单文件代码生成或存储库问题调试，未能全面衡量由真实世界编程活动提出的各种挑战的全谱。为此，我们提出了DevBench，一个综合基准测试，评估LLMs在软件开发生命周期的各个阶段，包括软件设计、环境设置、实现、验收测试和单元测试。DevBench具有各种编程语言和领域，高质量数据收集，并针对每个任务精心设计和验证的指标。实证研究表明，当前的LLMs，包括GPT-4-Turbo，无法解决DevBench提出的挑战。分析表明，模型难以理解

    arXiv:2403.08604v1 Announce Type: new  Abstract: Recent advancements in large language models (LLMs) have significantly enhanced their coding capabilities. However, existing benchmarks predominantly focused on simplified or isolated aspects of programming, such as single-file code generation or repository issue debugging, falling short of measuring the full spectrum of challenges raised by real-world programming activities. To this end, we propose DevBench, a comprehensive benchmark that evaluates LLMs across various stages of the software development lifecycle, including software design, environment setup, implementation, acceptance testing, and unit testing. DevBench features a wide range of programming languages and domains, high-quality data collection, and carefully designed and verified metrics for each task. Empirical studies show that current LLMs, including GPT-4-Turbo, fail to solve the challenges presented within DevBench. Analyses reveal that models struggle with understand
    
[^15]: 当需要时给我打电话：LLM可以高效而忠实地推理结构化环境

    Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments

    [https://arxiv.org/abs/2403.08593](https://arxiv.org/abs/2403.08593)

    LLMs借助Reasoning-Path-Editing (Readi)框架，可以在结构化环境中高效且忠实地推理，显著提升了多个KGQA和TableQA数据集上的表现。

    

    大型语言模型（LLMs）已经展示出在推理结构化环境中的潜力，例如知识图谱和表格。这些任务通常需要多跳推理，即将自然语言话语与环境中的实例匹配。以往的方法利用LLMs逐步构建推理路径，其中LLMs通过与环境逐步交互来调用工具或选择模式。我们提出了一种新颖的框架Reasoning-Path-Editing（Readi），在其中LLMs可以高效且忠实地在结构化环境中进行推理。在Readi中，LLMs在给定查询时最初生成一个推理路径，只有在必要时才编辑路径。我们将路径实例化到结构化环境上，并在出现问题时提供反馈以编辑路径。对三个KGQA数据集和两个TableQA数据集的实验结果显示，Readi的有效性，显著超越了所有基于LLM的方法（在WebQ上提高了9.1％）。

    arXiv:2403.08593v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown potential in reasoning over structured environments, e.g., knowledge graph and table. Such tasks typically require multi-hop reasoning, i.e., match natural language utterance with instances in the environment. Previous methods leverage LLMs to incrementally build a reasoning path, where the LLMs either invoke tools or pick up schemas by step-by-step interacting with the environment. We propose Reasoning-Path-Editing (Readi), a novel framework where LLMs can efficiently and faithfully reason over structured environments. In Readi, LLMs initially generate a reasoning path given a query, and edit the path only when necessary. We instantiate the path on structured environments and provide feedback to edit the path if anything goes wrong. Experimental results on three KGQA datasets and two TableQA datasets show the effectiveness of Readi, significantly surpassing all LLM-based methods (by 9.1% on WebQ
    
[^16]: 生成语言模型的非歧视标准

    Non-discrimination Criteria for Generative Language Models

    [https://arxiv.org/abs/2403.08564](https://arxiv.org/abs/2403.08564)

    本文研究如何在生成式语言模型中识别和量化性别偏见，提出了三个生成式人工智能的非歧视标准并设计了相应的提示。

    

    近年来，生成式人工智能，如大型语言模型，经历了快速发展。随着这些模型越来越普遍地提供给公众使用，人们开始担心在应用中延续和放大有害偏见的问题。性别刻板印象可能对其针对的个人造成伤害和限制，无论是由误传还是歧视所构成。识别性别偏见作为一种普遍的社会构造，本文研究如何发现和量化生成式语言模型中性别偏见的存在。具体而言，我们推导出三个来自分类的著名非歧视标准的生成式人工智能类比，即独立性、分离性和充分性。为了展示这些标准的作用，我们设计了针对每个标准的提示，重点关注职业性别刻板印象，具体利用医学测试来在生成式人工智能背景中引入基本事实。

    arXiv:2403.08564v1 Announce Type: cross  Abstract: Within recent years, generative AI, such as large language models, has undergone rapid development. As these models become increasingly available to the public, concerns arise about perpetuating and amplifying harmful biases in applications. Gender stereotypes can be harmful and limiting for the individuals they target, whether they consist of misrepresentation or discrimination. Recognizing gender bias as a pervasive societal construct, this paper studies how to uncover and quantify the presence of gender biases in generative language models. In particular, we derive generative AI analogues of three well-known non-discrimination criteria from classification, namely independence, separation and sufficiency. To demonstrate these criteria in action, we design prompts for each of the criteria with a focus on occupational gender stereotype, specifically utilizing the medical test to introduce the ground truth in the generative AI context. 
    
[^17]: 语言模型与过度训练以及下游任务可靠扩展

    Language models scale reliably with over-training and on downstream tasks

    [https://arxiv.org/abs/2403.08540](https://arxiv.org/abs/2403.08540)

    本研究解决了语言模型缩放研究中过度训练和下游任务性能评估之间的差距。

    

    缩放规律对于开发语言模型是有用的指导，但当前的缩放研究与语言模型最终训练和评估之间仍然存在差距。本文解决了过度训练和基于下游任务表现进行比较方面的这两个缺点。

    arXiv:2403.08540v1 Announce Type: new  Abstract: Scaling laws are useful guides for developing language models, but there are still gaps between current scaling studies and how language models are ultimately trained and evaluated. For instance, scaling is usually studied in the compute-optimal training regime (i.e., "Chinchilla optimal" regime); however, in practice, models are often over-trained to reduce inference costs. Moreover, scaling laws mostly predict loss on next-token prediction, but ultimately models are compared based on downstream task performance. In this paper, we address both shortcomings. To do so, we create a testbed of 104 models with 0.011B to 6.9B parameters trained with various numbers of tokens on three data distributions. First, we investigate scaling in the over-trained regime. We fit scaling laws that extrapolate in both the number of model parameters and the ratio of training tokens to parameters. This enables us to predict the validation loss of a 1.4B para
    
[^18]: 具有状态感知病人模拟器的大型语言模型自动互动评估

    Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator

    [https://arxiv.org/abs/2403.08495](https://arxiv.org/abs/2403.08495)

    介绍了自动互动评估（AIE）框架和状态感知病人模拟器（SAPS），以动态、真实的平台评估LLMs，弥补传统评估方法无法满足临床任务需求的不足。

    

    大型语言模型（LLMs）在人机互动中表现出色，但在医疗领域的应用仍未得到充分探索。本文引入了自动互动评估（AIE）框架和状态感知病人模拟器（SAPS），旨在弥补传统LLM评估与临床实践的微妙需求之间的差距。

    arXiv:2403.08495v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in human interactions, yet their application within the medical field remains insufficiently explored. Previous works mainly focus on the performance of medical knowledge with examinations, which is far from the realistic scenarios, falling short in assessing the abilities of LLMs on clinical tasks. In the quest to enhance the application of Large Language Models (LLMs) in healthcare, this paper introduces the Automated Interactive Evaluation (AIE) framework and the State-Aware Patient Simulator (SAPS), targeting the gap between traditional LLM evaluations and the nuanced demands of clinical practice. Unlike prior methods that rely on static medical knowledge assessments, AIE and SAPS provide a dynamic, realistic platform for assessing LLMs through multi-turn doctor-patient simulations. This approach offers a closer approximation to real clinical scenarios and allows f
    
[^19]: 富含语义知识增强的大型语言模型用于少样本中文拼写检查

    Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking

    [https://arxiv.org/abs/2403.08492](https://arxiv.org/abs/2403.08492)

    本文使用富含语义知识的大型语言模型在少样本中文拼写检查任务上取得了比BERT模型更好的性能。

    

    本文探讨了使用一种名为RS-LLM（基于丰富语义的LLMs）的上下文学习方法将大型语言模型（LLMs）引入作为基础模型，以及在我们的框架中引入各种中文丰富语义信息的影响。实验结果表明，通过引入少量特定的中文丰富语义结构，LLMs在少样本中文拼写检查任务上比基于BERT模型表现更好。

    arXiv:2403.08492v1 Announce Type: new  Abstract: Chinese Spell Checking (CSC) is a widely used technology, which plays a vital role in speech to text (STT) and optical character recognition (OCR). Most of the existing CSC approaches relying on BERT architecture achieve excellent performance. However, limited by the scale of the foundation model, BERT-based method does not work well in few-shot scenarios, showing certain limitations in practical applications. In this paper, we explore using an in-context learning method named RS-LLM (Rich Semantic based LLMs) to introduce large language models (LLMs) as the foundation model. Besides, we study the impact of introducing various Chinese rich semantic information in our framework. We found that by introducing a small number of specific Chinese rich semantic structures, LLMs achieve better performance than the BERT-based model on few-shot CSC task. Furthermore, we conduct experiments on multiple datasets, and the experimental results verifie
    
[^20]: 数据驱动的动态微调参数选择策略，用于基于FISH Mask的高效微调

    Data-oriented Dynamic Fine-tuning Parameter Selection Strategy for FISH Mask based Efficient Fine-tuning

    [https://arxiv.org/abs/2403.08484](https://arxiv.org/abs/2403.08484)

    提出了一种数据驱动的动态微调参数选择策略，针对FISH Mask提出了IRD算法，用于在不稳定的数据分布下动态选择最佳参数设置。

    

    鉴于大型语言模型(LLMs)的参数数量巨大，调整所有参数成本很高，因此更明智的做法是对特定参数进行微调。大多数参数高效微调(PEFT)集中在参数选择策略上，例如加法方法、选择性方法和基于重新参数化的方法。然而，很少有方法考虑数据样本对参数选择的影响，例如基于Fish Mask的方法。Fish Mask随机选择部分数据样本，并在参数选择过程中对它们进行同等处理，这无法为不稳定的数据分布动态选择最佳参数。在这项工作中，我们采用了数据驱动的视角，提出了一个IRD(迭代样本参数范围减小)算法，以搜索FISH Mask的最佳样本参数对设置。

    arXiv:2403.08484v1 Announce Type: new  Abstract: In view of the huge number of parameters of Large language models (LLMs) , tuning all parameters is very costly, and accordingly fine-tuning specific parameters is more sensible. Most of parameter efficient fine-tuning (PEFT) concentrate on parameter selection strategies, such as additive method, selective method and reparametrization-based method. However, there are few methods that consider the impact of data samples on parameter selecting, such as Fish Mask based method. Fish Mask randomly choose a part of data samples and treat them equally during parameter selection, which is unable to dynamically select optimal parameters for inconstant data distributions. In this work, we adopt a data-oriented perspective, then proposing an IRD ($\mathrm{\underline I}$terative sample-parameter $\mathrm{\underline R}$ange $\mathrm{\underline D}$ecreasing) algorithm to search the best setting of sample-parameter pair for FISH Mask. In each iteration
    
[^21]: 基于语法模型似然比的作者身份验证

    Authorship Verification based on the Likelihood Ratio of Grammar Models

    [https://arxiv.org/abs/2403.08462](https://arxiv.org/abs/2403.08462)

    提出了一种基于计算作者文件在候选作者语法模型与参考群体语法模型下的可能性比率的方法，用以解决作者身份验证中存在的科学解释不足和难以解释的问题

    

    作者身份验证（AV）是分析一组文件以确定它们是否由特定作者撰写的过程。现有的最先进AV方法使用计算解决方案，对于其功能没有合理的科学解释，并且常常难以解释给分析人员。为解决这个问题，我们提出了一种方法，依赖于计算一个我们称之为 $\lambda_G$（LambdaG）的量：候选作者的上下文语法模型给出的文档的可能性与参考群体的上下文语法模型给出的相同文档的可能性之间的比率。这些语法模型是使用仅针对语法特征进行训练的 $n$-gram语言模型进行估计的。尽管不需要大量数据进行训练，LambdaG...

    arXiv:2403.08462v1 Announce Type: new  Abstract: Authorship Verification (AV) is the process of analyzing a set of documents to determine whether they were written by a specific author. This problem often arises in forensic scenarios, e.g., in cases where the documents in question constitute evidence for a crime. Existing state-of-the-art AV methods use computational solutions that are not supported by a plausible scientific explanation for their functioning and that are often difficult for analysts to interpret. To address this, we propose a method relying on calculating a quantity we call $\lambda_G$ (LambdaG): the ratio between the likelihood of a document given a model of the Grammar for the candidate author and the likelihood of the same document given a model of the Grammar for a reference population. These Grammar Models are estimated using $n$-gram language models that are trained solely on grammatical features. Despite not needing large amounts of data for training, LambdaG st
    
[^22]: Tastle: 为自动越狱攻击干扰大型语言模型

    Tastle: Distract Large Language Models for Automatic Jailbreak Attack

    [https://arxiv.org/abs/2403.08424](https://arxiv.org/abs/2403.08424)

    Tastle是一种新颖的黑盒越狱框架，采用恶意内容隐藏和内存重构以及迭代优化算法，用于自动对大型语言模型进行红队攻击。

    

    大型语言模型（LLMs）近年来取得了重要进展。在LLMs公开发布之前，人们已经做出了大量努力来将它们的行为与人类价值观保持一致。对齐的主要目标是确保它们的有益性、诚实性和无害性。然而，即使经过细致对齐的LLMs仍然容易受到恶意操纵，如越狱，导致意外的行为。越狱是有意开发恶意提示，从LLM安全限制中逃脱以生成未经审查的有害内容。以前的工作探索了不同的越狱方法来对LLMs进行红队攻击，但它们在效果和可伸缩性方面遇到了挑战。在这项工作中，我们提出了Tastle，一种新颖的黑盒越狱框架，用于自动对LLMs进行红队攻击。我们设计了恶意内容隐藏和内存重构，并结合迭代优化算法来越狱LLMs。

    arXiv:2403.08424v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved significant advances in recent days. Extensive efforts have been made before the public release of LLMs to align their behaviors with human values. The primary goal of alignment is to ensure their helpfulness, honesty and harmlessness. However, even meticulously aligned LLMs remain vulnerable to malicious manipulations such as jailbreaking, leading to unintended behaviors. The jailbreak is to intentionally develop a malicious prompt that escapes from the LLM security restrictions to produce uncensored detrimental contents. Previous works explore different jailbreak methods for red teaming LLMs, yet they encounter challenges regarding to effectiveness and scalability. In this work, we propose Tastle, a novel black-box jailbreak framework for automated red teaming of LLMs. We designed malicious content concealing and memory reframing with an iterative optimization algorithm to jailbreak LLMs, mo
    
[^23]: 虚假信息不是关于错误事实：对边缘内容的生产和消费进行分析

    Misinformation is not about Bad Facts: An Analysis of the Production and Consumption of Fringe Content

    [https://arxiv.org/abs/2403.08391](https://arxiv.org/abs/2403.08391)

    虚假信息不仅仅涉及错误的事实，研究发现在线边缘意识形态通过共识和“事实正确”的内容传播，同时发现了极右用户倾向挑选关注特定主题的新闻，并且可以根据用户的沟通风格识别易于分享错误信息的用户。

    

    如果误传根本不是一个信息问题呢？我们的研究发现，在线边缘意识形态通过一种基于共识和“事实正确”的内容传播。我们发现，具有中间和极右政治倾向的澳大利亚新闻出版商在信息完整性和质量方面居于可比水平；此外，极右翼Twitter用户经常分享来自中间来源的内容。然而，当我们考虑到两个额外因素时，出现了明显差异：1）极右用户对文章的狭隘主题选择，暗示他们只挑选与他们关注特定主题的新闻文章，2）在审查文章写作风格时，中间和极右出版商之间的巨大差异。此外，我们甚至可以根据用户的沟通风格识别易于分享错误信息的用户。这些发现对于合作方面有重要的启示。

    arXiv:2403.08391v1 Announce Type: new  Abstract: What if misinformation is not an information problem at all? Our findings suggest that online fringe ideologies spread through the use of content that is consensus-based and "factually correct". We found that Australian news publishers with both moderate and far-right political leanings contain comparable levels of information completeness and quality; and furthermore, that far-right Twitter users often share from moderate sources. However, a stark difference emerges when we consider two additional factors: 1) the narrow topic selection of articles by far-right users, suggesting that they cherrypick only news articles that engage with specific topics of their concern, and 2) the difference between moderate and far-right publishers when we examine the writing style of their articles. Furthermore, we can even identify users prone to sharing misinformation based on their communication style. These findings have important implications for co
    
[^24]: 学习描述以预测零样本药物相互作用

    Learning to Describe for Predicting Zero-shot Drug-Drug Interactions

    [https://arxiv.org/abs/2403.08377](https://arxiv.org/abs/2403.08377)

    提出了一种新的零样本药物相互作用（DDI）预测问题设置，通过利用在线数据库的文本信息和基于语言模型和强化学习的方法，实现对新药物准确DDI预测。

    

    药物相互作用（DDIs）可能影响同时使用药物的有效性，在医疗保健中构成重要挑战。本文提出了一种新的问题设置作为零样本DDI预测，处理新药物的情况。利用来自DrugBank和PubChem等在线数据库的文本信息，我们提出了一种创新的方法TextDDI，其中包括基于语言模型的DDI预测器和基于强化学习（RL）的信息选择器，实现对新药物进行准确DDI预测的简洁而相关文本的选择。实证结果表明了所提方法在包括零样本在内的几种设置上的好处。

    arXiv:2403.08377v1 Announce Type: new  Abstract: Adverse drug-drug interactions~(DDIs) can compromise the effectiveness of concurrent drug administration, posing a significant challenge in healthcare. As the development of new drugs continues, the potential for unknown adverse effects resulting from DDIs becomes a growing concern. Traditional computational methods for DDI prediction may fail to capture interactions for new drugs due to the lack of knowledge. In this paper, we introduce a new problem setup as zero-shot DDI prediction that deals with the case of new drugs. Leveraging textual information from online databases like DrugBank and PubChem, we propose an innovative approach TextDDI with a language model-based DDI predictor and a reinforcement learning~(RL)-based information selector, enabling the selection of concise and pertinent text for accurate DDI prediction on new drugs. Empirical results show the benefits of the proposed approach on several settings including zero-shot 
    
[^25]: 云迁移中SQL方言的转换

    Translating between SQL Dialects for Cloud Migration

    [https://arxiv.org/abs/2403.08375](https://arxiv.org/abs/2403.08375)

    本文讨论了云迁移中SQL数据库方言的转换困难，尽管有一些工具可以帮助转换方言，但并不能完全解决问题，需要人工干预。

    

    从现场到云的系统迁移是许多工业机构的重要工作。这种云迁移的关键组成部分是将数据库转移到在线主机。在这项工作中，我们考虑了SQL数据库的迁移困难。尽管SQL是存储数据库程序的显著方法之一，但存在着大量不同的SQL方言（例如MySQL，Postgres等），当现场的SQL方言与云上托管的方言不同时，这可能会使迁移复杂化。一些常见云提供商如AWS和Azure提供了工具来帮助在方言之间进行转换，以减轻大部分困难。然而，这些工具并不成功地转换 100% 的代码。因此，软件工程师必须手动转换未翻译数据库的其余部分。对于大型组织，这项任务很快变得棘手。

    arXiv:2403.08375v1 Announce Type: cross  Abstract: Migrations of systems from on-site premises to the cloud has been a fundamental endeavor by many industrial institutions. A crucial component of such cloud migrations is the transition of databases to be hosted online. In this work, we consider the difficulties of this migration for SQL databases. While SQL is one of the prominent methods for storing database procedures, there are a plethora of different SQL dialects (e.g., MySQL, Postgres, etc.) which can complicate migrations when the on-premise SQL dialect differs to the dialect hosted on the cloud. Tools exist by common cloud provides such as AWS and Azure to aid in translating between dialects in order to mitigate the majority of the difficulties. However, these tools do not successfully translate $100\%$ of the code. Consequently, software engineers must manually convert the remainder of the untranslated database. For large organizations, this task quickly becomes intractable and
    
[^26]: SMART: 用于指令调整的子模块数据混合策略

    SMART: Submodular Data Mixture Strategy for Instruction Tuning

    [https://arxiv.org/abs/2403.08370](https://arxiv.org/abs/2403.08370)

    SMART引入了一种新颖的数据混合策略，利用子模块函数为任务分配重要性分数，并在微调中重新分配预算，从而在指令调整任务中取得明显优势。

    

    指令调整涉及在一组以指令格式化的数据集上对语言模型进行微调，以增强模型对未见任务的泛化能力。研究表明，在微调过程中平衡不同任务比例的重要性，但找到合适的平衡仍然具有挑战性。目前除了手动调整或依赖从业者的直觉外，尚无系统方法。在本文中，我们介绍了SMART（Submodular data Mixture strAtegy for instRuction Tuning）- 一种利用子模块函数为任务分配重要性分数的新颖数据混合策略，然后用这些分数来确定混合权重。给定微调预算，SMART重新分配任务间的预算，并从每个任务中选择非冗余样本。实验结果表明，SMART显著优于传统方法，如例子比例混合和均等分配。

    arXiv:2403.08370v1 Announce Type: cross  Abstract: Instruction Tuning involves finetuning a language model on a collection of instruction-formatted datasets in order to enhance the generalizability of the model to unseen tasks. Studies have shown the importance of balancing different task proportions during finetuning, but finding the right balance remains challenging. Unfortunately, there's currently no systematic method beyond manual tuning or relying on practitioners' intuition. In this paper, we introduce SMART (Submodular data Mixture strAtegy for instRuction Tuning) - a novel data mixture strategy which makes use of a submodular function to assign importance scores to tasks which are then used to determine the mixture weights. Given a fine-tuning budget, SMART redistributes the budget among tasks and selects non-redundant samples from each task. Experimental results demonstrate that SMART significantly outperforms traditional methods such as examples proportional mixing and equal
    
[^27]: 缺陷演化分析的日志总结

    Log Summarisation for Defect Evolution Analysis

    [https://arxiv.org/abs/2403.08358](https://arxiv.org/abs/2403.08358)

    提出了一种在线基于语义的聚类方法，用于动态更新日志聚类，以实现监控代码错误的生命周期，并引入了一种新颖的度量标准来评估时间日志聚类的性能，最终发现我们的解决方案优于类似系统。

    

    日志分析和监控是软件维护中至关重要的方面，也是识别缺陷的关键。特别是，日志数据的时间性质和庞大规模引发了一个有趣且重要的研究问题：如何对日志进行总结和随时间监控？尽管这在软件工程领域是一个基础性研究课题，但现有的工作通常集中在启发式、语法或基于静态方法。在这项工作中，我们提出了一种在线基于语义的聚类方法，用于动态更新日志聚类，以实现监控代码错误的生命周期。我们还引入了一种新颖的度量标准来评估时间日志聚类的性能。我们使用工业数据集测试了我们的系统和评估度量标准，发现我们的解决方案优于类似系统。我们希望我们的工作能够鼓励在缺陷数据集中进行更深入的时间性探索。

    arXiv:2403.08358v1 Announce Type: cross  Abstract: Log analysis and monitoring are essential aspects in software maintenance and identifying defects. In particular, the temporal nature and vast size of log data leads to an interesting and important research question: How can logs be summarised and monitored over time? While this has been a fundamental topic of research in the software engineering community, work has typically focused on heuristic-, syntax-, or static-based methods. In this work, we suggest an online semantic-based clustering approach to error logs that dynamically updates the log clusters to enable monitoring code error life-cycles. We also introduce a novel metric to evaluate the performance of temporal log clusters. We test our system and evaluation metric with an industrial dataset and find that our solution outperforms similar systems. We hope that our work encourages further temporal exploration in defect datasets.
    
[^28]: 从人类专家到机器：一种LLM支持的本体论和知识图构建方法

    From human experts to machines: An LLM supported approach to ontology and knowledge graph construction

    [https://arxiv.org/abs/2403.08345](https://arxiv.org/abs/2403.08345)

    本文探讨了利用开源LLMs（半）自动构建知识图的方法，通过制定能力问题（CQs）、基于这些CQs开发本体论（TBox）、构建知识图并实现几乎不涉及人类专家的评估，展示了半自动化流程的可行性。

    

    建立本体论和知识图的传统过程严重依赖于人类领域专家来定义实体和关系类型，建立层次结构，保持与领域的关联性，填充ABox（或用实例填充），并确保数据质量（包括准确性和完整性）。另一方面，大型语言模型（LLMs）最近因其理解和生成类似人类自然语言的能力而备受推崇，为自动化该过程的方面提供了有希望的途径。本工作探讨了利用开源LLMs（半）自动构建知识图的方法。我们的流程涉及制定能力问题（CQs），基于这些CQs开发本体论（TBox），使用开发的本体论构建知识图，并在几乎不涉及人类专家的情况下评估生成的知识图。我们通过创建实例展示了半自动化流程的可行性。

    arXiv:2403.08345v1 Announce Type: new  Abstract: The conventional process of building Ontologies and Knowledge Graphs (KGs) heavily relies on human domain experts to define entities and relationship types, establish hierarchies, maintain relevance to the domain, fill the ABox (or populate with instances), and ensure data quality (including amongst others accuracy and completeness). On the other hand, Large Language Models (LLMs) have recently gained popularity for their ability to understand and generate human-like natural language, offering promising ways to automate aspects of this process. This work explores the (semi-)automatic construction of KGs facilitated by open-source LLMs. Our pipeline involves formulating competency questions (CQs), developing an ontology (TBox) based on these CQs, constructing KGs using the developed ontology, and evaluating the resultant KG with minimal to no involvement of human experts. We showcase the feasibility of our semi-automated pipeline by creat
    
[^29]: 自回归得分生成用于多特征作文评分

    Autoregressive Score Generation for Multi-trait Essay Scoring

    [https://arxiv.org/abs/2403.08332](https://arxiv.org/abs/2403.08332)

    提出一种自回归预测多特征分数的方法（ArTS），通过利用预先训练的T5来结合解码过程，实现了自动作文评分中多分数预测的效果。

    

    最近，仅编码器预训练模型如BERT已成功应用于自动作文评分（AES）中，用于预测单一整体分数。然而，研究尚未探索这些模型在多特征AES中的应用，可能是由于为每个特征复制基于BERT的模型的效率低下。我们突破了现有仅使用编码器的模型，提出了一种自回归预测多特征分数（ArTS）的方法，通过利用预先训练的T5来结合一个解码过程。与先前的回归或分类方法不同，我们重新定义AES为一个得分生成任务，允许单个模型预测多个分数。在解码过程中，随后的特征预测可以通过在先前的特征分数上进行条件化而受益。实验结果证明了ArTS的有效性，显示了在提示和特征方面平均提高5%以上。

    arXiv:2403.08332v1 Announce Type: cross  Abstract: Recently, encoder-only pre-trained models such as BERT have been successfully applied in automated essay scoring (AES) to predict a single overall score. However, studies have yet to explore these models in multi-trait AES, possibly due to the inefficiency of replicating BERT-based models for each trait. Breaking away from the existing sole use of encoder, we propose an autoregressive prediction of multi-trait scores (ArTS), incorporating a decoding process by leveraging the pre-trained T5. Unlike prior regression or classification methods, we redefine AES as a score-generation task, allowing a single model to predict multiple scores. During decoding, the subsequent trait prediction can benefit by conditioning on the preceding trait scores. Experimental results proved the efficacy of ArTS, showing over 5% average improvements in both prompts and traits.
    
[^30]: LLMs的知识冲突：一项调查

    Knowledge Conflicts for LLMs: A Survey

    [https://arxiv.org/abs/2403.08319](https://arxiv.org/abs/2403.08319)

    这项调查深入分析了LLMs在融合上下文和参数化知识时所面临的知识冲突，探讨了三类知识冲突对其可信度和性能的重要影响，并提出改进LLMs稳健性策略的策略。

    

    这项调查对大型语言模型（LLMs）的知识冲突进行了深入分析，突出了当它们融合上下文和参数化知识时所遇到的复杂挑战。我们关注三类知识冲突：上下文-记忆冲突、跨上下文冲突和内部记忆冲突。这些冲突可能会显著影响LLMs的可信度和性能，特别是在现实世界应用中，噪音和错误信息很常见。通过对这些冲突进行分类，探讨其原因，研究LLMs在这些冲突下的行为，并回顾可用的解决方案，本调查旨在为改进LLMs的稳健性策略提供启示，从而成为推动这一不断发展领域研究的宝贵资源。

    arXiv:2403.08319v1 Announce Type: cross  Abstract: This survey provides an in-depth analysis of knowledge conflicts for large language models (LLMs), highlighting the complex challenges they encounter when blending contextual and parametric knowledge. Our focus is on three categories of knowledge conflicts: context-memory, inter-context, and intra-memory conflict. These conflicts can significantly impact the trustworthiness and performance of LLMs, especially in real-world applications where noise and misinformation are common. By categorizing these conflicts, exploring the causes, examining the behaviors of LLMs under such conflicts, and reviewing available solutions, this survey aims to shed light on strategies for improving the robustness of LLMs, thereby serving as a valuable resource for advancing research in this evolving area.
    
[^31]: 聊天翻译评估是否受上下文帮助？

    Is Context Helpful for Chat Translation Evaluation?

    [https://arxiv.org/abs/2403.08314](https://arxiv.org/abs/2403.08314)

    自动度量标准在评估机器翻译聊天质量方面的应用受到限制，无参考度量标准在评估翻译质量时落后于有参考度量标准，尤其在非英语环境下评估时。研究发现将会话上下文信息结合到度量标准中可以改善其性能。

    

    虽然自动评估翻译质量的度量标准取得了近期成功，但它们在评估机器翻译聊天质量方面的应用却受到了限制。与新闻等更为结构化的文本不同，聊天对话通常是非结构化的、短小并且严重依赖于上下文信息。这给现有句子级度量标准在该领域的可靠性以及上下文在评估翻译质量中的作用提出了问题。受此启发，我们对现有主要用于新闻等结构化领域的句子级自动度量标准进行了元评估，以评估机器翻译聊天的质量。我们发现，在评估非英语环境下的翻译质量时，无参考度量标准落后于有参考度量标准，然后我们调查了如何将会话上下文信息结合到这些度量标准中，以影响它们的性能。

    arXiv:2403.08314v1 Announce Type: new  Abstract: Despite the recent success of automatic metrics for assessing translation quality, their application in evaluating the quality of machine-translated chats has been limited. Unlike more structured texts like news, chat conversations are often unstructured, short, and heavily reliant on contextual information. This poses questions about the reliability of existing sentence-level metrics in this domain as well as the role of context in assessing the translation quality. Motivated by this, we conduct a meta-evaluation of existing sentence-level automatic metrics, primarily designed for structured domains such as news, to assess the quality of machine-translated chats. We find that reference-free metrics lag behind reference-based ones, especially when evaluating translation quality in out-of-English settings. We then investigate how incorporating conversational contextual information in these metrics affects their performance. Our findings s
    
[^32]: 通过最小损失进行长上下文压缩的StreamingDialogue：长对话学习

    StreamingDialogue: Prolonged Dialogue Learning via Long Context Compression with Minimal Losses

    [https://arxiv.org/abs/2403.08312](https://arxiv.org/abs/2403.08312)

    提出了StreamingDialogue，通过将长对话历史压缩为"会话注意力汇集点"，最小化损失，使计算复杂度减少，并有潜力处理超过200k条话语，实现长时间对话学习

    

    标准的大型语言模型(LLMs)在处理具有长上下文的对话时遇到了效率和一致性问题。根据我们的观察，对话上下文具有高度结构化，并且对话中的特殊标记\textit{End-of-Utterance} (EoU) 有聚合信息的潜力。我们将EoU标记称为"会话注意力汇集点"（conv-attn sinks）。因此，我们介绍了StreamingDialogue，将长对话历史压缩为conv-attn沉点，并最小化损失，从而使计算复杂度与沉点数量（即话语数量）的平方成正比。当前的LLMs已经展示了处理长上下文窗口的能力，例如，窗口大小达到200k甚至更大。通过将话语压缩为EoUs，我们的方法有潜力处理超过200k条话语，实现长时间对话学习。

    arXiv:2403.08312v1 Announce Type: cross  Abstract: Standard Large Language Models (LLMs) struggle with handling dialogues with long contexts due to efficiency and consistency issues. According to our observation, dialogue contexts are highly structured, and the special token of \textit{End-of-Utterance} (EoU) in dialogues has the potential to aggregate information. We refer to the EoU tokens as ``conversational attention sinks'' (conv-attn sinks). Accordingly, we introduce StreamingDialogue, which compresses long dialogue history into conv-attn sinks with minimal losses, and thus reduces computational complexity quadratically with the number of sinks (i.e., the number of utterances). Current LLMs already demonstrate the ability to handle long context window, e.g., a window size of 200k or more. To this end, by compressing utterances into EoUs, our method has the potential to handle more than 200k of utterances, resulting in a prolonged dialogue learning. In order to minimize informatio
    
[^33]: 基于匿名众包平台的大型语言模型个性化评估方法研究

    Towards Personalized Evaluation of Large Language Models with An Anonymous Crowd-Sourcing Platform

    [https://arxiv.org/abs/2403.08305](https://arxiv.org/abs/2403.08305)

    提出了一个新颖的匿名众包评估平台，BingJian，用于大型语言模型，采用了竞争性评分机制，解决了现有方法主要评估客观问题、忽视主观问题、使用中心化数据集、忽视个性化因素的局限性。

    

    大型语言模型的评估在提升其性能方面起着关键作用。以往已经提出了许多用于评估大型语言模型的方法。然而，这些现有方法主要集中在评估客观问题，忽视了对大型语言模型而言非常普遍的主观问题的评估能力。此外，这些方法主要利用中心化数据集进行评估，问题库集中在评估平台本身。而且，这些平台采用的评估过程经常忽视了个性化因素，未考虑评估者和被评估模型的个体特征。为了解决这些问题，我们提出了一个新颖的匿名众包评估平台——炳剑，用于大型语言模型，采用了竞争性评分机制。

    arXiv:2403.08305v1 Announce Type: new  Abstract: Large language model evaluation plays a pivotal role in the enhancement of its capacity. Previously, numerous methods for evaluating large language models have been proposed in this area. Despite their effectiveness, these existing works mainly focus on assessing objective questions, overlooking the capability to evaluate subjective questions which is extremely common for large language models. Additionally, these methods predominantly utilize centralized datasets for evaluation, with question banks concentrated within the evaluation platforms themselves. Moreover, the evaluation processes employed by these platforms often overlook personalized factors, neglecting to consider the individual characteristics of both the evaluators and the models being evaluated. To address these limitations, we propose a novel anonymous crowd-sourcing evaluation platform, BingJian, for large language models that employs a competitive scoring mechanism wher
    
[^34]: Gemma：基于Gemini研究和技术的开放模型

    Gemma: Open Models Based on Gemini Research and Technology

    [https://arxiv.org/abs/2403.08295](https://arxiv.org/abs/2403.08295)

    Gemma是基于Gemini研究和技术所构建的开放模型系列，在语言理解、推理和安全性等方面表现出色，负责任地发布这些大型语言模型对于提高前沿模型的安全性至关重要。

    

    本文介绍了Gemma，这是一个基于Gemini模型研究和技术构建的轻量级、最先进的开放模型系列。Gemma模型在语言理解、推理和安全性等学术基准上表现出色。我们发布了两个规模的模型（20亿和70亿参数），并提供了预训练和微调的检查点。Gemma在18个基于文本的任务中，有11个任务优于类似规模的开放模型，并对模型的安全性和责任方面进行了全面评估，同时详细描述了模型开发过程。我们相信负责任地发布大型语言模型对于提高前沿模型的安全性，并实现下一波大型语言模型创新至关重要。

    arXiv:2403.08295v1 Announce Type: cross  Abstract: This work introduces Gemma, a family of lightweight, state-of-the art open models built from the research and technology used to create Gemini models. Gemma models demonstrate strong performance across academic benchmarks for language understanding, reasoning, and safety. We release two sizes of models (2 billion and 7 billion parameters), and provide both pretrained and fine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out of 18 text-based tasks, and we present comprehensive evaluations of safety and responsibility aspects of the models, alongside a detailed description of model development. We believe the responsible release of LLMs is critical for improving the safety of frontier models, and for enabling the next wave of LLM innovations.
    
[^35]: 生成预训练结构化Transformer：规模化的无监督句法语言模型

    Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale

    [https://arxiv.org/abs/2403.08293](https://arxiv.org/abs/2403.08293)

    GPST是一种无监督的句法语言模型，通过联合训练两个模型实现对原始文本的高并行预训练，克服了之前SLM依赖于黄金树和顺序训练的限制，展示了在多个任务中优于同等规模的GPT-2。

    

    句法语言模型（SLM）以从左到右的方式逐步生成带有其句法树的句子。我们提出了生成预训练结构化Transformer（GPST），这是一种规模化的无监督SLM，能够在原始文本上从头开始进行高并行预训练。GPST规避了之前SLM的一些限制，比如依赖于黄金树和顺序训练。它由两个组件组成，一个通常的SLM受单向语言建模损失的监督，以及一个额外的组合模型，用于引导句法解析树并计算成分表示，受双向语言建模损失的监督。我们提出了一个表示替代方案，以实现两个模型的联合并行训练，采用硬EM的方式。我们在OpenWebText上对GPST进行了预训练，该语料库包括90亿个token，并展示了GPST在许多任务上的优越性，涵盖了与GPT-2相当规模的内容。

    arXiv:2403.08293v1 Announce Type: cross  Abstract: A syntactic language model (SLM) incrementally generates a sentence with its syntactic tree in a left-to-right manner. We present Generative Pretrained Structured Transformers (GPST), an unsupervised SLM at scale capable of being pre-trained from scratch on raw texts with high parallelism. GPST circumvents the limitations of previous SLMs such as relying on gold trees and sequential training. It consists of two components, a usual SLM supervised by a uni-directional language modeling loss, and an additional composition model, which induces syntactic parse trees and computes constituent representations, supervised by a bi-directional language modeling loss. We propose a representation surrogate to enable joint parallel training of the two models in a hard-EM fashion. We pre-train GPST on OpenWebText, a corpus with $9$ billion tokens, and demonstrate the superiority of GPST over GPT-2 with a comparable size in numerous tasks covering bot
    
[^36]: 通过融合高度专业化语言模型同时掌握文本、代码和数学

    Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models

    [https://arxiv.org/abs/2403.08281](https://arxiv.org/abs/2403.08281)

    通过融合高度专业化的语言、代码和数学模型，提出了一种名为UltraFuser的融合框架，引入了标记级别的门控机制，并设计了两阶段训练策略，以同时在三个领域取得高性能。

    

    自然语言、编程代码和数学符号的底层数据分布变化巨大，对于那些努力同时在三个领域实现高性能的大型语言模型（LLMs）提出了复杂挑战。本文提出了一种直接融合已经高度专业化模型的方法。所提出的融合框架UltraFuser包括三个已经在语言、编码和数学上得到充分训练的专家。引入了一个标记级别的门控机制来混合专家的输出。设计了一个伴随平衡采样的两阶段训练策略以确保稳定性。为了有效训练融合模型，我们进一步构建了一个

    arXiv:2403.08281v1 Announce Type: cross  Abstract: Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously. Achieving a very high level of proficiency for an LLM within a specific domain often requires extensive training with relevant corpora, which is typically accompanied by a sacrifice in performance in other domains. In this paper, we propose to fuse models that are already highly-specialized directly. The proposed fusing framework, UltraFuser, consists of three distinct specialists that are already sufficiently trained on language, coding, and mathematics. A token-level gating mechanism is introduced to blend the specialists' outputs. A two-stage training strategy accompanied by balanced sampling is designed to ensure stability. To effectively train the fused model, we further construct a 
    
[^37]: RECIPE4U：EFL写作教育中的学生-ChatGPT互动数据集

    RECIPE4U: Student-ChatGPT Interaction Dataset in EFL Writing Education

    [https://arxiv.org/abs/2403.08272](https://arxiv.org/abs/2403.08272)

    该论文提出了RECIPE4U数据集，从212名大学生的EFL写作课程中收集，用于研究学生与ChatGPT之间的互动，建立了任务导向对话系统中意图检测和满意度估计的基准结果。

    

    arXiv：2403.08272v1 类型：新研究 摘要：生成式AI在教育中的应用正在扩大，但关于学生与AI系统之间大规模和真实世界互动的经验分析仍然有限。为了填补这一空白，我们提出了RECIPE4U（大学RECIPE），这是一份从一学期的实验中收集的数据集，共有212名大学生参与其中，他们参加的是英语作为外语（EFL）写作课程。在研究过程中，学生与ChatGPT进行对话以修改他们的文章。RECIPE4U包括了这些互动的全面记录，包括对话日志、学生意图、学生自评满意度以及学生的文章编辑历史。特别地，我们根据我们的编码方案，为RECIPE4U中的学生话语标注了13个意图标签。我们为教育环境中任务导向对话系统中的两个子任务建立了基准结果：意图检测和满意度估计。作为基础步骤，我们探索了

    arXiv:2403.08272v1 Announce Type: new  Abstract: The integration of generative AI in education is expanding, yet empirical analyses of large-scale and real-world interactions between students and AI systems still remain limited. Addressing this gap, we present RECIPE4U (RECIPE for University), a dataset sourced from a semester-long experiment with 212 college students in English as Foreign Language (EFL) writing courses. During the study, students engaged in dialogues with ChatGPT to revise their essays. RECIPE4U includes comprehensive records of these interactions, including conversation logs, students' intent, students' self-rated satisfaction, and students' essay edit histories. In particular, we annotate the students' utterances in RECIPE4U with 13 intention labels based on our coding schemes. We establish baseline results for two subtasks in task-oriented dialogue systems within educational contexts: intent detection and satisfaction estimation. As a foundational step, we explore 
    
[^38]: Skipformer：一种用于高效语音识别的跳过和恢复策略

    Skipformer: A Skip-and-Recover Strategy for Efficient Speech Recognition

    [https://arxiv.org/abs/2403.08258](https://arxiv.org/abs/2403.08258)

    Skipformer提出了一种“跳过和恢复”的Conformer架构，可以动态、不均匀地压缩序列输入长度，大大减少了计算预算和内存消耗，并获得更好的识别准确性。

    

    基于Conformer的注意力模型已成为自动语音识别任务的事实标杆模型。通常引入一个空白符号来对齐CTC或RNN-T模型的输入和输出序列。不幸的是，由于注意力机制，长输入长度会对计算预算和内存消耗造成二次负荷。在这项工作中，我们提出了一种名为Skipformer的“跳过和恢复”Conformer架构，以动态和不均匀地压缩序列输入长度。Skipformer使用中间CTC输出作为标准将帧分为三组：关键、跳过和忽略。关键组馈送到下一个Conformer块，其输出与跳过组通过原始时间顺序联接作为最终编码器输出。实验表明，我们的模型在Aishell-1上将输入序列长度减少了31倍，在Librispeech语料库上减少了22倍。同时，该模型可实现更好的识别准确性。

    arXiv:2403.08258v1 Announce Type: new  Abstract: Conformer-based attention models have become the de facto backbone model for Automatic Speech Recognition tasks. A blank symbol is usually introduced to align the input and output sequences for CTC or RNN-T models. Unfortunately, the long input length overloads computational budget and memory consumption quadratically by attention mechanism. In this work, we propose a "Skip-and-Recover" Conformer architecture, named Skipformer, to squeeze sequence input length dynamically and inhomogeneously. Skipformer uses an intermediate CTC output as criteria to split frames into three groups: crucial, skipping and ignoring. The crucial group feeds into next conformer blocks and its output joint with skipping group by original temporal order as the final encoder output. Experiments show that our model reduces the input sequence length by 31 times on Aishell-1 and 22 times on Librispeech corpus. Meanwhile, the model can achieve better recognition accu
    
[^39]: 利用大型语言模型作为语篇生成器提升不流畅检测

    Boosting Disfluency Detection with Large Language Model as Disfluency Generator

    [https://arxiv.org/abs/2403.08229](https://arxiv.org/abs/2403.08229)

    本研究提出了一种利用大型语言模型生成不流畅句子作为数据增强的轻量级方法，通过数据过滤和小型模型训练实现了不流畅检测性能的提升。

    

    当前的不流畅检测方法严重依赖昂贵且稀缺的人工标注数据。为了解决这一问题，一些方法采用启发式或统计特征来生成不流畅句子，部分提高了检测性能。然而，这些句子常常偏离真实场景，限制了整体模型改善。本研究提出了一种轻量级数据增强方法，利用大型语言模型（LLM）卓越的生成和语义理解能力生成不流畅句子作为增强数据。我们利用LLM生成多样且更真实的句子，通过具体提示进行引导，无需对LLM进行微调。随后，我们应用一种基于不确定性的数据过滤方法来提高生成句子的质量，用于训练小型检测模型以提高性能。

    arXiv:2403.08229v1 Announce Type: new  Abstract: Current disfluency detection methods heavily rely on costly and scarce human-annotated data. To tackle this issue, some approaches employ heuristic or statistical features to generate disfluent sentences, partially improving detection performance. However, these sentences often deviate from real-life scenarios, constraining overall model enhancement. In this study, we propose a lightweight data augmentation approach for disfluency detection, utilizing the superior generative and semantic understanding capabilities of large language model (LLM) to generate disfluent sentences as augmentation data. We leverage LLM to generate diverse and more realistic sentences guided by specific prompts, without the need for fine-tuning the LLM. Subsequently, we apply an uncertainty-aware data filtering approach to improve the quality of the generated sentences, utilized in training a small detection model for improved performance. Experiments using enha
    
[^40]: 基于深度学习BERT模型在情感分析中的应用研究

    Research on the Application of Deep Learning-based BERT Model in Sentiment Analysis

    [https://arxiv.org/abs/2403.08217](https://arxiv.org/abs/2403.08217)

    本文研究了深度学习技术在情感分析中的应用，重点探讨了BERT模型的架构、特性以及优化策略，并通过实验证实了BERT模型在情感分析中表现出的稳健性能和提升潜力。

    

    本文探讨了深度学习技术在情感分析中的应用，尤其专注于BERT模型。文章首先介绍了情感分析的基本概念以及深度学习方法在该领域中的应用。随后，深入探讨了BERT模型的架构和特性。通过详细解释，阐明了BERT模型在情感分析中的应用效果和优化策略，并得到实验证实支持。实验结果表明，BERT模型在情感分析任务中表现出稳健的性能，在微调后有显著提升。最后，文章总结了BERT模型在情感分析中的潜在应用，并提出了未来研究和实际应用的方向。

    arXiv:2403.08217v1 Announce Type: new  Abstract: This paper explores the application of deep learning techniques, particularly focusing on BERT models, in sentiment analysis. It begins by introducing the fundamental concept of sentiment analysis and how deep learning methods are utilized in this domain. Subsequently, it delves into the architecture and characteristics of BERT models. Through detailed explanation, it elucidates the application effects and optimization strategies of BERT models in sentiment analysis, supported by experimental validation. The experimental findings indicate that BERT models exhibit robust performance in sentiment analysis tasks, with notable enhancements post fine-tuning. Lastly, the paper concludes by summarizing the potential applications of BERT models in sentiment analysis and suggests directions for future research and practical implementations.
    
[^41]: 大型语言模型能否识别作者身份？

    Can Large Language Models Identify Authorship?

    [https://arxiv.org/abs/2403.08213](https://arxiv.org/abs/2403.08213)

    大型语言模型在作者识别方面的潜力尚未得到充分探索，本文通过全面评估解决了LLMs在作者验证和归属中的三个关键研究问题。

    

    精准识别作者身份对验证内容真实性和减少误导信息至关重要。 大型语言模型（LLMs）展示了出色的推理和问题解决能力。然而，它们在作者分析（包括作者验证和归属）方面的潜力仍未得到充分探索。 本文对LLMs在这些关键任务中进行了全面评估。 传统研究依赖于手工制作的文体特征，而最先进的方法利用预先训练的语言模型中的文本嵌入。 这些方法通常需要在标记数据上进行微调，然而在跨领域应用中往往表现出性能下降，并提供有限的可解释性。 本文旨在回答三个研究问题：（1）LLMs能否有效执行零样本、端到端的作者验证？（2）LLMs能否准确进行作者身份归属？

    arXiv:2403.08213v1 Announce Type: new  Abstract: The ability to accurately identify authorship is crucial for verifying content authenticity and mitigating misinformation. Large Language Models (LLMs) have demonstrated exceptional capacity for reasoning and problem-solving. However, their potential in authorship analysis, encompassing authorship verification and attribution, remains underexplored. This paper conducts a comprehensive evaluation of LLMs in these critical tasks. Traditional studies have depended on hand-crafted stylistic features, whereas state-of-the-art approaches leverage text embeddings from pre-trained language models. These methods, which typically require fine-tuning on labeled data, often suffer from performance degradation in cross-domain applications and provide limited explainability. This work seeks to address three research questions: (1) Can LLMs perform zero-shot, end-to-end authorship verification effectively? (2) Are LLMs capable of accurately attributing
    
[^42]: 大型语言模型是对比推理者

    Large Language Models are Contrastive Reasoners

    [https://arxiv.org/abs/2403.08211](https://arxiv.org/abs/2403.08211)

    对比提示方法显著提高大型语言模型进行复杂推理的能力，不仅在算术、常识和符号推理任务上表现优良，还可以与现有提示方法整合，实现更好的性能。

    

    提示方法在增强预训练大型语言模型（LLMs）的能力方面发挥着至关重要的作用。我们探讨了对比提示（CP）如何显著提高大型语言模型执行复杂推理的能力。我们通过简单地在LLMs提供答案之前添加"让我们给出一个正确答案和一个错误答案"来演示LLMs是体面的对比推理者。对两个大型语言模型的实验表明，零迁移对比提示提升了在一系列算术、常识和符号推理任务上的表现，而不需要手工制作的少量迁移示例，比如使用最先进的GPT-4模型，提高了在GSM8K上的准确率从35.9%到88.8%以及AQUA-RAT从41.3%到62.2%。我们的方法不仅在大多数算术和常识推理任务中胜过零迁移CoT和少量迁移CoT，还可以与现有的提示方法无缝整合，从而实现改进或者竞争

    arXiv:2403.08211v1 Announce Type: cross  Abstract: Prompting methods play a crucial role in enhancing the capabilities of pre-trained large language models (LLMs). We explore how contrastive prompting (CP) significantly improves the ability of large language models to perform complex reasoning. We demonstrate that LLMs are decent contrastive reasoners by simply adding "Let's give a correct and a wrong answer." before LLMs provide answers. Experiments on two large language models show that zero-shot contrastive prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks without any hand-crafted few-shot examples, such as increasing the accuracy on GSM8K from 35.9% to 88.8% and AQUA-RAT from 41.3% to 62.2% with the state-of-the-art GPT-4 model. Our method not only surpasses zero-shot CoT and few-shot CoT in most arithmetic and commonsense reasoning tasks but also can seamlessly integrate with existing prompting methods, resulting in improved or comp
    
[^43]: 验证和探索大规模地理语料库

    Validating and Exploring Large Geographic Corpora

    [https://arxiv.org/abs/2403.08198](https://arxiv.org/abs/2403.08198)

    本文研究了在大规模地理多语言网络语料库中的语料库创建决策对质量的影响，通过改进数据清洗方法来提高特定语言-国家子语料库的有效性，并重点关注未充分代表的语言和人口群体。

    

    这篇论文研究了语料库创建决策对大规模多语言地理网络语料库的影响。从Common Crawl获得的4270亿词语语料开始，使用三种方法来提高代表特定语言-国家对如新西兰英语的子语料库的质量：(i) 独立语言识别系统的一致性，(ii) 基于哈希的重复数据删除，以及(iii) 特定地点的异常值检测。然后通过使用语料相似性度量来将每个生成的语料库与基线数据集比较，评估了每个步骤对语言级别和国家级别的影响。旨在了解上游数据清洗决策对下游语料库的影响，特别关注未被充分代表的语言和人口。评估表明，随着每个清理阶段的进行，子语料库的有效性得到改善，但这种改善是不均匀的。

    arXiv:2403.08198v1 Announce Type: new  Abstract: This paper investigates the impact of corpus creation decisions on large multi-lingual geographic web corpora. Beginning with a 427 billion word corpus derived from the Common Crawl, three methods are used to improve the quality of sub-corpora representing specific language-country pairs like New Zealand English: (i) the agreement of independent language identification systems, (ii) hash-based deduplication, and (iii) location-specific outlier detection. The impact of each of these steps is then evaluated at the language level and the country level by using corpus similarity measures to compare each resulting corpus with baseline data sets. The goal is to understand the impact of upstream data cleaning decisions on downstream corpora with a specific focus on under-represented languages and populations. The evaluation shows that the validity of sub-corpora is improved with each stage of cleaning but that this improvement is unevenly distr
    
[^44]: SpeechColab排行榜：用于自动语音识别评估的开源平台

    SpeechColab Leaderboard: An Open-Source Platform for Automatic Speech Recognition Evaluation

    [https://arxiv.org/abs/2403.08196](https://arxiv.org/abs/2403.08196)

    介绍了SpeechColab Leaderboard，一个用于ASR评估的开源平台，提供全面的基准测试，揭示了ASR系统的最新技术现状，并量化了得分管道中不同细微之处对最终基准测试结果的影响。

    

    随着过去十年深度学习浪潮的涌现，自动语音识别（ASR）引起了相当大的关注，导致了许多可公开访问的ASR系统的出现，这些系统正在积极地融入我们的日常生活中。然而，这些ASR系统的公正和可复制评估面临着由于各种关键微妙之处而带来的挑战。本文介绍了SpeechColab排行榜，这是一个通用的开源平台，专为ASR评估而设计。借助这个平台：(i)我们报告了一项全面的基准测试，揭示了ASR系统的最新技术现状，涵盖了开源模型和工业商业服务。 (ii)我们量化了得分管道中不同细微之处对最终基准测试结果的影响。这些包括与大写、标点、插入语、缩略语、同义词使用、复合词等相关的微妙之处。

    arXiv:2403.08196v1 Announce Type: new  Abstract: In the wake of the surging tide of deep learning over the past decade, Automatic Speech Recognition (ASR) has garnered substantial attention, leading to the emergence of numerous publicly accessible ASR systems that are actively being integrated into our daily lives. Nonetheless, the impartial and replicable evaluation of these ASR systems encounters challenges due to various crucial subtleties. In this paper we introduce the SpeechColab Leaderboard, a general-purpose, open-source platform designed for ASR evaluation. With this platform: (i) We report a comprehensive benchmark, unveiling the current state-of-the-art panorama for ASR systems, covering both open-source models and industrial commercial services. (ii) We quantize how distinct nuances in the scoring pipeline influence the final benchmark outcomes. These include nuances related to capitalization, punctuation, interjection, contraction, synonym usage, compound words, etc. These
    
[^45]: MoleculeQA: 一个用于评估分子理解中事实准确性的数据集

    MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension

    [https://arxiv.org/abs/2403.08192](https://arxiv.org/abs/2403.08192)

    MoleculeQA是一个用于评估分子理解中事实准确性的数据集，具有62K个QA对，是第一个分子事实偏见评估的基准，也是最大的分子研究QA数据集。

    

    大型语言模型在分子研究中发挥越来越重要的作用，然而现有模型通常生成错误信息，给准确的分子理解带来挑战。传统的生成内容评估指标无法评估模型在分子理解中的准确性。为了纠正事实评估的缺失，我们提出了MoleculeQA，这是一个新颖的问题回答（QA）数据集，其中包含了23K个分子的62K个QA对。每个QA对由一个手动问题、一个正选项和三个负选项组成，并且与权威分子语料库中的分子描述具有一致的语义。MoleculeQA不仅是用于分子事实偏见评估的第一个基准，也是用于分子研究的最大QA数据集。对现有分子LLMs在MoleculeQA上进行的全面评估揭示了它们在特定领域的不足之处，并指出了一些特别关键的问题。

    arXiv:2403.08192v1 Announce Type: new  Abstract: Large language models are playing an increasingly significant role in molecular research, yet existing models often generate erroneous information, posing challenges to accurate molecular comprehension. Traditional evaluation metrics for generated content fail to assess a model's accuracy in molecular understanding. To rectify the absence of factual evaluation, we present MoleculeQA, a novel question answering (QA) dataset which possesses 62K QA pairs over 23K molecules. Each QA pair, composed of a manual question, a positive option and three negative options, has consistent semantics with a molecular description from authoritative molecular corpus. MoleculeQA is not only the first benchmark for molecular factual bias evaluation but also the largest QA dataset for molecular research. A comprehensive evaluation on MoleculeQA for existing molecular LLMs exposes their deficiencies in specific areas and pinpoints several particularly crucial
    
[^46]: 嵌入式翻译用于低资源自动互译词汇标注

    Embedded Translations for Low-resource Automated Glossing

    [https://arxiv.org/abs/2403.08189](https://arxiv.org/abs/2403.08189)

    研究在低资源环境下自动词间标注，通过嵌入式翻译信息提升神经模型性能达到提升，尤其在处理和解释适度数据源时。

    

    我们研究了在低资源环境下自动词间标注。我们使用从词间标注文本中提取的嵌入式翻译信息来增强基于硬注意力的神经模型。通过使用大型语言模型（具体来说是BERT和T5）对这些翻译进行编码，我们引入了一个字符级解码器来生成标注输出。在这些增强的帮助下，我们的模型在SIGMORPHON 2023词间标注共享任务数据集上相比之前的最先进技术展现出了平均提升3.97\%。在模拟的超低资源环境中，即使只训练了100个句子，我们的系统也比简单的硬注意力基线平均提升了9.78\%。这些结果突显了翻译信息在提升系统性能中的关键作用，尤其是在处理和解释适度数据源时。我们的发现为这一领域未来研究指明了一个有前景的方向。

    arXiv:2403.08189v1 Announce Type: new  Abstract: We investigate automatic interlinear glossing in low-resource settings. We augment a hard-attentional neural model with embedded translation information extracted from interlinear glossed text. After encoding these translations using large language models, specifically BERT and T5, we introduce a character-level decoder for generating glossed output. Aided by these enhancements, our model demonstrates an average improvement of 3.97\%-points over the previous state of the art on datasets from the SIGMORPHON 2023 Shared Task on Interlinear Glossing. In a simulated ultra low-resource setting, trained on as few as 100 sentences, our system achieves an average 9.78\%-point improvement over the plain hard-attentional baseline. These results highlight the critical role of translation information in boosting the system's performance, especially in processing and interpreting modest data sources. Our findings suggest a promising avenue for the do
    
[^47]: 自动语音识别 (ASR) 用于诊断韩国儿童言语声音障碍的发音

    Automatic Speech Recognition (ASR) for the Diagnosis of pronunciation of Speech Sound Disorders in Korean children

    [https://arxiv.org/abs/2403.08187](https://arxiv.org/abs/2403.08187)

    该研究提出了一个专门用于诊断韩国儿童言语声音障碍发音问题的自动语音识别模型，通过微调 wav2vec 2.0 XLS-R 模型，成功实现了对孩子们发音的高准确度识别。

    

    这项研究提出了一个自动语音识别 (ASR) 模型，旨在诊断患有言语声音障碍 (SSDs) 的儿童的发音问题，以取代临床程序中的手动转录。我们对 wav2vec 2.0 XLS-R 模型进行了微调，使其能够识别实际发音而非现有单词。该模型使用了来自137名言语表达不足的儿童的语音数据集，这些儿童发音73个为实际临床诊断选定的韩语单词。模型对这些单词的发音进行的预测与人工标注的准确率约为90%。尽管模型仍需改进以识别不清楚的发音，但该研究表明 ASR 模型能够简化串行的诊断过程。

    arXiv:2403.08187v1 Announce Type: new  Abstract: This study presents a model of automatic speech recognition (ASR) designed to diagnose pronunciation issues in children with speech sound disorders (SSDs) to replace manual transcriptions in clinical procedures. Since ASR models trained for general purposes primarily predict input speech into real words, employing a well-known high-performance ASR model for evaluating pronunciation in children with SSDs is impractical. We fine-tuned the wav2vec 2.0 XLS-R model to recognize speech as pronounced rather than as existing words. The model was fine-tuned with a speech dataset from 137 children with inadequate speech production pronouncing 73 Korean words selected for actual clinical diagnosis. The model's predictions of the pronunciations of the words matched the human annotations with about 90% accuracy. While the model still requires improvement in recognizing unclear pronunciation, this study demonstrates that ASR models can streamline comp
    
[^48]: 重新思考事实验证的损失函数

    Rethinking Loss Functions for Fact Verification

    [https://arxiv.org/abs/2403.08174](https://arxiv.org/abs/2403.08174)

    提出了专为FEVER任务定制的两种任务特定目标函数，相比标准交叉熵在事实验证中表现更好，并通过简单类别加权进一步提高性能。

    

    我们研究了FEVER共享任务中事实验证的损失函数。虽然交叉熵损失是训练判决预测器的标准目标，但它未能捕捉到FEVER判决类别之间的异质性。本文提出了两个针对FEVER的特定任务目标。实验结果证实，所提出的目标函数优于标准的交叉熵。当这些目标与简单的类别加权相结合时，性能进一步提高，有效地克服了训练数据中的不平衡。源代码可在https://github.com/yuta-mukobara/RLF-KGAT 上找到。

    arXiv:2403.08174v1 Announce Type: cross  Abstract: We explore loss functions for fact verification in the FEVER shared task. While the cross-entropy loss is a standard objective for training verdict predictors, it fails to capture the heterogeneity among the FEVER verdict classes. In this paper, we develop two task-specific objectives tailored to FEVER. Experimental results confirm that the proposed objective functions outperform the standard cross-entropy. Performance is further improved when these objectives are combined with simple class weighting, which effectively overcomes the imbalance in the training data. The souce code is available at https://github.com/yuta-mukobara/RLF-KGAT
    
[^49]: MolBind: 多模态对齐语言、分子和蛋白质

    MolBind: Multimodal Alignment of Language, Molecules, and Proteins

    [https://arxiv.org/abs/2403.08167](https://arxiv.org/abs/2403.08167)

    MolBind 提出了一个框架，通过对比学习为多种模态训练编码器，将所有模态映射到共享特征空间，实现多模态语义对齐。

    

    生物学和化学的最新进展已经利用多模态学习，将分子及其自然语言描述整合起来，以增强药物发现。然而，当前的预训练框架仅限于两种模态，设计一个统一的网络来处理不同模态（例如自然语言、2D分子图、3D分子构象和3D蛋白质）仍然具有挑战性，因为它们之间存在固有的差距。

    arXiv:2403.08167v1 Announce Type: cross  Abstract: Recent advancements in biology and chemistry have leveraged multi-modal learning, integrating molecules and their natural language descriptions to enhance drug discovery. However, current pre-training frameworks are limited to two modalities, and designing a unified network to process different modalities (e.g., natural language, 2D molecular graphs, 3D molecular conformations, and 3D proteins) remains challenging due to inherent gaps among them. In this work, we propose MolBind, a framework that trains encoders for multiple modalities through contrastive learning, mapping all modalities to a shared feature space for multi-modal semantic alignment. To facilitate effective pre-training of MolBind on multiple modalities, we also build and collect a high-quality dataset with four modalities, MolBind-M4, including graph-language, conformation-language, graph-conformation, and conformation-protein paired data. MolBind shows superior zero-sh
    
[^50]: BAGEL: 通过语言引导探索引导代理自主学习

    BAGEL: Bootstrapping Agents by Guiding Exploration with Language

    [https://arxiv.org/abs/2403.08140](https://arxiv.org/abs/2403.08140)

    BAGEL 提出了一种新方法，通过循环操作将随机探索到的轨迹或合成指令转换为演示，以使语言模型代理能够在新环境中自主学习适应。

    

    在数字环境（例如Web浏览器和REST API）中通过执行动作来遵循自然语言指令对于语言模型代理是一项具有挑战性的任务。不幸的是，语言模型代理经常在没有人类演示的情况下无法推广到新环境。本文提出了BAGEL，一种无需人类监督即可引导语言模型代理的方法。BAGEL将一组随机探索的轨迹或合成指令转换成演示，通过两个噪声语言模型组件之间的往返来完成：一个将轨迹转换为合成指令的语言模型标记器，以及一个将合成指令映射为经过改进的轨迹的零样本语言模型代理。通过迭代执行这些往返操作，BAGEL可以快速将最初的轨迹分布转变为那些被自然语言描述完善的轨迹。我们使用BAGEL演示来在测试时间通过在上下文学习上调零样本语言模型代理。

    arXiv:2403.08140v1 Announce Type: new  Abstract: Following natural language instructions by executing actions in digital environments (e.g. web-browsers and REST APIs) is a challenging task for language model (LM) agents. Unfortunately, LM agents often fail to generalize to new environments without human demonstrations. This work presents BAGEL, a method for bootstrapping LM agents without human supervision. BAGEL converts a seed set of randomly explored trajectories or synthetic instructions, into demonstrations, via round-trips between two noisy LM components: an LM labeler which converts a trajectory into a synthetic instruction, and a zero-shot LM agent which maps the synthetic instruction into a refined trajectory. By performing these round-trips iteratively, BAGEL quickly converts the initial distribution of trajectories towards those that are well-described by natural language. We use BAGEL demonstrations to adapt a zero shot LM agent at test time via in-context learning over re
    
[^51]: 从论文到卡片：利用生成人工智能改变设计启示

    From Paper to Card: Transforming Design Implications with Generative AI

    [https://arxiv.org/abs/2403.08137](https://arxiv.org/abs/2403.08137)

    使用生成人工智能构建系统，从学术论文中创建设计卡片，帮助设计师更好理解设计启示并提高沟通效率。

    

    交流设计启示在人机交互领域中发表学术论文时很常见，然而这些论文很少被设计师们阅读和使用。一种解决方案是使用设计卡片作为一种翻译资源，以更易消化和获取的方式传达论文中的有价值见解，以协助设计过程。然而，创建设计卡片可能耗时，而作者可能缺乏制作卡片的资源和知识。通过迭代设计过程，我们构建了一个系统，使用LLM和文本转图像模型从学术论文中帮助创建设计卡片。我们对设计师（N=21）和所选论文的作者（N=12）进行的评估显示，设计师认为我们设计卡片中的设计启示比阅读原始论文文本更具启发性和生成性，而作者则认为我们的系统是传达他们设计启示的有效方式。

    arXiv:2403.08137v1 Announce Type: cross  Abstract: Communicating design implications is common within the HCI community when publishing academic papers, yet these papers are rarely read and used by designers. One solution is to use design cards as a form of translational resource that communicates valuable insights from papers in a more digestible and accessible format to assist in design processes. However, creating design cards can be time-consuming, and authors may lack the resources/know-how to produce cards. Through an iterative design process, we built a system that helps create design cards from academic papers using an LLM and text-to-image model. Our evaluation with designers (N=21) and authors of selected papers (N=12) revealed that designers perceived the design implications from our design cards as more inspiring and generative, compared to reading original paper texts, and the authors viewed our system as an effective way of communicating their design implications. We also
    
[^52]: 法律约束但不公平？朝向评估隐私政策公平性的方向

    Legally Binding but Unfair? Towards Assessing Fairness of Privacy Policies

    [https://arxiv.org/abs/2403.08115](https://arxiv.org/abs/2403.08115)

    本研究旨在评估隐私政策的公平性，通过从法律来源和公平性研究中确定信息公正性、表现公正性和道德/伦理与隐私政策的关系，并提出自动评估政策的选项。

    

    隐私政策应当告知数据主体其数据保护权利，解释数据控制者的数据管理实践，并使保留期限或数据转移给第三方等事实透明化。隐私政策只有在数据主体正确感知、解释、理解和信任时才能实现其目的。其中，这要求隐私政策以公平的方式编写，例如不使用极端的术语，不需要特定的教育程度，或不假设特定的社会背景。在这份进行中的工作论文中，我们概述了我们评估隐私政策公平性的方法。为此，我们从基本法律来源和公平性研究中确定信息公正性、表现公正性和道德/伦理与隐私政策的关系。我们提出了自动评估政策的选项。

    arXiv:2403.08115v1 Announce Type: cross  Abstract: Privacy policies are expected to inform data subjects about their data protection rights. They should explain the data controller's data management practices, and make facts such as retention periods or data transfers to third parties transparent. Privacy policies only fulfill their purpose, if they are correctly perceived, interpreted, understood, and trusted by the data subject. Amongst others, this requires that a privacy policy is written in a fair way, e.g., it does not use polarizing terms, does not require a certain education, or does not assume a particular social background. In this work-in-progress paper, we outline our approach to assessing fairness in privacy policies. To this end, we identify from fundamental legal sources and fairness research, how the dimensions informational fairness, representational fairness and ethics/morality are related to privacy policies. We propose options to automatically assess policies in the
    
[^53]: 人类中心设计的AI辅助因果路径图

    AI-Assisted Causal Pathway Diagram for Human-Centered Design

    [https://arxiv.org/abs/2403.08111](https://arxiv.org/abs/2403.08111)

    本文研究了将因果路径图整合到人类中心设计中的方法，开发了专用插件用于在线协作白板平台，通过用户研究发现其支持设计过程中的分散和集中阶段，减少设计师的认知负荷并增加创造力。

    

    本文探讨了将因果路径图（CPD）整合到人类中心设计（HCD）中，研究这些图如何增强设计过程的早期阶段。开发了专用的CPD插件，用于在线协作白板平台Miro，以简化图的创建并提供实时的AI驱动指导。通过与设计师（N=20）的用户研究，我们发现CPD的分支和其对因果关系的强调在设计过程的分散和集中阶段都得到了支持。CPD也可以促进利益相关者之间的沟通。此外，我们发现我们的插件显著减少了设计师的认知负荷，并在头脑风暴过程中增加了他们的创造力，突显了AI辅助工具在支持创造性工作和基于证据的设计中的影响。

    arXiv:2403.08111v1 Announce Type: cross  Abstract: This paper explores the integration of causal pathway diagrams (CPD) into human-centered design (HCD), investigating how these diagrams can enhance the early stages of the design process. A dedicated CPD plugin for the online collaborative whiteboard platform Miro was developed to streamline diagram creation and offer real-time AI-driven guidance. Through a user study with designers (N=20), we found that CPD's branching and its emphasis on causal connections supported both divergent and convergent processes during design. CPD can also facilitate communication among stakeholders. Additionally, we found our plugin significantly reduces designers' cognitive workload and increases their creativity during brainstorming, highlighting the implications of AI-assisted tools in supporting creative work and evidence-based designs.
    
[^54]: 利用Context-Reverso数据使用Transformer模型生成具有上下文清晰度的句子

    Contextual Clarity: Generating Sentences with Transformer Models using Context-Reverso Data

    [https://arxiv.org/abs/2403.08103](https://arxiv.org/abs/2403.08103)

    使用Transformer模型和Context-Reverso数据生成具有上下文清晰度的句子

    

    在信息丰富的时代，提供与上下文相关且简洁的信息对用户至关重要。关键词上下文(KIC)生成是在一些应用中扮演至关重要角色的任务，比如搜索引擎、个人助手和内容摘要。本文提出了一种利用T5 transformer模型生成给定关键词的明确且简洁句子上下文的新方法，利用了从Context-Reverso API获取的数据。

    arXiv:2403.08103v1 Announce Type: cross  Abstract: In the age of information abundance, the ability to provide users with contextually relevant and concise information is crucial. Keyword in Context (KIC) generation is a task that plays a vital role in and generation applications, such as search engines, personal assistants, and content summarization. In this paper, we present a novel approach to generating unambiguous and brief sentence-contexts for given keywords using the T5 transformer model, leveraging data obtained from the Context-Reverso API. The code is available at https://github.com/Rusamus/word2context/tree/main .
    
[^55]: 具有自注意力机制的下一个标记预测的力学

    Mechanics of Next Token Prediction with Self-Attention

    [https://arxiv.org/abs/2403.08081](https://arxiv.org/abs/2403.08081)

    通过梯度下降训练自注意力学习到一个自动机，在下一个标记预测中生成标记的两个不同步骤是：硬检索和软组合。

    

    基于Transformer的语言模型在大型数据集上训练，以预测给定输入序列的下一个标记。尽管训练目标简单，但它们已经在自然语言处理领域取得了革命性进展。这一成功的基础是自注意力机制。在这项研究中，我们提出了一个问题：一个单独的自注意力层从下一个标记预测中学到了什么？我们展示：通过梯度下降训练自注意力学习到一个自动机，该自动机通过两个不同的步骤生成下一个标记：(1) 硬检索：在给定输入序列的情况下，自注意力精确选择与上一个输入标记相关的高优先级输入标记。(2) 软组合：然后，它创建高优先级标记的凸组合。

    arXiv:2403.08081v1 Announce Type: cross  Abstract: Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: $\textit{What}$ $\textit{does}$ $\textit{a}$ $\textit{single}$ $\textit{self-attention}$ $\textit{layer}$ $\textit{learn}$ $\textit{from}$ $\textit{next-token}$ $\textit{prediction?}$ We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: $\textbf{(1)}$ $\textbf{Hard}$ $\textbf{retrieval:}$ Given input sequence, self-attention precisely selects the $\textit{high-priority}$ $\textit{input}$ $\textit{tokens}$ associated with the last input token. $\textbf{(2)}$ $\textbf{Soft}$ $\textbf{composition:}$ It then creates a convex combination of the high-priority tok
    
[^56]: FluoroSAM: 用于X光图像分割的语言对齐基础模型

    FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation

    [https://arxiv.org/abs/2403.08059](https://arxiv.org/abs/2403.08059)

    FluoroSAM是用于X光图像的分割的语言对齐基础模型，提供了一种在X光成像领域具有广泛适用性的自动图像分析工具。

    

    自动X光图像分割将加速诊断和介入精准医学领域的研究和发展。先前的研究已经提出了适用于解决特定图像分析问题的特定任务模型，但这些模型的效用受限于特定任务领域，要拓展到更广泛的应用则需要额外的数据、标签和重新训练工作。最近，基础模型（FMs） - 训练在大量高度变化数据上的机器学习模型因此使得广泛适用性成为可能 - 已经成为自动图像分析的有希望的工具。现有的用于医学图像分析的FMs聚焦于对象被明显可见边界清晰定义的场景和模式，如内窥镜手术工具分割。相比之下，X光成像通常没有提供这种清晰的边界或结构先验。在X光图像形成期间，复杂的三维

    arXiv:2403.08059v1 Announce Type: cross  Abstract: Automated X-ray image segmentation would accelerate research and development in diagnostic and interventional precision medicine. Prior efforts have contributed task-specific models capable of solving specific image analysis problems, but the utility of these models is restricted to their particular task domain, and expanding to broader use requires additional data, labels, and retraining efforts. Recently, foundation models (FMs) -- machine learning models trained on large amounts of highly variable data thus enabling broad applicability -- have emerged as promising tools for automated image analysis. Existing FMs for medical image analysis focus on scenarios and modalities where objects are clearly defined by visually apparent boundaries, such as surgical tool segmentation in endoscopy. X-ray imaging, by contrast, does not generally offer such clearly delineated boundaries or structure priors. During X-ray image formation, complex 3D
    
[^57]: CHAI：高效LLM推理的聚类头部注意力

    CHAI: Clustered Head Attention for Efficient LLM Inference

    [https://arxiv.org/abs/2403.08058](https://arxiv.org/abs/2403.08058)

    CHAI提出了Clustered Head Attention（CHAI）方法，通过在运行时结合具有高相关性的注意力头部，实现了减少内存需求和计算量，能够在不需要微调的情况下将存储K,V缓存的内存需求降低21.4％，推理时间延迟降低1.73倍。

    

    大语言模型(LLMs)拥有数百亿参数改变了机器学习领域。然而，在推理时为这些模型提供服务既需要计算又需要内存，一个请求可能需要多个GPU和数十GB的内存。多头注意力是LLMs的关键组件之一，可以占LLMs内存和计算需求的50%以上。我们观察到在各头之间对注意力的关注有很高的冗余性。基于这一观察，我们提出了Clustered Head Attention (CHAI)。CHAI在运行时将具有高相关性的头部结合进行自注意力，从而减少内存和计算。在我们的实验中，我们展示了CHAI能够将存储K,V缓存的内存需求降低多达21.4%，推理时延迟降低多达1.73倍，而无需任何微调。CHAI实现了最多3.2%的偏差。

    arXiv:2403.08058v1 Announce Type: cross  Abstract: Large Language Models (LLMs) with hundreds of billions of parameters have transformed the field of machine learning. However, serving these models at inference time is both compute and memory intensive, where a single request can require multiple GPUs and tens of Gigabytes of memory. Multi-Head Attention is one of the key components of LLMs, which can account for over 50% of LLMs memory and compute requirement. We observe that there is a high amount of redundancy across heads on which tokens they pay attention to. Based on this insight, we propose Clustered Head Attention (CHAI). CHAI combines heads with a high amount of correlation for self-attention at runtime, thus reducing both memory and compute. In our experiments, we show that CHAI is able to reduce the memory requirements for storing K,V cache by up to 21.4% and inference time latency by up to 1.73x without any fine-tuning required. CHAI achieves this with a maximum 3.2% deviat
    
[^58]: 生成用于消除合同歧义的澄清问题

    Generating Clarification Questions for Disambiguating Contracts

    [https://arxiv.org/abs/2403.08053](https://arxiv.org/abs/2403.08053)

    本研究提出了一个新颖的法律自然语言处理任务，旨在生成合同的澄清问题，以帮助识别合同中的歧义。

    

    企业经常签订商业合同，这些合同可以作为项目特定需求的重要来源。合同条款是必须遵守的，并且从合同中得出的需求可以详细说明非法务利益相关者（包括需求分析师、工程师和交付人员）需要进行的下游实施活动。然而，由于广泛使用法律术语和合同语言的固有复杂性，理解合同对这些利益相关者来说是一项认知上的挑战，也容易出错。此外，为了确保全面覆盖，合同通常包含措辞含糊的条款。相反，非法务利益相关者需要详细明了、无歧义地理解合同条款，以制定可执行的需求。在这项工作中，我们介绍了一个涉及生成合同澄清问题的新颖法律自然语言处理任务。这些问题旨在识别合同的歧义。

    arXiv:2403.08053v1 Announce Type: new  Abstract: Enterprises frequently enter into commercial contracts that can serve as vital sources of project-specific requirements. Contractual clauses are obligatory, and the requirements derived from contracts can detail the downstream implementation activities that non-legal stakeholders, including requirement analysts, engineers, and delivery personnel, need to conduct. However, comprehending contracts is cognitively demanding and error-prone for such stakeholders due to the extensive use of Legalese and the inherent complexity of contract language. Furthermore, contracts often contain ambiguously worded clauses to ensure comprehensive coverage. In contrast, non-legal stakeholders require a detailed and unambiguous comprehension of contractual clauses to craft actionable requirements. In this work, we introduce a novel legal NLP task that involves generating clarification questions for contracts. These questions aim to identify contract ambigui
    
[^59]: 大城市偏见：评估都市规模对语言模型计算工作市场能力的影响

    Big City Bias: Evaluating the Impact of Metropolitan Size on Computational Job Market Abilities of Language Models

    [https://arxiv.org/abs/2403.08046](https://arxiv.org/abs/2403.08046)

    该研究评估了大型语言模型对美国384个都市地区的工作市场能力，发现都市规模越小，模型的表现越差。

    

    大型语言模型（LLMs）已经成为求职匹配的一项有用技术，对求职者和雇主都有帮助。求职匹配通常基于特定地理位置，比如城市或地区。然而，LLMs具有已知偏见，通常源自它们的训练数据。在这项工作中，我们旨在量化大型语言模型中编码的都市规模偏见，评估美国384个都市地区的零射击薪水、雇主存在和通勤时间预测。在所有基准测试中，我们观察到都市规模与LLMs性能之间存在负相关，表明较小地区的确受到低估。更具体地说，最小的10个都市地区的基准测试性能要比最大的10个都市地区低300%以上。

    arXiv:2403.08046v1 Announce Type: new  Abstract: Large language models (LLMs) have emerged as a useful technology for job matching, for both candidates and employers. Job matching is often based on a particular geographic location, such as a city or region. However, LLMs have known biases, commonly derived from their training data. In this work, we aim to quantify the metropolitan size bias encoded within large language models, evaluating zero-shot salary, employer presence, and commute duration predictions in 384 of the United States' metropolitan regions. Across all benchmarks, we observe negative correlations between the metropolitan size and the performance of the LLMS, indicating that smaller regions are indeed underrepresented. More concretely, the smallest 10 metropolitan regions show upwards of 300% worse benchmark performance than the largest 10.
    
[^60]: 基于策略优化的作者风格转移

    Authorship Style Transfer with Policy Optimization

    [https://arxiv.org/abs/2403.08043](https://arxiv.org/abs/2403.08043)

    提出了一种简单的两步调整和优化技术，用于低资源文本风格转移，在作者转移和母语风格任务方面均优于最先进的基准模型。

    

    作者风格转移的目标是将给定的文本重写成指定的目标，同时保留原始文本的含义。现有方法依赖于大量目标风格示例进行模型训练。然而，这些方法忽视了目标风格示例数量有限的情况。参数高效的迁移学习技术和策略优化方法的发展表明，轻量级的策略优化是一种可行的低资源风格转移方法。在这项工作中，我们提出了一个简单的两步调整和优化技术，用于低资源文本风格转移。我们将该技术应用于作者转移以及更大数据的母语风格任务，在两种情况下都发现它优于最先进的基准模型。

    arXiv:2403.08043v1 Announce Type: new  Abstract: Authorship style transfer aims to rewrite a given text into a specified target while preserving the original meaning in the source. Existing approaches rely on the availability of a large number of target style exemplars for model training. However, these overlook cases where a limited number of target style examples are available. The development of parameter-efficient transfer learning techniques and policy optimization (PO) approaches suggest lightweight PO is a feasible approach to low-resource style transfer. In this work, we propose a simple two step tune-and-optimize technique for low-resource textual style transfer. We apply our technique to authorship transfer as well as a larger-data native language style task and in both cases find it outperforms state-of-the-art baseline models.
    
[^61]: 利用人工智能打击网络仇恨：探讨大型语言模型在仇恨言论检测中的挑战和机遇

    Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection

    [https://arxiv.org/abs/2403.08035](https://arxiv.org/abs/2403.08035)

    该论文围绕大型语言模型（LLMs）在检测和分类令人憎恶或有毒内容方面的作用展开文献综述和实证分析，旨在揭示LLM在识别令人憎恶内容方面的能力及其影响因素。

    

    大型语言模型（LLMs）在许多不同的应用中表现出色，除了语言生成，还包括翻译、摘要和情感分析等。一个引人注目的应用是文本分类。在识别令人憎恶或有毒言论的领域中，这变得至关重要，这是一个充满挑战和伦理困境的领域。在我们的研究中，我们有两个目标：首先，提供一个围绕LLMs作为分类器的文献综述，强调它们在检测和分类令人憎恶或有毒内容方面的作用。随后，我们探究了几种LLMs在分类仇恨言论方面的效力：识别哪些LLMs在这一任务中表现出色以及它们的基本属性和训练。借此洞察促成LLM在识别令人憎恶内容方面的优劣性所依赖的因素。通过结合全面的文献回顾和实证分析，我们的论文旨在解开这些大型语言模型在辨别令人憎恶内容方面的能力。

    arXiv:2403.08035v1 Announce Type: cross  Abstract: Large language models (LLMs) excel in many diverse applications beyond language generation, e.g., translation, summarization, and sentiment analysis. One intriguing application is in text classification. This becomes pertinent in the realm of identifying hateful or toxic speech -- a domain fraught with challenges and ethical dilemmas. In our study, we have two objectives: firstly, to offer a literature review revolving around LLMs as classifiers, emphasizing their role in detecting and classifying hateful or toxic content. Subsequently, we explore the efficacy of several LLMs in classifying hate speech: identifying which LLMs excel in this task as well as their underlying attributes and training. Providing insight into the factors that contribute to an LLM proficiency (or lack thereof) in discerning hateful content. By combining a comprehensive literature review with an empirical analysis, our paper strives to shed light on the capabil
    
[^62]: 使用集成预测口语言识别的古吉拉特语-英语混合语音识别

    Gujarati-English Code-Switching Speech Recognition using ensemble prediction of spoken language

    [https://arxiv.org/abs/2403.08011](https://arxiv.org/abs/2403.08011)

    通过在输出中以每层有监督的方式对单词和字符的语言ID条件化变压器层，该方法虽然未能显著降低词错误率，但展现了在仅仅通过口语数据预测正确语言的潜力。

    

    混合语音识别中一个重要且困难的任务是识别语言，因为两种语言中的许多词在某些口音下听起来相似。我们专注于通过在输出中以每层有监督的方式对单词和字符的语言ID条件化变压器层，以改善端到端自动语音识别模型的性能。为此，我们提出了两种引入语言特定参数和可解释性到多头注意力机制的方法，并实施了一个有助于保持输入对齐连续性的时间损失。尽管无法显著降低词错误率（WER），我们的方法展现了在仅仅通过口语数据预测正确语言的潜力。我们通过在序列中删除LID引入了语言预测的正则化，有助于对齐长重复的输出序列。

    arXiv:2403.08011v1 Announce Type: cross  Abstract: An important and difficult task in code-switched speech recognition is to recognize the language, as lots of words in two languages can sound similar, especially in some accents. We focus on improving performance of end-to-end Automatic Speech Recognition models by conditioning transformer layers on language ID of words and character in the output in an per layer supervised manner. To this end, we propose two methods of introducing language specific parameters and explainability in the multi-head attention mechanism, and implement a Temporal Loss that helps maintain continuity in input alignment. Despite being unable to reduce WER significantly, our method shows promise in predicting the correct language from just spoken data. We introduce regularization in the language prediction by dropping LID in the sequence, which helps align long repeated output sequences.
    
[^63]: Debatrix:基于LLM的多维辩论评判系统与迭代时间序列分析

    Debatrix: Multi-dimensinal Debate Judge with Iterative Chronological Analysis Based on LLM

    [https://arxiv.org/abs/2403.08010](https://arxiv.org/abs/2403.08010)

    提出了Debatrix系统，利用LLMs进行多轮辩论的分析和评估，性能显著优于直接使用LLMs，实现了对整场辩论的评估。

    

    如何构建一个自动化辩论评判系统来评估一场广泛、充满活力的多轮辩论？这一任务具有挑战性，因为评判辩论涉及处理冗长文本、复杂的论点关系和多维度评估。当前的研究主要集中在短对话，很少涉及对整场辩论的评估。在本文中，通过利用大型语言模型（LLMs），我们提出了Debatrix，使得多轮辩论的分析和评估更符合大多数人的偏好。具体而言，Debatrix具有垂直的、迭代式的时间序列分析和水平的、多维度的评估协作。为了与现实世界的辩论场景保持一致，我们引入了PanelBench基准，将我们系统的性能与实际辩论结果进行比较。研究结果显示，相较于直接使用LLMs进行辩论评估，我们的系统表现出显著的增强效果。

    arXiv:2403.08010v1 Announce Type: new  Abstract: How can we construct an automated debate judge to evaluate an extensive, vibrant, multi-turn debate? This task is challenging, as judging a debate involves grappling with lengthy texts, intricate argument relationships, and multi-dimensional assessments. At the same time, current research mainly focuses on short dialogues, rarely touching upon the evaluation of an entire debate. In this paper, by leveraging Large Language Models (LLMs), we propose Debatrix, which makes the analysis and assessment of multi-turn debates more aligned with majority preferences. Specifically, Debatrix features a vertical, iterative chronological analysis and a horizontal, multi-dimensional evaluation collaboration. To align with real-world debate scenarios, we introduced the PanelBench benchmark, comparing our system's performance to actual debate outcomes. The findings indicate a notable enhancement over directly using LLMs for debate evaluation. Source code
    
[^64]: Pix2Pix-OnTheFly: 利用LLMs进行指导图像编辑

    Pix2Pix-OnTheFly: Leveraging LLMs for Instruction-Guided Image Editing

    [https://arxiv.org/abs/2403.08004](https://arxiv.org/abs/2403.08004)

    本文提出了一种新方法，实现了基于自然语言指令的图像编辑，在不需要任何预备工作的情况下，通过图像字幕和DDIM反演，获取编辑方向嵌入，进行指导图像编辑，表现出有效性和竞争力。

    

    众所周知，最近结合语言处理和图像处理的研究引起了广泛关注，本文提出了一种全新的方法，通过图像字幕和DDIM反演，获取编辑方向嵌入，进行指导图像编辑，而无需预备工作，证明了该方法的有效性和竞争力。

    arXiv:2403.08004v1 Announce Type: cross  Abstract: The combination of language processing and image processing keeps attracting increased interest given recent impressive advances that leverage the combined strengths of both domains of research. Among these advances, the task of editing an image on the basis solely of a natural language instruction stands out as a most challenging endeavour. While recent approaches for this task resort, in one way or other, to some form of preliminary preparation, training or fine-tuning, this paper explores a novel approach: We propose a preparation-free method that permits instruction-guided image editing on the fly. This approach is organized along three steps properly orchestrated that resort to image captioning and DDIM inversion, followed by obtaining the edit direction embedding, followed by image editing proper. While dispensing with preliminary preparation, our approach demonstrates to be effective and competitive, outperforming recent, state 
    
[^65]: 训练小型多模态模型以填补生物医学能力差距：以放射学成像为例

    Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging

    [https://arxiv.org/abs/2403.08002](https://arxiv.org/abs/2403.08002)

    本文针对生物医学应用中前沿模型尚存在的多模态能力差距，探讨了训练开源小型多模态模型以弥补临床需求的生物医学能力差距。

    

    放大基础模型的尺度规律和非凡表现激励了在生物医学领域开发和利用这些大型模型。然而，尽管在一些生物医学基准测试中取得了早期有希望的结果，但在这些模型能够应用于真实世界的应用之前仍然存在一些重大挑战。像GPT-4V这样的前沿模型在生物医学应用中仍存在重大的多模态能力差距。此外，访问、成本、延迟和合规等实际问题使临床医生难以直接在私人患者数据上使用私人托管的最先进大型模型。在本文中，我们探讨训练开源小型多模态模型（SMMs）来填补未满足的临床需求的生物医学能力差距。为了最大化数据效率，我们采用模块化方法，将用于图像和文本模态的最先进预训练模型纳入，并侧重于t

    arXiv:2403.08002v1 Announce Type: new  Abstract: The scaling laws and extraordinary performance of large foundation models motivate the development and utilization of such large models in biomedicine. However, despite early promising results on some biomedical benchmarks, there are still major challenges that need to be addressed before these models can be used in real-world applications. Frontier models such as GPT-4V still have major competency gaps in multimodal capabilities for biomedical applications. Moreover, pragmatic issues such as access, cost, latency, and compliance make it hard for clinicians to use privately-hosted state-of-the-art large models directly on private patient data. In this paper, we explore training open-source small multimodal models (SMMs) to bridge biomedical competency gaps for unmet clinical needs. To maximize data efficiency, we adopt a modular approach by incorporating state-of-the-art pre-trained models for image and text modalities, and focusing on t
    
[^66]: LiveCodeBench：用于代码的大型语言模型的全面和无污染评估

    LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code

    [https://arxiv.org/abs/2403.07974](https://arxiv.org/abs/2403.07974)

    LiveCodeBench提出了一个全面的、无污染的LLMs评估工具，聚焦于从LeetCode、AtCoder和CodeForces等平台连续收集的新问题，覆盖自修复、代码执行、测试输出预测等更广泛的代码相关能力。

    

    大型语言模型（LLMs）应用于与代码相关的应用程序已经成为一个突出的领域，吸引了学术界和工业界的极大兴趣。然而，随着新的和改进的LLMs的开发，现有的评估基准（例如HumanEval，MBPP）不再足以评估它们的能力。在这项工作中，我们提出LiveCodeBench，这是一个全面的、无污染的LLMs评估工具，用于代码，它会从三个竞赛平台（LeetCode、AtCoder和CodeForces）上连续地收集新问题。值得注意的是，我们的基准还着重关注更广泛的与代码相关的能力，如自修复、代码执行和测试输出预测，而不仅仅是代码生成。目前，LiveCodeBench托管了在2023年5月至2024年2月之间发布的400个高质量编码问题。我们已经评估了9个基本LLMs和20个指令调整的LLMs。

    arXiv:2403.07974v1 Announce Type: cross  Abstract: Large Language Models (LLMs) applied to code-related applications have emerged as a prominent field, attracting significant interest from both academia and industry. However, as new and improved LLMs are developed, existing evaluation benchmarks (e.g., HumanEval, MBPP) are no longer sufficient for assessing their capabilities. In this work, we propose LiveCodeBench, a comprehensive and contamination-free evaluation of LLMs for code, which continuously collects new problems over time from contests across three competition platforms, namely LeetCode, AtCoder, and CodeForces. Notably, our benchmark also focuses on a broader range of code related capabilities, such as self-repair, code execution, and test output prediction, beyond just code generation. Currently, LiveCodeBench hosts four hundred high-quality coding problems that were published between May 2023 and February 2024. We have evaluated 9 base LLMs and 20 instruction-tuned LLMs o
    
[^67]: 评估一种混合使用Sepedi-英语的自动语音识别系统

    The evaluation of a code-switched Sepedi-English automatic speech recognition system

    [https://arxiv.org/abs/2403.07947](https://arxiv.org/abs/2403.07947)

    评估了一种混合使用Sepedi-英语的自动语音识别系统，探讨了端到端方法在低资源语言中的有效性。

    

    arXiv:2403.07947v1 发表类型: 跨领域  摘要: 语音技术是一个涵盖各种技术和工具的领域，用于使设备能够与语音进行交互，例如自动语音识别（ASR）、口语对话系统等，允许设备通过麦克风从说话者那里捕获说话的话语。端到端方法，如连接主义时间分类（CTC）和基于注意力的方法是开发ASR系统中使用最广泛的方法。然而，这些技术通常用于对具有大量语音数据进行训练和评估的高资源语言进行研究和开发，导致低资源语言相对较少发展。尽管CTC方法在其他语言中已成功使用，但它在Sepedi语言中的有效性仍存在不确定性。在这项研究中，我们介绍了混合使用Sepedi-英语的自动语音识别系统的评估。

    arXiv:2403.07947v1 Announce Type: cross  Abstract: Speech technology is a field that encompasses various techniques and tools used to enable machines to interact with speech, such as automatic speech recognition (ASR), spoken dialog systems, and others, allowing a device to capture spoken words through a microphone from a human speaker. End-to-end approaches such as Connectionist Temporal Classification (CTC) and attention-based methods are the most used for the development of ASR systems. However, these techniques were commonly used for research and development for many high-resourced languages with large amounts of speech data for training and evaluation, leaving low-resource languages relatively underdeveloped. While the CTC method has been successfully used for other languages, its effectiveness for the Sepedi language remains uncertain. In this study, we present the evaluation of the Sepedi-English code-switched automatic speech recognition system. This end-to-end system was devel
    
[^68]: 语音鲁棒基准：用于语音识别的鲁棒性基准

    Speech Robust Bench: A Robustness Benchmark For Speech Recognition

    [https://arxiv.org/abs/2403.07937](https://arxiv.org/abs/2403.07937)

    提出了一个全面基准（SRB），用于评估自动语音识别（ASR）模型对各种破坏的鲁棒性，发现模型大小和某些建模选择有助于提高鲁棒性，并观察到在不同人口亚组上模型的鲁棒性存在明显差异。

    

    随着自动语音识别（ASR）模型变得越来越普遍，确保它们在物理世界和数字世界中的各种破坏下进行可靠预测变得愈发重要。我们提出了语音鲁棒基准（SRB），这是一个用于评估ASR模型对各种破坏的鲁棒性的全面基准。SRB由69个输入扰动组成，旨在模拟ASR模型可能在物理世界和数字世界中遇到的各种破坏。我们使用SRB来评估几种最先进的ASR模型的鲁棒性，并观察到模型大小和某些建模选择（如离散表示和自我训练）似乎有助于提高鲁棒性。我们将此分析扩展到衡量ASR模型在来自各种人口亚组的数据上的鲁棒性，即英语和西班牙语使用者以及男性和女性，并观察到模型的鲁棒性在不同亚组之间存在明显差异。

    arXiv:2403.07937v1 Announce Type: cross  Abstract: As Automatic Speech Recognition (ASR) models become ever more pervasive, it is important to ensure that they make reliable predictions under corruptions present in the physical and digital world. We propose Speech Robust Bench (SRB), a comprehensive benchmark for evaluating the robustness of ASR models to diverse corruptions. SRB is composed of 69 input perturbations which are intended to simulate various corruptions that ASR models may encounter in the physical and digital world. We use SRB to evaluate the robustness of several state-of-the-art ASR models and observe that model size and certain modeling choices such as discrete representations, and self-training appear to be conducive to robustness. We extend this analysis to measure the robustness of ASR models on data from various demographic subgroups, namely English and Spanish speakers, and males and females, and observed noticeable disparities in the model's robustness across su
    
[^69]: Merino：基于熵驱动的IoT设备上生成式语言模型设计

    Merino: Entropy-driven Design for Generative Language Models on IoT Devices

    [https://arxiv.org/abs/2403.07921](https://arxiv.org/abs/2403.07921)

    在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型，通过最大化transformer解码器的熵来在计算预算内，成功设计了MeRino模型，在移动设置下展现出与当前最先进的自回归transformer模型竞争性能的特点

    

    大规模生成式语言模型（LLMs）作为人工智能现代时代的革命性进步，然而，直接部署LLMs在资源受限的硬件上，比如物联网（IoT）设备，由于其高计算成本而变得困难。在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型。我们的主要设计范式是在给定的计算预算内最大化transformer解码器的熵。整个设计过程涉及解决一个数学规划（MP）问题，可以在几分钟内在CPU上完成，使其几乎是零成本的。我们评估了我们设计的模型MeRino，在九个NLP下游任务上展示了它们在移动设置下对抗当前最先进的自回归transformer模型的竞争性表现。值得注意的是，MeRino在移动设置下获得了类似或更好的零性能表现

    arXiv:2403.07921v1 Announce Type: cross  Abstract: Generative Large Language Models (LLMs) stand as a revolutionary advancement in the modern era of artificial intelligence (AI). However, directly deploying LLMs in resource-constrained hardware, such as Internet-of-Things (IoT) devices, is difficult due to their high computational cost. In this paper, we propose a novel information-entropy framework for designing mobile-friendly generative language models. Our key design paradigm is to maximize the entropy of transformer decoders within the given computational budgets. The whole design procedure involves solving a mathematical programming (MP) problem, which can be done on the CPU within minutes, making it nearly zero-cost. We evaluate our designed models, termed MeRino, across nine NLP downstream tasks, showing their competitive performance against the state-of-the-art autoregressive transformer models under the mobile setting. Notably, MeRino achieves similar or better zero performan
    
[^70]: ProtLLM：一种具有蛋白质作为单词预训练的交织式蛋白质-语言LLM

    ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training

    [https://arxiv.org/abs/2403.07920](https://arxiv.org/abs/2403.07920)

    提出了ProtLLM，一种具有独特动态蛋白质装配机制及蛋白质作为单词语言建模方法的交织式蛋白质-语言LLM，并构建了大规模的交织式蛋白质-文本数据集用于预训练。

    

    我们提出了ProtLLM，一种多功能的跨模式大型语言模型（LLM），用于处理既有蛋白质为中心又有蛋白质-语言任务。ProtLLM具有独特的动态蛋白质装配机制，使其能够处理自然语言文本与任意数量的蛋白质交织在一起的复杂输入。此外，我们提出了蛋白质作为单词语言建模方法来训练ProtLLM。通过开发专门的蛋白质词汇表，我们赋予该模型不仅预测自然语言而且预测来自大量候选蛋白质的能力。此外，我们构建了一个大规模的交织式蛋白质-文本数据集，命名为InterPT，用于预训练。该数据集全面涵盖了结构化数据源（如蛋白质注释）和非结构化数据源（如生物研究论文），从而赋予ProtLLM理解蛋白质的关键知识。我们在经典数据集上对ProtLLM进行了评估。

    arXiv:2403.07920v1 Announce Type: cross  Abstract: We propose ProtLLM, a versatile cross-modal large language model (LLM) for both protein-centric and protein-language tasks. ProtLLM features a unique dynamic protein mounting mechanism, enabling it to handle complex inputs where the natural language text is interspersed with an arbitrary number of proteins. Besides, we propose the protein-as-word language modeling approach to train ProtLLM. By developing a specialized protein vocabulary, we equip the model with the capability to predict not just natural language but also proteins from a vast pool of candidates. Additionally, we construct a large-scale interleaved protein-text dataset, named InterPT, for pre-training. This dataset comprehensively encompasses both (1) structured data sources like protein annotations and (2) unstructured data sources like biological research papers, thereby endowing ProtLLM with crucial knowledge for understanding proteins. We evaluate ProtLLM on classic 
    
[^71]: 多任务媒体偏见分析通用化的预训练表达识别

    Multi-Task Media-Bias Analysis Generalization for Pre-Trained Identification of Expressions

    [https://arxiv.org/abs/2403.07910](https://arxiv.org/abs/2403.07910)

    MAGPIE是第一个为媒体偏见检测定制的大规模多任务预训练方法，在媒体偏见检测方面表现优异，并且相对于单一任务方法需要更少的微调步骤。

    

    媒体偏见检测是一个复杂的、多方面的问题，传统上通过使用单一任务模型和小型领域内数据集来解决，因此缺乏泛化能力。为了解决这一问题，我们介绍了MAGPIE，这是第一个专门为媒体偏见检测定制的大规模多任务预训练方法。为了实现规模化的预训练，我们提出了大偏见混合（LBM），这是一个包含59个与偏见相关的任务的编译。MAGPIE在Bias Annotation By Experts (BABE)数据集上的媒体偏见检测方面优于先前的方法，F1分数相对提高了3.3%。MAGPIE在Media Bias Identification Benchmark (MBIB)中的8个任务中有5个方面表现优于先前的模型。使用RoBERTa编码器，MAGPIE仅需要相对于单一任务方法的15%的微调步骤。我们的评估表明，比如任务如情感和情绪会增强所有学习，所有任务会增强假新闻检测，

    arXiv:2403.07910v1 Announce Type: cross  Abstract: Media bias detection poses a complex, multifaceted problem traditionally tackled using single-task models and small in-domain datasets, consequently lacking generalizability. To address this, we introduce MAGPIE, the first large-scale multi-task pre-training approach explicitly tailored for media bias detection. To enable pre-training at scale, we present Large Bias Mixture (LBM), a compilation of 59 bias-related tasks. MAGPIE outperforms previous approaches in media bias detection on the Bias Annotation By Experts (BABE) dataset, with a relative improvement of 3.3% F1-score. MAGPIE also performs better than previous models on 5 out of 8 tasks in the Media Bias Identification Benchmark (MBIB). Using a RoBERTa encoder, MAGPIE needs only 15% of finetuning steps compared to single-task approaches. Our evaluation shows, for instance, that tasks like sentiment and emotionality boost all learning, all tasks enhance fake news detection, and s
    
[^72]: 超越死记硬背：语言模型中的随机内存访问挑战

    Beyond Memorization: The Challenge of Random Memory Access in Language Models

    [https://arxiv.org/abs/2403.07805](https://arxiv.org/abs/2403.07805)

    本文研究了语言模型在访问内存时的挑战，发现通过背诵和置换等技术可以改善语言模型的随机内存访问能力，从而在开放域问题回答任务中取得显著改进。

    

    最近语言模型(LMs)的发展展示了它们在NLP任务中的有效性，尤其是在知识密集型任务中。然而，在其参数内部的知识存储和内存访问机制仍然令人费解。本文探讨了生成式语言模型（如GPT-2）是否能够顺序或随机地访问其内存。通过精心设计的合成任务，涵盖全面背诵、选择性背诵和基于问题回答的情景，我们揭示了LMs能够顺序访问其内存，同时在随机访问已记忆内容时遇到挑战。我们发现，通过背诵和置换等技术可以提高LMs的随机内存访问能力。此外，通过将这种干预应用于开放域问题回答的现实场景，我们验证了通过背诵来增强随机访问技术对问题回答能力的显著改进。

    arXiv:2403.07805v1 Announce Type: cross  Abstract: Recent developments in Language Models (LMs) have shown their effectiveness in NLP tasks, particularly in knowledge-intensive tasks. However, the mechanisms underlying knowledge storage and memory access within their parameters remain elusive. In this paper, we investigate whether a generative LM (e.g., GPT-2) is able to access its memory sequentially or randomly. Through carefully-designed synthetic tasks, covering the scenarios of full recitation, selective recitation and grounded question answering, we reveal that LMs manage to sequentially access their memory while encountering challenges in randomly accessing memorized content. We find that techniques including recitation and permutation improve the random memory access capability of LMs. Furthermore, by applying this intervention to realistic scenarios of open-domain question answering, we validate that enhancing random access by recitation leads to notable improvements in questi
    
[^73]: StableToolBench：面向大规模稳定基准测试的工具学习大语言模型

    StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models

    [https://arxiv.org/abs/2403.07714](https://arxiv.org/abs/2403.07714)

    StableToolBench提出了一种虚拟API服务器和稳定评估系统，通过缓存系统、API模拟器和稳定评估设计，解决了大语言模型利用外部工具的稳定大规模基准测试问题。

    

    大语言模型（LLMs）近年来取得了显著进展，促使人们探索工具学习，将LLMs与外部工具整合以解决各种现实挑战。评估LLMs利用工具的能力需要大规模且稳定的基准测试。我们介绍了由ToolBench演变而来的StableToolBench，提出了一个虚拟API服务器和稳定评估系统。虚拟API服务器包含缓存系统和API模拟器，互补减轻API状态变化。同时，稳定的评估系统使用GPT-4作为自动评估器设计可解决的通过率和胜率，以消除评估过程中的随机性。实验结果证明

    arXiv:2403.07714v1 Announce Type: new  Abstract: Large Language Models (LLMs) have witnessed remarkable advancements in recent years, prompting the exploration of tool learning, which integrates LLMs with external tools to address diverse real-world challenges. Assessing the capability of LLMs to utilise tools necessitates large-scale and stable benchmarks. However, previous works relied on either hand-crafted online tools with limited scale, or large-scale real online APIs suffering from instability of API status. To address this problem, we introduce StableToolBench, a benchmark evolving from ToolBench, proposing a virtual API server and stable evaluation system. The virtual API server contains a caching system and API simulators which are complementary to alleviate the change in API status. Meanwhile, the stable evaluation system designs solvable pass and win rates using GPT-4 as the automatic evaluator to eliminate the randomness during evaluation. Experimental results demonstrate 
    
[^74]: 从英语到ASIC：大型语言模型的硬件实现

    From English to ASIC: Hardware Implementation with Large Language Model

    [https://arxiv.org/abs/2403.07039](https://arxiv.org/abs/2403.07039)

    大型语言模型的快速发展改变了ASIC工程领域，但现代语言模型在生成硬件描述代码方面性能不佳，研究重点在于通过微调自然语言模型和重组HDL代码数据集来提高精度和准确性。

    

    在ASIC工程领域，随着大型语言模型的快速发展，现代数字电路的复杂性也在增加，这加剧了对HDL编码的要求，需要更高的精度和复杂性。然而，由于现代语言模型在生成硬件描述代码方面性能不佳，加之相应高质量的代码数据集稀缺，挑战不断。这些挑战凸显了LLM潜力革新数字电路设计与当前能力准确解释和实施硬件规范之间的差距。为了解决这些挑战，制定了一种专注于领先自然语言模型微调和HDL代码数据集重组的策略。

    arXiv:2403.07039v1 Announce Type: cross  Abstract: In the realm of ASIC engineering, the landscape has been significantly reshaped by the rapid development of LLM, paralleled by an increase in the complexity of modern digital circuits. This complexity has escalated the requirements for HDL coding, necessitating a higher degree of precision and sophistication. However, challenges have been faced due to the less-than-optimal performance of modern language models in generating hardware description code, a situation further exacerbated by the scarcity of the corresponding high-quality code datasets. These challenges have highlighted the gap between the potential of LLMs to revolutionize digital circuit design and their current capabilities in accurately interpreting and implementing hardware specifications. To address these challenges, a strategy focusing on the fine-tuning of the leading-edge nature language model and the reshuffling of the HDL code dataset has been developed. The fine-tu
    
[^75]: 人类和语言大型语言模型中的视觉对象命名、描述和量化

    Naming, Describing, and Quantifying Visual Objects in Humans and LLMs

    [https://arxiv.org/abs/2403.06935](https://arxiv.org/abs/2403.06935)

    评估了当前视觉与语言大语言模型在人类在可能标签的分布上显示出极大主观变异性的情况下，对视觉对象的命名、描述和量化的能力

    

    人类讲话者在描述图像中的同一对象时使用各种不同的表达方式，这产生了由语用约束驱动的合理标签分布，当前视觉与语言大语言模型（VLLMs）能够模仿语言使用中这一关键特征的程度尚不明确。我们评估了VLLMs（FROMAGe、BLIP-2、LLaVA）在人类在可能标签的分布上显示出极大主观变异性的三个类别（名词、属性和量词）上的性能。

    arXiv:2403.06935v1 Announce Type: new  Abstract: While human speakers use a variety of different expressions when describing the same object in an image, giving rise to a distribution of plausible labels driven by pragmatic constraints, the extent to which current Vision \& Language Large Language Models (VLLMs) can mimic this crucial feature of language use is an open question. This applies to common, everyday objects, but it is particularly interesting for uncommon or novel objects for which a category label may be lacking or fuzzy. Furthermore, humans show clear production preferences for highly context-sensitive expressions, such as the quantifiers `few' or `most'. In our work, we evaluate VLLMs (FROMAGe, BLIP-2, LLaVA) on three categories (nouns, attributes, and quantifiers) where humans show great subjective variability concerning the distribution over plausible labels, using datasets and resources mostly under-explored in previous work. Our results reveal mixed evidence on the a
    
[^76]: 使用语音活动投影进行多语言交替预测

    Multilingual Turn-taking Prediction Using Voice Activity Projection

    [https://arxiv.org/abs/2403.06487](https://arxiv.org/abs/2403.06487)

    本文研究了在口头对话中使用语音活动投影进行多语言交替预测，在多语言数据上训练的多语言模型展示出与单一语言模型相当的预测性能，并且学会了辨别输入信号的语言。

    

    本文研究了在多语言数据上应用语音活动投影（VAP），这是一种用于口头对话的预测性交替模型，涵盖英语、汉语和日语。VAP模型持续预测双人对话中参与者即将发生的语音活动，利用交叉注意力Transformer捕捉参与者之间的动态互动。结果表明，在单一语言上训练的VAP模型在其他语言上的应用不会产生很好的预测。然而，在三种语言上训练的多语言模型，在所有语言上表现出与单语模型相当的预测性能。进一步的分析表明，多语言模型已学会辨别输入信号的语言。我们还分析了对音调敏感性，这是一种被认为对于交替非常重要的韵律线索。最后，我们比较了两种不同的音频编码器。

    arXiv:2403.06487v1 Announce Type: new  Abstract: This paper investigates the application of voice activity projection (VAP), a predictive turn-taking model for spoken dialogue, on multilingual data, encompassing English, Mandarin, and Japanese. The VAP model continuously predicts the upcoming voice activities of participants in dyadic dialogue, leveraging a cross-attention Transformer to capture the dynamic interplay between participants. The results show that a monolingual VAP model trained on one language does not make good predictions when applied to other languages. However, a multilingual model, trained on all three languages, demonstrates predictive performance on par with monolingual models across all languages. Further analyses show that the multilingual model has learned to discern the language of the input signal. We also analyze the sensitivity to pitch, a prosodic cue that is thought to be important for turn-taking. Finally, we compare two different audio encoders, contrast
    
[^77]: 通过小语言模型全面改造多模态助手

    A Comprehensive Overhaul of Multimodal Assistant with Small Language Models

    [https://arxiv.org/abs/2403.06199](https://arxiv.org/abs/2403.06199)

    通过设计多模态小语言模型(MSLMs)及提出高效多模态助手Mipha，实现了在多个方面的协同作用，击败了大语言模型，为开发强大MSLMs提供了见解和指南

    

    多模态大语言模型(MLLMs)展示了在与视觉理解和推理相关的任务中令人印象深刻的技能。然而，由于培训和推理阶段的高计算需求，它们的广泛应用面临障碍，限制了它们在研究和用户社区中受众的范围。在本文中，我们研究了多模态小语言模型（MSLMs）的设计方面，并提出了一种名为Mipha的高效多模态助手，旨在在多个方面之间创造协同作用：视觉表示、语言模型和优化策略。我们表明，在不增加训练数据量的情况下，我们的Mipha-3B在多个基准测试中胜过了最先进的大型MLLMs，特别是LLaVA-1.5-13B。通过详细讨论，我们提供了发展强大的MSLMs的见解和指南，使其能够与MLLMs的能力相媲美。我们的代码可以获得。

    arXiv:2403.06199v1 Announce Type: cross  Abstract: Multimodal Large Language Models (MLLMs) have showcased impressive skills in tasks related to visual understanding and reasoning. Yet, their widespread application faces obstacles due to the high computational demands during both the training and inference phases, restricting their use to a limited audience within the research and user communities. In this paper, we investigate the design aspects of Multimodal Small Language Models (MSLMs) and propose an efficient multimodal assistant named Mipha, which is designed to create synergy among various aspects: visual representation, language models, and optimization strategies. We show that without increasing the volume of training data, our Mipha-3B outperforms the state-of-the-art large MLLMs, especially LLaVA-1.5-13B, on multiple benchmarks. Through detailed discussion, we provide insights and guidelines for developing strong MSLMs that rival the capabilities of MLLMs. Our code is availa
    
[^78]: 为报告生成调优心电图指导

    Electrocardiogram Instruction Tuning for Report Generation

    [https://arxiv.org/abs/2403.04945](https://arxiv.org/abs/2403.04945)

    提出了Multimodal ECG Instruction Tuning（MEIT）框架，首次尝试使用LLMs和多模态指导解决ECG报告生成问题，并在两个大规模ECG数据集上进行了广泛的实验评估其优越性。

    

    心电图（ECG）作为心脏病情监测的主要非侵入性诊断工具，对于协助临床医生至关重要。最近的研究集中在使用ECG数据对心脏病情进行分类，但忽略了ECG报告生成，这不仅耗时，而且需要临床专业知识。为了自动化ECG报告生成并确保其多功能性，我们提出了Multimodal ECG Instruction Tuning（MEIT）框架，这是\textit{首次}尝试使用LLMs和多模态指导来解决ECG报告生成问题。为了促进未来的研究，我们建立了一个基准来评估MEIT在两个大规模ECG数据集上使用各种LLM骨干的表现。我们的方法独特地对齐了ECG信号和报告的表示，并进行了大量实验来评估MEIT与九个开源LLMs，使用了超过80万个ECG报告。MEIT的结果凸显了其优越性。

    arXiv:2403.04945v1 Announce Type: new  Abstract: Electrocardiogram (ECG) serves as the primary non-invasive diagnostic tool for cardiac conditions monitoring, are crucial in assisting clinicians. Recent studies have concentrated on classifying cardiac conditions using ECG data but have overlooked ECG report generation, which is not only time-consuming but also requires clinical expertise. To automate ECG report generation and ensure its versatility, we propose the Multimodal ECG Instruction Tuning (MEIT) framework, the \textit{first} attempt to tackle ECG report generation with LLMs and multimodal instructions. To facilitate future research, we establish a benchmark to evaluate MEIT with various LLMs backbones across two large-scale ECG datasets. Our approach uniquely aligns the representations of the ECG signal and the report, and we conduct extensive experiments to benchmark MEIT with nine open source LLMs, using more than 800,000 ECG reports. MEIT's results underscore the superior p
    
[^79]: MuseGraph：面向大型语言模型的图导向指令调整用于通用图挖掘

    MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining

    [https://arxiv.org/abs/2403.04780](https://arxiv.org/abs/2403.04780)

    MuseGraph将GNNs和LLMs的优势结合起来，提出了一种更有效和通用的图挖掘方法，可以跨不同任务和数据集使用

    

    具有丰富属性的图在建模互联实体和改进各种实际应用中的预测方面至关重要。传统图神经网络（GNNs）通常用于建模带属性的图，但需要在应用于不同图任务和数据集时进行重新训练。尽管大型语言模型（LLMs）的出现在自然语言处理中引入了新的范例，但LLMs在图挖掘中的生成潜力仍未得到充分探索。为此，我们提出了一个新颖的框架 MuseGraph，它无缝整合了GNNs和LLMs的优势，并促进了一种更有效和通用的图挖掘方法，可跨不同任务和数据集使用。具体而言，我们首先通过提出的自适应输入生成引入一个紧凑的图描述，以在语言令牌限制的约束下封装来自图的关键信息。

    arXiv:2403.04780v1 Announce Type: cross  Abstract: Graphs with abundant attributes are essential in modeling interconnected entities and improving predictions in various real-world applications. Traditional Graph Neural Networks (GNNs), which are commonly used for modeling attributed graphs, need to be re-trained every time when applied to different graph tasks and datasets. Although the emergence of Large Language Models (LLMs) has introduced a new paradigm in natural language processing, the generative potential of LLMs in graph mining remains largely under-explored. To this end, we propose a novel framework MuseGraph, which seamlessly integrates the strengths of GNNs and LLMs and facilitates a more effective and generic approach for graph mining across different tasks and datasets. Specifically, we first introduce a compact graph description via the proposed adaptive input generation to encapsulate key information from the graph under the constraints of language token limitations. T
    
[^80]: 自发性言语中的非言语信息 - 朝着新的分析框架

    Non-verbal information in spontaneous speech - towards a new framework of analysis

    [https://arxiv.org/abs/2403.03522](https://arxiv.org/abs/2403.03522)

    这项研究提出了一个分析框架和技术验证概念，用于对言语中的非言语信号进行分类，并将其与含义关联起来，从而为探索表达实现多层韵律事件的大型数据提供了一种方法。

    

    言语中的非言语信号是由韵律编码的，携带的信息范围从对话行为到态度和情感。尽管其重要性，掌握掌声结构的原则仍未得到充分理解。本文提出了一个分析框架和技术验证概念，用于对韵律信号进行分类，并将其与含义关联起来。该框架解释了多层韵律事件的表层表示。作为实施的第一步，我们提出了一个分类过程，可以解开三个级别的韵律现象。它依赖于微调预训练的语音识别模型，实现同时的多类别/多标签检测。它可以概括各种各样的自发数据，在与人类注释相当或优于的情况下执行。除了对韵律的标准化形式化外，解开韵律模式还可以指导

    arXiv:2403.03522v1 Announce Type: cross  Abstract: Non-verbal signals in speech are encoded by prosody and carry information that ranges from conversation action to attitude and emotion. Despite its importance, the principles that govern prosodic structure are not yet adequately understood. This paper offers an analytical schema and a technological proof-of-concept for the categorization of prosodic signals and their association with meaning. The schema interprets surface-representations of multi-layered prosodic events. As a first step towards implementation, we present a classification process that disentangles prosodic phenomena of three orders. It relies on fine-tuning a pre-trained speech recognition model, enabling the simultaneous multi-class/multi-label detection. It generalizes over a large variety of spontaneous data, performing on a par with, or superior to, human annotation. In addition to a standardized formalization of prosody, disentangling prosodic patterns can direct a
    
[^81]: 在回答和解释具有挑战性的医学问题上对大型语言模型的基准测试

    Benchmarking Large Language Models on Answering and Explaining Challenging Medical Questions

    [https://arxiv.org/abs/2402.18060](https://arxiv.org/abs/2402.18060)

    在回答医学问题方面，大型语言模型在处理具有挑战性的实际临床案例上的表现是关键，因此构建了两个结构化数据集进行评估。

    

    LLMs在回答医学问题方面表现出色，例如通过医学执照考试。然而，大多数现有的基准测试依赖于委员会考试问题或一般医学问题，无法捕捉真实临床案例的复杂性。此外，缺乏答案的参考解释阻碍了对模型解释的评估，这对支持医生做出复杂的医疗决策至关重要。为解决这些挑战，我们构建了两个新数据集：JAMA临床挑战和Medbullets。JAMA临床挑战包含基于具有挑战性的临床案例的问题，而Medbullets包含类似USMLE Step 2&3风格的临床问题。两个数据集均以多项选择问题-回答任务的结构化形式呈现，每个问题都附有专家撰写的解释。我们使用各种提示在这两个数据集上评估了四个LLMs。实验表明

    arXiv:2402.18060v1 Announce Type: new  Abstract: LLMs have demonstrated impressive performance in answering medical questions, such as passing medical licensing examinations. However, most existing benchmarks rely on board exam questions or general medical questions, falling short in capturing the complexity of realistic clinical cases. Moreover, the lack of reference explanations for answers hampers the evaluation of model explanations, which are crucial to supporting doctors in making complex medical decisions. To address these challenges, we construct two new datasets: JAMA Clinical Challenge and Medbullets. JAMA Clinical Challenge consists of questions based on challenging clinical cases, while Medbullets comprises USMLE Step 2&3 style clinical questions. Both datasets are structured as multiple-choice question-answering tasks, where each question is accompanied by an expert-written explanation. We evaluate four LLMs on the two datasets using various prompts. Experiments demonstrat
    
[^82]: TOOLVERIFIER: 通过自验证实现对新工具的泛化

    TOOLVERIFIER: Generalization to New Tools via Self-Verification

    [https://arxiv.org/abs/2402.14158](https://arxiv.org/abs/2402.14158)

    通过自验证方法，本研究提出了一种区分新工具的方法，通过对比性自问问题来实现工具选择和参数生成，进一步提升了语言模型对新工具的学习能力。

    

    将语言模型教会如何使用工具是迈向构建通用助手的重要里程碑，但仍然是一个未解之谜。虽然在针对特定工具的微调方面取得了显著进展，但语言模型仍然在如何从仅有少数示例中强大地使用新工具方面遇到困难。在这项工作中，我们引入了一种自验证方法，通过在工具选择和参数生成过程中进行对比性自问问题来区分近似的候选工具。我们利用Llama-2 70B构建了合成的高质量自生成数据，用于实现这一目标，我们打算将其公开发布。在ToolBench基准测试中的4项任务上进行了大量实验，包括17个未见过的工具，展示了在少样本基线测试中平均提升了22%，即使在候选工具之间的区别微妙之处的情况下也是如此。

    arXiv:2402.14158v1 Announce Type: new  Abstract: Teaching language models to use tools is an important milestone towards building general assistants, but remains an open problem. While there has been significant progress on learning to use specific tools via fine-tuning, language models still struggle with learning how to robustly use new tools from only a few demonstrations. In this work we introduce a self-verification method which distinguishes between close candidates by self-asking contrastive questions during (1) tool selection; and (2) parameter generation. We construct synthetic, high-quality, self-generated data for this goal using Llama-2 70B, which we intend to release publicly. Extensive experiments on 4 tasks from the ToolBench benchmark, consisting of 17 unseen tools, demonstrate an average improvement of 22% over few-shot baselines, even in scenarios where the distinctions between candidate tools are finely nuanced.
    
[^83]: 一个统一的基于分类学指导的实体集扩展和分类学扩展的指导调整框架

    A Unified Taxonomy-Guided Instruction Tuning Framework for Entity Set Expansion and Taxonomy Expansion

    [https://arxiv.org/abs/2402.13405](https://arxiv.org/abs/2402.13405)

    通过统一的基于分类学指导的指导调整框架，本文提出了一种利用现有分类学进行实体关系微调的方法，有效解决实体集扩展、分类学扩展和种子引导分类学构建三个任务。

    

    实体集扩展、分类学扩展和种子引导分类学构建是三个代表性任务，可以用来自动向现有分类学填充新实体。然而，先前的方法通常使用异质技术分别解决这些任务，缺乏统一的视角。为了解决这个问题，在本文中，我们从分类学结构的视角确认了这些任务所需的共同关键技能——找到“兄弟”和找到“父母”，并提出了一个统一的基于分类学指导的指导调整框架来共同解决这三个任务。具体来说，通过利用现有分类学作为丰富的实体关系源，我们利用指导调整来微调大型语言模型，生成父母和兄弟实体。在多个基准数据集上的大量实验证明了TaxoInstruct的有效性，该方法在各项指标上均优于特定任务的基线方法。

    arXiv:2402.13405v1 Announce Type: new  Abstract: Entity Set Expansion, Taxonomy Expansion, and Seed-Guided Taxonomy Construction are three representative tasks that can be used to automatically populate an existing taxonomy with new entities. However, previous approaches often address these tasks separately with heterogeneous techniques, lacking a unified perspective. To tackle this issue, in this paper, we identify the common key skills needed for these tasks from the view of taxonomy structures -- finding 'siblings' and finding 'parents' -- and propose a unified taxonomy-guided instruction tuning framework to jointly solve the three tasks. To be specific, by leveraging the existing taxonomy as a rich source of entity relationships, we utilize instruction tuning to fine-tune a large language model to generate parent and sibling entities. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of TaxoInstruct, which outperforms task-specific baselines across 
    
[^84]: LongAgent: 通过多智能体协作将语言模型扩展到128K上下文

    LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration

    [https://arxiv.org/abs/2402.11550](https://arxiv.org/abs/2402.11550)

    LongAgent通过多智能体协作将语言模型扩展到128K上下文，并在长文本处理方面表现出潜在的优越性。

    

    大型语言模型（LLMs）在理解语言和执行复杂推理任务方面表现出色。然而，具有长上下文窗口的LLMs以其昂贵的训练成本和高推理延迟而臭名昭著。即使是最先进的模型如GPT-4和Claude2在处理超过$100k$标记的输入时也经常出错，这种现象也被称为\textit{中间迷失}。在本文中，我们提出了基于多智能体协作的方法\textsc{LongAgent}，将LLMs（例如LLaMA）扩展到128K上下文，并展示出在长文本处理方面可能优于GPT-4的潜力。在\textsc{LongAgent}中，一位领导者负责理解用户意图并指导团队成员从文档中获取信息。由于成员存在幻觉，领导者从几十到数百名成员的回应中获取准确信息并非易事。

    arXiv:2402.11550v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated impressive performance in understanding language and executing complex reasoning tasks. However, LLMs with long context windows have been notorious for their expensive training costs and high inference latency. Even the most advanced models such as GPT-4 and Claude2 often make mistakes when processing inputs of over $100k$ tokens, a phenomenon also known as \textit{lost in the middle}. In this paper, we propose \textsc{LongAgent}, a method based on multi-agent collaboration, which scales LLMs (e.g., LLaMA) to a context of 128K and demonstrates potential superiority in long-text processing compared to GPT-4. In \textsc{LongAgent}, a leader is responsible for understanding user intent and directing team members to acquire information from documents. Due to members' hallucinations, it is non-trivial for a leader to obtain accurate information from the responses of dozens to hundreds of member
    
[^85]: 揭示引人入胜对话的秘密：让用户沉迷于角色扮演对话代理的因素

    Unveiling the Secrets of Engaging Conversations: Factors that Keep Users Hooked on Role-Playing Dialog Agents

    [https://arxiv.org/abs/2402.11522](https://arxiv.org/abs/2402.11522)

    机器人体现其扮演角色的程度对保留率的影响有限，而其讲话的每个轮次的长度显著影响保留率

    

    随着对话代理变得越来越类人化，人们现在正在进行持续对话，可以从短暂的时刻延伸到长时间。理解促使这些互动持续的因素至关重要，然而现有研究主要集中在很少探索这种长时间和真实对话的短期模拟。在本文中，我们研究了影响角色扮演模型与真实用户之间互动中保留率的因素。通过分析真实用户和数千个角色之间的大型数据集，我们系统地检查了多个因素，并评估了它们对用户保留率的影响。令人惊讶的是，我们发现机器人体现其扮演角色的程度对保留率的影响有限，而其讲话的每个轮次的长度显著影响保留率。这项研究揭示了用户参与度的关键方面。

    arXiv:2402.11522v1 Announce Type: new  Abstract: With the growing humanlike nature of dialog agents, people are now engaging in extended conversations that can stretch from brief moments to substantial periods of time. Understanding the factors that contribute to sustaining these interactions is crucial, yet existing studies primarily focusing on short-term simulations that rarely explore such prolonged and real conversations.   In this paper, we investigate the factors influencing retention rates in real interactions with roleplaying models. By analyzing a large dataset of interactions between real users and thousands of characters, we systematically examine multiple factors and assess their impact on user retention rate. Surprisingly, we find that the degree to which the bot embodies the roles it plays has limited influence on retention rates, while the length of each turn it speaks significantly affects retention rates. This study sheds light on the critical aspects of user engageme
    
[^86]: 多个LLM之间的网络形成与动态

    Network Formation and Dynamics Among Multi-LLMs

    [https://arxiv.org/abs/2402.10659](https://arxiv.org/abs/2402.10659)

    分析了多个LLM在社交网络中的行为，发现它们在给定网络结构并被询问形成网络偏好时表现出与人类社交动态一致的原则。

    

    社交网络影响行为、偏好和关系，在人类社会中对信息和规范的传播起着至关重要的作用。随着大型语言模型（LLMs）越来越多地融入社交和专业环境中，理解它们在社交网络和互动背景下的行为变得至关重要。我们的研究分析了标准网络结构和现实世界网络的行为，以确定多个LLMs的动态是否与人类社交动态一致。我们探讨了各种社交网络原则，包括微观层面的概念，如偏爱附着、三角闭合和同似性，以及宏观层面的概念，如社区结构和小世界现象。我们的研究发现表明，当向LLMs提供网络结构并询问它们对网络形成的偏好时，它们表现出所有这些原则。

    arXiv:2402.10659v1 Announce Type: cross  Abstract: Social networks influence behaviors, preferences, and relationships and play a crucial role in the dissemination of information and norms within human societies. As large language models (LLMs) increasingly integrate into social and professional environments, understanding their behavior within the context of social networks and interactions becomes essential. Our study analyzes the behaviors of standard network structures and real-world networks to determine whether the dynamics of multiple LLMs align with human social dynamics. We explore various social network principles, including micro-level concepts such as preferential attachment, triadic closure, and homophily, as well as macro-level concepts like community structure and the small-world phenomenon. Our findings suggest that LLMs demonstrate all these principles when they are provided with network structures and asked about their preferences regarding network formation. Furtherm
    
[^87]: SciGLM: 用自我反思指导注释和调整训练科学语言模型

    SciGLM: Training Scientific Language Models with Self-Reflective Instruction Annotation and Tuning

    [https://arxiv.org/abs/2401.07950](https://arxiv.org/abs/2401.07950)

    SciGLM引入了自我反思指导注释框架，用于弥补大型语言模型在理解复杂科学概念、推导符号方程式和解决高级数值计算方面的不足，以训练能够进行大学水平科学推理的科学语言模型。

    

    大型语言模型(LLMs)已显示出在协助科学发现方面的潜力。然而，目前LLMs在理解复杂科学概念、推导符号方程式和解决高级数值计算方面存在局限。为了弥补这些差距，我们引入了SciGLM，一套能够进行大学水平科学推理的科学语言模型。我们方法的核心是一种新颖的自我反思指导注释框架，以解决科学领域中数据稀缺挑战。该框架利用现有LLMs为未标记的科学问题生成逐步推理，随后经过自我反思的批评和修改过程。应用这一框架，我们整理了SciInstruct，这是一个涵盖物理、化学、数学和形式证明的多样化、高质量的数据集。我们利用SciInstruct对ChatGLM系列语言模型进行了微调，增强了

    arXiv:2401.07950v2 Announce Type: replace  Abstract: Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving advanced numerical calculations. To bridge these gaps, we introduce SciGLM, a suite of scientific language models able to conduct college-level scientific reasoning. Central to our approach is a novel self-reflective instruction annotation framework to address the data scarcity challenge in the science domain. This framework leverages existing LLMs to generate step-by-step reasoning for unlabelled scientific questions, followed by a process of self-reflective critic-and-revise. Applying this framework, we curated SciInstruct, a diverse and high-quality dataset encompassing physics, chemistry, math, and formal proofs. We fine-tuned the ChatGLM family of language models with SciInstruct, enhancing
    
[^88]: KnowGPT：大型语言模型的黑盒知识注入

    KnowGPT: Black-Box Knowledge Injection for Large Language Models

    [https://arxiv.org/abs/2312.06185](https://arxiv.org/abs/2312.06185)

    KnowGPT是一种为大型语言模型提供黑盒知识注入的框架，通过深度强化学习和多臂老虎机构建最适合每个问题的提示，在三个基准数据集上实验证明其显著提升了知识注入的效果。

    

    生成式大型语言模型（LLMs），如ChatGPT，提供互动式API，可以以人类专家水平回答常见问题。然而，当面临需要特定领域或专业领域知识的问题时，这些模型通常会给出不准确或不正确的响应，这些知识并未包含在它们的训练语料库中。此外，许多最先进的LLMs并非开源，这使得仅使用模型API注入知识具有挑战性。在本研究中，我们介绍了KnowGPT，一种用于LLMs在问答中的黑盒知识注入框架。KnowGPT利用深度强化学习（RL）从知识图中提取相关知识，并使用多臂老虎机（MAB）为每个问题构建最合适的提示。我们在三个基准数据集上进行了大量实验，展示了KnowGPT显著增强了现有方法。值得注意的是，KnowGPT平均改进了23%。

    arXiv:2312.06185v2 Announce Type: replace-cross  Abstract: Generative Large Language Models (LLMs), such as ChatGPT, offer interactive APIs that can answer common questions at a human-expert level. However, these models often give inaccurate or incorrect responses when faced with questions requiring domain-specific or professional-specific knowledge not covered in their training corpus. Furthermore, many state-of-the-art LLMs are not open-source, making it challenging to inject knowledge with model APIs only. In this work, we introduce KnowGPT, a black-box knowledge injection framework for LLMs in question answering. KnowGPT leverages deep reinforcement learning (RL) to extract relevant knowledge from Knowledge Graphs (KGs) and use Multi-Armed Bandit (MAB) to construct the most suitable prompt for each question. Our extensive experiments on three benchmark datasets showcase that KnowGPT significantly enhances the existing methods. Notably, KnowGPT achieves an average improvement of 23.
    
[^89]: Jellyfish：一个用于数据预处理的大型语言模型

    Jellyfish: A Large Language Model for Data Preprocessing

    [https://arxiv.org/abs/2312.01678](https://arxiv.org/abs/2312.01678)

    这项研究探讨了在数据挖掘中利用大型语言模型进行数据预处理的方法，通过指导调整本地LLMs来解决通用数据预处理问题，确保数据安全并进行进一步调整

    

    这篇论文探讨了在数据挖掘管道中将原始数据转换为有利于简单处理的干净格式的数据预处理（DP）中LLMs的利用。与使用LLMs为DP设计通用解决方案引起了兴趣相比，最近在这一领域的倡议通常依赖于GPT API，引发了不可避免的数据泄霏担忧。与这些方法不同，我们考虑将指导调整本地LLMs（7-13B模型）作为通用DP问解器。我们选择了代表性DP任务的四组数据集，并利用针对DP定制的序列化和知识注入技术构建了指导调整数据。因此，指导调整的LLMs使用户能够为DP手动制定指导。同时，它们可以在本地、单一和价格低廉的GPU上运行，确保数据安全并实现进一步调整。我们的实验表明，我们为DP指导构建的数据集

    arXiv:2312.01678v4 Announce Type: replace  Abstract: This paper explores the utilization of LLMs for data preprocessing (DP), a crucial step in the data mining pipeline that transforms raw data into a clean format conducive to easy processing. Whereas the use of LLMs has sparked interest in devising universal solutions to DP, recent initiatives in this domain typically rely on GPT APIs, raising inevitable data breach concerns. Unlike these approaches, we consider instruction-tuning local LLMs (7 - 13B models) as universal DP ask solver. We select a collection of datasets across four representative DP tasks and construct instruction-tuning data using serialization and knowledge injection techniques tailored to DP. As such, the instruction-tuned LLMs empower users to manually craft instructions for DP. Meanwhile, they can operate on a local, single, and low-priced GPU, ensuring data security and enabling further tuning. Our experiments show that our dataset constructed for DP instruction
    
[^90]: MLLMs增强视觉-语言表示学习

    MLLMs-Augmented Visual-Language Representation Learning

    [https://arxiv.org/abs/2311.18765](https://arxiv.org/abs/2311.18765)

    MLLMs通过为图像-文本数据集建立更丰富的图像-文本关联，以增强视觉-语言表示学习，并通过“文本剪切”方法来避免偏见引入，显著提高了图像-文本检索的性能。

    

    arXiv:2311.18765v3 公告类型: replace-cross 视觉-语言预训练在许多多模态任务中取得了显著成功，这在很大程度上归功于大规模图像-文本数据集的可用性。在这项工作中，我们证明了多模态大型语言模型（MLLMs）可以通过为图像-文本数据集建立更丰富的图像-文本关联来加强视觉-语言表示学习。我们的方法很简单，利用MLLMs为每个图像扩展多个不同的标题。为了防止MLLMs的幻觉和单调语言风格引入的偏见，我们提出了“文本剪切”来保持扩展标题的质量和可用性。在图像-文本检索中，在不引入额外的训练成本的情况下，我们的方法在精调和零-shot设置下一致地在Recall@1上获得了5.6 ~ 35.0和16.8 ~ 46.1的改进。值得注意的是，我们获得了与在目标数据集上进行微调相当的零-shot结果。

    arXiv:2311.18765v3 Announce Type: replace-cross  Abstract: Visual-language pre-training has achieved remarkable success in many multi-modal tasks, largely attributed to the availability of large-scale image-text datasets. In this work, we demonstrate that Multi-modal Large Language Models (MLLMs) can enhance visual-language representation learning by establishing richer image-text associations for image-text datasets. Our approach is simple, utilizing MLLMs to extend multiple diverse captions for each image. To prevent the bias introduced by MLLMs' hallucinations and monotonous language styles, we propose "text shearing" to maintain the quality and availability of extended captions. In image-text retrieval, without introducing additional training cost, our method consistently obtains 5.6 ~ 35.0 and 16.8 ~ 46.1 improvement on Recall@1 under the fine-tuning and zero-shot settings, respectively. Notably, we obtain zero-shot results that are comparable to fine-tuning on target datasets, wh
    
[^91]: 病理报告的多实例生成用于千亿像素全切片图像

    WsiCaption: Multiple Instance Generation of Pathology Reports for Gigapixel Whole-Slide Images

    [https://arxiv.org/abs/2311.16480](https://arxiv.org/abs/2311.16480)

    研究提出了一种基于多实例生成模型的方法，能够生成千亿像素全切片图像的病理报告，实验结果表明该模型能够产生包含多个临床线索的病理报告。

    

    全切片图像是用于癌症诊断和治疗的数字病理学的基础。撰写病理报告对经验不足的病理学家来说是费时且容易出错的。为了减少工作量并改善临床自动化，我们研究了如何生成给定全切片图像的病理报告。在数据端，我们整理了最大的WSI-文本数据集（TCGA-PathoText）。具体来说，我们通过识别和清理TCGA中叙述诊断幻灯片的病理报告，收集了近1万对高质量的WSI-文本配对，供视觉-语言模型使用。在模型端，我们提出了可以为千亿像素WSI生成病理报告的多实例生成模型（MI-Gen）。我们在TCGA-PathoText的最大子集上对我们的模型进行了基准测试。实验结果表明，我们的模型可以生成包含多个临床线索的病理报告。此外，WSI-文本预测可被视为一种方法。

    arXiv:2311.16480v2 Announce Type: replace-cross  Abstract: Whole slide images are the foundation of digital pathology for the diagnosis and treatment of carcinomas. Writing pathology reports is laborious and error-prone for inexperienced pathologists. To reduce the workload and improve clinical automation, we investigate how to generate pathology reports given whole slide images. On the data end, we curated the largest WSI-text dataset (TCGA-PathoText). In specific, we collected nearly 10000 high-quality WSI-text pairs for visual-language models by recognizing and cleaning pathology reports which narrate diagnostic slides in TCGA. On the model end, we propose the multiple instance generative model (MI-Gen) which can produce pathology reports for gigapixel WSIs. We benchmark our model on the largest subset of TCGA-PathoText. Experimental results show our model can generate pathology reports which contain multiple clinical clues. Furthermore, WSI-text prediction can be seen as an approac
    
[^92]: SUQL：利用大型语言模型对结构化和非结构化数据进行对话式搜索

    SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models

    [https://arxiv.org/abs/2311.09818](https://arxiv.org/abs/2311.09818)

    SUQL是第一个支持大型知识语料库中的混合数据访问的对话代理，通过自由文本基元扩展了SQL，提出了一种新的语言SUQL，并开发了一个可以处理混合数据源的语义解析器。

    

    虽然大多数对话代理都基于自由文本或结构化知识，但许多知识语料库由混合来源组成。本文提出了第一个支持大型知识语料库的混合数据访问的对话代理，通过我们开发的一种名为SUQL（结构化和非结构化查询语言）的语言。具体来说，SUQL通过自由文本基元（汇总和答案）扩展了SQL，因此信息检索可以与结构化数据访问任意组合，采用正式、简洁、准确和可解释的表示。通过SUQL，我们提出了第一个语义解析器，这是一种具有上下文学习的LLM，可以处理混合数据源。我们的基于上下文学习的方法，在应用于HybridQA数据集时，与SOTA存在8.9%的精确匹配和7.1%的F1值的差距，后者在62K个数据样本上进行了训练。更重要的是，与以往的方法不同，我们的技术

    arXiv:2311.09818v2 Announce Type: replace  Abstract: While most conversational agents are grounded on either free-text or structured knowledge, many knowledge corpora consist of hybrid sources. This paper presents the first conversational agent that supports the full generality of hybrid data access for large knowledge corpora, through a language we developed called SUQL (Structured and Unstructured Query Language). Specifically, SUQL extends SQL with free-text primitives (summary and answer), so information retrieval can be composed with structured data accesses arbitrarily in a formal, succinct, precise, and interpretable notation. With SUQL, we propose the first semantic parser, an LLM with in-context learning, that can handle hybrid data sources.   Our in-context learning-based approach, when applied to the HybridQA dataset, comes within 8.9% exact match and 7.1% F1 of the SOTA, which was trained on 62K data samples. More significantly, unlike previous approaches, our technique is 
    
[^93]: 推理链上的欺骗性语义快捷方式：模型在没有幻觉的情况下能走多远？

    Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?

    [https://arxiv.org/abs/2311.09702](https://arxiv.org/abs/2311.09702)

    本研究探讨了大型语言模型存在的幻觉和不忠实推理问题，提出一种新的探测方法和基准测试以研究LLMs在推理过程中是否会采取欺骗性语义快捷方式。

    

    尽管大型语言模型（LLMs）近期取得了显著进展，并在众多基准测试中表现出色，但最近的研究揭示了LLMs存在幻觉和不忠实推理的问题。本研究探讨了一种特定类型由语义关联引起的幻觉。具体来说，我们调查了LLMs在提示中是否会因为某些关键字/实体偏见而采取捷径，而不是遵循正确的推理路径。为了量化这一现象，我们提出了一种名为EureQA的新型探测方法和基准测试。我们从LLMs会以绝对确定性正确回答的问题开始，然后递归地用证据句子遮蔽重要实体，要求模型在回答问题之前找到根据证据链条遮蔽的实体。

    arXiv:2311.09702v2 Announce Type: replace-cross  Abstract: Despite the recent advancement in large language models (LLMs) and their high performances across numerous benchmarks, recent research has unveiled that LLMs suffer from hallucinations and unfaithful reasoning. This work studies a specific type of hallucination induced by semantic associations. Specifically, we investigate to what extent LLMs take shortcuts from certain keyword/entity biases in the prompt instead of following the correct reasoning path. To quantify this phenomenon, we propose a novel probing method and benchmark called EureQA. We start from questions that LLMs will answer correctly with utmost certainty, and mask the important entity with evidence sentence recursively, asking models to find masked entities according to a chain of evidence before answering the question.   During the construction of the evidence, we purposefully replace semantic clues (entities) that may lead to the correct answer with distractor
    
[^94]: 推测对比解码

    Speculative Contrastive Decoding

    [https://arxiv.org/abs/2311.08981](https://arxiv.org/abs/2311.08981)

    SCD是一种结合了推测解码和对比解码的解码方法，利用较小语言模型的预测实现了解码加速和质量提升

    

    大型语言模型在语言任务中表现出色，但由于高计算需求和曝光偏差，它们的自回归推理存在局限性。受到推测解码和对比解码的启发，我们引入了推测对比解码（SCD），这是一种简单而强大的解码方法，利用较小语言模型的预测来实现解码加速和质量提升。对四种不同的语言任务进行了广泛评估和分析，证明了SCD的有效性，表明解码效率和质量可以兼得一种较小的语言模型。

    arXiv:2311.08981v2 Announce Type: replace  Abstract: Large language models~(LLMs) exhibit exceptional performance in language tasks, yet their auto-regressive inference is limited due to high computational requirements and is sub-optimal due to the exposure bias. Inspired by speculative decoding and contrastive decoding, we introduce Speculative Contrastive Decoding~(SCD), a straightforward yet powerful decoding approach that leverages predictions from smaller language models~(LMs) to achieve both decoding acceleration and quality improvement. Extensive evaluations and analyses on four diverse language tasks demonstrate the effectiveness of SCD, showing that decoding efficiency and quality can compatibly benefit from one smaller LM.
    
[^95]: Agent Lumos: 统一和模块化训练开源语言代理

    Agent Lumos: Unified and Modular Training for Open-Source Language Agents

    [https://arxiv.org/abs/2311.05657](https://arxiv.org/abs/2311.05657)

    Agent Lumos提出了一种统一和模块化的框架，通过规划模块学习高级子目标生成，训练接地模块将其转化为动作，促进广泛互动任务应用。

    

    闭源代理存在诸多问题，如缺乏负担得起性、透明度和可重复性，特别是在复杂的互动任务中。这促使了开源替代方案的发展。我们介绍了 LUMOS，这是第一个为训练开源 LLM-based 代理而设计的框架之一。LUMOS具有可学习、统一和模块化的架构，其中包括一个学习高级子目标生成的规划模块，以及一个训练有素的接地模块，用于使用执行模块中的各种工具将这些转化为动作。这种设计允许模块化升级，并更广泛地适用于不同的互动任务。为了促进通用代理学习，我们收集了源自各种复杂互动任务中不同地面真实推理原理的大规模、统一和高质量的训练注释。在9个数据集上，LUMOS表现出了几个关键优势：（1）LUMOS在多个较大的开源a

    arXiv:2311.05657v2 Announce Type: replace  Abstract: Closed-source agents suffer from several issues such as a lack of affordability, transparency, and reproducibility, particularly on complex interactive tasks. This motivates the development of open-source alternatives. We introduce LUMOS, one of the first frameworks for training open-source LLM-based agents. LUMOS features a learnable, unified, and modular architecture with a planning module that learns high-level subgoal generation, and a grounding module trained to translate these into actions using various tools in the execution module. The design allows for modular upgrades and wider applicability to diverse interactive tasks. To foster generalizable agent learning, we collect large-scale, unified, and high-quality training annotations derived from diverse ground-truth reasoning rationales across various complex interactive tasks. On 9 datasets, LUMOS exhibits several key advantages: (1) LUMOS excels multiple larger open-source a
    
[^96]: Octavius：通过MoE减轻MLLM中的任务干扰

    Octavius: Mitigating Task Interference in MLLMs via MoE

    [https://arxiv.org/abs/2311.02684](https://arxiv.org/abs/2311.02684)

    提出了一个名为Octavius的新框架，通过结合MoE和LoRA技术设计了一种新颖的LLM解码器LoRA-MoE，用于多模态学习，实验证明其在各种2D和3D下游任务中具有约20%的改进效果。

    

    最近的研究表明，大型语言模型（LLMs）可以通过指导调整将它们的零-shot泛化能力扩展到多模态学习。随着引入更多的形式和下游任务，负面冲突和干扰可能对性能产生更严重的影响。虽然这种现象在以前的工作中被忽视了，但我们提出了一个名为\mname 的新颖且可扩展的框架，用于与Multimodal Large Language Models（MLLMs）一起进行多模态学习的全面研究和实验。具体来说，我们结合了众所周知的专家混合（MoE）和代表性PEFT技术之一，即LoRA，设计了一种新颖的基于LLM的解码器，称为LoRA-MoE，用于多模态学习。实验结果（约20\%的改进）表明了我们设计在各种2D和3D下游任务中的有效性和多功能性。代码和相应数据集将很快提供。

    arXiv:2311.02684v1 Announce Type: cross  Abstract: Recent studies have demonstrated Large Language Models (LLMs) can extend their zero-shot generalization capabilities to multimodal learning through instruction tuning. As more modalities and downstream tasks are introduced, negative conflicts and interference may have a worse impact on performance. While this phenomenon has been overlooked in previous work, we propose a novel and extensible framework, called \mname, for comprehensive studies and experimentation on multimodal learning with Multimodal Large Language Models (MLLMs). Specifically, we combine the well-known Mixture-of-Experts (MoE) and one of the representative PEFT techniques, \emph{i.e.,} LoRA, designing a novel LLM-based decoder, called LoRA-MoE, for multimodal learning. The experimental results (about 20\% improvement) have shown the effectiveness and versatility of our design in various 2D and 3D downstream tasks. Code and corresponding dataset will be available soon.
    
[^97]: LitCab: 在短语和长语言模型应答中的轻量级校准

    LitCab: Lightweight Language Model Calibration over Short- and Long-form Responses

    [https://arxiv.org/abs/2310.19208](https://arxiv.org/abs/2310.19208)

    LitCab 是一种轻量级校准机制，通过仅添加原始模型参数的 < 2%，以一个单一线性层的形式改善语言模型的校准。

    

    当模型的概率估计与实际输出正确的可能性一致时，该模型被认为是校准良好的。校准语言模型（LMs）至关重要，因为它在检测和减轻LMs的幻觉以及构建更可信赖的模型中发挥着重要作用。我们提出了LitCab，这是一种轻量级校准机制，由一个单一线性层组成，它接受输入文本表示并预测一个偏差项，然后将其添加到LM输出logits中。

    arXiv:2310.19208v2 Announce Type: replace  Abstract: A model is considered well-calibrated when its probability estimate aligns with the actual likelihood of the output being correct. Calibrating language models (LMs) is crucial, as it plays a vital role in detecting and mitigating hallucinations of LMs as well as building more trustworthy models. However, standard calibration techniques may not be suited for LM calibration. For instance, post-processing methods such as temperature scaling do not reorder the candidate generations. On the other hand, training-based methods require fine-tuning the entire model, which is impractical for LMs of large scale. We present LitCab, a lightweight calibration mechanism consisting of a single linear layer that takes the input text representation and predicts a bias term, which is then added to the LM output logits. LitCab improves model calibration by only adding < 2% of the original model parameters. For evaluation, we construct CaT, a benchmark c
    
[^98]: RoPE基外推的尺度律

    Scaling Laws of RoPE-based Extrapolation

    [https://arxiv.org/abs/2310.05209](https://arxiv.org/abs/2310.05209)

    本研究提出了RoPE基外推的尺度律，通过调整 RoPE 中的基数和微调文本长度来显著提高大型语言模型的外推性能。

    

    基于Rotary Position Embedding的大型语言模型（LLMs）的外推能力是目前备受关注的话题。用于解决LLMs外推问题的主流方法是通过将RoPE中的10000, $\theta_n={10000}^{-2n/d}$，这个旋转基数，替换为更大的值，并提供更长的微调文本。本研究首先观察到，在预训练上用较小或较大的基数微调RoPE-based LLM，可以显著提高其外推性能。之后，我们提出了RoPE基外推的尺度律，这是一个从周期性的角度描述外推性能与基值以及调整上下文长度之间关系的统一框架。在这个过程中，我们还通过RoPE基外推问题的关键维度介绍了其起源。

    arXiv:2310.05209v2 Announce Type: replace-cross  Abstract: The extrapolation capability of Large Language Models (LLMs) based on Rotary Position Embedding is currently a topic of considerable interest. The mainstream approach to addressing extrapolation with LLMs involves modifying RoPE by replacing 10000, the rotary base of $\theta_n={10000}^{-2n/d}$ in the original RoPE, with a larger value and providing longer fine-tuning text. In this work, we first observe that fine-tuning a RoPE-based LLM with either a smaller or larger base in pre-training context length could significantly enhance its extrapolation performance. After that, we propose \textbf{\textit{Scaling Laws of RoPE-based Extrapolation}}, a unified framework from the periodic perspective, to describe the relationship between the extrapolation performance and base value as well as tuning context length. In this process, we also explain the origin of the RoPE-based extrapolation issue by \textbf{\textit{critical dimension for
    
[^99]: 用大型语言模型解密嵌入空间

    Demystifying Embedding Spaces using Large Language Models

    [https://arxiv.org/abs/2310.04475](https://arxiv.org/abs/2310.04475)

    通过使用大型语言模型（LLMs）直接与嵌入交互，将抽象向量转换为可理解的叙述，使得复杂嵌入数据更具解释性和广泛实用性。

    

    嵌入已经成为表示有关实体、概念和关系的复杂多方面信息的关键手段，以一种紧凑且有用的方式。然而，它们通常难以直接解释。尽管下游任务利用了这些压缩表示，但有意义的解释通常需要使用降维或专门的机器学习可解释性方法进行可视化。本文通过使用大型语言模型（LLMs）直接与嵌入交互，将抽象向量转换为可理解的叙述，从而解决了使这些嵌入更具解释性和广泛实用性的挑战。通过将嵌入注入LLMs，我们实现了对复杂嵌入数据的查询和探索。我们在各种不同的任务上演示了我们的方法，其中包括：增强概念激活向量（CAVs）、传达新颖的嵌入实体等。

    arXiv:2310.04475v2 Announce Type: replace-cross  Abstract: Embeddings have become a pivotal means to represent complex, multi-faceted information about entities, concepts, and relationships in a condensed and useful format. Nevertheless, they often preclude direct interpretation. While downstream tasks make use of these compressed representations, meaningful interpretation usually requires visualization using dimensionality reduction or specialized machine learning interpretability methods. This paper addresses the challenge of making such embeddings more interpretable and broadly useful, by employing Large Language Models (LLMs) to directly interact with embeddings -- transforming abstract vectors into understandable narratives. By injecting embeddings into LLMs, we enable querying and exploration of complex embedding data. We demonstrate our approach on a variety of diverse tasks, including: enhancing concept activation vectors (CAVs), communicating novel embedded entities, and decod
    
[^100]: 量化神经机器翻译中背景依赖性的可信度

    Quantifying the Plausibility of Context Reliance in Neural Machine Translation

    [https://arxiv.org/abs/2310.01188](https://arxiv.org/abs/2310.01188)

    引入了PECoRe框架，用于量化语言模型生成中的上下文使用情况，从而评估上下文感知机器翻译模型的可信度。

    

    本文介绍了一种名为PECoRe的端到端可解释性框架，旨在量化语言模型生成中上下文使用的情况。我们的方法利用模型内部来对比识别生成文本中上下文敏感的目标令牌，并将它们与证明其预测的上下文线索联系起来。我们使用PECORE来量化具有上下文感知的机器翻译模型的可信度，将模型的理由与人类注释在几个层次的话语水平上进行比较。

    arXiv:2310.01188v2 Announce Type: replace-cross  Abstract: Establishing whether language models can use contextual information in a human-plausible way is important to ensure their trustworthiness in real-world settings. However, the questions of when and which parts of the context affect model generations are typically tackled separately, with current plausibility evaluations being practically limited to a handful of artificial benchmarks. To address this, we introduce Plausibility Evaluation of Context Reliance (PECoRe), an end-to-end interpretability framework designed to quantify context usage in language models' generations. Our approach leverages model internals to (i) contrastively identify context-sensitive target tokens in generated texts and (ii) link them to contextual cues justifying their prediction. We use \pecore to quantify the plausibility of context-aware machine translation models, comparing model rationales with human annotations across several discourse-level pheno
    
[^101]: CRAFT: 通过创建和检索专业工具集定制LLMs

    CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets

    [https://arxiv.org/abs/2309.17428](https://arxiv.org/abs/2309.17428)

    CRAFT提出了一个通用工具创建和检索框架，能够定制LLMs，为其创建特定任务的工具集，并使用这些工具集增强其解决复杂任务的能力。

    

    大语言模型（LLMs）通常通过生成代码片段并通过特定任务的应用程序编程接口（API）执行它们来解决复杂任务。本文介绍了CRAFT，这是一个专门为LLMs创建工具集的通用工具创建和检索框架。它为任务创建了特定的工具集，并为LLMs配备了一个组件，用于从这些集合中检索工具，以增强它们解决复杂任务的能力。

    arXiv:2309.17428v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) are often augmented with tools to solve complex tasks. By generating code snippets and executing them through task-specific Application Programming Interfaces (APIs), they can offload certain functions to dedicated external modules, such as image encoding and performing calculations. However, most existing approaches to augment LLMs with tools are constrained by general-purpose APIs and lack the flexibility for tailoring them to specific tasks. In this work, we present CRAFT, a general tool creation and retrieval framework for LLMs. It creates toolsets specifically curated for the tasks and equips LLMs with a component that retrieves tools from these sets to enhance their capability to solve complex tasks. For each task, we collect specific code solutions by prompting GPT-4 to solve the training examples. Following a validation step ensuring the correctness, these solutions are abstracted into code 
    
[^102]: 通过链接大型语言模型增强私人辅导

    Empowering Private Tutoring by Chaining Large Language Models

    [https://arxiv.org/abs/2309.08112](https://arxiv.org/abs/2309.08112)

    通过链式连接大型语言模型，开发了一种全面智能辅导系统，实现了自动课程规划、个性化指导和灵活测验评估。

    

    人工智能已被应用于在线教育的各个方面，以促进教学和学习。然而，很少有方法致力于完整的AI辅导系统。在这项工作中，我们探讨了一个由最先进的大型语言模型（LLMs）驱动的全面智能辅导系统的开发，涵盖自动课程规划和调整、定制指导以及灵活的测验评估。为了使系统能够经受住长时间交互并满足个性化教育的需求，系统被分解为三个相互连接的核心流程-交互、反思和反应。每个流程都通过链接LLM驱动的工具以及动态更新的记忆模块来实现。工具是LLMs，被提示执行一项特定任务，而记忆是在教育过程中更新的数据存储。学习日志中的统计结果证明了这种方法的有效性。

    arXiv:2309.08112v1 Announce Type: cross  Abstract: Artificial intelligence has been applied in various aspects of online education to facilitate teaching and learning. However, few approaches has been made toward a complete AI-powered tutoring system. In this work, we explore the development of a full-fledged intelligent tutoring system powered by state-of-the-art large language models (LLMs), covering automatic course planning and adjusting, tailored instruction, and flexible quiz evaluation. To make the system robust to prolonged interaction and cater to individualized education, the system is decomposed into three inter-connected core processes-interaction, reflection, and reaction. Each process is implemented by chaining LLM-powered tools along with dynamically updated memory modules. Tools are LLMs prompted to execute one specific task at a time, while memories are data storage that gets updated during education process. Statistical results from learning logs demonstrate the effec
    
[^103]: BED：基于双编码器的检测器用于异常检测

    BED: Bi-Encoder-Based Detectors for Out-of-Distribution Detection

    [https://arxiv.org/abs/2306.08852](https://arxiv.org/abs/2306.08852)

    本文提出了一种基于双编码器的检测器方法，通过对不同的特征提取器进行比较研究，在NLP领域中展现出了在异常检测方面的潜力。

    

    本文提出了一种新颖的方法，利用基于双编码器的检测器，并进行了一项全面的研究，比较了NLP中使用不同特征提取器的不同异常检测方法。特征提取阶段采用通用句子编码器（USE）、BERT、MPNET和GLOVE等流行方法，从文本数据中提取信息丰富的表示。评估是在几个数据集上进行的，包括CLINC150、ROSTD-Coarse、SNIPS和YELLOW。性能是使用F1-Score、MCC、FPR@90、FPR@95、AUPR和AUROC等指标进行评估的。实验结果表明，所提出的基于双编码器的检测器在所有数据集上均优于其他方法，无论是那些需要训练中的OOD标签的方法还是不需要的方法，在NLP中显示出了很大的异常检测潜力。训练过程的简单性和卓越的检测性能使其适用于实际应用。

    arXiv:2306.08852v2 Announce Type: replace  Abstract: This paper introduces a novel method leveraging bi-encoder-based detectors along with a comprehensive study comparing different out-of-distribution (OOD) detection methods in NLP using different feature extractors. The feature extraction stage employs popular methods such as Universal Sentence Encoder (USE), BERT, MPNET, and GLOVE to extract informative representations from textual data. The evaluation is conducted on several datasets, including CLINC150, ROSTD-Coarse, SNIPS, and YELLOW. Performance is assessed using metrics such as F1-Score, MCC, FPR@90, FPR@95, AUPR, an AUROC. The experimental results demonstrate that the proposed bi-encoder-based detectors outperform other methods, both those that require OOD labels in training and those that do not, across all datasets, showing great potential for OOD detection in NLP. The simplicity of the training process and the superior detection performance make them applicable to real-world
    
[^104]: 来自异构表格的基于模式的信息提取

    Schema-Driven Information Extraction from Heterogeneous Tables

    [https://arxiv.org/abs/2305.14336](https://arxiv.org/abs/2305.14336)

    本文探讨了大型语言模型在通过引入基于模式的信息提取任务进行多领域表格数据处理时的竞争性表现，而无需特定流水线或标签，同时保持成本效率。

    

    在本文中，我们探讨了大型语言模型是否能够支持高效地从表格中提取信息的问题。我们引入了基于模式的信息提取，这是一项将表格数据转换为按照人类编写的模式组织的记录的新任务。为了评估各种LLM在这一任务上的能力，我们提出了一个基准，包括来自四个不同领域的表格：机器学习论文、化学文献、材料科学期刊和网页。我们利用这个带有注释的表格集合来评估开源和基于API的语言模型从涵盖多种领域和数据格式的表格中提取信息的能力。我们的实验表明，即使不需要任务特定的流水线或标签，也可以实现出人意料的竞争性表现，F1分数范围从74.2到96.1，同时保持成本效率。此外，通过详细的消融研究

    arXiv:2305.14336v3 Announce Type: replace  Abstract: In this paper, we explore the question of whether large language models can support cost-efficient information extraction from tables. We introduce schema-driven information extraction, a new task that transforms tabular data into structured records following a human-authored schema. To assess various LLM's capabilities on this task, we present a benchmark comprised of tables from four diverse domains: machine learning papers, chemistry literature, material science journals, and webpages. We use this collection of annotated tables to evaluate the ability of open-source and API-based language models to extract information from tables covering diverse domains and data formats. Our experiments demonstrate that surprisingly competitive performance can be achieved without requiring task-specific pipelines or labels, achieving F1 scores ranging from 74.2 to 96.1, while maintaining cost efficiency. Moreover, through detailed ablation studie
    
[^105]: 化学命名实体识别模型中性别偏见的全面研究

    A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models

    [https://arxiv.org/abs/2212.12799](https://arxiv.org/abs/2212.12799)

    本文研究了化学命名实体识别模型中的性别偏见，使用合成数据和Reddit上的性别信息注释语料库评估多个生物医学NER模型，揭示了明显的偏见。

    

    化学命名实体识别（NER）模型在许多下游任务中被使用，从不良药物反应识别到药物流行病学。然而，目前尚不清楚这些模型是否对所有人都起作用。性能差异可能会造成实际伤害而不是预期的益处。本文评估了化学NER系统中与性别相关的性能差异。我们开发了一个框架，使用合成数据和来自Reddit的超过92,405个词的自我识别性别信息的新注释语料库，来衡量化学NER模型中的性别偏见。我们对多个生物医学NER模型进行评估，发现了明显的偏见。例如，合成数据表明女性相关名称经常被误分类为化学品，特别是品牌名称的提及。此外，我们观察到两个数据集中的男性和女性关联数据之间的性能差异。许多系统未能检测避孕药物。

    arXiv:2212.12799v2 Announce Type: replace  Abstract: Chemical named entity recognition (NER) models are used in many downstream tasks, from adverse drug reaction identification to pharmacoepidemiology. However, it is unknown whether these models work the same for everyone. Performance disparities can potentially cause harm rather than the intended good. This paper assesses gender-related performance disparities in chemical NER systems. We develop a framework for measuring gender bias in chemical NER models using synthetic data and a newly annotated corpus of over 92,405 words with self-identified gender information from Reddit. Our evaluation of multiple biomedical NER models reveals evident biases. For instance, synthetic data suggests female-related names are frequently misclassified as chemicals, especially for brand name mentions. Additionally, we observe performance disparities between female- and male-associated data in both datasets. Many systems fail to detect contraceptives su
    
[^106]: ToPro: 跨语言序列标注任务的基于Token级别的提示分解

    ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence Labeling Tasks. (arXiv:2401.16589v1 [cs.CL])

    [http://arxiv.org/abs/2401.16589](http://arxiv.org/abs/2401.16589)

    这项研究提出了一种名为ToPro的方法，用于跨语言序列标注任务。该方法通过将输入句子分解为单个词汇并应用提示模板，在零样本跨语言转移中实现了优于其他微调方法的性能，并在结构不同的语言上取得了最先进的结果。

    

    基于提示的方法已成功应用于多语言预训练语言模型的零样本跨语言理解。然而，大多数之前的研究主要关注句子级别的分类任务，只有少数考虑到了词汇级别的标注任务，如命名实体识别（NER）和词性标注（POS）。在本文中，我们提出了基于Token级别的提示分解（ToPro），该方法可用于词汇级别的序列标注任务。ToPro方法将输入句子分解为单个词汇，并对每个词汇应用一个提示模板。我们在多语言NER和POS标注数据集上的实验表明，基于ToPro的微调在零样本跨语言转移中优于Vanilla微调和Prompt-Tuning，尤其对于结构与源语言英语不同的语言。我们的方法在使用mT5模型时也获得了最先进的性能。

    Prompt-based methods have been successfully applied to multilingual pretrained language models for zero-shot cross-lingual understanding. However, most previous studies primarily focused on sentence-level classification tasks, and only a few considered token-level labeling tasks such as Named Entity Recognition (NER) and Part-of-Speech (POS) tagging. In this paper, we propose Token-Level Prompt Decomposition (ToPro), which facilitates the prompt-based method for token-level sequence labeling tasks. The ToPro method decomposes an input sentence into single tokens and applies one prompt template to each token. Our experiments on multilingual NER and POS tagging datasets demonstrate that ToPro-based fine-tuning outperforms Vanilla fine-tuning and Prompt-Tuning in zero-shot cross-lingual transfer, especially for languages that are typologically different from the source language English. Our method also attains state-of-the-art performance when employed with the mT5 model. Besides, our exp
    
[^107]: GPT-4V(ision)是一个通用的网络代理，如果有基础的话。

    GPT-4V(ision) is a Generalist Web Agent, if Grounded. (arXiv:2401.01614v1 [cs.IR])

    [http://arxiv.org/abs/2401.01614](http://arxiv.org/abs/2401.01614)

    GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。

    

    最近对大型多模型（LMM）的研究，特别是GPT-4V(ision)和Gemini，快速推动了多模型的能力边界超越传统任务，如图像字幕和视觉问答。在这项工作中，我们探索了像GPT-4V这样的LMM作为通用网络代理的潜力，可以根据自然语言指令在任何给定的网站上完成任务。我们提出了SEEACT，一种利用LMM的力量进行综合视觉理解和网页操作的通用网络代理。我们在最新的MIND2WEB基准上进行评估。除了对缓存网站的标准离线评估外，我们还通过开发一个允许在实时网站上运行网络代理的工具，实现了一种新的在线评估设置。我们展示了GPT-4V在网页代理方面表现出巨大的潜力-如果我们将其文本计划手动地实施为网站上的行动，它可以成功地完成50%的任务。此结果明显超过了传统方法。

    The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering. In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website. We propose SEEACT, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web. We evaluate on the recent MIND2WEB benchmark. In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites. We show that GPT-4V presents a great potential for web agents - it can successfully complete 50% of the tasks on live websites if we manually ground its textual plans into actions on the websites. This substantially outperforms
    
[^108]: 超越梯度和先验知识在隐私攻击中：利用联邦学习中语言模型的池化层输入

    Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer Inputs of Language Models in Federated Learning. (arXiv:2312.05720v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.05720](http://arxiv.org/abs/2312.05720)

    本文引入了一种创新的方法，在联邦学习中利用语言模型的池化层输入来实现对隐私攻击的改进。通过恢复池化层输入，这种方法能够在不同的批处理大小下提供更高的文本恢复率，从而提供更细致和有效的见解。

    

    联邦学习强调分散式训练，通过本地存储数据并仅发送模型更新，强调用户隐私。最近，一系列有关隐私攻击的工作通过从联邦学习上下文的语言模型中提取敏感的训练文本来损害用户隐私。然而，这些攻击技术面临着不同的障碍：一些工作主要使用有限的批处理大小（例如，批处理大小为1），而其他技术则容易被检测出来。本文介绍了一种创新的方法，具有难以检测的特点，在不同的批处理大小设置下显著提高了文本恢复率。基于基本的梯度匹配和领域先验知识，我们通过恢复语言模型的池化层输入来增强攻击能力，这使我们能够在特征级别提供额外的监督信号。与梯度数据不同，这些信号不会在句子和标记之间进行平均，从而提供更细致和有效的见解。

    Federated learning (FL) emphasizes decentralized training by storing data locally and sending only model updates, underlining user privacy. Recently, a line of works on privacy attacks impairs user privacy by extracting sensitive training text from language models in the context of FL. Yet, these attack techniques face distinct hurdles: some work chiefly with limited batch sizes (e.g., batch size of 1), and others are easily detectable. This paper introduces an innovative approach that is challenging to detect, significantly enhancing the recovery rate of text in various batch-size settings. Building on fundamental gradient matching and domain prior knowledge, we enhance the attack by recovering the input of the Pooler layer of language models, which enables us to provide additional supervised signals at the feature level. Unlike gradient data, these signals do not average across sentences and tokens, thereby offering more nuanced and effective insights. We benchmark our method using t
    
[^109]: GenTKG: 基于生成模型的时间知识图谱预测

    GenTKG: Generative Forecasting on Temporal Knowledge Graph. (arXiv:2310.07793v1 [cs.CL])

    [http://arxiv.org/abs/2310.07793](http://arxiv.org/abs/2310.07793)

    研究提出了一种名为GenTKG的生成模型，用于在时间知识图谱上进行预测。该模型通过结合基于时间逻辑规则的检索策略和轻量级的参数效率指导，克服了复杂的时间图数据结构和庞大的数据量所带来的挑战。

    

    大规模语言模型(LLM)的快速发展引发了对时间知识图谱(tKG)领域的兴趣，其中传统的基于嵌入和规则的模型占主导地位。目前仍然存在一个问题，即预训练的LLM是否能够理解结构化的时间关系数据，并取代它们成为时间关系预测的基础模型。因此，我们将时间知识预测引入生成模式。然而，在复杂的时间图数据结构和LLM可以处理的序列自然表达之间存在巨大的鸿沟，在tKG的庞大数据量和微调LLM的巨大计算成本之间也存在挑战。为了解决这些挑战，我们提出了一种新颖的检索增强生成框架，称为GenTKG，它在tKG上执行生成式预测，结合了基于时间逻辑规则的检索策略和轻量级的参数效率指导。通过大量实验证明了GenTKG的有效性。

    The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional carefully designed embedding-based and rule-based models dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs. To address these challenges, we propose a novel retrieval augmented generation framework that performs generative forecasting on tKGs named GenTKG, which combines a temporal logical rule-based retrieval strategy and lightweight parameter-efficient instruction tuning. Extensive experiments hav
    
[^110]: PROGrasp:实现物体抓取的人机交流

    PROGrasp: Pragmatic Human-Robot Communication for Object Grasping. (arXiv:2309.07759v1 [cs.CL])

    [http://arxiv.org/abs/2309.07759](http://arxiv.org/abs/2309.07759)

    PROGrasp是一个实现物体抓取的人机交流系统，通过使用面向意图的多模态对话和答案解释模块，机器人能够根据用户的意图来识别和抓取目标物体。

    

    交互式物体抓取(IOG)是通过人机自然语言交流识别和抓取目标物体的任务。当前IOG系统假定人类用户最初指定目标对象的类别(例如，瓶子)。受到语用学的启发，人类往往通过依赖上下文来传达意图以实现目标。我们引入了一项新的IOG任务，即实用IOG，并提出相应的数据集，即面向意图的多模态对话(IM-Dial)。在我们提出的任务场景中，首先给出一个面向意图的话语(例如，“我渴了”)。然后，机器人应通过与人类用户互动来识别目标对象。基于任务设置，我们提出了一个新的机器人系统，可以解释用户的意图并捡起目标对象，即实用物体抓取(PROGrasp)。PROGrasp通过结合视觉定位、问题提问、物体抓取以及最重要的，答案解释模块执行实用IOG。

    Interactive Object Grasping (IOG) is the task of identifying and grasping the desired object via human-robot natural language interaction. Current IOG systems assume that a human user initially specifies the target object's category (e.g., bottle). Inspired by pragmatics, where humans often convey their intentions by relying on context to achieve goals, we introduce a new IOG task, Pragmatic-IOG, and the corresponding dataset, Intention-oriented Multi-modal Dialogue (IM-Dial). In our proposed task scenario, an intention-oriented utterance (e.g., "I am thirsty") is initially given to the robot. The robot should then identify the target object by interacting with a human user. Based on the task setup, we propose a new robotic system that can interpret the user's intention and pick up the target object, Pragmatic Object Grasping (PROGrasp). PROGrasp performs Pragmatic-IOG by incorporating modules for visual grounding, question asking, object grasping, and most importantly, answer interpre
    
[^111]: 提高ChatGPT生成的假科学检测的方法：引入xFakeBibs监督学习网络算法

    Improving Detection of ChatGPT-Generated Fake Science Using Real Publication Text: Introducing xFakeBibs a Supervised-Learning Network Algorithm. (arXiv:2308.11767v1 [cs.CL])

    [http://arxiv.org/abs/2308.11767](http://arxiv.org/abs/2308.11767)

    本文介绍了一种能够提高对ChatGPT生成的假科学进行检测的算法。通过使用一种新设计的监督机器学习算法，该算法能够准确地将机器生成的出版物与科学家生成的出版物区分开来。结果表明，ChatGPT在技术术语方面与真实科学存在显著差异。算法在分类过程中取得了较高的准确率。

    

    ChatGPT正在成为现实。本文展示了如何区分ChatGPT生成的出版物与科学家生成的出版物。通过使用一种新设计的监督机器学习算法，我们演示了如何检测机器生成的出版物和科学家生成的出版物。该算法使用100个真实出版物摘要进行训练，然后采用10倍交叉验证方法建立了一个接受范围的下限和上限。与ChatGPT内容进行比较，明显可见ChatGPT仅贡献了23\%的二元组内容，这比其他10个交叉验证中的任何一个都少50\%。这个分析凸显了ChatGPT在技术术语上与真实科学的明显差异。在对每篇文章进行分类时，xFakeBibs算法准确地将98篇出版物识别为假的，有2篇文献错误地分类为真实出版物。尽管这项工作引入了一种算法应用

    ChatGPT is becoming a new reality. In this paper, we show how to distinguish ChatGPT-generated publications from counterparts produced by scientists. Using a newly designed supervised Machine Learning algorithm, we demonstrate how to detect machine-generated publications from those produced by scientists. The algorithm was trained using 100 real publication abstracts, followed by a 10-fold calibration approach to establish a lower-upper bound range of acceptance. In the comparison with ChatGPT content, it was evident that ChatGPT contributed merely 23\% of the bigram content, which is less than 50\% of any of the other 10 calibrating folds. This analysis highlights a significant disparity in technical terms where ChatGPT fell short of matching real science. When categorizing the individual articles, the xFakeBibs algorithm accurately identified 98 out of 100 publications as fake, with 2 articles incorrectly classified as real publications. Though this work introduced an algorithmic app
    
[^112]: 大型语言模型中的上下文学习在学习标签关系上具有创新，但并非传统学习方法

    In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning. (arXiv:2307.12375v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12375](http://arxiv.org/abs/2307.12375)

    大型语言模型（LLMs）在包含标签关系示例的上下文中的学习能力使其在下游任务中表现显著提高，但与传统学习方法不同。我们研究了上下文示例中的标签如何影响预测、预训练中学习到的标签关系如何与上下文示例相互作用以及上下文学习如何聚合标签信息。研究结果揭示了LLMs的工作机制及其对上下文信息的处理方式。

    

    在下游任务中，大型语言模型（LLMs）的性能在包含输入-标签关系示例的上下文中通常显著提高。然而，目前对LLMs的这种上下文学习（ICL）能力的工作机制尚无共识：例如，虽然Xie等人（2021年）将ICL比作一种通用学习算法，但Min等人（2022b年）认为ICL甚至不能从上下文示例中学习标签关系。在本文中，我们研究了以下三个问题：（1）上下文示例的标签如何影响预测结果，（2）预训练期间学习到的标签关系如何与上下文中提供的输入-标签示例相互作用，以及（3）ICL如何聚合来自上下文示例的标签信息。我们的研究发现，LLMs通常会整合上下文标签的信息，但预训练和上下文标签关系被区别对待，模型不会将所有上下文信息等同对待。我们的结果揭示了对LLMs的理解。

    The performance of Large Language Models (LLMs) on downstream tasks often improves significantly when including examples of the input-label relationship in the context. However, there is currently no consensus about how this in-context learning (ICL) ability of LLMs works: for example, while Xie et al. (2021) liken ICL to a general-purpose learning algorithm, Min et al. (2022b) argue ICL does not even learn label relationships from in-context examples. In this paper, we study (1) how labels of in-context examples affect predictions, (2) how label relationships learned during pre-training interact with input-label examples provided in-context, and (3) how ICL aggregates label information across in-context examples. Our findings suggests LLMs usually incorporate information from in-context labels, but that pre-training and in-context label relationships are treated differently, and that the model does not consider all in-context information equally. Our results give insights into underst
    
[^113]: UniTabE: 面向异构表格数据的统一预训练表格编码器

    UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data. (arXiv:2307.09249v1 [cs.LG])

    [http://arxiv.org/abs/2307.09249](http://arxiv.org/abs/2307.09249)

    UniTabE是一种面向异构表格数据的统一预训练表格编码器，能够处理不同表格结构的挑战，并具有对多样化下游应用的适应性。

    

    自然语言处理（NLP）的最新进展明证了预训练模型的突破性影响，在各种任务上取得了令人印象深刻的结果。本研究旨在将预训练方法的威力扩展到传统被忽视的表格数据领域，该领域由于不同任务固有的众多表格模式而具有挑战性。本工作的主要研究问题围绕异构表格结构的适应性、表格数据的统一预训练协议的建立、学到的知识在任务之间的泛化和可传递性、对多样化下游应用的适应性以及随时间的增量列的纳入进行了探讨。针对这些挑战，我们引入了UniTabE，这是一种创新的方法，旨在以一致的方式处理表格，摆脱了特定表格结构强加的约束。UniTabE的核心概念是对每个基本表格进行表示

    Recent advancements in Natural Language Processing (NLP) have witnessed the groundbreaking impact of pretrained models, yielding impressive outcomes across various tasks. This study seeks to extend the power of pretraining methodologies to tabular data, a domain traditionally overlooked, yet inherently challenging due to the plethora of table schemas intrinsic to different tasks. The primary research questions underpinning this work revolve around the adaptation to heterogeneous table structures, the establishment of a universal pretraining protocol for tabular data, the generalizability and transferability of learned knowledge across tasks, the adaptation to diverse downstream applications, and the incorporation of incremental columns over time. In response to these challenges, we introduce UniTabE, a pioneering method designed to process tables in a uniform manner, devoid of constraints imposed by specific table structures. UniTabE's core concept relies on representing each basic tab
    
[^114]: 记忆还是忘却？深入探讨语言模型的知识记忆机制

    Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism of Language Models. (arXiv:2305.09144v1 [cs.CL])

    [http://arxiv.org/abs/2305.09144](http://arxiv.org/abs/2305.09144)

    本论文研究了语言模型的记忆机制，发现预训练可以有效提高模型的记忆能力，而知识相关性和多样性对于记忆形成也有显著影响。

    

    记忆是最基本的认知功能之一，是存储世界知识和活动经历的储藏库。近年来，大规模预训练语言模型展现出卓越的记忆能力。相反，没有预训练的神经网络长期以来一直存在灾难性遗忘问题。为了研究这种保持-遗忘的矛盾并了解语言模型的记忆机制，我们通过控制目标知识类型、学习策略和学习时间表等，开展了深入的实验研究。结果发现：1）传统语言模型是容易遗忘的；2）预训练可以使语言模型具有记忆能力；3）知识相关性和多样性显著影响记忆形成。这些结论有助于理解预训练语言模型的能力，并为设计和评估新的语言模型学习方法和推理算法提供了启示。

    Memory is one of the most essential cognitive functions serving as a repository of world knowledge and episodes of activities. In recent years, large-scale pre-trained language models have shown remarkable memorizing ability. On the contrary, vanilla neural networks without pre-training have been long observed suffering from the catastrophic forgetting problem. To investigate such a retentive-forgetful contradiction and understand the memory mechanism of language models, we conduct thorough experiments by controlling the target knowledge types, the learning strategies and the learning schedules. We find that: 1) Vanilla language models are forgetful; 2) Pre-training leads to retentive language models; 3) Knowledge relevance and diversification significantly influence the memory formation. These conclusions are useful for understanding the abilities of pre-trained language models and shed light on designing and evaluating new learning and inference algorithms of language models.
    
[^115]: 两阶段LLM精调方法：更少特化、更多泛化

    Two-stage LLM Fine-tuning with Less Specialization and More Generalization. (arXiv:2211.00635v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.00635](http://arxiv.org/abs/2211.00635)

    预训练的大型语言模型（LLMs）通过精调可以提高特定任务的性能，但精调通常会使模型过度专门化，降低了其在上下文中的泛化学习性能。通过两阶段精调框架ProMoT可以减少这种格式特化。

    

    预训练的大型语言模型（LLM）是适用于各种任务和提示的通用问题解决方案。通过在专门的数据集上进行精调，可以进一步改进其在特定任务上的性能。然而，精调通常使模型在特定数据集上过于专门化，并降低了其在上下文中的泛化学习性能，这在需要处理没有精调数据的其他任务时是不可取的。在这项工作中，我们首先证明了单任务精调确实会降低LLM的泛化学习性能。我们发现这种遗忘的一个重要原因是格式特化，即模型过度拟合于精调任务的格式。我们进一步表明格式特化发生在精调的早期阶段。为了解决这个问题，我们提出了Prompt Tuning with MOdel Tuning (ProMoT)这一简单而有效的两阶段精调框架，可以减少格式特化。

    Pretrained large language models (LLMs) are general purpose problem solvers applicable to a diverse set of tasks with prompts. They can be further improved towards a specific task by fine-tuning on a specialized dataset. However, fine-tuning usually makes the model narrowly specialized on this dataset with reduced general in-context learning performances, which is undesirable whenever the fine-tuned model needs to handle additional tasks where no fine-tuning data is available. In this work, we first demonstrate that fine-tuning on a single task indeed decreases LLMs' general in-context learning performance. We discover one important cause of such forgetting, format specialization, where the model overfits to the format of the fine-tuned task. We further show that format specialization happens at the very beginning of fine-tuning. To solve this problem, we propose Prompt Tuning with MOdel Tuning (ProMoT), a simple yet effective two-stage fine-tuning framework that reduces format special
    
[^116]: 量子密度矩阵在经典问答和图像分类中的应用

    Application of Quantum Density Matrix in Classical Question Answering and Classical Image Classification. (arXiv:2203.11155v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.11155](http://arxiv.org/abs/2203.11155)

    该论文将量子密度矩阵应用于经典问答和图像分类中，证明了其可以提高任务的效率，尤其在图像分类中取得了优秀的性能表现。

    

    量子密度矩阵可表示整个量子系统的全部信息，将密度矩阵用于经典问答任务可以更加有效地实现问题回答。本论文设计了一种基于LSTM的新机制，以应对输入为矩阵的情况，并将该机制应用于卷积神经网络进行QA问题的求解，同时也证明了量子密度矩阵可以增强经典图像分类中的特征信息和特征之间的关系。实验结果表明，该新框架在CIFAR-10数据集上的性能优于传统的基于CNN的分类方法。

    Quantum density matrix represents all the information of the entire quantum system, and novel models of meaning employing density matrices naturally model linguistic phenomena such as hyponymy and linguistic ambiguity, among others in quantum question answering tasks. Naturally, we argue that applying the quantum density matrix into classical Question Answering (QA) tasks can show more effective performance. Specifically, we (i) design a new mechanism based on Long Short-Term Memory (LSTM) to accommodate the case when the inputs are matrixes; (ii) apply the new mechanism to QA problems with Convolutional Neural Network (CNN) and gain the LSTM-based QA model with the quantum density matrix. Experiments of our new model on TREC-QA and WIKI-QA data sets show encouraging results. Similarly, we argue that the quantum density matrix can also enhance the image feature information and the relationship between the features for the classical image classification. Thus, we (i) combine density mat
    

