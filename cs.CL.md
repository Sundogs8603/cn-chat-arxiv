# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Scaling Expert Language Models with Unsupervised Domain Discovery.](http://arxiv.org/abs/2303.14177) | 该论文提出了一种用于扩展专家语言模型的简单而有效的方法，使用无监督的领域发现来自动化训练并消除通信开销，通过将语料库聚类成相关文档集来训练单独的专家语言模型，并将它们组合成一个稀疏的集合进行推理。 |
| [^2] | [The crime of being poor.](http://arxiv.org/abs/2303.14128) | 本文使用自然语言处理技术在Twitter中分析了八个英语国家对贫穷与犯罪之间关联的社会偏见水平，结果显示出了对最弱势群体的集体偏见。 |
| [^3] | [Improving Prediction Performance and Model Interpretability through Attention Mechanisms from Basic and Applied Research Perspectives.](http://arxiv.org/abs/2303.14116) | 这篇论文总结了作者关于注意力机制在提高深度学习模型解释性和性能中的潜力。这是基础与应用研究的重要问题，尤其在医学领域，而注意力机制可以成为解决这个问题的一种方法。 |
| [^4] | [ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge.](http://arxiv.org/abs/2303.14070) | 本文介绍了一种在医学领域利用LLaMA模型微调的医疗聊天模型ChatDoctor。经过700多种疾病和其相应症状、药品和医疗检查的收集和处理，这种模型具有理解患者需求、提供建议和帮助的潜力。这些先进的语言模型集成到医疗保健中可以极大地改进医疗专业人员和患者的沟通方式。 |
| [^5] | [SPEC: Summary Preference Decomposition for Low-Resource Abstractive Summarization.](http://arxiv.org/abs/2303.14011) | 本文提出了一种低资源抽象文摘的总结偏好分解的方法，以在只有少量示例的情况下学习生成器。其中，以预训练的语言模型为基础，提出了一种元学习框架，将少量样本的学习过程从源语料库转移到目标语料库。 |
| [^6] | [Paraphrase Detection: Human vs. Machine Content.](http://arxiv.org/abs/2303.13989) | 本研究分析了不同数据集和检测方法，对人类和机器释义内容进行了比较，发现人类释义难度、多样性和相似性超过机器释义，机器生成的数据集不足。Transformer 是最有效的检测方法，而 SVM-based 方法不及 BERT 和 RoBERTa 变体。 |
| [^7] | [Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods.](http://arxiv.org/abs/2303.13988) | 本文提出了一种新领域——机器心理学，利用心理学的方法考察大型语言模型的能力。该文规范了机器心理学研究的方法论标准，并对心理实验中提示设计政策进行了探讨和制定。 |
| [^8] | [MUG: A General Meeting Understanding and Generation Benchmark.](http://arxiv.org/abs/2303.13939) | 本文建立了一个通用的会议理解和生成基准(MUG)，以评估一系列自然语言处理任务的性能，为口语语言处理技术的发展提供支持 |
| [^9] | [Overview of the ICASSP 2023 General Meeting Understanding and Generation Challenge (MUG).](http://arxiv.org/abs/2303.13932) | ICASSP 2023年将举行总会理解与生成挑战赛，希望通过该挑战赛促进SLP研究的发展，挑战赛包括五个跟踪项目，发起了大规模会议数据集AliMeeting4MUG Corpus。 |
| [^10] | [$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference.](http://arxiv.org/abs/2303.13824) | 本文提出$k$NN提示，一种不需要校准就可以推理最近相邻的算法，用来解决上下文学习的限制和偏见问题，显着优于最先进的方法。 |
| [^11] | [Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT.](http://arxiv.org/abs/2303.13809) | 本文提出一种新的提示方法Error Analysis Prompting可改善LLMs在机器翻译质量评估上的性能，实现人类水平的评估。 |
| [^12] | [Toward Open-domain Slot Filling via Self-supervised Co-training.](http://arxiv.org/abs/2303.13801) | 本文提出了一种名为SCot的自监督协同训练框架，通过使用BERT模型和伪标签，实现开放域槽填充任务的零样本学习，克服了传统监督学习方法需要大量手动标注数据的问题。 |
| [^13] | [Personalizing Task-oriented Dialog Systems via Zero-shot Generalizable Reward Function.](http://arxiv.org/abs/2303.13797) | 本研究提出了一种个性化任务导向对话系统的新框架P-ToD，它使用零-shot泛化奖励函数进行无监督训练，并取得了优于现有技术的实验结果。 |
| [^14] | [Towards Making the Most of ChatGPT for Machine Translation.](http://arxiv.org/abs/2303.13780) | 本文提出了任务和领域特定提示来优化ChatGPT在复杂机器翻译任务中的表现，研究发现温度设置和任务信息对ChatGPT表现有显著影响。 |
| [^15] | [Natural language processing to automatically extract the presence and severity of esophagitis in notes of patients undergoing radiotherapy.](http://arxiv.org/abs/2303.13722) | 本文使用自然语言处理技术，针对放疗患者的临床记录，自动提取食管炎的存在和严重程度，为研究毒性反应提供可能。 |
| [^16] | [ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation.](http://arxiv.org/abs/2303.13716) | 本文研究了合成通用基准的局限性，发现逻辑形式（LF）的细节可能影响模型性能。作者对COGS基准进行了研究，结果表明基础模型能够获得足够的掌握。作者还强调了设计能准确捕捉自然语言语义的LF的重要性。 |
| [^17] | [Mordecai 3: A Neural Geoparser and Event Geocoder.](http://arxiv.org/abs/2303.13675) | Mordecai 3是一个神经网络地理解析和事件地理编码系统，使用新的神经排名模型解决从文档中提取的地名，并使用现成的问答模型执行事件地理编码。它以Mordecai 3的形式提供给用户作为一个开源Python库。 |
| [^18] | [ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction Benchmark.](http://arxiv.org/abs/2303.13648) | 评估发现，在语法错误修正中，ChatGPT的表现不如商业和最先进的基线模型，但是ChatGPT更喜欢用改变表达方式来保持语法正确性的方式进行修正并且过修正的问题较多。 |
| [^19] | [In-depth analysis of music structure as a self-organized network.](http://arxiv.org/abs/2303.13631) | 本文介绍了一种利用Essential Element Network (EEN)算法将音频编码成文本并进行相关性计算和优化应用于聚类系数的频率和排名的方法，得到了音乐的深层结构信息，为厘清音乐结构提供了新方法。 |
| [^20] | [Authorship attribution for Differences between Literary Texts by Bilingual Russian-French and Non-Bilingual French Authors.](http://arxiv.org/abs/2303.13622) | 本文旨在利用SVM、KNN、岭分类、神经网络等方法探究双语俄法作家与非双语法国作家的文学作品在风格、语言干扰上的差异。 |
| [^21] | [Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages.](http://arxiv.org/abs/2303.13592) | 本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。 |
| [^22] | [Return of the RNN: Residual Recurrent Networks for Invertible Sentence Embeddings.](http://arxiv.org/abs/2303.13570) | 本研究提出了一种使用残差循环神经网络的新型模型，实现了可逆的句子嵌入。与其他神经机器翻译模型不同，该方法使用基于回归的输出层重建输入序列的单词向量，其具有高准确度和快速训练速度。这种方法适合各种自然语言处理应用，特别是对需要高质量句嵌入的神经网络系统的使用具有潜在优势。 |
| [^23] | [Enhancing Unsupervised Speech Recognition with Diffusion GANs.](http://arxiv.org/abs/2303.13559) | 本论文提出了一种基于扩散GAN的增强方法，可用于无监督语音识别任务，实验结果表明该方法在多个数据集上都取得了良好的效果。 |
| [^24] | [Optical Character Recognition and Transcription of Berber Signs from Images in a Low-Resource Language Amazigh.](http://arxiv.org/abs/2303.13549) | 本文介绍了一种名为DaToBS的方法，用于从自然环境中的照片中检测和转录Tifinagh字符，以提高非洲低资源语言阿马齐语在教育、研究和网络应用等方面的支持。 |
| [^25] | [A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability.](http://arxiv.org/abs/2303.13547) | 本文对ChatGPT的Text-to-SQL能力进行了全面的评估，展示其强大的零-shot表现，尤其在ADVETA(RPL)情境下优于需要微调的SOTA模型，有望在实际应用中发挥潜力。 |
| [^26] | [GETT-QA: Graph Embedding based T2T Transformer for Knowledge Graph Question Answering.](http://arxiv.org/abs/2303.13284) | 本论文提出了GETT-QA系统，该系统使用T5对自然语言问题生成简化的SPARQL查询，并使用截断的KG嵌入提高了知识图谱问答的性能。 |
| [^27] | [Fillers in Spoken Language Understanding: Computational and Psycholinguistic Perspectives.](http://arxiv.org/abs/2301.10761) | 本文综述了口语理解中填充语的研究视角，包括心理语言学理论、自动语音识别和SLU系统中的注释与考虑、以及生成角度的研究等，并探讨了每个领域的趋势和挑战。 |
| [^28] | [One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER.](http://arxiv.org/abs/2301.10410) | 本论文提出了基于协作域前缀调整的跨领域实体识别，使用文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务，避免了先前的为每个领域结束一个全新的NER模型的问题。 |
| [^29] | [Emergent Analogical Reasoning in Large Language Models.](http://arxiv.org/abs/2212.09196) | GPT-3在许多类比任务中表现出与甚至超越人类的能力，揭示了大型语言模型的紧急能力。 |
| [^30] | [POTATO: The Portable Text Annotation Tool.](http://arxiv.org/abs/2212.08620) | POTATO是一个免费、开源的便携式文本注释工具，支持多种类型的文本和多模态数据的标注，提供易于配置的功能以最大化生产力，特别是对于长文档和复杂任务。 |
| [^31] | [Open-world Story Generation with Structured Knowledge Enhancement: A Comprehensive Survey.](http://arxiv.org/abs/2212.04634) | 本文对结构化知识增强的故事生成进行了综述，总结了目前的方法与技术，指出了未来的发展方向和尚未解决的问题。 |
| [^32] | [Mathematically Modeling the Lexicon Entropy of Emergent Language.](http://arxiv.org/abs/2211.15783) | 本文提出了一种随机过程 FiLex 作为深度学习新兴语言系统中词汇熵的数学模型，该模型可以正确预测超参数与新兴语言熵之间的相关性，为研究新兴语言带来新的方法。 |
| [^33] | [When and why vision-language models behave like bags-of-words, and what to do about it?.](http://arxiv.org/abs/2210.01936) | 针对大型视觉语言模型在编码组合信息方面的表现存在问题，我们创建了Attribution、Relation和Order（ARO）基准，并提出了对VLMs进行Attention机制和对抗训练等修改以提高其组合理解能力。 |
| [^34] | [Measuring Causal Effects of Data Statistics on Language Model's `Factual' Predictions.](http://arxiv.org/abs/2207.14251) | 本文提供了一个因果框架，描述了数据统计对预训练语言模型的“事实性”预测的影响。结果表明，PLMs的预测受到这些统计的影响，暗示这样的模型依赖于浅显的启发式策略。 |
| [^35] | [Penguins Don't Fly: Reasoning about Generics through Instantiations and Exceptions.](http://arxiv.org/abs/2205.11658) | 本文提出了一个基于语言学理论的框架，通过生成具体情况的实例，解决了泛化问题中的例外和普遍性的挑战，并在650个泛型上比GPT-3基线高出12.8个精度点。 |
| [^36] | [DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing.](http://arxiv.org/abs/2111.09543) | 本论文介绍了一种新的预训练语言模型DeBERTaV3，使用更加样本有效的替换令牌检测（RTD）取代了掩码语言建模（MLM）并提出了一种新的梯度去耦合嵌入共享方法，避免了“拔河”动态，提高了预训练模型的训练效率和质量。在多个下游自然语言理解任务中，DeBERTaV3表现出优秀的性能。 |

# 详细

[^1]: 用无监督的领域发现方法扩展专家语言模型

    Scaling Expert Language Models with Unsupervised Domain Discovery. (arXiv:2303.14177v1 [cs.CL])

    [http://arxiv.org/abs/2303.14177](http://arxiv.org/abs/2303.14177)

    该论文提出了一种用于扩展专家语言模型的简单而有效的方法，使用无监督的领域发现来自动化训练并消除通信开销，通过将语料库聚类成相关文档集来训练单独的专家语言模型，并将它们组合成一个稀疏的集合进行推理。

    

    大型语言模型通常进行密集训练：所有参数均对所有输入进行更新。这要求在数千个GPU之间同步数十亿个参数。我们引入了一种简单而有效的方法，能够异步地在任意文本语料库上训练大型稀疏语言模型。我们的方法将一个语料库聚类成相关文档集，对每个集群训练一个单独的专家语言模型，然后在推理时将它们组合成稀疏的集合。这种方法通过自动发现每个专家的领域来推广了尴尬平行训练，并消除了现有稀疏语言模型中几乎所有的通信开销。我们的技术在多个语料库和少量训练任务上优于密集基线，并且我们的分析表明将专家特化到有意义的集群是取得这些增益的关键。性能还随着专家数量和训练数据的大小而提高，这表明这是一种高效且可访问的缩放专家语言模型的方法。

    Large language models are typically trained densely: all parameters are updated with respect to all inputs. This requires synchronization of billions of parameters across thousands of GPUs. We introduce a simple but effective method to asynchronously train large, sparse language models on arbitrary text corpora. Our method clusters a corpus into sets of related documents, trains a separate expert language model on each cluster, and combines them in a sparse ensemble for inference. This approach generalizes embarrassingly parallel training by automatically discovering the domains for each expert, and eliminates nearly all the communication overhead of existing sparse language models. Our technique outperforms dense baselines on multiple corpora and few-shot tasks, and our analysis shows that specializing experts to meaningful clusters is key to these gains. Performance also improves with the number of experts and size of training data, suggesting this is a highly efficient and accessibl
    
[^2]: 贫穷的罪行

    The crime of being poor. (arXiv:2303.14128v1 [cs.CL])

    [http://arxiv.org/abs/2303.14128](http://arxiv.org/abs/2303.14128)

    本文使用自然语言处理技术在Twitter中分析了八个英语国家对贫穷与犯罪之间关联的社会偏见水平，结果显示出了对最弱势群体的集体偏见。

    

    贫穷犯罪化一直被公认为是一种对最弱势群体的集体偏见。NGO和国际组织声称，穷人因其处境而受到指责，与刑事犯罪的触发因素的关联性比富人更高，甚至只是因为贫穷而犯罪。然而，文献中没有找到贫穷与整体犯罪率之间的相关证据，本文利用自然语言处理技术在Twitter中量化了在八个英语国家面板中，犯罪和贫穷之间的社会偏见水平，并测量了该观念的程度。根据文献相关的不同水平的不平等或失业，不足以证明在犯罪和贫穷之间的联想所呈现出的区域性差异。

    The criminalization of poverty has been widely denounced as a collective bias against the most vulnerable. NGOs and international organizations claim that the poor are blamed for their situation, are more often associated with criminal offenses than the wealthy strata of society and even incur criminal offenses simply as a result of being poor. While no evidence has been found in the literature that correlates poverty and overall criminality rates, this paper offers evidence of a collective belief that associates both concepts. This brief report measures the societal bias that correlates criminality with the poor, as compared to the rich, by using Natural Language Processing (NLP) techniques in Twitter. The paper quantifies the level of crime-poverty bias in a panel of eight different English-speaking countries. The regional differences in the association between crime and poverty cannot be justified based on different levels of inequality or unemployment, which the literature correlat
    
[^3]: 从基础与应用研究视角提高预测性能和模型可解释性：注意力机制

    Improving Prediction Performance and Model Interpretability through Attention Mechanisms from Basic and Applied Research Perspectives. (arXiv:2303.14116v1 [cs.LG])

    [http://arxiv.org/abs/2303.14116](http://arxiv.org/abs/2303.14116)

    这篇论文总结了作者关于注意力机制在提高深度学习模型解释性和性能中的潜力。这是基础与应用研究的重要问题，尤其在医学领域，而注意力机制可以成为解决这个问题的一种方法。

    

    随着深度学习技术的快速发展，机器学习研究关注于提高模型预测的可解释性和性能，涵盖基础与应用研究的各个领域。虽然深度学习模型比传统机器学习模型具有更高的预测性能，但具体预测过程仍难以解释和说明，这被称为机器学习模型的黑盒化，并被广泛认为是许多研究领域的一个特别重要的问题，包括制造业、商业、机器人和其他行业等普遍使用该技术，以及医学领域，在这些领域中错误是不可容忍的。本文基于作者论文的摘要，该论文的核心研究关注于近年来备受关注的注意力机制，并探讨了其在基础研究和应用研究中的潜力。

    With the dramatic advances in deep learning technology, machine learning research is focusing on improving the interpretability of model predictions as well as prediction performance in both basic and applied research. While deep learning models have much higher prediction performance than traditional machine learning models, the specific prediction process is still difficult to interpret and/or explain. This is known as the black-boxing of machine learning models and is recognized as a particularly important problem in a wide range of research fields, including manufacturing, commerce, robotics, and other industries where the use of such technology has become commonplace, as well as the medical field, where mistakes are not tolerated. This bulletin is based on the summary of the author's dissertation. The research summarized in the dissertation focuses on the attention mechanism, which has been the focus of much attention in recent years, and discusses its potential for both basic res
    
[^4]: ChatDoctor：使用医学领域知识在LLaMA模型上微调的医疗聊天模型

    ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge. (arXiv:2303.14070v1 [cs.CL])

    [http://arxiv.org/abs/2303.14070](http://arxiv.org/abs/2303.14070)

    本文介绍了一种在医学领域利用LLaMA模型微调的医疗聊天模型ChatDoctor。经过700多种疾病和其相应症状、药品和医疗检查的收集和处理，这种模型具有理解患者需求、提供建议和帮助的潜力。这些先进的语言模型集成到医疗保健中可以极大地改进医疗专业人员和患者的沟通方式。

    

    最近，在一般领域中应用的大型语言模型（LLM），例如ChatGPT，已经表现出仿佛是人类讲话般的成功。然而，这样的语言模型并没有经过个别且仔细为医学领域学习，导致诊断准确度低且不能给出正确的医疗诊断、药品等建议。为了解决这个问题，我们收集了700多种疾病及其相应症状、推荐药品和所需医疗检查，然后生成了5K名医患的对话。通过微调医患对话模型，这些模型具有了理解患者需求、提供明智建议并在各种医疗相关领域提供宝贵帮助的巨大潜力。将这些先进的语言模型集成到医疗保健中，可以彻底改变医疗专业人员和患者的沟通方式，最终改善整体质量。

    Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses. However, such language models have not been learned individually and carefully for the medical domain, resulting in poor diagnostic accuracy and inability to give correct recommendations for medical diagnosis, medications, etc. To address this issue, we collected more than 700 diseases and their corresponding symptoms, recommended medications, and required medical tests, and then generated 5K doctor-patient conversations. By fine-tuning models of doctor-patient conversations, these models emerge with great potential to understand patients' needs, provide informed advice, and offer valuable assistance in a variety of medical-related fields. The integration of these advanced language models into healthcare can revolutionize the way healthcare professionals and patients communicate, ultimately improving the overall quality 
    
[^5]: SPEC: 低资源抽象文摘的总结偏好分解

    SPEC: Summary Preference Decomposition for Low-Resource Abstractive Summarization. (arXiv:2303.14011v1 [cs.CL])

    [http://arxiv.org/abs/2303.14011](http://arxiv.org/abs/2303.14011)

    本文提出了一种低资源抽象文摘的总结偏好分解的方法，以在只有少量示例的情况下学习生成器。其中，以预训练的语言模型为基础，提出了一种元学习框架，将少量样本的学习过程从源语料库转移到目标语料库。

    

    神经抽象摘要已经被广泛研究，并在大规模语料库中取得了巨大成功。 然而，注释数据的相当高的成本促使我们需要在低资源环境下学习策略。 本文研究了只有少量示例情况下学习摘要生成器的问题，并提出了相应的改进方法。

    Neural abstractive summarization has been widely studied and achieved great success with large-scale corpora. However, the considerable cost of annotating data motivates the need for learning strategies under low-resource settings. In this paper, we investigate the problems of learning summarizers with only few examples and propose corresponding methods for improvements. First, typical transfer learning methods are prone to be affected by data properties and learning objectives in the pretext tasks. Therefore, based on pretrained language models, we further present a meta learning framework to transfer few-shot learning processes from source corpora to the target corpus. Second, previous methods learn from training examples without decomposing the content and preference. The generated summaries could therefore be constrained by the preference bias in the training set, especially under low-resource settings. As such, we propose decomposing the contents and preferences during learning th
    
[^6]: 人类与机器内容的释义检测比较研究

    Paraphrase Detection: Human vs. Machine Content. (arXiv:2303.13989v1 [cs.CL])

    [http://arxiv.org/abs/2303.13989](http://arxiv.org/abs/2303.13989)

    本研究分析了不同数据集和检测方法，对人类和机器释义内容进行了比较，发现人类释义难度、多样性和相似性超过机器释义，机器生成的数据集不足。Transformer 是最有效的检测方法，而 SVM-based 方法不及 BERT 和 RoBERTa 变体。

    

    大型语言模型（如 GPT-4 和 ChatGPT）日益重要，但也引起了学术诚信问题，因为存在机器生成的内容和释义。虽然有研究探讨了人类和机器释义内容的检测，但这些类型内容之间的比较仍未得到广泛研究。本文对常用的各种数据集进行了全面分析，并评估了各种检测方法。我们的研究发现，相对于机器生成的数据集缺乏，现有的评估方法在不同数据集上表现各有优劣。我们的主要发现是，人类释义超过机器释义的难度、多样性和相似性，暗示自动生成的文本还没有达到人类水平。Transformer 是最有效的检测方法，BERT 和 RoBERTa 变体在所有数据集上都取得了显著的结果，而基于 SVM 的方法则落后于它们。

    The growing prominence of large language models, such as GPT-4 and ChatGPT, has led to increased concerns over academic integrity due to the potential for machine-generated content and paraphrasing. Although studies have explored the detection of human- and machine-paraphrased content, the comparison between these types of content remains underexplored. In this paper, we conduct a comprehensive analysis of various datasets commonly employed for paraphrase detection tasks and evaluate an array of detection methods. Our findings highlight the strengths and limitations of different detection methods in terms of performance on individual datasets, revealing a lack of suitable machine-generated datasets that can be aligned with human expectations. Our main finding is that human-authored paraphrases exceed machine-generated ones in terms of difficulty, diversity, and similarity implying that automatically generated texts are not yet on par with human-level performance. Transformers emerged a
    
[^7]: 机器心理学：利用心理学方法探究大型语言模型的新兴能力和行为

    Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods. (arXiv:2303.13988v1 [cs.CL])

    [http://arxiv.org/abs/2303.13988](http://arxiv.org/abs/2303.13988)

    本文提出了一种新领域——机器心理学，利用心理学的方法考察大型语言模型的能力。该文规范了机器心理学研究的方法论标准，并对心理实验中提示设计政策进行了探讨和制定。

    

    大型语言模型（LLM）是将人工智能系统与人类交流和日常生活紧密结合的先锋。由于快速技术进步和其极高的通用性，现今LLM已经拥有数百万用户，并正处于成为主要信息检索、内容生成、问题解决等技术的前沿。因此，对其进行全面评估和审查显得尤为重要。由于当前LLM中出现愈加复杂和新颖的行为模式，可将其视为参与人类心理实验的对象，以便更为全面地评估其能力。为此，本文引入了一个名为"机器心理学"的新兴研究领域。本文概述了各类心理学分支如何为LLM的行为测试提供有用参考。同时，本文规范了机器心理学研究的方法论标准，特别是专注于提示设计政策的制定。此外，它还描述了行为测试结果如何为未来的LLM发展提供指导。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Due to rapid technological advances and their extreme versatility, LLMs nowadays have millions of users and are at the cusp of being the main go-to technology for information retrieval, content generation, problem-solving, etc. Therefore, it is of great importance to thoroughly assess and scrutinize their capabilities. Due to increasingly complex and novel behavioral patterns in current LLMs, this can be done by treating them as participants in psychology experiments that were originally designed to test humans. For this purpose, the paper introduces a new field of research called "machine psychology". The paper outlines how different subfields of psychology can inform behavioral tests for LLMs. It defines methodological standards for machine psychology research, especially by focusing on policies for prompt designs. Additionally, it describes how behaviora
    
[^8]: MUG: 一项通用的会议理解与生成基准

    MUG: A General Meeting Understanding and Generation Benchmark. (arXiv:2303.13939v1 [cs.CL])

    [http://arxiv.org/abs/2303.13939](http://arxiv.org/abs/2303.13939)

    本文建立了一个通用的会议理解和生成基准(MUG)，以评估一系列自然语言处理任务的性能，为口语语言处理技术的发展提供支持

    

    听取视频会议和在线课程的长时间音频记录以获取信息极为低效。即使自动语音识别系统将记录转录为长形式的口语语言文档，仅阅读语音识别转录也只能在一定程度上加快寻找信息的速度。研究表明，关键词提取、主题分割和摘要等一系列自然语言处理应用显著提高用户获得重要信息的效率。会议场景是应用这些口语语言处理能力最有价值的场景之一。然而，缺乏大规模公开的会议数据集对这些自然语言处理任务的进展产生了严重阻碍。为了促进自然语言处理技术的发展，我们建立了一个大规模的通用会议理解和生成基准(MUG)，以评估一系列自然语言处理任务的性能，包括主题分割、话题级别和会话级别的摘要提取等。

    Listening to long video/audio recordings from video conferencing and online courses for acquiring information is extremely inefficient. Even after ASR systems transcribe recordings into long-form spoken language documents, reading ASR transcripts only partly speeds up seeking information. It has been observed that a range of NLP applications, such as keyphrase extraction, topic segmentation, and summarization, significantly improve users' efficiency in grasping important information. The meeting scenario is among the most valuable scenarios for deploying these spoken language processing (SLP) capabilities. However, the lack of large-scale public meeting datasets annotated for these SLP tasks severely hinders their advancement. To prompt SLP advancement, we establish a large-scale general Meeting Understanding and Generation Benchmark (MUG) to benchmark the performance of a wide range of SLP tasks, including topic segmentation, topic-level and session-level extractive summarization and 
    
[^9]: ICASSP 2023年总会理解与生成挑战赛（MUG）概述 (arXiv：2303.13932v1 [cs.CL])

    Overview of the ICASSP 2023 General Meeting Understanding and Generation Challenge (MUG). (arXiv:2303.13932v1 [cs.CL])

    [http://arxiv.org/abs/2303.13932](http://arxiv.org/abs/2303.13932)

    ICASSP 2023年将举行总会理解与生成挑战赛，希望通过该挑战赛促进SLP研究的发展，挑战赛包括五个跟踪项目，发起了大规模会议数据集AliMeeting4MUG Corpus。

    

    ICASSP2023年总会理解与生成挑战赛（MUG）旨在促进针对会议记录的广泛口语语言处理（SLP）研究，因为SLP应用对于提高用户在会议中抓住重要信息的效率至关重要。MUG包括五个跟踪项目，包括主题分割、主题级和会话级的提取性摘要、主题标题生成、关键短语提取和动作项检测。为了方便MUG，我们构建了并发布了大规模会议数据集AliMeeting4MUG Corpus。

    ICASSP2023 General Meeting Understanding and Generation Challenge (MUG) focuses on prompting a wide range of spoken language processing (SLP) research on meeting transcripts, as SLP applications are critical to improve users' efficiency in grasping important information in meetings. MUG includes five tracks, including topic segmentation, topic-level and session-level extractive summarization, topic title generation, keyphrase extraction, and action item detection. To facilitate MUG, we construct and release a large-scale meeting dataset, the AliMeeting4MUG Corpus.
    
[^10]: $k$NN提示：无需校准的最近相邻推理，超越上下文学习

    $k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference. (arXiv:2303.13824v1 [cs.CL])

    [http://arxiv.org/abs/2303.13824](http://arxiv.org/abs/2303.13824)

    本文提出$k$NN提示，一种不需要校准就可以推理最近相邻的算法，用来解决上下文学习的限制和偏见问题，显着优于最先进的方法。

    

    在上下文学习中，将目标任务制定为在上下文演示的条件下完成提示完成，已成为LLM的主要用途。本文首先披露了这种典型用法的实际问题，由于上下文长度的限制，它无法随着训练数据扩展。此外，现有的研究表明，ICL还受到各种偏见的影响，并需要精细的校准处理。为了解决这两个挑战，我们提出了一种简单有效的解决方案，$k$NN提示，它首先使用训练数据查询LLM的分布式表示，然后通过简单地参考最近邻来预测测试实例。我们进行了全面的实验来证明其优越性：1）无需校准：$k$NN提示不直接将LLM输出分布与特定任务标签空间对准，而是利用这种分布将测试和训练实例对准。它显着优于最先进的方法。

    In-Context Learning (ICL), which formulates target tasks as prompt completion conditioned on in-context demonstrations, has become the prevailing utilization of LLMs. In this paper, we first disclose an actual predicament for this typical usage that it can not scale up with training data due to context length restriction. Besides, existing works have shown that ICL also suffers from various biases and requires delicate calibration treatment. To address both challenges, we advocate a simple and effective solution, $k$NN Prompting, which first queries LLM with training data for distributed representations, then predicts test instances by simply referring to nearest neighbors. We conduct comprehensive experiments to demonstrate its two-fold superiority: 1) Calibration-Free: $k$NN Prompting does not directly align LLM output distribution with task-specific label space, instead leverages such distribution to align test and training instances. It significantly outperforms state-of-the-art ca
    
[^11]: 错误分析提示使得大型语言模型在翻译评估方面实现了人类水平：以ChatGPT为例进行案例研究

    Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT. (arXiv:2303.13809v1 [cs.CL])

    [http://arxiv.org/abs/2303.13809](http://arxiv.org/abs/2303.13809)

    本文提出一种新的提示方法Error Analysis Prompting可改善LLMs在机器翻译质量评估上的性能，实现人类水平的评估。

    

    生成式大型语言模型（LLM），例如ChatGPT，在机器翻译、问答、文本摘要和自然语言理解等多个NLP任务上表现出卓越的能力。最近的研究表明，利用ChatGPT评估机器翻译质量在系统水平上取得了最先进的性能，但在段落水平上表现不佳。为了进一步提高LLM在机器翻译质量评估上的性能，我们进行了关于几种提示方法的研究。我们的结果表明，通过将Chain-of-Thoughts和Error Analysis结合起来，一种新的提示方法Error Analysis Prompting，像ChatGPT这样的LLM可以在系统和段落级别上生成人类般的机器翻译评估。此外，我们发现ChatGPT作为机器翻译评估器存在一些局限性，例如在提供单个查询中的多个译文时存在不稳定的评分和偏差。

    Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks such as machine translation, question answering, text summarization, and natural language understanding. Recent research has shown that utilizing ChatGPT for assessing the quality of machine translation (MT) achieves state-of-the-art performance at the system level but performs poorly at the segment level. To further improve the performance of LLMs on MT quality assessment, we conducted an investigation into several prompting methods. Our results indicate that by combining Chain-of-Thoughts and Error Analysis, a new prompting method called \textbf{\texttt{Error Analysis Prompting}}, LLMs like ChatGPT can \textit{generate human-like MT evaluations at both the system and segment level}. Additionally, we discovered some limitations of ChatGPT as an MT evaluator, such as unstable scoring and biases when provided with multiple translations in a single query. Our findings
    
[^12]: 通过自监督协同训练实现开放域槽填充

    Toward Open-domain Slot Filling via Self-supervised Co-training. (arXiv:2303.13801v1 [cs.CL])

    [http://arxiv.org/abs/2303.13801](http://arxiv.org/abs/2303.13801)

    本文提出了一种名为SCot的自监督协同训练框架，通过使用BERT模型和伪标签，实现开放域槽填充任务的零样本学习，克服了传统监督学习方法需要大量手动标注数据的问题。

    

    槽填充是现代会话系统中的关键任务之一。现有大部分文献采用监督学习方法，需要每个新域的标记训练数据。零样本学习和弱监督方法等已表现出替代手动标注的前景，但是这些学习范例在性能方面明显逊于监督学习方法。为了最小化这种性能差距并展示开放域槽填充的可能性，我们提出了一种自监督协同训练框架，称为SCot，它不需要领域内手动标记训练示例并分为三个阶段进行。

    Slot filling is one of the critical tasks in modern conversational systems. The majority of existing literature employs supervised learning methods, which require labeled training data for each new domain. Zero-shot learning and weak supervision approaches, among others, have shown promise as alternatives to manual labeling. Nonetheless, these learning paradigms are significantly inferior to supervised learning approaches in terms of performance. To minimize this performance gap and demonstrate the possibility of open-domain slot filling, we propose a Self-supervised Co-training framework, called SCot, that requires zero in-domain manually labeled training examples and works in three phases. Phase one acquires two sets of complementary pseudo labels automatically. Phase two leverages the power of the pre-trained language model BERT, by adapting it for the slot filling task using these sets of pseudo labels. In phase three, we introduce a self-supervised cotraining mechanism, where both
    
[^13]: 零-shot泛化奖励函数个性化任务导向对话系统

    Personalizing Task-oriented Dialog Systems via Zero-shot Generalizable Reward Function. (arXiv:2303.13797v1 [cs.CL])

    [http://arxiv.org/abs/2303.13797](http://arxiv.org/abs/2303.13797)

    本研究提出了一种个性化任务导向对话系统的新框架P-ToD，它使用零-shot泛化奖励函数进行无监督训练，并取得了优于现有技术的实验结果。

    

    任务导向的对话系统使用户能够使用自然语言完成任务。现有技术的系统无论用户如何，都会用相同的方式回应，但是自定义对话可能会提高采用率和更好的用户体验。构建个性化对话系统是一项重要但具有挑战性的任务，只有少数几项工作面对了这一挑战。大部分现有工作依赖于监督学习方法，并需要每个用户资料进行繁琐和昂贵的标记训练数据。此外，为每个用户档案收集和标记数据几乎是不可能的。在本文中，我们提出了一个新的框架，P-ToD，通过零-shot泛化奖励函数，个性化任务导向的对话系统，适应了广泛的用户资料，以无监督的方式进行。我们的实验结果表明，在基准数据集上，P-ToD在任务成功率和用户满意度方面显著优于现有技术。

    Task-oriented dialog systems enable users to accomplish tasks using natural language. State-of-the-art systems respond to users in the same way regardless of their personalities, although personalizing dialogues can lead to higher levels of adoption and better user experiences. Building personalized dialog systems is an important, yet challenging endeavor and only a handful of works took on the challenge. Most existing works rely on supervised learning approaches and require laborious and expensive labeled training data for each user profile. Additionally, collecting and labeling data for each user profile is virtually impossible. In this work, we propose a novel framework, P-ToD, to personalize task-oriented dialog systems capable of adapting to a wide range of user profiles in an unsupervised fashion using a zero-shot generalizable reward function. P-ToD uses a pre-trained GPT-2 as a backbone model and works in three phases. Phase one performs task-specific training. Phase two kicks 
    
[^14]: 优化ChatGPT在机器翻译中的表现

    Towards Making the Most of ChatGPT for Machine Translation. (arXiv:2303.13780v1 [cs.CL])

    [http://arxiv.org/abs/2303.13780](http://arxiv.org/abs/2303.13780)

    本文提出了任务和领域特定提示来优化ChatGPT在复杂机器翻译任务中的表现，研究发现温度设置和任务信息对ChatGPT表现有显著影响。

    

    ChatGPT在机器翻译中表现出卓越的能力。先前的研究表明，它在高资源语言方面可以达到商业系统相当的结果，但在复杂任务方面（例如低资源和远程语言对翻译）落后。然而，它们通常采用简单的提示，无法充分发挥ChatGPT的能力。本文旨在通过重新审视温度、任务信息和领域信息等几个方面，进一步挖掘ChatGPT的翻译能力，并相应地提出两种（简单但有效的）提示：任务特定提示（TSP）和领域特定提示（DSP）。

    ChatGPT shows remarkable capabilities for machine translation (MT). Several prior studies have shown that it achieves comparable results to commercial systems for high-resource languages, but lags behind in complex tasks, e.g, low-resource and distant-language-pairs translation. However, they usually adopt simple prompts which can not fully elicit the capability of ChatGPT. In this report, we aim to further mine ChatGPT's translation ability by revisiting several aspects: temperature, task information, and domain information, and correspondingly propose two (simple but effective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts (DSP). We show that: 1) The performance of ChatGPT depends largely on temperature, and a lower temperature usually can achieve better performance; 2) Emphasizing the task information further improves ChatGPT's performance, particularly in complex MT tasks; 3) Introducing domain information can elicit ChatGPT's generalization ability and improve i
    
[^15]: 使用自然语言处理自动提取放疗患者临床记录中的食管炎

    Natural language processing to automatically extract the presence and severity of esophagitis in notes of patients undergoing radiotherapy. (arXiv:2303.13722v1 [cs.CL])

    [http://arxiv.org/abs/2303.13722](http://arxiv.org/abs/2303.13722)

    本文使用自然语言处理技术，针对放疗患者的临床记录，自动提取食管炎的存在和严重程度，为研究毒性反应提供可能。

    

    放射治疗（RT）毒性反应会影响患者的生存和生活质量，但研究还不足。现实世界的证据有望改善我们对毒性反应的认识，但毒性信息通常仅存在于临床记录中。本文开发了自然语言处理（NLP）模型，用于从接受胸部 RT 治疗的患者的记录中识别食管炎的存在和严重程度。我们对三个食管炎分类任务进行了统计和预训练 BERT 模型的微调：任务 1）食管炎的存在，任务 2）重度食管炎或否，以及任务 3）无食管炎 vs. 一级 vs. 二三级。我们使用接受食管癌放疗的 345 份患者记录进行了可迁移性测试。使用 PubmedBERT 进行微调取得了最佳性能。任务 1、任务 2 和任务 3 的最佳宏 F1 分别为 0.92、0.82 和 0.74。在微调过程中选择最信息量的记录部分，可将宏 F1 提高超过 2%。银标记数据将宏 F1 提高超过 3 个百分点。

    Radiotherapy (RT) toxicities can impair survival and quality-of-life, yet remain under-studied. Real-world evidence holds potential to improve our understanding of toxicities, but toxicity information is often only in clinical notes. We developed natural language processing (NLP) models to identify the presence and severity of esophagitis from notes of patients treated with thoracic RT. We fine-tuned statistical and pre-trained BERT-based models for three esophagitis classification tasks: Task 1) presence of esophagitis, Task 2) severe esophagitis or not, and Task 3) no esophagitis vs. grade 1 vs. grade 2-3. Transferability was tested on 345 notes from patients with esophageal cancer undergoing RT.  Fine-tuning PubmedBERT yielded the best performance. The best macro-F1 was 0.92, 0.82, and 0.74 for Task 1, 2, and 3, respectively. Selecting the most informative note sections during fine-tuning improved macro-F1 by over 2% for all tasks. Silver-labeled data improved the macro-F1 by over 3
    
[^16]: ReCOGS: 一个逻辑形式的细节如何影响语义解释的评估

    ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation. (arXiv:2303.13716v1 [cs.CL])

    [http://arxiv.org/abs/2303.13716](http://arxiv.org/abs/2303.13716)

    本文研究了合成通用基准的局限性，发现逻辑形式（LF）的细节可能影响模型性能。作者对COGS基准进行了研究，结果表明基础模型能够获得足够的掌握。作者还强调了设计能准确捕捉自然语言语义的LF的重要性。

    

    合成通用基准旨在评估模型是否能够准确地计算新句子的含义，但是用逻辑形式（LF）预测来操作。这引发了一个担忧，即所选择的LF的语义无关的细节可能会塑造模型的性能。我们认为COGS基准（Kim和Linzen，2020）实现了这一关注点。COGS提出了看起来对现有模型来说不可能的通用分割，这可能被视为对这些模型的控诉。然而，我们表明负面结果跟COGS LFs的细节相关。将这些LF转换为语义等效的LF，并分解出与语义解释无关的能力，我们发现即使是基线模型也能获得足够的掌握。最近的COGS LFs无变量翻译表明了类似的结论，但我们观察到这种格式不是语义等效的；它无法准确表示一些COGS的含义。这些发现促进我们对当前的合成通用基准的局限性的理解，并强调设计准确捕捉自然语言语义的LF的重要性。

    Compositional generalization benchmarks seek to assess whether models can accurately compute meanings for novel sentences, but operationalize this in terms of logical form (LF) prediction. This raises the concern that semantically irrelevant details of the chosen LFs could shape model performance. We argue that this concern is realized for the COGS benchmark (Kim and Linzen, 2020). COGS poses generalization splits that appear impossible for present-day models, which could be taken as an indictment of those models. However, we show that the negative results trace to incidental features of COGS LFs. Converting these LFs to semantically equivalent ones and factoring out capabilities unrelated to semantic interpretation, we find that even baseline models get traction. A recent variable-free translation of COGS LFs suggests similar conclusions, but we observe this format is not semantically equivalent; it is incapable of accurately representing some COGS meanings. These findings inform our 
    
[^17]: Mordecai 3: 一种神经文本地理解析和事件地理编码器

    Mordecai 3: A Neural Geoparser and Event Geocoder. (arXiv:2303.13675v1 [cs.CL])

    [http://arxiv.org/abs/2303.13675](http://arxiv.org/abs/2303.13675)

    Mordecai 3是一个神经网络地理解析和事件地理编码系统，使用新的神经排名模型解决从文档中提取的地名，并使用现成的问答模型执行事件地理编码。它以Mordecai 3的形式提供给用户作为一个开源Python库。

    

    Mordecai3 是一个新的端到端文本地理解析和事件地理编码系统。该系统使用新的神经排名模型对从文档中提取的地名进行地名解析，将其解析成Geonames地名词典中的条目。它还使用现成的问答模型执行事件地理编码，即将文本中报告的事件与它们发生的地方联系起来。地址解析模型在现有的多个训练数据集上进行了训练，同时还进行了几千个新的注释示例。本文描述了模型、它的训练过程和与现有地理解析器的性能比较。该系统以开源Python库Mordecai 3的形式提供，取代了先前地理解析器Mordecai v2成为最广泛使用的文本地理解析器之一(Halterman 2017)。

    Mordecai3 is a new end-to-end text geoparser and event geolocation system. The system performs toponym resolution using a new neural ranking model to resolve a place name extracted from a document to its entry in the Geonames gazetteer. It also performs event geocoding, the process of linking events reported in text with the place names where they are reported to occur, using an off-the-shelf question-answering model. The toponym resolution model is trained on a diverse set of existing training data, along with several thousand newly annotated examples. The paper describes the model, its training process, and performance comparisons with existing geoparsers. The system is available as an open source Python library, Mordecai 3, and replaces an earlier geoparser, Mordecai v2, one of the most widely used text geoparsers (Halterman 2017).
    
[^18]: ChatGPT还是Grammarly？在语法错误修正基准测试上评估ChatGPT。

    ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction Benchmark. (arXiv:2303.13648v1 [cs.CL])

    [http://arxiv.org/abs/2303.13648](http://arxiv.org/abs/2303.13648)

    评估发现，在语法错误修正中，ChatGPT的表现不如商业和最先进的基线模型，但是ChatGPT更喜欢用改变表达方式来保持语法正确性的方式进行修正并且过修正的问题较多。

    

    ChatGPT是由OpenAI开发的尖端人工智能语言模型，因其惊人的回答跟进问题的能力而受到了很多关注。本文旨在评估ChatGPT在语法错误修正任务中的表现，并将其与商业GEC产品（例如Grammarly）和最先进的模型（例如GECToR）进行比较。通过在CoNLL2014基准数据集上的测试，我们发现ChatGPT在自动评估指标（如$F_{0.5}$得分）方面的表现不如那些基线，特别是在长句中。我们检查了输出结果，发现ChatGPT不仅进行单个修正，还更喜欢通过改变某些短语或句子结构的表达方式来保持语法上的正确性。人类评估量化地证实了这一点，并表明ChatGPT产生的欠修正或误修正问题较少，但过修正的问题较多。这些结果说明

    ChatGPT is a cutting-edge artificial intelligence language model developed by OpenAI, which has attracted a lot of attention due to its surprisingly strong ability in answering follow-up questions. In this report, we aim to evaluate ChatGPT on the Grammatical Error Correction(GEC) task, and compare it with commercial GEC product (e.g., Grammarly) and state-of-the-art models (e.g., GECToR). By testing on the CoNLL2014 benchmark dataset, we find that ChatGPT performs not as well as those baselines in terms of the automatic evaluation metrics (e.g., $F_{0.5}$ score), particularly on long sentences. We inspect the outputs and find that ChatGPT goes beyond one-by-one corrections. Specifically, it prefers to change the surface expression of certain phrases or sentence structure while maintaining grammatical correctness. Human evaluation quantitatively confirms this and suggests that ChatGPT produces less under-correction or mis-correction issues but more over-corrections. These results demon
    
[^19]: 音乐结构的自组织网络分析

    In-depth analysis of music structure as a self-organized network. (arXiv:2303.13631v1 [cs.SD])

    [http://arxiv.org/abs/2303.13631](http://arxiv.org/abs/2303.13631)

    本文介绍了一种利用Essential Element Network (EEN)算法将音频编码成文本并进行相关性计算和优化应用于聚类系数的频率和排名的方法，得到了音乐的深层结构信息，为厘清音乐结构提供了新方法。

    

    自然语言中的词汇不仅传递信息，还随着文明和人类迁移而演变。音乐也是如此。为了理解音乐背后的复杂结构，我们引入了一个叫做Essential Element Network (EEN)的算法将音频编码成文本。该网络通过计算音调、时间和音量之间的相关性得到，通过优化EEN算法以生成Zipf定律应用于聚类系数的频率和排名，我们可以将语义关系视为词汇并生成它们的映射。我们将这些编码后的词汇映射到音调-时间空间中，有助于我们系统地组织音乐深层结构中的句法。相比于其他深度学习方法的黑盒子特性，我们的算法提供了对音乐背后复杂网络的精确描述。因此，这些过程积累的经验和属性不仅为此类应用提供了新的方法，同时也为许多其他相关领域的研究提供了探索的路径。

    Words in a natural language not only transmit information but also evolve with the development of civilization and human migration. The same is true for music. To understand the complex structure behind the music, we introduced an algorithm called the Essential Element Network (EEN) to encode the audio into text. The network is obtained by calculating the correlations between scales, time, and volume. Optimizing EEN to generate Zipfs law for the frequency and rank of the clustering coefficient enables us to generate and regard the semantic relationships as words. We map these encoded words into the scale-temporal space, which helps us organize systematically the syntax in the deep structure of music. Our algorithm provides precise descriptions of the complex network behind the music, as opposed to the black-box nature of other deep learning approaches. As a result, the experience and properties accumulated through these processes can offer not only a new approach to the applications of
    
[^20]: 双语俄法作家与非双语法国作家文学作品的作者归属问题研究

    Authorship attribution for Differences between Literary Texts by Bilingual Russian-French and Non-Bilingual French Authors. (arXiv:2303.13622v1 [cs.CL])

    [http://arxiv.org/abs/2303.13622](http://arxiv.org/abs/2303.13622)

    本文旨在利用SVM、KNN、岭分类、神经网络等方法探究双语俄法作家与非双语法国作家的文学作品在风格、语言干扰上的差异。

    

    本文使用支持向量机（SVM）、$K$最近邻（KNN）、岭分类、神经网络等方法进行分析，旨在探究双语俄法作家（如安德雷·马金、瓦莱里·阿法纳谢夫、弗拉基米尔·费奥多罗夫斯基、伊戈尔·格兰、卢巴·尤尔戈森）与非双语法国作家的文学作品在风格上的差异，以及在俄罗斯作家的法语作品中是否存在语言干扰现象。

    Do bilingual Russian-French authors of the end of the twentieth century such as Andre\"i Makine, Val\'ery Afanassiev, Vladimir F\'edorovski, Iegor Gran, Luba Jurgenson have common stylistic traits in the novels they wrote in French? Can we distinguish between them and non-bilingual French writers' texts? Is the phenomenon of interference observable in French texts of Russian authors? This paper applies authorship attribution methods including Support Vector Machine (SVM), $K$-Nearest Neighbors (KNN), Ridge classification, and Neural Network to answer these questions.
    
[^21]: 大型语言模型生成混合代码文本的提示：东南亚语言的案例

    Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages. (arXiv:2303.13592v1 [cs.CL])

    [http://arxiv.org/abs/2303.13592](http://arxiv.org/abs/2303.13592)

    本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。

    

    尽管混合代码在世界许多地区是一种常见的语言实践，但收集高质量且低成本的混合代码数据仍然是自然语言处理（NLP）研究的重大挑战。最近大型语言模型（LLMs）的普及迫使人们问：这些系统能用于数据生成吗？在本文中，我们探讨了在一个零-shot的方式下如何提示LLMs为东南亚（SEA）的五种语言（印尼语，马来语，中文，塔加路语，越南语）及克里奥尔语S ingl ish创造混合代码数据。我们发现，ChatGPT显示出最大的潜力，当明确定义“混合代码”术语时，能够68%的时间生成混合代码文本。此外，ChatGPT和InstructGPT（davinci-003）生成S ingl ish文本的表现也值得注意，它们在各种提示下的成功率平均为96%。但是，ChatGPT和InstructGPT的混合代码熟练程度受到词汇选择错误的影响，导致语义不正确的输出。

    While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The proliferation of Large Language Models (LLMs) in recent times compels one to ask: can these systems be used for data generation? In this article, we explore prompting LLMs in a zero-shot manner to create code-mixed data for five languages in South East Asia (SEA) -Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the creole language Singlish. We find that ChatGPT shows the most potential, capable of producing code-mixed text 68% of the time when the term "code-mixing" is explicitly defined. Moreover, both ChatGPT and InstructGPT's (davinci-003) performances in generating Singlish texts are noteworthy, averaging a 96% success rate across a variety of prompts. The code-mixing proficiency of ChatGPT and InstructGPT, however, is dampened by word choice errors that lead to semant
    
[^22]: RNN 的回归：用可逆句嵌入的残差循环神经网络

    Return of the RNN: Residual Recurrent Networks for Invertible Sentence Embeddings. (arXiv:2303.13570v1 [cs.CL])

    [http://arxiv.org/abs/2303.13570](http://arxiv.org/abs/2303.13570)

    本研究提出了一种使用残差循环神经网络的新型模型，实现了可逆的句子嵌入。与其他神经机器翻译模型不同，该方法使用基于回归的输出层重建输入序列的单词向量，其具有高准确度和快速训练速度。这种方法适合各种自然语言处理应用，特别是对需要高质量句嵌入的神经网络系统的使用具有潜在优势。

    

    本研究提出了一种新型模型，使用残差循环神经网络在无监督编码任务上进行训练，以生成可逆的句子嵌入。相比于神经机器翻译模型中常见的概率输出，我们的方法采用基于回归的输出层来重建输入序列的单词向量。该模型在使用 ADAM 优化器进行快速训练的同时，取得了高准确度的结果。我们引入了残差连接和“match drop”技术，即只计算错误单词的梯度。我们的方法在各种自然语言处理应用中表现出潜在优势，特别是在需要高质量句嵌入的神经网络系统中。

    This study presents a novel model for invertible sentence embeddings using a residual recurrent network trained on an unsupervised encoding task. Rather than the probabilistic outputs common to neural machine translation models, our approach employs a regression-based output layer to reconstruct the input sequence's word vectors. The model achieves high accuracy and fast training with the ADAM optimizer, a significant finding given that RNNs typically require memory units, such as LSTMs, or second-order optimization methods. We incorporate residual connections and introduce a "match drop" technique, where gradients are calculated only for incorrect words. Our approach demonstrates potential for various natural language processing applications, particularly in neural network-based systems that require high-quality sentence embeddings.
    
[^23]: 基于扩散GAN的无监督语音识别的增强

    Enhancing Unsupervised Speech Recognition with Diffusion GANs. (arXiv:2303.13559v1 [cs.CL])

    [http://arxiv.org/abs/2303.13559](http://arxiv.org/abs/2303.13559)

    本论文提出了一种基于扩散GAN的增强方法，可用于无监督语音识别任务，实验结果表明该方法在多个数据集上都取得了良好的效果。

    

    我们通过扩散GAN增强了用于无监督自动语音识别(ASR)的普通对抗训练方法。我们的模型(1)注入了强度不同的实例噪声到生成器的输出和未标记的参考文本，这些文本是从带有长度约束的预训练音素语言模型中采样的，(2)请求扩散时间步骤相关的判别器将它们分开，(3)反向传播梯度以更新生成器。在Librispeech(测试干净和测试其他的误差率分别为3.1%和5.6%)、TIMIT和MLS数据集下，与wav2vec-U进行单词/音素错误率比较表明，我们的增强策略是有效的。

    We enhance the vanilla adversarial training method for unsupervised Automatic Speech Recognition (ASR) by a diffusion-GAN. Our model (1) injects instance noises of various intensities to the generator's output and unlabeled reference text which are sampled from pretrained phoneme language models with a length constraint, (2) asks diffusion timestep-dependent discriminators to separate them, and (3) back-propagates the gradients to update the generator. Word/phoneme error rate comparisons with wav2vec-U under Librispeech (3.1% for test-clean and 5.6% for test-other), TIMIT and MLS datasets, show that our enhancement strategies work effectively.
    
[^24]: 从低资源语言阿马齐语的图像中进行Tifinagh字符的光学字符识别和转录

    Optical Character Recognition and Transcription of Berber Signs from Images in a Low-Resource Language Amazigh. (arXiv:2303.13549v1 [cs.CV])

    [http://arxiv.org/abs/2303.13549](http://arxiv.org/abs/2303.13549)

    本文介绍了一种名为DaToBS的方法，用于从自然环境中的照片中检测和转录Tifinagh字符，以提高非洲低资源语言阿马齐语在教育、研究和网络应用等方面的支持。

    

    柏柏尔语是一种低资源的北非土语，在摩洛哥、阿尔及利亚等地的柏柏尔社区中使用自己独特的字母表Tifinagh。这种非洲亚细亚语言是由1400万人使用的，但缺乏足够的教育、研究、网络应用等方面的支持。我们提出了一种DaToBS的有监督方法，用于检测和转录Berber字符，旨在实现从自然环境的照片中自动识别和转录Tifinagh字符。

    The Berber, or Amazigh language family is a low-resource North African vernacular language spoken by the indigenous Berber ethnic group. It has its own unique alphabet called Tifinagh used across Berber communities in Morocco, Algeria, and others. The Afroasiatic language Berber is spoken by 14 million people, yet lacks adequate representation in education, research, web applications etc. For instance, there is no option of translation to or from Amazigh / Berber on Google Translate, which hosts over 100 languages today. Consequently, we do not find specialized educational apps, L2 (2nd language learner) acquisition, automated language translation, and remote-access facilities enabled in Berber. Motivated by this background, we propose a supervised approach called DaToBS for Detection and Transcription of Berber Signs. The DaToBS approach entails the automatic recognition and transcription of Tifinagh characters from signs in photographs of natural environments. This is achieved by sel
    
[^25]: ChatGPT 的零-shot Text-to-SQL 能力的综合评估

    A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability. (arXiv:2303.13547v1 [cs.CL])

    [http://arxiv.org/abs/2303.13547](http://arxiv.org/abs/2303.13547)

    本文对ChatGPT的Text-to-SQL能力进行了全面的评估，展示其强大的零-shot表现，尤其在ADVETA(RPL)情境下优于需要微调的SOTA模型，有望在实际应用中发挥潜力。

    

    本文首次全面分析了 ChatGPT 的 Text-to-SQL 能力。考虑到大型对话语言模型 ChatGPT 和其在对话能力和代码生成能力上的印象深刻的表现，我们试图评估其 Text-to-SQL 性能。我们对12个基准数据集进行了实验，涉及不同的语言、设置或场景，并且结果表明 ChatGPT 具有强大的 Text-to-SQL 能力。虽然与当前最先进的模型表现仍有差距，但考虑到 实验是在零-shot场景下进行的，ChatGPT 的表现仍然令人印象深刻。值得注意的是，在 ADVETA（RPL）场景中，即使是零-shot ChatGPT 在 Spider 数据集上仍然优于需要微调的 SOTA 模型，表现提升了4.1\%，展示了它在实际应用中的潜力。为了支持相关领域的进一步研究，我们已经公开 ChatGPT 生成的数据。

    This paper presents the first comprehensive analysis of ChatGPT's Text-to-SQL ability. Given the recent emergence of large-scale conversational language model ChatGPT and its impressive capabilities in both conversational abilities and code generation, we sought to evaluate its Text-to-SQL performance. We conducted experiments on 12 benchmark datasets with different languages, settings, or scenarios, and the results demonstrate that ChatGPT has strong text-to-SQL abilities. Although there is still a gap from the current state-of-the-art (SOTA) model performance, considering that the experiment was conducted in a zero-shot scenario, ChatGPT's performance is still impressive. Notably, in the ADVETA (RPL) scenario, the zero-shot ChatGPT even outperforms the SOTA model that requires fine-tuning on the Spider dataset by 4.1\%, demonstrating its potential for use in practical applications. To support further research in related fields, we have made the data generated by ChatGPT publicly avai
    
[^26]: GETT-QA：基于图嵌入的知识图谱问答中的T2T Transformer

    GETT-QA: Graph Embedding based T2T Transformer for Knowledge Graph Question Answering. (arXiv:2303.13284v1 [cs.CL])

    [http://arxiv.org/abs/2303.13284](http://arxiv.org/abs/2303.13284)

    本论文提出了GETT-QA系统，该系统使用T5对自然语言问题生成简化的SPARQL查询，并使用截断的KG嵌入提高了知识图谱问答的性能。

    

    本文提出了一个名为GETT-QA的端到端知识图谱问答系统。GETT-QA使用了T5，这是一种热门的文本到文本预训练语言模型。该模型以自然语言形式的问题作为输入并生成所需SPARQL查询的简化形式。在简化形式中，模型不直接生成实体和关系ID，而是产生相应的实体和关系标签。标签在随后的步骤中与KG实体和关系ID联系起来。为了进一步改进结果，我们指导模型为每个实体生成KG嵌入的截断版本。截断的KG嵌入使得更精细的搜索从而更有效进行消歧。我们发现，T5能够在不改变损失函数的情况下学习截断的KG嵌入，提高了KGQA的性能。因此，我们在Wikidata的LC-QuAD 2.0和SimpleQuestions-Wikidata数据集上报告了端到端KGQA的强大结果。

    In this work, we present an end-to-end Knowledge Graph Question Answering (KGQA) system named GETT-QA. GETT-QA uses T5, a popular text-to-text pre-trained language model. The model takes a question in natural language as input and produces a simpler form of the intended SPARQL query. In the simpler form, the model does not directly produce entity and relation IDs. Instead, it produces corresponding entity and relation labels. The labels are grounded to KG entity and relation IDs in a subsequent step. To further improve the results, we instruct the model to produce a truncated version of the KG embedding for each entity. The truncated KG embedding enables a finer search for disambiguation purposes. We find that T5 is able to learn the truncated KG embeddings without any change of loss function, improving KGQA performance. As a result, we report strong results for LC-QuAD 2.0 and SimpleQuestions-Wikidata datasets on end-to-end KGQA over Wikidata.
    
[^27]: 口语理解中的填充语：计算和心理语言学视角

    Fillers in Spoken Language Understanding: Computational and Psycholinguistic Perspectives. (arXiv:2301.10761v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10761](http://arxiv.org/abs/2301.10761)

    本文综述了口语理解中填充语的研究视角，包括心理语言学理论、自动语音识别和SLU系统中的注释与考虑、以及生成角度的研究等，并探讨了每个领域的趋势和挑战。

    

    给话语中的停顿打断（即说话流畅度不连续）是口头表达中普遍存在的现象。相比其他种类的停顿，填充语（“嗯”、“啊”）是最常见的。然而据我们所知，还没有一种资源将影响口语理解（SLU）对这些语音事件的研究视角汇聚在一起。本文的目的是以全面的方式调查各种视角，从考虑基础的（心理）语言学理论开始，到它们在自动语音识别（ASR）和SLU系统中的注释和考虑，最后从生成角度研究它们。本文旨在以可达到的方式向SLU和会话AI社区展示这些视角，并讨论前进时每个领域的趋势和挑战。

    Disfluencies (i.e. interruptions in the regular flow of speech), are ubiquitous to spoken discourse. Fillers ("uh", "um") are disfluencies that occur the most frequently compared to other kinds of disfluencies. Yet, to the best of our knowledge, there isn't a resource that brings together the research perspectives influencing Spoken Language Understanding (SLU) on these speech events. This aim of this article is to survey a breadth of perspectives in a holistic way; i.e. from considering underlying (psycho)linguistic theory, to their annotation and consideration in Automatic Speech Recognition (ASR) and SLU systems, to lastly, their study from a generation standpoint. This article aims to present the perspectives in an approachable way to the SLU and Conversational AI community, and discuss moving forward, what we believe are the trends and challenges in each area.
    
[^28]: 适用于所有领域的一个模型：基于协作域前缀调整的跨领域实体识别

    One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER. (arXiv:2301.10410v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10410](http://arxiv.org/abs/2301.10410)

    本论文提出了基于协作域前缀调整的跨领域实体识别，使用文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务，避免了先前的为每个领域结束一个全新的NER模型的问题。

    

    解决实际场景中低资源问题是跨领域实体识别的一个挑战性任务。先前典型的解决方案主要通过使用来自丰富资源领域的数据进行预训练语言模型(PLMs)获得NER模型并将其适应于目标领域。由于不同领域实体类型之间的不匹配问题，先前的方法通常调整所有PLMs的参数，从而为每个领域结束一个全新的NER模型。此外，当前的模型只关注于利用一个普通来源领域中的知识，而未能成功地将来自多个来源领域的知识转移到目标上。为了解决这些问题，我们基于文本到文本生成的PLM引入了协作域前缀调整跨领域NER(CP-NER)。具体来说，我们呈现了用于文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务而无需结构修改。我们利用冻结的PLMs并进行协作域前缀调整。

    Cross-domain NER is a challenging task to address the low-resource problem in practical scenarios. Previous typical solutions mainly obtain a NER model by pre-trained language models (PLMs) with data from a rich-resource domain and adapt it to the target domain. Owing to the mismatch issue among entity types in different domains, previous approaches normally tune all parameters of PLMs, ending up with an entirely new NER model for each domain. Moreover, current models only focus on leveraging knowledge in one general source domain while failing to successfully transfer knowledge from multiple sources to the target. To address these issues, we introduce Collaborative Domain-Prefix Tuning for cross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically, we present text-to-text generation grounding domain-related instructors to transfer knowledge to new domain NER tasks without structural modifications. We utilize frozen PLMs and conduct collaborative domain-prefix tuning
    
[^29]: 大型语言模型中的类比推理的紧急性

    Emergent Analogical Reasoning in Large Language Models. (arXiv:2212.09196v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.09196](http://arxiv.org/abs/2212.09196)

    GPT-3在许多类比任务中表现出与甚至超越人类的能力，揭示了大型语言模型的紧急能力。

    

    大型语言模型的出现重新点燃了人们对于这样一种问题的辩论：足够的训练数据是否能使这些通用模型内涵人类认知能力。特别的，这些模型的零样本推理能力——不经过任何直接训练，就能够推理出新问题，特别令人关注。在人类认知中，这种能力与一种通过类比推理的能力密切相关。在本文中，我们在一系列类比任务中进行了直接的人机比较，包括一种新颖的基于文本的矩阵推理任务，该任务与 Raven's Progressive Matrices密切相关。我们发现，GPT-3呈现出了一种令人惊讶的抽象模式归纳能力，甚至在大部分情况下与或甚至超越了人类的能力。我们的结果表明，像GPT-3这样的大型语言模型已经获得了在广泛的类比问题上找到零样本解决方案的紧急能力。

    The recent advent of large language models has reinvigorated debate over whether human cognitive capacities might emerge in such generic models given sufficient training data. Of particular interest is the ability of these models to reason about novel problems zero-shot, without any direct training. In human cognition, this capacity is closely tied to an ability to reason by analogy. Here, we performed a direct comparison between human reasoners and a large language model (the text-davinci-003 variant of GPT-3) on a range of analogical tasks, including a novel text-based matrix reasoning task closely modeled on Raven's Progressive Matrices. We found that GPT-3 displayed a surprisingly strong capacity for abstract pattern induction, matching or even surpassing human capabilities in most settings. Our results indicate that large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems.
    
[^30]: POTATO: 便携式文本注释工具

    POTATO: The Portable Text Annotation Tool. (arXiv:2212.08620v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08620](http://arxiv.org/abs/2212.08620)

    POTATO是一个免费、开源的便携式文本注释工具，支持多种类型的文本和多模态数据的标注，提供易于配置的功能以最大化生产力，特别是对于长文档和复杂任务。

    

    我们介绍了POTATO，即便携式文本注释工具，这是一个完全免费、开源的注释系统，支持标注多种类型的文本和多模态数据，提供易于配置的功能以最大化部署和注释者的生产力（便捷的机器学习/自然语言处理任务模板、主动学习、按键缩写键、关键字高亮、提示工具），并支持高度定制化（可编辑的UI，插入预筛选问题，注意力和资格测试）。两项注释任务的实验表明，POTATO通过其特别设计的生产力功能，特别是长文档和复杂任务，提高了标注速度。POTATO可在 https://github.com/davidjurgens/potato 上获取，并将继续更新。

    We present POTATO, the Portable text annotation tool, a free, fully open-sourced annotation system that 1) supports labeling many types of text and multimodal data; 2) offers easy-to-configure features to maximize the productivity of both deployers and annotators (convenient templates for common ML/NLP tasks, active learning, keypress shortcuts, keyword highlights, tooltips); and 3) supports a high degree of customization (editable UI, inserting pre-screening questions, attention and qualification tests). Experiments over two annotation tasks suggest that POTATO improves labeling speed through its specially-designed productivity features, especially for long documents and complex tasks. POTATO is available at https://github.com/davidjurgens/potato and will continue to be updated.
    
[^31]: 结构化知识增强的开放世界故事生成：一项全面调查

    Open-world Story Generation with Structured Knowledge Enhancement: A Comprehensive Survey. (arXiv:2212.04634v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.04634](http://arxiv.org/abs/2212.04634)

    本文对结构化知识增强的故事生成进行了综述，总结了目前的方法与技术，指出了未来的发展方向和尚未解决的问题。

    

    讲故事和叙事是人类体验的基础，与我们的社会和文化参与密不可分。因此，长期以来，研究人员一直尝试创建能够自动生成故事的系统。近年来，受深度学习和大规模数据资源的推动，自动生成故事已经取得了很大的进展。然而，仍然存在一些重大挑战，例如，需要在生成的故事中实现全局一致性，这使得生成模型无法达到与人类叙述者相同的叙事能力。为了解决这些挑战，许多研究试图在生成过程中注入结构化知识，这被称为结构化知识增强的故事生成。将外部知识纳入其中可以增强故事事件之间的逻辑连贯性，实现更好的知识基础，并减轻故事中过度概括和重复问题。本次调查提供了对该研究领域的最新和全面的回顾：（i）我们提供了对结构化知识增强故事生成的综述，（ii）我们总结了目前的方法与技术，（iii）我们指出了尚待解决的问题与未来的发展方向。

    Storytelling and narrative are fundamental to human experience, intertwined with our social and cultural engagement. As such, researchers have long attempted to create systems that can generate stories automatically. In recent years, powered by deep learning and massive data resources, automatic story generation has shown significant advances. However, considerable challenges, like the need for global coherence in generated stories, still hamper generative models from reaching the same storytelling ability as human narrators. To tackle these challenges, many studies seek to inject structured knowledge into the generation process, which is referred to as structured knowledge-enhanced story generation. Incorporating external knowledge can enhance the logical coherence among story events, achieve better knowledge grounding, and alleviate over-generalization and repetition problems in stories. This survey provides the latest and comprehensive review of this research field: (i) we present a
    
[^32]: 数学建模深度学习新兴语言系统的词汇熵

    Mathematically Modeling the Lexicon Entropy of Emergent Language. (arXiv:2211.15783v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15783](http://arxiv.org/abs/2211.15783)

    本文提出了一种随机过程 FiLex 作为深度学习新兴语言系统中词汇熵的数学模型，该模型可以正确预测超参数与新兴语言熵之间的相关性，为研究新兴语言带来新的方法。

    

    本文提出了一种随机过程 FiLex 作为深度学习新兴语言系统中词汇熵的数学模型。通过将模型进行数学定义，可以产生清晰的预测并直接予以验证。我们在四个不同环境下进行了验证测试，证明 FiLex 可以以20个组合中的20个组合正确预测超参数(训练步数、词汇库大小、学习率、回溯缓存大小和 Gumbel-Softmax温度)与新兴语言熵之间的相关性。此外，我们的实验表明不同环境之间的超参数与熵之间的关系是各异的，这表明需要一种可以在精确的粒度水平上进行明确定义的模型进行预测。

    We formulate a stochastic process, FiLex, as a mathematical model of lexicon entropy in deep learning-based emergent language systems. Defining a model mathematically allows it to generate clear predictions which can be directly and decisively tested. We empirically verify across four different environments that FiLex predicts the correct correlation between hyperparameters (training steps, lexicon size, learning rate, rollout buffer size, and Gumbel-Softmax temperature) and the emergent language's entropy in 20 out of 20 environment-hyperparameter combinations. Furthermore, our experiments reveal that different environments show diverse relationships between their hyperparameters and entropy which demonstrates the need for a model which can make well-defined predictions at a precise level of granularity.
    
[^33]: 视觉语言模型何时以及为何行为像词袋，以及如何解决？

    When and why vision-language models behave like bags-of-words, and what to do about it?. (arXiv:2210.01936v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.01936](http://arxiv.org/abs/2210.01936)

    针对大型视觉语言模型在编码组合信息方面的表现存在问题，我们创建了Attribution、Relation和Order（ARO）基准，并提出了对VLMs进行Attention机制和对抗训练等修改以提高其组合理解能力。

    

    尽管大型视觉语言模型（VLM）在许多下游应用中取得了成功，但它们编码组合信息的能力尚不清楚。为此，我们创建了Attribution、Relation和Order（ARO）基准来系统评估VLM理解不同类型关系、属性和顺序的能力。ARO由Visual Genome Attribution测试对象属性的理解能力；Visual Genome Relation测试关系理解能力；以及COCO＆Flickr30k-Order测试顺序敏感性。ARO比以前的组合性基准大多个数量级，包括50,000多个测试用例。我们展示了最先进的VLM在哪些方面存在关系理解问题，当链接对象和属性时容易出错，并展示了其明显的缺乏顺序敏感性。VLM主要在具有丰富组合结构的图像和标题的大型数据集上进行训练和评估。然而，仅仅在这些数据集上训练并不能保证在需要组合理解的任务上表现良好。为了解决这些问题，我们提出了几种修改VLMs的方法，包括强调组成关系的注意机制和使用对抗训练来改善属性预测。我们提出的修改可以显著提高VLM在ARO基准上的组合理解能力。

    Despite the success of large vision and language models (VLMs) in many downstream applications, it is unclear how well they encode compositional information. Here, we create the Attribution, Relation, and Order (ARO) benchmark to systematically evaluate the ability of VLMs to understand different types of relationships, attributes, and order. ARO consists of Visual Genome Attribution, to test the understanding of objects' properties; Visual Genome Relation, to test for relational understanding; and COCO & Flickr30k-Order, to test for order sensitivity. ARO is orders of magnitude larger than previous benchmarks of compositionality, with more than 50,000 test cases. We show where state-of-the-art VLMs have poor relational understanding, can blunder when linking objects to their attributes, and demonstrate a severe lack of order sensitivity. VLMs are predominantly trained and evaluated on large datasets with rich compositional structure in the images and captions. Yet, training on these d
    
[^34]: 测量数据统计对语言模型“事实性”预测的因果影响

    Measuring Causal Effects of Data Statistics on Language Model's `Factual' Predictions. (arXiv:2207.14251v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.14251](http://arxiv.org/abs/2207.14251)

    本文提供了一个因果框架，描述了数据统计对预训练语言模型的“事实性”预测的影响。结果表明，PLMs的预测受到这些统计的影响，暗示这样的模型依赖于浅显的启发式策略。

    

    大量训练数据是最先进的自然语言处理模型表现出色的主要原因之一。但是，在训练数据中，到底是什么导致模型做出了某个预测呢？我们通过一个因果框架提供了一种描述训练数据如何影响预测的语言来回答这个问题。重要的是，我们的框架避免了重新训练昂贵模型的需要，仅通过观察数据就可以估计因果效应。针对从预训练语言模型（PLMs）中提取事实知识的问题，我们关注简单的数据统计，例如共现计数，并展示了这些统计对PLMs的预测具有影响，暗示这样的模型依赖于浅显的启发式策略。我们的因果框架和研究结果证明了研究数据集的重要性，以及因果关系对于理解NLP模型的益处。

    Large amounts of training data are one of the major reasons for the high performance of state-of-the-art NLP models. But what exactly in the training data causes a model to make a certain prediction? We seek to answer this question by providing a language for describing how training data influences predictions, through a causal framework. Importantly, our framework bypasses the need to retrain expensive models and allows us to estimate causal effects based on observational data alone. Addressing the problem of extracting factual knowledge from pretrained language models (PLMs), we focus on simple data statistics such as co-occurrence counts and show that these statistics do influence the predictions of PLMs, suggesting that such models rely on shallow heuristics. Our causal framework and our results demonstrate the importance of studying datasets and the benefits of causality for understanding NLP models.
    
[^35]: 企鹅不能飞：通过实例和异常推理泛化问题

    Penguins Don't Fly: Reasoning about Generics through Instantiations and Exceptions. (arXiv:2205.11658v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.11658](http://arxiv.org/abs/2205.11658)

    本文提出了一个基于语言学理论的框架，通过生成具体情况的实例，解决了泛化问题中的例外和普遍性的挑战，并在650个泛型上比GPT-3基线高出12.8个精度点。

    

    泛化表达了世界上的概括（例如，鸟可以飞翔），但并非普遍适用（例如，新生儿鸟和企鹅不能飞翔）。常识知识库通常编码一些泛化知识，但很少列举这些异常。知道何时泛化语句成立或不成立对于开发对泛化问题的全面理解至关重要。本文提出了一种新颖的框架，基于语言学理论生成实例，即泛化成立或不成立的具体情况。我们为大约650个泛型生成了约19k个实例，并展示了我们的框架比强劲的GPT-3基线高出12.8个精度点。我们的分析突显了基于语言学理论的可控性在生成实例中的重要性，知识库作为实例来源的不足之处，以及实例对自然语言推理任务的挑战。

    Generics express generalizations about the world (e.g., birds can fly) that are not universally true (e.g., newborn birds and penguins cannot fly). Commonsense knowledge bases, used extensively in NLP, encode some generic knowledge but rarely enumerate such exceptions and knowing when a generic statement holds or does not hold true is crucial for developing a comprehensive understanding of generics. We present a novel framework informed by linguistic theory to generate exemplars -- specific cases when a generic holds true or false. We generate ~19k exemplars for ~650 generics and show that our framework outperforms a strong GPT-3 baseline by 12.8 precision points. Our analysis highlights the importance of linguistic theory-based controllability for generating exemplars, the insufficiency of knowledge bases as a source of exemplars, and the challenges exemplars pose for the task of natural language inference.
    
[^36]: DeBERTaV3：使用梯度去耦合嵌入共享的ELECTRA风格预训练来改进DeBERTa模型

    DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing. (arXiv:2111.09543v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2111.09543](http://arxiv.org/abs/2111.09543)

    本论文介绍了一种新的预训练语言模型DeBERTaV3，使用更加样本有效的替换令牌检测（RTD）取代了掩码语言建模（MLM）并提出了一种新的梯度去耦合嵌入共享方法，避免了“拔河”动态，提高了预训练模型的训练效率和质量。在多个下游自然语言理解任务中，DeBERTaV3表现出优秀的性能。

    

    本文介绍了一种新的预训练语言模型DeBERTaV3，它通过将掩码语言建模（MLM）替换为更加样本有效的替换令牌检测（RTD）来改进原始的DeBERTa模型。我们的分析表明，ELECTRA中的香草嵌入共享会影响训练效率和模型性能，因为判别器和生成器的训练损失将令牌嵌入拉向不同的方向，会造成“拔河”动态。因此，我们提出了一种新的梯度去耦合嵌入共享方法，避免了“拔河”动态，提高了预训练模型的训练效率和质量。我们使用与DeBERTa相同的设置预训练了DeBERTaV3，以展示其在各种下游自然语言理解（NLU）任务中的优秀性能。以八项任务为例的GLUE基准测试中，DeBERTaV3 Large模型平均得分为91.37％，比D高1.37％。

    This paper presents a new pre-trained language model, DeBERTaV3, which improves the original DeBERTa model by replacing mask language modeling (MLM) with replaced token detection (RTD), a more sample-efficient pre-training task. Our analysis shows that vanilla embedding sharing in ELECTRA hurts training efficiency and model performance. This is because the training losses of the discriminator and the generator pull token embeddings in different directions, creating the "tug-of-war" dynamics. We thus propose a new gradient-disentangled embedding sharing method that avoids the tug-of-war dynamics, improving both training efficiency and the quality of the pre-trained model. We have pre-trained DeBERTaV3 using the same settings as DeBERTa to demonstrate its exceptional performance on a wide range of downstream natural language understanding (NLU) tasks. Taking the GLUE benchmark with eight tasks as an example, the DeBERTaV3 Large model achieves a 91.37% average score, which is 1.37% over D
    

