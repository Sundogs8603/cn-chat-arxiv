# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models](https://arxiv.org/abs/2403.20331) | 本文提出了一个新颖且重要的挑战，即Unsolvable Problem Detection（UPD），用于评估视觉语言模型在视觉问答任务中能否在面对不可解问题时保持答案的能力，并通过广泛实验发现大多数模型存在改进的空间。 |
| [^2] | [ReALM: Reference Resolution As Language Modeling](https://arxiv.org/abs/2403.20329) | 本论文展示了如何利用LLMs创建一个极其有效的系统来解决各种类型的引用问题，通过将参考解析转化为语言建模问题，尽管涉及到屏幕上的实体等不易约简为纯文本形式的实体。 |
| [^3] | [Gecko: Versatile Text Embeddings Distilled from Large Language Models](https://arxiv.org/abs/2403.20327) | Gecko是一种紧凑而多功能的文本嵌入式模型，通过提炼大型语言模型中的知识为检索器，在性能上表现出色，并在Massive Text Embedding Benchmark上超越了现有的所有条目。 |
| [^4] | [Towards a Framework for Evaluating Explanations in Automated Fact Verification](https://arxiv.org/abs/2403.20322) | 倡导并提出了一个形式化框架，用于系统评估理性化解释，针对自动事实验证任务中不同结构的解释提供了一套评估方法 |
| [^5] | [ChainNet: Structured Metaphor and Metonymy in WordNet](https://arxiv.org/abs/2403.20308) | ChainNet是一个词典资源，首次明确地识别了WordNet中词义的结构化隐喻和转喻关系，成为第一个具有基础隐喻和转喻数据集的资源。 |
| [^6] | [Emotion-Anchored Contrastive Learning Framework for Emotion Recognition in Conversation](https://arxiv.org/abs/2403.20289) | 提出了一种情感锚定的对比学习框架，用于在会话中识别情感，能够生成更易区分的话语表示，提高了相似情感的区分度和分类性能。 |
| [^7] | [Can LLMs Correct Physicians, Yet? Investigating Effective Interaction Methods in the Medical Domain](https://arxiv.org/abs/2403.20288) | LLMs在医学决策中提供重要反馈，可以挑战不正确的诊断，促进更准确的决策。 |
| [^8] | [LayerNorm: A key component in parameter-efficient fine-tuning](https://arxiv.org/abs/2403.20284) | LayerNorm在参数高效微调中扮演关键角色，微调output LayerNorm而保持其他部分不变足以在多个GLUE任务中取得竞争力 |
| [^9] | [LUQ: Long-text Uncertainty Quantification for LLMs](https://arxiv.org/abs/2403.20279) | LUQ提出了一种针对长文本设计的新型采样UQ方法，优于现有基准方法在与模型的事实得分相关方面。 |
| [^10] | [Latxa: An Open Language Model and Evaluation Suite for Basque](https://arxiv.org/abs/2403.20266) | Latxa是一种用于巴斯克语的大型语言模型系列，在语言熟练度和理解能力方面表现出色，优于所有以前的开放模型，并具有多个评估数据集，填补了巴斯克语高质量基准的不足。 |
| [^11] | [ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models](https://arxiv.org/abs/2403.20262) | 该论文提出了一个新的基准 ELITR-Bench，专注于长上下文语言模型的实际会议助理场景，通过在现有 ELITR 语料库的转录中添加手工制作的问题和真实答案，揭示了开源模型和专有模型之间的差距。 |
| [^12] | [Using LLMs to Model the Beliefs and Preferences of Targeted Populations](https://arxiv.org/abs/2403.20252) | 使用LLMs建模目标人群的信念和偏好，旨在实现各种应用，评估不同微调方法的效果，并检验其在匹配真实人类受访者偏好方面的能力。 |
| [^13] | [Shallow Cross-Encoders for Low-Latency Retrieval](https://arxiv.org/abs/2403.20222) | 张海洋这里是中文总结出的一句话要点：本文展示了在低延迟设置下，较弱的浅层Transformer模型在文本检索中的表现优于完整模型，并且可能受益于广义二元交叉熵（gBCE）训练方案。 |
| [^14] | [Advancing the Arabic WordNet: Elevating Content Quality](https://arxiv.org/abs/2403.20215) | 本文关注阿拉伯语，通过对阿拉伯语WordNet进行重大修订，提高内容质量，更新了超过58%的同义词集，并解决了词形错误和缺失信息等问题 |
| [^15] | [Automatic Alignment of Discourse Relations of Different Discourse Annotation Frameworks](https://arxiv.org/abs/2403.20196) | 研究探索不同话语标注框架间的话语关系清单相关性，并提出半自动方法来解决这一问题。 |
| [^16] | [Exploring Pathological Speech Quality Assessment with ASR-Powered Wav2Vec2 in Data-Scarce Context](https://arxiv.org/abs/2403.20184) | 本文提出了一种新颖的方法，在数据稀缺情况下系统在整体音频级别进行学习，同时利用ASR驱动的Wav2Vec2架构作为特征提取器，在语音评估中取得了显著的结果。 |
| [^17] | [Measuring Taiwanese Mandarin Language Understanding](https://arxiv.org/abs/2403.20180) | 该研究致力于在评估汉语环境中的大型语言模型，提出了一个综合评估套件TMLU，覆盖37个科目，通过精心策划的少样本解释促进复杂推理能力的评估，并对24个高级LLMs进行了广泛实验和分析，结果显示中国开放权重模型表现较差。 |
| [^18] | [ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models](https://arxiv.org/abs/2403.20158) | 研究比较了ChatGPT与Fine-tuned语言模型在检测媒体偏见方面的表现，发现ChatGPT在检测仇恨言论和文本级上下文偏见方面表现一致，但在检测虚假新闻、种族、性别和认知偏见方面则存在困难。 |
| [^19] | [A Systematic Analysis of Subwords and Cross-Lingual Transfer in Multilingual Translation](https://arxiv.org/abs/2403.20157) | 本文研究了多语种翻译中子词分割的作用，发现子词正则化提高了多语种建模的协同作用，而BPE则更有效地促进了跨语言迁移。 |
| [^20] | [IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context](https://arxiv.org/abs/2403.20147) | IndiBias是一个为评估印度语境中社会偏见而设计的综合基准数据集，通过过滤和翻译现有数据集以及利用不同LLMs的方法，涵盖了印度中流行的各种社会偏见维度。 |
| [^21] | [Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries](https://arxiv.org/abs/2403.20145) | 该研究通过评估大型语言模型在自定义数据集上的微调和未微调，发现经过微调的模型胜过现有模型，在生成摘要方面取得了显著的进展。 |
| [^22] | [User Modeling Challenges in Interactive AI Assistant Systems](https://arxiv.org/abs/2403.20134) | 分析用户在任务执行过程中的心理状态，研究大型语言模型解读用户资料以实现更个性化用户指导的能力和挑战。 |
| [^23] | [NLP for Counterspeech against Hate: A Survey and How-To Guide](https://arxiv.org/abs/2403.20103) | 反言论作为一种非升级回应策略，可以有效减少在线和离线暴力，最近NLP社区对于分析、收集、分类和自动生成反言论的挑战表现出越来越浓厚的兴趣。 |
| [^24] | [RealKIE: Five Novel Datasets for Enterprise Key Information Extraction](https://arxiv.org/abs/2403.20101) | RealKIE提供了五个具有挑战性的企业关键信息提取数据集，为投资分析和法律数据处理等任务提供了现实的测试基地，并为NLP模型的发展做出了贡献。 |
| [^25] | [An Efficient Approach for Studying Cross-Lingual Transfer in Multilingual Language Models](https://arxiv.org/abs/2403.20088) | 提出了一种高效方法来研究零翻译语言模型在目标语言上的迁移语言影响，发现一些语言对其他语言影响不大，而一些语言对不同目标语言可能极为有利或有害，同时也观察到以前未被MLMs看到的语言始终受益于来自几乎所有迁移。 |
| [^26] | [IPA Transcription of Bengali Texts](https://arxiv.org/abs/2403.20084) | 这项工作对孟加拉文本的国际音标转写进行了全面研究，并引入了一个包含基于DL的基准数据集的新颖IPA转写框架。 |
| [^27] | [Cross-Lingual Transfer Robustness to Lower-Resource Languages on Adversarial Datasets](https://arxiv.org/abs/2403.20056) | 多语言语言模型展示了强大的跨语言传输能力，对低资源语言的鲁棒性具有实际应用，研究发现命名实体识别跨语言传输在很大程度上取决于实体的重叠 |
| [^28] | [Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning](https://arxiv.org/abs/2403.20046) | 通过新设计的基准测试\textsc{CoTErrorSet}，研究了LLMs是否能够从以往的错误中学习，尤其是对于推理能力方面的提升。 |
| [^29] | [Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs](https://arxiv.org/abs/2403.20041) | 提出了四种优化技术来在手机GPU上高效部署大型语言模型，并通过实现在移动推断引擎Transformer-Lite中，提高了推断速度和降低了手机滞后，从而改善用户体验。 |
| [^30] | [FSMR: A Feature Swapping Multi-modal Reasoning Approach with Joint Textual and Visual Clues](https://arxiv.org/abs/2403.20026) | 这项研究提出了一种新的特征交换多模态推理（FSMR）模型，通过特征交换增强多模态推理，包括利用预训练的视觉-语言模型和独特的特征交换模块，以及融合多模态交叉注意机制来促进文本和图像信息的联合建模。 |
| [^31] | [Adverb Is the Key: Simple Text Data Augmentation with Adverb Deletion](https://arxiv.org/abs/2403.20015) | 使用简单的副词删除策略，提出了一种新颖的文本数据增强方法，能有效增强文本数据，保留语义，适用于单一文本分类和自然语言推理。 |
| [^32] | [PURPLE: Making a Large Language Model a Better SQL Writer](https://arxiv.org/abs/2403.20014) | 提出了PURPLE模型，通过检索演示来提高大型语言模型在SQL生成中的准确性 |
| [^33] | [On Large Language Models' Hallucination with Regard to Known Facts](https://arxiv.org/abs/2403.20009) | 通过推理动态的角度研究大型语言模型对已知事实的幻觉现象，通过对事实性问题和输出 token 概率动态的分析，揭示了幻觉发生的模式。 |
| [^34] | [Large Language Model based Situational Dialogues for Second Language Learning](https://arxiv.org/abs/2403.20005) | 提出了基于大型语言模型的情境对话模型，旨在帮助语言学习者进行有效的会话练习，具有泛化能力，可以支持多样的会话话题，为解决学生缺乏合格教师或母语者练习会话技能的问题提供了一种可行的解决方案 |
| [^35] | [Development of Compositionality and Generalization through Interactive Learning of Language and Action of Robots](https://arxiv.org/abs/2403.19995) | 提出了一个融合视觉、本体感知和语言的大脑启发式神经网络模型，通过预测编码和主动推断的框架，基于自由能原理，实现了语言组合性和感觉运动技能的联合发展。 |
| [^36] | [Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning](https://arxiv.org/abs/2403.19962) | 通过构建特定于代理的数据并细调模型以及设计能够有效激活LLMs推理能力的提示，提出了一种综合方法来增强低参数LLMs的通用代理功能。 |
| [^37] | [SLFNet: Generating Semantic Logic Forms from Natural Language Using Semantic Probability Graphs](https://arxiv.org/abs/2403.19936) | SLFNet提出了一种新颖的神经网络架构，利用依赖句法信息和语义概率图来从自然语言生成语义逻辑形式，以解决序列到序列模型中的“顺序重要性”问题。 |
| [^38] | [Are LLMs Effective Backbones for Fine-tuning? An Experimental Investigation of Supervised LLMs on Chinese Short Text Matching](https://arxiv.org/abs/2403.19930) | 研究评估了在监督设置中为中文短文本匹配任务微调LLMs的实验分析，探讨了任务建模方法、提示格式和输出格式等因素对性能的影响。 |
| [^39] | [DiJiang: Efficient Large Language Models through Compact Kernelization](https://arxiv.org/abs/2403.19928) | DiJiang提出了一种新颖的频域核方法，可以将预训练的基本Transformer模型转化为具有线性复杂度的模型，大大减少训练成本，并在理论上提供更好的逼近效率。 |
| [^40] | [MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models](https://arxiv.org/abs/2403.19913) | 提出了用于评估大型语言模型执行文本映射和导航能力的MANGO基准，发现即使是迄今为止最好的语言模型GPT-4在回答涉及映射和导航的问题时表现不佳。 |
| [^41] | [Towards a Robust Retrieval-Based Summarization System](https://arxiv.org/abs/2403.19889) | 该论文对大型语言模型在检索增强生成-基础摘要任务中的健壮性进行了调查，并提出了一个创新的评估框架和一个全面的系统来增强模型在特定场景下的健壮性。 |
| [^42] | [Jamba: A Hybrid Transformer-Mamba Language Model](https://arxiv.org/abs/2403.19887) | Jamba是一个基于混合Transformer-Mamba架构的语言模型，在单个80GB GPU上实现了强大的性能，对标准语言模型基准和长上下文评估具有state-of-the-art的表现。 |
| [^43] | [Localizing Paragraph Memorization in Language Models](https://arxiv.org/abs/2403.19851) | 论文展示了语言模型中段落记忆的梯度具有可区分的空间模式，通过微调高梯度权重可以取消学习，定位了特别参与段落记忆的低层注意头，并研究了记忆在前缀中的本地化程度。 |
| [^44] | [The New Agronomists: Language Models are Experts in Crop Management](https://arxiv.org/abs/2403.19839) | 本文介绍了一个更先进的智能作物管理系统，利用深度强化学习和语言模型结合决策支持系统来优化作物管理实践。 |
| [^45] | [Concept-based Analysis of Neural Networks via Vision-Language Models](https://arxiv.org/abs/2403.19837) | 本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。 |
| [^46] | [Target Span Detection for Implicit Harmful Content](https://arxiv.org/abs/2403.19836) | 研究侧重于辨识仇恨言论的暗示目标，定义了一个新任务，通过收集和标注目标跨度在多个数据集上实现，目的是识别更加微妙的仇恨言论并增强对数字平台上有害内容的检测。 |
| [^47] | [Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs](https://arxiv.org/abs/2403.19827) | 语言模型通过从相关结构（例如“a few days”）进行泛化学习，能够更好地学习AANN结构。 |
| [^48] | [Multi-Stage Multi-Modal Pre-Training for Automatic Speech Recognition](https://arxiv.org/abs/2403.19822) | 提出了一种结合多模态和多任务无监督预训练以及基于翻译的监督中间训练方法的新方法，能够在Librispeech和SUPERB上相对提高高达38.45%的词错误率（WER）。 |
| [^49] | [Developing Healthcare Language Model Embedding Spaces](https://arxiv.org/abs/2403.19802) | 通过深度对比学习训练的模型在医疗保健文本分类任务中表现出色，有效利用有限标记数据，并减少了模型参数更新。 |
| [^50] | [Natural Language, AI, and Quantum Computing in 2024: Research Ingredients and Directions in QNLP](https://arxiv.org/abs/2403.19758) | 该论文调查了2024年自然语言处理、人工智能发展中的量子计算应用，在量子自然语言处理中使用了诸如词嵌入、序列模型、注意力和语法分析等NLP技术，提出了一种新的量子设计来处理文本编码，并探讨了量子理论对“不确定性是什么？”和“智能是什么？”等核心问题的关键贡献。 |
| [^51] | [GOLD: Generalized Knowledge Distillation via Out-of-Distribution-Guided Language Data Generation](https://arxiv.org/abs/2403.19754) | GOLD提出了一种任务无关的数据生成和知识蒸馏框架，通过使用超出分布引导的反馈机制，提高了生成数据的泛化能力，并引入了处理嘈杂生成数据的基于能量的OOD评估方法。 |
| [^52] | [EmoScan: Automatic Screening of Depression Symptoms in Romanized Sinhala Tweets](https://arxiv.org/abs/2403.19728) | 通过分析罗马化僧伽罗语社交媒体数据，提出了一种基于神经网络的框架，利用语言模式、情绪和行为线索可高准确率自动筛查抑郁症症状，显著超越了当前方法，有助于确定需积极干预和支持的个体。 |
| [^53] | [New Semantic Task for the French Spoken Language Understanding MEDIA Benchmark](https://arxiv.org/abs/2403.19727) | 提出了一个用于法语口语理解的新语义任务，通过在MEDIA基准测试数据集上标注意图来扩展其用途和使用情况。 |
| [^54] | [A Benchmark Evaluation of Clinical Named Entity Recognition in French](https://arxiv.org/abs/2403.19726) | 该论文评估了生物医学法语掩码语言模型在临床命名实体识别任务上的性能，对几种模型进行了比较。 |
| [^55] | [MUGC: Machine Generated versus User Generated Content Detection](https://arxiv.org/abs/2403.19725) | 本研究对八种传统机器学习算法在识别机器生成和人类生成数据方面进行了比较评估，发现这些方法在识别机器生成数据方面具有较高的准确性。另外，机器生成的文本往往更短、词汇变化更少，而人类生成内容则使用了一些特定领域相关关键词被当前的大型语言模型忽略了。 |
| [^56] | [HGT: Leveraging Heterogeneous Graph-enhanced Large Language Models for Few-shot Complex Table Understanding](https://arxiv.org/abs/2403.19723) | HGT框架结合了异质图增强的大型语言模型，通过软提示和多粒度自监督HG预训练目标，实现了少样本复杂表格理解任务的最新成果。 |
| [^57] | [Capability-aware Prompt Reformulation Learning for Text-to-Image Generation](https://arxiv.org/abs/2403.19716) | 通过利用来自交互日志的用户重组数据来开发自动提示重组模型，CAPR框架创新性地将用户能力整合到提示重组过程中。 |
| [^58] | [NJUST-KMG at TRAC-2024 Tasks 1 and 2: Offline Harm Potential Identification](https://arxiv.org/abs/2403.19713) | 该研究提出了在TRAC-2024离线危害潜在性识别任务中的方法，利用专家标注的社交媒体评论数据集，成功设计了能够准确评估危害可能性并识别目标的算法，在两个赛道中取得第二名的成绩。 |
| [^59] | [STRUM-LLM: Attributed and Structured Contrastive Summarization](https://arxiv.org/abs/2403.19710) | STRUM-LLM提出了一种生成属性化、结构化和有帮助的对比摘要的方法，识别并突出两个选项之间的关键差异，不需要人工标记的数据或固定属性列表，具有高吞吐量和小体积。 |
| [^60] | [Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of Large Speech Models](https://arxiv.org/abs/2403.19709) | 提出了一种分层递归适配器模块，能够在大规模多任务适配场景下降低每个任务的参数开销，同时保持在下游任务中的性能表现，优于先前的适配器方法和完整模型微调基线 |
| [^61] | [AttentionStore: Cost-effective Attention Reuse across Multi-turn Conversations in Large Language Model Serving](https://arxiv.org/abs/2403.19708) | AttentionStore提出了一种新的注意力机制，通过实现KV缓存的复用，在大型语言模型服务中显著降低了多轮对话中的重复计算成本。 |
| [^62] | [Analyzing the Roles of Language and Vision in Learning from Limited Data](https://arxiv.org/abs/2403.19669) | 研究人工智能中的复杂视觉-语言模型，发现即使缺乏视觉输入，利用所有组件的语言模型能够恢复大部分VLM的性能，表明语言通过提供对先前知识和推理的访问来对学习新任务有贡献 |
| [^63] | [Uncovering Misattributed Suicide Causes through Annotation Inconsistency Detection in Death Investigation Notes](https://arxiv.org/abs/2403.19432) | 通过自然语言处理方法检测并纠正国家暴力死亡报告系统中的注释不一致性，提高了自杀危机分类器的性能。 |
| [^64] | [STaR-GATE: Teaching Language Models to Ask Clarifying Questions](https://arxiv.org/abs/2403.19154) | 通过奖励语言模型生成有用问题来自我改进的方法，提问者通过询问角色扮演者来引出偏好，从而迭代微调以增加任务高质量响应的概率。 |
| [^65] | [Language Models are Free Boosters for Biomedical Imaging Tasks](https://arxiv.org/abs/2403.17343) | 本研究揭示了基于残差的大型语言模型在生物医学成像任务中作为编码器的意想不到的有效性，利用冻结的变压器块进行直接处理视觉令牌，从而提高各种生物医学成像应用的性能。 |
| [^66] | [WoLF: Large Language Model Framework for CXR Understanding](https://arxiv.org/abs/2403.15456) | WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。 |
| [^67] | [Emotion Detection with Transformers: A Comparative Study](https://arxiv.org/abs/2403.15454) | 本研究探索了在文本数据情感分类中应用基于Transformer的模型，并发现常用技术如去除标点符号和停用词可能会阻碍模型的性能，因为这些元素仍然能够传达情感或强调，而Transformer的优势在于理解文本内的语境关系。 |
| [^68] | [PET-SQL: A Prompt-enhanced Two-stage Text-to-SQL Framework with Cross-consistency](https://arxiv.org/abs/2403.09732) | 提出了一个两阶段框架，通过引入参考增强表示和少样本演示，解决了在处理冗长的数据库信息和复杂用户意图时的挑战。 |
| [^69] | [Rectifying Demonstration Shortcut in In-Context Learning](https://arxiv.org/abs/2403.09488) | 本研究旨在纠正大型语言模型在上下文学习中的演示快捷方式，并引入了一种新的明示意识校准方法。 |
| [^70] | [SemEval-2024 Shared Task 6: SHROOM, a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes](https://arxiv.org/abs/2403.07726) | 本文介绍了SHROOM共享任务，重点关注检测幻觉，以及参与者使用的模型和策略。 |
| [^71] | [Utilizing Local Hierarchy with Adversarial Training for Hierarchical Text Classification](https://arxiv.org/abs/2402.18825) | 通过引入对抗性框架和本地层次结构，我们提出了一个适用于几乎所有HTC模型的HiAdv框架，优化了分层文本分类，并证明了本地层次结构的有效性，特别对于训练数据不足的罕见类别。 |
| [^72] | [What Generative Artificial Intelligence Means for Terminological Definitions](https://arxiv.org/abs/2402.16139) | 生成人工智能工具如ChatGPT在提供定制化的语境特定含义方面表现出色，但在准确性方面存在挑战，可以辅助术语学家进行术语编纂，实现AI效率与人类专业知识的结合。 |
| [^73] | [Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2402.12168) | PEFT相对于全参数微调更容易受到权重投毒后门攻击的影响，提出了一个通过置信度识别受污染样本的毒化样本识别模块（PSIM），为权重投毒后门攻击提供稳健防御 |
| [^74] | [A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models](https://arxiv.org/abs/2402.11676) | 提出了一个多方面框架，使用大型语言模型评估反叙事，通过5个方面从专门 NGO 指南中提取定义的内容，以解决以往评估方法的局限性。 |
| [^75] | [Uncertainty Decomposition and Quantification for In-Context Learning of Large Language Models](https://arxiv.org/abs/2402.10189) | 本文研究了大型语言模型（LLM）上下文学习中的不确定性，并提出了一种新的方法来量化这种不确定性，包括演示产生的不确定性和模型配置的模糊性。 |
| [^76] | [Enhance Reasoning for Large Language Models in the Game Werewolf](https://arxiv.org/abs/2402.02330) | 本文提出了一个创新的框架，将大型语言模型（LLM）与外部思考模块相结合，以增强推理能力，通过引入通信协议和使用大量数据进行训练，展示了其在游戏推理、语音生成和在线评估方面的有效性。 |
| [^77] | [CroissantLLM: A Truly Bilingual French-English Language Model](https://arxiv.org/abs/2402.00786) | CroissantLLM是一个1.3B的双语语言模型，通过使用1:1的英语-法语预训练数据比例、自定义的分词器和双语调优数据集进行训练，实现了高性能和开源。模型还发布了训练数据集和多个检查点，以及一个法语基准测试 FrenchBench。 |
| [^78] | [Conversational Question Answering with Reformulations over Knowledge Graph](https://arxiv.org/abs/2312.17269) | 提出了使用重述技术改进对话式问答性能的CornNet模型 |
| [^79] | [GlitchBench: Can large multimodal models detect video game glitches?](https://arxiv.org/abs/2312.05291) | GlitchBench是一个基于视频游戏质量保证任务的新基准，旨在挑战LMMs在检测和解释异常事件方面的视觉和语言推理能力。 |
| [^80] | [Compositional Chain-of-Thought Prompting for Large Multimodal Models](https://arxiv.org/abs/2311.17076) | 提出了一种新颖的零样式思维提示（CCoT），以克服大型多模态模型难以捕捉到组合视觉推理方面的细节的问题。 |
| [^81] | [PEMA: An Offsite-Tunable Plug-in External Memory Adaptation for Language Models](https://arxiv.org/abs/2311.08590) | PEMA是一种参数有效的微调方法，通过插件外部内存自适应实现了对预训练语言模型的微调，绕过了对所有权重的访问需求，同时利用外部内存和适配器权重矩阵来提高效率。 |
| [^82] | [Learning From Mistakes Makes LLM Better Reasoner](https://arxiv.org/abs/2310.20689) | 本研究探索了大型语言模型（LLMs）是否可以从错误中学习，类似于人类学习的过程，并通过引入错误纠正的数据对来改进LLMs的推理能力。实验结果表明，这种方法能够持续提升仅使用CoT进行微调后的性能。 |
| [^83] | [Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning](https://arxiv.org/abs/2309.10814) | 该论文提出了一种自然语言嵌入程序的框架，以解决需要符号和数值推理的任务，不仅能够生成Python程序进行推理，还可以在数学推理、文本分类、问题回答等多个任务中优于基线方法。 |
| [^84] | [S\={a}mayik: A Benchmark and Dataset for English-Sanskrit Translation](https://arxiv.org/abs/2305.14004) | S\={a}mayik是一个包含约53,000个平行英梵句子的数据集，覆盖了多个领域，特别关注梵文的当代用法，用于培训的翻译模型在翻译出领域的当代语料时显示出显著的提升 |
| [^85] | [DialogCC: An Automated Pipeline for Creating High-Quality Multi-Modal Dialogue Dataset](https://arxiv.org/abs/2212.04119) | 提出了一个自动化流水线来构建高质量和多样化的多模态对话数据集，确保对话质量和图像多样性，并且不需要人力介入。 |
| [^86] | [QAGCN: Answering Multi-Relation Questions via Single-Step Implicit Reasoning over Knowledge Graphs](https://arxiv.org/abs/2206.01818) | 本文提出了 QAGCN 方法，通过对问题进行感知来实现单步隐式推理，从而回答多关系问题，相比于显式多步推理方法，该方法更简单、高效且易于采用。 |
| [^87] | [Natural Language Processing for Dialects of a Language: A Survey.](http://arxiv.org/abs/2401.05632) | 这项调查研究了自然语言处理中针对方言的方法和问题，强调了方言对于NLP模型性能和语言技术公平性的影响，并提供了关于方言相关任务和语言的全面综述。 |
| [^88] | [DialogBench: Evaluating LLMs as Human-like Dialogue Systems.](http://arxiv.org/abs/2311.01677) | 本文提出了DialogBench，一个对话评估基准，用于评估LLMs作为人类对话系统的能力。通过对28个LLMs的广泛测试，发现指导微调对提升性能效果显著。 |
| [^89] | [Conversational Financial Information Retrieval Model (ConFIRM).](http://arxiv.org/abs/2310.13001) | ConFIRM是一种会话式金融信息检索模型，通过合成金融领域特定问答对和评估参数微调方法，实现了超过90%的准确性，为金融对话系统提供了数据高效的解决方案。 |
| [^90] | [Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2310.00648) | 本文研究了参数高效微调（PEFT）的安全性问题，发现PEFT易受特洛伊攻击。通过提出一种新的攻击方式PETA，并在各种下游任务和触发器设计中进行广泛测试，发现PETA能够在攻击成功率和未受影响的准确性方面取得有效结果。 |
| [^91] | [Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks.](http://arxiv.org/abs/2307.02477) | 通过反事实任务的研究，我们发现当前的语言模型具备一定的抽象推理能力，但它们在任务求解过程中往往也依赖于狭窄、难以转移的过程，这对语言模型的性能解释和理解有着重要的启示。 |
| [^92] | [mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality.](http://arxiv.org/abs/2304.14178) | 本文介绍了一种名为mPLUG-Owl的训练范式，它通过模块化学习基础LLM、视觉知识模块和视觉抽象器模块，赋予LLMs多模态的能力。实验结果表明，mPLUG-Owl在图像字幕和视觉问答任务中表现优于基线模型，并在某些情况下达到了最先进的性能水平。 |

# 详细

[^1]: 不可解问题检测：评估视觉语言模型的可信度

    Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models

    [https://arxiv.org/abs/2403.20331](https://arxiv.org/abs/2403.20331)

    本文提出了一个新颖且重要的挑战，即Unsolvable Problem Detection（UPD），用于评估视觉语言模型在视觉问答任务中能否在面对不可解问题时保持答案的能力，并通过广泛实验发现大多数模型存在改进的空间。

    

    本文介绍了一个新颖而重要的挑战，即Unsolvable Problem Detection（UPD），用于评估视觉语言模型（VLMs）在视觉问答（VQA）任务中面对不可解问题时保持答案的能力。UPD包括三个不同的设置：缺失答案检测（AAD）、不兼容答案集检测（IASD）和不兼容视觉问题检测（IVQD）。通过广泛的实验深入研究UPD问题表明，大多数VLMs，包括GPT-4V和LLaVA-Next-34B，在各种程度上都很难应对我们的基准测试，突显了改进的重要空间。为了解决UPD，我们探索了无需训练和基于训练的解决方案，提供了对其有效性和局限性的新见解。我们希望我们的见解，以及在提议的UPD设置内的未来努力，将增强对VLMs的更广泛理解和发展。

    arXiv:2403.20331v1 Announce Type: cross  Abstract: This paper introduces a novel and significant challenge for Vision Language Models (VLMs), termed Unsolvable Problem Detection (UPD). UPD examines the VLM's ability to withhold answers when faced with unsolvable problems in the context of Visual Question Answering (VQA) tasks. UPD encompasses three distinct settings: Absent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and Incompatible Visual Question Detection (IVQD). To deeply investigate the UPD problem, extensive experiments indicate that most VLMs, including GPT-4V and LLaVA-Next-34B, struggle with our benchmarks to varying extents, highlighting significant room for the improvements. To address UPD, we explore both training-free and training-based solutions, offering new insights into their effectiveness and limitations. We hope our insights, together with future efforts within the proposed UPD settings, will enhance the broader understanding and development of
    
[^2]: ReALM: 参考解析作为语言建模

    ReALM: Reference Resolution As Language Modeling

    [https://arxiv.org/abs/2403.20329](https://arxiv.org/abs/2403.20329)

    本论文展示了如何利用LLMs创建一个极其有效的系统来解决各种类型的引用问题，通过将参考解析转化为语言建模问题，尽管涉及到屏幕上的实体等不易约简为纯文本形式的实体。

    

    参考解析是一个重要的问题，对于理解和成功处理各种上下文至关重要。 这种上下文既包括先前的对话，也包括与非对话实体相关的上下文，例如用户屏幕上的实体或后台运行的实体。 尽管已经证明了LLMs在各种任务中非常强大，但它们在参考解析中的运用，特别是对于非对话实体，仍未充分利用。 本文展示了LLMs如何被用来创建一个极其有效的系统来解决各种类型的引用问题，通过展示如何将参考解析转化为语言建模问题，尽管其中涉及屏幕上的这种实体等传统上不易约简为纯文本形式的实体。 我们展示了在不同类型的参考解析中相对于已有类似功能的系统的显着改进。

    arXiv:2403.20329v1 Announce Type: cross  Abstract: Reference resolution is an important problem, one that is essential to understand and successfully handle context of different kinds. This context includes both previous turns and context that pertains to non-conversational entities, such as entities on the user's screen or those running in the background. While LLMs have been shown to be extremely powerful for a variety of tasks, their use in reference resolution, particularly for non-conversational entities, remains underutilized. This paper demonstrates how LLMs can be used to create an extremely effective system to resolve references of various types, by showing how reference resolution can be converted into a language modeling problem, despite involving forms of entities like those on screen that are not traditionally conducive to being reduced to a text-only modality. We demonstrate large improvements over an existing system with similar functionality across different types of re
    
[^3]: 由大型语言模型提炼出的多功能文本嵌入式模型Gecko

    Gecko: Versatile Text Embeddings Distilled from Large Language Models

    [https://arxiv.org/abs/2403.20327](https://arxiv.org/abs/2403.20327)

    Gecko是一种紧凑而多功能的文本嵌入式模型，通过提炼大型语言模型中的知识为检索器，在性能上表现出色，并在Massive Text Embedding Benchmark上超越了现有的所有条目。

    

    我们提出了Gecko，一种紧凑而多功能的文本嵌入式模型。Gecko通过利用一个关键思想实现了强大的检索性能：将大型语言模型(LLMs)中的知识提炼为检索器。我们的两步提炼过程首先涉及使用LLM生成多样化合成的配对数据。接下来，我们通过为每个查询检索一组候选段落，并使用相同的LLM重新标记正面和困难的负面段落，进一步提高数据质量。Gecko模型的紧凑性展示了我们方法的有效性。在大规模文本嵌入式基准测试(MTEB)上，具有256嵌入维度的Gecko的表现优于所有现有的768嵌入尺寸的条目。具有768嵌入维度的Gecko实现了平均得分66.31，与7倍大的模型和5倍高维嵌入相竞争。

    arXiv:2403.20327v1 Announce Type: new  Abstract: We present Gecko, a compact and versatile text embedding model. Gecko achieves strong retrieval performance by leveraging a key idea: distilling knowledge from large language models (LLMs) into a retriever. Our two-step distillation process begins with generating diverse, synthetic paired data using an LLM. Next, we further refine the data quality by retrieving a set of candidate passages for each query, and relabeling the positive and hard negative passages using the same LLM. The effectiveness of our approach is demonstrated by the compactness of the Gecko. On the Massive Text Embedding Benchmark (MTEB), Gecko with 256 embedding dimensions outperforms all existing entries with 768 embedding size. Gecko with 768 embedding dimensions achieves an average score of 66.31, competing with 7x larger models and 5x higher dimensional embeddings.
    
[^4]: 在自动事实验证中评估解释的框架

    Towards a Framework for Evaluating Explanations in Automated Fact Verification

    [https://arxiv.org/abs/2403.20322](https://arxiv.org/abs/2403.20322)

    倡导并提出了一个形式化框架，用于系统评估理性化解释，针对自动事实验证任务中不同结构的解释提供了一套评估方法

    

    随着自然语言处理中的深度神经模型变得越来越复杂，也因此变得不透明，解释它们的必要性变得更为重要。越来越多的人对理性化解释产生了兴趣，以提供对预测的简短和连贯的理由。在这篇立场论文中，我们倡导一个形式化框架，用于关于理性化解释的关键概念和属性，以支持系统地评估它们。我们还概述了一个这样的形式化框架，定制于越来越复杂结构的理性化解释，从自由形式的解释到演绎性解释，再到具有最丰富结构的论证性解释。我们聚焦于自动事实验证任务，提供了使用我们的形式化评估解释的示例及其实用性，针对不同结构做出了定制。

    arXiv:2403.20322v1 Announce Type: new  Abstract: As deep neural models in NLP become more complex, and as a consequence opaque, the necessity to interpret them becomes greater. A burgeoning interest has emerged in rationalizing explanations to provide short and coherent justifications for predictions. In this position paper, we advocate for a formal framework for key concepts and properties about rationalizing explanations to support their evaluation systematically. We also outline one such formal framework, tailored to rationalizing explanations of increasingly complex structures, from free-form explanations to deductive explanations, to argumentative explanations (with the richest structure). Focusing on the automated fact verification task, we provide illustrations of the use and usefulness of our formalization for evaluating explanations, tailored to their varying structures.
    
[^5]: ChainNet: 在WordNet中的结构化隐喻和转喻

    ChainNet: Structured Metaphor and Metonymy in WordNet

    [https://arxiv.org/abs/2403.20308](https://arxiv.org/abs/2403.20308)

    ChainNet是一个词典资源，首次明确地识别了WordNet中词义的结构化隐喻和转喻关系，成为第一个具有基础隐喻和转喻数据集的资源。

    

    一个词的意义展现出丰富的内部结构。在典型的词典中，这种结构往往被忽视：一个词的意义被编码为一个没有意义间关系的列表。我们介绍了ChainNet，这是一个词典资源，首次明确地识别了这些结构。ChainNet表达了在Open English Wordnet中词义如何从彼此衍生出来：一个词的每个名词意义要么通过隐喻或转喻与另一个意义相连，要么在同义词的情况下是断开的。由于WordNet的含义与捕捉其含义信息的资源相连，ChainNet代表了第一个具有基础隐喻和转喻的数据集。

    arXiv:2403.20308v1 Announce Type: cross  Abstract: The senses of a word exhibit rich internal structure. In a typical lexicon, this structure is overlooked: a word's senses are encoded as a list without inter-sense relations. We present ChainNet, a lexical resource which for the first time explicitly identifies these structures. ChainNet expresses how senses in the Open English Wordnet are derived from one another: every nominal sense of a word is either connected to another sense by metaphor or metonymy, or is disconnected in the case of homonymy. Because WordNet senses are linked to resources which capture information about their meaning, ChainNet represents the first dataset of grounded metaphor and metonymy.
    
[^6]: 情感锚定的对比学习框架用于会话中的情感识别

    Emotion-Anchored Contrastive Learning Framework for Emotion Recognition in Conversation

    [https://arxiv.org/abs/2403.20289](https://arxiv.org/abs/2403.20289)

    提出了一种情感锚定的对比学习框架，用于在会话中识别情感，能够生成更易区分的话语表示，提高了相似情感的区分度和分类性能。

    

    arXiv:2403.20289v1 公告类型: 新摘要: 会话中的情感识别（ERC）涉及在对话中检测每个话语背后的情感。有效生成话语表示仍然是这一任务中的重大挑战。最近的研究提出了各种模型来解决这个问题，但它们仍然在区分类似情感（如兴奋和幸福）方面存在困难。为了缓解这一问题，我们提出了一种情感锚定的对比学习（EACL）框架，可以为相似情感生成更易区分的话语表示。为了实现这一目标，我们利用标签编码作为锚点来指导话语表示的学习，并设计了一个辅助损失来确保相似情感的锚点有效分离。此外，我们提出了一个额外的适应过程，用于调整锚点以作为有效的分类器，以改善分类性能。通过广泛实验证明，我们的方法在不同数据集上实现了显著的性能提升。

    arXiv:2403.20289v1 Announce Type: new  Abstract: Emotion Recognition in Conversation (ERC) involves detecting the underlying emotion behind each utterance within a conversation. Effectively generating representations for utterances remains a significant challenge in this task. Recent works propose various models to address this issue, but they still struggle with differentiating similar emotions such as excitement and happiness. To alleviate this problem, We propose an Emotion-Anchored Contrastive Learning (EACL) framework that can generate more distinguishable utterance representations for similar emotions. To achieve this, we utilize label encodings as anchors to guide the learning of utterance representations and design an auxiliary loss to ensure the effective separation of anchors for similar emotions. Moreover, an additional adaptation process is proposed to adapt anchors to serve as effective classifiers to improve classification performance. Across extensive experiments, our pr
    
[^7]: LLM能够在医学领域中纠正医生吗？研究有效的交互方法

    Can LLMs Correct Physicians, Yet? Investigating Effective Interaction Methods in the Medical Domain

    [https://arxiv.org/abs/2403.20288](https://arxiv.org/abs/2403.20288)

    LLMs在医学决策中提供重要反馈，可以挑战不正确的诊断，促进更准确的决策。

    

    我们探讨了大型语言模型（LLMs）在协助并可能纠正医生进行医疗决策任务方面的潜力。我们评估了几种LLMs，包括Meditron、Llama2和Mistral，分析这些模型在不同情景下与医生有效交互的能力。我们考虑了来自PubMedQA的问题和几项任务，从二元（是/否）回答到长答案生成，其中模型的答案是在与医生交互后产生的。我们的研究结果表明，提示设计显著影响了LLMs的下游准确性，并且LLMs可以为医生提供有价值的反馈，挑战不正确的诊断，促进更准确的决策。例如，当医生准确率为38%时，Mistral可以给出正确答案，根据所使用的提示，将准确性提高到74%，而Llama2和Meditron模型也能提供类似的改进。

    arXiv:2403.20288v1 Announce Type: cross  Abstract: We explore the potential of Large Language Models (LLMs) to assist and potentially correct physicians in medical decision-making tasks. We evaluate several LLMs, including Meditron, Llama2, and Mistral, to analyze the ability of these models to interact effectively with physicians across different scenarios. We consider questions from PubMedQA and several tasks, ranging from binary (yes/no) responses to long answer generation, where the answer of the model is produced after an interaction with a physician. Our findings suggest that prompt design significantly influences the downstream accuracy of LLMs and that LLMs can provide valuable feedback to physicians, challenging incorrect diagnoses and contributing to more accurate decision-making. For example, when the physician is accurate 38% of the time, Mistral can produce the correct answer, improving accuracy up to 74% depending on the prompt being used, while Llama2 and Meditron models
    
[^8]: LayerNorm：参数高效微调中的关键组件

    LayerNorm: A key component in parameter-efficient fine-tuning

    [https://arxiv.org/abs/2403.20284](https://arxiv.org/abs/2403.20284)

    LayerNorm在参数高效微调中扮演关键角色，微调output LayerNorm而保持其他部分不变足以在多个GLUE任务中取得竞争力

    

    细调预训练模型，如双向编码器表示来自转换器（BERT），已被证明是解决许多自然语言处理（NLP）任务的有效方法。然而，由于许多最先进的NLP模型（包括BERT）中的参数数量庞大，微调过程耗费了大量计算资源。解决这一问题的一种吸引人方法是参数高效微调，即仅修改模型的最小部分，同时保持其余部分不变。然而，目前仍不清楚BERT模型的哪个部分对微调至关重要。在本文中，我们首先分析BERT模型中的不同组件，以查明在微调后哪些组件发生了最显著的变化。我们发现，在针对不同General Language Understanding Evaluation（GLUE）任务进行微调时，输出的LayerNorm发生的变化比其他组件都要大。然后我们展示仅微调output LayerNorm而保持其他部分不变就足以在多个GLUE任务中取得竞争力。

    arXiv:2403.20284v1 Announce Type: new  Abstract: Fine-tuning a pre-trained model, such as Bidirectional Encoder Representations from Transformers (BERT), has been proven to be an effective method for solving many natural language processing (NLP) tasks. However, due to the large number of parameters in many state-of-the-art NLP models, including BERT, the process of fine-tuning is computationally expensive. One attractive solution to this issue is parameter-efficient fine-tuning, which involves modifying only a minimal segment of the model while keeping the remainder unchanged. Yet, it remains unclear which segment of the BERT model is crucial for fine-tuning. In this paper, we first analyze different components in the BERT model to pinpoint which one undergoes the most significant changes after fine-tuning. We find that output LayerNorm changes more than any other components when fine-tuned for different General Language Understanding Evaluation (GLUE) tasks. Then we show that only fi
    
[^9]: LUQ：LLM模型的长文本不确定性量化

    LUQ: Long-text Uncertainty Quantification for LLMs

    [https://arxiv.org/abs/2403.20279](https://arxiv.org/abs/2403.20279)

    LUQ提出了一种针对长文本设计的新型采样UQ方法，优于现有基准方法在与模型的事实得分相关方面。

    

    大型语言模型（LLMs）在各种自然语言处理任务中展现出了显著的能力。尽管它们有效，但这些模型倾向于生成非事实内容。不确定性量化（UQ）对于增强我们对模型在生成内容上的信心至关重要，从而有助于减轻非事实输出。现有的UQ研究主要针对短文本生成，通常产生简短的、受词限制的响应。然而，现实世界中的应用往往需要更长的响应。我们的研究首先强调了当前UQ方法在处理长文本生成中的局限性。然后，我们介绍了一种名为\textsc{Luq}的新型基于抽样的UQ方法，专门设计用于长文本。我们的研究结果显示，\textsc{Luq}在与模型的事实得分相关方面优于现有的基准方法（Gemini Pro观察到-0.85的负相关系数）。

    arXiv:2403.20279v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated remarkable capability in a variety of NLP tasks. Despite their effectiveness, these models are prone to generate nonfactual content. Uncertainty Quantification (UQ) is pivotal in enhancing our understanding of a model's confidence in its generated content, thereby aiding in the mitigation of nonfactual outputs. Existing research on UQ predominantly targets short text generation, typically yielding brief, word-limited responses. However, real-world applications frequently necessitate much longer responses. Our study first highlights the limitations of current UQ methods in handling long text generation. We then introduce \textsc{Luq}, a novel sampling-based UQ approach specifically designed for long text. Our findings reveal that \textsc{Luq} outperforms existing baseline methods in correlating with the model's factuality scores (negative coefficient of -0.85 observed for Gemini Pro). With \t
    
[^10]: Latxa: 一种用于巴斯克语的开放语言模型和评估套件

    Latxa: An Open Language Model and Evaluation Suite for Basque

    [https://arxiv.org/abs/2403.20266](https://arxiv.org/abs/2403.20266)

    Latxa是一种用于巴斯克语的大型语言模型系列，在语言熟练度和理解能力方面表现出色，优于所有以前的开放模型，并具有多个评估数据集，填补了巴斯克语高质量基准的不足。

    

    我们介绍了Latxa，这是一个基于Llama 2的大型巴斯克语言模型系列，参数范围从7到700亿。Latxa基于新的巴斯克语语料库预训练，包括430万个文档和42亿个标记。针对巴斯克语高质量基准的稀缺性，我们进一步提出了4个多项选择评估数据集：EusProficiency，包括来自官方语言能力考试的5169个问题；EusReading，包括352个阅读理解问题；EusTrivia，包括来自5个知识领域的1715个琐事问题；以及EusExams，包括来自公共考试的16774个问题。在我们的广泛评估中，Latxa在与我们比较的所有先前开放模型中表现出色。此外，尽管在阅读理解和知识密集型任务方面落后，但在语言熟练度和理解能力方面，它与GPT-4 Turbo具有竞争力。Latxa模型系列，以及

    arXiv:2403.20266v1 Announce Type: cross  Abstract: We introduce Latxa, a family of large language models for Basque ranging from 7 to 70 billion parameters. Latxa is based on Llama 2, which we continue pretraining on a new Basque corpus comprising 4.3M documents and 4.2B tokens. Addressing the scarcity of high-quality benchmarks for Basque, we further introduce 4 multiple choice evaluation datasets: EusProficiency, comprising 5,169 questions from official language proficiency exams; EusReading, comprising 352 reading comprehension questions; EusTrivia, comprising 1,715 trivia questions from 5 knowledge areas; and EusExams, comprising 16,774 questions from public examinations. In our extensive evaluation, Latxa outperforms all previous open models we compare to by a large margin. In addition, it is competitive with GPT-4 Turbo in language proficiency and understanding, despite lagging behind in reading comprehension and knowledge-intensive tasks. Both the Latxa family of models, as well
    
[^11]: ELITR-Bench: 面向长上下文语言模型的会议助理基准

    ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models

    [https://arxiv.org/abs/2403.20262](https://arxiv.org/abs/2403.20262)

    该论文提出了一个新的基准 ELITR-Bench，专注于长上下文语言模型的实际会议助理场景，通过在现有 ELITR 语料库的转录中添加手工制作的问题和真实答案，揭示了开源模型和专有模型之间的差距。

    

    最近，对大型语言模型（LLMs）的研究越来越受到关注，主要致力于扩展模型的上下文大小，以更好地捕捉长文档内部的依赖关系。尽管已经提出了用于评估长距离能力的基准，但现有的努力主要考虑的是不一定与现实应用相关的通用任务。相反，我们的工作提出了一个针对实际会议助理场景的长上下文LLMs的新基准。在这种情景下，长上下文由自动语音识别获得的转录组成，由于这些数据的固有嘈杂性和口语特性，这为LLMs提出了独特的挑战。我们的基准，名为ELITR-Bench，通过271个手工制作的问题及其真实答案来增强现有的ELITR语料库的转录。我们在ELITR-Bench上对最新的长上下文LLMs进行的实验凸显了开源模型和专有模型之间的差距。

    arXiv:2403.20262v1 Announce Type: cross  Abstract: Research on Large Language Models (LLMs) has recently witnessed an increasing interest in extending models' context size to better capture dependencies within long documents. While benchmarks have been proposed to assess long-range abilities, existing efforts primarily considered generic tasks that are not necessarily aligned with real-world applications. In contrast, our work proposes a new benchmark for long-context LLMs focused on a practical meeting assistant scenario. In this scenario, the long contexts consist of transcripts obtained by automatic speech recognition, presenting unique challenges for LLMs due to the inherent noisiness and oral nature of such data. Our benchmark, named ELITR-Bench, augments the existing ELITR corpus' transcripts with 271 manually crafted questions and their ground-truth answers. Our experiments with recent long-context LLMs on ELITR-Bench highlight a gap between open-source and proprietary models, e
    
[^12]: 使用LLMs建模目标人群的信念和偏好

    Using LLMs to Model the Beliefs and Preferences of Targeted Populations

    [https://arxiv.org/abs/2403.20252](https://arxiv.org/abs/2403.20252)

    使用LLMs建模目标人群的信念和偏好，旨在实现各种应用，评估不同微调方法的效果，并检验其在匹配真实人类受访者偏好方面的能力。

    

    我们考虑了将大型语言模型(LLM)与人群的偏好进行对齐的问题。建模特定人群的信念、偏好和行为对于各种不同应用可能很有用，比如为新产品开展模拟焦点小组、进行虚拟调查以及测试行为干预，特别是对于昂贵、不切实际或不道德的干预。现有研究在不同情境下使用LLMs准确建模人类行为方面取得了不同程度的成功。我们对两种众所周知的微调方法进行基准测试和评估，评估得到的人群在匹配对电池电动汽车(BEVs)偏好调查中真实人类受访者偏好方面的能力。我们评估我们的模型是否能与整体人口统计数据以及个体回应相匹配，并研究LLMs在建模人群信念和偏好方面的作用。

    arXiv:2403.20252v1 Announce Type: cross  Abstract: We consider the problem of aligning a large language model (LLM) to model the preferences of a human population. Modeling the beliefs, preferences, and behaviors of a specific population can be useful for a variety of different applications, such as conducting simulated focus groups for new products, conducting virtual surveys, and testing behavioral interventions, especially for interventions that are expensive, impractical, or unethical. Existing work has had mixed success using LLMs to accurately model human behavior in different contexts. We benchmark and evaluate two well-known fine-tuning approaches and evaluate the resulting populations on their ability to match the preferences of real human respondents on a survey of preferences for battery electric vehicles (BEVs). We evaluate our models against their ability to match population-wide statistics as well as their ability to match individual responses, and we investigate the role
    
[^13]: 用于低延迟检索的浅层交叉编码器

    Shallow Cross-Encoders for Low-Latency Retrieval

    [https://arxiv.org/abs/2403.20222](https://arxiv.org/abs/2403.20222)

    张海洋这里是中文总结出的一句话要点：本文展示了在低延迟设置下，较弱的浅层Transformer模型在文本检索中的表现优于完整模型，并且可能受益于广义二元交叉熵（gBCE）训练方案。

    

    基于Transformer的交叉编码器在文本检索中取得了最先进的效果。然而，基于大型Transformer模型（如BERT或T5）的交叉编码器在计算上是昂贵的，且只允许在相对较小的延迟时间窗口内评分少量文档。本文表明，用于这些实际低延迟设置的较弱的浅层Transformer模型（即具有有限层数的Transformer）实际上比完整模型表现更好，因为它们可以在同样的时间预算内估算出更多文档的相关性。我们进一步表明，浅层Transformer可能会受益于最近在推荐任务中展示成功的广义二元交叉熵（gBCE）训练方案。我们在TREC深度学习段落排序查询集上的实验证明。

    arXiv:2403.20222v1 Announce Type: cross  Abstract: Transformer-based Cross-Encoders achieve state-of-the-art effectiveness in text retrieval. However, Cross-Encoders based on large transformer models (such as BERT or T5) are computationally expensive and allow for scoring only a small number of documents within a reasonably small latency window. However, keeping search latencies low is important for user satisfaction and energy usage. In this paper, we show that weaker shallow transformer models (i.e., transformers with a limited number of layers) actually perform better than full-scale models when constrained to these practical low-latency settings since they can estimate the relevance of more documents in the same time budget. We further show that shallow transformers may benefit from the generalized Binary Cross-Entropy (gBCE) training scheme, which has recently demonstrated success for recommendation tasks. Our experiments with TREC Deep Learning passage ranking query sets demonstr
    
[^14]: 推进阿拉伯语WordNet：提升内容质量

    Advancing the Arabic WordNet: Elevating Content Quality

    [https://arxiv.org/abs/2403.20215](https://arxiv.org/abs/2403.20215)

    本文关注阿拉伯语，通过对阿拉伯语WordNet进行重大修订，提高内容质量，更新了超过58%的同义词集，并解决了词形错误和缺失信息等问题

    

    高质量的WordNet对于依赖此类资源的NLP应用程序实现高质量结果至关重要。然而，大多数语言的WordNet存在严重的正确性和完整性问题，包括错误的词形、缺失的注释和例句，以及对语言的形态和语义的不足，体现了西方中心的表征。先前的努力主要集中在增加词汇覆盖率，而忽略了其他质量方面。在本文中，我们专注于阿拉伯语并介绍了阿拉伯语WordNet的重大修订，涵盖了词汇语义资源质量的多个维度。结果，我们通过添加缺失信息和纠正错误更新了现有阿拉伯语WordNet超过58%的同义词集。为了解决语言多样性和无法翻译性的问题，我们还扩展了

    arXiv:2403.20215v1 Announce Type: new  Abstract: High-quality WordNets are crucial for achieving high-quality results in NLP applications that rely on such resources. However, the wordnets of most languages suffer from serious issues of correctness and completeness with respect to the words and word meanings they define, such as incorrect lemmas, missing glosses and example sentences, or an inadequate, Western-centric representation of the morphology and the semantics of the language. Previous efforts have largely focused on increasing lexical coverage while ignoring other qualitative aspects. In this paper, we focus on the Arabic language and introduce a major revision of the Arabic WordNet that addresses multiple dimensions of lexico-semantic resource quality. As a result, we updated more than 58% of the synsets of the existing Arabic WordNet by adding missing information and correcting errors. In order to address issues of language diversity and untranslatability, we also extended t
    
[^15]: 不同话语标注框架的话语关系自动对齐

    Automatic Alignment of Discourse Relations of Different Discourse Annotation Frameworks

    [https://arxiv.org/abs/2403.20196](https://arxiv.org/abs/2403.20196)

    研究探索不同话语标注框架间的话语关系清单相关性，并提出半自动方法来解决这一问题。

    

    现有的话语语料库基于不同的框架进行标注，在参数和关系的定义以及结构约束方面存在显著差异。尽管表面上存在差异，这些框架分享话语关系的基本理解。这些框架之间的关系一直是一个开放性的研究问题，特别是不同框架中使用的关系清单之间的相关性。更好地理解这个问题有助于整合话语理论，并实现在不同框架下标注的话语语料库的互操作性。然而，研究探索话语关系清单之间的相关性受到了话语划分标准的不同限制，通常需要专家知识和手动检查。一些半自动方法已被提出，但这些方法依赖于同时在多个框架中进行标注的语料库。

    arXiv:2403.20196v1 Announce Type: new  Abstract: Existing discourse corpora are annotated based on different frameworks, which show significant dissimilarities in definitions of arguments and relations and structural constraints. Despite surface differences, these frameworks share basic understandings of discourse relations. The relationship between these frameworks has been an open research question, especially the correlation between relation inventories utilized in different frameworks. Better understanding of this question is helpful for integrating discourse theories and enabling interoperability of discourse corpora annotated under different frameworks. However, studies that explore correlations between discourse relation inventories are hindered by different criteria of discourse segmentation, and expert knowledge and manual examination are typically needed. Some semi-automatic methods have been proposed, but they rely on corpora annotated in multiple frameworks in parallel. In 
    
[^16]: 利用ASR驱动的Wav2Vec2在数据稀缺环境中探究病态语音质量评估

    Exploring Pathological Speech Quality Assessment with ASR-Powered Wav2Vec2 in Data-Scarce Context

    [https://arxiv.org/abs/2403.20184](https://arxiv.org/abs/2403.20184)

    本文提出了一种新颖的方法，在数据稀缺情况下系统在整体音频级别进行学习，同时利用ASR驱动的Wav2Vec2架构作为特征提取器，在语音评估中取得了显著的结果。

    

    自动语音质量评估作为传统感知临床评估的替代或支持近年来备受关注。然而，迄今为止大部分研究仅在简单任务（如二元分类）上取得了良好的结果，这主要是由于数据稀缺造成的。为了应对这一挑战，目前的研究倾向于将患者的音频文件分割成多个样本以增加数据集。然而，这种方法存在局限性，因为它将整体音频得分间接地与个别段相关联。本文提出了一种新颖的方法，即系统在整个音频级别学习，而不是在片段级别学习，尽管存在数据稀缺情况。本文建议在语音评估中使用预训练的Wav2Vec2架构进行自监督学习（SSL）和ASR作为特征提取器。在HNC数据集上进行了实验，我们的ASR驱动方法与其他方法相比建立了新的基线，实现了平均$MSE=0.73$和$MSE=1.15$来预测智商。

    arXiv:2403.20184v1 Announce Type: cross  Abstract: Automatic speech quality assessment has raised more attention as an alternative or support to traditional perceptual clinical evaluation. However, most research so far only gains good results on simple tasks such as binary classification, largely due to data scarcity. To deal with this challenge, current works tend to segment patients' audio files into many samples to augment the datasets. Nevertheless, this approach has limitations, as it indirectly relates overall audio scores to individual segments. This paper introduces a novel approach where the system learns at the audio level instead of segments despite data scarcity. This paper proposes to use the pre-trained Wav2Vec2 architecture for both SSL, and ASR as feature extractor in speech assessment. Carried out on the HNC dataset, our ASR-driven approach established a new baseline compared with other approaches, obtaining average $MSE=0.73$ and $MSE=1.15$ for the prediction of intel
    
[^17]: 测量台湾普通话理解能力

    Measuring Taiwanese Mandarin Language Understanding

    [https://arxiv.org/abs/2403.20180](https://arxiv.org/abs/2403.20180)

    该研究致力于在评估汉语环境中的大型语言模型，提出了一个综合评估套件TMLU，覆盖37个科目，通过精心策划的少样本解释促进复杂推理能力的评估，并对24个高级LLMs进行了广泛实验和分析，结果显示中国开放权重模型表现较差。

    

    最近，对大型语言模型（LLMs）的评估引起了领域内的重视。本研究致力于在汉语环境下评估LLMs，具体而言，针对传统中文，在现有基准中一直存在着较大的欠表征。我们提出了TMLU，这是一个为评估LLMs的高级知识和推理能力量身定制的综合评估套件，适用于台湾普通话环境。TMLU由37个科目组成，涵盖社会科学、STEM、人文学科、台湾特定内容等，涉及初中到专业水平。此外，我们为每个科目精心策划了一些类似于思维链的少样本解释，以促进复杂推理能力的评估。为建立全面的基准线，我们对24个高级LLMs进行了广泛的实验和分析。研究结果表明，相较于多项式开重量模型，中国开放权重模型表现出较低的性能。

    arXiv:2403.20180v1 Announce Type: new  Abstract: The evaluation of large language models (LLMs) has drawn substantial attention in the field recently. This work focuses on evaluating LLMs in a Chinese context, specifically, for Traditional Chinese which has been largely underrepresented in existing benchmarks. We present TMLU, a holistic evaluation suit tailored for assessing the advanced knowledge and reasoning capability in LLMs, under the context of Taiwanese Mandarin. TMLU consists of an array of 37 subjects across social science, STEM, humanities, Taiwan-specific content, and others, ranging from middle school to professional levels. In addition, we curate chain-of-thought-like few-shot explanations for each subject to facilitate the evaluation of complex reasoning skills. To establish a comprehensive baseline, we conduct extensive experiments and analysis on 24 advanced LLMs. The results suggest that Chinese open-weight models demonstrate inferior performance comparing to multili
    
[^18]: ChatGPT与媒体偏见：GPT-3.5和Fine-tuned语言模型的比较研究

    ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models

    [https://arxiv.org/abs/2403.20158](https://arxiv.org/abs/2403.20158)

    研究比较了ChatGPT与Fine-tuned语言模型在检测媒体偏见方面的表现，发现ChatGPT在检测仇恨言论和文本级上下文偏见方面表现一致，但在检测虚假新闻、种族、性别和认知偏见方面则存在困难。

    

    在我们快速发展的数字领域中，辨别媒体偏见的能力变得至关重要，因为它可以塑造公众情绪并影响关键决策。大型语言模型（LLMs），如ChatGPT，在各种自然语言处理（NLP）任务中具有广泛实用性，引发了对它们在媒体偏见检测中有效性的探究。ChatGPT能否检测媒体偏见？本研究旨在通过利用媒体偏见识别基准（MBIB）来评估ChatGPT在区分六种媒体偏见方面的能力，与Fine-tuned模型（如BART、ConvBERT和GPT-2）进行对比。研究结果呈现了一种二分法：ChatGPT在检测仇恨言论和文本级上下文偏见方面与Fine-tuned模型表现一致，但在其他偏见检测的更微妙要素上，即虚假新闻、种族、性别和认知偏见方面则面临困难。

    arXiv:2403.20158v1 Announce Type: cross  Abstract: In our rapidly evolving digital sphere, the ability to discern media bias becomes crucial as it can shape public sentiment and influence pivotal decisions. The advent of large language models (LLMs), such as ChatGPT, noted for their broad utility in various natural language processing (NLP) tasks, invites exploration of their efficacy in media bias detection. Can ChatGPT detect media bias? This study seeks to answer this question by leveraging the Media Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in distinguishing six categories of media bias, juxtaposed against fine-tuned models such as BART, ConvBERT, and GPT-2. The findings present a dichotomy: ChatGPT performs at par with fine-tuned models in detecting hate speech and text-level context bias, yet faces difficulties with subtler elements of other bias detections, namely, fake news, racial, gender, and cognitive biases.
    
[^19]: 多语种翻译中的子词和跨语言迁移的系统分析

    A Systematic Analysis of Subwords and Cross-Lingual Transfer in Multilingual Translation

    [https://arxiv.org/abs/2403.20157](https://arxiv.org/abs/2403.20157)

    本文研究了多语种翻译中子词分割的作用，发现子词正则化提高了多语种建模的协同作用，而BPE则更有效地促进了跨语言迁移。

    

    多语种建模可以通过共享子词表示部分改善低资源语言的机器翻译。本文研究了子词分割在跨语言迁移中的作用。我们系统比较了几种子词方法在不同语言类型之间促进协同作用和防止干扰的功效。研究结果表明，子词正则化提高了多语种建模中的协同作用，而BPE在跨语言微调中更有效地促进了迁移。值得注意的是，我们的结果表明，正字法单词边界约定的差异（书面词汇形态的粒度）可能比语言无关性更显著地阻碍跨语言迁移。我们的研究证实，围绕子词建模的决策可能是优化多语种建模效益的关键。

    arXiv:2403.20157v1 Announce Type: new  Abstract: Multilingual modelling can improve machine translation for low-resource languages, partly through shared subword representations. This paper studies the role of subword segmentation in cross-lingual transfer. We systematically compare the efficacy of several subword methods in promoting synergy and preventing interference across different linguistic typologies. Our findings show that subword regularisation boosts synergy in multilingual modelling, whereas BPE more effectively facilitates transfer during cross-lingual fine-tuning. Notably, our results suggest that differences in orthographic word boundary conventions (the morphological granularity of written words) may impede cross-lingual transfer more significantly than linguistic unrelatedness. Our study confirms that decisions around subword modelling can be key to optimising the benefits of multilingual modelling.
    
[^20]: IndiBias：一个用于衡量印度语境下语言模型社会偏见的基准数据集

    IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context

    [https://arxiv.org/abs/2403.20147](https://arxiv.org/abs/2403.20147)

    IndiBias是一个为评估印度语境中社会偏见而设计的综合基准数据集，通过过滤和翻译现有数据集以及利用不同LLMs的方法，涵盖了印度中流行的各种社会偏见维度。

    

    在语言数据中普遍存在的社会偏见影响引发了对捕捉和评估大型语言模型（LLMs）中这些偏见的基准数据集的需求。现有工作主要集中在英语和西方背景，缺乏一个可靠的数据集，能够体现印度独特的社会文化细微差别。为了弥补这一空白，我们引入了IndiBias，这是一个专门设计用于评估印度语境中社会偏见的全面基准数据集。我们过滤和翻译现有的CrowS-Pairs数据集，创建了一个适合印度语境中使用的基准数据集，使用印地语。此外，我们利用包括ChatGPT和InstructGPT在内的LLMs，以印度流行的各种社会偏见和刻板印象增强我们的数据集。包含的偏见维度涵盖性别、宗教、种姓、年龄、地区、外貌和职业。我们还建立了一个资源来解决交叉

    arXiv:2403.20147v1 Announce Type: new  Abstract: The pervasive influence of social biases in language data has sparked the need for benchmark datasets that capture and evaluate these biases in Large Language Models (LLMs). Existing efforts predominantly focus on English language and the Western context, leaving a void for a reliable dataset that encapsulates India's unique socio-cultural nuances. To bridge this gap, we introduce IndiBias, a comprehensive benchmarking dataset designed specifically for evaluating social biases in the Indian context. We filter and translate the existing CrowS-Pairs dataset to create a benchmark dataset suited to the Indian context in Hindi language. Additionally, we leverage LLMs including ChatGPT and InstructGPT to augment our dataset with diverse societal biases and stereotypes prevalent in India. The included bias dimensions encompass gender, religion, caste, age, region, physical appearance, and occupation. We also build a resource to address intersec
    
[^21]: 为自动诊断筛查总结优化大型语言模型的研究

    Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries

    [https://arxiv.org/abs/2403.20145](https://arxiv.org/abs/2403.20145)

    该研究通过评估大型语言模型在自定义数据集上的微调和未微调，发现经过微调的模型胜过现有模型，在生成摘要方面取得了显著的进展。

    

    在发展中国家改善心理健康支持是一个紧迫的需求。一种潜在的解决方案是开发可扩展的自动系统进行诊断筛查，这有助于减轻心理健康专业人员的负担。本研究评估了几种最先进的大型语言模型（LLMs）在自定义数据集上进行了微调和未微调，用于从心理状态检查中生成简明摘要。我们使用已建立的ROUGE指标和人类评估者的输入，对四种不同的摘要生成模型进行了严格评估。结果表明，我们表现最佳的经过微调的模型胜过现有模型，分别实现了0.810和0.764的ROUGE-1和ROUGE-L值。此外，我们对微调模型在公开可用的D4数据集上的泛化能力进行了评估，结果令人鼓舞，表明其潜在适用性超出我们的自定义数据集。

    arXiv:2403.20145v1 Announce Type: new  Abstract: Improving mental health support in developing countries is a pressing need. One potential solution is the development of scalable, automated systems to conduct diagnostic screenings, which could help alleviate the burden on mental health professionals. In this work, we evaluate several state-of-the-art Large Language Models (LLMs), with and without fine-tuning, on our custom dataset for generating concise summaries from mental state examinations. We rigorously evaluate four different models for summary generation using established ROUGE metrics and input from human evaluators. The results highlight that our top-performing fine-tuned model outperforms existing models, achieving ROUGE-1 and ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessed the fine-tuned model's generalizability on a publicly available D4 dataset, and the outcomes were promising, indicating its potential applicability beyond our custom dataset.
    
[^22]: 交互式AI助手系统中的用户建模挑战

    User Modeling Challenges in Interactive AI Assistant Systems

    [https://arxiv.org/abs/2403.20134](https://arxiv.org/abs/2403.20134)

    分析用户在任务执行过程中的心理状态，研究大型语言模型解读用户资料以实现更个性化用户指导的能力和挑战。

    

    交互式人工智能（AI）助手系统旨在提供及时的指导，帮助用户完成各种任务。其中仍然存在的挑战之一是在任务执行过程中了解用户的心理状态，以提供更加个性化的指导。本研究分析了用户在任务执行过程中的心理状态，并研究了大型语言模型解读用户资料以实现更个性化用户指导的能力和挑战。

    arXiv:2403.20134v1 Announce Type: new  Abstract: Interactive Artificial Intelligent(AI) assistant systems are designed to offer timely guidance to help human users to complete a variety tasks. One of the remaining challenges is to understand user's mental states during the task for more personalized guidance. In this work, we analyze users' mental states during task executions and investigate the capabilities and challenges for large language models to interpret user profiles for more personalized user guidance.
    
[^23]: NLP用于对抗仇恨的言论：调查与实用指南

    NLP for Counterspeech against Hate: A Survey and How-To Guide

    [https://arxiv.org/abs/2403.20103](https://arxiv.org/abs/2403.20103)

    反言论作为一种非升级回应策略，可以有效减少在线和离线暴力，最近NLP社区对于分析、收集、分类和自动生成反言论的挑战表现出越来越浓厚的兴趣。

    

    近年来，反言论已经成为打击网络仇恨的最有前途的策略之一。这些非升级回应处理在线虐待行为的同时保留用户的言论自由，并且在减少在线和离线暴力方面可以产生切实影响。最近，自然语言处理（NLP）社区对分析、收集、分类和自动生成反言论的挑战表现出越来越浓厚的兴趣，以减轻手动生产的巨大负担。特别是，研究人员在解决这些挑战方面采取了不同的方向，因此提供了各种相关任务和资源。在本文中，我们通过详细示例描述了研究反言论的步骤，并提供了可以从这个主题的NLP研究中学到的最佳实践，为研究反言论提供一个指南。最后，我们讨论了存在的挑战和未来。

    arXiv:2403.20103v1 Announce Type: new  Abstract: In recent years, counterspeech has emerged as one of the most promising strategies to fight online hate. These non-escalatory responses tackle online abuse while preserving the freedom of speech of the users, and can have a tangible impact in reducing online and offline violence. Recently, there has been growing interest from the Natural Language Processing (NLP) community in addressing the challenges of analysing, collecting, classifying, and automatically generating counterspeech, to reduce the huge burden of manually producing it. In particular, researchers have taken different directions in addressing these challenges, thus providing a variety of related tasks and resources. In this paper, we provide a guide for doing research on counterspeech, by describing - with detailed examples - the steps to undertake, and providing best practices that can be learnt from the NLP studies on this topic. Finally, we discuss open challenges and fut
    
[^24]: RealKIE: 五个新颖的企业关键信息提取数据集

    RealKIE: Five Novel Datasets for Enterprise Key Information Extraction

    [https://arxiv.org/abs/2403.20101](https://arxiv.org/abs/2403.20101)

    RealKIE提供了五个具有挑战性的企业关键信息提取数据集，为投资分析和法律数据处理等任务提供了现实的测试基地，并为NLP模型的发展做出了贡献。

    

    我们介绍了RealKIE，这是一个旨在推动关键信息提取方法发展的五个具有挑战性的数据集基准，重点是企业应用。这些数据集包括美国SEC S1文件、美国保密协议、英国慈善报告、FCC发票和资源合同等各种类型的文档。每个数据集都具有独特的挑战：文本序列化不佳、长文档中稀疏的注释和复杂的表格布局。这些数据集为关键信息提取任务（如投资分析和法律数据处理）提供了一个现实的测试基地。除了介绍这些数据集外，我们还提供了对注释过程、文档处理技术和基线建模方法的深入描述。这一贡献促进了能够处理实际挑战的NLP模型的发展，并支持进一步研究可应用于工业的信息提取技术。

    arXiv:2403.20101v1 Announce Type: new  Abstract: We introduce RealKIE, a benchmark of five challenging datasets aimed at advancing key information extraction methods, with an emphasis on enterprise applications. The datasets include a diverse range of documents including SEC S1 Filings, US Non-disclosure Agreements, UK Charity Reports, FCC Invoices, and Resource Contracts. Each presents unique challenges: poor text serialization, sparse annotations in long documents, and complex tabular layouts. These datasets provide a realistic testing ground for key information extraction tasks like investment analysis and legal data processing.   In addition to presenting these datasets, we offer an in-depth description of the annotation process, document processing techniques, and baseline modeling approaches. This contribution facilitates the development of NLP models capable of handling practical challenges and supports further research into information extraction technologies applicable to indu
    
[^25]: 在多语言语言模型中研究跨语言迁移的高效方法

    An Efficient Approach for Studying Cross-Lingual Transfer in Multilingual Language Models

    [https://arxiv.org/abs/2403.20088](https://arxiv.org/abs/2403.20088)

    提出了一种高效方法来研究零翻译语言模型在目标语言上的迁移语言影响，发现一些语言对其他语言影响不大，而一些语言对不同目标语言可能极为有利或有害，同时也观察到以前未被MLMs看到的语言始终受益于来自几乎所有迁移。

    

    arXiv:2403.20088v1 公告类型：新摘要：众所周知，预训练的多语言模型（MLMs）在零翻译跨语言迁移的容量和效果已经得到确认。然而，正向或负向迁移的现象以及语言选择的影响仍需要得到充分理解，特别是在大规模多语言LMs的复杂环境中。我们提出了一种\textit {高效}方法来研究零翻译性能上对目标语言的迁移语言影响。与以往工作不同，我们的方法将下游任务与语言分离，使用专用的适配器单元。我们的研究结果表明，一些语言对其他语言影响不大，而一些语言，尤其是在预训练期间未见过的语言，对不同的目标语言可能极为有利或有害。我们发现没有一种迁移语言对所有目标语言都有益。我们奇怪地观察到，此前未被MLMs看到的语言一直受益于来自几乎所有迁移

    arXiv:2403.20088v1 Announce Type: new  Abstract: The capacity and effectiveness of pre-trained multilingual models (MLMs) for zero-shot cross-lingual transfer is well established. However, phenomena of positive or negative transfer, and the effect of language choice still need to be fully understood, especially in the complex setting of massively multilingual LMs. We propose an \textit{efficient} method to study transfer language influence in zero-shot performance on another target language. Unlike previous work, our approach disentangles downstream tasks from language, using dedicated adapter units. Our findings suggest that some languages do not largely affect others, while some languages, especially ones unseen during pre-training, can be extremely beneficial or detrimental for different target languages. We find that no transfer language is beneficial for all target languages. We do, curiously, observe languages previously unseen by MLMs consistently benefit from transfer from almo
    
[^26]: 孟加拉文本的国际音标转写

    IPA Transcription of Bengali Texts

    [https://arxiv.org/abs/2403.20084](https://arxiv.org/abs/2403.20084)

    这项工作对孟加拉文本的国际音标转写进行了全面研究，并引入了一个包含基于DL的基准数据集的新颖IPA转写框架。

    

    国际音标（IPA）用于系统化语言中的音素，实现对发音的精确文本表示。在孟加拉语音韵学中，学术界一直在探讨IPA标准和核心孟加拉音素的问题。本研究检视了先前的研究，识别了当前和潜在的问题，并提出了一个孟加拉IPA标准的框架，促进了语言分析和NLP资源创建以及技术发展。

    arXiv:2403.20084v1 Announce Type: new  Abstract: The International Phonetic Alphabet (IPA) serves to systematize phonemes in language, enabling precise textual representation of pronunciation. In Bengali phonology and phonetics, ongoing scholarly deliberations persist concerning the IPA standard and core Bengali phonemes. This work examines prior research, identifies current and potential issues, and suggests a framework for a Bengali IPA standard, facilitating linguistic analysis and NLP resource creation and downstream technology development. In this work, we present a comprehensive study of Bengali IPA transcription and introduce a novel IPA transcription framework incorporating a novel dataset with DL-based benchmarks.
    
[^27]: 在对抗数据集上跨语言传输对低资源语言的鲁棒性

    Cross-Lingual Transfer Robustness to Lower-Resource Languages on Adversarial Datasets

    [https://arxiv.org/abs/2403.20056](https://arxiv.org/abs/2403.20056)

    多语言语言模型展示了强大的跨语言传输能力，对低资源语言的鲁棒性具有实际应用，研究发现命名实体识别跨语言传输在很大程度上取决于实体的重叠

    

    多语言语言模型（MLLMs）展示了强大的跨语言传输能力，即利用在源语言中获取的信息并将其应用于目标语言的能力。这些能力在已建立的自然语言处理（NLP）任务中找到实际应用，如命名实体识别（NER）。该研究旨在调查将源语言应用于目标语言时的有效性，特别是在扰动输入测试集的情况下。我们评估了13对语言，每对语言包括一个高资源语言（HRL）和一个低资源语言（LRL），它们之间存在地理、遗传或借用关系。我们在这些语言对上评估了两个知名的MLLMs--MBERT和XLM-R，在本机LRL和跨语言传输设置中，在两个任务中，在一组不同的扰动下。我们的研究结果表明，NER跨语言传输在很大程度上取决于实体的重叠

    arXiv:2403.20056v1 Announce Type: new  Abstract: Multilingual Language Models (MLLMs) exhibit robust cross-lingual transfer capabilities, or the ability to leverage information acquired in a source language and apply it to a target language. These capabilities find practical applications in well-established Natural Language Processing (NLP) tasks such as Named Entity Recognition (NER). This study aims to investigate the effectiveness of a source language when applied to a target language, particularly in the context of perturbing the input test set. We evaluate on 13 pairs of languages, each including one high-resource language (HRL) and one low-resource language (LRL) with a geographic, genetic, or borrowing relationship. We evaluate two well-known MLLMs--MBERT and XLM-R--on these pairs, in native LRL and cross-lingual transfer settings, in two tasks, under a set of different perturbations. Our findings indicate that NER cross-lingual transfer depends largely on the overlap of entity 
    
[^28]: LLM能从以前的错误中学习吗？调查LLMs'错误以增强推理能力

    Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning

    [https://arxiv.org/abs/2403.20046](https://arxiv.org/abs/2403.20046)

    通过新设计的基准测试\textsc{CoTErrorSet}，研究了LLMs是否能够从以往的错误中学习，尤其是对于推理能力方面的提升。

    

    最近的研究表明，LLMs从微调黄金标准的思维链（CoT）解释或将其用作少量提示中的正确示例中受益。尽管人类确实可以模仿正确的例子，但从我们的错误中学习是人类认知的另一个至关重要的方面。因此，一个问题自然而然地出现：LLMs能否学习并受益于他们的错误，尤其是对于他们的推理？本研究从提示和模型调整的角度研究了这个问题。我们首先介绍了一个新的基准\textsc{CoTErrorSet}，其中包含609,432个问题，每个问题都设计有正确和错误的参考文献，并展示了制造这些错误的类型和原因。为了探讨这些错误的有效性，我们设计了两种方法：（1）\textbf{自我反思}提示指导LLMs重新考虑他们是否曾经犯过类似的错误；和（2）\textbf{错误调整}包括对模型进行微调

    arXiv:2403.20046v1 Announce Type: new  Abstract: Recent works have shown the benefits to LLMs from fine-tuning golden-standard Chain-of-Thought (CoT) rationales or using them as correct examples in few-shot prompting. While humans can indeed imitate correct examples, learning from our mistakes is another vital aspect of human cognition. Hence, a question naturally arises: \textit{can LLMs learn and benefit from their mistakes, especially for their reasoning? } This study investigates this problem from both the prompting and model-tuning perspectives. We begin by introducing \textsc{CoTErrorSet}, a new benchmark with 609,432 questions, each designed with both correct and error references, and demonstrating the types and reasons for making such mistakes. To explore the effectiveness of those mistakes, we design two methods: (1) \textbf{Self-rethinking} prompting guides LLMs to rethink whether they have made similar previous mistakes; and (2) \textbf{Mistake tuning} involves finetuning mo
    
[^29]: Transformer-Lite: 在手机GPU上高效部署大型语言模型

    Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs

    [https://arxiv.org/abs/2403.20041](https://arxiv.org/abs/2403.20041)

    提出了四种优化技术来在手机GPU上高效部署大型语言模型，并通过实现在移动推断引擎Transformer-Lite中，提高了推断速度和降低了手机滞后，从而改善用户体验。

    

    大型语言模型（LLM）被广泛应用于智能助手、文本摘要、翻译和手机上的多模任务。然而，当前的设备上LLM部署方法速度较慢，导致用户体验不佳。为了实现在设备GPU上高效部署LLM，我们提出了四种优化技术：（a）基于符号表达的方法支持动态形状模型推断；（b）操作优化和执行优先级设置以提高推断速度并减少手机滞后；（c）一种名为M0E4的FP4量化方法以减少去量化开销；（d）一种基于子张量的技术来在LLM推断后消除复制KV缓存的需要。此外，我们在我们的移动推断引擎Transformer-Lite中实现了这些方法，该引擎与高通和MTK处理器兼容。我们评估了Transformer-Lite的性能。

    arXiv:2403.20041v1 Announce Type: new  Abstract: The Large Language Model (LLM) is widely employed for tasks such as intelligent assistants, text summarization, translation, and multi-modality on mobile phones. However, the current methods for on-device LLM deployment maintain slow inference speed, which causes poor user experience. To facilitate high-efficiency LLM deployment on device GPUs, we propose four optimization techniques: (a) a symbolic expression-based approach to support dynamic shape model inference; (b) operator optimizations and execution priority setting to enhance inference speed and reduce phone lagging; (c) an FP4 quantization method termed M0E4 to reduce dequantization overhead; (d) a sub-tensor-based technique to eliminate the need for copying KV cache after LLM inference. Furthermore, we implement these methods in our mobile inference engine, Transformer-Lite, which is compatible with both Qualcomm and MTK processors. We evaluated Transformer-Lite's performance u
    
[^30]: FSMR：具有联合文本和视觉线索的特征交换多模态推理方法

    FSMR: A Feature Swapping Multi-modal Reasoning Approach with Joint Textual and Visual Clues

    [https://arxiv.org/abs/2403.20026](https://arxiv.org/abs/2403.20026)

    这项研究提出了一种新的特征交换多模态推理（FSMR）模型，通过特征交换增强多模态推理，包括利用预训练的视觉-语言模型和独特的特征交换模块，以及融合多模态交叉注意机制来促进文本和图像信息的联合建模。

    

    多模态推理在弥合文本和视觉信息之间的差距，实现对上下文的更深入理解方面起着至关重要的作用。本文提出了特征交换多模态推理（FSMR）模型，旨在通过特征交换增强多模态推理。FSMR利用预训练的视觉语言模型作为编码器，接纳文本和图像输入，有效地表征两种模态的特征。它引入了一个独特的特征交换模块，实现了图像中识别的对象和文本中对应词汇之间特征的交换，从而增强模型对图像和文本之间相互作用的理解。为了进一步加强其多模态对齐能力，FSMR融合了多模态交叉注意机制，促进了文本和视觉信息的联合建模。

    arXiv:2403.20026v1 Announce Type: cross  Abstract: Multi-modal reasoning plays a vital role in bridging the gap between textual and visual information, enabling a deeper understanding of the context. This paper presents the Feature Swapping Multi-modal Reasoning (FSMR) model, designed to enhance multi-modal reasoning through feature swapping. FSMR leverages a pre-trained visual-language model as an encoder, accommodating both text and image inputs for effective feature representation from both modalities. It introduces a unique feature swapping module, enabling the exchange of features between identified objects in images and corresponding vocabulary words in text, thereby enhancing the model's comprehension of the interplay between images and text. To further bolster its multi-modal alignment capabilities, FSMR incorporates a multi-modal cross-attention mechanism, facilitating the joint modeling of textual and visual information. During training, we employ image-text matching and cros
    
[^31]: 副词是关键：使用副词删除进行简单文本数据增强

    Adverb Is the Key: Simple Text Data Augmentation with Adverb Deletion

    [https://arxiv.org/abs/2403.20015](https://arxiv.org/abs/2403.20015)

    使用简单的副词删除策略，提出了一种新颖的文本数据增强方法，能有效增强文本数据，保留语义，适用于单一文本分类和自然语言推理。

    

    在文本数据增强领域，基于规则的方法被广泛采用于现实世界的应用，因为它们具有成本效益。然而，传统的基于规则的方法存在可能丢失给定文本的原始语义的问题。我们提出了一种新颖的文本数据增强策略，通过简单地删除在句子中起辅助作用的副词来避免这种现象。我们的全面实验证明了我们提出的方法的效率和有效性，不仅适用于单一文本分类，还适用于需要语义保留的自然语言推理。我们公开发布了用于可重现性的源代码。

    arXiv:2403.20015v1 Announce Type: cross  Abstract: In the field of text data augmentation, rule-based methods are widely adopted for real-world applications owing to their cost-efficiency. However, conventional rule-based approaches suffer from the possibility of losing the original semantics of the given text. We propose a novel text data augmentation strategy that avoids such phenomena through a straightforward deletion of adverbs, which play a subsidiary role in the sentence. Our comprehensive experiments demonstrate the efficiency and effectiveness of our proposed approach for not just single text classification, but also natural language inference that requires semantic preservation. We publicly released our source code for reproducibility.
    
[^32]: PURPLE: 让大型语言模型成为更好的SQL编写器

    PURPLE: Making a Large Language Model a Better SQL Writer

    [https://arxiv.org/abs/2403.20014](https://arxiv.org/abs/2403.20014)

    提出了PURPLE模型，通过检索演示来提高大型语言模型在SQL生成中的准确性

    

    大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）翻译中起着越来越重要的作用。通过大规模语料库训练的LLMs具有强大的自然语言理解和基本SQL生成能力，无需针对NL2SQL任务进行额外调整。现有基于LLMs的NL2SQL方法试图通过强调用户意图理解来提高翻译效果。然而，由于缺乏在组织复杂的逻辑运算符组合方面的知识，LLMs有时会生成不合适的SQL。一种有希望的方法是向LLMs输入演示，其中包括来自各种数据库的已知NL2SQL翻译。LLMs可以从输入演示中学习如何为给定任务组织运算符组合。在本文中，我们提出了PURPLE（Pre-trained models Utilized to Retrieve Prompts for Logical Enhancement），通过检索演示来提高准确性。

    arXiv:2403.20014v1 Announce Type: cross  Abstract: Large Language Model (LLM) techniques play an increasingly important role in Natural Language to SQL (NL2SQL) translation. LLMs trained by extensive corpora have strong natural language understanding and basic SQL generation abilities without additional tuning specific to NL2SQL tasks. Existing LLMs-based NL2SQL approaches try to improve the translation by enhancing the LLMs with an emphasis on user intention understanding. However, LLMs sometimes fail to generate appropriate SQL due to their lack of knowledge in organizing complex logical operator composition. A promising method is to input the LLMs with demonstrations, which include known NL2SQL translations from various databases. LLMs can learn to organize operator compositions from the input demonstrations for the given task. In this paper, we propose PURPLE (Pre-trained models Utilized to Retrieve Prompts for Logical Enhancement), which improves accuracy by retrieving demonstrati
    
[^33]: 关于大型语言模型对已知事实的幻觉现象

    On Large Language Models' Hallucination with Regard to Known Facts

    [https://arxiv.org/abs/2403.20009](https://arxiv.org/abs/2403.20009)

    通过推理动态的角度研究大型语言模型对已知事实的幻觉现象，通过对事实性问题和输出 token 概率动态的分析，揭示了幻觉发生的模式。

    

    大型语言模型在回答事实类问题方面取得成功，但也容易出现幻觉。我们通过推理动态的角度研究LLMs具有正确答案知识却仍然产生幻觉的现象，这是以往关于幻觉研究尚未涵盖的领域。我们通过两个关键思路进行分析。首先，我们确定了查询相同三元知识但导致不同答案的事实性问题。模型在正确和不正确输出上的行为差异因此暗示了幻觉发生的模式。其次，为了衡量这种模式，我们利用了剩余流到词汇空间的映射。我们揭示了输出令牌概率在正确和幻觉情况下在层深度上的不同动态。在幻觉案例中，输出令牌的信息很少表现出突增和持续的情况。

    arXiv:2403.20009v1 Announce Type: new  Abstract: Large language models are successful in answering factoid questions but are also prone to hallucination.We investigate the phenomenon of LLMs possessing correct answer knowledge yet still hallucinating from the perspective of inference dynamics, an area not previously covered in studies on hallucinations.We are able to conduct this analysis via two key ideas.First, we identify the factual questions that query the same triplet knowledge but result in different answers. The difference between the model behaviors on the correct and incorrect outputs hence suggests the patterns when hallucinations happen. Second, to measure the pattern, we utilize mappings from the residual streams to vocabulary space. We reveal the different dynamics of the output token probabilities along the depths of layers between the correct and hallucinated cases. In hallucinated cases, the output token's information rarely demonstrates abrupt increases and consistent
    
[^34]: 基于大型语言模型的情境对话在第二语言学习中的应用

    Large Language Model based Situational Dialogues for Second Language Learning

    [https://arxiv.org/abs/2403.20005](https://arxiv.org/abs/2403.20005)

    提出了基于大型语言模型的情境对话模型，旨在帮助语言学习者进行有效的会话练习，具有泛化能力，可以支持多样的会话话题，为解决学生缺乏合格教师或母语者练习会话技能的问题提供了一种可行的解决方案

    

    在第二语言学习中，基于情境的对话练习对于语言学习者实现口语流利至关重要，但学生常常缺乏与合格教师或母语者练习会话技能的机会。为了弥补这一差距，我们提出了情境对话模型，供学生参与会话练习。我们的情境对话模型是在大型语言模型（LLM）上进行微调的，旨在结合开放式对话的吸引力和基于情境任务的专注练习。利用LLMs的泛化能力，我们证明我们的情境对话模型不仅在训练话题上表现出色，而且在训练中未遇到的话题上也表现出色。这为支持广泛的会话话题提供了一个有希望的解决方案，而不需要大量手动工作。此外，在对话领域的研究...

    arXiv:2403.20005v1 Announce Type: new  Abstract: In second language learning, scenario-based conversation practice is important for language learners to achieve fluency in speaking, but students often lack sufficient opportunities to practice their conversational skills with qualified instructors or native speakers. To bridge this gap, we propose situational dialogue models for students to engage in conversational practice. Our situational dialogue models are fine-tuned on large language models (LLMs), with the aim of combining the engaging nature of an open-ended conversation with the focused practice of scenario-based tasks. Leveraging the generalization capabilities of LLMs, we demonstrate that our situational dialogue models perform effectively not only on training topics but also on topics not encountered during training. This offers a promising solution to support a wide range of conversational topics without extensive manual work. Additionally, research in the field of dialogue 
    
[^35]: 通过交互学习语言和机器人动作实现组合性和泛化能力的发展

    Development of Compositionality and Generalization through Interactive Learning of Language and Action of Robots

    [https://arxiv.org/abs/2403.19995](https://arxiv.org/abs/2403.19995)

    提出了一个融合视觉、本体感知和语言的大脑启发式神经网络模型，通过预测编码和主动推断的框架，基于自由能原理，实现了语言组合性和感觉运动技能的联合发展。

    

    人类擅长将学到的行为应用于未学习过的情境。这种泛化行为的一个关键组成部分是我们能够将整体分解成可重复利用的部分的能力，即组合性。机器人领域的一个基本问题是涉及这种特征。“在个体只学习部分语言组合及其相应的感觉运动模式时，如何通过联想学习同时发展语言的组合性和感觉运动技能？”为了解决这个问题，我们提出了一个融合视觉、本体感知和语言的大脑启发式神经网络模型，将其纳入基于自由能原理的预测编码和主动推断框架中。通过与机器人手臂进行的各种模拟实验评估了这个模型的有效性和能力。我们的结果表明，在学习中对于遗忘。

    arXiv:2403.19995v1 Announce Type: new  Abstract: Humans excel at applying learned behavior to unlearned situations. A crucial component of this generalization behavior is our ability to compose/decompose a whole into reusable parts, an attribute known as compositionality. One of the fundamental questions in robotics concerns this characteristic. "How can linguistic compositionality be developed concomitantly with sensorimotor skills through associative learning, particularly when individuals only learn partial linguistic compositions and their corresponding sensorimotor patterns?" To address this question, we propose a brain-inspired neural network model that integrates vision, proprioception, and language into a framework of predictive coding and active inference, based on the free-energy principle. The effectiveness and capabilities of this model were assessed through various simulation experiments conducted with a robot arm. Our results show that generalization in learning to unlear
    
[^36]: 通过调整和多支路推理增强低参数LLMs的通用代理功能

    Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning

    [https://arxiv.org/abs/2403.19962](https://arxiv.org/abs/2403.19962)

    通过构建特定于代理的数据并细调模型以及设计能够有效激活LLMs推理能力的提示，提出了一种综合方法来增强低参数LLMs的通用代理功能。

    

    arXiv:2403.19962v1 声明类型: 跨领域 摘要: 开源预训练的大型语言模型（LLM）表现出强大的语言理解和生成能力，使它们在各种任务中非常成功。然而，当将它们用作处理现实世界复杂问题的代理时，它们的性能远远不及ChatGPT和GPT-4等大型商用模型。作为智能代理，LLMs需要具备任务规划、长期记忆以及利用外部工具实现令人满意的性能的能力。各种方法已被提出来增强LLMs的代理能力。一方面，有些方法涉及构建特定于代理的数据和微调模型。另一方面，一些方法集中于设计能有效激活LLMs推理能力的提示。我们在7B和13B模型上同时探讨了这两种策略。我们提出了一种使用GPT-4构建特定于代理数据的全面方法。

    arXiv:2403.19962v1 Announce Type: cross  Abstract: Open-source pre-trained Large Language Models (LLMs) exhibit strong language understanding and generation capabilities, making them highly successful in a variety of tasks. However, when used as agents for dealing with complex problems in the real world, their performance is far inferior to large commercial models such as ChatGPT and GPT-4. As intelligent agents, LLMs need to have the capabilities of task planning, long-term memory, and the ability to leverage external tools to achieve satisfactory performance. Various methods have been proposed to enhance the agent capabilities of LLMs. On the one hand, methods involve constructing agent-specific data and fine-tuning the models. On the other hand, some methods focus on designing prompts that effectively activate the reasoning abilities of the LLMs. We explore both strategies on the 7B and 13B models. We propose a comprehensive method for constructing agent-specific data using GPT-4. T
    
[^37]: SLFNet: 使用语义概率图从自然语言生成语义逻辑形式

    SLFNet: Generating Semantic Logic Forms from Natural Language Using Semantic Probability Graphs

    [https://arxiv.org/abs/2403.19936](https://arxiv.org/abs/2403.19936)

    SLFNet提出了一种新颖的神经网络架构，利用依赖句法信息和语义概率图来从自然语言生成语义逻辑形式，以解决序列到序列模型中的“顺序重要性”问题。

    

    构建自然语言接口通常使用语义解析器来解析用户的自然语言并将其转换为结构化的语义逻辑形式(SLFs)。 主流方法是采用序列到序列框架，这要求自然语言命令和SLFs必须按顺序表示。 由于单个自然语言可能具有多个SLF或多个自然语言命令可能具有相同的SLF，因此训练序列到序列模型对它们之间的选择敏感，这一现象被记录为“顺序重要性”。 为了解决这个问题，我们提出了一种新颖的神经网络SLFNet，首先将依赖句法信息作为先验知识并能够捕获上下文信息和单词之间的长距离交互作用。 其次构建语义概率图以获得预测变量之间的局部依赖性。

    arXiv:2403.19936v1 Announce Type: new  Abstract: Building natural language interfaces typically uses a semantic parser to parse the user's natural language and convert it into structured \textbf{S}emantic \textbf{L}ogic \textbf{F}orms (SLFs). The mainstream approach is to adopt a sequence-to-sequence framework, which requires that natural language commands and SLFs must be represented serially. Since a single natural language may have multiple SLFs or multiple natural language commands may have the same SLF, training a sequence-to-sequence model is sensitive to the choice among them, a phenomenon recorded as "order matters". To solve this problem, we propose a novel neural network, SLFNet, which firstly incorporates dependent syntactic information as prior knowledge and can capture the long-range interactions between contextual information and words. Secondly construct semantic probability graphs to obtain local dependencies between predictor variables. Finally we propose the Multi-Hea
    
[^38]: 大语言模型(LLMs)是否是微调的有效骨干？对中文短文本匹配的监督LLMs的实验调查

    Are LLMs Effective Backbones for Fine-tuning? An Experimental Investigation of Supervised LLMs on Chinese Short Text Matching

    [https://arxiv.org/abs/2403.19930](https://arxiv.org/abs/2403.19930)

    研究评估了在监督设置中为中文短文本匹配任务微调LLMs的实验分析，探讨了任务建模方法、提示格式和输出格式等因素对性能的影响。

    

    大语言模型（LLMs）的最近成功在学术界和工业界引起了相当大的关注。先前对LLMs的研究主要集中在增强或利用它们在零-shot和少-shot设置中的泛化能力。然而，在受监督的设置中，对LLMs进行有效微调以用于特定的自然语言理解任务的调查有限。在本研究中，我们通过对中文短文本匹配任务对LLMs进行微调进行了实验分析。我们探讨了影响在微调LLMs时性能的各种因素，包括任务建模方法，提示格式和输出格式。

    arXiv:2403.19930v1 Announce Type: new  Abstract: The recent success of Large Language Models (LLMs) has garnered significant attention in both academia and industry. Prior research on LLMs has primarily focused on enhancing or leveraging their generalization capabilities in zero- and few-shot settings. However, there has been limited investigation into effectively fine-tuning LLMs for a specific natural language understanding task in supervised settings. In this study, we conduct an experimental analysis by fine-tuning LLMs for the task of Chinese short text matching. We explore various factors that influence performance when fine-tuning LLMs, including task modeling methods, prompt formats, and output formats.
    
[^39]: DiJiang：通过紧凑的核方法实现高效的大型语言模型

    DiJiang: Efficient Large Language Models through Compact Kernelization

    [https://arxiv.org/abs/2403.19928](https://arxiv.org/abs/2403.19928)

    DiJiang提出了一种新颖的频域核方法，可以将预训练的基本Transformer模型转化为具有线性复杂度的模型，大大减少训练成本，并在理论上提供更好的逼近效率。

    

    为了减少Transformers的计算负荷，线性注意力的研究已经取得了显著的进展。然而，注意机制的改进策略通常需要经过大量的重新训练，在具有大量参数的大型语言模型上是不切实际的。本文介绍了DiJiang，一种新颖的频域核方法，可将预训练的基本Transformer转化为具有较小训练成本的线性复杂度模型。通过采用加权拟随机采样法，所提出的方法在理论上提供了更好的逼近效率。为了进一步降低训练的计算复杂度，我们的核方法基于离散余弦变换（DCT）操作。大量实验证明，所提出的方法达到了与原始Transformer相当的性能，但训练时间大大减少。

    arXiv:2403.19928v1 Announce Type: new  Abstract: In an effort to reduce the computational load of Transformers, research on linear attention has gained significant momentum. However, the improvement strategies for attention mechanisms typically necessitate extensive retraining, which is impractical for large language models with a vast array of parameters. In this paper, we present DiJiang, a novel Frequency Domain Kernelization approach that enables the transformation of a pre-trained vanilla Transformer into a linear complexity model with little training costs. By employing a weighted Quasi-Monte Carlo method for sampling, the proposed approach theoretically offers superior approximation efficiency. To further reduce the training computational complexity, our kernelization is based on Discrete Cosine Transform (DCT) operations. Extensive experiments demonstrate that the proposed method achieves comparable performance to the original Transformer, but with significantly reduced trainin
    
[^40]: MANGO：用于评估大型语言模型映射和导航能力的基准

    MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models

    [https://arxiv.org/abs/2403.19913](https://arxiv.org/abs/2403.19913)

    提出了用于评估大型语言模型执行文本映射和导航能力的MANGO基准，发现即使是迄今为止最好的语言模型GPT-4在回答涉及映射和导航的问题时表现不佳。

    

    如ChatGPT和GPT-4等大型语言模型最近在各种自然语言处理任务上取得了惊人的性能。本文提出了MANGO，这是一个用于评估它们执行基于文本映射和导航能力的基准。我们的基准包括来自一套文本游戏的53个迷宫：每个迷宫都与一个游览说明配对，其中包含每个位置的访问但不涵盖所有可能的路径。任务是问答：对于每个迷宫，大型语言模型读取游览说明并回答数百个映射和导航问题，例如“你应该从房子西部如何去阁楼？”和“如果我们从地下室向北和东走，我们会在哪里？”。尽管这些问题对人类来说很容易，但事实证明，迄今为止最好的语言模型GPT-4甚至在回答这些问题时表现不佳。此外，我们的实验表明，强大的映射和导航能力将有利于大型语言模型。

    arXiv:2403.19913v1 Announce Type: cross  Abstract: Large language models such as ChatGPT and GPT-4 have recently achieved astonishing performance on a variety of natural language processing tasks. In this paper, we propose MANGO, a benchmark to evaluate their capabilities to perform text-based mapping and navigation. Our benchmark includes 53 mazes taken from a suite of textgames: each maze is paired with a walkthrough that visits every location but does not cover all possible paths. The task is question-answering: for each maze, a large language model reads the walkthrough and answers hundreds of mapping and navigation questions such as "How should you go to Attic from West of House?" and "Where are we if we go north and east from Cellar?". Although these questions are easy to humans, it turns out that even GPT-4, the best-to-date language model, performs poorly at answering them. Further, our experiments suggest that a strong mapping and navigation ability would benefit large languag
    
[^41]: 朝向一个强大的基于检索的摘要系统

    Towards a Robust Retrieval-Based Summarization System

    [https://arxiv.org/abs/2403.19889](https://arxiv.org/abs/2403.19889)

    该论文对大型语言模型在检索增强生成-基础摘要任务中的健壮性进行了调查，并提出了一个创新的评估框架和一个全面的系统来增强模型在特定场景下的健壮性。

    

    本文描述了对大型语言模型（LLMs）在检索增强生成（RAG）-基础摘要任务中的健壮性进行的调查。虽然LLMs提供了摘要能力，但它们在复杂的实际场景中的表现仍未得到充分探讨。我们的第一个贡献是LogicSumm，这是一个创新的评估框架，结合了现实场景，用来评估LLMs在RAG基础摘要过程中的健壮性。根据LogicSumm识别出的局限性，我们开发了SummRAG，这是一个全面的系统，用于创建训练对话并微调模型，以增强在LogicSumm场景中的健壮性。SummRAG是我们定义结构化方法来测试LLM能力的目标的一个示例，而不是一劳永逸地解决问题。实验结果证实了SummRAG的强大，展示了逻辑连贯性和摘要质量的提升。

    arXiv:2403.19889v1 Announce Type: cross  Abstract: This paper describes an investigation of the robustness of large language models (LLMs) for retrieval augmented generation (RAG)-based summarization tasks. While LLMs provide summarization capabilities, their performance in complex, real-world scenarios remains under-explored. Our first contribution is LogicSumm, an innovative evaluation framework incorporating realistic scenarios to assess LLM robustness during RAG-based summarization. Based on limitations identified by LogiSumm, we then developed SummRAG, a comprehensive system to create training dialogues and fine-tune a model to enhance robustness within LogicSumm's scenarios. SummRAG is an example of our goal of defining structured methods to test the capabilities of an LLM, rather than addressing issues in a one-off fashion. Experimental results confirm the power of SummRAG, showcasing improved logical coherence and summarization quality. Data, corresponding model weights, and Py
    
[^42]: Jamba: 一个混合Transformer-Mamba语言模型

    Jamba: A Hybrid Transformer-Mamba Language Model

    [https://arxiv.org/abs/2403.19887](https://arxiv.org/abs/2403.19887)

    Jamba是一个基于混合Transformer-Mamba架构的语言模型，在单个80GB GPU上实现了强大的性能，对标准语言模型基准和长上下文评估具有state-of-the-art的表现。

    

    我们提出了Jamba，这是一个基于新颖的混合Transformer-Mamba混合专家(MoE)架构的新基础大型语言模型。具体来说，Jamba交错使用Transformer和Mamba层，从两种模型家族中获益。MoE被添加在其中一些层中，以增加模型容量，同时保持活跃参数的可控性。这种灵活的架构允许特定资源和目标的配置。

    arXiv:2403.19887v1 Announce Type: new  Abstract: We present Jamba, a new base large language model based on a novel hybrid Transformer-Mamba mixture-of-experts (MoE) architecture. Specifically, Jamba interleaves blocks of Transformer and Mamba layers, enjoying the benefits of both model families. MoE is added in some of these layers to increase model capacity while keeping active parameter usage manageable. This flexible architecture allows resource- and objective-specific configurations. In the particular configuration we have implemented, we end up with a powerful model that fits in a single 80GB GPU. Built at large scale, Jamba provides high throughput and small memory footprint compared to vanilla Transformers, and at the same time state-of-the-art performance on standard language model benchmarks and long-context evaluations. Remarkably, the model presents strong results for up to 256K tokens context length. We study various architectural decisions, such as how to combine Transfor
    
[^43]: 将语言模型中的段落记忆本地化

    Localizing Paragraph Memorization in Language Models

    [https://arxiv.org/abs/2403.19851](https://arxiv.org/abs/2403.19851)

    论文展示了语言模型中段落记忆的梯度具有可区分的空间模式，通过微调高梯度权重可以取消学习，定位了特别参与段落记忆的低层注意头，并研究了记忆在前缀中的本地化程度。

    

    我们能否将语言模型用于记忆和背诵整个训练数据段的权重和机制本地化？本文表明，虽然记忆分布在多个层次和模型组件中，但记忆段落的梯度具有可区分的空间模式，较低模型层次中的梯度比非记忆示例的梯度更大。此外，这些记忆示例可以通过仅微调高梯度权重来取消学习。我们定位了一个似乎特别参与段落记忆的低层注意头。这个头部主要将注意力集中在在语料库级别的单语分布中最不频繁的独特、罕见的令牌上。接下来，我们通过扰动令牌并测量对解码造成的改变来研究记忆在前缀中的本地化程度。前缀中的一些独特令牌经常会使整个内容受损。

    arXiv:2403.19851v1 Announce Type: new  Abstract: Can we localize the weights and mechanisms used by a language model to memorize and recite entire paragraphs of its training data? In this paper, we show that while memorization is spread across multiple layers and model components, gradients of memorized paragraphs have a distinguishable spatial pattern, being larger in lower model layers than gradients of non-memorized examples. Moreover, the memorized examples can be unlearned by fine-tuning only the high-gradient weights. We localize a low-layer attention head that appears to be especially involved in paragraph memorization. This head is predominantly focusing its attention on distinctive, rare tokens that are least frequent in a corpus-level unigram distribution. Next, we study how localized memorization is across the tokens in the prefix by perturbing tokens and measuring the caused change in the decoding. A few distinctive tokens early in a prefix can often corrupt the entire cont
    
[^44]: 新的农学家：语言模型是作物管理专家

    The New Agronomists: Language Models are Experts in Crop Management

    [https://arxiv.org/abs/2403.19839](https://arxiv.org/abs/2403.19839)

    本文介绍了一个更先进的智能作物管理系统，利用深度强化学习和语言模型结合决策支持系统来优化作物管理实践。

    

    作物管理在决定作物产量、经济盈利和环境可持续性方面起着至关重要的作用。本文在以往研究基础上引入了一个更先进的智能作物管理系统，该系统独特地将强化学习、语言模型（LM）和由决策支持系统为农业技术转移（DSSAT）实现的作物模拟相结合。我们利用深度强化学习，特别是深度Q网络，来训练处理模拟器中众多状态变量作为观测的管理策略。

    arXiv:2403.19839v1 Announce Type: cross  Abstract: Crop management plays a crucial role in determining crop yield, economic profitability, and environmental sustainability. Despite the availability of management guidelines, optimizing these practices remains a complex and multifaceted challenge. In response, previous studies have explored using reinforcement learning with crop simulators, typically employing simple neural-network-based reinforcement learning (RL) agents. Building on this foundation, this paper introduces a more advanced intelligent crop management system. This system uniquely combines RL, a language model (LM), and crop simulations facilitated by the Decision Support System for Agrotechnology Transfer (DSSAT). We utilize deep RL, specifically a deep Q-network, to train management policies that process numerous state variables from the simulator as observations. A novel aspect of our approach is the conversion of these state variables into more informative language, fac
    
[^45]: 通过视觉语言模型对神经网络进行基于概念的分析

    Concept-based Analysis of Neural Networks via Vision-Language Models

    [https://arxiv.org/abs/2403.19837](https://arxiv.org/abs/2403.19837)

    本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。

    

    视觉深度神经网络（DNNs）的形式化分析非常可取，但由于难以表达视觉任务的形式化规范以及缺乏高效的验证程序，这是非常具有挑战性的。在本文中，我们提出利用新兴的多模态、视觉语言、基础模型（VLMs）作为一种通过其可以推理视觉模型的透镜。VLMs已经在大量图像及其文本描述上进行了训练，因此隐式地了解描述这些图像的高层次、人类可理解的概念。我们描述了一种名为$\texttt{Con}_{\texttt{spec}}$的逻辑规范语言，旨在便于按照这些概念编写规范。为了定义和形式化检查$\texttt{Con}_{\texttt{spec}}$规范，我们利用了一个VLM，它提供了一种编码和高效检查视觉模型的自然语言属性的方法。我们展示了我们的te

    arXiv:2403.19837v1 Announce Type: cross  Abstract: Formal analysis of vision-based deep neural networks (DNNs) is highly desirable but it is very challenging due to the difficulty of expressing formal specifications for vision tasks and the lack of efficient verification procedures. In this paper, we propose to leverage emerging multimodal, vision-language, foundation models (VLMs) as a lens through which we can reason about vision models. VLMs have been trained on a large body of images accompanied by their textual description, and are thus implicitly aware of high-level, human-understandable concepts describing the images. We describe a logical specification language $\texttt{Con}_{\texttt{spec}}$ designed to facilitate writing specifications in terms of these concepts. To define and formally check $\texttt{Con}_{\texttt{spec}}$ specifications, we leverage a VLM, which provides a means to encode and efficiently check natural-language properties of vision models. We demonstrate our te
    
[^46]: 隐式有害内容的目标跨度检测

    Target Span Detection for Implicit Harmful Content

    [https://arxiv.org/abs/2403.19836](https://arxiv.org/abs/2403.19836)

    研究侧重于辨识仇恨言论的暗示目标，定义了一个新任务，通过收集和标注目标跨度在多个数据集上实现，目的是识别更加微妙的仇恨言论并增强对数字平台上有害内容的检测。

    

    辨识仇恨言论的目标是理解此类言论性质的关键一步，最终有助于改进在线论坛上冒犯性帖子的检测。在线平台上许多有害内容使用隐含语言，尤其是针对脆弱和受保护群体，例如使用刻板的特征而非明示的目标名称，这使得检测和减轻其语言更加困难。本研究侧重于辨识仇恨言论的暗示目标，这对识别更加微妙的仇恨言论及增强数字平台上有害内容的检测至关重要。我们定义了一个旨在识别即使未明示的目标的新任务。为了解决这一任务，我们在三个著名的隐式仇恨言论数据集（SBIC、DynaHate和IHC）中收集并标注目标跨度。我们将得到的合并集合命名为隐含-目标-跨度。这一集合是通过一个创新的方法实现的。

    arXiv:2403.19836v1 Announce Type: new  Abstract: Identifying the targets of hate speech is a crucial step in grasping the nature of such speech and, ultimately, in improving the detection of offensive posts on online forums. Much harmful content on online platforms uses implicit language especially when targeting vulnerable and protected groups such as using stereotypical characteristics instead of explicit target names, making it harder to detect and mitigate the language. In this study, we focus on identifying implied targets of hate speech, essential for recognizing subtler hate speech and enhancing the detection of harmful content on digital platforms. We define a new task aimed at identifying the targets even when they are not explicitly stated. To address that task, we collect and annotate target spans in three prominent implicit hate speech datasets: SBIC, DynaHate, and IHC. We call the resulting merged collection Implicit-Target-Span. The collection is achieved using an innovat
    
[^47]: 语言模型从不常见的现象中学习：缺失AANN的情况

    Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs

    [https://arxiv.org/abs/2403.19827](https://arxiv.org/abs/2403.19827)

    语言模型通过从相关结构（例如“a few days”）进行泛化学习，能够更好地学习AANN结构。

    

    语言模型学习罕见的句法现象，但有人认为它们依赖于死记硬背，而不是语法概括。我们在规模为人类规模的语料库（1亿字）上进行训练，迭代训练变压器语言模型，然后评估它们对特定罕见语法现象的学习：英语的冠词+形容词+数字+名词（AANN）结构（“a beautiful five days”）。

    arXiv:2403.19827v1 Announce Type: new  Abstract: Language models learn rare syntactic phenomena, but it has been argued that they rely on rote memorization, as opposed to grammatical generalization. Training on a corpus of human-scale in size (100M words), we iteratively trained transformer language models on systematically manipulated corpora and then evaluated their learning of a particular rare grammatical phenomenon: the English Article+Adjective+Numeral+Noun (AANN) construction (``a beautiful five days''). We first compared how well this construction was learned on the default corpus relative to a counterfactual corpus in which the AANN sentences were removed. AANNs were still learned better than systematically perturbed variants of the construction. Using additional counterfactual corpora, we suggest that this learning occurs through generalization from related constructions (e.g., ``a few days''). An additional experiment showed that this learning is enhanced when there is more 
    
[^48]: 多阶段多模态预训练用于自动语音识别

    Multi-Stage Multi-Modal Pre-Training for Automatic Speech Recognition

    [https://arxiv.org/abs/2403.19822](https://arxiv.org/abs/2403.19822)

    提出了一种结合多模态和多任务无监督预训练以及基于翻译的监督中间训练方法的新方法，能够在Librispeech和SUPERB上相对提高高达38.45%的词错误率（WER）。

    

    机器学习的最新进展表明，与随机初始化模型相比，多模态预训练可以提高自动语音识别（ASR）性能，即使模型在单模态任务上进行微调。现有的用于ASR任务的多模态预训练方法主要集中在单阶段预训练，即使用单个无监督任务进行预训练，然后在下游任务上进行微调。在这项工作中，我们介绍了一种将多模态和多任务无监督预训练与基于翻译的监督中间训练方法相结合的新方法。我们在实验中证明，这种多阶段方法在Librispeech和SUPERB上相对词错误率（WER）的改进最高达38.45％。此外，我们分享了选择预训练方法和数据集的一些重要发现。

    arXiv:2403.19822v1 Announce Type: cross  Abstract: Recent advances in machine learning have demonstrated that multi-modal pre-training can improve automatic speech recognition (ASR) performance compared to randomly initialized models, even when models are fine-tuned on uni-modal tasks. Existing multi-modal pre-training methods for the ASR task have primarily focused on single-stage pre-training where a single unsupervised task is used for pre-training followed by fine-tuning on the downstream task. In this work, we introduce a novel method combining multi-modal and multi-task unsupervised pre-training with a translation-based supervised mid-training approach. We empirically demonstrate that such a multi-stage approach leads to relative word error rate (WER) improvements of up to 38.45% over baselines on both Librispeech and SUPERB. Additionally, we share several important findings for choosing pre-training methods and datasets.
    
[^49]: 开发医疗保健语言模型嵌入空间

    Developing Healthcare Language Model Embedding Spaces

    [https://arxiv.org/abs/2403.19802](https://arxiv.org/abs/2403.19802)

    通过深度对比学习训练的模型在医疗保健文本分类任务中表现出色，有效利用有限标记数据，并减少了模型参数更新。

    

    预训练大型语言模型 (LLMs) 在诸如专注于医疗保健文本之类的跨领域数据集上经常面临困难。我们探索专门的预训练方法，以调整较小的LLMs以适应不同的医疗保健数据集。评估了三种方法：传统的掩码语言建模、用于无监督文本表示的深度对比学习 (DeCLUTR) 和一种利用医疗保健环境中的元数据类别的新颖预训练目标。对每个数据集进行了下游文档分类任务的评估，并对生成的嵌入空间进行了额外分析。对比训练的模型在分类任务上表现优于其他方法，能够在有限标记数据的情况下提供强大性能，并且需要较少的模型参数更新。虽然基于元数据的预训练并未进一步提高数据集上的分类性能，但它确实产生了有趣的嵌入聚类可分性。所有领域的调整

    arXiv:2403.19802v1 Announce Type: cross  Abstract: Pre-trained Large Language Models (LLMs) often struggle on out-of-domain datasets like healthcare focused text. We explore specialized pre-training to adapt smaller LLMs to different healthcare datasets. Three methods are assessed: traditional masked language modeling, Deep Contrastive Learning for Unsupervised Textual Representations (DeCLUTR), and a novel pre-training objective utilizing metadata categories from the healthcare settings. These schemes are evaluated on downstream document classification tasks for each dataset, with additional analysis of the resultant embedding spaces. Contrastively trained models outperform other approaches on the classification tasks, delivering strong performance from limited labeled data and with fewer model parameter updates required. While metadata-based pre-training does not further improve classifications across the datasets, it yields interesting embedding cluster separability. All domain adap
    
[^50]: 2024年的自然语言、人工智能和量子计算：QNLP中的研究要点和方向

    Natural Language, AI, and Quantum Computing in 2024: Research Ingredients and Directions in QNLP

    [https://arxiv.org/abs/2403.19758](https://arxiv.org/abs/2403.19758)

    该论文调查了2024年自然语言处理、人工智能发展中的量子计算应用，在量子自然语言处理中使用了诸如词嵌入、序列模型、注意力和语法分析等NLP技术，提出了一种新的量子设计来处理文本编码，并探讨了量子理论对“不确定性是什么？”和“智能是什么？”等核心问题的关键贡献。

    

    arXiv:2403.19758v1 公告类型：跨领域 抽象：语言处理是当前人工智能发展的关键，同时量子计算也开始应用。这引起了量子自然语言处理的极大兴趣，出现了几个早期提案和实验。本文调查了这一领域的最新进展，展示了NLP相关技术，包括词嵌入、序列模型、注意力和语法分析是如何应用于量子语言处理中的。我们提出了一种新的量子设计用于文本编码的基本任务（在内存中表示一个字符串），这在以前没有详细讨论过。除了推动新技术，量子理论还对“不确定性是什么？”和“智能是什么？”等具有挑战性的问题做出了关键贡献。随着这些问题在人工系统中变得愈发紧迫，本文还考虑了一些事实概念化的方式。

    arXiv:2403.19758v1 Announce Type: cross  Abstract: Language processing is at the heart of current developments in artificial intelligence, and quantum computers are becoming available at the same time. This has led to great interest in quantum natural language processing, and several early proposals and experiments. This paper surveys the state of this area, showing how NLP-related techniques including word embeddings, sequential models, attention, and grammatical parsing have been used in quantum language processing. We introduce a new quantum design for the basic task of text encoding (representing a string of characters in memory), which has not been addressed in detail before.   As well as motivating new technologies, quantum theory has made key contributions to the challenging questions of 'What is uncertainty?' and 'What is intelligence?' As these questions are taking on fresh urgency with artificial systems, the paper also considers some of the ways facts are conceptualized and 
    
[^51]: GOLD: 通过超出分布引导的语言数据生成实现通用知识蒸馏

    GOLD: Generalized Knowledge Distillation via Out-of-Distribution-Guided Language Data Generation

    [https://arxiv.org/abs/2403.19754](https://arxiv.org/abs/2403.19754)

    GOLD提出了一种任务无关的数据生成和知识蒸馏框架，通过使用超出分布引导的反馈机制，提高了生成数据的泛化能力，并引入了处理嘈杂生成数据的基于能量的OOD评估方法。

    

    arXiv:2403.19754v1 通告类型：新 抽象：从LLMs进行知识蒸馏对于有效部署语言模型至关重要。之前的研究提出使用LLMs生成数据来准备蒸馏模型。我们认为使用LLMs生成数据容易从原始内容分布的中心进行抽样。这种局限性阻碍了蒸馏模型学习真实的潜在数据分布并且遗忘分布的尾部（具有较低概率的样本）。因此，我们提出了GOLD，一个任务无关的数据生成和知识蒸馏框架，它采用迭代的超出分布引导反馈机制用于LLM。因此，生成的数据提高了蒸馏模型的泛化能力。同时，还引入了基于能量的OOD评估方法来处理嘈杂的生成数据。我们在NLP的10个不同分类和序列到序列任务上进行了大量实验证明GOLD respe

    arXiv:2403.19754v1 Announce Type: new  Abstract: Knowledge distillation from LLMs is essential for the efficient deployment of language models. Prior works have proposed data generation using LLMs for preparing distilled models. We argue that generating data with LLMs is prone to sampling mainly from the center of original content distribution. This limitation hinders the distilled model from learning the true underlying data distribution and to forget the tails of the distributions (samples with lower probability). To this end, we propose GOLD, a task-agnostic data generation and knowledge distillation framework, which employs an iterative out-of-distribution-guided feedback mechanism for the LLM. As a result, the generated data improves the generalizability of distilled models. An energy-based OOD evaluation approach is also introduced to deal with noisy generated data. Our extensive experiments on 10 different classification and sequence-to-sequence tasks in NLP show that GOLD respe
    
[^52]: EmoScan：罗马化僧伽罗语推文中抑郁症症状的自动筛查

    EmoScan: Automatic Screening of Depression Symptoms in Romanized Sinhala Tweets

    [https://arxiv.org/abs/2403.19728](https://arxiv.org/abs/2403.19728)

    通过分析罗马化僧伽罗语社交媒体数据，提出了一种基于神经网络的框架，利用语言模式、情绪和行为线索可高准确率自动筛查抑郁症症状，显著超越了当前方法，有助于确定需积极干预和支持的个体。

    

    本文探讨了利用罗马化僧伽罗语社交媒体数据识别存在抑郁风险的个体。提出了基于机器学习的框架，通过分析社交媒体帖子中的语言模式、情绪和行为线索，在一套全面的数据集中自动筛查抑郁症症状。研究比较了神经网络与传统机器学习技术的适用性。所提出的神经网络具有注意力层，能处理长序列数据，在检测抑郁症状方面达到了93.25%的显著准确率，超越了当前的最先进方法。这些发现强调了该方法在确定需要积极干预和支持的个体方面的功效。通过提出的模型，心理健康专业人士、决策者和社交媒体公司可以获得有价值的见解。

    arXiv:2403.19728v1 Announce Type: new  Abstract: This work explores the utilization of Romanized Sinhala social media data to identify individuals at risk of depression. A machine learning-based framework is presented for the automatic screening of depression symptoms by analyzing language patterns, sentiment, and behavioural cues within a comprehensive dataset of social media posts. The research has been carried out to compare the suitability of Neural Networks over the classical machine learning techniques. The proposed Neural Network with an attention layer which is capable of handling long sequence data, attains a remarkable accuracy of 93.25% in detecting depression symptoms, surpassing current state-of-the-art methods. These findings underscore the efficacy of this approach in pinpointing individuals in need of proactive interventions and support. Mental health professionals, policymakers, and social media companies can gain valuable insights through the proposed model. Leveragin
    
[^53]: 用于法语口语理解的新语义任务MEDIA基准测试

    New Semantic Task for the French Spoken Language Understanding MEDIA Benchmark

    [https://arxiv.org/abs/2403.19727](https://arxiv.org/abs/2403.19727)

    提出了一个用于法语口语理解的新语义任务，通过在MEDIA基准测试数据集上标注意图来扩展其用途和使用情况。

    

    意图分类和槽填充是口语理解（SLU）的基本任务。在大多数SLU系统中，这些任务由独立模块实现。近十五年来，提出了同时实现这两个任务并利用它们相互增强的模型。一个使用联合模型的多语言模块被设想用于为一个欧洲项目HumanE-AI-Net创建一个旅游对话系统。建议结合多个数据集，包括MEDIA数据集，来训练这个联合模型。MEDIA SLU数据集是由ELRA从2005年开始分发的法语数据集，主要被法国研究界使用，自2020年起用于学术研究免费使用。不幸的是，它只在槽上标注而不标注意图。已构建了一个带有意图标注的增强版本的MEDIA，以扩展其用途到更多任务和用例。本文介绍了用于获得此增强版本的半自动方法。

    arXiv:2403.19727v1 Announce Type: cross  Abstract: Intent classification and slot-filling are essential tasks of Spoken Language Understanding (SLU). In most SLUsystems, those tasks are realized by independent modules. For about fifteen years, models achieving both of themjointly and exploiting their mutual enhancement have been proposed. A multilingual module using a joint modelwas envisioned to create a touristic dialogue system for a European project, HumanE-AI-Net. A combination ofmultiple datasets, including the MEDIA dataset, was suggested for training this joint model. The MEDIA SLU datasetis a French dataset distributed since 2005 by ELRA, mainly used by the French research community and free foracademic research since 2020. Unfortunately, it is annotated only in slots but not intents. An enhanced version ofMEDIA annotated with intents has been built to extend its use to more tasks and use cases. This paper presents thesemi-automatic methodology used to obtain this enhanced ver
    
[^54]: 法语临床命名实体识别的基准评估

    A Benchmark Evaluation of Clinical Named Entity Recognition in French

    [https://arxiv.org/abs/2403.19726](https://arxiv.org/abs/2403.19726)

    该论文评估了生物医学法语掩码语言模型在临床命名实体识别任务上的性能，对几种模型进行了比较。

    

    背景：基于Transformer的语言模型在许多自然语言处理（NLP）任务中表现出了强大的性能。掩码语言模型（MLMs）吸引了持续的关注，因为它们可以通过在特定语料库上进行训练或微调来适应不同的语言和子域，同时保持比现代大语言模型（LLMs）更轻。最近，针对法语生物医学领域发布了几个MLMs，并且实验表明它们优于标准法语模型。然而，目前没有提供对同一语料库上所有模型进行比较的系统评估。目标：本文提出了一个评估生物医学法语掩码语言模型在临床命名实体识别任务上的性能。方法和材料：我们评估了生物医学模型CamemBERT-bio和DrBERT，并将它们与标准法语模型CamemBERT、FlauBERT和FrALBERT以及多语言mBERT进行比较。

    arXiv:2403.19726v1 Announce Type: cross  Abstract: Background: Transformer-based language models have shown strong performance on many Natural LanguageProcessing (NLP) tasks. Masked Language Models (MLMs) attract sustained interest because they can be adaptedto different languages and sub-domains through training or fine-tuning on specific corpora while remaining lighterthan modern Large Language Models (LLMs). Recently, several MLMs have been released for the biomedicaldomain in French, and experiments suggest that they outperform standard French counterparts. However, nosystematic evaluation comparing all models on the same corpora is available. Objective: This paper presentsan evaluation of masked language models for biomedical French on the task of clinical named entity recognition.Material and methods: We evaluate biomedical models CamemBERT-bio and DrBERT and compare them tostandard French models CamemBERT, FlauBERT and FrALBERT as well as multilingual mBERT using three publicall
    
[^55]: MUGC：机器生成与用户生成内容的检测

    MUGC: Machine Generated versus User Generated Content Detection

    [https://arxiv.org/abs/2403.19725](https://arxiv.org/abs/2403.19725)

    本研究对八种传统机器学习算法在识别机器生成和人类生成数据方面进行了比较评估，发现这些方法在识别机器生成数据方面具有较高的准确性。另外，机器生成的文本往往更短、词汇变化更少，而人类生成内容则使用了一些特定领域相关关键词被当前的大型语言模型忽略了。

    

    随着先进的现代系统如深度神经网络（DNNs）和生成式人工智能不断增强其产生令人信服和逼真内容的能力，区分用户生成与机器生成内容的需求变得越来越明显。在这项研究中，我们对八种传统机器学习算法进行了比较评估，以区分跨三个不同数据集（诗歌、摘要和论文）中的机器生成和人类生成数据。我们的结果表明，传统方法在识别机器生成数据方面表现出很高的准确性，反映了像RoBERT这样的热门预训练模型的有效性。我们注意到，与人类生成内容相比，机器生成的文本往往更短，词汇变化更少。虽然人类常用的特定领域相关关键词被当前的大型语言模型（LLMs）忽略了。

    arXiv:2403.19725v1 Announce Type: cross  Abstract: As advanced modern systems like deep neural networks (DNNs) and generative AI continue to enhance their capabilities in producing convincing and realistic content, the need to distinguish between user-generated and machine generated content is becoming increasingly evident. In this research, we undertake a comparative evaluation of eight traditional machine-learning algorithms to distinguish between machine-generated and human-generated data across three diverse datasets: Poems, Abstracts, and Essays. Our results indicate that traditional methods demonstrate a high level of accuracy in identifying machine-generated data, reflecting the documented effectiveness of popular pre-trained models like RoBERT. We note that machine-generated texts tend to be shorter and exhibit less word variety compared to human-generated content. While specific domain-related keywords commonly utilized by humans, albeit disregarded by current LLMs (Large Lang
    
[^56]: HGT：利用异质图增强的大型语言模型进行少样本复杂表格理解

    HGT: Leveraging Heterogeneous Graph-enhanced Large Language Models for Few-shot Complex Table Understanding

    [https://arxiv.org/abs/2403.19723](https://arxiv.org/abs/2403.19723)

    HGT框架结合了异质图增强的大型语言模型，通过软提示和多粒度自监督HG预训练目标，实现了少样本复杂表格理解任务的最新成果。

    

    表格理解 (TU) 取得了显著进展，但面临手动标记表格的稀缺性和复杂表格结构的挑战。为解决这些问题，我们提出了 HGT 框架，其中包含一个异质图 (HG) 增强的大型语言模型 (LLM)，用于解决少样本 TU 任务。它通过软提示和指导转换将表格语义与LLM的参数化知识对齐，并通过涉及三种新的多粒度自监督HG预训练目标的多任务预训练方案处理复杂表格。我们在几个基准测试上通过实证方法展示了HGT的有效性，表明它在少样本复杂TU方面的表现优于SOTA。

    arXiv:2403.19723v1 Announce Type: cross  Abstract: Table understanding (TU) has achieved promising advancements, but it faces the challenges of the scarcity of manually labeled tables and the presence of complex table structures.To address these challenges, we propose HGT, a framework with a heterogeneous graph (HG)-enhanced large language model (LLM) to tackle few-shot TU tasks.It leverages the LLM by aligning the table semantics with the LLM's parametric knowledge through soft prompts and instruction turning and deals with complex tables by a multi-task pre-training scheme involving three novel multi-granularity self-supervised HG pre-training objectives.We empirically demonstrate the effectiveness of HGT, showing that it outperforms the SOTA for few-shot complex TU on several benchmarks.
    
[^57]: 文本到图像生成的能力感知提示重组学习

    Capability-aware Prompt Reformulation Learning for Text-to-Image Generation

    [https://arxiv.org/abs/2403.19716](https://arxiv.org/abs/2403.19716)

    通过利用来自交互日志的用户重组数据来开发自动提示重组模型，CAPR框架创新性地将用户能力整合到提示重组过程中。

    

    文本到图像生成系统已经成为艺术创作领域中的革命性工具，为将文本提示转化为视觉艺术提供了前所未有的便利。然而，这些系统的效力与用户提供的提示质量密切相关，这常常对不熟悉提示制作的用户构成挑战。本文通过利用来自交互日志的用户重组数据来开发自动提示重组模型来解决这一挑战。我们对这些日志的深入分析表明，用户提示的重组在很大程度上取决于个体用户的能力，导致重组对的质量存在显著差异。为有效地利用这些数据进行训练，我们引入了能力感知提示重组（CAPR）框架。CAPR创新性地通过两个关键组件将用户能力整合到重组过程中：有条件的提示重组

    arXiv:2403.19716v1 Announce Type: cross  Abstract: Text-to-image generation systems have emerged as revolutionary tools in the realm of artistic creation, offering unprecedented ease in transforming textual prompts into visual art. However, the efficacy of these systems is intricately linked to the quality of user-provided prompts, which often poses a challenge to users unfamiliar with prompt crafting. This paper addresses this challenge by leveraging user reformulation data from interaction logs to develop an automatic prompt reformulation model. Our in-depth analysis of these logs reveals that user prompt reformulation is heavily dependent on the individual user's capability, resulting in significant variance in the quality of reformulation pairs. To effectively use this data for training, we introduce the Capability-aware Prompt Reformulation (CAPR) framework. CAPR innovatively integrates user capability into the reformulation process through two key components: the Conditional Refo
    
[^58]: NJUST-KMG参加TRAC-2024任务1和任务2：离线危害潜在性识别

    NJUST-KMG at TRAC-2024 Tasks 1 and 2: Offline Harm Potential Identification

    [https://arxiv.org/abs/2403.19713](https://arxiv.org/abs/2403.19713)

    该研究提出了在TRAC-2024离线危害潜在性识别任务中的方法，利用专家标注的社交媒体评论数据集，成功设计了能够准确评估危害可能性并识别目标的算法，在两个赛道中取得第二名的成绩。

    

    这份报告详细描述了我们在TRAC-2024离线危害潜在性识别中提出的方法，该比赛包含两个子任务。研究利用了一个包含多种印度语言社交媒体评论的丰富数据集，由专家评分标注，以捕捉离线环境危害的微妙含义。参与者的任务是设计能够准确评估特定情况下危害可能性并识别离线危害最可能的目标的算法。我们的方法在两个不同的赛道中排名第二，F1值分别为0.73和0.96。我们的方法主要涉及选择预训练模型进行微调，整合对比学习技术，并通过集成方法应用于测试集。

    arXiv:2403.19713v1 Announce Type: new  Abstract: This report provide a detailed description of the method that we proposed in the TRAC-2024 Offline Harm Potential dentification which encloses two sub-tasks. The investigation utilized a rich dataset comprised of social media comments in several Indian languages, annotated with precision by expert judges to capture the nuanced implications for offline context harm. The objective assigned to the participants was to design algorithms capable of accurately assessing the likelihood of harm in given situations and identifying the most likely target(s) of offline harm. Our approach ranked second in two separate tracks, with F1 values of 0.73 and 0.96 respectively. Our method principally involved selecting pretrained models for finetuning, incorporating contrastive learning techniques, and culminating in an ensemble approach for the test set.
    
[^59]: STRUM-LLM: 属性化和结构化对比摘要

    STRUM-LLM: Attributed and Structured Contrastive Summarization

    [https://arxiv.org/abs/2403.19710](https://arxiv.org/abs/2403.19710)

    STRUM-LLM提出了一种生成属性化、结构化和有帮助的对比摘要的方法，识别并突出两个选项之间的关键差异，不需要人工标记的数据或固定属性列表，具有高吞吐量和小体积。

    

    用户经常在两个选项（A vs B）之间做决策时感到困难，因为这通常需要在多个网页上进行耗时的研究。我们提出了STRUM-LLM，通过生成带属性、结构化和有帮助的对比摘要，突出两个选项之间的关键差异，来解决这一挑战。STRUM-LLM识别了有帮助的对比：两个选项在哪些特定属性上有显著差异，以及最有可能影响用户决策。我们的技术是与领域无关的，并不需要任何人工标记的数据或固定属性列表作为监督。STRUM-LLM将所有提取的内容属性化，以及文本证据，且不限制其处理的输入来源的长度。STRUM-LLM Distilled的吞吐量比具有相似性能的模型高100倍，同时体积小10倍。在本文中，我们进行了广泛的评估。

    arXiv:2403.19710v1 Announce Type: cross  Abstract: Users often struggle with decision-making between two options (A vs B), as it usually requires time-consuming research across multiple web pages. We propose STRUM-LLM that addresses this challenge by generating attributed, structured, and helpful contrastive summaries that highlight key differences between the two options. STRUM-LLM identifies helpful contrast: the specific attributes along which the two options differ significantly and which are most likely to influence the user's decision. Our technique is domain-agnostic, and does not require any human-labeled data or fixed attribute list as supervision. STRUM-LLM attributes all extractions back to the input sources along with textual evidence, and it does not have a limit on the length of input sources that it can process. STRUM-LLM Distilled has 100x more throughput than the models with comparable performance while being 10x smaller. In this paper, we provide extensive evaluations
    
[^60]: 高效多任务调整大型语音模型的分层递归适配器

    Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of Large Speech Models

    [https://arxiv.org/abs/2403.19709](https://arxiv.org/abs/2403.19709)

    提出了一种分层递归适配器模块，能够在大规模多任务适配场景下降低每个任务的参数开销，同时保持在下游任务中的性能表现，优于先前的适配器方法和完整模型微调基线

    

    参数高效的适配方法已经成为训练大型预训练模型用于下游任务的关键机制。我们引入了一种适配器模块，在大规模多任务适配场景下具有更好的效率。我们的适配器在适配器参数分配方面是分层的。适配器由一个共享的控制网络和多个任务级适配器头组成，以减少每个任务的参数开销，而不会影响下游任务的性能。适配器还是递归的，因此整个适配器参数在预训练模型的不同层之间被重用。我们的分层递归适配器（HRA）在单任务和多任务适配设置中都优于先前的基于适配器的方法以及完整模型微调基线。

    arXiv:2403.19709v1 Announce Type: cross  Abstract: Parameter efficient adaptation methods have become a key mechanism to train large pre-trained models for downstream tasks. However, their per-task parameter overhead is considered still high when the number of downstream tasks to adapt for is large. We introduce an adapter module that has a better efficiency in large scale multi-task adaptation scenario. Our adapter is hierarchical in terms of how the adapter parameters are allocated. The adapter consists of a single shared controller network and multiple task-level adapter heads to reduce the per-task parameter overhead without performance regression on downstream tasks. The adapter is also recurrent so the entire adapter parameters are reused across different layers of the pre-trained model. Our Hierarchical Recurrent Adapter (HRA) outperforms the previous adapter-based approaches as well as full model fine-tuning baseline in both single and multi-task adaptation settings when evalua
    
[^61]: AttentionStore: 在大型语言模型服务中实现多轮对话中的注意力成本效益复用

    AttentionStore: Cost-effective Attention Reuse across Multi-turn Conversations in Large Language Model Serving

    [https://arxiv.org/abs/2403.19708](https://arxiv.org/abs/2403.19708)

    AttentionStore提出了一种新的注意力机制，通过实现KV缓存的复用，在大型语言模型服务中显著降低了多轮对话中的重复计算成本。

    

    通过多轮对话与人类进行交互是大型语言模型（LLMs）的基本特征。然而，由于需要重复计算历史记号的键值（KV）缓存，导致现有用于执行多轮对话的LLM服务引擎效率低下，产生高昂的服务成本。为解决这一问题，本文提出了AttentionStore，一种新的注意力机制，实现了跨多轮对话的KV缓存复用（即 注意力复用），显著降低了重复计算开销。AttentionStore维护了一个层次结构的KV缓存系统，利用成本效益的内存/存储介质为所有请求保存KV缓存。为了减少慢速介质的KV缓存访问开销，AttentionStore采用逐层预加载和异步保存方案，将KV缓存访问与GPU计算重叠。为确保要访问的KV缓存…

    arXiv:2403.19708v1 Announce Type: new  Abstract: Interacting with humans through multi-turn conversations is a fundamental feature of large language models (LLMs). However, existing LLM serving engines for executing multi-turn conversations are inefficient due to the need to repeatedly compute the key-value (KV) caches of historical tokens, incurring high serving costs. To address the problem, this paper proposes AttentionStore, a new attention mechanism that enables the reuse of KV caches (i.e., attention reuse) across multi-turn conversations, significantly reducing the repetitive computation overheads. AttentionStore maintains a hierarchical KV caching system that leverages cost-effective memory/storage mediums to save KV caches for all requests. To reduce KV cache access overheads from slow mediums, AttentionStore employs layer-wise pre-loading and asynchronous saving schemes to overlap the KV cache access with the GPU computation. To ensure that the KV caches to be accessed are pl
    
[^62]: 分析语言和视觉在从有限数据中学习中的作用

    Analyzing the Roles of Language and Vision in Learning from Limited Data

    [https://arxiv.org/abs/2403.19669](https://arxiv.org/abs/2403.19669)

    研究人工智能中的复杂视觉-语言模型，发现即使缺乏视觉输入，利用所有组件的语言模型能够恢复大部分VLM的性能，表明语言通过提供对先前知识和推理的访问来对学习新任务有贡献

    

    arXiv:2403.19669v1 公告类型：交叉摘要：语言是否有助于理解视觉世界？实际观察世界需要看到实际情况，而不是用文字描述吗？关于智能本质的这些基本问题很难回答，因为我们只有一个智能系统的例子——人类——以及有限的独立语言或视觉的案例。然而，人工智能研究人员开发出复杂的视觉-语言模型（VLMs）为我们提供了新的机会，探索语言和视觉对于学习世界的贡献。我们从这些模型的认知架构中切除组件，以确定它们对从有限数据中学习新任务的贡献。我们发现，利用所有组件的语言模型恢复了大部分VLM的性能，尽管它缺乏视觉输入，而语言似乎可以通过提供对先前知识和推理的访问来实现这一点。

    arXiv:2403.19669v1 Announce Type: cross  Abstract: Does language help make sense of the visual world? How important is it to actually see the world rather than having it described with words? These basic questions about the nature of intelligence have been difficult to answer because we only had one example of an intelligent system -- humans -- and limited access to cases that isolated language or vision. However, the development of sophisticated Vision-Language Models (VLMs) by artificial intelligence researchers offers us new opportunities to explore the contributions that language and vision make to learning about the world. We ablate components from the cognitive architecture of these models to identify their contributions to learning new tasks from limited data. We find that a language model leveraging all components recovers a majority of a VLM's performance, despite its lack of visual input, and that language seems to allow this by providing access to prior knowledge and reasoni
    
[^63]: 通过死因调查笔记中的注释不一致性检测揭示自杀原因的误归因

    Uncovering Misattributed Suicide Causes through Annotation Inconsistency Detection in Death Investigation Notes

    [https://arxiv.org/abs/2403.19432](https://arxiv.org/abs/2403.19432)

    通过自然语言处理方法检测并纠正国家暴力死亡报告系统中的注释不一致性，提高了自杀危机分类器的性能。

    

    数据准确性对科学研究和政策制定至关重要。国家暴力死亡报告系统（NVDRS）数据被广泛用于发现死亡的模式和原因。最近的研究表明NVDRS内存在注释不一致性，并可能影响错误的自杀原因归因。我们提出了一种经验性的自然语言处理（NLP）方法来检测注释不一致性，并采用类似交叉验证的范式来识别有问题的实例。我们分析了2003年至2020年间从NVDRS中的267,804起自杀死亡案例。结果显示，将目标州的数据纳入训练自杀危机分类器，使得在目标州测试集上的F-1分数增加了5.4％，在其他州测试集上降低了1.1％。总之，我们展示了NVDRS死因调查笔记中的注释不一致性，并确定了问题的实例。

    arXiv:2403.19432v1 Announce Type: cross  Abstract: Data accuracy is essential for scientific research and policy development. The National Violent Death Reporting System (NVDRS) data is widely used for discovering the patterns and causes of death. Recent studies suggested the annotation inconsistencies within the NVDRS and the potential impact on erroneous suicide-cause attributions. We present an empirical Natural Language Processing (NLP) approach to detect annotation inconsistencies and adopt a cross-validation-like paradigm to identify problematic instances. We analyzed 267,804 suicide death incidents between 2003 and 2020 from the NVDRS. Our results showed that incorporating the target state's data into training the suicide-crisis classifier brought an increase of 5.4% to the F-1 score on the target state's test set and a decrease of 1.1% on other states' test set. To conclude, we demonstrated the annotation inconsistencies in NVDRS's death investigation notes, identified problema
    
[^64]: STaR-GATE: 教授语言模型询问澄清问题

    STaR-GATE: Teaching Language Models to Ask Clarifying Questions

    [https://arxiv.org/abs/2403.19154](https://arxiv.org/abs/2403.19154)

    通过奖励语言模型生成有用问题来自我改进的方法，提问者通过询问角色扮演者来引出偏好，从而迭代微调以增加任务高质量响应的概率。

    

    当提示语言模型完成任务时，用户通常会遗漏重要的细节。虽然提问可以解决这种歧义，但模型往往很难提出好问题。我们探讨了语言模型通过奖励模型生成有用问题来自我改进的能力，这是一种简单方法，我们称之为STaR-GATE。我们生成了一个包含25,500个独特人物-任务提示的合成数据集，以模拟预训练语言模型--提问者--与一个其偏好未知的角色扮演者之间的对话。通过提问，提问者从角色扮演者那里引出偏好。提问者在那些增加高质量响应概率的问题上进行迭代微调，这些问题是由具有对角色扮演者访问权限的预言者生成的。

    arXiv:2403.19154v1 Announce Type: cross  Abstract: When prompting language models to complete a task, users often leave important aspects unsaid. While asking questions could resolve this ambiguity \citep[GATE;][]{li2023eliciting}, models often struggle to ask good questions. We explore a language model's ability to self-improve \citep[STaR;][]{zelikman2022star} by rewarding the model for generating useful questions -- a simple method we dub STaR-GATE. We generate a synthetic dataset of 25,500 unique persona-task prompts to simulate conversations between a pretrained language model -- the \texttt{Questioner} -- and a \texttt{Roleplayer} whose preferences are unknown to the \texttt{Questioner}. By asking questions, the \texttt{Questioner} elicits preferences from the \texttt{Roleplayer}. The \texttt{Questioner} is iteratively finetuned on questions that increase the probability of high-quality responses to the task, which are generated by an \texttt{Oracle} with access to the \texttt{Ro
    
[^65]: 语言模型是生物医学成像任务的免费助推器

    Language Models are Free Boosters for Biomedical Imaging Tasks

    [https://arxiv.org/abs/2403.17343](https://arxiv.org/abs/2403.17343)

    本研究揭示了基于残差的大型语言模型在生物医学成像任务中作为编码器的意想不到的有效性，利用冻结的变压器块进行直接处理视觉令牌，从而提高各种生物医学成像应用的性能。

    

    在这项研究中，我们揭示了基于残差的大型语言模型（LLMs）在生物医学成像任务中作为编码器的意想不到的有效性，这是传统上缺乏语言或文本数据的领域。该方法不同于已建立的方法，通过利用从预训练的LLMs中提取的冻结变压器块作为创新的编码器层，直接处理视觉令牌。这种策略与通常依赖于语言驱动提示和输入的标准多模态视觉语言框架有着显著的不同。我们发现这些LLMs能够提升各种生物医学成像应用的性能，包括2D和3D视觉分类任务，充当即插即用的助推器。更有趣的是，作为副产品，我们发现所提出的框架实现了卓越的性能，在M的广泛、标准化数据集中取得了新的最先进结果。

    arXiv:2403.17343v1 Announce Type: cross  Abstract: In this study, we uncover the unexpected efficacy of residual-based large language models (LLMs) as part of encoders for biomedical imaging tasks, a domain traditionally devoid of language or textual data. The approach diverges from established methodologies by utilizing a frozen transformer block, extracted from pre-trained LLMs, as an innovative encoder layer for the direct processing of visual tokens. This strategy represents a significant departure from the standard multi-modal vision-language frameworks, which typically hinge on language-driven prompts and inputs. We found that these LLMs could boost performance across a spectrum of biomedical imaging applications, including both 2D and 3D visual classification tasks, serving as plug-and-play boosters. More interestingly, as a byproduct, we found that the proposed framework achieved superior performance, setting new state-of-the-art results on extensive, standardized datasets in M
    
[^66]: WoLF: 用于胸部X线图理解的大型语言模型框架

    WoLF: Large Language Model Framework for CXR Understanding

    [https://arxiv.org/abs/2403.15456](https://arxiv.org/abs/2403.15456)

    WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。

    

    通过现代视觉语言模型(VLMs)取得了对胸部X线图(CXR)理解方面的显着方法进展，展示了令人印象深刻的视觉问答(VQA)和CXR报告生成能力。然而，现有的CXR理解框架仍存在几个程序上的缺陷。(1)以往的方法仅使用CXR报告，这对于全面的视觉问答(VQA)来说是不够的，特别是当需要额外的健康相关数据如用药历史和先前的诊断时。(2)以往的方法使用未经处理的CXR报告，这些报告往往结构随意。虽然现代语言模型可以理解各种文本格式，但为了提供更清晰、有组织的基于解剖学的信息，重构报告可能会增强它们的实用性。(3)目前用于CXR-VQA的评估方法主要强调语言正确性，缺乏对生成答案的微妙评估能力。

    arXiv:2403.15456v1 Announce Type: new  Abstract: Significant methodological strides have been made toward Chest X-ray (CXR) understanding via modern vision-language models (VLMs), demonstrating impressive Visual Question Answering (VQA) and CXR report generation abilities. However, existing CXR understanding frameworks still possess several procedural caveats. (1) Previous methods solely use CXR reports, which are insufficient for comprehensive Visual Question Answering (VQA), especially when additional health-related data like medication history and prior diagnoses are needed. (2) Previous methods use raw CXR reports, which are often arbitrarily structured. While modern language models can understand various text formats, restructuring reports for clearer, organized anatomy-based information could enhance their usefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize linguistic correctness, lacking the capability to offer nuanced assessments of the generated answers.
    
[^67]: 使用Transformer进行情感检测：一项比较研究

    Emotion Detection with Transformers: A Comparative Study

    [https://arxiv.org/abs/2403.15454](https://arxiv.org/abs/2403.15454)

    本研究探索了在文本数据情感分类中应用基于Transformer的模型，并发现常用技术如去除标点符号和停用词可能会阻碍模型的性能，因为这些元素仍然能够传达情感或强调，而Transformer的优势在于理解文本内的语境关系。

    

    在这项研究中，我们探讨了基于Transformer模型在文本数据情感分类中的应用。我们使用不同变体的Transformer对Emotion数据集进行训练和评估。论文还分析了一些影响模型性能的因素，比如Transformer层的微调、层的可训练性以及文本数据的预处理。我们的分析表明，常用技术如去除标点符号和停用词可能会阻碍模型的性能。这可能是因为Transformer的优势在于理解文本内的语境关系。像标点符号和停用词这样的元素仍然可以传达情感或强调，去除它们可能会破坏这种上下文。

    arXiv:2403.15454v1 Announce Type: new  Abstract: In this study, we explore the application of transformer-based models for emotion classification on text data. We train and evaluate several pre-trained transformer models, on the Emotion dataset using different variants of transformers. The paper also analyzes some factors that in-fluence the performance of the model, such as the fine-tuning of the transformer layer, the trainability of the layer, and the preprocessing of the text data. Our analysis reveals that commonly applied techniques like removing punctuation and stop words can hinder model performance. This might be because transformers strength lies in understanding contextual relationships within text. Elements like punctuation and stop words can still convey sentiment or emphasis and removing them might disrupt this context.
    
[^68]: PET-SQL：一个带有交叉一致性的增强提示的两阶段文本到SQL框架

    PET-SQL: A Prompt-enhanced Two-stage Text-to-SQL Framework with Cross-consistency

    [https://arxiv.org/abs/2403.09732](https://arxiv.org/abs/2403.09732)

    提出了一个两阶段框架，通过引入参考增强表示和少样本演示，解决了在处理冗长的数据库信息和复杂用户意图时的挑战。

    

    最近文本到SQL（Text2SQL）领域的进展强调刺激大型语言模型（LLM）进行上下文学习，取得了显著成果。然而，他们在处理冗长的数据库信息和复杂的用户意图时面临挑战。本文提出了一个两阶段框架，以增强当前基于LLM的自然语言到SQL系统的性能。我们首先引入了一种新颖的提示表示，称为参考增强表示，其中包括模式信息和从表格随机抽样的单元格值，以指导LLM生成SQL查询。然后，在第一阶段，我们检索问题-SQL对作为少量演示，促使LLM生成初步SQL（PreSQL）。之后，解析PreSQL中提到的实体进行模式链接，可以显著压缩有用信息。在第二阶段，利用链接的模式，我们简化了

    arXiv:2403.09732v1 Announce Type: cross  Abstract: Recent advancements in Text-to-SQL (Text2SQL) emphasize stimulating the large language models (LLM) on in-context learning, achieving significant results. Nevertheless, they face challenges when dealing with verbose database information and complex user intentions. This paper presents a two-stage framework to enhance the performance of current LLM-based natural language to SQL systems. We first introduce a novel prompt representation, called reference-enhanced representation, which includes schema information and randomly sampled cell values from tables to instruct LLMs in generating SQL queries. Then, in the first stage, question-SQL pairs are retrieved as few-shot demonstrations, prompting the LLM to generate a preliminary SQL (PreSQL). After that, the mentioned entities in PreSQL are parsed to conduct schema linking, which can significantly compact the useful information. In the second stage, with the linked schema, we simplify the 
    
[^69]: 在上下文学习中纠正演示快捷方式

    Rectifying Demonstration Shortcut in In-Context Learning

    [https://arxiv.org/abs/2403.09488](https://arxiv.org/abs/2403.09488)

    本研究旨在纠正大型语言模型在上下文学习中的演示快捷方式，并引入了一种新的明示意识校准方法。

    

    大型语言模型（LLMs）能够利用它们的上下文学习（ICL）能力，仅凭少量演示便能解决各种任务。然而，LLMs常常依赖于它们对演示的预先训练的语义先验，而不是根据输入-标签关系继续进行ICL预测。本文将这一现象称为“演示快捷方式”。尽管先前的研究主要集中于改进预定义任务的ICL预测结果，我们的目标是纠正演示快捷方式，从而使LLM能够有效地从演示中学习新的输入-标签关系。为实现此目标，我们引入了一种明示意识的校准方法：In-Context Calibration。我们在两个设置中评估了所提出方法的有效性：（1）使用标准标签空间的原始ICL任务以及（2）任务学习设置，其中标签空间被语义无关的标记替换。

    arXiv:2403.09488v1 Announce Type: cross  Abstract: Large language models (LLMs) are able to solve various tasks with only a few demonstrations utilizing their in-context learning (ICL) abilities. However, LLMs often rely on their pre-trained semantic priors of demonstrations rather than on the input-label relationships to proceed with ICL prediction. In this work, we term this phenomenon as the `Demonstration Shortcut'. While previous works have primarily focused on improving ICL prediction results for predefined tasks, we aim to rectify the Demonstration Shortcut, thereby enabling the LLM to effectively learn new input-label relationships from demonstrations. To achieve this, we introduce In-Context Calibration, a demonstration-aware calibration method. We evaluate the effectiveness of the proposed method in two settings: (1) the Original ICL Task using the standard label space and (2) the Task Learning setting, where the label space is replaced with semantically unrelated tokens. In 
    
[^70]: SemEval-2024共享任务6: SHROOM，一个关于幻觉及相关可观察过度生成错误的共享任务

    SemEval-2024 Shared Task 6: SHROOM, a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes

    [https://arxiv.org/abs/2403.07726](https://arxiv.org/abs/2403.07726)

    本文介绍了SHROOM共享任务，重点关注检测幻觉，以及参与者使用的模型和策略。

    

    本文介绍了SHROOM的结果，这是一个专注于检测幻觉的共享任务：即自然语言生成（NLG）系统的输出流畅但不准确。这种过度生成的情况可能危及许多NLG应用，其中正确性往往至关重要。共享任务使用了一个新构建的数据集，包含4000个由5个标注者标记的模型输出，涵盖了3个NLP任务：机器翻译、释义生成和定义建模。 共享任务由58个不同用户组成的42支团队共同解决，其中27支选择撰写系统描述论文；他们共提交了超过300个预测集在共享任务的两个跟踪上。我们观察到这种方法如何被处理的一些关键趋势--许多参与者依赖少数模型，并经常依赖合成数据进行微调或零样本提示策略。

    arXiv:2403.07726v1 Announce Type: new  Abstract: This paper presents the results of the SHROOM, a shared task focused on detecting hallucinations: outputs from natural language generation (NLG) systems that are fluent, yet inaccurate. Such cases of overgeneration put in jeopardy many NLG applications, where correctness is often mission-critical. The shared task was conducted with a newly constructed dataset of 4000 model outputs labeled by 5 annotators each, spanning 3 NLP tasks: machine translation, paraphrase generation and definition modeling.   The shared task was tackled by a total of 58 different users grouped in 42 teams, out of which 27 elected to write a system description paper; collectively, they submitted over 300 prediction sets on both tracks of the shared task. We observe a number of key trends in how this approach was tackled -- many participants rely on a handful of model, and often rely either on synthetic data for fine-tuning or zero-shot prompting strategies. While 
    
[^71]: 利用对抗训练的本地层次结构进行分层文本分类

    Utilizing Local Hierarchy with Adversarial Training for Hierarchical Text Classification

    [https://arxiv.org/abs/2402.18825](https://arxiv.org/abs/2402.18825)

    通过引入对抗性框架和本地层次结构，我们提出了一个适用于几乎所有HTC模型的HiAdv框架，优化了分层文本分类，并证明了本地层次结构的有效性，特别对于训练数据不足的罕见类别。

    

    分层文本分类（HTC）是多标签分类的一个具有挑战性的子任务，因为其复杂的分类结构。几乎所有最近的HTC作品都关注标签如何结构化，但忽略了根据每个输入文本的地面真实标签的子结构，其中包含丰富的标签共现信息。在这项工作中，我们引入了这种本地层次结构和一个对抗性框架。我们提出了一个名为HiAdv的框架，可以适应几乎所有HTC模型，并将本地层次结构作为辅助信息进行优化。我们在两个典型的HTC模型上进行测试，并发现HiAdv在所有情况下都是有效的，能够处理复杂的分类层次结构。进一步的实验证明，我们框架的提升确实来自本地层次结构，本地层次结构有利于那些训练数据不足的罕见类别。

    arXiv:2402.18825v1 Announce Type: new  Abstract: Hierarchical text classification (HTC) is a challenging subtask of multi-label classification due to its complex taxonomic structure. Nearly all recent HTC works focus on how the labels are structured but ignore the sub-structure of ground-truth labels according to each input text which contains fruitful label co-occurrence information. In this work, we introduce this local hierarchy with an adversarial framework. We propose a HiAdv framework that can fit in nearly all HTC models and optimize them with the local hierarchy as auxiliary information. We test on two typical HTC models and find that HiAdv is effective in all scenarios and is adept at dealing with complex taxonomic hierarchies. Further experiments demonstrate that the promotion of our framework indeed comes from the local hierarchy and the local hierarchy is beneficial for rare classes which have insufficient training data.
    
[^72]: 生成人工智能对术语定义的意义

    What Generative Artificial Intelligence Means for Terminological Definitions

    [https://arxiv.org/abs/2402.16139](https://arxiv.org/abs/2402.16139)

    生成人工智能工具如ChatGPT在提供定制化的语境特定含义方面表现出色，但在准确性方面存在挑战，可以辅助术语学家进行术语编纂，实现AI效率与人类专业知识的结合。

    

    本文探讨了生成人工智能（GenAI）对术语定义的创建和消费的影响。像ChatGPT这样的GenAI工具与传统术语资源相比，带来了一系列益处和挑战。ChatGPT在以交互式和定制化的方式提供特定语境含义方面表现出色，但在准确性方面面临挑战。识别资源中的术语定义可能会因其可靠性而继续存在。从术语学家的角度来看，诸如ChatGPT之类的工具使得AI辅助的术语编纂成为可能，包括后期编辑术语编纂，将AI效率与人类专业知识相结合，以实现更快速的定义创建。

    arXiv:2402.16139v1 Announce Type: cross  Abstract: This paper examines the impact of Generative Artificial Intelligence (GenAI) on the creation and consumption of terminological definitions. GenAI tools like ChatGPT present a mix of benefits and drawbacks compared to traditional terminological resources. ChatGPT excels in providing context-specific meanings in an interactive and customized fashion but faces challenges with accuracy. Terminological definitions in recognized resources will likely survive because of their reliability. From the point of view of the terminologist, tools like ChatGPT enable AI-assisted terminography, including post-editing terminography, as an approach blending AI efficiency with human expertise for faster definition creation.
    
[^73]: 针对参数高效微调的权重投毒后门攻击的防御

    Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning

    [https://arxiv.org/abs/2402.12168](https://arxiv.org/abs/2402.12168)

    PEFT相对于全参数微调更容易受到权重投毒后门攻击的影响，提出了一个通过置信度识别受污染样本的毒化样本识别模块（PSIM），为权重投毒后门攻击提供稳健防御

    

    最近，针对语言模型应用提出并成功实施了各种参数高效微调（PEFT）策略。然而，这引发了一个问题，即当面对权重投毒后门攻击时，仅更新有限模型参数的PEFT是否构成安全漏洞。我们展示了PEFT相对于全参数微调方法更容易受到权重投毒后门攻击的影响，预定义的触发器仍然易受利用，预定义的目标在微调后依然保持高置信度。受到这一见解的启发，我们开发了一个利用PEFT的毒化样本识别模块（PSIM），通过置信度识别受污染样本，提供针对权重投毒后门攻击的稳健防御。具体而言，我们利用PEFT训练PSIM，带有随机重置样本标签。在推断过程中，

    arXiv:2402.12168v1 Announce Type: cross  Abstract: Recently, various parameter-efficient fine-tuning (PEFT) strategies for application to language models have been proposed and successfully implemented. However, this raises the question of whether PEFT, which only updates a limited set of model parameters, constitutes security vulnerabilities when confronted with weight-poisoning backdoor attacks. In this study, we show that PEFT is more susceptible to weight-poisoning backdoor attacks compared to the full-parameter fine-tuning method, with pre-defined triggers remaining exploitable and pre-defined targets maintaining high confidence, even after fine-tuning. Motivated by this insight, we developed a Poisoned Sample Identification Module (PSIM) leveraging PEFT, which identifies poisoned samples through confidence, providing robust defense against weight-poisoning backdoor attacks. Specifically, we leverage PEFT to train the PSIM with randomly reset sample labels. During the inference pr
    
[^74]: 使用大型语言模型进行反叙事评估的多方面框架

    A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models

    [https://arxiv.org/abs/2402.11676](https://arxiv.org/abs/2402.11676)

    提出了一个多方面框架，使用大型语言模型评估反叙事，通过5个方面从专门 NGO 指南中提取定义的内容，以解决以往评估方法的局限性。

    

    反叙事是对仇恨言论背景的知情回应，旨在驳斥仇恨主张并化解冲突，已成为一种有效的仇恨言论干预策略。先前的工作提出了自动生成反叙事的方法来辅助手动干预，但这些方法的评估仍未得到充分发展。先前用于反叙事评估的自动度量标准缺乏与人类判断的一致性，因为它们依赖于表面参考比较，而不是将反叙事质量的关键方面纳入评估标准。为解决先前的评估局限性，我们提出了一个新颖的评估框架，促使LLM提供生成的反叙事候选的得分和反馈，使用了来自专门NGO的反叙事指南中提取的5个定义的方面。

    arXiv:2402.11676v1 Announce Type: cross  Abstract: Counter narratives - informed responses to hate speech contexts designed to refute hateful claims and de-escalate encounters - have emerged as an effective hate speech intervention strategy. While previous work has proposed automatic counter narrative generation methods to aid manual interventions, the evaluation of these approaches remains underdeveloped. Previous automatic metrics for counter narrative evaluation lack alignment with human judgment as they rely on superficial reference comparisons instead of incorporating key aspects of counter narrative quality as evaluation criteria. To address prior evaluation limitations, we propose a novel evaluation framework prompting LLMs to provide scores and feedback for generated counter narrative candidates using 5 defined aspects derived from guidelines from counter narrative specialized NGOs. We found that LLM evaluators achieve strong alignment to human-annotated scores and feedback and
    
[^75]: 大型语言模型的上下文学习中的不确定性分解和量化

    Uncertainty Decomposition and Quantification for In-Context Learning of Large Language Models

    [https://arxiv.org/abs/2402.10189](https://arxiv.org/abs/2402.10189)

    本文研究了大型语言模型（LLM）上下文学习中的不确定性，并提出了一种新的方法来量化这种不确定性，包括演示产生的不确定性和模型配置的模糊性。

    

    上下文学习已经成为大型语言模型（LLM）的突破性能力，并通过在提示中提供一些与任务相关的演示来彻底改变了各个领域。然而，LLM响应中的可信问题，如幻觉，也被积极讨论。现有工作致力于量化LLM响应中的不确定性，但往往忽视LLM的复杂性和上下文学习的独特性。在这项工作中，我们深入研究了与上下文学习相关的LLM预测不确定性，并强调这种不确定性可能来自于提供的演示（aleatoric不确定性）和与模型配置相关的模糊性（epistemic不确定性）。我们提出了一种新的公式和相应的估计方法来量化这两种类型的不确定性。该方法为理解上下文学习里的预测提供了一种无监督的方式。

    arXiv:2402.10189v1 Announce Type: new  Abstract: In-context learning has emerged as a groundbreaking ability of Large Language Models (LLMs) and revolutionized various fields by providing a few task-relevant demonstrations in the prompt. However, trustworthy issues with LLM's response, such as hallucination, have also been actively discussed. Existing works have been devoted to quantifying the uncertainty in LLM's response, but they often overlook the complex nature of LLMs and the uniqueness of in-context learning. In this work, we delve into the predictive uncertainty of LLMs associated with in-context learning, highlighting that such uncertainties may stem from both the provided demonstrations (aleatoric uncertainty) and ambiguities tied to the model's configurations (epistemic uncertainty). We propose a novel formulation and corresponding estimation method to quantify both types of uncertainties. The proposed method offers an unsupervised way to understand the prediction of in-cont
    
[^76]: 在狼人游戏中增强大型语言模型的推理能力

    Enhance Reasoning for Large Language Models in the Game Werewolf

    [https://arxiv.org/abs/2402.02330](https://arxiv.org/abs/2402.02330)

    本文提出了一个创新的框架，将大型语言模型（LLM）与外部思考模块相结合，以增强推理能力，通过引入通信协议和使用大量数据进行训练，展示了其在游戏推理、语音生成和在线评估方面的有效性。

    

    本文提出了一个创新的框架，将大型语言模型（LLM）与外部思考模块相结合，以增强基于LLM的代理的推理能力。与通过prompt工程增加LLM不同，思考者直接利用数据库中的知识，并采用各种优化技术。该框架形成了一个推理层次结构，在其中LLM处理直观的系统1任务，如自然语言处理，而思考者专注于需要复杂的逻辑分析和领域特定知识的认知系统2任务。我们以需要双系统推理的9人狼人游戏为例介绍了该框架。我们引入了LLM和思考者之间的通信协议，并使用来自18800个人类会话和强化学习的数据训练了思考者。实验证明了该框架在演绎推理、语音生成和在线游戏评估方面的有效性。此外，我们通过微调6B LLM，超越了GPT4。

    This paper presents an innovative framework that integrates Large Language Models (LLMs) with an external Thinker module to enhance the reasoning capabilities of LLM-based agents. Unlike augmenting LLMs with prompt engineering, Thinker directly harnesses knowledge from databases and employs various optimization techniques. The framework forms a reasoning hierarchy where LLMs handle intuitive System-1 tasks such as natural language processing, while the Thinker focuses on cognitive System-2 tasks that require complex logical analysis and domain-specific knowledge. Our framework is presented using a 9-player Werewolf game that demands dual-system reasoning. We introduce a communication protocol between LLMs and the Thinker, and train the Thinker using data from 18800 human sessions and reinforcement learning. Experiments demonstrate the framework's effectiveness in deductive reasoning, speech generation, and online game evaluation. Additionally, we fine-tune a 6B LLM to surpass GPT4 when
    
[^77]: CroissantLLM: 一个真正的双语法语-英语语言模型

    CroissantLLM: A Truly Bilingual French-English Language Model

    [https://arxiv.org/abs/2402.00786](https://arxiv.org/abs/2402.00786)

    CroissantLLM是一个1.3B的双语语言模型，通过使用1:1的英语-法语预训练数据比例、自定义的分词器和双语调优数据集进行训练，实现了高性能和开源。模型还发布了训练数据集和多个检查点，以及一个法语基准测试 FrenchBench。

    

    我们介绍了CroissantLLM，这是一个在3T个英语和法语标记上预训练的13亿语言模型，为研究和工业社区带来了一种高性能的、完全开源的双语模型，可以在消费级本地硬件上快速运行。为此，我们首次尝试使用1:1的英语-法语预训练数据比例、自定义的分词器和双语调优数据集来训练一种内在双语的模型。我们发布了训练数据集，其中包含了一个法语分割，其中包含了手工策划、高质量和多样化的数据源。为了评估在英语以外的性能，我们创建了一个新的基准测试 FrenchBench，包括一系列分类和生成任务，涵盖了模型在法语语言中性能的各个方面。此外，为了保持透明度并促进进一步的大规模语言模型研究，我们发布了代码库和各种模型规模、训练数据分布上的几十个检查点。

    We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3T English and French tokens, to bring to the research and industrial community a high-performance, fully open-sourced bilingual model that runs swiftly on consumer-grade local hardware. To that end, we pioneer the approach of training an intrinsically bilingual model with a 1:1 English-to-French pretraining data ratio, a custom tokenizer, and bilingual finetuning datasets. We release the training dataset, notably containing a French split with manually curated, high-quality, and varied data sources. To assess performance outside of English, we craft a novel benchmark, FrenchBench, consisting of an array of classification and generation tasks, covering various orthogonal aspects of model performance in the French Language. Additionally, rooted in transparency and to foster further Large Language Model research, we release codebases, and dozens of checkpoints across various model sizes, training data distributions, 
    
[^78]: 使用知识图谱上的重述进行对话式问答

    Conversational Question Answering with Reformulations over Knowledge Graph

    [https://arxiv.org/abs/2312.17269](https://arxiv.org/abs/2312.17269)

    提出了使用重述技术改进对话式问答性能的CornNet模型

    

    对话式问答（convQA）是关于知识图谱（KGs）中包含的信息的多轮自然语言问题的回答。目前的convQA方法通常在难以理解的问答配对方面遇到困难。这些输入对于人类来说在对话历史的基础上很容易理解，但对于机器来说很难解释，这可能会降低convQA性能。为了解决这个问题，我们提出了一个基于强化学习（RL）的模型CornNet，它利用大型语言模型（LLMs）生成的问题重述来提高convQA性能。CornNet采用教师-学生架构，其中教师模型使用人类编写的重述来学习问题表示，学生模型通过LLMs生成的重述来模仿教师模型的输出。然后，RL模型使用学到的问题表示来在KG中定位正确答案。

    arXiv:2312.17269v2 Announce Type: replace-cross  Abstract: Conversational question answering (convQA) over knowledge graphs (KGs) involves answering multi-turn natural language questions about information contained in a KG. State-of-the-art methods of ConvQA often struggle with inexplicit question-answer pairs. These inputs are easy for human beings to understand given a conversation history, but hard for a machine to interpret, which can degrade ConvQA performance. To address this problem, we propose a reinforcement learning (RL) based model, CornNet, which utilizes question reformulations generated by large language models (LLMs) to improve ConvQA performance. CornNet adopts a teacher-student architecture where a teacher model learns question representations using human writing reformulations, and a student model to mimic the teacher model's output via reformulations generated by LLMs. The learned question representation is then used by an RL model to locate the correct answer in a K
    
[^79]: GlitchBench：大型多模态模型能够检测视频游戏漏洞吗？

    GlitchBench: Can large multimodal models detect video game glitches?

    [https://arxiv.org/abs/2312.05291](https://arxiv.org/abs/2312.05291)

    GlitchBench是一个基于视频游戏质量保证任务的新基准，旨在挑战LMMs在检测和解释异常事件方面的视觉和语言推理能力。

    

    大型多模态模型（LMMs）已从大型语言模型（LLMs）发展而来，以整合多种输入模态，如视觉输入。这种整合增强了LLMs在需要视觉理解和推理的任务上的能力。然而，尤其是在涉及真实世界任务时，它们增强的能力的程度和限制尚未完全被理解。为了填补这一空白，我们引入了GlitchBench，这是一个新颖的基准，源自于视频游戏质量保证任务，旨在测试和评估LMMs的推理能力。我们的基准是从各种视频游戏中的不寻常和出现故障的场景精心策划而成，旨在挑战LMMs在检测和解释非同寻常事件方面的视觉和语言推理能力。我们评估了多个最先进的LMMs，并展示了GlitchBench为这些模型提出了新挑战。 代码和数据可在以下链接找到：https://glitchb

    arXiv:2312.05291v2 Announce Type: replace-cross  Abstract: Large multimodal models (LMMs) have evolved from large language models (LLMs) to integrate multiple input modalities, such as visual inputs. This integration augments the capacity of LLMs for tasks requiring visual comprehension and reasoning. However, the extent and limitations of their enhanced abilities are not fully understood, especially when it comes to real-world tasks. To address this gap, we introduce GlitchBench, a novel benchmark derived from video game quality assurance tasks, to test and evaluate the reasoning capabilities of LMMs. Our benchmark is curated from a variety of unusual and glitched scenarios from video games and aims to challenge both the visual and linguistic reasoning powers of LMMs in detecting and interpreting out-of-the-ordinary events. We evaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents a new challenge for these models. Code and data are available at: https://glitchb
    
[^80]: 大型多模态模型的组合式思维提示

    Compositional Chain-of-Thought Prompting for Large Multimodal Models

    [https://arxiv.org/abs/2311.17076](https://arxiv.org/abs/2311.17076)

    提出了一种新颖的零样式思维提示（CCoT），以克服大型多模态模型难以捕捉到组合视觉推理方面的细节的问题。

    

    强大的视觉骨干和大规模语言模型(LLM)推理的结合已经导致大型多模态模型(LMM)成为当前广泛视觉和语言(VL)任务的标准。然而，最近的研究表明，即使是最先进的LMM仍然难以捕捉到组合视觉推理方面的细节，比如对象之间的属性和关系。一种解决方案是利用场景图(SGs)——对象及其关系和属性的形式化表达，它已被广泛用作视觉和文本领域之间的桥梁。然而，场景图数据需要场景图注释，这种数据收集成本高昂，因此难以扩展。此外，基于场景图数据微调LMM可能导致预训练目标的灾难性遗忘。为了克服这一问题，受到思维链方法的启发，我们提出了一种新颖的零样式思维提示（CCoT）。

    arXiv:2311.17076v2 Announce Type: replace-cross  Abstract: The combination of strong visual backbones and Large Language Model (LLM) reasoning has led to Large Multimodal Models (LMMs) becoming the current standard for a wide range of vision and language (VL) tasks. However, recent research has shown that even the most advanced LMMs still struggle to capture aspects of compositional visual reasoning, such as attributes and relationships between objects. One solution is to utilize scene graphs (SGs)--a formalization of objects and their relations and attributes that has been extensively used as a bridge between the visual and textual domains. Yet, scene graph data requires scene graph annotations, which are expensive to collect and thus not easily scalable. Moreover, finetuning an LMM based on SG data can lead to catastrophic forgetting of the pretraining objective. To overcome this, inspired by chain-of-thought methods, we propose Compositional Chain-of-Thought (CCoT), a novel zero-sho
    
[^81]: PEMA：一种可在离线调整的外部插件内存自适应语言模型

    PEMA: An Offsite-Tunable Plug-in External Memory Adaptation for Language Models

    [https://arxiv.org/abs/2311.08590](https://arxiv.org/abs/2311.08590)

    PEMA是一种参数有效的微调方法，通过插件外部内存自适应实现了对预训练语言模型的微调，绕过了对所有权重的访问需求，同时利用外部内存和适配器权重矩阵来提高效率。

    

    预训练语言模型（PLM）在各种下游自然语言处理任务中表现出色。然而，训练大型语言模型需要大量内存和计算资源。由于资源需求巨大，许多PLM权重是机密的，用户被迫将其数据与模型所有者共享，以便为特定任务进行微调。为了克服这些限制，我们引入了插件外部内存自适应（PEMA），一种参数有效的微调（PEFT）方法，实现了在不需要访问所有权重的情况下对PLM进行微调。PEMA在推理期间集成了来自测试数据的上下文表示以执行下游任务。它使用外部内存存储由PLM生成的上下文表示与目标标记相映射。我们的方法利用了PLM最终层中类似LoRA的瓶颈适配器的权重矩阵来提高效率。

    arXiv:2311.08590v2 Announce Type: replace  Abstract: Pre-trained language models (PLMs) show impressive performance in various downstream NLP tasks. However, pre-training large language models demands substantial memory and training compute. Furthermore, due to the substantial resources required, many PLM weights are confidential. Consequently, users are compelled to share their data with model owners for fine-tuning specific tasks. To overcome the limitations, we introduce Plug-in External Memory Adaptation (PEMA), a Parameter-Efficient Fine-Tuning (PEFT) method, enabling PLM fine-tuning without requiring access to all the weights. PEMA integrates with context representations from test data during inference to perform downstream tasks. It uses external memory to store PLM-generated context representations mapped with target tokens. Our method utilizes weight matrices of LoRA-like bottlenecked adapter in the PLM's final layer to enhance efficiency. Our approach also includes Gradual Un
    
[^82]: 学习从错误中使LLM成为更好的推理者

    Learning From Mistakes Makes LLM Better Reasoner

    [https://arxiv.org/abs/2310.20689](https://arxiv.org/abs/2310.20689)

    本研究探索了大型语言模型（LLMs）是否可以从错误中学习，类似于人类学习的过程，并通过引入错误纠正的数据对来改进LLMs的推理能力。实验结果表明，这种方法能够持续提升仅使用CoT进行微调后的性能。

    

    最近，大型语言模型（LLM）在解决数学问题方面展示出了卓越的推理能力。为了进一步提高它们的推理能力，本研究探讨了LLM是否可以学习从错误中获益（LEMA），类似于人类的学习过程。考虑一个未能解决数学问题的人类学生，他会从自己犯的错误中学习，并纠正它。模仿这种错误驱动的学习过程，LEMA在LLM的微调过程中引入了错误纠正的数据对。具体而言，我们首先收集来自各种LLM的错误推理路径，然后使用GPT-4作为“纠正者”来识别错误步骤，解释错误原因，纠正错误并生成最终答案。此外，我们还应用了一种基于纠正的进化策略，有效地扩展了生成纠正数据的问题集。在各种LLM和推理任务上的实验表明，LEMA始终可以提升仅使用CoT的微调。我们...

    Large language models (LLMs) recently exhibited remarkable reasoning capabilities on solving math problems. To further improve their reasoning capabilities, this work explores whether LLMs can LEarn from MistAkes (LEMA), akin to the human learning process. Consider a human student who failed to solve a math problem, he will learn from what mistake he has made and how to correct it. Mimicking this error-driven learning process, LEMA incorporates mistake-correction data pairs during fine-tuning LLMs. Specifically, we first collect inaccurate reasoning paths from various LLMs, and then employ GPT-4 as a "corrector" to identify the mistake step, explain the reason for the mistake, correct the mistake and generate the final answer. In addition, we apply a correction-centric evolution strategy that effectively expands the question set for generating correction data. Experiments across various LLMs and reasoning tasks show that \textsc{LeMa} consistently improves CoT-alone fine-tuning. Our fu
    
[^83]: 用于混合语言符号推理的自然语言嵌入程序

    Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning

    [https://arxiv.org/abs/2309.10814](https://arxiv.org/abs/2309.10814)

    该论文提出了一种自然语言嵌入程序的框架，以解决需要符号和数值推理的任务，不仅能够生成Python程序进行推理，还可以在数学推理、文本分类、问题回答等多个任务中优于基线方法。

    

    arXiv:2309.10814v2 公告类型: 替换 摘要: 我们如何通过自然语言表示执行计算以解决需要符号和数值推理的任务？我们提出了自然语言嵌入程序（NLEP）作为一个统一的框架，用于解决数学/符号推理、自然语言理解和指令跟随任务。我们的方法促使语言模型生成完整的Python程序，定义在包含结构化知识自然语言表示的数据结构上的函数。然后Python解释器执行生成的代码并打印输出。尽管使用了一个任务通用的提示，我们发现这种方法可以在一系列不同任务上包括数学和符号推理、文本分类、问题回答和指令跟随中改进强基线。我们发现生成的程序是可解释的，因为它们概述了程序解释器遵循的确切推理过程。

    arXiv:2309.10814v2 Announce Type: replace  Abstract: How can we perform computations over natural language representations to solve tasks that require symbolic and numeric reasoning? We propose natural language embedded programs (NLEP) as a unifying framework for addressing math/symbolic reasoning, natural language understanding, and instruction following tasks. Our approach prompts a language model to generate full Python programs that define functions over data structures which contain natural language representations of structured knowledge. A Python interpreter then executes the generated code and prints the output. Despite using a task-general prompt, we find that this approach can improve upon strong baselines across a range of different tasks including math and symbolic reasoning, text classification, question answering, and instruction following. We found that the generated programs are interpretable since they outline the exact reasoning process followed by the program interpr
    
[^84]: S\={a}mayik: 一种用于英梵语翻译的基准和数据集

    S\={a}mayik: A Benchmark and Dataset for English-Sanskrit Translation

    [https://arxiv.org/abs/2305.14004](https://arxiv.org/abs/2305.14004)

    S\={a}mayik是一个包含约53,000个平行英梵句子的数据集，覆盖了多个领域，特别关注梵文的当代用法，用于培训的翻译模型在翻译出领域的当代语料时显示出显著的提升

    

    我们发布了S\={a}mayik，这是一个包含约53,000个英梵平行句子的数据集，使用现代散文书写。梵文是一种仍在使用的古典语言，拥有丰富的文献传承。然而，由于数字化内容的有限可用性，梵文仍然是一种低资源语言。现有的梵文语料库，无论是单语还是双语，主要集中在诗歌上，并对当代书面材料的覆盖范围有限。S\={a}mayik从各种领域中精选出来，其中包括语言教学材料、文本教学法和在线教程等。它作为一种独特的资源，特别适用于梵文的当代用法，主要强调散文写作。在我们的数据集上训练的翻译模型在翻译域外的当代语料时表现出显著的改进，优于那些训练模型

    arXiv:2305.14004v2 Announce Type: replace  Abstract: We release S\={a}mayik, a dataset of around 53,000 parallel English-Sanskrit sentences, written in contemporary prose. Sanskrit is a classical language still in sustenance and has a rich documented heritage. However, due to the limited availability of digitized content, it still remains a low-resource language. Existing Sanskrit corpora, whether monolingual or bilingual, have predominantly focused on poetry and offer limited coverage of contemporary written materials. S\={a}mayik is curated from a diverse range of domains, including language instruction material, textual teaching pedagogy, and online tutorials, among others. It stands out as a unique resource that specifically caters to the contemporary usage of Sanskrit, with a primary emphasis on prose writing. Translation models trained on our dataset demonstrate statistically significant improvements when translating out-of-domain contemporary corpora, outperforming models traine
    
[^85]: DialogCC: 一个用于创建高质量多模态对话数据集的自动化流水线

    DialogCC: An Automated Pipeline for Creating High-Quality Multi-Modal Dialogue Dataset

    [https://arxiv.org/abs/2212.04119](https://arxiv.org/abs/2212.04119)

    提出了一个自动化流水线来构建高质量和多样化的多模态对话数据集，确保对话质量和图像多样性，并且不需要人力介入。

    

    随着在即时消息中分享图片成为一个关键因素，对学习图像文本多模态对话模型进行了积极研究。然而，由于现有多模态对话数据集中每个对话中图像的质量低和多样性有限，训练一个良好泛化的多模态对话模型仍具挑战性。本文提出了一个自动化流水线来构建多模态对话数据集，确保对话质量和图像多样性，并且不需要人力介入。在我们的流水线中，为了确保图像与对话之间的连贯性，我们引导GPT-4推断潜在的图像分享时刻 - 具体地，话语、说话者、理由和图像描述。此外，我们利用CLIP相似度来保持多个对齐图像与话语之间的一致性。通过这个流水线，我们介绍了DialogCC，一个高质量且多样化的多模态对话数据集。

    arXiv:2212.04119v2 Announce Type: replace-cross  Abstract: As sharing images in an instant message is a crucial factor, there has been active research on learning an image-text multi-modal dialogue models. However, training a well-generalized multi-modal dialogue model remains challenging due to the low quality and limited diversity of images per dialogue in existing multi-modal dialogue datasets. In this paper, we propose an automated pipeline to construct a multi-modal dialogue dataset, ensuring both dialogue quality and image diversity without requiring minimum human effort. In our pipeline, to guarantee the coherence between images and dialogue, we prompt GPT-4 to infer potential image-sharing moments - specifically, the utterance, speaker, rationale, and image description. Furthermore, we leverage CLIP similarity to maintain consistency between aligned multiple images to the utterance. Through this pipeline, we introduce DialogCC, a high-quality and diverse multi-modal dialogue da
    
[^86]: QAGCN：通过对知识图谱进行单步隐式推理回答多关系问题

    QAGCN: Answering Multi-Relation Questions via Single-Step Implicit Reasoning over Knowledge Graphs

    [https://arxiv.org/abs/2206.01818](https://arxiv.org/abs/2206.01818)

    本文提出了 QAGCN 方法，通过对问题进行感知来实现单步隐式推理，从而回答多关系问题，相比于显式多步推理方法，该方法更简单、高效且易于采用。

    

    多关系问题回答（QA）是一项具有挑战性的任务，通常需要在由多个关系组成的知识图谱中进行长时间推理链的问题。最近，在这一任务中明显使用了基于知识图谱的显式多步推理方法，并展现出了良好的性能。这些方法包括通过知识图谱三元组逐步标签传播的方法以及基于强化学习浏览知识图谱三元组的方法。这些方法的一个主要弱点是它们的推理机制通常复杂且难以实现或训练。在本文中，我们认为可以通过端到端单步隐式推理实现多关系QA，这种方法更简单、更高效且更易于采用。我们提出了 QAGCN -- 一种基于问题意识的图卷积网络（GCN）方法，其中包括一种新颖的具有受控问题相关信息传播的GCN架构。

    arXiv:2206.01818v3 Announce Type: replace  Abstract: Multi-relation question answering (QA) is a challenging task, where given questions usually require long reasoning chains in KGs that consist of multiple relations. Recently, methods with explicit multi-step reasoning over KGs have been prominently used in this task and have demonstrated promising performance. Examples include methods that perform stepwise label propagation through KG triples and methods that navigate over KG triples based on reinforcement learning. A main weakness of these methods is that their reasoning mechanisms are usually complex and difficult to implement or train. In this paper, we argue that multi-relation QA can be achieved via end-to-end single-step implicit reasoning, which is simpler, more efficient, and easier to adopt. We propose QAGCN -- a Question-Aware Graph Convolutional Network (GCN)-based method that includes a novel GCN architecture with controlled question-dependent message propagation for the 
    
[^87]: 一种针对语言方言的自然语言处理方法：一项调查

    Natural Language Processing for Dialects of a Language: A Survey. (arXiv:2401.05632v1 [cs.CL])

    [http://arxiv.org/abs/2401.05632](http://arxiv.org/abs/2401.05632)

    这项调查研究了自然语言处理中针对方言的方法和问题，强调了方言对于NLP模型性能和语言技术公平性的影响，并提供了关于方言相关任务和语言的全面综述。

    

    最先进的自然语言处理（NLP）模型是在大规模训练语料库上训练的，并在评估数据集上展现出卓越的性能。本调查探讨了这些数据集的一个重要属性：语言方言。考虑到针对方言数据集的NLP模型性能下降及其对语言技术公平性的影响，我们调查了有关方言NLP的过去研究，包括数据集和方法。我们从两个类别的视角描述了各种NLP任务：自然语言理解（NLU）（如方言分类、情感分析、解析和NLU基准测试）和自然语言生成（NLG）（如摘要、机器翻译和对话系统）。这项调查还广泛涵盖了英语、阿拉伯语、德语等多种语言。我们观察到，有关方言的过去NLP工作不止于方言分类，而是...

    State-of-the-art natural language processing (NLP) models are trained on massive training corpora, and report a superlative performance on evaluation datasets. This survey delves into an important attribute of these datasets: the dialect of a language. Motivated by the performance degradation of NLP models for dialectic datasets and its implications for the equity of language technologies, we survey past research in NLP for dialects in terms of datasets, and approaches. We describe a wide range of NLP tasks in terms of two categories: natural language understanding (NLU) (for tasks such as dialect classification, sentiment analysis, parsing, and NLU benchmarks) and natural language generation (NLG) (for summarisation, machine translation, and dialogue systems). The survey is also broad in its coverage of languages which include English, Arabic, German among others. We observe that past work in NLP concerning dialects goes deeper than mere dialect classification, and . This includes ear
    
[^88]: DialogBench: 将LLMs作为人类对话系统进行评估

    DialogBench: Evaluating LLMs as Human-like Dialogue Systems. (arXiv:2311.01677v1 [cs.CL])

    [http://arxiv.org/abs/2311.01677](http://arxiv.org/abs/2311.01677)

    本文提出了DialogBench，一个对话评估基准，用于评估LLMs作为人类对话系统的能力。通过对28个LLMs的广泛测试，发现指导微调对提升性能效果显著。

    

    大型语言模型(LLMs)在新的对话能力方面取得了显著突破，刷新了人们对对话系统的印象。对话系统长期以来的目标是足够像人类，以便通过满足交流、情感和社交归属的需要与用户建立长期联系。因此，迫切需要评估LLMs作为人类对话系统的能力。本文提出了DialogBench，一个对话评估基准，目前包含12个对话任务，评估LLMs作为人类对话系统应具备的能力。具体来说，我们使用GPT-4生成每个任务的评估实例。我们首先根据广泛使用的设计原则设计基本提示，并进一步减轻现有的偏见，生成更高质量的评估实例。我们对28个LLMs进行了广泛的测试（包括预训练和监督指导调优），结果显示指导微调效益显著。

    Large language models (LLMs) have achieved remarkable breakthroughs in new dialogue capabilities, refreshing human's impressions on dialogue systems. The long-standing goal of dialogue systems is to be human-like enough to establish long-term connections with users by satisfying the need for communication, affection and social belonging. Therefore, there has been an urgent need to evaluate LLMs as human-like dialogue systems. In this paper, we propose DialogBench, a dialogue evaluation benchmark that currently contains $12$ dialogue tasks to assess the capabilities of LLMs as human-like dialogue systems should have. Specifically, we prompt GPT-4 to generate evaluation instances for each task. We first design the basic prompt based on widely-used design principles and further mitigate the existing biases to generate higher-quality evaluation instances. Our extensive test over $28$ LLMs (including pre-trained and supervised instruction-tuning) shows that instruction fine-tuning benefits 
    
[^89]: 会话式金融信息检索模型（ConFIRM）

    Conversational Financial Information Retrieval Model (ConFIRM). (arXiv:2310.13001v1 [cs.IR])

    [http://arxiv.org/abs/2310.13001](http://arxiv.org/abs/2310.13001)

    ConFIRM是一种会话式金融信息检索模型，通过合成金融领域特定问答对和评估参数微调方法，实现了超过90%的准确性，为金融对话系统提供了数据高效的解决方案。

    

    随着大型语言模型（LLM）的指数级增长，利用它们在金融等专门领域的新兴特性具有探索的价值。然而，金融等受监管领域具有独特的约束条件，需要具备针对该领域的优化框架。我们提出了ConFIRM，一种基于LLM的会话式金融信息检索模型，用于查询意图分类和知识库标记。ConFIRM包括两个模块：1）一种合成金融领域特定问答对的方法，以及2）评估参数高效的微调方法来进行查询分类任务。我们生成了一个包含4000多个样本的数据集，并在单独的测试集上评估了准确性。ConFIRM实现了超过90%的准确性，这对于符合监管要求至关重要。ConFIRM提供了一种数据高效的解决方案，用于提取金融对话系统的精确查询意图。

    With the exponential growth in large language models (LLMs), leveraging their emergent properties for specialized domains like finance merits exploration. However, regulated fields such as finance pose unique constraints, requiring domain-optimized frameworks. We present ConFIRM, an LLM-based conversational financial information retrieval model tailored for query intent classification and knowledge base labeling.  ConFIRM comprises two modules:  1) a method to synthesize finance domain-specific question-answer pairs, and  2) evaluation of parameter efficient fine-tuning approaches for the query classification task. We generate a dataset of over 4000 samples, assessing accuracy on a separate test set.  ConFIRM achieved over 90% accuracy, essential for regulatory compliance. ConFIRM provides a data-efficient solution to extract precise query intent for financial dialog systems.
    
[^90]: 更少就意味着更多: 对参数高效微调的特洛伊攻击

    Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning. (arXiv:2310.00648v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00648](http://arxiv.org/abs/2310.00648)

    本文研究了参数高效微调（PEFT）的安全性问题，发现PEFT易受特洛伊攻击。通过提出一种新的攻击方式PETA，并在各种下游任务和触发器设计中进行广泛测试，发现PETA能够在攻击成功率和未受影响的准确性方面取得有效结果。

    

    参数高效微调（PEFT）可以将预训练语言模型（PLM）高效地适应到特定任务中。通过仅微调一小部分（额外的）参数，PEFT实现了与全面微调相当的性能。然而，尽管它被广泛使用，但PEFT的安全性影响仍然鲜为人知。在本文中，我们进行了一项初步研究，揭示了PEFT对特洛伊攻击的独特易受攻击性。具体而言，我们提出了PETA，一种通过双层优化考虑下游适应的新型攻击方式：上层目标将后门嵌入PLM中，而下层目标模拟PEFT以保留PLM的任务特定性能。通过对多种下游任务和触发器设计的广泛评估，我们证明了PETA在攻击成功率和未受影响的干净准确性方面的有效性，即使受害用户在使用纯净数据对带有后门的PLM进行PEFT后。

    Parameter-efficient fine-tuning (PEFT) enables efficient adaptation of pre-trained language models (PLMs) to specific tasks. By tuning only a minimal set of (extra) parameters, PEFT achieves performance comparable to full fine-tuning. However, despite its prevalent use, the security implications of PEFT remain largely unexplored. In this paper, we conduct a pilot study revealing that PEFT exhibits unique vulnerability to trojan attacks. Specifically, we present PETA, a novel attack that accounts for downstream adaptation through bilevel optimization: the upper-level objective embeds the backdoor into a PLM while the lower-level objective simulates PEFT to retain the PLM's task-specific performance. With extensive evaluation across a variety of downstream tasks and trigger designs, we demonstrate PETA's effectiveness in terms of both attack success rate and unaffected clean accuracy, even after the victim user performs PEFT over the backdoored PLM using untainted data. Moreover, we empi
    
[^91]: 推理还是背诵？通过反事实任务探索语言模型的能力和限制

    Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks. (arXiv:2307.02477v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.02477](http://arxiv.org/abs/2307.02477)

    通过反事实任务的研究，我们发现当前的语言模型具备一定的抽象推理能力，但它们在任务求解过程中往往也依赖于狭窄、难以转移的过程，这对语言模型的性能解释和理解有着重要的启示。

    

    最近语言模型在各种任务上的出色表现表明它们具备一定程度的抽象推理能力。这些能力是通用且可转移的，还是专门针对预训练过程中遇到的特定任务？为了分开这些效果，我们提出了一个评估框架，基于“反事实”任务变种，这些变种与支撑标准任务的默认假设有所偏离。在一套包含11个任务的实验中，我们观察到反事实变种的非平凡性能，但与默认条件相比，性能显著而持续地下降。这表明当前的语言模型可能在一定程度上具备抽象任务求解能力，但它们通常也依赖于狭窄、难以转移的任务求解过程。这些结果促使我们对语言模型性能进行更加谨慎的解释，以区分这些行为方面。

    The impressive performance of recent language models across a wide range of tasks suggests that they possess a degree of abstract reasoning skills. Are these skills general and transferable, or specialized to specific tasks seen during pretraining? To disentangle these effects, we propose an evaluation framework based on "counterfactual" task variants that deviate from the default assumptions underlying standard tasks. Across a suite of 11 tasks, we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions. This suggests that while current LMs may possess abstract task-solving skills to a degree, they often also rely on narrow, non-transferable procedures for task-solving. These results motivate a more careful interpretation of language model performance that teases apart these aspects of behavior.
    
[^92]: mPLUG-Owl: 模块化增强了大型语言模型的多模态能力

    mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality. (arXiv:2304.14178v1 [cs.CL])

    [http://arxiv.org/abs/2304.14178](http://arxiv.org/abs/2304.14178)

    本文介绍了一种名为mPLUG-Owl的训练范式，它通过模块化学习基础LLM、视觉知识模块和视觉抽象器模块，赋予LLMs多模态的能力。实验结果表明，mPLUG-Owl在图像字幕和视觉问答任务中表现优于基线模型，并在某些情况下达到了最先进的性能水平。

    

    大型语言模型(LLMs)已经在各种开放式任务中展示出了令人印象深刻的零-shot表现，而最近的研究还探讨了将LLMs用于多模态生成的应用。在本研究中，我们引入了一种新的训练范式mPLUG-Owl，通过基础LLM、视觉知识模块和视觉抽象器模块的模块化学习，使LLMs具备了多模态的能力。该方法可以支持多种模态，并通过模态协作促进了多单模态和多模态的能力。mPLUG-Owl的训练范式包括用于对齐图像和文本的两阶段方法，该方法利用LLM的辅助学习视觉知识，同时保持甚至改进了LLM的生成能力。在第一阶段中，使用冻结的LLM模块对视觉知识模块和抽象器模块进行训练以对齐图像和文本。在第二阶段中，使用仅语言和多模态监督数据集共同对模型进行微调。对于图像字幕和视觉问答任务的实验结果表明，mPLUG-Owl优于基线模型，在某些情况下达到了最先进的性能水平。

    Large language models (LLMs) have demonstrated impressive zero-shot abilities on a variety of open-ended tasks, while recent research has also explored the use of LLMs for multi-modal generation. In this study, we introduce mPLUG-Owl, a novel training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. This approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The training paradigm of mPLUG-Owl involves a two-stage method for aligning image and text, which learns visual knowledge with the assistance of LLM while maintaining and even improving the generation abilities of LLM. In the first stage, the visual knowledge module and abstractor module are trained with a frozen LLM module to align the image and text. In the second stage, language-only and multi-modal supervised datasets are used to jointly fine-tu
    

