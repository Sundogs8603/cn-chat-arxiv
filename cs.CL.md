# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ChatGPT as Data Augmentation for Compositional Generalization: A Case Study in Open Intent Detection.](http://arxiv.org/abs/2308.13517) | 本文通过使用ChatGPT作为数据增强技术，提高了开放意图检测任务中的合成泛化能力，有效改善了模型性能，并在多个基准测试中超过了现有技术。 |
| [^2] | [Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level.](http://arxiv.org/abs/2308.13506) | 本论文研究了在机器翻译中，如何在段落级别评估翻译质量。实验结果表明，使用句子级别的评估指标来评分整个段落与使用段落级别的指标一样有效。 |
| [^3] | [Ngambay-French Neural Machine Translation (sba-Fr).](http://arxiv.org/abs/2308.13497) | 该论文介绍了Ngambay-French神经机器翻译系统，并创造了第一个sba-Fr数据集，用于低资源语言的翻译研究。 |
| [^4] | [Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages.](http://arxiv.org/abs/2308.13479) | 本研究探讨了使用众包流程的提示对大型语言模型生成多样化的激励信息的影响。结果显示，通过使用众包流程的提示，GPT-4生成的信息比基准提示更加多样化。 |
| [^5] | [Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models.](http://arxiv.org/abs/2308.13467) | 本研究通过利用知识和强化学习的方法，实现了一个知识引导的语言模型集成，通过整合外部知识来弥补现有数据集中的信息缺失，从而提高了语言模型的可靠性和准确性。 |
| [^6] | [ARTIST: ARTificial Intelligence for Simplified Text.](http://arxiv.org/abs/2308.13458) | 本研究针对低资源语言的文本简化，设计和实现了一个可配置的文本简化流程，通过生成式AI技术实现了文本的简化，以满足公民获取公共信息和知识的需要。 |
| [^7] | [The Poison of Alignment.](http://arxiv.org/abs/2308.13449) | 对齐行为会污染指令数据集，降低微调模型的性能。 |
| [^8] | [EntropyRank: Unsupervised Keyphrase Extraction via Side-Information Optimization for Language Model-based Text Compression.](http://arxiv.org/abs/2308.13399) | 该论文提出了一种无监督的关键词提取方法，通过利用预训练语言模型和信息论方法，在文本中提取具有最高条件熵的短语作为关键词。实验证明，该方法在关键词提取任务上取得了与常用方法相当的结果。 |
| [^9] | [Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs.](http://arxiv.org/abs/2308.13387) | 这项工作收集了第一个用于评估LLMs中安全机制的开源数据集，并通过训练分类器实现了与GPT-4在自动安全评估上相媲美的结果。 |
| [^10] | [Assessing Keyness using Permutation Tests.](http://arxiv.org/abs/2308.13383) | 这项研究提出了一种使用排列检验评估语料库关键性的方法，解决了传统方法中对词分布不均导致的假阳性问题。 |
| [^11] | [On the Impact of Language Selection for Training and Evaluating Programming Language Models.](http://arxiv.org/abs/2308.13354) | 这项研究根据使用CodeBERT模型分析编程语言的表示，发现编程语言之间在标记表示方面存在差异，建议使用这种相似度度量方法来选择跨多种语言的模型。 |
| [^12] | [Decoupled Structure for Improved Adaptability of End-to-End Models.](http://arxiv.org/abs/2308.13345) | 本论文提出了一种解耦结构，通过解耦端到端ASR模型的声学和语言部分，来解决领域转变带来的问题，实现了灵活的领域自适应。 |
| [^13] | [Transforming the Output of Generative Pre-trained Transformer: The Influence of the PGI Framework on Attention Dynamics.](http://arxiv.org/abs/2308.13317) | 本文介绍了一种名为PGI的新方法，在实际商业问题中应用于GPT模型。该方法利用GPT模型的能力来理解复杂的语言结构，并生成上下文相关的回应。实验证实了PGI策略的有效性，并帮助解决了人类智能低度利用的问题。 |
| [^14] | [Construction Grammar and Language Models.](http://arxiv.org/abs/2308.13315) | 最新的深度学习和自然语言处理进展为计算方法和建构语法研究之间的协同关系提供了机会，本章提供了三种不同的计算方法与建构语法相互作用的途径，并重点关注语言模型。 |
| [^15] | [Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering.](http://arxiv.org/abs/2308.13259) | 本文提出了一个名为知识驱动的思维链（KD-CoT）的框架，用于验证和修改LLMs中的推理过程，通过与外部知识的交互来解决幻觉和错误传播的问题。 |
| [^16] | [LLM2KB: Constructing Knowledge Bases using instruction tuned context aware Large Language Models.](http://arxiv.org/abs/2308.13207) | 本文提出了LLM2KB，一种使用大语言模型构建知识库的系统，通过对Llama 2架构和维基百科数据集进行参数高效的指令调整，利用上下文感知和低秩适应技术，实现了有效构建知识库的目标。 |
| [^17] | [Journey to the Center of the Knowledge Neurons: Discoveries of Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons.](http://arxiv.org/abs/2308.13198) | 本文研究了多语言预训练语言模型中事实知识的存储方式，并引入了一种新的方法，能够更准确地定位知识神经元。通过实验证明了语言无关知识神经元的存在，以及发现了一种新型退化知识神经元。 |
| [^18] | [Formalising Natural Language Quantifiers for Human-Robot Interactions.](http://arxiv.org/abs/2308.13192) | 本文提出了一种在人机交互中形式化自然语言量词的方法，并设计了一个端到端系统以实现自然语言输入到逻辑表示的转换和评估，从而实现对机器人的控制。 |
| [^19] | [Chunk, Align, Select: A Simple Long-sequence Processing Method for Transformers.](http://arxiv.org/abs/2308.13191) | 这种方法提出了一种简单的框架，使得transformer能够处理更长的序列，同时计算和内存成本与输入序列长度线性增长。 |
| [^20] | [How to Evaluate the Generalization of Detection? A Benchmark for Comprehensive Open-Vocabulary Detection.](http://arxiv.org/abs/2308.13177) | 提出了一个名为OVDEval的新的基准测试方法，用于全面开放词汇检测。该方法包括9个子任务，并引入了常识知识、属性理解、位置理解、对象关系理解等方面的评估。数据集被精心创建以提供具有挑战性的负例，考验模型对视觉和语言输入的真正理解。此外，该方法发现了平均精确度（AP）指标在这些细粒度标签数据集上的问题，并提出了一种新指标。 |
| [^21] | [DISGO: Automatic End-to-End Evaluation for Scene Text OCR.](http://arxiv.org/abs/2308.13173) | 本文提出了一种自动化评估场景文本OCR的方法，采用统一的词错误率作为衡量标准，考虑了删除、插入、替换和分组/排序错误，同时使用超级块的概念计算BLEU分数。 |
| [^22] | [Measuring Spurious Correlation in Classification: 'Clever Hans' in Translationese.](http://arxiv.org/abs/2308.13170) | 这项研究揭示了高性能神经翻译分类器中存在的“聪明的汉斯”行为，它利用虚假相关性而非真实的翻译信号来提高分类性能。研究重点关注基于主题的虚假相关性，探讨了在没有关于虚假主题信息的情况下以及有关虚假主题信息的情况下分类器性能的影响。 |
| [^23] | [SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research.](http://arxiv.org/abs/2308.13149) | SciEval是一个综合且多学科的评估基准，用于评估大型语言模型在科学研究中的能力。它基于布鲁姆的分类法，包括客观和主观问题，并设计了一个防止数据泄漏的“动态”子集。实验结果表明，尽管GPT-4在某些方面取得了较高的得分，但仍存在挑战。 |
| [^24] | [MatchXML: An Efficient Text-label Matching Framework for Extreme Multi-label Text Classification.](http://arxiv.org/abs/2308.13139) | MatchXML是一种高效的文本-标签匹配框架，用于极端多标签文本分类。它通过label2vec方法生成语义密集的标签嵌入，并利用这些嵌入构建层次化标签树。通过微调预训练的Transformer模型，MatchXML将多标签文本分类问题转化为文本-标签匹配问题，并提取出密集的文本表示和静态的句子嵌入。 |
| [^25] | [OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models.](http://arxiv.org/abs/2308.13137) | OmniQuant是一种用于大型语言模型的全向校准量化技术，通过优化各种量化参数实现了良好的性能，并保持了计算效率。 |
| [^26] | [Sentence Embedding Models for Ancient Greek Using Multilingual Knowledge Distillation.](http://arxiv.org/abs/2308.13116) | 本文提出了一种使用多语种知识蒸馏方法来训练古希腊文本的句子嵌入模型，克服了缺乏训练数据的困难。 |
| [^27] | [Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models using an Interdisciplinary Lens.](http://arxiv.org/abs/2308.13089) | 该论文通过一个跨学科的视角，面对NLP模型中的社会人口偏见，探索了三个方面，解决了仅关注种族和性别等有限范围偏见、以及技术中心实施方法等挑战。 |
| [^28] | [Formal specification terminology for demographic agent-based models of fixed-step single-clocked simulations.](http://arxiv.org/abs/2308.13081) | 本文提出了一种适用于人口学领域的Agent Based Models (ABMs)的数学规范的合适形式术语，这进一步提高了模型的理解，并与O.D.D.协议相结合，减少了模型复制过程中的歧义。 |
| [^29] | [Causal Parrots: Large Language Models May Talk Causality But Are Not Causal.](http://arxiv.org/abs/2308.13067) | 大型语言模型（LLM）不能具备因果性，它们只是重复嵌入在数据中的因果知识。 |
| [^30] | [Lexical Diversity in Kinship Across Languages and Dialects.](http://arxiv.org/abs/2308.13056) | 本文研究了跨语言和方言中的亲属关系词汇的词汇多样性，并提出了一种方法来丰富计算词汇资源。通过大规模的案例研究，我们验证了该方法，并提供了可供浏览和下载的计算资源，扩展了对亲属关系术语的语言学研究，揭示了在语言和文化上相互接近的社区中多样性的程度。 |
| [^31] | [Financial News Analytics Using Fine-Tuned Llama 2 GPT Model.](http://arxiv.org/abs/2308.13032) | 本研究通过精细调整的Llama 2模型实现了金融新闻的多任务分析，包括文本分析、摘要和情感提取等。实验结果显示，提取的命名实体情感可以作为有监督机器学习模型的预测特征。 |
| [^32] | [Code Llama: Open Foundation Models for Code.](http://arxiv.org/abs/2308.12950) | Code Llama是一系列用于代码的开放基础模型，具有最先进的性能和填充功能，支持大型输入上下文和零-shot指令跟踪能力。在多个代码基准测试中，Code Llama达到开放模型中最高的性能，同时Python专门化模型在某些测试上超越了Llama 2的70B版本。 |
| [^33] | [Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?.](http://arxiv.org/abs/2308.12898) | 本论文研究了语言知识在多模态对齐中的作用，设计并发布了一个多模态对齐探测基准来检测关键的语言组成部分。 |
| [^34] | [Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning.](http://arxiv.org/abs/2308.12219) | 本文研究表明，通过扩展扩散语言模型的数据、规模和任务，可以有效使其成为强大的语言学习者。实验证明，扩展扩散语言模型在解决通用语言任务方面能够持续提高性能。 |
| [^35] | [Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models.](http://arxiv.org/abs/2308.11521) | 这篇论文研究了大型语言模型的越狱问题，并提出了一种自动越狱方法，介绍了语义防火墙的概念和三种技术实现方法。 |
| [^36] | [Unsupervised Prototype Adapter for Vision-Language Models.](http://arxiv.org/abs/2308.11507) | 本文介绍了一种无监督的视觉语言模型微调方法，称为无监督原型适配器（UP-Adapter）。该方法利用CLIP的文本-图像对齐能力，针对未标注的目标数据集自动选择自信度最高的样本，并生成类别原型，以实现无监督的微调。 |
| [^37] | [Can Authorship Representation Learning Capture Stylistic Features?.](http://arxiv.org/abs/2308.11490) | 本论文研究了作者身份表征学习能否捕捉文体特征的问题，并通过实验验证了这些表征能够有效地捕捉写作风格的特征。 |
| [^38] | [cantnlp@LT-EDI-2023: Homophobia/Transphobia Detection in Social Media Comments using Spatio-Temporally Retrained Language Models.](http://arxiv.org/abs/2308.10370) | 本文介绍了我们开发的多分类系统，使用基于BERT的语言模型在五种语言条件下检测社交媒体评论中的恐同和恐惧跨性别内容。我们通过时空相关的社交媒体语言数据对跨语言预训练语言模型进行了重新训练，取得了表现最好的七种标签分类系统。结果显示，时空训练可以提高分类性能，有效检测社交媒体评论中的恐同和恐惧跨性别内容。 |
| [^39] | [Benchmarking Neural Network Generalization for Grammar Induction.](http://arxiv.org/abs/2308.08253) | 提供了一种基于完全指定的形式语言的神经网络泛化度量方法，并在语法归纳任务中使用该基准评估了不同架构的网络。结果显示，使用最小描述长度目标（MDL）训练的网络泛化性能更好且使用更少的数据。 |
| [^40] | [ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks.](http://arxiv.org/abs/2308.01423) | ChatMOF是一种自主AI系统，用于预测和生成金属-有机骨架。通过利用大规模语言模型，它能够从文本输入中提取关键细节，并提供适当的回应。该系统通过组合代理、工具包和评估器的核心组件，实现了数据检索、性质预测和结构生成等多个任务。研究进一步展示了在材料科学中使用大型语言模型的优势和潜力。 |
| [^41] | [Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions.](http://arxiv.org/abs/2307.14107) | 本论文对ChatGPT的现有研究进行了分类学总结，并探索了其在各个应用领域中的潜力。此外，该研究还批判性分析了现有文献和ChatGPT在解决现实挑战方面的贡献。 |
| [^42] | [When Dialects Collide: How Socioeconomic Mixing Affects Language Use.](http://arxiv.org/abs/2307.10016) | 本研究使用地理标记的推特数据和计算方法，在英格兰和威尔士的七千个行政区域上进行了大规模映射，发现社会经济交叉影响了语言使用，混合不同社会经济阶层的人群频率偏离标准语法的程度越高，其收入关联越弱。 |
| [^43] | [ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification Task.](http://arxiv.org/abs/2307.06954) | ACTI在EVALITA 2023中的阴谋论辨识任务共有15支团队参与，通过使用大型语言模型判断阴谋内容和分类，得出了关于利用这些模型抵制在在线平台传播错误信息的结论。 |
| [^44] | [Domain-specific ChatBots for Science using Embeddings.](http://arxiv.org/abs/2306.10067) | 本论文演示如何利用现有方法和软件工具结合嵌入技术设计面向科学领域的聊天机器人，该机器人能够处理科学文献，提供特定领域的上下文信息，并在初步研究辅助知识方面为物理科学家提供帮助。 |
| [^45] | [SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts.](http://arxiv.org/abs/2306.02207) | 本文探索了一个名为SpeechGen的统一框架，通过提示调节，解锁了语音语言模型的生成能力，成功地实现了直接适应连续语音到离散标记的任务，使得语音生成成为可能。 |
| [^46] | [How to Estimate Model Transferability of Pre-Trained Speech Models?.](http://arxiv.org/abs/2306.01015) | 本文介绍了一个新的框架，可以高效地评估预训练语音模型在微调目标任务时的迁移性。该框架利用两个表示理论，通过生成候选模型的排名分数，可以在不进行实际微调的情况下计算迁移性分数，实验结果表明该框架与微调基础事实之间存在很高的相关性和低的p值，是一个节省资源、高效节省时间的微调方法。 |
| [^47] | [Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers.](http://arxiv.org/abs/2305.07011) | 本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。 |
| [^48] | [TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis.](http://arxiv.org/abs/2305.00976) | 本文介绍了一种名为TMR的方法，用于将文本转换为3D人体运动。它在先前的工作中取得了明显的优势，并通过引入对比性损失的方法来更好地建立跨模态潜在空间结构。结果表明，保持运动生成损失和对比性训练至关重要。 |
| [^49] | [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds.](http://arxiv.org/abs/2305.00969) | CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。 |
| [^50] | [PMC-LLaMA: Further Finetuning LLaMA on Medical Papers.](http://arxiv.org/abs/2304.14454) | 本文介绍了一个针对医学领域进一步微调的开源语言模型PMC-LLaMA，其通过增加医学知识提高了在生物医学领域的性能表现，有望在生物医学问答领域有更好的应用表现。 |
| [^51] | [Approximating Human Evaluation of Social Chatbots with Prompting.](http://arxiv.org/abs/2304.05253) | 该论文提出了一种利用提示来评估社交Chatbot的新方法，可以近似人类对Chatbot的主观评估，而不需要人类准备评估材料。 |
| [^52] | [ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance.](http://arxiv.org/abs/2303.16894) | 本文提出了ViewRefer，这是一个多视角的三维视觉定位框架，利用大规模语言模型和多视角原型，从文本和3D模态中获取视角知识并增强框架的表现。 |
| [^53] | [Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales.](http://arxiv.org/abs/2302.08961) | 通过插入格林童话和基于现有文本的启示工程，我们探讨了文本到图像生成和启示工程的可行性，提出了一个4阶段的启示工程过程，并讨论了生成模型在某些插图上的困难。 |
| [^54] | [Grammar-Based Grounded Lexicon Learning.](http://arxiv.org/abs/2202.08806) | 基于语法的基础词汇学习（G2L2）是一种从基础数据中学习语言含义表示的方法，通过将单词映射到语法类型和神经符号语义程序，利用基于语法的组合推导句子的含义，最终可以在基础输入上执行。 |
| [^55] | [A Simplified Variant of G\"odel's Ontological Argument.](http://arxiv.org/abs/2202.06264) | 本论文提出了G\"odel的本体论证的简化变体，该变体在基本模态逻辑K或KT中已经是有效的，避免了复杂的谓词，并且展示了人机交互在计算形而上学中的应用。 |
| [^56] | [Graph-Based Recommendation System Enhanced with Community Detection.](http://arxiv.org/abs/2201.03622) | 本文提出了一个基于图的推荐系统，利用数学和统计方法确定标签的相似性，包括词汇相似性和共现解决方案，并考虑了标签分配的时间，以提高推荐的准确性。 |

# 详细

[^1]: ChatGPT作为合成泛化的数据增强方法在开放意图检测中的案例研究

    ChatGPT as Data Augmentation for Compositional Generalization: A Case Study in Open Intent Detection. (arXiv:2308.13517v1 [cs.CL])

    [http://arxiv.org/abs/2308.13517](http://arxiv.org/abs/2308.13517)

    本文通过使用ChatGPT作为数据增强技术，提高了开放意图检测任务中的合成泛化能力，有效改善了模型性能，并在多个基准测试中超过了现有技术。

    

    开放意图检测是自然语言理解的关键方面，涉及对用户生成的文本中以前未见过的意图进行识别。虽然在这个领域取得了一些进展，但是在处理语言组成成分的新组合方面仍面临挑战，这对于合成泛化至关重要。本文提出了一个案例研究，探讨了在开放意图检测任务中将ChatGPT作为数据增强技术来提高合成泛化能力。我们首先讨论了现有基准在评估这个问题时的局限性，强调了构建数据集来解决开放意图检测任务中的合成泛化问题的需求。通过将ChatGPT生成的合成数据纳入训练过程中，我们证明了我们的方法可以有效提高模型性能。对多个基准进行了严格评估，结果显示我们的方法优于现有技术，并显著提高了开放意图检测的性能。

    Open intent detection, a crucial aspect of natural language understanding, involves the identification of previously unseen intents in user-generated text. Despite the progress made in this field, challenges persist in handling new combinations of language components, which is essential for compositional generalization. In this paper, we present a case study exploring the use of ChatGPT as a data augmentation technique to enhance compositional generalization in open intent detection tasks. We begin by discussing the limitations of existing benchmarks in evaluating this problem, highlighting the need for constructing datasets for addressing compositional generalization in open intent detection tasks. By incorporating synthetic data generated by ChatGPT into the training process, we demonstrate that our approach can effectively improve model performance. Rigorous evaluation of multiple benchmarks reveals that our method outperforms existing techniques and significantly enhances open inte
    
[^2]: 在段落级别上训练和元评估机器翻译评估指标

    Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level. (arXiv:2308.13506v1 [cs.CL])

    [http://arxiv.org/abs/2308.13506](http://arxiv.org/abs/2308.13506)

    本论文研究了在机器翻译中，如何在段落级别评估翻译质量。实验结果表明，使用句子级别的评估指标来评分整个段落与使用段落级别的指标一样有效。

    

    随着机器翻译研究的发展，将文本翻译到句子以上的级别，自动评估指标在评分更长的翻译上的有效性仍不清楚。在本研究中，我们首先提出了一种方法，通过使用现有的句子级别数据创建段落级别的数据，用于训练和元评估指标。然后，我们使用这些新数据集来评估现有的句子级别指标，并在段落级别上训练学习指标。有趣的是，我们的实验结果表明，使用句子级别的指标来评分整个段落与使用专门设计用于段落级别工作的指标一样有效。我们推测这个结果可能归因于参考评估任务的特性以及我们的数据集在捕捉段落级别翻译中出现的所有类型现象方面的局限性。

    As research on machine translation moves to translating text beyond the sentence level, it remains unclear how effective automatic evaluation metrics are at scoring longer translations. In this work, we first propose a method for creating paragraph-level data for training and meta-evaluating metrics from existing sentence-level data. Then, we use these new datasets to benchmark existing sentence-level metrics as well as train learned metrics at the paragraph level. Interestingly, our experimental results demonstrate that using sentence-level metrics to score entire paragraphs is equally as effective as using a metric designed to work at the paragraph level. We speculate this result can be attributed to properties of the task of reference-based evaluation as well as limitations of our datasets with respect to capturing all types of phenomena that occur in paragraph-level translations.
    
[^3]: Ngambay-French神经机器翻译（sba-Fr）论文

    Ngambay-French Neural Machine Translation (sba-Fr). (arXiv:2308.13497v1 [cs.CL])

    [http://arxiv.org/abs/2308.13497](http://arxiv.org/abs/2308.13497)

    该论文介绍了Ngambay-French神经机器翻译系统，并创造了第一个sba-Fr数据集，用于低资源语言的翻译研究。

    

    在非洲和全球范围内，越来越多的关注于开发神经机器翻译（NMT）系统，以克服语言障碍。对于低资源语言的NMT尤为引人注目，因为它涉及到有限标记数据的学习。然而，对于低资源语言来说，获取一个良好对齐的平行语料库可能有挑战性。查德地区全球少数语言的技术先进程度与NMT研究的不足之间存在明显差距。尚未尝试过在低资源查德语言上进行端到端NMT实验。此外，与一些非洲语言不同，自然语言处理领域的在线和结构化数据收集的数据匮乏。然而，通过指导性的数据收集方法，可以产生许多查德语言翻译对的双语数据，其中另一种语言是有大量数据的知名语言。在这个项目中，我们创建了第一个sba-Fr数据集，它是一个Ngambay到French的语料库。

    In Africa, and the world at large, there is an increasing focus on developing Neural Machine Translation (NMT) systems to overcome language barriers. NMT for Low-resource language is particularly compelling as it involves learning with limited labelled data. However, obtaining a well-aligned parallel corpus for low-resource languages can be challenging. The disparity between the technological advancement of a few global languages and the lack of research on NMT for local languages in Chad is striking. End-to-end NMT trials on low-resource Chad languages have not been attempted. Additionally, there is a dearth of online and well-structured data gathering for research in Natural Language Processing, unlike some African languages. However, a guided approach for data gathering can produce bitext data for many Chadian language translation pairs with well-known languages that have ample data. In this project, we created the first sba-Fr Dataset, which is a corpus of Ngambay-to-French transla
    
[^4]: 引导大型语言模型生成多样化的激励信息：与人工编写信息的比较

    Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages. (arXiv:2308.13479v1 [cs.CL])

    [http://arxiv.org/abs/2308.13479](http://arxiv.org/abs/2308.13479)

    本研究探讨了使用众包流程的提示对大型语言模型生成多样化的激励信息的影响。结果显示，通过使用众包流程的提示，GPT-4生成的信息比基准提示更加多样化。

    

    大型语言模型（LLM）的能力越来越强大，已经被广泛应用于生成创意内容。内容的质量受到所使用的提示的影响，更具体且包含示例的提示通常能产生更好的结果。在此基础上，可以看出使用为众包任务编写的指令（具体且包含示例以指导工作者）可能成为有效的LLM提示。为了探索这一点，我们使用之前的众包流程，为人们提供示例来帮助生成一个具有多样性的激励信息语料库。之后，我们使用相同的流程使用GPT-4生成信息，并比较了来自以下不同提示的信息的多样性：（1）众包写手，（2）使用该流程的GPT-4，以及（3和4）两个基准GPT-4提示。我们发现使用众包流程的LLM提示导致GPT-4生成比两个基准提示更多样化的信息。我们还讨论了信息的意义。

    Large language models (LLMs) are increasingly capable and prevalent, and can be used to produce creative content. The quality of content is influenced by the prompt used, with more specific prompts that incorporate examples generally producing better results. On from this, it could be seen that using instructions written for crowdsourcing tasks (that are specific and include examples to guide workers) could prove effective LLM prompts. To explore this, we used a previous crowdsourcing pipeline that gave examples to people to help them generate a collectively diverse corpus of motivational messages. We then used this same pipeline to generate messages using GPT-4, and compared the collective diversity of messages from: (1) crowd-writers, (2) GPT-4 using the pipeline, and (3 & 4) two baseline GPT-4 prompts. We found that the LLM prompts using the crowdsourcing pipeline caused GPT-4 to produce more diverse messages than the two baseline prompts. We also discuss implications from messages 
    
[^5]: 利用知识和强化学习提高语言模型的可靠性

    Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models. (arXiv:2308.13467v1 [cs.CL])

    [http://arxiv.org/abs/2308.13467](http://arxiv.org/abs/2308.13467)

    本研究通过利用知识和强化学习的方法，实现了一个知识引导的语言模型集成，通过整合外部知识来弥补现有数据集中的信息缺失，从而提高了语言模型的可靠性和准确性。

    

    自然语言处理(NLP)社区一直在使用众包技术，创建用于训练现代语言模型如BERT的基准数据集，例如General Language Understanding and Evaluation(GLUE)。GLUE任务使用互评计量方法（如Cohens Kappa）来衡量可靠性分数。然而，语言模型的可靠性方面常常被忽视。为解决这个问题，我们探索了一种知识引导的语言模型集成方法，利用强化学习将ConceptNet和维基百科的知识作为知识图嵌入进行整合。这种方法模仿了人类注释者使用外部知识来弥补数据集中的信息缺失。通过在九个GLUE数据集上的研究表明，语言模型集成可以增强可靠性和准确性得分，超过现有最先进方法。

    The Natural Language Processing(NLP) community has been using crowd sourcing techniques to create benchmark datasets such as General Language Understanding and Evaluation(GLUE) for training modern Language Models such as BERT. GLUE tasks measure the reliability scores using inter annotator metrics i.e. Cohens Kappa. However, the reliability aspect of LMs has often been overlooked. To counter this problem, we explore a knowledge-guided LM ensembling approach that leverages reinforcement learning to integrate knowledge from ConceptNet and Wikipedia as knowledge graph embeddings. This approach mimics human annotators resorting to external knowledge to compensate for information deficits in the datasets. Across nine GLUE datasets, our research shows that ensembling strengthens reliability and accuracy scores, outperforming state of the art.
    
[^6]: ARTIST: 简化文本的人工智能技术

    ARTIST: ARTificial Intelligence for Simplified Text. (arXiv:2308.13458v1 [cs.CL])

    [http://arxiv.org/abs/2308.13458](http://arxiv.org/abs/2308.13458)

    本研究针对低资源语言的文本简化，设计和实现了一个可配置的文本简化流程，通过生成式AI技术实现了文本的简化，以满足公民获取公共信息和知识的需要。

    

    对于许多公民来说，复杂的文本是获取公共信息和知识的主要障碍。而文本简化是一项重要的自然语言处理任务，旨在减少文本的语言复杂性，同时保留原始含义。最近，生成式人工智能（AI）的进展使得自动文本简化成为可能，无论是在词汇还是句法层面上。然而，由于应用通常集中在英语上，对于荷兰语等低资源语言上应用生成式AI技术的有效性了解甚少。出于这个原因，我们进行了实证研究，以了解将生成式技术应用于文本简化的益处和局限，并提供以下结果：1）一个可配置的文本简化流程的设计和实施，将最先进的生成式文本简化模型、领域和读者适应性以及可视化模块结合在一起；2）ins

    Complex text is a major barrier for many citizens when accessing public information and knowledge. While often done manually, Text Simplification is a key Natural Language Processing task that aims for reducing the linguistic complexity of a text while preserving the original meaning. Recent advances in Generative Artificial Intelligence (AI) have enabled automatic text simplification both on the lexical and syntactical levels. However, as applications often focus on English, little is understood about the effectiveness of Generative AI techniques on low-resource languages such as Dutch. For this reason, we carry out empirical studies to understand the benefits and limitations of applying generative technologies for text simplification and provide the following outcomes: 1) the design and implementation for a configurable text simplification pipeline that orchestrates state-of-the-art generative text simplification models, domain and reader adaptation, and visualisation modules; 2) ins
    
[^7]: 对齐的毒性

    The Poison of Alignment. (arXiv:2308.13449v1 [cs.CL])

    [http://arxiv.org/abs/2308.13449](http://arxiv.org/abs/2308.13449)

    对齐行为会污染指令数据集，降低微调模型的性能。

    

    从内容安全问题的角度来看，对齐已经显示出限制大型语言模型（LLM）生成有害内容的能力。这种有意的方法是为了不让模型对某些用户输入作出响应，在许多现代开源指令调整数据集（如OpenAssistant或Guanaco）中都存在。我们引入了一个新颖的观点，指出对齐对指令调整模型的性能产生了影响。具体而言，我们注意到对齐的作用就像是对指令数据集进行了污染。通过实验证明，对齐的答案显著地降低了最终微调模型在各种推理基准测试（如Big Bench（BBH）、大规模多任务语言理解（MMLU）、人工评估和段落离散推理（DROP））上的性能，相比没有对齐的微调模型下降了4-33%。

    From the perspective of content safety issues, alignment has shown to limit large language models' (LLMs) harmful content generation. This intentional method of reinforcing models to not respond to certain user inputs seem to be present in many modern open-source instruction tuning datasets such as OpenAssistant or Guanaco. We introduce a novel insight to an instruction-tuned model's performance affected by the presence of alignment in supervised fine-tuning dataset. To be specific, we noticed that alignment acts as if it is poisoning the instruction dataset. Experimentally, we demonstrate that aligned answers significantly worsen the performance of the resulting fine-tuned model's on various reasoning benchmarks such as Big Bench (BBH), Massive Multitask Language Understanding (MMLU), Human Eval, and Discrete Reasoning Over Paragraphs (DROP), performing worse than the counterpart tuned without alignment by 4-33%.
    
[^8]: EntropyRank: 通过基于语言模型的文本压缩的副信息优化来进行无监督关键词提取

    EntropyRank: Unsupervised Keyphrase Extraction via Side-Information Optimization for Language Model-based Text Compression. (arXiv:2308.13399v1 [cs.CL])

    [http://arxiv.org/abs/2308.13399](http://arxiv.org/abs/2308.13399)

    该论文提出了一种无监督的关键词提取方法，通过利用预训练语言模型和信息论方法，在文本中提取具有最高条件熵的短语作为关键词。实验证明，该方法在关键词提取任务上取得了与常用方法相当的结果。

    

    我们提出了一种无监督的方法，基于预训练的语言模型（LM）和Shannon的信息最大化，从文本中提取关键词和关键词短语。具体来说，我们的方法提取在LM下具有最高条件熵的短语。得到的关键词短语集合解决了一个相关的信息论问题：如果作为副信息提供，它会导致使用LM和熵编码器对文本进行压缩时的预期最小二进制码长度。另外，得到的集合是通过因果LM对在给定条件下最小化文本熵的短语集合的近似。在实证上，该方法在各种关键词提取基准挑战中提供了与最常用方法可比较的结果。

    We propose an unsupervised method to extract keywords and keyphrases from texts based on a pre-trained language model (LM) and Shannon's information maximization. Specifically, our method extracts phrases having the highest conditional entropy under the LM. The resulting set of keyphrases turns out to solve a relevant information-theoretic problem: if provided as side information, it leads to the expected minimal binary code length in compressing the text using the LM and an entropy encoder. Alternately, the resulting set is an approximation via a causal LM to the set of phrases that minimize the entropy of the text when conditioned upon it. Empirically, the method provides results comparable to the most commonly used methods in various keyphrase extraction benchmark challenges.
    
[^9]: Do-Not-Answer: 用于评估LLMs中安全机制的数据集

    Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs. (arXiv:2308.13387v1 [cs.CL])

    [http://arxiv.org/abs/2308.13387](http://arxiv.org/abs/2308.13387)

    这项工作收集了第一个用于评估LLMs中安全机制的开源数据集，并通过训练分类器实现了与GPT-4在自动安全评估上相媲美的结果。

    

    随着大型语言模型（LLMs）的快速发展，出现了新的难以预测的有害功能。这要求开发者能够通过评估LLMs中的“危险能力”来识别风险，以负责任地部署LLMs。在这项工作中，我们收集了第一个用于评估LLMs中安全机制的开源数据集，并以较低成本部署更安全的开源LLMs。我们的数据集由负责任的语言模型不应遵循的指令精心策划和过滤而成。我们对六种流行的LLMs对这些指令的回应进行了注释和评估。基于我们的标注，我们继续训练了几个类似BERT的分类器，并发现这些小分类器在自动安全评估上可以达到与GPT-4相当的结果。警告：本文包含可能具有冒犯性、有害性或偏见性的示例数据。

    With the rapid evolution of large language models (LLMs), new and hard-to-predict harmful capabilities are emerging. This requires developers to be able to identify risks through the evaluation of "dangerous capabilities" in order to responsibly deploy LLMs. In this work, we collect the first open-source dataset to evaluate safeguards in LLMs, and deploy safer open-source LLMs at a low cost. Our dataset is curated and filtered to consist only of instructions that responsible language models should not follow. We annotate and assess the responses of six popular LLMs to these instructions. Based on our annotation, we proceed to train several BERT-like classifiers, and find that these small classifiers can achieve results that are comparable with GPT-4 on automatic safety evaluation. Warning: this paper contains example data that may be offensive, harmful, or biased.
    
[^10]: 使用排列检验评估关键性

    Assessing Keyness using Permutation Tests. (arXiv:2308.13383v1 [cs.CL])

    [http://arxiv.org/abs/2308.13383](http://arxiv.org/abs/2308.13383)

    这项研究提出了一种使用排列检验评估语料库关键性的方法，解决了传统方法中对词分布不均导致的假阳性问题。

    

    我们提出了一种基于重新采样的方法来评估语料库语言学中的关键性，这个方法基于Gries（2006，2022）的建议。传统的基于假设检验（如似然比）的方法将语料库建模为独立同分布的标记样本。这个模型没有考虑到词在语料库中的出现分布不均的情况。当一个词的出现集中在少数文档中时，LLR和类似的分数的大值实际上比标记对标记采样模型预期的更有可能，从而导致假阳性。我们将标记对标记采样模型替换为更接近实际语料库组装方式的文档样本模型。然后，我们使用排列方法来近似给定关键性分数在等频假设下的分布，并获得用于评估显著性的p值。我们不需要任何关于数据分布的假设。

    We propose a resampling-based approach for assessing keyness in corpus linguistics based on suggestions by Gries (2006, 2022). Traditional approaches based on hypothesis tests (e.g. Likelihood Ratio) model the copora as independent identically distributed samples of tokens. This model does not account for the often observed uneven distribution of occurences of a word across a corpus. When occurences of a word are concentrated in few documents, large values of LLR and similar scores are in fact much more likely than accounted for by the token-by-token sampling model, leading to false positives.  We replace the token-by-token sampling model by a model where corpora are samples of documents rather than tokens, which is much closer to the way corpora are actually assembled. We then use a permutation approach to approximate the distribution of a given keyness score under the null hypothesis of equal frequencies and obtain p-values for assessing significance. We do not need any assumption on
    
[^11]: 关于语言选择对训练和评估编程语言模型的影响

    On the Impact of Language Selection for Training and Evaluating Programming Language Models. (arXiv:2308.13354v1 [cs.SE])

    [http://arxiv.org/abs/2308.13354](http://arxiv.org/abs/2308.13354)

    这项研究根据使用CodeBERT模型分析编程语言的表示，发现编程语言之间在标记表示方面存在差异，建议使用这种相似度度量方法来选择跨多种语言的模型。

    

    基于Transformer的语言模型的最新进展显示出在增强这些模型的多语言能力方面具有显著潜力。在自然语言任务中取得的显著进展不仅适用于编程语言领域，而且还扩展到编程语言领域。尽管这些模型具备从多种语言中学习的能力，但评估通常只关注同一种语言的特定组合。在本研究中，我们使用基于CodeBERT模型的编程语言表示分析来评估编程语言的相似性。我们的实验揭示了像C++、Python和Java这样的语言中的标记表示之间存在相近性，而像Mathematica和R这样的语言中的相同标记显示出显著的不相似性。我们的研究结果表明，当处理多种语言时，这种现象可能导致性能挑战。因此，我们建议使用我们的相似度度量来选择一个可以平衡多种语言的模型。

    The recent advancements in Transformer-based Language Models have demonstrated significant potential in enhancing the multilingual capabilities of these models. The remarkable progress made in this domain not only applies to natural language tasks but also extends to the domain of programming languages. Despite the ability of these models to learn from multiple languages, evaluations typically focus on particular combinations of the same languages. In this study, we evaluate the similarity of programming languages by analyzing their representations using a CodeBERT-based model. Our experiments reveal that token representation in languages such as C++, Python, and Java exhibit proximity to one another, whereas the same tokens in languages such as Mathematica and R display significant dissimilarity. Our findings suggest that this phenomenon can potentially result in performance challenges when dealing with diverse languages. Thus, we recommend using our similarity measure to select a div
    
[^12]: 改进端到端模型适应性的解耦结构

    Decoupled Structure for Improved Adaptability of End-to-End Models. (arXiv:2308.13345v1 [eess.AS])

    [http://arxiv.org/abs/2308.13345](http://arxiv.org/abs/2308.13345)

    本论文提出了一种解耦结构，通过解耦端到端ASR模型的声学和语言部分，来解决领域转变带来的问题，实现了灵活的领域自适应。

    

    尽管端到端可训练的自动语音识别（ASR）通过联合学习声学和语言信息取得了巨大成功，但仍然受到领域转变的影响，限制了潜在的应用。端到端ASR模型隐式学习了内部语言模型（LM），该模型表征了源领域的训练分布，而端到端训练的性质使得内部LM很难适应只有文本数据的目标领域。为了解决这个问题，本文提出了基于注意力编码-解码器（Decoupled-AED）和神经传输器（Decoupled-Transducer）模型的解耦结构，可以在离线和在线场景中实现灵活的领域自适应，同时保持稳健的领域内性能。为此，端到端模型解码器（或预测网络）的声学和语言部分进行解耦，使得语言组成部分（即内部LM）可以替代。当遇到领域转变时，

    Although end-to-end (E2E) trainable automatic speech recognition (ASR) has shown great success by jointly learning acoustic and linguistic information, it still suffers from the effect of domain shifts, thus limiting potential applications. The E2E ASR model implicitly learns an internal language model (LM) which characterises the training distribution of the source domain, and the E2E trainable nature makes the internal LM difficult to adapt to the target domain with text-only data To solve this problem, this paper proposes decoupled structures for attention-based encoder-decoder (Decoupled-AED) and neural transducer (Decoupled-Transducer) models, which can achieve flexible domain adaptation in both offline and online scenarios while maintaining robust intra-domain performance. To this end, the acoustic and linguistic parts of the E2E model decoder (or prediction network) are decoupled, making the linguistic component (i.e. internal LM) replaceable. When encountering a domain shift, t
    
[^13]: 改造生成预训练变换器的输出: PGI框架对注意力动态的影响

    Transforming the Output of Generative Pre-trained Transformer: The Influence of the PGI Framework on Attention Dynamics. (arXiv:2308.13317v1 [cs.AI])

    [http://arxiv.org/abs/2308.13317](http://arxiv.org/abs/2308.13317)

    本文介绍了一种名为PGI的新方法，在实际商业问题中应用于GPT模型。该方法利用GPT模型的能力来理解复杂的语言结构，并生成上下文相关的回应。实验证实了PGI策略的有效性，并帮助解决了人类智能低度利用的问题。

    

    本文提出了一种名为Persona-Grouping-Intelligence (PGI)的新方法，旨在解决GPT模型在实际商业问题中的应用所带来的挑战。PGI利用GPT模型的内在能力来理解复杂的语言结构，并生成与上下文相关的回应。实验在一个商业场景中进行，该场景存在人类智能被低效的商业流程低度利用的问题。该方法的主要目标是利用GPT模型来减轻人类在广泛、单调和重复的任务中的工作负荷，将重点转向决策活动。该实验生成的4,000个回应的验证准确率为93.81%，突出了PGI策略的有效性。这种范式转变有效地解决了人类智能低度利用的问题，使企业环境与决策活动相一致。

    This paper presents a novel approach named Persona-Grouping-Intelligence (PGI), which has been crafted to tackle the challenges posed by GPT models when applied to real-world business issues. PGI leverages the inherent capabilities of the GPT model to comprehend intricate language structures and generate responses that are contextually relevant. The experiment occurred in a business scenario where human intelligence was being underutilized due to less optimized business processes. The primary objective of this approach is to leverage GPT models to reduce the workload on humans in tasks that are extensive, monotonous, and repetitive. Instead, the focus is redirected toward decision-making activities. Remarkably, the experiment yielded an accuracy rate of 93.81% in validating 4,000 responses generated by the model, underscoring the effectiveness of the PGI strategies. Effectively addressing the issue of underutilized human intelligence, this paradigm shift aligns business environments wi
    
[^14]: 建构语法与语言模型

    Construction Grammar and Language Models. (arXiv:2308.13315v1 [cs.CL])

    [http://arxiv.org/abs/2308.13315](http://arxiv.org/abs/2308.13315)

    最新的深度学习和自然语言处理进展为计算方法和建构语法研究之间的协同关系提供了机会，本章提供了三种不同的计算方法与建构语法相互作用的途径，并重点关注语言模型。

    

    深度学习和自然语言处理的最新进展已经产生了强大的模型，这些模型主要在一个填空式任务上进行训练，并显示出具有丰富语言信息的一些证据，包括一些构式知识。这一突破性的发现为计算方法和建构语法研究之间的协同关系提供了令人兴奋的机会。在本章中，我们探讨了三种不同的计算方法和建构语法之间的相互作用方式：（一）文本分析的计算方法、（二）计算建构语法，以及（三）深度学习模型，特别关注语言模型。我们在介绍计算方法的基础上接触第一种和第二种方法，然后提供一种易于理解但全面的深度学习模型概述，也解决了建构语法学家可能存在的保留意见。此外，我们还深入探讨了...

    Recent progress in deep learning and natural language processing has given rise to powerful models that are primarily trained on a cloze-like task and show some evidence of having access to substantial linguistic information, including some constructional knowledge. This groundbreaking discovery presents an exciting opportunity for a synergistic relationship between computational methods and Construction Grammar research. In this chapter, we explore three distinct approaches to the interplay between computational methods and Construction Grammar: (i) computational methods for text analysis, (ii) computational Construction Grammar, and (iii) deep learning models, with a particular focus on language models. We touch upon the first two approaches as a contextual foundation for the use of computational methods before providing an accessible, yet comprehensive overview of deep learning models, which also addresses reservations construction grammarians may have. Additionally, we delve into e
    
[^15]: 基于知识驱动的CoT：探索LLMs中对知识密集型问答进行忠实推理

    Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering. (arXiv:2308.13259v1 [cs.CL])

    [http://arxiv.org/abs/2308.13259](http://arxiv.org/abs/2308.13259)

    本文提出了一个名为知识驱动的思维链（KD-CoT）的框架，用于验证和修改LLMs中的推理过程，通过与外部知识的交互来解决幻觉和错误传播的问题。

    

    大型语言模型（LLMs）配备了思维链（CoT），在各种下游任务中展现出了令人印象深刻的推理能力。但是，由于幻觉和无法访问外部知识，LLMs在对知识密集型任务（如知识库问答）进行推理时常常会产生不正确或不忠实的中间推理步骤。为了缓解这个问题，我们提出了一个名为知识驱动的思维链（KD-CoT）的框架，通过与外部知识的交互来验证和修改CoT中的推理过程，从而克服幻觉和错误传播。具体地，我们将LLMs的CoT推理过程规范化为结构化的多轮问答格式。在每一轮中，LLMs与一个问答系统进行交互，该系统检索外部知识并基于检索到的准确答案产生忠实的推理过程。我们开发的KBQA CoT集合促进了LLMs的结构化CoT推理，它作为上下文学习的一部分。

    Equipped with Chain-of-Thought (CoT), Large language models (LLMs) have shown impressive reasoning ability in various downstream tasks. Even so, suffering from hallucinations and the inability to access external knowledge, LLMs often come with incorrect or unfaithful intermediate reasoning steps, especially in the context of answering knowledge-intensive tasks such as KBQA. To alleviate this issue, we propose a framework called Knowledge-Driven Chain-of-Thought (KD-CoT) to verify and modify reasoning traces in CoT via interaction with external knowledge, and thus overcome the hallucinations and error propagation. Concretely, we formulate the CoT rationale process of LLMs into a structured multi-round QA format. In each round, LLMs interact with a QA system that retrieves external knowledge and produce faithful reasoning traces based on retrieved precise answers. The structured CoT reasoning of LLMs is facilitated by our developed KBQA CoT collection, which serves as in-context learning
    
[^16]: LLM2KB: 使用经过指令调整的上下文感知大语言模型构建知识库

    LLM2KB: Constructing Knowledge Bases using instruction tuned context aware Large Language Models. (arXiv:2308.13207v1 [cs.CL])

    [http://arxiv.org/abs/2308.13207](http://arxiv.org/abs/2308.13207)

    本文提出了LLM2KB，一种使用大语言模型构建知识库的系统，通过对Llama 2架构和维基百科数据集进行参数高效的指令调整，利用上下文感知和低秩适应技术，实现了有效构建知识库的目标。

    

    大语言模型（LLM）的出现彻底改变了自然语言处理领域，使得在各种应用中取得了重大进展。其中一个关键领域是利用这些强大的模型构建知识库（KB）。知识库作为结构化信息的存储库，能够促进信息检索和推理任务。我们的论文提出了LLM2KB，这是一个使用大语言模型构建知识库的系统，重点关注于Llama 2架构和维基百科数据集。我们通过训练小的注入模型来进行参数高效的指令调整，这些注入模型仅具有基础模型参数的0.05%，使用了低秩适应（LoRA）技术。这些注入模型通过使用密集通道检索（DPR）算法提取的主体实体的维基百科页面上下文相对应的提示进行训练，以回答相关的客体实体。

    The advent of Large Language Models (LLM) has revolutionized the field of natural language processing, enabling significant progress in various applications. One key area of interest is the construction of Knowledge Bases (KB) using these powerful models. Knowledge bases serve as repositories of structured information, facilitating information retrieval and inference tasks. Our paper proposes LLM2KB, a system for constructing knowledge bases using large language models, with a focus on the Llama 2 architecture and the Wikipedia dataset. We perform parameter efficient instruction tuning for Llama-2-13b-chat and StableBeluga-13B by training small injection models that have only 0.05 % of the parameters of the base models using the Low Rank Adaptation (LoRA) technique. These injection models have been trained with prompts that are engineered to utilize Wikipedia page contexts of subject entities fetched using a Dense Passage Retrieval (DPR) algorithm, to answer relevant object entities fo
    
[^17]: 深入理解多语言预训练语言模型中的知识神经元：语言无关知识神经元和退化知识神经元的发现

    Journey to the Center of the Knowledge Neurons: Discoveries of Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons. (arXiv:2308.13198v1 [cs.CL])

    [http://arxiv.org/abs/2308.13198](http://arxiv.org/abs/2308.13198)

    本文研究了多语言预训练语言模型中事实知识的存储方式，并引入了一种新的方法，能够更准确地定位知识神经元。通过实验证明了语言无关知识神经元的存在，以及发现了一种新型退化知识神经元。

    

    预训练语言模型（PLMs）包含大量的事实知识，但其存储在参数中的方式尚不清楚。本文深入研究了多语言PLMs中事实知识的存储方式，并引入了一种基于体系结构的多语言整合梯度方法，相比现有方法更准确地定位知识神经元，并在不同体系结构和语言之间更具普遍性。此外，我们对知识神经元进行了深入探索，得出了以下两项重要的发现：（1）发现了语言无关知识神经元，其以超越语言的方式存储事实知识。我们设计了跨语言知识编辑实验，证明了PLMs可以基于语言无关的神经元完成此任务；（2）发现了退化知识神经元，这是一种新型神经元，表明不同的知识神经元可以在数据特征萎缩的情况下展示。

    Pre-trained language models (PLMs) contain vast amounts of factual knowledge, but how the knowledge is stored in the parameters remains unclear. This paper delves into the complex task of understanding how factual knowledge is stored in multilingual PLMs, and introduces the Architecture-adapted Multilingual Integrated Gradients method, which successfully localizes knowledge neurons more precisely compared to current methods, and is more universal across various architectures and languages. Moreover, we conduct an in-depth exploration of knowledge neurons, leading to the following two important discoveries: (1) The discovery of Language-Independent Knowledge Neurons, which store factual knowledge in a form that transcends language. We design cross-lingual knowledge editing experiments, demonstrating that the PLMs can accomplish this task based on language-independent neurons; (2) The discovery of Degenerate Knowledge Neurons, a novel type of neuron showing that different knowledge neuro
    
[^18]: 人机交互中自然语言量词的形式化

    Formalising Natural Language Quantifiers for Human-Robot Interactions. (arXiv:2308.13192v1 [cs.AI])

    [http://arxiv.org/abs/2308.13192](http://arxiv.org/abs/2308.13192)

    本文提出了一种在人机交互中形式化自然语言量词的方法，并设计了一个端到端系统以实现自然语言输入到逻辑表示的转换和评估，从而实现对机器人的控制。

    

    我们提出了一种在人机交互背景下形式化自然语言量词的方法。该解决方案基于一阶逻辑并扩展了表示变量基数的能力，类似于广义量词。为了展示这种方法，我们设计了一个端到端的系统，能够接收自然语言输入，将其转换为形式化的逻辑表示，评估它，并返回结果或向模拟机器人发送命令。

    We present a method for formalising quantifiers in natural language in the context of human-robot interactions. The solution is based on first-order logic extended with capabilities to represent the cardinality of variables, operating similarly to generalised quantifiers. To demonstrate the method, we designed an end-to-end system able to receive input as natural language, convert it into a formal logical representation, evaluate it, and return a result or send a command to a simulated robot.
    
[^19]: Chunk, Align, Select: 一种简单的用于transformer的长序列处理方法

    Chunk, Align, Select: A Simple Long-sequence Processing Method for Transformers. (arXiv:2308.13191v1 [cs.CL])

    [http://arxiv.org/abs/2308.13191](http://arxiv.org/abs/2308.13191)

    这种方法提出了一种简单的框架，使得transformer能够处理更长的序列，同时计算和内存成本与输入序列长度线性增长。

    

    尽管在自然语言处理中占据主导地位，基于transformer的模型仍然面临着长序列处理的挑战，因为transformer中自注意操作的计算成本随着输入序列长度的增加呈二次增长。为了减轻长序列处理的复杂性，我们提出了一个简单的框架，使得现有的预训练transformer能够处理更长的序列，同时计算和内存成本与输入序列长度线性增长。具体来说，我们的方法将每个长序列输入划分为一批chunk，然后在编码过程中对chunk之间的信息进行对齐，最后从编码器中选择最具代表性的隐藏状态进行解码。为了提取chunk之间的语义信息，我们在每个编码transformer块中对chunk之间的起始和结束token进行对齐。为了学习一个有效的隐藏状态选择策略，我们设计了一个双重更新机制。

    Although dominant in natural language processing, transformer-based models remain challenged by the task of long-sequence processing, because the computational cost of self-attention operations in transformers swells quadratically with the input sequence length. To alleviate the complexity of long-sequence processing, we propose a simple framework to enable the offthe-shelf pre-trained transformers to process much longer sequences, while the computation and memory costs remain growing linearly with the input sequence lengths. More specifically, our method divides each long-sequence input into a batch of chunks, then aligns the interchunk information during the encoding steps, and finally selects the most representative hidden states from the encoder for the decoding process. To extract inter-chunk semantic information, we align the start and end token embeddings among chunks in each encoding transformer block. To learn an effective hidden selection policy, we design a dual updating sch
    
[^20]: 如何评估检测的泛化能力？一种用于全面开放词汇检测的基准测试方法

    How to Evaluate the Generalization of Detection? A Benchmark for Comprehensive Open-Vocabulary Detection. (arXiv:2308.13177v1 [cs.CV])

    [http://arxiv.org/abs/2308.13177](http://arxiv.org/abs/2308.13177)

    提出了一个名为OVDEval的新的基准测试方法，用于全面开放词汇检测。该方法包括9个子任务，并引入了常识知识、属性理解、位置理解、对象关系理解等方面的评估。数据集被精心创建以提供具有挑战性的负例，考验模型对视觉和语言输入的真正理解。此外，该方法发现了平均精确度（AP）指标在这些细粒度标签数据集上的问题，并提出了一种新指标。

    

    计算机视觉中的目标检测在近年取得了显著的进展，从基于封闭集标签到基于大规模视觉语言预训练的开放词汇检测（OVD）。然而，当前的评估方法和数据集仅限于测试对象类型和引用表达的泛化能力，无法提供OVD模型能力的系统、细粒度和准确的基准。在本文中，我们提出了一个名为OVDEval的新基准测试方法，包括9个子任务，并引入了常识知识、属性理解、位置理解、对象关系理解等方面的评估。数据集被精心创建以提供具有挑战性的负例，考验模型对视觉和语言输入的真正理解。此外，我们还发现了在这些细粒度标签数据集上对模型进行基准测试时普遍使用的平均精确度（AP）指标存在的问题，并提出了一种名为非极大值抑制的新指标。

    Object detection (OD) in computer vision has made significant progress in recent years, transitioning from closed-set labels to open-vocabulary detection (OVD) based on large-scale vision-language pre-training (VLP). However, current evaluation methods and datasets are limited to testing generalization over object types and referral expressions, which do not provide a systematic, fine-grained, and accurate benchmark of OVD models' abilities. In this paper, we propose a new benchmark named OVDEval, which includes 9 sub-tasks and introduces evaluations on commonsense knowledge, attribute understanding, position understanding, object relation comprehension, and more. The dataset is meticulously created to provide hard negatives that challenge models' true understanding of visual and linguistic input. Additionally, we identify a problem with the popular Average Precision (AP) metric when benchmarking models on these fine-grained label datasets and propose a new metric called Non-Maximum Su
    
[^21]: DISGO: 自动化端到端评估场景文本OCR

    DISGO: Automatic End-to-End Evaluation for Scene Text OCR. (arXiv:2308.13173v1 [cs.CV])

    [http://arxiv.org/abs/2308.13173](http://arxiv.org/abs/2308.13173)

    本文提出了一种自动化评估场景文本OCR的方法，采用统一的词错误率作为衡量标准，考虑了删除、插入、替换和分组/排序错误，同时使用超级块的概念计算BLEU分数。

    

    本文讨论了在自然场景中进行光学字符识别（OCR）的挑战，相比于文档上的OCR来说更困难，因为其中包含了各种各样的图像背景。我们提出统一使用词错误率（WER）作为评估场景文本OCR性能的一种新的衡量标准，既可以用于端到端（e2e）性能，也可以用于单个系统组件的性能。特别是对于端到端的度量，我们称其为DISGO WER，因为它考虑了删除、插入、替换和分组/排序错误。最后，我们提出利用超级块的概念来自动计算端到端OCR机器翻译的BLEU分数。使用小规模的SCUT公共测试数据集来演示模块化OCR系统的WER性能。

    This paper discusses the challenges of optical character recognition (OCR) on natural scenes, which is harder than OCR on documents due to the wild content and various image backgrounds. We propose to uniformly use word error rates (WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e) performance and individual system component performances. Particularly for the e2e metric, we name it DISGO WER as it considers Deletion, Insertion, Substitution, and Grouping/Ordering errors. Finally we propose to utilize the concept of super blocks to automatically compute BLEU scores for e2e OCR machine translation. The small SCUT public test set is used to demonstrate WER performance by a modularized OCR system.
    
[^22]: 在分类中测量虚假相关性：译文中的“聪明的汉斯”

    Measuring Spurious Correlation in Classification: 'Clever Hans' in Translationese. (arXiv:2308.13170v1 [cs.CL])

    [http://arxiv.org/abs/2308.13170](http://arxiv.org/abs/2308.13170)

    这项研究揭示了高性能神经翻译分类器中存在的“聪明的汉斯”行为，它利用虚假相关性而非真实的翻译信号来提高分类性能。研究重点关注基于主题的虚假相关性，探讨了在没有关于虚假主题信息的情况下以及有关虚假主题信息的情况下分类器性能的影响。

    

    最近的研究显示高性能神经翻译分类器中存在“聪明的汉斯”行为，即基于BERT的分类器利用数据与目标分类标签之间的虚假相关性，特别是主题信息，而不是真实的翻译信号。翻译信号微妙（尤其是对于专业翻译），并且与数据中的许多其他信号竞争，如流派、风格、作者和尤其是主题。这引发了一个总体问题，分类器的性能到底有多少是由于数据中的虚假相关性，而不是分类器实际针对的信号，尤其是对于微妙的目标信号和具有挑战性的（低资源）数据环境。我们重点研究基于主题的虚假相关性，并从两个方向探讨这个问题：（i）在没有关于虚假主题信息及其在数据中分布的知识的情况下，（ii）在有关虚假主题信息及其在数据中分布的一些指示的情况下。

    Recent work has shown evidence of 'Clever Hans' behavior in high-performance neural translationese classifiers, where BERT-based classifiers capitalize on spurious correlations, in particular topic information, between data and target classification labels, rather than genuine translationese signals. Translationese signals are subtle (especially for professional translation) and compete with many other signals in the data such as genre, style, author, and, in particular, topic. This raises the general question of how much of the performance of a classifier is really due to spurious correlations in the data versus the signals actually targeted for by the classifier, especially for subtle target signals and in challenging (low resource) data settings. We focus on topic-based spurious correlation and approach the question from two directions: (i) where we have no knowledge about spurious topic information and its distribution in the data, (ii) where we have some indication about the natur
    
[^23]: SciEval: 用于科学研究的多级大型语言模型评估基准

    SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research. (arXiv:2308.13149v1 [cs.CL])

    [http://arxiv.org/abs/2308.13149](http://arxiv.org/abs/2308.13149)

    SciEval是一个综合且多学科的评估基准，用于评估大型语言模型在科学研究中的能力。它基于布鲁姆的分类法，包括客观和主观问题，并设计了一个防止数据泄漏的“动态”子集。实验结果表明，尽管GPT-4在某些方面取得了较高的得分，但仍存在挑战。

    

    最近，使用大型语言模型（LLMs）进行科学研究引起了越来越多的关注。已经提出了许多基准来评估LLMs在科学研究中的能力。然而，目前的基准主要基于预先收集的客观问题。这种设计存在数据泄漏问题，并且缺乏对主观问答能力的评估。在本文中，我们提出了SciEval，这是一个综合、多学科的评估基准，以解决这些问题。基于布鲁姆的分类法，SciEval涵盖了四个维度来系统评估科学研究能力。特别地，我们设计了一个基于科学原理的“动态”子集，以防止评估出现潜在的数据泄漏。SciEval包含了客观和主观问题。这些特点使SciEval成为评估LLMs科学研究能力的更有效的基准。对最先进的LLMs进行了全面实验，结果显示，尽管GPT-4取得了较高的得分，但在某些方面仍存在挑战。

    Recently, there has been growing interest in using Large Language Models (LLMs) for scientific research. Numerous benchmarks have been proposed to evaluate the ability of LLMs for scientific research. However, current benchmarks are mostly based on pre-collected objective questions. This design suffers from data leakage problem and lacks the evaluation of subjective Q/A ability. In this paper, we propose SciEval, a comprehensive and multi-disciplinary evaluation benchmark to address these issues. Based on Bloom's taxonomy, SciEval covers four dimensions to systematically evaluate scientific research ability. In particular, we design a "dynamic" subset based on scientific principles to prevent evaluation from potential data leakage. Both objective and subjective questions are included in SciEval. These characteristics make SciEval a more effective benchmark for scientific research ability evaluation of LLMs. Comprehensive experiments on most advanced LLMs show that, although GPT-4 achie
    
[^24]: MatchXML: 高效的文本-标签匹配框架，用于极端多标签文本分类

    MatchXML: An Efficient Text-label Matching Framework for Extreme Multi-label Text Classification. (arXiv:2308.13139v1 [cs.CL])

    [http://arxiv.org/abs/2308.13139](http://arxiv.org/abs/2308.13139)

    MatchXML是一种高效的文本-标签匹配框架，用于极端多标签文本分类。它通过label2vec方法生成语义密集的标签嵌入，并利用这些嵌入构建层次化标签树。通过微调预训练的Transformer模型，MatchXML将多标签文本分类问题转化为文本-标签匹配问题，并提取出密集的文本表示和静态的句子嵌入。

    

    极端多标签文本分类（XMC）是指训练一个分类器，从一个非常大规模的标签集中（例如数百万个标签）为文本样本分配相关标签。我们提出了MatchXML，一种用于XMC的高效文本-标签匹配框架。我们观察到，由稀疏的词频-逆文档频率（TF-IDF）特征生成的标签嵌入存在一些限制。因此，我们提出了label2vec，通过Skip-gram模型来有效训练语义密集的标签嵌入。然后，使用这些密集的标签嵌入来构建一个层次化标签树。在微调预训练的编码器Transformer时，我们将多标签文本分类问题制定为一个在二分图中的文本-标签匹配问题。然后，从微调后的Transformer中提取密集的文本表示。除了微调后的密集文本嵌入之外，我们还从预训练的Sentence Transformer中提取静态的密集句子嵌入。

    The eXtreme Multi-label text Classification(XMC) refers to training a classifier that assigns a text sample with relevant labels from an extremely large-scale label set (e.g., millions of labels). We propose MatchXML, an efficient text-label matching framework for XMC. We observe that the label embeddings generated from the sparse Term Frequency-Inverse Document Frequency(TF-IDF) features have several limitations. We thus propose label2vec to effectively train the semantic dense label embeddings by the Skip-gram model. The dense label embeddings are then used to build a Hierarchical Label Tree by clustering. In fine-tuning the pre-trained encoder Transformer, we formulate the multi-label text classification as a text-label matching problem in a bipartite graph. We then extract the dense text representations from the fine-tuned Transformer. Besides the fine-tuned dense text embeddings, we also extract the static dense sentence embeddings from a pre-trained Sentence Transformer. Finally,
    
[^25]: OmniQuant：用于大型语言模型的全向校准量化

    OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models. (arXiv:2308.13137v1 [cs.LG])

    [http://arxiv.org/abs/2308.13137](http://arxiv.org/abs/2308.13137)

    OmniQuant是一种用于大型语言模型的全向校准量化技术，通过优化各种量化参数实现了良好的性能，并保持了计算效率。

    

    大型语言模型（LLM）已经在自然语言处理任务中带来了革命性的变化。然而，它们的实际部署受到了其庞大的内存和计算需求的限制。虽然最近的后训练量化（PTQ）方法在减少内存占用和提高LLM的计算效率方面非常有效，但它们手工制定量化参数，导致性能较低并且不能处理极低位量化。为了解决这个问题，我们介绍了一种全向校准量化（OmniQuant）技术，用于LLMs，它在多种量化设置下实现了良好的性能，并通过高效优化各种量化参数来保持PTQ的计算效率。OmniQuant包含两个创新组件，包括可学习的权重剪裁（LWC）和可学习的等效变换（LET）。LWC通过优化剪裁阈值来调节权重的极值。与此同时，LET处理激活函数。

    Large language models (LLMs) have revolutionized natural language processing tasks. However, their practical deployment is hindered by their immense memory and computation requirements. Although recent post-training quantization (PTQ) methods are effective in reducing memory footprint and improving the computational efficiency of LLM, they hand-craft quantization parameters, which leads to low performance and fails to deal with extremely low-bit quantization. To tackle this issue, we introduce an Omnidirectionally calibrated Quantization (OmniQuant) technique for LLMs, which achieves good performance in diverse quantization settings while maintaining the computational efficiency of PTQ by efficiently optimizing various quantization parameters. OmniQuant comprises two innovative components including Learnable Weight Clipping (LWC) and Learnable Equivalent Transformation (LET). LWC modulates the extreme values of weights by optimizing the clipping threshold. Meanwhile, LET tackles activa
    
[^26]: 使用多语种知识蒸馏的句子嵌入模型用于古希腊语

    Sentence Embedding Models for Ancient Greek Using Multilingual Knowledge Distillation. (arXiv:2308.13116v1 [cs.CL])

    [http://arxiv.org/abs/2308.13116](http://arxiv.org/abs/2308.13116)

    本文提出了一种使用多语种知识蒸馏方法来训练古希腊文本的句子嵌入模型，克服了缺乏训练数据的困难。

    

    针对古希腊语等历史语言，高质量的句子嵌入模型难以实现，主要是因为缺乏训练数据。本文使用多语种知识蒸馏的方法，训练BERT模型来生成古希腊文本的句子嵌入。我们通过句子嵌入对齐方法构建了一个平行语料库，将古希腊文档与英文翻译对齐，并利用这个数据集来训练我们的模型。

    Contextual language models have been trained on Classical languages, including Ancient Greek and Latin, for tasks such as lemmatization, morphological tagging, part of speech tagging, authorship attribution, and detection of scribal errors. However, high-quality sentence embedding models for these historical languages are significantly more difficult to achieve due to the lack of training data. In this work, we use a multilingual knowledge distillation approach to train BERT models to produce sentence embeddings for Ancient Greek text. The state-of-the-art sentence embedding approaches for high-resource languages use massive datasets, but our distillation approach allows our Ancient Greek models to inherit the properties of these models while using a relatively small amount of translated sentence data. We build a parallel sentence dataset using a sentence-embedding alignment method to align Ancient Greek documents with English translations, and use this dataset to train our models. We 
    
[^27]: 朝着一个整体化方法：借助跨学科视角理解NLP模型中的社会人口偏见

    Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models using an Interdisciplinary Lens. (arXiv:2308.13089v1 [cs.CL])

    [http://arxiv.org/abs/2308.13089](http://arxiv.org/abs/2308.13089)

    该论文通过一个跨学科的视角，面对NLP模型中的社会人口偏见，探索了三个方面，解决了仅关注种族和性别等有限范围偏见、以及技术中心实施方法等挑战。

    

    自然语言处理（NLP）在各种社会技术解决方案中的使用和应用的迅速增长，突显了对偏见及其对社会的影响的全面理解的需求。虽然关于NLP中偏见的研究已经扩大，但仍然存在一些需要注意的挑战。这些挑战包括在种族和性别之外对社会人口偏见的有限关注，主要集中在模型上的狭窄分析范围以及技术中心的实施方法。本文正是解决这些挑战并倡导更多的跨学科方法来理解NLP中的偏见。该工作分为三个方面，分别探索NLP中特定方面的偏见。

    The rapid growth in the usage and applications of Natural Language Processing (NLP) in various sociotechnical solutions has highlighted the need for a comprehensive understanding of bias and its impact on society. While research on bias in NLP has expanded, several challenges persist that require attention. These include the limited focus on sociodemographic biases beyond race and gender, the narrow scope of analysis predominantly centered on models, and the technocentric implementation approaches. This paper addresses these challenges and advocates for a more interdisciplinary approach to understanding bias in NLP. The work is structured into three facets, each exploring a specific aspect of bias in NLP.
    
[^28]: 基于人口特征的固定步长单时钟模拟的Agent-Based模型的形式化规范术语

    Formal specification terminology for demographic agent-based models of fixed-step single-clocked simulations. (arXiv:2308.13081v1 [cs.CL])

    [http://arxiv.org/abs/2308.13081](http://arxiv.org/abs/2308.13081)

    本文提出了一种适用于人口学领域的Agent Based Models (ABMs)的数学规范的合适形式术语，这进一步提高了模型的理解，并与O.D.D.协议相结合，减少了模型复制过程中的歧义。

    

    本文提出了一种适用于人口学领域的Agent Based Models (ABMs)的数学规范的合适形式术语。目标ABMs的模拟遵循固定步长单时钟模式。所提出的术语进一步提高了模型的理解，并可以作为一种独立的方法论，用于规范和选择性地记录一组重要的（人口）ABMs。然而，可以想象通过进一步扩展，这种术语可能与广泛使用的模型文档和通信O.D.D.协议[Grimm和et al.，2020，Amouroux等，2010]合并，以减少许多模型建模者的源源不断产生的歧义，从而阻碍模型复制。已经出版的人口模型文档，单亲模型的大大简化版本[Gostoli和Silverman，2020]作为形式术语的示例，单独发布在[Elsheikh，2023b]中。该模型已被实现。

    This document presents adequate formal terminology for the mathematical specification of a subset of Agent Based Models (ABMs) in the field of Demography. The simulation of the targeted ABMs follows a fixed-step single-clocked pattern. The proposed terminology further improves the model understanding and can act as a stand-alone methodology for the specification and optionally the documentation of a significant set of (demographic) ABMs. Nevertheless, it is imaginable the this terminology probably with further extensions can be merged with the largely-informal widely-used model documentation and communication O.D.D. protocol [Grimm and et al., 2020, Amouroux et al., 2010] to reduce many sources of ambiguity, hindering model replications by other modelers. A published demographic model documentation, largely simplified version of the Lone Parent Model [Gostoli and Silverman, 2020] is separately published in [Elsheikh, 2023b] as illustration for the formal terminology. The model was impl
    
[^29]: 因果鹦鹉：大型语言模型可能谈论因果性，但它们并不具备因果性

    Causal Parrots: Large Language Models May Talk Causality But Are Not Causal. (arXiv:2308.13067v1 [cs.AI])

    [http://arxiv.org/abs/2308.13067](http://arxiv.org/abs/2308.13067)

    大型语言模型（LLM）不能具备因果性，它们只是重复嵌入在数据中的因果知识。

    

    有人认为规模是实现人工智能的全部所需，甚至可以涵盖因果模型。我们明确指出，大型语言模型（LLM）不能具备因果性，并解释为什么有时我们可能有这种感觉。为此，我们定义并举例了一种新的结构因果模型（SCM）的子群，称之为元SCM，它在其变量中编码关于其他SCM的因果事实。我们猜测，在LLM成功进行因果推理的情况下，背后可能存在一个相应的元SCM，在其数据中展示了自然语言中因果事实之间的相关性，而LLM最终是在这些数据上进行训练的。如果我们的假设成立，那么这将意味着LLM就像鹦鹉一样，它们只是重复嵌入在数据中的因果知识。我们的实证分析提供了支持证据，表明当前的LLM甚至是弱“因果鹦鹉”。

    Some argue scale is all what is needed to achieve AI, covering even causal models. We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables. We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained. If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.'
    
[^30]: 跨语言和方言中的亲属关系词汇的词汇多样性研究

    Lexical Diversity in Kinship Across Languages and Dialects. (arXiv:2308.13056v1 [cs.CL])

    [http://arxiv.org/abs/2308.13056](http://arxiv.org/abs/2308.13056)

    本文研究了跨语言和方言中的亲属关系词汇的词汇多样性，并提出了一种方法来丰富计算词汇资源。通过大规模的案例研究，我们验证了该方法，并提供了可供浏览和下载的计算资源，扩展了对亲属关系术语的语言学研究，揭示了在语言和文化上相互接近的社区中多样性的程度。

    

    已知语言以多样的方式描述世界。在词汇中，多样性广泛存在，如词汇空缺和无法翻译等现象。然而，在计算资源中，如多语种词汇数据库中，多样性很少得到表示。本文介绍了一种方法，通过增加与语言多样性相关的内容，丰富计算词汇资源。该方法通过对亲属关系术语进行两个大规模案例研究进行验证，这是一个众所周知在语言和文化中具有多样性的领域：一个案例研究涉及七种阿拉伯方言，而另一个案例研究涉及三种印度尼西亚语言。我们所得到的结果以可浏览和可下载的计算资源的形式提供，扩展了先前对亲属关系术语的语言学研究，同时揭示了在语言和文化上相互接近的社区中多样性的程度。

    Languages are known to describe the world in diverse ways. Across lexicons, diversity is pervasive, appearing through phenomena such as lexical gaps and untranslatability. However, in computational resources, such as multilingual lexical databases, diversity is hardly ever represented. In this paper, we introduce a method to enrich computational lexicons with content relating to linguistic diversity. The method is verified through two large-scale case studies on kinship terminology, a domain known to be diverse across languages and cultures: one case study deals with seven Arabic dialects, while the other one with three Indonesian languages. Our results, made available as browseable and downloadable computational resources, extend prior linguistics research on kinship terminology, and provide insight into the extent of diversity even within linguistically and culturally close communities.
    
[^31]: 使用精细调整的Llama 2 GPT模型进行金融新闻分析

    Financial News Analytics Using Fine-Tuned Llama 2 GPT Model. (arXiv:2308.13032v1 [cs.CL])

    [http://arxiv.org/abs/2308.13032](http://arxiv.org/abs/2308.13032)

    本研究通过精细调整的Llama 2模型实现了金融新闻的多任务分析，包括文本分析、摘要和情感提取等。实验结果显示，提取的命名实体情感可以作为有监督机器学习模型的预测特征。

    

    本文考虑了使用精细调整的Llama 2 Large Language Model (LLM) 对金融新闻进行多任务分析的可能性。通过PEFT/LoRA方法对模型进行精细调整，主要包括从金融市场角度分析文本、突出文本的主要观点、对文本进行摘要和提取具有适当情感的命名实体等任务。实验结果表明，经过精细调整的Llama 2模型能够进行多任务的金融新闻分析，其响应的结构可以部分为结构化文本，另一部分数据可以采用JSON格式进一步处理。提取的命名实体情感可以被视为具有定量目标变量的监督机器学习模型的预测特征。

    The paper considers the possibility to fine-tune Llama 2 Large Language Model (LLM) for the multitask analysis of financial news. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text from financial market perspectives, highlighting main points of a text, summarizing a text and extracting named entities with appropriate sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a multitask financial news analysis with a specified structure of response, part of response can be a structured text and another part of data can have JSON format for further processing. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models with quantitative target variables.
    
[^32]: Code Llama: 用于代码的开放基础模型

    Code Llama: Open Foundation Models for Code. (arXiv:2308.12950v1 [cs.CL])

    [http://arxiv.org/abs/2308.12950](http://arxiv.org/abs/2308.12950)

    Code Llama是一系列用于代码的开放基础模型，具有最先进的性能和填充功能，支持大型输入上下文和零-shot指令跟踪能力。在多个代码基准测试中，Code Llama达到开放模型中最高的性能，同时Python专门化模型在某些测试上超越了Llama 2的70B版本。

    

    我们发布了Code Llama，这是一系列基于Llama 2的用于代码的大型语言模型，具有开放模型中最先进的性能，填充功能，支持大型输入上下文，并且能够进行零-shot指令跟踪编程任务。我们提供多种版本以覆盖广泛的应用场景：基础模型（Code Llama），Python专门化模型（Code Llama-Python），以及指令跟踪模型（Code Llama-Instruct），每个模型参数分别为7B、13B和34B。所有模型都是在16k标记序列上训练的，可以改善长度不超过100k标记的输入。7B和13B的Code Llama和Code Llama-Instruct变种会根据周围内容进行填充。Code Llama在几个代码基准测试中达到了开放模型中最先进的性能，HumanEval和MBPP分别达到了53%和55%的分数。值得注意的是，Code Llama-Python 7B在HumanEval和MBPP上优于Llama 2 70B，而我们的所有模型都优于其他任何模型。

    We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every othe
    
[^33]: 语言知识能改进视觉-语言预训练中的多模态对齐吗？

    Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?. (arXiv:2308.12898v1 [cs.MM])

    [http://arxiv.org/abs/2308.12898](http://arxiv.org/abs/2308.12898)

    本论文研究了语言知识在多模态对齐中的作用，设计并发布了一个多模态对齐探测基准来检测关键的语言组成部分。

    

    多媒体领域对通过多模态预训练神经网络模型感知和表达物理世界展现出了强烈的兴趣，其中视觉-语言相关的研究是当前最吸引人的话题之一。然而，目前对以下两个问题的探索非常有限：1）在视觉-语言预训练中是否可以提取关键的语言知识（如语义和句法），2）这种语言知识如何影响或增强多模态对齐。因此，本文旨在阐明全面的语言知识，包括语义表达和句法结构，对多模态对齐的影响。具体而言，我们设计并发布了SNARE，第一个大规模的多模态对齐探测基准，来检测关键的语言组成部分，如词汇、语义和句法知识，包含了四个任务：语义结构、否定逻辑、属性归属和关系组合。基于我们的实验结果，我们证明了.....

    The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic. However, there have been few endeavors dedicated to the exploration of 1) whether essential linguistic knowledge (e.g., semantics and syntax) can be extracted during VLP, and 2) how such linguistic knowledge impact or enhance the multimodal alignment. In response, here we aim to elucidate the impact of comprehensive linguistic knowledge, including semantic expression and syntactic structure, on multimodal alignment. Specifically, we design and release the SNARE, the first large-scale multimodal alignment probing benchmark, to detect the vital linguistic components, e.g., lexical, semantic, and syntax knowledge, containing four tasks: Semantic structure, Negation logic, Attribute ownership, and Relationship composition. Based on our prop
    
[^34]: 扩展性和指导调优的扩散语言模型能够完成多种任务

    Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning. (arXiv:2308.12219v1 [cs.CL])

    [http://arxiv.org/abs/2308.12219](http://arxiv.org/abs/2308.12219)

    本文研究表明，通过扩展扩散语言模型的数据、规模和任务，可以有效使其成为强大的语言学习者。实验证明，扩展扩散语言模型在解决通用语言任务方面能够持续提高性能。

    

    最近生成式人工智能的兴起得益于扩散概率模型的生成能力和大规模语言模型的可扩展性。尽管具有潜力，但扩散语言模型是否能够解决与自回归模型相媲美的通用语言任务仍然不明确。本文证明了在数据、规模和任务方面扩展扩散模型能够有效使其成为强大的语言学习者。我们通过先通过掩码语言建模预训练从大规模数据中获取知识，再通过扩散适应将预训练的掩码语言模型改进为扩散语言模型，通过任务特定的微调和指导调优来发掘其在解决通用语言任务方面的多样性。实验证明，扩展扩散语言模型能够在下游语言任务中持续提高性能。

    The recent surge of generative AI has been fueled by the generative power of diffusion probabilistic models and the scalable capabilities of large language models. Despite their potential, it remains elusive whether diffusion language models can solve general language tasks comparable to their autoregressive counterparts. This paper demonstrates that scaling diffusion models w.r.t. data, sizes, and tasks can effectively make them strong language learners. We build competent diffusion language models at scale by first acquiring knowledge from massive data via masked language modeling pretraining thanks to their intrinsic connections. We then reprogram pretrained masked language models into diffusion language models via diffusive adaptation, wherein task-specific finetuning and instruction finetuning are explored to unlock their versatility in solving general language tasks. Experiments show that scaling diffusion language models consistently improves performance across downstream langua
    
[^35]: 自我欺骗：逆向破解大型语言模型的语义防火墙

    Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models. (arXiv:2308.11521v1 [cs.CL])

    [http://arxiv.org/abs/2308.11521](http://arxiv.org/abs/2308.11521)

    这篇论文研究了大型语言模型的越狱问题，并提出了一种自动越狱方法，介绍了语义防火墙的概念和三种技术实现方法。

    

    大型语言模型（LLM），如ChatGPT，具有接近人工通用智能的惊人能力。虽然为各种社会需求提供了便利，但LLM也降低了生成有害内容的成本。因此，LLM开发人员已经部署了语义级的防御机制，用于识别和拒绝可能导致不适当内容的提示。不幸的是，这些防御机制并不完全可靠，一些攻击者已经设计出了“越狱”提示，临时使LLM忘记内容防御规则并回答任何不适当的问题。迄今为止，业界和学术界尚无关于这些语义级攻击和防御原则的明确解释。本文研究了LLM越狱问题，并首次提出了一种自动越狱方法。我们提出了语义防火墙的概念，并提供了三种技术实现方法。

    Large language models (LLMs), such as ChatGPT, have emerged with astonishing capabilities approaching artificial general intelligence. While providing convenience for various societal needs, LLMs have also lowered the cost of generating harmful content. Consequently, LLM developers have deployed semantic-level defenses to recognize and reject prompts that may lead to inappropriate content. Unfortunately, these defenses are not foolproof, and some attackers have crafted "jailbreak" prompts that temporarily hypnotize the LLM into forgetting content defense rules and answering any improper questions. To date, there is no clear explanation of the principles behind these semantic-level attacks and defenses in both industry and academia.  This paper investigates the LLM jailbreak problem and proposes an automatic jailbreak method for the first time. We propose the concept of a semantic firewall and provide three technical implementation approaches. Inspired by the attack that penetrates trad
    
[^36]: 无监督原型适配器用于视觉语言模型

    Unsupervised Prototype Adapter for Vision-Language Models. (arXiv:2308.11507v1 [cs.CV])

    [http://arxiv.org/abs/2308.11507](http://arxiv.org/abs/2308.11507)

    本文介绍了一种无监督的视觉语言模型微调方法，称为无监督原型适配器（UP-Adapter）。该方法利用CLIP的文本-图像对齐能力，针对未标注的目标数据集自动选择自信度最高的样本，并生成类别原型，以实现无监督的微调。

    

    最近，大规模预训练的视觉语言模型（如CLIP和ALIGN）在获取可转移的视觉表示方面显示出了显著的有效性。为了利用这些模型中编码的宝贵知识用于下游任务，已经开发了几种微调方法，包括提示调整方法和适配器方法，以有效地适应视觉语言模型的监督。然而，这些方法依赖于可获得的标注样本，这可能耗时且费力，从而限制了可扩展性。为了解决这个问题，在这项工作中，我们设计了一种无监督的视觉语言模型微调方法，称为无监督原型适配器（UP-Adapter）。具体而言，对于未标注的目标数据集，我们利用CLIP的文本-图像对齐能力自动选择每个类别的最自信样本。利用这些选择的样本，我们生成类别原型，这将为无监督的微调提供指导。

    Recently, large-scale pre-trained vision-language models (e.g. CLIP and ALIGN) have demonstrated remarkable effectiveness in acquiring transferable visual representations. To leverage the valuable knowledge encoded within these models for downstream tasks, several fine-tuning approaches, including prompt tuning methods and adapter-based methods, have been developed to adapt vision-language models effectively with supervision. However, these methods rely on the availability of annotated samples, which can be labor-intensive and time-consuming to acquire, thus limiting scalability. To address this issue, in this work, we design an unsupervised fine-tuning approach for vision-language models called Unsupervised Prototype Adapter (UP-Adapter). Specifically, for the unannotated target datasets, we leverage the text-image aligning capability of CLIP to automatically select the most confident samples for each class. Utilizing these selected samples, we generate class prototypes, which serve a
    
[^37]: 作者身份表征学习能够捕捉文体特征吗？

    Can Authorship Representation Learning Capture Stylistic Features?. (arXiv:2308.11490v1 [cs.CL])

    [http://arxiv.org/abs/2308.11490](http://arxiv.org/abs/2308.11490)

    本论文研究了作者身份表征学习能否捕捉文体特征的问题，并通过实验验证了这些表征能够有效地捕捉写作风格的特征。

    

    在计算语言学中，自动将作者的风格从其写作内容中分离出来是一个长期存在且可能不可解决的问题。同时，最近有大量带有作者标签的文本语料库可用，使得以纯数据驱动的方式学习作者身份表征成为可能，用于作者归属这一任务，该任务显然更多地依赖于编码写作风格而不是编码内容。然而，对这一替代任务的成功并不能确保这些表征能够捕捉写作风格，因为作者身份也可能与其他潜在变量（如主题）相关。为了更好地理解这些表征所传递的信息的本质，特别是为了验证其主要编码的是写作风格的假设，我们通过一系列有针对性的实验系统地检查了这些表征。这些实验的结果表明，为作者表示学习的表征能够有效地捕捉写作风格的特征。

    Automatically disentangling an author's style from the content of their writing is a longstanding and possibly insurmountable problem in computational linguistics. At the same time, the availability of large text corpora furnished with author labels has recently enabled learning authorship representations in a purely data-driven manner for authorship attribution, a task that ostensibly depends to a greater extent on encoding writing style than encoding content. However, success on this surrogate task does not ensure that such representations capture writing style since authorship could also be correlated with other latent variables, such as topic. In an effort to better understand the nature of the information these representations convey, and specifically to validate the hypothesis that they chiefly encode writing style, we systematically probe these representations through a series of targeted experiments. The results of these experiments suggest that representations learned for the 
    
[^38]: cantnlp@LT-EDI-2023: 使用时空重新训练的语言模型在社交媒体评论中检测恐同与恐惧跨性别内容

    cantnlp@LT-EDI-2023: Homophobia/Transphobia Detection in Social Media Comments using Spatio-Temporally Retrained Language Models. (arXiv:2308.10370v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10370](http://arxiv.org/abs/2308.10370)

    本文介绍了我们开发的多分类系统，使用基于BERT的语言模型在五种语言条件下检测社交媒体评论中的恐同和恐惧跨性别内容。我们通过时空相关的社交媒体语言数据对跨语言预训练语言模型进行了重新训练，取得了表现最好的七种标签分类系统。结果显示，时空训练可以提高分类性能，有效检测社交媒体评论中的恐同和恐惧跨性别内容。

    

    本文描述了我们作为LTEDI@RANLP-2023共享任务的一部分开发的多分类系统。我们使用基于BERT的语言模型来检测社交媒体评论中的恐同和恐惧跨性别内容，涵盖英语、西班牙语、印地语、马拉雅拉姆语和泰米尔语五种语言条件。我们使用时空相关的社交媒体语言数据对基于Transformer的跨语言预训练语言模型XLMRoBERTa进行重新训练。我们还使用模拟的混合脚本社交媒体语言数据对部分模型进行重新训练，其性能有所变化。我们为马拉雅拉姆语开发了表现最好的七种标签分类系统，基于加权宏平均F1得分（在六个系统中排名第一），其他语言和类别标签条件下的性能有所差异。我们发现，将这种时空数据纳入分类性能相对于基线模型在所有语言和任务条件下都有所提升。结果表明，基于Transformer的语言模型经过时空训练可以有效检测社交媒体评论中的恐同与恐惧跨性别内容。

    This paper describes our multiclass classification system developed as part of the LTEDI@RANLP-2023 shared task. We used a BERT-based language model to detect homophobic and transphobic content in social media comments across five language conditions: English, Spanish, Hindi, Malayalam, and Tamil. We retrained a transformer-based crosslanguage pretrained language model, XLMRoBERTa, with spatially and temporally relevant social media language data. We also retrained a subset of models with simulated script-mixed social media language data with varied performance. We developed the best performing seven-label classification system for Malayalam based on weighted macro averaged F1 score (ranked first out of six) with variable performance for other language and class-label conditions. We found the inclusion of this spatio-temporal data improved the classification performance for all language and task conditions when compared with the baseline. The results suggests that transformer-based lan
    
[^39]: 神经网络泛化性能在语法归纳任务中的基准评估

    Benchmarking Neural Network Generalization for Grammar Induction. (arXiv:2308.08253v1 [cs.CL])

    [http://arxiv.org/abs/2308.08253](http://arxiv.org/abs/2308.08253)

    提供了一种基于完全指定的形式语言的神经网络泛化度量方法，并在语法归纳任务中使用该基准评估了不同架构的网络。结果显示，使用最小描述长度目标（MDL）训练的网络泛化性能更好且使用更少的数据。

    

    神经网络的泛化能力如何？即使对于语法归纳任务这样目标泛化完全已知的任务，以前的工作也未能给出明确的答案，只在训练集之外进行了非常有限的测试，并使用不同的成功标准。我们提出了一种基于完全指定的形式语言的神经网络泛化度量方法。给定一个模型和一个形式语法，该方法根据模型在未见样本上的泛化能力分配一个泛化得分，这个得分与模型训练所使用的数据量成反比。这个基准包含了诸如$a^nb^n$，$a^nb^nc^n$，$a^nb^mc^{n+m}$以及Dyck-1和2等语言。我们使用这个基准评估了一些架构，并发现使用最小描述长度目标（MDL）训练的网络比使用标准损失函数训练的网络泛化性能更好且使用更少的数据。该基准可在https://github.com/taucompling/bliss找到。

    How well do neural networks generalize? Even for grammar induction tasks, where the target generalization is fully known, previous works have left the question open, testing very limited ranges beyond the training set and using different success criteria. We provide a measure of neural network generalization based on fully specified formal languages. Given a model and a formal grammar, the method assigns a generalization score representing how well a model generalizes to unseen samples in inverse relation to the amount of data it was trained on. The benchmark includes languages such as $a^nb^n$, $a^nb^nc^n$, $a^nb^mc^{n+m}$, and Dyck-1 and 2. We evaluate selected architectures using the benchmark and find that networks trained with a Minimum Description Length objective (MDL) generalize better and using less data than networks trained using standard loss functions. The benchmark is available at https://github.com/taucompling/bliss.
    
[^40]: ChatMOF: 一种自主人工智能系统用于预测和生成金属-有机骨架

    ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks. (arXiv:2308.01423v1 [cs.CL])

    [http://arxiv.org/abs/2308.01423](http://arxiv.org/abs/2308.01423)

    ChatMOF是一种自主AI系统，用于预测和生成金属-有机骨架。通过利用大规模语言模型，它能够从文本输入中提取关键细节，并提供适当的回应。该系统通过组合代理、工具包和评估器的核心组件，实现了数据检索、性质预测和结构生成等多个任务。研究进一步展示了在材料科学中使用大型语言模型的优势和潜力。

    

    ChatMOF是一个自主人工智能系统，用于预测和生成金属-有机骨架（MOFs）。通过利用大规模语言模型（gpt-3.5-turbo），ChatMOF从文本输入中提取关键细节并提供适当的回应，从而消除了对刚性结构化查询的需求。该系统由三个核心组件（即代理、工具包和评估器）组成，形成一个强大的流水线，管理多种任务，包括数据检索、性质预测和结构生成。该研究进一步探讨了在材料科学中使用大型语言模型（LLMs）人工智能系统的优点和限制，并展示了其对未来发展的变革潜力。

    ChatMOF is an autonomous Artificial Intelligence (AI) system that is built to predict and generate of metal-organic frameworks (MOFs). By leveraging a large-scale language model (gpt-3.5-turbo), ChatMOF extracts key details from textual inputs and delivers appropriate responses, thus eliminating the necessity for rigid structured queries. The system is comprised of three core components (i.e. an agent, a toolkit, and an evaluator) and it forms a robust pipeline that manages a variety of tasks, including data retrieval, property prediction, and structure generation. The study further explores the merits and constraints of using large language models (LLMs) AI system in material sciences using and showcases its transformative potential for future advancements.
    
[^41]: 解码ChatGPT：现有研究、当前挑战和未来可能方向的分类学

    Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions. (arXiv:2307.14107v1 [cs.CL])

    [http://arxiv.org/abs/2307.14107](http://arxiv.org/abs/2307.14107)

    本论文对ChatGPT的现有研究进行了分类学总结，并探索了其在各个应用领域中的潜力。此外，该研究还批判性分析了现有文献和ChatGPT在解决现实挑战方面的贡献。

    

    自2022年11月发布以来，Chat GPT（Chat Generative Pre-trained Transformer）引起了极大的兴趣和关注。它在包括考试通过和创造性写作在内的各个领域中展现出令人印象深刻的表现。然而，与偏见和信任相关的挑战和担忧依然存在。在这项工作中，我们对ChatGPT的100多篇Scopus索引的出版物进行了全面回顾，旨在提供ChatGPT研究的分类学，并探索其应用。我们对现有文献进行了批判性分析，确定了研究中常用的方法。此外，我们调查了ChatGPT在医疗、营销和金融服务、软件工程、学术和科学写作、研究和教育、环境科学以及自然语言处理等各种应用领域中的实用性。通过研究这些应用，我们获得了ChatGPT在应对现实挑战方面的有价值的见解。

    Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022. It has shown impressive performance in various domains, including passing exams and creative writing. However, challenges and concerns related to biases and trust persist. In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications. We critically analyze the existing literature, identifying common approaches employed in the studies. Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing. Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges. We also 
    
[^42]: 方言的碰撞：社会经济交叉对语言使用的影响

    When Dialects Collide: How Socioeconomic Mixing Affects Language Use. (arXiv:2307.10016v1 [physics.soc-ph] CROSS LISTED)

    [http://arxiv.org/abs/2307.10016](http://arxiv.org/abs/2307.10016)

    本研究使用地理标记的推特数据和计算方法，在英格兰和威尔士的七千个行政区域上进行了大规模映射，发现社会经济交叉影响了语言使用，混合不同社会经济阶层的人群频率偏离标准语法的程度越高，其收入关联越弱。

    

    人们的社会经济背景与他们使用标准语言的方式并不独立，这在各种社会语言学研究中已经得到证明。然而，不同社会经济阶层的人们交叉混合可能对这些相关性造成何种影响，在定量角度上尚未得到充分探索。在这项工作中，我们利用带地理标记的推特和可转移的计算方法，在英格兰和威尔士的七千个行政区域上对与标准英语偏离的情况进行大规模映射。我们将这些数据与高分辨率的收入地图结合起来，为居住地用户分配一个代理社会经济指标。令人惊讶的是，在八个大都市区域，我们发现一种一致的模式，表明不同社会经济阶层的人们混合得越多，其偏离标准语法和收入的频率就越不相互依存。

    The socioeconomic background of people and how they use standard forms of language are not independent, as demonstrated in various sociolinguistic studies. However, the extent to which these correlations may be influenced by the mixing of people from different socioeconomic classes remains relatively unexplored from a quantitative perspective. In this work we leverage geotagged tweets and transferable computational methods to map deviations from standard English on a large scale, in seven thousand administrative areas of England and Wales. We combine these data with high-resolution income maps to assign a proxy socioeconomic indicator to home-located users. Strikingly, across eight metropolitan areas we find a consistent pattern suggesting that the more different socioeconomic classes mix, the less interdependent the frequency of their departures from standard grammar and their income become. Further, we propose an agent-based model of linguistic variety adoption that sheds light on th
    
[^43]: ACTI在EVALITA 2023中的综述：阴谋论辨识任务概述

    ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification Task. (arXiv:2307.06954v1 [cs.CL])

    [http://arxiv.org/abs/2307.06954](http://arxiv.org/abs/2307.06954)

    ACTI在EVALITA 2023中的阴谋论辨识任务共有15支团队参与，通过使用大型语言模型判断阴谋内容和分类，得出了关于利用这些模型抵制在在线平台传播错误信息的结论。

    

    阴谋论辨识任务是Evalita 2023首次提出的新共享任务。ACTI挑战仅基于Telegram上的阴谋频道评论，分为两个子任务：(i) 阴谋内容分类：辨识阴谋内容和(ii) 阴谋类别分类：针对特定阴谋理论分类。共有15支团队参与了该任务，总共提交了81个结果。我们说明了基于大型语言模型的最佳方法。最后，我们得出了关于利用这些模型来抵制在在线平台上传播错误信息的结论。

    Conspiracy Theory Identication task is a new shared task proposed for the first time at the Evalita 2023. The ACTI challenge, based exclusively on comments published on conspiratorial channels of telegram, is divided into two subtasks: (i) Conspiratorial Content Classification: identifying conspiratorial content and (ii) Conspiratorial Category Classification about specific conspiracy theory classification. A total of fifteen teams participated in the task for a total of 81 submissions. We illustrate the best performing approaches were based on the utilization of large language models. We finally draw conclusions about the utilization of these models for counteracting the spreading of misinformation in online platforms.
    
[^44]: 利用嵌入技术设计面向科学领域的聊天机器人

    Domain-specific ChatBots for Science using Embeddings. (arXiv:2306.10067v1 [cs.CL])

    [http://arxiv.org/abs/2306.10067](http://arxiv.org/abs/2306.10067)

    本论文演示如何利用现有方法和软件工具结合嵌入技术设计面向科学领域的聊天机器人，该机器人能够处理科学文献，提供特定领域的上下文信息，并在初步研究辅助知识方面为物理科学家提供帮助。

    

    大语言模型(LLM)已成为强大的机器学习系统，能处理多种任务。经调整的这些系统已被转化为聊天机器人，能回答用户对广泛话题的查询，提供丰富的信息和创意回答。然而，由于它们在自然科学领域的知识仍不完整，并且面临严格需求和来源标准，因此其在物理科学研究中的应用仍受到限制。本文演示了如何轻松地将现有方法和软件工具结合起来，实现面向特定领域的聊天机器人。该系统能接受现有格式的科学文献，并使用文本嵌入查找来为LLM提供特定领域的上下文信息，以便在撰写回答时使用。我们同样证明了现有的图像嵌入方法可以用于跨出版物图片的搜索和检索。这些结果表明，在提供初步研究辅助知识方面，LLM已经适用于物理科学家的使用，并且进一步的开发可以扩展这些应用。

    Large language models (LLMs) have emerged as powerful machine-learning systems capable of handling a myriad of tasks. Tuned versions of these systems have been turned into chatbots that can respond to user queries on a vast diversity of topics, providing informative and creative replies. However, their application to physical science research remains limited owing to their incomplete knowledge in these areas, contrasted with the needs of rigor and sourcing in science domains. Here, we demonstrate how existing methods and software tools can be easily combined to yield a domain-specific chatbot. The system ingests scientific documents in existing formats, and uses text embedding lookup to provide the LLM with domain-specific contextual information when composing its reply. We similarly demonstrate that existing image embedding methods can be used for search and retrieval across publication figures. These results confirm that LLMs are already suitable for use by physical scientists in acc
    
[^45]: SpeechGen: 利用提示解锁语音语言模型的生成能力

    SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts. (arXiv:2306.02207v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2306.02207](http://arxiv.org/abs/2306.02207)

    本文探索了一个名为SpeechGen的统一框架，通过提示调节，解锁了语音语言模型的生成能力，成功地实现了直接适应连续语音到离散标记的任务，使得语音生成成为可能。

    

    大型语言模型（LLM）在人工智能生成内容（AIGC）中引起了相当大的关注，特别是随着ChatGPT的出现。然而，将连续语音直接适应于处理离散标记的LLM仍然是一个未解决的挑战，这妨碍了LLM在语音生成方面的应用。高级语音LM们无法充分利用语音信号所包含的丰富信息，包括说话者和情感等，这些信息仅通过文本数据无法获取。在一些语音分类任务中，简单的提示调整已经表现出明显的参数效率和竞争性能的提高。但在多大程度上提示能够有效地激发语音LM的生成任务仍然是一个未知的问题。本文提出了一项先驱性研究，该研究在称为SpeechGen的统一框架中使用提示调节来刺激语音LM进行各种生成任务，并具有约10M可训练参数。

    Large language models (LLMs) have gained considerable attention for Artificial Intelligence Generated Content (AIGC), particularly with the emergence of ChatGPT. However, the direct adaptation of continuous speech to LLMs that process discrete tokens remains an unsolved challenge, hindering the application of LLMs for speech generation. The advanced speech LMs are in the corner, as that speech signals encapsulate a wealth of information, including speaker and emotion, beyond textual data alone. Prompt tuning has demonstrated notable gains in parameter efficiency and competitive performance on some speech classification tasks. However, the extent to which prompts can effectively elicit generation tasks from speech LMs remains an open question. In this paper, we present pioneering research that explores the application of prompt tuning to stimulate speech LMs for various generation tasks, within a unified framework called SpeechGen, with around 10M trainable parameters. The proposed unif
    
[^46]: 如何评估预训练语音模型的迁移性？

    How to Estimate Model Transferability of Pre-Trained Speech Models?. (arXiv:2306.01015v1 [cs.CL])

    [http://arxiv.org/abs/2306.01015](http://arxiv.org/abs/2306.01015)

    本文介绍了一个新的框架，可以高效地评估预训练语音模型在微调目标任务时的迁移性。该框架利用两个表示理论，通过生成候选模型的排名分数，可以在不进行实际微调的情况下计算迁移性分数，实验结果表明该框架与微调基础事实之间存在很高的相关性和低的p值，是一个节省资源、高效节省时间的微调方法。

    

    本文提出了一个“基于分数评估”的框架，用于估计预训练语音模型（PSMs）在微调目标任务时的迁移性。我们利用两个表示理论，贝叶斯似然估计和最优传输，使用提取的表示生成PSM候选的排名分数。通过假设独立性，我们的框架可以高效地计算迁移性分数，而无需实际微调候选模型或层。我们使用公共数据在交叉层和交叉模型设置中评估了一些流行的监督语音模型（例如Conformer RNN-Transducer）和自监督语音模型（例如HuBERT）。实验结果显示，我们的估计框架与微调基础事实之间存在很高的Spearman排名相关性和低的p值。我们提出的迁移性框架需要较少的计算时间和资源，因此是一个节省资源、高效节省时间的微调方法。

    In this work, we introduce a ``score-based assessment'' framework for estimating the transferability of pre-trained speech models (PSMs) for fine-tuning target tasks. We leverage upon two representation theories, Bayesian likelihood estimation and optimal transport, to generate rank scores for the PSM candidates using the extracted representations. Our framework efficiently computes transferability scores without actual fine-tuning of candidate models or layers by making a temporal independent hypothesis. We evaluate some popular supervised speech models (e.g., Conformer RNN-Transducer) and self-supervised speech models (e.g., HuBERT) in cross-layer and cross-model settings using public data. Experimental results show a high Spearman's rank correlation and low $p$-value between our estimation framework and fine-tuning ground truth. Our proposed transferability framework requires less computational time and resources, making it a resource-saving and time-efficient approach for tuning sp
    
[^47]: 区域感知预训练：视觉变压器下的开放词汇物体检测

    Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers. (arXiv:2305.07011v1 [cs.CV])

    [http://arxiv.org/abs/2305.07011](http://arxiv.org/abs/2305.07011)

    本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。

    

    本文提出了区域感知开放词汇视觉变压器（RO-ViT），一种对比图像-文本预训练方法，旨在填补图像级预训练和开放词汇物体检测之间的差距。在预训练阶段，我们建议随机裁剪并调整位置嵌入的区域，而不是使用整个图像位置嵌入。这更好地匹配了检测微调阶段中区域级别上使用位置嵌入的方式。此外，我们用聚焦损失替换了对比学习中常用的softmax交叉熵损失，以更好地学习那些有信息量但难以捕捉的例子。最后，我们利用了最近在新颖物体提案方面的进展，以改进开放词汇检测的微调。我们在LVIS和COCO开放词汇检测基准上评估了完整模型和零-shot转移性能。RO-ViT在LVIS上实现了32.1$AP_r$的最佳效果，超过现有最佳方法5.8个百分点，同时还具有竞争性的零-shot转移检测结果。

    We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a contrastive image-text pretraining recipe to bridge the gap between image-level pretraining and open-vocabulary object detection. At the pretraining phase, we propose to randomly crop and resize regions of positional embeddings instead of using the whole image positional embeddings. This better matches the use of positional embeddings at region-level in the detection finetuning phase. In addition, we replace the common softmax cross entropy loss in contrastive learning with focal loss to better learn the informative yet difficult examples. Finally, we leverage recent advances in novel object proposals to improve open-vocabulary detection finetuning. We evaluate our full model on the LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer. RO-ViT achieves a state-of-the-art 32.1 $AP_r$ on LVIS, surpassing the best existing approach by +5.8 points in addition to competitive zero-shot transfer detec
    
[^48]: TMR:使用对比3D人体运动合成的文本到运动检索

    TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis. (arXiv:2305.00976v1 [cs.CV])

    [http://arxiv.org/abs/2305.00976](http://arxiv.org/abs/2305.00976)

    本文介绍了一种名为TMR的方法，用于将文本转换为3D人体运动。它在先前的工作中取得了明显的优势，并通过引入对比性损失的方法来更好地建立跨模态潜在空间结构。结果表明，保持运动生成损失和对比性训练至关重要。

    

    本文提出了一种名为TMR的简单而有效的方法，用于将文本转换为3D人体运动。与之前的工作仅将检索视为代理评估指标不同，我们将其作为一个独立的任务来解决。我们的方法扩展了最先进的文本到动作合成模型TEMOS，并结合对比损失来更好地构造跨模态的潜在空间。我们表明保持运动生成损失和对比性训练至关重要，以获得良好的性能。我们引入了一个基准来进行评估，并通过报告几个协议的结果进行了深入分析。我们在KIT-ML和HumanML3D数据集上进行的广泛实验表明，TMR比先前的工作表现出明显的优势，例如将中位数排名从54降至19。最后，我们展示了我们方法在时刻检索方面的潜力。我们的代码和模型是公开可用的。

    In this paper, we present TMR, a simple yet effective approach for text to 3D human motion retrieval. While previous work has only treated retrieval as a proxy evaluation metric, we tackle it as a standalone task. Our method extends the state-of-the-art text-to-motion synthesis model TEMOS, and incorporates a contrastive loss to better structure the cross-modal latent space. We show that maintaining the motion generation loss, along with the contrastive training, is crucial to obtain good performance. We introduce a benchmark for evaluation and provide an in-depth analysis by reporting results on several protocols. Our extensive experiments on the KIT-ML and HumanML3D datasets show that TMR outperforms the prior work by a significant margin, for example reducing the median rank from 54 to 19. Finally, we showcase the potential of our approach on moment retrieval. Our code and models are publicly available.
    
[^49]: CryCeleb: 基于婴儿哭声的说话人认证数据集

    CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds. (arXiv:2305.00969v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2305.00969](http://arxiv.org/abs/2305.00969)

    CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。

    

    本文描述了Ubenwa CryCeleb数据集——一个标记的婴儿哭声收集，以及附带的CryCeleb 2023任务——一个基于婴儿哭声的公共说话人验证挑战。我们释放出786名新生儿超过6小时的手动分割哭声，以鼓励婴儿哭声分析方面的研究。

    This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.
    
[^50]: PMC-LLaMA: 在医学论文中进行LLaMA的进一步微调

    PMC-LLaMA: Further Finetuning LLaMA on Medical Papers. (arXiv:2304.14454v1 [cs.CL])

    [http://arxiv.org/abs/2304.14454](http://arxiv.org/abs/2304.14454)

    本文介绍了一个针对医学领域进一步微调的开源语言模型PMC-LLaMA，其通过增加医学知识提高了在生物医学领域的性能表现，有望在生物医学问答领域有更好的应用表现。

    

    大型语言模型(LLM)在各个领域的自然语言理解方面具有出色的能力。这些模型通常在日常对话或问答场景中表现良好，然而，在注重精度的领域，例如医疗应用中，它们往往表现出不尽人意的性能，原因是缺乏特定领域的知识。在本文中，我们介绍了PMC-LLaMA，这是一种开源的语言模型，通过在总共480万篇生物医学论文上微调开源语言模型，以进一步注入医学知识，增强其在医学领域的能力。我们进行了初步评估，包括PubMedQA、MedMCQA和USMLE等三个生物医学问答数据集，结果显示，我们的模型经过微调后，即PMC-LLaMA，对生物医学领域的特定概念有更好的理解，因此在问答基准测试中取得了较高的性能。该模型和代码以及在线演示均可在https://github.com/cstorm125/pmc-llama上找到。

    Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding in various domains. These models can usually behave well on daily dialog, or question answering scenarios, however, in areas that value precision, for example, in medical applications, they often exhibit unsatisfactory performance due to a lack of domain-specific knowledge. In this report, we introduce PMC-LLaMA, an open-source language model that is acquired by fine-tuning an open-source language model on a total of 4.8 million biomedical academic papers for further injecting medical knowledge, enhancing its capability in medical domain. Our preliminary evaluations are conducted on three biomedical QA datasets, including PubMedQA, MedMCQA, and USMLE, showing that the our model after finetuning, i.e., PMC-LLaMA, demonstrates better understanding of biomedical domain-specific concepts, thus achieving high performance on QA benchmarks. The model and codes, along with an online demo, are 
    
[^51]: 利用提示来近似人类对社交Chatbot的评估

    Approximating Human Evaluation of Social Chatbots with Prompting. (arXiv:2304.05253v1 [cs.CL])

    [http://arxiv.org/abs/2304.05253](http://arxiv.org/abs/2304.05253)

    该论文提出了一种利用提示来评估社交Chatbot的新方法，可以近似人类对Chatbot的主观评估，而不需要人类准备评估材料。

    

    随着强大的对话模型逐渐面向广大用户开放，用户开始积极地与这种技术进行社交互动。除非技术得到适当的控制，这种前所未有的交互体验可能会对用户造成相当大的社交和心理风险。这就需要可扩展和强大的评估指标来评估社交Chatbot。现有的自动评估指标通常关注客观质量指标，忽略社交维度的主观感受。此外，大多数这些方法都基于可用基准数据集中预生成的对话，这意味着需要人类参与准备评估材料，因此影响了指标的可扩展性。为了解决这个问题，我们提出利用来自GPT系列的新兴大型语言模型(LLM)并描述了一种新的框架，允许进行提示式的对话系统评估。通过这个框架，我们可以通过关注主观评价标准来近似人类对社交Chatbot的评估。通过使用GPT-3，该框架可以应用于各种各样的对话模型，并且不需要任何人类输入来准备评估材料。我们通过对四种不同的对话模型进行一系列彻底的实验，并分析了框架的优缺点，证明了我们方法的有效性。

    Once powerful conversational models have become available for a wide audience, users started actively engaging in social interactions with this technology. Such unprecedented interaction experiences may pose considerable social and psychological risks to the users unless the technology is properly controlled. This creates an urgent need for scalable and robust evaluation metrics for conversational chatbots. Existing automatic evaluation metrics usually focus on objective quality measures and disregard subjective perceptions of social dimensions. Moreover, most of these approaches operate on pre-produced dialogs from available benchmark corpora, which implies human involvement for preparing the material for evaluation and, thus, impeded scalability of the metrics. To address this limitation, we propose to make use of the emerging large language models (LLMs) from the GPT-family and describe a new framework allowing to conduct dialog system evaluation with prompting. With this framework,
    
[^52]: ViewRefer: 基于GPT和样例引导的多视角知识处理的三维视觉定位

    ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance. (arXiv:2303.16894v1 [cs.CV])

    [http://arxiv.org/abs/2303.16894](http://arxiv.org/abs/2303.16894)

    本文提出了ViewRefer，这是一个多视角的三维视觉定位框架，利用大规模语言模型和多视角原型，从文本和3D模态中获取视角知识并增强框架的表现。

    

    通过利用多视角输入的3D场景，可以缓解3D视觉定位中的视角差异问题。然而，现有方法通常忽略了嵌入在文本模态中的视角线索，并且未能权衡不同视图的相对重要性。本文提出了ViewRefer，这是一个多视角的三维视觉定位框架，探索如何从文本和3D模态中获取视角知识。其中，ViewRefer利用大规模语言模型（例如GPT）的多样化语言知识，将单一的定位文本扩展为多个几何一致的描述；同时，在3D模态中，引入了基于Transformer的融合模块和视图间注意力，以增强视图之间物体的交互。此外，还提出了一组可学习的多视角原型，用于记忆不同视角下的场景无关知识，从两个方面增强了框架。

    Understanding 3D scenes from multi-view inputs has been proven to alleviate the view discrepancy issue in 3D visual grounding. However, existing methods normally neglect the view cues embedded in the text modality and fail to weigh the relative importance of different views. In this paper, we propose ViewRefer, a multi-view framework for 3D visual grounding exploring how to grasp the view knowledge from both text and 3D modalities. For the text branch, ViewRefer leverages the diverse linguistic knowledge of large-scale language models, e.g., GPT, to expand a single grounding text to multiple geometry-consistent descriptions. Meanwhile, in the 3D modality, a transformer fusion module with inter-view attention is introduced to boost the interaction of objects across views. On top of that, we further present a set of learnable multi-view prototypes, which memorize scene-agnostic knowledge for different views, and enhance the framework from two perspectives: a view-guided attention module 
    
[^53]: 在仙境与仙境之间的启示工程中插入格林童话：中途旅程来说明童话故事

    Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales. (arXiv:2302.08961v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08961](http://arxiv.org/abs/2302.08961)

    通过插入格林童话和基于现有文本的启示工程，我们探讨了文本到图像生成和启示工程的可行性，提出了一个4阶段的启示工程过程，并讨论了生成模型在某些插图上的困难。

    

    文本到图像生成的质量不断提高，但其适用范围的界限仍不清楚。特别是，以改进文本输入以实现更好结果为目标的启示工程，似乎尚未针对与现有文本一起工作进行研究。我们研究了文本到图像生成和启示工程是否可以用于生成流行童话的基本插图。使用Midjourney v4，我们进行了行动研究，旨在尝试为5个流行童话中的每个童话生成5个令人信服的插图，并确定一个从现有文本到插图的启示工程过程。我们得出了一个初步的4阶段过程：i）初始提示，ii）构图调整，iii）风格细化，和iv）变异选择。我们还讨论了生成模型在某些插图上遇到困难的三个原因：计数困难，

    The quality of text-to-image generation is continuously improving, yet the boundaries of its applicability are still unclear. In particular, refinement of the text input with the objective of achieving better results - commonly called prompt engineering - so far seems to have not been geared towards work with pre-existing texts. We investigate whether text-to-image generation and prompt engineering could be used to generate basic illustrations of popular fairytales. Using Midjourney v4, we engage in action research with a dual aim: to attempt to generate 5 believable illustrations for each of 5 popular fairytales, and to define a prompt engineering process that starts from a pre-existing text and arrives at an illustration of it. We arrive at a tentative 4-stage process: i) initial prompt, ii) composition adjustment, iii) style refinement, and iv) variation selection. We also discuss three reasons why the generation model struggles with certain illustrations: difficulties with counts, 
    
[^54]: 基于语法的基础词汇学习

    Grammar-Based Grounded Lexicon Learning. (arXiv:2202.08806v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.08806](http://arxiv.org/abs/2202.08806)

    基于语法的基础词汇学习（G2L2）是一种从基础数据中学习语言含义表示的方法，通过将单词映射到语法类型和神经符号语义程序，利用基于语法的组合推导句子的含义，最终可以在基础输入上执行。

    

    我们提出了一种基于语法的基础词汇学习方法（G2L2），用于从基础数据（如图像和文本的配对）中学习语言的组合和基于基础的含义表示。G2L2的核心是一组词汇条目，将每个单词映射到一个语法类型和神经符号语义程序的元组。给定一个输入句子，G2L2首先查找与每个标记相关联的词汇条目。然后通过基于语法的组合词汇含义来推导句子的含义作为可执行的神经符号程序。恢复的含义程序可以在基础输入上执行。为了在指数级增长的组合空间中促进学习，我们引入了一种基于逻辑回归的channel pruning方法。

    We present Grammar-Based Grounded Lexicon Learning (G2L2), a lexicalist approach toward learning a compositional and grounded meaning representation of language from grounded data, such as paired images and texts. At the core of G2L2 is a collection of lexicon entries, which map each word to a tuple of a syntactic type and a neuro-symbolic semantic program. For example, the word shiny has a syntactic type of adjective; its neuro-symbolic semantic program has the symbolic form {\lambda}x. filter(x, SHINY), where the concept SHINY is associated with a neural network embedding, which will be used to classify shiny objects. Given an input sentence, G2L2 first looks up the lexicon entries associated with each token. It then derives the meaning of the sentence as an executable neuro-symbolic program by composing lexical meanings based on syntax. The recovered meaning programs can be executed on grounded inputs. To facilitate learning in an exponentially-growing compositional space, we introd
    
[^55]: G\"odel的本体论证的简化变体

    A Simplified Variant of G\"odel's Ontological Argument. (arXiv:2202.06264v3 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2202.06264](http://arxiv.org/abs/2202.06264)

    本论文提出了G\"odel的本体论证的简化变体，该变体在基本模态逻辑K或KT中已经是有效的，避免了复杂的谓词，并且展示了人机交互在计算形而上学中的应用。

    

    提出了G\"odel的本体论证的简化变体。这个简化的论证在基本模态逻辑K或KT中已经是有效的，它不会遭受模态崩溃，并且避免了G\"odel所使用的相当复杂的本质（Ess.）和必然存在（NE）的谓词。所提出的变体是通过与现代证明助理系统交互进行一系列理论简化实验的副产物。这些实验的起点是G\"odel论证的计算机编码，然后系统地应用自动推理技术来得到所展示的简化变体。所呈现的工作因此展示了计算形而上学中富有成果的人机交互。这个展示结果是否增加或减少了本体论证的吸引力和说服力，是一个我想交给哲学和神学讨论的问题。

    A simplified variant of G\"odel's ontological argument is presented. The simplified argument is valid already in basic modal logics K or KT, it does not suffer from modal collapse, and it avoids the rather complex predicates of essence (Ess.) and necessary existence (NE) as used by G\"odel. The variant presented has been obtained as a side result of a series of theory simplification experiments conducted in interaction with a modern proof assistant system. The starting point for these experiments was the computer encoding of G\"odel's argument, and then automated reasoning techniques were systematically applied to arrive at the simplified variant presented. The presented work thus exemplifies a fruitful human-computer interaction in computational metaphysics. Whether the presented result increases or decreases the attractiveness and persuasiveness of the ontological argument is a question I would like to pass on to philosophy and theology.
    
[^56]: 基于图的推荐系统在社区检测中的增强

    Graph-Based Recommendation System Enhanced with Community Detection. (arXiv:2201.03622v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2201.03622](http://arxiv.org/abs/2201.03622)

    本文提出了一个基于图的推荐系统，利用数学和统计方法确定标签的相似性，包括词汇相似性和共现解决方案，并考虑了标签分配的时间，以提高推荐的准确性。

    

    许多研究者已经利用标签信息来改善推荐系统中推荐技术的性能。通过研究用户的标签，可以了解他们的兴趣，从而提高推荐的准确性。然而，由于用户自定义标签的任意性和缺乏限制，确定其确切含义和标签之间的相似性存在问题。本文利用数学和统计方法确定标签的词汇相似性和共现解决方案，以分配语义相似性。另外，考虑到用户兴趣随时间变化，本文还在共现标签中考虑了标签分配的时间以确定标签的相似性。然后，基于标签的相似性创建图形模型来建模用户的兴趣。

    Many researchers have used tag information to improve the performance of recommendation techniques in recommender systems. Examining the tags of users will help to get their interests and leads to more accuracy in the recommendations. Since user-defined tags are chosen freely and without any restrictions, problems arise in determining their exact meaning and the similarity of tags. However, using thesaurus and ontologies to find the meaning of tags is not very efficient due to their free definition by users and the use of different languages in many data sets. Therefore, this article uses mathematical and statistical methods to determine lexical similarity and co-occurrence tags solution to assign semantic similarity. On the other hand, due to the change of users' interests over time this article has considered the time of tag assignments in co-occurrence tags for determining similarity of tags. Then the graph is created based on similarity of tags. For modeling the interests of the us
    

