# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning to Trust Your Feelings: Leveraging Self-awareness in LLMs for Hallucination Mitigation.](http://arxiv.org/abs/2401.15449) | 该论文评估了大型语言模型（LLMs）辨别和表达其内部知识状态的能力。研究发现LLMs具有自我意识的内部知识状态，并提出了一个强化学习训练框架来增强模型的事实性和诚实性。 |
| [^2] | [Pre-training and Diagnosing Knowledge Base Completion Models.](http://arxiv.org/abs/2401.15439) | 本论文介绍了一种无需实体或关系匹配的知识迁移方法，可以利用大规模预训练事实改进对特定领域结构化数据的预测。在小数据集上取得了显著的提高，尽管没有依赖于大型预训练模型。 |
| [^3] | [Indexing Portuguese NLP Resources with PT-Pump-Up.](http://arxiv.org/abs/2401.15400) | 本文介绍了PT-Pump-Up，一套旨在提高葡萄牙语自然语言处理资源可访问性的工具，并包括了一个Web平台、一个客户端Python软件包、一个管理平台的管理Python软件包和一个公共GitHub存储库。 |
| [^4] | [Semantics of Multiword Expressions in Transformer-Based Models: A Survey.](http://arxiv.org/abs/2401.15393) | 该研究调查了使用Transformer模型处理多词表达式的语义问题。结果显示，这些模型在捕捉MWE语义方面存在一致性问题，并且MWE的含义主要集中在体系结构的早期层中。这个发现对于Transformer模型是否能够可靠捕捉细粒度语义提出了质疑。 |
| [^5] | [MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries.](http://arxiv.org/abs/2401.15391) | 本论文提出了一个用于多跳查询的检索增强生成（RAG）的基准测试，通过在大型语言模型中检索相关知识来提高响应质量。通过构建MultiHop-RAG数据集，该数据集包含知识库、多个多跳查询、真实答案和支持证据，展示了该基准测试的实用性。 |
| [^6] | [Towards Event Extraction from Speech with Contextual Clues.](http://arxiv.org/abs/2401.15385) | 本文引入了语音事件提取任务，并通过引入序列到结构生成和条件生成方法来解决从语音中提取语义事件的挑战，取得了良好的效果。 |
| [^7] | [A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM.](http://arxiv.org/abs/2401.15378) | 基于RAG的MufassirQAS问答系统利用NLP技术建立联系并准确回答复杂问题，提高了LLMs的准确性和透明度，帮助理解伊斯兰教的复杂性和教义深度。 |
| [^8] | [LegalDuet: Learning Effective Representations for Legal Judgment Prediction through a Dual-View Legal Clue Reasoning.](http://arxiv.org/abs/2401.15371) | LegalDuet是一种通过双视角法律线索推理模型，使用预训练语言模型学习定制嵌入空间来进行法律判决预测。该模型通过法律案例推理和法律基础推理两个推理链进行判决。在实验中，LegalDuet在CAIL2018数据集上表现出最先进的性能，并超过了基线模型。 |
| [^9] | [Importance-Aware Data Augmentation for Document-Level Neural Machine Translation.](http://arxiv.org/abs/2401.15360) | 本论文提出了一种新颖的基于标记重要性信息的文档级神经机器翻译数据增强算法，通过计算隐藏状态和训练梯度的范数来增强训练数据。实验证明，该算法在句级和文档级BLEU上优于强大的基线和几种数据增强方法。 |
| [^10] | [A Survey on Neural Topic Models: Methods, Applications, and Challenges.](http://arxiv.org/abs/2401.15351) | 这篇综述调研了神经主题模型的方法、应用和挑战，对于短文本和跨语言文档等各种场景提供了系统性的组织和介绍，并讨论了广泛应用的一系列热门应用。 |
| [^11] | [A Comprehensive Survey of Compression Algorithms for Language Models.](http://arxiv.org/abs/2401.15347) | 这篇论文是关于语言模型压缩算法的综合调查，讨论了如何在不损失准确性的情况下压缩语言模型。通过对多种压缩算法的调查和分析，总结了各个算法的整体趋势和价值。 |
| [^12] | [Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance.](http://arxiv.org/abs/2401.15328) | 在金融数据分析领域，通过为语言模型添加工具使用能力，我们成功解决了大型语言模型在处理异构金融数据和保证精度时所面临的挑战，并取得了显著的改进。 |
| [^13] | [UNSEE: Unsupervised Non-contrastive Sentence Embeddings.](http://arxiv.org/abs/2401.15316) | UNSEE是一种无监督的非对比度句子嵌入方法，通过引入目标网络解决了表示坍塌问题，达到了与对比目标相当的性能提升。 |
| [^14] | [How We Refute Claims: Automatic Fact-Checking through Flaw Identification and Explanation.](http://arxiv.org/abs/2401.15312) | 本文介绍了一种新的自动化事实检验方法，通过缺陷识别和解释来解决现实世界传言和欺骗性主张的复杂问题。引入了RefuteClaim框架，并提出了创新的FlawCheck数据集。实验结果证明了RefuteClaim在分类和阐明虚假主张方面的有效性。 |
| [^15] | [Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models.](http://arxiv.org/abs/2401.15269) | 本论文介绍了一种名为Self-BioRAG的框架，通过使用检索和自我反思的方法，提高了医疗推理的能力。该框架专注于生成解释、检索领域特定文档以及对生成的响应进行自我反思。 |
| [^16] | [Unlearning Reveals the Influential Training Data of Language Models.](http://arxiv.org/abs/2401.15241) | 本文提出了一种简单而有效的方法UnTrac，通过反学习训练数据集来估计语言模型的影响。实验结果表明，UnTrac能够准确评估预训练数据集对生成有害内容的影响，并且无需额外的资源。 |
| [^17] | [Transfer Learning for the Prediction of Entity Modifiers in Clinical Text: Application to Opioid Use Disorder Case Detection.](http://arxiv.org/abs/2401.15222) | 本研究提出了一种使用多任务学习和迁移学习的方法，在临床文本中预测实体修饰语。实验结果表明，该方法在公开数据集和新数据集上均取得了最新技术的结果。 |
| [^18] | [Scalable Qualitative Coding with LLMs: Chain-of-Thought Reasoning Matches Human Performance in Some Hermeneutic Tasks.](http://arxiv.org/abs/2401.15170) | 本研究证明了大型语言模型在定性编码中的应用潜力。相比于GPT-3.5，GPT-4能够实现与人类相当的解释能力，并具有较高的编码一致性。无论模型规模大小，只要满足一定条件，模型都可以实现较高的编码准确性。 |
| [^19] | [The Power of Noise: Redefining Retrieval for RAG Systems.](http://arxiv.org/abs/2401.14887) | 本研究通过分析和评估检索增强生成（RAG）系统中的信息检索（IR）组件，填补了目前研究中忽视的领域，在有效的RAG的提示表述中，不相关文档的包含可能会对系统性能产生负面影响。 |
| [^20] | [MaLLaM -- Malaysia Large Language Model.](http://arxiv.org/abs/2401.14680) | MaLLaM是马来西亚大型语言模型，通过使用大型数据集和预训练的BPE分词器，在马来语的自然语言理解和生成任务中取得了竞争力，并展示了在捕捉和理解马来西亚语言细微差异方面的有效性，为提升自然语言理解和生成打下了基础。 |
| [^21] | [Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement.](http://arxiv.org/abs/2401.14215) | 本文提出了一个旨在解决长期对话中角色句子不具信息性的问题的框架，通过利用常识增强的角色扩展，并设计策略将相互矛盾的角色转化为包含丰富说话者信息的句子，以提高回应生成质量。 |
| [^22] | [BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction.](http://arxiv.org/abs/2401.14166) | BayesPrompt通过无偏领域抽象解决大规模预训练语言模型在少样本推理中的泛化问题。 |
| [^23] | [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models.](http://arxiv.org/abs/2401.13919) | WebVoyager是一种创新的基于大型多模态模型的Web代理，能够通过与真实网站交互来端到端地完成用户指令。它提出了一个新的Web代理评估协议，并在实际任务中取得了显著的成功率。 |
| [^24] | [Investigating the Efficacy of Large Language Models for Code Clone Detection.](http://arxiv.org/abs/2401.13802) | 这项研究探索了大型语言模型在代码克隆检测任务中的应用。 |
| [^25] | [Large Malaysian Language Model Based on Mistral for Enhanced Local Language Understanding.](http://arxiv.org/abs/2401.13565) | 本文介绍了Mistral 7B大规模语言模型在马来西亚语言数据集上的预训练进展和性能优化，证明了继续预训练和扩展上下文长度对提升语言理解能力的有效性，并对比了其在Tatabahasa上的优越性能。 |
| [^26] | [Can AI Assistants Know What They Don't Know?.](http://arxiv.org/abs/2401.13275) | 本文研究了AI助手是否能知道自己不知道的事情，并通过自然语言表达出来的问题。为了回答这个问题，我们构建了一个特定模型的"I don't know"（Idk）数据集，并与AI助手进行对齐。 |
| [^27] | [Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource Languages.](http://arxiv.org/abs/2401.13165) | 本章论文研究了低资源语言中机器翻译中的性别相关错误，以孟加拉语为例，讨论了性别的假设和推断，以及这些错误导致的后殖民和社会影响。同时提出了提升语言地位的潜在解决方案。 |
| [^28] | [Improving Small Language Models' Mathematical Reasoning via Equation-of-Thought Distillation.](http://arxiv.org/abs/2401.11864) | 本研究提出了思维方程蒸馏（EoTD）技术和集合思维蒸馏（ETD）框架，通过构建基于方程的表示和使用多个思维过程的推理数据集来改进小型语言模型（SLMs）的数学推理能力，实验结果表明，EoTD和ETD显著提升了SLMs的推理能力。 |
| [^29] | [Location Sensitive Embedding for Knowledge Graph Embedding.](http://arxiv.org/abs/2401.10893) | 这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。 |
| [^30] | [Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment.](http://arxiv.org/abs/2401.10768) | 本文提出了一种称为知识一致性对齐（KCA）的方法，通过减少训练数据中外部知识和预训练语料库中内在知识之间的不一致性，从而缓解了大型语言模型产生幻觉的问题。实验结果表明，KCA方法在多个基准测试中取得了优异的性能。 |
| [^31] | [Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering.](http://arxiv.org/abs/2401.10711) | 本论文提出了一种使用大型多模型的弱监督高斯对比基础模型来处理视频问答问题的方法。通过将问题和答案对作为事件描述，找到多个关键帧作为目标时刻，并利用这些时刻作为伪标签来强制LMMs进行推理。所提出的方法使用轻量级的基于高斯的对比基础模块（GCG）来学习时效结构。 |
| [^32] | [Knowledge graph driven recommendation model of graph neural network.](http://arxiv.org/abs/2401.10244) | 提出了一种基于知识图谱的图神经网络推荐模型KGLN，通过合并节点特征、调整聚合权重和迭代演化，提高了个性化推荐的准确性和效果。在实验中相对于已有基准方法，KGLN在不同数据集上的AUC提高了0.3%至5.9%和1.1%至8.2%。 |
| [^33] | [Semantic Parsing for Question Answering over Knowledge Graphs.](http://arxiv.org/abs/2401.06772) | 本文介绍了一种新的方法，利用图到段映射来实现问题回答知识图谱。该方法侧重于语义解析，解决了理解问题中的隐含实体、关系和复杂约束的挑战。通过结合规则和神经网络技术，构建了高精度和全面的语义段序列，实现了问题陈述的有效表示。 |
| [^34] | [Text Classification Based on Knowledge Graphs and Improved Attention Mechanism.](http://arxiv.org/abs/2401.03591) | 该论文介绍了一种基于知识图谱和改进的注意机制的文本分类模型，通过将知识图谱与注意机制相结合，解决了文本中的语义歧义问题，并通过局部注意机制和双向门控循环单元实现了更好的分类效果。 |
| [^35] | [Rule-Guided Joint Embedding Learning of Knowledge Graphs.](http://arxiv.org/abs/2401.02968) | 本文介绍了一种新型模型，该模型将上下文和字面信息容纳到实体和关系的嵌入中，利用图卷积网络，并通过规则和字面信息的表示计算置信度和相关性指标，以提高知识图谱嵌入学习的效果。 |
| [^36] | [TEILP: Time Prediction over Knowledge Graphs via Logical Reasoning.](http://arxiv.org/abs/2312.15816) | 这篇论文提出了一个名为TEILP的逻辑推理框架，用于在知识图谱中进行时间预测。通过将知识图谱转换为时间事件知识图谱，并使用可微分的随机游走方法和条件概率密度函数，该方法在时间预测方面取得了显著的改进。 |
| [^37] | [Knowledge Graph Enhanced Aspect-Level Sentiment Analysis.](http://arxiv.org/abs/2312.10048) | 本文提出了一种知识图谱增强的方面级情感分析方法，通过使用BERT模型和知识图谱的同义词数据，在解决上下文特定词义的挑战上取得了优越的性能。 |
| [^38] | [A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints.](http://arxiv.org/abs/2312.03905) | 本论文提出了一种针对具有逻辑约束的自回归模型的伪语义损失方法，通过在模型输出的局部近似上优化约束的似然，提高了神经符号学习的效率和适用性。 |
| [^39] | [MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs.](http://arxiv.org/abs/2312.03731) | 本文提出了一种名为MultiGPrompt的多任务预训练和提示框架，用于在图形表示学习中提高鲁棒性和减少标注成本。 |
| [^40] | [Automatic Functional Differentiation in JAX.](http://arxiv.org/abs/2311.18727) | 我们在JAX中扩展了自动微分功能，使其能够自动微分高阶函数，通过引入一组原始算子，我们实现了函数微分的线性化和转置规则，并展示了该工具在函数导数应用中的效果和简单性。 |
| [^41] | [Dynamic Fault Characteristics Evaluation in Power Grid.](http://arxiv.org/abs/2311.16522) | 该论文提出了一种在电力系统中进行故障检测的新方法，通过图神经网络识别故障节点，并利用前后时间段内节点的状态来辅助当前故障检测。实验证明该方法准确可靠，并提供了对故障节点传播的定性分析。 |
| [^42] | [Automatic Time Signature Determination for New Scores Using Lyrics for Latent Rhythmic Structure.](http://arxiv.org/abs/2311.15480) | 本文提出了一种新颖的方法，通过仅使用歌词作为输入，自动生成适合歌词歌曲的节拍记号，并揭示潜在的节奏结构。 |
| [^43] | [Dynamic Fault Analysis in Substations Based on Knowledge Graphs.](http://arxiv.org/abs/2311.13708) | 提出了一种基于知识图谱的变电站动态故障分析方法，利用非结构化文本提取相关信息，通过隐藏马尔科夫模型训练数据，利用Neo4j图数据库创建知识图谱，实现对变电站中隐藏危险的可视化分析。 |
| [^44] | [Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization.](http://arxiv.org/abs/2311.09335) | 本文通过广泛的实证研究发现，修剪后的大型语言模型在抽象摘要任务中产生幻觉的情况较原始模型要少，表现更可靠，具有更高的效率和稀疏推理能力。 |
| [^45] | [Knowledge Graph Construction in Power Distribution Networks.](http://arxiv.org/abs/2311.08724) | 本文提出了一种在电力分配网络中构建知识图谱的方法，该方法利用实体特征，在分配网络的知识图谱和分配文本中进行匹配，通过实验证明了其在电力分配知识图谱构建任务中的高准确性。 |
| [^46] | [A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual Question Answering.](http://arxiv.org/abs/2311.07536) | 本论文对知识密集型视觉问答中的GPT-4V进行了全面评估，从常识知识、细粒度的世界知识和全面知识与决策理据三个方面对其能力进行了深入考察。 |
| [^47] | [Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs.](http://arxiv.org/abs/2311.04892) | 这项研究首次广泛研究了Persona分配对LLMs执行基本推理任务能力的意外副作用。实验证明，LLMs虽然在明确要求时拒绝刻板印象，但在扮演特定角色时会表现出刻板印象和错误的假设。 |
| [^48] | [Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction.](http://arxiv.org/abs/2311.04507) | 本论文提出了一个名为CORECT的神经网络框架，通过关系时态图神经网络和辅助跨模态交互的方式有效地捕捉对话中的情感信息。 |
| [^49] | [GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling.](http://arxiv.org/abs/2311.01927) | GateLoop是一种完全数据控制的线性递归序列模型，优于现有模型，可以提供数据控制的相对位置信息给Attention。 |
| [^50] | [An Open Source Data Contamination Report for Large Language Models.](http://arxiv.org/abs/2310.17589) | 本文介绍了一个针对大型语言模型的开源数据污染报告，其中包括超过15个热门模型对六个常见多项选择问答基准测试的污染分析。实验证明，数据污染会显著降低模型性能，并且随着时间的推移污染程度不断增加。 |
| [^51] | [Establishing Vocabulary Tests as a Benchmark for Evaluating Large Language Models.](http://arxiv.org/abs/2310.14703) | 本论文主张将词汇测试作为评估大型语言模型性能的重要工具，在评估七个LLM模型时发现了它们在词汇知识方面存在差距，并探讨了LLM词汇表示、学习机制和性能变化的细节。自动生成和执行词汇测试为扩展这一方法提供了新的机会。 |
| [^52] | [Reconstructing Materials Tetrahedron: Challenges in Materials Information Extraction.](http://arxiv.org/abs/2310.08383) | 本论文讨论了从材料科学文献中自动提取信息面临的挑战，并希望能够创建一个大型的材料科学知识库。 |
| [^53] | [BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations.](http://arxiv.org/abs/2310.07276) | BioT5是一个全面的预训练框架，在生物学中利用化学知识和自然语言关联丰富了跨模态整合，通过鲁棒的分子表示和上下文知识提取，实现了更有效的信息利用，展现出卓越的性能。 |
| [^54] | [Low-Resource Languages Jailbreak GPT-4.](http://arxiv.org/abs/2310.02446) | 通过翻译不安全的英文输入成低资源语言，我们成功绕过了GPT-4的安全机制，并展示了这种跨语言漏洞。这一方法在实验中取得了与甚至超过了最先进的越狱攻击的效果，揭示了低资源语言在AI安全性中的薄弱环节。 |
| [^55] | [Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs.](http://arxiv.org/abs/2310.01801) | 该研究提出了一种自适应的KV缓存压缩方法，用于减少大型语言模型的内存消耗。通过有针对性的分析和结构识别，构建了具有自适应性的KV缓存，通过清除和丢弃特定的上下文，以及只对特定的注意力头使用标准KV缓存，实现了显著的内存占用减少。 |
| [^56] | [Syllable-level lyrics generation from melody exploiting character-level language model.](http://arxiv.org/abs/2310.00863) | 该论文提出了一种利用字符级语言模型从旋律中生成音节级歌词的方法，并通过融合语言模型知识和生成器网络进行优化。通过探索ChatGPT的评估方法，以及人工评估，证明了该方法提高了生成歌词的连贯性和正确性。 |
| [^57] | [Towards LLM-guided Causal Explainability for Black-box Text Classifiers.](http://arxiv.org/abs/2309.13340) | 本文提出了一种利用大型语言模型（LLM）引导黑盒文本分类器的因果可解释性的方法，通过生成反事实解释来解决这一挑战。 |
| [^58] | [Media of Langue.](http://arxiv.org/abs/2309.08609) | 该论文介绍了《Media of Langue》这一全新词典和公共雕塑，通过描述不同语言之间的意义地图和两个力量之间的边界，重点介绍了三个新的概念：《Inter-Langue Map/Dictionary》、《Inter-Langue Space》和《Inter-Langue Network》。 |
| [^59] | [Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding.](http://arxiv.org/abs/2309.07098) | 本文介绍了一种通过源对比和语言对比解码来解决机器翻译中幻觉和偏离目标的问题的方法，实验证明这些方法能有效地抑制幻觉和偏离目标的翻译。 |
| [^60] | [How does representation impact in-context learning: A exploration on a synthetic task.](http://arxiv.org/abs/2309.06054) | 本研究通过探索表示学习的角度，研究了表示对上下文学习的影响。实验结果表明，在上下文学习中，上下文内部成分对学习性能起到重要作用。 |
| [^61] | [Manifold-based Verbalizer Space Re-embedding for Tuning-free Prompt-based Classification.](http://arxiv.org/abs/2309.04174) | 本研究提出了一种无需调参的基于流形的语言转换器嵌入方法，通过保留同一类中的局部特性来进行分类，实验证明其与自动化的语言转换器效果相当。 |
| [^62] | [A Study on Robustness and Reliability of Large Language Model Code Generation.](http://arxiv.org/abs/2308.10335) | 本研究针对大型语言模型生成的代码的可靠性和鲁棒性进行了研究，发现在真实的软件开发中可执行的代码并不能保证可靠和鲁棒，滥用API可能导致严重问题。这对初级开发者来说尤其危险，因为他们很难察觉到代码中的API滥用问题。 |
| [^63] | [Learning the meanings of function words from grounded language using a visual question answering model.](http://arxiv.org/abs/2308.08628) | 本研究通过研究基于视觉问答模型学习到的功能词的意义，旨在更好地了解模型和儿童如何学习这些词汇。研究发现，在以视觉为基础的语言上训练的递归模型能够学习到需要空间和数字推理的功能词的梯度语义，并且可以在没有逻辑推理先验知识的情况下学习到"和"和"或"的意义，以及迅速发展出替换推论的能力的早期证据。 |
| [^64] | [Leveraging Large Language Models for Mental Health Prediction via Online Text Data.](http://arxiv.org/abs/2307.14385) | 本研究首次对多种大型语言模型在心理健康预测任务上进行了全面评估，结果表明指令微调可以显著提升模型性能，并且最优微调模型在平衡准确度上胜过GPT-3.5，并与最先进的任务特定模型持平。 |
| [^65] | [Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models.](http://arxiv.org/abs/2307.12896) | 本文的创新是基于Hapax Rate模型引入了对Zipf和Heaps定律的修正，并发现逻辑模型拟合效果最优。 |
| [^66] | [Measuring the Robustness of Natural Language Processing Models to Domain Shifts.](http://arxiv.org/abs/2306.00168) | 本文探讨了自然领域转移设置下微调和小样本学习模型的DR挑战，引入了一个DR基准，提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），并发现两者之一通常是正值，强调了评估DR挑战的两个视角的重要性。 |
| [^67] | [Give Me More Details: Improving Fact-Checking with Latent Retrieval.](http://arxiv.org/abs/2305.16128) | 该论文提出了一种利用潜在检索来改进事实核查的方法。通过将源文档的全文作为证据，并引入多语言和单语言数据集，该系统能够提供足够的上下文线索，即使没有注释的黄金证据句子，也能进行准确的主张验证，并且在不同的设置下实现了显著的改进。 |
| [^68] | [ConvGQR: Generative Query Reformulation for Conversational Search.](http://arxiv.org/abs/2305.15645) | 本文提出了一种新的面向会话搜索的ConvGQR框架，通过结合预训练语言模型来重新构造查询，从而提供更好的搜索查询。 |
| [^69] | [mPLM-Sim: Unveiling Better Cross-Lingual Similarity and Transfer in Multilingual Pretrained Language Models.](http://arxiv.org/abs/2305.13684) | mPLM-Sim是一种新的语言相似度测量方法，利用多语言平行语料库从mPLMs中引导出语言之间的相似性，可用于选择源语言以增强跨语言迁移，具有中等程度的相关性。不同的mPLMs和层产生不同的相似性结果。 |
| [^70] | [CEO: Corpus-based Open-Domain Event Ontology Induction.](http://arxiv.org/abs/2305.13521) | 本文介绍了一种名为CEO的事件本体诱导模型，它可以放松预定义事件本体所强加的限制，通过远程监督检测整个语料库中显著的事件，并诱导具有有意义名称的分层事件本体，实验结果表明，其诱导的模式具有更好的覆盖范围和更高的准确性。 |
| [^71] | [EnCore: Fine-Grained Entity Typing by Pre-Training Entity Encoders on Coreference Chains.](http://arxiv.org/abs/2305.12924) | 本文提出了EnCore模型，通过预训练实体编码器并使用谨慎筛选的共指链接，提高了细粒度实体类型标注的性能。 |
| [^72] | [Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach.](http://arxiv.org/abs/2305.11789) | 本研究提出了一种基于讨论的方法，旨在通过人机协作解决自然语言处理难题。提出了一个可以进行对话并修正预测的系统，通过实验证明该系统可以通过与人类的讨论提高准确性高达25%。 |
| [^73] | [Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.](http://arxiv.org/abs/2305.10163) | 本研究通过在ChatGPT中集成医学领域知识和启用少样本学习的新方法，在中国国家医学执业医师资格考试中取得成功，这为建立在自然语言处理技术和医学领域知识的创新应用提供了可能。 |
| [^74] | [Towards Building the Federated GPT: Federated Instruction Tuning.](http://arxiv.org/abs/2305.05644) | 本文提出了一种名为Federated Instruction Tuning (FedIT)的新方法，利用联邦学习（FL）模型对LLMs进行指令调整，以解决获取高质量指令数据的挑战，从而提高调整模型的通用性和效果。 |
| [^75] | [LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions.](http://arxiv.org/abs/2304.14402) | 本文提出的LaMini-LM是一种基于大规模指令的多样性压缩模型群集，从指令微调过的LLMs中提取知识到更小的模型中，其在15个不同的NLP基准测试中与其他竞争基线的表现相当，但体积约小了10倍。 |
| [^76] | [Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning.](http://arxiv.org/abs/2304.01295) | 本文提出了一个平行大规模多语种会话数据集XSGD，开发了一种有效的基于提示调整的方法来学习对齐提示，同时研究了跨语言任务的NLI-based和vanilla分类器，并在插槽填充和意图分类任务上评估了模型的跨语言泛化能力。 |
| [^77] | [Like a Good Nearest Neighbor: Practical Content Moderation and Text Classification.](http://arxiv.org/abs/2302.08957) | 我们提出了一种名为LaGoNN的修改方法，该方法在不引入可学习参数的情况下，通过使用训练数据中最近邻的信息改变输入文本，从而使新颖的数据看起来类似于模型优化的实例。该方法对于标记不需要的内容和文本分类非常有效，并且改善了效果。 |
| [^78] | [Flexible, Model-Agnostic Method for Materials Data Extraction from Text Using General Purpose Language Models.](http://arxiv.org/abs/2302.04914) | 本文提出了一个灵活的、模型无关的方法，使用通用语言模型从研究论文中提取材料数据。该方法几乎不需要编码或模型训练，并且在生成的数据库中具有高召回率和几乎完美的精确度。 |
| [^79] | [Detecting Reddit Users with Depression Using a Hybrid Neural Network SBERT-CNN.](http://arxiv.org/abs/2302.02759) | 本论文介绍了一种混合神经网络模型，结合了预训练的SBERT和CNN，用于通过分析Reddit用户的帖子自动识别抑郁症患者。 |
| [^80] | [AutoPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2301.12132) | AutoPEFT是一个自动化的PEFT（参数高效微调）配置搜索方法，它能够自动地找到最佳的PEFT模块和体系结构，以优化任务的性能和参数效率。在典型的NLP任务中，AutoPEFT表现出比手动设计更好的性能。 |
| [^81] | [Compressing Transformer-based self-supervised models for speech processing.](http://arxiv.org/abs/2211.09949) | 本文研究了对基于Transformer的自监督模型进行压缩的方法，包括权重修剪、头部修剪、低秩逼近和知识蒸馏。结果发现，基本的压缩技术是强大的基准，可以改善模型的压缩效果。 |
| [^82] | [Graphemic Normalization of the Perso-Arabic Script.](http://arxiv.org/abs/2210.12273) | 本文记录了波斯-阿拉伯文字在自然语言处理中的挑战，包括使用外观上相似但规范上不等价的字母以及混合使用来自不同正字法的字母。对于这些挑战，本文提供了字形规范化的解决方案，并评估了其对不同方面的影响。 |
| [^83] | [On the Relation between Sensitivity and Accuracy in In-context Learning.](http://arxiv.org/abs/2209.07661) | 在上下文学习中，我们发现ICL对多种扰动类型具有敏感性，标签偏差导致过去的研究低估了ICL的敏感性。同时，我们观察到ICL的敏感性和准确性之间呈现负相关关系。基于这些发现，我们提出了一种少样本选择性预测方法SenSel，它在放弃敏感预测决策上取得了优于常用基准方法的结果。 |
| [^84] | [DiSCoMaT: Distantly Supervised Composition Extraction from Tables in Materials Science Articles.](http://arxiv.org/abs/2207.01079) | 本文提出了一个新型挑战任务，即通过远程监督方式从科学文章中的表格中提取有关材料组成的信息。为此，研究者创建了一个包含4408个远程监督表格和1475个手动注释的开发和测试表格的训练数据集，并提出了一个强基线——DiSCoMaT。 |
| [^85] | [MiniDisc: Minimal Distillation Schedule for Language Model Compression.](http://arxiv.org/abs/2205.14570) | 本研究提出了一个叫做MiniDisc的最小蒸馏计划，可以在最少一次尝试中调度最优的教师助手，用于实现语言模型压缩。 |
| [^86] | [Geographic Adaptation of Pretrained Language Models.](http://arxiv.org/abs/2203.08565) | 本文研究了预训练语言模型（PLMs）的地理适应性，通过多任务学习中的地理位置预测，成功地注入了地理语言知识，提升了模型在各项任务上的表现。 |

# 详细

[^1]: 学会相信你的感觉：利用自我意识在对抗LMM中减轻幻觉

    Learning to Trust Your Feelings: Leveraging Self-awareness in LLMs for Hallucination Mitigation. (arXiv:2401.15449v1 [cs.CL])

    [http://arxiv.org/abs/2401.15449](http://arxiv.org/abs/2401.15449)

    该论文评估了大型语言模型（LLMs）辨别和表达其内部知识状态的能力。研究发现LLMs具有自我意识的内部知识状态，并提出了一个强化学习训练框架来增强模型的事实性和诚实性。

    

    我们评估了大型语言模型（LLMs）辨别和表达其内部知识状态的能力，这是对抗事实性幻觉和确保LLMs可靠应用的关键因素。我们观察到LLMs具有稳健的内部知识状态的自我意识，通过超过85%的知识探索准确度来证明。然而，LLMs在生成过程中常常无法表达其内部知识，导致了事实幻觉的产生。我们开发了一个自动化幻觉标注工具"Dreamcatcher"，它将知识探测和一致性检查方法结合起来，对事实偏好数据进行排名。通过将知识偏好作为奖励，我们提出了一种从知识反馈中进行强化学习（RLKF）训练框架，利用强化学习增强LLMs的事实性和诚实性。我们在多个模型上进行的实验表明，RLKF训练有效地增强了模型利用其内部知识状态的能力，在多个方面提升了性能。

    We evaluate the ability of Large Language Models (LLMs) to discern and express their internal knowledge state, a key factor in countering factual hallucination and ensuring reliable application of LLMs. We observe a robust self-awareness of internal knowledge state in LLMs, evidenced by over 85% accuracy in knowledge probing. However, LLMs often fail to express their internal knowledge during generation, leading to factual hallucinations. We develop an automated hallucination annotation tool, Dreamcatcher, which merges knowledge probing and consistency checking methods to rank factual preference data. Using knowledge preference as reward, We propose a Reinforcement Learning from Knowledge Feedback (RLKF) training framework, leveraging reinforcement learning to enhance the factuality and honesty of LLMs. Our experiments across multiple models show that RLKF training effectively enhances the ability of models to utilize their internal knowledge state, boosting performance in a variety of
    
[^2]: Pre-training and Diagnosing Knowledge Base Completion Models. (arXiv:2401.15439v1 [cs.CL])

    Pre-training and Diagnosing Knowledge Base Completion Models. (arXiv:2401.15439v1 [cs.CL])

    [http://arxiv.org/abs/2401.15439](http://arxiv.org/abs/2401.15439)

    本论文介绍了一种无需实体或关系匹配的知识迁移方法，可以利用大规模预训练事实改进对特定领域结构化数据的预测。在小数据集上取得了显著的提高，尽管没有依赖于大型预训练模型。

    

    在这项工作中，我们介绍并分析了一种无需实体或关系匹配的知识迁移方法，该方法可将一个事实集合的知识转移到另一个事实集合中。该方法适用于规范化知识库和非规范化或开放式知识库，即可能存在多个实体或关系的知识库。主要贡献是一种方法，可以利用从非结构化文本中收集的大规模预训练事实，改进对特定领域结构化数据的预测。引入的方法在小数据集（如ReVerb20k）上产生了重大影响，尽管没有依赖于大型预训练模型如Bert，但平均倒数排名增加了6个百分点，平均排名相对减少了65%。为了更好地理解获得的预训练模型，我们还介绍了一种用于分析开放式知识库完成预训练模型的新数据集，称为...

    In this work, we introduce and analyze an approach to knowledge transfer from one collection of facts to another without the need for entity or relation matching. The method works for both canonicalized knowledge bases and uncanonicalized or open knowledge bases, i.e., knowledge bases where more than one copy of a real-world entity or relation may exist. The main contribution is a method that can make use of large-scale pre-training on facts, which were collected from unstructured text, to improve predictions on structured data from a specific domain. The introduced method is most impactful on small datasets such as ReVerb20k, where a 6% absolute increase of mean reciprocal rank and 65% relative decrease of mean rank over the previously best method was achieved, despite not relying on large pre-trained models like Bert. To understand the obtained pre-trained models better, we then introduce a novel dataset for the analysis of pre-trained models for Open Knowledge Base Completion, calle
    
[^3]: 使用PT-Pump-Up索引葡萄牙自然语言处理资源

    Indexing Portuguese NLP Resources with PT-Pump-Up. (arXiv:2401.15400v1 [cs.CL])

    [http://arxiv.org/abs/2401.15400](http://arxiv.org/abs/2401.15400)

    本文介绍了PT-Pump-Up，一套旨在提高葡萄牙语自然语言处理资源可访问性的工具，并包括了一个Web平台、一个客户端Python软件包、一个管理平台的管理Python软件包和一个公共GitHub存储库。

    

    自然语言处理(NLP)的最新进展与需要大量语料库的训练过程相关。由于资源分散和需要维护这些基础设施的在线和更新，访问这些数据通常不是一个简单的过程。由于缺乏数据和适当的资源管理基础设施，低资源和中资源语言（如葡萄牙语）在NLP方面的新发展往往受到限制。在这项工作中，我们提出了PT-Pump-Up，一套旨在减少资源分散并提高葡萄牙语自然语言处理资源可访问性的工具。我们的提议分为四个软件组件：a）一个列出可用资源的Web平台；b）一个客户端Python软件包，简化葡萄牙语NLP资源的加载；c）一个管理平台的管理Python软件包；d）一个公共GitHub存储库

    The recent advances in natural language processing (NLP) are linked to training processes that require vast amounts of corpora. Access to this data is commonly not a trivial process due to resource dispersion and the need to maintain these infrastructures online and up-to-date. New developments in NLP are often compromised due to the scarcity of data or lack of a shared repository that works as an entry point to the community. This is especially true in low and mid-resource languages, such as Portuguese, which lack data and proper resource management infrastructures. In this work, we propose PT-Pump-Up, a set of tools that aim to reduce resource dispersion and improve the accessibility to Portuguese NLP resources. Our proposal is divided into four software components: a) a web platform to list the available resources; b) a client-side Python package to simplify the loading of Portuguese NLP resources; c) an administrative Python package to manage the platform and d) a public GitHub rep
    
[^4]: 基于Transformer模型的多词表达式语义：一项调查

    Semantics of Multiword Expressions in Transformer-Based Models: A Survey. (arXiv:2401.15393v1 [cs.CL])

    [http://arxiv.org/abs/2401.15393](http://arxiv.org/abs/2401.15393)

    该研究调查了使用Transformer模型处理多词表达式的语义问题。结果显示，这些模型在捕捉MWE语义方面存在一致性问题，并且MWE的含义主要集中在体系结构的早期层中。这个发现对于Transformer模型是否能够可靠捕捉细粒度语义提出了质疑。

    

    多词表达式（MWEs）由多个词组成，具有可变的组合程度。因此，它们的含义难以建模，而且不清楚这个问题在多头注意力模型中的影响程度。针对这一空白，我们首次对使用Transformer模型处理MWE进行了深入调查。我们发现它们在捕捉MWE语义方面存在不一致性，以表面模式和记忆信息为依赖。MWE的含义也在体系结构的早期层中局部化。表示收益于特定的语言属性，例如目标表达式的较低语义异质性和歧义性。我们的调查结果总体上质疑Transformer模型对细粒度语义的可靠捕捉能力。此外，我们强调需要更直接可比的评估设置。

    Multiword expressions (MWEs) are composed of multiple words and exhibit variable degrees of compositionality. As such, their meanings are notoriously difficult to model, and it is unclear to what extent this issue affects transformer architectures. Addressing this gap, we provide the first in-depth survey of MWE processing with transformer models. We overall find that they capture MWE semantics inconsistently, as shown by reliance on surface patterns and memorized information. MWE meaning is also strongly localized, predominantly in early layers of the architecture. Representations benefit from specific linguistic properties, such as lower semantic idiosyncrasy and ambiguity of target expressions. Our findings overall question the ability of transformer models to robustly capture fine-grained semantics. Furthermore, we highlight the need for more directly comparable evaluation setups.
    
[^5]: MultiHop-RAG: 用于多跳查询的检索增强生成的基准测试

    MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries. (arXiv:2401.15391v1 [cs.CL])

    [http://arxiv.org/abs/2401.15391](http://arxiv.org/abs/2401.15391)

    本论文提出了一个用于多跳查询的检索增强生成（RAG）的基准测试，通过在大型语言模型中检索相关知识来提高响应质量。通过构建MultiHop-RAG数据集，该数据集包含知识库、多个多跳查询、真实答案和支持证据，展示了该基准测试的实用性。

    

    检索增强生成（RAG）通过检索相关知识来增强大型语言模型（LLM），在缓解LLM的幻觉和提高响应质量方面显示出有希望的潜力，从而促进了LLM在实践中的广泛应用。然而，我们发现现有的RAG系统在回答多跳查询方面不足，这需要检索和推理多个支持证据。此外，据我们所知，目前没有任何现有的RAG基准测试数据集专注于多跳查询。在本文中，我们开发了一个新颖的数据集MultiHop-RAG，它包括一个知识库、一个大型的多跳查询集合、它们的真实答案和相关的支持证据。我们详细介绍了构建数据集的过程，利用英语新闻文章数据集作为基本的RAG知识库。我们通过两个实验展示了MultiHop-RAG的基准测试实用性。第一个实验比较了不同的嵌入模型，用于生成答案展示

    Retrieval-augmented generation (RAG) augments large language models (LLM) by retrieving relevant knowledge, showing promising potential in mitigating LLM hallucinations and enhancing response quality, thereby facilitating the great adoption of LLMs in practice. However, we find that existing RAG systems are inadequate in answering multi-hop queries, which require retrieving and reasoning over multiple pieces of supporting evidence. Furthermore, to our knowledge, no existing RAG benchmarking dataset focuses on multi-hop queries. In this paper, we develop a novel dataset, MultiHop-RAG, which consists of a knowledge base, a large collection of multi-hop queries, their ground-truth answers, and the associated supporting evidence. We detail the procedure of building the dataset, utilizing an English news article dataset as the underlying RAG knowledge base. We demonstrate the benchmarking utility of MultiHop-RAG in two experiments. The first experiment compares different embedding models fo
    
[^6]: 从语言环境中提取事件的研究

    Towards Event Extraction from Speech with Contextual Clues. (arXiv:2401.15385v1 [cs.CL])

    [http://arxiv.org/abs/2401.15385](http://arxiv.org/abs/2401.15385)

    本文引入了语音事件提取任务，并通过引入序列到结构生成和条件生成方法来解决从语音中提取语义事件的挑战，取得了良好的效果。

    

    虽然基于文本的事件提取已成为一个活跃的研究领域，在许多领域已经取得了成功的应用，但直接从语音中提取语义事件是一个尚未探索的问题。本文介绍了语音事件提取（SpeechEE）任务，并构建了三个合成训练集和一个由人类朗读的测试集。与从文本中提取事件相比，SpeechEE主要由于连续且没有词边界的复杂语音信号而面临更大的挑战。此外，与可感知的声音事件不同，语义事件更加微妙，需要更深入的理解。为了解决这些挑战，我们引入了一种序列到结构生成的范式，可以以端到端的方式从语音信号中产生事件，并且提出了一种依赖语音识别转录作为语境线索的条件生成方法。我们进一步提议以扁平的格式表示事件，使输出更像自然语言。实验结果表明，我们的方法在语音事件提取任务上取得了很好的效果。

    While text-based event extraction has been an active research area and has seen successful application in many domains, extracting semantic events from speech directly is an under-explored problem. In this paper, we introduce the Speech Event Extraction (SpeechEE) task and construct three synthetic training sets and one human-spoken test set. Compared to event extraction from text, SpeechEE poses greater challenges mainly due to complex speech signals that are continuous and have no word boundaries. Additionally, unlike perceptible sound events, semantic events are more subtle and require a deeper understanding. To tackle these challenges, we introduce a sequence-to-structure generation paradigm that can produce events from speech signals in an end-to-end manner, together with a conditioned generation method that utilizes speech recognition transcripts as the contextual clue. We further propose to represent events with a flat format to make outputs more natural language-like. Our exper
    
[^7]: 基于RAG的理解伊斯兰教问题回答系统提案：MufassirQAS LLM

    A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM. (arXiv:2401.15378v1 [cs.CL])

    [http://arxiv.org/abs/2401.15378](http://arxiv.org/abs/2401.15378)

    基于RAG的MufassirQAS问答系统利用NLP技术建立联系并准确回答复杂问题，提高了LLMs的准确性和透明度，帮助理解伊斯兰教的复杂性和教义深度。

    

    学习和理解宗教存在复杂性和教义深度的挑战。问答机器人作为解决这些挑战的问题回答系统，可以帮助。LLM聊天机器人利用自然语言处理技术建立主题之间的联系，准确回答复杂问题。这些能力使其成为用于宗教启蒙的问题回答聊天机器人的理想选择。然而，LLM也有生成虚假信息的倾向，称为幻觉。聊天机器人的回答可能包含侮辱个人宗教信仰、跨宗派冲突和有争议或敏感的话题的内容。它需要避免这种情况，而不会宣扬仇恨言论或冒犯某些群体的人或他们的信仰。本研究使用基于向量数据库的检索增强生成（RAG）方法来提高LLMs的准确性和透明度。我们的问答系统称为"MufassirQAS"。我们创建了一个模型来评估该系统并证明其在解决宗教行业问题中的效果。

    There exist challenges in learning and understanding religions as the presence of complexity and depth of religious doctrines and teachings. Chatbots as question-answering systems can help in solving these challenges. LLM chatbots use NLP techniques to establish connections between topics and accurately respond to complex questions. These capabilities make it perfect to be used in enlightenment on religion as a question answering chatbot. However, LLMs also have a tendency to generate false information, known as hallucination. The responses of the chatbots can include content that insults personal religious beliefs, interfaith conflicts, and controversial or sensitive topics. It needs to avoid such cases without promoting hate speech or offending certain groups of people or their beliefs. This study uses a vector database-based Retrieval Augmented Generation (RAG) approach to enhance the accuracy and transparency of LLMs. Our question-answering system is called as "MufassirQAS". We cre
    
[^8]: LegalDuet: 通过双视角法律线索推理学习有效的法律判决预测表示

    LegalDuet: Learning Effective Representations for Legal Judgment Prediction through a Dual-View Legal Clue Reasoning. (arXiv:2401.15371v1 [cs.CL])

    [http://arxiv.org/abs/2401.15371](http://arxiv.org/abs/2401.15371)

    LegalDuet是一种通过双视角法律线索推理模型，使用预训练语言模型学习定制嵌入空间来进行法律判决预测。该模型通过法律案例推理和法律基础推理两个推理链进行判决。在实验中，LegalDuet在CAIL2018数据集上表现出最先进的性能，并超过了基线模型。

    

    大多数现有的法律判决预测（LJP）模型侧重于发现刑事事实描述中的法律线索。然而，在现实场景中，专业法官不仅需要吸收过去判决的法律案例经验，还依赖于从专业法律知识中学到的专业法律基础推理。本文提出了一种名为LegalDuet的模型，该模型预训练语言模型以学习用于进行法律判决的定制嵌入空间。它提出了一种双视角法律线索推理机制，由两个推理链组成：1）法律案例推理，根据从类比/混淆的法律案例中学到的判决经验进行法律判决；2）法律基础推理，通过匹配刑事案件和法律决定之间的法律线索。实验证明，LegalDuet在CAIL2018数据集上实现了最先进的性能，并且超过了基线模型。

    Most existing Legal Judgment Prediction (LJP) models focus on discovering the legal triggers in the criminal fact description. However, in real-world scenarios, a professional judge not only needs to assimilate the law case experience that thrives on past sentenced legal judgments but also depends on the professional legal grounded reasoning that learned from professional legal knowledge. In this paper, we propose a LegalDuet model, which pretrains language models to learn a tailored embedding space for making legal judgments. It proposes a dual-view legal clue reasoning mechanism, which derives from two reasoning chains of judges: 1) Law Case Reasoning, which makes legal judgments according to the judgment experiences learned from analogy/confusing legal cases; 2) Legal Ground Reasoning, which lies in matching the legal clues between criminal cases and legal decisions. Our experiments show that LegalDuet achieves state-of-the-art performance on the CAIL2018 dataset and outperforms bas
    
[^9]: 重要性感知数据增强用于文档级神经机器翻译

    Importance-Aware Data Augmentation for Document-Level Neural Machine Translation. (arXiv:2401.15360v1 [cs.CL])

    [http://arxiv.org/abs/2401.15360](http://arxiv.org/abs/2401.15360)

    本论文提出了一种新颖的基于标记重要性信息的文档级神经机器翻译数据增强算法，通过计算隐藏状态和训练梯度的范数来增强训练数据。实验证明，该算法在句级和文档级BLEU上优于强大的基线和几种数据增强方法。

    

    文档级神经机器翻译（DocNMT）旨在生成连贯且连贯的翻译，与其句级对应物相比。然而，由于其较长的输入长度和有限的训练数据可用性，DocNMT常常面临着数据稀疏性的挑战。为了克服这个问题，我们提出了一种新颖的基于标记重要性信息的文档级神经机器翻译数据增强（IADA）算法，该算法通过计算隐藏状态和训练梯度的范数来增强训练数据。我们在三个广泛使用的DocNMT基准测试集上进行了全面的实验证明。我们的实证结果表明，我们提出的IADA算法在句级和文档级BLEU上均优于强大的DocNMT基线和几种数据增强方法，具有统计学意义。

    Document-level neural machine translation (DocNMT) aims to generate translations that are both coherent and cohesive, in contrast to its sentence-level counterpart. However, due to its longer input length and limited availability of training data, DocNMT often faces the challenge of data sparsity. To overcome this issue, we propose a novel Importance-Aware Data Augmentation (IADA) algorithm for DocNMT that augments the training data based on token importance information estimated by the norm of hidden states and training gradients. We conduct comprehensive experiments on three widely-used DocNMT benchmarks. Our empirical results show that our proposed IADA outperforms strong DocNMT baselines as well as several data augmentation approaches, with statistical significance on both sentence-level and document-level BLEU.
    
[^10]: 关于神经主题模型的综述：方法、应用和挑战

    A Survey on Neural Topic Models: Methods, Applications, and Challenges. (arXiv:2401.15351v1 [cs.CL])

    [http://arxiv.org/abs/2401.15351](http://arxiv.org/abs/2401.15351)

    这篇综述调研了神经主题模型的方法、应用和挑战，对于短文本和跨语言文档等各种场景提供了系统性的组织和介绍，并讨论了广泛应用的一系列热门应用。

    

    主题模型几十年来一直被广泛应用于无监督方式下发现潜在主题和推断文档的主题比例。它们在文本分析和上下文推荐等各种应用中得到广泛应用。近年来，神经网络的崛起促成了一个新的研究领域——神经主题模型(NTMs)的出现。与传统的主题模型不同，NTMs直接优化参数，而不需要模型特定的推导。这使得NTMs具有更好的可扩展性和灵活性，吸引了大量的研究关注并产生了丰富的新方法和应用。在本文中，我们对神经主题模型的方法、应用和挑战进行了全面的调研。具体而言，根据网络结构系统地组织了当前NTM方法，并介绍了针对短文本和跨语言文档等各种场景的NTMs。我们还讨论了广泛应用的一系列热门应用。

    Topic models have been prevalent for decades to discover latent topics and infer topic proportions of documents in an unsupervised fashion. They have been widely used in various applications like text analysis and context recommendation. Recently, the rise of neural networks has facilitated the emergence of a new research field -- Neural Topic Models (NTMs). Different from conventional topic models, NTMs directly optimize parameters without requiring model-specific derivations. This endows NTMs with better scalability and flexibility, resulting in significant research attention and plentiful new methods and applications. In this paper, we present a comprehensive survey on neural topic models concerning methods, applications, and challenges. Specifically, we systematically organize current NTM methods according to their network structures and introduce the NTMs for various scenarios like short texts and cross-lingual documents. We also discuss a wide range of popular applications built 
    
[^11]: 关于语言模型压缩算法的综合调查

    A Comprehensive Survey of Compression Algorithms for Language Models. (arXiv:2401.15347v1 [cs.CL])

    [http://arxiv.org/abs/2401.15347](http://arxiv.org/abs/2401.15347)

    这篇论文是关于语言模型压缩算法的综合调查，讨论了如何在不损失准确性的情况下压缩语言模型。通过对多种压缩算法的调查和分析，总结了各个算法的整体趋势和价值。

    

    如何在不损失准确性的情况下压缩语言模型？语言模型的压缩算法数量正在快速增长，以从最近语言模型的显著进展中受益，而不会产生庞大语言模型的副作用，比如增加的碳排放和昂贵的维护费用。虽然许多压缩算法在压缩语言模型方面表现出色，但由于过多的算法，部分的难题在于捕捉新兴趋势并识别其基本概念。在本文中，我们对包括修剪、量化、知识蒸馏、低秩逼近、参数共享和高效架构设计在内的多种压缩算法进行了调查和总结。我们不仅总结了各种压缩算法的整体趋势，还选择了代表性算法，并对其进行了深入分析。我们讨论了每个类别的压缩算法的价值。

    How can we compress language models without sacrificing accuracy? The number of compression algorithms for language models is rapidly growing to benefit from remarkable advances of recent language models without side effects due to the gigantic size of language models, such as increased carbon emissions and expensive maintenance fees. While numerous compression algorithms have shown remarkable progress in compressing language models, it ironically becomes challenging to capture emerging trends and identify the fundamental concepts underlying them due to the excessive number of algorithms. In this paper, we survey and summarize diverse compression algorithms including pruning, quantization, knowledge distillation, low-rank approximation, parameter sharing, and efficient architecture design. We not only summarize the overall trend of diverse compression algorithms but also select representative algorithms and provide in-depth analyses of them. We discuss the value of each category of com
    
[^12]: 在金融数据分析中，为语言模型添加工具使用能力

    Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance. (arXiv:2401.15328v1 [cs.CL])

    [http://arxiv.org/abs/2401.15328](http://arxiv.org/abs/2401.15328)

    在金融数据分析领域，通过为语言模型添加工具使用能力，我们成功解决了大型语言模型在处理异构金融数据和保证精度时所面临的挑战，并取得了显著的改进。

    

    大型语言模型(LLMs)展示了一系列的推理能力，但在金融等专业领域中遇到了错误传播和产生幻觉等挑战，其中数据异构性和精度至关重要。为了克服这些限制，我们探索了语言模型通过外部工具增强能力，将某些推理步骤转移到更适合该任务的外部工具上，而不仅仅依赖LLM的内在能力。具体而言，我们使用金融领域的问答数据集，在LLaMA-2 13B Chat模型上进行有监督的微调，使其既充当“任务路由器”又充当“任务解决器”。该“任务路由器”动态将问题定向到LLM内部回答或通过工具集中的正确工具外部回答。我们的工具增强型SFT模型Raven相比基础模型和仅有SFT的基准模型分别提高了35.2%和5.06%，在竞争力方面具有很高的水平。

    Large language models (LLMs) have exhibited an array of reasoning capabilities but face challenges like error propagation and hallucination, particularly in specialised areas like finance, where data is heterogeneous, and precision is paramount. We explore the potential of language model augmentation with external tools to mitigate these limitations and offload certain reasoning steps to external tools that are more suited for the task, instead of solely depending on the LLM's inherent abilities. More concretely, using financial domain question-answering datasets, we apply supervised fine-tuning on a LLaMA-2 13B Chat model to act both as a 'task router' and 'task solver'. The 'task router' dynamically directs a question to either be answered internally by the LLM or externally via the right tool from the tool set. Our tool-equipped SFT model, Raven, demonstrates an improvement of 35.2% and 5.06% over the base model and SFT-only baselines, respectively, and is highly competitive with st
    
[^13]: UNSEE: 无监督的非对比度句子嵌入

    UNSEE: Unsupervised Non-contrastive Sentence Embeddings. (arXiv:2401.15316v1 [cs.CL])

    [http://arxiv.org/abs/2401.15316](http://arxiv.org/abs/2401.15316)

    UNSEE是一种无监督的非对比度句子嵌入方法，通过引入目标网络解决了表示坍塌问题，达到了与对比目标相当的性能提升。

    

    我们提出了一种名为UNSEE（Unsupervised Non-Contrastive Sentence Embeddings）的新方法，在大规模文本嵌入基准测试中超越了SimCSE。我们首先解决了SimCSE中替换对比目标为非对比目标时出现的表示坍塌挑战。为了解决这个问题，我们提出了一种称为目标网络的简单解决方案，有效地缓解了表示坍塌。目标网络的引入使我们能够利用非对比目标，在保持训练稳定性的同时实现与对比目标相当的性能提升。通过精心调整和优化，我们的方法在非对比度句子嵌入上达到了巅峰性能。这一全面的努力产生了出色的句子表示模型，展示了我们方法的有效性。

    We present UNSEE: Unsupervised Non-Contrastive Sentence Embeddings, a novel approach that outperforms SimCSE in the Massive Text Embedding benchmark. Our exploration begins by addressing the challenge of representation collapse, a phenomenon observed when contrastive objectives in SimCSE are replaced with non-contrastive objectives. To counter this issue, we propose a straightforward solution known as the target network, effectively mitigating representation collapse. The introduction of the target network allows us to leverage non-contrastive objectives, maintaining training stability while achieving performance improvements comparable to contrastive objectives. Our method has achieved peak performance in non-contrastive sentence embeddings through meticulous fine-tuning and optimization. This comprehensive effort has yielded superior sentence representation models, showcasing the effectiveness of our approach.
    
[^14]: 如何反驳主张：通过缺陷识别和解释进行自动事实检验。

    How We Refute Claims: Automatic Fact-Checking through Flaw Identification and Explanation. (arXiv:2401.15312v1 [cs.CL])

    [http://arxiv.org/abs/2401.15312](http://arxiv.org/abs/2401.15312)

    本文介绍了一种新的自动化事实检验方法，通过缺陷识别和解释来解决现实世界传言和欺骗性主张的复杂问题。引入了RefuteClaim框架，并提出了创新的FlawCheck数据集。实验结果证明了RefuteClaim在分类和阐明虚假主张方面的有效性。

    

    自动化事实检验是治理互联网内容的重要任务。尽管各种研究利用先进模型来解决这个问题，但在处理复杂的真实世界传言和欺骗性主张方面仍存在重大差距。为了解决这个挑战，本文探讨了基于缺陷的事实检验的新任务，包括方面生成和缺陷识别。我们还引入了RefuteClaim，一个专为这一任务设计的新框架。鉴于目前不存在合适的数据集，我们提出了FlawCheck，这是一个通过从专家评论中提取和转换见解而创建的数据集，以获取相关方面和已确定的缺陷。实验结果强调了RefuteClaim的有效性，特别是在分类和阐明虚假主张方面。

    Automated fact-checking is a crucial task in the governance of internet content. Although various studies utilize advanced models to tackle this issue, a significant gap persists in addressing complex real-world rumors and deceptive claims. To address this challenge, this paper explores the novel task of flaw-oriented fact-checking, including aspect generation and flaw identification. We also introduce RefuteClaim, a new framework designed specifically for this task. Given the absence of an existing dataset, we present FlawCheck, a dataset created by extracting and transforming insights from expert reviews into relevant aspects and identified flaws. The experimental results underscore the efficacy of RefuteClaim, particularly in classifying and elucidating false claims.
    
[^15]: 通过检索和自我反思改善医疗推理能力的检索增强型大型语言模型

    Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models. (arXiv:2401.15269v1 [cs.CL])

    [http://arxiv.org/abs/2401.15269](http://arxiv.org/abs/2401.15269)

    本论文介绍了一种名为Self-BioRAG的框架，通过使用检索和自我反思的方法，提高了医疗推理的能力。该框架专注于生成解释、检索领域特定文档以及对生成的响应进行自我反思。

    

    最近的专有大型语言模型（LLMs），例如GPT-4，在生物医学领域中解决了从多项选择题到长篇生成等多样化挑战的里程碑。为了解决LLMs编码知识无法处理的挑战，已经开发了各种检索增强生成（RAG）方法，通过从知识语料库中搜索文档并无条件或有选择地将其附加到LLMs的输入来进行生成。然而，将现有方法应用于不同领域特定问题时，出现了泛化能力差的问题，导致获取不正确的文档或做出不准确的判断。在本文中，我们介绍了一种可靠的医学文本框架Self-BioRAG，专门用于生成解释、检索领域特定文档和自我反思生成的响应。我们使用了84k个经过过滤的生物医学指令集来训练Self-BioRAG，它具备评估自己的基因

    Recent proprietary large language models (LLMs), such as GPT-4, have achieved a milestone in tackling diverse challenges in the biomedical domain, ranging from multiple-choice questions to long-form generations. To address challenges that still cannot be handled with the encoded knowledge of LLMs, various retrieval-augmented generation (RAG) methods have been developed by searching documents from the knowledge corpus and appending them unconditionally or selectively to the input of LLMs for generation. However, when applying existing methods to different domain-specific problems, poor generalization becomes apparent, leading to fetching incorrect documents or making inaccurate judgments. In this paper, we introduce Self-BioRAG, a framework reliable for biomedical text that specializes in generating explanations, retrieving domain-specific documents, and self-reflecting generated responses. We utilize 84k filtered biomedical instruction sets to train Self-BioRAG that can assess its gene
    
[^16]: 反学习揭示了语言模型的影响训练数据

    Unlearning Reveals the Influential Training Data of Language Models. (arXiv:2401.15241v1 [cs.CL])

    [http://arxiv.org/abs/2401.15241](http://arxiv.org/abs/2401.15241)

    本文提出了一种简单而有效的方法UnTrac，通过反学习训练数据集来估计语言模型的影响。实验结果表明，UnTrac能够准确评估预训练数据集对生成有害内容的影响，并且无需额外的资源。

    

    为了提高语言模型的性能，同时减少生成有害内容的风险，识别哪些训练数据集影响模型的输出至关重要。理想情况下，我们可以通过从训练中移除每个数据集来衡量其影响;然而，多次重新训练模型是非常昂贵的。本文提出了UnTrac，通过从训练模型中取消学习来估计训练数据集的影响。UnTrac非常简单; 通过梯度上升来取消学习每个训练数据集，并评估在取消学习后模型的预测发生了多大变化。我们经验性地研究了我们的方法是否能评估预训练数据集对生成有毒、有偏见和不真实内容的影响。实验结果表明，我们的方法比现有方法更准确地估计了它们的影响，同时不需要过多的内存空间或多个模型检查点。

    In order to enhance the performance of language models while mitigating the risks of generating harmful content, it is crucial to identify which training dataset affects the model's outputs. Ideally, we can measure the influence of each dataset by removing it from training; however, it is prohibitively expensive to retrain a model multiple times. This paper presents UnTrac, which estimates the influence of a training dataset by unlearning it from the trained model. UnTrac is extremely simple; each training dataset is unlearned by gradient ascent, and we evaluate how much the model's predictions change after unlearning. We empirically examine if our methods can assess the influence of pretraining datasets on generating toxic, biased, and untruthful content. Experimental results demonstrate that our method estimates their influence much more accurately than existing methods while requiring neither excessive memory space nor multiple model checkpoints.
    
[^17]: 在临床文本中预测实体修饰语的迁移学习：以阿片类物质使用障碍病例检测为应用

    Transfer Learning for the Prediction of Entity Modifiers in Clinical Text: Application to Opioid Use Disorder Case Detection. (arXiv:2401.15222v1 [cs.CL])

    [http://arxiv.org/abs/2401.15222](http://arxiv.org/abs/2401.15222)

    本研究提出了一种使用多任务学习和迁移学习的方法，在临床文本中预测实体修饰语。实验结果表明，该方法在公开数据集和新数据集上均取得了最新技术的结果。

    

    背景：从临床文本中提取的实体的语义可能会受到修饰语的显著改变，包括实体的否定、不确定性、条件性、严重性和主观性。现有的确定临床实体修饰语的模型涉及使用正则表达式或特征权重，这些权重是独立训练每个修饰语的。方法：我们开发并评估了一个多任务变换器架构设计，在公开可用的SemEval 2015任务14语料库和一个新的阿片类物质使用障碍（OUD）数据集上共同学习和预测修饰语，该数据集包含与SemEval共享的修饰语以及OUD特定的新修饰语。我们评估了我们的多任务学习方法与以前发表的系统的效果，并评估了仅共享部分临床修饰语时的临床实体修饰语的迁移学习的可行性。结果：我们的方法在来自SemEval 2015的ShARe语料库上取得了最新技术的结果。

    Background: The semantics of entities extracted from a clinical text can be dramatically altered by modifiers, including entity negation, uncertainty, conditionality, severity, and subject. Existing models for determining modifiers of clinical entities involve regular expression or features weights that are trained independently for each modifier.  Methods: We develop and evaluate a multi-task transformer architecture design where modifiers are learned and predicted jointly using the publicly available SemEval 2015 Task 14 corpus and a new Opioid Use Disorder (OUD) data set that contains modifiers shared with SemEval as well as novel modifiers specific for OUD. We evaluate the effectiveness of our multi-task learning approach versus previously published systems and assess the feasibility of transfer learning for clinical entity modifiers when only a portion of clinical modifiers are shared.  Results: Our approach achieved state-of-the-art results on the ShARe corpus from SemEval 2015 T
    
[^18]: LLMs实现可扩展的定性编码：思维链推理在某些解释学任务中能达到人类水平

    Scalable Qualitative Coding with LLMs: Chain-of-Thought Reasoning Matches Human Performance in Some Hermeneutic Tasks. (arXiv:2401.15170v1 [cs.CL])

    [http://arxiv.org/abs/2401.15170](http://arxiv.org/abs/2401.15170)

    本研究证明了大型语言模型在定性编码中的应用潜力。相比于GPT-3.5，GPT-4能够实现与人类相当的解释能力，并具有较高的编码一致性。无论模型规模大小，只要满足一定条件，模型都可以实现较高的编码准确性。

    

    定性编码或内容分析从文本中提取含义，以识别跨文本语料库的定量模式。最近，大型语言模型（LLMs）在解释能力方面的进展为自动化编码过程（对文本应用类别标签）提供了潜力，从而使人类研究人员能够专注于更有创造力的研究方面，同时将这些解释任务委托给人工智能。我们的案例研究包括对人文学研究具有代表性的密集段落的一组社会历史编码。我们发现GPT-4能够达到与人类相当的解释，而GPT-3.5则不能。与我们由人类获得的金标准相比，GPT-4在3个编码中具有优秀的编码一致性（Cohen's κ ≥ 0.79），在9个编码中有8个具有显著的一致性（κ ≥ 0.6）。相比之下，GPT-3.5在所有编码中表现不佳（mean(κ) = 0.34；max(κ) = 0.55）。重要的是，我们发现编码的准确性不受模型规模影响，在满足一定条件的情况下，较小的模型也可以实现较高的编码准确性。

    Qualitative coding, or content analysis, extracts meaning from text to discern quantitative patterns across a corpus of texts. Recently, advances in the interpretive abilities of large language models (LLMs) offer potential for automating the coding process (applying category labels to texts), thereby enabling human researchers to concentrate on more creative research aspects, while delegating these interpretive tasks to AI. Our case study comprises a set of socio-historical codes on dense, paragraph-long passages representative of a humanistic study. We show that GPT-4 is capable of human-equivalent interpretations, whereas GPT-3.5 is not. Compared to our human-derived gold standard, GPT-4 delivers excellent intercoder reliability (Cohen's $\kappa \geq 0.79$) for 3 of 9 codes, and substantial reliability ($\kappa \geq 0.6$) for 8 of 9 codes. In contrast, GPT-3.5 greatly underperforms for all codes ($mean(\kappa) = 0.34$; $max(\kappa) = 0.55$). Importantly, we find that coding fidelity
    
[^19]: 噪声的力量：重新定义RAG系统的检索

    The Power of Noise: Redefining Retrieval for RAG Systems. (arXiv:2401.14887v1 [cs.IR])

    [http://arxiv.org/abs/2401.14887](http://arxiv.org/abs/2401.14887)

    本研究通过分析和评估检索增强生成（RAG）系统中的信息检索（IR）组件，填补了目前研究中忽视的领域，在有效的RAG的提示表述中，不相关文档的包含可能会对系统性能产生负面影响。

    

    检索增强生成（RAG）系统相对于传统的大型语言模型（LLMs）代表了一个重大进步。RAG系统通过整合通过信息检索（IR）阶段检索的外部数据来增强其生成能力，克服了标准LLMs的限制，后者仅限于其预先训练的知识和有限的上下文窗口。这个领域的大部分研究主要集中在RAG系统内LLMs的生成方面。我们的研究填补了这一空白，通过全面而批判性地分析IR组件对RAG系统的影响。本文分析了一个检索器在有效的RAG的提示表述中应该具备的特征，重点关注应该检索哪种类型的文档。我们评估了各种因素，如文档与提示的相关性，它们的位置以及上下文中包含的数量。我们的发现揭示出，包含不相关的文档可能会…

    Retrieval-Augmented Generation (RAG) systems represent a significant advancement over traditional Large Language Models (LLMs). RAG systems enhance their generation ability by incorporating external data retrieved through an Information Retrieval (IR) phase, overcoming the limitations of standard LLMs, which are restricted to their pre-trained knowledge and limited context window. Most research in this area has predominantly concentrated on the generative aspect of LLMs within RAG systems. Our study fills this gap by thoroughly and critically analyzing the influence of IR components on RAG systems. This paper analyzes which characteristics a retriever should possess for an effective RAG's prompt formulation, focusing on the type of documents that should be retrieved. We evaluate various elements, such as the relevance of the documents to the prompt, their position, and the number included in the context. Our findings reveal, among other insights, that including irrelevant documents can
    
[^20]: MaLLaM -- 马来西亚大型语言模型

    MaLLaM -- Malaysia Large Language Model. (arXiv:2401.14680v1 [cs.CL])

    [http://arxiv.org/abs/2401.14680](http://arxiv.org/abs/2401.14680)

    MaLLaM是马来西亚大型语言模型，通过使用大型数据集和预训练的BPE分词器，在马来语的自然语言理解和生成任务中取得了竞争力，并展示了在捕捉和理解马来西亚语言细微差异方面的有效性，为提升自然语言理解和生成打下了基础。

    

    针对马来西亚语境下从头预训练的大型语言模型的不足，我们使用349GB的大型数据集（相当于90亿个标记），使用我们预训练的字节对编码（BPE）分词器，在1.1亿、30亿和50亿参数上训练了模型。MaLLaM在马来语的自然语言理解和生成任务中做出了贡献。尽管只是使用了90亿个标记的较小数据集进行了训练，我们经过指令调整的MaLLaM模型表现出了竞争力。与ChatGPT3.5和Malaysian Mistral相比，MaLLaM的指令调整模型展示了显著的熟练度，突出了我们方法在捕捉和理解马来西亚语言细微差异方面的有效性。MaLLaM模型在该领域中起到了重要作用，提供了与马来西亚语境紧密联系的全面语言表示。这项努力旨在为提升自然语言理解和生成铺平道路。

    Addressing the gap in Large Language Model pretrained from scratch with Malaysian context, We trained models with 1.1 billion, 3 billion, and 5 billion parameters on a substantial 349GB dataset, equivalent to 90 billion tokens based on our pretrained Byte Pair Encoding (BPE) tokenizer for a single epoch. MaLLaM contributes to enhanced natural language understanding and generation tasks in the Malay language. Although trained on a smaller dataset of 90 billion tokens, our instruction-tuned MaLLaM models perform competitively. When compared to ChatGPT3.5 and Malaysian Mistral, MaLLaM's instruction-tuned models demonstrate notable proficiency, underscoring the effectiveness of our approach in capturing and understanding the nuances of the Malaysian language. MaLLaM models mark a significant contribution to the field, providing comprehensive language representations grounded in Malaysian context. This endeavor aims to pave the way for enhanced natural language understanding and generation 
    
[^21]: 通过上下文感知个性化细化，增强长期对话中的常识增强性内存构建和管理

    Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement. (arXiv:2401.14215v1 [cs.CL])

    [http://arxiv.org/abs/2401.14215](http://arxiv.org/abs/2401.14215)

    本文提出了一个旨在解决长期对话中角色句子不具信息性的问题的框架，通过利用常识增强的角色扩展，并设计策略将相互矛盾的角色转化为包含丰富说话者信息的句子，以提高回应生成质量。

    

    在长期对话中，记忆和利用说话者的角色是生成回应的常见做法。然而，人工编写的数据集通常提供无信息的角色句子，这妨碍了回应质量。本文提出了一个新颖的框架，利用常识增强的角色扩展来解决长期对话中的这些问题。以前的工作侧重于不产生与其他角色相矛盾的角色，我们侧重于根据设计的策略，将相互矛盾的角色转化为包含丰富说话者信息的句子，以此来细化它们的上下文背景。作为多会话情境中角色扩展的先驱，我们的框架通过类人个性细化促进了更好的回应生成。

    Memorizing and utilizing speakers' personas is a common practice for response generation in long-term conversations. Yet, human-authored datasets often provide uninformative persona sentences that hinder response quality. This paper presents a novel framework that leverages commonsense-based persona expansion to address such issues in long-term conversation. While prior work focuses on not producing personas that contradict others, we focus on transforming contradictory personas into sentences that contain rich speaker information, by refining them based on their contextual backgrounds with designed strategies. As the pioneer of persona expansion in multi-session settings, our framework facilitates better response generation via human-like persona refinement. The supplementary video of our work is available at https://caffeine-15bbf.web.app/.
    
[^22]: BayesPrompt: 通过无偏领域抽象在少样本推理上指导大规模预训练语言模型

    BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction. (arXiv:2401.14166v1 [cs.CL])

    [http://arxiv.org/abs/2401.14166](http://arxiv.org/abs/2401.14166)

    BayesPrompt通过无偏领域抽象解决大规模预训练语言模型在少样本推理中的泛化问题。

    

    作为一种基于大规模预训练语言模型（PLMs）的新颖有效的微调范式，prompt-tuning旨在缩小下游任务与预训练目标之间的差距。虽然prompt-tuning在各种任务中取得了持续进展，但这种方法仍然存在一个持久的缺陷：prompt-tuning方法无法泛化到特定的少样本模式。从分布分析的角度来看，我们揭示了这一现象背后的内在问题是PLMs中包含过多的概念知识和目标下游领域的缩减知识，两者共同导致PLMs在普遍的知识嵌入空间中错误地定位与目标领域相对应的知识分布。为此，我们直观地探索了以无偏方式逼近下游任务的完整目标领域，并通过抽象这样的领域生成有区别的提示，从而提供了无歧义的信息。

    As a novel and effective fine-tuning paradigm based on large-scale pre-trained language models (PLMs), prompt-tuning aims to reduce the gap between downstream tasks and pre-training objectives. While prompt-tuning has yielded continuous advancements in various tasks, such an approach still remains a persistent defect: prompt-tuning methods fail to generalize to specific few-shot patterns. From the perspective of distribution analyses, we disclose that the intrinsic issues behind the phenomenon are the over-multitudinous conceptual knowledge contained in PLMs and the abridged knowledge for target downstream domains, which jointly result in that PLMs mis-locate the knowledge distributions corresponding to the target domains in the universal knowledge embedding space. To this end, we intuitively explore to approximate the unabridged target domains of downstream tasks in a debiased manner, and then abstract such domains to generate discriminative prompts, thereby providing the de-ambiguous
    
[^23]: WebVoyager：使用大型多模态模型构建端到端的Web Agent

    WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models. (arXiv:2401.13919v1 [cs.CL])

    [http://arxiv.org/abs/2401.13919](http://arxiv.org/abs/2401.13919)

    WebVoyager是一种创新的基于大型多模态模型的Web代理，能够通过与真实网站交互来端到端地完成用户指令。它提出了一个新的Web代理评估协议，并在实际任务中取得了显著的成功率。

    

    大型语言模型（LLMs）的进步引领了一个由真实世界中自主应用程序的发展所标志的新时代，推动了基于网络的高级代理的创新。现有的网络代理通常只处理一个输入模态，并且仅在简化的网络模拟器或静态的网络快照中进行评估，极大地限制了它们在真实场景中的适用性。为了填补这一差距，我们引入了WebVoyager，一种创新的基于大型多模态模型（LMM）的Web代理，通过与真实网站进行交互，能够端到端地完成用户指令。此外，我们提出了一个新的Web代理评估协议，以解决开放式Web代理任务的自动评估挑战，利用了GPT-4V的强大多模态理解能力。我们通过收集来自15个广泛使用的网站的真实世界任务来创建一个新的基准来评估我们的代理。我们展示了WebVoyager实现了55.7％的任务成功率，显著地.....

    The advancement of large language models (LLMs) leads to a new era marked by the development of autonomous applications in the real world, which drives innovation in the creation of advanced web-based agents. Existing web agents typically only handle one input modality and are evaluated only in simplified web simulators or static web snapshots, greatly limiting their applicability in real-world scenarios. To bridge this gap, we introduce WebVoyager, an innovative Large Multimodal Model (LMM) powered web agent that can complete user instructions end-to-end by interacting with real-world websites. Moreover, we propose a new evaluation protocol for web agents to address the challenges of automatic evaluation of open-ended web agent tasks, leveraging the robust multimodal comprehension capabilities of GPT-4V. We create a new benchmark by gathering real-world tasks from 15 widely used websites to evaluate our agents. We show that WebVoyager achieves a 55.7% task success rate, significantly 
    
[^24]: 研究大型语言模型在代码克隆检测方面的功效

    Investigating the Efficacy of Large Language Models for Code Clone Detection. (arXiv:2401.13802v1 [cs.SE])

    [http://arxiv.org/abs/2401.13802](http://arxiv.org/abs/2401.13802)

    这项研究探索了大型语言模型在代码克隆检测任务中的应用。

    

    大型语言模型（LLMs）在各种自然语言处理和软件工程任务中表现出了显著的成功，例如代码生成。LLMs主要在基于提示的零/少样本范式中被用于指导模型完成任务。本研究探索了LLMs在代码克隆检测（CCD）这一非生成任务中的适用性。

    Large Language Models (LLMs) have demonstrated remarkable success in various natural language processing and software engineering tasks, such as code generation. The LLMs are mainly utilized in the prompt-based zero/few-shot paradigm to guide the model in accomplishing the task. %\textbf{Goal:} GPT-based models are one of the popular ones studied for tasks such as code comment generation or test generation. These tasks are `generative' tasks. However, there is limited research on the usage of LLMs for `non-generative' tasks such as classification using the prompt-based paradigm. In this preliminary exploratory study, we investigated the applicability of LLMs for Code Clone Detection (CCD), a non-generative task. %\textbf{Method:} By building a mono-lingual and cross-lingual CCD dataset derived from CodeNet, we first investigated two different prompts using ChatGPT to detect \textcolor{black}{Type-4} code clones in Java-Java and Java-Ruby pairs in a zero-shot setting. We \textcolor{blac
    
[^25]: 基于Mistral的大规模马来西亚语言模型，提升本地语言理解能力

    Large Malaysian Language Model Based on Mistral for Enhanced Local Language Understanding. (arXiv:2401.13565v1 [cs.CL])

    [http://arxiv.org/abs/2401.13565](http://arxiv.org/abs/2401.13565)

    本文介绍了Mistral 7B大规模语言模型在马来西亚语言数据集上的预训练进展和性能优化，证明了继续预训练和扩展上下文长度对提升语言理解能力的有效性，并对比了其在Tatabahasa上的优越性能。

    

    本文提出了Mistral 7B的预训练的重要进展，使用了32.6GB的数据集，相当于11亿个标记。我们研究了扩展上下文长度的影响，发布了上下文长度为4096和32768的模型，并使用特定的16384上下文长度的指令调整模型，我们称之为马来西亚Mistral。我们的实验证明了继续预训练的有效性以及扩展上下文长度对Mistral 7B语言理解能力的影响。此外，我们发布了一个专门调整了16384上下文长度的模型，展示了其捕捉微妙语言细节的潜力。此外，我们的研究还对比了马来西亚Mistral与ChatGPT3.5和Claude 2等著名语言模型，并呈现了令人信服的结果表明马来西亚Mistral在Tatabahasa上的优越性能。

    In this paper, we present significant advancements in the pretraining of Mistral 7B, a large-scale language model, using a dataset of 32.6 GB, equivalent to 1.1 billion tokens. We explore the impact of extending the context length, releasing models with context lengths of 4096 and 32768 tokens, and further refining performance with a specialized 16384 context length instruction-tuned model, we called it Malaysian Mistral.  Our experiments demonstrate the efficacy of continue pretraining and the influence of extended context lengths on Mistral 7B's language understanding capabilities. Additionally, we release a model specifically tuned with a 16384 context length instruction, showcasing its potential for capturing nuanced language intricacies.  Furthermore, our research contributes to the benchmarking of Malaysian Mistral against prominent language models, including ChatGPT3.5 and Claude 2. We present compelling results indicating Malaysian Mistral's superior performance on Tatabahasa (
    
[^26]: AI助手是否能知道自己不知道的事情?

    Can AI Assistants Know What They Don't Know?. (arXiv:2401.13275v1 [cs.CL])

    [http://arxiv.org/abs/2401.13275](http://arxiv.org/abs/2401.13275)

    本文研究了AI助手是否能知道自己不知道的事情，并通过自然语言表达出来的问题。为了回答这个问题，我们构建了一个特定模型的"I don't know"（Idk）数据集，并与AI助手进行对齐。

    

    最近，基于大型语言模型（LLMs）的AI助手在对话、解决数学问题、编写代码和使用工具等许多任务中表现出令人惊讶的性能。尽管LLMs具有深入的世界知识，但在面对某些知识密集型任务（如开放领域问答）时仍然会出现事实错误。AI助手的这种不真实回答可能在实际应用中造成重大风险。我们认为，AI助手拒绝回答自己不知道的问题是减少幻觉和使助手真实的关键方法。因此，在本文中，我们提出问题“AI助手是否能知道自己不知道的事情，并通过自然语言表达出来？”为了回答这个问题，我们为助手构建了一个特定模型的“I don't know”(Idk)数据集，其中包含了已知和未知的问题，基于现有的开放领域问答数据集。然后我们将助手与其相应的Idk数据进行对齐。

    Recently, AI assistants based on large language models (LLMs) show surprising performance in many tasks, such as dialogue, solving math problems, writing code, and using tools. Although LLMs possess intensive world knowledge, they still make factual errors when facing some knowledge intensive tasks, like open-domain question answering. These untruthful responses from the AI assistant may cause significant risks in practical applications. We believe that an AI assistant's refusal to answer questions it does not know is a crucial method for reducing hallucinations and making the assistant truthful. Therefore, in this paper, we ask the question "Can AI assistants know what they don't know and express them through natural language?" To answer this question, we construct a model-specific "I don't know" (Idk) dataset for an assistant, which contains its known and unknown questions, based on existing open-domain question answering datasets. Then we align the assistant with its corresponding I
    
[^27]: 在处理低资源语言时，机器翻译中称呼错误和性别假设问题的研究

    Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource Languages. (arXiv:2401.13165v1 [cs.CL])

    [http://arxiv.org/abs/2401.13165](http://arxiv.org/abs/2401.13165)

    本章论文研究了低资源语言中机器翻译中的性别相关错误，以孟加拉语为例，讨论了性别的假设和推断，以及这些错误导致的后殖民和社会影响。同时提出了提升语言地位的潜在解决方案。

    

    本章论文针对低资源语言中机器翻译中的性别相关错误进行研究。我们首先解释了低资源语言的概念，并探讨了造成这种语言层级的社会和计算因素的不可分割性。通过对我们的母语孟加拉语进行案例研究，我们展示了当源文本中没有提供相应信息时，性别如何被假设和推断出来，并以高资源英语进行翻译。我们讨论了这些错误导致语言消失和表征伤害的后殖民和社会影响，并讨论了提升语言地位的潜在解决方案，以在机器翻译中赋予语言更多的权威性。

    This chapter focuses on gender-related errors in machine translation (MT) in the context of low-resource languages. We begin by explaining what low-resource languages are, examining the inseparable social and computational factors that create such linguistic hierarchies. We demonstrate through a case study of our mother tongue Bengali, a global language spoken by almost 300 million people but still classified as low-resource, how gender is assumed and inferred in translations to and from the high(est)-resource English when no such information is provided in source texts. We discuss the postcolonial and societal impacts of such errors leading to linguistic erasure and representational harms, and conclude by discussing potential solutions towards uplifting languages by providing them more agency in MT conversations.
    
[^28]: 通过思维方程蒸馏改进小型语言模型的数学推理能力

    Improving Small Language Models' Mathematical Reasoning via Equation-of-Thought Distillation. (arXiv:2401.11864v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.11864](http://arxiv.org/abs/2401.11864)

    本研究提出了思维方程蒸馏（EoTD）技术和集合思维蒸馏（ETD）框架，通过构建基于方程的表示和使用多个思维过程的推理数据集来改进小型语言模型（SLMs）的数学推理能力，实验结果表明，EoTD和ETD显著提升了SLMs的推理能力。

    

    本研究解决了将先进的大型语言模型（LLMs）的数学推理能力压缩到具有小于十亿参数的小型语言模型（SLMs）中的挑战，同时不损害性能。我们引入了一种新颖的思维方程蒸馏（EoTD）技术，将推理过程封装为基于方程的表示，构建了一个EoTD数据集来对SLMs进行微调。此外，我们提出了集合思维蒸馏（ETD）框架，以提升SLMs的推理性能。这包括创建一个包含多个思维过程（包括思维链、思维程序和思维方程）的推理数据集，并将其用于微调。我们的实验证明，EoTD显著提升了SLMs的推理能力，而ETD使这些模型实现了最先进的推理性能。

    This work addresses the challenge of democratizing advanced Large Language Models (LLMs) by compressing their mathematical reasoning capabilities into sub-billion parameter Small Language Models (SLMs) without compromising performance. We introduce Equation-of-Thought Distillation (EoTD), a novel technique that encapsulates the reasoning process into equation-based representations to construct an EoTD dataset for fine-tuning SLMs. Additionally, we propose the Ensemble Thoughts Distillation (ETD) framework to enhance the reasoning performance of SLMs. This involves creating a reasoning dataset with multiple thought processes, including Chain-of-Thought (CoT), Program-of-Thought (PoT), and Equation-of-Thought (EoT), and using it for fine-tuning. Our experimental findings demonstrate that EoTD significantly boosts the reasoning abilities of SLMs, while ETD enables these models to achieve state-of-the-art reasoning performance.
    
[^29]: 知识图谱嵌入的位置敏感嵌入

    Location Sensitive Embedding for Knowledge Graph Embedding. (arXiv:2401.10893v1 [cs.IR])

    [http://arxiv.org/abs/2401.10893](http://arxiv.org/abs/2401.10893)

    这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。

    

    知识图谱嵌入将知识图谱转化为连续的、低维度的空间，有助于推理和补全任务。该领域主要分为传统的距离模型和语义匹配模型。传统的距离模型面临的关键挑战是无法有效区分图谱中的“头实体”和“尾实体”。为了解决这个问题，提出了新颖的位置敏感嵌入（LSE）方法。LSE通过关系特定的映射修改头实体，将关系概念化为线性变换而不仅仅是平移。LSE的理论基础，包括其表示能力和与现有模型的联系，都进行了详细研究。一种更简化的变体LSEd利用对角矩阵进行变换以提高实用性能。在对四个大规模数据集进行链接预测的测试中，LSEd要么表现更好，要么具有竞争力。

    Knowledge graph embedding transforms knowledge graphs into a continuous, low-dimensional space, facilitating inference and completion tasks. This field is mainly divided into translational distance models and semantic matching models. A key challenge in translational distance models is their inability to effectively differentiate between 'head' and 'tail' entities in graphs. To address this, the novel location-sensitive embedding (LSE) method has been developed. LSE innovatively modifies the head entity using relation-specific mappings, conceptualizing relations as linear transformations rather than mere translations. The theoretical foundations of LSE, including its representational capabilities and its connections to existing models, have been thoroughly examined. A more streamlined variant, LSEd, employs a diagonal matrix for transformations to enhance practical efficiency. In tests conducted on four large-scale datasets for link prediction, LSEd either outperforms or is competitive
    
[^30]: 缓解大型语言模型的幻觉问题：通过知识一致性对齐

    Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment. (arXiv:2401.10768v1 [cs.CL])

    [http://arxiv.org/abs/2401.10768](http://arxiv.org/abs/2401.10768)

    本文提出了一种称为知识一致性对齐（KCA）的方法，通过减少训练数据中外部知识和预训练语料库中内在知识之间的不一致性，从而缓解了大型语言模型产生幻觉的问题。实验结果表明，KCA方法在多个基准测试中取得了优异的性能。

    

    虽然大型语言模型在对齐后在各种任务上表现出色，但它们仍可能产生与上下文或世界知识自信矛盾的响应，这被称为“幻觉”现象。本文展示了通过减少训练数据中的外部知识与预训练语料库中继承的内在知识之间的不一致性，可以缓解对齐中的幻觉问题。具体而言，我们引入了一种新颖的知识一致性对齐（KCA）方法，该方法通过根据外部知识自动制定考试来评估大型语言模型的理解能力。对于包含知识不一致性的数据，KCA实施了几种简单而高效的处理策略。我们通过使用不同背景和规模的大型语言模型在六个基准测试中展示了所提出的KCA方法在缓解幻觉方面的卓越性能。

    While Large Language Models (LLMs) have proven to be exceptional on a variety of tasks after alignment, they may still produce responses that contradict the context or world knowledge confidently, a phenomenon known as ``hallucination''. In this paper, we demonstrate that reducing the inconsistency between the external knowledge encapsulated in the training data and the intrinsic knowledge inherited in the pretraining corpus could mitigate hallucination in alignment. Specifically, we introduce a novel knowledge consistent alignment (KCA) approach, which involves automatically formulating examinations based on external knowledge for accessing the comprehension of LLMs. For data encompassing knowledge inconsistency, KCA implements several simple yet efficient strategies for processing. We illustrate the superior performance of the proposed KCA approach in mitigating hallucinations across six benchmarks using LLMs of different backbones and scales. Furthermore, we confirm the correlation 
    
[^31]: 使用大型多模型的弱监督高斯对比基础模型来处理视频问答问题

    Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering. (arXiv:2401.10711v1 [cs.CV])

    [http://arxiv.org/abs/2401.10711](http://arxiv.org/abs/2401.10711)

    本论文提出了一种使用大型多模型的弱监督高斯对比基础模型来处理视频问答问题的方法。通过将问题和答案对作为事件描述，找到多个关键帧作为目标时刻，并利用这些时刻作为伪标签来强制LMMs进行推理。所提出的方法使用轻量级的基于高斯的对比基础模块（GCG）来学习时效结构。

    

    视频问答（VideoQA）旨在基于观察到的视频信息回答自然语言问题。尽管大型多模型（LMMs）在图像语言理解和推理方面取得了近期的成功，但它们在处理视频问答方面还不足够，仅仅是将均匀采样的帧作为视觉输入，忽略了与问题相关的视觉线索。此外，现有的视频问答数据集中没有针对问题关键时间戳的人工注释。基于此，我们提出了一种新的弱监督框架，强制LMMs使用问题关键时刻作为视觉输入推理出答案。具体来说，我们将问题和答案对合并为事件描述，以找到多个关键帧作为目标时刻，这些时刻将作为伪标签。通过将这些伪标签作为额外的弱监督，我们设计了一个轻量级的基于高斯的对比基础模块（GCG）。GCG学习多个高斯函数来描述时效结构。

    Video Question Answering (VideoQA) aims to answer natural language questions based on the information observed in videos. Despite the recent success of Large Multimodal Models (LMMs) in image-language understanding and reasoning, they deal with VideoQA insufficiently by simply taking uniformly sampled frames as visual inputs, which ignores question-relevant visual clues. Moreover, there are no human annotations for question-critical timestamps in existing VideoQA datasets. In light of this, we propose a novel weakly supervised framework to enforce the LMMs to reason out the answers with question-critical moments as visual inputs. Specifically, we fuse the question and answer pairs as event descriptions to find multiple keyframes as target moments, which will be pseudo-labels. With these pseudo-labels as additionally weak supervision, we devise a lightweight Gaussian-based Contrastive Grounding (GCG) module. GCG learns multiple Gaussian functions to characterize the temporal structure o
    
[^32]: 基于知识图谱驱动的图神经网络推荐模型

    Knowledge graph driven recommendation model of graph neural network. (arXiv:2401.10244v1 [cs.IR])

    [http://arxiv.org/abs/2401.10244](http://arxiv.org/abs/2401.10244)

    提出了一种基于知识图谱的图神经网络推荐模型KGLN，通过合并节点特征、调整聚合权重和迭代演化，提高了个性化推荐的准确性和效果。在实验中相对于已有基准方法，KGLN在不同数据集上的AUC提高了0.3%至5.9%和1.1%至8.2%。

    

    提出了一种新的基于图神经网络的推荐模型KGLN，该模型利用知识图谱（KG）信息，提高了个性化推荐的准确性和效果。该模型首先利用单层神经网络将图中的个体节点特征合并，然后通过结合影响因素调整相邻实体的聚合权重。通过迭代，模型从单层逐渐演变为多层，使实体能够获取丰富的多阶关联实体信息。最后，将实体和用户的特征结合起来产生推荐分数。通过比较不同聚合方法和影响因素的效果，评估了模型的性能。在使用MovieLen-1M和Book-Crossing数据集进行测试时，KGLN相对于LibFM和D等已有基准方法，AUC（ROC曲线下的面积）提高了0.3%至5.9%和1.1%至8.2%。

    A new graph neural network-based recommendation model called KGLN, which leverages Knowledge Graph (KG) information, was developed to enhance the accuracy and effectiveness of personalized recommendations. This model begins by using a single-layer neural network to merge individual node features in the graph. It then adjusts the aggregation weights of neighboring entities by incorporating influence factors. The model evolves from a single layer to multiple layers through iteration, enabling entities to access extensive multi-order associated entity information. The final step involves integrating features of entities and users to produce a recommendation score. The model's performance was evaluated by comparing its effects on various aggregation methods and influence factors. In tests using the MovieLen-1M and Book-Crossing datasets, KGLN showed an AUC (Area Under the ROC curve) improvement of 0.3% to 5.9% and 1.1% to 8.2%, respectively, over established benchmark methods like LibFM, D
    
[^33]: 问题回答知识图谱的语义解析

    Semantic Parsing for Question Answering over Knowledge Graphs. (arXiv:2401.06772v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.06772](http://arxiv.org/abs/2401.06772)

    本文介绍了一种新的方法，利用图到段映射来实现问题回答知识图谱。该方法侧重于语义解析，解决了理解问题中的隐含实体、关系和复杂约束的挑战。通过结合规则和神经网络技术，构建了高精度和全面的语义段序列，实现了问题陈述的有效表示。

    

    本文介绍了一种新的方法，利用图到段映射来实现问题回答知识图谱。该方法侧重于语义解析，这是解释问题陈述的关键方法。挑战在于理解问题中的隐含实体、关系以及时间、排序和聚合等复杂约束，这些约束在知识图谱的背景下进行上下文处理。我们的框架采用了基于规则和基于神经网络的技术的组合，解析并构建了高精度和全面的语义段序列。这些序列形成语义查询图，有效地表示问题陈述。我们将问题语义解析作为一个序列生成任务，利用编码器-解码器神经网络将自然语言问题转化为语义段。此外，为了增强对隐含实体和关系的解析，我们结合了图神经网络。

    In this paper, we introduce a novel method with graph-to-segment mapping for question answering over knowledge graphs, which helps understanding question utterances. This method centers on semantic parsing, a key approach for interpreting these utterances. The challenges lie in comprehending implicit entities, relationships, and complex constraints like time, ordinality, and aggregation within questions, contextualized by the knowledge graph. Our framework employs a combination of rule-based and neural-based techniques to parse and construct highly accurate and comprehensive semantic segment sequences. These sequences form semantic query graphs, effectively representing question utterances. We approach question semantic parsing as a sequence generation task, utilizing an encoder-decoder neural network to transform natural language questions into semantic segments. Moreover, to enhance the parsing of implicit entities and relations, we incorporate a graph neural network that leverages t
    
[^34]: 基于知识图谱和改进的注意机制的文本分类

    Text Classification Based on Knowledge Graphs and Improved Attention Mechanism. (arXiv:2401.03591v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.03591](http://arxiv.org/abs/2401.03591)

    该论文介绍了一种基于知识图谱和改进的注意机制的文本分类模型，通过将知识图谱与注意机制相结合，解决了文本中的语义歧义问题，并通过局部注意机制和双向门控循环单元实现了更好的分类效果。

    

    为了解决文本中的语义歧义问题，我们提出了一个模型，创新地将知识图谱与改进的注意机制相结合。该模型利用现有知识库来丰富文本与相关的上下文概念的内容。该模型在字符和单词级别上操作，通过整合概念来加深其理解。我们首先采用信息增益来选择重要的单词。然后使用编码器-解码器框架对文本进行编码，同时包含相关的概念。局部注意机制调整每个概念的权重，在分类过程中减少无关或噪音概念的影响。我们改进了局部自注意机制中注意力分数的计算公式，确保在文本中出现频率不同的单词获得更高的注意力分数。最后，模型采用了双向门控循环单元（Bi-GRU），有效地从文本中提取特征以提高分类效果。

    To resolve the semantic ambiguity in texts, we propose a model, which innovatively combines a knowledge graph with an improved attention mechanism. An existing knowledge base is utilized to enrich the text with relevant contextual concepts. The model operates at both character and word levels to deepen its understanding by integrating the concepts. We first adopt information gain to select import words. Then an encoder-decoder framework is used to encode the text along with the related concepts. The local attention mechanism adjusts the weight of each concept, reducing the influence of irrelevant or noisy concepts during classification. We improve the calculation formula for attention scores in the local self-attention mechanism, ensuring that words with different frequencies of occurrence in the text receive higher attention scores. Finally, the model employs a Bi-directional Gated Recurrent Unit (Bi-GRU), which is effective in feature extraction from texts for improved classification
    
[^35]: 知识图谱的规则引导联合嵌入学习

    Rule-Guided Joint Embedding Learning of Knowledge Graphs. (arXiv:2401.02968v1 [cs.CL])

    [http://arxiv.org/abs/2401.02968](http://arxiv.org/abs/2401.02968)

    本文介绍了一种新型模型，该模型将上下文和字面信息容纳到实体和关系的嵌入中，利用图卷积网络，并通过规则和字面信息的表示计算置信度和相关性指标，以提高知识图谱嵌入学习的效果。

    

    在最近的研究中，关注点主要集中在增强知识图谱嵌入学习上，该学习将知识图谱中的实体和关系编码为低维向量空间。尽管当前模型主要考虑这些图谱的结构方面，但在知识图谱中存在着丰富的上下文和字面信息，可以用于更有效的嵌入学习。本文引入了一种新型模型，该模型将上下文和字面信息容纳到实体和关系的嵌入中，利用图卷积网络。具体地，对于上下文信息，我们通过置信度和相关性指标评估其重要性。我们开发了一种独特的基于规则的方法来计算置信度指标，并从字面信息的表示中得出相关性指标。我们通过对两个已建立的基准数据集进行详尽的实验证实了我们模型的性能。

    In recent studies, the focus has been on enhancing knowledge graph embedding learning, which encodes entities and relations in knowledge graphs into low-dimensional vector spaces. While current models mainly consider the structural aspects of these graphs, there's a wealth of contextual and literal information in knowledge graphs that can be utilized for more effective embeddings. This paper introduces a novel model that incorporates both contextual and literal information into entity and relation embeddings, utilizing graph convolutional networks. Specifically, for contextual information, we assess its significance through confidence and relatedness metrics. A unique rule-based method is developed to calculate the confidence metric, and the relatedness metric is derived from the literal information's representations. We validated our model's performance with thorough experiments on two established benchmark datasets.
    
[^36]: TEILP:通过逻辑推理在知识图谱上进行时间预测

    TEILP: Time Prediction over Knowledge Graphs via Logical Reasoning. (arXiv:2312.15816v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.15816](http://arxiv.org/abs/2312.15816)

    这篇论文提出了一个名为TEILP的逻辑推理框架，用于在知识图谱中进行时间预测。通过将知识图谱转换为时间事件知识图谱，并使用可微分的随机游走方法和条件概率密度函数，该方法在时间预测方面取得了显著的改进。

    

    传统的基于嵌入模型的方法将时间知识图谱（TKG）中的事件时间预测视为一种排序问题。然而，它们常常无法很好地捕捉到诸如顺序和距离等重要的时间关系。在本文中，我们提出了TEILP，这是一个逻辑推理框架，可以自然地将这些时间要素融入到知识图谱的预测中。我们首先将TKG转换为一个具有更明确时间表示的时间事件知识图谱（TEKG）。TEKG使我们能够开发一种可微分的随机游走方法来进行时间预测。最后，我们引入了与查询时间间隔相关的条件概率密度函数，通过这些函数得出时间预测结果。我们将TEILP与五个基准数据集上的最先进方法进行比较。结果显示，我们的模型在提供可解释性解释的同时，相对于基线模型实现了显著的改进。

    Conventional embedding-based models approach event time prediction in temporal knowledge graphs (TKGs) as a ranking problem. However, they often fall short in capturing essential temporal relationships such as order and distance. In this paper, we propose TEILP, a logical reasoning framework that naturally integrates such temporal elements into knowledge graph predictions. We first convert TKGs into a temporal event knowledge graph (TEKG) which has a more explicit representation of time in term of nodes of the graph. The TEKG equips us to develop a differentiable random walk approach to time prediction. Finally, we introduce conditional probability density functions, associated with the logical rules involving the query interval, using which we arrive at the time prediction. We compare TEILP with state-of-the-art methods on five benchmark datasets. We show that our model achieves a significant improvement over baselines while providing interpretable explanations. In particular, we cons
    
[^37]: 知识图谱增强的方面级情感分析

    Knowledge Graph Enhanced Aspect-Level Sentiment Analysis. (arXiv:2312.10048v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.10048](http://arxiv.org/abs/2312.10048)

    本文提出了一种知识图谱增强的方面级情感分析方法，通过使用BERT模型和知识图谱的同义词数据，在解决上下文特定词义的挑战上取得了优越的性能。

    

    本文提出了一种新颖的方法，通过解决上下文特定词义的挑战，增强情感分析。它将BERT模型的优势与基于知识图谱的同义词数据相结合。这种协同作用利用动态注意机制来构建一个知识驱动的状态向量。为了对特定方面链接的情感进行分类，该方法构建了一个集成了位置数据的记忆库。然后使用DCGRU分析数据，以确定与特定方面术语相关的情感特征。在三个广泛使用的数据集上的实验表明，我们的方法在情感分类中具有卓越的性能。

    In this paper, we propose a novel method to enhance sentiment analysis by addressing the challenge of context-specific word meanings. It combines the advantages of a BERT model with a knowledge graph based synonym data. This synergy leverages a dynamic attention mechanism to develop a knowledge-driven state vector. For classifying sentiments linked to specific aspects, the approach constructs a memory bank integrating positional data. The data are then analyzed using a DCGRU to pinpoint sentiment characteristics related to specific aspect terms. Experiments on three widely used datasets demonstrate the superior performance of our method in sentiment classification.
    
[^38]: 具有逻辑约束的自回归模型的伪语义损失

    A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints. (arXiv:2312.03905v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.03905](http://arxiv.org/abs/2312.03905)

    本论文提出了一种针对具有逻辑约束的自回归模型的伪语义损失方法，通过在模型输出的局部近似上优化约束的似然，提高了神经符号学习的效率和适用性。

    

    神经符号化人工智能（neuro-symbolic AI）填补了纯符号和神经学习方法之间的鸿沟。这通常需要在神经网络的输出分布方面最大化对符号约束的似然。这些输出分布通常被假设为完全因子化的。这限制了神经符号学习在更具表现力的自回归分布（例如transformers）中的适用性。在这样的分布下，甚至简单约束的概率似然的计算是#P-hard的。我们提出，不是试图将约束强加在整个输出分布上，而是在其随机的局部近似上这样做。更确切地说，我们在以模型样本为中心的基于伪似然的近似中优化约束的似然。我们的近似是因子化的，可以重用子问题的解决方案，这是高效计算神经符号损失的主要原则。此外，它是一个局部的，高保真度的似然近似。

    Neuro-symbolic AI bridges the gap between purely symbolic and neural approaches to learning. This often requires maximizing the likelihood of a symbolic constraint w.r.t the neural network's output distribution. Such output distributions are typically assumed to be fully-factorized. This limits the applicability of neuro-symbolic learning to the more expressive autoregressive distributions, e.g., transformers. Under such distributions, computing the likelihood of even simple constraints is #P-hard. Instead of attempting to enforce the constraint on the entire output distribution, we propose to do so on a random, local approximation thereof. More precisely, we optimize the likelihood of the constraint under a pseudolikelihood-based approximation centered around a model sample. Our approximation is factorized, allowing the reuse of solutions to sub-problems, a main tenet for efficiently computing neuro-symbolic losses. Moreover, it is a local, high-fidelity approximation of the likelihoo
    
[^39]: 多个任务预训练和图形提示的MultiGPrompt

    MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs. (arXiv:2312.03731v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.03731](http://arxiv.org/abs/2312.03731)

    本文提出了一种名为MultiGPrompt的多任务预训练和提示框架，用于在图形表示学习中提高鲁棒性和减少标注成本。

    

    图形可以固有地对Web上相互连接的对象进行建模，从而支持一系列Web应用，比如网络分析和内容推荐。最近，图神经网络（GNNs）已经成为图表示学习的主流技术。然而，在端到端监督框架中，它们的有效性与任务特定标签的可用性密切相关。为了减少标注成本并增强在少样本设置中的鲁棒性，基于自监督任务的预训练已经成为一种有前途的方法，而提示则被提出来进一步缩小预训练任务与下游任务之间的目标差距。虽然已经对基于提示的图形学习进行了初步的探索，但它们主要利用单个预训练任务，导致从预训练数据中可能学习的通用知识的子集受限。因此，在本文中，我们提出了一种新颖的多任务预训练和提示框架MultiGPrompt，用于进一步提高对图形的表示学习。

    Graphs can inherently model interconnected objects on the Web, thereby facilitating a series of Web applications, such as web analyzing and content recommendation. Recently, Graph Neural Networks (GNNs) have emerged as a mainstream technique for graph representation learning. However, their efficacy within an end-to-end supervised framework is significantly tied to the availabilityof task-specific labels. To mitigate labeling costs and enhance robustness in few-shot settings, pre-training on self-supervised tasks has emerged as a promising method, while prompting has been proposed to further narrow the objective gap between pretext and downstream tasks. Although there has been some initial exploration of prompt-based learning on graphs, they primarily leverage a single pretext task, resulting in a limited subset of general knowledge that could be learned from the pre-training data. Hence, in this paper, we propose MultiGPrompt, a novel multi-task pre-training and prompting framework to
    
[^40]: JAX中的自动函数微分

    Automatic Functional Differentiation in JAX. (arXiv:2311.18727v2 [cs.PL] UPDATED)

    [http://arxiv.org/abs/2311.18727](http://arxiv.org/abs/2311.18727)

    我们在JAX中扩展了自动微分功能，使其能够自动微分高阶函数，通过引入一组原始算子，我们实现了函数微分的线性化和转置规则，并展示了该工具在函数导数应用中的效果和简单性。

    

    我们扩展了JAX的功能，使其能够自动微分高阶函数（函数算子和算符）。通过将函数表示为数组的推广，我们无缝地使用JAX的现有原语系统来实现高阶函数。我们提出了一组原始算子，作为构造几种关键类型的函数算子的基本构建模块。对于每个引入的原始算子，我们推导并实现了线性化和转置规则，与JAX的前向和反向模式自动微分的内部协议保持一致。这个增强功能允许使用传统用于函数的相同语法进行函数微分。得到的函数梯度本身就是可以在python中调用的函数。我们通过一些应用展示了这个工具的效果和简单性，其中函数导数是不可或缺的。此工作的源代码已在https://github.com/sail-sg/autofd上发布。

    We extend JAX with the capability to automatically differentiate higher-order functions (functionals and operators). By representing functions as a generalization of arrays, we seamlessly use JAX's existing primitive system to implement higher-order functions. We present a set of primitive operators that serve as foundational building blocks for constructing several key types of functionals. For every introduced primitive operator, we derive and implement both linearization and transposition rules, aligning with JAX's internal protocols for forward and reverse mode automatic differentiation. This enhancement allows for functional differentiation in the same syntax traditionally use for functions. The resulting functional gradients are themselves functions ready to be invoked in python. We showcase this tool's efficacy and simplicity through applications where functional derivatives are indispensable. The source code of this work is released at https://github.com/sail-sg/autofd .
    
[^41]: 电力系统中动态故障特性评估

    Dynamic Fault Characteristics Evaluation in Power Grid. (arXiv:2311.16522v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.16522](http://arxiv.org/abs/2311.16522)

    该论文提出了一种在电力系统中进行故障检测的新方法，通过图神经网络识别故障节点，并利用前后时间段内节点的状态来辅助当前故障检测。实验证明该方法准确可靠，并提供了对故障节点传播的定性分析。

    

    为了增强运维的智能度，提出了一种在电力系统中进行故障检测的新方法。该方法基于图神经网络，通过专门的特征提取方法和知识图谱来识别故障节点。通过引入时间数据，该方法利用前后时间段内节点的状态来辅助当前故障检测。为了验证节点特征的有效性，还进行了每个节点输出特征的相关性分析。实验证明，该方法可以在仿真场景中准确地定位故障节点，并具有显著的准确性。此外，基于图神经网络的特征建模可以定性地考察故障如何在节点间传播，为分析故障节点提供了有价值的见解。

    To enhance the intelligence degree in operation and maintenance, a novel method for fault detection in power grids is proposed. The proposed GNN-based approach first identifies fault nodes through a specialized feature extraction method coupled with a knowledge graph. By incorporating temporal data, the method leverages the status of nodes from preceding and subsequent time periods to help current fault detection. To validate the effectiveness of the node features, a correlation analysis of the output features from each node was conducted. The results from experiments show that this method can accurately locate fault nodes in simulation scenarios with a remarkable accuracy. Additionally, the graph neural network based feature modeling allows for a qualitative examination of how faults spread across nodes, which provides valuable insights for analyzing fault nodes.
    
[^42]: 使用歌词自动确定新曲谱的节拍记号

    Automatic Time Signature Determination for New Scores Using Lyrics for Latent Rhythmic Structure. (arXiv:2311.15480v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.15480](http://arxiv.org/abs/2311.15480)

    本文提出了一种新颖的方法，通过仅使用歌词作为输入，自动生成适合歌词歌曲的节拍记号，并揭示潜在的节奏结构。

    

    最近对于人工智能生成内容(AIGC)的兴趣急剧增加。然而，尚未对音乐组成部分如节拍记号进行足够的研究，以制定新作品的算法确定方法，尤其是歌词歌曲。这可能是因为忽视了音乐细节，而音乐细节对于构建强大的框架至关重要。具体而言，节拍记号为歌曲的几乎所有方面(包括短语和音符)建立了基础的节奏结构。在本文中，我们提出了一种新颖的方法，仅使用歌词作为输入，自动生成适合歌词歌曲的节拍记号，并利用可解释的机器学习模型揭示潜在的节奏结构。具体而言，我们设计了多种与发现歌词模式和创建同时包含歌词、节奏和统计信息的新特征相关的方法。在这种方法中，

    There has recently been a sharp increase in interest in Artificial Intelligence-Generated Content (AIGC). Despite this, musical components such as time signatures have not been studied sufficiently to form an algorithmic determination approach for new compositions, especially lyrical songs. This is likely because of the neglect of musical details, which is critical for constructing a robust framework. Specifically, time signatures establish the fundamental rhythmic structure for almost all aspects of a song, including the phrases and notes. In this paper, we propose a novel approach that only uses lyrics as input to automatically generate a fitting time signature for lyrical songs and uncover the latent rhythmic structure utilizing explainable machine learning models. In particular, we devise multiple methods that are associated with discovering lyrical patterns and creating new features that simultaneously contain lyrical, rhythmic, and statistical information. In this approach, the b
    
[^43]: 基于知识图谱的变电站动态故障分析

    Dynamic Fault Analysis in Substations Based on Knowledge Graphs. (arXiv:2311.13708v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.13708](http://arxiv.org/abs/2311.13708)

    提出了一种基于知识图谱的变电站动态故障分析方法，利用非结构化文本提取相关信息，通过隐藏马尔科夫模型训练数据，利用Neo4j图数据库创建知识图谱，实现对变电站中隐藏危险的可视化分析。

    

    为了解决从非结构化文本中识别变电站隐藏危险的挑战，提出了一种新颖的动态分析方法。首先从非结构化文本中提取相关信息，然后利用基于Elastic-Search构建的灵活分布式搜索引擎处理数据。接下来，使用隐藏马尔科夫模型来训练引擎中的数据。维特比算法被整合进来解密隐藏状态序列，便于对与隐藏危险相关的实体进行分割和标注。最后，使用Neo4j图数据库动态创建知识图谱来可视化变电站中的隐藏危险。通过对文本记录中揭示的具体变电站的隐藏危险进行案例分析，证明了所提方法的有效性。

    To address the challenge of identifying hidden danger in substations from unstructured text, a novel dynamic analysis method is proposed. We first extract relevant information from the unstructured text, and then leverages a flexible distributed search engine built on Elastic-Search to handle the data. Following this, the hidden Markov model is employed to train the data within the engine. The Viterbi algorithm is integrated to decipher the hidden state sequences, facilitating the segmentation and labeling of entities related to hidden dangers. The final step involves using the Neo4j graph database to dynamically create a knowledge graph that visualizes hidden dangers in the substation. The effectiveness of the proposed method is demonstrated through a case analysis from a specific substation with hidden dangers revealed in the text records.
    
[^44]: 通过修剪大型语言模型调查幻觉在抽象摘要中的应用

    Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization. (arXiv:2311.09335v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.09335](http://arxiv.org/abs/2311.09335)

    本文通过广泛的实证研究发现，修剪后的大型语言模型在抽象摘要任务中产生幻觉的情况较原始模型要少，表现更可靠，具有更高的效率和稀疏推理能力。

    

    尽管生成型的大型语言模型在抽象摘要任务中表现出色，但它们面临两个重要挑战：模型庞大和易产生幻觉。幻觉是令人担忧的，因为它们降低了可靠性并引发安全问题。修剪是一种通过去除冗余权重来减小模型大小，实现更高效稀疏推理的技术。修剪后的模型在下游任务性能上与原始模型相当，因此在预算有限的情况下成为理想的替代选择。然而，修剪对语言模型在抽象摘要中产生幻觉的影响尚未被探索。本文通过对五个摘要数据集、两种最先进的修剪方法和五个经调试的语言模型进行了广泛的实证研究。令人惊讶的是，我们发现修剪后的语言模型产生幻觉的情况较原始模型要少。我们的分析表明，修剪后的模型更倾向于依赖指导信息。

    Despite the remarkable performance of generative large language models (LLMs) on abstractive summarization, they face two significant challenges: their considerable size and tendency to hallucinate. Hallucinations are concerning because they erode reliability and raise safety issues. Pruning is a technique that reduces model size by removing redundant weights, enabling more efficient sparse inference. Pruned models yield downstream task performance comparable to the original, making them ideal alternatives when operating on a limited budget. However, the effect that pruning has upon hallucinations in abstractive summarization with LLMs has yet to be explored. In this paper, we provide an extensive empirical study across five summarization datasets, two state-of-the-art pruning methods, and five instruction-tuned LLMs. Surprisingly, we find that hallucinations from pruned LLMs are less prevalent than the original models. Our analysis suggests that pruned models tend to depend more on th
    
[^45]: 电力分配网络中的知识图谱构建

    Knowledge Graph Construction in Power Distribution Networks. (arXiv:2311.08724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.08724](http://arxiv.org/abs/2311.08724)

    本文提出了一种在电力分配网络中构建知识图谱的方法，该方法利用实体特征，在分配网络的知识图谱和分配文本中进行匹配，通过实验证明了其在电力分配知识图谱构建任务中的高准确性。

    

    本文提出了一种在电力分配网络中构建知识图谱的方法。该方法利用实体特征，包括其语义、音韵和句法特征，在分配网络的知识图谱和分配文本中进行匹配。基于卷积神经网络的增强模型，用于有效地将分配文本实体与知识图谱中的实体匹配。通过在真实世界的电力分配场景中进行实验评估了该模型的有效性。结果表明，与基线方法相比，所提出的模型在链接各种实体类型方面表现出色，在电力分配知识图谱构建任务中具有很高的整体准确性。

    In this paper, we propose a method for knowledge graph construction in power distribution networks. This method leverages entity features, which involve their semantic, phonetic, and syntactic characteristics, in both the knowledge graph of distribution network and the dispatching texts. An enhanced model based on Convolutional Neural Network, is utilized for effectively matching dispatch text entities with those in the knowledge graph. The effectiveness of this model is evaluated through experiments in real-world power distribution dispatch scenarios. The results indicate that, compared with the baselines, the proposed model excels in linking a variety of entity types, demonstrating high overall accuracy in power distribution knowledge graph construction task.
    
[^46]: 对GPT-4V在知识密集型视觉问答中的全面评估

    A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual Question Answering. (arXiv:2311.07536v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.07536](http://arxiv.org/abs/2311.07536)

    本论文对知识密集型视觉问答中的GPT-4V进行了全面评估，从常识知识、细粒度的世界知识和全面知识与决策理据三个方面对其能力进行了深入考察。

    

    多模态大型模型（MLMs）的出现显著推动了视觉理解领域的发展，在视觉问答（VQA）领域提供了卓越的能力。然而，真正的挑战在于知识密集型VQA任务，并不仅需要识别视觉元素，还需要深入理解视觉信息并结合丰富的学习知识库。为了揭示MLMs特别是新引入的GPT-4V的这些能力，我们从三个角度进行了深入评估：1）常识知识，评估模型理解视觉线索并连接到通用知识的能力；2）细粒度的世界知识，测试模型从图像中推理出具体知识的能力，展示其在各个专业领域的能力；3）全面知识与决策理据，检查模型提供逻辑解释的能力。

    The emergence of multimodal large models (MLMs) has significantly advanced the field of visual understanding, offering remarkable capabilities in the realm of visual question answering (VQA). Yet, the true challenge lies in the domain of knowledge-intensive VQA tasks, which necessitate not just recognition of visual elements, but also a deep comprehension of the visual information in conjunction with a vast repository of learned knowledge. To uncover such capabilities of MLMs, particularly the newly introduced GPT-4V, we provide an in-depth evaluation from three perspectives: 1) Commonsense Knowledge, which assesses how well models can understand visual cues and connect to general knowledge; 2) Fine-grained World Knowledge, which tests the model's skill in reasoning out specific knowledge from images, showcasing their proficiency across various specialized fields; 3) Comprehensive Knowledge with Decision-making Rationales, which examines model's capability to provide logical explanatio
    
[^47]: 偏见深入：Persona分配的LLMs中的隐式推理偏见

    Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs. (arXiv:2311.04892v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04892](http://arxiv.org/abs/2311.04892)

    这项研究首次广泛研究了Persona分配对LLMs执行基本推理任务能力的意外副作用。实验证明，LLMs虽然在明确要求时拒绝刻板印象，但在扮演特定角色时会表现出刻板印象和错误的假设。

    

    近期的研究展示了LLMs具备在其回答中体现不同角色的能力，例如通过“你是Yoda。解释相对论。”这样的提示。虽然这种能力允许LLMs个性化，并实现人类行为模拟，但其对LLMs能力的影响仍不清楚。为了填补这一空白，我们首次对Persona分配对LLMs执行基本推理任务能力的意外副作用进行了广泛研究。我们的研究涵盖了24个推理数据集、4个LLMs和19个不同的角色（如亚洲人），跨越了5个社会人口群体。我们的实验揭示了在公平的幌子下，LLMs中存在根深蒂固的偏见。虽然当明确要求时它们公然拒绝刻板印象（例如“黑人在数学上是否不擅长？”），但当他们被要求在扮演特定角色的情况下回答问题时，它们表现出刻板印象和错误的假设。这些可以观察到的行为表现为推理结果的弃权。

    Recent works have showcased the ability of LLMs to embody diverse personas in their responses, exemplified by prompts like 'You are Yoda. Explain the Theory of Relativity.' While this ability allows personalization of LLMs and enables human behavior simulation, its effect on LLMs' capabilities remains unclear. To fill this gap, we present the first extensive study of the unintended side-effects of persona assignment on the ability of LLMs to perform basic reasoning tasks. Our study covers 24 reasoning datasets, 4 LLMs, and 19 diverse personas (e.g. an Asian person) spanning 5 socio-demographic groups. Our experiments unveil that LLMs harbor deep rooted bias against various socio-demographics underneath a veneer of fairness. While they overtly reject stereotypes when explicitly asked ('Are Black people less skilled at mathematics?'), they manifest stereotypical and erroneous presumptions when asked to answer questions while adopting a persona. These can be observed as abstentions in res
    
[^48]: 使用具有辅助跨模态交互的关系时态图神经网络进行对话理解

    Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction. (arXiv:2311.04507v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04507](http://arxiv.org/abs/2311.04507)

    本论文提出了一个名为CORECT的神经网络框架，通过关系时态图神经网络和辅助跨模态交互的方式有效地捕捉对话中的情感信息。

    

    情绪识别是人类对话理解的一个关键任务，随着多模态数据的引入，如语言、声音和面部表情，这变得更具挑战性。作为一种典型的解决方案，利用全局和局部上下文信息来预测对话中每个句子（即话语）的情绪标签。具体而言，全局表示可以通过建模对话级别的跨模态交互来捕捉。局部表示通常是通过说话者或情绪变化的时间信息来推断的，忽视了话语级别的重要因素。此外，大多数现有方法采用统一输入的多模态融合特征，而不利用模态特定的表示。为了解决这些问题，我们提出了关系时态图神经网络与辅助跨模态交互（CORECT），这是一个有效捕捉对话中情感信息的神经网络框架。

    Emotion recognition is a crucial task for human conversation understanding. It becomes more challenging with the notion of multimodal data, e.g., language, voice, and facial expressions. As a typical solution, the global- and the local context information are exploited to predict the emotional label for every single sentence, i.e., utterance, in the dialogue. Specifically, the global representation could be captured via modeling of cross-modal interactions at the conversation level. The local one is often inferred using the temporal information of speakers or emotional shifts, which neglects vital factors at the utterance level. Additionally, most existing approaches take fused features of multiple modalities in an unified input without leveraging modality-specific representations. Motivating from these problems, we propose the Relational Temporal Graph Neural Network with Auxiliary Cross-Modality Interaction (CORECT), an novel neural network framework that effectively captures convers
    
[^49]: GateLoop: 完全数据控制的线性递归用于序列建模

    GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling. (arXiv:2311.01927v1 [cs.LG])

    [http://arxiv.org/abs/2311.01927](http://arxiv.org/abs/2311.01927)

    GateLoop是一种完全数据控制的线性递归序列模型，优于现有模型，可以提供数据控制的相对位置信息给Attention。

    

    线性递归已被证明是一种有效建模长序列的强大工具。在这项工作中，我们表明现有模型未能充分利用其潜力。在这一发现的基础上，我们开发了GateLoop，这是一种基础性的序列模型，通过使用数据控制的状态转换来推广线性递归模型，如S4、S5、LRU和RetNet。利用这一理论进步，GateLoop在自回归语言建模方面在实证上优于现有模型。我们的方法具有低成本的$O(l)$递归模式和高度优化的关联扫描实现的高效$O(l \log_{2} l)$并行模式。此外，我们还推导出了一个$O(l^2)$的代理注意力模式，揭示了对Transformer和最近提出的架构的显著影响。具体而言，我们证明了我们的方法可以被解释为向Attention提供数据控制的相对位置信息。而许多现有模型仅依赖于数据无关的位置信息。

    Linear Recurrence has proven to be a powerful tool for modeling long sequences efficiently. In this work, we show that existing models fail to take full advantage of its potential. Motivated by this finding, we develop GateLoop, a foundational sequence model that generalizes linear recurrent models such as S4, S5, LRU and RetNet, by employing data-controlled state transitions. Utilizing this theoretical advance, GateLoop empirically outperforms existing models for auto-regressive language modeling. Our method comes with a low-cost $O(l)$ recurrent mode and an efficient $O(l \log_{2} l)$ parallel mode making use of highly optimized associative scan implementations. Furthermore, we derive an $O(l^2)$ surrogate attention mode, revealing remarkable implications for Transformer and recently proposed architectures. Specifically, we prove that our approach can be interpreted as providing data-controlled relative-positional information to Attention. While many existing models solely rely on da
    
[^50]: 一份针对大型语言模型的开源数据污染报告

    An Open Source Data Contamination Report for Large Language Models. (arXiv:2310.17589v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.17589](http://arxiv.org/abs/2310.17589)

    本文介绍了一个针对大型语言模型的开源数据污染报告，其中包括超过15个热门模型对六个常见多项选择问答基准测试的污染分析。实验证明，数据污染会显著降低模型性能，并且随着时间的推移污染程度不断增加。

    

    随着大型语言模型的日益普及，模型评估中的数据污染问题越来越普遍。它允许模型通过记忆而不是展示真正的能力来"作弊"。因此，污染分析已成为可靠的模型评估的重要部分，用于验证结果。然而，现有的污染分析通常由大型语言模型开发者内部进行，往往缺乏透明度和完整性。本文为六个常见的多项选择问答基准测试提供了超过15个热门大型语言模型的详细数据污染报告。我们还介绍了一个开源的流程，使社区能够对自定义数据和模型进行污染分析。我们的实验揭示了基准测试中不同的污染水平，范围从1%到45%，污染程度随时间迅速增加。大型语言模型的性能分析表明，数据污染会显著降低模型的性能。

    Data contamination in model evaluation has become increasingly prevalent with the growing popularity of large language models. It allows models to "cheat" via memorisation instead of displaying true capabilities. Therefore, contamination analysis has become an crucial part of reliable model evaluation to validate results. However, existing contamination analysis is usually conducted internally by large language model developers and often lacks transparency and completeness. This paper presents an extensive data contamination report for over 15 popular large language models across six popular multiple-choice QA benchmarks. We also introduce an open-source pipeline that enables the community to perform contamination analysis on customised data and models. Our experiments reveal varying contamination levels ranging from 1\% to 45\% across benchmarks, with the contamination degree increasing rapidly over time. Performance analysis of large language models indicates that data contamination 
    
[^51]: 将词汇测试作为评估大型语言模型的基准

    Establishing Vocabulary Tests as a Benchmark for Evaluating Large Language Models. (arXiv:2310.14703v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.14703](http://arxiv.org/abs/2310.14703)

    本论文主张将词汇测试作为评估大型语言模型性能的重要工具，在评估七个LLM模型时发现了它们在词汇知识方面存在差距，并探讨了LLM词汇表示、学习机制和性能变化的细节。自动生成和执行词汇测试为扩展这一方法提供了新的机会。

    

    在当前大型语言模型（LLMs）如Llama、Mistral和GPT主导的语言模型评估环境中，词汇测试一度被忽视。虽然大多数LLM评估基准关注特定任务或领域特定知识，但它们常常忽略了语言理解和产出的基本语言学方面。本文主张恢复词汇测试作为评估LLM性能的有价值工具。我们使用两种词汇测试格式评估了七个LLM模型，并发现了它们在词汇知识上的一些令人惊讶的差距。这些发现揭示了LLM词汇表示的复杂性、它们的学习机制以及模型和语言之间的性能变化。此外，自动生成和执行词汇测试的能力提供了扩展这一方法并提供LLM语言技能更完整画面的新机会。

    Vocabulary tests, once a cornerstone of language modeling evaluation, have been largely overlooked in the current landscape of Large Language Models (LLMs) like Llama, Mistral, and GPT. While most LLM evaluation benchmarks focus on specific tasks or domain-specific knowledge, they often neglect the fundamental linguistic aspects of language understanding and production. In this paper, we advocate for the revival of vocabulary tests as a valuable tool for assessing LLM performance. We evaluate seven LLMs using two vocabulary test formats across two languages and uncover surprising gaps in their lexical knowledge. These findings shed light on the intricacies of LLM word representations, their learning mechanisms, and performance variations across models and languages. Moreover, the ability to automatically generate and perform vocabulary tests offers new opportunities to expand the approach and provide a more complete picture of LLMs' language skills.
    
[^52]: 重构材料四面体：材料信息提取中的挑战

    Reconstructing Materials Tetrahedron: Challenges in Materials Information Extraction. (arXiv:2310.08383v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.08383](http://arxiv.org/abs/2310.08383)

    本论文讨论了从材料科学文献中自动提取信息面临的挑战，并希望能够创建一个大型的材料科学知识库。

    

    新材料的发现已经有着持续几个世纪乃至更长时间的推动人类进步的历史。材料的行为取决于其组成、结构和性质，而这些又依赖于其加工和测试条件。最近深度学习和自然语言处理的发展使得从出版的文献中（如同行评审出版物、图书和专利）大规模提取信息成为可能。然而，这些信息以不同的格式（如表格、文本和图像）展现，并且在报告样式上缺乏一致性，这引发了几个机器学习的挑战。在这里，我们讨论、量化和记录了材料科学文献自动信息提取方面的这些挑战，以期创建一个大型的材料科学知识库。具体而言，我们关注从文本和表格中进行信息提取，并举例说明了几个挑战。我们希望本研究能激发研究人员解决这些挑战。

    Discovery of new materials has a documented history of propelling human progress for centuries and more. The behaviour of a material is a function of its composition, structure, and properties, which further depend on its processing and testing conditions. Recent developments in deep learning and natural language processing have enabled information extraction at scale from published literature such as peer-reviewed publications, books, and patents. However, this information is spread in multiple formats, such as tables, text, and images, and with little or no uniformity in reporting style giving rise to several machine learning challenges. Here, we discuss, quantify, and document these challenges in automated information extraction (IE) from materials science literature towards the creation of a large materials science knowledge base. Specifically, we focus on IE from text and tables and outline several challenges with examples. We hope the present work inspires researchers to address 
    
[^53]: BioT5：在生物学中利用化学知识和自然语言关联丰富跨模态整合

    BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations. (arXiv:2310.07276v1 [cs.CL])

    [http://arxiv.org/abs/2310.07276](http://arxiv.org/abs/2310.07276)

    BioT5是一个全面的预训练框架，在生物学中利用化学知识和自然语言关联丰富了跨模态整合，通过鲁棒的分子表示和上下文知识提取，实现了更有效的信息利用，展现出卓越的性能。

    

    最近在生物研究领域的进展利用分子、蛋白质和自然语言的整合来增强药物发现。然而，当前的模型存在一些限制，如生成无效的分子SMILES、对上下文信息的利用不足以及对结构化和非结构化知识的等量处理。为了解决这些问题，我们提出了一个全面的预训练框架BioT5，它通过化学知识和自然语言关联丰富了生物学中的跨模态整合。BioT5利用SELFIES进行100%鲁棒的分子表示，并从非结构化的生物文献中提取生物实体周围上下文的知识。此外，BioT5区分结构化和非结构化知识，从而更有效地利用信息。在微调后，BioT5在各种任务中展现出卓越的性能，表明其强大的能力。

    Recent advancements in biological research leverage the integration of molecules, proteins, and natural language to enhance drug discovery. However, current models exhibit several limitations, such as the generation of invalid molecular SMILES, underutilization of contextual information, and equal treatment of structured and unstructured knowledge. To address these issues, we propose $\mathbf{BioT5}$, a comprehensive pre-training framework that enriches cross-modal integration in biology with chemical knowledge and natural language associations. $\mathbf{BioT5}$ utilizes SELFIES for $100%$ robust molecular representations and extracts knowledge from the surrounding context of bio-entities in unstructured biological literature. Furthermore, $\mathbf{BioT5}$ distinguishes between structured and unstructured knowledge, leading to more effective utilization of information. After fine-tuning, BioT5 shows superior performance across a wide range of tasks, demonstrating its strong capability 
    
[^54]: 低资源语言越狱 GPT-4

    Low-Resource Languages Jailbreak GPT-4. (arXiv:2310.02446v1 [cs.CL])

    [http://arxiv.org/abs/2310.02446](http://arxiv.org/abs/2310.02446)

    通过翻译不安全的英文输入成低资源语言，我们成功绕过了GPT-4的安全机制，并展示了这种跨语言漏洞。这一方法在实验中取得了与甚至超过了最先进的越狱攻击的效果，揭示了低资源语言在AI安全性中的薄弱环节。

    

    人工智能安全培训和大型语言模型（LLM）的红队测试是减少生成不安全内容的措施。我们的工作通过将不安全的英文输入翻译成低资源语言，成功绕过GPT-4的安全机制，并揭示了这些安全机制的跨语言漏洞。在AdvBenchmark中，GPT-4针对不安全的翻译输入进行交互，并且79%的时间内提供了可行的方案，使用户实现其有害目标，这与甚至超过了最先进的越狱攻击的效果相当。其他高/中资源语言的攻击成功率显著较低，这表明跨语言漏洞主要适用于低资源语言。以前，对低资源语言的有限训练主要影响那些使用这些语言的人，造成技术差距。然而，我们的工作突出了一个关键转变：

    AI safety training and red-teaming of large language models (LLMs) are measures to mitigate the generation of unsafe content. Our work exposes the inherent cross-lingual vulnerability of these safety mechanisms, resulting from the linguistic inequality of safety training data, by successfully circumventing GPT-4's safeguard through translating unsafe English inputs into low-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe translated inputs and provides actionable items that can get the users towards their harmful goals 79% of the time, which is on par with or even surpassing state-of-the-art jailbreaking attacks. Other high-/mid-resource languages have significantly lower attack success rate, which suggests that the cross-lingual vulnerability mainly applies to low-resource languages. Previously, limited training on low-resource languages primarily affects speakers of those languages, causing technological disparities. However, our work highlights a crucial shift:
    
[^55]: 模型告诉你该丢弃什么：适应性KV缓存压缩用于LLMs

    Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs. (arXiv:2310.01801v1 [cs.CL])

    [http://arxiv.org/abs/2310.01801](http://arxiv.org/abs/2310.01801)

    该研究提出了一种自适应的KV缓存压缩方法，用于减少大型语言模型的内存消耗。通过有针对性的分析和结构识别，构建了具有自适应性的KV缓存，通过清除和丢弃特定的上下文，以及只对特定的注意力头使用标准KV缓存，实现了显著的内存占用减少。

    

    在这项研究中，我们引入了一种自适应的KV缓存压缩方法，它可以减少大型语言模型（LLMs）生成推理的内存占用。与传统的KV缓存不同，我们通过有针对性的分析来识别注意力模块的内在结构。基于识别出的结构，我们以自适应的方式构建KV缓存：在强调本地上下文的注意力头上清除长距离上下文，在以特殊标记为中心的注意力头上丢弃非特殊标记，并且仅对广泛关注所有标记的注意力头使用标准的KV缓存。此外，通过使用轻量级的注意力分析来指导自适应KV缓存的构建，FastGen可以在不需要资源密集型的微调或重新训练的情况下部署。在各种任务的实验中，FastGen在GPU内存消耗方面显示出了显著的减少。

    In this study, we introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs). Different from the conventional KV cache that retains key and value vectors for all context tokens, we conduct targeted profiling to discern the intrinsic structure of attention modules. Based on the recognized structure, we then construct the KV cache in an adaptive manner: evicting long-range contexts on attention heads emphasizing local contexts, discarding non-special tokens on attention heads centered on special tokens, and only employing the standard KV cache for attention heads that broadly attend to all tokens. Moreover, with the lightweight attention profiling used to guide the construction of the adaptive KV cache, FastGen can be deployed without resource-intensive fine-tuning or re-training. In our experiments across various asks, FastGen demonstrates substantial reduction on GPU memory consumption with 
    
[^56]: 从旋律中利用字符级语言模型生成音节级歌词

    Syllable-level lyrics generation from melody exploiting character-level language model. (arXiv:2310.00863v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00863](http://arxiv.org/abs/2310.00863)

    该论文提出了一种利用字符级语言模型从旋律中生成音节级歌词的方法，并通过融合语言模型知识和生成器网络进行优化。通过探索ChatGPT的评估方法，以及人工评估，证明了该方法提高了生成歌词的连贯性和正确性。

    

    生成与伴奏旋律紧密相关的歌词涉及建立音乐音符与歌词音节之间的映射。这个过程需要对音节级、词级和句级语义意义上的音乐约束和语义模式有深入的理解。然而，公开的音节级预训练语言模型并不存在。为了解决这些具有挑战性的问题，我们提出利用以字符级语言模型进行音节级歌词生成。特别地，我们的方法将语言模型的语言知识融入音节级Transformer生成器网络的束搜索过程中。此外，通过探索基于ChatGPT的生成歌词评估方法，以及人工主观评估，我们证明了我们的方法增强了生成歌词的连贯性和正确性，消除了训练昂贵的新模型的需求。

    The generation of lyrics tightly connected to accompanying melodies involves establishing a mapping between musical notes and syllables of lyrics. This process requires a deep understanding of music constraints and semantic patterns at syllable-level, word-level, and sentence-level semantic meanings. However, pre-trained language models specifically designed at the syllable level are publicly unavailable. To solve these challenging issues, we propose to exploit fine-tuning character-level language models for syllable-level lyrics generation from symbolic melody. In particular, our method endeavors to incorporate linguistic knowledge of the language model into the beam search process of a syllable-level Transformer generator network. Additionally, by exploring ChatGPT-based evaluation for generated lyrics, along with human subjective evaluation, we demonstrate that our approach enhances the coherence and correctness of the generated lyrics, eliminating the need to train expensive new la
    
[^57]: 面向黑盒文本分类器的LLM引导因果可解释性

    Towards LLM-guided Causal Explainability for Black-box Text Classifiers. (arXiv:2309.13340v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.13340](http://arxiv.org/abs/2309.13340)

    本文提出了一种利用大型语言模型（LLM）引导黑盒文本分类器的因果可解释性的方法，通过生成反事实解释来解决这一挑战。

    

    随着越来越大且更复杂的深度学习模型的出现，比如在自然语言处理（NLP）领域，像可解释性和可解释性这样的模型质量，尽管非常令人向往，但变得越来越难以解决。例如，文本分类中的最先进模型是设计为黑盒。尽管标准的解释方法可以提供一定程度的解释能力，但这些方法主要是基于相关性的，对模型的理解能力有限。因果解释能力是更理想的目标，但在NLP领域却极具挑战性，原因有很多。受到最近利用大型语言模型（LLMs）作为专家的工作的启发，本文旨在利用最新的LLMs的指导和理解能力，通过生成反事实解释来实现黑盒文本分类器的因果可解释性。为此，我们提出了一个三步骤的流程，

    With the advent of larger and more complex deep learning models, such as in Natural Language Processing (NLP), model qualities like explainability and interpretability, albeit highly desirable, are becoming harder challenges to tackle and solve. For example, state-of-the-art models in text classification are black-box by design. Although standard explanation methods provide some degree of explainability, these are mostly correlation-based methods and do not provide much insight into the model. The alternative of causal explainability is more desirable to achieve but extremely challenging in NLP due to a variety of reasons. Inspired by recent endeavors to utilize Large Language Models (LLMs) as experts, in this work, we aim to leverage the instruction-following and textual understanding capabilities of recent state-of-the-art LLMs to facilitate causal explainability via counterfactual explanation generation for black-box text classifiers. To do this, we propose a three-step pipeline via
    
[^58]: 《Media of Langue》的媒体

    Media of Langue. (arXiv:2309.08609v1 [cs.CL])

    [http://arxiv.org/abs/2309.08609](http://arxiv.org/abs/2309.08609)

    该论文介绍了《Media of Langue》这一全新词典和公共雕塑，通过描述不同语言之间的意义地图和两个力量之间的边界，重点介绍了三个新的概念：《Inter-Langue Map/Dictionary》、《Inter-Langue Space》和《Inter-Langue Network》。

    

    本文旨在存档Goki Muramoto等人的《Media of Langue》后面的材料。《Media of Langue》是一个全新的字典和公共雕塑，它仅从“这个词被翻译成那个词”的广泛事件和两个力量之间的边界上描述出不同语言之间的意义地图。首先，介绍了三个新概念：《Inter-Langue Map/Dictionary》、《Inter-Langue Space》和《Inter-Langue Network》并将其与字典、语义空间和语义网络的三个领域进行了比较。接下来，描述了该作品中实施的具体算法和设计。

    This paper aims to archive the materials behind "Media of Langue" by Goki Muramoto et al. Media of Langue is a new dictionary and public sculpture that depicts the map of meaning on the boundary between languages solely from the vast events of "this word was translated into that word" and two forces: repulsion between all words in the same language and attraction between translated words in different languages. First, the three new concepts proposed, Inter-Langue Map/Dictionary, Inter-Langue Space, and then Inter-Langue Network, are introduced, comparing them to the three domains of dictionary, semantic space, and semantic network. Next, the specific algorithms and designs implemented in the work were described.
    
[^59]: 通过源对比和语言对比解码来缓解幻觉和偏离目标的机器翻译问题

    Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding. (arXiv:2309.07098v1 [cs.CL])

    [http://arxiv.org/abs/2309.07098](http://arxiv.org/abs/2309.07098)

    本文介绍了一种通过源对比和语言对比解码来解决机器翻译中幻觉和偏离目标的问题的方法，实验证明这些方法能有效地抑制幻觉和偏离目标的翻译。

    

    在机器翻译中，幻觉和偏离目标的翻译仍然是一个未解决的问题，特别是对于低资源语言和大规模多语言模型。本文介绍了一种修改的解码目标来缓解这两种失败情况的方法，而不需要重新训练或外部模型。在源对比解码中，我们寻找一个翻译，在给定正确输入时是可信的，但在随机输入片段给定时是不可信的，假设幻觉在任何情况下都是同样可信的。在语言对比解码中，我们寻找一个翻译，在给定正确语言指示符令牌时是可信的，但给定错误语言指示符令牌时是不可信的。在对M2M-100 (418M)和SMaLL-100进行实验后，我们发现这些方法有效地抑制了幻觉和偏离目标的翻译，平均在57个测试的翻译方向上提高了1.7和1.4个chrF2分数。在英德语言对的一个概念验证中，我们还展示了我们可以抑制偏离目标的翻译。

    Hallucinations and off-target translation remain unsolved problems in machine translation, especially for low-resource languages and massively multilingual models. In this paper, we introduce methods to mitigate both failure cases with a modified decoding objective, without requiring retraining or external models. In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either. In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token. In experiments on M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4 points on average across 57 tested translation directions. In a proof of concept on English--German, we also show that we can suppress off-target translat
    
[^60]: 表示对上下文学习的影响：对合成任务的探索

    How does representation impact in-context learning: A exploration on a synthetic task. (arXiv:2309.06054v1 [cs.LG])

    [http://arxiv.org/abs/2309.06054](http://arxiv.org/abs/2309.06054)

    本研究通过探索表示学习的角度，研究了表示对上下文学习的影响。实验结果表明，在上下文学习中，上下文内部成分对学习性能起到重要作用。

    

    上下文学习，即从上下文样本中学习，是Transformer的一项引人注目的能力。然而，驱动上下文学习的机制尚未被充分理解。本研究旨在从一个未被充分探索的表示学习角度进行调查。在上下文学习场景中，表示更加复杂，表示可以受到模型权重和上下文样本的影响。我们将上述两个概念方面的表示分别称为权重内部成分和上下文内部成分。为了研究这两个成分如何影响上下文学习能力，我们构建了一个新颖的合成任务，从而可以设计两个探针，即权重内部探针和上下文探针，分别评估这两个成分。我们证明上下文内部成分的好坏与上下文学习性能高度相关，这表明上下文学习与表示学习之间的纠缠关系。

    In-context learning, i.e., learning from in-context samples, is an impressive ability of Transformer. However, the mechanism driving the in-context learning is not yet fully understood. In this study, we aim to investigate from an underexplored perspective of representation learning. The representation is more complex for in-context learning senario, where the representation can be impacted by both model weights and in-context samples. We refer the above two conceptually aspects of representation as in-weight component and in-context component, respectively. To study how the two components affect in-context learning capabilities, we construct a novel synthetic task, making it possible to device two probes, in-weights probe and in-context probe, to evaluate the two components, respectively. We demonstrate that the goodness of in-context component is highly related to the in-context learning performance, which indicates the entanglement between in-context learning and representation lear
    
[^61]: 基于流形的无调参提示分类的重新嵌入方法

    Manifold-based Verbalizer Space Re-embedding for Tuning-free Prompt-based Classification. (arXiv:2309.04174v1 [cs.CL])

    [http://arxiv.org/abs/2309.04174](http://arxiv.org/abs/2309.04174)

    本研究提出了一种无需调参的基于流形的语言转换器嵌入方法，通过保留同一类中的局部特性来进行分类，实验证明其与自动化的语言转换器效果相当。

    

    提示分类通过利用[MASK]标记的遗漏问题形式来适应任务，然后通过预定义的语言转换器将填充的标记映射到标签上。最近的研究已经探索了使用语言转换器嵌入来减少这一过程中的劳动力。然而，所有现有的研究都需要对预训练模型或附加可训练嵌入进行调参过程。同时，由于表示空间中潜在的非线性流形，高维语言转换器嵌入之间的距离不应该使用欧氏距离来衡量。在本研究中，我们提出了一种无调参基于流形的空间重新嵌入方法，称为具有内类近邻约束的局部线性嵌入（LLE-INC），用于语言转换器嵌入，它保留了同一类中的局部特性作为分类的引导。实验结果表明，即使不进行任何参数调优，我们的LLE-INC与自动化的语言转换器相媲美。

    Prompt-based classification adapts tasks to a cloze question format utilizing the [MASK] token and the filled tokens are then mapped to labels through pre-defined verbalizers. Recent studies have explored the use of verbalizer embeddings to reduce labor in this process. However, all existing studies require a tuning process for either the pre-trained models or additional trainable embeddings. Meanwhile, the distance between high-dimensional verbalizer embeddings should not be measured by Euclidean distance due to the potential for non-linear manifolds in the representation space. In this study, we propose a tuning-free manifold-based space re-embedding method called Locally Linear Embedding with Intra-class Neighborhood Constraint (LLE-INC) for verbalizer embeddings, which preserves local properties within the same class as guidance for classification. Experimental results indicate that even without tuning any parameters, our LLE-INC is on par with automated verbalizers with parameter 
    
[^62]: 对大型语言模型代码生成的鲁棒性和可靠性的研究

    A Study on Robustness and Reliability of Large Language Model Code Generation. (arXiv:2308.10335v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10335](http://arxiv.org/abs/2308.10335)

    本研究针对大型语言模型生成的代码的可靠性和鲁棒性进行了研究，发现在真实的软件开发中可执行的代码并不能保证可靠和鲁棒，滥用API可能导致严重问题。这对初级开发者来说尤其危险，因为他们很难察觉到代码中的API滥用问题。

    

    最近，大型语言模型(LLMs)在理解自然语言和生成编程代码方面显示出了非凡能力。当遇到编码问题时，软件工程师常常会咨询LLMs。尽管已经做出了一些努力来避免语法错误并使代码与预期的语义对齐，但LLMs生成的代码的可靠性和鲁棒性尚未被深入研究。在真实的软件开发环境中，可执行的代码并不等同于可靠和鲁棒的代码。在生成的代码中滥用API可能会导致严重的问题，如资源泄漏、程序崩溃。更糟糕的是，LLM代码生成服务的用户实际上是最容易受到这些看似正确的代码影响的开发者——他们通常是不熟悉LLMs为他们生成代码的API的初级开发者。因此，他们很难察觉到API的滥用。

    Recently, the large language models (LLMs) have shown extraordinary ability in understanding natural language and generating programming code. It has been a common practice of software engineers to consult LLMs when encountering coding questions. Although efforts have been made to avoid syntax errors and align the code with the intended semantics, the reliability and robustness of the code generationfrom LLMs have not yet been thoroughly studied. The executable code is not equivalent to the reliable and robust code, especially in the context of real-world software development. The misuse of APIs in the generated code could lead to severe problem, such as resource leaks, program crashes. To make things worse, the users of LLM code generation services are actually the developers that are most vulnerable to these code that seems right -- They are always novice developers that are not familiar with the APIs that LLMs generate code for them. Therefore, they could hardly tell the misuse in t
    
[^63]: 从视觉问答模型中以基于语境语言学习功能词的意义

    Learning the meanings of function words from grounded language using a visual question answering model. (arXiv:2308.08628v1 [cs.CL])

    [http://arxiv.org/abs/2308.08628](http://arxiv.org/abs/2308.08628)

    本研究通过研究基于视觉问答模型学习到的功能词的意义，旨在更好地了解模型和儿童如何学习这些词汇。研究发现，在以视觉为基础的语言上训练的递归模型能够学习到需要空间和数字推理的功能词的梯度语义，并且可以在没有逻辑推理先验知识的情况下学习到"和"和"或"的意义，以及迅速发展出替换推论的能力的早期证据。

    

    解释一个看似简单的功能词，如“或者”，“在......后面”，或“更多”可能需要逻辑、数字和关系推理。儿童如何学习这样的词汇？既往的习得理论通常依赖于认为具有先天知识的基础。然而，最近基于神经网络的视觉问答模型显然可以通过使用功能词来回答关于复杂视觉场景的问题而进行学习。在本文中，我们研究了这些模型对功能词的学习，并希望更好地了解这些词汇的意义如何被模型和儿童所学习。我们展示了在以视觉为基础的语言上训练的递归模型学习了需要空间和数字推理的功能词的梯度语义。此外，我们发现这些模型可以在没有任何逻辑推理的先验知识下学习到"和"和"或"的意义，并迅速发展出进行替换推论的能力的早期证据。

    Interpreting a seemingly-simple function word like "or", "behind", or "more" can require logical, numerical, and relational reasoning. How are such words learned by children? Prior acquisition theories have often relied on positing a foundation of innate knowledge. Yet recent neural-network based visual question answering models apparently can learn to use function words as part of answering questions about complex visual scenes. In this paper, we study what these models learn about function words, in the hope of better understanding how the meanings of these words can be learnt by both models and children. We show that recurrent models trained on visually grounded language learn gradient semantics for function words requiring spacial and numerical reasoning. Furthermore, we find that these models can learn the meanings of logical connectives "and" and "or" without any prior knowledge of logical reasoning, as well as early evidence that they can develop the ability to reason about alte
    
[^64]: 利用大型语言模型通过在线文本数据预测心理健康

    Leveraging Large Language Models for Mental Health Prediction via Online Text Data. (arXiv:2307.14385v1 [cs.HC])

    [http://arxiv.org/abs/2307.14385](http://arxiv.org/abs/2307.14385)

    本研究首次对多种大型语言模型在心理健康预测任务上进行了全面评估，结果表明指令微调可以显著提升模型性能，并且最优微调模型在平衡准确度上胜过GPT-3.5，并与最先进的任务特定模型持平。

    

    最近大型语言模型（LLM）的技术提升使得多种应用成为可能。然而，对于LLM在心理健康领域的理解和改进研究几乎没有。在这项工作中，我们首次全面评估了多种LLM（包括Alpaca，Alpaca-LoRA和GPT-3.5）在通过在线文本数据进行多个心理健康预测任务上的表现。我们进行了广泛的实验，包括零-shot提示、少-shot提示和指令微调。结果表明，LLM在零-shot和少-shot提示设计上在心理健康任务上表现出有限但有前景的性能。更重要的是，我们的实验结果表明，指令微调可以显著提升LLM在所有任务上的性能。我们最好的微调模型，Mental-Alpaca，在平衡准确度上比GPT-3.5（体积大25倍）高出16.7\%，并与最先进的任务特定模型持平。我们总结我们的发现。

    The recent technology boost of large language models (LLMs) has empowered a variety of applications. However, there is very little research on understanding and improving LLMs' capability for the mental health domain. In this work, we present the first comprehensive evaluation of multiple LLMs, including Alpaca, Alpaca-LoRA, and GPT-3.5, on various mental health prediction tasks via online text data. We conduct a wide range of experiments, covering zero-shot prompting, few-shot prompting, and instruction finetuning. The results indicate the promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned model, Mental-Alpaca, outperforms GPT-3.5 (25 times bigger) by 16.7\% on balanced accuracy and performs on par with the state-of-the-art task-specific model. We summarize our find
    
[^65]: 从Hapax Rate模型导出的Zipf和Heaps定律的修正

    Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models. (arXiv:2307.12896v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12896](http://arxiv.org/abs/2307.12896)

    本文的创新是基于Hapax Rate模型引入了对Zipf和Heaps定律的修正，并发现逻辑模型拟合效果最优。

    

    本文基于Hapax Rate模型引入了对Zipf和Heaps定律的修正。推导基于两个假设：第一个假设是标准的瓮模型，预测较短文本的边际词频分布看起来就像是从一个给定的较长文本中盲目采样词元。第二个假设假定Hapax的频率是文本大小的简单函数。讨论了四个这样的函数：常数模型、Davis模型、线性模型和逻辑模型。结果显示逻辑模型拟合效果最好。

    The article introduces corrections to Zipf's and Heaps' laws based on systematic models of the hapax rate. The derivation rests on two assumptions: The first one is the standard urn model which predicts that marginal frequency distributions for shorter texts look as if word tokens were sampled blindly from a given longer text. The second assumption posits that the rate of hapaxes is a simple function of the text size. Four such functions are discussed: the constant model, the Davis model, the linear model, and the logistic model. It is shown that the logistic model yields the best fit.
    
[^66]: 衡量自然语言处理模型面对领域转移的鲁棒性

    Measuring the Robustness of Natural Language Processing Models to Domain Shifts. (arXiv:2306.00168v1 [cs.CL])

    [http://arxiv.org/abs/2306.00168](http://arxiv.org/abs/2306.00168)

    本文探讨了自然领域转移设置下微调和小样本学习模型的DR挑战，引入了一个DR基准，提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），并发现两者之一通常是正值，强调了评估DR挑战的两个视角的重要性。

    

    大型语言模型在各种任务中表现出了很好的性能，包括微调、小样本学习和零样本学习。然而，它们在没有标记数据的领域中的性能仍然落后于有标记数据的领域，我们称之为领域鲁棒性（DR）挑战。现有的DR研究存在不一致的设置、缺乏评估任务的多样性和过多依靠挑战集。在本文中，我们探讨了自然领域转移设置下微调和小样本学习模型的DR挑战。我们引入了一个DR基准，包括多样化的NLP任务，包括句子和标记级分类、问答和生成，每个任务都由几个领域组成。我们提出了DR挑战的两个视角：源域降低（SD）和目标域降低（TD），它们交替作为参考点来比较源域和目标域的性能。我们发现，在重大比例的领域转移中，SD或TD之一是正的，但不是两者都正，强调了评估DR挑战的两个视角的重要性。我们的基准允许在模型、任务和设置上公平比较DR，并提供有关NLP模型DR性质的见解。

    Large Language Models have shown promising performance on various tasks, including fine-tuning, few-shot learning, and zero-shot learning. However, their performance on domains without labeled data still lags behind those with labeled data, which we refer as the Domain Robustness (DR) challenge. Existing research on DR suffers from disparate setups, lack of evaluation task variety, and reliance on challenge sets. In this paper, we explore the DR challenge of both fine-tuned and few-shot learning models in natural domain shift settings. We introduce a DR benchmark comprising diverse NLP tasks, including sentence and token-level classification, QA, and generation, each task consists of several domains. We propose two views of the DR challenge: Source Drop (SD) and Target Drop (TD), which alternate between the source and target in-domain performance as reference points. We find that in significant proportions of domain shifts, either SD or TD is positive, but not both, emphasizing the imp
    
[^67]: 给我更多细节：利用潜在检索提高事实核查

    Give Me More Details: Improving Fact-Checking with Latent Retrieval. (arXiv:2305.16128v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16128](http://arxiv.org/abs/2305.16128)

    该论文提出了一种利用潜在检索来改进事实核查的方法。通过将源文档的全文作为证据，并引入多语言和单语言数据集，该系统能够提供足够的上下文线索，即使没有注释的黄金证据句子，也能进行准确的主张验证，并且在不同的设置下实现了显著的改进。

    

    证据在自动化事实核查中起着关键作用。在验证现实世界的主张时，现有的事实核查系统要么假设提供了证据句子，要么使用搜索引擎返回的搜索片段。这些方法忽略了收集证据的挑战，并且可能没有提供足够的信息来验证现实世界的主张。为了构建一个更好的事实核查系统，我们提出将源文档的全文作为证据，并引入了两个丰富的数据集。第一个是多语言数据集，而第二个是单语言（英语）数据集。我们进一步开发了一个潜变量模型，从文档中联合提取证据句子并进行主张验证。实验证明，即使没有注释的黄金证据句子，包括源文档在内可以提供足够的上下文线索。在不同的设置下，所提出的系统能够在最佳报告模型的基础上实现显著改进。

    Evidence plays a crucial role in automated fact-checking. When verifying real-world claims, existing fact-checking systems either assume the evidence sentences are given or use the search snippets returned by the search engine. Such methods ignore the challenges of collecting evidence and may not provide sufficient information to verify real-world claims. Aiming at building a better fact-checking system, we propose to incorporate full text from source documents as evidence and introduce two enriched datasets. The first one is a multilingual dataset, while the second one is monolingual (English). We further develop a latent variable model to jointly extract evidence sentences from documents and perform claim verification. Experiments indicate that including source documents can provide sufficient contextual clues even when gold evidence sentences are not annotated. The proposed system is able to achieve significant improvements upon best-reported models under different settings.
    
[^68]: ConvGQR：面向会话搜索的生成式查询重构

    ConvGQR: Generative Query Reformulation for Conversational Search. (arXiv:2305.15645v1 [cs.IR])

    [http://arxiv.org/abs/2305.15645](http://arxiv.org/abs/2305.15645)

    本文提出了一种新的面向会话搜索的ConvGQR框架，通过结合预训练语言模型来重新构造查询，从而提供更好的搜索查询。

    

    在会话搜索中，用户当前搜索意图依赖于先前的对话历史。从整个对话上下文中确定一个良好的搜索查询是具有挑战性的。为避免查询编码器的昂贵重新训练，大部分现有方法尝试学习一个重写模型，通过模仿手动查询重写来去除当前查询的上下文。然而，手动重写的查询并不总是最好的搜索查询。训练重写模型会限制模型产生良好搜索查询的能力。本文提出一种新的框架ConvGQR，基于预训练语言模型（PLM），一个用于查询重写，另一个用于生成潜在答案，以重新构造会话查询。通过结合两者，ConvGQR可以提供更好的搜索查询。此外，为了将查询重构与检索性能联系起来，我们提出了一种基于特征选择的相似度分数模型，用于验证ConvGQR的有效性。

    In conversational search, the user's real search intent for the current turn is dependent on the previous conversation history. It is challenging to determine a good search query from the whole conversation context. To avoid the expensive re-training of the query encoder, most existing methods try to learn a rewriting model to de-contextualize the current query by mimicking the manual query rewriting. However, manually rewritten queries are not always the best search queries. Training a rewriting model on them would limit the model's ability to produce good search queries. Another useful hint is the potential answer to the question. In this paper, we propose ConvGQR, a new framework to reformulate conversational queries based on generative pre-trained language models (PLMs), one for query rewriting and another for generating potential answers. By combining both, ConvGQR can produce better search queries. In addition, to relate query reformulation to retrieval performance, we propose a 
    
[^69]: mPLM-Sim: 揭示多语言预训练语言模型中更好的跨语言相似性和迁移

    mPLM-Sim: Unveiling Better Cross-Lingual Similarity and Transfer in Multilingual Pretrained Language Models. (arXiv:2305.13684v1 [cs.CL])

    [http://arxiv.org/abs/2305.13684](http://arxiv.org/abs/2305.13684)

    mPLM-Sim是一种新的语言相似度测量方法，利用多语言平行语料库从mPLMs中引导出语言之间的相似性，可用于选择源语言以增强跨语言迁移，具有中等程度的相关性。不同的mPLMs和层产生不同的相似性结果。

    

    近期的多语言预训练语言模型（mPLMs）已经证明具有强大的特定语言信号，这些信号在预训练期间并没有被明确提供。目前仍然存在一个问题，即是否可将mPLMs用于测量语言相似性，并随后使用相似性结果选择源语言以增强跨语言迁移。为了研究这一问题，我们提出了一种新的语言相似度测量方法mPLM-Sim，它利用多语言平行语料库从mPLMs中引导出语言之间的相似性。我们的研究表明，mPLM-Sim与词汇统计、语系和地理区域等语言相似度测量具有中等程度的相关性。我们还对相关性较低的语言进行了案例研究，并观察到mPLM-Sim产生更准确的相似性结果。此外，我们发现相似性结果因不同的mPLMs和mPLM中的不同层而异。我们进一步调查了mPLMs对语言迁移的影响。

    Recent multilingual pretrained language models (mPLMs) have been shown to encode strong language-specific signals, which are not explicitly provided during pretraining. It remains an open question whether it is feasible to employ mPLMs to measure language similarity, and subsequently use the similarity results to select source languages for boosting cross-lingual transfer. To investigate this, we propose mPLM-Sim, a new language similarity measure that induces the similarities across languages from mPLMs using multi-parallel corpora. Our study shows that mPLM-Sim exhibits moderately high correlations with linguistic similarity measures, such as lexicostatistics, genealogical language family, and geographical sprachbund. We also conduct a case study on languages with low correlation and observe that mPLM-Sim yields more accurate similarity results. Additionally, we find that similarity results vary across different mPLMs and different layers within an mPLM. We further investigate whethe
    
[^70]: CEO：基于语料库的开放域事件本体诱导

    CEO: Corpus-based Open-Domain Event Ontology Induction. (arXiv:2305.13521v1 [cs.CL])

    [http://arxiv.org/abs/2305.13521](http://arxiv.org/abs/2305.13521)

    本文介绍了一种名为CEO的事件本体诱导模型，它可以放松预定义事件本体所强加的限制，通过远程监督检测整个语料库中显著的事件，并诱导具有有意义名称的分层事件本体，实验结果表明，其诱导的模式具有更好的覆盖范围和更高的准确性。

    

    现有的面向事件的自然语言处理模型通常仅适用于预定义本体，这严重限制了它们的泛化能力。本文介绍了一种新颖的基于语料库的事件本体诱导模型CEO，以放松预定义事件本体所强加的限制。在没有直接监督的情况下，CEO利用可用摘要数据集的远程监督来检测整个语料库中显著的事件，并利用外部事件知识使距离短的事件具有相似的嵌入。对三个常用的事件数据集进行的实验表明，CEO诱导的模式具有比以前的方法更好的覆盖范围和更高的准确性。此外，CEO是第一个能在十一个开放域语料库上诱导具有有意义名称的分层事件本体的事件本体诱导模型，使诱导的模式更值得信赖并更易于进一步编辑。

    Existing event-centric NLP models often only apply to the pre-defined ontology, which significantly restricts their generalization capabilities. This paper presents CEO, a novel Corpus-based Event Ontology induction model to relax the restriction imposed by pre-defined event ontologies. Without direct supervision, CEO leverages distant supervision from available summary datasets to detect corpus-wise salient events and exploits external event knowledge to force events within a short distance to have close embeddings. Experiments on three popular event datasets show that the schema induced by CEO has better coverage and higher accuracy than previous methods. Moreover, CEO is the first event ontology induction model that can induce a hierarchical event ontology with meaningful names on eleven open-domain corpora, making the induced schema more trustworthy and easier to be further curated.
    
[^71]: EnCore:通过在指代链上预训练实体编码器来进行精细粒度实体类型标注

    EnCore: Fine-Grained Entity Typing by Pre-Training Entity Encoders on Coreference Chains. (arXiv:2305.12924v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12924](http://arxiv.org/abs/2305.12924)

    本文提出了EnCore模型，通过预训练实体编码器并使用谨慎筛选的共指链接，提高了细粒度实体类型标注的性能。

    

    实体类型标注是将语义类型分配给文本中提到的实体的任务。在细粒度实体类型标注（FET）的情况下，考虑了一个大型的候选类型标签集合。由于获取足够的手动注释往往成本高昂，因此FET模型通常使用远程监督进行训练。在本文中，我们提出通过预训练实体编码器，使得共指实体的嵌入更相似于彼此，而不是其他实体，来改进这个过程。这种策略的主要问题是，预测的共指链接通常存在噪声。我们证明通过使用一个简单的技巧可以解决该问题：我们只考虑由两个不同的现成系统预测的共指链接。通过谨慎使用共指链接，我们的预训练策略使我们能够改进基准测试结果

    Entity typing is the task of assigning semantic types to the entities that are mentioned in a text. In the case of fine-grained entity typing (FET), a large set of candidate type labels is considered. Since obtaining sufficient amounts of manual annotations is then prohibitively expensive, FET models are typically trained using distant supervision. In this paper, we propose to improve on this process by pre-training an entity encoder such that embeddings of coreferring entities are more similar to each other than to the embeddings of other entities. The main problem with this strategy, which helps to explain why it has not previously been considered, is that predicted coreference links are often too noisy. We show that this problem can be addressed by using a simple trick: we only consider coreference links that are predicted by two different off-the-shelf systems. With this prudent use of coreference links, our pre-training strategy allows us to improve the state-of-the-art in benchma
    
[^72]: 通过人机协作解决自然语言处理难题：一种基于讨论的方法

    Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach. (arXiv:2305.11789v1 [cs.CL])

    [http://arxiv.org/abs/2305.11789](http://arxiv.org/abs/2305.11789)

    本研究提出了一种基于讨论的方法，旨在通过人机协作解决自然语言处理难题。提出了一个可以进行对话并修正预测的系统，通过实验证明该系统可以通过与人类的讨论提高准确性高达25%。

    

    人类通过讨论、解释并相互赞同或反对等方式共同解决共同问题。同样，如果系统在解决任务时能与人类进行讨论，它可以提高系统的性能和可靠性。在之前的可解释性研究中，系统只能做出预测，人类只能就这些预测提问，而没有彼此间的意见交换。本研究旨在创建一个数据集和计算框架，使系统可以通过对话进行讨论和修正预测。通过实验证明，所提出的系统可以与人类进行有益的讨论，将自然语言推理任务的准确性提高了高达25个百分点。

    Humans work together to solve common problems by having discussions, explaining, and agreeing or disagreeing with each other. Similarly, if a system can have discussions with humans when solving tasks, it can improve the system's performance and reliability. In previous research on explainability, it has only been possible for the system to make predictions and for humans to ask questions about them rather than having a mutual exchange of opinions. This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.
    
[^73]: 基于知识增强的生成预训练模型在中国医学执业医师资格考试上的应用研究

    Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model. (arXiv:2305.10163v1 [cs.CL])

    [http://arxiv.org/abs/2305.10163](http://arxiv.org/abs/2305.10163)

    本研究通过在ChatGPT中集成医学领域知识和启用少样本学习的新方法，在中国国家医学执业医师资格考试中取得成功，这为建立在自然语言处理技术和医学领域知识的创新应用提供了可能。

    

    生成式预训练模型（GPT），如ChatGPT，在各种自然语言处理任务中展现出了出色的性能。尽管ChatGPT已被整合到各个领域的工作流中以提高效率，但其微调过程的灵活性不足，阻碍了其在需要广泛领域专业知识和语义知识的领域，如医疗保健，的应用。在本文中，我们评估了ChatGPT在中国国家医学执业医师资格考试（CNMLE）中的表现，并提出了一种新的方法来改进ChatGPT，即从两个方面集成医学领域知识和启用少样本学习。通过使用简单但有效的检索方法，将医学背景知识提取为语义指令来指导ChatGPT的推断。类似地，相关的医疗问题被识别并作为演示输入给ChatGPT。实验结果表明，直接应用ChatGPT无法在CNMLE上获得合格分数（51分），只有基于知识增强训练的模型成功通过考试。

    Generative Pre-Training (GPT) models like ChatGPT have demonstrated exceptional performance in various Natural Language Processing (NLP) tasks. Although ChatGPT has been integrated into the overall workflow to boost efficiency in many domains, the lack of flexibility in the finetuning process hinders its applications in areas that demand extensive domain expertise and semantic knowledge, such as healthcare. In this paper, we evaluate ChatGPT on the China National Medical Licensing Examination (CNMLE) and propose a novel approach to improve ChatGPT from two perspectives: integrating medical domain knowledge and enabling few-shot learning. By using a simple but effective retrieval method, medical background knowledge is extracted as semantic instructions to guide the inference of ChatGPT. Similarly, relevant medical questions are identified and fed as demonstrations to ChatGPT. Experimental results show that directly applying ChatGPT fails to qualify the CNMLE at a score of 51 (i.e., onl
    
[^74]: 为建立联邦 GPT 做出努力：联邦指令调整

    Towards Building the Federated GPT: Federated Instruction Tuning. (arXiv:2305.05644v1 [cs.CL])

    [http://arxiv.org/abs/2305.05644](http://arxiv.org/abs/2305.05644)

    本文提出了一种名为Federated Instruction Tuning (FedIT)的新方法，利用联邦学习（FL）模型对LLMs进行指令调整，以解决获取高质量指令数据的挑战，从而提高调整模型的通用性和效果。

    

    虽然“指令调整”生成大型语言模型（LLMs）展现出了出色的新任务概括能力，但训练阶段严重依赖于大量多样和高质量的指令数据（如ChatGPT和GPT-4）。然而，获取高质量数据，特别是人工撰写的数据，可能会面临显著的成本和可访问性方面的挑战。此外，与隐私有关的问题可能会进一步限制对这些数据的访问，使得获取数据的过程变得复杂而微妙。因此，这限制了调整模型的通用性并可能限制其在特定情境下的效果。为解决这个问题，我们的研究引入了一种新的方法，称为联邦指令调整（FedIT），它利用联邦学习（FL）作为LLMs指令调整的学习框架。这是FL在LLMs指令调整中的首次探索。这尤其重要，因为...

    While ``instruction-tuned" generative large language models (LLMs) have demonstrated an impressive ability to generalize to new tasks, the training phases heavily rely on large amounts of diverse and high-quality instruction data (such as ChatGPT and GPT-4). Unfortunately, acquiring high-quality data, especially when it comes to human-written data, can pose significant challenges both in terms of cost and accessibility. Moreover, concerns related to privacy can further limit access to such data, making the process of obtaining it a complex and nuanced undertaking. Consequently, this hinders the generality of the tuned models and may restrict their effectiveness in certain contexts. To tackle this issue, our study introduces a new approach called Federated Instruction Tuning (FedIT), which leverages federated learning (FL) as the learning framework for the instruction tuning of LLMs. This marks the first exploration of FL-based instruction tuning for LLMs. This is especially important s
    
[^75]: LaMini-LM: 基于大规模指令的多样性压缩模型群集

    LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions. (arXiv:2304.14402v1 [cs.CL])

    [http://arxiv.org/abs/2304.14402](http://arxiv.org/abs/2304.14402)

    本文提出的LaMini-LM是一种基于大规模指令的多样性压缩模型群集，从指令微调过的LLMs中提取知识到更小的模型中，其在15个不同的NLP基准测试中与其他竞争基线的表现相当，但体积约小了10倍。

    

    指令微调的大型语言模型表现出优秀的生成能力，但是这些模型需要大量的资源。为了减轻这个问题，我们探索从微调过的LLMs中提取知识到更小的模型中。为此，我们仔细开发了一组258万份基于现有和新生成的指令。除了规模大之外，我们还设计了广泛的话题，以确保指令的多样性，并使用gpt-3.5-turbo为这些指令生成响应。我们使用这些指令来微调多个模型，即LaMini-LM，包括编码器-解码器和仅解码器系列。我们对这些模型进行自动（在15个不同的NLP基准测试中）和手动评估。结果表明，我们提出的LaMini-LM与其他竞争基线的表现相当，而且体积约小了10倍。

    Large language models (LLMs) with instruction finetuning demonstrate superior generative capabilities. However, these models are resource intensive. To alleviate this issue, we explore distilling knowledge from instruction-tuned LLMs to much smaller ones. To this end, we carefully develop a large set of 2.58M instructions based on both existing and newly-generated instructions. In addition to being sizeable, we design our instructions to cover a broad set of topics to ensure. A thorough investigation of our instruction data demonstrate their diversity, and we generate responses for these instructions using gpt-3.5-turbo. We then exploit the instructions to tune a host of models, dubbed LaMini-LM, of varying sizes, both from the encoder-decoder as well as the decoder-only families. We evaluate our models both automatically (on 15 different NLP benchmarks) and manually. Results show that our proposed LaMini-LM are on par with competitive baselines while being nearly 10 times smaller in s
    
[^76]: 有效地对齐跨语言会话任务的提示调整跨语言转移学习

    Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning. (arXiv:2304.01295v1 [cs.CL])

    [http://arxiv.org/abs/2304.01295](http://arxiv.org/abs/2304.01295)

    本文提出了一个平行大规模多语种会话数据集XSGD，开发了一种有效的基于提示调整的方法来学习对齐提示，同时研究了跨语言任务的NLI-based和vanilla分类器，并在插槽填充和意图分类任务上评估了模型的跨语言泛化能力。

    

    针对自然语言处理任务，跨语言转移的语言模型已被广泛研究，但是对于会话任务的研究相对较少。本文提出了XSGD，这是一个由Schema-Guided Dialogue（SGD）翻译成105种其他语言的平行大规模多语种会话数据集。为了实现对齐的跨语言表示方法，我们开发了一种有效的基于提示调整的方法来学习对齐提示。我们还研究了两种不同的分类器：NLI-based和vanilla分类器，并测试了对齐提示所实现的跨语言能力。我们在两个对话任务（插槽填充和意图分类）上评估了我们模型的跨语言泛化能力。

    Cross-lingual transfer of language models trained on high-resource languages like English has been widely studied for many NLP tasks, but focus on conversational tasks has been rather limited. This is partly due to the high cost of obtaining non-English conversational data, which results in limited coverage. In this work, we introduce XSGD, a parallel and large-scale multilingual conversation dataset that we created by translating the English-only Schema-Guided Dialogue (SGD) dataset (Rastogi et al., 2020) into 105 other languages. XSGD contains approximately 330k utterances per language. To facilitate aligned cross-lingual representations, we develop an efficient prompt-tuning-based method for learning alignment prompts. We also investigate two different classifiers: NLI-based and vanilla classifiers, and test cross-lingual capability enabled by the aligned prompts. We evaluate our model's cross-lingual generalization capabilities on two conversation tasks: slot-filling and intent cla
    
[^77]: 如同一个好邻居：实用的内容审核和文本分类

    Like a Good Nearest Neighbor: Practical Content Moderation and Text Classification. (arXiv:2302.08957v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08957](http://arxiv.org/abs/2302.08957)

    我们提出了一种名为LaGoNN的修改方法，该方法在不引入可学习参数的情况下，通过使用训练数据中最近邻的信息改变输入文本，从而使新颖的数据看起来类似于模型优化的实例。该方法对于标记不需要的内容和文本分类非常有效，并且改善了效果。

    

    少样本文本分类系统具有令人印象深刻的能力，但由于依赖于提示和十亿参数的语言模型，因此无法可靠地部署和使用。SetFit（Tunstall等，2022年）是一种最近的实用方法，它在对比学习范式下微调了一个句子转换器，并取得了与更难管理的系统类似的结果。廉价的文本分类对于解决所有分类任务中的领域漂移问题非常重要，尤其是在检测社交媒体平台上的有害内容方面。在这里，我们提出了像一个好邻居（LaGoNN）这样的修改SetFit的方法，它不引入可学习参数，但是通过使用训练数据中最近邻的信息改变输入文本，例如标签和文本，使新颖的数据看起来类似于模型优化的实例。LaGoNN在标记不需要的内容和文本分类方面非常有效，并且改善了效果。

    Few-shot text classification systems have impressive capabilities but are infeasible to deploy and use reliably due to their dependence on prompting and billion-parameter language models. SetFit (Tunstall et al., 2022) is a recent, practical approach that fine-tunes a Sentence Transformer under a contrastive learning paradigm and achieves similar results to more unwieldy systems. Inexpensive text classification is important for addressing the problem of domain drift in all classification tasks, and especially in detecting harmful content, which plagues social media platforms. Here, we propose Like a Good Nearest Neighbor (LaGoNN), a modification to SetFit that introduces no learnable parameters but alters input text with information from its nearest neighbor, for example, the label and text, in the training data, making novel data appear similar to an instance on which the model was optimized. LaGoNN is effective at flagging undesirable content and text classification, and improves the
    
[^78]: 灵活的、模型无关的方法用于从文本中提取材料数据，使用通用语言模型

    Flexible, Model-Agnostic Method for Materials Data Extraction from Text Using General Purpose Language Models. (arXiv:2302.04914v2 [cond-mat.mtrl-sci] UPDATED)

    [http://arxiv.org/abs/2302.04914](http://arxiv.org/abs/2302.04914)

    本文提出了一个灵活的、模型无关的方法，使用通用语言模型从研究论文中提取材料数据。该方法几乎不需要编码或模型训练，并且在生成的数据库中具有高召回率和几乎完美的精确度。

    

    准确和全面的从研究论文中提取材料数据库对于材料科学和工程至关重要，但需要大量人力来开发。本文提出了一种简单的方法，从研究论文的全文中提取材料数据，适用于快速开发规模适中的数据库。该方法几乎不需要编码，不需要关于提取属性的先验知识或模型训练，且在生成的数据库中具有高召回率和几乎完美的精确度。该方法是完全自动化的，除了一个需要人工辅助的步骤，通常只需要几个小时的人力劳动。该方法基于自然语言处理和大型通用语言模型，但几乎可以与任何此类模型一起使用。这里评估了GPT-3/3.5、bart和DeBERTaV3这些语言模型的性能比较。我们详细分析了该方法在提取体模量数据方面的性能，获得了高达90%的精确度。

    Accurate and comprehensive material databases extracted from research papers are critical for materials science and engineering but require significant human effort to develop. In this paper we present a simple method of extracting materials data from full texts of research papers suitable for quickly developing modest-sized databases. The method requires minimal to no coding, prior knowledge about the extracted property, or model training, and provides high recall and almost perfect precision in the resultant database. The method is fully automated except for one human-assisted step, which typically requires just a few hours of human labor. The method builds on top of natural language processing and large general language models but can work with almost any such model. The language models GPT-3/3.5, bart and DeBERTaV3 are evaluated here for comparison. We provide a detailed detailed analysis of the methods performance in extracting bulk modulus data, obtaining up to 90% precision at 9
    
[^79]: 用混合神经网络SBERT-CNN检测Reddit用户的抑郁症状态

    Detecting Reddit Users with Depression Using a Hybrid Neural Network SBERT-CNN. (arXiv:2302.02759v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.02759](http://arxiv.org/abs/2302.02759)

    本论文介绍了一种混合神经网络模型，结合了预训练的SBERT和CNN，用于通过分析Reddit用户的帖子自动识别抑郁症患者。

    

    抑郁症是一种广泛存在的心理健康问题，影响了全球估计3.8%的人口。它也是全球残疾的主要因素之一。最近，个人越来越喜欢使用社交媒体平台（如Reddit）来表达他们的困难和健康问题（如抑郁症），并在在线社区寻求其他用户的支持。这为通过分析数百万帖子以寻找潜在的干预机会，自动识别具有抑郁症的社交媒体用户提供了巨大的机会。深度学习方法因其易用性、高效处理能力和在许多自然语言处理（NLP）任务上的最新结果而在机器学习和自然语言处理领域开始占据主导地位。在这项工作中，我们提出了一种混合深度学习模型，将预训练的句子BERT（SBERT）和卷积神经网络（CNN）结合起来，以通过他们在Reddit上的帖子检测抑郁症患者。句子BERT用于学习句子的意思。

    Depression is a widespread mental health issue, affecting an estimated 3.8% of the global population. It is also one of the main contributors to disability worldwide. Recently it is becoming popular for individuals to use social media platforms (e.g., Reddit) to express their difficulties and health issues (e.g., depression) and seek support from other users in online communities. It opens great opportunities to automatically identify social media users with depression by parsing millions of posts for potential interventions. Deep learning methods have begun to dominate in the field of machine learning and natural language processing (NLP) because of their ease of use, efficient processing, and state-of-the-art results on many NLP tasks. In this work, we propose a hybrid deep learning model which combines a pretrained sentence BERT (SBERT) and convolutional neural network (CNN) to detect individuals with depression with their Reddit posts. The sentence BERT is used to learn the meaning
    
[^80]: AutoPEFT：用于参数高效微调的自动配置搜索

    AutoPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning. (arXiv:2301.12132v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.12132](http://arxiv.org/abs/2301.12132)

    AutoPEFT是一个自动化的PEFT（参数高效微调）配置搜索方法，它能够自动地找到最佳的PEFT模块和体系结构，以优化任务的性能和参数效率。在典型的NLP任务中，AutoPEFT表现出比手动设计更好的性能。

    

    大型预训练语言模型通过专门的微调用于下游NLP任务，但这样的过程可能很昂贵。最近，参数高效微调（PEFT）方法通过更新比完整模型微调（FFT）少得多的参数，实现了强大的任务性能。然而，在PEFT配置方面做出明智的设计选择是不容易的，例如它们的体系结构、可调参数的数量，甚至是PEFT模块插入的图层。因此，目前的手动设计配置很可能在性能效率权衡方面是次优的。受神经架构搜索的进展启发，我们提出了AutoPEFT来自动选择PEFT配置：首先设计具有多个代表性PEFT模块的表达配置搜索空间。然后使用多目标贝叶斯优化进行低成本的设置，从而发现优化任务性能和参数效率的Pareto优化配置。我们在几个典型的NLP任务，包括文本分类、问答和命名实体识别上评估了AutoPEFT，并展示了其优于手动设计基线的性能。

    Large pretrained language models are widely used in downstream NLP tasks via task-specific fine-tuning, but such procedures can be costly. Recently, Parameter-Efficient Fine-Tuning (PEFT) methods have achieved strong task performance while updating a much smaller number of parameters compared to full model fine-tuning (FFT). However, it is non-trivial to make informed design choices on the PEFT configurations, such as their architecture, the number of tunable parameters, and even the layers in which the PEFT modules are inserted. Consequently, it is highly likely that the current, manually designed configurations are suboptimal in terms of their performance-efficiency trade-off. Inspired by advances in neural architecture search, we propose AutoPEFT for automatic PEFT configuration selection: we first design an expressive configuration search space with multiple representative PEFT modules as building blocks. Using multi-objective Bayesian optimisation in a low-cost setup, we then disc
    
[^81]: 对基于Transformer的自监督模型在语音处理中进行压缩

    Compressing Transformer-based self-supervised models for speech processing. (arXiv:2211.09949v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.09949](http://arxiv.org/abs/2211.09949)

    本文研究了对基于Transformer的自监督模型进行压缩的方法，包括权重修剪、头部修剪、低秩逼近和知识蒸馏。结果发现，基本的压缩技术是强大的基准，可以改善模型的压缩效果。

    

    尽管Transformer在自监督学习中取得了成功，并应用于各种下游任务，但是训练和推断的计算成本仍然是将这些模型应用于各种设备的主要挑战。目前已有一些孤立的尝试来压缩Transformer，但研究中的设置和指标各不相同。此前的工作很少涉及不同压缩率之间的权衡，这使得比较压缩技术变得困难。在这项工作中，我们旨在为这些孤立结果提供背景，研究几种常用的压缩技术，包括权重修剪、头部修剪、低秩逼近和知识蒸馏。我们报告了在不同压缩率下的权衡，包括墙钟时间、参数数量和乘加操作数量。我们的结果表明，与最近的方法相比，基本的压缩技术是强大的基准。我们进一步提出了几种压缩方法来改进模型的压缩效果。

    Despite the success of Transformers in self- supervised learning with applications to various downstream tasks, the computational cost of training and inference remains a major challenge for applying these models to a wide spectrum of devices. Several isolated attempts have been made to compress Transformers, but the settings and metrics are different across studies. Trade-off at various compression rates are also largely missing in prior work, making it difficult to compare compression techniques. In this work, we aim to provide context for the isolated results, studying several commonly used compression techniques, including weight pruning, head pruning, low-rank approximation, and knowledge distillation. We report trade- off at various compression rate, including wall-clock time, the number of parameters, and the number of multiply-accumulate operations. Our results show that compared to recent approaches, basic compression techniques are strong baselines. We further present several
    
[^82]: 波斯-阿拉伯文字的字形规范化

    Graphemic Normalization of the Perso-Arabic Script. (arXiv:2210.12273v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.12273](http://arxiv.org/abs/2210.12273)

    本文记录了波斯-阿拉伯文字在自然语言处理中的挑战，包括使用外观上相似但规范上不等价的字母以及混合使用来自不同正字法的字母。对于这些挑战，本文提供了字形规范化的解决方案，并评估了其对不同方面的影响。

    

    自1991年首次出现以来，Unicode中的波斯-阿拉伯文字表示已经从169个扩展到了超过440个原子孤立字符，分布在多个代码页中，代表了原始阿拉伯语和许多其他地区正字法传统的标准字母、各种变音符号和标点符号。本文记录了波斯-阿拉伯文字在自然语言处理（NLP）中的挑战，这些挑战超出了阿拉伯语和波斯语等最受研究的语言。我们尤其关注NLP中的情况，该问题受到多个常常被忽视的问题的影响，如使用外观上模糊但规范上不等价的字母以及混合使用来自不同正字法的字母。造成这种混淆的因素包括缺乏输入方法、现代正字法的不稳定性、识字能力不足以及正字传统的丢失或缺乏。我们评估了字形规范化对八个方面的影响。

    Since its original appearance in 1991, the Perso-Arabic script representation in Unicode has grown from 169 to over 440 atomic isolated characters spread over several code pages representing standard letters, various diacritics and punctuation for the original Arabic and numerous other regional orthographic traditions. This paper documents the challenges that Perso-Arabic presents beyond the best-documented languages, such as Arabic and Persian, building on earlier work by the expert community. We particularly focus on the situation in natural language processing (NLP), which is affected by multiple, often neglected, issues such as the use of visually ambiguous yet canonically nonequivalent letters and the mixing of letters from different orthographies. Among the contributing conflating factors are the lack of input methods, the instability of modern orthographies, insufficient literacy, and loss or lack of orthographic tradition. We evaluate the effects of script normalization on eigh
    
[^83]: 关于敏感性与准确性在上下文学习中的关系

    On the Relation between Sensitivity and Accuracy in In-context Learning. (arXiv:2209.07661v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.07661](http://arxiv.org/abs/2209.07661)

    在上下文学习中，我们发现ICL对多种扰动类型具有敏感性，标签偏差导致过去的研究低估了ICL的敏感性。同时，我们观察到ICL的敏感性和准确性之间呈现负相关关系。基于这些发现，我们提出了一种少样本选择性预测方法SenSel，它在放弃敏感预测决策上取得了优于常用基准方法的结果。

    

    上下文学习 (In-context learning, ICL) 在实际场景中常常受到提示的过度敏感性的影响，导致其在现实世界中不可靠。我们研究了ICL对多种扰动类型的敏感性。首先，我们发现标签偏差掩盖了真实的敏感性，因此之前的研究可能大大低估了ICL的敏感性。其次，我们观察到ICL的敏感性与准确性之间存在强烈的负相关关系：对扰动敏感的预测更不容易正确。在这些发现的基础上，我们提出了一种称为SenSel的少样本选择性预测方法，该方法避免了对敏感预测的使用。在十个分类数据集上的实验证明，SenSel在放弃预测决策上始终优于两种常用的基于置信度和基于熵的基准方法。

    In-context learning (ICL) suffers from oversensitivity to the prompt, making it unreliable in real-world scenarios. We study the sensitivity of ICL with respect to multiple perturbation types. First, we find that label bias obscures the true sensitivity, and therefore prior work may have significantly underestimated ICL sensitivity. Second, we observe a strong negative correlation between ICL sensitivity and accuracy: predictions sensitive to perturbations are less likely to be correct. Motivated by these findings, we propose \textsc{SenSel}, a few-shot selective prediction method that abstains from sensitive predictions. Experiments on ten classification datasets show that \textsc{SenSel} consistently outperforms two commonly used confidence-based and entropy-based baselines on abstention decisions.
    
[^84]: DiSCoMaT：材料科学文章中基于远程监督的表格组成提取

    DiSCoMaT: Distantly Supervised Composition Extraction from Tables in Materials Science Articles. (arXiv:2207.01079v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.01079](http://arxiv.org/abs/2207.01079)

    本文提出了一个新型挑战任务，即通过远程监督方式从科学文章中的表格中提取有关材料组成的信息。为此，研究者创建了一个包含4408个远程监督表格和1475个手动注释的开发和测试表格的训练数据集，并提出了一个强基线——DiSCoMaT。

    

    从科学领域文章中的表格中提取有关材料组成的信息是知识库策划的重要组成部分。然而，现有的表格提取器假定您已经了解表格结构和格式，而科学表格中可能没有这些先前的知识。本文研究了一种特定且具有挑战性的表格提取问题：提取材料（例如玻璃，合金）的组成。我们首先观察到材料科学研究人员使用各种表格样式组织类似的组成，这需要一个智能模型来理解表格和提取组成。因此，我们将其定义为机器学习领域的新型挑战，并创建了一个由4408个远程监督表格和1475个手动注释的开发和测试表格组成的训练数据集。我们还提出了DiSCoMaT，它是一个针对该问题的强基线。

    A crucial component in the curation of KB for a scientific domain is information extraction from tables in the domain's published articles -- tables carry important information (often numeric), which must be adequately extracted for a comprehensive machine understanding of an article. Existing table extractors assume prior knowledge of table structure and format, which may not be known in scientific tables. We study a specific and challenging table extraction problem: extracting compositions of materials (e.g., glasses, alloys). We first observe that materials science researchers organize similar compositions in a wide variety of table styles, necessitating an intelligent model for table understanding and composition extraction. Consequently, we define this novel task as a challenge for the ML community and create a training dataset comprising 4,408 distantly supervised tables, along with 1,475 manually annotated dev and test tables. We also present DiSCoMaT, a strong baseline geared t
    
[^85]: MiniDisc: 最小蒸馏计划用于语言模型压缩

    MiniDisc: Minimal Distillation Schedule for Language Model Compression. (arXiv:2205.14570v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.14570](http://arxiv.org/abs/2205.14570)

    本研究提出了一个叫做MiniDisc的最小蒸馏计划，可以在最少一次尝试中调度最优的教师助手，用于实现语言模型压缩。

    

    最近的研究发现，在教师模型和学生模型之间存在较大的容量差距时，语言模型蒸馏的效果不佳，引入了教师助手辅助蒸馏来弥补差距。然而，现有的基于教师助手的方法需要大量的尝试才能调度出最优的教师助手。为此，我们提出了一种最小蒸馏计划（MiniDisc），可以在最少一次尝试中调度最优的教师助手。MiniDisc是基于教师助手的规模-性能的权衡来度量教师助手的最优性，并可以在不对学生进行实验的情况下调度最优的教师助手。

    Recent studies have uncovered that language model distillation is less effective when facing a large capacity gap between the teacher and the student, and introduced teacher assistant-based distillation to bridge the gap. As a connection, the scale and the performance of the teacher assistant is of vital importance to bring the knowledge from the teacher to the student. However, existing teacher assistant-based methods require maximally many trials before scheduling an optimal teacher assistant. To this end, we propose a minimal distillation schedule (MiniDisc) for scheduling the optimal teacher assistant in minimally one trial. In particular, motivated by the finding that the performance of the student is positively correlated to the scale-performance tradeoff of the teacher assistant, MiniDisc is designed with a $\lambda$-tradeoff to measure the optimality of the teacher assistant without trial distillation to the student. MiniDisc then can schedule the optimal teacher assistant with
    
[^86]: 预训练语言模型的地理适应性

    Geographic Adaptation of Pretrained Language Models. (arXiv:2203.08565v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.08565](http://arxiv.org/abs/2203.08565)

    本文研究了预训练语言模型（PLMs）的地理适应性，通过多任务学习中的地理位置预测，成功地注入了地理语言知识，提升了模型在各项任务上的表现。

    

    虽然已经证明预训练语言模型（PLMs）具有丰富的语言知识，但现有的研究大多忽视了与语言无关的地理知识，这些知识通常难以通过仅对文本进行预训练获得。我们通过在多任务学习框架中结合语言建模和地理位置预测来填补这一空白，提出了地理适应性（geoadaptation）。我们对来自三个地理区域的语言组的四个PLMs进行地理适应，并在五个不同的任务上评估它们：经过微调的（即有监督的）地理位置预测、零样本（即无监督的）地理位置预测、经过微调的语言识别、零样本语言识别以及零样本方言特征预测。地理适应性非常成功地将地理语言知识注入到PLMs中：经过地理适应的PLMs在不同任务上表现出色。

    While pretrained language models (PLMs) have been shown to possess a plethora of linguistic knowledge, the existing body of research has largely neglected extralinguistic knowledge, which is generally difficult to obtain by pretraining on text alone. Here, we contribute to closing this gap by examining geolinguistic knowledge, i.e., knowledge about geographic variation in language. We introduce geoadaptation, an intermediate training step that couples language modeling with geolocation prediction in a multi-task learning setup. We geoadapt four PLMs, covering language groups from three geographic areas, and evaluate them on five different tasks: fine-tuned (i.e., supervised) geolocation prediction, zero-shot (i.e., unsupervised) geolocation prediction, fine-tuned language identification, zero-shot language identification, and zero-shot prediction of dialect features. Geoadaptation is very successful at injecting geolinguistic knowledge into the PLMs: the geoadapted PLMs consistently ou
    

