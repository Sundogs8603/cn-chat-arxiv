# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following.](http://arxiv.org/abs/2309.00615) | Point-Bind和Point-LLM是用于3D理解、生成和指导跟随的多模态点云对齐模型，能实现任意到3D生成、3D嵌入算术和3D开放世界的理解，并且Point-LLM能实现3D和多模态问答功能。 |
| [^2] | [Baseline Defenses for Adversarial Attacks Against Aligned Language Models.](http://arxiv.org/abs/2309.00614) | 这篇论文研究了对齐语言模型面临的对抗攻击问题，通过评估基线防御策略的效果，探讨了各种策略的可行性和有效性，并对鲁棒性和性能进行了讨论。 |
| [^3] | [CPSP: Learning Speech Concepts From Phoneme Supervision.](http://arxiv.org/abs/2309.00424) | 论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。 |
| [^4] | [Satisfiability Checking of Multi-Variable TPTL with Unilateral Intervals Is PSPACE-Complete.](http://arxiv.org/abs/2309.00386) | 多变量TPTL与单边区间的可满足性检查是PSPACE-Complete的，与Metric Interval Temporal Logic相比，具有更强的表达能力和更容易的计算检查方法。这是第一个对定时词没有限制的多变量TPTL的可判定可满足性检查的片段。 |
| [^5] | [BatchPrompt: Accomplish more with less.](http://arxiv.org/abs/2309.00384) | BatchPrompt是一种提示策略，它通过将多个数据点批量打包到一个提示中来提高LLM的令牌资源利用效率，从而缓解由于令牌计数差异导致的成本效率问题，提高推理速度和计算预算的利用率。 |
| [^6] | [Long-Term Memorability On Advertisements.](http://arxiv.org/abs/2309.00378) | 本研究是首个大规模的记忆性研究，发现广告的长期记忆性对于市场营销非常重要，但在机器学习文献中一直缺乏相关研究。通过分析大量参与者和广告，我们得出了关于什么使广告记忆深刻的有趣见解。 |
| [^7] | [When Do Discourse Markers Affect Computational Sentence Understanding?.](http://arxiv.org/abs/2309.00368) | 本文研究了自然语言处理（NLP）系统对话语连接词的理解能力，发现不同的连接词种类的处理复杂性不同，对上下文和语言理解任务有影响。 |
| [^8] | [Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior.](http://arxiv.org/abs/2309.00359) | 该论文提出了使用大型内容和行为模型来理解、模拟和优化内容和行为。大型语言模型虽然在任务泛化能力方面取得了进展，但还无法解决预测和优化通信以实现期望接收者行为的问题。其中的一个原因可能是训练语料库中缺少"行为标记"。 |
| [^9] | [Comparative Topic Modeling for Determinants of Divergent Report Results Applied to Macular Degeneration Studies.](http://arxiv.org/abs/2309.00312) | 本研究提出了一种比较话题建模方法，用于分析马克白彦病研究中存在矛盾结果的报告。通过对比不同话题与显著结果的相关性，找到了与黄斑变性研究中显著结果报告相关的八种化合物。 |
| [^10] | [Enhancing the vocal range of single-speaker singing voice synthesis with melody-unsupervised pre-training.](http://arxiv.org/abs/2309.00284) | 本研究提出了一种无旋律监督预训练方法，通过在多歌手数据集上进行预训练，增强了单声道的音域，在不降低音色相似性的情况下。这种方法能够应用于大规模的多歌手数据集，提供音高和音素定时信息，从而改善单声道唱歌声音合成的效果。 |
| [^11] | [RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback.](http://arxiv.org/abs/2309.00267) | RLAIF是一种新的强化学习方法，利用AI反馈代替人类标注偏好，相比强化学习从人类反馈中学习（RLHF），在摘要任务上取得了类似的改进效果，并且在人类评估中得到了相同的认可。这提供了一种有潜力解决RLHF的可扩展性限制的解决方案。 |
| [^12] | [Why do universal adversarial attacks work on large language models?: Geometry might be the answer.](http://arxiv.org/abs/2309.00254) | 本研究从几何视角解释了对大型语言模型的通用对抗性攻击，发现通用对抗性触发器可能是嵌入向量，仅仅近似了其对抗训练区域中的语义信息。 |
| [^13] | [Detecting Suicidality in Arabic Tweets Using Machine Learning and Deep Learning Techniques.](http://arxiv.org/abs/2309.00246) | 使用机器学习和深度学习技术，研究了检测阿拉伯推文中自杀思维的方法。开发了一个新的阿拉伯语自杀推文数据集，训练了多种机器学习模型，并研究了预训练深度学习模型的能力。 |
| [^14] | [NeuroSurgeon: A Toolkit for Subnetwork Analysis.](http://arxiv.org/abs/2309.00244) | NeuroSurgeon是一个用于在Huggingface Transformers库中发现和操作模型子网络的Python工具包，可以推进对神经网络学习算法的理解。 |
| [^15] | [FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking.](http://arxiv.org/abs/2309.00240) | 本研究提出了一种结合外部知识检索来增强指令追踪语言模型的自动事实核查方法，通过利用搜索引擎检索相关证据，并指导调整语言模型，从而提高了事实核查的准确性。 |
| [^16] | [ALJP: An Arabic Legal Judgment Prediction in Personal Status Cases Using Machine Learning Models.](http://arxiv.org/abs/2309.00238) | 这项研究开发了一个使用深度学习和自然语言处理技术预测阿拉伯个人身份案件法律判决的系统，有助于改进法官和律师的工作效率，减少判决差异，并帮助诉讼当事人事先分析案件的可能结果。 |
| [^17] | [Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes.](http://arxiv.org/abs/2309.00237) | 使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。 |
| [^18] | [Image Hijacking: Adversarial Images can Control Generative Models at Runtime.](http://arxiv.org/abs/2309.00236) | 本研究发现对抗性图像能够在运行时控制生成模型，并提出了通用的方法来创建图像劫持。通过研究三种攻击类型，我们发现这些攻击对最新的视觉语言模型具有高达90％以上的成功率。该研究引发了对基础模型安全性的严重担忧。 |
| [^19] | [JoTR: A Joint Transformer and Reinforcement Learning Framework for Dialog Policy Learning.](http://arxiv.org/abs/2309.00230) | JoTR是一种新颖的对话策略学习框架，利用基于Transformer的模型生成灵活的对话动作，提高了响应多样性和系统处理极端情况的能力。 |
| [^20] | [The FruitShell French synthesis system at the Blizzard 2023 Challenge.](http://arxiv.org/abs/2309.00223) | 本文介绍了一个用于Blizzard Challenge 2023的法语文本到语音合成系统，通过对数据的筛选和增强，以及添加词边界和起始/结束符号的方式，提高了语音质量并进行了标准化转录。 |
| [^21] | [Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding.](http://arxiv.org/abs/2309.00215) | 本研究通过语义引地解决了视觉语言任务中对象提议评估不对齐的问题，提出了通过阈值选择注释重要性得分来评估对象提议的方法，并证明了与现有方法相比，在与图像字幕度量和人工注释选择的注释上表现出了极大的改进性对齐。 |
| [^22] | [Large Language Models for Semantic Monitoring of Corporate Disclosures: A Case Study on Korea's Top 50 KOSPI Companies.](http://arxiv.org/abs/2309.00208) | 本研究探讨了OpenAI的GPT-3.5-turbo和GPT-4在韩国上市公司披露中的语义分析能力，并发现GPT-4在人类评估中表现出显著的准确性。 |
| [^23] | [Exploring the law of text geographic information.](http://arxiv.org/abs/2309.00180) | 该论文探索了文本地理信息的规律，通过研究不同语言和类型的数据集，证实了地理信息的数量、长度和距离符合Gamma分布，并且排除了高斯分布和Zipf定律的适用性。 |
| [^24] | [Will Sentiment Analysis Need Subculture? A New Data Augmentation Approach.](http://arxiv.org/abs/2309.00178) | 本文提出了一种新的数据增强方法SCDA，通过利用亚文化表达生成器为每个训练文本生成六个增强文本，以解决情感分析中面临的训练数据不足问题。实验证明了SCDA的有效性和潜力。 |
| [^25] | [LLM in the Shell: Generative Honeypots.](http://arxiv.org/abs/2309.00155) | 本研究引入了一种基于大型语言模型的新方法来创建动态和真实的软件蜜罐，解决了以往蜜罐的重要局限性，并通过实验验证了其高准确率。 |
| [^26] | [Construction Grammar and Artificial Intelligence.](http://arxiv.org/abs/2309.00135) | 建构语法和人工智能之间有着紧密的关系，人工智能领域的洞见和技术对于操作化建构主义方法以及构建智能代理非常重要。 |
| [^27] | [QS-TTS: Towards Semi-Supervised Text-to-Speech Synthesis via Vector-Quantized Self-Supervised Speech Representation Learning.](http://arxiv.org/abs/2309.00126) | 通过向量量化自监督语音表示学习，QS-TTS是一种半监督的TTS框架，通过利用更多无标签语音音频提高合成质量并降低对有监督数据的要求。 |
| [^28] | [Large language models in medicine: the potentials and pitfalls.](http://arxiv.org/abs/2309.00087) | 医学中大规模语言模型（LLMs）的潜力和风险。LLMs已经被广泛应用于医疗任务，但在使用时存在潜在的问题。本文回顾了LLMs的发展、应用和可能的限制，以帮助医疗从业者理解和应对LLMs在医学中的挑战。 |
| [^29] | [YaRN: Efficient Context Window Extension of Large Language Models.](http://arxiv.org/abs/2309.00071) | YaRN是一种高效的上下文窗口扩展方法，可以在大型语言模型中有效利用和推断比原始预训练允许的上下文长度更长的上下文，同时超越了之前的最新研究成果。 |
| [^30] | [Is the U.S. Legal System Ready for AI's Challenges to Human Values?.](http://arxiv.org/abs/2308.15906) | 美国法律需要加强应对生成式人工智能对人类价值观挑战的能力，并提供积极、可审计的指导，以填补现有法律框架在保护基本价值观方面的空白和不确定性。 |
| [^31] | [Efficient Benchmarking (of Language Models).](http://arxiv.org/abs/2308.11696) | 本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。 |
| [^32] | [Activation Addition: Steering Language Models Without Optimization.](http://arxiv.org/abs/2308.10248) | 这项研究探讨了一种在推理时通过改变激活来预测性地改变语言模型行为的方法，并且相比于传统方法具有更低的计算和实施成本，并且能够保持模型性能。 |
| [^33] | [Breaking Language Barriers: A Question Answering Dataset for Hindi and Marathi.](http://arxiv.org/abs/2308.09862) | 本论文开发了一个用于印地语和马拉地语的问答数据集，通过翻译SQuAD 2.0数据集解决了数据稀缺问题，提供了这两种语言的最好表现模型。 |
| [^34] | [Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding.](http://arxiv.org/abs/2307.15484) | 本文提出了两种语音合成方法来解决自回归和非自回归模型中的问题，并在语义编码方面进行了比较研究。 |
| [^35] | [Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models.](http://arxiv.org/abs/2307.11991) | Psy-LLM是一个基于人工智能的系统，利用大型语言模型（LLMs）为在线心理咨询提供问答服务，前端工具可让医疗专业人员提供即时响应和正念活动，同时还可作为筛查工具辅助识别紧急案例。 |
| [^36] | [Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications.](http://arxiv.org/abs/2307.09162) | 本研究分析了大型语言模型中的性别偏见，以GPT-2和GPT-3.5为例，通过全面的文献综述和深入的定量分析揭示了存在的性别化词语关联、语言使用和偏见叙述，并探讨了性别偏见可能对社会认知产生的伦理影响。 |
| [^37] | [AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge.](http://arxiv.org/abs/2307.07851) | AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。 |
| [^38] | [Learning to Prompt in the Classroom to Understand AI Limits: A pilot study.](http://arxiv.org/abs/2307.01540) | 在本研究中，通过学习提示，试图在课堂环境中理解人工智能的限制。人工智能的进展带来了巨大的潜力，但也引发了负面情绪。当前大型语言模型的能力限制被忽视，导致了错误的自信和不准确的建议。承认人工智能的不可靠性是解决这个问题的关键。 |
| [^39] | [CLIPAG: Towards Generator-Free Text-to-Image Generation.](http://arxiv.org/abs/2306.16805) | 本文将感知对齐梯度（PAG）的研究扩展到视觉-语言架构，并通过对 CLIP 进行鲁棒性调整，展示了在视觉-语言生成任务中集成 CLIPAG 可以实现显著改进，并实现了无生成器的文本到图像生成。 |
| [^40] | [C-PMI: Conditional Pointwise Mutual Information for Turn-level Dialogue Evaluation.](http://arxiv.org/abs/2306.15245) | 本研究提出了一种基于条件点对点互信息的模型-无关方法，用于衡量对话系统与用户之间的交互，通过替换评分器，显著改进了与人类判断的相关性。 |
| [^41] | [Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement.](http://arxiv.org/abs/2306.14704) | 本研究提出了一个新的数据集，通过在PubMed摘要中使用SNOMED CT版本，解决了先前数据集所存在的问题，可以用于自动化地发现和放置新概念到知识库中。 |
| [^42] | [Lingua Manga: A Generic Large Language Model Centric System for Data Curation.](http://arxiv.org/abs/2306.11702) | Lingua Manga是一个以大型语言模型为中心的通用数据管理系统，通过自动优化实现高性能和标签效率，同时促进灵活和快速开发。它能够有效地协助熟练的程序员和低代码甚至无代码用户解决数据管理挑战。 |
| [^43] | [RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model.](http://arxiv.org/abs/2306.11300) | 本文提出了一个新的框架RS5M，该框架包括领域基础模型（DFM），用于实现通用基础模型（GFM）和领域特定下游任务之间的转换。另外，还介绍了一个遥感领域的大规模图像-文本配对数据集RS5M，该数据集是通过过滤公开可用的图像-文本配对数据集并使用预训练的视觉-语言基础模型为标签数据集生成标题。 |
| [^44] | [Constructing Holistic Measures for Social Biases in Masked Language Models.](http://arxiv.org/abs/2305.07795) | 本文提出了KLDivS和JSDivS这两个评估指标，将掩码语言模型输出的刻板印象和反刻板印象样本的对数似然函数视为高斯分布，可以更稳定、可解释地评估MLMs中的社会偏见。 |
| [^45] | [A Case-Based Reasoning Framework for Adaptive Prompting in Cross-Domain Text-to-SQL.](http://arxiv.org/abs/2304.13301) | 本文提出了一个基于案例推理框架的跨域文本到SQL自适应提示的解决方案，可以精确控制与案例相关和不相关的知识，解决了大型语言模型提示设计不良限制性能的问题。 |
| [^46] | [LEVER: Learning to Verify Language-to-Code Generation with Execution.](http://arxiv.org/abs/2302.08468) | 提出了一种使用执行结果来验证生成的程序的简单方法LEVER，通过训练验证器根据自然语言输入、程序本身和执行结果来确定程序的正确性，从而改进了语言到代码生成的过程。 |
| [^47] | [Big Little Transformer Decoder.](http://arxiv.org/abs/2302.07863) | 提出了一种名为BiLD的框架，它由大小不同的两个模型协作生成文本。其中小型模型自回归地生成文本，而大型模型则在必要时以非自回归的方式对小型模型的预测进行微调，从而显著减少了推理延迟。 |
| [^48] | [Domain-Agnostic Molecular Generation with Self-feedback.](http://arxiv.org/abs/2301.11259) | MolGen是一个专注于分子生成的预训练语言模型，使用了领域无关的分子前缀调整和自我反馈的范式，实现了化学有效性、多样性、新颖性和复杂性的突破，在分子生成领域表现出了出色的性能。 |
| [^49] | [ComCLIP: Training-Free Compositional Image and Text Matching.](http://arxiv.org/abs/2211.13854) | 本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。 |
| [^50] | [A Zipf's Law-based Text Generation Approach for Addressing Imbalance in Entity Extraction.](http://arxiv.org/abs/2205.12636) | 这项研究提出了一种基于Zipf's Law的方法，通过将文档中的词汇分类为常见词和稀缺词，并使用文本生成模型对句子进行处理，进而解决实体抽取中的数据不平衡问题。通过人设计的规则对生成的句子中的稀缺实体进行标记，作为原始数据集的补充，从而有效缓解了不平衡问题。 |
| [^51] | [A New Multifractal-based Deep Learning Model for Text Mining.](http://arxiv.org/abs/2111.13861) | 该论文介绍了一个基于多重分形的深度学习模型，用于解读文本中隐藏的多重分形属性，并结合提出的激活函数，在神经网络结构中实现非线性信息传输。 |

# 详细

[^1]: Point-Bind和Point-LLM：用于3D理解、生成和指导跟随的多模态点云对齐

    Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following. (arXiv:2309.00615v1 [cs.CV])

    [http://arxiv.org/abs/2309.00615](http://arxiv.org/abs/2309.00615)

    Point-Bind和Point-LLM是用于3D理解、生成和指导跟随的多模态点云对齐模型，能实现任意到3D生成、3D嵌入算术和3D开放世界的理解，并且Point-LLM能实现3D和多模态问答功能。

    

    我们引入了Point-Bind，一个将点云与2D图像、语言、音频和视频对齐的3D多模态模型。在ImageBind的指导下，我们构建了一个将3D和多模态嵌入空间进行结合的模型，实现了许多有前景的应用，例如任意到3D生成、3D嵌入算术和3D开放世界的理解。在此基础上，我们进一步提出了Point-LLM，第一个遵循3D多模态指令的大型语言模型（LLM）。通过参数高效调优技术，Point-LLM将Point-Bind的语义注入到预训练的LLMs中，例如LLaMA，不需要3D指令数据但展现出卓越的3D和多模态问答能力。我们希望我们的工作能为将3D点云扩展到多模态应用的研究社区提供启示。代码可在https://github.com/ZiyuGuo99/Point-Bind_Point-LLM找到。

    We introduce Point-Bind, a 3D multi-modality model aligning point clouds with 2D image, language, audio, and video. Guided by ImageBind, we construct a joint embedding space between 3D and multi-modalities, enabling many promising applications, e.g., any-to-3D generation, 3D embedding arithmetic, and 3D open-world understanding. On top of this, we further present Point-LLM, the first 3D large language model (LLM) following 3D multi-modal instructions. By parameter-efficient fine-tuning techniques, Point-LLM injects the semantics of Point-Bind into pre-trained LLMs, e.g., LLaMA, which requires no 3D instruction data, but exhibits superior 3D and multi-modal question-answering capacity. We hope our work may cast a light on the community for extending 3D point clouds to multi-modality applications. Code is available at https://github.com/ZiyuGuo99/Point-Bind_Point-LLM.
    
[^2]: 面向对齐语言模型的对抗攻击的基线防御

    Baseline Defenses for Adversarial Attacks Against Aligned Language Models. (arXiv:2309.00614v1 [cs.LG])

    [http://arxiv.org/abs/2309.00614](http://arxiv.org/abs/2309.00614)

    这篇论文研究了对齐语言模型面临的对抗攻击问题，通过评估基线防御策略的效果，探讨了各种策略的可行性和有效性，并对鲁棒性和性能进行了讨论。

    

    随着大型语言模型的普及，其安全漏洞变得至关重要。最近的研究表明，文本优化器可以生成绕过审查和对齐的越狱提示。借鉴对抗机器学习的丰富研究成果，我们从三个问题入手：在这个领域中什么样的威胁模型是实用的？基线防御技术在这个新领域中表现如何？LLM安全性与计算机视觉有何不同？我们对主导对抗LLM攻击的几种基线防御策略进行评估，讨论了每种策略在各种设置下的可行性和有效性。特别是，我们关注三种类型的防御：检测（基于困惑度）、输入预处理（改写和重新标记化）和对抗训练。我们讨论了白盒和灰盒设置，并讨论了每种考虑的防御策略在鲁棒性和性能之间的权衡。

    As Large Language Models quickly become ubiquitous, their security vulnerabilities are critical to understand. Recent work shows that text optimizers can produce jailbreaking prompts that bypass moderation and alignment. Drawing from the rich body of work on adversarial machine learning, we approach these attacks with three questions: What threat models are practically useful in this domain? How do baseline defense techniques perform in this new domain? How does LLM security differ from computer vision?  We evaluate several baseline defense strategies against leading adversarial attacks on LLMs, discussing the various settings in which each is feasible and effective. Particularly, we look at three types of defenses: detection (perplexity based), input preprocessing (paraphrase and retokenization), and adversarial training. We discuss white-box and gray-box settings and discuss the robustness-performance trade-off for each of the defenses considered. Surprisingly, we find much more succ
    
[^3]: CPSP: 从音素监督中学习语音概念

    CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])

    [http://arxiv.org/abs/2309.00424](http://arxiv.org/abs/2309.00424)

    论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。

    

    对于诸如最小监督的文本转语音（TTS）、语音转换（VC）和自动语音识别（ASR）等细粒度生成和识别任务，从语音中提取的中间表示应包含介于文本编码和声学编码之间的信息。语言内容突出，而发言人身份和声学细节等语音信息应该被去除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余性过高和维度爆炸的问题。此外，音频领域中现有的对比学习方法主要关注提取用于下游音频分类任务的全局描述信息，不适合TTS、VC和ASR任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练（CPSP）的方法，该方法使用三个编码器、一个解码器和对比学习来将音素和语音信息相结合。

    For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representation extracted from speech should contain information that is between text coding and acoustic coding. The linguistic content is salient, while the paralinguistic information such as speaker identity and acoustic details should be removed. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Additionally, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named Contrastive Phoneme-Speech Pretraining (CPSP), which uses three encoders, one decoder, and contrastive learning to bring phoneme and speech
    
[^4]: 多变量TPTL与单边区间的可满足性检查是PSPACE-Complete的

    Satisfiability Checking of Multi-Variable TPTL with Unilateral Intervals Is PSPACE-Complete. (arXiv:2309.00386v1 [cs.LO])

    [http://arxiv.org/abs/2309.00386](http://arxiv.org/abs/2309.00386)

    多变量TPTL与单边区间的可满足性检查是PSPACE-Complete的，与Metric Interval Temporal Logic相比，具有更强的表达能力和更容易的计算检查方法。这是第一个对定时词没有限制的多变量TPTL的可判定可满足性检查的片段。

    

    我们研究了时间命题时态逻辑（TPTL）的{0, ∞}片段的可决定性。我们证明了TPTL的可满足性检查在TPTL$^{0, ∞}$中是PSPACE-Complete的。此外，即使是它的1变量片段（1-TPTL$^{0, ∞}$），与其可满足性检查是EXPSPACE-Complete的Metric Interval Temporal Logic（MITL）相比，更加表达力强。因此，我们在计算上更容易检查可满足性的逻辑表达式是更加表达力强的。据我们所知，TPTL$^{0, ∞}$是第一个不对定时词（例如有界变异度，有界时间等）施加任何限制/约束即可判定可满足性的TPTL的多变量片段。通过将其规约到一种称为单边非时态交替自动机的空类别的空检查问题，我们得到PSPACE的会员。该规约涉及多个时钟的交替时控自动机。

    We investigate the decidability of the ${0,\infty}$ fragment of Timed Propositional Temporal Logic (TPTL). We show that the satisfiability checking of TPTL$^{0,\infty}$ is PSPACE-complete. Moreover, even its 1-variable fragment (1-TPTL$^{0,\infty}$) is strictly more expressive than Metric Interval Temporal Logic (MITL) for which satisfiability checking is EXPSPACE complete. Hence, we have a strictly more expressive logic with computationally easier satisfiability checking. To the best of our knowledge, TPTL$^{0,\infty}$ is the first multi-variable fragment of TPTL for which satisfiability checking is decidable without imposing any bounds/restrictions on the timed words (e.g. bounded variability, bounded time, etc.). The membership in PSPACE is obtained by a reduction to the emptiness checking problem for a new "non-punctual" subclass of Alternating Timed Automata with multiple clocks called Unilateral Very Weak Alternating Timed Automata (VWATA$^{0,\infty}$) which we prove to be in PSP
    
[^5]: BatchPrompt: 用更少的资源实现更多任务的策略

    BatchPrompt: Accomplish more with less. (arXiv:2309.00384v1 [cs.CL])

    [http://arxiv.org/abs/2309.00384](http://arxiv.org/abs/2309.00384)

    BatchPrompt是一种提示策略，它通过将多个数据点批量打包到一个提示中来提高LLM的令牌资源利用效率，从而缓解由于令牌计数差异导致的成本效率问题，提高推理速度和计算预算的利用率。

    

    许多LLM（Language Model）被训练来使用基于指令的提示实现零样本或少样本推理。为这些LLM制作提示通常需要用户提供详细的任务描述、上下文和完成示例以及推理上下文的单个示例。本文将这种常规提示基准称为SinglePrompt。然而，在每个推理数据点不一定很长的NLP任务中，提示中的指令和少样本示例的令牌计数可能比数据点的令牌计数大得多，与Fine-tuned BERT等基于编码器的模型相比，导致令牌资源利用率降低。这个成本效率问题影响了推理速度和计算预算，抵消了LLM所能提供的许多好处。本文旨在通过将多个数据点批量打包到一个提示中来缓解上述问题，我们将这种提示策略称为BatchPrompt。这种策略增加了数据点的密度，

    Many LLMs are trained to perform zero-shot or few-shot inference using instruction-based prompts. Crafting prompts for these LLMs typically requires the user to provide a detailed task description, examples of context and completion, and single example of context for inference. This regular prompt baseline is referred to as SinglePrompt in this paper. However, for NLP tasks where each data point for inference is not necessarily lengthy, the token count for instructions and few-shot examples in the prompt may be considerably larger than that of the data point, resulting in lower token-resource utilization compared with encoder-based models like fine-tuned BERT. This cost-efficiency issue, affecting inference speed and compute budget, counteracts the many benefits LLMs have to offer. This paper aims to alleviate the preceding problem by batching multiple data points into a single prompt, a prompting strategy we refer to as BatchPrompt. This strategy increases the density of data points, 
    
[^6]: 广告的长期记忆性研究

    Long-Term Memorability On Advertisements. (arXiv:2309.00378v1 [cs.CL])

    [http://arxiv.org/abs/2309.00378](http://arxiv.org/abs/2309.00378)

    本研究是首个大规模的记忆性研究，发现广告的长期记忆性对于市场营销非常重要，但在机器学习文献中一直缺乏相关研究。通过分析大量参与者和广告，我们得出了关于什么使广告记忆深刻的有趣见解。

    

    市场营销人员花费数十亿美元在广告上，但是投入到广告上的金钱能起多大作用呢？当顾客在购买时无法辨认出他们看过的品牌的话，花在广告上的钱基本上就被浪费了。尽管在营销中很重要，但迄今为止，在机器学习的文献中还没有关于广告记忆力的研究。大多数研究都是对特定内容类型（如物体和动作视频）进行短期回忆（<5分钟）的研究。另一方面，广告行业只关心长期记忆（几个小时或更长时间），而且广告几乎总是高度多模式化，通过不同的形式（文本、图像和视频）来讲故事。基于这一动机，我们进行了首个大规模记忆性研究，共有1203名参与者和2205个广告涵盖了276个品牌。在不同参与者子群体和广告类型上进行统计测试，我们发现了许多有关什么使广告难忘的有趣见解-无论是内容还是

    Marketers spend billions of dollars on advertisements but to what end? At the purchase time, if customers cannot recognize a brand for which they saw an ad, the money spent on the ad is essentially wasted. Despite its importance in marketing, until now, there has been no study on the memorability of ads in the ML literature. Most studies have been conducted on short-term recall (<5 mins) on specific content types like object and action videos. On the other hand, the advertising industry only cares about long-term memorability (a few hours or longer), and advertisements are almost always highly multimodal, depicting a story through its different modalities (text, images, and videos). With this motivation, we conduct the first large scale memorability study consisting of 1203 participants and 2205 ads covering 276 brands. Running statistical tests over different participant subpopulations and ad-types, we find many interesting insights into what makes an ad memorable - both content and h
    
[^7]: 论论文时候会影响计算句子理解

    When Do Discourse Markers Affect Computational Sentence Understanding?. (arXiv:2309.00368v1 [cs.CL])

    [http://arxiv.org/abs/2309.00368](http://arxiv.org/abs/2309.00368)

    本文研究了自然语言处理（NLP）系统对话语连接词的理解能力，发现不同的连接词种类的处理复杂性不同，对上下文和语言理解任务有影响。

    

    在过去几年中，自然语言处理（NLP）的能力和使用情况显著增长。尽管已经有很多研究致力于理解人类如何处理话语连接词，但对计算系统中的这一现象的研究还不够。因此，很重要的是将NLP模型置于显微镜下，检查它们是否能够充分理解、处理和推理自然语言的复杂性。在本章中，我们逐步介绍了自动句子处理系统的主要机制，然后着重评估了话语连接词的处理。我们评估了九个流行的系统在理解英语话语连接词方面的能力，并分析了上下文和语言理解任务如何影响它们的连接词理解。结果表明，NLP系统不能同样好地处理所有的话语连接词，并且不同连接词种类的计算处理复杂性并不总是相同。

    The capabilities and use cases of automatic natural language processing (NLP) have grown significantly over the last few years. While much work has been devoted to understanding how humans deal with discourse connectives, this phenomenon is understudied in computational systems. Therefore, it is important to put NLP models under the microscope and examine whether they can adequately comprehend, process, and reason within the complexity of natural language. In this chapter, we introduce the main mechanisms behind automatic sentence processing systems step by step and then focus on evaluating discourse connective processing. We assess nine popular systems in their ability to understand English discourse connectives and analyze how context and language understanding tasks affect their connective comprehension. The results show that NLP systems do not process all discourse connectives equally well and that the computational processing complexity of different connective kinds is not always 
    
[^8]: 大型内容和行为模型用于理解、模拟和优化内容和行为

    Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior. (arXiv:2309.00359v1 [cs.CL])

    [http://arxiv.org/abs/2309.00359](http://arxiv.org/abs/2309.00359)

    该论文提出了使用大型内容和行为模型来理解、模拟和优化内容和行为。大型语言模型虽然在任务泛化能力方面取得了进展，但还无法解决预测和优化通信以实现期望接收者行为的问题。其中的一个原因可能是训练语料库中缺少"行为标记"。

    

    香农在引入信息理论的经典论文中将通信分为三个层次：技术层、语义层和效果层。技术层关注的是准确重构传输的符号，而语义层和效果层则涉及推断出的意义及其对接收者的影响。得益于电信技术，第一层问题已经取得了较大的进步，如互联网。大型语言模型（LLM）在第二个目标方面取得了一些进展，但第三层仍然基本上未被触及。第三个问题涉及预测和优化通信以实现期望的接收者行为。LLM在各种任务中显示出了广泛的泛化能力，但无法解决这个问题。表现不佳的原因之一可能是LLM的训练语料库中缺少"行为标记"。行为标记定义了在一次通信中的接收者行为，如分享、点赞、点击、购买、转推等。

    Shannon, in his seminal paper introducing information theory, divided the communication into three levels: technical, semantic, and effectivenss. While the technical level is concerned with accurate reconstruction of transmitted symbols, the semantic and effectiveness levels deal with the inferred meaning and its effect on the receiver. Thanks to telecommunications, the first level problem has produced great advances like the internet. Large Language Models (LLMs) make some progress towards the second goal, but the third level still remains largely untouched. The third problem deals with predicting and optimizing communication for desired receiver behavior. LLMs, while showing wide generalization capabilities across a wide range of tasks, are unable to solve for this. One reason for the underperformance could be a lack of "behavior tokens" in LLMs' training corpora. Behavior tokens define receiver behavior over a communication, such as shares, likes, clicks, purchases, retweets, etc. W
    
[^9]: 用于马克白彦病研究的不同报告结果的比较话题建模

    Comparative Topic Modeling for Determinants of Divergent Report Results Applied to Macular Degeneration Studies. (arXiv:2309.00312v1 [cs.CL])

    [http://arxiv.org/abs/2309.00312](http://arxiv.org/abs/2309.00312)

    本研究提出了一种比较话题建模方法，用于分析马克白彦病研究中存在矛盾结果的报告。通过对比不同话题与显著结果的相关性，找到了与黄斑变性研究中显著结果报告相关的八种化合物。

    

    话题建模和文本挖掘是自然语言处理的子集，适用于进行元分析和系统审查。对于证据综述，上述NLP方法通常用于特定主题的文献搜索或从报告中提取值以自动化SR和MA的关键阶段。相反，本文提出了一种比较话题建模方法，用于分析同一广义研究问题上存在矛盾结果的报告。具体而言，目标是通过根据其比例发生和在显著结果报告中的一致性分布对其进行排名，找到与感兴趣的结果显著相关的话题。该方法在涉及补充营养化合物是否显著有益于黄斑变性(MD)的广泛范围的研究中进行了测试。确定了八种化合物与显著结果报告的特定相关性。

    Topic modeling and text mining are subsets of Natural Language Processing with relevance for conducting meta-analysis (MA) and systematic review (SR). For evidence synthesis, the above NLP methods are conventionally used for topic-specific literature searches or extracting values from reports to automate essential phases of SR and MA. Instead, this work proposes a comparative topic modeling approach to analyze reports of contradictory results on the same general research question. Specifically, the objective is to find topics exhibiting distinct associations with significant results for an outcome of interest by ranking them according to their proportional occurrence and consistency of distribution across reports of significant results. The proposed method was tested on broad-scope studies addressing whether supplemental nutritional compounds significantly benefit macular degeneration (MD). Eight compounds were identified as having a particular association with reports of significant r
    
[^10]: 用无旋律监督预训练增强单声道唱歌声音合成的音域

    Enhancing the vocal range of single-speaker singing voice synthesis with melody-unsupervised pre-training. (arXiv:2309.00284v1 [cs.SD])

    [http://arxiv.org/abs/2309.00284](http://arxiv.org/abs/2309.00284)

    本研究提出了一种无旋律监督预训练方法，通过在多歌手数据集上进行预训练，增强了单声道的音域，在不降低音色相似性的情况下。这种方法能够应用于大规模的多歌手数据集，提供音高和音素定时信息，从而改善单声道唱歌声音合成的效果。

    

    单声道唱歌声音合成（SVS）通常在歌手音域之外或基于有限的训练样本的音高上效果不佳。基于我们之前的工作，本研究提出了一种基于多歌手数据集进行的无旋律监督多声道预训练方法，以增强单声道的音域，同时不降低音色的相似性。这种预训练方法可以应用于大规模的多歌手数据集，该数据集仅包含音频和歌词配对，没有音素定时信息和音高标注。具体而言，在预训练步骤中，我们设计了一个音素预测器来生成帧级音素概率向量作为音素定时信息，以及一个说话人编码器来建模不同唱歌者的音色变化，并直接从音频中估计帧级f0值来提供音高信息。这些预训练的模型参数在微调步骤中应用。

    The single-speaker singing voice synthesis (SVS) usually underperforms at pitch values that are out of the singer's vocal range or associated with limited training samples. Based on our previous work, this work proposes a melody-unsupervised multi-speaker pre-training method conducted on a multi-singer dataset to enhance the vocal range of the single-speaker, while not degrading the timbre similarity. This pre-training method can be deployed to a large-scale multi-singer dataset, which only contains audio-and-lyrics pairs without phonemic timing information and pitch annotation. Specifically, in the pre-training step, we design a phoneme predictor to produce the frame-level phoneme probability vectors as the phonemic timing information and a speaker encoder to model the timbre variations of different singers, and directly estimate the frame-level f0 values from the audio to provide the pitch information. These pre-trained model parameters are delivered into the fine-tuning step as prio
    
[^11]: RLAIF: 使用AI反馈来扩展强化学习从人类反馈中学习

    RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback. (arXiv:2309.00267v1 [cs.CL])

    [http://arxiv.org/abs/2309.00267](http://arxiv.org/abs/2309.00267)

    RLAIF是一种新的强化学习方法，利用AI反馈代替人类标注偏好，相比强化学习从人类反馈中学习（RLHF），在摘要任务上取得了类似的改进效果，并且在人类评估中得到了相同的认可。这提供了一种有潜力解决RLHF的可扩展性限制的解决方案。

    

    从人类反馈中进行强化学习（RLHF）对于将大型语言模型（LLMs）与人类偏好相一致是有效的，但是收集高质量的人类偏好标签是一个关键瓶颈。我们比较了RLHF和利用现成的LLM进行标记的RL from AI Feedback (RLAIF)技术，并发现它们都能获得类似的改善效果。在摘要任务上，人类评估者在约70%的案例中都更喜欢RLAIF和RLHF产生的文本，而不是基准的监督微调模型。此外，当被要求评估RLAIF和RLHF的摘要时，人类以相同的比率更喜欢两者。这些结果表明，RLAIF可以达到人类水平的性能，为克服RLHF的可扩展性限制提供了潜在的解决方案。

    Reinforcement learning from human feedback (RLHF) is effective at aligning large language models (LLMs) to human preferences, but gathering high quality human preference labels is a key bottleneck. We conduct a head-to-head comparison of RLHF vs. RL from AI Feedback (RLAIF) - a technique where preferences are labeled by an off-the-shelf LLM in lieu of humans, and we find that they result in similar improvements. On the task of summarization, human evaluators prefer generations from both RLAIF and RLHF over a baseline supervised fine-tuned model in ~70% of cases. Furthermore, when asked to rate RLAIF vs. RLHF summaries, humans prefer both at equal rates. These results suggest that RLAIF can yield human-level performance, offering a potential solution to the scalability limitations of RLHF.
    
[^12]: 为什么通用对抗性攻击对大型语言模型有效：几何可能是答案

    Why do universal adversarial attacks work on large language models?: Geometry might be the answer. (arXiv:2309.00254v1 [cs.LG])

    [http://arxiv.org/abs/2309.00254](http://arxiv.org/abs/2309.00254)

    本研究从几何视角解释了对大型语言模型的通用对抗性攻击，发现通用对抗性触发器可能是嵌入向量，仅仅近似了其对抗训练区域中的语义信息。

    

    基于Transformer的大型语言模型具有新发能力，在社会中越来越普遍。然而，在对抗攻击的背景下，理解和解释它们的内部工作仍然基本未解决。已经证明基于梯度的通用对抗性攻击对大型语言模型非常有效，由于它们对输入不敏感的特性，可能具有潜在的危险。本研究提出了一个新颖的几何视角，解释了对大型语言模型的通用对抗性攻击。通过对攻击117M参数的GPT-2模型，我们发现证据表明通用对抗性触发器可能是嵌入向量，仅仅近似了其对抗训练区域中的语义信息。这个假设得到了通过白盒模型分析的支持，包括对隐藏表示的降维和相似度测量。我们相信这种关于驱动通用对抗性攻击的潜在机制的新几何视角。

    Transformer based large language models with emergent capabilities are becoming increasingly ubiquitous in society. However, the task of understanding and interpreting their internal workings, in the context of adversarial attacks, remains largely unsolved. Gradient-based universal adversarial attacks have been shown to be highly effective on large language models and potentially dangerous due to their input-agnostic nature. This work presents a novel geometric perspective explaining universal adversarial attacks on large language models. By attacking the 117M parameter GPT-2 model, we find evidence indicating that universal adversarial triggers could be embedding vectors which merely approximate the semantic information in their adversarial training region. This hypothesis is supported by white-box model analysis comprising dimensionality reduction and similarity measurement of hidden representations. We believe this new geometric perspective on the underlying mechanism driving univer
    
[^13]: 使用机器学习和深度学习技术检测阿拉伯推文中的自杀风险

    Detecting Suicidality in Arabic Tweets Using Machine Learning and Deep Learning Techniques. (arXiv:2309.00246v1 [cs.CL])

    [http://arxiv.org/abs/2309.00246](http://arxiv.org/abs/2309.00246)

    使用机器学习和深度学习技术，研究了检测阿拉伯推文中自杀思维的方法。开发了一个新的阿拉伯语自杀推文数据集，训练了多种机器学习模型，并研究了预训练深度学习模型的能力。

    

    社交媒体平台通过使全球人民能够即时、公开和频繁地连接起来，改变了传统的沟通技术。人们使用社交媒体分享个人故事并表达自己的观点。负面情绪，比如死亡、自残和困难思维，在社交媒体上普遍存在，尤其是在年轻一代中。因此，利用社交媒体检测自杀思维将有助于提供适当的干预，最终阻止他人自残和自杀，并阻止自杀思维在社交媒体上的传播。为了研究自动检测阿拉伯推文中的自杀思维的能力，我们开发了一个新颖的阿拉伯语自杀推文数据集，使用词频和词嵌入特征训练了几种机器学习模型，包括朴素贝叶斯、支持向量机、KNN、随机森林和XGBoost，并研究了预训练深度学习模型的能力。

    Social media platforms have revolutionized traditional communication techniques by enabling people globally to connect instantaneously, openly, and frequently. People use social media to share personal stories and express their opinion. Negative emotions such as thoughts of death, self-harm, and hardship are commonly expressed on social media, particularly among younger generations. As a result, using social media to detect suicidal thoughts will help provide proper intervention that will ultimately deter others from self-harm and committing suicide and stop the spread of suicidal ideation on social media. To investigate the ability to detect suicidal thoughts in Arabic tweets automatically, we developed a novel Arabic suicidal tweets dataset, examined several machine learning models, including Na\"ive Bayes, Support Vector Machine, K-Nearest Neighbor, Random Forest, and XGBoost, trained on word frequency and word embedding features, and investigated the ability of pre-trained deep lea
    
[^14]: NeuroSurgeon: 一种用于子网络分析的工具包

    NeuroSurgeon: A Toolkit for Subnetwork Analysis. (arXiv:2309.00244v1 [cs.LG])

    [http://arxiv.org/abs/2309.00244](http://arxiv.org/abs/2309.00244)

    NeuroSurgeon是一个用于在Huggingface Transformers库中发现和操作模型子网络的Python工具包，可以推进对神经网络学习算法的理解。

    

    尽管在可解释性领域取得了一些进展，但我们对神经网络学习表示的算法仍知之甚少。最近的研究尝试通过将已训练模型分解为功能电路来理解它们(参考Csord\'as等人的研究，2020；Lepori等人，2023)。为了推进这项研究，我们开发了NeuroSurgeon，这是一个Python库，可以用于发现和操作Huggingface Transformers库中的模型中的子网络(Wolf等人，2019)。NeuroSurgeon可以在https://github.com/mlepori1/NeuroSurgeon 免费获取。

    Despite recent advances in the field of explainability, much remains unknown about the algorithms that neural networks learn to represent. Recent work has attempted to understand trained models by decomposing them into functional circuits (Csord\'as et al., 2020; Lepori et al., 2023). To advance this research, we developed NeuroSurgeon, a python library that can be used to discover and manipulate subnetworks within models in the Huggingface Transformers library (Wolf et al., 2019). NeuroSurgeon is freely available at https://github.com/mlepori1/NeuroSurgeon.
    
[^15]: FactLLaMA: 基于外部知识优化指令追踪语言模型以实现自动事实核查

    FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking. (arXiv:2309.00240v1 [cs.CL])

    [http://arxiv.org/abs/2309.00240](http://arxiv.org/abs/2309.00240)

    本研究提出了一种结合外部知识检索来增强指令追踪语言模型的自动事实核查方法，通过利用搜索引擎检索相关证据，并指导调整语言模型，从而提高了事实核查的准确性。

    

    自动事实核查在打击虚假信息传播中发挥了重要作用。大型语言模型（LLM）和指令追踪变种，如InstructGPT和Alpaca，在各种自然语言处理任务中展现出了显著的性能。然而，它们的知识可能并不总是最新或充分的，可能导致事实核查的不准确性。为了解决这个问题，我们提出了将指令追踪语言模型与外部证据检索相结合，以增强事实核查性能。我们的方法涉及利用搜索引擎检索与给定输入声明相关的证据。这些外部证据作为有价值的补充信息，可以增强预训练语言模型的知识。然后，我们使用这些证据对一个名为LLaMA的开源语言模型进行指令调整，从而使其更准确地预测输入声明的真实性。为了评估我们的方法，我们进行了一系列实验。

    Automatic fact-checking plays a crucial role in combating the spread of misinformation. Large Language Models (LLMs) and Instruction-Following variants, such as InstructGPT and Alpaca, have shown remarkable performance in various natural language processing tasks. However, their knowledge may not always be up-to-date or sufficient, potentially leading to inaccuracies in fact-checking. To address this limitation, we propose combining the power of instruction-following language models with external evidence retrieval to enhance fact-checking performance. Our approach involves leveraging search engines to retrieve relevant evidence for a given input claim. This external evidence serves as valuable supplementary information to augment the knowledge of the pretrained language model. Then, we instruct-tune an open-sourced language model, called LLaMA, using this evidence, enabling it to predict the veracity of the input claim more accurately. To evaluate our method, we conducted experiments 
    
[^16]: ALJP: 使用机器学习模型预测阿拉伯个人身份案件的法律判决

    ALJP: An Arabic Legal Judgment Prediction in Personal Status Cases Using Machine Learning Models. (arXiv:2309.00238v1 [cs.AI])

    [http://arxiv.org/abs/2309.00238](http://arxiv.org/abs/2309.00238)

    这项研究开发了一个使用深度学习和自然语言处理技术预测阿拉伯个人身份案件法律判决的系统，有助于改进法官和律师的工作效率，减少判决差异，并帮助诉讼当事人事先分析案件的可能结果。

    

    法律判决预测（LJP）旨在基于案情描述预测判决结果。一些研究人员已经开发出了一些技术，通过预测法律职业的结果来帮助潜在的客户。然而，没有一种提出的技术是用阿拉伯语实现的，只有少数尝试采用英语、汉语和印地语实现。在本文中，我们开发了一个系统，利用深度学习（DL）和自然语言处理（NLP）技术，从阿拉伯语案情脚本中预测判决结果，特别是在抚养权和婚姻无效的案件中。该系统将帮助法官和律师提高工作和时间效率，同时减少判决差异。此外，在审判之前，它将帮助诉讼当事人、律师和法学生分析任何给定案件的可能结果。我们使用了不同的机器和深度学习模型，如支持向量机（SVM）、逻辑回归（LR）、长短期记忆（LSTM）和双向。

    Legal Judgment Prediction (LJP) aims to predict judgment outcomes based on case description. Several researchers have developed techniques to assist potential clients by predicting the outcome in the legal profession. However, none of the proposed techniques were implemented in Arabic, and only a few attempts were implemented in English, Chinese, and Hindi. In this paper, we develop a system that utilizes deep learning (DL) and natural language processing (NLP) techniques to predict the judgment outcome from Arabic case scripts, especially in cases of custody and annulment of marriage. This system will assist judges and attorneys in improving their work and time efficiency while reducing sentencing disparity. In addition, it will help litigants, lawyers, and law students analyze the probable outcomes of any given case before trial. We use a different machine and deep learning models such as Support Vector Machine (SVM), Logistic regression (LR), Long Short Term Memory (LSTM), and Bidir
    
[^17]: 基于合成临床记录的公开可共享的临床大语言模型

    Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes. (arXiv:2309.00237v1 [cs.CL])

    [http://arxiv.org/abs/2309.00237](http://arxiv.org/abs/2309.00237)

    使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。

    

    基于合成的临床案例报告，我们首先创建了大规模的合成临床记录，以解决临床记录的有限可及性和可用性的问题。然后，我们使用这些合成记录来训练我们的专门的临床大语言模型Asclepius。虽然Asclepius是在合成数据上训练的，但我们通过使用真实临床记录对其进行评估，以评估其在现实应用中的潜在性能。我们将Asclepius与包括GPT-3.5-turbo和其他开源替代方案在内的几种其他大语言模型进行了基准测试。为了进一步验证我们使用合成记录的方法，我们还将Asclepius与其在真实临床记录上训练的变体进行了比较。我们的发现有力地证明，合成临床记录在构建临床大语言模型时可以作为可行的替代品。

    The development of large language models tailored for handling patients' clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations. To address these challenges, we first create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature. We then use these synthetic notes to train our specialized clinical large language model, Asclepius. While Asclepius is trained on synthetic data, we assess its potential performance in real-world applications by evaluating it using real clinical notes. We benchmark Asclepius against several other large language models, including GPT-3.5-turbo and other open-source alternatives. To further validate our approach using synthetic notes, we also compare Asclepius with its variants trained on real clinical notes. Our findings convincingly demonstrate that synthetic clinical notes can serve as viable substitutes for real ones when constructi
    
[^18]: 图像劫持：对抗性图像能在运行时控制生成模型

    Image Hijacking: Adversarial Images can Control Generative Models at Runtime. (arXiv:2309.00236v1 [cs.LG])

    [http://arxiv.org/abs/2309.00236](http://arxiv.org/abs/2309.00236)

    本研究发现对抗性图像能够在运行时控制生成模型，并提出了通用的方法来创建图像劫持。通过研究三种攻击类型，我们发现这些攻击对最新的视觉语言模型具有高达90％以上的成功率。该研究引发了对基础模型安全性的严重担忧。

    

    基础模型是否能够免受恶意行为者的攻击？本文研究了视觉语言模型（VLM）的图像输入。我们发现了图像劫持，即能够在运行时控制生成模型的对抗性图像。我们引入了一种名为“行为匹配”的通用方法来创建图像劫持，并用它来探索三种类型的攻击：具体字符串攻击可以生成任意被攻击者选择的输出；泄露上下文攻击可以将上下文窗口中的信息泄露到输出中；越狱攻击可以绕过模型的安全训练。我们对基于CLIP和LLaMA-2的最新VLM模型LLaVA-2进行了这些攻击的研究，并发现我们所有的攻击类型成功率均在90％以上。而且，我们的攻击是自动化的，只需要对图像进行小的扰动。这些发现对基础模型的安全性提出了严重的担忧。如果图像劫持与CIFAR-10中的对抗性样本一样难以防御，那么可能需要很多年才能找到解决方案。

    Are foundation models secure from malicious actors? In this work, we focus on the image input to a vision-language model (VLM). We discover image hijacks, adversarial images that control generative models at runtime. We introduce Behavior Matching, a general method for creating image hijacks, and we use it to explore three types of attacks. Specific string attacks generate arbitrary output of the adversary's choosing. Leak context attacks leak information from the context window into the output. Jailbreak attacks circumvent a model's safety training. We study these attacks against LLaVA-2, a state-of-the-art VLM based on CLIP and LLaMA-2, and find that all our attack types have above a 90\% success rate. Moreover, our attacks are automated and require only small image perturbations. These findings raise serious concerns about the security of foundation models. If image hijacks are as difficult to defend against as adversarial examples in CIFAR-10, then it might be many years before a s
    
[^19]: JoTR: 一种基于联合Transformer和强化学习的对话策略学习框架

    JoTR: A Joint Transformer and Reinforcement Learning Framework for Dialog Policy Learning. (arXiv:2309.00230v1 [cs.CL])

    [http://arxiv.org/abs/2309.00230](http://arxiv.org/abs/2309.00230)

    JoTR是一种新颖的对话策略学习框架，利用基于Transformer的模型生成灵活的对话动作，提高了响应多样性和系统处理极端情况的能力。

    

    对话策略学习是对话建模的关键组成部分，其主要作用是确定合适的抽象回应，通常称为"对话动作"。传统的对话策略学习方法将其视为一个顺序决策问题，使用从语料库中提取的预定义动作候选项。然而，这些不完整的候选项可能会显著限制响应的多样性，并在处理极端操作参数下出现挑战性情况时造成困难。为了解决这些限制，我们引入了一种新颖的框架，JoTR。该框架独特之处在于利用基于文本到文本的Transformer模型生成灵活的对话动作。与传统方法不同，JoTR制定了一个词级策略，允许更动态和适应性的对话动作生成，无需任何动作模板。这种设置增强了响应的多样性，并提高了系统处理极端情况的能力。

    Dialogue policy learning (DPL) is a crucial component of dialogue modelling. Its primary role is to determine the appropriate abstract response, commonly referred to as the "dialogue action". Traditional DPL methodologies have treated this as a sequential decision problem, using pre-defined action candidates extracted from a corpus. However, these incomplete candidates can significantly limit the diversity of responses and pose challenges when dealing with edge cases, which are scenarios that occur only at extreme operating parameters. To address these limitations, we introduce a novel framework, JoTR. This framework is unique as it leverages a text-to-text Transformer-based model to generate flexible dialogue actions. Unlike traditional methods, JoTR formulates a word-level policy that allows for a more dynamic and adaptable dialogue action generation, without the need for any action templates. This setting enhances the diversity of responses and improves the system's ability to handl
    
[^20]: FruitShell法语合成系统在Blizzard 2023挑战赛中的应用

    The FruitShell French synthesis system at the Blizzard 2023 Challenge. (arXiv:2309.00223v1 [eess.AS])

    [http://arxiv.org/abs/2309.00223](http://arxiv.org/abs/2309.00223)

    本文介绍了一个用于Blizzard Challenge 2023的法语文本到语音合成系统，通过对数据的筛选和增强，以及添加词边界和起始/结束符号的方式，提高了语音质量并进行了标准化转录。

    

    本文介绍了一个用于Blizzard Challenge 2023的法语文本到语音合成系统。该挑战包括两个任务：从女性演讲者生成高质量的语音和生成与特定个体相似的语音。关于比赛数据，我们进行了筛选过程，去除了缺失或错误的文本数据。我们对除音素以外的所有符号进行了整理，并消除了没有发音或持续时间为零的符号。此外，我们还在文本中添加了词边界和起始/结束符号，根据我们之前的经验，我们发现这样可以提高语音质量。对于Spoke任务，我们根据比赛规则进行了数据增强。我们使用了一个开源的G2P模型将法语文本转录为音素。由于G2P模型使用国际音标（IPA），我们对提供的比赛数据应用了相同的转录过程，以进行标准化。然而，由于编译器对某些技术限制的识别能力有限，所以我们为了保持竞争的公正，将数据按音标划分为不同的片段进行评估。

    This paper presents a French text-to-speech synthesis system for the Blizzard Challenge 2023. The challenge consists of two tasks: generating high-quality speech from female speakers and generating speech that closely resembles specific individuals. Regarding the competition data, we conducted a screening process to remove missing or erroneous text data. We organized all symbols except for phonemes and eliminated symbols that had no pronunciation or zero duration. Additionally, we added word boundary and start/end symbols to the text, which we have found to improve speech quality based on our previous experience. For the Spoke task, we performed data augmentation according to the competition rules. We used an open-source G2P model to transcribe the French texts into phonemes. As the G2P model uses the International Phonetic Alphabet (IPA), we applied the same transcription process to the provided competition data for standardization. However, due to compiler limitations in recognizing 
    
[^21]: 通过语义引地来解决视觉语言任务中对象提议评估的不对齐问题

    Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding. (arXiv:2309.00215v1 [cs.CV])

    [http://arxiv.org/abs/2309.00215](http://arxiv.org/abs/2309.00215)

    本研究通过语义引地解决了视觉语言任务中对象提议评估不对齐的问题，提出了通过阈值选择注释重要性得分来评估对象提议的方法，并证明了与现有方法相比，在与图像字幕度量和人工注释选择的注释上表现出了极大的改进性对齐。

    

    对象提议生成作为视觉语言任务（图像字幕、视觉问答等）的标准预处理步骤。目前，对于视觉语言任务生成的对象提议的性能是通过所有可用的注释进行评估的，我们发现这种评估方法存在不对齐的问题 - 更高的分数不一定对应下游视觉语言任务的改进性能。本研究探讨了语义引地的有效性以减轻这一影响，并建议仅针对一部分通过阈值选择注释重要性得分的可用注释来评估对象提议。通过从描述图像的文本中提取相关语义信息来量化对象注释对视觉语言任务的重要性。我们证明了我们的方法是一致的，并且与现有方法相比，在与图像字幕度量和人工注释选择的注释上表现出了极大的改进性对齐。

    Object proposal generation serves as a standard pre-processing step in Vision-Language (VL) tasks (image captioning, visual question answering, etc.). The performance of object proposals generated for VL tasks is currently evaluated across all available annotations, a protocol that we show is misaligned - higher scores do not necessarily correspond to improved performance on downstream VL tasks. Our work serves as a study of this phenomenon and explores the effectiveness of semantic grounding to mitigate its effects. To this end, we propose evaluating object proposals against only a subset of available annotations, selected by thresholding an annotation importance score. Importance of object annotations to VL tasks is quantified by extracting relevant semantic information from text describing the image. We show that our method is consistent and demonstrates greatly improved alignment with annotations selected by image captioning metrics and human annotation when compared against existi
    
[^22]: 用于语义监测公司披露的大型语言模型：韩国KOSPI前50家公司的案例研究

    Large Language Models for Semantic Monitoring of Corporate Disclosures: A Case Study on Korea's Top 50 KOSPI Companies. (arXiv:2309.00208v1 [cs.CL])

    [http://arxiv.org/abs/2309.00208](http://arxiv.org/abs/2309.00208)

    本研究探讨了OpenAI的GPT-3.5-turbo和GPT-4在韩国上市公司披露中的语义分析能力，并发现GPT-4在人类评估中表现出显著的准确性。

    

    在快速发展的人工智能领域中，OpenAI的GPT-3.5-turbo和GPT-4等最先进的语言模型为自动化复杂任务提供了前所未有的机会。本研究深入探讨了这些模型在韩国情境下语义分析公司披露的能力，特别是对及时披露的能力。研究聚焦于韩国KOSPI上市的市值前50家上市公司，并在17个月的时间内详细审查了它们的月度披露摘要。每个摘要都按照从1（非常负面）到5（非常正面）的比例进行了情感评级。为了衡量语言模型的有效性，将它们的情感评级与人工专家生成的评级进行了比较。我们的研究结果显示了GPT-3.5-turbo和GPT-4之间明显的性能差异，后者在人类评估测试中展现出了显著的准确性。

    In the rapidly advancing domain of artificial intelligence, state-of-the-art language models such as OpenAI's GPT-3.5-turbo and GPT-4 offer unprecedented opportunities for automating complex tasks. This research paper delves into the capabilities of these models for semantically analyzing corporate disclosures in the Korean context, specifically for timely disclosure. The study focuses on the top 50 publicly traded companies listed on the Korean KOSPI, based on market capitalization, and scrutinizes their monthly disclosure summaries over a period of 17 months. Each summary was assigned a sentiment rating on a scale ranging from 1(very negative) to 5(very positive). To gauge the effectiveness of the language models, their sentiment ratings were compared with those generated by human experts. Our findings reveal a notable performance disparity between GPT-3.5-turbo and GPT-4, with the latter demonstrating significant accuracy in human evaluation tests. The Spearman correlation coefficie
    
[^23]: 探索文本地理信息的规律

    Exploring the law of text geographic information. (arXiv:2309.00180v1 [cs.CL])

    [http://arxiv.org/abs/2309.00180](http://arxiv.org/abs/2309.00180)

    该论文探索了文本地理信息的规律，通过研究不同语言和类型的数据集，证实了地理信息的数量、长度和距离符合Gamma分布，并且排除了高斯分布和Zipf定律的适用性。

    

    文本地理信息在实际应用中不可或缺且被广泛依赖。由于地理信息分布不清晰，有效利用地理信息面临着挑战，因此驱使我们进行探索。我们认为地理信息受到人类行为、认知、表达和思维过程的影响，基于我们对自然系统的直观理解，我们假设其符合Gamma分布。通过在包含不同语言和类型的24个数据集上进行严格实验，我们证实了这一假设，揭示了地理信息中数量、长度和距离的基本规律。此外，理论分析和与高斯分布和Zipf定律的比较证明了这些法则的不依赖性。重要的是，我们估计了人类利用地理信息的上限，指向t

    Textual geographic information is indispensable and heavily relied upon in practical applications. The absence of clear distribution poses challenges in effectively harnessing geographic information, thereby driving our quest for exploration. We contend that geographic information is influenced by human behavior, cognition, expression, and thought processes, and given our intuitive understanding of natural systems, we hypothesize its conformity to the Gamma distribution. Through rigorous experiments on a diverse range of 24 datasets encompassing different languages and types, we have substantiated this hypothesis, unearthing the underlying regularities governing the dimensions of quantity, length, and distance in geographic information. Furthermore, theoretical analyses and comparisons with Gaussian distributions and Zipf's law have refuted the contingency of these laws. Significantly, we have estimated the upper bounds of human utilization of geographic information, pointing towards t
    
[^24]: 情感分析是否需要亚文化？一种新的数据增强方法

    Will Sentiment Analysis Need Subculture? A New Data Augmentation Approach. (arXiv:2309.00178v1 [cs.CL])

    [http://arxiv.org/abs/2309.00178](http://arxiv.org/abs/2309.00178)

    本文提出了一种新的数据增强方法SCDA，通过利用亚文化表达生成器为每个训练文本生成六个增强文本，以解决情感分析中面临的训练数据不足问题。实验证明了SCDA的有效性和潜力。

    

    著名谚语“笔能胜过剑”强调了文字表达在塑造情感方面所具有的强大影响力。事实上，精心打造的文字可以在文化中产生深远共鸣，传达深刻的情感。如今，互联网的普及促成了围绕当代社会环境聚集的亚文化。亚文化通过热衷追求新奇来巧妙地表达人类情感的复杂性，这在情感分析中是不可忽视的事实。本文旨在通过亚文化的视角丰富数据，以解决情感分析面临的训练数据不足问题。为此，提出了一种基于亚文化的数据增强（SCDA）新方法，通过创建六种不同亚文化表达生成器，为每个训练文本生成六个增强文本。大量实验证实了SCDA的有效性和潜力。结果还揭示了该方法对提高情感分析性能的启示。

    The renowned proverb that "The pen is mightier than the sword" underscores the formidable influence wielded by text expressions in shaping sentiments. Indeed, well-crafted written can deeply resonate within cultures, conveying profound sentiments. Nowadays, the omnipresence of the Internet has fostered a subculture that congregates around the contemporary milieu. The subculture artfully articulates the intricacies of human feelings by ardently pursuing the allure of novelty, a fact that cannot be disregarded in the sentiment analysis. This paper strives to enrich data through the lens of subculture, to address the insufficient training data faced by sentiment analysis. To this end, a new approach of subculture-based data augmentation (SCDA) is proposed, which engenders six enhanced texts for each training text by leveraging the creation of six diverse subculture expression generators. The extensive experiments attest to the effectiveness and potential of SCDA. The results also shed lig
    
[^25]: LLM在Shell中的应用：生成式蜜罐

    LLM in the Shell: Generative Honeypots. (arXiv:2309.00155v1 [cs.CR])

    [http://arxiv.org/abs/2309.00155](http://arxiv.org/abs/2309.00155)

    本研究引入了一种基于大型语言模型的新方法来创建动态和真实的软件蜜罐，解决了以往蜜罐的重要局限性，并通过实验验证了其高准确率。

    

    蜜罐是网络安全中的重要工具。然而，大多数蜜罐（即使是高交互式的）缺乏足够的真实感来欺骗攻击者。这个限制使得它们很容易被识别，从而影响到它们的有效性。本研究引入了一种基于大型语言模型的新方法来创建动态和真实的软件蜜罐。初步结果表明，LLM能够创建可信且动态的蜜罐，能够解决以往蜜罐的重要局限性，如确定性响应、缺乏适应性等。我们通过与需要判断蜜罐回应是否虚假的攻击者进行实验来评估每个命令的真实性。我们提出的蜜罐，称为shelLM，达到了0.92的准确率。

    Honeypots are essential tools in cybersecurity. However, most of them (even the high-interaction ones) lack the required realism to engage and fool human attackers. This limitation makes them easily discernible, hindering their effectiveness. This work introduces a novel method to create dynamic and realistic software honeypots based on Large Language Models. Preliminary results indicate that LLMs can create credible and dynamic honeypots capable of addressing important limitations of previous honeypots, such as deterministic responses, lack of adaptability, etc. We evaluated the realism of each command by conducting an experiment with human attackers who needed to say if the answer from the honeypot was fake or not. Our proposed honeypot, called shelLM, reached an accuracy rate of 0.92.
    
[^26]: 建构语法与人工智能的关系

    Construction Grammar and Artificial Intelligence. (arXiv:2309.00135v1 [cs.AI])

    [http://arxiv.org/abs/2309.00135](http://arxiv.org/abs/2309.00135)

    建构语法和人工智能之间有着紧密的关系，人工智能领域的洞见和技术对于操作化建构主义方法以及构建智能代理非常重要。

    

    在本文中，我们认为对于当代的建构语法学者来说，深入理解建构语法与人工智能研究领域之间的紧密关系非常有益。我们首先揭示了两个领域之间的历史联系，展示了它们的关系根植于对人类沟通和语言的共同态度。然后我们讨论了第一个影响方向，特别关注人工智能领域的洞见和技术在操作化、验证和扩展语言建构主义方法中的重要作用。然后，我们进一步讨论了第二个影响方向，强调建构语法洞见和分析对于构建真正智能代理的人工智能努力的重要性。我们用各种例子支持我们的观点，并得出结论认为进一步发展这种关系十分重要。

    In this chapter, we argue that it is highly beneficial for the contemporary construction grammarian to have a thorough understanding of the strong relationship between the research fields of construction grammar and artificial intelligence. We start by unravelling the historical links between the two fields, showing that their relationship is rooted in a common attitude towards human communication and language. We then discuss the first direction of influence, focussing in particular on how insights and techniques from the field of artificial intelligence play an important role in operationalising, validating and scaling constructionist approaches to language. We then proceed to the second direction of influence, highlighting the relevance of construction grammar insights and analyses to the artificial intelligence endeavour of building truly intelligent agents. We support our case with a variety of illustrative examples and conclude that the further elaboration of this relationship wi
    
[^27]: QS-TTS: 通过向量量化自监督语音表示学习实现半监督文本到语音合成

    QS-TTS: Towards Semi-Supervised Text-to-Speech Synthesis via Vector-Quantized Self-Supervised Speech Representation Learning. (arXiv:2309.00126v1 [cs.SD])

    [http://arxiv.org/abs/2309.00126](http://arxiv.org/abs/2309.00126)

    通过向量量化自监督语音表示学习，QS-TTS是一种半监督的TTS框架，通过利用更多无标签语音音频提高合成质量并降低对有监督数据的要求。

    

    本文提出了一种新颖的半监督TTS框架QS-TTS，通过利用更多无标签语音音频的向量量化自监督语音表示学习（VQ-S3RL）来提高TTS质量，并降低对有监督数据的要求。该框架包括两个VQ-S3R学习器：首先，主要学习器通过多阶段多码本（MSMC）VQ-S3R与对比式S3RL相结合的MSMC-VQ-GAN生成高质量音频，然后解码回原音频；同时，副学习器通过VQ-VAE将MSMC表示进一步抽象为高度紧凑的VQ表示。这两个生成式VQ-S3R学习器为TTS提供了有利的语音表示和预训练模型，显著提高了合成质量并降低了对有监督数据的要求。QS-TTS在各种场景下进行了全面的主观和客观测试实验评估。实验结果有力地证明了其卓越的性能。

    This paper proposes a novel semi-supervised TTS framework, QS-TTS, to improve TTS quality with lower supervised data requirements via Vector-Quantized Self-Supervised Speech Representation Learning (VQ-S3RL) utilizing more unlabeled speech audio. This framework comprises two VQ-S3R learners: first, the principal learner aims to provide a generative Multi-Stage Multi-Codebook (MSMC) VQ-S3R via the MSMC-VQ-GAN combined with the contrastive S3RL, while decoding it back to the high-quality audio; then, the associate learner further abstracts the MSMC representation into a highly-compact VQ representation through a VQ-VAE. These two generative VQ-S3R learners provide profitable speech representations and pre-trained models for TTS, significantly improving synthesis quality with the lower requirement for supervised data. QS-TTS is evaluated comprehensively under various scenarios via subjective and objective tests in experiments. The results powerfully demonstrate the superior performance of
    
[^28]: 医学中的大语言模型：潜力与风险

    Large language models in medicine: the potentials and pitfalls. (arXiv:2309.00087v1 [cs.CL])

    [http://arxiv.org/abs/2309.00087](http://arxiv.org/abs/2309.00087)

    医学中大规模语言模型（LLMs）的潜力和风险。LLMs已经被广泛应用于医疗任务，但在使用时存在潜在的问题。本文回顾了LLMs的发展、应用和可能的限制，以帮助医疗从业者理解和应对LLMs在医学中的挑战。

    

    大规模语言模型（LLMs）已经被应用于医疗中的各种任务，从医学考试问题到回答患者问题。随着生产LLMs的公司与医疗系统之间的机构合作增加，真实世界的临床应用正逐渐成为现实。随着这些模型的推广，医疗从业者了解LLMs是什么，它们的发展以及在医学中的当前和潜在应用，以及在使用LLMs时可能出现的问题至关重要。本综述和配套教程旨在为医疗从业者提供关于这些主题的概述，以帮助他们理解LLMs在医学中应用的快速变化的情况。

    Large language models (LLMs) have been applied to tasks in healthcare, ranging from medical exam questions to responding to patient questions. With increasing institutional partnerships between companies producing LLMs and healthcare systems, real world clinical application is coming closer to reality. As these models gain traction, it is essential for healthcare practitioners to understand what LLMs are, their development, their current and potential applications, and the associated pitfalls when utilized in medicine. This review and accompanying tutorial aim to give an overview of these topics to aid healthcare practitioners in understanding the rapidly changing landscape of LLMs as applied to medicine.
    
[^29]: YaRN: 大型语言模型的高效上下文窗口扩展方法

    YaRN: Efficient Context Window Extension of Large Language Models. (arXiv:2309.00071v1 [cs.CL])

    [http://arxiv.org/abs/2309.00071](http://arxiv.org/abs/2309.00071)

    YaRN是一种高效的上下文窗口扩展方法，可以在大型语言模型中有效利用和推断比原始预训练允许的上下文长度更长的上下文，同时超越了之前的最新研究成果。

    

    旋转位置嵌入（RoPE）已被证明可以有效地编码transformer-based语言模型中的位置信息。然而，这些模型在超过它们训练的序列长度时无法泛化。我们提出了YaRN（Yet another RoPE extensioN method），一种计算高效的方法来扩展这些模型的上下文窗口，需要的tokens数量和训练步骤少于之前的方法的10倍和2.5倍。使用YaRN，我们展示了LLaMA模型可以有效地利用和推断比原始预训练允许的上下文长度更长的上下文，并且在上下文窗口扩展方面超过了之前的最新研究成果。此外，我们还展示了YaRN具有超越微调数据集有限上下文的能力。我们在https://github.com/jquesnelle/yarn上发布了使用64k和128k上下文窗口进行Fine-tuning的Llama 2 7B/13B的检查点。

    Rotary Position Embeddings (RoPE) have been shown to effectively encode positional information in transformer-based language models. However, these models fail to generalize past the sequence length they were trained on. We present YaRN (Yet another RoPE extensioN method), a compute-efficient method to extend the context window of such models, requiring 10x less tokens and 2.5x less training steps than previous methods. Using YaRN, we show that LLaMA models can effectively utilize and extrapolate to context lengths much longer than their original pre-training would allow, while also surpassing previous the state-of-the-art at context window extension. In addition, we demonstrate that YaRN exhibits the capability to extrapolate beyond the limited context of a fine-tuning dataset. We publish the checkpoints of Llama 2 7B/13B fine-tuned using YaRN with 64k and 128k context windows at https://github.com/jquesnelle/yarn
    
[^30]: 美国法律体系是否准备好应对人工智能对人类价值观的挑战？

    Is the U.S. Legal System Ready for AI's Challenges to Human Values?. (arXiv:2308.15906v1 [cs.CY])

    [http://arxiv.org/abs/2308.15906](http://arxiv.org/abs/2308.15906)

    美国法律需要加强应对生成式人工智能对人类价值观挑战的能力，并提供积极、可审计的指导，以填补现有法律框架在保护基本价值观方面的空白和不确定性。

    

    我们的跨学科研究调查了美国法律在面对生成式人工智能对人类价值观挑战时的有效性。通过分析专家研讨会期间制定的多种假设情景，我们发现现有法律框架在保护自主权、隐私权、尊严、多样性、平等以及身心健康等基本价值观方面存在明显的空白和不确定性。宪法和民权法似乎无法对人工智能生成的歧视性产出提供足够的保护。此外，即使我们排除第230条款提供的责任保护，由于人工智能系统的复杂和不透明性，证明诽谤和产品责任索赔的因果关系也是一项具有挑战性的任务。为了应对生成式人工智能带来的独特和难以预测的威胁，我们主张建立能够适应新威胁并为行业利益相关者提供积极、可审计的指导的法律框架。

    Our interdisciplinary study investigates how effectively U.S. laws confront the challenges posed by Generative AI to human values. Through an analysis of diverse hypothetical scenarios crafted during an expert workshop, we have identified notable gaps and uncertainties within the existing legal framework regarding the protection of fundamental values, such as autonomy, privacy, dignity, diversity, equality, and physical/mental well-being. Constitutional and civil rights, it appears, may not provide sufficient protection against AI-generated discriminatory outputs. Furthermore, even if we exclude the liability shield provided by Section 230, proving causation for defamation and product liability claims is a challenging endeavor due to the intricate and opaque nature of AI systems. To address the unique and unforeseeable threats posed by Generative AI, we advocate for legal frameworks that evolve to recognize new threat and provide proactive, auditable guidelines to industry stakeholders
    
[^31]: 有效的语言模型基准测试

    Efficient Benchmarking (of Language Models). (arXiv:2308.11696v1 [cs.CL])

    [http://arxiv.org/abs/2308.11696](http://arxiv.org/abs/2308.11696)

    本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。

    

    语言模型的多功能性增加导致了一类全面评估广泛能力的基准测试的出现。这些基准测试与大规模计算成本相关，每个模型需要数千个GPU小时。然而，关于评估效率方面的问题在文献中讨论较少。本文提出了一种名为"Efficient Benchmarking"的问题，即在不损害可靠性的情况下智能地减少语言模型评估的计算成本。通过使用HELM基准测试作为示例，我们研究了不同基准测试设计选择如何影响计算-可靠性权衡。我们提出使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估这些决策的可靠性。例如，我们发现仅通过从基准测试中删除一个低排名模型，当前在HELM上的领先者可能会改变，并且观察到只需一小部分示例即可获得正确的基准测试排名。

    The increasing versatility of language models LMs has given rise to a new class of benchmarks that comprehensively assess a broad range of capabilities. Such benchmarks are associated with massive computational costs reaching thousands of GPU hours per model. However the efficiency aspect of these evaluation efforts had raised little discussion in the literature. In this work we present the problem of Efficient Benchmarking namely intelligently reducing the computation costs of LM evaluation without compromising reliability. Using the HELM benchmark as a test case we investigate how different benchmark design choices affect the computation-reliability tradeoff. We propose to evaluate the reliability of such decisions by using a new measure Decision Impact on Reliability DIoR for short. We find for example that the current leader on HELM may change by merely removing a low-ranked model from the benchmark and observe that a handful of examples suffice to obtain the correct benchmark rank
    
[^32]: 激活添加: 无需优化即可操纵语言模型

    Activation Addition: Steering Language Models Without Optimization. (arXiv:2308.10248v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10248](http://arxiv.org/abs/2308.10248)

    这项研究探讨了一种在推理时通过改变激活来预测性地改变语言模型行为的方法，并且相比于传统方法具有更低的计算和实施成本，并且能够保持模型性能。

    

    可靠地控制大型语言模型的行为是一个紧迫的开放性问题。现有的方法包括有监督微调、根据人类反馈进行强化学习、提示工程和引导解码。我们相反，研究了激活工程：在推理时修改激活以可预测地改变模型行为。特别地，我们通过自然语言隐式指定了一个添加的“导向向量”来偏置前向传播。与以前学习这些导向向量的工作不同，我们的激活添加（ActAdd）方法通过计算来自提示对的激活差异来计算它们。我们在OpenWebText和ConceptNet上展示了ActAdd在GPT-2上的应用。我们的推理时方法控制了输出的高级属性并保持了非目标模型的性能。它所需的计算和实施工作比微调要少得多，允许用户提供自然语言的规范，并且其开销与模型规模自然地扩展。

    Reliably controlling the behavior of large language models is a pressing open problem. Existing methods include supervised finetuning, reinforcement learning from human feedback, prompt engineering, and guided decoding. We instead investigate activation engineering: modifying activations at inference time to predictably alter model behavior. In particular, we bias the forward pass with an added 'steering vector' implicitly specified through natural language.  Unlike past work which learned these steering vectors, our Activation Addition (ActAdd) method computes them by taking the activation differences that result from pairs of prompts. We demonstrate ActAdd on GPT-2 on OpenWebText and ConceptNet. Our inference-time approach yields control over high-level properties of output and preserves off-target model performance. It involves far less compute and implementation effort than finetuning, allows users to provide natural language specifications, and its overhead scales naturally with m
    
[^33]: 打破语言障碍：用于印地语和马拉地语的问答数据集

    Breaking Language Barriers: A Question Answering Dataset for Hindi and Marathi. (arXiv:2308.09862v1 [cs.CL])

    [http://arxiv.org/abs/2308.09862](http://arxiv.org/abs/2308.09862)

    本论文开发了一个用于印地语和马拉地语的问答数据集，通过翻译SQuAD 2.0数据集解决了数据稀缺问题，提供了这两种语言的最好表现模型。

    

    深度学习的最新进展导致了开发出高度复杂的系统，对数据有着无止境的需求。然而，对于低资源语言来说，构建良好的深度学习模型仍然是一个具有挑战性的任务。本文重点是为两种这样的语言-印地语和马拉地语-开发一个问答数据集。虽然印地语是全球第三大使用人数最多的语言，拥有3.45亿说话者，而马拉地语则是全球第11大使用人数最多的语言，拥有8.32千万说话者，但这两种语言在构建高效的问答系统的资源上都面临限制。为了解决数据稀缺的挑战，我们开发了一种新颖的方法来将SQuAD 2.0数据集翻译成印地语和马拉地语。我们发布了这两种语言中最大的问答数据集，每个数据集包含28,000个样本。我们在各种架构上评估了数据集，并发布了在印地语和马拉地语中表现最好的模型。

    The recent advances in deep-learning have led to the development of highly sophisticated systems with an unquenchable appetite for data. On the other hand, building good deep-learning models for low-resource languages remains a challenging task. This paper focuses on developing a Question Answering dataset for two such languages- Hindi and Marathi. Despite Hindi being the 3rd most spoken language worldwide, with 345 million speakers, and Marathi being the 11th most spoken language globally, with 83.2 million speakers, both languages face limited resources for building efficient Question Answering systems. To tackle the challenge of data scarcity, we have developed a novel approach for translating the SQuAD 2.0 dataset into Hindi and Marathi. We release the largest Question-Answering dataset available for these languages, with each dataset containing 28,000 samples. We evaluate the dataset on various architectures and release the best-performing models for both Hindi and Marathi, which 
    
[^34]: 用条件扩散模型和语言模型进行最小监督语音合成：基于语义编码的比较研究

    Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding. (arXiv:2307.15484v1 [cs.SD])

    [http://arxiv.org/abs/2307.15484](http://arxiv.org/abs/2307.15484)

    本文提出了两种语音合成方法来解决自回归和非自回归模型中的问题，并在语义编码方面进行了比较研究。

    

    近年来，对于能够采用最小监督训练方法的文本到语音(TTS)技术越来越受关注，该方法通过结合两种离散语音表示并使用两种序列到序列任务来解耦TTS。为了解决离散表示中的高维度和波形失真的挑战，我们提出了Diff-LM-Speech方法，该方法基于扩散模型将语义嵌入模型为基于mel频谱图，并引入基于变分自动编码器和韵律瓶颈的提示编码结构，以提高提示表示能力。自回归语言模型常常遇到缺失和重复单词的问题，而非自回归框架由于预测模型的存在导致表达平均问题。为了解决这些问题，我们提出了Tetra-Diff-Speech，该方法设计了一个时长扩散模型以实现多样化的韵律表达。我们期望语义编码的信息内容介于...

    Recently, there has been a growing interest in text-to-speech (TTS) methods that can be trained with minimal supervision by combining two types of discrete speech representations and using two sequence-to-sequence tasks to decouple TTS. To address the challenges associated with high dimensionality and waveform distortion in discrete representations, we propose Diff-LM-Speech, which models semantic embeddings into mel-spectrogram based on diffusion models and introduces a prompt encoder structure based on variational autoencoders and prosody bottlenecks to improve prompt representation capabilities. Autoregressive language models often suffer from missing and repeated words, while non-autoregressive frameworks face expression averaging problems due to duration prediction models. To address these issues, we propose Tetra-Diff-Speech, which designs a duration diffusion model to achieve diverse prosodic expressions. While we expect the information content of semantic coding to be between t
    
[^35]: 用基于人工智能的大型语言模型扩展全球心理健康心理服务的Psy-LLM

    Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models. (arXiv:2307.11991v1 [cs.CL])

    [http://arxiv.org/abs/2307.11991](http://arxiv.org/abs/2307.11991)

    Psy-LLM是一个基于人工智能的系统，利用大型语言模型（LLMs）为在线心理咨询提供问答服务，前端工具可让医疗专业人员提供即时响应和正念活动，同时还可作为筛查工具辅助识别紧急案例。

    

    近年来，心理咨询的需求显著增长，特别是随着全球COVID-19的爆发，这加强了及时和专业的心理健康支持的需求。在线心理咨询成为应对这一需求的主要服务方式。在本研究中，我们提出了Psy-LLM框架，这是一种基于人工智能的系统，利用大型语言模型（LLMs）进行在线心理咨询中的问答。我们的框架结合了经过预训练的LLMs和从心理学家和广泛收集的心理文章中获取的真实世界专业问答。Psy-LLM框架作为医疗专业人员的前端工具，允许他们提供即时响应和正念活动来缓解患者压力，同时还可以作为筛查工具，识别需要进一步协助的紧急案例。我们使用困惑度等内在度量标准和外部度量标准对框架进行了评估。

    The demand for psychological counseling has grown significantly in recent years, particularly with the global outbreak of COVID-19, which has heightened the need for timely and professional mental health support. Online psychological counseling has emerged as the predominant mode of providing services in response to this demand. In this study, we propose the Psy-LLM framework, an AI-based system leveraging Large Language Models (LLMs) for question-answering in online psychological consultation. Our framework combines pre-trained LLMs with real-world professional Q&A from psychologists and extensively crawled psychological articles. The Psy-LLM framework serves as a front-end tool for healthcare professionals, allowing them to provide immediate responses and mindfulness activities to alleviate patient stress. Additionally, it functions as a screening tool to identify urgent cases requiring further assistance. We evaluated the framework using intrinsic metrics, such as perplexity, and ex
    
[^36]: 揭示在LLM中职业性别偏见：分析和解决社会学影响

    Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications. (arXiv:2307.09162v1 [cs.CL])

    [http://arxiv.org/abs/2307.09162](http://arxiv.org/abs/2307.09162)

    本研究分析了大型语言模型中的性别偏见，以GPT-2和GPT-3.5为例，通过全面的文献综述和深入的定量分析揭示了存在的性别化词语关联、语言使用和偏见叙述，并探讨了性别偏见可能对社会认知产生的伦理影响。

    

    人工智能（AI）和自然语言处理中的性别偏见引起了广泛关注，因为它可能对社会认知和偏见产生影响。这篇研究旨在分析大型语言模型（LLMs）中的性别偏见，重点比较了GPT-2和GPT-3.5这些著名语言模型，以更好地理解其影响。通过全面的文献综述，该研究考察了现有关于AI语言模型中性别偏见的研究，并确定了当前知识的空白。研究方法包括收集和预处理GPT-2和GPT-3.5的数据，并运用深入的定量分析技术评估生成文本中的性别偏见。研究结果揭示了这些大型语言模型输出中存在的具有性别色彩的词语关联、语言使用和偏见叙述。讨论部分探讨了性别偏见的伦理影响以及其对社会认知的潜在后果。

    Gender bias in artificial intelligence (AI) and natural language processing has garnered significant attention due to its potential impact on societal perceptions and biases. This research paper aims to analyze gender bias in Large Language Models (LLMs) with a focus on multiple comparisons between GPT-2 and GPT-3.5, some prominent language models, to better understand its implications. Through a comprehensive literature review, the study examines existing research on gender bias in AI language models and identifies gaps in the current knowledge. The methodology involves collecting and preprocessing data from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis techniques to evaluate gender bias in the generated text. The findings shed light on gendered word associations, language usage, and biased narratives present in the outputs of these Large Language Models. The discussion explores the ethical implications of gender bias and its potential consequences on social percepti
    
[^37]: AspectCSE: 使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入

    AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])

    [http://arxiv.org/abs/2307.07851](http://arxiv.org/abs/2307.07851)

    AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。

    

    通用的句子嵌入提供了对语义文本相似性的粗略近似，但忽略了使文本相似的特定方面。相反，基于方面的句子嵌入提供了基于预定义方面的文本相似性。因此，文本的相似性预测更加针对特定要求，并且更容易解释。在本文中，我们提出了AspectCSE，一种用于基于方面的对比学习句子嵌入的方法。结果表明，与之前最好的结果相比，AspectCSE在多个方面的信息检索任务中实现了平均改善3.97%。我们还提出使用Wikidata知识图属性来训练多方面句子嵌入模型，其中在相似性预测过程中同时考虑多个特定方面。我们证明了多方面嵌入在特定方面信息检索任务上优于单方面嵌入。最后，我们展示了嵌入模型的可解释性，并提出通过对比学习来改进嵌入质量。

    Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
    
[^38]: 在课堂上学习提示以了解人工智能的限制：一项试点研究

    Learning to Prompt in the Classroom to Understand AI Limits: A pilot study. (arXiv:2307.01540v1 [cs.HC])

    [http://arxiv.org/abs/2307.01540](http://arxiv.org/abs/2307.01540)

    在本研究中，通过学习提示，试图在课堂环境中理解人工智能的限制。人工智能的进展带来了巨大的潜力，但也引发了负面情绪。当前大型语言模型的能力限制被忽视，导致了错误的自信和不准确的建议。承认人工智能的不可靠性是解决这个问题的关键。

    

    人工智能的进展在帮助社会解决紧迫的社会问题方面具有巨大的潜力。特别是大型语言模型（LLM）和派生的聊天机器人，如ChatGPT，大大改进了AI系统的自然语言处理能力，使其能够处理前所未有的大量非结构化数据。由此产生的炒作也产生了负面情绪，即使在新颖的AI方法取得令人惊讶的贡献之后。造成这种情况的原因之一，但也是一个重要的问题本身，是越来越多人错误地认为自己能够轻松访问和处理任何形式的知识，以解决任何领域的问题，无需对AI或问题领域有任何专业知识，而忽视了当前LLMs的限制，例如幻觉和推理限制。承认人工智能的不可靠性对于解决由LLMs生成的可能错误建议可能产生的盲目过度自信的影响至关重要。同时，这可以减少恐惧和其他负面态度。

    Artificial intelligence's progress holds great promise in assisting society in addressing pressing societal issues. In particular Large Language Models (LLM) and the derived chatbots, like ChatGPT, have highly improved the natural language processing capabilities of AI systems allowing them to process an unprecedented amount of unstructured data. The consequent hype has also backfired, raising negative sentiment even after novel AI methods' surprising contributions. One of the causes, but also an important issue per se, is the rising and misleading feeling of being able to access and process any form of knowledge to solve problems in any domain with no effort or previous expertise in AI or problem domain, disregarding current LLMs limits, such as hallucinations and reasoning limits. Acknowledging AI fallibility is crucial to address the impact of dogmatic overconfidence in possibly erroneous suggestions generated by LLMs. At the same time, it can reduce fear and other negative attitude
    
[^39]: CLIPAG: 走向无需生成器的文本到图像生成

    CLIPAG: Towards Generator-Free Text-to-Image Generation. (arXiv:2306.16805v1 [cs.CV])

    [http://arxiv.org/abs/2306.16805](http://arxiv.org/abs/2306.16805)

    本文将感知对齐梯度（PAG）的研究扩展到视觉-语言架构，并通过对 CLIP 进行鲁棒性调整，展示了在视觉-语言生成任务中集成 CLIPAG 可以实现显著改进，并实现了无生成器的文本到图像生成。

    

    感知对齐梯度 (Perceptually Aligned Gradients, PAG) 是在健壮的图像分类模型中观察到的一种有趣属性，其中它们的输入渐变与人类感知对齐并具有语义意义。虽然这一现象引起了显着的研究关注，但仅仅在单模态纯视觉架构的背景下进行了研究。在本研究中，我们将 PAG 的研究扩展到视觉-语言架构，这是多样化的图像-文本任务和应用的基础。通过对 CLIP 进行对抗性鲁棒微调，我们证明了鲁棒的视觉-语言模型相对于其基准模型表现出了 PAG。这项工作展示了 CLIPAG 在几种视觉-语言生成任务中的优势。值得注意的是，我们展示了无缝集成 CLIPAG 的 "即插即用" 方式显著改进了视觉-语言生成应用。此外，利用其 PAG 属性，CLIPAG 实现了无生成器的文本到图像生成。

    Perceptually Aligned Gradients (PAG) refer to an intriguing property observed in robust image classification models, wherein their input gradients align with human perception and pose semantic meanings. While this phenomenon has gained significant research attention, it was solely studied in the context of unimodal vision-only architectures. In this work, we extend the study of PAG to Vision-Language architectures, which form the foundations for diverse image-text tasks and applications. Through an adversarial robustification finetuning of CLIP, we demonstrate that robust Vision-Language models exhibit PAG in contrast to their vanilla counterparts. This work reveals the merits of CLIP with PAG (CLIPAG) in several vision-language generative tasks. Notably, we show that seamlessly integrating CLIPAG in a "plug-n-play" manner leads to substantial improvements in vision-language generative applications. Furthermore, leveraging its PAG property, CLIPAG enables text-to-image generation witho
    
[^40]: C-PMI: 条件点对点互信息用于对话评估的方法研究

    C-PMI: Conditional Pointwise Mutual Information for Turn-level Dialogue Evaluation. (arXiv:2306.15245v1 [cs.CL])

    [http://arxiv.org/abs/2306.15245](http://arxiv.org/abs/2306.15245)

    本研究提出了一种基于条件点对点互信息的模型-无关方法，用于衡量对话系统与用户之间的交互，通过替换评分器，显著改进了与人类判断的相关性。

    

    现有的chatbot的无参考级对话评估指标不足以捕捉用户与系统之间的交互。因此，它们通常与人类评估的相关性较差。为解决这一问题，我们提出了一种新颖的模型无关方法，利用条件点对点互信息（C-PMI）来度量系统和用户之间基于给定评估维度的对话交互。在广泛使用的FED对话评估数据集上的实验结果表明，与现有评估系统相比，我们的方法显著提高了与人类判断的相关性。通过将基于负对数似然的评分器替换为我们提出的C-PMI评分器，我们在FED评估指标上的Spearman相关性平均相对提高了60.5%。我们的代码公开发布在https://github.com/renll/C-PMI。

    Existing reference-free turn-level evaluation metrics for chatbots inadequately capture the interaction between the user and the system. Consequently, they often correlate poorly with human evaluations. To address this issue, we propose a novel model-agnostic approach that leverages Conditional Pointwise Mutual Information (C-PMI) to measure the turn-level interaction between the system and the user based on a given evaluation dimension. Experimental results on the widely used FED dialogue evaluation dataset demonstrate that our approach significantly improves the correlation with human judgment compared with existing evaluation systems. By replacing the negative log-likelihood-based scorer with our proposed C-PMI scorer, we achieve a relative 60.5% higher Spearman correlation on average for the FED evaluation metric. Our code is publicly available at https://github.com/renll/C-PMI.
    
[^41]: 从文本中丰富本体知识：一种用于概念发现和放置的生物医学数据集

    Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement. (arXiv:2306.14704v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.14704](http://arxiv.org/abs/2306.14704)

    本研究提出了一个新的数据集，通过在PubMed摘要中使用SNOMED CT版本，解决了先前数据集所存在的问题，可以用于自动化地发现和放置新概念到知识库中。

    

    新概念的提及经常出现在文本中，需要自动化的方法将其收集并放置到知识库（例如本体和分类系统）中。现有的数据集存在三个问题：（一）大部分假设新概念已经被发现，不能支持概念发现；（二）只使用概念标签作为输入，缺乏概念标签的上下文信息；（三）主要关注与原子概念的分类，而不是复杂概念（包含逻辑运算符）的放置。为了解决这些问题，我们提出了一个新的基准，使用2014年和2017年的SNOMED CT版本适配MedMentions数据集（PubMed摘要），涵盖疾病子类别和更广泛的临床发现、过程以及制药/生物产品类别。我们用该数据集评估了概念发现和放置的工作，并对其进行了使用方式的说明。

    Mentions of new concepts appear regularly in texts and require automated approaches to harvest and place them into Knowledge Bases (KB), e.g., ontologies and taxonomies. Existing datasets suffer from three issues, (i) mostly assuming that a new concept is pre-discovered and cannot support out-of-KB mention discovery; (ii) only using the concept label as the input along with the KB and thus lacking the contexts of a concept label; and (iii) mostly focusing on concept placement w.r.t a taxonomy of atomic concepts, instead of complex concepts, i.e., with logical operators. To address these issues, we propose a new benchmark, adapting MedMentions dataset (PubMed abstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases sub-category and the broader categories of Clinical finding, Procedure, and Pharmaceutical / biologic product. We provide usage on the evaluation with the dataset for out-of-KB mention discovery and concept placement, adapting recent Large Language Model based m
    
[^42]: Lingua Manga: 一个以大型语言模型为中心的通用数据管理系统

    Lingua Manga: A Generic Large Language Model Centric System for Data Curation. (arXiv:2306.11702v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2306.11702](http://arxiv.org/abs/2306.11702)

    Lingua Manga是一个以大型语言模型为中心的通用数据管理系统，通过自动优化实现高性能和标签效率，同时促进灵活和快速开发。它能够有效地协助熟练的程序员和低代码甚至无代码用户解决数据管理挑战。

    

    数据管理是一个广泛的领域，包含许多关键但耗时的数据处理任务。然而，这些任务的多样性使得开发通用数据管理系统具有挑战性。为了解决这个问题，我们提出了Lingua Manga，一个用户友好且多功能的系统，利用预训练的大型语言模型。Lingua Manga通过三个具有不同目标和技术水平的用户的示例应用，展示了它可以有效地协助熟练的程序员和低代码甚至无代码用户解决数据管理挑战。

    Data curation is a wide-ranging area which contains many critical but time-consuming data processing tasks. However, the diversity of such tasks makes it challenging to develop a general-purpose data curation system. To address this issue, we present Lingua Manga, a user-friendly and versatile system that utilizes pre-trained large language models. Lingua Manga offers automatic optimization for achieving high performance and label efficiency while facilitating flexible and rapid development. Through three example applications with distinct objectives and users of varying levels of technical proficiency, we demonstrate that Lingua Manga can effectively assist both skilled programmers and low-code or even no-code users in addressing data curation challenges.
    
[^43]: RS5M：用于遥感视觉-语言基础模型的大规模视觉-语言数据集

    RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model. (arXiv:2306.11300v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.11300](http://arxiv.org/abs/2306.11300)

    本文提出了一个新的框架RS5M，该框架包括领域基础模型（DFM），用于实现通用基础模型（GFM）和领域特定下游任务之间的转换。另外，还介绍了一个遥感领域的大规模图像-文本配对数据集RS5M，该数据集是通过过滤公开可用的图像-文本配对数据集并使用预训练的视觉-语言基础模型为标签数据集生成标题。

    

    利用大量图像-文本配对数据进行预训练的视觉-语言基础模型展示了前所未有的图像-文本关联能力，在各种下游任务中取得了显著的成果。关键挑战是如何利用已有的大规模预训练的视觉-语言基础模型，在域相关的下游任务中进行领域特定的迁移。本文提出了一个新的框架，包括领域基础模型（DFM），弥合了通用基础模型（GFM）和领域特定下游任务之间的差距。此外，我们还介绍了一个遥感领域（RS）的图像-文本配对数据集RS5M，其中包含了500万张带有英文描述的RS图像。该数据集是通过过滤公开可用的图像-文本配对数据集，并使用预训练的视觉-语言基础模型为仅带标签的RS数据集生成标题。这是第一个大规模的RS图像-文本配对数据集。

    Pre-trained Vision-Language Foundation Models utilizing extensive image-text paired data have demonstrated unprecedented image-text association capabilities, achieving remarkable results across various downstream tasks. A critical challenge is how to make use of existing large-scale pre-trained VLMs, which are trained on common objects, to perform the domain-specific transfer for accomplishing domain-related downstream tasks. In this paper, we propose a new framework that includes the Domain Foundation Model (DFM), bridging the gap between the General Foundation Model (GFM) and domain-specific downstream tasks. Moreover, we present an image-text paired dataset in the field of remote sensing (RS), RS5M, which has 5 million RS images with English descriptions. The dataset is obtained from filtering publicly available image-text paired datasets and captioning label-only RS datasets with pre-trained VLM. These constitute the first large-scale RS image-text paired dataset. Additionally, we 
    
[^44]: 构建掩码语言模型中社会偏见的整体评估指标

    Constructing Holistic Measures for Social Biases in Masked Language Models. (arXiv:2305.07795v1 [cs.CL])

    [http://arxiv.org/abs/2305.07795](http://arxiv.org/abs/2305.07795)

    本文提出了KLDivS和JSDivS这两个评估指标，将掩码语言模型输出的刻板印象和反刻板印象样本的对数似然函数视为高斯分布，可以更稳定、可解释地评估MLMs中的社会偏见。

    

    掩码语言模型（MLMs）在许多自然语言处理任务中取得了成功。然而，由于从大型文本语料库中学习，MLMs 很可能反映现实中的刻板印象偏见。过去提出的大多数评估指标采用不同的掩码策略，设计了MLMs 的对数似然函数。这些指标缺乏对刻板印象和反刻板印象样本变化的考虑。本文将MLMs输出的刻板印象和反刻板印象样本的对数似然函数视为高斯分布，提出了两个评估指标——Kullback Leibler 散度得分（KLDivS）和Jensen Shannon 距离得分（JSDivS），以评估MLMs中的社会偏见。StereoSet 和CrowS-Pairs的公共数据集上的实验结果表明，与过去提出的指标相比，KLDivS和JSDivS更加稳定和可解释。

    Masked Language Models (MLMs) have been successful in many natural language processing tasks. However, real-world stereotype biases are likely to be reflected in MLMs due to their learning from large text corpora. Most of the evaluation metrics proposed in the past adopt different masking strategies, designed with the log-likelihood of MLMs. They lack holistic considerations such as variance for stereotype bias and anti-stereotype bias samples. In this paper, the log-likelihoods of stereotype bias and anti-stereotype bias samples output by MLMs are considered Gaussian distributions. Two evaluation metrics, Kullback Leibler Divergence Score (KLDivS) and Jensen Shannon Divergence Score (JSDivS) are proposed to evaluate social biases in MLMs The experimental results on the public datasets StereoSet and CrowS-Pairs demonstrate that KLDivS and JSDivS are more stable and interpretable compared to the metrics proposed in the past.
    
[^45]: 跨域文本到SQL自适应提示的基于案例推理框架

    A Case-Based Reasoning Framework for Adaptive Prompting in Cross-Domain Text-to-SQL. (arXiv:2304.13301v1 [cs.CL])

    [http://arxiv.org/abs/2304.13301](http://arxiv.org/abs/2304.13301)

    本文提出了一个基于案例推理框架的跨域文本到SQL自适应提示的解决方案，可以精确控制与案例相关和不相关的知识，解决了大型语言模型提示设计不良限制性能的问题。

    

    最近流行的大型语言模型（例如Codex、ChatGPT和GPT-4）在AI社区方面有了显著的进展，包括文本到SQL的任务。一些关于大型语言模型的评估和分析表明，它们有潜力生成SQL查询，但是它们所使用的提示设计不良（例如简单的结构或随机抽样）限制了大型语言模型的性能，并可能导致不必要或无关的输出。为了解决这些问题，我们提出了CBR-ApSQL，这是一个基于案例推理（CBR）的框架，与GPT-3.5相结合，用于在文本到SQL任务中对与案例相关和不相关的知识进行精确控制。我们设计了自适应提示，以灵活调整GPT-3.5的输入，其中涉及（1）通过去语义化输入问题来自适应检索案例，根据问题意图，以及（2）自适应回退机制，以确保提示的信息量和案例与提示之间的相关性。在去语义化阶段中，我们设计了Semantic D

    Recent advancements in Large Language Models (LLMs), such as Codex, ChatGPT and GPT-4 have significantly impacted the AI community, including Text-to-SQL tasks. Some evaluations and analyses on LLMs show their potential to generate SQL queries but they point out poorly designed prompts (e.g. simplistic construction or random sampling) limit LLMs' performance and may cause unnecessary or irrelevant outputs. To address these issues, we propose CBR-ApSQL, a Case-Based Reasoning (CBR)-based framework combined with GPT-3.5 for precise control over case-relevant and case-irrelevant knowledge in Text-to-SQL tasks. We design adaptive prompts for flexibly adjusting inputs for GPT-3.5, which involves (1) adaptively retrieving cases according to the question intention by de-semantizing the input question, and (2) an adaptive fallback mechanism to ensure the informativeness of the prompt, as well as the relevance between cases and the prompt. In the de-semanticization phase, we designed Semantic D
    
[^46]: LEVER: 使用执行进行语言到代码生成的学习验证

    LEVER: Learning to Verify Language-to-Code Generation with Execution. (arXiv:2302.08468v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08468](http://arxiv.org/abs/2302.08468)

    提出了一种使用执行结果来验证生成的程序的简单方法LEVER，通过训练验证器根据自然语言输入、程序本身和执行结果来确定程序的正确性，从而改进了语言到代码生成的过程。

    

    训练在代码上的大型语言模型（code LLMs）的出现，已经在语言到代码生成方面取得了显著进展。此领域的最新方法将LLM解码与使用测试用例或基于执行结果的启发式方法的样本修剪和重新排序相结合。然而，对于许多现实世界的语言到代码应用来说，获取测试用例是具有挑战性的，而启发式方法不能很好地捕捉执行结果的语义特征，比如数据类型和值范围，这往往表明程序的正确性。在这项工作中，我们提出了LEVER，一种通过学习使用执行结果来验证生成的程序，从而改进语言到代码生成的简单方法。具体地说，我们训练验证器根据自然语言输入、程序本身和执行结果来确定从LLM中抽样的程序是否正确。通过将验证分数与LLM生成分数相结合，对抽样的程序进行重新排序。

    The advent of large language models trained on code (code LLMs) has led to significant progress in language-to-code generation. State-of-the-art approaches in this area combine LLM decoding with sample pruning and reranking using test cases or heuristics based on the execution results. However, it is challenging to obtain test cases for many real-world language-to-code applications, and heuristics cannot well capture the semantic features of the execution results, such as data type and value range, which often indicates the correctness of the program. In this work, we propose LEVER, a simple approach to improve language-to-code generation by learning to verify the generated programs with their execution results. Specifically, we train verifiers to determine whether a program sampled from the LLMs is correct or not based on the natural language input, the program itself and its execution results. The sampled programs are reranked by combining the verification score with the LLM generati
    
[^47]: 大小不同的Transformer解码器

    Big Little Transformer Decoder. (arXiv:2302.07863v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07863](http://arxiv.org/abs/2302.07863)

    提出了一种名为BiLD的框架，它由大小不同的两个模型协作生成文本。其中小型模型自回归地生成文本，而大型模型则在必要时以非自回归的方式对小型模型的预测进行微调，从而显著减少了推理延迟。

    

    基于Transformer架构的大型语言模型的出现，使得自然语言处理领域取得了巨大的进展。然而，这些模型存在长时间的推理延迟，限制了它们的使用并且使得它们在各种实时应用中过于昂贵。在自回归生成任务中，由于模型需要迭代地运行才能逐个生成标记，因此推理延迟更加严重。为了解决这个问题，我们提出了Big Little Decoder（BiLD）框架，它可以提高各种文本生成应用的推理效率和延迟。BiLD框架包含两个不同大小的模型，它们协作地生成文本。小型模型自回归地运行以低延迟生成文本，大型模型只在需要时以非自回归的方式调整小型模型不准确的预测。为了提高训练的稳定性和改善模型性能，我们引入了一种渐进蒸馏机制，使小型模型逐渐地从大型模型中学习。实验结果证明，所提出的BiLD框架显著降低了推理延迟，同时在保持与大型自回归模型相当甚至更好的生成质量的情况下。

    The recent emergence of Large Language Models based on the Transformer architecture has enabled dramatic advancements in the field of Natural Language Processing. However, these models have long inference latency, which limits their deployment, and which makes them prohibitively expensive for various real-time applications. The inference latency is further exacerbated by autoregressive generative tasks, as models need to run iteratively to generate tokens sequentially without leveraging token-level parallelization. To address this, we propose Big Little Decoder (BiLD), a framework that can improve inference efficiency and latency for a wide range of text generation applications. The BiLD framework contains two models with different sizes that collaboratively generate text. The small model runs autoregressively to generate text with a low inference cost, and the large model is only invoked occasionally to refine the small model's inaccurate predictions in a non-autoregressive manner. To
    
[^48]: 领域无关的分子生成与自我反馈

    Domain-Agnostic Molecular Generation with Self-feedback. (arXiv:2301.11259v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11259](http://arxiv.org/abs/2301.11259)

    MolGen是一个专注于分子生成的预训练语言模型，使用了领域无关的分子前缀调整和自我反馈的范式，实现了化学有效性、多样性、新颖性和复杂性的突破，在分子生成领域表现出了出色的性能。

    

    分子的生成已经受到极大的关注，其革新了科学家设计分子结构的方式，并为化学和药物设计提供了宝贵的支持。然而，尽管在分子生成中使用语言模型具有潜力，但它们面临着许多挑战，比如生成语法或化学存在缺陷的分子，狭窄的领域专注以及由于缺乏注释数据或外部分子数据库而限制了生成多样性和可行性。因此，我们引入了MolGen，它是一个专门用于分子生成的预训练分子语言模型。MolGen通过重构一亿多个分子SELFIES获得了固有的结构和语法概念，并通过领域无关的分子前缀调整促进了不同领域之间的知识传递。此外，我们提出了一种自我反馈范式，启发预训练模型与最终下游目标对齐，有助于更稳健和高效的分子生成。我们在基准数据集上的实验表明，MolGen在化学有效性，多样性，新颖性和复杂性方面优于现有技术。

    The generation of molecules with desired properties has gained tremendous popularity, revolutionizing the way scientists design molecular structures and providing valuable support for chemical and drug design. However, despite the potential of language models in molecule generation, they face numerous challenges such as the generation of syntactically or chemically flawed molecules, narrow domain focus, and limitations in creating diverse and directionally feasible molecules due to a dearth of annotated data or external molecular databases. To this end, we introduce MolGen, a pre-trained molecular language model tailored specifically for molecule generation. MolGen acquires intrinsic structural and grammatical insights by reconstructing over 100 million molecular SELFIES, while facilitating knowledge transfer between different domains through domain-agnostic molecular prefix tuning. Moreover, we present a self-feedback paradigm that inspires the pre-trained model to align with the ulti
    
[^49]: ComCLIP: 无需训练的组合图像与文本匹配

    ComCLIP: Training-Free Compositional Image and Text Matching. (arXiv:2211.13854v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13854](http://arxiv.org/abs/2211.13854)

    本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。

    

    对比语言-图像预训练（CLIP）已经展示了在图像与文本匹配方面的很好的零样本性能。然而，将 CLIP 这样的视觉-语言预训练模型适应于更具挑战性的组合图像与文本匹配仍然具有挑战性，这需要模型理解组合词概念和视觉组件。为了实现更好的零样本图像与文本匹配中的组合泛化能力，本文从因果关系的角度研究了该问题：单个实体的错误语义本质上是导致匹配失败的混淆因素。因此，我们提出了一种新颖的“无需训练”的组合 CLIP 模型（ComCLIP）。ComCLIP将输入图像分解为主体、对象和动作子图像，并组合 CLIP 的视觉编码器和文本编码器，以在组合文本嵌入和子图像嵌入之上进行逐步匹配。通过这种方式，ComCLIP 可以减轻伪匹配问题。

    Contrastive Language-Image Pretraining (CLIP) has demonstrated great zero-shot performance for matching images and text. However, it is still challenging to adapt vision-lanaguage pretrained models like CLIP to compositional image and text matching -- a more challenging image and text matching task requiring the model understanding of compositional word concepts and visual components. Towards better compositional generalization in zero-shot image and text matching, in this paper, we study the problem from a causal perspective: the erroneous semantics of individual entities are essentially confounders that cause the matching failure. Therefore, we propose a novel \textbf{\textit{training-free}} compositional CLIP model (ComCLIP). ComCLIP disentangles input images into subjects, objects, and action sub-images and composes CLIP's vision encoder and text encoder to perform evolving matching over compositional text embedding and sub-image embeddings. In this way, ComCLIP can mitigate spurio
    
[^50]: 基于Zipf's Law的文本生成方法解决实体抽取中的数据不平衡问题

    A Zipf's Law-based Text Generation Approach for Addressing Imbalance in Entity Extraction. (arXiv:2205.12636v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12636](http://arxiv.org/abs/2205.12636)

    这项研究提出了一种基于Zipf's Law的方法，通过将文档中的词汇分类为常见词和稀缺词，并使用文本生成模型对句子进行处理，进而解决实体抽取中的数据不平衡问题。通过人设计的规则对生成的句子中的稀缺实体进行标记，作为原始数据集的补充，从而有效缓解了不平衡问题。

    

    实体抽取在各个领域的智能发展中至关重要。然而，其有效性受到数据不平衡的挑战。本文通过定量信息观察该问题，认识到实体表现出不同的共性和稀缺性，这可以在词汇的可量化分布中反映出来。Zipf's Law成为一个合适的采用方式，并且为了将词汇转变为实体，将文档中的词汇分类为常见词和稀缺词。随后，句子被分类为常见句和稀缺句，并根据这些分类使用文本生成模型进行进一步处理。生成的句子中的稀缺实体然后使用人设计的规则进行标记，作为原始数据集的补充，从而缓解了不平衡问题。本研究提供了从技术文档中提取实体的案例，并给出了两个数据集的实验结果。

    Entity extraction is critical in the intelligent advancement across diverse domains. Nevertheless, a challenge to its effectiveness arises from the data imbalance. This paper proposes a novel approach by viewing the issue through the quantitative information, recognizing that entities exhibit certain levels of commonality while others are scarce, which can be reflected in the quantifiable distribution of words. The Zipf's Law emerges as a well-suited adoption, and to transition from words to entities, words within the documents are classified as common and rare ones. Subsequently, sentences are classified into common and rare ones, and are further processed by text generation models accordingly. Rare entities within the generated sentences are then labeled using human-designed rules, serving as a supplement to the raw dataset, thereby mitigating the imbalance problem. The study presents a case of extracting entities from technical documents, and experimental results from two datasets p
    
[^51]: 一个基于多重分形的深度学习模型用于文本挖掘

    A New Multifractal-based Deep Learning Model for Text Mining. (arXiv:2111.13861v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.13861](http://arxiv.org/abs/2111.13861)

    该论文介绍了一个基于多重分形的深度学习模型，用于解读文本中隐藏的多重分形属性，并结合提出的激活函数，在神经网络结构中实现非线性信息传输。

    

    在这个充满不确定性的世界中，存在的纹理编织出复杂的模式，多重分形成为洞察力的标志，照亮它们。当我们深入探索构成各种自然语言处理应用和智能服务的文本挖掘领域时，我们意识到在文本的面纱后面隐藏着人类思想和认知的表现，与复杂性紧密相互交织。在将文本视为复杂系统的基础上，本研究致力于揭示其中隐藏的宝藏，借助提出的多重分形方法解读嵌入在文本景观中的多重分形属性。这一努力最终孕育出我们的新颖模型，该模型还利用了提出的激活函数的力量，在其神经网络结构中实现非线性信息传输。

    In this world full of uncertainty, where the fabric of existence weaves patterns of complexity, multifractal emerges as beacons of insight, illuminating them. As we delve into the realm of text mining that underpins various natural language processing applications and powers a range of intelligent services, we recognize that behind the veil of text lies a manifestation of human thought and cognition, intricately intertwined with the complexities. Building upon the foundation of perceiving text as a complex system, this study embarks on a journey to unravel the hidden treasures within, armed with the proposed multifractal method that deciphers the multifractal attributes embedded within the text landscape. This endeavor culminates in the birth of our novel model, which also harnesses the power of the proposed activation function to facilitate nonlinear information transmission within its neural network architecture. The success on experiments anchored in real-world technical reports cov
    

